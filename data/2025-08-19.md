<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 156]
- [cs.RO](#cs.RO) [Total: 47]
- [cs.LG](#cs.LG) [Total: 110]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [A Deep Learning-Based CCTV System for Automatic Smoking Detection in Fire Exit Zones](https://arxiv.org/abs/2508.11696)
*Sami Sadat,Mohammad Irtiza Hossain,Junaid Ahmed Sifat,Suhail Haque Rafi,Md. Waseq Alauddin Alvi,Md. Khalilur Rhaman*

Main category: cs.CV

TL;DR: 提出了一种基于深度学习的实时吸烟检测系统，用于监控消防出口区域，满足安全需求。


<details>
  <summary>Details</summary>
Motivation: 由于消防出口区域的吸烟行为可能引发严重安全问题，需要实时监控系统以确保公共安全。

Method: 评估了YOLOv8、YOLOv11和YOLOv12三种目标检测模型，并基于YOLOv8开发了定制模型，适应复杂监控场景。

Result: 定制模型表现最佳，召回率为78.90%，mAP@50为83.70%，在多种边缘设备上验证了实时性。

Conclusion: 该系统为公共安全监控和自动合规提供了强大且适应性强的平台。

Abstract: A deep learning real-time smoking detection system for CCTV surveillance of
fire exit areas is proposed due to critical safety requirements. The dataset
contains 8,124 images from 20 different scenarios along with 2,708 raw samples
demonstrating low-light areas. We evaluated three advanced object detection
models: YOLOv8, YOLOv11, and YOLOv12, followed by development of a custom model
derived from YOLOv8 with added structures for challenging surveillance
contexts. The proposed model outperformed the others, achieving a recall of
78.90 percent and mAP at 50 of 83.70 percent, delivering optimal object
detection across varied environments. Performance evaluation on multiple edge
devices using multithreaded operations showed the Jetson Xavier NX processed
data at 52 to 97 milliseconds per inference, establishing its suitability for
time-sensitive operations. This system offers a robust and adaptable platform
for monitoring public safety and enabling automatic regulatory compliance.

</details>


### [2] [Separating Knowledge and Perception with Procedural Data](https://arxiv.org/abs/2508.11697)
*Adrián Rodríguez-Muñoz,Manel Baradad,Phillip Isola,Antonio Torralba*

Main category: cs.CV

TL;DR: 该论文提出了一种仅使用程序化数据训练表示模型的方法，并通过视觉记忆（参考图像嵌入的显式数据库）在视觉相似性、分类和语义分割任务中实现强性能，且无需进一步训练。


<details>
  <summary>Details</summary>
Motivation: 研究动机是实现与真实世界图像的完全隔离，同时保持高性能的视觉表示模型。

Method: 方法是通过程序化数据训练表示模型，并利用视觉记忆（参考图像嵌入的显式数据库）进行任务推理。

Result: 结果显示，程序化模型在多个任务中表现接近或优于基于真实数据训练的模型，例如在NIGHTS视觉相似性任务中仅相差1%，在CUB200和Flowers102细粒度分类任务中分别超出8%和15%。

Conclusion: 结论是程序化模型在零样本分割和分类任务中表现优异，但对象部分的表示差异可能导致内存搜索错误，解释了性能差距的剩余部分。

Abstract: We train representation models with procedural data only, and apply them on
visual similarity, classification, and semantic segmentation tasks without
further training by using visual memory -- an explicit database of reference
image embeddings. Unlike prior work on visual memory, our approach achieves
full compartmentalization with respect to all real-world images while retaining
strong performance. Compared to a model trained on Places, our procedural model
performs within $1\%$ on NIGHTS visual similarity, outperforms by $8\%$ and
$15\%$ on CUB200 and Flowers102 fine-grained classification, and is within
$10\%$ on ImageNet-1K classification. It also demonstrates strong zero-shot
segmentation, achieving an $R^2$ on COCO within $10\%$ of the models trained on
real data. Finally, we analyze procedural versus real data models, showing that
parts of the same object have dissimilar representations in procedural models,
resulting in incorrect searches in memory and explaining the remaining
performance gap.

</details>


### [3] [FusionFM: Fusing Eye-specific Foundational Models for Optimized Ophthalmic Diagnosis](https://arxiv.org/abs/2508.11721)
*Ke Zou,Jocelyn Hui Lin Goh,Yukun Zhou,Tian Lin,Samantha Min Er Yew,Sahana Srinivasan,Meng Wang,Rui Santos,Gabor M. Somfai,Huazhu Fu,Haoyu Chen,Pearse A. Keane,Ching-Yu Cheng,Yih Chung Tham*

Main category: cs.CV

TL;DR: 该研究首次系统评估了单一和融合的眼科基础模型（FMs），提出了FusionFM评估套件和两种融合方法，发现DINORET和RetiZero表现最佳，融合策略在部分任务中略有提升。


<details>
  <summary>Details</summary>
Motivation: 解决眼科基础模型性能差异和融合效果的未知问题，填补系统性评估的空白。

Method: 提出FusionFM评估套件，测试四种FMs（RETFound、VisionFM、RetiZero、DINORET），使用标准化数据集和AUC/F1指标，并尝试两种融合策略。

Result: DINORET和RetiZero在眼科和全身疾病任务中表现最优，融合策略对青光眼、AMD和高血压预测有轻微提升。

Conclusion: 研究为眼科FMs提供了实证评估，展示了融合模型的潜力，并指出提升临床适用性的方向。

Abstract: Foundation models (FMs) have shown great promise in medical image analysis by
improving generalization across diverse downstream tasks. In ophthalmology,
several FMs have recently emerged, but there is still no clear answer to
fundamental questions: Which FM performs the best? Are they equally good across
different tasks? What if we combine all FMs together? To our knowledge, this is
the first study to systematically evaluate both single and fused ophthalmic
FMs. To address these questions, we propose FusionFM, a comprehensive
evaluation suite, along with two fusion approaches to integrate different
ophthalmic FMs. Our framework covers both ophthalmic disease detection
(glaucoma, diabetic retinopathy, and age-related macular degeneration) and
systemic disease prediction (diabetes and hypertension) based on retinal
imaging. We benchmarked four state-of-the-art FMs (RETFound, VisionFM,
RetiZero, and DINORET) using standardized datasets from multiple countries and
evaluated their performance using AUC and F1 metrics. Our results show that
DINORET and RetiZero achieve superior performance in both ophthalmic and
systemic disease tasks, with RetiZero exhibiting stronger generalization on
external datasets. Regarding fusion strategies, the Gating-based approach
provides modest improvements in predicting glaucoma, AMD, and hypertension.
Despite these advances, predicting systemic diseases, especially hypertension
in external cohort remains challenging. These findings provide an
evidence-based evaluation of ophthalmic FMs, highlight the benefits of model
fusion, and point to strategies for enhancing their clinical applicability.

</details>


### [4] [UniDCF: A Foundation Model for Comprehensive Dentocraniofacial Hard Tissue Reconstruction](https://arxiv.org/abs/2508.11728)
*Chunxia Ren,Ning Zhu,Yue Lai,Gui Chen,Ruijie Wang,Yangyi Hu,Suyao Liu,Shuwen Mao,Hong Su,Yu Zhang,Li Xiao*

Main category: cs.CV

TL;DR: UniDCF是一个统一框架，通过多模态融合编码点云和多视图图像，重建多种牙颌面硬组织，解决了现有单模态方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 牙颌面硬组织缺损严重影响患者的生理功能、面部美观和心理健康，现有深度学习模型局限于单组织和特定模态输入，通用性差。

Method: UniDCF通过多模态融合编码和基于分数的去噪模块优化表面平滑度，利用6,609名患者的多模态数据集进行训练。

Result: UniDCF在几何精度、结构完整性和空间准确性上优于现有方法，临床模拟显示设计时间减少99%，临床接受率超过94%。

Conclusion: UniDCF实现了快速、自动化和高保真重建，支持个性化治疗，优化临床流程并改善患者预后。

Abstract: Dentocraniofacial hard tissue defects profoundly affect patients'
physiological functions, facial aesthetics, and psychological well-being,
posing significant challenges for precise reconstruction. Current deep learning
models are limited to single-tissue scenarios and modality-specific imaging
inputs, resulting in poor generalizability and trade-offs between anatomical
fidelity, computational efficiency, and cross-tissue adaptability. Here we
introduce UniDCF, a unified framework capable of reconstructing multiple
dentocraniofacial hard tissues through multimodal fusion encoding of point
clouds and multi-view images. By leveraging the complementary strengths of each
modality and incorporating a score-based denoising module to refine surface
smoothness, UniDCF overcomes the limitations of prior single-modality
approaches. We curated the largest multimodal dataset, comprising intraoral
scans, CBCT, and CT from 6,609 patients, resulting in 54,555 annotated
instances. Evaluations demonstrate that UniDCF outperforms existing
state-of-the-art methods in terms of geometric precision, structural
completeness, and spatial accuracy. Clinical simulations indicate UniDCF
reduces reconstruction design time by 99% and achieves clinician-rated
acceptability exceeding 94%. Overall, UniDCF enables rapid, automated, and
high-fidelity reconstruction, supporting personalized and precise restorative
treatments, streamlining clinical workflows, and enhancing patient outcomes.

</details>


### [5] [Ovis2.5 Technical Report](https://arxiv.org/abs/2508.11737)
*Shiyin Lu,Yang Li,Yu Xia,Yuwei Hu,Shanshan Zhao,Yanqing Ma,Zhichao Wei,Yinglun Li,Lunhao Duan,Jianshan Zhao,Yuxuan Han,Haijun Li,Wanying Chen,Junke Tang,Chengkun Hou,Zhixing Du,Tianli Zhou,Wenjie Zhang,Huping Ding,Jiahe Li,Wen Li,Gui Hu,Yiliang Gu,Siran Yang,Jiamang Wang,Hailong Sun,Yibo Wang,Hui Sun,Jinlong Huang,Yuping He,Shengze Shi,Weihong Zhang,Guodong Zheng,Junpeng Jiang,Sensen Gao,Yi-Feng Wu,Sijia Chen,Yuhui Chen,Qing-Guo Chen,Zhao Xu,Weihua Luo,Kaifu Zhang*

Main category: cs.CV

TL;DR: Ovis2.5是Ovis2的升级版，专注于原生分辨率视觉感知和多模态推理，通过原生分辨率视觉Transformer和反思机制提升性能，训练采用五阶段课程，发布两个开源模型，在多个任务上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 解决固定分辨率分块导致的细节和全局布局损失，以及提升多模态推理能力。

Method: 集成原生分辨率视觉Transformer，引入反思机制（自检和修订），采用五阶段课程训练（视觉预训练、指令调优、对齐和推理增强）。

Result: Ovis2.5-9B在OpenCompass上平均78.3分，Ovis2.5-2B得73.9分，均在各自规模下达到SOTA。

Conclusion: Ovis2.5在多模态任务中表现优异，尤其在STEM和复杂图表分析上领先，适合资源受限场景。

Abstract: We present Ovis2.5, a successor to Ovis2 designed for native-resolution
visual perception and strong multimodal reasoning. Ovis2.5 integrates a
native-resolution vision transformer that processes images at their native,
variable resolutions, avoiding the degradation from fixed-resolution tiling and
preserving both fine detail and global layout -- crucial for visually dense
content like complex charts. To strengthen reasoning, we train the model to
move beyond linear chain-of-thought and perform reflection -- including
self-checking and revision. This advanced capability is exposed as an optional
"thinking mode" at inference time, allowing users to trade latency for enhanced
accuracy on difficult inputs. The model is trained via a comprehensive
five-phase curriculum that progressively builds its skills. The process begins
with foundational visual and multimodal pretraining, advances through
large-scale instruction tuning, and culminates in alignment and reasoning
enhancement using DPO and GRPO. To scale these upgrades efficiently, we employ
multimodal data packing and hybrid parallelism, yielding a significant
end-to-end speedup. We release two open-source models: Ovis2.5-9B and
Ovis2.5-2B. The latter continues the "small model, big performance" philosophy
of Ovis2, making it ideal for resource-constrained, on-device scenarios. On the
OpenCompass multimodal leaderboard, Ovis2.5-9B averages 78.3, marking a
substantial improvement over its predecessor, Ovis2-8B, and achieving
state-of-the-art results among open-source MLLMs in the sub-40B parameter
range; Ovis2.5-2B scores 73.9, establishing SOTA for its size. Beyond aggregate
scores, Ovis2.5 achieves leading results on STEM benchmarks, exhibits strong
capabilities on grounding and video tasks, and achieves open-source SOTA at its
scale for complex chart analysis.

</details>


### [6] [VideoAVE: A Multi-Attribute Video-to-Text Attribute Value Extraction Dataset and Benchmark Models](https://arxiv.org/abs/2508.11801)
*Ming Cheng,Tong Wu,Jiazhen Hu,Jiaying Gong,Hoda Eldardiry*

Main category: cs.CV

TL;DR: VideoAVE是首个公开的视频到文本电商属性值提取数据集，涵盖14个领域和172个属性，通过CLIP-MoE过滤系统提升数据质量，并建立了基准测试。


<details>
  <summary>Details</summary>
Motivation: 现有AVE数据集缺乏对产品视频、多样化属性和公开可用性的支持，VideoAVE填补了这一空白。

Method: 提出CLIP-MoE过滤系统去除不匹配的视频-产品对，并评估多种视频视觉语言模型。

Result: 视频到文本AVE仍具挑战性，尤其在开放设置中，现有模型在利用时间信息方面有待改进。

Conclusion: VideoAVE为视频属性值提取提供了新基准，推动了更先进视觉语言模型的发展。

Abstract: Attribute Value Extraction (AVE) is important for structuring product
information in e-commerce. However, existing AVE datasets are primarily limited
to text-to-text or image-to-text settings, lacking support for product videos,
diverse attribute coverage, and public availability. To address these gaps, we
introduce VideoAVE, the first publicly available video-to-text e-commerce AVE
dataset across 14 different domains and covering 172 unique attributes. To
ensure data quality, we propose a post-hoc CLIP-based Mixture of Experts
filtering system (CLIP-MoE) to remove the mismatched video-product pairs,
resulting in a refined dataset of 224k training data and 25k evaluation data.
In order to evaluate the usability of the dataset, we further establish a
comprehensive benchmark by evaluating several state-of-the-art video vision
language models (VLMs) under both attribute-conditioned value prediction and
open attribute-value pair extraction tasks. Our results analysis reveals that
video-to-text AVE remains a challenging problem, particularly in open settings,
and there is still room for developing more advanced VLMs capable of leveraging
effective temporal information. The dataset and benchmark code for VideoAVE are
available at: https://github.com/gjiaying/VideoAVE

</details>


### [7] [An MLP Baseline for Handwriting Recognition Using Planar Curvature and Gradient Orientation](https://arxiv.org/abs/2508.11803)
*Azam Nouri*

Main category: cs.CV

TL;DR: 研究探讨二阶几何线索是否足以驱动多层感知机（MLP）进行手写字符识别，替代卷积神经网络（CNNs）。


<details>
  <summary>Details</summary>
Motivation: 探索手写字符识别中，是否可以通过手工设计的特征（如曲率和方向）实现高精度分类，同时保持特征的可解释性。

Method: 使用曲率大小、曲率符号和梯度方向三个手工特征图作为输入，构建曲率-方向MLP分类器。

Result: 在MNIST数字上达到97%准确率，EMNIST字母上达到89%准确率。

Conclusion: 曲率特征在手写字符识别中具有显著区分能力，且深度学习优势可通过可解释的手工特征实现。

Abstract: This study investigates whether second-order geometric cues - planar
curvature magnitude, curvature sign, and gradient orientation - are sufficient
on their own to drive a multilayer perceptron (MLP) classifier for handwritten
character recognition (HCR), offering an alternative to convolutional neural
networks (CNNs). Using these three handcrafted feature maps as inputs, our
curvature-orientation MLP achieves 97 percent accuracy on MNIST digits and 89
percent on EMNIST letters. These results underscore the discriminative power of
curvature-based representations for handwritten character images and
demonstrate that the advantages of deep learning can be realized even with
interpretable, hand-engineered features.

</details>


### [8] [Labels or Input? Rethinking Augmentation in Multimodal Hate Detection](https://arxiv.org/abs/2508.11808)
*Sahajpreet Singh,Rongxin Ouyang,Subhayan Mukerjee,Kokil Jaidka*

Main category: cs.CV

TL;DR: 论文提出了一种双管齐下的方法改进多模态仇恨内容检测，包括提示优化框架和多模态数据增强流程。


<details>
  <summary>Details</summary>
Motivation: 现代网络中多模态内容泛滥，仇恨表情包检测面临挑战，现有视觉语言模型缺乏细粒度监督且易受隐含仇恨言论影响。

Method: 1. 提出提示优化框架，调整提示结构和监督粒度；2. 引入多模态数据增强流程，生成中立表情包以减少虚假关联。

Result: 结构化提示提升模型鲁棒性，InternVL2在多种设置下表现最佳；数据增强流程有效改善分类器泛化能力。

Conclusion: 提示结构和数据组成对模型性能至关重要，针对性数据增强可支持更可信的仇恨检测。

Abstract: The modern web is saturated with multimodal content, intensifying the
challenge of detecting hateful memes, where harmful intent is often conveyed
through subtle interactions between text and image under the guise of humor or
satire. While recent advances in Vision-Language Models (VLMs) show promise,
these models lack support for fine-grained supervision and remain susceptible
to implicit hate speech. In this paper, we present a dual-pronged approach to
improve multimodal hate detection. First, we propose a prompt optimization
framework that systematically varies prompt structure, supervision granularity,
and training modality. We show that prompt design and label scaling both
influence performance, with structured prompts improving robustness even in
small models, and InternVL2 achieving the best F1-scores across binary and
scaled settings. Second, we introduce a multimodal data augmentation pipeline
that generates 2,479 counterfactually neutral memes by isolating and rewriting
the hateful modality. This pipeline, powered by a multi-agent LLM-VLM setup,
successfully reduces spurious correlations and improves classifier
generalization. Our approaches inspire new directions for building synthetic
data to train robust and fair vision-language models. Our findings demonstrate
that prompt structure and data composition are as critical as model size, and
that targeted augmentation can support more trustworthy and context-sensitive
hate detection.

</details>


### [9] [Towards Understanding 3D Vision: the Role of Gaussian Curvature](https://arxiv.org/abs/2508.11825)
*Sherlon Almeida da Silva,Davi Geiger,Luiz Velho,Moacir Antonelli Ponti*

Main category: cs.CV

TL;DR: 论文探讨了高斯曲率在3D表面建模中的作用，提出其作为稀疏描述符和几何先验的潜力。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的3D重建方法缺乏显式的几何模型，限制了可分析性和可控性。

Method: 利用Middlebury立体数据集，研究高斯曲率在3D建模中的特性与应用。

Result: 高斯曲率可作为稀疏描述符、几何先验和无监督度量，提升3D重建效果。

Conclusion: 高斯曲率在3D建模中具有重要价值，未来可进一步开发其显式模块化应用。

Abstract: Recent advances in computer vision have predominantly relied on data-driven
approaches that leverage deep learning and large-scale datasets. Deep neural
networks have achieved remarkable success in tasks such as stereo matching and
monocular depth reconstruction. However, these methods lack explicit models of
3D geometry that can be directly analyzed, transferred across modalities, or
systematically modified for controlled experimentation. We investigate the role
of Gaussian curvature in 3D surface modeling. Besides Gaussian curvature being
an invariant quantity under change of observers or coordinate systems, we
demonstrate using the Middlebury stereo dataset that it offers: (i) a sparse
and compact description of 3D surfaces, (ii) state-of-the-art monocular and
stereo methods seem to implicitly consider it, but no explicit module of such
use can be extracted, (iii) a form of geometric prior that can inform and
improve 3D surface reconstruction, and (iv) a possible use as an unsupervised
metric for stereo methods.

</details>


### [10] [From Pixels to Graphs: Deep Graph-Level Anomaly Detection on Dermoscopic Images](https://arxiv.org/abs/2508.11826)
*Dehn Xu,Tim Katzke,Emmanuel Müller*

Main category: cs.CV

TL;DR: 系统评估了多种图像到图转换方法对GNN图级异常检测的影响，发现颜色特征表现最佳，结合形状和纹理特征可进一步提升效果。


<details>
  <summary>Details</summary>
Motivation: 现有研究未系统比较图像到图转换方法对GNN图级异常检测的影响，本研究填补了这一空白。

Method: 通过多种分割方案、边构建策略和节点特征集（颜色、纹理、形状）生成图像衍生图，并在不同监督模式下评估性能。

Result: 颜色特征单独表现最佳，结合形状和纹理特征效果更优；无监督模式下AUC-ROC达0.805，全监督下提升至0.914。

Conclusion: 图像到图转换方法对GNN异常检测至关重要，颜色特征为核心，结合其他特征可显著提升性能。

Abstract: Graph Neural Networks (GNNs) have emerged as a powerful approach for
graph-based machine learning tasks. Previous work applied GNNs to image-derived
graph representations for various downstream tasks such as classification or
anomaly detection. These transformations include segmenting images, extracting
features from segments, mapping them to nodes, and connecting them. However, to
the best of our knowledge, no study has rigorously compared the effectiveness
of the numerous potential image-to-graph transformation approaches for
GNN-based graph-level anomaly detection (GLAD). In this study, we
systematically evaluate the efficacy of multiple segmentation schemes, edge
construction strategies, and node feature sets based on color, texture, and
shape descriptors to produce suitable image-derived graph representations to
perform graph-level anomaly detection. We conduct extensive experiments on
dermoscopic images using state-of-the-art GLAD models, examining performance
and efficiency in purely unsupervised, weakly supervised, and fully supervised
regimes. Our findings reveal, for example, that color descriptors contribute
the best standalone performance, while incorporating shape and texture features
consistently enhances detection efficacy. In particular, our best unsupervised
configuration using OCGTL achieves a competitive AUC-ROC score of up to 0.805
without relying on pretrained backbones like comparable image-based approaches.
With the inclusion of sparse labels, the performance increases substantially to
0.872 and with full supervision to 0.914 AUC-ROC.

</details>


### [11] [Recent Advances in Transformer and Large Language Models for UAV Applications](https://arxiv.org/abs/2508.11834)
*Hamza Kheddar,Yassine Habchi,Mohamed Chahine Ghanem,Mustapha Hemis,Dusit Niyato*

Main category: cs.CV

TL;DR: 本文综述了Transformer架构在无人机（UAV）领域的应用，包括感知、决策和自主性提升，并提出了统一的分类法和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 探讨Transformer模型如何推动无人机技术的发展，填补现有文献的空白，并为研究者和从业者提供指导。

Method: 系统分类和评估Transformer架构在无人机中的应用，包括注意力机制、CNN-Transformer混合模型、强化学习Transformer和大型语言模型（LLMs）。

Result: 提出了统一的分类法，总结了关键数据集和评估指标，并指出了计算效率和实时部署的挑战。

Conclusion: 本文为Transformer驱动的无人机技术提供了全面的综述，并指明了未来的研究方向。

Abstract: The rapid advancement of Transformer-based models has reshaped the landscape
of uncrewed aerial vehicle (UAV) systems by enhancing perception,
decision-making, and autonomy. This review paper systematically categorizes and
evaluates recent developments in Transformer architectures applied to UAVs,
including attention mechanisms, CNN-Transformer hybrids, reinforcement learning
Transformers, and large language models (LLMs). Unlike previous surveys, this
work presents a unified taxonomy of Transformer-based UAV models, highlights
emerging applications such as precision agriculture and autonomous navigation,
and provides comparative analyses through structured tables and performance
benchmarks. The paper also reviews key datasets, simulators, and evaluation
metrics used in the field. Furthermore, it identifies existing gaps in the
literature, outlines critical challenges in computational efficiency and
real-time deployment, and offers future research directions. This comprehensive
synthesis aims to guide researchers and practitioners in understanding and
advancing Transformer-driven UAV technologies.

</details>


### [12] [ComplicitSplat: Downstream Models are Vulnerable to Blackbox Attacks by 3D Gaussian Splat Camouflages](https://arxiv.org/abs/2508.11854)
*Matthew Hull,Haoyang Yang,Pratham Mehta,Mansi Phute,Aeree Cho,Haorang Wang,Matthew Lau,Wenke Lee,Wilian Lunardi,Martin Andreoni,Polo Chau*

Main category: cs.CV

TL;DR: ComplicitSplat是一种针对3D高斯泼溅（3DGS）的黑盒攻击方法，通过视角特定的伪装在特定视角下嵌入对抗内容，无需访问模型架构或权重。


<details>
  <summary>Details</summary>
Motivation: 随着3DGS在安全关键任务中的广泛应用，研究如何通过篡改图像造成危害。

Method: 利用标准3DGS着色方法创建视角特定的伪装，攻击多种流行的检测器。

Result: 实验表明，ComplicitSplat能成功攻击多种检测器，包括单阶段、多阶段和基于Transformer的模型。

Conclusion: 该攻击暴露了3DGS在自主导航等关键应用中的安全风险。

Abstract: As 3D Gaussian Splatting (3DGS) gains rapid adoption in safety-critical tasks
for efficient novel-view synthesis from static images, how might an adversary
tamper images to cause harm? We introduce ComplicitSplat, the first attack that
exploits standard 3DGS shading methods to create viewpoint-specific camouflage
- colors and textures that change with viewing angle - to embed adversarial
content in scene objects that are visible only from specific viewpoints and
without requiring access to model architecture or weights. Our extensive
experiments show that ComplicitSplat generalizes to successfully attack a
variety of popular detector - both single-stage, multi-stage, and
transformer-based models on both real-world capture of physical objects and
synthetic scenes. To our knowledge, this is the first black-box attack on
downstream object detectors using 3DGS, exposing a novel safety risk for
applications like autonomous navigation and other mission-critical robotic
systems.

</details>


### [13] [Impact of Clinical Image Quality on Efficient Foundation Model Finetuning](https://arxiv.org/abs/2508.11864)
*Yucheng Tang,Pawel Rajwa,Alexander Ng,Yipei Wang,Wen Yan,Natasha Thorley,Aqua Asif,Clare Allen,Louise Dickinson,Francesco Giganti,Shonit Punwani,Daniel C. Alexander,Veeru Kasivisvanathan,Yipeng Hu*

Main category: cs.CV

TL;DR: 研究评估了前列腺多参数MRI中图像质量对标签高效微调的影响，发现图像质量分布及其微调与测试不匹配显著影响模型性能。


<details>
  <summary>Details</summary>
Motivation: 探索医学影像基础模型在标签高效微调中的表现，特别是在前列腺MRI中，分析图像质量对模型泛化能力的影响。

Method: 使用ProFound（前列腺MRI领域特定基础模型），系统变化微调和测试集中的高/低质量图像比例，评估模型性能。

Result: 图像质量分布不一致会导致性能差异；微调集中足够高质量图像对性能至关重要，但不同下游任务对质量匹配的需求不同。

Conclusion: 强调在微调和部署中评估和匹配图像质量分布的重要性，提出需要为特定下游任务制定微调数据的质量标准。

Abstract: Foundation models in medical imaging have shown promising label efficiency,
achieving high downstream performance with only a fraction of annotated data.
Here, we evaluate this in prostate multiparametric MRI using ProFound, a
domain-specific vision foundation model pretrained on large-scale prostate MRI
datasets. We investigate how variable image quality affects label-efficient
finetuning by measuring the generalisability of finetuned models. Experiments
systematically vary high-/low-quality image ratios in finetuning and evaluation
sets. Our findings indicate that image quality distribution and its
finetune-and-test mismatch significantly affect model performance. In
particular: a) Varying the ratio of high- to low-quality images between
finetuning and test sets leads to notable differences in downstream
performance; and b) The presence of sufficient high-quality images in the
finetuning set is critical for maintaining strong performance, whilst the
importance of matched finetuning and testing distribution varies between
different downstream tasks, such as automated radiology reporting and prostate
cancer detection.When quality ratios are consistent, finetuning needs far less
labeled data than training from scratch, but label efficiency depends on image
quality distribution. Without enough high-quality finetuning data, pretrained
models may fail to outperform those trained without pretraining. This
highlights the importance of assessing and aligning quality distributions
between finetuning and deployment, and the need for quality standards in
finetuning data for specific downstream tasks. Using ProFound, we show the
value of quantifying image quality in both finetuning and deployment to fully
realise the data and compute efficiency benefits of foundation models.

</details>


### [14] [AdaRing: Towards Ultra-Light Vision-Language Adaptation via Cross-Layer Tensor Ring Decomposition](https://arxiv.org/abs/2508.11870)
*Ying Huang,Yuanbin Man,Wenqi Jia,Zhengzhong Tu,Junzhou Huang,Miao Yin*

Main category: cs.CV

TL;DR: 提出了一种基于跨层张量环分解（TRD）的轻量级视觉语言微调框架AdaRing，显著减少参数并提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有适配器方法存在跨层冗余和表示能力有限的问题，需更高效的参数适应方法。

Method: 利用张量级低秩性将适配器分解为层共享张量核心和层特定切片，结合多样化秩驱动适配器。

Result: AdaRing在减少90%训练参数的同时达到最优性能。

Conclusion: AdaRing通过跨层TRD和多样化适配器协作，实现了高效且高性能的视觉语言模型微调。

Abstract: Adapter-based fine-tuning has gained remarkable attention in adapting large
pre-trained vision language models (VLMs) for a wide range of downstream tasks
efficiently. In this paradigm, only the inserted adapters are fine-tuned,
without the need for training the original VLM backbone. Existing works scale
adapters by integrating them into every layer of VLMs to increase the capacity
of adapters. However, these methods face two primary limitations: 1) limited
compression rate due to ignoring cross-layer redundancy, and 2) limited
representational capacity across homogeneous adapters. In this paper, we
propose a novel vision-language fine-tuning framework based on cross-layer
tensor ring decomposition (TRD) with the integration and collaboration of
diverse adapters, called AdaRing, achieving ultra-light parameter-efficient
adaptation of VLMs on various tasks. To remove the high redundancy that exists
among adapters across layers, we exploit the tensor-level low-rankness to
formulate adapters as layer-shared tensor cores and layer-specific slices.
Moreover, guided by generalization-aware fine-tuning, diverse rank-driven
adapters cooperate to handle tasks that require different representations. Our
experiments show that the proposed AdaRing achieves the state-of-the-art
performance while reducing average training parameters by 90%.

</details>


### [15] [EVTP-IVS: Effective Visual Token Pruning For Unifying Instruction Visual Segmentation In Multi-Modal Large Language Models](https://arxiv.org/abs/2508.11886)
*Wenhui Zhu,Xiwen Chen,Zhipeng Wang,Shao Tang,Sayan Ghosh,Xuanzhao Dong,Rajat Koner,Yalin Wang*

Main category: cs.CV

TL;DR: EVTP-IV是一种新颖的视觉令牌剪枝方法，用于加速基于自然语言指令的视觉分割任务，显著提升推理速度，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在视觉分割任务中表现优异，但推理成本高，尤其是视频任务。研究发现令牌覆盖率与分割性能强相关，因此设计了一种高效的令牌剪枝方法。

Method: 提出EVTP-IV方法，基于k-center算法并整合空间信息，选择紧凑且空间代表性的令牌子集，加速推理。

Result: 实验显示，EVTP-IV在视频任务中实现5倍加速，图像任务中3.5倍加速，仅使用20%令牌即可保持准确性，且优于现有剪枝方法。

Conclusion: EVTP-IV通过高效令牌剪枝显著降低推理成本，为视觉分割任务提供了实用的加速解决方案。

Abstract: Instructed Visual Segmentation (IVS) tasks require segmenting objects in
images or videos based on natural language instructions. While recent
multimodal large language models (MLLMs) have achieved strong performance on
IVS, their inference cost remains a major bottleneck, particularly in video. We
empirically analyze visual token sampling in MLLMs and observe a strong
correlation between subset token coverage and segmentation performance. This
motivates our design of a simple and effective token pruning method that
selects a compact yet spatially representative subset of tokens to accelerate
inference. In this paper, we introduce a novel visual token pruning method for
IVS, called EVTP-IV, which builds upon the k-center by integrating spatial
information to ensure better coverage. We further provide an
information-theoretic analysis to support our design. Experiments on standard
IVS benchmarks show that our method achieves up to 5X speed-up on video tasks
and 3.5X on image tasks, while maintaining comparable accuracy using only 20%
of the tokens. Our method also consistently outperforms state-of-the-art
pruning baselines under varying pruning ratios.

</details>


### [16] [Large Kernel Modulation Network for Efficient Image Super-Resolution](https://arxiv.org/abs/2508.11893)
*Quanwei Hu,Yinggan Tang,Xuguang Zhang*

Main category: cs.CV

TL;DR: LKMN是一种纯CNN模型，通过增强部分大核块和交叉门前馈网络，在资源受限场景下实现高性能和低延迟的图像超分辨率。


<details>
  <summary>Details</summary>
Motivation: 解决CNN缺乏非局部特征捕获和Transformer推理速度慢的问题，提出轻量级模型以平衡性能与延迟。

Method: 采用EPLKB增强通道交互和注意力机制，结合CGFN动态调整特征差异并融合，实现非局部特征提取。

Result: 在Manga109数据集上，LKMN-L比DAT-light PSNR提升0.23 dB，推理速度快4.8倍。

Conclusion: LKMN在轻量级超分辨率任务中表现优异，平衡了质量与效率。

Abstract: Image super-resolution (SR) in resource-constrained scenarios demands
lightweight models balancing performance and latency. Convolutional neural
networks (CNNs) offer low latency but lack non-local feature capture, while
Transformers excel at non-local modeling yet suffer slow inference. To address
this trade-off, we propose the Large Kernel Modulation Network (LKMN), a pure
CNN-based model. LKMN has two core components: Enhanced Partial Large Kernel
Block (EPLKB) and Cross-Gate Feed-Forward Network (CGFN). The EPLKB utilizes
channel shuffle to boost inter-channel interaction, incorporates channel
attention to focus on key information, and applies large kernel strip
convolutions on partial channels for non-local feature extraction with reduced
complexity. The CGFN dynamically adjusts discrepancies between input, local,
and non-local features via a learnable scaling factor, then employs a
cross-gate strategy to modulate and fuse these features, enhancing their
complementarity. Extensive experiments demonstrate that our method outperforms
existing state-of-the-art (SOTA) lightweight SR models while balancing quality
and efficiency. Specifically, LKMN-L achieves 0.23 dB PSNR improvement over
DAT-light on the Manga109 dataset at $\times$4 upscale, with nearly $\times$4.8
times faster. Codes are in the supplementary materials. The code is available
at https://github.com/Supereeeee/LKMN.

</details>


### [17] [A Sobel-Gradient MLP Baseline for Handwritten Character Recognition](https://arxiv.org/abs/2508.11902)
*Azam Nouri*

Main category: cs.CV

TL;DR: 研究探讨了仅使用Sobel算子的一阶边缘图是否能驱动MLP进行手写字符识别，替代CNN。


<details>
  <summary>Details</summary>
Motivation: 探索是否简单的边缘信息足以替代复杂的CNN进行手写字符识别。

Method: 使用水平和垂直Sobel导数作为输入，训练MLP在MNIST和EMNIST数据集上。

Result: MLP在MNIST上达到98%准确率，EMNIST字母上92%，接近CNN但更轻量。

Conclusion: 一阶梯度已包含足够分类信息，边缘感知MLP是HCR的可行选择。

Abstract: We revisit the classical Sobel operator to ask a simple question: Are
first-order edge maps sufficient to drive an all-dense multilayer perceptron
(MLP) for handwritten character recognition (HCR), as an alternative to
convolutional neural networks (CNNs)? Using only horizontal and vertical Sobel
derivatives as input, we train an MLP on MNIST and EMNIST Letters. Despite its
extreme simplicity, the resulting network reaches 98% accuracy on MNIST digits
and 92% on EMNIST letters -- approaching CNNs while offering a smaller memory
footprint and transparent features. Our findings highlight that much of the
class-discriminative information in handwritten character images is already
captured by first-order gradients, making edge-aware MLPs a compelling option
for HCR.

</details>


### [18] [OVG-HQ: Online Video Grounding with Hybrid-modal Queries](https://arxiv.org/abs/2508.11903)
*Runhao Zeng,Jiaqi Mao,Minghao Lai,Minh Hieu Phan,Yanjie Dong,Wei Wang,Qi Chen,Xiping Hu*

Main category: cs.CV

TL;DR: 论文提出了一种名为OVG-HQ的新任务，用于在线视频定位，支持多模态查询，并提出了统一框架OVG-HQ-Unify解决模态不平衡和上下文限制问题。


<details>
  <summary>Details</summary>
Motivation: 传统视频定位任务在流媒体和视觉线索查询场景中表现不佳，需要一种支持多模态查询的在线解决方案。

Method: 提出OVG-HQ-Unify框架，包含参数记忆块（PMB）和跨模态蒸馏策略，以增强非主导模态的学习。

Result: 实验表明OVG-HQ-Unify优于现有模型，并在新数据集QVHighlights-Unify上验证了其有效性。

Conclusion: OVG-HQ-Unify为在线多模态视频定位提供了高效且准确的解决方案，并引入了新的评估指标。

Abstract: Video grounding (VG) task focuses on locating specific moments in a video
based on a query, usually in text form. However, traditional VG struggles with
some scenarios like streaming video or queries using visual cues. To fill this
gap, we present a new task named Online Video Grounding with Hybrid-modal
Queries (OVG-HQ), which enables online segment localization using text, images,
video segments, and their combinations. This task poses two new challenges:
limited context in online settings and modality imbalance during training,
where dominant modalities overshadow weaker ones. To address these, we propose
OVG-HQ-Unify, a unified framework featuring a Parametric Memory Block (PMB)
that retain previously learned knowledge to enhance current decision and a
cross-modal distillation strategy that guides the learning of non-dominant
modalities. This design enables a single model to effectively handle
hybrid-modal queries. Due to the lack of suitable datasets, we construct
QVHighlights-Unify, an expanded dataset with multi-modal queries. Besides,
since offline metrics overlook prediction timeliness, we adapt them to the
online setting, introducing oR@n, IoU=m, and online mean Average Precision
(omAP) to evaluate both accuracy and efficiency. Experiments show that our
OVG-HQ-Unify outperforms existing models, offering a robust solution for
online, hybrid-modal video grounding. Source code and datasets are available at
https://github.com/maojiaqi2324/OVG-HQ.

</details>


### [19] [SafeCtrl: Region-Based Safety Control for Text-to-Image Diffusion via Detect-Then-Suppress](https://arxiv.org/abs/2508.11904)
*Lingyun Zhang,Yu Xie,Yanwei Fu,Ping Chen*

Main category: cs.CV

TL;DR: SafeCtrl是一种轻量级插件，通过检测并抑制有害内容，提升文本到图像模型的安全性，同时保持生成内容的连贯性。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在安全性和保真度之间的权衡问题，避免语义不连贯的替换。

Method: 采用检测-抑制范式，结合Direct Preference Optimization (DPO)训练策略，无需像素级标注。

Result: 在安全性和保真度上显著优于现有方法。

Conclusion: 基于抑制的解耦控制是构建更负责任生成模型的有效方向。

Abstract: The widespread deployment of text-to-image models is challenged by their
potential to generate harmful content. While existing safety methods, such as
prompt rewriting or model fine-tuning, provide valuable interventions, they
often introduce a trade-off between safety and fidelity. Recent
localization-based approaches have shown promise, yet their reliance on
explicit ``concept replacement" can sometimes lead to semantic incongruity. To
address these limitations, we explore a more flexible detect-then-suppress
paradigm. We introduce SafeCtrl, a lightweight, non-intrusive plugin that first
precisely localizes unsafe content. Instead of performing a hard A-to-B
substitution, SafeCtrl then suppresses the harmful semantics, allowing the
generative process to naturally and coherently resolve into a safe,
context-aware alternative. A key aspect of our work is a novel training
strategy using Direct Preference Optimization (DPO). We leverage readily
available, image-level preference data to train our module, enabling it to
learn nuanced suppression behaviors and perform region-guided interventions at
inference without requiring costly, pixel-level annotations. Extensive
experiments show that SafeCtrl significantly outperforms state-of-the-art
methods in both safety efficacy and fidelity preservation. Our findings suggest
that decoupled, suppression-based control is a highly effective and scalable
direction for building more responsible generative models.

</details>


### [20] [TimeSenCLIP: A Vision-Language Model for Remote Sensing Using Single-Pixel Time Series](https://arxiv.org/abs/2508.11919)
*Pallavi Jain,Diego Marcos,Dino Ienco,Roberto Interdonato,Tristan Berchoux*

Main category: cs.CV

TL;DR: TimeSenCLIP是一个轻量级框架，利用单像素的时空和光谱信息进行土地分类，减少对文本监督和大空间块的依赖。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法依赖大空间块和文本监督的问题，提出更高效、可扩展的遥感分类方法。

Method: 结合Sentinel-2影像的时空光谱信息和地面照片的跨视角学习，减少对文本训练的依赖。

Result: 实验表明，单像素输入结合时空光谱信息足以完成主题分类，适用于大规模遥感应用。

Conclusion: TimeSenCLIP为遥感分类提供了高效、可扩展的解决方案，代码已开源。

Abstract: Vision-language models have shown significant promise in remote sensing
applications, particularly for land-use and land-cover (LULC) via zero-shot
classification and retrieval. However, current approaches face two key
challenges: reliance on large spatial tiles that increase computational cost,
and dependence on text-based supervision, which is often not readily available.
In this work, we present TimeSenCLIP, a lightweight framework that reevaluate
the role of spatial context by evaluating the effectiveness of a single pixel
by leveraging its temporal and spectral dimensions, for classifying LULC and
ecosystem types. By leveraging spectral and temporal information from
Sentinel-2 imagery and cross-view learning with geo-tagged ground-level photos,
we minimises the need for caption-based training while preserving semantic
alignment between overhead (satellite) and ground perspectives. Our approach is
grounded in the LUCAS and Sen4Map datasets, and evaluated on classification
tasks including LULC, crop type, and ecosystem type. We demonstrate that single
pixel inputs, when combined with temporal and spectral cues, are sufficient for
thematic mapping, offering a scalable and efficient alternative for large-scale
remote sensing applications. Code is available at
https://github.com/pallavijain-pj/TimeSenCLIP

</details>


### [21] [Assessment of Using Synthetic Data in Brain Tumor Segmentation](https://arxiv.org/abs/2508.11922)
*Aditi Jahagirdar,Sameer Joshi*

Main category: cs.CV

TL;DR: 研究探讨了合成MRI数据对脑肿瘤分割的影响，发现混合数据集（40%真实+60%合成数据）能改善肿瘤边界划分，但核心区域精度仍不足。


<details>
  <summary>Details</summary>
Motivation: 解决脑肿瘤分割中数据稀缺和类别不平衡问题，探索合成数据的潜力。

Method: 使用预训练GAN生成合成MRI数据，结合BraTS 2020真实数据训练U-Net分割网络，对比纯真实数据和混合数据的效果。

Result: 混合数据集在整体性能上与纯真实数据相当，但改善了肿瘤边界划分；核心区域精度仍较低。

Conclusion: 合成数据可作为脑肿瘤分割的增强策略，但需进一步解决类别不平衡和扩大实验规模。

Abstract: Manual brain tumor segmentation from MRI scans is challenging due to tumor
heterogeneity, scarcity of annotated data, and class imbalance in medical
imaging datasets. Synthetic data generated by generative models has the
potential to mitigate these issues by improving dataset diversity. This study
investigates, as a proof of concept, the impact of incorporating synthetic MRI
data, generated using a pre-trained GAN model, into training a U-Net
segmentation network. Experiments were conducted using real data from the BraTS
2020 dataset, synthetic data generated with the medigan library, and hybrid
datasets combining real and synthetic samples in varying proportions. While
overall quantitative performance (Dice coefficient, IoU, precision, recall,
accuracy) was comparable between real-only and hybrid-trained models,
qualitative inspection suggested that hybrid datasets, particularly with 40%
real and 60% synthetic data, improved whole tumor boundary delineation.
However, region-wise accuracy for the tumor core and the enhancing tumor
remained lower, indicating a persistent class imbalance. The findings support
the feasibility of synthetic data as an augmentation strategy for brain tumor
segmentation, while highlighting the need for larger-scale experiments,
volumetric data consistency, and mitigating class imbalance in future work.

</details>


### [22] [Deep Learning For Point Cloud Denoising: A Survey](https://arxiv.org/abs/2508.11932)
*Chengwei Zhang,Xueyi Zhang,Mingrui Lao,Tao Jiang,Xinhao Xu,Wenjie Li,Fubo Zhang,Longyong Chen*

Main category: cs.CV

TL;DR: 本文综述了基于深度学习的点云去噪（PCD）方法，总结了现有技术的主要贡献，并提出了一种针对去噪任务的分类法。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的点云数据常带有噪声，影响下游任务性能。尽管深度学习在PCD中表现优异，但缺乏系统性综述。本文旨在填补这一空白。

Method: 将PCD分为两步：异常值去除和表面噪声恢复，并比较不同方法的相似性、差异和优势。

Result: 提出了一种针对PCD任务的分类法，总结了现有方法的贡献，并讨论了研究局限和未来方向。

Conclusion: 本文为PCD领域的研究提供了系统性总结和未来发展的见解。

Abstract: Real-world environment-derived point clouds invariably exhibit noise across
varying modalities and intensities. Hence, point cloud denoising (PCD) is
essential as a preprocessing step to improve downstream task performance. Deep
learning (DL)-based PCD models, known for their strong representation
capabilities and flexible architectures, have surpassed traditional methods in
denoising performance. To our best knowledge, despite recent advances in
performance, no comprehensive survey systematically summarizes the developments
of DL-based PCD. To fill the gap, this paper seeks to identify key challenges
in DL-based PCD, summarizes the main contributions of existing methods, and
proposes a taxonomy tailored to denoising tasks. To achieve this goal, we
formulate PCD as a two-step process: outlier removal and surface noise
restoration, encompassing most scenarios and requirements of PCD. Additionally,
we compare methods in terms of similarities, differences, and respective
advantages. Finally, we discuss research limitations and future directions,
offering insights for further advancements in PCD.

</details>


### [23] [DynamicPose: Real-time and Robust 6D Object Pose Tracking for Fast-Moving Cameras and Objects](https://arxiv.org/abs/2508.11950)
*Tingbang Liang,Yixin Zeng,Jiatong Xie,Boyu Zhou*

Main category: cs.CV

TL;DR: DynamicPose是一个无需重新训练的6D姿态跟踪框架，适用于快速移动的相机和物体场景。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要适用于静态或准静态场景，在相机和物体快速移动时性能显著下降。

Method: 提出三个协同组件：视觉惯性里程计补偿相机运动引起的ROI偏移；深度信息辅助的2D跟踪器校正物体大位移引起的ROI偏差；VIO引导的卡尔曼滤波预测旋转并通过分层细化生成最终姿态。

Result: 实验证明该方法能实时且鲁棒地跟踪快速移动的相机和物体的6D姿态。

Conclusion: DynamicPose通过闭环系统实现了精确的姿态初始化和跟踪，适用于动态场景。

Abstract: We present DynamicPose, a retraining-free 6D pose tracking framework that
improves tracking robustness in fast-moving camera and object scenarios.
Previous work is mainly applicable to static or quasi-static scenes, and its
performance significantly deteriorates when both the object and the camera move
rapidly. To overcome these challenges, we propose three synergistic components:
(1) A visual-inertial odometry compensates for the shift in the Region of
Interest (ROI) caused by camera motion; (2) A depth-informed 2D tracker
corrects ROI deviations caused by large object translation; (3) A VIO-guided
Kalman filter predicts object rotation, generates multiple candidate poses, and
then obtains the final pose by hierarchical refinement. The 6D pose tracking
results guide subsequent 2D tracking and Kalman filter updates, forming a
closed-loop system that ensures accurate pose initialization and precise pose
tracking. Simulation and real-world experiments demonstrate the effectiveness
of our method, achieving real-time and robust 6D pose tracking for fast-moving
cameras and objects.

</details>


### [24] [Transferable Class Statistics and Multi-scale Feature Approximation for 3D Object Detection](https://arxiv.org/abs/2508.11951)
*Hao Peng,Hong Sang,Yajing Ma,Ping Qiu,Chao Ji*

Main category: cs.CV

TL;DR: 论文提出了一种基于知识蒸馏的单邻域多尺度特征近似方法，并设计了可转移特征嵌入机制，以降低计算成本并提升检测效果。


<details>
  <summary>Details</summary>
Motivation: 多尺度特征对点云目标检测至关重要，但传统方法计算成本高，难以轻量化。

Method: 通过单邻域近似多尺度特征，结合可转移特征嵌入机制和中心加权交并比优化定位。

Result: 在公开数据集上验证了方法的有效性，显著节省了计算成本。

Conclusion: 该方法在保持检测性能的同时，显著降低了计算复杂度。

Abstract: This paper investigates multi-scale feature approximation and transferable
features for object detection from point clouds. Multi-scale features are
critical for object detection from point clouds. However, multi-scale feature
learning usually involves multiple neighborhood searches and scale-aware
layers, which can hinder efforts to achieve lightweight models and may not be
conducive to research constrained by limited computational resources. This
paper approximates point-based multi-scale features from a single neighborhood
based on knowledge distillation. To compensate for the loss of constructive
diversity in a single neighborhood, this paper designs a transferable feature
embedding mechanism. Specifically, class-aware statistics are employed as
transferable features given the small computational cost. In addition, this
paper introduces the central weighted intersection over union for localization
to alleviate the misalignment brought by the center offset in optimization.
Note that the method presented in this paper saves computational costs.
Extensive experiments on public datasets demonstrate the effectiveness of the
proposed method.

</details>


### [25] [UniUGG: Unified 3D Understanding and Generation via Geometric-Semantic Encoding](https://arxiv.org/abs/2508.11952)
*Yueming Xu,Jiahui Zhang,Ze Huang,Yurui Chen,Yanpeng Zhou,Zhenyu Chen,Yu-Jie Yuan,Pengxiang Xia,Guowei Huang,Xinyue Cai,Zhongang Qi,Xingyue Quan,Jianye Hao,Hang Xu,Li Zhang*

Main category: cs.CV

TL;DR: UniUGG是一个统一的理解和生成框架，首次将3D任务整合到统一的架构中，通过LLM和潜在扩散模型实现高质量的3D表示生成和理解。


<details>
  <summary>Details</summary>
Motivation: 尽管现有统一架构在图像理解和生成方面取得了显著进展，但3D任务的整合仍具有挑战性且未被充分探索。

Method: 提出UniUGG框架，利用LLM理解和解码句子与3D表示，核心是空间解码器（基于潜在扩散模型）生成高质量3D表示，并支持空间视觉问答任务。此外，提出几何语义学习策略预训练视觉编码器。

Result: 实验结果表明，该方法在视觉表示、空间理解和3D生成方面具有优越性。

Conclusion: UniUGG首次实现了3D任务的统一理解和生成，为3D场景的生成和理解提供了新思路。

Abstract: Despite the impressive progress on understanding and generating images shown
by the recent unified architectures, the integration of 3D tasks remains
challenging and largely unexplored. In this paper, we introduce UniUGG, the
first unified understanding and generation framework for 3D modalities. Our
unified framework employs an LLM to comprehend and decode sentences and 3D
representations. At its core, we propose a spatial decoder leveraging a latent
diffusion model to generate high-quality 3D representations. This allows for
the generation and imagination of 3D scenes based on a reference image and an
arbitrary view transformation, while remaining supports for spatial visual
question answering (VQA) tasks. Additionally, we propose a geometric-semantic
learning strategy to pretrain the vision encoder. This design jointly captures
the input's semantic and geometric cues, enhancing both spatial understanding
and generation. Extensive experimental results demonstrate the superiority of
our method in visual representation, spatial understanding, and 3D generation.
The source code will be released upon paper acceptance.

</details>


### [26] [SAMDWICH: Moment-aware Video-text Alignment for Referring Video Object Segmentation](https://arxiv.org/abs/2508.11955)
*Seunghun Lee,Jiwan Seo,Jeonghoon Kim,Siwon Kim,Haeun Yun,Hyogyeong Jeon,Wonhyeok Choi,Jaehoon Jeong,Zane Durante,Sang Hyun Park,Sunghoon Im*

Main category: cs.CV

TL;DR: SAMDWICH是一种基于时刻感知的RVOS框架，通过新标注的数据集MeViS-M和提出的MDP与OSS策略，显著提升了视频与文本的对齐效果。


<details>
  <summary>Details</summary>
Motivation: 现有RVOS方法存在语义不对齐问题，主要由于训练时对所有可见对象进行无差别采样和监督，忽略了其与文本查询的实际相关性。

Method: 提出SAMDWICH框架，包括Moment-guided Dual-path Propagation（MDP）和Object-level Selective Supervision（OSS）策略，利用时刻标注数据强化视频-文本对齐。

Result: 在MeViS基准测试中达到最优性能，尤其在复杂场景下表现突出。

Conclusion: SAMDWICH通过时刻感知和监督策略有效解决了语义对齐问题，提升了RVOS的性能。

Abstract: Referring Video Object Segmentation (RVOS) aims to segment and track objects
in videos based on natural language expressions, requiring precise alignment
between visual content and textual queries. However, existing methods often
suffer from semantic misalignment, largely due to indiscriminate frame sampling
and supervision of all visible objects during training -- regardless of their
actual relevance to the expression. To address this, we introduce a
moment-aware RVOS framework named SAMDWICH, along with a newly annotated
dataset, MeViS-M, built upon the challenging MeViS benchmark. We manually
annotate temporal moments indicating when each object is referred to by the
expression, enabling semantically grounded supervision that strengthens
video-text alignment. SAMDWICH leverages these aligned text-to-clip pairs to
guide training, significantly enhancing referential understanding. Building
upon this framework, we propose Moment-guided Dual-path Propagation (MDP), a
moment-aware propagation strategy that improves both object grounding and
tracking by training on both relevant and irrelevant frames through a
moment-centric memory mechanism. In addition, we introduce Object-level
Selective Supervision (OSS), an object-level filtering strategy that supervises
only the objects temporally aligned with the expression in each training clip.
This selective supervision reduces semantic noise and reinforces
language-conditioned learning. Extensive experiments show that SAMDWICH
achieves state-of-the-art performance on challenging MeViS benchmark,
particularly excelling in complex scenarios involving diverse expressions.

</details>


### [27] [PEdger++: Practical Edge Detection via Assembling Cross Information](https://arxiv.org/abs/2508.11961)
*Yuanbin Fu,Liang Li,Xiaojie Guo*

Main category: cs.CV

TL;DR: PEdger++是一个协作学习框架，旨在降低计算成本和模型大小，同时提高边缘检测精度。


<details>
  <summary>Details</summary>
Motivation: 边缘检测在计算机视觉中至关重要，但现有深度学习方法计算成本高，限制了在资源受限设备上的应用。

Method: 通过异构架构、多样化训练时刻和参数采样的交叉信息，从集成角度增强学习。

Result: 在BSDS500、NYUD和Multicue数据集上表现优异，定量和定性均优于现有方法。

Conclusion: PEdger++在精度和效率之间取得了平衡，并提供了适应不同资源需求的多个版本。

Abstract: Edge detection serves as a critical foundation for numerous computer vision
applications, including object detection, semantic segmentation, and image
editing, by extracting essential structural cues that define object boundaries
and salient edges. To be viable for broad deployment across devices with
varying computational capacities, edge detectors shall balance high accuracy
with low computational complexity. While deep learning has evidently improved
accuracy, they often suffer from high computational costs, limiting their
applicability on resource-constrained devices. This paper addresses the
challenge of achieving that balance: \textit{i.e.}, {how to efficiently capture
discriminative features without relying on large-size and sophisticated
models}. We propose PEdger++, a collaborative learning framework designed to
reduce computational costs and model sizes while improving edge detection
accuracy. The core principle of our PEdger++ is that cross-information derived
from heterogeneous architectures, diverse training moments, and multiple
parameter samplings, is beneficial to enhance learning from an ensemble
perspective. Extensive experimental results on the BSDS500, NYUD and Multicue
datasets demonstrate the effectiveness of our approach, both quantitatively and
qualitatively, showing clear improvements over existing methods. We also
provide multiple versions of the model with varying computational requirements,
highlighting PEdger++'s adaptability with respect to different resource
constraints. Codes are accessible at
https://github.com/ForawardStar/EdgeDetectionviaPEdgerPlus/.

</details>


### [28] [Exploring Spatial-Temporal Dynamics in Event-based Facial Micro-Expression Analysis](https://arxiv.org/abs/2508.11988)
*Nicolas Mastropasqua,Ignacio Bugueno-Cordova,Rodrigo Verschae,Daniel Acevedo,Pablo Negri,Maria E. Buemi*

Main category: cs.CV

TL;DR: 论文提出了一种多分辨率多模态的微表情数据集，结合RGB和事件相机，展示了事件数据在微表情识别和帧重建中的潜力。


<details>
  <summary>Details</summary>
Motivation: RGB相机在捕捉快速细微面部动作时存在局限性，事件相机因其高时间分辨率和低延迟成为替代方案，但目前相关数据集稀缺。

Method: 引入同步RGB和事件相机记录的多模态数据集，评估了两个基线任务：使用脉冲神经网络进行动作单元分类，以及使用条件变分自编码器进行帧重建。

Result: 动作单元分类任务中，事件数据准确率51.23%，显著高于RGB数据的23.12%；帧重建任务中，高分辨率事件输入达到SSIM=0.8513和PSNR=26.89dB。

Conclusion: 事件数据在微表情分析和帧重建中表现优异，展示了其应用潜力。

Abstract: Micro-expression analysis has applications in domains such as Human-Robot
Interaction and Driver Monitoring Systems. Accurately capturing subtle and fast
facial movements remains difficult when relying solely on RGB cameras, due to
limitations in temporal resolution and sensitivity to motion blur. Event
cameras offer an alternative, with microsecond-level precision, high dynamic
range, and low latency. However, public datasets featuring event-based
recordings of Action Units are still scarce. In this work, we introduce a
novel, preliminary multi-resolution and multi-modal micro-expression dataset
recorded with synchronized RGB and event cameras under variable lighting
conditions. Two baseline tasks are evaluated to explore the spatial-temporal
dynamics of micro-expressions: Action Unit classification using Spiking Neural
Networks (51.23\% accuracy with events vs. 23.12\% with RGB), and frame
reconstruction using Conditional Variational Autoencoders, achieving SSIM =
0.8513 and PSNR = 26.89 dB with high-resolution event input. These promising
results show that event-based data can be used for micro-expression recognition
and frame reconstruction.

</details>


### [29] [MOON: Generative MLLM-based Multimodal Representation Learning for E-commerce Product Understanding](https://arxiv.org/abs/2508.11999)
*Daoze Zhang,Zhanheng Nie,Jianyu Liu,Chenghan Fu,Wanxian Guan,Yuan Gao,Jun Song,Pengjie Wang,Jian Xu,Bo Zheng*

Main category: cs.CV

TL;DR: 论文提出了一种基于生成式多模态大语言模型（MLLM）的MOON模型，用于产品表示学习，解决了多模态建模、背景噪声和评估基准缺失等问题。


<details>
  <summary>Details</summary>
Motivation: 现有判别式双流架构难以建模产品多图像与文本的多对一关系，生成式MLLM具有潜力但面临多模态建模不足、背景噪声和缺乏标准评估基准的挑战。

Method: 提出MOON模型，采用引导的Mixture-of-Experts模块建模多模态和特定方面内容，检测核心语义区域以减少背景噪声干扰，并引入负采样策略。

Result: 模型在零样本任务中表现优异，在跨模态检索、产品分类和属性预测等下游任务中展示出强泛化能力。

Conclusion: MOON模型通过创新方法有效提升了产品理解能力，并发布了MBE基准数据集支持未来研究。

Abstract: With the rapid advancement of e-commerce, exploring general representations
rather than task-specific ones has attracted increasing research attention. For
product understanding, although existing discriminative dual-flow architectures
drive progress in this field, they inherently struggle to model the many-to-one
alignment between multiple images and texts of products. Therefore, we argue
that generative Multimodal Large Language Models (MLLMs) hold significant
potential for improving product representation learning. Nevertheless,
achieving this goal still remains non-trivial due to several key challenges:
the lack of multimodal and aspect-aware modeling modules in typical LLMs; the
common presence of background noise in product images; and the absence of a
standard benchmark for evaluation. To address these issues, we propose the
first generative MLLM-based model named MOON for product representation
learning. Our method (1) employs a guided Mixture-of-Experts (MoE) module for
targeted modeling of multimodal and aspect-specific product content; (2)
effectively detects core semantic regions in product images to mitigate the
distraction and interference caused by background noise; and (3) introduces the
specialized negative sampling strategy to increase the difficulty and diversity
of negative samples. In addition, we release a large-scale multimodal benchmark
MBE for various product understanding tasks. Experimentally, our model
demonstrates competitive zero-shot performance on both our benchmark and the
public dataset, showcasing strong generalization across various downstream
tasks, including cross-modal retrieval, product classification, and attribute
prediction. Furthermore, the case study and visualization illustrate the
effectiveness of MOON for product understanding.

</details>


### [30] [InstDrive: Instance-Aware 3D Gaussian Splatting for Driving Scenes](https://arxiv.org/abs/2508.12015)
*Hongyuan Liu,Haochen Yu,Jianfei Jiang,Qiankun Liu,Jiansheng Chen,Huimin Ma*

Main category: cs.CV

TL;DR: InstDrive是一个针对动态驾驶场景的实例感知3D高斯泼溅框架，通过SAM生成的掩码指导2D特征学习，并在3D层面引入正则化，实现了动态开放世界驾驶场景的3D实例分割。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将所有背景元素统一为单一表示，限制了实例级理解和灵活场景编辑。此外，现有方法多针对室内场景，不适用于室外驾驶场景。

Method: 使用SAM生成的掩码作为伪真值，通过对比损失和伪监督目标指导2D特征学习；在3D层面引入正则化和基于体素的损失，确保一致性；使用轻量级静态代码桥接连续特征和离散身份。

Result: 定量和定性实验证明了InstDrive的有效性，首次实现了动态开放世界驾驶场景的3D实例分割。

Conclusion: InstDrive为动态驾驶场景的交互式重建提供了一种高效且实例感知的解决方案。

Abstract: Reconstructing dynamic driving scenes from dashcam videos has attracted
increasing attention due to its significance in autonomous driving and scene
understanding. While recent advances have made impressive progress, most
methods still unify all background elements into a single representation,
hindering both instance-level understanding and flexible scene editing. Some
approaches attempt to lift 2D segmentation into 3D space, but often rely on
pre-processed instance IDs or complex pipelines to map continuous features to
discrete identities. Moreover, these methods are typically designed for indoor
scenes with rich viewpoints, making them less applicable to outdoor driving
scenarios. In this paper, we present InstDrive, an instance-aware 3D Gaussian
Splatting framework tailored for the interactive reconstruction of dynamic
driving scene. We use masks generated by SAM as pseudo ground-truth to guide 2D
feature learning via contrastive loss and pseudo-supervised objectives. At the
3D level, we introduce regularization to implicitly encode instance identities
and enforce consistency through a voxel-based loss. A lightweight static
codebook further bridges continuous features and discrete identities without
requiring data pre-processing or complex optimization. Quantitative and
qualitative experiments demonstrate the effectiveness of InstDrive, and to the
best of our knowledge, it is the first framework to achieve 3D instance
segmentation in dynamic, open-world driving scenes.More visualizations are
available at our project page.

</details>


### [31] [WiseLVAM: A Novel Framework For Left Ventricle Automatic Measurements](https://arxiv.org/abs/2508.12023)
*Durgesh Kumar Singh,Qing Cao,Sarina Thomas,Ahcène Boubekki,Robert Jenssen,Michael Kampffmeyer*

Main category: cs.CV

TL;DR: 论文提出了一种名为WiseLVAM的全自动框架，用于在超声心动图中自动放置虚拟扫描线（SL）并进行左心室线性测量，结合B模式图像的结构感知和AMM模式的运动感知以提高准确性。


<details>
  <summary>Details</summary>
Motivation: 现有自动化方法在B模式图像中直接预测标志点可能导致测量误差，临床可靠性不足。EnLVAM方法通过约束标志点预测到临床定义的SL上部分解决了这一问题，但仍需进一步自动化。

Method: 提出了一种轮廓感知的SL放置方法，通过弱监督B模式标志点检测器估计左心室轮廓，并推断LV长轴和基底水平。在此基础上，开发了WiseLVAM框架，结合B模式和AMM模式的优势。

Result: WiseLVAM框架能够全自动且可手动调整地进行SL放置和LV线性测量，提高了测量的鲁棒性和准确性。

Conclusion: WiseLVAM为临床常规应用提供了一种实用的解决方案，结合了结构感知和运动感知的优势。

Abstract: Clinical guidelines recommend performing left ventricular (LV) linear
measurements in B-mode echocardiographic images at the basal level -- typically
at the mitral valve leaflet tips -- and aligned perpendicular to the LV long
axis along a virtual scanline (SL). However, most automated methods estimate
landmarks directly from B-mode images for the measurement task, where even
small shifts in predicted points along the LV walls can lead to significant
measurement errors, reducing their clinical reliability. A recent
semi-automatic method, EnLVAM, addresses this limitation by constraining
landmark prediction to a clinician-defined SL and training on generated
Anatomical Motion Mode (AMM) images to predict LV landmarks along the same. To
enable full automation, a contour-aware SL placement approach is proposed in
this work, in which the LV contour is estimated using a weakly supervised
B-mode landmark detector. SL placement is then performed by inferring the LV
long axis and the basal level-mimicking clinical guidelines. Building on this
foundation, we introduce \textit{WiseLVAM} -- a novel, fully automated yet
manually adaptable framework for automatically placing the SL and then
automatically performing the LV linear measurements in the AMM mode.
\textit{WiseLVAM} utilizes the structure-awareness from B-mode images and the
motion-awareness from AMM mode to enhance robustness and accuracy with the
potential to provide a practical solution for the routine clinical application.

</details>


### [32] [Q-FSRU: Quantum-Augmented Frequency-Spectral Fusion for Medical Visual Question Answering](https://arxiv.org/abs/2508.12036)
*Rakesh Thakur,Yusra Tariq*

Main category: cs.CV

TL;DR: Q-FSRU模型结合频率谱表示与融合（FSRU）和量子检索增强生成（Quantum RAG），用于医学视觉问答（VQA），在复杂病例中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决医疗AI中需要同时理解图像和文本的难题。

Method: 使用FFT将图像和文本特征转换到频域，结合量子检索系统获取外部医学知识。

Result: 在VQA-RAD数据集上表现优于现有模型，尤其在需要图像-文本推理的复杂案例中。

Conclusion: Q-FSRU为医生提供了智能、清晰且实用的AI工具。

Abstract: Solving tough clinical questions that require both image and text
understanding is still a major challenge in healthcare AI. In this work, we
propose Q-FSRU, a new model that combines Frequency Spectrum Representation and
Fusion (FSRU) with a method called Quantum Retrieval-Augmented Generation
(Quantum RAG) for medical Visual Question Answering (VQA). The model takes in
features from medical images and related text, then shifts them into the
frequency domain using Fast Fourier Transform (FFT). This helps it focus on
more meaningful data and filter out noise or less useful information. To
improve accuracy and ensure that answers are based on real knowledge, we add a
quantum-inspired retrieval system. It fetches useful medical facts from
external sources using quantum-based similarity techniques. These details are
then merged with the frequency-based features for stronger reasoning. We
evaluated our model using the VQA-RAD dataset, which includes real radiology
images and questions. The results showed that Q-FSRU outperforms earlier
models, especially on complex cases needing image-text reasoning. The mix of
frequency and quantum information improves both performance and explainability.
Overall, this approach offers a promising way to build smart, clear, and
helpful AI tools for doctors.

</details>


### [33] [VimoRAG: Video-based Retrieval-augmented 3D Motion Generation for Motion Language Models](https://arxiv.org/abs/2508.12081)
*Haidong Xu,Guangwei Xu,Zhedong Zheng,Xiatian Zhu,Wei Ji,Xiangtai Li,Ruijie Guo,Meishan Zhang,Min zhang,Hao Fei*

Main category: cs.CV

TL;DR: VimoRAG是一个基于视频的检索增强运动生成框架，用于解决运动大语言模型（LLMs）因数据不足导致的问题。


<details>
  <summary>Details</summary>
Motivation: 运动LLMs因标注数据有限面临严重的领域外/词汇外问题，需要利用大规模视频数据库增强3D运动生成。

Method: 设计了Gemini Motion Video Retriever机制和Motion-centric Dual-alignment DPO Trainer，解决视频检索和错误传播问题。

Result: 实验表明，VimoRAG显著提升了仅依赖文本输入的运动LLMs性能。

Conclusion: VimoRAG通过视频检索有效解决了运动LLMs的数据限制问题。

Abstract: This paper introduces VimoRAG, a novel video-based retrieval-augmented motion
generation framework for motion large language models (LLMs). As motion LLMs
face severe out-of-domain/out-of-vocabulary issues due to limited annotated
data, VimoRAG leverages large-scale in-the-wild video databases to enhance 3D
motion generation by retrieving relevant 2D human motion signals. While
video-based motion RAG is nontrivial, we address two key bottlenecks: (1)
developing an effective motion-centered video retrieval model that
distinguishes human poses and actions, and (2) mitigating the issue of error
propagation caused by suboptimal retrieval results. We design the Gemini Motion
Video Retriever mechanism and the Motion-centric Dual-alignment DPO Trainer,
enabling effective retrieval and generation processes. Experimental results
show that VimoRAG significantly boosts the performance of motion LLMs
constrained to text-only input.

</details>


### [34] [Automated Model Evaluation for Object Detection via Prediction Consistency and Reliablity](https://arxiv.org/abs/2508.12082)
*Seungju Yoo,Hyuk Kwon,Joong-Won Hwang,Kibok Lee*

Main category: cs.CV

TL;DR: 提出了一种自动化评估框架AutoEval，通过预测一致性和可靠性（PCR）方法，无需人工标注即可评估目标检测器的性能。


<details>
  <summary>Details</summary>
Motivation: 当前目标检测器性能评估依赖昂贵的人工标注，限制了实际应用效率。

Method: 提出PCR方法，利用非极大抑制（NMS）前后的候选框空间一致性和置信度可靠性，自动估计检测性能。

Result: 实验表明PCR比现有AutoEval方法更准确，且构建的元数据集覆盖更广的性能范围。

Conclusion: AutoEval框架和PCR方法为无标注评估目标检测性能提供了高效解决方案。

Abstract: Recent advances in computer vision have made training object detectors more
efficient and effective; however, assessing their performance in real-world
applications still relies on costly manual annotation. To address this
limitation, we develop an automated model evaluation (AutoEval) framework for
object detection. We propose Prediction Consistency and Reliability (PCR),
which leverages the multiple candidate bounding boxes that conventional
detectors generate before non-maximum suppression (NMS). PCR estimates
detection performance without ground-truth labels by jointly measuring 1) the
spatial consistency between boxes before and after NMS, and 2) the reliability
of the retained boxes via the confidence scores of overlapping boxes. For a
more realistic and scalable evaluation, we construct a meta-dataset by applying
image corruptions of varying severity. Experimental results demonstrate that
PCR yields more accurate performance estimates than existing AutoEval methods,
and the proposed meta-dataset covers a wider range of detection performance.
The code is available at https://github.com/YonseiML/autoeval-det.

</details>


### [35] [Generic Event Boundary Detection via Denoising Diffusion](https://arxiv.org/abs/2508.12084)
*Jaejun Hwang,Dayoung Gong,Manjin Kim,Minsu Cho*

Main category: cs.CV

TL;DR: DiffGEBD是一种基于扩散模型的通用事件边界检测方法，通过生成多样性边界解决主观性问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法忽视事件边界的主观性和多样性，DiffGEBD从生成视角解决这一问题。

Method: 利用时间自相似性编码帧间变化，通过去噪扩散模型迭代生成边界，并采用无分类器引导控制多样性。

Result: 在Kinetics-GEBD和TAPOS基准测试中表现优异，生成多样且合理的事件边界。

Conclusion: DiffGEBD通过生成模型有效解决事件边界多样性问题，新评估指标兼顾多样性和保真度。

Abstract: Generic event boundary detection (GEBD) aims to identify natural boundaries
in a video, segmenting it into distinct and meaningful chunks. Despite the
inherent subjectivity of event boundaries, previous methods have focused on
deterministic predictions, overlooking the diversity of plausible solutions. In
this paper, we introduce a novel diffusion-based boundary detection model,
dubbed DiffGEBD, that tackles the problem of GEBD from a generative
perspective. The proposed model encodes relevant changes across adjacent frames
via temporal self-similarity and then iteratively decodes random noise into
plausible event boundaries being conditioned on the encoded features.
Classifier-free guidance allows the degree of diversity to be controlled in
denoising diffusion. In addition, we introduce a new evaluation metric to
assess the quality of predictions considering both diversity and fidelity.
Experiments show that our method achieves strong performance on two standard
benchmarks, Kinetics-GEBD and TAPOS, generating diverse and plausible event
boundaries.

</details>


### [36] [Enhancing 3D point accuracy of laser scanner through multi-stage convolutional neural network for applications in construction](https://arxiv.org/abs/2508.12089)
*Qinyuan Fan,Clemens Gühmann*

Main category: cs.CV

TL;DR: 提出了一种基于多阶段卷积神经网络（MSCNN）的方法，用于减少激光扫描仪在粗糙室内环境中的3D点精度不确定性。


<details>
  <summary>Details</summary>
Motivation: 高精度和低精度激光扫描仪因设备和环境因素存在位置误差，需量化误差模式以提高测量精度。

Method: 通过配对高精度和低精度扫描仪，建立统计关系，结合几何处理和神经网络优化，量化系统误差。

Result: 实验显示测量精度显著提升，MSE降低超70%，PSNR提高约6分贝。

Conclusion: 该方法使低端设备无需硬件改造即可接近高端设备的测量精度。

Abstract: We propose a multi-stage convolutional neural network (MSCNN) based
integrated method for reducing uncertainty of 3D point accuracy of lasar
scanner (LS) in rough indoor rooms, providing more accurate spatial
measurements for high-precision geometric model creation and renovation. Due to
different equipment limitations and environmental factors, high-end and low-end
LS have positional errors. Our approach pairs high-accuracy scanners (HAS) as
references with corresponding low-accuracy scanners (LAS) of measurements in
identical environments to quantify specific error patterns. By establishing a
statistical relationship between measurement discrepancies and their spatial
distribution, we develop a correction framework that combines traditional
geometric processing with targeted neural network refinement. This method
transforms the quantification of systematic errors into a supervised learning
problem, allowing precise correction while preserving critical geometric
features. Experimental results in our rough indoor rooms dataset show
significant improvements in measurement accuracy, with mean square error (MSE)
reductions exceeding 70% and peak signal-to-noise ratio (PSNR) improvements of
approximately 6 decibels. This approach enables low-end devices to achieve
measurement uncertainty levels approaching those of high-end devices without
hardware modifications.

</details>


### [37] [Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion](https://arxiv.org/abs/2508.12094)
*Songwei Liu,Hong Liu,Fangmin Chen,Xurui Peng,Chenqian Yan,Lean Fu,Xing Mei*

Main category: cs.CV

TL;DR: 提出了一种时间感知的累积误差补偿方案，显著提升了低精度扩散模型的性能。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像合成中表现出色，但迭代去噪过程计算量大，量化误差累积影响输出质量。

Method: 建立理论框架，量化误差传播方程，提出时间感知的累积误差补偿方案。

Result: 实验证明该方法有效减少误差传播，提升低精度扩散模型的性能。

Conclusion: 提出的补偿方案显著改善了量化误差问题，实现了低精度扩散模型的SOTA性能。

Abstract: Diffusion models have transformed image synthesis by establishing
unprecedented quality and creativity benchmarks. Nevertheless, their
large-scale deployment faces challenges due to computationally intensive
iterative denoising processes. Although post-training quantization(PTQ)
provides an effective pathway for accelerating sampling, the iterative nature
of diffusion models causes stepwise quantization errors to accumulate
progressively during generation, inevitably compromising output fidelity. To
address this challenge, we develop a theoretical framework that mathematically
formulates error propagation in Diffusion Models (DMs), deriving per-step
quantization error propagation equations and establishing the first closed-form
solution for cumulative error. Building on this theoretical foundation, we
propose a timestep-aware cumulative error compensation scheme. Extensive
experiments across multiple image datasets demonstrate that our compensation
strategy effectively mitigates error propagation, significantly enhancing
existing PTQ methods to achieve state-of-the-art(SOTA) performance on
low-precision diffusion models.

</details>


### [38] [VELVET-Med: Vision and Efficient Language Pre-training for Volumetric Imaging Tasks in Medicine](https://arxiv.org/abs/2508.12108)
*Ziyang Zhang,Yang Yu,Xulei Yang,Si Yong Yeo*

Main category: cs.CV

TL;DR: VELVET-Med 是一种针对有限体积数据（如3D CT扫描和放射学报告）设计的视觉语言预训练框架，通过自监督学习和新型语言编码器提升性能。


<details>
  <summary>Details</summary>
Motivation: 医学领域中，体积数据（如CT扫描）与文本的配对数据收集困难，限制了模型在下游任务中的表现。

Method: 结合单模态自监督学习、新型语言编码器TriBERT和分层对比学习，利用少量数据（38,875对）学习空间和语义关系。

Result: 模型在3D分割、跨模态检索、视觉问答和报告生成等任务中达到最先进性能。

Conclusion: VELVET-Med 通过高效预训练目标和架构设计，显著提升了体积医学数据的视觉语言模型性能。

Abstract: Vision-and-language models (VLMs) have been increasingly explored in the
medical domain, particularly following the success of CLIP in general domain.
However, unlike the relatively straightforward pairing of 2D images and text,
curating large-scale paired data in the medical field for volumetric modalities
such as CT scans remains a challenging and time-intensive process. This
difficulty often limits the performance on downstream tasks. To address these
challenges, we propose a novel vision-language pre-training (VLP) framework,
termed as \textbf{VELVET-Med}, specifically designed for limited volumetric
data such as 3D CT and associated radiology reports. Instead of relying on
large-scale data collection, our method focuses on the development of effective
pre-training objectives and model architectures. The key contributions are: 1)
We incorporate uni-modal self-supervised learning into VLP framework, which are
often underexplored in the existing literature. 2) We propose a novel language
encoder, termed as \textbf{TriBERT}, for learning multi-level textual
semantics. 3) We devise the hierarchical contrastive learning to capture
multi-level vision-language correspondence. Using only 38,875 scan-report
pairs, our approach seeks to uncover rich spatial and semantic relationships
embedded in volumetric medical images and corresponding clinical narratives,
thereby enhancing the generalization ability of the learned encoders. The
resulting encoders exhibit strong transferability, achieving state-of-the-art
performance across a wide range of downstream tasks, including 3D segmentation,
cross-modal retrieval, visual question answering, and report generation.

</details>


### [39] [Simple o3: Towards Interleaved Vision-Language Reasoning](https://arxiv.org/abs/2508.12109)
*Ye Wang,Qianglong Chen,Zejun Li,Siyuan Wang,Shijie Guo,Zhirui Zhang,Zhongyu Wei*

Main category: cs.CV

TL;DR: Simple o3是一个端到端框架，通过动态工具交互和监督微调提升多模态长链推理能力，并在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 探索多模态大语言模型在长链推理中的潜力，弥补现有研究的不足。

Method: 提出Simple o3框架，结合动态工具交互（如裁剪、缩放）和视觉语言推理，通过数据合成管道生成高质量推理链。

Result: 在多个基准测试中表现优异，首次深入分析了不同交错推理策略对模型性能的影响。

Conclusion: Simple o3为多模态推理提供了高效且计算成本低的范例，显著提升了视觉推理和细粒度感知能力。

Abstract: Multimodal Large Language Models (MLLMs) have shown impressive performance on
vision-language tasks, but their long Chain-of-Thought (CoT) capabilities in
multimodal scenarios remain underexplored. Inspired by OpenAI's o3 model, which
emulates human-like ''thinking with image'' through iterative visual
transformations and linguistic reasoning, we propose Simple o3, an end-to-end
framework that integrates dynamic tool interactions (e.g., cropping, zooming,
and reusing) into interleaved vision-language reasoning via supervised
fine-tuning (SFT). Our approach features a scalable data synthesis pipeline
that generates high-quality interleaved vision-language reasoning chains via an
''observe-reason-act'' cycle, complete with executable visual operations and
rigorous verification, yielding the open-source TWI-Tools-146K dataset.
Experimental results demonstrate Simple o3's superior performance on diverse
benchmarks, outperforming existing approaches. By combining enhanced reasoning
capabilities, Simple o3 establishes a powerful yet computationally affordable
paradigm for advancing multimodal reasoning. Remarkably, we provide the first
in-depth analysis of different interleaved reasoning strategies, offering
insights into their impact on model performance. We found that by introducing
additional visual tokens for interleaved vision-language reasoning, reusing and
magnifying the original image significantly improves the model's visual
reasoning and fine-grained perception, while image cropping based on precise
visual grounding allows the model to effectively focus on key entities or
regions, further enhancing its capabilities.

</details>


### [40] [DualFit: A Two-Stage Virtual Try-On via Warping and Synthesis](https://arxiv.org/abs/2508.12131)
*Minh Tran,Johnmark Clements,Annie Prasanna,Tri Nguyen,Ngan Le*

Main category: cs.CV

TL;DR: DualFit是一种混合虚拟试穿技术，通过两阶段方法保留服装细节。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以保留服装的精细细节（如标志和印刷文本），影响品牌完整性和客户信任。

Method: DualFit采用两阶段流程：1）通过学习流场对齐服装；2）通过保真试穿模块合成最终图像。

Result: DualFit在视觉上无缝地保留了高频服装细节，平衡了重建准确性和感知真实性。

Conclusion: DualFit在虚拟试穿中有效保留了服装细节，提升了用户体验。

Abstract: Virtual Try-On technology has garnered significant attention for its
potential to transform the online fashion retail experience by allowing users
to visualize how garments would look on them without physical trials. While
recent advances in diffusion-based warping-free methods have improved
perceptual quality, they often fail to preserve fine-grained garment details
such as logos and printed text elements that are critical for brand integrity
and customer trust. In this work, we propose DualFit, a hybrid VTON pipeline
that addresses this limitation by two-stage approach. In the first stage,
DualFit warps the target garment to align with the person image using a learned
flow field, ensuring high-fidelity preservation. In the second stage, a
fidelity-preserving try-on module synthesizes the final output by blending the
warped garment with preserved human regions. Particularly, to guide this
process, we introduce a preserved-region input and an inpainting mask, enabling
the model to retain key areas and regenerate only where necessary, particularly
around garment seams. Extensive qualitative results show that DualFit achieves
visually seamless try-on results while faithfully maintaining high-frequency
garment details, striking an effective balance between reconstruction accuracy
and perceptual realism.

</details>


### [41] [TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks](https://arxiv.org/abs/2508.12132)
*Amira Guesmi,Bassem Ouni,Muhammad Shafique*

Main category: cs.CV

TL;DR: TriQDef是一种针对量化神经网络（QNNs）的三级防御框架，通过破坏语义和梯度对齐来抵御跨位宽的补丁攻击。


<details>
  <summary>Details</summary>
Motivation: QNNs在资源受限环境中广泛使用，但对跨位宽的补丁攻击防御不足，现有方法无法解决这一漏洞。

Method: TriQDef包含特征不对齐惩罚（FDP）、梯度感知不一致惩罚（GPDP）和联合量化感知训练协议。

Result: 在CIFAR-10和ImageNet上，TriQDef将攻击成功率降低40%以上，同时保持高准确率。

Conclusion: 破坏语义和梯度对齐是减少QNNs中补丁攻击转移性的关键。

Abstract: Quantized Neural Networks (QNNs) are increasingly deployed in edge and
resource-constrained environments due to their efficiency in computation and
memory usage. While shown to distort the gradient landscape and weaken
conventional pixel-level attacks, it provides limited robustness against
patch-based adversarial attacks-localized, high-saliency perturbations that
remain surprisingly transferable across bit-widths. Existing defenses either
overfit to fixed quantization settings or fail to address this cross-bit
generalization vulnerability. We introduce \textbf{TriQDef}, a tri-level
quantization-aware defense framework designed to disrupt the transferability of
patch-based adversarial attacks across QNNs. TriQDef consists of: (1) a Feature
Disalignment Penalty (FDP) that enforces semantic inconsistency by penalizing
perceptual similarity in intermediate representations; (2) a Gradient
Perceptual Dissonance Penalty (GPDP) that explicitly misaligns input gradients
across bit-widths by minimizing structural and directional agreement via Edge
IoU and HOG Cosine metrics; and (3) a Joint Quantization-Aware Training
Protocol that unifies these penalties within a shared-weight training scheme
across multiple quantization levels. Extensive experiments on CIFAR-10 and
ImageNet demonstrate that TriQDef reduces Attack Success Rates (ASR) by over
40\% on unseen patch and quantization combinations, while preserving high clean
accuracy. Our findings underscore the importance of disrupting both semantic
and perceptual gradient alignment to mitigate patch transferability in QNNs.

</details>


### [42] [Infusing fine-grained visual knowledge to Vision-Language Models](https://arxiv.org/abs/2508.12137)
*Nikolaos-Antonios Ypsilantis,Kaifeng Chen,André Araujo,Ondřej Chum*

Main category: cs.CV

TL;DR: 提出一种微调方法，平衡细粒度领域适应与预训练视觉语言模型的多模态知识保留，避免灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 预训练视觉语言模型在细粒度开放集视觉检索中表现不佳，直接微调会导致灾难性遗忘。

Method: 结合持续学习中的正则化技术，设计高效的组合策略，并优化验证集和超参数调优。

Result: 在细粒度和粗粒度图像-图像及图像-文本检索任务中表现优异，保留视觉-文本对齐能力。

Conclusion: 方法有效平衡领域适应与知识保留，无需文本数据或原始文本编码器即可实现强泛化能力。

Abstract: Large-scale contrastive pre-training produces powerful Vision-and-Language
Models (VLMs) capable of generating representations (embeddings) effective for
a wide variety of visual and multimodal tasks. However, these pretrained
embeddings remain suboptimal for fine-grained open-set visual retrieval, where
state-of-the-art results require fine-tuning the vision encoder using annotated
domain-specific samples. Naively performing such fine-tuning typically leads to
catastrophic forgetting, severely diminishing the model's general-purpose
visual and cross-modal capabilities.
  In this work, we propose a fine-tuning method explicitly designed to achieve
optimal balance between fine-grained domain adaptation and retention of the
pretrained VLM's broad multimodal knowledge. Drawing inspiration from continual
learning literature, we systematically analyze standard regularization
techniques aimed at knowledge retention and propose an efficient and effective
combination strategy. Additionally, we address the commonly overlooked yet
critical aspects of validation set design and hyperparameter tuning to ensure
reproducibility and robust generalization across datasets and pretrained
models. We extensively evaluate our method on both fine-grained and
coarse-grained image-image and image-text retrieval benchmarks. Our approach
consistently achieves strong results, notably retaining the visual-text
alignment without utilizing any text data or the original text encoder during
fine-tuning. Code and model checkpoints: https://github.com/nikosips/infusing .

</details>


### [43] [KP-INR: A Dual-Branch Implicit Neural Representation Model for Cardiac Cine MRI Reconstruction](https://arxiv.org/abs/2508.12147)
*Donghang Lyu,Marius Staring,Mariya Doneva,Hildo J. Lamb,Nicola Pezzotti*

Main category: cs.CV

TL;DR: KP-INR是一种双分支隐式神经表示方法，用于心脏电影MRI重建，通过结合坐标位置嵌入和局部多尺度k空间特征表示，显著提升了图像质量。


<details>
  <summary>Details</summary>
Motivation: 现有INR方法主要关注坐标位置嵌入，忽略了目标点及其邻域的特征表示，导致重建效果受限。

Method: 提出KP-INR，采用双分支结构：一支处理k空间坐标的位置嵌入，另一支学习局部多尺度k空间特征表示，并通过跨分支交互提升性能。

Result: 在CMRxRecon2024数据集上，KP-INR表现优于基线模型，验证了其有效性。

Conclusion: KP-INR通过结合位置和特征表示，为心脏电影MRI重建提供了高质量解决方案，具有广阔应用前景。

Abstract: Cardiac Magnetic Resonance (CMR) imaging is a non-invasive method for
assessing cardiac structure, function, and blood flow. Cine MRI extends this by
capturing heart motion, providing detailed insights into cardiac mechanics. To
reduce scan time and breath-hold discomfort, fast acquisition techniques have
been utilized at the cost of lowering image quality. Recently, Implicit Neural
Representation (INR) methods have shown promise in unsupervised reconstruction
by learning coordinate-to-value mappings from undersampled data, enabling
high-quality image recovery. However, current existing INR methods primarily
focus on using coordinate-based positional embeddings to learn the mapping,
while overlooking the feature representations of the target point and its
neighboring context. In this work, we propose KP-INR, a dual-branch INR method
operating in k-space for cardiac cine MRI reconstruction: one branch processes
the positional embedding of k-space coordinates, while the other learns from
local multi-scale k-space feature representations at those coordinates. By
enabling cross-branch interaction and approximating the target k-space values
from both branches, KP-INR can achieve strong performance on challenging
Cartesian k-space data. Experiments on the CMRxRecon2024 dataset confirms its
improved performance over baseline models and highlights its potential in this
field.

</details>


### [44] [Demystifying Foreground-Background Memorization in Diffusion Models](https://arxiv.org/abs/2508.12148)
*Jimmy Z. Di,Yiwei Lu,Yaoliang Yu,Gautam Kamath,Adam Dziedzic,Franziska Boenisch*

Main category: cs.CV

TL;DR: FB-Mem是一种基于分割的度量方法，用于量化扩散模型中的记忆区域，揭示记忆现象比之前认为的更普遍，并提出了一种新的缓解方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法全面捕捉扩散模型中的部分记忆和复杂记忆模式，需要更有效的检测和缓解手段。

Method: 提出FB-Mem，通过分割和分类生成图像中的记忆区域，并结合聚类方法分析记忆模式。

Result: 发现记忆现象更普遍，现有缓解方法无法消除局部记忆，尤其是前景区域。

Conclusion: FB-Mem为测量扩散模型记忆提供了有效框架，并提出了更强大的聚类缓解方法。

Abstract: Diffusion models (DMs) memorize training images and can reproduce
near-duplicates during generation. Current detection methods identify verbatim
memorization but fail to capture two critical aspects: quantifying partial
memorization occurring in small image regions, and memorization patterns beyond
specific prompt-image pairs. To address these limitations, we propose
Foreground Background Memorization (FB-Mem), a novel segmentation-based metric
that classifies and quantifies memorized regions within generated images. Our
method reveals that memorization is more pervasive than previously understood:
(1) individual generations from single prompts may be linked to clusters of
similar training images, revealing complex memorization patterns that extend
beyond one-to-one correspondences; and (2) existing model-level mitigation
methods, such as neuron deactivation and pruning, fail to eliminate local
memorization, which persists particularly in foreground regions. Our work
establishes an effective framework for measuring memorization in diffusion
models, demonstrates the inadequacy of current mitigation approaches, and
proposes a stronger mitigation method using a clustering approach.

</details>


### [45] [RealTalk: Realistic Emotion-Aware Lifelike Talking-Head Synthesis](https://arxiv.org/abs/2508.12163)
*Wenqing Wang,Yun Fu*

Main category: cs.CV

TL;DR: RealTalk是一种新型框架，用于合成具有高情感准确性、增强情感可控性和稳健身份保留的情感说话头部。


<details>
  <summary>Details</summary>
Motivation: 当前方法在唇同步和图像质量上表现优异，但在生成准确且可控的情感表达同时保留主体身份方面存在不足。

Method: RealTalk利用变分自编码器（VAE）生成3D面部标志点，结合情感标签嵌入和基于ResNet的标志点变形模型（LDM），并通过新型三平面注意力神经辐射场（NeRF）合成高度真实的情感说话头部。

Result: 实验表明，RealTalk在情感准确性、可控性和身份保留方面优于现有方法。

Conclusion: RealTalk推动了社交智能AI系统的发展。

Abstract: Emotion is a critical component of artificial social intelligence. However,
while current methods excel in lip synchronization and image quality, they
often fail to generate accurate and controllable emotional expressions while
preserving the subject's identity. To address this challenge, we introduce
RealTalk, a novel framework for synthesizing emotional talking heads with high
emotion accuracy, enhanced emotion controllability, and robust identity
preservation. RealTalk employs a variational autoencoder (VAE) to generate 3D
facial landmarks from driving audio, which are concatenated with emotion-label
embeddings using a ResNet-based landmark deformation model (LDM) to produce
emotional landmarks. These landmarks and facial blendshape coefficients jointly
condition a novel tri-plane attention Neural Radiance Field (NeRF) to
synthesize highly realistic emotional talking heads. Extensive experiments
demonstrate that RealTalk outperforms existing methods in emotion accuracy,
controllability, and identity preservation, advancing the development of
socially intelligent AI systems.

</details>


### [46] [Scalable RF Simulation in Generative 4D Worlds](https://arxiv.org/abs/2508.12176)
*Zhiwei Zheng,Dongyin Hu,Mingmin Zhao*

Main category: cs.CV

TL;DR: WaveVerse是一个基于提示的可扩展框架，通过生成室内场景和人体运动模拟真实的RF信号，解决了动态多样室内环境中高质量RF数据收集的挑战。


<details>
  <summary>Details</summary>
Motivation: RF传感在室内感知任务中是一种隐私保护的替代方案，但高质量RF数据的收集在动态多样的环境中仍具挑战性。

Method: WaveVerse结合语言引导的4D世界生成器和相位相干射线追踪模拟器，生成空间约束和文本条件下的人体运动，并模拟准确的RF信号。

Result: 实验表明WaveVerse在条件人体运动生成和相位相干应用于波束成形和呼吸监测中有效，并在ML高分辨率成像和人类活动识别中表现优异。

Conclusion: WaveVerse首次实现了RF成像数据生成，并在数据有限和充足场景中均表现优异。

Abstract: Radio Frequency (RF) sensing has emerged as a powerful, privacy-preserving
alternative to vision-based methods for indoor perception tasks. However,
collecting high-quality RF data in dynamic and diverse indoor environments
remains a major challenge. To address this, we introduce WaveVerse, a
prompt-based, scalable framework that simulates realistic RF signals from
generated indoor scenes with human motions. WaveVerse introduces a
language-guided 4D world generator, which includes a state-aware causal
transformer for human motion generation conditioned on spatial constraints and
texts, and a phase-coherent ray tracing simulator that enables the simulation
of accurate and coherent RF signals. Experiments demonstrate the effectiveness
of our approach in conditioned human motion generation and highlight how phase
coherence is applied to beamforming and respiration monitoring. We further
present two case studies in ML-based high-resolution imaging and human activity
recognition, demonstrating that WaveVerse not only enables data generation for
RF imaging for the first time, but also consistently achieves performance gain
in both data-limited and data-adequate scenarios.

</details>


### [47] [Splat Feature Solver](https://arxiv.org/abs/2508.12216)
*Butian Xiong,Rong Liu,Kenneth Xu,Meida Chen,Andrew Feng*

Main category: cs.CV

TL;DR: 提出了一种统一、高效的特征提升方法，通过稀疏线性逆问题和正则化策略，显著提升了3D场景理解中的特征质量。


<details>
  <summary>Details</summary>
Motivation: 解决多视角图像中特征不一致性问题，优化3D基元上的通用属性分配。

Method: 将特征提升问题建模为稀疏线性逆问题，引入Tikhonov指导和后提升聚合两种正则化策略。

Result: 在开放词汇3D分割基准上达到SOTA性能，且特征提取速度快。

Conclusion: 该方法高效、稳定，显著提升了3D场景理解的特征质量。

Abstract: Feature lifting has emerged as a crucial component in 3D scene understanding,
enabling the attachment of rich image feature descriptors (e.g., DINO, CLIP)
onto splat-based 3D representations. The core challenge lies in optimally
assigning rich general attributes to 3D primitives while addressing the
inconsistency issues from multi-view images. We present a unified, kernel- and
feature-agnostic formulation of the feature lifting problem as a sparse linear
inverse problem, which can be solved efficiently in closed form. Our approach
admits a provable upper bound on the global optimal error under convex losses
for delivering high quality lifted features. To address inconsistencies and
noise in multi-view observations, we introduce two complementary regularization
strategies to stabilize the solution and enhance semantic fidelity. Tikhonov
Guidance enforces numerical stability through soft diagonal dominance, while
Post-Lifting Aggregation filters noisy inputs via feature clustering. Extensive
experiments demonstrate that our approach achieves state-of-the-art performance
on open-vocabulary 3D segmentation benchmarks, outperforming training-based,
grouping-based, and heuristic-forward baselines while producing the lifted
features in minutes. Code is available at
\href{https://github.com/saliteta/splat-distiller.git}{\textbf{github}}. We
also have a \href{https://splat-distiller.pages.dev/}

</details>


### [48] [Precise Action-to-Video Generation Through Visual Action Prompts](https://arxiv.org/abs/2508.13104)
*Yuang Wang,Chao Wen,Haoyu Guo,Sida Peng,Minghan Qin,Hujun Bao,Xiaowei Zhou,Ruizhen Hu*

Main category: cs.CV

TL;DR: 提出视觉动作提示（VAP），用于复杂高自由度交互的动作到视频生成，平衡动作精度和跨域动态迁移能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在动作驱动的视频生成中存在精度与通用性的权衡，文本、原始动作或粗略掩码缺乏精度，而基于代理的动作信号则牺牲了跨域迁移能力。

Method: 通过将动作“渲染”为视觉提示（如视觉骨架），作为领域无关表示，结合轻量级微调预训练视频生成模型。

Result: 在EgoVid、RT-1和DROID数据集上验证了方法的有效性，实现了复杂交互的精确动作控制。

Conclusion: 视觉动作提示成功平衡了动作精度与跨域动态迁移能力，适用于复杂动作的视频生成。

Abstract: We present visual action prompts, a unified action representation for
action-to-video generation of complex high-DoF interactions while maintaining
transferable visual dynamics across domains. Action-driven video generation
faces a precision-generality trade-off: existing methods using text, primitive
actions, or coarse masks offer generality but lack precision, while
agent-centric action signals provide precision at the cost of cross-domain
transferability. To balance action precision and dynamic transferability, we
propose to "render" actions into precise visual prompts as domain-agnostic
representations that preserve both geometric precision and cross-domain
adaptability for complex actions; specifically, we choose visual skeletons for
their generality and accessibility. We propose robust pipelines to construct
skeletons from two interaction-rich data sources - human-object interactions
(HOI) and dexterous robotic manipulation - enabling cross-domain training of
action-driven generative models. By integrating visual skeletons into
pretrained video generation models via lightweight fine-tuning, we enable
precise action control of complex interaction while preserving the learning of
cross-domain dynamics. Experiments on EgoVid, RT-1 and DROID demonstrate the
effectiveness of our proposed approach. Project page:
https://zju3dv.github.io/VAP/.

</details>


### [49] [C2PSA-Enhanced YOLOv11 Architecture: A Novel Approach for Small Target Detection in Cotton Disease Diagnosis](https://arxiv.org/abs/2508.12219)
*Kaiyuan Wang,Jixing Liu,Xiaobo Cai*

Main category: cs.CV

TL;DR: 该研究通过深度学习优化YOLOv11，用于棉花病害检测，解决了早期斑点检测精度低、田间条件性能下降和多病害场景高错误率的问题。


<details>
  <summary>Details</summary>
Motivation: 解决棉花病害检测中的三个关键挑战：早期斑点检测精度低、田间条件性能下降和多病害场景高错误率。

Method: 提出C2PSA模块增强小目标特征提取，动态类别权重处理样本不平衡，改进数据增强方法Mosaic-MixUp缩放。

Result: 在4078张图像的测试集上，mAP50达到0.820（提升8.0%），mAP50-95达到0.705（提升10.5%），推理速度为158 FPS。

Conclusion: 该系统在移动端部署，实现了实时病害监测和精准治疗，适用于农业应用。

Abstract: This study presents a deep learning-based optimization of YOLOv11 for cotton
disease detection, developing an intelligent monitoring system. Three key
challenges are addressed: (1) low precision in early spot detection (35%
leakage rate for sub-5mm2 spots), (2) performance degradation in field
conditions (25% accuracy drop), and (3) high error rates (34.7%) in
multi-disease scenarios. The proposed solutions include: C2PSA module for
enhanced small-target feature extraction; Dynamic category weighting to handle
sample imbalance; Improved data augmentation via Mosaic-MixUp scaling.
Experimental results on a 4,078-image dataset show: mAP50: 0.820 (+8.0%
improvement); mAP50-95: 0.705 (+10.5% improvement); Inference speed: 158 FPS.
The mobile-deployed system enables real-time disease monitoring and precision
treatment in agricultural applications.

</details>


### [50] [Has GPT-5 Achieved Spatial Intelligence? An Empirical Study](https://arxiv.org/abs/2508.13142)
*Zhongang Cai,Yubo Wang,Qingping Sun,Ruisi Wang,Chenyang Gu,Wanqi Yin,Zhiqian Lin,Zhitao Yang,Chen Wei,Xuanke Shi,Kewang Deng,Xiaoyang Han,Zukai Chen,Jiaqi Li,Xiangyu Fan,Hanming Deng,Lewei Lu,Bo Li,Ziwei Liu,Quan Wang,Dahua Lin,Lei Yang*

Main category: cs.CV

TL;DR: GPT-5在空间智能方面表现突出，但仍未达到人类水平，且开源模型在复杂问题上不逊于专有模型。


<details>
  <summary>Details</summary>
Motivation: 评估多模态模型在空间理解和推理方面的能力，以推动人工通用智能的发展。

Method: 提出空间任务分类法，评估8个基准测试，消耗超过10亿token。

Result: GPT-5表现优异但不及人类，开源模型在难题上表现相当。

Conclusion: 多模态模型在空间智能方面仍有提升空间，需进一步研究。

Abstract: Multi-modal models have achieved remarkable progress in recent years.
Nevertheless, they continue to exhibit notable limitations in spatial
understanding and reasoning, which are fundamental capabilities to achieving
artificial general intelligence. With the recent release of GPT-5, allegedly
the most powerful AI model to date, it is timely to examine where the leading
models stand on the path toward spatial intelligence. First, we propose a
comprehensive taxonomy of spatial tasks that unifies existing benchmarks and
discuss the challenges in ensuring fair evaluation. We then evaluate
state-of-the-art proprietary and open-source models on eight key benchmarks, at
a cost exceeding one billion total tokens. Our empirical study reveals that (1)
GPT-5 demonstrates unprecedented strength in spatial intelligence, yet (2)
still falls short of human performance across a broad spectrum of tasks.
Moreover, we (3) identify the more challenging spatial intelligence problems
for multi-modal models, and (4) proprietary models do not exhibit a decisive
advantage when facing the most difficult problems. In addition, we conduct a
qualitative evaluation across a diverse set of scenarios that are intuitive for
humans yet fail even the most advanced multi-modal models.

</details>


### [51] [In vivo 3D ultrasound computed tomography of musculoskeletal tissues with generative neural physics](https://arxiv.org/abs/2508.12226)
*Zhijun Zeng,Youjia Zheng,Chang Su,Qianhang Wu,Hao Hu,Zeyuan Dong,Shan Gao,Yang Lv,Rui Tang,Ligang Cui,Zhiyong Hou,Weijun Lin,Zuoqiang Shi,Yubing Li,He Sun*

Main category: cs.CV

TL;DR: 提出了一种结合生成网络与物理模拟的神经物理框架，用于快速、高保真的3D超声计算机断层扫描（USCT），解决了传统射线重建在强散射环境中的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统USCT在肌肉骨骼成像中因强散射问题受限，需要一种新方法提高成像质量和效率。

Method: 结合生成网络与物理模拟，学习超声波传播的紧凑替代模型，实现高效稳定的3D成像。

Result: 在合成和体内数据中，10分钟内重建组织参数3D图，分辨率和敏感性媲美MRI。

Conclusion: 该方法克服了强散射的计算瓶颈，推动USCT在肌肉骨骼疾病临床评估中的应用。

Abstract: Ultrasound computed tomography (USCT) is a radiation-free, high-resolution
modality but remains limited for musculoskeletal imaging due to conventional
ray-based reconstructions that neglect strong scattering. We propose a
generative neural physics framework that couples generative networks with
physics-informed neural simulation for fast, high-fidelity 3D USCT. By learning
a compact surrogate of ultrasonic wave propagation from only dozens of
cross-modality images, our method merges the accuracy of wave modeling with the
efficiency and stability of deep learning. This enables accurate quantitative
imaging of in vivo musculoskeletal tissues, producing spatial maps of acoustic
properties beyond reflection-mode images. On synthetic and in vivo data
(breast, arm, leg), we reconstruct 3D maps of tissue parameters in under ten
minutes, with sensitivity to biomechanical properties in muscle and bone and
resolution comparable to MRI. By overcoming computational bottlenecks in
strongly scattering regimes, this approach advances USCT toward routine
clinical assessment of musculoskeletal disease.

</details>


### [52] [WXSOD: A Benchmark for Robust Salient Object Detection in Adverse Weather Conditions](https://arxiv.org/abs/2508.12250)
*Quan Chen,Xiong Yang,Rongfeng Lu,Qianyu Zhang,Yu Liu,Xiaofei Zhou,Bolun Zheng*

Main category: cs.CV

TL;DR: 论文提出了一个包含天气噪声的显著目标检测数据集WXSOD，并设计了一个两分支网络WFANet，通过融合天气特征提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有显著目标检测方法在复杂天气条件下表现不佳，缺乏相关数据集和算法研究。

Method: 提出WXSOD数据集，包含合成和真实天气噪声图像；设计WFANet网络，通过天气预测分支和显著检测分支融合特征。

Result: WFANet在WXSOD数据集上优于17种现有方法。

Conclusion: WXSOD数据集和WFANet为复杂天气下的显著目标检测提供了有效解决方案。

Abstract: Salient object detection (SOD) in complex environments remains a challenging
research topic. Most existing methods perform well in natural scenes with
negligible noise, and tend to leverage multi-modal information (e.g., depth and
infrared) to enhance accuracy. However, few studies are concerned with the
damage of weather noise on SOD performance due to the lack of dataset with
pixel-wise annotations. To bridge this gap, this paper introduces a novel
Weather-eXtended Salient Object Detection (WXSOD) dataset. It consists of
14,945 RGB images with diverse weather noise, along with the corresponding
ground truth annotations and weather labels. To verify algorithm
generalization, WXSOD contains two test sets, i.e., a synthesized test set and
a real test set. The former is generated by adding weather noise to clean
images, while the latter contains real-world weather noise. Based on WXSOD, we
propose an efficient baseline, termed Weather-aware Feature Aggregation Network
(WFANet), which adopts a fully supervised two-branch architecture.
Specifically, the weather prediction branch mines weather-related deep
features, while the saliency detection branch fuses semantic features extracted
from the backbone with weather features for SOD. Comprehensive comparisons
against 17 SOD methods shows that our WFANet achieves superior performance on
WXSOD. The code and benchmark results will be made publicly available at
https://github.com/C-water/WXSOD

</details>


### [53] [Superpixel-informed Continuous Low-Rank Tensor Representation for Multi-Dimensional Data Recovery](https://arxiv.org/abs/2508.12261)
*Zhizhou Wang,Ruijing Zheng,Zhenyu Wu,Jianli Wang*

Main category: cs.CV

TL;DR: 提出了一种基于超像素的连续低秩张量表示（SCTR）框架，解决了传统低秩张量表示方法的局限性，提升了多维度数据处理的灵活性和性能。


<details>
  <summary>Details</summary>
Motivation: 传统低秩张量表示方法假设整体数据低秩且受限于离散网格数据，难以适应现实场景中的空间变化和连续数据需求。

Method: 采用超像素作为建模单元，提出非对称低秩张量分解（ALTF），通过共享神经网络参数化超像素特定因子矩阵，分离全局模式学习和局部适应。

Result: 在多个基准数据集上，SCTR比现有方法在峰值信噪比（PSNR）上提升了3-5 dB。

Conclusion: SCTR框架在多维度数据处理中表现出更高的表达能力和适应性，显著优于传统方法。

Abstract: Low-rank tensor representation (LRTR) has emerged as a powerful tool for
multi-dimensional data processing. However, classical LRTR-based methods face
two critical limitations: (1) they typically assume that the holistic data is
low-rank, this assumption is often violated in real-world scenarios with
significant spatial variations; and (2) they are constrained to discrete
meshgrid data, limiting their flexibility and applicability. To overcome these
limitations, we propose a Superpixel-informed Continuous low-rank Tensor
Representation (SCTR) framework, which enables continuous and flexible modeling
of multi-dimensional data beyond traditional grid-based constraints. Our
approach introduces two main innovations: First, motivated by the observation
that semantically coherent regions exhibit stronger low-rank characteristics
than holistic data, we employ superpixels as the basic modeling units. This
design not only encodes rich semantic information, but also enhances
adaptability to diverse forms of data streams. Second, we propose a novel
asymmetric low-rank tensor factorization (ALTF) where superpixel-specific
factor matrices are parameterized by a shared neural network with specialized
heads. By strategically separating global pattern learning from local
adaptation, this framework efficiently captures both cross-superpixel
commonalities and within-superpixel variations. This yields a representation
that is both highly expressive and compact, balancing model efficiency with
adaptability. Extensive experiments on several benchmark datasets demonstrate
that SCTR achieves 3-5 dB PSNR improvements over existing LRTR-based methods
across multispectral images, videos, and color images.

</details>


### [54] [Region-Level Context-Aware Multimodal Understanding](https://arxiv.org/abs/2508.12263)
*Hongliang Wei,Xianqi Zhang,Xingtao Wang,Xiaopeng Fan,Debin Zhao*

Main category: cs.CV

TL;DR: 论文提出了一种区域级上下文感知多模态理解（RCMU）任务，并通过RCVIT方法增强MLLMs的能力，同时构建了RCMU数据集和RC&P-Bench基准。实验表明，RC-Qwen2-VL模型在RCMU任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs研究主要关注通用视觉理解，缺乏对区域级文本上下文的多模态整合能力，因此需要解决这一局限性。

Method: 提出RCVIT方法，将对象信息融入模型输入，并利用边界框坐标关联视觉内容与文本信息；构建RCMU数据集和RC&P-Bench基准。

Result: RC-Qwen2-VL模型在RCMU任务中表现优异，并在多模态RAG和个性化对话中成功应用。

Conclusion: 通过RCVIT和RCMU数据集，成功提升了MLLMs的区域级上下文感知能力，为多模态理解提供了新方向。

Abstract: Despite significant progress, existing research on Multimodal Large Language
Models (MLLMs) mainly focuses on general visual understanding, overlooking the
ability to integrate textual context associated with objects for a more
context-aware multimodal understanding -- an ability we refer to as
Region-level Context-aware Multimodal Understanding (RCMU). To address this
limitation, we first formulate the RCMU task, which requires models to respond
to user instructions by integrating both image content and textual information
of regions or objects. To equip MLLMs with RCMU capabilities, we propose
Region-level Context-aware Visual Instruction Tuning (RCVIT), which
incorporates object information into the model input and enables the model to
utilize bounding box coordinates to effectively associate objects' visual
content with their textual information. To address the lack of datasets, we
introduce the RCMU dataset, a large-scale visual instruction tuning dataset
that covers multiple RCMU tasks. We also propose RC\&P-Bench, a comprehensive
benchmark that can evaluate the performance of MLLMs in RCMU and multimodal
personalized understanding tasks. Additionally, we propose a reference-free
evaluation metric to perform a comprehensive and fine-grained evaluation of the
region-level context-aware image descriptions. By performing RCVIT on Qwen2-VL
models with the RCMU dataset, we developed RC-Qwen2-VL models. Experimental
results indicate that RC-Qwen2-VL models not only achieve outstanding
performance on multiple RCMU tasks but also demonstrate successful applications
in multimodal RAG and personalized conversation. Our data, model and benchmark
are available at https://github.com/hongliang-wei/RC-MLLM

</details>


### [55] [SNNSIR: A Simple Spiking Neural Network for Stereo Image Restoration](https://arxiv.org/abs/2508.12271)
*Ronghua Xu,Jin Xie,Jing Nie,Jiale Cao,Yanwei Pang*

Main category: cs.CV

TL;DR: 提出了一种名为SNNSIR的脉冲神经网络，用于立体图像恢复，通过全脉冲驱动架构实现低功耗和硬件友好计算。


<details>
  <summary>Details</summary>
Motivation: 现有混合SNN-ANN模型仍依赖浮点运算，与SNN的二进制和事件驱动特性不兼容，因此设计完全脉冲驱动的SNN以提升效率和兼容性。

Method: 引入轻量级脉冲残差基本块（SRBB）增强信息流，通过脉冲立体卷积调制（SSCM）模块简化非线性，并利用脉冲立体交叉注意力（SSCA）模块改进立体对应关系。

Result: 在多种立体图像恢复任务中表现优异，显著降低计算开销，适合实时低功耗应用。

Conclusion: SNNSIR展示了脉冲神经网络在立体视觉应用中的潜力，为低功耗实时处理提供了可行方案。

Abstract: Spiking Neural Networks (SNNs), characterized by discrete binary activations,
offer high computational efficiency and low energy consumption, making them
well-suited for computation-intensive tasks such as stereo image restoration.
In this work, we propose SNNSIR, a simple yet effective Spiking Neural Network
for Stereo Image Restoration, specifically designed under the spike-driven
paradigm where neurons transmit information through sparse, event-based binary
spikes. In contrast to existing hybrid SNN-ANN models that still rely on
operations such as floating-point matrix division or exponentiation, which are
incompatible with the binary and event-driven nature of SNNs, our proposed
SNNSIR adopts a fully spike-driven architecture to achieve low-power and
hardware-friendly computation. To address the expressiveness limitations of
binary spiking neurons, we first introduce a lightweight Spike Residual Basic
Block (SRBB) to enhance information flow via spike-compatible residual
learning. Building on this, the Spike Stereo Convolutional Modulation (SSCM)
module introduces simplified nonlinearity through element-wise multiplication
and highlights noise-sensitive regions via cross-view-aware modulation.
Complementing this, the Spike Stereo Cross-Attention (SSCA) module further
improves stereo correspondence by enabling efficient bidirectional feature
interaction across views within a spike-compatible framework. Extensive
experiments on diverse stereo image restoration tasks, including rain streak
removal, raindrop removal, low-light enhancement, and super-resolution
demonstrate that our model achieves competitive restoration performance while
significantly reducing computational overhead. These results highlight the
potential for real-time, low-power stereo vision applications. The code will be
available after the article is accepted.

</details>


### [56] [TSLA: A Task-Specific Learning Adaptation for Semantic Segmentation on Autonomous Vehicles Platform](https://arxiv.org/abs/2508.12279)
*Jun Liu,Zhenglun Kong,Pu Zhao,Weihao Zeng,Hao Tang,Xuan Shen,Changdi Yang,Wenbin Zhang,Geng Yuan,Wei Niu,Xue Lin,Yanzhi Wang*

Main category: cs.CV

TL;DR: 提出了一种动态适应性的语义分割网络，通过三层控制机制和贝叶斯优化，优化自动驾驶硬件资源分配和性能。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶平台硬件资源有限，需根据计算能力和场景需求定制网络。

Method: 采用宽度乘数、分类器深度和分类器内核的三层控制机制，结合贝叶斯优化进行超参数搜索。

Result: 实现了针对不同任务的资源配置优化，提升了计算效率和模型精度。

Conclusion: 该方法有效适应自动驾驶的多样性和计算限制，优化了硬件利用和性能。

Abstract: Autonomous driving platforms encounter diverse driving scenarios, each with
varying hardware resources and precision requirements. Given the computational
limitations of embedded devices, it is crucial to consider computing costs when
deploying on target platforms like the NVIDIA\textsuperscript{\textregistered}
DRIVE PX 2. Our objective is to customize the semantic segmentation network
according to the computing power and specific scenarios of autonomous driving
hardware. We implement dynamic adaptability through a three-tier control
mechanism -- width multiplier, classifier depth, and classifier kernel --
allowing fine-grained control over model components based on hardware
constraints and task requirements. This adaptability facilitates broad model
scaling, targeted refinement of the final layers, and scenario-specific
optimization of kernel sizes, leading to improved resource allocation and
performance.
  Additionally, we leverage Bayesian Optimization with surrogate modeling to
efficiently explore hyperparameter spaces under tight computational budgets.
Our approach addresses scenario-specific and task-specific requirements through
automatic parameter search, accommodating the unique computational complexity
and accuracy needs of autonomous driving. It scales its Multiply-Accumulate
Operations (MACs) for Task-Specific Learning Adaptation (TSLA), resulting in
alternative configurations tailored to diverse self-driving tasks. These TSLA
customizations maximize computational capacity and model accuracy, optimizing
hardware utilization.

</details>


### [57] [CLAIR: CLIP-Aided Weakly Supervised Zero-Shot Cross-Domain Image Retrieval](https://arxiv.org/abs/2508.12290)
*Chor Boon Tan,Conghui Hu,Gim Hee Lee*

Main category: cs.CV

TL;DR: 本文提出CLAIR方法，通过改进CLIP生成的噪声伪标签，设计对比损失和跨域映射函数，提升弱监督零样本跨域图像检索性能。


<details>
  <summary>Details</summary>
Motivation: 大型基础模型能生成大量伪标签，使无监督零样本跨域图像检索（UZS-CDIR）不再重要，因此转向弱监督零样本跨域图像检索（WSZS-CDIR）。

Method: 提出CLAIR方法，包括：1) 用CLIP文本和图像特征的相似性改进伪标签；2) 设计类感知潜在空间的对比损失；3) 学习跨域映射函数；4) 引入可学习提示增强零样本泛化能力。

Result: 在多个数据集上，CLAIR表现优于现有方法。

Conclusion: CLAIR通过改进伪标签和设计新损失函数，显著提升了弱监督零样本跨域图像检索的性能。

Abstract: The recent growth of large foundation models that can easily generate
pseudo-labels for huge quantity of unlabeled data makes unsupervised Zero-Shot
Cross-Domain Image Retrieval (UZS-CDIR) less relevant. In this paper, we
therefore turn our attention to weakly supervised ZS-CDIR (WSZS-CDIR) with
noisy pseudo labels generated by large foundation models such as CLIP. To this
end, we propose CLAIR to refine the noisy pseudo-labels with a confidence score
from the similarity between the CLIP text and image features. Furthermore, we
design inter-instance and inter-cluster contrastive losses to encode images
into a class-aware latent space, and an inter-domain contrastive loss to
alleviate domain discrepancies. We also learn a novel cross-domain mapping
function in closed-form, using only CLIP text embeddings to project image
features from one domain to another, thereby further aligning the image
features for retrieval. Finally, we enhance the zero-shot generalization
ability of our CLAIR to handle novel categories by introducing an extra set of
learnable prompts. Extensive experiments are carried out using TUBerlin,
Sketchy, Quickdraw, and DomainNet zero-shot datasets, where our CLAIR
consistently shows superior performance compared to existing state-of-the-art
methods.

</details>


### [58] [Improving Densification in 3D Gaussian Splatting for High-Fidelity Rendering](https://arxiv.org/abs/2508.12313)
*Xiaobin Deng,Changyu Diao,Min Li,Ruohan Yu,Duanqing Xu*

Main category: cs.CV

TL;DR: 本文提出了一种改进3D高斯泼溅（3DGS）的致密化策略，通过边缘感知评分、长轴分割和抗过拟合技术，提升了重建质量和渲染保真度。


<details>
  <summary>Details</summary>
Motivation: 3DGS的致密化策略在实时渲染中表现优异，但重建质量常不理想，因此需要优化其致密化流程。

Method: 提出边缘感知评分选择候选高斯分布，长轴分割减少几何失真，以及抗过拟合技术（恢复感知剪枝、多步更新和生长控制）。

Result: 方法在不增加训练或推理开销的情况下，以更少的高斯分布实现了最先进的渲染质量。

Conclusion: 通过多角度优化致密化流程，显著提升了3DGS的重建和渲染性能。

Abstract: Although 3D Gaussian Splatting (3DGS) has achieved impressive performance in
real-time rendering, its densification strategy often results in suboptimal
reconstruction quality. In this work, we present a comprehensive improvement to
the densification pipeline of 3DGS from three perspectives: when to densify,
how to densify, and how to mitigate overfitting. Specifically, we propose an
Edge-Aware Score to effectively select candidate Gaussians for splitting. We
further introduce a Long-Axis Split strategy that reduces geometric distortions
introduced by clone and split operations. To address overfitting, we design a
set of techniques, including Recovery-Aware Pruning, Multi-step Update, and
Growth Control. Our method enhances rendering fidelity without introducing
additional training or inference overhead, achieving state-of-the-art
performance with fewer Gaussians.

</details>


### [59] [Neural Cellular Automata for Weakly Supervised Segmentation of White Blood Cells](https://arxiv.org/abs/2508.12322)
*Michael Deutges,Chen Yang,Raheleh Salehi,Nassir Navab,Carsten Marr,Ario Sadafi*

Main category: cs.CV

TL;DR: 提出了一种基于神经细胞自动机（NCA-WSS）的弱监督分割方法，用于白细胞检测和分割，无需分割标签即可生成分割掩码。


<details>
  <summary>Details</summary>
Motivation: 白细胞检测和分割在医学诊断中至关重要，但获取大量标注数据耗时且昂贵。

Method: 利用NCA在分类过程中生成的特征图提取分割掩码，无需重新训练。

Result: 在三个白细胞显微镜数据集上显著优于现有弱监督方法。

Conclusion: 展示了NCA在弱监督框架下分类和分割的潜力，为医学图像分析提供了可扩展且高效的解决方案。

Abstract: The detection and segmentation of white blood cells in blood smear images is
a key step in medical diagnostics, supporting various downstream tasks such as
automated blood cell counting, morphological analysis, cell classification, and
disease diagnosis and monitoring. Training robust and accurate models requires
large amounts of labeled data, which is both time-consuming and expensive to
acquire. In this work, we propose a novel approach for weakly supervised
segmentation using neural cellular automata (NCA-WSS). By leveraging the
feature maps generated by NCA during classification, we can extract
segmentation masks without the need for retraining with segmentation labels. We
evaluate our method on three white blood cell microscopy datasets and
demonstrate that NCA-WSS significantly outperforms existing weakly supervised
approaches. Our work illustrates the potential of NCA for both classification
and segmentation in a weakly supervised framework, providing a scalable and
efficient solution for medical image analysis.

</details>


### [60] [Attention Pooling Enhances NCA-based Classification of Microscopy Images](https://arxiv.org/abs/2508.12324)
*Chen Yang,Michael Deutges,Jingsong Liu,Han Li,Nassir Navab,Carsten Marr,Ario Sadafi*

Main category: cs.CV

TL;DR: 通过将注意力池化与神经细胞自动机（NCA）结合，提升了显微镜图像分类的性能，同时保持了模型的参数效率和可解释性。


<details>
  <summary>Details</summary>
Motivation: NCA在图像分类中具有鲁棒性和可解释性，但其性能与更复杂的架构相比仍有差距。

Method: 集成注意力池化机制，优化特征提取，专注于信息丰富的区域。

Result: 在八个显微镜图像数据集上显著优于现有NCA方法，且参数更少。

Conclusion: NCA模型有望成为可解释图像分类的替代方案。

Abstract: Neural Cellular Automata (NCA) offer a robust and interpretable approach to
image classification, making them a promising choice for microscopy image
analysis. However, a performance gap remains between NCA and larger, more
complex architectures. We address this challenge by integrating attention
pooling with NCA to enhance feature extraction and improve classification
accuracy. The attention pooling mechanism refines the focus on the most
informative regions, leading to more accurate predictions. We evaluate our
method on eight diverse microscopy image datasets and demonstrate that our
approach significantly outperforms existing NCA methods while remaining
parameter-efficient and explainable. Furthermore, we compare our method with
traditional lightweight convolutional neural network and vision transformer
architectures, showing improved performance while maintaining a significantly
lower parameter count. Our results highlight the potential of NCA-based models
an alternative for explainable image classification.

</details>


### [61] [DoppDrive: Doppler-Driven Temporal Aggregation for Improved Radar Object Detection](https://arxiv.org/abs/2508.12330)
*Yuval Haitman,Oded Bialer*

Main category: cs.CV

TL;DR: DoppDrive是一种基于多普勒效应的雷达点云密度增强方法，通过动态多普勒补偿减少散射，显著提升目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 雷达点云在远距离时稀疏性高，现有方法通过时间聚合增加密度但会引入动态物体的散射，影响检测精度。

Method: DoppDrive利用多普勒信息动态调整点云聚合，通过径向和切向散射最小化策略增强点云密度。

Result: 实验表明，DoppDrive显著提升了多种检测器和数据集上的目标检测性能。

Conclusion: DoppDrive是一种高效且通用的雷达点云增强方法，适用于自动驾驶中的目标检测任务。

Abstract: Radar-based object detection is essential for autonomous driving due to
radar's long detection range. However, the sparsity of radar point clouds,
especially at long range, poses challenges for accurate detection. Existing
methods increase point density through temporal aggregation with ego-motion
compensation, but this approach introduces scatter from dynamic objects,
degrading detection performance. We propose DoppDrive, a novel Doppler-Driven
temporal aggregation method that enhances radar point cloud density while
minimizing scatter. Points from previous frames are shifted radially according
to their dynamic Doppler component to eliminate radial scatter, with each point
assigned a unique aggregation duration based on its Doppler and angle to
minimize tangential scatter. DoppDrive is a point cloud density enhancement
step applied before detection, compatible with any detector, and we demonstrate
that it significantly improves object detection performance across various
detectors and datasets.

</details>


### [62] [Geometry-Aware Video Inpainting for Joint Headset Occlusion Removal and Face Reconstruction in Social XR](https://arxiv.org/abs/2508.12336)
*Fatemeh Ghorbani Lohesara,Karen Eguiazarian,Sebastian Knorr*

Main category: cs.CV

TL;DR: 提出了一种基于几何感知的学习框架，用于从单视角RGB帧中去除HMD遮挡并重建完整3D面部几何。


<details>
  <summary>Details</summary>
Motivation: HMD遮挡了用户上半部分面部，影响社交XR应用（如远程会议）中面部表情和眼神交流的沉浸感。

Method: 结合GAN视频修复网络和SynergyNet模块，通过密集面部标志点和无遮挡参考帧恢复缺失区域并重建3D面部。

Result: 实验表明框架能成功去除HMD遮挡，保持面部真实感和身份，生成逼真3D面部几何。

Conclusion: 该框架在稀疏标志点配置下仍保持鲁棒性，为社交XR应用提供了实用解决方案。

Abstract: Head-mounted displays (HMDs) are essential for experiencing extended reality
(XR) environments and observing virtual content. However, they obscure the
upper part of the user's face, complicating external video recording and
significantly impacting social XR applications such as teleconferencing, where
facial expressions and eye gaze details are crucial for creating an immersive
experience. This study introduces a geometry-aware learning-based framework to
jointly remove HMD occlusions and reconstruct complete 3D facial geometry from
RGB frames captured from a single viewpoint. The method integrates a GAN-based
video inpainting network, guided by dense facial landmarks and a single
occlusion-free reference frame, to restore missing facial regions while
preserving identity. Subsequently, a SynergyNet-based module regresses 3D
Morphable Model (3DMM) parameters from the inpainted frames, enabling accurate
3D face reconstruction. Dense landmark optimization is incorporated throughout
the pipeline to improve both the inpainting quality and the fidelity of the
recovered geometry. Experimental results demonstrate that the proposed
framework can successfully remove HMDs from RGB facial videos while maintaining
facial identity and realism, producing photorealistic 3D face geometry outputs.
Ablation studies further show that the framework remains robust across
different landmark densities, with only minor quality degradation under sparse
landmark configurations.

</details>


### [63] [Semantic Discrepancy-aware Detector for Image Forgery Identification](https://arxiv.org/abs/2508.12341)
*Ziye Wang,Minghang Yu,Chunyan Xu,Zhen Cui*

Main category: cs.CV

TL;DR: 提出了一种基于语义差异的伪造检测器（SDD），通过细粒度视觉对齐和语义概念增强，显著提升了伪造检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在伪造与语义概念空间的对齐上存在不足，影响了检测性能。

Method: 设计了语义标记采样模块和概念级伪造差异学习模块，通过重建学习对齐空间并增强伪造痕迹。

Result: 在两个标准数据集上表现优于现有方法。

Conclusion: SDD通过语义对齐和差异学习，有效提升了伪造检测的准确性和鲁棒性。

Abstract: With the rapid advancement of image generation techniques, robust forgery
detection has become increasingly imperative to ensure the trustworthiness of
digital media. Recent research indicates that the learned semantic concepts of
pre-trained models are critical for identifying fake images. However, the
misalignment between the forgery and semantic concept spaces hinders the
model's forgery detection performance. To address this problem, we propose a
novel Semantic Discrepancy-aware Detector (SDD) that leverages reconstruction
learning to align the two spaces at a fine-grained visual level. By exploiting
the conceptual knowledge embedded in the pre-trained vision language model, we
specifically design a semantic token sampling module to mitigate the space
shifts caused by features irrelevant to both forgery traces and semantic
concepts. A concept-level forgery discrepancy learning module, built upon a
visual reconstruction paradigm, is proposed to strengthen the interaction
between visual semantic concepts and forgery traces, effectively capturing
discrepancies under the concepts' guidance. Finally, the low-level forgery
feature enhancemer integrates the learned concept level forgery discrepancies
to minimize redundant forgery information. Experiments conducted on two
standard image forgery datasets demonstrate the efficacy of the proposed SDD,
which achieves superior results compared to existing methods. The code is
available at https://github.com/wzy1111111/SSD.

</details>


### [64] [AquaFeat: A Features-Based Image Enhancement Model for Underwater Object Detection](https://arxiv.org/abs/2508.12343)
*Emanuel C. Silva,Tatiana T. Schein,Stephanie L. Brião,Guilherme L. M. Costa,Felipe G. Oliveira,Gustavo P. Almeida,Eduardo L. Silva,Sam S. Devincenzi,Karina S. Machado,Paulo L. J. Drews-Jr*

Main category: cs.CV

TL;DR: AquaFeat是一种新型的即插即用模块，通过任务驱动的特征增强提升水下环境中的目标检测性能，结合YOLOv8m在多个指标上达到最优。


<details>
  <summary>Details</summary>
Motivation: 水下环境的图像退化严重影响了目标检测模型的性能，传统图像增强方法未针对此类下游任务优化。

Method: 提出多尺度特征增强网络，与检测器的损失函数端到端训练，确保增强过程明确优化检测任务相关特征。

Result: 在YOLOv8m上集成AquaFeat后，Precision（0.877）、Recall（0.624）和mAP（0.677@0.5，0.421@[0.5:0.95]）表现优异，处理速度为46.5 FPS。

Conclusion: AquaFeat为水下目标检测提供了高效且计算友好的解决方案，适用于海洋生态监测和基础设施检查等实际应用。

Abstract: The severe image degradation in underwater environments impairs object
detection models, as traditional image enhancement methods are often not
optimized for such downstream tasks. To address this, we propose AquaFeat, a
novel, plug-and-play module that performs task-driven feature enhancement. Our
approach integrates a multi-scale feature enhancement network trained
end-to-end with the detector's loss function, ensuring the enhancement process
is explicitly guided to refine features most relevant to the detection task.
When integrated with YOLOv8m on challenging underwater datasets, AquaFeat
achieves state-of-the-art Precision (0.877) and Recall (0.624), along with
competitive mAP scores (mAP@0.5 of 0.677 and mAP@[0.5:0.95] of 0.421). By
delivering these accuracy gains while maintaining a practical processing speed
of 46.5 FPS, our model provides an effective and computationally efficient
solution for real-world applications, such as marine ecosystem monitoring and
infrastructure inspection.

</details>


### [65] [MBMamba: When Memory Buffer Meets Mamba for Structure-Aware Image Deblurring](https://arxiv.org/abs/2508.12346)
*Hu Gao,Depeng Dang*

Main category: cs.CV

TL;DR: MBMamba提出了一种基于Mamba架构的图像去模糊方法，通过内存缓冲机制和Ising正则化损失，解决了局部像素遗忘和通道冗余问题，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: Mamba架构在图像去模糊中存在局部像素遗忘和通道冗余问题，现有改进方法增加了计算复杂度，影响实时性能。

Method: 设计了内存缓冲机制保留历史信息，并引入Ising正则化损失模拟像素间的物理吸引力，保持图像结构。

Result: 在多个基准测试中性能优于现有方法。

Conclusion: MBMamba在不改变Mamba架构的情况下，有效提升了图像去模糊的性能和效率。

Abstract: The Mamba architecture has emerged as a promising alternative to CNNs and
Transformers for image deblurring. However, its flatten-and-scan strategy often
results in local pixel forgetting and channel redundancy, limiting its ability
to effectively aggregate 2D spatial information. Although existing methods
mitigate this by modifying the scan strategy or incorporating local feature
modules, it increase computational complexity and hinder real-time performance.
In this paper, we propose a structure-aware image deblurring network without
changing the original Mamba architecture. Specifically, we design a memory
buffer mechanism to preserve historical information for later fusion, enabling
reliable modeling of relevance between adjacent features. Additionally, we
introduce an Ising-inspired regularization loss that simulates the energy
minimization of the physical system's "mutual attraction" between pixels,
helping to maintain image structure and coherence. Building on this, we develop
MBMamba. Experimental results show that our method outperforms state-of-the-art
approaches on widely used benchmarks.

</details>


### [66] [EgoLoc: A Generalizable Solution for Temporal Interaction Localization in Egocentric Videos](https://arxiv.org/abs/2508.12349)
*Junyi Ma,Erhang Zhang,Yin-Dong Zheng,Yuchen Xie,Yixuan Zhou,Hesheng Wang*

Main category: cs.CV

TL;DR: 论文提出了一种零样本方法EgoLoc，用于定位第一人称视频中手与物体的接触和分离时刻，解决了现有方法在对象定位和时序精度上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注交互行为的建模（“如何交互”），而忽略了更细粒度的接触和分离时刻的定位（“何时交互”），这对混合现实和机器人运动规划至关重要。

Method: 提出EgoLoc方法，通过手部动态引导采样生成高质量视觉提示，利用视觉语言模型识别接触/分离属性并定位具体时间点，无需对象掩码和动作分类标注。

Result: 在公开数据集和新基准测试中，EgoLoc实现了有效的时序交互定位，并在下游应用中验证了其有效性。

Conclusion: EgoLoc是一种通用的零样本方法，能够精确定位手与物体的交互时刻，适用于第一人称视觉和机器人任务。

Abstract: Analyzing hand-object interaction in egocentric vision facilitates VR/AR
applications and human-robot policy transfer. Existing research has mostly
focused on modeling the behavior paradigm of interactive actions (i.e., ``how
to interact''). However, the more challenging and fine-grained problem of
capturing the critical moments of contact and separation between the hand and
the target object (i.e., ``when to interact'') is still underexplored, which is
crucial for immersive interactive experiences in mixed reality and robotic
motion planning. Therefore, we formulate this problem as temporal interaction
localization (TIL). Some recent works extract semantic masks as TIL references,
but suffer from inaccurate object grounding and cluttered scenarios. Although
current temporal action localization (TAL) methods perform well in detecting
verb-noun action segments, they rely on category annotations during training
and exhibit limited precision in localizing hand-object contact/separation
moments. To address these issues, we propose a novel zero-shot approach dubbed
EgoLoc to localize hand-object contact and separation timestamps in egocentric
videos. EgoLoc introduces hand-dynamics-guided sampling to generate
high-quality visual prompts. It exploits the vision-language model to identify
contact/separation attributes, localize specific timestamps, and provide
closed-loop feedback for further refinement. EgoLoc eliminates the need for
object masks and verb-noun taxonomies, leading to generalizable zero-shot
implementation. Comprehensive experiments on the public dataset and our novel
benchmarks demonstrate that EgoLoc achieves plausible TIL for egocentric
videos. It is also validated to effectively facilitate multiple downstream
applications in egocentric vision and robotic manipulation tasks. Code and
relevant data will be released at https://github.com/IRMVLab/EgoLoc.

</details>


### [67] [Synthetic Data is Sufficient for Zero-Shot Visual Generalization from Offline Data](https://arxiv.org/abs/2508.12356)
*Ahmet H. Güzel,Ilija Bogunovic,Jack Parker-Holder*

Main category: cs.CV

TL;DR: 提出一种通过生成合成数据增强离线强化学习泛化能力的方法。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习在视觉数据中面临泛化能力不足和过拟合问题，需要更多样化的训练数据。

Method: 采用两步法：先增强原始数据以增加多样性，再用扩散模型在潜在空间生成额外数据。

Result: 在连续和离散动作空间测试中显著提升泛化能力，且无需修改现有算法。

Conclusion: 该方法能有效提升数据多样性并减少泛化差距，有望推动未来合成数据生成的研究。

Abstract: Offline reinforcement learning (RL) offers a promising framework for training
agents using pre-collected datasets without the need for further environment
interaction. However, policies trained on offline data often struggle to
generalise due to limited exposure to diverse states. The complexity of visual
data introduces additional challenges such as noise, distractions, and spurious
correlations, which can misguide the policy and increase the risk of
overfitting if the training data is not sufficiently diverse. Indeed, this
makes it challenging to leverage vision-based offline data in training robust
agents that can generalize to unseen environments. To solve this problem, we
propose a simple approach generating additional synthetic training data. We
propose a two-step process, first augmenting the originally collected offline
data to improve zero-shot generalization by introducing diversity, then using a
diffusion model to generate additional data in latent space. We test our method
across both continuous action spaces (Visual D4RL) and discrete action spaces
(Procgen), demonstrating that it significantly improves generalization without
requiring any algorithmic changes to existing model-free offline RL methods. We
show that our method not only increases the diversity of the training data but
also significantly reduces the generalization gap at test time while
maintaining computational efficiency. We believe this approach could fuel
additional progress in generating synthetic data to train more general agents
in the future.

</details>


### [68] [IPGPhormer: Interpretable Pathology Graph-Transformer for Survival Analysis](https://arxiv.org/abs/2508.12381)
*Guo Tang,Songhan Jiang,Jinpeng Lu,Linghan Cai,Yongbing Zhang*

Main category: cs.CV

TL;DR: IPGPhormer是一种新型框架，通过图-Transformer结合技术提升病理图像生存分析的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在平衡长距离空间关系和局部上下文依赖方面表现不足，且缺乏可解释性，限制了临床实用性。

Method: 提出IPGPhormer框架，捕捉肿瘤微环境特征并建模其空间依赖关系，无需后处理标注即可实现组织和细胞级别的可解释性。

Result: 在四个公共数据集上，IPGPhormer在预测准确性和可解释性上均优于现有方法。

Conclusion: IPGPhormer为癌症预后评估提供了可靠且可解释的工具，推动了病理学决策支持系统的发展。

Abstract: Pathological images play an essential role in cancer prognosis, while
survival analysis, which integrates computational techniques, can predict
critical clinical events such as patient mortality or disease recurrence from
whole-slide images (WSIs). Recent advancements in multiple instance learning
have significantly improved the efficiency of survival analysis. However,
existing methods often struggle to balance the modeling of long-range spatial
relationships with local contextual dependencies and typically lack inherent
interpretability, limiting their clinical utility. To address these challenges,
we propose the Interpretable Pathology Graph-Transformer (IPGPhormer), a novel
framework that captures the characteristics of the tumor microenvironment and
models their spatial dependencies across the tissue. IPGPhormer uniquely
provides interpretability at both tissue and cellular levels without requiring
post-hoc manual annotations, enabling detailed analyses of individual WSIs and
cross-cohort assessments. Comprehensive evaluations on four public benchmark
datasets demonstrate that IPGPhormer outperforms state-of-the-art methods in
both predictive accuracy and interpretability. In summary, our method,
IPGPhormer, offers a promising tool for cancer prognosis assessment, paving the
way for more reliable and interpretable decision-support systems in pathology.
The code is publicly available at
https://anonymous.4open.science/r/IPGPhormer-6EEB.

</details>


### [69] [ViT-EnsembleAttack: Augmenting Ensemble Models for Stronger Adversarial Transferability in Vision Transformers](https://arxiv.org/abs/2508.12384)
*Hanwen Cao,Haobo Lu,Xiaosen Wang,Kun He*

Main category: cs.CV

TL;DR: 提出ViT-EnsembleAttack方法，通过对抗性增强ViT模型提升对抗样本的迁移性。


<details>
  <summary>Details</summary>
Motivation: 现有研究忽视通过增强集成模型提升对抗迁移性，且ViT集成攻击研究不足。

Method: 采用多策略（多头丢弃、注意力分数缩放、MLP特征混合）增强ViT模型，并结合贝叶斯优化和自动重加权模块。

Result: 实验表明ViT-EnsembleAttack显著优于现有方法。

Conclusion: 该方法有效提升ViT集成攻击的迁移性，填补了研究空白。

Abstract: Ensemble-based attacks have been proven to be effective in enhancing
adversarial transferability by aggregating the outputs of models with various
architectures. However, existing research primarily focuses on refining
ensemble weights or optimizing the ensemble path, overlooking the exploration
of ensemble models to enhance the transferability of adversarial attacks. To
address this gap, we propose applying adversarial augmentation to the surrogate
models, aiming to boost overall generalization of ensemble models and reduce
the risk of adversarial overfitting. Meanwhile, observing that ensemble Vision
Transformers (ViTs) gain less attention, we propose ViT-EnsembleAttack based on
the idea of model adversarial augmentation, the first ensemble-based attack
method tailored for ViTs to the best of our knowledge. Our approach generates
augmented models for each surrogate ViT using three strategies: Multi-head
dropping, Attention score scaling, and MLP feature mixing, with the associated
parameters optimized by Bayesian optimization. These adversarially augmented
models are ensembled to generate adversarial examples. Furthermore, we
introduce Automatic Reweighting and Step Size Enlargement modules to boost
transferability. Extensive experiments demonstrate that ViT-EnsembleAttack
significantly enhances the adversarial transferability of ensemble-based
attacks on ViTs, outperforming existing methods by a substantial margin. Code
is available at https://github.com/Trustworthy-AI-Group/TransferAttack.

</details>


### [70] [DeCoT: Decomposing Complex Instructions for Enhanced Text-to-Image Generation with Large Language Models](https://arxiv.org/abs/2508.12396)
*Xiaochuan Lin,Xiangyong Chen,Xuan Li,Yichen Su*

Main category: cs.CV

TL;DR: DeCoT框架通过分解复杂指令和语义增强，显著提升T2I模型对复杂文本的理解和生成能力。


<details>
  <summary>Details</summary>
Motivation: 当前T2I模型在处理复杂长文本指令时表现不佳，无法准确生成细节和空间关系。

Method: DeCoT分两阶段：1) 分解复杂指令并增强语义；2) 将语义单元转化为适合T2I模型的提示。

Result: 在LongBench-T2I数据集上，DeCoT显著提升模型性能，平均得分3.52（基线3.44）。

Conclusion: DeCoT有效弥合用户意图与T2I模型需求，提升生成图像的准确性和忠实度。

Abstract: Despite remarkable advancements, current Text-to-Image (T2I) models struggle
with complex, long-form textual instructions, frequently failing to accurately
render intricate details, spatial relationships, or specific constraints. This
limitation is highlighted by benchmarks such as LongBench-T2I, which reveal
deficiencies in handling composition, specific text, and fine textures. To
address this, we propose DeCoT (Decomposition-CoT), a novel framework that
leverages Large Language Models (LLMs) to significantly enhance T2I models'
understanding and execution of complex instructions. DeCoT operates in two core
stages: first, Complex Instruction Decomposition and Semantic Enhancement,
where an LLM breaks down raw instructions into structured, actionable semantic
units and clarifies ambiguities; second, Multi-Stage Prompt Integration and
Adaptive Generation, which transforms these units into a hierarchical or
optimized single prompt tailored for existing T2I models. Extensive experiments
on the LongBench-T2I dataset demonstrate that DeCoT consistently and
substantially improves the performance of leading T2I models across all
evaluated dimensions, particularly in challenging aspects like "Text" and
"Composition". Quantitative results, validated by multiple MLLM evaluators
(Gemini-2.0-Flash and InternVL3-78B), show that DeCoT, when integrated with
Infinity-8B, achieves an average score of 3.52, outperforming the baseline
Infinity-8B (3.44). Ablation studies confirm the critical contribution of each
DeCoT component and the importance of sophisticated LLM prompting. Furthermore,
human evaluations corroborate these findings, indicating superior perceptual
quality and instruction fidelity. DeCoT effectively bridges the gap between
high-level user intent and T2I model requirements, leading to more faithful and
accurate image generation.

</details>


### [71] [Federated Cross-Modal Style-Aware Prompt Generation](https://arxiv.org/abs/2508.12399)
*Suraj Prasad,Navyansh Mahla,Sunny Gupta,Amit Sethi*

Main category: cs.CV

TL;DR: FedCSAP是一种联邦学习框架，通过多尺度视觉特征和客户端特定风格生成上下文感知的提示词，提升CLIP模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统方法仅依赖最终层特征，忽略了多尺度视觉线索和客户端数据的风格差异，FedCSAP旨在解决这一问题。

Method: 利用CLIP视觉编码器的低、中、高层特征及客户端风格指标，生成非冗余的上下文感知提示词。

Result: 在多个图像分类数据集上，FedCSAP在准确性和泛化能力上优于现有联邦提示学习方法。

Conclusion: FedCSAP通过结合多尺度特征和风格信息，显著提升了联邦学习中的模型性能。

Abstract: Prompt learning has propelled vision-language models like CLIP to excel in
diverse tasks, making them ideal for federated learning due to computational
efficiency. However, conventional approaches that rely solely on final-layer
features miss out on rich multi-scale visual cues and domain-specific style
variations in decentralized client data. To bridge this gap, we introduce
FedCSAP (Federated Cross-Modal Style-Aware Prompt Generation). Our framework
harnesses low, mid, and high-level features from CLIP's vision encoder
alongside client-specific style indicators derived from batch-level statistics.
By merging intricate visual details with textual context, FedCSAP produces
robust, context-aware prompt tokens that are both distinct and non-redundant,
thereby boosting generalization across seen and unseen classes. Operating
within a federated learning paradigm, our approach ensures data privacy through
local training and global aggregation, adeptly handling non-IID class
distributions and diverse domain-specific styles. Comprehensive experiments on
multiple image classification datasets confirm that FedCSAP outperforms
existing federated prompt learning methods in both accuracy and overall
generalization.

</details>


### [72] [MPCAR: Multi-Perspective Contextual Augmentation for Enhanced Visual Reasoning in Large Vision-Language Models](https://arxiv.org/abs/2508.12400)
*Amirul Rahman,Qiang Xu,Xueying Huang*

Main category: cs.CV

TL;DR: MPCAR通过多视角上下文增强推理策略，提升大型视觉语言模型在复杂视觉推理任务中的表现，无需微调模型参数。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂视觉推理任务中表现有限，MPCAR旨在通过多角度分析和上下文增强来提升性能。

Method: MPCAR分三阶段：生成多样描述、整合上下文、生成最终答案。

Result: 在多个VQA数据集上显著提升准确率，尤其在需要深度上下文理解的任务中。

Conclusion: MPCAR展示了利用模型生成能力增强输入的潜力，解锁复杂多模态任务的推理能力。

Abstract: Despite significant advancements, Large Vision-Language Models (LVLMs)
continue to face challenges in complex visual reasoning tasks that demand deep
contextual understanding, multi-angle analysis, or meticulous detail
recognition. Existing approaches often rely on single-shot image encoding and
prompts, limiting their ability to fully capture nuanced visual information.
Inspired by the notion that strategically generated "additional" information
can serve as beneficial contextual augmentation, we propose Multi-Perspective
Contextual Augmentation for Reasoning (MPCAR), a novel inference-time strategy
designed to enhance LVLM performance. MPCAR operates in three stages: first, an
LVLM generates N diverse and complementary descriptions or preliminary
reasoning paths from various angles; second, these descriptions are
intelligently integrated with the original question to construct a
comprehensive context-augmented prompt; and finally, this enriched prompt
guides the ultimate LVLM for deep reasoning and final answer generation.
Crucially, MPCAR achieves these enhancements without requiring any fine-tuning
of the underlying LVLM's parameters. Extensive experiments on challenging
Visual Question Answering (VQA) datasets, including GQA, VQA-CP v2, and
ScienceQA (Image-VQA), demonstrate that MPCAR consistently outperforms
established baseline methods. Our quantitative results show significant
accuracy gains, particularly on tasks requiring robust contextual
understanding, while human evaluations confirm improved coherence and
completeness of the generated answers. Ablation studies further highlight the
importance of diverse prompt templates and the number of generated
perspectives. This work underscores the efficacy of leveraging LVLMs' inherent
generative capabilities to enrich input contexts, thereby unlocking their
latent reasoning potential for complex multimodal tasks.

</details>


### [73] [LMAD: Integrated End-to-End Vision-Language Model for Explainable Autonomous Driving](https://arxiv.org/abs/2508.12404)
*Nan Song,Bozhou Zhang,Xiatian Zhu,Jiankang Deng,Li Zhang*

Main category: cs.CV

TL;DR: LMAD是一种专为自动驾驶设计的新型视觉语言框架，通过综合场景理解和任务专用结构提升现有VLM的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在自动驾驶中缺乏全面和细致的场景识别及强大的空间感知能力，尤其是在复杂情况下。

Method: LMAD结合了初步场景交互和专用专家适配器，以更好地将VLM与自动驾驶场景对齐。

Result: 在DriveLM和nuScenes-QA数据集上的实验表明，LMAD显著提升了现有VLM在驾驶推理任务中的性能。

Conclusion: LMAD为可解释自动驾驶设定了新标准，并与规划导向的驾驶系统无缝集成。

Abstract: Large vision-language models (VLMs) have shown promising capabilities in
scene understanding, enhancing the explainability of driving behaviors and
interactivity with users. Existing methods primarily fine-tune VLMs on on-board
multi-view images and scene reasoning text, but this approach often lacks the
holistic and nuanced scene recognition and powerful spatial awareness required
for autonomous driving, especially in complex situations. To address this gap,
we propose a novel vision-language framework tailored for autonomous driving,
called LMAD. Our framework emulates modern end-to-end driving paradigms by
incorporating comprehensive scene understanding and a task-specialized
structure with VLMs. In particular, we introduce preliminary scene interaction
and specialized expert adapters within the same driving task structure, which
better align VLMs with autonomous driving scenarios. Furthermore, our approach
is designed to be fully compatible with existing VLMs while seamlessly
integrating with planning-oriented driving systems. Extensive experiments on
the DriveLM and nuScenes-QA datasets demonstrate that LMAD significantly boosts
the performance of existing VLMs on driving reasoning tasks,setting a new
standard in explainable autonomous driving.

</details>


### [74] [S5: Scalable Semi-Supervised Semantic Segmentation in Remote Sensing](https://arxiv.org/abs/2508.12409)
*Liang Lv,Di Wang,Jing Zhang,Lefei Zhang*

Main category: cs.CV

TL;DR: S5是一个可扩展的半监督语义分割框架，利用大规模遥感数据和数据选择策略提升模型性能，并在多个基准测试中达到最优。


<details>
  <summary>Details</summary>
Motivation: 解决现有半监督语义分割方法依赖小规模数据集和模型的问题，充分利用未标记的遥感数据。

Method: 提出数据选择策略（熵过滤和多样性扩展）构建RS4P-1M数据集，预训练不同规模的RSFMs，并采用MoE多数据集微调方法。

Result: RSFMs在土地覆盖分割和目标检测任务中表现优异，达到SOTA性能。

Conclusion: S5证明了半监督学习在遥感应用中的可扩展性和有效性，相关资源将开源。

Abstract: Semi-supervised semantic segmentation (S4) has advanced remote sensing (RS)
analysis by leveraging unlabeled data through pseudo-labeling and consistency
learning. However, existing S4 studies often rely on small-scale datasets and
models, limiting their practical applicability. To address this, we propose S5,
the first scalable framework for semi-supervised semantic segmentation in RS,
which unlocks the potential of vast unlabeled Earth observation data typically
underutilized due to costly pixel-level annotations. Built upon existing
large-scale RS datasets, S5 introduces a data selection strategy that
integrates entropy-based filtering and diversity expansion, resulting in the
RS4P-1M dataset. Using this dataset, we systematically scales S4 methods by
pre-training RS foundation models (RSFMs) of varying sizes on this extensive
corpus, significantly boosting their performance on land cover segmentation and
object detection tasks. Furthermore, during fine-tuning, we incorporate a
Mixture-of-Experts (MoE)-based multi-dataset fine-tuning approach, which
enables efficient adaptation to multiple RS benchmarks with fewer parameters.
This approach improves the generalization and versatility of RSFMs across
diverse RS benchmarks. The resulting RSFMs achieve state-of-the-art performance
across all benchmarks, underscoring the viability of scaling semi-supervised
learning for RS applications. All datasets, code, and models will be released
at https://github.com/MiliLab/S5

</details>


### [75] [SRMA-Mamba: Spatial Reverse Mamba Attention Network for Pathological Liver Segmentation in MRI Volumes](https://arxiv.org/abs/2508.12410)
*Jun Zeng,Yannan Huang,Elif Keles,Halil Ertugrul Aktas,Gorkem Durak,Nikhil Kumar Tomar,Quoc-Huy Trinh,Deepak Ranjan Nayak,Ulas Bagci,Debesh Jha*

Main category: cs.CV

TL;DR: SRMA-Mamba是一种基于Mamba的网络，用于MRI体积中肝硬化组织的空间关系建模和分割，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 肝硬化早期检测对降低死亡率至关重要，但现有方法未能充分利用MRI数据的空间解剖细节。

Method: 提出SRMA-Mamba网络，结合SABMamba模块和SRMA模块，通过多平面解剖信息建模和反向注意力机制优化分割。

Result: 实验表明SRMA-Mamba在3D病理肝脏分割中表现优异，超越现有方法。

Conclusion: SRMA-Mamba通过空间建模和注意力机制显著提升了肝硬化分割的准确性和可解释性。

Abstract: Liver Cirrhosis plays a critical role in the prognosis of chronic liver
disease. Early detection and timely intervention are critical in significantly
reducing mortality rates. However, the intricate anatomical architecture and
diverse pathological changes of liver tissue complicate the accurate detection
and characterization of lesions in clinical settings. Existing methods
underutilize the spatial anatomical details in volumetric MRI data, thereby
hindering their clinical effectiveness and explainability. To address this
challenge, we introduce a novel Mamba-based network, SRMA-Mamba, designed to
model the spatial relationships within the complex anatomical structures of MRI
volumes. By integrating the Spatial Anatomy-Based Mamba module (SABMamba),
SRMA-Mamba performs selective Mamba scans within liver cirrhotic tissues and
combines anatomical information from the sagittal, coronal, and axial planes to
construct a global spatial context representation, enabling efficient
volumetric segmentation of pathological liver structures. Furthermore, we
introduce the Spatial Reverse Attention module (SRMA), designed to
progressively refine cirrhotic details in the segmentation map, utilizing both
the coarse segmentation map and hierarchical encoding features. Extensive
experiments demonstrate that SRMA-Mamba surpasses state-of-the-art methods,
delivering exceptional performance in 3D pathological liver segmentation. Our
code is available for public:
{\color{blue}{https://github.com/JunZengz/SRMA-Mamba}}.

</details>


### [76] [TiP4GEN: Text to Immersive Panorama 4D Scene Generation](https://arxiv.org/abs/2508.12415)
*Ke Xing,Hanwen Liang,Dejia Xu,Yuyang Yin,Konstantinos N. Plataniotis,Yao Zhao,Yunchao Wei*

Main category: cs.CV

TL;DR: TiP4GEN是一个文本到动态全景场景生成的先进框架，支持细粒度内容控制和生成运动丰富的4D全景场景。


<details>
  <summary>Details</summary>
Motivation: 现有生成工作主要集中于静态场景或窄视角动态场景，无法提供真正的360度沉浸式体验。

Method: TiP4GEN结合全景视频生成和动态场景重建，采用双分支生成模型和几何对齐重建模型。

Result: 实验证明TiP4GEN能生成视觉吸引且运动连贯的动态全景场景。

Conclusion: TiP4GEN在生成高质量沉浸式动态场景方面表现出色。

Abstract: With the rapid advancement and widespread adoption of VR/AR technologies,
there is a growing demand for the creation of high-quality, immersive dynamic
scenes. However, existing generation works predominantly concentrate on the
creation of static scenes or narrow perspective-view dynamic scenes, falling
short of delivering a truly 360-degree immersive experience from any viewpoint.
In this paper, we introduce \textbf{TiP4GEN}, an advanced text-to-dynamic
panorama scene generation framework that enables fine-grained content control
and synthesizes motion-rich, geometry-consistent panoramic 4D scenes. TiP4GEN
integrates panorama video generation and dynamic scene reconstruction to create
360-degree immersive virtual environments. For video generation, we introduce a
\textbf{Dual-branch Generation Model} consisting of a panorama branch and a
perspective branch, responsible for global and local view generation,
respectively. A bidirectional cross-attention mechanism facilitates
comprehensive information exchange between the branches. For scene
reconstruction, we propose a \textbf{Geometry-aligned Reconstruction Model}
based on 3D Gaussian Splatting. By aligning spatial-temporal point clouds using
metric depth maps and initializing scene cameras with estimated poses, our
method ensures geometric consistency and temporal coherence for the
reconstructed scenes. Extensive experiments demonstrate the effectiveness of
our proposed designs and the superiority of TiP4GEN in generating visually
compelling and motion-coherent dynamic panoramic scenes. Our project page is at
https://ke-xing.github.io/TiP4GEN/.

</details>


### [77] [Illusions in Humans and AI: How Visual Perception Aligns and Diverges](https://arxiv.org/abs/2508.12422)
*Jianyi Yang,Junyi Ye,Ankan Dash,Guiling Wang*

Main category: cs.CV

TL;DR: 通过比较生物和人工感知系统在视觉错觉中的表现，揭示了它们在构建视觉现实时的关键差异，为开发更鲁棒、可解释且与人类对齐的AI视觉系统提供指导。


<details>
  <summary>Details</summary>
Motivation: 理解生物与人工感知系统在视觉错觉中的差异，有助于开发更符合人类需求的AI视觉系统。

Method: 通过分析AI对经典视觉错觉（如颜色、大小、形状和运动）的反应，探索其是否产生类似人类的错觉或独特的AI错觉。

Result: 发现AI可能产生类似人类的错觉效应，但也存在独特的AI错觉（如像素级敏感性和幻觉），揭示了与人类感知的对齐差距和AI特有的感知漏洞。

Conclusion: 研究结果为未来开发既能保留人类有益感知偏差，又能避免破坏信任和安全性的AI视觉系统提供了重要见解。

Abstract: By comparing biological and artificial perception through the lens of
illusions, we highlight critical differences in how each system constructs
visual reality. Understanding these divergences can inform the development of
more robust, interpretable, and human-aligned artificial intelligence (AI)
vision systems. In particular, visual illusions expose how human perception is
based on contextual assumptions rather than raw sensory data. As artificial
vision systems increasingly perform human-like tasks, it is important to ask:
does AI experience illusions, too? Does it have unique illusions? This article
explores how AI responds to classic visual illusions that involve color, size,
shape, and motion. We find that some illusion-like effects can emerge in these
models, either through targeted training or as by-products of pattern
recognition. In contrast, we also identify illusions unique to AI, such as
pixel-level sensitivity and hallucinations, that lack human counterparts. By
systematically comparing human and AI responses to visual illusions, we uncover
alignment gaps and AI-specific perceptual vulnerabilities invisible to human
perception. These findings provide insights for future research on vision
systems that preserve human-beneficial perceptual biases while avoiding
distortions that undermine trust and safety.

</details>


### [78] [Adversarial Attacks on VQA-NLE: Exposing and Alleviating Inconsistencies in Visual Question Answering Explanations](https://arxiv.org/abs/2508.12430)
*Yahsin Yeh,Yilun Wu,Bokai Ruan,Honghan Shuai*

Main category: cs.CV

TL;DR: 论文指出现有VQA-NLE系统存在解释不一致和结论不可靠的问题，提出新的对抗攻击和知识驱动的缓解方法。


<details>
  <summary>Details</summary>
Motivation: 揭示现有VQA-NLE系统的脆弱性，提升其透明度和可靠性。

Method: 结合对抗攻击（扰动问题和图像）和外部知识驱动的缓解方法。

Result: 在标准基准测试中验证了攻击的有效性和防御的潜力。

Conclusion: 当前VQA-NLE系统存在安全和可靠性问题，知识驱动方法可提升鲁棒性。

Abstract: Natural language explanations in visual question answering (VQA-NLE) aim to
make black-box models more transparent by elucidating their decision-making
processes. However, we find that existing VQA-NLE systems can produce
inconsistent explanations and reach conclusions without genuinely understanding
the underlying context, exposing weaknesses in either their inference pipeline
or explanation-generation mechanism. To highlight these vulnerabilities, we not
only leverage an existing adversarial strategy to perturb questions but also
propose a novel strategy that minimally alters images to induce contradictory
or spurious outputs. We further introduce a mitigation method that leverages
external knowledge to alleviate these inconsistencies, thereby bolstering model
robustness. Extensive evaluations on two standard benchmarks and two widely
used VQA-NLE models underscore the effectiveness of our attacks and the
potential of knowledge-based defenses, ultimately revealing pressing security
and reliability concerns in current VQA-NLE systems.

</details>


### [79] [X-Ray-CoT: Interpretable Chest X-ray Diagnosis with Vision-Language Models via Chain-of-Thought Reasoning](https://arxiv.org/abs/2508.12455)
*Chee Ng,Liliang Sun,Shaoqing Tang*

Main category: cs.CV

TL;DR: X-Ray-CoT框架利用视觉语言大模型进行智能胸片诊断和可解释报告生成，模拟放射科医生的思维链，性能优于现有黑盒模型。


<details>
  <summary>Details</summary>
Motivation: 解决胸片诊断中临床经验需求高和观察者间差异大的问题，同时提升深度学习模型的可解释性。

Method: 通过多模态特征提取和视觉概念识别，结合基于LLM的思维链推理生成详细诊断报告。

Result: 在CORDA数据集上，平衡准确率达80.52%，F1分数78.65%，并能生成高质量可解释报告。

Conclusion: X-Ray-CoT是迈向可信赖且临床可操作医疗AI的重要一步。

Abstract: Chest X-ray imaging is crucial for diagnosing pulmonary and cardiac diseases,
yet its interpretation demands extensive clinical experience and suffers from
inter-observer variability. While deep learning models offer high diagnostic
accuracy, their black-box nature hinders clinical adoption in high-stakes
medical settings. To address this, we propose X-Ray-CoT (Chest X-Ray
Chain-of-Thought), a novel framework leveraging Vision-Language Large Models
(LVLMs) for intelligent chest X-ray diagnosis and interpretable report
generation. X-Ray-CoT simulates human radiologists' "chain-of-thought" by first
extracting multi-modal features and visual concepts, then employing an
LLM-based component with a structured Chain-of-Thought prompting strategy to
reason and produce detailed natural language diagnostic reports. Evaluated on
the CORDA dataset, X-Ray-CoT achieves competitive quantitative performance,
with a Balanced Accuracy of 80.52% and F1 score of 78.65% for disease
diagnosis, slightly surpassing existing black-box models. Crucially, it
uniquely generates high-quality, explainable reports, as validated by
preliminary human evaluations. Our ablation studies confirm the integral role
of each proposed component, highlighting the necessity of multi-modal fusion
and CoT reasoning for robust and transparent medical AI. This work represents a
significant step towards trustworthy and clinically actionable AI systems in
medical imaging.

</details>


### [80] [Inverse-LLaVA: Eliminating Alignment Pre-training Through Text-to-Vision Mapping](https://arxiv.org/abs/2508.12466)
*Xuhui Zhan,Tyler Derr*

Main category: cs.CV

TL;DR: Inverse-LLaVA提出了一种无需对齐预训练的多模态学习方法，通过将文本嵌入映射到视觉空间，动态融合视觉和文本表示。


<details>
  <summary>Details</summary>
Motivation: 挑战传统多模态学习中对齐预训练的必要性，探索更高效的多模态融合方法。

Method: 通过逆向映射文本嵌入到视觉空间，在Transformer中间层进行动态融合，减少计算需求。

Result: 在推理密集型任务上表现优异（如认知推理+27.2%），但在感知任务上有所下降（如OCR-21.3%）。

Conclusion: 证明了对齐预训练并非必要，为高效多模态架构开辟了新方向。

Abstract: Traditional multimodal learning approaches require expensive alignment
pre-training to bridge vision and language modalities, typically projecting
visual features into discrete text token spaces. We challenge both fundamental
assumptions underlying this paradigm by proposing Inverse-LLaVA, a novel
approach that eliminates alignment pre-training entirely while inverting the
conventional mapping direction. Rather than projecting visual features to text
space, our method maps text embeddings into continuous visual representation
space and performs fusion within transformer intermediate layers. Through
selective additive components in attention mechanisms, we enable dynamic
integration of visual and textual representations without requiring massive
image-text alignment datasets. Comprehensive experiments across nine multimodal
benchmarks demonstrate nuanced performance trade-offs: Inverse-LLaVA achieves
notable improvements on reasoning-intensive and cognitive tasks (MM-VET: +0.2%,
VizWiz: +1.8%, ScienceQA: +0.2%, cognitive reasoning: +27.2%), while showing
expected decreases in perception tasks requiring memorized visual-text
associations (celebrity recognition: -49.5%, OCR: -21.3%). These results
provide the first empirical evidence that alignment pre-training is not
necessary for effective multimodal learning, particularly for complex reasoning
tasks. Our work establishes the feasibility of a new paradigm that reduces
computational requirements by 45%, challenges conventional wisdom about
modality fusion, and opens new research directions for efficient multimodal
architectures that preserve modality-specific characteristics. Our project
website with code and additional resources is available at
https://inverse-llava.github.io.

</details>


### [81] [Standardization of Neuromuscular Reflex Analysis -- Role of Fine-Tuned Vision-Language Model Consortium and OpenAI gpt-oss Reasoning LLM Enabled Decision Support System](https://arxiv.org/abs/2508.12473)
*Eranga Bandara,Ross Gore,Sachin Shetty,Ravi Mukkamala,Christopher Rhea,Atmaram Yarlagadda,Shaifali Kaushik,L. H. M. P. De Silva,Andriy Maznychenko,Inna Sokolowska,Amin Hass,Kasun De Zoysa*

Main category: cs.CV

TL;DR: 提出了一种结合视觉语言模型（VLM）和大语言模型（LLM）的自动化H反射波形分析系统，用于提高神经肌肉诊断的准确性和标准化。


<details>
  <summary>Details</summary>
Motivation: 传统H反射EMG波形分析存在变异性大和解释偏差的问题，限制了其可靠性和标准化。

Method: 使用多个经过微调的VLM分析H反射EMG波形图像，结合LLM进行决策支持，通过共识方法和推理LLM优化诊断结果。

Result: 实验表明，该系统能提供高准确性、一致性和可解释性的H反射评估，显著提升了诊断的自动化水平。

Conclusion: 该研究首次将微调VLM与推理LLM结合用于H反射分析，为下一代AI辅助神经肌肉评估奠定了基础。

Abstract: Accurate assessment of neuromuscular reflexes, such as the H-reflex, plays a
critical role in sports science, rehabilitation, and clinical neurology.
Traditional analysis of H-reflex EMG waveforms is subject to variability and
interpretation bias among clinicians and researchers, limiting reliability and
standardization. To address these challenges, we propose a Fine-Tuned
Vision-Language Model (VLM) Consortium and a reasoning Large-Language Model
(LLM)-enabled Decision Support System for automated H-reflex waveform
interpretation and diagnosis. Our approach leverages multiple VLMs, each
fine-tuned on curated datasets of H-reflex EMG waveform images annotated with
clinical observations, recovery timelines, and athlete metadata. These models
are capable of extracting key electrophysiological features and predicting
neuromuscular states, including fatigue, injury, and recovery, directly from
EMG images and contextual metadata. Diagnostic outputs from the VLM consortium
are aggregated using a consensus-based method and refined by a specialized
reasoning LLM, which ensures robust, transparent, and explainable decision
support for clinicians and sports scientists. The end-to-end platform
orchestrates seamless communication between the VLM ensemble and the reasoning
LLM, integrating prompt engineering strategies and automated reasoning
workflows using LLM Agents. Experimental results demonstrate that this hybrid
system delivers highly accurate, consistent, and interpretable H-reflex
assessments, significantly advancing the automation and standardization of
neuromuscular diagnostics. To our knowledge, this work represents the first
integration of a fine-tuned VLM consortium with a reasoning LLM for image-based
H-reflex analysis, laying the foundation for next-generation AI-assisted
neuromuscular assessment and athlete monitoring platforms.

</details>


### [82] [Skin Cancer Classification: Hybrid CNN-Transformer Models with KAN-Based Fusion](https://arxiv.org/abs/2508.12484)
*Shubhi Agarwal,Amulya Kumar Mahto*

Main category: cs.CV

TL;DR: 论文提出了一种结合CNN-Transformer和CKAN的混合模型，用于皮肤癌分类，通过特征融合和迁移学习提升性能。


<details>
  <summary>Details</summary>
Motivation: 皮肤癌分类对早期诊断和治疗至关重要，需要精确区分恶性和非恶性病变。

Method: 采用Sequential和Parallel Hybrid CNN-Transformer模型，结合CKAN进行非线性特征融合，并利用迁移学习和数据增强。

Result: 在多个数据集上表现优异，HAM10000准确率92.81%，PAD-UFES准确率97.83%，BCN20000准确率91.17%。

Conclusion: 混合模型能有效捕捉空间和上下文特征，CKAN增强特征融合，模型设计对医学图像分类至关重要。

Abstract: Skin cancer classification is a crucial task in medical image analysis, where
precise differentiation between malignant and non-malignant lesions is
essential for early diagnosis and treatment. In this study, we explore
Sequential and Parallel Hybrid CNN-Transformer models with Convolutional
Kolmogorov-Arnold Network (CKAN). Our approach integrates transfer learning and
extensive data augmentation, where CNNs extract local spatial features,
Transformers model global dependencies, and CKAN facilitates nonlinear feature
fusion for improved representation learning. To assess generalization, we
evaluate our models on multiple benchmark datasets (HAM10000,BCN20000 and
PAD-UFES) under varying data distributions and class imbalances. Experimental
results demonstrate that hybrid CNN-Transformer architectures effectively
capture both spatial and contextual features, leading to improved
classification performance. Additionally, the integration of CKAN enhances
feature fusion through learnable activation functions, yielding more
discriminative representations. Our proposed approach achieves competitive
performance in skin cancer classification, demonstrating 92.81% accuracy and
92.47% F1-score on the HAM10000 dataset, 97.83% accuracy and 97.83% F1-score on
the PAD-UFES dataset, and 91.17% accuracy with 91.79% F1- score on the BCN20000
dataset highlighting the effectiveness and generalizability of our model across
diverse datasets. This study highlights the significance of feature
representation and model design in advancing robust and accurate medical image
classification.

</details>


### [83] [Design and Validation of a Responsible Artificial Intelligence-based System for the Referral of Diabetic Retinopathy Patients](https://arxiv.org/abs/2508.12506)
*E. Ulises Moya-Sánchez,Abraham Sánchez-Perez,Raúl Nanclares Da Veiga,Alejandro Zarate-Macías,Edgar Villareal,Alejandro Sánchez-Montes,Edtna Jauregui-Ulloa,Héctor Moreno,Ulises Cortés*

Main category: cs.CV

TL;DR: RAIS-DR是一种负责任的人工智能系统，用于糖尿病视网膜病变筛查，通过整合伦理原则和高效模型，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 糖尿病视网膜病变（DR）是导致工作年龄人群视力丧失的主要原因，早期检测可大幅降低风险，但临床实践中存在数据质量和偏见问题。

Method: RAIS-DR结合了预处理、质量评估和三个专用DR分类模型，并在未见过的数据集上与FDA批准的EyeArt系统进行比较。

Result: RAIS-DR在F1分数、准确性和特异性上分别提升了5-12%、6-19%和10-20%，同时在公平性指标上表现优异。

Conclusion: RAIS-DR是一种稳健且符合伦理的DR筛查解决方案，适合临床推广。

Abstract: Diabetic Retinopathy (DR) is a leading cause of vision loss in working-age
individuals. Early detection of DR can reduce the risk of vision loss by up to
95%, but a shortage of retinologists and challenges in timely examination
complicate detection. Artificial Intelligence (AI) models using retinal fundus
photographs (RFPs) offer a promising solution. However, adoption in clinical
settings is hindered by low-quality data and biases that may lead AI systems to
learn unintended features. To address these challenges, we developed RAIS-DR, a
Responsible AI System for DR screening that incorporates ethical principles
across the AI lifecycle. RAIS-DR integrates efficient convolutional models for
preprocessing, quality assessment, and three specialized DR classification
models. We evaluated RAIS-DR against the FDA-approved EyeArt system on a local
dataset of 1,046 patients, unseen by both systems. RAIS-DR demonstrated
significant improvements, with F1 scores increasing by 5-12%, accuracy by
6-19%, and specificity by 10-20%. Additionally, fairness metrics such as
Disparate Impact and Equal Opportunity Difference indicated equitable
performance across demographic subgroups, underscoring RAIS-DR's potential to
reduce healthcare disparities. These results highlight RAIS-DR as a robust and
ethically aligned solution for DR screening in clinical settings. The code,
weights of RAIS-DR are available at
https://gitlab.com/inteligencia-gubernamental-jalisco/jalisco-retinopathy with
RAIL.

</details>


### [84] [LangVision-LoRA-NAS: Neural Architecture Search for Variable LoRA Rank in Vision Language Models](https://arxiv.org/abs/2508.12512)
*Krishna Teja Chitty-Venkata,Murali Emani,Venkatram Vishwanath*

Main category: cs.CV

TL;DR: LangVision-LoRA-NAS结合NAS与LoRA，优化VLMs的动态秩配置，提升性能并降低微调成本。


<details>
  <summary>Details</summary>
Motivation: 当前LoRA方法采用固定秩，限制了多模态任务的灵活性和效率。

Method: 通过NAS动态搜索最优LoRA秩配置，平衡性能与计算效率。

Result: 在LLaMA-3.2-11B模型上实验显示性能显著提升，同时降低微调成本。

Conclusion: LangVision-LoRA-NAS为多模态任务提供了一种高效且灵活的微调方法。

Abstract: Vision Language Models (VLMs) integrate visual and text modalities to enable
multimodal understanding and generation. These models typically combine a
Vision Transformer (ViT) as an image encoder and a Large Language Model (LLM)
for text generation. LoRA (Low-Rank Adaptation) is an efficient fine-tuning
method to adapt pre-trained models to new tasks by introducing low-rank updates
to their weights. While LoRA has emerged as a powerful technique for
fine-tuning large models by introducing low-rank updates, current
implementations assume a fixed rank, potentially limiting flexibility and
efficiency across diverse tasks. This paper introduces
\textit{LangVision-LoRA-NAS}, a novel framework that integrates Neural
Architecture Search (NAS) with LoRA to optimize VLMs for variable-rank
adaptation. Our approach leverages NAS to dynamically search for the optimal
LoRA rank configuration tailored to specific multimodal tasks, balancing
performance and computational efficiency. Through extensive experiments using
the LLaMA-3.2-11B model on several datasets, LangVision-LoRA-NAS demonstrates
notable improvement in model performance while reducing fine-tuning costs. Our
Base and searched fine-tuned models on LLaMA-3.2-11B-Vision-Instruct can be
found
\href{https://huggingface.co/collections/krishnateja95/llama-32-11b-vision-instruct-langvision-lora-nas-6786cac480357a6a6fcc59ee}{\textcolor{blue}{here}}
and the code for LangVision-LoRA-NAS can be found
\href{https://github.com/krishnateja95/LangVision-NAS}{\textcolor{blue}{here}}.

</details>


### [85] [An Initial Study of Bird's-Eye View Generation for Autonomous Vehicles using Cross-View Transformers](https://arxiv.org/abs/2508.12520)
*Felipe Carlos dos Santos,Eric Aislan Antonelo,Gustavo Claudio Karl Couto*

Main category: cs.CV

TL;DR: 使用Cross-View Transformers (CVT)将相机图像映射到鸟瞰图(BEV)的三个通道（道路、车道标记和规划轨迹），并通过模拟器验证其泛化性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 鸟瞰图(BEV)在自动驾驶感知中至关重要，但如何从相机输入生成准确的BEV地图仍具挑战性。

Method: 采用CVT模型，结合不同相机布局和损失函数（focal和L1），在模拟器中训练并测试泛化能力。

Result: 在仅使用一个城镇数据训练的情况下，四相机CVT模型结合L1损失在新城镇测试中表现最鲁棒。

Conclusion: CVT在将相机输入映射到BEV地图方面具有潜力，能够生成较为准确的结果。

Abstract: Bird's-Eye View (BEV) maps provide a structured, top-down abstraction that is
crucial for autonomous-driving perception. In this work, we employ Cross-View
Transformers (CVT) for learning to map camera images to three BEV's channels -
road, lane markings, and planned trajectory - using a realistic simulator for
urban driving. Our study examines generalization to unseen towns, the effect of
different camera layouts, and two loss formulations (focal and L1). Using
training data from only a town, a four-camera CVT trained with the L1 loss
delivers the most robust test performance, evaluated in a new town. Overall,
our results underscore CVT's promise for mapping camera inputs to reasonably
accurate BEV maps.

</details>


### [86] [MuSACo: Multimodal Subject-Specific Selection and Adaptation for Expression Recognition with Co-Training](https://arxiv.org/abs/2508.12522)
*Muhammad Osama Zeeshan,Natacha Gillet,Alessandro Lameiras Koerich,Marco Pedersoli,Francois Bremond,Eric Granger*

Main category: cs.CV

TL;DR: MuSACo是一种基于协同训练的多模态个性化表情识别方法，通过选择相关源域并利用多模态信息，显著提升了模型在个性化ER任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有MSDA方法常忽略多模态信息或将源域合并为单一域，限制了模型对个性化特征的捕捉能力。

Method: MuSACo利用多模态互补信息，选择相关源域生成伪标签，并结合类感知和类无关损失进行学习。

Result: 在BioVid和StressID数据集上，MuSACo优于UDA和现有MSDA方法。

Conclusion: MuSACo通过多模态选择和协同训练，有效提升了个性化表情识别的准确性和鲁棒性。

Abstract: Personalized expression recognition (ER) involves adapting a machine learning
model to subject-specific data for improved recognition of expressions with
considerable interpersonal variability. Subject-specific ER can benefit
significantly from multi-source domain adaptation (MSDA) methods, where each
domain corresponds to a specific subject, to improve model accuracy and
robustness. Despite promising results, state-of-the-art MSDA approaches often
overlook multimodal information or blend sources into a single domain, limiting
subject diversity and failing to explicitly capture unique subject-specific
characteristics. To address these limitations, we introduce MuSACo, a
multi-modal subject-specific selection and adaptation method for ER based on
co-training. It leverages complementary information across multiple modalities
and multiple source domains for subject-specific adaptation. This makes MuSACo
particularly relevant for affective computing applications in digital health,
such as patient-specific assessment for stress or pain, where subject-level
nuances are crucial. MuSACo selects source subjects relevant to the target and
generates pseudo-labels using the dominant modality for class-aware learning,
in conjunction with a class-agnostic loss to learn from less confident target
samples. Finally, source features from each modality are aligned, while only
confident target features are combined. Our experimental results on challenging
multimodal ER datasets: BioVid and StressID, show that MuSACo can outperform
UDA (blending) and state-of-the-art MSDA methods.

</details>


### [87] [REVEAL -- Reasoning and Evaluation of Visual Evidence through Aligned Language](https://arxiv.org/abs/2508.12543)
*Ipsita Praharaj,Yukta Butala,Yash Butala*

Main category: cs.CV

TL;DR: 论文提出了一种基于视觉语言模型的图像伪造检测框架REVEAL，通过语义对齐和区域异常检测实现跨域泛化。


<details>
  <summary>Details</summary>
Motivation: 生成模型的快速发展增加了检测和解释视觉伪造的难度，现有方法在跨域泛化上存在挑战。

Method: 提出REVEAL框架，结合整体场景评估和区域异常检测两种方法，利用视觉语言模型的语义对齐能力。

Result: 在多个数据集（Photoshop、DeepFake和AIGC编辑）上实验，验证了模型的有效性和推理能力。

Conclusion: REVEAL框架通过语义对齐和区域分析，提升了图像伪造检测的跨域泛化能力。

Abstract: The rapid advancement of generative models has intensified the challenge of
detecting and interpreting visual forgeries, necessitating robust frameworks
for image forgery detection while providing reasoning as well as localization.
While existing works approach this problem using supervised training for
specific manipulation or anomaly detection in the embedding space,
generalization across domains remains a challenge. We frame this problem of
forgery detection as a prompt-driven visual reasoning task, leveraging the
semantic alignment capabilities of large vision-language models. We propose a
framework, `REVEAL` (Reasoning and Evaluation of Visual Evidence through
Aligned Language), that incorporates generalized guidelines. We propose two
tangential approaches - (1) Holistic Scene-level Evaluation that relies on the
physics, semantics, perspective, and realism of the image as a whole and (2)
Region-wise anomaly detection that splits the image into multiple regions and
analyzes each of them. We conduct experiments over datasets from different
domains (Photoshop, DeepFake and AIGC editing). We compare the Vision Language
Models against competitive baselines and analyze the reasoning provided by
them.

</details>


### [88] [Structure-preserving Feature Alignment for Old Photo Colorization](https://arxiv.org/abs/2508.12570)
*Yingxue Pang,Xin Jin,Jun Fu,Zhibo Chen*

Main category: cs.CV

TL;DR: SFAC是一种基于CNN的算法，用于旧照片着色，仅需两张图像训练，解决了领域差距问题。


<details>
  <summary>Details</summary>
Motivation: 旧照片着色缺乏真实数据和领域差距问题，现有方法难以直接应用。

Method: SFAC通过特征分布对齐损失和结构保持机制，实现语义对应和颜色传递。

Result: 实验证明SFAC在旧照片着色上效果显著，定性和定量指标均验证其有效性。

Conclusion: SFAC成功解决了旧照片着色的挑战，无需大数据依赖，且能保持结构一致性。

Abstract: Deep learning techniques have made significant advancements in
reference-based colorization by training on large-scale datasets. However,
directly applying these methods to the task of colorizing old photos is
challenging due to the lack of ground truth and the notorious domain gap
between natural gray images and old photos. To address this issue, we propose a
novel CNN-based algorithm called SFAC, i.e., Structure-preserving Feature
Alignment Colorizer. SFAC is trained on only two images for old photo
colorization, eliminating the reliance on big data and allowing direct
processing of the old photo itself to overcome the domain gap problem. Our
primary objective is to establish semantic correspondence between the two
images, ensuring that semantically related objects have similar colors. We
achieve this through a feature distribution alignment loss that remains robust
to different metric choices. However, utilizing robust semantic correspondence
to transfer color from the reference to the old photo can result in inevitable
structure distortions. To mitigate this, we introduce a structure-preserving
mechanism that incorporates a perceptual constraint at the feature level and a
frozen-updated pyramid at the pixel level. Extensive experiments demonstrate
the effectiveness of our method for old photo colorization, as confirmed by
qualitative and quantitative metrics.

</details>


### [89] [Foundation Model for Skeleton-Based Human Action Understanding](https://arxiv.org/abs/2508.12586)
*Hongsong Wang,Wanjiang Weng,Junbo Wang,Fang Zhao,Guo-Sen Xie,Xin Geng,Liang Wang*

Main category: cs.CV

TL;DR: 提出了一种统一的骨架基础模型USDRL，用于多样化动作理解任务，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有骨架动作理解方法缺乏可扩展性和泛化能力，需要一种能适应广泛任务的基础模型。

Method: USDRL框架包含Transformer编码器、多粒度特征解耦和多视角一致性训练模块。

Result: 在25个基准测试中表现优异，覆盖9种任务。

Conclusion: USDRL扩展了骨架动作理解的研究范围，并推动了对密集预测任务的关注。

Abstract: Human action understanding serves as a foundational pillar in the field of
intelligent motion perception. Skeletons serve as a modality- and
device-agnostic representation for human modeling, and skeleton-based action
understanding has potential applications in humanoid robot control and
interaction. \RED{However, existing works often lack the scalability and
generalization required to handle diverse action understanding tasks. There is
no skeleton foundation model that can be adapted to a wide range of action
understanding tasks}. This paper presents a Unified Skeleton-based Dense
Representation Learning (USDRL) framework, which serves as a foundational model
for skeleton-based human action understanding. USDRL consists of a
Transformer-based Dense Spatio-Temporal Encoder (DSTE), Multi-Grained Feature
Decorrelation (MG-FD), and Multi-Perspective Consistency Training (MPCT). The
DSTE module adopts two parallel streams to learn temporal dynamic and spatial
structure features. The MG-FD module collaboratively performs feature
decorrelation across temporal, spatial, and instance domains to reduce
dimensional redundancy and enhance information extraction. The MPCT module
employs both multi-view and multi-modal self-supervised consistency training.
The former enhances the learning of high-level semantics and mitigates the
impact of low-level discrepancies, while the latter effectively facilitates the
learning of informative multimodal features. We perform extensive experiments
on 25 benchmarks across across 9 skeleton-based action understanding tasks,
covering coarse prediction, dense prediction, and transferred prediction. Our
approach significantly outperforms the current state-of-the-art methods. We
hope that this work would broaden the scope of research in skeleton-based
action understanding and encourage more attention to dense prediction tasks.

</details>


### [90] [Multimodal Chain of Continuous Thought for Latent-Space Reasoning in Vision-Language Models](https://arxiv.org/abs/2508.12587)
*Tan-Hanh Pham,Chris Ngo*

Main category: cs.CV

TL;DR: 提出了一种名为MCOUT的多模态连续思维链方法，直接在联合潜在空间中进行推理，优于传统的语言模型方法。


<details>
  <summary>Details</summary>
Motivation: 传统语言模型方法（如CoT）在多模态环境中表现不佳，难以动态对齐音频、视觉和文本信息。

Method: MCOUT通过连续隐藏向量表示推理状态，迭代优化并与视觉和文本嵌入对齐，开发了MCOUT-Base和MCOUT-Multi两种变体。

Result: 在多个基准测试中，MCOUT显著提升了多模态推理性能，准确率最高提升8.23%，BLEU分数提升8.27%。

Conclusion: MCOUT展示了连续潜在推理在多模态推理中的潜力，为超越语言限制的CoT提供了可扩展框架。

Abstract: Many reasoning techniques for large multimodal models adapt language model
approaches, such as Chain-of-Thought (CoT) prompting, which express reasoning
as word sequences. While effective for text, these methods are suboptimal for
multimodal contexts, struggling to align audio, visual, and textual information
dynamically. To explore an alternative paradigm, we propose the Multimodal
Chain of Continuous Thought (MCOUT), which enables reasoning directly in a
joint latent space rather than in natural language. In MCOUT, the reasoning
state is represented as a continuous hidden vector, iteratively refined and
aligned with visual and textual embeddings, inspired by human reflective
cognition. We develop two variants: MCOUT-Base, which reuses the language
model`s last hidden state as the continuous thought for iterative reasoning,
and MCOUT-Multi, which integrates multimodal latent attention to strengthen
cross-modal alignment between visual and textual features. Experiments on
benchmarks including MMMU, ScienceQA, and MMStar show that MCOUT consistently
improves multimodal reasoning, yielding up to 8.23% accuracy gains over strong
baselines and improving BLEU scores up to 8.27% across multiple-choice and
open-ended tasks. These findings highlight latent continuous reasoning as a
promising direction for advancing LMMs beyond language-bound CoT, offering a
scalable framework for human-like reflective multimodal inference. Code is
available at https://github.com/Hanhpt23/OmniMod.

</details>


### [91] [ViLaD: A Large Vision Language Diffusion Framework for End-to-End Autonomous Driving](https://arxiv.org/abs/2508.12603)
*Can Cui,Yupeng Zhou,Juntong Peng,Sung-Yeon Park,Zichong Yang,Prashanth Sankaranarayanan,Jiaru Zhang,Ruqi Zhang,Ziran Wang*

Main category: cs.CV

TL;DR: ViLaD是一种新型的大视觉语言扩散框架，用于端到端自动驾驶，通过并行生成决策序列显著降低延迟，并支持双向推理。


<details>
  <summary>Details</summary>
Motivation: 现有基于自回归架构的视觉语言模型在实时性和双向推理能力上存在局限，不适合动态、安全关键的环境。

Method: 采用掩码扩散模型实现并行生成驾驶决策序列，支持双向推理和渐进式生成。

Result: 在nuScenes数据集上，ViLaD在规划准确性和推理速度上优于现有自回归模型，且故障率接近零。

Conclusion: ViLaD框架在实际应用中表现出高效性和可靠性，适合自动驾驶任务。

Abstract: End-to-end autonomous driving systems built on Vision Language Models (VLMs)
have shown significant promise, yet their reliance on autoregressive
architectures introduces some limitations for real-world applications. The
sequential, token-by-token generation process of these models results in high
inference latency and cannot perform bidirectional reasoning, making them
unsuitable for dynamic, safety-critical environments. To overcome these
challenges, we introduce ViLaD, a novel Large Vision Language Diffusion (LVLD)
framework for end-to-end autonomous driving that represents a paradigm shift.
ViLaD leverages a masked diffusion model that enables parallel generation of
entire driving decision sequences, significantly reducing computational
latency. Moreover, its architecture supports bidirectional reasoning, allowing
the model to consider both past and future simultaneously, and supports
progressive easy-first generation to iteratively improve decision quality. We
conduct comprehensive experiments on the nuScenes dataset, where ViLaD
outperforms state-of-the-art autoregressive VLM baselines in both planning
accuracy and inference speed, while achieving a near-zero failure rate.
Furthermore, we demonstrate the framework's practical viability through a
real-world deployment on an autonomous vehicle for an interactive parking task,
confirming its effectiveness and soundness for practical applications.

</details>


### [92] [ViDA-UGC: Detailed Image Quality Analysis via Visual Distortion Assessment for UGC Images](https://arxiv.org/abs/2508.12605)
*Wenjie Liao,Jieyu Yuan,Yifang Xu,Chunle Guo,Zilong Zhang,Jihong Li,Jiachen Fu,Haotian Fan,Tao Li,Junhui Cui,Chongyi Li*

Main category: cs.CV

TL;DR: 该论文提出了ViDA-UGC数据集和CoT评估框架，用于提升多模态大语言模型在用户生成内容（UGC）图像质量评估中的能力。


<details>
  <summary>Details</summary>
Motivation: 当前的可解释图像质量评估方法对UGC和AIGC图像使用相同的失真标准，且缺乏详细的图像质量分析和修复指导。

Method: 构建了包含11K图像的ViDA-UGC数据集，采用失真导向的标注流程和CoT框架，生成细粒度质量描述。

Result: 实验表明，ViDA-UGC和CoT框架能显著提升多种MLLM的图像质量分析能力，甚至超越GPT-4o。

Conclusion: ViDA-UGC数据集和CoT框架为UGC图像质量评估提供了有效工具，推动了可解释IQA的发展。

Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have introduced a
paradigm shift for Image Quality Assessment (IQA) from unexplainable image
quality scoring to explainable IQA, demonstrating practical applications like
quality control and optimization guidance. However, current explainable IQA
methods not only inadequately use the same distortion criteria to evaluate both
User-Generated Content (UGC) and AI-Generated Content (AIGC) images, but also
lack detailed quality analysis for monitoring image quality and guiding image
restoration. In this study, we establish the first large-scale Visual
Distortion Assessment Instruction Tuning Dataset for UGC images, termed
ViDA-UGC, which comprises 11K images with fine-grained quality grounding,
detailed quality perception, and reasoning quality description data. This
dataset is constructed through a distortion-oriented pipeline, which involves
human subject annotation and a Chain-of-Thought (CoT) assessment framework.
This framework guides GPT-4o to generate quality descriptions by identifying
and analyzing UGC distortions, which helps capturing rich low-level visual
features that inherently correlate with distortion patterns. Moreover, we
carefully select 476 images with corresponding 6,149 question answer pairs from
ViDA-UGC and invite a professional team to ensure the accuracy and quality of
GPT-generated information. The selected and revised data further contribute to
the first UGC distortion assessment benchmark, termed ViDA-UGC-Bench.
Experimental results demonstrate the effectiveness of the ViDA-UGC and CoT
framework for consistently enhancing various image quality analysis abilities
across multiple base MLLMs on ViDA-UGC-Bench and Q-Bench, even surpassing
GPT-4o.

</details>


### [93] [OpenMoCap: Rethinking Optical Motion Capture under Real-world Occlusion](https://arxiv.org/abs/2508.12610)
*Chen Qian,Danyang Li,Xinran Yu,Zheng Yang,Qiang Ma*

Main category: cs.CV

TL;DR: 论文提出了OpenMoCap模型和CMU-Occlu数据集，解决了光学运动捕捉中大规模标记遮挡的问题。


<details>
  <summary>Details</summary>
Motivation: 现实应用中，大规模标记遮挡严重影响光学运动捕捉系统性能，现有模型缺乏反映真实遮挡模式的训练数据和捕捉标记间长程依赖的训练策略。

Method: 引入CMU-Occlu数据集模拟真实遮挡模式，提出OpenMoCap模型，利用标记-关节链推理机制优化和构建标记与关节间的深度约束。

Result: OpenMoCap在多种场景下优于现有方法，CMU-Occlu数据集为未来研究提供了基础。

Conclusion: OpenMoCap和CMU-Occlu数据集显著提升了遮挡环境下的运动捕捉性能，并已集成到MoSen系统中。

Abstract: Optical motion capture is a foundational technology driving advancements in
cutting-edge fields such as virtual reality and film production. However,
system performance suffers severely under large-scale marker occlusions common
in real-world applications. An in-depth analysis identifies two primary
limitations of current models: (i) the lack of training datasets accurately
reflecting realistic marker occlusion patterns, and (ii) the absence of
training strategies designed to capture long-range dependencies among markers.
To tackle these challenges, we introduce the CMU-Occlu dataset, which
incorporates ray tracing techniques to realistically simulate practical marker
occlusion patterns. Furthermore, we propose OpenMoCap, a novel motion-solving
model designed specifically for robust motion capture in environments with
significant occlusions. Leveraging a marker-joint chain inference mechanism,
OpenMoCap enables simultaneous optimization and construction of deep
constraints between markers and joints. Extensive comparative experiments
demonstrate that OpenMoCap consistently outperforms competing methods across
diverse scenarios, while the CMU-Occlu dataset opens the door for future
studies in robust motion solving. The proposed OpenMoCap is integrated into the
MoSen MoCap system for practical deployment. The code is released at:
https://github.com/qianchen214/OpenMoCap.

</details>


### [94] [WIPES: Wavelet-based Visual Primitives](https://arxiv.org/abs/2508.12615)
*Wenhao Zhang,Hao Zhu,Delong Wu,Di Kang,Linchao Bao,Zhan Ma,Xun Cao*

Main category: cs.CV

TL;DR: WIPES是一种基于小波的通用视觉基元，用于表示多维视觉信号，提供高质量和快速渲染。


<details>
  <summary>Details</summary>
Motivation: 现有视觉表示方法依赖频率引导或复杂神经网络解码，导致频谱损失或渲染速度慢。

Method: 利用小波的空间-频率局部化优势，开发了基于小波的视觉基元和可微分光栅化器。

Result: 在多种视觉任务中，WIPES在渲染质量和推理速度上优于基于INR和高斯的方法。

Conclusion: WIPES作为一种视觉基元，在多维视觉信号表示中表现出色，解决了现有方法的局限性。

Abstract: Pursuing a continuous visual representation that offers flexible frequency
modulation and fast rendering speed has recently garnered increasing attention
in the fields of 3D vision and graphics. However, existing representations
often rely on frequency guidance or complex neural network decoding, leading to
spectrum loss or slow rendering. To address these limitations, we propose
WIPES, a universal Wavelet-based vIsual PrimitivES for representing
multi-dimensional visual signals. Building on the spatial-frequency
localization advantages of wavelets, WIPES effectively captures both the
low-frequency "forest" and the high-frequency "trees." Additionally, we develop
a wavelet-based differentiable rasterizer to achieve fast visual rendering.
Experimental results on various visual tasks, including 2D image
representation, 5D static and 6D dynamic novel view synthesis, demonstrate that
WIPES, as a visual primitive, offers higher rendering quality and faster
inference than INR-based methods, and outperforms Gaussian-based
representations in rendering quality.

</details>


### [95] [Creative4U: MLLMs-based Advertising Creative Image Selector with Comparative Reasoning](https://arxiv.org/abs/2508.12628)
*Yukang Lin,Xiang Zhang,Shichang Jia,Bowen Wan,Chenghan Fu,Xudong Ren,Yueran Liu,Wanxian Guan,Pengji Wang,Jian Xu,Bo Zheng,Baolin Liu*

Main category: cs.CV

TL;DR: 提出了一种基于多模态大语言模型（MLLMs）的可解释创意评估与选择方法，并构建了首个比较推理数据集CreativePair和创意选择器Creative4U。


<details>
  <summary>Details</summary>
Motivation: 广告创意图像对电商平台至关重要，但现有方法缺乏可解释性，无法满足创意选择的需求。

Method: 利用MLLMs将创意评估与选择转化为自然语言生成任务，通过CoT-SFT和GRPO强化学习训练模型。

Result: 构建了8k标注图像对的数据集CreativePair，并开发了创意选择器Creative4U，实验证明其有效性。

Conclusion: 该方法为创意评估与选择提供了可解释的解决方案，推动了研究和工业应用。

Abstract: Creative image in advertising is the heart and soul of e-commerce platform.
An eye-catching creative image can enhance the shopping experience for users,
boosting income for advertisers and advertising revenue for platforms. With the
advent of AIGC technology, advertisers can produce large quantities of creative
images at minimal cost. However, they struggle to assess the creative quality
to select. Existing methods primarily focus on creative ranking, which fails to
address the need for explainable creative selection.
  In this work, we propose the first paradigm for explainable creative
assessment and selection. Powered by multimodal large language models (MLLMs),
our approach integrates the assessment and selection of creative images into a
natural language generation task. To facilitate this research, we construct
CreativePair, the first comparative reasoning-induced creative dataset
featuring 8k annotated image pairs, with each sample including a label
indicating which image is superior. Additionally, we introduce Creative4U
(pronounced Creative for You), a MLLMs-based creative selector that takes into
account users' interests. Through Reason-to-Select RFT, which includes
supervised fine-tuning with Chain-of-Thought (CoT-SFT) and Group Relative
Policy Optimization (GRPO) based reinforcement learning, Creative4U is able to
evaluate and select creative images accurately. Both offline and online
experiments demonstrate the effectiveness of our approach. Our code and dataset
will be made public to advance research and industrial applications.

</details>


### [96] [SpotVLM: Cloud-edge Collaborative Real-time VLM based on Context Transfer](https://arxiv.org/abs/2508.12638)
*Chen Qian,Xinran Yu,Zewen Huang,Danyang Li,Qiang Ma,Fan Dang,Xuan Ding,Guangyong Shang,Zheng Yang*

Main category: cs.CV

TL;DR: 提出了一种名为Context Transfer的新范式，利用延迟的LVLM输出作为历史上下文指导SVLM推理，设计了SpotVLM框架，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有云边协作方法无法适应云延迟波动，且未充分利用延迟但准确的LVLM响应。

Method: 提出Context Transfer范式，设计SpotVLM框架，包含上下文替换和视觉聚焦模块。

Result: 在四个数据集上的三个实时视觉任务中验证了框架的有效性。

Conclusion: 新范式为未来VLM系统提供了更有效且延迟感知的协作策略基础。

Abstract: Vision-Language Models (VLMs) are increasingly deployed in real-time
applications such as autonomous driving and human-computer interaction, which
demand fast and reliable responses based on accurate perception. To meet these
requirements, existing systems commonly employ cloud-edge collaborative
architectures, such as partitioned Large Vision-Language Models (LVLMs) or task
offloading strategies between Large and Small Vision-Language Models (SVLMs).
However, these methods fail to accommodate cloud latency fluctuations and
overlook the full potential of delayed but accurate LVLM responses. In this
work, we propose a novel cloud-edge collaborative paradigm for VLMs, termed
Context Transfer, which treats the delayed outputs of LVLMs as historical
context to provide real-time guidance for SVLMs inference. Based on this
paradigm, we design SpotVLM, which incorporates both context replacement and
visual focus modules to refine historical textual input and enhance visual
grounding consistency. Extensive experiments on three real-time vision tasks
across four datasets demonstrate the effectiveness of the proposed framework.
The new paradigm lays the groundwork for more effective and latency-aware
collaboration strategies in future VLM systems.

</details>


### [97] [Synthesizing Accurate and Realistic T1-weighted Contrast-Enhanced MR Images using Posterior-Mean Rectified Flow](https://arxiv.org/abs/2508.12640)
*Bastian Brandstötter,Erich Kobler*

Main category: cs.CV

TL;DR: 提出了一种两阶段的后验均值校正流（PMRF）方法，用于从非对比MRI合成对比增强的脑MRI，以降低成本和风险。


<details>
  <summary>Details</summary>
Motivation: 传统对比增强MRI需要钆剂，增加成本、时间和风险，且对环境有影响。

Method: 使用3D U-Net预测体素后验均值，再通过时间条件3D校正流细化，以保持结构保真度并增加真实纹理。

Result: 在360个测试数据上，轴向FID为12.46，KID为0.007，体积MSE为0.057，且能恢复病灶边缘和血管细节。

Conclusion: 该方法在感知-失真权衡中表现优异，适合临床部署。

Abstract: Contrast-enhanced (CE) T1-weighted MRI is central to neuro-oncologic
diagnosis but requires gadolinium-based agents, which add cost and scan time,
raise environmental concerns, and may pose risks to patients. In this work, we
propose a two-stage Posterior-Mean Rectified Flow (PMRF) pipeline for
synthesizing volumetric CE brain MRI from non-contrast inputs. First, a
patch-based 3D U-Net predicts the voxel-wise posterior mean (minimizing MSE).
Then, this initial estimate is refined by a time-conditioned 3D rectified flow
to incorporate realistic textures without compromising structural fidelity. We
train this model on a multi-institutional collection of paired pre- and
post-contrast T1w volumes (BraTS 2023-2025). On a held-out test set of 360
diverse volumes, our best refined outputs achieve an axial FID of $12.46$ and
KID of $0.007$ ($\sim 68.7\%$ lower FID than the posterior mean) while
maintaining low volumetric MSE of $0.057$ ($\sim 27\%$ higher than the
posterior mean). Qualitative comparisons confirm that our method restores
lesion margins and vascular details realistically, effectively navigating the
perception-distortion trade-off for clinical deployment.

</details>


### [98] [Learn Faster and Remember More: Balancing Exploration and Exploitation for Continual Test-time Adaptation](https://arxiv.org/abs/2508.12643)
*Pinci Yang,Peisong Wen,Ke Ma,Qianqian Xu*

Main category: cs.CV

TL;DR: 提出了一种平衡探索与利用的CTTA方法，通过多级一致性正则化和互补锚点重放机制，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有CTTA方法在探索新域时调整深层预测效率低，以及单一模型易遗忘历史知识的问题。

Method: 采用均值教师框架，引入多级一致性正则化（MCR）和互补锚点重放（CAR）机制。

Result: 在多个基准测试中显著优于现有方法。

Conclusion: 该方法有效平衡了探索与利用，提升了CTTA任务的适应能力。

Abstract: Continual Test-Time Adaptation (CTTA) aims to adapt a source pre-trained
model to continually changing target domains during inference. As a fundamental
principle, an ideal CTTA method should rapidly adapt to new domains
(exploration) while retaining and exploiting knowledge from previously
encountered domains to handle similar domains in the future. Despite
significant advances, balancing exploration and exploitation in CTTA is still
challenging: 1) Existing methods focus on adjusting predictions based on
deep-layer outputs of neural networks. However, domain shifts typically affect
shallow features, which are inefficient to be adjusted from deep predictions,
leading to dilatory exploration; 2) A single model inevitably forgets knowledge
of previous domains during the exploration, making it incapable of exploiting
historical knowledge to handle similar future domains. To address these
challenges, this paper proposes a mean teacher framework that strikes an
appropriate Balance between Exploration and Exploitation (BEE) during the CTTA
process. For the former challenge, we introduce a Multi-level Consistency
Regularization (MCR) loss that aligns the intermediate features of the student
and teacher models, accelerating adaptation to the current domain. For the
latter challenge, we employ a Complementary Anchor Replay (CAR) mechanism to
reuse historical checkpoints (anchors), recovering complementary knowledge for
diverse domains. Experiments show that our method significantly outperforms
state-of-the-art methods on several benchmarks, demonstrating its effectiveness
for CTTA tasks.

</details>


### [99] [DyCrowd: Towards Dynamic Crowd Reconstruction from a Large-scene Video](https://arxiv.org/abs/2508.12644)
*Hao Wen,Hongbo Kang,Jian Ma,Jing Huang,Yuanwang Yang,Haozhe Lin,Yu-Kun Lai,Kun Li*

Main category: cs.CV

TL;DR: DyCrowd框架首次实现了从大场景视频中对数百人的姿态、位置和形状进行时空一致的3D重建，解决了遮挡和时序不一致问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法从静态图像重建3D人群，缺乏时序一致性且无法解决遮挡问题，DyCrowd旨在填补这一空白。

Method: 采用粗到细的群体引导运动优化策略，结合VAE运动先验和异步运动一致性损失（AMC），优化个体运动序列。

Result: 实验表明，DyCrowd在大场景动态人群重建任务中达到最先进性能，并贡献了虚拟数据集VirtualCrowd。

Conclusion: DyCrowd通过群体行为优化和AMC损失，实现了遮挡鲁棒的高质量3D重建，填补了数据集空白。

Abstract: 3D reconstruction of dynamic crowds in large scenes has become increasingly
important for applications such as city surveillance and crowd analysis.
However, current works attempt to reconstruct 3D crowds from a static image,
causing a lack of temporal consistency and inability to alleviate the typical
impact caused by occlusions. In this paper, we propose DyCrowd, the first
framework for spatio-temporally consistent 3D reconstruction of hundreds of
individuals' poses, positions and shapes from a large-scene video. We design a
coarse-to-fine group-guided motion optimization strategy for occlusion-robust
crowd reconstruction in large scenes. To address temporal instability and
severe occlusions, we further incorporate a VAE (Variational Autoencoder)-based
human motion prior along with a segment-level group-guided optimization. The
core of our strategy leverages collective crowd behavior to address long-term
dynamic occlusions. By jointly optimizing the motion sequences of individuals
with similar motion segments and combining this with the proposed Asynchronous
Motion Consistency (AMC) loss, we enable high-quality unoccluded motion
segments to guide the motion recovery of occluded ones, ensuring robust and
plausible motion recovery even in the presence of temporal desynchronization
and rhythmic inconsistencies. Additionally, in order to fill the gap of no
existing well-annotated large-scene video dataset, we contribute a virtual
benchmark dataset, VirtualCrowd, for evaluating dynamic crowd reconstruction
from large-scene videos. Experimental results demonstrate that the proposed
method achieves state-of-the-art performance in the large-scene dynamic crowd
reconstruction task. The code and dataset will be available for research
purposes.

</details>


### [100] [Stable Diffusion-Based Approach for Human De-Occlusion](https://arxiv.org/abs/2508.12663)
*Seung Young Noh,Ju Yong Chang*

Main category: cs.CV

TL;DR: 论文提出了一种两阶段的人体去遮挡方法，结合扩散模型和文本特征，显著提升了遮挡区域的恢复效果。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在预测遮挡区域时表现不佳，尤其是人体结构的恢复。

Method: 分为掩码完成和RGB完成两阶段，利用扩散模型和VQA模型提取的文本特征。

Result: 方法在严重遮挡下仍能有效恢复人体外观，并在下游任务中提升性能。

Conclusion: 该方法在人体去遮挡任务中优于现有方法，且能提升后续任务的性能。

Abstract: Humans can infer the missing parts of an occluded object by leveraging prior
knowledge and visible cues. However, enabling deep learning models to
accurately predict such occluded regions remains a challenging task.
De-occlusion addresses this problem by reconstructing both the mask and RGB
appearance. In this work, we focus on human de-occlusion, specifically
targeting the recovery of occluded body structures and appearances. Our
approach decomposes the task into two stages: mask completion and RGB
completion. The first stage leverages a diffusion-based human body prior to
provide a comprehensive representation of body structure, combined with
occluded joint heatmaps that offer explicit spatial cues about missing regions.
The reconstructed amodal mask then serves as a conditioning input for the
second stage, guiding the model on which areas require RGB reconstruction. To
further enhance RGB generation, we incorporate human-specific textual features
derived using a visual question answering (VQA) model and encoded via a CLIP
encoder. RGB completion is performed using Stable Diffusion, with decoder
fine-tuning applied to mitigate pixel-level degradation in visible regions -- a
known limitation of prior diffusion-based de-occlusion methods caused by latent
space transformations. Our method effectively reconstructs human appearances
even under severe occlusions and consistently outperforms existing methods in
both mask and RGB completion. Moreover, the de-occluded images generated by our
approach can improve the performance of downstream human-centric tasks, such as
2D pose estimation and 3D human reconstruction. The code will be made publicly
available.

</details>


### [101] [WP-CLIP: Leveraging CLIP to Predict Wölfflin's Principles in Visual Art](https://arxiv.org/abs/2508.12668)
*Abhijay Ghildyal,Li-Yun Wang,Feng Liu*

Main category: cs.CV

TL;DR: 研究探讨了CLIP模型是否能理解和预测Wölfflin的五项艺术风格原则，发现其原生能力不足，但通过微调可以提升效果。


<details>
  <summary>Details</summary>
Motivation: 现有指标无法有效预测Wolfflin的五项艺术风格原则，需要一种能分析颜色、构图等视觉元素的指标。

Method: 微调CLIP模型，使用真实艺术图像的标注数据集预测每项原则的分数。

Result: WP-CLIP模型在GAN生成画作和Pandora-18K数据集上表现良好，能泛化到多样艺术风格。

Conclusion: 视觉语言模型在自动化艺术分析中具有潜力。

Abstract: W\"olfflin's five principles offer a structured approach to analyzing
stylistic variations for formal analysis. However, no existing metric
effectively predicts all five principles in visual art. Computationally
evaluating the visual aspects of a painting requires a metric that can
interpret key elements such as color, composition, and thematic choices. Recent
advancements in vision-language models (VLMs) have demonstrated their ability
to evaluate abstract image attributes, making them promising candidates for
this task. In this work, we investigate whether CLIP, pre-trained on
large-scale data, can understand and predict W\"olfflin's principles. Our
findings indicate that it does not inherently capture such nuanced stylistic
elements. To address this, we fine-tune CLIP on annotated datasets of real art
images to predict a score for each principle. We evaluate our model, WP-CLIP,
on GAN-generated paintings and the Pandora-18K art dataset, demonstrating its
ability to generalize across diverse artistic styles. Our results highlight the
potential of VLMs for automated art analysis.

</details>


### [102] [Vision-G1: Towards General Vision Language Reasoning with Multi-Domain Data Curation](https://arxiv.org/abs/2508.12680)
*Yuheng Zha,Kun Zhou,Yujia Wu,Yushu Wang,Jie Feng,Zhi Xu,Shibo Hao,Zhengzhong Liu,Eric P. Xing,Zhiting Hu*

Main category: cs.CV

TL;DR: 论文提出了一种多领域视觉推理数据集和训练方法，通过数据选择和难度过滤策略训练VLM模型Vision-G1，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型（VLM）的训练主要集中在数学和逻辑推理任务，难以泛化到其他领域，且缺乏跨领域兼容的数据集。

Method: 构建了涵盖8个领域的46个数据源的RL-ready数据集，采用基于影响函数的数据选择和难度过滤策略，并通过多轮RL训练提升模型能力。

Result: Vision-G1在多个视觉推理基准测试中表现优异，优于同类VLM及GPT-4o、Gemini-1.5 Flash等专有模型。

Conclusion: 通过多领域数据集和优化训练策略，Vision-G1显著提升了视觉推理能力，为VLM的泛化提供了新思路。

Abstract: Despite their success, current training pipelines for reasoning VLMs focus on
a limited range of tasks, such as mathematical and logical reasoning. As a
result, these models face difficulties in generalizing their reasoning
capabilities to a wide range of domains, primarily due to the scarcity of
readily available and verifiable reward data beyond these narrowly defined
areas. Moreover, integrating data from multiple domains is challenging, as the
compatibility between domain-specific datasets remains uncertain. To address
these limitations, we build a comprehensive RL-ready visual reasoning dataset
from 46 data sources across 8 dimensions, covering a wide range of tasks such
as infographic, mathematical, spatial, cross-image, graphic user interface,
medical, common sense and general science. We propose an influence function
based data selection and difficulty based filtering strategy to identify
high-quality training samples from this dataset. Subsequently, we train the
VLM, referred to as Vision-G1, using multi-round RL with a data curriculum to
iteratively improve its visual reasoning capabilities. Our model achieves
state-of-the-art performance across various visual reasoning benchmarks,
outperforming similar-sized VLMs and even proprietary models like GPT-4o and
Gemini-1.5 Flash. The model, code and dataset are publicly available at
https://github.com/yuh-zha/Vision-G1.

</details>


### [103] [Refine-and-Contrast: Adaptive Instance-Aware BEV Representations for Multi-UAV Collaborative Object Detection](https://arxiv.org/abs/2508.12684)
*Zhongyao Li,Peirui Cheng,Liangjin Zhao,Chen Chen,Yundu Li,Zhechao Wang,Xue Yang,Xian Sun,Zhirui Wang*

Main category: cs.CV

TL;DR: AdaBEV是一种通过自适应实例感知BEV表示的多无人机协作3D检测框架，通过Box-Guided Refinement Module和Instance-Background Contrastive Learning提升性能。


<details>
  <summary>Details</summary>
Motivation: 多无人机协作3D检测在覆盖和遮挡处理方面具有优势，但资源受限的无人机平台计算能力有限，需要高效方法。

Method: AdaBEV采用BG-RM和IBCL模块，前者通过2D监督和空间细分优化前景实例的BEV网格，后者通过对比学习增强特征区分。

Result: 在Air-Co-Pred数据集上，AdaBEV在低分辨率下优于其他方法，接近上限性能且计算开销低。

Conclusion: AdaBEV通过自适应学习和对比机制，实现了高效且准确的多无人机3D检测。

Abstract: Multi-UAV collaborative 3D detection enables accurate and robust perception
by fusing multi-view observations from aerial platforms, offering significant
advantages in coverage and occlusion handling, while posing new challenges for
computation on resource-constrained UAV platforms. In this paper, we present
AdaBEV, a novel framework that learns adaptive instance-aware BEV
representations through a refine-and-contrast paradigm. Unlike existing methods
that treat all BEV grids equally, AdaBEV introduces a Box-Guided Refinement
Module (BG-RM) and an Instance-Background Contrastive Learning (IBCL) to
enhance semantic awareness and feature discriminability. BG-RM refines only BEV
grids associated with foreground instances using 2D supervision and spatial
subdivision, while IBCL promotes stronger separation between foreground and
background features via contrastive learning in BEV space. Extensive
experiments on the Air-Co-Pred dataset demonstrate that AdaBEV achieves
superior accuracy-computation trade-offs across model scales, outperforming
other state-of-the-art methods at low resolutions and approaching upper bound
performance while maintaining low-resolution BEV inputs and negligible
overhead.

</details>


### [104] [TTA-DAME: Test-Time Adaptation with Domain Augmentation and Model Ensemble for Dynamic Driving Conditions](https://arxiv.org/abs/2508.12690)
*Dongjae Jeon,Taeheon Kim,Seongwon Cho,Minhyuk Seo,Jonghyun Choi*

Main category: cs.CV

TL;DR: TTA-DAME方法通过数据增强和域鉴别器解决测试时适应问题，显著提升SHIFT Benchmark性能。


<details>
  <summary>Details</summary>
Motivation: 现实驾驶场景中天气变化频繁，模型需动态适应目标域变化。

Method: 利用源域数据增强到目标域，引入域鉴别器和专用域检测器，结合NMS整合多个检测器预测。

Result: 在SHIFT Benchmark上表现显著提升。

Conclusion: TTA-DAME有效应对动态域变化，提升模型适应性。

Abstract: Test-time Adaptation (TTA) poses a challenge, requiring models to dynamically
adapt and perform optimally on shifting target domains. This task is
particularly emphasized in real-world driving scenes, where weather domain
shifts occur frequently. To address such dynamic changes, our proposed method,
TTA-DAME, leverages source domain data augmentation into target domains.
Additionally, we introduce a domain discriminator and a specialized domain
detector to mitigate drastic domain shifts, especially from daytime to
nighttime conditions. To further improve adaptability, we train multiple
detectors and consolidate their predictions through Non-Maximum Suppression
(NMS). Our empirical validation demonstrates the effectiveness of our method,
showing significant performance enhancements on the SHIFT Benchmark.

</details>


### [105] [Multi-Level Knowledge Distillation and Dynamic Self-Supervised Learning for Continual Learning](https://arxiv.org/abs/2508.12692)
*Taeheon Kim,San Kim,Minhyuk Seo,Dongjae Jeon,Wonje Jeong,Jonghyun Choi*

Main category: cs.CV

TL;DR: 论文提出了一种在类增量重复（CIR）场景下的方法，通过多级知识蒸馏和动态自监督损失，有效利用未标记数据提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统类增量学习假设每个任务包含新类，而CIR更现实，允许已训练类重复出现。未标记数据易获取，但如何高效利用是关键。

Method: 提出多级知识蒸馏（MLKD）和动态自监督损失（SSL），前者从多角度蒸馏知识，后者利用未标记数据加速新类学习。

Result: 方法显著提升CIR性能，在CVPR CLVISION挑战赛中获第二名。

Conclusion: MLKD和动态SSL的组合有效解决了CIR场景下的稳定性和可塑性问题。

Abstract: Class-incremental with repetition (CIR), where previously trained classes
repeatedly introduced in future tasks, is a more realistic scenario than the
traditional class incremental setup, which assumes that each task contains
unseen classes. CIR assumes that we can easily access abundant unlabeled data
from external sources, such as the Internet. Therefore, we propose two
components that efficiently use the unlabeled data to ensure the high stability
and the plasticity of models trained in CIR setup. First, we introduce
multi-level knowledge distillation (MLKD) that distills knowledge from multiple
previous models across multiple perspectives, including features and logits, so
the model can maintain much various previous knowledge. Moreover, we implement
dynamic self-supervised loss (SSL) to utilize the unlabeled data that
accelerates the learning of new classes, while dynamic weighting of SSL keeps
the focus of training to the primary task. Both of our proposed components
significantly improve the performance in CIR setup, achieving 2nd place in the
CVPR 5th CLVISION Challenge.

</details>


### [106] [Neural Rendering for Sensor Adaptation in 3D Object Detection](https://arxiv.org/abs/2508.12695)
*Felix Embacher,David Holtz,Jonas Uhrig,Marius Cordts,Markus Enzweiler*

Main category: cs.CV

TL;DR: 论文研究了自动驾驶车辆中不同摄像头传感器配置对3D目标检测器性能的影响，提出了CamShift数据集和一种基于神经渲染的数据驱动解决方案。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆因车型不同导致摄像头传感器配置差异，导致跨传感器域差距，影响感知模型的准确性。

Method: 引入CamShift数据集模拟不同车型的传感器差异，并提出基于神经渲染的数据驱动传感器适配管道。

Result: 密集BEV表示模型（如BEVFormer）对传感器配置变化最鲁棒；提出的适配方法显著减少了跨传感器域差距。

Conclusion: 通过数据驱动方法可以有效缓解跨传感器域差距，提升数据重用性，减少新数据收集需求。

Abstract: Autonomous vehicles often have varying camera sensor setups, which is
inevitable due to restricted placement options for different vehicle types.
Training a perception model on one particular setup and evaluating it on a new,
different sensor setup reveals the so-called cross-sensor domain gap, typically
leading to a degradation in accuracy. In this paper, we investigate the impact
of the cross-sensor domain gap on state-of-the-art 3D object detectors. To this
end, we introduce CamShift, a dataset inspired by nuScenes and created in CARLA
to specifically simulate the domain gap between subcompact vehicles and sport
utility vehicles (SUVs). Using CamShift, we demonstrate significant
cross-sensor performance degradation, identify robustness dependencies on model
architecture, and propose a data-driven solution to mitigate the effect. On the
one hand, we show that model architectures based on a dense Bird's Eye View
(BEV) representation with backward projection, such as BEVFormer, are the most
robust against varying sensor configurations. On the other hand, we propose a
novel data-driven sensor adaptation pipeline based on neural rendering, which
can transform entire datasets to match different camera sensor setups. Applying
this approach improves performance across all investigated 3D object detectors,
mitigating the cross-sensor domain gap by a large margin and reducing the need
for new data collection by enabling efficient data reusability across vehicles
with different sensor setups. The CamShift dataset and the sensor adaptation
benchmark are available at https://dmholtz.github.io/camshift/.

</details>


### [107] [Drifting Away from Truth: GenAI-Driven News Diversity Challenges LVLM-Based Misinformation Detection](https://arxiv.org/abs/2508.12711)
*Fanxiao Li,Jiaying Wu,Tingchao Fu,Yunyun Dong,Bingbing Song,Wei Zhou*

Main category: cs.CV

TL;DR: 多模态虚假信息的扩散对公共话语和社会信任构成威胁。生成式AI（GenAI）驱动的新闻多样性导致多级漂移，显著降低了当前基于大视觉语言模型（LVLM）的多模态虚假信息检测（MMD）系统的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 研究GenAI驱动的新闻多样性对MMD系统的影响，揭示其脆弱性。

Method: 引入DriftBench基准，包含16,000个新闻实例，设计三个评估任务：多级漂移下的真实性验证鲁棒性、对抗性证据污染的敏感性、以及推理一致性分析。

Result: 实验显示六种最先进的LVLM检测器性能显著下降（平均F1 -14.8%），推理轨迹不稳定，对抗性证据注入下表现更差。

Conclusion: 现有MMD系统存在根本性脆弱性，GenAI时代需要更鲁棒的方法。

Abstract: The proliferation of multimodal misinformation poses growing threats to
public discourse and societal trust. While Large Vision-Language Models (LVLMs)
have enabled recent progress in multimodal misinformation detection (MMD), the
rise of generative AI (GenAI) tools introduces a new challenge: GenAI-driven
news diversity, characterized by highly varied and complex content. We show
that this diversity induces multi-level drift, comprising (1) model-level
misperception drift, where stylistic variations disrupt a model's internal
reasoning, and (2) evidence-level drift, where expression diversity degrades
the quality or relevance of retrieved external evidence. These drifts
significantly degrade the robustness of current LVLM-based MMD systems. To
systematically study this problem, we introduce DriftBench, a large-scale
benchmark comprising 16,000 news instances across six categories of
diversification. We design three evaluation tasks: (1) robustness of truth
verification under multi-level drift; (2) susceptibility to adversarial
evidence contamination generated by GenAI; and (3) analysis of reasoning
consistency across diverse inputs. Experiments with six state-of-the-art
LVLM-based detectors show substantial performance drops (average F1 -14.8%) and
increasingly unstable reasoning traces, with even more severe failures under
adversarial evidence injection. Our findings uncover fundamental
vulnerabilities in existing MMD systems and suggest an urgent need for more
resilient approaches in the GenAI era.

</details>


### [108] [Real-Time Sign Language Gestures to Speech Transcription using Deep Learning](https://arxiv.org/abs/2508.12713)
*Brandone Fonya*

Main category: cs.CV

TL;DR: 论文提出了一种基于深度学习的实时手语翻译系统，通过CNN分类手势并转换为文本和语音，提升听障人士的沟通能力。


<details>
  <summary>Details</summary>
Motivation: 听力和语言障碍者面临沟通困难，现有技术难以满足实时交互需求。

Method: 使用CNN训练Sign Language MNIST数据集，实时捕捉手势并翻译为文本和语音。

Result: 系统准确率高，实时性能良好，但存在一定延迟。

Conclusion: 该系统实用性强，可靠且用户友好，有助于提升手语使用者的自主性和社交融入。

Abstract: Communication barriers pose significant challenges for individuals with
hearing and speech impairments, often limiting their ability to effectively
interact in everyday environments. This project introduces a real-time
assistive technology solution that leverages advanced deep learning techniques
to translate sign language gestures into textual and audible speech. By
employing convolution neural networks (CNN) trained on the Sign Language MNIST
dataset, the system accurately classifies hand gestures captured live via
webcam. Detected gestures are instantaneously translated into their
corresponding meanings and transcribed into spoken language using
text-to-speech synthesis, thus facilitating seamless communication.
Comprehensive experiments demonstrate high model accuracy and robust real-time
performance with some latency, highlighting the system's practical
applicability as an accessible, reliable, and user-friendly tool for enhancing
the autonomy and integration of sign language users in diverse social settings.

</details>


### [109] [Single-Reference Text-to-Image Manipulation with Dual Contrastive Denoising Score](https://arxiv.org/abs/2508.12718)
*Syed Muhmmad Israr,Feng Zhao*

Main category: cs.CV

TL;DR: 提出了一种名为Dual Contrastive Denoising Score的框架，用于改进文本到图像生成模型在真实图像编辑中的应用，解决了文本提示不准确和区域修改不稳定的问题。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像生成模型在编辑真实图像时面临两个主要挑战：用户难以提供完美描述所有视觉细节的文本提示，以及模型在修改某些区域时会意外改变其他区域。

Method: 提出了一种基于对比学习的双对比损失框架，利用潜在扩散模型中自注意力层的空间信息，无需依赖辅助网络。

Result: 该方法在真实图像编辑中优于现有方法，同时保留了直接使用预训练文本到图像扩散模型的能力。

Conclusion: Dual Contrastive Denoising Score框架能够灵活修改内容并保持结构，同时支持零样本图像到图像转换。

Abstract: Large-scale text-to-image generative models have shown remarkable ability to
synthesize diverse and high-quality images. However, it is still challenging to
directly apply these models for editing real images for two reasons. First, it
is difficult for users to come up with a perfect text prompt that accurately
describes every visual detail in the input image. Second, while existing models
can introduce desirable changes in certain regions, they often dramatically
alter the input content and introduce unexpected changes in unwanted regions.
To address these challenges, we present Dual Contrastive Denoising Score, a
simple yet powerful framework that leverages the rich generative prior of
text-to-image diffusion models. Inspired by contrastive learning approaches for
unpaired image-to-image translation, we introduce a straightforward dual
contrastive loss within the proposed framework. Our approach utilizes the
extensive spatial information from the intermediate representations of the
self-attention layers in latent diffusion models without depending on auxiliary
networks. Our method achieves both flexible content modification and structure
preservation between input and output images, as well as zero-shot
image-to-image translation. Through extensive experiments, we show that our
approach outperforms existing methods in real image editing while maintaining
the capability to directly utilize pretrained text-to-image diffusion models
without further training.

</details>


### [110] [Quantifying and Alleviating Co-Adaptation in Sparse-View 3D Gaussian Splatting](https://arxiv.org/abs/2508.12720)
*Kangjie Chen,Yingji Zhong,Zhihao Li,Jiaqi Lin,Youyu Chen,Minghan Qin,Haoqian Wang*

Main category: cs.CV

TL;DR: 论文研究了稀疏视角下3D高斯泼溅（3DGS）的外观伪影问题，揭示了高斯之间过度纠缠是核心限制，并提出两种轻量级策略来缓解。


<details>
  <summary>Details</summary>
Motivation: 稀疏视角下3DGS在训练视角中表现真实，但在新视角中会出现外观伪影，需要解决这一问题。

Method: 提出了一种称为‘共适应分数’（CA）的指标量化高斯纠缠，并提出了随机高斯丢弃和乘性噪声注入两种策略。

Result: 实验验证了两种策略的有效性，表明它们能显著缓解稀疏视角下的外观伪影。

Conclusion: 论文揭示了共适应效应的本质，为稀疏视角3DGS的进一步研究提供了新思路。

Abstract: 3D Gaussian Splatting (3DGS) has demonstrated impressive performance in novel
view synthesis under dense-view settings. However, in sparse-view scenarios,
despite the realistic renderings in training views, 3DGS occasionally manifests
appearance artifacts in novel views. This paper investigates the appearance
artifacts in sparse-view 3DGS and uncovers a core limitation of current
approaches: the optimized Gaussians are overly-entangled with one another to
aggressively fit the training views, which leads to a neglect of the real
appearance distribution of the underlying scene and results in appearance
artifacts in novel views. The analysis is based on a proposed metric, termed
Co-Adaptation Score (CA), which quantifies the entanglement among Gaussians,
i.e., co-adaptation, by computing the pixel-wise variance across multiple
renderings of the same viewpoint, with different random subsets of Gaussians.
The analysis reveals that the degree of co-adaptation is naturally alleviated
as the number of training views increases. Based on the analysis, we propose
two lightweight strategies to explicitly mitigate the co-adaptation in
sparse-view 3DGS: (1) random gaussian dropout; (2) multiplicative noise
injection to the opacity. Both strategies are designed to be plug-and-play, and
their effectiveness is validated across various methods and benchmarks. We hope
that our insights into the co-adaptation effect will inspire the community to
achieve a more comprehensive understanding of sparse-view 3DGS.

</details>


### [111] [Frequency-Driven Inverse Kernel Prediction for Single Image Defocus Deblurring](https://arxiv.org/abs/2508.12736)
*Ying Zhang,Xiongxin Tang,Chongyi Li,Qiao Chen,Yuquan Wu*

Main category: cs.CV

TL;DR: 提出了一种基于频率域的逆核预测网络（FDIKP），通过双分支策略和位置自适应卷积提升去模糊效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在严重模糊区域表现不佳，因高频细节缺失，需引入频率域增强结构可识别性。

Method: 结合频率域表示设计双分支逆核预测（DIKP），引入位置自适应卷积（PAC）和双域尺度循环模块（DSRM）。

Result: 实验表明，该方法优于现有方法。

Conclusion: FDIKP通过频率域建模和自适应策略显著提升了去模糊性能。

Abstract: Single image defocus deblurring aims to recover an all-in-focus image from a
defocus counterpart, where accurately modeling spatially varying blur kernels
remains a key challenge. Most existing methods rely on spatial features for
kernel estimation, but their performance degrades in severely blurry regions
where local high-frequency details are missing. To address this, we propose a
Frequency-Driven Inverse Kernel Prediction network (FDIKP) that incorporates
frequency-domain representations to enhance structural identifiability in
kernel modeling. Given the superior discriminative capability of the frequency
domain for blur modeling, we design a Dual-Branch Inverse Kernel Prediction
(DIKP) strategy that improves the accuracy of kernel estimation while
maintaining stability. Moreover, considering the limited number of predicted
inverse kernels, we introduce a Position Adaptive Convolution (PAC) to enhance
the adaptability of the deconvolution process. Finally, we propose a
Dual-Domain Scale Recurrent Module (DSRM) to fuse deconvolution results and
progressively improve deblurring quality from coarse to fine. Extensive
experiments demonstrate that our method outperforms existing approaches. Code
will be made publicly available.

</details>


### [112] [DCSCR: A Class-Specific Collaborative Representation based Network for Image Set Classification](https://arxiv.org/abs/2508.12745)
*Xizhan Gao,Wei Hu*

Main category: cs.CV

TL;DR: 提出了一种名为DCSCR的新型少样本图像集分类方法，结合传统方法和深度学习，同时学习帧级和概念级特征表示。


<details>
  <summary>Details</summary>
Motivation: 传统方法忽略特征学习，深度方法在测量集距离时无法自适应调整特征，导致少样本分类性能有限。

Method: DCSCR包含深度特征提取器、全局特征学习模块和基于类特定协作表示的度量学习模块。

Result: 在多个少样本图像集分类数据集上表现优于现有先进方法。

Conclusion: DCSCR通过结合传统和深度学习方法，有效提升了少样本图像集分类的性能。

Abstract: Image set classification (ISC), which can be viewed as a task of comparing
similarities between sets consisting of unordered heterogeneous images with
variable quantities and qualities, has attracted growing research attention in
recent years. How to learn effective feature representations and how to explore
the similarities between different image sets are two key yet challenging
issues in this field. However, existing traditional ISC methods classify image
sets based on raw pixel features, ignoring the importance of feature learning.
Existing deep ISC methods can learn deep features, but they fail to adaptively
adjust the features when measuring set distances, resulting in limited
performance in few-shot ISC. To address the above issues, this paper combines
traditional ISC methods with deep models and proposes a novel few-shot ISC
approach called Deep Class-specific Collaborative Representation (DCSCR)
network to simultaneously learn the frame- and concept-level feature
representations of each image set and the distance similarities between
different sets. Specifically, DCSCR consists of a fully convolutional deep
feature extractor module, a global feature learning module, and a
class-specific collaborative representation-based metric learning module. The
deep feature extractor and global feature learning modules are used to learn
(local and global) frame-level feature representations, while the
class-specific collaborative representation-based metric learning module is
exploit to adaptively learn the concept-level feature representation of each
image set and thus obtain the distance similarities between different sets by
developing a new CSCR-based contrastive loss function. Extensive experiments on
several well-known few-shot ISC datasets demonstrate the effectiveness of the
proposed method compared with some state-of-the-art image set classification
algorithms.

</details>


### [113] [D2-Mamba: Dual-Scale Fusion and Dual-Path Scanning with SSMs for Shadow Removal](https://arxiv.org/abs/2508.12750)
*Linhao Li,Boya Jin,Zizhe Li,Lanqing Guo,Hao Cheng,Bo Li,Yongfeng Dong*

Main category: cs.CV

TL;DR: 提出了一种基于Mamba的双尺度融合和双路径扫描网络，用于阴影去除任务，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 阴影去除任务需要利用非阴影区域的信息进行指导，但由于阴影区域与非阴影区域的变换差异大，需要有效整合非局部上下文线索和自适应建模区域特定变换。

Method: 提出Dual-Scale Fusion Mamba Block (DFMB)增强多尺度特征表示，减少边界伪影；Dual-Path Mamba Group (DPMG)通过水平扫描和掩码感知自适应扫描策略捕获全局特征。

Result: 实验结果表明，该方法在阴影去除基准测试中显著优于现有最先进方法。

Conclusion: 通过双尺度融合和双路径扫描策略，有效提升了阴影去除的性能。

Abstract: Shadow removal aims to restore images that are partially degraded by shadows,
where the degradation is spatially localized and non-uniform. Unlike general
restoration tasks that assume global degradation, shadow removal can leverage
abundant information from non-shadow regions for guidance. However, the
transformation required to correct shadowed areas often differs significantly
from that of well-lit regions, making it challenging to apply uniform
correction strategies. This necessitates the effective integration of non-local
contextual cues and adaptive modeling of region-specific transformations. To
this end, we propose a novel Mamba-based network featuring dual-scale fusion
and dual-path scanning to selectively propagate contextual information based on
transformation similarity across regions. Specifically, the proposed Dual-Scale
Fusion Mamba Block (DFMB) enhances multi-scale feature representation by fusing
original features with low-resolution features, effectively reducing boundary
artifacts. The Dual-Path Mamba Group (DPMG) captures global features via
horizontal scanning and incorporates a mask-aware adaptive scanning strategy,
which improves structural continuity and fine-grained region modeling.
Experimental results demonstrate that our method significantly outperforms
existing state-of-the-art approaches on shadow removal benchmarks.

</details>


### [114] [CLAIRE-DSA: Fluoroscopic Image Classification for Quality Assurance of Computer Vision Pipelines in Acute Ischemic Stroke](https://arxiv.org/abs/2508.12755)
*Cristo J. van den Berg,Frank G. te Nijenhuis,Mirre J. Blaauboer,Daan T. W. van Erp,Carlijn M. Keppels,Matthijs van der Sluijs,Bob Roozenbeek,Wim van Zwam,Sandra Cornelissen,Danny Ruijters,Ruisheng Su,Theo van Walsum*

Main category: cs.CV

TL;DR: CLAIRE-DSA是一个基于深度学习的框架，用于分类急性缺血性卒中机械取栓术中的图像属性，提升下游质量控制和工作流优化。


<details>
  <summary>Details</summary>
Motivation: 解决机械取栓术中图像质量差导致计算机视觉模型性能下降的问题。

Method: 使用预训练的ResNet模型，微调以预测9种图像属性，并在1,758张标注的MinIPs上训练分类器。

Result: 模型在所有标签上表现优异（ROC-AUC 0.91-0.98，精度0.70-1.00），过滤低质量图像后分割成功率从42%提升至69%。

Conclusion: CLAIRE-DSA在急性缺血性卒中患者的DSA系列中表现出强大的自动分类潜力，支持临床和研究应用中的图像标注和质量控制。

Abstract: Computer vision models can be used to assist during mechanical thrombectomy
(MT) for acute ischemic stroke (AIS), but poor image quality often degrades
performance. This work presents CLAIRE-DSA, a deep learning--based framework
designed to categorize key image properties in minimum intensity projections
(MinIPs) acquired during MT for AIS, supporting downstream quality control and
workflow optimization. CLAIRE-DSA uses pre-trained ResNet backbone models,
fine-tuned to predict nine image properties (e.g., presence of contrast,
projection angle, motion artefact severity). Separate classifiers were trained
on an annotated dataset containing $1,758$ fluoroscopic MinIPs. The model
achieved excellent performance on all labels, with ROC-AUC ranging from $0.91$
to $0.98$, and precision ranging from $0.70$ to $1.00$. The ability of
CLAIRE-DSA to identify suitable images was evaluated on a segmentation task by
filtering poor quality images and comparing segmentation performance on
filtered and unfiltered datasets. Segmentation success rate increased from
$42%$ to $69%$, $p < 0.001$. CLAIRE-DSA demonstrates strong potential as an
automated tool for accurately classifying image properties in DSA series of
acute ischemic stroke patients, supporting image annotation and quality control
in clinical and research applications. Source code is available at
https://gitlab.com/icai-stroke-lab/wp3_neurointerventional_ai/claire-dsa.

</details>


### [115] [Harnessing Group-Oriented Consistency Constraints for Semi-Supervised Semantic Segmentation in CdZnTe Semiconductors](https://arxiv.org/abs/2508.12766)
*Peihao Li,Yan Fang,Man Liu,Huihui Bai,Anhong Wang,Yunchao Wei,Yao Zhao*

Main category: cs.CV

TL;DR: 提出了一种针对CdZnTe半导体图像标注的组内一致性增强框架（ICAF），通过多视图合成和校正提升低对比度区域的标注效果。


<details>
  <summary>Details</summary>
Motivation: CdZnTe图像的低对比度缺陷边界标注困难，现有半监督方法因‘一对一’关系限制导致误差累积。

Method: 提出ICAF框架，包括视图增强模块（VAM）和视图校正模块（VCM），通过多视图合成和交互提升一致性。

Result: 在仅使用2组标注数据（5‰）的情况下，达到70.6% mIoU。

Conclusion: ICAF有效解决了CdZnTe图像标注中的低对比度问题，提升了半监督分割性能。

Abstract: Labeling Cadmium Zinc Telluride (CdZnTe) semiconductor images is challenging
due to the low-contrast defect boundaries, necessitating annotators to
cross-reference multiple views. These views share a single ground truth (GT),
forming a unique ``many-to-one'' relationship. This characteristic renders
advanced semi-supervised semantic segmentation (SSS) methods suboptimal, as
they are generally limited by a ``one-to-one'' relationship, where each image
is independently associated with its GT. Such limitation may lead to error
accumulation in low-contrast regions, further exacerbating confirmation bias.
To address this issue, we revisit the SSS pipeline from a group-oriented
perspective and propose a human-inspired solution: the Intra-group Consistency
Augmentation Framework (ICAF). First, we experimentally validate the inherent
consistency constraints within CdZnTe groups, establishing a group-oriented
baseline using the Intra-group View Sampling (IVS). Building on this insight,
we introduce the Pseudo-label Correction Network (PCN) to enhance consistency
representation, which consists of two key modules. The View Augmentation Module
(VAM) improves boundary details by dynamically synthesizing a boundary-aware
view through the aggregation of multiple views. In the View Correction Module
(VCM), this synthesized view is paired with other views for information
interaction, effectively emphasizing salient regions while minimizing noise.
Extensive experiments demonstrate the effectiveness of our solution for CdZnTe
materials. Leveraging DeepLabV3+ with a ResNet-101 backbone as our segmentation
model, we achieve a 70.6\% mIoU on the CdZnTe dataset using only 2
group-annotated data (5\textperthousand). The code is available at
\href{https://github.com/pipixiapipi/ICAF}{https://github.com/pipixiapipi/ICAF}.

</details>


### [116] [SocialTrack: Multi-Object Tracking in Complex Urban Traffic Scenes Inspired by Social Behavior](https://arxiv.org/abs/2508.12777)
*Wenguang Tao,Xiaotian Wang,Tian Yan,Jie Yan,Guodong Li,Kun Bai*

Main category: cs.CV

TL;DR: SocialTrack是一种新型多目标跟踪框架，针对无人机视角下的小目标跟踪问题，通过多尺度特征增强、速度自适应卡尔曼滤波、群体运动补偿和时空记忆预测等技术，显著提升了复杂城市交通环境中的跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 无人机视角下的多目标跟踪在智能交通系统中具有重要应用价值，但小目标尺度变化、遮挡、非线性运动和运动模糊等问题严重影响了跟踪稳定性。

Method: 提出SocialTrack框架，包括多尺度特征增强的小目标检测器、速度自适应卡尔曼滤波（VACKF）、群体运动补偿策略（GMCS）和时空记忆预测（STMP）。

Result: 在UAVDT和MOT17数据集上的实验表明，SocialTrack在MOTA和IDF1等核心指标上优于现有方法，表现出更高的鲁棒性和适应性。

Conclusion: SocialTrack不仅性能优越，还具有高度模块化和兼容性，可无缝集成到现有跟踪器中进一步提升性能。

Abstract: As a key research direction in the field of multi-object tracking (MOT),
UAV-based multi-object tracking has significant application value in the
analysis and understanding of urban intelligent transportation systems.
However, in complex UAV perspectives, challenges such as small target scale
variations, occlusions, nonlinear crossing motions, and motion blur severely
hinder the stability of multi-object tracking. To address these challenges,
this paper proposes a novel multi-object tracking framework, SocialTrack, aimed
at enhancing the tracking accuracy and robustness of small targets in complex
urban traffic environments. The specialized small-target detector enhances the
detection performance by employing a multi-scale feature enhancement mechanism.
The Velocity Adaptive Cubature Kalman Filter (VACKF) improves the accuracy of
trajectory prediction by incorporating a velocity dynamic modeling mechanism.
The Group Motion Compensation Strategy (GMCS) models social group motion priors
to provide stable state update references for low-quality tracks, significantly
improving the target association accuracy in complex dynamic environments.
Furthermore, the Spatio-Temporal Memory Prediction (STMP) leverages historical
trajectory information to predict the future state of low-quality tracks,
effectively mitigating identity switching issues. Extensive experiments on the
UAVDT and MOT17 datasets demonstrate that SocialTrack outperforms existing
state-of-the-art (SOTA) methods across several key metrics. Significant
improvements in MOTA and IDF1, among other core performance indicators,
highlight its superior robustness and adaptability. Additionally, SocialTrack
is highly modular and compatible, allowing for seamless integration with
existing trackers to further enhance performance.

</details>


### [117] [Leveraging Diffusion Models for Stylization using Multiple Style Images](https://arxiv.org/abs/2508.12784)
*Dan Ruta,Abdelaziz Djelouah,Raphael Ortiz,Christopher Schroers*

Main category: cs.CV

TL;DR: 提出了一种基于多风格图像的潜在扩散模型方法，通过图像提示适配器和特征统计对齐，解决了现有风格迁移方法中风格匹配不准确、风格图像数量受限及内容与风格纠缠的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在风格迁移中存在风格匹配不准确、风格图像数量受限以及内容与风格纠缠的问题。

Method: 利用多风格图像，结合图像提示适配器和特征统计对齐，在去噪过程中干预交叉注意力和自注意力层。

Result: 实验表明，该方法在风格化任务中取得了最先进的结果。

Conclusion: 通过多风格图像和特征统计对齐，显著提升了风格迁移的准确性和效果。

Abstract: Recent advances in latent diffusion models have enabled exciting progress in
image style transfer. However, several key issues remain. For example, existing
methods still struggle to accurately match styles. They are often limited in
the number of style images that can be used. Furthermore, they tend to entangle
content and style in undesired ways. To address this, we propose leveraging
multiple style images which helps better represent style features and prevent
content leaking from the style images. We design a method that leverages both
image prompt adapters and statistical alignment of the features during the
denoising process. With this, our approach is designed such that it can
intervene both at the cross-attention and the self-attention layers of the
denoising UNet. For the statistical alignment, we employ clustering to distill
a small representative set of attention features from the large number of
attention values extracted from the style samples. As demonstrated in our
experimental section, the resulting method achieves state-of-the-art results
for stylization.

</details>


### [118] [Vehicle detection from GSV imagery: Predicting travel behaviour for cycling and motorcycling using Computer Vision](https://arxiv.org/abs/2508.12794)
*Kyriaki,Kokka,Rahul Goel,Ali Abbas,Kerry A. Nice,Luca Martial,SM Labib,Rihuan Ke,Carola Bibiane Schönlieb,James Woodcock*

Main category: cs.CV

TL;DR: 利用深度学习分析街景图像，预测全球城市的骑行和摩托车使用情况。


<details>
  <summary>Details</summary>
Motivation: 缺乏全球范围内骑行和摩托车行为的比较数据，传统调查方法效率低。

Method: 使用YOLOv4模型检测街景图像中的自行车和摩托车，结合Beta回归模型预测使用比例。

Result: 模型预测骑行和摩托车使用比例的R²分别为0.614和0.612，中位绝对误差为1.3%和1.4%。

Conclusion: 街景图像结合计算机视觉可高效补充传统数据，为全球城市交通行为提供新视角。

Abstract: Transportation influence health by shaping exposure to physical activity, air
pollution and injury risk.Comparative data on cycling and motorcycling
behaviours is scarce, particularly at a global scale.Street view imagery, such
as Google Street View (GSV), combined with computer vision, is a valuable
resource for efficiently capturing travel behaviour data.This study
demonstrates a novel approach using deep learning on street view images to
estimate cycling and motorcycling levels across diverse cities worldwide.We
utilized data from 185 global cities.The data on mode shares of cycling and
motorcycling estimated using travel surveys or censuses.We used GSV images to
detect cycles and motorcycles in sampled locations, using 8000 images per
city.The YOLOv4 model, fine-tuned using images from six cities, achieved a mean
average precision of 89% for detecting cycles and motorcycles in GSV images.A
global prediction model was developed using beta regression with city-level
mode shares as outcome, with log transformed explanatory variables of counts of
GSV-detected images with cycles and motorcycles, while controlling for
population density.We found strong correlations between GSV motorcycle counts
and motorcycle mode share (0.78) and moderate correlations between GSV cycle
counts and cycling mode share (0.51).Beta regression models predicted mode
shares with $R^2$ values of 0.614 for cycling and 0.612 for motorcycling,
achieving median absolute errors (MDAE) of 1.3% and 1.4%,
respectively.Scatterplots demonstrated consistent prediction accuracy, though
cities like Utrecht and Cali were outliers.The model was applied to 60 cities
globally for which we didn't have recent mode share data.We provided estimates
for some cities in the Middle East, Latin America and East Asia.With computer
vision, GSV images capture travel modes and activity, providing insights
alongside traditional data sources.

</details>


### [119] [Morphological classification of eclipsing binary stars using computer vision methods](https://arxiv.org/abs/2508.12802)
*Štefan Parimucha,Maksim Gabdeev,Yanna Markus,Martin Vaňko,Pavol Gajdoš*

Main category: cs.CV

TL;DR: 利用计算机视觉方法对食双星（EB）的光变曲线进行分类，通过预训练的卷积神经网络和视觉变换器模型，结合极坐标和六边形可视化改进图像表示，实现了高精度的分类，但自动斑点检测效果不佳。


<details>
  <summary>Details</summary>
Motivation: 研究旨在利用计算机视觉技术提高食双星分类的效率和准确性，尤其是在大规模巡天数据中。

Method: 使用预训练的ResNet50和vit_base_patch16_224模型，通过极坐标和六边形可视化改进图像表示，分两阶段分类（分离与过接触类型、斑点检测）。

Result: 在验证数据上分类准确率>96%，在OGLE、DEBCat和WUMaCat观测数据上表现优异（>94%），但斑点检测效果差。

Conclusion: 计算机视觉在食双星形态分类中潜力巨大，但自动斑点检测需进一步研究。

Abstract: We present an application of computer vision methods to classify the light
curves of eclipsing binaries (EB). We have used pre-trained models based on
convolutional neural networks ($\textit{ResNet50}$) and vision transformers
($\textit{vit\_base\_patch16\_224}$), which were fine-tuned on images created
from synthetic datasets. To improve model generalisation and reduce
overfitting, we developed a novel image representation by transforming
phase-folded light curves into polar coordinates combined with hexbin
visualisation. Our hierarchical approach in the first stage classifies systems
into detached and overcontact types, and in the second stage identifies the
presence or absence of spots. The binary classification models achieved high
accuracy ($>96\%$) on validation data across multiple passbands (Gaia~$G$, $I$,
and $TESS$) and demonstrated strong performance ($>94\%$, up to $100\%$ for
$TESS$) when tested on extensive observational data from the OGLE, DEBCat, and
WUMaCat catalogues. While the primary binary classification was highly
successful, the secondary task of automated spot detection performed poorly,
revealing a significant limitation of our models for identifying subtle
photometric features. This study highlights the potential of computer vision
for EB morphological classification in large-scale surveys, but underscores the
need for further research into robust, automated spot detection.

</details>


### [120] [Next Visual Granularity Generation](https://arxiv.org/abs/2508.12811)
*Yikai Wang,Zhouxia Wang,Zhonghua Wu,Qingyi Tao,Kang Liao,Chen Change Loy*

Main category: cs.CV

TL;DR: 提出了一种新的图像生成方法，通过将图像分解为结构化序列，逐步从全局布局到细节生成图像，性能优于VAR系列。


<details>
  <summary>Details</summary>
Motivation: 传统图像生成方法缺乏对多粒度层次的控制，无法灵活生成不同细节层次的图像。

Method: 引入Next Visual Granularity (NVG)框架，通过结构化序列逐步生成图像，从全局到细节分层控制。

Result: 在ImageNet数据集上训练，NVG在FID分数上优于VAR系列（3.30 -> 3.03等）。

Conclusion: NVG框架在多粒度图像生成中表现出色，具有潜力，代码和模型将开源。

Abstract: We propose a novel approach to image generation by decomposing an image into
a structured sequence, where each element in the sequence shares the same
spatial resolution but differs in the number of unique tokens used, capturing
different level of visual granularity. Image generation is carried out through
our newly introduced Next Visual Granularity (NVG) generation framework, which
generates a visual granularity sequence beginning from an empty image and
progressively refines it, from global layout to fine details, in a structured
manner. This iterative process encodes a hierarchical, layered representation
that offers fine-grained control over the generation process across multiple
granularity levels. We train a series of NVG models for class-conditional image
generation on the ImageNet dataset and observe clear scaling behavior. Compared
to the VAR series, NVG consistently outperforms it in terms of FID scores (3.30
-> 3.03, 2.57 ->2.44, 2.09 -> 2.06). We also conduct extensive analysis to
showcase the capability and potential of the NVG framework. Our code and models
will be released.

</details>


### [121] [SIS-Challenge: Event-based Spatio-temporal Instance Segmentation Challenge at the CVPR 2025 Event-based Vision Workshop](https://arxiv.org/abs/2508.12813)
*Friedhelm Hamann,Emil Mededovic,Fabian Gülhan,Yuli Wu,Johannes Stegmaier,Jing He,Yiqing Wang,Kexin Zhang,Lingling Li,Licheng Jiao,Mengru Ma,Hongxiang Huang,Yuhao Yan,Hongwei Ren,Xiaopeng Lin,Yulong Huang,Bojun Cheng,Se Hyun Lee,Gyu Sung Ham,Kanghan Oh,Gi Hyun Lim,Boxuan Yang,Bowen Du,Guillermo Gallego*

Main category: cs.CV

TL;DR: 该论文概述了CVPR 2025 Event-based Vision Workshop中的时空实例分割（SIS）挑战赛，包括任务、数据集、挑战细节和结果，并介绍了前五名团队的方法。


<details>
  <summary>Details</summary>
Motivation: 旨在通过事件相机和灰度相机数据预测精确的像素级分割掩码，推动时空实例分割技术的发展。

Method: 挑战赛任务涉及从时空对齐的事件相机和灰度相机数据中生成分割掩码，并分析了前五名团队的方法。

Result: 提供了挑战赛的详细结果和参与者方法的代码资源。

Conclusion: 该挑战赛为时空实例分割领域提供了新的数据集和方法参考，促进了相关研究的进展。

Abstract: We present an overview of the Spatio-temporal Instance Segmentation (SIS)
challenge held in conjunction with the CVPR 2025 Event-based Vision Workshop.
The task is to predict accurate pixel-level segmentation masks of defined
object classes from spatio-temporally aligned event camera and grayscale camera
data. We provide an overview of the task, dataset, challenge details and
results. Furthermore, we describe the methods used by the top-5 ranking teams
in the challenge. More resources and code of the participants' methods are
available here:
https://github.com/tub-rip/MouseSIS/blob/main/docs/challenge_results.md

</details>


### [122] [DEEP-SEA: Deep-Learning Enhancement for Environmental Perception in Submerged Aquatics](https://arxiv.org/abs/2508.12824)
*Shuang Chen,Ronald Thenius,Farshad Arvin,Amir Atapour-Abarghouei*

Main category: cs.CV

TL;DR: DEEP-SEA是一种基于深度学习的水下图像恢复模型，旨在增强低频和高频信息并保留空间结构。


<details>
  <summary>Details</summary>
Motivation: 水下环境的光散射、吸收和浑浊导致图像清晰度下降和颜色失真，影响准确观测。

Method: 提出双频增强自注意力空间和频率调制器，自适应优化频域特征表示和空间信息。

Result: 在EUVP和LSUI数据集上表现优于现有方法，能恢复精细图像细节和结构一致性。

Conclusion: DEEP-SEA通过有效减轻水下视觉退化，可提升水下监测平台的可靠性。

Abstract: Continuous and reliable underwater monitoring is essential for assessing
marine biodiversity, detecting ecological changes and supporting autonomous
exploration in aquatic environments. Underwater monitoring platforms rely on
mainly visual data for marine biodiversity analysis, ecological assessment and
autonomous exploration. However, underwater environments present significant
challenges due to light scattering, absorption and turbidity, which degrade
image clarity and distort colour information, which makes accurate observation
difficult. To address these challenges, we propose DEEP-SEA, a novel deep
learning-based underwater image restoration model to enhance both low- and
high-frequency information while preserving spatial structures. The proposed
Dual-Frequency Enhanced Self-Attention Spatial and Frequency Modulator aims to
adaptively refine feature representations in frequency domains and
simultaneously spatial information for better structural preservation. Our
comprehensive experiments on EUVP and LSUI datasets demonstrate the superiority
over the state of the art in restoring fine-grained image detail and structural
consistency. By effectively mitigating underwater visual degradation, DEEP-SEA
has the potential to improve the reliability of underwater monitoring platforms
for more accurate ecological observation, species identification and autonomous
navigation.

</details>


### [123] [Multi-source Multimodal Progressive Domain Adaption for Audio-Visual Deception Detection](https://arxiv.org/abs/2508.12842)
*Ronghao Lin,Sijie Mai,Ying Zeng,Qiaolin He,Aolin Xiong,Haifeng Hu*

Main category: cs.CV

TL;DR: 本文提出了一种多源多模态渐进域适应（MMPDA）框架，用于解决跨源域和目标域的领域偏移问题，并在多模态欺骗检测挑战中取得优异成绩。


<details>
  <summary>Details</summary>
Motivation: 解决源域和目标域之间的领域偏移问题，提升多模态数据集中的欺骗检测性能。

Method: 通过逐步在特征和决策层面对齐源域和目标域，实现跨多模态数据集的领域适应。

Result: 在竞赛第二阶段达到60.43%的准确率和56.99%的F1分数，超越第一名团队5.59%的F1分数和第三名团队6.75%的准确率。

Conclusion: MMPDA框架在多模态欺骗检测任务中表现出色，有效解决了领域偏移问题。

Abstract: This paper presents the winning approach for the 1st MultiModal Deception
Detection (MMDD) Challenge at the 1st Workshop on Subtle Visual Computing
(SVC). Aiming at the domain shift issue across source and target domains, we
propose a Multi-source Multimodal Progressive Domain Adaptation (MMPDA)
framework that transfers the audio-visual knowledge from diverse source domains
to the target domain. By gradually aligning source and the target domain at
both feature and decision levels, our method bridges domain shifts across
diverse multimodal datasets. Extensive experiments demonstrate the
effectiveness of our approach securing Top-2 place. Our approach reaches 60.43%
on accuracy and 56.99\% on F1-score on competition stage 2, surpassing the 1st
place team by 5.59% on F1-score and the 3rd place teams by 6.75% on accuracy.
Our code is available at https://github.com/RH-Lin/MMPDA.

</details>


### [124] [Cross-Domain Few-Shot Learning via Multi-View Collaborative Optimization with Vision-Language Models](https://arxiv.org/abs/2508.12861)
*Dexia Chen,Wentao Zhang,Qianjie Zhu,Ping Hu,Weibing Li,Tong Zhang,Ruixuan Wang*

Main category: cs.CV

TL;DR: 提出了一种名为CoMuCo的新微调策略，用于提升视觉语言模型在跨域少样本任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在跨域任务中表现不佳，需要更鲁棒的特征学习方法。

Method: 采用多视图特征提取和一致性约束机制，结合先验知识和信息几何共识。

Result: 在多个基准测试中，CoMuCo表现优于现有方法。

Conclusion: CoMuCo为跨域少样本任务提供了有效的解决方案，并发布了新的基准测试。

Abstract: Vision-language models (VLMs) pre-trained on natural image and language data,
such as CLIP, have exhibited significant potential in few-shot image
recognition tasks, leading to development of various efficient transfer
learning methods. These methods exploit inherent pre-learned knowledge in VLMs
and have achieved strong performance on standard image datasets. However, their
effectiveness is often limited when confronted with cross-domain tasks where
imaging domains differ from natural images. To address this limitation, we
propose Consistency-guided Multi-view Collaborative Optimization (CoMuCo), a
novel fine-tuning strategy for VLMs. This strategy employs two functionally
complementary expert modules to extract multi-view features, while
incorporating prior knowledge-based consistency constraints and information
geometry-based consensus mechanisms to enhance the robustness of feature
learning. Additionally, a new cross-domain few-shot benchmark is established to
help comprehensively evaluate methods on imaging domains distinct from natural
images. Extensive empirical evaluations on both existing and newly proposed
benchmarks suggest CoMuCo consistently outperforms current methods in few-shot
tasks. The code and benchmark will be released.

</details>


### [125] [Preserve and Sculpt: Manifold-Aligned Fine-tuning of Vision-Language Models for Few-Shot Learning](https://arxiv.org/abs/2508.12877)
*Dexia Chen,Qianjie Zhu,Weibing Li,Yue Yu,Tong Zhang,Ruixuan Wang*

Main category: cs.CV

TL;DR: MPS-Tuning是一种新的微调方法，通过保持和塑造数据分布的几何结构，提升预训练视觉语言模型在少样本图像分类中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在微调时忽略了数据分布的几何结构，可能导致语义表示失真。

Method: MPS-Tuning通过对齐Gram矩阵保持宏观和微观拓扑结构，并优化模态间相似性以增强类区分性。

Result: 实验表明，MPS-Tuning显著提升模型性能并有效保持语义流形结构。

Conclusion: MPS-Tuning通过几何约束和相似性优化，实现了更高效的领域适应和语义表示保持。

Abstract: Pretrained vision-language models (VLMs), such as CLIP, have shown remarkable
potential in few-shot image classification and led to numerous effective
transfer learning strategies. These methods leverage the pretrained knowledge
of VLMs to enable effective domain adaptation while mitigating overfitting
through parameter-efficient tuning or instance-based consistency constraints.
However, such regularizations often neglect the geometric structure of data
distribution, which may lead to distortion of the overall semantic
representation. To overcome this limitation, we propose a novel fine-tuning
method, Manifold-Preserving and Sculpting Tuning (MPS-Tuning). Regarding the
data distribution in feature space as a semantic manifold, MPS-Tuning
explicitly constrains the intrinsic geometry of this manifold while further
sculpting it to enhance class separability. Specifically, MPS-Tuning preserves
both macroscopic and microscopic topological structures of the original
manifold by aligning Gram matrices of features before and after fine-tuning.
Theoretically, this constraint is shown to approximate an upper bound of the
Gromov-Wasserstein distance. Furthermore, features from the image and text
modalities are paired, and pairwise similarities are optimized to enhance the
manifold's class discriminability. Extensive experiments demonstrate that
MPS-Tuning significantly improves model performance while effectively
preserving the structure of the semantic manifold. The code will be released.

</details>


### [126] [S^2-Guidance: Stochastic Self Guidance for Training-Free Enhancement of Diffusion Models](https://arxiv.org/abs/2508.12880)
*Chubin Chen,Jiashu Zhu,Xiaokun Feng,Nisha Huang,Meiqi Wu,Fangyuan Mao,Jiahong Wu,Xiangxiang Chu,Xiu Li*

Main category: cs.CV

TL;DR: S^2-Guidance通过随机子网络优化CFG的次优预测，提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 发现CFG在生成过程中依赖次优预测，导致语义不连贯和低质量输出。

Method: 提出S^2-Guidance，利用随机块丢弃构建子网络，优化预测。

Result: 在文本到图像和视频任务中表现优于CFG和其他方法。

Conclusion: S^2-Guidance有效提升生成质量，优于现有方法。

Abstract: Classifier-free Guidance (CFG) is a widely used technique in modern diffusion
models for enhancing sample quality and prompt adherence. However, through an
empirical analysis on Gaussian mixture modeling with a closed-form solution, we
observe a discrepancy between the suboptimal results produced by CFG and the
ground truth. The model's excessive reliance on these suboptimal predictions
often leads to semantic incoherence and low-quality outputs. To address this
issue, we first empirically demonstrate that the model's suboptimal predictions
can be effectively refined using sub-networks of the model itself. Building on
this insight, we propose S^2-Guidance, a novel method that leverages stochastic
block-dropping during the forward process to construct stochastic sub-networks,
effectively guiding the model away from potential low-quality predictions and
toward high-quality outputs. Extensive qualitative and quantitative experiments
on text-to-image and text-to-video generation tasks demonstrate that
S^2-Guidance delivers superior performance, consistently surpassing CFG and
other advanced guidance strategies. Our code will be released.

</details>


### [127] [ONG: One-Shot NMF-based Gradient Masking for Efficient Model Sparsification](https://arxiv.org/abs/2508.12891)
*Sankar Behera,Yamuna Prasad*

Main category: cs.CV

TL;DR: ONG是一种基于非负矩阵分解（NMF）的一次性剪枝方法，通过梯度掩码保持训练过程中的稀疏性，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络（DNNs）的尺寸过大导致部署困难，现有剪枝方法复杂且难以保持稀疏性。

Method: 使用NMF一次性识别重要权重结构，并通过梯度掩码机制仅更新未剪枝权重。

Result: 在CIFAR-10和CIFAR-100上，ONG在不同稀疏度下表现优于或与现有方法相当。

Conclusion: ONG提供了一种高效且结构完整的剪枝方法，适用于目标稀疏度的实现。

Abstract: Deep Neural Networks (DNNs) have achieved remarkable success but their large
size poses deployment challenges. While various pruning techniques exist, many
involve complex iterative processes, specialized criteria, or struggle to
maintain sparsity effectively during training. We introduce ONG (One-shot
NMF-based Gradient Masking), a novel sparsification strategy that identifies
salient weight structures using Non-negative Matrix Factorization (NMF) for
one-shot pruning at the outset of training. Subsequently, ONG employs a precise
gradient masking mechanism to ensure that only unpruned weights are updated,
strictly preserving the target sparsity throughout the training phase. We
integrate ONG into the BIMP comparative framework and evaluate it on CIFAR-10
and CIFAR-100 with ResNet56, ResNet34, and ResNet18 against established stable
sparsification methods. Our experiments demonstrate ONG's ability to achieve
comparable or superior performance at various sparsity levels while maintaining
structural integrity post-pruning and offering a clear mechanism for targeting
desired sparsities.

</details>


### [128] [CTFlow: Video-Inspired Latent Flow Matching for 3D CT Synthesis](https://arxiv.org/abs/2508.12900)
*Jiayi Wang,Hadrien Reynaud,Franciskus Xaverius Erick,Bernhard Kainz*

Main category: cs.CV

TL;DR: CTFlow是一种基于临床报告的0.5B潜在流匹配变压器模型，用于生成CT体积，具有时间一致性、图像多样性和文本-图像对齐优势。


<details>
  <summary>Details</summary>
Motivation: 通过生成CT体积加速研究，实现数据增强、隐私保护合成，并减少对患者数据的监管限制。

Method: 利用A-VAE定义潜在空间，CT-Clip编码临床报告，采用自回归方法生成一致的CT体积。

Result: 在时间一致性、图像多样性和文本-图像对齐方面优于现有生成CT模型。

Conclusion: CTFlow在生成CT体积方面表现出色，为医学影像研究提供了新工具。

Abstract: Generative modelling of entire CT volumes conditioned on clinical reports has
the potential to accelerate research through data augmentation,
privacy-preserving synthesis and reducing regulator-constraints on patient data
while preserving diagnostic signals. With the recent release of CT-RATE, a
large-scale collection of 3D CT volumes paired with their respective clinical
reports, training large text-conditioned CT volume generation models has become
achievable. In this work, we introduce CTFlow, a 0.5B latent flow matching
transformer model, conditioned on clinical reports. We leverage the A-VAE from
FLUX to define our latent space, and rely on the CT-Clip text encoder to encode
the clinical reports. To generate consistent whole CT volumes while keeping the
memory constraints tractable, we rely on a custom autoregressive approach,
where the model predicts the first sequence of slices of the volume from
text-only, and then relies on the previously generated sequence of slices and
the text, to predict the following sequence. We evaluate our results against
state-of-the-art generative CT model, and demonstrate the superiority of our
approach in terms of temporal coherence, image diversity and text-image
alignment, with FID, FVD, IS scores and CLIP score.

</details>


### [129] [CMF-IoU: Multi-Stage Cross-Modal Fusion 3D Object Detection with IoU Joint Prediction](https://arxiv.org/abs/2508.12917)
*Zhiwei Ning,Zhaojiang Liu,Xuanang Gao,Yifan Zuo,Jie Yang,Yuming Fang,Wei Liu*

Main category: cs.CV

TL;DR: CMF-IOU是一种多阶段跨模态融合3D检测框架，通过深度补全网络和双边跨视图增强3D骨干网络，有效对齐3D空间和2D语义信息，提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法多为单阶段或部分融合，导致特征提取不足和性能不佳。CMF-IOU旨在解决3D空间与2D语义信息对齐的挑战。

Method: 1. 通过深度补全网络将像素信息投影到3D空间生成伪点；2. 设计双边跨视图增强3D骨干网络（S2D和ResVC分支）；3. 引入迭代体素-点感知细粒度池化模块和IoU联合预测分支。

Result: 在KITTI、nuScenes和Waymo数据集上表现出优越性能。

Conclusion: CMF-IOU通过多阶段融合和精细设计模块，显著提升了3D检测的准确性和鲁棒性。

Abstract: Multi-modal methods based on camera and LiDAR sensors have garnered
significant attention in the field of 3D detection. However, many prevalent
works focus on single or partial stage fusion, leading to insufficient feature
extraction and suboptimal performance. In this paper, we introduce a
multi-stage cross-modal fusion 3D detection framework, termed CMF-IOU, to
effectively address the challenge of aligning 3D spatial and 2D semantic
information. Specifically, we first project the pixel information into 3D space
via a depth completion network to get the pseudo points, which unifies the
representation of the LiDAR and camera information. Then, a bilateral
cross-view enhancement 3D backbone is designed to encode LiDAR points and
pseudo points. The first sparse-to-distant (S2D) branch utilizes an
encoder-decoder structure to reinforce the representation of sparse LiDAR
points. The second residual view consistency (ResVC) branch is proposed to
mitigate the influence of inaccurate pseudo points via both the 3D and 2D
convolution processes. Subsequently, we introduce an iterative voxel-point
aware fine grained pooling module, which captures the spatial information from
LiDAR points and textural information from pseudo points in the proposal
refinement stage. To achieve more precise refinement during iteration, an
intersection over union (IoU) joint prediction branch integrated with a novel
proposals generation technique is designed to preserve the bounding boxes with
both high IoU and classification scores. Extensive experiments show the
superior performance of our method on the KITTI, nuScenes and Waymo datasets.

</details>


### [130] [7Bench: a Comprehensive Benchmark for Layout-guided Text-to-image Models](https://arxiv.org/abs/2508.12919)
*Elena Izzo,Luca Parolari,Davide Vezzaro,Lamberto Ballan*

Main category: cs.CV

TL;DR: 7Bench是首个评估布局引导文本到图像生成中语义和空间对齐的基准测试，涵盖七种挑战性场景，并提出了包含布局对齐分数的评估协议。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试仅评估文本对齐，忽略了布局对齐，限制了模型空间保真度的评估能力，尤其是在合成数据生成中。

Method: 提出了7Bench基准测试，包含七种场景的文本和布局对，并设计了评估协议，结合布局对齐分数评估空间准确性。

Result: 评估了多种先进扩散模型，揭示了它们在多样化对齐任务中的优势和局限性。

Conclusion: 7Bench填补了布局对齐评估的空白，为布局引导文本到图像生成提供了更全面的评估工具。

Abstract: Layout-guided text-to-image models offer greater control over the generation
process by explicitly conditioning image synthesis on the spatial arrangement
of elements. As a result, their adoption has increased in many computer vision
applications, ranging from content creation to synthetic data generation. A
critical challenge is achieving precise alignment between the image, textual
prompt, and layout, ensuring semantic fidelity and spatial accuracy. Although
recent benchmarks assess text alignment, layout alignment remains overlooked,
and no existing benchmark jointly evaluates both. This gap limits the ability
to evaluate a model's spatial fidelity, which is crucial when using
layout-guided generation for synthetic data, as errors can introduce noise and
degrade data quality. In this work, we introduce 7Bench, the first benchmark to
assess both semantic and spatial alignment in layout-guided text-to-image
generation. It features text-and-layout pairs spanning seven challenging
scenarios, investigating object generation, color fidelity, attribute
recognition, inter-object relationships, and spatial control. We propose an
evaluation protocol that builds on existing frameworks by incorporating the
layout alignment score to assess spatial accuracy. Using 7Bench, we evaluate
several state-of-the-art diffusion models, uncovering their respective
strengths and limitations across diverse alignment tasks. The benchmark is
available at https://github.com/Elizzo/7Bench.

</details>


### [131] [Towards High-Resolution Industrial Image Anomaly Detection](https://arxiv.org/abs/2508.12931)
*Ximiao Zhang,Min Xu,Xiuzhuang Zhou*

Main category: cs.CV

TL;DR: HiAD是一个针对高分辨率图像异常检测的通用框架，通过双分支架构和多分辨率特征融合策略，有效检测不同大小的异常区域。


<details>
  <summary>Details</summary>
Motivation: 现有方法在高分辨率图像中因下采样导致细粒度信息丢失，检测效果不佳，HiAD旨在解决这一问题。

Method: 采用双分支架构和多分辨率特征融合策略，结合检测器池和自适应分配策略。

Result: 在多个高分辨率异常检测基准测试中表现优异。

Conclusion: HiAD在高分辨率异常检测中具有优越性能，适用于工业场景。

Abstract: Current anomaly detection methods primarily focus on low-resolution
scenarios. For high-resolution images, conventional downsampling often results
in missed detections of subtle anomalous regions due to the loss of
fine-grained discriminative information. Despite some progress, recent studies
have attempted to improve detection resolution by employing lightweight
networks or using simple image tiling and ensemble methods. However, these
approaches still struggle to meet the practical demands of industrial scenarios
in terms of detection accuracy and efficiency. To address the above issues, we
propose HiAD, a general framework for high-resolution anomaly detection. HiAD
is capable of detecting anomalous regions of varying sizes in high-resolution
images under limited computational resources. Specifically, HiAD employs a
dual-branch architecture that integrates anomaly cues across different scales
to comprehensively capture both subtle and large-scale anomalies. Furthermore,
it incorporates a multi-resolution feature fusion strategy to tackle the
challenges posed by fine-grained texture variations in high-resolution images.
To enhance both adaptability and efficiency, HiAD utilizes a detector pool in
conjunction with various detector assignment strategies, enabling detectors to
be adaptively assigned based on patch features, ensuring detection performance
while effectively controlling computational costs. We conduct extensive
experiments on our specifically constructed high-resolution anomaly detection
benchmarks, including MVTec-HD, VisA-HD, and the real-world benchmark
RealIAD-HD, demonstrating the superior performance of HiAD. The code is
available at https://github.com/cnulab/HiAD.

</details>


### [132] [SEDEG:Sequential Enhancement of Decoder and Encoder's Generality for Class Incremental Learning with Small Memory](https://arxiv.org/abs/2508.12932)
*Hongyang Chen,Shaoling Pu,Lingyu Zheng,Zhongwu Sun*

Main category: cs.CV

TL;DR: SEDEG是一个两阶段训练框架，专注于提升视觉变换器（ViT）中编码器和解码器的泛化能力，以缓解增量学习中的灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 在增量学习中，提升知识的泛化能力对适应动态数据输入至关重要。现有方法通常仅关注编码器或解码器之一，限制了其效果。

Method: SEDEG通过特征增强训练集成编码器，随后通过知识蒸馏策略压缩编码器并提升解码器的泛化能力。

Result: 在三个基准数据集上的实验表明SEDEG表现优异，消融研究验证了其组件的有效性。

Conclusion: SEDEG通过两阶段训练有效提升了编码器和解码器的泛化能力，显著缓解了灾难性遗忘问题。

Abstract: In incremental learning, enhancing the generality of knowledge is crucial for
adapting to dynamic data inputs. It can develop generalized representations or
more balanced decision boundaries, preventing the degradation of long-term
knowledge over time and thus mitigating catastrophic forgetting. Some emerging
incremental learning methods adopt an encoder-decoder architecture and have
achieved promising results. In the encoder-decoder achitecture, improving the
generalization capabilities of both the encoder and decoder is critical, as it
helps preserve previously learned knowledge while ensuring adaptability and
robustness to new, diverse data inputs. However, many existing continual
methods focus solely on enhancing one of the two components, which limits their
effectiveness in mitigating catastrophic forgetting. And these methods perform
even worse in small-memory scenarios, where only a limited number of historical
samples can be stored. To mitigate this limitation, we introduces SEDEG, a
two-stage training framework for vision transformers (ViT), focusing on
sequentially improving the generality of both Decoder and Encoder. Initially,
SEDEG trains an ensembled encoder through feature boosting to learn generalized
representations, which subsequently enhance the decoder's generality and
balance the classifier. The next stage involves using knowledge distillation
(KD) strategies to compress the ensembled encoder and develop a new, more
generalized encoder. This involves using a balanced KD approach and feature KD
for effective knowledge transfer. Extensive experiments on three benchmark
datasets show SEDEG's superior performance, and ablation studies confirm the
efficacy of its components. The code is available at
https://github.com/ShaolingPu/CIL.

</details>


### [133] [Fully Automated Segmentation of Fiber Bundles in Anatomic Tracing Data](https://arxiv.org/abs/2508.12942)
*Kyriaki-Margarita Bintsi,Yaël Balbastre,Jingjing Wu,Julia F. Lehman,Suzanne N. Haber,Anastasia Yendiki*

Main category: cs.CV

TL;DR: 提出了一种基于U-Net的全自动框架，用于猕猴示踪数据中的纤维束分割，显著提升了稀疏束的检测并降低了错误率。


<details>
  <summary>Details</summary>
Motivation: 传统的手动注释纤维束方法耗时且现有自动化方法存在局限性，需要一种更高效、准确的解决方案。

Method: 采用U-Net架构，结合大块尺寸、前景感知采样和半监督预训练。

Result: 稀疏束检测提升20%，误发现率降低40%，支持独立切片分析。

Conclusion: 该框架为大规模解剖示踪数据自动化分析提供了高效工具，有助于优化dMRI追踪方法。

Abstract: Anatomic tracer studies are critical for validating and improving diffusion
MRI (dMRI) tractography. However, large-scale analysis of data from such
studies is hampered by the labor-intensive process of annotating fiber bundles
manually on histological slides. Existing automated methods often miss sparse
bundles or require complex post-processing across consecutive sections,
limiting their flexibility and generalizability. We present a streamlined,
fully automated framework for fiber bundle segmentation in macaque tracer data,
based on a U-Net architecture with large patch sizes, foreground aware
sampling, and semisupervised pre-training. Our approach eliminates common
errors such as mislabeling terminals as bundles, improves detection of sparse
bundles by over 20% and reduces the False Discovery Rate (FDR) by 40% compared
to the state-of-the-art, all while enabling analysis of standalone slices. This
new framework will facilitate the automated analysis of anatomic tracing data
at a large scale, generating more ground-truth data that can be used to
validate and optimize dMRI tractography methods.

</details>


### [134] [Empirical Evidences for the Effects of Feature Diversity in Open Set Recognition and Continual Learning](https://arxiv.org/abs/2508.13005)
*Jiawen Xu,Odej Kao*

Main category: cs.CV

TL;DR: 增强特征多样性有助于开放集识别和持续学习。


<details>
  <summary>Details</summary>
Motivation: 探讨特征多样性在开放集识别和持续学习中的作用。

Method: 通过实证研究验证特征多样性的影响。

Result: 特征多样性提升开放集样本识别能力，并促进持续学习中的数据保留和新数据整合。

Conclusion: 研究结果可为这两个领域的实践方法和理论理解提供启发。

Abstract: Open set recognition (OSR) and continual learning are two critical challenges
in machine learning, focusing respectively on detecting novel classes at
inference time and updating models to incorporate the new classes. While many
recent approaches have addressed these problems, particularly OSR, by
heuristically promoting feature diversity, few studies have directly examined
the role that feature diversity plays in tackling them. In this work, we
provide empirical evidence that enhancing feature diversity improves the
recognition of open set samples. Moreover, increased feature diversity also
facilitates both the retention of previously learned data and the integration
of new data in continual learning. We hope our findings can inspire further
research into both practical methods and theoretical understanding in these
domains.

</details>


### [135] [Lumen: Consistent Video Relighting and Harmonious Background Replacement with Video Generative Models](https://arxiv.org/abs/2508.12945)
*Jianshu Zeng,Yuxuan Liu,Yutong Feng,Chenxuan Miao,Zixiang Gao,Jiwang Qu,Jianzhang Zhang,Bin Wang,Kun Yuan*

Main category: cs.CV

TL;DR: Lumen是一个基于大规模视频生成模型的端到端视频重光照框架，通过文本描述控制光照和背景，结合合成和真实视频数据集进行训练，实现一致的光照调整和前景保留。


<details>
  <summary>Details</summary>
Motivation: 视频重光照任务需要替换背景并调整前景光照，同时保持前景属性（如反照率）和时间一致性。现有高质量配对视频数据稀缺，因此需要构建混合数据集。

Method: 利用3D渲染引擎合成视频对，并结合HDR光照模拟补充真实视频数据。通过联合训练课程和域感知适配器，分离重光照和域外观分布的学习。

Result: Lumen能够生成具有一致光照和严格前景保留的电影级重光照视频，实验证明其在前景保留和视频一致性评估中表现优异。

Conclusion: Lumen通过混合数据集和域感知训练策略，有效解决了视频重光照任务中的光照一致性和前景保留问题。

Abstract: Video relighting is a challenging yet valuable task, aiming to replace the
background in videos while correspondingly adjusting the lighting in the
foreground with harmonious blending. During translation, it is essential to
preserve the original properties of the foreground, e.g., albedo, and propagate
consistent relighting among temporal frames. In this paper, we propose Lumen,
an end-to-end video relighting framework developed on large-scale video
generative models, receiving flexible textual description for instructing the
control of lighting and background. Considering the scarcity of high-qualified
paired videos with the same foreground in various lighting conditions, we
construct a large-scale dataset with a mixture of realistic and synthetic
videos. For the synthetic domain, benefiting from the abundant 3D assets in the
community, we leverage advanced 3D rendering engine to curate video pairs in
diverse environments. For the realistic domain, we adapt a HDR-based lighting
simulation to complement the lack of paired in-the-wild videos. Powered by the
aforementioned dataset, we design a joint training curriculum to effectively
unleash the strengths of each domain, i.e., the physical consistency in
synthetic videos, and the generalized domain distribution in realistic videos.
To implement this, we inject a domain-aware adapter into the model to decouple
the learning of relighting and domain appearance distribution. We construct a
comprehensive benchmark to evaluate Lumen together with existing methods, from
the perspectives of foreground preservation and video consistency assessment.
Experimental results demonstrate that Lumen effectively edit the input into
cinematic relighted videos with consistent lighting and strict foreground
preservation. Our project page: https://lumen-relight.github.io/

</details>


### [136] [Eyes on the Image: Gaze Supervised Multimodal Learning for Chest X-ray Diagnosis and Report Generation](https://arxiv.org/abs/2508.13068)
*Tanjim Islam Riju,Shuchismita Anwar,Saman Sarker Joy,Farig Sadeque,Swakkhar Shatabda*

Main category: cs.CV

TL;DR: 提出了一种两阶段多模态框架，结合放射科医生的眼动数据提升胸部X光片的疾病分类和报告生成效果。


<details>
  <summary>Details</summary>
Motivation: 利用眼动数据增强疾病分类和报告生成的准确性和可解释性。

Method: 第一阶段采用注视引导的对比学习架构，结合多种损失函数；第二阶段通过模块化流程生成区域感知的报告。

Result: 疾病分类的F1分数提升5.7%，AUC提升3.41%；报告生成质量也有所提高。

Conclusion: 眼动数据的整合显著提升了分类性能和报告的可解释性。

Abstract: We propose a two-stage multimodal framework that enhances disease
classification and region-aware radiology report generation from chest X-rays,
leveraging the MIMIC-Eye dataset. In the first stage, we introduce a
gaze-guided contrastive learning architecture for disease classification. It
integrates visual features, clinical labels, bounding boxes, and radiologist
eye-tracking signals and is equipped with a novel multi-term gaze-attention
loss combining MSE, KL divergence, correlation, and center-of-mass alignment.
Incorporating fixations improves F1 score from 0.597 to 0.631 (+5.70%) and AUC
from 0.821 to 0.849 (+3.41%), while also improving precision and recall,
highlighting the effectiveness of gaze-informed attention supervision. In the
second stage, we present a modular report generation pipeline that extracts
confidence-weighted diagnostic keywords, maps them to anatomical regions using
a curated dictionary constructed from domain-specific priors, and generates
region-aligned sentences via structured prompts. This pipeline improves report
quality as measured by clinical keyword recall and ROUGE overlap. Our results
demonstrate that integrating gaze data improves both classification performance
and the interpretability of generated medical reports.

</details>


### [137] [MaskSem: Semantic-Guided Masking for Learning 3D Hybrid High-Order Motion Representation](https://arxiv.org/abs/2508.12948)
*Wei Wei,Shaojie Zhang,Yonghao Dang,Jianqin Yin*

Main category: cs.CV

TL;DR: MaskSem是一种新颖的语义引导掩码方法，用于学习3D混合高阶运动表示，通过结合低阶和高阶运动模式提升骨架动作识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有自监督骨架动作识别方法局限于少数关节和低阶运动模式，难以理解复杂运动模式。

Method: 提出MaskSem，利用基于相对运动的Grad-CAM引导关节掩码，并结合低阶速度和高阶加速度作为重建目标。

Result: 在NTU60、NTU120和PKU-MMD数据集上，MaskSem结合普通Transformer提升了骨架动作识别性能。

Conclusion: MaskSem通过语义引导掩码和混合高阶运动学习，更适合人机交互应用。

Abstract: Human action recognition is a crucial task for intelligent robotics,
particularly within the context of human-robot collaboration research. In
self-supervised skeleton-based action recognition, the mask-based
reconstruction paradigm learns the spatial structure and motion patterns of the
skeleton by masking joints and reconstructing the target from unlabeled data.
However, existing methods focus on a limited set of joints and low-order motion
patterns, limiting the model's ability to understand complex motion patterns.
To address this issue, we introduce MaskSem, a novel semantic-guided masking
method for learning 3D hybrid high-order motion representations. This novel
framework leverages Grad-CAM based on relative motion to guide the masking of
joints, which can be represented as the most semantically rich temporal
orgions. The semantic-guided masking process can encourage the model to explore
more discriminative features. Furthermore, we propose using hybrid high-order
motion as the reconstruction target, enabling the model to learn multi-order
motion patterns. Specifically, low-order motion velocity and high-order motion
acceleration are used together as the reconstruction target. This approach
offers a more comprehensive description of the dynamic motion process,
enhancing the model's understanding of motion patterns. Experiments on the
NTU60, NTU120, and PKU-MMD datasets show that MaskSem, combined with a vanilla
transformer, improves skeleton-based action recognition, making it more
suitable for applications in human-robot interaction.

</details>


### [138] [Breaking Reward Collapse: Adaptive Reinforcement for Open-ended Medical Reasoning with Enhanced Semantic Discrimination](https://arxiv.org/abs/2508.12957)
*Yizhou Liu,Jingwei Wei,Zizhi Chen,Minghao Han,Xukun Zhang,Keliang Liu,Lihua Zhang*

Main category: cs.CV

TL;DR: ARMed提出了一种自适应强化学习框架，用于开放式的医学视觉问答，显著提升了模型的准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有强化微调方法在医学影像中主要针对封闭式问题，而开放式问题更贴近临床实践，但研究较少。模型基于语义奖励常出现奖励崩溃问题。

Method: ARMed结合领域知识进行监督微调，再通过强化学习结合文本正确性和自适应语义奖励提升推理质量。

Result: 在六个医学VQA基准测试中，ARMed在域内任务上提升32.64%，域外任务上提升11.65%。

Conclusion: 奖励区分性在医学强化学习中至关重要，语义引导奖励有望实现稳健且临床意义的多模态推理。

Abstract: Reinforcement learning (RL) with rule-based rewards has demonstrated strong
potential in enhancing the reasoning and generalization capabilities of
vision-language models (VLMs) and large language models (LLMs), while reducing
computational overhead. However, its application in medical imaging remains
underexplored. Existing reinforcement fine-tuning (RFT) approaches in this
domain primarily target closed-ended visual question answering (VQA), limiting
their applicability to real-world clinical reasoning. In contrast, open-ended
medical VQA better reflects clinical practice but has received limited
attention. While some efforts have sought to unify both formats via
semantically guided RL, we observe that model-based semantic rewards often
suffer from reward collapse, where responses with significant semantic
differences receive similar scores. To address this, we propose ARMed (Adaptive
Reinforcement for Medical Reasoning), a novel RL framework for open-ended
medical VQA. ARMed first incorporates domain knowledge through supervised
fine-tuning (SFT) on chain-of-thought data, then applies reinforcement learning
with textual correctness and adaptive semantic rewards to enhance reasoning
quality. We evaluate ARMed on six challenging medical VQA benchmarks. Results
show that ARMed consistently boosts both accuracy and generalization, achieving
a 32.64% improvement on in-domain tasks and an 11.65% gain on out-of-domain
benchmarks. These results highlight the critical role of reward
discriminability in medical RL and the promise of semantically guided rewards
for enabling robust and clinically meaningful multimodal reasoning.

</details>


### [139] [Multi-Phase Automated Segmentation of Dental Structures in CBCT Using a Lightweight Auto3DSeg and SegResNet Implementation](https://arxiv.org/abs/2508.12962)
*Dominic LaBella,Keshav Jha,Jared Robbins,Esther Yu*

Main category: cs.CV

TL;DR: DLaBella29团队在MICCAI 2025 ToothFairy3挑战赛中提出了一种基于深度学习的多类别牙齿分割方法，使用3D SegResNet架构和MONAI Auto3DSeg框架，在63个CBCT扫描数据上训练，最终在验证集上平均Dice得分为0.87。


<details>
  <summary>Details</summary>
Motivation: 自动化牙齿分割在CBCT中能高效辅助病理识别（如牙髓或根尖周病变）和头颈癌患者的放射治疗规划，从而改善患者护理。

Method: 采用MONAI Auto3DSeg框架和3D SegResNet架构，通过5折交叉验证训练，预处理包括图像重采样和强度裁剪，分两阶段进行分割（先分割下颌骨，再分割神经结构）。

Result: 在ToothFairy3挑战赛的验证集上平均Dice得分为0.87。

Conclusion: 该方法展示了自动化牙齿分割在放射肿瘤学中改善患者护理的潜力，并提供了详细的临床背景、数据准备和模型开发过程。

Abstract: Cone-beam computed tomography (CBCT) has become an invaluable imaging
modality in dentistry, enabling 3D visualization of teeth and surrounding
structures for diagnosis and treatment planning. Automated segmentation of
dental structures in CBCT can efficiently assist in identifying pathology
(e.g., pulpal or periapical lesions) and facilitate radiation therapy planning
in head and neck cancer patients. We describe the DLaBella29 team's approach
for the MICCAI 2025 ToothFairy3 Challenge, which involves a deep learning
pipeline for multi-class tooth segmentation. We utilized the MONAI Auto3DSeg
framework with a 3D SegResNet architecture, trained on a subset of the
ToothFairy3 dataset (63 CBCT scans) with 5-fold cross-validation. Key
preprocessing steps included image resampling to 0.6 mm isotropic resolution
and intensity clipping. We applied an ensemble fusion using Multi-Label STAPLE
on the 5-fold predictions to infer a Phase 1 segmentation and then conducted
tight cropping around the easily segmented Phase 1 mandible to perform Phase 2
segmentation on the smaller nerve structures. Our method achieved an average
Dice of 0.87 on the ToothFairy3 challenge out-of-sample validation set. This
paper details the clinical context, data preparation, model development,
results of our approach, and discusses the relevance of automated dental
segmentation for improving patient care in radiation oncology.

</details>


### [140] [GazeDETR: Gaze Detection using Disentangled Head and Gaze Representations](https://arxiv.org/abs/2508.12966)
*Ryan Anthony Jalova de Belen,Gelareh Mohammadi,Arcot Sowmya*

Main category: cs.CV

TL;DR: GazeDETR是一种新型端到端架构，通过两个解耦的解码器分别学习头部定位和视线预测，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 视线交流在社交互动中很重要，但现有端到端模型使用单一解码器，导致头部定位和视线预测任务表征纠缠。

Method: 提出GazeDETR，采用两个解耦的解码器分别处理头部定位（局部信息）和视线预测（局部+全局信息）。

Result: 在GazeFollow等数据集上达到SOTA，显著超越现有端到端模型。

Conclusion: 解耦设计能更有效学习任务专属表征，提升视线预测性能。

Abstract: Gaze communication plays a crucial role in daily social interactions.
Quantifying this behavior can help in human-computer interaction and digital
phenotyping. While end-to-end models exist for gaze target detection, they only
utilize a single decoder to simultaneously localize human heads and predict
their corresponding gaze (e.g., 2D points or heatmap) in a scene. This
multitask learning approach generates a unified and entangled representation
for human head localization and gaze location prediction. Herein, we propose
GazeDETR, a novel end-to-end architecture with two disentangled decoders that
individually learn unique representations and effectively utilize coherent
attentive fields for each subtask. More specifically, we demonstrate that its
human head predictor utilizes local information, while its gaze decoder
incorporates both local and global information. Our proposed architecture
achieves state-of-the-art results on the GazeFollow, VideoAttentionTarget and
ChildPlay datasets. It outperforms existing end-to-end models with a notable
margin.

</details>


### [141] [Compact Attention: Exploiting Structured Spatio-Temporal Sparsity for Fast Video Generation](https://arxiv.org/abs/2508.12969)
*Qirui Li,Guangcong Zheng,Qi Zhao,Jie Li,Bin Dong,Yiwu Yao,Xi Li*

Main category: cs.CV

TL;DR: 提出了一种名为Compact Attention的硬件感知加速框架，通过自适应分块策略、时间变化窗口和自动配置搜索算法，显著提升了视频生成中注意力计算的效率。


<details>
  <summary>Details</summary>
Motivation: 自注意力机制的计算需求对基于Transformer的视频生成（尤其是超长序列合成）提出了挑战，现有方法未能充分利用视频数据的时空冗余性。

Method: 通过分析视频扩散Transformer的注意力矩阵，发现其具有结构化但异质的稀疏模式，提出了Compact Attention框架，包含自适应分块、时间变化窗口和自动配置搜索。

Result: 在单GPU设置下，注意力计算实现了1.6~2.5倍的加速，同时保持了与全注意力基线相当的视觉质量。

Conclusion: Compact Attention通过结构化稀疏性利用，为高效长视频生成提供了原则性方法。

Abstract: The computational demands of self-attention mechanisms pose a critical
challenge for transformer-based video generation, particularly in synthesizing
ultra-long sequences. Current approaches, such as factorized attention and
fixed sparse patterns, fail to fully exploit the inherent spatio-temporal
redundancies in video data. Through systematic analysis of video diffusion
transformers (DiT), we uncover a key insight: Attention matrices exhibit
structured, yet heterogeneous sparsity patterns, where specialized heads
dynamically attend to distinct spatiotemporal regions (e.g., local pattern,
cross-shaped pattern, or global pattern). Existing sparse attention methods
either impose rigid constraints or introduce significant overhead, limiting
their effectiveness. To address this, we propose Compact Attention, a
hardware-aware acceleration framework featuring three innovations: 1) Adaptive
tiling strategies that approximate diverse spatial interaction patterns via
dynamic tile grouping, 2) Temporally varying windows that adjust sparsity
levels based on frame proximity, and 3) An automated configuration search
algorithm that optimizes sparse patterns while preserving critical attention
pathways. Our method achieves 1.6~2.5x acceleration in attention computation on
single-GPU setups while maintaining comparable visual quality with
full-attention baselines. This work provides a principled approach to unlocking
efficient long-form video generation through structured sparsity exploitation.
Project Page: https://yo-ava.github.io/Compact-Attention.github.io/

</details>


### [142] [Dextr: Zero-Shot Neural Architecture Search with Singular Value Decomposition and Extrinsic Curvature](https://arxiv.org/abs/2508.12977)
*Rohan Asthana,Joschua Conrad,Maurits Ortmanns,Vasileios Belagiannis*

Main category: cs.CV

TL;DR: 提出了一种无需标记数据的零成本代理方法，通过结合收敛性、泛化性和表达能力，利用SVD和网络输出外曲率设计代理，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有代理方法依赖标记数据且仅关注收敛性或表达能力，无法满足实际需求。

Method: 利用层特征的SVD和网络输出外曲率设计代理，结合收敛性、泛化性和表达能力。

Result: 在多个基准测试和NAS任务中表现优异，且高效。

Conclusion: 该方法有效解决了标记数据依赖问题，并在性能上超越现有方法。

Abstract: Zero-shot Neural Architecture Search (NAS) typically optimises the
architecture search process by exploiting the network or gradient properties at
initialisation through zero-cost proxies. The existing proxies often rely on
labelled data, which is usually unavailable in real-world settings.
Furthermore, the majority of the current methods focus either on optimising the
convergence and generalisation attributes or solely on the expressivity of the
network architectures. To address both limitations, we first demonstrate how
channel collinearity affects the convergence and generalisation properties of a
neural network. Then, by incorporating the convergence, generalisation and
expressivity in one approach, we propose a zero-cost proxy that omits the
requirement of labelled data for its computation. In particular, we leverage
the Singular Value Decomposition (SVD) of the neural network layer features and
the extrinsic curvature of the network output to design our proxy. %As a
result, the proposed proxy is formulated as the simplified harmonic mean of the
logarithms of two key components: the sum of the inverse of the feature
condition number and the extrinsic curvature of the network output. Our
approach enables accurate prediction of network performance on test data using
only a single label-free data sample. Our extensive evaluation includes a total
of six experiments, including the Convolutional Neural Network (CNN) search
space, i.e. DARTS and the Transformer search space, i.e. AutoFormer. The
proposed proxy demonstrates a superior performance on multiple correlation
benchmarks, including NAS-Bench-101, NAS-Bench-201, and
TransNAS-Bench-101-micro; as well as on the NAS task within the DARTS and the
AutoFormer search space, all while being notably efficient. The code is
available at https://github.com/rohanasthana/Dextr.

</details>


### [143] [Omni Survey for Multimodality Analysis in Visual Object Tracking](https://arxiv.org/abs/2508.13000)
*Zhangyong Tang,Tianyang Xu,Xuefeng Zhu,Hui Li,Shaochuan Zhao,Tao Zhou,Chunyang Cheng,Xiaojun Wu,Josef Kittler*

Main category: cs.CV

TL;DR: 本文综述了多模态视觉目标跟踪（MMVOT）的关键任务，从数据收集、模态对齐、模型设计到评估，全面分析了其挑战与方法，并探讨了多模态跟踪是否总是优于单模态跟踪的问题。


<details>
  <summary>Details</summary>
Motivation: 智能城市的发展产生了大量多模态数据，多模态视觉目标跟踪（MMVOT）成为关键任务。本文旨在全面分析MMVOT的各个方面，包括数据、方法和评估，并探讨其实际应用效果。

Method: 通过分类现有MMVOT方法，基于处理可见光（RGB）和其他模态（如热红外、深度等）的不同方式，并分析数据集的分布特点。

Result: 揭示了现有MMVOT数据集的显著长尾分布和动物类别的缺乏，并探讨了多模态跟踪的优势与局限性。

Conclusion: 多模态跟踪并非在所有情况下都优于单模态跟踪，其效果取决于具体场景和信息融合方式。未来研究需关注数据集的多样性和模态融合的优化。

Abstract: The development of smart cities has led to the generation of massive amounts
of multi-modal data in the context of a range of tasks that enable a
comprehensive monitoring of the smart city infrastructure and services. This
paper surveys one of the most critical tasks, multi-modal visual object
tracking (MMVOT), from the perspective of multimodality analysis. Generally,
MMVOT differs from single-modal tracking in four key aspects, data collection,
modality alignment and annotation, model designing, and evaluation.
Accordingly, we begin with an introduction to the relevant data modalities,
laying the groundwork for their integration. This naturally leads to a
discussion of challenges of multi-modal data collection, alignment, and
annotation. Subsequently, existing MMVOT methods are categorised, based on
different ways to deal with visible (RGB) and X modalities: programming the
auxiliary X branch with replicated or non-replicated experimental
configurations from the RGB branch. Here X can be thermal infrared (T), depth
(D), event (E), near infrared (NIR), language (L), or sonar (S). The final part
of the paper addresses evaluation and benchmarking. In summary, we undertake an
omni survey of all aspects of multi-modal visual object tracking (VOT),
covering six MMVOT tasks and featuring 338 references in total. In addition, we
discuss the fundamental rhetorical question: Is multi-modal tracking always
guaranteed to provide a superior solution to unimodal tracking with the help of
information fusion, and if not, in what circumstances its application is
beneficial. Furthermore, for the first time in this field, we analyse the
distributions of the object categories in the existing MMVOT datasets,
revealing their pronounced long-tail nature and a noticeable lack of animal
categories when compared with RGB datasets.

</details>


### [144] [SlimComm: Doppler-Guided Sparse Queries for Bandwidth-Efficient Cooperative 3-D Perception](https://arxiv.org/abs/2508.13007)
*Melih Yazgan,Qiyuan Wu,Iramm Hamdard,Shiqi Li,J. Marius Zoellner*

Main category: cs.CV

TL;DR: SlimComm是一个通信高效的协作感知框架，通过4D雷达多普勒和查询驱动稀疏方案，显著降低带宽需求。


<details>
  <summary>Details</summary>
Motivation: 解决协作感知中密集BEV特征图传输导致的带宽问题。

Method: 结合4D雷达多普勒，构建动态地图并生成两类查询（参考查询和探索查询），仅交换查询相关特征。

Result: 带宽降低90%，性能优于或匹配现有基线。

Conclusion: SlimComm在保持精度的同时大幅减少通信开销，适用于高密度交通和遮挡场景。

Abstract: Collaborative perception allows connected autonomous vehicles (CAVs) to
overcome occlusion and limited sensor range by sharing intermediate features.
Yet transmitting dense Bird's-Eye-View (BEV) feature maps can overwhelm the
bandwidth available for inter-vehicle communication. We present SlimComm, a
communication-efficient framework that integrates 4D radar Doppler with a
query-driven sparse scheme. SlimComm builds a motion-centric dynamic map to
distinguish moving from static objects and generates two query types: (i)
reference queries on dynamic and high-confidence regions, and (ii) exploratory
queries probing occluded areas via a two-stage offset. Only query-specific BEV
features are exchanged and fused through multi-scale gated deformable
attention, reducing payload while preserving accuracy. For evaluation, we
release OPV2V-R and Adver-City-R, CARLA-based datasets with per-point Doppler
radar. SlimComm achieves up to 90% lower bandwidth than full-map sharing while
matching or surpassing prior baselines across varied traffic densities and
occlusions. Dataset and code will be available at: https://url.fzi.de/SlimComm.

</details>


### [145] [Matrix-Game 2.0: An Open-Source, Real-Time, and Streaming Interactive World Model](https://arxiv.org/abs/2508.13009)
*Xianglong He,Chunli Peng,Zexiang Liu,Boyang Wang,Yifan Zhang,Qi Cui,Fei Kang,Biao Jiang,Mengyin An,Yangyang Ren,Baixin Xu,Hao-Xiang Guo,Kaixiong Gong,Cyrus Wu,Wei Li,Xuchen Song,Yang Liu,Eric Li,Yahui Zhou*

Main category: cs.CV

TL;DR: Matrix-Game 2.0 是一个基于扩散模型的交互式世界模型，通过少步自回归扩散实时生成长视频，解决了现有模型因双向注意力和长推理步骤导致的实时性能问题。


<details>
  <summary>Details</summary>
Motivation: 现有交互式世界模型依赖双向注意力和长推理步骤，限制了实时性能，难以模拟需要即时更新的真实世界动态。

Method: 提出三个关键组件：可扩展的数据生产管道、动作注入模块和基于因果架构的少步蒸馏，实现实时视频生成。

Result: Matrix-Game 2.0 能以25 FPS的速度生成高质量分钟级视频。

Conclusion: 该模型通过开源权重和代码库，推动了交互式世界建模的研究。

Abstract: Recent advances in interactive video generations have demonstrated diffusion
model's potential as world models by capturing complex physical dynamics and
interactive behaviors. However, existing interactive world models depend on
bidirectional attention and lengthy inference steps, severely limiting
real-time performance. Consequently, they are hard to simulate real-world
dynamics, where outcomes must update instantaneously based on historical
context and current actions. To address this, we present Matrix-Game 2.0, an
interactive world model generates long videos on-the-fly via few-step
auto-regressive diffusion. Our framework consists of three key components: (1)
A scalable data production pipeline for Unreal Engine and GTA5 environments to
effectively produce massive amounts (about 1200 hours) of video data with
diverse interaction annotations; (2) An action injection module that enables
frame-level mouse and keyboard inputs as interactive conditions; (3) A few-step
distillation based on the casual architecture for real-time and streaming video
generation. Matrix Game 2.0 can generate high-quality minute-level videos
across diverse scenes at an ultra-fast speed of 25 FPS. We open-source our
model weights and codebase to advance research in interactive world modeling.

</details>


### [146] [EgoTwin: Dreaming Body and View in First Person](https://arxiv.org/abs/2508.13013)
*Jingqiao Xiu,Fangzhou Hong,Yicong Li,Mengze Li,Wentao Wang,Sirui Han,Liang Pan,Ziwei Liu*

Main category: cs.CV

TL;DR: 论文提出EgoTwin框架，解决第一人称视频与人体运动联合生成任务，通过头部中心运动表示和因果交互机制实现视频与运动的一致性。


<details>
  <summary>Details</summary>
Motivation: 第一人称视频生成尚未充分探索，需同时建模视角内容和穿戴者身体运动引起的相机运动模式。

Method: 提出EgoTwin框架，基于扩散Transformer架构，引入头部中心运动表示和因果交互机制。

Result: 实验证明EgoTwin在视频与运动一致性生成上的有效性。

Conclusion: EgoTwin为第一人称视频与运动联合生成提供了有效解决方案。

Abstract: While exocentric video synthesis has achieved great progress, egocentric
video generation remains largely underexplored, which requires modeling
first-person view content along with camera motion patterns induced by the
wearer's body movements. To bridge this gap, we introduce a novel task of joint
egocentric video and human motion generation, characterized by two key
challenges: 1) Viewpoint Alignment: the camera trajectory in the generated
video must accurately align with the head trajectory derived from human motion;
2) Causal Interplay: the synthesized human motion must causally align with the
observed visual dynamics across adjacent video frames. To address these
challenges, we propose EgoTwin, a joint video-motion generation framework built
on the diffusion transformer architecture. Specifically, EgoTwin introduces a
head-centric motion representation that anchors the human motion to the head
joint and incorporates a cybernetics-inspired interaction mechanism that
explicitly captures the causal interplay between video and motion within
attention operations. For comprehensive evaluation, we curate a large-scale
real-world dataset of synchronized text-video-motion triplets and design novel
metrics to assess video-motion consistency. Extensive experiments demonstrate
the effectiveness of the EgoTwin framework.

</details>


### [147] [HierAdaptMR: Cross-Center Cardiac MRI Reconstruction with Hierarchical Feature Adapters](https://arxiv.org/abs/2508.13026)
*Ruru Xu,Ilkay Oksuz*

Main category: cs.CV

TL;DR: HierAdaptMR提出了一种分层特征适应框架，通过参数高效的适配器解决多中心心脏MRI重建中的域偏移问题。


<details>
  <summary>Details</summary>
Motivation: 深度学习在心脏MRI重建中面临多中心数据域偏移的挑战，不同扫描仪配置和成像协议导致性能下降。

Method: 采用分层适配器（协议级和中心级）结合变分展开主干，通过多尺度SSIM损失和频域增强优化。

Result: 在CMRxRecon2025数据集上验证，跨中心泛化能力优异，重建质量保持。

Conclusion: HierAdaptMR有效解决了多中心域偏移问题，提升了心脏MRI重建的泛化性和鲁棒性。

Abstract: Deep learning-based cardiac MRI reconstruction faces significant domain shift
challenges when deployed across multiple clinical centers with heterogeneous
scanner configurations and imaging protocols. We propose HierAdaptMR, a
hierarchical feature adaptation framework that addresses multi-level domain
variations through parameter-efficient adapters. Our method employs
Protocol-Level Adapters for sequence-specific characteristics and Center-Level
Adapters for scanner-dependent variations, built upon a variational unrolling
backbone. A Universal Adapter enables generalization to entirely unseen centers
through stochastic training that learns center-invariant adaptations. The
framework utilizes multi-scale SSIM loss with frequency domain enhancement and
contrast-adaptive weighting for robust optimization. Comprehensive evaluation
on the CMRxRecon2025 dataset spanning 5+ centers, 10+ scanners, and 9
modalities demonstrates superior cross-center generalization while maintaining
reconstruction quality. code: https://github.com/Ruru-Xu/HierAdaptMR

</details>


### [148] [IntelliCap: Intelligent Guidance for Consistent View Sampling](https://arxiv.org/abs/2508.13043)
*Ayaka Yasunaga,Hideo Saito,Dieter Schmalstieg,Shohei Mori*

Main category: cs.CV

TL;DR: 提出了一种新的多尺度扫描可视化技术，通过语义分割和视觉语言模型指导用户采集图像，以优化视图合成质量。


<details>
  <summary>Details</summary>
Motivation: 高质量的视图合成需要均匀且密集的视图采样，但人类操作者往往难以满足这些要求。现有方法忽略了多尺度场景和视图依赖的材料特性。

Method: 利用语义分割和视觉语言模型识别重要对象，生成球形代理指导用户扫描。

Result: 在真实场景中表现优于传统视图采样策略。

Conclusion: 该方法能有效提升视图合成的输入图像质量。

Abstract: Novel view synthesis from images, for example, with 3D Gaussian splatting,
has made great progress. Rendering fidelity and speed are now ready even for
demanding virtual reality applications. However, the problem of assisting
humans in collecting the input images for these rendering algorithms has
received much less attention. High-quality view synthesis requires uniform and
dense view sampling. Unfortunately, these requirements are not easily addressed
by human camera operators, who are in a hurry, impatient, or lack understanding
of the scene structure and the photographic process. Existing approaches to
guide humans during image acquisition concentrate on single objects or neglect
view-dependent material characteristics. We propose a novel situated
visualization technique for scanning at multiple scales. During the scanning of
a scene, our method identifies important objects that need extended image
coverage to properly represent view-dependent appearance. To this end, we
leverage semantic segmentation and category identification, ranked by a
vision-language model. Spherical proxies are generated around highly ranked
objects to guide the user during scanning. Our results show superior
performance in real scenes compared to conventional view sampling strategies.

</details>


### [149] [Odo: Depth-Guided Diffusion for Identity-Preserving Body Reshaping](https://arxiv.org/abs/2508.13065)
*Siddharth Khandelwal,Sridhar Kamath,Arjun Jain*

Main category: cs.CV

TL;DR: 论文提出了一种基于扩散模型的人体形状编辑方法Odo，并引入首个大规模数据集，显著提升了编辑的逼真度和准确性。


<details>
  <summary>Details</summary>
Motivation: 当前人体形状编辑方法依赖3D可变形模型或图像变形，常导致不真实的身体比例和纹理失真，且缺乏公开数据集。

Method: 提出Odo方法，结合冻结UNet保留细节和ControlNet引导形状变换，使用目标SMPL深度图。

Result: 实验显示，Odo的顶点重建误差低至7.5mm，优于基线方法的13.6mm，且结果更逼真。

Conclusion: Odo方法在人体形状编辑中表现出色，解决了现有方法的局限性，并提供了高质量的数据集支持。

Abstract: Human shape editing enables controllable transformation of a person's body
shape, such as thin, muscular, or overweight, while preserving pose, identity,
clothing, and background. Unlike human pose editing, which has advanced
rapidly, shape editing remains relatively underexplored. Current approaches
typically rely on 3D morphable models or image warping, often introducing
unrealistic body proportions, texture distortions, and background
inconsistencies due to alignment errors and deformations. A key limitation is
the lack of large-scale, publicly available datasets for training and
evaluating body shape manipulation methods. In this work, we introduce the
first large-scale dataset of 18,573 images across 1523 subjects, specifically
designed for controlled human shape editing. It features diverse variations in
body shape, including fat, muscular and thin, captured under consistent
identity, clothing, and background conditions. Using this dataset, we propose
Odo, an end-to-end diffusion-based method that enables realistic and intuitive
body reshaping guided by simple semantic attributes. Our approach combines a
frozen UNet that preserves fine-grained appearance and background details from
the input image with a ControlNet that guides shape transformation using target
SMPL depth maps. Extensive experiments demonstrate that our method outperforms
prior approaches, achieving per-vertex reconstruction errors as low as 7.5mm,
significantly lower than the 13.6mm observed in baseline methods, while
producing realistic results that accurately match the desired target shapes.

</details>


### [150] [ID-Card Synthetic Generation: Toward a Simulated Bona fide Dataset](https://arxiv.org/abs/2508.13078)
*Qingwen Zeng,Juan E. Tapia,Izan Garcia,Juan M. Espin,Christoph Busch*

Main category: cs.CV

TL;DR: 提出了一种使用Stable Diffusion生成合成真实图像的方法，以改善PAD系统的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 由于真实图像数量有限且攻击手段多样化，现有PAD系统训练不足，需要生成更多真实图像样本。

Method: 利用Stable Diffusion生成合成真实图像，并在从头训练的系统及商业解决方案中评估。

Result: 生成的图像被识别为真实图像，提升了检测性能并缓解了数据限制问题。

Conclusion: 该方法为PAD系统提供了新的数据增强途径，有助于提升系统性能。

Abstract: Nowadays, the development of a Presentation Attack Detection (PAD) system for
ID cards presents a challenge due to the lack of images available to train a
robust PAD system and the increase in diversity of possible attack instrument
species. Today, most algorithms focus on generating attack samples and do not
take into account the limited number of bona fide images. This work is one of
the first to propose a method for mimicking bona fide images by generating
synthetic versions of them using Stable Diffusion, which may help improve the
generalisation capabilities of the detector. Furthermore, the new images
generated are evaluated in a system trained from scratch and in a commercial
solution. The PAD system yields an interesting result, as it identifies our
images as bona fide, which has a positive impact on detection performance and
data restrictions.

</details>


### [151] [Checkmate: interpretable and explainable RSVQA is the endgame](https://arxiv.org/abs/2508.13086)
*Lucrezia Tosato,Christel Tartini Chappuis,Syrielle Montariol,Flora Weissgerber,Sylvain Lobry,Devis Tuia*

Main category: cs.CV

TL;DR: 提出了一种新的RSVQA数据集Chessboard，并开发了可解释模型Checkmate，以提高遥感视觉问答系统的透明度和可信度。


<details>
  <summary>Details</summary>
Motivation: 解决当前RSVQA模型缺乏可解释性和数据集偏差导致的问题。

Method: 设计平衡的数据集Chessboard，并开发可解释模型Checkmate，通过关联图像单元格实现细粒度推理。

Result: 实验表明，该方法提高了模型的透明度和决策可信度。

Conclusion: Chessboard数据集和Checkmate模型为RSVQA系统提供了更可靠和可解释的解决方案。

Abstract: Remote Sensing Visual Question Answering (RSVQA) presents unique challenges
in ensuring that model decisions are both understandable and grounded in visual
content. Current models often suffer from a lack of interpretability and
explainability, as well as from biases in dataset distributions that lead to
shortcut learning. In this work, we tackle these issues by introducing a novel
RSVQA dataset, Chessboard, designed to minimize biases through 3'123'253
questions and a balanced answer distribution. Each answer is linked to one or
more cells within the image, enabling fine-grained visual reasoning.
  Building on this dataset, we develop an explainable and interpretable model
called Checkmate that identifies the image cells most relevant to its
decisions. Through extensive experiments across multiple model architectures,
we show that our approach improves transparency and supports more trustworthy
decision-making in RSVQA systems.

</details>


### [152] [DMS:Diffusion-Based Multi-Baseline Stereo Generation for Improving Self-Supervised Depth Estimation](https://arxiv.org/abs/2508.13091)
*Zihua Liu,Yizhou Li,Songyan Zhang,Masatoshi Okutomi*

Main category: cs.CV

TL;DR: 提出DMS方法，利用扩散模型生成新视角以解决自监督立体匹配和单目深度估计中的遮挡问题。


<details>
  <summary>Details</summary>
Motivation: 自监督方法在立体匹配和深度估计中因遮挡和视角问题导致的光度重建模糊性需要改进。

Method: 通过微调Stable Diffusion模型生成新视角（左-左、右-右及中间视角），补充遮挡像素。

Result: 实验显示DMS能减少35%异常值，并在多个数据集上达到SOTA性能。

Conclusion: DMS是一种无需额外成本的即插即用方法，显著提升自监督立体匹配和深度估计效果。

Abstract: While supervised stereo matching and monocular depth estimation have advanced
significantly with learning-based algorithms, self-supervised methods using
stereo images as supervision signals have received relatively less focus and
require further investigation. A primary challenge arises from ambiguity
introduced during photometric reconstruction, particularly due to missing
corresponding pixels in ill-posed regions of the target view, such as
occlusions and out-of-frame areas. To address this and establish explicit
photometric correspondences, we propose DMS, a model-agnostic approach that
utilizes geometric priors from diffusion models to synthesize novel views along
the epipolar direction, guided by directional prompts. Specifically, we
finetune a Stable Diffusion model to simulate perspectives at key positions:
left-left view shifted from the left camera, right-right view shifted from the
right camera, along with an additional novel view between the left and right
cameras. These synthesized views supplement occluded pixels, enabling explicit
photometric reconstruction. Our proposed DMS is a cost-free, ''plug-and-play''
method that seamlessly enhances self-supervised stereo matching and monocular
depth estimation, and relies solely on unlabeled stereo image pairs for both
training and synthesizing. Extensive experiments demonstrate the effectiveness
of our approach, with up to 35% outlier reduction and state-of-the-art
performance across multiple benchmark datasets.

</details>


### [153] [Real-Time Beach Litter Detection and Counting: A Comparative Analysis of RT-DETR Model Variants](https://arxiv.org/abs/2508.13101)
*Miftahul Huda,Arsyiah Azahra,Putri Maulida Chairani,Dimas Rizky Ramadhani,Nabila Azhari,Ade Lailani*

Main category: cs.CV

TL;DR: RT-DETR模型用于海滩垃圾检测，RT-DETR-X精度略高但计算成本大，RT-DETR-L在速度和精度间更平衡，适合实时部署。


<details>
  <summary>Details</summary>
Motivation: 海岸污染是全球性问题，需要自动化监测方案。

Method: 比较RT-DETR-L和RT-DETR-X在公开数据集上的性能。

Result: RT-DETR-X精度略高（mAP@50 0.816），但RT-DETR-L推理更快（20.1ms vs 34.5ms）。

Conclusion: RT-DETR-L更适合实时部署，平衡了速度和精度。

Abstract: Coastal pollution is a pressing global environmental issue, necessitating
scalable and automated solutions for monitoring and management. This study
investigates the efficacy of the Real-Time Detection Transformer (RT-DETR), a
state-of-the-art, end-to-end object detection model, for the automated
detection and counting of beach litter. A rigorous comparative analysis is
conducted between two model variants, RT-DETR-Large (RT-DETR-L) and
RT-DETR-Extra-Large (RT-DETR-X), trained on a publicly available dataset of
coastal debris. The evaluation reveals that the RT-DETR-X model achieves
marginally superior accuracy, with a mean Average Precision at 50\% IoU
(mAP@50) of 0.816 and a mAP@50-95 of 0.612, compared to the RT-DETR-L model's
0.810 and 0.606, respectively. However, this minor performance gain is realized
at a significant computational cost; the RT-DETR-L model demonstrates a
substantially faster inference time of 20.1 ms versus 34.5 ms for the
RT-DETR-X. The findings suggest that the RT-DETR-L model offers a more
practical and efficient solution for real-time, in-field deployment due to its
superior balance of processing speed and detection accuracy. This research
provides valuable insights into the application of advanced Transformer-based
detectors for environmental conservation, highlighting the critical trade-offs
between model complexity and operational viability.

</details>


### [154] [Motion2Motion: Cross-topology Motion Transfer with Sparse Correspondence](https://arxiv.org/abs/2508.13139)
*Ling-Hao Chen,Yuhong Zhang,Zixin Yin,Zhiyang Dou,Xin Chen,Jingbo Wang,Taku Komura,Lei Zhang*

Main category: cs.CV

TL;DR: Motion2Motion是一种无需训练的框架，用于在不同骨骼拓扑结构的角色之间高效传递动画。


<details>
  <summary>Details</summary>
Motivation: 解决不同骨骼拓扑结构角色间动画传递的挑战，尤其是缺乏大规模配对运动数据集的问题。

Method: 通过稀疏骨骼对应关系，仅需少量目标骨骼示例动作即可实现动画传递。

Result: 在相似骨骼和跨物种骨骼传递场景中均表现出高效可靠的性能。

Conclusion: Motion2Motion具有实际应用潜力，尤其在工业领域。代码和数据已公开。

Abstract: This work studies the challenge of transfer animations between characters
whose skeletal topologies differ substantially. While many techniques have
advanced retargeting techniques in decades, transfer motions across diverse
topologies remains less-explored. The primary obstacle lies in the inherent
topological inconsistency between source and target skeletons, which restricts
the establishment of straightforward one-to-one bone correspondences. Besides,
the current lack of large-scale paired motion datasets spanning different
topological structures severely constrains the development of data-driven
approaches. To address these limitations, we introduce Motion2Motion, a novel,
training-free framework. Simply yet effectively, Motion2Motion works with only
one or a few example motions on the target skeleton, by accessing a sparse set
of bone correspondences between the source and target skeletons. Through
comprehensive qualitative and quantitative evaluations, we demonstrate that
Motion2Motion achieves efficient and reliable performance in both
similar-skeleton and cross-species skeleton transfer scenarios. The practical
utility of our approach is further evidenced by its successful integration in
downstream applications and user interfaces, highlighting its potential for
industrial applications. Code and data are available at
https://lhchen.top/Motion2Motion.

</details>


### [155] [IGFuse: Interactive 3D Gaussian Scene Reconstruction via Multi-Scans Fusion](https://arxiv.org/abs/2508.13153)
*Wenhao Hu,Zesheng Li,Haonan Zhou,Liu Liu,Xuexiang Wen,Zhizhong Su,Xi Li,Gaoang Wang*

Main category: cs.CV

TL;DR: IGFuse是一种新框架，通过融合多次扫描的观测数据重建交互式高斯场景，解决遮挡和传感器覆盖不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖多阶段流程或密集扫描，易出错且难以扩展。

Method: 构建分割感知的高斯场，通过双向光度和语义一致性对齐扫描数据，引入伪中间场景状态和协作共剪枝策略。

Result: 实现了高保真渲染和对象级场景操控，无需密集观测或复杂流程。

Conclusion: 实验证明IGFuse对新场景配置有强泛化能力，适用于真实世界3D重建和仿真转移。

Abstract: Reconstructing complete and interactive 3D scenes remains a fundamental
challenge in computer vision and robotics, particularly due to persistent
object occlusions and limited sensor coverage. Multiview observations from a
single scene scan often fail to capture the full structural details. Existing
approaches typically rely on multi stage pipelines, such as segmentation,
background completion, and inpainting or require per-object dense scanning,
both of which are error-prone, and not easily scalable. We propose IGFuse, a
novel framework that reconstructs interactive Gaussian scene by fusing
observations from multiple scans, where natural object rearrangement between
captures reveal previously occluded regions. Our method constructs segmentation
aware Gaussian fields and enforces bi-directional photometric and semantic
consistency across scans. To handle spatial misalignments, we introduce a
pseudo-intermediate scene state for unified alignment, alongside collaborative
co-pruning strategies to refine geometry. IGFuse enables high fidelity
rendering and object level scene manipulation without dense observations or
complex pipelines. Extensive experiments validate the framework's strong
generalization to novel scene configurations, demonstrating its effectiveness
for real world 3D reconstruction and real-to-simulation transfer. Our project
page is available online.

</details>


### [156] [4DNeX: Feed-Forward 4D Generative Modeling Made Easy](https://arxiv.org/abs/2508.13154)
*Zhaoxi Chen,Tianqi Liu,Long Zhuo,Jiawei Ren,Zeng Tao,He Zhu,Fangzhou Hong,Liang Pan,Ziwei Liu*

Main category: cs.CV

TL;DR: 4DNeX是首个基于单张图像生成动态3D场景的端到端框架，通过微调预训练视频扩散模型实现高效生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖计算密集型优化或多帧视频输入，4DNeX旨在解决这些问题，提供高效且可扩展的图像到4D生成方案。

Method: 1) 构建大规模4D数据集4DNeX-10M；2) 提出统一6D视频表示联合建模RGB和XYZ序列；3) 设计适配策略微调视频扩散模型。

Result: 4DNeX生成高质量动态点云，支持新视角视频合成，在效率和泛化性上优于现有方法。

Conclusion: 4DNeX为图像到4D建模提供了可扩展解决方案，并为模拟动态场景演化的生成式4D世界模型奠定基础。

Abstract: We present 4DNeX, the first feed-forward framework for generating 4D (i.e.,
dynamic 3D) scene representations from a single image. In contrast to existing
methods that rely on computationally intensive optimization or require
multi-frame video inputs, 4DNeX enables efficient, end-to-end image-to-4D
generation by fine-tuning a pretrained video diffusion model. Specifically, 1)
to alleviate the scarcity of 4D data, we construct 4DNeX-10M, a large-scale
dataset with high-quality 4D annotations generated using advanced
reconstruction approaches. 2) we introduce a unified 6D video representation
that jointly models RGB and XYZ sequences, facilitating structured learning of
both appearance and geometry. 3) we propose a set of simple yet effective
adaptation strategies to repurpose pretrained video diffusion models for 4D
modeling. 4DNeX produces high-quality dynamic point clouds that enable
novel-view video synthesis. Extensive experiments demonstrate that 4DNeX
outperforms existing 4D generation methods in efficiency and generalizability,
offering a scalable solution for image-to-4D modeling and laying the foundation
for generative 4D world models that simulate dynamic scene evolution.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [157] [Using Natural Language for Human-Robot Collaboration in the Real World](https://arxiv.org/abs/2508.11759)
*Peter Lindes,Kaoutar Skiker*

Main category: cs.RO

TL;DR: 论文探讨了如何利用大型语言模型（LLMs）提升自主机器人通过自然语言与人类协作的能力，并提出了一个基于认知代理的集成系统框架。


<details>
  <summary>Details</summary>
Motivation: 传统交互式任务学习（ITL）系统的语言理解能力有限，LLMs的出现为机器人语言理解提供了改进机会，但如何将其与物理世界中的机器人集成仍具挑战性。

Method: 通过回顾现有商业机器人产品，提出一个以认知代理为核心的AI系统框架，结合人类和LLMs的交互，并通过实验验证ChatGPT在自然语言理解中的应用。

Result: 提出了一个初步的概念验证实验，展示了LLMs在机器人语言理解中的潜力。

Conclusion: 未来需要进一步研究，将简单的实验转化为一个集成的机器人助手系统，实现LLM辅助的语言理解与人类协作。

Abstract: We have a vision of a day when autonomous robots can collaborate with humans
as assistants in performing complex tasks in the physical world. This vision
includes that the robots will have the ability to communicate with their human
collaborators using language that is natural to the humans. Traditional
Interactive Task Learning (ITL) systems have some of this ability, but the
language they can understand is very limited. The advent of large language
models (LLMs) provides an opportunity to greatly improve the language
understanding of robots, yet integrating the language abilities of LLMs with
robots that operate in the real physical world is a challenging problem.
  In this chapter we first review briefly a few commercial robot products that
work closely with humans, and discuss how they could be much better
collaborators with robust language abilities. We then explore how an AI system
with a cognitive agent that controls a physical robot at its core, interacts
with both a human and an LLM, and accumulates situational knowledge through its
experiences, can be a possible approach to reach that vision. We focus on three
specific challenges of having the robot understand natural language, and
present a simple proof-of-concept experiment using ChatGPT for each. Finally,
we discuss what it will take to turn these simple experiments into an
operational system where LLM-assisted language understanding is a part of an
integrated robotic assistant that uses language to collaborate with humans.

</details>


### [158] [Anticipatory and Adaptive Footstep Streaming for Teleoperated Bipedal Robots](https://arxiv.org/abs/2508.11802)
*Luigi Penco,Beomyeong Park,Stefan Fasano,Nehar Poddar,Stephen McCrory,Nicholas Kitchel,Tomasz Bialek,Dexton Anderson,Duncan Calvert,Robert Griffin*

Main category: cs.RO

TL;DR: 提出了一种实时步态重定向方法，通过预测用户脚步并适应机器人动态和环境，实现高同步性。


<details>
  <summary>Details</summary>
Motivation: 解决高速任务中用户与机器人运动同步的挑战，提升平衡与稳定性。

Method: 重定向用户脚步到机器人步态位置，预测脚步以减少延迟，并动态适应环境和用户参考。

Result: 在Nadia人形机器人上验证了系统的有效性。

Conclusion: 该方法显著提升了同步性和适应性，适用于复杂环境。

Abstract: Achieving seamless synchronization between user and robot motion in
teleoperation, particularly during high-speed tasks, remains a significant
challenge. In this work, we propose a novel approach for transferring stepping
motions from the user to the robot in real-time. Instead of directly
replicating user foot poses, we retarget user steps to robot footstep
locations, allowing the robot to utilize its own dynamics for locomotion,
ensuring better balance and stability. Our method anticipates user footsteps to
minimize delays between when the user initiates and completes a step and when
the robot does it. The step estimates are continuously adapted to converge with
the measured user references. Additionally, the system autonomously adjusts the
robot's steps to account for its surrounding terrain, overcoming challenges
posed by environmental mismatches between the user's flat-ground setup and the
robot's uneven terrain. Experimental results on the humanoid robot Nadia
demonstrate the effectiveness of the proposed system.

</details>


### [159] [LocoMamba: Vision-Driven Locomotion via End-to-End Deep Reinforcement Learning with Mamba](https://arxiv.org/abs/2508.11849)
*Allen Wang,Gavin Tao*

Main category: cs.RO

TL;DR: LocoMamba是一个基于选择性状态空间模型的视觉驱动跨模态DRL框架，利用Mamba实现近线性时间序列建模，高效捕捉长程依赖关系，并支持长序列的高效训练。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理长序列和复杂环境时存在效率低、泛化能力不足的问题，LocoMamba旨在通过选择性状态空间模型和跨模态融合解决这些问题。

Method: 1. 使用多层感知机嵌入本体感知状态，轻量级CNN处理深度图像生成紧凑标记；2. 堆叠Mamba层通过选择性扫描融合标记，降低延迟和内存占用；3. 使用PPO算法在随机化环境和障碍密度课程下训练策略。

Result: 在模拟环境中，LocoMamba相比基线方法实现了更高的回报和成功率，碰撞更少，泛化能力更强，训练效率更高。

Conclusion: LocoMamba通过选择性状态空间模型和跨模态融合，显著提升了DRL在复杂环境中的性能和效率。

Abstract: We introduce LocoMamba, a vision-driven cross-modal DRL framework built on
selective state-space models, specifically leveraging Mamba, that achieves
near-linear-time sequence modeling, effectively captures long-range
dependencies, and enables efficient training with longer sequences. First, we
embed proprioceptive states with a multilayer perceptron and patchify depth
images with a lightweight convolutional neural network, producing compact
tokens that improve state representation. Second, stacked Mamba layers fuse
these tokens via near-linear-time selective scanning, reducing latency and
memory footprint, remaining robust to token length and image resolution, and
providing an inductive bias that mitigates overfitting. Third, we train the
policy end-to-end with Proximal Policy Optimization under terrain and
appearance randomization and an obstacle-density curriculum, using a compact
state-centric reward that balances progress, smoothness, and safety. We
evaluate our method in challenging simulated environments with static and
moving obstacles as well as uneven terrain. Compared with state-of-the-art
baselines, our method achieves higher returns and success rates with fewer
collisions, exhibits stronger generalization to unseen terrains and obstacle
densities, and improves training efficiency by converging in fewer updates
under the same compute budget.

</details>


### [160] [Data Shift of Object Detection in Autonomous Driving](https://arxiv.org/abs/2508.11868)
*Lida Xu*

Main category: cs.RO

TL;DR: 论文研究了自动驾驶中数据偏移问题，提出了一种结合CycleGAN数据增强和YOLOv5的优化方法，在BDD100K数据集上表现优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习模型在自动驾驶中表现脆弱，因训练和测试数据需满足独立同分布假设，而实际应用中数据分布动态变化（如季节、天气）导致数据偏移问题。

Method: 系统分析数据偏移问题，采用数据偏移检测技术进行数据集分类和平衡，构建目标检测模型，结合CycleGAN数据增强和YOLOv5框架优化。

Result: 在BDD100K数据集上，优化后的模型性能优于基线模型。

Conclusion: 提出的方法有效解决了自动驾驶目标检测中的数据偏移问题，提升了模型性能。

Abstract: With the widespread adoption of machine learning technologies in autonomous
driving systems, their role in addressing complex environmental perception
challenges has become increasingly crucial. However, existing machine learning
models exhibit significant vulnerability, as their performance critically
depends on the fundamental assumption that training and testing data satisfy
the independent and identically distributed condition, which is difficult to
guarantee in real-world applications. Dynamic variations in data distribution
caused by seasonal changes, weather fluctuations lead to data shift problems in
autonomous driving systems. This study investigates the data shift problem in
autonomous driving object detection tasks, systematically analyzing its
complexity and diverse manifestations. We conduct a comprehensive review of
data shift detection methods and employ shift detection analysis techniques to
perform dataset categorization and balancing. Building upon this foundation, we
construct an object detection model. To validate our approach, we optimize the
model by integrating CycleGAN-based data augmentation techniques with the
YOLOv5 framework. Experimental results demonstrate that our method achieves
superior performance compared to baseline models on the BDD100K dataset.

</details>


### [161] [Bioinspired underwater soft robots: from biology to robotics and back](https://arxiv.org/abs/2508.11883)
*Lei Li,Boyang Qin,Wenzhuo Gao,Yanyu Li,Yiyuan Zhang,Bo Wang,Shihan Kong,Jian Wang,Dekui He,Junzhi Yu*

Main category: cs.RO

TL;DR: 提出了一种双向框架，将生物学原理与机器人技术结合，软体机器人可作为实验工具验证生物功能，并在非结构化环境中优于刚性系统。


<details>
  <summary>Details</summary>
Motivation: 探索海洋和软体生物激发了仿生水下软体机器人的研究，但目前研究多为单向（生物学指导机器人），缺乏机器人技术反馈生物学。

Method: 提出了一种整体双向框架，整合生物学原理、机器人实现和生物验证，并引入跨物种的通用仿生机器人范式。

Result: 软体机器人能验证生物功能、测试进化假设，在非结构化环境中表现优于刚性系统，适用于海洋探索和医学。

Conclusion: 通过结合生物学与工程学，软体机器人可推动海洋探索和科学发现，但仍需解决材料、驱动效率和智能等挑战。

Abstract: The ocean vast unexplored regions and diverse soft-bodied marine organisms
have spurred interest in bio-inspired underwater soft robotics. Recent advances
have enabled new capabilities in underwater movement, sensing, and interaction.
However, these efforts are largely unidirectional, with biology guiding
robotics while insights from robotics rarely feed back into biology. Here we
propose a holistic, bidirectional framework that integrates biological
principles, robotic implementation, and biological validation. We show that
soft robots can serve as experimental tools to probe biological functions and
even test evolutionary hypotheses. Their inherent compliance also allows them
to outperform rigid systems in unstructured environments, supporting
applications in marine exploration, manipulation, and medicine. Looking
forward, we introduce bio-universal-inspired robotics, a paradigm that
transcends species-specific mimicry by identifying convergent principles across
species to inspire more adaptable designs. Despite rapid progress, challenges
persist in material robustness, actuation efficiency, autonomy, and
intelligence. By uniting biology and engineering, soft robots can advance ocean
exploration and deepen scientific discovery.

</details>


### [162] [From Screen to Stage: Kid Cosmo, A Life-Like, Torque-Controlled Humanoid for Entertainment Robotics](https://arxiv.org/abs/2508.11884)
*Havel Liu,Mingzhang Zhu,Arturo Moises Flores Alvarez,Yuan Hung Lo,Conrad Ku,Federico Parres,Justin Quan,Colin Togashi,Aditya Navghare,Quanyou Wang,Dennis W. Hong*

Main category: cs.RO

TL;DR: 论文介绍了Kid Cosmo，一个专为娱乐设计的儿童大小人形机器人，展示了其在角色体现和技术功能上的可行性。


<details>
  <summary>Details</summary>
Motivation: 探索人形机器人在娱乐领域的潜力，解决娱乐机器人设计中视觉与功能结合的挑战。

Method: 开发Kid Cosmo，采用28自由度和本体感受执行器，实现扭矩控制行走和逼真动作生成。

Result: 展示了Kid Cosmo在同时进行上下半身运动时的稳定性，验证了其技术功能。

Conclusion: Kid Cosmo证明了性能导向的人形机器人在角色体现和技术功能上的可行性。

Abstract: Humanoid robots represent the cutting edge of robotics research, yet their
potential in entertainment remains largely unexplored. Entertainment as a field
prioritizes visuals and form, a principle that contrasts with the purely
functional designs of most contemporary humanoid robots. Designing
entertainment humanoid robots capable of fluid movement presents a number of
unique challenges. In this paper, we present Kid Cosmo, a research platform
designed for robust locomotion and life-like motion generation while imitating
the look and mannerisms of its namesake character from Netflix's movie The
Electric State. Kid Cosmo is a child-sized humanoid robot, standing 1.45 m tall
and weighing 25 kg. It contains 28 degrees of freedom and primarily uses
proprioceptive actuators, enabling torque-control walking and lifelike motion
generation. Following worldwide showcases as part of the movie's press tour, we
present the system architecture, challenges of a functional entertainment robot
and unique solutions, and our initial findings on stability during simultaneous
upper and lower body movement. We demonstrate the viability of
performance-oriented humanoid robots that prioritize both character embodiment
and technical functionality.

</details>


### [163] [Contact-Rich and Deformable Foot Modeling for Locomotion Control of the Human Musculoskeletal System](https://arxiv.org/abs/2508.11885)
*Haixin Gong,Chen Zhang,Yanan Sui*

Main category: cs.RO

TL;DR: 提出了一种新型的接触丰富且可变形的人足模型，通过两阶段策略训练模拟自然步态，相比传统刚性模型在运动学、动力学和步态稳定性上表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有肌肉骨骼模型对足地接触力学的简化限制了步态动力学的准确模拟。

Method: 开发了接触丰富且可变形的人足模型，采用两阶段策略训练解决多点接触和可变形材料的控制挑战。

Result: 模型在运动学、动力学和步态稳定性上优于传统刚性模型，且能准确复现真实生物力学数据。

Conclusion: 该研究推进了接触丰富的接口建模，为需要精确足地交互控制的人形机器人应用提供了框架。

Abstract: The human foot serves as the critical interface between the body and
environment during locomotion. Existing musculoskeletal models typically
oversimplify foot-ground contact mechanics, limiting their ability to
accurately simulate human gait dynamics. We developed a novel contact-rich and
deformable model of the human foot integrated within a complete musculoskeletal
system that captures the complex biomechanical interactions during walking. To
overcome the control challenges inherent in modeling multi-point contacts and
deformable material, we developed a two-stage policy training strategy to learn
natural walking patterns for this interface-enhanced model. Comparative
analysis between our approach and conventional rigid musculoskeletal models
demonstrated improvements in kinematic, kinetic, and gait stability metrics.
Validation against human subject data confirmed that our simulation closely
reproduced real-world biomechanical measurements. This work advances
contact-rich interface modeling for human musculoskeletal systems and
establishes a robust framework that can be extended to humanoid robotics
applications requiring precise foot-ground interaction control.

</details>


### [164] [Saliency-Based Attention Shifting: A Framework for Improving Driver Situational Awareness of Out-of-Label Hazards](https://arxiv.org/abs/2508.11887)
*Yousra Shleibik,Jordan Sinclair,Kerstin Haring*

Main category: cs.RO

TL;DR: 论文探讨了在半自动驾驶场景中，通过视觉和听觉提示来增强驾驶员注意力，以减少潜在风险。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶技术的发展，需要集成系统以支持人类在决策中的参与，特别是在车辆无法独立行动时。

Method: 提出了一个结合实时视线跟踪、上下文感知显著性分析和同步视听警报的概念框架。

Result: 该框架旨在增强情境意识，主动应对潜在危险，促进人与自动驾驶系统的有效协作。

Conclusion: 通过注意力重定向技术，可以有效提升驾驶员在接管操作中的表现，减少目标固定现象。

Abstract: The advent of autonomous driving systems promises to transform transportation
by enhancing safety, efficiency, and comfort. As these technologies evolve
toward higher levels of autonomy, the need for integrated systems that
seamlessly support human involvement in decision-making becomes increasingly
critical. Certain scenarios necessitate human involvement, including those
where the vehicle is unable to identify an object or element in the scene, and
as such cannot take independent action. Therefore, situational awareness is
essential to mitigate potential risks during a takeover, where a driver must
assume control and autonomy from the vehicle. The need for driver attention is
important to avoid collisions with external agents and ensure a smooth
transition during takeover operations. This paper explores the integration of
attention redirection techniques, such as gaze manipulation through targeted
visual and auditory cues, to help drivers maintain focus on emerging hazards
and reduce target fixation in semi-autonomous driving scenarios. We propose a
conceptual framework that combines real-time gaze tracking, context-aware
saliency analysis, and synchronized visual and auditory alerts to enhance
situational awareness, proactively address potential hazards, and foster
effective collaboration between humans and autonomous systems.

</details>


### [165] [Integrating Symbolic RL Planning into a BDI-based Autonomous UAV Framework: System Integration and SIL Validation](https://arxiv.org/abs/2508.11890)
*Sangwoo Jeon,Juchul Shin,YeonJe Cho,Gyeong-Tae Kim,Seongwoo Kim*

Main category: cs.RO

TL;DR: AMAD-SRL框架结合符号规划与强化学习，提升无人机任务规划的可靠性和安全性，实验显示任务效率提高75%。


<details>
  <summary>Details</summary>
Motivation: 传统规则架构在动态复杂环境中适应性不足，需结合符号强化学习以提升无人机决策能力。

Method: 提出AMAD-SRL框架，结合PDDL和强化学习，在SIL环境中验证模块集成与任务性能。

Result: 实验显示任务效率提升75%，模块集成稳定，规划阶段转换成功。

Conclusion: AMAD-SRL为复杂无人机任务提供基础，未来可进一步优化与验证。

Abstract: Modern autonomous drone missions increasingly require software frameworks
capable of seamlessly integrating structured symbolic planning with adaptive
reinforcement learning (RL). Although traditional rule-based architectures
offer robust structured reasoning for drone autonomy, their capabilities fall
short in dynamically complex operational environments that require adaptive
symbolic planning. Symbolic RL (SRL), using the Planning Domain Definition
Language (PDDL), explicitly integrates domain-specific knowledge and
operational constraints, significantly improving the reliability and safety of
unmanned aerial vehicle (UAV) decision making. In this study, we propose the
AMAD-SRL framework, an extended and refined version of the Autonomous Mission
Agents for Drones (AMAD) cognitive multi-agent architecture, enhanced with
symbolic reinforcement learning for dynamic mission planning and execution. We
validated our framework in a Software-in-the-Loop (SIL) environment structured
identically to an intended Hardware-In-the-Loop Simulation (HILS) platform,
ensuring seamless transition to real hardware. Experimental results demonstrate
stable integration and interoperability of modules, successful transitions
between BDI-driven and symbolic RL-driven planning phases, and consistent
mission performance. Specifically, we evaluate a target acquisition scenario in
which the UAV plans a surveillance path followed by a dynamic reentry path to
secure the target while avoiding threat zones. In this SIL evaluation, mission
efficiency improved by approximately 75% over a coverage-based baseline,
measured by travel distance reduction. This study establishes a robust
foundation for handling complex UAV missions and discusses directions for
further enhancement and validation.

</details>


### [166] [OmniD: Generalizable Robot Manipulation Policy via Image-Based BEV Representation](https://arxiv.org/abs/2508.11898)
*Jilei Mao,Jiarui Guan,Yingjuan Tang,Qirui Hu,Zhihang Li,Junjie Yu,Yongjie Mao,Yunzhe Sun,Shuang Liu,Xiaozhu Ju*

Main category: cs.RO

TL;DR: OmniD提出了一种多视角融合框架，通过BEV表示解决视觉运动策略的过拟合和多视角信息融合问题。


<details>
  <summary>Details</summary>
Motivation: 视觉运动策略容易过拟合训练数据（如固定相机位置和背景），且在分布外泛化中表现不佳，现有方法也难以有效融合多视角信息。

Method: 提出OmniD框架，利用可变形注意力机制（OFG）选择性提取任务相关特征，抑制视角噪声和背景干扰。

Result: 在分布内、分布外和少样本实验中，OmniD分别比基线模型平均提升11%、17%和84%。

Conclusion: OmniD通过BEV表示和多视角特征融合，显著提升了视觉运动策略的泛化能力和性能。

Abstract: The visuomotor policy can easily overfit to its training datasets, such as
fixed camera positions and backgrounds. This overfitting makes the policy
perform well in the in-distribution scenarios but underperform in the
out-of-distribution generalization. Additionally, the existing methods also
have difficulty fusing multi-view information to generate an effective 3D
representation. To tackle these issues, we propose Omni-Vision Diffusion Policy
(OmniD), a multi-view fusion framework that synthesizes image observations into
a unified bird's-eye view (BEV) representation. We introduce a deformable
attention-based Omni-Feature Generator (OFG) to selectively abstract
task-relevant features while suppressing view-specific noise and background
distractions. OmniD achieves 11\%, 17\%, and 84\% average improvement over the
best baseline model for in-distribution, out-of-distribution, and few-shot
experiments, respectively. Training code and simulation benchmark are
available: https://github.com/1mather/omnid.git

</details>


### [167] [Control of Legged Robots using Model Predictive Optimized Path Integral](https://arxiv.org/abs/2508.11917)
*Hossein Keshavarz,Alejandro Ramirez-Serrano,Majid Khadiv*

Main category: cs.RO

TL;DR: 提出了一种结合MPPI、CE和CMA的采样模型预测策略（MPOPI），用于四足机器人的实时全身运动控制，提高了样本效率和运动性能。


<details>
  <summary>Details</summary>
Motivation: 四足机器人在复杂地形中表现出色，但尚未达到自然系统的水平。采样预测控制器显示出潜力，但需要更高效的算法。

Method: 结合MPPI、CE和CMA方法，提出MPOPI策略，优化路径积分，提高样本效率。

Result: MPOPI在多种场景下表现出更高的样本效率和运动性能，优于传统MPPI算法。

Conclusion: MPOPI作为一种实时控制策略，能逐步提升四足机器人的运动能力。

Abstract: Legged robots possess a unique ability to traverse rough terrains and
navigate cluttered environments, making them well-suited for complex,
real-world unstructured scenarios. However, such robots have not yet achieved
the same level as seen in natural systems. Recently, sampling-based predictive
controllers have demonstrated particularly promising results. This paper
investigates a sampling-based model predictive strategy combining model
predictive path integral (MPPI) with cross-entropy (CE) and covariance matrix
adaptation (CMA) methods to generate real-time whole-body motions for legged
robots across multiple scenarios. The results show that combining the benefits
of MPPI, CE and CMA, namely using model predictive optimized path integral
(MPOPI), demonstrates greater sample efficiency, enabling robots to attain
superior locomotion results using fewer samples when compared to typical MPPI
algorithms. Extensive simulation experiments in multiple scenarios on a
quadruped robot show that MPOPI can be used as an anytime control strategy,
increasing locomotion capabilities at each iteration.

</details>


### [168] [ExploreVLM: Closed-Loop Robot Exploration Task Planning with Vision-Language Models](https://arxiv.org/abs/2508.11918)
*Zhichen Lou,Kechun Xu,Zhongxiang Zhou,Rong Xiong*

Main category: cs.RO

TL;DR: ExploreVLM是一个基于视觉语言模型（VLMs）的闭环任务规划框架，通过实时调整和交互探索提升机器人任务执行能力。


<details>
  <summary>Details</summary>
Motivation: 现有VLM方法在交互探索、精确感知和实时计划调整方面存在不足，需要更高效的解决方案。

Method: 提出ExploreVLM框架，包含双阶段任务规划器、对象中心空间关系图和执行验证器，支持闭环反馈。

Result: 实验表明ExploreVLM在探索任务中显著优于现有方法，验证了其关键组件的有效性。

Conclusion: ExploreVLM通过结构化感知和反思规划实现了高效任务执行，为机器人助手提供了新思路。

Abstract: The advancement of embodied intelligence is accelerating the integration of
robots into daily life as human assistants. This evolution requires robots to
not only interpret high-level instructions and plan tasks but also perceive and
adapt within dynamic environments. Vision-Language Models (VLMs) present a
promising solution by combining visual understanding and language reasoning.
However, existing VLM-based methods struggle with interactive exploration,
accurate perception, and real-time plan adaptation. To address these
challenges, we propose ExploreVLM, a novel closed-loop task planning framework
powered by Vision-Language Models (VLMs). The framework is built around a
step-wise feedback mechanism that enables real-time plan adjustment and
supports interactive exploration. At its core is a dual-stage task planner with
self-reflection, enhanced by an object-centric spatial relation graph that
provides structured, language-grounded scene representations to guide
perception and planning. An execution validator supports the closed loop by
verifying each action and triggering re-planning. Extensive real-world
experiments demonstrate that ExploreVLM significantly outperforms
state-of-the-art baselines, particularly in exploration-centric tasks. Ablation
studies further validate the critical role of the reflective planner and
structured perception in achieving robust and efficient task execution.

</details>


### [169] [No More Blind Spots: Learning Vision-Based Omnidirectional Bipedal Locomotion for Challenging Terrain](https://arxiv.org/abs/2508.11929)
*Mohitvishnu S. Gadde,Pranay Dugar,Ashish Malik,Alan Fern*

Main category: cs.RO

TL;DR: 提出了一种基于视觉的全向双足运动学习框架，通过结合盲控制器和教师策略，避免了高计算成本的渲染，并在仿真和实际测试中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 在动态环境中实现敏捷的全向双足运动需要全向地形感知和高效控制器，但传统方法因渲染成本高而不实用。

Method: 结合盲控制器和教师策略，训练基于视觉的学生策略，并通过数据增强技术加速训练。

Result: 框架在仿真和实际测试中表现出色，实现了全向运动且对渲染依赖低。

Conclusion: 首次展示了基于视觉的全向双足运动，证明了其在地形适应性上的优势。

Abstract: Effective bipedal locomotion in dynamic environments, such as cluttered
indoor spaces or uneven terrain, requires agile and adaptive movement in all
directions. This necessitates omnidirectional terrain sensing and a controller
capable of processing such input. We present a learning framework for
vision-based omnidirectional bipedal locomotion, enabling seamless movement
using depth images. A key challenge is the high computational cost of rendering
omnidirectional depth images in simulation, making traditional sim-to-real
reinforcement learning (RL) impractical. Our method combines a robust blind
controller with a teacher policy that supervises a vision-based student policy,
trained on noise-augmented terrain data to avoid rendering costs during RL and
ensure robustness. We also introduce a data augmentation technique for
supervised student training, accelerating training by up to 10 times compared
to conventional methods. Our framework is validated through simulation and
real-world tests, demonstrating effective omnidirectional locomotion with
minimal reliance on expensive rendering. This is, to the best of our knowledge,
the first demonstration of vision-based omnidirectional bipedal locomotion,
showcasing its adaptability to diverse terrains.

</details>


### [170] [Toward General Physical Intelligence for Resilient Agile Manufacturing Automation](https://arxiv.org/abs/2508.11960)
*Sandeep Kanta,Mehrdad Tavassoli,Varun Teja Chirkuri,Venkata Akhil Kumar,Santhi Bharath Punati,Praveen Damacharla,Sunny Katyara*

Main category: cs.RO

TL;DR: 综述探讨了通用物理智能（GPI）在敏捷制造中的应用，分析了VLA模型的进展及其工业部署潜力。


<details>
  <summary>Details</summary>
Motivation: 填补GPI在敏捷制造中实际应用的研究空白。

Method: 系统综述VLA模型在GPI中的进展，进行对比分析和消融研究。

Result: 将前沿技术归纳为五大主题，评估其工业适用性。

Conclusion: 提出未来研究方向，以促进GPI与工业5.0的融合。

Abstract: Agile and human-centric manufacturing stipulates resilient robotic solutions
capable of contextual reasoning and safe interaction in unstructured
environments. Foundation models particularly the Vision Language Action (VLA)
models have emerged to fuse multimodal perception, reasoning and physically
grounded action across varied embodiments into unified representation, termed
as General Physical Intelligence (GPI). While GPI has already been described in
the literature but its practical application and evolving role in contemporary
agile manufacturing processes have yet to be duly explored. To bridge this gap,
this practical review systematically surveys recent advancements in VLA models
within GPI context, performs comprehensive comparative analysis of leading
implementations and evaluates their readiness for industrial deployment through
structured ablation study. Our analysis has organized state-of-the-art into
five thematic pillars including multisensory representation learning, sim2real
transfer, planning and control, uncertainty and safety measures and
benchmarking. Finally, we articulate open research challenges and propose
directions to better integrate GPI into next-generation industrial ecosystems
in line with Industry 5.0.

</details>


### [171] [Fully Spiking Actor-Critic Neural Network for Robotic Manipulation](https://arxiv.org/abs/2508.12038)
*Liwen Zhang,Heng Deng,Guanghui Sun*

Main category: cs.RO

TL;DR: 提出了一种基于全脉冲神经网络的混合课程强化学习框架，用于9自由度机械臂的目标抓取任务，简化了网络结构并降低了延迟。


<details>
  <summary>Details</summary>
Motivation: 解决资源受限环境中网络复杂性和推理延迟的问题，同时利用SNN的高推理速度、低能耗和生物合理性优势。

Method: 结合时间进度分区课程策略与PPO算法，引入能耗建模框架，并采用动态两阶段奖励调整机制和优化观测空间。

Result: 在Isaac Gym平台上实验表明，该方法在物理约束下表现优异，验证了其在动态机器人操作任务中的可扩展性和能效。

Conclusion: 提出的方法在资源受限环境中具有高效性和实用性，适用于动态机器人操作任务。

Abstract: This study proposes a hybrid curriculum reinforcement learning (CRL)
framework based on a fully spiking neural network (SNN) for 9-degree-of-freedom
robotic arms performing target reaching and grasping tasks. To reduce network
complexity and inference latency, the SNN architecture is simplified to include
only an input and an output layer, which shows strong potential for
resource-constrained environments. Building on the advantages of SNNs-high
inference speed, low energy consumption, and spike-based biological
plausibility, a temporal progress-partitioned curriculum strategy is integrated
with the Proximal Policy Optimization (PPO) algorithm. Meanwhile, an energy
consumption modeling framework is introduced to quantitatively compare the
theoretical energy consumption between SNNs and conventional Artificial Neural
Networks (ANNs). A dynamic two-stage reward adjustment mechanism and optimized
observation space further improve learning efficiency and policy accuracy.
Experiments on the Isaac Gym simulation platform demonstrate that the proposed
method achieves superior performance under realistic physical constraints.
Comparative evaluations with conventional PPO and ANN baselines validate the
scalability and energy efficiency of the proposed approach in dynamic robotic
manipulation tasks.

</details>


### [172] [Talk Less, Fly Lighter: Autonomous Semantic Compression for UAV Swarm Communication via LLMs](https://arxiv.org/abs/2508.12043)
*Fei Lin,Tengchao Zhang,Qinghua Ni,Jun Huang,Siji Ma,Yonglin Tian,Yisheng Lv,Naiqi Wu*

Main category: cs.RO

TL;DR: LLM驱动的无人机群在带宽受限条件下实现高效语义压缩通信。


<details>
  <summary>Details</summary>
Motivation: 无人机群在语义理解和任务执行方面面临通信带宽限制和高频交互的挑战。

Method: 构建四种2D仿真场景，设计通信-执行流程，评估九种主流LLM的语义压缩性能。

Result: 实验表明LLM驱动的无人机群在带宽受限和多跳链路条件下能实现高效协作通信。

Conclusion: LLM在无人机群中具有潜力，但需进一步优化环境复杂性和群规模适应性。

Abstract: The rapid adoption of Large Language Models (LLMs) in unmanned systems has
significantly enhanced the semantic understanding and autonomous task execution
capabilities of Unmanned Aerial Vehicle (UAV) swarms. However, limited
communication bandwidth and the need for high-frequency interactions pose
severe challenges to semantic information transmission within the swarm. This
paper explores the feasibility of LLM-driven UAV swarms for autonomous semantic
compression communication, aiming to reduce communication load while preserving
critical task semantics. To this end, we construct four types of 2D simulation
scenarios with different levels of environmental complexity and design a
communication-execution pipeline that integrates system prompts with task
instruction prompts. On this basis, we systematically evaluate the semantic
compression performance of nine mainstream LLMs in different scenarios and
analyze their adaptability and stability through ablation studies on
environmental complexity and swarm size. Experimental results demonstrate that
LLM-based UAV swarms have the potential to achieve efficient collaborative
communication under bandwidth-constrained and multi-hop link conditions.

</details>


### [173] [OASIS: Real-Time Opti-Acoustic Sensing for Intervention Systems in Unstructured Environments](https://arxiv.org/abs/2508.12071)
*Amy Phung,Richard Camilli*

Main category: cs.RO

TL;DR: OASIS是一种实时水下3D重建方法，结合光学图像和体素雕刻技术，适用于非结构化水下环境。


<details>
  <summary>Details</summary>
Motivation: 高分辨率水下3D场景重建对建筑、维护、监测和科学调查至关重要，现有方法多为离线重建，而实时空间感知对水下车辆操作至关重要。

Method: 采用光学图像与体素雕刻技术融合的OASIS方法，利用"手眼"配置通过机器人臂捕获多视角数据。

Result: 通过水箱实验验证，展示了OASIS在水下操作任务中的实用性。

Conclusion: OASIS实现了实时水下3D重建，为非结构化水下工作空间提供了有效解决方案。

Abstract: High resolution underwater 3D scene reconstruction is crucial for various
applications, including construction, infrastructure maintenance, monitoring,
exploration, and scientific investigation. Prior work has leveraged the
complementary sensing modalities of imaging sonars and optical cameras for
opti-acoustic 3D scene reconstruction, demonstrating improved results over
methods which rely solely on either sensor. However, while most existing
approaches focus on offline reconstruction, real-time spatial awareness is
essential for both autonomous and piloted underwater vehicle operations. This
paper presents OASIS, an opti-acoustic fusion method that integrates data from
optical images with voxel carving techniques to achieve real-time 3D
reconstruction unstructured underwater workspaces. Our approach utilizes an
"eye-in-hand" configuration, which leverages the dexterity of robotic
manipulator arms to capture multiple workspace views across a short baseline.
We validate OASIS through tank-based experiments and present qualitative and
quantitative results that highlight its utility for underwater manipulation
tasks.

</details>


### [174] [Into the Wild: When Robots Are Not Welcome](https://arxiv.org/abs/2508.12075)
*Shaul Ashkenazi,Gabriel Skantze,Jane Stuart-Smith,Mary Ellen Foster*

Main category: cs.RO

TL;DR: 论文总结了在公共场所部署社交机器人时遇到的挑战，包括技术问题和利益相关者的反对，但最终通过建立信任成功部署。


<details>
  <summary>Details</summary>
Motivation: 探讨在公共场所部署社交机器人时面临的困难，尤其是技术障碍和利益相关者的不信任。

Method: 在两个公共场景（学生服务中心和难民服务点）中尝试部署社交机器人，记录过程中的挑战和解决方案。

Result: 尽管初期遇到困难，最终通过建立信任关系成功部署机器人并完成研究。

Conclusion: 在公共场所部署社交机器人需要克服技术和人际关系的双重挑战，但通过耐心和沟通可以取得成功。

Abstract: Social robots are increasingly being deployed in public spaces, where they
face not only technological difficulties and unexpected user utterances, but
also objections from stakeholders who may not be comfortable with introducing a
robot into those spaces. We describe our difficulties with deploying a social
robot in two different public settings: 1) Student services center; 2) Refugees
and asylum seekers drop-in service. Although this is a failure report, in each
use case we eventually managed to earn the trust of the staff and form a
relationship with them, allowing us to deploy our robot and conduct our
studies.

</details>


### [175] [Belief-Conditioned One-Step Diffusion: Real-Time Trajectory Planning with Just-Enough Sensing](https://arxiv.org/abs/2508.12166)
*Gokul Puthumanaillam,Aditya Penumarti,Manav Vora,Paulo Padrao,Jose Fuentes,Leonardo Bobadilla,Jane Shin,Melkior Ornik*

Main category: cs.RO

TL;DR: B-COD是一种基于扩散模型的规划器，通过条件化位姿信念和传感器掩码，在10毫秒内生成轨迹并优化传感器选择，以减少能耗。


<details>
  <summary>Details</summary>
Motivation: 在部分可观测环境中，机器人需要持续激活传感器以定位，但能耗高且不必要。现有方法要么依赖启发式传感器切换，要么假设精确的状态估计。

Method: 提出B-COD，一种基于扩散模型的规划器，通过位姿信念栅格和传感器掩码条件化，生成轨迹并预测定位误差，结合软演员-评论家算法在线选择传感器。

Result: 在无人水面车辆实验中，B-COD显著降低能耗，同时保持与持续激活传感器基线相当的到达目标性能。

Conclusion: B-COD通过数据驱动方法解决了传感器选择问题，实现了能耗优化和定位性能的平衡。

Abstract: Robots equipped with rich sensor suites can localize reliably in
partially-observable environments, but powering every sensor continuously is
wasteful and often infeasible. Belief-space planners address this by
propagating pose-belief covariance through analytic models and switching
sensors heuristically--a brittle, runtime-expensive approach. Data-driven
approaches--including diffusion models--learn multi-modal trajectories from
demonstrations, but presuppose an accurate, always-on state estimate. We
address the largely open problem: for a given task in a mapped environment,
which \textit{minimal sensor subset} must be active at each location to
maintain state uncertainty \textit{just low enough} to complete the task? Our
key insight is that when a diffusion planner is explicitly conditioned on a
pose-belief raster and a sensor mask, the spread of its denoising trajectories
yields a calibrated, differentiable proxy for the expected localisation error.
Building on this insight, we present Belief-Conditioned One-Step Diffusion
(B-COD), the first planner that, in a 10 ms forward pass, returns a
short-horizon trajectory, per-waypoint aleatoric variances, and a proxy for
localisation error--eliminating external covariance rollouts. We show that this
single proxy suffices for a soft-actor-critic to choose sensors online,
optimising energy while bounding pose-covariance growth. We deploy B-COD in
real-time marine trials on an unmanned surface vehicle and show that it reduces
sensing energy consumption while matching the goal-reach performance of an
always-on baseline.

</details>


### [176] [Energy Efficiency in Robotics Software: A Systematic Literature Review (2020-2024)](https://arxiv.org/abs/2508.12170)
*Aryan Gupta*

Main category: cs.RO

TL;DR: 系统文献综述了2020-2024年机器人软件层面的能效方法，更新了2020年前的证据。


<details>
  <summary>Details</summary>
Motivation: 填补机器人能效领域的研究空白，提供最新的系统综述。

Method: 结合Google Scholar、雪球抽样和LLM辅助筛选，人工审核10%的自动化步骤。

Result: 分析了79篇研究，发现工业应用和运动优化是主流，但报告标准不统一。

Conclusion: 提出了最小报告清单，并强调跨层设计和量化非性能权衡的机会。

Abstract: This study presents a systematic literature review of software-level
approaches to energy efficiency in robotics published from 2020 through 2024,
updating and extending pre-2020 evidence. An automated-but-audited pipeline
combined Google Scholar seeding, backward/forward snowballing, and
large-language-model (LLM) assistance for screening and data extraction, with
~10% human audits at each automated step and consensus-with-tie-breaks for
full-text decisions. The final corpus comprises 79 peer-reviewed studies
analyzed across application domain, metrics, evaluation type, energy models,
major energy consumers, software technique families, and energy-quality
trade-offs. Industrial settings dominate (31.6%) followed by exploration
(25.3%). Motors/actuators are identified as the primary consumer in 68.4% of
studies, with computing/controllers a distant second (13.9%). Simulation-only
evaluations remain most common (51.9%), though hybrid evaluations are frequent
(25.3%). Representational (physics-grounded) energy models predominate (87.3%).
Motion and trajectory optimization is the leading technique family (69.6%),
often paired with learning/prediction (40.5%) and computation
allocation/scheduling (26.6%); power management/idle control (11.4%) and
communication/data efficiency (3.8%) are comparatively underexplored. Reporting
is heterogeneous: composite objectives that include energy are most common,
while task-normalized and performance-per-energy metrics appear less often,
limiting cross-paper comparability. The review offers a minimal reporting
checklist (e.g., total energy and average power plus a task-normalized metric
and clear baselines) and highlights opportunities in cross-layer designs and in
quantifying non-performance trade-offs (accuracy, stability). A replication
package with code, prompts, and frozen datasets accompanies the review.

</details>


### [177] [Humanoid Motion Scripting with Postural Synergies](https://arxiv.org/abs/2508.12184)
*Rhea Malhotra,William Chong,Catie Cuan,Oussama Khatib*

Main category: cs.RO

TL;DR: SynSculptor是一个基于姿态协同的无训练人体运动脚本框架，用于分析和编辑人形机器人运动。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人运动中参考运动收集、分析和映射的挑战。

Method: 通过PCA提取主要姿态协同，构建风格条件协同库，结合运动-语言转换器生成运动。

Result: 生成的运动通过足滑比和动量/动能偏差等指标评估，与参考运动对比。

Conclusion: SynSculptor有效生成人形机器人的类人运动，并支持任务执行中的姿态适应。

Abstract: Generating sequences of human-like motions for humanoid robots presents
challenges in collecting and analyzing reference human motions, synthesizing
new motions based on these reference motions, and mapping the generated motion
onto humanoid robots. To address these issues, we introduce SynSculptor, a
humanoid motion analysis and editing framework that leverages postural
synergies for training-free human-like motion scripting. To analyze human
motion, we collect 3+ hours of motion capture data across 20 individuals where
a real-time operational space controller mimics human motion on a simulated
humanoid robot. The major postural synergies are extracted using principal
component analysis (PCA) for velocity trajectories segmented by changes in
robot momentum, constructing a style-conditioned synergy library for free-space
motion generation. To evaluate generated motions using the synergy library, the
foot-sliding ratio and proposed metrics for motion smoothness involving total
momentum and kinetic energy deviations are computed for each generated motion,
and compared with reference motions. Finally, we leverage the synergies with a
motion-language transformer, where the humanoid, during execution of motion
tasks with its end-effectors, adapts its posture based on the chosen synergy.
Supplementary material, code, and videos are available at
https://rhea-mal.github.io/humanoidsynergies.io.

</details>


### [178] [Self-Guided Action Diffusion](https://arxiv.org/abs/2508.12189)
*Rhea Malhotra,Yuejiang Liu,Chelsea Finn*

Main category: cs.RO

TL;DR: 提出了一种名为自引导动作扩散的新方法，通过优化扩散步骤中的提议分布，显著降低了计算成本，同时提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在提高生成机器人策略的一致性时计算成本过高，尤其是在动作样本多样性增加时。

Method: 采用自引导动作扩散，基于先验决策指导每个扩散步骤的提议分布。

Result: 在模拟任务中，新方法以极低的推理成本实现了接近最优的性能，并在严格采样预算下比现有方法成功率高出70%。

Conclusion: 自引导动作扩散是一种高效且性能优越的扩散策略优化方法。

Abstract: Recent works have shown the promise of inference-time search over action
samples for improving generative robot policies. In particular, optimizing
cross-chunk coherence via bidirectional decoding has proven effective in
boosting the consistency and reactivity of diffusion policies. However, this
approach remains computationally expensive as the diversity of sampled actions
grows. In this paper, we introduce self-guided action diffusion, a more
efficient variant of bidirectional decoding tailored for diffusion-based
policies. At the core of our method is to guide the proposal distribution at
each diffusion step based on the prior decision. Experiments in simulation
tasks show that the proposed self-guidance enables near-optimal performance at
negligible inference cost. Notably, under a tight sampling budget, our method
achieves up to 70% higher success rates than existing counterparts on
challenging dynamic tasks. See project website at
https://rhea-mal.github.io/selfgad.github.io.

</details>


### [179] [Improving Pre-Trained Vision-Language-Action Policies with Model-Based Search](https://arxiv.org/abs/2508.12211)
*Cyrus Neary,Omar G. Younis,Artur Kuramshin,Ozgur Aslan,Glen Berseth*

Main category: cs.RO

TL;DR: VLAPS框架通过结合预训练的视觉-语言-动作模型与模型搜索，提升机器人在分布外场景中的任务表现。


<details>
  <summary>Details</summary>
Motivation: 预训练的视觉-语言-动作模型在零样本部署时表现脆弱且不安全，需要改进。

Method: 提出VLAPS框架，将模型搜索嵌入VLA模型的推理过程，使用改进的蒙特卡洛树搜索算法。

Result: VLAPS显著提升了任务成功率，最高增加67个百分点。

Conclusion: VLAPS为VLA模型提供了一种可控、高效且安全的推理框架。

Abstract: Pre-trained vision-language-action (VLA) models offer a promising foundation
for generalist robot policies, but often produce brittle behaviours or unsafe
failures when deployed zero-shot in out-of-distribution scenarios. We present
Vision-Language-Action Planning & Search (VLAPS) -- a novel framework and
accompanying algorithms that embed model-based search into the inference
procedure of pre-trained VLA policies to improve their performance on robotic
tasks. Specifically, our method biases a modified Monte Carlo Tree Search
(MCTS) algorithm -- run using a model of the target environment -- using action
priors defined by the VLA policy. By using VLA-derived abstractions and priors
in model-based search, VLAPS efficiently explores language-conditioned robotics
tasks whose search spaces would otherwise be intractably large. Conversely, by
integrating model-based search with the VLA policy's inference procedure, VLAPS
yields behaviours that are more performant than those obtained by directly
following the VLA policy's action predictions. VLAPS offers a principled
framework to: i) control test-time compute in VLA models, ii) leverage a priori
knowledge of the robotic environment, and iii) integrate established planning
and reinforcement learning techniques into the VLA inference process. Across
all experiments, VLAPS significantly outperforms VLA-only baselines on
language-specified tasks that would otherwise be intractable for uninformed
search algorithms, increasing success rates by as much as 67 percentage points.

</details>


### [180] [Robot Trains Robot: Automatic Real-World Policy Adaptation and Learning for Humanoids](https://arxiv.org/abs/2508.12252)
*Kaizhe Hu,Haochen Shi,Yao He,Weizhuo Wang,C. Karen Liu,Shuran Song*

Main category: cs.RO

TL;DR: 提出Robot-Trains-Robot（RTR）框架，通过机械臂教师指导人形机器人学生，实现高效、安全的真实世界强化学习。


<details>
  <summary>Details</summary>
Motivation: 解决真实世界强化学习中的安全、奖励设计和学习效率问题，缩小仿真与现实的差距。

Method: RTR框架提供保护、学习计划、奖励、扰动、失败检测和自动重置；提出优化动态编码潜在变量的RL流程。

Result: 成功应用于人形机器人行走策略微调和摆动任务学习，展示了真实世界学习的潜力。

Conclusion: RTR系统为真实世界人形机器人学习提供了高效、安全的解决方案。

Abstract: Simulation-based reinforcement learning (RL) has significantly advanced
humanoid locomotion tasks, yet direct real-world RL from scratch or adapting
from pretrained policies remains rare, limiting the full potential of humanoid
robots. Real-world learning, despite being crucial for overcoming the
sim-to-real gap, faces substantial challenges related to safety, reward design,
and learning efficiency. To address these limitations, we propose
Robot-Trains-Robot (RTR), a novel framework where a robotic arm teacher
actively supports and guides a humanoid robot student. The RTR system provides
protection, learning schedule, reward, perturbation, failure detection, and
automatic resets. It enables efficient long-term real-world humanoid training
with minimal human intervention. Furthermore, we propose a novel RL pipeline
that facilitates and stabilizes sim-to-real transfer by optimizing a single
dynamics-encoded latent variable in the real world. We validate our method
through two challenging real-world humanoid tasks: fine-tuning a walking policy
for precise speed tracking and learning a humanoid swing-up task from scratch,
illustrating the promising capabilities of real-world humanoid learning
realized by RTR-style systems. See https://robot-trains-robot.github.io/ for
more info.

</details>


### [181] [Bimanual Robot-Assisted Dressing: A Spherical Coordinate-Based Strategy for Tight-Fitting Garments](https://arxiv.org/abs/2508.12274)
*Jian Zhao,Yunlong Lian,Andy M Tyrrell,Michael Gienger,Jihong Zhu*

Main category: cs.RO

TL;DR: 提出了一种适用于紧身衣物的双臂穿衣策略，通过球坐标系和模仿学习生成适应不同手臂姿势的穿衣轨迹。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注宽松衣物，紧身衣物因袖窿狭窄和刚性减弱导致单臂穿衣失败，需双臂协作策略。

Method: 建立球坐标系，以方位角为任务相关特征，结合GMM和GMR进行模仿学习，生成适应不同姿势的穿衣轨迹。

Result: 实验验证了所提方法的有效性。

Conclusion: 双臂策略和球坐标系能有效解决紧身衣物穿衣问题，适应多样化手臂姿势。

Abstract: Robot-assisted dressing is a popular but challenging topic in the field of
robotic manipulation, offering significant potential to improve the quality of
life for individuals with mobility limitations. Currently, the majority of
research on robot-assisted dressing focuses on how to put on loose-fitting
clothing, with little attention paid to tight garments. For the former, since
the armscye is larger, a single robotic arm can usually complete the dressing
task successfully. However, for the latter, dressing with a single robotic arm
often fails due to the narrower armscye and the property of diminishing
rigidity in the armscye, which eventually causes the armscye to get stuck. This
paper proposes a bimanual dressing strategy suitable for dressing tight-fitting
clothing. To facilitate the encoding of dressing trajectories that adapt to
different human arm postures, a spherical coordinate system for dressing is
established. We uses the azimuthal angle of the spherical coordinate system as
a task-relevant feature for bimanual manipulation. Based on this new
coordinate, we employ Gaussian Mixture Model (GMM) and Gaussian Mixture
Regression (GMR) for imitation learning of bimanual dressing trajectories,
generating dressing strategies that adapt to different human arm postures. The
effectiveness of the proposed method is validated through various experiments.

</details>


### [182] [A robust and compliant robotic assembly control strategy for batch precision assembly task with uncertain fit types and fit amounts](https://arxiv.org/abs/2508.12296)
*Bin Wang,Jiwen Zhang,Song Wang,Dan Wu*

Main category: cs.RO

TL;DR: 论文提出了一种基于力-视觉融合控制器驱动的强化学习方法（FVFC-MTRL），用于解决机器人批量精密装配任务中不确定配合类型和配合量的问题，并通过多教师策略蒸馏整合多个控制策略，最终实现高效、鲁棒的控制。


<details>
  <summary>Details</summary>
Motivation: 在精密工业应用中，机器人需处理批量制造的轴孔装配任务，但由于加工误差导致配合类型和配合量不确定，传统方法难以适应。

Method: 将任务分解为多个确定性子任务，采用FVFC-MTRL方法联合学习多个顺应控制策略，并通过多教师策略蒸馏整合为统一策略。

Result: 实验表明，该方法能有效构建鲁棒控制策略，显著提高训练效率，并在顺应性和成功率上优于现有方法。

Conclusion: 提出的方法成功解决了不确定配合条件下的精密装配问题，为工业应用提供了高效解决方案。

Abstract: In some high-precision industrial applications, robots are deployed to
perform precision assembly tasks on mass batches of manufactured pegs and
holes. If the peg and hole are designed with transition fit, machining errors
may lead to either a clearance or an interference fit for a specific pair of
components, with uncertain fit amounts. This paper focuses on the robotic batch
precision assembly task involving components with uncertain fit types and fit
amounts, and proposes an efficient methodology to construct the robust and
compliant assembly control strategy. Specifically, the batch precision assembly
task is decomposed into multiple deterministic subtasks, and a force-vision
fusion controller-driven reinforcement learning method and a multi-task
reinforcement learning training method (FVFC-MTRL) are proposed to jointly
learn multiple compliance control strategies for these subtasks. Subsequently,
the multi-teacher policy distillation approach is designed to integrate
multiple trained strategies into a unified student network, thereby
establishing a robust control strategy. Real-world experiments demonstrate that
the proposed method successfully constructs the robust control strategy for
high-precision assembly task with different fit types and fit amounts.
Moreover, the MTRL framework significantly improves training efficiency, and
the final developed control strategy achieves superior force compliance and
higher success rate compared with many existing methods.

</details>


### [183] [Implementation and evaluation of a prediction algorithm for an autonomous vehicle](https://arxiv.org/abs/2508.12312)
*Marco Leon Rapp*

Main category: cs.RO

TL;DR: 提出了一种预测算法，用于自动驾驶车辆每5毫秒估计轨迹，动态自行车模型在高速下更准确。


<details>
  <summary>Details</summary>
Motivation: 提高自动驾驶车辆轨迹预测的精度，尤其是在高速场景下。

Method: 比较了运动学和动态自行车模型，实验确定了车辆参数，并引入光学位置跟踪测量侧偏刚度。模型集成到扩展卡尔曼滤波器中，用C++在ROS节点中实现。

Result: 算法在整个测试中每米位置偏差仅1.25厘米，比运动学模型精确82.6%。

Conclusion: 动态模型在高速下表现更优，新测量方法有效提升了预测精度。

Abstract: This paper presents a prediction algorithm that estimates the vehicle
trajectory every five milliseconds for an autonomous vehicle. A kinematic and a
dynamic bicycle model are compared, with the dynamic model exhibiting superior
accuracy at higher speeds. Vehicle parameters such as mass, center of gravity,
moment of inertia, and cornering stiffness are determined experimentally. For
cornering stiffness, a novel measurement procedure using optical position
tracking is introduced. The model is incorporated into an extended Kalman
filter and implemented in a ROS node in C++. The algorithm achieves a
positional deviation of only 1.25 cm per meter over the entire test drive and
is up to 82.6% more precise than the kinematic model.

</details>


### [184] [Semi-Infinite Programming for Collision-Avoidance in Optimal and Model Predictive Control](https://arxiv.org/abs/2508.12335)
*Yunfan Gao,Florian Messerer,Niels van Duijkeren,Rashmi Dabir,Moritz Diehl*

Main category: cs.RO

TL;DR: 提出了一种基于半无限规划（SIP）的碰撞避免方法，结合局部缩减和外部主动集方法，实现了高效的最优控制和模型预测控制。


<details>
  <summary>Details</summary>
Motivation: 解决机器人导航中因环境点表示和机器人形状参数化导致的无限约束问题，以及在状态不确定性下的鲁棒碰撞避免。

Method: 通过局部缩减和外部主动集方法，迭代识别最近障碍点，确定机器人形状参数的最小距离，并求解上层有限约束子问题。

Result: 在真实机器人上实现了20Hz的快速无碰撞导航，并在仿真中展示了3D碰撞避免应用。

Conclusion: 该方法有效解决了无限约束问题，适用于复杂环境下的鲁棒碰撞避免。

Abstract: This paper presents a novel approach for collision avoidance in optimal and
model predictive control, in which the environment is represented by a large
number of points and the robot as a union of padded polygons. The conditions
that none of the points shall collide with the robot can be written in terms of
an infinite number of constraints per obstacle point. We show that the
resulting semi-infinite programming (SIP) optimal control problem (OCP) can be
efficiently tackled through a combination of two methods: local reduction and
an external active-set method. Specifically, this involves iteratively
identifying the closest point obstacles, determining the lower-level distance
minimizer among all feasible robot shape parameters, and solving the
upper-level finitely-constrained subproblems.
  In addition, this paper addresses robust collision avoidance in the presence
of ellipsoidal state uncertainties. Enforcing constraint satisfaction over all
possible uncertainty realizations extends the dimension of constraint
infiniteness. The infinitely many constraints arising from translational
uncertainty are handled by local reduction together with the robot shape
parameterization, while rotational uncertainty is addressed via a backoff
reformulation.
  A controller implemented based on the proposed method is demonstrated on a
real-world robot running at 20Hz, enabling fast and collision-free navigation
in tight spaces. An application to 3D collision avoidance is also demonstrated
in simulation.

</details>


### [185] [SIGN: Safety-Aware Image-Goal Navigation for Autonomous Drones via Reinforcement Learning](https://arxiv.org/abs/2508.12394)
*Zichen Yan,Rui Huang,Lei He,Shao Guo,Lin Zhao*

Main category: cs.RO

TL;DR: 提出了一种基于视觉强化学习的无人机图像目标导航框架，支持自主探索、避障和目标寻找，无需全局定位。


<details>
  <summary>Details</summary>
Motivation: 解决无人机在未知环境中实现高频率反馈控制和全局定位的挑战，扩展图像目标导航能力。

Method: 利用视觉强化学习训练视觉主干网络，结合辅助任务（如图像扰动和未来状态预测）提升表示能力，并集成深度安全模块实现实时避障。

Result: 实现了端到端的图像目标导航，支持直接速度控制，无需外部定位，且能在复杂环境中安全飞行。

Conclusion: 该框架为无人机提供了全面的导航能力，适用于未知环境中的自主探索和目标寻找。

Abstract: Image-goal navigation (ImageNav) tasks a robot with autonomously exploring an
unknown environment and reaching a location that visually matches a given
target image. While prior works primarily study ImageNav for ground robots,
enabling this capability for autonomous drones is substantially more
challenging due to their need for high-frequency feedback control and global
localization for stable flight. In this paper, we propose a novel sim-to-real
framework that leverages visual reinforcement learning (RL) to achieve ImageNav
for drones. To enhance visual representation ability, our approach trains the
vision backbone with auxiliary tasks, including image perturbations and future
transition prediction, which results in more effective policy training. The
proposed algorithm enables end-to-end ImageNav with direct velocity control,
eliminating the need for external localization. Furthermore, we integrate a
depth-based safety module for real-time obstacle avoidance, allowing the drone
to safely navigate in cluttered environments. Unlike most existing drone
navigation methods that focus solely on reference tracking or obstacle
avoidance, our framework supports comprehensive navigation
behaviors--autonomous exploration, obstacle avoidance, and image-goal
seeking--without requiring explicit global mapping. Code and model checkpoints
will be released upon acceptance.

</details>


### [186] [PUB: A Plasma-Propelled Ultra-Quiet Blimp with Two-DOF Vector Thrusting](https://arxiv.org/abs/2508.12395)
*Zihan Wang*

Main category: cs.RO

TL;DR: 设计并控制了一种新型等离子体推进超静音飞艇（PUB），采用等离子体矢量推进实现无机械螺旋桨的超静音飞行。


<details>
  <summary>Details</summary>
Motivation: 解决传统机械螺旋桨飞行器噪音大、结构复杂的问题，适用于噪音敏感、封闭和近空间应用。

Method: 使用氦气提升平台延长续航，四层环形不对称电容器产生离子风推力，模块化推进单元和两自由度头部实现推力矢量控制，闭环滑移控制方案确保稳定机动。

Result: 飞行实验验证了全包线能力，包括起飞、爬升、悬停、下降和平稳着陆，证明了等离子体矢量推进的可行性、矢量控制的有效性和控制系统的稳定性。

Conclusion: PUB因其低噪音、结构简单和高机动性，适用于噪音敏感、封闭和近空间应用。

Abstract: This study presents the design and control of a Plasma-propelled
Ultra-silence Blimp (PUB), a novel aerial robot employing plasma vector
propulsion for ultra-quiet flight without mechanical propellers. The system
utilizes a helium-lift platform for extended endurance and a four-layer ring
asymmetric capacitor to generate ionic wind thrust. The modular propulsion
units allow flexible configuration to meet mission-specific requirements, while
a two-degree-of-freedom (DOF) head enables thrust vector control. A closed-loop
slip control scheme is implemented for stable maneuvering. Flight experiments
demonstrate full-envelope capability, including take-off, climb, hover,
descent, and smooth landing, confirming the feasibility of plasma vector
propulsion, the effectiveness of DOF vector control, and the stability of the
control system. Owing to its low acoustic signature, structural simplicity, and
high maneuverability, PUB is well suited for noise-sensitive, enclosed, and
near-space applications.

</details>


### [187] [Tactile Gesture Recognition with Built-in Joint Sensors for Industrial Robots](https://arxiv.org/abs/2508.12435)
*Deqing Song,Weimin Yang,Maryam Rezayati,Hans Wernher van de Venn*

Main category: cs.RO

TL;DR: 论文探讨了仅使用机器人内置关节传感器的深度学习手势识别方法，无需外部传感器。结果表明，基于频谱图的数据表示显著提高了准确性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索无需外部传感器的低成本、可扩展的人机协作解决方案。

Method: 评估了多种CNN架构，并收集了两个数据集，研究了数据表示和模型架构对识别准确性的影响。

Result: STFT2DCNN和STT3DCNN方法在接触检测和手势分类中实现了超过95%的准确率。

Conclusion: 研究证明了无需外部传感器的触觉识别的可行性，并推动了人机协作的进一步研究。

Abstract: While gesture recognition using vision or robot skins is an active research
area in Human-Robot Collaboration (HRC), this paper explores deep learning
methods relying solely on a robot's built-in joint sensors, eliminating the
need for external sensors. We evaluated various convolutional neural network
(CNN) architectures and collected two datasets to study the impact of data
representation and model architecture on the recognition accuracy. Our results
show that spectrogram-based representations significantly improve accuracy,
while model architecture plays a smaller role. We also tested generalization to
new robot poses, where spectrogram-based models performed better. Implemented
on a Franka Emika Research robot, two of our methods, STFT2DCNN and STT3DCNN,
achieved over 95% accuracy in contact detection and gesture classification.
These findings demonstrate the feasibility of external-sensor-free tactile
recognition and promote further research toward cost-effective, scalable
solutions for HRC.

</details>


### [188] [Geodesic Tracing-Based Kinematic Integration of Rolling and Sliding Contact on Manifold Meshes for Dexterous In-Hand Manipulation](https://arxiv.org/abs/2508.12439)
*Sunyu Wang,Arjun S. Lakshmipathy,Jean Oh,Nancy S. Pollard*

Main category: cs.RO

TL;DR: 论文提出了一种基于测地线追踪的滚滑接触建模方法，适用于流形网格，提升了灵巧操作的几何精度。


<details>
  <summary>Details</summary>
Motivation: 现有滚滑接触研究多关注连续形状，而本文扩展至流形网格，以更精确地表示物体几何。

Method: 采用测地线追踪的积分方案，直接在网格上对滚滑接触进行一阶时间积分。

Result: 在仿真中，多指机器人手操作五个物体时，方法在精度和准确度上优于碰撞检测和原始形状基线。

Conclusion: 未来工作将探索多接触和接触力的整合，以实现更鲁棒的网格表面接触建模。

Abstract: Reasoning about rolling and sliding contact, or roll-slide contact for short,
is critical for dexterous manipulation tasks that involve intricate geometries.
But existing works on roll-slide contact mostly focus on continuous shapes with
differentiable parametrizations. This work extends roll-slide contact modeling
to manifold meshes. Specifically, we present an integration scheme based on
geodesic tracing to first-order time-integrate roll-slide contact directly on
meshes, enabling dexterous manipulation to reason over high-fidelity discrete
representations of an object's true geometry. Using our method, we planned
dexterous motions of a multi-finger robotic hand manipulating five objects
in-hand in simulation. The planning was achieved with a least-squares optimizer
that strives to maintain the most stable instantaneous grasp by minimizing
contact sliding and spinning. Then, we evaluated our method against a baseline
using collision detection and a baseline using primitive shapes. The results
show that our method performed the best in accuracy and precision, even for
coarse meshes. We conclude with a future work discussion on incorporating
multiple contacts and contact forces to achieve accurate and robust mesh-based
surface contact modeling.

</details>


### [189] [Autonomous Oil Spill Response Through Liquid Neural Trajectory Modeling and Coordinated Marine Robotics](https://arxiv.org/abs/2508.12456)
*Hadas C. Kuzmenko,David Ehevich,Oren Gal*

Main category: cs.RO

TL;DR: 提出了一种结合多智能体群机器人系统和LTCNs的框架，用于实时预测和动态跟踪海洋油污扩散，显著提高了预测精度和响应协调性。


<details>
  <summary>Details</summary>
Motivation: 海洋油污对环境和经济造成严重威胁，实时预测和协调响应是减少灾害影响的关键。

Method: 结合MOOS-IvP平台的多智能体群机器人系统和LTCNs，实现实时预测和动态跟踪。

Result: 在Deepwater Horizon数据上验证，LTC-RK4模型空间精度达0.96，优于LSTM方法23%。

Conclusion: 该研究通过先进神经建模与自主机器人协调，提升了油污管理的预测精度和操作可扩展性，推动了可持续环境保护技术的发展。

Abstract: Marine oil spills pose grave environmental and economic risks, threatening
marine ecosystems, coastlines, and dependent industries. Predicting and
managing oil spill trajectories is highly complex, due to the interplay of
physical, chemical, and environmental factors such as wind, currents, and
temperature, which makes timely and effective response challenging. Accurate
real-time trajectory forecasting and coordinated mitigation are vital for
minimizing the impact of these disasters. This study introduces an integrated
framework combining a multi-agent swarm robotics system built on the MOOS-IvP
platform with Liquid Time-Constant Neural Networks (LTCNs). The proposed system
fuses adaptive machine learning with autonomous marine robotics, enabling
real-time prediction, dynamic tracking, and rapid response to evolving oil
spills. By leveraging LTCNs--well-suited for modeling complex, time-dependent
processes--the framework achieves real-time, high-accuracy forecasts of spill
movement. Swarm intelligence enables decentralized, scalable, and resilient
decision-making among robot agents, enhancing collective monitoring and
containment efforts. Our approach was validated using data from the Deepwater
Horizon spill, where the LTC-RK4 model achieved 0.96 spatial accuracy,
surpassing LSTM approaches by 23%. The integration of advanced neural modeling
with autonomous, coordinated robotics demonstrates substantial improvements in
prediction precision, flexibility, and operational scalability. Ultimately,
this research advances the state-of-the-art for sustainable, autonomous oil
spill management and environmental protection by enhancing both trajectory
prediction and response coordination.

</details>


### [190] [Mechanical Automation with Vision: A Design for Rubik's Cube Solver](https://arxiv.org/abs/2508.12469)
*Abhinav Chalise,Nimesh Gopal Pradhan,Nishan Khanal,Prashant Raj Bista,Dinesh Baniya Kshatri*

Main category: cs.RO

TL;DR: 论文描述了一个结合硬件和软件的系统，用于实时检测和解决魔方问题，平均解决时间为约2.2分钟。


<details>
  <summary>Details</summary>
Motivation: 开发一个用户友好的系统，通过硬件和软件的结合实现魔方的实时检测和解决。

Method: 系统使用三个步进电机进行物理操作，微控制器控制硬件，摄像头和YOLO检测模型实时检测魔方状态。软件部分包括基于Unity开发的GUI，并使用Kociemba算法生成解决方案。

Result: 系统实现了高精度的魔方状态检测（YOLOv8模型的Precision为0.98443，Recall为0.98419），平均解决时间为约2.2分钟。

Conclusion: 该系统成功结合了硬件和软件技术，实现了高效的魔方实时检测和解决。

Abstract: The core mechanical system is built around three stepper motors for physical
manipulation, a microcontroller for hardware control, a camera and YOLO
detection model for real-time cube state detection. A significant software
component is the development of a user-friendly graphical user interface (GUI)
designed in Unity. The initial state after detection from real-time YOLOv8
model (Precision 0.98443, Recall 0.98419, Box Loss 0.42051, Class Loss 0.2611)
is virtualized on GUI. To get the solution, the system employs the Kociemba's
algorithm while physical manipulation with a single degree of freedom is done
by combination of stepper motors' interaction with the cube achieving the
average solving time of ~2.2 minutes.

</details>


### [191] [PROD: Palpative Reconstruction of Deformable Objects through Elastostatic Signed Distance Functions](https://arxiv.org/abs/2508.12554)
*Hamza El-Kebir*

Main category: cs.RO

TL;DR: PROD是一种通过触觉交互和弹性静力学SDF重建可变形物体形状和力学特性的新方法。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖几何或视觉数据，无法全面捕捉软材料的静态和动态响应。PROD通过触觉交互弥补这一不足。

Method: 利用弹性静力学SDF和泊松方程，结合力控表面探测数据，估计物体的形状和材料刚度。

Result: PROD在模拟软体交互中表现出对姿态误差、非垂直力施加和曲率误差的鲁棒性。

Conclusion: PROD在机器人操作、医学成像和触觉反馈等领域具有广泛应用潜力。

Abstract: We introduce PROD (Palpative Reconstruction of Deformables), a novel method
for reconstructing the shape and mechanical properties of deformable objects
using elastostatic signed distance functions (SDFs). Unlike traditional
approaches that rely on purely geometric or visual data, PROD integrates
palpative interaction -- measured through force-controlled surface probing --
to estimate both the static and dynamic response of soft materials. We model
the deformation of an object as an elastostatic process and derive a governing
Poisson equation for estimating its SDF from a sparse set of pose and force
measurements. By incorporating steady-state elastodynamic assumptions, we show
that the undeformed SDF can be recovered from deformed observations with
provable convergence. Our approach also enables the estimation of material
stiffness by analyzing displacement responses to varying force inputs. We
demonstrate the robustness of PROD in handling pose errors, non-normal force
application, and curvature errors in simulated soft body interactions. These
capabilities make PROD a powerful tool for reconstructing deformable objects in
applications ranging from robotic manipulation to medical imaging and haptic
feedback systems.

</details>


### [192] [Temporal and Rotational Calibration for Event-Centric Multi-Sensor Systems](https://arxiv.org/abs/2508.12564)
*Jiayao Mai,Xiuyuan Lu,Kuan Dai,Shaojie Shen,Yi Zhou*

Main category: cs.RO

TL;DR: 提出了一种基于运动的时空标定框架，用于事件相机多传感器系统，无需专用标定目标。


<details>
  <summary>Details</summary>
Motivation: 事件相机在多传感器系统中的标定问题尚未充分研究，现有方法依赖标定目标或事件到帧转换。

Method: 利用事件相机和其他传感器的旋转运动估计，通过角速度估计和两步优化（CCA初始化和非线性优化）完成标定。

Result: 在公开和自采数据集上验证，标定精度与基于目标的方法相当，稳定性优于纯CCA方法。

Conclusion: 方法具有高精度、鲁棒性和灵活性，代码已开源。

Abstract: Event cameras generate asynchronous signals in response to pixel-level
brightness changes, offering a sensing paradigm with theoretically
microsecond-scale latency that can significantly enhance the performance of
multi-sensor systems. Extrinsic calibration is a critical prerequisite for
effective sensor fusion; however, the configuration that involves event cameras
remains an understudied topic. In this paper, we propose a motion-based
temporal and rotational calibration framework tailored for event-centric
multi-sensor systems, eliminating the need for dedicated calibration targets.
Our method uses as input the rotational motion estimates obtained from event
cameras and other heterogeneous sensors, respectively. Different from
conventional approaches that rely on event-to-frame conversion, our method
efficiently estimates angular velocity from normal flow observations, which are
derived from the spatio-temporal profile of event data. The overall calibration
pipeline adopts a two-step approach: it first initializes the temporal offset
and rotational extrinsics by exploiting kinematic correlations in the spirit of
Canonical Correlation Analysis (CCA), and then refines both temporal and
rotational parameters through a joint non-linear optimization using a
continuous-time parametrization in SO(3). Extensive evaluations on both
publicly available and self-collected datasets validate that the proposed
method achieves calibration accuracy comparable to target-based methods, while
exhibiting superior stability over purely CCA-based methods, and highlighting
its precision, robustness and flexibility. To facilitate future research, our
implementation will be made open-source. Code:
https://github.com/NAIL-HNU/EvMultiCalib.

</details>


### [193] [Adaptive Model-Predictive Control of a Soft Continuum Robot Using a Physics-Informed Neural Network Based on Cosserat Rod Theory](https://arxiv.org/abs/2508.12681)
*Johann Licher,Max Bartholdt,Henrik Krauss,Tim-Lukas Habich,Thomas Seel,Moritz Schappler*

Main category: cs.RO

TL;DR: 提出了一种基于DD-PINN的实时非线性MPC框架，用于软体连续机器人的动态控制，显著提升了计算速度和跟踪精度。


<details>
  <summary>Details</summary>
Motivation: 软体连续机器人的动态控制因高计算需求而具有挑战性，现有数据驱动方法缺乏适应性和形状捕捉能力。

Method: 采用域解耦物理信息神经网络（DD-PINN）作为动态模型的替代，结合无迹卡尔曼滤波和GPU加速的非线性MPC。

Result: 仿真中跟踪误差低于3毫米（2.3%长度），实验中达到类似精度和最高3.55 m/s²的加速度。

Conclusion: 该框架在计算效率和动态控制精度上表现优异，适用于实际应用。

Abstract: Dynamic control of soft continuum robots (SCRs) holds great potential for
expanding their applications, but remains a challenging problem due to the high
computational demands of accurate dynamic models. While data-driven approaches
like Koopman-operator-based methods have been proposed, they typically lack
adaptability and cannot capture the full robot shape, limiting their
applicability. This work introduces a real-time-capable nonlinear
model-predictive control (MPC) framework for SCRs based on a domain-decoupled
physics-informed neural network (DD-PINN) with adaptable bending stiffness. The
DD-PINN serves as a surrogate for the dynamic Cosserat rod model with a
speed-up factor of 44000. It is also used within an unscented Kalman filter for
estimating the model states and bending compliance from end-effector position
measurements. We implement a nonlinear evolutionary MPC running at 70 Hz on the
GPU. In simulation, it demonstrates accurate tracking of dynamic trajectories
and setpoint control with end-effector position errors below 3 mm (2.3% of the
actuator's length). In real-world experiments, the controller achieves similar
accuracy and accelerations up to 3.55 m/s2.

</details>


### [194] [MCTR: Midpoint Corrected Triangulation for Autonomous Racing via Digital Twin Simulation in CARLA](https://arxiv.org/abs/2508.12729)
*Junhao Ye,Cheng Hu,Yiqin Wang,Weizhan Huang,Nicolas Baumann,Jie He,Meixun Qu,Lei Xie,Hongye Su*

Main category: cs.RO

TL;DR: MCTR算法通过改进轨迹平滑度和引入3D LiDAR感知验证，提升了自动驾驶赛车中的反应式控制性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如DTR）在轨迹生成中存在平滑度不足的问题，且F1TENTH模拟器缺乏3D LiDAR支持，限制了测试效果。

Method: 提出MCTR算法，结合曲率校正移动平均（CCMA）提升轨迹平滑度，并在CARLA模拟器中构建数字孪生系统以支持3D LiDAR验证。

Result: 算法在仿真和实际车辆实验中均验证了其鲁棒性和性能提升。

Conclusion: MCTR算法有效解决了轨迹平滑度和3D LiDAR测试的挑战，为自动驾驶赛车提供了更优的解决方案。

Abstract: In autonomous racing, reactive controllers eliminate the computational burden
of the full See-Think-Act autonomy stack by directly mapping sensor inputs to
control actions. This bypasses the need for explicit localization and
trajectory planning. A widely adopted baseline in this category is the
Follow-The-Gap method, which performs trajectory planning using LiDAR data.
Building on FTG, the Delaunay Triangulation-based Racing algorithm introduces
further enhancements. However, DTR's use of circumcircles for trajectory
generation often results in insufficiently smooth paths, ultimately degrading
performance. Additionally, the commonly used F1TENTH-simulator for autonomous
racing competitions lacks support for 3D LiDAR perception, limiting its
effectiveness in realistic testing. To address these challenges, this work
proposes the MCTR algorithm. MCTR improves trajectory smoothness through the
use of Curvature Corrected Moving Average and implements a digital twin system
within the CARLA simulator to validate the algorithm's robustness under 3D
LiDAR perception. The proposed algorithm has been thoroughly validated through
both simulation and real-world vehicle experiments.

</details>


### [195] [RoboRetriever: Single-Camera Robot Object Retrieval via Active and Interactive Perception with Dynamic Scene Graph](https://arxiv.org/abs/2508.12916)
*Hecheng Wang,Jiankun Ren,Jia Yu,Lizhe Qi,Yunquan Sun*

Main category: cs.RO

TL;DR: RoboRetriever是一个仅使用单个手腕安装的RGB-D相机和自然语言指令的机器人框架，通过动态层次场景图和主动感知实现物体检索。


<details>
  <summary>Details</summary>
Motivation: 人类在部分可见环境中能轻松检索物体，而现有机器人系统依赖多摄像头设置，成本高且适应性差。

Method: 构建动态层次场景图，结合视觉提示和大型视觉语言模型，协调主动感知、交互感知和操作。

Result: 在多样化真实场景中表现出强适应性和鲁棒性。

Conclusion: RoboRetriever展示了单摄像头系统在复杂环境中的高效物体检索能力。

Abstract: Humans effortlessly retrieve objects in cluttered, partially observable
environments by combining visual reasoning, active viewpoint adjustment, and
physical interaction-with only a single pair of eyes. In contrast, most
existing robotic systems rely on carefully positioned fixed or multi-camera
setups with complete scene visibility, which limits adaptability and incurs
high hardware costs. We present \textbf{RoboRetriever}, a novel framework for
real-world object retrieval that operates using only a \textbf{single}
wrist-mounted RGB-D camera and free-form natural language instructions.
RoboRetriever grounds visual observations to build and update a \textbf{dynamic
hierarchical scene graph} that encodes object semantics, geometry, and
inter-object relations over time. The supervisor module reasons over this
memory and task instruction to infer the target object and coordinate an
integrated action module combining \textbf{active perception},
\textbf{interactive perception}, and \textbf{manipulation}. To enable
task-aware scene-grounded active perception, we introduce a novel visual
prompting scheme that leverages large reasoning vision-language models to
determine 6-DoF camera poses aligned with the semantic task goal and geometry
scene context. We evaluate RoboRetriever on diverse real-world object retrieval
tasks, including scenarios with human intervention, demonstrating strong
adaptability and robustness in cluttered scenes with only one RGB-D camera.

</details>


### [196] [Deformation of the panoramic sphere into an ellipsoid to induce self-motion in telepresence users](https://arxiv.org/abs/2508.12925)
*Eetu Laukka,Evan G. Center,Timo Ojala,Steven M. LaValle,Matti Pouke*

Main category: cs.RO

TL;DR: 研究探讨了利用光流在延迟期间创造自运动错觉的方法，但未显著提升控制性能，反而可能增加VR眩晕感。


<details>
  <summary>Details</summary>
Motivation: 解决360度摄像头在远程控制机器人时的高延迟问题，提升用户体验。

Method: 使用光流在用户发送指令到实际看到运动之间的延迟期间创造自运动错觉。

Result: 在500毫秒延迟下，该方法未显著提升任务完成时间或减少碰撞，但可能增加VR眩晕感。

Conclusion: 需进一步调整方法以使其可行。

Abstract: Mobile telepresence robots allow users to feel present and explore remote
environments using technology. Traditionally, these systems are implemented
using a camera onboard a mobile robot that can be controlled. Although
high-immersion technologies, such as 360-degree cameras, can increase
situational awareness and presence, they also introduce significant challenges.
Additional processing and bandwidth requirements often result in latencies of
up to seconds. The current delay with a 360-degree camera streaming over the
internet makes real-time control of these systems difficult. Working with
high-latency systems requires some form of assistance to the users.
  This study presents a novel way to utilize optical flow to create an illusion
of self-motion to the user during the latency period between user sending
motion commands to the robot and seeing the actual motion through the
360-camera stream. We find no significant benefit of using the self-motion
illusion to performance or accuracy of controlling a telepresence robot with a
latency of 500 ms, as measured by the task completion time and collisions into
objects. Some evidence is shown that the method might increase virtual reality
(VR) sickness, as measured by the simulator sickness questionnaire (SSQ). We
conclude that further adjustments are necessary in order to render the method
viable.

</details>


### [197] [Simultaneous Contact Sequence and Patch Planning for Dynamic Locomotion](https://arxiv.org/abs/2508.12928)
*Victor Dhédin,Haizhou Zhao,Majid Khadiv*

Main category: cs.RO

TL;DR: 提出了一种基于MCTS和TO的框架，用于解决四足机器人在复杂环境中的运动规划问题，并成功应用于真实机器人。


<details>
  <summary>Details</summary>
Motivation: 解决四足机器人在高度受限环境中运动规划的复杂优化问题。

Method: 结合蒙特卡洛树搜索（MCTS）和全身轨迹优化（TO），实现接触序列和路径选择的同步规划。

Result: 在仿真和真实机器人上验证了框架的有效性，能够快速生成多样化的动态一致计划。

Conclusion: 首次展示了基于全身动力学的四足机器人非周期性多接触运动规划的成功应用。

Abstract: Legged robots have the potential to traverse highly constrained environments
with agile maneuvers. However, planning such motions requires solving a highly
challenging optimization problem with a mixture of continuous and discrete
decision variables. In this paper, we present a full pipeline based on
Monte-Carlo tree search (MCTS) and whole-body trajectory optimization (TO) to
perform simultaneous contact sequence and patch selection on highly challenging
environments. Through extensive simulation experiments, we show that our
framework can quickly find a diverse set of dynamically consistent plans. We
experimentally show that these plans are transferable to a real quadruped
robot. We further show that the same framework can find highly complex acyclic
humanoid maneuvers. To the best of our knowledge, this is the first
demonstration of simultaneous contact sequence and patch selection for acyclic
multi-contact locomotion using the whole-body dynamics of a quadruped.

</details>


### [198] [Insights from Interviews with Teachers and Students on the Use of a Social Robot in Computer Science Class in Sixth Grade](https://arxiv.org/abs/2508.12946)
*Ann-Sophie Schenk,Stefan Schiffer,Heqiu Song*

Main category: cs.RO

TL;DR: 研究探讨了六年级计算机科学课堂中使用社交机器人的初步见解，重点关注教师和学生的需求与应用潜力。


<details>
  <summary>Details</summary>
Motivation: 了解教师和学习者对机器人使用的看法及其功能需求，以促进教育机器人的设计。

Method: 通过访谈教师和学生，收集他们对社交机器人在课堂中使用的要求和潜在应用的看法。

Result: 教师和学生普遍对课堂中使用机器人持开放态度，但需求在不同群体中存在较大差异。

Conclusion: 研究揭示了复杂的设计挑战，需要在机器人设计中平衡不同群体的需求。

Abstract: In this paper we report on first insights from interviews with teachers and
students on using social robots in computer science class in sixth grade. Our
focus is on learning about requirements and potential applications. We are
particularly interested in getting both perspectives, the teachers' and the
learners' view on how robots could be used and what features they should or
should not have. Results show that teachers as well as students are very open
to robots in the classroom. However, requirements are partially quite
heterogeneous among the groups. This leads to complex design challenges which
we discuss at the end of this paper.

</details>


### [199] [Scaling Whole-body Multi-contact Manipulation with Contact Optimization](https://arxiv.org/abs/2508.12980)
*Victor Levé,João Moura,Sachiya Fujita,Tamon Miyake,Steve Tonneau,Sethu Vijayakumar*

Main category: cs.RO

TL;DR: 提出了一种用于人形机器人全身操纵任务的连续接触表面表示方法，显著提高了规划效率。


<details>
  <summary>Details</summary>
Motivation: 现有规划方法依赖离散采样，难以处理机器人全身操纵任务中接触表面的无限可能性。

Method: 提出了一种机器人及物体表面的表示方法，支持闭式计算邻近点，并设计了有效的成本函数。

Result: 实验显示，该方法解决了现有方法未解决的问题，规划时间比现有技术提高了77%。

Conclusion: 该方法在真实硬件上验证了其有效性，适用于人形机器人的全身操纵任务。

Abstract: Daily tasks require us to use our whole body to manipulate objects, for
instance when our hands are unavailable. We consider the issue of providing
humanoid robots with the ability to autonomously perform similar whole-body
manipulation tasks. In this context, the infinite possibilities for where and
how contact can occur on the robot and object surfaces hinder the scalability
of existing planning methods, which predominantly rely on discrete sampling.
Given the continuous nature of contact surfaces, gradient-based optimization
offers a more suitable approach for finding solutions. However, a key remaining
challenge is the lack of an efficient representation of robot surfaces. In this
work, we propose (i) a representation of robot and object surfaces that enables
closed-form computation of proximity points, and (ii) a cost design that
effectively guides whole-body manipulation planning. Our experiments
demonstrate that the proposed framework can solve problems unaddressed by
existing methods, and achieves a 77% improvement in planning time over the
state of the art. We also validate the suitability of our approach on real
hardware through the whole-body manipulation of boxes by a humanoid robot.

</details>


### [200] [BOW: Bayesian Optimization over Windows for Motion Planning in Complex Environments](https://arxiv.org/abs/2508.13052)
*Sourav Raxit,Abdullah Al Redwan Newaz,Paulo Padrao,Jose Fuentes,Leonardo Bobadilla*

Main category: cs.RO

TL;DR: BOW Planner是一种基于约束贝叶斯优化的可扩展运动规划算法，适用于复杂环境中的机器人导航，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统运动规划方法在处理动力学约束（如速度和加速度限制）时表现不佳，BOW Planner通过优化可达速度窗口和高效采样控制输入来解决这一问题。

Method: 采用约束贝叶斯优化（CBO）方法，专注于可达速度窗口，高效采样控制输入，以处理高维目标函数和严格安全约束。

Result: 理论分析证明算法渐近收敛于接近最优解，实验显示在计算时间、轨迹长度和解算时间上显著优于现有技术。

Conclusion: BOW Planner在实际机器人系统中表现出色，具有高效采样、安全优化和快速规划能力，已开源并展示于实验视频。

Abstract: This paper introduces the BOW Planner, a scalable motion planning algorithm
designed to navigate robots through complex environments using constrained
Bayesian optimization (CBO). Unlike traditional methods, which often struggle
with kinodynamic constraints such as velocity and acceleration limits, the BOW
Planner excels by concentrating on a planning window of reachable velocities
and employing CBO to sample control inputs efficiently. This approach enables
the planner to manage high-dimensional objective functions and stringent safety
constraints with minimal sampling, ensuring rapid and secure trajectory
generation. Theoretical analysis confirms the algorithm's asymptotic
convergence to near-optimal solutions, while extensive evaluations in cluttered
and constrained settings reveal substantial improvements in computation times,
trajectory lengths, and solution times compared to existing techniques.
Successfully deployed across various real-world robotic systems, the BOW
Planner demonstrates its practical significance through exceptional sample
efficiency, safety-aware optimization, and rapid planning capabilities, making
it a valuable tool for advancing robotic applications. The BOW Planner is
released as an open-source package and videos of real-world and simulated
experiments are available at https://bow-web.github.io.

</details>


### [201] [Large VLM-based Vision-Language-Action Models for Robotic Manipulation: A Survey](https://arxiv.org/abs/2508.13073)
*Rui Shao,Wei Li,Lingsen Zhang,Renshan Zhang,Zhiyang Liu,Ran Chen,Liqiang Nie*

Main category: cs.RO

TL;DR: 这篇综述系统地回顾了基于大型视觉语言模型（VLM）的视觉-语言-动作（VLA）模型在机器人操作中的应用，提出了分类架构并总结了最新进展。


<details>
  <summary>Details</summary>
Motivation: 传统基于规则的方法在非结构化环境中难以扩展和泛化，而基于大型VLM的VLA模型为解决这一问题提供了新范式。

Method: 定义了基于大型VLM的VLA模型，并分类为单体模型（单系统和双系统设计）和分层模型（显式解耦规划与执行）。

Result: 总结了VLA模型在强化学习、无训练优化、人类视频学习和世界模型集成等领域的应用，并提出了未来研究方向。

Conclusion: 该综述整合了最新进展，解决了现有分类的不一致性，填补了大型VLM与机器人操作交叉研究的空白。

Abstract: Robotic manipulation, a key frontier in robotics and embodied AI, requires
precise motor control and multimodal understanding, yet traditional rule-based
methods fail to scale or generalize in unstructured, novel environments. In
recent years, Vision-Language-Action (VLA) models, built upon Large
Vision-Language Models (VLMs) pretrained on vast image-text datasets, have
emerged as a transformative paradigm. This survey provides the first
systematic, taxonomy-oriented review of large VLM-based VLA models for robotic
manipulation. We begin by clearly defining large VLM-based VLA models and
delineating two principal architectural paradigms: (1) monolithic models,
encompassing single-system and dual-system designs with differing levels of
integration; and (2) hierarchical models, which explicitly decouple planning
from execution via interpretable intermediate representations. Building on this
foundation, we present an in-depth examination of large VLM-based VLA models:
(1) integration with advanced domains, including reinforcement learning,
training-free optimization, learning from human videos, and world model
integration; (2) synthesis of distinctive characteristics, consolidating
architectural traits, operational strengths, and the datasets and benchmarks
that support their development; (3) identification of promising directions,
including memory mechanisms, 4D perception, efficient adaptation, multi-agent
cooperation, and other emerging capabilities. This survey consolidates recent
advances to resolve inconsistencies in existing taxonomies, mitigate research
fragmentation, and fill a critical gap through the systematic integration of
studies at the intersection of large VLMs and robotic manipulation. We provide
a regularly updated project page to document ongoing progress:
https://github.com/JiuTian-VL/Large-VLM-based-VLA-for-Robotic-Manipulation.

</details>


### [202] [Grounding Actions in Camera Space: Observation-Centric Vision-Language-Action Policy](https://arxiv.org/abs/2508.13103)
*Tianyi Zhang,Haonan Duan,Haoran Hao,Yu Qiao,Jifeng Dai,Zhi Hou*

Main category: cs.RO

TL;DR: OC-VLA框架通过将动作预测直接基于相机观测空间，解决了VLA模型在真实环境中因观测与动作空间不一致导致的泛化问题。


<details>
  <summary>Details</summary>
Motivation: VLA模型在真实环境中泛化能力受限，主要由于观测空间与动作空间的不一致。

Method: 提出OC-VLA框架，利用相机外参矩阵将末端执行器位姿转换到相机坐标系，统一预测目标。

Result: 实验表明OC-VLA加速收敛、提高任务成功率，并增强跨视角泛化能力。

Conclusion: OC-VLA是一种轻量级即插即用方案，显著提升VLA模型对相机视角变化的鲁棒性。

Abstract: Vision-Language-Action (VLA) models frequently encounter challenges in
generalizing to real-world environments due to inherent discrepancies between
observation and action spaces. Although training data are collected from
diverse camera perspectives, the models typically predict end-effector poses
within the robot base coordinate frame, resulting in spatial inconsistencies.
To mitigate this limitation, we introduce the Observation-Centric VLA (OC-VLA)
framework, which grounds action predictions directly in the camera observation
space. Leveraging the camera's extrinsic calibration matrix, OC-VLA transforms
end-effector poses from the robot base coordinate system into the camera
coordinate system, thereby unifying prediction targets across heterogeneous
viewpoints. This lightweight, plug-and-play strategy ensures robust alignment
between perception and action, substantially improving model resilience to
camera viewpoint variations. The proposed approach is readily compatible with
existing VLA architectures, requiring no substantial modifications.
Comprehensive evaluations on both simulated and real-world robotic manipulation
tasks demonstrate that OC-VLA accelerates convergence, enhances task success
rates, and improves cross-view generalization. The code will be publicly
available.

</details>


### [203] [Manipulate-to-Navigate: Reinforcement Learning with Visual Affordances and Manipulability Priors](https://arxiv.org/abs/2508.13151)
*Yuying Zhang,Joni Pajarinen*

Main category: cs.RO

TL;DR: 论文提出了一种基于强化学习的方法，解决动态环境中机器人移动与操纵结合的挑战，通过结合可操纵性先验和功能映射，有效学习操纵策略。


<details>
  <summary>Details</summary>
Motivation: 动态环境中，传统方法将导航与操纵分开处理，无法应对需要先操纵障碍物再导航的场景。

Method: 结合可操纵性先验和功能映射，通过强化学习学习操纵动作，减少不必要的探索。

Result: 在模拟任务（Reach和Door）中表现良好，并将策略成功迁移到真实机器人上。

Conclusion: 该方法能有效解决动态环境中的移动与操纵问题，具有实际应用潜力。

Abstract: Mobile manipulation in dynamic environments is challenging due to movable
obstacles blocking the robot's path. Traditional methods, which treat
navigation and manipulation as separate tasks, often fail in such
'manipulate-to-navigate' scenarios, as obstacles must be removed before
navigation. In these cases, active interaction with the environment is required
to clear obstacles while ensuring sufficient space for movement. To address the
manipulate-to-navigate problem, we propose a reinforcement learning-based
approach for learning manipulation actions that facilitate subsequent
navigation. Our method combines manipulability priors to focus the robot on
high manipulability body positions with affordance maps for selecting
high-quality manipulation actions. By focusing on feasible and meaningful
actions, our approach reduces unnecessary exploration and allows the robot to
learn manipulation strategies more effectively. We present two new
manipulate-to-navigate simulation tasks called Reach and Door with the Boston
Dynamics Spot robot. The first task tests whether the robot can select a good
hand position in the target area such that the robot base can move effectively
forward while keeping the end effector position fixed. The second task requires
the robot to move a door aside in order to clear the navigation path. Both of
these tasks need first manipulation and then navigating the base forward.
Results show that our method allows a robot to effectively interact with and
traverse dynamic environments. Finally, we transfer the learned policy to a
real Boston Dynamics Spot robot, which successfully performs the Reach task.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [204] [Sparse Attention across Multiple-context KV Cache](https://arxiv.org/abs/2508.11661)
*Ziyi Cao,Qingyi Si,Jingbin Zhang,Bingquan Liu*

Main category: cs.LG

TL;DR: SamKV提出了一种针对多上下文KV Cache的注意力稀疏化方法，显著提升了RAG场景中的推理效率。


<details>
  <summary>Details</summary>
Motivation: 解决多上下文RAG场景中现有KV Cache稀疏化方法因缺乏跨上下文注意力而失效的问题。

Method: SamKV在稀疏化一个上下文时考虑其他上下文的互补信息，并局部重新计算稀疏化信息。

Result: 实验表明，SamKV将序列长度压缩至15%，且无准确率损失，显著提升了吞吐量。

Conclusion: SamKV是首个针对多上下文KV Cache的注意力稀疏化方法，有效解决了现有方法的局限性。

Abstract: Large language models face significant cost challenges in long-sequence
inference. To address this, reusing historical Key-Value (KV) Cache for
improved inference efficiency has become a mainstream approach. Recent advances
further enhance throughput by sparse attention mechanisms to select the most
relevant KV Cache, thereby reducing sequence length. However, such techniques
are limited to single-context scenarios, where historical KV Cache is computed
sequentially with causal-attention dependencies. In retrieval-augmented
generation (RAG) scenarios, where retrieved documents as context are unknown
beforehand, each document's KV Cache is computed and stored independently
(termed multiple-context KV Cache), lacking cross-attention between contexts.
This renders existing methods ineffective. Although prior work partially
recomputes multiple-context KV Cache to mitigate accuracy loss from missing
cross-attention, it requires retaining all KV Cache throughout, failing to
reduce memory overhead. This paper presents SamKV, the first exploration of
attention sparsification for multiple-context KV Cache. Specifically, SamKV
takes into account the complementary information of other contexts when
sparsifying one context, and then locally recomputes the sparsified
information. Experiments demonstrate that our method compresses sequence length
to 15% without accuracy degradation compared with full-recompuation baselines,
significantly boosting throughput in multi-context RAG scenarios.

</details>


### [205] [Assessing Representation Stability for Transformer Models](https://arxiv.org/abs/2508.11667)
*Bryan E. Tuck,Rakesh M. Verma*

Main category: cs.LG

TL;DR: 提出了一种名为Representation Stability (RS)的模型无关检测框架，通过测量嵌入表示的变化来识别对抗性文本攻击。


<details>
  <summary>Details</summary>
Motivation: 现有防御方法通常针对特定攻击或需要昂贵的模型重新训练，RS旨在提供一种更通用且高效的解决方案。

Method: RS通过重要性启发式对单词进行排序，测量嵌入对屏蔽关键词的敏感性，并使用BiLSTM检测器处理结果模式。

Result: 在三个数据集、三种攻击类型和两种受害者模型上，RS实现了超过88%的检测准确率，且计算成本较低。

Conclusion: RS无需重新训练即可泛化到未见过的数据集、攻击和模型，为对抗性文本检测提供了实用解决方案。

Abstract: Adversarial text attacks remain a persistent threat to transformer models,
yet existing defenses are typically attack-specific or require costly model
retraining. We introduce Representation Stability (RS), a model-agnostic
detection framework that identifies adversarial examples by measuring how
embedding representations change when important words are masked. RS first
ranks words using importance heuristics, then measures embedding sensitivity to
masking top-k critical words, and processes the resulting patterns with a
BiLSTM detector. Experiments show that adversarially perturbed words exhibit
disproportionately high masking sensitivity compared to naturally important
words. Across three datasets, three attack types, and two victim models, RS
achieves over 88% detection accuracy and demonstrates competitive performance
compared to existing state-of-the-art methods, often at lower computational
cost. Using Normalized Discounted Cumulative Gain (NDCG) to measure
perturbation identification quality, we reveal that gradient-based ranking
outperforms attention and random selection approaches, with identification
quality correlating with detection performance for word-level attacks. RS also
generalizes well to unseen datasets, attacks, and models without retraining,
providing a practical solution for adversarial text detection.

</details>


### [206] [Collaborative Learning-Enhanced Lightweight Models for Predicting Arterial Blood Pressure Waveform in a Large-scale Perioperative Dataset](https://arxiv.org/abs/2508.11669)
*Wentao Li,Yonghu He,Kun Gao,Qing Liu,Yali Zheng*

Main category: cs.LG

TL;DR: 该论文提出了一种轻量级的sInvResUNet模型及协作学习方案KDCL_sInvResUNet，用于在嵌入式设备上实现实时无创血压监测。


<details>
  <summary>Details</summary>
Motivation: 解决现有深度学习模型在嵌入式系统上部署时的性能和计算负载问题。

Method: 采用轻量级sInvResUNet和协作学习方案KDCL_sInvResUNet，参数少且计算负载低。

Result: 在大型数据集上验证，模型性能优于大型模型，但泛化能力有限。

Conclusion: 为实时无创血压监测奠定了基础，但需进一步改进泛化能力。

Abstract: Noninvasive arterial blood pressure (ABP) monitoring is essential for patient
management in critical care and perioperative settings, providing continuous
assessment of cardiovascular hemodynamics with minimal risks. Numerous deep
learning models have developed to reconstruct ABP waveform from noninvasively
acquired physiological signals such as electrocardiogram and
photoplethysmogram. However, limited research has addressed the issue of model
performance and computational load for deployment on embedded systems. The
study introduces a lightweight sInvResUNet, along with a collaborative learning
scheme named KDCL_sInvResUNet. With only 0.89 million parameters and a
computational load of 0.02 GFLOPS, real-time ABP estimation was successfully
achieved on embedded devices with an inference time of just 8.49 milliseconds
for a 10-second output. We performed subject-independent validation in a
large-scale and heterogeneous perioperative dataset containing 1,257,141 data
segments from 2,154 patients, with a wide BP range (41-257 mmHg for SBP, and
31-234 mmHg for DBP). The proposed KDCL_sInvResUNet achieved lightly better
performance compared to large models, with a mean absolute error of 10.06 mmHg
and mean Pearson correlation of 0.88 in tracking ABP changes. Despite these
promising results, all deep learning models showed significant performance
variations across different demographic and cardiovascular conditions,
highlighting their limited ability to generalize across such a broad and
diverse population. This study lays a foundation work for real-time,
unobtrusive ABP monitoring in real-world perioperative settings, providing
baseline for future advancements in this area.

</details>


### [207] [Contrastive Regularization over LoRA for Multimodal Biomedical Image Incremental Learning](https://arxiv.org/abs/2508.11673)
*Haojie Zhang,Yixiong Liang,Hulin Kuang,Lihui Cen,Zhe Qu,Yigang Cen,Min Zeng,Shichao Kan*

Main category: cs.LG

TL;DR: MBIIL提出MSLoRA-CR方法，通过模态特定LoRA模块和对比正则化解决跨模态增量学习问题，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决生物医学领域中多模态增量学习的挑战，避免为每个模态或任务单独训练模型的高成本。

Method: 使用模态特定LoRA模块和对比正则化，基于大型视觉语言模型（LVLM）进行增量学习。

Result: MSLoRA-CR在生物医学图像增量学习中表现优于现有方法，性能提升1.88%，同时保持计算效率。

Conclusion: MSLoRA-CR为多模态增量学习提供了一种高效且性能优越的解决方案。

Abstract: Multimodal Biomedical Image Incremental Learning (MBIIL) is essential for
handling diverse tasks and modalities in the biomedical domain, as training
separate models for each modality or task significantly increases inference
costs. Existing incremental learning methods focus on task expansion within a
single modality, whereas MBIIL seeks to train a unified model incrementally
across modalities. The MBIIL faces two challenges: I) How to preserve
previously learned knowledge during incremental updates? II) How to effectively
leverage knowledge acquired from existing modalities to support new modalities?
To address these challenges, we propose MSLoRA-CR, a method that fine-tunes
Modality-Specific LoRA modules while incorporating Contrastive Regularization
to enhance intra-modality knowledge sharing and promote inter-modality
knowledge differentiation. Our approach builds upon a large vision-language
model (LVLM), keeping the pretrained model frozen while incrementally adapting
new LoRA modules for each modality or task. Experiments on the incremental
learning of biomedical images demonstrate that MSLoRA-CR outperforms both the
state-of-the-art (SOTA) approach of training separate models for each modality
and the general incremental learning method (incrementally fine-tuning LoRA).
Specifically, MSLoRA-CR achieves a 1.88% improvement in overall performance
compared to unconstrained incremental learning methods while maintaining
computational efficiency. Our code is publicly available at
https://github.com/VentusAislant/MSLoRA_CR.

</details>


### [208] [Lifelong Learner: Discovering Versatile Neural Solvers for Vehicle Routing Problems](https://arxiv.org/abs/2508.11679)
*Shaodi Feng,Zhuoyi Lin,Jianan Zhou,Cong Zhang,Jingwen Li,Kuan-Wen Chen,Senthilnath Jayavelu,Yew-Soon Ong*

Main category: cs.LG

TL;DR: 提出了一种终身学习框架，通过增量训练神经求解器解决不同场景下的车辆路径问题（VRP），提升了神经求解器的通用性。


<details>
  <summary>Details</summary>
Motivation: 现有神经求解器在单一场景下训练，限制了其在不同场景中的应用，因此需要提升其通用性。

Method: 采用Transformer网络作为主干，提出跨上下文自注意力机制和动态上下文调度器（DCS），通过经验回放促进知识迁移。

Result: 在合成和基准实例（问题规模达18k）上表现优异，优于其他神经求解器。

Conclusion: 该框架能够有效解决不同场景下的VRP问题，具有广泛适用性。

Abstract: Deep learning has been extensively explored to solve vehicle routing problems
(VRPs), which yields a range of data-driven neural solvers with promising
outcomes. However, most neural solvers are trained to tackle VRP instances in a
relatively monotonous context, e.g., simplifying VRPs by using Euclidean
distance between nodes and adhering to a single problem size, which harms their
off-the-shelf application in different scenarios. To enhance their versatility,
this paper presents a novel lifelong learning framework that incrementally
trains a neural solver to manage VRPs in distinct contexts. Specifically, we
propose a lifelong learner (LL), exploiting a Transformer network as the
backbone, to solve a series of VRPs. The inter-context self-attention mechanism
is proposed within LL to transfer the knowledge obtained from solving preceding
VRPs into the succeeding ones. On top of that, we develop a dynamic context
scheduler (DCS), employing the cross-context experience replay to further
facilitate LL looking back on the attained policies of solving preceding VRPs.
Extensive results on synthetic and benchmark instances (problem sizes up to
18k) show that our LL is capable of discovering effective policies for tackling
generic VRPs in varying contexts, which outperforms other neural solvers and
achieves the best performance for most VRPs.

</details>


### [209] [Comparative Analysis of Time Series Foundation Models for Demographic Forecasting: Enhancing Predictive Accuracy in US Population Dynamics](https://arxiv.org/abs/2508.11680)
*Aditya Akella,Jonathan Farah*

Main category: cs.LG

TL;DR: 研究探讨了时间序列基础模型（TimesFM）在美国人口预测中的应用，相比传统方法表现更优。


<details>
  <summary>Details</summary>
Motivation: 人口变化对政策制定至关重要，但传统预测方法在少数群体数据稀疏时表现不佳。

Method: 使用美国人口普查局和FRED数据集，比较TimesFM与LSTM、ARIMA和线性回归的性能。

Result: TimesFM在86.67%的测试案例中MSE最低，尤其在少数群体数据稀疏时表现突出。

Conclusion: 预训练基础模型可提升人口分析能力，无需大量任务特定微调即可支持政策干预。

Abstract: Demographic shifts, influenced by globalization, economic conditions,
geopolitical events, and environmental factors, pose significant challenges for
policymakers and researchers. Accurate demographic forecasting is essential for
informed decision-making in areas such as urban planning, healthcare, and
economic policy. This study explores the application of time series foundation
models to predict demographic changes in the United States using datasets from
the U.S. Census Bureau and Federal Reserve Economic Data (FRED). We evaluate
the performance of the Time Series Foundation Model (TimesFM) against
traditional baselines including Long Short-Term Memory (LSTM) networks,
Autoregressive Integrated Moving Average (ARIMA), and Linear Regression. Our
experiments across six demographically diverse states demonstrate that TimesFM
achieves the lowest Mean Squared Error (MSE) in 86.67% of test cases, with
particularly strong performance on minority populations with sparse historical
data. These findings highlight the potential of pre-trained foundation models
to enhance demographic analysis and inform proactive policy interventions
without requiring extensive task-specific fine-tuning.

</details>


### [210] [From Heuristics to Data: Quantifying Site Planning Layout Indicators with Deep Learning and Multi-Modal Data](https://arxiv.org/abs/2508.11723)
*Qian Cao,Jielin Chen,Junchao Zhao,Rudi Stouffs*

Main category: cs.LG

TL;DR: 提出了一种数据驱动的城市空间规划指标系统（SPLI），整合多源数据提升布局量化能力。


<details>
  <summary>Details</summary>
Motivation: 传统规划依赖经验和单一数据，难以系统量化多功能布局。

Method: SPLI整合OSM、POI、建筑形态等数据，通过五个维度扩展传统指标，并利用深度学习填补数据空白。

Result: 实验表明SPLI提高了功能分类准确性，为自动化空间分析提供了标准化基础。

Conclusion: SPLI为数据驱动的城市空间分析提供了系统化框架。

Abstract: The spatial layout of urban sites shapes land-use efficiency and spatial
organization. Traditional site planning often relies on experiential judgment
and single-source data, limiting systematic quantification of multifunctional
layouts. We propose a Site Planning Layout Indicator (SPLI) system, a
data-driven framework integrating empirical knowledge with heterogeneous
multi-source data to produce structured urban spatial information. The SPLI
supports multimodal spatial data systems for analytics, inference, and
retrieval by combining OpenStreetMap (OSM), Points of Interest (POI), building
morphology, land use, and satellite imagery. It extends conventional metrics
through five dimensions: (1) Hierarchical Building Function Classification,
refining empirical systems into clear hierarchies; (2) Spatial Organization,
quantifying seven layout patterns (e.g., symmetrical, concentric,
axial-oriented); (3) Functional Diversity, transforming qualitative assessments
into measurable indicators using Functional Ratio (FR) and Simpson Index (SI);
(4) Accessibility to Essential Services, integrating facility distribution and
transport networks for comprehensive accessibility metrics; and (5) Land Use
Intensity, using Floor Area Ratio (FAR) and Building Coverage Ratio (BCR) to
assess utilization efficiency. Data gaps are addressed through deep learning,
including Relational Graph Neural Networks (RGNN) and Graph Neural Networks
(GNN). Experiments show the SPLI improves functional classification accuracy
and provides a standardized basis for automated, data-driven urban spatial
analytics.

</details>


### [211] [Causal Structure Learning in Hawkes Processes with Complex Latent Confounder Networks](https://arxiv.org/abs/2508.11727)
*Songyao Jin,Biwei Huang*

Main category: cs.LG

TL;DR: 论文提出了一种基于离散时间模型的方法，用于识别多元霍克斯过程中的潜在子过程及其因果影响。


<details>
  <summary>Details</summary>
Motivation: 现实系统中常存在部分观测的潜在子过程，现有方法难以处理这一问题。

Method: 提出两阶段迭代算法，交替推断因果关系和发现潜在子过程。

Result: 实验表明，该方法能有效恢复因果结构。

Conclusion: 该方法为处理潜在子过程提供了可行方案。

Abstract: Multivariate Hawkes process provides a powerful framework for modeling
temporal dependencies and event-driven interactions in complex systems. While
existing methods primarily focus on uncovering causal structures among observed
subprocesses, real-world systems are often only partially observed, with latent
subprocesses posing significant challenges. In this paper, we show that
continuous-time event sequences can be represented by a discrete-time model as
the time interval shrinks, and we leverage this insight to establish necessary
and sufficient conditions for identifying latent subprocesses and the causal
influences. Accordingly, we propose a two-phase iterative algorithm that
alternates between inferring causal relationships among discovered subprocesses
and uncovering new latent subprocesses, guided by path-based conditions that
guarantee identifiability. Experiments on both synthetic and real-world
datasets show that our method effectively recovers causal structures despite
the presence of latent subprocesses.

</details>


### [212] [BRIEF: BRain-Inspired network connection search with Extensive temporal feature Fusion enhances disease classification](https://arxiv.org/abs/2508.11732)
*Xiangxiang Cui,Min Zhao,Dongmei Zhi,Shile Qi,Vince D Calhoun,Jing Sui*

Main category: cs.LG

TL;DR: 提出了一种基于脑启发的特征融合框架（BRIEF），通过改进的神经网络连接搜索和Transformer多特征融合，显著提升了fMRI分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在fMRI分类中存在网络架构依赖经验和特征融合简单的问题，受大脑学习机制启发，提出BRIEF框架。

Method: 提取4种fMRI特征，通过改进的Q-learning动态优化网络连接搜索，并用Transformer融合特征，嵌入注意力模块提升可解释性。

Result: 在精神分裂症和自闭症分类任务中，BRIEF比21种现有算法提升2.2%-12.1%，AUC分别达91.5%和78.4%。

Conclusion: BRIEF首次结合脑启发和强化学习优化fMRI分类，展示了识别精确神经影像生物标志物的潜力。

Abstract: Existing deep learning models for functional MRI-based classification have
limitations in network architecture determination (relying on experience) and
feature space fusion (mostly simple concatenation, lacking mutual learning).
Inspired by the human brain's mechanism of updating neural connections through
learning and decision-making, we proposed a novel BRain-Inspired feature Fusion
(BRIEF) framework, which is able to optimize network architecture automatically
by incorporating an improved neural network connection search (NCS) strategy
and a Transformer-based multi-feature fusion module. Specifically, we first
extracted 4 types of fMRI temporal representations, i.e., time series (TCs),
static/dynamic functional connection (FNC/dFNC), and multi-scale dispersion
entropy (MsDE), to construct four encoders. Within each encoder, we employed a
modified Q-learning to dynamically optimize the NCS to extract high-level
feature vectors, where the NCS is formulated as a Markov Decision Process.
Then, all feature vectors were fused via a Transformer, leveraging both
stable/time-varying connections and multi-scale dependencies across different
brain regions to achieve the final classification. Additionally, an attention
module was embedded to improve interpretability. The classification performance
of our proposed BRIEF was compared with 21 state-of-the-art models by
discriminating two mental disorders from healthy controls: schizophrenia (SZ,
n=1100) and autism spectrum disorder (ASD, n=1550). BRIEF demonstrated
significant improvements of 2.2% to 12.1% compared to 21 algorithms, reaching
an AUC of 91.5% - 0.6% for SZ and 78.4% - 0.5% for ASD, respectively. This is
the first attempt to incorporate a brain-inspired, reinforcement learning
strategy to optimize fMRI-based mental disorder classification, showing
significant potential for identifying precise neuroimaging biomarkers.

</details>


### [213] [Scalable Geospatial Data Generation Using AlphaEarth Foundations Model](https://arxiv.org/abs/2508.11739)
*Luc Houriez,Sebastian Pilarski,Behzad Vahedi,Ali Ahmadalipour,Teo Honda Scully,Nicholas Aflitto,David Andre,Caroline Jaffe,Martha Wedner,Rich Mazzola,Josh Jeffery,Ben Messinger,Sage McGinley-Smith,Sarah Russell*

Main category: cs.LG

TL;DR: 利用AlphaEarth Foundations（AEF）扩展地理空间标记数据集的方法，通过基本模型（如随机森林或逻辑回归）实现，并在LANDFIRE的植被类型数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 高质量的地理空间标记数据集通常局限于特定地理区域，无法覆盖全球。本文旨在利用AEF扩展这些数据集的地理覆盖范围。

Method: 提出一种方法，利用AEF作为输入，通过随机森林或逻辑回归等基本模型扩展地理空间标记数据集。

Result: 在LANDFIRE的植被类型数据集上，模型在美国和加拿大的验证集上分别达到81%和73%的分类准确率。

Conclusion: 尽管存在局限性，但该方法能够有效扩展地理空间标记数据集的地理覆盖范围，且基本模型表现良好。

Abstract: High-quality labeled geospatial datasets are essential for extracting
insights and understanding our planet. Unfortunately, these datasets often do
not span the entire globe and are limited to certain geographic regions where
data was collected. Google DeepMind's recently released AlphaEarth Foundations
(AEF) provides an information-dense global geospatial representation designed
to serve as a useful input across a wide gamut of tasks. In this article we
propose and evaluate a methodology which leverages AEF to extend geospatial
labeled datasets beyond their initial geographic regions. We show that even
basic models like random forests or logistic regression can be used to
accomplish this task. We investigate a case study of extending LANDFIRE's
Existing Vegetation Type (EVT) dataset beyond the USA into Canada at two levels
of granularity: EvtPhys (13 classes) and EvtGp (80 classes). Qualitatively, for
EvtPhys, model predictions align with ground truth. Trained models achieve 81%
and 73% classification accuracy on EvtPhys validation sets in the USA and
Canada, despite discussed limitations.

</details>


### [214] [Fed-Meta-Align: A Similarity-Aware Aggregation and Personalization Pipeline for Federated TinyML on Heterogeneous Data](https://arxiv.org/abs/2508.11794)
*Hemanth Macharla,Mayukha Pal*

Main category: cs.LG

TL;DR: Fed-Meta-Align是一个四阶段框架，通过序列化初始化和自适应聚合，在资源受限的IoT设备上实现高精度实时故障分类。


<details>
  <summary>Details</summary>
Motivation: 解决标准联邦学习在非独立同分布数据下模型发散的问题，提升IoT设备在异构环境中的故障分类性能。

Method: 包括基础模型训练、序列化元初始化、并行联邦学习和设备个性化四个阶段，结合双准则聚合机制。

Result: 在异构IoT设备上平均测试准确率达91.27%，优于个性化FedAvg和FedProx。

Conclusion: Fed-Meta-Align为多样化TinyML网络部署高性能智能提供了可靠路径。

Abstract: Real-time fault classification in resource-constrained Internet of Things
(IoT) devices is critical for industrial safety, yet training robust models in
such heterogeneous environments remains a significant challenge. Standard
Federated Learning (FL) often fails in the presence of non-IID data, leading to
model divergence. This paper introduces Fed-Meta-Align, a novel four-phase
framework designed to overcome these limitations through a sophisticated
initialization and training pipeline. Our process begins by training a
foundational model on a general public dataset to establish a competent
starting point. This model then undergoes a serial meta-initialization phase,
where it sequentially trains on a subset of IOT Device data to learn a
heterogeneity-aware initialization that is already situated in a favorable
region of the loss landscape. This informed model is subsequently refined in a
parallel FL phase, which utilizes a dual-criterion aggregation mechanism that
weights for IOT devices updates based on both local performance and cosine
similarity alignment. Finally, an on-device personalization phase adapts the
converged global model into a specialized expert for each IOT Device.
Comprehensive experiments demonstrate that Fed-Meta-Align achieves an average
test accuracy of 91.27% across heterogeneous IOT devices, outperforming
personalized FedAvg and FedProx by up to 3.87% and 3.37% on electrical and
mechanical fault datasets, respectively. This multi-stage approach of sequenced
initialization and adaptive aggregation provides a robust pathway for deploying
high-performance intelligence on diverse TinyML networks.

</details>


### [215] [Uncalibrated Reasoning: GRPO Induces Overconfidence for Stochastic Outcomes](https://arxiv.org/abs/2508.11800)
*Michael Bereket,Jure Leskovec*

Main category: cs.LG

TL;DR: 研究探讨了强化学习在随机结果领域优化语言模型的效果，发现GRPO会导致过度自信的概率预测，而PPO和RLOO表现良好。


<details>
  <summary>Details</summary>
Motivation: 验证强化学习方法在随机结果领域（如科学实验）中的有效性，以扩展其在非确定性领域的应用。

Method: 通过合成数据和真实生物实验，比较GRPO、PPO和RLOO在语言模型校准上的表现。

Result: GRPO导致过度自信预测，去除其标准化可解决问题；PPO和RLOO表现良好。

Conclusion: 反对在GRPO中使用标准化，为强化学习在非确定性领域的应用提供新方向。

Abstract: Reinforcement learning (RL) has proven remarkably effective at improving the
accuracy of language models in verifiable and deterministic domains like
mathematics. Here, we examine if current RL methods are also effective at
optimizing language models in verifiable domains with stochastic outcomes, like
scientific experiments. Through applications to synthetic data and real-world
biological experiments, we demonstrate that Group Relative Policy Optimization
(GRPO) induces overconfident probability predictions for binary stochastic
outcomes, while Proximal Policy Optimization (PPO) and REINFORCE Leave-One-Out
(RLOO) yield well-calibrated models. We show that removing group standard
normalization in GRPO fixes its miscalibration and provide a theoretical
explanation for why normalization causes overconfidence. Our results provide
new evidence against the use of standard normalization in GRPO and help pave
the way for applications of RL for reasoning language models beyond
deterministic domains.

</details>


### [216] [FairTabGen: Unifying Counterfactual and Causal Fairness in Synthetic Tabular Data Generation](https://arxiv.org/abs/2508.11810)
*Nitish Nagesh,Salar Shakibhamedan,Mahdi Bagheri,Ziyu Wang,Nima TaheriNejad,Axel Jantsch,Amir M. Rahmani*

Main category: cs.LG

TL;DR: FairTabGen是一个基于大语言模型的公平性感知框架，用于生成表格合成数据，在公平性和实用性上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在隐私敏感和数据稀缺的环境中生成合成数据，尤其是表格数据，同时提升反事实和因果公平性。

Method: 结合反事实和因果公平性定义，利用上下文学习、提示优化和公平性感知数据管理。

Result: 在多个数据集上优于现有方法，公平性指标提升10%，且仅需20%原始数据。

Conclusion: FairTabGen提供了一种生成公平且实用合成表格数据的有效方法。

Abstract: Generating synthetic data is crucial in privacy-sensitive, data-scarce
settings, especially for tabular datasets widely used in real-world
applications. A key challenge is improving counterfactual and causal fairness,
while preserving high utility. We present FairTabGen, a fairness-aware large
language model-based framework for tabular synthetic data generation. We
integrate multiple fairness definitions including counterfactual and causal
fairness into both its generation and evaluation pipelines. We use in-context
learning, prompt refinement, and fairness-aware data curation to balance
fairness and utility. Across diverse datasets, our method outperforms
state-of-the-art GAN-based and LLM-based methods, achieving up to 10%
improvements on fairness metrics such as demographic parity and path-specific
causal effects while retaining statistical utility. Remarkably, it achieves
these gains using less than 20% of the original data, highlighting its
efficiency in low-data regimes. These results demonstrate a principled and
practical approach for generating fair and useful synthetic tabular data.

</details>


### [217] [Combinations of Fast Activation and Trigonometric Functions in Kolmogorov-Arnold Networks](https://arxiv.org/abs/2508.11876)
*Hoang-Thang Ta,Duy-Quy Thai,Phuong-Linh Tran-Thi*

Main category: cs.LG

TL;DR: 提出在KANs中使用ReLU和三角函数等快速计算函数，以提高计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统KANs中使用的多项式函数（如B样条和RBF）在GPU上支持不足且不够流行。

Method: 将ReLU和三角函数（如sin、cos、arctan）作为基础组件集成到KANs中。

Result: 实验表明，这些组合在保持性能的同时，可能提升训练时间和泛化能力。

Conclusion: 快速计算函数组合为KANs提供了高效且性能优越的替代方案。

Abstract: For years, many neural networks have been developed based on the
Kolmogorov-Arnold Representation Theorem (KART), which was created to address
Hilbert's 13th problem. Recently, relying on KART, Kolmogorov-Arnold Networks
(KANs) have attracted attention from the research community, stimulating the
use of polynomial functions such as B-splines and RBFs. However, these
functions are not fully supported by GPU devices and are still considered less
popular. In this paper, we propose the use of fast computational functions,
such as ReLU and trigonometric functions (e.g., ReLU, sin, cos, arctan), as
basis components in Kolmogorov-Arnold Networks (KANs). By integrating these
function combinations into the network structure, we aim to enhance
computational efficiency. Experimental results show that these combinations
maintain competitive performance while offering potential improvements in
training time and generalization.

</details>


### [218] [PCA- and SVM-Grad-CAM for Convolutional Neural Networks: Closed-form Jacobian Expression](https://arxiv.org/abs/2508.11880)
*Yuto Omae*

Main category: cs.LG

TL;DR: 提出了PCA-Grad-CAM和SVM-Grad-CAM方法，用于可视化CNN中PCA和SVM层的注意力区域，解决了传统Grad-CAM无法直接应用于这些层的问题。


<details>
  <summary>Details</summary>
Motivation: 在训练样本有限时，将PCA和SVM集成到CNN中可以提升分类性能，但传统Grad-CAM无法直接应用于这些层，因此需要开发新的可视化方法。

Method: 通过解析计算从最后一个卷积层到PCA和SVM层的闭式雅可比矩阵，提出了PCA-Grad-CAM和SVM-Grad-CAM方法。

Result: 在多个主要数据集上展示了可视化结果，验证了方法的有效性。

Conclusion: 提出的方法为开发基于PCA和SVM的白盒CNN方法提供了支持，解决了传统Grad-CAM的局限性。

Abstract: Convolutional Neural Networks (CNNs) are an effective approach for
classification tasks, particularly when the training dataset is large. Although
CNNs have long been considered a black-box classification method, they can be
used as a white-box method through visualization techniques such as Grad-CAM.
When training samples are limited, incorporating a Principal Component Analysis
(PCA) layer and/or a Support Vector Machine (SVM) classifier into a CNN can
effectively improve classification performance. However, traditional Grad-CAM
cannot be directly applied to PCA and/or SVM layers. It is important to
generate attention regions for PCA and/or SVM layers in CNNs to facilitate the
development of white-box methods. Therefore, we propose ``PCA-Grad-CAM'', a
method for visualizing attention regions in PCA feature vectors, and
``SVM-Grad-CAM'', a method for visualizing attention regions in an SVM
classifier layer. To complete our methods analytically, it is necessary to
solve the closed-form Jacobian consisting of partial derivatives from the last
convolutional layer to the PCA and/or SVM layers. In this paper, we present the
exact closed-form Jacobian and the visualization results of our methods applied
to several major datasets.

</details>


### [219] [ENA: Efficient N-dimensional Attention](https://arxiv.org/abs/2508.11921)
*Yibo Zhong*

Main category: cs.LG

TL;DR: 论文提出了一种结合线性循环和高阶滑动窗口注意力（SWA）的高效N维注意力（ENA）架构，用于高效建模高维数据的长序列。


<details>
  <summary>Details</summary>
Motivation: Transformer在处理高维数据的长序列时效率不足，需要更高效的架构。

Method: 研究了扫描策略和注意力混合架构，发现注意力混合模型效果更好，进一步评估了不同类型的注意力，最终提出结合线性循环和高阶SWA的ENA架构。

Result: 实验证明ENA在理论和实践中均高效，能够有效建模超长高维数据。

Conclusion: 线性循环压缩全局信息，SWA补充局部建模，两者结合为高维数据建模提供了实用解决方案。

Abstract: Efficient modeling of long sequences of high-order data requires a more
efficient architecture than Transformer. In this paper, we investigate two key
aspects of extending linear recurrent models, especially those originally
designed for language modeling, to high-order data (1D to ND): scanning
strategies and attention-hybrid architectures. Empirical results suggest that
scanning provides limited benefits, while attention-hybrid models yield
promising results. Focusing on the latter, we further evaluate types of
attention and find that tiled high-order sliding window attention (SWA) is
efficient in both theory and practice. We term the resulting hybrid
architecture of linear recurrence and high-order SWA as Efficient N-dimensional
Attention (ENA). We then conduct several experiments to demonstrate its
effectiveness. The intuition behind ENA is that linear recurrence compresses
global information into a state, while SWA complements it by enforcing strict
local modeling. Together, they form a simple framework that offers a promising
and practical solution for ultra-long high-order data modeling.

</details>


### [220] [Scale-Disentangled spatiotemporal Modeling for Long-term Traffic Emission Forecasting](https://arxiv.org/abs/2508.11923)
*Yan Wu,Lihong Pei,Yukai Han,Yang Cao,Yu Kang,Yanlong Zhao*

Main category: cs.LG

TL;DR: 提出了一种尺度解耦的时空建模框架（SDSTM），用于长期交通排放预测，通过多尺度特征分解与融合提升预测精度。


<details>
  <summary>Details</summary>
Motivation: 传统时空图模型在长期推理中易受级联误差放大的影响，无法有效处理交通排放的多尺度时空纠缠问题。

Method: 采用基于Koopman提升算子的双流特征分解策略，结合门控小波分解和多流独立性约束的动态融合机制。

Result: 在西安二环路的道路级交通排放数据集上，SDSTM模型取得了最先进的性能。

Conclusion: SDSTM框架通过解耦多尺度特征并保持其独立互补性，显著提升了长期交通排放预测的准确性。

Abstract: Long-term traffic emission forecasting is crucial for the comprehensive
management of urban air pollution. Traditional forecasting methods typically
construct spatiotemporal graph models by mining spatiotemporal dependencies to
predict emissions. However, due to the multi-scale entanglement of traffic
emissions across time and space, these spatiotemporal graph modeling method
tend to suffer from cascading error amplification during long-term inference.
To address this issue, we propose a Scale-Disentangled Spatio-Temporal Modeling
(SDSTM) framework for long-term traffic emission forecasting. It leverages the
predictability differences across multiple scales to decompose and fuse
features at different scales, while constraining them to remain independent yet
complementary. Specifically, the model first introduces a dual-stream feature
decomposition strategy based on the Koopman lifting operator. It lifts the
scale-coupled spatiotemporal dynamical system into an infinite-dimensional
linear space via Koopman operator, and delineates the predictability boundary
using gated wavelet decomposition. Then a novel fusion mechanism is
constructed, incorporating a dual-stream independence constraint based on
cross-term loss to dynamically refine the dual-stream prediction results,
suppress mutual interference, and enhance the accuracy of long-term traffic
emission prediction. Extensive experiments conducted on a road-level traffic
emission dataset within Xi'an's Second Ring Road demonstrate that the proposed
model achieves state-of-the-art performance.

</details>


### [221] [An Improved Algorithm for Adversarial Linear Contextual Bandits via Reduction](https://arxiv.org/abs/2508.11931)
*Tim van Erven,Jack Mayo,Julia Olkhovskaya,Chen-Yu Wei*

Main category: cs.LG

TL;DR: 提出一种高效算法，用于解决具有对抗性损失和随机动作集的线性上下文赌博机问题，实现了多项式时间内的低遗憾。


<details>
  <summary>Details</summary>
Motivation: 解决Liu等人（2023）提出的开放性问题，即在多项式时间内实现与动作数量无关的多项式维度平方根遗憾。

Method: 将问题转化为具有固定动作集的对抗性线性赌博机问题，无需上下文分布知识或模拟器。

Result: 算法实现了$\tilde{O}(\min\{d^2\sqrt{T}, \sqrt{d^3T\log K}\})$遗憾，并在多项式时间内运行。

Conclusion: 该算法在多项式时间内首次实现了多项式维度的平方根遗憾，解决了重要组合赌博机类别的开放性问题。

Abstract: We present an efficient algorithm for linear contextual bandits with
adversarial losses and stochastic action sets. Our approach reduces this
setting to misspecification-robust adversarial linear bandits with fixed action
sets. Without knowledge of the context distribution or access to a context
simulator, the algorithm achieves $\tilde{O}(\min\{d^2\sqrt{T}, \sqrt{d^3T\log
K}\})$ regret and runs in $\text{poly}(d,C,T)$ time, where $d$ is the feature
dimension, $C$ is an upper bound on the number of linear constraints defining
the action set in each round, $K$ is an upper bound on the number of actions in
each round, and $T$ is number of rounds. This resolves the open question by Liu
et al. (2023) on whether one can obtain $\text{poly}(d)\sqrt{T}$ regret in
polynomial time independent of the number of actions. For the important class
of combinatorial bandits with adversarial losses and stochastic action sets
where the action sets can be described by a polynomial number of linear
constraints, our algorithm is the first to achieve $\text{poly}(d)\sqrt{T}$
regret in polynomial time, while no prior algorithm achieves even $o(T)$ regret
in polynomial time to our knowledge. When a simulator is available, the regret
bound can be improved to $\tilde{O}(d\sqrt{L^\star})$, where $L^\star$ is the
cumulative loss of the best policy.

</details>


### [222] [M3OOD: Automatic Selection of Multimodal OOD Detectors](https://arxiv.org/abs/2508.11936)
*Yuehan Qin,Li Li,Defu Cao,Tiankai Yang,Yue Zhao*

Main category: cs.LG

TL;DR: M3OOD是一个基于元学习的框架，用于在多元模态设置中自动选择最佳OOD检测器。


<details>
  <summary>Details</summary>
Motivation: 解决OOD检测任务中因数据分布变化导致单一检测器无法适应所有场景的问题。

Method: 结合多元模态嵌入和手工设计的元特征，利用历史性能数据推荐适合新数据分布的检测器。

Result: 在12个测试场景中，M3OOD优于10个基线方法，且计算开销低。

Conclusion: M3OOD通过元学习有效解决了OOD检测器选择问题，适用于多元模态场景。

Abstract: Out-of-distribution (OOD) robustness is a critical challenge for modern
machine learning systems, particularly as they increasingly operate in
multimodal settings involving inputs like video, audio, and sensor data.
Currently, many OOD detection methods have been proposed, each with different
designs targeting various distribution shifts. A single OOD detector may not
prevail across all the scenarios; therefore, how can we automatically select an
ideal OOD detection model for different distribution shifts? Due to the
inherent unsupervised nature of the OOD detection task, it is difficult to
predict model performance and find a universally Best model. Also,
systematically comparing models on the new unseen data is costly or even
impractical. To address this challenge, we introduce M3OOD, a
meta-learning-based framework for OOD detector selection in multimodal
settings. Meta learning offers a solution by learning from historical model
behaviors, enabling rapid adaptation to new data distribution shifts with
minimal supervision. Our approach combines multimodal embeddings with
handcrafted meta-features that capture distributional and cross-modal
characteristics to represent datasets. By leveraging historical performance
across diverse multimodal benchmarks, M3OOD can recommend suitable detectors
for a new data distribution shift. Experimental evaluation demonstrates that
M3OOD consistently outperforms 10 competitive baselines across 12 test
scenarios with minimal computational overhead.

</details>


### [223] [Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware](https://arxiv.org/abs/2508.11940)
*Yuannuo Feng,Wenyong Zhou,Yuexi Lyu,Yixiang Zhang,Zhengwu Liu,Ngai Wong,Wang Kang*

Main category: cs.LG

TL;DR: 提出了一种基于STE框架的噪声感知训练方法，用于模拟CIM系统中的硬件噪声建模，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 模拟CIM架构的硬件噪声复杂且难以建模，现有方法依赖理想化噪声模型，无法捕捉实际硬件变化。

Method: 通过STE框架解耦前向噪声模拟和后向梯度计算，支持更准确但计算复杂的噪声建模。

Result: 实验显示，该方法在图像分类和文本生成任务中分别提升5.3%准确率和降低0.72困惑度，同时训练速度提升2.2倍，内存使用降低37.9%。

Conclusion: 该方法有效解决了模拟CIM系统中的噪声建模问题，显著提升了训练效率和模型性能。

Abstract: Analog Compute-In-Memory (CIM) architectures promise significant energy
efficiency gains for neural network inference, but suffer from complex
hardware-induced noise that poses major challenges for deployment. While
noise-aware training methods have been proposed to address this issue, they
typically rely on idealized and differentiable noise models that fail to
capture the full complexity of analog CIM hardware variations. Motivated by the
Straight-Through Estimator (STE) framework in quantization, we decouple forward
noise simulation from backward gradient computation, enabling noise-aware
training with more accurate but computationally intractable noise modeling in
analog CIM systems. We provide theoretical analysis demonstrating that our
approach preserves essential gradient directional information while maintaining
computational tractability and optimization stability. Extensive experiments
show that our extended STE framework achieves up to 5.3% accuracy improvement
on image classification, 0.72 perplexity reduction on text generation,
2.2$\times$ speedup in training time, and 37.9% lower peak memory usage
compared to standard noise-aware training methods.

</details>


### [224] [Learning Marked Temporal Point Process Explanations based on Counterfactual and Factual Reasoning](https://arxiv.org/abs/2508.11943)
*Sishun Liu,Ke Deng,Xiuzhen Zhang,Yan Wang*

Main category: cs.LG

TL;DR: 论文提出了一种结合反事实和事实解释的方法（CFF），用于标记时间点过程（MTPP）模型，以提高解释的合理性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有MTPP模型的解释方法（反事实或事实解释）可能导致不合理结果，需结合两者以提升解释质量。

Method: 提出CFF方法，结合反事实和事实解释，通过精心设计的技术解决MTPP的解释问题。

Result: 实验表明CFF在解释质量和处理效率上优于基线方法。

Conclusion: CFF方法为MTPP模型提供了更合理和高效的解释方案。

Abstract: Neural network-based Marked Temporal Point Process (MTPP) models have been
widely adopted to model event sequences in high-stakes applications, raising
concerns about the trustworthiness of outputs from these models. This study
focuses on Explanation for MTPP, aiming to identify the minimal and rational
explanation, that is, the minimum subset of events in history, based on which
the prediction accuracy of MTPP matches that based on full history to a great
extent and better than that based on the complement of the subset. This study
finds that directly defining Explanation for MTPP as counterfactual explanation
or factual explanation can result in irrational explanations. To address this
issue, we define Explanation for MTPP as a combination of counterfactual
explanation and factual explanation. This study proposes Counterfactual and
Factual Explainer for MTPP (CFF) to solve Explanation for MTPP with a series of
deliberately designed techniques. Experiments demonstrate the correctness and
superiority of CFF over baselines regarding explanation quality and processing
efficiency.

</details>


### [225] [Set-Valued Transformer Network for High-Emission Mobile Source Identification](https://arxiv.org/abs/2508.11976)
*Yunning Cao,Lihong Pei,Jian Guo,Yang Cao,Yu Kang,Yanlong Zhao*

Main category: cs.LG

TL;DR: 提出了一种基于Set-Valued Transformer Network（SVTN）的方法，用于识别高排放车辆，解决了数据长尾分布和非线性特征的挑战。


<details>
  <summary>Details</summary>
Motivation: 高排放车辆识别对城市污染控制至关重要，但数据的长尾分布和非线性特征增加了建模难度。

Method: 使用Transformer测量微行程条件变化的时间相似性，构建高维到低维的映射规则，并结合集值识别算法进行概率建模。

Result: 在合肥市2020年柴油车监测数据上，SVTN比基线方法降低了9.5%的漏检率。

Conclusion: SVTN能有效提升高排放车辆的识别精度，适用于移动污染源的精准监测。

Abstract: Identifying high-emission vehicles is a crucial step in regulating urban
pollution levels and formulating traffic emission reduction strategies.
However, in practical monitoring data, the proportion of high-emission state
data is significantly lower compared to normal emission states. This
characteristic long-tailed distribution severely impedes the extraction of
discriminative features for emission state identification during data mining.
Furthermore, the highly nonlinear nature of vehicle emission states and the
lack of relevant prior knowledge also pose significant challenges to the
construction of identification models.To address the aforementioned issues, we
propose a Set-Valued Transformer Network (SVTN) to achieve comprehensive
learning of discriminative features from high-emission samples, thereby
enhancing detection accuracy. Specifically, this model first employs the
transformer to measure the temporal similarity of micro-trip condition
variations, thus constructing a mapping rule that projects the original
high-dimensional emission data into a low-dimensional feature space. Next, a
set-valued identification algorithm is used to probabilistically model the
relationship between the generated feature vectors and their labels, providing
an accurate metric criterion for the classification algorithm. To validate the
effectiveness of our proposed approach, we conducted extensive experiments on
the diesel vehicle monitoring data of Hefei city in 2020. The results
demonstrate that our method achieves a 9.5\% reduction in the missed detection
rate for high-emission vehicles compared to the transformer-based baseline,
highlighting its superior capability in accurately identifying high-emission
mobile pollution sources.

</details>


### [226] [Efficient Modular Learning through Naive LoRA Summation: Leveraging Orthogonality in High-Dimensional Models](https://arxiv.org/abs/2508.11985)
*Zhanhao Cao,Clement Truong,Andrew Lizarraga*

Main category: cs.LG

TL;DR: LoRA模块在独立训练后可通过简单加法组合，性能接近合并数据训练模型，同时揭示高阶组合中的干扰现象。


<details>
  <summary>Details</summary>
Motivation: 利用叠加原理，假设独立训练的LoRA模块在不相交领域上近似正交，可通过加法组合。

Method: 使用GPT-2 Small（117M）和LoRA（rank 4，alpha=64）训练三个QA领域（数学、医学、金融）的适配器，测试组合效果。

Result: 数学+医学组合相对合并数据微调困惑度降低9.10%，数学+金融和金融+医学分别变化+4.54%和+27.56%。LoRA增量间的余弦相似度与困惑度变化呈正相关。

Conclusion: LoRA模块的简单加法组合无需额外训练，性能接近合并数据训练模型，但需注意高阶组合中的干扰问题。

Abstract: Recent advances in large language models are driven by scale, while
parameter-efficient fine-tuning (PEFT) enables updating only a small fraction
of parameters. Low-Rank Adaptation (LoRA) stores parameter deltas as the
product of two small matrices, which makes them natural building blocks that
can be composed. Motivated by the superposition principle, we hypothesize that
independently trained LoRA modules on disjoint domains are approximately
orthogonal and can be combined by simple addition. Using GPT-2 Small (117M)
with LoRA rank 4 and alpha=64, we train adapters for three QA domains (math,
medicine, finance). In pairwise tests, adding Math+Medicine adapters improves
perplexity by -9.10% relative to merged-data fine-tuning, while Math+Finance
and Finance+Medicine change by +4.54% and +27.56%, respectively. Across
combinations, the RMS cosine similarity between LoRA deltas correlates
positively and approximately linearly with the change in perplexity. Naive
summation requires no additional training, can be applied in seconds, and
achieves performance comparable to models trained on merged data, while
clarifying when interference appears in higher-order compositions.

</details>


### [227] [Universal Learning of Nonlinear Dynamics](https://arxiv.org/abs/2508.11990)
*Evan Dogariu,Anand Brahmbhatt,Elad Hazan*

Main category: cs.LG

TL;DR: 提出了一种基于谱滤波的算法，用于学习具有有限边际稳定模式的非线性动态系统，证明了预测误差趋近于零。


<details>
  <summary>Details</summary>
Motivation: 研究如何学习未知的非线性动态系统，尤其是边际稳定的系统。

Method: 采用谱滤波技术，结合在线凸优化方法，从过去的观测中学习映射关系。

Result: 证明了对于具有有限边际稳定模式的非线性动态系统，预测误差趋近于零。

Conclusion: 该方法显著扩展了原始谱滤波算法的适用范围，包括非对称动态和噪声校正，具有独立的研究价值。

Abstract: We study the fundamental problem of learning a marginally stable unknown
nonlinear dynamical system. We describe an algorithm for this problem, based on
the technique of spectral filtering, which learns a mapping from past
observations to the next based on a spectral representation of the system.
Using techniques from online convex optimization, we prove vanishing prediction
error for any nonlinear dynamical system that has finitely many marginally
stable modes, with rates governed by a novel quantitative control-theoretic
notion of learnability. The main technical component of our method is a new
spectral filtering algorithm for linear dynamical systems, which incorporates
past observations and applies to general noisy and marginally stable systems.
This significantly generalizes the original spectral filtering algorithm to
both asymmetric dynamics as well as incorporating noise correction, and is of
independent interest.

</details>


### [228] [FedUHD: Unsupervised Federated Learning using Hyperdimensional Computing](https://arxiv.org/abs/2508.12021)
*You Hak Lee,Xiaofan Yu,Quanling Zhao,Flavio Ponzina,Tajana Rosing*

Main category: cs.LG

TL;DR: FedUHD是一个基于超维计算（HDC）的无监督联邦学习框架，解决了非独立同分布数据、高计算通信成本和通信噪声等问题，显著提升了性能和效率。


<details>
  <summary>Details</summary>
Motivation: 无监督联邦学习（UFL）在实际应用中面临非独立同分布数据、高计算通信成本和通信噪声等挑战，现有基于深度神经网络的方法开销大。

Method: 提出FedUHD框架，利用HDC的轻量级特性，客户端采用kNN聚类去除异常值，服务器端采用加权HDC聚合平衡数据分布。

Result: FedUHD在训练速度、能效、通信成本和准确性上显著优于现有方法，且对噪声具有更强鲁棒性。

Conclusion: FedUHD通过HDC和优化设计，为UFL提供了一种高效、鲁棒的解决方案。

Abstract: Unsupervised federated learning (UFL) has gained attention as a
privacy-preserving, decentralized machine learning approach that eliminates the
need for labor-intensive data labeling. However, UFL faces several challenges
in practical applications: (1) non-independent and identically distributed
(non-iid) data distribution across devices, (2) expensive computational and
communication costs at the edge, and (3) vulnerability to communication noise.
Previous UFL approaches have relied on deep neural networks (NN), which
introduce substantial overhead in both computation and communication. In this
paper, we propose FedUHD, the first UFL framework based on Hyperdimensional
Computing (HDC). HDC is a brain-inspired computing scheme with lightweight
training and inference operations, much smaller model size, and robustness to
communication noise. FedUHD introduces two novel HDC-based designs to improve
UFL performance. On the client side, a kNN-based cluster hypervector removal
method addresses non-iid data samples by eliminating detrimental outliers. On
the server side, a weighted HDC aggregation technique balances the non-iid data
distribution across clients. Our experiments demonstrate that FedUHD achieves
up to 173.6x and 612.7x better speedup and energy efficiency, respectively, in
training, up to 271x lower communication cost, and 15.50% higher accuracy on
average across diverse settings, along with superior robustness to various
types of noise compared to state-of-the-art NN-based UFL approaches.

</details>


### [229] [Fairness Regularization in Federated Learning](https://arxiv.org/abs/2508.12042)
*Zahra Kharaghani,Ali Dadras,Tommy Löfstedt*

Main category: cs.LG

TL;DR: 联邦学习（FL）通过协作训练解决隐私问题，但数据异构性导致性能差异。本文研究性能公平性方法，提出FairGrad及其变体，在异构数据中提升公平性和模型性能。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中数据异构性导致客户端性能差异，现有公平性方法在异构数据中的效果和关系尚不明确。

Method: 研究明确正则化客户端损失的公平性方法，提出FairGrad和FairGrad*，通过梯度方差正则化实现性能公平。

Result: FairGrad及其变体在异构数据中提升公平性和整体模型性能，并理论解释了方法间的联系。

Conclusion: FairGrad方法在联邦学习中有效解决异构数据带来的公平性问题，同时提升模型性能。

Abstract: Federated Learning (FL) has emerged as a vital paradigm in modern machine
learning that enables collaborative training across decentralized data sources
without exchanging raw data. This approach not only addresses privacy concerns
but also allows access to overall substantially larger and potentially more
diverse datasets, without the need for centralized storage or hardware
resources. However, heterogeneity in client data may cause certain clients to
have disproportionate impacts on the global model, leading to disparities in
the clients' performances. Fairness, therefore, becomes a crucial concern in FL
and can be addressed in various ways. However, the effectiveness of existing
fairness-aware methods, particularly in heterogeneous data settings, remains
unclear, and the relationships between different approaches are not well
understood. In this work, we focus on performance equitable fairness, which
aims to minimize differences in performance across clients. We restrict our
study to fairness-aware methods that explicitly regularize client losses,
evaluating both existing and newly proposed approaches. We identify and
theoretically explain connections between the investigated fairness methods,
and empirically show that FairGrad (approximate) and FairGrad* (exact) (two
variants of a gradient variance regularization method introduced here for
performance equitable fairness) improve both fairness and overall model
performance in heterogeneous data settings.

</details>


### [230] [VARAN: Variational Inference for Self-Supervised Speech Models Fine-Tuning on Downstream Tasks](https://arxiv.org/abs/2508.12061)
*Daria Diatlova,Nikita Balagansky,Alexander Varlamov,Egor Spirin*

Main category: cs.LG

TL;DR: VARAN框架通过动态调整层聚合方式，解决了传统方法的信息瓶颈和静态特征权重问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法在聚合自监督语音模型的层时存在信息瓶颈和静态特征权重问题，无法适应不同输入的需求。

Method: VARAN采用层专用探测头和数据依赖的权重分配，动态调整层特征的优先级。

Result: 在自动语音识别和语音情感识别任务中，VARAN表现出色，尤其是在使用LoRA微调技术时。

Conclusion: VARAN解决了保留层特定信息与灵活特征利用之间的权衡，提升了自监督语音表示的高效适应性。

Abstract: Conventional methods for aggregating layers in fine-tuned self-supervised
speech models, such as using the final layer or weighted sum, suffer from
information bottlenecks and static feature weighting for all dataset examples.
We propose VARAN, a framework that dynamically tailors layer aggregation to
individual inputs. By employing layer-specialized probing heads and
data-dependent weighting, VARAN adaptively prioritizes layer's features based
on input. Evaluations on automatic speech recognition and speech emotion
recognition tasks demonstrate VARAN's superior performance, particularly when
using the LoRA fine-tuning technique. The framework resolves the trade-off
between preserving layer-specific information and enabling flexible feature
utilization, advancing efficient adaptation of self-supervised speech
representations.

</details>


### [231] [Content Accuracy and Quality Aware Resource Allocation Based on LP-Guided DRL for ISAC-Driven AIGC Networks](https://arxiv.org/abs/2508.12079)
*Ningzhe Shi,Yiqing Zhou,Ling Liu,Jinglin Shi,Yihao Wu,Haiwei Shi,Hanxiao Yu*

Main category: cs.LG

TL;DR: 论文提出了一种基于ISAC的AIGC网络资源优化方法，通过CAQA指标评估服务质量，并设计了低复杂度的LPDRL-F算法进行资源分配。


<details>
  <summary>Details</summary>
Motivation: 现有AIGC服务假设输入数据准确，但ISAC网络中传感数据不准确，且AIGC模型本身存在生成误差，需综合考虑资源分配。

Method: 提出CAQA指标，设计LPDRL-F算法，通过LP和动作过滤器降低DRL复杂度，优化三维资源分配。

Result: LPDRL-F收敛速度提升60%以上，AvgCAQA提高14%，相比仅关注CGQ的方案提升50%以上。

Conclusion: LPDRL-F有效解决了ISAC-AIGC网络的资源分配问题，显著提升了服务质量。

Abstract: Integrated sensing and communication (ISAC) can enhance artificial
intelligence-generated content (AIGC) networks by providing efficient sensing
and transmission. Existing AIGC services usually assume that the accuracy of
the generated content can be ensured, given accurate input data and prompt,
thus only the content generation quality (CGQ) is concerned. However, it is not
applicable in ISAC-based AIGC networks, where content generation is based on
inaccurate sensed data. Moreover, the AIGC model itself introduces generation
errors, which depend on the number of generating steps (i.e., computing
resources). To assess the quality of experience of ISAC-based AIGC services, we
propose a content accuracy and quality aware service assessment metric (CAQA).
Since allocating more resources to sensing and generating improves content
accuracy but may reduce communication quality, and vice versa, this
sensing-generating (computing)-communication three-dimensional resource
tradeoff must be optimized to maximize the average CAQA (AvgCAQA) across all
users with AIGC (CAQA-AIGC). This problem is NP-hard, with a large solution
space that grows exponentially with users. To solve the CAQA-AIGC problem with
low complexity, a linear programming (LP) guided deep reinforcement learning
(DRL) algorithm with an action filter (LPDRL-F) is proposed. Through the
LP-guided approach and the action filter, LPDRL-F can transform the original
three-dimensional solution space to two dimensions, reducing complexity while
improving the learning performance of DRL. Simulations show that compared to
existing DRL and generative diffusion model algorithms without LP, LPDRL-F
converges faster by over 60% and finds better resource allocation solutions,
improving AvgCAQA by more than 14%. With LPDRL-F, CAQA-AIGC can achieve an
improvement in AvgCAQA of more than 50% compared to existing schemes focusing
solely on CGQ.

</details>


### [232] [Generative Medical Event Models Improve with Scale](https://arxiv.org/abs/2508.12104)
*Shane Waxler,Paul Blazek,Davis White,Daniel Sneider,Kevin Chung,Mani Nagarathnam,Patrick Williams,Hank Voeller,Karen Wong,Matthew Swanhorst,Sheng Zhang,Naoto Usuyama,Cliff Wong,Tristan Naumann,Hoifung Poon,Andrew Loza,Daniella Meeker,Seth Hain,Rahul Shah*

Main category: cs.LG

TL;DR: CoMET是一种基于医疗事件数据的生成式基础模型，通过预训练和模拟推理在多种临床任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 实现个性化医疗需要从患者纵向医疗事件中提取洞察，基础模型为此提供了规模化解决方案。

Method: 使用Epic Cosmos数据集预训练解码器Transformer模型（CoMET），并进行扩展律研究。

Result: CoMET在78项任务中表现优于或匹配任务专用模型，且预测能力随模型规模提升。

Conclusion: CoMET能有效捕捉临床动态，支持临床决策和改善患者结局。

Abstract: Realizing personalized medicine at scale calls for methods that distill
insights from longitudinal patient journeys, which can be viewed as a sequence
of medical events. Foundation models pretrained on large-scale medical event
data represent a promising direction for scaling real-world evidence generation
and generalizing to diverse downstream tasks. Using Epic Cosmos, a dataset with
medical events from de-identified longitudinal health records for 16.3 billion
encounters over 300 million unique patient records from 310 health systems, we
introduce the Cosmos Medical Event Transformer ( CoMET) models, a family of
decoder-only transformer models pretrained on 118 million patients representing
115 billion discrete medical events (151 billion tokens). We present the
largest scaling-law study for medical event data, establishing a methodology
for pretraining and revealing power-law scaling relationships for compute,
tokens, and model size. Based on this, we pretrained a series of
compute-optimal models with up to 1 billion parameters. Conditioned on a
patient's real-world history, CoMET autoregressively generates the next medical
event, simulating patient health timelines. We studied 78 real-world tasks,
including diagnosis prediction, disease prognosis, and healthcare operations.
Remarkably for a foundation model with generic pretraining and simulation-based
inference, CoMET generally outperformed or matched task-specific supervised
models on these tasks, without requiring task-specific fine-tuning or few-shot
examples. CoMET's predictive power consistently improves as the model and
pretraining scale. Our results show that CoMET, a generative medical event
foundation model, can effectively capture complex clinical dynamics, providing
an extensible and generalizable framework to support clinical decision-making,
streamline healthcare operations, and improve patient outcomes.

</details>


### [233] [DynamixSFT: Dynamic Mixture Optimization of Instruction Tuning Collections](https://arxiv.org/abs/2508.12116)
*Haebin Shin,Lei Ji,Xiao Liu,Zhiwei Yu,Qi Chen,Yeyun Gong*

Main category: cs.LG

TL;DR: DynamixSFT是一种动态自动化方法，用于优化指令调优数据集的混合，通过多臂老虎机框架和Prior-scaled Boltzmann Exploration实现，性能提升2.2%。


<details>
  <summary>Details</summary>
Motivation: 随着指令调优数据集的增多，动态平衡和优化其混合成为关键挑战。

Method: 采用多臂老虎机框架和Prior-scaled Boltzmann Exploration，通过1-Step Look-ahead Reward更新采样概率。

Result: 在Tulu-v2-mixture集合上，性能提升达2.2%。

Conclusion: DynamixSFT有效优化数据集混合，提升模型性能，并提供动态分析。

Abstract: As numerous instruction-tuning datasets continue to emerge during the
post-training stage, dynamically balancing and optimizing their mixtures has
become a critical challenge. To address this, we propose DynamixSFT, a dynamic
and automated method for instruction-tuning dataset mixture optimization. We
formulate the problem as a multi-armed bandit setup and introduce a
Prior-scaled Boltzmann Exploration that softly anchors the updated sampling
distribution to the original dataset proportions, thereby preserving the
inherent diversity and coverage of the collection. Sampling probabilities are
updated using a lightweight 1-Step Look-ahead Reward, reflecting how much the
dataset contributes to improving the model's performance at its current state.
When applied to the Tulu-v2-mixture collection comprising 16 instruction-tuning
datasets, DynamixSFT achieves up to a 2.2% performance improvement across 10
benchmarks. Furthermore, we provide a comprehensive analysis and visualizations
to offer deeper insights into the adaptive dynamics of our method.

</details>


### [234] [Time-Scale Coupling Between States and Parameters in Recurrent Neural Networks](https://arxiv.org/abs/2508.12121)
*Lorenzo Livi*

Main category: cs.LG

TL;DR: 研究门控机制如何在RNN中隐式地调整学习率，即使使用固定学习率训练。


<details>
  <summary>Details</summary>
Motivation: 探讨门控机制如何通过耦合状态空间时间尺度与参数空间动态，影响梯度传播和参数更新。

Method: 通过推导漏积分器和门控RNN的精确雅可比矩阵，分析门控如何重塑梯度传播和调整有效步长。

Result: 门控不仅控制隐藏状态中的记忆保留，还作为数据驱动的预处理器，优化参数空间中的轨迹。

Conclusion: 门控机制自然地耦合状态演化与参数更新，解释了门控架构在实践中实现稳健训练和稳定性的原因。

Abstract: We study how gating mechanisms in recurrent neural networks (RNNs) implicitly
induce adaptive learning-rate behavior, even when training is carried out with
a fixed, global learning rate. This effect arises from the coupling between
state-space time scales--parametrized by the gates--and parameter-space
dynamics during gradient descent. By deriving exact Jacobians for
leaky-integrator and gated RNNs, we obtain a first-order expansion that makes
explicit how constant, scalar, and multi-dimensional gates reshape gradient
propagation, modulate effective step sizes, and introduce anisotropy in
parameter updates. These findings reveal that gates not only control memory
retention in the hidden states, but also act as data-driven preconditioners
that adapt optimization trajectories in parameter space. We further draw formal
analogies with learning-rate schedules, momentum, and adaptive methods such as
Adam, showing that these optimization behaviors emerge naturally from gating.
Numerical experiments confirm the validity of our perturbative analysis,
supporting the view that gate-induced corrections remain small while exerting
systematic effects on training dynamics. Overall, this work provides a unified
dynamical-systems perspective on how gating couples state evolution with
parameter updates, explaining why gated architectures achieve robust
trainability and stability in practice.

</details>


### [235] [DE-VAE: Revealing Uncertainty in Parametric and Inverse Projections with Variational Autoencoders using Differential Entropy](https://arxiv.org/abs/2508.12145)
*Frederik L. Dennig,Daniel A. Keim*

Main category: cs.LG

TL;DR: DE-VAE是一种基于变分自编码器（VAE）的方法，通过微分熵（DE）改进参数化和可逆投影，特别适用于处理分布外样本。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理分布外样本时表现不佳，因此需要一种能够分析嵌入不确定性的方法。

Method: DE-VAE通过训练学习从原始空间到2D空间的映射及其逆映射，结合微分熵提升投影性能。

Result: 在四个数据集上的实验表明，DE-VAE在参数化和可逆投影方面与其他AE方法相当，同时能分析嵌入不确定性。

Conclusion: DE-VAE在保持投影准确性的同时，提供了对嵌入不确定性的分析能力。

Abstract: Recently, autoencoders (AEs) have gained interest for creating parametric and
invertible projections of multidimensional data. Parametric projections make it
possible to embed new, unseen samples without recalculating the entire
projection, while invertible projections allow the synthesis of new data
instances. However, existing methods perform poorly when dealing with
out-of-distribution samples in either the data or embedding space. Thus, we
propose DE-VAE, an uncertainty-aware variational AE using differential entropy
(DE) to improve the learned parametric and invertible projections. Given a
fixed projection, we train DE-VAE to learn a mapping into 2D space and an
inverse mapping back to the original space. We conduct quantitative and
qualitative evaluations on four well-known datasets, using UMAP and t-SNE as
baseline projection methods. Our findings show that DE-VAE can create
parametric and inverse projections with comparable accuracy to other current
AE-based approaches while enabling the analysis of embedding uncertainty.

</details>


### [236] [AICRN: Attention-Integrated Convolutional Residual Network for Interpretable Electrocardiogram Analysis](https://arxiv.org/abs/2508.12162)
*J. M. I. H. Jayakody,A. M. H. H. Alahakoon,C. R. M. Perera,R. M. L. C. Srimal,Roshan Ragel,Vajira Thambawita,Isuru Nawinne*

Main category: cs.LG

TL;DR: 提出了一种名为AICRN的新型深度学习架构，用于ECG参数回归，提高了诊断精度和预测能力。


<details>
  <summary>Details</summary>
Motivation: 传统ECG分析存在人为误差和效率低下的问题，需要更精确和自动化的解决方案。

Method: 采用空间和通道注意力机制的卷积残差网络（AICRN），解决梯度消失和爆炸问题。

Result: AICRN在ECG参数回归中表现优于现有模型，精度更高。

Conclusion: 深度学习可显著提升ECG分析的准确性和可解释性，为心脏监测开辟新应用。

Abstract: The paradigm of electrocardiogram (ECG) analysis has evolved into real-time
digital analysis, facilitated by artificial intelligence (AI) and machine
learning (ML), which has improved the diagnostic precision and predictive
capacity of cardiac diseases. This work proposes a novel deep learning (DL)
architecture called the attention-integrated convolutional residual network
(AICRN) to regress key ECG parameters such as the PR interval, the QT interval,
the QRS duration, the heart rate, the peak amplitude of the R wave, and the
amplitude of the T wave for interpretable ECG analysis. Our architecture is
specially designed with spatial and channel attention-related mechanisms to
address the type and spatial location of the ECG features for regression. The
models employ a convolutional residual network to address vanishing and
exploding gradient problems. The designed system addresses traditional analysis
challenges, such as loss of focus due to human errors, and facilitates the fast
and easy detection of cardiac events, thereby reducing the manual efforts
required to solve analysis tasks. AICRN models outperform existing models in
parameter regression with higher precision. This work demonstrates that DL can
play a crucial role in the interpretability and precision of ECG analysis,
opening up new clinical applications for cardiac monitoring and management.

</details>


### [237] [ProtTeX-CC: Activating In-Context Learning in Protein LLM via Two-Stage Instruction Compression](https://arxiv.org/abs/2508.12212)
*Chuanliu Fan,Zicheng Ma,Jun Gao,Nan Yu,Jun Zhang,Ziqiang Cao,Yi Qin Gao,Guohong Fu*

Main category: cs.LG

TL;DR: ProtTeX-CC是一个轻量级的两阶段压缩框架，旨在解决ProtTeX在少样本设置下的局限性，通过联合嵌入压缩和自压缩模块显著减少输入长度，提升性能。


<details>
  <summary>Details</summary>
Motivation: ProtTeX在处理多模态蛋白质信息时存在输入长度加倍和无法进行上下文学习的限制，影响了其泛化能力。

Method: 提出两阶段压缩框架：1）联合嵌入压缩机制融合序列和结构表示；2）自压缩模块将演示样本压缩为少量潜在标记。

Result: 在16-shot设置下，压缩比达93.68%，域内性能提升2%，域外性能提升11%。

Conclusion: ProtTeX-CC在不修改主干模型的情况下，显著提升了ProtTeX的性能和泛化能力。

Abstract: Recent advances in protein large language models, such as ProtTeX, represent
both side-chain amino acids and backbone structure as discrete token sequences
of residue length. While this design enables unified modeling of multimodal
protein information, it suffers from two major limitations: (1) The
concatenation of sequence and structure tokens approximately doubles the
protein length and breaks the intrinsic residue-level alignment between
modalities. (2) Constrained by the training corpus and limited context window,
ProtTeX is typically trained on single-protein inputs, rendering it
incompatible with in-context learning (ICL) and thus limiting its
generalization capability. To address these issues, we propose ProtTeX-CC, a
lightweight two-stage compression framework designed to enhance ProtTeX under
few-shot settings. We first design a joint embedding compression mechanism that
fuses sequence and structure representations at the residue level, effectively
reducing the protein input length by half without sacrificing performance. Then
we propose a self-compression module that aggregates each full demonstration
into the latent space of the last few linguistic tokens, reducing the average
demonstration length from 751 tokens to less than 16 tokens. Compared to the
original ProtTeX, our self-compression approach achieves a compression ratio of
approximately 93.68% in the total prompt length under the 16-shot setting.
Without modifying the backbone model, ProtTeX-CC introduces only a small number
of additional parameters through PEFT-based tuning in the joint embedding
compression stage and a single trainable projection layer in the
self-compression stage. Extensive experiments on protein function prediction
show that ProtTeX-CC improves performance on the in-domain benchmark by 2%, and
generalizes well to the out-of-domain dataset with a performance gain of 11%.

</details>


### [238] [Unlearning at Scale: Implementing the Right to be Forgotten in Large Language Models](https://arxiv.org/abs/2508.12220)
*Abdullah X*

Main category: cs.LG

TL;DR: 该论文研究了大型语言模型中的‘被遗忘权’（GDPR第17条），将遗忘学习视为可复现的系统问题，提出了确定性训练记录和多种互补路径来实现高效遗忘。


<details>
  <summary>Details</summary>
Motivation: 研究动机是实现GDPR规定的‘被遗忘权’，确保模型能够高效、准确地删除特定数据，同时保持模型性能。

Method: 方法包括记录训练过程的确定性日志（如ID哈希、RNG种子等），并通过重放训练尾部、微检查点、适配器删除和抗更新等技术实现遗忘。

Result: 在满足前提条件下，模型和优化器状态实现了字节级完全一致，验证了方法的有效性。

Conclusion: 结论是该方法能够高效实现数据遗忘，满足法律和性能要求。

Abstract: We study the right to be forgotten (GDPR Art. 17) for large language models
and frame unlearning as a reproducible systems problem. Our approach treats
training as a deterministic program and logs a minimal per-microbatch record
(ordered ID hash, RNG seed, learning-rate value, optimizer-step counter, and
accumulation boundary). Under a pinned stack and deterministic kernels,
replaying the training tail while filtering only the forget closure yields the
same parameters as training on the retain set (bit-identical in the training
dtype) when preconditions hold. To meet latency and availability constraints,
we add complementary paths: (i) exact reverts of recent steps via
micro-checkpoints or dense per-step deltas, (ii) cohort-scoped adapter deletion
when the base is frozen, and (iii) a curvature-guided anti-update followed by a
short retain-tune, audit-gated with escalation to exact replay. We report
storage/latency budgets and a toy artifact validating mechanics; in a
controlled run that satisfies the preconditions we demonstrate byte-identical
equality of model and optimizer states.

</details>


### [239] [Distribution Matching via Generalized Consistency Models](https://arxiv.org/abs/2508.12222)
*Sagar Shrestha,Rajesh Shrestha,Tri Nguyen,Subash Timilsina*

Main category: cs.LG

TL;DR: 提出一种基于连续归一化流（CNF）的新型分布匹配方法，结合了CNF的简单目标函数和GAN的灵活性，解决了GAN训练中的挑战。


<details>
  <summary>Details</summary>
Motivation: 生成对抗网络（GAN）在分布匹配任务中表现优异，但存在训练困难和模式崩溃问题，需要更稳定高效的方法。

Method: 受CNF一致性模型启发，提出新方法，结合CNF的简单目标函数和GAN的灵活性，适应多种约束。

Result: 理论验证了新目标函数的有效性，并在合成和真实数据集上展示了性能。

Conclusion: 新方法结合了CNF和GAN的优势，为分布匹配任务提供了更稳定高效的解决方案。

Abstract: Recent advancement in generative models have demonstrated remarkable
performance across various data modalities. Beyond their typical use in data
synthesis, these models play a crucial role in distribution matching tasks such
as latent variable modeling, domain translation, and domain adaptation.
Generative Adversarial Networks (GANs) have emerged as the preferred method of
distribution matching due to their efficacy in handling high-dimensional data
and their flexibility in accommodating various constraints. However, GANs often
encounter challenge in training due to their bi-level min-max optimization
objective and susceptibility to mode collapse. In this work, we propose a novel
approach for distribution matching inspired by the consistency models employed
in Continuous Normalizing Flow (CNF). Our model inherits the advantages of CNF
models, such as having a straight forward norm minimization objective, while
remaining adaptable to different constraints similar to GANs. We provide
theoretical validation of our proposed objective and demonstrate its
performance through experiments on synthetic and real-world datasets.

</details>


### [240] [Communication-Efficient Distributed Asynchronous ADMM](https://arxiv.org/abs/2508.12233)
*Sagar Shrestha*

Main category: cs.LG

TL;DR: 提出了一种在异步ADMM中引入粗量化的方法，以减少大规模联邦学习和分布式优化中的通信开销。


<details>
  <summary>Details</summary>
Motivation: 在分布式优化和联邦学习中，异步ADMM因其适用于大规模优化、数据隐私和异构目标函数而备受青睐，但通信成本可能成为瓶颈。

Method: 通过引入粗量化技术，减少节点间交换的数据量。

Result: 实验验证了该方法在包括神经网络在内的多个分布式学习任务中的收敛性。

Conclusion: 粗量化是一种有效降低通信开销的方法，适用于大规模联邦学习和分布式优化。

Abstract: In distributed optimization and federated learning, asynchronous alternating
direction method of multipliers (ADMM) serves as an attractive option for
large-scale optimization, data privacy, straggler nodes and variety of
objective functions. However, communication costs can become a major bottleneck
when the nodes have limited communication budgets or when the data to be
communicated is prohibitively large. In this work, we propose introducing
coarse quantization to the data to be exchanged in aynchronous ADMM so as to
reduce communication overhead for large-scale federated learning and
distributed optimization applications. We experimentally verify the convergence
of the proposed method for several distributed learning tasks, including neural
networks.

</details>


### [241] [CC-Time: Cross-Model and Cross-Modality Time Series Forecasting](https://arxiv.org/abs/2508.12235)
*Peng Chen,Yihang Wang,Yang Shu,Yunyao Cheng,Kai Zhao,Zhongwen Rao,Lujia Pan,Bin Yang,Chenjuan Guo*

Main category: cs.LG

TL;DR: CC-Time是一种结合预训练语言模型（PLM）和时间序列模型的跨模型与跨模态学习方法，用于提升时间序列预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前基于PLM的时间序列预测方法未能充分利用语言模型的强大序列建模能力，预测精度不足。

Method: CC-Time通过跨模态学习建模时间依赖性和通道相关性，并通过跨模型融合块整合PLM和时间序列模型的知识。

Result: 在九个真实数据集上的实验表明，CC-Time在全数据训练和少样本学习情况下均达到最先进的预测精度。

Conclusion: CC-Time通过跨模型和跨模态学习有效提升了时间序列预测的准确性。

Abstract: With the success of pre-trained language models (PLMs) in various application
fields beyond natural language processing, language models have raised emerging
attention in the field of time series forecasting (TSF) and have shown great
prospects. However, current PLM-based TSF methods still fail to achieve
satisfactory prediction accuracy matching the strong sequential modeling power
of language models. To address this issue, we propose Cross-Model and
Cross-Modality Learning with PLMs for time series forecasting (CC-Time). We
explore the potential of PLMs for time series forecasting from two aspects: 1)
what time series features could be modeled by PLMs, and 2) whether relying
solely on PLMs is sufficient for building time series models. In the first
aspect, CC-Time incorporates cross-modality learning to model temporal
dependency and channel correlations in the language model from both time series
sequences and their corresponding text descriptions. In the second aspect,
CC-Time further proposes the cross-model fusion block to adaptively integrate
knowledge from the PLMs and time series model to form a more comprehensive
modeling of time series patterns. Extensive experiments on nine real-world
datasets demonstrate that CC-Time achieves state-of-the-art prediction accuracy
in both full-data training and few-shot learning situations.

</details>


### [242] [DHG-Bench: A Comprehensive Benchmark on Deep Hypergraph Learning](https://arxiv.org/abs/2508.12244)
*Fan Li,Xiaoyang Wang,Wenjie Zhang,Ying Zhang,Xuemin Lin*

Main category: cs.LG

TL;DR: DHG-Bench是首个全面的深度超图学习基准，涵盖20个数据集和16种算法，系统评估了超图神经网络的性能。


<details>
  <summary>Details</summary>
Motivation: 现有超图神经网络缺乏统一的基准，导致数据集、算法和任务覆盖不足，评估不全面且实验设置不一致。

Method: 提出DHG-Bench，整合多样数据集和算法，采用一致的数据处理和实验协议，评估有效性、效率、鲁棒性和公平性。

Result: 实验揭示了现有算法的优势和局限性，为未来研究提供了方向。

Conclusion: DHG-Bench填补了深度超图学习领域的基准空白，促进了可重复研究和算法改进。

Abstract: Although conventional deep graph models have achieved great success in
relational learning, their focus on pairwise relationships limits their
capacity to learn pervasive higher-order interactions in real-world complex
systems, which can be naturally modeled as hypergraphs. To tackle this,
hypergraph neural networks (HNNs), the dominant approach in deep hypergraph
learning (DHGL), has garnered substantial attention in recent years. Despite
the proposal of numerous HNN methods, there is no comprehensive benchmark for
HNNs, which creates a great obstacle to understanding the progress of DHGL in
several aspects: (i) insufficient coverage of datasets, algorithms, and tasks;
(ii) a narrow evaluation of algorithm performance; and (iii) inconsistent
dataset usage, preprocessing, and experimental setups that hinder
comparability. To fill the gap, we introduce DHG-Bench, the first comprehensive
benchmark for DHGL. Specifically, DHG-Bench integrates 20 diverse datasets
spanning node-, edge-, and graph-level tasks, along with 16 state-of-the-art
HNN algorithms, under consistent data processing and experimental protocols.
Our benchmark systematically investigates the characteristics of HNNs in terms
of four dimensions: effectiveness, efficiency, robustness, and fairness.
Further, to facilitate reproducible research, we have developed an easy-to-use
library for training and evaluating different HNN methods. Extensive
experiments conducted with DHG-Bench reveal both the strengths and inherent
limitations of existing algorithms, offering valuable insights and directions
for future research. The code is publicly available at:
https://github.com/Coco-Hut/DHG-Bench.

</details>


### [243] [STM3: Mixture of Multiscale Mamba for Long-Term Spatio-Temporal Time-Series Prediction](https://arxiv.org/abs/2508.12247)
*Haolong Chen,Liang Zhang,Zhengyuan Xin,Guangxu Zhu*

Main category: cs.LG

TL;DR: STM2/STM3模型通过多尺度Mamba架构和自适应图因果卷积网络，高效学习长期时空依赖，在长期时空时间序列预测中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法难以高效学习复杂的长期时空依赖，尤其是多尺度信息和节点间高度相关的时空信息。

Method: STM2采用多尺度Mamba架构和自适应图因果卷积网络；STM3进一步引入混合专家架构，增强尺度区分能力。

Result: 在真实世界基准测试中，STM2/STM3表现优异，达到最先进的预测效果。

Conclusion: STM2/STM3通过多尺度建模和专家混合策略，显著提升了长期时空时间序列预测的性能。

Abstract: Recently, spatio-temporal time-series prediction has developed rapidly, yet
existing deep learning methods struggle with learning complex long-term
spatio-temporal dependencies efficiently. The long-term spatio-temporal
dependency learning brings two new challenges: 1) The long-term temporal
sequence includes multiscale information naturally which is hard to extract
efficiently; 2) The multiscale temporal information from different nodes is
highly correlated and hard to model. To address these challenges, we propose an
efficient \textit{\textbf{S}patio-\textbf{T}emporal \textbf{M}ultiscale
\textbf{M}amba} (STM2) that includes a multiscale Mamba architecture to capture
the multiscale information efficiently and simultaneously, and an adaptive
graph causal convolution network to learn the complex multiscale
spatio-temporal dependency. STM2 includes hierarchical information aggregation
for different-scale information that guarantees their distinguishability. To
capture diverse temporal dynamics across all spatial nodes more efficiently, we
further propose an enhanced version termed
\textit{\textbf{S}patio-\textbf{T}emporal \textbf{M}ixture of
\textbf{M}ultiscale \textbf{M}amba} (STM3) that employs a special
Mixture-of-Experts architecture, including a more stable routing strategy and a
causal contrastive learning strategy to enhance the scale distinguishability.
We prove that STM3 has much better routing smoothness and guarantees the
pattern disentanglement for each expert successfully. Extensive experiments on
real-world benchmarks demonstrate STM2/STM3's superior performance, achieving
state-of-the-art results in long-term spatio-temporal time-series prediction.

</details>


### [244] [Interpreting Time Series Forecasts with LIME and SHAP: A Case Study on the Air Passengers Dataset](https://arxiv.org/abs/2508.12253)
*Manish Shukla*

Main category: cs.LG

TL;DR: 提出了一种结合LIME和SHAP的时间序列预测解释框架，解决了传统方法在非线性或可解释性上的不足。


<details>
  <summary>Details</summary>
Motivation: 时间序列预测在多个领域至关重要，但传统ARIMA模型难以处理非线性，而机器学习模型（如XGBoost）缺乏可解释性。

Method: 将单变量时间序列转换为无泄漏的监督学习问题，结合梯度提升树和ARIMA基线，并应用LIME和SHAP进行后解释。

Result: 通过Air Passengers数据集验证，发现少量滞后特征（如12个月滞后）和季节性编码能解释大部分预测方差。

Conclusion: 提供了一种不违反时间顺序的解释方法，并给出了实践指南，为时间序列预测的可解释性提供了新思路。

Abstract: Time-series forecasting underpins critical decisions across aviation, energy,
retail and health. Classical autoregressive integrated moving average (ARIMA)
models offer interpretability via coefficients but struggle with
nonlinearities, whereas tree-based machine-learning models such as XGBoost
deliver high accuracy but are often opaque. This paper presents a unified
framework for interpreting time-series forecasts using local interpretable
model-agnostic explanations (LIME) and SHapley additive exPlanations (SHAP). We
convert a univariate series into a leakage-free supervised learning problem,
train a gradient-boosted tree alongside an ARIMA baseline and apply post-hoc
explainability. Using the Air Passengers dataset as a case study, we show that
a small set of lagged features -- particularly the twelve-month lag -- and
seasonal encodings explain most forecast variance. We contribute: (i) a
methodology for applying LIME and SHAP to time series without violating
chronology; (ii) theoretical exposition of the underlying algorithms; (iii)
empirical evaluation with extensive analysis; and (iv) guidelines for
practitioners.

</details>


### [245] [L-SR1: Learned Symmetric-Rank-One Preconditioning](https://arxiv.org/abs/2508.12270)
*Gal Lifshitz,Shahar Zuler,Ori Fouks,Dan Raviv*

Main category: cs.LG

TL;DR: 提出一种新型的学习二阶优化器，通过可训练预条件单元增强SR1算法，在单目人体网格恢复任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 结合深度学习的数据效率和经典优化的轻量性，探索学习二阶优化方法。

Method: 引入可训练预条件单元生成数据驱动向量，构建正半定秩一矩阵，并通过学习投影对齐割线约束。

Result: 在单目人体网格恢复任务中优于现有学习优化方法，具有强泛化能力。

Conclusion: 该方法轻量、无需标注数据或微调，适合集成到更广泛的优化框架中。

Abstract: End-to-end deep learning has achieved impressive results but remains limited
by its reliance on large labeled datasets, poor generalization to unseen
scenarios, and growing computational demands. In contrast, classical
optimization methods are data-efficient and lightweight but often suffer from
slow convergence. While learned optimizers offer a promising fusion of both
worlds, most focus on first-order methods, leaving learned second-order
approaches largely unexplored.
  We propose a novel learned second-order optimizer that introduces a trainable
preconditioning unit to enhance the classical Symmetric-Rank-One (SR1)
algorithm. This unit generates data-driven vectors used to construct positive
semi-definite rank-one matrices, aligned with the secant constraint via a
learned projection. Our method is evaluated through analytic experiments and on
the real-world task of Monocular Human Mesh Recovery (HMR), where it
outperforms existing learned optimization-based approaches. Featuring a
lightweight model and requiring no annotated data or fine-tuning, our approach
offers strong generalization and is well-suited for integration into broader
optimization-based frameworks.

</details>


### [246] [CRoC: Context Refactoring Contrast for Graph Anomaly Detection with Limited Supervision](https://arxiv.org/abs/2508.12278)
*Siyue Xie,Da Sun Handason Tam,Wing Cheong Lau*

Main category: cs.LG

TL;DR: CRoC框架通过上下文重构和对比学习，提升了图异常检测（GAD）中GNN的性能，尤其在标签有限的情况下表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决图异常检测中标签数据稀缺和异常模式隐蔽的问题。

Method: 通过重构节点上下文和对比学习，结合有限标签和大量无标签数据训练GNN。

Result: 在七个真实数据集上，CRoC比基线GNN提升14% AUC，优于现有方法。

Conclusion: CRoC有效提升了GAD任务中GNN的鲁棒性和性能。

Abstract: Graph Neural Networks (GNNs) are widely used as the engine for various
graph-related tasks, with their effectiveness in analyzing graph-structured
data. However, training robust GNNs often demands abundant labeled data, which
is a critical bottleneck in real-world applications. This limitation severely
impedes progress in Graph Anomaly Detection (GAD), where anomalies are
inherently rare, costly to label, and may actively camouflage their patterns to
evade detection. To address these problems, we propose Context Refactoring
Contrast (CRoC), a simple yet effective framework that trains GNNs for GAD by
jointly leveraging limited labeled and abundant unlabeled data. Different from
previous works, CRoC exploits the class imbalance inherent in GAD to refactor
the context of each node, which builds augmented graphs by recomposing the
attributes of nodes while preserving their interaction patterns. Furthermore,
CRoC encodes heterogeneous relations separately and integrates them into the
message-passing process, enhancing the model's capacity to capture complex
interaction semantics. These operations preserve node semantics while
encouraging robustness to adversarial camouflage, enabling GNNs to uncover
intricate anomalous cases. In the training stage, CRoC is further integrated
with the contrastive learning paradigm. This allows GNNs to effectively harness
unlabeled data during joint training, producing richer, more discriminative
node embeddings. CRoC is evaluated on seven real-world GAD datasets with
varying scales. Extensive experiments demonstrate that CRoC achieves up to 14%
AUC improvement over baseline GNNs and outperforms state-of-the-art GAD methods
under limited-label settings.

</details>


### [247] [Convergence Analysis of the Lion Optimizer in Centralized and Distributed Settings](https://arxiv.org/abs/2508.12327)
*Wei Jiang,Lijun Zhang*

Main category: cs.LG

TL;DR: 分析了Lion优化器的收敛性质，包括标准、方差缩减和分布式版本，以及通信高效的变体。


<details>
  <summary>Details</summary>
Motivation: 研究Lion优化器的收敛性能，并提出改进方法以提升收敛速度。

Method: 通过理论分析，提出标准Lion、方差缩减Lion、分布式Lion及其通信高效变体。

Result: 标准Lion收敛率为O(d^{1/2}T^{-1/4})，方差缩减版本为O(d^{1/2}T^{-1/3})；分布式版本进一步优化。

Conclusion: Lion优化器及其变体在不同场景下均表现出良好的收敛性能，通信高效变体尤其适合分布式环境。

Abstract: In this paper, we analyze the convergence properties of the Lion optimizer.
First, we establish that the Lion optimizer attains a convergence rate of
$\mathcal{O}(d^{1/2}T^{-1/4})$ under standard assumptions, where $d$ denotes
the problem dimension and $T$ is the iteration number. To further improve this
rate, we introduce the Lion optimizer with variance reduction, resulting in an
enhanced convergence rate of $\mathcal{O}(d^{1/2}T^{-1/3})$. We then analyze in
distributed settings, where the standard and variance reduced version of the
distributed Lion can obtain the convergence rates of
$\mathcal{O}(d^{1/2}(nT)^{-1/4})$ and $\mathcal{O}(d^{1/2}(nT)^{-1/3})$, with
$n$ denoting the number of nodes. Furthermore, we investigate a
communication-efficient variant of the distributed Lion that ensures sign
compression in both communication directions. By employing the unbiased sign
operations, the proposed Lion variant and its variance reduction counterpart,
achieve convergence rates of $\mathcal{O}\left( \max
\left\{\frac{d^{1/4}}{T^{1/4}}, \frac{d^{1/10}}{n^{1/5}T^{1/5}} \right\}
\right)$ and $\mathcal{O}\left( \frac{d^{1/4}}{T^{1/4}} \right)$, respectively.

</details>


### [248] [Navigating the Exploration-Exploitation Tradeoff in Inference-Time Scaling of Diffusion Models](https://arxiv.org/abs/2508.12361)
*Xun Su,Jianming Huang,Yang Yusen,Zhongxi Fang,Hiroyuki Kasai*

Main category: cs.LG

TL;DR: 论文提出两种策略（Funnel Schedule和Adaptive Temperature）以解决扩散模型中探索与利用的权衡问题，显著提升样本质量。


<details>
  <summary>Details</summary>
Motivation: 现有Sequential Monte Carlo (SMC)方法在扩散模型中面临早期噪声样本难以评估、晚期样本不可逆的困境。

Method: 通过逐步减少粒子数量和调整早期奖励权重，优化扩散模型的生成动态和相变行为。

Result: 在多个基准测试和先进文本到图像扩散模型中，方法表现优于基线。

Conclusion: 提出的策略有效解决了扩散模型中的探索与利用问题，提升了生成质量。

Abstract: Inference-time scaling has achieved remarkable success in language models,
yet its adaptation to diffusion models remains underexplored. We observe that
the efficacy of recent Sequential Monte Carlo (SMC)-based methods largely stems
from globally fitting the The reward-tilted distribution, which inherently
preserves diversity during multi-modal search. However, current applications of
SMC to diffusion models face a fundamental dilemma: early-stage noise samples
offer high potential for improvement but are difficult to evaluate accurately,
whereas late-stage samples can be reliably assessed but are largely
irreversible. To address this exploration-exploitation trade-off, we approach
the problem from the perspective of the search algorithm and propose two
strategies: Funnel Schedule and Adaptive Temperature. These simple yet
effective methods are tailored to the unique generation dynamics and
phase-transition behavior of diffusion models. By progressively reducing the
number of maintained particles and down-weighting the influence of early-stage
rewards, our methods significantly enhance sample quality without increasing
the total number of Noise Function Evaluations. Experimental results on
multiple benchmarks and state-of-the-art text-to-image diffusion models
demonstrate that our approach outperforms previous baselines.

</details>


### [249] [Bi-Axial Transformers: Addressing the Increasing Complexity of EHR Classification](https://arxiv.org/abs/2508.12418)
*Rachael DeVries,Casper Christensen,Marie Lisandra Zepeda Mendoza,Ole Winther*

Main category: cs.LG

TL;DR: BAT（Bi-Axial Transformer）是一种针对电子健康记录（EHR）分类的新型Transformer模型，通过同时关注临床变量和时间点轴，解决了数据稀疏性问题，并在脓毒症预测和死亡率分类任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录（EHR）数据日益复杂，传统Transformer在EHR分类中因数据表示问题性能受限。BAT旨在通过改进数据关系建模和解决数据稀疏性问题，提升EHR分类性能。

Method: BAT通过同时关注临床变量和时间点轴，学习更丰富的数据关系，并利用独特的传感器嵌入进行迁移学习。所有基线模型均用PyTorch重新实现以确保可复现性。

Result: BAT在脓毒症预测任务中达到最先进性能，在死亡率分类任务中与顶级方法竞争。此外，BAT对数据缺失具有更强的鲁棒性。

Conclusion: BAT通过改进数据表示和建模方法，显著提升了EHR分类任务的性能，并为未来研究提供了可复现的基准模型。

Abstract: Electronic Health Records (EHRs), the digital representation of a patient's
medical history, are a valuable resource for epidemiological and clinical
research. They are also becoming increasingly complex, with recent trends
indicating larger datasets, longer time series, and multi-modal integrations.
Transformers, which have rapidly gained popularity due to their success in
natural language processing and other domains, are well-suited to address these
challenges due to their ability to model long-range dependencies and process
data in parallel. But their application to EHR classification remains limited
by data representations, which can reduce performance or fail to capture
informative missingness. In this paper, we present the Bi-Axial Transformer
(BAT), which attends to both the clinical variable and time point axes of EHR
data to learn richer data relationships and address the difficulties of data
sparsity. BAT achieves state-of-the-art performance on sepsis prediction and is
competitive to top methods for mortality classification. In comparison to other
transformers, BAT demonstrates increased robustness to data missingness, and
learns unique sensor embeddings which can be used in transfer learning.
Baseline models, which were previously located across multiple repositories or
utilized deprecated libraries, were re-implemented with PyTorch and made
available for reproduction and future benchmarking.

</details>


### [250] [Machine Learning-Based Manufacturing Cost Prediction from 2D Engineering Drawings via Geometric Features](https://arxiv.org/abs/2508.12440)
*Ahmet Bilal Arıkan,Şener Özönder,Mustafa Taha Koçyiğit,Hüseyin Oktay Altun,H. Kübra Küçükkartal,Murat Arslanoğlu,Fatih Çağırankaya,Berk Ayvaz*

Main category: cs.LG

TL;DR: 提出了一种集成机器学习框架，直接从2D工程图纸预测制造成本，替代传统人工流程。


<details>
  <summary>Details</summary>
Motivation: 传统成本估算依赖人工流程规划，效率低且不一致。

Method: 从13,684张汽车零部件图纸提取200个几何/统计特征，用XGBoost等梯度提升树模型训练。

Result: 模型在24类零件上实现10%平均绝对误差，并通过SHAP工具解释设计驱动因素。

Conclusion: 该框架缩短报价周期，为工业4.0提供实时成本决策支持。

Abstract: We present an integrated machine learning framework that transforms how
manufacturing cost is estimated from 2D engineering drawings. Unlike
traditional quotation workflows that require labor-intensive process planning,
our approach about 200 geometric and statistical descriptors directly from
13,684 DWG drawings of automotive suspension and steering parts spanning 24
product groups. Gradient-boosted decision tree models (XGBoost, CatBoost,
LightGBM) trained on these features achieve nearly 10% mean absolute percentage
error across groups, demonstrating robust scalability beyond part-specific
heuristics. By coupling cost prediction with explainability tools such as SHAP,
the framework identifies geometric design drivers including rotated dimension
maxima, arc statistics and divergence metrics, offering actionable insights for
cost-aware design. This end-to-end CAD-to-cost pipeline shortens quotation lead
times, ensures consistent and transparent cost assessments across part families
and provides a deployable pathway toward real-time, ERP-integrated decision
support in Industry 4.0 manufacturing environments.

</details>


### [251] [Local Cluster Cardinality Estimation for Adaptive Mean Shift](https://arxiv.org/abs/2508.12450)
*Étienne Pepin*

Main category: cs.LG

TL;DR: 提出了一种自适应均值漂移算法，适用于具有不同局部尺度和簇基数的数据集。


<details>
  <summary>Details</summary>
Motivation: 传统KDE方法仅能提供簇的局部区域信息，无法适应不同局部尺度和簇基数的数据集。

Method: 利用点到其他点的局部距离分布估计簇基数，并据此自适应调整带宽和均值漂移核半径阈值。

Result: 算法在原始数据集上优于最近提出的自适应均值漂移方法，并在更广泛的聚类基准上表现出竞争力。

Conclusion: 该算法通过自适应调整参数，有效提升了均值漂移算法在复杂数据集上的性能。

Abstract: This article presents an adaptive mean shift algorithm designed for datasets
with varying local scale and cluster cardinality. Local distance distributions,
from a point to all others, are used to estimate the cardinality of the local
cluster by identifying a local minimum in the density of the distance
distribution. Based on these cardinality estimates, local cluster parameters
are then computed for the entire cluster in contrast to KDE-based methods,
which provide insight only into localized regions of the cluster. During the
mean shift execution, the cluster cardinality estimate is used to adaptively
adjust the bandwidth and the mean shift kernel radius threshold. Our algorithm
outperformed a recently proposed adaptive mean shift method on its original
dataset and demonstrated competitive performance on a broader clustering
benchmark.

</details>


### [252] [Cold-RL: Learning Cache Eviction with Offline Reinforcement Learning for NGINX](https://arxiv.org/abs/2508.12485)
*Aayush Gupta,Arpit Bhayani*

Main category: cs.LG

TL;DR: Cold-RL是一种基于强化学习的NGINX缓存淘汰策略，通过离线训练和微秒级预算内的决策，显著提高了缓存命中率。


<details>
  <summary>Details</summary>
Motivation: 传统LRU策略在周期性突发和混合对象大小情况下表现不佳，Cold-RL旨在通过学习优化缓存淘汰决策。

Method: 使用Dueling Deep Q-Network和ONNX侧车，在500微秒内决策，提取六种轻量级特征进行训练。

Result: 在25MB缓存下，命中率提升146%；100MB下提升15%；400MB时与传统方法持平。

Conclusion: Cold-RL是首个在NGINX中实现严格SLO的强化学习淘汰策略，显著提升了性能。

Abstract: Web proxies such as NGINX commonly rely on least-recently-used (LRU)
eviction, which is size agnostic and can thrash under periodic bursts and mixed
object sizes. We introduce Cold-RL, a learned eviction policy for NGINX that
replaces LRU's forced-expire path with a dueling Deep Q-Network served by an
ONNX sidecar within a strict microsecond budget. On each eviction, Cold-RL
samples the K least-recently-used objects, extracts six lightweight features
(age, size, hit count, inter-arrival time, remaining TTL, and last origin RTT),
and requests a bitmask of victims; a hard timeout of 500 microseconds triggers
immediate fallback to native LRU. Policies are trained offline by replaying
NGINX access logs through a cache simulator with a simple reward: a retained
object earns one point if it is hit again before TTL expiry. We compare against
LRU, LFU, size-based, adaptive LRU, and a hybrid baseline on two adversarial
workloads. With a 25 MB cache, Cold-RL raises hit ratio from 0.1436 to 0.3538,
a 146 percent improvement over the best classical baseline; at 100 MB, from
0.7530 to 0.8675, a 15 percent gain; and at 400 MB it matches classical methods
(about 0.918). Inference adds less than 2 percent CPU overhead and keeps 95th
percentile eviction latency within budget. To our knowledge, this is the first
reinforcement learning eviction policy integrated into NGINX with strict SLOs.

</details>


### [253] [Cost-Aware Contrastive Routing for LLMs](https://arxiv.org/abs/2508.12491)
*Reza Shirkavand,Shangqian Gao,Peiran Yu,Heng Huang*

Main category: cs.LG

TL;DR: CSCR是一种轻量级框架，通过共享嵌入空间快速选择成本敏感的模型，显著提升准确性与成本的权衡。


<details>
  <summary>Details</summary>
Motivation: 现有方法常忽略提示特定上下文、依赖昂贵模型分析或使用低效试错策略，需要更高效的动态路由方案。

Method: CSCR使用紧凑的logit足迹和困惑度指纹映射模型与提示到共享空间，通过对比编码器选择最经济准确的专家。

Result: 在多个基准测试中，CSCR比基线方法提升25%的准确性与成本权衡，且能泛化到未见过的模型和提示。

Conclusion: CSCR提供了一种高效、动态且成本敏感的路由方案，适用于多样化模型池。

Abstract: We study cost-aware routing for large language models across diverse and
dynamic pools of models. Existing approaches often overlook prompt-specific
context, rely on expensive model profiling, assume a fixed set of experts, or
use inefficient trial-and-error strategies. We introduce Cost-Spectrum
Contrastive Routing (CSCR), a lightweight framework that maps both prompts and
models into a shared embedding space to enable fast, cost-sensitive selection.
CSCR uses compact, fast-to-compute logit footprints for open-source models and
perplexity fingerprints for black-box APIs. A contrastive encoder is trained to
favor the cheapest accurate expert within adaptive cost bands. At inference
time, routing reduces to a single k-NN lookup via a FAISS index, requiring no
retraining when the expert pool changes and enabling microsecond latency.
Across multiple benchmarks, CSCR consistently outperforms baselines, improving
the accuracy-cost tradeoff by up to 25%, while generalizing robustly to unseen
LLMs and out-of-distribution prompts.

</details>


### [254] [Trust Region Constrained Measure Transport in Path Space for Stochastic Optimal Control and Inference](https://arxiv.org/abs/2508.12511)
*Denis Blessing,Julius Berner,Lorenz Richter,Carles Domingo-Enrich,Yuanqi Du,Arash Vahdat,Gerhard Neumann*

Main category: cs.LG

TL;DR: 提出了一种基于信任区域的迭代方法，逐步逼近目标路径空间测度，显著提升了随机最优控制问题的性能。


<details>
  <summary>Details</summary>
Motivation: 解决目标测度与先验测度差异较大时，传统梯度优化方法难以有效求解的问题。

Method: 通过引入信任区域的约束问题，逐步逼近目标测度，形成几何退火路径。

Result: 在扩散采样、路径转移采样和扩散模型微调等任务中，性能显著提升。

Conclusion: 信任区域策略提供了一种系统化的几何退火方法，有效解决了目标测度与先验差异大的优化问题。

Abstract: Solving stochastic optimal control problems with quadratic control costs can
be viewed as approximating a target path space measure, e.g. via gradient-based
optimization. In practice, however, this optimization is challenging in
particular if the target measure differs substantially from the prior. In this
work, we therefore approach the problem by iteratively solving constrained
problems incorporating trust regions that aim for approaching the target
measure gradually in a systematic way. It turns out that this trust region
based strategy can be understood as a geometric annealing from the prior to the
target measure, where, however, the incorporated trust regions lead to a
principled and educated way of choosing the time steps in the annealing path.
We demonstrate in multiple optimal control applications that our novel method
can improve performance significantly, including tasks in diffusion-based
sampling, transition path sampling, and fine-tuning of diffusion models.

</details>


### [255] [Results of the NeurIPS 2023 Neural MMO Competition on Multi-task Reinforcement Learning](https://arxiv.org/abs/2508.12524)
*Joseph Suárez,Kyoung Whan Choe,David Bloomin,Jianming Gao,Yunkun Li,Yao Feng,Saidinesh Pola,Kun Zhang,Yonghui Zhu,Nikhil Pinnaparaju,Hao Xiang Li,Nishaanth Kanna,Daniel Scott,Ryan Sullivan,Rose S. Shuman,Lucas de Alcântara,Herbie Bradley,Kirsty You,Bo Wu,Yuhao Jiang,Qimai Li,Jiaxin Chen,Louis Castricato,Xiaolong Zhu,Phillip Isola*

Main category: cs.LG

TL;DR: NeurIPS 2023 Neural MMO竞赛吸引了200多名参与者，展示了在未见任务、地图和对手上的泛化能力，最佳解决方案在单GPU上8小时内训练完成，性能是基线的4倍。


<details>
  <summary>Details</summary>
Motivation: 探索目标条件策略在复杂多智能体环境中的泛化能力，并推动相关研究的发展。

Method: 参与者训练目标条件策略，并在未见过的任务、地图和对手上进行测试。

Result: 最佳解决方案在单GPU上8小时内训练完成，性能是基线的4倍。

Conclusion: 竞赛展示了目标条件策略的潜力，并开源了所有相关资源以促进进一步研究。

Abstract: We present the results of the NeurIPS 2023 Neural MMO Competition, which
attracted over 200 participants and submissions. Participants trained
goal-conditional policies that generalize to tasks, maps, and opponents never
seen during training. The top solution achieved a score 4x higher than our
baseline within 8 hours of training on a single 4090 GPU. We open-source
everything relating to Neural MMO and the competition under the MIT license,
including the policy weights and training code for our baseline and for the top
submissions.

</details>


### [256] [Toward Architecture-Agnostic Local Control of Posterior Collapse in VAEs](https://arxiv.org/abs/2508.12530)
*Hyunsoo Song,Seungwhan Kim,Seungkyu Lee*

Main category: cs.LG

TL;DR: 提出了一种新的损失函数（LR损失）来控制变分自编码器中的后验坍塌问题，无需特定架构限制。


<details>
  <summary>Details</summary>
Motivation: 变分自编码器（VAEs）存在后验坍塌问题，导致生成样本多样性降低。现有方法需要在架构上施加限制，限制了灵活性。

Method: 定义了局部后验坍塌，并提出基于数学性质的LR损失函数，无需特定架构约束。

Result: 在多个数据集（MNIST、fashionMNIST等）上验证了方法的有效性。

Conclusion: LR损失能有效控制后验坍塌，且不依赖特定网络架构，具有广泛适用性。

Abstract: Variational autoencoders (VAEs), one of the most widely used generative
models, are known to suffer from posterior collapse, a phenomenon that reduces
the diversity of generated samples. To avoid posterior collapse, many prior
works have tried to control the influence of regularization loss. However, the
trade-off between reconstruction and regularization is not satisfactory. For
this reason, several methods have been proposed to guarantee latent
identifiability, which is the key to avoiding posterior collapse. However, they
require structural constraints on the network architecture. For further
clarification, we define local posterior collapse to reflect the importance of
individual sample points in the data space and to relax the network constraint.
Then, we propose Latent Reconstruction(LR) loss, which is inspired by
mathematical properties of injective and composite functions, to control
posterior collapse without restriction to a specific architecture. We
experimentally evaluate our approach, which controls posterior collapse on
varied datasets such as MNIST, fashionMNIST, Omniglot, CelebA, and FFHQ.

</details>


### [257] [Rethinking Safety in LLM Fine-tuning: An Optimization Perspective](https://arxiv.org/abs/2508.12531)
*Minseon Kim,Jin Myung Kwak,Lama Alssum,Bernard Ghanem,Philip Torr,David Krueger,Fazl Barez,Adel Bibi*

Main category: cs.LG

TL;DR: 研究发现，通过优化训练超参数和采用EMA动量技术，可以在微调语言模型时避免安全性下降，无需额外安全措施。


<details>
  <summary>Details</summary>
Motivation: 挑战微调语言模型必然损害安全性的普遍观点，探索优化选择对安全性的影响。

Method: 系统测试不同训练超参数（如学习率、批量大小）的影响，并提出EMA动量技术以稳定优化路径。

Result: 通过优化超参数，将不安全响应率从16%降至5%，同时保持模型性能。

Conclusion: 微调语言模型时，通过合理选择和优化技术，可以避免安全性问题，无需额外干预。

Abstract: Fine-tuning language models is commonly believed to inevitably harm their
safety, i.e., refusing to respond to harmful user requests, even when using
harmless datasets, thus requiring additional safety measures. We challenge this
belief through systematic testing, showing that poor optimization choices,
rather than inherent trade-offs, often cause safety problems, measured as
harmful responses to adversarial prompts. By properly selecting key training
hyper-parameters, e.g., learning rate, batch size, and gradient steps, we
reduce unsafe model responses from 16\% to approximately 5\%, as measured by
keyword matching, while maintaining utility performance. Based on this
observation, we propose a simple exponential moving average (EMA) momentum
technique in parameter space that preserves safety performance by creating a
stable optimization path and retains the original pre-trained model's safety
properties. Our experiments on the Llama families across multiple datasets
(Dolly, Alpaca, ORCA) demonstrate that safety problems during fine-tuning can
largely be avoided without specialized interventions, outperforming existing
approaches that require additional safety data while offering practical
guidelines for maintaining both model performance and safety during adaptation.

</details>


### [258] [Defining and Benchmarking a Data-Centric Design Space for Brain Graph Construction](https://arxiv.org/abs/2508.12533)
*Qinwen Ge,Roza G. Bayrak,Anwar Said,Catie Chang,Xenofon Koutsoukos,Tyler Derr*

Main category: cs.LG

TL;DR: 论文提出了一种数据为中心的脑图构建方法，通过系统评估现有技术组合对下游性能的影响，显著提升了分类准确性。


<details>
  <summary>Details</summary>
Motivation: 当前脑图构建方法过于依赖固定流程，忽视了数据为中心的关键选择，限制了图机器学习在神经影像中的应用。

Method: 将脑图构建分为三个阶段：时间信号处理、拓扑提取和图特征化，评估了多种技术组合的效果。

Result: 在HCP1200和ABIDE数据集上，数据为中心的配置显著优于标准流程，提升了分类准确性。

Conclusion: 数据为中心的脑图构建方法对提升图机器学习在神经影像中的应用至关重要，需系统探索其设计空间。

Abstract: The construction of brain graphs from functional Magnetic Resonance Imaging
(fMRI) data plays a crucial role in enabling graph machine learning for
neuroimaging. However, current practices often rely on rigid pipelines that
overlook critical data-centric choices in how brain graphs are constructed. In
this work, we adopt a Data-Centric AI perspective and systematically define and
benchmark a data-centric design space for brain graph construction,
constrasting with primarily model-centric prior work. We organize this design
space into three stages: temporal signal processing, topology extraction, and
graph featurization. Our contributions lie less in novel components and more in
evaluating how combinations of existing and modified techniques influence
downstream performance. Specifically, we study high-amplitude BOLD signal
filtering, sparsification and unification strategies for connectivity,
alternative correlation metrics, and multi-view node and edge features, such as
incorporating lagged dynamics. Experiments on the HCP1200 and ABIDE datasets
show that thoughtful data-centric configurations consistently improve
classification accuracy over standard pipelines. These findings highlight the
critical role of upstream data decisions and underscore the importance of
systematically exploring the data-centric design space for graph-based
neuroimaging. Our code is available at
https://github.com/GeQinwen/DataCentricBrainGraphs.

</details>


### [259] [OS-R1: Agentic Operating System Kernel Tuning with Reinforcement Learning](https://arxiv.org/abs/2508.12551)
*Hongyu Lin,Yuchen Li,Haoran Luo,Kaichun Yao,Libo Zhang,Mingjie Xing,Yanjun Wu*

Main category: cs.LG

TL;DR: OS-R1是一个基于规则强化学习的Linux内核调优框架，通过LLM高效探索配置空间，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有Linux内核调优方法在效率、可扩展性和泛化性方面存在不足，OS-R1旨在解决这些问题。

Method: 将内核配置空间抽象为RL环境，设计定制奖励函数，并采用两阶段训练加速收敛。

Result: 实验显示OS-R1性能提升5.6%，数据效率高，且适用于多种实际场景。

Conclusion: OS-R1具有实际部署潜力，代码和数据集已开源。

Abstract: Linux kernel tuning is essential for optimizing operating system (OS)
performance. However, existing methods often face challenges in terms of
efficiency, scalability, and generalization. This paper introduces OS-R1, an
agentic Linux kernel tuning framework powered by rule-based reinforcement
learning (RL). By abstracting the kernel configuration space as an RL
environment, OS-R1 facilitates efficient exploration by large language models
(LLMs) and ensures accurate configuration modifications. Additionally, custom
reward functions are designed to enhance reasoning standardization,
configuration modification accuracy, and system performance awareness of the
LLMs. Furthermore, we propose a two-phase training process that accelerates
convergence and minimizes retraining across diverse tuning scenarios.
Experimental results show that OS-R1 significantly outperforms existing
baseline methods, achieving up to 5.6% performance improvement over heuristic
tuning and maintaining high data efficiency. Notably, OS-R1 is adaptable across
various real-world applications, demonstrating its potential for practical
deployment in diverse environments. Our dataset and code are publicly available
at https://github.com/LHY-24/OS-R1.

</details>


### [260] [Illuminating LLM Coding Agents: Visual Analytics for Deeper Understanding and Enhancement](https://arxiv.org/abs/2508.12555)
*Junpeng Wang,Yuzhong Chen,Menghai Pan,Chin-Chia Michael Yeh,Mahashweta Das*

Main category: cs.LG

TL;DR: 提出了一种可视化分析系统，帮助ML科学家更有效地审查和调整基于LLM的编码代理行为。


<details>
  <summary>Details</summary>
Motivation: 当前手动检查编码代理输出的方法效率低下，难以追踪代码演变和比较迭代。

Method: 开发了一个支持代码级、过程级和LLM级比较分析的可视化系统。

Result: 通过案例研究展示了系统如何提供对迭代编码过程的深入见解。

Conclusion: 该系统有助于结构化理解代理行为，提升调试和提示工程效率。

Abstract: Coding agents powered by large language models (LLMs) have gained traction
for automating code generation through iterative problem-solving with minimal
human involvement. Despite the emergence of various frameworks, e.g.,
LangChain, AutoML, and AIDE, ML scientists still struggle to effectively review
and adjust the agents' coding process. The current approach of manually
inspecting individual outputs is inefficient, making it difficult to track code
evolution, compare coding iterations, and identify improvement opportunities.
To address this challenge, we introduce a visual analytics system designed to
enhance the examination of coding agent behaviors. Focusing on the AIDE
framework, our system supports comparative analysis across three levels: (1)
Code-Level Analysis, which reveals how the agent debugs and refines its code
over iterations; (2) Process-Level Analysis, which contrasts different
solution-seeking processes explored by the agent; and (3) LLM-Level Analysis,
which highlights variations in coding behavior across different LLMs. By
integrating these perspectives, our system enables ML scientists to gain a
structured understanding of agent behaviors, facilitating more effective
debugging and prompt engineering. Through case studies using coding agents to
tackle popular Kaggle competitions, we demonstrate how our system provides
valuable insights into the iterative coding process.

</details>


### [261] [Deep Learning-Based Financial Time Series Forecasting via Sliding Window and Variational Mode Decomposition](https://arxiv.org/abs/2508.12565)
*Luke Li*

Main category: cs.LG

TL;DR: 提出了一种结合滑动窗口和变分模态分解（VMD）的金融时间序列预测模型，通过分解非平稳数据提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 金融时间序列复杂且非平稳，传统方法难以有效预测。

Method: 使用VMD分解历史股票价格和市场指标，输入深度学习模型（LSTM）进行预测。

Result: VMD处理后的序列比原始时间序列预测效果更好且更稳定。

Conclusion: VMD结合深度学习能有效提升金融时间序列预测的准确性和稳定性。

Abstract: To address the complexity of financial time series, this paper proposes a
forecasting model combining sliding window and variational mode decomposition
(VMD) methods. Historical stock prices and relevant market indicators are used
to construct datasets. VMD decomposes non-stationary financial time series into
smoother subcomponents, improving model adaptability. The decomposed data is
then input into a deep learning model for prediction. The study compares the
forecasting effects of an LSTM model trained on VMD-processed sequences with
those using raw time series, demonstrating better performance and stability.

</details>


### [262] [Data-driven particle dynamics: Structure-preserving coarse-graining for emergent behavior in non-equilibrium systems](https://arxiv.org/abs/2508.12569)
*Quercus Hernandez,Max Win,Thomas C. O'Connor,Paulo E. Arratia,Nathaniel Trask*

Main category: cs.LG

TL;DR: 提出了一种基于度量-辛括号形式的框架，用于从粒子轨迹的时间序列数据中学习粗粒化动力学，保留了耗散性、历史依赖性和随机性，并验证了其在复杂系统中的应用。


<details>
  <summary>Details</summary>
Motivation: 多尺度系统模拟的挑战在于如何将短时空尺度与涌现的宏观物理联系起来，粗粒化过程中信息损失导致耗散性、历史依赖性和随机性。

Method: 使用度量-辛括号形式构建框架，确保热力学第一、第二定律、动量守恒和涨落-耗散平衡；提出自监督学习策略识别涌现结构变量。

Result: 在基准系统和两个挑战性示例（星形聚合物粗粒化和胶体悬浮液动力学）中验证了方法的有效性。

Conclusion: 框架成功保留了粗粒化动力学的关键物理特性，并提供了开源实现，适用于多样化的粒子系统。

Abstract: Multiscale systems are ubiquitous in science and technology, but are
notoriously challenging to simulate as short spatiotemporal scales must be
appropriately linked to emergent bulk physics. When expensive high-dimensional
dynamical systems are coarse-grained into low-dimensional models, the entropic
loss of information leads to emergent physics which are dissipative,
history-dependent, and stochastic. To machine learn coarse-grained dynamics
from time-series observations of particle trajectories, we propose a framework
using the metriplectic bracket formalism that preserves these properties by
construction; most notably, the framework guarantees discrete notions of the
first and second laws of thermodynamics, conservation of momentum, and a
discrete fluctuation-dissipation balance crucial for capturing non-equilibrium
statistics. We introduce the mathematical framework abstractly before
specializing to a particle discretization. As labels are generally unavailable
for entropic state variables, we introduce a novel self-supervised learning
strategy to identify emergent structural variables. We validate the method on
benchmark systems and demonstrate its utility on two challenging examples: (1)
coarse-graining star polymers at challenging levels of coarse-graining while
preserving non-equilibrium statistics, and (2) learning models from high-speed
video of colloidal suspensions that capture coupling between local
rearrangement events and emergent stochastic dynamics. We provide open-source
implementations in both PyTorch and LAMMPS, enabling large-scale inference and
extensibility to diverse particle-based systems.

</details>


### [263] [Deep Learning Model for Amyloidogenicity Prediction using a Pre-trained Protein LLM](https://arxiv.org/abs/2508.12575)
*Zohra Yagoub,Hafida Bouziane*

Main category: cs.LG

TL;DR: 利用预训练蛋白质大语言模型结合双向LSTM和GRU预测淀粉样蛋白区域，准确率达84.5%。


<details>
  <summary>Details</summary>
Motivation: 淀粉样蛋白预测是生物信息学的研究重点，现有方法多基于进化基序和氨基酸特性，但序列信息特征显示出更高的预测性能。

Method: 采用预训练蛋白质大语言模型提取序列上下文特征，结合双向LSTM和GRU进行预测。

Result: 在10折交叉验证中准确率达84.5%，测试数据集准确率为83%。

Conclusion: 结果表明，大语言模型能显著提升淀粉样蛋白预测的准确性。

Abstract: The prediction of amyloidogenicity in peptides and proteins remains a focal
point of ongoing bioinformatics. The crucial step in this field is to apply
advanced computational methodologies. Many recent approaches to predicting
amyloidogenicity within proteins are highly based on evolutionary motifs and
the individual properties of amino acids. It is becoming increasingly evident
that the sequence information-based features show high predictive performance.
Consequently, our study evaluated the contextual features of protein sequences
obtained from a pretrained protein large language model leveraging
bidirectional LSTM and GRU to predict amyloidogenic regions in peptide and
protein sequences. Our method achieved an accuracy of 84.5% on 10-fold
cross-validation and an accuracy of 83% in the test dataset. Our results
demonstrate competitive performance, highlighting the potential of LLMs in
enhancing the accuracy of amyloid prediction.

</details>


### [264] [Widening the Network Mitigates the Impact of Data Heterogeneity on FedAvg](https://arxiv.org/abs/2508.12576)
*Like Jian,Dong Liu*

Main category: cs.LG

TL;DR: 论文分析了过参数化FedAvg在梯度下降下的收敛性，证明数据异质性影响随网络宽度增加而减小，无限宽度时消失。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中数据异质性对全局模型泛化能力的挑战。

Method: 理论分析过参数化FedAvg的收敛性，证明网络宽度增加时数据异质性影响减小。

Result: 无限宽度时，FedAvg的全局和局部模型表现为线性模型，泛化性能与集中式学习相同。

Conclusion: 实验验证了理论发现，表明FedAvg在无限宽度下能有效应对数据异质性。

Abstract: Federated learning (FL) enables decentralized clients to train a model
collaboratively without sharing local data. A key distinction between FL and
centralized learning is that clients' data are non-independent and identically
distributed, which poses significant challenges in training a global model that
generalizes well across heterogeneous local data distributions. In this paper,
we analyze the convergence of overparameterized FedAvg with gradient descent
(GD). We prove that the impact of data heterogeneity diminishes as the width of
neural networks increases, ultimately vanishing when the width approaches
infinity. In the infinite-width regime, we further prove that both the global
and local models in FedAvg behave as linear models, and that FedAvg achieves
the same generalization performance as centralized learning with the same
number of GD iterations. Extensive experiments validate our theoretical
findings across various network architectures, loss functions, and optimization
methods.

</details>


### [265] [Energy-Efficient Wireless LLM Inference via Uncertainty and Importance-Aware Speculative Decoding](https://arxiv.org/abs/2508.12590)
*Jihoon Park,Seungeun Oh,Seong-Lyun Kim*

Main category: cs.LG

TL;DR: 提出了一种基于令牌级过滤的混合语言模型（HLM）推理方法，通过利用认知不确定性和基于注意力的重要性，仅上传信息丰富的令牌，从而降低能耗和通信成本。


<details>
  <summary>Details</summary>
Motivation: 解决资源受限环境中设备上LLM推理的需求，同时关注通信和能源效率，而不仅仅是准确性和延迟。

Method: 采用令牌级过滤机制，结合认知不确定性和注意力重要性，选择性上传令牌。

Result: 实验显示，相比标准HLM，能耗降低40.7%，BERT Score达87.5%，令牌吞吐量为0.37 tokens/sec。相比U-HLM基线，BERT Score从85.8%提升至87.0%，能耗节省从31.6%提升至43.6%，吞吐量从0.36提升至0.40。

Conclusion: 该方法在带宽受限的边缘环境中实现了高效节能且准确的LLM部署。

Abstract: To address the growing demand for on-device LLM inference in
resource-constrained environments, hybrid language models (HLM) have emerged,
combining lightweight local models with powerful cloud-based LLMs. Recent
studies on HLM have primarily focused on improving accuracy and latency, while
often overlooking communication and energy efficiency. We propose a token-level
filtering mechanism for an energy-efficient importance- and uncertainty-aware
HLM inference that leverages both epistemic uncertainty and attention-based
importance. Our method opportunistically uploads only informative tokens,
reducing LLM usage and communication costs. Experiments with TinyLlama-1.1B and
LLaMA-2-7B demonstrate that our method achieves up to 87.5% BERT Score and
token throughput of 0.37 tokens/sec while saving the energy consumption by
40.7% compared to standard HLM. Furthermore, compared to our previous U-HLM
baseline, our method improves BERTScore from 85.8% to 87.0%, energy savings
from 31.6% to 43.6%, and throughput from 0.36 to 0.40. This approach enables an
energy-efficient and accurate deployment of LLMs in bandwidth-constrained edge
environments.

</details>


### [266] [Physics-informed deep operator network for traffic state estimation](https://arxiv.org/abs/2508.12593)
*Zhihao Li,Ting Wang,Guojian Zou,Ruofei Wang,Ye Li*

Main category: cs.LG

TL;DR: 论文提出了一种基于物理信息的深度算子网络（PI-DeepONet）框架，用于交通状态估计（TSE），通过将稀疏输入数据映射到完整的时空交通状态场，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统物理信息神经网络（PINNs）在点级强制执行偏微分方程（PDE）约束，而本文旨在通过算子学习问题重新定义TSE，确保物理一致性并捕捉交通流动态。

Method: 采用PI-DeepONet框架，将交通流守恒定律和基本图直接集成到算子学习过程中，训练参数化神经算子。

Result: 在NGSIM数据集上的实验表明，该方法优于现有基线，并揭示了最优函数生成策略和分支网络复杂性的见解。

Conclusion: PI-DeepONet框架在交通状态估计中表现出鲁棒性和高效性，为输入函数生成方法和函数数量对模型性能的影响提供了新见解。

Abstract: Traffic state estimation (TSE) fundamentally involves solving
high-dimensional spatiotemporal partial differential equations (PDEs) governing
traffic flow dynamics from limited, noisy measurements. While Physics-Informed
Neural Networks (PINNs) enforce PDE constraints point-wise, this paper adopts a
physics-informed deep operator network (PI-DeepONet) framework that
reformulates TSE as an operator learning problem. Our approach trains a
parameterized neural operator that maps sparse input data to the full
spatiotemporal traffic state field, governed by the traffic flow conservation
law. Crucially, unlike PINNs that enforce PDE constraints point-wise,
PI-DeepONet integrates traffic flow conservation model and the fundamental
diagram directly into the operator learning process, ensuring physical
consistency while capturing congestion propagation, spatial correlations, and
temporal evolution. Experiments on the NGSIM dataset demonstrate superior
performance over state-of-the-art baselines. Further analysis reveals insights
into optimal function generation strategies and branch network complexity.
Additionally, the impact of input function generation methods and the number of
functions on model performance is explored, highlighting the robustness and
efficacy of proposed framework.

</details>


### [267] [FLARE: Fast Low-rank Attention Routing Engine](https://arxiv.org/abs/2508.12594)
*Vedant Puri,Aditya Joglekar,Kevin Ferguson,Yu-hsuan Chen,Yongjie Jessica Zhang,Levent Burak Kara*

Main category: cs.LG

TL;DR: FLARE是一种线性复杂度的自注意力机制，通过固定长度的潜在序列路由注意力，解决了传统自注意力在大型非结构化网格上的计算复杂度问题。


<details>
  <summary>Details</summary>
Motivation: 传统自注意力的二次复杂度限制了其在大型非结构化网格上的应用和扩展性。

Method: FLARE通过将输入序列投影到固定长度的潜在序列上，使用可学习的查询令牌实现全局通信，从而学习低秩形式的注意力。

Result: FLARE不仅能够扩展到前所未有的问题规模，还在多个基准测试中优于最先进的神经PDE替代模型。

Conclusion: FLARE提供了一种高效且准确的自注意力机制，适用于大规模非结构化网格问题，并发布了新的增材制造数据集以促进进一步研究。

Abstract: The quadratic complexity of self-attention limits its applicability and
scalability on large unstructured meshes. We introduce Fast Low-rank Attention
Routing Engine (FLARE), a linear complexity self-attention mechanism that
routes attention through fixed-length latent sequences. Each attention head
performs global communication among $N$ tokens by projecting the input sequence
onto a fixed length latent sequence of $M \ll N$ tokens using learnable query
tokens. By routing attention through a bottleneck sequence, FLARE learns a
low-rank form of attention that can be applied at $O(NM)$ cost. FLARE not only
scales to unprecedented problem sizes, but also delivers superior accuracy
compared to state-of-the-art neural PDE surrogates across diverse benchmarks.
We also release a new additive manufacturing dataset to spur further research.
Our code is available at https://github.com/vpuri3/FLARE.py.

</details>


### [268] [Constructing Invariant and Equivariant Operations by Symmetric Tensor Network](https://arxiv.org/abs/2508.12596)
*Meng Zhang,Chao Wang,Hao Zhang,Shaojun Dong,Lixin He*

Main category: cs.LG

TL;DR: 提出了一种系统方法，用于构建不变和等变操作，适用于不同秩的笛卡尔张量和不同类型的球张量，并应用于几何图神经网络和材料本构律的机器学习模型。


<details>
  <summary>Details</summary>
Motivation: 设计具有对称性的神经网络对于几何深度学习至关重要，需要开发不变和等变操作。

Method: 提出了一种系统方法，利用对称张量网络的图形表示，简化了不变和等变函数的证明和构造。

Result: 该方法成功应用于设计几何图神经网络的等变交互消息和材料本构律的等变机器学习模型。

Conclusion: 该方法为构建不变和等变操作提供了系统且简化的工具，适用于多种张量类型和实际应用。

Abstract: Design of neural networks that incorporate symmetry is crucial for geometric
deep learning. Central to this effort is the development of invariant and
equivariant operations. This works presents a systematic method for
constructing valid invariant and equivariant operations. It can handle inputs
and outputs in the form of Cartesian tensors with different rank, as well as
spherical tensors with different types. In addition, our method features a
graphical representation utilizing the symmetric tensor network, which
simplifies both the proofs and constructions related to invariant and
equivariant functions. We also apply this approach to design the equivariant
interaction message for the geometry graph neural network, and equivariant
machine learning model to learn the constitutive law of materials.

</details>


### [269] [A Hybrid Surrogate for Electric Vehicle Parameter Estimation and Power Consumption via Physics-Informed Neural Operators](https://arxiv.org/abs/2508.12602)
*Hansol Lim,Jongseong Brad Choi,Jee Won Lee,Haeseong Jeoung,Minkyu Han*

Main category: cs.LG

TL;DR: 提出了一种混合代理模型，用于电动汽车参数估计和功耗预测，结合了傅里叶神经算子和可微分物理模块，实现了高精度和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统方法在电动汽车参数估计和功耗预测中缺乏全局上下文和物理一致性，需要一种既能捕捉全局特征又能嵌入物理约束的模型。

Method: 结合了基于傅里叶神经算子的Spectral Parameter Operator和可微分物理模块，从速度和加速度数据中输出动态参数，并通过物理嵌入的电池功率估计消除物理残差损失。

Result: 在特斯拉Model 3、Model S和Kia EV9的真实数据上测试，平均绝对误差分别为0.2kW和0.8kW，表现出高精度和泛化能力。

Conclusion: 该模型具有可解释性和实用性，适用于路径优化、生态路由和车载诊断等应用。

Abstract: We present a hybrid surrogate model for electric vehicle parameter estimation
and power consumption. We combine our novel architecture Spectral Parameter
Operator built on a Fourier Neural Operator backbone for global context and a
differentiable physics module in the forward pass. From speed and acceleration
alone, it outputs time-varying motor and regenerative braking efficiencies, as
well as aerodynamic drag, rolling resistance, effective mass, and auxiliary
power. These parameters drive a physics-embedded estimate of battery power,
eliminating any separate physics-residual loss. The modular design lets
representations converge to physically meaningful parameters that reflect the
current state and condition of the vehicle. We evaluate on real-world logs from
a Tesla Model 3, Tesla Model S, and the Kia EV9. The surrogate achieves a mean
absolute error of 0.2kW (about 1% of average traction power at highway speeds)
for Tesla vehicles and about 0.8kW on the Kia EV9. The framework is
interpretable, and it generalizes well to unseen conditions, and sampling
rates, making it practical for path optimization, eco-routing, on-board
diagnostics, and prognostics health management.

</details>


### [270] [SSPO: Self-traced Step-wise Preference Optimization for Process Supervision and Reasoning Compression](https://arxiv.org/abs/2508.12604)
*Yuyang Xu,Yi Cheng,Haochao Ying,Zhuoyun Du,Renjun Hu,Xing Shi,Wei Lin,Jian Wu*

Main category: cs.LG

TL;DR: SSPO是一种无需辅助模型或手动标注的RL框架，通过自生成的步进偏好信号优化推理步骤，减少过思考行为。


<details>
  <summary>Details</summary>
Motivation: 主流后训练方法（如RL与CoT推理）因辅助模型和过思考导致高计算开销，错误答案源于冗长推理过程缺乏自我修正。

Method: 提出SSPO，利用模型自生成的步进偏好信号进行细粒度推理步骤优化，无需辅助模型或手动标注。

Result: 实验表明SSPO生成的推理序列准确且简洁，有效减少过思考行为，且不影响模型性能。

Conclusion: SSPO是一种高效且通用的推理优化框架，适用于多领域和语言。

Abstract: Test-time scaling has proven effective in further enhancing the performance
of pretrained Large Language Models (LLMs). However, mainstream post-training
methods (i.e., reinforcement learning (RL) with chain-of-thought (CoT)
reasoning) often incur substantial computational overhead due to auxiliary
models and overthinking. In this paper, we empirically reveal that the
incorrect answers partially stem from verbose reasoning processes lacking
correct self-fix, where errors accumulate across multiple reasoning steps. To
this end, we propose Self-traced Step-wise Preference Optimization (SSPO), a
pluggable RL process supervision framework that enables fine-grained
optimization of each reasoning step. Specifically, SSPO requires neither
auxiliary models nor stepwise manual annotations. Instead, it leverages
step-wise preference signals generated by the model itself to guide the
optimization process for reasoning compression. Experiments demonstrate that
the generated reasoning sequences from SSPO are both accurate and succinct,
effectively mitigating overthinking behaviors without compromising model
performance across diverse domains and languages.

</details>


### [271] [How can we trust opaque systems? Criteria for robust explanations in XAI](https://arxiv.org/abs/2508.12623)
*Florian J. Boge,Annika Schuster*

Main category: cs.LG

TL;DR: 论文探讨了深度学习算法的可解释性问题，提出了解释稳健性（ER）和解释方法稳健性（EMR）作为可信赖解释的标准。


<details>
  <summary>Details</summary>
Motivation: 深度学习算法虽然预测准确，但其内部机制不透明，缺乏可信赖的解释方法。

Method: 提出并形式化了ER和EMR的标准，为建立可信赖的解释框架提供了理论基础。

Result: 通过ER和EMR的框架，可以更可靠地解释深度学习算法的预测过程。

Conclusion: 论文为深度学习算法的可解释性提供了新的标准，并指出了未来研究方向。

Abstract: Deep learning (DL) algorithms are becoming ubiquitous in everyday life and in
scientific research. However, the price we pay for their impressively accurate
predictions is significant: their inner workings are notoriously opaque - it is
unknown to laypeople and researchers alike what features of the data a DL
system focuses on and how it ultimately succeeds in predicting correct outputs.
A necessary criterion for trustworthy explanations is that they should reflect
the relevant processes the algorithms' predictions are based on. The field of
eXplainable Artificial Intelligence (XAI) presents promising methods to create
such explanations. But recent reviews about their performance offer reasons for
skepticism. As we will argue, a good criterion for trustworthiness is
explanatory robustness: different XAI methods produce the same explanations in
comparable contexts. However, in some instances, all methods may give the same,
but still wrong, explanation. We therefore argue that in addition to
explanatory robustness (ER), a prior requirement of explanation method
robustness (EMR) has to be fulfilled by every XAI method. Conversely, the
robustness of an individual method is in itself insufficient for
trustworthiness. In what follows, we develop and formalize criteria for ER as
well as EMR, providing a framework for explaining and establishing trust in DL
algorithms. We also highlight interesting application cases and outline
directions for future work.

</details>


### [272] [FlowMol3: Flow Matching for 3D De Novo Small-Molecule Generation](https://arxiv.org/abs/2508.12629)
*Ian Dunn,David R. Koes*

Main category: cs.LG

TL;DR: FlowMol3是一种多模态流匹配模型，通过三种架构无关技术显著提升了分子生成性能，实现了近乎100%的有效性，并减少了参数数量。


<details>
  <summary>Details</summary>
Motivation: 开发能够生成具有所需属性的真实分子的生成模型，以加速化学发现。

Method: 采用自条件、假原子和训练时几何扭曲三种技术，无需改变图神经网络架构或流匹配公式。

Result: FlowMol3在药物分子生成中实现了近乎100%的有效性，更准确地复现了训练数据的功能组成和几何结构，且参数数量大幅减少。

Conclusion: 这些技术缓解了基于传输的生成模型的普遍问题，为扩散和流基分子生成模型提供了简单且可转移的改进策略。

Abstract: A generative model capable of sampling realistic molecules with desired
properties could accelerate chemical discovery across a wide range of
applications. Toward this goal, significant effort has focused on developing
models that jointly sample molecular topology and 3D structure. We present
FlowMol3, an open-source, multi-modal flow matching model that advances the
state of the art for all-atom, small-molecule generation. Its substantial
performance gains over previous FlowMol versions are achieved without changes
to the graph neural network architecture or the underlying flow matching
formulation. Instead, FlowMol3's improvements arise from three
architecture-agnostic techniques that incur negligible computational cost:
self-conditioning, fake atoms, and train-time geometry distortion. FlowMol3
achieves nearly 100% molecular validity for drug-like molecules with explicit
hydrogens, more accurately reproduces the functional group composition and
geometry of its training data, and does so with an order of magnitude fewer
learnable parameters than comparable methods. We hypothesize that these
techniques mitigate a general pathology affecting transport-based generative
models, enabling detection and correction of distribution drift during
inference. Our results highlight simple, transferable strategies for improving
the stability and quality of diffusion- and flow-based molecular generative
models.

</details>


### [273] [Score-informed Neural Operator for Enhancing Ordering-based Causal Discovery](https://arxiv.org/abs/2508.12650)
*Jiyeon Kang,Songseong Kim,Chanhui Lee,Doyeong Hwang,Joanie Hayoun Chung,Yunkyung Ko,Sumin Lee,Sungwoong Kim,Sungbin Lim*

Main category: cs.LG

TL;DR: SciNO是一种新的概率生成模型，用于稳定估计Hessian对角线和保持结构信息，显著提高了因果排序的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于ANM的因果排序方法依赖Hessian对角线的估计，但计算成本高且数值不稳定。

Method: 提出Score-informed Neural Operator (SciNO)，在平滑函数空间中稳定近似Hessian对角线，并保持结构信息。

Result: 在合成图和真实数据集上，SciNO平均比DiffAN减少42.7%和31.5%的排序差异，同时保持内存效率和可扩展性。

Conclusion: SciNO结合自回归模型先验，提升了LLMs的因果推理能力，无需额外微调或提示工程。

Abstract: Ordering-based approaches to causal discovery identify topological orders of
causal graphs, providing scalable alternatives to combinatorial search methods.
Under the Additive Noise Model (ANM) assumption, recent causal ordering methods
based on score matching require an accurate estimation of the Hessian diagonal
of the log-densities. However, previous approaches mainly use Stein gradient
estimators, which are computationally expensive and memory-intensive. Although
DiffAN addresses these limitations by substituting kernel-based estimates with
diffusion models, it remains numerically unstable due to the second-order
derivatives of score models. To alleviate these problems, we propose
Score-informed Neural Operator (SciNO), a probabilistic generative model in
smooth function spaces designed to stably approximate the Hessian diagonal and
to preserve structural information during the score modeling. Empirical results
show that SciNO reduces order divergence by 42.7% on synthetic graphs and by
31.5% on real-world datasets on average compared to DiffAN, while maintaining
memory efficiency and scalability. Furthermore, we propose a probabilistic
control algorithm for causal reasoning with autoregressive models that
integrates SciNO's probability estimates with autoregressive model priors,
enabling reliable data-driven causal ordering informed by semantic information.
Consequently, the proposed method enhances causal reasoning abilities of LLMs
without additional fine-tuning or prompt engineering.

</details>


### [274] [Robust Federated Learning under Adversarial Attacks via Loss-Based Client Clustering](https://arxiv.org/abs/2508.12672)
*Emmanouil Kritharakis,Dusan Jakovetic,Antonios Makris,Konstantinos Tserpes*

Main category: cs.LG

TL;DR: 该论文提出了一种在联邦学习（FL）中抵御拜占庭攻击的方法，仅需服务器和一个诚实客户端即可有效运行，无需预先知道恶意客户端的数量。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中客户端可能受到拜占庭攻击的问题，同时服务器拥有可信的辅助数据集。

Method: 通过理论分析和实验验证，提出了一种无需预先知道恶意客户端数量的防御方法。

Result: 实验表明，该方法在多种攻击策略下显著优于标准及鲁棒FL基线方法。

Conclusion: 该方法在强拜占庭攻击下仍能保持有界最优性差距，具有实际应用潜力。

Abstract: Federated Learning (FL) enables collaborative model training across multiple
clients without sharing private data. We consider FL scenarios wherein FL
clients are subject to adversarial (Byzantine) attacks, while the FL server is
trusted (honest) and has a trustworthy side dataset. This may correspond to,
e.g., cases where the server possesses trusted data prior to federation, or to
the presence of a trusted client that temporarily assumes the server role. Our
approach requires only two honest participants, i.e., the server and one
client, to function effectively, without prior knowledge of the number of
malicious clients. Theoretical analysis demonstrates bounded optimality gaps
even under strong Byzantine attacks. Experimental results show that our
algorithm significantly outperforms standard and robust FL baselines such as
Mean, Trimmed Mean, Median, Krum, and Multi-Krum under various attack
strategies including label flipping, sign flipping, and Gaussian noise addition
across MNIST, FMNIST, and CIFAR-10 benchmarks using the Flower framework.

</details>


### [275] [Deploying Models to Non-participating Clients in Federated Learning without Fine-tuning: A Hypernetwork-based Approach](https://arxiv.org/abs/2508.12673)
*Yuhao Zhou,Jindi Lv,Yuxin Tian,Dan Si,Qing Ye,Jiancheng Lv*

Main category: cs.LG

TL;DR: HyperFedZero是一种动态生成专用模型的新方法，通过超网络处理数据分布异构性，显著提升联邦学习在非参与客户端上的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中数据异构性对非参与客户端泛化能力不足的问题。

Method: 利用超网络基于分布感知嵌入动态生成专用模型，结合NoisyEmbed增强提取器和平衡惩罚防止特征崩溃。

Result: 在多个数据集和模型上表现优异，计算、存储和通信开销低。

Conclusion: HyperFedZero有效解决了数据异构性问题，验证了各组件必要性。

Abstract: Federated Learning (FL) has emerged as a promising paradigm for
privacy-preserving collaborative learning, yet data heterogeneity remains a
critical challenge. While existing methods achieve progress in addressing data
heterogeneity for participating clients, they fail to generalize to
non-participating clients with in-domain distribution shifts and resource
constraints. To mitigate this issue, we present HyperFedZero, a novel method
that dynamically generates specialized models via a hypernetwork conditioned on
distribution-aware embeddings. Our approach explicitly incorporates
distribution-aware inductive biases into the model's forward pass, extracting
robust distribution embeddings using a NoisyEmbed-enhanced extractor with a
Balancing Penalty, effectively preventing feature collapse. The hypernetwork
then leverages these embeddings to generate specialized models chunk-by-chunk
for non-participating clients, ensuring adaptability to their unique data
distributions. Extensive experiments on multiple datasets and models
demonstrate HyperFedZero's remarkable performance, surpassing competing methods
consistently with minimal computational, storage, and communication overhead.
Moreover, ablation studies and visualizations further validate the necessity of
each component, confirming meaningful adaptations and validating the
effectiveness of HyperFedZero.

</details>


### [276] [BUILDA: A Thermal Building Data Generation Framework for Transfer Learning](https://arxiv.org/abs/2508.12703)
*Thomas Krug,Fabian Raisch,Dominik Aimer,Markus Wirnsberger,Ferdinand Sigg,Benjamin Schäfer,Benjamin Tischler*

Main category: cs.LG

TL;DR: BuilDa是一个用于生成建筑热力学数据的框架，支持迁移学习研究，无需深厚的建筑模拟知识。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏高质量和大规模的建筑热力学数据，限制了迁移学习研究的发展。

Method: BuilDa使用单区域Modelica模型，导出为FMU并在Python中模拟，生成合成数据。

Result: BuilDa能够生成足够质量和数量的数据，用于迁移学习的预训练和微调。

Conclusion: BuilDa为建筑热力学迁移学习研究提供了高效的数据生成解决方案。

Abstract: Transfer learning (TL) can improve data-driven modeling of building thermal
dynamics. Therefore, many new TL research areas emerge in the field, such as
selecting the right source model for TL. However, these research directions
require massive amounts of thermal building data which is lacking presently.
Neither public datasets nor existing data generators meet the needs of TL
research in terms of data quality and quantity. Moreover, existing data
generation approaches typically require expert knowledge in building
simulation. We present BuilDa, a thermal building data generation framework for
producing synthetic data of adequate quality and quantity for TL research. The
framework does not require profound building simulation knowledge to generate
large volumes of data. BuilDa uses a single-zone Modelica model that is
exported as a Functional Mock-up Unit (FMU) and simulated in Python. We
demonstrate BuilDa by generating data and utilizing it for pretraining and
fine-tuning TL models.

</details>


### [277] [Argos: A Decentralized Federated System for Detection of Traffic Signs in CAVs](https://arxiv.org/abs/2508.12712)
*Seyed Mahdi Haji Seyed Hossein,Alireza Hosseini,Soheil Hajian Manesh,Amirali Shahriary*

Main category: cs.LG

TL;DR: 提出了一种用于交通标志检测的联邦学习框架，通过分散式训练保护数据隐私，并在模拟环境中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 集中式机器学习在车辆感知任务中存在隐私和通信挑战，需要一种不共享原始数据的协作训练方法。

Method: 使用轻量级目标检测器进行本地训练，通过FedProx、FedAdam和FedAVG等算法聚合模型参数，并在模拟环境中评估不同配置。

Result: 增加服务器轮次、适中的本地训练轮次和更高的客户端参与率能显著提高准确性，FedProx在处理异构数据时表现最佳。

Conclusion: 联邦学习方法为车辆部署提供了可扩展且隐私保护的解决方案，未来可进一步优化聚合和通信策略。

Abstract: Connected and automated vehicles generate vast amounts of sensor data daily,
raising significant privacy and communication challenges for centralized
machine learning approaches in perception tasks. This study presents a
decentralized, federated learning framework tailored for traffic sign detection
in vehicular networks to enable collaborative model training without sharing
raw data. The framework partitioned traffic sign classes across vehicles for
specialized local training using lightweight object detectors, aggregated model
parameters via algorithms like FedProx, FedAdam and FedAVG in a simulated
environment with the Flower framework, and evaluated multiple configurations
including varying server rounds, local epochs, client participation fractions,
and data distributions. Experiments demonstrated that increasing server rounds
from 2 to 20 boosted accuracy from below 0.1 to over 0.8, moderate local epochs
(8-10) provided optimal efficiency with accuracies around 0.67, higher client
participation fractions enhanced generalization up to 0.83, FedProx
outperformed other aggregators in handling heterogeneity, non-IID data
distributions reduced performance compared to IID, and training duration
primarily scaled with the number of rounds rather than aggregation strategy. We
conclude that this federated approach may offer a scalable, privacy-preserving
solution for real-world vehicular deployments, potentially guiding future
integrations of robust aggregation and communication optimizations to advance
intelligent transportation systems.

</details>


### [278] [FedSODA: Federated Fine-tuning of LLMs via Similarity Group Pruning and Orchestrated Distillation Alignment](https://arxiv.org/abs/2508.12727)
*Manning Zhu,Songtao Guo,Pengzhan Zhou,Yansong Ning,Chang Han,Dewen Qiao*

Main category: cs.LG

TL;DR: FedSODA是一个资源高效的联邦微调框架，通过相似性组剪枝和协调蒸馏对齐模块，显著降低了通信开销和存储需求，同时提升了任务准确性。


<details>
  <summary>Details</summary>
Motivation: 解决资源受限客户端在联邦微调中因计算和内存需求高而受限的问题。

Method: 提出相似性组剪枝（SGP）模块和协调蒸馏对齐（ODA）模块，结合QLoRA技术，减少本地资源需求。

Result: 实验表明，FedSODA平均减少70.6%的通信开销，降低75.6%的存储使用，并提高3.1%的任务准确性。

Conclusion: FedSODA适用于资源受限的联邦微调应用，具有高效性和实用性。

Abstract: Federated fine-tuning (FFT) of large language models (LLMs) has recently
emerged as a promising solution to enable domain-specific adaptation while
preserving data privacy. Despite its benefits, FFT on resource-constrained
clients relies on the high computational and memory demands of full-model
fine-tuning, which limits the potential advancement. This paper presents
FedSODA, a resource-efficient FFT framework that enables clients to adapt LLMs
without accessing or storing the full model. Specifically, we first propose a
similarity group pruning (SGP) module, which prunes redundant layers from the
full LLM while retaining the most critical layers to preserve the model
performance. Moreover, we introduce an orchestrated distillation alignment
(ODA) module to reduce gradient divergence between the sub-LLM and the full LLM
during FFT. Through the use of the QLoRA, clients only need to deploy quantized
sub-LLMs and fine-tune lightweight adapters, significantly reducing local
resource requirements. We conduct extensive experiments on three open-source
LLMs across a variety of downstream tasks. The experimental results demonstrate
that FedSODA reduces communication overhead by an average of 70.6%, decreases
storage usage by 75.6%, and improves task accuracy by 3.1%, making it highly
suitable for practical FFT applications under resource constraints.

</details>


### [279] [FedUNet: A Lightweight Additive U-Net Module for Federated Learning with Heterogeneous Models](https://arxiv.org/abs/2508.12740)
*Beomseok Seo,Kichang Lee,JaeYeon Park*

Main category: cs.LG

TL;DR: FedUNet是一个轻量级且架构无关的联邦学习框架，通过U-Net风格的附加模块实现异构环境下的高效知识共享。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习方法通常假设客户端模型架构相同，限制了在异构环境中的应用。

Method: FedUNet为每个客户端的骨干网络附加U-Net风格的模块，仅共享紧凑的瓶颈层，无需结构对齐。

Result: 实验表明，FedUNet在VGG变体上达到93.11%准确率，轻量版仅需0.89MB通信开销。

Conclusion: FedUNet通过U-Net设计实现了异构联邦学习的高效协作，通信成本低。

Abstract: Federated learning (FL) enables decentralized model training without sharing
local data. However, most existing methods assume identical model architectures
across clients, limiting their applicability in heterogeneous real-world
environments. To address this, we propose FedUNet, a lightweight and
architecture-agnostic FL framework that attaches a U-Net-inspired additive
module to each client's backbone. By sharing only the compact bottleneck of the
U-Net, FedUNet enables efficient knowledge transfer without structural
alignment. The encoder-decoder design and skip connections in the U-Net help
capture both low-level and high-level features, facilitating the extraction of
clientinvariant representations. This enables cooperative learning between the
backbone and the additive module with minimal communication cost. Experiment
with VGG variants shows that FedUNet achieves 93.11% accuracy and 92.68% in
compact form (i.e., a lightweight version of FedUNet) with only 0.89 MB low
communication overhead.

</details>


### [280] [A Multi-Resolution Benchmark Framework for Spatial Reasoning Assessment in Neural Networks](https://arxiv.org/abs/2508.12741)
*Manuela Imbriani,Gina Belmonte,Mieke Massink,Alessandro Tofani,Vincenzo Ciancia*

Main category: cs.LG

TL;DR: 论文提出了一个评估神经网络空间推理能力的基准框架，重点关注连通性和距离关系等形态学特性，并初步揭示了神经网络在这些任务中的系统性缺陷。


<details>
  <summary>Details</summary>
Motivation: 开发一个系统性的基准框架，以评估神经网络在空间推理任务中的能力，特别是在临床应用中可能遇到的几何和拓扑问题。

Method: 利用VoxLogicA空间模型检查器生成合成数据集（迷宫连通性和空间距离任务），并通过标准化训练、推理和评估（Dice系数和IoU）进行测试。

Result: 初步结果显示神经网络在基本几何和拓扑任务中存在系统性缺陷。

Conclusion: 框架为识别神经网络的空间推理限制提供了可重复的实验协议，并建议结合符号推理方法以改进临床应用中的空间理解。

Abstract: This paper presents preliminary results in the definition of a comprehensive
benchmark framework designed to systematically evaluate spatial reasoning
capabilities in neural networks, with a particular focus on morphological
properties such as connectivity and distance relationships. The framework is
currently being used to study the capabilities of nnU-Net, exploiting the
spatial model checker VoxLogicA to generate two distinct categories of
synthetic datasets: maze connectivity problems for topological analysis and
spatial distance computation tasks for geometric understanding. Each category
is evaluated across multiple resolutions to assess scalability and
generalization properties. The automated pipeline encompasses a complete
machine learning workflow including: synthetic dataset generation, standardized
training with cross-validation, inference execution, and comprehensive
evaluation using Dice coefficient and IoU (Intersection over Union) metrics.
Preliminary experimental results demonstrate significant challenges in neural
network spatial reasoning capabilities, revealing systematic failures in basic
geometric and topological understanding tasks. The framework provides a
reproducible experimental protocol, enabling researchers to identify specific
limitations. Such limitations could be addressed through hybrid approaches
combining neural networks with symbolic reasoning methods for improved spatial
understanding in clinical applications, establishing a foundation for ongoing
research into neural network spatial reasoning limitations and potential
solutions.

</details>


### [281] [Constrained Centroid Clustering: A Novel Approach for Compact and Structured Partitioning](https://arxiv.org/abs/2508.12758)
*Sowmini Devi Veeramachaneni,Ramamurthy Garimella*

Main category: cs.LG

TL;DR: CCC是一种通过约束聚类中心与最远点距离的聚类方法，优于K-means和GMM，适用于需要控制聚类扩散的应用。


<details>
  <summary>Details</summary>
Motivation: 传统聚类方法无法控制聚类扩散，CCC通过约束最大距离解决这一问题。

Method: 使用拉格朗日公式推导闭式解，控制聚类扩散并保持可解释性。

Result: 在合成数据上，CCC通过减少径向扩散同时保持角度结构，实现更紧凑的聚类。

Conclusion: CCC适用于需要结构化聚类和扩散控制的应用场景。

Abstract: This paper presents Constrained Centroid Clustering (CCC), a method that
extends classical centroid-based clustering by enforcing a constraint on the
maximum distance between the cluster center and the farthest point in the
cluster. Using a Lagrangian formulation, we derive a closed-form solution that
maintains interpretability while controlling cluster spread. To evaluate CCC,
we conduct experiments on synthetic circular data with radial symmetry and
uniform angular distribution. Using ring-wise, sector-wise, and joint entropy
as evaluation metrics, we show that CCC achieves more compact clusters by
reducing radial spread while preserving angular structure, outperforming
standard methods such as K-means and GMM. The proposed approach is suitable for
applications requiring structured clustering with spread control, including
sensor networks, collaborative robotics, and interpretable pattern analysis.

</details>


### [282] [Short-Term Forecasting of Energy Production and Consumption Using Extreme Learning Machine: A Comprehensive MIMO based ELM Approach](https://arxiv.org/abs/2508.12764)
*Cyril Voyant,Milan Despotovic,Luis Garcia-Gutierrez,Mohammed Asloune,Yves-Marie Saint-Drenan,Jean-Laurent Duchaud,hjuvan Antone Faggianelli,Elena Magliaro*

Main category: cs.LG

TL;DR: 提出了一种基于极限学习机（ELM）的短期能源预测新方法，通过多输入多输出（MIMO）架构预测多种能源的产量，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决能源预测中的非平稳性和季节性变化问题，同时降低计算复杂度，适用于实时应用。

Method: 采用滑动窗口技术和循环时间编码，结合ELM的MIMO架构，动态适应能源波动。

Result: 在1小时预测范围内，nRMSE为17.9%（太阳能）和5.1%（热能），R²>0.98，且在5小时内保持高精度。

Conclusion: 该方法计算效率高，适用于实时应用，并能适应不同场景和数据集。

Abstract: A novel methodology for short-term energy forecasting using an Extreme
Learning Machine ($\mathtt{ELM}$) is proposed. Using six years of hourly data
collected in Corsica (France) from multiple energy sources (solar, wind, hydro,
thermal, bioenergy, and imported electricity), our approach predicts both
individual energy outputs and total production (\cyr{including imports, which
closely follow energy demand, modulo losses)} through a Multi-Input
Multi-Output ($\mathtt{MIMO}$) architecture. To address non-stationarity and
seasonal variability, sliding window techniques and cyclic time encoding are
incorporated, enabling dynamic adaptation to fluctuations. The $\mathtt{ELM}$
model significantly outperforms persistence-based forecasting, particularly for
solar and thermal energy, achieving an $\mathtt{nRMSE}$ of $17.9\%$ and
$5.1\%$, respectively, with $\mathtt{R^2} > 0.98$ (1-hour horizon). The model
maintains high accuracy up to five hours ahead, beyond which renewable energy
sources become increasingly volatile. While $\mathtt{MIMO}$ provides marginal
gains over Single-Input Single-Output ($\mathtt{SISO}$) architectures and
offers key advantages over deep learning methods such as $\mathtt{LSTM}$, it
provides a closed-form solution with lower computational demands, making it
well-suited for real-time applications, including online learning. Beyond
predictive accuracy, the proposed methodology is adaptable to various contexts
and datasets, as it can be tuned to local constraints such as resource
availability, grid characteristics, and market structures.

</details>


### [283] [Online Ensemble Transformer for Accurate Cloud Workload Forecasting in Predictive Auto-Scaling](https://arxiv.org/abs/2508.12773)
*Jiadong Chen,Xiao He,Hengyu Ye,Fuxin Jiang,Tieying Zhang,Jianjun Chen,Xiaofeng Gao*

Main category: cs.LG

TL;DR: 提出了一种名为E3Former的在线集成模型，用于大规模预测性自动扩展中的工作负载预测，显著提高了准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在快速变化的云环境中，现有预测模型难以适应动态工作负载和复杂周期性，需要更高效的解决方案。

Method: 采用多子网络协同的在线集成模型E3Former，克服单模型局限性，同时保持低计算开销。

Result: 实验表明，该方法平均减少10%的预测误差，并在实际系统中成功部署，资源利用率降低40%以上。

Conclusion: E3Former在预测性自动扩展中表现出色，已成功应用于字节跳动的多个平台，验证了其实际价值。

Abstract: In the swiftly evolving domain of cloud computing, the advent of serverless
systems underscores the crucial need for predictive auto-scaling systems. This
necessity arises to ensure optimal resource allocation and maintain operational
efficiency in inherently volatile environments. At the core of a predictive
auto-scaling system is the workload forecasting model. Existing forecasting
models struggle to quickly adapt to the dynamics in online workload streams and
have difficulty capturing the complex periodicity brought by fine-grained,
high-frequency forecasting tasks. Addressing this, we propose a novel online
ensemble model, E3Former, for online workload forecasting in large-scale
predictive auto-scaling. Our model synergizes the predictive capabilities of
multiple subnetworks to surmount the limitations of single-model approaches,
thus ensuring superior accuracy and robustness. Remarkably, it accomplishes
this with a minimal increase in computational overhead, adhering to the lean
operational ethos of serverless systems. Through extensive experimentation on
real-world workload datasets, we establish the efficacy of our ensemble model.
In online forecasting tasks, the proposed method reduces forecast error by an
average of 10%, and its effectiveness is further demonstrated through a
predictive auto-scaling test in the real-life online system. Currently, our
method has been deployed within ByteDance's Intelligent Horizontal Pod
Auto-scaling (IHPA) platform, which supports the stable operation of over 30
applications, such as Douyin E-Comerce, TouTiao, and Volcano Engine. The
predictive auto-scaling capacity reaching over 600,000 CPU cores. On the basis
of essentially ensuring service quality, the predictive auto-scaling system can
reduce resource utilization by over 40%.

</details>


### [284] [Randomized PCA Forest for Outlier Detection](https://arxiv.org/abs/2508.12776)
*Muhammad Rajabinasab,Farhad Pakdaman,Moncef Gabbouj,Peter Schneider-Kamp,Arthur Zimek*

Main category: cs.LG

TL;DR: 提出了一种基于随机主成分分析（RPCA）森林的无监督异常检测方法，性能优于经典和最先进方法。


<details>
  <summary>Details</summary>
Motivation: 受随机PCA森林在近似K近邻搜索中的性能启发，开发了一种新的无监督异常检测方法。

Method: 利用随机PCA森林进行异常检测。

Result: 在多个数据集上表现优于经典和最先进方法，计算效率高，泛化能力强。

Conclusion: 该方法是无监督异常检测的良好选择。

Abstract: We propose a novel unsupervised outlier detection method based on Randomized
Principal Component Analysis (PCA). Inspired by the performance of Randomized
PCA (RPCA) Forest in approximate K-Nearest Neighbor (KNN) search, we develop a
novel unsupervised outlier detection method that utilizes RPCA Forest for
outlier detection. Experimental results showcase the superiority of the
proposed approach compared to the classical and state-of-the-art methods in
performing the outlier detection task on several datasets while performing
competitively on the rest. The extensive analysis of the proposed method
reflects it high generalization power and its computational efficiency,
highlighting it as a good choice for unsupervised outlier detection.

</details>


### [285] [Wavy Transformer](https://arxiv.org/abs/2508.12787)
*Satoshi Noguchi,Yoshinobu Kawahara*

Main category: cs.LG

TL;DR: Wavy Transformer通过引入二阶波动动力学解决Transformer中的过平滑问题，提升性能且无需额外调参。


<details>
  <summary>Details</summary>
Motivation: Transformer在深度模型中存在过平滑问题，导致表征趋同。本文从图神经扩散角度解释此现象，并提出物理启发的解决方案。

Method: 提出基于二阶波动动力学的新型注意力层，并设计保持物理状态-速度关系的FFN和归一化层。

Result: 在多种NLP和CV任务中验证，Wavy Transformer以最少额外参数显著提升性能。

Conclusion: 物理视角为Transformer改进提供了新思路，波动动力学有效缓解过平滑问题。

Abstract: Transformers have achieved remarkable success across natural language
processing (NLP) and computer vision (CV). However, deep transformer models
often suffer from an over-smoothing issue, in which token representations
converge to similar values as they pass through successive transformer blocks.
In this paper, we establish an equivalence between the hidden-state dynamics
induced by stacked attention layers and graph neural diffusion on a complete
graph. From this perspective, over-smoothing can be interpreted as a
consequence of the dissipative nature of the underlying diffusion dynamics.
Motivated by this physical interpretation, we propose Wavy Transformer, which
consists of a novel attention layer based on second-order wavy dynamics. We
also introduce a feed-forward network and a normalization layer designed to
preserve the physical state-velocity relationship under the chain rule, thereby
extending the transformer architecture. We further validate our proposed
techniques on various transformer models for NLP and CV tasks. The results
consistently demonstrate that Wavy Transformer improves performance with
minimal additional parameters and no extra hyperparameter tuning.

</details>


### [286] [Bridging Human and LLM Judgments: Understanding and Narrowing the Gap](https://arxiv.org/abs/2508.12792)
*Felipe Maia Polo,Xinhe Wang,Mikhail Yurochkin,Gongjun Xu,Moulinath Banerjee,Yuekai Sun*

Main category: cs.LG

TL;DR: Bridge框架通过统计建模桥接人类与LLM评估差异，提升评估一致性。


<details>
  <summary>Details</summary>
Motivation: LLM作为评估者时与人类判断存在系统性差异，需统一框架解决。

Method: 提出Bridge统计框架，建模人类偏好与LLM偏差的线性关系。

Result: 在两大基准测试中，Bridge显著提升与人类评估的一致性。

Conclusion: Bridge为LLM评估提供统计修正方法，揭示人机评估差异。

Abstract: Large language models are increasingly used as judges (LLM-as-a-judge) to
evaluate model outputs at scale, but their assessments often diverge
systematically from human judgments. We present Bridge, a unified statistical
framework that explicitly bridges human and LLM evaluations under both absolute
scoring and pairwise comparison paradigms. Bridge posits a latent human
preference score for each prompt-response pair and models LLM deviations as
linear transformations of covariates that capture sources of discrepancies.
This offers a simple and principled framework for refining LLM ratings and
characterizing systematic discrepancies between humans and LLMs. We provide an
efficient fitting algorithm with asymptotic guarantees for statistical
inference. Using six LLM judges and two benchmarks (BigGen Bench and Chatbot
Arena), Bridge achieves higher agreement with human ratings (accuracy,
calibration, and KL divergence) and exposes systematic human-LLM gaps.

</details>


### [287] [A Shift in Perspective on Causality in Domain Generalization](https://arxiv.org/abs/2508.12798)
*Damian Machlanski,Stephanie Riley,Edward Moroshko,Kurt Butler,Panagiotis Dimitrakopoulos,Thomas Melistas,Akchunya Chanchal,Steven McDonagh,Ricardo Silva,Sotirios A. Tsaftaris*

Main category: cs.LG

TL;DR: 重新审视因果建模在AI泛化中的作用，提出更细致的理论。


<details>
  <summary>Details</summary>
Motivation: 近期研究对因果建模在领域泛化（DG）基准中的效果提出质疑，需要澄清其作用。

Method: 通过文献回顾和理论分析，调和因果性与DG领域的矛盾观点。

Result: 提出更细致的因果理论，并提供了交互式演示。

Conclusion: 因果建模在AI泛化中的作用需要更复杂的理解，而非简单否定或肯定。

Abstract: The promise that causal modelling can lead to robust AI generalization has
been challenged in recent work on domain generalization (DG) benchmarks. We
revisit the claims of the causality and DG literature, reconciling apparent
contradictions and advocating for a more nuanced theory of the role of
causality in generalization. We also provide an interactive demo at
https://chai-uk.github.io/ukairs25-causal-predictors/.

</details>


### [288] [Maximum Score Routing For Mixture-of-Experts](https://arxiv.org/abs/2508.12801)
*Bowen Dong,Yilong Fan,Yutao Sun,Zhenyu Li,Tengyu Pan,Xun Zhou,Jianyong Wang*

Main category: cs.LG

TL;DR: MaxScore提出了一种新的MoE路由范式，通过最小成本最大流问题和SoftTopk算子解决传统MoE路由中的容量限制和负载平衡问题。


<details>
  <summary>Details</summary>
Motivation: 传统MoE网络在GPU友好计算中引入专家容量约束，导致令牌丢弃和硬件效率低下。去除约束又会破坏负载平衡和计算效率。

Method: MaxScore将路由建模为最小成本最大流问题，并集成SoftTopk算子，避免了迭代重路由和最优传输公式的限制。

Result: MaxScore在相同FLOPs下实现了更低的训练损失和更高的评估分数，优于有约束和无约束的基线方法。

Conclusion: MaxScore有效解决了MoE路由中的核心问题，提升了模型性能和硬件效率。

Abstract: Routing networks in sparsely activated mixture-of-experts (MoE) dynamically
allocate input tokens to top-k experts through differentiable sparse
transformations, enabling scalable model capacity while preserving
computational efficiency. Traditional MoE networks impose an expert capacity
constraint to ensure GPU-friendly computation. However, this leads to token
dropping when capacity is saturated and results in low hardware efficiency due
to padding in underutilized experts. Removing the capacity constraint, in turn,
compromises load balancing and computational efficiency. To address these
issues, we propose Maximum Score Routing ($\mathbf{MaxScore}$), a novel MoE
routing paradigm that models routing as a minimum-cost maximum-flow problem and
integrates a SoftTopk operator. MaxScore resolves the fundamental limitations
of iterative rerouting and optimal transport formulations, achieving lower
training losses and higher evaluation scores at equivalent FLOPs compared to
both constrained and unconstrained baselines. Implementation details and
experimental configurations can be obtained from
$\href{https://github.com/dongbw18/MaxScore.git}{MaxScore}$.

</details>


### [289] [Learning to Steer: Input-dependent Steering for Multimodal LLMs](https://arxiv.org/abs/2508.12815)
*Jayneel Parekh,Pegah Khayatan,Mustafa Shukor,Arnaud Dapogny,Alasdair Newson,Matthieu Cord*

Main category: cs.LG

TL;DR: L2S（Learn-to-Steer）是一种针对多模态大语言模型（MLLMs）的细粒度引导方法，通过输入特定的线性偏移来提升模型的安全性和减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 现有引导技术（如均值引导）依赖单一引导向量，无法适应输入相关的行为需求，例如安全回答或医疗建议。

Method: 提出L2S方法，训练辅助模块预测输入特定的引导向量，基于对比输入特定提示。

Result: L2S在减少幻觉和增强安全性方面优于静态基线方法。

Conclusion: L2S为MLLMs提供了一种更灵活和有效的引导方式，适用于输入相关的行为调整。

Abstract: Steering has emerged as a practical approach to enable post-hoc guidance of
LLMs towards enforcing a specific behavior. However, it remains largely
underexplored for multimodal LLMs (MLLMs); furthermore, existing steering
techniques, such as mean steering, rely on a single steering vector, applied
independently of the input query. This paradigm faces limitations when the
desired behavior is dependent on the example at hand. For example, a safe
answer may consist in abstaining from answering when asked for an illegal
activity, or may point to external resources or consultation with an expert
when asked about medical advice. In this paper, we investigate a fine-grained
steering that uses an input-specific linear shift. This shift is computed using
contrastive input-specific prompting. However, the input-specific prompts
required for this approach are not known at test time. Therefore, we propose to
train a small auxiliary module to predict the input-specific steering vector.
Our approach, dubbed as L2S (Learn-to-Steer), demonstrates that it reduces
hallucinations and enforces safety in MLLMs, outperforming other static
baselines.

</details>


### [290] [Toward Storage-Aware Learning with Compressed Data An Empirical Exploratory Study on JPEG](https://arxiv.org/abs/2508.12833)
*Kichang Lee,Songkuk Kim,JaeYeon Park,JeongGil Ko*

Main category: cs.LG

TL;DR: 本文研究了存储感知学习，通过压缩权衡数据数量与质量，发现样本对压缩的敏感性不同，支持自适应压缩策略的可行性。


<details>
  <summary>Details</summary>
Motivation: 设备端机器学习常受限于存储空间，尤其是在连续数据收集场景中，需要探索存储感知学习的优化方法。

Method: 通过实证研究，比较了均匀数据丢弃和通用压缩等策略，并分析了样本对压缩的敏感性。

Result: 研究发现样本对压缩的敏感性不同，支持自适应压缩策略的可行性，为存储感知学习系统提供了新思路。

Conclusion: 本文系统性地描述了存储感知学习的挑战，为开发新型存储感知学习系统奠定了基础。

Abstract: On-device machine learning is often constrained by limited storage,
particularly in continuous data collection scenarios. This paper presents an
empirical study on storage-aware learning, focusing on the trade-off between
data quantity and quality via compression. We demonstrate that naive
strategies, such as uniform data dropping or one-size-fits-all compression, are
suboptimal. Our findings further reveal that data samples exhibit varying
sensitivities to compression, supporting the feasibility of a sample-wise
adaptive compression strategy. These insights provide a foundation for
developing a new class of storage-aware learning systems. The primary
contribution of this work is the systematic characterization of this
under-explored challenge, offering valuable insights that advance the
understanding of storage-aware learning.

</details>


### [291] [Learning In-context $\pmb{n}$-grams with Transformers: Sub-$\pmb{n}$-grams Are Near-stationary Points](https://arxiv.org/abs/2508.12837)
*Aditya Varre,Gizem Yüce,Nicolas Flammarion*

Main category: cs.LG

TL;DR: 研究发现，在无限序列长度和参数范数下，子n-gram模型是损失函数的近稳态点，解释了阶段式学习和突现相变现象。


<details>
  <summary>Details</summary>
Motivation: 基于训练中观察到的平台期和阶段式进展现象，研究transformer模型在上下文预测任务中的损失景观。

Method: 研究简化transformer模型学习上下文n-gram语言模型，建立参数配置的稳态条件，并构造k-gram估计器。

Result: 证明子n-gram模型在特定条件下是损失函数的近稳态点，支持阶段式学习动态的观察。

Conclusion: 理论揭示了损失景观的关键特性，为阶段式学习和突现相变提供了理论依据。

Abstract: Motivated by empirical observations of prolonged plateaus and stage-wise
progression during training, we investigate the loss landscape of transformer
models trained on in-context next-token prediction tasks. In particular, we
focus on learning in-context $n$-gram language models under cross-entropy loss,
and establish a sufficient condition for parameter configurations to be
stationary points. We then construct a set of parameter configurations for a
simplified transformer model that represent $k$-gram estimators (for $k \leq
n$), and show that the gradient of the population loss at these solutions
vanishes in the limit of infinite sequence length and parameter norm. This
reveals a key property of the loss landscape: {sub-$n$-grams are
near-stationary points of the population cross-entropy loss}, offering
theoretical insight into widely observed phenomena such as stage-wise learning
dynamics and emergent phase transitions. These insights are further supported
by numerical experiments that illustrate the learning dynamics of $n$-grams,
characterized by discrete transitions between near-stationary solutions.

</details>


### [292] [HRS: Hybrid Representation Framework with Scheduling Awareness for Time Series Forecasting in Crowdsourced Cloud-Edge Platforms](https://arxiv.org/abs/2508.12839)
*Tiancheng Zhang,Cheng Zhang,Shuren Liu,Xiaofei Wang,Shaoyuan Huang,Wenyu Wang*

Main category: cs.LG

TL;DR: HRS框架通过结合数值和图像表示，优化负载预测，减少SLA违规和利润损失。


<details>
  <summary>Details</summary>
Motivation: 流媒体服务快速增长导致网络负载波动大，现有预测方法无法平衡资源分配与SLA风险。

Method: 提出HRS混合表示框架和SAL损失函数，结合数值与图像表示，优化预测准确性。

Result: 在四个真实数据集上，HRS优于十个基线，SLA违规率降低63.1%，利润损失减少32.3%。

Conclusion: HRS通过改进预测和调度决策，显著提升CCP平台的QoS和盈利能力。

Abstract: With the rapid proliferation of streaming services, network load exhibits
highly time-varying and bursty behavior, posing serious challenges for
maintaining Quality of Service (QoS) in Crowdsourced Cloud-Edge Platforms
(CCPs). While CCPs leverage Predict-then-Schedule architecture to improve QoS
and profitability, accurate load forecasting remains challenging under traffic
surges. Existing methods either minimize mean absolute error, resulting in
underprovisioning and potential Service Level Agreement (SLA) violations during
peak periods, or adopt conservative overprovisioning strategies, which mitigate
SLA risks at the expense of increased resource expenditure. To address this
dilemma, we propose HRS, a hybrid representation framework with scheduling
awareness that integrates numerical and image-based representations to better
capture extreme load dynamics. We further introduce a Scheduling-Aware Loss
(SAL) that captures the asymmetric impact of prediction errors, guiding
predictions that better support scheduling decisions. Extensive experiments on
four real-world datasets demonstrate that HRS consistently outperforms ten
baselines and achieves state-of-the-art performance, reducing SLA violation
rates by 63.1% and total profit loss by 32.3%.

</details>


### [293] [One-Class Intrusion Detection with Dynamic Graphs](https://arxiv.org/abs/2508.12885)
*Aleksei Liuliakov,Alexander Schulz,Luca Hermes,Barbara Hammer*

Main category: cs.LG

TL;DR: 提出了一种基于动态图建模和深度异常检测的新型入侵检测方法TGN-SVDD，优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 随着全球数字化发展，网络安全的重要性日益凸显。机器学习在入侵检测中具有潜力，但面临检测新事件和处理网络通信图结构等挑战。

Method: 结合动态图建模和深度异常检测技术，提出TGN-SVDD方法。

Result: 在真实入侵检测数据上表现优于多个基线方法，并提出了更具挑战性的数据变体。

Conclusion: TGN-SVDD方法在入侵检测中表现出色，为处理复杂网络事件提供了有效解决方案。

Abstract: With the growing digitalization all over the globe, the relevance of network
security becomes increasingly important. Machine learning-based intrusion
detection constitutes a promising approach for improving security, but it bears
several challenges. These include the requirement to detect novel and unseen
network events, as well as specific data properties, such as events over time
together with the inherent graph structure of network communication. In this
work, we propose a novel intrusion detection method, TGN-SVDD, which builds
upon modern dynamic graph modelling and deep anomaly detection. We demonstrate
its superiority over several baselines for realistic intrusion detection data
and suggest a more challenging variant of the latter.

</details>


### [294] [TCUQ: Single-Pass Uncertainty Quantification from Temporal Consistency with Streaming Conformal Calibration for TinyML](https://arxiv.org/abs/2508.12905)
*Ismail Lamaakal,Chaymae Yahyati,Khalid El Makkaoui,Ibrahim Ouahbi,Yassine Maleh*

Main category: cs.LG

TL;DR: TCUQ是一种用于TinyML流式处理的单次无标签不确定性监测方法，通过轻量级信号和环形缓冲区实现高效风险评分。


<details>
  <summary>Details</summary>
Motivation: 解决TinyML设备上资源有限、需要高效不确定性监测的问题。

Method: 利用短时域时间一致性，通过轻量级信号和环形缓冲区生成校准风险评分，结合流式共形校准层实现预算化决策。

Result: 在微控制器上，TCUQ比早期退出和深度集成方法更小（50-60%）和更快（30-45%），并在高严重性下达到0.86 AUPRC和0.92 AUROC。

Conclusion: TCUQ通过时间一致性和流式共形校准，为TinyML设备提供了一种实用且资源高效的监测方案。

Abstract: We introduce TCUQ, a single pass, label free uncertainty monitor for
streaming TinyML that converts short horizon temporal consistency captured via
lightweight signals on posteriors and features into a calibrated risk score
with an O(W ) ring buffer and O(1) per step updates. A streaming conformal
layer turns this score into a budgeted accept/abstain rule, yielding calibrated
behavior without online labels or extra forward passes. On microcontrollers,
TCUQ fits comfortably on kilobyte scale devices and reduces footprint and
latency versus early exit and deep ensembles (typically about 50 to 60% smaller
and about 30 to 45% faster), while methods of similar accuracy often run out of
memory. Under corrupted in distribution streams, TCUQ improves accuracy drop
detection by 3 to 7 AUPRC points and reaches up to 0.86 AUPRC at high
severities; for failure detection it attains up to 0.92 AUROC. These results
show that temporal consistency, coupled with streaming conformal calibration,
provides a practical and resource efficient foundation for on device monitoring
in TinyML.

</details>


### [295] [SparseMap: A Sparse Tensor Accelerator Framework Based on Evolution Strategy](https://arxiv.org/abs/2508.12906)
*Boran Zhao,Haiming Zhai,Zihang Yuan,Hetian Liu,Tian Xia,Wenzhe Zhao,Pengju Ren*

Main category: cs.LG

TL;DR: SparseMap是一个基于进化策略的稀疏张量加速器优化框架，通过联合优化映射和稀疏策略，解决了设计空间爆炸问题。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏张量加速器设计多为手动且局限于特定场景，调整设计因素耗时且困难，亟需自动化设计方法。

Method: 提出SparseMap框架，结合遗传编码和进化算子增强，高效探索设计空间。

Result: SparseMap在实验中优于现有方法和经典优化方法，找到更优解。

Conclusion: SparseMap为稀疏张量加速器设计提供了高效且全面的解决方案。

Abstract: The growing demand for sparse tensor algebra (SpTA) in machine learning and
big data has driven the development of various sparse tensor accelerators.
However, most existing manually designed accelerators are limited to specific
scenarios, and it's time-consuming and challenging to adjust a large number of
design factors when scenarios change. Therefore, automating the design of SpTA
accelerators is crucial. Nevertheless, previous works focus solely on either
mapping (i.e., tiling communication and computation in space and time) or
sparse strategy (i.e., bypassing zero elements for efficiency), leading to
suboptimal designs due to the lack of comprehensive consideration of both. A
unified framework that jointly optimizes both is urgently needed. However,
integrating mapping and sparse strategies leads to a combinatorial explosion in
the design space(e.g., as large as $O(10^{41})$ for the workload $P_{32 \times
64} \times Q_{64 \times 48} = Z_{32 \times 48}$). This vast search space
renders most conventional optimization methods (e.g., particle swarm
optimization, reinforcement learning and Monte Carlo tree search) inefficient.
To address this challenge, we propose an evolution strategy-based sparse tensor
accelerator optimization framework, called SparseMap. SparseMap constructing a
more comprehensive design space with the consideration of both mapping and
sparse strategy. We introduce a series of enhancements to genetic encoding and
evolutionary operators, enabling SparseMap to efficiently explore the vast and
diverse design space. We quantitatively compare SparseMap with prior works and
classical optimization methods, demonstrating that SparseMap consistently finds
superior solutions.

</details>


### [296] [SNAP-UQ: Self-supervised Next-Activation Prediction for Single-Pass Uncertainty in TinyML](https://arxiv.org/abs/2508.12907)
*Ismail Lamaakal,Chaymae Yahyati,Khalid El Makkaoui,Ibrahim Ouahbi,Yassine Maleh*

Main category: cs.LG

TL;DR: SNAP-UQ是一种单次、无标签的TinyML不确定性方法，通过深度激活预测估计风险，资源高效且适用于边缘设备。


<details>
  <summary>Details</summary>
Motivation: 为TinyML提供一种资源高效的不确定性估计方法，避免传统方法的高内存和计算开销。

Method: 使用int8头部预测下一层统计信息，轻量级单调映射器将结果转化为可操作分数，无需额外缓冲区或重复前向传递。

Result: 在视觉和音频任务中，SNAP-UQ显著减少存储和延迟（约40-60%更小，25-35%更快），并在单次传递中保持高失败检测能力（AUROC≈0.9）。

Conclusion: SNAP-UQ通过层间动态估计不确定性，为TinyML提供了一种实用且资源高效的设备端监控方案。

Abstract: We introduce \textbf{SNAP-UQ}, a single-pass, label-free uncertainty method
for TinyML that estimates risk from \emph{depth-wise next-activation
prediction}: tiny int8 heads forecast the statistics of the next layer from a
compressed view of the previous one, and a lightweight monotone mapper turns
the resulting surprisal into an actionable score. The design requires no
temporal buffers, auxiliary exits, or repeated forward passes, and adds only a
few tens of kilobytes to MCU deployments. Across vision and audio backbones,
SNAP-UQ consistently reduces flash and latency relative to early-exit and deep
ensembles (typically $\sim$40--60\% smaller and $\sim$25--35\% faster), with
competing methods of similar accuracy often exceeding memory limits. In
corrupted streams it improves accuracy-drop detection by several AUPRC points
and maintains strong failure detection (AUROC $\approx$0.9) in a single pass.
Grounding uncertainty in layer-to-layer dynamics yields a practical,
resource-efficient basis for on-device monitoring in TinyML.

</details>


### [297] [Fed-DPRoC:Communication-Efficient Differentially Private and Robust Federated Learning](https://arxiv.org/abs/2508.12978)
*Yue Xia,Tayyebeh Jahani-Nezhad,Rawad Bitar*

Main category: cs.LG

TL;DR: Fed-DPRoC是一个联邦学习框架，结合差分隐私、拜占庭鲁棒性和通信效率，通过RobAJoL实现压缩和鲁棒聚合。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中同时保障隐私、鲁棒性和通信效率的挑战。

Method: 引入鲁棒兼容压缩概念，结合JL变换和鲁棒平均（RobAJoL）。

Result: 理论证明兼容性，实验显示在CIFAR-10和Fashion MNIST上优于现有方法。

Conclusion: RobAJoL在隐私、鲁棒性和通信效率上表现优异。

Abstract: We propose Fed-DPRoC, a novel federated learning framework that
simultaneously ensures differential privacy (DP), Byzantine robustness, and
communication efficiency. We introduce the concept of robust-compatible
compression, which enables users to compress DP-protected updates while
maintaining the robustness of the aggregation rule. We instantiate our
framework as RobAJoL, combining the Johnson-Lindenstrauss (JL) transform for
compression with robust averaging for robust aggregation. We theoretically
prove the compatibility of JL transform with robust averaging and show that
RobAJoL preserves robustness guarantees, ensures DP, and reduces communication
cost. Experiments on CIFAR-10 and Fashion MNIST validate our theoretical claims
and demonstrate that RobAJoL outperforms existing methods in terms of
robustness and utility under different Byzantine attacks.

</details>


### [298] [SL-ACC: A Communication-Efficient Split Learning Framework with Adaptive Channel-wise Compression](https://arxiv.org/abs/2508.12984)
*Zehang Lin,Zheng Lin,Miao Yang,Jianhao Huang,Yuxin Zhang,Zihan Fang,Xia Du,Zhe Chen,Shunzhi Zhu,Wei Ni*

Main category: cs.LG

TL;DR: SL-ACC框架通过自适应通道重要性识别和通道分组压缩，显著减少了分布式机器学习中的通信开销，同时保持训练精度。


<details>
  <summary>Details</summary>
Motivation: 随着分布式机器学习在资源受限设备上的应用增加，传统分割学习（SL）因大量数据传输成为瓶颈，需要更高效的通信解决方案。

Method: 提出SL-ACC框架，包含自适应通道重要性识别（ACII）和通道分组压缩（CGC），通过熵评估通道贡献并分组压缩以减少传输量。

Result: 实验表明，SL-ACC在多个数据集上比现有方法更快达到目标精度。

Conclusion: SL-ACC有效解决了分割学习中的通信瓶颈问题，提升了分布式机器学习的效率。

Abstract: The increasing complexity of neural networks poses a significant barrier to
the deployment of distributed machine learning (ML) on resource-constrained
devices, such as federated learning (FL). Split learning (SL) offers a
promising solution by offloading the primary computing load from edge devices
to a server via model partitioning. However, as the number of participating
devices increases, the transmission of excessive smashed data (i.e.,
activations and gradients) becomes a major bottleneck for SL, slowing down the
model training. To tackle this challenge, we propose a communication-efficient
SL framework, named SL-ACC, which comprises two key components: adaptive
channel importance identification (ACII) and channel grouping compression
(CGC). ACII first identifies the contribution of each channel in the smashed
data to model training using Shannon entropy. Following this, CGC groups the
channels based on their entropy and performs group-wise adaptive compression to
shrink the transmission volume without compromising training accuracy.
Extensive experiments across various datasets validate that our proposed SL-ACC
framework takes considerably less time to achieve a target accuracy than
state-of-the-art benchmarks.

</details>


### [299] [Predicting the Performance of Graph Convolutional Networks with Spectral Properties of the Graph Laplacian](https://arxiv.org/abs/2508.12993)
*Shalima Binta Manir,Tim Oates*

Main category: cs.LG

TL;DR: 研究发现图的代数连通性（Fiedler值）能有效预测GCN性能，相似Fiedler值的图结构相似，适合迁移学习。


<details>
  <summary>Details</summary>
Motivation: 探索GCN性能与图结构的关系，发现Fiedler值可作为性能预测指标。

Method: 通过理论和实验分析，使用合成和真实图数据（如Cora、CiteSeer等），研究Fiedler值与GCN性能的关系。

Result: Fiedler值能有效预测GCN性能，相似Fiedler值的图适合迁移学习。

Conclusion: Fiedler值是GCN性能的可靠预测指标，为迁移学习提供新思路。

Abstract: A common observation in the Graph Convolutional Network (GCN) literature is
that stacking GCN layers may or may not result in better performance on tasks
like node classification and edge prediction. We have found empirically that a
graph's algebraic connectivity, which is known as the Fiedler value, is a good
predictor of GCN performance. Intuitively, graphs with similar Fiedler values
have analogous structural properties, suggesting that the same filters and
hyperparameters may yield similar results when used with GCNs, and that
transfer learning may be more effective between graphs with similar algebraic
connectivity. We explore this theoretically and empirically with experiments on
synthetic and real graph data, including the Cora, CiteSeer and Polblogs
datasets. We explore multiple ways of aggregating the Fiedler value for
connected components in the graphs to arrive at a value for the entire graph,
and show that it can be used to predict GCN performance. We also present
theoretical arguments as to why the Fiedler value is a good predictor.

</details>


### [300] [Kourkoutas-Beta: A Sunspike-Driven Adam Optimizer with Desert Flair](https://arxiv.org/abs/2508.12996)
*Stavros C. Kassinos*

Main category: cs.LG

TL;DR: Kourkoutas-Beta是一种动态调整beta2的Adam优化器，用于解决物理问题中梯度不稳定问题，表现优于固定beta2的Adam。


<details>
  <summary>Details</summary>
Motivation: 在物理驱动的神经网络中，梯度不稳定和损失函数波动大是常见问题，需要更鲁棒的优化器。

Method: 提出Kourkoutas-Beta优化器，动态调整beta2值，结合多种技术如leaky-AMSGrad和信任区域裁剪。

Result: 在多个测试场景中表现优于Adam，尤其在small-enwik8任务中显著降低损失和方差。

Conclusion: Kourkoutas-Beta在保持Adam收敛性的同时，显著提升了梯度不稳定情况下的鲁棒性。

Abstract: Transformer neural networks are increasingly used for physics-based problems.
In data-driven PDE surrogates, training samples from varying boundary and
initial conditions can cause erratic losses and spiky gradients; in
physics-informed neural networks (PINNs), stiff composite losses amplify this
effect.
  We introduce Kourkoutas-Beta, an Adam-style optimizer where the fixed
second-moment discount beta2 is replaced by a layer-wise dynamic value driven
by a bounded ``sunspike'' ratio: the current pooled gradient norm divided by an
exponential moving average (EMA) of past norms, squashed to the interval [0,1).
Spikes lower beta2 toward beta2_min; calm phases keep it near beta2_max.
Options include leaky-AMSGrad (decay), trust-region clipping (max_ratio),
adaptive tiny terms, and several bias-correction modes ``none'', ``beta2max'',
``exact'). With all features off and bias_correction=``none'', the method is
exactly Adam.
  We test on four settings: (i) a Transformer PDE surrogate (Heat2D), (ii) a 3D
PINN for heat conduction (Heat3D), (iii) a lightweight MLX synthetic task with
jitter and rare-trigger bursts, and (iv) a character-level Transformer on 30 MB
of enwik8 (small-enwik8). Kourkoutas-Beta improves stability and final loss
versus fixed-beta2 Adam. On small-enwik8 it lowers bits-per-character by about
38% vs Adam-0.95 and about 58% vs Adam-0.999 over 10 seeds, with smaller
variance. The method remains drop-in, with runtime overhead comparable to Adam
in testbeds A-C and within single-digit percent in testbed D. It preserves
Adam-style convergence guarantees while improving robustness under spiky
gradients.

</details>


### [301] [Fairness-Aware Multi-view Evidential Learning with Adaptive Prior](https://arxiv.org/abs/2508.12997)
*Haishun Chen,Cai Xu,Jinlong Yu,Yilin Zhang,Ziyu Guan,Wei Zhao*

Main category: cs.LG

TL;DR: FAML提出了一种公平感知的多视图证据学习方法，通过自适应先验和公平约束校准证据学习，提升预测性能和不确定性估计的可靠性。


<details>
  <summary>Details</summary>
Motivation: 实践中证据学习存在偏差，导致数据丰富类别分配更多证据，影响不确定性估计的可靠性。

Method: 引入自适应先验和公平约束，结合意见对齐机制，校准证据学习并平衡证据分配。

Result: 在五个真实数据集上，FAML实现了更平衡的证据分配，提升了预测性能和不确定性估计的可靠性。

Conclusion: FAML有效解决了证据学习偏差问题，在多视图学习中表现出优越性能。

Abstract: Multi-view evidential learning aims to integrate information from multiple
views to improve prediction performance and provide trustworthy uncertainty
esitimation. Most previous methods assume that view-specific evidence learning
is naturally reliable. However, in practice, the evidence learning process
tends to be biased. Through empirical analysis on real-world data, we reveal
that samples tend to be assigned more evidence to support data-rich classes,
thereby leading to unreliable uncertainty estimation in predictions. This
motivates us to delve into a new Biased Evidential Multi-view Learning (BEML)
problem. To this end, we propose Fairness-Aware Multi-view Evidential Learning
(FAML). FAML first introduces an adaptive prior based on training trajectory,
which acts as a regularization strategy to flexibly calibrate the biased
evidence learning process. Furthermore, we explicitly incorporate a fairness
constraint based on class-wise evidence variance to promote balanced evidence
allocation. In the multi-view fusion stage, we propose an opinion alignment
mechanism to mitigate view-specific bias across views, thereby encouraging the
integration of consistent and mutually supportive evidence. Extensive
experiments on five real-world multi-view datasets demonstrate that FAML
achieves more balanced evidence allocation and improves both prediction
performance and the reliability of uncertainty estimation compared to
state-of-the-art methods.

</details>


### [302] [Monte Carlo Functional Regularisation for Continual Learning](https://arxiv.org/abs/2508.13006)
*Pengcheng Hao,Menghao Waiyan William Zhu,Ercan Engin Kuruoglu*

Main category: cs.LG

TL;DR: MCFRCL是一种新的持续学习框架，通过蒙特卡洛采样和统计特性捕捉，提高了预测准确性和训练效率。


<details>
  <summary>Details</summary>
Motivation: 现有的功能正则化持续学习方法存在高计算成本和线性近似误差大的问题。

Method: 使用蒙特卡洛采样近似模型预测分布，并通过矩方法捕捉统计特性，结合Wasserstein和KL距离构建正则化函数。

Result: 在MNIST和CIFAR数据集上，MCFRCL在预测准确性和训练效率上优于基准方法。

Conclusion: MCFRCL是一种有效的持续学习方法，解决了现有方法的局限性。

Abstract: Continual learning (CL) is crucial for the adaptation of neural network
models to new environments. Although outperforming weight-space regularisation
approaches, the functional regularisation-based CL methods suffer from high
computational costs and large linear approximation errors. In this work, we
present a new functional regularisation CL framework, called MCFRCL, which
approximates model prediction distributions by Monte Carlo (MC) sampling.
Moreover, three continuous distributions are leveraged to capture the
statistical characteristics of the MC samples via moment-based methods.
Additionally, both the Wasserstein distance and the Kullback-Leibler (KL)
distance are employed to construct the regularisation function. The proposed
MCFRCL is evaluated against multiple benchmark methods on the MNIST and CIFAR
datasets, with simulation results highlighting its effectiveness in both
prediction accuracy and training efficiency.

</details>


### [303] [Design and Analysis of Robust Adaptive Filtering with the Hyperbolic Tangent Exponential Kernel M-Estimator Function for Active Noise Control](https://arxiv.org/abs/2508.13018)
*Iam Kim de S. Hermont,Andre R. Flores,Rodrigo C. de Lamare*

Main category: cs.LG

TL;DR: 提出了一种鲁棒自适应滤波方法FXHEKM，用于抑制脉冲噪声环境下的主动噪声控制，并通过MSE和ANR指标验证其优于竞争算法。


<details>
  <summary>Details</summary>
Motivation: 解决脉冲噪声环境下主动噪声控制的问题。

Method: 开发了FXHEKM鲁棒自适应算法，并进行了统计分析和计算成本研究。

Result: 数值结果表明FXHEKM在抑制α稳定噪声等加性干扰信号方面优于竞争算法。

Conclusion: FXHEKM算法在脉冲噪声环境下表现出高效性和鲁棒性。

Abstract: In this work, we propose a robust adaptive filtering approach for active
noise control applications in the presence of impulsive noise. In particular,
we develop the filtered-x hyperbolic tangent exponential generalized Kernel
M-estimate function (FXHEKM) robust adaptive algorithm. A statistical analysis
of the proposed FXHEKM algorithm is carried out along with a study of its
computational cost. {In order to evaluate the proposed FXHEKM algorithm, the
mean-square error (MSE) and the average noise reduction (ANR) performance
metrics have been adopted.} Numerical results show the efficiency of the
proposed FXHEKM algorithm to cancel the presence of the additive spurious
signals, such as \textbf{$\alpha$}-stable noises against competing algorithms.

</details>


### [304] [The Application of Transformer-Based Models for Predicting Consequences of Cyber Attacks](https://arxiv.org/abs/2508.13030)
*Bipin Chhetri,Akbar Siami Namin*

Main category: cs.LG

TL;DR: 论文探讨了如何利用NLP和深度学习（特别是BERT和HAN）对网络攻击后果进行分类，BERT在准确率上显著优于传统模型。


<details>
  <summary>Details</summary>
Motivation: 网络攻击日益复杂，自动化方法需求迫切，需通过分析攻击描述预测后果。

Method: 使用BERT和HAN进行多标签分类，对比传统CNN和LSTM模型。

Result: BERT准确率达0.972，优于传统模型；HAN在特定标签上表现更好。

Conclusion: BERT更适合预测网络攻击后果，因其在精确率和召回率上表现更优。

Abstract: Cyberattacks are increasing, and securing against such threats is costing
industries billions of dollars annually. Threat Modeling, that is,
comprehending the consequences of these attacks, can provide critical support
to cybersecurity professionals, enabling them to take timely action and
allocate resources that could be used elsewhere. Cybersecurity is heavily
dependent on threat modeling, as it assists security experts in assessing and
mitigating risks related to identifying vulnerabilities and threats. Recently,
there has been a pressing need for automated methods to assess attack
descriptions and forecast the future consequences of the increasing complexity
of cyberattacks. This study examines how Natural Language Processing (NLP) and
deep learning can be applied to analyze the potential impact of cyberattacks by
leveraging textual descriptions from the MITRE Common Weakness Enumeration
(CWE) database. We emphasize classifying attack consequences into five
principal categories: Availability, Access Control, Confidentiality, Integrity,
and Other. This paper investigates the use of Bidirectional Encoder
Representations from Transformers (BERT) in combination with Hierarchical
Attention Networks (HANs) for Multi-label classification, evaluating their
performance in comparison with conventional CNN and LSTM-based models.
Experimental findings show that BERT achieves an overall accuracy of $0.972$,
far higher than conventional deep learning models in multi-label
classification. HAN outperforms baseline forms of CNN and LSTM-based models on
specific cybersecurity labels. However, BERT consistently achieves better
precision and recall, making it more suitable for predicting the consequences
of a cyberattack.

</details>


### [305] [Beyond Internal Data: Bounding and Estimating Fairness from Incomplete Data](https://arxiv.org/abs/2508.13040)
*Varsha Ramineni,Hossein A. Rahmani,Emine Yilmaz,David Barber*

Main category: cs.LG

TL;DR: 利用分散数据评估AI系统公平性，解决完整数据不可获取的问题。


<details>
  <summary>Details</summary>
Motivation: 高风险领域（如贷款、招聘、医疗）的AI系统公平性至关重要，但数据隐私和法规限制导致完整数据难以获取。

Method: 利用内部预测属性和外部保护属性的分散数据，估计可行联合分布并计算公平性指标范围。

Result: 通过仿真和真实实验，证明该方法能有效估计公平性指标的真实范围。

Conclusion: 该方法为数据受限场景下的公平性测试提供了实用解决方案。

Abstract: Ensuring fairness in AI systems is critical, especially in high-stakes
domains such as lending, hiring, and healthcare. This urgency is reflected in
emerging global regulations that mandate fairness assessments and independent
bias audits. However, procuring the necessary complete data for fairness
testing remains a significant challenge. In industry settings, legal and
privacy concerns restrict the collection of demographic data required to assess
group disparities, and auditors face practical and cultural challenges in
gaining access to data. In practice, data relevant for fairness testing is
often split across separate sources: internal datasets held by institutions
with predictive attributes, and external public datasets such as census data
containing protected attributes, each providing only partial, marginal
information. Our work seeks to leverage such available separate data to
estimate model fairness when complete data is inaccessible. We propose
utilising the available separate data to estimate a set of feasible joint
distributions and then compute the set plausible fairness metrics. Through
simulation and real experiments, we demonstrate that we can derive meaningful
bounds on fairness metrics and obtain reliable estimates of the true metric.
Our results demonstrate that this approach can serve as a practical and
effective solution for fairness testing in real-world settings where access to
complete data is restricted.

</details>


### [306] [Hierarchical Evaluation Function (HEF): A Multi-Metric Approach for Optimizing Demand Forecasting Models](https://arxiv.org/abs/2508.13057)
*Adolfo González,Víctor Parada*

Main category: cs.LG

TL;DR: 该研究比较了两种自定义评估函数FMAE和HEF在需求预测中的表现，发现HEF在全局指标上更优，而FMAE在局部指标和计算效率上更佳。


<details>
  <summary>Details</summary>
Motivation: 需求预测在竞争环境中至关重要，但多变量时间序列建模面临数据复杂性和传统评估指标的局限性。

Method: 通过不同数据分割和优化器实验，比较FMAE和HEF在拟合度、准确性、鲁棒性和计算效率上的表现。

Result: HEF在全局指标（如R2、RMSE）上表现更好，FMAE在局部指标（如MAE）和计算效率上更优。

Conclusion: HEF适合战略规划，FMAE适合短期场景，研究提出了一个可复现的优化框架。

Abstract: Demand forecasting is essential for strategic planning in competitive
environments, enabling resource optimization and improved responsiveness to
market dynamics. However, multivariate time series modeling faces challenges
due to data complexity, uncertainty, and frequent regime shifts. Traditional
evaluation metrics can introduce biases and limit generalization. This work
compares two custom evaluation functions: FMAE (Focused Mean Absolute Error),
focused on minimizing absolute errors, and HEF (Hierarchical Evaluation
Function), designed to weight global metrics and penalize large deviations.
Experiments were conducted under different data splits (91:9, 80:20, 70:30)
using three optimizers (Grid Search, PSO, Optuna), assessing fit, relative
accuracy, robustness, and computational efficiency. Results show that HEF
consistently outperforms FMAE in global metrics (R2, Relative Accuracy, RMSE,
RMSSE), enhancing model robustness and explanatory power. These findings were
confirmed via visualizations and statistical tests. Conversely, FMAE offers
advantages in local metrics (MAE, MASE) and execution time, making it suitable
for short-term scenarios. The study highlights a methodological trade-off: HEF
is ideal for strategic planning, while FMAE is better suited for operational
efficiency. A replicable framework is proposed for optimizing predictive models
in dynamic environments.

</details>


### [307] [Seeing the Many: Exploring Parameter Distributions Conditioned on Features in Surrogates](https://arxiv.org/abs/2508.13088)
*Xiaohan Wang,Zhimin Li,Joshua A. Levine,Matthew Berger*

Main category: cs.LG

TL;DR: 该论文提出了一种通过神经代理模型解决逆问题的方法，旨在建模和可视化产生特定输出特征的输入参数分布，解决了代理模型误差和交互式参数分布形成的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统模拟工作流程成本高昂，神经代理模型成为替代方案，但现有方法仅关注少量匹配参数，忽略了更广泛的可能参数分布。

Method: 通过密度估计建模代理模型的误差，结合先验参数分布和特征似然，高效采样生成目标输出特征的参数配置。

Result: 通过可视化界面在三个模拟数据集上展示了特征驱动的参数分析，验证了方法的实用性。

Conclusion: 该方法有效解决了逆问题中的参数分布建模和可视化问题，为科学模拟提供了新工具。

Abstract: Recently, neural surrogate models have emerged as a compelling alternative to
traditional simulation workflows. This is accomplished by modeling the
underlying function of scientific simulations, removing the need to run
expensive simulations. Beyond just mapping from input parameter to output,
surrogates have also been shown useful for inverse problems: output to input
parameters. Inverse problems can be understood as search, where we aim to find
parameters whose surrogate outputs contain a specified feature. Yet finding
these parameters can be costly, especially for high-dimensional parameter
spaces. Thus, existing surrogate-based solutions primarily focus on finding a
small set of matching parameters, in the process overlooking the broader
picture of plausible parameters. Our work aims to model and visualize the
distribution of possible input parameters that produce a given output feature.
To achieve this goal, we aim to address two challenges: (1) the approximation
error inherent in the surrogate model and (2) forming the parameter
distribution in an interactive manner. We model error via density estimation,
reporting high density only if a given parameter configuration is close to
training parameters, measured both over the input and output space. Our density
estimate is used to form a prior belief on parameters, and when combined with a
likelihood on features, gives us an efficient way to sample plausible parameter
configurations that generate a target output feature. We demonstrate the
usability of our solution through a visualization interface by performing
feature-driven parameter analysis over the input parameter space of three
simulation datasets. Source code is available at
https://github.com/matthewberger/seeing-the-many

</details>


### [308] [Outlier Detection of Poisson-Distributed Targets Using a Seabed Sensor Network](https://arxiv.org/abs/2508.13099)
*Mingyu Kim,Daniel Stilwell,Jorge Jimenez*

Main category: cs.LG

TL;DR: 提出了一种基于海底声学传感器网络和LGCPs的海事空间异常分类与检测框架，通过混合模型和二阶近似提高分类精度，并动态优化传感器布局。


<details>
  <summary>Details</summary>
Motivation: 解决海事环境中空间异常检测的挑战，提高分类和检测的准确性。

Method: 使用LGCPs建模目标到达，提出二阶近似概率估计方法，并结合动态传感器布局策略。

Result: 在真实船舶交通数据中验证，显示分类和检测性能显著提升。

Conclusion: 框架有效提高了海事异常检测的准确性和实时性。

Abstract: This paper presents a framework for classifying and detecting spatial
commission outliers in maritime environments using seabed acoustic sensor
networks and log Gaussian Cox processes (LGCPs). By modeling target arrivals as
a mixture of normal and outlier processes, we estimate the probability that a
newly observed event is an outlier. We propose a second-order approximation of
this probability that incorporates both the mean and variance of the normal
intensity function, providing improved classification accuracy compared to
mean-only approaches. We analytically show that our method yields a tighter
bound to the true probability using Jensen's inequality. To enhance detection,
we integrate a real-time, near-optimal sensor placement strategy that
dynamically adjusts sensor locations based on the evolving outlier intensity.
The proposed framework is validated using real ship traffic data near Norfolk,
Virginia, where numerical results demonstrate the effectiveness of our approach
in improving both classification performance and outlier detection through
sensor deployment.

</details>


### [309] [A Perfectly Truthful Calibration Measure](https://arxiv.org/abs/2508.13100)
*Jason Hartline,Lunjia Hu,Yifan Wu*

Main category: cs.LG

TL;DR: 论文提出了一种名为ATB的完美真实校准度量方法，解决了现有校准度量在有限样本下不真实的问题。


<details>
  <summary>Details</summary>
Motivation: 现有校准度量在有限样本下会激励预测器撒谎以显得更校准，缺乏真实性。

Method: 设计了ATB（平均两箱校准误差），并通过通用方法证明了其真实性。

Result: ATB不仅真实，还具有高效、易计算等优点，且与现有校准度量有二次关系。

Conclusion: ATB是首个在批量设置中完美真实的校准度量，为校准测试问题提供了更高效的解决方案。

Abstract: Calibration requires that predictions are conditionally unbiased and,
therefore, reliably interpretable as probabilities. Calibration measures
quantify how far a predictor is from perfect calibration. As introduced by
Haghtalab et al. (2024), a calibration measure is truthful if it is minimized
in expectation when a predictor outputs the ground-truth probabilities.
Although predicting the true probabilities guarantees perfect calibration, in
reality, when calibration is evaluated on a finite sample, predicting the truth
is not guaranteed to minimize any known calibration measure. All known
calibration measures incentivize predictors to lie in order to appear more
calibrated on a finite sample. Such lack of truthfulness motivated Haghtalab et
al. (2024) and Qiao and Zhao (2025) to construct approximately truthful
calibration measures in the sequential prediction setting, but no perfectly
truthful calibration measure was known to exist even in the more basic batch
setting.
  We design a perfectly truthful calibration measure in the batch setting:
averaged two-bin calibration error (ATB). In addition to being truthful, ATB is
sound, complete, continuous, and quadratically related to two existing
calibration measures: the smooth calibration error (smCal) and the (lower)
distance to calibration (distCal). The simplicity in our definition of ATB
makes it efficient and straightforward to compute. ATB allows faster estimation
algorithms with significantly easier implementations than smCal and distCal,
achieving improved running time and simplicity for the calibration testing
problem studied by Hu et al. (2024). We also introduce a general recipe for
constructing truthful measures, which proves the truthfulness of ATB as a
special case and allows us to construct other truthful calibration measures
such as quantile-binned l_2-ECE.

</details>


### [310] [Causally-Guided Pairwise Transformer -- Towards Foundational Digital Twins in Process Industry](https://arxiv.org/abs/2508.13111)
*Michael Mayr,Georgios C. Chasparis*

Main category: cs.LG

TL;DR: CGPT是一种新型架构，通过整合已知因果图作为归纳偏置，解决了多维时间序列数据建模中通道依赖（CD）和通道独立（CI）模型的矛盾。


<details>
  <summary>Details</summary>
Motivation: 工业系统中多维时间序列数据建模存在CD模型缺乏鲁棒性和CI模型忽略变量交互的问题，需要一种兼顾两者的方法。

Method: CGPT采用成对建模范式，将多维数据分解为对，使用通道无关的可学习层，并在对级别实现CD信息流和跨对的CI泛化。

Result: CGPT在合成和真实工业数据集上显著优于CD和CI基线模型，且在预测准确性和问题维度无关性上表现优异。

Conclusion: CGPT通过成对建模和因果引导，实现了灵活、可扩展且适应性强的时间序列建模方法。

Abstract: Foundational modelling of multi-dimensional time-series data in industrial
systems presents a central trade-off: channel-dependent (CD) models capture
specific cross-variable dynamics but lack robustness and adaptability as model
layers are commonly bound to the data dimensionality of the tackled use-case,
while channel-independent (CI) models offer generality at the cost of modelling
the explicit interactions crucial for system-level predictive regression tasks.
To resolve this, we propose the Causally-Guided Pairwise Transformer (CGPT), a
novel architecture that integrates a known causal graph as an inductive bias.
The core of CGPT is built around a pairwise modeling paradigm, tackling the
CD/CI conflict by decomposing the multidimensional data into pairs. The model
uses channel-agnostic learnable layers where all parameter dimensions are
independent of the number of variables. CGPT enforces a CD information flow at
the pair-level and CI-like generalization across pairs. This approach
disentangles complex system dynamics and results in a highly flexible
architecture that ensures scalability and any-variate adaptability. We validate
CGPT on a suite of synthetic and real-world industrial datasets on long-term
and one-step forecasting tasks designed to simulate common industrial
complexities. Results demonstrate that CGPT significantly outperforms both CI
and CD baselines in predictive accuracy and shows competitive performance with
end-to-end trained CD models while remaining agnostic to the problem
dimensionality.

</details>


### [311] [Contrastive Representations for Temporal Reasoning](https://arxiv.org/abs/2508.13113)
*Alicja Ziarko,Michal Bortkiewicz,Michal Zawalski,Benjamin Eysenbach,Piotr Milos*

Main category: cs.LG

TL;DR: CRTR方法通过负采样方案去除虚假特征，促进时间推理，在复杂时间结构领域表现优异。


<details>
  <summary>Details</summary>
Motivation: 研究是否可以通过同时捕捉感知和时间结构的表示来替代传统AI中的状态表示和搜索规划。

Method: 提出CRTR方法，利用负采样方案去除虚假特征，促进时间推理。

Result: 在Sokoban和Rubik's Cube等复杂时间结构领域表现优异，Rubik's Cube上仅用学习表示即可高效解决任意状态。

Conclusion: CRTR是首个仅依赖学习表示而不依赖外部搜索算法的方法，能高效解决复杂时间推理问题。

Abstract: In classical AI, perception relies on learning state-based representations,
while planning, which can be thought of as temporal reasoning over action
sequences, is typically achieved through search. We study whether such
reasoning can instead emerge from representations that capture both perceptual
and temporal structure. We show that standard temporal contrastive learning,
despite its popularity, often fails to capture temporal structure due to its
reliance on spurious features. To address this, we introduce Combinatorial
Representations for Temporal Reasoning (CRTR), a method that uses a negative
sampling scheme to provably remove these spurious features and facilitate
temporal reasoning. CRTR achieves strong results on domains with complex
temporal structure, such as Sokoban and Rubik's Cube. In particular, for the
Rubik's Cube, CRTR learns representations that generalize across all initial
states and allow it to solve the puzzle using fewer search steps than BestFS,
though with longer solutions. To our knowledge, this is the first method that
efficiently solves arbitrary Cube states using only learned representations,
without relying on an external search algorithm.

</details>


### [312] [Training Machine Learning Models on Human Spatio-temporal Mobility Data: An Experimental Study [Experiment Paper]](https://arxiv.org/abs/2508.13135)
*Yueyang Liu,Lance Kennedy,Ruochen Kong,Joon-Seok Kim,Andreas Züfle*

Main category: cs.LG

TL;DR: 论文探讨了如何利用历史数据训练机器学习模型以预测个体未来几天或几周的完整轨迹，重点研究了模型、参数配置和训练策略，并分析了人类移动模式的统计分布。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注微观轨迹预测，而忽视了宏观移动模式和生活习惯。本文旨在填补这一空白，探索如何更好地预测个体长期轨迹。

Method: 实验分析了多种模型（如LSTM和Transformer）、参数配置和训练策略，结合个体生活模式（如星期几信息）提升预测效果。采用用户语义聚类和分层抽样解决数据偏差问题。

Result: 结果表明，加入语义信息和用户历史数据能显著提升预测准确性；分层抽样和小批量随机梯度优化在数据有限时表现更优。

Conclusion: 通过结合宏观模式和生活习惯信息，并优化数据采样和训练策略，可以有效提升长期人类移动预测的准确性。

Abstract: Individual-level human mobility prediction has emerged as a significant topic
of research with applications in infectious disease monitoring, child, and
elderly care. Existing studies predominantly focus on the microscopic aspects
of human trajectories: such as predicting short-term trajectories or the next
location visited, while offering limited attention to macro-level mobility
patterns and the corresponding life routines. In this paper, we focus on an
underexplored problem in human mobility prediction: determining the best
practices to train a machine learning model using historical data to forecast
an individuals complete trajectory over the next days and weeks. In this
experiment paper, we undertake a comprehensive experimental analysis of diverse
models, parameter configurations, and training strategies, accompanied by an
in-depth examination of the statistical distribution inherent in human mobility
patterns. Our empirical evaluations encompass both Long Short-Term Memory and
Transformer-based architectures, and further investigate how incorporating
individual life patterns can enhance the effectiveness of the prediction. We
show that explicitly including semantic information such as day-of-the-week and
user-specific historical information can help the model better understand
individual patterns of life and improve predictions. Moreover, since the
absence of explicit user information is often missing due to user privacy, we
show that the sampling of users may exacerbate data skewness and result in a
substantial loss in predictive accuracy. To mitigate data imbalance and
preserve diversity, we apply user semantic clustering with stratified sampling
to ensure that the sampled dataset remains representative. Our results further
show that small-batch stochastic gradient optimization improves model
performance, especially when human mobility training data is limited.

</details>


### [313] [MDPO: Overcoming the Training-Inference Divide of Masked Diffusion Language Models](https://arxiv.org/abs/2508.13148)
*Haoyu He,Katrin Renz,Yong Cao,Andreas Geiger*

Main category: cs.LG

TL;DR: 论文提出了一种名为MDPO的方法，通过强化学习解决扩散语言模型在训练与推理阶段的结构不一致问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型在训练和推理阶段存在结构不一致问题，导致性能下降，但此前研究未充分解决这一问题。

Method: 将学习有效去噪轨迹问题建模为序列决策问题，提出MDPO方法，利用马尔可夫性质显式训练模型。

Result: MDPO在相同梯度更新次数下性能优于SOTA方法，且在MATH500和Countdown任务上分别提升9.6%和54.2%。

Conclusion: MDPO和RCR策略的结合展示了解决扩散语言模型训练与推理不一致问题的潜力。

Abstract: Diffusion language models, as a promising alternative to traditional
autoregressive (AR) models, enable faster generation and richer conditioning on
bidirectional context. However, they suffer from a key discrepancy between
training and inference: during inference, MDLMs progressively reveal the
structure of the generated sequence by producing fewer and fewer masked tokens,
whereas this structure is ignored in training as tokens are masked at random.
Although this discrepancy between training and inference can lead to suboptimal
performance, it has been largely overlooked by previous works, leaving closing
this gap between the two stages an open problem. To address this, we frame the
problem of learning effective denoising trajectories as a sequential
decision-making problem and use the resulting framework to apply reinforcement
learning. We propose a novel Masked Diffusion Policy Optimization (MDPO) to
exploit the Markov property diffusion possesses and explicitly train the model
under the same progressive refining schedule used at inference. MDPO matches
the performance of the previous state-of-the-art (SOTA) method with 60x fewer
gradient updates, while achieving average improvements of 9.6% on MATH500 and
54.2% on Countdown over SOTA when trained within the same number of weight
updates. Additionally, we improve the remasking strategy of MDLMs as a plug-in
inference replacement to overcome the limitation that the model cannot refine
tokens flexibly. This simple yet effective training-free strategy, what we
refer to as RCR, consistently improves performance and yields additional gains
when combined with MDPO. Our findings establish great potential for
investigating the discrepancy between pre-training and inference of MDLMs.
Code: https://github.com/autonomousvision/mdpo. Project Page:
https://cli212.github.io/MDPO/.

</details>
