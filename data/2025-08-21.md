<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 73]
- [cs.RO](#cs.RO) [Total: 23]
- [cs.LG](#cs.LG) [Total: 92]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [A comparative study of some wavelet and sampling operators on various features of an image](https://arxiv.org/abs/2508.14043)
*Digvijay Singh,Rahul Shukla,Karunesh Kumar Singh*

Main category: cs.CV

TL;DR: 研究了多种Kantorovich采样算子（SK算子）及其收敛性，分析了局部和全局逼近特性，并通过数值实验验证了不同算子在图像处理中的表现。


<details>
  <summary>Details</summary>
Motivation: 探讨不同SK算子在图像处理中的适用性，验证其逼近定理（FTA）的有效性。

Method: 使用SK、高斯、双边和阈值小波算子，通过误差测量（如MSE、SI等）和数值实验（如Shepp-Logan Phantom）分析性能。

Result: 不同算子在图像不同特征下表现各异，部分算子对特定特征有效，而其他则无效。

Conclusion: SK算子的适用性取决于图像特征，需根据具体需求选择合适的算子。

Abstract: This research includes the study of some positive sampling Kantorovich
operators (SK operators) and their convergence properties. A comprehensive
analysis of both local and global approximation properties is presented using
sampling Kantorovich (SK), Gaussian, Bilateral and the thresholding
wavelet-based operators in the framework of SK-operators. Explicitly, we start
the article by introducing the basic terminology and state the fundamental
theorem of approximation (FTA) by imposing the various required conditions
corresponding to the various defined operators. We measure the error and study
the other mathematical parameters such as the mean square error (MSE), the
speckle index (SI), the speckle suppression index (SSI), the speckle mean
preservation index (SMPI), and the equivalent number of looks (ENL) at various
levels of resolution parameters. The nature of these operators are demonstrated
via an example under ideal conditions in tabulated form at a certain level of
samples. Eventually, another numerical example is illustrated to discuss the
region of interest (ROI) via SI, SSI and SMPI of 2D Shepp-Logan Phantom taken
slice from the 3D image, which gives the justification of the fundamental
theorem of approximation (FTA). At the end of the derivation and illustrations
we observe that the various operators have their own significance while
studying the various features of the image because of the uneven nature of an
image (non-ideal condition). Therefore, to some extent, some operators work
well and some do not for some specific features of the image.

</details>


### [2] [Federated Action Recognition for Smart Worker Assistance Using FastPose](https://arxiv.org/abs/2508.14113)
*Vinit Hegiste,Vidit Goyal,Tatjana Legler,Martin Ruskowski*

Main category: cs.CV

TL;DR: 论文提出了一种基于联邦学习的姿态动作识别框架，在隐私敏感的工业场景中显著提升了跨用户泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在智能制造环境中，实时准确识别工人动作对生产力、安全和人机协作至关重要，但现有方法依赖集中式数据集，不适用于隐私敏感场景。

Method: 使用自定义骨骼数据集和修改的FastPose模型，比较了四种训练范式（集中式、本地、联邦平均和联邦集成学习），并评估了LSTM和Transformer编码器的性能。

Result: 联邦学习的Transformer模型在全局测试集上比集中式训练提升了12.4个百分点，联邦集成学习提升了16.3个百分点；在未见过的客户端上，联邦学习分别提升了52.6和58.3个百分点。

Conclusion: 联邦学习不仅保护隐私，还显著增强了跨用户泛化能力，是异构工业环境中可扩展、隐私感知的动作识别实用解决方案。

Abstract: In smart manufacturing environments, accurate and real-time recognition of
worker actions is essential for productivity, safety, and human-machine
collaboration. While skeleton-based human activity recognition (HAR) offers
robustness to lighting, viewpoint, and background variations, most existing
approaches rely on centralized datasets, which are impractical in
privacy-sensitive industrial scenarios. This paper presents a federated
learning (FL) framework for pose-based HAR using a custom skeletal dataset of
eight industrially relevant upper-body gestures, captured from five
participants and processed using a modified FastPose model. Two temporal
backbones, an LSTM and a Transformer encoder, are trained and evaluated under
four paradigms: centralized, local (per-client), FL with weighted federated
averaging (FedAvg), and federated ensemble learning (FedEnsemble). On the
global test set, the FL Transformer improves over centralized training by +12.4
percentage points, with FedEnsemble delivering a +16.3 percentage points gain.
On an unseen external client, FL and FedEnsemble exceed centralized accuracy by
+52.6 and +58.3 percentage points, respectively. These results demonstrate that
FL not only preserves privacy but also substantially enhances cross-user
generalization, establishing it as a practical solution for scalable,
privacy-aware HAR in heterogeneous industrial settings.

</details>


### [3] [LENS: Learning to Segment Anything with Unified Reinforced Reasoning](https://arxiv.org/abs/2508.14153)
*Lianghui Zhu,Bin Ouyang,Yuxuan Zhang,Tianheng Cheng,Rui Hu,Haocheng Shen,Longjin Ran,Xiaoxin Chen,Li Yu,Wenyu Liu,Xinggang Wang*

Main category: cs.CV

TL;DR: LENS是一个通过强化学习联合优化推理过程和图像分割的框架，显著提升了文本提示分割的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在测试时忽略了显式的思维链推理，限制了模型对未见提示和领域的泛化能力。

Method: 提出LENS框架，利用强化学习统一优化句子、框和分割级别的奖励，生成信息丰富的推理过程并提升分割质量。

Result: 在RefCOCO等基准上平均cIoU达到81.2%，优于GLaMM方法5.6%。

Conclusion: 强化学习驱动的思维链推理为文本提示分割提供了鲁棒的先验，推动了更通用的Segment Anything模型的发展。

Abstract: Text-prompted image segmentation enables fine-grained visual understanding
and is critical for applications such as human-computer interaction and
robotics. However, existing supervised fine-tuning methods typically ignore
explicit chain-of-thought (CoT) reasoning at test time, which limits their
ability to generalize to unseen prompts and domains. To address this issue, we
introduce LENS, a scalable reinforcement-learning framework that jointly
optimizes the reasoning process and segmentation in an end-to-end manner. We
propose unified reinforcement-learning rewards that span sentence-, box-, and
segment-level cues, encouraging the model to generate informative CoT
rationales while refining mask quality. Using a publicly available
3-billion-parameter vision-language model, i.e., Qwen2.5-VL-3B-Instruct, LENS
achieves an average cIoU of 81.2% on the RefCOCO, RefCOCO+, and RefCOCOg
benchmarks, outperforming the strong fine-tuned method, i.e., GLaMM, by up to
5.6%. These results demonstrate that RL-driven CoT reasoning serves as a robust
prior for text-prompted segmentation and offers a practical path toward more
generalizable Segment Anything models. Code is available at
https://github.com/hustvl/LENS.

</details>


### [4] [RynnEC: Bringing MLLMs into Embodied World](https://arxiv.org/abs/2508.14160)
*Ronghao Dang,Yuqian Yuan,Yunxuan Mao,Kehan Li,Jiangpin Liu,Zhikai Wang,Xin Li,Fan Wang,Deli Zhao*

Main category: cs.CV

TL;DR: RynnEC是一种视频多模态大语言模型，专注于具身认知，通过区域编码器和掩码解码器实现灵活的区域级视频交互，性能优越。


<details>
  <summary>Details</summary>
Motivation: 为具身代理提供细粒度感知和精确交互能力，解决标注3D数据集稀缺问题。

Method: 基于通用视觉语言基础模型，结合区域编码器和掩码解码器，提出基于自我中心视频的数据生成流程。

Result: 在物体属性理解、分割和空间推理任务中达到最优性能，并推出RynnEC-Bench评估基准。

Conclusion: RynnEC有望推动具身代理通用认知核心的发展，促进跨任务泛化。

Abstract: We introduce RynnEC, a video multimodal large language model designed for
embodied cognition. Built upon a general-purpose vision-language foundation
model, RynnEC incorporates a region encoder and a mask decoder, enabling
flexible region-level video interaction. Despite its compact architecture,
RynnEC achieves state-of-the-art performance in object property understanding,
object segmentation, and spatial reasoning. Conceptually, it offers a
region-centric video paradigm for the brain of embodied agents, providing
fine-grained perception of the physical world and enabling more precise
interactions. To mitigate the scarcity of annotated 3D datasets, we propose an
egocentric video based pipeline for generating embodied cognition data.
Furthermore, we introduce RynnEC-Bench, a region-centered benchmark for
evaluating embodied cognitive capabilities. We anticipate that RynnEC will
advance the development of general-purpose cognitive cores for embodied agents
and facilitate generalization across diverse embodied tasks. The code, model
checkpoints, and benchmark are available at:
https://github.com/alibaba-damo-academy/RynnEC

</details>


### [5] [Local Scale Equivariance with Latent Deep Equilibrium Canonicalizer](https://arxiv.org/abs/2508.14187)
*Md Ashiqur Rahman,Chiao-An Yang,Michael N. Cheng,Lim Jun Hao,Jeremiah Jiang,Teck-Yian Lim,Raymond A. Yeh*

Main category: cs.CV

TL;DR: 提出了一种深度平衡规范化器（DEC）来提升模型的局部尺度等变性，适用于多种预训练网络。


<details>
  <summary>Details</summary>
Motivation: 解决计算机视觉中物体尺度变化的问题，尤其是同一图像中不同物体的局部尺度变化。

Method: 通过DEC改进模型的局部尺度等变性，可轻松集成到现有网络架构中，并适配预训练模型。

Result: 在ImageNet基准测试中，DEC提升了ViT、DeiT、Swin和BEiT等四种流行预训练网络的性能和局部尺度一致性。

Conclusion: DEC是一种有效处理尺度变化的方法，能显著提升模型性能。

Abstract: Scale variation is a fundamental challenge in computer vision. Objects of the
same class can have different sizes, and their perceived size is further
affected by the distance from the camera. These variations are local to the
objects, i.e., different object sizes may change differently within the same
image. To effectively handle scale variations, we present a deep equilibrium
canonicalizer (DEC) to improve the local scale equivariance of a model. DEC can
be easily incorporated into existing network architectures and can be adapted
to a pre-trained model. Notably, we show that on the competitive ImageNet
benchmark, DEC improves both model performance and local scale consistency
across four popular pre-trained deep-nets, e.g., ViT, DeiT, Swin, and BEiT. Our
code is available at https://github.com/ashiq24/local-scale-equivariance.

</details>


### [6] [CLIPSym: Delving into Symmetry Detection with CLIP](https://arxiv.org/abs/2508.14197)
*Tinghan Yang,Md Ashiqur Rahman,Raymond A. Yeh*

Main category: cs.CV

TL;DR: CLIPSym利用CLIP模型和新型提示技术SAPG，结合旋转等变解码器，显著提升了对称性检测性能。


<details>
  <summary>Details</summary>
Motivation: 探索预训练的CLIP模型是否能通过自然图像描述中的对称线索改进对称性检测。

Method: 结合CLIP的图像和语言编码器，使用基于Transformer和G-卷积的旋转等变解码器，并提出SAPG提示技术。

Result: 在三个标准数据集（DENDI、SDRW、LDRS）上超越当前最优方法。

Conclusion: CLIP的预训练、等变解码器和SAPG技术均对性能提升有显著贡献。

Abstract: Symmetry is one of the most fundamental geometric cues in computer vision,
and detecting it has been an ongoing challenge. With the recent advances in
vision-language models,~i.e., CLIP, we investigate whether a pre-trained CLIP
model can aid symmetry detection by leveraging the additional symmetry cues
found in the natural image descriptions. We propose CLIPSym, which leverages
CLIP's image and language encoders and a rotation-equivariant decoder based on
a hybrid of Transformer and $G$-Convolution to detect rotation and reflection
symmetries. To fully utilize CLIP's language encoder, we have developed a novel
prompting technique called Semantic-Aware Prompt Grouping (SAPG), which
aggregates a diverse set of frequent object-based prompts to better integrate
the semantic cues for symmetry detection. Empirically, we show that CLIPSym
outperforms the current state-of-the-art on three standard symmetry detection
datasets (DENDI, SDRW, and LDRS). Finally, we conduct detailed ablations
verifying the benefits of CLIP's pre-training, the proposed equivariant
decoder, and the SAPG technique. The code is available at
https://github.com/timyoung2333/CLIPSym.

</details>


### [7] [A Survey on Video Anomaly Detection via Deep Learning: Human, Vehicle, and Environment](https://arxiv.org/abs/2508.14203)
*Ghazal Alinezhad Noghre,Armin Danesh Pazho,Hamed Tabkhi*

Main category: cs.CV

TL;DR: 本文是一篇关于视频异常检测（VAD）的综述，系统梳理了不同监督水平和自适应学习方法，并分析了三大应用场景的现状与挑战。


<details>
  <summary>Details</summary>
Motivation: 视频异常检测在计算机视觉中具有重要意义，但领域分散且方法多样，本文旨在整合文献，为社区提供结构化基础。

Method: 通过系统整理文献，分类不同监督水平和自适应学习方法，并分析三大应用场景（人、车、环境）的现状。

Result: 总结了当前方法的贡献与局限性，为理论研究和实际应用提供了参考。

Conclusion: 本文为VAD研究提供了结构化视角，同时指出了开放挑战，推动领域进一步发展。

Abstract: Video Anomaly Detection (VAD) has emerged as a pivotal task in computer
vision, with broad relevance across multiple fields. Recent advances in deep
learning have driven significant progress in this area, yet the field remains
fragmented across domains and learning paradigms. This survey offers a
comprehensive perspective on VAD, systematically organizing the literature
across various supervision levels, as well as adaptive learning methods such as
online, active, and continual learning. We examine the state of VAD across
three major application categories: human-centric, vehicle-centric, and
environment-centric scenarios, each with distinct challenges and design
considerations. In doing so, we identify fundamental contributions and
limitations of current methodologies. By consolidating insights from subfields,
we aim to provide the community with a structured foundation for advancing both
theoretical understanding and real-world applicability of VAD systems. This
survey aims to support researchers by providing a useful reference, while also
drawing attention to the broader set of open challenges in anomaly detection,
including both fundamental research questions and practical obstacles to
real-world deployment.

</details>


### [8] [Accelerating Image Classification with Graph Convolutional Neural Networks using Voronoi Diagrams](https://arxiv.org/abs/2508.14218)
*Mustafa Mohammadi Gharasuie,Luis Rueda*

Main category: cs.CV

TL;DR: 论文提出了一种结合图卷积网络（GCN）和Voronoi图的新型图像分类框架，显著提升了分类精度和预处理效率。


<details>
  <summary>Details</summary>
Motivation: 传统卷积神经网络在处理复杂数据结构和细粒度分类时表现不足，因此研究探索了基于图的表示方法。

Method: 通过将图像像素或区域表示为图的顶点，并利用Delaunay三角剖分简化，结合新型GCN（NVGCN）进行分类。

Result: 在多个基准数据集上，模型在预处理时间和分类精度上显著优于现有方法，尤其在复杂场景和细粒度分类中表现突出。

Conclusion: 该研究为图像分类提供了新思路，并拓展了图学习范式在计算机视觉和非结构化数据中的应用潜力。

Abstract: Recent advances in image classification have been significantly propelled by
the integration of Graph Convolutional Networks (GCNs), offering a novel
paradigm for handling complex data structures. This study introduces an
innovative framework that employs GCNs in conjunction with Voronoi diagrams to
peform image classification, leveraging their exceptional capability to model
relational data. Unlike conventional convolutional neural networks, our
approach utilizes a graph-based representation of images, where pixels or
regions are treated as vertices of a graph, which are then simplified in the
form of the corresponding Delaunay triangulations. Our model yields significant
improvement in pre-processing time and classification accuracy on several
benchmark datasets, surpassing existing state-of-the-art models, especially in
scenarios that involve complex scenes and fine-grained categories. The
experimental results, validated via cross-validation, underscore the potential
of integrating GCNs with Voronoi diagrams in advancing image classification
tasks. This research contributes to the field by introducing a novel approach
to image classification, while opening new avenues for developing graph-based
learning paradigms in other domains of computer vision and non-structured data.
In particular, we have proposed a new version of the GCN in this paper, namely
normalized Voronoi Graph Convolution Network (NVGCN), which is faster than the
regular GCN.

</details>


### [9] [Directed-Tokens: A Robust Multi-Modality Alignment Approach to Large Language-Vision Models](https://arxiv.org/abs/2508.14264)
*Thanh-Dat Truong,Huu-Thien Tran,Tran Thai Son,Bhiksha Raj,Khoa Luu*

Main category: cs.CV

TL;DR: 提出了一种通过解决视觉和文本特征对齐问题来提升大型多模态模型（LMMs）鲁棒性和泛化能力的方法。


<details>
  <summary>Details</summary>
Motivation: 现有LMMs在视觉和文本特征对齐与相关性方面存在局限性，影响了模型的鲁棒性和泛化能力。

Method: 通过引入图像和文本顺序重建任务，结合定向标记方法和Image-to-Response Guided损失函数，优化LMMs的预训练和微调过程。

Result: 在学术任务导向和指令遵循的LMM基准测试中，该方法取得了最先进的性能。

Conclusion: 该方法有效提升了LMMs的推理能力、视觉理解和跨模态对齐能力。

Abstract: Large multimodal models (LMMs) have gained impressive performance due to
their outstanding capability in various understanding tasks. However, these
models still suffer from some fundamental limitations related to robustness and
generalization due to the alignment and correlation between visual and textual
features. In this paper, we introduce a simple but efficient learning mechanism
for improving the robust alignment between visual and textual modalities by
solving shuffling problems. In particular, the proposed approach can improve
reasoning capability, visual understanding, and cross-modality alignment by
introducing two new tasks: reconstructing the image order and the text order
into the LMM's pre-training and fine-tuning phases. In addition, we propose a
new directed-token approach to capture visual and textual knowledge, enabling
the capability to reconstruct the correct order of visual inputs. Then, we
introduce a new Image-to-Response Guided loss to further improve the visual
understanding of the LMM in its responses. The proposed approach consistently
achieves state-of-the-art (SoTA) performance compared with prior LMMs on
academic task-oriented and instruction-following LMM benchmarks.

</details>


### [10] [Effect of Data Augmentation on Conformal Prediction for Diabetic Retinopathy](https://arxiv.org/abs/2508.14266)
*Rizwan Ahamed,Annahita Amireskandari,Joel Palko,Carol Laxson,Binod Bhattarai,Prashnna Gyawali*

Main category: cs.CV

TL;DR: 研究探讨了不同数据增强策略对糖尿病视网膜病变分级中保形预测性能的影响，发现样本混合策略（如Mixup和CutMix）能提高预测准确性和不确定性估计的可靠性。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在高风险任务（如糖尿病视网膜病变分级）中需要可靠的性能，但缺乏稳健的不确定性量化限制了其临床实用性。

Method: 使用DDR数据集，评估了两种架构（ResNet-50和CoaT）在五种数据增强策略下的性能，并分析了其对保形预测指标的影响。

Result: 样本混合策略（Mixup和CutMix）不仅提高了预测准确性，还提供了更可靠和高效的不确定性估计；而CLAHE等方法可能对模型确定性产生负面影响。

Conclusion: 在设计数据增强策略时需考虑下游不确定性量化，以构建真正可信赖的医疗影像AI系统。

Abstract: The clinical deployment of deep learning models for high-stakes tasks such as
diabetic retinopathy (DR) grading requires demonstrable reliability. While
models achieve high accuracy, their clinical utility is limited by a lack of
robust uncertainty quantification. Conformal prediction (CP) offers a
distribution-free framework to generate prediction sets with statistical
guarantees of coverage. However, the interaction between standard training
practices like data augmentation and the validity of these guarantees is not
well understood. In this study, we systematically investigate how different
data augmentation strategies affect the performance of conformal predictors for
DR grading. Using the DDR dataset, we evaluate two backbone architectures --
ResNet-50 and a Co-Scale Conv-Attentional Transformer (CoaT) -- trained under
five augmentation regimes: no augmentation, standard geometric transforms,
CLAHE, Mixup, and CutMix. We analyze the downstream effects on conformal
metrics, including empirical coverage, average prediction set size, and correct
efficiency. Our results demonstrate that sample-mixing strategies like Mixup
and CutMix not only improve predictive accuracy but also yield more reliable
and efficient uncertainty estimates. Conversely, methods like CLAHE can
negatively impact model certainty. These findings highlight the need to
co-design augmentation strategies with downstream uncertainty quantification in
mind to build genuinely trustworthy AI systems for medical imaging.

</details>


### [11] [Tooth-Diffusion: Guided 3D CBCT Synthesis with Fine-Grained Tooth Conditioning](https://arxiv.org/abs/2508.14276)
*Said Djafar Said,Torkan Gholamalizadeh,Mostafa Mehdipour Ghazi*

Main category: cs.CV

TL;DR: 提出了一种基于条件扩散框架的3D牙齿体积生成方法，通过牙齿级二元属性实现精确控制。


<details>
  <summary>Details</summary>
Motivation: 解决牙科CBCT扫描在诊断和治疗计划中生成解剖学上真实且可控的扫描图像的挑战。

Method: 结合小波去噪扩散、FiLM条件和掩码损失函数，专注于相关解剖结构的学习。

Result: 模型在牙齿添加、移除和全牙列合成等任务中表现出高保真度和泛化能力，FID分数低，SSIM值超过0.91。

Conclusion: 该方法为手术规划、患者沟通和牙科AI工作流中的数据增强提供了新机会。

Abstract: Despite the growing importance of dental CBCT scans for diagnosis and
treatment planning, generating anatomically realistic scans with fine-grained
control remains a challenge in medical image synthesis. In this work, we
propose a novel conditional diffusion framework for 3D dental volume
generation, guided by tooth-level binary attributes that allow precise control
over tooth presence and configuration. Our approach integrates wavelet-based
denoising diffusion, FiLM conditioning, and masked loss functions to focus
learning on relevant anatomical structures. We evaluate the model across
diverse tasks, such as tooth addition, removal, and full dentition synthesis,
using both paired and distributional similarity metrics. Results show strong
fidelity and generalization with low FID scores, robust inpainting performance,
and SSIM values above 0.91 even on unseen scans. By enabling realistic,
localized modification of dentition without rescanning, this work opens
opportunities for surgical planning, patient communication, and targeted data
augmentation in dental AI workflows. The codes are available at:
https://github.com/djafar1/tooth-diffusion.

</details>


### [12] [GALA: Guided Attention with Language Alignment for Open Vocabulary Gaussian Splatting](https://arxiv.org/abs/2508.14278)
*Elena Alegret Regalado,Kunyi Li,Sen Wang,Siyun Liang,Michael Niemeyer,Stefano Gasperini,Nassir Navab,Federico Tombari*

Main category: cs.CV

TL;DR: GALA是一个基于3D高斯泼溅的新型框架，用于开放词汇的3D场景理解，通过自监督对比学习提取场景特定的3D实例特征，并引入跨注意力模块支持2D和3D查询。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以从2D图像中捕捉细粒度、语言感知的3D表示，GALA旨在解决这一问题。

Method: GALA通过自监督对比学习提取3D实例特征，并引入跨注意力模块和可学习代码本，支持开放词汇查询。

Result: 在真实数据集上的实验表明，GALA在2D和3D开放词汇任务中表现优异。

Conclusion: GALA通过创新的跨注意力模块和代码本设计，实现了高效的开放词汇3D场景理解。

Abstract: 3D scene reconstruction and understanding have gained increasing popularity,
yet existing methods still struggle to capture fine-grained, language-aware 3D
representations from 2D images. In this paper, we present GALA, a novel
framework for open-vocabulary 3D scene understanding with 3D Gaussian Splatting
(3DGS). GALA distills a scene-specific 3D instance feature field via
self-supervised contrastive learning. To extend to generalized language feature
fields, we introduce the core contribution of GALA, a cross-attention module
with two learnable codebooks that encode view-independent semantic embeddings.
This design not only ensures intra-instance feature similarity but also
supports seamless 2D and 3D open-vocabulary queries. It reduces memory
consumption by avoiding per-Gaussian high-dimensional feature learning.
Extensive experiments on real-world datasets demonstrate GALA's remarkable
open-vocabulary performance on both 2D and 3D.

</details>


### [13] [Multi-Rationale Explainable Object Recognition via Contrastive Conditional Inference](https://arxiv.org/abs/2508.14280)
*Ali Rasekh,Sepehr Kazemi Ranjbar,Simon Gottschalk*

Main category: cs.CV

TL;DR: 论文提出了一种多理由可解释物体识别基准和对比条件推理框架，解决了现有方法在理由多样性和条件推理上的不足，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在可解释物体识别中依赖提示条件，但受限于CLIP文本编码器，且理由单一、噪声多，无法捕捉多样特征。

Method: 提出对比条件推理（CCI）框架，显式建模图像嵌入、类别标签和理由的概率关系，无需训练即可有效推理。

Result: 在多理由基准上实现了最先进的性能，包括零样本表现，同时提升了分类准确性和理由质量。

Conclusion: 该工作为可解释物体识别提供了更完整的评估框架和基准，推动了未来模型的发展。

Abstract: Explainable object recognition using vision-language models such as CLIP
involves predicting accurate category labels supported by rationales that
justify the decision-making process. Existing methods typically rely on
prompt-based conditioning, which suffers from limitations in CLIP's text
encoder and provides weak conditioning on explanatory structures. Additionally,
prior datasets are often restricted to single, and frequently noisy, rationales
that fail to capture the full diversity of discriminative image features. In
this work, we introduce a multi-rationale explainable object recognition
benchmark comprising datasets in which each image is annotated with multiple
ground-truth rationales, along with evaluation metrics designed to offer a more
comprehensive representation of the task. To overcome the limitations of
previous approaches, we propose a contrastive conditional inference (CCI)
framework that explicitly models the probabilistic relationships among image
embeddings, category labels, and rationales. Without requiring any training,
our framework enables more effective conditioning on rationales to predict
accurate object categories. Our approach achieves state-of-the-art results on
the multi-rationale explainable object recognition benchmark, including strong
zero-shot performance, and sets a new standard for both classification accuracy
and rationale quality. Together with the benchmark, this work provides a more
complete framework for evaluating future models in explainable object
recognition. The code will be made available online.

</details>


### [14] [OccluNet: Spatio-Temporal Deep Learning for Occlusion Detection on DSA](https://arxiv.org/abs/2508.14286)
*Anushka A. Kore,Frank G. te Nijenhuis,Matthijs van der Sluijs,Wim van Zwam,Charles Majoie,Geert Lycklama à Nijeholt,Danny Ruijters,Frans Vos,Sandra Cornelissen,Ruisheng Su,Theo van Walsum*

Main category: cs.CV

TL;DR: OccluNet是一种结合YOLOX和时空注意力机制的深度学习模型，用于自动检测DSA序列中的血管闭塞，显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 急性缺血性卒中（AIS）中，血管闭塞的准确检测至关重要，但DSA序列的复杂性和时间限制增加了诊断难度。

Method: OccluNet整合了YOLOX目标检测器和基于Transformer的时空注意力机制，探索了纯时间注意力和分时空注意力两种变体。

Result: 在MR CLEAN Registry数据集上，OccluNet的精确率和召回率分别为89.02%和74.87%，显著优于基线模型。

Conclusion: OccluNet能够捕捉时间一致性特征，为AIS中的血管闭塞检测提供了高效自动化解决方案。

Abstract: Accurate detection of vascular occlusions during endovascular thrombectomy
(EVT) is critical in acute ischemic stroke (AIS). Interpretation of digital
subtraction angiography (DSA) sequences poses challenges due to anatomical
complexity and time constraints. This work proposes OccluNet, a spatio-temporal
deep learning model that integrates YOLOX, a single-stage object detector, with
transformer-based temporal attention mechanisms to automate occlusion detection
in DSA sequences. We compared OccluNet with a YOLOv11 baseline trained on
either individual DSA frames or minimum intensity projections. Two
spatio-temporal variants were explored for OccluNet: pure temporal attention
and divided space-time attention. Evaluation on DSA images from the MR CLEAN
Registry revealed the model's capability to capture temporally consistent
features, achieving precision and recall of 89.02% and 74.87%, respectively.
OccluNet significantly outperformed the baseline models, and both attention
variants attained similar performance. Source code is available at
https://github.com/anushka-kore/OccluNet.git

</details>


### [15] [Pixels to Play: A Foundation Model for 3D Gameplay](https://arxiv.org/abs/2508.14295)
*Yuguang Yue,Chris Green,Samuel Hunt,Irakli Salia,Wenzhe Shi,Jonathan J Hunt*

Main category: cs.CV

TL;DR: P2P0.1是一个通过像素流学习玩多种3D游戏的基础模型，模仿人类行为，适用于AI队友、NPC等场景。


<details>
  <summary>Details</summary>
Motivation: 满足AI队友、可控NPC等新兴需求，需依赖像素流并泛化到新游戏。

Method: 通过行为克隆训练，结合标记演示和未标记视频，使用解码器Transformer处理动作。

Result: 在Roblox和MS-DOS游戏中表现良好，支持无标签数据。

Conclusion: 需进一步扩展和评估以实现专家级、文本控制。

Abstract: We introduce Pixels2Play-0.1 (P2P0.1), a foundation model that learns to play
a wide range of 3D video games with recognizable human-like behavior. Motivated
by emerging consumer and developer use cases - AI teammates, controllable NPCs,
personalized live-streamers, assistive testers - we argue that an agent must
rely on the same pixel stream available to players and generalize to new titles
with minimal game-specific engineering. P2P0.1 is trained end-to-end with
behavior cloning: labeled demonstrations collected from instrumented human
game-play are complemented by unlabeled public videos, to which we impute
actions via an inverse-dynamics model. A decoder-only transformer with
auto-regressive action output handles the large action space while remaining
latency-friendly on a single consumer GPU. We report qualitative results
showing competent play across simple Roblox and classic MS-DOS titles,
ablations on unlabeled data, and outline the scaling and evaluation steps
required to reach expert-level, text-conditioned control.

</details>


### [16] [MoVieDrive: Multi-Modal Multi-View Urban Scene Video Generation](https://arxiv.org/abs/2508.14327)
*Guile Wu,David Huang,Dongfeng Bai,Bingbing Liu*

Main category: cs.CV

TL;DR: 提出了一种多模态多视角视频生成方法，用于自动驾驶场景合成，通过统一的扩散变换器模型实现高保真和可控性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注RGB视频生成，缺乏多模态支持，而多模态数据（如深度图和语义图）对自动驾驶场景理解至关重要。

Method: 构建了统一的扩散变换器模型，包含模态共享和模态特定组件，利用多样化条件输入编码可控场景结构和内容线索。

Result: 在nuScenes数据集上实验表明，该方法能生成高保真、可控的多模态多视角视频，超越现有方法。

Conclusion: 该方法在统一框架下实现了多模态多视角视频生成，为自动驾驶场景合成提供了更全面的解决方案。

Abstract: Video generation has recently shown superiority in urban scene synthesis for
autonomous driving. Existing video generation approaches to autonomous driving
primarily focus on RGB video generation and lack the ability to support
multi-modal video generation. However, multi-modal data, such as depth maps and
semantic maps, are crucial for holistic urban scene understanding in autonomous
driving. Although it is feasible to use multiple models to generate different
modalities, this increases the difficulty of model deployment and does not
leverage complementary cues for multi-modal data generation. To address this
problem, in this work, we propose a novel multi-modal multi-view video
generation approach to autonomous driving. Specifically, we construct a unified
diffusion transformer model composed of modal-shared components and
modal-specific components. Then, we leverage diverse conditioning inputs to
encode controllable scene structure and content cues into the unified diffusion
model for multi-modal multi-view video generation. In this way, our approach is
capable of generating multi-modal multi-view driving scene videos in a unified
framework. Our experiments on the challenging real-world autonomous driving
dataset, nuScenes, show that our approach can generate multi-modal multi-view
urban scene videos with high fidelity and controllability, surpassing the
state-of-the-art methods.

</details>


### [17] [Inter-Class Relational Loss for Small Object Detection: A Case Study on License Plates](https://arxiv.org/abs/2508.14343)
*Dian Ning,Dong Seog Han*

Main category: cs.CV

TL;DR: 提出了一种基于类间关系的损失函数（ICR），用于解决小物体检测中梯度更新不足的问题，并通过车牌检测案例验证其有效性。


<details>
  <summary>Details</summary>
Motivation: IoU-based损失函数在小物体检测中梯度更新不足，导致收敛效果差。

Method: 利用类间空间关系（如车牌与车的关联）设计ICR损失函数，通过惩罚机制增强小物体梯度更新。

Result: 在YOLOv12-T和UAV-DETR上分别提升10.3%和1.6%的mAP。

Conclusion: ICR损失函数能有效提升小物体检测性能，且易于集成到现有IoU-based损失中。

Abstract: In one-stage multi-object detection tasks, various intersection over union
(IoU)-based solutions aim at smooth and stable convergence near the targets
during training. However, IoU-based losses fail to correctly update the
gradient of small objects due to an extremely flat gradient. During the update
of multiple objects, the learning of small objects' gradients suffers more
because of insufficient gradient updates. Therefore, we propose an inter-class
relational loss to efficiently update the gradient of small objects while not
sacrificing the learning efficiency of other objects based on the simple fact
that an object has a spatial relationship to another object (e.g., a car plate
is attached to a car in a similar position). When the predicted car plate's
bounding box is not within its car, a loss punishment is added to guide the
learning, which is inversely proportional to the overlapped area of the car's
and predicted car plate's bounding box. By leveraging the spatial relationship
at the inter-class level, the loss guides small object predictions using larger
objects and enhances latent information in deeper feature maps. In this paper,
we present twofold contributions using license plate detection as a case study:
(1) a new small vehicle multi-license plate dataset (SVMLP), featuring diverse
real-world scenarios with high-quality annotations; and (2) a novel inter-class
relational loss function designed to promote effective detection performance.
We highlight the proposed ICR loss penalty can be easily added to existing
IoU-based losses and enhance the performance. These contributions improve the
standard mean Average Precision (mAP) metric, achieving gains of 10.3% and 1.6%
in mAP$^{\text{test}}_{50}$ for YOLOv12-T and UAV-DETR, respectively, without
any additional hyperparameter tuning. Code and dataset will be available soon.

</details>


### [18] [HandCraft: Dynamic Sign Generation for Synthetic Data Augmentation](https://arxiv.org/abs/2508.14345)
*Gaston Gustavo Rios*

Main category: cs.CV

TL;DR: 提出了一种基于CMLPe的轻量级手语生成模型，结合合成数据预训练，显著提升了手语识别性能。


<details>
  <summary>Details</summary>
Motivation: 解决手语识别（SLR）中因训练数据不足导致的性能限制问题。

Method: 使用CMLPe构建轻量级手语生成模型，并采用合成数据预训练方法。

Result: 在LSFB和DiSPLaY数据集上实现了新的最佳识别准确率。

Conclusion: 合成数据预训练在某些情况下优于传统数据增强方法，且两者结合效果更佳，为SLR提供了高效的计算方法。

Abstract: Sign Language Recognition (SLR) models face significant performance
limitations due to insufficient training data availability. In this article, we
address the challenge of limited data in SLR by introducing a novel and
lightweight sign generation model based on CMLPe. This model, coupled with a
synthetic data pretraining approach, consistently improves recognition
accuracy, establishing new state-of-the-art results for the LSFB and DiSPLaY
datasets using our Mamba-SL and Transformer-SL classifiers. Our findings reveal
that synthetic data pretraining outperforms traditional augmentation methods in
some cases and yields complementary benefits when implemented alongside them.
Our approach democratizes sign generation and synthetic data pretraining for
SLR by providing computationally efficient methods that achieve significant
performance improvements across diverse datasets.

</details>


### [19] [Deep Learning for Taxol Exposure Analysis: A New Cell Image Dataset and Attention-Based Baseline Model](https://arxiv.org/abs/2508.14349)
*Sean Fletcher,Gabby Scott,Douglas Currie,Xin Zhang,Yuqi Song,Bruce MacLeod*

Main category: cs.CV

TL;DR: 提出了一种基于深度学习的Taxol浓度分类方法，并发布了一个新的显微镜图像数据集。


<details>
  <summary>Details</summary>
Motivation: 现有Taxol检测方法设备要求高、耗时长，不适合高通量或实时分析，缺乏公开数据集。

Method: 结合ResNet-50、注意力模块和KNN分类器，提出ResAttention-KNN模型。

Result: 模型增强了鲁棒性和可解释性，数据集和实现代码已公开。

Conclusion: 为基于视觉的生物医学分析提供了基准和工具，支持未来研究。

Abstract: Monitoring the effects of the chemotherapeutic agent Taxol at the cellular
level is critical for both clinical evaluation and biomedical research.
However, existing detection methods require specialized equipment, skilled
personnel, and extensive sample preparation, making them expensive,
labor-intensive, and unsuitable for high-throughput or real-time analysis. Deep
learning approaches have shown great promise in medical and biological image
analysis, enabling automated, high-throughput assessment of cellular
morphology. Yet, no publicly available dataset currently exists for automated
morphological analysis of cellular responses to Taxol exposure. To address this
gap, we introduce a new microscopy image dataset capturing C6 glioma cells
treated with varying concentrations of Taxol. To provide an effective solution
for Taxol concentration classification and establish a benchmark for future
studies on this dataset, we propose a baseline model named ResAttention-KNN,
which combines a ResNet-50 with Convolutional Block Attention Modules and uses
a k-Nearest Neighbors classifier in the learned embedding space. This model
integrates attention-based refinement and non-parametric classification to
enhance robustness and interpretability. Both the dataset and implementation
are publicly released to support reproducibility and facilitate future research
in vision-based biomedical analysis.

</details>


### [20] [Learning Point Cloud Representations with Pose Continuity for Depth-Based Category-Level 6D Object Pose Estimation](https://arxiv.org/abs/2508.14358)
*Zhujun Li,Shuo Zhang,Ioannis Stamos*

Main category: cs.CV

TL;DR: HRC-Pose是一种基于深度学习的类别级物体姿态估计方法，通过对比学习捕捉姿态连续性，提升预测一致性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅依赖6D姿态作为监督信号，忽略了姿态的连续性，导致预测不一致和泛化能力差。

Method: 提出HRC-Pose框架，利用对比学习学习点云表示，分离旋转和平移分量，并设计多任务多类别的对比学习策略。

Result: 在REAL275和CAMERA25基准测试中表现优于现有深度学习方法，且实时运行。

Conclusion: HRC-Pose通过捕捉姿态连续性，显著提升了类别级物体姿态估计的性能和实用性。

Abstract: Category-level object pose estimation aims to predict the 6D pose and 3D size
of objects within given categories. Existing approaches for this task rely
solely on 6D poses as supervisory signals without explicitly capturing the
intrinsic continuity of poses, leading to inconsistencies in predictions and
reduced generalization to unseen poses. To address this limitation, we propose
HRC-Pose, a novel depth-only framework for category-level object pose
estimation, which leverages contrastive learning to learn point cloud
representations that preserve the continuity of 6D poses. HRC-Pose decouples
object pose into rotation and translation components, which are separately
encoded and leveraged throughout the network. Specifically, we introduce a
contrastive learning strategy for multi-task, multi-category scenarios based on
our 6D pose-aware hierarchical ranking scheme, which contrasts point clouds
from multiple categories by considering rotational and translational
differences as well as categorical information. We further design pose
estimation modules that separately process the learned rotation-aware and
translation-aware embeddings. Our experiments demonstrate that HRC-Pose
successfully learns continuous feature spaces. Results on REAL275 and CAMERA25
benchmarks show that our method consistently outperforms existing depth-only
state-of-the-art methods and runs in real-time, demonstrating its effectiveness
and potential for real-world applications. Our code is at
https://github.com/zhujunli1993/HRC-Pose.

</details>


### [21] [Taming Transformer for Emotion-Controllable Talking Face Generation](https://arxiv.org/abs/2508.14359)
*Ziqi Zhang,Cheng Deng*

Main category: cs.CV

TL;DR: 提出了一种新方法，用于情感可控的说话人脸生成，通过预训练策略和情感锚表示实现。


<details>
  <summary>Details</summary>
Motivation: 解决情感可控说话人脸生成中的多模态关系建模和身份保持问题。

Method: 使用预训练策略分离音频，量化视频为视觉标记，引入情感锚表示，并用自回归变换器建模全局分布。

Result: 在MEAD数据集上实验，定性和定量结果均优于现有方法。

Conclusion: 方法有效解决了情感可控说话人脸生成的挑战。

Abstract: Talking face generation is a novel and challenging generation task, aiming at
synthesizing a vivid speaking-face video given a specific audio. To fulfill
emotion-controllable talking face generation, current methods need to overcome
two challenges: One is how to effectively model the multimodal relationship
related to the specific emotion, and the other is how to leverage this
relationship to synthesize identity preserving emotional videos. In this paper,
we propose a novel method to tackle the emotion-controllable talking face
generation task discretely. Specifically, we employ two pre-training strategies
to disentangle audio into independent components and quantize videos into
combinations of visual tokens. Subsequently, we propose the emotion-anchor (EA)
representation that integrates the emotional information into visual tokens.
Finally, we introduce an autoregressive transformer to model the global
distribution of the visual tokens under the given conditions and further
predict the index sequence for synthesizing the manipulated videos. We conduct
experiments on the MEAD dataset that controls the emotion of videos conditioned
on multiple emotional audios. Extensive experiments demonstrate the
superiorities of our method both qualitatively and quantitatively.

</details>


### [22] [FastTracker: Real-Time and Accurate Visual Tracking](https://arxiv.org/abs/2508.14370)
*Hamidreza Hashempoor,Yu Dong Hwang*

Main category: cs.CV

TL;DR: 提出了一种通用的多目标跟踪框架，特别适用于复杂交通场景中的车辆跟踪，结合了遮挡感知重识别和道路结构感知轨迹优化，并在新数据集和公共基准上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统多目标跟踪系统主要针对行人跟踪，对其他物体类别的泛化能力有限，因此需要一种更通用的跟踪方法。

Method: 方法包含两部分：遮挡感知重识别机制和道路结构感知轨迹优化策略，利用语义场景先验（如车道方向、人行道等）提升轨迹连续性。

Result: 在新数据集和公共基准（MOT17和MOT20）上表现优异，HOTA分数分别为66.4和65.7。

Conclusion: 该框架不仅适用于多类物体跟踪，还在传统基准上表现强劲，展示了其通用性和有效性。

Abstract: Conventional multi-object tracking (MOT) systems are predominantly designed
for pedestrian tracking and often exhibit limited generalization to other
object categories. This paper presents a generalized tracking framework capable
of handling multiple object types, with a particular emphasis on vehicle
tracking in complex traffic scenes. The proposed method incorporates two key
components: (1) an occlusion-aware re-identification mechanism that enhances
identity preservation for heavily occluded objects, and (2) a
road-structure-aware tracklet refinement strategy that utilizes semantic scene
priors such as lane directions, crosswalks, and road boundaries to improve
trajectory continuity and accuracy. In addition, we introduce a new benchmark
dataset comprising diverse vehicle classes with frame-level tracking
annotations, specifically curated to support evaluation of vehicle-focused
tracking methods. Extensive experimental results demonstrate that the proposed
approach achieves robust performance on both the newly introduced dataset and
several public benchmarks, highlighting its effectiveness in general-purpose
object tracking. While our framework is designed for generalized multi-class
tracking, it also achieves strong performance on conventional benchmarks, with
HOTA scores of 66.4 on MOT17 and 65.7 on MOT20 test sets. Code and Benchmark
are available: github.com/Hamidreza-Hashempoor/FastTracker,
huggingface.co/datasets/Hamidreza-Hashemp/FastTracker-Benchmark.

</details>


### [23] [TCFNet: Bidirectional face-bone transformation via a Transformer-based coarse-to-fine point movement network](https://arxiv.org/abs/2508.14373)
*Runshi Zhang,Bimeng Jie,Yang He,Junchen Wang*

Main category: cs.CV

TL;DR: TCFNet是一种基于Transformer的粗到细点移动网络，用于密集面部骨骼点云转换，解决了传统方法和现有深度学习方法在计算时间、精度和适用性上的不足。


<details>
  <summary>Details</summary>
Motivation: 传统生物力学模拟方法计算时间长、数据处理复杂且精度低，现有深度学习方法无法处理大规模点云且预处理复杂。

Method: 提出TCFNet，结合Transformer网络和局部信息聚合网络（LIA-Net），分阶段学习点云转换，并引入辅助损失函数利用专家知识。

Result: 在数据集上，TCFNet在评估指标和可视化结果上优于现有方法。

Conclusion: TCFNet通过结合全局和局部特征，显著提升了点云转换的精度和效率，具有广泛的应用潜力。

Abstract: Computer-aided surgical simulation is a critical component of orthognathic
surgical planning, where accurately simulating face-bone shape transformations
is significant. The traditional biomechanical simulation methods are limited by
their computational time consumption levels, labor-intensive data processing
strategies and low accuracy. Recently, deep learning-based simulation methods
have been proposed to view this problem as a point-to-point transformation
between skeletal and facial point clouds. However, these approaches cannot
process large-scale points, have limited receptive fields that lead to noisy
points, and employ complex preprocessing and postprocessing operations based on
registration. These shortcomings limit the performance and widespread
applicability of such methods. Therefore, we propose a Transformer-based
coarse-to-fine point movement network (TCFNet) to learn unique, complicated
correspondences at the patch and point levels for dense face-bone point cloud
transformations. This end-to-end framework adopts a Transformer-based network
and a local information aggregation network (LIA-Net) in the first and second
stages, respectively, which reinforce each other to generate precise point
movement paths. LIA-Net can effectively compensate for the neighborhood
precision loss of the Transformer-based network by modeling local geometric
structures (edges, orientations and relative position features). The previous
global features are employed to guide the local displacement using a gated
recurrent unit. Inspired by deformable medical image registration, we propose
an auxiliary loss that can utilize expert knowledge for reconstructing critical
organs.Compared with the existing state-of-the-art (SOTA) methods on gathered
datasets, TCFNet achieves outstanding evaluation metrics and visualization
results. The code is available at https://github.com/Runshi-Zhang/TCFNet.

</details>


### [24] [Making Pose Representations More Expressive and Disentangled via Residual Vector Quantization](https://arxiv.org/abs/2508.14561)
*Sukhyun Jeong,Hong-Gi Shin,Yong-Hoon Choi*

Main category: cs.CV

TL;DR: 提出了一种通过残差向量量化（RVQ）增强姿势代码的方法，以捕捉细粒度运动细节，提升文本到运动的生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于姿势代码的方法无法捕捉细粒度运动细节，限制了表达的丰富性。

Method: 结合姿势代码和连续运动特征，使用残差向量量化（RVQ）增强潜在表示。

Result: 在HumanML3D数据集上，FID从0.041降至0.015，Top-1 R-Precision从0.508提升至0.510。

Conclusion: 该方法在保持姿势代码可解释性和可操作性的同时，显著提升了运动生成的细节表现和可控性。

Abstract: Recent progress in text-to-motion has advanced both 3D human motion
generation and text-based motion control. Controllable motion generation
(CoMo), which enables intuitive control, typically relies on pose code
representations, but discrete pose codes alone cannot capture fine-grained
motion details, limiting expressiveness. To overcome this, we propose a method
that augments pose code-based latent representations with continuous motion
features using residual vector quantization (RVQ). This design preserves the
interpretability and manipulability of pose codes while effectively capturing
subtle motion characteristics such as high-frequency details. Experiments on
the HumanML3D dataset show that our model reduces Frechet inception distance
(FID) from 0.041 to 0.015 and improves Top-1 R-Precision from 0.508 to 0.510.
Qualitative analysis of pairwise direction similarity between pose codes
further confirms the model's controllability for motion editing.

</details>


### [25] [QuadINR: Hardware-Efficient Implicit Neural Representations Through Quadratic Activation](https://arxiv.org/abs/2508.14374)
*Wenyong Zhou,Boyu Li,Jiachen Ren,Taiqiang Wu,Zhilin Ai,Zhengwu Liu,Ngai Wong*

Main category: cs.CV

TL;DR: QuadINR是一种硬件高效的隐式神经表示方法，通过分段二次激活函数减少硬件开销，同时提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法因复杂激活函数导致的硬件开销大问题。

Method: 采用分段二次激活函数，结合NTK分析，设计统一的N级流水线框架。

Result: 在FPGA和ASIC上实现，PSNR提升2.06dB，硬件资源减少97%，功耗降低6.14mW。

Conclusion: QuadINR在性能和硬件效率上均优于现有方法。

Abstract: Implicit Neural Representations (INRs) encode discrete signals continuously
while addressing spectral bias through activation functions (AFs). Previous
approaches mitigate this bias by employing complex AFs, which often incur
significant hardware overhead. To tackle this challenge, we introduce QuadINR,
a hardware-efficient INR that utilizes piecewise quadratic AFs to achieve
superior performance with dramatic reductions in hardware consumption. The
quadratic functions encompass rich harmonic content in their Fourier series,
delivering enhanced expressivity for high-frequency signals, as verified
through Neural Tangent Kernel (NTK) analysis. We develop a unified $N$-stage
pipeline framework that facilitates efficient hardware implementation of
various AFs in INRs. We demonstrate FPGA implementations on the VCU128 platform
and an ASIC implementation in a 28nm process. Experiments across images and
videos show that QuadINR achieves up to 2.06dB PSNR improvement over prior
work, with an area of only 1914$\mu$m$^2$ and a dynamic power of 6.14mW,
reducing resource and power consumption by up to 97\% and improving latency by
up to 93\% vs existing baselines.

</details>


### [26] [Fusing Monocular RGB Images with AIS Data to Create a 6D Pose Estimation Dataset for Marine Vessels](https://arxiv.org/abs/2508.14767)
*Fabian Holst,Emre Gülsoylu,Simone Frintrop*

Main category: cs.CV

TL;DR: 论文提出了一种融合单目RGB图像与AIS数据生成6D姿态估计数据集的新方法，解决了AIS数据可靠性问题，并公开了BONK-pose数据集。


<details>
  <summary>Details</summary>
Motivation: AIS数据存在设备可靠性、数据操纵和传输延迟等问题，纯依赖AIS获取位置信息受限。

Method: 结合单目RGB图像（使用YOLOX-X检测）与AIS数据，生成3D边界框表示6D姿态，比较了PnP和单应性变换方法。

Result: PnP方法投影误差显著低于单应性方法，YOLOX-X模型的mAP为0.80（IoU=0.5）。BONK-pose数据集包含3753张图像。

Conclusion: 该方法无需人工标注即可生成6D姿态数据集，公开的BONK-pose数据集可用于姿态估计网络的训练与评估。

Abstract: The paper presents a novel technique for creating a 6D pose estimation
dataset for marine vessels by fusing monocular RGB images with Automatic
Identification System (AIS) data. The proposed technique addresses the
limitations of relying purely on AIS for location information, caused by issues
like equipment reliability, data manipulation, and transmission delays. By
combining vessel detections from monocular RGB images, obtained using an object
detection network (YOLOX-X), with AIS messages, the technique generates 3D
bounding boxes that represent the vessels' 6D poses, i.e. spatial and
rotational dimensions. The paper evaluates different object detection models to
locate vessels in image space. We also compare two transformation methods
(homography and Perspective-n-Point) for aligning AIS data with image
coordinates. The results of our work demonstrate that the Perspective-n-Point
(PnP) method achieves a significantly lower projection error compared to
homography-based approaches used before, and the YOLOX-X model achieves a mean
Average Precision (mAP) of 0.80 at an Intersection over Union (IoU) threshold
of 0.5 for relevant vessel classes. We show indication that our approach allows
the creation of a 6D pose estimation dataset without needing manual annotation.
Additionally, we introduce the Boats on Nordelbe Kehrwieder (BONK-pose), a
publicly available dataset comprising 3753 images with 3D bounding box
annotations for pose estimation, created by our data fusion approach. This
dataset can be used for training and evaluating 6D pose estimation networks. In
addition we introduce a set of 1000 images with 2D bounding box annotations for
ship detection from the same scene.

</details>


### [27] [Img2ST-Net: Efficient High-Resolution Spatial Omics Prediction from Whole Slide Histology Images via Fully Convolutional Image-to-Image Learning](https://arxiv.org/abs/2508.14393)
*Junchao Zhu,Ruining Deng,Junlin Guo,Tianyuan Yao,Juming Xiong,Chongyu Qu,Mengmeng Yin,Yu Wang,Shilin Zhao,Haichun Yang,Daguang Xu,Yucheng Tang,Yuankai Huo*

Main category: cs.CV

TL;DR: Img2ST-Net提出了一种高效并行的高分辨率空间转录组（ST）预测框架，解决了传统方法在计算和建模上的挑战。


<details>
  <summary>Details</summary>
Motivation: 高分辨率ST数据的获取成本高且耗时，传统方法在8um或更细分辨率下效率低下且不稳定。

Method: 采用全卷积架构生成密集的HD基因表达图，将任务重新定义为超内容图像生成问题。

Result: Img2ST-Net提高了计算效率并保留了空间组学数据的空间组织特性，同时引入了SSIM-ST评估指标。

Conclusion: Img2ST-Net为高效、准确的大规模ST推断提供了理论基础，为下一代ST建模奠定了基础。

Abstract: Recent advances in multi-modal AI have demonstrated promising potential for
generating the currently expensive spatial transcriptomics (ST) data directly
from routine histology images, offering a means to reduce the high cost and
time-intensive nature of ST data acquisition. However, the increasing
resolution of ST, particularly with platforms such as Visium HD achieving 8um
or finer, introduces significant computational and modeling challenges.
Conventional spot-by-spot sequential regression frameworks become inefficient
and unstable at this scale, while the inherent extreme sparsity and low
expression levels of high-resolution ST further complicate both prediction and
evaluation. To address these limitations, we propose Img2ST-Net, a novel
histology-to-ST generation framework for efficient and parallel high-resolution
ST prediction. Unlike conventional spot-by-spot inference methods, Img2ST-Net
employs a fully convolutional architecture to generate dense, HD gene
expression maps in a parallelized manner. By modeling HD ST data as super-pixel
representations, the task is reformulated from image-to-omics inference into a
super-content image generation problem with hundreds or thousands of output
channels. This design not only improves computational efficiency but also
better preserves the spatial organization intrinsic to spatial omics data. To
enhance robustness under sparse expression patterns, we further introduce
SSIM-ST, a structural-similarity-based evaluation metric tailored for
high-resolution ST analysis. We present a scalable, biologically coherent
framework for high-resolution ST prediction. Img2ST-Net offers a principled
solution for efficient and accurate ST inference at scale. Our contributions
lay the groundwork for next-generation ST modeling that is robust and
resolution-aware. The source code has been made publicly available at
https://github.com/hrlblab/Img2ST-Net.

</details>


### [28] [Virtual Community: An Open World for Humans, Robots, and Society](https://arxiv.org/abs/2508.14893)
*Qinhong Zhou,Hongxin Zhang,Xiangye Lin,Zheyuan Zhang,Yutian Chen,Wenjun Liu,Zunzhe Zhang,Sunli Chen,Lixing Fang,Qiushi Lyu,Xinyu Sun,Jincheng Yang,Zeyuan Wang,Bao Chi Dang,Zhehuan Chen,Daksha Ladia,Jiageng Liu,Chuang Gan*

Main category: cs.CV

TL;DR: Virtual Community是一个开放世界平台，用于研究人类与机器人共存的社交智能，提供多智能体物理模拟器和社区生成工具。


<details>
  <summary>Details</summary>
Motivation: 探索AI和机器人快速发展下人类与机器人共存的未来，研究社交智能和大规模共存问题。

Method: 开发Virtual Community平台，包含开源多智能体物理模拟器和真实世界对齐的社区生成管道，提出两个新挑战任务。

Result: 评估了多个基线模型，展示了在开放世界任务规划与协作控制中的挑战。

Conclusion: Virtual Community有望推动开放世界中人类与机器人共存的研究。

Abstract: The rapid progress in AI and Robotics may lead to a profound societal
transformation, as humans and robots begin to coexist within shared
communities, introducing both opportunities and challenges. To explore this
future, we present Virtual Community-an open-world platform for humans, robots,
and society-built on a universal physics engine and grounded in real-world 3D
scenes. With Virtual Community, we aim to study embodied social intelligence at
scale: 1) How robots can intelligently cooperate or compete; 2) How humans
develop social relations and build community; 3) More importantly, how
intelligent robots and humans can co-exist in an open world. To support these,
Virtual Community features: 1) An open-source multi-agent physics simulator
that supports robots, humans, and their interactions within a society; 2) A
large-scale, real-world aligned community generation pipeline, including vast
outdoor space, diverse indoor scenes, and a community of grounded agents with
rich characters and appearances. Leveraging Virtual Community, we propose two
novel challenges. The Community Planning Challenge evaluates multi-agent
reasoning and planning ability in open-world settings, such as cooperating to
help agents with daily activities and efficiently connecting other agents. The
Community Robot Challenge requires multiple heterogeneous robots to collaborate
in solving complex open-world tasks. We evaluate various baselines on these
tasks and demonstrate the challenges in both high-level open-world task
planning and low-level cooperation controls. We hope that Virtual Community
will unlock further study of human-robot coexistence within open-world
environments.

</details>


### [29] [CTA-Flux: Integrating Chinese Cultural Semantics into High-Quality English Text-to-Image Communities](https://arxiv.org/abs/2508.14405)
*Yue Gong,Shanyuan Liu,Liuzhuozheng Li,Jian Zhu,Bo Cheng,Liebucha Wu,Xiaoyu Wu,Yuhang Ma,Dawei Leng,Yuhui Yin*

Main category: cs.CV

TL;DR: CTA-Flux是一种适配方法，将中文文本输入适配到Flux模型，提升中文语义理解与图像生成质量。


<details>
  <summary>Details</summary>
Motivation: 解决Flux模型在非英语提示（尤其是中文）下表现不佳的问题，现有方法无法满足文化特定语义的需求。

Method: 利用MultiModal Diffusion Transformer (MMDiT)直接控制Flux主干，减少参数量并增强中文语义理解。

Result: CTA-Flux显著提升生成质量和文化真实性，兼容现有插件，支持中英文提示。

Conclusion: CTA-Flux在中文语义表达和图像生成质量上表现优异，同时保持模型兼容性。

Abstract: We proposed the Chinese Text Adapter-Flux (CTA-Flux). An adaptation method
fits the Chinese text inputs to Flux, a powerful text-to-image (TTI) generative
model initially trained on the English corpus. Despite the notable image
generation ability conditioned on English text inputs, Flux performs poorly
when processing non-English prompts, particularly due to linguistic and
cultural biases inherent in predominantly English-centric training datasets.
Existing approaches, such as translating non-English prompts into English or
finetuning models for bilingual mappings, inadequately address culturally
specific semantics, compromising image authenticity and quality. To address
this issue, we introduce a novel method to bridge Chinese semantic
understanding with compatibility in English-centric TTI model communities.
Existing approaches relying on ControlNet-like architectures typically require
a massive parameter scale and lack direct control over Chinese semantics. In
comparison, CTA-flux leverages MultiModal Diffusion Transformer (MMDiT) to
control the Flux backbone directly, significantly reducing the number of
parameters while enhancing the model's understanding of Chinese semantics. This
integration significantly improves the generation quality and cultural
authenticity without extensive retraining of the entire model, thus maintaining
compatibility with existing text-to-image plugins such as LoRA, IP-Adapter, and
ControlNet. Empirical evaluations demonstrate that CTA-flux supports Chinese
and English prompts and achieves superior image generation quality, visual
realism, and faithful depiction of Chinese semantics.

</details>


### [30] [MoCHA-former: Moiré-Conditioned Hybrid Adaptive Transformer for Video Demoiréing](https://arxiv.org/abs/2508.14423)
*Jeahun Sung,Changhyun Roh,Chanho Eom,Jihyong Oh*

Main category: cs.CV

TL;DR: MoCHA-former是一种新型的去摩尔纹方法，通过DMAD和STAD模块解决了现有方法的局限性，并在RAW和sRGB视频数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 便携式成像设备拍摄屏幕时，CFA与显示子像素之间的频率混叠会导致摩尔纹，严重影响图像质量。现有去摩尔纹方法存在局部强度变化、大尺度结构、通道依赖和时序波动等问题。

Method: MoCHA-former包含DMAD和STAD模块：DMAD通过MDB和DDB分离摩尔纹与内容，MCB生成自适应特征；STAD通过SFB和FCA处理大尺度结构和通道依赖，并实现隐式帧对齐。

Result: 在RAW和sRGB视频数据集上，MoCHA-former在PSNR、SSIM和LPIPS指标上均优于现有方法。

Conclusion: MoCHA-former通过创新的模块设计，有效解决了摩尔纹问题，并在多个指标上取得了显著提升。

Abstract: Recent advances in portable imaging have made camera-based screen capture
ubiquitous. Unfortunately, frequency aliasing between the camera's color filter
array (CFA) and the display's sub-pixels induces moir\'e patterns that severely
degrade captured photos and videos. Although various demoir\'eing models have
been proposed to remove such moir\'e patterns, these approaches still suffer
from several limitations: (i) spatially varying artifact strength within a
frame, (ii) large-scale and globally spreading structures, (iii)
channel-dependent statistics and (iv) rapid temporal fluctuations across
frames. We address these issues with the Moir\'e Conditioned Hybrid Adaptive
Transformer (MoCHA-former), which comprises two key components: Decoupled
Moir\'e Adaptive Demoir\'eing (DMAD) and Spatio-Temporal Adaptive Demoir\'eing
(STAD). DMAD separates moir\'e and content via a Moir\'e Decoupling Block (MDB)
and a Detail Decoupling Block (DDB), then produces moir\'e-adaptive features
using a Moir\'e Conditioning Block (MCB) for targeted restoration. STAD
introduces a Spatial Fusion Block (SFB) with window attention to capture
large-scale structures, and a Feature Channel Attention (FCA) to model channel
dependence in RAW frames. To ensure temporal consistency, MoCHA-former performs
implicit frame alignment without any explicit alignment module. We analyze
moir\'e characteristics through qualitative and quantitative studies, and
evaluate on two video datasets covering RAW and sRGB domains. MoCHA-former
consistently surpasses prior methods across PSNR, SSIM, and LPIPS.

</details>


### [31] [HyperDiff: Hypergraph Guided Diffusion Model for 3D Human Pose Estimation](https://arxiv.org/abs/2508.14431)
*Bing Han,Yuhua Huang,Pan Gao*

Main category: cs.CV

TL;DR: HyperDiff结合扩散模型和HyperGCN，解决了单目3D人体姿态估计中的深度模糊和遮挡问题，并通过多粒度结构提升姿态估计精度。


<details>
  <summary>Details</summary>
Motivation: 传统方法在2D到3D转换过程中存在深度模糊和遮挡问题，且忽略多尺度骨架特征，影响姿态估计准确性。

Method: 提出HyperDiff方法，结合扩散模型捕捉数据不确定性，HyperGCN作为去噪器建模关节间高阶相关性。

Result: 在Human3.6M和MPI-INF-3DHP数据集上达到最优性能，并能灵活平衡性能与效率。

Conclusion: HyperDiff通过多粒度结构和扩散模型，显著提升了3D姿态估计的准确性和适应性。

Abstract: Monocular 3D human pose estimation (HPE) often encounters challenges such as
depth ambiguity and occlusion during the 2D-to-3D lifting process.
Additionally, traditional methods may overlook multi-scale skeleton features
when utilizing skeleton structure information, which can negatively impact the
accuracy of pose estimation. To address these challenges, this paper introduces
a novel 3D pose estimation method, HyperDiff, which integrates diffusion models
with HyperGCN. The diffusion model effectively captures data uncertainty,
alleviating depth ambiguity and occlusion. Meanwhile, HyperGCN, serving as a
denoiser, employs multi-granularity structures to accurately model high-order
correlations between joints. This improves the model's denoising capability
especially for complex poses. Experimental results demonstrate that HyperDiff
achieves state-of-the-art performance on the Human3.6M and MPI-INF-3DHP
datasets and can flexibly adapt to varying computational resources to balance
performance and efficiency.

</details>


### [32] [FOCUS: Frequency-Optimized Conditioning of DiffUSion Models for mitigating catastrophic forgetting during Test-Time Adaptation](https://arxiv.org/abs/2508.14437)
*Gabriel Tjio,Jie Zhang,Xulei Yang,Yun Xing,Nhat Chung,Xiaofeng Cao,Ivor W. Tsang,Chee Keong Kwoh,Qing Guo*

Main category: cs.CV

TL;DR: FOCUS是一种基于频率的调节方法，通过扩散驱动的输入适应框架解决模型适应中的知识保留与领域适应平衡问题。


<details>
  <summary>Details</summary>
Motivation: 解决模型适应过程中因领域偏移导致的任务相关知识遗忘问题。

Method: 利用频率预测网络（Y-FPN）分离高低频信息，结合FrequencyMix数据增强方法，在扩散驱动框架中实现高效适应。

Result: 在15种损坏类型和三个数据集上，FOCUS在语义分割和单目深度估计中达到最先进性能。

Conclusion: FOCUS不仅提升独立性能，还能通过伪标签补充现有模型适应方法，缓解灾难性遗忘。

Abstract: Test-time adaptation enables models to adapt to evolving domains. However,
balancing the tradeoff between preserving knowledge and adapting to domain
shifts remains challenging for model adaptation methods, since adapting to
domain shifts can induce forgetting of task-relevant knowledge. To address this
problem, we propose FOCUS, a novel frequency-based conditioning approach within
a diffusion-driven input-adaptation framework. Utilising learned, spatially
adaptive frequency priors, our approach conditions the reverse steps during
diffusion-driven denoising to preserve task-relevant semantic information for
dense prediction.
  FOCUS leverages a trained, lightweight, Y-shaped Frequency Prediction Network
(Y-FPN) that disentangles high and low frequency information from noisy images.
This minimizes the computational costs involved in implementing our approach in
a diffusion-driven framework. We train Y-FPN with FrequencyMix, a novel data
augmentation method that perturbs the images across diverse frequency bands,
which improves the robustness of our approach to diverse corruptions.
  We demonstrate the effectiveness of FOCUS for semantic segmentation and
monocular depth estimation across 15 corruption types and three datasets,
achieving state-of-the-art averaged performance. In addition to improving
standalone performance, FOCUS complements existing model adaptation methods
since we can derive pseudo labels from FOCUS-denoised images for additional
supervision. Even under limited, intermittent supervision with the pseudo
labels derived from the FOCUS denoised images, we show that FOCUS mitigates
catastrophic forgetting for recent model adaptation methods.

</details>


### [33] [MUSE: Multi-Subject Unified Synthesis via Explicit Layout Semantic Expansion](https://arxiv.org/abs/2508.14440)
*Fei Peng,Junqiang Wu,Yan Li,Tingting Gao,Di Zhang,Huiyuan Fu*

Main category: cs.CV

TL;DR: MUSE框架通过串联交叉注意力机制实现多主题合成与精确布局控制，提升图像合成的空间准确性和身份一致性。


<details>
  <summary>Details</summary>
Motivation: 解决现有文本到图像扩散模型在多主题合成中难以同时满足空间精确控制和身份保持的问题。

Method: 提出串联交叉注意力（CCA）机制和渐进式两阶段训练策略，实现布局与文本的双向对齐。

Result: MUSE在零样本端到端生成中表现出优越的空间准确性和身份一致性。

Conclusion: MUSE推动了可控图像合成的前沿，为多主题合成提供了高效解决方案。

Abstract: Existing text-to-image diffusion models have demonstrated remarkable
capabilities in generating high-quality images guided by textual prompts.
However, achieving multi-subject compositional synthesis with precise spatial
control remains a significant challenge. In this work, we address the task of
layout-controllable multi-subject synthesis (LMS), which requires both faithful
reconstruction of reference subjects and their accurate placement in specified
regions within a unified image. While recent advancements have separately
improved layout control and subject synthesis, existing approaches struggle to
simultaneously satisfy the dual requirements of spatial precision and identity
preservation in this composite task. To bridge this gap, we propose MUSE, a
unified synthesis framework that employs concatenated cross-attention (CCA) to
seamlessly integrate layout specifications with textual guidance through
explicit semantic space expansion. The proposed CCA mechanism enables
bidirectional modality alignment between spatial constraints and textual
descriptions without interference. Furthermore, we design a progressive
two-stage training strategy that decomposes the LMS task into learnable
sub-objectives for effective optimization. Extensive experiments demonstrate
that MUSE achieves zero-shot end-to-end generation with superior spatial
accuracy and identity consistency compared to existing solutions, advancing the
frontier of controllable image synthesis. Our code and model are available at
https://github.com/pf0607/MUSE.

</details>


### [34] [Reconstruction Using the Invisible: Intuition from NIR and Metadata for Enhanced 3D Gaussian Splatting](https://arxiv.org/abs/2508.14443)
*Gyusam Chang,Tuan-Anh Vu,Vivek Alumootil,Harris Song,Deanna Pham,Sangpil Kim,M. Khalid Jawed*

Main category: cs.CV

TL;DR: 论文提出了一种名为NIRSplat的多模态高斯泼溅架构，结合NIRPlant数据集，解决了农业场景中3D重建的挑战。


<details>
  <summary>Details</summary>
Motivation: 农业场景中的3D重建面临光照不均、遮挡和视野受限等问题，现有方法表现不佳。

Method: 提出NIRSplat架构，结合NIR数据、RGB图像、文本元数据等，使用交叉注意力机制和3D点位置编码。

Result: NIRSplat在农业场景中优于3DGS、CoR-GS和InstantSplat等方法。

Conclusion: NIRSplat通过多模态数据提升了农业场景3D重建的鲁棒性和准确性。

Abstract: While 3D Gaussian Splatting (3DGS) has rapidly advanced, its application in
agriculture remains underexplored. Agricultural scenes present unique
challenges for 3D reconstruction methods, particularly due to uneven
illumination, occlusions, and a limited field of view. To address these
limitations, we introduce \textbf{NIRPlant}, a novel multimodal dataset
encompassing Near-Infrared (NIR) imagery, RGB imagery, textual metadata, Depth,
and LiDAR data collected under varied indoor and outdoor lighting conditions.
By integrating NIR data, our approach enhances robustness and provides crucial
botanical insights that extend beyond the visible spectrum. Additionally, we
leverage text-based metadata derived from vegetation indices, such as NDVI,
NDWI, and the chlorophyll index, which significantly enriches the contextual
understanding of complex agricultural environments. To fully exploit these
modalities, we propose \textbf{NIRSplat}, an effective multimodal Gaussian
splatting architecture employing a cross-attention mechanism combined with 3D
point-based positional encoding, providing robust geometric priors.
Comprehensive experiments demonstrate that \textbf{NIRSplat} outperforms
existing landmark methods, including 3DGS, CoR-GS, and InstantSplat,
highlighting its effectiveness in challenging agricultural scenarios. The code
and dataset are publicly available at:
https://github.com/StructuresComp/3D-Reconstruction-NIR

</details>


### [35] [Generalizable Engagement Estimation in Conversation via Domain Prompting and Parallel Attention](https://arxiv.org/abs/2508.14448)
*Yangche Yu,Yin Chen,Jia Li,Peng Jia,Yu Zhang,Li Dai,Zhenzhen Hu,Meng Wang,Richang Hong*

Main category: cs.CV

TL;DR: DAPA框架通过域提示和并行交叉注意力模块提升跨领域对话参与度建模的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有对话参与度估计方法在跨领域泛化性和复杂交互动态建模方面存在不足。

Method: 提出DAPA框架，结合域提示机制和并行交叉注意力模块，显式对齐参与者的反应和预期状态。

Result: 在多个跨文化/语言基准上达到SOTA，NoXi-J测试集CCC提升0.45，并获MultiMediate'25挑战赛冠军。

Conclusion: DAPA通过域自适应和交互同步建模显著提升了对话参与度估计的泛化性能。

Abstract: Accurate engagement estimation is essential for adaptive human-computer
interaction systems, yet robust deployment is hindered by poor generalizability
across diverse domains and challenges in modeling complex interaction
dynamics.To tackle these issues, we propose DAPA (Domain-Adaptive Parallel
Attention), a novel framework for generalizable conversational engagement
modeling. DAPA introduces a Domain Prompting mechanism by prepending learnable
domain-specific vectors to the input, explicitly conditioning the model on the
data's origin to facilitate domain-aware adaptation while preserving
generalizable engagement representations. To capture interactional synchrony,
the framework also incorporates a Parallel Cross-Attention module that
explicitly aligns reactive (forward BiLSTM) and anticipatory (backward BiLSTM)
states between participants.Extensive experiments demonstrate that DAPA
establishes a new state-of-the-art performance on several cross-cultural and
cross-linguistic benchmarks, notably achieving an absolute improvement of 0.45
in Concordance Correlation Coefficient (CCC) over a strong baseline on the
NoXi-J test set. The superiority of our method was also confirmed by winning
the first place in the Multi-Domain Engagement Estimation Challenge at
MultiMediate'25.

</details>


### [36] [D^3-Talker: Dual-Branch Decoupled Deformation Fields for Few-Shot 3D Talking Head Synthesis](https://arxiv.org/abs/2508.14449)
*Yuhang Guo,Kaijun Deng,Siyang Song,Jindong Xie,Wenhui Ma,Linlin Shen*

Main category: cs.CV

TL;DR: D^3-Talker通过解耦通用和个性化变形预测，结合音频和面部运动信号，实现了在有限训练数据下的高质量3D说话头合成。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖大量训练数据且难以准确映射音频到唇部运动，导致同步性和图像质量不佳。

Method: 构建静态3D高斯属性场，独立控制两个变形场，并设计相似性对比损失函数和粗到细模块。

Result: 在有限数据下，D^3-Talker在高保真渲染和音频-唇部同步性上优于现有方法。

Conclusion: D^3-Talker有效解决了小样本训练下的3D说话头合成问题，提升了同步性和图像质量。

Abstract: A key challenge in 3D talking head synthesis lies in the reliance on a
long-duration talking head video to train a new model for each target identity
from scratch. Recent methods have attempted to address this issue by extracting
general features from audio through pre-training models. However, since audio
contains information irrelevant to lip motion, existing approaches typically
struggle to map the given audio to realistic lip behaviors in the target face
when trained on only a few frames, causing poor lip synchronization and talking
head image quality. This paper proposes D^3-Talker, a novel approach that
constructs a static 3D Gaussian attribute field and employs audio and Facial
Motion signals to independently control two distinct Gaussian attribute
deformation fields, effectively decoupling the predictions of general and
personalized deformations. We design a novel similarity contrastive loss
function during pre-training to achieve more thorough decoupling. Furthermore,
we integrate a Coarse-to-Fine module to refine the rendered images, alleviating
blurriness caused by head movements and enhancing overall image quality.
Extensive experiments demonstrate that D^3-Talker outperforms state-of-the-art
methods in both high-fidelity rendering and accurate audio-lip synchronization
with limited training data. Our code will be provided upon acceptance.

</details>


### [37] [Ouroboros: Single-step Diffusion Models for Cycle-consistent Forward and Inverse Rendering](https://arxiv.org/abs/2508.14461)
*Shanlin Sun,Yifan Wang,Hanwen Zhang,Yifeng Xiong,Qin Ren,Ruogu Fang,Xiaohui Xie,Chenyu You*

Main category: cs.CV

TL;DR: Ouroboros框架通过两个单步扩散模型实现前向和逆向渲染的相互增强，提高了循环一致性和推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有方法独立处理前向和逆向渲染，导致循环不一致和推理速度慢。

Method: 使用两个单步扩散模型，引入循环一致性机制，扩展了室内外场景的本征分解。

Result: 在多样场景中实现最先进性能，推理速度显著提升，并可无训练迁移到视频分解。

Conclusion: Ouroboros框架在渲染任务中表现出高效性和一致性，适用于视频处理。

Abstract: While multi-step diffusion models have advanced both forward and inverse
rendering, existing approaches often treat these problems independently,
leading to cycle inconsistency and slow inference speed. In this work, we
present Ouroboros, a framework composed of two single-step diffusion models
that handle forward and inverse rendering with mutual reinforcement. Our
approach extends intrinsic decomposition to both indoor and outdoor scenes and
introduces a cycle consistency mechanism that ensures coherence between forward
and inverse rendering outputs. Experimental results demonstrate
state-of-the-art performance across diverse scenes while achieving
substantially faster inference speed compared to other diffusion-based methods.
We also demonstrate that Ouroboros can transfer to video decomposition in a
training-free manner, reducing temporal inconsistency in video sequences while
maintaining high-quality per-frame inverse rendering.

</details>


### [38] [DreamSwapV: Mask-guided Subject Swapping for Any Customized Video Editing](https://arxiv.org/abs/2508.14465)
*Weitao Wang,Zichen Wang,Hongdeng Shen,Yulei Lu,Xirui Fan,Suhui Wu,Jun Zhang,Haoqian Wang,Hao Zhang*

Main category: cs.CV

TL;DR: DreamSwapV是一个基于掩码引导、主题无关的端到端框架，用于视频中任意主题的替换，通过用户指定的掩码和参考图像实现定制化。


<details>
  <summary>Details</summary>
Motivation: 随着视频生成的快速发展，定制化视频编辑需求激增，但主题替换作为关键组成部分仍未被充分探索。现有方法要么局限于狭窄领域，要么依赖间接编辑范式或模糊文本提示，影响最终保真度。

Method: 提出DreamSwapV框架，引入多条件和专用条件融合模块以注入细粒度指导，并设计自适应掩码策略以适应不同尺度和属性的主题。通过两阶段数据集构建和训练方案实现。

Result: DreamSwapV在VBench指标和首次引入的DreamSwapV-Benchmark上通过综合实验验证，优于现有方法。

Conclusion: DreamSwapV为视频主题替换提供了一种高效、灵活的解决方案，显著提升了定制化视频编辑的保真度和适应性。

Abstract: With the rapid progress of video generation, demand for customized video
editing is surging, where subject swapping constitutes a key component yet
remains under-explored. Prevailing swapping approaches either specialize in
narrow domains--such as human-body animation or hand-object interaction--or
rely on some indirect editing paradigm or ambiguous text prompts that
compromise final fidelity. In this paper, we propose DreamSwapV, a mask-guided,
subject-agnostic, end-to-end framework that swaps any subject in any video for
customization with a user-specified mask and reference image. To inject
fine-grained guidance, we introduce multiple conditions and a dedicated
condition fusion module that integrates them efficiently. In addition, an
adaptive mask strategy is designed to accommodate subjects of varying scales
and attributes, further improving interactions between the swapped subject and
its surrounding context. Through our elaborate two-phase dataset construction
and training scheme, our DreamSwapV outperforms existing methods, as validated
by comprehensive experiments on VBench indicators and our first introduced
DreamSwapV-Benchmark.

</details>


### [39] [LookOut: Real-World Humanoid Egocentric Navigation](https://arxiv.org/abs/2508.14466)
*Boxiao Pan,Adam W. Harley,C. Karen Liu,Leonidas J. Guibas*

Main category: cs.CV

TL;DR: 预测未来6D头部姿态的挑战性任务，提出了一种基于3D潜在特征的框架，并贡献了一个新的数据集AND。


<details>
  <summary>Details</summary>
Motivation: 解决从自我中心视频预测未来无碰撞轨迹的需求，特别是在人形机器人、VR/AR和辅助导航中。

Method: 提出一个框架，利用时间聚合的3D潜在特征建模环境和动态部分的几何和语义约束。

Result: 模型学习了人类导航行为（如等待、绕行、观察交通），并能泛化到未见环境。

Conclusion: 通过新数据集和框架，成功预测了未来头部姿态，展示了人类导航行为的泛化能力。

Abstract: The ability to predict collision-free future trajectories from egocentric
observations is crucial in applications such as humanoid robotics, VR / AR, and
assistive navigation. In this work, we introduce the challenging problem of
predicting a sequence of future 6D head poses from an egocentric video. In
particular, we predict both head translations and rotations to learn the active
information-gathering behavior expressed through head-turning events. To solve
this task, we propose a framework that reasons over temporally aggregated 3D
latent features, which models the geometric and semantic constraints for both
the static and dynamic parts of the environment. Motivated by the lack of
training data in this space, we further contribute a data collection pipeline
using the Project Aria glasses, and present a dataset collected through this
approach. Our dataset, dubbed Aria Navigation Dataset (AND), consists of 4
hours of recording of users navigating in real-world scenarios. It includes
diverse situations and navigation behaviors, providing a valuable resource for
learning real-world egocentric navigation policies. Extensive experiments show
that our model learns human-like navigation behaviors such as waiting / slowing
down, rerouting, and looking around for traffic while generalizing to unseen
environments. Check out our project webpage at
https://sites.google.com/stanford.edu/lookout.

</details>


### [40] [Vivid-VR: Distilling Concepts from Text-to-Video Diffusion Transformer for Photorealistic Video Restoration](https://arxiv.org/abs/2508.14483)
*Haoran Bai,Xiaoxu Chen,Canqian Yang,Zongyao He,Sibin Deng,Ying Chen*

Main category: cs.CV

TL;DR: Vivid-VR是一种基于DiT的视频修复方法，通过ControlNet控制生成过程，提出概念蒸馏训练策略和新的控制架构，显著提升纹理真实性和时间一致性。


<details>
  <summary>Details</summary>
Motivation: 传统可控生成方法因多模态对齐不完美导致分布漂移，影响纹理真实性和时间一致性。

Method: 采用概念蒸馏训练策略，利用预训练T2V模型合成训练样本；重新设计控制架构，包括控制特征投影器和双分支ControlNet连接器。

Result: 在合成和真实基准测试中表现优异，纹理真实性和时间一致性显著提升。

Conclusion: Vivid-VR通过创新训练策略和控制架构，有效解决了视频修复中的纹理和时间一致性问题。

Abstract: We present Vivid-VR, a DiT-based generative video restoration method built
upon an advanced T2V foundation model, where ControlNet is leveraged to control
the generation process, ensuring content consistency. However, conventional
fine-tuning of such controllable pipelines frequently suffers from distribution
drift due to limitations in imperfect multimodal alignment, resulting in
compromised texture realism and temporal coherence. To tackle this challenge,
we propose a concept distillation training strategy that utilizes the
pretrained T2V model to synthesize training samples with embedded textual
concepts, thereby distilling its conceptual understanding to preserve texture
and temporal quality. To enhance generation controllability, we redesign the
control architecture with two key components: 1) a control feature projector
that filters degradation artifacts from input video latents to minimize their
propagation through the generation pipeline, and 2) a new ControlNet connector
employing a dual-branch design. This connector synergistically combines
MLP-based feature mapping with cross-attention mechanism for dynamic control
feature retrieval, enabling both content preservation and adaptive control
signal modulation. Extensive experiments show that Vivid-VR performs favorably
against existing approaches on both synthetic and real-world benchmarks, as
well as AIGC videos, achieving impressive texture realism, visual vividness,
and temporal consistency. The codes and checkpoints are publicly available at
https://github.com/csbhr/Vivid-VR.

</details>


### [41] [WeedSense: Multi-Task Learning for Weed Segmentation, Height Estimation, and Growth Stage Classification](https://arxiv.org/abs/2508.14486)
*Toqi Tahamid Sarker,Khaled R Ahmed,Taminul Islam,Cristiana Bernardi Rankrape,Karla Gage*

Main category: cs.CV

TL;DR: WeedSense是一种多任务学习架构，用于杂草分析，同时进行语义分割、高度估计和生长阶段分类，性能优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 杂草管理对农业至关重要，但资源消耗大，需要有效的监测和分析策略以实现可持续农业。

Method: WeedSense采用双路径编码器和多任务分叉解码器，结合Universal Inverted Bottleneck块和基于Transformer的特征融合。

Result: 在分割任务中mIoU达89.78%，高度估计MAE为1.67cm，生长阶段分类准确率99.99%，推理速度160 FPS。

Conclusion: WeedSense在性能和效率上均优于单任务模型，为杂草管理提供了高效解决方案。

Abstract: Weed management represents a critical challenge in agriculture, significantly
impacting crop yields and requiring substantial resources for control.
Effective weed monitoring and analysis strategies are crucial for implementing
sustainable agricultural practices and site-specific management approaches. We
introduce WeedSense, a novel multi-task learning architecture for comprehensive
weed analysis that jointly performs semantic segmentation, height estimation,
and growth stage classification. We present a unique dataset capturing 16 weed
species over an 11-week growth cycle with pixel-level annotations, height
measurements, and temporal labels. WeedSense leverages a dual-path encoder
incorporating Universal Inverted Bottleneck blocks and a Multi-Task Bifurcated
Decoder with transformer-based feature fusion to generate multi-scale features
and enable simultaneous prediction across multiple tasks. WeedSense outperforms
other state-of-the-art models on our comprehensive evaluation. On our
multi-task dataset, WeedSense achieves mIoU of 89.78% for segmentation, 1.67cm
MAE for height estimation, and 99.99% accuracy for growth stage classification
while maintaining real-time inference at 160 FPS. Our multitask approach
achieves 3$\times$ faster inference than sequential single-task execution and
uses 32.4% fewer parameters. Please see our project page at
weedsense.github.io.

</details>


### [42] [SATURN: Autoregressive Image Generation Guided by Scene Graphs](https://arxiv.org/abs/2508.14502)
*Thanh-Nhan Vo,Trong-Thuan Nguyen,Tam V. Nguyen,Minh-Triet Tran*

Main category: cs.CV

TL;DR: SATURN是一种轻量级扩展方法，通过将场景图转换为显著性排序的标记序列，提升了文本到图像模型在布局和对象关系上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像模型在复杂提示下难以准确捕捉布局和对象关系，而场景图提供了结构先验，但现有方法依赖复杂的GAN或扩散模型，速度和保真度不足。

Method: SATURN扩展了VAR-CLIP，将场景图转换为显著性排序的标记序列，仅微调VAR变换器，利用冻结的CLIP-VQ-VAE主干解释图结构。

Result: 在Visual Genome数据集上，SATURN将FID从56.45%降至21.62%，Inception Score从16.03提升至24.78，优于SG2IM和SGDiff等方法。

Conclusion: SATURN成功将结构感知与最先进的自回归保真度结合，显著提升了对象数量和空间关系的准确性。

Abstract: State-of-the-art text-to-image models excel at photorealistic rendering but
often struggle to capture the layout and object relationships implied by
complex prompts. Scene graphs provide a natural structural prior, yet previous
graph-guided approaches have typically relied on heavy GAN or diffusion
pipelines, which lag behind modern autoregressive architectures in both speed
and fidelity. We introduce SATURN (Structured Arrangement of Triplets for
Unified Rendering Networks), a lightweight extension to VAR-CLIP that
translates a scene graph into a salience-ordered token sequence, enabling a
frozen CLIP-VQ-VAE backbone to interpret graph structure while fine-tuning only
the VAR transformer. On the Visual Genome dataset, SATURN reduces FID from
56.45% to 21.62% and increases the Inception Score from 16.03 to 24.78,
outperforming prior methods such as SG2IM and SGDiff without requiring extra
modules or multi-stage training. Qualitative results further confirm
improvements in object count fidelity and spatial relation accuracy, showing
that SATURN effectively combines structural awareness with state-of-the-art
autoregressive fidelity.

</details>


### [43] [PB-IAD: Utilizing multimodal foundation models for semantic industrial anomaly detection in dynamic manufacturing environments](https://arxiv.org/abs/2508.14504)
*Bernd Hofmann,Albert Scheck,Joerg Franke,Patrick Bruendl*

Main category: cs.CV

TL;DR: PB-IAD是一种基于基础模型的新型工业异常检测框架，通过语义指令实现高性能检测，特别适用于数据稀疏和动态生产环境。


<details>
  <summary>Details</summary>
Motivation: 工业异常检测依赖大量标注数据和有限灵活性，基础模型的多模态和推理能力为解决这些问题提供了新机会。

Method: PB-IAD结合提示模板和预处理模块，利用GPT-4.1实现用户定制化异常检测，无需数据科学专业知识。

Result: 在数据稀疏和低样本场景中，PB-IAD表现优于PatchCore等现有方法。

Conclusion: PB-IAD通过语义指令和用户中心设计，显著提升了工业异常检测的适应性和性能。

Abstract: The detection of anomalies in manufacturing processes is crucial to ensure
product quality and identify process deviations. Statistical and data-driven
approaches remain the standard in industrial anomaly detection, yet their
adaptability and usability are constrained by the dependence on extensive
annotated datasets and limited flexibility under dynamic production conditions.
Recent advances in the perception capabilities of foundation models provide
promising opportunities for their adaptation to this downstream task. This
paper presents PB-IAD (Prompt-based Industrial Anomaly Detection), a novel
framework that leverages the multimodal and reasoning capabilities of
foundation models for industrial anomaly detection. Specifically, PB-IAD
addresses three key requirements of dynamic production environments: data
sparsity, agile adaptability, and domain user centricity. In addition to the
anomaly detection, the framework includes a prompt template that is
specifically designed for iteratively implementing domain-specific process
knowledge, as well as a pre-processing module that translates domain user
inputs into effective system prompts. This user-centric design allows domain
experts to customise the system flexibly without requiring data science
expertise. The proposed framework is evaluated by utilizing GPT-4.1 across
three distinct manufacturing scenarios, two data modalities, and an ablation
study to systematically assess the contribution of semantic instructions.
Furthermore, PB-IAD is benchmarked to state-of-the-art methods for anomaly
detection such as PatchCore. The results demonstrate superior performance,
particularly in data-sparse scenarios and low-shot settings, achieved solely
through semantic instructions.

</details>


### [44] [Adversarial Generation and Collaborative Evolution of Safety-Critical Scenarios for Autonomous Vehicles](https://arxiv.org/abs/2508.14527)
*Jiangfan Liu,Yongkang Guo,Fangzhi Zhong,Tianyuan Zhang,Zonglei Jing,Siyuan Liang,Jiakai Wang,Mingchuan Zhang,Aishan Liu,Xianglong Liu*

Main category: cs.CV

TL;DR: ScenGE框架通过生成多样化的安全关键场景，提升自动驾驶车辆的安全评估能力。


<details>
  <summary>Details</summary>
Motivation: 当前方法依赖预定义威胁模式或规则，难以暴露多样化的故障模式，需更灵活的场景生成方法。

Method: 结合大语言模型生成对抗性场景，并通过复杂交通流放大威胁，优化关键轨迹。

Result: ScenGE比现有方法多发现31.96%的严重碰撞案例，并提升模型鲁棒性。

Conclusion: ScenGE生成的场景既真实又关键，有助于增强公众信任和确保安全部署。

Abstract: The generation of safety-critical scenarios in simulation has become
increasingly crucial for safety evaluation in autonomous vehicles prior to road
deployment in society. However, current approaches largely rely on predefined
threat patterns or rule-based strategies, which limit their ability to expose
diverse and unforeseen failure modes. To overcome these, we propose ScenGE, a
framework that can generate plentiful safety-critical scenarios by reasoning
novel adversarial cases and then amplifying them with complex traffic flows.
Given a simple prompt of a benign scene, it first performs Meta-Scenario
Generation, where a large language model, grounded in structured driving
knowledge, infers an adversarial agent whose behavior poses a threat that is
both plausible and deliberately challenging. This meta-scenario is then
specified in executable code for precise in-simulator control. Subsequently,
Complex Scenario Evolution uses background vehicles to amplify the core threat
introduced by Meta-Scenario. It builds an adversarial collaborator graph to
identify key agent trajectories for optimization. These perturbations are
designed to simultaneously reduce the ego vehicle's maneuvering space and
create critical occlusions. Extensive experiments conducted on multiple
reinforcement learning based AV models show that ScenGE uncovers more severe
collision cases (+31.96%) on average than SoTA baselines. Additionally, our
ScenGE can be applied to large model based AV systems and deployed on different
simulators; we further observe that adversarial training on our scenarios
improves the model robustness. Finally, we validate our framework through
real-world vehicle tests and human evaluation, confirming that the generated
scenarios are both plausible and critical. We hope our paper can build up a
critical step towards building public trust and ensuring their safe deployment.

</details>


### [45] [WISE-FUSE: Efficient Whole Slide Image Encoding via Coarse-to-Fine Patch Selection with VLM and LLM Knowledge Fusion](https://arxiv.org/abs/2508.14537)
*Yonghan Shin,SeungKyu Kim,Won-Ki Jeong*

Main category: cs.CV

TL;DR: WISE-FUSE是一种自适应WSI编码框架，通过选择性处理诊断相关区域，显著减少编码时间。


<details>
  <summary>Details</summary>
Motivation: 解决WSI因规模庞大导致的编码成本高、预处理和训练时间长的问题。

Method: 利用病理领域视觉语言模型和大型语言模型，通过知识蒸馏机制计算相似性分数，选择信息区域进行编码。

Result: 编码时间减少三倍以上，诊断性能与全面处理相当或更好。

Conclusion: WISE-FUSE为计算病理学提供了可扩展且实用的解决方案。

Abstract: Whole slide images (WSIs) in computational pathology (CPath) pose a major
computational challenge due to their gigapixel scale, often requiring the
processing of tens to hundreds of thousands of high-resolution patches per
slide. This results in prohibitive encoding costs, with preprocessing and
training times extending to days or even weeks-making WSI encoding the most
significant bottleneck in real-world deployment. In this work, we propose
WISE-FUSE, an adaptive WSI encoding framework that leverages pathology-domain
vision-language models and large language models to address this challenge by
selectively processing diagnostically relevant regions. WISE-FUSE first
computes similarity scores between low-resolution patches and class-specific
textual descriptions using a knowledge distillation mechanism that preserves
fine-grained diagnostic features. Based on these similarity scores, we select a
small subset of informative regions for the target task, which quickly
eliminates irrelevant patches at the coarse level. The corresponding
high-resolution patches are then selectively encoded and fused with textual
embeddings to reinforce diagnostic context. Extensive experiments demonstrate
that WISE-FUSE reduces WSI encoding time by over threefold while achieving
diagnostic performance comparable to or surpassing that of exhaustive patch
processing, offering a scalable and practical solution for CPath.

</details>


### [46] [Improving OCR using internal document redundancy](https://arxiv.org/abs/2508.14557)
*Diego Belzarena,Seginus Mowlavi,Aitor Artola,Camilo Mariño,Marina Gardella,Ignacio Ramírez,Antoine Tadros,Roy He,Natalia Bottaioli,Boshra Rajaei,Gregory Randall,Jean-Michel Morel*

Main category: cs.CV

TL;DR: 提出一种无监督方法，利用文档内字符形状的冗余性改进OCR输出。


<details>
  <summary>Details</summary>
Motivation: 当前OCR系统在低质量数据识别上表现不佳，尤其是印刷文档中字符形状冗余未被充分利用。

Method: 引入扩展高斯混合模型（GMM），结合EM算法和簇内重对齐过程及正态性统计测试。

Result: 在多种退化程度的文档（如乌拉圭军事档案和欧洲古报纸）上表现提升。

Conclusion: 该方法有效利用文档内冗余，显著改进OCR输出质量。

Abstract: Current OCR systems are based on deep learning models trained on large
amounts of data. Although they have shown some ability to generalize to unseen
data, especially in detection tasks, they can struggle with recognizing
low-quality data. This is particularly evident for printed documents, where
intra-domain data variability is typically low, but inter-domain data
variability is high. In that context, current OCR methods do not fully exploit
each document's redundancy. We propose an unsupervised method by leveraging the
redundancy of character shapes within a document to correct imperfect outputs
of a given OCR system and suggest better clustering. To this aim, we introduce
an extended Gaussian Mixture Model (GMM) by alternating an
Expectation-Maximization (EM) algorithm with an intra-cluster realignment
process and normality statistical testing. We demonstrate improvements in
documents with various levels of degradation, including recovered Uruguayan
military archives and 17th to mid-20th century European newspapers.

</details>


### [47] [A Comprehensive Review of Agricultural Parcel and Boundary Delineation from Remote Sensing Images: Recent Progress and Future Perspectives](https://arxiv.org/abs/2508.14558)
*Juepeng Zheng,Zi Ye,Yibin Wen,Jianxi Huang,Zhiwei Zhang,Qingmei Li,Qiong Hu,Baodong Xu,Lingyuan Zhao,Haohuan Fu*

Main category: cs.CV

TL;DR: 本文综述了农业地块与边界划分（APBD）的研究进展，包括传统图像处理、传统机器学习和深度学习方法，并探讨了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 高分辨率遥感图像为农业地块自动化分析提供了潜力，但缺乏系统的APBD方法综述。

Method: 对APBD相关研究进行系统回顾，分类为传统图像处理、传统机器学习和深度学习方法，并讨论多传感器数据、多任务学习等问题。

Result: 深度学习方法是当前主流，包括语义分割、目标检测和Transformer等方法。

Conclusion: 本文总结了APBD领域的发展趋势，并提出了未来研究的热点方向和应用前景。

Abstract: Powered by advances in multiple remote sensing sensors, the production of
high spatial resolution images provides great potential to achieve
cost-efficient and high-accuracy agricultural inventory and analysis in an
automated way. Lots of studies that aim at providing an inventory of the level
of each agricultural parcel have generated many methods for Agricultural Parcel
and Boundary Delineation (APBD). This review covers APBD methods for detecting
and delineating agricultural parcels and systematically reviews the past and
present of APBD-related research applied to remote sensing images. With the
goal to provide a clear knowledge map of existing APBD efforts, we conduct a
comprehensive review of recent APBD papers to build a meta-data analysis,
including the algorithm, the study site, the crop type, the sensor type, the
evaluation method, etc. We categorize the methods into three classes: (1)
traditional image processing methods (including pixel-based, edge-based and
region-based); (2) traditional machine learning methods (such as random forest,
decision tree); and (3) deep learning-based methods. With deep
learning-oriented approaches contributing to a majority, we further discuss
deep learning-based methods like semantic segmentation-based, object
detection-based and Transformer-based methods. In addition, we discuss five
APBD-related issues to further comprehend the APBD domain using remote sensing
data, such as multi-sensor data in APBD task, comparisons between single-task
learning and multi-task learning in the APBD domain, comparisons among
different algorithms and different APBD tasks, etc. Finally, this review
proposes some APBD-related applications and a few exciting prospects and
potential hot topics in future APBD research. We hope this review help
researchers who involved in APBD domain to keep track of its development and
tendency.

</details>


### [48] [Locality-aware Concept Bottleneck Model](https://arxiv.org/abs/2508.14562)
*Sujin Jeon,Hyundo Lee,Eungseo Kim,Sanghack Lee,Byoung-Tak Zhang,Inwoo Hwang*

Main category: cs.CV

TL;DR: LCBM通过原型学习改进概念定位，提升分类性能。


<details>
  <summary>Details</summary>
Motivation: 传统CBMs难以准确定位概念区域，LCBM旨在解决这一问题。

Method: 利用基础模型和原型学习，确保概念的空间定位准确性。

Result: 实验显示LCBM能有效识别概念并提升定位能力。

Conclusion: LCBM在保持分类性能的同时，显著改善了概念定位能力。

Abstract: Concept bottleneck models (CBMs) are inherently interpretable models that
make predictions based on human-understandable visual cues, referred to as
concepts. As obtaining dense concept annotations with human labeling is
demanding and costly, recent approaches utilize foundation models to determine
the concepts existing in the images. However, such label-free CBMs often fail
to localize concepts in relevant regions, attending to visually unrelated
regions when predicting concept presence. To this end, we propose a framework,
coined Locality-aware Concept Bottleneck Model (LCBM), which utilizes rich
information from foundation models and adopts prototype learning to ensure
accurate spatial localization of the concepts. Specifically, we assign one
prototype to each concept, promoted to represent a prototypical image feature
of that concept. These prototypes are learned by encouraging them to encode
similar local regions, leveraging foundation models to assure the relevance of
each prototype to its associated concept. Then we use the prototypes to
facilitate the learning process of identifying the proper local region from
which each concept should be predicted. Experimental results demonstrate that
LCBM effectively identifies present concepts in the images and exhibits
improved localization while maintaining comparable classification performance.

</details>


### [49] [GOGS: High-Fidelity Geometry and Relighting for Glossy Objects via Gaussian Surfels](https://arxiv.org/abs/2508.14563)
*Xingyuan Yang,Min Wei*

Main category: cs.CV

TL;DR: GOGS提出了一种基于2D高斯面元的两阶段框架，解决了高光物体逆渲染中的多视角不一致性和材质分解问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如NeRF和3D高斯Splatting）在高光物体逆渲染中存在计算成本高、多视角噪声和材质分解不准确的问题。

Method: GOGS采用两阶段方法：1）基于物理渲染和几何先验的鲁棒表面重建；2）通过蒙特卡洛重要性采样和2D高斯光线追踪进行材质分解。

Result: 实验表明，GOGS在几何重建、材质分离和新光照下的真实感重光照方面优于现有方法。

Conclusion: GOGS通过创新的两阶段框架，显著提升了高光物体逆渲染的性能和效果。

Abstract: Inverse rendering of glossy objects from RGB imagery remains fundamentally
limited by inherent ambiguity. Although NeRF-based methods achieve
high-fidelity reconstruction via dense-ray sampling, their computational cost
is prohibitive. Recent 3D Gaussian Splatting achieves high reconstruction
efficiency but exhibits limitations under specular reflections. Multi-view
inconsistencies introduce high-frequency surface noise and structural
artifacts, while simplified rendering equations obscure material properties,
leading to implausible relighting results. To address these issues, we propose
GOGS, a novel two-stage framework based on 2D Gaussian surfels. First, we
establish robust surface reconstruction through physics-based rendering with
split-sum approximation, enhanced by geometric priors from foundation models.
Second, we perform material decomposition by leveraging Monte Carlo importance
sampling of the full rendering equation, modeling indirect illumination via
differentiable 2D Gaussian ray tracing and refining high-frequency specular
details through spherical mipmap-based directional encoding that captures
anisotropic highlights. Extensive experiments demonstrate state-of-the-art
performance in geometry reconstruction, material separation, and photorealistic
relighting under novel illuminations, outperforming existing inverse rendering
approaches.

</details>


### [50] [Safety-Critical Learning for Long-Tail Events: The TUM Traffic Accident Dataset](https://arxiv.org/abs/2508.14567)
*Walter Zimmer,Ross Greer,Xingcheng Zhou,Rui Song,Marc Pavel,Daniel Lehmberg,Ahmed Ghita,Akshay Gopalkrishnan,Mohan Trivedi,Alois Knoll*

Main category: cs.CV

TL;DR: TUMTraf-A数据集提供真实高速公路事故数据，Accid3nD模型结合规则与学习方法检测事故。


<details>
  <summary>Details</summary>
Motivation: 尽管交通网络安全性提升，事故仍不可避免且偶发，需更深入理解。

Method: 提出Accid3nD模型，结合规则与学习方法，使用TUMTraf-A数据集验证。

Result: 实验表明模型鲁棒性高，数据集包含大量标注数据。

Conclusion: TUMTraf-A数据集和Accid3nD模型为事故检测研究提供有力工具。

Abstract: Even though a significant amount of work has been done to increase the safety
of transportation networks, accidents still occur regularly. They must be
understood as an unavoidable and sporadic outcome of traffic networks. We
present the TUM Traffic Accident (TUMTraf-A) dataset, a collection of
real-world highway accidents. It contains ten sequences of vehicle crashes at
high-speed driving with 294,924 labeled 2D and 93,012 labeled 3D boxes and
track IDs within 48,144 labeled frames recorded from four roadside cameras and
LiDARs at 10 Hz. The dataset contains ten object classes and is provided in the
OpenLABEL format. We propose Accid3nD, an accident detection model that
combines a rule-based approach with a learning-based one. Experiments and
ablation studies on our dataset show the robustness of our proposed method. The
dataset, model, and code are available on our project website:
https://tum-traffic-dataset.github.io/tumtraf-a.

</details>


### [51] [Controllable Latent Space Augmentation for Digital Pathology](https://arxiv.org/abs/2508.14588)
*Sofiène Boutaj,Marin Scalbert,Pierre Marza,Florent Couzinie-Devy,Maria Vakalopoulou,Stergios Christodoulidis*

Main category: cs.CV

TL;DR: HistAug是一种高效的生成模型，用于数字病理学中的可控增强，通过潜在空间生成增强嵌入，提升多实例学习模型的性能。


<details>
  <summary>Details</summary>
Motivation: 解决数字病理学中全切片图像（WSI）分析因高分辨率和稀疏监督信号带来的挑战，以及传统增强方法的高成本和语义控制不足问题。

Method: 提出HistAug，一种基于条件生成模型的潜在空间增强方法，通过显式补丁级变换生成增强嵌入。

Result: 在多个切片级任务和器官上，HistAug优于现有方法，尤其在数据稀缺情况下表现突出。

Conclusion: HistAug通过高效可控的增强方法显著提升了模型性能，特别是在低数据环境下。

Abstract: Whole slide image (WSI) analysis in digital pathology presents unique
challenges due to the gigapixel resolution of WSIs and the scarcity of dense
supervision signals. While Multiple Instance Learning (MIL) is a natural fit
for slide-level tasks, training robust models requires large and diverse
datasets. Even though image augmentation techniques could be utilized to
increase data variability and reduce overfitting, implementing them effectively
is not a trivial task. Traditional patch-level augmentation is prohibitively
expensive due to the large number of patches extracted from each WSI, and
existing feature-level augmentation methods lack control over transformation
semantics. We introduce HistAug, a fast and efficient generative model for
controllable augmentations in the latent space for digital pathology. By
conditioning on explicit patch-level transformations (e.g., hue, erosion),
HistAug generates realistic augmented embeddings while preserving initial
semantic information. Our method allows the processing of a large number of
patches in a single forward pass efficiently, while at the same time
consistently improving MIL model performance. Experiments across multiple
slide-level tasks and diverse organs show that HistAug outperforms existing
methods, particularly in low-data regimes. Ablation studies confirm the
benefits of learned transformations over noise-based perturbations and
highlight the importance of uniform WSI-wise augmentation. Code is available at
https://github.com/MICS-Lab/HistAug.

</details>


### [52] [Reliable Smoke Detection via Optical Flow-Guided Feature Fusion and Transformer-Based Uncertainty Modeling](https://arxiv.org/abs/2508.14597)
*Nitish Kumar Mahala,Muzammil Khan,Pushpendra Kumar*

Main category: cs.CV

TL;DR: 提出了一种基于单目图像的两阶段不确定性感知Shifted Windows Transformer框架，用于高精度烟雾检测，结合光流和外观线索，通过两阶段学习优化检测和不确定性估计。


<details>
  <summary>Details</summary>
Motivation: 烟雾检测对火灾预警至关重要，但传统方法受复杂时空动态和环境噪声影响，可靠性不足。

Method: 结合光流编码和外观线索生成烟雾分割掩码，使用两阶段学习的Shifted Windows Transformer进行检测和不确定性估计。

Result: 实验表明该方法在泛化性和鲁棒性上优于现有技术。

Conclusion: 为监控、工业安全和自主监测提供了可靠的早期火灾检测方案。

Abstract: Fire outbreaks pose critical threats to human life and infrastructure,
necessitating high-fidelity early-warning systems that detect combustion
precursors such as smoke. However, smoke plumes exhibit complex spatiotemporal
dynamics influenced by illumination variability, flow kinematics, and
environmental noise, undermining the reliability of traditional detectors. To
address these challenges without the logistical complexity of multi-sensor
arrays, we propose an information-fusion framework by integrating smoke feature
representations extracted from monocular imagery. Specifically, a Two-Phase
Uncertainty-Aware Shifted Windows Transformer for robust and reliable smoke
detection, leveraging a novel smoke segmentation dataset, constructed via
optical flow-based motion encoding, is proposed. The optical flow estimation is
performed with a four-color-theorem-inspired dual-phase level-set
fractional-order variational model, which preserves motion discontinuities. The
resulting color-encoded optical flow maps are fused with appearance cues via a
Gaussian Mixture Model to generate binary segmentation masks of the smoke
regions. These fused representations are fed into the novel Shifted-Windows
Transformer, which is augmented with a multi-scale uncertainty estimation head
and trained under a two-phase learning regimen. First learning phase optimizes
smoke detection accuracy, while during the second phase, the model learns to
estimate plausibility confidence in its predictions by jointly modeling
aleatoric and epistemic uncertainties. Extensive experiments using multiple
evaluation metrics and comparative analysis with state-of-the-art approaches
demonstrate superior generalization and robustness, offering a reliable
solution for early fire detection in surveillance, industrial safety, and
autonomous monitoring applications.

</details>


### [53] [Incremental Object Detection with Prompt-based Methods](https://arxiv.org/abs/2508.14599)
*Matthias Neuwirth-Trapp,Maarten Bieshaar,Danda Pani Paudel,Luc Van Gool*

Main category: cs.CV

TL;DR: 论文研究了基于视觉提示的方法在增量目标检测（IOD）中的应用，发现其在复杂域增量学习设置中表现不佳，但结合少量历史数据回放的方法效果最佳。


<details>
  <summary>Details</summary>
Motivation: 探索视觉提示方法在增量目标检测中的通用性，填补此前研究的空白。

Method: 分析了三种不同的基于提示的方法，并在复杂域增量学习设置下进行了实验，同时提供了广泛的基线参考。

Result: 测试的提示方法表现不佳，但结合少量历史数据回放的方法效果最好。

Conclusion: 研究为推进基于提示的增量学习在IOD中的应用提供了有价值的见解。

Abstract: Visual prompt-based methods have seen growing interest in incremental
learning (IL) for image classification. These approaches learn additional
embedding vectors while keeping the model frozen, making them efficient to
train. However, no prior work has applied such methods to incremental object
detection (IOD), leaving their generalizability unclear. In this paper, we
analyze three different prompt-based methods under a complex domain-incremental
learning setting. We additionally provide a wide range of reference baselines
for comparison. Empirically, we show that the prompt-based approaches we tested
underperform in this setting. However, a strong yet practical method, combining
visual prompts with replaying a small portion of previous data, achieves the
best results. Together with additional experiments on prompt length and
initialization, our findings offer valuable insights for advancing prompt-based
IL in IOD.

</details>


### [54] [UST-SSM: Unified Spatio-Temporal State Space Models for Point Cloud Video Modeling](https://arxiv.org/abs/2508.14604)
*Peiming Li,Ziyi Wang,Yulin Yuan,Hong Liu,Xiangming Meng,Junsong Yuan,Mengyuan Liu*

Main category: cs.CV

TL;DR: 提出了一种名为UST-SSM的模型，通过STSS、STSA和TIS技术解决了点云视频时空无序问题，提升了动作识别性能。


<details>
  <summary>Details</summary>
Motivation: 点云视频的动态3D运动捕捉能力强，但时空无序性阻碍了单向建模的有效性。

Method: 引入STSS重组无序点，STSA补偿缺失细节，TIS增强时间依赖性。

Result: 在MSR-Action3D、NTU RGB+D和Synthia 4D数据集上验证了有效性。

Conclusion: UST-SSM通过时空建模技术显著提升了点云视频的动作识别效果。

Abstract: Point cloud videos capture dynamic 3D motion while reducing the effects of
lighting and viewpoint variations, making them highly effective for recognizing
subtle and continuous human actions. Although Selective State Space Models
(SSMs) have shown good performance in sequence modeling with linear complexity,
the spatio-temporal disorder of point cloud videos hinders their unidirectional
modeling when directly unfolding the point cloud video into a 1D sequence
through temporally sequential scanning. To address this challenge, we propose
the Unified Spatio-Temporal State Space Model (UST-SSM), which extends the
latest advancements in SSMs to point cloud videos. Specifically, we introduce
Spatial-Temporal Selection Scanning (STSS), which reorganizes unordered points
into semantic-aware sequences through prompt-guided clustering, thereby
enabling the effective utilization of points that are spatially and temporally
distant yet similar within the sequence. For missing 4D geometric and motion
details, Spatio-Temporal Structure Aggregation (STSA) aggregates
spatio-temporal features and compensates. To improve temporal interaction
within the sampled sequence, Temporal Interaction Sampling (TIS) enhances
fine-grained temporal dependencies through non-anchor frame utilization and
expanded receptive fields. Experimental results on the MSR-Action3D, NTU RGB+D,
and Synthia 4D datasets validate the effectiveness of our method. Our code is
available at https://github.com/wangzy01/UST-SSM.

</details>


### [55] [SMTrack: End-to-End Trained Spiking Neural Networks for Multi-Object Tracking in RGB Videos](https://arxiv.org/abs/2508.14607)
*Pengzhi Zhong,Xinzhe Wang,Dan Zeng,Qihua Zhou,Feixiang He,Shuiwang Li*

Main category: cs.CV

TL;DR: SMTrack是首个直接训练的深度SNN框架，用于标准RGB视频的端到端多目标跟踪，性能与领先的ANN方法相当。


<details>
  <summary>Details</summary>
Motivation: 探索SNN在复杂时序任务（如多目标跟踪）中的潜力，填补其在RGB视频流中应用的空白。

Method: 引入自适应尺度感知的归一化Wasserstein距离损失（Asa-NWDLoss）和TrackTrack身份模块。

Result: 在多个数据集上表现优异，性能与ANN方法相当。

Conclusion: SMTrack推动了SNN在复杂场景中的鲁棒和准确跟踪。

Abstract: Brain-inspired Spiking Neural Networks (SNNs) exhibit significant potential
for low-power computation, yet their application in visual tasks remains
largely confined to image classification, object detection, and event-based
tracking. In contrast, real-world vision systems still widely use conventional
RGB video streams, where the potential of directly-trained SNNs for complex
temporal tasks such as multi-object tracking (MOT) remains underexplored. To
address this challenge, we propose SMTrack-the first directly trained deep SNN
framework for end-to-end multi-object tracking on standard RGB videos. SMTrack
introduces an adaptive and scale-aware Normalized Wasserstein Distance loss
(Asa-NWDLoss) to improve detection and localization performance under varying
object scales and densities. Specifically, the method computes the average
object size within each training batch and dynamically adjusts the
normalization factor, thereby enhancing sensitivity to small objects. For the
association stage, we incorporate the TrackTrack identity module to maintain
robust and consistent object trajectories. Extensive evaluations on BEE24,
MOT17, MOT20, and DanceTrack show that SMTrack achieves performance on par with
leading ANN-based MOT methods, advancing robust and accurate SNN-based tracking
in complex scenarios.

</details>


### [56] [AnchorSync: Global Consistency Optimization for Long Video Editing](https://arxiv.org/abs/2508.14609)
*Zichi Liu,Yinggui Wang,Tao Wei,Chao Ma*

Main category: cs.CV

TL;DR: AnchorSync是一种基于扩散模型的视频编辑框架，通过分离稀疏锚帧编辑和平滑中间帧插值任务，实现高质量长视频编辑。


<details>
  <summary>Details</summary>
Motivation: 长视频编辑面临全局一致性和时间连贯性的挑战，现有方法常出现结构漂移或时间伪影。

Method: 采用渐进去噪过程确保结构一致性，并通过多模态引导保留时间动态。

Result: 实验表明，AnchorSync在视觉质量和时间稳定性上优于现有方法。

Conclusion: AnchorSync为长视频编辑提供了高质量且连贯的解决方案。

Abstract: Editing long videos remains a challenging task due to the need for
maintaining both global consistency and temporal coherence across thousands of
frames. Existing methods often suffer from structural drift or temporal
artifacts, particularly in minute-long sequences. We introduce AnchorSync, a
novel diffusion-based framework that enables high-quality, long-term video
editing by decoupling the task into sparse anchor frame editing and smooth
intermediate frame interpolation. Our approach enforces structural consistency
through a progressive denoising process and preserves temporal dynamics via
multimodal guidance. Extensive experiments show that AnchorSync produces
coherent, high-fidelity edits, surpassing prior methods in visual quality and
temporal stability.

</details>


### [57] [Towards PerSense++: Advancing Training-Free Personalized Instance Segmentation in Dense Images](https://arxiv.org/abs/2508.14660)
*Muhammad Ibraheem Siddiqui,Muhammad Umer Sheikh,Hassan Abid,Kevin Henry,Muhammad Haris Khan*

Main category: cs.CV

TL;DR: PerSense++是一种无需训练、模型无关的单样本框架，用于密集图像中的个性化实例分割，通过改进的检测和选择模块显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 密集视觉场景中的分割面临遮挡、背景杂乱和尺度变化等挑战，需要一种高效且鲁棒的解决方案。

Method: PerSense++结合了多样性感知的示例选择、混合实例检测模块和无关掩码拒绝模块，以提升分割质量。

Result: 在多个基准测试中，PerSense++在密集场景下优于现有方法。

Conclusion: PerSense++通过创新模块和反馈机制，为密集图像分割提供了高效且鲁棒的解决方案。

Abstract: Segmentation in dense visual scenes poses significant challenges due to
occlusions, background clutter, and scale variations. To address this, we
introduce PerSense, an end-to-end, training-free, and model-agnostic one-shot
framework for Personalized instance Segmentation in dense images. PerSense
employs a novel Instance Detection Module (IDM) that leverages density maps
(DMs) to generate instance-level candidate point prompts, followed by a Point
Prompt Selection Module (PPSM) that filters false positives via adaptive
thresholding and spatial gating. A feedback mechanism further enhances
segmentation by automatically selecting effective exemplars to improve DM
quality. We additionally present PerSense++, an enhanced variant that
incorporates three additional components to improve robustness in cluttered
scenes: (i) a diversity-aware exemplar selection strategy that leverages
feature and scale diversity for better DM generation; (ii) a hybrid IDM
combining contour and peak-based prompt generation for improved instance
separation within complex density patterns; and (iii) an Irrelevant Mask
Rejection Module (IMRM) that discards spatially inconsistent masks using
outlier analysis. Finally, to support this underexplored task, we introduce
PerSense-D, a dedicated benchmark for personalized segmentation in dense
images. Extensive experiments across multiple benchmarks demonstrate that
PerSense++ outperforms existing methods in dense settings.

</details>


### [58] [GeMS: Efficient Gaussian Splatting for Extreme Motion Blur](https://arxiv.org/abs/2508.14682)
*Gopi Raju Matta,Trisha Reddypalli,Vemunuri Divya Madhuri,Kaushik Mitra*

Main category: cs.CV

TL;DR: GeMS是一个处理严重运动模糊图像的3D高斯溅射框架，无需依赖清晰图像，结合深度学习和概率方法实现稳定重建。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖清晰图像或COLMAP初始化，在极端模糊下失效，GeMS直接处理模糊输入。

Method: 整合VGGSfM（深度学习SfM）、3DGS-MCMC（概率分布初始化）和联合优化，GeMS-E加入事件增强的渐进细化。

Result: 在合成和真实数据集上达到SOTA性能，首次直接从模糊输入解决3DGS中的极端模糊问题。

Conclusion: GeMS和GeMS-E通过创新方法有效解决了极端模糊场景的3D重建挑战。

Abstract: We introduce GeMS, a framework for 3D Gaussian Splatting (3DGS) designed to
handle severely motion-blurred images. State-of-the-art deblurring methods for
extreme blur, such as ExBluRF, as well as Gaussian Splatting-based approaches
like Deblur-GS, typically assume access to sharp images for camera pose
estimation and point cloud generation, an unrealistic assumption. Methods
relying on COLMAP initialization, such as BAD-Gaussians, also fail due to
unreliable feature correspondences under severe blur. To address these
challenges, we propose GeMS, a 3DGS framework that reconstructs scenes directly
from extremely blurred images. GeMS integrates: (1) VGGSfM, a deep
learning-based Structure-from-Motion pipeline that estimates poses and
generates point clouds directly from blurred inputs; (2) 3DGS-MCMC, which
enables robust scene initialization by treating Gaussians as samples from a
probability distribution, eliminating heuristic densification and pruning; and
(3) joint optimization of camera trajectories and Gaussian parameters for
stable reconstruction. While this pipeline produces strong results,
inaccuracies may remain when all inputs are severely blurred. To mitigate this,
we propose GeMS-E, which integrates a progressive refinement step using events:
(4) Event-based Double Integral (EDI) deblurring restores sharper images that
are then fed into GeMS, improving pose estimation, point cloud generation, and
overall reconstruction. Both GeMS and GeMS-E achieve state-of-the-art
performance on synthetic and real-world datasets. To our knowledge, this is the
first framework to address extreme motion blur within 3DGS directly from
severely blurred inputs.

</details>


### [59] [Seeing Further on the Shoulders of Giants: Knowledge Inheritance for Vision Foundation Models](https://arxiv.org/abs/2508.14707)
*Jiabo Huang,Chen Chen,Lingjuan Lyu*

Main category: cs.CV

TL;DR: 提出了一种基于联合知识迁移和保存的模型驱动方法，用于训练视觉基础模型（VFM），避免了大规模标注数据的需求。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动方法需要大量高质量标注数据和高端GPU，限制了大多数机构的应用。开源视觉模型虽具备领域知识，但未充分用于通用VFM开发。

Method: 通过共享潜在空间统一多个预训练教师模型，解决分布差异导致的迁移不平衡问题，并引入知识保存策略整合通用和专用教师模型的知识。

Result: 实验表明，该方法在图像分类、目标检测、语义和实例分割等任务上优于现有数据驱动模型。

Conclusion: 通过统一和聚合现有模型，构建了强大的VFM，无需大量标注数据即可继承教师模型的专长。

Abstract: Vision foundation models (VFMs) are predominantly developed using
data-centric methods. These methods require training on vast amounts of data
usually with high-quality labels, which poses a bottleneck for most
institutions that lack both large-scale data and high-end GPUs. On the other
hand, many open-source vision models have been pretrained on domain-specific
data, enabling them to distill and represent core knowledge in a form that is
transferable across diverse applications. Even though these models are highly
valuable assets, they remain largely under-explored in empowering the
development of a general-purpose VFM. In this paper, we presents a new
model-driven approach for training VFMs through joint knowledge transfer and
preservation. Our method unifies multiple pre-trained teacher models in a
shared latent space to mitigate the ``imbalanced transfer'' issue caused by
their distributional gaps. Besides, we introduce a knowledge preservation
strategy to take a general-purpose teacher as a knowledge base for integrating
knowledge from the remaining purpose-specific teachers using an adapter module.
By unifying and aggregating existing models, we build a powerful VFM to inherit
teachers' expertise without needing to train on a large amount of labeled data.
Our model not only provides generalizable visual features, but also inherently
supports multiple downstream tasks. Extensive experiments demonstrate that our
VFM outperforms existing data-centric models across four fundamental vision
tasks, including image classification, object detection, semantic and instance
segmentation.

</details>


### [60] [GSFix3D: Diffusion-Guided Repair of Novel Views in Gaussian Splatting](https://arxiv.org/abs/2508.14717)
*Jiaxin Wei,Stefan Leutenegger,Simon Schaefer*

Main category: cs.CV

TL;DR: GSFix3D通过结合3D高斯泼溅和扩散模型，提升极端视角或部分缺失区域的渲染质量，实现高质量3D重建。


<details>
  <summary>Details</summary>
Motivation: 解决3D高斯泼溅在极端视角或部分缺失区域渲染质量不足的问题，同时克服扩散模型依赖文本提示且缺乏场景信息的问题。

Method: 提出GSFix3D框架，通过GSFixer（潜在扩散模型）将扩散模型先验知识融入3D表示，结合随机掩码增强策略修复缺失区域。

Result: 在挑战性基准测试中表现优异，仅需少量场景微调即可实现高质量渲染，且对姿态误差具有鲁棒性。

Conclusion: GSFix3D和GSFixer在提升渲染质量和3D重建准确性方面达到最先进水平，适用于多种环境和重建方法。

Abstract: Recent developments in 3D Gaussian Splatting have significantly enhanced
novel view synthesis, yet generating high-quality renderings from extreme novel
viewpoints or partially observed regions remains challenging. Meanwhile,
diffusion models exhibit strong generative capabilities, but their reliance on
text prompts and lack of awareness of specific scene information hinder
accurate 3D reconstruction tasks. To address these limitations, we introduce
GSFix3D, a novel framework that improves the visual fidelity in
under-constrained regions by distilling prior knowledge from diffusion models
into 3D representations, while preserving consistency with observed scene
details. At its core is GSFixer, a latent diffusion model obtained via our
customized fine-tuning protocol that can leverage both mesh and 3D Gaussians to
adapt pretrained generative models to a variety of environments and artifact
types from different reconstruction methods, enabling robust novel view repair
for unseen camera poses. Moreover, we propose a random mask augmentation
strategy that empowers GSFixer to plausibly inpaint missing regions.
Experiments on challenging benchmarks demonstrate that our GSFix3D and GSFixer
achieve state-of-the-art performance, requiring only minimal scene-specific
fine-tuning on captured data. Real-world test further confirms its resilience
to potential pose errors. Our code and data will be made publicly available.
Project page: https://gsfix3d.github.io.

</details>


### [61] [Multiscale Video Transformers for Class Agnostic Segmentation in Autonomous Driving](https://arxiv.org/abs/2508.14729)
*Leila Cheshmi,Mennatullah Siam*

Main category: cs.CV

TL;DR: 提出了一种高效的多尺度视频变换器，用于未知物体的类无关分割，无需光流，在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶安全需处理未知物体和场景，现有方法依赖已知类别或计算成本高。

Method: 使用多尺度查询-记忆解码和尺度特定随机丢弃令牌，保持高分辨率时空特征。

Result: 在DAVIS'16、KITTI和Cityscapes上优于多尺度基线，高效且内存友好。

Conclusion: 该方法为实时、鲁棒的密集预测提供了有前景的方向。

Abstract: Ensuring safety in autonomous driving is a complex challenge requiring
handling unknown objects and unforeseen driving scenarios. We develop
multiscale video transformers capable of detecting unknown objects using only
motion cues. Video semantic and panoptic segmentation often relies on known
classes seen during training, overlooking novel categories. Recent visual
grounding with large language models is computationally expensive, especially
for pixel-level output. We propose an efficient video transformer trained
end-to-end for class-agnostic segmentation without optical flow. Our method
uses multi-stage multiscale query-memory decoding and a scale-specific random
drop-token to ensure efficiency and accuracy, maintaining detailed
spatiotemporal features with a shared, learnable memory module. Unlike
conventional decoders that compress features, our memory-centric design
preserves high-resolution information at multiple scales. We evaluate on
DAVIS'16, KITTI, and Cityscapes. Our method consistently outperforms multiscale
baselines while being efficient in GPU memory and run-time, demonstrating a
promising direction for real-time, robust dense prediction in safety-critical
robotics.

</details>


### [62] [Improved Mapping Between Illuminations and Sensors for RAW Images](https://arxiv.org/abs/2508.14730)
*Abhijith Punnappurath,Luxi Zhao,Hoang Le,Abdelrahman Abdelhamed,SaiKiran Kumar Tedla,Michael S. Brown*

Main category: cs.CV

TL;DR: 论文提出了一个用于RAW图像光照和传感器映射的数据集和轻量级神经网络方法，以解决数据采集的挑战。


<details>
  <summary>Details</summary>
Motivation: RAW图像的传感器和光照特性使得深度学习数据采集困难，需要针对不同传感器和光照条件进行大量拍摄。

Method: 使用定制光箱捕获多光照条件下的场景，构建包含390种光照、4台相机和18个场景的数据集，并提出轻量级神经网络方法。

Result: 提出的方法在光照和传感器映射任务上优于现有方法，并成功应用于神经ISP训练。

Conclusion: 该数据集和方法有效减轻了RAW图像数据采集的负担，为相关任务提供了实用工具。

Abstract: RAW images are unprocessed camera sensor output with sensor-specific RGB
values based on the sensor's color filter spectral sensitivities. RAW images
also incur strong color casts due to the sensor's response to the spectral
properties of scene illumination. The sensor- and illumination-specific nature
of RAW images makes it challenging to capture RAW datasets for deep learning
methods, as scenes need to be captured for each sensor and under a wide range
of illumination. Methods for illumination augmentation for a given sensor and
the ability to map RAW images between sensors are important for reducing the
burden of data capture. To explore this problem, we introduce the
first-of-its-kind dataset comprising carefully captured scenes under a wide
range of illumination. Specifically, we use a customized lightbox with tunable
illumination spectra to capture several scenes with different cameras. Our
illumination and sensor mapping dataset has 390 illuminations, four cameras,
and 18 scenes. Using this dataset, we introduce a lightweight neural network
approach for illumination and sensor mapping that outperforms competing
methods. We demonstrate the utility of our approach on the downstream task of
training a neural ISP. Link to project page:
https://github.com/SamsungLabs/illum-sensor-mapping.

</details>


### [63] [6-DoF Object Tracking with Event-based Optical Flow and Frames](https://arxiv.org/abs/2508.14776)
*Zhichao Li,Arren Glover,Chiara Bartolozzi,Lorenzo Natale*

Main category: cs.CV

TL;DR: 结合事件相机和RGB相机的优势，提出了一种用于高速运动物体6-DoF姿态跟踪的方法。


<details>
  <summary>Details</summary>
Motivation: 高速运动物体的6-DoF姿态跟踪在机器人环境交互中至关重要，但传统相机因帧率限制和运动模糊难以实现。事件相机的高时间分辨率和低延迟特性可以弥补这一不足。

Method: 提出了一种基于事件光流的物体运动测量算法，结合RGB相机的全局姿态估计，实现6-DoF速度跟踪。

Result: 在合成和真实数据上验证了算法的有效性，尤其在高速运动场景中表现优异。

Conclusion: 该方法成功结合了事件相机和RGB相机的优势，为高速运动物体的6-DoF姿态跟踪提供了有效解决方案。

Abstract: Tracking the position and orientation of objects in space (i.e., in 6-DoF) in
real time is a fundamental problem in robotics for environment interaction. It
becomes more challenging when objects move at high-speed due to frame rate
limitations in conventional cameras and motion blur. Event cameras are
characterized by high temporal resolution, low latency and high dynamic range,
that can potentially overcome the impacts of motion blur. Traditional RGB
cameras provide rich visual information that is more suitable for the
challenging task of single-shot object pose estimation. In this work, we
propose using event-based optical flow combined with an RGB based global object
pose estimator for 6-DoF pose tracking of objects at high-speed, exploiting the
core advantages of both types of vision sensors. Specifically, we propose an
event-based optical flow algorithm for object motion measurement to implement
an object 6-DoF velocity tracker. By integrating the tracked object 6-DoF
velocity with low frequency estimated pose from the global pose estimator, the
method can track pose when objects move at high-speed. The proposed algorithm
is tested and validated on both synthetic and real world data, demonstrating
its effectiveness, especially in high-speed motion scenarios.

</details>


### [64] [Adversarial Hospital-Invariant Feature Learning for WSI Patch Classification](https://arxiv.org/abs/2508.14779)
*Mengliang Zhang,Jacob M. Luber*

Main category: cs.CV

TL;DR: 该论文研究了病理基础模型（PFMs）中的医院域偏差问题，提出了一个轻量级对抗框架来消除医院特定特征，同时保持疾病分类性能。


<details>
  <summary>Details</summary>
Motivation: 不同医院的病理图像因扫描硬件和预处理风格差异可能导致PFMs学习到医院特定特征，影响临床部署。

Method: 构建了量化域偏差的流程，提出了一种轻量级对抗框架，通过可训练适配器和域分类器（通过梯度反转层连接）来学习任务区分但域不变的表示。

Result: 在多中心组织病理数据集上，该方法显著降低了域可预测性，同时保持或提高了疾病分类性能，尤其是在未见医院场景中。

Conclusion: 该方法有效减轻了医院偏差，并通过医院检测和特征空间可视化验证了其有效性。

Abstract: Pathology foundation models (PFMs) have demonstrated remarkable potential in
whole-slide image (WSI) diagnosis. However, pathology images from different
hospitals often vary due to differences in scanning hardware and preprocessing
styles, which may lead PFMs to inadvertently learn hospital-specific features,
posing risks for clinical deployment. In this work, we present the first
systematic study of domain bias in PFMs arising from hospital source
characteristics. Specifically, we (1) construct a pipeline for quantifying
domain bias in PFMs, (2) evaluate and compare the performance of multiple
models, and (3) propose a lightweight adversarial framework that removes latent
hospital-specific features from frozen representations without modifying the
encoder itself. By introducing a trainable adapter and a domain classifier
connected through a gradient reversal layer (GRL), our method learns
task-discriminative yet domain-invariant representations. Experiments on
multi-center histopathology datasets demonstrate that our approach
substantially reduces domain predictability while maintaining or even improving
disease classification performance, particularly in out-of-domain (unseen
hospital) scenarios. Further analyses, including hospital detection and feature
space visualization, confirm the effectiveness of our method in mitigating
hospital bias. We will provide our code based on acceptance.

</details>


### [65] [MF-LPR$^2$: Multi-Frame License Plate Image Restoration and Recognition using Optical Flow](https://arxiv.org/abs/2508.14797)
*Kihyun Na,Junseok Oh,Youngkwan Cho,Bumjin Kim,Sungmin Cho,Jinyoung Choi,Injung Kim*

Main category: cs.CV

TL;DR: MF-LPR²框架通过多帧对齐和聚合提升低质量车牌图像的恢复和识别效果，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 车牌识别在交通执法和监控中很重要，但低分辨率、运动模糊和眩光等问题导致识别困难，现有生成模型无法可靠恢复此类图像。

Method: 提出MF-LPR²框架，利用光流估计器和时空一致性算法对齐和聚合多帧图像，避免依赖预训练知识。

Result: 在RLPR数据集上，MF-LPR²在PSNR、SSIM和LPIPS指标上显著优于8种模型，识别准确率达86.44%。

Conclusion: 多帧对齐和优化算法显著提升了车牌恢复和识别性能，验证了方法的有效性。

Abstract: License plate recognition (LPR) is important for traffic law enforcement,
crime investigation, and surveillance. However, license plate areas in dash cam
images often suffer from low resolution, motion blur, and glare, which make
accurate recognition challenging. Existing generative models that rely on
pretrained priors cannot reliably restore such poor-quality images, frequently
introducing severe artifacts and distortions. To address this issue, we propose
a novel multi-frame license plate restoration and recognition framework,
MF-LPR$^2$, which addresses ambiguities in poor-quality images by aligning and
aggregating neighboring frames instead of relying on pretrained knowledge. To
achieve accurate frame alignment, we employ a state-of-the-art optical flow
estimator in conjunction with carefully designed algorithms that detect and
correct erroneous optical flow estimations by leveraging the spatio-temporal
consistency inherent in license plate image sequences. Our approach enhances
both image quality and recognition accuracy while preserving the evidential
content of the input images. In addition, we constructed a novel Realistic LPR
(RLPR) dataset to evaluate MF-LPR$^2$. The RLPR dataset contains 200 pairs of
low-quality license plate image sequences and high-quality pseudo ground-truth
images, reflecting the complexities of real-world scenarios. In experiments,
MF-LPR$^2$ outperformed eight recent restoration models in terms of PSNR, SSIM,
and LPIPS by significant margins. In recognition, MF-LPR$^2$ achieved an
accuracy of 86.44%, outperforming both the best single-frame LPR (14.04%) and
the multi-frame LPR (82.55%) among the eleven baseline models. The results of
ablation studies confirm that our filtering and refinement algorithms
significantly contribute to these improvements.

</details>


### [66] [DINOv3 with Test-Time Training for Medical Image Registration](https://arxiv.org/abs/2508.14809)
*Shansong Wang,Mojtaba Safari,Mingzhe Hu,Qiang Li,Chih-Wei Chang,Richard LJ Qiu,Xiaofeng Yang*

Main category: cs.CV

TL;DR: 提出一种无需训练的医学图像配准方法，利用冻结的DINOv3编码器和特征空间变形场优化，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统学习方法需要大量训练数据，限制了临床应用，因此提出无需训练的方法。

Method: 使用冻结的DINOv3编码器，在测试时优化特征空间的变形场。

Result: 在Abdomen MR-CT和ACDC心脏MRI上取得高Dice分数和低变形误差。

Conclusion: 该方法为临床图像配准提供了一种实用且通用的解决方案。

Abstract: Prior medical image registration approaches, particularly learning-based
methods, often require large amounts of training data, which constrains
clinical adoption. To overcome this limitation, we propose a training-free
pipeline that relies on a frozen DINOv3 encoder and test-time optimization of
the deformation field in feature space. Across two representative benchmarks,
the method is accurate and yields regular deformations. On Abdomen MR-CT, it
attained the best mean Dice score (DSC) of 0.790 together with the lowest 95th
percentile Hausdorff Distance (HD95) of 4.9+-5.0 and the lowest standard
deviation of Log-Jacobian (SDLogJ) of 0.08+-0.02. On ACDC cardiac MRI, it
improves mean DSC to 0.769 and reduces SDLogJ to 0.11 and HD95 to 4.8, a marked
gain over the initial alignment. The results indicate that operating in a
compact foundation feature space at test time offers a practical and general
solution for clinical registration without additional training.

</details>


### [67] [Tinker: Diffusion's Gift to 3D--Multi-View Consistent Editing From Sparse Inputs without Per-Scene Optimization](https://arxiv.org/abs/2508.14811)
*Canyu Zhao,Xiaoman Li,Tianjian Feng,Zhiyue Zhao,Hao Chen,Chunhua Shen*

Main category: cs.CV

TL;DR: Tinker是一个无需逐场景微调的高保真3D编辑框架，支持单次和少量样本编辑，利用预训练扩散模型实现多视角一致性编辑。


<details>
  <summary>Details</summary>
Motivation: 现有技术需要大量逐场景优化才能保证多视角一致性或生成大量一致的编辑输入视图，Tinker旨在通过少量图像实现高效编辑。

Method: Tinker包含两个新组件：参考多视角编辑器（实现跨视角精确编辑）和任意视角到视频合成器（利用视频扩散的空间-时间先验进行高质量场景补全和新视角生成）。

Result: Tinker在编辑、新视角合成和渲染增强任务上达到最先进性能，显著降低了通用3D内容创建的障碍。

Conclusion: Tinker是迈向真正可扩展、零样本3D编辑的关键一步。

Abstract: We introduce Tinker, a versatile framework for high-fidelity 3D editing that
operates in both one-shot and few-shot regimes without any per-scene
finetuning. Unlike prior techniques that demand extensive per-scene
optimization to ensure multi-view consistency or to produce dozens of
consistent edited input views, Tinker delivers robust, multi-view consistent
edits from as few as one or two images. This capability stems from repurposing
pretrained diffusion models, which unlocks their latent 3D awareness. To drive
research in this space, we curate the first large-scale multi-view editing
dataset and data pipeline, spanning diverse scenes and styles. Building on this
dataset, we develop our framework capable of generating multi-view consistent
edited views without per-scene training, which consists of two novel
components: (1) Referring multi-view editor: Enables precise, reference-driven
edits that remain coherent across all viewpoints. (2) Any-view-to-video
synthesizer: Leverages spatial-temporal priors from video diffusion to perform
high-quality scene completion and novel-view generation even from sparse
inputs. Through extensive experiments, Tinker significantly reduces the barrier
to generalizable 3D content creation, achieving state-of-the-art performance on
editing, novel-view synthesis, and rendering enhancement tasks. We believe that
Tinker represents a key step towards truly scalable, zero-shot 3D editing.
Project webpage: https://aim-uofa.github.io/Tinker

</details>


### [68] [Repeating Words for Video-Language Retrieval with Coarse-to-Fine Objectives](https://arxiv.org/abs/2508.14812)
*Haoyu Zhao,Jiaxi Gu,Shicong Wang,Xing Zhang,Hang Xu,Zuxuan Wu,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: 论文提出了一种新框架，通过细粒度特征学习和推理管道提升视频-文本检索性能，无需额外训练。


<details>
  <summary>Details</summary>
Motivation: 解决视频流爆炸式增长带来的高精度和低训练成本挑战，同时探索视频与文本的细粒度信息。

Method: 采用粗到细的目标学习视频-文本对的语义信息，包括对比和匹配学习，并通过Granularity-Aware Representation模块获取细粒度数据。

Result: 在四个基准测试中表现优于现有方法，推理管道显著提升性能（MSR-VTT数据集Recall@1提升2.1%，DiDeMo数据集提升1.6%）。

Conclusion: 提出的框架和推理管道有效提升了视频-文本检索性能，且无需额外预训练。

Abstract: The explosive growth of video streaming presents challenges in achieving high
accuracy and low training costs for video-language retrieval. However, existing
methods rely on large-scale pre-training to improve video retrieval
performance, resulting in significant computational demands. Additionally, the
fine-grained information in videos and texts remains underexplored. To
alleviate these problems, we propose a novel framework to learn fine-grained
features for better alignment and introduce an inference pipeline to improve
performance without additional training. Specifically, we employ coarse-to-fine
objectives to understand the semantic information of video-text pairs,
including contrastive and matching learning. The fine-grained data used for
training is obtained through the Granularity-Aware Representation module, which
is designed based on similarity analysis between video frames and words in
captions. Furthermore, we observe that the repetition of keywords in the
original captions, referred to as "Repetition", can enhance retrieval
performance and improve alignment between video and text. Based on this
insight, we propose a novel and effective inference pipeline that incorporates
a voting mechanism and a new Matching Entropy metric to achieve better
retrieval performance without requiring additional pre-training. Experimental
results on four benchmarks demonstrate that the proposed method outperforms
previous approaches. Additionally, our inference pipeline achieves significant
performance improvements, with a 2.1% increase in Recall@1 on the MSR-VTT
dataset and a 1.6% increase on the DiDeMo dataset.

</details>


### [69] [TransLight: Image-Guided Customized Lighting Control with Generative Decoupling](https://arxiv.org/abs/2508.14814)
*Zongming Li,Lianghui Zhu,Haocheng Shen,Longjin Ran,Wenyu Liu,Xinggang Wang*

Main category: cs.CV

TL;DR: TransLight框架通过生成解耦技术实现高保真、高自由度的光效转移，解决了现有方法在光效定制与内容完整性保存上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有光效编辑方法难以同时实现光效定制和内容完整性保存，尤其在复杂光效转移任务中表现不佳。

Method: 提出生成解耦技术，利用两个微调扩散模型分离图像内容与光效，构建百万级数据集；结合IC-Light生成模型，实现光效转移。

Result: TransLight成功实现跨图像光效转移，提供比现有技术更灵活的光照控制。

Conclusion: TransLight为光照和谐化与编辑研究开辟了新方向。

Abstract: Most existing illumination-editing approaches fail to simultaneously provide
customized control of light effects and preserve content integrity. This makes
them less effective for practical lighting stylization requirements, especially
in the challenging task of transferring complex light effects from a reference
image to a user-specified target image. To address this problem, we propose
TransLight, a novel framework that enables high-fidelity and high-freedom
transfer of light effects. Extracting the light effect from the reference image
is the most critical and challenging step in our method. The difficulty lies in
the complex geometric structure features embedded in light effects that are
highly coupled with content in real-world scenarios. To achieve this, we first
present Generative Decoupling, where two fine-tuned diffusion models are used
to accurately separate image content and light effects, generating a newly
curated, million-scale dataset of image-content-light triplets. Then, we employ
IC-Light as the generative model and train our model with our triplets,
injecting the reference lighting image as an additional conditioning signal.
The resulting TransLight model enables customized and natural transfer of
diverse light effects. Notably, by thoroughly disentangling light effects from
reference images, our generative decoupling strategy endows TransLight with
highly flexible illumination control. Experimental results establish TransLight
as the first method to successfully transfer light effects across disparate
images, delivering more customized illumination control than existing
techniques and charting new directions for research in illumination
harmonization and editing.

</details>


### [70] [EventSSEG: Event-driven Self-Supervised Segmentation with Probabilistic Attention](https://arxiv.org/abs/2508.14856)
*Lakshmi Annamalai,Chetan Singh Thakur*

Main category: cs.CV

TL;DR: EventSSEG是一种基于事件相机的道路分割方法，通过事件自监督学习和概率注意力机制，解决了传统相机预训练权重迁移和标注数据稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 事件相机在低功耗感知方面具有优势，但缺乏标注数据限制了其在道路分割中的应用。

Method: 采用事件自监督学习和概率注意力机制，避免依赖大量标注数据。

Result: 在DSEC-Semantic和DDD17数据集上达到最先进性能，仅需少量标注事件。

Conclusion: EventSSEG充分利用事件相机能力，解决了标注数据不足的问题，为低延迟、低计算的道路分割提供了有效方案。

Abstract: Road segmentation is pivotal for autonomous vehicles, yet achieving low
latency and low compute solutions using frame based cameras remains a
challenge. Event cameras offer a promising alternative. To leverage their low
power sensing, we introduce EventSSEG, a method for road segmentation that uses
event only computing and a probabilistic attention mechanism. Event only
computing poses a challenge in transferring pretrained weights from the
conventional camera domain, requiring abundant labeled data, which is scarce.
To overcome this, EventSSEG employs event-based self supervised learning,
eliminating the need for extensive labeled data. Experiments on DSEC-Semantic
and DDD17 show that EventSSEG achieves state of the art performance with
minimal labeled events. This approach maximizes event cameras capabilities and
addresses the lack of labeled events.

</details>


### [71] [Lifespan Pancreas Morphology for Control vs Type 2 Diabetes using AI on Largescale Clinical Imaging](https://arxiv.org/abs/2508.14878)
*Lucas W. Remedios,Chloe Cho,Trent M. Schwartz,Dingjie Su,Gaurav Rudravaram,Chenyu Gao,Aravind R. Krishnan,Adam M. Saunders,Michael E. Kim,Shunxing Bao,Thomas A. Lasko,Alvin C. Powers,Bennett A. Landman,John Virostko*

Main category: cs.CV

TL;DR: 研究通过AI方法测量胰腺形态，揭示2型糖尿病患者的胰腺大小和形状变化，并比较CT和MRI的测量差异。


<details>
  <summary>Details</summary>
Motivation: 了解胰腺随年龄的变化对检测2型糖尿病和其他胰腺疾病至关重要。

Method: 分析2533名患者的CT或MRI数据，提取13种胰腺形态特征，使用GAMLSS回归建模。

Result: 10/13的形态特征在2型糖尿病患者中显著不同，MRI与CT测量结果存在差异。

Conclusion: 2型糖尿病患者的胰腺形态与对照组不同，MRI和CT测量结果不一致，研究提供了非糖尿病患者的胰腺形态参考。

Abstract: Purpose: Understanding how the pancreas changes is critical for detecting
deviations in type 2 diabetes and other pancreatic disease. We measure pancreas
size and shape using morphological measurements from ages 0 to 90. Our goals
are to 1) identify reliable clinical imaging modalities for AI-based pancreas
measurement, 2) establish normative morphological aging trends, and 3) detect
potential deviations in type 2 diabetes.
  Approach: We analyzed a clinically acquired dataset of 2533 patients imaged
with abdominal CT or MRI. We resampled the scans to 3mm isotropic resolution,
segmented the pancreas using automated methods, and extracted 13 morphological
pancreas features across the lifespan. First, we assessed CT and MRI
measurements to determine which modalities provide consistent lifespan trends.
Second, we characterized distributions of normative morphological patterns
stratified by age group and sex. Third, we used GAMLSS regression to model
pancreas morphology trends in 1350 patients matched for age, sex, and type 2
diabetes status to identify any deviations from normative aging associated with
type 2 diabetes.
  Results: When adjusting for confounders, the aging trends for 10 of 13
morphological features were significantly different between patients with type
2 diabetes and non-diabetic controls (p < 0.05 after multiple comparisons
corrections). Additionally, MRI appeared to yield different pancreas
measurements than CT using our AI-based method.
  Conclusions: We provide lifespan trends demonstrating that the size and shape
of the pancreas is altered in type 2 diabetes using 675 control patients and
675 diabetes patients. Moreover, our findings reinforce that the pancreas is
smaller in type 2 diabetes. Additionally, we contribute a reference of lifespan
pancreas morphology from a large cohort of non-diabetic control patients in a
clinical setting.

</details>


### [72] [MS-CLR: Multi-Skeleton Contrastive Learning for Human Action Recognition](https://arxiv.org/abs/2508.14889)
*Mert Kiray,Alvaro Ritter,Nassir Navab,Benjamin Busam*

Main category: cs.CV

TL;DR: MS-CLR是一种自监督框架，通过多骨架对比学习提升动作识别的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖单一骨架结构，难以适应不同数据集中的多样化关节结构。

Method: 提出MS-CLR框架，通过统一表示方案对齐多骨架姿态表示，并改进ST-GCN架构。

Result: 在NTU RGB+D 60和120数据集上表现优于单骨架对比学习方法，并达到新SOTA。

Conclusion: MS-CLR通过多骨架学习提升了特征表达能力和泛化性。

Abstract: Contrastive learning has gained significant attention in skeleton-based
action recognition for its ability to learn robust representations from
unlabeled data. However, existing methods rely on a single skeleton convention,
which limits their ability to generalize across datasets with diverse joint
structures and anatomical coverage. We propose Multi-Skeleton Contrastive
Learning (MS-CLR), a general self-supervised framework that aligns pose
representations across multiple skeleton conventions extracted from the same
sequence. This encourages the model to learn structural invariances and capture
diverse anatomical cues, resulting in more expressive and generalizable
features. To support this, we adapt the ST-GCN architecture to handle skeletons
with varying joint layouts and scales through a unified representation scheme.
Experiments on the NTU RGB+D 60 and 120 datasets demonstrate that MS-CLR
consistently improves performance over strong single-skeleton contrastive
learning baselines. A multi-skeleton ensemble further boosts performance,
setting new state-of-the-art results on both datasets.

</details>


### [73] [GaussianArt: Unified Modeling of Geometry and Motion for Articulated Objects](https://arxiv.org/abs/2508.14891)
*Licheng Shen,Saining Zhang,Honghan Li,Peilin Yang,Zihao Huang,Zongzheng Zhang,Hao Zhao*

Main category: cs.CV

TL;DR: 提出了一种联合建模几何和运动的统一表示方法，显著提升了复杂多部件物体的重建效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法将几何和运动解耦，导致重建流程复杂且难以处理多部件物体。

Method: 使用基于3D高斯的统一表示方法，联合建模几何和运动。

Result: 在包含90个物体的新基准测试中表现优异，支持多达20个部件的物体。

Conclusion: 统一表示方法在几何重建和运动估计中表现优越，适用于机器人仿真等下游任务。

Abstract: Reconstructing articulated objects is essential for building digital twins of
interactive environments. However, prior methods typically decouple geometry
and motion by first reconstructing object shape in distinct states and then
estimating articulation through post-hoc alignment. This separation complicates
the reconstruction pipeline and restricts scalability, especially for objects
with complex, multi-part articulation. We introduce a unified representation
that jointly models geometry and motion using articulated 3D Gaussians. This
formulation improves robustness in motion decomposition and supports
articulated objects with up to 20 parts, significantly outperforming prior
approaches that often struggle beyond 2--3 parts due to brittle initialization.
To systematically assess scalability and generalization, we propose MPArt-90, a
new benchmark consisting of 90 articulated objects across 20 categories, each
with diverse part counts and motion configurations. Extensive experiments show
that our method consistently achieves superior accuracy in part-level geometry
reconstruction and motion estimation across a broad range of object types. We
further demonstrate applicability to downstream tasks such as robotic
simulation and human-scene interaction modeling, highlighting the potential of
unified articulated representations in scalable physical modeling.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [74] [Research on UAV Applications in Public Administration: Based on an Improved RRT Algorithm](https://arxiv.org/abs/2508.14096)
*Zhanxi Xie,Baili Lu,Yanzhao Gu,Zikun Li,Junhao Wei,Ngai Cheong*

Main category: cs.RO

TL;DR: 研究提出改进的RRT算法（dRRT），优化无人机路径规划，解决能耗、避障和空域限制问题，在模拟环境中表现优于传统算法。


<details>
  <summary>Details</summary>
Motivation: 无人机从技术工具转向治理基础设施，需高效路径规划以适应低空经济和智慧城市需求。

Method: dRRT算法结合目标偏置、动态步长、绕行优先和B样条平滑策略。

Result: dRRT在500m³城市模拟中实现100%成功率，路径更短、更平滑，但计算开销增加。

Conclusion: dRRT适用于公共管理场景，需结合实时避障框架，推动城市治理与机器人技术发展。

Abstract: This study investigates the application of unmanned aerial vehicles (UAVs) in
public management, focusing on optimizing path planning to address challenges
such as energy consumption, obstacle avoidance, and airspace constraints. As
UAVs transition from 'technical tools' to 'governance infrastructure', driven
by advancements in low-altitude economy policies and smart city demands,
efficient path planning becomes critical. The research proposes an enhanced
Rapidly-exploring Random Tree algorithm (dRRT), incorporating four strategies:
Target Bias (to accelerate convergence), Dynamic Step Size (to balance
exploration and obstacle navigation), Detour Priority (to prioritize horizontal
detours over vertical ascents), and B-spline smoothing (to enhance path
smoothness). Simulations in a 500 m3 urban environment with randomized
buildings demonstrate dRRT's superiority over traditional RRT, A*, and Ant
Colony Optimization (ACO). Results show dRRT achieves a 100\% success rate with
an average runtime of 0.01468s, shorter path lengths, fewer waypoints, and
smoother trajectories (maximum yaw angles <45{\deg}). Despite improvements,
limitations include increased computational overhead from added mechanisms and
potential local optima due to goal biasing. The study highlights dRRT's
potential for efficient UAV deployment in public management scenarios like
emergency response and traffic monitoring, while underscoring the need for
integration with real-time obstacle avoidance frameworks. This work contributes
to interdisciplinary advancements in urban governance, robotics, and
computational optimization.

</details>


### [75] [No More Marching: Learning Humanoid Locomotion for Short-Range SE(2) Targets](https://arxiv.org/abs/2508.14098)
*Pranay Dugar,Mohitvishnu S. Gadde,Jonah Siekmann,Yesh Godse,Aayam Shrestha,Alan Fern*

Main category: cs.RO

TL;DR: 提出了一种强化学习方法，直接优化人形机器人在SE(2)目标下的运动，通过新的基于星座的奖励函数实现高效自然的运动。


<details>
  <summary>Details</summary>
Motivation: 现有学习方法主要优化速度跟踪而非直接到达目标位姿，导致短距离任务效率低下。

Method: 采用强化学习方法，设计新的星座奖励函数，优化SE(2)目标下的运动。

Result: 在能量消耗、到达时间和步数上优于标准方法，并能从仿真成功迁移到硬件。

Conclusion: 针对性的奖励设计对短距离人形机器人运动至关重要。

Abstract: Humanoids operating in real-world workspaces must frequently execute
task-driven, short-range movements to SE(2) target poses. To be practical,
these transitions must be fast, robust, and energy efficient. While
learning-based locomotion has made significant progress, most existing methods
optimize for velocity-tracking rather than direct pose reaching, resulting in
inefficient, marching-style behavior when applied to short-range tasks. In this
work, we develop a reinforcement learning approach that directly optimizes
humanoid locomotion for SE(2) targets. Central to this approach is a new
constellation-based reward function that encourages natural and efficient
target-oriented movement. To evaluate performance, we introduce a benchmarking
framework that measures energy consumption, time-to-target, and footstep count
on a distribution of SE(2) goals. Our results show that the proposed approach
consistently outperforms standard methods and enables successful transfer from
simulation to hardware, highlighting the importance of targeted reward design
for practical short-range humanoid locomotion.

</details>


### [76] [Task and Motion Planning for Humanoid Loco-manipulation](https://arxiv.org/abs/2508.14099)
*Michal Ciebielski,Victor Dhédin,Majid Khadiv*

Main category: cs.RO

TL;DR: 提出了一种基于优化的任务与运动规划（TAMP）框架，统一了通过接触模式共享表示的移动与操作规划。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人在复杂任务中移动与操作规划的集成问题，实现物理一致的行为生成。

Method: 将符号动作定义为接触模式变化，结合高层规划与底层运动，统一搜索任务、接触和运动规划，并整合全身动力学与约束。

Result: 在人形机器人平台上生成了多种物理一致的移动与操作行为，支持长序列复杂推理。

Conclusion: 首次实现了集成TAMP框架，支持完全非循环规划和全身动力学约束的人形机器人移动与操作问题。

Abstract: This work presents an optimization-based task and motion planning (TAMP)
framework that unifies planning for locomotion and manipulation through a
shared representation of contact modes. We define symbolic actions as contact
mode changes, grounding high-level planning in low-level motion. This enables a
unified search that spans task, contact, and motion planning while
incorporating whole-body dynamics, as well as all constraints between the
robot, the manipulated object, and the environment. Results on a humanoid
platform show that our method can generate a broad range of physically
consistent loco-manipulation behaviors over long action sequences requiring
complex reasoning. To the best of our knowledge, this is the first work that
enables the resolution of an integrated TAMP formulation with fully acyclic
planning and whole body dynamics with actuation constraints for the humanoid
loco-manipulation problem.

</details>


### [77] [Domain Translation of a Soft Robotic Arm using Conditional Cycle Generative Adversarial Network](https://arxiv.org/abs/2508.14100)
*Nilay Kushawaha,Carlo Alessi,Lorenzo Fruzzetti,Egidio Falotico*

Main category: cs.RO

TL;DR: 提出了一种基于条件循环生成对抗网络（CCGAN）的领域翻译框架，用于软机器人跨领域知识迁移。


<details>
  <summary>Details</summary>
Motivation: 软机器人动态建模复杂且非线性，传统分析方法难以适应材料退化等变化，需要一种能跨领域迁移知识的方法。

Method: 使用CCGAN框架，通过动态学习将标准模拟环境中的姿态控制器适配到粘度增加的目标领域。

Result: 在五种不同形状的轨迹跟踪实验中验证了方法的有效性，并展示了其在噪声扰动和周期性测试中的鲁棒性。

Conclusion: CCGAN-GP成功实现了跨领域技能迁移，为软机器人控制器的适应性和泛化性提供了新途径。

Abstract: Deep learning provides a powerful method for modeling the dynamics of soft
robots, offering advantages over traditional analytical approaches that require
precise knowledge of the robot's structure, material properties, and other
physical characteristics. Given the inherent complexity and non-linearity of
these systems, extracting such details can be challenging. The mappings learned
in one domain cannot be directly transferred to another domain with different
physical properties. This challenge is particularly relevant for soft robots,
as their materials gradually degrade over time. In this paper, we introduce a
domain translation framework based on a conditional cycle generative
adversarial network (CCGAN) to enable knowledge transfer from a source domain
to a target domain. Specifically, we employ a dynamic learning approach to
adapt a pose controller trained in a standard simulation environment to a
domain with tenfold increased viscosity. Our model learns from input pressure
signals conditioned on corresponding end-effector positions and orientations in
both domains. We evaluate our approach through trajectory-tracking experiments
across five distinct shapes and further assess its robustness under noise
perturbations and periodicity tests. The results demonstrate that CCGAN-GP
effectively facilitates cross-domain skill transfer, paving the way for more
adaptable and generalizable soft robotic controllers.

</details>


### [78] [Efficient Environment Design for Multi-Robot Navigation via Continuous Control](https://arxiv.org/abs/2508.14105)
*Jahid Chowdhury Choton,John Woods,William Hsu*

Main category: cs.RO

TL;DR: 提出了一种高效且可定制的多机器人导航环境，基于MDP建模，并通过多种RL方法验证性能。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人在连续状态和动作空间中的导航问题，克服现有RL方法的样本效率低和训练时间长的问题。

Method: 将任务建模为MDP，设计优化问题，并使用A2C、PPO、TRPO等RL方法进行实验。

Result: 在3D农业模拟环境中验证了方法的鲁棒性和实用性。

Conclusion: 为研究者提供了开发适用于现实系统的MDP环境的方法，并展示了在有限资源下使用RL解决问题的可行性。

Abstract: Multi-robot navigation and path planning in continuous state and action
spaces with uncertain environments remains an open challenge. Deep
Reinforcement Learning (RL) is one of the most popular paradigms for solving
this task, but its real-world application has been limited due to sample
inefficiency and long training periods. Moreover, the existing works using RL
for multi-robot navigation lack formal guarantees while designing the
environment. In this paper, we introduce an efficient and highly customizable
environment for continuous-control multi-robot navigation, where the robots
must visit a set of regions of interest (ROIs) by following the shortest paths.
The task is formally modeled as a Markov Decision Process (MDP). We describe
the multi-robot navigation task as an optimization problem and relate it to
finding an optimal policy for the MDP. We crafted several variations of the
environment and measured the performance using both gradient and non-gradient
based RL methods: A2C, PPO, TRPO, TQC, CrossQ and ARS. To show real-world
applicability, we deployed our environment to a 3-D agricultural field with
uncertainties using the CoppeliaSim robot simulator and measured the robustness
by running inference on the learned models. We believe our work will guide the
researchers on how to develop MDP-based environments that are applicable to
real-world systems and solve them using the existing state-of-the-art RL
methods with limited resources and within reasonable time periods.

</details>


### [79] [SimGenHOI: Physically Realistic Whole-Body Humanoid-Object Interaction via Generative Modeling and Reinforcement Learning](https://arxiv.org/abs/2508.14120)
*Yuhang Lin,Yijia Xie,Jiahong Xie,Yuehao Huang,Ruoyu Wang,Jiajun Lv,Yukai Ma,Xingxing Zuo*

Main category: cs.RO

TL;DR: SimGenHOI是一个结合生成建模和强化学习的框架，用于生成可控且物理合理的人形物体交互（HOI）。


<details>
  <summary>Details</summary>
Motivation: 现有HOI生成方法（如扩散模型）常产生不合理的接触、穿透和不真实的全身动作，影响物理环境中的执行效果。

Method: 结合Diffusion Transformers（DiT）和强化学习，生成关键动作并通过插值形成平滑轨迹，再通过接触感知的全身控制策略修正物理不合理的动作。

Result: SimGenHOI能生成真实、多样且物理合理的HOI，在模拟中实现更高的跟踪成功率，并支持长时程操作任务。

Conclusion: SimGenHOI通过生成模型和强化学习的协同优化，显著提升了HOI的物理合理性和实用性。

Abstract: Generating physically realistic humanoid-object interactions (HOI) is a
fundamental challenge in robotics. Existing HOI generation approaches, such as
diffusion-based models, often suffer from artifacts such as implausible
contacts, penetrations, and unrealistic whole-body actions, which hinder
successful execution in physical environments. To address these challenges, we
introduce SimGenHOI, a unified framework that combines the strengths of
generative modeling and reinforcement learning to produce controllable and
physically plausible HOI. Our HOI generative model, based on Diffusion
Transformers (DiT), predicts a set of key actions conditioned on text prompts,
object geometry, sparse object waypoints, and the initial humanoid pose. These
key actions capture essential interaction dynamics and are interpolated into
smooth motion trajectories, naturally supporting long-horizon generation. To
ensure physical realism, we design a contact-aware whole-body control policy
trained with reinforcement learning, which tracks the generated motions while
correcting artifacts such as penetration and foot sliding. Furthermore, we
introduce a mutual fine-tuning strategy, where the generative model and the
control policy iteratively refine each other, improving both motion realism and
tracking robustness. Extensive experiments demonstrate that SimGenHOI generates
realistic, diverse, and physically plausible humanoid-object interactions,
achieving significantly higher tracking success rates in simulation and
enabling long-horizon manipulation tasks. Code will be released upon acceptance
on our project page: https://xingxingzuo.github.io/simgen_hoi.

</details>


### [80] [Lightweight Tracking Control for Computationally Constrained Aerial Systems with the Newton-Raphson Method](https://arxiv.org/abs/2508.14185)
*Evanns Morales-Cuadrado,Luke Baird,Yorai Wardi,Samuel Coogan*

Main category: cs.RO

TL;DR: 论文研究了基于牛顿-拉夫森流方法的轻量级跟踪控制器在小型飞艇和中型四旋翼上的性能，实验表明其在计算时间和能耗上优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 研究该控制器在真实飞行硬件平台上的性能，以验证其在现实部署和计算约束下的有效性。

Method: 使用牛顿-拉夫森流方法设计跟踪控制器，并与反馈线性化（飞艇）和非线性模型预测控制（四旋翼和飞艇）进行对比。

Result: 实验结果显示，该控制器在跟踪性能上与传统方法相当或更优，同时显著降低了计算时间和能耗。

Conclusion: 牛顿-拉夫森流控制器在真实飞行平台上表现优异，适合计算资源受限的应用场景。

Abstract: We investigate the performance of a lightweight tracking controller, based on
a flow version of the Newton-Raphson method, applied to a miniature blimp and a
mid-size quadrotor. This tracking technique has been shown to enjoy theoretical
guarantees of performance and has been applied with success in simulation
studies and on mobile robots with simple motion models. This paper investigates
the technique through real-world flight experiments on aerial hardware
platforms subject to realistic deployment and onboard computational
constraints. The technique's performance is assessed in comparison with the
established control frameworks of feedback linearization for the blimp, and
nonlinear model predictive control for both quadrotor and blimp. The
performance metrics under consideration are (i) root mean square error of
flight trajectories with respect to target trajectories, (ii) algorithms'
computation times, and (iii) CPU energy consumption associated with the control
algorithms. The experimental findings show that the Newton-Raphson flow-based
tracking controller achieves comparable or superior tracking performance to the
baseline methods with substantially reduced computation time and energy
expenditure.

</details>


### [81] [SLAM-based Safe Indoor Exploration Strategy](https://arxiv.org/abs/2508.14235)
*Omar Mostafa,Nikolaos Evangeliou,Anthony Tzes*

Main category: cs.RO

TL;DR: 本文提出了一种在充满障碍物的平面空间中的2D探索策略，适用于具有圆形足迹的经典代理，而非即时调整位置和高度的点机器人。


<details>
  <summary>Details</summary>
Motivation: 研究动机是开发一种适用于无法即时控制姿态的经典代理的探索策略，确保代理在探索过程中的安全性。

Method: 方法包括使用自平衡双轮差速驱动系统，配备线性加速度计、角速度陀螺仪、3D-LiDAR和RGB-D相机，通过RTAB-SLAM和骨架安全策略进行探索。

Result: 实验结果表明，该策略在ROS支持的移动代理中有效实现了路径规划和空间探索。

Conclusion: 结论是该策略优先保障代理的安全性，同时有效探索未检测空间。

Abstract: This paper suggests a 2D exploration strategy for a planar space cluttered
with obstacles. Rather than using point robots capable of adjusting their
position and altitude instantly, this research is tailored to classical agents
with circular footprints that cannot control instantly their pose. Inhere, a
self-balanced dual-wheeled differential drive system is used to explore the
place. The system is equipped with linear accelerometers and angular
gyroscopes, a 3D-LiDAR, and a forward-facing RGB-D camera. The system performs
RTAB-SLAM using the IMU and the LiDAR, while the camera is used for loop
closures. The mobile agent explores the planar space using a safe skeleton
approach that places the agent as far as possible from the static obstacles.
During the exploration strategy, the heading is towards any offered openings of
the space. This space exploration strategy has as its highest priority the
agent's safety in avoiding the obstacles followed by the exploration of
undetected space. Experimental studies with a ROS-enabled mobile agent are
presented indicating the path planning strategy while exploring the space.

</details>


### [82] [Adapting Biological Reflexes for Dynamic Reorientation in Space Manipulator Systems](https://arxiv.org/abs/2508.14258)
*Daegyun Choi,Alhim Vera,Donghoon Kim*

Main category: cs.RO

TL;DR: 研究探索了如何从动物的空中调整反射中获取灵感，改进空间机械臂系统的控制策略。


<details>
  <summary>Details</summary>
Motivation: 微重力环境下空间机械臂与航天器基座的动态耦合问题难以解决，生物启发可能提供新思路。

Method: 通过计算机视觉技术提取蜥蜴等动物的空中调整轨迹，并利用多目标优化框架分析其行为目标。

Result: 将动物行为轨迹应用于空间机械臂控制，提高了系统的机动性和鲁棒性。

Conclusion: 生物启发的控制策略为空间机器人提供了可解释且自适应的解决方案，对未来任务有重要意义。

Abstract: Robotic arms mounted on spacecraft, known as space manipulator systems
(SMSs), are critical for enabling on-orbit assembly, satellite servicing, and
debris removal. However, controlling these systems in microgravity remains a
significant challenge due to the dynamic coupling between the manipulator and
the spacecraft base. This study explores the potential of using biological
inspiration to address this issue, focusing on animals, particularly lizards,
that exhibit mid-air righting reflexes. Based on similarities between SMSs and
these animals in terms of behavior, morphology, and environment, their
air-righting motion trajectories are extracted from high-speed video recordings
using computer vision techniques. These trajectories are analyzed within a
multi-objective optimization framework to identify the key behavioral goals and
assess their relative importance. The resulting motion profiles are then
applied as reference trajectories for SMS control, with baseline controllers
used to track them. The findings provide a step toward translating evolved
animal behaviors into interpretable, adaptive control strategies for space
robotics, with implications for improving maneuverability and robustness in
future missions.

</details>


### [83] [D$^2$-LIO: Enhanced Optimization for LiDAR-IMU Odometry Considering Directional Degeneracy](https://arxiv.org/abs/2508.14355)
*Guodong Yao,Hao Wang,Qing Chang*

Main category: cs.RO

TL;DR: 提出了一种增强的LiDAR-惯性里程计（LIO）框架，通过自适应异常容忍匹配和扫描到子图配准策略，解决了LiDAR特征退化问题，提升了定位和建图的鲁棒性与精度。


<details>
  <summary>Details</summary>
Motivation: LiDAR特征退化在复杂环境中对状态估计的可靠性构成挑战，需要一种更鲁棒的方法来应对。

Method: 结合自适应异常移除阈值和扫描到子图配准策略，利用IMU数据优化位姿估计，并设计新的权重矩阵融合IMU预积分协方差和退化度量。

Result: 在室内外稀疏或退化特征环境中，实验表明该方法在鲁棒性和精度上均优于现有技术。

Conclusion: 所提框架有效解决了LiDAR特征退化问题，显著提升了LIO系统的性能。

Abstract: LiDAR-inertial odometry (LIO) plays a vital role in achieving accurate
localization and mapping, especially in complex environments. However, the
presence of LiDAR feature degeneracy poses a major challenge to reliable state
estimation. To overcome this issue, we propose an enhanced LIO framework that
integrates adaptive outlier-tolerant correspondence with a scan-to-submap
registration strategy. The core contribution lies in an adaptive outlier
removal threshold, which dynamically adjusts based on point-to-sensor distance
and the motion amplitude of platform. This mechanism improves the robustness of
feature matching in varying conditions. Moreover, we introduce a flexible
scan-to-submap registration method that leverages IMU data to refine pose
estimation, particularly in degenerate geometric configurations. To further
enhance localization accuracy, we design a novel weighting matrix that fuses
IMU preintegration covariance with a degeneration metric derived from the
scan-to-submap process. Extensive experiments conducted in both indoor and
outdoor environments-characterized by sparse or degenerate features-demonstrate
that our method consistently outperforms state-of-the-art approaches in terms
of both robustness and accuracy.

</details>


### [84] [Action-Constrained Imitation Learning](https://arxiv.org/abs/2508.14379)
*Chia-Han Yeh,Tse-Sheng Nan,Risto Vuorio,Wei Hung,Hung-Yen Wu,Shao-Hua Sun,Ping-Chun Hsieh*

Main category: cs.RO

TL;DR: 论文提出了一种称为动作约束模仿学习（ACIL）的新问题设置，通过轨迹对齐方法（DTWIL）解决专家与模仿者之间的动作空间不匹配问题，显著提升了机器人控制任务的性能。


<details>
  <summary>Details</summary>
Motivation: 在机器人控制和资源分配中，动作约束下的策略学习对确保安全行为至关重要。ACIL旨在解决专家与模仿者因动作空间不同导致的占用度量不匹配问题。

Method: 提出DTWIL方法，通过动态时间规整（DTW）距离和模型预测控制（MPC）对齐专家轨迹与模仿者轨迹，生成符合动作约束的替代数据集。

Result: 实验表明，DTWIL生成的替代数据集显著提升了机器人控制任务的性能，并在样本效率上优于多种基准模仿学习算法。

Conclusion: DTWIL通过轨迹对齐有效解决了ACIL问题，为动作约束下的模仿学习提供了高效解决方案。

Abstract: Policy learning under action constraints plays a central role in ensuring
safe behaviors in various robot control and resource allocation applications.
In this paper, we study a new problem setting termed Action-Constrained
Imitation Learning (ACIL), where an action-constrained imitator aims to learn
from a demonstrative expert with larger action space. The fundamental challenge
of ACIL lies in the unavoidable mismatch of occupancy measure between the
expert and the imitator caused by the action constraints. We tackle this
mismatch through \textit{trajectory alignment} and propose DTWIL, which
replaces the original expert demonstrations with a surrogate dataset that
follows similar state trajectories while adhering to the action constraints.
Specifically, we recast trajectory alignment as a planning problem and solve it
via Model Predictive Control, which aligns the surrogate trajectories with the
expert trajectories based on the Dynamic Time Warping (DTW) distance. Through
extensive experiments, we demonstrate that learning from the dataset generated
by DTWIL significantly enhances performance across multiple robot control tasks
and outperforms various benchmark imitation learning algorithms in terms of
sample efficiency. Our code is publicly available at
https://github.com/NYCU-RL-Bandits-Lab/ACRL-Baselines.

</details>


### [85] [Fair-CoPlan: Negotiated Flight Planning with Fair Deconfliction for Urban Air Mobility](https://arxiv.org/abs/2508.14380)
*Nicole Fronda,Phil Smith,Bardh Hoxha,Yash Pant,Houssam Abbas*

Main category: cs.RO

TL;DR: Fair-CoPlan是一种半分布式飞行规划器，通过公平分配飞行路径长度优化城市空中交通（UAM）中的无人机系统（UAS）操作。


<details>
  <summary>Details</summary>
Motivation: 当前飞行规划器可能导致某些UAS的飞行路径被不公平地缩短，影响整体参与度和安全性。Fair-CoPlan旨在公平分配路径成本，促进更广泛的UAM参与。

Method: Fair-CoPlan分为三步：PSU约束起降选择，运营商独立规划，PSU解决冲突路径并优化公平性。

Result: 模拟实验显示，Fair-CoPlan比非公平规划器产生更公平的结果，但以轻微延迟为代价。

Conclusion: Fair-CoPlan通过公平分配路径成本，提升了UAM的参与度、安全性和灵活性。

Abstract: Urban Air Mobility (UAM) is an emerging transportation paradigm in which
Uncrewed Aerial Systems (UAS) autonomously transport passengers and goods in
cities. The UAS have different operators with different, sometimes competing
goals, yet must share the airspace. We propose a negotiated, semi-distributed
flight planner that optimizes UAS' flight lengths {\em in a fair manner}.
Current flight planners might result in some UAS being given disproportionately
shorter flight paths at the expense of others. We introduce Fair-CoPlan, a
planner in which operators and a Provider of Service to the UAM (PSU) together
compute \emph{fair} flight paths. Fair-CoPlan has three steps: First, the PSU
constrains take-off and landing choices for flights based on capacity at and
around vertiports. Then, operators plan independently under these constraints.
Finally, the PSU resolves any conflicting paths, optimizing for path length
fairness. By fairly spreading the cost of deconfliction Fair-CoPlan encourages
wider participation in UAM, ensures safety of the airspace and the areas below
it, and promotes greater operator flexibility. We demonstrate Fair-CoPlan
through simulation experiments and find fairer outcomes than a non-fair planner
with minor delays as a trade-off.

</details>


### [86] [FiReFly: Fair Distributed Receding Horizon Planning for Multiple UAVs](https://arxiv.org/abs/2508.14381)
*Nicole Fronda,Bardh Hoxha,Houssam Abbas*

Main category: cs.RO

TL;DR: 提出了一种在多机器人运动规划中引入公平性的方法，通过优化机器人之间的能量消耗公平性，同时确保任务成功。


<details>
  <summary>Details</summary>
Motivation: 在机器人存在竞争利益时，公平分配资源（如能量消耗）对任务成功至关重要。

Method: 开发了分布式公平运动规划器FiReFly，并与安全控制器集成。

Result: 在模拟任务中，FiReFly比非公平规划器生成更公平的轨迹并提高任务成功率，实时性能可达15架无人机，50架无人机时需权衡运行时间和公平性。

Conclusion: FiReFly在多机器人系统中有效实现了公平性与任务成功的平衡，具有实际应用潜力。

Abstract: We propose injecting notions of fairness into multi-robot motion planning.
When robots have competing interests, it is important to optimize for some kind
of fairness in their usage of resources. In this work, we explore how the
robots' energy expenditures might be fairly distributed among them, while
maintaining mission success. We formulate a distributed fair motion planner and
integrate it with safe controllers in a algorithm called FiReFly. For simulated
reach-avoid missions, FiReFly produces fairer trajectories and improves mission
success rates over a non-fair planner. We find that real-time performance is
achievable up to 15 UAVs, and that scaling up to 50 UAVs is possible with
trade-offs between runtime and fairness improvements.

</details>


### [87] [Offline Imitation Learning upon Arbitrary Demonstrations by Pre-Training Dynamics Representations](https://arxiv.org/abs/2508.14383)
*Haitong Ma,Bo Dai,Zhaolin Ren,Yebin Wang,Na Li*

Main category: cs.RO

TL;DR: 提出一种通过预训练学习动态表示的方法，提升有限专家数据下的离线模仿学习性能。


<details>
  <summary>Details</summary>
Motivation: 有限数据是离线模仿学习的主要瓶颈，需要利用非专家数据提升性能。

Method: 通过动态表示的预训练阶段，利用噪声对比估计的损失函数学习表示。

Result: 在MuJoCo和真实四足机器人上验证了仅需少量轨迹即可模仿专家策略。

Conclusion: 动态表示预训练有效解决了有限数据问题，并可跨领域应用。

Abstract: Limited data has become a major bottleneck in scaling up offline imitation
learning (IL). In this paper, we propose enhancing IL performance under limited
expert data by introducing a pre-training stage that learns dynamics
representations, derived from factorizations of the transition dynamics. We
first theoretically justify that the optimal decision variable of offline IL
lies in the representation space, significantly reducing the parameters to
learn in the downstream IL. Moreover, the dynamics representations can be
learned from arbitrary data collected with the same dynamics, allowing the
reuse of massive non-expert data and mitigating the limited data issues. We
present a tractable loss function inspired by noise contrastive estimation to
learn the dynamics representations at the pre-training stage. Experiments on
MuJoCo demonstrate that our proposed algorithm can mimic expert policies with
as few as a single trajectory. Experiments on real quadrupeds show that we can
leverage pre-trained dynamics representations from simulator data to learn to
walk from a few real-world demonstrations.

</details>


### [88] [DEXTER-LLM: Dynamic and Explainable Coordination of Multi-Robot Systems in Unknown Environments via Large Language Models](https://arxiv.org/abs/2508.14387)
*Yuxiao Zhu,Junfeng Chen,Xintong Zhang,Meng Guo,Zhongkui Li*

Main category: cs.RO

TL;DR: DEXTER-LLM框架结合LLM的开放世界推理能力和模型分配方法的最优性，解决了多机器人系统在未知环境中的动态任务规划和可解释性问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的场景推理和规划方法缺乏动态适应能力和可解释性，无法满足在线操作需求。

Method: 框架包含任务理解、在线子任务生成、最优子任务分配和调度、动态适应与人工验证四个模块。

Result: 实验显示100%成功率，完成160任务和480子任务（基线3倍），适应时LLM查询减少62%，复合任务计划质量提高2倍。

Conclusion: DEXTER-LLM有效结合LLM推理和模型优化，显著提升动态任务规划的适应性和可解释性。

Abstract: Online coordination of multi-robot systems in open and unknown environments
faces significant challenges, particularly when semantic features detected
during operation dynamically trigger new tasks. Recent large language model
(LLMs)-based approaches for scene reasoning and planning primarily focus on
one-shot, end-to-end solutions in known environments, lacking both dynamic
adaptation capabilities for online operation and explainability in the
processes of planning. To address these issues, a novel framework (DEXTER-LLM)
for dynamic task planning in unknown environments, integrates four modules: (i)
a mission comprehension module that resolves partial ordering of tasks
specified by natural languages or linear temporal logic formulas (LTL); (ii) an
online subtask generator based on LLMs that improves the accuracy and
explainability of task decomposition via multi-stage reasoning; (iii) an
optimal subtask assigner and scheduler that allocates subtasks to robots via
search-based optimization; and (iv) a dynamic adaptation and human-in-the-loop
verification module that implements multi-rate, event-based updates for both
subtasks and their assignments, to cope with new features and tasks detected
online. The framework effectively combines LLMs' open-world reasoning
capabilities with the optimality of model-based assignment methods,
simultaneously addressing the critical issue of online adaptability and
explainability. Experimental evaluations demonstrate exceptional performances,
with 100% success rates across all scenarios, 160 tasks and 480 subtasks
completed on average (3 times the baselines), 62% less queries to LLMs during
adaptation, and superior plan quality (2 times higher) for compound tasks.
Project page at https://tcxm.github.io/DEXTER-LLM/

</details>


### [89] [FBI: Learning Dexterous In-hand Manipulation with Dynamic Visuotactile Shortcut Policy](https://arxiv.org/abs/2508.14441)
*Yijin Chen,Wenqiang Xu,Zhenjun Yu,Tutian Tang,Yutong Li,Siqiong Yao,Cewu Lu*

Main category: cs.RO

TL;DR: FBI是一种结合视觉和触觉的模仿学习框架，通过动态融合触觉信号与视觉观察，提升机器人灵巧操作的性能。


<details>
  <summary>Details</summary>
Motivation: 解决机器人灵巧操作中因复杂接触动力学和部分可观测性带来的挑战，通过结合视觉和触觉模态提升适应性。

Method: 提出FBI框架，通过动态融合触觉信号与视觉观察，利用基于Transformer的交互模块和扩散策略进行实时执行。

Result: 在仿真和现实世界的多个灵巧操作任务中优于基线方法。

Conclusion: FBI通过动态融合视觉和触觉模态，显著提升了机器人灵巧操作的性能。

Abstract: Dexterous in-hand manipulation is a long-standing challenge in robotics due
to complex contact dynamics and partial observability. While humans synergize
vision and touch for such tasks, robotic approaches often prioritize one
modality, therefore limiting adaptability. This paper introduces Flow Before
Imitation (FBI), a visuotactile imitation learning framework that dynamically
fuses tactile interactions with visual observations through motion dynamics.
Unlike prior static fusion methods, FBI establishes a causal link between
tactile signals and object motion via a dynamics-aware latent model. FBI
employs a transformer-based interaction module to fuse flow-derived tactile
features with visual inputs, training a one-step diffusion policy for real-time
execution. Extensive experiments demonstrate that the proposed method
outperforms the baseline methods in both simulation and the real world on two
customized in-hand manipulation tasks and three standard dexterous manipulation
tasks. Code, models, and more results are available in the website
https://sites.google.com/view/dex-fbi.

</details>


### [90] [Taming VR Teleoperation and Learning from Demonstration for Multi-Task Bimanual Table Service Manipulation](https://arxiv.org/abs/2508.14542)
*Weize Li,Zhengxiao Han,Lixin Xu,Xiangyu Chen,Harrison Bounds,Chenrui Zhang,Yifan Xu*

Main category: cs.RO

TL;DR: 冠军解决方案结合VR遥操作和演示学习，高效完成多项任务。


<details>
  <summary>Details</summary>
Motivation: 解决在速度、精度和可靠性要求下的复杂双手机器人任务。

Method: 结合VR遥操作和ACT策略（基于100次演示训练）。

Result: 高效可靠，获得比赛第一名。

Conclusion: 综合评分规则和任务特性，实现了技术能力的平衡。

Abstract: This technical report presents the champion solution of the Table Service
Track in the ICRA 2025 What Bimanuals Can Do (WBCD) competition. We tackled a
series of demanding tasks under strict requirements for speed, precision, and
reliability: unfolding a tablecloth (deformable-object manipulation), placing a
pizza onto the table (pick-and-place), and opening and closing a food container
with the lid. Our solution combines VR-based teleoperation and Learning from
Demonstrations (LfD) to balance robustness and autonomy. Most subtasks were
executed through high-fidelity remote teleoperation, while the pizza placement
was handled by an ACT-based policy trained from 100 in-person teleoperated
demonstrations with randomized initial configurations. By carefully integrating
scoring rules, task characteristics, and current technical capabilities, our
approach achieved both high efficiency and reliability, ultimately securing the
first place in the competition.

</details>


### [91] [EAROL: Environmental Augmented Perception-Aware Planning and Robust Odometry via Downward-Mounted Tilted LiDAR](https://arxiv.org/abs/2508.14554)
*Xinkai Liang,Yigu Ge,Yangxi Shi,Haoyu Yang,Xu Cao,Hao Fang*

Main category: cs.RO

TL;DR: EAROL是一个针对无人机在开放场景中定位漂移和感知-规划耦合问题的新框架，结合倾斜LiDAR和优化算法，显著提升了定位精度和任务效率。


<details>
  <summary>Details</summary>
Motivation: 解决无人机在开放场景（如倒塌建筑、无顶迷宫）中的定位漂移和感知-规划耦合问题。

Method: 提出EAROL框架，采用向下倾斜20度的LiDAR配置，结合LiDAR-惯性里程计（LIO）系统和分层轨迹-偏航优化算法。

Result: 实验显示跟踪误差减少81%，感知覆盖率提升22%，垂直漂移接近零。

Conclusion: 通过硬件-算法协同设计，为灾后搜救任务提供了鲁棒的无人机自主解决方案，并将开源软硬件。

Abstract: To address the challenges of localization drift and perception-planning
coupling in unmanned aerial vehicles (UAVs) operating in open-top scenarios
(e.g., collapsed buildings, roofless mazes), this paper proposes EAROL, a novel
framework with a downward-mounted tilted LiDAR configuration (20{\deg}
inclination), integrating a LiDAR-Inertial Odometry (LIO) system and a
hierarchical trajectory-yaw optimization algorithm. The hardware innovation
enables constraint enhancement via dense ground point cloud acquisition and
forward environmental awareness for dynamic obstacle detection. A
tightly-coupled LIO system, empowered by an Iterative Error-State Kalman Filter
(IESKF) with dynamic motion compensation, achieves high level 6-DoF
localization accuracy in feature-sparse environments. The planner, augmented by
environment, balancing environmental exploration, target tracking precision,
and energy efficiency. Physical experiments demonstrate 81% tracking error
reduction, 22% improvement in perceptual coverage, and near-zero vertical drift
across indoor maze and 60-meter-scale outdoor scenarios. This work proposes a
hardware-algorithm co-design paradigm, offering a robust solution for UAV
autonomy in post-disaster search and rescue missions. We will release our
software and hardware as an open-source package for the community. Video:
https://youtu.be/7av2ueLSiYw.

</details>


### [92] [TRUST-Planner: Topology-guided Robust Trajectory Planner for AAVs with Uncertain Obstacle Spatial-temporal Avoidance](https://arxiv.org/abs/2508.14610)
*Junzhi Li,Teng Long,Jingliang Sun,Jianxin Zhong*

Main category: cs.RO

TL;DR: TRUST-Planner是一种拓扑引导的分层规划框架，用于解决复杂动态环境中的局部最小值和死锁问题，提高避障成功率。


<details>
  <summary>Details</summary>
Motivation: 现有AAV运动规划框架在复杂动态环境中面临局部最小值和死锁问题，增加了碰撞风险。

Method: 前端使用DEV-PRM快速探索全局路径，后端结合UTF-MINCO和DDF实现高效预测避障和并行计算，并引入多分支轨迹管理框架优化决策。

Result: 仿真显示TRUST-Planner在复杂环境中成功率达96%，计算效率达毫秒级，实际实验验证了其可行性。

Conclusion: TRUST-Planner显著提升了AAV在动态环境中的避障能力和计算效率。

Abstract: Despite extensive developments in motion planning of autonomous aerial
vehicles (AAVs), existing frameworks faces the challenges of local minima and
deadlock in complex dynamic environments, leading to increased collision risks.
To address these challenges, we present TRUST-Planner, a topology-guided
hierarchical planning framework for robust spatial-temporal obstacle avoidance.
In the frontend, a dynamic enhanced visible probabilistic roadmap (DEV-PRM) is
proposed to rapidly explore topological paths for global guidance. The backend
utilizes a uniform terminal-free minimum control polynomial (UTF-MINCO) and
dynamic distance field (DDF) to enable efficient predictive obstacle avoidance
and fast parallel computation. Furthermore, an incremental multi-branch
trajectory management framework is introduced to enable spatio-temporal
topological decision-making, while efficiently leveraging historical
information to reduce replanning time. Simulation results show that
TRUST-Planner outperforms baseline competitors, achieving a 96\% success rate
and millisecond-level computation efficiency in tested complex environments.
Real-world experiments further validate the feasibility and practicality of the
proposed method.

</details>


### [93] [Can LLM Agents Solve Collaborative Tasks? A Study on Urgency-Aware Planning and Coordination](https://arxiv.org/abs/2508.14635)
*João Vitor de Carvalho Silva,Douglas G. Macharet*

Main category: cs.RO

TL;DR: 研究探讨了LLM在多智能体协作任务中的表现，特别是在资源分配和优先级规划方面的能力。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在复杂多智能体协作任务中的潜力，尤其是在需要分工和优先级规划的场景。

Method: 使用LLM代理在已知图环境中执行救援任务，评估其协调能力。

Result: 通过协调敏感指标（如任务成功率、冗余行动等）系统评估LLM表现。

Conclusion: 揭示了LLM在物理多智能体协作中的优势和失败模式，为未来基准和架构改进提供参考。

Abstract: The ability to coordinate actions across multiple agents is critical for
solving complex, real-world problems. Large Language Models (LLMs) have shown
strong capabilities in communication, planning, and reasoning, raising the
question of whether they can also support effective collaboration in
multi-agent settings. In this work, we investigate the use of LLM agents to
solve a structured victim rescue task that requires division of labor,
prioritization, and cooperative planning. Agents operate in a fully known
graph-based environment and must allocate resources to victims with varying
needs and urgency levels. We systematically evaluate their performance using a
suite of coordination-sensitive metrics, including task success rate, redundant
actions, room conflicts, and urgency-weighted efficiency. This study offers new
insights into the strengths and failure modes of LLMs in physically grounded
multi-agent collaboration tasks, contributing to future benchmarks and
architectural improvements.

</details>


### [94] [An Informative Planning Framework for Target Tracking and Active Mapping in Dynamic Environments with ASVs](https://arxiv.org/abs/2508.14636)
*Sanjeev Ramkumar Sudha,Marija Popović,Erlend M. Coates*

Main category: cs.RO

TL;DR: 提出了一种用于动态环境中移动目标跟踪的信息路径规划框架，结合时空预测网络和自适应规划目标，提升了跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 动态环境中漂浮目标的主动映射是一个挑战性问题，涉及预测空间和时间变化。

Method: 采用时空预测网络预测目标位置分布，并提出自适应规划目标。

Result: 仿真和实地测试表明，该方法优于仅考虑熵减少的现有方法。

Conclusion: 该方法在真实监测场景中有效，适用于动态环境中的目标跟踪。

Abstract: Mobile robot platforms are increasingly being used to automate information
gathering tasks such as environmental monitoring. Efficient target tracking in
dynamic environments is critical for applications such as search and rescue and
pollutant cleanups. In this letter, we study active mapping of floating targets
that drift due to environmental disturbances such as wind and currents. This is
a challenging problem as it involves predicting both spatial and temporal
variations in the map due to changing conditions. We propose an informative
path planning framework to map an arbitrary number of moving targets with
initially unknown positions in dynamic environments. A key component of our
approach is a spatiotemporal prediction network that predicts target position
distributions over time. We propose an adaptive planning objective for target
tracking that leverages these predictions. Simulation experiments show that our
proposed planning objective improves target tracking performance compared to
existing methods that consider only entropy reduction as the planning
objective. Finally, we validate our approach in field tests using an autonomous
surface vehicle, showcasing its ability to track targets in real-world
monitoring scenarios.

</details>


### [95] [Consistent Pose Estimation of Unmanned Ground Vehicles through Terrain-Aided Multi-Sensor Fusion on Geometric Manifolds](https://arxiv.org/abs/2508.14661)
*Alexander Raab,Stephan Weiss,Alessandro Fornasier,Christian Brommer,Abdalrahman Ibrahim*

Main category: cs.RO

TL;DR: 提出了一种基于流形误差状态的扩展卡尔曼滤波器（M-ESEKF），用于提高地面车辆定位的长期准确性。


<details>
  <summary>Details</summary>
Motivation: 传统扩展卡尔曼滤波器在复杂地面环境下可能因维度问题导致性能下降，需要改进。

Method: 通过降维表示机器人位姿，避免人为约束，并引入新的校正方案以嵌入领域知识。

Result: M-ESEKF在多样场景和动态传感器配置下表现出更高的稳定性和一致性，且无需场景特定调参。

Conclusion: M-ESEKF是一种通用且高效的定位滤波器，适用于实际应用。

Abstract: Aiming to enhance the consistency and thus long-term accuracy of Extended
Kalman Filters for terrestrial vehicle localization, this paper introduces the
Manifold Error State Extended Kalman Filter (M-ESEKF). By representing the
robot's pose in a space with reduced dimensionality, the approach ensures
feasible estimates on generic smooth surfaces, without introducing artificial
constraints or simplifications that may degrade a filter's performance. The
accompanying measurement models are compatible with common loosely- and
tightly-coupled sensor modalities and also implicitly account for the ground
geometry. We extend the formulation by introducing a novel correction scheme
that embeds additional domain knowledge into the sensor data, giving more
accurate uncertainty approximations and further enhancing filter consistency.
The proposed estimator is seamlessly integrated into a validated modular state
estimation framework, demonstrating compatibility with existing
implementations. Extensive Monte Carlo simulations across diverse scenarios and
dynamic sensor configurations show that the M-ESEKF outperforms classical
filter formulations in terms of consistency and stability. Moreover, it
eliminates the need for scenario-specific parameter tuning, enabling its
application in a variety of real-world settings.

</details>


### [96] [Safe and Transparent Robots for Human-in-the-Loop Meat Processing](https://arxiv.org/abs/2508.14763)
*Sagar Parekh,Casey Grothoff,Ryan Wright,Robin White,Dylan P. Losey*

Main category: cs.RO

TL;DR: 开发了一种通用机器人框架，用于肉类加工，确保安全性和透明度。


<details>
  <summary>Details</summary>
Motivation: 解决肉类加工行业劳动力短缺问题，同时提升自动化技术的灵活性和成本效益。

Method: 通过手部检测系统和力传感器确保安全；利用LED和图形界面提高透明度。

Result: 验证了框架在安全操作和工人理解机器人行为方面的有效性。

Conclusion: 该框架成功实现了安全协作和透明度，适用于肉类加工行业。

Abstract: Labor shortages have severely affected the meat processing sector. Automated
technology has the potential to support the meat industry, assist workers, and
enhance job quality. However, existing automation in meat processing is highly
specialized, inflexible, and cost intensive. Instead of forcing manufacturers
to buy a separate device for each step of the process, our objective is to
develop general-purpose robotic systems that work alongside humans to perform
multiple meat processing tasks. Through a recently conducted survey of industry
experts, we identified two main challenges associated with integrating these
collaborative robots alongside human workers. First, there must be measures to
ensure the safety of human coworkers; second, the coworkers need to understand
what the robot is doing. This paper addresses both challenges by introducing a
safety and transparency framework for general-purpose meat processing robots.
For safety, we implement a hand-detection system that continuously monitors
nearby humans. This system can halt the robot in situations where the human
comes into close proximity of the operating robot. We also develop an
instrumented knife equipped with a force sensor that can differentiate contact
between objects such as meat, bone, or fixtures. For transparency, we introduce
a method that detects the robot's uncertainty about its performance and uses an
LED interface to communicate that uncertainty to the human. Additionally, we
design a graphical interface that displays the robot's plans and allows the
human to provide feedback on the planned cut. Overall, our framework can ensure
safe operation while keeping human workers in-the-loop about the robot's
actions which we validate through a user study.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [97] [Deep Learning for School Dropout Detection: A Comparison of Tabular and Graph-Based Models for Predicting At-Risk Students](https://arxiv.org/abs/2508.14057)
*Pablo G. Almeida,Guilherme A. L. Silva,Valéria Santos,Gladston Moreira,Pedro Silva,Eduardo Luz*

Main category: cs.LG

TL;DR: 研究探讨了将表格学生数据转换为图结构（通过聚类技术）是否能提升辍学预测准确性，发现特定GNN配置（GraphSAGE结合PCA-KMeans图）优于传统表格模型，但其他配置效果不一。


<details>
  <summary>Details</summary>
Motivation: 学生辍学是全球教育系统的重大挑战，预测高风险学生可及时干预。GNN可能通过捕捉学生数据中的复杂关系提升预测效果。

Method: 将表格数据转换为图结构（使用K-Means、HDBSCAN等聚类算法和PCA、UMAP降维技术），比较GNN（GCN、GraphSAGE）与传统表格模型（RF、XGBoost、TabNet）的性能。

Result: GraphSAGE结合PCA-KMeans图的配置表现最佳，宏F1分数提升约7%，准确率提升近2%，但其他GNN配置效果不稳定。

Conclusion: GNN在辍学预测中具有潜力，但图生成策略和架构选择至关重要，需进一步优化。

Abstract: Student dropout is a significant challenge in educational systems worldwide,
leading to substantial social and economic costs. Predicting students at risk
of dropout allows for timely interventions. While traditional Machine Learning
(ML) models operating on tabular data have shown promise, Graph Neural Networks
(GNNs) offer a potential advantage by capturing complex relationships inherent
in student data if structured as graphs. This paper investigates whether
transforming tabular student data into graph structures, primarily using
clustering techniques, enhances dropout prediction accuracy. We compare the
performance of GNNs (a custom Graph Convolutional Network (GCN) and GraphSAGE)
on these generated graphs against established tabular models (Random Forest
(RF), XGBoost, and TabNet) using a real-world student dataset. Our experiments
explore various graph construction strategies based on different clustering
algorithms (K-Means, HDBSCAN) and dimensionality reduction techniques
(Principal Component Analysis (PCA), Uniform Manifold Approximation and
Projection (UMAP)). Our findings demonstrate that a specific GNN configuration,
GraphSAGE on a graph derived from PCA-KMeans clustering, achieved superior
performance, notably improving the macro F1-score by approximately 7 percentage
points and accuracy by nearly 2 percentage points over the strongest tabular
baseline (XGBoost). However, other GNN configurations and graph construction
methods did not consistently surpass tabular models, emphasizing the critical
role of the graph generation strategy and GNN architecture selection. This
highlights both the potential of GNNs and the challenges in optimally
transforming tabular data for graph-based learning in this domain.

</details>


### [98] [Load Forecasting on A Highly Sparse Electrical Load Dataset Using Gaussian Interpolation](https://arxiv.org/abs/2508.14069)
*Chinmoy Biswas,Nafis Faisal,Vivek Chowdhury,Abrar Al-Shadid Abir,Sabir Mahmud,Mithon Rahman,Shaikh Anowarul Fattah,Hafiz Imtiaz*

Main category: cs.LG

TL;DR: 论文研究了高斯插值在电力负荷预测中的应用，证明了其在处理稀疏数据时的有效性，并发现LSTM模型表现最佳。


<details>
  <summary>Details</summary>
Motivation: 稀疏数据在现实数据集中常见，传统插值方法适用于严格平稳数据，但本文探讨了高斯插值在宽平稳数据中的适用性。

Method: 对电力负荷数据进行统计分析，使用高斯插值处理稀疏数据，并训练多种机器学习和深度学习模型进行比较。

Result: 高斯插值适用于负荷预测问题，且LSTM模型在多种模型中表现最优。

Conclusion: 高斯插值是处理稀疏数据的有效方法，LSTM模型在负荷预测中表现最佳。

Abstract: Sparsity, defined as the presence of missing or zero values in a dataset,
often poses a major challenge while operating on real-life datasets. Sparsity
in features or target data of the training dataset can be handled using various
interpolation methods, such as linear or polynomial interpolation, spline,
moving average, or can be simply imputed. Interpolation methods usually perform
well with Strict Sense Stationary (SSS) data. In this study, we show that an
approximately 62\% sparse dataset with hourly load data of a power plant can be
utilized for load forecasting assuming the data is Wide Sense Stationary (WSS),
if augmented with Gaussian interpolation. More specifically, we perform
statistical analysis on the data, and train multiple machine learning and deep
learning models on the dataset. By comparing the performance of these models,
we empirically demonstrate that Gaussian interpolation is a suitable option for
dealing with load forecasting problems. Additionally, we demonstrate that Long
Short-term Memory (LSTM)-based neural network model offers the best performance
among a diverse set of classical and neural network-based models.

</details>


### [99] [Edge-Selector Model Applied for Local Search Neighborhood for Solving Vehicle Routing Problems](https://arxiv.org/abs/2508.14071)
*Bachtiar Herdianto,Romain Billot,Flavien Lucas,Marc Sevaux,Daniele Vigo*

Main category: cs.LG

TL;DR: 提出了一种结合机器学习和元启发式的混合机制，用于解决车辆路径问题（VRP），通过边缘解选择器模型指导搜索过程。


<details>
  <summary>Details</summary>
Motivation: 传统元启发式方法在解决VRP时可能效率不足，需要更智能的搜索引导机制。

Method: 使用基于表格的二元分类器和图神经网络（GNN）开发边缘选择器，结合梯度提升树和前馈神经网络。

Result: 方法在多种基准测试中表现出可扩展性和通用性，性能优于现有元启发式方法。

Conclusion: 混合机制显著提升了VRP求解效率，适用于大规模和复杂变体问题。

Abstract: This research proposes a hybrid Machine Learning and metaheuristic mechanism
that is designed to solve Vehicle Routing Problems (VRPs). The main of our
method is an edge solution selector model, which classifies solution edges to
identify prohibited moves during the local search, hence guiding the search
process within metaheuristic baselines. Two learning-based mechanisms are used
to develop the edge selector: a simple tabular binary classifier and a Graph
Neural Network (GNN). The tabular classifier employs Gradient Boosting Trees
and Feedforward Neural Network as the baseline algorithms. Adjustments to the
decision threshold are also applied to handle the class imbalance in the
problem instance. An alternative mechanism employs the GNN to utilize graph
structure for direct solution edge prediction, with the objective of guiding
local search by predicting prohibited moves. These hybrid mechanisms are then
applied in state-fo-the-art metaheuristic baselines. Our method demonstrates
both scalability and generalizability, achieving performance improvements
across different baseline metaheuristics, various problem sizes and variants,
including the Capacitated Vehicle Routing Problem (CVRP) and CVRP with Time
Windows (CVRPTW). Experimental evaluations on benchmark datasets up to 30,000
customer nodes, supported by pair-wise statistical analysis, verify the
observed improvements.

</details>


### [100] [Multi-Objective Bayesian Optimization with Independent Tanimoto Kernel Gaussian Processes for Diverse Pareto Front Exploration](https://arxiv.org/abs/2508.14072)
*Anabel Yong*

Main category: cs.LG

TL;DR: GP-MOBO是一种新型多目标贝叶斯优化算法，用于分子优化，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决分子优化中多目标优化的挑战，提升效率和效果。

Method: 结合快速精确高斯过程（GPs）处理稀疏分子指纹的全维度。

Result: 在DockSTRING数据集中表现优异，几何平均值更高。

Conclusion: GP-MOBO在多目标优化中高效且有效，计算开销低。

Abstract: We present GP-MOBO, a novel multi-objective Bayesian Optimization algorithm
that advances the state-of-the-art in molecular optimization. Our approach
integrates a fast minimal package for Exact Gaussian Processes (GPs) capable of
efficiently handling the full dimensionality of sparse molecular fingerprints
without the need for extensive computational resources. GP-MOBO consistently
outperforms traditional methods like GP-BO by fully leveraging fingerprint
dimensionality, leading to the identification of higher-quality and valid
SMILES. Moreover, our model achieves a broader exploration of the chemical
search space, as demonstrated by its superior proximity to the Pareto front in
all tested scenarios. Empirical results from the DockSTRING dataset reveal that
GP-MOBO yields higher geometric mean values across 20 Bayesian optimization
iterations, underscoring its effectiveness and efficiency in addressing complex
multi-objective optimization challenges with minimal computational overhead.

</details>


### [101] [MCLPD:Multi-view Contrastive Learning for EEG-based PD Detection Across Datasets](https://arxiv.org/abs/2508.14073)
*Qian Zhanga,Ruilin Zhang,Jun Xiao,Yifan Liu,Zhe Wang*

Main category: cs.LG

TL;DR: 提出了一种半监督学习框架MCLPD，通过多视图对比预训练和轻量级监督微调，提升跨数据集帕金森病检测性能。


<details>
  <summary>Details</summary>
Motivation: EEG数据标注成本高导致数据集小且差异大，影响模型在跨数据集检测中的鲁棒性和泛化性。

Method: 结合自监督学习（使用未标记数据）和轻量级监督微调（少量标记数据），通过时间和频域双重增强构建对比对。

Result: 仅用1%标记数据在UI和UC数据集上F1分数分别达0.91和0.81，5%标记数据时提升至0.97和0.87。

Conclusion: MCLPD显著减少对标记数据的依赖，同时提升跨数据集泛化能力，验证了框架的有效性。

Abstract: Electroencephalography has been validated as an effective technique for
detecting Parkinson's disease,particularly in its early stages.However,the high
cost of EEG data annotation often results in limited dataset size and
considerable discrepancies across datasets,including differences in acquisition
protocols and subject demographics,significantly hinder the robustness and
generalizability of models in cross-dataset detection scenarios.To address such
challenges,this paper proposes a semi-supervised learning framework named
MCLPD,which integrates multi-view contrastive pre-training with lightweight
supervised fine-tuning to enhance cross-dataset PD detection performance.During
pre-training,MCLPD uses self-supervised learning on the unlabeled UNM
dataset.To build contrastive pairs,it applies dual augmentations in both time
and frequency domains,which enrich the data and naturally fuse time-frequency
information.In the fine-tuning phase,only a small proportion of labeled data
from another two datasets (UI and UC)is used for supervised
optimization.Experimental results show that MCLPD achieves F1 scores of 0.91 on
UI and 0.81 on UC using only 1%of labeled data,which further improve to 0.97
and 0.87,respectively,when 5%of labeled data is used.Compared to existing
methods,MCLPD substantially improves cross-dataset generalization while
reducing the dependency on labeled data,demonstrating the effectiveness of the
proposed framework.

</details>


### [102] [GEPD:GAN-Enhanced Generalizable Model for EEG-Based Detection of Parkinson's Disease](https://arxiv.org/abs/2508.14074)
*Qian Zhang,Ruilin Zhang,Biaokai Zhu,Xun Han,Jun Xiao,Yifan Liu,Zhe Wang*

Main category: cs.LG

TL;DR: 论文提出了一种名为GEPD的GAN增强通用模型，用于基于EEG的跨数据集帕金森病分类，解决了现有方法在不同数据集间泛化能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有帕金森病检测方法在单个数据集中表现良好，但在跨数据集场景下因数据差异和小样本问题难以泛化。

Method: 设计了生成网络生成融合EEG数据，并引入信号质量评估模型；分类网络结合多卷积神经网络捕捉EEG信号的时频特征。

Result: 模型在跨数据集设置下达到84.3%的准确率和84.0%的F1分数，表现与先进模型相当。

Conclusion: GEPD模型展示了良好的泛化能力，为神经疾病的诊断和监测提供了智能方法。

Abstract: Electroencephalography has been established as an effective method for
detecting Parkinson's disease, typically diagnosed early.Current Parkinson's
disease detection methods have shown significant success within individual
datasets, however, the variability in detection methods across different EEG
datasets and the small size of each dataset pose challenges for training a
generalizable model for cross-dataset scenarios. To address these issues, this
paper proposes a GAN-enhanced generalizable model, named GEPD, specifically for
EEG-based cross-dataset classification of Parkinson's disease.First, we design
a generative network that creates fusion EEG data by controlling the
distribution similarity between generated data and real data.In addition, an
EEG signal quality assessment model is designed to ensure the quality of
generated data great.Second, we design a classification network that utilizes a
combination of multiple convolutional neural networks to effectively capture
the time-frequency characteristics of EEG signals, while maintaining a
generalizable structure and ensuring easy convergence.This work is dedicated to
utilizing intelligent methods to study pathological manifestations, aiming to
facilitate the diagnosis and monitoring of neurological diseases.The evaluation
results demonstrate that our model performs comparably to state-of-the-art
models in cross-dataset settings, achieving an accuracy of 84.3% and an
F1-score of 84.0%, showcasing the generalizability of the proposed model.

</details>


### [103] [Explainable Graph Spectral Clustering For Text Embeddings](https://arxiv.org/abs/2508.14075)
*Mieczysław A. Kłopotek,Sławomir T. Wierzchoń,Bartłomiej Starosta,Piotr Borkowski,Dariusz Czerski,Eryk Laskowski*

Main category: cs.LG

TL;DR: 本文扩展了之前关于图谱聚类可解释性的研究，考虑了其他文档嵌入方法，特别是基于GloVe的嵌入。


<details>
  <summary>Details</summary>
Motivation: 之前的研究仅基于词向量空间的余弦相似性，本文旨在探索其他嵌入方法（如GloVe）对图谱聚类结果可解释性的影响。

Method: 通过引入GloVe等嵌入方法，扩展了文档相似性计算的方式，并分析其对图谱聚类结果的影响。

Result: 研究表明，不同的嵌入方法（如GloVe）可以改进图谱聚类的可解释性。

Conclusion: 本文证明了嵌入方法的选择对图谱聚类的可解释性有重要影响，为未来研究提供了新的方向。

Abstract: In a previous paper, we proposed an introduction to the explainability of
Graph Spectral Clustering results for textual documents, given that document
similarity is computed as cosine similarity in term vector space.
  In this paper, we generalize this idea by considering other embeddings of
documents, in particular, based on the GloVe embedding idea.

</details>


### [104] [PersRM-R1: Enhance Personalized Reward Modeling with Reinforcement Learning](https://arxiv.org/abs/2508.14076)
*Mengdi Li,Guanqiao Chen,Xufeng Zhao,Haochen Wen,Shu Yang,Di Wang*

Main category: cs.LG

TL;DR: PersRM-R1是一个基于推理的奖励建模框架，旨在通过少量个人示例捕捉用户特定偏好，优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有奖励模型难以在有限数据和多样化领域中捕捉用户特定的细微偏好。

Method: 结合合成数据生成和两阶段训练流程（监督微调+强化微调）。

Result: PersRM-R1在准确性和泛化性上优于类似规模模型，媲美更大模型。

Conclusion: PersRM-R1为更有效的个性化LLM铺平了道路。

Abstract: Reward models (RMs), which are central to existing post-training methods, aim
to align LLM outputs with human values by providing feedback signals during
fine-tuning. However, existing RMs struggle to capture nuanced, user-specific
preferences, especially under limited data and across diverse domains. Thus, we
introduce PersRM-R1, the first reasoning-based reward modeling framework
specifically designed to identify and represent personal factors from only one
or a few personal exemplars. To address challenges including limited data
availability and the requirement for robust generalization, our approach
combines synthetic data generation with a two-stage training pipeline
consisting of supervised fine-tuning followed by reinforcement fine-tuning.
Experimental results demonstrate that PersRM-R1 outperforms existing models of
similar size and matches the performance of much larger models in both accuracy
and generalizability, paving the way for more effective personalized LLMs.

</details>


### [105] [Label Smoothing is a Pragmatic Information Bottleneck](https://arxiv.org/abs/2508.14077)
*Sota Kudo*

Main category: cs.LG

TL;DR: 标签平滑通过信息瓶颈的形式被重新研究，展示了其在模型输出中探索最优解的能力。


<details>
  <summary>Details</summary>
Motivation: 研究标签平滑与信息瓶颈的关系，探索其在实际应用中的简单实现和优势。

Method: 通过理论和实验验证标签平滑在信息瓶颈中的最优解探索能力。

Result: 标签平滑表现出对无关信息不敏感的特性，符合信息瓶颈方法的特点。

Conclusion: 标签平滑可视为信息瓶颈的实用方法，具有简单实现和对无关信息不敏感的优势。

Abstract: This study revisits label smoothing via a form of information bottleneck.
Under the assumption of sufficient model flexibility and no conflicting labels
for the same input, we theoretically and experimentally demonstrate that the
model output obtained through label smoothing explores the optimal solution of
the information bottleneck. Based on this, label smoothing can be interpreted
as a practical approach to the information bottleneck, enabling simple
implementation. As an information bottleneck method, we experimentally show
that label smoothing also exhibits the property of being insensitive to factors
that do not contain information about the target, or to factors that provide no
additional information about it when conditioned on another variable.

</details>


### [106] [Out-of-Sample Hydrocarbon Production Forecasting: Time Series Machine Learning using Productivity Index-Driven Features and Inductive Conformal Prediction](https://arxiv.org/abs/2508.14078)
*Mohamed Hassan Abdalla Idris,Jakub Marek Cebula,Jebraeel Gholinezhad,Shamsul Masum,Hongjie Ma*

Main category: cs.LG

TL;DR: 提出了一种结合生产力指数特征选择和归纳共形预测的机器学习框架，用于提高油气产量预测的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决多变量时间序列分析中样本外预测的不确定性问题，提升油气产量预测的可靠性。

Method: 整合生产力指数特征选择和归纳共形预测，评估LSTM、BiLSTM、GRU和XGBoost等模型。

Result: LSTM表现最佳，测试集和样本外预测的MAE最低，分别为19.468和29.638。

Conclusion: 结合领域知识和先进ML技术可显著提升油气产量预测的可靠性。

Abstract: This research introduces a new ML framework designed to enhance the
robustness of out-of-sample hydrocarbon production forecasting, specifically
addressing multivariate time series analysis. The proposed methodology
integrates Productivity Index (PI)-driven feature selection, a concept derived
from reservoir engineering, with Inductive Conformal Prediction (ICP) for
rigorous uncertainty quantification. Utilizing historical data from the Volve
(wells PF14, PF12) and Norne (well E1H) oil fields, this study investigates the
efficacy of various predictive algorithms-namely Long Short-Term Memory (LSTM),
Bidirectional LSTM (BiLSTM), Gated Recurrent Unit (GRU), and eXtreme Gradient
Boosting (XGBoost) - in forecasting historical oil production rates (OPR_H).
All the models achieved "out-of-sample" production forecasts for an upcoming
future timeframe. Model performance was comprehensively evaluated using
traditional error metrics (e.g., MAE) supplemented by Forecast Bias and
Prediction Direction Accuracy (PDA) to assess bias and trend-capturing
capabilities. The PI-based feature selection effectively reduced input
dimensionality compared to conventional numerical simulation workflows. The
uncertainty quantification was addressed using the ICP framework, a
distribution-free approach that guarantees valid prediction intervals (e.g.,
95% coverage) without reliance on distributional assumptions, offering a
distinct advantage over traditional confidence intervals, particularly for
complex, non-normal data. Results demonstrated the superior performance of the
LSTM model, achieving the lowest MAE on test (19.468) and genuine out-of-sample
forecast data (29.638) for well PF14, with subsequent validation on Norne well
E1H. These findings highlight the significant potential of combining
domain-specific knowledge with advanced ML techniques to improve the
reliability of hydrocarbon production forecasts.

</details>


### [107] [A Guide to Robust Generalization: The Impact of Architecture, Pre-training, and Optimization Strategy](https://arxiv.org/abs/2508.14079)
*Maxime Heuillet,Rishika Bhagwatkar,Jonas Ngnawé,Yann Pequignot,Alexandre Larouche,Christian Gagné,Irina Rish,Ola Ahmad,Audrey Durand*

Main category: cs.LG

TL;DR: 论文研究了深度学习中图像模型的鲁棒微调方法，通过大规模实验验证了不同设计选择对鲁棒泛化能力的影响。


<details>
  <summary>Details</summary>
Motivation: 探讨如何通过微调预训练模型来提高其对输入扰动的鲁棒性，解决现有方法在设计和选择上的不确定性。

Method: 使用6个数据集、40种预训练架构、2种专用损失函数和3种适应协议，进行了1,440种训练配置和7,200次鲁棒性测量。

Result: 发现监督式预训练的卷积神经网络在大型数据集上表现最佳，挑战了当前流行的注意力架构和鲁棒预训练表示的优势。

Conclusion: 研究为鲁棒微调提供了实践指导，并指出了未来研究方向，强调了传统方法在某些情况下的优越性。

Abstract: Deep learning models operating in the image domain are vulnerable to small
input perturbations. For years, robustness to such perturbations was pursued by
training models from scratch (i.e., with random initializations) using
specialized loss objectives. Recently, robust fine-tuning has emerged as a more
efficient alternative: instead of training from scratch, pretrained models are
adapted to maximize predictive performance and robustness. To conduct robust
fine-tuning, practitioners design an optimization strategy that includes the
model update protocol (e.g., full or partial) and the specialized loss
objective. Additional design choices include the architecture type and size,
and the pretrained representation. These design choices affect robust
generalization, which is the model's ability to maintain performance when
exposed to new and unseen perturbations at test time. Understanding how these
design choices influence generalization remains an open question with
significant practical implications. In response, we present an empirical study
spanning 6 datasets, 40 pretrained architectures, 2 specialized losses, and 3
adaptation protocols, yielding 1,440 training configurations and 7,200
robustness measurements across five perturbation types. To our knowledge, this
is the most diverse and comprehensive benchmark of robust fine-tuning to date.
While attention-based architectures and robust pretrained representations are
increasingly popular, we find that convolutional neural networks pretrained in
a supervised manner on large datasets often perform best. Our analysis both
confirms and challenges prior design assumptions, highlighting promising
research directions and offering practical guidance.

</details>


### [108] [KnowDR-REC: A Benchmark for Referring Expression Comprehension with Real-World Knowledge](https://arxiv.org/abs/2508.14080)
*Guanghao Jin,Jingpei Wu,Tianpei Guo,Yiyi Niu,Weidong Zhou,Guoyang Liu*

Main category: cs.LG

TL;DR: KnowDR-REC是一个新的REC基准，强调知识驱动的多模态推理，包含负样本和新的评估指标，揭示现有MLLMs在知识驱动任务中的不足。


<details>
  <summary>Details</summary>
Motivation: 传统REC基准缺乏对多模态大语言模型（MLLMs）推理能力的评估，需要更细粒度和知识驱动的任务。

Method: 提出KnowDR-REC基准，基于真实知识构建，包含细粒度负样本和三个新评估指标。

Result: 实验显示现有MLLMs在知识驱动任务中表现不佳，且存在文本理解与视觉定位的脱节问题。

Conclusion: KnowDR-REC有望推动更鲁棒、可解释和知识密集的多模态系统发展。

Abstract: Referring Expression Comprehension (REC) is a popular multimodal task that
aims to accurately detect target objects within a single image based on a given
textual expression. However, due to the limitations of earlier models,
traditional REC benchmarks either rely solely on intra-image cues or lack
sufficiently fine-grained instance annotations, making them inadequate for
evaluating the reasoning capabilities of Multi-modal Large Language Models
(MLLMs). To address this gap, we propose a new benchmark, KnowDR-REC,
characterized by three key features: Firstly, it is built upon real-world
knowledge, requiring fine-grained multimodal reasoning across text and image.
Secondly, the dataset includes elaborately constructed negative samples via
fine-grained expression editing, designed to evaluate a model's robustness and
anti-hallucination ability. Lastly, we introduce three novel evaluation metrics
to systematically explore the model's internal reasoning process. We evaluate
16 state-of-the-art multimodal models on KnowDR-REC, with experimental results
showing that existing MLLMs still struggle with knowledge-driven visual
grounding tasks. Furthermore, we observe a decoupling between textual
understanding and visual grounding in MLLMs, where many models are
significantly influenced by memorized shortcut correlations, which severely
affect their behavior on our benchmark and hinder genuine multimodal reasoning.
We anticipate that the proposed benchmark will inspire future research towards
developing more robust, interpretable, and knowledge-intensive visual grounding
frameworks, driving the development of more reliable and robust multimodal
systems for complex real-world scenarios.

</details>


### [109] [Toward Lifelong Learning in Equilibrium Propagation: Sleep-like and Awake Rehearsal for Enhanced Stability](https://arxiv.org/abs/2508.14081)
*Yoshimasa Kubo,Jean Erik Delanois,Maxim Bazhenov*

Main category: cs.LG

TL;DR: 提出了一种睡眠式回放巩固（SRC）算法，用于解决EP训练的RNN在持续学习中的灾难性遗忘问题，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 人类大脑通过睡眠中的记忆回放巩固知识，而RNN在持续学习中容易发生灾难性遗忘，因此需要类似机制来提升其学习能力。

Method: 在EP训练的RNN中引入睡眠式回放巩固（SRC）算法，并结合清醒回放（awake replay）技术。

Result: SRC显著提升了RNN在持续学习中的表现，在多个数据集上优于或与BPTT训练的模型相当。

Conclusion: 睡眠式回放技术可应用于RNN，展示了将人类学习行为整合到人工神经网络中的潜力。

Abstract: Recurrent neural networks (RNNs) trained using Equilibrium Propagation (EP),
a biologically plausible training algorithm, have demonstrated strong
performance in various tasks such as image classification and reinforcement
learning. However, these networks face a critical challenge in continuous
learning: catastrophic forgetting, where previously acquired knowledge is
overwritten when new tasks are learned. This limitation contrasts with the
human brain's ability to retain and integrate both old and new knowledge, aided
by processes like memory consolidation during sleep through the replay of
learned information. To address this challenge in RNNs, here we propose a
sleep-like replay consolidation (SRC) algorithm for EP-trained RNNs. We found
that SRC significantly improves RNN's resilience to catastrophic forgetting in
continuous learning scenarios. In class-incremental learning with SRC
implemented after each new task training, the EP-trained multilayer RNN model
(MRNN-EP) performed significantly better compared to feedforward networks
incorporating several well-established regularization techniques. The MRNN-EP
performed on par with MRNN trained using Backpropagation Through Time (BPTT)
when both were equipped with SRC on MNIST data and surpassed BPTT-based models
on the Fashion MNIST, Kuzushiji-MNIST, CIFAR10, and ImageNet datasets.
Combining SRC with rehearsal, also known as "awake replay", further boosted the
network's ability to retain long-term knowledge while continuing to learn new
tasks. Our study reveals the applicability of sleep-like replay techniques to
RNNs and highlights the potential for integrating human-like learning behaviors
into artificial neural networks (ANNs).

</details>


### [110] [Toward Generalist Semi-supervised Regression via Decoupled Representation Distillation](https://arxiv.org/abs/2508.14082)
*Ye Su,Hezhe Qiao,Wei Huang,Lin Chen*

Main category: cs.LG

TL;DR: DRILL框架通过将回归任务转化为离散分布估计任务，解决了半监督回归中伪标签质量依赖和过拟合问题。


<details>
  <summary>Details</summary>
Motivation: 现有半监督回归方法依赖伪标签质量且易过拟合，需改进。

Method: 提出DRILL框架，将回归任务转化为离散分布估计任务，并采用解耦分布对齐方法。

Result: DRILL在多个领域数据集上表现优于现有方法。

Conclusion: DRILL有效提升了半监督回归的泛化能力。

Abstract: Semi-supervised regression (SSR), which aims to predict continuous scores of
samples while reducing reliance on a large amount of labeled data, has recently
received considerable attention across various applications, including computer
vision, natural language processing, and audio and medical analysis. Existing
semi-supervised methods typically apply consistency regularization on the
general regression task by generating pseudo-labels. However, these methods
heavily rely on the quality of pseudo-labels, and direct regression fails to
learn the label distribution and can easily lead to overfitting. To address
these challenges, we introduce an end-to-end Decoupled Representation
distillation framework (DRILL) which is specially designed for the
semi-supervised regression task where we transform the general regression task
into a Discrete Distribution Estimation (DDE) task over multiple buckets to
better capture the underlying label distribution and mitigate the risk of
overfitting associated with direct regression. Then we employ the Decoupled
Distribution Alignment (DDA) to align the target bucket and non-target bucket
between teacher and student on the distribution of buckets, encouraging the
student to learn more robust and generalized knowledge from the teacher.
Extensive experiments conducted on datasets from diverse domains demonstrate
that the proposed DRILL has strong generalization and outperforms the competing
methods.

</details>


### [111] [GeoMAE: Masking Representation Learning for Spatio-Temporal Graph Forecasting with Missing Values](https://arxiv.org/abs/2508.14083)
*Songyu Ke,Chenyu Wu,Yuxuan Liang,Xiuwen Yi,Yanping Sun,Junbo Zhang,Yu Zheng*

Main category: cs.LG

TL;DR: 论文提出了一种自监督图表示学习框架（CSST），用于从低质量数据中推断POI的精确人流。


<details>
  <summary>Details</summary>
Motivation: 由于城市感知技术的限制，现有数据质量不足以监测每个POI的人流，且面临标记数据稀缺、时空依赖复杂和GPS报告与精确人流关联多样等挑战。

Method: 通过构建空间邻接图，利用对比学习技术处理大量未标记时空数据，采用交换预测方法预训练模型，最后用精确人流数据微调。

Result: 在两个真实数据集上的实验表明，CSST在大量噪声数据上预训练的模型表现优于从头训练的模型。

Conclusion: CSST框架有效解决了低质量数据下人流推断的挑战，为交通管理和城市规划提供了可靠工具。

Abstract: Accurate acquisition of crowd flow at Points of Interest (POIs) is pivotal
for effective traffic management, public service, and urban planning. Despite
this importance, due to the limitations of urban sensing techniques, the data
quality from most sources is inadequate for monitoring crowd flow at each POI.
This renders the inference of accurate crowd flow from low-quality data a
critical and challenging task. The complexity is heightened by three key
factors: 1) \emph{The scarcity and rarity of labeled data}, 2) \emph{The
intricate spatio-temporal dependencies among POIs}, and 3) \emph{The myriad
correlations between precise crowd flow and GPS reports}.
  To address these challenges, we recast the crowd flow inference problem as a
self-supervised attributed graph representation learning task and introduce a
novel \underline{C}ontrastive \underline{S}elf-learning framework for
\underline{S}patio-\underline{T}emporal data (\model). Our approach initiates
with the construction of a spatial adjacency graph founded on the POIs and
their respective distances. We then employ a contrastive learning technique to
exploit large volumes of unlabeled spatio-temporal data. We adopt a swapped
prediction approach to anticipate the representation of the target subgraph
from similar instances. Following the pre-training phase, the model is
fine-tuned with accurate crowd flow data. Our experiments, conducted on two
real-world datasets, demonstrate that the \model pre-trained on extensive noisy
data consistently outperforms models trained from scratch.

</details>


### [112] [Parameter-Aware Ensemble SINDy for Interpretable Symbolic SGS Closure](https://arxiv.org/abs/2508.14085)
*Hanseul Kang,Shervin Karimkashi,Ville Vuorinen*

Main category: cs.LG

TL;DR: 提出了一种可扩展、参数感知的稀疏回归框架，用于从多参数模拟数据中发现可解释的偏微分方程和亚网格尺度闭合模型。


<details>
  <summary>Details</summary>
Motivation: 解决SINDy方法的局限性，通过创新方法提升模型识别能力。

Method: 采用符号参数化、维度相似性过滤、内存高效的Gram矩阵累积和集成共识系数稳定性分析。

Result: 在一维基准测试中可靠恢复控制方程，并在Burgers数据中发现Smagorinsky型闭合模型，预测精度优于经典方法。

Conclusion: 该框架为数据驱动的闭合模型发现提供了新方法，对湍流建模领域有重要贡献。

Abstract: We present a scalable, parameter-aware sparse regression framework for
discovering interpretable partial differential equations and subgrid-scale
closures from multi-parameter simulation data. Building on SINDy (Sparse
Identification of Nonlinear Dynamics), our approach addresses key limitations
through four innovations: symbolic parameterisation enabling physical
parameters to vary within unified regression; Dimensional Similarity Filter
enforcing unit-consistency whilst reducing candidate libraries;
memory-efficient Gram-matrix accumulation enabling batch processing; and
ensemble consensus with coefficient stability analysis for robust model
identification.
  Validation on canonical one-dimensional benchmarks demonstrates reliable
recovery of governing equations across parameter ranges. Applied to filtered
Burgers datasets, the framework discovers an SGS closure $\tau_{\mathrm{SGS}} =
0.1603\cdot\Delta^2\left(\frac{\partial \bar{u}}{\partial x}\right)^2$,
corresponding to a Smagorinsky constant of approximately 0.4004. This
represents autonomous discovery of Smagorinsky-type closure structure from data
without prior theoretical assumptions.
  The discovered model achieves $R^2 = 0.886$ across filter scales and
demonstrates improved prediction accuracy compared to classical closures. The
framework's ability to identify physically meaningful SGS forms and calibrate
coefficients offers a complementary approach to existing turbulence modelling
methods, contributing to the growing field of data-driven closure discovery.

</details>


### [113] [EEGDM: EEG Representation Learning via Generative Diffusion Model](https://arxiv.org/abs/2508.14086)
*Jia Hong Puah,Sim Kuan Goh,Ziwei Zhang,Zixuan Ye,Chow Khuen Chan,Kheng Seang Lim,Si Lei Fong,Kok Sin Woon*

Main category: cs.LG

TL;DR: EEGDM框架通过生成扩散模型和结构化状态空间模型改进EEG信号表示学习，性能优于现有方法且更轻量。


<details>
  <summary>Details</summary>
Motivation: 解决EEG信号表示学习中标注数据有限、信号变异性高的问题，同时降低计算成本。

Method: 提出EEGDM框架，结合生成扩散模型和结构化状态空间模型（SSMDP）进行预训练，并使用潜在融合变换器（LFT）进行下游分类任务。

Result: 在Temple University EEG Event Corpus上，EEGDM性能优于现有方法，且模型轻量19倍。

Conclusion: EEGDM为EEG信号表示学习提供了一种高效且轻量的替代方案。

Abstract: While electroencephalogram (EEG) has been a crucial tool for monitoring the
brain and diagnosing neurological disorders (e.g., epilepsy), learning
meaningful representations from raw EEG signals remains challenging due to
limited annotations and high signal variability. Recently, EEG foundation
models (FMs) have shown promising potential by adopting transformer
architectures and self-supervised pre-training methods from large language
models (e.g., masked prediction) to learn representations from diverse EEG
data, followed by fine-tuning on specific EEG tasks. Nonetheless, these large
models often incurred high computational costs during both training and
inference, with only marginal performance improvements as model size increases.
In this work, we proposed EEG representation learning framework building upon
Generative Diffusion Model (EEGDM). Specifically, we developed structured
state-space model for diffusion pretraining (SSMDP) to better capture the
temporal dynamics of EEG signals and trained the architecture using a Denoising
Diffusion Probabilistic Model. The resulting latent EEG representations were
then used for downstream classification tasks via our proposed latent fusion
transformer (LFT). To evaluate our method, we used the multi-event Temple
University EEG Event Corpus and compared EEGDM with current state-of-the-art
approaches, including EEG FMs. Empirical results showed that our method
outperformed existing methods while being approximately 19x more lightweight.
These findings suggested that EEGDM offered a promising alternative to current
FMs. Our code is available at: https://github.com/jhpuah/EEGDM.

</details>


### [114] [FM4NPP: A Scaling Foundation Model for Nuclear and Particle Physics](https://arxiv.org/abs/2508.14087)
*David Park,Shuhang Li,Yi Huang,Xihaier Luo,Haiwang Yu,Yeonju Go,Christopher Pinkenburg,Yuewei Lin,Shinjae Yoo,Joseph Osborn,Jin Huang,Yihui Ren*

Main category: cs.LG

TL;DR: 论文探讨了在实验粒子物理学中应用科学基础模型（FMs）的可能性，提出了一种新的自监督训练方法，并在大规模数据集上验证了其性能。


<details>
  <summary>Details</summary>
Motivation: 粒子物理学的探测器数据稀疏且空间分布不均，与自然语言数据差异显著，因此需要探索是否可以通过基础模型实现跨任务的扩展和泛化。

Method: 提出了一种针对探测器数据的新型自监督训练方法，并构建了包含1100万次粒子碰撞事件的数据集及下游任务评估套件。

Result: 模型在冻结权重和任务特定适配器的情况下，在所有下游任务中均优于基线模型，并表现出高效的数据适应能力。

Conclusion: 研究表明，基础模型提取的表征是任务无关的，但可以通过简单的线性映射适应不同下游任务，验证了其在粒子物理学中的潜力。

Abstract: Large language models have revolutionized artificial intelligence by enabling
large, generalizable models trained through self-supervision. This paradigm has
inspired the development of scientific foundation models (FMs). However,
applying this capability to experimental particle physics is challenging due to
the sparse, spatially distributed nature of detector data, which differs
dramatically from natural language. This work addresses if an FM for particle
physics can scale and generalize across diverse tasks. We introduce a new
dataset with more than 11 million particle collision events and a suite of
downstream tasks and labeled data for evaluation. We propose a novel
self-supervised training method for detector data and demonstrate its neural
scalability with models that feature up to 188 million parameters. With frozen
weights and task-specific adapters, this FM consistently outperforms baseline
models across all downstream tasks. The performance also exhibits robust
data-efficient adaptation. Further analysis reveals that the representations
extracted by the FM are task-agnostic but can be specialized via a single
linear mapping for different downstream tasks.

</details>


### [115] [CoBAD: Modeling Collective Behaviors for Human Mobility Anomaly Detection](https://arxiv.org/abs/2508.14088)
*Haomin Wen,Shurui Cao,Leman Akoglu*

Main category: cs.LG

TL;DR: CoBAD是一种新型模型，用于检测人类移动中的集体异常行为，通过两阶段注意力机制和预训练任务，显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 传统异常检测方法主要关注个体移动模式，而集体异常检测需要建模个体间的时空依赖关系，这一挑战尚未充分探索。

Method: CoBAD通过集体事件序列（CES）和共现事件图进行无监督学习，采用两阶段注意力机制建模个体模式和个体间交互。

Result: 在大规模移动数据集上，CoBAD在AUCROC和AUCPR指标上分别提升了13%-18%和19%-70%。

Conclusion: CoBAD成功解决了集体异常检测的挑战，特别是在共现异常和缺失异常检测方面表现优异。

Abstract: Detecting anomalies in human mobility is essential for applications such as
public safety and urban planning. While traditional anomaly detection methods
primarily focus on individual movement patterns (e.g., a child should stay at
home at night), collective anomaly detection aims to identify irregularities in
collective mobility behaviors across individuals (e.g., a child is at home
alone while the parents are elsewhere) and remains an underexplored challenge.
Unlike individual anomalies, collective anomalies require modeling
spatiotemporal dependencies between individuals, introducing additional
complexity. To address this gap, we propose CoBAD, a novel model designed to
capture Collective Behaviors for human mobility Anomaly Detection. We first
formulate the problem as unsupervised learning over Collective Event Sequences
(CES) with a co-occurrence event graph, where CES represents the event
sequences of related individuals. CoBAD then employs a two-stage attention
mechanism to model both the individual mobility patterns and the interactions
across multiple individuals. Pre-trained on large-scale collective behavior
data through masked event and link reconstruction tasks, CoBAD is able to
detect two types of collective anomalies: unexpected co-occurrence anomalies
and absence anomalies, the latter of which has been largely overlooked in prior
work. Extensive experiments on large-scale mobility datasets demonstrate that
CoBAD significantly outperforms existing anomaly detection baselines, achieving
an improvement of 13%-18% in AUCROC and 19%-70% in AUCPR. All source code is
available at https://github.com/wenhaomin/CoBAD.

</details>


### [116] [Logical Expressivity and Explanations for Monotonic GNNs with Scoring Functions](https://arxiv.org/abs/2508.14091)
*Matthew Morris,David J. Tena Cucala,Bernardo Cuenca Grau*

Main category: cs.LG

TL;DR: 论文提出了一种方法，通过使GNN和评分函数单调，提取可解释的Datalog规则，用于知识图谱中的链接预测任务。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在知识图谱链接预测中缺乏可解释性的问题，并扩展了低表达能力图编码/解码方法的限制。

Method: 通过调整GNN和评分函数使其单调，利用单调性提取可靠的规则，并定义等效Datalog程序的生成过程。

Result: 实验表明，单调GNN和评分函数在实践中表现良好，并能生成大量可靠的规则。

Conclusion: 该方法不仅提高了链接预测的可解释性，还扩展了GNN模型的表达能力。

Abstract: Graph neural networks (GNNs) are often used for the task of link prediction:
predicting missing binary facts in knowledge graphs (KGs). To address the lack
of explainability of GNNs on KGs, recent works extract Datalog rules from GNNs
with provable correspondence guarantees. The extracted rules can be used to
explain the GNN's predictions; furthermore, they can help characterise the
expressive power of various GNN models. However, these works address only a
form of link prediction based on a restricted, low-expressivity graph
encoding/decoding method. In this paper, we consider a more general and popular
approach for link prediction where a scoring function is used to decode the GNN
output into fact predictions. We show how GNNs and scoring functions can be
adapted to be monotonic, use the monotonicity to extract sound rules for
explaining predictions, and leverage existing results about the kind of rules
that scoring functions can capture. We also define procedures for obtaining
equivalent Datalog programs for certain classes of monotonic GNNs with scoring
functions. Our experiments show that, on link prediction benchmarks, monotonic
GNNs and scoring functions perform well in practice and yield many sound rules.

</details>


### [117] [Beyond Fixed Morphologies: Learning Graph Policies with Trust Region Compensation in Variable Action Spaces](https://arxiv.org/abs/2508.14102)
*Thomas Gallien*

Main category: cs.LG

TL;DR: 论文分析了基于信任区域的优化方法在强化学习中的行为，特别是TRPO和PPO在不同动作空间维度下的表现，并通过实验验证了形态学泛化的能力。


<details>
  <summary>Details</summary>
Motivation: 研究信任区域方法在动作空间维度变化时的行为，以支持形态学泛化的需求。

Method: 理论分析了TRPO和PPO在不同动作空间维度下的优化情况，并在Gymnasium Swimmer环境中进行了实验。

Result: 揭示了动作空间维度变化对优化景观的影响，并验证了形态学泛化的可行性。

Conclusion: 信任区域方法在形态学泛化中表现稳定，为可扩展和可重用控制策略提供了理论基础。

Abstract: Trust region-based optimization methods have become foundational
reinforcement learning algorithms that offer stability and strong empirical
performance in continuous control tasks. Growing interest in scalable and
reusable control policies translate also in a demand for morphological
generalization, the ability of control policies to cope with different
kinematic structures. Graph-based policy architectures provide a natural and
effective mechanism to encode such structural differences. However, while these
architectures accommodate variable morphologies, the behavior of trust region
methods under varying action space dimensionality remains poorly understood. To
this end, we conduct a theoretical analysis of trust region-based policy
optimization methods, focusing on both Trust Region Policy Optimization (TRPO)
and its widely used first-order approximation, Proximal Policy Optimization
(PPO). The goal is to demonstrate how varying action space dimensionality
influence the optimization landscape, particularly under the constraints
imposed by KL-divergence or policy clipping penalties. Complementing the
theoretical insights, an empirical evaluation under morphological variation is
carried out using the Gymnasium Swimmer environment. This benchmark offers a
systematically controlled setting for varying the kinematic structure without
altering the underlying task, making it particularly well-suited to study
morphological generalization.

</details>


### [118] [Physics-Informed Reward Machines](https://arxiv.org/abs/2508.14093)
*Daniel Ajeleye,Ashutosh Trivedi,Majid Zamani*

Main category: cs.LG

TL;DR: 论文提出了一种物理信息奖励机（pRMs），用于增强强化学习中的奖励表达和效率。


<details>
  <summary>Details</summary>
Motivation: 奖励机（RMs）能够结构化地表达非马尔可夫奖励，但需要进一步改进以支持更复杂的学习目标和物理环境。

Method: 引入物理信息奖励机（pRMs），结合反事实经验生成和奖励塑形技术，设计新的强化学习算法。

Result: 实验表明，pRMs显著提高了训练阶段的奖励获取速度，并在有限和连续物理环境中验证了其有效性。

Conclusion: pRMs通过增强奖励结构和学习效率，为强化学习提供了更可编程和高效的解决方案。

Abstract: Reward machines (RMs) provide a structured way to specify non-Markovian
rewards in reinforcement learning (RL), thereby improving both expressiveness
and programmability. Viewed more broadly, they separate what is known about the
environment, captured by the reward mechanism, from what remains unknown and
must be discovered through sampling. This separation supports techniques such
as counterfactual experience generation and reward shaping, which reduce sample
complexity and speed up learning. We introduce physics-informed reward machines
(pRMs), a symbolic machine designed to express complex learning objectives and
reward structures for RL agents, thereby enabling more programmable,
expressive, and efficient learning. We present RL algorithms capable of
exploiting pRMs via counterfactual experiences and reward shaping. Our
experimental results show that these techniques accelerate reward acquisition
during the training phases of RL. We demonstrate the expressiveness and
effectiveness of pRMs through experiments in both finite and continuous
physical environments, illustrating that incorporating pRMs significantly
improves learning efficiency across several control tasks.

</details>


### [119] [Hard Examples Are All You Need: Maximizing GRPO Post-Training Under Annotation Budgets](https://arxiv.org/abs/2508.14094)
*Benjamin Pikus,Pratyush Ranjan Tiwari,Burton Ye*

Main category: cs.LG

TL;DR: 在固定预算下，优先选择难度较大的训练样本能带来最大的性能提升（高达47%），而简单样本的提升最小。


<details>
  <summary>Details</summary>
Motivation: 研究在资源受限的情况下，如何选择训练样本的难度以优化语言模型微调效果。

Method: 使用Group Relative Policy Optimization (GRPO)微调，比较不同难度样本（易、中、难、随机）的选择策略。

Result: 最难样本训练带来最大性能提升（47%），因其提供更多学习机会。

Conclusion: 预算有限时，优先选择难样本可显著提升推理任务性能。

Abstract: Collecting high-quality training examples for language model fine-tuning is
expensive, with practical budgets limiting the amount of data that can be
procured. We investigate a critical question for resource-constrained
alignment: under a fixed acquisition budget, should practitioners prioritize
examples that are easy, medium, hard, or of random difficulty? We study Group
Relative Policy Optimization (GRPO) fine-tuning across different model sizes
and families, comparing four subset selection policies chosen from the same
unlabeled pool using base-model difficulty estimates obtained via multi-sample
evaluation. Our experiments reveal that training on the hardest examples yields
the largest performance gains, up to 47%, while training on easy examples yield
the smallest gains. Analysis reveals that this effect arises from harder
examples providing more learnable opportunities during GRPO training. These
findings provide practical guidance for budget-constrained post-training:
prioritizing hard examples yields substantial performance gains on reasoning
tasks when using GRPO.

</details>


### [120] [Implicit Hypergraph Neural Network](https://arxiv.org/abs/2508.14101)
*Akash Choudhuri,Yongjian Zhong,Bijaya Adhikari*

Main category: cs.LG

TL;DR: 论文提出了一种隐式超图神经网络（IHNN），通过联合学习节点和超边的固定点表示来解决现有超图神经网络在捕获长程依赖时性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: 现有超图神经网络在捕获长程依赖时性能下降，而隐式图神经网络在标准图中表现良好，但未在超图中研究。

Method: 提出IHNN框架，通过隐式微分和投影梯度下降联合学习节点和超边的固定点表示。

Result: 在真实超图数据上的节点分类任务中，IHNN在多数情况下优于现有方法，达到新最优性能。

Conclusion: IHNN通过隐式方法有效解决了超图神经网络的长程依赖问题，提升了性能。

Abstract: Hypergraphs offer a generalized framework for capturing high-order
relationships between entities and have been widely applied in various domains,
including healthcare, social networks, and bioinformatics. Hypergraph neural
networks, which rely on message-passing between nodes over hyperedges to learn
latent representations, have emerged as the method of choice for predictive
tasks in many of these domains. These approaches typically perform only a small
number of message-passing rounds to learn the representations, which they then
utilize for predictions. The small number of message-passing rounds comes at a
cost, as the representations only capture local information and forego
long-range high-order dependencies. However, as we demonstrate, blindly
increasing the message-passing rounds to capture long-range dependency also
degrades the performance of hyper-graph neural networks.
  Recent works have demonstrated that implicit graph neural networks capture
long-range dependencies in standard graphs while maintaining performance.
Despite their popularity, prior work has not studied long-range dependency
issues on hypergraph neural networks. Here, we first demonstrate that existing
hypergraph neural networks lose predictive power when aggregating more
information to capture long-range dependency. We then propose Implicit
Hypergraph Neural Network (IHNN), a novel framework that jointly learns
fixed-point representations for both nodes and hyperedges in an end-to-end
manner to alleviate this issue. Leveraging implicit differentiation, we
introduce a tractable projected gradient descent approach to train the model
efficiently. Extensive experiments on real-world hypergraphs for node
classification demonstrate that IHNN outperforms the closest prior works in
most settings, establishing a new state-of-the-art in hypergraph learning.

</details>


### [121] [From AI for Science to Agentic Science: A Survey on Autonomous Scientific Discovery](https://arxiv.org/abs/2508.14111)
*Jiaqi Wei,Yuejin Yang,Xiang Zhang,Yuhan Chen,Xiang Zhuang,Zhangyang Gao,Dongzhan Zhou,Guangshuai Wang,Zhiqiang Gao,Juntai Cao,Zijie Qiu,Xuming He,Qiang Zhang,Chenyu You,Shuangjia Zheng,Ning Ding,Wanli Ouyang,Nanqing Dong,Yu Cheng,Siqi Sun,Lei Bai,Bowen Zhou*

Main category: cs.LG

TL;DR: Agentic Science是AI for Science的关键阶段，AI系统从辅助工具发展为自主科研伙伴，具备假设生成、实验设计等能力。


<details>
  <summary>Details</summary>
Motivation: 探讨AI如何从辅助工具演变为具有自主科研能力的伙伴，推动科学发现。

Method: 通过大语言模型、多模态系统和集成研究平台，构建一个统一框架，结合过程、自主性和机制视角。

Result: 提出了一个综合框架，总结了AI在生命科学、化学等领域的应用，并识别了核心能力和挑战。

Conclusion: Agentic Science为AI驱动的科研提供了结构化范式，未来有望进一步推动自主科学发现。

Abstract: Artificial intelligence (AI) is reshaping scientific discovery, evolving from
specialized computational tools into autonomous research partners. We position
Agentic Science as a pivotal stage within the broader AI for Science paradigm,
where AI systems progress from partial assistance to full scientific agency.
Enabled by large language models (LLMs), multimodal systems, and integrated
research platforms, agentic AI shows capabilities in hypothesis generation,
experimental design, execution, analysis, and iterative refinement -- behaviors
once regarded as uniquely human. This survey provides a domain-oriented review
of autonomous scientific discovery across life sciences, chemistry, materials
science, and physics. We unify three previously fragmented perspectives --
process-oriented, autonomy-oriented, and mechanism-oriented -- through a
comprehensive framework that connects foundational capabilities, core
processes, and domain-specific realizations. Building on this framework, we (i)
trace the evolution of AI for Science, (ii) identify five core capabilities
underpinning scientific agency, (iii) model discovery as a dynamic four-stage
workflow, (iv) review applications across the above domains, and (v) synthesize
key challenges and future opportunities. This work establishes a
domain-oriented synthesis of autonomous scientific discovery and positions
Agentic Science as a structured paradigm for advancing AI-driven research.

</details>


### [122] [A Cost-Effective Framework for Predicting Parking Availability Using Geospatial Data and Machine Learning](https://arxiv.org/abs/2508.14125)
*Madyan Bagosher,Tala Mustafa,Mohammad Alsmirat,Amal Al-Ali,Isam Mashhour Al Jawarneh*

Main category: cs.LG

TL;DR: 论文提出了一种智能框架，通过整合多源数据预测校园停车位占用情况，评估了多种预测模型，其中随机森林回归表现最佳。


<details>
  <summary>Details</summary>
Motivation: 随着城市人口增长，校园停车位管理成为挑战，学生需快速找到空位，因此需要高效的系统来分配停车位。

Method: 框架整合了地图、移动和气象数据，通过空间连接操作分析停车行为，无需安装传感器，使用位置服务收集数据。评估了线性回归、SVR、RFR和LSTM模型。

Result: 随机森林回归的RMSE最低（0.142），R2最高（0.582），但LSTM可能在更多数据和更长时序下表现更好。

Conclusion: 提出的智能框架能有效预测停车位占用情况，随机森林回归表现最佳，但LSTM有潜力进一步提升。

Abstract: As urban populations continue to grow, cities face numerous challenges in
managing parking and determining occupancy. This issue is particularly
pronounced in university campuses, where students need to find vacant parking
spots quickly and conveniently during class timings. The limited availability
of parking spaces on campuses underscores the necessity of implementing
efficient systems to allocate vacant parking spots effectively. We propose a
smart framework that integrates multiple data sources, including street maps,
mobility, and meteorological data, through a spatial join operation to capture
parking behavior and vehicle movement patterns over the span of 3 consecutive
days with an hourly duration between 7AM till 3PM. The system will not require
any sensing tools to be installed in the street or in the parking area to
provide its services since all the data needed will be collected using location
services. The framework will use the expected parking entrance and time to
specify a suitable parking area. Several forecasting models, namely, Linear
Regression, Support Vector Regression (SVR), Random Forest Regression (RFR),
and Long Short-Term Memory (LSTM), are evaluated. Hyperparameter tuning was
employed using grid search, and model performance is assessed using Root Mean
Squared Error (RMSE), Mean Absolute Error (MAE) and Coefficient of
Determination (R2). Random Forest Regression achieved the lowest RMSE of 0.142
and highest R2 of 0.582. However, given the time-series nature of the task, an
LSTM model may perform better with additional data and longer timesteps.

</details>


### [123] [Comparison of derivative-free and gradient-based minimization for multi-objective compositional design of shape memory alloys](https://arxiv.org/abs/2508.14127)
*S. Josyula,Y. Noiman,E. J. Payton,T. Giovannelli*

Main category: cs.LG

TL;DR: 利用机器学习和优化算法设计形状记忆合金（SMAs），以目标马氏体起始温度（Ms）和低成本为优化目标。


<details>
  <summary>Details</summary>
Motivation: 设计性能达标、经济可持续的形状记忆合金（SMAs）是一个复杂挑战。

Method: 使用树集成和神经网络作为代理预测器，结合数值优化方法（COBYLA和TRUST-CONSTR）搜索合金组合。

Result: 神经网络与梯度优化器（TRUST-CONSTR）表现更稳定，能更一致地找到满足目标的合金组合。

Conclusion: 结合物理数据、机器学习和优化算法，为有限数据下的材料设计提供实用方法。

Abstract: Designing shape memory alloys (SMAs) that meet performance targets while
remaining affordable and sustainable is a complex challenge. In this work, we
focus on optimizing SMA compositions to achieve a desired martensitic start
temperature (Ms) while minimizing cost. To do this, we use machine learning
models as surrogate predictors and apply numerical optimization methods to
search for suitable alloy combinations. We trained two types of machine
learning models, a tree-based ensemble and a neural network, using a dataset of
experimentally characterized alloys and physics-informed features. The
tree-based model was used with a derivative-free optimizer (COBYLA), while the
neural network, which provides gradient information, was paired with a
gradient-based optimizer (TRUST-CONSTR). Our results show that while both
models predict Ms with similar accuracy, the optimizer paired with the neural
network finds better solutions more consistently. COBYLA often converged to
suboptimal results, especially when the starting guess was far from the target.
The TRUST-CONSTR method showed more stable behavior and was better at reaching
alloy compositions that met both objectives. This study demonstrates a
practical approach to exploring new SMA compositions by combining
physics-informed data, machine learning models, and optimization algorithms.
Although the scale of our dataset is smaller than simulation-based efforts, the
use of experimental data improves the reliability of the predictions. The
approach can be extended to other materials where design trade-offs must be
made with limited data.

</details>


### [124] [ERIS: An Energy-Guided Feature Disentanglement Framework for Out-of-Distribution Time Series Classification](https://arxiv.org/abs/2508.14134)
*Xin Wu,Fei Teng,Ji Zhang,Xingwang Li,Yuxuan Liang*

Main category: cs.LG

TL;DR: ERIS框架通过能量正则化信息和语义引导实现特征解耦，提升时间序列分类在分布外数据上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有特征解耦方法缺乏语义引导，导致模型在分布外数据上性能不可靠。

Method: 提出ERIS框架，结合能量引导校准、权重正交性和对抗训练机制。

Result: 在四个基准测试中平均准确率提升4.04%。

Conclusion: ERIS通过语义引导和结构独立性有效提升特征解耦的可靠性。

Abstract: An ideal time series classification (TSC) should be able to capture invariant
representations, but achieving reliable performance on out-of-distribution
(OOD) data remains a core obstacle. This obstacle arises from the way models
inherently entangle domain-specific and label-relevant features, resulting in
spurious correlations. While feature disentanglement aims to solve this,
current methods are largely unguided, lacking the semantic direction required
to isolate truly universal features. To address this, we propose an end-to-end
Energy-Regularized Information for Shift-Robustness (\textbf{ERIS}) framework
to enable guided and reliable feature disentanglement. The core idea is that
effective disentanglement requires not only mathematical constraints but also
semantic guidance to anchor the separation process. ERIS incorporates three key
mechanisms to achieve this goal. Specifically, we first introduce an
energy-guided calibration mechanism, which provides crucial semantic guidance
for the separation, enabling the model to self-calibrate. Additionally, a
weight-level orthogonality strategy enforces structural independence between
domain-specific and label-relevant features, thereby mitigating their
interference. Moreover, an auxiliary adversarial training mechanism enhances
robustness by injecting structured perturbations. Experiments demonstrate that
ERIS improves upon state-of-the-art baselines by an average of 4.04% accuracy
across four benchmarks.

</details>


### [125] [Towards Agent-based Test Support Systems: An Unsupervised Environment Design Approach](https://arxiv.org/abs/2508.14135)
*Collins O. Ogbodo,Timothy J. Rogers,Mattia Dal Borgo,David J. Wagg*

Main category: cs.LG

TL;DR: 提出了一种基于代理的自适应传感器放置框架，用于动态模态测试环境，通过强化学习优化传感器配置。


<details>
  <summary>Details</summary>
Motivation: 传统模态测试方法静态且缺乏适应性，影响测试精度。

Method: 采用部分可观察马尔可夫决策过程和双课程学习策略训练强化学习代理。

Result: 在钢悬臂结构案例中验证了方法的有效性和实用性。

Conclusion: 框架提高了模态测试的适应性和准确性。

Abstract: Modal testing plays a critical role in structural analysis by providing
essential insights into dynamic behaviour across a wide range of engineering
industries. In practice, designing an effective modal test campaign involves
complex experimental planning, comprising a series of interdependent decisions
that significantly influence the final test outcome. Traditional approaches to
test design are typically static-focusing only on global tests without
accounting for evolving test campaign parameters or the impact of such changes
on previously established decisions, such as sensor configurations, which have
been found to significantly influence test outcomes. These rigid methodologies
often compromise test accuracy and adaptability. To address these limitations,
this study introduces an agent-based decision support framework for adaptive
sensor placement across dynamically changing modal test environments. The
framework formulates the problem using an underspecified partially observable
Markov decision process, enabling the training of a generalist reinforcement
learning agent through a dual-curriculum learning strategy. A detailed case
study on a steel cantilever structure demonstrates the efficacy of the proposed
method in optimising sensor locations across frequency segments, validating its
robustness and real-world applicability in experimental settings.

</details>


### [126] [Topological Data Analysis for Unsupervised Anomaly Detection and Customer Segmentation on Banking Data](https://arxiv.org/abs/2508.14136)
*Leonardo Aldo Alejandro Barberi,Linda Maria De Cave*

Main category: cs.LG

TL;DR: 论文介绍了拓扑数据分析（TDA）在银行数据中的无监督异常检测和客户分群中的先进技术。


<details>
  <summary>Details</summary>
Motivation: 将抽象的拓扑数学与工业中的实际用例结合，提供可操作的见解。

Method: 使用Mapper算法和持久同调开发无监督程序，利用拓扑信息揭示客户银行数据中的有意义模式。

Result: 提出的框架能够揭示客户数据中的有意义模式，并生成实际可用的见解。

Conclusion: 该研究成功地将拓扑数据分析应用于银行数据，为工业提供了实用的解决方案。

Abstract: This paper introduces advanced techniques of Topological Data Analysis (TDA)
for unsupervised anomaly detection and customer segmentation in banking data.
Using the Mapper algorithm and persistent homology, we develop unsupervised
procedures that uncover meaningful patterns in customers' banking data by
exploiting topological information. The framework we present in this paper
yields actionable insights that combine the abstract mathematical subject of
topology with real-life use cases that are useful in industry.

</details>


### [127] [Learning to Learn the Macroscopic Fundamental Diagram using Physics-Informed and meta Machine Learning techniques](https://arxiv.org/abs/2508.14137)
*Amalie Roark,Serio Agriesti,Francisco Camara Pereira,Guido Cantelmo*

Main category: cs.LG

TL;DR: 提出了一种基于元学习的框架，用于解决交通网络中宏观基本图（MFD）估计时数据不足的问题，通过多城市数据训练模型，显著提升了流量预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统MFD估计需要大量环路检测器数据，但在实际中往往数据不足。本文旨在通过元学习解决这一问题。

Method: 采用元学习方法，结合多任务物理信息神经网络（Multi-Task Physics-Informed Neural Network），利用多城市数据训练模型。

Result: 在流量预测中，平均MSE提升了17500至36000，证明了模型在数据有限的城市中的泛化能力。

Conclusion: 元学习框架在数据稀缺情况下表现优异，优于传统迁移学习方法，展示了其在交通网络中的潜力。

Abstract: The Macroscopic Fundamental Diagram is a popular tool used to describe
traffic dynamics in an aggregated way, with applications ranging from traffic
control to incident analysis. However, estimating the MFD for a given network
requires large numbers of loop detectors, which is not always available in
practice. This article proposes a framework harnessing meta-learning, a
subcategory of machine learning that trains models to understand and adapt to
new tasks on their own, to alleviate the data scarcity challenge. The developed
model is trained and tested by leveraging data from multiple cities and
exploiting it to model the MFD of other cities with different shares of
detectors and topological structures. The proposed meta-learning framework is
applied to an ad-hoc Multi-Task Physics-Informed Neural Network, specifically
designed to estimate the MFD. Results show an average MSE improvement in flow
prediction ranging between ~ 17500 and 36000 (depending on the subset of loop
detectors tested). The meta-learning framework thus successfully generalizes
across diverse urban settings and improves performance on cities with limited
data, demonstrating the potential of using meta-learning when a limited number
of detectors is available. Finally, the proposed framework is validated against
traditional transfer learning approaches and tested with FitFun, a
non-parametric model from the literature, to prove its transferability.

</details>


### [128] [STAS: Spatio-Temporal Adaptive Computation Time for Spiking Transformers](https://arxiv.org/abs/2508.14138)
*Donghwa Kang,Doohyun Kim,Sang-Ki Ko,Jinkyu Lee,Brent ByungHoon Kang,Hyeongboo Baek*

Main category: cs.LG

TL;DR: STAS框架通过联合设计静态架构和动态计算策略，解决了SNN-based ViTs中的高延迟和计算开销问题，显著降低了能耗并提高了准确性。


<details>
  <summary>Details</summary>
Motivation: SNNs虽然比ANNs更节能，但由于多时间步操作导致高延迟和计算开销。现有方法分散且不统一，ACT原则在SNN-based ViTs中的应用受到限制。

Method: 提出STAS框架，包含I-SPS模块建立时间稳定性，A-SSA模块实现空间和时间维度的token剪枝。

Result: 在CIFAR-10、CIFAR-100和ImageNet上，STAS分别降低能耗45.9%、43.8%和30.1%，同时准确性优于SOTA模型。

Conclusion: STAS通过联合设计架构和计算策略，有效解决了SNN-based ViTs的问题，实现了能耗和性能的双重优化。

Abstract: Spiking neural networks (SNNs) offer energy efficiency over artificial neural
networks (ANNs) but suffer from high latency and computational overhead due to
their multi-timestep operational nature. While various dynamic computation
methods have been developed to mitigate this by targeting spatial, temporal, or
architecture-specific redundancies, they remain fragmented. While the
principles of adaptive computation time (ACT) offer a robust foundation for a
unified approach, its application to SNN-based vision Transformers (ViTs) is
hindered by two core issues: the violation of its temporal similarity
prerequisite and a static architecture fundamentally unsuited for its
principles. To address these challenges, we propose STAS (Spatio-Temporal
Adaptive computation time for Spiking transformers), a framework that
co-designs the static architecture and dynamic computation policy. STAS
introduces an integrated spike patch splitting (I-SPS) module to establish
temporal stability by creating a unified input representation, thereby solving
the architectural problem of temporal dissimilarity. This stability, in turn,
allows our adaptive spiking self-attention (A-SSA) module to perform
two-dimensional token pruning across both spatial and temporal axes.
Implemented on spiking Transformer architectures and validated on CIFAR-10,
CIFAR-100, and ImageNet, STAS reduces energy consumption by up to 45.9%, 43.8%,
and 30.1%, respectively, while simultaneously improving accuracy over SOTA
models.

</details>


### [129] [Neuro-inspired Ensemble-to-Ensemble Communication Primitives for Sparse and Efficient ANNs](https://arxiv.org/abs/2508.14140)
*Orestis Konstantaropoulos,Stelios Manolis Smirnakis,Maria Papadopouli*

Main category: cs.LG

TL;DR: 论文提出了一种受生物神经网络启发的稀疏模块化架构G2GNet，通过动态稀疏训练和Hebbian重连规则，在减少参数和计算量的同时提升了性能。


<details>
  <summary>Details</summary>
Motivation: 受小鼠视觉皮层功能连接模式的启发，探索如何将生物神经网络的稀疏、模块化和层次化特性应用于人工神经网络设计，以提高效率和性能。

Method: 提出G2GNet架构，结合静态稀疏模块化连接和动态稀疏训练（DST），并引入基于激活相关的Hebbian重连规则。

Result: G2GNet在Fashion-MNIST、CIFAR-10和CIFAR-100等基准测试中，参数减少但准确率提升4.3%，最高实现75%的稀疏度。

Conclusion: G2GNet首次将生物功能连接模式作为结构偏置引入ANN设计，证明了生物启发的稀疏模块化架构在性能和效率上的优势。

Abstract: The structure of biological neural circuits-modular, hierarchical, and
sparsely interconnected-reflects an efficient trade-off between wiring cost,
functional specialization, and robustness. These principles offer valuable
insights for artificial neural network (ANN) design, especially as networks
grow in depth and scale. Sparsity, in particular, has been widely explored for
reducing memory and computation, improving speed, and enhancing generalization.
Motivated by systems neuroscience findings, we explore how patterns of
functional connectivity in the mouse visual cortex-specifically,
ensemble-to-ensemble communication, can inform ANN design. We introduce G2GNet,
a novel architecture that imposes sparse, modular connectivity across
feedforward layers. Despite having significantly fewer parameters than fully
connected models, G2GNet achieves superior accuracy on standard vision
benchmarks. To our knowledge, this is the first architecture to incorporate
biologically observed functional connectivity patterns as a structural bias in
ANN design. We complement this static bias with a dynamic sparse training (DST)
mechanism that prunes and regrows edges during training. We also propose a
Hebbian-inspired rewiring rule based on activation correlations, drawing on
principles of biological plasticity. G2GNet achieves up to 75% sparsity while
improving accuracy by up to 4.3% on benchmarks, including Fashion-MNIST,
CIFAR-10, and CIFAR-100, outperforming dense baselines with far fewer
computations.

</details>


### [130] [Beyond Turing: Memory-Amortized Inference as a Foundation for Cognitive Computation](https://arxiv.org/abs/2508.14143)
*Xin Li*

Main category: cs.LG

TL;DR: 论文提出了一种基于记忆的结构化推理框架（MAI），将认知建模为对记忆中的潜在循环进行推理，而非通过梯度下降重新计算。


<details>
  <summary>Details</summary>
Motivation: 传统智能模型假设智能是均匀采样或从头优化的，而本文认为智能源于对先前推理轨迹的结构化重用。

Method: 引入MAI框架，通过结构重用编码归纳偏差，最小化熵并实现上下文感知、结构保持的推理。

Result: MAI为Mountcastle的通用皮层算法提供了理论基础，并建立了与强化学习的时间反转对偶性。

Conclusion: MAI为基于结构、重用和记忆的智能理论提供了统一框架，对实现AGI具有深远意义。

Abstract: Intelligence is fundamentally non-ergodic: it emerges not from uniform
sampling or optimization from scratch, but from the structured reuse of prior
inference trajectories. We introduce Memory-Amortized Inference (MAI) as a
formal framework in which cognition is modeled as inference over latent cycles
in memory, rather than recomputation through gradient descent. MAI systems
encode inductive biases via structural reuse, minimizing entropy and enabling
context-aware, structure-preserving inference. This approach reframes cognitive
systems not as ergodic samplers, but as navigators over constrained latent
manifolds, guided by persistent topological memory. Through the lens of
delta-homology, we show that MAI provides a principled foundation for
Mountcastle's Universal Cortical Algorithm, modeling each cortical column as a
local inference operator over cycle-consistent memory states. Furthermore, we
establish a time-reversal duality between MAI and reinforcement learning:
whereas RL propagates value forward from reward, MAI reconstructs latent causes
backward from memory. This inversion paves a path toward energy-efficient
inference and addresses the computational bottlenecks facing modern AI. MAI
thus offers a unified, biologically grounded theory of intelligence based on
structure, reuse, and memory. We also briefly discuss the profound implications
of MAI for achieving artificial general intelligence (AGI).

</details>


### [131] [Noise Robust One-Class Intrusion Detection on Dynamic Graphs](https://arxiv.org/abs/2508.14192)
*Aleksei Liuliakov,Alexander Schulz,Luca Hermes,Barbara Hammer*

Main category: cs.LG

TL;DR: 提出了一种概率版本的TGN-SVDD模型，用于增强网络入侵检测在噪声数据下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 网络入侵检测中，数据污染和噪声输入对模型鲁棒性构成挑战。

Method: 通过预测每个网络事件的高斯分布参数，模型能够自然处理噪声对抗样本。

Result: 在添加合成噪声的CIC-IDS2017数据集上，模型检测性能显著优于基线TGN-SVDD。

Conclusion: 概率TGN-SVDD模型在噪声环境下表现出更强的鲁棒性和检测准确性。

Abstract: In the domain of network intrusion detection, robustness against contaminated
and noisy data inputs remains a critical challenge. This study introduces a
probabilistic version of the Temporal Graph Network Support Vector Data
Description (TGN-SVDD) model, designed to enhance detection accuracy in the
presence of input noise. By predicting parameters of a Gaussian distribution
for each network event, our model is able to naturally address noisy
adversarials and improve robustness compared to a baseline model. Our
experiments on a modified CIC-IDS2017 data set with synthetic noise demonstrate
significant improvements in detection performance compared to the baseline
TGN-SVDD model, especially as noise levels increase.

</details>


### [132] [Reliability comparison of vessel trajectory prediction models via Probability of Detection](https://arxiv.org/abs/2508.14198)
*Zahra Rastin,Kathrin Donandt,Dirk Söffker*

Main category: cs.LG

TL;DR: 评估不同深度学习方法的船舶轨迹预测性能，重点关注交通复杂性下的可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有船舶轨迹预测模型忽视交通复杂性且缺乏可靠性评估，本研究填补这一空白。

Method: 使用检测概率分析量化模型在不同交通场景下的可靠性，并进行分类测试。

Result: 全面评估揭示了各预测方法的优缺点及其在不同预测时间范围内的可靠性。

Conclusion: 研究结果为开发更可靠的船舶轨迹预测方法提供了依据，提升内河航行安全与效率。

Abstract: This contribution addresses vessel trajectory prediction (VTP), focusing on
the evaluation of different deep learning-based approaches. The objective is to
assess model performance in diverse traffic complexities and compare the
reliability of the approaches. While previous VTP models overlook the specific
traffic situation complexity and lack reliability assessments, this research
uses a probability of detection analysis to quantify model reliability in
varying traffic scenarios, thus going beyond common error distribution
analyses. All models are evaluated on test samples categorized according to
their traffic situation during the prediction horizon, with performance metrics
and reliability estimates obtained for each category. The results of this
comprehensive evaluation provide a deeper understanding of the strengths and
weaknesses of the different prediction approaches, along with their reliability
in terms of the prediction horizon lengths for which safe forecasts can be
guaranteed. These findings can inform the development of more reliable vessel
trajectory prediction approaches, enhancing safety and efficiency in future
inland waterways navigation.

</details>


### [133] [Graph Concept Bottleneck Models](https://arxiv.org/abs/2508.14255)
*Haotian Xu,Tsui-Wei Weng,Lam M. Nguyen,Tengfei Ma*

Main category: cs.LG

TL;DR: GraphCBMs通过构建潜在概念图改进概念瓶颈模型，提升分类性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有概念瓶颈模型假设概念条件独立，忽略了概念间的隐藏关系。

Method: 提出GraphCBMs，通过构建潜在概念图捕捉概念间关系。

Result: 实验显示GraphCBMs在分类任务中表现更优，提供更多概念结构信息。

Conclusion: GraphCBMs在保持可解释性的同时，提升了模型性能和干预效果。

Abstract: Concept Bottleneck Models (CBMs) provide explicit interpretations for deep
neural networks through concepts and allow intervention with concepts to adjust
final predictions. Existing CBMs assume concepts are conditionally independent
given labels and isolated from each other, ignoring the hidden relationships
among concepts. However, the set of concepts in CBMs often has an intrinsic
structure where concepts are generally correlated: changing one concept will
inherently impact its related concepts. To mitigate this limitation, we propose
GraphCBMs: a new variant of CBM that facilitates concept relationships by
constructing latent concept graphs, which can be combined with CBMs to enhance
model performance while retaining their interpretability. Our experiment
results on real-world image classification tasks demonstrate Graph CBMs offer
the following benefits: (1) superior in image classification tasks while
providing more concept structure information for interpretability; (2) able to
utilize latent concept graphs for more effective interventions; and (3) robust
in performance across different training and architecture settings.

</details>


### [134] [Amortized Bayesian Meta-Learning for Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2508.14285)
*Liyi Zhang,Jake Snell,Thomas L. Griffiths*

Main category: cs.LG

TL;DR: ABMLL是一种基于摊销贝叶斯元学习的LoRA微调方法，旨在提高大语言模型的泛化能力，同时保持计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在提高泛化能力时存在内存和计算成本高的问题，ABMLL旨在解决这些挑战。

Method: 通过摊销贝叶斯元学习框架，重新定义LoRA中的任务特定和全局参数，并引入新超参数平衡重建精度和参数保真度。

Result: 在Unified-QA和CrossFit数据集上，ABMLL在准确性和预期校准误差方面优于现有方法。

Conclusion: ABMLL为LoRA微调提供了一种高效且泛化能力强的解决方案，适用于大型模型如Llama3-8B。

Abstract: Fine-tuning large language models (LLMs) with low-rank adaptaion (LoRA) is a
cost-effective way to incorporate information from a specific dataset. However,
it is often unclear how well the fine-tuned LLM will generalize, i.e., how well
it will perform on unseen datasets. Methods have been proposed to improve
generalization by optimizing with in-context prompts, or by using meta-learning
to fine-tune LLMs. However, these methods are expensive in memory and
computation, requiring either long-context prompts or saving copies of
parameters and using second-order gradient updates. To address these
challenges, we propose Amortized Bayesian Meta-Learning for LoRA (ABMLL). This
method builds on amortized Bayesian meta-learning for smaller models, adapting
this approach to LLMs while maintaining its computational efficiency. We
reframe task-specific and global parameters in the context of LoRA and use a
set of new hyperparameters to balance reconstruction accuracy and the fidelity
of task-specific parameters to the global ones. ABMLL provides effective
generalization and scales to large models such as Llama3-8B. Furthermore, as a
result of using a Bayesian framework, ABMLL provides improved uncertainty
quantification. We test ABMLL on Unified-QA and CrossFit datasets and find that
it outperforms existing methods on these benchmarks in terms of both accuracy
and expected calibration error.

</details>


### [135] [GLASS: Test-Time Acceleration for LLMs via Global-Local Neural Importance Aggregation](https://arxiv.org/abs/2508.14302)
*Amirmohsen Sattarifard,Sepehr Lavasani,Ehsan Imani,Kunlin Zhang,Hanlin Xu,Fengyu Sun,Negar Hassanpour,Chao Gao*

Main category: cs.LG

TL;DR: A/I-GLASS是一种无需训练的动态剪枝方法，通过全局-局部神经元重要性聚合优化LLM在边缘硬件上的部署。


<details>
  <summary>Details</summary>
Motivation: 解决静态或预测器剪枝方法的局限性，如固定稀疏模式或额外运行时开销，以及零样本方法在短提示/长生成场景中的失败。

Method: 基于激活和影响的全局-局部神经元重要性聚合，动态选择FFN单元。

Result: 在多个LLM和基准测试中显著优于现有方法，尤其在长生成场景中表现突出。

Conclusion: GLASS无需额外推理开销或辅助预测器，有效提升LLM在边缘设备上的性能。

Abstract: Deploying Large Language Models (LLMs) on edge hardware demands aggressive,
prompt-aware dynamic pruning to reduce computation without degrading quality.
Static or predictor-based schemes either lock in a single sparsity pattern or
incur extra runtime overhead, and recent zero-shot methods that rely on
statistics from a single prompt fail on short prompt and/or long generation
scenarios. We introduce A/I-GLASS: Activation- and Impact-based Global-Local
neural importance Aggregation for feed-forward network SparSification, two
training-free methods that dynamically select FFN units using a
rank-aggregation of prompt local and model-intrinsic global neuron statistics.
Empirical results across multiple LLMs and benchmarks demonstrate that GLASS
significantly outperforms prior training-free methods, particularly in
challenging long-form generation scenarios, without relying on auxiliary
predictors or adding any inference overhead.

</details>


### [136] [Learning Time-Varying Convexifications of Multiple Fairness Measures](https://arxiv.org/abs/2508.14311)
*Quan Zhou,Jakub Marecek,Robert Shorten*

Main category: cs.LG

TL;DR: 论文探讨了多公平性度量的动态学习问题，提出了一种基于图结构反馈的方法。


<details>
  <summary>Details</summary>
Motivation: 随着对公平性需求的增加，需要同时考虑多种公平性度量（如群体和个体公平性），但这些度量的权重未知且可能随时间变化。

Method: 通过图结构反馈学习时间变化的多公平性度量的凸组合。

Result: 提出了一种动态学习多公平性度量的方法，适用于权重未知且变化的情况。

Conclusion: 该方法能够有效处理多公平性度量的动态权重问题，适用于实际应用中的公平性需求。

Abstract: There is an increasing appreciation that one may need to consider multiple
measures of fairness, e.g., considering multiple group and individual fairness
notions. The relative weights of the fairness regularisers are a priori
unknown, may be time varying, and need to be learned on the fly. We consider
the learning of time-varying convexifications of multiple fairness measures
with limited graph-structured feedback.

</details>


### [137] [Your Reward Function for RL is Your Best PRM for Search: Unifying RL and Search-Based TTS](https://arxiv.org/abs/2508.14313)
*Can Jin,Yang Zhou,Qixin Zhang,Hongwu Peng,Di Zhang,Marco Pavone,Ligong Han,Zhang-Wei Hong,Tong Che,Dimitris N. Metaxas*

Main category: cs.LG

TL;DR: AIRL-S统一了基于强化学习和搜索的测试时间缩放方法，通过动态奖励模型提升LLM性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法的不稳定性、低效性和依赖标注数据的问题。

Method: 结合对抗逆强化学习和组相对策略优化，从正确推理轨迹学习动态奖励模型。

Result: 在八个基准测试中平均性能提升9%，匹配GPT-4o。

Conclusion: 动态奖励模型是强化学习和搜索的理想结合，提供高效且鲁棒的解决方案。

Abstract: Test-time scaling (TTS) for large language models (LLMs) has thus far fallen
into two largely separate paradigms: (1) reinforcement learning (RL) methods
that optimize sparse outcome-based rewards, yet suffer from instability and low
sample efficiency; and (2) search-based techniques guided by independently
trained, static process reward models (PRMs), which require expensive human- or
LLM-generated labels and often degrade under distribution shifts. In this
paper, we introduce AIRL-S, the first natural unification of RL-based and
search-based TTS. Central to AIRL-S is the insight that the reward function
learned during RL training inherently represents the ideal PRM for guiding
downstream search. Specifically, we leverage adversarial inverse reinforcement
learning (AIRL) combined with group relative policy optimization (GRPO) to
learn a dense, dynamic PRM directly from correct reasoning traces, entirely
eliminating the need for labeled intermediate process data. At inference, the
resulting PRM simultaneously serves as the critic for RL rollouts and as a
heuristic to effectively guide search procedures, facilitating robust reasoning
chain extension, mitigating reward hacking, and enhancing cross-task
generalization. Experimental results across eight benchmarks, including
mathematics, scientific reasoning, and code generation, demonstrate that our
unified approach improves performance by 9 % on average over the base model,
matching GPT-4o. Furthermore, when integrated into multiple search algorithms,
our PRM consistently outperforms all baseline PRMs trained with labeled data.
These results underscore that, indeed, your reward function for RL is your best
PRM for search, providing a robust and cost-effective solution to complex
reasoning tasks in LLMs.

</details>


### [138] [FedRAIN-Lite: Federated Reinforcement Algorithms for Improving Idealised Numerical Weather and Climate Models](https://arxiv.org/abs/2508.14315)
*Pritthijit Nath,Sebastian Schemm,Henry Moss,Peter Haynes,Emily Shuckburgh,Mark Webb*

Main category: cs.LG

TL;DR: FedRAIN-Lite是一个基于联邦强化学习的框架，用于改进气候模型中的子网格参数化，通过局部学习和全局聚合提升适应性。


<details>
  <summary>Details</summary>
Motivation: 传统气候模型的子网格参数化是静态且离线调优的，难以适应气候状态的变化。

Method: 使用联邦强化学习框架，将代理分配到纬度带，结合简化的能量平衡气候模型，评估了三种RL算法。

Result: DDPG算法在热带和中纬度区域表现最佳，收敛更快且误差更低。

Conclusion: FedRAIN-Lite为高复杂度气候模型提供了可扩展的解决方案，支持在线学习和适应性参数化。

Abstract: Sub-grid parameterisations in climate models are traditionally static and
tuned offline, limiting adaptability to evolving states. This work introduces
FedRAIN-Lite, a federated reinforcement learning (FedRL) framework that mirrors
the spatial decomposition used in general circulation models (GCMs) by
assigning agents to latitude bands, enabling local parameter learning with
periodic global aggregation. Using a hierarchy of simplified energy-balance
climate models, from a single-agent baseline (ebm-v1) to multi-agent ensemble
(ebm-v2) and GCM-like (ebm-v3) setups, we benchmark three RL algorithms under
different FedRL configurations. Results show that Deep Deterministic Policy
Gradient (DDPG) consistently outperforms both static and single-agent
baselines, with faster convergence and lower area-weighted RMSE in tropical and
mid-latitude zones across both ebm-v2 and ebm-v3 setups. DDPG's ability to
transfer across hyperparameters and low computational cost make it well-suited
for geographically adaptive parameter learning. This capability offers a
scalable pathway towards high-complexity GCMs and provides a prototype for
physically aligned, online-learning climate models that can evolve with a
changing climate. Code accessible at
https://github.com/p3jitnath/climate-rl-fedrl.

</details>


### [139] [Multi-view Graph Condensation via Tensor Decomposition](https://arxiv.org/abs/2508.14330)
*Nícolas Roque dos Santos,Dawon Ahn,Diego Minatel,Alneu de Andrade Lopes,Evangelos E. Papalexakis*

Main category: cs.LG

TL;DR: 论文提出了一种基于张量分解的多视图图压缩方法（GCTD），用于减少大规模图的计算需求，同时保持GNN性能。


<details>
  <summary>Details</summary>
Motivation: 大规模图的存储和处理对GNN训练带来巨大计算挑战，现有图压缩方法依赖计算密集型双层优化且缺乏可解释性。

Method: 通过张量分解技术学习线性或多线性函数，提出GCTD方法合成更小的图并保持下游任务性能。

Result: 在六个真实数据集上，GCTD有效减少图大小并提升性能，在三个数据集上准确率提升4.0%。

Conclusion: GCTD是一种高效且可解释的图压缩方法，适用于大规模图处理。

Abstract: Graph Neural Networks (GNNs) have demonstrated remarkable results in various
real-world applications, including drug discovery, object detection, social
media analysis, recommender systems, and text classification. In contrast to
their vast potential, training them on large-scale graphs presents significant
computational challenges due to the resources required for their storage and
processing. Graph Condensation has emerged as a promising solution to reduce
these demands by learning a synthetic compact graph that preserves the
essential information of the original one while maintaining the GNN's
predictive performance. Despite their efficacy, current graph condensation
approaches frequently rely on a computationally intensive bi-level
optimization. Moreover, they fail to maintain a mapping between synthetic and
original nodes, limiting the interpretability of the model's decisions. In this
sense, a wide range of decomposition techniques have been applied to learn
linear or multi-linear functions from graph data, offering a more transparent
and less resource-intensive alternative. However, their applicability to graph
condensation remains unexplored. This paper addresses this gap and proposes a
novel method called Multi-view Graph Condensation via Tensor Decomposition
(GCTD) to investigate to what extent such techniques can synthesize an
informative smaller graph and achieve comparable downstream task performance.
Extensive experiments on six real-world datasets demonstrate that GCTD
effectively reduces graph size while preserving GNN performance, achieving up
to a 4.0\ improvement in accuracy on three out of six datasets and competitive
performance on large graphs compared to existing approaches. Our code is
available at https://anonymous.4open.science/r/gctd-345A.

</details>


### [140] [NeRC: Neural Ranging Correction through Differentiable Moving Horizon Location Estimation](https://arxiv.org/abs/2508.14336)
*Xu Weng,K. V. Ling,Haochen Liu,Bingheng Wang,Kun Cao*

Main category: cs.LG

TL;DR: 提出了一种名为NeRC的端到端神经网络框架，用于校正GNSS测距误差，无需标注测距误差标签，仅需相对容易获取的地面真实位置即可训练。


<details>
  <summary>Details</summary>
Motivation: 城市环境中，GNSS定位因信号传播复杂和硬件质量低导致测距误差，影响定位精度。传统数据驱动方法依赖标注测距误差，但标注过程繁琐。

Method: 通过可微分移动水平位置估计（MHE）和欧几里得距离场（EDF）成本图，利用地面真实位置训练神经网络，避免直接标注测距误差。

Result: 在公开基准和自收集数据集上验证了NeRC的定位精度显著提升，并在边缘设备上验证了其实时性能。

Conclusion: NeRC框架通过端到端学习有效校正测距误差，提升GNSS定位精度，且适用于移动设备实时应用。

Abstract: GNSS localization using everyday mobile devices is challenging in urban
environments, as ranging errors caused by the complex propagation of satellite
signals and low-quality onboard GNSS hardware are blamed for undermining
positioning accuracy. Researchers have pinned their hopes on data-driven
methods to regress such ranging errors from raw measurements. However, the
grueling annotation of ranging errors impedes their pace. This paper presents a
robust end-to-end Neural Ranging Correction (NeRC) framework, where
localization-related metrics serve as the task objective for training the
neural modules. Instead of seeking impractical ranging error labels, we train
the neural network using ground-truth locations that are relatively easy to
obtain. This functionality is supported by differentiable moving horizon
location estimation (MHE) that handles a horizon of measurements for
positioning and backpropagates the gradients for training. Even better, as a
blessing of end-to-end learning, we propose a new training paradigm using
Euclidean Distance Field (EDF) cost maps, which alleviates the demands on
labeled locations. We evaluate the proposed NeRC on public benchmarks and our
collected datasets, demonstrating its distinguished improvement in positioning
accuracy. We also deploy NeRC on the edge to verify its real-time performance
for mobile devices.

</details>


### [141] [On the Interplay between Graph Structure and Learning Algorithms in Graph Neural Networks](https://arxiv.org/abs/2508.14338)
*Junwei Su,Chuan Wu*

Main category: cs.LG

TL;DR: 论文研究了图神经网络（GNNs）中学习算法与图结构的相互作用，填补了现有理论在噪声环境下泛化性能研究的空白。


<details>
  <summary>Details</summary>
Motivation: 现有理论研究主要关注无噪声环境下学习算法的收敛速度，而忽略了图结构对泛化性能的影响。本文旨在研究噪声环境下学习算法的过度风险（泛化性能）与图结构的关系。

Method: 通过扩展传统学习理论到GNNs，分析了图结构对SGD和Ridge回归等算法性能的影响，并利用谱图理论连接过度风险与图结构。

Result: 研究发现不同图结构（规则与幂律）对算法性能有显著影响，并揭示了多层线性GNNs中过度风险的非各向同性效应，为GNNs的过平滑问题提供了新视角。

Conclusion: 理论与实证结果一致，展示了图结构、GNNs与学习算法之间的耦合关系，为实际中GNN算法设计与选择提供了指导。

Abstract: This paper studies the interplay between learning algorithms and graph
structure for graph neural networks (GNNs). Existing theoretical studies on the
learning dynamics of GNNs primarily focus on the convergence rates of learning
algorithms under the interpolation regime (noise-free) and offer only a crude
connection between these dynamics and the actual graph structure (e.g., maximum
degree). This paper aims to bridge this gap by investigating the excessive risk
(generalization performance) of learning algorithms in GNNs within the
generalization regime (with noise). Specifically, we extend the conventional
settings from the learning theory literature to the context of GNNs and examine
how graph structure influences the performance of learning algorithms such as
stochastic gradient descent (SGD) and Ridge regression. Our study makes several
key contributions toward understanding the interplay between graph structure
and learning in GNNs. First, we derive the excess risk profiles of SGD and
Ridge regression in GNNs and connect these profiles to the graph structure
through spectral graph theory. With this established framework, we further
explore how different graph structures (regular vs. power-law) impact the
performance of these algorithms through comparative analysis. Additionally, we
extend our analysis to multi-layer linear GNNs, revealing an increasing
non-isotropic effect on the excess risk profile, thereby offering new insights
into the over-smoothing issue in GNNs from the perspective of learning
algorithms. Our empirical results align with our theoretical predictions,
\emph{collectively showcasing a coupling relation among graph structure, GNNs
and learning algorithms, and providing insights on GNN algorithm design and
selection in practice.}

</details>


### [142] [A Comparative Evaluation of Teacher-Guided Reinforcement Learning Techniques for Autonomous Cyber Operations](https://arxiv.org/abs/2508.14340)
*Konur Tholl,Mariam El Mezouar,Ranwa Al Mallah*

Main category: cs.LG

TL;DR: 教师引导技术显著提升自主网络操作中强化学习的训练效率和收敛速度。


<details>
  <summary>Details</summary>
Motivation: 现有自主网络操作（ACO）应用中，强化学习（RL）需从零开始学习，导致收敛慢且早期性能差。教师引导技术在其他领域表现优异，但尚未应用于ACO。

Method: 在模拟CybORG环境中实现并比较四种教师引导技术。

Result: 教师集成显著提升训练效率，包括早期策略性能和收敛速度。

Conclusion: 教师引导技术对自主网络安全具有潜在益处。

Abstract: Autonomous Cyber Operations (ACO) rely on Reinforcement Learning (RL) to
train agents to make effective decisions in the cybersecurity domain. However,
existing ACO applications require agents to learn from scratch, leading to slow
convergence and poor early-stage performance. While teacher-guided techniques
have demonstrated promise in other domains, they have not yet been applied to
ACO. In this study, we implement four distinct teacher-guided techniques in the
simulated CybORG environment and conduct a comparative evaluation. Our results
demonstrate that teacher integration can significantly improve training
efficiency in terms of early policy performance and convergence speed,
highlighting its potential benefits for autonomous cybersecurity.

</details>


### [143] [Generative AI Against Poaching: Latent Composite Flow Matching for Wildlife Conservation](https://arxiv.org/abs/2508.14342)
*Lingkai Kong,Haichuan Wang,Charles A. Emogor,Vincent Börsch-Supan,Lily Xu,Milind Tambe*

Main category: cs.LG

TL;DR: 论文提出了一种结合流匹配和占用检测模型的方法，用于预测偷猎行为，解决了现有方法无法捕捉复杂时空模式的局限性，并在乌干达两个国家公园的数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 偷猎对野生动物和生物多样性构成严重威胁。预测偷猎行为有助于规划巡逻和其他保护措施，但现有方法（如线性模型或决策树）无法捕捉复杂的非线性时空模式。

Method: 结合流匹配和占用检测模型，在潜在空间中训练流以推断潜在的占用状态，并通过从线性模型预测初始化复合流来缓解数据稀缺问题。

Result: 在乌干达两个国家公园的数据集上验证，新方法在预测准确性上表现优于现有方法。

Conclusion: 该方法通过整合流匹配和占用检测模型，有效提升了偷猎行为预测的准确性，为野生动物保护提供了更可靠的工具。

Abstract: Poaching poses significant threats to wildlife and biodiversity. A valuable
step in reducing poaching is to forecast poacher behavior, which can inform
patrol planning and other conservation interventions. Existing poaching
prediction methods based on linear models or decision trees lack the
expressivity to capture complex, nonlinear spatiotemporal patterns. Recent
advances in generative modeling, particularly flow matching, offer a more
flexible alternative. However, training such models on real-world poaching data
faces two central obstacles: imperfect detection of poaching events and limited
data. To address imperfect detection, we integrate flow matching with an
occupancy-based detection model and train the flow in latent space to infer the
underlying occupancy state. To mitigate data scarcity, we adopt a composite
flow initialized from a linear-model prediction rather than random noise which
is the standard in diffusion models, injecting prior knowledge and improving
generalization. Evaluations on datasets from two national parks in Uganda show
consistent gains in predictive accuracy.

</details>


### [144] [A Non-Asymptotic Convergent Analysis for Scored-Based Graph Generative Model via a System of Stochastic Differential Equations](https://arxiv.org/abs/2508.14351)
*Junwei Su,Chuan Wu*

Main category: cs.LG

TL;DR: 本文首次对基于分数的图生成模型（SGGMs）进行了非渐近收敛分析，揭示了影响收敛的独特因素，并提供了超参数选择和模型设计的实用指导。


<details>
  <summary>Details</summary>
Motivation: SGGMs在药物发现和蛋白质合成等关键应用中表现出色，但其理论行为（尤其是收敛性）尚未充分研究。现有分析不适用于SGGMs，因为它们涉及耦合的随机微分方程（SDEs）。

Method: 通过分析三种图生成范式（固定图结构的特征生成、固定节点特征的图结构生成、联合生成）的收敛边界，研究SGGMs的收敛性。

Result: 揭示了影响收敛的独特因素（如图结构的拓扑特性），并验证了超参数选择和技术（如归一化）对收敛的改进效果。

Conclusion: 本研究深化了对SGGMs的理论理解，证明了其在关键领域的适用性，并为设计有效模型提供了实用指导。

Abstract: Score-based graph generative models (SGGMs) have proven effective in critical
applications such as drug discovery and protein synthesis. However, their
theoretical behavior, particularly regarding convergence, remains
underexplored. Unlike common score-based generative models (SGMs), which are
governed by a single stochastic differential equation (SDE), SGGMs involve a
system of coupled SDEs. In SGGMs, the graph structure and node features are
governed by separate but interdependent SDEs. This distinction makes existing
convergence analyses from SGMs inapplicable for SGGMs. In this work, we present
the first non-asymptotic convergence analysis for SGGMs, focusing on the
convergence bound (the risk of generative error) across three key graph
generation paradigms: (1) feature generation with a fixed graph structure, (2)
graph structure generation with fixed node features, and (3) joint generation
of both graph structure and node features. Our analysis reveals several unique
factors specific to SGGMs (e.g., the topological properties of the graph
structure) which affect the convergence bound. Additionally, we offer
theoretical insights into the selection of hyperparameters (e.g., sampling
steps and diffusion length) and advocate for techniques like normalization to
improve convergence. To validate our theoretical findings, we conduct a
controlled empirical study using synthetic graph models, and the results align
with our theoretical predictions. This work deepens the theoretical
understanding of SGGMs, demonstrates their applicability in critical domains,
and provides practical guidance for designing effective models.

</details>


### [145] [SBGD: Improving Graph Diffusion Generative Model via Stochastic Block Diffusion](https://arxiv.org/abs/2508.14352)
*Junwei Su,Shan Wu*

Main category: cs.LG

TL;DR: SBGD模型通过块图空间改进图扩散生成模型，解决了可扩展性和尺寸泛化问题。


<details>
  <summary>Details</summary>
Motivation: GDGMs在大型图上的内存需求和尺寸泛化能力不足，限制了其实际应用。

Method: 提出SBGD模型，将图表示细化到块图空间，降低内存复杂度并提升泛化能力。

Result: SBGD显著减少内存使用（最高6倍），同时保持或超越现有方法的生成性能。

Conclusion: SBGD不仅是一种高效GDGM，还展示了模块化生成建模的潜力。

Abstract: Graph diffusion generative models (GDGMs) have emerged as powerful tools for
generating high-quality graphs. However, their broader adoption faces
challenges in \emph{scalability and size generalization}. GDGMs struggle to
scale to large graphs due to their high memory requirements, as they typically
operate in the full graph space, requiring the entire graph to be stored in
memory during training and inference. This constraint limits their feasibility
for large-scale real-world graphs. GDGMs also exhibit poor size generalization,
with limited ability to generate graphs of sizes different from those in the
training data, restricting their adaptability across diverse applications. To
address these challenges, we propose the stochastic block graph diffusion
(SBGD) model, which refines graph representations into a block graph space.
This space incorporates structural priors based on real-world graph patterns,
significantly reducing memory complexity and enabling scalability to large
graphs. The block representation also improves size generalization by capturing
fundamental graph structures. Empirical results show that SBGD achieves
significant memory improvements (up to 6$\times$) while maintaining comparable
or even superior graph generation performance relative to state-of-the-art
methods. Furthermore, experiments demonstrate that SBGD better generalizes to
unseen graph sizes. The significance of SBGD extends beyond being a scalable
and effective GDGM; it also exemplifies the principle of modularization in
generative modeling, offering a new avenue for exploring generative models by
decomposing complex tasks into more manageable components.

</details>


### [146] [Organ-Agents: Virtual Human Physiology Simulator via LLMs](https://arxiv.org/abs/2508.14357)
*Rihao Chang,He Jiao,Weizhi Nie,Honglin Guo,Keliang Xie,Zhenhua Wu,Lina Zhao,Yunpeng Bai,Yongtao Ma,Lanjun Wang,Yuting Su,Xi Gao,Weijie Wang,Nicu Sebe,Bruno Lepri,Bingwei Sun*

Main category: cs.LG

TL;DR: Organ-Agents是一个基于大语言模型的多代理框架，用于模拟人类生理系统，具有高精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 利用大语言模型模拟复杂生理系统，为精准诊断和治疗模拟提供可信的数字孪生工具。

Method: 通过监督微调和强化学习协调多代理系统，使用高分辨率时间序列数据进行训练。

Result: 在4,509名患者上表现出高模拟精度（MSE<0.16），并在外部验证中保持稳定。

Conclusion: Organ-Agents是一个可信、可解释且通用的数字孪生工具，适用于重症监护的精准诊断和治疗模拟。

Abstract: Recent advances in large language models (LLMs) have enabled new
possibilities in simulating complex physiological systems. We introduce
Organ-Agents, a multi-agent framework that simulates human physiology via
LLM-driven agents. Each Simulator models a specific system (e.g.,
cardiovascular, renal, immune). Training consists of supervised fine-tuning on
system-specific time-series data, followed by reinforcement-guided coordination
using dynamic reference selection and error correction. We curated data from
7,134 sepsis patients and 7,895 controls, generating high-resolution
trajectories across 9 systems and 125 variables. Organ-Agents achieved high
simulation accuracy on 4,509 held-out patients, with per-system MSEs <0.16 and
robustness across SOFA-based severity strata. External validation on 22,689 ICU
patients from two hospitals showed moderate degradation under distribution
shifts with stable simulation. Organ-Agents faithfully reproduces critical
multi-system events (e.g., hypotension, hyperlactatemia, hypoxemia) with
coherent timing and phase progression. Evaluation by 15 critical care
physicians confirmed realism and physiological plausibility (mean Likert
ratings 3.9 and 3.7). Organ-Agents also enables counterfactual simulations
under alternative sepsis treatment strategies, generating trajectories and
APACHE II scores aligned with matched real-world patients. In downstream early
warning tasks, classifiers trained on synthetic data showed minimal AUROC drops
(<0.04), indicating preserved decision-relevant patterns. These results
position Organ-Agents as a credible, interpretable, and generalizable digital
twin for precision diagnosis, treatment simulation, and hypothesis testing in
critical care.

</details>


### [147] [Online Incident Response Planning under Model Misspecification through Bayesian Learning and Belief Quantization](https://arxiv.org/abs/2508.14385)
*Kim Hammar,Tao Li*

Main category: cs.LG

TL;DR: MOBAL是一种在线贝叶斯学习方法，用于在模型不准确时进行事件响应规划，通过动态编程实现高效响应。


<details>
  <summary>Details</summary>
Motivation: 现有的事件响应决策支持框架依赖详细的系统模型，限制了实际应用。

Method: MOBAL通过贝叶斯学习迭代优化模型猜想，并将其量化为有限马尔可夫模型以进行动态编程。

Result: 实验表明，MOBAL在适应性和对模型不准确的鲁棒性上优于现有方法。

Conclusion: MOBAL提供了一种有效的在线事件响应规划方法，适用于模型不完整或不准确的情况。

Abstract: Effective responses to cyberattacks require fast decisions, even when
information about the attack is incomplete or inaccurate. However, most
decision-support frameworks for incident response rely on a detailed system
model that describes the incident, which restricts their practical utility. In
this paper, we address this limitation and present an online method for
incident response planning under model misspecification, which we call MOBAL:
Misspecified Online Bayesian Learning. MOBAL iteratively refines a conjecture
about the model through Bayesian learning as new information becomes available,
which facilitates model adaptation as the incident unfolds. To determine
effective responses online, we quantize the conjectured model into a finite
Markov model, which enables efficient response planning through dynamic
programming. We prove that Bayesian learning is asymptotically consistent with
respect to the information feedback. Additionally, we establish bounds on
misspecification and quantization errors. Experiments on the CAGE-2 benchmark
show that MOBAL outperforms the state of the art in terms of adaptability and
robustness to model misspecification.

</details>


### [148] [Disentanglement in T-space for Faster and Distributed Training of Diffusion Models with Fewer Latent-states](https://arxiv.org/abs/2508.14413)
*Samarth Gupta,Raghudeep Gadde,Rui Chen,Aleix M. Martinez*

Main category: cs.LG

TL;DR: 论文挑战了扩散模型需要大量潜在状态或时间步的假设，证明通过精心选择噪声计划，少量潜在状态（如32）即可达到与大量状态（如1000）相当的性能，并进一步将极限推至单个潜在状态，实现快速收敛。


<details>
  <summary>Details</summary>
Motivation: 传统扩散模型假设需要大量潜在状态或时间步以确保反向生成过程接近高斯分布，但作者认为这一假设可能不必要，希望通过优化噪声计划减少计算成本。

Method: 通过精心选择噪声计划，减少潜在状态数量（从32到1），并研究完全解耦的T空间模型，结合多个独立训练的单潜在状态模型生成高质量样本。

Result: 实验表明，解耦模型在多种指标上实现了4-6倍的更快收敛，并在两个不同数据集上验证了其有效性。

Conclusion: 论文证明了扩散模型可以通过优化噪声计划和减少潜在状态数量实现高效训练，为实际应用提供了更经济的解决方案。

Abstract: We challenge a fundamental assumption of diffusion models, namely, that a
large number of latent-states or time-steps is required for training so that
the reverse generative process is close to a Gaussian. We first show that with
careful selection of a noise schedule, diffusion models trained over a small
number of latent states (i.e. $T \sim 32$) match the performance of models
trained over a much large number of latent states ($T \sim 1,000$). Second, we
push this limit (on the minimum number of latent states required) to a single
latent-state, which we refer to as complete disentanglement in T-space. We show
that high quality samples can be easily generated by the disentangled model
obtained by combining several independently trained single latent-state models.
We provide extensive experiments to show that the proposed disentangled model
provides 4-6$\times$ faster convergence measured across a variety of metrics on
two different datasets.

</details>


### [149] [Personalized Counterfactual Framework: Generating Potential Outcomes from Wearable Data](https://arxiv.org/abs/2508.14432)
*Ajan Subramanian,Amir M. Rahmani*

Main category: cs.LG

TL;DR: 提出了一种从可穿戴设备数据中学习个性化反事实模型的框架，用于探索生活方式选择对个体健康的影响。


<details>
  <summary>Details</summary>
Motivation: 解决从复杂的可穿戴设备数据中提取个性化健康洞察的挑战。

Method: 通过多模态相似性分析增强个体数据，使用时序PC算法发现预测关系，并训练梯度提升机量化个体效应。

Result: 预测准确性较高（心率MAE 4.71 bpm），反事实干预的合理性高（中位数0.9643），显示了个体间对生活方式变化的显著差异。

Conclusion: 该框架为探索个性化健康动态和生成个体对生活方式变化的假设提供了工具。

Abstract: Wearable sensor data offer opportunities for personalized health monitoring,
yet deriving actionable insights from their complex, longitudinal data streams
is challenging. This paper introduces a framework to learn personalized
counterfactual models from multivariate wearable data. This enables exploring
what-if scenarios to understand potential individual-specific outcomes of
lifestyle choices. Our approach first augments individual datasets with data
from similar patients via multi-modal similarity analysis. We then use a
temporal PC (Peter-Clark) algorithm adaptation to discover predictive
relationships, modeling how variables at time t-1 influence physiological
changes at time t. Gradient Boosting Machines are trained on these discovered
relationships to quantify individual-specific effects. These models drive a
counterfactual engine projecting physiological trajectories under hypothetical
interventions (e.g., activity or sleep changes). We evaluate the framework via
one-step-ahead predictive validation and by assessing the plausibility and
impact of interventions. Evaluation showed reasonable predictive accuracy
(e.g., mean heart rate MAE 4.71 bpm) and high counterfactual plausibility
(median 0.9643). Crucially, these interventions highlighted significant
inter-individual variability in response to hypothetical lifestyle changes,
showing the framework's potential for personalized insights. This work provides
a tool to explore personalized health dynamics and generate hypotheses on
individual responses to lifestyle changes.

</details>


### [150] [DuPO: Enabling Reliable LLM Self-Verification via Dual Preference Optimization](https://arxiv.org/abs/2508.14460)
*Shuaijie She,Yu Bao,Yu Lu,Lu Xu,Tao Li,Wenhao Zhu,Shujian Huang,Shanbo Cheng,Lu Lu,Yuxuan Wang*

Main category: cs.LG

TL;DR: DuPO是一种基于双重学习的偏好优化框架，通过广义对偶性生成无标注反馈，解决了RLVR依赖昂贵标签和传统双重学习限于严格对偶任务的问题。


<details>
  <summary>Details</summary>
Motivation: 解决RLVR依赖昂贵标签和传统双重学习限于严格对偶任务的局限性。

Method: 将原始任务输入分解为已知和未知部分，构建对偶任务以重建未知部分，利用重建质量作为自监督奖励优化原始任务。

Result: 在翻译、数学推理和推理时重排序任务中取得显著提升。

Conclusion: DuPO是一种可扩展、通用且无需标注的LLM优化范式。

Abstract: We present DuPO, a dual learning-based preference optimization framework that
generates annotation-free feedback via a generalized duality. DuPO addresses
two key limitations: Reinforcement Learning with Verifiable Rewards (RLVR)'s
reliance on costly labels and applicability restricted to verifiable tasks, and
traditional dual learning's restriction to strictly dual task pairs (e.g.,
translation and back-translation). Specifically, DuPO decomposes a primal
task's input into known and unknown components, then constructs its dual task
to reconstruct the unknown part using the primal output and known information
(e.g., reversing math solutions to recover hidden variables), broadening
applicability to non-invertible tasks. The quality of this reconstruction
serves as a self-supervised reward to optimize the primal task, synergizing
with LLMs' ability to instantiate both tasks via a single model. Empirically,
DuPO achieves substantial gains across diverse tasks: it enhances the average
translation quality by 2.13 COMET over 756 directions, boosts the mathematical
reasoning accuracy by an average of 6.4 points on three challenge benchmarks,
and enhances performance by 9.3 points as an inference-time reranker (trading
computation for accuracy). These results position DuPO as a scalable, general,
and annotation-free paradigm for LLM optimization.

</details>


### [151] [Fast Symbolic Regression Benchmarking](https://arxiv.org/abs/2508.14481)
*Viktor Martinek*

Main category: cs.LG

TL;DR: 该论文改进了符号回归（SR）的基准测试方法，通过引入可接受的表达式列表和早期终止机制，提高了算法的重新发现率并减少了计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试过于强调恢复单一表达式形式或依赖计算机代数系统评估成功，且搜索过程在发现表达式后仍继续，导致效率低下。

Method: 提出了一种新的基准测试方法，包括精心设计的可接受表达式列表和早期终止回调机制，并以SRSD基准问题为基础进行测试。

Result: SymbolicRegression.jl的重新发现率从26.7%提高到44.7%，计算开销减少41.2%；TiSR的重新发现率为69.4%，时间节省63%。

Conclusion: 新方法显著提高了符号回归算法的效率和重新发现率，为未来的基准测试提供了更优的框架。

Abstract: Symbolic regression (SR) uncovers mathematical models from data. Several
benchmarks have been proposed to compare the performance of SR algorithms.
However, existing ground-truth rediscovery benchmarks overemphasize the
recovery of "the one" expression form or rely solely on computer algebra
systems (such as SymPy) to assess success. Furthermore, existing benchmarks
continue the expression search even after its discovery. We improve upon these
issues by introducing curated lists of acceptable expressions, and a callback
mechanism for early termination. As a starting point, we use the symbolic
regression for scientific discovery (SRSD) benchmark problems proposed by
Yoshitomo et al., and benchmark the two SR packages SymbolicRegression.jl and
TiSR. The new benchmarking method increases the rediscovery rate of
SymbolicRegression.jl from 26.7%, as reported by Yoshitomo et at., to 44.7%.
Performing the benchmark takes 41.2% less computational expense. TiSR's
rediscovery rate is 69.4%, while performing the benchmark saves 63% time.

</details>


### [152] [On the notion of missingness for path attribution explainability methods in medical settings: Guiding the selection of medically meaningful baselines](https://arxiv.org/abs/2508.14482)
*Alexander Geiger,Lars Wagner,Daniel Rueckert,Dirk Wilhelm,Alissa Jell*

Main category: cs.LG

TL;DR: 提出了一种基于反事实的基线选择方法，用于医学数据中的路径归因解释，提高了归因的准确性和医学相关性。


<details>
  <summary>Details</summary>
Motivation: 医学领域中深度学习的可解释性至关重要，但传统基线选择方法（如全零输入）在医学上下文中语义无意义，甚至可能误导。

Method: 使用变分自编码器生成与输入接近的临床正常反事实基线，动态适应每个输入。

Result: 在三个医学数据集上验证，反事实基线比传统基线产生更忠实和医学相关的归因。

Conclusion: 反事实基线为医学数据提供了一种更准确的缺失特征表示，提升了模型解释的临床可信度。

Abstract: The explainability of deep learning models remains a significant challenge,
particularly in the medical domain where interpretable outputs are critical for
clinical trust and transparency. Path attribution methods such as Integrated
Gradients rely on a baseline input representing the absence of relevant
features ("missingness"). Commonly used baselines, such as all-zero inputs, are
often semantically meaningless, especially in medical contexts where
missingness can itself be informative. While alternative baseline choices have
been explored, existing methods lack a principled approach to dynamically
select baselines tailored to each input. In this work, we examine the notion of
missingness in the medical setting, analyze its implications for baseline
selection, and introduce a counterfactual-guided approach to address the
limitations of conventional baselines. We argue that a clinically normal but
input-close counterfactual represents a more accurate representation of a
meaningful absence of features in medical data. To implement this, we use a
Variational Autoencoder to generate counterfactual baselines, though our
concept is generative-model-agnostic and can be applied with any suitable
counterfactual method. We evaluate the approach on three distinct medical data
sets and empirically demonstrate that counterfactual baselines yield more
faithful and medically relevant attributions compared to standard baseline
choices.

</details>


### [153] [Semantic Energy: Detecting LLM Hallucination Beyond Entropy](https://arxiv.org/abs/2508.14496)
*Huan Ma,Jiadong Pan,Jing Liu,Yan Chen,Joey Tianyi Zhou,Guangyu Wang,Qinghua Hu,Hua Wu,Changqing Zhang,Haifeng Wang*

Main category: cs.LG

TL;DR: 论文提出了一种名为Semantic Energy的新框架，通过直接利用LLMs的logits来改进不确定性估计，从而更有效地检测幻觉。


<details>
  <summary>Details</summary>
Motivation: LLMs在实际应用中容易产生幻觉，导致错误决策。现有的不确定性估计方法（如语义熵）依赖后softmax概率，无法捕捉模型的固有不确定性。

Method: 提出Semantic Energy框架，结合语义聚类和Boltzmann-inspired能量分布，直接利用LLMs的倒数第二层logits来估计不确定性。

Result: 实验表明，Semantic Energy在多基准测试中显著提升了幻觉检测和不确定性估计的准确性。

Conclusion: Semantic Energy为下游应用（如幻觉检测）提供了更可靠的不确定性信号，解决了语义熵的局限性。

Abstract: Large Language Models (LLMs) are being increasingly deployed in real-world
applications, but they remain susceptible to hallucinations, which produce
fluent yet incorrect responses and lead to erroneous decision-making.
Uncertainty estimation is a feasible approach to detect such hallucinations.
For example, semantic entropy estimates uncertainty by considering the semantic
diversity across multiple sampled responses, thus identifying hallucinations.
However, semantic entropy relies on post-softmax probabilities and fails to
capture the model's inherent uncertainty, causing it to be ineffective in
certain scenarios. To address this issue, we introduce Semantic Energy, a novel
uncertainty estimation framework that leverages the inherent confidence of LLMs
by operating directly on logits of penultimate layer. By combining semantic
clustering with a Boltzmann-inspired energy distribution, our method better
captures uncertainty in cases where semantic entropy fails. Experiments across
multiple benchmarks show that Semantic Energy significantly improves
hallucination detection and uncertainty estimation, offering more reliable
signals for downstream applications such as hallucination detection.

</details>


### [154] [Exact Shapley Attributions in Quadratic-time for FANOVA Gaussian Processes](https://arxiv.org/abs/2508.14499)
*Majid Mohammadi,Krikamol Muandet,Ilaria Tiddi,Annette Ten Teije,Siu Lun Chau*

Main category: cs.LG

TL;DR: 提出了一种在FANOVA GP模型中高效计算Shapley值的方法，将时间复杂度从指数级降至二次方，适用于局部和全局解释。


<details>
  <summary>Details</summary>
Motivation: Shapley值在机器学习中用于特征重要性评估，但计算复杂度高，尤其在概率模型（如高斯过程）中更复杂。

Method: 利用FANOVA GP的闭式Möbius表示和递归算法，高效计算Shapley值的均值和方差。

Result: 实现了在二次时间内计算局部和全局的精确Shapley值，并捕捉了不确定性。

Conclusion: 该方法提升了可解释AI的实用性，提供了更高效、理论可靠且考虑不确定性的解释。

Abstract: Shapley values are widely recognized as a principled method for attributing
importance to input features in machine learning. However, the exact
computation of Shapley values scales exponentially with the number of features,
severely limiting the practical application of this powerful approach. The
challenge is further compounded when the predictive model is probabilistic - as
in Gaussian processes (GPs) - where the outputs are random variables rather
than point estimates, necessitating additional computational effort in modeling
higher-order moments. In this work, we demonstrate that for an important class
of GPs known as FANOVA GP, which explicitly models all main effects and
interactions, *exact* Shapley attributions for both local and global
explanations can be computed in *quadratic time*. For local, instance-wise
explanations, we define a stochastic cooperative game over function components
and compute the exact stochastic Shapley value in quadratic time only,
capturing both the expected contribution and uncertainty. For global
explanations, we introduce a deterministic, variance-based value function and
compute exact Shapley values that quantify each feature's contribution to the
model's overall sensitivity. Our methods leverage a closed-form (stochastic)
M\"{o}bius representation of the FANOVA decomposition and introduce recursive
algorithms, inspired by Newton's identities, to efficiently compute the mean
and variance of Shapley values. Our work enhances the utility of explainable
AI, as demonstrated by empirical studies, by providing more scalable,
axiomatically sound, and uncertainty-aware explanations for predictions
generated by structured probabilistic models.

</details>


### [155] [Artificial Intelligence-Based Multiscale Temporal Modeling for Anomaly Detection in Cloud Services](https://arxiv.org/abs/2508.14503)
*Lian Lian,Yilin Li,Song Han,Renzi Meng,Sibo Wang,Ming Wang*

Main category: cs.LG

TL;DR: 提出了一种基于Transformer架构的多尺度特征感知异常检测方法，用于解决云服务环境中时间建模和尺度感知特征表示的局限性。


<details>
  <summary>Details</summary>
Motivation: 针对云服务环境中高维监控数据的时间建模和尺度感知特征表示不足的问题，提出改进方法。

Method: 结合改进的Transformer模块和多尺度特征构建路径，通过自注意力机制和并行编码提取多粒度特征，并设计注意力加权融合模块动态调整各尺度贡献。

Result: 实验结果表明，该方法在精度、召回率、AUC和F1分数等关键指标上优于主流基线模型，且在扰动条件下表现稳定。

Conclusion: 该方法在复杂云环境中表现出卓越的异常检测能力和鲁棒性。

Abstract: This study proposes an anomaly detection method based on the Transformer
architecture with integrated multiscale feature perception, aiming to address
the limitations of temporal modeling and scale-aware feature representation in
cloud service environments. The method first employs an improved Transformer
module to perform temporal modeling on high-dimensional monitoring data, using
a self-attention mechanism to capture long-range dependencies and contextual
semantics. Then, a multiscale feature construction path is introduced to
extract temporal features at different granularities through downsampling and
parallel encoding. An attention-weighted fusion module is designed to
dynamically adjust the contribution of each scale to the final decision,
enhancing the model's robustness in anomaly pattern modeling. In the input
modeling stage, standardized multidimensional time series are constructed,
covering core signals such as CPU utilization, memory usage, and task
scheduling states, while positional encoding is used to strengthen the model's
temporal awareness. A systematic experimental setup is designed to evaluate
performance, including comparative experiments and hyperparameter sensitivity
analysis, focusing on the impact of optimizers, learning rates, anomaly ratios,
and noise levels. Experimental results show that the proposed method
outperforms mainstream baseline models in key metrics, including precision,
recall, AUC, and F1-score, and maintains strong stability and detection
performance under various perturbation conditions, demonstrating its superior
capability in complex cloud environments.

</details>


### [156] [Great GATsBi: Hybrid, Multimodal, Trajectory Forecasting for Bicycles using Anticipation Mechanism](https://arxiv.org/abs/2508.14523)
*Kevin Riehl,Shaimaa K. El-Baklish,Anastasios Kouvelas,Michail A. Makridis*

Main category: cs.LG

TL;DR: 论文提出了一种基于领域知识的混合多模态自行车轨迹预测框架Great GATsBi，结合物理和社会模型，显著提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: 自行车在交通事故中占比较高，但现有研究主要关注行人和机动车，因此需要专门针对自行车的轨迹预测方法。

Method: 采用物理模型（受机动车启发）和社会模型（受行人启发）的混合框架，利用图注意力网络建模社会交互。

Result: 模型在短期和长期预测中均优于现有方法，并通过大规模骑行实验验证了其性能。

Conclusion: Great GATsBi框架有效结合了物理和社会模型，为自行车轨迹预测提供了新思路。

Abstract: Accurate prediction of road user movement is increasingly required by many
applications ranging from advanced driver assistance systems to autonomous
driving, and especially crucial for road safety. Even though most traffic
accident fatalities account to bicycles, they have received little attention,
as previous work focused mainly on pedestrians and motorized vehicles. In this
work, we present the Great GATsBi, a domain-knowledge-based, hybrid, multimodal
trajectory prediction framework for bicycles. The model incorporates both
physics-based modeling (inspired by motorized vehicles) and social-based
modeling (inspired by pedestrian movements) to explicitly account for the dual
nature of bicycle movement. The social interactions are modeled with a graph
attention network, and include decayed historical, but also anticipated, future
trajectory data of a bicycles neighborhood, following recent insights from
psychological and social studies. The results indicate that the proposed
ensemble of physics models -- performing well in the short-term predictions --
and social models -- performing well in the long-term predictions -- exceeds
state-of-the-art performance. We also conducted a controlled mass-cycling
experiment to demonstrate the framework's performance when forecasting bicycle
trajectories and modeling social interactions with road users.

</details>


### [157] [Beyond ReLU: Chebyshev-DQN for Enhanced Deep Q-Networks](https://arxiv.org/abs/2508.14536)
*Saman Yazdannik,Morteza Tayefi,Shamim Sanisales*

Main category: cs.LG

TL;DR: 论文提出了一种基于切比雪夫多项式的DQN架构（Ch-DQN），在CartPole-v1任务中表现优于标准DQN，但多项式次数的选择是关键。


<details>
  <summary>Details</summary>
Motivation: 标准DQN的神经网络可能难以高效表示复杂值函数，切比雪夫多项式因其强大的函数逼近能力可能提升性能。

Method: 将切比雪夫多项式基集成到DQN框架中，构建Ch-DQN，并在CartPole-v1上测试不同多项式次数的影响。

Result: Ch-DQN（N=4）比标准DQN性能提升约39%，但多项式次数过高（N=8）会损害学习效果。

Conclusion: 切比雪夫多项式在深度强化学习中具有潜力，但需权衡模型复杂度。

Abstract: The performance of Deep Q-Networks (DQN) is critically dependent on the
ability of its underlying neural network to accurately approximate the
action-value function. Standard function approximators, such as multi-layer
perceptrons, may struggle to efficiently represent the complex value landscapes
inherent in many reinforcement learning problems. This paper introduces a novel
architecture, the Chebyshev-DQN (Ch-DQN), which integrates a Chebyshev
polynomial basis into the DQN framework to create a more effective feature
representation. By leveraging the powerful function approximation properties of
Chebyshev polynomials, we hypothesize that the Ch-DQN can learn more
efficiently and achieve higher performance. We evaluate our proposed model on
the CartPole-v1 benchmark and compare it against a standard DQN with a
comparable number of parameters. Our results demonstrate that the Ch-DQN with a
moderate polynomial degree (N=4) achieves significantly better asymptotic
performance, outperforming the baseline by approximately 39\%. However, we also
find that the choice of polynomial degree is a critical hyperparameter, as a
high degree (N=8) can be detrimental to learning. This work validates the
potential of using orthogonal polynomial bases in deep reinforcement learning
while also highlighting the trade-offs involved in model complexity.

</details>


### [158] [FedEve: On Bridging the Client Drift and Period Drift for Cross-device Federated Learning](https://arxiv.org/abs/2508.14539)
*Tao Shen,Zexi Li,Didi Zhu,Ziyu Zhao,Chao Wu,Fei Wu*

Main category: cs.LG

TL;DR: 论文研究了联邦学习中的两种漂移（周期漂移和客户端漂移），提出了FedEve方法以减少漂移对模型性能的影响。


<details>
  <summary>Details</summary>
Motivation: 数据异构性是联邦学习的主要挑战，周期漂移和客户端漂移会进一步加剧性能下降，但周期漂移的影响尚未被充分研究。

Method: 提出了预测-观察框架及其实例化方法FedEve，通过两种漂移的相互补偿来降低整体影响。

Result: 理论分析和实验表明，FedEve在非独立同分布数据上优于其他方法。

Conclusion: FedEve能有效缓解周期漂移和客户端漂移，提升跨设备联邦学习的性能。

Abstract: Federated learning (FL) is a machine learning paradigm that allows multiple
clients to collaboratively train a shared model without exposing their private
data. Data heterogeneity is a fundamental challenge in FL, which can result in
poor convergence and performance degradation. Client drift has been recognized
as one of the factors contributing to this issue resulting from the multiple
local updates in FedAvg. However, in cross-device FL, a different form of drift
arises due to the partial client participation, but it has not been studied
well. This drift, we referred as period drift, occurs as participating clients
at each communication round may exhibit distinct data distribution that
deviates from that of all clients. It could be more harmful than client drift
since the optimization objective shifts with every round.
  In this paper, we investigate the interaction between period drift and client
drift, finding that period drift can have a particularly detrimental effect on
cross-device FL as the degree of data heterogeneity increases. To tackle these
issues, we propose a predict-observe framework and present an instantiated
method, FedEve, where these two types of drift can compensate each other to
mitigate their overall impact. We provide theoretical evidence that our
approach can reduce the variance of model updates. Extensive experiments
demonstrate that our method outperforms alternatives on non-iid data in
cross-device settings.

</details>


### [159] [Adaptively Robust LLM Inference Optimization under Prediction Uncertainty](https://arxiv.org/abs/2508.14544)
*Zixi Chen,Yinyu Ye,Zijie Zhou*

Main category: cs.LG

TL;DR: 论文研究了如何优化大型语言模型（LLM）推理调度以最小化总延迟，提出两种算法：保守的$\mathcal{A}_{\\max}$和自适应的$\mathcal{A}_{\\min}$，后者通过动态调整预测输出长度实现高效调度。


<details>
  <summary>Details</summary>
Motivation: LLM推理是一个在线、多任务且高能耗的过程，需高效调度以减少延迟和能耗，但输出长度未知是主要挑战。

Method: 提出$\mathcal{A}_{\\max}$和$\mathcal{A}_{\\min}$算法，利用机器学习预测输出长度区间，$\mathcal{A}_{\\min}$动态调整预测值。

Result: $\mathcal{A}_{\\min}$在数值模拟中表现接近最优调度器，且仅依赖预测区间的下限，更具鲁棒性。

Conclusion: $\mathcal{A}_{\\min}$通过动态调整预测输出长度，实现了高效且鲁棒的LLM推理调度。

Abstract: We study the problem of optimizing Large Language Model (LLM) inference
scheduling to minimize total latency. LLM inference is an online and multi-task
service process and also heavily energy consuming by which a pre-trained LLM
processes input requests and generates output tokens sequentially. Therefore,
it is vital to improve its scheduling efficiency and reduce the power
consumption while a great amount of prompt requests are arriving. A key
challenge in LLM inference scheduling is that while the prompt length is known
upon arrival, the output length, which critically impacts memory usage and
processing time, is unknown. To address this uncertainty, we propose algorithms
that leverage machine learning to predict output lengths, assuming the
prediction provides an interval classification (min-max range) for each
request.
  We first design a conservative algorithm, $\mathcal{A}_{\max}$, which
schedules requests based on the upper bound of predicted output lengths to
prevent memory overflow. However, this approach is overly conservative: as
prediction accuracy decreases, performance degrades significantly due to
potential overestimation. To overcome this limitation, we propose
$\mathcal{A}_{\min}$, an adaptive algorithm that initially treats the predicted
lower bound as the output length and dynamically refines this estimate during
inferencing. We prove that $\mathcal{A}_{\min}$ achieves a log-scale
competitive ratio. Through numerical simulations, we demonstrate that
$\mathcal{A}_{\min}$ often performs nearly as well as the hindsight scheduler,
highlighting both its efficiency and robustness in practical scenarios.
Moreover, $\mathcal{A}_{\min}$ relies solely on the lower bound of the
prediction interval--an advantageous design choice since upper bounds on output
length are typically more challenging to predict accurately.

</details>


### [160] [Cooperative SGD with Dynamic Mixing Matrices](https://arxiv.org/abs/2508.14565)
*Soumya Sarkar,Shweta Jain*

Main category: cs.LG

TL;DR: 提出了一种统一框架，用于动态拓扑的分布式SGD算法，提升了收敛性能。


<details>
  <summary>Details</summary>
Motivation: 现有分布式SGD假设固定拓扑和均匀节点贡献，实验表明这些假设次优。

Method: 开发了涵盖多种动态拓扑的本地更新SGD算法框架。

Result: 提供了优于或匹配现有工作的收敛理论保证。

Conclusion: 动态拓扑和非均匀聚合策略能显著提升模型性能。

Abstract: One of the most common methods to train machine learning algorithms today is
the stochastic gradient descent (SGD). In a distributed setting, SGD-based
algorithms have been shown to converge theoretically under specific
circumstances. A substantial number of works in the distributed SGD setting
assume a fixed topology for the edge devices. These papers also assume that the
contribution of nodes to the global model is uniform. However, experiments have
shown that such assumptions are suboptimal and a non uniform aggregation
strategy coupled with a dynamically shifting topology and client selection can
significantly improve the performance of such models. This paper details a
unified framework that covers several Local-Update SGD-based distributed
algorithms with dynamic topologies and provides improved or matching
theoretical guarantees on convergence compared to existing work.

</details>


### [161] [A Comprehensive Evaluation of the Sensitivity of Density-Ratio Estimation Based Fairness Measurement in Regression](https://arxiv.org/abs/2508.14576)
*Abdalwahab Almajed,Maryam Tabar,Peyman Najafirad*

Main category: cs.LG

TL;DR: 本文研究了不同密度比估计算法对回归中公平性测量的影响，发现选择不同核心算法会导致不一致的公平性结果。


<details>
  <summary>Details</summary>
Motivation: 现有研究未探讨密度比估计算法选择对公平性测量的敏感性，本文旨在填补这一空白。

Method: 开发了多种基于不同密度比估计核心的公平性测量方法，并进行了全面实验比较。

Result: 实验表明，密度比估计核心的选择会显著影响公平性测量结果，甚至导致算法间公平性相对关系不一致。

Conclusion: 基于密度比估计的回归公平性测量存在重大问题，需进一步研究以提高其可靠性。

Abstract: The prevalence of algorithmic bias in Machine Learning (ML)-driven approaches
has inspired growing research on measuring and mitigating bias in the ML
domain. Accordingly, prior research studied how to measure fairness in
regression which is a complex problem. In particular, recent research proposed
to formulate it as a density-ratio estimation problem and relied on a Logistic
Regression-driven probabilistic classifier-based approach to solve it. However,
there are several other methods to estimate a density ratio, and to the best of
our knowledge, prior work did not study the sensitivity of such fairness
measurement methods to the choice of underlying density ratio estimation
algorithm. To fill this gap, this paper develops a set of fairness measurement
methods with various density-ratio estimation cores and thoroughly investigates
how different cores would affect the achieved level of fairness. Our
experimental results show that the choice of density-ratio estimation core
could significantly affect the outcome of fairness measurement method, and
even, generate inconsistent results with respect to the relative fairness of
various algorithms. These observations suggest major issues with density-ratio
estimation based fairness measurement in regression and a need for further
research to enhance their reliability.

</details>


### [162] [DualNILM: Energy Injection Identification Enabled Disaggregation with Deep Multi-Task Learning](https://arxiv.org/abs/2508.14600)
*Xudong Wang,Guoming Tang,Junyu Xue,Srinivasan Keshav,Tongxin Li,Chris Ding*

Main category: cs.LG

TL;DR: DualNILM是一种基于Transformer的多任务学习框架，用于解决非侵入式负载监测（NILM）中因分布式能源引入导致的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 分布式能源（如太阳能板和电池存储）的普及使得传统NILM方法性能下降，需要新的解决方案。

Method: DualNILM结合序列到点和序列到序列策略，通过多任务学习同时识别电器状态和注入能量。

Result: 实验表明，DualNILM在双任务上表现优异，显著优于传统方法。

Conclusion: DualNILM为NILM在分布式能源环境中的应用提供了有效解决方案。

Abstract: Non-Intrusive Load Monitoring (NILM) offers a cost-effective method to obtain
fine-grained appliance-level energy consumption in smart homes and building
applications. However, the increasing adoption of behind-the-meter energy
sources, such as solar panels and battery storage, poses new challenges for
conventional NILM methods that rely solely on at-the-meter data. The injected
energy from the behind-the-meter sources can obscure the power signatures of
individual appliances, leading to a significant decline in NILM performance. To
address this challenge, we present DualNILM, a deep multi-task learning
framework designed for the dual tasks of appliance state recognition and
injected energy identification in NILM. By integrating sequence-to-point and
sequence-to-sequence strategies within a Transformer-based architecture,
DualNILM can effectively capture multi-scale temporal dependencies in the
aggregate power consumption patterns, allowing for accurate appliance state
recognition and energy injection identification. We conduct validation of
DualNILM using both self-collected and synthesized open NILM datasets that
include both appliance-level energy consumption and energy injection. Extensive
experimental results demonstrate that DualNILM maintains an excellent
performance for the dual tasks in NILM, much outperforming conventional
methods.

</details>


### [163] [Measuring IIA Violations in Similarity Choices with Bayesian Models](https://arxiv.org/abs/2508.14615)
*Hugo Sales Corrêa,Suryanarayana Sankagiri,Daniel Ratton Figueiredo,Matthias Grossglauser*

Main category: cs.LG

TL;DR: 论文提出两种统计方法测试相似性选择中的IIA假设，发现显著违反，并揭示上下文效应是主要原因。


<details>
  <summary>Details</summary>
Motivation: 相似性选择中IIA假设的违反研究较少，且测试复杂，因此需要新方法来量化和分析。

Method: 提出经典拟合优度检验和基于后验预测检查的贝叶斯方法，设计两种数据集进行测试。

Result: 在两个数据集中均发现显著IIA违反，且程度相似，表明上下文效应是主要驱动因素。

Conclusion: 需要开发考虑上下文效应的新相似性选择模型。

Abstract: Similarity choice data occur when humans make choices among alternatives
based on their similarity to a target, e.g., in the context of information
retrieval and in embedding learning settings. Classical metric-based models of
similarity choice assume independence of irrelevant alternatives (IIA), a
property that allows for a simpler formulation. While IIA violations have been
detected in many discrete choice settings, the similarity choice setting has
received scant attention. This is because the target-dependent nature of the
choice complicates IIA testing. We propose two statistical methods to test for
IIA: a classical goodness-of-fit test and a Bayesian counterpart based on the
framework of Posterior Predictive Checks (PPC). This Bayesian approach, our
main technical contribution, quantifies the degree of IIA violation beyond its
mere significance. We curate two datasets: one with choice sets designed to
elicit IIA violations, and another with randomly generated choice sets from the
same item universe. Our tests confirmed significant IIA violations on both
datasets, and notably, we find a comparable degree of violation between them.
Further, we devise a new PPC test for population homogeneity. Results show that
the population is indeed homogenous, suggesting that the IIA violations are
driven by context effects -- specifically, interactions within the choice sets.
These results highlight the need for new similarity choice models that account
for such context effects.

</details>


### [164] [A Fuzzy-Enhanced Explainable AI Framework for Flight Continuous Descent Operations Classification](https://arxiv.org/abs/2508.14618)
*Amin Noroozi,Sandaruwan K. Sethunge,Elham Norouzi,Phat T. Phan,Kavinda U. Waduge,Md. Arafatur Rahman*

Main category: cs.LG

TL;DR: 提出了一种结合模糊逻辑、机器学习和SHAP分析的FEXAI框架，用于分析连续下降操作（CDO）的性能影响因素，并生成可解释的规则。


<details>
  <summary>Details</summary>
Motivation: 尽管CDO具有操作和环境优势，但缺乏对其性能影响因素的系统研究，且现有方法缺乏航空领域所需的透明度和可解释性。

Method: 使用ADS-B数据收集了1094次航班的29个特征，应用机器学习和SHAP分析分类CDO依从性，并构建模糊规则分类器。

Result: 模型分类准确率超过90%，识别出下降速率、下降段数量和航向变化为CDO性能的关键预测因素。

Conclusion: FEXAI方法为操作决策支持提供了新途径，可集成到航空工具中以实现实时建议。

Abstract: Continuous Descent Operations (CDO) involve smooth, idle-thrust descents that
avoid level-offs, reducing fuel burn, emissions, and noise while improving
efficiency and passenger comfort. Despite its operational and environmental
benefits, limited research has systematically examined the factors influencing
CDO performance. Moreover, many existing methods in related areas, such as
trajectory optimization, lack the transparency required in aviation, where
explainability is critical for safety and stakeholder trust. This study
addresses these gaps by proposing a Fuzzy-Enhanced Explainable AI (FEXAI)
framework that integrates fuzzy logic with machine learning and SHapley
Additive exPlanations (SHAP) analysis. For this purpose, a comprehensive
dataset of 29 features, including 11 operational and 18 weather-related
features, was collected from 1,094 flights using Automatic Dependent
Surveillance-Broadcast (ADS-B) data. Machine learning models and SHAP were then
applied to classify flights' CDO adherence levels and rank features by
importance. The three most influential features, as identified by SHAP scores,
were then used to construct a fuzzy rule-based classifier, enabling the
extraction of interpretable fuzzy rules. All models achieved classification
accuracies above 90%, with FEXAI providing meaningful, human-readable rules for
operational users. Results indicated that the average descent rate within the
arrival route, the number of descent segments, and the average change in
directional heading during descent were the strongest predictors of CDO
performance. The FEXAI method proposed in this study presents a novel pathway
for operational decision support and could be integrated into aviation tools to
enable real-time advisories that maintain CDO adherence under varying
operational conditions.

</details>


### [165] [Clinical semantics for lung cancer prediction](https://arxiv.org/abs/2508.14627)
*Luis H. John,Jan A. Kors,Jenna M. Reps,Peter R. Rijnbeek,Egill A. Fridgeirsson*

Main category: cs.LG

TL;DR: 该研究通过将SNOMED医学术语层次结构映射到双曲空间（Poincaré嵌入），改进了肺癌发病预测模型，结合深度学习架构（ResNet和Transformer）提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有临床预测模型通常忽略临床概念间的语义关系，本研究旨在通过整合领域特定的语义信息来改进预测。

Method: 利用SNOMED分类构建临床知识图谱，生成Poincaré嵌入，并将其融入ResNet和Transformer模型进行预测。

Result: 使用Poincaré嵌入的模型在区分性能上有所提升，ResNet模型在校准性能上表现更优。

Conclusion: 双曲空间嵌入临床知识图谱并结合深度学习模型，是一种可行的方法，能够结合数据驱动特征提取与临床知识。

Abstract: Background: Existing clinical prediction models often represent patient data
using features that ignore the semantic relationships between clinical
concepts. This study integrates domain-specific semantic information by mapping
the SNOMED medical term hierarchy into a low-dimensional hyperbolic space using
Poincar\'e embeddings, with the aim of improving lung cancer onset prediction.
  Methods: Using a retrospective cohort from the Optum EHR dataset, we derived
a clinical knowledge graph from the SNOMED taxonomy and generated Poincar\'e
embeddings via Riemannian stochastic gradient descent. These embeddings were
then incorporated into two deep learning architectures, a ResNet and a
Transformer model. Models were evaluated for discrimination (area under the
receiver operating characteristic curve) and calibration (average absolute
difference between observed and predicted probabilities) performance.
  Results: Incorporating pre-trained Poincar\'e embeddings resulted in modest
and consistent improvements in discrimination performance compared to baseline
models using randomly initialized Euclidean embeddings. ResNet models,
particularly those using a 10-dimensional Poincar\'e embedding, showed enhanced
calibration, whereas Transformer models maintained stable calibration across
configurations.
  Discussion: Embedding clinical knowledge graphs into hyperbolic space and
integrating these representations into deep learning models can improve lung
cancer onset prediction by preserving the hierarchical structure of clinical
terminologies used for prediction. This approach demonstrates a feasible method
for combining data-driven feature extraction with established clinical
knowledge.

</details>


### [166] [Understanding Data Influence with Differential Approximation](https://arxiv.org/abs/2508.14648)
*Haoru Tan,Sitong Wu,Xiuzhe Wu,Wang Wang,Bo Zhao,Zeke Xie,Gui-Song Xia,Xiaojuan Qi*

Main category: cs.LG

TL;DR: Diff-In是一种新的样本影响力近似方法，通过累积连续学习步骤中的影响力差异，避免了现有方法对模型凸性的要求，并在计算效率上保持与一阶方法相当。


<details>
  <summary>Details</summary>
Motivation: 现有数据影响力分析工具在准确性和模型假设（如凸性）上存在局限，难以有效应用于实际场景。

Method: 提出Diff-In方法，通过二阶近似累积样本在连续训练迭代中的影响力差异，高效计算Hessian与梯度的乘积。

Result: 理论分析和实验证明Diff-In在近似误差上显著优于现有方法，并在数据清洗、删除和核心集选择等任务中表现优异。

Conclusion: Diff-In是一种高效、可扩展的样本影响力分析方法，适用于大规模数据任务。

Abstract: Data plays a pivotal role in the groundbreaking advancements in artificial
intelligence. The quantitative analysis of data significantly contributes to
model training, enhancing both the efficiency and quality of data utilization.
However, existing data analysis tools often lag in accuracy. For instance, many
of these tools even assume that the loss function of neural networks is convex.
These limitations make it challenging to implement current methods effectively.
In this paper, we introduce a new formulation to approximate a sample's
influence by accumulating the differences in influence between consecutive
learning steps, which we term Diff-In. Specifically, we formulate the
sample-wise influence as the cumulative sum of its changes/differences across
successive training iterations. By employing second-order approximations, we
approximate these difference terms with high accuracy while eliminating the
need for model convexity required by existing methods. Despite being a
second-order method, Diff-In maintains computational complexity comparable to
that of first-order methods and remains scalable. This efficiency is achieved
by computing the product of the Hessian and gradient, which can be efficiently
approximated using finite differences of first-order gradients. We assess the
approximation accuracy of Diff-In both theoretically and empirically. Our
theoretical analysis demonstrates that Diff-In achieves significantly lower
approximation error compared to existing influence estimators. Extensive
experiments further confirm its superior performance across multiple benchmark
datasets in three data-centric tasks: data cleaning, data deletion, and coreset
selection. Notably, our experiments on data pruning for large-scale
vision-language pre-training show that Diff-In can scale to millions of data
points and outperforms strong baselines.

</details>


### [167] [ELATE: Evolutionary Language model for Automated Time-series Engineering](https://arxiv.org/abs/2508.14667)
*Andrew Murray,Danial Dervovic,Michael Cashmore*

Main category: cs.LG

TL;DR: ELATE利用语言模型和进化框架自动化时间序列特征工程，提升预测精度8.4%。


<details>
  <summary>Details</summary>
Motivation: 传统特征工程耗时且依赖人工，现有自动化方法计算成本高且缺乏领域洞察。

Method: 结合时间序列统计指标和特征重要性，语言模型提出新特征变换。

Result: 实验显示ELATE平均提升预测精度8.4%。

Conclusion: ELATE有效自动化特征工程，显著提升时间序列预测性能。

Abstract: Time-series prediction involves forecasting future values using machine
learning models. Feature engineering, whereby existing features are transformed
to make new ones, is critical for enhancing model performance, but is often
manual and time-intensive. Existing automation attempts rely on exhaustive
enumeration, which can be computationally costly and lacks domain-specific
insights. We introduce ELATE (Evolutionary Language model for Automated
Time-series Engineering), which leverages a language model within an
evolutionary framework to automate feature engineering for time-series data.
ELATE employs time-series statistical measures and feature importance metrics
to guide and prune features, while the language model proposes new,
contextually relevant feature transformations. Our experiments demonstrate that
ELATE improves forecasting accuracy by an average of 8.4% across various
domains.

</details>


### [168] [Improving Fairness in Graph Neural Networks via Counterfactual Debiasing](https://arxiv.org/abs/2508.14683)
*Zengyi Wo,Chang Liu,Yumeng Wang,Minglai Shao,Wenjun Wang*

Main category: cs.LG

TL;DR: Fair-ICD是一种利用反事实数据增强来缓解GNN偏见的创新方法，通过增强图学习无偏节点表示，并在保持高预测性能的同时显著提升公平性。


<details>
  <summary>Details</summary>
Motivation: GNN在预测中可能因图结构和消息传递机制加剧偏见，现有方法可能无意中消除非敏感特征，导致预测准确性与公平性失衡。

Method: 采用反事实数据增强创建多样化邻域，结合对抗性判别器减少GNN分类器的预测偏见。

Result: 在标准数据集上，Fair-ICD显著提升公平性指标，同时保持高预测性能。

Conclusion: Fair-ICD在适度条件下有效确保GNN的公平性，为偏见缓解提供了新思路。

Abstract: Graph Neural Networks (GNNs) have been successful in modeling
graph-structured data. However, similar to other machine learning models, GNNs
can exhibit bias in predictions based on attributes like race and gender.
Moreover, bias in GNNs can be exacerbated by the graph structure and
message-passing mechanisms. Recent cutting-edge methods propose mitigating bias
by filtering out sensitive information from input or representations, like edge
dropping or feature masking. Yet, we argue that such strategies may
unintentionally eliminate non-sensitive features, leading to a compromised
balance between predictive accuracy and fairness. To tackle this challenge, we
present a novel approach utilizing counterfactual data augmentation for bias
mitigation. This method involves creating diverse neighborhoods using
counterfactuals before message passing, facilitating unbiased node
representations learning from the augmented graph. Subsequently, an adversarial
discriminator is employed to diminish bias in predictions by conventional GNN
classifiers. Our proposed technique, Fair-ICD, ensures the fairness of GNNs
under moderate conditions. Experiments on standard datasets using three GNN
backbones demonstrate that Fair-ICD notably enhances fairness metrics while
preserving high predictive performance.

</details>


### [169] [Addressing Graph Anomaly Detection via Causal Edge Separation and Spectrum](https://arxiv.org/abs/2508.14684)
*Zengyi Wo,Wenjun Wang,Minglai Shao,Chang Liu,Yumeng Wang,Yueheng Sun*

Main category: cs.LG

TL;DR: 提出了一种基于因果边分离的谱神经网络CES2-GAD，用于解决异质图中异常检测问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界中异常实体常通过增加合法连接隐藏异常链接，导致异质结构，现有GNN方法难以处理。

Method: 通过因果干预分离同质和异质边，使用混合谱滤波器捕获信号，最后分类预测异常。

Result: 实验证明该方法在真实数据集上有效。

Conclusion: CES2-GAD能有效解决异质图中的异常检测问题。

Abstract: In the real world, anomalous entities often add more legitimate connections
while hiding direct links with other anomalous entities, leading to
heterophilic structures in anomalous networks that most GNN-based techniques
fail to address. Several works have been proposed to tackle this issue in the
spatial domain. However, these methods overlook the complex relationships
between node structure encoding, node features, and their contextual
environment and rely on principled guidance, research on solving spectral
domain heterophilic problems remains limited. This study analyzes the spectral
distribution of nodes with different heterophilic degrees and discovers that
the heterophily of anomalous nodes causes the spectral energy to shift from low
to high frequencies. To address the above challenges, we propose a spectral
neural network CES2-GAD based on causal edge separation for anomaly detection
on heterophilic graphs. Firstly, CES2-GAD will separate the original graph into
homophilic and heterophilic edges using causal interventions. Subsequently,
various hybrid-spectrum filters are used to capture signals from the segmented
graphs. Finally, representations from multiple signals are concatenated and
input into a classifier to predict anomalies. Extensive experiments with
real-world datasets have proven the effectiveness of the method we proposed.

</details>


### [170] [AFABench: A Generic Framework for Benchmarking Active Feature Acquisition](https://arxiv.org/abs/2508.14734)
*Valter Schütz,Han Wu,Reza Rezvan,Linus Aronsson,Morteza Haghir Chehreghani*

Main category: cs.LG

TL;DR: AFABench是首个用于主动特征获取（AFA）的标准化基准框架，旨在解决现有方法评估不足的问题。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏标准化基准，AFA方法的公平和系统性评估受到阻碍。

Method: AFABench包括多样化的数据集，支持多种获取策略，并采用模块化设计以方便新方法和任务的集成。

Result: 通过评估代表性算法，揭示了不同AFA策略的关键权衡，并提供了未来研究的实用见解。

Conclusion: AFABench为AFA研究提供了标准化评估工具，并展示了不同策略的优缺点。

Abstract: In many real-world scenarios, acquiring all features of a data instance can
be expensive or impractical due to monetary cost, latency, or privacy concerns.
Active Feature Acquisition (AFA) addresses this challenge by dynamically
selecting a subset of informative features for each data instance, trading
predictive performance against acquisition cost. While numerous methods have
been proposed for AFA, ranging from greedy information-theoretic strategies to
non-myopic reinforcement learning approaches, fair and systematic evaluation of
these methods has been hindered by the lack of standardized benchmarks. In this
paper, we introduce AFABench, the first benchmark framework for AFA. Our
benchmark includes a diverse set of synthetic and real-world datasets, supports
a wide range of acquisition policies, and provides a modular design that
enables easy integration of new methods and tasks. We implement and evaluate
representative algorithms from all major categories, including static, greedy,
and reinforcement learning-based approaches. To test the lookahead capabilities
of AFA policies, we introduce a novel synthetic dataset, AFAContext, designed
to expose the limitations of greedy selection. Our results highlight key
trade-offs between different AFA strategies and provide actionable insights for
future research. The benchmark code is available at:
https://github.com/Linusaronsson/AFA-Benchmark.

</details>


### [171] [CaTE Data Curation for Trustworthy AI](https://arxiv.org/abs/2508.14741)
*Mary Versa Clemens-Sewall,Christopher Cervantes,Emma Rafkin,J. Neil Otte,Tom Magelinski,Libby Lewis,Michelle Liu,Dana Udwin,Monique Kirkman-Bey*

Main category: cs.LG

TL;DR: 报告为设计或开发AI系统的团队提供了数据整理阶段提升可信度的实用指南。


<details>
  <summary>Details</summary>
Motivation: 提供数据整理阶段的具体步骤和工具，以增强AI系统的可信度。

Method: 定义数据、数据整理阶段和可信度，列举核心步骤及替代路径，分析优缺点和工具实现。

Result: 综合了学术文献中的数据整理工具和方法，提供了一套多样且一致的实践方案。

Conclusion: 报告旨在帮助读者通过数据整理提升AI系统的可信度。

Abstract: This report provides practical guidance to teams designing or developing
AI-enabled systems for how to promote trustworthiness during the data curation
phase of development. In this report, the authors first define data, the data
curation phase, and trustworthiness. We then describe a series of steps that
the development team, especially data scientists, can take to build a
trustworthy AI-enabled system. We enumerate the sequence of core steps and
trace parallel paths where alternatives exist. The descriptions of these steps
include strengths, weaknesses, preconditions, outcomes, and relevant
open-source software tool implementations. In total, this report is a synthesis
of data curation tools and approaches from relevant academic literature, and
our goal is to equip readers with a diverse yet coherent set of practices for
improving AI trustworthiness.

</details>


### [172] [MissionHD: Data-Driven Refinement of Reasoning Graph Structure through Hyperdimensional Causal Path Encoding and Decoding](https://arxiv.org/abs/2508.14746)
*Sanggeon Yun,Raheeb Hassan,Ryozo Masukawa,Mohsen Imani*

Main category: cs.LG

TL;DR: 提出了一种数据驱动的图结构优化方法D-GSR，结合超维计算框架MissionHD，显著提升了视频异常检测等任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有图结构优化方法不适用于无数据集的图，且与下游视觉任务不匹配。

Method: 提出D-GSR方法，直接利用下游任务数据优化图结构，并通过MissionHD框架实现高效的编码-解码过程。

Result: 在视频异常检测等任务上表现出显著性能提升。

Conclusion: D-GSR是一种有效的预处理步骤，适用于无数据集的图结构优化。

Abstract: Reasoning graphs from Large Language Models (LLMs) are often misaligned with
downstream visual tasks such as video anomaly detection (VAD). Existing Graph
Structure Refinement (GSR) methods are ill-suited for these novel, dataset-less
graphs. We introduce Data-driven GSR (D-GSR), a new paradigm that directly
optimizes graph structure using downstream task data, and propose MissionHD, a
hyperdimensional computing (HDC) framework to operationalize it. MissionHD uses
an efficient encode-decode process to refine the graph, guided by the
downstream task signal. Experiments on challenging VAD and VAR benchmarks show
significant performance improvements when using our refined graphs, validating
our approach as an effective pre-processing step.

</details>


### [173] [Cross-Modality Controlled Molecule Generation with Diffusion Language Model](https://arxiv.org/abs/2508.14748)
*Yunzhe Zhang,Yifei Wang,Khanh Vinh Nguyen,Pengyu Hong*

Main category: cs.LG

TL;DR: 提出了一种名为CMCM-DLM的扩散语言模型，支持跨模态约束的分子生成，无需重新训练即可适应新约束。


<details>
  <summary>Details</summary>
Motivation: 现有SMILES扩散模型仅支持单模态约束，且需重新训练以适应新约束，无法满足多模态和动态约束需求。

Method: 基于预训练扩散模型，引入结构控制模块（SCM）和性质控制模块（PCM），分两阶段注入约束。

Result: 实验证明CMCM-DLM在多数据集上高效且适应性强，显著推进了药物发现中的分子生成。

Conclusion: CMCM-DLM为跨模态约束的分子生成提供了灵活高效的解决方案，适用于动态研究需求。

Abstract: Current SMILES-based diffusion models for molecule generation typically
support only unimodal constraint. They inject conditioning signals at the start
of the training process and require retraining a new model from scratch
whenever the constraint changes. However, real-world applications often involve
multiple constraints across different modalities, and additional constraints
may emerge over the course of a study. This raises a challenge: how to extend a
pre-trained diffusion model not only to support cross-modality constraints but
also to incorporate new ones without retraining. To tackle this problem, we
propose the Cross-Modality Controlled Molecule Generation with Diffusion
Language Model (CMCM-DLM), demonstrated by two distinct cross modalities:
molecular structure and chemical properties. Our approach builds upon a
pre-trained diffusion model, incorporating two trainable modules, the Structure
Control Module (SCM) and the Property Control Module (PCM), and operates in two
distinct phases during the generation process. In Phase I, we employs the SCM
to inject structural constraints during the early diffusion steps, effectively
anchoring the molecular backbone. Phase II builds on this by further
introducing PCM to guide the later stages of inference to refine the generated
molecules, ensuring their chemical properties match the specified targets.
Experimental results on multiple datasets demonstrate the efficiency and
adaptability of our approach, highlighting CMCM-DLM's significant advancement
in molecular generation for drug discovery applications.

</details>


### [174] [Squeezed Diffusion Models](https://arxiv.org/abs/2508.14871)
*Jyotirmai Singh,Samar Khanna,James Burgess*

Main category: cs.LG

TL;DR: 论文提出了一种名为Squeezed Diffusion Models (SDM)的方法，通过各向异性缩放噪声来改进扩散模型，实验显示在多个数据集上性能提升显著。


<details>
  <summary>Details</summary>
Motivation: 传统扩散模型使用各向同性高斯噪声，忽略了数据中的结构信息。受量子压缩态启发，作者希望通过数据依赖的噪声缩放提升模型学习能力。

Method: 引入两种配置：(i) Heisenberg扩散模型，在主轴上补偿缩放；(ii) 标准SDM变体，仅缩放主轴。实验发现适度反压缩（增加主轴方差）效果更佳。

Result: 在CIFAR-10/100和CelebA-64数据集上，FID提升达15%，且精度-召回曲线向更高召回方向移动。

Conclusion: 简单的数据感知噪声调整可在不改变架构的情况下带来稳健的生成性能提升。

Abstract: Diffusion models typically inject isotropic Gaussian noise, disregarding
structure in the data. Motivated by the way quantum squeezed states
redistribute uncertainty according to the Heisenberg uncertainty principle, we
introduce Squeezed Diffusion Models (SDM), which scale noise anisotropically
along the principal component of the training distribution. As squeezing
enhances the signal-to-noise ratio in physics, we hypothesize that scaling
noise in a data-dependent manner can better assist diffusion models in learning
important data features. We study two configurations: (i) a Heisenberg
diffusion model that compensates the scaling on the principal axis with inverse
scaling on orthogonal directions and (ii) a standard SDM variant that scales
only the principal axis. Counterintuitively, on CIFAR-10/100 and CelebA-64,
mild antisqueezing - i.e. increasing variance on the principal axis -
consistently improves FID by up to 15% and shifts the precision-recall frontier
toward higher recall. Our results demonstrate that simple, data-aware noise
shaping can deliver robust generative gains without architectural changes.

</details>


### [175] [HERAKLES: Hierarchical Skill Compilation for Open-ended LLM Agents](https://arxiv.org/abs/2508.14751)
*Thomas Carta,Clément Romac,Loris Gaven,Pierre-Yves Oudeyer,Olivier Sigaud,Sylvain Lamprier*

Main category: cs.LG

TL;DR: HERAKLES框架通过动态编译已掌握目标到低层策略，利用LLM作为高层控制器，提升开放环境中AI代理的目标复杂性和适应性。


<details>
  <summary>Details</summary>
Motivation: 解决开放环境中AI代理目标复杂性和多样性增长带来的样本和计算复杂度问题。

Method: 采用两层分层强化学习框架，动态编译目标到低层策略，并利用LLM作为高层控制器。

Result: 在Crafter环境中，HERAKLES能有效适应目标复杂性，提升样本效率，并增强对新挑战的适应性。

Conclusion: HERAKLES为开放环境中的AI代理提供了一种高效、可扩展的目标学习和适应方法。

Abstract: Open-ended AI agents need to be able to learn efficiently goals of increasing
complexity, abstraction and heterogeneity over their lifetime. Beyond sampling
efficiently their own goals, autotelic agents specifically need to be able to
keep the growing complexity of goals under control, limiting the associated
growth in sample and computational complexity. To adress this challenge, recent
approaches have leveraged hierarchical reinforcement learning (HRL) and
language, capitalizing on its compositional and combinatorial generalization
capabilities to acquire temporally extended reusable behaviours. Existing
approaches use expert defined spaces of subgoals over which they instantiate a
hierarchy, and often assume pre-trained associated low-level policies. Such
designs are inadequate in open-ended scenarios, where goal spaces naturally
diversify across a broad spectrum of difficulties. We introduce HERAKLES, a
framework that enables a two-level hierarchical autotelic agent to continuously
compile mastered goals into the low-level policy, executed by a small, fast
neural network, dynamically expanding the set of subgoals available to the
high-level policy. We train a Large Language Model (LLM) to serve as the
high-level controller, exploiting its strengths in goal decomposition and
generalization to operate effectively over this evolving subgoal space. We
evaluate HERAKLES in the open-ended Crafter environment and show that it scales
effectively with goal complexity, improves sample efficiency through skill
compilation, and enables the agent to adapt robustly to novel challenges over
time.

</details>


### [176] [PepThink-R1: LLM for Interpretable Cyclic Peptide Optimization with CoT SFT and Reinforcement Learning](https://arxiv.org/abs/2508.14765)
*Ruheng Wang,Hang Zhang,Trieu Nguyen,Shasha Feng,Hao-Wei Pang,Xiang Yu,Li Xiao,Peter Zhiping Zhang*

Main category: cs.LG

TL;DR: PepThink-R1是一个结合大型语言模型、链式思维微调和强化学习的生成框架，用于设计具有优化药理特性的肽。


<details>
  <summary>Details</summary>
Motivation: 设计具有特定特性的治疗肽面临序列空间庞大、实验数据有限和现有生成模型可解释性差的问题。

Method: PepThink-R1整合了大型语言模型、链式思维监督微调和强化学习，通过显式推理单体级修改来优化多药理特性。

Result: PepThink-R1生成的环肽在亲脂性、稳定性和暴露性上显著优于现有模型，同时在优化成功率和可解释性上表现优异。

Conclusion: PepThink-R1是首个结合显式推理和强化学习驱动的特性控制的肽设计框架，为治疗发现提供了可靠且透明的肽优化方法。

Abstract: Designing therapeutic peptides with tailored properties is hindered by the
vastness of sequence space, limited experimental data, and poor
interpretability of current generative models. To address these challenges, we
introduce PepThink-R1, a generative framework that integrates large language
models (LLMs) with chain-of-thought (CoT) supervised fine-tuning and
reinforcement learning (RL). Unlike prior approaches, PepThink-R1 explicitly
reasons about monomer-level modifications during sequence generation, enabling
interpretable design choices while optimizing for multiple pharmacological
properties. Guided by a tailored reward function balancing chemical validity
and property improvements, the model autonomously explores diverse sequence
variants. We demonstrate that PepThink-R1 generates cyclic peptides with
significantly enhanced lipophilicity, stability, and exposure, outperforming
existing general LLMs (e.g., GPT-5) and domain-specific baseline in both
optimization success and interpretability. To our knowledge, this is the first
LLM-based peptide design framework that combines explicit reasoning with
RL-driven property control, marking a step toward reliable and transparent
peptide optimization for therapeutic discovery.

</details>


### [177] [Federated Distillation on Edge Devices: Efficient Client-Side Filtering for Non-IID Data](https://arxiv.org/abs/2508.14769)
*Ahmed Mujtaba,Gleb Radchenko,Radu Prodan,Marc Masana*

Main category: cs.LG

TL;DR: EdgeFD是一种高效的联邦蒸馏方法，通过简化客户端密度比估计和去除服务器端过滤，提升了知识共享质量和计算效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有联邦蒸馏方法中复杂的知识共享策略和高计算开销问题，提升隐私保护和通信效率。

Method: 提出基于KMeans的密度比估计器，有效过滤客户端的内外分布代理数据，无需服务器端过滤或预训练教师模型。

Result: 在多种数据分布场景下表现优异，计算开销低，适合资源受限的边缘设备。

Conclusion: EdgeFD在异构和挑战性条件下仍能接近IID场景的准确率，提升了联邦蒸馏的可扩展性和实际应用性。

Abstract: Federated distillation has emerged as a promising collaborative machine
learning approach, offering enhanced privacy protection and reduced
communication compared to traditional federated learning by exchanging model
outputs (soft logits) rather than full model parameters. However, existing
methods employ complex selective knowledge-sharing strategies that require
clients to identify in-distribution proxy data through computationally
expensive statistical density ratio estimators. Additionally, server-side
filtering of ambiguous knowledge introduces latency to the process. To address
these challenges, we propose a robust, resource-efficient EdgeFD method that
reduces the complexity of the client-side density ratio estimation and removes
the need for server-side filtering. EdgeFD introduces an efficient KMeans-based
density ratio estimator for effectively filtering both in-distribution and
out-of-distribution proxy data on clients, significantly improving the quality
of knowledge sharing. We evaluate EdgeFD across diverse practical scenarios,
including strong non-IID, weak non-IID, and IID data distributions on clients,
without requiring a pre-trained teacher model on the server for knowledge
distillation. Experimental results demonstrate that EdgeFD outperforms
state-of-the-art methods, consistently achieving accuracy levels close to IID
scenarios even under heterogeneous and challenging conditions. The
significantly reduced computational overhead of the KMeans-based estimator is
suitable for deployment on resource-constrained edge devices, thereby enhancing
the scalability and real-world applicability of federated distillation. The
code is available online for reproducibility.

</details>


### [178] [Context Steering: A New Paradigm for Compression-based Embeddings by Synthesizing Relevant Information Features](https://arxiv.org/abs/2508.14780)
*Guillermo Sarasa Durán,Ana Granados Fontecha,Francisco de Borja Rodríguez Ortíz*

Main category: cs.LG

TL;DR: 提出了一种名为“context steering”的新方法，通过主动引导特征形成过程，优化压缩距离在复杂任务中的应用。


<details>
  <summary>Details</summary>
Motivation: 压缩距离（CD）虽灵活且领域无关，但其特征源自数据而非预定义，难以与复杂任务（如聚类或分类）对齐。

Method: 引入“context steering”，通过分析对象对聚类框架中关系上下文的影响，生成定制化嵌入，突出类别区分信息。

Result: 实验验证了该方法在多种数据集（如文本和音频）中的鲁棒性和通用性，优于传统方法。

Conclusion: 该方法标志着从被动发现数据结构到主动塑造特征空间的转变，适用于特定目标。

Abstract: Compression-based distances (CD) offer a flexible and domain-agnostic means
of measuring similarity by identifying implicit information through
redundancies between data objects. However, as similarity features are derived
from the data, rather than defined as an input, it often proves difficult to
align with the task at hand, particularly in complex clustering or
classification settings. To address this issue, we introduce "context
steering," a novel methodology that actively guides the feature-shaping
process. Instead of passively accepting the emergent data structure (typically
a hierarchy derived from clustering CDs), our approach "steers" the process by
systematically analyzing how each object influences the relational context
within a clustering framework. This process generates a custom-tailored
embedding that isolates and amplifies class-distinctive information. We
validate the capabilities of this strategy using Normalized Compression
Distance (NCD) and Relative Compression Distance (NRC) with common hierarchical
clustering, providing an effective alternative to common transductive methods.
Experimental results across heterogeneous datasets-from text to real-world
audio-validate the robustness and generality of context steering, marking a
fundamental shift in their application: from merely discovering inherent data
structures to actively shaping a feature space tailored to a specific
objective.

</details>


### [179] [Synthetic Adaptive Guided Embeddings (SAGE): A Novel Knowledge Distillation Method](https://arxiv.org/abs/2508.14783)
*Suleyman Olcay Polat,Poli A. Nemkova,Mark V. Albert*

Main category: cs.LG

TL;DR: 提出了一种自适应蒸馏框架，通过动态增强高损失区域的数据和轻量级师生接口，提升了学生模型的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 传统蒸馏方法存在计算开销大和泛化能力有限的问题，需要更高效的蒸馏方法。

Method: 使用UMAP降维和最近邻采样识别高损失区域，生成针对性合成数据，并引入轻量级师生接口直接蒸馏向量化表示。

Result: 66M参数的学生模型在QNLI和SST-2上分别达到91.2%和92.3%，训练周期更少。

Conclusion: 损失感知数据增强和向量化蒸馏为高效模型压缩提供了新思路。

Abstract: Model distillation enables the transfer of knowledge from large-scale models
to compact student models, facilitating deployment in resource-constrained
environments. However, conventional distillation approaches often suffer from
computational overhead and limited generalization. We propose a novel adaptive
distillation framework that dynamically augments training data in regions of
high student model loss. Using UMAP-based dimensionality reduction and nearest
neighbor sampling, our method identifies underperforming regions in the
embedding space and generates targeted synthetic examples to guide student
learning. To further improve efficiency, we introduce a lightweight
teacher-student interface that bypasses the teacher's input layer, enabling
direct distillation on vectorized representations. Experiments across standard
NLP benchmarks demonstrate that our 66M-parameter student model consistently
matches or surpasses established baselines, achieving 91.2% on QNLI and 92.3%
on SST-2, while training with fewer epochs. These results highlight the promise
of loss-aware data augmentation and vectorized distillation for efficient and
effective model compression.

</details>


### [180] [A Guide for Manual Annotation of Scientific Imagery: How to Prepare for Large Projects](https://arxiv.org/abs/2508.14801)
*Azim Ahmadzadeh,Rohan Adhyapak,Armin Iraji,Kartik Chaurasiya,V Aparna,Petrus C. Martens*

Main category: cs.LG

TL;DR: 本文提供了一个领域无关的图像标注项目准备指南，重点关注科学图像，旨在减少人工标注成本并提高效率。


<details>
  <summary>Details</summary>
Motivation: 尽管对人工标注图像数据的需求很高，但管理复杂且昂贵的标注项目仍缺乏讨论，且缺乏实用指南。

Method: 基于作者管理大型人工标注项目的经验，讨论了成功标准、标注主题、项目目标、数据可用性和团队角色等基本概念，并推荐了工具和技术。

Result: 提出了一个全面的准备指南，旨在减少偏见并提高标注质量和效率。

Conclusion: 目标是鼓励进一步研究和框架，以创建一个全面的知识库，降低各领域人工标注项目的成本。

Abstract: Despite the high demand for manually annotated image data, managing complex
and costly annotation projects remains under-discussed. This is partly due to
the fact that leading such projects requires dealing with a set of diverse and
interconnected challenges which often fall outside the expertise of specific
domain experts, leaving practical guidelines scarce. These challenges range
widely from data collection to resource allocation and recruitment, from
mitigation of biases to effective training of the annotators. This paper
provides a domain-agnostic preparation guide for annotation projects, with a
focus on scientific imagery. Drawing from the authors' extensive experience in
managing a large manual annotation project, it addresses fundamental concepts
including success measures, annotation subjects, project goals, data
availability, and essential team roles. Additionally, it discusses various
human biases and recommends tools and technologies to improve annotation
quality and efficiency. The goal is to encourage further research and
frameworks for creating a comprehensive knowledge base to reduce the costs of
manual annotation projects across various fields.

</details>


### [181] [Source-Guided Flow Matching](https://arxiv.org/abs/2508.14807)
*Zifan Wang,Alice Harting,Matthieu Barreau,Michael M. Zavlanos,Karl H. Johansson*

Main category: cs.LG

TL;DR: 提出了一种新的生成模型引导框架SGFM，通过直接修改源分布而非向量场来实现精确的目标分布采样。


<details>
  <summary>Details</summary>
Motivation: 传统方法通过修改概率流向量场来引导生成模型，但这种方法可能不够灵活或精确。

Method: 提出Source-Guided Flow Matching (SGFM)框架，保持预训练向量场不变，直接修改源分布。

Result: 理论证明SGFM能精确恢复目标分布，实验验证了其在多种任务中的有效性。

Conclusion: SGFM提供了一种灵活且精确的生成模型引导方法，适用于多种采样任务。

Abstract: Guidance of generative models is typically achieved by modifying the
probability flow vector field through the addition of a guidance field. In this
paper, we instead propose the Source-Guided Flow Matching (SGFM) framework,
which modifies the source distribution directly while keeping the pre-trained
vector field intact. This reduces the guidance problem to a well-defined
problem of sampling from the source distribution. We theoretically show that
SGFM recovers the desired target distribution exactly. Furthermore, we provide
bounds on the Wasserstein error for the generated distribution when using an
approximate sampler of the source distribution and an approximate vector field.
The key benefit of our approach is that it allows the user to flexibly choose
the sampling method depending on their specific problem. To illustrate this, we
systematically compare different sampling methods and discuss conditions for
asymptotically exact guidance. Moreover, our framework integrates well with
optimal flow matching models since the straight transport map generated by the
vector field is preserved. Experimental results on synthetic 2D benchmarks,
image datasets, and physics-informed generative tasks demonstrate the
effectiveness and flexibility of the proposed framework.

</details>


### [182] [Enhancing Contrastive Link Prediction With Edge Balancing Augmentation](https://arxiv.org/abs/2508.14808)
*Chen-Hao Chang,Hui-Ju Hung,Chia-Hsun Lu,Chih-Ya Shen*

Main category: cs.LG

TL;DR: 论文提出了一种新的图增强方法（EBA）和对比学习损失（CoEBA），用于改进链接预测任务，并在8个基准数据集上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有研究在链接预测中缺乏对比学习的理论分析，且未充分考虑节点度数的影响。

Method: 提出了Edge Balancing Augmentation（EBA）调整节点度数，并设计了CoEBA方法结合新的对比损失。

Result: 在8个基准数据集上，CoEBA显著优于其他最先进的链接预测模型。

Conclusion: 通过理论分析和实验验证，CoEBA为链接预测任务提供了更优的解决方案。

Abstract: Link prediction is one of the most fundamental tasks in graph mining, which
motivates the recent studies of leveraging contrastive learning to enhance the
performance. However, we observe two major weaknesses of these studies: i) the
lack of theoretical analysis for contrastive learning on link prediction, and
ii) inadequate consideration of node degrees in contrastive learning. To
address the above weaknesses, we provide the first formal theoretical analysis
for contrastive learning on link prediction, where our analysis results can
generalize to the autoencoder-based link prediction models with contrastive
learning. Motivated by our analysis results, we propose a new graph
augmentation approach, Edge Balancing Augmentation (EBA), which adjusts the
node degrees in the graph as the augmentation. We then propose a new approach,
named Contrastive Link Prediction with Edge Balancing Augmentation (CoEBA),
that integrates the proposed EBA and the proposed new contrastive losses to
improve the model performance. We conduct experiments on 8 benchmark datasets.
The results demonstrate that our proposed CoEBA significantly outperforms the
other state-of-the-art link prediction models.

</details>


### [183] [Successive Halving with Learning Curve Prediction via Latent Kronecker Gaussian Processes](https://arxiv.org/abs/2508.14818)
*Jihao Andreas Lin,Nicolas Mayoraz,Steffen Rendle,Dima Kuzmin,Emil Praun,Berivan Isik*

Main category: cs.LG

TL;DR: 研究探讨了基于潜在Kronecker高斯过程的学习曲线预测是否能改进Successive Halving算法，避免过早淘汰慢启动候选。实验表明，预测方法虽具竞争力，但需依赖完整学习曲线数据，不如直接增加标准方法的资源投入高效。


<details>
  <summary>Details</summary>
Motivation: Successive Halving算法依赖中间性能值分配资源，可能导致过早淘汰潜在最优候选。研究旨在通过学习曲线预测改进这一局限。

Method: 使用潜在Kronecker高斯过程预测学习曲线，指导Successive Halving的资源分配，并与标准方法对比。

Result: 预测方法表现竞争性，但因需完整学习曲线数据，不如直接增加标准方法资源投入高效。

Conclusion: 预测方法有潜力，但需优化数据依赖问题；利用现有学习曲线数据可缓解此问题。

Abstract: Successive Halving is a popular algorithm for hyperparameter optimization
which allocates exponentially more resources to promising candidates. However,
the algorithm typically relies on intermediate performance values to make
resource allocation decisions, which can cause it to prematurely prune slow
starters that would eventually become the best candidate. We investigate
whether guiding Successive Halving with learning curve predictions based on
Latent Kronecker Gaussian Processes can overcome this limitation. In a
large-scale empirical study involving different neural network architectures
and a click prediction dataset, we compare this predictive approach to the
standard approach based on current performance values. Our experiments show
that, although the predictive approach achieves competitive performance, it is
not Pareto optimal compared to investing more resources into the standard
approach, because it requires fully observed learning curves as training data.
However, this downside could be mitigated by leveraging existing learning curve
data.

</details>


### [184] [On Defining Neural Averaging](https://arxiv.org/abs/2508.14832)
*Su Hyeong Lee,Richard Ngo*

Main category: cs.LG

TL;DR: 论文探讨了如何通过权重平均合成多个预训练神经网络，提出了一种数据无关的元优化方法AME，优于传统模型汤方法。


<details>
  <summary>Details</summary>
Motivation: 研究如何在不访问训练数据的情况下，通过权重平均合成多个预训练模型，以提升泛化性能。

Method: 提出Amortized Model Ensembling (AME)框架，将模型差异视为伪梯度来指导权重更新。

Result: AME在分布外场景下优于单个专家模型和模型汤基线。

Conclusion: AME提供了一种数据无关的模型权重聚合方法，定义了神经平均的可行方案。

Abstract: What does it even mean to average neural networks? We investigate the problem
of synthesizing a single neural network from a collection of pretrained models,
each trained on disjoint data shards, using only their final weights and no
access to training data. In forming a definition of neural averaging, we take
insight from model soup, which appears to aggregate multiple models into a
singular model while enhancing generalization performance. In this work, we
reinterpret model souping as a special case of a broader framework: Amortized
Model Ensembling (AME) for neural averaging, a data-free meta-optimization
approach that treats model differences as pseudogradients to guide neural
weight updates. We show that this perspective not only recovers model soup but
enables more expressive and adaptive ensembling strategies. Empirically, AME
produces averaged neural solutions that outperform both individual experts and
model soup baselines, especially in out-of-distribution settings. Our results
suggest a principled and generalizable notion of data-free model weight
aggregation and defines, in one sense, how to perform neural averaging.

</details>


### [185] [Multimodal Quantum Vision Transformer for Enzyme Commission Classification from Biochemical Representations](https://arxiv.org/abs/2508.14844)
*Murat Isik,Mandeep Kaur Saggi,Humaira Gowher,Sabre Kais*

Main category: cs.LG

TL;DR: 提出了一种多模态量子机器学习框架，用于提升酶功能分类的准确性。


<details>
  <summary>Details</summary>
Motivation: 准确预测酶功能是计算生物学的主要挑战之一，尤其是对于结构注释或序列同源性有限的酶。

Method: 整合了四种互补的生物化学模态：蛋白质序列嵌入、量子电子描述符、分子图结构和2D分子图像表示，采用量子视觉Transformer（QVT）框架。

Result: 多模态QVT模型在EC分类中达到85.1%的top-1准确率，显著优于仅基于序列的基线和其他QML模型。

Conclusion: 该方法通过整合多种模态，能够捕捉酶功能的关键立体电子相互作用，显著提升了分类性能。

Abstract: Accurately predicting enzyme functionality remains one of the major
challenges in computational biology, particularly for enzymes with limited
structural annotations or sequence homology. We present a novel multimodal
Quantum Machine Learning (QML) framework that enhances Enzyme Commission (EC)
classification by integrating four complementary biochemical modalities:
protein sequence embeddings, quantum-derived electronic descriptors, molecular
graph structures, and 2D molecular image representations. Quantum Vision
Transformer (QVT) backbone equipped with modality-specific encoders and a
unified cross-attention fusion module. By integrating graph features and
spatial patterns, our method captures key stereoelectronic interactions behind
enzyme function. Experimental results demonstrate that our multimodal QVT model
achieves a top-1 accuracy of 85.1%, outperforming sequence-only baselines by a
substantial margin and achieving better performance results compared to other
QML models.

</details>


### [186] [Universal and Transferable Adversarial Attack on Large Language Models Using Exponentiated Gradient Descent](https://arxiv.org/abs/2508.14853)
*Sajib Biswas,Mao Nishino,Samuel Jacob Chacko,Xiuwen Liu*

Main category: cs.LG

TL;DR: 提出了一种直接优化松弛的one-hot编码的对抗性后缀令牌的方法，使用指数梯度下降和Bregman投影，提高了攻击成功率和收敛速度。


<details>
  <summary>Details</summary>
Motivation: 尽管现有对齐技术（如RLHF）在典型提示上取得了成功，但LLMs仍容易受到对抗性触发器的攻击。现有方法效率低或难以应用于专有模型。

Method: 采用指数梯度下降和Bregman投影优化松弛的one-hot编码，确保每个令牌的编码保持在概率单纯形内。

Result: 在多个开源LLMs和对抗行为数据集上，该方法比三种基线方法具有更高的成功率和更快的收敛速度。

Conclusion: 该方法不仅适用于单个提示攻击，还能生成跨多个提示的通用对抗性后缀，并展示了优化后缀在不同LLMs间的可转移性。

Abstract: As large language models (LLMs) are increasingly deployed in critical
applications, ensuring their robustness and safety alignment remains a major
challenge. Despite the overall success of alignment techniques such as
reinforcement learning from human feedback (RLHF) on typical prompts, LLMs
remain vulnerable to jailbreak attacks enabled by crafted adversarial triggers
appended to user prompts. Most existing jailbreak methods either rely on
inefficient searches over discrete token spaces or direct optimization of
continuous embeddings. While continuous embeddings can be given directly to
selected open-source models as input, doing so is not feasible for proprietary
models. On the other hand, projecting these embeddings back into valid discrete
tokens introduces additional complexity and often reduces attack effectiveness.
We propose an intrinsic optimization method which directly optimizes relaxed
one-hot encodings of the adversarial suffix tokens using exponentiated gradient
descent coupled with Bregman projection, ensuring that the optimized one-hot
encoding of each token always remains within the probability simplex. We
provide theoretical proof of convergence for our proposed method and implement
an efficient algorithm that effectively jailbreaks several widely used LLMs.
Our method achieves higher success rates and faster convergence compared to
three state-of-the-art baselines, evaluated on five open-source LLMs and four
adversarial behavior datasets curated for evaluating jailbreak methods. In
addition to individual prompt attacks, we also generate universal adversarial
suffixes effective across multiple prompts and demonstrate transferability of
optimized suffixes to different LLMs.

</details>


### [187] [Graph Structure Learning with Temporal Graph Information Bottleneck for Inductive Representation Learning](https://arxiv.org/abs/2508.14859)
*Jiafeng Xiong,Rizos Sakellariou*

Main category: cs.LG

TL;DR: GTGIB框架结合图结构学习和时间图信息瓶颈，有效解决动态网络中未见节点表示和噪声信息问题。


<details>
  <summary>Details</summary>
Motivation: 动态网络中节点和边随时间变化，新节点不断加入，需要解决未见节点表示和噪声信息问题。

Method: 提出GTGIB框架，结合两步图结构学习增强器优化节点邻域，并通过时间图信息瓶颈正则化边和特征。

Result: 在四个真实数据集上，GTGIB在归纳和转导设置下均优于现有方法。

Conclusion: GTGIB通过结构优化和信息瓶颈，显著提升了动态图学习的性能。

Abstract: Temporal graph learning is crucial for dynamic networks where nodes and edges
evolve over time and new nodes continuously join the system. Inductive
representation learning in such settings faces two major challenges:
effectively representing unseen nodes and mitigating noisy or redundant graph
information. We propose GTGIB, a versatile framework that integrates Graph
Structure Learning (GSL) with Temporal Graph Information Bottleneck (TGIB). We
design a novel two-step GSL-based structural enhancer to enrich and optimize
node neighborhoods and demonstrate its effectiveness and efficiency through
theoretical proofs and experiments. The TGIB refines the optimized graph by
extending the information bottleneck principle to temporal graphs, regularizing
both edges and features based on our derived tractable TGIB objective function
via variational approximation, enabling stable and efficient optimization.
GTGIB-based models are evaluated to predict links on four real-world datasets;
they outperform existing methods in all datasets under the inductive setting,
with significant and consistent improvement in the transductive setting.

</details>


### [188] [Compute-Optimal Scaling for Value-Based Deep RL](https://arxiv.org/abs/2508.14881)
*Preston Fu,Oleh Rybkin,Zhiyuan Zhou,Michal Nauman,Pieter Abbeel,Sergey Levine,Aviral Kumar*

Main category: cs.LG

TL;DR: 论文研究了在固定计算预算下，如何分配模型容量和更新数据比（UTD）以最大化深度强化学习的样本效率，发现TD过拟合现象并提出了优化计算使用的指南。


<details>
  <summary>Details</summary>
Motivation: 随着模型规模增大和训练成本上升，如何在计算最优的方式下扩展训练方法，尤其是在强化学习中，成为一个重要问题。

Method: 研究了在线、基于价值的深度强化学习中的计算分配问题，重点关注模型容量和UTD比两个轴。

Result: 发现TD过拟合现象，即小模型增加批次大小会损害Q函数准确性，而大模型则无此问题，从而可以高效使用大批次。

Conclusion: 提出了计算最优扩展的指南，为深度强化学习中的计算优化提供了基础。

Abstract: As models grow larger and training them becomes expensive, it becomes
increasingly important to scale training recipes not just to larger models and
more data, but to do so in a compute-optimal manner that extracts maximal
performance per unit of compute. While such scaling has been well studied for
language modeling, reinforcement learning (RL) has received less attention in
this regard. In this paper, we investigate compute scaling for online,
value-based deep RL. These methods present two primary axes for compute
allocation: model capacity and the update-to-data (UTD) ratio. Given a fixed
compute budget, we ask: how should resources be partitioned across these axes
to maximize sample efficiency? Our analysis reveals a nuanced interplay between
model size, batch size, and UTD. In particular, we identify a phenomenon we
call TD-overfitting: increasing the batch quickly harms Q-function accuracy for
small models, but this effect is absent in large models, enabling effective use
of large batch size at scale. We provide a mental model for understanding this
phenomenon and build guidelines for choosing batch size and UTD to optimize
compute usage. Our findings provide a grounded starting point for
compute-optimal scaling in deep RL, mirroring studies in supervised learning
but adapted to TD learning.

</details>
