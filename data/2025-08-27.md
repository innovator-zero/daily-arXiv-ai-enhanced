<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 74]
- [eess.IV](#eess.IV) [Total: 6]
- [eess.SP](#eess.SP) [Total: 1]
- [cs.LG](#cs.LG) [Total: 82]
- [cs.RO](#cs.RO) [Total: 29]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Towards Training-Free Underwater 3D Object Detection from Sonar Point Clouds: A Comparison of Traditional and Deep Learning Approaches](https://arxiv.org/abs/2508.18293)
*M. Salman Shaukat,Yannik Käckenmeister,Sebastian Bader,Thomas Kirste*

Main category: cs.CV

TL;DR: 论文探讨了无需真实训练数据的水下3D物体检测方法，比较了基于物理模拟的神经网络和基于模板匹配的方法，发现后者在真实数据中表现更稳健。


<details>
  <summary>Details</summary>
Motivation: 解决水下3D物体检测中训练数据稀缺和获取成本高的问题，探索无需真实数据的检测方法。

Method: 开发了两种方法：基于物理模拟的神经网络训练和基于几何先验的模板匹配系统。

Result: 神经网络在模拟数据上表现优异（98% mAP），但在真实数据中下降至40%；模板匹配方法在真实数据中保持83% mAP。

Conclusion: 模板匹配方法在数据稀缺环境下更稳健，挑战了传统深度学习对数据的依赖，为水下3D检测提供了新思路。

Abstract: Underwater 3D object detection remains one of the most challenging frontiers
in computer vision, where traditional approaches struggle with the harsh
acoustic environment and scarcity of training data. While deep learning has
revolutionized terrestrial 3D detection, its application underwater faces a
critical bottleneck: obtaining sufficient annotated sonar data is prohibitively
expensive and logistically complex, often requiring specialized vessels, expert
surveyors, and favorable weather conditions. This work addresses a fundamental
question: Can we achieve reliable underwater 3D object detection without
real-world training data? We tackle this challenge by developing and comparing
two paradigms for training-free detection of artificial structures in multibeam
echo-sounder point clouds. Our dual approach combines a physics-based sonar
simulation pipeline that generates synthetic training data for state-of-the-art
neural networks, with a robust model-based template matching system that
leverages geometric priors of target objects. Evaluation on real bathymetry
surveys from the Baltic Sea reveals surprising insights: while neural networks
trained on synthetic data achieve 98% mean Average Precision (mAP) on simulated
scenes, they drop to 40% mAP on real sonar data due to domain shift.
Conversely, our template matching approach maintains 83% mAP on real data
without requiring any training, demonstrating remarkable robustness to acoustic
noise and environmental variations. Our findings challenge conventional wisdom
about data-hungry deep learning in underwater domains and establish the first
large-scale benchmark for training-free underwater 3D detection. This work
opens new possibilities for autonomous underwater vehicle navigation, marine
archaeology, and offshore infrastructure monitoring in data-scarce environments
where traditional machine learning approaches fail.

</details>


### [2] [MobileDenseAttn:A Dual-Stream Architecture for Accurate and Interpretable Brain Tumor Detection](https://arxiv.org/abs/2508.18294)
*Shudipta Banik,Muna Das,Trapa Banik,Md. Ehsanul Haque*

Main category: cs.CV

TL;DR: MobileDenseAttn是一种融合MobileNetV2和DenseNet201的双流模型，用于高效、可解释地检测脑肿瘤MRI图像，显著提升准确性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有脑肿瘤检测方法泛化能力差、计算效率低且缺乏可解释性，MobileDenseAttn旨在解决这些问题。

Method: 结合MobileNetV2和DenseNet201的双流模型，使用特征级融合和GradCAM增强可视化解释，训练于6,020个MRI扫描的增强数据集。

Result: 模型训练准确率99.75%，测试准确率98.35%，F1分数0.9835，比基线模型VGG19准确率提升3.67%，训练时间减少39.3%。

Conclusion: MobileDenseAttn高效、高性能且可解释，有望成为临床实用的脑肿瘤检测工具。

Abstract: The detection of brain tumor in MRI is an important aspect of ensuring timely
diagnostics and treatment; however, manual analysis is commonly long and
error-prone. Current approaches are not universal because they have limited
generalization to heterogeneous tumors, are computationally inefficient, are
not interpretable, and lack transparency, thus limiting trustworthiness. To
overcome these issues, we introduce MobileDenseAttn, a fusion model of dual
streams of MobileNetV2 and DenseNet201 that can help gradually improve the
feature representation scale, computing efficiency, and visual explanations via
GradCAM. Our model uses feature level fusion and is trained on an augmented
dataset of 6,020 MRI scans representing glioma, meningioma, pituitary tumors,
and normal samples. Measured under strict 5-fold cross-validation protocols,
MobileDenseAttn provides a training accuracy of 99.75%, a testing accuracy of
98.35%, and a stable F1 score of 0.9835 (95% CI: 0.9743 to 0.9920). The
extensive validation shows the stability of the model, and the comparative
analysis proves that it is a great advancement over the baseline models (VGG19,
DenseNet201, MobileNetV2) with a +3.67% accuracy increase and a 39.3% decrease
in training time compared to VGG19. The GradCAM heatmaps clearly show
tumor-affected areas, offering clinically significant localization and
improving interpretability. These findings position MobileDenseAttn as an
efficient, high performance, interpretable model with a high probability of
becoming a clinically practical tool in identifying brain tumors in the real
world.

</details>


### [3] [Can VLMs Recall Factual Associations From Visual References?](https://arxiv.org/abs/2508.18297)
*Dhananjay Ashok,Ashutosh Chaubey,Hirona J. Arai,Jonathan May,Jesse Thomason*

Main category: cs.CV

TL;DR: 研究发现视觉语言模型（VLMs）在多模态基础中存在系统性缺陷，尤其是在视觉参考下知识回忆能力显著下降。


<details>
  <summary>Details</summary>
Motivation: 探讨VLMs在视觉与文本参考下知识回忆能力的差异，揭示其内部状态与知识链接的不足。

Method: 通过控制研究，分析VLMs在视觉和文本参考下的表现，并利用内部状态探针检测不可靠响应。

Result: 视觉参考下VLMs的知识回忆能力减半；内部状态探针可92%准确检测不可靠响应，提升任务覆盖率和降低错误风险。

Conclusion: 解决VLMs的多模态基础缺陷是重要方向，未来需改进其视觉与知识链接能力。

Abstract: Through a controlled study, we identify a systematic deficiency in the
multimodal grounding of Vision Language Models (VLMs). While VLMs can recall
factual associations when provided a textual reference to an entity; their
ability to do so is significantly diminished when the reference is visual
instead. Forcing VLMs to rely on image representations of an entity halves
their ability to recall factual knowledge, suggesting that VLMs struggle to
link their internal knowledge of an entity with its image representation. We
show that such linking failures are correlated with the expression of distinct
patterns in model internal states, and that probes on these internal states
achieve over 92% accuracy at flagging cases where the VLM response is
unreliable. These probes can be applied, without retraining, to identify when a
VLM will fail to correctly answer a question that requires an understanding of
multimodal input. When used to facilitate selective prediction on a visual
question answering task, the probes increase coverage by 7.87% (absolute) while
also reducing the risk of error by 0.9% (absolute). Addressing the systematic,
detectable deficiency is an important avenue in language grounding, and we
provide informed recommendations for future directions.

</details>


### [4] [SERES: Semantic-aware neural reconstruction from sparse views](https://arxiv.org/abs/2508.18314)
*Bo Xu,Yuhu Guo,Yuchao Wang,Wenting Wang,Yeung Yam,Charlie C. L. Wang,Xinyi Le*

Main category: cs.CV

TL;DR: 提出了一种语义感知的神经重建方法，从稀疏图像生成高保真3D模型。


<details>
  <summary>Details</summary>
Motivation: 解决稀疏输入中因特征不匹配导致的严重辐射模糊问题。

Method: 通过添加基于块的语义逻辑来丰富神经隐式表示，并结合几何基元掩码的正则化来减少形状模糊。

Result: 在DTU数据集上，平均倒角距离显著降低（SparseNeuS减少44%，VolRecon减少20%）。作为插件使用时，NeuS和Neuralangelo的误差分别减少69%和68%。

Conclusion: 该方法有效提升了稀疏图像重建的精度和鲁棒性。

Abstract: We propose a semantic-aware neural reconstruction method to generate 3D
high-fidelity models from sparse images. To tackle the challenge of severe
radiance ambiguity caused by mismatched features in sparse input, we enrich
neural implicit representations by adding patch-based semantic logits that are
optimized together with the signed distance field and the radiance field. A
novel regularization based on the geometric primitive masks is introduced to
mitigate shape ambiguity. The performance of our approach has been verified in
experimental evaluation. The average chamfer distances of our reconstruction on
the DTU dataset can be reduced by 44% for SparseNeuS and 20% for VolRecon. When
working as a plugin for those dense reconstruction baselines such as NeuS and
Neuralangelo, the average error on the DTU dataset can be reduced by 69% and
68% respectively.

</details>


### [5] [Automated Landfill Detection Using Deep Learning: A Comparative Study of Lightweight and Custom Architectures with the AerialWaste Dataset](https://arxiv.org/abs/2508.18315)
*Nowshin Sharmily,Rusab Sarmun,Muhammad E. H. Chowdhury,Mir Hamidul Hussain,Saad Bin Abul Kashem,Molla E Majid,Amith Khandakar*

Main category: cs.CV

TL;DR: 该论文提出了一种利用轻量级深度学习模型和集成技术检测非法垃圾填埋场的方法，使用AerialWaste数据集取得了高精度分类结果。


<details>
  <summary>Details</summary>
Motivation: 非法垃圾填埋场对环境和人类健康构成严重威胁，但手动检测效率低且难以覆盖。缺乏高质量公开数据集也限制了相关研究。

Method: 采用轻量级深度学习模型（如Mobilenetv2、Googlenet等）训练AerialWaste数据集，并通过集成技术提升分类性能。

Result: 集成模型在二分类任务中达到92.33%准确率、92.67%精确率、92.33%灵敏度、92.41% F1分数和92.71%特异性。

Conclusion: 轻量级模型结合集成技术能高效检测非法垃圾填埋场，为实际应用提供了可行方案。

Abstract: Illegal landfills are posing as a hazardous threat to people all over the
world. Due to the arduous nature of manually identifying the location of
landfill, many landfills go unnoticed by authorities and later cause dangerous
harm to people and environment. Deep learning can play a significant role in
identifying these landfills while saving valuable time, manpower and resources.
Despite being a burning concern, good quality publicly released datasets for
illegal landfill detection are hard to find due to security concerns. However,
AerialWaste Dataset is a large collection of 10434 images of Lombardy region of
Italy. The images are of varying qualities, collected from three different
sources: AGEA Orthophotos, WorldView-3, and Google Earth. The dataset contains
professionally curated, diverse and high-quality images which makes it
particularly suitable for scalable and impactful research. As we trained
several models to compare results, we found complex and heavy models to be
prone to overfitting and memorizing training data instead of learning patterns.
Therefore, we chose lightweight simpler models which could leverage general
features from the dataset. In this study, Mobilenetv2, Googlenet, Densenet,
MobileVit and other lightweight deep learning models were used to train and
validate the dataset as they achieved significant success with less
overfitting. As we saw substantial improvement in the performance using some of
these models, we combined the best performing models and came up with an
ensemble model. With the help of ensemble and fusion technique, binary
classification could be performed on this dataset with 92.33% accuracy, 92.67%
precision, 92.33% sensitivity, 92.41% F1 score and 92.71% specificity.

</details>


### [6] [Structures Meet Semantics: Multimodal Fusion via Graph Contrastive Learning](https://arxiv.org/abs/2508.18322)
*Jiangfeng Sun,Sihao He,Zhonghong Ou,Meina Song*

Main category: cs.CV

TL;DR: 提出了一种名为SSU的新框架，通过整合模态特定结构信息和跨模态语义对齐，提升多模态情感分析的性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态融合方法忽视模态特定结构依赖和语义对齐，影响质量、可解释性和鲁棒性。

Method: SSU动态构建模态特定图，利用文本语义锚点对齐跨模态语义空间，并采用多视图对比学习目标。

Result: 在CMU-MOSI和CMU-MOSEI数据集上表现最优，显著降低计算开销。

Conclusion: SSU通过语义对齐和结构整合，提升了多模态情感分析的性能和可解释性。

Abstract: Multimodal sentiment analysis (MSA) aims to infer emotional states by
effectively integrating textual, acoustic, and visual modalities. Despite
notable progress, existing multimodal fusion methods often neglect
modality-specific structural dependencies and semantic misalignment, limiting
their quality, interpretability, and robustness. To address these challenges,
we propose a novel framework called the Structural-Semantic Unifier (SSU),
which systematically integrates modality-specific structural information and
cross-modal semantic grounding for enhanced multimodal representations.
Specifically, SSU dynamically constructs modality-specific graphs by leveraging
linguistic syntax for text and a lightweight, text-guided attention mechanism
for acoustic and visual modalities, thus capturing detailed intra-modal
relationships and semantic interactions. We further introduce a semantic
anchor, derived from global textual semantics, that serves as a cross-modal
alignment hub, effectively harmonizing heterogeneous semantic spaces across
modalities. Additionally, we develop a multiview contrastive learning objective
that promotes discriminability, semantic consistency, and structural coherence
across intra- and inter-modal views. Extensive evaluations on two widely used
benchmark datasets, CMU-MOSI and CMU-MOSEI, demonstrate that SSU consistently
achieves state-of-the-art performance while significantly reducing
computational overhead compared to prior methods. Comprehensive qualitative
analyses further validate SSU's interpretability and its ability to capture
nuanced emotional patterns through semantically grounded interactions.

</details>


### [7] [FastAvatar: Instant 3D Gaussian Splatting for Faces from Single Unconstrained Poses](https://arxiv.org/abs/2508.18389)
*Hao Liang,Zhixuan Ge,Ashish Tiwari,Soumendu Majee,G. M. Dilshan Godaliyadda,Ashok Veeraraghavan,Guha Balakrishnan*

Main category: cs.CV

TL;DR: FastAvatar是一个快速、姿态不变的框架，能够从单张任意姿态的人脸图像中生成3D高斯泼溅模型，速度快（<10ms），且支持实时身份插值和属性编辑。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成3D高斯泼溅模型时，要么速度慢（需要逐脸优化），要么重建质量不足。FastAvatar旨在解决这一问题，实现快速且高质量的人脸3D重建。

Method: FastAvatar通过编码器-解码器网络设计，将输入图像编码为姿态不变的身份嵌入，并预测模板3DGS模型的高斯参数残差，从而实现快速拟合。

Result: FastAvatar在重建质量上显著优于现有方法（如GAGAvatar），速度比逐脸优化方法快1000倍，并支持实时身份插值和属性编辑。

Conclusion: FastAvatar结合了高质量重建和快速推理，扩展了3D高斯泼溅模型在消费和交互系统中的实际应用范围。

Abstract: We present FastAvatar, a pose-invariant, feed-forward framework that can
generate a 3D Gaussian Splatting (3DGS) model from a single face image from an
arbitrary pose in near-instant time (<10ms). FastAvatar uses a novel
encoder-decoder neural network design to achieve both fast fitting and identity
preservation regardless of input pose. First, FastAvatar constructs a 3DGS face
``template'' model from a training dataset of faces with multi-view captures.
Second, FastAvatar encodes the input face image into an identity-specific and
pose-invariant latent embedding, and decodes this embedding to predict
residuals to the structural and appearance parameters of each Gaussian in the
template 3DGS model. By only inferring residuals in a feed-forward fashion,
model inference is fast and robust. FastAvatar significantly outperforms
existing feed-forward face 3DGS methods (e.g., GAGAvatar) in reconstruction
quality, and runs 1000x faster than per-face optimization methods (e.g.,
FlashAvatar, GaussianAvatars and GASP). In addition, FastAvatar's novel latent
space design supports real-time identity interpolation and attribute editing
which is not possible with any existing feed-forward 3DGS face generation
framework. FastAvatar's combination of excellent reconstruction quality and
speed expands the scope of 3DGS for photorealistic avatar applications in
consumer and interactive systems.

</details>


### [8] [Securing Face and Fingerprint Templates in Humanitarian Biometric Systems](https://arxiv.org/abs/2508.18415)
*Giuseppe Stragapede,Sam Merrick,Vedrana Krivokuća Hahn,Justin Sukaitis,Vincent Graf Narbel*

Main category: cs.CV

TL;DR: 提出了一种适用于人道主义场景的移动生物识别系统，采用PolyProtect方法保护生物特征模板，并在人脸和指纹数据上验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 在紧急和人道主义场景中，生物识别技术能提高效率，但也带来隐私风险，需要一种轻量级且安全的保护方案。

Method: 通过比较分析生物特征模板保护（BTP）方法，选择PolyProtect，并在人脸和指纹数据上评估其性能。

Result: 实验表明PolyProtect在验证和识别准确性、不可逆性和不可链接性方面表现良好。

Conclusion: PolyProtect是一种适用于多模态生物识别的有效保护方法，未来计划开源代码。

Abstract: In humanitarian and emergency scenarios, the use of biometrics can
dramatically improve the efficiency of operations, but it poses risks for the
data subjects, which are exacerbated in contexts of vulnerability. To address
this, we present a mobile biometric system implementing a biometric template
protection (BTP) scheme suitable for these scenarios. After rigorously
formulating the functional, operational, and security and privacy requirements
of these contexts, we perform a broad comparative analysis of the BTP
landscape. PolyProtect, a method designed to operate on neural network face
embeddings, is identified as the most suitable method due to its effectiveness,
modularity, and lightweight computational burden. We evaluate PolyProtect in
terms of verification and identification accuracy, irreversibility, and
unlinkability, when this BTP method is applied to face embeddings extracted
using EdgeFace, a novel state-of-the-art efficient feature extractor, on a
real-world face dataset from a humanitarian field project in Ethiopia.
Moreover, as PolyProtect promises to be modality-independent, we extend its
evaluation to fingerprints. To the best of our knowledge, this is the first
time that PolyProtect has been evaluated for the identification scenario and
for fingerprint biometrics. Our experimental results are promising, and we plan
to release our code

</details>


### [9] [Why Relational Graphs Will Save the Next Generation of Vision Foundation Models?](https://arxiv.org/abs/2508.18421)
*Fatemeh Ziaeetabar*

Main category: cs.CV

TL;DR: 下一代视觉基础模型应引入动态关系图以提升关系推理能力，在细粒度任务中表现更优。


<details>
  <summary>Details</summary>
Motivation: 当前视觉基础模型在需要显式关系推理的任务中存在局限性，影响细粒度任务表现。

Method: 提出通过动态关系图增强模型，结合轻量级图推理模块。

Result: 实验表明，该方法在语义保真度、鲁棒性和效率上优于纯基础模型。

Conclusion: 建议未来研究关注动态图构建、多级关系推理和跨模态融合。

Abstract: Vision foundation models (FMs) have become the predominant architecture in
computer vision, providing highly transferable representations learned from
large-scale, multimodal corpora. Nonetheless, they exhibit persistent
limitations on tasks that require explicit reasoning over entities, roles, and
spatio-temporal relations. Such relational competence is indispensable for
fine-grained human activity recognition, egocentric video understanding, and
multimodal medical image analysis, where spatial, temporal, and semantic
dependencies are decisive for performance. We advance the position that
next-generation FMs should incorporate explicit relational interfaces,
instantiated as dynamic relational graphs (graphs whose topology and edge
semantics are inferred from the input and task context). We illustrate this
position with cross-domain evidence from recent systems in human manipulation
action recognition and brain tumor segmentation, showing that augmenting FMs
with lightweight, context-adaptive graph-reasoning modules improves
fine-grained semantic fidelity, out of distribution robustness,
interpretability, and computational efficiency relative to FM only baselines.
Importantly, by reasoning sparsely over semantic nodes, such hybrids also
achieve favorable memory and hardware efficiency, enabling deployment under
practical resource constraints. We conclude with a targeted research agenda for
FM graph hybrids, prioritizing learned dynamic graph construction, multi-level
relational reasoning (e.g., part object scene in activity understanding, or
region organ in medical imaging), cross-modal fusion, and evaluation protocols
that directly probe relational competence in structured vision tasks.

</details>


### [10] [LPLC: A Dataset for License Plate Legibility Classification](https://arxiv.org/abs/2508.18425)
*Lucas Wojcik,Gabriel E. Lima,Valfride Nascimento,Eduil Nascimento Jr.,Rayson Laroca,David Menotti*

Main category: cs.CV

TL;DR: 论文介绍了LPLC数据集，用于车牌可读性分类，并提出了基于三种图像识别网络的分类任务，结果显示任务难度较大，需进一步研究。


<details>
  <summary>Details</summary>
Motivation: 解决车牌识别中低质量车牌的可读性问题，优化模型性能和计算效率。

Method: 引入包含10,210张车辆图像的数据集，采用细粒度标注策略，提出分类任务并使用ViT、ResNet和YOLO三种网络进行基准测试。

Result: 三种基线模型的F1分数均低于80%，表明任务难度高。

Conclusion: 车牌可读性分类任务具有挑战性，需进一步研究，数据集已公开。

Abstract: Automatic License Plate Recognition (ALPR) faces a major challenge when
dealing with illegible license plates (LPs). While reconstruction methods such
as super-resolution (SR) have emerged, the core issue of recognizing these
low-quality LPs remains unresolved. To optimize model performance and
computational efficiency, image pre-processing should be applied selectively to
cases that require enhanced legibility. To support research in this area, we
introduce a novel dataset comprising 10,210 images of vehicles with 12,687
annotated LPs for legibility classification (the LPLC dataset). The images span
a wide range of vehicle types, lighting conditions, and camera/image quality
levels. We adopt a fine-grained annotation strategy that includes vehicle- and
LP-level occlusions, four legibility categories (perfect, good, poor, and
illegible), and character labels for three categories (excluding illegible
LPs). As a benchmark, we propose a classification task using three image
recognition networks to determine whether an LP image is good enough, requires
super-resolution, or is completely unrecoverable. The overall F1 score, which
remained below 80% for all three baseline models (ViT, ResNet, and YOLO),
together with the analyses of SR and LP recognition methods, highlights the
difficulty of the task and reinforces the need for further research. The
proposed dataset is publicly available at
https://github.com/lmlwojcik/lplc-dataset.

</details>


### [11] [CLARIFY: A Specialist-Generalist Framework for Accurate and Lightweight Dermatological Visual Question Answering](https://arxiv.org/abs/2508.18430)
*Aranya Saha,Tanvir Ahmed Khan,Ismam Nur Swapnil,Mohammad Ariful Haque*

Main category: cs.CV

TL;DR: CLARIFY是一个专为皮肤病视觉问答设计的专家-通用框架，结合轻量级图像分类器和压缩的对话模型，显著提升诊断准确性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 解决通用视觉语言模型在医疗任务中诊断准确性不足和计算成本高的问题。

Method: 结合专家（图像分类器）和通用（对话模型）组件，并通过知识图谱增强推理。

Result: 诊断准确性提升18%，计算资源需求降低20%，延迟减少5%。

Conclusion: 专家-通用系统为构建轻量、可信且临床可行的AI系统提供了实用范例。

Abstract: Vision-language models (VLMs) have shown significant potential for medical
tasks; however, their general-purpose nature can limit specialized diagnostic
accuracy, and their large size poses substantial inference costs for real-world
clinical deployment. To address these challenges, we introduce CLARIFY, a
Specialist-Generalist framework for dermatological visual question answering
(VQA). CLARIFY combines two components: (i) a lightweight, domain-trained image
classifier (the Specialist) that provides fast and highly accurate diagnostic
predictions, and (ii) a powerful yet compressed conversational VLM (the
Generalist) that generates natural language explanations to user queries. In
our framework, the Specialist's predictions directly guide the Generalist's
reasoning, focusing it on the correct diagnostic path. This synergy is further
enhanced by a knowledge graph-based retrieval module, which grounds the
Generalist's responses in factual dermatological knowledge, ensuring both
accuracy and reliability. This hierarchical design not only reduces diagnostic
errors but also significantly improves computational efficiency. Experiments on
our curated multimodal dermatology dataset demonstrate that CLARIFY achieves an
18\% improvement in diagnostic accuracy over the strongest baseline, a
fine-tuned, uncompressed single-line VLM, while reducing the average VRAM
requirement and latency by at least 20\% and 5\%, respectively. These results
indicate that a Specialist-Generalist system provides a practical and powerful
paradigm for building lightweight, trustworthy, and clinically viable AI
systems.

</details>


### [12] [VQualA 2025 Challenge on Face Image Quality Assessment: Methods and Results](https://arxiv.org/abs/2508.18445)
*Sizhuo Ma,Wei-Ting Chen,Qiang Gao,Jian Wang,Chris Wei Zhou,Wei Sun,Weixia Zhang,Linhan Cao,Jun Jia,Xiangyang Zhu,Dandan Zhu,Xiongkuo Min,Guangtao Zhai,Baoying Chen,Xiongwei Xiao,Jishen Zeng,Wei Wu,Tiexuan Lou,Yuchen Tan,Chunyi Song,Zhiwei Xu,MohammadAli Hamidi,Hadi Amirpour,Mingyin Bai,Jiawang Du,Zhenyu Jiang,Zilong Lu,Ziguan Cui,Zongliang Gan,Xinpeng Li,Shiqi Jiang,Chenhui Li,Changbo Wang,Weijun Yuan,Zhan Li,Yihang Chen,Yifan Deng,Ruting Deng,Zhanglu Chen,Boyang Yao,Shuling Zheng,Feng Zhang,Zhiheng Fu,Abhishek Joshi,Aman Agarwal,Rakhil Immidisetti,Ajay Narasimha Mopidevi,Vishwajeet Shukla,Hao Yang,Ruikun Zhang,Liyuan Pan,Kaixin Deng,Hang Ouyang,Fan yang,Zhizun Luo,Zhuohang Shi,Songning Lai,Weilin Ruan,Yutao Yue*

Main category: cs.CV

TL;DR: VQualA 2025挑战赛聚焦于轻量级高效的面部图像质量评估模型，旨在解决真实场景中的图像退化问题。


<details>
  <summary>Details</summary>
Motivation: 真实场景中的面部图像常因噪声、模糊和压缩伪影等退化问题影响质量，阻碍后续任务。

Method: 参与者需开发轻量级模型（限制为0.5 GFLOPs和500万参数），预测任意分辨率和真实退化面部图像的平均意见分数（MOS）。

Result: 挑战赛吸引了127名参与者，提交了1519份最终方案，并通过相关性指标在真实面部图像数据集上进行了全面评估。

Conclusion: 报告总结了方法和发现，推动了实用面部图像质量评估方法的发展。

Abstract: Face images play a crucial role in numerous applications; however, real-world
conditions frequently introduce degradations such as noise, blur, and
compression artifacts, affecting overall image quality and hindering subsequent
tasks. To address this challenge, we organized the VQualA 2025 Challenge on
Face Image Quality Assessment (FIQA) as part of the ICCV 2025 Workshops.
Participants created lightweight and efficient models (limited to 0.5 GFLOPs
and 5 million parameters) for the prediction of Mean Opinion Scores (MOS) on
face images with arbitrary resolutions and realistic degradations. Submissions
underwent comprehensive evaluations through correlation metrics on a dataset of
in-the-wild face images. This challenge attracted 127 participants, with 1519
final submissions. This report summarizes the methodologies and findings for
advancing the development of practical FIQA approaches.

</details>


### [13] [Context-Aware Zero-Shot Anomaly Detection in Surveillance Using Contrastive and Predictive Spatiotemporal Modeling](https://arxiv.org/abs/2508.18463)
*Md. Rashid Shahriar Khan,Md. Abrar Hasan,Mohammod Tareq Aziz Justice*

Main category: cs.CV

TL;DR: 提出了一种新型的上下文感知零样本异常检测框架，结合TimeSformer、DPC和CLIP模型，无需训练异常样本即可检测异常。


<details>
  <summary>Details</summary>
Motivation: 监控视频中的异常检测因异常事件的不可预测性和上下文依赖性而具有挑战性。

Method: 采用混合架构，结合TimeSformer提取时空特征，DPC预测未来表示，CLIP进行语义级异常检测，并通过上下文门控机制增强决策。

Result: 系统能够泛化到复杂环境中未见过的行为，填补了零样本异常检测中时间推理与语义上下文的空白。

Conclusion: 该框架为监控中的零样本异常检测提供了新思路，代码已开源。

Abstract: Detecting anomalies in surveillance footage is inherently challenging due to
their unpredictable and context-dependent nature. This work introduces a novel
context-aware zero-shot anomaly detection framework that identifies abnormal
events without exposure to anomaly examples during training. The proposed
hybrid architecture combines TimeSformer, DPC, and CLIP to model spatiotemporal
dynamics and semantic context. TimeSformer serves as the vision backbone to
extract rich spatial-temporal features, while DPC forecasts future
representations to identify temporal deviations. Furthermore, a CLIP-based
semantic stream enables concept-level anomaly detection through
context-specific text prompts. These components are jointly trained using
InfoNCE and CPC losses, aligning visual inputs with their temporal and semantic
representations. A context-gating mechanism further enhances decision-making by
modulating predictions with scene-aware cues or global video features. By
integrating predictive modeling with vision-language understanding, the system
can generalize to previously unseen behaviors in complex environments. This
framework bridges the gap between temporal reasoning and semantic context in
zero-shot anomaly detection for surveillance. The code for this research has
been made available at
https://github.com/NK-II/Context-Aware-ZeroShot-Anomaly-Detection-in-Surveillance.

</details>


### [14] [DoGFlow: Self-Supervised LiDAR Scene Flow via Cross-Modal Doppler Guidance](https://arxiv.org/abs/2508.18506)
*Ajinkya Khoche,Qingwen Zhang,Yixi Cai,Sina Sharif Mansouri,Patric Jensfelt*

Main category: cs.CV

TL;DR: DoGFlow是一种新型自监督框架，利用4D雷达多普勒测量生成伪标签，无需人工标注即可估计3D场景流。


<details>
  <summary>Details</summary>
Motivation: 解决3D场景流估计中大规模人工标注数据集难以获取的问题，提升自监督方法在复杂场景下的性能。

Method: 通过跨模态标签转移，利用4D雷达实时生成运动伪标签，并动态关联和传播到LiDAR域。

Result: 在MAN TruckScenes数据集上，DoGFlow显著优于现有自监督方法，仅需10%标注数据即可达到90%全监督性能。

Conclusion: DoGFlow提供了一种高效且可扩展的自监督解决方案，显著减少了对人工标注的依赖。

Abstract: Accurate 3D scene flow estimation is critical for autonomous systems to
navigate dynamic environments safely, but creating the necessary large-scale,
manually annotated datasets remains a significant bottleneck for developing
robust perception models. Current self-supervised methods struggle to match the
performance of fully supervised approaches, especially in challenging
long-range and adverse weather scenarios, while supervised methods are not
scalable due to their reliance on expensive human labeling. We introduce
DoGFlow, a novel self-supervised framework that recovers full 3D object motions
for LiDAR scene flow estimation without requiring any manual ground truth
annotations. This paper presents our cross-modal label transfer approach, where
DoGFlow computes motion pseudo-labels in real-time directly from 4D radar
Doppler measurements and transfers them to the LiDAR domain using dynamic-aware
association and ambiguity-resolved propagation. On the challenging MAN
TruckScenes dataset, DoGFlow substantially outperforms existing self-supervised
methods and improves label efficiency by enabling LiDAR backbones to achieve
over 90% of fully supervised performance with only 10% of the ground truth
data. For more details, please visit https://ajinkyakhoche.github.io/DogFlow/

</details>


### [15] [SAT-SKYLINES: 3D Building Generation from Satellite Imagery and Coarse Geometric Priors](https://arxiv.org/abs/2508.18531)
*Zhangyu Jin,Andrew Feng*

Main category: cs.CV

TL;DR: SatSkylines提出了一种结合卫星图像和粗略几何先验的3D建筑生成方法，解决了现有方法在几何精度和细节化上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基于图像的3D生成方法难以从卫星图像中恢复精确建筑结构，而3D细节化方法依赖高细节体素输入，无法从简单先验（如立方体）生成满意结果。

Method: 通过建模从插值噪声粗略先验到详细几何的转换，实现灵活的几何控制，无需额外计算成本。

Result: 开发了Skylines-50K数据集（5万多样式化3D建筑资产），实验证明模型有效且泛化能力强。

Conclusion: SatSkylines在几何控制和细节生成上表现优异，为3D建筑生成提供了新思路。

Abstract: We present SatSkylines, a 3D building generation approach that takes
satellite imagery and coarse geometric priors. Without proper geometric
guidance, existing image-based 3D generation methods struggle to recover
accurate building structures from the top-down views of satellite images alone.
On the other hand, 3D detailization methods tend to rely heavily on highly
detailed voxel inputs and fail to produce satisfying results from simple priors
such as cuboids. To address these issues, our key idea is to model the
transformation from interpolated noisy coarse priors to detailed geometries,
enabling flexible geometric control without additional computational cost. We
have further developed Skylines-50K, a large-scale dataset of over 50,000
unique and stylized 3D building assets in order to support the generations of
detailed building models. Extensive evaluations indicate the effectiveness of
our model and strong generalization ability.

</details>


### [16] [Adaptive Visual Navigation Assistant in 3D RPGs](https://arxiv.org/abs/2508.18539)
*Kaijie Xu,Clark Verbrugge*

Main category: cs.CV

TL;DR: 论文提出了一种检测游戏中可穿越空间过渡点（STP）和主STP（MSTP）的方法，使用两阶段深度学习流程，并在低数据场景中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在复杂3D游戏环境中，玩家依赖视觉线索识别地图过渡点，这对自动地图生成和评估地图设计至关重要。

Method: 采用两阶段深度学习流程：先用Faster R-CNN检测潜在STP，再用轻量级MSTP选择器结合局部和全局视觉特征进行排序。

Result: 实验表明，全网络微调在数据充足时表现更好，而仅使用适配器在低数据场景中更稳健。

Conclusion: 论文定义了新问题，提供了基线流程和数据集，为未来AI导航工具和数据驱动的关卡设计工具奠定了基础。

Abstract: In complex 3D game environments, players rely on visual affordances to spot
map transition points. Efficient identification of such points is important to
client-side auto-mapping, and provides an objective basis for evaluating map
cue presentation. In this work, we formalize the task of detecting traversable
Spatial Transition Points (STPs)-connectors between two sub regions-and
selecting the singular Main STP (MSTP), the unique STP that lies on the
designer-intended critical path toward the player's current macro-objective,
from a single game frame, proposing this as a new research focus. We introduce
a two-stage deep-learning pipeline that first detects potential STPs using
Faster R-CNN and then ranks them with a lightweight MSTP selector that fuses
local and global visual features. Both stages benefit from parameter-efficient
adapters, and we further introduce an optional retrieval-augmented fusion step.
Our primary goal is to establish the feasibility of this problem and set
baseline performance metrics. We validate our approach on a custom-built,
diverse dataset collected from five Action RPG titles. Our experiments reveal a
key trade-off: while full-network fine-tuning produces superior STP detection
with sufficient data, adapter-only transfer is significantly more robust and
effective in low-data scenarios and for the MSTP selection task. By defining
this novel problem, providing a baseline pipeline and dataset, and offering
initial insights into efficient model adaptation, we aim to contribute to
future AI-driven navigation aids and data-informed level-design tools.

</details>


### [17] [Wan-S2V: Audio-Driven Cinematic Video Generation](https://arxiv.org/abs/2508.18621)
*Xin Gao,Li Hu,Siqi Hu,Mingyang Huang,Chaonan Ji,Dechao Meng,Jinwei Qi,Penchong Qiao,Zhen Shen,Yafei Song,Ke Sun,Linrui Tian,Guangyuan Wang,Qi Wang,Zhongjian Wang,Jiayu Xiao,Sheng Xu,Bang Zhang,Peng Zhang,Xindi Zhang,Zhe Zhang,Jingren Zhou,Lian Zhuo*

Main category: cs.CV

TL;DR: Wan-S2V模型在音频驱动角色动画中显著提升电影级表现力，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂影视制作中表现不足，需解决角色互动、身体动作和镜头动态等挑战。

Method: 基于Wan构建的Wan-S2V模型，专注于提升表达力和保真度。

Result: 实验表明Wan-S2V优于Hunyuan-Avatar和Omnihuman等先进模型。

Conclusion: Wan-S2V适用于长视频生成和精确唇同步编辑，具有广泛潜力。

Abstract: Current state-of-the-art (SOTA) methods for audio-driven character animation
demonstrate promising performance for scenarios primarily involving speech and
singing. However, they often fall short in more complex film and television
productions, which demand sophisticated elements such as nuanced character
interactions, realistic body movements, and dynamic camera work. To address
this long-standing challenge of achieving film-level character animation, we
propose an audio-driven model, which we refere to as Wan-S2V, built upon Wan.
Our model achieves significantly enhanced expressiveness and fidelity in
cinematic contexts compared to existing approaches. We conducted extensive
experiments, benchmarking our method against cutting-edge models such as
Hunyuan-Avatar and Omnihuman. The experimental results consistently demonstrate
that our approach significantly outperforms these existing solutions.
Additionally, we explore the versatility of our method through its applications
in long-form video generation and precise video lip-sync editing.

</details>


### [18] [Decouple, Reorganize, and Fuse: A Multimodal Framework for Cancer Survival Prediction](https://arxiv.org/abs/2508.18632)
*Huayi Wang,Haochao Ying,Yuyang Xu,Qibo Qiu,Cheng Zhang,Danny Z. Chen,Ying Sun,Jian Wu*

Main category: cs.CV

TL;DR: 提出了一种新的Decoupling-Reorganization-Fusion框架（DeReF），通过随机特征重组和动态MoE融合解决癌症生存分析中的模态融合问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在模态融合时存在固定融合方案导致特征组合受限，以及MoE方法中专家网络信息交互不足的问题。

Method: 采用随机特征重组策略和动态MoE融合模块，结合区域交叉注意力网络提升特征表示质量。

Result: 在内部肝癌数据集和TCGA公共数据集上验证了方法的有效性。

Conclusion: DeReF框架提高了特征组合的多样性和信息交互能力，增强了模型的泛化能力。

Abstract: Cancer survival analysis commonly integrates information across diverse
medical modalities to make survival-time predictions. Existing methods
primarily focus on extracting different decoupled features of modalities and
performing fusion operations such as concatenation, attention, and MoE-based
(Mixture-of-Experts) fusion. However, these methods still face two key
challenges: i) Fixed fusion schemes (concatenation and attention) can lead to
model over-reliance on predefined feature combinations, limiting the dynamic
fusion of decoupled features; ii) in MoE-based fusion methods, each expert
network handles separate decoupled features, which limits information
interaction among the decoupled features. To address these challenges, we
propose a novel Decoupling-Reorganization-Fusion framework (DeReF), which
devises a random feature reorganization strategy between modalities decoupling
and dynamic MoE fusion modules.Its advantages are: i) it increases the
diversity of feature combinations and granularity, enhancing the generalization
ability of the subsequent expert networks; ii) it overcomes the problem of
information closure and helps expert networks better capture information among
decoupled features. Additionally, we incorporate a regional cross-attention
network within the modality decoupling module to improve the representation
quality of decoupled features. Extensive experimental results on our in-house
Liver Cancer (LC) and three widely used TCGA public datasets confirm the
effectiveness of our proposed method. The code will be made publicly available.

</details>


### [19] [ROSE: Remove Objects with Side Effects in Videos](https://arxiv.org/abs/2508.18633)
*Chenxuan Miao,Yutong Feng,Jianshu Zeng,Zixiang Gao,Hantang Liu,Yunfeng Yan,Donglian Qi,Xi Chen,Bin Wang,Hengshuang Zhao*

Main category: cs.CV

TL;DR: ROSE是一个视频对象移除框架，专注于消除对象及其副作用（如阴影、反射等），通过合成数据和扩散变压器模型实现高效移除。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理对象副作用（如阴影、反射）时表现不佳，主要因缺乏成对视频数据作为监督。

Method: 利用3D渲染引擎生成合成数据，构建视频修复模型（基于扩散变压器），并通过差异掩码定位副作用区域。

Result: ROSE在ROSE-Bench基准测试中表现优于现有模型，并能泛化到真实场景。

Conclusion: ROSE通过系统化处理对象副作用，显著提升了视频对象移除的效果。

Abstract: Video object removal has achieved advanced performance due to the recent
success of video generative models. However, when addressing the side effects
of objects, e.g., their shadows and reflections, existing works struggle to
eliminate these effects for the scarcity of paired video data as supervision.
This paper presents ROSE, termed Remove Objects with Side Effects, a framework
that systematically studies the object's effects on environment, which can be
categorized into five common cases: shadows, reflections, light, translucency
and mirror. Given the challenges of curating paired videos exhibiting the
aforementioned effects, we leverage a 3D rendering engine for synthetic data
generation. We carefully construct a fully-automatic pipeline for data
preparation, which simulates a large-scale paired dataset with diverse scenes,
objects, shooting angles, and camera trajectories. ROSE is implemented as an
video inpainting model built on diffusion transformer. To localize all
object-correlated areas, the entire video is fed into the model for
reference-based erasing. Moreover, additional supervision is introduced to
explicitly predict the areas affected by side effects, which can be revealed
through the differential mask between the paired videos. To fully investigate
the model performance on various side effect removal, we presents a new
benchmark, dubbed ROSE-Bench, incorporating both common scenarios and the five
special side effects for comprehensive evaluation. Experimental results
demonstrate that ROSE achieves superior performance compared to existing video
object erasing models and generalizes well to real-world video scenarios. The
project page is https://rose2025-inpaint.github.io/.

</details>


### [20] [OwlCap: Harmonizing Motion-Detail for Video Captioning via HMD-270K and Caption Set Equivalence Reward](https://arxiv.org/abs/2508.18634)
*Chunlin Zhong,Qiuxia Hou,Zhangjun Zhou,Shuang Hao,Haonan Lu,Yanhao Zhang,He Tang,Xiang Bai*

Main category: cs.CV

TL;DR: 论文提出OwlCap模型和HMD-270K数据集，通过数据与优化两方面解决视频字幕生成中的运动-细节不平衡问题，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频字幕生成方法存在运动与细节不平衡问题，导致描述不完整，影响视频理解与生成的一致性。

Method: 1) 数据方面：构建HMD-270K数据集（两阶段流程：运动-细节融合与细粒度检查）；2) 优化方面：提出基于GRPO的CSER奖励机制，通过单元到集合匹配和双向验证增强完整性。

Result: OwlCap在VDC（细节）和DREAM-1K（运动）基准测试中分别提升4.2 Acc和4.6 F1。

Conclusion: HMD-270K数据集和OwlCap模型公开，推动视频字幕生成研究发展。

Abstract: Video captioning aims to generate comprehensive and coherent descriptions of
the video content, contributing to the advancement of both video understanding
and generation. However, existing methods often suffer from motion-detail
imbalance, as models tend to overemphasize one aspect while neglecting the
other. This imbalance results in incomplete captions, which in turn leads to a
lack of consistency in video understanding and generation. To address this
issue, we propose solutions from two aspects: 1) Data aspect: We constructed
the Harmonizing Motion-Detail 270K (HMD-270K) dataset through a two-stage
pipeline: Motion-Detail Fusion (MDF) and Fine-Grained Examination (FGE). 2)
Optimization aspect: We introduce the Caption Set Equivalence Reward (CSER)
based on Group Relative Policy Optimization (GRPO). CSER enhances completeness
and accuracy in capturing both motion and details through unit-to-set matching
and bidirectional validation. Based on the HMD-270K supervised fine-tuning and
GRPO post-training with CSER, we developed OwlCap, a powerful video captioning
multi-modal large language model (MLLM) with motion-detail balance.
Experimental results demonstrate that OwlCap achieves significant improvements
compared to baseline models on two benchmarks: the detail-focused VDC (+4.2
Acc) and the motion-focused DREAM-1K (+4.6 F1). The HMD-270K dataset and OwlCap
model will be publicly released to facilitate video captioning research
community advancements.

</details>


### [21] [Clustering-based Feature Representation Learning for Oracle Bone Inscriptions Detection](https://arxiv.org/abs/2508.18641)
*Ye Tao,Xinran Fu,Honglin Pang,Xi Yang,Chuntao Li*

Main category: cs.CV

TL;DR: 提出了一种基于聚类的特征空间表示学习方法，用于甲骨文（OBIs）的自动检测，通过利用甲骨文字体库数据集作为先验知识，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 甲骨文在理解中国古代文明中至关重要，但由于噪声和裂纹等退化因素，传统检测网络效果有限。

Method: 利用甲骨文字体库数据集进行聚类表示学习，设计专用损失函数优化特征表示，并集成到网络总损失中。

Result: 在三种主流检测框架（Faster R-CNN、DETR、Sparse R-CNN）上实验，性能均显著提升。

Conclusion: 该方法有效解决了甲骨文检测中的挑战，为数字考古提供了新思路。

Abstract: Oracle Bone Inscriptions (OBIs), play a crucial role in understanding ancient
Chinese civilization. The automated detection of OBIs from rubbing images
represents a fundamental yet challenging task in digital archaeology, primarily
due to various degradation factors including noise and cracks that limit the
effectiveness of conventional detection networks. To address these challenges,
we propose a novel clustering-based feature space representation learning
method. Our approach uniquely leverages the Oracle Bones Character (OBC) font
library dataset as prior knowledge to enhance feature extraction in the
detection network through clustering-based representation learning. The method
incorporates a specialized loss function derived from clustering results to
optimize feature representation, which is then integrated into the total
network loss. We validate the effectiveness of our method by conducting
experiments on two OBIs detection dataset using three mainstream detection
frameworks: Faster R-CNN, DETR, and Sparse R-CNN. Through extensive
experimentation, all frameworks demonstrate significant performance
improvements.

</details>


### [22] [SFormer: SNR-guided Transformer for Underwater Image Enhancement from the Frequency Domain](https://arxiv.org/abs/2508.18664)
*Xin Tian,Yingtie Lei,Xiujun Zhang,Zimeng Li,Chi-Man Pun,Xuhang Chen*

Main category: cs.CV

TL;DR: 提出了一种基于频域SNR先验的Transformer方法（FAST和FAT），用于水下图像增强，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有空间域SNR先验方法在分离跨通道干扰和增强信息结构方面存在不足。

Method: 在频域使用SNR先验，结合FAST和FAT模块，通过U形架构整合RGB流和SNR分支。

Result: 在多个数据集上训练，PSNR提升3.1 dB，SSIM提升0.08，有效恢复水下场景的颜色和纹理。

Conclusion: 频域SNR先验和Transformer结合的方法在水下图像增强中表现优异。

Abstract: Recent learning-based underwater image enhancement (UIE) methods have
advanced by incorporating physical priors into deep neural networks,
particularly using the signal-to-noise ratio (SNR) prior to reduce
wavelength-dependent attenuation. However, spatial domain SNR priors have two
limitations: (i) they cannot effectively separate cross-channel interference,
and (ii) they provide limited help in amplifying informative structures while
suppressing noise. To overcome these, we propose using the SNR prior in the
frequency domain, decomposing features into amplitude and phase spectra for
better channel modulation. We introduce the Fourier Attention SNR-prior
Transformer (FAST), combining spectral interactions with SNR cues to highlight
key spectral components. Additionally, the Frequency Adaptive Transformer (FAT)
bottleneck merges low- and high-frequency branches using a gated attention
mechanism to enhance perceptual quality. Embedded in a unified U-shaped
architecture, these modules integrate a conventional RGB stream with an
SNR-guided branch, forming SFormer. Trained on 4,800 paired images from UIEB,
EUVP, and LSUI, SFormer surpasses recent methods with a 3.1 dB gain in PSNR and
0.08 in SSIM, successfully restoring colors, textures, and contrast in
underwater scenes.

</details>


### [23] [Hierarchical Spatio-temporal Segmentation Network for Ejection Fraction Estimation in Echocardiography Videos](https://arxiv.org/abs/2508.18681)
*Dongfang Wang,Jian Yang,Yizhe Zhang,Tao Zhou*

Main category: cs.CV

TL;DR: 提出了一种分层时空分割网络（HSSN）用于超声心动图视频的左心室内膜分割，旨在通过结合局部细节建模和全局动态感知提高射血分数（EF）估计的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有研究在分割性能上表现良好，但在EF估计上效果不佳，因此需要一种能同时处理局部细节和全局动态的方法。

Method: 采用分层设计，低层使用卷积网络处理单帧图像以保留细节，高层使用Mamba架构捕捉时空关系，并提出时空交叉扫描（STCS）模块整合长程上下文。

Result: 该方法平衡了单帧和多帧处理的优势，避免了局部误差累积或细节丢失的问题，有效减少了EF计算偏差。

Conclusion: HSSN通过分层设计和STCS模块显著提升了EF估计的准确性，为心脏功能评估提供了更可靠的解决方案。

Abstract: Automated segmentation of the left ventricular endocardium in
echocardiography videos is a key research area in cardiology. It aims to
provide accurate assessment of cardiac structure and function through Ejection
Fraction (EF) estimation. Although existing studies have achieved good
segmentation performance, their results do not perform well in EF estimation.
In this paper, we propose a Hierarchical Spatio-temporal Segmentation Network
(\ourmodel) for echocardiography video, aiming to improve EF estimation
accuracy by synergizing local detail modeling with global dynamic perception.
The network employs a hierarchical design, with low-level stages using
convolutional networks to process single-frame images and preserve details,
while high-level stages utilize the Mamba architecture to capture
spatio-temporal relationships. The hierarchical design balances single-frame
and multi-frame processing, avoiding issues such as local error accumulation
when relying solely on single frames or neglecting details when using only
multi-frame data. To overcome local spatio-temporal limitations, we propose the
Spatio-temporal Cross Scan (STCS) module, which integrates long-range context
through skip scanning across frames and positions. This approach helps mitigate
EF calculation biases caused by ultrasound image noise and other factors.

</details>


### [24] [Feature-Space Planes Searcher: A Universal Domain Adaptation Framework for Interpretability and Computational Efficiency](https://arxiv.org/abs/2508.18693)
*Zhitong Cheng,Yiran Jiang,Yulong Ge,Yufeng Li,Zhongheng Qin,Rongzhi Lin,Jianwei Ma*

Main category: cs.CV

TL;DR: 论文提出了一种名为FPS的新方法，通过优化决策边界来解决领域适应问题，避免了传统微调方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 领域偏移导致模型性能下降，当前的无监督领域适应方法效率低且难以解释。

Method: FPS利用预训练模型中的几何模式优化决策边界，保持特征编码器冻结。

Result: FPS在多个公共基准测试中表现优异，且适用于多模态大模型和多样化领域。

Conclusion: FPS为领域适应任务提供了一种简单、高效且通用的解决方案。

Abstract: Domain shift, characterized by degraded model performance during transition
from labeled source domains to unlabeled target domains, poses a persistent
challenge for deploying deep learning systems. Current unsupervised domain
adaptation (UDA) methods predominantly rely on fine-tuning feature extractors -
an approach limited by inefficiency, reduced interpretability, and poor
scalability to modern architectures.
  Our analysis reveals that models pretrained on large-scale data exhibit
domain-invariant geometric patterns in their feature space, characterized by
intra-class clustering and inter-class separation, thereby preserving
transferable discriminative structures. These findings indicate that domain
shifts primarily manifest as boundary misalignment rather than feature
degradation.
  Unlike fine-tuning entire pre-trained models - which risks introducing
unpredictable feature distortions - we propose the Feature-space Planes
Searcher (FPS): a novel domain adaptation framework that optimizes decision
boundaries by leveraging these geometric patterns while keeping the feature
encoder frozen. This streamlined approach enables interpretative analysis of
adaptation while substantially reducing memory and computational costs through
offline feature extraction, permitting full-dataset optimization in a single
computation cycle.
  Evaluations on public benchmarks demonstrate that FPS achieves competitive or
superior performance to state-of-the-art methods. FPS scales efficiently with
multimodal large models and shows versatility across diverse domains including
protein structure prediction, remote sensing classification, and earthquake
detection. We anticipate FPS will provide a simple, effective, and
generalizable paradigm for transfer learning, particularly in domain adaptation
tasks. .

</details>


### [25] [A Novel Deep Hybrid Framework with Ensemble-Based Feature Optimization for Robust Real-Time Human Activity Recognition](https://arxiv.org/abs/2508.18695)
*Wasi Ullah,Yasir Noman Khalid,Saddam Hussain Khan*

Main category: cs.CV

TL;DR: 提出了一种优化的混合深度学习框架，结合定制InceptionV3、LSTM和基于集成的特征选择策略，显著提升了HAR系统的性能和效率。


<details>
  <summary>Details</summary>
Motivation: HAR系统面临高计算成本、冗余特征和实时性不足等挑战，需优化框架以提升性能和可扩展性。

Method: 使用定制InceptionV3提取空间特征，LSTM建模时间依赖，集成遗传算法ADFSA选择优化特征子集。

Result: 在UCF-YouTube数据集上达到99.65%识别准确率，特征降至7个，推理时间缩短，支持边缘设备部署。

Conclusion: 该框架轻量且可扩展，适用于实时HAR应用，如公共安全和辅助技术。

Abstract: Human Activity Recognition (HAR) plays a pivotal role in various
applications, including smart surveillance, healthcare, assistive technologies,
sports analytics, etc. However, HAR systems still face critical challenges,
including high computational costs, redundant features, and limited scalability
in real-time scenarios. An optimized hybrid deep learning framework is
introduced that integrates a customized InceptionV3, an LSTM architecture, and
a novel ensemble-based feature selection strategy. The proposed framework first
extracts spatial descriptors using the customized InceptionV3 model, which
captures multilevel contextual patterns, region homogeneity, and fine-grained
localization cues. The temporal dependencies across frames are then modeled
using LSTMs to effectively encode motion dynamics. Finally, an ensemble-based
genetic algorithm with Adaptive Dynamic Fitness Sharing and Attention (ADFSA)
is employed to select a compact and optimized feature set by dynamically
balancing objectives such as accuracy, redundancy, uniqueness, and complexity
reduction. Consequently, the selected feature subsets, which are both diverse
and discriminative, enable various lightweight machine learning classifiers to
achieve accurate and robust HAR in heterogeneous environments. Experimental
results on the robust UCF-YouTube dataset, which presents challenges such as
occlusion, cluttered backgrounds, motion dynamics, and poor illumination,
demonstrate good performance. The proposed approach achieves 99.65% recognition
accuracy, reduces features to as few as 7, and enhances inference time. The
lightweight and scalable nature of the HAR system supports real-time deployment
on edge devices such as Raspberry Pi, enabling practical applications in
intelligent, resource-aware environments, including public safety, assistive
technology, and autonomous monitoring systems.

</details>


### [26] [ColorGS: High-fidelity Surgical Scene Reconstruction with Colored Gaussian Splatting](https://arxiv.org/abs/2508.18696)
*Qun Ji,Peng Li,Mingqiang Wei*

Main category: cs.CV

TL;DR: ColorGS提出了一种结合空间自适应颜色编码和增强变形建模的新框架，显著提升了内窥镜视频中组织重建的保真度和实时渲染效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在捕捉细微颜色变化和建模全局变形方面存在局限性，3D高斯泼溅（3DGS）的固定颜色分配和线性变形建模无法满足复杂纹理和一致全局变形的需求。

Method: ColorGS通过彩色高斯基元（动态锚点和可学习颜色参数）和增强变形模型（时间感知基函数与时间无关变形结合），实现了对复杂纹理和全局变形的精确建模。

Result: 在达芬奇机器人手术视频和基准数据集（EndoNeRF、StereoMIS）上，ColorGS实现了PSNR 39.85（比现有3DGS方法高1.5）和SSIM 97.25%的优异性能，同时保持实时渲染效率。

Conclusion: ColorGS在手术场景重建中实现了高保真度与计算实用性的平衡，对术中导航和AR/VR应用具有重要意义。

Abstract: High-fidelity reconstruction of deformable tissues from endoscopic videos
remains challenging due to the limitations of existing methods in capturing
subtle color variations and modeling global deformations. While 3D Gaussian
Splatting (3DGS) enables efficient dynamic reconstruction, its fixed
per-Gaussian color assignment struggles with intricate textures, and linear
deformation modeling fails to model consistent global deformation. To address
these issues, we propose ColorGS, a novel framework that integrates spatially
adaptive color encoding and enhanced deformation modeling for surgical scene
reconstruction. First, we introduce Colored Gaussian Primitives, which employ
dynamic anchors with learnable color parameters to adaptively encode spatially
varying textures, significantly improving color expressiveness under complex
lighting and tissue similarity. Second, we design an Enhanced Deformation Model
(EDM) that combines time-aware Gaussian basis functions with learnable
time-independent deformations, enabling precise capture of both localized
tissue deformations and global motion consistency caused by surgical
interactions. Extensive experiments on DaVinci robotic surgery videos and
benchmark datasets (EndoNeRF, StereoMIS) demonstrate that ColorGS achieves
state-of-the-art performance, attaining a PSNR of 39.85 (1.5 higher than prior
3DGS-based methods) and superior SSIM (97.25\%) while maintaining real-time
rendering efficiency. Our work advances surgical scene reconstruction by
balancing high fidelity with computational practicality, critical for
intraoperative guidance and AR/VR applications.

</details>


### [27] [Class-wise Flooding Regularization for Imbalanced Image Classification](https://arxiv.org/abs/2508.18723)
*Hiroaki Aizawa,Yuta Naito,Kohei Fukuda*

Main category: cs.CV

TL;DR: 提出了一种基于类别的洪水正则化方法，用于解决不平衡数据集中少数类识别性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: 在不平衡数据集上训练神经网络时，模型倾向于偏向多数类，导致少数类的识别性能显著下降。

Method: 扩展了洪水正则化技术，为每个类别分配特定的洪水水平，抑制多数类的过拟合，同时允许少数类充分学习。

Result: 在图像分类任务中验证了方法的有效性，相比传统洪水正则化，少数类的分类性能和整体泛化能力均有提升。

Conclusion: 提出的类级别洪水正则化方法有效改善了不平衡数据集上的模型性能。

Abstract: The purpose of training neural networks is to achieve high generalization
performance on unseen inputs. However, when trained on imbalanced datasets, a
model's prediction tends to favor majority classes over minority classes,
leading to significant degradation in the recognition performance of minority
classes. To address this issue, we propose class-wise flooding regularization,
an extension of flooding regularization applied at the class level. Flooding is
a regularization technique that mitigates overfitting by preventing the
training loss from falling below a predefined threshold, known as the flooding
level, thereby discouraging memorization. Our proposed method assigns a
class-specific flooding level based on class frequencies. By doing so, it
suppresses overfitting in majority classes while allowing sufficient learning
for minority classes. We validate our approach on imbalanced image
classification. Compared to conventional flooding regularizations, our method
improves the classification performance of minority classes and achieves better
overall generalization.

</details>


### [28] [Flatness-aware Curriculum Learning via Adversarial Difficulty](https://arxiv.org/abs/2508.18726)
*Hiroaki Aizawa,Yoshikazu Hayashi*

Main category: cs.CV

TL;DR: 提出了一种结合课程学习（CL）和锐度感知最小化（SAM）的方法，通过对抗难度度量（ADM）动态评估样本难度，提升模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统CL和SAM结合时，在平坦区域难以评估样本难度，导致效果不佳。

Method: 提出ADM，通过测量原始样本与对抗样本的归一化损失差距来量化对抗脆弱性，并将其融入CL和SAM的训练中。

Result: 在图像分类、细粒度识别和领域泛化任务中，该方法优于现有课程学习和平坦感知训练策略。

Conclusion: ADM有效解决了平坦区域样本难度评估问题，结合CL和SAM显著提升了模型性能。

Abstract: Neural networks trained by empirical risk minimization often suffer from
overfitting, especially to specific samples or domains, which leads to poor
generalization. Curriculum Learning (CL) addresses this issue by selecting
training samples based on the difficulty. From the optimization perspective,
methods such as Sharpness-Aware Minimization (SAM) improve robustness and
generalization by seeking flat minima. However, combining CL with SAM is not
straightforward. In flat regions, both the loss values and the gradient norms
tend to become uniformly small, which makes it difficult to evaluate sample
difficulty and design an effective curriculum. To overcome this problem, we
propose the Adversarial Difficulty Measure (ADM), which quantifies adversarial
vulnerability by leveraging the robustness properties of models trained toward
flat minima. Unlike loss- or gradient-based measures, which become ineffective
as training progresses into flatter regions, ADM remains informative by
measuring the normalized loss gap between original and adversarial examples. We
incorporate ADM into CL-based training with SAM to dynamically assess sample
difficulty. We evaluated our approach on image classification tasks,
fine-grained recognition, and domain generalization. The results demonstrate
that our method preserves the strengths of both CL and SAM while outperforming
existing curriculum-based and flatness-aware training strategies.

</details>


### [29] [Are All Marine Species Created Equal? Performance Disparities in Underwater Object Detection](https://arxiv.org/abs/2508.18729)
*Melanie Wille,Tobias Fischer,Scarlett Raine*

Main category: cs.CV

TL;DR: 论文分析了水下目标检测中类别性能差异的原因，并提出改进方法，重点关注扇贝类别的定位和分类问题。


<details>
  <summary>Details</summary>
Motivation: 水下目标检测面临图像质量差、类别分布不均和视觉特征独特等挑战，某些物种检测效果不佳的原因尚不明确。

Method: 通过操纵DUO数据集，将目标检测任务分为定位和分类两部分，使用YOLO11和TIDE分析扇贝类别的性能问题。

Result: 定位分析发现前景-背景区分是主要问题；分类实验显示即使数据平衡，精度差距仍存在，表明特征本身存在挑战。

Conclusion: 建议根据需求选择数据分布策略，改进低性能类别应聚焦算法优化，尤其是定位模块。代码和数据集已公开。

Abstract: Underwater object detection is critical for monitoring marine ecosystems but
poses unique challenges, including degraded image quality, imbalanced class
distribution, and distinct visual characteristics. Not every species is
detected equally well, yet underlying causes remain unclear. We address two key
research questions: 1) What factors beyond data quantity drive class-specific
performance disparities? 2) How can we systematically improve detection of
under-performing marine species? We manipulate the DUO dataset to separate the
object detection task into localization and classification and investigate the
under-performance of the scallop class. Localization analysis using YOLO11 and
TIDE finds that foreground-background discrimination is the most problematic
stage regardless of data quantity. Classification experiments reveal persistent
precision gaps even with balanced data, indicating intrinsic feature-based
challenges beyond data scarcity and inter-class dependencies. We recommend
imbalanced distributions when prioritizing precision, and balanced
distributions when prioritizing recall. Improving under-performing classes
should focus on algorithmic advances, especially within localization modules.
We publicly release our code and datasets.

</details>


### [30] [PseudoMapTrainer: Learning Online Mapping without HD Maps](https://arxiv.org/abs/2508.18788)
*Christian Löwens,Thorben Funke,Jingchao Xie,Alexandru Paul Condurache*

Main category: cs.CV

TL;DR: 提出PseudoMapTrainer，利用伪标签从无标注传感器数据训练在线地图模型，无需高精地图。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖昂贵且地理多样性不足的高精地图，限制了泛化能力。

Method: 通过多视角图像重建道路表面（高斯泼溅）和预训练2D分割网络生成伪标签，并提出掩码感知分配算法和损失函数。

Result: 首次实现无需高精地图的在线地图模型训练，并可利用大规模无标注数据进行半监督预训练。

Conclusion: PseudoMapTrainer为在线地图提供了一种低成本、高泛化的解决方案。

Abstract: Online mapping models show remarkable results in predicting vectorized maps
from multi-view camera images only. However, all existing approaches still rely
on ground-truth high-definition maps during training, which are expensive to
obtain and often not geographically diverse enough for reliable generalization.
In this work, we propose PseudoMapTrainer, a novel approach to online mapping
that uses pseudo-labels generated from unlabeled sensor data. We derive those
pseudo-labels by reconstructing the road surface from multi-camera imagery
using Gaussian splatting and semantics of a pre-trained 2D segmentation
network. In addition, we introduce a mask-aware assignment algorithm and loss
function to handle partially masked pseudo-labels, allowing for the first time
the training of online mapping models without any ground-truth maps.
Furthermore, our pseudo-labels can be effectively used to pre-train an online
model in a semi-supervised manner to leverage large-scale unlabeled
crowdsourced data. The code is available at
github.com/boschresearch/PseudoMapTrainer.

</details>


### [31] [Drawing2CAD: Sequence-to-Sequence Learning for CAD Generation from Vectorized Drawings](https://arxiv.org/abs/2508.18733)
*Feiwei Qin,Shichao Lu,Junhao Hou,Changmiao Wang,Meie Fang,Ligang Liu*

Main category: cs.CV

TL;DR: 论文提出Drawing2CAD框架，将2D工程图自动转换为参数化CAD模型，解决了传统工业流程中的关键问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法多从点云、网格或文本生成CAD模型，但忽略了工业流程中从2D工程图开始的传统方式，这一关键步骤尚未充分探索。

Method: 将CAD生成问题重构为序列到序列学习任务，提出Drawing2CAD框架，包含网络友好的矢量图表示、双解码器Transformer架构和软目标分布损失函数。

Result: 通过创建CAD-VGDrawing数据集并进行实验，验证了方法的有效性。

Conclusion: Drawing2CAD成功实现了从2D工程图到参数化CAD模型的精确转换，保留了设计意图和几何精度。

Abstract: Computer-Aided Design (CAD) generative modeling is driving significant
innovations across industrial applications. Recent works have shown remarkable
progress in creating solid models from various inputs such as point clouds,
meshes, and text descriptions. However, these methods fundamentally diverge
from traditional industrial workflows that begin with 2D engineering drawings.
The automatic generation of parametric CAD models from these 2D vector drawings
remains underexplored despite being a critical step in engineering design. To
address this gap, our key insight is to reframe CAD generation as a
sequence-to-sequence learning problem where vector drawing primitives directly
inform the generation of parametric CAD operations, preserving geometric
precision and design intent throughout the transformation process. We propose
Drawing2CAD, a framework with three key technical components: a
network-friendly vector primitive representation that preserves precise
geometric information, a dual-decoder transformer architecture that decouples
command type and parameter generation while maintaining precise correspondence,
and a soft target distribution loss function accommodating inherent flexibility
in CAD parameters. To train and evaluate Drawing2CAD, we create CAD-VGDrawing,
a dataset of paired engineering drawings and parametric CAD models, and conduct
thorough experiments to demonstrate the effectiveness of our method. Code and
dataset are available at https://github.com/lllssc/Drawing2CAD.

</details>


### [32] [Interpretable Decision-Making for End-to-End Autonomous Driving](https://arxiv.org/abs/2508.18898)
*Mona Mirzaie,Bodo Rosenhahn*

Main category: cs.CV

TL;DR: 提出一种增强自动驾驶中AI决策可解释性的方法，通过稀疏和局部化特征图优化控制命令。


<details>
  <summary>Details</summary>
Motivation: 端到端方法在复杂城市场景中难以解释AI决策逻辑，需要提升可解释性以增强信任。

Method: 设计损失函数生成稀疏和局部化特征图，解释图像区域对控制命令的贡献。

Result: 在CARLA基准测试中表现优异，减少违规并提高路线完成率，同时保持可解释性。

Conclusion: 单目非集成模型在CARLA排行榜上超越现有方法，实现更安全的驾驶性能。

Abstract: Trustworthy AI is mandatory for the broad deployment of autonomous vehicles.
Although end-to-end approaches derive control commands directly from raw data,
interpreting these decisions remains challenging, especially in complex urban
scenarios. This is mainly attributed to very deep neural networks with
non-linear decision boundaries, making it challenging to grasp the logic behind
AI-driven decisions. This paper presents a method to enhance interpretability
while optimizing control commands in autonomous driving. To address this, we
propose loss functions that promote the interpretability of our model by
generating sparse and localized feature maps. The feature activations allow us
to explain which image regions contribute to the predicted control command. We
conduct comprehensive ablation studies on the feature extraction step and
validate our method on the CARLA benchmarks. We also demonstrate that our
approach improves interpretability, which correlates with reducing infractions,
yielding a safer, high-performance driving model. Notably, our monocular,
non-ensemble model surpasses the top-performing approaches from the CARLA
Leaderboard by achieving lower infraction scores and the highest route
completion rate, all while ensuring interpretability.

</details>


### [33] [Improving Noise Robust Audio-Visual Speech Recognition via Router-Gated Cross-Modal Feature Fusion](https://arxiv.org/abs/2508.18734)
*DongHoon Lim,YoungChae Kim,Dong-Hyun Kim,Da-Hee Yang,Joon-Hyuk Chang*

Main category: cs.CV

TL;DR: 提出了一种基于路由门控的跨模态特征融合方法，用于动态调整音频和视觉特征的权重，以提升噪声环境下的音频-视觉语音识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有系统难以准确估计音频可靠性并动态调整模态依赖，导致在噪声环境下的性能下降。

Method: 通过路由门控机制，基于声学损坏分数动态调整音频和视觉特征的权重，并在解码器层中通过门控跨注意力强化视觉线索。

Result: 在LRS3数据集上，相比AV-HuBERT，词错误率相对降低了16.51-42.67%。

Conclusion: 路由门控机制和门控跨注意力机制共同提升了模型在真实噪声环境下的鲁棒性。

Abstract: Robust audio-visual speech recognition (AVSR) in noisy environments remains
challenging, as existing systems struggle to estimate audio reliability and
dynamically adjust modality reliance. We propose router-gated cross-modal
feature fusion, a novel AVSR framework that adaptively reweights audio and
visual features based on token-level acoustic corruption scores. Using an
audio-visual feature fusion-based router, our method down-weights unreliable
audio tokens and reinforces visual cues through gated cross-attention in each
decoder layer. This enables the model to pivot toward the visual modality when
audio quality deteriorates. Experiments on LRS3 demonstrate that our approach
achieves an 16.51-42.67% relative reduction in word error rate compared to
AV-HuBERT. Ablation studies confirm that both the router and gating mechanism
contribute to improved robustness under real-world acoustic noise.

</details>


### [34] [VibES: Induced Vibration for Persistent Event-Based Sensing](https://arxiv.org/abs/2508.19094)
*Vincenzo Polizzi,Stephen Yang,Quentin Clark,Jonathan Kelly,Igor Gilitschenski,David B. Lindell*

Main category: cs.CV

TL;DR: 提出了一种轻量级方法，通过旋转不平衡质量产生周期性振动，以持续生成事件，并结合运动补偿管道，提高事件相机的性能。


<details>
  <summary>Details</summary>
Motivation: 解决事件相机在静态或低运动场景下无法生成事件的问题，避免复杂硬件或额外光学组件的需求。

Method: 使用旋转不平衡质量诱导周期性振动，结合运动补偿管道去除注入的运动。

Result: 在真实数据集上验证了方法的有效性，提高了图像重建和边缘检测性能。

Conclusion: 该方法可靠地恢复了运动参数，显著提升了事件相机的感知能力。

Abstract: Event cameras are a bio-inspired class of sensors that asynchronously measure
per-pixel intensity changes. Under fixed illumination conditions in static or
low-motion scenes, rigidly mounted event cameras are unable to generate any
events, becoming unsuitable for most computer vision tasks. To address this
limitation, recent work has investigated motion-induced event stimulation that
often requires complex hardware or additional optical components. In contrast,
we introduce a lightweight approach to sustain persistent event generation by
employing a simple rotating unbalanced mass to induce periodic vibrational
motion. This is combined with a motion-compensation pipeline that removes the
injected motion and yields clean, motion-corrected events for downstream
perception tasks. We demonstrate our approach with a hardware prototype and
evaluate it on real-world captured datasets. Our method reliably recovers
motion parameters and improves both image reconstruction and edge detection
over event-based sensing without motion induction.

</details>


### [35] [Rethinking Human-Object Interaction Evaluation for both Vision-Language Models and HOI-Specific Methods](https://arxiv.org/abs/2508.18753)
*Qinqian Lei,Bo Wang,Robby T. Tan*

Main category: cs.CV

TL;DR: 论文提出了一种新的基准测试方法，将HOI检测重新定义为多答案选择题任务，以减少对生成式VLMs和专用HOI方法的惩罚。


<details>
  <summary>Details</summary>
Motivation: 现有HOI基准测试（如HICO-DET）与现代VLMs不兼容，其严格匹配标注类别的评估方式可能惩罚合理的预测。

Method: 引入新的基准测试，将HOI检测设计为多答案选择题任务，仅包含真实正选项和精心筛选的负选项以减少歧义。

Result: 新评估协议首次实现了VLMs和HOI方法的直接比较，为HOI理解提供了新视角。

Conclusion: 新基准测试避免了惩罚合理预测，为HOI检测领域提供了更公平的评估方式。

Abstract: Prior human-object interaction (HOI) detection methods have integrated early
vision-language models (VLMs) such as CLIP, but only as supporting components
within their frameworks. In contrast, recent advances in large, generative VLMs
suggest that these models may already possess strong ability to understand
images involving HOI. This naturally raises an important question: can
general-purpose standalone VLMs effectively solve HOI detection, and how do
they compare with specialized HOI methods? Answering this requires a benchmark
that can accommodate both paradigms. However, existing HOI benchmarks such as
HICO-DET were developed before the emergence of modern VLMs, and their
evaluation protocols require exact matches to annotated HOI classes. This is
poorly aligned with the generative nature of VLMs, which often yield multiple
valid interpretations in ambiguous cases. For example, a static image may
capture a person mid-motion with a frisbee, which can plausibly be interpreted
as either "throwing" or "catching". When only "catching" is annotated, the
other, though equally plausible for the image, is marked incorrect when exact
matching is used. As a result, correct predictions might be penalized,
affecting both VLMs and HOI-specific methods. To avoid penalizing valid
predictions, we introduce a new benchmark that reformulates HOI detection as a
multiple-answer multiple-choice task, where each question includes only
ground-truth positive options and a curated set of negatives that are
constructed to reduce ambiguity (e.g., when "catching" is annotated, "throwing"
is not selected as a negative to avoid penalizing valid predictions). The
proposed evaluation protocol is the first of its kind for both VLMs and HOI
methods, enabling direct comparison and offering new insight into the current
state of progress in HOI understanding.

</details>


### [36] [Beyond the Textual: Generating Coherent Visual Options for MCQs](https://arxiv.org/abs/2508.18772)
*Wanqiang Wang,Longzhu He,Wei Zheng*

Main category: cs.CV

TL;DR: CmOS框架通过多模态思维链和检索增强生成技术，生成具有视觉选项的教育选择题，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有研究忽视视觉选项和高质量干扰项生成的问题。

Method: 结合多模态思维链推理和检索增强生成技术，生成语义合理且视觉相似的答案和干扰项。

Result: 实验证明CmOS在内容筛选、问题生成和视觉选项生成上优于现有方法。

Conclusion: CmOS为教育选择题生成提供了高效且可扩展的解决方案。

Abstract: Multiple-choice questions (MCQs) play a crucial role in fostering deep
thinking and knowledge integration in education. However, previous research has
primarily focused on generating MCQs with textual options, but it largely
overlooks the visual options. Moreover, generating high-quality distractors
remains a major challenge due to the high cost and limited scalability of
manual authoring. To tackle these problems, we propose a Cross-modal Options
Synthesis (CmOS), a novel framework for generating educational MCQs with visual
options. Our framework integrates Multimodal Chain-of-Thought (MCoT) reasoning
process and Retrieval-Augmented Generation (RAG) to produce semantically
plausible and visually similar answer and distractors. It also includes a
discrimination module to identify content suitable for visual options.
Experimental results on test tasks demonstrate the superiority of CmOS in
content discrimination, question generation and visual option generation over
existing methods across various subjects and educational levels.

</details>


### [37] [Design, Implementation and Evaluation of a Real-Time Remote Photoplethysmography (rPPG) Acquisition System for Non-Invasive Vital Sign Monitoring](https://arxiv.org/abs/2508.18787)
*Constantino Álvarez Casado,Sasan Sharifipour,Manuel Lage Cañellas,Nhi Nguyen,Le Nguyen,Miguel Bordallo López*

Main category: cs.CV

TL;DR: 本文提出了一种针对低功耗设备优化的实时远程光电容积描记（rPPG）系统，用于从面部视频流中提取心率、呼吸频率和血氧饱和度等生理信号。


<details>
  <summary>Details</summary>
Motivation: 智能环境和低功耗计算设备的普及推动了远程非接触式生理监测的发展，但在资源受限平台上实时部署这些系统面临可扩展性、互操作性和性能的挑战。

Method: 系统基于Face2PPG流水线，采用多线程架构管理视频捕获、实时处理、网络通信和GUI更新，并结合功能反应式编程（FRP）和Actor模型实现高效任务并行化。

Result: 系统在30帧/秒下实现连续可靠运行，并通过自适应反馈优化信号捕获条件，同时网络接口支持视频流和按需生命体征检索。

Conclusion: 该研究解决了实时生物信号监测中的关键挑战，为现代医疗和人机交互应用提供了性能优化的实用解决方案。

Abstract: The growing integration of smart environments and low-power computing
devices, coupled with mass-market sensor technologies, is driving advancements
in remote and non-contact physiological monitoring. However, deploying these
systems in real-time on resource-constrained platforms introduces significant
challenges related to scalability, interoperability, and performance. This
paper presents a real-time remote photoplethysmography (rPPG) system optimized
for low-power devices, designed to extract physiological signals, such as heart
rate (HR), respiratory rate (RR), and oxygen saturation (SpO2), from facial
video streams. The system is built on the Face2PPG pipeline, which processes
video frames sequentially for rPPG signal extraction and analysis, while
leveraging a multithreaded architecture to manage video capture, real-time
processing, network communication, and graphical user interface (GUI) updates
concurrently. This design ensures continuous, reliable operation at 30 frames
per second (fps), with adaptive feedback through a collaborative user interface
to guide optimal signal capture conditions. The network interface includes both
an HTTP server for continuous video streaming and a RESTful API for on-demand
vital sign retrieval. To ensure accurate performance despite the limitations of
low-power devices, we use a hybrid programming model combining Functional
Reactive Programming (FRP) and the Actor Model, allowing event-driven
processing and efficient task parallelization. The system is evaluated under
real-time constraints, demonstrating robustness while minimizing computational
overhead. Our work addresses key challenges in real-time biosignal monitoring,
offering practical solutions for optimizing performance in modern healthcare
and human-computer interaction applications.

</details>


### [38] [Robust and Label-Efficient Deep Waste Detection](https://arxiv.org/abs/2508.18799)
*Hassan Abid,Khan Muhammad,Muhammad Haris Khan*

Main category: cs.CV

TL;DR: 论文提出了一种基于集成学习的半监督框架，用于提升AI驱动的废物检测性能，并在ZeroWaste数据集上建立了新的基准。


<details>
  <summary>Details</summary>
Motivation: 废物分类对可持续回收至关重要，但现有AI研究因数据集有限和依赖传统检测器而落后于商业系统。

Method: 通过基准测试OVOD模型，优化提示词，微调检测器，并提出软伪标签策略进行半监督训练。

Result: 在ZeroWaste-s子集上，伪标注性能超越全监督训练，达到51.6 mAP。

Conclusion: 研究为废物检测领域提供了新基准和高效标注方法，推动了AI在废物分类中的应用。

Abstract: Effective waste sorting is critical for sustainable recycling, yet AI
research in this domain continues to lag behind commercial systems due to
limited datasets and reliance on legacy object detectors. In this work, we
advance AI-driven waste detection by establishing strong baselines and
introducing an ensemble-based semi-supervised learning framework. We first
benchmark state-of-the-art Open-Vocabulary Object Detection (OVOD) models on
the real-world ZeroWaste dataset, demonstrating that while class-only prompts
perform poorly, LLM-optimized prompts significantly enhance zero-shot accuracy.
Next, to address domain-specific limitations, we fine-tune modern
transformer-based detectors, achieving a new baseline of 51.6 mAP. We then
propose a soft pseudo-labeling strategy that fuses ensemble predictions using
spatial and consensus-aware weighting, enabling robust semi-supervised
training. Applied to the unlabeled ZeroWaste-s subset, our pseudo-annotations
achieve performance gains that surpass fully supervised training, underscoring
the effectiveness of scalable annotation pipelines. Our work contributes to the
research community by establishing rigorous baselines, introducing a robust
ensemble-based pseudo-labeling pipeline, generating high-quality annotations
for the unlabeled ZeroWaste-s subset, and systematically evaluating OVOD models
under real-world waste sorting conditions. Our code is available at:
https://github.com/h-abid97/robust-waste-detection.

</details>


### [39] [Embedding Font Impression Word Tags Based on Co-occurrence](https://arxiv.org/abs/2508.18825)
*Yugo Kubota,Seiichi Uchida*

Main category: cs.CV

TL;DR: 提出了一种基于字体形状与印象标签关系的新型嵌入方法，用于字体生成和检索。


<details>
  <summary>Details</summary>
Motivation: 字体形状与印象标签之间存在紧密关系，但传统嵌入方法（如BERT和CLIP）无法有效捕捉这种关系。

Method: 构建印象标签的共现关系图，应用谱嵌入生成标签向量。

Result: 在印象引导的字体生成任务中，该方法优于BERT和CLIP。

Conclusion: 该方法能更准确地捕捉字体形状与印象标签的关系，适用于字体生成和检索。

Abstract: Different font styles (i.e., font shapes) convey distinct impressions,
indicating a close relationship between font shapes and word tags describing
those impressions. This paper proposes a novel embedding method for impression
tags that leverages these shape-impression relationships. For instance, our
method assigns similar vectors to impression tags that frequently co-occur in
order to represent impressions of fonts, whereas standard word embedding
methods (e.g., BERT and CLIP) yield very different vectors. This property is
particularly useful for impression-based font generation and font retrieval.
Technically, we construct a graph whose nodes represent impression tags and
whose edges encode co-occurrence relationships. Then, we apply spectral
embedding to obtain the impression vectors for each tag. We compare our method
with BERT and CLIP in qualitative and quantitative evaluations, demonstrating
that our approach performs better in impression-guided font generation.

</details>


### [40] [Deep Pre-trained Time Series Features for Tree Species Classification in the Dutch Forest Inventory](https://arxiv.org/abs/2508.18829)
*Takayuki Ishikawa,Carmelo Bonannella,Bas J. W. Lerink,Marc Rußwurm*

Main category: cs.CV

TL;DR: 该论文探讨了如何利用预训练的遥感基础模型和深度学习特征，显著提高荷兰国家森林清单（NFI）中树种分类的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统NFI更新依赖人工实地调查，耗时耗力。结合遥感和机器学习的方法可以更高效地更新NFI数据，但现有方法主要依赖随机森林分类器和手工设计的特征。

Method: 使用预训练的遥感时间序列基础模型，提取Sentinel-1、Sentinel-2、ERA5和SRTM卫星数据的时间序列特征，并通过微调模型进行树种分类。

Result: 实验结果表明，该方法在荷兰NFI分类任务中比现有方法准确率提高了10%，证明了深度学习特征的优越性。

Conclusion: 预训练模型和深度学习特征可以显著提升数据有限任务（如NFI分类）的准确性，为森林清单更新提供了高效补充手段。

Abstract: National Forest Inventory (NFI)s serve as the primary source of forest
information, providing crucial tree species distribution data. However,
maintaining these inventories requires labor-intensive on-site campaigns.
Remote sensing approaches, particularly when combined with machine learning,
offer opportunities to update NFIs more frequently and at larger scales. While
the use of Satellite Image Time Series has proven effective for distinguishing
tree species through seasonal canopy reflectance patterns, current approaches
rely primarily on Random Forest classifiers with hand-designed features and
phenology-based metrics. Using deep features from an available pre-trained
remote sensing foundation models offers a complementary strategy. These
pre-trained models leverage unannotated global data and are meant to used for
general-purpose applications and can then be efficiently fine-tuned with
smaller labeled datasets for specific classification tasks. This work
systematically investigates how deep features improve tree species
classification accuracy in the Netherlands with few annotated data. Data-wise,
we extracted time-series data from Sentinel-1, Sentinel-2 and ERA5 satellites
data and SRTM data using Google Earth Engine. Our results demonstrate that
fine-tuning a publicly available remote sensing time series foundation model
outperforms the current state-of-the-art in NFI classification in the
Netherlands by a large margin of up to 10% across all datasets. This
demonstrates that classic hand-defined harmonic features are too simple for
this task and highlights the potential of using deep AI features for
data-limited application like NFI classification. By leveraging openly
available satellite data and pre-trained models, this approach significantly
improves classification accuracy compared to traditional methods and can
effectively complement existing forest inventory processes.

</details>


### [41] [Automated Classification of Normal and Atypical Mitotic Figures Using ConvNeXt V2: MIDOG 2025 Track 2](https://arxiv.org/abs/2508.18831)
*Yosuke Yamagishi,Shouhei Hanaoka*

Main category: cs.CV

TL;DR: 本文提出了一种基于ConvNeXt V2模型的解决方案，用于MIDOG 2025挑战赛中的正常与异常有丝分裂图像分类任务。


<details>
  <summary>Details</summary>
Motivation: 解决组织病理学图像中正常与异常有丝分裂分类的挑战，包括类别不平衡、形态多样性和领域异质性。

Method: 采用ConvNeXt V2基础模型，结合中心裁剪预处理和5折交叉验证集成策略。

Result: 模型在MIDOG 2025数据集上表现出色，证明了现代卷积架构的有效性。

Conclusion: 通过精心设计的架构和训练优化，该方法在保持计算效率的同时，成功解决了有丝分裂子类型分类问题。

Abstract: This paper presents our solution for the MIDOG 2025 Challenge Track 2, which
focuses on binary classification of normal mitotic figures (NMFs) versus
atypical mitotic figures (AMFs) in histopathological images. Our approach
leverages a ConvNeXt V2 base model with center cropping preprocessing and
5-fold cross-validation ensemble strategy. The method addresses key challenges
including severe class imbalance, high morphological variability, and domain
heterogeneity across different tumor types, species, and scanners. Through
strategic preprocessing with 60% center cropping and mixed precision training,
our model achieved robust performance on the diverse MIDOG 2025 dataset. The
solution demonstrates the effectiveness of modern convolutional architectures
for mitotic figure subtyping while maintaining computational efficiency through
careful architectural choices and training optimizations.

</details>


### [42] [Boosting Micro-Expression Analysis via Prior-Guided Video-Level Regression](https://arxiv.org/abs/2508.18834)
*Zizheng Guo,Bochao Zou,Yinuo Jia,Xiangyu Li,Huimin Ma*

Main category: cs.CV

TL;DR: 提出了一种基于先验引导的视频级回归方法，用于微表情分析，通过可扩展的区间选择策略和协同优化框架，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖固定窗口大小和硬决策，难以捕捉微表情的复杂时间动态，部分方法虽采用视频级回归，但区间解码仍依赖手动预定义窗口。

Method: 引入可扩展的区间选择策略，综合考虑微表情的时间演化、持续时间和类别分布特征，并提出协同优化框架，共享参数以提升效率。

Result: 在多个基准数据集上表现优异，CAS(ME)$^3$上的STRS为0.0562，SAMMLV上为0.2000。

Conclusion: 该方法通过结合先验知识和协同优化，显著提升了微表情分析的性能，代码已开源。

Abstract: Micro-expressions (MEs) are involuntary, low-intensity, and short-duration
facial expressions that often reveal an individual's genuine thoughts and
emotions. Most existing ME analysis methods rely on window-level classification
with fixed window sizes and hard decisions, which limits their ability to
capture the complex temporal dynamics of MEs. Although recent approaches have
adopted video-level regression frameworks to address some of these challenges,
interval decoding still depends on manually predefined, window-based methods,
leaving the issue only partially mitigated. In this paper, we propose a
prior-guided video-level regression method for ME analysis. We introduce a
scalable interval selection strategy that comprehensively considers the
temporal evolution, duration, and class distribution characteristics of MEs,
enabling precise spotting of the onset, apex, and offset phases. In addition,
we introduce a synergistic optimization framework, in which the spotting and
recognition tasks share parameters except for the classification heads. This
fully exploits complementary information, makes more efficient use of limited
data, and enhances the model's capability. Extensive experiments on multiple
benchmark datasets demonstrate the state-of-the-art performance of our method,
with an STRS of 0.0562 on CAS(ME)$^3$ and 0.2000 on SAMMLV. The code is
available at https://github.com/zizheng-guo/BoostingVRME.

</details>


### [43] [Quantitative Outcome-Oriented Assessment of Microsurgical Anastomosis](https://arxiv.org/abs/2508.18836)
*Luyin Hu,Soheil Gholami,George Dindelegan,Torstein R. Meling,Aude Billard*

Main category: cs.CV

TL;DR: 提出了一种基于图像处理的定量评估框架，用于客观评估显微外科吻合术，提高了评估的效率和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有的显微外科吻合术评估方法依赖主观判断，可能引入偏差，影响评估的可靠性和效率。

Method: 利用三个医院数据集，采用图像处理技术和几何建模错误的方法，结合检测和评分机制。

Result: 几何指标能有效复现专家评分，验证了方法的有效性。

Conclusion: 该框架为显微外科培训提供了更高效、可靠的评估工具。

Abstract: Microsurgical anastomosis demands exceptional dexterity and visuospatial
skills, underscoring the importance of comprehensive training and precise
outcome assessment. Currently, methods such as the outcome-oriented anastomosis
lapse index are used to evaluate this procedure. However, they often rely on
subjective judgment, which can introduce biases that affect the reliability and
efficiency of the assessment of competence. Leveraging three datasets from
hospitals with participants at various levels, we introduce a quantitative
framework that uses image-processing techniques for objective assessment of
microsurgical anastomoses. The approach uses geometric modeling of errors along
with a detection and scoring mechanism, enhancing the efficiency and
reliability of microsurgical proficiency assessment and advancing training
protocols. The results show that the geometric metrics effectively replicate
expert raters' scoring for the errors considered in this work.

</details>


### [44] [Harnessing Meta-Learning for Controllable Full-Frame Video Stabilization](https://arxiv.org/abs/2508.18859)
*Muhammad Kashif Ali,Eun Woo Im,Dongjin Kim,Tae Hyun Kim,Vivek Gupta,Haonan Luo,Tianrui Li*

Main category: cs.CV

TL;DR: 提出了一种快速适应输入视频的像素级合成视频稳定方法，通过低层次视觉线索和针对性适应策略提升稳定性和视觉质量。


<details>
  <summary>Details</summary>
Motivation: 解决像素级合成视频稳定方法因固定参数难以适应多样化运动和视觉内容的问题。

Method: 利用低层次视觉线索快速适应输入视频，引入抖动定位模块和针对性适应策略。

Result: 在多样化的真实数据集上显著提升性能，包括下游应用。

Conclusion: 该方法克服了现有方法的局限性，同时保持了现代方法的全帧特性，并提供类似经典方法的控制机制。

Abstract: Video stabilization remains a fundamental problem in computer vision,
particularly pixel-level synthesis solutions for video stabilization, which
synthesize full-frame outputs, add to the complexity of this task. These
methods aim to enhance stability while synthesizing full-frame videos, but the
inherent diversity in motion profiles and visual content present in each video
sequence makes robust generalization with fixed parameters difficult. To
address this, we present a novel method that improves pixel-level synthesis
video stabilization methods by rapidly adapting models to each input video at
test time. The proposed approach takes advantage of low-level visual cues
available during inference to improve both the stability and visual quality of
the output. Notably, the proposed rapid adaptation achieves significant
performance gains even with a single adaptation pass. We further propose a jerk
localization module and a targeted adaptation strategy, which focuses the
adaptation on high-jerk segments for maximizing stability with fewer adaptation
steps. The proposed methodology enables modern stabilizers to overcome the
longstanding SOTA approaches while maintaining the full frame nature of the
modern methods, while offering users with control mechanisms akin to classical
approaches. Extensive experiments on diverse real-world datasets demonstrate
the versatility of the proposed method. Our approach consistently improves the
performance of various full-frame synthesis models in both qualitative and
quantitative terms, including results on downstream applications.

</details>


### [45] [Toward Robust Medical Fairness: Debiased Dual-Modal Alignment via Text-Guided Attribute-Disentangled Prompt Learning for Vision-Language Models](https://arxiv.org/abs/2508.18886)
*Yuexuan Xia,Benteng Ma,Jiang He,Zhiyong Wang,Qi Dou,Yong Xia*

Main category: cs.CV

TL;DR: DualFairVL是一种多模态提示学习框架，通过联合去偏和对齐跨模态表示，提升医疗诊断中的公平性和准确性。


<details>
  <summary>Details</summary>
Motivation: 医疗诊断中确保跨人口群体的公平性至关重要，尤其是在成像设备和临床实践变化导致的分布偏移下。现有方法独立处理视觉和文本模态，导致跨模态未对齐和公平性差距。

Method: DualFairVL采用并行双分支架构，分离敏感和目标属性，构建近似正交的文本锚点，并通过超网络生成实例感知的视觉提示。

Result: 在八个医疗影像数据集上的实验表明，DualFairVL在分布内和分布外设置下均实现了最先进的公平性和准确性，仅需3.6M可训练参数。

Conclusion: DualFairVL通过多模态联合去偏和对齐，显著提升了医疗诊断的公平性和鲁棒性，优于现有方法。

Abstract: Ensuring fairness across demographic groups in medical diagnosis is essential
for equitable healthcare, particularly under distribution shifts caused by
variations in imaging equipment and clinical practice. Vision-language models
(VLMs) exhibit strong generalization, and text prompts encode identity
attributes, enabling explicit identification and removal of sensitive
directions. However, existing debiasing approaches typically address vision and
text modalities independently, leaving residual cross-modal misalignment and
fairness gaps. To address this challenge, we propose DualFairVL, a multimodal
prompt-learning framework that jointly debiases and aligns cross-modal
representations. DualFairVL employs a parallel dual-branch architecture that
separates sensitive and target attributes, enabling disentangled yet aligned
representations across modalities. Approximately orthogonal text anchors are
constructed via linear projections, guiding cross-attention mechanisms to
produce fused features. A hypernetwork further disentangles attribute-related
information and generates instance-aware visual prompts, which encode
dual-modal cues for fairness and robustness. Prototype-based regularization is
applied in the visual branch to enforce separation of sensitive features and
strengthen alignment with textual anchors. Extensive experiments on eight
medical imaging datasets across four modalities show that DualFairVL achieves
state-of-the-art fairness and accuracy under both in- and out-of-distribution
settings, outperforming full fine-tuning and parameter-efficient baselines with
only 3.6M trainable parameters. Code will be released upon publication.

</details>


### [46] [DQEN: Dual Query Enhancement Network for DETR-based HOI Detection](https://arxiv.org/abs/2508.18896)
*Zhehao Li,Chong Wang,Yi Chen,Yinghao Lu,Jiangbo Qian,Jiong Wang,Jiafei Wu*

Main category: cs.CV

TL;DR: 论文提出了一种双查询增强网络（DQEN），通过增强对象和交互查询，提升了HOI检测的性能。


<details>
  <summary>Details</summary>
Motivation: 现有DETR-based HOI模型依赖随机初始化的查询，导致表示模糊，限制了模型效果。

Method: 设计了对象感知编码器特征增强对象查询，以及交互语义融合模块增强交互查询，并引入辅助预测单元。

Result: 在HICO-Det和V-COCO数据集上取得了竞争性性能。

Conclusion: DQEN通过增强查询表示，显著提升了HOI检测的准确性和理解能力。

Abstract: Human-Object Interaction (HOI) detection focuses on localizing human-object
pairs and recognizing their interactions. Recently, the DETR-based framework
has been widely adopted in HOI detection. In DETR-based HOI models, queries
with clear meaning are crucial for accurately detecting HOIs. However, prior
works have typically relied on randomly initialized queries, leading to vague
representations that limit the model's effectiveness. Meanwhile, humans in the
HOI categories are fixed, while objects and their interactions are variable.
Therefore, we propose a Dual Query Enhancement Network (DQEN) to enhance object
and interaction queries. Specifically, object queries are enhanced with
object-aware encoder features, enabling the model to focus more effectively on
humans interacting with objects in an object-aware way. On the other hand, we
design a novel Interaction Semantic Fusion module to exploit the HOI candidates
that are promoted by the CLIP model. Semantic features are extracted to enhance
the initialization of interaction queries, thereby improving the model's
ability to understand interactions. Furthermore, we introduce an Auxiliary
Prediction Unit aimed at improving the representation of interaction features.
Our proposed method achieves competitive performance on both the HICO-Det and
the V-COCO datasets. The source code is available at
https://github.com/lzzhhh1019/DQEN.

</details>


### [47] [Event-Enriched Image Analysis Grand Challenge at ACM Multimedia 2025](https://arxiv.org/abs/2508.18904)
*Thien-Phuc Tran,Minh-Quang Nguyen,Minh-Triet Tran,Tam V. Nguyen,Trong-Le Do,Duy-Nam Ly,Viet-Tham Huynh,Khanh-Duy Le,Mai-Khiem Tran,Trung-Nghia Le*

Main category: cs.CV

TL;DR: EVENTA Grand Challenge是首个专注于事件级多模态理解的大规模基准测试，旨在弥补传统任务在上下文和语义维度上的不足。


<details>
  <summary>Details</summary>
Motivation: 传统图像描述和检索任务往往忽略事件的上下文和语义信息，EVENTA通过整合这些信息来捕捉图像背后的完整事件。

Method: 基于OpenEvents V1数据集，挑战分为两个赛道：事件增强的图像检索与描述，以及基于事件的图像检索。

Result: 45支团队参与，通过公开和私有测试阶段评估，前三名团队在ACM Multimedia 2025上展示解决方案。

Conclusion: EVENTA为上下文感知、叙事驱动的多媒体AI奠定了基础，适用于新闻、媒体分析等领域。

Abstract: The Event-Enriched Image Analysis (EVENTA) Grand Challenge, hosted at ACM
Multimedia 2025, introduces the first large-scale benchmark for event-level
multimodal understanding. Traditional captioning and retrieval tasks largely
focus on surface-level recognition of people, objects, and scenes, often
overlooking the contextual and semantic dimensions that define real-world
events. EVENTA addresses this gap by integrating contextual, temporal, and
semantic information to capture the who, when, where, what, and why behind an
image. Built upon the OpenEvents V1 dataset, the challenge features two tracks:
Event-Enriched Image Retrieval and Captioning, and Event-Based Image Retrieval.
A total of 45 teams from six countries participated, with evaluation conducted
through Public and Private Test phases to ensure fairness and reproducibility.
The top three teams were invited to present their solutions at ACM Multimedia
2025. EVENTA establishes a foundation for context-aware, narrative-driven
multimedia AI, with applications in journalism, media analysis, cultural
archiving, and accessibility. Further details about the challenge are available
at the official homepage: https://ltnghia.github.io/eventa/eventa-2025.

</details>


### [48] [Preliminary Study on Space Utilization and Emergent Behaviors of Group vs. Single Pedestrians in Real-World Trajectories](https://arxiv.org/abs/2508.18939)
*Amartaivan Sanjjamts,Morita Hiroshi*

Main category: cs.CV

TL;DR: 提出了一种基于Transformer的框架，用于区分群体和单个行人的轨迹数据，并分析其空间利用和行为模式的差异。


<details>
  <summary>Details</summary>
Motivation: 研究群体和单个行人在空间利用和行为模式上的差异，为行人模拟和空间设计验证提供基础。

Method: 通过固定时间分段和Transformer模型分类行人轨迹，结合空间和行为指标进行分析。

Result: 建立了包含空间和行为维度的综合指标框架，并提出了三种交互类型的分类。

Conclusion: 为未来行人动态研究中的定量分析和模拟验证奠定了基础。

Abstract: This study presents an initial framework for distinguishing group and single
pedestrians based on real-world trajectory data, with the aim of analyzing
their differences in space utilization and emergent behavioral patterns. By
segmenting pedestrian trajectories into fixed time bins and applying a
Transformer-based pair classification model, we identify cohesive groups and
isolate single pedestrians over a structured sequence-based filtering process.
To prepare for deeper analysis, we establish a comprehensive metric framework
incorporating both spatial and behavioral dimensions. Spatial utilization
metrics include convex hull area, smallest enclosing circle radius, and
heatmap-based spatial densities to characterize how different pedestrian types
occupy and interact with space. Behavioral metrics such as velocity change,
motion angle deviation, clearance radius, and trajectory straightness are
designed to capture local adaptations and responses during interactions.
Furthermore, we introduce a typology of encounter types-single-to-single,
single-to-group, and group-to-group to categorize and later quantify different
interaction scenarios. Although this version focuses primarily on the
classification pipeline and dataset structuring, it establishes the groundwork
for scalable analysis across different sequence lengths 60, 100, and 200
frames. Future versions will incorporate complete quantitative analysis of the
proposed metrics and their implications for pedestrian simulation and space
design validation in crowd dynamics research.

</details>


### [49] [The point is the mask: scaling coral reef segmentation with weak supervision](https://arxiv.org/abs/2508.18958)
*Matteo Contini,Victor Illien,Sylvain Poulain,Serge Bernard,Julien Barde,Sylvain Bonhommeau,Alexis Joly*

Main category: cs.CV

TL;DR: 提出了一种多尺度弱监督语义分割框架，用于从无人机图像中大规模监测珊瑚礁，减少人工标注需求。


<details>
  <summary>Details</summary>
Motivation: 解决无人机图像分辨率不足和人工标注成本高的问题，以实现大规模珊瑚礁监测。

Method: 结合分类监督、空间插值和自蒸馏技术，将水下图像的细尺度信息迁移到无人机图像。

Result: 实现了珊瑚形态的大范围分割，并展示了新类别的灵活性。

Conclusion: 该方法为高分辨率珊瑚礁监测提供了一种可扩展且经济高效的解决方案。

Abstract: Monitoring coral reefs at large spatial scales remains an open challenge,
essential for assessing ecosystem health and informing conservation efforts.
While drone-based aerial imagery offers broad spatial coverage, its limited
resolution makes it difficult to reliably distinguish fine-scale classes, such
as coral morphotypes. At the same time, obtaining pixel-level annotations over
large spatial extents is costly and labor-intensive, limiting the scalability
of deep learning-based segmentation methods for aerial imagery. We present a
multi-scale weakly supervised semantic segmentation framework that addresses
this challenge by transferring fine-scale ecological information from
underwater imagery to aerial data. Our method enables large-scale coral reef
mapping from drone imagery with minimal manual annotation, combining
classification-based supervision, spatial interpolation and self-distillation
techniques. We demonstrate the efficacy of the approach, enabling large-area
segmentation of coral morphotypes and demonstrating flexibility for integrating
new classes. This study presents a scalable, cost-effective methodology for
high-resolution reef monitoring, combining low-cost data collection, weakly
supervised deep learning and multi-scale remote sensing.

</details>


### [50] [Generative AI in Map-Making: A Technical Exploration and Its Implications for Cartographers](https://arxiv.org/abs/2508.18959)
*Claudio Affolter,Sidi Wu,Yizi Chen,Lorenz Hurni*

Main category: cs.CV

TL;DR: 利用生成式AI和矢量数据指导地图生成，首次实现可控风格的地图生成，并通过用户研究验证其潜力。


<details>
  <summary>Details</summary>
Motivation: 传统地图制作依赖GIS，耗时且需专业知识，生成式AI为自动化和民主化地图制作提供新机会。

Method: 整合矢量数据，通过文本提示指导地图生成，开发网页应用提升可用性。

Result: 用户研究表明，生成的地图保真度高，应用易用性强，GenAI在提升地图制作效率方面潜力显著。

Conclusion: 研究展示了GenAI在地图制作中的潜力，并提出了进一步技术改进和制图师新角色的方向。

Abstract: Traditional map-making relies heavily on Geographic Information Systems
(GIS), requiring domain expertise and being time-consuming, especially for
repetitive tasks. Recent advances in generative AI (GenAI), particularly image
diffusion models, offer new opportunities for automating and democratizing the
map-making process. However, these models struggle with accurate map creation
due to limited control over spatial composition and semantic layout. To address
this, we integrate vector data to guide map generation in different styles,
specified by the textual prompts. Our model is the first to generate accurate
maps in controlled styles, and we have integrated it into a web application to
improve its usability and accessibility. We conducted a user study with
professional cartographers to assess the fidelity of generated maps, the
usability of the web application, and the implications of ever-emerging GenAI
in map-making. The findings have suggested the potential of our developed
application and, more generally, the GenAI models in helping both non-expert
users and professionals in creating maps more efficiently. We have also
outlined further technical improvements and emphasized the new role of
cartographers to advance the paradigm of AI-assisted map-making.

</details>


### [51] [Enhancing compact convolutional transformers with super attention](https://arxiv.org/abs/2508.18960)
*Simpenzwe Honore Leandre,Natenaile Asmamaw Shiferaw,Dillip Rout*

Main category: cs.CV

TL;DR: 提出了一种结合token混合、序列池化和卷积tokenizer的视觉模型，在固定上下文长度任务中实现了高效推理和SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统SDPA transformers在固定上下文长度任务中效率不足的问题，同时提升性能。

Method: 采用token混合、序列池化和卷积tokenizer的架构设计。

Result: 在CIFAR100基准测试中，top 1%和top 5%验证准确率分别从36.50%提升至46.29%和66.33%提升至76.31%，且模型更高效。

Conclusion: 该模型在性能和效率上均优于传统方法，且训练稳定性高，无需依赖数据增强等技术。

Abstract: In this paper, we propose a vision model that adopts token mixing,
sequence-pooling, and convolutional tokenizers to achieve state-of-the-art
performance and efficient inference in fixed context-length tasks. In the
CIFAR100 benchmark, our model significantly improves the baseline of the top 1%
and top 5% validation accuracy from 36.50% to 46.29% and 66.33% to 76.31%,
while being more efficient than the Scaled Dot Product Attention (SDPA)
transformers when the context length is less than the embedding dimension and
only 60% the size. In addition, the architecture demonstrates high training
stability and does not rely on techniques such as data augmentation like mixup,
positional embeddings, or learning rate scheduling. We make our code available
on Github.

</details>


### [52] [USO: Unified Style and Subject-Driven Generation via Disentangled and Reward Learning](https://arxiv.org/abs/2508.18966)
*Shaojin Wu,Mengqi Huang,Yufeng Cheng,Wenxu Wu,Jiahe Tian,Yiming Luo,Fei Ding,Qian He*

Main category: cs.CV

TL;DR: USO是一个统一风格与主题优化的定制化模型，通过解耦和重组内容与风格，同时实现风格相似性和主题一致性。


<details>
  <summary>Details</summary>
Motivation: 现有研究将风格驱动和主题驱动生成视为两个独立任务，导致目标冲突。USO旨在统一这两个目标。

Method: 构建大规模三元组数据集，引入解耦学习方案（风格对齐训练和内容-风格解耦训练），并采用风格奖励学习范式（SRL）。

Result: USO在开源模型中实现了主题一致性和风格相似性的最先进性能。

Conclusion: USO通过统一框架解决了风格与主题的冲突，并发布了首个联合评估基准USO-Bench。

Abstract: Existing literature typically treats style-driven and subject-driven
generation as two disjoint tasks: the former prioritizes stylistic similarity,
whereas the latter insists on subject consistency, resulting in an apparent
antagonism. We argue that both objectives can be unified under a single
framework because they ultimately concern the disentanglement and
re-composition of content and style, a long-standing theme in style-driven
research. To this end, we present USO, a Unified Style-Subject Optimized
customization model. First, we construct a large-scale triplet dataset
consisting of content images, style images, and their corresponding stylized
content images. Second, we introduce a disentangled learning scheme that
simultaneously aligns style features and disentangles content from style
through two complementary objectives, style-alignment training and
content-style disentanglement training. Third, we incorporate a style
reward-learning paradigm denoted as SRL to further enhance the model's
performance. Finally, we release USO-Bench, the first benchmark that jointly
evaluates style similarity and subject fidelity across multiple metrics.
Extensive experiments demonstrate that USO achieves state-of-the-art
performance among open-source models along both dimensions of subject
consistency and style similarity. Code and model:
https://github.com/bytedance/USO

</details>


### [53] [Can we make NeRF-based visual localization privacy-preserving?](https://arxiv.org/abs/2508.18971)
*Maxime Pietrantoni,Martin Humenberger,Torsten Sattler,Gabriela Csurka*

Main category: cs.CV

TL;DR: 论文提出了一种评估NeRF隐私保护的新协议，并开发了ppNeSF，一种基于分割监督的隐私保护NeRF变体，用于视觉定位。


<details>
  <summary>Details</summary>
Motivation: NeRF在视觉定位中广泛应用，但其编码的精细场景细节可能泄露隐私信息，需要解决这一问题。

Method: 提出评估NeRF隐私保护的协议，并开发ppNeSF，通过自监督分割标签训练，避免存储敏感细节。

Result: ppNeSF在保护隐私的同时，实现了高精度的视觉定位，性能达到最先进水平。

Conclusion: ppNeSF是一种有效的隐私保护视觉定位方法，解决了NeRF的隐私泄露问题。

Abstract: Visual localization (VL) is the task of estimating the camera pose in a known
scene. VL methods, a.o., can be distinguished based on how they represent the
scene, e.g., explicitly through a (sparse) point cloud or a collection of
images or implicitly through the weights of a neural network. Recently,
NeRF-based methods have become popular for VL. While NeRFs offer high-quality
novel view synthesis, they inadvertently encode fine scene details, raising
privacy concerns when deployed in cloud-based localization services as
sensitive information could be recovered. In this paper, we tackle this
challenge on two ends. We first propose a new protocol to assess
privacy-preservation of NeRF-based representations. We show that NeRFs trained
with photometric losses store fine-grained details in their geometry
representations, making them vulnerable to privacy attacks, even if the head
that predicts colors is removed. Second, we propose ppNeSF (Privacy-Preserving
Neural Segmentation Field), a NeRF variant trained with segmentation
supervision instead of RGB images. These segmentation labels are learned in a
self-supervised manner, ensuring they are coarse enough to obscure identifiable
scene details while remaining discriminativeness in 3D. The segmentation space
of ppNeSF can be used for accurate visual localization, yielding
state-of-the-art results.

</details>


### [54] [Enhancing Document VQA Models via Retrieval-Augmented Generation](https://arxiv.org/abs/2508.18984)
*Eric López,Artemis Llabrés,Ernest Valveny*

Main category: cs.CV

TL;DR: RAG方法在Document VQA中显著提升性能，文本检索和视觉检索分别带来22.5和5.0 ANLS的改进。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理多页文档时内存消耗大，RAG提供了一种高效替代方案。

Method: 通过文本检索（OCR）和视觉检索两种变体，结合检索和重排序组件。

Result: 文本检索改进22.5 ANLS，视觉检索改进5.0 ANLS，布局分块策略无效。

Conclusion: RAG在多页文档VQA中具有实际价值，证据选择是关键。

Abstract: Document Visual Question Answering (Document VQA) must cope with documents
that span dozens of pages, yet leading systems still concatenate every page or
rely on very large vision-language models, both of which are memory-hungry.
Retrieval-Augmented Generation (RAG) offers an attractive alternative, first
retrieving a concise set of relevant segments before generating answers from
this selected evidence. In this paper, we systematically evaluate the impact of
incorporating RAG into Document VQA through different retrieval variants -
text-based retrieval using OCR tokens and purely visual retrieval without OCR -
across multiple models and benchmarks. Evaluated on the multi-page datasets
MP-DocVQA, DUDE, and InfographicVQA, the text-centric variant improves the
"concatenate-all-pages" baseline by up to +22.5 ANLS, while the visual variant
achieves +5.0 ANLS improvement without requiring any text extraction. An
ablation confirms that retrieval and reranking components drive most of the
gain, whereas the layout-guided chunking strategy - proposed in several recent
works to leverage page structure - fails to help on these datasets. Our
experiments demonstrate that careful evidence selection consistently boosts
accuracy across multiple model sizes and multi-page benchmarks, underscoring
its practical value for real-world Document VQA.

</details>


### [55] [Ask Me Again Differently: GRAS for Measuring Bias in Vision Language Models on Gender, Race, Age, and Skin Tone](https://arxiv.org/abs/2508.18989)
*Shaivi Malik,Hasnat Md Abdullah,Sriparna Saha,Amit Sheth*

Main category: cs.CV

TL;DR: GRAS是一个用于评估视觉语言模型（VLMs）在性别、种族、年龄和肤色等人口统计特征上偏见的基准，并提出可解释的GRAS Bias Score。


<details>
  <summary>Details</summary>
Motivation: 随着VLMs在现实应用中的普及，理解其人口统计偏见变得至关重要。

Method: 提出GRAS基准和GRAS Bias Score，评估五种先进VLMs的偏见水平，并强调视觉问答（VQA）中多问题表述的重要性。

Result: 最不偏见的模型GRAS Bias Score仅为2/100，显示VLMs存在显著偏见。

Conclusion: GRAS为评估和量化VLMs偏见提供了工具，并揭示了VQA评估中多问题表述的必要性。

Abstract: As Vision Language Models (VLMs) become integral to real-world applications,
understanding their demographic biases is critical. We introduce GRAS, a
benchmark for uncovering demographic biases in VLMs across gender, race, age,
and skin tone, offering the most diverse coverage to date. We further propose
the GRAS Bias Score, an interpretable metric for quantifying bias. We benchmark
five state-of-the-art VLMs and reveal concerning bias levels, with the least
biased model attaining a GRAS Bias Score of only 2 out of 100. Our findings
also reveal a methodological insight: evaluating bias in VLMs with visual
question answering (VQA) requires considering multiple formulations of a
question. Our code, data, and evaluation results are publicly available.

</details>


### [56] [RoofSeg: An edge-aware transformer-based network for end-to-end roof plane segmentation](https://arxiv.org/abs/2508.19003)
*Siyuan You,Guozheng Xu,Pengwei Zhou,Qiwen Jin,Jian Yao,Li Li*

Main category: cs.CV

TL;DR: RoofSeg是一种基于Transformer的端到端网络，用于从LiDAR点云中分割屋顶平面，通过边缘感知模块和几何损失提升分割精度。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的屋顶平面分割方法存在三个问题：非端到端、边缘特征区分度低、几何约束不足。

Method: 提出RoofSeg网络，结合Transformer编码器-解码器框架、边缘感知掩码模块（EAMM）、自适应加权策略和平面几何损失。

Result: RoofSeg实现了端到端的屋顶平面分割，并提升了边缘区域的精度。

Conclusion: RoofSeg通过结合几何先验和Transformer框架，有效解决了现有方法的不足。

Abstract: Roof plane segmentation is one of the key procedures for reconstructing
three-dimensional (3D) building models at levels of detail (LoD) 2 and 3 from
airborne light detection and ranging (LiDAR) point clouds. The majority of
current approaches for roof plane segmentation rely on the manually designed or
learned features followed by some specifically designed geometric clustering
strategies. Because the learned features are more powerful than the manually
designed features, the deep learning-based approaches usually perform better
than the traditional approaches. However, the current deep learning-based
approaches have three unsolved problems. The first is that most of them are not
truly end-to-end, the plane segmentation results may be not optimal. The second
is that the point feature discriminability near the edges is relatively low,
leading to inaccurate planar edges. The third is that the planar geometric
characteristics are not sufficiently considered to constrain the network
training. To solve these issues, a novel edge-aware transformer-based network,
named RoofSeg, is developed for segmenting roof planes from LiDAR point clouds
in a truly end-to-end manner. In the RoofSeg, we leverage a transformer
encoder-decoder-based framework to hierarchically predict the plane instance
masks with the use of a set of learnable plane queries. To further improve the
segmentation accuracy of edge regions, we also design an Edge-Aware Mask Module
(EAMM) that sufficiently incorporates planar geometric prior of edges to
enhance its discriminability for plane instance mask refinement. In addition,
we propose an adaptive weighting strategy in the mask loss to reduce the
influence of misclassified points, and also propose a new plane geometric loss
to constrain the network training.

</details>


### [57] [MicroDetect-Net (MDN): Leveraging Deep Learning to Detect Microplastics in Clam Blood, a Step Towards Human Blood Analysis](https://arxiv.org/abs/2508.19021)
*Riju Marwah,Riya Arora,Navneet Yadav,Himank Arora*

Main category: cs.CV

TL;DR: MicroDetect-Net (MDN) 是一种结合荧光显微镜、尼罗红染色和深度学习的新模型，用于检测血液样本中的微塑料，准确率达92%。


<details>
  <summary>Details</summary>
Motivation: 微塑料污染日益严重，对人体健康造成潜在危害，需要高效检测方法。

Method: 使用尼罗红染色荧光显微镜和卷积神经网络（CNN）进行图像分割和微塑料定位计数。

Result: MDN在276张荧光血液图像上表现优异，准确率92%，IoU为87.4%，F1分数92.1%。

Conclusion: MDN在微塑料检测中表现出高效性和准确性，为未来应用于人体样本提供了可能。

Abstract: With the prevalence of plastics exceeding 368 million tons yearly,
microplastic pollution has grown to an extent where air, water, soil, and
living organisms have all tested positive for microplastic presence. These
particles, which are smaller than 5 millimeters in size, are no less harmful to
humans than to the environment. Toxicity research on microplastics has shown
that exposure may cause liver infection, intestinal injuries, and gut flora
imbalance, leading to numerous potential health hazards. This paper presents a
new model, MicroDetect-Net (MDN), which applies fluorescence microscopy with
Nile Red dye staining and deep learning to scan blood samples for
microplastics. Although clam blood has certain limitations in replicating real
human blood, this study opens avenues for applying the approach to human
samples, which are more consistent for preliminary data collection. The MDN
model integrates dataset preparation, fluorescence imaging, and segmentation
using a convolutional neural network to localize and count microplastic
fragments. The combination of convolutional networks and Nile Red dye for
segmentation produced strong image detection and accuracy. MDN was evaluated on
a dataset of 276 Nile Red-stained fluorescent blood images and achieved an
accuracy of ninety two percent. Robust performance was observed with an
Intersection over Union of 87.4 percent, F1 score of 92.1 percent, Precision of
90.6 percent, and Recall of 93.7 percent. These metrics demonstrate the
effectiveness of MDN in the detection of microplastics.

</details>


### [58] [ProPy: Building Interactive Prompt Pyramids upon CLIP for Partially Relevant Video Retrieval](https://arxiv.org/abs/2508.19024)
*Yi Pan,Yujia Zhang,Michael Kampffmeyer,Xiaoguang Zhao*

Main category: cs.CV

TL;DR: ProPy是一种基于CLIP的模型，通过多粒度事件语义和动态交互机制，显著提升了部分相关视频检索的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要处理单模态特征，而强大的预训练视觉语言模型（如CLIP）在部分相关视频检索（PRVR）领域尚未充分探索。

Method: ProPy引入两个关键创新：1）提示金字塔结构，组织多粒度事件提示；2）祖先-后代交互机制，实现事件间的动态语义交互。

Result: ProPy在三个公共数据集上达到SOTA性能，显著优于先前模型。

Conclusion: ProPy通过系统化适配CLIP，为PRVR任务提供了高效解决方案，并展示了多粒度语义和动态交互的重要性。

Abstract: Partially Relevant Video Retrieval (PRVR) is a practical yet challenging task
that involves retrieving videos based on queries relevant to only specific
segments. While existing works follow the paradigm of developing models to
process unimodal features, powerful pretrained vision-language models like CLIP
remain underexplored in this field. To bridge this gap, we propose ProPy, a
model with systematic architectural adaption of CLIP specifically designed for
PRVR. Drawing insights from the semantic relevance of multi-granularity events,
ProPy introduces two key innovations: (1) A Prompt Pyramid structure that
organizes event prompts to capture semantics at multiple granularity levels,
and (2) An Ancestor-Descendant Interaction Mechanism built on the pyramid that
enables dynamic semantic interaction among events. With these designs, ProPy
achieves SOTA performance on three public datasets, outperforming previous
models by significant margins. Code is available at
https://github.com/BUAAPY/ProPy.

</details>


### [59] [GReAT: leveraging geometric artery data to improve wall shear stress assessment](https://arxiv.org/abs/2508.19030)
*Julian Suk,Jolanda J. Wentzel,Patryk Rygiel,Joost Daemen,Daniel Rueckert,Jelmer M. Wolterink*

Main category: cs.CV

TL;DR: 利用大数据和自监督预训练方法，通过几何动脉模型提升冠状动脉壁剪切应力评估的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决医疗领域中因数据稀缺导致的血流动力学生物标志物（如壁剪切应力）评估难题。

Method: 使用自监督预训练和基础模型，基于8449个几何动脉模型数据集，计算热核签名作为目标。

Result: 在有限数据下，学习到的几何表示能显著提升冠状动脉壁剪切应力区域的分割效果。

Conclusion: 几何表示学习可有效改善小规模临床试验中的血流动力学生物标志物评估。

Abstract: Leveraging big data for patient care is promising in many medical fields such
as cardiovascular health. For example, hemodynamic biomarkers like wall shear
stress could be assessed from patient-specific medical images via machine
learning algorithms, bypassing the need for time-intensive computational fluid
simulation. However, it is extremely challenging to amass large-enough datasets
to effectively train such models. We could address this data scarcity by means
of self-supervised pre-training and foundations models given large datasets of
geometric artery models. In the context of coronary arteries, leveraging
learned representations to improve hemodynamic biomarker assessment has not yet
been well studied. In this work, we address this gap by investigating whether a
large dataset (8449 shapes) consisting of geometric models of 3D blood vessels
can benefit wall shear stress assessment in coronary artery models from a
small-scale clinical trial (49 patients). We create a self-supervised target
for the 3D blood vessels by computing the heat kernel signature, a quantity
obtained via Laplacian eigenvectors, which captures the very essence of the
shapes. We show how geometric representations learned from this datasets can
boost segmentation of coronary arteries into regions of low, mid and high
(time-averaged) wall shear stress even when trained on limited data.

</details>


### [60] [No Label Left Behind: A Unified Surface Defect Detection Model for all Supervision Regimes](https://arxiv.org/abs/2508.19060)
*Blaž Rolih,Matic Fučka,Danijel Skočaj*

Main category: cs.CV

TL;DR: SuperSimpleNet是一种高效、适应性强的表面缺陷检测模型，支持多种监督场景，性能优异且速度快。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以满足工业需求，无法适应多样化的数据标注场景。

Method: 基于SimpleNet，引入合成异常生成、增强分类头和改进学习过程。

Result: 在四个基准数据集上表现优异，推理时间低于10毫秒。

Conclusion: SuperSimpleNet为工业应用提供了高效可靠的解决方案，缩小了学术研究与工业实践的差距。

Abstract: Surface defect detection is a critical task across numerous industries, aimed
at efficiently identifying and localising imperfections or irregularities on
manufactured components. While numerous methods have been proposed, many fail
to meet industrial demands for high performance, efficiency, and adaptability.
Existing approaches are often constrained to specific supervision scenarios and
struggle to adapt to the diverse data annotations encountered in real-world
manufacturing processes, such as unsupervised, weakly supervised, mixed
supervision, and fully supervised settings. To address these challenges, we
propose SuperSimpleNet, a highly efficient and adaptable discriminative model
built on the foundation of SimpleNet. SuperSimpleNet incorporates a novel
synthetic anomaly generation process, an enhanced classification head, and an
improved learning procedure, enabling efficient training in all four
supervision scenarios, making it the first model capable of fully leveraging
all available data annotations. SuperSimpleNet sets a new standard for
performance across all scenarios, as demonstrated by its results on four
challenging benchmark datasets. Beyond accuracy, it is very fast, achieving an
inference time below 10 ms. With its ability to unify diverse supervision
paradigms while maintaining outstanding speed and reliability, SuperSimpleNet
represents a promising step forward in addressing real-world manufacturing
challenges and bridging the gap between academic research and industrial
applications. Code: https://github.com/blaz-r/SuperSimpleNet

</details>


### [61] [Learning Binary Sampling Patterns for Single-Pixel Imaging using Bilevel Optimisation](https://arxiv.org/abs/2508.19068)
*Serban C. Tudosie,Alexander Denker,Zeljko Kereta,Simon Arridge*

Main category: cs.CV

TL;DR: 提出了一种双层优化方法，用于学习任务特定的二进制照明模式，适用于单像素荧光显微镜等应用。


<details>
  <summary>Details</summary>
Motivation: 解决二进制模式优化的不可微性问题，并提升在高度欠采样情况下的重建性能。

Method: 使用Straight-Through Estimator和Total Deep Variation正则化器在双层优化中学习二进制照明模式。

Result: 在CytoImageNet显微镜数据集上展示了优于基线方法的重建性能。

Conclusion: 学习到的模式在高度欠采样情况下表现优越。

Abstract: Single-Pixel Imaging enables reconstructing objects using a single detector
through sequential illuminations with structured light patterns. We propose a
bilevel optimisation method for learning task-specific, binary illumination
patterns, optimised for applications like single-pixel fluorescence microscopy.
We address the non-differentiable nature of binary pattern optimisation using
the Straight-Through Estimator and leveraging a Total Deep Variation
regulariser in the bilevel formulation. We demonstrate our method on the
CytoImageNet microscopy dataset and show that learned patterns achieve superior
reconstruction performance compared to baseline methods, especially in highly
undersampled regimes.

</details>


### [62] [Few-Shot Connectivity-Aware Text Line Segmentation in Historical Documents](https://arxiv.org/abs/2508.19162)
*Rafael Sterzinger,Tingyu Lin,Robert Sablatnig*

Main category: cs.CV

TL;DR: 论文提出了一种基于轻量级UNet++和拓扑感知损失函数的少样本学习方法，用于历史文档的文本行分割，显著提高了准确性和数据效率。


<details>
  <summary>Details</summary>
Motivation: 历史文档的文本行分割需要大量标注数据，但标注成本高且专家知识稀缺，因此需要少样本学习方法以减少数据需求。

Method: 采用轻量级UNet++结合连通性感知损失函数，通过小样本训练（仅三页标注数据）提升模型性能。

Result: 在U-DIADS-TL数据集上，识别准确率提升200%，行交并比提升75%，并在DIVA-HisDB任务中达到或超过最佳性能。

Conclusion: 该方法在少样本条件下显著优于现有技术，证明了其高效性和实用性。

Abstract: A foundational task for the digital analysis of documents is text line
segmentation. However, automating this process with deep learning models is
challenging because it requires large, annotated datasets that are often
unavailable for historical documents. Additionally, the annotation process is a
labor- and cost-intensive task that requires expert knowledge, which makes
few-shot learning a promising direction for reducing data requirements. In this
work, we demonstrate that small and simple architectures, coupled with a
topology-aware loss function, are more accurate and data-efficient than more
complex alternatives. We pair a lightweight UNet++ with a connectivity-aware
loss, initially developed for neuron morphology, which explicitly penalizes
structural errors like line fragmentation and unintended line merges. To
increase our limited data, we train on small patches extracted from a mere
three annotated pages per manuscript. Our methodology significantly improves
upon the current state-of-the-art on the U-DIADS-TL dataset, with a 200%
increase in Recognition Accuracy and a 75% increase in Line Intersection over
Union. Our method also achieves an F-Measure score on par with or even
exceeding that of the competition winner of the DIVA-HisDB baseline detection
task, all while requiring only three annotated pages, exemplifying the efficacy
of our approach. Our implementation is publicly available at:
https://github.com/RafaelSterzinger/acpr_few_shot_hist.

</details>


### [63] [Dual Enhancement on 3D Vision-Language Perception for Monocular 3D Visual Grounding](https://arxiv.org/abs/2508.19165)
*Yuzhen Li,Min Liu,Yuan Bian,Xueping Wang,Zhaoyang Li,Gen Li,Yaonan Wang*

Main category: cs.CV

TL;DR: 论文提出两种方法（3DTE和TGE）增强文本嵌入和几何特征的3D感知，显著提升了单目3D视觉定位的性能。


<details>
  <summary>Details</summary>
Motivation: 发现预训练语言模型对数值单位不敏感，导致3D理解能力弱，影响3D视觉定位效果。

Method: 提出3DTE增强文本查询的多样性，TGE模块将文本特征投影到几何一致空间。

Result: 在Mono3DRefer数据集上取得显著提升，远距离场景准确率提高11.94%。

Conclusion: 通过增强文本和几何特征的3D感知，实现了新的SOTA性能。

Abstract: Monocular 3D visual grounding is a novel task that aims to locate 3D objects
in RGB images using text descriptions with explicit geometry information.
Despite the inclusion of geometry details in the text, we observe that the text
embeddings are sensitive to the magnitude of numerical values but largely
ignore the associated measurement units. For example, simply equidistant
mapping the length with unit "meter" to "decimeters" or "centimeters" leads to
severe performance degradation, even though the physical length remains
equivalent. This observation signifies the weak 3D comprehension of pre-trained
language model, which generates misguiding text features to hinder 3D
perception. Therefore, we propose to enhance the 3D perception of model on text
embeddings and geometry features with two simple and effective methods.
Firstly, we introduce a pre-processing method named 3D-text Enhancement (3DTE),
which enhances the comprehension of mapping relationships between different
units by augmenting the diversity of distance descriptors in text queries.
Next, we propose a Text-Guided Geometry Enhancement (TGE) module to further
enhance the 3D-text information by projecting the basic text features into
geometrically consistent space. These 3D-enhanced text features are then
leveraged to precisely guide the attention of geometry features. We evaluate
the proposed method through extensive comparisons and ablation studies on the
Mono3DRefer dataset. Experimental results demonstrate substantial improvements
over previous methods, achieving new state-of-the-art results with a notable
accuracy gain of 11.94\% in the "Far" scenario. Our code will be made publicly
available.

</details>


### [64] [Beyond flattening: a geometrically principled positional encoding for vision transformers with Weierstrass elliptic functions](https://arxiv.org/abs/2508.19167)
*Zhihang Xin,Xitong Hu,Rui Wang*

Main category: cs.CV

TL;DR: 提出了一种基于Weierstrass椭圆函数的位置编码方法（WEF-PE），用于改进视觉Transformer在图像任务中的空间结构建模能力。


<details>
  <summary>Details</summary>
Motivation: 传统的位置编码方法破坏了图像的二维空间结构，且缺乏几何约束，无法有效利用空间邻近性先验。

Method: 利用椭圆函数的双周期性和非线性几何特性，直接在复数域表示二维坐标，并通过代数加法公式推导相对位置信息。

Result: 在CIFAR-100和VTAB-1k等任务上取得了显著性能提升，如ViT-Tiny在CIFAR-100上达到63.78%的准确率。

Conclusion: WEF-PE通过数学原理增强了空间距离关系的建模能力，提供了更优的几何归纳偏置和语义聚焦。

Abstract: Vision Transformers have demonstrated remarkable success in computer vision
tasks, yet their reliance on learnable one-dimensional positional embeddings
fundamentally disrupts the inherent two-dimensional spatial structure of images
through patch flattening procedures. Traditional positional encoding approaches
lack geometric constraints and fail to establish monotonic correspondence
between Euclidean spatial distances and sequential index distances, thereby
limiting the model's capacity to leverage spatial proximity priors effectively.
We propose Weierstrass Elliptic Function Positional Encoding (WEF-PE), a
mathematically principled approach that directly addresses two-dimensional
coordinates through natural complex domain representation, where the doubly
periodic properties of elliptic functions align remarkably with translational
invariance patterns commonly observed in visual data. Our method exploits the
non-linear geometric nature of elliptic functions to encode spatial distance
relationships naturally, while the algebraic addition formula enables direct
derivation of relative positional information between arbitrary patch pairs
from their absolute encodings. Comprehensive experiments demonstrate that
WEF-PE achieves superior performance across diverse scenarios, including
63.78\% accuracy on CIFAR-100 from-scratch training with ViT-Tiny architecture,
93.28\% on CIFAR-100 fine-tuning with ViT-Base, and consistent improvements on
VTAB-1k benchmark tasks. Theoretical analysis confirms the distance-decay
property through rigorous mathematical proof, while attention visualization
reveals enhanced geometric inductive bias and more coherent semantic focus
compared to conventional approaches.The source code implementing the methods
described in this paper is publicly available on GitHub.

</details>


### [65] [SoccerNet 2025 Challenges Results](https://arxiv.org/abs/2508.19182)
*Silvio Giancola,Anthony Cioppa,Marc Gutiérrez-Pérez,Jan Held,Carlos Hinojosa,Victor Joos,Arnaud Leduc,Floriane Magera,Karen Sanchez,Vladimir Somers,Artur Xarles,Antonio Agudo,Alexandre Alahi,Olivier Barnich,Albert Clapés,Christophe De Vleeschouwer,Sergio Escalera,Bernard Ghanem,Thomas B. Moeslund,Marc Van Droogenbroeck,Tomoki Abe,Saad Alotaibi,Faisal Altawijri,Steven Araujo,Xiang Bai,Xiaoyang Bi,Jiawang Cao,Vanyi Chao,Kamil Czarnogórski,Fabian Deuser,Mingyang Du,Tianrui Feng,Patrick Frenzel,Mirco Fuchs,Jorge García,Konrad Habel,Takaya Hashiguchi,Sadao Hirose,Xinting Hu,Yewon Hwang,Ririko Inoue,Riku Itsuji,Kazuto Iwai,Hongwei Ji,Yangguang Ji,Licheng Jiao,Yuto Kageyama,Yuta Kamikawa,Yuuki Kanasugi,Hyungjung Kim,Jinwook Kim,Takuya Kurihara,Bozheng Li,Lingling Li,Xian Li,Youxing Lian,Dingkang Liang,Hongkai Lin,Jiadong Lin,Jian Liu,Liang Liu,Shuaikun Liu,Zhaohong Liu,Yi Lu,Federico Méndez,Huadong Ma,Wenping Ma,Jacek Maksymiuk,Henry Mantilla,Ismail Mathkour,Daniel Matthes,Ayaha Motomochi,Amrulloh Robbani Muhammad,Haruto Nakayama,Joohyung Oh,Yin May Oo,Marcelo Ortega,Norbert Oswald,Rintaro Otsubo,Fabian Perez,Mengshi Qi,Cristian Rey,Abel Reyes-Angulo,Oliver Rose,Hoover Rueda-Chacón,Hideo Saito,Jose Sarmiento,Kanta Sawafuji,Atom Scott,Xi Shen,Pragyan Shrestha,Jae-Young Sim,Long Sun,Yuyang Sun,Tomohiro Suzuki,Licheng Tang,Masato Tonouchi,Ikuma Uchida,Henry O. Velesaca,Tiancheng Wang,Rio Watanabe,Jay Wu,Yongliang Wu,Shunzo Yamagishi,Di Yang,Xu Yang,Yuxin Yang,Hao Ye,Xinyu Ye,Calvin Yeung,Xuanlong Yu,Chao Zhang,Dingyuan Zhang,Kexing Zhang,Zhe Zhao,Xin Zhou,Wenbo Zhu,Julian Ziegler*

Main category: cs.CV

TL;DR: SoccerNet 2025 Challenges聚焦于足球视频理解的计算机视觉研究，包含四项任务：团队球动作检测、单目深度估计、多视角犯规识别和游戏状态重建。


<details>
  <summary>Details</summary>
Motivation: 推动足球视频分析的计算机视觉研究，提供统一评估标准和基线模型。

Method: 提供大规模标注数据集、统一评估协议和基线模型，支持四项任务的解决方案开发。

Result: 报告了各项挑战的结果，展示了社区在足球视频理解方面的进展。

Conclusion: SoccerNet挑战赛促进了计算机视觉与体育交叉领域的可重复、开放研究。

Abstract: The SoccerNet 2025 Challenges mark the fifth annual edition of the SoccerNet
open benchmarking effort, dedicated to advancing computer vision research in
football video understanding. This year's challenges span four vision-based
tasks: (1) Team Ball Action Spotting, focused on detecting ball-related actions
in football broadcasts and assigning actions to teams; (2) Monocular Depth
Estimation, targeting the recovery of scene geometry from single-camera
broadcast clips through relative depth estimation for each pixel; (3)
Multi-View Foul Recognition, requiring the analysis of multiple synchronized
camera views to classify fouls and their severity; and (4) Game State
Reconstruction, aimed at localizing and identifying all players from a
broadcast video to reconstruct the game state on a 2D top-view of the field.
Across all tasks, participants were provided with large-scale annotated
datasets, unified evaluation protocols, and strong baselines as starting
points. This report presents the results of each challenge, highlights the
top-performing solutions, and provides insights into the progress made by the
community. The SoccerNet Challenges continue to serve as a driving force for
reproducible, open research at the intersection of computer vision, artificial
intelligence, and sports. Detailed information about the tasks, challenges, and
leaderboards can be found at https://www.soccer-net.org, with baselines and
development kits available at https://github.com/SoccerNet.

</details>


### [66] [FastMesh:Efficient Artistic Mesh Generation via Component Decoupling](https://arxiv.org/abs/2508.19188)
*Jeonghwan Kim,Yushi Lan,Armando Fortes,Yongwei Chen,Xingang Pan*

Main category: cs.CV

TL;DR: 提出了一种高效的网格生成框架，通过分离顶点和面生成，减少冗余，显著提升生成速度和质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在表示流形网格时重复使用顶点，导致序列过长和生成效率低下。

Method: 使用自回归模型生成顶点，双向Transformer构建面，并引入保真度增强器和后处理框架。

Result: 生成速度提升8倍以上，网格质量更高。

Conclusion: 该方法在效率和生成质量上均优于现有技术。

Abstract: Recent mesh generation approaches typically tokenize triangle meshes into
sequences of tokens and train autoregressive models to generate these tokens
sequentially. Despite substantial progress, such token sequences inevitably
reuse vertices multiple times to fully represent manifold meshes, as each
vertex is shared by multiple faces. This redundancy leads to excessively long
token sequences and inefficient generation processes. In this paper, we propose
an efficient framework that generates artistic meshes by treating vertices and
faces separately, significantly reducing redundancy. We employ an
autoregressive model solely for vertex generation, decreasing the token count
to approximately 23\% of that required by the most compact existing tokenizer.
Next, we leverage a bidirectional transformer to complete the mesh in a single
step by capturing inter-vertex relationships and constructing the adjacency
matrix that defines the mesh faces. To further improve the generation quality,
we introduce a fidelity enhancer to refine vertex positioning into more natural
arrangements and propose a post-processing framework to remove undesirable edge
connections. Experimental results show that our method achieves more than
8$\times$ faster speed on mesh generation compared to state-of-the-art
approaches, while producing higher mesh quality.

</details>


### [67] [All-in-One Slider for Attribute Manipulation in Diffusion Models](https://arxiv.org/abs/2508.19195)
*Weixin Ye,Hongguang Zhu,Wei Wang,Yahui Liu,Mengyu Wang*

Main category: cs.CV

TL;DR: 提出了一种名为All-in-One Slider的轻量级模块，用于在文本到图像扩散模型中实现多属性的精细控制，支持零样本操作和属性组合。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要为每个属性独立训练滑块模块，导致参数冗余和灵活性不足，无法满足多属性操作的需求。

Method: 通过将文本嵌入空间分解为稀疏的语义属性方向，训练一个通用的滑块模块，支持多种属性的连续控制和组合。

Result: 实验表明，该方法在属性操作上具有高精度和可扩展性，并能扩展到真实图像的处理。

Conclusion: All-in-One Slider提供了一种高效且灵活的多属性控制方案，适用于各种实际场景。

Abstract: Text-to-image (T2I) diffusion models have made significant strides in
generating high-quality images. However, progressively manipulating certain
attributes of generated images to meet the desired user expectations remains
challenging, particularly for content with rich details, such as human faces.
Some studies have attempted to address this by training slider modules.
However, they follow a One-for-One manner, where an independent slider is
trained for each attribute, requiring additional training whenever a new
attribute is introduced. This not only results in parameter redundancy
accumulated by sliders but also restricts the flexibility of practical
applications and the scalability of attribute manipulation. To address this
issue, we introduce the All-in-One Slider, a lightweight module that decomposes
the text embedding space into sparse, semantically meaningful attribute
directions. Once trained, it functions as a general-purpose slider, enabling
interpretable and fine-grained continuous control over various attributes.
Moreover, by recombining the learned directions, the All-in-One Slider supports
zero-shot manipulation of unseen attributes (e.g., races and celebrities) and
the composition of multiple attributes. Extensive experiments demonstrate that
our method enables accurate and scalable attribute manipulation, achieving
notable improvements compared to previous methods. Furthermore, our method can
be extended to integrate with the inversion framework to perform attribute
manipulation on real images, broadening its applicability to various real-world
scenarios. The code and trained model will be released at:
https://github.com/ywxsuperstar/KSAE-FaceSteer.

</details>


### [68] [LSD-3D: Large-Scale 3D Driving Scene Generation with Geometry Grounding](https://arxiv.org/abs/2508.19204)
*Julian Ost,Andrea Ramazzina,Amogh Joshi,Maximilian Bömer,Mario Bijelic,Felix Heide*

Main category: cs.CV

TL;DR: 提出了一种直接生成大规模3D驾驶场景的方法，结合代理几何生成与2D图像先验的分数蒸馏，实现高可控性和几何一致性。


<details>
  <summary>Details</summary>
Motivation: 现有神经重建方法局限于静态环境且场景控制有限，而基于扩散模型的驾驶数据生成缺乏几何基础和因果性。本文旨在填补这一空白。

Method: 结合代理几何生成与环境表示，利用2D图像先验的分数蒸馏，实现高可控性和几何一致性。

Result: 生成的大规模3D驾驶场景具有高保真纹理和结构，可基于地图布局进行条件生成，实现逼真且几何一致的复杂驾驶场景。

Conclusion: 该方法成功结合了几何准确性和可控性，为机器人学习提供了高质量的大规模3D场景数据。

Abstract: Large-scale scene data is essential for training and testing in robot
learning. Neural reconstruction methods have promised the capability of
reconstructing large physically-grounded outdoor scenes from captured sensor
data. However, these methods have baked-in static environments and only allow
for limited scene control -- they are functionally constrained in scene and
trajectory diversity by the captures from which they are reconstructed. In
contrast, generating driving data with recent image or video diffusion models
offers control, however, at the cost of geometry grounding and causality. In
this work, we aim to bridge this gap and present a method that directly
generates large-scale 3D driving scenes with accurate geometry, allowing for
causal novel view synthesis with object permanence and explicit 3D geometry
estimation. The proposed method combines the generation of a proxy geometry and
environment representation with score distillation from learned 2D image
priors. We find that this approach allows for high controllability, enabling
the prompt-guided geometry and high-fidelity texture and structure that can be
conditioned on map layouts -- producing realistic and geometrically consistent
3D generations of complex driving scenes.

</details>


### [69] [OmniHuman-1.5: Instilling an Active Mind in Avatars via Cognitive Simulation](https://arxiv.org/abs/2508.19209)
*Jianwen Jiang,Weihong Zeng,Zerong Zheng,Jiaqi Yang,Chao Liang,Wang Liao,Han Liang,Yuan Zhang,Mingyuan Gao*

Main category: cs.CV

TL;DR: OmniHuman-1.5提出了一种新框架，通过多模态大语言模型和专用架构生成语义一致且富有表现力的角色动画。


<details>
  <summary>Details</summary>
Motivation: 现有视频角色模型仅能捕捉物理相似性，缺乏对情感、意图或上下文的理解。

Method: 利用多模态大语言模型生成结构化文本表示，结合Multimodal DiT架构和Pseudo Last Frame设计。

Result: 在多项指标上表现领先，包括唇同步精度、视频质量和语义一致性。

Conclusion: 该模型在复杂场景中表现出色，扩展性强。

Abstract: Existing video avatar models can produce fluid human animations, yet they
struggle to move beyond mere physical likeness to capture a character's
authentic essence. Their motions typically synchronize with low-level cues like
audio rhythm, lacking a deeper semantic understanding of emotion, intent, or
context. To bridge this gap, \textbf{we propose a framework designed to
generate character animations that are not only physically plausible but also
semantically coherent and expressive.} Our model, \textbf{OmniHuman-1.5}, is
built upon two key technical contributions. First, we leverage Multimodal Large
Language Models to synthesize a structured textual representation of conditions
that provides high-level semantic guidance. This guidance steers our motion
generator beyond simplistic rhythmic synchronization, enabling the production
of actions that are contextually and emotionally resonant. Second, to ensure
the effective fusion of these multimodal inputs and mitigate inter-modality
conflicts, we introduce a specialized Multimodal DiT architecture with a novel
Pseudo Last Frame design. The synergy of these components allows our model to
accurately interpret the joint semantics of audio, images, and text, thereby
generating motions that are deeply coherent with the character, scene, and
linguistic content. Extensive experiments demonstrate that our model achieves
leading performance across a comprehensive set of metrics, including lip-sync
accuracy, video quality, motion naturalness and semantic consistency with
textual prompts. Furthermore, our approach shows remarkable extensibility to
complex scenarios, such as those involving multi-person and non-human subjects.
Homepage: \href{https://omnihuman-lab.github.io/v1_5/}

</details>


### [70] [Automated Feature Tracking for Real-Time Kinematic Analysis and Shape Estimation of Carbon Nanotube Growth](https://arxiv.org/abs/2508.19232)
*Kaveh Safavigerdini,Ramakrishna Surya,Jaired Collins,Prasad Calyam,Filiz Bunyak,Matthew R. Maschmann,Kannappan Palaniappan*

Main category: cs.CV

TL;DR: VFTrack是一种实时原位粒子跟踪框架，用于自动检测和跟踪SEM图像序列中的碳纳米管（CNT）粒子，解决了现有方法的静态分析和手动初始化问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法提供连续的动态生长分析，限制了碳纳米管生长的实验研究。

Method: VFTrack结合手工或深度学习特征检测器和匹配器，实现CNT微柱生长的运动学分析。

Result: 通过13,540条手动标注轨迹的系统评估，ALIKED检测器与LightGlue匹配器组合表现最佳（F1分数0.78，α分数0.89）。

Conclusion: VFTrack为纳米材料表征提供了自动化工具，填补了物理模型与实验观察之间的差距，支持CNT合成的实时优化。

Abstract: Carbon nanotubes (CNTs) are critical building blocks in nanotechnology, yet
the characterization of their dynamic growth is limited by the experimental
challenges in nanoscale motion measurement using scanning electron microscopy
(SEM) imaging. Existing ex situ methods offer only static analysis, while in
situ techniques often require manual initialization and lack continuous
per-particle trajectory decomposition. We present Visual Feature Tracking
(VFTrack) an in-situ real-time particle tracking framework that automatically
detects and tracks individual CNT particles in SEM image sequences. VFTrack
integrates handcrafted or deep feature detectors and matchers within a particle
tracking framework to enable kinematic analysis of CNT micropillar growth. A
systematic using 13,540 manually annotated trajectories identifies the ALIKED
detector with LightGlue matcher as an optimal combination (F1-score of 0.78,
$\alpha$-score of 0.89). VFTrack motion vectors decomposed into axial growth,
lateral drift, and oscillations, facilitate the calculation of heterogeneous
regional growth rates and the reconstruction of evolving CNT pillar
morphologies. This work enables advancement in automated nano-material
characterization, bridging the gap between physics-based models and
experimental observation to enable real-time optimization of CNT synthesis.

</details>


### [71] [Autoregressive Universal Video Segmentation Model](https://arxiv.org/abs/2508.19242)
*Miran Heo,Sukjun Hwang,Min-Hung Chen,Yu-Chiang Frank Wang,Albert Gu,Seon Joo Kim,Ryo Hachiuma*

Main category: cs.CV

TL;DR: AUSM是一种统一提示和无提示视频分割的模型，通过顺序掩码预测实现高效训练和性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有视频分割模型在无提示场景下表现不足，任务专用模型导致碎片化。

Method: 采用顺序掩码预测和状态空间模型，支持并行训练和任意长度视频流。

Result: 在多个基准测试中表现优于现有方法，训练速度提升2.5倍。

Conclusion: AUSM为视频分割提供了一种高效统一的解决方案。

Abstract: Recent video foundation models such as SAM2 excel at prompted video
segmentation by treating masks as a general-purpose primitive. However, many
real-world settings require unprompted segmentation that aims to detect and
track all objects in a video without external cues, leaving today's landscape
fragmented across task-specific models and pipelines. We recast streaming video
segmentation as sequential mask prediction, analogous to language modeling, and
introduce the Autoregressive Universal Segmentation Model (AUSM), a single
architecture that unifies both prompted and unprompted video segmentation.
Built on recent state-space models, AUSM maintains a fixed-size spatial state
and scales to video streams of arbitrary length. Furthermore, all components of
AUSM are designed for parallel training across frames, yielding substantial
speedups over iterative training. On standard benchmarks (DAVIS17, YouTube-VOS
2018 & 2019, MOSE, YouTube-VIS 2019 & 2021, and OVIS) AUSM outperforms prior
universal streaming video segmentation methods and achieves up to 2.5x faster
training on 16-frame sequences.

</details>


### [72] [Style4D-Bench: A Benchmark Suite for 4D Stylization](https://arxiv.org/abs/2508.19243)
*Beiqi Chen,Shuai Shao,Haitang Feng,Jianhuang Lai,Jianlou Si,Guangcong Wang*

Main category: cs.CV

TL;DR: Style4D-Bench是首个专为4D风格化设计的基准套件，包含评估协议、强基线方法和高质量动态4D场景数据集。Style4D框架基于4D高斯泼溅技术，实现了时空一致的风格化效果。


<details>
  <summary>Details</summary>
Motivation: 为4D风格化领域提供标准化评估工具，推动这一新兴领域的研究进展。

Method: Style4D框架包含4D高斯泼溅场景表示、风格高斯表示和几何保持风格迁移模块，通过对比一致性学习和结构内容保留增强时空一致性。

Result: Style4D在Style4D-Bench上表现优异，实现了细粒度风格细节和稳定的时空动态。

Conclusion: Style4D-Bench将成为动态3D场景风格化渲染研究的重要资源。

Abstract: We introduce Style4D-Bench, the first benchmark suite specifically designed
for 4D stylization, with the goal of standardizing evaluation and facilitating
progress in this emerging area. Style4D-Bench comprises: 1) a comprehensive
evaluation protocol measuring spatial fidelity, temporal coherence, and
multi-view consistency through both perceptual and quantitative metrics, 2) a
strong baseline that make an initial attempt for 4D stylization, and 3) a
curated collection of high-resolution dynamic 4D scenes with diverse motions
and complex backgrounds. To establish a strong baseline, we present Style4D, a
novel framework built upon 4D Gaussian Splatting. It consists of three key
components: a basic 4DGS scene representation to capture reliable geometry, a
Style Gaussian Representation that leverages lightweight per-Gaussian MLPs for
temporally and spatially aware appearance control, and a Holistic
Geometry-Preserved Style Transfer module designed to enhance spatio-temporal
consistency via contrastive coherence learning and structural content
preservation. Extensive experiments on Style4D-Bench demonstrate that Style4D
achieves state-of-the-art performance in 4D stylization, producing fine-grained
stylistic details with stable temporal dynamics and consistent multi-view
rendering. We expect Style4D-Bench to become a valuable resource for
benchmarking and advancing research in stylized rendering of dynamic 3D scenes.
Project page: https://becky-catherine.github.io/Style4D . Code:
https://github.com/Becky-catherine/Style4D-Bench .

</details>


### [73] [Articulate3D: Zero-Shot Text-Driven 3D Object Posing](https://arxiv.org/abs/2508.19244)
*Oishi Deb,Anjun Hu,Ashkan Khakzar,Philip Torr,Christian Rupprecht*

Main category: cs.CV

TL;DR: Articulate3D是一种无需训练的方法，通过语言控制调整3D资产的姿态，结合图像生成和多视角优化。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉和语言模型有所进展，但通过语言控制3D姿态仍具挑战性。

Method: 分两步：1）修改图像生成器以根据输入图像和文本指令生成目标图像；2）通过多视角姿态优化对齐网格。引入RSActrl机制解耦源结构和姿态。

Result: 在多样3D对象和自由文本提示下成功调整姿态，保持网格原始身份。用户研究中85%的偏好证实其优越性。

Conclusion: Articulate3D通过语言控制有效调整3D姿态，优于现有方法。

Abstract: We propose a training-free method, Articulate3D, to pose a 3D asset through
language control. Despite advances in vision and language models, this task
remains surprisingly challenging. To achieve this goal, we decompose the
problem into two steps. We modify a powerful image-generator to create target
images conditioned on the input image and a text instruction. We then align the
mesh to the target images through a multi-view pose optimisation step. In
detail, we introduce a self-attention rewiring mechanism (RSActrl) that
decouples the source structure from pose within an image generative model,
allowing it to maintain a consistent structure across varying poses. We
observed that differentiable rendering is an unreliable signal for articulation
optimisation; instead, we use keypoints to establish correspondences between
input and target images. The effectiveness of Articulate3D is demonstrated
across a diverse range of 3D objects and free-form text prompts, successfully
manipulating poses while maintaining the original identity of the mesh.
Quantitative evaluations and a comparative user study, in which our method was
preferred over 85\% of the time, confirm its superiority over existing
approaches. Project page:https://odeb1.github.io/articulate3d_page_deb/

</details>


### [74] [VoxHammer: Training-Free Precise and Coherent 3D Editing in Native 3D Space](https://arxiv.org/abs/2508.19247)
*Lin Li,Zehuan Huang,Haoran Feng,Gengxiong Zhuang,Rui Chen,Chunchao Guo,Lu Sheng*

Main category: cs.CV

TL;DR: VoxHammer是一种无需训练的方法，通过在3D潜在空间中进行精确和连贯的编辑，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 3D局部编辑在游戏行业和机器人交互中至关重要，但现有方法难以精确保留未编辑区域和整体一致性。

Method: VoxHammer通过预测反转轨迹并替换去噪特征，确保未编辑区域的上下文一致性和编辑部分的连贯集成。

Result: 实验表明，VoxHammer在保留区域的3D一致性和整体质量上显著优于现有方法。

Conclusion: VoxHammer为高质量编辑配对数据的合成提供了可能，为上下文3D生成奠定了数据基础。

Abstract: 3D local editing of specified regions is crucial for game industry and robot
interaction. Recent methods typically edit rendered multi-view images and then
reconstruct 3D models, but they face challenges in precisely preserving
unedited regions and overall coherence. Inspired by structured 3D generative
models, we propose VoxHammer, a novel training-free approach that performs
precise and coherent editing in 3D latent space. Given a 3D model, VoxHammer
first predicts its inversion trajectory and obtains its inverted latents and
key-value tokens at each timestep. Subsequently, in the denoising and editing
phase, we replace the denoising features of preserved regions with the
corresponding inverted latents and cached key-value tokens. By retaining these
contextual features, this approach ensures consistent reconstruction of
preserved areas and coherent integration of edited parts. To evaluate the
consistency of preserved regions, we constructed Edit3D-Bench, a
human-annotated dataset comprising hundreds of samples, each with carefully
labeled 3D editing regions. Experiments demonstrate that VoxHammer
significantly outperforms existing methods in terms of both 3D consistency of
preserved regions and overall quality. Our method holds promise for
synthesizing high-quality edited paired data, thereby laying the data
foundation for in-context 3D generation. See our project page at
https://huanngzh.github.io/VoxHammer-Page/.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [75] [Federative ischemic stroke segmentation as alternative to overcome domain-shift multi-institution challenges](https://arxiv.org/abs/2508.18296)
*Edgar Rangel,Fabio Martinez*

Main category: eess.IV

TL;DR: 该论文提出了一种协作框架，通过共享深度中心无关表示知识，用于分割DWI序列中的缺血性卒中病灶，解决了现有方法因数据来源单一而泛化能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 卒中是全球第二大死因和第三大致残原因，临床指南依赖DWI和ADC进行病灶定位和测量，但分析结果因患者、设备和专家标注差异而高度可变。现有计算方法通常仅基于单一机构数据，缺乏泛化能力。

Method: 开发了一个协作框架，利用联邦平均（FedAvg）模型，从14个模拟医疗中心的2031项研究中共享知识，生成中心无关的深度表示。

Result: FedAvg模型在所有中心上表现优异（DSC 0.71±0.24，AVD 5.29±22.74，ALD 2.16±3.60，LF1 0.70±0.26），优于集中式和其他联邦方法，且在分布外中心表现稳定（DSC 0.64±0.29，AVD 4.44±8.74）。

Conclusion: 该协作框架通过共享知识显著提升了卒中病灶分割的泛化能力，为临床提供了可靠的计算支持。

Abstract: Stroke is the second leading cause of death and the third leading cause of
disability worldwide. Clinical guidelines establish diffusion resonance imaging
(DWI, ADC) as the standard for localizing, characterizing, and measuring
infarct volume, enabling treatment support and prognosis. Nonetheless, such
lesion analysis is highly variable due to different patient demographics,
scanner vendors, and expert annotations. Computational support approaches have
been key to helping with the localization and segmentation of lesions. However,
these strategies are dedicated solutions that learn patterns from only one
institution, lacking the variability to generalize geometrical lesions shape
models. Even worse, many clinical centers lack sufficient labeled samples to
adjust these dedicated solutions. This work developed a collaborative framework
for segmenting ischemic stroke lesions in DWI sequences by sharing knowledge
from deep center-independent representations. From 14 emulated healthcare
centers with 2031 studies, the FedAvg model achieved a general DSC of $0.71 \pm
0.24$, AVD of $5.29 \pm 22.74$, ALD of $2.16 \pm 3.60$ and LF1 of $0.70 \pm
0.26$ over all centers, outperforming both the centralized and other federated
rules. Interestingly, the model demonstrated strong generalization properties,
showing uniform performance across different lesion categories and reliable
performance in out-of-distribution centers (with DSC of $0.64 \pm 0.29$ and AVD
of $4.44 \pm 8.74$ without any additional training).

</details>


### [76] [Analise de Desaprendizado de Maquina em Modelos de Classificacao de Imagens Medicas](https://arxiv.org/abs/2508.18509)
*Andreza M. C. Falcao,Filipe R. Cordeiro*

Main category: eess.IV

TL;DR: SalUn模型在医学图像分类中实现高效去学习，性能接近完全重新训练。


<details>
  <summary>Details</summary>
Motivation: 探索去学习技术在医学图像分类中的应用，以保护敏感数据。

Method: 使用SalUn模型在PathMNIST、OrganAMNIST和BloodMNIST数据集上进行实验，并分析数据增强的影响。

Result: SalUn性能接近完全重新训练，适用于医学应用。

Conclusion: SalUn为医学图像分类提供了一种高效的去学习解决方案。

Abstract: Machine unlearning aims to remove private or sensitive data from a
pre-trained model while preserving the model's robustness. Despite recent
advances, this technique has not been explored in medical image classification.
This work evaluates the SalUn unlearning model by conducting experiments on the
PathMNIST, OrganAMNIST, and BloodMNIST datasets. We also analyse the impact of
data augmentation on the quality of unlearning. Results show that SalUn
achieves performance close to full retraining, indicating an efficient solution
for use in medical applications.

</details>


### [77] [A Deep Learning Application for Psoriasis Detection](https://arxiv.org/abs/2508.18528)
*Anna Milani,Fábio S. da Silva,Elloá B. Guedes,Ricardo Rios*

Main category: eess.IV

TL;DR: 比较了ResNet50、Inception v3和VGG19三种CNN模型在银屑病皮肤图像分类中的性能，Inception v3表现最佳。


<details>
  <summary>Details</summary>
Motivation: 评估不同CNN模型在银屑病诊断中的表现，以支持临床诊断。

Method: 使用专业平台获取的皮肤图像训练和验证模型，并调整评估指标。

Result: Inception v3在准确率和F1分数上表现最佳（97.5% ± 0.2）。

Conclusion: Inception v3是支持银屑病诊断的有价值工具。

Abstract: In this paper a comparative study of the performance of three Convolutional
Neural Network models, ResNet50, Inception v3 and VGG19 for classification of
skin images with lesions affected by psoriasis is presented. The images used
for training and validation of the models were obtained from specialized
platforms. Some techniques were used to adjust the evaluation metrics of the
neural networks. The results found suggest the model Inception v3 as a valuable
tool for supporting the diagnosis of psoriasis. This is due to its satisfactory
performance with respect to accuracy and F1-Score (97.5% ${\pm}$ 0.2).

</details>


### [78] [A Closer Look at Edema Area Segmentation in SD-OCT Images Using Adversarial Framework](https://arxiv.org/abs/2508.18790)
*Yuhui Tao,Yizhe Zhang,Qiang Chen*

Main category: eess.IV

TL;DR: 提出了一种结合视网膜层结构引导后处理和测试时适应策略的弱监督学习方法，用于提升黄斑水肿分割的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决弱监督学习方法在黄斑水肿分割任务中性能不足的问题，利用视网膜层结构与水肿区域的强相关性。

Method: 结合视网膜层信息，将水肿区域分割任务转化为确认水肿轮廓与视网膜层交点的问题，并引入测试时适应策略。

Result: 在两个公开数据集上的实验表明，该方法显著提升了分割准确性和鲁棒性，缩小了弱监督与全监督模型的差距。

Conclusion: 通过结合视网膜层信息和测试时适应策略，有效提升了弱监督方法在黄斑水肿分割任务中的性能。

Abstract: The development of artificial intelligence models for macular edema (ME)
analy-sis always relies on expert-annotated pixel-level image datasets which
are expen-sive to collect prospectively. While anomaly-detection-based
weakly-supervised methods have shown promise in edema area (EA) segmentation
task, their per-formance still lags behind fully-supervised approaches. In this
paper, we leverage the strong correlation between EA and retinal layers in
spectral-domain optical coherence tomography (SD-OCT) images, along with the
update characteristics of weakly-supervised learning, to enhance an
off-the-shelf adversarial framework for EA segmentation with a novel
layer-structure-guided post-processing step and a test-time-adaptation (TTA)
strategy. By incorporating additional retinal lay-er information, our framework
reframes the dense EA prediction task as one of confirming intersection points
between the EA contour and retinal layers, result-ing in predictions that
better align with the shape prior of EA. Besides, the TTA framework further
helps address discrepancies in the manifestations and presen-tations of EA
between training and test sets. Extensive experiments on two pub-licly
available datasets demonstrate that these two proposed ingredients can im-prove
the accuracy and robustness of EA segmentation, bridging the gap between
weakly-supervised and fully-supervised models.

</details>


### [79] [Understanding Benefits and Pitfalls of Current Methods for the Segmentation of Undersampled MRI Data](https://arxiv.org/abs/2508.18975)
*Jan Nikolas Morshuis,Matthias Hein,Christian F. Baumgartner*

Main category: eess.IV

TL;DR: 本文首次统一比较了7种加速MRI数据分割方法，发现简单的两阶段方法优于专门开发的复杂方法。


<details>
  <summary>Details</summary>
Motivation: MRI采集耗时且昂贵，加速采集后的数据直接用于分割任务的需求增加，但现有方法缺乏统一比较。

Method: 比较了7种方法，特别关注一阶段（联合重建与分割）与两阶段（先重建后分割）方法。

Result: 两阶段方法在数据一致性考虑下表现最佳，超越专门任务开发的复杂方法。

Conclusion: 简单两阶段方法是加速MRI数据分割的最优策略。

Abstract: MR imaging is a valuable diagnostic tool allowing to non-invasively visualize
patient anatomy and pathology with high soft-tissue contrast. However, MRI
acquisition is typically time-consuming, leading to patient discomfort and
increased costs to the healthcare system. Recent years have seen substantial
research effort into the development of methods that allow for accelerated MRI
acquisition while still obtaining a reconstruction that appears similar to the
fully-sampled MR image. However, for many applications a perfectly
reconstructed MR image may not be necessary, particularly, when the primary
goal is a downstream task such as segmentation. This has led to growing
interest in methods that aim to perform segmentation directly on accelerated
MRI data. Despite recent advances, existing methods have largely been developed
in isolation, without direct comparison to one another, often using separate or
private datasets, and lacking unified evaluation standards. To date, no
high-quality, comprehensive comparison of these methods exists, and the optimal
strategy for segmenting accelerated MR data remains unknown. This paper
provides the first unified benchmark for the segmentation of undersampled MRI
data comparing 7 approaches. A particular focus is placed on comparing
\textit{one-stage approaches}, that combine reconstruction and segmentation
into a unified model, with \textit{two-stage approaches}, that utilize
established MRI reconstruction methods followed by a segmentation network. We
test these methods on two MRI datasets that include multi-coil k-space data as
well as a human-annotated segmentation ground-truth. We find that simple
two-stage methods that consider data-consistency lead to the best segmentation
scores, surpassing complex specialized methods that are developed specifically
for this task.

</details>


### [80] [RDDM: Practicing RAW Domain Diffusion Model for Real-world Image Restoration](https://arxiv.org/abs/2508.19154)
*Yan Chen,Yi Wen,Wei Li,Junchao Liu,Yong Guo,Jie Hu,Xinghao Chen*

Main category: eess.IV

TL;DR: RDDM是一种直接在RAW域恢复图像的扩散模型，解决了sRGB域扩散模型在高保真和真实生成之间的困境。


<details>
  <summary>Details</summary>
Motivation: 现有的sRGB域扩散模型处理有损的sRGB输入，忽略了传感器RAW图像的可访问性，导致性能不佳。RDDM直接在RAW域恢复图像，避免了这一问题。

Method: 提出了RAW域VAE（RVAE）学习最优潜在表示，以及可微的后色调处理（PTP）模块实现RAW和sRGB空间的联合优化。还开发了可扩展的退化管道和配置多拜耳（CMB）LoRA模块。

Result: 实验表明，RDDM优于现有的sRGB扩散方法，生成更高保真且更少伪影的结果。

Conclusion: RDDM通过直接在RAW域工作，显著提升了图像恢复的保真度和真实感。

Abstract: We present the RAW domain diffusion model (RDDM), an end-to-end diffusion
model that restores photo-realistic images directly from the sensor RAW data.
While recent sRGB-domain diffusion methods achieve impressive results, they are
caught in a dilemma between high fidelity and realistic generation. As these
models process lossy sRGB inputs and neglect the accessibility of the sensor
RAW images in many scenarios, e.g., in image and video capturing in edge
devices, resulting in sub-optimal performance. RDDM bypasses this limitation by
directly restoring images in the RAW domain, replacing the conventional
two-stage image signal processing (ISP) + IR pipeline. However, a simple
adaptation of pre-trained diffusion models to the RAW domain confronts the
out-of-distribution (OOD) issues. To this end, we propose: (1) a RAW-domain VAE
(RVAE) learning optimal latent representations, (2) a differentiable Post Tone
Processing (PTP) module enabling joint RAW and sRGB space optimization. To
compensate for the deficiency in the dataset, we develop a scalable degradation
pipeline synthesizing RAW LQ-HQ pairs from existing sRGB datasets for
large-scale training. Furthermore, we devise a configurable multi-bayer (CMB)
LoRA module handling diverse RAW patterns such as RGGB, BGGR, etc. Extensive
experiments demonstrate RDDM's superiority over state-of-the-art sRGB diffusion
methods, yielding higher fidelity results with fewer artifacts.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [81] [EMind: A Foundation Model for Multi-task Electromagnetic Signals Understanding](https://arxiv.org/abs/2508.18785)
*Luqing Luo,Wenjin Gui,Yunfei Liu,Ziyue Zhang,Yunxi Zhang,Fengxiang Wang,Zonghao Guo,Zizhi Ma,Xinzhu Liu,Hanxiang He,Jinhai Li,Xin Qiu,Wupeng Xie,Yangang Sun*

Main category: eess.SP

TL;DR: EMind是一个电磁信号基础模型，通过大规模预训练和独特模态特性，解决了电磁信号处理中的异构性和多任务泛化问题。


<details>
  <summary>Details</summary>
Motivation: 电磁信号具有高异构性、强背景噪声和复杂时频结构，现有通用模型难以直接应用，且缺乏跨任务泛化和高质量数据集。

Method: 构建统一标准化数据集，设计长度自适应多信号打包方法和硬件感知训练策略。

Result: EMind在多下游任务中表现出色，实现了从任务特定模型到统一框架的转变。

Conclusion: EMind为电磁信号智能处理提供了高效、通用的解决方案。

Abstract: Deep understanding of electromagnetic signals is fundamental to dynamic
spectrum management, intelligent transportation, autonomous driving and
unmanned vehicle perception. The field faces challenges because electromagnetic
signals differ greatly from text and images, showing high heterogeneity, strong
background noise and complex joint time frequency structure, which prevents
existing general models from direct use. Electromagnetic communication and
sensing tasks are diverse, current methods lack cross task generalization and
transfer efficiency, and the scarcity of large high quality datasets blocks the
creation of a truly general multitask learning framework. To overcome these
issue, we introduce EMind, an electromagnetic signals foundation model that
bridges large scale pretraining and the unique nature of this modality. We
build the first unified and largest standardized electromagnetic signal dataset
covering multiple signal types and tasks. By exploiting the physical properties
of electromagnetic signals, we devise a length adaptive multi-signal packing
method and a hardware-aware training strategy that enable efficient use and
representation learning from heterogeneous multi-source signals. Experiments
show that EMind achieves strong performance and broad generalization across
many downstream tasks, moving decisively from task specific models to a unified
framework for electromagnetic intelligence. The code is available at:
https://github.com/GabrielleTse/EMind.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [82] [Reasoning Steps as Curriculum: Using Depth of Thought as a Difficulty Signal for Tuning LLMs](https://arxiv.org/abs/2508.18279)
*Jeesu Jung,Sangkeun Jung*

Main category: cs.LG

TL;DR: 论文提出了一种基于思维深度（DoT）的课程学习方法，用于训练大型语言模型，并通过实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有课程学习的难度信号往往与推理能力不匹配，缺乏可解释性和可扩展性。

Method: 定义难度为思维深度（DoT），通过统计教师模型推理步骤的数量来量化，并设计从浅到深的课程。

Result: 实验验证了DoT与推理任务难度的相关性，且DoT排序的课程优于其他方法。

Conclusion: DoT是一种认知基础明确、可解释的课程设计方法，适用于以推理为中心的模型训练。

Abstract: Curriculum learning for training LLMs requires a difficulty signal that
aligns with reasoning while remaining scalable and interpretable. We propose a
simple premise: tasks that demand deeper depth of thought for humans should
also be harder for models. Accordingly, we define difficulty as depth of
thought (DoT) and operationalize it by counting the discrete steps in a teacher
model's reasoning trace (e.g., Chain-of-Thought). We then train with a shallow
to deep curriculum ordered by this DoT and outline how to derive, validate, and
schedule it at scale. Our position yields three testable hypotheses: (i) DoT
correlates with conventional difficulty on reasoning benchmarks, (ii)
DoT-ordered curricula outperform length- or judge-scored curricula under
matched budgets, and (iii) the difficulty is robust across teacher models given
light formatting controls. We propose an evaluation framework and discuss
threats to validity (teacher style, length confounds) alongside practical
mitigations. Taken together, we aim to move toward cognitively grounded,
interpretable curricula for reasoning-centric training.

</details>


### [83] [Multi-Modal Drift Forecasting of Leeway Objects via Navier-Stokes-Guided CNN and Sequence-to-Sequence Attention-Based Models](https://arxiv.org/abs/2508.18284)
*Rahmat K. Adesunkanmi,Alexander W. Brandt,Masoud Deylami,Gustavo A. Giraldo Echeverri,Hamidreza Karbasian,Adel Alaeddini*

Main category: cs.LG

TL;DR: 提出了一种多模态机器学习框架，结合Sentence Transformer嵌入和注意力机制，用于预测海上漂浮物的漂移轨迹。


<details>
  <summary>Details</summary>
Motivation: 准确预测海上漂浮物的漂移在搜救等时间敏感场景中至关重要，但现有方法存在局限性。

Method: 通过实验收集环境与物理数据，利用Navier-Stokes模型模拟数据训练CNN估计阻力系数，结合语言模型编码的文本描述，输入注意力机制模型预测轨迹。

Result: 多模态模型在多个时间尺度（1-10秒）上表现与传统方法相当，且支持长期预测。

Conclusion: 多模态建模策略能提供准确且适应性强的海上漂浮物漂移预测。

Abstract: Accurately predicting the drift (displacement) of leeway objects in maritime
environments remains a critical challenge, particularly in time-sensitive
scenarios such as search and rescue operations. In this study, we propose a
multi-modal machine learning framework that integrates Sentence Transformer
embeddings with attention-based sequence-to-sequence architectures to predict
the drift of leeway objects in water. We begin by experimentally collecting
environmental and physical data, including water current and wind velocities,
object mass, and surface area, for five distinct leeway objects. Using
simulated data from a Navier-Stokes-based model to train a convolutional neural
network on geometrical image representations, we estimate drag and lift
coefficients of the leeway objects. These coefficients are then used to derive
the net forces responsible for driving the objects' motion. The resulting time
series, comprising physical forces, environmental velocities, and
object-specific features, combined with textual descriptions encoded via a
language model, are inputs to attention-based sequence-to-sequence
long-short-term memory and Transformer models, to predict future drift
trajectories. We evaluate the framework across multiple time horizons ($1$,
$3$, $5$, and $10$ seconds) and assess its generalization across different
objects. We compare our approach against a fitted physics-based model and
traditional machine learning methods, including recurrent neural networks and
temporal convolutional neural networks. Our results show that these multi-modal
models perform comparably to traditional models while also enabling longer-term
forecasting in place of single-step prediction. Overall, our findings
demonstrate the ability of a multi-modal modeling strategy to provide accurate
and adaptable predictions of leeway object drift in dynamic maritime
conditions.

</details>


### [84] [Data-driven models for production forecasting and decision supporting in petroleum reservoirs](https://arxiv.org/abs/2508.18289)
*Mateus A. Fernandes,Michael M. Furlanetti,Eduardo Gildin,Marcio A. Sampaio*

Main category: cs.LG

TL;DR: 提出了一种基于机器学习的石油生产预测方法，不依赖地质模型或流体属性，通过分析生产和注入数据来预测生产参数。


<details>
  <summary>Details</summary>
Motivation: 解决石油储层工程中生产预测和岩石-流体系统行为变化的挑战。

Method: 使用监督学习方法（如回归和神经网络），分析生产和注入变量，并处理概念漂移问题。

Result: 在合成数据和巴西盐下实际案例中验证了方法的可靠性。

Conclusion: 设计了一种快速响应、能处理实际困难的可靠预测器，支持储层管理并最大化石油采收率。

Abstract: Forecasting production reliably and anticipating changes in the behavior of
rock-fluid systems are the main challenges in petroleum reservoir engineering.
This project proposes to deal with this problem through a data-driven approach
and using machine learning methods. The objective is to develop a methodology
to forecast production parameters based on simple data as produced and injected
volumes and, eventually, gauges located in wells, without depending on
information from geological models, fluid properties or details of well
completions and flow systems. Initially, we performed relevance analyses of the
production and injection variables, as well as conditioning the data to suit
the problem. As reservoir conditions change over time, concept drift is a
priority concern and require special attention to those observation windows and
the periodicity of retraining, which are also objects of study. For the
production forecasts, we study supervised learning methods, such as those based
on regressions and Neural Networks, to define the most suitable for our
application in terms of performance and complexity. In a first step, we
evaluate the methodology using synthetic data generated from the UNISIM III
compositional simulation model. Next, we applied it to cases of real plays in
the Brazilian pre-salt. The expected result is the design of a reliable
predictor for reproducing reservoir dynamics, with rapid response, capability
of dealing with practical difficulties such as restrictions in wells and
processing units, and that can be used in actions to support reservoir
management, including the anticipation of deleterious behaviors, optimization
of production and injection parameters and the analysis of the effects of
probabilistic events, aiming to maximize oil recovery.

</details>


### [85] [A Fast and Minimal System to Identify Depression Using Smartphones: Explainable Machine Learning-Based Approach](https://arxiv.org/abs/2508.18301)
*Md Sabbir Ahmed,Nova Ahmed*

Main category: cs.LG

TL;DR: 开发了一个快速、简约的系统，通过7天的应用使用数据在1秒内识别抑郁症，准确率达82.4%。


<details>
  <summary>Details</summary>
Motivation: 现有系统需要长时间数据收集，不适用于早期检测，因此开发了快速检测工具。

Method: 使用7天应用数据，开发多种ML模型，结合特征选择方法。

Result: 最佳模型准确率82.4%，SHAP分析揭示了与抑郁症相关的行为标记。

Conclusion: 系统快速简约，适用于资源有限的地区，有助于开发低资源消耗的抑郁症检测工具。

Abstract: Background: Existing robust, pervasive device-based systems developed in
recent years to detect depression require data collected over a long period and
may not be effective in cases where early detection is crucial.
  Objective: Our main objective was to develop a minimalistic system to
identify depression using data retrieved in the fastest possible time.
  Methods: We developed a fast tool that retrieves the past 7 days' app usage
data in 1 second (mean 0.31, SD 1.10 seconds). A total of 100 students from
Bangladesh participated in our study, and our tool collected their app usage
data. To identify depressed and nondepressed students, we developed a diverse
set of ML models. We selected important features using the stable approach,
along with 3 main types of feature selection (FS) approaches.
  Results: Leveraging only the app usage data retrieved in 1 second, our light
gradient boosting machine model used the important features selected by the
stable FS approach and correctly identified 82.4% (n=42) of depressed students
(precision=75%, F1-score=78.5%). Moreover, after comprehensive exploration, we
presented a parsimonious stacking model where around 5 features selected by the
all-relevant FS approach Boruta were used in each iteration of validation and
showed a maximum precision of 77.4% (balanced accuracy=77.9%). A SHAP analysis
of our best models presented behavioral markers that were related to
depression.
  Conclusions: Due to our system's fast and minimalistic nature, it may make a
worthwhile contribution to identifying depression in underdeveloped and
developing regions. In addition, our detailed discussion about the implication
of our findings can facilitate the development of less resource-intensive
systems to better understand students who are depressed.

</details>


### [86] [Learning Explainable Imaging-Genetics Associations Related to a Neurological Disorder](https://arxiv.org/abs/2508.18303)
*Jueqi Wang,Zachary Jacokes,John Darrell Van Horn,Michael C. Schatz,Kevin A. Pelphrey,Archana Venkataraman*

Main category: cs.LG

TL;DR: NeuroPathX是一种可解释的深度学习框架，通过交叉注意力机制捕捉大脑结构与遗传数据的交互，优于传统方法并揭示生物学关联。


<details>
  <summary>Details</summary>
Motivation: 传统方法在成像遗传学中局限于简单线性模型或缺乏可解释性的黑盒技术，无法揭示大脑结构与遗传变异的复杂交互。

Method: 提出NeuroPathX框架，采用早期融合策略和交叉注意力机制，引入稀疏性和通路相似性损失函数增强可解释性和鲁棒性。

Result: 在自闭症谱系障碍和阿尔茨海默病上验证，NeuroPathX优于基线方法并揭示生物学合理的关联。

Conclusion: NeuroPathX有潜力推动对复杂脑部疾病的理解，代码已开源。

Abstract: While imaging-genetics holds great promise for unraveling the complex
interplay between brain structure and genetic variation in neurological
disorders, traditional methods are limited to simplistic linear models or to
black-box techniques that lack interpretability. In this paper, we present
NeuroPathX, an explainable deep learning framework that uses an early fusion
strategy powered by cross-attention mechanisms to capture meaningful
interactions between structural variations in the brain derived from MRI and
established biological pathways derived from genetics data. To enhance
interpretability and robustness, we introduce two loss functions over the
attention matrix - a sparsity loss that focuses on the most salient
interactions and a pathway similarity loss that enforces consistent
representations across the cohort. We validate NeuroPathX on both autism
spectrum disorder and Alzheimer's disease. Our results demonstrate that
NeuroPathX outperforms competing baseline approaches and reveals biologically
plausible associations linked to the disorder. These findings underscore the
potential of NeuroPathX to advance our understanding of complex brain
disorders. Code is available at https://github.com/jueqiw/NeuroPathX .

</details>


### [87] [SALMAN: Stability Analysis of Language Models Through the Maps Between Graph-based Manifolds](https://arxiv.org/abs/2508.18306)
*Wuxinlin Cheng,Yupeng Cao,Jinwen Wu,Koduvayur Subbalakshmi,Tian Han,Zhuo Feng*

Main category: cs.LG

TL;DR: 提出了一种名为SALMAN的统一局部鲁棒性框架，用于评估模型稳定性，无需修改内部参数或复杂扰动启发式。


<details>
  <summary>Details</summary>
Motivation: 随着预训练语言模型规模和部署的增加，其输入扰动下的鲁棒性成为紧迫问题，现有方法在小模型和大模型之间差异大且依赖人工设计的对抗样本。

Method: 提出Distance Mapping Distortion (DMD)度量，通过比较输入到输出的距离映射以近线性复杂度排序样本易感性。

Result: 在攻击效率和鲁棒训练方面取得显著提升。

Conclusion: SALMAN框架是提升基于Transformer的NLP系统可靠性的实用、模型无关工具。

Abstract: Recent strides in pretrained transformer-based language models have propelled
state-of-the-art performance in numerous NLP tasks. Yet, as these models grow
in size and deployment, their robustness under input perturbations becomes an
increasingly urgent question. Existing robustness methods often diverge between
small-parameter and large-scale models (LLMs), and they typically rely on
labor-intensive, sample-specific adversarial designs. In this paper, we propose
a unified, local (sample-level) robustness framework (SALMAN) that evaluates
model stability without modifying internal parameters or resorting to complex
perturbation heuristics. Central to our approach is a novel Distance Mapping
Distortion (DMD) measure, which ranks each sample's susceptibility by comparing
input-to-output distance mappings in a near-linear complexity manner. By
demonstrating significant gains in attack efficiency and robust training, we
position our framework as a practical, model-agnostic tool for advancing the
reliability of transformer-based NLP systems.

</details>


### [88] [Learning Spatio-Temporal Dynamics via Operator-Valued RKHS and Kernel Koopman Methods](https://arxiv.org/abs/2508.18307)
*Mahishanka Withanachchi*

Main category: cs.LG

TL;DR: 提出了一种结合OV-RKHS和Koopman算子方法的统一框架，用于学习向量值函数的时空动态。


<details>
  <summary>Details</summary>
Motivation: 解决高维非线性系统中复杂时空动态的非参数化、数据驱动建模问题。

Method: 结合OV-RKHS和Koopman算子方法，建立时间依赖的插值表示定理，并推导Sobolev型近似边界。

Result: 实现了高效降阶建模和长期预测，提供理论支持的预测、控制和不确定性量化工具。

Conclusion: 该框架为时空机器学习提供了理论基础和实用工具，适用于复杂系统的建模与预测。

Abstract: We introduce a unified framework for learning the spatio-temporal dynamics of
vector valued functions by combining operator valued reproducing kernel Hilbert
spaces (OV-RKHS) with kernel based Koopman operator methods. The approach
enables nonparametric and data driven estimation of complex time evolving
vector fields while preserving both spatial and temporal structure. We
establish representer theorems for time dependent OV-RKHS interpolation, derive
Sobolev type approximation bounds for smooth vector fields, and provide
spectral convergence guarantees for kernel Koopman operator approximations.
This framework supports efficient reduced order modeling and long term
prediction of high dimensional nonlinear systems, offering theoretically
grounded tools for forecasting, control, and uncertainty quantification in
spatio- temporal machine learning.

</details>


### [89] [CoPE: A Lightweight Complex Positional Encoding](https://arxiv.org/abs/2508.18308)
*Avinash Amballa*

Main category: cs.LG

TL;DR: CoPE是一种轻量级复杂位置编码方法，通过复数编码同时捕捉内容和位置信息，性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统位置编码方法在建模序列元素间依赖关系时存在局限性，需要更高效且兼容性强的方法。

Method: 提出CoPE，使用复数嵌入（实部为语义内容，虚部为位置信息），并在第一层引入相位感知注意力。

Result: 在GLUE基准测试中表现优异，计算复杂度更低，且兼容线性注意力。

Conclusion: CoPE是一种高效且兼容性强的位置编码方法，适用于Transformer架构。

Abstract: Recent studies have demonstrated the effectiveness of position encoding in
transformer architectures. By incorporating positional information, this
approach provides essential guidance for modeling dependencies between elements
across different sequence positions. We introduce CoPE (a lightweight Complex
Positional Encoding), a novel architecture that leverages complex-valued
encoding to encode both content and positional information. Our approach
replaces traditional positional encodings with complex embeddings where the
real part captures semantic content and the imaginary part encodes positional
information. We introduce phase-aware attention in the first layer of the
transformer model to capture position-dependent patterns, followed by standard
attention layers for higher-levels. We show that CoPE doesn't exhibit long term
decay and is compatible with linear attention. Experimental evaluation on the
GLUE benchmark suggest that our approach achieves superior performance with
less computational complexity, compared to RoPE, Sinusoidal and Learned
positional encodings.

</details>


### [90] [What Matters in Data for DPO?](https://arxiv.org/abs/2508.18312)
*Yu Pan,Zhongze Cai,Guanting Chen,Huaiyang Zhong,Chonghuan Wang*

Main category: cs.LG

TL;DR: DPO性能主要依赖于偏好数据中被选回答的质量，而被拒绝回答的质量影响较小。理论分析揭示了对比性如何通过提升被选样本来优化目标，实验验证了这一点。


<details>
  <summary>Details</summary>
Motivation: 研究偏好数据分布如何影响DPO的性能，以指导构建更高效的偏好数据集。

Method: 通过理论和实证分析，探讨被选和被拒绝回答质量对DPO的影响，并研究在线DPO设置。

Result: 被选回答质量对DPO性能起主导作用，被拒绝回答质量影响有限；在线DPO可简化为对被选回答的监督微调。

Conclusion: 构建偏好数据集时应优先提升被选回答质量，混合策略数据可能带来额外收益。

Abstract: Direct Preference Optimization (DPO) has emerged as a simple and effective
approach for aligning large language models (LLMs) with human preferences,
bypassing the need for a learned reward model. Despite its growing adoption, a
fundamental question remains open: what characteristics of preference data are
most critical for DPO performance? In this work, we provide a systematic study
of how preference data distribution influences DPO, from both theoretical and
empirical perspectives. We show that the quality of chosen responses plays a
dominant role in optimizing the DPO objective, while the quality of rejected
responses may have relatively limited impact. Our theoretical analysis
characterizes the optimal response distribution under DPO and reveals how
contrastiveness between responses helps primarily by improving the chosen
samples. We further study an online DPO setting and show it effectively reduces
to supervised fine-tuning on the chosen responses. Extensive experiments across
diverse tasks confirm our findings: improving the quality of chosen responses
consistently boosts performance regardless of the quality of the rejected
responses. We also investigate the benefit of mixing the on-policy data. Our
results interpret the mechanism behind some widely adopted strategies and offer
practical insights for constructing high-impact preference datasets for LLM
alignment.

</details>


### [91] [ProtoEHR: Hierarchical Prototype Learning for EHR-based Healthcare Predictions](https://arxiv.org/abs/2508.18313)
*Zi Cai,Yu Liu,Zhiyao Luo,Tingting Zhu*

Main category: cs.LG

TL;DR: ProtoEHR是一个可解释的分层原型学习框架，利用EHR数据的多层次结构提升医疗预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究常孤立处理EHR数据，限制了预测性能和可解释性。

Method: ProtoEHR通过构建医学知识图谱，设计分层表示学习框架，捕捉EHR数据的多层次关系。

Result: 在五个临床任务中，ProtoEHR表现优于基线方法，并提供可解释的预测。

Conclusion: ProtoEHR能够实现准确、鲁棒且可解释的医疗预测，同时提供多层次洞察。

Abstract: Digital healthcare systems have enabled the collection of mass healthcare
data in electronic healthcare records (EHRs), allowing artificial intelligence
solutions for various healthcare prediction tasks. However, existing studies
often focus on isolated components of EHR data, limiting their predictive
performance and interpretability. To address this gap, we propose ProtoEHR, an
interpretable hierarchical prototype learning framework that fully exploits the
rich, multi-level structure of EHR data to enhance healthcare predictions. More
specifically, ProtoEHR models relationships within and across three
hierarchical levels of EHRs: medical codes, hospital visits, and patients. We
first leverage large language models to extract semantic relationships among
medical codes and construct a medical knowledge graph as the knowledge source.
Building on this, we design a hierarchical representation learning framework
that captures contextualized representations across three levels, while
incorporating prototype information within each level to capture intrinsic
similarities and improve generalization. To perform a comprehensive assessment,
we evaluate ProtoEHR in two public datasets on five clinically significant
tasks, including prediction of mortality, prediction of readmission, prediction
of length of stay, drug recommendation, and prediction of phenotype. The
results demonstrate the ability of ProtoEHR to make accurate, robust, and
interpretable predictions compared to baselines in the literature. Furthermore,
ProtoEHR offers interpretable insights on code, visit, and patient levels to
aid in healthcare prediction.

</details>


### [92] [Evaluating Federated Learning for At-Risk Student Prediction: A Comparative Analysis of Model Complexity and Data Balancing](https://arxiv.org/abs/2508.18316)
*Rodrigo Tertulino*

Main category: cs.LG

TL;DR: 该研究开发了一个基于联邦学习的机器学习模型，用于预测远程教育中的高风险学生，解决了数据隐私和机构孤岛问题，并取得了85%的ROC AUC分数。


<details>
  <summary>Details</summary>
Motivation: 远程教育中的高退学率和失败率对学术机构构成挑战，需要及时识别高风险学生以提供支持。

Method: 使用OULAD数据集，基于早期学术表现和数字参与模式，采用联邦学习框架（逻辑回归和深度神经网络）进行模型开发。

Result: 联邦学习模型在识别高风险学生方面表现出色，ROC AUC分数约为85%。

Conclusion: 联邦学习方法为机构提供了一种实用且可扩展的解决方案，既能有效预警，又能保护数据隐私。

Abstract: High dropout and failure rates in distance education pose a significant
challenge for academic institutions, making the proactive identification of
at-risk students crucial for providing timely support. This study develops and
evaluates a machine learning model based on early academic performance and
digital engagement patterns from the large-scale OULAD dataset to predict
student risk at a UK university. To address the practical challenges of data
privacy and institutional silos that often hinder such initiatives, we
implement the model using a Federated Learning (FL) framework. We compare model
complexity (Logistic Regression vs. a Deep Neural Network) and data balancing.
The final federated model demonstrates strong predictive capability, achieving
an ROC AUC score of approximately 85% in identifying at-risk students. Our
findings show that this federated approach provides a practical and scalable
solution for institutions to build effective early-warning systems, enabling
proactive student support while inherently respecting data privacy.

</details>


### [93] [ZTFed-MAS2S: A Zero-Trust Federated Learning Framework with Verifiable Privacy and Trust-Aware Aggregation for Wind Power Data Imputation](https://arxiv.org/abs/2508.18318)
*Yang Li,Hanjie Wang,Yuanzheng Li,Jiazheng Li,Zhaoyang Dong*

Main category: cs.LG

TL;DR: ZTFed-MAS2S是一个零信任联邦学习框架，结合多头注意力序列到序列模型，用于风电数据缺失值填补，同时确保隐私保护和参数传输安全。


<details>
  <summary>Details</summary>
Motivation: 风电数据常因传感器故障和传输不稳定而缺失，联邦学习虽保护隐私但易受异常更新和隐私泄露影响，需零信任机制。

Method: 整合可验证差分隐私、非交互零知识证明和动态信任感知聚合机制，结合MAS2S模型填补缺失数据。

Result: 在真实风电数据集上验证了ZTFed-MAS2S在联邦学习和数据填补上的优越性。

Conclusion: ZTFed-MAS2S是能源领域安全高效的解决方案。

Abstract: Wind power data often suffers from missing values due to sensor faults and
unstable transmission at edge sites. While federated learning enables
privacy-preserving collaboration without sharing raw data, it remains
vulnerable to anomalous updates and privacy leakage during parameter exchange.
These challenges are amplified in open industrial environments, necessitating
zero-trust mechanisms where no participant is inherently trusted. To address
these challenges, this work proposes ZTFed-MAS2S, a zero-trust federated
learning framework that integrates a multi-head attention-based
sequence-to-sequence imputation model. ZTFed integrates verifiable differential
privacy with non-interactive zero-knowledge proofs and a confidentiality and
integrity verification mechanism to ensure verifiable privacy preservation and
secure model parameters transmission. A dynamic trust-aware aggregation
mechanism is employed, where trust is propagated over similarity graphs to
enhance robustness, and communication overhead is reduced via sparsity- and
quantization-based compression. MAS2S captures long-term dependencies in wind
power data for accurate imputation. Extensive experiments on real-world wind
farm datasets validate the superiority of ZTFed-MAS2S in both federated
learning performance and missing data imputation, demonstrating its
effectiveness as a secure and efficient solution for practical applications in
the energy sector.

</details>


### [94] [Linear cost mutual information estimation and independence test of similar performance as HSIC](https://arxiv.org/abs/2508.18338)
*Jarek Duda,Jagoda Bracha,Adrian Przybysz*

Main category: cs.LG

TL;DR: HCR（分层相关重建）是一种线性成本的方法，用于替代HSIC，具有更高的依赖性敏感性，并能提供联合分布模型。


<details>
  <summary>Details</summary>
Motivation: HSIC虽然是最先进的方法，但其计算复杂度高（O(n^2.37)），不适用于大规模数据样本。

Method: HCR通过描述依赖关系的特征（如混合矩）来构建联合分布模型，计算单个特征的时间为O(n)。

Result: HCR在测试中表现出更高的依赖性敏感性，并能近似互信息。

Conclusion: HCR是一种高效且实用的替代方法，适用于大规模数据样本的依赖性分析。

Abstract: Evaluation of statistical dependencies between two data samples is a basic
problem of data science/machine learning, and HSIC (Hilbert-Schmidt Information
Criterion)~\cite{HSIC} is considered the state-of-art method. However, for size
$n$ data sample it requires multiplication of $n\times n$ matrices, what
currently needs $\sim O(n^{2.37})$ computational complexity~\cite{mult}, making
it impractical for large data samples. We discuss HCR (Hierarchical Correlation
Reconstruction) as its linear cost practical alternative of even higher
dependence sensitivity in tests, and additionally providing actual joint
distribution model by description of dependencies through features being mixed
moments, starting with correlation and homoscedasticity, also allowing to
approximate mutual information as just sum of squares of such nontrivial mixed
moments between two data samples. Such single dependence describing feature is
calculated in $O(n)$ linear time. Their number to test varies with dimension
$d$ - requiring $O(d^2)$ for pairwise dependencies, $O(d^3)$ if wanting to also
consider more subtle triplewise, and so on.

</details>


### [95] [DualSparse-MoE: Coordinating Tensor/Neuron-Level Sparsity with Expert Partition and Reconstruction](https://arxiv.org/abs/2508.18376)
*Weilin Cai,Le Qin,Shwai He,Junwei Cui,Ang Li,Jiayi Huang*

Main category: cs.LG

TL;DR: 论文提出DualSparse-MoE系统，通过后训练专家分区和动态计算丢弃，显著提升MoE模型的效率，同时保持高精度。


<details>
  <summary>Details</summary>
Motivation: MoE架构虽能减少计算量，但仍面临大规模计算和不可预测激活模式的挑战。

Method: 通过后训练专家分区引入张量和神经元级别的双重稀疏性，结合动态计算丢弃和静态神经元重建。

Result: 实验显示，25%的计算丢弃仅导致0.08%-0.28%的精度损失，计算速度显著提升。

Conclusion: DualSparse-MoE在效率和精度间取得平衡，适用于大规模MoE模型部署。

Abstract: Mixture of Experts (MoE) has become a mainstream architecture for building
Large Language Models (LLMs) by reducing per-token computation while enabling
model scaling. It can be viewed as partitioning a large Feed-Forward Network
(FFN) at the tensor level into fine-grained sub-FFNs, or experts, and
activating only a sparse subset for each input. While this sparsity improves
efficiency, MoE still faces substantial challenges due to their massive
computational scale and unpredictable activation patterns.
  To enable efficient MoE deployment, we identify dual sparsity at the tensor
and neuron levels in pre-trained MoE modules as a key factor for both accuracy
and efficiency. Unlike prior work that increases tensor-level sparsity through
finer-grained expert design during pre-training, we introduce post-training
expert partitioning to induce such sparsity without retraining. This preserves
the mathematical consistency of model transformations and enhances both
efficiency and accuracy in subsequent fine-tuning and inference. Building upon
this, we propose DualSparse-MoE, an inference system that integrates dynamic
tensor-level computation dropping with static neuron-level reconstruction to
deliver significant efficiency gains with minimal accuracy loss.
  Experimental results show that enforcing an approximate 25% drop rate with
our approach reduces average accuracy by only 0.08%-0.28% across three
prevailing MoE models, while nearly all degrees of computation dropping
consistently yield proportional computational speedups. Furthermore,
incorporating load-imbalance awareness into expert parallelism achieves a 1.41x
MoE module speedup with just 0.5% average accuracy degradation.

</details>


### [96] [Low-Rank Tensor Decompositions for the Theory of Neural Networks](https://arxiv.org/abs/2508.18408)
*Ricardo Borsoi,Konstantin Usevich,Marianne Clausel*

Main category: cs.LG

TL;DR: 论文综述了低秩张量分解在深度学习理论中的基础作用，解释了深度神经网络的表达能力、可学习性、计算复杂性、泛化性和可识别性。


<details>
  <summary>Details</summary>
Motivation: 为深度学习理论提供数学基础，利用低秩张量分解与神经网络的紧密联系及其丰富的理论成果。

Method: 通过综述不同社区（计算机科学、数学等）的现有方法，以统一的方式展示低秩张量分解的应用。

Result: 低秩张量分解在解释深度神经网络的多个理论方面发挥了核心作用。

Conclusion: 低秩张量分解为深度神经网络理论提供了重要工具，并有望在更广泛的视角下推动该领域的发展。

Abstract: The groundbreaking performance of deep neural networks (NNs) promoted a surge
of interest in providing a mathematical basis to deep learning theory. Low-rank
tensor decompositions are specially befitting for this task due to their close
connection to NNs and their rich theoretical results. Different tensor
decompositions have strong uniqueness guarantees, which allow for a direct
interpretation of their factors, and polynomial time algorithms have been
proposed to compute them. Through the connections between tensors and NNs, such
results supported many important advances in the theory of NNs. In this review,
we show how low-rank tensor methods--which have been a core tool in the signal
processing and machine learning communities--play a fundamental role in
theoretically explaining different aspects of the performance of deep NNs,
including their expressivity, algorithmic learnability and computational
hardness, generalization, and identifiability. Our goal is to give an
accessible overview of existing approaches (developed by different communities,
ranging from computer science to mathematics) in a coherent and unified way,
and to open a broader perspective on the use of low-rank tensor decompositions
for the theory of deep NNs.

</details>


### [97] [LLM-Driven Intrinsic Motivation for Sparse Reward Reinforcement Learning](https://arxiv.org/abs/2508.18420)
*André Quadros,Cassio Silva,Ronnie Alves*

Main category: cs.LG

TL;DR: 结合两种内在激励策略（VSIMR和LLM）提升稀疏奖励环境中强化学习效率，效果显著优于单独策略或标准A2C。


<details>
  <summary>Details</summary>
Motivation: 解决稀疏奖励环境中传统强化学习因反馈稀少而效率低下的问题。

Method: 整合VSIMR（基于VAE的状态新颖性奖励）和LLM（基于预训练知识的奖励生成），在MiniGrid DoorKey环境中用A2C实现。

Result: 组合策略显著提升性能和采样效率，优于单独策略或标准A2C。

Conclusion: VSIMR促进探索新状态，LLM奖励引导目标达成，两者互补提升学习效果。

Abstract: This paper explores the combination of two intrinsic motivation strategies to
improve the efficiency of reinforcement learning (RL) agents in environments
with extreme sparse rewards, where traditional learning struggles due to
infrequent positive feedback. We propose integrating Variational State as
Intrinsic Reward (VSIMR), which uses Variational AutoEncoders (VAEs) to reward
state novelty, with an intrinsic reward approach derived from Large Language
Models (LLMs). The LLMs leverage their pre-trained knowledge to generate reward
signals based on environment and goal descriptions, guiding the agent. We
implemented this combined approach with an Actor-Critic (A2C) agent in the
MiniGrid DoorKey environment, a benchmark for sparse rewards. Our empirical
results show that this combined strategy significantly increases agent
performance and sampling efficiency compared to using each strategy
individually or a standard A2C agent, which failed to learn. Analysis of
learning curves indicates that the combination effectively complements
different aspects of the environment and task: VSIMR drives exploration of new
states, while the LLM-derived rewards facilitate progressive exploitation
towards goals.

</details>


### [98] [Enhancing Trust-Region Bayesian Optimization via Newton Methods](https://arxiv.org/abs/2508.18423)
*Quanlin Chen,Yiyu Chen,Jing Huo,Tianyu Ding,Yang Gao,Yuetong Chen*

Main category: cs.LG

TL;DR: 提出一种基于全局高斯过程的多局部二次模型方法，提升高维贝叶斯优化的采样效率和性能。


<details>
  <summary>Details</summary>
Motivation: 解决高维空间中贝叶斯优化的挑战，尤其是局部高斯过程采样效率低的问题。

Method: 利用全局高斯过程的梯度和Hessian构建多个局部二次模型，通过求解约束二次规划选择新样本点。

Result: 实验证明该方法提升了TuRBO的效能，并在合成函数和实际应用中优于多种高维贝叶斯优化技术。

Conclusion: 该方法在保持异质建模的同时提高了采样效率，适用于高维贝叶斯优化问题。

Abstract: Bayesian Optimization (BO) has been widely applied to optimize expensive
black-box functions while retaining sample efficiency. However, scaling BO to
high-dimensional spaces remains challenging. Existing literature proposes
performing standard BO in multiple local trust regions (TuRBO) for
heterogeneous modeling of the objective function and avoiding over-exploration.
Despite its advantages, using local Gaussian Processes (GPs) reduces sampling
efficiency compared to a global GP. To enhance sampling efficiency while
preserving heterogeneous modeling, we propose to construct multiple local
quadratic models using gradients and Hessians from a global GP, and select new
sample points by solving the bound-constrained quadratic program. Additionally,
we address the issue of vanishing gradients of GPs in high-dimensional spaces.
We provide a convergence analysis and demonstrate through experimental results
that our method enhances the efficacy of TuRBO and outperforms a wide range of
high-dimensional BO techniques on synthetic functions and real-world
applications.

</details>


### [99] [VERIRL: Boosting the LLM-based Verilog Code Generation via Reinforcement Learning](https://arxiv.org/abs/2508.18462)
*Fu Teng,Miao Pan,Xuhong Zhang,Zhezhi He,Yiyao Yang,Xinyi Chai,Mengnan Qi,Liqiang Lu,Jianwei Yin*

Main category: cs.LG

TL;DR: 论文提出了一种针对Verilog代码生成的强化学习框架，通过高质量数据集和创新的奖励机制，显著提升了生成代码的性能。


<details>
  <summary>Details</summary>
Motivation: 硬件描述语言（如Verilog）由于并发语义、语法严格性和仿真复杂性，在代码生成领域研究较少。论文旨在解决这些问题。

Method: 构建了Veribench-53K数据集，提出Trace-back based Rescore机制和样本平衡加权策略，结合强化学习优化代码生成。

Result: 在Verilog生成任务中实现了最先进的性能，测试通过率、功能正确性和编译鲁棒性均有显著提升。

Conclusion: 研究表明，强化学习方法在硬件领域的结构化代码生成中具有巨大潜力。

Abstract: Recent advancements in code generation have shown remarkable success across
software domains, yet hardware description languages (HDLs) such as Verilog
remain underexplored due to their concurrency semantics, syntactic rigidity,
and simulation complexity. In this work, we address these challenges by
introducing a reinforcement learning (RL) framework tailored for Verilog code
generation. We first construct Veribench-53K, a high-quality dataset curated
from over 700K Verilog problems, enriched with structured prompts, complexity
labels, and diverse testbenches. To tackle the problem of sparse and noisy
reward signals, we propose a Trace-back based Rescore mechanism that leverages
reasoning paths and iterative refinement to enhance feedback reliability and
support reward model training. Furthermore, to mitigate catastrophic forgetting
and overfitting during RL fine-tuning, we introduce a sample-balanced weighting
strategy that adaptively balances learning dynamics based on reward-probability
distributions. These innovations are integrated into an iterative RL pipeline
that co-evolves the policy and reward models. In contrast to recent work such
as CraftRTL, which relies on large-scale closed-source model distillation, and
DeepSeek-style approaches that struggle with sparse feedback, our method
demonstrates superior performance using a smaller but high-quality dataset
combined with RL optimization. Experiments on Verilog generation tasks
demonstrate state-of-the-art performance, with substantial gains in test pass
rate, functional correctness, and compilation robustness. Our findings
highlight the potential of RL-driven approaches for structured code generation
in hardware-centric domains. VERIRL is publicly available at
https://github.com/omniAI-Lab/VeriRL.

</details>


### [100] [DRTA: Dynamic Reward Scaling for Reinforcement Learning in Time Series Anomaly Detection](https://arxiv.org/abs/2508.18474)
*Bahareh Golchin,Banafsheh Rekabdar,Kunpeng Liu*

Main category: cs.LG

TL;DR: 提出了一种基于强化学习的异常检测框架DRTA，结合动态奖励调整、变分自编码器和主动学习，有效解决传统方法在低标签系统中的问题。


<details>
  <summary>Details</summary>
Motivation: 传统异常检测方法在有限标签数据、高误报率和泛化能力不足方面表现不佳，需要更高效的解决方案。

Method: 使用动态奖励机制平衡探索与利用，结合VAE重建误差和分类奖励，提升异常检测性能。

Result: 在Yahoo A1和A2数据集上表现优于现有无监督和半监督方法，展示了高精度和召回率。

Conclusion: DRTA框架是一种可扩展且高效的异常检测解决方案，适用于实际应用场景。

Abstract: Anomaly detection in time series data is important for applications in
finance, healthcare, sensor networks, and industrial monitoring. Traditional
methods usually struggle with limited labeled data, high false-positive rates,
and difficulty generalizing to novel anomaly types. To overcome these
challenges, we propose a reinforcement learning-based framework that integrates
dynamic reward shaping, Variational Autoencoder (VAE), and active learning,
called DRTA. Our method uses an adaptive reward mechanism that balances
exploration and exploitation by dynamically scaling the effect of VAE-based
reconstruction error and classification rewards. This approach enables the
agent to detect anomalies effectively in low-label systems while maintaining
high precision and recall. Our experimental results on the Yahoo A1 and Yahoo
A2 benchmark datasets demonstrate that the proposed method consistently
outperforms state-of-the-art unsupervised and semi-supervised approaches. These
findings show that our framework is a scalable and efficient solution for
real-world anomaly detection tasks.

</details>


### [101] [Data Augmentation Improves Machine Unlearning](https://arxiv.org/abs/2508.18502)
*Andreza M. C. Falcao,Filipe R. Cordeiro*

Main category: cs.LG

TL;DR: 研究了数据增强策略对机器遗忘（MU）性能的影响，发现适当的增强设计可显著提高遗忘效果。


<details>
  <summary>Details</summary>
Motivation: 探索数据增强在机器遗忘中的作用，填补现有研究的空白。

Method: 在CIFAR-10和CIFAR-100数据集上测试不同增强策略（如TrivialAug）对SalUn、Random Label和Fine-Tuning等遗忘方法的影响。

Result: 使用TrivialAug增强时，平均遗忘指标差距减少高达40.12%，接近重新训练模型的性能。

Conclusion: 数据增强不仅减少记忆，还对实现隐私保护和高效遗忘至关重要。

Abstract: Machine Unlearning (MU) aims to remove the influence of specific data from a
trained model while preserving its performance on the remaining data. Although
a few works suggest connections between memorisation and augmentation, the role
of systematic augmentation design in MU remains under-investigated. In this
work, we investigate the impact of different data augmentation strategies on
the performance of unlearning methods, including SalUn, Random Label, and
Fine-Tuning. Experiments conducted on CIFAR-10 and CIFAR-100, under varying
forget rates, show that proper augmentation design can significantly improve
unlearning effectiveness, reducing the performance gap to retrained models.
Results showed a reduction of up to 40.12% of the Average Gap unlearning
Metric, when using TrivialAug augmentation. Our results suggest that
augmentation not only helps reduce memorization but also plays a crucial role
in achieving privacy-preserving and efficient unlearning.

</details>


### [102] [Breaking Through Barren Plateaus: Reinforcement Learning Initializations for Deep Variational Quantum Circuits](https://arxiv.org/abs/2508.18514)
*Yifeng Peng,Xinyi Li,Zhemin Zhang,Samuel Yen-Chi Chen,Zhiding Liang,Ying Wang*

Main category: cs.LG

TL;DR: 提出了一种基于强化学习的初始化策略，用于缓解变分量子算法中的贫瘠高原问题，显著提升了收敛速度和最终解质量。


<details>
  <summary>Details</summary>
Motivation: 变分量子算法（VQAs）在近量子设备应用中表现突出，但贫瘠高原问题限制了其有效性，导致梯度消失。

Method: 采用多种强化学习算法（如确定性策略梯度、软演员-评论家等）生成电路参数，作为梯度优化前的初始化策略。

Result: 实验表明，该方法在不同噪声条件和任务下显著提升了收敛速度和最终解质量。

Conclusion: 强化学习驱动的参数初始化为量子算法设计提供了新思路，有望加速VQAs的扩展和实际部署。

Abstract: Variational Quantum Algorithms (VQAs) have gained prominence as a viable
framework for exploiting near-term quantum devices in applications ranging from
optimization and chemistry simulation to machine learning. However, the
effectiveness of VQAs is often constrained by the so-called barren plateau
problem, wherein gradients diminish exponentially as system size or circuit
depth increases, thereby hindering training. In this work, we propose a
reinforcement learning (RL)-based initialization strategy to alleviate the
barren plateau issue by reshaping the initial parameter landscape to avoid
regions prone to vanishing gradients. In particular, we explore several RL
algorithms (Deterministic Policy Gradient, Soft Actor-Critic, and Proximal
Policy Optimization, etc.) to generate the circuit parameters (treated as
actions) that minimize the VQAs cost function before standard gradient-based
optimization. By pre-training with RL in this manner, subsequent optimization
using methods such as gradient descent or Adam proceeds from a more favorable
initial state. Extensive numerical experiments under various noise conditions
and tasks consistently demonstrate that the RL-based initialization method
significantly enhances both convergence speed and final solution quality.
Moreover, comparisons among different RL algorithms highlight that multiple
approaches can achieve comparable performance gains, underscoring the
flexibility and robustness of our method. These findings shed light on a
promising avenue for integrating machine learning techniques into quantum
algorithm design, offering insights into how RL-driven parameter initialization
can accelerate the scalability and practical deployment of VQAs. Opening up a
promising path for the research community in machine learning for quantum,
especially barren plateau problems in VQAs.

</details>


### [103] [Quantifying The Limits of AI Reasoning: Systematic Neural Network Representations of Algorithms](https://arxiv.org/abs/2508.18526)
*Anastasis Kratsios,Dennis Zvigelsky,Bradd Hart*

Main category: cs.LG

TL;DR: 论文提出了一种将任意电路转换为ReLU激活的前馈神经网络的方法，证明了神经网络可以精确模拟任何推理任务。


<details>
  <summary>Details</summary>
Motivation: 解决神经网络在完美训练下能执行何种形式推理的开放性问题。

Method: 通过将推理任务视为电路模拟，提出一种元算法，将电路转换为ReLU神经网络。

Result: 神经网络可以精确模拟电路，包括布尔逻辑、动态规划等复杂推理任务。

Conclusion: 神经网络的推理能力不受限制，且其能力超越经典通用逼近定理。

Abstract: A main open question in contemporary AI research is quantifying the forms of
reasoning neural networks can perform when perfectly trained. This paper
answers this by interpreting reasoning tasks as circuit emulation, where the
gates define the type of reasoning; e.g. Boolean gates for predicate logic,
tropical circuits for dynamic programming, arithmetic and analytic gates for
symbolic mathematical representation, and hybrids thereof for deeper reasoning;
e.g. higher-order logic.
  We present a systematic meta-algorithm that converts essentially any circuit
into a feedforward neural network (NN) with ReLU activations by iteratively
replacing each gate with a canonical ReLU MLP emulator. We show that, on any
digital computer, our construction emulates the circuit exactly--no
approximation, no rounding, modular overflow included--demonstrating that no
reasoning task lies beyond the reach of neural networks. The number of neurons
in the resulting network (parametric complexity) scales with the circuit's
complexity, and the network's computational graph (structure) mirrors that of
the emulated circuit. This formalizes the folklore that NNs networks trade
algorithmic run-time (circuit runtime) for space complexity (number of
neurons).
  We derive a range of applications of our main result, from emulating
shortest-path algorithms on graphs with cubic--size NNs, to simulating stopped
Turing machines with roughly quadratically--large NNs, and even the emulation
of randomized Boolean circuits. Lastly, we demonstrate that our result is
strictly more powerful than a classical universal approximation theorem: any
universal function approximator can be encoded as a circuit and directly
emulated by a NN.

</details>


### [104] [BTW: A Non-Parametric Variance Stabilization Framework for Multimodal Model Integration](https://arxiv.org/abs/2508.18551)
*Jun Hou,Le Wang,Xuan Wang*

Main category: cs.LG

TL;DR: BTW框架通过KL散度和互信息动态调整多模态训练中的模态重要性，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 多模态学习中，额外模态可能引入噪声而非互补信息，现有方法难以扩展且缺乏实例级控制。

Method: 提出BTW框架，结合实例级KL散度和模态级互信息，无参动态调整模态重要性。

Result: 在情感回归和临床分类任务中显著提升回归性能和分类准确率。

Conclusion: BTW框架有效解决了多模态噪声问题，适用于任意数量模态且无需额外参数。

Abstract: Mixture-of-Experts (MoE) models have become increasingly powerful in
multimodal learning by enabling modular specialization across modalities.
However, their effectiveness remains unclear when additional modalities
introduce more noise than complementary information. Existing approaches, such
as the Partial Information Decomposition, struggle to scale beyond two
modalities and lack the resolution needed for instance-level control. We
propose Beyond Two-modality Weighting (BTW), a bi-level, non-parametric
weighting framework that combines instance-level Kullback-Leibler (KL)
divergence and modality-level mutual information (MI) to dynamically adjust
modality importance during training. Our method does not require additional
parameters and can be applied to an arbitrary number of modalities.
Specifically, BTW computes per-example KL weights by measuring the divergence
between each unimodal and the current multimodal prediction, and modality-wide
MI weights by estimating global alignment between unimodal and multimodal
outputs. Extensive experiments on sentiment regression and clinical
classification demonstrate that our method significantly improves regression
performance and multiclass classification accuracy.

</details>


### [105] [Enhancing Chemical Explainability Through Counterfactual Masking](https://arxiv.org/abs/2508.18561)
*Łukasz Janisiów,Marek Kochańczyk,Bartosz Zieliński,Tomasz Danel*

Main category: cs.LG

TL;DR: 提出了一种名为“反事实掩码”的新框架，通过生成模型替换掩码子结构，提供更直观和化学合理的解释。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖掩码策略，但往往不符合分子分布，导致解释不直观。

Method: 使用生成模型生成化学合理的片段替换掩码子结构，评估反事实分子的预测。

Result: 方法在多个数据集和任务中表现优异，提供更可靠的解释和可操作的见解。

Conclusion: 反事实掩码填补了解释性与分子设计之间的空白，为化学中的可解释机器学习提供了新路径。

Abstract: Molecular property prediction is a crucial task that guides the design of new
compounds, including drugs and materials. While explainable artificial
intelligence methods aim to scrutinize model predictions by identifying
influential molecular substructures, many existing approaches rely on masking
strategies that remove either atoms or atom-level features to assess importance
via fidelity metrics. These methods, however, often fail to adhere to the
underlying molecular distribution and thus yield unintuitive explanations. In
this work, we propose counterfactual masking, a novel framework that replaces
masked substructures with chemically reasonable fragments sampled from
generative models trained to complete molecular graphs. Rather than evaluating
masked predictions against implausible zeroed-out baselines, we assess them
relative to counterfactual molecules drawn from the data distribution. Our
method offers two key benefits: (1) molecular realism underpinning robust and
distribution-consistent explanations, and (2) meaningful counterfactuals that
directly indicate how structural modifications may affect predicted properties.
We demonstrate that counterfactual masking is well-suited for benchmarking
model explainers and yields more actionable insights across multiple datasets
and property prediction tasks. Our approach bridges the gap between
explainability and molecular design, offering a principled and generative path
toward explainable machine learning in chemistry.

</details>


### [106] [A Note on Graphon-Signal Analysis of Graph Neural Networks](https://arxiv.org/abs/2508.18564)
*Levi Rauchwerger,Ron Levie*

Main category: cs.LG

TL;DR: 本文对Levie的图神经网络（MPNNs）分析进行了改进和扩展，解决了原论文在实际应用中的局限性。


<details>
  <summary>Details</summary>
Motivation: 原论文在分析MPNNs时存在一些不足，限制了其在图机器学习实际场景中的应用。本文旨在通过扩展和改进现有结果来解决这些问题。

Method: 1) 将主要结果扩展到多维信号；2) 扩展Lipschitz连续性到带readout的MPNNs；3) 利用鲁棒性泛化界改进泛化边界；4) 扩展到非对称图核。

Result: 通过上述改进，提升了MPNNs的理论分析和实际应用能力。

Conclusion: 本文的扩展和改进填补了原论文的不足，为图神经网络的实际应用提供了更全面的理论支持。

Abstract: A recent paper, ``A Graphon-Signal Analysis of Graph Neural Networks'', by
Levie, analyzed message passing graph neural networks (MPNNs) by embedding the
input space of MPNNs, i.e., attributed graphs (graph-signals), to a space of
attributed graphons (graphon-signals). Based on extensions of standard results
in graphon analysis to graphon-signals, the paper proved a generalization bound
and a sampling lemma for MPNNs. However, there are some missing ingredients in
that paper, limiting its applicability in practical settings of graph machine
learning. In the current paper, we introduce several refinements and extensions
to existing results that address these shortcomings. In detail, 1) we extend
the main results in the paper to graphon-signals with multidimensional signals
(rather than 1D signals), 2) we extend the Lipschitz continuity to MPNNs with
readout with respect to cut distance (rather than MPNNs without readout with
respect to cut metric), 3) we improve the generalization bound by utilizing
robustness-type generalization bounds, and 4) we extend the analysis to
non-symmetric graphons and kernels.

</details>


### [107] [Improving Long-term Autoregressive Spatiotemporal Predictions: A Proof of Concept with Fluid Dynamics](https://arxiv.org/abs/2508.18565)
*Hao Zhou,Sibo Cheng*

Main category: cs.LG

TL;DR: SPF框架通过补充数据集和随机获取策略，平衡短期和长期预测性能，降低内存需求。


<details>
  <summary>Details</summary>
Motivation: 传统数据驱动方法在复杂系统中长期预测准确性下降，且自回归训练内存需求高。

Method: SPF框架通过补充模型预测数据集，结合随机获取策略，实现多步学习。

Result: 在Burgers方程和浅水基准测试中，SPF比自回归方法长期准确性更高且内存需求更低。

Conclusion: SPF适用于资源有限和复杂系统模拟，具有高效性和准确性。

Abstract: Data-driven methods are emerging as efficient alternatives to traditional
numerical forecasting, offering fast inference and lower computational cost.
Yet, for complex systems, long-term accuracy often deteriorates due to error
accumulation, and autoregressive training (though effective) demands large GPU
memory and may sacrifice short-term performance. We propose the Stochastic
PushForward (SPF) framework, which retains one-step-ahead training while
enabling multi-step learning. SPF builds a supplementary dataset from model
predictions and combines it with ground truth via a stochastic acquisition
strategy, balancing short- and long-term performance while reducing
overfitting. Multi-step predictions are precomputed between epochs, keeping
memory usage stable without storing full unrolled sequences. Experiments on the
Burgers' equation and the Shallow Water benchmark show that SPF achieves higher
long-term accuracy than autoregressive methods while lowering memory
requirements, making it promising for resource-limited and complex simulations.

</details>


### [108] [Sparse Autoencoders for Low-$N$ Protein Function Prediction and Design](https://arxiv.org/abs/2508.18567)
*Darin Tsui,Kunal Talreja,Amirali Aghazadeh*

Main category: cs.LG

TL;DR: 论文研究了稀疏自编码器（SAEs）在低数据量（low-$N$）蛋白质功能预测和设计中的表现，发现SAEs在少量数据下优于或与ESM2基线模型相当。


<details>
  <summary>Details</summary>
Motivation: 解决在数据稀缺情况下蛋白质功能预测和设计的挑战，探索SAEs在低数据量下的有效性。

Method: 使用基于ESM2嵌入的SAEs，评估其在多种任务中的表现，包括适应度预测和蛋白质工程。

Result: SAEs在仅24个序列的情况下，表现优于或与ESM2基线相当，且其稀疏潜在空间能更有效地从有限数据中泛化。

Conclusion: SAEs在低数据量下表现优异，其潜在空间能捕捉生物相关特征，为蛋白质设计提供更优方案。

Abstract: Predicting protein function from amino acid sequence remains a central
challenge in data-scarce (low-$N$) regimes, limiting machine learning-guided
protein design when only small amounts of assay-labeled sequence-function data
are available. Protein language models (pLMs) have advanced the field by
providing evolutionary-informed embeddings and sparse autoencoders (SAEs) have
enabled decomposition of these embeddings into interpretable latent variables
that capture structural and functional features. However, the effectiveness of
SAEs for low-$N$ function prediction and protein design has not been
systematically studied. Herein, we evaluate SAEs trained on fine-tuned ESM2
embeddings across diverse fitness extrapolation and protein engineering tasks.
We show that SAEs, with as few as 24 sequences, consistently outperform or
compete with their ESM2 baselines in fitness prediction, indicating that their
sparse latent space encodes compact and biologically meaningful representations
that generalize more effectively from limited data. Moreover, steering
predictive latents exploits biological motifs in pLM representations, yielding
top-fitness variants in 83% of cases compared to designing with ESM2 alone.

</details>


### [109] [DrugReasoner: Interpretable Drug Approval Prediction with a Reasoning-augmented Language Model](https://arxiv.org/abs/2508.18579)
*Mohammadreza Ghaffarzadeh-Esfahani,Ali Motahharynia,Nahid Yousefian,Navid Mazrouei,Jafar Ghaisari,Yousof Gheisari*

Main category: cs.LG

TL;DR: DrugReasoner是一个基于推理的大型语言模型，用于预测小分子药物批准的可能性，性能优于传统方法，并提供可解释的推理过程。


<details>
  <summary>Details</summary>
Motivation: 药物发现过程复杂且资源密集，早期预测批准结果对优化研究投资至关重要。现有机器学习方法预测效果有限且缺乏可解释性。

Method: 基于LLaMA架构构建的DrugReasoner模型，通过GRPO微调，结合分子描述符和结构相似化合物的比较推理，生成预测及逐步推理过程。

Result: 在验证集和测试集上AUC分别为0.732和0.725，F1分数为0.729和0.718，优于传统基线模型和ChemAP模型。

Conclusion: DrugReasoner不仅预测性能优越，还通过推理输出增强透明度，为AI辅助药物发现提供了可解释且有效的工具。

Abstract: Drug discovery is a complex and resource-intensive process, making early
prediction of approval outcomes critical for optimizing research investments.
While classical machine learning and deep learning methods have shown promise
in drug approval prediction, their limited interpretability constraints their
impact. Here, we present DrugReasoner, a reasoning-based large language model
(LLM) built on the LLaMA architecture and fine-tuned with group relative policy
optimization (GRPO) to predict the likelihood of small-molecule approval.
DrugReasoner integrates molecular descriptors with comparative reasoning
against structurally similar approved and unapproved compounds, generating
predictions alongside step-by-step rationales and confidence scores.
DrugReasoner achieved robust performance with an AUC of 0.732 and an F1 score
of 0.729 on the validation set and 0.725 and 0.718 on the test set,
respectively. These results outperformed conventional baselines, including
logistic regression, support vector machine, and k-nearest neighbors and had
competitive performance relative to XGBoost. On an external independent
dataset, DrugReasoner outperformed both baseline and the recently developed
ChemAP model, achieving an AUC of 0.728 and an F1-score of 0.774, while
maintaining high precision and balanced sensitivity, demonstrating robustness
in real-world scenarios. These findings demonstrate that DrugReasoner not only
delivers competitive predictive accuracy but also enhances transparency through
its reasoning outputs, thereby addressing a key bottleneck in AI-assisted drug
discovery. This study highlights the potential of reasoning-augmented LLMs as
interpretable and effective tools for pharmaceutical decision-making.

</details>


### [110] [History Rhymes: Accelerating LLM Reinforcement Learning with RhymeRL](https://arxiv.org/abs/2508.18588)
*Jingkai He,Tianjian Li,Erhu Feng,Dong Du,Qian Liu,Tao Liu,Yubin Xia,Haibo Chen*

Main category: cs.LG

TL;DR: RhymeRL通过利用历史rollout的相似性，提出两种创新方法（HistoSpec和HistoPipe），显著提升RL训练效率，性能提升2.6倍且不影响准确性。


<details>
  <summary>Details</summary>
Motivation: 当前RL系统因rollout阶段主导和长度不平衡导致GPU利用率低，传统方法可能牺牲准确性。

Method: 提出RhymeRL系统，包含HistoSpec（利用历史rollout相似性生成准确草稿）和HistoPipe（基于历史分布平衡工作负载）。

Result: 实验显示RhymeRL在真实生产环境中可扩展至数千GPU，性能提升2.6倍。

Conclusion: RhymeRL高效解决了GPU利用率问题，未改变RL范式且保持准确性。

Abstract: With the rapid advancement of large language models (LLMs), reinforcement
learning (RL) has emerged as a pivotal methodology for enhancing the reasoning
capabilities of LLMs. Unlike traditional pre-training approaches, RL
encompasses multiple stages: rollout, reward, and training, which necessitates
collaboration among various worker types. However, current RL systems continue
to grapple with substantial GPU underutilization, due to two primary factors:
(1) The rollout stage dominates the overall RL process due to test-time
scaling; (2) Imbalances in rollout lengths (within the same batch) result in
GPU bubbles. While prior solutions like asynchronous execution and truncation
offer partial relief, they may compromise training accuracy for efficiency.
  Our key insight stems from a previously overlooked observation: rollout
responses exhibit remarkable similarity across adjacent training epochs. Based
on the insight, we introduce RhymeRL, an LLM RL system designed to accelerate
RL training with two key innovations. First, to enhance rollout generation, we
present HistoSpec, a speculative decoding inference engine that utilizes the
similarity of historical rollout token sequences to obtain accurate drafts.
Second, to tackle rollout bubbles, we introduce HistoPipe, a two-tier
scheduling strategy that leverages the similarity of historical rollout
distributions to balance workload among rollout workers. We have evaluated
RhymeRL within a real production environment, demonstrating scalability from
dozens to thousands of GPUs. Experimental results demonstrate that RhymeRL
achieves a 2.6x performance improvement over existing methods, without
compromising accuracy or modifying the RL paradigm.

</details>


### [111] [Linear Trading Position with Sparse Spectrum](https://arxiv.org/abs/2508.18596)
*Zhao-Rong Lai,Haisheng Yang*

Main category: cs.LG

TL;DR: 提出了一种基于稀疏频谱的线性交易头寸方法，通过Krasnosel'ski\u \i-Mann固定点算法优化，具有下降特性和线性收敛速度。


<details>
  <summary>Details</summary>
Motivation: 主投资组合方法在信号交易中缺乏多样性和鲁棒性，无法充分挖掘预测矩阵的关键特征。

Method: 提出稀疏频谱线性交易头寸，开发Krasnosel'ski\u \i-Mann固定点算法优化，具有下降特性和线性收敛速度。

Result: 实验表明，该方法在各种情况下表现良好且鲁棒。

Conclusion: 该方法在理论和实验上均表现出色，解决了主投资组合方法的局限性。

Abstract: The principal portfolio approach is an emerging method in signal-based
trading. However, these principal portfolios may not be diversified to explore
the key features of the prediction matrix or robust to different situations. To
address this problem, we propose a novel linear trading position with sparse
spectrum that can explore a larger spectral region of the prediction matrix. We
also develop a Krasnosel'ski\u \i-Mann fixed-point algorithm to optimize this
trading position, which possesses the descent property and achieves a linear
convergence rate in the objective value. This is a new theoretical result for
this type of algorithms. Extensive experiments show that the proposed method
achieves good and robust performance in various situations.

</details>


### [112] [Uncertainty Awareness on Unsupervised Domain Adaptation for Time Series Data](https://arxiv.org/abs/2508.18630)
*Weide Liu,Xiaoyang Zhong,Lu Wang,Jingwen Hou,Yuemei Luo,Jiebin Yan,Yuming Fang*

Main category: cs.LG

TL;DR: 提出了一种结合多尺度特征提取和不确定性估计的无监督域自适应方法，用于时间序列数据，显著提升了目标域的性能和预测校准。


<details>
  <summary>Details</summary>
Motivation: 时间序列数据中训练和测试数据集之间的分布偏移是一个常见挑战，需要提高模型的泛化能力和鲁棒性。

Method: 采用多尺度混合输入架构捕获不同尺度的特征，并引入基于证据学习的不确定性感知机制，通过Dirichlet先验促进目标预测和不确定性估计。

Result: 在多个基准数据集上实现了最先进的性能，同时显著降低了预期校准误差（ECE）。

Conclusion: 该方法通过多尺度特征和不确定性感知机制有效提升了时间序列数据无监督域自适应的性能。

Abstract: Unsupervised domain adaptation methods seek to generalize effectively on
unlabeled test data, especially when encountering the common challenge in time
series data that distribution shifts occur between training and testing
datasets. In this paper, we propose incorporating multi-scale feature
extraction and uncertainty estimation to improve the model's generalization and
robustness across domains. Our approach begins with a multi-scale mixed input
architecture that captures features at different scales, increasing training
diversity and reducing feature discrepancies between the training and testing
domains. Based on the mixed input architecture, we further introduce an
uncertainty awareness mechanism based on evidential learning by imposing a
Dirichlet prior on the labels to facilitate both target prediction and
uncertainty estimation. The uncertainty awareness mechanism enhances domain
adaptation by aligning features with the same labels across different domains,
which leads to significant performance improvements in the target domain.
Additionally, our uncertainty-aware model demonstrates a much lower Expected
Calibration Error (ECE), indicating better-calibrated prediction confidence.
Our experimental results show that this combined approach of mixed input
architecture with the uncertainty awareness mechanism achieves state-of-the-art
performance across multiple benchmark datasets, underscoring its effectiveness
in unsupervised domain adaptation for time series data.

</details>


### [113] [STRATA-TS: Selective Knowledge Transfer for Urban Time Series Forecasting with Retrieval-Guided Reasoning](https://arxiv.org/abs/2508.18635)
*Yue Jiang,Chenxi Liu,Yile Chen,Qin Chao,Shuai Liu,Gao Cong*

Main category: cs.LG

TL;DR: STRATA-TS框架通过选择性迁移和检索增强推理，解决了城市预测中的数据不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 城市预测中存在数据不平衡问题，直接迁移可能导致噪声和负迁移。

Method: 结合领域自适应检索和大型模型推理，通过目标感知检索和推理阶段提升预测效果。

Result: 在三个停车可用性数据集上表现优于基线方法，并提供可解释的迁移路径。

Conclusion: STRATA-TS有效提升了数据稀缺场景下的预测性能，且具有可解释性。

Abstract: Urban forecasting models often face a severe data imbalance problem: only a
few cities have dense, long-span records, while many others expose short or
incomplete histories. Direct transfer from data-rich to data-scarce cities is
unreliable because only a limited subset of source patterns truly benefits the
target domain, whereas indiscriminate transfer risks introducing noise and
negative transfer. We present STRATA-TS (Selective TRAnsfer via TArget-aware
retrieval for Time Series), a framework that combines domain-adapted retrieval
with reasoning-capable large models to improve forecasting in scarce data
regimes. STRATA-TS employs a patch-based temporal encoder to identify source
subsequences that are semantically and dynamically aligned with the target
query. These retrieved exemplars are then injected into a retrieval-guided
reasoning stage, where an LLM performs structured inference over target inputs
and retrieved support. To enable efficient deployment, we distill the reasoning
process into a compact open model via supervised fine-tuning. Extensive
experiments on three parking availability datasets across Singapore,
Nottingham, and Glasgow demonstrate that STRATA-TS consistently outperforms
strong forecasting and transfer baselines, while providing interpretable
knowledge transfer pathways.

</details>


### [114] [Biologically Disentangled Multi-Omic Modeling Reveals Mechanistic Insights into Pan-Cancer Immunotherapy Resistance](https://arxiv.org/abs/2508.18638)
*Ifrah Tariq,Ernest Fraenkel*

Main category: cs.LG

TL;DR: BDVAE是一种深度生成模型，通过整合转录组和基因组数据，预测免疫检查点抑制剂的治疗反应，并揭示耐药机制。


<details>
  <summary>Details</summary>
Motivation: 免疫检查点抑制剂（ICIs）的治疗反应差异大，耐药机制不明确，现有机器学习模型缺乏可解释性且未充分利用多组学数据的生物结构。

Method: BDVAE采用模块化编码器架构和变分推断，学习与免疫、基因组和代谢过程相关的潜在特征。

Result: BDVAE在366名患者中预测治疗反应的AUC-ROC为0.94，揭示了免疫抑制、代谢变化和神经元信号等耐药机制。

Conclusion: BDVAE展示了生物结构机器学习在解析复杂耐药模式和指导精准免疫治疗中的价值。

Abstract: Immune checkpoint inhibitors (ICIs) have transformed cancer treatment, yet
patient responses remain highly variable, and the biological mechanisms
underlying resistance are poorly understood. While machine learning models hold
promise for predicting responses to ICIs, most existing methods lack
interpretability and do not effectively leverage the biological structure
inherent to multi-omics data. Here, we introduce the Biologically Disentangled
Variational Autoencoder (BDVAE), a deep generative model that integrates
transcriptomic and genomic data through modality- and pathway-specific
encoders. Unlike existing rigid, pathway-informed models, BDVAE employs a
modular encoder architecture combined with variational inference to learn
biologically meaningful latent features associated with immune, genomic, and
metabolic processes. Applied to a pan-cancer cohort of 366 patients across four
cancer types treated with ICIs, BDVAE accurately predicts treatment response
(AUC-ROC = 0.94 on unseen test data) and uncovers critical resistance
mechanisms, including immune suppression, metabolic shifts, and neuronal
signaling. Importantly, BDVAE reveals that resistance spans a continuous
biological spectrum rather than strictly binary states, reflecting gradations
of tumor dysfunction. Several latent features correlate with survival outcomes
and known clinical subtypes, demonstrating BDVAE's capability to generate
interpretable, clinically relevant insights. These findings underscore the
value of biologically structured machine learning in elucidating complex
resistance patterns and guiding precision immunotherapy strategies.

</details>


### [115] [The Sound of Risk: A Multimodal Physics-Informed Acoustic Model for Forecasting Market Volatility and Enhancing Market Interpretability](https://arxiv.org/abs/2508.18653)
*Xiaoliang Chen,Xin Yu,Le Chang,Teng Jing,Jiashuai He,Ze Wang,Yangjun Luo,Xingyu Chen,Jiayue Liang,Yuchen Wang,Jiaying Xie*

Main category: cs.LG

TL;DR: 提出了一种多模态金融风险评估框架，结合文本情感和语音特征，显著提升了波动性预测能力。


<details>
  <summary>Details</summary>
Motivation: 金融市场信息不对称问题严重，传统文本分析方法效果有限，需要更全面的情感分析工具。

Method: 使用物理声学模型（PIAM）提取语音情感特征，结合文本情感，投影到三维情感状态空间（ASL）。

Result: 多模态特征可解释43.8%的30天波动性方差，情感动态变化（如CFO的稳定性降低、CEO的兴奋度变化）是关键预测因素。

Conclusion: 多模态方法优于纯金融基线，为投资者和监管者提供了识别隐藏市场不确定性的有力工具。

Abstract: Information asymmetry in financial markets, often amplified by strategically
crafted corporate narratives, undermines the effectiveness of conventional
textual analysis. We propose a novel multimodal framework for financial risk
assessment that integrates textual sentiment with paralinguistic cues derived
from executive vocal tract dynamics in earnings calls. Central to this
framework is the Physics-Informed Acoustic Model (PIAM), which applies
nonlinear acoustics to robustly extract emotional signatures from raw
teleconference sound subject to distortions such as signal clipping. Both
acoustic and textual emotional states are projected onto an interpretable
three-dimensional Affective State Label (ASL) space-Tension, Stability, and
Arousal. Using a dataset of 1,795 earnings calls (approximately 1,800 hours),
we construct features capturing dynamic shifts in executive affect between
scripted presentation and spontaneous Q&A exchanges. Our key finding reveals a
pronounced divergence in predictive capacity: while multimodal features do not
forecast directional stock returns, they explain up to 43.8% of the
out-of-sample variance in 30-day realized volatility. Importantly, volatility
predictions are strongly driven by emotional dynamics during executive
transitions from scripted to spontaneous speech, particularly reduced textual
stability and heightened acoustic instability from CFOs, and significant
arousal variability from CEOs. An ablation study confirms that our multimodal
approach substantially outperforms a financials-only baseline, underscoring the
complementary contributions of acoustic and textual modalities. By decoding
latent markers of uncertainty from verifiable biometric signals, our
methodology provides investors and regulators a powerful tool for enhancing
market interpretability and identifying hidden corporate uncertainty.

</details>


### [116] [FFT-MoE: Efficient Federated Fine-Tuning for Foundation Models via Large-scale Sparse MoE under Heterogeneous Edge](https://arxiv.org/abs/2508.18663)
*Gang Hu,Yinglei Teng,Pengfei Wu,Nan Wang*

Main category: cs.LG

TL;DR: 论文提出了一种名为FFT MoE的新框架，通过稀疏Mixture of Experts (MoE)适配器解决LoRA在异构联邦学习中的局限性，提升了泛化性能和训练效率。


<details>
  <summary>Details</summary>
Motivation: 在隐私和资源受限的环境下，如何高效微调模型以适应分布式边缘设备上的非IID数据分布是一个关键挑战。

Method: 采用稀疏MoE适配器替代LoRA，每个客户端训练轻量级门控网络以选择性地激活专家子集，并引入异构感知辅助损失以平衡专家负载。

Result: 实验表明，FFT MoE在IID和非IID条件下均优于现有基线方法。

Conclusion: FFT MoE通过专家选择和负载平衡机制，有效解决了异构联邦学习中的挑战，提升了模型性能。

Abstract: As FMs drive progress toward Artificial General Intelligence (AGI),
fine-tuning them under privacy and resource constraints has become increasingly
critical particularly when highquality training data resides on distributed
edge devices. Federated Learning (FL) offers a compelling solution through
Federated Fine-Tuning (FFT), which enables collaborative model adaptation
without sharing raw data. Recent approaches incorporate Parameter-Efficient
Fine-Tuning (PEFT) techniques such as Low Rank Adaptation (LoRA) to reduce
computational overhead. However, LoRA-based FFT faces two major limitations in
heterogeneous FL environments: structural incompatibility across clients with
varying LoRA configurations and limited adaptability to non-IID data
distributions, which hinders convergence and generalization. To address these
challenges, we propose FFT MoE, a novel FFT framework that replaces LoRA with
sparse Mixture of Experts (MoE) adapters. Each client trains a lightweight
gating network to selectively activate a personalized subset of experts,
enabling fine-grained adaptation to local resource budgets while preserving
aggregation compatibility. To further combat the expert load imbalance caused
by device and data heterogeneity, we introduce a heterogeneity-aware auxiliary
loss that dynamically regularizes the routing distribution to ensure expert
diversity and balanced utilization. Extensive experiments spanning both IID and
non-IID conditions demonstrate that FFT MoE consistently outperforms state of
the art FFT baselines in generalization performance and training efficiency.

</details>


### [117] [Auditing Approximate Machine Unlearning for Differentially Private Models](https://arxiv.org/abs/2508.18671)
*Yuechun Gu,Jiajie He,Keke Chen*

Main category: cs.LG

TL;DR: 本文研究了近似机器遗忘算法对保留样本隐私的影响，提出了基于差分隐私和成员推理攻击的隐私标准，并开发了高效的A-LiRA攻击方法。实验发现现有算法可能损害差分隐私模型的保留样本隐私，建议使用差分隐私遗忘算法。


<details>
  <summary>Details</summary>
Motivation: 现有近似机器遗忘方法假设保留样本不受影响，但隐私洋葱效应表明这一假设可能不成立，尤其在差分隐私模型中尚未有研究验证保留样本是否仍满足差分隐私标准。

Method: 提出基于差分隐私和成员推理攻击的隐私标准，开发高效的A-LiRA攻击方法，利用数据增强减少影子模型训练成本。

Result: 实验表明现有近似机器遗忘算法可能损害差分隐私模型的保留样本隐私，需要差分隐私遗忘算法。

Conclusion: 现有近似机器遗忘算法对保留样本隐私有潜在风险，建议采用差分隐私遗忘算法以确保隐私保护。

Abstract: Approximate machine unlearning aims to remove the effect of specific data
from trained models to ensure individuals' privacy. Existing methods focus on
the removed records and assume the retained ones are unaffected. However,
recent studies on the \emph{privacy onion effect} indicate this assumption
might be incorrect. Especially when the model is differentially private, no
study has explored whether the retained ones still meet the differential
privacy (DP) criterion under existing machine unlearning methods. This paper
takes a holistic approach to auditing both unlearned and retained samples'
privacy risks after applying approximate unlearning algorithms. We propose the
privacy criteria for unlearned and retained samples, respectively, based on the
perspectives of DP and membership inference attacks (MIAs). To make the
auditing process more practical, we also develop an efficient MIA, A-LiRA,
utilizing data augmentation to reduce the cost of shadow model training. Our
experimental findings indicate that existing approximate machine unlearning
algorithms may inadvertently compromise the privacy of retained samples for
differentially private models, and we need differentially private unlearning
algorithms. For reproducibility, we have pubished our code:
https://anonymous.4open.science/r/Auditing-machine-unlearning-CB10/README.md

</details>


### [118] [Optimal Sparsity of Mixture-of-Experts Language Models for Reasoning Tasks](https://arxiv.org/abs/2508.18672)
*Taishi Nakamura,Satoki Ishikawa,Masaki Kawamura,Takumi Okamoto,Daisuke Nohara,Jun Suzuki,Rio Yokota*

Main category: cs.LG

TL;DR: 研究了MoE稀疏性对记忆和推理能力的影响，发现记忆性能随参数增加而提升，而推理性能会饱和甚至下降。


<details>
  <summary>Details</summary>
Motivation: 探索MoE稀疏性如何影响LLMs的记忆和推理能力，填补当前密集模型研究的空白。

Method: 训练不同参数配置的MoE Transformer家族，固定计算预算，记录预训练和下游任务表现。

Result: 记忆性能与总参数正相关，推理性能会饱和；稀疏性调整和经典超参数影响泛化差距。

Conclusion: MoE稀疏性对记忆和推理能力有不同影响，推理性能无法通过后训练或额外计算弥补。

Abstract: Empirical scaling laws have driven the evolution of large language models
(LLMs), yet their coefficients shift whenever the model architecture or data
pipeline changes. Mixture-of-Experts (MoE) models, now standard in
state-of-the-art systems, introduce a new sparsity dimension that current
dense-model frontiers overlook. We investigate how MoE sparsity influences two
distinct capability regimes: memorization and reasoning. We train families of
MoE Transformers that systematically vary total parameters, active parameters,
and top-$k$ routing while holding the compute budget fixed. For every model we
record pre-training loss, downstream task loss, and task accuracy, allowing us
to separate the train-test generalization gap from the loss-accuracy gap.
Memorization benchmarks improve monotonically with total parameters, mirroring
training loss. By contrast, reasoning performance saturates and can even
regress despite continued gains in both total parameters and training loss.
Altering top-$k$ alone has little effect when active parameters are constant,
and classic hyperparameters such as learning rate and initialization modulate
the generalization gap in the same direction as sparsity. Neither post-training
reinforcement learning (GRPO) nor extra test-time compute rescues the reasoning
deficit of overly sparse models. Our model checkpoints, code and logs are
open-source at https://github.com/rioyokotalab/optimal-sparsity.

</details>


### [119] [Utilizing Training Data to Improve LLM Reasoning for Tabular Understanding](https://arxiv.org/abs/2508.18676)
*Chufan Gao,Jintai Chen,Jimeng Sun*

Main category: cs.LG

TL;DR: 提出了一种结合训练数据检索的提示方法LRTab，用于表格推理任务，兼具通用性和数据利用效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在表格推理任务中通用性与数据利用之间的权衡问题。

Method: 通过提示获取训练数据的CoT响应，学习错误避免的Prompt Conditions，并在推理时检索相关条件。

Result: 在WikiTQ和Tabfact上表现优于基线，具有可解释性和成本效益。

Conclusion: LRTab方法有效结合了训练数据和通用性，提升了表格推理性能。

Abstract: Automated tabular understanding and reasoning are essential tasks for data
scientists. Recently, Large language models (LLMs) have become increasingly
prevalent in tabular reasoning tasks. Previous work focuses on (1) finetuning
LLMs using labeled data or (2) Training-free prompting LLM agents using
chain-of-thought (CoT). Finetuning offers dataset-specific learning at the cost
of generalizability. Training-free prompting is highly generalizable but does
not take full advantage of training data. In this paper, we propose a novel
prompting-based reasoning approach, Learn then Retrieve: LRTab, which
integrates the benefits of both by retrieving relevant information learned from
training data. We first use prompting to obtain CoT responses over the training
data. For incorrect CoTs, we prompt the LLM to predict Prompt Conditions to
avoid the error, learning insights from the data. We validate the effectiveness
of Prompt Conditions using validation data. Finally, at inference time, we
retrieve the most relevant Prompt Conditions for additional context for table
understanding. We provide comprehensive experiments on WikiTQ and Tabfact,
showing that LRTab is interpretable, cost-efficient, and can outperform
previous baselines in tabular reasoning.

</details>


### [120] [End to End Autoencoder MLP Framework for Sepsis Prediction](https://arxiv.org/abs/2508.18688)
*Hejiang Cai,Di Wu,Ji Xu,Xiang Liu,Yiziting Zhu,Xin Shu,Yujie Li,Bin Yi*

Main category: cs.LG

TL;DR: 提出了一种端到端的深度学习框架，结合无监督自动编码器和多层感知机分类器，用于脓毒症风险预测，优于传统机器学习方法。


<details>
  <summary>Details</summary>
Motivation: 脓毒症是一种危及生命的疾病，需要及时检测。传统机器学习方法依赖手动特征工程，难以处理电子健康记录中不完整的时间序列数据。

Method: 采用无监督自动编码器进行自动特征提取，结合多层感知机分类器，并引入定制下采样策略和动态滑动窗口机制。

Result: 在三个ICU队列中，模型的准确率分别为74.6%、80.6%和93.5%，优于传统基线方法。

Conclusion: 该框架在脓毒症早期检测中表现出更强的鲁棒性、泛化能力和临床实用性。

Abstract: Sepsis is a life threatening condition that requires timely detection in
intensive care settings. Traditional machine learning approaches, including
Naive Bayes, Support Vector Machine (SVM), Random Forest, and XGBoost, often
rely on manual feature engineering and struggle with irregular, incomplete
time-series data commonly present in electronic health records. We introduce an
end-to-end deep learning framework integrating an unsupervised autoencoder for
automatic feature extraction with a multilayer perceptron classifier for binary
sepsis risk prediction. To enhance clinical applicability, we implement a
customized down sampling strategy that extracts high information density
segments during training and a non-overlapping dynamic sliding window mechanism
for real-time inference. Preprocessed time series data are represented as fixed
dimension vectors with explicit missingness indicators, mitigating bias and
noise. We validate our approach on three ICU cohorts. Our end-to-end model
achieves accuracies of 74.6 percent, 80.6 percent, and 93.5 percent,
respectively, consistently outperforming traditional machine learning
baselines. These results demonstrate the framework's superior robustness,
generalizability, and clinical utility for early sepsis detection across
heterogeneous ICU environments.

</details>


### [121] [Natural Image Classification via Quasi-Cyclic Graph Ensembles and Random-Bond Ising Models at the Nishimori Temperature](https://arxiv.org/abs/2508.18717)
*V. S. Usatyuk,D. A. Sapoznikov,S. I. Egorov*

Main category: cs.LG

TL;DR: 提出了一种结合统计物理、编码理论和代数拓扑的统一框架，用于高效多类图像分类。


<details>
  <summary>Details</summary>
Motivation: 通过高维特征向量的物理模型和拓扑方法，提升分类效率和准确性。

Method: 将特征向量视为稀疏MET-QC-LDPC图上的自旋，构建RBIM模型，并在Nishimori温度下操作，利用拓扑指导设计图结构。

Result: 在ImageNet-10和-100上分别达到98.7%和82.7%的准确率，压缩比达40倍。

Conclusion: 拓扑指导的图设计能实现高效、物理启发的嵌入，性能达到先进水平。

Abstract: We present a unified framework combining statistical physics, coding theory,
and algebraic topology for efficient multi-class image classification.
High-dimensional feature vectors from a frozen MobileNetV2 backbone are
interpreted as spins on a sparse Multi-Edge Type quasi-cyclic LDPC
(MET-QC-LDPC) graph, forming a Random-Bond Ising Model (RBIM). We operate this
RBIM at its Nishimori temperature, $\beta_N$, where the smallest eigenvalue of
the Bethe-Hessian matrix vanishes, maximizing class separability.
  Our theoretical contribution establishes a correspondence between local
trapping sets in the code's graph and topological invariants (Betti numbers,
bordism classes) of the feature manifold. A practical algorithm estimates
$\beta_N$ efficiently with a quadratic interpolant and Newton correction,
achieving a six-fold speed-up over bisection.
  Guided by topology, we design spherical and toroidal MET-QC-LDPC graph
ensembles, using permanent bounds to suppress harmful trapping sets. This
compresses 1280-dimensional features to 32 or 64 dimensions for ImageNet-10 and
-100 subsets. Despite massive compression (40x fewer parameters), we achieve
98.7% accuracy on ImageNet-10 and 82.7% on ImageNet-100, demonstrating that
topology-guided graph design yields highly efficient, physics-inspired
embeddings with state-of-the-art performance.

</details>


### [122] [Beyond Tokens: Enhancing RTL Quality Estimation via Structural Graph Learning](https://arxiv.org/abs/2508.18730)
*Yi Liu,Hongji Zhang,Yiwen Wang,Dimitris Tsaras,Lei Chen,Mingxuan Yuan,Qiang Xu*

Main category: cs.LG

TL;DR: 提出了一种名为StructRTL的结构感知图自监督学习框架，用于改进RTL设计质量估计，通过结合结构学习和跨阶段监督，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略了RTL代码中的结构语义，而CDFG视图能更明确地展示设计结构特征，为表示学习提供更丰富的线索。

Method: 使用CDFG学习结构感知表示，并结合知识蒸馏策略，将后映射网表中的低级信息转移到CDFG预测器中。

Result: 实验表明，StructRTL在各种质量估计任务中显著优于现有方法，确立了新的最先进结果。

Conclusion: 结合结构学习和跨阶段监督的方法在RTL设计质量估计中表现出色，证明了其有效性。

Abstract: Estimating the quality of register transfer level (RTL) designs is crucial in
the electronic design automation (EDA) workflow, as it enables instant feedback
on key metrics like area and delay without the need for time-consuming logic
synthesis. While recent approaches have leveraged large language models (LLMs)
to derive embeddings from RTL code and achieved promising results, they
overlook the structural semantics essential for accurate quality estimation. In
contrast, the control data flow graph (CDFG) view exposes the design's
structural characteristics more explicitly, offering richer cues for
representation learning. In this work, we introduce a novel structure-aware
graph self-supervised learning framework, StructRTL, for improved RTL design
quality estimation. By learning structure-informed representations from CDFGs,
our method significantly outperforms prior art on various quality estimation
tasks. To further boost performance, we incorporate a knowledge distillation
strategy that transfers low-level insights from post-mapping netlists into the
CDFG predictor. Experiments show that our approach establishes new
state-of-the-art results, demonstrating the effectiveness of combining
structural learning with cross-stage supervision.

</details>


### [123] [FLAegis: A Two-Layer Defense Framework for Federated Learning Against Poisoning Attacks](https://arxiv.org/abs/2508.18737)
*Enrique Mármol Campos,Aurora González Vidal,José Luis Hernández Ramos,Antonio Skarmeta*

Main category: cs.LG

TL;DR: FLAegis是一个两阶段防御框架，用于识别联邦学习中的拜占庭客户端并提升系统鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习的去中心化特性导致训练过程缺乏可见性，依赖客户端的诚实性，易受拜占庭客户端攻击。

Method: 结合符号时间序列变换（SAX）和谱聚类检测恶意行为，并使用基于FFT的鲁棒聚合函数减轻攻击影响。

Result: 在五种攻击场景下表现优异，检测精度和模型准确性均优于现有防御方法。

Conclusion: FLAegis在强对抗条件下仍能保持高性能，为联邦学习提供了有效的防御方案。

Abstract: Federated Learning (FL) has become a powerful technique for training Machine
Learning (ML) models in a decentralized manner, preserving the privacy of the
training datasets involved. However, the decentralized nature of FL limits the
visibility of the training process, relying heavily on the honesty of
participating clients. This assumption opens the door to malicious third
parties, known as Byzantine clients, which can poison the training process by
submitting false model updates. Such malicious clients may engage in poisoning
attacks, manipulating either the dataset or the model parameters to induce
misclassification. In response, this study introduces FLAegis, a two-stage
defensive framework designed to identify Byzantine clients and improve the
robustness of FL systems. Our approach leverages symbolic time series
transformation (SAX) to amplify the differences between benign and malicious
models, and spectral clustering, which enables accurate detection of
adversarial behavior. Furthermore, we incorporate a robust FFT-based
aggregation function as a final layer to mitigate the impact of those Byzantine
clients that manage to evade prior defenses. We rigorously evaluate our method
against five poisoning attacks, ranging from simple label flipping to adaptive
optimization-based strategies. Notably, our approach outperforms
state-of-the-art defenses in both detection precision and final model accuracy,
maintaining consistently high performance even under strong adversarial
conditions.

</details>


### [124] [Stability and Generalization for Bellman Residuals](https://arxiv.org/abs/2508.18741)
*Enoch H. Kang,Kyoungseok Jang*

Main category: cs.LG

TL;DR: 论文分析了离线强化学习和离线逆强化学习中Bellman残差最小化（BRM）的统计行为，提出了一种新的Lyapunov势能方法，显著提升了样本复杂度。


<details>
  <summary>Details</summary>
Motivation: 当前离线强化学习和逆强化学习在实践中难以保证Bellman一致性，BRM方法虽被提出，但其统计行为尚未充分研究。

Method: 引入单一Lyapunov势能，耦合相邻数据集上的SGDA运行，提出O(1/n)的平均参数稳定性边界。

Result: 实现了O(1/n)的BRM超额风险边界，无需方差缩减、额外正则化或对minibatch采样的独立性假设。

Conclusion: 该方法适用于标准神经网络参数化和minibatch SGD，显著提升了样本复杂度。

Abstract: Offline reinforcement learning and offline inverse reinforcement learning aim
to recover near-optimal value functions or reward models from a fixed batch of
logged trajectories, yet current practice still struggles to enforce Bellman
consistency. Bellman residual minimization (BRM) has emerged as an attractive
remedy, as a globally convergent stochastic gradient descent-ascent based
method for BRM has been recently discovered. However, its statistical behavior
in the offline setting remains largely unexplored. In this paper, we close this
statistical gap. Our analysis introduces a single Lyapunov potential that
couples SGDA runs on neighbouring datasets and yields an O(1/n) on-average
argument-stability bound-doubling the best known sample-complexity exponent for
convex-concave saddle problems. The same stability constant translates into the
O(1/n) excess risk bound for BRM, without variance reduction, extra
regularization, or restrictive independence assumptions on minibatch sampling.
The results hold for standard neural-network parameterizations and minibatch
SGD.

</details>


### [125] [Constraint Matters: Multi-Modal Representation for Reducing Mixed-Integer Linear programming](https://arxiv.org/abs/2508.18742)
*Jiajun Li,Ran Hou,Yu Ding,Yixuan Li,Shisi Guan,Jiahui Duan,Xiongwei Han,Tao Zhong,Vincent Chau,Weiwei Wu,Wanyuan Wang*

Main category: cs.LG

TL;DR: 提出了一种基于约束的MILP模型简化方法，通过识别关键约束并利用多模态表示技术，显著提升求解速度和解的质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法多基于变量简化，而约束简化被忽视，但其也能有效降低MILP复杂度。

Method: 通过标记最优解中的紧约束作为关键约束，并设计启发式规则和多模态表示技术来预测这些约束。

Result: 实验表明，该方法比现有方法解质量提升50%以上，计算时间减少17.47%。

Conclusion: 约束简化是MILP求解的有效途径，多模态表示技术能高效识别关键约束。

Abstract: Model reduction, which aims to learn a simpler model of the original mixed
integer linear programming (MILP), can solve large-scale MILP problems much
faster. Most existing model reduction methods are based on variable reduction,
which predicts a solution value for a subset of variables. From a dual
perspective, constraint reduction that transforms a subset of inequality
constraints into equalities can also reduce the complexity of MILP, but has
been largely ignored. Therefore, this paper proposes a novel constraint-based
model reduction approach for the MILP. Constraint-based MILP reduction has two
challenges: 1) which inequality constraints are critical such that reducing
them can accelerate MILP solving while preserving feasibility, and 2) how to
predict these critical constraints efficiently. To identify critical
constraints, we first label these tight-constraints at the optimal solution as
potential critical constraints and design a heuristic rule to select a subset
of critical tight-constraints. To learn the critical tight-constraints, we
propose a multi-modal representation technique that leverages information from
both instance-level and abstract-level MILP formulations. The experimental
results show that, compared to the state-of-the-art methods, our method
improves the quality of the solution by over 50\% and reduces the computation
time by 17.47\%.

</details>


### [126] [UltraMemV2: Memory Networks Scaling to 120B Parameters with Superior Long-Context Learning](https://arxiv.org/abs/2508.18756)
*Zihao Huang,Yu Bao,Qiyang Min,Siyan Chen,Ran Guo,Hongzhi Huang,Defa Zhu,Yutao Zeng,Banggu Wu,Xun Zhou,Siyuan Qiao*

Main category: cs.LG

TL;DR: UltraMemV2是一种改进的内存层架构，通过五项关键改进，实现了与8专家MoE模型相同的性能，同时显著降低了内存访问成本。


<details>
  <summary>Details</summary>
Motivation: 解决Mixture of Experts (MoE)模型在推理时高内存访问成本的问题，同时提升性能以匹配最先进的8专家配置。

Method: 1. 在每个Transformer块中集成内存层；2. 简化值扩展为单线性投影；3. 采用PEER的FFN值处理；4. 实现原则性参数初始化；5. 重新平衡内存与FFN计算比例。

Result: UltraMemV2在相同计算和参数下与8专家MoE模型性能相当，内存访问显著降低，在内存密集型任务中表现更优（如长上下文记忆+1.6分，多轮记忆+6.2分，上下文学习+7.9分）。

Conclusion: UltraMemV2将内存层架构性能提升至与最先进MoE模型相当，为高效稀疏计算提供了有吸引力的替代方案。

Abstract: While Mixture of Experts (MoE) models achieve remarkable efficiency by
activating only subsets of parameters, they suffer from high memory access
costs during inference. Memory-layer architectures offer an appealing
alternative with very few memory access, but previous attempts like UltraMem
have only matched the performance of 2-expert MoE models, falling significantly
short of state-of-the-art 8-expert configurations. We present UltraMemV2, a
redesigned memory-layer architecture that closes this performance gap. Our
approach introduces five key improvements: integrating memory layers into every
transformer block, simplifying value expansion with single linear projections,
adopting FFN-based value processing from PEER, implementing principled
parameter initialization, and rebalancing memory-to-FFN computation ratios.
Through extensive evaluation, we demonstrate that UltraMemV2 achieves
performance parity with 8-expert MoE models under same computation and
parameters but significantly low memory access. Notably, UltraMemV2 shows
superior performance on memory-intensive tasks, with improvements of +1.6
points on long-context memorization, +6.2 points on multi-round memorization,
and +7.9 points on in-context learning. We validate our approach at scale with
models up to 2.5B activated parameters from 120B total parameters, and
establish that activation density has greater impact on performance than total
sparse parameter count. Our work brings memory-layer architectures to
performance parity with state-of-the-art MoE models, presenting a compelling
alternative for efficient sparse computation.

</details>


### [127] [Governance-as-a-Service: A Multi-Agent Framework for AI System Compliance and Policy Enforcement](https://arxiv.org/abs/2508.18765)
*Helen Pervez,Suyash Gaurav,Jukka Heikkonen,Jatin Chaudhary*

Main category: cs.LG

TL;DR: 论文提出了一种名为GaaS（Governance-as-a-Service）的模块化治理层，用于在运行时监管多智能体系统的行为，而无需修改模型内部或依赖智能体合作。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统发展为分布式生态系统，现有的治理机制反应迟钝、脆弱且难以审计，无法适应异构部署的需求。

Method: GaaS采用声明性规则和信任因子机制，通过评分智能体的合规性和违规严重性，实现强制、规范和自适应干预。

Result: 实验表明，GaaS能有效拦截高风险行为，同时保持系统吞吐量，并通过信任评分追踪规则遵守情况。

Conclusion: GaaS将治理定位为运行时服务，为多智能体系统提供了基础设施级别的对齐机制，强制执行伦理而非教授伦理。

Abstract: As AI systems evolve into distributed ecosystems with autonomous execution,
asynchronous reasoning, and multi-agent coordination, the absence of scalable,
decoupled governance poses a structural risk. Existing oversight mechanisms are
reactive, brittle, and embedded within agent architectures, making them
non-auditable and hard to generalize across heterogeneous deployments.
  We introduce Governance-as-a-Service (GaaS): a modular, policy-driven
enforcement layer that regulates agent outputs at runtime without altering
model internals or requiring agent cooperation. GaaS employs declarative rules
and a Trust Factor mechanism that scores agents based on compliance and
severity-weighted violations. It enables coercive, normative, and adaptive
interventions, supporting graduated enforcement and dynamic trust modulation.
  To evaluate GaaS, we conduct three simulation regimes with open-source models
(LLaMA3, Qwen3, DeepSeek-R1) across content generation and financial
decision-making. In the baseline, agents act without governance; in the second,
GaaS enforces policies; in the third, adversarial agents probe robustness. All
actions are intercepted, evaluated, and logged for analysis. Results show that
GaaS reliably blocks or redirects high-risk behaviors while preserving
throughput. Trust scores track rule adherence, isolating and penalizing
untrustworthy components in multi-agent systems.
  By positioning governance as a runtime service akin to compute or storage,
GaaS establishes infrastructure-level alignment for interoperable agent
ecosystems. It does not teach agents ethics; it enforces them.

</details>


### [128] [Predicting Drug-Drug Interactions Using Heterogeneous Graph Neural Networks: HGNN-DDI](https://arxiv.org/abs/2508.18766)
*Hongbo Liu,Siyi Li,Zheng Yu*

Main category: cs.LG

TL;DR: HGNN-DDI是一种基于异构图神经网络的模型，用于预测药物相互作用，整合多源数据并优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 药物相互作用（DDIs）可能导致疗效降低或严重副作用，传统计算方法难以捕捉复杂关系。

Method: HGNN-DDI利用异构图表示学习，整合多源药物相关数据，建模异构生物医学网络。

Result: 在基准数据集上，HGNN-DDI在预测准确性和鲁棒性上优于现有方法。

Conclusion: HGNN-DDI有潜力支持更安全的药物开发和精准医疗。

Abstract: Drug-drug interactions (DDIs) are a major concern in clinical practice, as
they can lead to reduced therapeutic efficacy or severe adverse effects.
Traditional computational approaches often struggle to capture the complex
relationships among drugs, targets, and biological entities. In this work, we
propose HGNN-DDI, a heterogeneous graph neural network model designed to
predict potential DDIs by integrating multiple drug-related data sources.
HGNN-DDI leverages graph representation learning to model heterogeneous
biomedical networks, enabling effective information propagation across diverse
node and edge types. Experimental results on benchmark DDI datasets demonstrate
that HGNN-DDI outperforms state-of-the-art baselines in prediction accuracy and
robustness, highlighting its potential to support safer drug development and
precision medicine.

</details>


### [129] [Federated Learning with Heterogeneous and Private Label Sets](https://arxiv.org/abs/2508.18774)
*Adam Breitholtz,Edvin Listo Zec,Fredrik D. Johansson*

Main category: cs.LG

TL;DR: 研究了联邦学习中客户端标签集异构性的影响，比较了公开和私有标签设置下的模型性能，提出了适应私有标签集的联邦学习方法。


<details>
  <summary>Details</summary>
Motivation: 现实应用中客户端标签集异构性常见但研究较少，且现有研究假设客户端愿意共享全部标签集，私有标签集增加了学习算法的约束。

Method: 应用经典分类器组合方法到联邦学习，并调整常见联邦学习方法以适应私有标签集设置。

Result: 实验表明标签减少会显著降低性能，但通过集中调优和提出的方法可以在私有标签集下保持与公开标签集相似的性能。

Conclusion: 客户端可以在几乎不影响模型准确性的情况下增加隐私保护。

Abstract: Although common in real-world applications, heterogeneous client label sets
are rarely investigated in federated learning (FL). Furthermore, in the cases
they are, clients are assumed to be willing to share their entire label sets
with other clients. Federated learning with private label sets, shared only
with the central server, adds further constraints on learning algorithms and
is, in general, a more difficult problem to solve. In this work, we study the
effects of label set heterogeneity on model performance, comparing the public
and private label settings -- when the union of label sets in the federation is
known to clients and when it is not. We apply classical methods for the
classifier combination problem to FL using centralized tuning, adapt common FL
methods to the private label set setting, and discuss the justification of both
approaches under practical assumptions. Our experiments show that reducing the
number of labels available to each client harms the performance of all methods
substantially. Centralized tuning of client models for representational
alignment can help remedy this, but often at the cost of higher variance.
Throughout, our proposed adaptations of standard FL methods perform well,
showing similar performance in the private label setting as the standard
methods achieve in the public setting. This shows that clients can enjoy
increased privacy at little cost to model accuracy.

</details>


### [130] [SWiFT: Soft-Mask Weight Fine-tuning for Bias Mitigation](https://arxiv.org/abs/2508.18826)
*Junyu Yan,Feng Chen,Yuyang Xue,Yuning Du,Konstantinos Vilouras,Sotirios A. Tsaftaris,Steven McDonagh*

Main category: cs.LG

TL;DR: SWiFT是一种高效的去偏框架，通过软掩码权重微调，在减少模型偏见的同时保持性能，且成本较低。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在敏感领域（如医疗）中的偏见问题可能加剧社会歧视，现有方法需大量数据和重新训练，且公平性与性能难以兼顾。

Method: 提出SWiFT框架，通过分析参数对偏见和性能的贡献，分两步微调参数，仅需少量外部数据和少量训练轮次。

Result: 在多个数据集和敏感属性上，SWiFT显著减少偏见，同时保持或提升诊断准确性，并在OOD数据集上表现优异。

Conclusion: SWiFT是一种高效、低成本且性能优越的去偏方法，适用于敏感领域的机器学习模型。

Abstract: Recent studies have shown that Machine Learning (ML) models can exhibit bias
in real-world scenarios, posing significant challenges in ethically sensitive
domains such as healthcare. Such bias can negatively affect model fairness,
model generalization abilities and further risks amplifying social
discrimination. There is a need to remove biases from trained models. Existing
debiasing approaches often necessitate access to original training data and
need extensive model retraining; they also typically exhibit trade-offs between
model fairness and discriminative performance. To address these challenges, we
propose Soft-Mask Weight Fine-Tuning (SWiFT), a debiasing framework that
efficiently improves fairness while preserving discriminative performance with
much less debiasing costs. Notably, SWiFT requires only a small external
dataset and only a few epochs of model fine-tuning. The idea behind SWiFT is to
first find the relative, and yet distinct, contributions of model parameters to
both bias and predictive performance. Then, a two-step fine-tuning process
updates each parameter with different gradient flows defined by its
contribution. Extensive experiments with three bias sensitive attributes
(gender, skin tone, and age) across four dermatological and two chest X-ray
datasets demonstrate that SWiFT can consistently reduce model bias while
achieving competitive or even superior diagnostic accuracy under common
fairness and accuracy metrics, compared to the state-of-the-art. Specifically,
we demonstrate improved model generalization ability as evidenced by superior
performance on several out-of-distribution (OOD) datasets.

</details>


### [131] [DRMD: Deep Reinforcement Learning for Malware Detection under Concept Drift](https://arxiv.org/abs/2508.18839)
*Shae McFadden,Myles Foley,Mario D'Onghia,Chris Hicks,Vasilios Mavroudis,Nicola Paoletti,Fabio Pierazzi*

Main category: cs.LG

TL;DR: 论文提出了一种基于深度强化学习（DRL）的恶意软件检测方法（DRMD），通过马尔可夫决策过程优化分类和样本拒绝策略，显著提升了对概念漂移的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统分类器在恶意软件检测中难以应对概念漂移和有限标注预算的问题，需要一种更动态的解决方案。

Method: 将恶意软件检测建模为马尔可夫决策过程，训练DRL代理同时优化分类性能和拒绝高风险样本的策略。

Result: DRMD在Android恶意软件数据集上表现出更高的时间性能（AUT），分类、拒绝和主动学习组合策略分别提升了5.18、14.49和10.06分。

Conclusion: DRL首次在动态环境中实现了有效的恶意软件检测，并显著提升了对概念漂移的鲁棒性。

Abstract: Malware detection in real-world settings must deal with evolving threats,
limited labeling budgets, and uncertain predictions. Traditional classifiers,
without additional mechanisms, struggle to maintain performance under concept
drift in malware domains, as their supervised learning formulation cannot
optimize when to defer decisions to manual labeling and adaptation. Modern
malware detection pipelines combine classifiers with monthly active learning
(AL) and rejection mechanisms to mitigate the impact of concept drift. In this
work, we develop a novel formulation of malware detection as a one-step Markov
Decision Process and train a deep reinforcement learning (DRL) agent,
simultaneously optimizing sample classification performance and rejecting
high-risk samples for manual labeling. We evaluated the joint detection and
drift mitigation policy learned by the DRL-based Malware Detection (DRMD) agent
through time-aware evaluations on Android malware datasets subject to realistic
drift requiring multi-year performance stability. The policies learned under
these conditions achieve a higher Area Under Time (AUT) performance compared to
standard classification approaches used in the domain, showing improved
resilience to concept drift. Specifically, the DRMD agent achieved a
$5.18\pm5.44$, $14.49\pm12.86$, and $10.06\pm10.81$ average AUT performance
improvement for the classification only, classification with rejection, and
classification with rejection and AL settings, respectively. Our results
demonstrate for the first time that DRL can facilitate effective malware
detection and improved resiliency to concept drift in the dynamic environment
of the Android malware domain.

</details>


### [132] [Recycling History: Efficient Recommendations from Contextual Dueling Bandits](https://arxiv.org/abs/2508.18841)
*Suryanarayana Sankagiri,Jalal Etesami,Pouria Fatemi,Matthias Grossglauser*

Main category: cs.LG

TL;DR: 论文提出了一种新的上下文决斗老虎机模型，通过用户消费后的比较反馈提升推荐系统性能，并证明了其具有O(√T)的遗憾界。


<details>
  <summary>Details</summary>
Motivation: 现有模型仅捕捉用户的隐式选择，而用户消费后的反馈更可靠，因此提出新模型以利用这种反馈。

Method: 算法推荐一个物品，用户消费后与历史物品比较，通过初始随机探索积累丰富历史以构造信息性查询。

Result: 理论证明算法具有O(√T)的遗憾界，仿真显示重用历史物品比较能显著降低遗憾。

Conclusion: 新模型通过消费后比较反馈提升了性能，且理论分析和仿真结果验证了其有效性。

Abstract: The contextual duelling bandit problem models adaptive recommender systems,
where the algorithm presents a set of items to the user, and the user's choice
reveals their preference. This setup is well suited for implicit choices users
make when navigating a content platform, but does not capture other possible
comparison queries. Motivated by the fact that users provide more reliable
feedback after consuming items, we propose a new bandit model that can be
described as follows. The algorithm recommends one item per time step; after
consuming that item, the user is asked to compare it with another item chosen
from the user's consumption history. Importantly, in our model, this comparison
item can be chosen without incurring any additional regret, potentially leading
to better performance. However, the regret analysis is challenging because of
the temporal dependency in the user's history. To overcome this challenge, we
first show that the algorithm can construct informative queries provided the
history is rich, i.e., satisfies a certain diversity condition. We then show
that a short initial random exploration phase is sufficient for the algorithm
to accumulate a rich history with high probability. This result, proven via
matrix concentration bounds, yields $O(\sqrt{T})$ regret guarantees.
Additionally, our simulations show that reusing past items for comparisons can
lead to significantly lower regret than only comparing between simultaneously
recommended items.

</details>


### [133] [C-Flat++: Towards a More Efficient and Powerful Framework for Continual Learning](https://arxiv.org/abs/2508.18860)
*Wei Li,Hangjie Yuan,Zixiang Zhao,Yifan Zhu,Aojun Lu,Tao Feng,Yanan Sun*

Main category: cs.LG

TL;DR: C-Flat是一种持续学习方法，通过促进平坦的损失景观来提高性能，并提出了高效的C-Flat++框架。


<details>
  <summary>Details</summary>
Motivation: 在持续学习中，平衡新任务的敏感性和保留过去知识的能力是关键。现有方法依赖零阶锐度可能导致次优解。

Method: 提出C-Flat方法，通过平坦损失景观优化持续学习，并扩展为C-Flat++框架以减少更新成本。

Result: 实验表明C-Flat在各种设置下均能提升性能，C-Flat++进一步提高了效率。

Conclusion: C-Flat和C-Flat++在持续学习中表现出色，提供了高效且兼容的解决方案。

Abstract: Balancing sensitivity to new tasks and stability for retaining past knowledge
is crucial in continual learning (CL). Recently, sharpness-aware minimization
has proven effective in transfer learning and has also been adopted in
continual learning (CL) to improve memory retention and learning efficiency.
However, relying on zeroth-order sharpness alone may favor sharper minima over
flatter ones in certain settings, leading to less robust and potentially
suboptimal solutions. In this paper, we propose \textbf{C}ontinual
\textbf{Flat}ness (\textbf{C-Flat}), a method that promotes flatter loss
landscapes tailored for CL. C-Flat offers plug-and-play compatibility, enabling
easy integration with minimal modifications to the code pipeline. Besides, we
present a general framework that integrates C-Flat into all major CL paradigms
and conduct comprehensive comparisons with loss-minima optimizers and
flat-minima-based CL methods. Our results show that C-Flat consistently
improves performance across a wide range of settings. In addition, we introduce
C-Flat++, an efficient yet effective framework that leverages selective
flatness-driven promotion, significantly reducing the update cost required by
C-Flat. Extensive experiments across multiple CL methods, datasets, and
scenarios demonstrate the effectiveness and efficiency of our proposed
approaches. Code is available at https://github.com/WanNaa/C-Flat.

</details>


### [134] [MOCHA: Discovering Multi-Order Dynamic Causality in Temporal Point Processes](https://arxiv.org/abs/2508.18873)
*Yunyang Cao,Juekai Lin,Wenhao Li,Bo Jin*

Main category: cs.LG

TL;DR: MOCHA是一个新颖的框架，用于在时间点过程中发现多阶动态因果关系，通过建模时变有向无环图（DAG）实现高精度事件预测和可解释结构。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖静态或一阶因果结构，忽略了因果关系的多阶性和时变性，MOCHA旨在解决这一问题。

Method: MOCHA将多阶影响建模为潜在时变图上的多跳因果路径，并引入可学习结构权重的时变DAG，施加无环性和稀疏性约束。

Result: 在真实数据集上的实验表明，MOCHA在事件预测中达到最先进性能，并揭示了有意义且可解释的因果结构。

Conclusion: MOCHA不仅提升了事件预测的准确性，还提供了对复杂因果依赖的深入理解。

Abstract: Discovering complex causal dependencies in temporal point processes (TPPs) is
critical for modeling real-world event sequences. Existing methods typically
rely on static or first-order causal structures, overlooking the multi-order
and time-varying nature of causal relationships. In this paper, we propose
MOCHA, a novel framework for discovering multi-order dynamic causality in TPPs.
MOCHA characterizes multi-order influences as multi-hop causal paths over a
latent time-evolving graph. To model such dynamics, we introduce a time-varying
directed acyclic graph (DAG) with learnable structural weights, where
acyclicity and sparsity constraints are enforced to ensure structural validity.
We design an end-to-end differentiable framework that jointly models causal
discovery and TPP dynamics, enabling accurate event prediction and revealing
interpretable structures. Extensive experiments on real-world datasets
demonstrate that MOCHA not only achieves state-of-the-art performance in event
prediction, but also reveals meaningful and interpretable causal structures.

</details>


### [135] [HAEPO: History-Aggregated Exploratory Policy Optimization](https://arxiv.org/abs/2508.18884)
*Gaurish Trivedi,Alakh Sharma,Kartikey Singh Bhandari,Dhruv Kumar,Pratik Narang,Jagat Sesh Challa*

Main category: cs.LG

TL;DR: HAEPO是一种新的探索性策略优化方法，通过历史感知的探索性损失和熵正则化，解决了现有方法在长时任务中探索不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如DPO和GRPO）在长时任务中探索不足，限制了模型性能的提升。

Method: HAEPO通过累积对数似然和Plackett-Luce softmax加权轨迹，结合熵正则化和KL惩罚，实现更广泛的探索和稳定性。

Result: 实验表明，HAEPO在收敛速度、探索深度和奖励对齐方面优于或与PPO、GRPO和DPO相当。

Conclusion: HAEPO提供了一个稳定且可解释的框架，通过显式利用全轨迹历史来平衡探索和稳定性。

Abstract: Exploration is essential in modern learning, from reinforcement learning
environments with small neural policies to large language models (LLMs).
Existing work, such as DPO, leverages full sequence log-likelihoods to capture
an entire trajectory of the model's decisions, while methods like GRPO
aggregate per-token ratios into a trajectory-level update. However, both often
limit exploration on long-horizon tasks. We introduce History-Aggregated
Exploratory Policy Optimization (HAEPO), a history-aware exploratory loss to
combat these shortcomings. HAEPO compresses each trajectory into the sum of its
logarithmic probabilities (a cumulative logarithmic likelihood), and applies a
Plackett-Luce softmax across trajectories to obtain normalized weights
proportional to their returns, thus encouraging broader exploration. We add
entropy regularization to stabilize the aggressive updates to prevent premature
collapse and a soft KL penalty relative to a frozen copy of the previous
(reference) policy. Empirically, HAEPO converges fast, explores thoroughly,
aligns closely with true rewards, and demonstrates robust learning behavior
better or at par with PPO, GRPO, and DPO across diverse tasks. Thus, HAEPO
provides a stable and interpretable framework by explicitly leveraging
full-trajectory history while balancing exploration and stability.

</details>


### [136] [pyFAST: A Modular PyTorch Framework for Time Series Modeling with Multi-source and Sparse Data](https://arxiv.org/abs/2508.18891)
*Zhijin Wang,Senzhen Wu,Yue Hu,Xiufeng Liu*

Main category: cs.LG

TL;DR: pyFAST是一个基于PyTorch的时间序列分析框架，专注于模块化和支持复杂数据场景，如多源、稀疏数据，并提供丰富的模型库和训练工具。


<details>
  <summary>Details</summary>
Motivation: 现有Python库在模块化和对不规则、多源或稀疏数据的支持上存在不足，pyFAST旨在解决这些问题。

Method: 通过数据引擎支持多源加载、动态归一化等复杂场景，并集成LLM架构实现稀疏数据融合，提供模块化模型库。

Result: pyFAST实现了高效的数据处理和模型计算分离，支持多种时间序列任务（如填补和预测）。

Conclusion: pyFAST是一个紧凑而强大的平台，适用于时间序列研究和应用，已开源。

Abstract: Modern time series analysis demands frameworks that are flexible, efficient,
and extensible. However, many existing Python libraries exhibit limitations in
modularity and in their native support for irregular, multi-source, or sparse
data. We introduce pyFAST, a research-oriented PyTorch framework that
explicitly decouples data processing from model computation, fostering a
cleaner separation of concerns and facilitating rapid experimentation. Its data
engine is engineered for complex scenarios, supporting multi-source loading,
protein sequence handling, efficient sequence- and patch-level padding, dynamic
normalization, and mask-based modeling for both imputation and forecasting.
pyFAST integrates LLM-inspired architectures for the alignment-free fusion of
sparse data sources and offers native sparse metrics, specialized loss
functions, and flexible exogenous data fusion. Training utilities include
batch-based streaming aggregation for evaluation and device synergy to maximize
computational efficiency. A comprehensive suite of classical and deep learning
models (Linears, CNNs, RNNs, Transformers, and GNNs) is provided within a
modular architecture that encourages extension. Released under the MIT license
at GitHub, pyFAST provides a compact yet powerful platform for advancing time
series research and applications.

</details>


### [137] [Distance-informed Neural Processes](https://arxiv.org/abs/2508.18903)
*Aishwarya Venkataramanan,Joachim Denzler*

Main category: cs.LG

TL;DR: DNP通过结合全局和局部潜在结构改进不确定性估计，优于标准NPs。


<details>
  <summary>Details</summary>
Motivation: 标准NPs依赖全局潜在变量，难以校准不确定性和捕捉局部数据依赖。

Method: 引入全局和局部潜在变量，通过bi-Lipschitz正则化保持距离关系。

Result: DNP在回归和分类任务中表现优异，不确定性校准更好。

Conclusion: DNP有效提升不确定性估计和分布外数据区分能力。

Abstract: We propose the Distance-informed Neural Process (DNP), a novel variant of
Neural Processes that improves uncertainty estimation by combining global and
distance-aware local latent structures. Standard Neural Processes (NPs) often
rely on a global latent variable and struggle with uncertainty calibration and
capturing local data dependencies. DNP addresses these limitations by
introducing a global latent variable to model task-level variations and a local
latent variable to capture input similarity within a distance-preserving latent
space. This is achieved through bi-Lipschitz regularization, which bounds
distortions in input relationships and encourages the preservation of relative
distances in the latent space. This modeling approach allows DNP to produce
better-calibrated uncertainty estimates and more effectively distinguish in-
from out-of-distribution data. Empirical results demonstrate that DNP achieves
strong predictive performance and improved uncertainty calibration across
regression and classification tasks.

</details>


### [138] [Enhancing Model Privacy in Federated Learning with Random Masking and Quantization](https://arxiv.org/abs/2508.18911)
*Zhibo Xu,Jianhao Zhu,Jingwen Xu,Changze Lv,Zisu Huang,Xiaohua Wang,Muling Wu,Qi Qian,Xiaoqing Zheng,Xuanjing Huang*

Main category: cs.LG

TL;DR: 该方法在联邦学习中保持模型性能的同时，增强了模型参数的保护。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中模型参数保护不足的问题。

Method: 提出了一种新方法，在联邦学习环境中优化模型参数保护。

Result: 实验表明，该方法在多种模型和任务中表现优异，且保护效果优于基线方法。

Conclusion: 该方法在联邦学习中实现了性能与安全性的平衡。

Abstract: Experimental results across various models and tasks demonstrate that our
approach not only maintains strong model performance in federated learning
settings but also achieves enhanced protection of model parameters compared to
baseline methods.

</details>


### [139] [Generalization Bound for a General Class of Neural Ordinary Differential Equations](https://arxiv.org/abs/2508.18920)
*Madhusudan Verma,Manoj Kumar*

Main category: cs.LG

TL;DR: 本文研究了神经ODE在广义非线性动力学下的泛化误差界，填补了现有研究的空白。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注线性动力学或依赖采样间隔的神经控制ODE，缺乏对广义非线性动力学神经ODE泛化误差界的分析。

Method: 分析了一类更广泛的神经ODE，其动力学函数为广义非线性函数（时间依赖或独立），且满足Lipschitz连续性条件。

Result: 证明了在Lipschitz条件下，神经ODE的解具有有界变差，并建立了时间依赖和独立情况的泛化界。

Conclusion: 首次推导了广义非线性动力学神经ODE的泛化界，并探讨了过参数化和域约束的影响。

Abstract: Neural ordinary differential equations (neural ODEs) are a popular type of
deep learning model that operate with continuous-depth architectures. To assess
how well such models perform on unseen data, it is crucial to understand their
generalization error bounds. Previous research primarily focused on the linear
case for the dynamics function in neural ODEs - Marion, P. (2023), or provided
bounds for Neural Controlled ODEs that depend on the sampling interval
Bleistein et al. (2023). In this work, we analyze a broader class of neural
ODEs where the dynamics function is a general nonlinear function, either time
dependent or time independent, and is Lipschitz continuous with respect to the
state variables. We showed that under this Lipschitz condition, the solutions
to neural ODEs have solutions with bounded variations. Based on this
observation, we establish generalization bounds for both time-dependent and
time-independent cases and investigate how overparameterization and domain
constraints influence these bounds. To our knowledge, this is the first
derivation of generalization bounds for neural ODEs with general nonlinear
dynamics.

</details>


### [140] [HierCVAE: Hierarchical Attention-Driven Conditional Variational Autoencoders for Multi-Scale Temporal Modeling](https://arxiv.org/abs/2508.18922)
*Yao Wu*

Main category: cs.LG

TL;DR: HierCVAE是一种结合分层注意力机制和条件变分自编码器的新架构，用于处理复杂系统中的多时间尺度依赖性和不确定性。


<details>
  <summary>Details</summary>
Motivation: 复杂系统中的时间建模需要捕捉多时间尺度的依赖性并管理不确定性，现有方法难以兼顾这两点。

Method: HierCVAE采用三层注意力结构（局部、全局、跨时间）和多模态条件编码，结合ResFormer块和显式不确定性量化。

Result: 在能源消耗数据集上，HierCVAE的预测精度提高了15-40%，并在不确定性校准和长期预测中表现优异。

Conclusion: HierCVAE在多变量依赖性和长期预测中优于现有方法，具有显著的实际应用价值。

Abstract: Temporal modeling in complex systems requires capturing dependencies across
multiple time scales while managing inherent uncertainties. We propose
HierCVAE, a novel architecture that integrates hierarchical attention
mechanisms with conditional variational autoencoders to address these
challenges. HierCVAE employs a three-tier attention structure (local, global,
cross-temporal) combined with multi-modal condition encoding to capture
temporal, statistical, and trend information. The approach incorporates
ResFormer blocks in the latent space and provides explicit uncertainty
quantification via prediction heads. Through evaluations on energy consumption
datasets, HierCVAE demonstrates a 15-40% improvement in prediction accuracy and
superior uncertainty calibration compared to state-of-the-art methods,
excelling in long-term forecasting and complex multi-variate dependencies.

</details>


### [141] [Energy-Based Flow Matching for Generating 3D Molecular Structure](https://arxiv.org/abs/2508.18949)
*Wenyin Zhou,Christopher Iliffe Sprague,Vsevolod Viliuga,Matteo Tadiello,Arne Elofsson,Hossein Azizpour*

Main category: cs.LG

TL;DR: 本文提出了一种基于能量视角的流匹配方法，用于分子结构生成，通过迭代映射随机配置到目标结构，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 分子结构生成在生物应用中至关重要，如分子对接和蛋白质折叠。现有生成模型（如扩散模型和流匹配）虽取得进展，但仍有改进空间。

Method: 采用能量视角改进流匹配，通过深度网络学习迭代映射函数，将随机配置映射到目标结构。

Result: 在蛋白质对接和蛋白质骨架生成任务中，该方法优于现有的流匹配和扩散模型。

Conclusion: 该方法概念简单、理论合理且实证有效，为分子结构生成提供了新思路。

Abstract: Molecular structure generation is a fundamental problem that involves
determining the 3D positions of molecules' constituents. It has crucial
biological applications, such as molecular docking, protein folding, and
molecular design. Recent advances in generative modeling, such as diffusion
models and flow matching, have made great progress on these tasks by modeling
molecular conformations as a distribution. In this work, we focus on flow
matching and adopt an energy-based perspective to improve training and
inference of structure generation models. Our view results in a mapping
function, represented by a deep network, that is directly learned to
\textit{iteratively} map random configurations, i.e. samples from the source
distribution, to target structures, i.e. points in the data manifold. This
yields a conceptually simple and empirically effective flow matching setup that
is theoretically justified and has interesting connections to fundamental
properties such as idempotency and stability, as well as the empirically useful
techniques such as structure refinement in AlphaFold. Experiments on protein
docking as well as protein backbone generation consistently demonstrate the
method's effectiveness, where it outperforms recent baselines of
task-associated flow matching and diffusion models, using a similar
computational budget.

</details>


### [142] [Estimating Conditional Covariance between labels for Multilabel Data](https://arxiv.org/abs/2508.18951)
*Laurence A. F. Park,Jesse Read*

Main category: cs.LG

TL;DR: 比较三种模型（多元Probit、多元Bernoulli和分阶段Logit）用于估计多标签条件标签协方差，发现多元Probit模型误差率最低。


<details>
  <summary>Details</summary>
Motivation: 多标签数据的标签依赖性分析对模型应用至关重要，但直接测量独立性困难。

Method: 通过多元Probit、多元Bernoulli和分阶段Logit模型估计条件标签协方差。

Result: 所有模型在协方差强度下表现相似，但会误判依赖性；多元Probit误差最低。

Conclusion: 多元Probit模型在多标签协方差估计中表现最佳。

Abstract: Multilabel data should be analysed for label dependence before applying
multilabel models. Independence between multilabel data labels cannot be
measured directly from the label values due to their dependence on the set of
covariates $\vec{x}$, but can be measured by examining the conditional label
covariance using a multivariate Probit model. Unfortunately, the multivariate
Probit model provides an estimate of its copula covariance, and so might not be
reliable in estimating constant covariance and dependent covariance. In this
article, we compare three models (Multivariate Probit, Multivariate Bernoulli
and Staged Logit) for estimating the constant and dependent multilabel
conditional label covariance. We provide an experiment that allows us to
observe each model's measurement of conditional covariance. We found that all
models measure constant and dependent covariance equally well, depending on the
strength of the covariance, but the models all falsely detect that dependent
covariance is present for data where constant covariance is present. Of the
three models, the Multivariate Probit model had the lowest error rate.

</details>


### [143] [On the Generalisation of Koopman Representations for Chaotic System Control](https://arxiv.org/abs/2508.18954)
*Kyriakos Hjikakou,Juan Diego Cardenas Cartagena,Matthia Sabatelli*

Main category: cs.LG

TL;DR: 研究探讨了Koopman表示在混沌动力系统中的泛化能力，特别是在预测和控制任务中的可迁移性。


<details>
  <summary>Details</summary>
Motivation: 研究Koopman表示是否能够跨任务（预测和控制）泛化，并验证其在混沌系统中的有效性。

Method: 提出三阶段方法：通过自编码学习Koopman嵌入，预训练Transformer进行状态预测，微调用于安全关键控制。

Result: Koopman嵌入优于标准和物理信息PCA基线，且在微调时固定预训练权重不会降低性能。

Conclusion: Koopman嵌入可作为物理信息多任务学习的基础，其表示捕获了可重用的动态结构。

Abstract: This paper investigates the generalisability of Koopman-based representations
for chaotic dynamical systems, focusing on their transferability across
prediction and control tasks. Using the Lorenz system as a testbed, we propose
a three-stage methodology: learning Koopman embeddings through autoencoding,
pre-training a transformer on next-state prediction, and fine-tuning for
safety-critical control. Our results show that Koopman embeddings outperform
both standard and physics-informed PCA baselines, achieving accurate and
data-efficient performance. Notably, fixing the pre-trained transformer weights
during fine-tuning leads to no performance degradation, indicating that the
learned representations capture reusable dynamical structure rather than
task-specific patterns. These findings support the use of Koopman embeddings as
a foundation for multi-task learning in physics-informed machine learning. A
project page is available at https://kikisprdx.github.io/.

</details>


### [144] [PAX-TS: Model-agnostic multi-granular explanations for time series forecasting via localized perturbations](https://arxiv.org/abs/2508.18982)
*Tim Kreuzer,Jelena Zdravkovic,Panagiotis Papapetrou*

Main category: cs.LG

TL;DR: PAX-TS是一种模型无关的后处理算法，用于解释时间序列预测模型及其预测结果，通过局部输入扰动生成多粒度解释，并能捕捉跨通道相关性。


<details>
  <summary>Details</summary>
Motivation: 现代预测模型通常不透明且缺乏解释性，而现有的后处理方法（如LIME）不适用于预测场景。

Method: 基于局部输入扰动，生成多粒度解释，并分析跨通道相关性。

Result: PAX-TS能有效捕捉模型行为，识别出6类重复出现的模式，这些模式与预测性能相关。

Conclusion: PAX-TS能详细展示预测模型机制，并回答实际预测问题。

Abstract: Time series forecasting has seen considerable improvement during the last
years, with transformer models and large language models driving advancements
of the state of the art. Modern forecasting models are generally opaque and do
not provide explanations for their forecasts, while well-known post-hoc
explainability methods like LIME are not suitable for the forecasting context.
We propose PAX-TS, a model-agnostic post-hoc algorithm to explain time series
forecasting models and their forecasts. Our method is based on localized input
perturbations and results in multi-granular explanations. Further, it is able
to characterize cross-channel correlations for multivariate time series
forecasts. We clearly outline the algorithmic procedure behind PAX-TS,
demonstrate it on a benchmark with 7 algorithms and 10 diverse datasets,
compare it with two other state-of-the-art explanation algorithms, and present
the different explanation types of the method. We found that the explanations
of high-performing and low-performing algorithms differ on the same datasets,
highlighting that the explanations of PAX-TS effectively capture a model's
behavior. Based on time step correlation matrices resulting from the benchmark,
we identify 6 classes of patterns that repeatedly occur across different
datasets and algorithms. We found that the patterns are indicators of
performance, with noticeable differences in forecasting error between the
classes. Lastly, we outline a multivariate example where PAX-TS demonstrates
how the forecasting model takes cross-channel correlations into account. With
PAX-TS, time series forecasting models' mechanisms can be illustrated in
different levels of detail, and its explanations can be used to answer
practical questions on forecasts.

</details>


### [145] [FedProtoKD: Dual Knowledge Distillation with Adaptive Class-wise Prototype Margin for Heterogeneous Federated Learning](https://arxiv.org/abs/2508.19009)
*Md Anwar Hossen,Fatema Siddika,Wensheng Zhang,Anuj Sharma,Ali Jannesari*

Main category: cs.LG

TL;DR: FedProtoKD是一种改进的异构联邦学习方法，通过双知识蒸馏和对比学习解决原型聚合问题，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决异构联邦学习中原型聚合导致的性能下降问题。

Method: 使用双知识蒸馏机制和对比学习优化原型聚合。

Result: 在多种设置下平均提升1.13%至34.13%的准确率。

Conclusion: FedProtoKD显著优于现有方法，解决了原型聚合的局限性。

Abstract: Heterogeneous Federated Learning (HFL) has gained attention for its ability
to accommodate diverse models and heterogeneous data across clients.
Prototype-based HFL methods emerge as a promising solution to address
statistical heterogeneity and privacy challenges, paving the way for new
advancements in HFL research. This method focuses on sharing only
class-representative prototypes among heterogeneous clients. However, these
prototypes are often aggregated on the server using weighted averaging, leading
to sub-optimal global knowledge; these cause the shrinking of aggregated
prototypes, which negatively affects the model performance in scenarios when
models are heterogeneous and data distributions are extremely non-IID. We
propose FedProtoKD in a Heterogeneous Federated Learning setting, using an
enhanced dual-knowledge distillation mechanism to improve the system
performance with clients' logits and prototype feature representation. We aim
to resolve the prototype margin-shrinking problem using a contrastive
learning-based trainable server prototype by leveraging a class-wise adaptive
prototype margin. Furthermore, we assess the importance of public samples using
the closeness of the sample's prototype to its class representative prototypes,
which enhances learning performance. FedProtoKD achieved average improvements
of 1.13% up to 34.13% accuracy across various settings and significantly
outperforms existing state-of-the-art HFL methods.

</details>


### [146] [STDiff: A State Transition Diffusion Framework for Time Series Imputation in Industrial Systems](https://arxiv.org/abs/2508.19011)
*Gary Simethy,Daniel Ortiz-Arroyo,Petar Durdevic*

Main category: cs.LG

TL;DR: STDiff是一种基于条件去噪扩散模型的时间序列缺失值填补方法，适用于非平稳工业系统。


<details>
  <summary>Details</summary>
Motivation: 工业系统中的动态性由控制行为驱动且高度非平稳，传统固定时间窗口方法难以应对长时间缺失。

Method: STDiff使用因果偏置的条件去噪扩散模型，基于最近已知状态和控制输入逐步生成缺失值。

Result: 在模拟和真实工业数据上，STDiff填补效果优于窗口模型，尤其在长时间缺失时优势明显。

Conclusion: STDiff证明了动态感知的条件填补在工业时间序列中的有效性，并讨论了计算权衡和扩展潜力。

Abstract: Most deep learning methods for imputing missing values treat the task as
completing patterns within a fixed time window. This assumption often fails in
industrial systems, where dynamics are driven by control actions, are highly
non-stationary, and can experience long, uninterrupted gaps. We propose STDiff,
which reframes imputation as learning how the system evolves from one state to
the next. STDiff uses a conditional denoising diffusion model with a causal
bias aligned to control theory, generating missing values step-by-step based on
the most recent known state and relevant control or environmental inputs. On a
public wastewater treatment dataset with simulated missing blocks, STDiff
consistently achieves the lowest errors, with its advantage increasing for
longer gaps. On a raw industrial dataset with substantial real gaps, it
produces trajectories that remain dynamically plausible, in contrast to
window-based models that tend to flatten or over-smooth. These results support
dynamics-aware, explicitly conditioned imputation as a robust approach for
industrial time series, and we discuss computational trade-offs and extensions
to broader domains.

</details>


### [147] [Learning with springs and sticks](https://arxiv.org/abs/2508.19015)
*Luis Mantilla Calderón,Alán Aspuru-Guzik*

Main category: cs.LG

TL;DR: 研究了一种由弹簧和木棒组成的简单动力系统，能够近似任意连续函数，并通过能量最小化实现学习。


<details>
  <summary>Details</summary>
Motivation: 探索从物理角度理解学习过程，利用弹簧和木棒模拟函数逼近和能量最小化。

Method: 使用木棒模拟分段线性逼近，弹簧势能编码损失函数，通过耗散收敛到最小能量配置。

Result: 系统在回归任务中表现与多层感知机相当，并发现自由能变化与学习能力的关系。

Conclusion: 提出了一个简单物理模型，有助于从物理角度理解学习系统，并发现了热力学学习障碍。

Abstract: Learning is a physical process. Here, we aim to study a simple dynamical
system composed of springs and sticks capable of arbitrarily approximating any
continuous function. The main idea of our work is to use the sticks to mimic a
piecewise-linear approximation of the given function, use the potential energy
of springs to encode a desired mean squared error loss function, and converge
to a minimum-energy configuration via dissipation. We apply the proposed
simulation system to regression tasks and show that its performance is
comparable to that of multi-layer perceptrons. In addition, we study the
thermodynamic properties of the system and find a relation between the free
energy change of the system and its ability to learn an underlying data
distribution. We empirically find a \emph{thermodynamic learning barrier} for
the system caused by the fluctuations of the environment, whereby the system
cannot learn if its change in free energy hits such a barrier. We believe this
simple model can help us better understand learning systems from a physical
point of view.

</details>


### [148] [Working My Way Back to You: Resource-Centric Next-Activity Prediction](https://arxiv.org/abs/2508.19016)
*Kelly Kurowski,Xixi Lu,Hajo A Reijers*

Main category: cs.LG

TL;DR: 论文研究了基于资源视角的下一活动预测，评估了四种模型和三种编码策略，发现LightGBM和Transformer模型表现最佳，资源中心方法为PPM研究开辟了新方向。


<details>
  <summary>Details</summary>
Motivation: 现有研究多从控制流视角进行预测，而资源视角能带来工作组织、负载平衡等额外优势，但其在下一活动预测中的作用尚未探索。

Method: 评估了四种预测模型（LightGBM、Transformer等）和三种编码策略（如2-gram活动转换），在四个真实数据集上进行实验。

Result: LightGBM和Transformer在2-gram编码下表现最佳，随机森林在结合2-gram和活动重复特征的编码中受益最多，后者平均准确率最高。

Conclusion: 资源中心方法为PPM提供了新思路，支持更智能的资源分配和个性化员工支持，未来研究潜力巨大。

Abstract: Predictive Process Monitoring (PPM) aims to train models that forecast
upcoming events in process executions. These predictions support early
bottleneck detection, improved scheduling, proactive interventions, and timely
communication with stakeholders. While existing research adopts a control-flow
perspective, we investigate next-activity prediction from a resource-centric
viewpoint, which offers additional benefits such as improved work organization,
workload balancing, and capacity forecasting. Although resource information has
been shown to enhance tasks such as process performance analysis, its role in
next-activity prediction remains unexplored. In this study, we evaluate four
prediction models and three encoding strategies across four real-life datasets.
Compared to the baseline, our results show that LightGBM and Transformer models
perform best with an encoding based on 2-gram activity transitions, while
Random Forest benefits most from an encoding that combines 2-gram transitions
and activity repetition features. This combined encoding also achieves the
highest average accuracy. This resource-centric approach could enable smarter
resource allocation, strategic workforce planning, and personalized employee
support by analyzing individual behavior rather than case-level progression.
The findings underscore the potential of resource-centric next-activity
prediction, opening up new venues for research on PPM.

</details>


### [149] [Metric Matters: A Formal Evaluation of Similarity Measures in Active Learning for Cyber Threat Intelligence](https://arxiv.org/abs/2508.19019)
*Sidahmed Benabderrahmane,Talal Rahwan*

Main category: cs.LG

TL;DR: 提出了一种基于主动学习的异常检测框架，利用相似性搜索优化决策空间，提升APT检测效果。


<details>
  <summary>Details</summary>
Motivation: APT攻击隐蔽性强且检测数据集类别极度不平衡，传统方法难以应对。

Method: 基于注意力自编码器，通过特征空间相似性识别正常与异常实例，减少人工标注需求。

Result: 实验表明相似性度量选择显著影响模型收敛性、检测准确性和标签效率。

Conclusion: 为威胁情报和网络防御中的主动学习流程提供了相似性函数选择的实用指导。

Abstract: Advanced Persistent Threats (APTs) pose a severe challenge to cyber defense
due to their stealthy behavior and the extreme class imbalance inherent in
detection datasets. To address these issues, we propose a novel active
learning-based anomaly detection framework that leverages similarity search to
iteratively refine the decision space. Built upon an Attention-Based
Autoencoder, our approach uses feature-space similarity to identify normal-like
and anomaly-like instances, thereby enhancing model robustness with minimal
oracle supervision. Crucially, we perform a formal evaluation of various
similarity measures to understand their influence on sample selection and
anomaly ranking effectiveness. Through experiments on diverse datasets,
including DARPA Transparent Computing APT traces, we demonstrate that the
choice of similarity metric significantly impacts model convergence, anomaly
detection accuracy, and label efficiency. Our results offer actionable insights
for selecting similarity functions in active learning pipelines tailored for
threat intelligence and cyber defense.

</details>


### [150] [GRADSTOP: Early Stopping of Gradient Descent via Posterior Sampling](https://arxiv.org/abs/2508.19028)
*Arash Jamshidi,Lauri Seppäläinen,Katsiaryna Haitsiukevich,Hoang Phuc Hau Luu,Anton Björklund,Kai Puolamäki*

Main category: cs.LG

TL;DR: Gradstop是一种新的随机早停方法，利用梯度信息避免过拟合，无需验证集。


<details>
  <summary>Details</summary>
Motivation: 传统早停方法需要验证集，减少了训练数据。Gradstop利用梯度信息，避免数据浪费。

Method: 通过梯度信息估计贝叶斯后验，将早停问题定义为从后验中采样，并基于后验制定停止准则。

Result: 在测试数据上表现良好，优于基于验证集的早停方法，尤其适用于数据有限场景。

Conclusion: Gradstop是一种高效且计算开销小的早停方法，适合集成到梯度下降库中。

Abstract: Machine learning models are often learned by minimising a loss function on
the training data using a gradient descent algorithm. These models often suffer
from overfitting, leading to a decline in predictive performance on unseen
data. A standard solution is early stopping using a hold-out validation set,
which halts the minimisation when the validation loss stops decreasing.
However, this hold-out set reduces the data available for training. This paper
presents {\sc gradstop}, a novel stochastic early stopping method that only
uses information in the gradients, which are produced by the gradient descent
algorithm ``for free.'' Our main contributions are that we estimate the
Bayesian posterior by the gradient information, define the early stopping
problem as drawing sample from this posterior, and use the approximated
posterior to obtain a stopping criterion. Our empirical evaluation shows that
{\sc gradstop} achieves a small loss on test data and compares favourably to a
validation-set-based stopping criterion. By leveraging the entire dataset for
training, our method is particularly advantageous in data-limited settings,
such as transfer learning. It can be incorporated as an optional feature in
gradient descent libraries with only a small computational overhead. The source
code is available at https://github.com/edahelsinki/gradstop.

</details>


### [151] [When recalling in-context, Transformers are not SSMs](https://arxiv.org/abs/2508.19029)
*Destiny Okpekpe,Antonio Orvieto*

Main category: cs.LG

TL;DR: 本文探讨了现代循环深度学习模型（如状态空间模型）在推理和记忆任务中的潜在不足，重点关注关联回忆（AR）基准，并分析了缩放和优化问题对性能的影响。


<details>
  <summary>Details</summary>
Motivation: 尽管现代循环模型具有次二次复杂度优势，但与Transformer相比，其在推理和记忆任务中表现不佳，尤其是在AR任务中。本文旨在深入分析这些问题。

Method: 通过实验分析学习率对循环模型性能的影响，比较循环模型和基于注意力的模型在宽度和深度缩放中的表现，并研究单层Transformer的训练动态。

Result: 发现学习率对循环模型性能至关重要；循环模型和注意力模型在宽度和深度缩放中表现不同；单层Transformer的训练动态与双层模型类似。

Conclusion: 需要进一步研究以稳定循环模型的训练，并优化模型架构以提高性能。

Abstract: Despite the advantageous subquadratic complexity of modern recurrent deep
learning models -- such as state-space models (SSMs) -- recent studies have
highlighted their potential shortcomings compared to transformers on reasoning
and memorization tasks. In this paper, we dive deeper into one of such
benchmarks: associative recall (AR), which has been shown to correlate well
with language modeling performance, and inspect in detail the effects of
scaling and optimization issues in recently proposed token mixing strategies.
We first demonstrate that, unlike standard transformers, the choice of learning
rate plays a critical role in the performance of modern recurrent models: an
issue that can severely affect reported performance in previous works and
suggests further research is needed to stabilize training. Next, we show that
recurrent and attention-based models exhibit contrasting benefits when scaling
in width as opposed to depth, with attention being notably unable to solve AR
when limited to a single layer. We then further inspect 1-layer transformers,
revealing that despite their poor performance, their training dynamics
surprisingly resemble the formation of induction heads, a phenomenon previously
observed only in their 2-layer counterparts. Finally, through architectural
ablations, we study how components affects Transformer and Mamba's performance
and optimization stability.

</details>


### [152] [Breaking the Black Box: Inherently Interpretable Physics-Informed Machine Learning for Imbalanced Seismic Data](https://arxiv.org/abs/2508.19031)
*Vemula Sreenath,Filippo Gatti,Pierre Jehel*

Main category: cs.LG

TL;DR: 提出了一种透明的地震动模型（GMM）架构，使用HazBinLoss函数解决传统机器学习方法的不透明性和数据不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习方法在GMM中难以解释且数据不平衡，限制了其在关键决策中的应用。

Method: 开发了透明ML架构，通过HazBinLoss函数单独处理输入并线性组合，同时加权处理关键数据。

Result: 模型捕捉了已知地震学原理，性能与现有GMM相当且保持透明。

Conclusion: 该框架促进了基于ML的风险评估和灾害规划的广泛应用。

Abstract: Ground motion models (GMMs) predict how strongly the ground will shake during
an earthquake. They are essential for structural analysis, seismic design, and
seismic risk assessment studies. Traditional machine learning (ML) approaches
are popular to develop GMMs, due to large earthquake databases worldwide.
However, they operate as "black boxes," which are hard to interpret and trust,
limiting their use in high-stake decisions. Additionally, these databases
suffer from significant data imbalances: fewer large, critically damaging
records near the fault compared to abundant, less severely damaging distant
records. These two limitations are addressed in this work by developing a
transparent ML architecture using the HazBinLoss function. Each input (e.g.,
magnitude, distance, their interaction term, etc.) is processed separately and
added linearly to obtain the output, resulting in exact contribution of each
term. The HazBinLoss function assigns higher weights to critical near-field
large magnitude records and lower weights to less-critical far-field smaller
magnitude records, during training to prevent underprediction of the most
damaging scenarios. Our model captures known seismological principles and
achieves comparable performance with established GMMs while maintaining
transparency. This framework enables broader adoption of ML-based approaches
for risk assessment studies and disaster planning.

</details>


### [153] [Automated discovery of finite volume schemes using Graph Neural Networks](https://arxiv.org/abs/2508.19052)
*Paul Garnier,Jonathan Viquerat,Elie Hachem*

Main category: cs.LG

TL;DR: GNNs不仅可用于数值模拟，还能通过符号回归生成数值方案，包括一阶和二阶有限体积格式。


<details>
  <summary>Details</summary>
Motivation: 探索GNN在传统近似角色之外的潜力，特别是在生成数值方案方面的能力。

Method: 结合符号回归和GNN，从两节点图数据中学习并推广到非分布外网格；使用无监督PINN损失恢复数值方案。

Result: GNN成功重现了一阶有限体积格式，并自主发现了二阶修正项和中点格式。

Conclusion: GNN不仅是强大的近似工具，还能主动推动新型数值方法的开发。

Abstract: Graph Neural Networks (GNNs) have deeply modified the landscape of numerical
simulations by demonstrating strong capabilities in approximating solutions of
physical systems. However, their ability to extrapolate beyond their training
domain (\textit{e.g.} larger or structurally different graphs) remains
uncertain. In this work, we establish that GNNs can serve purposes beyond their
traditional role, and be exploited to generate numerical schemes, in
conjunction with symbolic regression. First, we show numerically and
theoretically that a GNN trained on a dataset consisting solely of two-node
graphs can extrapolate a first-order Finite Volume (FV) scheme for the heat
equation on out-of-distribution, unstructured meshes. Specifically, if a GNN
achieves a loss $\varepsilon$ on such a dataset, it implements the FV scheme
with an error of $\mathcal{O}(\varepsilon)$. Using symbolic regression, we show
that the network effectively rediscovers the exact analytical formulation of
the standard first-order FV scheme. We then extend this approach to an
unsupervised context: the GNN recovers the first-order FV scheme using only a
residual loss similar to Physics-Informed Neural Networks (PINNs) with no
access to ground-truth data. Finally, we push the methodology further by
considering higher-order schemes: we train (i) a 2-hop and (ii) a 2-layers GNN
using the same PINN loss, that autonomously discover (i) a second-order
correction term to the initial scheme using a 2-hop stencil, and (ii) the
classic second-order midpoint scheme. These findings follows a recent paradigm
in scientific computing: GNNs are not only strong approximators, but can be
active contributors to the development of novel numerical methods.

</details>


### [154] [Tackling Federated Unlearning as a Parameter Estimation Problem](https://arxiv.org/abs/2508.19065)
*Antonio Balordi,Lorenzo Manini,Fabio Stella,Alessio Merlo*

Main category: cs.LG

TL;DR: 提出了一种基于信息论的高效联邦遗忘框架，通过二阶Hessian信息选择性重置敏感参数，实现隐私保护和高效性能。


<details>
  <summary>Details</summary>
Motivation: 隐私法规要求从深度学习模型中删除数据，这在联邦学习中尤为困难，因为数据保留在客户端，完全重新训练或协调更新通常不可行。

Method: 使用二阶Hessian信息识别并选择性重置对遗忘数据最敏感的模型参数，随后进行最小化联邦重新训练。

Result: 在基准数据集上表现出强隐私性（MIA攻击成功率接近随机）和高性能（归一化准确率≈0.9），并能有效消除恶意后门攻击。

Conclusion: 该框架为联邦学习中的数据遗忘提供了实用解决方案，兼顾隐私保护和模型性能。

Abstract: Privacy regulations require the erasure of data from deep learning models.
This is a significant challenge that is amplified in Federated Learning, where
data remains on clients, making full retraining or coordinated updates often
infeasible. This work introduces an efficient Federated Unlearning framework
based on information theory, modeling leakage as a parameter estimation
problem. Our method uses second-order Hessian information to identify and
selectively reset only the parameters most sensitive to the data being
forgotten, followed by minimal federated retraining. This model-agnostic
approach supports categorical and client unlearning without requiring server
access to raw client data after initial information aggregation. Evaluations on
benchmark datasets demonstrate strong privacy (MIA success near random,
categorical knowledge erased) and high performance (Normalized Accuracy against
re-trained benchmarks of $\approx$ 0.9), while aiming for increased efficiency
over complete retraining. Furthermore, in a targeted backdoor attack scenario,
our framework effectively neutralizes the malicious trigger, restoring model
integrity. This offers a practical solution for data forgetting in FL.

</details>


### [155] [Dynamic Triangulation-Based Graph Rewiring for Graph Neural Networks](https://arxiv.org/abs/2508.19071)
*Hugo Attali,Thomas Papastergiou,Nathalie Pernelle,Fragkiskos D. Malliaros*

Main category: cs.LG

TL;DR: TRIGON是一种新型图重布线框架，通过多视图学习选择相关三角形，优化图结构以提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决图神经网络中因图拓扑结构导致的过压缩和过平滑问题。

Method: 通过联合优化三角形选择和下游分类任务，构建非平面三角剖分图。

Result: 在节点分类任务中优于现有方法，改善了图的直径、谱间隙和有效电阻等结构特性。

Conclusion: TRIGON通过优化图拓扑结构，显著提升了图神经网络的性能。

Abstract: Graph Neural Networks (GNNs) have emerged as the leading paradigm for
learning over graph-structured data. However, their performance is limited by
issues inherent to graph topology, most notably oversquashing and
oversmoothing. Recent advances in graph rewiring aim to mitigate these
limitations by modifying the graph topology to promote more effective
information propagation. In this work, we introduce TRIGON, a novel framework
that constructs enriched, non-planar triangulations by learning to select
relevant triangles from multiple graph views. By jointly optimizing triangle
selection and downstream classification performance, our method produces a
rewired graph with markedly improved structural properties such as reduced
diameter, increased spectral gap, and lower effective resistance compared to
existing rewiring methods. Empirical results demonstrate that TRIGON
outperforms state-of-the-art approaches on node classification tasks across a
range of homophilic and heterophilic benchmarks.

</details>


### [156] [APT-LLM: Exploiting Arbitrary-Precision Tensor Core Computing for LLM Acceleration](https://arxiv.org/abs/2508.19087)
*Shaobo Ma,Chao Fang,Haikuo Shao,Zhongfeng Wang*

Main category: cs.LG

TL;DR: APT-LLM提出了一种针对任意精度大语言模型的高效加速方案，通过新型数据格式、矩阵乘法方法和内存管理优化，显著提升了推理速度。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的计算需求巨大，限制了部署和实时性能。现有量化方法在GPU上实现超低比特量化时面临挑战，如Tensor Core支持不足、内存管理低效等。

Method: 1. 引入双极INT数据格式；2. 开发支持任意精度的矩阵乘法方法；3. 提出基于数据恢复的内存管理系统；4. 动态选择最优内核配置。

Result: 在RTX 3090上，APT-LLM比FP16基线快3.99倍，比CUTLASS INT4快2.16倍；在RTX 4090和H800上，分别快2.44倍和1.65倍。

Conclusion: APT-LLM通过综合优化方案，显著提升了任意精度大语言模型的推理效率，适用于不同架构和精度设置。

Abstract: Large language models (LLMs) have revolutionized AI applications, yet their
enormous computational demands severely limit deployment and real-time
performance. Quantization methods can help reduce computational costs, however,
attaining the extreme efficiency associated with ultra-low-bit quantized LLMs
at arbitrary precision presents challenges on GPUs. This is primarily due to
the limited support for GPU Tensor Cores, inefficient memory management, and
inflexible kernel optimizations. To tackle these challenges, we propose a
comprehensive acceleration scheme for arbitrary precision LLMs, namely APT-LLM.
Firstly, we introduce a novel data format, bipolar-INT, which allows for
efficient and lossless conversion with signed INT, while also being more
conducive to parallel computation. We also develop a matrix multiplication
(MatMul) method allowing for arbitrary precision by dismantling and
reassembling matrices at the bit level. This method provides flexible precision
and optimizes the utilization of GPU Tensor Cores. In addition, we propose a
memory management system focused on data recovery, which strategically employs
fast shared memory to substantially increase kernel execution speed and reduce
memory access latency. Finally, we develop a kernel mapping method that
dynamically selects the optimal configurable hyperparameters of kernels for
varying matrix sizes, enabling optimal performance across different LLM
architectures and precision settings. In LLM inference, APT-LLM achieves up to
a 3.99$\times$ speedup compared to FP16 baselines and a 2.16$\times$ speedup
over NVIDIA CUTLASS INT4 acceleration on RTX 3090. On RTX 4090 and H800,
APT-LLM achieves up to 2.44$\times$ speedup over FP16 and 1.65$\times$ speedup
over CUTLASS integer baselines.

</details>


### [157] [Composition and Alignment of Diffusion Models using Constrained Learning](https://arxiv.org/abs/2508.19104)
*Shervin Khalafi,Ignacio Hounie,Dongsheng Ding,Alejandro Ribeiro*

Main category: cs.LG

TL;DR: 提出了一种约束优化框架，统一了扩散模型的对齐和组合，通过满足奖励约束和保持与预训练模型的接近性，有效生成满足多属性的样本。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法保证生成的样本同时满足多个竞争属性，因此需要一种新方法来统一对齐和组合，确保样本满足所有期望属性。

Method: 采用约束优化框架，结合拉格朗日对偶训练算法，理论分析了约束对齐和组合问题的解。

Result: 实验证明，该方法在图像生成中有效满足约束，优于等权重方法。

Conclusion: 提出的框架在扩散模型的对齐和组合中表现出色，能够同时满足多个竞争属性。

Abstract: Diffusion models have become prevalent in generative modeling due to their
ability to sample from complex distributions. To improve the quality of
generated samples and their compliance with user requirements, two commonly
used methods are: (i) Alignment, which involves fine-tuning a diffusion model
to align it with a reward; and (ii) Composition, which combines several
pre-trained diffusion models, each emphasizing a desirable attribute in the
generated outputs. However, trade-offs often arise when optimizing for multiple
rewards or combining multiple models, as they can often represent competing
properties. Existing methods cannot guarantee that the resulting model
faithfully generates samples with all the desired properties. To address this
gap, we propose a constrained optimization framework that unifies alignment and
composition of diffusion models by enforcing that the aligned model satisfies
reward constraints and/or remains close to (potentially multiple) pre-trained
models. We provide a theoretical characterization of the solutions to the
constrained alignment and composition problems and develop a Lagrangian-based
primal-dual training algorithm to approximate these solutions. Empirically, we
demonstrate the effectiveness and merits of our proposed approach in image
generation, applying it to alignment and composition, and show that our aligned
or composed model satisfies constraints effectively, and improves on the
equally-weighted approach. Our implementation can be found at
https://github.com/shervinkhalafi/constrained_comp_align.

</details>


### [158] [Active Query Selection for Crowd-Based Reinforcement Learning](https://arxiv.org/abs/2508.19132)
*Jonathan Erskine,Taku Yamagata,Raúl Santos-Rodríguez*

Main category: cs.LG

TL;DR: 提出了一种结合概率众包建模和主动学习的新框架，用于偏好强化学习，以高效利用稀缺的人类反馈。


<details>
  <summary>Details</summary>
Motivation: 解决偏好强化学习中人类反馈成本高且稀缺的问题，尤其是在专家反馈少或错误代价高的领域。

Method: 扩展Advise算法，支持多训练者、在线估计其可靠性，并引入基于熵的查询选择来优化反馈请求。

Result: 在多个环境中（如Taxi、Pacman、Frozen Lake和血糖控制任务）验证，显示在不确定轨迹上请求反馈能加速学习，并在血糖控制任务中优于基线。

Conclusion: 新框架有效提升了偏好强化学习的效率，尤其在需要稀缺专家反馈的复杂任务中表现优异。

Abstract: Preference-based reinforcement learning has gained prominence as a strategy
for training agents in environments where the reward signal is difficult to
specify or misaligned with human intent. However, its effectiveness is often
limited by the high cost and low availability of reliable human input,
especially in domains where expert feedback is scarce or errors are costly. To
address this, we propose a novel framework that combines two complementary
strategies: probabilistic crowd modelling to handle noisy, multi-annotator
feedback, and active learning to prioritize feedback on the most informative
agent actions. We extend the Advise algorithm to support multiple trainers,
estimate their reliability online, and incorporate entropy-based query
selection to guide feedback requests. We evaluate our approach in a set of
environments that span both synthetic and real-world-inspired settings,
including 2D games (Taxi, Pacman, Frozen Lake) and a blood glucose control task
for Type 1 Diabetes using the clinically approved UVA/Padova simulator. Our
preliminary results demonstrate that agents trained with feedback on uncertain
trajectories exhibit faster learning in most tasks, and we outperform the
baselines for the blood glucose control task.

</details>


### [159] [Saddle Hierarchy in Dense Associative Memory](https://arxiv.org/abs/2508.19151)
*Robin Thériault,Daniele Tantari*

Main category: cs.LG

TL;DR: 研究了基于三层玻尔兹曼机的密集关联记忆（DAM）模型，提出了一种新的正则化方案，显著提高了训练稳定性，并展示了其在监督和无监督分类问题中的可解释性。


<details>
  <summary>Details</summary>
Motivation: 密集关联记忆模型因其对对抗样本的鲁棒性以及与注意力机制和生成扩散模型的紧密联系而受到关注。

Method: 通过统计力学分析，推导了描述DAM训练固定点的鞍点方程，并提出了新的正则化方案。

Result: 实验表明，DAM能够学习到可解释的分类解决方案，并通过网络增长算法显著降低了计算成本。

Conclusion: DAM模型在训练稳定性和计算效率方面取得了显著进展，为未来研究提供了新的方向。

Abstract: Dense associative memory (DAM) models have been attracting renewed attention
since they were shown to be robust to adversarial examples and closely related
to state-of-the-art machine learning paradigms, such as the attention
mechanisms in transformers and generative diffusion models. We study a DAM
built upon a three-layer Boltzmann machine with Potts hidden units, which
represent data clusters and classes. Through a statistical mechanics analysis,
we derive saddle-point equations that characterize both the stationary points
of DAMs trained on real data and the fixed points of DAMs trained on synthetic
data within a teacher-student framework. Based on these results, we propose a
novel regularization scheme that makes training significantly more stable.
Moreover, we show empirically that our DAM learns interpretable solutions to
both supervised and unsupervised classification problems. Pushing our
theoretical analysis further, we find that the weights learned by relatively
small DAMs correspond to unstable saddle points in larger DAMs. We implement a
network-growing algorithm that leverages this saddle-point hierarchy to
drastically reduce the computational cost of training dense associative memory.

</details>


### [160] [Get Global Guarantees: On the Probabilistic Nature of Perturbation Robustness](https://arxiv.org/abs/2508.19183)
*Wenchuan Mu,Kwan Hui Lim*

Main category: cs.LG

TL;DR: 提出了一种基于假设检验的新度量方法——塔鲁棒性（tower robustness），用于更严格高效地评估深度学习模型在安全关键应用中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有鲁棒性评估方法在计算成本和测量精度之间存在显著权衡，限制了其实际应用。

Method: 通过全面比较现有鲁棒性定义和评估方法，提出基于假设检验的概率鲁棒性量化度量。

Result: 实验表明，该方法在评估效率和严谨性上优于现有方法。

Conclusion: 塔鲁棒性推动了安全关键深度学习中模型鲁棒性的系统化理解和提升。

Abstract: In safety-critical deep learning applications, robustness measures the
ability of neural models that handle imperceptible perturbations in input data,
which may lead to potential safety hazards. Existing pre-deployment robustness
assessment methods typically suffer from significant trade-offs between
computational cost and measurement precision, limiting their practical utility.
To address these limitations, this paper conducts a comprehensive comparative
analysis of existing robustness definitions and associated assessment
methodologies. We propose tower robustness to evaluate robustness, which is a
novel, practical metric based on hypothesis testing to quantitatively evaluate
probabilistic robustness, enabling more rigorous and efficient pre-deployment
assessments. Our extensive comparative evaluation illustrates the advantages
and applicability of our proposed approach, thereby advancing the systematic
understanding and enhancement of model robustness in safety-critical deep
learning applications.

</details>


### [161] [Emotions as Ambiguity-aware Ordinal Representations](https://arxiv.org/abs/2508.19193)
*Jingyao Wu,Matthew Barthet,David Melhart,Georgios N. Yannakakis*

Main category: cs.LG

TL;DR: 论文提出了一种新的情感表示框架，通过序数表示捕捉情感标注的模糊性和动态性，并在两种情感数据集上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有连续情感识别方法忽视情感的模糊性或将其视为静态变量，论文旨在填补这一空白。

Method: 提出基于变化率的情感模糊性建模方法，采用序数表示框架。

Result: 序数表示在无界标签上表现最佳，CCC和SDA得分最高；在有界标签上SDA表现优越。

Conclusion: 序数表示能有效捕捉情感标注的动态性和模糊性，尤其在无界标签上表现突出。

Abstract: Emotions are inherently ambiguous and dynamic phenomena, yet existing
continuous emotion recognition approaches either ignore their ambiguity or
treat ambiguity as an independent and static variable over time. Motivated by
this gap in the literature, in this paper we introduce \emph{ambiguity-aware
ordinal} emotion representations, a novel framework that captures both the
ambiguity present in emotion annotation and the inherent temporal dynamics of
emotional traces. Specifically, we propose approaches that model emotion
ambiguity through its rate of change. We evaluate our framework on two
affective corpora -- RECOLA and GameVibe -- testing our proposed approaches on
both bounded (arousal, valence) and unbounded (engagement) continuous traces.
Our results demonstrate that ordinal representations outperform conventional
ambiguity-aware models on unbounded labels, achieving the highest Concordance
Correlation Coefficient (CCC) and Signed Differential Agreement (SDA) scores,
highlighting their effectiveness in modeling the traces' dynamics. For bounded
traces, ordinal representations excel in SDA, revealing their superior ability
to capture relative changes of annotated emotion traces.

</details>


### [162] [Understanding Tool-Integrated Reasoning](https://arxiv.org/abs/2508.19201)
*Heng Lin,Zhongwen Xu*

Main category: cs.LG

TL;DR: 本文首次正式证明了工具集成推理（TIR）如何扩展大语言模型（LLM）的能力，并提出了新的算法ASPO来优化模型行为。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM与工具（如Python解释器）结合显示出巨大潜力，但缺乏解释其有效性的理论。

Method: 通过形式化证明和实验验证TIR的能力扩展，并引入ASPO算法优化模型行为。

Result: TIR模型在数学基准测试中显著优于纯文本模型，且ASPO改善了工具使用行为。

Conclusion: 本文为TIR的成功提供了理论解释，揭示了工具如何增强推理能力。

Abstract: We study why Tool-Integrated Reasoning (TIR) makes Large Language Models
(LLMs) more capable. While LLMs integrated with tools like Python code
interpreters show great promise, a principled theory explaining why this
paradigm is effective has been missing. This work provides the first formal
proof that TIR fundamentally expands an LLM's capabilities. We demonstrate that
tools enable a strict expansion of the model's empirical and feasible support,
breaking the capability ceiling of pure-text models by unlocking
problem-solving strategies that are otherwise impossible or intractably
verbose. To guide model behavior without compromising training stability and
performance, we also introduce Advantage Shaping Policy Optimization (ASPO), a
novel algorithm that directly modifies the advantage function to guide the
policy behavior. We conduct comprehensive experiments on challenging
mathematical benchmarks, leveraging a Python interpreter as the external tool.
Our results show that the TIR model decisively outperforms its pure-text
counterpart on the pass@k metric. Crucially, this advantage is not confined to
computationally-intensive problems but extends to those requiring significant
abstract insight. We further identify the emergent cognitive patterns that
illustrate how models learn to think with tools. Finally, we report improved
tool usage behavior with early code invocation and much more interactive turns
with ASPO. Overall, our work provides the first principled explanation for
TIR's success, shifting the focus from the mere fact that tools work to why and
how they enable more powerful reasoning.

</details>


### [163] [Predicting the Order of Upcoming Tokens Improves Language Modeling](https://arxiv.org/abs/2508.19228)
*Zayd M. K. Zuhri,Erland Hilman Fuadi,Alham Fikri Aji*

Main category: cs.LG

TL;DR: 论文提出Token Order Prediction (TOP)作为辅助目标，优于Multi-Token Prediction (MTP)和Next-Token Prediction (NTP)。


<details>
  <summary>Details</summary>
Motivation: MTP在语言模型训练中表现不一致，其预测未来token的难度过高。

Method: 提出TOP，通过排序损失训练模型对即将到来的token进行排序，仅需一个额外的unembedding层。

Result: 在8个标准NLP基准测试中，TOP整体优于NTP和MTP，且在不同规模模型上表现一致。

Conclusion: TOP是一种更有效的辅助训练目标，适用于大规模语言模型。

Abstract: Multi-Token Prediction (MTP) has been proposed as an auxiliary objective to
improve next-token prediction (NTP) in language model training but shows
inconsistent improvements, underperforming in standard NLP benchmarks. We argue
that MTP's exact future token prediction is too difficult as an auxiliary loss.
Instead, we propose Token Order Prediction (TOP), which trains models to order
upcoming tokens by their proximity using a learning-to-rank loss. TOP requires
only a single additional unembedding layer compared to MTP's multiple
transformer layers. We pretrain models of 340M, 1.8B, and 7B parameters using
NTP, MTP, and TOP objectives. Results on eight standard NLP benchmarks show
that TOP overall outperforms both NTP and MTP even at scale. Our code is
available at https://github.com/zaydzuhri/token-order-prediction

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [164] [Mining the Long Tail: A Comparative Study of Data-Centric Criticality Metrics for Robust Offline Reinforcement Learning in Autonomous Motion Planning](https://arxiv.org/abs/2508.18397)
*Antonio Guillen-Perez*

Main category: cs.RO

TL;DR: 该论文研究了离线强化学习中数据不平衡问题，通过六种数据筛选策略显著提升了自动驾驶规划策略的安全性和性能。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习在自动驾驶规划中面临数据不平衡问题，常规均匀采样导致策略脆弱且不安全。

Method: 研究了六种关键性加权方案，分为启发式、不确定性和行为三类，并在两个时间尺度上评估。

Result: 所有数据筛选方法均显著优于基线，基于模型不确定性的方法将碰撞率从16.0%降至5.5%。

Conclusion: 智能非均匀采样是构建安全可靠自动驾驶代理的关键，不同时间尺度的加权方案各有优势。

Abstract: Offline Reinforcement Learning (RL) presents a promising paradigm for
training autonomous vehicle (AV) planning policies from large-scale, real-world
driving logs. However, the extreme data imbalance in these logs, where mundane
scenarios vastly outnumber rare "long-tail" events, leads to brittle and unsafe
policies when using standard uniform data sampling. In this work, we address
this challenge through a systematic, large-scale comparative study of data
curation strategies designed to focus the learning process on information-rich
samples. We investigate six distinct criticality weighting schemes which are
categorized into three families: heuristic-based, uncertainty-based, and
behavior-based. These are evaluated at two temporal scales, the individual
timestep and the complete scenario. We train seven goal-conditioned
Conservative Q-Learning (CQL) agents with a state-of-the-art, attention-based
architecture and evaluate them in the high-fidelity Waymax simulator. Our
results demonstrate that all data curation methods significantly outperform the
baseline. Notably, data-driven curation using model uncertainty as a signal
achieves the most significant safety improvements, reducing the collision rate
by nearly three-fold (from 16.0% to 5.5%). Furthermore, we identify a clear
trade-off where timestep-level weighting excels at reactive safety while
scenario-level weighting improves long-horizon planning. Our work provides a
comprehensive framework for data curation in Offline RL and underscores that
intelligent, non-uniform sampling is a critical component for building safe and
reliable autonomous agents.

</details>


### [165] [Maintenance automation: methods for robotics manipulation planning and execution](https://arxiv.org/abs/2508.18399)
*Christian Friedrich,Ralf Gulde,Armin Lechler,Alexander Verl*

Main category: cs.RO

TL;DR: 论文提出了一种用于维护自动化的完整机器人系统，能够在环境不确定性下自动化拆卸和组装操作。


<details>
  <summary>Details</summary>
Motivation: 自动化复杂任务需要规划、控制和执行技能，尤其是在环境不确定性（如计划信息偏差）的情况下。

Method: 基于CAD和RGBD数据的规划方法，将符号计划转化为可执行的机器人指令。

Result: 通过实际应用实验评估了系统的有效性。

Conclusion: 该研究是将理论成果转化为实际机器人解决方案的第一步。

Abstract: Automating complex tasks using robotic systems requires skills for planning,
control and execution. This paper proposes a complete robotic system for
maintenance automation, which can automate disassembly and assembly operations
under environmental uncertainties (e.g. deviations between prior plan
information). The cognition of the robotic system is based on a planning
approach (using CAD and RGBD data) and includes a method to interpret a
symbolic plan and transform it to a set of executable robot instructions. The
complete system is experimentally evaluated using real-world applications. This
work shows the first step to transfer these theoretical results into a
practical robotic solution.

</details>


### [166] [Efficient task and path planning for maintenance automation using a robot system](https://arxiv.org/abs/2508.18400)
*Christian Friedrich,Akos Csiszar,Armin Lechler,Alexander Verl*

Main category: cs.RO

TL;DR: 论文提出了一种结合离线CAD数据和在线RGBD视觉系统的智能自动化方法，用于维护任务的自主规划和路径规划。


<details>
  <summary>Details</summary>
Motivation: 工厂未来的智能化自动化需要自主机器人系统完成维护任务，但需解决低计算复杂度和环境不确定性问题。

Method: 结合离线CAD数据和在线RGBD视觉系统，通过概率滤波补偿不确定性；使用基于采样的符号描述方法规划任务，并采用全局路径规划算法。

Result: 实验验证了方法的有效性，能够减少规划时间并处理环境不确定性。

Conclusion: 该方法为维护自动化提供了一种高效且适应性强的解决方案。

Abstract: The research and development of intelligent automation solutions is a
ground-breaking point for the factory of the future. A promising and
challenging mission is the use of autonomous robot systems to automate tasks in
the field of maintenance. For this purpose, the robot system must be able to
plan autonomously the different manipulation tasks and the corresponding paths.
Basic requirements are the development of algorithms with a low computational
complexity and the possibility to deal with environmental uncertainties. In
this work, an approach is presented, which is especially suited to solve the
problem of maintenance automation. For this purpose, offline data from CAD is
combined with online data from an RGBD vision system via a probabilistic
filter, to compensate uncertainties from offline data. For planning the
different tasks, a method is explained, which use a symbolic description,
founded on a novel sampling-based method to compute the disassembly space. For
path planning we use global state-of-the art algorithms with a method that
allows the adaption of the exploration stepsize in order to reduce the planning
time. Every method is experimentally validated and discussed.

</details>


### [167] [PneuGelSight: Soft Robotic Vision-Based Proprioception and Tactile Sensing](https://arxiv.org/abs/2508.18443)
*Ruohan Zhang,Uksang Yoo,Yichen Li,Arpit Argawal,Wenzhen Yuan*

Main category: cs.RO

TL;DR: 提出了一种基于视觉的软体机器人传感方法，通过嵌入式摄像头实现高分辨率本体感知和触觉反馈，并通过仿真优化性能。


<details>
  <summary>Details</summary>
Motivation: 软体气动机器人在工业和人际交互中应用广泛，但需要先进的传感技术以实现触觉反馈和本体感知。

Method: 开发了PneuGelSight气动机械手，结合嵌入式摄像头和仿真管道，实现从仿真到现实的零样本知识迁移。

Result: PneuGelSight和仿真管道提供了一种新颖、易实现且鲁棒的传感方法。

Conclusion: 该方法为开发具有增强感知能力的先进软体机器人铺平了道路。

Abstract: Soft pneumatic robot manipulators are popular in industrial and
human-interactive applications due to their compliance and flexibility.
However, deploying them in real-world scenarios requires advanced sensing for
tactile feedback and proprioception. Our work presents a novel vision-based
approach for sensorizing soft robots. We demonstrate our approach on
PneuGelSight, a pioneering pneumatic manipulator featuring high-resolution
proprioception and tactile sensing via an embedded camera. To optimize the
sensor's performance, we introduce a comprehensive pipeline that accurately
simulates its optical and dynamic properties, facilitating a zero-shot
knowledge transition from simulation to real-world applications. PneuGelSight
and our sim-to-real pipeline provide a novel, easily implementable, and robust
sensing methodology for soft robots, paving the way for the development of more
advanced soft robots with enhanced sensory capabilities.

</details>


### [168] [Mimicking associative learning of rats via a neuromorphic robot in open field maze using spatial cell models](https://arxiv.org/abs/2508.18460)
*Tianze Liu,Md Abu Bakr Siddique,Hongyu An*

Main category: cs.RO

TL;DR: 论文提出了一种通过模拟动物联想学习机制来增强智能机器人自主能力的方法，以解决传统AI依赖大数据和高能耗的问题。


<details>
  <summary>Details</summary>
Motivation: 传统AI方法依赖大数据和高能耗，限制了在资源受限环境（如行星探索）中的应用。模拟动物的联想学习机制可以提高机器人的适应性和自主性。

Method: 通过神经形态机器人模拟啮齿类动物在开放迷宫环境中的联想学习，利用空间细胞（如位置细胞和网格细胞）的模型。

Result: 该方法旨在实现实时场景中的在线联想学习，优化机器人在动态环境中的自主导航能力。

Conclusion: 通过结合生物空间认知与机器人技术，该方法为自主系统的进步提供了新思路。

Abstract: Data-driven Artificial Intelligence (AI) approaches have exhibited remarkable
prowess across various cognitive tasks using extensive training data. However,
the reliance on large datasets and neural networks presents challenges such as
highpower consumption and limited adaptability, particularly in
SWaP-constrained applications like planetary exploration. To address these
issues, we propose enhancing the autonomous capabilities of intelligent robots
by emulating the associative learning observed in animals. Associative learning
enables animals to adapt to their environment by memorizing concurrent events.
By replicating this mechanism, neuromorphic robots can navigate dynamic
environments autonomously, learning from interactions to optimize performance.
This paper explores the emulation of associative learning in rodents using
neuromorphic robots within open-field maze environments, leveraging insights
from spatial cells such as place and grid cells. By integrating these models,
we aim to enable online associative learning for spatial tasks in real-time
scenarios, bridging the gap between biological spatial cognition and robotics
for advancements in autonomous systems.

</details>


### [169] [SignLoc: Robust Localization using Navigation Signs and Public Maps](https://arxiv.org/abs/2508.18606)
*Nicky Zimmerman,Joel Loo,Ayush Agrawal,David Hsu*

Main category: cs.RO

TL;DR: SignLoc是一种利用导航标志进行机器人全局定位的方法，无需先前的传感器建图，适用于公开地图如楼层平面图和OpenStreetMap。


<details>
  <summary>Details</summary>
Motivation: 导航标志和地图在人类环境中广泛用于寻路，但机器人系统很少使用。SignLoc旨在填补这一空白。

Method: 从输入地图提取导航图，使用概率观测模型匹配标志的方向和位置线索，结合蒙特卡洛框架实现鲁棒的拓扑语义定位。

Result: 在校园、购物中心和医院等大规模环境中测试，SignLoc仅需观察1-2个标志即可可靠定位机器人。

Conclusion: SignLoc展示了利用现有导航标志进行机器人定位的潜力，无需额外建图。

Abstract: Navigation signs and maps, such as floor plans and street maps, are widely
available and serve as ubiquitous aids for way-finding in human environments.
Yet, they are rarely used by robot systems. This paper presents SignLoc, a
global localization method that leverages navigation signs to localize the
robot on publicly available maps -- specifically floor plans and OpenStreetMap
(OSM) graphs--without prior sensor-based mapping. SignLoc first extracts a
navigation graph from the input map. It then employs a probabilistic
observation model to match directional and locational cues from the detected
signs to the graph, enabling robust topo-semantic localization within a Monte
Carlo framework. We evaluated SignLoc in diverse large-scale environments: part
of a university campus, a shopping mall, and a hospital complex. Experimental
results show that SignLoc reliably localizes the robot after observing only one
to two signs.

</details>


### [170] [Integration of Robot and Scene Kinematics for Sequential Mobile Manipulation Planning](https://arxiv.org/abs/2508.18627)
*Ziyuan Jiao,Yida Niu,Zeyu Zhang,Yangyang Wu,Yao Su,Yixin Zhu,Hangxin Liu,Song-Chun Zhu*

Main category: cs.RO

TL;DR: 提出了一种Sequential Mobile Manipulation Planning (SMMP)框架，用于解决长时域多步移动操作任务，并整合了机器人运动与场景运动学模型。


<details>
  <summary>Details</summary>
Motivation: 传统方法中导航和操作的任务约束是分离的，且未充分考虑机器人基座、手臂和被操作物体的联合可达性。

Method: 通过构建Augmented Configuration Space (A-Space)，将环境结构抽象为运动学模型，并采用三层次规划框架（任务规划、运动规划、计划细化）实现高效规划。

Result: 仿真实验显示任务成功率提高84.6%，真实机器人实验中成功完成17种不同场景下的长时域任务（最多14步）。

Conclusion: 将场景运动学模型整合到规划实体中，提供了一种可扩展且通用的复杂机器人操作方法。

Abstract: We present a Sequential Mobile Manipulation Planning (SMMP) framework that
can solve long-horizon multi-step mobile manipulation tasks with coordinated
whole-body motion, even when interacting with articulated objects. By
abstracting environmental structures as kinematic models and integrating them
with the robot's kinematics, we construct an Augmented Configuration Apace
(A-Space) that unifies the previously separate task constraints for navigation
and manipulation, while accounting for the joint reachability of the robot
base, arm, and manipulated objects. This integration facilitates efficient
planning within a tri-level framework: a task planner generates symbolic action
sequences to model the evolution of A-Space, an optimization-based motion
planner computes continuous trajectories within A-Space to achieve desired
configurations for both the robot and scene elements, and an intermediate plan
refinement stage selects action goals that ensure long-horizon feasibility. Our
simulation studies first confirm that planning in A-Space achieves an 84.6\%
higher task success rate compared to baseline methods. Validation on real
robotic systems demonstrates fluid mobile manipulation involving (i) seven
types of rigid and articulated objects across 17 distinct contexts, and (ii)
long-horizon tasks of up to 14 sequential steps. Our results highlight the
significance of modeling scene kinematics into planning entities, rather than
encoding task-specific constraints, offering a scalable and generalizable
approach to complex robotic manipulation.

</details>


### [171] [Engineering Automotive Digital Twins on Standardized Architectures: A Case Study](https://arxiv.org/abs/2508.18662)
*Stefan Ramdhan,Winnie Trandinh,Istvan David,Vera Pantelic,Mark Lawford*

Main category: cs.RO

TL;DR: 该论文探讨了ISO 23247参考架构在汽车数字孪生（DT）开发中的适用性，并通过自适应巡航控制DT的案例研究，总结了其优缺点及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 汽车行业对数字孪生技术的需求增长，但缺乏针对性的架构指南，ISO 23247是目前可行的起点。

Method: 通过开发1/10比例自动驾驶车辆的自适应巡航控制DT，评估ISO 23247参考架构的适用性。

Result: 识别了ISO 23247架构的优势和局限性，并提出了未来研究方向。

Conclusion: ISO 23247架构在汽车DT开发中具有一定适用性，但需进一步优化和扩展。

Abstract: Digital twin (DT) technology has become of interest in the automotive
industry. There is a growing need for smarter services that utilize the unique
capabilities of DTs, ranging from computer-aided remote control to cloud-based
fleet coordination. Developing such services starts with the software
architecture. However, the scarcity of DT architectural guidelines poses a
challenge for engineering automotive DTs. Currently, the only DT architectural
standard is the one defined in ISO 23247. Though not developed for automotive
systems, it is one of the few feasible starting points for automotive DTs. In
this work, we investigate the suitability of the ISO 23247 reference
architecture for developing automotive DTs. Through the case study of
developing an Adaptive Cruise Control DT for a 1/10\textsuperscript{th}-scale
autonomous vehicle, we identify some strengths and limitations of the reference
architecture and begin distilling future directions for researchers,
practitioners, and standard developers.

</details>


### [172] [Deep Sensorimotor Control by Imitating Predictive Models of Human Motion](https://arxiv.org/abs/2508.18691)
*Himanshu Gaurav Singh,Pieter Abbeel,Jitendra Malik,Antonio Loquercio*

Main category: cs.RO

TL;DR: 提出一种通过模仿人类运动预测模型训练机器人传感器运动策略的新方法，无需梯度运动重定向或对抗损失。


<details>
  <summary>Details</summary>
Motivation: 利用人类与环境的交互数据集，缩小机器人与人类之间的体现差距，提升机器人学习效果。

Method: 通过模仿人类运动预测模型，训练传感器运动策略，优化稀疏任务奖励。

Result: 在多种机器人和任务中表现优异，显著超越现有基线方法。

Conclusion: 该方法能有效替代密集奖励和课程设计，适用于多种机器人任务。

Abstract: As the embodiment gap between a robot and a human narrows, new opportunities
arise to leverage datasets of humans interacting with their surroundings for
robot learning. We propose a novel technique for training sensorimotor policies
with reinforcement learning by imitating predictive models of human motions.
Our key insight is that the motion of keypoints on human-inspired robot
end-effectors closely mirrors the motion of corresponding human body keypoints.
This enables us to use a model trained to predict future motion on human data
\emph{zero-shot} on robot data. We train sensorimotor policies to track the
predictions of such a model, conditioned on a history of past robot states,
while optimizing a relatively sparse task reward. This approach entirely
bypasses gradient-based kinematic retargeting and adversarial losses, which
limit existing methods from fully leveraging the scale and diversity of modern
human-scene interaction datasets. Empirically, we find that our approach can
work across robots and tasks, outperforming existing baselines by a large
margin. In addition, we find that tracking a human motion model can substitute
for carefully designed dense rewards and curricula in manipulation tasks. Code,
data and qualitative results available at
https://jirl-upenn.github.io/track_reward/.

</details>


### [173] [AgriChrono: A Multi-modal Dataset Capturing Crop Growth and Lighting Variability with a Field Robot](https://arxiv.org/abs/2508.18694)
*Jaehwan Jeong,Tuan-Anh Vu,Mohammad Jony,Shahab Ahmad,Md. Mukhlesur Rahman,Sangpil Kim,M. Khalid Jawed*

Main category: cs.RO

TL;DR: AgriChrono是一个新型机器人数据收集平台和多模态数据集，旨在捕捉真实农业环境的动态条件，填补现有静态数据集在鲁棒性和泛化性上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有农业数据集多在静态或受控环境中收集，缺乏真实农田的动态变化（如光照、作物生长），导致模型在真实场景中表现不佳。

Method: 开发了AgriChrono平台，集成多种传感器（RGB、深度、LiDAR、IMU），支持远程、时间同步的长期数据收集。

Result: 在AgriChrono数据集上测试了多种3D重建模型，验证了其在动态环境中的挑战性，并展示了其对模型泛化研究的价值。

Conclusion: AgriChrono为动态农业环境研究提供了宝贵资源，代码和数据集已开源。

Abstract: Existing datasets for precision agriculture have primarily been collected in
static or controlled environments such as indoor labs or greenhouses, often
with limited sensor diversity and restricted temporal span. These conditions
fail to reflect the dynamic nature of real farmland, including illumination
changes, crop growth variation, and natural disturbances. As a result, models
trained on such data often lack robustness and generalization when applied to
real-world field scenarios. In this paper, we present AgriChrono, a novel
robotic data collection platform and multi-modal dataset designed to capture
the dynamic conditions of real-world agricultural environments. Our platform
integrates multiple sensors and enables remote, time-synchronized acquisition
of RGB, Depth, LiDAR, and IMU data, supporting efficient and repeatable
long-term data collection across varying illumination and crop growth stages.
We benchmark a range of state-of-the-art 3D reconstruction models on the
AgriChrono dataset, highlighting the difficulty of reconstruction in real-world
field environments and demonstrating its value as a research asset for
advancing model generalization under dynamic conditions. The code and dataset
are publicly available at: https://github.com/StructuresComp/agri-chrono

</details>


### [174] [Enhancing Video-Based Robot Failure Detection Using Task Knowledge](https://arxiv.org/abs/2508.18705)
*Santosh Thoduka,Sebastian Houben,Juergen Gall,Paul G. Plöger*

Main category: cs.RO

TL;DR: 提出了一种基于视频的机器人任务失败检测方法，利用时空知识和任务相关对象信息，通过数据增强提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有失败检测方法在多样化的现实场景中表现不佳，需要更可靠的方法来触发安全操作或任务重规划。

Method: 利用机器人执行的动作和任务相关对象的时空信息，结合可变帧率的数据增强技术。

Result: 在ARMBench数据集上F1分数从77.9提升到80.0，测试时增强后达到81.4。

Conclusion: 时空信息对失败检测至关重要，未来可进一步探索合适的启发式方法。

Abstract: Robust robotic task execution hinges on the reliable detection of execution
failures in order to trigger safe operation modes, recovery strategies, or task
replanning. However, many failure detection methods struggle to provide
meaningful performance when applied to a variety of real-world scenarios. In
this paper, we propose a video-based failure detection approach that uses
spatio-temporal knowledge in the form of the actions the robot performs and
task-relevant objects within the field of view. Both pieces of information are
available in most robotic scenarios and can thus be readily obtained. We
demonstrate the effectiveness of our approach on three datasets that we amend,
in part, with additional annotations of the aforementioned task-relevant
knowledge. In light of the results, we also propose a data augmentation method
that improves performance by applying variable frame rates to different parts
of the video. We observe an improvement from 77.9 to 80.0 in F1 score on the
ARMBench dataset without additional computational expense and an additional
increase to 81.4 with test-time augmentation. The results emphasize the
importance of spatio-temporal information during failure detection and suggest
further investigation of suitable heuristics in future implementations. Code
and annotations are available.

</details>


### [175] [HyperTASR: Hypernetwork-Driven Task-Aware Scene Representations for Robust Manipulation](https://arxiv.org/abs/2508.18802)
*Li Sun,Jiefeng Wu,Feng Chen,Ruizhe Liu,Yanchao Yang*

Main category: cs.RO

TL;DR: HyperTASR是一个基于超网络的框架，动态调整场景表示以适应任务目标和执行阶段，显著提升了机器人操作任务的性能。


<details>
  <summary>Details</summary>
Motivation: 当前的任务无关表示提取方法无法模拟人类认知中的动态感知适应，限制了策略学习的效果。

Method: 通过超网络动态生成表示转换参数，结合任务目标和执行状态，实现场景表示的上下文演化。

Result: 在仿真和真实环境中均表现出显著的性能提升，能够选择性关注任务相关信息。

Conclusion: HyperTASR通过任务和状态依赖的表示处理路径，高效提升了机器人操作的策略学习质量。

Abstract: Effective policy learning for robotic manipulation requires scene
representations that selectively capture task-relevant environmental features.
Current approaches typically employ task-agnostic representation extraction,
failing to emulate the dynamic perceptual adaptation observed in human
cognition. We present HyperTASR, a hypernetwork-driven framework that modulates
scene representations based on both task objectives and the execution phase.
Our architecture dynamically generates representation transformation parameters
conditioned on task specifications and progression state, enabling
representations to evolve contextually throughout task execution. This approach
maintains architectural compatibility with existing policy learning frameworks
while fundamentally reconfiguring how visual features are processed. Unlike
methods that simply concatenate or fuse task embeddings with task-agnostic
representations, HyperTASR establishes computational separation between
task-contextual and state-dependent processing paths, enhancing learning
efficiency and representational quality. Comprehensive evaluations in both
simulation and real-world environments demonstrate substantial performance
improvements across different representation paradigms. Through ablation
studies and attention visualization, we confirm that our approach selectively
prioritizes task-relevant scene information, closely mirroring human adaptive
perception during manipulation tasks. The project website is at
\href{https://lisunphil.github.io/HyperTASR_projectpage/}{lisunphil.github.io/HyperTASR\_projectpage}.

</details>


### [176] [Learning Real-World Acrobatic Flight from Human Preferences](https://arxiv.org/abs/2508.18817)
*Colin Merk,Ismail Geles,Jiaxu Xing,Angel Romero,Giorgia Ramponi,Davide Scaramuzza*

Main category: cs.RO

TL;DR: PbRL用于敏捷无人机控制，提出Reward Ensemble under Confidence (REC)改进偏好建模和学习稳定性，性能达88.4%，优于标准Preference PPO的55.2%。


<details>
  <summary>Details</summary>
Motivation: 解决复杂动态任务（如特技飞行）中难以形式化或主观性强的目标问题。

Method: 基于Preference PPO提出REC，改进奖励学习目标，并在仿真和真实无人机中验证。

Result: REC性能达88.4%，成功迁移到真实无人机，展示多种特技动作。

Conclusion: PbRL能有效捕捉复杂、以人为中心的目标，优于手动设计奖励。

Abstract: Preference-based reinforcement learning (PbRL) enables agents to learn
control policies without requiring manually designed reward functions, making
it well-suited for tasks where objectives are difficult to formalize or
inherently subjective. Acrobatic flight poses a particularly challenging
problem due to its complex dynamics, rapid movements, and the importance of
precise execution. In this work, we explore the use of PbRL for agile drone
control, focusing on the execution of dynamic maneuvers such as powerloops.
Building on Preference-based Proximal Policy Optimization (Preference PPO), we
propose Reward Ensemble under Confidence (REC), an extension to the reward
learning objective that improves preference modeling and learning stability.
Our method achieves 88.4% of the shaped reward performance, compared to 55.2%
with standard Preference PPO. We train policies in simulation and successfully
transfer them to real-world drones, demonstrating multiple acrobatic maneuvers
where human preferences emphasize stylistic qualities of motion. Furthermore,
we demonstrate the applicability of our probabilistic reward model in a
representative MuJoCo environment for continuous control. Finally, we highlight
the limitations of manually designed rewards, observing only 60.7% agreement
with human preferences. These results underscore the effectiveness of PbRL in
capturing complex, human-centered objectives across both physical and simulated
domains.

</details>


### [177] [AS2FM: Enabling Statistical Model Checking of ROS 2 Systems for Robust Autonomy](https://arxiv.org/abs/2508.18820)
*Christian Henkel,Marco Lampacrescia,Michaela Klauck,Matteo Morelli*

Main category: cs.RO

TL;DR: 提出了一种使用统计模型检查（SMC）验证自主机器人系统属性的新方法，并开发了AS2FM工具，验证速度快且可扩展。


<details>
  <summary>Details</summary>
Motivation: 自主机器人在未知环境中运行时，系统属性的验证是一个挑战。

Method: 扩展SCXML格式以建模系统组件，开发AS2FM工具将模型转换为JANI格式，利用SMC工具验证。

Result: 在ROS 2机器人用例中成功识别问题，验证时间短且线性扩展。

Conclusion: 该方法在系统功能支持和验证效率上优于现有技术。

Abstract: Designing robotic systems to act autonomously in unforeseen environments is a
challenging task. This work presents a novel approach to use formal
verification, specifically Statistical Model Checking (SMC), to verify system
properties of autonomous robots at design-time. We introduce an extension of
the SCXML format, designed to model system components including both Robot
Operating System 2 (ROS 2) and Behavior Tree (BT) features. Further, we
contribute Autonomous Systems to Formal Models (AS2FM), a tool to translate the
full system model into JANI. The use of JANI, a standard format for
quantitative model checking, enables verification of system properties with
off-the-shelf SMC tools. We demonstrate the practical usability of AS2FM both
in terms of applicability to real-world autonomous robotic control systems, and
in terms of verification runtime scaling. We provide a case study, where we
successfully identify problems in a ROS 2-based robotic manipulation use case
that is verifiable in less than one second using consumer hardware.
Additionally, we compare to the state of the art and demonstrate that our
method is more comprehensive in system feature support, and that the
verification runtime scales linearly with the size of the model, instead of
exponentially.

</details>


### [178] [VisionSafeEnhanced VPC: Cautious Predictive Control with Visibility Constraints under Uncertainty for Autonomous Robotic Surgery](https://arxiv.org/abs/2508.18937)
*Wang Jiayin,Wei Yanran,Jiang Lei,Guo Xiaoyu,Zheng Ayong,Zhao Weidong,Li Zhongkui*

Main category: cs.RO

TL;DR: 提出了一种名为VisionSafeEnhanced VPC的鲁棒且不确定性自适应框架，用于自主腹腔镜控制，确保在不确定性下的视野安全。


<details>
  <summary>Details</summary>
Motivation: 解决像素级IBVS控制中连续可见性要求和复杂干扰（如参数化误差、测量噪声和负载不确定性）对手术安全的影响。

Method: 利用高斯过程回归（GPR）进行混合不确定性量化，提出基于概率保证的安全感知轨迹优化框架，结合不确定性自适应CBF条件和机会约束。

Result: 在商业手术机器人平台上验证，保持目标可见性>99.9%，减少跟踪误差。

Conclusion: VisionSafeEnhanced VPC框架在复杂干扰下显著提升了手术安全性和视觉体验。

Abstract: Autonomous control of the laparoscope in robot-assisted Minimally Invasive
Surgery (MIS) has received considerable research interest due to its potential
to improve surgical safety. Despite progress in pixel-level Image-Based Visual
Servoing (IBVS) control, the requirement of continuous visibility and the
existence of complex disturbances, such as parameterization error, measurement
noise, and uncertainties of payloads, could degrade the surgeon's visual
experience and compromise procedural safety. To address these limitations, this
paper proposes VisionSafeEnhanced Visual Predictive Control (VPC), a robust and
uncertainty-adaptive framework for autonomous laparoscope control that
guarantees Field of View (FoV) safety under uncertainty. Firstly, Gaussian
Process Regression (GPR) is utilized to perform hybrid (deterministic +
stochastic) quantification of operational uncertainties including residual
model uncertainties, stochastic uncertainties, and external disturbances. Based
on uncertainty quantification, a novel safety aware trajectory optimization
framework with probabilistic guarantees is proposed, where a
uncertainty-adaptive safety Control Barrier Function (CBF) condition is given
based on uncertainty propagation, and chance constraints are simultaneously
formulated based on probabilistic approximation. This uncertainty aware
formulation enables adaptive control effort allocation, minimizing unnecessary
camera motion while maintaining robustness. The proposed method is validated
through comparative simulations and experiments on a commercial surgical robot
platform (MicroPort MedBot Toumai) performing a sequential multi-target lymph
node dissection. Compared with baseline methods, the framework maintains
near-perfect target visibility (>99.9%), reduces tracking e

</details>


### [179] [Enhanced UAV Path Planning Using the Tangent Intersection Guidance (TIG) Algorithm](https://arxiv.org/abs/2508.18967)
*Hichem Cheriet,Khellat Kihel Badra,Chouraqui Samira*

Main category: cs.RO

TL;DR: TIG算法是一种高效的无人机路径规划方法，适用于静态和动态环境，通过椭圆切线交点生成最优路径。


<details>
  <summary>Details</summary>
Motivation: 无人机的高效安全导航在多种应用中至关重要，如战斗支持、包裹递送和搜救行动。

Method: 使用椭圆切线交点法生成可行路径，通过启发式规则选择最优子路径，并采用二次Bézier曲线平滑技术。

Result: TIG算法在静态环境中生成最短路径（耗时0.01秒起），在未知环境中实时避障性能优于其他算法。

Conclusion: TIG算法在路径规划中表现出高效性和实时性，优于现有方法。

Abstract: Efficient and safe navigation of Unmanned Aerial Vehicles (UAVs) is critical
for various applications, including combat support, package delivery and Search
and Rescue Operations. This paper introduces the Tangent Intersection Guidance
(TIG) algorithm, an advanced approach for UAV path planning in both static and
dynamic environments. The algorithm uses the elliptic tangent intersection
method to generate feasible paths. It generates two sub-paths for each threat,
selects the optimal route based on a heuristic rule, and iteratively refines
the path until the target is reached. Considering the UAV kinematic and dynamic
constraints, a modified smoothing technique based on quadratic B\'ezier curves
is adopted to generate a smooth and efficient route. Experimental results show
that the TIG algorithm can generate the shortest path in less time, starting
from 0.01 seconds, with fewer turning angles compared to A*, PRM, RRT*, Tangent
Graph, and Static APPATT algorithms in static environments. Furthermore, in
completely unknown and partially known environments, TIG demonstrates efficient
real-time path planning capabilities for collision avoidance, outperforming APF
and Dynamic APPATT algorithms.

</details>


### [180] [HuBE: Cross-Embodiment Human-like Behavior Execution for Humanoid Robots](https://arxiv.org/abs/2508.19002)
*Shipeng Lyu,Fangyuan Wang,Weiwei Lin,Luhao Zhu,David Navarro-Alarcon,Guodong Guo*

Main category: cs.RO

TL;DR: HuBE框架通过双层闭环设计解决人形机器人运动生成中的行为相似性和适当性问题，支持跨平台适配。


<details>
  <summary>Details</summary>
Motivation: 人形机器人运动生成中行为相似性和适当性难以兼顾，且缺乏跨平台适配能力。

Method: 提出HuBE框架，整合机器人状态、目标姿态和上下文情境，构建HPose数据集，并采用骨骼缩放数据增强策略。

Result: 在多平台上验证显示，HuBE显著提升运动相似性、行为适当性和计算效率。

Conclusion: HuBE为跨平台人形机器人行为执行提供了可迁移且类人的解决方案。

Abstract: Achieving both behavioral similarity and appropriateness in human-like motion
generation for humanoid robot remains an open challenge, further compounded by
the lack of cross-embodiment adaptability. To address this problem, we propose
HuBE, a bi-level closed-loop framework that integrates robot state, goal poses,
and contextual situations to generate human-like behaviors, ensuring both
behavioral similarity and appropriateness, and eliminating structural
mismatches between motion generation and execution. To support this framework,
we construct HPose, a context-enriched dataset featuring fine-grained
situational annotations. Furthermore, we introduce a bone scaling-based data
augmentation strategy that ensures millimeter-level compatibility across
heterogeneous humanoid robots. Comprehensive evaluations on multiple commercial
platforms demonstrate that HuBE significantly improves motion similarity,
behavioral appropriateness, and computational efficiency over state-of-the-art
baselines, establishing a solid foundation for transferable and human-like
behavior execution across diverse humanoid robots.

</details>


### [181] [An LLM-powered Natural-to-Robotic Language Translation Framework with Correctness Guarantees](https://arxiv.org/abs/2508.19074)
*ZhenDong Chen,ZhanShang Nie,ShiXing Wan,JunYi Li,YongTian Cheng,Shuai Zhao*

Main category: cs.RO

TL;DR: 提出了一种自然语言与机器人语言翻译框架（NRTrans），通过验证和反馈机制提升LLM生成机器人控制程序的正确性和性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法直接利用LLM从自然语言生成可执行程序，但由于LLM的不一致性和任务复杂性，常导致大量编程错误，尤其对轻量级LLM影响显著。

Method: 引入Robot Skill Language（RSL）抽象控制程序细节，构建RSL编译器和调试器验证程序并提供错误反馈，通过反馈微调LLM输出。

Result: 实验表明NRTrans在多种LLM和任务中优于现有方法，显著提升轻量级LLM的成功率。

Conclusion: NRTrans框架通过验证和反馈机制，显著提升了LLM生成机器人控制程序的正确性和实用性。

Abstract: The Large Language Models (LLM) are increasingly being deployed in robotics
to generate robot control programs for specific user tasks, enabling embodied
intelligence. Existing methods primarily focus on LLM training and prompt
design that utilize LLMs to generate executable programs directly from user
tasks in natural language. However, due to the inconsistency of the LLMs and
the high complexity of the tasks, such best-effort approaches often lead to
tremendous programming errors in the generated code, which significantly
undermines the effectiveness especially when the light-weight LLMs are applied.
This paper introduces a natural-robotic language translation framework that (i)
provides correctness verification for generated control programs and (ii)
enhances the performance of LLMs in program generation via feedback-based
fine-tuning for the programs. To achieve this, a Robot Skill Language (RSL) is
proposed to abstract away from the intricate details of the control programs,
bridging the natural language tasks with the underlying robot skills. Then, the
RSL compiler and debugger are constructed to verify RSL programs generated by
the LLM and provide error feedback to the LLM for refining the outputs until
being verified by the compiler. This provides correctness guarantees for the
LLM-generated programs before being offloaded to the robots for execution,
significantly enhancing the effectiveness of LLM-powered robotic applications.
Experiments demonstrate NRTrans outperforms the existing method under a range
of LLMs and tasks, and achieves a high success rate for light-weight LLMs.

</details>


### [182] [DELIVER: A System for LLM-Guided Coordinated Multi-Robot Pickup and Delivery using Voronoi-Based Relay Planning](https://arxiv.org/abs/2508.19114)
*Alkesh K. Srivastava,Jared Michael Levin,Alexander Derrico,Philip Dames*

Main category: cs.RO

TL;DR: DELIVER是一个基于自然语言指令的多机器人协作拾取与交付框架，结合语言理解、空间分解、中继规划和运动执行，实现高效、无碰撞的协调。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人在自然语言指令下的协作问题，提升系统的可扩展性和效率。

Method: 使用LLaMA3解析指令，Voronoi空间分解定义区域，计算最优中继点，有限状态机控制行为。

Result: 在仿真和实际硬件中验证，团队规模变化时任务成本稳定，单机工作量减少55%，中继代理数量低。

Conclusion: DELIVER展示了语言引导多机器人协调的模块化和可扩展架构，推动了物理系统集成的前沿。

Abstract: We present DELIVER (Directed Execution of Language-instructed Item Via
Engineered Relay), a fully integrated framework for cooperative multi-robot
pickup and delivery driven by natural language commands. DELIVER unifies
natural language understanding, spatial decomposition, relay planning, and
motion execution to enable scalable, collision-free coordination in real-world
settings. Given a spoken or written instruction, a lightweight instance of
LLaMA3 interprets the command to extract pickup and delivery locations. The
environment is partitioned using a Voronoi tessellation to define
robot-specific operating regions. Robots then compute optimal relay points
along shared boundaries and coordinate handoffs. A finite-state machine governs
each robot's behavior, enabling robust execution. We implement DELIVER on the
MultiTRAIL simulation platform and validate it in both ROS2-based Gazebo
simulations and real-world hardware using TurtleBot3 robots. Empirical results
show that DELIVER maintains consistent mission cost across varying team sizes
while reducing per-agent workload by up to 55% compared to a single-agent
system. Moreover, the number of active relay agents remains low even as team
size increases, demonstrating the system's scalability and efficient agent
utilization. These findings underscore DELIVER's modular and extensible
architecture for language-guided multi-robot coordination, advancing the
frontiers of cyber-physical system integration.

</details>


### [183] [ZeST: an LLM-based Zero-Shot Traversability Navigation for Unknown Environments](https://arxiv.org/abs/2508.19131)
*Shreya Gummadi,Mateus V. Gasparino,Gianluca Capezzuto,Marcelo Becker,Girish Chowdhary*

Main category: cs.RO

TL;DR: ZeST利用大型语言模型的视觉推理能力实时生成地形可通行性地图，避免机器人暴露于危险环境，提供零样本可通行性预测，并加速导航系统开发。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要机器人进入危险环境收集数据，存在设备与安全风险。ZeST旨在解决这一问题。

Method: 利用大型语言模型（LLMs）的视觉推理能力，实时生成地形可通行性地图。

Result: 在室内和室外环境中，ZeST比其他先进方法更安全且能持续到达目标。

Conclusion: ZeST提供了一种安全、高效且可扩展的解决方案，推动了机器人导航系统的发展。

Abstract: The advancement of robotics and autonomous navigation systems hinges on the
ability to accurately predict terrain traversability. Traditional methods for
generating datasets to train these prediction models often involve putting
robots into potentially hazardous environments, posing risks to equipment and
safety. To solve this problem, we present ZeST, a novel approach leveraging
visual reasoning capabilities of Large Language Models (LLMs) to create a
traversability map in real-time without exposing robots to danger. Our approach
not only performs zero-shot traversability and mitigates the risks associated
with real-world data collection but also accelerates the development of
advanced navigation systems, offering a cost-effective and scalable solution.
To support our findings, we present navigation results, in both controlled
indoor and unstructured outdoor environments. As shown in the experiments, our
method provides safer navigation when compared to other state-of-the-art
methods, constantly reaching the final goal.

</details>


### [184] [Uncertainty-Resilient Active Intention Recognition for Robotic Assistants](https://arxiv.org/abs/2508.19150)
*Juan Carlos Saborío,Marc Vinci,Oscar Lima,Sebastian Stock,Lennart Niecksch,Martin Günther,Alexander Sung,Joachim Hertzberg,Martin Atzmüller*

Main category: cs.RO

TL;DR: 论文提出了一种基于POMDP的框架，用于在不确定性和传感器噪声下进行人类意图识别和协作规划。


<details>
  <summary>Details</summary>
Motivation: 当前机器人助手的行为通常依赖于显式提示识别或简化假设，缺乏对不确定性和感知错误的处理能力。

Method: 提出了一种结合实时传感器数据和规划器的框架，核心是意图识别的POMDP模型。

Result: 框架在物理机器人上成功测试，表现出色。

Conclusion: 该框架有效解决了不确定性下的协作规划和行为问题。

Abstract: Purposeful behavior in robotic assistants requires the integration of
multiple components and technological advances. Often, the problem is reduced
to recognizing explicit prompts, which limits autonomy, or is oversimplified
through assumptions such as near-perfect information. We argue that a critical
gap remains unaddressed -- specifically, the challenge of reasoning about the
uncertain outcomes and perception errors inherent to human intention
recognition. In response, we present a framework designed to be resilient to
uncertainty and sensor noise, integrating real-time sensor data with a
combination of planners. Centered around an intention-recognition POMDP, our
approach addresses cooperative planning and acting under uncertainty. Our
integrated framework has been successfully tested on a physical robot with
promising results.

</details>


### [185] [QuadKAN: KAN-Enhanced Quadruped Motion Control via End-to-End Reinforcement Learning](https://arxiv.org/abs/2508.19153)
*Allen Wang,Gavin Tao*

Main category: cs.RO

TL;DR: QuadKAN结合强化学习和视觉引导，通过KANs和样条编码实现稳健的四足运动控制，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 结合本体感觉和视觉以实现更稳健的运动控制。

Method: 提出QuadKAN框架，使用KANs和样条编码，结合MMDR和PPO进行端到端训练。

Result: 在多样地形中表现优异，回报更高、距离更远、碰撞更少。

Conclusion: 样条参数化策略为视觉引导运动提供了简单、有效且可解释的解决方案。

Abstract: We address vision-guided quadruped motion control with reinforcement learning
(RL) and highlight the necessity of combining proprioception with vision for
robust control. We propose QuadKAN, a spline-parameterized cross-modal policy
instantiated with Kolmogorov-Arnold Networks (KANs). The framework incorporates
a spline encoder for proprioception and a spline fusion head for
proprioception-vision inputs. This structured function class aligns the
state-to-action mapping with the piecewise-smooth nature of gait, improving
sample efficiency, reducing action jitter and energy consumption, and providing
interpretable posture-action sensitivities. We adopt Multi-Modal Delay
Randomization (MMDR) and perform end-to-end training with Proximal Policy
Optimization (PPO). Evaluations across diverse terrains, including both even
and uneven surfaces and scenarios with static or dynamic obstacles, demonstrate
that QuadKAN achieves consistently higher returns, greater distances, and fewer
collisions than state-of-the-art (SOTA) baselines. These results show that
spline-parameterized policies offer a simple, effective, and interpretable
alternative for robust vision-guided locomotion. A repository will be made
available upon acceptance.

</details>


### [186] [Real-time Testing of Satellite Attitude Control With a Reaction Wheel Hardware-In-the-Loop Platform](https://arxiv.org/abs/2508.19164)
*Morokot Sakal,George Nehma,Camilo Riano-Rios,Madhur Tiwari*

Main category: cs.RO

TL;DR: 提出了一种用于卫星姿态控制系统的硬件在环（HIL）测试方法，具备反作用轮健康估计功能。


<details>
  <summary>Details</summary>
Motivation: 通过真实动量交换设备验证控制器的有效性，弥补之前仿真和软件在环测试的不足。

Method: 构建HIL测试平台，包括无刷直流电机、CAN总线通信、嵌入式计算机和卫星模拟器，并设计人工诱导反作用轮故障的方法。

Result: 展示了测试平台的实现及相关问题和经验教训。

Conclusion: 该工作是验证航天器姿态控制算法综合测试框架的重要一步。

Abstract: We propose the Hardware-in-the-Loop (HIL) test of an adaptive satellite
attitude control system with reaction wheel health estimation capabilities.
Previous simulations and Software-in-the-Loop testing have prompted further
experiments to explore the validity of the controller with real momentum
exchange devices in the loop. This work is a step toward a comprehensive
testing framework for validation of spacecraft attitude control algorithms. The
proposed HIL testbed includes brushless DC motors and drivers that communicate
using a CAN bus, an embedded computer that executes control and adaptation
laws, and a satellite simulator that produces simulated sensor data, estimated
attitude states, and responds to actions of the external actuators. We propose
methods to artificially induce failures on the reaction wheels, and present
related issues and lessons learned.

</details>


### [187] [Direction Informed Trees (DIT*): Optimal Path Planning via Direction Filter and Direction Cost Heuristic](https://arxiv.org/abs/2508.19168)
*Liding Zhang,Kejia Chen,Kuanqi Cai,Yu Zhang,Yixuan Dang,Yansong Wu,Zhenshan Bing,Fan Wu,Sami Haddadin,Alois Knoll*

Main category: cs.RO

TL;DR: DIT*是一种基于采样的路径规划算法，通过优化搜索方向实现目标偏向探索，比现有算法收敛更快。


<details>
  <summary>Details</summary>
Motivation: 现有启发式算法在准确性和计算效率之间存在冲突，DIT*旨在通过方向优化解决这一问题。

Method: 定义边为广义向量，集成相似性索引建立方向过滤器，用于选择最近邻和估计方向成本。

Result: 在R^4到R^16的测试问题中，DIT*比现有单查询采样规划器收敛更快，并在实际环境中验证。

Conclusion: DIT*通过方向优化和高效信息共享，显著提升了路径规划的性能。

Abstract: Optimal path planning requires finding a series of feasible states from the
starting point to the goal to optimize objectives. Popular path planning
algorithms, such as Effort Informed Trees (EIT*), employ effort heuristics to
guide the search. Effective heuristics are accurate and computationally
efficient, but achieving both can be challenging due to their conflicting
nature. This paper proposes Direction Informed Trees (DIT*), a sampling-based
planner that focuses on optimizing the search direction for each edge,
resulting in goal bias during exploration. We define edges as generalized
vectors and integrate similarity indexes to establish a directional filter that
selects the nearest neighbors and estimates direction costs. The estimated
direction cost heuristics are utilized in edge evaluation. This strategy allows
the exploration to share directional information efficiently. DIT* convergence
faster than existing single-query, sampling-based planners on tested problems
in R^4 to R^16 and has been demonstrated in real-world environments with
various planning tasks. A video showcasing our experimental results is
available at: https://youtu.be/2SX6QT2NOek

</details>


### [188] [From Tabula Rasa to Emergent Abilities: Discovering Robot Skills via Real-World Unsupervised Quality-Diversity](https://arxiv.org/abs/2508.19172)
*Luca Grillotti,Lisa Coiffard,Oscar Pang,Maxence Faldor,Antoine Cully*

Main category: cs.RO

TL;DR: URSA是一种扩展的QDAC方法，能够在真实世界中自主发现和掌握多样化的机器人技能。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要手动定义技能空间和调整启发式，限制了实际应用。

Method: URSA通过无监督方式在真实世界中学习多样化技能，支持启发式和完全无监督设置。

Result: URSA在四足机器人上成功发现多样化运动技能，并在下游任务（如损伤适应）中表现优异。

Conclusion: URSA为真实世界机器人学习提供了新框架，显著提升了自主性和适应性。

Abstract: Autonomous skill discovery aims to enable robots to acquire diverse behaviors
without explicit supervision. Learning such behaviors directly on physical
hardware remains challenging due to safety and data efficiency constraints.
Existing methods, including Quality-Diversity Actor-Critic (QDAC), require
manually defined skill spaces and carefully tuned heuristics, limiting
real-world applicability. We propose Unsupervised Real-world Skill Acquisition
(URSA), an extension of QDAC that enables robots to autonomously discover and
master diverse, high-performing skills directly in the real world. We
demonstrate that URSA successfully discovers diverse locomotion skills on a
Unitree A1 quadruped in both simulation and the real world. Our approach
supports both heuristic-driven skill discovery and fully unsupervised settings.
We also show that the learned skill repertoire can be reused for downstream
tasks such as real-world damage adaptation, where URSA outperforms all
baselines in 5 out of 9 simulated and 3 out of 5 real-world damage scenarios.
Our results establish a new framework for real-world robot learning that
enables continuous skill discovery with limited human intervention,
representing a significant step toward more autonomous and adaptable robotic
systems. Demonstration videos are available at
http://adaptive-intelligent-robotics.github.io/URSA .

</details>


### [189] [Real-Time Model Checking for Closed-Loop Robot Reactive Planning](https://arxiv.org/abs/2508.19186)
*Christopher Chandler,Bernd Porr,Giulia Lafratta,Alice Miller*

Main category: cs.RO

TL;DR: 提出一种基于模型检查的实时多步规划方法，用于自主机器人的障碍物避障。


<details>
  <summary>Details</summary>
Motivation: 探索模型检查在实时多步规划和障碍物避障中的应用，模仿生物智能的核心知识和注意力机制。

Method: 开发小型专用模型检查算法，结合临时控制系统链和2D LiDAR数据离散化，进行前向深度优先搜索的多步规划。

Result: 在低功耗设备上实现实时规划，性能优于仅能单步规划的反应式代理。

Conclusion: 模型检查可用于高效多步规划，为自主车辆的安全可靠规划提供案例研究。

Abstract: We present a new application of model checking which achieves real-time
multi-step planning and obstacle avoidance on a real autonomous robot. We have
developed a small, purpose-built model checking algorithm which generates plans
in situ based on "core" knowledge and attention as found in biological agents.
This is achieved in real-time using no pre-computed data on a low-powered
device. Our approach is based on chaining temporary control systems which are
spawned to counteract disturbances in the local environment that disrupt an
autonomous agent from its preferred action (or resting state). A novel
discretization of 2D LiDAR data sensitive to bounded variations in the local
environment is used. Multi-step planning using model checking by forward
depth-first search is applied to cul-de-sac and playground scenarios. Both
empirical results and informal proofs of two fundamental properties of our
approach demonstrate that model checking can be used to create efficient
multi-step plans for local obstacle avoidance, improving on the performance of
a reactive agent which can only plan one step. Our approach is an instructional
case study for the development of safe, reliable and explainable planning in
the context of autonomous vehicles.

</details>


### [190] [AutoRing: Imitation Learning--based Autonomous Intraocular Foreign Body Removal Manipulation with Eye Surgical Robot](https://arxiv.org/abs/2508.19191)
*Yue Wang,Wenjie Deng,Haotian Xue,Di Cui,Yiqi Chen,Mingchuan Zhou,Haochao Ying,Jian Wu*

Main category: cs.RO

TL;DR: AutoRing是一个模仿学习框架，用于自主眼内异物环操作，解决了运动缩放和RCM点变化带来的运动学不确定性。


<details>
  <summary>Details</summary>
Motivation: 现有机器人系统主要依赖手动远程操作，学习曲线陡峭，难以实现毫米级精度的自主操作。

Method: 结合动态RCM校准和RCM-ACT架构，利用专家演示的立体视觉数据和仪器运动学进行训练。

Result: 在未校准显微镜条件下成功完成环抓取和定位任务，无需显式深度感知。

Conclusion: 为开发能够执行复杂眼内手术的智能眼科系统提供了可行框架。

Abstract: Intraocular foreign body removal demands millimeter-level precision in
confined intraocular spaces, yet existing robotic systems predominantly rely on
manual teleoperation with steep learning curves. To address the challenges of
autonomous manipulation (particularly kinematic uncertainties from variable
motion scaling and variation of the Remote Center of Motion (RCM) point), we
propose AutoRing, an imitation learning framework for autonomous intraocular
foreign body ring manipulation. Our approach integrates dynamic RCM calibration
to resolve coordinate-system inconsistencies caused by intraocular instrument
variation and introduces the RCM-ACT architecture, which combines
action-chunking transformers with real-time kinematic realignment. Trained
solely on stereo visual data and instrument kinematics from expert
demonstrations in a biomimetic eye model, AutoRing successfully completes ring
grasping and positioning tasks without explicit depth sensing. Experimental
validation demonstrates end-to-end autonomy under uncalibrated microscopy
conditions. The results provide a viable framework for developing intelligent
eye-surgical systems capable of complex intraocular procedures.

</details>


### [191] [Planning-Query-Guided Model Generation for Model-Based Deformable Object Manipulation](https://arxiv.org/abs/2508.19199)
*Alex LaGrassa,Zixuan Huang,Dmitry Berenson,Oliver Kroemer*

Main category: cs.RO

TL;DR: 提出一种自动生成任务特定、空间自适应动力学模型的方法，通过预测区域分辨率优化规划速度。


<details>
  <summary>Details</summary>
Motivation: 高维空间（如涉及可变形物体）的高效规划需要计算可行且足够表达的动力学模型。

Method: 基于扩散的模型生成器根据规划查询的起点和目标点云预测区域分辨率，采用两阶段数据收集优化。

Result: 在树木操纵任务中，规划速度提升一倍，任务性能仅小幅下降。

Conclusion: 该方法为利用历史规划数据生成高效且表达充分的动力学模型提供了新思路。

Abstract: Efficient planning in high-dimensional spaces, such as those involving
deformable objects, requires computationally tractable yet sufficiently
expressive dynamics models. This paper introduces a method that automatically
generates task-specific, spatially adaptive dynamics models by learning which
regions of the object require high-resolution modeling to achieve good task
performance for a given planning query. Task performance depends on the complex
interplay between the dynamics model, world dynamics, control, and task
requirements. Our proposed diffusion-based model generator predicts per-region
model resolutions based on start and goal pointclouds that define the planning
query. To efficiently collect the data for learning this mapping, a two-stage
process optimizes resolution using predictive dynamics as a prior before
directly optimizing using closed-loop performance. On a tree-manipulation task,
our method doubles planning speed with only a small decrease in task
performance over using a full-resolution model. This approach informs a path
towards using previous planning and control data to generate computationally
efficient yet sufficiently expressive dynamics models for new tasks.

</details>


### [192] [MemoryVLA: Perceptual-Cognitive Memory in Vision-Language-Action Models for Robotic Manipulation](https://arxiv.org/abs/2508.19236)
*Hao Shi,Bin Xie,Yingfei Liu,Lin Sun,Fengrong Liu,Tiancai Wang,Erjin Zhou,Haoqiang Fan,Xiangyu Zhang,Gao Huang*

Main category: cs.RO

TL;DR: MemoryVLA是一个受人类记忆机制启发的机器人操作框架，通过工作记忆和长期记忆的结合，显著提升了长时程任务的性能。


<details>
  <summary>Details</summary>
Motivation: 机器人操作任务通常具有非马尔可夫性，而现有的视觉语言动作（VLA）模型往往忽略时间上下文，导致在长时程任务中表现不佳。

Method: 提出MemoryVLA框架，结合工作记忆和长期记忆机制，通过感知-认知记忆库存储和检索信息，并利用记忆条件扩散动作专家生成动作序列。

Result: 在仿真和真实任务中，MemoryVLA均优于现有基线，特别是在长时程任务中表现突出。

Conclusion: MemoryVLA通过模拟人类记忆机制，有效解决了长时程机器人操作任务中的时间依赖性问题。

Abstract: Temporal context is essential for robotic manipulation because such tasks are
inherently non-Markovian, yet mainstream VLA models typically overlook it and
struggle with long-horizon, temporally dependent tasks. Cognitive science
suggests that humans rely on working memory to buffer short-lived
representations for immediate control, while the hippocampal system preserves
verbatim episodic details and semantic gist of past experience for long-term
memory. Inspired by these mechanisms, we propose MemoryVLA, a
Cognition-Memory-Action framework for long-horizon robotic manipulation. A
pretrained VLM encodes the observation into perceptual and cognitive tokens
that form working memory, while a Perceptual-Cognitive Memory Bank stores
low-level details and high-level semantics consolidated from it. Working memory
retrieves decision-relevant entries from the bank, adaptively fuses them with
current tokens, and updates the bank by merging redundancies. Using these
tokens, a memory-conditioned diffusion action expert yields temporally aware
action sequences. We evaluate MemoryVLA on 150+ simulation and real-world tasks
across three robots. On SimplerEnv-Bridge, Fractal, and LIBERO-5 suites, it
achieves 71.9%, 72.7%, and 96.5% success rates, respectively, all outperforming
state-of-the-art baselines CogACT and pi-0, with a notable +14.6 gain on
Bridge. On 12 real-world tasks spanning general skills and long-horizon
temporal dependencies, MemoryVLA achieves 84.0% success rate, with long-horizon
tasks showing a +26 improvement over state-of-the-art baseline. Project Page:
https://shihao1895.github.io/MemoryVLA

</details>
