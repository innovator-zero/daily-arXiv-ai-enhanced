<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 89]
- [cs.RO](#cs.RO) [Total: 23]
- [cs.LG](#cs.LG) [Total: 72]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Real-Time Intuitive AI Drawing System for Collaboration: Enhancing Human Creativity through Formal and Contextual Intent Integration](https://arxiv.org/abs/2508.19254)
*Jookyung Song,Mookyoung Kang,Nojun Kwak*

Main category: cs.CV

TL;DR: 提出了一种实时生成绘图系统，结合形式意图和上下文意图进行统一转换。


<details>
  <summary>Details</summary>
Motivation: 传统基于文本提示的生成系统主要捕捉高级上下文描述，而忽略了地面级的几何特征。本文旨在同时分析这两类意图信号。

Method: 通过多阶段生成管道结合轮廓保持的结构控制和风格内容感知的图像合成，使用触摸屏界面和分布式推理架构实现低延迟转换。

Result: 系统支持多用户协作，实现同步共创，重新定义了人机交互为共同创作和相互增强的过程。

Conclusion: 该系统为不同艺术水平的用户提供了同步共创的平台，推动了人机交互的新范式。

Abstract: This paper presents a real-time generative drawing system that interprets and
integrates both formal intent - the structural, compositional, and stylistic
attributes of a sketch - and contextual intent - the semantic and thematic
meaning inferred from its visual content - into a unified transformation
process. Unlike conventional text-prompt-based generative systems, which
primarily capture high-level contextual descriptions, our approach
simultaneously analyzes ground-level intuitive geometric features such as line
trajectories, proportions, and spatial arrangement, and high-level semantic
cues extracted via vision-language models. These dual intent signals are
jointly conditioned in a multi-stage generation pipeline that combines
contour-preserving structural control with style- and content-aware image
synthesis. Implemented with a touchscreen-based interface and distributed
inference architecture, the system achieves low-latency, two-stage
transformation while supporting multi-user collaboration on shared canvases.
The resulting platform enables participants, regardless of artistic expertise,
to engage in synchronous, co-authored visual creation, redefining human-AI
interaction as a process of co-creation and mutual enhancement.

</details>


### [2] [TTF-VLA: Temporal Token Fusion via Pixel-Attention Integration for Vision-Language-Action Models](https://arxiv.org/abs/2508.19257)
*Chenghao Liu,Jiachen Zhang,Chengxuan Li,Zhimu Zhou,Shixin Wu,Songfang Huang,Huiling Duan*

Main category: cs.CV

TL;DR: TTF是一种无需训练的方法，通过整合历史和当前视觉表示提升VLA模型推理质量，实验显示在多个任务中性能提升显著。


<details>
  <summary>Details</summary>
Motivation: VLA模型逐帧处理视觉输入，忽略了机器人操作任务中的时间信息，导致对视觉噪声敏感且忽略帧间连贯性。

Method: 提出Temporal Token Fusion (TTF)，结合灰度像素差异分析和注意力语义相关性评估，选择性融合时间令牌。

Result: 在LIBERO、SimplerEnv和真实机器人任务中分别提升4.0、4.8和8.7个百分点，且模型无关。

Conclusion: TTF不仅提升性能，还揭示了注意力机制中Query矩阵重用的潜力，为计算加速和任务成功率提升提供新方向。

Abstract: Vision-Language-Action (VLA) models process visual inputs independently at
each timestep, discarding valuable temporal information inherent in robotic
manipulation tasks. This frame-by-frame processing makes models vulnerable to
visual noise while ignoring the substantial coherence between consecutive
frames in manipulation sequences. We propose Temporal Token Fusion (TTF), a
training-free approach that intelligently integrates historical and current
visual representations to enhance VLA inference quality. Our method employs
dual-dimension detection combining efficient grayscale pixel difference
analysis with attention-based semantic relevance assessment, enabling selective
temporal token fusion through hard fusion strategies and keyframe anchoring to
prevent error accumulation. Comprehensive experiments across LIBERO,
SimplerEnv, and real robot tasks demonstrate consistent improvements: 4.0
percentage points average on LIBERO (72.4\% vs 68.4\% baseline),
cross-environment validation on SimplerEnv (4.8\% relative improvement), and
8.7\% relative improvement on real robot tasks. Our approach proves
model-agnostic, working across OpenVLA and VLA-Cache architectures. Notably,
TTF reveals that selective Query matrix reuse in attention mechanisms enhances
rather than compromises performance, suggesting promising directions for direct
KQV matrix reuse strategies that achieve computational acceleration while
improving task success rates.

</details>


### [3] [Seeing Like a Designer Without One: A Study on Unsupervised Slide Quality Assessment via Designer Cue Augmentation](https://arxiv.org/abs/2508.19289)
*Tai Inui,Steven Oh,Magdeline Kuan*

Main category: cs.CV

TL;DR: 提出了一种结合专家视觉设计指标与CLIP-ViT嵌入的无监督幻灯片质量评估方法，效果优于主流视觉语言模型。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在评估幻灯片质量时表现不足，需要更接近人类感知的客观评估方法。

Method: 结合七项视觉设计指标与CLIP-ViT嵌入，使用Isolation Forest异常评分评估幻灯片质量。

Result: 在专业讲座幻灯片上训练，与人类视觉评分相关性达0.83，优于主流模型。

Conclusion: 结合低级设计线索与多模态嵌入能有效评估幻灯片质量，提供实时反馈。

Abstract: We present an unsupervised slide-quality assessment pipeline that combines
seven expert-inspired visual-design metrics (whitespace, colorfulness, edge
density, brightness contrast, text density, color harmony, layout balance) with
CLIP-ViT embeddings, using Isolation Forest-based anomaly scoring to evaluate
presentation slides. Trained on 12k professional lecture slides and evaluated
on six academic talks (115 slides), our method achieved Pearson correlations up
to 0.83 with human visual-quality ratings-1.79x to 3.23x stronger than scores
from leading vision-language models (ChatGPT o4-mini-high, ChatGPT o3, Claude
Sonnet 4, Gemini 2.5 Pro). We demonstrate convergent validity with visual
ratings, discriminant validity against speaker-delivery scores, and exploratory
alignment with overall impressions. Our results show that augmenting low-level
design cues with multimodal embeddings closely approximates audience
perceptions of slide quality, enabling scalable, objective feedback in real
time.

</details>


### [4] [Efficient Model-Based Purification Against Adversarial Attacks for LiDAR Segmentation](https://arxiv.org/abs/2508.19290)
*Alexandros Gkillas,Ioulia Kapsali,Nikos Piperigkos,Aris S. Lalos*

Main category: cs.CV

TL;DR: 提出了一种针对2D范围视图LiDAR分割的高效对抗防御框架，通过可解释的净化网络实现强鲁棒性且计算开销低。


<details>
  <summary>Details</summary>
Motivation: 现有防御方法多针对3D点云且计算量大，而2D范围视图LiDAR分割缺乏轻量级对抗防御研究。

Method: 基于数学优化的可解释净化网络，直接在范围视图域进行对抗防御。

Result: 在公开基准测试中表现优异，优于生成模型和对抗训练基线，并在实际自动驾驶场景中验证有效性。

Conclusion: 该框架为2D范围视图LiDAR分割提供了高效且实用的对抗防御解决方案。

Abstract: LiDAR-based segmentation is essential for reliable perception in autonomous
vehicles, yet modern segmentation networks are highly susceptible to
adversarial attacks that can compromise safety. Most existing defenses are
designed for networks operating directly on raw 3D point clouds and rely on
large, computationally intensive generative models. However, many
state-of-the-art LiDAR segmentation pipelines operate on more efficient 2D
range view representations. Despite their widespread adoption, dedicated
lightweight adversarial defenses for this domain remain largely unexplored. We
introduce an efficient model-based purification framework tailored for
adversarial defense in 2D range-view LiDAR segmentation. We propose a direct
attack formulation in the range-view domain and develop an explainable
purification network based on a mathematical justified optimization problem,
achieving strong adversarial resilience with minimal computational overhead.
Our method achieves competitive performance on open benchmarks, consistently
outperforming generative and adversarial training baselines. More importantly,
real-world deployment on a demo vehicle demonstrates the framework's ability to
deliver accurate operation in practical autonomous driving scenarios.

</details>


### [5] [Object Detection with Multimodal Large Vision-Language Models: An In-depth Review](https://arxiv.org/abs/2508.19294)
*Ranjan Sapkota,Manoj Karkee*

Main category: cs.CV

TL;DR: 大型视觉语言模型（LVLMs）通过融合语言和视觉技术，提升了目标检测的适应性和泛化能力，未来可能超越传统方法。


<details>
  <summary>Details</summary>
Motivation: 探讨LVLMs如何通过结合自然语言处理和计算机视觉技术，推动目标检测领域的进步。

Method: 通过三步研究流程，分析LVLMs的架构创新、训练范式和信息整合方式。

Result: LVLMs在多样场景中表现出色，但仍有局限性，需进一步改进。

Conclusion: LVLMs的进步将深刻影响目标检测和机器人应用的未来发展。

Abstract: The fusion of language and vision in large vision-language models (LVLMs) has
revolutionized deep learning-based object detection by enhancing adaptability,
contextual reasoning, and generalization beyond traditional architectures. This
in-depth review presents a structured exploration of the state-of-the-art in
LVLMs, systematically organized through a three-step research review process.
First, we discuss the functioning of vision language models (VLMs) for object
detection, describing how these models harness natural language processing
(NLP) and computer vision (CV) techniques to revolutionize object detection and
localization. We then explain the architectural innovations, training
paradigms, and output flexibility of recent LVLMs for object detection,
highlighting how they achieve advanced contextual understanding for object
detection. The review thoroughly examines the approaches used in integration of
visual and textual information, demonstrating the progress made in object
detection using VLMs that facilitate more sophisticated object detection and
localization strategies. This review presents comprehensive visualizations
demonstrating LVLMs' effectiveness in diverse scenarios including localization
and segmentation, and then compares their real-time performance, adaptability,
and complexity to traditional deep learning systems. Based on the review, its
is expected that LVLMs will soon meet or surpass the performance of
conventional methods in object detection. The review also identifies a few
major limitations of the current LVLM modes, proposes solutions to address
those challenges, and presents a clear roadmap for the future advancement in
this field. We conclude, based on this study, that the recent advancement in
LVLMs have made and will continue to make a transformative impact on object
detection and robotic applications in the future.

</details>


### [6] [Large VLM-based Stylized Sports Captioning](https://arxiv.org/abs/2508.19295)
*Sauptik Dhar,Nicholas Buoncristiani,Joe Anakata,Haoyu Zhang,Michelle Munson*

Main category: cs.CV

TL;DR: 论文提出了一种两级微调的LVLM管道，用于生成体育比赛的图像描述，显著提升了F1和BERT分数，并在实际应用中验证了其高效性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM/LVLM在体育领域的自然语言描述中缺乏领域特定的术语，无法生成符合生产要求的风格化描述。

Method: 采用两级微调的LVLM管道，优化了体育图像描述的生成。

Result: F1分数提升8-10%，BERT分数提升2-10%，运行时内存占用小且执行速度快。

Conclusion: 该方法在超级碗LIX中成功应用，证明了其在实际体育新闻报道中的高效性和准确性。

Abstract: The advent of large (visual) language models (LLM / LVLM) have led to a
deluge of automated human-like systems in several domains including social
media content generation, search and recommendation, healthcare prognosis, AI
assistants for cognitive tasks etc. Although these systems have been
successfully integrated in production; very little focus has been placed on
sports, particularly accurate identification and natural language description
of the game play. Most existing LLM/LVLMs can explain generic sports
activities, but lack sufficient domain-centric sports' jargon to create natural
(human-like) descriptions. This work highlights the limitations of existing
SoTA LLM/LVLMs for generating production-grade sports captions from images in a
desired stylized format, and proposes a two-level fine-tuned LVLM pipeline to
address that. The proposed pipeline yields an improvement > 8-10% in the F1,
and > 2-10% in BERT score compared to alternative approaches. In addition, it
has a small runtime memory footprint and fast execution time. During Super Bowl
LIX the pipeline proved its practical application for live professional sports
journalism; generating highly accurate and stylized captions at the rate of 6
images per 3-5 seconds for over 1000 images during the game play.

</details>


### [7] [DemoBias: An Empirical Study to Trace Demographic Biases in Vision Foundation Models](https://arxiv.org/abs/2508.19298)
*Abu Sufian,Anirudha Ghosh,Debaditya Barman,Marco Leo,Cosimo Distante*

Main category: cs.CV

TL;DR: 论文通过DemoBias项目评估了大型视觉语言模型（LVLMs）在生物特征人脸识别（FR）任务中的群体偏见问题，发现不同模型在不同人口群体中存在性能差异。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决LVLMs在生物特征人脸识别任务中存在的群体偏见问题，尤其是针对不同种族、性别和年龄群体的公平性。

Method: 方法包括对三种预训练LVLMs（LLaVA、BLIP-2和PaliGemma）进行微调，并在自建的人口平衡数据集上评估其性能，使用BERTScores和Fairness Discrepancy Rate等指标量化差异。

Result: 实验结果显示PaliGemma和LLaVA在西班牙裔/拉丁裔、高加索人和南亚群体中表现差异较大，而BLIP-2表现相对一致。

Conclusion: 结论指出LVLMs存在群体偏见，需进一步优化以提高公平性和可靠性。

Abstract: Large Vision Language Models (LVLMs) have demonstrated remarkable
capabilities across various downstream tasks, including biometric face
recognition (FR) with description. However, demographic biases remain a
critical concern in FR, as these foundation models often fail to perform
equitably across diverse demographic groups, considering ethnicity/race,
gender, and age. Therefore, through our work DemoBias, we conduct an empirical
evaluation to investigate the extent of demographic biases in LVLMs for
biometric FR with textual token generation tasks. We fine-tuned and evaluated
three widely used pre-trained LVLMs: LLaVA, BLIP-2, and PaliGemma on our own
generated demographic-balanced dataset. We utilize several evaluation metrics,
like group-specific BERTScores and the Fairness Discrepancy Rate, to quantify
and trace the performance disparities. The experimental results deliver
compelling insights into the fairness and reliability of LVLMs across diverse
demographic groups. Our empirical study uncovered demographic biases in LVLMs,
with PaliGemma and LLaVA exhibiting higher disparities for Hispanic/Latino,
Caucasian, and South Asian groups, whereas BLIP-2 demonstrated comparably
consistent. Repository: https://github.com/Sufianlab/DemoBias.

</details>


### [8] [Geo2Vec: Shape- and Distance-Aware Neural Representation of Geospatial Entities](https://arxiv.org/abs/2508.19305)
*Chen Chu,Cyrus Shahabi*

Main category: cs.CV

TL;DR: Geo2Vec是一种新的空间表示学习方法，直接操作于原始空间，通过自适应采样和符号距离场（SDF）捕捉几何特征，避免了现有方法的计算复杂性和几何对齐问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么仅针对单一地理实体类型，要么通过分解实体引入高计算成本，且缺乏几何对齐，导致细粒度特征模糊。

Method: Geo2Vec利用SDF自适应采样点并编码其符号距离，通过神经网络训练生成紧凑、几何感知的统一表示，并提出旋转不变的位置编码。

Result: Geo2Vec在形状和位置表示、拓扑和距离关系捕捉以及实际GeoAI应用中均优于现有方法。

Conclusion: Geo2Vec提供了一种高效、统一且几何感知的空间表示学习方法，适用于多种地理实体类型和下游GeoAI任务。

Abstract: Spatial representation learning is essential for GeoAI applications such as
urban analytics, enabling the encoding of shapes, locations, and spatial
relationships (topological and distance-based) of geo-entities like points,
polylines, and polygons. Existing methods either target a single geo-entity
type or, like Poly2Vec, decompose entities into simpler components to enable
Fourier transformation, introducing high computational cost. Moreover, since
the transformed space lacks geometric alignment, these methods rely on uniform,
non-adaptive sampling, which blurs fine-grained features like edges and
boundaries. To address these limitations, we introduce Geo2Vec, a novel method
inspired by signed distance fields (SDF) that operates directly in the original
space. Geo2Vec adaptively samples points and encodes their signed distances
(positive outside, negative inside), capturing geometry without decomposition.
A neural network trained to approximate the SDF produces compact,
geometry-aware, and unified representations for all geo-entity types.
Additionally, we propose a rotation-invariant positional encoding to model
high-frequency spatial variations and construct a structured and robust
embedding space for downstream GeoAI models. Empirical results show that
Geo2Vec consistently outperforms existing methods in representing shape and
location, capturing topological and distance relationships, and achieving
greater efficiency in real-world GeoAI applications. Code and Data can be found
at: https://github.com/chuchen2017/GeoNeuralRepresentation.

</details>


### [9] [Advancements in Crop Analysis through Deep Learning and Explainable AI](https://arxiv.org/abs/2508.19307)
*Hamza Khan*

Main category: cs.CV

TL;DR: 该研究提出了一种基于卷积神经网络（CNN）的自动化方法，用于分类五种水稻品种，并结合可解释人工智能（XAI）技术开发了水稻叶片病害诊断方法。


<details>
  <summary>Details</summary>
Motivation: 水稻是全球重要的主食，其质量和产量对贸易、营养和经济增长至关重要。传统的人工检测方法效率低且易出错，因此需要自动化解决方案。

Method: 使用包含75000张图像的公开数据集训练和测试CNN模型，并结合VGG16、ResNet50和MobileNetV2等深度学习模型及SHAP和LIME解释性技术。

Result: 模型在分类水稻品种时表现出高准确性和低误分类率，同时成功诊断了水稻叶片病害。解释性技术增强了模型的透明度和可靠性。

Conclusion: 深度学习在农业应用中具有巨大潜力，可支持自动化作物质量检查和病害诊断，为农民、消费者和农业经济带来益处。

Abstract: Rice is a staple food of global importance in terms of trade, nutrition, and
economic growth. Among Asian nations such as China, India, Pakistan, Thailand,
Vietnam and Indonesia are leading producers of both long and short grain
varieties, including basmati, jasmine, arborio, ipsala, and kainat saila. To
ensure consumer satisfaction and strengthen national reputations, monitoring
rice crops and grain quality is essential. Manual inspection, however, is
labour intensive, time consuming and error prone, highlighting the need for
automated solutions for quality control and yield improvement. This study
proposes an automated approach to classify five rice grain varieties using
Convolutional Neural Networks (CNN). A publicly available dataset of 75000
images was used for training and testing. Model evaluation employed accuracy,
recall, precision, F1-score, ROC curves, and confusion matrices. Results
demonstrated high classification accuracy with minimal misclassifications,
confirming the model effectiveness in distinguishing rice varieties. In
addition, an accurate diagnostic method for rice leaf diseases such as Brown
Spot, Blast, Bacterial Blight, and Tungro was developed. The framework combined
explainable artificial intelligence (XAI) with deep learning models including
CNN, VGG16, ResNet50, and MobileNetV2. Explainability techniques such as SHAP
(SHapley Additive exPlanations) and LIME (Local Interpretable Model-agnostic
Explanations) revealed how specific grain and leaf features influenced
predictions, enhancing model transparency and reliability. The findings
demonstrate the strong potential of deep learning in agricultural applications,
paving the way for robust, interpretable systems that can support automated
crop quality inspection and disease diagnosis, ultimately benefiting farmers,
consumers, and the agricultural economy.

</details>


### [10] [Sistema de Reconocimiento Facial Federado en Conjuntos Abiertos basado en OpenMax](https://arxiv.org/abs/2508.19312)
*Ander Galván,Marivi Higuero,Jorge Sasiain,Eduardo Jacob*

Main category: cs.CV

TL;DR: 论文提出了一种基于联邦学习和OpenMax算法的人脸识别系统，用于开放集场景，有效区分已知和未知个体。


<details>
  <summary>Details</summary>
Motivation: AI人脸识别在隐私和身份管理方面面临挑战，尤其是在开放集中处理未知个体时。

Method: 结合OpenMax算法和联邦学习，通过交换平均激活向量和局部距离度量来识别已知和未知个体。

Result: 实验验证了该方法的有效性，提升了分布式环境中隐私保护和鲁棒性。

Conclusion: 该方法为隐私感知的分布式人脸识别提供了可行解决方案。

Abstract: Facial recognition powered by Artificial Intelligence has achieved high
accuracy in specific scenarios and applications. Nevertheless, it faces
significant challenges regarding privacy and identity management, particularly
when unknown individuals appear in the operational context. This paper presents
the design, implementation, and evaluation of a facial recognition system
within a federated learning framework tailored to open-set scenarios. The
proposed approach integrates the OpenMax algorithm into federated learning,
leveraging the exchange of mean activation vectors and local distance measures
to reliably distinguish between known and unknown subjects. Experimental
results validate the effectiveness of the proposed solution, demonstrating its
potential for enhancing privacy-aware and robust facial recognition in
distributed environments.
  --
  El reconocimiento facial impulsado por Inteligencia Artificial ha demostrado
una alta precisi\'on en algunos escenarios y aplicaciones. Sin embargo,
presenta desaf\'ios relacionados con la privacidad y la identificaci\'on de
personas, especialmente considerando que pueden aparecer sujetos desconocidos
para el sistema que lo implementa. En este trabajo, se propone el dise\~no,
implementaci\'on y evaluaci\'on de un sistema de reconocimiento facial en un
escenario de aprendizaje federado, orientado a conjuntos abiertos.
Concretamente, se dise\~na una soluci\'on basada en el algoritmo OpenMax para
escenarios de aprendizaje federado. La propuesta emplea el intercambio de los
vectores de activaci\'on promedio y distancias locales para identificar de
manera eficaz tanto personas conocidas como desconocidas. Los experimentos
realizados demuestran la implementaci\'on efectiva de la soluci\'on propuesta.

</details>


### [11] [Automated classification of natural habitats using ground-level imagery](https://arxiv.org/abs/2508.19314)
*Mahdis Tourian,Sareh Rowlands,Remy Vandaele,Max Fancourt,Rebecca Mein,Hywel T. P. Williams*

Main category: cs.CV

TL;DR: 提出了一种基于地面照片的深度学习方法来分类陆地栖息地，展示了在生态监测中的潜力。


<details>
  <summary>Details</summary>
Motivation: 准确的陆地栖息地分类对生物多样性保护、生态监测和土地利用规划至关重要。传统方法依赖卫星图像和生态学家验证，而本研究旨在通过地面照片实现更高效的分类。

Method: 使用DeepLabV3-ResNet101模型对地面照片进行分类，预处理包括调整大小、归一化和数据增强，并通过重采样平衡训练数据。

Result: 模型在18类栖息地中表现良好，平均F1分数为0.61，部分类别（如Bare Soil）得分超过0.90。

Conclusion: 地面照片结合深度学习方法在生态监测中具有广泛应用潜力，并提供了配套的网页工具供实践者使用。

Abstract: Accurate classification of terrestrial habitats is critical for biodiversity
conservation, ecological monitoring, and land-use planning. Several habitat
classification schemes are in use, typically based on analysis of satellite
imagery with validation by field ecologists. Here we present a methodology for
classification of habitats based solely on ground-level imagery (photographs),
offering improved validation and the ability to classify habitats at scale (for
example using citizen-science imagery). In collaboration with Natural England,
a public sector organisation responsible for nature conservation in England,
this study develops a classification system that applies deep learning to
ground-level habitat photographs, categorising each image into one of 18
classes defined by the 'Living England' framework. Images were pre-processed
using resizing, normalisation, and augmentation; re-sampling was used to
balance classes in the training data and enhance model robustness. We developed
and fine-tuned a DeepLabV3-ResNet101 classifier to assign a habitat class label
to each photograph. Using five-fold cross-validation, the model demonstrated
strong overall performance across 18 habitat classes, with accuracy and
F1-scores varying between classes. Across all folds, the model achieved a mean
F1-score of 0.61, with visually distinct habitats such as Bare Soil, Silt and
Peat (BSSP) and Bare Sand (BS) reaching values above 0.90, and mixed or
ambiguous classes scoring lower. These findings demonstrate the potential of
this approach for ecological monitoring. Ground-level imagery is readily
obtained, and accurate computational methods for habitat classification based
on such data have many potential applications. To support use by practitioners,
we also provide a simple web application that classifies uploaded images using
our model.

</details>


### [12] [MIDAS: Multimodal Interactive Digital-human Synthesis via Real-time Autoregressive Video Generation](https://arxiv.org/abs/2508.19320)
*Ming Chen,Liyuan Cui,Wenyuan Zhang,Haoxian Zhang,Yan Zhou,Xiaohan Li,Xiaoqiang Liu,Pengfei Wan*

Main category: cs.CV

TL;DR: 提出了一种自回归视频生成框架，支持多模态交互控制和低延迟流式推断，解决了现有方法的高延迟、高计算成本和有限可控性问题。


<details>
  <summary>Details</summary>
Motivation: 现有交互式数字人视频生成方法存在高延迟、高计算成本和可控性有限的问题，难以满足实时交互需求。

Method: 通过微调大型语言模型（LLM），接受音频、姿态和文本等多模态条件编码，输出空间和语义一致的表示，指导扩散头的去噪过程。构建了大规模对话数据集（约20,000小时），并引入深度压缩自编码器（压缩比达64倍）减轻自回归模型的长时推理负担。

Result: 在双工对话、多语言人合成和交互世界模型等实验中，展示了低延迟、高效率和细粒度多模态可控性的优势。

Conclusion: 该框架为实时交互式数字人视频生成提供了高效、可控的解决方案。

Abstract: Recently, interactive digital human video generation has attracted widespread
attention and achieved remarkable progress. However, building such a practical
system that can interact with diverse input signals in real time remains
challenging to existing methods, which often struggle with high latency, heavy
computational cost, and limited controllability. In this work, we introduce an
autoregressive video generation framework that enables interactive multimodal
control and low-latency extrapolation in a streaming manner. With minimal
modifications to a standard large language model (LLM), our framework accepts
multimodal condition encodings including audio, pose, and text, and outputs
spatially and semantically coherent representations to guide the denoising
process of a diffusion head. To support this, we construct a large-scale
dialogue dataset of approximately 20,000 hours from multiple sources, providing
rich conversational scenarios for training. We further introduce a deep
compression autoencoder with up to 64$\times$ reduction ratio, which
effectively alleviates the long-horizon inference burden of the autoregressive
model. Extensive experiments on duplex conversation, multilingual human
synthesis, and interactive world model highlight the advantages of our approach
in low latency, high efficiency, and fine-grained multimodal controllability.

</details>


### [13] [Deep Data Hiding for ICAO-Compliant Face Images: A Survey](https://arxiv.org/abs/2508.19324)
*Jefferson David Rodriguez Chivata,Davide Ghiani,Simone Maurizio La Cava,Marco Micheletto,Giulia Orrù,Federico Lama,Gian Luca Marcialis*

Main category: cs.CV

TL;DR: 该论文探讨了数字水印和隐写术作为补充解决方案，用于在ICAO合规的面部图像中嵌入防篡改信号，以实现持久验证。


<details>
  <summary>Details</summary>
Motivation: ICAO合规的面部图像在身份验证中广泛应用，但也容易被用于恶意目的（如身份盗窃）。传统防护措施（如PAD）存在局限性，需要新的解决方案。

Method: 论文调查了数字水印和隐写术技术，并对其进行了全面分析。

Result: 研究评估了这些技术的潜力和局限性，并提出了在标准约束下的适用性建议。

Conclusion: 数字水印和隐写术是有效的补充解决方案，但需权衡关键因素以确保实际部署的安全性。

Abstract: ICAO-compliant facial images, initially designed for secure biometric
passports, are increasingly becoming central to identity verification in a wide
range of application contexts, including border control, digital travel
credentials, and financial services. While their standardization enables global
interoperability, it also facilitates practices such as morphing and deepfakes,
which can be exploited for harmful purposes like identity theft and illegal
sharing of identity documents. Traditional countermeasures like Presentation
Attack Detection (PAD) are limited to real-time capture and offer no
post-capture protection. This survey paper investigates digital watermarking
and steganography as complementary solutions that embed tamper-evident signals
directly into the image, enabling persistent verification without compromising
ICAO compliance. We provide the first comprehensive analysis of
state-of-the-art techniques to evaluate the potential and drawbacks of the
underlying approaches concerning the applications involving ICAO-compliant
images and their suitability under standard constraints. We highlight key
trade-offs, offering guidance for secure deployment in real-world identity
systems.

</details>


### [14] [PRISM: A Framework Harnessing Unsupervised Visual Representations and Textual Prompts for Explainable MACE Survival Prediction from Cardiac Cine MRI](https://arxiv.org/abs/2508.19325)
*Haoyang Su,Jin-Yi Xiang,Shaohao Rui,Yifan Gao,Xingyu Chen,Tingxuan Yin,Xiaosong Wang,Lian-Ming Wu*

Main category: cs.CV

TL;DR: PRISM是一种自监督框架，结合心脏MRI和电子健康记录（EHR）进行生存分析，优于传统和SOTA模型。


<details>
  <summary>Details</summary>
Motivation: 准确预测主要不良心脏事件（MACE）是心血管预后的核心挑战。

Method: PRISM通过运动感知多视图蒸馏提取时间同步的成像特征，并使用医学文本提示进行调制。

Result: 在四个独立临床队列中，PRISM表现优于基线模型，并揭示了三种与MACE风险相关的成像特征。

Conclusion: PRISM为心脏风险提供了有价值的见解，并识别了高血压、糖尿病和吸烟等主要风险因素。

Abstract: Accurate prediction of major adverse cardiac events (MACE) remains a central
challenge in cardiovascular prognosis. We present PRISM (Prompt-guided
Representation Integration for Survival Modeling), a self-supervised framework
that integrates visual representations from non-contrast cardiac cine magnetic
resonance imaging with structured electronic health records (EHRs) for survival
analysis. PRISM extracts temporally synchronized imaging features through
motion-aware multi-view distillation and modulates them using medically
informed textual prompts to enable fine-grained risk prediction. Across four
independent clinical cohorts, PRISM consistently surpasses classical survival
prediction models and state-of-the-art (SOTA) deep learning baselines under
internal and external validation. Further clinical findings demonstrate that
the combined imaging and EHR representations derived from PRISM provide
valuable insights into cardiac risk across diverse cohorts. Three distinct
imaging signatures associated with elevated MACE risk are uncovered, including
lateral wall dyssynchrony, inferior wall hypersensitivity, and anterior
elevated focus during diastole. Prompt-guided attribution further identifies
hypertension, diabetes, and smoking as dominant contributors among clinical and
physiological EHR factors.

</details>


### [15] [EffNetViTLoRA: An Efficient Hybrid Deep Learning Approach for Alzheimer's Disease Diagnosis](https://arxiv.org/abs/2508.19349)
*Mahdieh Behjat Khatooni,Mohsen Soryani*

Main category: cs.CV

TL;DR: EffNetViTLoRA模型结合CNN与ViT，利用完整ADNI MRI数据集进行阿尔茨海默病诊断，准确率达92.52%。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病（AD）早期诊断至关重要，但轻度认知障碍（MCI）诊断困难，需更鲁棒的模型。

Method: 结合CNN与ViT捕捉MRI图像的局部和全局特征，使用LoRA微调ViT以适应目标域。

Result: 模型在AD、MCI和CN分类中达到92.52%准确率和92.76% F1分数。

Conclusion: EffNetViTLoRA提供了一种高效、可靠的AD诊断方法，适用于临床。

Abstract: Alzheimer's disease (AD) is one of the most prevalent neurodegenerative
disorders worldwide. As it progresses, it leads to the deterioration of
cognitive functions. Since AD is irreversible, early diagnosis is crucial for
managing its progression. Mild Cognitive Impairment (MCI) represents an
intermediate stage between Cognitively Normal (CN) individuals and those with
AD, and is considered a transitional phase from normal cognition to Alzheimer's
disease. Diagnosing MCI is particularly challenging due to the subtle
differences between adjacent diagnostic categories. In this study, we propose
EffNetViTLoRA, a generalized end-to-end model for AD diagnosis using the whole
Alzheimer's Disease Neuroimaging Initiative (ADNI) Magnetic Resonance Imaging
(MRI) dataset. Our model integrates a Convolutional Neural Network (CNN) with a
Vision Transformer (ViT) to capture both local and global features from MRI
images. Unlike previous studies that rely on limited subsets of data, our
approach is trained on the full T1-weighted MRI dataset from ADNI, resulting in
a more robust and unbiased model. This comprehensive methodology enhances the
model's clinical reliability. Furthermore, fine-tuning large pretrained models
often yields suboptimal results when source and target dataset domains differ.
To address this, we incorporate Low-Rank Adaptation (LoRA) to effectively adapt
the pretrained ViT model to our target domain. This method enables efficient
knowledge transfer and reduces the risk of overfitting. Our model achieves a
classification accuracy of 92.52% and an F1-score of 92.76% across three
diagnostic categories: AD, MCI, and CN for full ADNI dataset.

</details>


### [16] [Concurrent validity of computer-vision artificial intelligence player tracking software using broadcast footage](https://arxiv.org/abs/2508.19477)
*Zachary L. Crang,Rich D. Johnston,Katie L. Mills,Johsan Billingham,Sam Robertson,Michael H. Cole,Jonathon Weakley,Adam Hewitt and,Grant M. Duthie*

Main category: cs.CV

TL;DR: 研究评估了商业AI球员追踪软件在广播画面中的准确性，发现其位置和速度测量存在显著误差，建议使用战术画面以提高精度。


<details>
  <summary>Details</summary>
Motivation: 了解商业AI追踪软件在足球比赛中的准确性，并探讨摄像头画面和分辨率对结果的影响。

Method: 使用2022年卡塔尔世界杯的一场比赛数据，对比三种商业AI追踪软件与高精度多摄像头系统（TRACAB Gen 5）的结果，计算RMSE和平均偏差。

Result: 位置误差范围为1.68至16.39米，速度误差为0.34至2.38米/秒；总距离偏差高达±24.3%。战术画面能显著提高精度。

Conclusion: 商业AI追踪软件在球员检测时表现尚可，建议使用战术画面和适当分辨率以优化准确性。

Abstract: This study aimed to: (1) understand whether commercially available
computer-vision and artificial intelligence (AI) player tracking software can
accurately measure player position, speed and distance using broadcast footage
and (2) determine the impact of camera feed and resolution on accuracy. Data
were obtained from one match at the 2022 Qatar Federation Internationale de
Football Association (FIFA) World Cup. Tactical, programme and camera 1 feeds
were used. Three commercial tracking providers that use computer-vision and AI
participated. Providers analysed instantaneous position (x, y coordinates) and
speed (m\,s^{-1}) of each player. Their data were compared with a
high-definition multi-camera tracking system (TRACAB Gen 5). Root mean square
error (RMSE) and mean bias were calculated. Position RMSE ranged from 1.68 to
16.39 m, while speed RMSE ranged from 0.34 to 2.38 m\,s^{-1}. Total match
distance mean bias ranged from -1745 m (-21.8%) to 1945 m (24.3%) across
providers. Computer-vision and AI player tracking software offer the ability to
track players with fair precision when players are detected by the software.
Providers should use a tactical feed when tracking position and speed, which
will maximise player detection, improving accuracy. Both 720p and 1080p
resolutions are suitable, assuming appropriate computer-vision and AI models
are implemented.

</details>


### [17] [JVLGS: Joint Vision-Language Gas Leak Segmentation](https://arxiv.org/abs/2508.19485)
*Xinlong Zhao,Qixiang Pang,Shan Du*

Main category: cs.CV

TL;DR: 提出了一种名为JVLGS的新框架，结合视觉和文本模态的优势，提升气体泄漏的表示和分割能力，并通过后处理减少误报。


<details>
  <summary>Details</summary>
Motivation: 气体泄漏对人类健康和大气污染构成严重威胁，但现有检测方法效果有限，尤其是红外视频技术因气体云的非刚性和模糊性而受限。

Method: JVLGS框架整合视觉和文本模态的互补优势，增强气体泄漏的表示和分割，并引入后处理步骤减少噪声和非目标物体导致的误报。

Result: 在多种场景下的实验表明，JVLGS显著优于现有气体泄漏分割方法，在监督学习和少样本学习设置下均表现优异。

Conclusion: JVLGS通过多模态融合和后处理，有效提升了气体泄漏检测的准确性和鲁棒性，适用于不同学习场景。

Abstract: Gas leaks pose serious threats to human health and contribute significantly
to atmospheric pollution, drawing increasing public concern. However, the lack
of effective detection methods hampers timely and accurate identification of
gas leaks. While some vision-based techniques leverage infrared videos for leak
detection, the blurry and non-rigid nature of gas clouds often limits their
effectiveness. To address these challenges, we propose a novel framework called
Joint Vision-Language Gas leak Segmentation (JVLGS), which integrates the
complementary strengths of visual and textual modalities to enhance gas leak
representation and segmentation. Recognizing that gas leaks are sporadic and
many video frames may contain no leak at all, our method incorporates a
post-processing step to reduce false positives caused by noise and non-target
objects, an issue that affects many existing approaches. Extensive experiments
conducted across diverse scenarios show that JVLGS significantly outperforms
state-of-the-art gas leak segmentation methods. We evaluate our model under
both supervised and few-shot learning settings, and it consistently achieves
strong performance in both, whereas competing methods tend to perform well in
only one setting or poorly in both. Code available at:
https://github.com/GeekEagle/JVLGS

</details>


### [18] [UNIFORM: Unifying Knowledge from Large-scale and Diverse Pre-trained Models](https://arxiv.org/abs/2508.19498)
*Yimu Wang,Weiming Zhuang,Chen Chen,Jiabo Huang,Jingtao Li,Lingjuan Lyu*

Main category: cs.CV

TL;DR: UNIFORM框架通过投票机制整合异构预训练模型的知识，提升无监督目标识别性能。


<details>
  <summary>Details</summary>
Motivation: 预训练模型数量增多，但异构性导致知识整合困难，现有方法受限于数据和架构假设。

Method: 提出UNIFORM框架，通过logit和特征级别的投票机制整合不同预训练模型的知识。

Result: 实验表明UNIFORM显著提升性能，且能扩展到上百个教师模型。

Conclusion: UNIFORM有效解决了异构预训练模型知识整合的挑战，具有强扩展性。

Abstract: In the era of deep learning, the increasing number of pre-trained models
available online presents a wealth of knowledge. These models, developed with
diverse architectures and trained on varied datasets for different tasks,
provide unique interpretations of the real world. Their collective consensus is
likely universal and generalizable to unseen data. However, effectively
harnessing this collective knowledge poses a fundamental challenge due to the
heterogeneity of pre-trained models. Existing knowledge integration solutions
typically rely on strong assumptions about training data distributions and
network architectures, limiting them to learning only from specific types of
models and resulting in data and/or inductive biases. In this work, we
introduce a novel framework, namely UNIFORM, for knowledge transfer from a
diverse set of off-the-shelf models into one student model without such
constraints. Specifically, we propose a dedicated voting mechanism to capture
the consensus of knowledge both at the logit level -- incorporating teacher
models that are capable of predicting target classes of interest -- and at the
feature level, utilizing visual representations learned on arbitrary label
spaces. Extensive experiments demonstrate that UNIFORM effectively enhances
unsupervised object recognition performance compared to strong knowledge
transfer baselines. Notably, it exhibits remarkable scalability by benefiting
from over one hundred teachers, while existing methods saturate at a much
smaller scale.

</details>


### [19] [Sat2Flow: A Structure-Aware Diffusion Framework for Human Flow Generation from Satellite Imagery](https://arxiv.org/abs/2508.19499)
*Xiangxu Wang,Tianhong Zhao,Wei Tu,Bowen Zhang,Guanzhou Chen,Jinzhou Cao*

Main category: cs.CV

TL;DR: Sat2Flow是一种基于扩散的框架，仅使用卫星图像生成OD流量矩阵，解决了现有方法依赖辅助数据和空间拓扑敏感性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖昂贵且覆盖有限的辅助数据，并对空间拓扑敏感，Sat2Flow旨在解决这些问题。

Method: Sat2Flow采用多核编码器捕捉区域交互，并通过置换感知扩散过程确保结构一致性。

Result: 实验表明，Sat2Flow在数值准确性上优于基线方法，并在区域重排序时保持结构和分布一致性。

Conclusion: Sat2Flow为数据稀缺环境提供了一种可扩展的解决方案，消除了对辅助数据的依赖并保持结构不变性。

Abstract: Origin-Destination (OD) flow matrices are essential for urban mobility
analysis, underpinning applications in traffic forecasting, infrastructure
planning, and policy design. However, existing methods suffer from two critical
limitations: (1) reliance on auxiliary features (e.g., Points of Interest,
socioeconomic statistics) that are costly to collect and have limited spatial
coverage; and (2) sensitivity to spatial topology, where minor index reordering
of urban regions (e.g., census tract relabeling) disrupts structural coherence
in generated flows. To address these challenges, we propose Sat2Flow, a latent
structure-aware diffusion-based framework that generates structurally coherent
OD flows using solely satellite imagery as input. Our approach introduces a
multi-kernel encoder to capture diverse regional interactions and employs a
permutation-aware diffusion process that aligns latent representations across
different regional orderings. Through a joint contrastive training objective
that bridges satellite-derived features with OD patterns, combined with
equivariant diffusion training that enforces structural consistency, Sat2Flow
ensures topological robustness under arbitrary regional reindexing.
Experimental results on real-world urban datasets demonstrate that Sat2Flow
outperforms both physics-based and data-driven baselines in numerical accuracy
while preserving empirical distributions and spatial structures under index
permutations. Sat2Flow offers a globally scalable solution for OD flow
generation in data-scarce urban environments, eliminating region-specific
auxiliary data dependencies while maintaining structural invariance for robust
mobility modeling.

</details>


### [20] [Weed Detection in Challenging Field Conditions: A Semi-Supervised Framework for Overcoming Shadow Bias and Data Scarcity](https://arxiv.org/abs/2508.19511)
*Alzayat Saleh,Shunsuke Hatano,Mostafa Rahimi Azghadi*

Main category: cs.CV

TL;DR: 提出了一种半监督框架，通过诊断驱动的伪标签方法解决农业杂草检测中的环境挑战和数据标注成本问题。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习模型在真实农田中因环境挑战和高标注成本导致的性能下降问题。

Method: 使用带标签和无标签的Guinea Grass图像数据集，结合ResNet、YOLO和RF-DETR模型，通过伪标签增强模型鲁棒性。

Result: 在分类和检测任务中分别达到F1分数0.90和mAP50超过0.82，有效缓解了阴影偏差并提高了召回率。

Conclusion: 提供了一种可应用于精准农业的计算机视觉系统开发框架，通过半监督方法提升模型在复杂环境中的表现。

Abstract: The automated management of invasive weeds is critical for sustainable
agriculture, yet the performance of deep learning models in real-world fields
is often compromised by two factors: challenging environmental conditions and
the high cost of data annotation. This study tackles both issues through a
diagnostic-driven, semi-supervised framework. Using a unique dataset of
approximately 975 labeled and 10,000 unlabeled images of Guinea Grass in
sugarcane, we first establish strong supervised baselines for classification
(ResNet) and detection (YOLO, RF-DETR), achieving F1 scores up to 0.90 and
mAP50 scores exceeding 0.82. Crucially, this foundational analysis, aided by
interpretability tools, uncovered a pervasive "shadow bias," where models
learned to misidentify shadows as vegetation. This diagnostic insight motivated
our primary contribution: a semi-supervised pipeline that leverages unlabeled
data to enhance model robustness. By training models on a more diverse set of
visual information through pseudo-labeling, this framework not only helps
mitigate the shadow bias but also provides a tangible boost in recall, a
critical metric for minimizing weed escapes in automated spraying systems. To
validate our methodology, we demonstrate its effectiveness in a low-data regime
on a public crop-weed benchmark. Our work provides a clear and field-tested
framework for developing, diagnosing, and improving robust computer vision
systems for the complex realities of precision agriculture.

</details>


### [21] [MotionFlux: Efficient Text-Guided Motion Generation through Rectified Flow Matching and Preference Alignment](https://arxiv.org/abs/2508.19527)
*Zhiting Gao,Dan Song,Diqiong Jiang,Chao Xue,An-An Liu*

Main category: cs.CV

TL;DR: TAPO和MotionFLUX框架解决了文本驱动运动生成中的语义对齐和实时性问题，提升了生成质量和速度。


<details>
  <summary>Details</summary>
Motivation: 现有文本驱动方法在运动语义与语言描述的精确对齐及多步推理效率上存在不足。

Method: 提出TAPO框架优化语义对齐，MotionFLUX基于确定性整流流匹配实现实时生成。

Result: 实验表明，系统在语义一致性和运动质量上优于现有方法，且加速了生成速度。

Conclusion: TAPO与MotionFLUX结合形成高效统一的运动生成系统，代码和模型将开源。

Abstract: Motion generation is essential for animating virtual characters and embodied
agents. While recent text-driven methods have made significant strides, they
often struggle with achieving precise alignment between linguistic descriptions
and motion semantics, as well as with the inefficiencies of slow, multi-step
inference. To address these issues, we introduce TMR++ Aligned Preference
Optimization (TAPO), an innovative framework that aligns subtle motion
variations with textual modifiers and incorporates iterative adjustments to
reinforce semantic grounding. To further enable real-time synthesis, we propose
MotionFLUX, a high-speed generation framework based on deterministic rectified
flow matching. Unlike traditional diffusion models, which require hundreds of
denoising steps, MotionFLUX constructs optimal transport paths between noise
distributions and motion spaces, facilitating real-time synthesis. The
linearized probability paths reduce the need for multi-step sampling typical of
sequential methods, significantly accelerating inference time without
sacrificing motion quality. Experimental results demonstrate that, together,
TAPO and MotionFLUX form a unified system that outperforms state-of-the-art
approaches in both semantic consistency and motion quality, while also
accelerating generation speed. The code and pretrained models will be released.

</details>


### [22] [Discrete Diffusion VLA: Bringing Discrete Diffusion to Action Decoding in Vision-Language-Action Policies](https://arxiv.org/abs/2508.20072)
*Zhixuan Liang,Yizhuo Li,Tianshuo Yang,Chengyue Wu,Sitong Mao,Liuao Pei,Xiaokang Yang,Jiangmiao Pang,Yao Mu,Ping Luo*

Main category: cs.CV

TL;DR: 论文提出了一种基于离散扩散的视觉-语言-动作（VLA）模型，通过统一架构解决了现有方法在训练和解码效率上的问题。


<details>
  <summary>Details</summary>
Motivation: 现有VLA解码器要么采用固定的自回归顺序生成动作，要么依赖连续扩散或流匹配方法，导致训练复杂且效率低下。

Method: 提出Discrete Diffusion VLA，使用离散扩散建模离散化动作块，并与VLM主干共享交叉熵目标，支持并行解码和渐进式优化。

Result: 在LIBERO、SimplerEnv Fractal和SimplerEnv Bridge数据集上分别达到96.3%、71.2%和49.3%的性能，优于自回归和连续扩散基线。

Conclusion: 离散扩散动作解码器支持精确动作建模和一致性训练，为VLA模型的扩展奠定了基础。

Abstract: Vision-Language-Action (VLA) models adapt large vision-language backbones to
map images and instructions to robot actions. However, prevailing VLA decoders
either generate actions autoregressively in a fixed left-to-right order or
attach continuous diffusion or flow matching heads outside the backbone,
demanding specialized training and iterative sampling that hinder a unified,
scalable architecture. We present Discrete Diffusion VLA, a single-transformer
policy that models discretized action chunks with discrete diffusion and is
trained with the same cross-entropy objective as the VLM backbone. The design
retains diffusion's progressive refinement paradigm while remaining natively
compatible with the discrete token interface of VLMs. Our method achieves an
adaptive decoding order that resolves easy action elements before harder ones
and uses secondary remasking to revisit uncertain predictions across refinement
rounds, which improves consistency and enables robust error correction. This
unified decoder preserves pretrained vision language priors, supports parallel
decoding, breaks the autoregressive bottleneck, and reduces the number of
function evaluations. Discrete Diffusion VLA achieves 96.3% avg. SR on LIBERO,
71.2% visual matching on SimplerEnv Fractal and 49.3% overall on SimplerEnv
Bridge, improving over both autoregressive and continuous diffusion baselines.
These findings indicate that discrete-diffusion action decoder supports precise
action modeling and consistent training, laying groundwork for scaling VLA to
larger models and datasets.

</details>


### [23] [CVBench: Evaluating Cross-Video Synergies for Complex Multimodal Understanding and Reasoning](https://arxiv.org/abs/2508.19542)
*Nannan Zhu,Yonghao Dong,Teng Wang,Xueqian Li,Shengjun Deng,Yijia Wang,Zheng Hong,Tiantian Geng,Guo Niu,Hanyan Huang,Xiongfei Yao,Shuaiwei Jiao*

Main category: cs.CV

TL;DR: CVBench是首个评估跨视频关系推理能力的综合基准，包含1000个问题-答案对，覆盖三个层次的任务。评估显示当前MLLMs在多视频推理中存在显著性能差距。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在单视频任务中表现优异，但在跨视频推理能力方面研究不足，而这一能力对实际应用（如多摄像头监控）至关重要。

Method: 构建CVBench基准，包含三个层次的任务（对象关联、事件关联、复杂推理），并评估10+领先MLLMs在零样本或思维链提示下的表现。

Result: 顶级模型（如GPT-4o）在因果推理任务中仅达到60%准确率，远低于人类的91%。当前MLLMs存在跨视频上下文保留不足和实体消歧能力差的问题。

Conclusion: CVBench为诊断和改进多视频推理提供了严格框架，并为下一代MLLMs的架构设计提供了见解。

Abstract: While multimodal large language models (MLLMs) exhibit strong performance on
single-video tasks (e.g., video question answering), their ability across
multiple videos remains critically underexplored. However, this capability is
essential for real-world applications, including multi-camera surveillance and
cross-video procedural learning. To bridge this gap, we present CVBench, the
first comprehensive benchmark designed to assess cross-video relational
reasoning rigorously. CVBench comprises 1,000 question-answer pairs spanning
three hierarchical tiers: cross-video object association (identifying shared
entities), cross-video event association (linking temporal or causal event
chains), and cross-video complex reasoning (integrating commonsense and domain
knowledge). Built from five domain-diverse video clusters (e.g., sports, life
records), the benchmark challenges models to synthesise information across
dynamic visual contexts. Extensive evaluation of 10+ leading MLLMs (including
GPT-4o, Gemini-2.0-flash, Qwen2.5-VL) under zero-shot or chain-of-thought
prompting paradigms. Key findings reveal stark performance gaps: even top
models, such as GPT-4o, achieve only 60% accuracy on causal reasoning tasks,
compared to the 91% accuracy of human performance. Crucially, our analysis
reveals fundamental bottlenecks inherent in current MLLM architectures, notably
deficient inter-video context retention and poor disambiguation of overlapping
entities. CVBench establishes a rigorous framework for diagnosing and advancing
multi-video reasoning, offering architectural insights for next-generation
MLLMs.The data and evaluation code are available at
https://github.com/Hokhim2/CVBench.

</details>


### [24] [WEBEYETRACK: Scalable Eye-Tracking for the Browser via On-Device Few-Shot Personalization](https://arxiv.org/abs/2508.19544)
*Eduardo Davalos,Yike Zhang,Namrata Srivastava,Yashvitha Thatigotla,Jorge A. Salas,Sara McFadden,Sun-Joo Cho,Amanda Goodwin,Ashwin TS,Gautam Biswas*

Main category: cs.CV

TL;DR: WebEyeTrack是一个浏览器集成的轻量级注视估计框架，结合头部姿态估计和少量样本学习，实现了实时高性能注视追踪。


<details>
  <summary>Details</summary>
Motivation: 现有AI注视估计方法在真实应用中与商业眼动追踪方案存在差距，且模型大小、推理时间和隐私问题常被忽视。

Method: 集成轻量级SOTA注视估计模型，结合头部姿态估计和少量样本学习（k < 9）。

Result: 在GazeCapture上误差为2.32 cm，iPhone 14上推理速度为2.4毫秒。

Conclusion: WebEyeTrack在性能和实用性上填补了现有方法的不足，适合实际应用。

Abstract: With advancements in AI, new gaze estimation methods are exceeding
state-of-the-art (SOTA) benchmarks, but their real-world application reveals a
gap with commercial eye-tracking solutions. Factors like model size, inference
time, and privacy often go unaddressed. Meanwhile, webcam-based eye-tracking
methods lack sufficient accuracy, in particular due to head movement. To tackle
these issues, we introduce We bEyeTrack, a framework that integrates
lightweight SOTA gaze estimation models directly in the browser. It
incorporates model-based head pose estimation and on-device few-shot learning
with as few as nine calibration samples (k < 9). WebEyeTrack adapts to new
users, achieving SOTA performance with an error margin of 2.32 cm on
GazeCapture and real-time inference speeds of 2.4 milliseconds on an iPhone 14.
Our open-source code is available at
https://github.com/RedForestAi/WebEyeTrack.

</details>


### [25] [MonoRelief V2: Leveraging Real Data for High-Fidelity Monocular Relief Recovery](https://arxiv.org/abs/2508.19555)
*Yu-Wei Zhang,Tongju Han,Lipeng Gao,Mingqiang Wei,Hui Liu,Changbao Li,Caiming Zhang*

Main category: cs.CV

TL;DR: MonoRelief V2是一个端到端模型，用于从单张图像中直接恢复2.5D浮雕，具有更高的鲁棒性、准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决在复杂材料和光照变化下从单张图像恢复2.5D浮雕的挑战，并改进前代模型仅依赖合成数据的局限性。

Method: 结合伪真实图像（通过文本生成模型生成）和小规模真实数据集（通过多视角重建和细节优化），逐步训练模型。

Result: 在深度和法线预测方面表现出色，达到最先进水平。

Conclusion: MonoRelief V2在多种下游应用中具有强大潜力。

Abstract: This paper presents MonoRelief V2, an end-to-end model designed for directly
recovering 2.5D reliefs from single images under complex material and
illumination variations. In contrast to its predecessor, MonoRelief V1 [1],
which was solely trained on synthetic data, MonoRelief V2 incorporates real
data to achieve improved robustness, accuracy and efficiency. To overcome the
challenge of acquiring large-scale real-world dataset, we generate
approximately 15,000 pseudo real images using a text-to-image generative model,
and derive corresponding depth pseudo-labels through fusion of depth and normal
predictions. Furthermore, we construct a small-scale real-world dataset (800
samples) via multi-view reconstruction and detail refinement. MonoRelief V2 is
then progressively trained on the pseudo-real and real-world datasets.
Comprehensive experiments demonstrate its state-of-the-art performance both in
depth and normal predictions, highlighting its strong potential for a range of
downstream applications. Code is at: https://github.com/glp1001/MonoreliefV2.

</details>


### [26] [FlowDet: Overcoming Perspective and Scale Challenges in Real-Time End-to-End Traffic Detection](https://arxiv.org/abs/2508.19565)
*Yuhang Zhao,Zixing Wang*

Main category: cs.CV

TL;DR: FlowDet是一种基于DETR架构的高效端到端目标检测器，通过几何可变形单元和尺度感知注意力模块优化，显著提升了复杂交通场景下的检测性能。


<details>
  <summary>Details</summary>
Motivation: 解决端到端目标检测器在复杂场景（如交通监控）中计算成本高的问题。

Method: 提出FlowDet，采用解耦编码器优化策略，结合几何可变形单元（GDU）和尺度感知注意力模块（SAA）。

Result: 在Intersection-Flow-5k数据集上，FlowDet在AP和AP50上分别提升1.5%和1.6%，同时减少63.2%的计算量和提高16.2%的推理速度。

Conclusion: FlowDet为高效且精确的实时感知系统提供了新思路，并在复杂场景中表现优异。

Abstract: End-to-end object detectors offer a promising NMS-free paradigm for real-time
applications, yet their high computational cost remains a significant barrier,
particularly for complex scenarios like intersection traffic monitoring. To
address this challenge, we propose FlowDet, a high-speed detector featuring a
decoupled encoder optimization strategy applied to the DETR architecture.
Specifically, FlowDet employs a novel Geometric Deformable Unit (GDU) for
traffic-aware geometric modeling and a Scale-Aware Attention (SAA) module to
maintain high representational power across extreme scale variations. To
rigorously evaluate the model's performance in environments with severe
occlusion and high object density, we collected the Intersection-Flow-5k
dataset, a new challenging scene for this task. Evaluated on
Intersection-Flow-5k, FlowDet establishes a new state-of-the-art. Compared to
the strong RT-DETR baseline, it improves AP(test) by 1.5% and AP50(test) by
1.6%, while simultaneously reducing GFLOPs by 63.2% and increasing inference
speed by 16.2%. Our work demonstrates a new path towards building highly
efficient and accurate detectors for demanding, real-world perception systems.
The Intersection-Flow-5k dataset is available at
https://github.com/AstronZh/Intersection-Flow-5K.

</details>


### [27] [DNP-Guided Contrastive Reconstruction with a Reverse Distillation Transformer for Medical Anomaly Detection](https://arxiv.org/abs/2508.19573)
*Luhu Li,Bowen Lin,Mukhtiar Khan,Shujun Fu*

Main category: cs.CV

TL;DR: 提出了一种结合可训练编码器和原型引导重建的统一框架，通过多样性感知对齐损失解决原型崩溃问题，显著提升了医学图像异常检测的性能。


<details>
  <summary>Details</summary>
Motivation: 医学图像异常检测面临标注有限和与自然图像的领域差距问题，现有方法依赖预训练编码器，限制了领域适应性和定位准确性。

Method: 结合可训练编码器（含动量分支）和原型提取器，通过注意力机制引导重建，并引入多样性感知对齐损失防止原型崩溃。

Result: 在多个医学图像基准测试中表现优异，提升了表示质量和异常定位能力。

Conclusion: 框架有效解决了原型崩溃问题，增强了可解释性和性能。

Abstract: Anomaly detection in medical images is challenging due to limited annotations
and a domain gap compared to natural images. Existing reconstruction methods
often rely on frozen pre-trained encoders, which limits adaptation to
domain-specific features and reduces localization accuracy. Prototype-based
learning offers interpretability and clustering benefits but suffers from
prototype collapse, where few prototypes dominate training, harming diversity
and generalization. To address this, we propose a unified framework combining a
trainable encoder with prototype-guided reconstruction and a novel
Diversity-Aware Alignment Loss. The trainable encoder, enhanced by a momentum
branch, enables stable domain-adaptive feature learning. A lightweight
Prototype Extractor mines informative normal prototypes to guide the decoder
via attention for precise reconstruction. Our loss enforces balanced prototype
use through diversity constraints and per-prototype normalization, effectively
preventing collapse. Experiments on multiple medical imaging benchmarks show
significant improvements in representation quality and anomaly localization,
outperforming prior methods. Visualizations and prototype assignment analyses
further validate the effectiveness of our anti-collapse mechanism and enhanced
interpretability.

</details>


### [28] [Multimodal Prototype Alignment for Semi-supervised Pathology Image Segmentation](https://arxiv.org/abs/2508.19574)
*Mingxi Fu,Fanglei Fu,Xitong Ling,Huaitian Yuan,Tian Guan,Yonghong He,Lianghui Zhu*

Main category: cs.CV

TL;DR: MPAMatch提出了一种基于多模态原型引导监督的像素级对比学习框架，显著提升了病理图像分割的语义边界建模能力。


<details>
  <summary>Details</summary>
Motivation: 解决病理图像分割中语义边界模糊和像素级标注成本高的问题，现有方法难以捕捉高级语义先验。

Method: 通过图像原型与像素标签、文本原型与像素标签的双重对比学习，结合病理预训练模型改进分割架构。

Result: 在多个数据集上优于现有方法，验证了其在结构和语义建模上的双重优势。

Conclusion: MPAMatch通过多模态原型监督和架构改进，显著提升了病理图像分割的性能。

Abstract: Pathological image segmentation faces numerous challenges, particularly due
to ambiguous semantic boundaries and the high cost of pixel-level annotations.
Although recent semi-supervised methods based on consistency regularization
(e.g., UniMatch) have made notable progress, they mainly rely on
perturbation-based consistency within the image modality, making it difficult
to capture high-level semantic priors, especially in structurally complex
pathology images. To address these limitations, we propose MPAMatch - a novel
segmentation framework that performs pixel-level contrastive learning under a
multimodal prototype-guided supervision paradigm. The core innovation of
MPAMatch lies in the dual contrastive learning scheme between image prototypes
and pixel labels, and between text prototypes and pixel labels, providing
supervision at both structural and semantic levels. This coarse-to-fine
supervisory strategy not only enhances the discriminative capability on
unlabeled samples but also introduces the text prototype supervision into
segmentation for the first time, significantly improving semantic boundary
modeling. In addition, we reconstruct the classic segmentation architecture
(TransUNet) by replacing its ViT backbone with a pathology-pretrained
foundation model (Uni), enabling more effective extraction of
pathology-relevant features. Extensive experiments on GLAS, EBHI-SEG-GLAND,
EBHI-SEG-CANCER, and KPI show MPAMatch's superiority over state-of-the-art
methods, validating its dual advantages in structural and semantic modeling.

</details>


### [29] [Interact-Custom: Customized Human Object Interaction Image Generation](https://arxiv.org/abs/2508.19575)
*Zhu Xu,Zhaowen Wang,Yuxin Peng,Yang Liu*

Main category: cs.CV

TL;DR: 论文提出了一种定制化人机交互图像生成任务（CHOI），通过两阶段模型Interact-Custom解决身份保持与交互控制的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注目标实体的外观保持，而忽略了目标实体之间的细粒度交互控制。

Method: 设计了两阶段模型Interact-Custom，首先生成描述交互行为的前景掩码，然后在掩码指导下生成目标人机交互图像。

Result: 实验表明，该方法在CHOI任务上有效。

Conclusion: Interact-Custom能够同时实现身份保持和交互语义控制，提供高内容可控性。

Abstract: Compositional Customized Image Generation aims to customize multiple target
concepts within generation content, which has gained attention for its wild
application.Existing approaches mainly concentrate on the target entity's
appearance preservation, while neglecting the fine-grained interaction control
among target entities.To enable the model of such interaction control
capability, we focus on human object interaction scenario and propose the task
of Customized Human Object Interaction Image Generation(CHOI), which
simultaneously requires identity preservation for target human object and the
interaction semantic control between them.Two primary challenges exist for
CHOI:(1)simultaneous identity preservation and interaction control demands
require the model to decompose the human object into self-contained identity
features and pose-oriented interaction features, while the current HOI image
datasets fail to provide ideal samples for such feature-decomposed
learning.(2)inappropriate spatial configuration between human and object may
lead to the lack of desired interaction semantics.To tackle it, we first
process a large-scale dataset, where each sample encompasses the same pair of
human object involving different interactive poses.Then we design a two-stage
model Interact-Custom, which firstly explicitly models the spatial
configuration by generating a foreground mask depicting the interaction
behavior, then under the guidance of this mask, we generate the target human
object interacting while preserving their identities features.Furthermore, if
the background image and the union location of where the target human object
should appear are provided by users, Interact-Custom also provides the optional
functionality to specify them, offering high content controllability. Extensive
experiments on our tailored metrics for CHOI task demonstrate the effectiveness
of our approach.

</details>


### [30] [High-Speed FHD Full-Color Video Computer-Generated Holography](https://arxiv.org/abs/2508.19579)
*Haomiao Zhang,Miao Cao,Xuan Yu,Hui Luo,Yanling Piao,Mengjie Qin,Zhangyuan Li,Ping Wang,Xin Yuan*

Main category: cs.CV

TL;DR: 提出了一种新型高速全息视频生成方案，结合频谱引导深度分割复用（SGDDM）和轻量级HoloMamba架构，解决了高帧率全息显示中的颜色串扰和计算效率问题。


<details>
  <summary>Details</summary>
Motivation: 高帧率全息视频生成面临颜色串扰和计算效率低的挑战，现有方法无法兼顾帧率和颜色保真度。

Method: 1. 引入SGDDM通过频率调制优化相位分布；2. 提出HoloMamba架构，显式建模时空相关性。

Result: SGDDM实现高保真全彩显示，HoloMamba以260 FPS生成1080p全息视频，速度提升2.6倍。

Conclusion: 该方案显著提升了全息视频的生成速度和质量，为下一代显示技术提供了可行解决方案。

Abstract: Computer-generated holography (CGH) is a promising technology for
next-generation displays. However, generating high-speed, high-quality
holographic video requires both high frame rate display and efficient
computation, but is constrained by two key limitations: ($i$) Learning-based
models often produce over-smoothed phases with narrow angular spectra, causing
severe color crosstalk in high frame rate full-color displays such as
depth-division multiplexing and thus resulting in a trade-off between frame
rate and color fidelity. ($ii$) Existing frame-by-frame optimization methods
typically optimize frames independently, neglecting spatial-temporal
correlations between consecutive frames and leading to computationally
inefficient solutions. To overcome these challenges, in this paper, we propose
a novel high-speed full-color video CGH generation scheme. First, we introduce
Spectrum-Guided Depth Division Multiplexing (SGDDM), which optimizes phase
distributions via frequency modulation, enabling high-fidelity full-color
display at high frame rates. Second, we present HoloMamba, a lightweight
asymmetric Mamba-Unet architecture that explicitly models spatial-temporal
correlations across video sequences to enhance reconstruction quality and
computational efficiency. Extensive simulated and real-world experiments
demonstrate that SGDDM achieves high-fidelity full-color display without
compromise in frame rate, while HoloMamba generates FHD (1080p) full-color
holographic video at over 260 FPS, more than 2.6$\times$ faster than the prior
state-of-the-art Divide-Conquer-and-Merge Strategy.

</details>


### [31] [Guiding Noisy Label Conditional Diffusion Models with Score-based Discriminator Correction](https://arxiv.org/abs/2508.19581)
*Dat Nguyen Cong,Hieu Tran Bao,Hoang Thanh-Tung*

Main category: cs.CV

TL;DR: 论文提出了一种基于判别器校正的引导技术（SBDC），用于对齐预训练的条件扩散模型，以解决数据标签错误对生成能力的影响。


<details>
  <summary>Details</summary>
Motivation: 大规模数据集中常见手动标签错误，但此类错误对扩散模型生成能力和可控性的影响尚未充分研究。

Method: 提出Score-based Discriminator Correction（SBDC），利用对抗性损失的判别器训练，结合噪声检测技术评估样本真实性，并限制引导使用于生成早期阶段。

Result: 实验表明，该方法在不同噪声设置下优于现有技术，计算高效且几乎不增加推理时间。

Conclusion: SBDC是一种高效且无需重新训练扩散模型的解决方案，显著提升了生成质量和可控性。

Abstract: Diffusion models have gained prominence as state-of-the-art techniques for
synthesizing images and videos, particularly due to their ability to scale
effectively with large datasets. Recent studies have uncovered that these
extensive datasets often contain mistakes from manual labeling processes.
However, the extent to which such errors compromise the generative capabilities
and controllability of diffusion models is not well studied. This paper
introduces Score-based Discriminator Correction (SBDC), a guidance technique
for aligning noisy pre-trained conditional diffusion models. The guidance is
built on discriminator training using adversarial loss, drawing on prior noise
detection techniques to assess the authenticity of each sample. We further show
that limiting the usage of our guidance to the early phase of the generation
process leads to better performance. Our method is computationally efficient,
only marginally increases inference time, and does not require retraining
diffusion models. Experiments on different noise settings demonstrate the
superiority of our method over previous state-of-the-art methods.

</details>


### [32] [Generalizing Monocular 3D Object Detection](https://arxiv.org/abs/2508.19593)
*Abhinav Kumar*

Main category: cs.CV

TL;DR: 该论文提出了一系列方法（GrooMeD-NMS、DEVIANT、SeaBird）来提升单目3D目标检测模型在遮挡、数据集、大物体和相机参数变化等多样化场景中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 单目3D目标检测在自动驾驶等领域至关重要，但现有模型在遮挡、数据集差异、大物体检测和相机参数变化等场景中泛化能力不足。

Method: 1. 提出GrooMeD-NMS增强遮挡鲁棒性；2. 探索DEVIANT主干网络提升数据集泛化性；3. 引入SeaBird方法（基于分割和Dice损失）解决大物体检测问题；4. 分析并改进模型对相机高度变化的适应性。

Result: 所提方法在多样化场景中显著提升了单目3D目标检测的泛化性能。

Conclusion: 通过数学分析和创新方法，论文有效解决了单目3D目标检测在复杂场景中的泛化挑战。

Abstract: Monocular 3D object detection (Mono3D) is a fundamental computer vision task
that estimates an object's class, 3D position, dimensions, and orientation from
a single image. Its applications, including autonomous driving, augmented
reality, and robotics, critically rely on accurate 3D environmental
understanding. This thesis addresses the challenge of generalizing Mono3D
models to diverse scenarios, including occlusions, datasets, object sizes, and
camera parameters. To enhance occlusion robustness, we propose a mathematically
differentiable NMS (GrooMeD-NMS). To improve generalization to new datasets, we
explore depth equivariant (DEVIANT) backbones. We address the issue of large
object detection, demonstrating that it's not solely a data imbalance or
receptive field problem but also a noise sensitivity issue. To mitigate this,
we introduce a segmentation-based approach in bird's-eye view with dice loss
(SeaBird). Finally, we mathematically analyze the extrapolation of Mono3D
models to unseen camera heights and improve Mono3D generalization in such
out-of-distribution settings.

</details>


### [33] [Quantization Robustness to Input Degradations for Object Detection](https://arxiv.org/abs/2508.19600)
*Toghrul Karimov,Hassan Imani,Allan Kazakov*

Main category: cs.CV

TL;DR: 该论文研究了后训练量化（PTQ）对YOLO模型在多种精度格式下的鲁棒性影响，并提出了一种退化感知校准策略，但效果有限。


<details>
  <summary>Details</summary>
Motivation: 研究量化对模型在真实世界输入退化（如噪声、模糊等）下的鲁棒性影响，以优化资源受限设备上的部署。

Method: 通过在不同精度格式（FP32、FP16、Dynamic UINT8、Static INT8）下评估YOLO模型，并引入退化感知校准策略。

Result: Static INT8在干净数据上表现良好，但退化感知校准仅在特定噪声条件下对较大模型有效。

Conclusion: 增强PTQ鲁棒性具有挑战性，研究结果为在不可控环境中部署量化检测器提供了参考。

Abstract: Post-training quantization (PTQ) is crucial for deploying efficient object
detection models, like YOLO, on resource-constrained devices. However, the
impact of reduced precision on model robustness to real-world input
degradations such as noise, blur, and compression artifacts is a significant
concern. This paper presents a comprehensive empirical study evaluating the
robustness of YOLO models (nano to extra-large scales) across multiple
precision formats: FP32, FP16 (TensorRT), Dynamic UINT8 (ONNX), and Static INT8
(TensorRT). We introduce and evaluate a degradation-aware calibration strategy
for Static INT8 PTQ, where the TensorRT calibration process is exposed to a mix
of clean and synthetically degraded images. Models were benchmarked on the COCO
dataset under seven distinct degradation conditions (including various types
and levels of noise, blur, low contrast, and JPEG compression) and a
mixed-degradation scenario. Results indicate that while Static INT8 TensorRT
engines offer substantial speedups (~1.5-3.3x) with a moderate accuracy drop
(~3-7% mAP50-95) on clean data, the proposed degradation-aware calibration did
not yield consistent, broad improvements in robustness over standard clean-data
calibration across most models and degradations. A notable exception was
observed for larger model scales under specific noise conditions, suggesting
model capacity may influence the efficacy of this calibration approach. These
findings highlight the challenges in enhancing PTQ robustness and provide
insights for deploying quantized detectors in uncontrolled environments. All
code and evaluation tables are available at https://github.com/AllanK24/QRID.

</details>


### [34] [IELDG: Suppressing Domain-Specific Noise with Inverse Evolution Layers for Domain Generalized Semantic Segmentation](https://arxiv.org/abs/2508.19604)
*Qizhe Fan,Chaoyu Liu,Zhonghua Qiao,Xiaoqin Shen*

Main category: cs.CV

TL;DR: 论文提出了一种结合逆演化层（IELs）和多尺度频率融合（MFF）的方法，用于提升域广义语义分割（DGSS）的性能，通过改进生成图像质量和抑制缺陷传播来增强模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用扩散模型生成合成数据增强源域，但生成的图像存在结构或语义缺陷，导致分割模型性能下降。

Method: 提出IELDM框架，通过IELs过滤生成图像中的缺陷；并将IELs嵌入分割网络（IELFormer），结合MFF模块提升跨域一致性。

Result: 在基准数据集上，该方法显著优于现有方法，表现出更强的泛化性能。

Conclusion: IELs和MFF的结合有效提升了DGSS模型的跨域泛化能力，为数据增强和分割网络设计提供了新思路。

Abstract: Domain Generalized Semantic Segmentation (DGSS) focuses on training a model
using labeled data from a source domain, with the goal of achieving robust
generalization to unseen target domains during inference. A common approach to
improve generalization is to augment the source domain with synthetic data
generated by diffusion models (DMs). However, the generated images often
contain structural or semantic defects due to training imperfections. Training
segmentation models with such flawed data can lead to performance degradation
and error accumulation. To address this issue, we propose to integrate inverse
evolution layers (IELs) into the generative process. IELs are designed to
highlight spatial discontinuities and semantic inconsistencies using
Laplacian-based priors, enabling more effective filtering of undesirable
generative patterns. Based on this mechanism, we introduce IELDM, an enhanced
diffusion-based data augmentation framework that can produce higher-quality
images. Furthermore, we observe that the defect-suppression capability of IELs
can also benefit the segmentation network by suppressing artifact propagation.
Based on this insight, we embed IELs into the decoder of the DGSS model and
propose IELFormer to strengthen generalization capability in cross-domain
scenarios. To further strengthen the model's semantic consistency across
scales, IELFormer incorporates a multi-scale frequency fusion (MFF) module,
which performs frequency-domain analysis to achieve structured integration of
multi-resolution features, thereby improving cross-scale coherence. Extensive
experiments on benchmark datasets demonstrate that our approach achieves
superior generalization performance compared to existing methods.

</details>


### [35] [Controllable Skin Synthesis via Lesion-Focused Vector Autoregression Model](https://arxiv.org/abs/2508.19626)
*Jiajun Sun,Zhen Yu,Siyuan Yan,Jason J. Ong,Zongyuan Ge,Lei Zhang*

Main category: cs.CV

TL;DR: LF-VAR模型通过量化病变评分和类型标签，实现可控的皮肤图像合成，生成高质量且临床相关的图像。


<details>
  <summary>Details</summary>
Motivation: 解决现有皮肤图像合成方法生成质量低、无法控制病变位置和类型的问题。

Method: 结合多尺度病变聚焦的VQVAE和VAR Transformer，利用语言提示和条件嵌入增强合成保真度。

Result: 在七种病变类型中取得最佳FID分数（平均0.74），比之前SOTA提升6.3%。

Conclusion: LF-VAR能有效生成高保真、临床相关的合成皮肤图像。

Abstract: Skin images from real-world clinical practice are often limited, resulting in
a shortage of training data for deep-learning models. While many studies have
explored skin image synthesis, existing methods often generate low-quality
images and lack control over the lesion's location and type. To address these
limitations, we present LF-VAR, a model leveraging quantified lesion
measurement scores and lesion type labels to guide the clinically relevant and
controllable synthesis of skin images. It enables controlled skin synthesis
with specific lesion characteristics based on language prompts. We train a
multiscale lesion-focused Vector Quantised Variational Auto-Encoder (VQVAE) to
encode images into discrete latent representations for structured tokenization.
Then, a Visual AutoRegressive (VAR) Transformer trained on tokenized
representations facilitates image synthesis. Lesion measurement from the lesion
region and types as conditional embeddings are integrated to enhance synthesis
fidelity. Our method achieves the best overall FID score (average 0.74) among
seven lesion types, improving upon the previous state-of-the-art (SOTA) by
6.3%. The study highlights our controllable skin synthesis model's
effectiveness in generating high-fidelity, clinically relevant synthetic skin
images. Our framework code is available at
https://github.com/echosun1996/LF-VAR.

</details>


### [36] [Divide, Weight, and Route: Difficulty-Aware Optimization with Dynamic Expert Fusion for Long-tailed Recognition](https://arxiv.org/abs/2508.19630)
*Xiaolei Wei,Yi Ouyang,Haibo Ye*

Main category: cs.CV

TL;DR: DQRoute是一个模块化框架，通过结合难度感知优化和动态专家协作，解决了长尾视觉识别中的类别不平衡和分类难度差异问题。


<details>
  <summary>Details</summary>
Motivation: 长尾视觉识别不仅面临类别不平衡问题，还因不同类别的分类难度差异而更具挑战性。传统的基于频率的类别加权方法往往忽略了那些本质上难以学习的类别。

Method: DQRoute首先基于预测不确定性和历史性能估计类别难度，并利用这一信号指导自适应损失加权训练。在架构上，采用混合专家设计，每个专家专注于类别分布的不同区域。推理时，通过专家特定的OOD检测器生成的置信度加权专家预测，实现无需集中路由器的输入自适应路由。

Result: 在标准长尾基准测试中，DQRoute显著提升了性能，尤其是在稀有和困难类别上。

Conclusion: DQRoute通过将难度建模与去中心化专家路由相结合，展示了其在长尾视觉识别中的优势。

Abstract: Long-tailed visual recognition is challenging not only due to class imbalance
but also because of varying classification difficulty across categories. Simply
reweighting classes by frequency often overlooks those that are intrinsically
hard to learn. To address this, we propose \textbf{DQRoute}, a modular
framework that combines difficulty-aware optimization with dynamic expert
collaboration. DQRoute first estimates class-wise difficulty based on
prediction uncertainty and historical performance, and uses this signal to
guide training with adaptive loss weighting. On the architectural side, DQRoute
employs a mixture-of-experts design, where each expert specializes in a
different region of the class distribution. At inference time, expert
predictions are weighted by confidence scores derived from expert-specific OOD
detectors, enabling input-adaptive routing without the need for a centralized
router. All components are trained jointly in an end-to-end manner. Experiments
on standard long-tailed benchmarks demonstrate that DQRoute significantly
improves performance, particularly on rare and difficult classes, highlighting
the benefit of integrating difficulty modeling with decentralized expert
routing.

</details>


### [37] [Beyond BEV: Optimizing Point-Level Tokens for Collaborative Perception](https://arxiv.org/abs/2508.19638)
*Yang Li,Quan Yuan,Guiyang Luo,Xiaoyuan Fu,Rui Pan,Yujia Yang,Congzhang Shao,Yuewen Liu,Jinglin Li*

Main category: cs.CV

TL;DR: CoPLOT提出了一种基于点级优化的协作感知框架，通过点原生处理流程提升感知能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常使用2D BEV表示，丢弃了关键的3D结构信息，影响识别和定位精度。

Method: 引入点级令牌，结合语义感知重排序、频率增强状态空间模型和多智能体空间对齐。

Result: 在模拟和真实数据集上优于现有方法，通信和计算开销更低。

Conclusion: CoPLOT通过点级优化令牌和高效处理流程，显著提升了协作感知性能。

Abstract: Collaborative perception allows agents to enhance their perceptual
capabilities by exchanging intermediate features. Existing methods typically
organize these intermediate features as 2D bird's-eye-view (BEV)
representations, which discard critical fine-grained 3D structural cues
essential for accurate object recognition and localization. To this end, we
first introduce point-level tokens as intermediate representations for
collaborative perception. However, point-cloud data are inherently unordered,
massive, and position-sensitive, making it challenging to produce compact and
aligned point-level token sequences that preserve detailed structural
information. Therefore, we present CoPLOT, a novel Collaborative perception
framework that utilizes Point-Level Optimized Tokens. It incorporates a
point-native processing pipeline, including token reordering, sequence
modeling, and multi-agent spatial alignment. A semantic-aware token reordering
module generates adaptive 1D reorderings by leveraging scene-level and
token-level semantic information. A frequency-enhanced state space model
captures long-range sequence dependencies across both spatial and spectral
domains, improving the differentiation between foreground tokens and background
clutter. Lastly, a neighbor-to-ego alignment module applies a closed-loop
process, combining global agent-level correction with local token-level
refinement to mitigate localization noise. Extensive experiments on both
simulated and real-world datasets show that CoPLOT outperforms state-of-the-art
models, with even lower communication and computation overhead. Code will be
available at https://github.com/CheeryLeeyy/CoPLOT.

</details>


### [38] [UTAL-GNN: Unsupervised Temporal Action Localization using Graph Neural Networks](https://arxiv.org/abs/2508.19647)
*Bikash Kumar Badatya,Vipul Baghel,Ravi Hegde*

Main category: cs.CV

TL;DR: 提出了一种轻量级无监督的骨架动作定位方法，通过时空图神经网络实现高效动作分析。


<details>
  <summary>Details</summary>
Motivation: 解决细粒度动作定位在未修剪体育视频中的挑战，避免依赖大量标注数据和高容量模型。

Method: 使用基于注意力的时空图卷积网络（ASTGCN）预训练，并通过动作动态度量（ADM）检测动作边界。

Result: 在DSV Diving数据集上达到82.66%的mAP和29.09 ms的定位延迟，性能接近监督方法。

Conclusion: 方法在未训练数据上表现鲁棒，适用于轻量级实时动作分析系统。

Abstract: Fine-grained action localization in untrimmed sports videos presents a
significant challenge due to rapid and subtle motion transitions over short
durations. Existing supervised and weakly supervised solutions often rely on
extensive annotated datasets and high-capacity models, making them
computationally intensive and less adaptable to real-world scenarios. In this
work, we introduce a lightweight and unsupervised skeleton-based action
localization pipeline that leverages spatio-temporal graph neural
representations. Our approach pre-trains an Attention-based Spatio-Temporal
Graph Convolutional Network (ASTGCN) on a pose-sequence denoising task with
blockwise partitions, enabling it to learn intrinsic motion dynamics without
any manual labeling. At inference, we define a novel Action Dynamics Metric
(ADM), computed directly from low-dimensional ASTGCN embeddings, which detects
motion boundaries by identifying inflection points in its curvature profile.
Our method achieves a mean Average Precision (mAP) of 82.66% and average
localization latency of 29.09 ms on the DSV Diving dataset, matching
state-of-the-art supervised performance while maintaining computational
efficiency. Furthermore, it generalizes robustly to unseen, in-the-wild diving
footage without retraining, demonstrating its practical applicability for
lightweight, real-time action analysis systems in embedded or dynamic
environments.

</details>


### [39] [IDF: Iterative Dynamic Filtering Networks for Generalizable Image Denoising](https://arxiv.org/abs/2508.19649)
*Dongjin Kim,Jaekyun Ko,Muhammad Kashif Ali,Tae Hyun Kim*

Main category: cs.CV

TL;DR: 论文提出了一种动态生成核的图像去噪方法，通过高效操作防止过拟合并提升对未知噪声的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法依赖特定噪声分布，泛化能力有限且易过拟合，需大量数据和计算资源。

Method: 利用特征提取模块、全局统计和局部相关模块捕获噪声特征，通过核预测模块生成像素级动态核进行迭代去噪。

Result: 紧凑模型（约0.04M）在多种噪声类型和级别上表现优异，展示了动态滤波的潜力。

Conclusion: 迭代动态滤波方法在图像去噪中兼具高效性和高质量恢复能力。

Abstract: Image denoising is a fundamental challenge in computer vision, with
applications in photography and medical imaging. While deep learning-based
methods have shown remarkable success, their reliance on specific noise
distributions limits generalization to unseen noise types and levels. Existing
approaches attempt to address this with extensive training data and high
computational resources but they still suffer from overfitting. To address
these issues, we conduct image denoising by utilizing dynamically generated
kernels via efficient operations. This approach helps prevent overfitting and
improves resilience to unseen noise. Specifically, our method leverages a
Feature Extraction Module for robust noise-invariant features, Global
Statistics and Local Correlation Modules to capture comprehensive noise
characteristics and structural correlations. The Kernel Prediction Module then
employs these cues to produce pixel-wise varying kernels adapted to local
structures, which are then applied iteratively for denoising. This ensures both
efficiency and superior restoration quality. Despite being trained on
single-level Gaussian noise, our compact model (~ 0.04 M) excels across diverse
noise types and levels, demonstrating the promise of iterative dynamic
filtering for practical image denoising.

</details>


### [40] [Video-LevelGauge: Investigating Contextual Positional Bias in Large Video Language Models](https://arxiv.org/abs/2508.19650)
*Hou Xia,Zheren Fu,Fangcan Ling,Jiajun Li,Yi Tu,Zhendong Mao,Yongdong Zhang*

Main category: cs.CV

TL;DR: Video-LevelGauge是一个专门用于评估大型视频语言模型（LVLMs）位置偏见的基准测试，通过标准化探针和定制化上下文设置，揭示了开源模型中的显著位置偏见，而商业模型表现更一致。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试通常评估整个视频序列的整体性能，忽略了位置偏见等细微行为，这是LVLM性能中关键但未被充分探索的方面。

Method: 采用标准化探针和定制化上下文设置，结合统计分析方法和形态模式识别，评估27种LVLMs的位置偏见。

Result: 许多领先的开源模型表现出显著的位置偏见（如头部或邻近内容偏好），而商业模型（如Gemini2.5-Pro）表现一致。

Conclusion: Video-LevelGauge为减轻偏见和指导模型增强提供了可行见解，强调了位置偏见评估的重要性。

Abstract: Large video language models (LVLMs) have made notable progress in video
understanding, spurring the development of corresponding evaluation benchmarks.
However, existing benchmarks generally assess overall performance across entire
video sequences, overlooking nuanced behaviors such as contextual positional
bias, a critical yet under-explored aspect of LVLM performance. We present
Video-LevelGauge, a dedicated benchmark designed to systematically assess
positional bias in LVLMs. We employ standardized probes and customized
contextual setups, allowing flexible control over context length, probe
position, and contextual types to simulate diverse real-world scenarios. In
addition, we introduce a comprehensive analysis method that combines
statistical measures with morphological pattern recognition to characterize
bias. Our benchmark comprises 438 manually curated videos spanning multiple
types, yielding 1,177 high-quality multiple-choice questions and 120 open-ended
questions, validated for their effectiveness in exposing positional bias. Based
on these, we evaluate 27 state-of-the-art LVLMs, including both commercial and
open-source models. Our findings reveal significant positional biases in many
leading open-source models, typically exhibiting head or neighbor-content
preferences. In contrast, commercial models such as Gemini2.5-Pro show
impressive, consistent performance across entire video sequences. Further
analyses on context length, context variation, and model scale provide
actionable insights for mitigating bias and guiding model enhancement.

</details>


### [41] [Scalable Object Detection in the Car Interior With Vision Foundation Models](https://arxiv.org/abs/2508.19651)
*Bálint Mészáros,Ahmet Firintepe,Sebastian Schmidt,Stephan Günnemann*

Main category: cs.CV

TL;DR: 提出了一种名为ODAL的分布式框架，用于解决车载系统资源受限下的物体检测与定位问题，通过结合云端与车载计算，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 车载系统的计算资源有限，难以直接运行大型视觉基础模型，因此需要一种高效的分布式解决方案。

Method: 采用分布式架构，结合云端与车载计算，并引入新的评估指标ODALbench。对轻量级模型LLaVA 1.5 7B进行微调，提升性能。

Result: 微调后的ODAL-LLaVA模型ODAL$_{score}$达到89%，比基线提升71%，且优于GPT-4o近20%。同时显著减少幻觉，ODAL$_{SNR}$是GPT-4o的三倍。

Conclusion: ODAL框架通过分布式设计和轻量级模型微调，在资源受限的车载环境中实现了高性能的物体检测与定位，为领域设定了新标准。

Abstract: AI tasks in the car interior like identifying and localizing externally
introduced objects is crucial for response quality of personal assistants.
However, computational resources of on-board systems remain highly constrained,
restricting the deployment of such solutions directly within the vehicle. To
address this limitation, we propose the novel Object Detection and Localization
(ODAL) framework for interior scene understanding. Our approach leverages
vision foundation models through a distributed architecture, splitting
computational tasks between on-board and cloud. This design overcomes the
resource constraints of running foundation models directly in the car. To
benchmark model performance, we introduce ODALbench, a new metric for
comprehensive assessment of detection and localization.Our analysis
demonstrates the framework's potential to establish new standards in this
domain. We compare the state-of-the-art GPT-4o vision foundation model with the
lightweight LLaVA 1.5 7B model and explore how fine-tuning enhances the
lightweight models performance. Remarkably, our fine-tuned ODAL-LLaVA model
achieves an ODAL$_{score}$ of 89%, representing a 71% improvement over its
baseline performance and outperforming GPT-4o by nearly 20%. Furthermore, the
fine-tuned model maintains high detection accuracy while significantly reducing
hallucinations, achieving an ODAL$_{SNR}$ three times higher than GPT-4o.

</details>


### [42] [Self-Rewarding Vision-Language Model via Reasoning Decomposition](https://arxiv.org/abs/2508.19652)
*Zongxia Li,Wenhao Yu,Chengsong Huang,Rui Liu,Zhenwen Liang,Fuxiao Liu,Jingxi Che,Dian Yu,Jordan Boyd-Graber,Haitao Mi,Dong Yu*

Main category: cs.CV

TL;DR: Vision-SR1通过自奖励方法增强视觉语言模型的视觉推理能力，减少幻觉和语言捷径。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLMs）存在视觉幻觉和语言捷径问题，传统方法依赖外部监督，成本高且易导致分布偏移。

Method: Vision-SR1将推理分为视觉感知和语言推理两阶段，通过自奖励机制强化视觉信号。

Result: 实验表明Vision-SR1提升了视觉推理能力，减少了幻觉和语言捷径。

Conclusion: Vision-SR1提供了一种无需外部监督的有效方法，显著改善了VLMs的视觉推理性能。

Abstract: Vision-Language Models (VLMs) often suffer from visual hallucinations, saying
things that are not actually in the image, and language shortcuts, where they
skip the visual part and just rely on text priors. These issues arise because
most post-training methods for VLMs rely on simple verifiable answer matching
and supervise only final outputs, leaving intermediate visual reasoning without
explicit guidance. As a result, VLMs receive sparse visual signals and often
learn to prioritize language-based reasoning over visual perception. To
mitigate this, some existing methods add visual supervision using human
annotations or distilled labels from external large models. However, human
annotations are labor-intensive and costly, and because external signals cannot
adapt to the evolving policy, they cause distributional shifts that can lead to
reward hacking. In this paper, we introduce Vision-SR1, a self-rewarding method
that improves visual reasoning without relying on external visual supervisions
via reinforcement learning. Vision-SR1 decomposes VLM reasoning into two
stages: visual perception and language reasoning. The model is first prompted
to produce self-contained visual perceptions that are sufficient to answer the
question without referring back the input image. To validate this
self-containment, the same VLM model is then re-prompted to perform language
reasoning using only the generated perception as input to compute reward. This
self-reward is combined with supervision on final outputs, providing a balanced
training signal that strengthens both visual perception and language reasoning.
Our experiments demonstrate that Vision-SR1 improves visual reasoning,
mitigates visual hallucinations, and reduces reliance on language shortcuts
across diverse vision-language tasks.

</details>


### [43] [Hardware-aware vs. Hardware-agnostic Energy Estimation for SNN in Space Applications](https://arxiv.org/abs/2508.19654)
*Matthias Höfflin,Jürgen Wassner*

Main category: cs.CV

TL;DR: SNNs在硬件无关方法中表现优于CNNs，但在硬件相关分析中仅在高输入稀疏性和神经形态硬件上显著节能。


<details>
  <summary>Details</summary>
Motivation: 质疑SNNs的固有能效声誉，特别是在数字实现中，并探讨其在多输出回归任务中的表现。

Method: 使用LIF神经元的膜电位训练SNN，并与CNN在卫星数据集上比较MSE和能耗。

Result: SNN在MSE上与CNN相当，硬件无关方法预测SNN节能50-60%，但硬件相关分析显示节能仅在高输入稀疏性和神经形态硬件上显著。

Conclusion: 需透明评估方法和明确假设披露，以确保神经网络能效比较的公平性。

Abstract: Spiking Neural Networks (SNNs), inspired by biological intelligence, have
long been considered inherently energy-efficient, making them attractive for
resource-constrained domains such as space applications. However, recent
comparative studies with conventional Artificial Neural Networks (ANNs) have
begun to question this reputation, especially for digital implementations. This
work investigates SNNs for multi-output regression, specifically 3-D satellite
position estimation from monocular images, and compares hardware-aware and
hardware-agnostic energy estimation methods. The proposed SNN, trained using
the membrane potential of the Leaky Integrate-and-Fire (LIF) neuron in the
final layer, achieves comparable Mean Squared Error (MSE) to a reference
Convolutional Neural Network (CNN) on a photorealistic satellite dataset.
Energy analysis shows that while hardware-agnostic methods predict a consistent
50-60% energy advantage for SNNs over CNNs, hardware-aware analysis reveals
that significant energy savings are realized only on neuromorphic hardware and
with high input sparsity. The influence of dark pixel ratio on energy
consumption is quantified, emphasizing the impact of data characteristics and
hardware assumptions. These findings highlight the need for transparent
evaluation methods and explicit disclosure of underlying assumptions to ensure
fair comparisons of neural network energy efficiency.

</details>


### [44] [A Frequency-Aware Self-Supervised Learning for Ultra-Wide-Field Image Enhancement](https://arxiv.org/abs/2508.19664)
*Weicheng Liao,Zan Chen,Jianyang Xie,Yalin Zheng,Yuhui Ma,Yitian Zhao*

Main category: cs.CV

TL;DR: 提出了一种基于频率感知的自监督学习方法，用于超广角（UWF）视网膜图像增强，结合了频率解耦的去模糊和Retinex引导的照明补偿模块。


<details>
  <summary>Details</summary>
Motivation: UWF视网膜成像在诊断中具有重要作用，但常因模糊和照明不均导致细节丢失，现有方法无法满足其独特需求。

Method: 采用频率解耦的去模糊模块（结合全局和局部视图）和Retinex引导的照明补偿模块（包含颜色保护单元）。

Result: 实验表明，该方法不仅提升了图像质量，还改善了疾病诊断性能。

Conclusion: 这是首个针对UWF图像增强的尝试，为视网膜疾病管理提供了有价值的工具。

Abstract: Ultra-Wide-Field (UWF) retinal imaging has revolutionized retinal diagnostics
by providing a comprehensive view of the retina. However, it often suffers from
quality-degrading factors such as blurring and uneven illumination, which
obscure fine details and mask pathological information. While numerous retinal
image enhancement methods have been proposed for other fundus imageries, they
often fail to address the unique requirements in UWF, particularly the need to
preserve pathological details. In this paper, we propose a novel
frequency-aware self-supervised learning method for UWF image enhancement. It
incorporates frequency-decoupled image deblurring and Retinex-guided
illumination compensation modules. An asymmetric channel integration operation
is introduced in the former module, so as to combine global and local views by
leveraging high- and low-frequency information, ensuring the preservation of
fine and broader structural details. In addition, a color preservation unit is
proposed in the latter Retinex-based module, to provide multi-scale spatial and
frequency information, enabling accurate illumination estimation and
correction. Experimental results demonstrate that the proposed work not only
enhances visualization quality but also improves disease diagnosis performance
by restoring and correcting fine local details and uneven intensity. To the
best of our knowledge, this work is the first attempt for UWF image
enhancement, offering a robust and clinically valuable tool for improving
retinal disease management.

</details>


### [45] [SAT: Supervisor Regularization and Animation Augmentation for Two-process Monocular Texture 3D Human Reconstruction](https://arxiv.org/abs/2508.19688)
*Gangjian Zhang,Jian Shu,Nanjie Yao,Hao Wang*

Main category: cs.CV

TL;DR: SAT框架通过统一学习多种几何先验并引入监督特征正则化和在线动画增强模块，解决了单目3D人体重建中的几何模糊性和数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 单目2D图像的几何模糊性和3D人体训练数据的稀缺性限制了单目纹理3D人体重建的发展。

Method: 提出SAT框架，统一学习多种几何先验；引入监督特征正则化模块和多视角网络；提出在线动画增强模块以增加训练数据。

Result: 在两个基准测试中表现优于现有方法。

Conclusion: SAT框架有效解决了几何模糊性和数据稀缺问题，实现了高质量的3D人体重建。

Abstract: Monocular texture 3D human reconstruction aims to create a complete 3D
digital avatar from just a single front-view human RGB image. However, the
geometric ambiguity inherent in a single 2D image and the scarcity of 3D human
training data are the main obstacles limiting progress in this field. To
address these issues, current methods employ prior geometric estimation
networks to derive various human geometric forms, such as the SMPL model and
normal maps. However, they struggle to integrate these modalities effectively,
leading to view inconsistencies, such as facial distortions. To this end, we
propose a two-process 3D human reconstruction framework, SAT, which seamlessly
learns various prior geometries in a unified manner and reconstructs
high-quality textured 3D avatars as the final output. To further facilitate
geometry learning, we introduce a Supervisor Feature Regularization module. By
employing a multi-view network with the same structure to provide intermediate
features as training supervision, these varied geometric priors can be better
fused. To tackle data scarcity and further improve reconstruction quality, we
also propose an Online Animation Augmentation module. By building a
one-feed-forward animation network, we augment a massive number of samples from
the original 3D human data online for model training. Extensive experiments on
two benchmarks show the superiority of our approach compared to
state-of-the-art methods.

</details>


### [46] [Synthetic Image Detection via Spectral Gaps of QC-RBIM Nishimori Bethe-Hessian Operators](https://arxiv.org/abs/2508.19698)
*V. S. Usatyuk,D. A. Sapozhnikov,S. I. Egorov*

Main category: cs.CV

TL;DR: 提出了一种基于物理启发的无监督检测器，用于区分真实图像与合成图像，通过图社区检测方法实现高准确率。


<details>
  <summary>Details</summary>
Motivation: 深度生成模型（如GANs和扩散模型）生成的图像难以与真实照片区分，威胁媒体取证和生物识别安全，现有方法在未见过的生成器或对抗后处理下效果不佳。

Method: 将合成图像检测视为稀疏加权图上的社区检测问题，利用预训练CNN提取特征并构建多边类型QC-LDPC图，通过Nishimori温度校准边耦合，分析Bethe-Hessian谱的间隙。

Result: 在未使用标记合成数据或重新训练特征提取器的情况下，检测器在二元任务中达到94%以上的准确率。

Conclusion: 该方法通过LDPC图嵌入深度特征，建立了Nishimori温度RBIM与Bethe-Hessian谱的分析联系，提供了一种鲁棒的无监督合成图像检测方案。

Abstract: The rapid advance of deep generative models such as GANs and diffusion
networks now produces images that are virtually indistinguishable from genuine
photographs, undermining media forensics and biometric security. Supervised
detectors quickly lose effectiveness on unseen generators or after adversarial
post-processing, while existing unsupervised methods that rely on low-level
statistical cues remain fragile. We introduce a physics-inspired,
model-agnostic detector that treats synthetic-image identification as a
community-detection problem on a sparse weighted graph. Image features are
first extracted with pretrained CNNs and reduced to 32 dimensions, each feature
vector becomes a node of a Multi-Edge Type QC-LDPC graph. Pairwise similarities
are transformed into edge couplings calibrated at the Nishimori temperature,
producing a Random Bond Ising Model (RBIM) whose Bethe-Hessian spectrum
exhibits a characteristic gap when genuine community structure (real images) is
present. Synthetic images violate the Nishimori symmetry and therefore lack
such gaps. We validate the approach on binary tasks cat versus dog and male
versus female using real photos from Flickr-Faces-HQ and CelebA and synthetic
counterparts generated by GANs and diffusion models. Without any labeled
synthetic data or retraining of the feature extractor, the detector achieves
over 94% accuracy. Spectral analysis shows multiple well separated gaps for
real image sets and a collapsed spectrum for generated ones. Our contributions
are threefold: a novel LDPC graph construction that embeds deep image features,
an analytical link between Nishimori temperature RBIM and the Bethe-Hessian
spectrum providing a Bayes optimal detection criterion; and a practical,
unsupervised synthetic image detector robust to new generative architectures.
Future work will extend the framework to video streams and multi-class anomaly
detection.

</details>


### [47] [LabelGS: Label-Aware 3D Gaussian Splatting for 3D Scene Segmentation](https://arxiv.org/abs/2508.19699)
*Yupeng Zhang,Dezhi Zheng,Ping Lu,Han Zhang,Lei Wang,Liping xiang,Cheng Luo,Kaijun Deng,Xiaowen Fu,Linlin Shen,Jinbao Wang*

Main category: cs.CV

TL;DR: LabelGS通过引入对象标签和优化策略，显著提升了3D高斯溅射（3DGS）的3D分割能力，并在训练速度上实现了22倍的提升。


<details>
  <summary>Details</summary>
Motivation: 3DGS缺乏3D分割能力，限制了其在需要场景理解的任务中的应用。

Method: LabelGS通过跨视图一致的语义掩码、遮挡分析模型、主高斯标记模型和高斯投影过滤器来增强高斯表示。

Result: LabelGS在3D场景分割任务中优于现有方法，训练速度提升了22倍。

Conclusion: LabelGS有效解决了3DGS的分割问题，并显著提升了效率。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a novel explicit representation
for 3D scenes, offering both high-fidelity reconstruction and efficient
rendering. However, 3DGS lacks 3D segmentation ability, which limits its
applicability in tasks that require scene understanding. The identification and
isolating of specific object components is crucial. To address this limitation,
we propose Label-aware 3D Gaussian Splatting (LabelGS), a method that augments
the Gaussian representation with object label.LabelGS introduces cross-view
consistent semantic masks for 3D Gaussians and employs a novel Occlusion
Analysis Model to avoid overfitting occlusion during optimization, Main
Gaussian Labeling model to lift 2D semantic prior to 3D Gaussian and Gaussian
Projection Filter to avoid Gaussian label conflict. Our approach achieves
effective decoupling of Gaussian representations and refines the 3DGS
optimization process through a random region sampling strategy, significantly
improving efficiency. Extensive experiments demonstrate that LabelGS
outperforms previous state-of-the-art methods, including Feature-3DGS, in the
3D scene segmentation task. Notably, LabelGS achieves a remarkable 22X speedup
in training compared to Feature-3DGS, at a resolution of 1440X1080. Our code
will be at https://github.com/garrisonz/LabelGS.

</details>


### [48] [FreeVPS: Repurposing Training-Free SAM2 for Generalizable Video Polyp Segmentation](https://arxiv.org/abs/2508.19705)
*Qiang Hu,Ying Zhou,Gepeng Ji,Nick Barnes,Qiang Li,Zhiwei Wang*

Main category: cs.CV

TL;DR: 论文提出了一种新的视频息肉分割（VPS）方法FreeVPS，通过结合图像息肉分割（IPS）和SAM2模型，解决了时空建模与领域泛化的平衡问题，并通过两个免训练模块提升了分割稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有VPS方法难以平衡时空建模和领域泛化，限制了在真实临床场景中的应用。

Method: 采用track-by-detect范式，结合IPS的空间上下文和SAM2的时序建模能力，并通过两个免训练模块（内部关联过滤和跨关联细化）减少误差积累。

Result: FreeVPS在域内和域外场景中均达到领先性能，并在长视频中展示了鲁棒的跟踪能力。

Conclusion: FreeVPS通过创新设计解决了VPS的稳定性问题，具有潜在的可靠临床分析价值。

Abstract: Existing video polyp segmentation (VPS) paradigms usually struggle to balance
between spatiotemporal modeling and domain generalization, limiting their
applicability in real clinical scenarios. To embrace this challenge, we recast
the VPS task as a track-by-detect paradigm that leverages the spatial contexts
captured by the image polyp segmentation (IPS) model while integrating the
temporal modeling capabilities of segment anything model 2 (SAM2). However,
during long-term polyp tracking in colonoscopy videos, SAM2 suffers from error
accumulation, resulting in a snowball effect that compromises segmentation
stability. We mitigate this issue by repurposing SAM2 as a video polyp
segmenter with two training-free modules. In particular, the intra-association
filtering module eliminates spatial inaccuracies originating from the detecting
stage, reducing false positives. The inter-association refinement module
adaptively updates the memory bank to prevent error propagation over time,
enhancing temporal coherence. Both modules work synergistically to stabilize
SAM2, achieving cutting-edge performance in both in-domain and out-of-domain
scenarios. Furthermore, we demonstrate the robust tracking capabilities of
FreeVPS in long-untrimmed colonoscopy videos, underscoring its potential
reliable clinical analysis.

</details>


### [49] [Improving Generalization in Deepfake Detection with Face Foundation Models and Metric Learning](https://arxiv.org/abs/2508.19730)
*Stelios Mylonas,Symeon Papadopoulos*

Main category: cs.CV

TL;DR: 提出了一种基于面部基础模型的鲁棒视频深度伪造检测框架，通过自监督学习和多数据集微调提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 深度伪造技术日益逼真，检测模型在真实场景中泛化能力不足。

Method: 利用自监督面部基础模型FSFM，结合多数据集微调和三元组损失，增强判别能力。

Result: 在多样化评估基准中表现优异，尤其在真实场景中效果显著。

Conclusion: 该方法通过结合基础模型和多任务学习，显著提升了深度伪造检测的泛化性能。

Abstract: The increasing realism and accessibility of deepfakes have raised critical
concerns about media authenticity and information integrity. Despite recent
advances, deepfake detection models often struggle to generalize beyond their
training distributions, particularly when applied to media content found in the
wild. In this work, we present a robust video deepfake detection framework with
strong generalization that takes advantage of the rich facial representations
learned by face foundation models. Our method is built on top of FSFM, a
self-supervised model trained on real face data, and is further fine-tuned
using an ensemble of deepfake datasets spanning both face-swapping and
face-reenactment manipulations. To enhance discriminative power, we incorporate
triplet loss variants during training, guiding the model to produce more
separable embeddings between real and fake samples. Additionally, we explore
attribution-based supervision schemes, where deepfakes are categorized by
manipulation type or source dataset, to assess their impact on generalization.
Extensive experiments across diverse evaluation benchmarks demonstrate the
effectiveness of our approach, especially in challenging real-world scenarios.

</details>


### [50] [POEv2: a flexible and robust framework for generic line segment detection and wireframe line segment detection](https://arxiv.org/abs/2508.19742)
*Chenguang Liu,Chisheng Wang,Yuhua Cai,Chuanhua Zhu,Qingquan Li*

Main category: cs.CV

TL;DR: 提出了一种名为POEv2的框架，适用于通用和线框线段检测，结合高效边缘检测器在三个公开数据集上达到最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有线段检测器分为通用和线框两类，各自设计目标不同导致性能不理想，需要一种能同时满足两者的方法。

Method: 改进Pixel Orientation Estimation (POE)方法，提出POEv2，从边缘强度图中检测线段，可与任何边缘检测器结合。

Result: 结合高效边缘检测器后，POEv2在三个公开数据集上达到最优性能。

Conclusion: POEv2是一种通用且高效的线段检测框架，适用于多种场景。

Abstract: Line segment detection in images has been studied for several decades.
Existing line segment detectors can be roughly divided into two categories:
generic line segment detectors and wireframe line segment detectors. Generic
line segment detectors aim to detect all meaningful line segments in images and
traditional approaches usually fall into this category. Recent deep learning
based approaches are mostly wireframe line segment detectors. They detect only
line segments that are geometrically meaningful and have large spatial support.
Due to the difference in the aim of design, the performance of generic line
segment detectors for the task of wireframe line segment detection won't be
satisfactory, and vice versa. In this work, we propose a robust framework that
can be used for both generic line segment detection and wireframe line segment
detection. The proposed method is an improved version of the Pixel Orientation
Estimation (POE) method. It is thus named as POEv2. POEv2 detects line segments
from edge strength maps, and can be combined with any edge detector. We show in
our experiments that by combining the proposed POEv2 with an efficient edge
detector, it achieves state-of-the-art performance on three publicly available
datasets.

</details>


### [51] [SPLF-SAM: Self-Prompting Segment Anything Model for Light Field Salient Object Detection](https://arxiv.org/abs/2508.19746)
*Qiyao Xu,Qiming Wu,Xiaowei Li*

Main category: cs.CV

TL;DR: 提出了一种名为SPLF-SAM的新模型，结合UMFEB和MAFA模块，显著提升了光场显著目标检测的性能。


<details>
  <summary>Details</summary>
Motivation: 现有模型在光场显著目标检测任务中忽视提示信息提取和频域信息分析，导致小目标被噪声淹没。

Method: SPLF-SAM模型包含统一多尺度特征嵌入块（UMFEB）和多尺度自适应滤波适配器（MAFA），分别用于识别不同大小目标和学习频域特征。

Result: 实验表明，该方法优于十种先进的光场显著目标检测方法。

Conclusion: SPLF-SAM通过结合UMFEB和MAFA，有效解决了小目标被噪声淹没的问题，提升了检测性能。

Abstract: Segment Anything Model (SAM) has demonstrated remarkable capabilities in
solving light field salient object detection (LF SOD). However, most existing
models tend to neglect the extraction of prompt information under this task.
Meanwhile, traditional models ignore the analysis of frequency-domain
information, which leads to small objects being overwhelmed by noise. In this
paper, we put forward a novel model called self-prompting light field segment
anything model (SPLF-SAM), equipped with unified multi-scale feature embedding
block (UMFEB) and a multi-scale adaptive filtering adapter (MAFA). UMFEB is
capable of identifying multiple objects of varying sizes, while MAFA, by
learning frequency features, effectively prevents small objects from being
overwhelmed by noise. Extensive experiments have demonstrated the superiority
of our method over ten state-of-the-art (SOTA) LF SOD methods. Our code will be
available at https://github.com/XucherCH/splfsam.

</details>


### [52] [FastAvatar: Towards Unified Fast High-Fidelity 3D Avatar Reconstruction with Large Gaussian Reconstruction Transformers](https://arxiv.org/abs/2508.19754)
*Yue Wu,Yufan Wu,Wen Li,Yuxi Lu,Kairui Feng,Xuanhong Chen*

Main category: cs.CV

TL;DR: FastAvatar是一个快速3D头像重建框架，通过统一模型高效利用多种输入数据，实现高质量3D高斯溅射模型重建。


<details>
  <summary>Details</summary>
Motivation: 解决现有3D头像重建方法的高时间复杂性、数据质量敏感性和低数据利用率问题。

Method: 采用大型高斯重建Transformer，结合多帧线索、多粒度引导编码和增量高斯聚合技术。

Result: 实验表明FastAvatar在质量和速度上优于现有方法。

Conclusion: FastAvatar提供了一种高质量、快速且可调谐的3D头像建模范式。

Abstract: Despite significant progress in 3D avatar reconstruction, it still faces
challenges such as high time complexity, sensitivity to data quality, and low
data utilization. We propose FastAvatar, a feedforward 3D avatar framework
capable of flexibly leveraging diverse daily recordings (e.g., a single image,
multi-view observations, or monocular video) to reconstruct a high-quality 3D
Gaussian Splatting (3DGS) model within seconds, using only a single unified
model. FastAvatar's core is a Large Gaussian Reconstruction Transformer
featuring three key designs: First, a variant VGGT-style transformer
architecture aggregating multi-frame cues while injecting initial 3D prompt to
predict an aggregatable canonical 3DGS representation; Second, multi-granular
guidance encoding (camera pose, FLAME expression, head pose) mitigating
animation-induced misalignment for variable-length inputs; Third, incremental
Gaussian aggregation via landmark tracking and sliced fusion losses.
Integrating these features, FastAvatar enables incremental reconstruction,
i.e., improving quality with more observations, unlike prior work wasting input
data. This yields a quality-speed-tunable paradigm for highly usable avatar
modeling. Extensive experiments show that FastAvatar has higher quality and
highly competitive speed compared to existing methods.

</details>


### [53] [BuzzSet v1.0: A Dataset for Pollinator Detection in Field Conditions](https://arxiv.org/abs/2508.19762)
*Ahmed Emam,Mohamed Elbassiouny,Julius Miller,Patrick Donworth,Sabine Seidel,Ribana Roscher*

Main category: cs.CV

TL;DR: BuzzSet是一个大规模传粉昆虫图像数据集，用于自动化监测传粉昆虫，提供高分辨率图像和强基线模型。


<details>
  <summary>Details</summary>
Motivation: 传粉昆虫对全球食物生产和生态系统稳定至关重要，但其数量因人为和环境压力而下降，需要自动化监测工具。

Method: 使用YOLOv12模型生成初始标注，并通过人工验证和开源工具进行细化，图像预处理为256×256大小，采用RF-DETR目标检测器。

Result: 模型在蜜蜂和熊蜂类别上分别达到0.94和0.92的F1分数，mAP@0.50为0.559，未识别类别的检测更具挑战性。

Conclusion: BuzzSet为小目标检测、标签噪声下的类别分离和生态计算机视觉提供了有价值的基准。

Abstract: Pollinator insects such as honeybees and bumblebees are vital to global food
production and ecosystem stability, yet their populations are declining due to
increasing anthropogenic and environmental stressors. To support scalable,
automated pollinator monitoring, we introduce BuzzSet, a new large-scale
dataset of high-resolution pollinator images collected in real agricultural
field conditions. BuzzSet contains 7856 manually verified and labeled images,
with over 8000 annotated instances across three classes: honeybees, bumblebees,
and unidentified insects. Initial annotations were generated using a YOLOv12
model trained on external data and refined via human verification using
open-source labeling tools. All images were preprocessed into 256~$\times$~256
tiles to improve the detection of small insects. We provide strong baselines
using the RF-DETR transformer-based object detector. The model achieves high
F1-scores of 0.94 and 0.92 for honeybee and bumblebee classes, respectively,
with confusion matrix results showing minimal misclassification between these
categories. The unidentified class remains more challenging due to label
ambiguity and lower sample frequency, yet still contributes useful insights for
robustness evaluation. Overall detection quality is strong, with a best
mAP@0.50 of 0.559. BuzzSet offers a valuable benchmark for small object
detection, class separation under label noise, and ecological computer vision.

</details>


### [54] [AIM: Adaptive Intra-Network Modulation for Balanced Multimodal Learning](https://arxiv.org/abs/2508.19769)
*Shu Shen,C. L. Philip Chen,Tong Zhang*

Main category: cs.CV

TL;DR: 论文提出了一种自适应网络内调制方法（AIM），用于解决多模态学习中的不平衡问题，通过优化网络参数和深度差异，实现平衡学习而不抑制任何模态。


<details>
  <summary>Details</summary>
Motivation: 多模态学习中存在模态不平衡问题，现有方法通常抑制主导模态以提升弱势模态，影响了整体性能。论文分析了优化偏差问题，并提出解决方案。

Method: 提出AIM方法，通过解耦主导模态的未优化参数为辅助块，并与弱势模态联合训练，同时自适应调整不同深度的调制强度。

Result: 实验表明，AIM在多个基准测试中优于现有方法，并展现出对不同主干网络、融合策略和优化器的强泛化能力。

Conclusion: AIM首次实现了不抑制任何模态的平衡多模态学习，为多模态学习中的不平衡问题提供了有效解决方案。

Abstract: Multimodal learning has significantly enhanced machine learning performance
but still faces numerous challenges and limitations. Imbalanced multimodal
learning is one of the problems extensively studied in recent works and is
typically mitigated by modulating the learning of each modality. However, we
find that these methods typically hinder the dominant modality's learning to
promote weaker modalities, which affects overall multimodal performance. We
analyze the cause of this issue and highlight a commonly overlooked problem:
optimization bias within networks. To address this, we propose Adaptive
Intra-Network Modulation (AIM) to improve balanced modality learning. AIM
accounts for differences in optimization state across parameters and depths
within the network during modulation, achieving balanced multimodal learning
without hindering either dominant or weak modalities for the first time.
Specifically, AIM decouples the dominant modality's under-optimized parameters
into Auxiliary Blocks and encourages reliance on these performance-degraded
blocks for joint training with weaker modalities. This approach effectively
prevents suppression of weaker modalities while enabling targeted optimization
of under-optimized parameters to improve the dominant modality. Additionally,
AIM assesses modality imbalance level across network depths and adaptively
adjusts modulation strength at each depth. Experimental results demonstrate
that AIM outperforms state-of-the-art imbalanced modality learning methods
across multiple benchmarks and exhibits strong generalizability across
different backbones, fusion strategies, and optimizers.

</details>


### [55] [The Return of Structural Handwritten Mathematical Expression Recognition](https://arxiv.org/abs/2508.19773)
*Jakob Seitz,Tobias Lengfeld,Radu Timofte*

Main category: cs.CV

TL;DR: 论文提出了一种结构化的手写数学表达式识别方法，通过自动标注和模块化系统改进符号对齐和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有编码器-解码器架构缺乏显式的符号与轨迹对齐，限制了错误分析和交互应用。

Method: 1. 自动标注系统将LaTeX方程映射到原始轨迹；2. 模块化系统独立优化分割、分类和关系预测。

Result: 在CROHME-2023基准测试中表现优异，生成完整的图结构链接轨迹与符号。

Conclusion: 结构识别系统提升了透明度和可解释性，适用于交互式应用。

Abstract: Handwritten Mathematical Expression Recognition is foundational for
educational technologies, enabling applications like digital note-taking and
automated grading. While modern encoder-decoder architectures with large
language models excel at LaTeX generation, they lack explicit symbol-to-trace
alignment, a critical limitation for error analysis, interpretability, and
spatially aware interactive applications requiring selective content updates.
This paper introduces a structural recognition approach with two innovations: 1
an automatic annotation system that uses a neural network to map LaTeX
equations to raw traces, automatically generating annotations for symbol
segmentation, classification, and spatial relations, and 2 a modular structural
recognition system that independently optimizes segmentation, classification,
and relation prediction. By leveraging a dataset enriched with structural
annotations from our auto-labeling system, the proposed recognition system
combines graph-based trace sorting, a hybrid convolutional-recurrent network,
and transformer-based correction to achieve competitive performance on the
CROHME-2023 benchmark. Crucially, our structural recognition system generates a
complete graph structure that directly links handwritten traces to predicted
symbols, enabling transparent error analysis and interpretable outputs.

</details>


### [56] [MAPo : Motion-Aware Partitioning of Deformable 3D Gaussian Splatting for High-Fidelity Dynamic Scene Reconstruction](https://arxiv.org/abs/2508.19786)
*Han Jiao,Jiakai Sun,Yexing Xu,Lei Zhao,Wei Xing,Huaizhong Lin*

Main category: cs.CV

TL;DR: MAPo框架通过动态分区策略和跨帧一致性损失，显著提升了动态场景重建的渲染质量，尤其在复杂运动区域表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有基于变形的3D高斯泼溅方法在高度动态区域容易丢失细节，导致模糊渲染，需要更精细的运动建模方法。

Method: 提出动态评分分区策略，区分高动态和低动态3D高斯，对高动态部分递归分区并复制变形网络，同时引入跨帧一致性损失。

Result: 实验表明，MAPo在复杂运动区域渲染质量优于基线，计算成本相当。

Conclusion: MAPo通过分区和一致性损失，有效解决了动态场景重建中的模糊和细节丢失问题。

Abstract: 3D Gaussian Splatting, known for enabling high-quality static scene
reconstruction with fast rendering, is increasingly being applied to dynamic
scene reconstruction. A common strategy involves learning a deformation field
to model the temporal changes of a canonical set of 3D Gaussians. However,
these deformation-based methods often produce blurred renderings and lose fine
motion details in highly dynamic regions due to the inherent limitations of a
single, unified model in representing diverse motion patterns. To address these
challenges, we introduce Motion-Aware Partitioning of Deformable 3D Gaussian
Splatting (MAPo), a novel framework for high-fidelity dynamic scene
reconstruction. Its core is a dynamic score-based partitioning strategy that
distinguishes between high- and low-dynamic 3D Gaussians. For high-dynamic 3D
Gaussians, we recursively partition them temporally and duplicate their
deformation networks for each new temporal segment, enabling specialized
modeling to capture intricate motion details. Concurrently, low-dynamic 3DGs
are treated as static to reduce computational costs. However, this temporal
partitioning strategy for high-dynamic 3DGs can introduce visual
discontinuities across frames at the partition boundaries. To address this, we
introduce a cross-frame consistency loss, which not only ensures visual
continuity but also further enhances rendering quality. Extensive experiments
demonstrate that MAPo achieves superior rendering quality compared to baselines
while maintaining comparable computational costs, particularly in regions with
complex or rapid motions.

</details>


### [57] [StableIntrinsic: Detail-preserving One-step Diffusion Model for Multi-view Material Estimation](https://arxiv.org/abs/2508.19789)
*Xiuchao Wu,Pengfei Zhu,Jiangjing Lyu,Xinguo Liu,Jie Guo,Yanwen Guo,Weiwei Xu,Chengfei Lyu*

Main category: cs.CV

TL;DR: StableIntrinsic是一种一步扩散模型，用于多视角材料估计，解决了传统多步扩散模型的高方差和耗时问题。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在多步去噪过程中耗时且结果方差高，不适合确定性材料估计任务。

Method: 采用一步扩散模型，结合像素空间损失和细节注入网络（DIN）解决平滑问题和细节丢失。

Result: 在PSNR和MSE指标上显著优于现有方法，如albedo的PSNR提升9.9%，金属和粗糙度的MSE分别降低44.4%和60.0%。

Conclusion: StableIntrinsic通过一步扩散和细节增强，实现了高质量、低方差的材料估计。

Abstract: Recovering material information from images has been extensively studied in
computer graphics and vision. Recent works in material estimation leverage
diffusion model showing promising results. However, these diffusion-based
methods adopt a multi-step denoising strategy, which is time-consuming for each
estimation. Such stochastic inference also conflicts with the deterministic
material estimation task, leading to a high variance estimated results. In this
paper, we introduce StableIntrinsic, a one-step diffusion model for multi-view
material estimation that can produce high-quality material parameters with low
variance. To address the overly-smoothing problem in one-step diffusion,
StableIntrinsic applies losses in pixel space, with each loss designed based on
the properties of the material. Additionally, StableIntrinsic introduces a
Detail Injection Network (DIN) to eliminate the detail loss caused by VAE
encoding, while further enhancing the sharpness of material prediction results.
The experimental results indicate that our method surpasses the current
state-of-the-art techniques by achieving a $9.9\%$ improvement in the Peak
Signal-to-Noise Ratio (PSNR) of albedo, and by reducing the Mean Square Error
(MSE) for metallic and roughness by $44.4\%$ and $60.0\%$, respectively.

</details>


### [58] [Not Every Gift Comes in Gold Paper or with a Red Ribbon: Exploring Color Perception in Text-to-Image Models](https://arxiv.org/abs/2508.19791)
*Shay Shomer Chai,Wenxuan Peng,Bharath Hariharan,Hadar Averbuch-Elor*

Main category: cs.CV

TL;DR: 论文研究了文本到图像生成中多对象颜色属性的语义对齐问题，并提出了一种新的编辑技术来改善多颜色提示的生成效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理复杂多对象提示时难以准确捕捉语义，尤其是颜色属性，导致生成图像与文本描述不一致。

Method: 通过案例研究分析颜色属性问题，并提出了一种专门的图像编辑技术来改善多颜色提示的语义对齐。

Result: 实验表明，该方法显著提升了多颜色提示的生成效果，优于现有推理技术和编辑方法。

Conclusion: 提出的编辑技术有效解决了多对象颜色属性的语义对齐问题，为文本到图像生成提供了更可靠的解决方案。

Abstract: Text-to-image generation has recently seen remarkable success, granting users
with the ability to create high-quality images through the use of text.
However, contemporary methods face challenges in capturing the precise
semantics conveyed by complex multi-object prompts. Consequently, many works
have sought to mitigate such semantic misalignments, typically via
inference-time schemes that modify the attention layers of the denoising
networks. However, prior work has mostly utilized coarse metrics, such as the
cosine similarity between text and image CLIP embeddings, or human evaluations,
which are challenging to conduct on a larger-scale. In this work, we perform a
case study on colors -- a fundamental attribute commonly associated with
objects in text prompts, which offer a rich test bed for rigorous evaluation.
Our analysis reveals that pretrained models struggle to generate images that
faithfully reflect multiple color attributes-far more so than with single-color
prompts-and that neither inference-time techniques nor existing editing methods
reliably resolve these semantic misalignments. Accordingly, we introduce a
dedicated image editing technique, mitigating the issue of multi-object
semantic alignment for prompts containing multiple colors. We demonstrate that
our approach significantly boosts performance over a wide range of metrics,
considering images generated by various text-to-image diffusion-based
techniques.

</details>


### [59] [FusionSort: Enhanced Cluttered Waste Segmentation with Advanced Decoding and Comprehensive Modality Optimization](https://arxiv.org/abs/2508.19798)
*Muhammad Ali,Omar Ali AlSuwaidi*

Main category: cs.CV

TL;DR: 提出了一种改进的神经架构，用于提高非生物降解废物分类的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 废物管理中非生物降解材料的分类过程复杂且多变，自动化面临挑战。

Method: 基于Encoder-Decoder结构，引入综合注意力块、Mamba架构和数据融合块，结合PCA降维处理多通道图像。

Result: 在RGB、高光谱、多光谱及其组合数据上表现优于现有方法。

Conclusion: 新模型显著提升了废物分类系统的性能。

Abstract: In the realm of waste management, automating the sorting process for
non-biodegradable materials presents considerable challenges due to the
complexity and variability of waste streams. To address these challenges, we
introduce an enhanced neural architecture that builds upon an existing
Encoder-Decoder structure to improve the accuracy and efficiency of waste
sorting systems. Our model integrates several key innovations: a Comprehensive
Attention Block within the decoder, which refines feature representations by
combining convolutional and upsampling operations. In parallel, we utilize
attention through the Mamba architecture, providing an additional performance
boost. We also introduce a Data Fusion Block that fuses images with more than
three channels. To achieve this, we apply PCA transformation to reduce the
dimensionality while retaining the maximum variance and essential information
across three dimensions, which are then used for further processing. We
evaluated the model on RGB, hyperspectral, multispectral, and a combination of
RGB and hyperspectral data. The results demonstrate that our approach
outperforms existing methods by a significant margin.

</details>


### [60] [A bag of tricks for real-time Mitotic Figure detection](https://arxiv.org/abs/2508.19804)
*Christian Marzahl,Brian Napora*

Main category: cs.CV

TL;DR: 提出了一种基于RTMDet单阶段目标检测器的训练技巧集合，用于实现跨域鲁棒、实时的有丝分裂图像检测。


<details>
  <summary>Details</summary>
Motivation: 解决组织病理学图像中有丝分裂图像检测的挑战，如扫描仪、染色协议、组织类型和伪影的多样性。

Method: 采用多域训练数据、平衡采样、增强技术和硬负样本挖掘，基于RTMDet单阶段检测器。

Result: 在多个数据集上F1分数为0.78-0.84，在MIDOG 2025测试集上F1为0.81，优于大型模型。

Conclusion: 该方法在准确性和速度之间取得平衡，适合临床实际应用。

Abstract: Mitotic figure (MF) detection in histopathology images is challenging due to
large variations in slide scanners, staining protocols, tissue types, and the
presence of artifacts. This paper presents a collection of training techniques
- a bag of tricks - that enable robust, real-time MF detection across diverse
domains. We build on the efficient RTMDet single stage object detector to
achieve high inference speed suitable for clinical deployment. Our method
addresses scanner variability and tumor heterogeneity via extensive
multi-domain training data, balanced sampling, and careful augmentation.
Additionally, we employ targeted, hard negative mining on necrotic and debris
tissue to reduce false positives. In a grouped 5-fold cross-validation across
multiple MF datasets, our model achieves an F1 score between 0.78 and 0.84. On
the preliminary test set of the MItosis DOmain Generalization (MIDOG) 2025
challenge, our single-stage RTMDet-S based approach reaches an F1 of 0.81,
outperforming larger models and demonstrating adaptability to new, unfamiliar
domains. The proposed solution offers a practical trade-off between accuracy
and speed, making it attractive for real-world clinical adoption.

</details>


### [61] [Context-aware Sparse Spatiotemporal Learning for Event-based Vision](https://arxiv.org/abs/2508.19806)
*Shenqi Wang,Guangzhi Tang*

Main category: cs.CV

TL;DR: CSSL框架通过动态调节神经元激活，高效处理事件数据，适用于边缘计算。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能充分利用事件数据的稀疏性，且神经形态计算在复杂任务中性能不足。

Method: 提出CSSL框架，通过上下文感知阈值动态调节神经元激活，无需显式稀疏约束。

Result: 在事件目标检测和光流估计中，CSSL性能优于或媲美现有方法，同时保持高神经元稀疏性。

Conclusion: CSSL为神经形态处理提供了高效的事件视觉解决方案。

Abstract: Event-based camera has emerged as a promising paradigm for robot perception,
offering advantages with high temporal resolution, high dynamic range, and
robustness to motion blur. However, existing deep learning-based event
processing methods often fail to fully leverage the sparse nature of event
data, complicating their integration into resource-constrained edge
applications. While neuromorphic computing provides an energy-efficient
alternative, spiking neural networks struggle to match of performance of
state-of-the-art models in complex event-based vision tasks, like object
detection and optical flow. Moreover, achieving high activation sparsity in
neural networks is still difficult and often demands careful manual tuning of
sparsity-inducing loss terms. Here, we propose Context-aware Sparse
Spatiotemporal Learning (CSSL), a novel framework that introduces context-aware
thresholding to dynamically regulate neuron activations based on the input
distribution, naturally reducing activation density without explicit sparsity
constraints. Applied to event-based object detection and optical flow
estimation, CSSL achieves comparable or superior performance to
state-of-the-art methods while maintaining extremely high neuronal sparsity.
Our experimental results highlight CSSL's crucial role in enabling efficient
event-based vision for neuromorphic processing.

</details>


### [62] [AutoQ-VIS: Improving Unsupervised Video Instance Segmentation via Automatic Quality Assessment](https://arxiv.org/abs/2508.19808)
*Kaixuan Lu,Mehmet Onurcan Kaya,Dim P. Papadopoulos*

Main category: cs.CV

TL;DR: AutoQ-VIS是一种无监督视频实例分割框架，通过质量引导的自训练方法，解决了合成数据与真实视频之间的域差距问题，无需人工标注即可实现最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 视频实例分割（VIS）需要像素级掩码和时间一致性标签，标注成本高。现有无监督方法依赖合成数据，但存在合成到真实的域差距问题。

Method: 提出AutoQ-VIS框架，通过质量引导的自训练方法，在伪标签生成和自动质量评估之间建立闭环系统，逐步适应从合成到真实的视频。

Result: 在YouTubeVIS-2019验证集上达到52.6 AP50，比之前的SOTA方法VideoCutLER提升4.4%，且无需人工标注。

Conclusion: AutoQ-VIS证明了质量感知自训练在无监督VIS中的可行性，为减少标注依赖提供了新思路。

Abstract: Video Instance Segmentation (VIS) faces significant annotation challenges due
to its dual requirements of pixel-level masks and temporal consistency labels.
While recent unsupervised methods like VideoCutLER eliminate optical flow
dependencies through synthetic data, they remain constrained by the
synthetic-to-real domain gap. We present AutoQ-VIS, a novel unsupervised
framework that bridges this gap through quality-guided self-training. Our
approach establishes a closed-loop system between pseudo-label generation and
automatic quality assessment, enabling progressive adaptation from synthetic to
real videos. Experiments demonstrate state-of-the-art performance with 52.6
$\text{AP}_{50}$ on YouTubeVIS-2019 val set, surpassing the previous
state-of-the-art VideoCutLER by 4.4$\%$, while requiring no human annotations.
This demonstrates the viability of quality-aware self-training for unsupervised
VIS. The source code of our method is available at
https://github.com/wcbup/AutoQ-VIS.

</details>


### [63] [ERSR: An Ellipse-constrained pseudo-label refinement and symmetric regularization framework for semi-supervised fetal head segmentation in ultrasound images](https://arxiv.org/abs/2508.19815)
*Linkuan Zhou,Zhexin Chen,Yufei Shen,Junlin Xu,Ping Xuan,Yixin Zhu,Yuqi Fang,Cong Cong,Leyi Wei,Ran Su,Jia Zhou,Qiangguo Jin*

Main category: cs.CV

TL;DR: 提出ERSR框架，通过双评分自适应过滤、椭圆约束伪标签精炼和对称性多一致性正则化，提升胎儿头部超声图像分割性能。


<details>
  <summary>Details</summary>
Motivation: 超声图像质量差和标注数据不足导致胎儿头部分割困难，现有半监督方法难以生成可靠伪标签和有效一致性约束。

Method: 采用双评分自适应过滤策略评估教师输出，椭圆约束伪标签精炼优化伪标签，对称性多一致性正则化增强模型鲁棒性。

Result: 在HC18和PSFH数据集上，分别达到92.05%/95.36%和91.68%/93.70%的Dice分数。

Conclusion: ERSR框架显著提升半监督胎儿头部超声分割性能，适用于标注数据有限场景。

Abstract: Automated segmentation of the fetal head in ultrasound images is critical for
prenatal monitoring. However, achieving robust segmentation remains challenging
due to the poor quality of ultrasound images and the lack of annotated data.
Semi-supervised methods alleviate the lack of annotated data but struggle with
the unique characteristics of fetal head ultrasound images, making it
challenging to generate reliable pseudo-labels and enforce effective
consistency regularization constraints. To address this issue, we propose a
novel semi-supervised framework, ERSR, for fetal head ultrasound segmentation.
Our framework consists of the dual-scoring adaptive filtering strategy, the
ellipse-constrained pseudo-label refinement, and the symmetry-based multiple
consistency regularization. The dual-scoring adaptive filtering strategy uses
boundary consistency and contour regularity criteria to evaluate and filter
teacher outputs. The ellipse-constrained pseudo-label refinement refines these
filtered outputs by fitting least-squares ellipses, which strengthens pixels
near the center of the fitted ellipse and suppresses noise simultaneously. The
symmetry-based multiple consistency regularization enforces multi-level
consistency across perturbed images, symmetric regions, and between original
predictions and pseudo-labels, enabling the model to capture robust and stable
shape representations. Our method achieves state-of-the-art performance on two
benchmarks. On the HC18 dataset, it reaches Dice scores of 92.05% and 95.36%
with 10% and 20% labeled data, respectively. On the PSFH dataset, the scores
are 91.68% and 93.70% under the same settings.

</details>


### [64] [Gradient Rectification for Robust Calibration under Distribution Shift](https://arxiv.org/abs/2508.19830)
*Yilin Zhang,Cai Xu,You Wu,Ziyu Guan,Wei Zhao*

Main category: cs.CV

TL;DR: 提出一种无需目标域信息的新型校准框架，通过低频滤波和梯度修正机制提升分布偏移下的模型校准性能。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在分布偏移下预测过于自信，现有方法依赖目标域信息，实用性受限。

Method: 从频域角度分析分布偏移，采用低频滤波策略和梯度修正机制。

Result: 在合成和真实数据集上显著提升校准性能，同时保持域内性能。

Conclusion: 该方法有效解决了分布偏移下的校准问题，具有实际应用潜力。

Abstract: Deep neural networks often produce overconfident predictions, undermining
their reliability in safety-critical applications. This miscalibration is
further exacerbated under distribution shift, where test data deviates from the
training distribution due to environmental or acquisition changes. While
existing approaches improve calibration through training-time regularization or
post-hoc adjustment, their reliance on access to or simulation of target
domains limits their practicality in real-world scenarios. In this paper, we
propose a novel calibration framework that operates without access to target
domain information. From a frequency-domain perspective, we identify that
distribution shifts often distort high-frequency visual cues exploited by deep
models, and introduce a low-frequency filtering strategy to encourage reliance
on domain-invariant features. However, such information loss may degrade
In-Distribution (ID) calibration performance. Therefore, we further propose a
gradient-based rectification mechanism that enforces ID calibration as a hard
constraint during optimization. Experiments on synthetic and real-world shifted
datasets, including CIFAR-10/100-C and WILDS, demonstrate that our method
significantly improves calibration under distribution shift while maintaining
strong in-distribution performance.

</details>


### [65] [Image Quality Assessment for Machines: Paradigm, Large-scale Database, and Models](https://arxiv.org/abs/2508.19850)
*Xiaoqi Wang,Yun Zhang,Weisi Lin*

Main category: cs.CV

TL;DR: 提出了一种机器中心的图像质量评估（MIQA）框架，用于量化图像退化对机器视觉系统（MVS）性能的影响，并展示了其优越性。


<details>
  <summary>Details</summary>
Motivation: 机器视觉系统在恶劣视觉条件下性能易受损，现有基于人类视觉系统（HVS）的评估方法不适用于MVS。

Method: 构建了包含250万样本的机器中心图像质量数据库（MIQD-2.5M），并提出区域感知的MIQA（RA-MIQA）模型进行细粒度空间退化分析。

Result: RA-MIQA在一致性和准确性上显著优于HVS-based IQA指标和经典模型，例如在图像分类任务中SRCC增益分别达到13.56%和13.37%。

Conclusion: HVS-based指标不适用于MVS质量预测，而RA-MIQA为机器中心图像处理和优化奠定了基础。

Abstract: Machine vision systems (MVS) are intrinsically vulnerable to performance
degradation under adverse visual conditions. To address this, we propose a
machine-centric image quality assessment (MIQA) framework that quantifies the
impact of image degradations on MVS performance. We establish an MIQA paradigm
encompassing the end-to-end assessment workflow. To support this, we construct
a machine-centric image quality database (MIQD-2.5M), comprising 2.5 million
samples that capture distinctive degradation responses in both consistency and
accuracy metrics, spanning 75 vision models, 250 degradation types, and three
representative vision tasks. We further propose a region-aware MIQA (RA-MIQA)
model to evaluate MVS visual quality through fine-grained spatial degradation
analysis. Extensive experiments benchmark the proposed RA-MIQA against seven
human visual system (HVS)-based IQA metrics and five retrained classical
backbones. Results demonstrate RA-MIQA's superior performance in multiple
dimensions, e.g., achieving SRCC gains of 13.56% on consistency and 13.37% on
accuracy for image classification, while also revealing task-specific
degradation sensitivities. Critically, HVS-based metrics prove inadequate for
MVS quality prediction, while even specialized MIQA models struggle with
background degradations, accuracy-oriented estimation, and subtle distortions.
This study can advance MVS reliability and establish foundations for
machine-centric image processing and optimization. The model and code are
available at: https://github.com/XiaoqiWang/MIQA.

</details>


### [66] [Ego-centric Predictive Model Conditioned on Hand Trajectories](https://arxiv.org/abs/2508.19852)
*Binjie Zhang,Mike Zheng Shou*

Main category: cs.CV

TL;DR: 提出了一种统一的两阶段预测框架，联合建模自我中心场景中的动作和视觉未来，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法同时建模动作预测和视觉场景变化，导致预测不准确或不一致。

Method: 两阶段框架：第一阶段处理多模态输入并预测手部轨迹；第二阶段通过因果交叉注意力融合多模态线索，指导潜在扩散模型生成未来视频。

Result: 在Ego4D、BridgeData和RLBench上优于现有基线，动作预测和未来视频合成均表现更优。

Conclusion: 该框架首次统一处理自我中心人类活动理解和机器人操作任务，提供了动作和视觉后果的明确预测。

Abstract: In egocentric scenarios, anticipating both the next action and its visual
outcome is essential for understanding human-object interactions and for
enabling robotic planning. However, existing paradigms fall short of jointly
modeling these aspects. Vision-Language-Action (VLA) models focus on action
prediction but lack explicit modeling of how actions influence the visual
scene, while video prediction models generate future frames without
conditioning on specific actions, often resulting in implausible or
contextually inconsistent outcomes. To bridge this gap, we propose a unified
two-stage predictive framework that jointly models action and visual future in
egocentric scenarios, conditioned on hand trajectories. In the first stage, we
perform consecutive state modeling to process heterogeneous inputs (visual
observations, language, and action history) and explicitly predict future hand
trajectories. In the second stage, we introduce causal cross-attention to fuse
multi-modal cues, leveraging inferred action signals to guide an image-based
Latent Diffusion Model (LDM) for frame-by-frame future video generation. Our
approach is the first unified model designed to handle both egocentric human
activity understanding and robotic manipulation tasks, providing explicit
predictions of both upcoming actions and their visual consequences. Extensive
experiments on Ego4D, BridgeData, and RLBench demonstrate that our method
outperforms state-of-the-art baselines in both action prediction and future
video synthesis.

</details>


### [67] [Multimodal Conditional MeshGAN for Personalized Aneurysm Growth Prediction](https://arxiv.org/abs/2508.19862)
*Long Chen,Ashiv Patel,Mengyun Qiao,Mohammad Yousuf Salmasi,Salah A. Hammouche,Vasilis Stavrinides,Jasleen Nagi,Soodeh Kalaie,Xiao Yun Xu,Wenjia Bai,Declan P. O'Regan*

Main category: cs.CV

TL;DR: MCMeshGAN是一种用于预测主动脉瘤生长的多模态条件生成对抗网络，结合局部和全局特征建模，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 主动脉瘤生长的个性化预测对及时干预至关重要，但现有方法难以同时捕捉局部变形和全局解剖变化。

Method: 提出MCMeshGAN，结合局部KNN卷积网络（KCN）和全局图卷积网络（GCN），并引入临床属性编码分支。

Result: 在几何精度和临床直径估计上均优于现有方法，并公开了数据集和代码。

Conclusion: MCMeshGAN为个性化3D疾病轨迹建模提供了可靠工具，具有临床部署潜力。

Abstract: Personalized, accurate prediction of aortic aneurysm progression is essential
for timely intervention but remains challenging due to the need to model both
subtle local deformations and global anatomical changes within complex 3D
geometries. We propose MCMeshGAN, the first multimodal conditional mesh-to-mesh
generative adversarial network for 3D aneurysm growth prediction. MCMeshGAN
introduces a dual-branch architecture combining a novel local KNN-based
convolutional network (KCN) to preserve fine-grained geometric details and a
global graph convolutional network (GCN) to capture long-range structural
context, overcoming the over-smoothing limitations of deep GCNs. A dedicated
condition branch encodes clinical attributes (age, sex) and the target time
interval to generate anatomically plausible, temporally controlled predictions,
enabling retrospective and prospective modeling. We curated TAAMesh, a new
longitudinal thoracic aortic aneurysm mesh dataset consisting of 590 multimodal
records (CT scans, 3D meshes, and clinical data) from 208 patients. Extensive
experiments demonstrate that MCMeshGAN consistently outperforms
state-of-the-art baselines in both geometric accuracy and clinically important
diameter estimation. This framework offers a robust step toward clinically
deployable, personalized 3D disease trajectory modeling. The source code for
MCMeshGAN and the baseline methods is publicly available at
https://github.com/ImperialCollegeLondon/MCMeshGAN.

</details>


### [68] [Self-supervised structured object representation learning](https://arxiv.org/abs/2508.19864)
*Oussama Hadjerci,Antoine Letienne,Mohamed Abbas Hedjazi,Adel Hafiane*

Main category: cs.CV

TL;DR: 提出了一种自监督学习方法，通过结合语义分组、实例级分离和层次结构，逐步构建结构化视觉表示，并在目标检测任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有自监督学习方法在全局图像理解上表现良好，但在捕捉场景中的结构化表示方面存在局限。

Method: 提出基于ProtoScale模块的自监督方法，保留完整场景上下文，结合多空间尺度的视觉元素。

Result: 在COCO和UA-DETRAC数据集上验证，方法在目标检测任务中表现优异，尤其在有限标注数据和较少微调轮次下。

Conclusion: 该方法通过学习对象中心表示，提升了监督目标检测性能，优于当前最先进方法。

Abstract: Self-supervised learning (SSL) has emerged as a powerful technique for
learning visual representations. While recent SSL approaches achieve strong
results in global image understanding, they are limited in capturing the
structured representation in scenes. In this work, we propose a self-supervised
approach that progressively builds structured visual representations by
combining semantic grouping, instance level separation, and hierarchical
structuring. Our approach, based on a novel ProtoScale module, captures visual
elements across multiple spatial scales. Unlike common strategies like DINO
that rely on random cropping and global embeddings, we preserve full scene
context across augmented views to improve performance in dense prediction
tasks. We validate our method on downstream object detection tasks using a
combined subset of multiple datasets (COCO and UA-DETRAC). Experimental results
show that our method learns object centric representations that enhance
supervised object detection and outperform the state-of-the-art methods, even
when trained with limited annotated data and fewer fine-tuning epochs.

</details>


### [69] [TrajFusionNet: Pedestrian Crossing Intention Prediction via Fusion of Sequential and Visual Trajectory Representations](https://arxiv.org/abs/2508.19866)
*François G. Landry,Moulay A. Akhloufi*

Main category: cs.CV

TL;DR: TrajFusionNet是一种基于Transformer的模型，结合行人轨迹和车辆速度预测，用于预测行人过马路意图，性能优越且推理时间短。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶车辆的出现，预测行人过马路意图成为重要研究方向，以提高道路安全性。

Method: TrajFusionNet采用双分支结构（SAM和VAM），分别学习序列和视觉表示，结合轻量级模态实现高效预测。

Result: 模型在三个常用数据集上达到最优性能，且总推理时间最短。

Conclusion: TrajFusionNet在预测行人过马路意图方面表现出色，兼具高效性和准确性。

Abstract: With the introduction of vehicles with autonomous capabilities on public
roads, predicting pedestrian crossing intention has emerged as an active area
of research. The task of predicting pedestrian crossing intention involves
determining whether pedestrians in the scene are likely to cross the road or
not. In this work, we propose TrajFusionNet, a novel transformer-based model
that combines future pedestrian trajectory and vehicle speed predictions as
priors for predicting crossing intention. TrajFusionNet comprises two branches:
a Sequence Attention Module (SAM) and a Visual Attention Module (VAM). The SAM
branch learns from a sequential representation of the observed and predicted
pedestrian trajectory and vehicle speed. Complementarily, the VAM branch
enables learning from a visual representation of the predicted pedestrian
trajectory by overlaying predicted pedestrian bounding boxes onto scene images.
By utilizing a small number of lightweight modalities, TrajFusionNet achieves
the lowest total inference time (including model runtime and data
preprocessing) among current state-of-the-art approaches. In terms of
performance, it achieves state-of-the-art results across the three most
commonly used datasets for pedestrian crossing intention prediction.

</details>


### [70] [Sky Background Building of Multi-objective Fiber spectra Based on Mutual Information Network](https://arxiv.org/abs/2508.19875)
*Hui Zhang,Jianghui Cai,Haifeng Yang,Ali Luo,Yuqing Yang,Xiao Kong,Zhichao Ding,Lichan Zhou,Qin Han*

Main category: cs.CV

TL;DR: 提出了一种基于互信息的天空背景估计模型（SMI），通过利用所有光纤的光谱来估计天空背景，解决了传统方法依赖天空光纤光谱的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前天空背景减法主要依赖天空光纤光谱构建超级天空，缺乏对目标周围环境的建模。SMI旨在解决这一问题。

Method: SMI包含两个主要网络：第一个网络通过波长校准模块提取光谱中的天空特征；第二个网络采用增量训练方法最大化不同光谱表示间的互信息，以捕获共同成分，同时最小化相邻光谱表示间的互信息以获取个体成分。

Result: 在LAMOST光谱上的实验表明，SMI能更好地估计目标天空背景，尤其在蓝端表现优异。

Conclusion: SMI通过互信息和增量训练方法，显著提升了天空背景估计的准确性，尤其在复杂环境中表现突出。

Abstract: Sky background subtraction is a critical step in Multi-objective Fiber
spectra process. However, current subtraction relies mainly on sky fiber
spectra to build Super Sky. These average spectra are lacking in the modeling
of the environment surrounding the objects. To address this issue, a sky
background estimation model: Sky background building based on Mutual
Information (SMI) is proposed. SMI based on mutual information and incremental
training approach. It utilizes spectra from all fibers in the plate to estimate
the sky background. SMI contains two main networks, the first network applies a
wavelength calibration module to extract sky features from spectra, and can
effectively solve the feature shift problem according to the corresponding
emission position. The second network employs an incremental training approach
to maximize mutual information between representations of different spectra to
capturing the common component. Then, it minimizes the mutual information
between adjoining spectra representations to obtain individual components. This
network yields an individual sky background at each location of the object. To
verify the effectiveness of the method in this paper, we conducted experiments
on the spectra of LAMOST. Results show that SMI can obtain a better object sky
background during the observation, especially in the blue end.

</details>


### [71] [Multispectral LiDAR data for extracting tree points in urban and suburban areas](https://arxiv.org/abs/2508.19881)
*Narges Takhtkeshha,Gabriele Mazzacca,Fabio Remondino,Juha Hyyppä,Gottfried Mandlburger*

Main category: cs.CV

TL;DR: 该研究利用多光谱LiDAR和深度学习模型提取城市树木点云数据，评估了三种模型，发现SPT在时间和精度上表现最佳，结合pNDVI可显著提升检测精度。


<details>
  <summary>Details</summary>
Motivation: 城市树木动态监测对绿化政策和电力基础设施风险管理至关重要，但复杂环境和树木多样性带来挑战。

Method: 使用多光谱LiDAR数据，结合深度学习模型（SPT、PTv3、PTv1）进行树木点云提取，并评估其性能。

Result: SPT模型表现最优（mIoU 85.28%），结合pNDVI后误差率降低10.61个百分点。

Conclusion: 多光谱LiDAR和深度学习模型在树木提取和库存管理中具有显著潜力。

Abstract: Monitoring urban tree dynamics is vital for supporting greening policies and
reducing risks to electrical infrastructure. Airborne laser scanning has
advanced large-scale tree management, but challenges remain due to complex
urban environments and tree variability. Multispectral (MS) light detection and
ranging (LiDAR) improves this by capturing both 3D spatial and spectral data,
enabling detailed mapping. This study explores tree point extraction using
MS-LiDAR and deep learning (DL) models. Three state-of-the-art models are
evaluated: Superpoint Transformer (SPT), Point Transformer V3 (PTv3), and Point
Transformer V1 (PTv1). Results show the notable time efficiency and accuracy of
SPT, with a mean intersection over union (mIoU) of 85.28%. The highest
detection accuracy is achieved by incorporating pseudo normalized difference
vegetation index (pNDVI) with spatial data, reducing error rate by 10.61
percentage points (pp) compared to using spatial information alone. These
findings highlight the potential of MS-LiDAR and DL to improve tree extraction
and further tree inventories.

</details>


### [72] [PersonaAnimator: Personalized Motion Transfer from Unconstrained Videos](https://arxiv.org/abs/2508.19895)
*Ziyun Qian,Runyu Xiao,Shuyuan Tu,Wei Xue,Dingkang Yang,Mingcheng Li,Dongliang Kou,Minghao Han,Zizhi Chen,Lihua Zhang*

Main category: cs.CV

TL;DR: 论文提出PersonaAnimator框架，解决现有运动生成方法在风格学习、数据依赖和物理合理性上的不足，实现视频到视频的运动个性化。


<details>
  <summary>Details</summary>
Motivation: 现有方法在运动风格学习、数据获取和物理合理性方面存在局限，无法生成个性化且符合物理规律的运动。

Method: 提出PersonaAnimator框架，直接从无约束视频中学习个性化运动模式，并引入Physics-aware Motion Style Regularization机制确保物理合理性。

Result: 构建PersonaVid数据集，实验表明PersonaAnimator优于现有方法，为视频到视频运动个性化任务设定了新基准。

Conclusion: PersonaAnimator通过视频学习个性化运动并确保物理合理性，解决了现有方法的不足，推动了运动生成领域的发展。

Abstract: Recent advances in motion generation show remarkable progress. However,
several limitations remain: (1) Existing pose-guided character motion transfer
methods merely replicate motion without learning its style characteristics,
resulting in inexpressive characters. (2) Motion style transfer methods rely
heavily on motion capture data, which is difficult to obtain. (3) Generated
motions sometimes violate physical laws. To address these challenges, this
paper pioneers a new task: Video-to-Video Motion Personalization. We propose a
novel framework, PersonaAnimator, which learns personalized motion patterns
directly from unconstrained videos. This enables personalized motion transfer.
To support this task, we introduce PersonaVid, the first video-based
personalized motion dataset. It contains 20 motion content categories and 120
motion style categories. We further propose a Physics-aware Motion Style
Regularization mechanism to enforce physical plausibility in the generated
motions. Extensive experiments show that PersonaAnimator outperforms
state-of-the-art motion transfer methods and sets a new benchmark for the
Video-to-Video Motion Personalization task.

</details>


### [73] [Hyperspectral Sensors and Autonomous Driving: Technologies, Limitations, and Opportunities](https://arxiv.org/abs/2508.19905)
*Imad Ali Shah,Jiarong Li,Roshan George,Tim Brophy,Enda Ward,Martin Glavin,Edward Jones,Brian Deegan*

Main category: cs.CV

TL;DR: 综述了高光谱成像（HSI）在汽车应用中的现状，分析了其潜力与商业化差距，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 探讨HSI在ADAS和自动驾驶中的潜力，填补现有技术与实际应用之间的差距。

Method: 定性综述了HSI技术，并定量分析了216款商用HSI和多光谱相机，评估其性能指标。

Result: 仅有4款相机满足性能阈值，且均不符合AEC-Q100标准；现有HSI数据集在规模和多样性上不足。

Conclusion: HSI在汽车应用中潜力巨大，但需解决商业化挑战和数据集不足问题，以实现实际集成。

Abstract: Hyperspectral imaging (HSI) offers a transformative sensing modality for
Advanced Driver Assistance Systems (ADAS) and autonomous driving (AD)
applications, enabling material-level scene understanding through fine spectral
resolution beyond the capabilities of traditional RGB imaging. This paper
presents the first comprehensive review of HSI for automotive applications,
examining the strengths, limitations, and suitability of current HSI
technologies in the context of ADAS/AD. In addition to this qualitative review,
we analyze 216 commercially available HSI and multispectral imaging cameras,
benchmarking them against key automotive criteria: frame rate, spatial
resolution, spectral dimensionality, and compliance with AEC-Q100 temperature
standards. Our analysis reveals a significant gap between HSI's demonstrated
research potential and its commercial readiness. Only four cameras meet the
defined performance thresholds, and none comply with AEC-Q100 requirements. In
addition, the paper reviews recent HSI datasets and applications, including
semantic segmentation for road surface classification, pedestrian separability,
and adverse weather perception. Our review shows that current HSI datasets are
limited in terms of scale, spectral consistency, the number of spectral
channels, and environmental diversity, posing challenges for the development of
perception algorithms and the adequate validation of HSI's true potential in
ADAS/AD applications. This review paper establishes the current state of HSI in
automotive contexts as of 2025 and outlines key research directions toward
practical integration of spectral imaging in ADAS and autonomous systems.

</details>


### [74] [Streamlining the Development of Active Learning Methods in Real-World Object Detection](https://arxiv.org/abs/2508.19906)
*Moussa Kassem Sbeyti,Nadja Klein,Michelle Karg,Christian Wirth,Sahin Albayrak*

Main category: cs.CV

TL;DR: 提出了一种基于对象相似性的度量方法（OSS），用于高效评估和选择主动学习方法，无需训练检测器。


<details>
  <summary>Details</summary>
Motivation: 解决主动学习在目标检测中的高计算成本和评估可靠性问题。

Method: 使用对象级特征量化训练集与目标域的相似性，避免训练检测器。

Result: 在三个自动驾驶数据集上验证了OSS的有效性，提高了计算效率和评估可靠性。

Conclusion: OSS为实际应用中的主动学习提供了高效且可靠的框架。

Abstract: Active learning (AL) for real-world object detection faces computational and
reliability challenges that limit practical deployment. Developing new AL
methods requires training multiple detectors across iterations to compare
against existing approaches. This creates high costs for autonomous driving
datasets where the training of one detector requires up to 282 GPU hours.
Additionally, AL method rankings vary substantially across validation sets,
compromising reliability in safety-critical transportation systems. We
introduce object-based set similarity ($\mathrm{OSS}$), a metric that addresses
these challenges. $\mathrm{OSS}$ (1) quantifies AL method effectiveness without
requiring detector training by measuring similarity between training sets and
target domains using object-level features. This enables the elimination of
ineffective AL methods before training. Furthermore, $\mathrm{OSS}$ (2) enables
the selection of representative validation sets for robust evaluation. We
validate our similarity-based approach on three autonomous driving datasets
(KITTI, BDD100K, CODA) using uncertainty-based AL methods as a case study with
two detector architectures (EfficientDet, YOLOv3). This work is the first to
unify AL training and evaluation strategies in object detection based on object
similarity. $\mathrm{OSS}$ is detector-agnostic, requires only labeled object
crops, and integrates with existing AL pipelines. This provides a practical
framework for deploying AL in real-world applications where computational
efficiency and evaluation reliability are critical. Code is available at
https://mos-ks.github.io/publications/.

</details>


### [75] [Integrating SAM Supervision for 3D Weakly Supervised Point Cloud Segmentation](https://arxiv.org/abs/2508.19909)
*Lechun You,Zhonghua Wu,Weide Liu,Xulei Yang,Jun Cheng,Wei Zhou,Bharadwaj Veeravalli,Guosheng Lin*

Main category: cs.CV

TL;DR: 提出了一种利用2D基础模型增强稀疏3D标注的方法，通过几何对应和一致性正则化提升3D弱监督分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅关注3D数据，未充分利用2D和3D数据的互补性，且对伪标签的利用不足。

Method: 结合2D基础模型的语义分割结果，通过几何对应传播到3D空间，并利用置信度和不确定性选择可靠的伪标签。

Result: 显著增加了可用标注数量，提升了3D弱监督分割的性能。

Conclusion: 该方法有效弥补了3D标注不足与2D基础模型强大能力之间的差距。

Abstract: Current methods for 3D semantic segmentation propose training models with
limited annotations to address the difficulty of annotating large, irregular,
and unordered 3D point cloud data. They usually focus on the 3D domain only,
without leveraging the complementary nature of 2D and 3D data. Besides, some
methods extend original labels or generate pseudo labels to guide the training,
but they often fail to fully use these labels or address the noise within them.
Meanwhile, the emergence of comprehensive and adaptable foundation models has
offered effective solutions for segmenting 2D data. Leveraging this
advancement, we present a novel approach that maximizes the utility of sparsely
available 3D annotations by incorporating segmentation masks generated by 2D
foundation models. We further propagate the 2D segmentation masks into the 3D
space by establishing geometric correspondences between 3D scenes and 2D views.
We extend the highly sparse annotations to encompass the areas delineated by 3D
masks, thereby substantially augmenting the pool of available labels.
Furthermore, we apply confidence- and uncertainty-based consistency
regularization on augmentations of the 3D point cloud and select the reliable
pseudo labels, which are further spread on the 3D masks to generate more
labels. This innovative strategy bridges the gap between limited 3D annotations
and the powerful capabilities of 2D foundation models, ultimately improving the
performance of 3D weakly supervised segmentation.

</details>


### [76] [WaveHiT-SR: Hierarchical Wavelet Network for Efficient Image Super-Resolution](https://arxiv.org/abs/2508.19927)
*Fayaz Ali,Muhammad Zawish,Steven Davy,Radu Timofte*

Main category: cs.CV

TL;DR: WaveHiT-SR通过将小波变换嵌入分层Transformer框架，改进了图像超分辨率任务，提高了长距离依赖建模能力并降低了计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 传统基于Transformer的超分辨率方法因窗口自注意力的二次计算复杂度限制了感受野，无法有效捕捉长距离依赖关系。

Method: 提出WaveHiT-SR，采用自适应分层窗口和小波变换分解图像，分层处理逐步重建高分辨率图像。

Result: 实验表明WaveHiT-SR在效率和性能上均优于现有方法，如SwinIR-Light等，参数更少、计算量更低、速度更快。

Conclusion: WaveHiT-SR通过结合小波变换和分层Transformer，显著提升了图像超分辨率的效果和效率。

Abstract: Transformers have demonstrated promising performance in computer vision
tasks, including image super-resolution (SR). The quadratic computational
complexity of window self-attention mechanisms in many transformer-based SR
methods forces the use of small, fixed windows, limiting the receptive field.
In this paper, we propose a new approach by embedding the wavelet transform
within a hierarchical transformer framework, called (WaveHiT-SR). First, using
adaptive hierarchical windows instead of static small windows allows to capture
features across different levels and greatly improve the ability to model
long-range dependencies. Secondly, the proposed model utilizes wavelet
transforms to decompose images into multiple frequency subbands, allowing the
network to focus on both global and local features while preserving structural
details. By progressively reconstructing high-resolution images through
hierarchical processing, the network reduces computational complexity without
sacrificing performance. The multi-level decomposition strategy enables the
network to capture fine-grained information in lowfrequency components while
enhancing high-frequency textures. Through extensive experimentation, we
confirm the effectiveness and efficiency of our WaveHiT-SR. Our refined
versions of SwinIR-Light, SwinIR-NG, and SRFormer-Light deliver cutting-edge SR
results, achieving higher efficiency with fewer parameters, lower FLOPs, and
faster speeds.

</details>


### [77] [KRETA: A Benchmark for Korean Reading and Reasoning in Text-Rich VQA Attuned to Diverse Visual Contexts](https://arxiv.org/abs/2508.19944)
*Taebaek Hwang,Minseo Kim,Gisang Lee,Seonuk Kim,Hyunjun Eun*

Main category: cs.CV

TL;DR: KRETA是一个针对韩语的文本丰富视觉问答（VQA）基准，填补了低资源语言在视觉文本理解和推理评估上的空白。


<details>
  <summary>Details</summary>
Motivation: 低资源语言（如韩语）缺乏全面的视觉问答基准，阻碍了模型的评估和比较。

Method: 提出KRETA基准，包含15个领域和26种图像类型，并开发了一个半自动化的VQA生成流程，优化了图像分解和七项指标评估协议。

Result: KRETA支持对视觉文本理解和推理能力的深入评估，并确保数据质量。

Conclusion: KRETA不仅适用于韩语，其可扩展的流程也有助于其他语言的多语言VLM研究。

Abstract: Understanding and reasoning over text within visual contexts poses a
significant challenge for Vision-Language Models (VLMs), given the complexity
and diversity of real-world scenarios. To address this challenge, text-rich
Visual Question Answering (VQA) datasets and benchmarks have emerged for
high-resource languages like English. However, a critical gap persists for
low-resource languages such as Korean, where the lack of comprehensive
benchmarks hinders robust model evaluation and comparison. To bridge this gap,
we introduce KRETA, a benchmark for Korean Reading and rEasoning in Text-rich
VQA Attuned to diverse visual contexts. KRETA facilitates an in-depth
evaluation of both visual text understanding and reasoning capabilities, while
also supporting a multifaceted assessment across 15 domains and 26 image types.
Additionally, we introduce a semi-automated VQA generation pipeline
specifically optimized for text-rich settings, leveraging refined stepwise
image decomposition and a rigorous seven-metric evaluation protocol to ensure
data quality. While KRETA is tailored for Korean, we hope our adaptable and
extensible pipeline will facilitate the development of similar benchmarks in
other languages, thereby accelerating multilingual VLM research. The code and
dataset for KRETA are available at https://github.com/tabtoyou/KRETA.

</details>


### [78] [Reimagining Image Segmentation using Active Contour: From Chan Vese Algorithm into a Proposal Novel Functional Loss Framework](https://arxiv.org/abs/2508.19946)
*Gianluca Guzzetta*

Main category: cs.CV

TL;DR: 本文对Chan-Vese算法进行了全面研究，提出了一种基于水平集的功能分割损失方法，并与传统方法进行了比较。


<details>
  <summary>Details</summary>
Motivation: 研究Chan-Vese算法在图像分割中的应用，并改进其功能分割损失方法。

Method: 采用离散化方案和水平集函数，结合PyTorch实现功能分割损失。

Result: 在常见数据集上验证了方法的有效性，代码已开源。

Conclusion: 提出的方法在图像分割中表现优于传统损失函数。

Abstract: In this paper, we present a comprehensive study and analysis of the Chan-Vese
algorithm for image segmentation. We employ a discretized scheme derived from
the empirical study of the Chan-Vese model's functional energy and its partial
differential equation based on its level set function. We provide a proof of
the results and an implementation using MATLAB. Leveraging modern computer
vision methodologies, we propose a functional segmentation loss based on active
contours, utilizing pytorch.nn.ModuleLoss and a level set based on the
Chan-Vese algorithm. We compare our results with common computer vision
segmentation datasets and evaluate the performance of classical loss functions
against our proposed method. All code and materials used are available at
https://github.com/gguzzy/chan_vese_functional_loss.

</details>


### [79] [Assessing the Geolocation Capabilities, Limitations and Societal Risks of Generative Vision-Language Models](https://arxiv.org/abs/2508.19967)
*Oliver Grainge,Sania Waheed,Jack Stilgoe,Michael Milford,Shoaib Ehsan*

Main category: cs.CV

TL;DR: 论文评估了25种先进视觉语言模型（VLMs）的地理定位能力，发现其在社交媒体类图像上定位准确率高达61%，引发隐私担忧。


<details>
  <summary>Details</summary>
Motivation: 地理定位技术虽有益处，但VLMs的高精度可能带来隐私风险，目前缺乏对其能力的系统评估。

Method: 对25种VLMs在四个多样化环境的数据集上进行全面评估。

Result: VLMs在普通街景图像上表现不佳，但在社交媒体类图像上准确率达61%。

Conclusion: VLMs的地理定位能力存在显著隐私风险，需引起重视。

Abstract: Geo-localization is the task of identifying the location of an image using
visual cues alone. It has beneficial applications, such as improving disaster
response, enhancing navigation, and geography education. Recently,
Vision-Language Models (VLMs) are increasingly demonstrating capabilities as
accurate image geo-locators. This brings significant privacy risks, including
those related to stalking and surveillance, considering the widespread uses of
AI models and sharing of photos on social media. The precision of these models
is likely to improve in the future. Despite these risks, there is little work
on systematically evaluating the geolocation precision of Generative VLMs,
their limits and potential for unintended inferences. To bridge this gap, we
conduct a comprehensive assessment of the geolocation capabilities of 25
state-of-the-art VLMs on four benchmark image datasets captured in diverse
environments. Our results offer insight into the internal reasoning of VLMs and
highlight their strengths, limitations, and potential societal risks. Our
findings indicate that current VLMs perform poorly on generic street-level
images yet achieve notably high accuracy (61\%) on images resembling social
media content, raising significant and urgent privacy concerns.

</details>


### [80] [GLSim: Detecting Object Hallucinations in LVLMs via Global-Local Similarity](https://arxiv.org/abs/2508.19972)
*Seongheon Park,Yixuan Li*

Main category: cs.CV

TL;DR: GLSim是一种新的无需训练的对象幻觉检测框架，结合全局和局部嵌入相似性信号，显著提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅采用全局或局部视角，限制了检测可靠性。

Method: 利用图像和文本模态间的全局和局部嵌入相似性信号。

Result: GLSim在多样场景中表现优异，显著超越基线方法。

Conclusion: GLSim通过结合全局和局部信号，实现了更准确可靠的对象幻觉检测。

Abstract: Object hallucination in large vision-language models presents a significant
challenge to their safe deployment in real-world applications. Recent works
have proposed object-level hallucination scores to estimate the likelihood of
object hallucination; however, these methods typically adopt either a global or
local perspective in isolation, which may limit detection reliability. In this
paper, we introduce GLSim, a novel training-free object hallucination detection
framework that leverages complementary global and local embedding similarity
signals between image and text modalities, enabling more accurate and reliable
hallucination detection in diverse scenarios. We comprehensively benchmark
existing object hallucination detection methods and demonstrate that GLSim
achieves superior detection performance, outperforming competitive baselines by
a significant margin.

</details>


### [81] [GS: Generative Segmentation via Label Diffusion](https://arxiv.org/abs/2508.20020)
*Yuhao Chen,Shubin Chen,Liang Lin,Guangrun Wang*

Main category: cs.CV

TL;DR: GS（Generative Segmentation）是一种新框架，将分割任务视为生成任务，通过标签扩散直接生成分割掩码，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统方法将图像分割视为判别问题，而现有扩散模型仍以图像为中心。本文提出将分割本身作为生成任务，以提升空间和语义保真度。

Method: GS通过标签扩散直接生成分割掩码，结合输入图像和语言描述进行端到端训练。

Result: 在Panoptic Narrative Grounding基准测试中，GS显著优于现有判别和基于扩散的方法，达到新SOTA。

Conclusion: GS通过生成式分割框架，为语言驱动的图像分割任务提供了更优的解决方案。

Abstract: Language-driven image segmentation is a fundamental task in vision-language
understanding, requiring models to segment regions of an image corresponding to
natural language expressions. Traditional methods approach this as a
discriminative problem, assigning each pixel to foreground or background based
on semantic alignment. Recently, diffusion models have been introduced to this
domain, but existing approaches remain image-centric: they either (i) use image
diffusion models as visual feature extractors, (ii) synthesize segmentation
data via image generation to train discriminative models, or (iii) perform
diffusion inversion to extract attention cues from pre-trained image diffusion
models-thereby treating segmentation as an auxiliary process. In this paper, we
propose GS (Generative Segmentation), a novel framework that formulates
segmentation itself as a generative task via label diffusion. Instead of
generating images conditioned on label maps and text, GS reverses the
generative process: it directly generates segmentation masks from noise,
conditioned on both the input image and the accompanying language description.
This paradigm makes label generation the primary modeling target, enabling
end-to-end training with explicit control over spatial and semantic fidelity.
To demonstrate the effectiveness of our approach, we evaluate GS on Panoptic
Narrative Grounding (PNG), a representative and challenging benchmark for
multimodal segmentation that requires panoptic-level reasoning guided by
narrative captions. Experimental results show that GS significantly outperforms
existing discriminative and diffusion-based methods, setting a new
state-of-the-art for language-driven segmentation.

</details>


### [82] [Segmentation Assisted Incremental Test Time Adaptation in an Open World](https://arxiv.org/abs/2508.20029)
*Manogna Sreenivas,Soma Biswas*

Main category: cs.CV

TL;DR: 提出SegAssist模块，用于视觉语言模型在测试时增量适应新类别和新领域，通过主动标注和分割辅助提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决动态环境中模型面对未知类别和领域时的泛化能力问题。

Method: 结合主动标注技术和分割能力，提出SegAssist模块，无需训练即可优化样本选择。

Result: 在多个基准数据集上验证了SegAssist的有效性，提升了模型在持续适应新数据时的性能。

Conclusion: SegAssist为视觉语言模型在真实场景中的持续适应提供了有效解决方案。

Abstract: In dynamic environments, unfamiliar objects and distribution shifts are often
encountered, which challenge the generalization abilities of the deployed
trained models. This work addresses Incremental Test Time Adaptation of Vision
Language Models, tackling scenarios where unseen classes and unseen domains
continuously appear during testing. Unlike traditional Test Time Adaptation
approaches, where the test stream comes only from a predefined set of classes,
our framework allows models to adapt simultaneously to both covariate and label
shifts, actively incorporating new classes as they emerge. Towards this goal,
we establish a new benchmark for ITTA, integrating single image TTA methods for
VLMs with active labeling techniques that query an oracle for samples
potentially representing unseen classes during test time. We propose a
segmentation assisted active labeling module, termed SegAssist, which is
training free and repurposes the segmentation capabilities of VLMs to refine
active sample selection, prioritizing samples likely to belong to unseen
classes. Extensive experiments on several benchmark datasets demonstrate the
potential of SegAssist to enhance the performance of VLMs in real world
scenarios, where continuous adaptation to emerging data is essential.
Project-page:https://manogna-s.github.io/segassist/

</details>


### [83] [OpenM3D: Open Vocabulary Multi-view Indoor 3D Object Detection without Human Annotations](https://arxiv.org/abs/2508.20063)
*Peng-Hao Hsu,Ke Zhang,Fu-En Wang,Tao Tu,Ming-Feng Li,Yu-Lun Liu,Albert Y. C. Chen,Min Sun,Cheng-Hao Kuo*

Main category: cs.CV

TL;DR: OpenM3D是一种无需人工标注的开词汇多视角室内3D物体检测器，通过2D诱导的体素特征和CLIP特征对齐实现高效检测。


<details>
  <summary>Details</summary>
Motivation: 探索基于图像的开词汇3D物体检测方法，弥补现有方法在效率和准确性上的不足。

Method: 结合2D分割生成高质量3D伪框，并通过体素-语义对齐损失训练单阶段检测器。

Result: 在ScanNet200和ARKitScenes基准测试中，OpenM3D在精度和速度上均优于现有方法。

Conclusion: OpenM3D展示了高效且准确的开词汇3D物体检测能力，适用于室内场景。

Abstract: Open-vocabulary (OV) 3D object detection is an emerging field, yet its
exploration through image-based methods remains limited compared to 3D point
cloud-based methods. We introduce OpenM3D, a novel open-vocabulary multi-view
indoor 3D object detector trained without human annotations. In particular,
OpenM3D is a single-stage detector adapting the 2D-induced voxel features from
the ImGeoNet model. To support OV, it is jointly trained with a class-agnostic
3D localization loss requiring high-quality 3D pseudo boxes and a
voxel-semantic alignment loss requiring diverse pre-trained CLIP features. We
follow the training setting of OV-3DET where posed RGB-D images are given but
no human annotations of 3D boxes or classes are available. We propose a 3D
Pseudo Box Generation method using a graph embedding technique that combines 2D
segments into coherent 3D structures. Our pseudo-boxes achieve higher precision
and recall than other methods, including the method proposed in OV-3DET. We
further sample diverse CLIP features from 2D segments associated with each
coherent 3D structure to align with the corresponding voxel feature. The key to
training a highly accurate single-stage detector requires both losses to be
learned toward high-quality targets. At inference, OpenM3D, a highly efficient
detector, requires only multi-view images for input and demonstrates superior
accuracy and speed (0.3 sec. per scene) on ScanNet200 and ARKitScenes indoor
benchmarks compared to existing methods. We outperform a strong two-stage
method that leverages our class-agnostic detector with a ViT CLIP-based OV
classifier and a baseline incorporating multi-view depth estimator on both
accuracy and speed.

</details>


### [84] [Patch Progression Masked Autoencoder with Fusion CNN Network for Classifying Evolution Between Two Pairs of 2D OCT Slices](https://arxiv.org/abs/2508.20064)
*Philippe Zhang,Weili Jiang,Yihao Li,Jing Zhang,Sarah Matta,Yubo Tan,Hui Lin,Haoshen Wang,Jiangtian Pan,Hui Xu,Laurent Borderie,Alexandre Le Guilcher,Béatrice Cochener,Chubin Ou,Gwenolé Quellec,Mathieu Lamard*

Main category: cs.CV

TL;DR: 论文摘要介绍了通过OCT扫描监测AMD进展的方法，包括两个任务：分类OCT切片演化和预测未来三个月进展，团队采用融合CNN和自编码器技术，取得Top 10成绩。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过OCT扫描监测AMD进展，以制定更个性化的治疗方案。

Method: 任务1使用融合CNN网络和模型集成分类OCT切片演化；任务2提出Patch Progression Masked Autoencoder预测未来进展。

Result: 团队在两项任务中均进入Top 10。

Conclusion: 研究表明OCT扫描和深度学习技术可有效监测AMD进展，但团队因与组织者关联无法竞争奖项。

Abstract: Age-related Macular Degeneration (AMD) is a prevalent eye condition affecting
visual acuity. Anti-vascular endothelial growth factor (anti-VEGF) treatments
have been effective in slowing the progression of neovascular AMD, with better
outcomes achieved through timely diagnosis and consistent monitoring. Tracking
the progression of neovascular activity in OCT scans of patients with exudative
AMD allows for the development of more personalized and effective treatment
plans. This was the focus of the Monitoring Age-related Macular Degeneration
Progression in Optical Coherence Tomography (MARIO) challenge, in which we
participated. In Task 1, which involved classifying the evolution between two
pairs of 2D slices from consecutive OCT acquisitions, we employed a fusion CNN
network with model ensembling to further enhance the model's performance. For
Task 2, which focused on predicting progression over the next three months
based on current exam data, we proposed the Patch Progression Masked
Autoencoder that generates an OCT for the next exam and then classifies the
evolution between the current OCT and the one generated using our solution from
Task 1. The results we achieved allowed us to place in the Top 10 for both
tasks. Some team members are part of the same organization as the challenge
organizers; therefore, we are not eligible to compete for the prize.

</details>


### [85] [CODA: Coordinating the Cerebrum and Cerebellum for a Dual-Brain Computer Use Agent with Decoupled Reinforcement Learning](https://arxiv.org/abs/2508.20096)
*Zeyi Sun,Yuhang Cao,Jianze Liang,Qiushi Sun,Ziyu Liu,Zhixiong Zhang,Yuhang Zang,Xiaoyi Dong,Kai Chen,Dahua Lin,Jiaqi Wang*

Main category: cs.CV

TL;DR: CODA是一个可训练的复合框架，结合通用规划器和专业执行器，通过两阶段训练提升科学计算GUI中的自主代理性能。


<details>
  <summary>Details</summary>
Motivation: 解决科学计算GUI中自主代理在长期规划和精确执行之间的权衡问题，现有方法无法适应经验。

Method: 采用两阶段训练：专业化阶段训练专家规划器，泛化阶段整合轨迹数据微调最终规划器。

Result: 在ScienceBoard基准测试中，CODA显著优于基线模型，成为开源模型的新标杆。

Conclusion: CODA通过可训练框架实现了执行鲁棒性和跨领域泛化能力，解决了现有方法的局限性。

Abstract: Autonomous agents for Graphical User Interfaces (GUIs) face significant
challenges in specialized domains such as scientific computing, where both
long-horizon planning and precise execution are required. Existing approaches
suffer from a trade-off: generalist agents excel at planning but perform poorly
in execution, while specialized agents demonstrate the opposite weakness.
Recent compositional frameworks attempt to bridge this gap by combining a
planner and an actor, but they are typically static and non-trainable, which
prevents adaptation from experience. This is a critical limitation given the
scarcity of high-quality data in scientific domains. To address these
limitations, we introduce CODA, a novel and trainable compositional framework
that integrates a generalist planner (Cerebrum) with a specialist executor
(Cerebellum), trained via a dedicated two-stage pipeline. In the first stage,
Specialization, we apply a decoupled GRPO approach to train an expert planner
for each scientific application individually, bootstrapping from a small set of
task trajectories. In the second stage, Generalization, we aggregate all
successful trajectories from the specialized experts to build a consolidated
dataset, which is then used for supervised fine-tuning of the final planner.
This equips CODA with both robust execution and cross-domain generalization.
Evaluated on four challenging applications from the ScienceBoard benchmark,
CODA significantly outperforms baselines and establishes a new state of the art
among open-source models.

</details>


### [86] [PAUL: Uncertainty-Guided Partition and Augmentation for Robust Cross-View Geo-Localization under Noisy Correspondence](https://arxiv.org/abs/2508.20066)
*Zheng Li,Yanming Guo,WenZhe Liu,Xueyi Zhang,Zhaoyun Ding,Long Xu,Mingrui Lao*

Main category: cs.CV

TL;DR: PAUL框架通过不确定性学习和数据增强解决跨视角地理定位中的噪声对应问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法假设图像对完美对齐，但实际中GPS漂移等因素导致部分对应，噪声问题被忽视。

Method: PAUL通过不确定性感知的协同增强和证据协同训练，选择性地增强高置信区域并抑制噪声。

Result: PAUL在不同噪声比例下均优于其他噪声对应驱动的方法。

Conclusion: PAUL为噪声样本提供鲁棒监督，有效解决了NC-CVGL问题。

Abstract: Cross-view geo-localization is a critical task for UAV navigation, event
detection, and aerial surveying, as it enables matching between drone-captured
and satellite imagery. Most existing approaches embed multi-modal data into a
joint feature space to maximize the similarity of paired images. However, these
methods typically assume perfect alignment of image pairs during training,
which rarely holds true in real-world scenarios. In practice, factors such as
urban canyon effects, electromagnetic interference, and adverse weather
frequently induce GPS drift, resulting in systematic alignment shifts where
only partial correspondences exist between pairs. Despite its prevalence, this
source of noisy correspondence has received limited attention in current
research. In this paper, we formally introduce and address the Noisy
Correspondence on Cross-View Geo-Localization (NC-CVGL) problem, aiming to
bridge the gap between idealized benchmarks and practical applications. To this
end, we propose PAUL (Partition and Augmentation by Uncertainty Learning), a
novel framework that partitions and augments training data based on estimated
data uncertainty through uncertainty-aware co-augmentation and evidential
co-training. Specifically, PAUL selectively augments regions with high
correspondence confidence and utilizes uncertainty estimation to refine feature
learning, effectively suppressing noise from misaligned pairs. Distinct from
traditional filtering or label correction, PAUL leverages both data uncertainty
and loss discrepancy for targeted partitioning and augmentation, thus providing
robust supervision for noisy samples. Comprehensive experiments validate the
effectiveness of individual components in PAUL,which consistently achieves
superior performance over other competitive noisy-correspondence-driven methods
in various noise ratios.

</details>


### [87] [Seam360GS: Seamless 360° Gaussian Splatting from Real-World Omnidirectional Images](https://arxiv.org/abs/2508.20080)
*Changha Shin,Woong Oh Cho,Seon Joo Kim*

Main category: cs.CV

TL;DR: 提出了一种新的双鱼眼相机校准框架，结合3D高斯溅射管道，优化360度图像渲染。


<details>
  <summary>Details</summary>
Motivation: 消费级双鱼眼系统因镜头分离和角度失真导致全景图像不完美，需改进。

Method: 将双鱼眼相机模型融入3D高斯溅射管道，联合优化3D高斯参数与校准变量。

Result: 在真实数据集上验证，能从不完美图像生成无缝渲染，优于现有360度渲染模型。

Conclusion: 该框架有效解决了双鱼眼系统的视觉伪影问题，提升了360度图像合成质量。

Abstract: 360-degree visual content is widely shared on platforms such as YouTube and
plays a central role in virtual reality, robotics, and autonomous navigation.
However, consumer-grade dual-fisheye systems consistently yield imperfect
panoramas due to inherent lens separation and angular distortions. In this
work, we introduce a novel calibration framework that incorporates a
dual-fisheye camera model into the 3D Gaussian splatting pipeline. Our approach
not only simulates the realistic visual artifacts produced by dual-fisheye
cameras but also enables the synthesis of seamlessly rendered 360-degree
images. By jointly optimizing 3D Gaussian parameters alongside calibration
variables that emulate lens gaps and angular distortions, our framework
transforms imperfect omnidirectional inputs into flawless novel view synthesis.
Extensive evaluations on real-world datasets confirm that our method produces
seamless renderings-even from imperfect images-and outperforms existing
360-degree rendering models.

</details>


### [88] [AudioStory: Generating Long-Form Narrative Audio with Large Language Models](https://arxiv.org/abs/2508.20088)
*Yuxin Guo,Teng Wang,Yuying Ge,Shijie Ma,Yixiao Ge,Wei Zou,Ying Shan*

Main category: cs.CV

TL;DR: AudioStory是一个结合大型语言模型（LLM）和文本到音频（TTA）系统的框架，用于生成结构化的长音频叙事。


<details>
  <summary>Details</summary>
Motivation: 当前TTA生成技术在短音频合成上表现良好，但在长叙事音频上缺乏时间连贯性和组合推理能力。

Method: AudioStory通过LLM分解复杂叙事查询为有序子任务，并采用解耦的桥接机制和端到端训练。

Result: 实验表明，AudioStory在单音频生成和叙事音频生成上均优于现有TTA基线，指令跟随能力和音频保真度更高。

Conclusion: AudioStory为长音频叙事生成提供了高效解决方案，并通过AudioStory-10K基准验证了其优越性。

Abstract: Recent advances in text-to-audio (TTA) generation excel at synthesizing short
audio clips but struggle with long-form narrative audio, which requires
temporal coherence and compositional reasoning. To address this gap, we propose
AudioStory, a unified framework that integrates large language models (LLMs)
with TTA systems to generate structured, long-form audio narratives. AudioStory
possesses strong instruction-following reasoning generation capabilities. It
employs LLMs to decompose complex narrative queries into temporally ordered
sub-tasks with contextual cues, enabling coherent scene transitions and
emotional tone consistency. AudioStory has two appealing features: (1)
Decoupled bridging mechanism: AudioStory disentangles LLM-diffuser
collaboration into two specialized components, i.e., a bridging query for
intra-event semantic alignment and a residual query for cross-event coherence
preservation. (2) End-to-end training: By unifying instruction comprehension
and audio generation within a single end-to-end framework, AudioStory
eliminates the need for modular training pipelines while enhancing synergy
between components. Furthermore, we establish a benchmark AudioStory-10K,
encompassing diverse domains such as animated soundscapes and natural sound
narratives. Extensive experiments show the superiority of AudioStory on both
single-audio generation and narrative audio generation, surpassing prior TTA
baselines in both instruction-following ability and audio fidelity. Our code is
available at https://github.com/TencentARC/AudioStory

</details>


### [89] [Bridging Domain Gaps for Fine-Grained Moth Classification Through Expert-Informed Adaptation and Foundation Model Priors](https://arxiv.org/abs/2508.20089)
*Ross J Gardiner,Guillaume Mougeot,Sareh Rowlands,Benno I Simmons,Flemming Helsing,Toke Thomas Høye*

Main category: cs.CV

TL;DR: 提出一种轻量级分类方法，结合专家标记的野外数据和BioCLIP2模型的知识蒸馏，用于蛾类图像分类，显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 解决野外图像与标准图像之间的领域差异问题，以更高效地监测昆虫数量下降。

Method: 结合专家标记的少量野外数据和BioCLIP2模型的知识蒸馏，采用ConvNeXt-tiny架构。

Result: 在101种丹麦蛾类实验中，BioCLIP2表现优异，轻量级模型在保持精度的同时显著降低计算成本。

Conclusion: 为高效昆虫监测系统开发提供实用指南，并缩小领域差异以实现细粒度分类。

Abstract: Labelling images of Lepidoptera (moths) from automated camera systems is
vital for understanding insect declines. However, accurate species
identification is challenging due to domain shifts between curated images and
noisy field imagery. We propose a lightweight classification approach,
combining limited expert-labelled field data with knowledge distillation from
the high-performance BioCLIP2 foundation model into a ConvNeXt-tiny
architecture. Experiments on 101 Danish moth species from AMI camera systems
demonstrate that BioCLIP2 substantially outperforms other methods and that our
distilled lightweight model achieves comparable accuracy with significantly
reduced computational cost. These insights offer practical guidelines for the
development of efficient insect monitoring systems and bridging domain gaps for
fine-grained classification.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [90] [Inference of Human-derived Specifications of Object Placement via Demonstration](https://arxiv.org/abs/2508.19367)
*Alex Cuellar,Ho Chit Siu,Julie A Shah*

Main category: cs.RO

TL;DR: 论文提出了一种基于区域连接演算（RCC）的形式逻辑框架PARCC，用于描述物体在空间中的相对位置，并通过演示学习算法来推断PARCC规范。


<details>
  <summary>Details</summary>
Motivation: 现有方法在理解人类可接受的物体配置时，对捕捉人类重视的空间关系表达能力有限。

Method: 引入PARCC框架和基于演示学习的推理算法。

Result: 通过人类研究验证了PARCC框架能有效捕捉人类意图，且演示学习方法优于人工提供的规范。

Conclusion: PARCC框架和演示学习方法能提升机器人对人类物体排列规则的理解。

Abstract: As robots' manipulation capabilities improve for pick-and-place tasks (e.g.,
object packing, sorting, and kitting), methods focused on understanding
human-acceptable object configurations remain limited expressively with regard
to capturing spatial relationships important to humans. To advance robotic
understanding of human rules for object arrangement, we introduce
positionally-augmented RCC (PARCC), a formal logic framework based on region
connection calculus (RCC) for describing the relative position of objects in
space. Additionally, we introduce an inference algorithm for learning PARCC
specifications via demonstrations. Finally, we present the results from a human
study, which demonstrate our framework's ability to capture a human's intended
specification and the benefits of learning from demonstration approaches over
human-provided specifications.

</details>


### [91] [FlipWalker: Jacob's Ladder toy-inspired robot for locomotion across diverse, complex terrain](https://arxiv.org/abs/2508.19380)
*Diancheng Li,Nia Ralston,Bastiaan Hagen,Phoebe Tan,Matthew A. Robertson*

Main category: cs.RO

TL;DR: FlipWalker是一种新型欠驱动机器人系统，灵感来自Jacob's Ladder玩具，用于在轮式机器人难以通过的地形中移动。


<details>
  <summary>Details</summary>
Motivation: 设计一种能够在复杂地形中高效移动的机器人，克服传统轮式机器人的局限性。

Method: 采用两段式结构，通过柔性电缆连接，利用电机驱动的腿推动地面或另一段实现翻转运动。

Result: 原型机重0.78公斤，最大翻转速度为每秒0.2个身长，在草地、河石和雪地等复杂地形中表现良好。

Conclusion: FlipWalker的翻转策略为不规则地形导航提供了一种有前景的替代方案。

Abstract: This paper introduces FlipWalker, a novel underactuated robot locomotion
system inspired by Jacob's Ladder illusion toy, designed to traverse
challenging terrains where wheeled robots often struggle. Like the Jacob's
Ladder toy, FlipWalker features two interconnected segments joined by flexible
cables, enabling it to pivot and flip around singularities in a manner
reminiscent of the toy's cascading motion. Actuation is provided by
motor-driven legs within each segment that push off either the ground or the
opposing segment, depending on the robot's current configuration. A
physics-based model of the underactuated flipping dynamics is formulated to
elucidate the critical design parameters governing forward motion and obstacle
clearance or climbing. The untethered prototype weighs 0.78 kg, achieves a
maximum flipping speed of 0.2 body lengths per second. Experimental trials on
artificial grass, river rocks, and snow demonstrate that FlipWalker's flipping
strategy, which relies on ground reaction forces applied normal to the surface,
offers a promising alternative to traditional locomotion for navigating
irregular outdoor terrain.

</details>


### [92] [LaVA-Man: Learning Visual Action Representations for Robot Manipulation](https://arxiv.org/abs/2508.19391)
*Chaoran Zhu,Hengyi Wang,Yik Lung Pang,Changjae Oh*

Main category: cs.RO

TL;DR: 提出了一种通过自监督任务学习视觉-文本关联的方法，用于语言引导的机器人操作任务，并在多个基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过预训练视觉-语言模型测量视觉观察与文本指令的相似性，再训练模型映射到机器人动作，但这种方法限制了模型对视觉-文本关系的捕捉，导致操作任务精度降低。

Method: 通过自监督任务（重构被遮挡的目标图像）学习视觉-文本关联，无需机器人动作监督，随后用少量演示微调模型。

Result: 在五个基准测试（包括仿真和真实机器人验证）中表现优于现有方法。

Conclusion: 提出的方法能有效学习视觉-文本关联，提升机器人操作的精度和泛化能力。

Abstract: Visual-textual understanding is essential for language-guided robot
manipulation. Recent works leverage pre-trained vision-language models to
measure the similarity between encoded visual observations and textual
instructions, and then train a model to map this similarity to robot actions.
However, this two-step approach limits the model to capture the relationship
between visual observations and textual instructions, leading to reduced
precision in manipulation tasks. We propose to learn visual-textual
associations through a self-supervised pretext task: reconstructing a masked
goal image conditioned on an input image and textual instructions. This
formulation allows the model to learn visual-action representations without
robot action supervision. The learned representations can then be fine-tuned
for manipulation tasks with only a few demonstrations. We also introduce the
\textit{Omni-Object Pick-and-Place} dataset, which consists of annotated robot
tabletop manipulation episodes, including 180 object classes and 3,200
instances with corresponding textual instructions. This dataset enables the
model to acquire diverse object priors and allows for a more comprehensive
evaluation of its generalisation capability across object instances.
Experimental results on the five benchmarks, including both simulated and
real-robot validations, demonstrate that our method outperforms prior art.

</details>


### [93] [From Stoplights to On-Ramps: A Comprehensive Set of Crash Rate Benchmarks for Freeway and Surface Street ADS Evaluation](https://arxiv.org/abs/2508.19425)
*John M. Scanlon,Timothy L McMurry,Yin-Hsiu Chen,Kristofer D. Kusano,Trent Victor*

Main category: cs.RO

TL;DR: 本文提出了评估美国自动驾驶系统（ADS）的碰撞率基准，重点关注高速公路与城市道路的差异，强调了地理依赖性对碰撞率的影响。


<details>
  <summary>Details</summary>
Motivation: 扩展之前仅关注城市道路的基准，纳入高速公路碰撞风险，为未来ADS安全性能评估提供更全面的数据支持。

Method: 利用公开的警方报告碰撞数据和车辆行驶里程（VMT）数据，分离乘客车辆、道路类型分类和碰撞类型分析。

Result: 发现高速公路碰撞率存在显著地理差异（如亚特兰大比凤凰城高3.5倍），且碰撞类型随严重程度变化。

Conclusion: 需针对不同地区制定基准以避免评估偏差，并提供了统计显著里程的计算方法，为未来ADS评估奠定基础。

Abstract: This paper presents crash rate benchmarks for evaluating US-based Automated
Driving Systems (ADS) for multiple urban areas. The purpose of this study was
to extend prior benchmarks focused only on surface streets to additionally
capture freeway crash risk for future ADS safety performance assessments. Using
publicly available police-reported crash and vehicle miles traveled (VMT) data,
the methodology details the isolation of in-transport passenger vehicles, road
type classification, and crash typology. Key findings revealed that freeway
crash rates exhibit large geographic dependence variations with
any-injury-reported crash rates being nearly 3.5 times higher in Atlanta (2.4
IPMM; the highest) when compared to Phoenix (0.7 IPMM; the lowest). The results
show the critical need for location-specific benchmarks to avoid biased safety
evaluations and provide insights into the vehicle miles traveled (VMT) required
to achieve statistical significance for various safety impact levels. The
distribution of crash types depended on the outcome severity level. Higher
severity outcomes (e.g., fatal crashes) had a larger proportion of
single-vehicle, vulnerable road users (VRU), and opposite-direction collisions
compared to lower severity (police-reported) crashes. Given heterogeneity in
crash types by severity, performance in low-severity scenarios may not be
predictive of high-severity outcomes. These benchmarks are additionally used to
quantify at the required mileage to show statistically significant deviations
from human performance. This is the first paper to generate freeway-specific
benchmarks for ADS evaluation and provides a foundational framework for future
ADS benchmarking by evaluators and developers.

</details>


### [94] [An Iterative Approach for Heterogeneous Multi-Agent Route Planning with Resource Transportation Uncertainty and Temporal Logic Goals](https://arxiv.org/abs/2508.19429)
*Gustavo A. Cardona,Kaier Liang,Cristian-Ioan Vasile*

Main category: cs.RO

TL;DR: 提出了一种迭代方法，用于在资源分布未知的环境中规划异构多智能体路径，结合探索与任务完成。


<details>
  <summary>Details</summary>
Motivation: 解决异构机器人团队在未知资源分布环境中执行任务时的规划挑战。

Method: 引入基于Capability Temporal Logic的迭代算法，动态平衡探索与任务完成。

Result: 通过模拟案例验证了方法的有效性和性能。

Conclusion: 该方法为动态资源受限环境中的异构团队规划提供了鲁棒解决方案。

Abstract: This paper presents an iterative approach for heterogeneous multi-agent route
planning in environments with unknown resource distributions. We focus on a
team of robots with diverse capabilities tasked with executing missions
specified using Capability Temporal Logic (CaTL), a formal framework built on
Signal Temporal Logic to handle spatial, temporal, capability, and resource
constraints. The key challenge arises from the uncertainty in the initial
distribution and quantity of resources in the environment. To address this, we
introduce an iterative algorithm that dynamically balances exploration and task
fulfillment. Robots are guided to explore the environment, identifying resource
locations and quantities while progressively refining their understanding of
the resource landscape. At the same time, they aim to maximally satisfy the
mission objectives based on the current information, adapting their strategies
as new data is uncovered. This approach provides a robust solution for planning
in dynamic, resource-constrained environments, enabling efficient coordination
of heterogeneous teams even under conditions of uncertainty. Our method's
effectiveness and performance are demonstrated through simulated case studies.

</details>


### [95] [Gentle Object Retraction in Dense Clutter Using Multimodal Force Sensing and Imitation Learning](https://arxiv.org/abs/2508.19476)
*Dane Brouwer,Joshua Citron,Heather Nolte,Jeannette Bohg,Mark Cutkosky*

Main category: cs.RO

TL;DR: 论文研究了机器人如何通过非抓握触觉传感在密集物体中安全提取物体，发现结合触觉和力信息能显著提高成功率。


<details>
  <summary>Details</summary>
Motivation: 研究机器人如何在密集物体中安全提取物体，模仿人类利用非抓握触觉传感的能力。

Method: 使用模仿学习训练策略，结合多种传感模态（视觉、本体感觉、触觉、力信息等），并进行消融实验。

Result: 结合触觉和力信息的策略表现最佳，成功率比无力信息基线提高80%。

Conclusion: 触觉和力信息对机器人在密集物体中安全操作至关重要。

Abstract: Dense collections of movable objects are common in everyday spaces -- from
cabinets in a home to shelves in a warehouse. Safely retracting objects from
such collections is difficult for robots, yet people do it easily, using
non-prehensile tactile sensing on the sides and backs of their hands and arms.
We investigate the role of such sensing for training robots to gently reach
into constrained clutter and extract objects. The available sensing modalities
are (1) "eye-in-hand" vision, (2) proprioception, (3) non-prehensile triaxial
tactile sensing, (4) contact wrenches estimated from joint torques, and (5) a
measure of successful object acquisition obtained by monitoring the vacuum line
of a suction cup. We use imitation learning to train policies from a set of
demonstrations on randomly generated scenes, then conduct an ablation study of
wrench and tactile information. We evaluate each policy's performance across 40
unseen environment configurations. Policies employing any force sensing show
fewer excessive force failures, an increased overall success rate, and faster
completion times. The best performance is achieved using both tactile and
wrench information, producing an 80% improvement above the baseline without
force information.

</details>


### [96] [DATR: Diffusion-based 3D Apple Tree Reconstruction Framework with Sparse-View](https://arxiv.org/abs/2508.19508)
*Tian Qiu,Alan Zoubi,Yiyuan Lin,Ruiming Du,Lailiang Cheng,Yu Jiang*

Main category: cs.RO

TL;DR: DATR框架通过两阶段方法（树掩码生成和单图像到3D重建）解决了稀疏视角下苹果树3D重建的挑战，性能优于现有方法，并显著提升了效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在稀疏和遮挡视角下表现不佳，限制了数字孪生在农业中的应用。

Method: 采用两阶段框架：1）利用基础模型生成树掩码；2）结合扩散模型和大重建模型进行3D重建。

Result: 在真实和合成数据集上均优于现有方法，效率提升约360倍。

Conclusion: DATR框架展示了可扩展农业数字孪生系统的潜力。

Abstract: Digital twin applications offered transformative potential by enabling
real-time monitoring and robotic simulation through accurate virtual replicas
of physical assets. The key to these systems is 3D reconstruction with high
geometrical fidelity. However, existing methods struggled under field
conditions, especially with sparse and occluded views. This study developed a
two-stage framework (DATR) for the reconstruction of apple trees from sparse
views. The first stage leverages onboard sensors and foundation models to
semi-automatically generate tree masks from complex field images. Tree masks
are used to filter out background information in multi-modal data for the
single-image-to-3D reconstruction at the second stage. This stage consists of a
diffusion model and a large reconstruction model for respective multi view and
implicit neural field generation. The training of the diffusion model and LRM
was achieved by using realistic synthetic apple trees generated by a Real2Sim
data generator. The framework was evaluated on both field and synthetic
datasets. The field dataset includes six apple trees with field-measured ground
truth, while the synthetic dataset featured structurally diverse trees.
Evaluation results showed that our DATR framework outperformed existing 3D
reconstruction methods across both datasets and achieved domain-trait
estimation comparable to industrial-grade stationary laser scanners while
improving the throughput by $\sim$360 times, demonstrating strong potential for
scalable agricultural digital twin systems.

</details>


### [97] [A Lightweight Crowd Model for Robot Social Navigation](https://arxiv.org/abs/2508.19595)
*Maryam Kazemi Eskeri,Thomas Wiedemann,Ville Kyrki,Dominik Baumann,Tomasz Piotr Kucner*

Main category: cs.RO

TL;DR: 提出了一种轻量级的实时宏观人群预测模型，用于机器人导航，平衡了预测准确性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 机器人在人群密集环境中需要安全高效地导航，但现有模型要么计算成本高，要么过于简化。

Method: 基于行人流动特性简化时空处理，避免复杂架构。

Result: 推理时间减少3.6倍，预测准确性提高3.1%。

Conclusion: 高效的人群建模使机器人能在密集环境中导航，无需高计算成本。

Abstract: Robots operating in human-populated environments must navigate safely and
efficiently while minimizing social disruption. Achieving this requires
estimating crowd movement to avoid congested areas in real-time. Traditional
microscopic models struggle to scale in dense crowds due to high computational
cost, while existing macroscopic crowd prediction models tend to be either
overly simplistic or computationally intensive. In this work, we propose a
lightweight, real-time macroscopic crowd prediction model tailored for human
motion, which balances prediction accuracy and computational efficiency. Our
approach simplifies both spatial and temporal processing based on the inherent
characteristics of pedestrian flow, enabling robust generalization without the
overhead of complex architectures. We demonstrate a 3.6 times reduction in
inference time, while improving prediction accuracy by 3.1 %. Integrated into a
socially aware planning framework, the model enables efficient and socially
compliant robot navigation in dynamic environments. This work highlights that
efficient human crowd modeling enables robots to navigate dense environments
without costly computations.

</details>


### [98] [Impedance Primitive-augmented Hierarchical Reinforcement Learning for Sequential Tasks](https://arxiv.org/abs/2508.19607)
*Amin Berjaoui Tahmaz,Ravi Prakash,Jens Kober*

Main category: cs.RO

TL;DR: 提出了一种基于阻抗原语的层次强化学习框架，用于高效完成机器人顺序接触任务。


<details>
  <summary>Details</summary>
Motivation: 解决机器人操作中顺序接触任务的效率问题，通过可变刚度控制和层次化结构提升性能。

Method: 结合可变刚度控制动作空间、自适应刚度控制器和耦合感知，实现高效探索和合规性。

Result: 在学习和组合性方面优于现有方法，成功应用于多种任务（如开门、推物体等），并验证了仿真到现实的迁移能力。

Conclusion: 为自适应机器人操作系统奠定基础，适用于更复杂的接触任务。

Abstract: This paper presents an Impedance Primitive-augmented hierarchical
reinforcement learning framework for efficient robotic manipulation in
sequential contact tasks. We leverage this hierarchical structure to
sequentially execute behavior primitives with variable stiffness control
capabilities for contact tasks. Our proposed approach relies on three key
components: an action space enabling variable stiffness control, an adaptive
stiffness controller for dynamic stiffness adjustments during primitive
execution, and affordance coupling for efficient exploration while encouraging
compliance. Through comprehensive training and evaluation, our framework learns
efficient stiffness control capabilities and demonstrates improvements in
learning efficiency, compositionality in primitive selection, and success rates
compared to the state-of-the-art. The training environments include block
lifting, door opening, object pushing, and surface cleaning. Real world
evaluations further confirm the framework's sim2real capability. This work lays
the foundation for more adaptive and versatile robotic manipulation systems,
with potential applications in more complex contact-based tasks.

</details>


### [99] [Autonomous Aerial Manipulation at Arbitrary Pose in SE(3) with Robust Control and Whole-body Planning](https://arxiv.org/abs/2508.19608)
*Dongjae Lee,Byeongjun Kim,H. Jin Kim*

Main category: cs.RO

TL;DR: 提出了一种用于全向空中机械臂（OAM）的几何鲁棒控制和全身运动规划框架，以扩展其工作空间并实现复杂操作。


<details>
  <summary>Details</summary>
Motivation: 传统多旋翼机械臂由于基座欠驱动性，只能在小的滚转和俯仰角下操作。全向基座可以在任意姿态悬停，从而显著扩展操作空间。

Method: 设计了基于几何鲁棒控制的浮动基座控制器和两步优化的全身运动规划器，联合考虑基座姿态和机械臂关节角度。

Result: 实验表明，OAM能在近90°和180°俯仰角等极端姿态下稳定执行抓取和拉动任务。

Conclusion: 该框架使OAM能够在任意6D姿态下稳定操作，适用于复杂环境中的高级任务。

Abstract: Aerial manipulators based on conventional multirotors can conduct
manipulation only in small roll and pitch angles due to the underactuatedness
of the multirotor base. If the multirotor base is capable of hovering at
arbitrary orientation, the robot can freely locate itself at any point in
$\mathsf{SE}(3)$, significantly extending its manipulation workspace and
enabling a manipulation task that was originally not viable. In this work, we
present a geometric robust control and whole-body motion planning framework for
an omnidirectional aerial manipulator (OAM). To maximize the strength of OAM,
we first propose a geometric robust controller for a floating base. Since the
motion of the robotic arm and the interaction forces during manipulation affect
the stability of the floating base, the base should be capable of mitigating
these adverse effects while controlling its 6D pose. We then design a two-step
optimization-based whole-body motion planner, jointly considering the pose of
the floating base and the joint angles of the robotic arm to harness the entire
configuration space. The devised two-step approach facilitates real-time
applicability and enhances convergence of the optimization problem with
non-convex and non-Euclidean search space. The proposed approach enables the
base to be stationary at any 6D pose while autonomously carrying out
sophisticated manipulation near obstacles without any collision. We demonstrate
the effectiveness of the proposed framework through experiments in which an OAM
performs grasping and pulling of an object in multiple scenarios, including
near $90^\circ$ and even $180^\circ$ pitch angles.

</details>


### [100] [Embodied Intelligence for Sustainable Flight: A Soaring Robot with Active Morphological Control](https://arxiv.org/abs/2508.19684)
*Ghadeer Elmkaiel,Syn Schmitt,Michael Muehlebach*

Main category: cs.RO

TL;DR: Floaty是一种形状可变机器人，通过被动滑翔和智能形态控制实现高能效和敏捷机动性。


<details>
  <summary>Details</summary>
Motivation: 解决传统推进系统高能耗和固定翼设计缺乏悬停和机动能力的问题。

Method: 利用鸟类启发的智能形态控制，优化被动稳定性，并通过实验学习的空气动力学模型实现精确控制。

Result: 在风速达10 m/s的垂直气流中实现悬停、机动和抗干扰，能耗仅为10 W/kg。

Conclusion: Floaty为高能效空中机器人提供了新范式，利用形态智能在复杂风况下可持续运行。

Abstract: Achieving both agile maneuverability and high energy efficiency in aerial
robots, particularly in dynamic wind environments, remains challenging.
Conventional thruster-powered systems offer agility but suffer from high energy
consumption, while fixed-wing designs are efficient but lack hovering and
maneuvering capabilities. We present Floaty, a shape-changing robot that
overcomes these limitations by passively soaring, harnessing wind energy
through intelligent morphological control inspired by birds. Floaty's design is
optimized for passive stability, and its control policy is derived from an
experimentally learned aerodynamic model, enabling precise attitude and
position control without active propulsion. Wind tunnel experiments demonstrate
Floaty's ability to hover, maneuver, and reject disturbances in vertical
airflows up to 10 m/s. Crucially, Floaty achieves this with a specific power
consumption of 10 W/kg, an order of magnitude lower than thruster-powered
systems. This introduces a paradigm for energy-efficient aerial robotics,
leveraging morphological intelligence and control to operate sustainably in
challenging wind conditions.

</details>


### [101] [Efficient Human-Aware Task Allocation for Multi-Robot Systems in Shared Environments](https://arxiv.org/abs/2508.19731)
*Maryam Kazemi Eskeri,Ville Kyrki,Dominik Baumann,Tomasz Piotr Kucner*

Main category: cs.RO

TL;DR: 论文提出了一种基于动态地图（MoDs）的多机器人任务分配方法，显著减少了任务完成时间。


<details>
  <summary>Details</summary>
Motivation: 现有MRTA方法忽略人类动态行为，导致效率低下，需改进以适应共享环境。

Method: 利用动态地图（MoDs）捕捉人类运动模式，结合随机成本函数优化任务分配。

Result: 实验显示，新方法比静态方法减少26%任务完成时间，比基线减少19%。

Conclusion: 考虑人类动态对MRTA至关重要，新框架在多机器人系统中表现高效。

Abstract: Multi-robot systems are increasingly deployed in applications, such as
intralogistics or autonomous delivery, where multiple robots collaborate to
complete tasks efficiently. One of the key factors enabling their efficient
cooperation is Multi-Robot Task Allocation (MRTA). Algorithms solving this
problem optimize task distribution among robots to minimize the overall
execution time. In shared environments, apart from the relative distance
between the robots and the tasks, the execution time is also significantly
impacted by the delay caused by navigating around moving people. However, most
existing MRTA approaches are dynamics-agnostic, relying on static maps and
neglecting human motion patterns, leading to inefficiencies and delays. In this
paper, we introduce \acrfull{method name}. This method leverages Maps of
Dynamics (MoDs), spatio-temporal queryable models designed to capture
historical human movement patterns, to estimate the impact of humans on the
task execution time during deployment. \acrshort{method name} utilizes a
stochastic cost function that includes MoDs. Experimental results show that
integrating MoDs enhances task allocation performance, resulting in reduced
mission completion times by up to $26\%$ compared to the dynamics-agnostic
method and up to $19\%$ compared to the baseline. This work underscores the
importance of considering human dynamics in MRTA within shared environments and
presents an efficient framework for deploying multi-robot systems in
environments populated by humans.

</details>


### [102] [Elliptical K-Nearest Neighbors -- Path Optimization via Coulomb's Law and Invalid Vertices in C-space Obstacles](https://arxiv.org/abs/2508.19771)
*Liding Zhang,Zhenshan Bing,Yu Zhang,Kuanqi Cai,Lingyun Chen,Fan Wu,Sami Haddadin,Alois Knoll*

Main category: cs.RO

TL;DR: FDIT*是一种基于采样的路径规划算法，通过利用无效顶点信息和物理力原理（如库仑定律），提高了搜索效率和成本效益，适用于高维环境。


<details>
  <summary>Details</summary>
Motivation: 解决高维运动规划中的挑战，提升路径规划的速度和成本效益。

Method: 结合无效顶点信息和库仑定律，提出椭圆k近邻搜索方法，优化搜索区域。

Result: 在R^4到R^16的测试问题中表现优于现有单查询采样规划器，并在实际移动操作任务中验证。

Conclusion: FDIT*通过融合物理动力学和无效顶点数据，显著提升了收敛速度和路径质量。

Abstract: Path planning has long been an important and active research area in
robotics. To address challenges in high-dimensional motion planning, this study
introduces the Force Direction Informed Trees (FDIT*), a sampling-based planner
designed to enhance speed and cost-effectiveness in pathfinding. FDIT* builds
upon the state-of-the-art informed sampling planner, the Effort Informed Trees
(EIT*), by capitalizing on often-overlooked information in invalid vertices. It
incorporates principles of physical force, particularly Coulomb's law. This
approach proposes the elliptical $k$-nearest neighbors search method, enabling
fast convergence navigation and avoiding high solution cost or infeasible paths
by exploring more problem-specific search-worthy areas. It demonstrates
benefits in search efficiency and cost reduction, particularly in confined,
high-dimensional environments. It can be viewed as an extension of nearest
neighbors search techniques. Fusing invalid vertex data with physical dynamics
facilitates force-direction-based search regions, resulting in an improved
convergence rate to the optimum. FDIT* outperforms existing single-query,
sampling-based planners on the tested problems in R^4 to R^16 and has been
demonstrated on a real-world mobile manipulation task.

</details>


### [103] [Tree-Based Grafting Approach for Bidirectional Motion Planning with Local Subsets Optimization](https://arxiv.org/abs/2508.19776)
*Liding Zhang,Yao Ling,Zhenshan Bing,Fan Wu,Sami Haddadin,Alois Knoll*

Main category: cs.RO

TL;DR: G3T*是一种新型路径规划器，通过贪婪方法和动态调整采样分布，显著提高了双向搜索的效率和收敛速度。


<details>
  <summary>Details</summary>
Motivation: 解决双向运动规划中因懒惰反向搜索限制导致的失败和重启问题。

Method: 采用贪婪方法，利用GuILD子集的最小Lebesgue度量优化路径，并动态调整采样分布。

Result: 在R^2到R^8维度和实际机器人评估中表现优于现有单查询采样规划器。

Conclusion: G3T*通过改进路径收敛和成本优化，显著提升了双向运动规划的性能。

Abstract: Bidirectional motion planning often reduces planning time compared to its
unidirectional counterparts. It requires connecting the forward and reverse
search trees to form a continuous path. However, this process could fail and
restart the asymmetric bidirectional search due to the limitations of
lazy-reverse search. To address this challenge, we propose Greedy GuILD
Grafting Trees (G3T*), a novel path planner that grafts invalid edge
connections at both ends to re-establish tree-based connectivity, enabling
rapid path convergence. G3T* employs a greedy approach using the minimum
Lebesgue measure of guided incremental local densification (GuILD) subsets to
optimize paths efficiently. Furthermore, G3T* dynamically adjusts the sampling
distribution between the informed set and GuILD subsets based on historical and
current cost improvements, ensuring asymptotic optimality. These features
enhance the forward search's growth towards the reverse tree, achieving faster
convergence and lower solution costs. Benchmark experiments across dimensions
from R^2 to R^8 and real-world robotic evaluations demonstrate G3T*'s superior
performance compared to existing single-query sampling-based planners. A video
showcasing our experimental results is available at:
https://youtu.be/3mfCRL5SQIU

</details>


### [104] [Context-Aware Risk Estimation in Home Environments: A Probabilistic Framework for Service Robots](https://arxiv.org/abs/2508.19788)
*Sena Ishii,Akash Chikhalikar,Ankit A. Ravankar,Jose Victorio Salazar Luces,Yasuhisa Hirata*

Main category: cs.RO

TL;DR: 提出了一种新颖的框架，用于估计室内场景中的事故易发区域，以提高服务机器人在人机环境中的实时风险意识。


<details>
  <summary>Details</summary>
Motivation: 随着机器人融入日常生活，特别是在家庭环境中，预测和应对环境危险的能力对于确保用户安全、信任和有效的人机交互至关重要。

Method: 通过基于语义图的传播算法建模对象级风险和上下文，风险基于空间接近性和事故关系从高风险对象不对称传播到低风险对象。

Result: 在人工标注风险区域的数据集上验证，二元风险检测准确率达到75%，与人类感知高度一致。

Conclusion: 该框架展示了上下文感知风险推理在增强机器人场景理解和主动安全行为方面的潜力，可作为未来系统的基础。

Abstract: We present a novel framework for estimating accident-prone regions in
everyday indoor scenes, aimed at improving real-time risk awareness in service
robots operating in human-centric environments. As robots become integrated
into daily life, particularly in homes, the ability to anticipate and respond
to environmental hazards is crucial for ensuring user safety, trust, and
effective human-robot interaction. Our approach models object-level risk and
context through a semantic graph-based propagation algorithm. Each object is
represented as a node with an associated risk score, and risk propagates
asymmetrically from high-risk to low-risk objects based on spatial proximity
and accident relationship. This enables the robot to infer potential hazards
even when they are not explicitly visible or labeled. Designed for
interpretability and lightweight onboard deployment, our method is validated on
a dataset with human-annotated risk regions, achieving a binary risk detection
accuracy of 75%. The system demonstrates strong alignment with human
perception, particularly in scenes involving sharp or unstable objects. These
results underline the potential of context-aware risk reasoning to enhance
robotic scene understanding and proactive safety behaviors in shared
human-robot spaces. This framework could serve as a foundation for future
systems that make context-driven safety decisions, provide real-time alerts, or
autonomously assist users in avoiding or mitigating hazards within home
environments.

</details>


### [105] [APT*: Asymptotically Optimal Motion Planning via Adaptively Prolated Elliptical R-Nearest Neighbors](https://arxiv.org/abs/2508.19790)
*Liding Zhang,Sicheng Wang,Kuanqi Cai,Zhenshan Bing,Fan Wu,Chaoqun Wang,Sami Haddadin,Alois Knoll*

Main category: cs.RO

TL;DR: APT*是一种新型的基于采样的运动规划器，通过自适应批量大小和椭圆形最近邻模块动态调整路径搜索过程，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常使用固定批量大小且忽略障碍物信息，APT*旨在通过动态调整和虚拟力定义提升规划效率和效果。

Method: APT*结合自适应批量大小和椭圆形最近邻模块，利用库仑定律定义虚拟力，优化最近邻选择。

Result: APT*在R4到R16维度中表现优于现有方法，并在真实机器人操作任务中验证。

Conclusion: APT*通过动态调整和虚拟力定义显著提升了运动规划的效率和效果。

Abstract: Optimal path planning aims to determine a sequence of states from a start to
a goal while accounting for planning objectives. Popular methods often
integrate fixed batch sizes and neglect information on obstacles, which is not
problem-specific. This study introduces Adaptively Prolated Trees (APT*), a
novel sampling-based motion planner that extends based on Force Direction
Informed Trees (FDIT*), integrating adaptive batch-sizing and elliptical
$r$-nearest neighbor modules to dynamically modulate the path searching process
based on environmental feedback. APT* adjusts batch sizes based on the
hypervolume of the informed sets and considers vertices as electric charges
that obey Coulomb's law to define virtual forces via neighbor samples, thereby
refining the prolate nearest neighbor selection. These modules employ
non-linear prolate methods to adaptively adjust the electric charges of
vertices for force definition, thereby improving the convergence rate with
lower solution costs. Comparative analyses show that APT* outperforms existing
single-query sampling-based planners in dimensions from $\mathbb{R}^4$ to
$\mathbb{R}^{16}$, and it was further validated through a real-world robot
manipulation task. A video showcasing our experimental results is available at:
https://youtu.be/gCcUr8LiEw4

</details>


### [106] [A Standing Support Mobility Robot for Enhancing Independence in Elderly Daily Living](https://arxiv.org/abs/2508.19816)
*Ricardo J. Manríquez-Cisterna,Ankit A. Ravankar,Jose V. Salazar Luces,Takuro Hatsukari,Yasuhisa Hirata*

Main category: cs.RO

TL;DR: Moby是一款站立式辅助移动机器人，旨在提升老年人日常活动的独立性和安全性，支持直立姿势，减少体力消耗，并提供社交互动支持。


<details>
  <summary>Details</summary>
Motivation: 传统坐式移动辅助设备无法满足老年人直立活动的需求，Moby通过直立设计提升用户体验和独立性。

Method: Moby结合被动和主动移动支持，采用ROS系统实现手动和自主操作，集成NAV2和LiDAR进行导航。

Result: 实验通过NASA-TLX和时间对比验证了Moby的易用性、轻量化设计和高效辅助能力。

Conclusion: Moby为老年人提供了一种更独立、舒适的移动辅助解决方案，优于传统设备。

Abstract: This paper presents a standing support mobility robot "Moby" developed to
enhance independence and safety for elderly individuals during daily activities
such as toilet transfers. Unlike conventional seated mobility aids, the robot
maintains users in an upright posture, reducing physical strain, supporting
natural social interaction at eye level, and fostering a greater sense of
self-efficacy. Moby offers a novel alternative by functioning both passively
and with mobility support, enabling users to perform daily tasks more
independently. Its main advantages include ease of use, lightweight design,
comfort, versatility, and effective sit-to-stand assistance. The robot
leverages the Robot Operating System (ROS) for seamless control, featuring
manual and autonomous operation modes. A custom control system enables safe and
intuitive interaction, while the integration with NAV2 and LiDAR allows for
robust navigation capabilities. This paper reviews existing mobility solutions
and compares them to Moby, details the robot's design, and presents objective
and subjective experimental results using the NASA-TLX method and time
comparisons to other methods to validate our design criteria and demonstrate
the advantages of our contribution.

</details>


### [107] [FARM: Frame-Accelerated Augmentation and Residual Mixture-of-Experts for Physics-Based High-Dynamic Humanoid Control](https://arxiv.org/abs/2508.19926)
*Tan Jing,Shiting Chen,Yangfan Li,Weisheng Xu,Renjing Xu*

Main category: cs.RO

TL;DR: FARM框架通过帧加速增强和残差混合专家模型，显著提升了高动态人形控制的跟踪精度，同时保持低动态动作的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的人形控制器在温和动作上表现良好，但在高动态动作上表现不佳，限制了实际应用。

Method: FARM结合帧加速增强、基础控制器和残差混合专家模型，通过扩大帧间间隔和自适应分配网络容量来提升性能。

Result: 在HDHM数据集上，FARM将跟踪失败率降低42.8%，全局平均关节位置误差降低14.6%。

Conclusion: FARM成为高动态人形控制的新基准，并提供了首个公开的基准数据集。

Abstract: Unified physics-based humanoid controllers are pivotal for robotics and
character animation, yet models that excel on gentle, everyday motions still
stumble on explosive actions, hampering real-world deployment. We bridge this
gap with FARM (Frame-Accelerated Augmentation and Residual Mixture-of-Experts),
an end-to-end framework composed of frame-accelerated augmentation, a robust
base controller, and a residual mixture-of-experts (MoE). Frame-accelerated
augmentation exposes the model to high-velocity pose changes by widening
inter-frame gaps. The base controller reliably tracks everyday low-dynamic
motions, while the residual MoE adaptively allocates additional network
capacity to handle challenging high-dynamic actions, significantly enhancing
tracking accuracy. In the absence of a public benchmark, we curate the
High-Dynamic Humanoid Motion (HDHM) dataset, comprising 3593 physically
plausible clips. On HDHM, FARM reduces the tracking failure rate by 42.8\% and
lowers global mean per-joint position error by 14.6\% relative to the baseline,
while preserving near-perfect accuracy on low-dynamic motions. These results
establish FARM as a new baseline for high-dynamic humanoid control and
introduce the first open benchmark dedicated to this challenge. The code and
dataset will be released at https://github.com/Colin-Jing/FARM.

</details>


### [108] [Divide, Discover, Deploy: Factorized Skill Learning with Symmetry and Style Priors](https://arxiv.org/abs/2508.19953)
*Rafael Cathomen,Mayank Mittal,Marin Vlastelica,Marco Hutter*

Main category: cs.RO

TL;DR: 提出了一种模块化的无监督技能发现框架，通过状态空间分解和对称性偏置实现安全、可解释和可部署的技能学习。


<details>
  <summary>Details</summary>
Motivation: 解决现有无监督技能发现方法在安全性、可解释性和实际部署中的挑战。

Method: 采用用户定义的状态空间分解学习解耦技能表示，结合对称性偏置和风格因子提升技能结构化和安全性。

Result: 在四足机器人仿真中验证了框架有效性，并实现零样本迁移到真实硬件，技能表现与手工奖励策略相当。

Conclusion: 状态空间分解和对称性偏置有助于学习结构化、可解释的技能，风格因子和正则化提升了安全性和多样性。

Abstract: Unsupervised Skill Discovery (USD) allows agents to autonomously learn
diverse behaviors without task-specific rewards. While recent USD methods have
shown promise, their application to real-world robotics remains underexplored.
In this paper, we propose a modular USD framework to address the challenges in
the safety, interpretability, and deployability of the learned skills. Our
approach employs user-defined factorization of the state space to learn
disentangled skill representations. It assigns different skill discovery
algorithms to each factor based on the desired intrinsic reward function. To
encourage structured morphology-aware skills, we introduce symmetry-based
inductive biases tailored to individual factors. We also incorporate a style
factor and regularization penalties to promote safe and robust behaviors. We
evaluate our framework in simulation using a quadrupedal robot and demonstrate
zero-shot transfer of the learned skills to real hardware. Our results show
that factorization and symmetry lead to the discovery of structured
human-interpretable behaviors, while the style factor and penalties enhance
safety and diversity. Additionally, we show that the learned skills can be used
for downstream tasks and perform on par with oracle policies trained with
hand-crafted rewards.

</details>


### [109] [Long-VLA: Unleashing Long-Horizon Capability of Vision Language Action Model for Robot Manipulation](https://arxiv.org/abs/2508.19958)
*Yiguo Fan,Pengxiang Ding,Shuanghao Bai,Xinyang Tong,Yuyang Zhu,Hongchao Lu,Fengqi Dai,Wei Zhao,Yang Liu,Siteng Huang,Zhaoxin Fan,Badong Chen,Donglin Wang*

Main category: cs.RO

TL;DR: Long-VLA是一种专为长时程机器人任务设计的端到端视觉-语言-动作模型，通过相位感知输入掩码策略提升子任务兼容性，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有VLA框架主要解决短时程任务，在长时程多步机器人操作中因技能链和子任务依赖性问题效果有限。

Method: 提出相位感知输入掩码策略，将子任务分为移动和交互阶段，增强模型对阶段相关感官线索的关注。

Result: 在模拟和真实任务中，Long-VLA显著优于现有方法，为长时程机器人控制设立新基准。

Conclusion: Long-VLA通过统一策略提升长时程任务性能，且模块可无缝集成到现有VLA模型中。

Abstract: Vision-Language-Action (VLA) models have become a cornerstone in robotic
policy learning, leveraging large-scale multimodal data for robust and scalable
control. However, existing VLA frameworks primarily address short-horizon
tasks, and their effectiveness on long-horizon, multi-step robotic manipulation
remains limited due to challenges in skill chaining and subtask dependencies.
In this work, we introduce Long-VLA, the first end-to-end VLA model
specifically designed for long-horizon robotic tasks. Our approach features a
novel phase-aware input masking strategy that adaptively segments each subtask
into moving and interaction phases, enabling the model to focus on
phase-relevant sensory cues and enhancing subtask compatibility. This unified
strategy preserves the scalability and data efficiency of VLA training, and our
architecture-agnostic module can be seamlessly integrated into existing VLA
models. We further propose the L-CALVIN benchmark to systematically evaluate
long-horizon manipulation. Extensive experiments on both simulated and
real-world tasks demonstrate that Long-VLA significantly outperforms prior
state-of-the-art methods, establishing a new baseline for long-horizon robotic
control.

</details>


### [110] [Visio-Verbal Teleimpedance Interface: Enabling Semi-Autonomous Control of Physical Interaction via Eye Tracking and Speech](https://arxiv.org/abs/2508.20037)
*Henk H. A. Jekel,Alejandro Díaz Rosales,Luka Peternel*

Main category: cs.RO

TL;DR: 论文提出了一种结合视觉和语音的远程阻抗接口，用于通过操作者的注视和语音交互来指挥远程机器人的3D刚度椭球。


<details>
  <summary>Details</summary>
Motivation: 开发一种直观的交互方式，通过操作者的注视和语音指令来实时调整远程机器人的刚度，提高人机协作的效率和自然性。

Method: 使用眼动仪捕捉操作者的注视信息，结合语音交互和视觉语言模型（VLM）处理意图，生成相应的刚度矩阵。实验验证了接口在Kuka LBR iiwa机器人上的效果。

Result: 实验表明，接口能够有效生成刚度矩阵，并在滑入槽任务中展示了其功能多样性。

Conclusion: 该接口为远程机器人控制提供了一种自然且高效的交互方式，具有潜在的应用价值。

Abstract: The paper presents a visio-verbal teleimpedance interface for commanding 3D
stiffness ellipsoids to the remote robot with a combination of the operator's
gaze and verbal interaction. The gaze is detected by an eye-tracker, allowing
the system to understand the context in terms of what the operator is currently
looking at in the scene. Along with verbal interaction, a Visual Language Model
(VLM) processes this information, enabling the operator to communicate their
intended action or provide corrections. Based on these inputs, the interface
can then generate appropriate stiffness matrices for different physical
interaction actions. To validate the proposed visio-verbal teleimpedance
interface, we conducted a series of experiments on a setup including a Force
Dimension Sigma.7 haptic device to control the motion of the remote Kuka LBR
iiwa robotic arm. The human operator's gaze is tracked by Tobii Pro Glasses 2,
while human verbal commands are processed by a VLM using GPT-4o. The first
experiment explored the optimal prompt configuration for the interface. The
second and third experiments demonstrated different functionalities of the
interface on a slide-in-the-groove task.

</details>


### [111] [HERMES: Human-to-Robot Embodied Learning from Multi-Source Motion Data for Mobile Dexterous Manipulation](https://arxiv.org/abs/2508.20085)
*Zhecheng Yuan,Tianming Wei,Langzhe Gu,Pu Hua,Tianhai Liang,Yuanpei Chen,Huazhe Xu*

Main category: cs.RO

TL;DR: HERMES是一个将多源人类手部动作转化为机器人行为的框架，通过强化学习和sim2real方法实现通用性。


<details>
  <summary>Details</summary>
Motivation: 解决多指灵巧机器人高维动作空间和适应多样化环境条件的挑战。

Method: 采用统一强化学习方法转化人类动作，结合深度图像的sim2real迁移和PnP定位机制。

Result: 在多样化场景中表现出通用性，成功完成复杂任务。

Conclusion: HERMES框架在多源动作转化和环境适应性方面表现优异。

Abstract: Leveraging human motion data to impart robots with versatile manipulation
skills has emerged as a promising paradigm in robotic manipulation.
Nevertheless, translating multi-source human hand motions into feasible robot
behaviors remains challenging, particularly for robots equipped with
multi-fingered dexterous hands characterized by complex, high-dimensional
action spaces. Moreover, existing approaches often struggle to produce policies
capable of adapting to diverse environmental conditions. In this paper, we
introduce HERMES, a human-to-robot learning framework for mobile bimanual
dexterous manipulation. First, HERMES formulates a unified reinforcement
learning approach capable of seamlessly transforming heterogeneous human hand
motions from multiple sources into physically plausible robotic behaviors.
Subsequently, to mitigate the sim2real gap, we devise an end-to-end, depth
image-based sim2real transfer method for improved generalization to real-world
scenarios. Furthermore, to enable autonomous operation in varied and
unstructured environments, we augment the navigation foundation model with a
closed-loop Perspective-n-Point (PnP) localization mechanism, ensuring precise
alignment of visual goals and effectively bridging autonomous navigation and
dexterous manipulation. Extensive experimental results demonstrate that HERMES
consistently exhibits generalizable behaviors across diverse, in-the-wild
scenarios, successfully performing numerous complex mobile bimanual dexterous
manipulation tasks. Project Page:https:/gemcollector.github.io/HERMES/.

</details>


### [112] [Discrete-Guided Diffusion for Scalable and Safe Multi-Robot Motion Planning](https://arxiv.org/abs/2508.20095)
*Jinhao Liang,Sven Koenig,Ferdinando Fioretto*

Main category: cs.RO

TL;DR: 提出了一种结合离散MAPF求解器和生成扩散模型的新框架DGD，用于多机器人运动规划，解决了离散和连续方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 离散MAPF方法可扩展但轨迹质量低，连续优化方法轨迹质量高但难以扩展。DGD旨在结合两者优势。

Method: DGD框架分解非凸问题为凸子问题，结合MAPF解和优化技术引导扩散模型，并加入轻量级约束修复机制。

Result: 在复杂环境中扩展到100机器人，实现了高效规划和高成功率。

Conclusion: DGD在大型复杂环境中表现优异，结合了离散和连续方法的优势。

Abstract: Multi-Robot Motion Planning (MRMP) involves generating collision-free
trajectories for multiple robots operating in a shared continuous workspace.
While discrete multi-agent path finding (MAPF) methods are broadly adopted due
to their scalability, their coarse discretization severely limits trajectory
quality. In contrast, continuous optimization-based planners offer
higher-quality paths but suffer from the curse of dimensionality, resulting in
poor scalability with respect to the number of robots. This paper tackles the
limitations of these two approaches by introducing a novel framework that
integrates discrete MAPF solvers with constrained generative diffusion models.
The resulting framework, called Discrete-Guided Diffusion (DGD), has three key
characteristics: (1) it decomposes the original nonconvex MRMP problem into
tractable subproblems with convex configuration spaces, (2) it combines
discrete MAPF solutions with constrained optimization techniques to guide
diffusion models capture complex spatiotemporal dependencies among robots, and
(3) it incorporates a lightweight constraint repair mechanism to ensure
trajectory feasibility. The proposed method sets a new state-of-the-art
performance in large-scale, complex environments, scaling to 100 robots while
achieving planning efficiency and high success rates.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [113] [Physics-Informed Regression: Parameter Estimation in Parameter-Linear Nonlinear Dynamic Models](https://arxiv.org/abs/2508.19249)
*Jonas Søeborg Nielsen,Marcus Galea Jacobsen,Albert Brincker Olson,Mads Peter Sørensen,Allan Peter Engsig-Karup*

Main category: cs.LG

TL;DR: 提出了一种基于正则化最小二乘的混合参数估计方法PIR，用于参数线性非线性动态模型，性能优于PINN。


<details>
  <summary>Details</summary>
Motivation: 解决参数线性非线性动态模型的参数估计问题，结合物理模型与数据驱动方法。

Method: 使用正则化最小二乘（PIR）对ODE和PDE模型进行参数估计，并与PINN对比。

Result: PIR在复杂模型上表现优于PINN，计算速度更快。

Conclusion: PIR是一种高效可靠的参数估计方法，适用于实时应用。

Abstract: We present a new efficient hybrid parameter estimation method based on the
idea, that if nonlinear dynamic models are stated in terms of a system of
equations that is linear in terms of the parameters, then regularized ordinary
least squares can be used to estimate these parameters from time series data.
We introduce the term "Physics-Informed Regression" (PIR) to describe the
proposed data-driven hybrid technique as a way to bridge theory and data by use
of ordinary least squares to efficiently perform parameter estimation of the
model coefficients of different parameter-linear models; providing examples of
models based on nonlinear ordinary equations (ODE) and partial differential
equations (PDE). The focus is on parameter estimation on a selection of ODE and
PDE models, each illustrating performance in different model characteristics.
For two relevant epidemic models of different complexity and number of
parameters, PIR is tested and compared against the related technique,
physics-informed neural networks (PINN), both on synthetic data generated from
known target parameters and on real public Danish time series data collected
during the COVID-19 pandemic in Denmark. Both methods were able to estimate the
target parameters, while PIR showed to perform noticeably better, especially on
a compartment model with higher complexity. Given the difference in
computational speed, it is concluded that the PIR method is superior to PINN
for the models considered. It is also demonstrated how PIR can be applied to
estimate the time-varying parameters of a compartment model that is fitted
using real Danish data from the COVID-19 pandemic obtained during a period from
2020 to 2021. The study shows how data-driven and physics-informed techniques
may support reliable and fast -- possibly real-time -- parameter estimation in
parameter-linear nonlinear dynamic models.

</details>


### [114] [Lossless Compression of Neural Network Components: Weights, Checkpoints, and K/V Caches in Low-Precision Formats](https://arxiv.org/abs/2508.19263)
*Anat Heilper,Doron Singer*

Main category: cs.LG

TL;DR: 将ZipNN方法扩展到低精度浮点格式（FP8和FP4），设计了一种独立压缩指数和尾数的方法，实现了BF16和FP8的高压缩比，并探索了LLM中K/V缓存的压缩潜力。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习模型规模增大和部署普及，减少神经网络权重的存储和传输成本变得日益重要。

Method: 扩展ZipNN方法至低精度浮点格式（FP8和FP4），设计了一种独立压缩指数和尾数的熵编码方法。

Result: 实现了BF16压缩比达62%，FP8达83%，并发现LLM中的K/V缓存也具有可压缩性。

Conclusion: 低精度浮点格式的压缩方法能有效减少模型存储和传输成本，K/V缓存的压缩潜力为LLM部署提供了内存节省的可能。

Abstract: As deep learning models grow and deployment becomes more widespread, reducing
the storage and transmission costs of neural network weights has become
increasingly important. While prior work such as ZipNN has shown that lossless
compression methods - particularly those based on Huffman encoding
floating-point exponents can significantly reduce model sizes, these techniques
have primarily been applied to higher-precision formats such as FP32 and BF16.
In this work, we extend the ZipNN approach to lower-precision floating-point
formats, specifically FP8 and FP4, which are gaining popularity for efficient
inference. We design a compression method that separates and compresses the
exponent and mantissa components independently using entropy coding. Our
evaluation shows compression ratios up to 62% for BF16 and 83% for FP8. We also
investigate the compressibility of key-value (K/V) cache tensors used in large
language models (LLMs), finding that they, too, exhibit compressible patterns,
enabling memory savings during deployment.

</details>


### [115] [POT: Inducing Overthinking in LLMs via Black-Box Iterative Optimization](https://arxiv.org/abs/2508.19277)
*Xinyu Li,Tianjin Huang,Ronghui Mu,Xiaowei Huang,Gaojie Jin*

Main category: cs.LG

TL;DR: POT是一种新型黑盒攻击框架，通过LLM迭代优化生成隐蔽且语义自然的对抗提示，解决了现有方法依赖外部数据和检索的限制。


<details>
  <summary>Details</summary>
Motivation: 现有CoT提示方法增强了LLM的推理能力，但也引入了计算效率低下的漏洞，且传统攻击方法依赖外部知识或明显模板，实用性受限。

Method: 提出POT框架，利用LLM迭代优化生成对抗提示，无需外部数据或检索。

Result: 实验表明，POT在多种模型架构和数据集上表现优于其他方法。

Conclusion: POT提供了一种高效且实用的攻击方法，解决了现有技术的局限性。

Abstract: Recent advances in Chain-of-Thought (CoT) prompting have substantially
enhanced the reasoning capabilities of large language models (LLMs), enabling
sophisticated problem-solving through explicit multi-step reasoning traces.
However, these enhanced reasoning processes introduce novel attack surfaces,
particularly vulnerabilities to computational inefficiency through
unnecessarily verbose reasoning chains that consume excessive resources without
corresponding performance gains. Prior overthinking attacks typically require
restrictive conditions including access to external knowledge sources for data
poisoning, reliance on retrievable poisoned content, and structurally obvious
templates that limit practical applicability in real-world scenarios. To
address these limitations, we propose POT (Prompt-Only OverThinking), a novel
black-box attack framework that employs LLM-based iterative optimization to
generate covert and semantically natural adversarial prompts, eliminating
dependence on external data access and model retrieval. Extensive experiments
across diverse model architectures and datasets demonstrate that POT achieves
superior performance compared to other methods.

</details>


### [116] [(DEMO) Deep Reinforcement Learning Based Resource Allocation in Distributed IoT Systems](https://arxiv.org/abs/2508.19318)
*Aohan Li,Miyu Tsuzuki*

Main category: cs.LG

TL;DR: 提出了一种在分布式物联网环境中训练深度强化学习（DRL）模型的新框架，利用实际数据传输的反馈信息进行训练，验证了其可行性和有效性。


<details>
  <summary>Details</summary>
Motivation: 现有研究在真实分布式物联网系统中使用DRL进行资源分配的研究有限，本文旨在填补这一空白。

Method: 提出基于DRL的框架，物联网设备通过DRL方法选择通信信道，并利用实际数据传输的ACK反馈信息训练模型。

Result: 通过帧成功率（FSR）评估，证明了该框架的可行性和有效性。

Conclusion: 该框架为分布式物联网环境中的DRL模型训练提供了实用且高效的解决方案。

Abstract: Deep Reinforcement Learning (DRL) has emerged as an efficient approach to
resource allocation due to its strong capability in handling complex
decision-making tasks. However, only limited research has explored the training
of DRL models with real-world data in practical, distributed Internet of Things
(IoT) systems. To bridge this gap, this paper proposes a novel framework for
training DRL models in real-world distributed IoT environments. In the proposed
framework, IoT devices select communication channels using a DRL-based method,
while the DRL model is trained with feedback information. Specifically,
Acknowledgment (ACK) information is obtained from actual data transmissions
over the selected channels. Implementation and performance evaluation, in terms
of Frame Success Rate (FSR), are carried out, demonstrating both the
feasibility and the effectiveness of the proposed framework.

</details>


### [117] [Re:Frame -- Retrieving Experience From Associative Memory](https://arxiv.org/abs/2508.19344)
*Daniil Zelezetsky,Egor Cherepanov,Alexey K. Kovalev,Aleksandr I. Panov*

Main category: cs.LG

TL;DR: Re:Frame通过引入专家轨迹的关联记忆缓冲区，显著提升了离线强化学习在低质量数据上的性能。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习常面临数据质量低的问题，难以从次优数据中学习高性能策略。如何有效利用稀缺专家数据是关键挑战。

Method: 提出Re:Frame模块，通过关联记忆缓冲区（AMB）存储专家轨迹，训练时基于内容检索并整合专家数据。

Result: 在D4RL MuJoCo任务中，仅用0.1%的专家数据（60条轨迹），性能提升高达+10.7分。

Conclusion: Re:Frame提供了一种简单高效的方法，利用少量专家知识显著提升离线强化学习性能。

Abstract: Offline reinforcement learning (RL) often deals with suboptimal data when
collecting large expert datasets is unavailable or impractical. This limitation
makes it difficult for agents to generalize and achieve high performance, as
they must learn primarily from imperfect or inconsistent trajectories. A
central challenge is therefore how to best leverage scarce expert
demonstrations alongside abundant but lower-quality data. We demonstrate that
incorporating even a tiny amount of expert experience can substantially improve
RL agent performance. We introduce Re:Frame (Retrieving Experience From
Associative Memory), a plug-in module that augments a standard offline RL
policy (e.g., Decision Transformer) with a small external Associative Memory
Buffer (AMB) populated by expert trajectories drawn from a separate dataset.
During training on low-quality data, the policy learns to retrieve expert data
from the Associative Memory Buffer (AMB) via content-based associations and
integrate them into decision-making; the same AMB is queried at evaluation.
This requires no environment interaction and no modifications to the backbone
architecture. On D4RL MuJoCo tasks, using as few as 60 expert trajectories
(0.1% of a 6000-trajectory dataset), Re:Frame consistently improves over a
strong Decision Transformer baseline in three of four settings, with gains up
to +10.7 normalized points. These results show that Re:Frame offers a simple
and data-efficient way to inject scarce expert knowledge and substantially
improve offline RL from low-quality datasets.

</details>


### [118] [Memorization in Graph Neural Networks](https://arxiv.org/abs/2508.19352)
*Adarsh Jamadandi,Jing Xu,Adam Dziedzic,Franziska Boenisch*

Main category: cs.LG

TL;DR: NCMemo框架首次量化了半监督节点分类中的标签记忆效应，揭示了图同配性与记忆化的反比关系，并提出图重连方法以减少记忆化并保护隐私。


<details>
  <summary>Details</summary>
Motivation: 研究图神经网络（GNNs）中的记忆化现象，填补了该领域的研究空白，并探索其对隐私的影响。

Method: 通过NCMemo框架分析GNNs的训练动态，研究图同配性与记忆化的关系，并提出图重连方法。

Result: 低同配性图导致更高的记忆化，图重连方法有效减少记忆化且不影响模型性能，同时降低隐私风险。

Conclusion: 该研究深化了对GNN学习的理解，并支持更隐私保护的GNN部署。

Abstract: Deep neural networks (DNNs) have been shown to memorize their training data,
yet similar analyses for graph neural networks (GNNs) remain largely
under-explored. We introduce NCMemo (Node Classification Memorization), the
first framework to quantify label memorization in semi-supervised node
classification. We first establish an inverse relationship between memorization
and graph homophily, i.e., the property that connected nodes share similar
labels/features. We find that lower homophily significantly increases
memorization, indicating that GNNs rely on memorization to learn less
homophilic graphs. Secondly, we analyze GNN training dynamics. We find that the
increased memorization in low homophily graphs is tightly coupled to the GNNs'
implicit bias on using graph structure during learning. In low homophily
regimes, this structure is less informative, hence inducing memorization of the
node labels to minimize training loss. Finally, we show that nodes with higher
label inconsistency in their feature-space neighborhood are significantly more
prone to memorization. Building on our insights into the link between graph
homophily and memorization, we investigate graph rewiring as a means to
mitigate memorization. Our results demonstrate that this approach effectively
reduces memorization without compromising model performance. Moreover, we show
that it lowers the privacy risk for previously memorized data points in
practice. Thus, our work not only advances understanding of GNN learning but
also supports more privacy-preserving GNN deployment.

</details>


### [119] [Efficient Multi-Source Knowledge Transfer by Model Merging](https://arxiv.org/abs/2508.19353)
*Marcin Osial,Bartosz Wójcik,Bartosz Zieliński,Sebastian Cygert*

Main category: cs.LG

TL;DR: 提出了一种基于SVD的多源迁移学习框架，通过分解和聚合源模型的SVD组件，提升效率和精度。


<details>
  <summary>Details</summary>
Motivation: 现有迁移学习方法未能充分利用多源模型的潜力，且缺乏精细知识提取和高效聚合的能力。

Method: 利用SVD分解源模型为基本组件，选择最显著组件进行聚合，并通过微调主奇异值适应目标任务。

Result: 框架高效、鲁棒，能应对输入和参数空间的扰动，计算扩展性好。

Conclusion: 该方法显著提升了多源迁移学习的效率和适应性。

Abstract: While transfer learning is an advantageous strategy, it overlooks the
opportunity to leverage knowledge from numerous available models online.
Addressing this multi-source transfer learning problem is a promising path to
boost adaptability and cut re-training costs. However, existing approaches are
inherently coarse-grained, lacking the necessary precision for granular
knowledge extraction and the aggregation efficiency required to fuse knowledge
from either a large number of source models or those with high parameter
counts. We address these limitations by leveraging Singular Value Decomposition
(SVD) to first decompose each source model into its elementary, rank-one
components. A subsequent aggregation stage then selects only the most salient
components from all sources, thereby overcoming the previous efficiency and
precision limitations. To best preserve and leverage the synthesized knowledge
base, our method adapts to the target task by fine-tuning only the principal
singular values of the merged matrix. In essence, this process only
recalibrates the importance of top SVD components. The proposed framework
allows for efficient transfer learning, is robust to perturbations both at the
input level and in the parameter space (e.g., noisy or pruned sources), and
scales well computationally.

</details>


### [120] [Graph Data Modeling: Molecules, Proteins, & Chemical Processes](https://arxiv.org/abs/2508.19356)
*José Manuel Barraza-Chavez,Rana A. Barghout,Ricardo Almada-Monter,Benjamin Sanchez-Lengeling,Adrian Jinich,Radhakrishnan Mahadevan*

Main category: cs.LG

TL;DR: 这篇论文介绍了图数据模型在化学中的应用，特别是图神经网络在分子、蛋白质和化学过程中的作用。


<details>
  <summary>Details</summary>
Motivation: 化学科学中的分子、蛋白质和反应等可以用图结构自然描述，图模型能捕捉这些复杂结构和相互作用。

Method: 论文概述了图设计的基础、关键预测任务，以及机器学习在图建模中的角色，特别是图神经网络的应用。

Result: 通过图方法，读者可以更好地理解和应用图模型于化学发现的新一代技术。

Conclusion: 图数据模型和图神经网络为化学科学提供了强大的工具，有助于推动下一代化学发现。

Abstract: Graphs are central to the chemical sciences, providing a natural language to
describe molecules, proteins, reactions, and industrial processes. They capture
interactions and structures that underpin materials, biology, and medicine.
This primer, Graph Data Modeling: Molecules, Proteins, & Chemical Processes,
introduces graphs as mathematical objects in chemistry and shows how learning
algorithms (particularly graph neural networks) can operate on them. We outline
the foundations of graph design, key prediction tasks, representative examples
across chemical sciences, and the role of machine learning in graph-based
modeling. Together, these concepts prepare readers to apply graph methods to
the next generation of chemical discovery.

</details>


### [121] [Atrial Fibrillation Prediction Using a Lightweight Temporal Convolutional and Selective State Space Architecture](https://arxiv.org/abs/2508.19361)
*Yongbin Lee,Ki H. Chon*

Main category: cs.LG

TL;DR: 提出了一种轻量级深度学习模型，结合TCN和Mamba，用于早期预测房颤，性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 早期预测房颤（尤其是阵发性房颤）可减少疾病进展和并发症风险。

Method: 使用RR间隔数据，结合TCN和Mamba进行高效并行序列建模。

Result: 模型灵敏度0.908，特异性0.933，AUROC 0.972，可提前2小时预测房颤。

Conclusion: 该模型在准确性和计算效率上优于传统方法，适合临床预防干预。

Abstract: Atrial fibrillation (AF) is the most common arrhythmia, increasing the risk
of stroke, heart failure, and other cardiovascular complications. While AF
detection algorithms perform well in identifying persistent AF, early-stage
progression, such as paroxysmal AF (PAF), often goes undetected due to its
sudden onset and short duration. However, undetected PAF can progress into
sustained AF, increasing the risk of mortality and severe complications. Early
prediction of AF offers an opportunity to reduce disease progression through
preventive therapies, such as catecholamine-sparing agents or beta-blockers. In
this study, we propose a lightweight deep learning model using only RR
Intervals (RRIs), combining a Temporal Convolutional Network (TCN) for
positional encoding with Mamba, a selective state space model, to enable early
prediction of AF through efficient parallel sequence modeling. In subject-wise
testing results, our model achieved a sensitivity of 0.908, specificity of
0.933, F1-score of 0.930, AUROC of 0.972, and AUPRC of 0.932. Additionally, our
method demonstrates high computational efficiency, with only 73.5 thousand
parameters and 38.3 MFLOPs, outperforming traditional Convolutional Neural
Network-Recurrent Neural Network (CNN-RNN) approaches in both accuracy and
model compactness. Notably, the model can predict AF up to two hours in advance
using just 30 minutes of input data, providing enough lead time for preventive
interventions.

</details>


### [122] [Grounding the Ungrounded: A Spectral-Graph Framework for Quantifying Hallucinations in multimodal LLMs](https://arxiv.org/abs/2508.19366)
*Supratik Sarkar,Swagatam Das*

Main category: cs.LG

TL;DR: 本文提出了一种基于信息几何的框架，用于量化多模态大语言模型中的幻觉问题，从定性检测转向数学基础测量。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法多为启发式，缺乏理论基础和可操作保证，无法理解幻觉的产生、传播和跨模态交互。

Method: 通过将多模态输出表示为图拉普拉斯矩阵的谱嵌入，利用瑞利-里兹界限量化语义失真，并结合RKHS嵌入的模态感知度量。

Result: 提出了一种理论可解释的度量方法，能够捕捉幻觉随时间和输入提示的演变，为量化幻觉提供了理论基础。

Conclusion: 该框架将幻觉从定性风险转变为可分析和可量化的现象，为高风险领域提供了更可靠的AI评估方法。

Abstract: Hallucinations in large language models (LLMs) remain a fundamental obstacle
to trustworthy AI, particularly in high-stakes multimodal domains such as
medicine, law, and finance. Existing evaluation techniques are largely
heuristic -- anchored in qualitative benchmarking or ad-hoc empirical
mitigation -- providing neither principled quantification nor actionable
theoretical guarantees. This gap leaves a critical blind spot in understanding
how hallucinations arise, propagate, and interact across modalities. We
introduce the first (to our knowledge) rigorous information geometric framework
in diffusion dynamics for quantifying hallucinations in multimodal LLMs
(MLLMs), advancing the field from qualitative detection to mathematically
grounded measurement. Our approach represents MLLM outputs as the spectral
embeddings over multimodal graph Laplacians and characterizes the manifold gaps
of truth vs inconsistencies as the semantic distortion, enabling the tight
Rayleigh--Ritz bounds on the multimodal hallucination energy as a functional of
time-dependent temperature profiles. By leveraging eigenmode decompositions in
Reproducing Kernel Hilbert Space (RKHS) embeddings, our framework delivers
modality-aware, theoretically interpretable metrics that capture the evolution
of hallucinations across time and input prompts through temperature annealing.
This work establishes a principled foundation for quantifying and bounding
hallucinations, transforming them from a qualitative risk to a tractable,
analyzable phenomenon.

</details>


### [123] [Fine-Tuning Vision-Language Models for Neutrino Event Analysis in High-Energy Physics Experiments](https://arxiv.org/abs/2508.19376)
*Dikshant Sagar,Kaiwen Yu,Alejandro Yankelevich,Jianming Bian,Pierre Baldi*

Main category: cs.LG

TL;DR: 基于LLaMA 3.2的视觉语言模型（VLM）在高能物理实验中用于中微子相互作用分类，性能优于传统CNN，并支持多模态推理。


<details>
  <summary>Details</summary>
Motivation: 探索VLM在高能物理实验中的潜力，尤其是处理像素化探测器图像和多模态数据的能力。

Method: 使用基于LLaMA 3.2的VLM进行微调，并与CNN基线模型在分类准确率、精确率、召回率和AUC-ROC等指标上进行比较。

Result: VLM性能匹配或超过CNN，且能更好地整合辅助文本或语义上下文。

Conclusion: VLM为高能物理中的事件分类提供了通用且多模态的解决方案，有望推动实验性中微子物理的发展。

Abstract: Recent progress in large language models (LLMs) has shown strong potential
for multimodal reasoning beyond natural language. In this work, we explore the
use of a fine-tuned Vision-Language Model (VLM), based on LLaMA 3.2, for
classifying neutrino interactions from pixelated detector images in high-energy
physics (HEP) experiments. We benchmark its performance against an established
CNN baseline used in experiments like NOvA and DUNE, evaluating metrics such as
classification accuracy, precision, recall, and AUC-ROC. Our results show that
the VLM not only matches or exceeds CNN performance but also enables richer
reasoning and better integration of auxiliary textual or semantic context.
These findings suggest that VLMs offer a promising general-purpose backbone for
event classification in HEP, paving the way for multimodal approaches in
experimental neutrino physics.

</details>


### [124] [Towards Quantum Machine Learning for Malicious Code Analysis](https://arxiv.org/abs/2508.19381)
*Jesus Lopez,Saeefa Rubaiyet Nowmi,Viviana Cadena,Mohammad Saidur Rahman*

Main category: cs.LG

TL;DR: 论文研究了两种混合量子-经典模型（QMLP和QCNN）在恶意软件分类中的应用，展示了量子机器学习在恶意软件检测中的潜力。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算的兴起，量子机器学习（QML）为改进恶意软件检测提供了新的机会，但该领域的研究仍较少。

Method: 使用量子多层感知器（QMLP）和量子卷积神经网络（QCNN），通过角度嵌入将恶意软件特征编码为量子态。QMLP通过全量子比特测量和数据重上传捕获复杂模式，QCNN通过量子卷积和池化层减少活跃量子比特以加速训练。

Result: 在二进制分类任务中，模型在多个数据集上表现优异（最高96%准确率）。在多分类任务中，QMLP表现更优，而QCNN训练效率更高但准确率稍低。

Conclusion: QMLP在复杂多分类任务中表现更好，而QCNN在训练效率上有优势，量子机器学习在恶意软件分类中具有潜力。

Abstract: Classical machine learning (CML) has been extensively studied for malware
classification. With the emergence of quantum computing, quantum machine
learning (QML) presents a paradigm-shifting opportunity to improve malware
detection, though its application in this domain remains largely unexplored. In
this study, we investigate two hybrid quantum-classical models -- a Quantum
Multilayer Perceptron (QMLP) and a Quantum Convolutional Neural Network (QCNN),
for malware classification. Both models utilize angle embedding to encode
malware features into quantum states. QMLP captures complex patterns through
full qubit measurement and data re-uploading, while QCNN achieves faster
training via quantum convolution and pooling layers that reduce active qubits.
We evaluate both models on five widely used malware datasets -- API-Graph,
EMBER-Domain, EMBER-Class, AZ-Domain, and AZ-Class, across binary and
multiclass classification tasks.
  Our results show high accuracy for binary classification -- 95-96% on
API-Graph, 91-92% on AZ-Domain, and 77% on EMBER-Domain. In multiclass
settings, accuracy ranges from 91.6-95.7% on API-Graph, 41.7-93.6% on AZ-Class,
and 60.7-88.1% on EMBER-Class. Overall, QMLP outperforms QCNN in complex
multiclass tasks, while QCNN offers improved training efficiency at the cost of
reduced accuracy.

</details>


### [125] [DETNO: A Diffusion-Enhanced Transformer Neural Operator for Long-Term Traffic Forecasting](https://arxiv.org/abs/2508.19389)
*Owais Ahmad,Milad Ramezankhani,Anirudh Deodhar*

Main category: cs.LG

TL;DR: 提出了一种结合扩散模型和Transformer神经算子的新架构DETNO，用于解决交通流量预测中高频特征丢失的问题。


<details>
  <summary>Details</summary>
Motivation: 传统神经算子在预测高频交通现象（如冲击波和拥堵边界）时，由于平滑预测导致误差累积，无法满足实时交通管理的需求。

Method: DETNO结合了Transformer神经算子的跨注意力机制和扩散模型的迭代去噪，以重建高频交通细节。

Result: 在混沌交通数据集上，DETNO在长期预测中表现优于传统和基于Transformer的神经算子，保留了高频特征并提高了稳定性。

Conclusion: DETNO通过扩散增强的Transformer架构，有效解决了交通预测中的高频特征丢失和误差累积问题。

Abstract: Accurate long-term traffic forecasting remains a critical challenge in
intelligent transportation systems, particularly when predicting high-frequency
traffic phenomena such as shock waves and congestion boundaries over extended
rollout horizons. Neural operators have recently gained attention as promising
tools for modeling traffic flow. While effective at learning function space
mappings, they inherently produce smooth predictions that fail to reconstruct
high-frequency features such as sharp density gradients which results in rapid
error accumulation during multi-step rollout predictions essential for
real-time traffic management. To address these fundamental limitations, we
introduce a unified Diffusion-Enhanced Transformer Neural Operator (DETNO)
architecture. DETNO leverages a transformer neural operator with
cross-attention mechanisms, providing model expressivity and super-resolution,
coupled with a diffusion-based refinement component that iteratively
reconstructs high-frequency traffic details through progressive denoising. This
overcomes the inherent smoothing limitations and rollout instability of
standard neural operators. Through comprehensive evaluation on chaotic traffic
datasets, our method demonstrates superior performance in extended rollout
predictions compared to traditional and transformer-based neural operators,
preserving high-frequency components and improving stability over long
prediction horizons.

</details>


### [126] [Quantum-Classical Hybrid Molecular Autoencoder for Advancing Classical Decoding](https://arxiv.org/abs/2508.19394)
*Afrar Jahin,Yi Pan,Yingfeng Wang,Tianming Liu,Wei Zhang*

Main category: cs.LG

TL;DR: 提出了一种混合量子-经典架构用于SMILES重建，提升了量子保真度和经典相似性。


<details>
  <summary>Details</summary>
Motivation: 尽管量子机器学习在分子设计中潜力巨大，但现有方法在SMILES重建等任务中保真度不足。

Method: 结合量子编码与经典序列建模的混合架构。

Result: 量子保真度约84%，经典重建相似性60%，优于现有量子基线。

Conclusion: 为未来量子机器学习应用奠定基础，平衡量子表示与经典序列模型。

Abstract: Although recent advances in quantum machine learning (QML) offer significant
potential for enhancing generative models, particularly in molecular design, a
large array of classical approaches still face challenges in achieving high
fidelity and validity. In particular, the integration of QML with
sequence-based tasks, such as Simplified Molecular Input Line Entry System
(SMILES) string reconstruction, remains underexplored and usually suffers from
fidelity degradation. In this work, we propose a hybrid quantum-classical
architecture for SMILES reconstruction that integrates quantum encoding with
classical sequence modeling to improve quantum fidelity and classical
similarity. Our approach achieves a quantum fidelity of approximately 84% and a
classical reconstruction similarity of 60%, surpassing existing quantum
baselines. Our work lays a promising foundation for future QML applications,
striking a balance between expressive quantum representations and classical
sequence models and catalyzing broader research on quantum-aware sequence
models for molecular and drug discovery.

</details>


### [127] [Kolmogorov-Arnold Representation for Symplectic Learning: Advancing Hamiltonian Neural Networks](https://arxiv.org/abs/2508.19410)
*Zongyu Wu,Ruichen Xu,Luoyao Chen,Georgios Kementzidis,Siyao Wang,Yuefan Deng*

Main category: cs.LG

TL;DR: KAR-HNN是一种基于Kolmogorov-Arnold表示的哈密顿神经网络，通过单变量变换替代MLPs，提高了能量守恒和长期预测稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有HNNs依赖MLPs，导致对超参数敏感且难以处理复杂能量景观。

Method: 利用局部函数逼近捕捉高频和多尺度动态，减少能量漂移。

Result: 在四个基准问题上验证了其有效性，包括弹簧-质量、单摆、二体和三体问题。

Conclusion: KAR-HNN有望在高维和少参数的实际物理过程中实现准确稳定的建模。

Abstract: We propose a Kolmogorov-Arnold Representation-based Hamiltonian Neural
Network (KAR-HNN) that replaces the Multilayer Perceptrons (MLPs) with
univariate transformations. While Hamiltonian Neural Networks (HNNs) ensure
energy conservation by learning Hamiltonian functions directly from data,
existing implementations, often relying on MLPs, cause hypersensitivity to the
hyperparameters while exploring complex energy landscapes. Our approach
exploits the localized function approximations to better capture high-frequency
and multi-scale dynamics, reducing energy drift and improving long-term
predictive stability. The networks preserve the symplectic form of Hamiltonian
systems, and thus maintain interpretability and physical consistency. After
assessing KAR-HNN on four benchmark problems including spring-mass, simple
pendulum, two- and three-body problem, we foresee its effectiveness for
accurate and stable modeling of realistic physical processes often at high
dimensions and with few known parameters.

</details>


### [128] [Even Heads Fix Odd Errors: Mechanistic Discovery and Surgical Repair in Transformer Attention](https://arxiv.org/abs/2508.19414)
*Gustavo Sandoval*

Main category: cs.LG

TL;DR: Llama-3.1-8B-Instruct在特定格式下错误判断数字大小，研究发现其注意力头存在奇偶分工，修复需8个偶数头。


<details>
  <summary>Details</summary>
Motivation: 探究模型在特定格式下数字比较失败的原因，揭示注意力头的分工机制。

Method: 通过系统干预和SAE分析，研究注意力头的功能分工及修复阈值。

Result: 发现偶数头负责数字比较，修复需8个偶数头，特征重叠和权重变化是关键。

Conclusion: 模型模块需求隐藏了精细子结构，对可解释性和效率有启示。

Abstract: We present a mechanistic case study of a format-dependent reasoning failure
in Llama-3.1-8B-Instruct, where the model incorrectly judges "9.11" as larger
than "9.8" in chat or Q&A formats, but answers correctly in simple format.
Through systematic intervention, we discover transformers implement even/odd
attention head specialization: even indexed heads handle numerical comparison,
while odd heads serve incompatible functions. The bug requires exactly 8 even
heads at Layer 10 for perfect repair. Any combination of 8+ even heads
succeeds, while 7 or fewer completely fails, revealing sharp computational
thresholds with perfect redundancy among the 16 even heads. SAE analysis
reveals the mechanism: format representations separate (10% feature overlap at
Layer 7), then re-entangle with different weightings (80% feature overlap at
Layer 10), with specific features showing 1.5x amplification in failing
formats. We achieve perfect repair using only 25% of attention heads and
identify a 60% pattern replacement threshold, demonstrating that apparent
full-module requirements hide sophisticated substructure with implications for
interpretability and efficiency. All of our code is available at
https://github.com/gussand/surgeon.

</details>


### [129] [Differentiable multiphase flow model for physics-informed machine learning in reservoir pressure management](https://arxiv.org/abs/2508.19419)
*Harun Ur Rashid,Aleksandra Pachalieva,Daniel O'Malley*

Main category: cs.LG

TL;DR: 提出了一种结合物理模拟和卷积神经网络的机器学习方法，用于高效预测多相流体流动，显著减少计算成本。


<details>
  <summary>Details</summary>
Motivation: 地下储层压力控制因地质异质性和多相流体动力学而复杂，传统高保真模拟计算成本高。

Method: 结合可微分多相流模拟器和CNN，通过迁移学习从单相模拟预训练，再微调至多相场景。

Result: 仅需不到三千次多相模拟即可实现高精度预测，远低于之前千万次的需求。

Conclusion: 该方法通过物理信息机器学习显著提升了预测效率和实用性。

Abstract: Accurate subsurface reservoir pressure control is extremely challenging due
to geological heterogeneity and multiphase fluid-flow dynamics. Predicting
behavior in this setting relies on high-fidelity physics-based simulations that
are computationally expensive. Yet, the uncertain, heterogeneous properties
that control these flows make it necessary to perform many of these expensive
simulations, which is often prohibitive. To address these challenges, we
introduce a physics-informed machine learning workflow that couples a fully
differentiable multiphase flow simulator, which is implemented in the DPFEHM
framework with a convolutional neural network (CNN). The CNN learns to predict
fluid extraction rates from heterogeneous permeability fields to enforce
pressure limits at critical reservoir locations. By incorporating transient
multiphase flow physics into the training process, our method enables more
practical and accurate predictions for realistic injection-extraction scenarios
compare to previous works. To speed up training, we pretrain the model on
single-phase, steady-state simulations and then fine-tune it on full multiphase
scenarios, which dramatically reduces the computational cost. We demonstrate
that high-accuracy training can be achieved with fewer than three thousand
full-physics multiphase flow simulations -- compared to previous estimates
requiring up to ten million. This drastic reduction in the number of
simulations is achieved by leveraging transfer learning from much less
expensive single-phase simulations.

</details>


### [130] [MS-ConTab: Multi-Scale Contrastive Learning of Mutation Signatures for Pan Cancer Representation and Stratification](https://arxiv.org/abs/2508.19424)
*Yifan Dou,Adam Khadre,Ruben C Petreaca,Golrokh Mirzaei*

Main category: cs.LG

TL;DR: 提出了一种基于对比学习的无监督框架，用于聚类43种癌症类型，通过基因和染色体水平的突变特征，生成有生物学意义的癌症聚类。


<details>
  <summary>Details</summary>
Motivation: 理解泛癌突变景观对肿瘤发生机制至关重要，但现有的队列水平聚类方法主要依赖传统统计方法。

Method: 使用TabNet编码器和多尺度对比学习目标（NT-Xent损失）对基因和染色体水平的突变特征进行编码和优化。

Result: 生成的潜在表示能形成有生物学意义的癌症聚类，与已知突变过程和组织起源一致。

Conclusion: 首次将对比学习应用于队列水平癌症聚类，为突变驱动的癌症亚型分析提供了可扩展且可解释的框架。

Abstract: Motivation. Understanding the pan-cancer mutational landscape offers critical
insights into the molecular mechanisms underlying tumorigenesis. While
patient-level machine learning techniques have been widely employed to identify
tumor subtypes, cohort-level clustering, where entire cancer types are grouped
based on shared molecular features, has largely relied on classical statistical
methods.
  Results. In this study, we introduce a novel unsupervised contrastive
learning framework to cluster 43 cancer types based on coding mutation data
derived from the COSMIC database. For each cancer type, we construct two
complementary mutation signatures: a gene-level profile capturing nucleotide
substitution patterns across the most frequently mutated genes, and a
chromosome-level profile representing normalized substitution frequencies
across chromosomes. These dual views are encoded using TabNet encoders and
optimized via a multi-scale contrastive learning objective (NT-Xent loss) to
learn unified cancer-type embeddings. We demonstrate that the resulting latent
representations yield biologically meaningful clusters of cancer types,
aligning with known mutational processes and tissue origins. Our work
represents the first application of contrastive learning to cohort-level cancer
clustering, offering a scalable and interpretable framework for mutation-driven
cancer subtyping.

</details>


### [131] [Data-Augmented Few-Shot Neural Stencil Emulation for System Identification of Computer Models](https://arxiv.org/abs/2508.19441)
*Sanket Jantre,Deepak Akhare,Xiaoning Qian,Nathan M. Urban*

Main category: cs.LG

TL;DR: 提出一种基于空间填充采样的数据增强策略，用于高效生成神经PDE的训练数据。


<details>
  <summary>Details</summary>
Motivation: 传统神经PDE训练依赖长时间积分轨迹数据，存在冗余且难以泛化。

Method: 通过空间填充采样局部“模板”状态，减少冗余并增强泛化能力。

Result: 仅需10个时间步的等效计算即可训练出准确的神经PDE模板算子。

Conclusion: 数据增强策略显著提升神经PDE性能，优于传统轨迹采样方法。

Abstract: Partial differential equations (PDEs) underpin the modeling of many natural
and engineered systems. It can be convenient to express such models as neural
PDEs rather than using traditional numerical PDE solvers by replacing part or
all of the PDE's governing equations with a neural network representation.
Neural PDEs are often easier to differentiate, linearize, reduce, or use for
uncertainty quantification than the original numerical solver. They are usually
trained on solution trajectories obtained by long time integration of the PDE
solver. Here we propose a more sample-efficient data-augmentation strategy for
generating neural PDE training data from a computer model by space-filling
sampling of local "stencil" states. This approach removes a large degree of
spatiotemporal redundancy present in trajectory data and oversamples states
that may be rarely visited but help the neural PDE generalize across the state
space. We demonstrate that accurate neural PDE stencil operators can be learned
from synthetic training data generated by the computational equivalent of 10
timesteps' worth of numerical simulation. Accuracy is further improved if we
assume access to a single full-trajectory simulation from the computer model,
which is typically available in practice. Across several PDE systems, we show
that our data-augmented synthetic stencil data yield better trained neural
stencil operators, with clear performance gains compared with naively sampled
stencil data from simulation trajectories.

</details>


### [132] [Efficiently Generating Multidimensional Calorimeter Data with Tensor Decomposition Parameterization](https://arxiv.org/abs/2508.19443)
*Paimon Goulart,Shaan Pakala,Evangelos Papalexakis*

Main category: cs.LG

TL;DR: 论文提出了一种通过内部张量分解进一步降低生成模型成本的方法，适用于多维数据生成。


<details>
  <summary>Details</summary>
Motivation: 生成复杂模拟数据通常耗时耗资源，尤其是昂贵实验时，合成数据生成变得更为合理。

Method: 在生成模型中引入内部张量分解，生成较小的张量因子而非完整张量，以减少输出和参数。

Result: 实验表明生成的数据仍保持有用性，同时显著降低了生成成本。

Conclusion: 张量分解有潜力提高生成模型的效率，尤其适用于多维数据生成。

Abstract: Producing large complex simulation datasets can often be a time and resource
consuming task. Especially when these experiments are very expensive, it is
becoming more reasonable to generate synthetic data for downstream tasks.
Recently, these methods may include using generative machine learning models
such as Generative Adversarial Networks or diffusion models. As these
generative models improve efficiency in producing useful data, we introduce an
internal tensor decomposition to these generative models to even further reduce
costs. More specifically, for multidimensional data, or tensors, we generate
the smaller tensor factors instead of the full tensor, in order to
significantly reduce the model's output and overall parameters. This reduces
the costs of generating complex simulation data, and our experiments show the
generated data remains useful. As a result, tensor decomposition has the
potential to improve efficiency in generative models, especially when
generating multidimensional data, or tensors.

</details>


### [133] [On Surjectivity of Neural Networks: Can you elicit any behavior from your model?](https://arxiv.org/abs/2508.19445)
*Haozhe Jiang,Nika Haghtalab*

Main category: cs.LG

TL;DR: 论文研究了神经网络是否总能生成任意指定输出（即是否具有满射性），并证明了许多现代神经架构（如预层归一化和线性注意力模块）几乎总是满射的。


<details>
  <summary>Details</summary>
Motivation: 探讨神经网络生成有害或不良内容的能力，揭示模型安全和越狱漏洞的潜在风险。

Method: 通过数学证明，分析现代神经架构（如预层归一化和线性注意力模块）的满射性。

Result: 证明许多常用神经架构（如GPT风格Transformer和确定性ODE求解的扩散模型）对任意输出存在逆映射。

Conclusion: 研究揭示了现代神经架构对一类广泛对抗攻击的不可避免的脆弱性。

Abstract: Given a trained neural network, can any specified output be generated by some
input? Equivalently, does the network correspond to a function that is
surjective? In generative models, surjectivity implies that any output,
including harmful or undesirable content, can in principle be generated by the
networks, raising concerns about model safety and jailbreak vulnerabilities. In
this paper, we prove that many fundamental building blocks of modern neural
architectures, such as networks with pre-layer normalization and
linear-attention modules, are almost always surjective. As corollaries, widely
used generative frameworks, including GPT-style transformers and diffusion
models with deterministic ODE solvers, admit inverse mappings for arbitrary
outputs. By studying surjectivity of these modern and commonly used neural
architectures, we contribute a formalism that sheds light on their unavoidable
vulnerability to a broad class of adversarial attacks.

</details>


### [134] [The Sample Complexity of Membership Inference and Privacy Auditing](https://arxiv.org/abs/2508.19458)
*Mahdi Haghifam,Adam Smith,Jonathan Ullman*

Main category: cs.LG

TL;DR: 论文研究了成员推理攻击中攻击者所需的最小参考样本数量，发现攻击者有时需要比训练算法更多的样本。


<details>
  <summary>Details</summary>
Motivation: 探讨成员推理攻击中攻击者所需的信息量，特别是样本复杂度，以揭示现有攻击可能低估了成员推理的可能性。

Method: 在高斯均值估计的基本设置中，分析攻击者成功进行成员推理所需的最小参考样本数量。

Result: 发现攻击者有时需要比训练算法更多的样本（Ω(n + n²ρ²)），现有攻击可能低估了成员推理的可能性。

Conclusion: 研究结果表明，当攻击者容易获取分布信息时，可能存在更有效的成员推理攻击。

Abstract: A membership-inference attack gets the output of a learning algorithm, and a
target individual, and tries to determine whether this individual is a member
of the training data or an independent sample from the same distribution. A
successful membership-inference attack typically requires the attacker to have
some knowledge about the distribution that the training data was sampled from,
and this knowledge is often captured through a set of independent reference
samples from that distribution. In this work we study how much information the
attacker needs for membership inference by investigating the sample
complexity-the minimum number of reference samples required-for a successful
attack. We study this question in the fundamental setting of Gaussian mean
estimation where the learning algorithm is given $n$ samples from a Gaussian
distribution $\mathcal{N}(\mu,\Sigma)$ in $d$ dimensions, and tries to estimate
$\hat\mu$ up to some error $\mathbb{E}[\|\hat \mu - \mu\|^2_{\Sigma}]\leq
\rho^2 d$. Our result shows that for membership inference in this setting,
$\Omega(n + n^2 \rho^2)$ samples can be necessary to carry out any attack that
competes with a fully informed attacker. Our result is the first to show that
the attacker sometimes needs many more samples than the training algorithm uses
to train the model. This result has significant implications for practice, as
all attacks used in practice have a restricted form that uses $O(n)$ samples
and cannot benefit from $\omega(n)$ samples. Thus, these attacks may be
underestimating the possibility of membership inference, and better attacks may
be possible when information about the distribution is easy to obtain.

</details>


### [135] [Incentivized Lipschitz Bandits](https://arxiv.org/abs/2508.19466)
*Sourav Chakraborty,Amit Kiran Rege,Claire Monteleoni,Lijun Chen*

Main category: cs.LG

TL;DR: 研究在无限多臂的连续度量空间中，通过激励探索解决多臂老虎机问题，提出算法实现次线性累积遗憾和补偿。


<details>
  <summary>Details</summary>
Motivation: 解决经典多臂老虎机模型中，决策者激励短视代理探索时面临的奖励漂移问题。

Method: 提出均匀离散化无限臂空间的激励探索算法，适用于连续度量空间和上下文老虎机。

Result: 算法实现次线性累积遗憾和补偿，理论边界为$\Tilde{O}(T^{d+1/d+2})$。

Conclusion: 通过数值模拟验证理论结果，算法在无限臂和上下文场景中表现优异。

Abstract: We study incentivized exploration in multi-armed bandit (MAB) settings with
infinitely many arms modeled as elements in continuous metric spaces. Unlike
classical bandit models, we consider scenarios where the decision-maker
(principal) incentivizes myopic agents to explore beyond their greedy choices
through compensation, but with the complication of reward drift--biased
feedback arising due to the incentives. We propose novel incentivized
exploration algorithms that discretize the infinite arm space uniformly and
demonstrate that these algorithms simultaneously achieve sublinear cumulative
regret and sublinear total compensation. Specifically, we derive regret and
compensation bounds of $\Tilde{O}(T^{d+1/d+2})$, with $d$ representing the
covering dimension of the metric space. Furthermore, we generalize our results
to contextual bandits, achieving comparable performance guarantees. We validate
our theoretical findings through numerical simulations.

</details>


### [136] [DeepAtlas: a tool for effective manifold learning](https://arxiv.org/abs/2508.19479)
*Serena Hughes,Timothy Hamilton,Tom Kolokotrones,Eric J. Deeds*

Main category: cs.LG

TL;DR: DeepAtlas是一种算法，通过生成数据的局部邻域低维表示并训练深度神经网络来验证流形假设，适用于多种数据集。


<details>
  <summary>Details</summary>
Motivation: 验证流形假设是否适用于高维数据集，并提供一种工具来学习流形结构。

Method: 生成数据的局部邻域低维表示，训练深度神经网络映射局部嵌入与原始数据，利用拓扑失真评估流形假设。

Result: DeepAtlas能成功学习流形结构，但发现许多真实数据集（如单细胞RNA测序）不符合流形假设。

Conclusion: DeepAtlas在数据符合流形假设时能构建生成模型，并为应用微分几何工具提供可能。

Abstract: Manifold learning builds on the "manifold hypothesis," which posits that data
in high-dimensional datasets are drawn from lower-dimensional manifolds.
Current tools generate global embeddings of data, rather than the local maps
used to define manifolds mathematically. These tools also cannot assess whether
the manifold hypothesis holds true for a dataset. Here, we describe DeepAtlas,
an algorithm that generates lower-dimensional representations of the data's
local neighborhoods, then trains deep neural networks that map between these
local embeddings and the original data. Topological distortion is used to
determine whether a dataset is drawn from a manifold and, if so, its
dimensionality. Application to test datasets indicates that DeepAtlas can
successfully learn manifold structures. Interestingly, many real datasets,
including single-cell RNA-sequencing, do not conform to the manifold
hypothesis. In cases where data is drawn from a manifold, DeepAtlas builds a
model that can be used generatively and promises to allow the application of
powerful tools from differential geometry to a variety of datasets.

</details>


### [137] [Distribution Shift Aware Neural Tabular Learning](https://arxiv.org/abs/2508.19486)
*Wangyang Ying,Nanxu Gong,Dongjie Wang,Xinyuan Wang,Arun Vignesh Malarkkan,Vivek Gupta,Chandan K. Reddy,Yanjie Fu*

Main category: cs.LG

TL;DR: SAFT框架通过连续表示生成范式解决表格学习中的分布偏移问题，提升鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 表格学习在训练和测试数据分布偏移时效果下降，需要一种新方法应对此挑战。

Method: 提出SAFT框架，包括嵌入解相关、样本重加权、次优嵌入平均和归一化对齐三种机制。

Result: SAFT在多种真实分布偏移下优于现有方法，表现更鲁棒和有效。

Conclusion: SAFT成功将表格学习重构为连续优化问题，显著提升分布偏移下的性能。

Abstract: Tabular learning transforms raw features into optimized spaces for downstream
tasks, but its effectiveness deteriorates under distribution shifts between
training and testing data. We formalize this challenge as the Distribution
Shift Tabular Learning (DSTL) problem and propose a novel Shift-Aware Feature
Transformation (SAFT) framework to address it. SAFT reframes tabular learning
from a discrete search task into a continuous representation-generation
paradigm, enabling differentiable optimization over transformed feature sets.
SAFT integrates three mechanisms to ensure robustness: (i) shift-resistant
representation via embedding decorrelation and sample reweighting, (ii)
flatness-aware generation through suboptimal embedding averaging, and (iii)
normalization-based alignment between training and test distributions.
Extensive experiments show that SAFT consistently outperforms prior tabular
learning methods in terms of robustness, effectiveness, and generalization
ability under diverse real-world distribution shifts.

</details>


### [138] [Data-Efficient Symbolic Regression via Foundation Model Distillation](https://arxiv.org/abs/2508.19487)
*Wangyang Ying,Jinghan Zhang,Haoyue Bai,Nanxu Gong,Xinyuan Wang,Kunpeng Liu,Chandan K. Reddy,Yanjie Fu*

Main category: cs.LG

TL;DR: EQUATE是一种通过质量对齐转移嵌入的数据高效微调框架，用于在低数据量下进行符号方程发现。


<details>
  <summary>Details</summary>
Motivation: 基础模型在大规模方程数据集上预训练后，在小规模、特定领域数据集上表现不佳，存在负迁移和泛化能力差的问题。

Method: EQUATE结合符号-数值对齐和评估器引导的嵌入优化，将离散方程搜索转化为共享嵌入空间中的连续优化任务。

Result: 在三个标准公共基准测试中，EQUATE在准确性和鲁棒性上均优于现有基线方法，同时保持低复杂度和快速推理。

Conclusion: EQUATE是一种实用且可推广的解决方案，适用于基础模型蒸馏设置中的数据高效符号回归。

Abstract: Discovering interpretable mathematical equations from observed data (a.k.a.
equation discovery or symbolic regression) is a cornerstone of scientific
discovery, enabling transparent modeling of physical, biological, and economic
systems. While foundation models pre-trained on large-scale equation datasets
offer a promising starting point, they often suffer from negative transfer and
poor generalization when applied to small, domain-specific datasets. In this
paper, we introduce EQUATE (Equation Generation via QUality-Aligned Transfer
Embeddings), a data-efficient fine-tuning framework that adapts foundation
models for symbolic equation discovery in low-data regimes via distillation.
EQUATE combines symbolic-numeric alignment with evaluator-guided embedding
optimization, enabling a principled embedding-search-generation paradigm. Our
approach reformulates discrete equation search as a continuous optimization
task in a shared embedding space, guided by data-equation fitness and
simplicity. Experiments across three standard public benchmarks (Feynman,
Strogatz, and black-box datasets) demonstrate that EQUATE consistently
outperforms state-of-the-art baselines in both accuracy and robustness, while
preserving low complexity and fast inference. These results highlight EQUATE as
a practical and generalizable solution for data-efficient symbolic regression
in foundation model distillation settings.

</details>


### [139] [PoolFlip: A Multi-Agent Reinforcement Learning Security Environment for Cyber Defense](https://arxiv.org/abs/2508.19488)
*Xavier Cadet,Simona Boboila,Sie Hendrata Dharmawan,Alina Oprea,Peter Chin*

Main category: cs.LG

TL;DR: PoolFlip和Flip-PSRO通过多智能体强化学习提升FlipIt游戏中的防御能力，使防御者能更好地适应未知攻击。


<details>
  <summary>Details</summary>
Motivation: 现有FlipIt框架依赖有限启发式或专用学习技术，导致脆弱性和无法适应新攻击。

Method: 提出PoolFlip环境和Flip-PSRO方法，利用基于群体的训练训练防御者。

Result: Flip-PSRO防御者对未见过攻击的泛化能力是基线的2倍。

Conclusion: Flip-PSRO通过新设计的效用函数和MARL方法显著提升防御效果。

Abstract: Cyber defense requires automating defensive decision-making under stealthy,
deceptive, and continuously evolving adversarial strategies. The FlipIt game
provides a foundational framework for modeling interactions between a defender
and an advanced adversary that compromises a system without being immediately
detected. In FlipIt, the attacker and defender compete to control a shared
resource by performing a Flip action and paying a cost. However, the existing
FlipIt frameworks rely on a small number of heuristics or specialized learning
techniques, which can lead to brittleness and the inability to adapt to new
attacks. To address these limitations, we introduce PoolFlip, a multi-agent gym
environment that extends the FlipIt game to allow efficient learning for
attackers and defenders. Furthermore, we propose Flip-PSRO, a multi-agent
reinforcement learning (MARL) approach that leverages population-based training
to train defender agents equipped to generalize against a range of unknown,
potentially adaptive opponents. Our empirical results suggest that Flip-PSRO
defenders are $2\times$ more effective than baselines to generalize to a
heuristic attack not exposed in training. In addition, our newly designed
ownership-based utility functions ensure that Flip-PSRO defenders maintain a
high level of control while optimizing performance.

</details>


### [140] [Learning Game-Playing Agents with Generative Code Optimization](https://arxiv.org/abs/2508.19506)
*Zhiyi Kuang,Ryan Rong,YuCheng Yuan,Allen Nie*

Main category: cs.LG

TL;DR: 提出一种基于Python程序和LLM的生成优化方法，用于训练游戏代理，性能接近深度强化学习基线，但训练时间和交互更少。


<details>
  <summary>Details</summary>
Motivation: 探索程序化策略表示在构建高效、适应性强的游戏代理中的潜力，减少人工干预。

Method: 将策略表示为Python程序，利用LLM通过执行轨迹和自然语言反馈自我进化。

Result: 在Atari游戏中，性能与深度RL基线相当，但训练时间和环境交互显著减少。

Conclusion: 程序化策略表示有望构建高效、适应性强的代理，支持复杂、长程推理。

Abstract: We present a generative optimization approach for learning game-playing
agents, where policies are represented as Python programs and refined using
large language models (LLMs). Our method treats decision-making policies as
self-evolving code, with current observation as input and an in-game action as
output, enabling agents to self-improve through execution traces and natural
language feedback with minimal human intervention. Applied to Atari games, our
game-playing Python program achieves performance competitive with deep
reinforcement learning (RL) baselines while using significantly less training
time and much fewer environment interactions. This work highlights the promise
of programmatic policy representations for building efficient, adaptable agents
capable of complex, long-horizon reasoning.

</details>


### [141] [MobText-SISA: Efficient Machine Unlearning for Mobility Logs with Spatio-Temporal and Natural-Language Data](https://arxiv.org/abs/2508.19554)
*Haruki Yonekura,Ren Ozeki,Tatsuya Amano,Hamada Rizk,Hirozumi Yamaguchi*

Main category: cs.LG

TL;DR: MobText-SISA是一个可扩展的机器学习框架，用于异构时空数据的隐私合规分析，支持高效的数据删除请求。


<details>
  <summary>Details</summary>
Motivation: 现代移动平台存储了大量GPS轨迹和文本数据，但隐私法规要求支持数据删除，而从头训练模型不切实际。

Method: 通过共享潜在空间嵌入特征，使用相似性感知聚类分配样本到分片，增量训练并聚合预测结果。

Result: 在真实移动日志上验证，MobText-SISA保持预测准确性，且在错误率和收敛速度上优于随机分片。

Conclusion: MobText-SISA为多模态移动数据提供了隐私合规的实用解决方案。

Abstract: Modern mobility platforms have stored vast streams of GPS trajectories,
temporal metadata, free-form textual notes, and other unstructured data.
Privacy statutes such as the GDPR require that any individual's contribution be
unlearned on demand, yet retraining deep models from scratch for every request
is untenable. We introduce MobText-SISA, a scalable machine-unlearning
framework that extends Sharded, Isolated, Sliced, and Aggregated (SISA)
training to heterogeneous spatio-temporal data. MobText-SISA first embeds each
trip's numerical and linguistic features into a shared latent space, then
employs similarity-aware clustering to distribute samples across shards so that
future deletions touch only a single constituent model while preserving
inter-shard diversity. Each shard is trained incrementally; at inference time,
constituent predictions are aggregated to yield the output. Deletion requests
trigger retraining solely of the affected shard from its last valid checkpoint,
guaranteeing exact unlearning. Experiments on a ten-month real-world mobility
log demonstrate that MobText-SISA (i) sustains baseline predictive accuracy,
and (ii) consistently outperforms random sharding in both error and convergence
speed. These results establish MobText-SISA as a practical foundation for
privacy-compliant analytics on multimodal mobility data at urban scale.

</details>


### [142] [Just Because You Can, Doesn't Mean You Should: LLMs for Data Fitting](https://arxiv.org/abs/2508.19563)
*Hejia Liu,Mochen Yang,Gediminas Adomavicius*

Main category: cs.LG

TL;DR: LLMs在数据拟合中存在对任务无关变化的敏感性，预测结果可能因数据表示的小改动而大幅波动。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在数据拟合中的鲁棒性，揭示其对任务无关变化的敏感性。

Method: 通过改变变量名等任务无关操作，测试LLMs在上下文学习和监督微调下的预测稳定性，并分析注意力模式。

Result: LLMs预测结果对任务无关变化高度敏感，注意力分布不均匀，TabPFN也未能完全避免此问题。

Conclusion: 当前LLMs缺乏基本鲁棒性，不适合作为可靠的数据拟合工具。

Abstract: Large Language Models (LLMs) are being applied in a wide array of settings,
well beyond the typical language-oriented use cases. In particular, LLMs are
increasingly used as a plug-and-play method for fitting data and generating
predictions. Prior work has shown that LLMs, via in-context learning or
supervised fine-tuning, can perform competitively with many tabular supervised
learning techniques in terms of predictive performance. However, we identify a
critical vulnerability of using LLMs for data fitting -- making changes to data
representation that are completely irrelevant to the underlying learning task
can drastically alter LLMs' predictions on the same data. For example, simply
changing variable names can sway the size of prediction error by as much as 82%
in certain settings. Such prediction sensitivity with respect to
task-irrelevant variations manifests under both in-context learning and
supervised fine-tuning, for both close-weight and open-weight general-purpose
LLMs. Moreover, by examining the attention scores of an open-weight LLM, we
discover a non-uniform attention pattern: training examples and variable
names/values which happen to occupy certain positions in the prompt receive
more attention when output tokens are generated, even though different
positions are expected to receive roughly the same attention. This partially
explains the sensitivity in the presence of task-irrelevant variations. We also
consider a state-of-the-art tabular foundation model (TabPFN) trained
specifically for data fitting. Despite being explicitly designed to achieve
prediction robustness, TabPFN is still not immune to task-irrelevant
variations. Overall, despite LLMs' impressive predictive capabilities,
currently they lack even the basic level of robustness to be used as a
principled data-fitting tool.

</details>


### [143] [Bi-LoRA: Efficient Sharpness-Aware Minimization for Fine-Tuning Large-Scale Models](https://arxiv.org/abs/2508.19564)
*Yuhang Liu,Tao Li,Zhehao Huang,Zuopeng Yang,Xiaolin Huang*

Main category: cs.LG

TL;DR: Bi-LoRA通过双模块设计优化SAM与LoRA的结合，提升泛化能力且保持高效。


<details>
  <summary>Details</summary>
Motivation: 解决SAM在大模型上内存和计算开销大的问题，同时优化LoRA参数限制的尖锐性。

Method: 提出Bi-LoRA，通过主LoRA模块和辅助模块分别进行梯度下降和上升，优化尖锐性。

Result: 实验证明Bi-LoRA在多种任务和架构中高效且有效提升泛化能力。

Conclusion: Bi-LoRA成功解决了SAM与LoRA结合的局限性，实现了高效且有效的泛化优化。

Abstract: Fine-tuning large-scale pre-trained models with limited data presents
significant challenges for generalization. While Sharpness-Aware Minimization
(SAM) has proven effective in improving generalization by seeking flat minima,
its substantial extra memory and computation overhead make it impractical for
large models. Integrating SAM with parameter-efficient fine-tuning methods like
Low-Rank Adaptation (LoRA) is a promising direction. However, we find that
directly applying SAM to LoRA parameters limits the sharpness optimization to a
restricted subspace, hindering its effectiveness. To address this limitation,
we propose Bi-directional Low-Rank Adaptation (Bi-LoRA), which introduces an
auxiliary LoRA module to model SAM's adversarial weight perturbations. It
decouples SAM's weight perturbations from LoRA optimization: the primary LoRA
module adapts to specific tasks via standard gradient descent, while the
auxiliary module captures the sharpness of the loss landscape through gradient
ascent. Such dual-module design enables Bi-LoRA to capture broader sharpness
for achieving flatter minima while remaining memory-efficient. Another
important benefit is that the dual design allows for simultaneous optimization
and perturbation, eliminating SAM's doubled training costs. Extensive
experiments across diverse tasks and architectures demonstrate Bi-LoRA's
efficiency and effectiveness in enhancing generalization.

</details>


### [144] [Counterfactual Reward Model Training for Bias Mitigation in Multimodal Reinforcement Learning](https://arxiv.org/abs/2508.19567)
*Sheryl Mathew,N Harshit*

Main category: cs.LG

TL;DR: 论文提出了一种基于因果推理和多模态表示学习的反事实奖励模型，用于减少强化学习中的偏见，并在虚假新闻检测中取得了89.12%的准确率。


<details>
  <summary>Details</summary>
Motivation: 在强化学习人类反馈（RLHF）中，奖励模型可能放大数据中的潜在偏见，导致不公平和策略优化问题。现有方法通常采用被动约束，无法解决因果混淆问题。

Method: 提出反事实信任评分（Counterfactual Trust Score），包含四个组件：反事实偏移、重构不确定性、公平规则违反检测和动态奖励偏移。

Result: 在虚假新闻检测任务中，模型准确率达到89.12%，减少了虚假相关性和不公平的强化信号。

Conclusion: 该方法为公平感知的RLHF提供了可解释且鲁棒的解决方案，适用于动态实时策略制定。

Abstract: In reinforcement learning with human feedback (RLHF), reward models can
efficiently learn and amplify latent biases within multimodal datasets, which
can lead to imperfect policy optimization through flawed reward signals and
decreased fairness. Bias mitigation studies have often applied passive
constraints, which can fail under causal confounding. Here, we present a
counterfactual reward model that introduces causal inference with multimodal
representation learning to provide an unsupervised, bias-resilient reward
signal. The heart of our contribution is the Counterfactual Trust Score, an
aggregated score consisting of four components: (1) counterfactual shifts that
decompose political framing bias from topical bias; (2) reconstruction
uncertainty during counterfactual perturbations; (3) demonstrable violations of
fairness rules for each protected attribute; and (4) temporal reward shifts
aligned with dynamic trust measures. We evaluated the framework on a multimodal
fake versus true news dataset, which exhibits framing bias, class imbalance,
and distributional drift. Following methodologies similar to unsupervised drift
detection from representation-based distances [1] and temporal robustness
benchmarking in language models [2], we also inject synthetic bias across
sequential batches to test robustness. The resulting system achieved an
accuracy of 89.12% in fake news detection, outperforming the baseline reward
models. More importantly, it reduced spurious correlations and unfair
reinforcement signals. This pipeline outlines a robust and interpretable
approach to fairness-aware RLHF, offering tunable bias reduction thresholds and
increasing reliability in dynamic real-time policy making.

</details>


### [145] [Generative Models for Synthetic Data: Transforming Data Mining in the GenAI Era](https://arxiv.org/abs/2508.19570)
*Dawei Li,Yue Huang,Ming Li,Tianyi Zhou,Xiangliang Zhang,Huan Liu*

Main category: cs.LG

TL;DR: 教程介绍了生成模型在合成数据中的基础与最新进展，包括方法、框架、评估策略及应用，帮助解决数据挖掘中的数据稀缺和隐私问题。


<details>
  <summary>Details</summary>
Motivation: 解决数据挖掘中的数据稀缺、隐私和标注挑战，提供可扩展的合成数据生成方案。

Method: 涵盖生成模型（如大语言模型、扩散模型、生成对抗网络）的基础和最新方法，以及实用框架。

Result: 参与者将获得利用生成合成数据增强数据挖掘研究和实践的实用见解。

Conclusion: 生成模型为数据挖掘提供了创新的解决方案，教程旨在推广其应用。

Abstract: Generative models such as Large Language Models, Diffusion Models, and
generative adversarial networks have recently revolutionized the creation of
synthetic data, offering scalable solutions to data scarcity, privacy, and
annotation challenges in data mining. This tutorial introduces the foundations
and latest advances in synthetic data generation, covers key methodologies and
practical frameworks, and discusses evaluation strategies and applications.
Attendees will gain actionable insights into leveraging generative synthetic
data to enhance data mining research and practice. More information can be
found on our website: https://syndata4dm.github.io/.

</details>


### [146] [Escaping Stability-Plasticity Dilemma in Online Continual Learning for Motion Forecasting via Synergetic Memory Rehearsal](https://arxiv.org/abs/2508.19571)
*Yunlong Lin,Chao Lu,Tongshuai Wu,Xiaocong Zhao,Guodong Du,Yanwei Sun,Zirui Li,Jianwei Gong*

Main category: cs.LG

TL;DR: 提出了一种新的持续学习方法SyReM，用于解决DNN在运动预测中的稳定性-可塑性困境，通过选择性记忆重放机制提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决DNN在运动预测中因灾难性遗忘导致的性能下降问题，同时平衡记忆稳定性和学习可塑性。

Method: 使用紧凑记忆缓冲区表示知识，通过不等式约束保证稳定性，并通过基于损失梯度余弦相似度的选择性记忆重放机制增强可塑性。

Result: 在11个自然驾驶数据集上验证，SyReM显著减少灾难性遗忘并提高新场景的预测准确性。

Conclusion: SyReM有效解决了稳定性-可塑性困境，在持续学习任务中表现出色。

Abstract: Deep neural networks (DNN) have achieved remarkable success in motion
forecasting. However, most DNN-based methods suffer from catastrophic
forgetting and fail to maintain their performance in previously learned
scenarios after adapting to new data. Recent continual learning (CL) studies
aim to mitigate this phenomenon by enhancing memory stability of DNN, i.e., the
ability to retain learned knowledge. Yet, excessive emphasis on the memory
stability often impairs learning plasticity, i.e., the capacity of DNN to
acquire new information effectively. To address such stability-plasticity
dilemma, this study proposes a novel CL method, synergetic memory rehearsal
(SyReM), for DNN-based motion forecasting. SyReM maintains a compact memory
buffer to represent learned knowledge. To ensure memory stability, it employs
an inequality constraint that limits increments in the average loss over the
memory buffer. Synergistically, a selective memory rehearsal mechanism is
designed to enhance learning plasticity by selecting samples from the memory
buffer that are most similar to recently observed data. This selection is based
on an online-measured cosine similarity of loss gradients, ensuring targeted
memory rehearsal. Since replayed samples originate from learned scenarios, this
memory rehearsal mechanism avoids compromising memory stability. We validate
SyReM under an online CL paradigm where training samples from diverse scenarios
arrive as a one-pass stream. Experiments on 11 naturalistic driving datasets
from INTERACTION demonstrate that, compared to non-CL and CL baselines, SyReM
significantly mitigates catastrophic forgetting in past scenarios while
improving forecasting accuracy in new ones. The implementation is publicly
available at https://github.com/BIT-Jack/SyReM.

</details>


### [147] [Delta-Audit: Explaining What Changes When Models Change](https://arxiv.org/abs/2508.19589)
*Arshia Hemmat,Afsaneh Fatemi*

Main category: cs.LG

TL;DR: Delta-Attribution（Δ-Attribution）是一个模型无关的框架，通过差分特征归因来解释模型版本A和B之间的变化。


<details>
  <summary>Details</summary>
Motivation: 模型更新（如超参数、核函数、深度等）常导致性能变化，但原因往往不透明。Delta-Attribution旨在揭示这些变化的具体原因。

Method: 通过差分特征归因（Δϕ(x)=ϕ_B(x)−ϕ_A(x)）并结合一系列质量评估指标（如L1、Top-k、熵、Jensen-Shannon散度等）来分析模型变化。

Result: 实验表明，Delta-Attribution能有效区分行为相关的变化（如核函数切换）和无关的“表面”调整（如参数微调）。

Conclusion: Delta-Attribution提供了一种轻量级的模型更新审计方法，能够区分行为相关的变化和无关的调整，补充了准确性评估的不足。

Abstract: Model updates (new hyperparameters, kernels, depths, solvers, or data) change
performance, but the \emph{reason} often remains opaque. We introduce
\textbf{Delta-Attribution} (\mbox{$\Delta$-Attribution}), a model-agnostic
framework that explains \emph{what changed} between versions $A$ and $B$ by
differencing per-feature attributions: $\Delta\phi(x)=\phi_B(x)-\phi_A(x)$. We
evaluate $\Delta\phi$ with a \emph{$\Delta$-Attribution Quality Suite} covering
magnitude/sparsity (L1, Top-$k$, entropy), agreement/shift (rank-overlap@10,
Jensen--Shannon divergence), behavioural alignment (Delta Conservation Error,
DCE; Behaviour--Attribution Coupling, BAC; CO$\Delta$F), and robustness (noise,
baseline sensitivity, grouped occlusion).
  Instantiated via fast occlusion/clamping in standardized space with a
class-anchored margin and baseline averaging, we audit 45 settings: five
classical families (Logistic Regression, SVC, Random Forests, Gradient
Boosting, $k$NN), three datasets (Breast Cancer, Wine, Digits), and three A/B
pairs per family. \textbf{Findings.} Inductive-bias changes yield large,
behaviour-aligned deltas (e.g., SVC poly$\!\rightarrow$rbf on Breast Cancer:
BAC$\approx$0.998, DCE$\approx$6.6; Random Forest feature-rule swap on Digits:
BAC$\approx$0.997, DCE$\approx$7.5), while ``cosmetic'' tweaks (SVC
\texttt{gamma=scale} vs.\ \texttt{auto}, $k$NN search) show
rank-overlap@10$=1.0$ and DCE$\approx$0. The largest redistribution appears for
deeper GB on Breast Cancer (JSD$\approx$0.357). $\Delta$-Attribution offers a
lightweight update audit that complements accuracy by distinguishing benign
changes from behaviourally meaningful or risky reliance shifts.

</details>


### [148] [Complementary Learning System Empowers Online Continual Learning of Vehicle Motion Forecasting in Smart Cities](https://arxiv.org/abs/2508.19597)
*Zirui Li,Yunlong Lin,Guodong Du,Xiaocong Zhao,Cheng Gong,Chen Lv,Chao Lu,Jianwei Gong*

Main category: cs.LG

TL;DR: Dual-LS是一种任务无关的在线持续学习范式，通过双记忆回放机制解决DNN在车辆运动预测中的灾难性遗忘问题，显著提升预测稳定性并降低计算资源需求。


<details>
  <summary>Details</summary>
Motivation: 解决DNN在车辆运动预测中因灾难性遗忘导致的知识丢失问题，同时避免传统方法的高数据收集成本和低效样本利用。

Method: 提出Dual-LS，受人类大脑互补学习系统启发，通过协同的长短期记忆回放机制动态协调知识表示。

Result: 在三个国家的自然数据测试中，Dual-LS将灾难性遗忘减少74.31%，计算资源需求降低94.02%。

Conclusion: Dual-LS为智能城市中的DNN车辆运动预测提供了高效计算和类人持续学习适应性。

Abstract: Artificial intelligence underpins most smart city services, yet deep neural
network (DNN) that forecasts vehicle motion still struggle with catastrophic
forgetting, the loss of earlier knowledge when models are updated. Conventional
fixes enlarge the training set or replay past data, but these strategies incur
high data collection costs, sample inefficiently and fail to balance long- and
short-term experience, leaving them short of human-like continual learning.
Here we introduce Dual-LS, a task-free, online continual learning paradigm for
DNN-based motion forecasting that is inspired by the complementary learning
system of the human brain. Dual-LS pairs two synergistic memory rehearsal
replay mechanisms to accelerate experience retrieval while dynamically
coordinating long-term and short-term knowledge representations. Tests on
naturalistic data spanning three countries, over 772,000 vehicles and
cumulative testing mileage of 11,187 km show that Dual-LS mitigates
catastrophic forgetting by up to 74.31\% and reduces computational resource
demand by up to 94.02\%, markedly boosting predictive stability in vehicle
motion forecasting without inflating data requirements. Meanwhile, it endows
DNN-based vehicle motion forecasting with computation efficient and human-like
continual learning adaptability fit for smart cities.

</details>


### [149] [Encouraging Good Processes Without the Need for Good Answers: Reinforcement Learning for LLM Agent Planning](https://arxiv.org/abs/2508.19598)
*Zhiwei Li,Yong Hu,Wenqing Wang*

Main category: cs.LG

TL;DR: 论文提出RLTR框架，通过解耦训练过程，专注于规划模块的单目标优化，解决了现有方法中目标分配不平衡和数据稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 现有端到端多目标优化方法在LLM代理训练中存在目标分配不平衡和可验证数据稀缺的问题，限制了规划能力的提升。

Method: 提出RLTR框架，利用工具使用完整性的奖励信号直接评估工具调用序列质量，无需依赖最终响应内容。

Result: 实验显示RLTR在规划性能上比基线方法提升8%-12%，并间接提高最终响应质量5%-6%。

Conclusion: RLTR通过解耦训练和引入直接奖励信号，有效提升了LLM代理的规划能力和整体性能。

Abstract: The functionality of Large Language Model (LLM) agents is primarily
determined by two capabilities: action planning and answer summarization. The
former, action planning, is the core capability that dictates an agent's
performance. However, prevailing training paradigms employ end-to-end,
multi-objective optimization that jointly trains both capabilities. This
paradigm faces two critical challenges: imbalanced optimization objective
allocation and scarcity of verifiable data, making it difficult to enhance the
agent's planning capability. To address these challenges, we propose
Reinforcement Learning with Tool-use Rewards (RLTR), a novel framework that
decouples the training process to enable a focused, single-objective
optimization of the planning module. Crucially, RLTR introduces a reward signal
based on tool-use completeness to directly evaluate the quality of tool
invocation sequences. This method offers a more direct and reliable training
signal than assessing the final response content, thereby obviating the need
for verifiable data. Our experiments demonstrate that RLTR achieves an 8%-12%
improvement in planning performance compared to end-to-end baselines. Moreover,
this enhanced planning capability, in turn, translates to a 5%-6% increase in
the final response quality of the overall agent system.

</details>


### [150] [FinCast: A Foundation Model for Financial Time-Series Forecasting](https://arxiv.org/abs/2508.19609)
*Zhuohang Zhu,Haodong Chen,Qiang Qu,Vera Chung*

Main category: cs.LG

TL;DR: FinCast是一种专为金融时间序列预测设计的基础模型，具有零样本性能，无需领域微调即可捕捉多样模式。


<details>
  <summary>Details</summary>
Motivation: 金融时间序列预测对经济稳定、政策制定和可持续投资至关重要，但现有方法因模式变化（如时间非平稳性、多领域多样性和不同时间分辨率）而面临挑战。

Method: 提出FinCast，一种基于大规模金融数据集训练的基础模型，专注于解决金融时间序列的复杂模式。

Result: FinCast在零样本性能上表现优异，超越现有方法，展示了强大的泛化能力。

Conclusion: FinCast为金融时间序列预测提供了高效且通用的解决方案，显著提升了预测性能。

Abstract: Financial time-series forecasting is critical for maintaining economic
stability, guiding informed policymaking, and promoting sustainable investment
practices. However, it remains challenging due to various underlying pattern
shifts. These shifts arise primarily from three sources: temporal
non-stationarity (distribution changes over time), multi-domain diversity
(distinct patterns across financial domains such as stocks, commodities, and
futures), and varying temporal resolutions (patterns differing across
per-second, hourly, daily, or weekly indicators). While recent deep learning
methods attempt to address these complexities, they frequently suffer from
overfitting and typically require extensive domain-specific fine-tuning. To
overcome these limitations, we introduce FinCast, the first foundation model
specifically designed for financial time-series forecasting, trained on
large-scale financial datasets. Remarkably, FinCast exhibits robust zero-shot
performance, effectively capturing diverse patterns without domain-specific
fine-tuning. Comprehensive empirical and qualitative evaluations demonstrate
that FinCast surpasses existing state-of-the-art methods, highlighting its
strong generalization capabilities.

</details>


### [151] [ALSA: Anchors in Logit Space for Out-of-Distribution Accuracy Estimation](https://arxiv.org/abs/2508.19613)
*Chenzhi Liu,Mahsa Baktashmotlagh,Yanran Tang,Zi Huang,Ruihong Qiu*

Main category: cs.LG

TL;DR: ALSA是一种新颖的框架，通过在logit空间中操作，保留更丰富的信息，用于估计模型在未见未标记数据集上的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖softmax分数或数据相似性度量，前者导致信息损失，后者计算成本高且领域受限。ALSA旨在解决这些问题。

Method: ALSA在logit空间中初始化多个可学习的锚点，每个锚点分配一个影响函数，捕捉logits的细微变化。

Result: 实验表明，ALSA在视觉、语言和图基准测试中优于基于softmax和相似性的基线方法。

Conclusion: ALSA在显著分布偏移下表现出鲁棒性，是可靠模型评估的实用工具。

Abstract: Estimating model accuracy on unseen, unlabeled datasets is crucial for
real-world machine learning applications, especially under distribution shifts
that can degrade performance. Existing methods often rely on predicted class
probabilities (softmax scores) or data similarity metrics. While softmax-based
approaches benefit from representing predictions on the standard simplex,
compressing logits into probabilities leads to information loss. Meanwhile,
similarity-based methods can be computationally expensive and domain-specific,
limiting their broader applicability. In this paper, we introduce ALSA (Anchors
in Logit Space for Accuracy estimation), a novel framework that preserves
richer information by operating directly in the logit space. Building on
theoretical insights and empirical observations, we demonstrate that the
aggregation and distribution of logits exhibit a strong correlation with the
predictive performance of the model. To exploit this property, ALSA employs an
anchor-based modeling strategy: multiple learnable anchors are initialized in
logit space, each assigned an influence function that captures subtle
variations in the logits. This allows ALSA to provide robust and accurate
performance estimates across a wide range of distribution shifts. Extensive
experiments on vision, language, and graph benchmarks demonstrate ALSA's
superiority over both softmax- and similarity-based baselines. Notably, ALSA's
robustness under significant distribution shifts highlights its potential as a
practical tool for reliable model evaluation.

</details>


### [152] [Towards Instance-wise Personalized Federated Learning via Semi-Implicit Bayesian Prompt Tuning](https://arxiv.org/abs/2508.19621)
*Tiandi Ye,Wenyan Liu,Kai Yao,Lichun Li,Shangchao Su,Cen Chen,Xiang Li,Shan Yin,Ming Gao*

Main category: cs.LG

TL;DR: pFedBayesPT是一种基于视觉提示调优的细粒度实例级个性化联邦学习框架，解决了客户端内数据异质性问题。


<details>
  <summary>Details</summary>
Motivation: 现有pFL方法假设每个客户端数据服从单一分布，但实际中客户端可能拥有多源或多域数据，导致性能不佳。

Method: 提出基于贝叶斯视角的实例级提示生成，将提示后验建模为隐式分布以捕捉多样视觉语义，并在半隐式变分推断框架下推导训练目标。

Result: 在基准数据集上的实验表明，pFedBayesPT在特征和标签异质性设置下均优于现有pFL方法。

Conclusion: pFedBayesPT通过实例级个性化有效解决了客户端内数据异质性，提升了联邦学习性能。

Abstract: Federated learning (FL) is a privacy-preserving machine learning paradigm
that enables collaborative model training across multiple distributed clients
without disclosing their raw data. Personalized federated learning (pFL) has
gained increasing attention for its ability to address data heterogeneity.
However, most existing pFL methods assume that each client's data follows a
single distribution and learn one client-level personalized model for each
client. This assumption often fails in practice, where a single client may
possess data from multiple sources or domains, resulting in significant
intra-client heterogeneity and suboptimal performance. To tackle this
challenge, we propose pFedBayesPT, a fine-grained instance-wise pFL framework
based on visual prompt tuning. Specifically, we formulate instance-wise prompt
generation from a Bayesian perspective and model the prompt posterior as an
implicit distribution to capture diverse visual semantics. We derive a
variational training objective under the semi-implicit variational inference
framework. Extensive experiments on benchmark datasets demonstrate that
pFedBayesPT consistently outperforms existing pFL methods under both feature
and label heterogeneity settings.

</details>


### [153] [SCAR: A Characterization Scheme for Multi-Modal Dataset](https://arxiv.org/abs/2508.19659)
*Ri Su,Zhao Chen,Caleb Chen Cao,Nan Tang,Lei Chen*

Main category: cs.LG

TL;DR: SCAR是一种基于数据集内在结构特性（Scale、Coverage、Authenticity、Richness）的评估方法，用于指导数据优化和多模态数据集扩展。


<details>
  <summary>Details</summary>
Motivation: 传统方法过于关注数据量和训练效率，忽略了数据质量的结构特性，SCAR旨在填补这一理论空白。

Method: 提出SCAR框架，通过四个关键指标评估数据集结构特性，并基于此设计Foundation Data和模态感知的数据扩展策略。

Result: 实验验证了SCAR在预测数据效用和指导数据采集方面的有效性。

Conclusion: SCAR为数据理解和优化提供了理论支持，尤其在多模态任务中表现出色。

Abstract: Foundation models exhibit remarkable generalization across diverse tasks,
largely driven by the characteristics of their training data. Recent
data-centric methods like pruning and compression aim to optimize training but
offer limited theoretical insight into how data properties affect
generalization, especially the data characteristics in sample scaling.
Traditional perspectives further constrain progress by focusing predominantly
on data quantity and training efficiency, often overlooking structural aspects
of data quality. In this study, we introduce SCAR, a principled scheme for
characterizing the intrinsic structural properties of datasets across four key
measures: Scale, Coverage, Authenticity, and Richness. Unlike prior
data-centric measures, SCAR captures stable characteristics that remain
invariant under dataset scaling, providing a robust and general foundation for
data understanding. Leveraging these structural properties, we introduce
Foundation Data-a minimal subset that preserves the generalization behavior of
the full dataset without requiring model-specific retraining. We model
single-modality tasks as step functions and estimate the distribution of the
foundation data size to capture step-wise generalization bias across modalities
in the target multi-modal dataset. Finally, we develop a SCAR-guided data
completion strategy based on this generalization bias, which enables efficient,
modality-aware expansion of modality-specific characteristics in multimodal
datasets. Experiments across diverse multi-modal datasets and model
architectures validate the effectiveness of SCAR in predicting data utility and
guiding data acquisition. Code is available at https://github.com/McAloma/SCAR.

</details>


### [154] [Exploration of Low-Power Flexible Stress Monitoring Classifiers for Conformal Wearables](https://arxiv.org/abs/2508.19661)
*Florentia Afentaki,Sri Sai Rakesh Nakkilla,Konstantinos Balaskas,Paula Carolina Lozano Duarte,Shiyi Jiang,Georgios Zervakis,Farshad Firouzi,Krishnendu Chakrabarty,Mehdi B. Tahoori*

Main category: cs.LG

TL;DR: 本文探讨了低功耗、柔性压力分类器的设计空间，提出了比现有方法更高精度的实时压力监测方案。


<details>
  <summary>Details</summary>
Motivation: 传统压力监测方法缺乏连续性和成本效益，现有柔性电子技术虽灵活但难以集成复杂电路如机器学习分类器。

Method: 通过设计1200多种柔性分类器，结合特征选择和神经网络简化算法，优化硬件效率。

Result: 实现了比现有方法更高精度的实时压力分类器，同时具备低成本、低功耗和小尺寸特点。

Conclusion: 该研究为设计实时压力分类器提供了新思路，兼具高精度和实用性。

Abstract: Conventional stress monitoring relies on episodic, symptom-focused
interventions, missing the need for continuous, accessible, and cost-efficient
solutions. State-of-the-art approaches use rigid, silicon-based wearables,
which, though capable of multitasking, are not optimized for lightweight,
flexible wear, limiting their practicality for continuous monitoring. In
contrast, flexible electronics (FE) offer flexibility and low manufacturing
costs, enabling real-time stress monitoring circuits. However, implementing
complex circuits like machine learning (ML) classifiers in FE is challenging
due to integration and power constraints. Previous research has explored
flexible biosensors and ADCs, but classifier design for stress detection
remains underexplored. This work presents the first comprehensive design space
exploration of low-power, flexible stress classifiers. We cover various ML
classifiers, feature selection, and neural simplification algorithms, with over
1200 flexible classifiers. To optimize hardware efficiency, fully customized
circuits with low-precision arithmetic are designed in each case. Our
exploration provides insights into designing real-time stress classifiers that
offer higher accuracy than current methods, while being low-cost, conformable,
and ensuring low power and compact size.

</details>


### [155] [$\mathcal{C}^1$-approximation with rational functions and rational neural networks](https://arxiv.org/abs/2508.19672)
*Erion Morina,Martin Holler*

Main category: cs.LG

TL;DR: 论文证明了正则函数可以用有理函数和有理神经网络在$\mathcal{C}^1$-范数下逼近，并给出了网络宽度、深度和有理函数次数的逼近速率。


<details>
  <summary>Details</summary>
Motivation: 研究正则函数的逼近问题，特别是在符号回归和物理定律学习中的重要性。

Method: 使用有理函数和有理神经网络进行$\mathcal{C}^1$-逼近，并分析逼近速率。

Result: 获得了$\mathcal{C}^1$-逼近结果，适用于$\text{EQL}^\div$和ParFam架构的有理神经网络。

Conclusion: 有理神经网络在符号回归和物理定律学习中具有实际应用价值。

Abstract: We show that suitably regular functions can be approximated in the
$\mathcal{C}^1$-norm both with rational functions and rational neural networks,
including approximation rates with respect to width and depth of the network,
and degree of the rational functions. As consequence of our results, we further
obtain $\mathcal{C}^1$-approximation results for rational neural networks with
the $\text{EQL}^\div$ and ParFam architecture, both of which are important in
particular in the context of symbolic regression for physical law learning.

</details>


### [156] [Metric spaces of walks and Lipschitz duality on graphs](https://arxiv.org/abs/2508.19709)
*R. Arnau,A. González Cortés,E. A. Sánchez Pérez,S. Sanjuan*

Main category: cs.LG

TL;DR: 论文研究了图上游走的度量结构，引入加权度量处理序列，定义了基于顶点距离和加权范数的游走距离，并分析了其性质。


<details>
  <summary>Details</summary>
Motivation: 研究图上游走的度量结构，为分析游走间的相对距离提供理论基础，并探索其在强化学习等领域的应用。

Method: 引入加权度量处理序列，定义游走距离，分析其性质，并提供不同假设下的邻近度表示公式。

Result: 建立了度量框架，支持经典度量工具的应用，如Lipschitz函数的扩展，并展示了在邻近度估计和强化学习中的潜在应用。

Conclusion: 提出的度量框架为图上游走的分析提供了新工具，尤其在邻近度估计和网络结构上的Lipschitz回归中具有应用潜力。

Abstract: We study the metric structure of walks on graphs, understood as Lipschitz
sequences. To this end, a weighted metric is introduced to handle sequences,
enabling the definition of distances between walks based on stepwise vertex
distances and weighted norms. We analyze the main properties of these metric
spaces, which provides the foundation for the analysis of weaker forms of
instruments to measure relative distances between walks: proximities. We
provide some representation formulas for such proximities under different
assumptions and provide explicit constructions for these cases. The resulting
metric framework allows the use of classical tools from metric modeling, such
as the extension of Lipschitz functions from subspaces of walks, which permits
extending proximity functions while preserving fundamental properties via the
mentioned representations. Potential applications include the estimation of
proximities and the development of reinforcement learning strategies based on
exploratory walks, offering a robust approach to Lipschitz regression on
network structures.

</details>


### [157] [Tune My Adam, Please!](https://arxiv.org/abs/2508.19733)
*Theodoros Athanasiadis,Steven Adriaensen,Samuel Müller,Frank Hutter*

Main category: cs.LG

TL;DR: Adam-PFN是一种新的代理模型，用于Adam优化器的超参数调优，结合了预训练和新的学习曲线增强方法CDF-augment，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: Adam优化器广泛使用，但超参数调优耗时且昂贵。现有方法缺乏对超参数如何影响学习的先验知识。

Method: 提出Adam-PFN代理模型，结合预训练和CDF-augment方法增强学习曲线数据。

Result: 在TaskSet评估任务中提升了学习曲线外推和超参数优化速度，并在OOD任务中表现优异。

Conclusion: Adam-PFN为Adam超参数调优提供了高效且通用的解决方案。

Abstract: The Adam optimizer remains one of the most widely used optimizers in deep
learning, and effectively tuning its hyperparameters is key to optimizing
performance. However, tuning can be tedious and costly. Freeze-thaw Bayesian
Optimization (BO) is a recent promising approach for low-budget hyperparameter
tuning, but is limited by generic surrogates without prior knowledge of how
hyperparameters affect learning. We propose Adam-PFN, a new surrogate model for
Freeze-thaw BO of Adam's hyperparameters, pre-trained on learning curves from
TaskSet, together with a new learning curve augmentation method, CDF-augment,
which artificially increases the number of available training examples. Our
approach improves both learning curve extrapolation and accelerates
hyperparameter optimization on TaskSet evaluation tasks, with strong
performance on out-of-distribution (OOD) tasks.

</details>


### [158] [InfraredGP: Efficient Graph Partitioning via Spectral Graph Neural Networks with Negative Corrections](https://arxiv.org/abs/2508.19737)
*Meng Qin,Weihua Li,Jinqiang Cui,Sen Pei*

Main category: cs.LG

TL;DR: InfraredGP是一种基于图信号处理的社区检测方法，通过负修正机制放大低频信息，无需训练即可生成高质量结果。


<details>
  <summary>Details</summary>
Motivation: 探索低频信息是否能够编码更多社区结构信息。

Method: 采用谱GNN结合低通滤波器和负修正机制，仅输入随机信号，通过一次前向传播生成嵌入。

Result: 在静态和流式图分区任务中，效率显著提升（16x-23x），且质量优于基线方法。

Conclusion: InfraredGP通过负修正机制有效提升了社区检测的效率和效果。

Abstract: Graph partitioning (GP), a.k.a. community detection, is a classic problem
that divides nodes of a graph into densely-connected blocks. From a perspective
of graph signal processing, we find that graph Laplacian with a negative
correction can derive graph frequencies beyond the conventional range $[0, 2]$.
To explore whether the low-frequency information beyond this range can encode
more informative properties about community structures, we propose InfraredGP.
It (\romannumeral1) adopts a spectral GNN as its backbone combined with
low-pass filters and a negative correction mechanism, (\romannumeral2) only
feeds random inputs to this backbone, (\romannumeral3) derives graph embeddings
via one feed-forward propagation (FFP) without any training, and
(\romannumeral4) obtains feasible GP results by feeding the derived embeddings
to BIRCH. Surprisingly, our experiments demonstrate that based solely on the
negative correction mechanism that amplifies low-frequency information beyond
$[0, 2]$, InfraredGP can derive distinguishable embeddings for some standard
clustering modules (e.g., BIRCH) and obtain high-quality results for GP without
any training. Following the IEEE HPEC Graph Challenge benchmark, we evaluate
InfraredGP for both static and streaming GP, where InfraredGP can achieve much
better efficiency (e.g., 16x-23x faster) and competitive quality over various
baselines. We have made our code public at
https://github.com/KuroginQin/InfraredGP

</details>


### [159] [Fast 3D Diffusion for Scalable Granular Media Synthesis](https://arxiv.org/abs/2508.19752)
*Muhammad Moeeze Hassan,Régis Cottereau,Filippo Gatti,Patryk Dec*

Main category: cs.LG

TL;DR: 提出了一种基于3D扩散模型的新方法，用于高效生成大规模颗粒介质，显著减少了计算时间。


<details>
  <summary>Details</summary>
Motivation: 离散元法模拟颗粒介质时，初始化阶段计算量大且耗时，成为瓶颈。

Method: 采用两阶段生成管道：1) 3D扩散模型生成独立体素网格；2) 3D修复模型无缝拼接网格，支持大规模合成。

Result: 1.2米长的轨道合成仅需20秒，相比传统3小时DEM模拟大幅提速。

Conclusion: 该方法实现了物理一致、实时可扩展的颗粒介质合成，适用于工业应用。

Abstract: Simulating granular media, using Discrete Element Method is a computationally
intensive task. This is especially true during initialization phase, which
dominates total simulation time because of large displacements involved and
associated kinetic energy. We overcome this bottleneck with a novel generative
pipeline based on 3D diffusion models that directly synthesizes arbitrarily
large granular assemblies in their final and physically realistic
configurations. The approach frames the problem as a 3D generative modeling
task, consisting of a two-stage pipeline. First a diffusion model is trained to
generate independent 3D voxel grids representing granular media. Second, a 3D
inpainting model, adapted from 2D inpainting techniques using masked inputs,
stitches these grids together seamlessly, enabling synthesis of large samples
with physically realistic structure. The inpainting model explores several
masking strategies for the inputs to the underlying UNets by training the
network to infer missing portions of voxel grids from a concatenation of noised
tensors, masks, and masked tensors as input channels. The model also adapts a
2D repainting technique of re-injecting noise scheduler output with ground
truth to provide a strong guidance to the 3D model. This along with weighted
losses ensures long-term coherence over generation of masked regions. Both
models are trained on the same binarized 3D occupancy grids extracted from
small-scale DEM simulations, achieving linear scaling of computational time
with respect to sample size. Quantitatively, a 1.2 m long ballasted rail track
synthesis equivalent to a 3-hour DEM simulation, was completed under 20
seconds. The generated voxel grids can also be post-processed to extract grain
geometries for DEM-compatibility as well, enabling physically coherent,
real-time, scalable granular media synthesis for industrial applications.

</details>


### [160] [Interestingness First Classifiers](https://arxiv.org/abs/2508.19780)
*Ryoma Sato*

Main category: cs.LG

TL;DR: 论文提出了一种构建‘有趣分类器’的框架EUREKA，通过选择非传统但有趣的特性，即使牺牲部分准确性，也能提供新颖见解。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习模型追求高准确性，但忽略了模型的趣味性和新颖性。本文旨在构建能提供意外见解的分类器。

Method: 利用大语言模型评估特性的‘有趣性’，并基于这些特性构建可解释的分类器。

Result: 在多个数据集中，EUREKA成功识别出非传统但仍有预测力的特性，如湿度预测房间拥挤度。

Conclusion: 有趣分类器在需要新颖性和可解释性的场景中，为知识发现和传播提供了新途径。

Abstract: Most machine learning models are designed to maximize predictive accuracy. In
this work, we explore a different goal: building classifiers that are
interesting. An ``interesting classifier'' is one that uses unusual or
unexpected features, even if its accuracy is lower than the best possible
model. For example, predicting room congestion from CO2 levels achieves
near-perfect accuracy but is unsurprising. In contrast, predicting room
congestion from humidity is less accurate yet more nuanced and intriguing. We
introduce EUREKA, a simple framework that selects features according to their
perceived interestingness. Our method leverages large language models to rank
features by their interestingness and then builds interpretable classifiers
using only the selected interesting features. Across several benchmark
datasets, EUREKA consistently identifies features that are non-obvious yet
still predictive. For example, in the Occupancy Detection dataset, our method
favors humidity over CO2 levels and light intensity, producing classifiers that
achieve meaningful accuracy while offering insights. In the Twin Papers
dataset, our method discovers the rule that papers with a colon in the title
are more likely to be cited in the future. We argue that such models can
support new ways of knowledge discovery and communication, especially in
settings where moderate accuracy is sufficient but novelty and interpretability
are valued.

</details>


### [161] [PSO-Merging: Merging Models Based on Particle Swarm Optimization](https://arxiv.org/abs/2508.19839)
*Kehao Zhang,Shaolei Zhang,Yang Feng*

Main category: cs.LG

TL;DR: PSO-Merging是一种基于粒子群优化的数据驱动模型合并方法，解决了现有方法在性能和效率上的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有数据无关方法缺乏数据驱动指导，性能受限；数据驱动方法中，梯度法计算昂贵，无梯度法优化效果差。

Method: 使用粒子群优化（PSO），初始化粒子群为预训练模型和专家模型，通过迭代优化得到合并模型。

Result: 在不同语言模型上，PSO-Merging优于基线合并方法，效率更高且可扩展。

Conclusion: PSO-Merging为模型合并提供了高效、可扩展的解决方案。

Abstract: Model merging has emerged as an efficient strategy for constructing multitask
models by integrating the strengths of multiple available expert models,
thereby reducing the need to fine-tune a pre-trained model for all the tasks
from scratch. Existing data-independent methods struggle with performance
limitations due to the lack of data-driven guidance. Data-driven approaches
also face key challenges: gradient-based methods are computationally expensive,
limiting their practicality for merging large expert models, whereas existing
gradient-free methods often fail to achieve satisfactory results within a
limited number of optimization steps. To address these limitations, this paper
introduces PSO-Merging, a novel data-driven merging method based on the
Particle Swarm Optimization (PSO). In this approach, we initialize the particle
swarm with a pre-trained model, expert models, and sparsified expert models. We
then perform multiple iterations, with the final global best particle serving
as the merged model. Experimental results on different language models show
that PSO-Merging generally outperforms baseline merging methods, offering a
more efficient and scalable solution for model merging.

</details>


### [162] [Symplectic convolutional neural networks](https://arxiv.org/abs/2508.19842)
*Süleyman Yıldız,Konrad Janik,Peter Benner*

Main category: cs.LG

TL;DR: 提出了一种新的辛卷积神经网络（CNN）架构，结合辛神经网络、辛分解和张量技术，性能优于线性辛自编码器。


<details>
  <summary>Details</summary>
Motivation: 通过数学等效形式确保卷积层的辛性质，构建完整的自编码器。

Method: 引入辛神经网络参数化CNN层，并设计辛池化层。

Result: 在波动方程、非线性薛定谔方程和正弦-戈登方程上表现优异。

Conclusion: 辛CNN在数值实验中优于线性辛自编码器。

Abstract: We propose a new symplectic convolutional neural network (CNN) architecture
by leveraging symplectic neural networks, proper symplectic decomposition, and
tensor techniques. Specifically, we first introduce a mathematically equivalent
form of the convolution layer and then, using symplectic neural networks, we
demonstrate a way to parameterize the layers of the CNN to ensure that the
convolution layer remains symplectic. To construct a complete autoencoder, we
introduce a symplectic pooling layer. We demonstrate the performance of the
proposed neural network on three examples: the wave equation, the nonlinear
Schr\"odinger (NLS) equation, and the sine-Gordon equation. The numerical
results indicate that the symplectic CNN outperforms the linear symplectic
autoencoder obtained via proper symplectic decomposition.

</details>


### [163] [Physics-Informed DeepONet Coupled with FEM for Convective Transport in Porous Media with Sharp Gaussian Sources](https://arxiv.org/abs/2508.19847)
*Erdi Kara,Panos Stinis*

Main category: cs.LG

TL;DR: 提出了一种结合有限元方法（FEM）和物理信息DeepONet的混合框架，用于模拟多孔介质中流体传输，特别针对尖锐高斯源。


<details>
  <summary>Details</summary>
Motivation: 传统方法在处理尖锐源导致的陡峭梯度时效率较低，需要一种既能保持高精度又能快速推断的方法。

Method: 使用FEM求解Darcy流方程，将速度场传递给物理信息DeepONet，学习从源函数到溶质浓度分布的映射，并采用自适应采样策略处理陡峭梯度。

Result: 数值实验表明，该方法与参考解吻合良好，且速度比传统求解器快几个数量级。

Conclusion: 该方法在保持FEM精度的同时实现了快速推断，适用于实际应用。

Abstract: We present a hybrid framework that couples finite element methods (FEM) with
physics-informed DeepONet to model fluid transport in porous media from sharp,
localized Gaussian sources. The governing system consists of a steady-state
Darcy flow equation and a time-dependent convection-diffusion equation. Our
approach solves the Darcy system using FEM and transfers the resulting velocity
field to a physics-informed DeepONet, which learns the mapping from source
functions to solute concentration profiles. This modular strategy preserves
FEM-level accuracy in the flow field while enabling fast inference for
transport dynamics. To handle steep gradients induced by sharp sources, we
introduce an adaptive sampling strategy for trunk collocation points. Numerical
experiments demonstrate that our method is in good agreement with the reference
solutions while offering orders of magnitude speedups over traditional solvers,
making it suitable for practical applications in relevant scenarios.
Implementation of our proposed method is available at
https://github.com/erkara/fem-pi-deeponet.

</details>


### [164] [Quantum latent distributions in deep generative models](https://arxiv.org/abs/2508.19857)
*Omar Bacarreza,Thorin Farnsworth,Alexander Makarovskiy,Hugo Wallner,Tessa Hicks,Santiago Sempere-Llagostera,John Price,Robert J. A. Francis-Jones,William R. Clements*

Main category: cs.LG

TL;DR: 论文探讨了量子处理器生成的低维潜在分布如何提升生成模型的性能，并验证了其可重复性和适用条件。


<details>
  <summary>Details</summary>
Motivation: 研究量子潜在分布是否能在生成模型中提供经典分布无法实现的高效数据生成能力，并探索其实际应用场景。

Method: 通过理论证明和实验验证，使用合成量子数据集和QM9分子数据集，结合模拟和真实光量子处理器进行基准测试。

Result: 量子潜在分布在GAN中表现优于经典基线，同时验证了扩散和流匹配模型的兼容性。

Conclusion: 近期量子处理器能够扩展深度生成模型的能力，为实际应用提供新可能。

Abstract: Many successful families of generative models leverage a low-dimensional
latent distribution that is mapped to a data distribution. Though simple latent
distributions are commonly used, it has been shown that more sophisticated
distributions can improve performance. For instance, recent work has explored
using the distributions produced by quantum processors and found empirical
improvements. However, when latent space distributions produced by quantum
processors can be expected to improve performance, and whether these
improvements are reproducible, are open questions that we investigate in this
work. We prove that, under certain conditions, these "quantum latent
distributions" enable generative models to produce data distributions that
classical latent distributions cannot efficiently produce. We also provide
actionable intuitions to identify when such quantum advantages may arise in
real-world settings. We perform benchmarking experiments on both a synthetic
quantum dataset and the QM9 molecular dataset, using both simulated and real
photonic quantum processors. Our results demonstrate that quantum latent
distributions can lead to improved generative performance in GANs compared to a
range of classical baselines. We also explore diffusion and flow matching
models, identifying architectures compatible with quantum latent distributions.
This work confirms that near-term quantum processors can expand the
capabilities of deep generative models.

</details>


### [165] [Parameter-Free Structural-Diversity Message Passing for Graph Neural Networks](https://arxiv.org/abs/2508.19884)
*Mingyue Kong,Yinglong Zhang,Chengda Xu,Xuewen Xia,Xing Xu*

Main category: cs.LG

TL;DR: 提出了一种基于结构多样性的无参数图神经网络框架SDGNN，解决了传统GNN在结构异质性和复杂特征分布下的过平滑和语义退化问题。


<details>
  <summary>Details</summary>
Motivation: 传统GNN依赖大量可训练参数和固定聚合规则，难以适应结构异质性和复杂特征分布的图数据，导致节点表示过平滑和语义退化。

Method: 设计了一种基于结构多样性理论的无参数消息传递机制，同时捕捉邻域结构的异质性和特征语义的稳定性。

Result: 在八个公共基准数据集和一个跨学科PubMed引用网络上，SDGNN在低监督、类别不平衡和跨域迁移等挑战性条件下优于主流GNN。

Conclusion: SDGNN为无参数图神经网络设计提供了新理论视角和通用方法，验证了结构多样性在图表示学习中的核心信号作用。

Abstract: Graph Neural Networks (GNNs) have shown remarkable performance in structured
data modeling tasks such as node classification. However, mainstream approaches
generally rely on a large number of trainable parameters and fixed aggregation
rules, making it difficult to adapt to graph data with strong structural
heterogeneity and complex feature distributions. This often leads to
over-smoothing of node representations and semantic degradation. To address
these issues, this paper proposes a parameter-free graph neural network
framework based on structural diversity, namely SDGNN (Structural-Diversity
Graph Neural Network). The framework is inspired by structural diversity theory
and designs a unified structural-diversity message passing mechanism that
simultaneously captures the heterogeneity of neighborhood structures and the
stability of feature semantics, without introducing additional trainable
parameters. Unlike traditional parameterized methods, SDGNN does not rely on
complex model training, but instead leverages complementary modeling from both
structure-driven and feature-driven perspectives, thereby effectively improving
adaptability across datasets and scenarios. Experimental results show that on
eight public benchmark datasets and an interdisciplinary PubMed citation
network, SDGNN consistently outperforms mainstream GNNs under challenging
conditions such as low supervision, class imbalance, and cross-domain transfer.
This work provides a new theoretical perspective and general approach for the
design of parameter-free graph neural networks, and further validates the
importance of structural diversity as a core signal in graph representation
learning. To facilitate reproducibility and further research, the full
implementation of SDGNN has been released at:
https://github.com/mingyue15694/SGDNN/tree/main

</details>


### [166] [NM-Hebb: Coupling Local Hebbian Plasticity with Metric Learning for More Accurate and Interpretable CNNs](https://arxiv.org/abs/2508.19896)
*Davorin Miličević,Ratko Grbić*

Main category: cs.LG

TL;DR: NM-Hebb是一种结合神经启发局部可塑性和距离感知监督的两阶段训练框架，显著提升CNN的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决传统CNN依赖全局梯度优化导致的过拟合、冗余过滤器和可解释性差的问题。

Method: 两阶段训练：第一阶段结合交叉熵目标与Hebbian正则化和可学习神经调节器；第二阶段通过度量学习损失微调。

Result: 在多个数据集和骨干网络上，NM-Hebb显著提升准确性和NMI，生成更结构化、可解释的特征。

Conclusion: NM-Hebb通过结合局部Hebbian可塑性和度量微调，提供更准确、可解释的CNN，适用于资源受限和安全关键场景。

Abstract: Deep Convolutional Neural Networks (CNNs) achieve high accuracy but often
rely on purely global, gradient-based optimisation, which can lead to
overfitting, redundant filters, and reduced interpretability. To address these
limitations, we propose NM-Hebb, a two-phase training framework that integrates
neuro-inspired local plasticity with distance-aware supervision. Phase 1
extends standard supervised training by jointly optimising a cross-entropy
objective with two biologically inspired mechanisms: (i) a Hebbian regulariser
that aligns the spatial mean of activations with the mean of the corresponding
convolutional filter weights, encouraging structured, reusable primitives; and
(ii) a learnable neuromodulator that gates an elastic-weight-style
consolidation loss, preserving beneficial parameters without freezing the
network. Phase 2 fine-tunes the backbone with a pairwise metric-learning loss,
explicitly compressing intra-class distances and enlarging inter-class margins
in the embedding space. Evaluated on CIFAR-10, CIFAR-100, and TinyImageNet
across five backbones (ResNet-18, VGG-11, MobileNet-v2, EfficientNet-V2,
DenseNet-121), NM-Hebb achieves consistent gains over baseline and other
methods: Top-1 accuracy improves by +2.0-10.0 pp (CIFAR-10), +2.0-9.0 pp
(CIFAR-100), and up to +4.3-8.9 pp (TinyImageNet), with Normalised Mutual
Information (NMI) increased by up to +0.15. Qualitative visualisations and
filter-level analyses further confirm that NM-Hebb produces more structured and
selective features, yielding tighter and more interpretable class clusters.
Overall, coupling local Hebbian plasticity with metric-based fine-tuning yields
CNNs that are not only more accurate but also more interpretable, offering
practical benefits for resource-constrained and safety-critical AI deployments.

</details>


### [167] [Adaptive Scaling of Policy Constraints for Offline Reinforcement Learning](https://arxiv.org/abs/2508.19900)
*Tan Jing,Xiaorui Li,Chao Yao,Xiaojuan Ban,Yuetong Fang,Renjing Xu,Zhaolin Yuan*

Main category: cs.LG

TL;DR: ASPC是一种自适应策略约束框架，通过动态平衡强化学习和行为克隆，无需繁琐的超参数调整，在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有离线强化学习方法需要针对不同数据集调整超参数，耗时且不实用。

Method: 提出ASPC框架，动态平衡RL和BC，理论分析其性能提升保证。

Result: 在39个D4RL数据集上，ASPC表现优于其他方法，且计算开销小。

Conclusion: ASPC是一种高效且无需繁琐调整的离线强化学习方法。

Abstract: Offline reinforcement learning (RL) enables learning effective policies from
fixed datasets without any environment interaction. Existing methods typically
employ policy constraints to mitigate the distribution shift encountered during
offline RL training. However, because the scale of the constraints varies
across tasks and datasets of differing quality, existing methods must
meticulously tune hyperparameters to match each dataset, which is
time-consuming and often impractical. We propose Adaptive Scaling of Policy
Constraints (ASPC), a second-order differentiable framework that dynamically
balances RL and behavior cloning (BC) during training. We theoretically analyze
its performance improvement guarantee. In experiments on 39 datasets across
four D4RL domains, ASPC using a single hyperparameter configuration outperforms
other adaptive constraint methods and state-of-the-art offline RL algorithms
that require per-dataset tuning while incurring only minimal computational
overhead. The code will be released at https://github.com/Colin-Jing/ASPC.

</details>


### [168] [GegenNet: Spectral Convolutional Neural Networks for Link Sign Prediction in Signed Bipartite Graphs](https://arxiv.org/abs/2508.19907)
*Hewen Wang,Renchi Yang,Xiaokui Xiao*

Main category: cs.LG

TL;DR: GegenNet是一种新型的谱卷积神经网络模型，用于有符号二分图中的链接符号预测，通过多项技术创新显著提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要针对单分图，忽略了二分图的节点异质性和独特特性，且传统谱卷积算子不适用于有符号链接的预测。

Method: 提出GegenNet，包括快速谱分解技术、基于Gegenbauer多项式的新谱滤波器，以及多层符号感知卷积网络。

Result: 在6个基准数据集上，GegenNet比11个竞争对手在AUC和F1上分别提升了4.28%和11.69%。

Conclusion: GegenNet通过创新的谱卷积方法，显著提升了有符号二分图中的链接符号预测性能。

Abstract: Given a signed bipartite graph (SBG) G with two disjoint node sets U and V,
the goal of link sign prediction is to predict the signs of potential links
connecting U and V based on known positive and negative edges in G. The
majority of existing solutions towards link sign prediction mainly focus on
unipartite signed graphs, which are sub-optimal due to the neglect of node
heterogeneity and unique bipartite characteristics of SBGs. To this end, recent
studies adapt graph neural networks to SBGs by introducing message-passing
schemes for both inter-partition (UxV) and intra-partition (UxU or VxV) node
pairs. However, the fundamental spectral convolutional operators were
originally designed for positive links in unsigned graphs, and thus, are not
optimal for inferring missing positive or negative links from known ones in
SBGs.
  Motivated by this, this paper proposes GegenNet, a novel and effective
spectral convolutional neural network model for link sign prediction in SBGs.
In particular, GegenNet achieves enhanced model capacity and high predictive
accuracy through three main technical contributions: (i) fast and theoretically
grounded spectral decomposition techniques for node feature initialization;
(ii) a new spectral graph filter based on the Gegenbauer polynomial basis; and
(iii) multi-layer sign-aware spectral convolutional networks alternating
Gegenbauer polynomial filters with positive and negative edges. Our extensive
empirical studies reveal that GegenNet can achieve significantly superior
performance (up to a gain of 4.28% in AUC and 11.69% in F1) in link sign
prediction compared to 11 strong competitors over 6 benchmark SBG datasets.

</details>


### [169] [Ontology-Based Concept Distillation for Radiology Report Retrieval and Labeling](https://arxiv.org/abs/2508.19915)
*Felix Nützel,Mischa Dombrowski,Bernhard Kainz*

Main category: cs.LG

TL;DR: 提出一种基于UMLS的放射学报告检索方法，优于现有嵌入方法，尤其在长尾任务中表现突出。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖高维文本嵌入，难以解释且计算昂贵，与医学知识结构化特性不匹配。

Method: 使用RadGraph-XL和SapBERT提取标准化医学实体，基于改进的Tversky Index定义相似性度量。

Result: 在MIMIC-CXR上优于现有方法，生成了基于本体的疾病标签。

Conclusion: 提供了更可解释、可靠且任务特定的临床AI检索策略。

Abstract: Retrieval-augmented learning based on radiology reports has emerged as a
promising direction to improve performance on long-tail medical imaging tasks,
such as rare disease detection in chest X-rays. Most existing methods rely on
comparing high-dimensional text embeddings from models like CLIP or CXR-BERT,
which are often difficult to interpret, computationally expensive, and not
well-aligned with the structured nature of medical knowledge. We propose a
novel, ontology-driven alternative for comparing radiology report texts based
on clinically grounded concepts from the Unified Medical Language System
(UMLS). Our method extracts standardised medical entities from free-text
reports using an enhanced pipeline built on RadGraph-XL and SapBERT. These
entities are linked to UMLS concepts (CUIs), enabling a transparent,
interpretable set-based representation of each report. We then define a
task-adaptive similarity measure based on a modified and weighted version of
the Tversky Index that accounts for synonymy, negation, and hierarchical
relationships between medical entities. This allows efficient and semantically
meaningful similarity comparisons between reports. We demonstrate that our
approach outperforms state-of-the-art embedding-based retrieval methods in a
radiograph classification task on MIMIC-CXR, particularly in long-tail
settings. Additionally, we use our pipeline to generate ontology-backed disease
labels for MIMIC-CXR, offering a valuable new resource for downstream learning
tasks. Our work provides more explainable, reliable, and task-specific
retrieval strategies in clinical AI systems, especially when interpretability
and domain knowledge integration are essential. Our code is available at
https://github.com/Felix-012/ontology-concept-distillation

</details>


### [170] [FlowletFormer: Network Behavioral Semantic Aware Pre-training Model for Traffic Classification](https://arxiv.org/abs/2508.19924)
*Liming Liu,Ruoyu Li,Qing Li,Meijia Hou,Yong Jiang,Mingwei Xu*

Main category: cs.LG

TL;DR: FlowletFormer是一种基于BERT的预训练模型，用于网络流量分析，通过改进流量表示和分类性能显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以捕捉数据包结构特征、流级行为、分层协议语义和包间上下文关系。

Method: 提出FlowletFormer，包含行为感知流量表示模型、协议栈对齐嵌入层和特定领域预训练任务。

Result: 实验显示FlowletFormer在流量表示、分类准确性和少样本学习能力上显著优于现有方法。

Conclusion: FlowletFormer通过整合领域知识，提供了更鲁棒和可信的流量分析框架。

Abstract: Network traffic classification using pre-training models has shown promising
results, but existing methods struggle to capture packet structural
characteristics, flow-level behaviors, hierarchical protocol semantics, and
inter-packet contextual relationships. To address these challenges, we propose
FlowletFormer, a BERT-based pre-training model specifically designed for
network traffic analysis. FlowletFormer introduces a Coherent Behavior-Aware
Traffic Representation Model for segmenting traffic into semantically
meaningful units, a Protocol Stack Alignment-Based Embedding Layer to capture
multilayer protocol semantics, and Field-Specific and Context-Aware Pretraining
Tasks to enhance both inter-packet and inter-flow learning. Experimental
results demonstrate that FlowletFormer significantly outperforms existing
methods in the effectiveness of traffic representation, classification
accuracy, and few-shot learning capability. Moreover, by effectively
integrating domain-specific network knowledge, FlowletFormer shows better
comprehension of the principles of network transmission (e.g., stateful
connections of TCP), providing a more robust and trustworthy framework for
traffic analysis.

</details>


### [171] [Constraint Learning in Multi-Agent Dynamic Games from Demonstrations of Local Nash Interactions](https://arxiv.org/abs/2508.19945)
*Zhouyu Zhang,Chih-Yuan Chiu,Glen Chou*

Main category: cs.LG

TL;DR: 提出一种基于逆动态博弈的算法，从多智能体的局部广义纳什均衡交互数据中学习参数化约束。


<details>
  <summary>Details</summary>
Motivation: 研究如何从纳什均衡交互演示中学习约束条件，以设计满足这些约束的运动规划。

Method: 引入混合整数线性规划（MILP）编码KKT条件，恢复与纳什平稳性一致的约束。

Result: 理论证明方法能学习真实安全与非安全集的内近似，并在仿真和硬件实验中验证了有效性。

Conclusion: 方法适用于凸和非凸约束，能从非线性动态智能体的交互演示中推断约束并设计鲁棒运动规划。

Abstract: We present an inverse dynamic game-based algorithm to learn parametric
constraints from a given dataset of local generalized Nash equilibrium
interactions between multiple agents. Specifically, we introduce mixed-integer
linear programs (MILP) encoding the Karush-Kuhn-Tucker (KKT) conditions of the
interacting agents, which recover constraints consistent with the Nash
stationarity of the interaction demonstrations. We establish theoretical
guarantees that our method learns inner approximations of the true safe and
unsafe sets, as well as limitations of constraint learnability from
demonstrations of Nash equilibrium interactions. We also use the interaction
constraints recovered by our method to design motion plans that robustly
satisfy the underlying constraints. Across simulations and hardware
experiments, our methods proved capable of inferring constraints and designing
interactive motion plans for various classes of constraints, both convex and
non-convex, from interaction demonstrations of agents with nonlinear dynamics.

</details>


### [172] [Global Permutation Entropy](https://arxiv.org/abs/2508.19955)
*Abhijit Avhale,Joscha Diehl,Niraj Velankar,Emanuele Verri*

Main category: cs.LG

TL;DR: 论文提出了一种新的全局排列熵（GPE）方法，通过考虑所有可能的排列模式（包括非连续模式）来改进传统的排列熵方法。


<details>
  <summary>Details</summary>
Motivation: 传统的排列熵方法仅考虑连续段的排列模式，可能忽略了一些重要的结构信息。GPE旨在通过更全面的排列模式分析来提升复杂性测量的准确性。

Method: GPE利用新开发的算法高效提取完整的排列模式分布，并计算其香农熵。

Result: 实验表明，GPE能够揭示传统排列熵无法捕捉的结构信息。

Conclusion: GPE是一种有效的复杂性测量工具，适用于更广泛的时间序列分析场景。

Abstract: Permutation Entropy, introduced by Bandt and Pompe, is a widely used
complexity measure for real-valued time series that is based on the relative
order of values within consecutive segments of fixed length. After
standardizing each segment to a permutation and computing the frequency
distribution of these permutations, Shannon Entropy is then applied to quantify
the series' complexity. We introduce Global Permutation Entropy (GPE), a novel
index that considers all possible patterns of a given length, including
non-consecutive ones. Its computation relies on recently developed algorithms
that enable the efficient extraction of full permutation profiles. We
illustrate some properties of GPE and demonstrate its effectiveness through
experiments on synthetic datasets, showing that it reveals structural
information not accessible through standard permutation entropy. We provide a
Julia package for the calculation of GPE at
`https://github.com/AThreeH1/Global-Permutation-Entropy'.

</details>


### [173] [Short-Horizon Predictive Maintenance of Industrial Pumps Using Time-Series Features and Machine Learning](https://arxiv.org/abs/2508.19974)
*Khaled M. A. Alghtus,Aiyad Gannan,Khalid M. Alhajri,Ali L. A. Al Jubouri,Hassan A. I. Al-Janahi*

Main category: cs.LG

TL;DR: 提出了一种基于机器学习的工业离心泵短期故障预测框架，使用实时传感器数据预测5、15和30分钟前的故障。


<details>
  <summary>Details</summary>
Motivation: 旨在通过历史操作数据提取模式，提前预测故障，以支持工业实时监控系统的预测性维护。

Method: 采用滑动窗口方法评估60分钟和120分钟的回溯期，提取统计特征并使用SMOTE算法处理类别不平衡，训练和测试随机森林和XGBoost分类器。

Result: 随机森林模型在60分钟窗口下表现最佳，召回率分别为69.2%（5分钟）、64.9%（15分钟）和48.6%（30分钟）；120分钟窗口下召回率为57.6%（5分钟）和65.6%（15和30分钟）。

Conclusion: 结果表明，最佳历史长度取决于预测时间范围，不同故障模式可能在不同时间尺度上演变，该方法为实时工业监控系统提供了可解释和可扩展的解决方案。

Abstract: This study presents a machine learning framework for forecasting short-term
faults in industrial centrifugal pumps using real-time sensor data. The
approach aims to predict {EarlyWarning} conditions 5, 15, and 30 minutes in
advance based on patterns extracted from historical operation. Two lookback
periods, 60 minutes and 120 minutes, were evaluated using a sliding window
approach. For each window, statistical features including mean, standard
deviation, minimum, maximum, and linear trend were extracted, and class
imbalance was addressed using the SMOTE algorithm. Random Forest and XGBoost
classifiers were trained and tested on the labeled dataset. Results show that
the Random Forest model achieved the best short-term forecasting performance
with a 60-minute window, reaching recall scores of 69.2\% at 5 minutes, 64.9\%
at 15 minutes, and 48.6\% at 30 minutes. With a 120-minute window, the Random
Forest model achieved 57.6\% recall at 5 minutes, and improved predictive
accuracy of 65.6\% at both 15 and 30 minutes. XGBoost displayed similar but
slightly lower performance. These findings highlight that optimal history
length depends on the prediction horizon, and that different fault patterns may
evolve at different timescales. The proposed method offers an interpretable and
scalable solution for integrating predictive maintenance into real-time
industrial monitoring systems.

</details>


### [174] [Reducing Street Parking Search Time via Smart Assignment Strategies](https://arxiv.org/abs/2508.19979)
*Behafarid Hemmatpour,Javad Dogani,Nikolaos Laoutaris*

Main category: cs.LG

TL;DR: 论文研究了实时停车助手App对减少停车搜索时间和交通拥堵的影响，提出了一种新的协调近似策略（Cord-Approx），显著降低了停车搜索时间。


<details>
  <summary>Details</summary>
Motivation: 在密集的大都市中，寻找路边停车位会增加交通拥堵。尽管已有基于手机的实时助手应用，但其效果尚未充分研究。

Method: 通过数据驱动的模拟，分析了四种策略：无协调搜索（Unc-Agn）、协调停车但无非用户意识（Cord-Agn）、理想化的全知系统（Cord-Oracle）以及新提出的Cord-Approx策略。Cord-Approx利用历史占用分布和匈牙利匹配算法分配停车位。

Result: 在马德里的高保真模拟中，Cord-Approx用户平均停车搜索时间为6.69分钟，比非用户快72%-73%。

Conclusion: Cord-Approx策略显著减少了停车搜索时间，尤其在中心区域和住宅区效果显著。

Abstract: In dense metropolitan areas, searching for street parking adds to traffic
congestion. Like many other problems, real-time assistants based on mobile
phones have been proposed, but their effectiveness is understudied. This work
quantifies how varying levels of user coordination and information availability
through such apps impact search time and the probability of finding street
parking. Through a data-driven simulation of Madrid's street parking ecosystem,
we analyze four distinct strategies: uncoordinated search (Unc-Agn),
coordinated parking without awareness of non-users (Cord-Agn), an idealized
oracle system that knows the positions of all non-users (Cord-Oracle), and our
novel/practical Cord-Approx strategy that estimates non-users' behavior
probabilistically. The Cord-Approx strategy, instead of requiring knowledge of
how close non-users are to a certain spot in order to decide whether to
navigate toward it, uses past occupancy distributions to elongate physical
distances between system users and alternative parking spots, and then solves a
Hungarian matching problem to dispatch accordingly. In high-fidelity
simulations of Madrid's parking network with real traffic data, users of
Cord-Approx averaged 6.69 minutes to find parking, compared to 19.98 minutes
for non-users without an app. A zone-level snapshot shows that Cord-Approx
reduces search time for system users by 72% (range = 67-76%) in central hubs,
and up to 73% in residential areas, relative to non-users.

</details>


### [175] [Evaluating Language Model Reasoning about Confidential Information](https://arxiv.org/abs/2508.19980)
*Dylan Sam,Alexander Robey,Andy Zou,Matt Fredrikson,J. Zico Kolter*

Main category: cs.LG

TL;DR: 研究发现当前语言模型在遵循上下文相关安全规范方面表现不佳，推理能力并未提升性能，反而可能泄露敏感信息。


<details>
  <summary>Details</summary>
Motivation: 确保语言模型在高风险环境中可靠遵循用户定义规则是重要的安全问题。

Method: 开发了PasswordEval基准测试，评估模型在密码验证任务中的表现，并增加对抗性用户压力和多轮对话难度。

Result: 当前开源和闭源模型在简单任务中表现不佳，推理痕迹常泄露信息，不适合处理机密信息。

Conclusion: 前沿模型不适合处理机密信息，推理能力需改进以提升安全性。

Abstract: As language models are increasingly deployed as autonomous agents in
high-stakes settings, ensuring that they reliably follow user-defined rules has
become a critical safety concern. To this end, we study whether language models
exhibit contextual robustness, or the capability to adhere to context-dependent
safety specifications. For this analysis, we develop a benchmark (PasswordEval)
that measures whether language models can correctly determine when a user
request is authorized (i.e., with a correct password). We find that current
open- and closed-source models struggle with this seemingly simple task, and
that, perhaps surprisingly, reasoning capabilities do not generally improve
performance. In fact, we find that reasoning traces frequently leak
confidential information, which calls into question whether reasoning traces
should be exposed to users in such applications. We also scale the difficulty
of our evaluation along multiple axes: (i) by adding adversarial user pressure
through various jailbreaking strategies, and (ii) through longer multi-turn
conversations where password verification is more challenging. Overall, our
results suggest that current frontier models are not well-suited to handling
confidential information, and that reasoning capabilities may need to be
trained in a different manner to make them safer for release in high-stakes
settings.

</details>


### [176] [Self-Supervised Pre-Training with Equilibrium Constraints](https://arxiv.org/abs/2508.19990)
*Xiaodong Cui,A F M Saif,Brian Kingsbury,Tianyi Chen*

Main category: cs.LG

TL;DR: 提出了一种新的自监督预训练方法，通过引入均衡约束处理异构数据，显著提升下游任务的适应性。


<details>
  <summary>Details</summary>
Motivation: 传统方法将所有数据混合并最小化全局损失，无法充分优化异构数据的局部最优。

Method: 采用双层优化问题，通过一阶近似方法解决，并与MAML建立联系。

Result: 实验表明，该方法在多领域和多语言数据集上显著提升模型适应性。

Conclusion: 新方法通过均衡约束优化异构数据，有效提升自监督预训练模型的下游任务性能。

Abstract: Self-supervised pre-training using unlabeled data is widely used in machine
learning. In this paper, we propose a new self-supervised pre-training approach
to dealing with heterogeneous data. Instead of mixing all the data and
minimizing the averaged global loss in the conventional way, we impose
additional equilibrium constraints to ensure that the models optimizes each
source of heterogeneous data to its local optima after $K$-step gradient
descent initialized from the model. We formulate this as a bilevel optimization
problem, and use the first-order approximation method to solve the problem. We
discuss its connection to model-agnostic meta learning (MAML). Experiments are
carried out on self-supervised pre-training using multi-domain and multilingual
datasets, demonstrating that the proposed approach can significantly improve
the adaptivity of the self-supervised pre-trained model for the downstream
supervised fine-tuning tasks.

</details>


### [177] [Linear-Time Demonstration Selection for In-Context Learning via Gradient Estimation](https://arxiv.org/abs/2508.19999)
*Ziniu Zhang,Zhenshuo Zhang,Dongyue Li,Lu Wang,Jennifer Dy,Hongyang R. Zhang*

Main category: cs.LG

TL;DR: 提出一种基于梯度的算法，高效选择上下文学习中的示例，提升推理性能。


<details>
  <summary>Details</summary>
Motivation: 在上下文学习中，如何从大量示例中快速选择最优子集是一个关键问题，现有方法基于词嵌入相似性，但效果有限。

Method: 通过梯度估计模型输出，随机采样子集并聚合结果，形成影响分数来选择最优示例。

Result: 算法在多个数据集上误差小于1%，速度提升37.7倍，性能优于现有方法11%。

Conclusion: 梯度方法显著提升了示例选择的效率和准确性，适用于大规模模型。

Abstract: This paper introduces an algorithm to select demonstration examples for
in-context learning of a query set. Given a set of $n$ examples, how can we
quickly select $k$ out of $n$ to best serve as the conditioning for downstream
inference? This problem has broad applications in prompt tuning and
chain-of-thought reasoning. Since model weights remain fixed during in-context
learning, previous work has sought to design methods based on the similarity of
token embeddings. This work proposes a new approach based on gradients of the
output taken in the input embedding space. Our approach estimates model outputs
through a first-order approximation using the gradients. Then, we apply this
estimation to multiple randomly sampled subsets. Finally, we aggregate the
sampled subset outcomes to form an influence score for each demonstration, and
select $k$ most relevant examples. This procedure only requires pre-computing
model outputs and gradients once, resulting in a linear-time algorithm relative
to model and training set sizes. Extensive experiments across various models
and datasets validate the efficiency of our approach. We show that the gradient
estimation procedure yields approximations of full inference with less than
$\mathbf{1}\%$ error across six datasets. This allows us to scale up subset
selection that would otherwise run full inference by up to
$\mathbf{37.7}\times$ on models with up to $34$ billion parameters, and
outperform existing selection methods based on input embeddings by
$\mathbf{11}\%$ on average.

</details>


### [178] [Cross-Platform E-Commerce Product Categorization and Recategorization: A Multimodal Hierarchical Classification Approach](https://arxiv.org/abs/2508.20013)
*Lotte Gross,Rebecca Walter,Nicole Zoppi,Adrien Justus,Alessandro Gambetti,Qiwei Han,Maximilian Kaiser*

Main category: cs.LG

TL;DR: 提出多模态分层分类框架解决电商产品分类中的平台异构性和现有分类法结构限制问题，结合文本、视觉和视觉-语言特征，通过不同融合策略实现高精度分类。


<details>
  <summary>Details</summary>
Motivation: 解决电商平台产品分类中的平台异构性和现有分类法结构不一致问题。

Method: 使用RoBERTa、ViT和CLIP提取多模态特征，采用早期、晚期和注意力融合策略，结合动态掩码和自监督产品重分类流程。

Result: CLIP嵌入结合MLP晚期融合策略达到最高分层F1（98.59%），自监督流程发现新细粒度类别（纯度>86%）。

Conclusion: 复杂晚期融合方法在多样化数据中表现最佳，而早期融合方法在未见平台上泛化能力更强，框架已成功部署于商业平台。

Abstract: This study addresses critical industrial challenges in e-commerce product
categorization, namely platform heterogeneity and the structural limitations of
existing taxonomies, by developing and deploying a multimodal hierarchical
classification framework. Using a dataset of 271,700 products from 40
international fashion e-commerce platforms, we integrate textual features
(RoBERTa), visual features (ViT), and joint vision--language representations
(CLIP). We investigate fusion strategies, including early, late, and
attention-based fusion within a hierarchical architecture enhanced by dynamic
masking to ensure taxonomic consistency. Results show that CLIP embeddings
combined via an MLP-based late-fusion strategy achieve the highest hierarchical
F1 (98.59\%), outperforming unimodal baselines. To address shallow or
inconsistent categories, we further introduce a self-supervised ``product
recategorization'' pipeline using SimCLR, UMAP, and cascade clustering, which
discovered new, fine-grained categories (e.g., subtypes of ``Shoes'') with
cluster purities above 86\%. Cross-platform experiments reveal a
deployment-relevant trade-off: complex late-fusion methods maximize accuracy
with diverse training data, while simpler early-fusion methods generalize more
effectively to unseen platforms. Finally, we demonstrate the framework's
industrial scalability through deployment in EURWEB's commercial transaction
intelligence platform via a two-stage inference pipeline, combining a
lightweight RoBERTa stage with a GPU--accelerated multimodal stage to balance
cost and accuracy.

</details>


### [179] [Decomposing Behavioral Phase Transitions in LLMs: Order Parameters for Emergent Misalignment](https://arxiv.org/abs/2508.20015)
*Julian Arnold,Niels Lörch*

Main category: cs.LG

TL;DR: 论文提出了一种框架，用于检测和量化微调LLMs时出现的突发性不对齐行为，并分解了模型输出的分布变化。


<details>
  <summary>Details</summary>
Motivation: 研究微调LLMs时，模型行为如何从对齐变为不对齐，以及这种变化的机制。

Method: 结合分布变化检测方法和基于自然语言的序参量，通过LLM评估量化微调过程中的相变。

Result: 发现行为转变比梯度范数峰值更晚发生，并分解了模型输出的分布变化。

Conclusion: 框架能自动发现和量化语言序参量，适用于知识、政治和伦理等领域。

Abstract: Fine-tuning LLMs on narrowly harmful datasets can lead to behavior that is
broadly misaligned with respect to human values. To understand when and how
this emergent misalignment occurs, we develop a comprehensive framework for
detecting and characterizing rapid transitions during fine-tuning using both
distributional change detection methods as well as order parameters that are
formulated in plain English and evaluated by an LLM judge. Using an objective
statistical dissimilarity measure, we quantify how the phase transition that
occurs during fine-tuning affects multiple aspects of the model. In particular,
we assess what percentage of the total distributional change in model outputs
is captured by different aspects, such as alignment or verbosity, providing a
decomposition of the overall transition. We also find that the actual
behavioral transition occurs later in training than indicated by the peak in
the gradient norm alone. Our framework enables the automated discovery and
quantification of language-based order parameters, which we demonstrate on
examples ranging from knowledge questions to politics and ethics.

</details>


### [180] [Symphony: A Decentralized Multi-Agent Framework for Scalable Collective Intelligence](https://arxiv.org/abs/2508.20019)
*Ji Wang,Kashing Chen,Xinyuan Song,Ke Zhang,Lynn Ai,Eric Yang,Bill Shi*

Main category: cs.LG

TL;DR: Symphony是一个去中心化的多智能体系统，旨在解决现有LLM框架的高成本、通信拓扑僵化和适应性差的问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM框架依赖集中式编排，导致高部署成本、通信拓扑僵化和适应性受限。

Method: Symphony引入三种机制：去中心化账本记录能力、Beacon选择协议动态分配任务、基于CoTs的加权结果投票。

Result: Symphony在推理基准测试中优于现有基线，显著提升准确性，并在不同容量模型中表现稳健。

Conclusion: Symphony提供了一种低开销、隐私保护、可扩展且容错的编排方案。

Abstract: Most existing Large Language Model (LLM)-based agent frameworks rely on
centralized orchestration, incurring high deployment costs, rigid communication
topologies, and limited adaptability. To address these challenges, we introduce
Symphony, a decentralized multi-agent system which enables lightweight LLMs on
consumer-grade GPUs to coordinate. Symphony introduces three key mechanisms:
(1) a decentralized ledger that records capabilities, (2) a Beacon-selection
protocol for dynamic task allocation, and (3) weighted result voting based on
CoTs. This design forms a privacy-saving, scalable, and fault-tolerant
orchestration with low overhead. Empirically, Symphony outperforms existing
baselines on reasoning benchmarks, achieving substantial accuracy gains and
demonstrating robustness across models of varying capacities.

</details>


### [181] [FairLoop: Software Support for Human-Centric Fairness in Predictive Business Process Monitoring](https://arxiv.org/abs/2508.20021)
*Felix Möhrlein,Martin Käppel,Julian Neuberger,Sven Weinzierl,Lars Ackermann,Martin Matzner,Stefan Jablonski*

Main category: cs.LG

TL;DR: FairLoop是一种工具，通过人类参与选择性消除敏感属性对预测模型的影响，实现上下文感知的偏见缓解。


<details>
  <summary>Details</summary>
Motivation: 敏感属性（如性别或年龄）可能导致机器学习任务中的不公平预测，尤其是在不考虑上下文的情况下使用这些属性时。

Method: FairLoop通过从神经网络中提取决策树，允许用户检查和修改不公平的决策逻辑，然后用于微调原始模型以实现更公平的预测。

Result: 与其他公平性方法相比，FairLoop通过人类参与实现了上下文感知的偏见移除，选择性处理敏感属性的影响。

Conclusion: FairLoop提供了一种有效的方式，通过人类干预和模型微调，实现更公平的预测结果。

Abstract: Sensitive attributes like gender or age can lead to unfair predictions in
machine learning tasks such as predictive business process monitoring,
particularly when used without considering context. We present FairLoop1, a
tool for human-guided bias mitigation in neural network-based prediction
models. FairLoop distills decision trees from neural networks, allowing users
to inspect and modify unfair decision logic, which is then used to fine-tune
the original model towards fairer predictions. Compared to other approaches to
fairness, FairLoop enables context-aware bias removal through human
involvement, addressing the influence of sensitive attributes selectively
rather than excluding them uniformly.

</details>


### [182] [Using item recommendations and LLMs in marketing email titles](https://arxiv.org/abs/2508.20024)
*Deddy Jobson,Muktti Shukla,Phuong Dinh,Julio Christian Young,Nick Pitton,Nina Chen,Ryan Ginstrom*

Main category: cs.LG

TL;DR: 利用大型语言模型（LLM）生成个性化电子邮件主题，提升用户参与度。


<details>
  <summary>Details</summary>
Motivation: 传统电子邮件主题模板固定，无法有效激发用户兴趣，限制了营销效果。

Method: 通过离线模拟和在线实验，测试LLM生成个性化主题的效果。

Result: 实验表明，个性化主题显著提高了用户与电子邮件的互动率。

Conclusion: LLM生成的主题能安全、自动化地提升营销邮件的效果。

Abstract: E-commerce marketplaces make use of a number of marketing channels like
emails, push notifications, etc. to reach their users and stimulate purchases.
Personalized emails especially are a popular touch point for marketers to
inform users of latest items in stock, especially for those who stopped
visiting the marketplace. Such emails contain personalized recommendations
tailored to each user's interests, enticing users to buy relevant items. A
common limitation of these emails is that the primary entry point, the title of
the email, tends to follow fixed templates, failing to inspire enough interest
in the contents. In this work, we explore the potential of large language
models (LLMs) for generating thematic titles that reflect the personalized
content of the emails. We perform offline simulations and conduct online
experiments on the order of millions of users, finding our techniques useful in
improving the engagement between customers and our emails. We highlight key
findings and learnings as we productionize the safe and automated generation of
email titles for millions of users.

</details>


### [183] [Pruning Strategies for Backdoor Defense in LLMs](https://arxiv.org/abs/2508.20032)
*Santosh Chapagain,Shah Muhammad Hamdi,Soukaina Filali Boubrahimi*

Main category: cs.LG

TL;DR: 研究探讨了注意力头剪枝是否能有效防御预训练语言模型中的后门攻击，提出了六种剪枝策略，并评估了它们在防御不同类型攻击时的效果。


<details>
  <summary>Details</summary>
Motivation: 后门攻击对预训练语言模型的性能和完整性构成威胁，且难以通过传统方法防御，因此需要探索无需触发知识或干净模型的防御方法。

Method: 设计了六种剪枝策略（梯度剪枝、分层方差剪枝、结构化L1/L2剪枝、随机集成剪枝、强化学习剪枝和贝叶斯不确定性剪枝），通过迭代移除信息量最小的注意力头来防御攻击。

Result: 梯度剪枝在防御语法触发攻击时表现最佳，而强化学习和贝叶斯剪枝在防御风格攻击时更有效。

Conclusion: 注意力头剪枝是一种有效的后门攻击防御方法，且不同剪枝策略适用于不同类型的攻击。

Abstract: Backdoor attacks are a significant threat to the performance and integrity of
pre-trained language models. Although such models are routinely fine-tuned for
downstream NLP tasks, recent work shows they remain vulnerable to backdoor
attacks that survive vanilla fine-tuning. These attacks are difficult to defend
because end users typically lack knowledge of the attack triggers. Such attacks
consist of stealthy malicious triggers introduced through subtle syntactic or
stylistic manipulations, which can bypass traditional detection and remain in
the model, making post-hoc purification essential. In this study, we explore
whether attention-head pruning can mitigate these threats without any knowledge
of the trigger or access to a clean reference model. To this end, we design and
implement six pruning-based strategies: (i) gradient-based pruning, (ii)
layer-wise variance pruning, (iii) gradient-based pruning with structured L1/L2
sparsification, (iv) randomized ensemble pruning, (v)
reinforcement-learning-guided pruning, and (vi) Bayesian uncertainty pruning.
Each method iteratively removes the least informative heads while monitoring
validation accuracy to avoid over-pruning. Experimental evaluation shows that
gradient-based pruning performs best while defending the syntactic triggers,
whereas reinforcement learning and Bayesian pruning better withstand stylistic
attacks.

</details>


### [184] [Reinforcement Learning for Search Tree Size Minimization in Constraint Programming: New Results on Scheduling Benchmarks](https://arxiv.org/abs/2508.20056)
*Vilém Heinz,Petr Vilím,Zdeněk Hanzálek*

Main category: cs.LG

TL;DR: Failure-Directed Search (FDS)结合多臂老虎机（MAB）强化学习算法，在调度问题中显著提升了搜索效率。


<details>
  <summary>Details</summary>
Motivation: 分析FDS的特性，发现其搜索树最小化与MAB问题相关，从而探索如何通过MAB算法优化FDS。

Method: 将MAB算法应用于FDS，并进行问题特定改进和参数调优，评估其在JSSP和RCPSP上的表现。

Result: 优化后的FDS在JSSP和RCPSP基准测试中分别提速1.7倍和2.1倍，且改进了多个实例的下界。

Conclusion: 增强版FDS在调度问题中表现优异，显著提升了搜索效率和结果质量。

Abstract: Failure-Directed Search (FDS) is a significant complete generic search
algorithm used in Constraint Programming (CP) to efficiently explore the search
space, proven particularly effective on scheduling problems. This paper
analyzes FDS's properties, showing that minimizing the size of its search tree
guided by ranked branching decisions is closely related to the Multi-armed
bandit (MAB) problem. Building on this insight, MAB reinforcement learning
algorithms are applied to FDS, extended with problem-specific refinements and
parameter tuning, and evaluated on the two most fundamental scheduling
problems, the Job Shop Scheduling Problem (JSSP) and Resource-Constrained
Project Scheduling Problem (RCPSP). The resulting enhanced FDS, using the best
extended MAB algorithm and configuration, performs 1.7 times faster on the JSSP
and 2.1 times faster on the RCPSP benchmarks compared to the original
implementation in a new solver called OptalCP, while also being 3.5 times
faster on the JSSP and 2.1 times faster on the RCPSP benchmarks than the
current state-of-the-art FDS algorithm in IBM CP Optimizer 22.1. Furthermore,
using only a 900-second time limit per instance, the enhanced FDS improved the
existing state-of-the-art lower bounds of 78 of 84 JSSP and 226 of 393 RCPSP
standard open benchmark instances while also completely closing a few of them.

</details>
