<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 52]
- [cs.LG](#cs.LG) [Total: 51]
- [cs.RO](#cs.RO) [Total: 17]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Facial Emotion Recognition does not detect feeling unsafe in automated driving](https://arxiv.org/abs/2509.04490)
*Abel van Elburg,Konstantinos Gkentsidis,Mathieu Sarrazin,Sarah Barendswaard,Varun Kotian,Riender Happee*

Main category: cs.CV

TL;DR: 研究通过驾驶模拟器实验，分析了自动驾驶车辆中信任与感知安全对公众接受度的影响，发现动态驾驶风格和行人交互会增加不适感，面部表情识别不可靠，而神经网络模型能有效预测感知风险。


<details>
  <summary>Details</summary>
Motivation: 探讨自动驾驶车辆中公众的信任和感知安全对接受度的影响，以及如何客观评估感知风险。

Method: 使用驾驶模拟器进行实验，收集32名参与者的主观舒适度评分、生理数据（皮肤电导、心率）、面部表情和眼动数据，并开发神经网络模型预测感知风险。

Result: 动态驾驶风格和行人交互显著增加不适感；面部表情识别不可靠；神经网络模型能有效预测感知风险。

Conclusion: 面部表情识别不可靠，而基于车辆运动和皮肤电导的神经网络模型为客观评估感知风险提供了有效方法，减少了主观偏差。

Abstract: Trust and perceived safety play a crucial role in the public acceptance of
automated vehicles. To understand perceived risk, an experiment was conducted
using a driving simulator under two automated driving styles and optionally
introducing a crossing pedestrian. Data was collected from 32 participants,
consisting of continuous subjective comfort ratings, motion, webcam footage for
facial expression, skin conductance, heart rate, and eye tracking. The
continuous subjective perceived risk ratings showed significant discomfort
associated with perceived risk during cornering and braking followed by relief
or even positive comfort on continuing the ride. The dynamic driving style
induced a stronger discomfort as compared to the calm driving style. The
crossing pedestrian did not affect discomfort with the calm driving style but
doubled the comfort decrement with the dynamic driving style. This illustrates
the importance of consequences of critical interactions in risk perception.
Facial expression was successfully analyzed for 24 participants but most
(15/24) did not show any detectable facial reaction to the critical event.
Among the 9 participants who did, 8 showed a Happy expression, and only 4
showed a Surprise expression. Fear was never dominant. This indicates that
facial expression recognition is not a reliable method for assessing perceived
risk in automated vehicles. To predict perceived risk a neural network model
was implemented using vehicle motion and skin conductance. The model correlated
well with reported perceived risk, demonstrating its potential for objective
perceived risk assessment in automated vehicles, reducing subjective bias and
highlighting areas for future research.

</details>


### [2] [PromptEnhancer: A Simple Approach to Enhance Text-to-Image Models via Chain-of-Thought Prompt Rewriting](https://arxiv.org/abs/2509.04545)
*Linqing Wang,Ximing Xing,Yiji Cheng,Zhiyuan Zhao,Jiale Tao,Qixun Wang,Ruihuang Li,Xin Li,Mingrui Wu,Xinchi Deng,Chunyu Wang,Qinglin Lu*

Main category: cs.CV

TL;DR: PromptEnhancer是一个通用的提示词重写框架，通过强化学习优化提示词，提升文本到图像模型的生成效果。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像模型在复杂提示词（如属性绑定、否定和组合关系）上表现不佳，导致生成结果与用户意图不符。

Method: 提出一个基于强化学习的Chain-of-Thought重写器，通过AlignEvaluator提供的细粒度反馈优化提示词。

Result: 在HunyuanImage 2.1模型上实验表明，PromptEnhancer显著提升了图像与文本的对齐效果。

Conclusion: PromptEnhancer无需修改模型权重即可提升生成效果，并引入了一个新的人类偏好基准数据集。

Abstract: Recent advancements in text-to-image (T2I) diffusion models have demonstrated
remarkable capabilities in generating high-fidelity images. However, these
models often struggle to faithfully render complex user prompts, particularly
in aspects like attribute binding, negation, and compositional relationships.
This leads to a significant mismatch between user intent and the generated
output. To address this challenge, we introduce PromptEnhancer, a novel and
universal prompt rewriting framework that enhances any pretrained T2I model
without requiring modifications to its weights. Unlike prior methods that rely
on model-specific fine-tuning or implicit reward signals like image-reward
scores, our framework decouples the rewriter from the generator. We achieve
this by training a Chain-of-Thought (CoT) rewriter through reinforcement
learning, guided by a dedicated reward model we term the AlignEvaluator. The
AlignEvaluator is trained to provide explicit and fine-grained feedback based
on a systematic taxonomy of 24 key points, which are derived from a
comprehensive analysis of common T2I failure modes. By optimizing the CoT
rewriter to maximize the reward from our AlignEvaluator, our framework learns
to generate prompts that are more precisely interpreted by T2I models.
Extensive experiments on the HunyuanImage 2.1 model demonstrate that
PromptEnhancer significantly improves image-text alignment across a wide range
of semantic and compositional challenges. Furthermore, we introduce a new,
high-quality human preference benchmark to facilitate future research in this
direction.

</details>


### [3] [Skywork UniPic 2.0: Building Kontext Model with Online RL for Unified Multimodal Model](https://arxiv.org/abs/2509.04548)
*Hongyang Wei,Baixin Xu,Hongbo Liu,Cyrus Wu,Jie Liu,Yi Peng,Peiyu Wang,Zexiang Liu,Jingwen He,Yidan Xietian,Chuanxin Tang,Zidong Wang,Yichen Wei,Liang Hu,Boyi Jiang,William Li,Ying He,Yang Liu,Xuchen Song,Eric Li,Yahui Zhou*

Main category: cs.CV

TL;DR: UniPic2-SD3.5M-Kontext是一个基于SD3.5-Medium的2B参数DiT模型，通过改进架构和大规模预训练，结合渐进式双任务强化策略（PDTR），在图像生成和编辑任务中表现优异，并扩展为统一多模态模型UniPic2-Metaquery。


<details>
  <summary>Details</summary>
Motivation: 现有开源模型过于注重参数规模而忽视训练策略优化，限制了效率和性能。

Method: 改进SD3.5-Medium架构，大规模预训练，提出PDTR策略分阶段强化任务，并与Qwen2.5-VL-7B联合训练。

Result: UniPic2-SD3.5M-Kontext在生成和编辑任务上优于更大参数模型（如BAGEL和Flux-Kontext），UniPic2-Metaquery在多任务中表现顶级。

Conclusion: 提出的训练范式Skywork UniPic 2.0在效率和通用性上表现优异。

Abstract: Recent advances in multimodal models have demonstrated impressive
capabilities in unified image generation and editing. However, many prominent
open-source models prioritize scaling model parameters over optimizing training
strategies, limiting their efficiency and performance. In this work, we present
UniPic2-SD3.5M-Kontext, a 2B-parameter DiT model based on SD3.5-Medium, which
achieves state-of-the-art image generation and editing while extending
seamlessly into a unified multimodal framework. Our approach begins with
architectural modifications to SD3.5-Medium and large-scale pre-training on
high-quality data, enabling joint text-to-image generation and editing
capabilities. To enhance instruction following and editing consistency, we
propose a novel Progressive Dual-Task Reinforcement strategy (PDTR), which
effectively strengthens both tasks in a staged manner. We empirically validate
that the reinforcement phases for different tasks are mutually beneficial and
do not induce negative interference. After pre-training and reinforcement
strategies, UniPic2-SD3.5M-Kontext demonstrates stronger image generation and
editing capabilities than models with significantly larger generation
parameters-including BAGEL (7B) and Flux-Kontext (12B). Furthermore, following
the MetaQuery, we connect the UniPic2-SD3.5M-Kontext and Qwen2.5-VL-7B via a
connector and perform joint training to launch a unified multimodal model
UniPic2-Metaquery. UniPic2-Metaquery integrates understanding, generation, and
editing, achieving top-tier performance across diverse tasks with a simple and
scalable training paradigm. This consistently validates the effectiveness and
generalizability of our proposed training paradigm, which we formalize as
Skywork UniPic 2.0.

</details>


### [4] [Inpaint4Drag: Repurposing Inpainting Models for Drag-Based Image Editing via Bidirectional Warping](https://arxiv.org/abs/2509.04582)
*Jingyi Lu,Kai Han*

Main category: cs.CV

TL;DR: Inpaint4Drag是一个基于拖拽的图像编辑框架，通过双向变形和图像修复实现实时编辑，显著提升交互体验。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖生成模型的潜在空间操作，导致精度低、反馈延迟和模型限制。

Method: 将拖拽编辑分解为像素空间的双向变形和图像修复，模拟物理世界的弹性变形。

Result: 实现实时变形预览（0.01秒）和高效修复（0.3秒），支持512x512分辨率。

Conclusion: 该方法在视觉质量和精确控制上表现优异，且无需修改架构即可适配任何修复模型。

Abstract: Drag-based image editing has emerged as a powerful paradigm for intuitive
image manipulation. However, existing approaches predominantly rely on
manipulating the latent space of generative models, leading to limited
precision, delayed feedback, and model-specific constraints. Accordingly, we
present Inpaint4Drag, a novel framework that decomposes drag-based editing into
pixel-space bidirectional warping and image inpainting. Inspired by elastic
object deformation in the physical world, we treat image regions as deformable
materials that maintain natural shape under user manipulation. Our method
achieves real-time warping previews (0.01s) and efficient inpainting (0.3s) at
512x512 resolution, significantly improving the interaction experience compared
to existing methods that require minutes per edit. By transforming drag inputs
directly into standard inpainting formats, our approach serves as a universal
adapter for any inpainting model without architecture modification,
automatically inheriting all future improvements in inpainting technology.
Extensive experiments demonstrate that our method achieves superior visual
quality and precise control while maintaining real-time performance. Project
page: https://visual-ai.github.io/inpaint4drag/

</details>


### [5] [DisPatch: Disarming Adversarial Patches in Object Detection with Diffusion Models](https://arxiv.org/abs/2509.04597)
*Jin Ma,Mohammed Aldeen,Christopher Salas,Feng Luo,Mashrur Chowdhury,Mert Pesé,Long Cheng*

Main category: cs.CV

TL;DR: DISPATCH是一种基于扩散模型的防御框架，通过“再生和修正”策略有效对抗对抗性补丁攻击，无需先验知识，并在实验中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有目标检测器易受对抗性补丁攻击，导致严重后果，需要一种通用且鲁棒的防御方法。

Method: 利用扩散模型的生成能力再生图像，并通过修正过程替换对抗区域。

Result: 在隐藏攻击中达到89.3%的mAP.5，非目标创建攻击成功率降至24.8%，且对自适应攻击保持鲁棒性。

Conclusion: DISPATCH是一种实用且可靠的防御方法，适用于目标检测系统。

Abstract: Object detection is fundamental to various real-world applications, such as
security monitoring and surveillance video analysis. Despite their
advancements, state-of-theart object detectors are still vulnerable to
adversarial patch attacks, which can be easily applied to real-world objects to
either conceal actual items or create non-existent ones, leading to severe
consequences. Given the current diversity of adversarial patch attacks and
potential unknown threats, an ideal defense method should be effective,
generalizable, and robust against adaptive attacks. In this work, we introduce
DISPATCH, the first diffusion-based defense framework for object detection.
Unlike previous works that aim to "detect and remove" adversarial patches,
DISPATCH adopts a "regenerate and rectify" strategy, leveraging generative
models to disarm attack effects while preserving the integrity of the input
image. Specifically, we utilize the in-distribution generative power of
diffusion models to regenerate the entire image, aligning it with benign data.
A rectification process is then employed to identify and replace adversarial
regions with their regenerated benign counterparts. DISPATCH is attack-agnostic
and requires no prior knowledge of the existing patches. Extensive experiments
across multiple detectors and attacks demonstrate that DISPATCH consistently
outperforms state-of-the-art defenses on both hiding attacks and creating
attacks, achieving the best overall mAP.5 score of 89.3% on hiding attacks, and
lowering the attack success rate to 24.8% on untargeted creating attacks.
Moreover, it maintains strong robustness against adaptive attacks, making it a
practical and reliable defense for object detection systems.

</details>


### [6] [WATCH: World-aware Allied Trajectory and pose reconstruction for Camera and Human](https://arxiv.org/abs/2509.04600)
*Qijun Ying,Zhongyuan Hu,Rui Zhang,Ronghui Li,Yu Lu,Zijiao Zeng*

Main category: cs.CV

TL;DR: WATCH提出了一种统一框架，通过分解航向角和相机轨迹集成机制，解决了单目视频中全局人体运动重建的深度和运动模糊问题。


<details>
  <summary>Details</summary>
Motivation: 解决单目视频中人体运动重建的深度模糊、运动模糊及相机与人体运动纠缠问题。

Method: 引入航向角分解技术和相机轨迹集成机制。

Result: 在野外基准测试中达到最先进的轨迹重建性能。

Conclusion: 联合建模相机与人体运动关系有效，为相机平移集成提供了新思路。

Abstract: Global human motion reconstruction from in-the-wild monocular videos is
increasingly demanded across VR, graphics, and robotics applications, yet
requires accurate mapping of human poses from camera to world coordinates-a
task challenged by depth ambiguity, motion ambiguity, and the entanglement
between camera and human movements. While human-motion-centric approaches excel
in preserving motion details and physical plausibility, they suffer from two
critical limitations: insufficient exploitation of camera orientation
information and ineffective integration of camera translation cues. We present
WATCH (World-aware Allied Trajectory and pose reconstruction for Camera and
Human), a unified framework addressing both challenges. Our approach introduces
an analytical heading angle decomposition technique that offers superior
efficiency and extensibility compared to existing geometric methods.
Additionally, we design a camera trajectory integration mechanism inspired by
world models, providing an effective pathway for leveraging camera translation
information beyond naive hard-decoding approaches. Through experiments on
in-the-wild benchmarks, WATCH achieves state-of-the-art performance in
end-to-end trajectory reconstruction. Our work demonstrates the effectiveness
of jointly modeling camera-human motion relationships and offers new insights
for addressing the long-standing challenge of camera translation integration in
global human motion reconstruction. The code will be available publicly.

</details>


### [7] [Sali4Vid: Saliency-Aware Video Reweighting and Adaptive Caption Retrieval for Dense Video Captioning](https://arxiv.org/abs/2509.04602)
*MinJu Jeon,Si-Woo Kim,Ye-Chan Kim,HyunGee Kim,Dong-Jin Kim*

Main category: cs.CV

TL;DR: Sali4Vid框架通过显著性感知视频重加权和语义自适应字幕检索，解决了密集视频字幕任务中的视频帧权重分配和场景过渡问题，取得了SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 现有端到端模型在密集视频字幕任务中存在两个问题：1) 仅对文本应用时间戳监督，忽视视频帧的重要性差异；2) 从固定大小的视频块中检索字幕，忽略场景过渡。

Method: 提出Sali4Vid框架，包括显著性感知视频重加权（将时间戳注释转换为帧重要性权重）和语义自适应字幕检索（通过帧相似性分割视频以捕捉场景过渡）。

Result: 在YouCook2和ViTT数据集上取得SOTA结果。

Conclusion: 通过联合优化视频权重分配和字幕检索，显著提升了密集视频字幕的性能。

Abstract: Dense video captioning aims to temporally localize events in video and
generate captions for each event. While recent works propose end-to-end models,
they suffer from two limitations: (1) applying timestamp supervision only to
text while treating all video frames equally, and (2) retrieving captions from
fixed-size video chunks, overlooking scene transitions. To address these, we
propose Sali4Vid, a simple yet effective saliency-aware framework. We introduce
Saliency-aware Video Reweighting, which converts timestamp annotations into
sigmoid-based frame importance weights, and Semantic-based Adaptive Caption
Retrieval, which segments videos by frame similarity to capture scene
transitions and improve caption retrieval. Sali4Vid achieves state-of-the-art
results on YouCook2 and ViTT, demonstrating the benefit of jointly improving
video weighting and retrieval for dense video captioning

</details>


### [8] [UAV-Based Intelligent Traffic Surveillance System: Real-Time Vehicle Detection, Classification, Tracking, and Behavioral Analysis](https://arxiv.org/abs/2509.04624)
*Ali Khanpour,Tianyi Wang,Afra Vahidi-Shams,Wim Ectors,Farzam Nakhaie,Amirhossein Taheri,Christian Claudel*

Main category: cs.CV

TL;DR: 本文提出了一种基于无人机的交通监控系统，用于实时检测、分类、跟踪和分析车辆行为，解决传统监控系统的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统交通监控系统覆盖范围有限、适应性差且难以扩展，无法满足现代城市交通管理的需求。

Method: 系统采用多尺度多角度模板匹配、卡尔曼滤波和基于单应性的校准技术，处理从200米高空采集的视频数据。

Result: 系统在检测精度（91.8%）、F1分数（90.5%）和跟踪指标（MOTA/MOTP分别为92.1%和93.7%）上表现优异，并能自动检测多种交通违规行为。

Conclusion: 该系统具有高扩展性、准确性和实用性，是下一代智慧城市中独立于基础设施的交通监控解决方案。

Abstract: Traffic congestion and violations pose significant challenges for urban
mobility and road safety. Traditional traffic monitoring systems, such as fixed
cameras and sensor-based methods, are often constrained by limited coverage,
low adaptability, and poor scalability. To address these challenges, this paper
introduces an advanced unmanned aerial vehicle (UAV)-based traffic surveillance
system capable of accurate vehicle detection, classification, tracking, and
behavioral analysis in real-world, unconstrained urban environments. The system
leverages multi-scale and multi-angle template matching, Kalman filtering, and
homography-based calibration to process aerial video data collected from
altitudes of approximately 200 meters. A case study in urban area demonstrates
robust performance, achieving a detection precision of 91.8%, an F1-score of
90.5%, and tracking metrics (MOTA/MOTP) of 92.1% and 93.7%, respectively.
Beyond precise detection, the system classifies five vehicle types and
automatically detects critical traffic violations, including unsafe lane
changes, illegal double parking, and crosswalk obstructions, through the fusion
of geofencing, motion filtering, and trajectory deviation analysis. The
integrated analytics module supports origin-destination tracking, vehicle count
visualization, inter-class correlation analysis, and heatmap-based congestion
modeling. Additionally, the system enables entry-exit trajectory profiling,
vehicle density estimation across road segments, and movement direction
logging, supporting comprehensive multi-scale urban mobility analytics.
Experimental results confirms the system's scalability, accuracy, and practical
relevance, highlighting its potential as an enforcement-aware,
infrastructure-independent traffic monitoring solution for next-generation
smart cities.

</details>


### [9] [VCMamba: Bridging Convolutions with Multi-Directional Mamba for Efficient Visual Representation](https://arxiv.org/abs/2509.04669)
*Mustafa Munir,Alex Zhang,Radu Marculescu*

Main category: cs.CV

TL;DR: VCMamba是一种结合CNN和多向Mamba SSM的新型视觉主干网络，旨在整合局部特征提取和全局上下文建模的优势。


<details>
  <summary>Details</summary>
Motivation: ViTs和SSMs在全局上下文建模上表现优异，但缺乏CNN的局部特征提取能力；而CNN则缺乏全局推理能力。VCMamba旨在结合两者的优势。

Method: VCMamba采用卷积茎和分层结构，早期阶段使用卷积块提取局部特征，后期阶段引入多向Mamba块建模长程依赖和全局上下文。

Result: 在ImageNet-1K分类任务中，VCMamba-B达到82.6%的top-1准确率，参数更少；在ADE20K语义分割任务中，达到47.1 mIoU，性能优于对比模型。

Conclusion: VCMamba通过结合CNN和Mamba SSM的优势，实现了高效的局部和全局特征建模，并在多个任务中表现出色。

Abstract: Recent advances in Vision Transformers (ViTs) and State Space Models (SSMs)
have challenged the dominance of Convolutional Neural Networks (CNNs) in
computer vision. ViTs excel at capturing global context, and SSMs like Mamba
offer linear complexity for long sequences, yet they do not capture
fine-grained local features as effectively as CNNs. Conversely, CNNs possess
strong inductive biases for local features but lack the global reasoning
capabilities of transformers and Mamba. To bridge this gap, we introduce
\textit{VCMamba}, a novel vision backbone that integrates the strengths of CNNs
and multi-directional Mamba SSMs. VCMamba employs a convolutional stem and a
hierarchical structure with convolutional blocks in its early stages to extract
rich local features. These convolutional blocks are then processed by later
stages incorporating multi-directional Mamba blocks designed to efficiently
model long-range dependencies and global context. This hybrid design allows for
superior feature representation while maintaining linear complexity with
respect to image resolution. We demonstrate VCMamba's effectiveness through
extensive experiments on ImageNet-1K classification and ADE20K semantic
segmentation. Our VCMamba-B achieves 82.6% top-1 accuracy on ImageNet-1K,
surpassing PlainMamba-L3 by 0.3% with 37% fewer parameters, and outperforming
Vision GNN-B by 0.3% with 64% fewer parameters. Furthermore, VCMamba-B obtains
47.1 mIoU on ADE20K, exceeding EfficientFormer-L7 by 2.0 mIoU while utilizing
62% fewer parameters. Code is available at
https://github.com/Wertyuui345/VCMamba.

</details>


### [10] [Guideline-Consistent Segmentation via Multi-Agent Refinement](https://arxiv.org/abs/2509.04687)
*Vanshika Vats,Ashwani Rathee,James Davis*

Main category: cs.CV

TL;DR: 提出了一种多智能体、无需训练的框架，通过Worker-Supervisor架构迭代优化语义分割，确保符合复杂标注指南。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法在复杂标注指南下表现不佳且需重复训练的问题。

Method: 采用Worker-Supervisor迭代架构，结合轻量级强化学习停止策略。

Result: 在Waymo和ReasonSeg数据集上显著优于现有方法。

Conclusion: 框架能有效平衡资源使用与标注指南一致性，具有强泛化能力。

Abstract: Semantic segmentation in real-world applications often requires not only
accurate masks but also strict adherence to textual labeling guidelines. These
guidelines are typically complex and long, and both human and automated
labeling often fail to follow them faithfully. Traditional approaches depend on
expensive task-specific retraining that must be repeated as the guidelines
evolve. Although recent open-vocabulary segmentation methods excel with simple
prompts, they often fail when confronted with sets of paragraph-length
guidelines that specify intricate segmentation rules. To address this, we
introduce a multi-agent, training-free framework that coordinates
general-purpose vision-language models within an iterative Worker-Supervisor
refinement architecture. The Worker performs the segmentation, the Supervisor
critiques it against the retrieved guidelines, and a lightweight reinforcement
learning stop policy decides when to terminate the loop, ensuring
guideline-consistent masks while balancing resource use. Evaluated on the Waymo
and ReasonSeg datasets, our method notably outperforms state-of-the-art
baselines, demonstrating strong generalization and instruction adherence.

</details>


### [11] [Domain Adaptation for Different Sensor Configurations in 3D Object Detection](https://arxiv.org/abs/2509.04711)
*Satoshi Tanaka,Kok Seang Tan,Isamu Yamashita*

Main category: cs.CV

TL;DR: 论文提出两种技术（下游微调和部分层微调）来解决3D物体检测中不同传感器配置的领域适应问题，显著提升了跨配置的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 不同车辆平台使用不同传感器配置会导致点云分布变化，现有方法未充分解决这一问题。

Method: 提出下游微调和部分层微调技术，通过多数据集训练和特定层更新来适应不同传感器配置。

Result: 实验表明，联合训练结合这两种技术优于单一配置的简单联合训练。

Conclusion: 研究为适应多样化车辆平台提供了实用且可扩展的解决方案。

Abstract: Recent advances in autonomous driving have underscored the importance of
accurate 3D object detection, with LiDAR playing a central role due to its
robustness under diverse visibility conditions. However, different vehicle
platforms often deploy distinct sensor configurations, causing performance
degradation when models trained on one configuration are applied to another
because of shifts in the point cloud distribution. Prior work on multi-dataset
training and domain adaptation for 3D object detection has largely addressed
environmental domain gaps and density variation within a single LiDAR; in
contrast, the domain gap for different sensor configurations remains largely
unexplored. In this work, we address domain adaptation across different sensor
configurations in 3D object detection. We propose two techniques: Downstream
Fine-tuning (dataset-specific fine-tuning after multi-dataset training) and
Partial Layer Fine-tuning (updating only a subset of layers to improve
cross-configuration generalization). Using paired datasets collected in the
same geographic region with multiple sensor configurations, we show that joint
training with Downstream Fine-tuning and Partial Layer Fine-tuning consistently
outperforms naive joint training for each configuration. Our findings provide a
practical and scalable solution for adapting 3D object detection models to the
diverse vehicle platforms.

</details>


### [12] [CD-Mamba: Cloud detection with long-range spatial dependency modeling](https://arxiv.org/abs/2509.04729)
*Tianxiang Xue,Jiayi Zhao,Jingsheng Li,Changlu Chen,Kun Zhan*

Main category: cs.CV

TL;DR: CD-Mamba是一种结合卷积神经网络和Mamba状态空间建模的混合模型，用于解决遥感图像中云层遮挡问题，显著提高了检测精度。


<details>
  <summary>Details</summary>
Motivation: 遥感图像常被云层遮挡，影响数据完整性和可靠性，需要同时处理短距离空间冗余和长距离大气相似性。

Method: 提出CD-Mamba模型，结合卷积神经网络（捕捉局部空间依赖）和Mamba（建模长距离依赖），统一用于云检测。

Result: 实验验证了CD-Mamba的有效性，其性能优于现有方法。

Conclusion: CD-Mamba通过同时处理像素级纹理细节和长距离依赖，显著提升了云检测的准确性。

Abstract: Remote sensing images are frequently obscured by cloud cover, posing
significant challenges to data integrity and reliability. Effective cloud
detection requires addressing both short-range spatial redundancies and
long-range atmospheric similarities among cloud patches. Convolutional neural
networks are effective at capturing local spatial dependencies, while Mamba has
strong capabilities in modeling long-range dependencies. To fully leverage both
local spatial relations and long-range dependencies, we propose CD-Mamba, a
hybrid model that integrates convolution and Mamba's state-space modeling into
a unified cloud detection network. CD-Mamba is designed to comprehensively
capture pixelwise textural details and long term patchwise dependencies for
cloud detection. This design enables CD-Mamba to manage both pixel-wise
interactions and extensive patch-wise dependencies simultaneously, improving
detection accuracy across diverse spatial scales. Extensive experiments
validate the effectiveness of CD-Mamba and demonstrate its superior performance
over existing methods.

</details>


### [13] [Exploiting Unlabeled Structures through Task Consistency Training for Versatile Medical Image Segmentation](https://arxiv.org/abs/2509.04732)
*Shengqian Zhu,Jiafei Wu,Xiaogang Xu,Chengrong Yu,Ying Song,Zhang Yi,Guangjun Li,Junjie Hu*

Main category: cs.CV

TL;DR: 提出了一种任务一致性训练（TCT）框架，用于解决医学图像分割中的类别不平衡问题，无需额外模型。


<details>
  <summary>Details</summary>
Motivation: 部分标注数据集（PLDs）中的类别分布不均导致现有方法面临显著的类别不平衡问题，且生成伪全标签的方法可能引入噪声。

Method: TCT框架包含一个主干网络，具有主分割头（MSH）和多个辅助任务头（ATHs），通过一致性约束和过滤策略利用未标注数据。

Result: 在八个腹部数据集上的实验证明了该方法的有效性。

Conclusion: TCT框架能够有效解决类别不平衡问题，并提升分割性能。

Abstract: Versatile medical image segmentation (VMIS) targets the segmentation of
multiple classes, while obtaining full annotations for all classes is often
impractical due to the time and labor required. Leveraging partially labeled
datasets (PLDs) presents a promising alternative; however, current VMIS
approaches face significant class imbalance due to the unequal category
distribution in PLDs. Existing methods attempt to address this by generating
pseudo-full labels. Nevertheless, these typically require additional models and
often result in potential performance degradation from label noise. In this
work, we introduce a Task Consistency Training (TCT) framework to address class
imbalance without requiring extra models. TCT includes a backbone network with
a main segmentation head (MSH) for multi-channel predictions and multiple
auxiliary task heads (ATHs) for task-specific predictions. By enforcing a
consistency constraint between the MSH and ATH predictions, TCT effectively
utilizes unlabeled anatomical structures. To avoid error propagation from
low-consistency, potentially noisy data, we propose a filtering strategy to
exclude such data. Additionally, we introduce a unified auxiliary
uncertainty-weighted loss (UAUWL) to mitigate segmentation quality declines
caused by the dominance of specific tasks. Extensive experiments on eight
abdominal datasets from diverse clinical sites demonstrate our approach's
effectiveness.

</details>


### [14] [Enhancing Self-Driving Segmentation in Adverse Weather Conditions: A Dual Uncertainty-Aware Training Approach to SAM Optimization](https://arxiv.org/abs/2509.04735)
*Dharsan Ravindran,Kevin Wang,Zhuoyuan Cao,Saleh Abdelrahman,Jeffery Wu*

Main category: cs.CV

TL;DR: 论文提出两种方法增强SAM2在恶劣天气下的分割鲁棒性：多步微调引入不确定性指标，以及适配医学影像中的UAT到驾驶场景。


<details>
  <summary>Details</summary>
Motivation: 现有视觉基础模型在视觉模糊的恶劣天气下表现不佳，缺乏不确定性量化。

Method: 1. 多步微调SAM2，将不确定性指标融入损失函数；2. 将医学影像的UAT适配到驾驶场景。

Result: UAT-SAM在极端天气下优于标准SAM，SAM2在多样驾驶场景中表现更优。

Conclusion: 显式不确定性建模对安全关键的自动驾驶在挑战性环境中具有重要价值。

Abstract: Recent advances in vision foundation models, such as the Segment Anything
Model (SAM) and its successor SAM2, have achieved state-of-the-art performance
on general image segmentation benchmarks. However, these models struggle in
adverse weather conditions where visual ambiguity is high, largely due to their
lack of uncertainty quantification. Inspired by progress in medical imaging,
where uncertainty-aware training has improved reliability in ambiguous cases,
we investigate two approaches to enhance segmentation robustness for autonomous
driving. First, we introduce a multi-step finetuning procedure for SAM2 that
incorporates uncertainty metrics directly into the loss function, improving
overall scene recognition. Second, we adapt the Uncertainty-Aware Adapter
(UAT), originally designed for medical image segmentation, to driving contexts.
We evaluate both methods on CamVid, BDD100K, and GTA driving datasets.
Experiments show that UAT-SAM outperforms standard SAM in extreme weather,
while SAM2 with uncertainty-aware loss achieves improved performance across
diverse driving scenes. These findings underscore the value of explicit
uncertainty modeling for safety-critical autonomous driving in challenging
environments.

</details>


### [15] [WatchHAR: Real-time On-device Human Activity Recognition System for Smartwatches](https://arxiv.org/abs/2509.04736)
*Taeyoung Yeon,Vasco Xu,Henry Hoffmann,Karan Ahuja*

Main category: cs.CV

TL;DR: WatchHAR是一个完全在智能手表上运行的HAR系统，通过优化管道组件和统一传感器数据处理，实现了高效且隐私保护的实时活动识别。


<details>
  <summary>Details</summary>
Motivation: 解决智能手表在无约束环境中进行多模态细粒度活动识别时的隐私和延迟问题。

Method: 提出了一种新颖的端到端可训练架构，统一了传感器数据预处理和推理。

Result: 处理速度快5倍，在25个活动类别上保持90%以上准确率，检测和分类时间分别低至9.3毫秒和11.8毫秒。

Conclusion: WatchHAR推动了设备端活动识别的发展，使智能手表成为独立、隐私友好且非侵入性的持续活动追踪设备。

Abstract: Despite advances in practical and multimodal fine-grained Human Activity
Recognition (HAR), a system that runs entirely on smartwatches in unconstrained
environments remains elusive. We present WatchHAR, an audio and inertial-based
HAR system that operates fully on smartwatches, addressing privacy and latency
issues associated with external data processing. By optimizing each component
of the pipeline, WatchHAR achieves compounding performance gains. We introduce
a novel architecture that unifies sensor data preprocessing and inference into
an end-to-end trainable module, achieving 5x faster processing while
maintaining over 90% accuracy across more than 25 activity classes. WatchHAR
outperforms state-of-the-art models for event detection and activity
classification while running directly on the smartwatch, achieving 9.3 ms
processing time for activity event detection and 11.8 ms for multimodal
activity classification. This research advances on-device activity recognition,
realizing smartwatches' potential as standalone, privacy-aware, and
minimally-invasive continuous activity tracking devices.

</details>


### [16] [MCANet: A Multi-Scale Class-Specific Attention Network for Multi-Label Post-Hurricane Damage Assessment using UAV Imagery](https://arxiv.org/abs/2509.04757)
*Zhangding Liu,Neda Mohammadi,John E. Taylor*

Main category: cs.CV

TL;DR: MCANet是一种多标签分类框架，用于飓风后损害评估，通过多尺度表示和类特定注意力模块提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有CNN方法难以捕捉多尺度空间特征和区分视觉相似或共现的损害类型。

Method: MCANet采用Res2Net层次化主干和多头类特定残差注意力模块，平衡局部细节与全局上下文。

Result: 在RescueNet数据集上，MCANet的mAP达91.75%，优于其他模型，注意力头增至8个时提升至92.35%。

Conclusion: MCANet能定位损害相关区域，支持灾后风险映射和应急响应，未来可结合知识图谱和多模态模型提升适应性。

Abstract: Rapid and accurate post-hurricane damage assessment is vital for disaster
response and recovery. Yet existing CNN-based methods struggle to capture
multi-scale spatial features and to distinguish visually similar or
co-occurring damage types. To address these issues, we propose MCANet, a
multi-label classification framework that learns multi-scale representations
and adaptively attends to spatially relevant regions for each damage category.
MCANet employs a Res2Net-based hierarchical backbone to enrich spatial context
across scales and a multi-head class-specific residual attention module to
enhance discrimination. Each attention branch focuses on different spatial
granularities, balancing local detail with global context. We evaluate MCANet
on the RescueNet dataset of 4,494 UAV images collected after Hurricane Michael.
MCANet achieves a mean average precision (mAP) of 91.75%, outperforming ResNet,
Res2Net, VGG, MobileNet, EfficientNet, and ViT. With eight attention heads,
performance further improves to 92.35%, boosting average precision for
challenging classes such as Road Blocked by over 6%. Class activation mapping
confirms MCANet's ability to localize damage-relevant regions, supporting
interpretability. Outputs from MCANet can inform post-disaster risk mapping,
emergency routing, and digital twin-based disaster response. Future work could
integrate disaster-specific knowledge graphs and multimodal large language
models to improve adaptability to unseen disasters and enrich semantic
understanding for real-world decision-making.

</details>


### [17] [Enhancing 3D Point Cloud Classification with ModelNet-R and Point-SkipNet](https://arxiv.org/abs/2509.05198)
*Mohammad Saeid,Amir Salarpour,Pedram MohajerAnsari*

Main category: cs.CV

TL;DR: 论文提出了改进的ModelNet-R数据集和轻量级图神经网络Point-SkipNet，显著提升了3D点云分类的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 解决ModelNet40数据集在标签不一致、2D数据、尺寸不匹配和类别区分不足等问题，同时设计高效模型以降低计算开销。

Method: 提出ModelNet-R数据集优化数据质量，并设计Point-SkipNet网络，结合高效采样、邻域分组和跳跃连接。

Result: ModelNet-R显著提升模型性能，Point-SkipNet在低参数量下达到最优分类精度。

Conclusion: 高质量数据集对模型效率至关重要，Point-SkipNet为3D点云分类提供了高效解决方案。

Abstract: The classification of 3D point clouds is crucial for applications such as
autonomous driving, robotics, and augmented reality. However, the commonly used
ModelNet40 dataset suffers from limitations such as inconsistent labeling, 2D
data, size mismatches, and inadequate class differentiation, which hinder model
performance. This paper introduces ModelNet-R, a meticulously refined version
of ModelNet40 designed to address these issues and serve as a more reliable
benchmark. Additionally, this paper proposes Point-SkipNet, a lightweight
graph-based neural network that leverages efficient sampling, neighborhood
grouping, and skip connections to achieve high classification accuracy with
reduced computational overhead. Extensive experiments demonstrate that models
trained in ModelNet-R exhibit significant performance improvements. Notably,
Point-SkipNet achieves state-of-the-art accuracy on ModelNet-R with a
substantially lower parameter count compared to contemporary models. This
research highlights the crucial role of dataset quality in optimizing model
efficiency for 3D point cloud classification. For more details, see the code
at: https://github.com/m-saeid/ModeNetR_PointSkipNet.

</details>


### [18] [Dynamic Group Detection using VLM-augmented Temporal Groupness Graph](https://arxiv.org/abs/2509.04758)
*Kaname Yokoyama,Chihiro Nakatani,Norimichi Ukita*

Main category: cs.CV

TL;DR: 提出了一种动态视频中人类群体检测方法，结合局部与全局特征，利用增强的VLM和全局优化技术。


<details>
  <summary>Details</summary>
Motivation: 传统方法假设群体在视频中不变，无法处理动态变化的群体结构。

Method: 使用增强的VLM提取局部和全局特征，并通过全局优化图模型处理时序一致性。

Result: 在公开数据集上优于现有方法。

Conclusion: 该方法能有效检测动态变化的群体，性能优越。

Abstract: This paper proposes dynamic human group detection in videos. For detecting
complex groups, not only the local appearance features of in-group members but
also the global context of the scene are important. Such local and global
appearance features in each frame are extracted using a Vision-Language Model
(VLM) augmented for group detection in our method. For further improvement, the
group structure should be consistent over time. While previous methods are
stabilized on the assumption that groups are not changed in a video, our method
detects dynamically changing groups by global optimization using a graph with
all frames' groupness probabilities estimated by our groupness-augmented CLIP
features. Our experimental results demonstrate that our method outperforms
state-of-the-art group detection methods on public datasets. Code:
https://github.com/irajisamurai/VLM-GroupDetection.git

</details>


### [19] [FloodVision: Urban Flood Depth Estimation Using Foundation Vision-Language Models and Domain Knowledge Graph](https://arxiv.org/abs/2509.04772)
*Zhangding Liu,Neda Mohammadi,John E. Taylor*

Main category: cs.CV

TL;DR: FloodVision是一个零样本框架，结合GPT-4o的语义推理能力和知识图谱，用于洪水深度估计，表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有计算机视觉方法在洪水检测中存在准确性和泛化性不足的问题。

Method: 结合GPT-4o和知识图谱，动态识别参考物体并估计淹没比例。

Result: 在110张图像上测试，平均绝对误差为8.17厘米，比基线提升20.5%。

Conclusion: FloodVision适用于实时洪水监测，未来可集成到智慧城市平台。

Abstract: Timely and accurate floodwater depth estimation is critical for road
accessibility and emergency response. While recent computer vision methods have
enabled flood detection, they suffer from both accuracy limitations and poor
generalization due to dependence on fixed object detectors and task-specific
training. To enable accurate depth estimation that can generalize across
diverse flood scenarios, this paper presents FloodVision, a zero-shot framework
that combines the semantic reasoning abilities of the foundation
vision-language model GPT-4o with a structured domain knowledge graph. The
knowledge graph encodes canonical real-world dimensions for common urban
objects including vehicles, people, and infrastructure elements to ground the
model's reasoning in physical reality. FloodVision dynamically identifies
visible reference objects in RGB images, retrieves verified heights from the
knowledge graph to mitigate hallucination, estimates submergence ratios, and
applies statistical outlier filtering to compute final depth values. Evaluated
on 110 crowdsourced images from MyCoast New York, FloodVision achieves a mean
absolute error of 8.17 cm, reducing the GPT-4o baseline 10.28 cm by 20.5% and
surpassing prior CNN-based methods. The system generalizes well across varying
scenes and operates in near real-time, making it suitable for future
integration into digital twin platforms and citizen-reporting apps for smart
city flood resilience.

</details>


### [20] [Hybrid-Tower: Fine-grained Pseudo-query Interaction and Generation for Text-to-Video Retrieval](https://arxiv.org/abs/2509.04773)
*Bangxiang Lan,Ruobing Xie,Ruixiang Zhao,Xingwu Sun,Zhanhui Kang,Gang Yang,Xirong Li*

Main category: cs.CV

TL;DR: 提出了一种新的混合塔框架（Hybrid-Tower）PIG，结合双塔和单塔框架的优势，同时实现高效果和高效率。


<details>
  <summary>Details</summary>
Motivation: 现有双塔框架效果低，单塔框架效率低，需要一种兼顾两者的方法。

Method: 设计了伪查询生成器，使视频特征与伪查询文本特征细粒度交互，保持高效性。

Result: 在五个基准测试中R@1提升1.6%~3.9%，效率与双塔模型相当。

Conclusion: 混合塔框架PIG在效果和效率上均表现优异，接近SOTA性能。

Abstract: The Text-to-Video Retrieval (T2VR) task aims to retrieve unlabeled videos by
textual queries with the same semantic meanings. Recent CLIP-based approaches
have explored two frameworks: Two-Tower versus Single-Tower framework, yet the
former suffers from low effectiveness, while the latter suffers from low
efficiency. In this study, we explore a new Hybrid-Tower framework that can
hybridize the advantages of the Two-Tower and Single-Tower framework, achieving
high effectiveness and efficiency simultaneously. We propose a novel hybrid
method, Fine-grained Pseudo-query Interaction and Generation for T2VR, ie, PIG,
which includes a new pseudo-query generator designed to generate a pseudo-query
for each video. This enables the video feature and the textual features of
pseudo-query to interact in a fine-grained manner, similar to the Single-Tower
approaches to hold high effectiveness, even before the real textual query is
received. Simultaneously, our method introduces no additional storage or
computational overhead compared to the Two-Tower framework during the inference
stage, thus maintaining high efficiency. Extensive experiments on five commonly
used text-video retrieval benchmarks demonstrate that our method achieves a
significant improvement over the baseline, with an increase of $1.6\% \sim
3.9\%$ in R@1. Furthermore, our method matches the efficiency of Two-Tower
models while achieving near state-of-the-art performance, highlighting the
advantages of the Hybrid-Tower framework.

</details>


### [21] [Comparative Evaluation of Traditional and Deep Learning Feature Matching Algorithms using Chandrayaan-2 Lunar Data](https://arxiv.org/abs/2509.04775)
*R. Makharia,J. G. Singla,Amitabh,N. Dube,H. Sharma*

Main category: cs.CV

TL;DR: 论文评估了五种特征匹配算法在月球图像配准中的表现，发现深度学习方法SuperGlue效果最佳，并强调了预处理的重要性。


<details>
  <summary>Details</summary>
Motivation: 月球图像配准对探索任务至关重要，但多传感器数据的差异（如分辨率、光照等）带来了挑战。

Method: 比较了SIFT、ASIFT、AKAZE、RIFT2和SuperGlue五种算法，并提出预处理流程（如地理参考、分辨率对齐等）。

Result: SuperGlue在均方根误差和运行时间上表现最优，传统方法在赤道附近表现良好但在极地光照下效果下降。

Conclusion: 预处理和基于学习的方法对月球图像配准的鲁棒性至关重要。

Abstract: Accurate image registration is critical for lunar exploration, enabling
surface mapping, resource localization, and mission planning. Aligning data
from diverse lunar sensors -- optical (e.g., Orbital High Resolution Camera,
Narrow and Wide Angle Cameras), hyperspectral (Imaging Infrared Spectrometer),
and radar (e.g., Dual-Frequency Synthetic Aperture Radar, Selene/Kaguya
mission) -- is challenging due to differences in resolution, illumination, and
sensor distortion. We evaluate five feature matching algorithms: SIFT, ASIFT,
AKAZE, RIFT2, and SuperGlue (a deep learning-based matcher), using
cross-modality image pairs from equatorial and polar regions. A preprocessing
pipeline is proposed, including georeferencing, resolution alignment, intensity
normalization, and enhancements like adaptive histogram equalization, principal
component analysis, and shadow correction. SuperGlue consistently yields the
lowest root mean square error and fastest runtimes. Classical methods such as
SIFT and AKAZE perform well near the equator but degrade under polar lighting.
The results highlight the importance of preprocessing and learning-based
approaches for robust lunar image registration across diverse conditions.

</details>


### [22] [Toward Accessible Dermatology: Skin Lesion Classification Using Deep Learning Models on Mobile-Acquired Images](https://arxiv.org/abs/2509.04800)
*Asif Newaz,Masum Mushfiq Ishti,A Z M Ashraful Azam,Asif Ur Rahman Adib*

Main category: cs.CV

TL;DR: 论文提出了一种基于Transformer的移动设备皮肤病变分类方法，优于传统CNN，并通过Grad-CAM增强可解释性。


<details>
  <summary>Details</summary>
Motivation: 皮肤疾病诊断在资源匮乏地区成本高且复杂，现有深度学习研究局限于特定数据集和疾病类别。

Method: 构建了包含50多种皮肤疾病的大规模移动设备数据集，评估了CNN和Transformer架构，重点分析了Swin Transformer的性能。

Result: Transformer模型（尤其是Swin Transformer）表现最佳，Grad-CAM提供了临床相关区域的透明解释。

Conclusion: Transformer方法在移动设备皮肤病变分类中潜力巨大，有助于资源有限地区的早期诊断。

Abstract: Skin diseases are among the most prevalent health concerns worldwide, yet
conventional diagnostic methods are often costly, complex, and unavailable in
low-resource settings. Automated classification using deep learning has emerged
as a promising alternative, but existing studies are mostly limited to
dermoscopic datasets and a narrow range of disease classes. In this work, we
curate a large dataset of over 50 skin disease categories captured with mobile
devices, making it more representative of real-world conditions. We evaluate
multiple convolutional neural networks and Transformer-based architectures,
demonstrating that Transformer models, particularly the Swin Transformer,
achieve superior performance by effectively capturing global contextual
features. To enhance interpretability, we incorporate Gradient-weighted Class
Activation Mapping (Grad-CAM), which highlights clinically relevant regions and
provides transparency in model predictions. Our results underscore the
potential of Transformer-based approaches for mobile-acquired skin lesion
classification, paving the way toward accessible AI-assisted dermatological
screening and early diagnosis in resource-limited environments.

</details>


### [23] [Extracting Uncertainty Estimates from Mixtures of Experts for Semantic Segmentation](https://arxiv.org/abs/2509.04816)
*Svetlana Pavlitska,Beyza Keskin,Alwin Faßbender,Christian Hubschneider,J. Marius Zöllner*

Main category: cs.CV

TL;DR: MoE模型在不修改架构的情况下，通过预测熵、互信息和专家方差三种方法提取预测不确定性估计，比集成方法更可靠。


<details>
  <summary>Details</summary>
Motivation: 提高计算机视觉模型在安全关键应用中的可靠性，特别是在交通场景感知中。

Method: 使用混合专家（MoE）模型，通过门控网络动态加权专家预测，并研究三种不确定性估计方法。

Result: MoE在OOD数据下比集成方法提供更可靠的不确定性估计，且简单门控机制优于复杂门控。

Conclusion: MoE模型能有效提升不确定性校准，增加专家数量可进一步优化性能。

Abstract: Estimating accurate and well-calibrated predictive uncertainty is important
for enhancing the reliability of computer vision models, especially in
safety-critical applications like traffic scene perception. While ensemble
methods are commonly used to quantify uncertainty by combining multiple models,
a mixture of experts (MoE) offers an efficient alternative by leveraging a
gating network to dynamically weight expert predictions based on the input.
Building on the promising use of MoEs for semantic segmentation in our previous
works, we show that well-calibrated predictive uncertainty estimates can be
extracted from MoEs without architectural modifications. We investigate three
methods to extract predictive uncertainty estimates: predictive entropy, mutual
information, and expert variance. We evaluate these methods for an MoE with two
experts trained on a semantical split of the A2D2 dataset. Our results show
that MoEs yield more reliable uncertainty estimates than ensembles in terms of
conditional correctness metrics under out-of-distribution (OOD) data.
Additionally, we evaluate routing uncertainty computed via gate entropy and
find that simple gating mechanisms lead to better calibration of routing
uncertainty estimates than more complex classwise gates. Finally, our
experiments on the Cityscapes dataset suggest that increasing the number of
experts can further enhance uncertainty calibration. Our code is available at
https://github.com/KASTEL-MobilityLab/mixtures-of-experts/.

</details>


### [24] [Exploring Non-Local Spatial-Angular Correlations with a Hybrid Mamba-Transformer Framework for Light Field Super-Resolution](https://arxiv.org/abs/2509.04824)
*Haosong Liu,Xiancheng Zhu,Huanqiang Zeng,Jianqing Zhu,Jiuwen Cao,Junhui Hou*

Main category: cs.CV

TL;DR: 提出了一种基于Sub-SS策略和SSMB模块的LFMT框架，结合Mamba和Transformer优势，显著提升了光场图像超分辨率性能。


<details>
  <summary>Details</summary>
Motivation: 现有Mamba方法在多方向扫描策略下对复杂光场数据特征提取效率低且冗余，需改进。

Method: 采用Sub-SS策略设计SSMB模块，结合双阶段建模策略（SA-RSMB和EPMB/EPTB）探索空间-角度和视差信息。

Result: LFMT在真实和合成光场数据集上性能显著优于现有方法，且计算复杂度低。

Conclusion: LFMT通过混合Mamba-Transformer框架，实现了高效且全面的光场超分辨率特征提取。

Abstract: Recently, Mamba-based methods, with its advantage in long-range information
modeling and linear complexity, have shown great potential in optimizing both
computational cost and performance of light field image super-resolution
(LFSR). However, current multi-directional scanning strategies lead to
inefficient and redundant feature extraction when applied to complex LF data.
To overcome this challenge, we propose a Subspace Simple Scanning (Sub-SS)
strategy, based on which we design the Subspace Simple Mamba Block (SSMB) to
achieve more efficient and precise feature extraction. Furthermore, we propose
a dual-stage modeling strategy to address the limitation of state space in
preserving spatial-angular and disparity information, thereby enabling a more
comprehensive exploration of non-local spatial-angular correlations.
Specifically, in stage I, we introduce the Spatial-Angular Residual Subspace
Mamba Block (SA-RSMB) for shallow spatial-angular feature extraction; in stage
II, we use a dual-branch parallel structure combining the Epipolar Plane Mamba
Block (EPMB) and Epipolar Plane Transformer Block (EPTB) for deep epipolar
feature refinement. Building upon meticulously designed modules and strategies,
we introduce a hybrid Mamba-Transformer framework, termed LFMT. LFMT integrates
the strengths of Mamba and Transformer models for LFSR, enabling comprehensive
information exploration across spatial, angular, and epipolar-plane domains.
Experimental results demonstrate that LFMT significantly outperforms current
state-of-the-art methods in LFSR, achieving substantial improvements in
performance while maintaining low computational complexity on both real-word
and synthetic LF datasets.

</details>


### [25] [PropVG: End-to-End Proposal-Driven Visual Grounding with Multi-Granularity Discrimination](https://arxiv.org/abs/2509.04833)
*Ming Dai,Wenxuan Cheng,Jiedong Zhuang,Jiang-jiang Liu,Hongshen Zhao,Zhenhua Feng,Wankou Yang*

Main category: cs.CV

TL;DR: PropVG是一个端到端的基于提议的视觉定位框架，首次将前景对象提议生成与参考对象理解无缝集成，无需额外检测器。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅依赖参考目标进行监督，忽略了潜在的前景目标，且缺乏多粒度区分能力。

Method: 提出CRS模块（对比学习增强参考对象理解）和MTD模块（多粒度目标区分）。

Result: 在多个基准测试中表现优异。

Conclusion: PropVG有效解决了现有方法的局限性，提升了视觉定位性能。

Abstract: Recent advances in visual grounding have largely shifted away from
traditional proposal-based two-stage frameworks due to their inefficiency and
high computational complexity, favoring end-to-end direct reference paradigms.
However, these methods rely exclusively on the referred target for supervision,
overlooking the potential benefits of prominent prospective targets. Moreover,
existing approaches often fail to incorporate multi-granularity discrimination,
which is crucial for robust object identification in complex scenarios. To
address these limitations, we propose PropVG, an end-to-end proposal-based
framework that, to the best of our knowledge, is the first to seamlessly
integrate foreground object proposal generation with referential object
comprehension without requiring additional detectors. Furthermore, we introduce
a Contrastive-based Refer Scoring (CRS) module, which employs contrastive
learning at both sentence and word levels to enhance the capability in
understanding and distinguishing referred objects. Additionally, we design a
Multi-granularity Target Discrimination (MTD) module that fuses object- and
semantic-level information to improve the recognition of absent targets.
Extensive experiments on gRefCOCO (GREC/GRES), Ref-ZOM, R-RefCOCO, and RefCOCO
(REC/RES) benchmarks demonstrate the effectiveness of PropVG. The codes and
models are available at https://github.com/Dmmm1997/PropVG.

</details>


### [26] [TemporalFlowViz: Parameter-Aware Visual Analytics for Interpreting Scramjet Combustion Evolution](https://arxiv.org/abs/2509.04834)
*Yifei Jia,Shiyu Cheng,Yu Dong,Guan Li,Dong Tian,Ruixiao Peng,Xuyi Lu,Yu Wang,Wei Yao,Guihua Shan*

Main category: cs.CV

TL;DR: TemporalFlowViz是一个可视化分析系统，用于分析和解释超燃冲压发动机燃烧模拟中的时间流场数据，支持专家驱动的聚类和知识发现。


<details>
  <summary>Details</summary>
Motivation: 超燃冲压发动机燃烧模拟数据规模大、维度高，传统方法难以进行有效的可视化和特征分析。

Method: 结合预训练的Vision Transformers提取特征，降维和聚类揭示燃烧模式，并通过视觉语言模型生成自然语言描述。

Result: 系统通过案例研究和专家反馈验证了其在假设生成、模式发现和知识发现方面的有效性。

Conclusion: TemporalFlowViz为大规模燃烧数据分析提供了高效且可解释的工具。

Abstract: Understanding the complex combustion dynamics within scramjet engines is
critical for advancing high-speed propulsion technologies. However, the large
scale and high dimensionality of simulation-generated temporal flow field data
present significant challenges for visual interpretation, feature
differentiation, and cross-case comparison. In this paper, we present
TemporalFlowViz, a parameter-aware visual analytics workflow and system
designed to support expert-driven clustering, visualization, and interpretation
of temporal flow fields from scramjet combustion simulations. Our approach
leverages hundreds of simulated combustion cases with varying initial
conditions, each producing time-sequenced flow field images. We use pretrained
Vision Transformers to extract high-dimensional embeddings from these frames,
apply dimensionality reduction and density-based clustering to uncover latent
combustion modes, and construct temporal trajectories in the embedding space to
track the evolution of each simulation over time. To bridge the gap between
latent representations and expert reasoning, domain specialists annotate
representative cluster centroids with descriptive labels. These annotations are
used as contextual prompts for a vision-language model, which generates
natural-language summaries for individual frames and full simulation cases. The
system also supports parameter-based filtering, similarity-based case
retrieval, and coordinated multi-view exploration to facilitate in-depth
analysis. We demonstrate the effectiveness of TemporalFlowViz through two
expert-informed case studies and expert feedback, showing TemporalFlowViz
enhances hypothesis generation, supports interpretable pattern discovery, and
enhances knowledge discovery in large-scale scramjet combustion analysis.

</details>


### [27] [Pose-Free 3D Quantitative Phase Imaging of Flowing Cellular Populations](https://arxiv.org/abs/2509.04848)
*Enze Ye,Wei Lin,Shaochi Ren,Yakun Liu,Xiaoping Li,Hao Wang,He Sun,Feng Pan*

Main category: cs.CV

TL;DR: OmniFHT是一种无需姿态信息的3D折射率重建框架，适用于高通量流式细胞术成像，支持任意细胞几何形状和多轴旋转。


<details>
  <summary>Details</summary>
Motivation: 现有成像方法假设细胞进行均匀单轴旋转，限制了其适用于近球形细胞，无法准确成像不规则形状细胞。

Method: 利用傅里叶衍射定理和隐式神经表示（INRs），联合优化细胞的未知旋转轨迹和体积结构。

Result: OmniFHT能够在稀疏采样和有限角度覆盖下实现高保真重建，仅需10个视图或120度角度范围。

Conclusion: OmniFHT首次实现了对流动细胞群体的原位高通量断层成像，为流式细胞术平台提供了可扩展且无偏的形态分析解决方案。

Abstract: High-throughput 3D quantitative phase imaging (QPI) in flow cytometry enables
label-free, volumetric characterization of individual cells by reconstructing
their refractive index (RI) distributions from multiple viewing angles during
flow through microfluidic channels. However, current imaging methods assume
that cells undergo uniform, single-axis rotation, which require their poses to
be known at each frame. This assumption restricts applicability to
near-spherical cells and prevents accurate imaging of irregularly shaped cells
with complex rotations. As a result, only a subset of the cellular population
can be analyzed, limiting the ability of flow-based assays to perform robust
statistical analysis. We introduce OmniFHT, a pose-free 3D RI reconstruction
framework that leverages the Fourier diffraction theorem and implicit neural
representations (INRs) for high-throughput flow cytometry tomographic imaging.
By jointly optimizing each cell's unknown rotational trajectory and volumetric
structure under weak scattering assumptions, OmniFHT supports arbitrary cell
geometries and multi-axis rotations. Its continuous representation also allows
accurate reconstruction from sparsely sampled projections and restricted
angular coverage, producing high-fidelity results with as few as 10 views or
only 120 degrees of angular range. OmniFHT enables, for the first time, in
situ, high-throughput tomographic imaging of entire flowing cell populations,
providing a scalable and unbiased solution for label-free morphometric analysis
in flow cytometry platforms.

</details>


### [28] [CoRe-GS: Coarse-to-Refined Gaussian Splatting with Semantic Object Focus](https://arxiv.org/abs/2509.04859)
*Hannah Schieber,Dominik Frischmann,Simon Boche,Victor Schaack,Angela Schoellig,Stefan Leutenegger,Daniel Roth*

Main category: cs.CV

TL;DR: CoRe-GS通过语义高斯泼溅和颜色过滤，快速聚焦兴趣点，减少训练时间并提高重建质量。


<details>
  <summary>Details</summary>
Motivation: 移动机器人需要快速且准确的3D重建，尤其是针对特定兴趣点（PoIs），以减少全场景优化的需求。

Method: 结合语义高斯泼溅生成粗分割场景，并通过颜色过滤精修兴趣点。

Result: 在SCRREAM和NeRDS 360数据集上，训练时间减少25%，且新视角合成质量更高。

Conclusion: CoRe-GS在减少训练时间的同时，提升了兴趣点的重建质量，适用于实时应用。

Abstract: Mobile reconstruction for autonomous aerial robotics holds strong potential
for critical applications such as tele-guidance and disaster response. These
tasks demand both accurate 3D reconstruction and fast scene processing. Instead
of reconstructing the entire scene in detail, it is often more efficient to
focus on specific objects, i.e., points of interest (PoIs). Mobile robots
equipped with advanced sensing can usually detect these early during data
acquisition or preliminary analysis, reducing the need for full-scene
optimization. Gaussian Splatting (GS) has recently shown promise in delivering
high-quality novel view synthesis and 3D representation by an incremental
learning process. Extending GS with scene editing, semantics adds useful
per-splat features to isolate objects effectively.
  Semantic 3D Gaussian editing can already be achieved before the full training
cycle is completed, reducing the overall training time. Moreover, the
semantically relevant area, the PoI, is usually already known during capturing.
To balance high-quality reconstruction with reduced training time, we propose
CoRe-GS. We first generate a coarse segmentation-ready scene with semantic GS
and then refine it for the semantic object using our novel color-based
effective filtering for effective object isolation. This is speeding up the
training process to be about a quarter less than a full training cycle for
semantic GS. We evaluate our approach on two datasets, SCRREAM (real-world,
outdoor) and NeRDS 360 (synthetic, indoor), showing reduced runtime and higher
novel-view-synthesis quality.

</details>


### [29] [Cryo-RL: automating prostate cancer cryoablation planning with reinforcement learning](https://arxiv.org/abs/2509.04886)
*Trixia Simangan,Ahmed Nadeem Abbasi,Yipeng Hu,Shaheer U. Saeed*

Main category: cs.CV

TL;DR: Cryo-RL是一种基于强化学习的框架，用于自动化前列腺癌冷冻消融术中的冷冻探针放置规划，显著优于传统方法并接近专家水平。


<details>
  <summary>Details</summary>
Motivation: 冷冻消融术的成功依赖于精确的冷冻探针放置规划，但目前的手动规划方法耗时且依赖专家经验，导致治疗质量不稳定。

Method: Cryo-RL将冷冻探针放置规划建模为马尔可夫决策过程，通过强化学习在模拟环境中学习最优策略。

Result: 在583例回顾性病例中，Cryo-RL的Dice评分比最佳自动化基线提高了8个百分点，且与专家水平相当，规划时间大幅减少。

Conclusion: 强化学习能够提供临床可行、可重复且高效的冷冻消融规划方案。

Abstract: Cryoablation is a minimally invasive localised treatment for prostate cancer
that destroys malignant tissue during de-freezing, while sparing surrounding
healthy structures. Its success depends on accurate preoperative planning of
cryoprobe placements to fully cover the tumour and avoid critical anatomy. This
planning is currently manual, expertise-dependent, and time-consuming, leading
to variability in treatment quality and limited scalability. In this work, we
introduce Cryo-RL, a reinforcement learning framework that models cryoablation
planning as a Markov decision process and learns an optimal policy for
cryoprobe placement. Within a simulated environment that models clinical
constraints and stochastic intraoperative variability, an agent sequentially
selects cryoprobe positions and ice sphere diameters. Guided by a reward
function based on tumour coverage, this agent learns a cryoablation strategy
that leads to optimal cryoprobe placements without the need for any
manually-designed plans. Evaluated on 583 retrospective prostate cancer cases,
Cryo-RL achieved over 8 percentage-point Dice improvements compared with the
best automated baselines, based on geometric optimisation, and matched human
expert performance while requiring substantially less planning time. These
results highlight the potential of reinforcement learning to deliver clinically
viable, reproducible, and efficient cryoablation plans.

</details>


### [30] [SpiderNets: Estimating Fear Ratings of Spider-Related Images with Vision Models](https://arxiv.org/abs/2509.04889)
*Dominik Pegler,David Steyrl,Mengfan Zhang,Alexander Karner,Jozsef Arato,Frank Scharnowski,Filip Melinscak*

Main category: cs.CV

TL;DR: 预训练计算机视觉模型通过迁移学习预测蜘蛛相关图像的人类恐惧评分，平均绝对误差为10.1-11.0，模型解释性分析显示其基于蜘蛛相关特征。


<details>
  <summary>Details</summary>
Motivation: 探索计算机视觉模型在临床应用中预测恐惧评分的潜力，为自适应情绪治疗技术提供支持。

Method: 使用三种预训练模型通过迁移学习预测313张标准化图像的人类恐惧评分，采用交叉验证评估性能。

Result: 模型平均绝对误差为10.1-11.0，数据集大小显著影响性能，解释性分析确认模型关注蜘蛛相关特征。

Conclusion: 可解释的计算机视觉模型在预测恐惧评分中具有潜力，强调数据集大小和模型解释性对情绪感知治疗技术的重要性。

Abstract: Advances in computer vision have opened new avenues for clinical
applications, particularly in computerized exposure therapy where visual
stimuli can be dynamically adjusted based on patient responses. As a critical
step toward such adaptive systems, we investigated whether pretrained computer
vision models can accurately predict fear levels from spider-related images. We
adapted three diverse models using transfer learning to predict human fear
ratings (on a 0-100 scale) from a standardized dataset of 313 images. The
models were evaluated using cross-validation, achieving an average mean
absolute error (MAE) between 10.1 and 11.0. Our learning curve analysis
revealed that reducing the dataset size significantly harmed performance,
though further increases yielded no substantial gains. Explainability
assessments showed the models' predictions were based on spider-related
features. A category-wise error analysis further identified visual conditions
associated with higher errors (e.g., distant views and artificial/painted
spiders). These findings demonstrate the potential of explainable computer
vision models in predicting fear ratings, highlighting the importance of both
model explainability and a sufficient dataset size for developing effective
emotion-aware therapeutic technologies.

</details>


### [31] [SynGen-Vision: Synthetic Data Generation for training industrial vision models](https://arxiv.org/abs/2509.04894)
*Alpana Dubey,Suma Mani Kuriakose,Nitish Bhardwaj*

Main category: cs.CV

TL;DR: 提出一种生成合成数据的方法，用于训练工业磨损检测的计算机视觉模型。


<details>
  <summary>Details</summary>
Motivation: 工业磨损检测对预测性维护至关重要，但数据收集昂贵且耗时。

Method: 结合视觉语言模型和3D模拟渲染引擎，生成不同锈蚀条件的合成数据。

Result: 使用合成数据训练的模型在真实锈蚀图像上表现优异，mAP50得分为0.87。

Conclusion: 该方法可定制，适用于其他工业磨损检测场景。

Abstract: We propose an approach to generate synthetic data to train computer vision
(CV) models for industrial wear and tear detection. Wear and tear detection is
an important CV problem for predictive maintenance tasks in any industry.
However, data curation for training such models is expensive and time-consuming
due to the unavailability of datasets for different wear and tear scenarios.
Our approach employs a vision language model along with a 3D simulation and
rendering engine to generate synthetic data for varying rust conditions. We
evaluate our approach by training a CV model for rust detection using the
generated dataset and tested the trained model on real images of rusted
industrial objects. The model trained with the synthetic data generated by our
approach, outperforms the other approaches with a mAP50 score of 0.87. The
approach is customizable and can be easily extended to other industrial wear
and tear detection scenarios

</details>


### [32] [Evaluating Multiple Instance Learning Strategies for Automated Sebocyte Droplet Counting](https://arxiv.org/abs/2509.04895)
*Maryam Adelipour,Gustavo Carneiro,Jeongkwon Kim*

Main category: cs.CV

TL;DR: 提出了一种基于注意力机制的多实例学习框架用于皮脂腺细胞图像分析，比较了两种模型性能。


<details>
  <summary>Details</summary>
Motivation: 手动计数皮脂腺细胞中的脂滴耗时且主观，需要自动化解决方案。

Method: 使用Nile Red染色图像，标注14类脂滴数量，数据增强至约50,000细胞。比较了基线MLP和基于注意力的MIL模型。

Result: 基线MLP表现更稳定（平均MAE=5.6），而注意力MIL模型一致性较差（平均MAE=10.7），但在某些情况下表现更优。

Conclusion: 简单聚合方法在脂滴计数中表现稳健，注意力MIL需进一步优化以发挥潜力。

Abstract: Sebocytes are lipid-secreting cells whose differentiation is marked by the
accumulation of intracellular lipid droplets, making their quantification a key
readout in sebocyte biology. Manual counting is labor-intensive and subjective,
motivating automated solutions. Here, we introduce a simple attention-based
multiple instance learning (MIL) framework for sebocyte image analysis. Nile
Red-stained sebocyte images were annotated into 14 classes according to droplet
counts, expanded via data augmentation to about 50,000 cells. Two models were
benchmarked: a baseline multi-layer perceptron (MLP) trained on aggregated
patch-level counts, and an attention-based MIL model leveraging ResNet-50
features with instance weighting. Experiments using five-fold cross-validation
showed that the baseline MLP achieved more stable performance (mean MAE = 5.6)
compared with the attention-based MIL, which was less consistent (mean MAE =
10.7) but occasionally superior in specific folds. These findings indicate that
simple bag-level aggregation provides a robust baseline for slide-level droplet
counting, while attention-based MIL requires task-aligned pooling and
regularization to fully realize its potential in sebocyte image analysis.

</details>


### [33] [UniView: Enhancing Novel View Synthesis From A Single Image By Unifying Reference Features](https://arxiv.org/abs/2509.04932)
*Haowang Cui,Rui Chen,Tao Luo,Rui Li,Jiaze Wang*

Main category: cs.CV

TL;DR: UniView利用参考图像和MLLM提升单图像新视角合成性能，通过多级隔离层和三元注意力机制减少失真。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在合成未观察区域时因模糊先验和插值导致的严重失真问题。

Method: 构建检索与增强系统，利用MLLM选择参考图像；引入多级隔离层的适配器模块动态生成参考特征；设计解耦三元注意力机制对齐多分支特征。

Result: 在挑战性数据集上显著提升新视角合成性能，优于现有方法。

Conclusion: UniView通过参考图像和多模态大语言模型的结合，有效解决了单图像视角合成的失真问题。

Abstract: The task of synthesizing novel views from a single image is highly ill-posed
due to multiple explanations for unobserved areas. Most current methods tend to
generate unseen regions from ambiguity priors and interpolation near input
views, which often lead to severe distortions. To address this limitation, we
propose a novel model dubbed as UniView, which can leverage reference images
from a similar object to provide strong prior information during view
synthesis. More specifically, we construct a retrieval and augmentation system
and employ a multimodal large language model (MLLM) to assist in selecting
reference images that meet our requirements. Additionally, a plug-and-play
adapter module with multi-level isolation layers is introduced to dynamically
generate reference features for the target views. Moreover, in order to
preserve the details of an original input image, we design a decoupled triple
attention mechanism, which can effectively align and integrate multi-branch
features into the synthesis process. Extensive experiments have demonstrated
that our UniView significantly improves novel view synthesis performance and
outperforms state-of-the-art methods on the challenging datasets.

</details>


### [34] [Efficient Video-to-Audio Generation via Multiple Foundation Models Mapper](https://arxiv.org/abs/2509.04957)
*Gehui Chen,Guan'an Wang,Xiaowen Huang,Jitao Sang*

Main category: cs.CV

TL;DR: MFM-Mapper通过融合双视觉编码器特征和GPT-2映射器，提升了视频到音频生成的语义和时间一致性，同时显著降低了训练成本。


<details>
  <summary>Details</summary>
Motivation: 现有视频到音频生成模型依赖从头训练，资源消耗大。利用基础模型的跨模态知识转移能力可以提升效率。

Method: 引入MFM-Mapper，结合双视觉编码器特征和GPT-2映射器，优化特征对齐和训练效率。

Result: MFM-Mapper仅需16%的训练规模即可达到竞争性性能，语义和时间一致性更优。

Conclusion: MFM-Mapper展示了高效利用基础模型进行跨模态任务的优势。

Abstract: Recent Video-to-Audio (V2A) generation relies on extracting semantic and
temporal features from video to condition generative models. Training these
models from scratch is resource intensive. Consequently, leveraging foundation
models (FMs) has gained traction due to their cross-modal knowledge transfer
and generalization capabilities. One prior work has explored fine-tuning a
lightweight mapper network to connect a pre-trained visual encoder with a
text-to-audio generation model for V2A. Inspired by this, we introduce the
Multiple Foundation Model Mapper (MFM-Mapper). Compared to the previous mapper
approach, MFM-Mapper benefits from richer semantic and temporal information by
fusing features from dual visual encoders. Furthermore, by replacing a linear
mapper with GPT-2, MFM-Mapper improves feature alignment, drawing parallels
between cross-modal features mapping and autoregressive translation tasks. Our
MFM-Mapper exhibits remarkable training efficiency. It achieves better
performance in semantic and temporal consistency with fewer training consuming,
requiring only 16\% of the training scale compared to previous mapper-based
work, yet achieves competitive performance with models trained on a much larger
scale.

</details>


### [35] [Dual-Domain Perspective on Degradation-Aware Fusion: A VLM-Guided Robust Infrared and Visible Image Fusion Framework](https://arxiv.org/abs/2509.05000)
*Tianpei Zhang,Jufeng Zhao,Yiming Zhu,Guangmang Cui*

Main category: cs.CV

TL;DR: GD^2Fusion框架通过结合视觉语言模型和双域优化，解决了红外-可见光图像融合在双源退化场景中的性能问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法假设输入高质量图像，无法处理双源退化场景，导致误差累积和性能下降。

Method: 提出GD^2Fusion框架，结合视觉语言模型进行退化感知，并通过频率域和空间域联合优化实现特征提取和融合。

Result: 实验表明GD^2Fusion在双源退化场景中优于现有算法。

Conclusion: GD^2Fusion通过多模态协同优化，显著提升了退化场景下的图像融合性能。

Abstract: Most existing infrared-visible image fusion (IVIF) methods assume
high-quality inputs, and therefore struggle to handle dual-source degraded
scenarios, typically requiring manual selection and sequential application of
multiple pre-enhancement steps. This decoupled pre-enhancement-to-fusion
pipeline inevitably leads to error accumulation and performance degradation. To
overcome these limitations, we propose Guided Dual-Domain Fusion (GD^2Fusion),
a novel framework that synergistically integrates vision-language models (VLMs)
for degradation perception with dual-domain (frequency/spatial) joint
optimization. Concretely, the designed Guided Frequency Modality-Specific
Extraction (GFMSE) module performs frequency-domain degradation perception and
suppression and discriminatively extracts fusion-relevant sub-band features.
Meanwhile, the Guided Spatial Modality-Aggregated Fusion (GSMAF) module carries
out cross-modal degradation filtering and adaptive multi-source feature
aggregation in the spatial domain to enhance modality complementarity and
structural consistency. Extensive qualitative and quantitative experiments
demonstrate that GD^2Fusion achieves superior fusion performance compared with
existing algorithms and strategies in dual-source degraded scenarios. The code
will be publicly released after acceptance of this paper.

</details>


### [36] [Interpretable Deep Transfer Learning for Breast Ultrasound Cancer Detection: A Multi-Dataset Study](https://arxiv.org/abs/2509.05004)
*Mohammad Abbadi,Yassine Himeur,Shadi Atalla,Wathiq Mansoor*

Main category: cs.CV

TL;DR: 论文研究了机器学习和深度学习技术在乳腺癌超声图像分类中的应用，发现ResNet-18模型表现最佳，准确率达99.7%。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌是全球女性癌症相关死亡的主要原因，超声成像因其安全性和成本效益在早期检测中起关键作用。

Method: 使用BUSI、BUS-BRA和BrEaST-Lesions USG数据集，评估了SVM、KNN等经典机器学习模型及ResNet-18、EfficientNet-B0、GoogLeNet等深度卷积神经网络。

Result: ResNet-18表现最佳，准确率达99.7%，经典机器学习模型结合深度特征提取也表现良好。Grad-CAM可视化提高了模型透明度。

Conclusion: 研究支持将AI诊断工具整合到临床工作流程中，展示了高性能、可解释的超声乳腺癌检测系统的可行性。

Abstract: Breast cancer remains a leading cause of cancer-related mortality among women
worldwide. Ultrasound imaging, widely used due to its safety and
cost-effectiveness, plays a key role in early detection, especially in patients
with dense breast tissue. This paper presents a comprehensive study on the
application of machine learning and deep learning techniques for breast cancer
classification using ultrasound images. Using datasets such as BUSI, BUS-BRA,
and BrEaST-Lesions USG, we evaluate classical machine learning models (SVM,
KNN) and deep convolutional neural networks (ResNet-18, EfficientNet-B0,
GoogLeNet). Experimental results show that ResNet-18 achieves the highest
accuracy (99.7%) and perfect sensitivity for malignant lesions. Classical ML
models, though outperformed by CNNs, achieve competitive performance when
enhanced with deep feature extraction. Grad-CAM visualizations further improve
model transparency by highlighting diagnostically relevant image regions. These
findings support the integration of AI-based diagnostic tools into clinical
workflows and demonstrate the feasibility of deploying high-performing,
interpretable systems for ultrasound-based breast cancer detection.

</details>


### [37] [A biologically inspired separable learning vision model for real-time traffic object perception in Dark](https://arxiv.org/abs/2509.05012)
*Hulin Li,Qiliang Ren,Jun Li,Hanbing Wei,Zheng Liu,Linfang Fan*

Main category: cs.CV

TL;DR: 论文提出了一种针对低光交通场景的感知模型SLVM，并构建了大规模数据集Dark-traffic，显著提升了目标检测、实例分割和光流估计的性能。


<details>
  <summary>Details</summary>
Motivation: 低光交通场景中物体感知的快速性和准确性需求迫切，但现有方法因光照退化和缺乏可靠视觉线索而表现不佳，且缺乏专用的大规模基准数据集。

Method: 提出了SLVM框架，包含光适应瞳孔机制、特征级可分离学习策略、任务特定解耦分支和空间错位感知融合模块。

Result: SLVM在Dark-traffic数据集上表现优异，检测和分割性能显著提升，计算开销减少。

Conclusion: SLVM和Dark-traffic数据集填补了低光交通场景感知的空白，为未来研究提供了重要资源。

Abstract: Fast and accurate object perception in low-light traffic scenes has attracted
increasing attention. However, due to severe illumination degradation and the
lack of reliable visual cues, existing perception models and methods struggle
to quickly adapt to and accurately predict in low-light environments. Moreover,
there is the absence of available large-scale benchmark specifically focused on
low-light traffic scenes. To bridge this gap, we introduce a physically
grounded illumination degradation method tailored to real-world low-light
settings and construct Dark-traffic, the largest densely annotated dataset to
date for low-light traffic scenes, supporting object detection, instance
segmentation, and optical flow estimation. We further propose the Separable
Learning Vision Model (SLVM), a biologically inspired framework designed to
enhance perception under adverse lighting. SLVM integrates four key components:
a light-adaptive pupillary mechanism for illumination-sensitive feature
extraction, a feature-level separable learning strategy for efficient
representation, task-specific decoupled branches for multi-task separable
learning, and a spatial misalignment-aware fusion module for precise
multi-feature alignment. Extensive experiments demonstrate that SLVM achieves
state-of-the-art performance with reduced computational overhead. Notably, it
outperforms RT-DETR by 11.2 percentage points in detection, YOLOv12 by 6.1
percentage points in instance segmentation, and reduces endpoint error (EPE) of
baseline by 12.37% on Dark-traffic. On the LIS benchmark, the end-to-end
trained SLVM surpasses Swin Transformer+EnlightenGAN and
ConvNeXt-T+EnlightenGAN by an average of 11 percentage points across key
metrics, and exceeds Mask RCNN (with light enhancement) by 3.1 percentage
points. The Dark-traffic dataset and complete code is released at
https://github.com/alanli1997/slvm.

</details>


### [38] [Leveraging Transfer Learning and Mobile-enabled Convolutional Neural Networks for Improved Arabic Handwritten Character Recognition](https://arxiv.org/abs/2509.05019)
*Mohsine El Khayati,Ayyad Maafiri,Yassine Himeur,Hamzah Ali Alkhazaleh,Shadi Atalla,Wathiq Mansoor*

Main category: cs.CV

TL;DR: 研究探讨了迁移学习与轻量级卷积神经网络结合提升阿拉伯手写字符识别的效果，MobileNet表现最佳。


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯手写字符识别中的计算资源需求和数据集稀缺问题。

Method: 评估了三种迁移学习策略（全微调、部分微调、从头训练）和四种轻量级网络（MobileNet、SqueezeNet、MnasNet、ShuffleNet），在三个数据集上进行实验。

Result: MobileNet表现最优，IFHCDB数据集下MnasNet全微调达到99%准确率。全微调策略整体表现最佳。

Conclusion: 迁移学习与轻量级网络的结合为资源高效的阿拉伯手写字符识别提供了潜力，未来将探索更多优化方法。

Abstract: The study explores the integration of transfer learning (TL) with
mobile-enabled convolutional neural networks (MbNets) to enhance Arabic
Handwritten Character Recognition (AHCR). Addressing challenges like extensive
computational requirements and dataset scarcity, this research evaluates three
TL strategies--full fine-tuning, partial fine-tuning, and training from
scratch--using four lightweight MbNets: MobileNet, SqueezeNet, MnasNet, and
ShuffleNet. Experiments were conducted on three benchmark datasets: AHCD,
HIJJA, and IFHCDB. MobileNet emerged as the top-performing model, consistently
achieving superior accuracy, robustness, and efficiency, with ShuffleNet
excelling in generalization, particularly under full fine-tuning. The IFHCDB
dataset yielded the highest results, with 99% accuracy using MnasNet under full
fine-tuning, highlighting its suitability for robust character recognition. The
AHCD dataset achieved competitive accuracy (97%) with ShuffleNet, while HIJJA
posed significant challenges due to its variability, achieving a peak accuracy
of 92% with ShuffleNet. Notably, full fine-tuning demonstrated the best overall
performance, balancing accuracy and convergence speed, while partial
fine-tuning underperformed across metrics. These findings underscore the
potential of combining TL and MbNets for resource-efficient AHCR, paving the
way for further optimizations and broader applications. Future work will
explore architectural modifications, in-depth dataset feature analysis, data
augmentation, and advanced sensitivity analysis to enhance model robustness and
generalizability.

</details>


### [39] [LUIVITON: Learned Universal Interoperable VIrtual Try-ON](https://arxiv.org/abs/2509.05030)
*Cong Cao,Xianhang Cheng,Jingyuan Liu,Yujian Zheng,Zhenhui Lin,Meriem Chkir,Hao Li*

Main category: cs.CV

TL;DR: LUIVITON是一个端到端的全自动虚拟试衣系统，能够将复杂多层衣物覆盖到多样且任意姿态的人形角色上。


<details>
  <summary>Details</summary>
Motivation: 解决复杂衣物与多样体型对齐的挑战，实现高效且通用的虚拟试衣。

Method: 使用SMPL作为代理表示，将衣物到身体的覆盖问题分为衣物到SMPL和身体到SMPL两个对应任务，分别采用几何学习和扩散模型方法。

Result: 系统能处理复杂几何和非流形网格，适用于多种人形角色，并支持快速定制衣物尺寸和材质。

Conclusion: LUIVITON无需人工干预即可生成高质量3D衣物覆盖，即使没有2D衣物缝制图案。

Abstract: We present LUIVITON, an end-to-end system for fully automated virtual try-on,
capable of draping complex, multi-layer clothing onto diverse and arbitrarily
posed humanoid characters. To address the challenge of aligning complex
garments with arbitrary and highly diverse body shapes, we use SMPL as a proxy
representation and separate the clothing-to-body draping problem into two
correspondence tasks: 1) clothing-to-SMPL and 2) body-to-SMPL correspondence,
where each has its unique challenges. While we address the clothing-to-SMPL
fitting problem using a geometric learning-based approach for
partial-to-complete shape correspondence prediction, we introduce a diffusion
model-based approach for body-to-SMPL correspondence using multi-view
consistent appearance features and a pre-trained 2D foundation model. Our
method can handle complex geometries, non-manifold meshes, and generalizes
effectively to a wide range of humanoid characters -- including humans, robots,
cartoon subjects, creatures, and aliens, while maintaining computational
efficiency for practical adoption. In addition to offering a fully automatic
fitting solution, LUIVITON supports fast customization of clothing size,
allowing users to adjust clothing sizes and material properties after they have
been draped. We show that our system can produce high-quality 3D clothing
fittings without any human labor, even when 2D clothing sewing patterns are not
available.

</details>


### [40] [Towards Efficient Pixel Labeling for Industrial Anomaly Detection and Localization](https://arxiv.org/abs/2509.05034)
*Jingqi Wu,Hanxi Li,Lin Yuanbo Wu,Hao Chen,Deyin Liu,Peng Wang*

Main category: cs.CV

TL;DR: ADClick是一种交互式图像分割算法，通过少量用户点击和简短文本描述生成像素级异常标注，显著提升异常检测模型性能。ADClick-Seg结合视觉特征和文本提示，实现多类异常检测任务的最先进结果。


<details>
  <summary>Details</summary>
Motivation: 工业产品检测通常仅使用无缺陷样本训练异常检测模型，缺陷样本的利用需要像素级标注，限制了可扩展性。

Method: 提出ADClick算法，通过用户点击和文本描述生成像素级标注；进一步提出ADClick-Seg框架，结合视觉特征和文本提示进行异常检测和定位。

Result: ADClick在MVTec AD上AP达96.1%；ADClick-Seg在多类异常检测任务中AP达80.0%，PRO达97.5%，Pixel-AUROC达99.1%。

Conclusion: ADClick和ADClick-Seg通过交互式标注和跨模态框架，显著提升了工业异常检测的效率和性能。

Abstract: Industrial product inspection is often performed using Anomaly Detection (AD)
frameworks trained solely on non-defective samples. Although defective samples
can be collected during production, leveraging them usually requires
pixel-level annotations, limiting scalability. To address this, we propose
ADClick, an Interactive Image Segmentation (IIS) algorithm for industrial
anomaly detection. ADClick generates pixel-wise anomaly annotations from only a
few user clicks and a brief textual description, enabling precise and efficient
labeling that significantly improves AD model performance (e.g., AP = 96.1\% on
MVTec AD). We further introduce ADClick-Seg, a cross-modal framework that
aligns visual features and textual prompts via a prototype-based approach for
anomaly detection and localization. By combining pixel-level priors with
language-guided cues, ADClick-Seg achieves state-of-the-art results on the
challenging ``Multi-class'' AD task (AP = 80.0\%, PRO = 97.5\%, Pixel-AUROC =
99.1\% on MVTec AD).

</details>


### [41] [Systematic Review and Meta-analysis of AI-driven MRI Motion Artifact Detection and Correction](https://arxiv.org/abs/2509.05071)
*Mojtaba Safari,Zach Eidex,Richard L. J. Qiu,Matthew Goette,Tonghe Wang,Xiaofeng Yang*

Main category: cs.CV

TL;DR: AI驱动的深度学习方法，特别是生成模型，在检测和纠正MRI运动伪影方面显示出潜力，但仍面临泛化性不足、依赖配对数据和视觉失真等挑战。


<details>
  <summary>Details</summary>
Motivation: 评估AI方法在MRI运动伪影检测和纠正中的有效性，以提升图像质量和诊断准确性。

Method: 通过系统综述和元分析，重点关注深度学习和生成模型，提取数据集、架构和性能指标等定量数据。

Result: 生成模型在减少运动伪影和提升图像质量方面表现良好，但存在泛化性不足和依赖配对数据的问题。

Conclusion: AI方法在MRI运动伪影处理中潜力巨大，但需解决数据集标准化、报告协议和更先进的DL技术等挑战。

Abstract: Background: To systematically review and perform a meta-analysis of
artificial intelligence (AI)-driven methods for detecting and correcting
magnetic resonance imaging (MRI) motion artifacts, assessing current
developments, effectiveness, challenges, and future research directions.
Methods: A comprehensive systematic review and meta-analysis were conducted,
focusing on deep learning (DL) approaches, particularly generative models, for
the detection and correction of MRI motion artifacts. Quantitative data were
extracted regarding utilized datasets, DL architectures, and performance
metrics. Results: DL, particularly generative models, show promise for reducing
motion artifacts and improving image quality; however, limited
generalizability, reliance on paired training data, and risk of visual
distortions remain key challenges that motivate standardized datasets and
reporting. Conclusions: AI-driven methods, particularly DL generative models,
show significant potential for improving MRI image quality by effectively
addressing motion artifacts. However, critical challenges must be addressed,
including the need for comprehensive public datasets, standardized reporting
protocols for artifact levels, and more advanced, adaptable DL techniques to
reduce reliance on extensive paired datasets. Addressing these aspects could
substantially enhance MRI diagnostic accuracy, reduce healthcare costs, and
improve patient care outcomes.

</details>


### [42] [GeoSplat: A Deep Dive into Geometry-Constrained Gaussian Splatting](https://arxiv.org/abs/2509.05075)
*Yangming Li,Chaoyu Liu,Lihao Liu,Simon Masnou,Carola-Bibian Schönlieb*

Main category: cs.CV

TL;DR: GeoSplat框架通过引入一阶和二阶几何先验优化高斯溅射训练流程，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖低阶几何先验（如法向量），且估计不可靠。GeoSplat旨在通过高阶几何量解决这些问题。

Method: 提出GeoSplat框架，利用主曲率初始化高斯尺度，并基于局部流形引入鲁棒的几何估计方法。

Result: 在多个数据集上验证，GeoSplat显著优于基线方法。

Conclusion: GeoSplat通过动态几何先验优化高斯溅射，提升了性能与鲁棒性。

Abstract: A few recent works explored incorporating geometric priors to regularize the
optimization of Gaussian splatting, further improving its performance. However,
those early studies mainly focused on the use of low-order geometric priors
(e.g., normal vector), and they are also unreliably estimated by
noise-sensitive methods, like local principal component analysis. To address
their limitations, we first present GeoSplat, a general geometry-constrained
optimization framework that exploits both first-order and second-order
geometric quantities to improve the entire training pipeline of Gaussian
splatting, including Gaussian initialization, gradient update, and
densification. As an example, we initialize the scales of 3D Gaussian
primitives in terms of principal curvatures, leading to a better coverage of
the object surface than random initialization. Secondly, based on certain
geometric structures (e.g., local manifold), we introduce efficient and
noise-robust estimation methods that provide dynamic geometric priors for our
framework. We conduct extensive experiments on multiple datasets for novel view
synthesis, showing that our framework: GeoSplat, significantly improves the
performance of Gaussian splatting and outperforms previous baselines.

</details>


### [43] [Scale-interaction transformer: a hybrid cnn-transformer model for facial beauty prediction](https://arxiv.org/abs/2509.05078)
*Djamel Eddine Boukhari*

Main category: cs.CV

TL;DR: 论文提出了一种结合CNN和Transformer的混合架构SIT，用于面部美观预测，通过多尺度特征提取和自注意力机制建模特征间关系，在SCUT-FBP5500数据集上达到新SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有CNN方法在处理面部美观预测时，由于固定尺度的特征提取，可能忽略多尺度特征间的依赖关系。

Method: 提出SIT架构，结合CNN的多尺度特征提取和Transformer的自注意力机制，建模特征间关系。

Result: 在SCUT-FBP5500数据集上，SIT达到0.9187的Pearson相关系数，优于之前方法。

Conclusion: SIT的成功表明，显式建模多尺度特征关系对高性能面部美观预测至关重要，混合CNN-Transformer架构在复杂图像回归任务中具有潜力。

Abstract: Automated Facial Beauty Prediction (FBP) is a challenging computer vision
task due to the complex interplay of local and global facial features that
influence human perception. While Convolutional Neural Networks (CNNs) excel at
feature extraction, they often process information at a fixed scale,
potentially overlooking the critical inter-dependencies between features at
different levels of granularity. To address this limitation, we introduce the
Scale-Interaction Transformer (SIT), a novel hybrid deep learning architecture
that synergizes the feature extraction power of CNNs with the relational
modeling capabilities of Transformers. The SIT first employs a multi-scale
module with parallel convolutions to capture facial characteristics at varying
receptive fields. These multi-scale representations are then framed as a
sequence and processed by a Transformer encoder, which explicitly models their
interactions and contextual relationships via a self-attention mechanism. We
conduct extensive experiments on the widely-used SCUT-FBP5500 benchmark
dataset, where the proposed SIT model establishes a new state-of-the-art. It
achieves a Pearson Correlation of 0.9187, outperforming previous methods. Our
findings demonstrate that explicitly modeling the interplay between multi-scale
visual cues is crucial for high-performance FBP. The success of the SIT
architecture highlights the potential of hybrid CNN-Transformer models for
complex image regression tasks that demand a holistic, context-aware
understanding.

</details>


### [44] [Robust Experts: the Effect of Adversarial Training on CNNs with Sparse Mixture-of-Experts Layers](https://arxiv.org/abs/2509.05086)
*Svetlana Pavlitska,Haixi Fan,Konstantin Ditschuneit,J. Marius Zöllner*

Main category: cs.CV

TL;DR: 使用稀疏混合专家（MoE）层增强CNN对抗攻击的鲁棒性，通过替换残差块或卷积层，在不增加推理成本的情况下提升模型容量。


<details>
  <summary>Details</summary>
Motivation: 探索如何在不增加资源消耗的情况下，通过改进模型结构来增强CNN对抗攻击的鲁棒性。

Method: 在ResNet架构中插入稀疏MoE层，并结合对抗训练，评估其在PGD和AutoPGD攻击下的表现。

Result: 在CIFAR-100上，插入MoE层显著提升了鲁棒性，且某些专家子路径因专业化而表现更优。

Conclusion: 稀疏MoE层是一种有效的鲁棒性增强方法，且专家子路径的鲁棒性可能优于整体模型。

Abstract: Robustifying convolutional neural networks (CNNs) against adversarial attacks
remains challenging and often requires resource-intensive countermeasures. We
explore the use of sparse mixture-of-experts (MoE) layers to improve robustness
by replacing selected residual blocks or convolutional layers, thereby
increasing model capacity without additional inference cost. On ResNet
architectures trained on CIFAR-100, we find that inserting a single MoE layer
in the deeper stages leads to consistent improvements in robustness under PGD
and AutoPGD attacks when combined with adversarial training. Furthermore, we
discover that when switch loss is used for balancing, it causes routing to
collapse onto a small set of overused experts, thereby concentrating
adversarial training on these paths and inadvertently making them more robust.
As a result, some individual experts outperform the gated MoE model in
robustness, suggesting that robust subpaths emerge through specialization. Our
code is available at https://github.com/KASTEL-MobilityLab/robust-sparse-moes.

</details>


### [45] [Semi-supervised Deep Transfer for Regression without Domain Alignment](https://arxiv.org/abs/2509.05092)
*Mainak Biswas,Ambedkar Dukkipati,Devarajan Sridharan*

Main category: cs.CV

TL;DR: CRAFT是一种高效的源自由半监督深度迁移方法，适用于回归任务，在神经科学和医学领域表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决源数据不可用、目标数据标记稀少且输出为连续值的挑战，特别是在隐私和资源受限的场景中。

Method: 基于Contradistinguisher框架，开发了CRAFT方法，无需中间表示对齐，适用于源自由半监督回归任务。

Result: 在神经科学数据（EEG和MRI）上，CRAFT比微调模型RMSE提升9%，优于其他源自由域适应方法3%以上。

Conclusion: CRAFT是一种高效且通用的方法，适用于生物学和医学中的回归任务。

Abstract: Deep learning models deployed in real-world applications (e.g., medicine)
face challenges because source models do not generalize well to domain-shifted
target data. Many successful domain adaptation (DA) approaches require full
access to source data. Yet, such requirements are unrealistic in scenarios
where source data cannot be shared either because of privacy concerns or
because it is too large and incurs prohibitive storage or computational costs.
Moreover, resource constraints may limit the availability of labeled targets.
We illustrate this challenge in a neuroscience setting where source data are
unavailable, labeled target data are meager, and predictions involve
continuous-valued outputs. We build upon Contradistinguisher (CUDA), an
efficient framework that learns a shared model across the labeled source and
unlabeled target samples, without intermediate representation alignment. Yet,
CUDA was designed for unsupervised DA, with full access to source data, and for
classification tasks. We develop CRAFT -- a Contradistinguisher-based
Regularization Approach for Flexible Training -- for source-free (SF),
semi-supervised transfer of pretrained models in regression tasks. We showcase
the efficacy of CRAFT in two neuroscience settings: gaze prediction with
electroencephalography (EEG) data and ``brain age'' prediction with structural
MRI data. For both datasets, CRAFT yielded up to 9% improvement in
root-mean-squared error (RMSE) over fine-tuned models when labeled training
examples were scarce. Moreover, CRAFT leveraged unlabeled target data and
outperformed four competing state-of-the-art source-free domain adaptation
models by more than 3%. Lastly, we demonstrate the efficacy of CRAFT on two
other real-world regression benchmarks. We propose CRAFT as an efficient
approach for source-free, semi-supervised deep transfer for regression that is
ubiquitous in biology and medicine.

</details>


### [46] [A Scalable Attention-Based Approach for Image-to-3D Texture Mapping](https://arxiv.org/abs/2509.05131)
*Arianna Rampini,Kanika Madan,Bruno Roy,AmirHossein Zamani,Derek Cheung*

Main category: cs.CV

TL;DR: 提出了一种基于Transformer的框架，直接从单张图像和网格预测3D纹理场，无需UV映射和可微分渲染，实现更快纹理生成。


<details>
  <summary>Details</summary>
Motivation: 现有生成方法速度慢、依赖UV映射且难以保持对参考图像的忠实度，需解决这些问题。

Method: 结合三平面表示和基于深度的反向投影损失，实现高效训练和快速推理。

Result: 单次前向传播生成高保真纹理，每形状仅需0.2秒，在单图像纹理重建中优于现有方法。

Conclusion: 该方法在保真度和感知质量上表现优异，适用于可扩展、高质量和可控的3D内容创建。

Abstract: High-quality textures are critical for realistic 3D content creation, yet
existing generative methods are slow, rely on UV maps, and often fail to remain
faithful to a reference image. To address these challenges, we propose a
transformer-based framework that predicts a 3D texture field directly from a
single image and a mesh, eliminating the need for UV mapping and differentiable
rendering, and enabling faster texture generation. Our method integrates a
triplane representation with depth-based backprojection losses, enabling
efficient training and faster inference. Once trained, it generates
high-fidelity textures in a single forward pass, requiring only 0.2s per shape.
Extensive qualitative, quantitative, and user preference evaluations
demonstrate that our method outperforms state-of-the-art baselines on
single-image texture reconstruction in terms of both fidelity to the input
image and perceptual quality, highlighting its practicality for scalable,
high-quality, and controllable 3D content creation.

</details>


### [47] [SGS-3D: High-Fidelity 3D Instance Segmentation via Reliable Semantic Mask Splitting and Growing](https://arxiv.org/abs/2509.05144)
*Chaolei Wang,Yang Luo,Jing Du,Siyu Chen,Yiping Chen,Ting Han*

Main category: cs.CV

TL;DR: SGS-3D提出了一种新的“分割-生长”框架，通过几何基元净化模糊的2D-3D提升掩码，并利用语义和几何信息联合优化，显著提升了3D实例分割的精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于2D-3D提升的方法因语义模糊和深度约束不足导致分割不精确，SGS-3D旨在解决这些问题。

Method: 采用“分割-生长”框架，先通过几何基元净化掩码，再结合空间连续性和高层特征生长为完整实例。

Result: 在ScanNet200、ScanNet++和KITTI-360上验证了SGS-3D的高精度和强泛化能力。

Conclusion: SGS-3D是一种无需训练的优化方法，能有效提升3D实例分割质量。

Abstract: Accurate 3D instance segmentation is crucial for high-quality scene
understanding in the 3D vision domain. However, 3D instance segmentation based
on 2D-to-3D lifting approaches struggle to produce precise instance-level
segmentation, due to accumulated errors introduced during the lifting process
from ambiguous semantic guidance and insufficient depth constraints. To tackle
these challenges, we propose splitting and growing reliable semantic mask for
high-fidelity 3D instance segmentation (SGS-3D), a novel "split-then-grow"
framework that first purifies and splits ambiguous lifted masks using geometric
primitives, and then grows them into complete instances within the scene.
Unlike existing approaches that directly rely on raw lifted masks and sacrifice
segmentation accuracy, SGS-3D serves as a training-free refinement method that
jointly fuses semantic and geometric information, enabling effective
cooperation between the two levels of representation. Specifically, for
semantic guidance, we introduce a mask filtering strategy that leverages the
co-occurrence of 3D geometry primitives to identify and remove ambiguous masks,
thereby ensuring more reliable semantic consistency with the 3D object
instances. For the geometric refinement, we construct fine-grained object
instances by exploiting both spatial continuity and high-level features,
particularly in the case of semantic ambiguity between distinct objects.
Experimental results on ScanNet200, ScanNet++, and KITTI-360 demonstrate that
SGS-3D substantially improves segmentation accuracy and robustness against
inaccurate masks from pre-trained models, yielding high-fidelity object
instances while maintaining strong generalization across diverse indoor and
outdoor environments. Code is available in the supplementary materials.

</details>


### [48] [SL-SLR: Self-Supervised Representation Learning for Sign Language Recognition](https://arxiv.org/abs/2509.05188)
*Ariel Basso Madjoukeng,Jérôme Fink,Pierre Poitier,Edith Belise Kenmogne,Benoit Frenay*

Main category: cs.CV

TL;DR: 论文提出了一种自监督学习框架，通过自由负样本对和新数据增强技术，解决了手语识别中对比学习方法忽视关键部分和负样本相似的问题，显著提升了准确性。


<details>
  <summary>Details</summary>
Motivation: 手语识别中，对比学习方法忽视视频中关键部分且负样本相似度高，导致特征学习不具区分性。

Method: 提出自监督学习框架，包含自由负样本对和新数据增强技术。

Result: 在多种评估场景下，方法优于对比学习和自监督方法。

Conclusion: 该框架有效提升了手语识别的准确性，适用于跨语言迁移等任务。

Abstract: Sign language recognition (SLR) is a machine learning task aiming to identify
signs in videos. Due to the scarcity of annotated data, unsupervised methods
like contrastive learning have become promising in this field. They learn
meaningful representations by pulling positive pairs (two augmented versions of
the same instance) closer and pushing negative pairs (different from the
positive pairs) apart. In SLR, in a sign video, only certain parts provide
information that is truly useful for its recognition. Applying contrastive
methods to SLR raises two issues: (i) contrastive learning methods treat all
parts of a video in the same way, without taking into account the relevance of
certain parts over others; (ii) shared movements between different signs make
negative pairs highly similar, complicating sign discrimination. These issues
lead to learning non-discriminative features for sign recognition and poor
results in downstream tasks. In response, this paper proposes a self-supervised
learning framework designed to learn meaningful representations for SLR. This
framework consists of two key components designed to work together: (i) a new
self-supervised approach with free-negative pairs; (ii) a new data augmentation
technique. This approach shows a considerable gain in accuracy compared to
several contrastive and self-supervised methods, across linear evaluation,
semi-supervised learning, and transferability between sign languages.

</details>


### [49] [Symbolic Graphics Programming with Large Language Models](https://arxiv.org/abs/2509.05208)
*Yamei Chen,Haoquan Zhang,Yangyi Huang,Zeju Qiu,Kaipeng Zhang,Yandong Wen,Weiyang Liu*

Main category: cs.CV

TL;DR: LLMs在生成符号图形程序（SGPs）方面的能力尚待探索，本文通过SGP-GenBench评估并改进LLMs生成SVG的能力，提出强化学习方法提升性能。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs如何通过生成SGPs理解视觉世界，并探索其在符号图形编程中的表现。

Method: 引入SGP-GenBench基准，提出基于强化学习的可验证奖励方法，结合格式验证和跨模态对齐。

Result: 改进后的Qwen-2.5-7B模型在SVG生成质量和语义上达到前沿系统水平。

Conclusion: 符号图形编程为跨模态基础提供了精确且可解释的视角。

Abstract: Large language models (LLMs) excel at program synthesis, yet their ability to
produce symbolic graphics programs (SGPs) that render into precise visual
content remains underexplored. We study symbolic graphics programming, where
the goal is to generate an SGP from a natural-language description. This task
also serves as a lens into how LLMs understand the visual world by prompting
them to generate images rendered from SGPs. Among various SGPs, our paper
sticks to scalable vector graphics (SVGs). We begin by examining the extent to
which LLMs can generate SGPs. To this end, we introduce SGP-GenBench, a
comprehensive benchmark covering object fidelity, scene fidelity, and
compositionality (attribute binding, spatial relations, numeracy). On
SGP-GenBench, we discover that frontier proprietary models substantially
outperform open-source models, and performance correlates well with general
coding capabilities. Motivated by this gap, we aim to improve LLMs' ability to
generate SGPs. We propose a reinforcement learning (RL) with verifiable rewards
approach, where a format-validity gate ensures renderable SVG, and a
cross-modal reward aligns text and the rendered image via strong vision
encoders (e.g., SigLIP for text-image and DINO for image-image). Applied to
Qwen-2.5-7B, our method substantially improves SVG generation quality and
semantics, achieving performance on par with frontier systems. We further
analyze training dynamics, showing that RL induces (i) finer decomposition of
objects into controllable primitives and (ii) contextual details that improve
scene coherence. Our results demonstrate that symbolic graphics programming
offers a precise and interpretable lens on cross-modal grounding.

</details>


### [50] [COGITAO: A Visual Reasoning Framework To Study Compositionality & Generalization](https://arxiv.org/abs/2509.05249)
*Yassine Taoudi-Benchekroun,Klim Troyan,Pascal Sager,Stefan Gerber,Lukas Tuggener,Benjamin Grewe*

Main category: cs.CV

TL;DR: COGITAO是一个模块化、可扩展的数据生成框架和基准，用于系统研究视觉领域的组合性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决当前机器学习模型在组合学习概念和应用到新场景中的局限性。

Method: 基于ARC-AGI的问题设置，构建规则化任务，支持28种可互操作的变换的组合，并控制网格参数和对象属性。

Result: 生成数百万个独特任务规则，覆盖广泛难度范围，并展示现有视觉模型在新组合上的泛化失败。

Conclusion: COGITAO开源支持进一步研究组合性和泛化问题。

Abstract: The ability to compose learned concepts and apply them in novel settings is
key to human intelligence, but remains a persistent limitation in
state-of-the-art machine learning models. To address this issue, we introduce
COGITAO, a modular and extensible data generation framework and benchmark
designed to systematically study compositionality and generalization in visual
domains. Drawing inspiration from ARC-AGI's problem-setting, COGITAO constructs
rule-based tasks which apply a set of transformations to objects in grid-like
environments. It supports composition, at adjustable depth, over a set of 28
interoperable transformations, along with extensive control over grid
parametrization and object properties. This flexibility enables the creation of
millions of unique task rules -- surpassing concurrent datasets by several
orders of magnitude -- across a wide range of difficulties, while allowing
virtually unlimited sample generation per rule. We provide baseline experiments
using state-of-the-art vision models, highlighting their consistent failures to
generalize to novel combinations of familiar elements, despite strong in-domain
performance. COGITAO is fully open-sourced, including all code and datasets, to
support continued research in this field.

</details>


### [51] [WinT3R: Window-Based Streaming Reconstruction with Camera Token Pool](https://arxiv.org/abs/2509.05296)
*Zizun Li,Jianjun Zhou,Yifan Wang,Haoyu Guo,Wenzheng Chang,Yang Zhou,Haoyi Zhu,Junyi Chen,Chunhua Shen,Tong He*

Main category: cs.CV

TL;DR: WinT3R是一种前馈重建模型，能够在实时预测精确相机位姿和高质量点云地图的同时，平衡重建质量和实时性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在重建质量和实时性能之间存在权衡，WinT3R旨在解决这一问题。

Method: 引入滑动窗口机制和全局相机令牌池，确保帧间信息交换并提升相机位姿估计的可靠性。

Result: 在在线重建质量、相机位姿估计和重建速度方面达到最先进性能。

Conclusion: WinT3R通过高效设计实现了高质量实时重建，代码和模型已开源。

Abstract: We present WinT3R, a feed-forward reconstruction model capable of online
prediction of precise camera poses and high-quality point maps. Previous
methods suffer from a trade-off between reconstruction quality and real-time
performance. To address this, we first introduce a sliding window mechanism
that ensures sufficient information exchange among frames within the window,
thereby improving the quality of geometric predictions without large
computation. In addition, we leverage a compact representation of cameras and
maintain a global camera token pool, which enhances the reliability of camera
pose estimation without sacrificing efficiency. These designs enable WinT3R to
achieve state-of-the-art performance in terms of online reconstruction quality,
camera pose estimation, and reconstruction speed, as validated by extensive
experiments on diverse datasets. Code and model are publicly available at
https://github.com/LiZizun/WinT3R.

</details>


### [52] [FlowSeek: Optical Flow Made Easier with Depth Foundation Models and Motion Bases](https://arxiv.org/abs/2509.05297)
*Matteo Poggi,Fabio Tosi*

Main category: cs.CV

TL;DR: FlowSeek是一种新型光流框架，训练所需硬件资源极少，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决光流网络训练资源需求高的问题，结合最新技术和经典方法实现高效架构。

Method: 结合光流网络设计、单图像深度基础模型和低维运动参数化，构建紧凑且准确的架构。

Result: 在Sintel Final、KITTI等数据集上表现优异，相对SEA-RAFT提升10-15%，训练硬件需求降低8倍。

Conclusion: FlowSeek在资源受限条件下实现了高性能光流估计，具有广泛的应用潜力。

Abstract: We present FlowSeek, a novel framework for optical flow requiring minimal
hardware resources for training. FlowSeek marries the latest advances on the
design space of optical flow networks with cutting-edge single-image depth
foundation models and classical low-dimensional motion parametrization,
implementing a compact, yet accurate architecture. FlowSeek is trained on a
single consumer-grade GPU, a hardware budget about 8x lower compared to most
recent methods, and still achieves superior cross-dataset generalization on
Sintel Final and KITTI, with a relative improvement of 10 and 15% over the
previous state-of-the-art SEA-RAFT, as well as on Spring and LayeredFlow
datasets.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [53] [Q-SafeML: Safety Assessment of Quantum Machine Learning via Quantum Distance Metrics](https://arxiv.org/abs/2509.04536)
*Oliver Dunn,Koorosh Aslansefat,Yiannis Papadopoulos*

Main category: cs.LG

TL;DR: Q-SafeML是一种针对量子机器学习（QML）的安全监控方法，通过量子中心距离度量来检测概念漂移，提升系统透明度和安全性。


<details>
  <summary>Details</summary>
Motivation: 由于量子计算与经典计算的根本差异，现有的安全监控方法无法直接应用于QML，因此需要开发专门的安全机制。

Method: Q-SafeML基于SafeML，但引入了量子中心距离度量，以适应QML的概率性输出，并通过后分类评估检测概念漂移。

Result: 在QCNN和VQC模型上的实验表明，Q-SafeML能够提供有效的人类监督，增强系统透明度和安全性。

Conclusion: Q-SafeML为QML提供了专门的安全监控方法，填补了现有技术的空白，并展示了实际应用潜力。

Abstract: The rise of machine learning in safety-critical systems has paralleled
advancements in quantum computing, leading to the emerging field of Quantum
Machine Learning (QML). While safety monitoring has progressed in classical ML,
existing methods are not directly applicable to QML due to fundamental
differences in quantum computation. Given the novelty of QML, dedicated safety
mechanisms remain underdeveloped. This paper introduces Q-SafeML, a safety
monitoring approach for QML. The method builds on SafeML, a recent method that
utilizes statistical distance measures to assess model accuracy and provide
confidence in the reasoning of an algorithm. An adapted version of Q-SafeML
incorporates quantum-centric distance measures, aligning with the probabilistic
nature of QML outputs. This shift to a model-dependent, post-classification
evaluation represents a key departure from classical SafeML, which is
dataset-driven and classifier-agnostic. The distinction is motivated by the
unique representational constraints of quantum systems, requiring distance
metrics defined over quantum state spaces. Q-SafeML detects distances between
operational and training data addressing the concept drifts in the context of
QML. Experiments on QCNN and VQC Models show that this enables informed human
oversight, enhancing system transparency and safety.

</details>


### [54] [Finance-Grounded Optimization For Algorithmic Trading](https://arxiv.org/abs/2509.04541)
*Kasymkhan Khubiev,Mikhail Semenov,Irina Podlipnova*

Main category: cs.LG

TL;DR: 论文提出了一种基于金融指标的损失函数和周转率正则化方法，用于改进深度学习在金融领域的预测性能。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法在金融领域表现不佳，因为金融专家使用不同的指标评估模型性能。

Method: 引入基于金融指标的损失函数（如夏普比率、盈亏和最大回撤）和周转率正则化方法。

Result: 提出的方法在算法交易指标上优于传统的均方误差损失函数。

Conclusion: 金融基础指标能提升交易策略和投资组合优化的预测性能。

Abstract: Deep Learning is evolving fast and integrates into various domains. Finance
is a challenging field for deep learning, especially in the case of
interpretable artificial intelligence (AI). Although classical approaches
perform very well with natural language processing, computer vision, and
forecasting, they are not perfect for the financial world, in which specialists
use different metrics to evaluate model performance.
  We first introduce financially grounded loss functions derived from key
quantitative finance metrics, including the Sharpe ratio, Profit-and-Loss
(PnL), and Maximum Draw down. Additionally, we propose turnover regularization,
a method that inherently constrains the turnover of generated positions within
predefined limits.
  Our findings demonstrate that the proposed loss functions, in conjunction
with turnover regularization, outperform the traditional mean squared error
loss for return prediction tasks when evaluated using algorithmic trading
metrics. The study shows that financially grounded metrics enhance predictive
performance in trading strategies and portfolio optimization.

</details>


### [55] [i-Mask: An Intelligent Mask for Breath-Driven Activity Recognition](https://arxiv.org/abs/2509.04544)
*Ashutosh Kumar Sinha,Ayush Patel,Mitul Dudhat,Pritam Anand,Rahul Mishra*

Main category: cs.LG

TL;DR: i-Mask利用呼气模式进行人类活动识别，准确率超过95%。


<details>
  <summary>Details</summary>
Motivation: 呼吸模式包含重要生理信号，可用于预测行为和健康趋势。

Method: 开发定制口罩收集呼气数据，进行噪声过滤和时间序列分解。

Result: 实验验证方法有效，准确率超过95%。

Conclusion: i-Mask在医疗和健身领域有潜在应用价值。

Abstract: The patterns of inhalation and exhalation contain important physiological
signals that can be used to anticipate human behavior, health trends, and vital
parameters. Human activity recognition (HAR) is fundamentally connected to
these vital signs, providing deeper insights into well-being and enabling
real-time health monitoring. This work presents i-Mask, a novel HAR approach
that leverages exhaled breath patterns captured using a custom-developed mask
equipped with integrated sensors. Data collected from volunteers wearing the
mask undergoes noise filtering, time-series decomposition, and labeling to
train predictive models. Our experimental results validate the effectiveness of
the approach, achieving over 95\% accuracy and highlighting its potential in
healthcare and fitness applications.

</details>


### [56] [Bootstrapping Task Spaces for Self-Improvement](https://arxiv.org/abs/2509.04575)
*Minqi Jiang,Andrei Lupu,Yoram Bachrach*

Main category: cs.LG

TL;DR: ExIt是一种自课程强化学习方法，通过选择性采样最有信息量的中间历史来训练自我改进策略，实现推理时的多步自我改进。


<details>
  <summary>Details</summary>
Motivation: 传统RL方法在自我改进任务中假设固定最大迭代深度，成本高且随意，ExIt旨在解决这一问题。

Method: ExIt通过选择性采样中间历史作为新任务实例，训练自我改进策略，并可结合显式探索机制增加任务多样性。

Result: 在多个领域（如竞赛数学、多轮工具使用等）中，ExIt策略表现出在推理时的强自我改进能力，并能超越训练时的平均迭代深度。

Conclusion: ExIt提供了一种高效的自课程RL方法，能够在推理时实现多步自我改进，适用于多种任务领域。

Abstract: Progress in many task domains emerges from repeated revisions to previous
solution attempts. Training agents that can reliably self-improve over such
sequences at inference-time is a natural target for reinforcement learning
(RL), yet the naive approach assumes a fixed maximum iteration depth, which can
be both costly and arbitrary. We present Exploratory Iteration (ExIt), a family
of autocurriculum RL methods that directly exploits the recurrent structure of
self-improvement tasks to train LLMs to perform multi-step self-improvement at
inference-time while only training on the most informative single-step
iterations. ExIt grows a task space by selectively sampling the most
informative intermediate, partial histories encountered during an episode for
continued iteration, treating these starting points as new self-iteration task
instances to train a self-improvement policy. ExIt can further pair with
explicit exploration mechanisms to sustain greater task diversity. Across
several domains, encompassing competition math, multi-turn tool-use, and
machine learning engineering, we demonstrate that ExIt strategies, starting
from either a single or many task instances, can produce policies exhibiting
strong inference-time self-improvement on held-out task instances, and the
ability to iterate towards higher performance over a step budget extending
beyond the average iteration depth encountered during training.

</details>


### [57] [Instance-Wise Adaptive Sampling for Dataset Construction in Approximating Inverse Problem Solutions](https://arxiv.org/abs/2509.04583)
*Jiequn Han,Kui Ren,Nathan Soedjak*

Main category: cs.LG

TL;DR: 提出了一种实例自适应的采样框架，用于构建紧凑且信息丰富的训练数据集，以提高逆问题监督学习的效率。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要大量训练样本，成本高；新方法通过动态分配采样资源，针对特定测试实例优化数据集。

Method: 迭代调整训练数据集，根据测试实例的最新预测结果动态优化采样策略。

Result: 在逆散射问题中验证了方法的有效性，尤其在复杂先验或高精度要求下表现更优。

Conclusion: 自适应采样策略可扩展至其他逆问题，提供了一种高效且实用的替代方案。

Abstract: We propose an instance-wise adaptive sampling framework for constructing
compact and informative training datasets for supervised learning of inverse
problem solutions. Typical learning-based approaches aim to learn a
general-purpose inverse map from datasets drawn from a prior distribution, with
the training process independent of the specific test instance. When the prior
has a high intrinsic dimension or when high accuracy of the learned solution is
required, a large number of training samples may be needed, resulting in
substantial data collection costs. In contrast, our method dynamically
allocates sampling effort based on the specific test instance, enabling
significant gains in sample efficiency. By iteratively refining the training
dataset conditioned on the latest prediction, the proposed strategy tailors the
dataset to the geometry of the inverse map around each test instance. We
demonstrate the effectiveness of our approach in the inverse scattering problem
under two types of structured priors. Our results show that the advantage of
the adaptive method becomes more pronounced in settings with more complex
priors or higher accuracy requirements. While our experiments focus on a
particular inverse problem, the adaptive sampling strategy is broadly
applicable and readily extends to other inverse problems, offering a scalable
and practical alternative to conventional fixed-dataset training regimes.

</details>


### [58] [Toward Faithfulness-guided Ensemble Interpretation of Neural Network](https://arxiv.org/abs/2509.04588)
*Siyu Zhang,Kenneth Mcmillan*

Main category: cs.LG

TL;DR: FEI框架通过提升忠实性和可视化效果，显著改进了神经网络解释的广度和精确性。


<details>
  <summary>Details</summary>
Motivation: 为特定神经推理提供可解释且忠实的解释，以理解和评估模型行为。

Method: 提出FEI框架，通过平滑近似提升忠实性分数，并针对隐藏层编码设计多样化变体。

Result: FEI在实验中超越现有方法，在可视化效果和忠实性分数上均有显著提升。

Conclusion: FEI为神经网络解释提供了一个全面框架，强调广度和精确性。

Abstract: Interpretable and faithful explanations for specific neural inferences are
crucial for understanding and evaluating model behavior. Our work introduces
\textbf{F}aithfulness-guided \textbf{E}nsemble \textbf{I}nterpretation
(\textbf{FEI}), an innovative framework that enhances the breadth and
effectiveness of faithfulness, advancing interpretability by providing superior
visualization. Through an analysis of existing evaluation benchmarks,
\textbf{FEI} employs a smooth approximation to elevate quantitative
faithfulness scores. Diverse variations of \textbf{FEI} target enhanced
faithfulness in hidden layer encodings, expanding interpretability.
Additionally, we propose a novel qualitative metric that assesses hidden layer
faithfulness. In extensive experiments, \textbf{FEI} surpasses existing
methods, demonstrating substantial advances in qualitative visualization and
quantitative faithfulness scores. Our research establishes a comprehensive
framework for elevating faithfulness in neural network explanations,
emphasizing both breadth and precision

</details>


### [59] [Quantum-Enhanced Multi-Task Learning with Learnable Weighting for Pharmacokinetic and Toxicity Prediction](https://arxiv.org/abs/2509.04601)
*Han Zhang,Fengji Ma,Jiamin Su,Xinyue Yang,Lei Wang,Wen-Cai Ye,Li Liu*

Main category: cs.LG

TL;DR: 提出了一种新的量子增强和任务加权多任务学习框架（QW-MTL），用于ADMET分类任务，显著优于单任务基线。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖单任务学习（STL），无法充分利用任务间的互补性，且计算资源消耗大。

Method: 基于Chemprop-RDKit框架，引入量子化学描述符和指数任务加权方案，动态平衡任务损失。

Result: 在13个TDC分类基准中，QW-MTL在12个任务上显著优于单任务基线，预测性能高且模型复杂度低。

Conclusion: 量子增强特征和自适应任务加权的多任务分子学习高效且有效。

Abstract: Prediction for ADMET (Absorption, Distribution, Metabolism, Excretion, and
Toxicity) plays a crucial role in drug discovery and development, accelerating
the screening and optimization of new drugs. Existing methods primarily rely on
single-task learning (STL), which often fails to fully exploit the
complementarities between tasks. Besides, it requires more computational
resources while training and inference of each task independently. To address
these issues, we propose a new unified Quantum-enhanced and task-Weighted
Multi-Task Learning (QW-MTL) framework, specifically designed for ADMET
classification tasks. Built upon the Chemprop-RDKit backbone, QW-MTL adopts
quantum chemical descriptors to enrich molecular representations with
additional information about the electronic structure and interactions.
Meanwhile, it introduces a novel exponential task weighting scheme that
combines dataset-scale priors with learnable parameters to achieve dynamic loss
balancing across tasks. To the best of our knowledge, this is the first work to
systematically conduct joint multi-task training across all 13 Therapeutics
Data Commons (TDC) classification benchmarks, using leaderboard-style data
splits to ensure a standardized and realistic evaluation setting. Extensive
experimental results show that QW-MTL significantly outperforms single-task
baselines on 12 out of 13 tasks, achieving high predictive performance with
minimal model complexity and fast inference, demonstrating the effectiveness
and efficiency of multi-task molecular learning enhanced by quantum-informed
features and adaptive task weighting.

</details>


### [60] [Measuring the Measures: Discriminative Capacity of Representational Similarity Metrics Across Model Families](https://arxiv.org/abs/2509.04622)
*Jialin Wu,Shreya Saha,Yiqing Bo,Meenakshi Khosla*

Main category: cs.LG

TL;DR: 本文提出了一个定量框架，用于评估表征相似性度量在不同模型家族中的区分能力，并比较了多种常用度量方法的效果。


<details>
  <summary>Details</summary>
Motivation: 表征相似性度量在神经科学和AI中是基础工具，但缺乏对不同模型家族中这些度量区分能力的系统比较。

Method: 引入了一个定量框架，使用三种互补的分离度量（dprime、轮廓系数和ROC-AUC），评估了包括RSA、线性预测性、Procrustes和软匹配在内的常用度量。

Result: 结果显示，随着度量施加更严格的对齐约束，区分能力系统性增加。软匹配在基于映射的方法中表现最佳，其次是Procrustes对齐和线性预测性。非拟合方法如RSA也表现出较强的区分能力。

Conclusion: 研究首次通过区分性视角系统比较了相似性度量，明确了它们的相对敏感性，并为大规模模型和大脑比较中的度量选择提供了指导。

Abstract: Representational similarity metrics are fundamental tools in neuroscience and
AI, yet we lack systematic comparisons of their discriminative power across
model families. We introduce a quantitative framework to evaluate
representational similarity measures based on their ability to separate model
families-across architectures (CNNs, Vision Transformers, Swin Transformers,
ConvNeXt) and training regimes (supervised vs. self-supervised). Using three
complementary separability measures-dprime from signal detection theory,
silhouette coefficients and ROC-AUC, we systematically assess the
discriminative capacity of commonly used metrics including RSA, linear
predictivity, Procrustes, and soft matching. We show that separability
systematically increases as metrics impose more stringent alignment
constraints. Among mapping-based approaches, soft-matching achieves the highest
separability, followed by Procrustes alignment and linear predictivity.
Non-fitting methods such as RSA also yield strong separability across families.
These results provide the first systematic comparison of similarity metrics
through a separability lens, clarifying their relative sensitivity and guiding
metric choice for large-scale model and brain comparisons.

</details>


### [61] [Split Conformal Prediction in the Function Space with Neural Operators](https://arxiv.org/abs/2509.04623)
*David Millard,Lars Lindemann,Ali Baheri*

Main category: cs.LG

TL;DR: 该论文提出了一种将分体式共形预测扩展到函数空间的方法，通过离散化和渐进收敛保证有限样本覆盖，并提出了诊断指标来量化预测退化。


<details>
  <summary>Details</summary>
Motivation: 神经算子的不确定性量化在无限维空间中缺乏有限样本覆盖保证，现有方法需要强分布假设或覆盖保守。

Method: 采用两步法：先在有限维空间建立覆盖保证，再通过渐进收敛扩展到函数空间，并提出回归校正和诊断指标。

Result: 实验表明，该方法在分辨率变化下保持校准覆盖，且在高分辨率任务中覆盖更好。

Conclusion: 该方法有效解决了函数空间中的不确定性量化问题，覆盖更稳定且适应性强。

Abstract: Uncertainty quantification for neural operators remains an open problem in
the infinite-dimensional setting due to the lack of finite-sample coverage
guarantees over functional outputs. While conformal prediction offers
finite-sample guarantees in finite-dimensional spaces, it does not directly
extend to function-valued outputs. Existing approaches (Gaussian processes,
Bayesian neural networks, and quantile-based operators) require strong
distributional assumptions or yield conservative coverage. This work extends
split conformal prediction to function spaces following a two step method. We
first establish finite-sample coverage guarantees in a finite-dimensional space
using a discretization map in the output function space. Then these guarantees
are lifted to the function-space by considering the asymptotic convergence as
the discretization is refined. To characterize the effect of resolution, we
decompose the conformal radius into discretization, calibration, and
misspecification components. This decomposition motivates a regression-based
correction to transfer calibration across resolutions. Additionally, we propose
two diagnostic metrics (conformal ensemble score and internal agreement) to
quantify forecast degradation in autoregressive settings. Empirical results
show that our method maintains calibrated coverage with less variation under
resolution shifts and achieves better coverage in super-resolution tasks.

</details>


### [62] [Fundamental bounds on efficiency-confidence trade-off for transductive conformal prediction](https://arxiv.org/abs/2509.04631)
*Arash Behboodi,Alvaro H. C. Correia,Fabio Valerio Massoli,Christos Louizos*

Main category: cs.LG

TL;DR: 论文研究了转导共形预测中的置信度与效率之间的权衡，证明了在数据不确定性下，非平凡置信度会导致预测集大小的指数增长。


<details>
  <summary>Details</summary>
Motivation: 探讨转导共形预测中置信度与效率的关系，特别是在数据不确定性下的表现。

Method: 通过严格的有限样本界限分析，研究了预测集大小与置信度的关系，并引入条件熵和分散度作为关键因素。

Result: 证明了预测集大小随样本数和条件熵线性增长，且在理想化设置下可实现该界限。

Conclusion: 转导预测在特定情况下可简化为假设检验问题，并提供了渐近最优的置信预测器及误差指数分析。

Abstract: Transductive conformal prediction addresses the simultaneous prediction for
multiple data points. Given a desired confidence level, the objective is to
construct a prediction set that includes the true outcomes with the prescribed
confidence. We demonstrate a fundamental trade-off between confidence and
efficiency in transductive methods, where efficiency is measured by the size of
the prediction sets. Specifically, we derive a strict finite-sample bound
showing that any non-trivial confidence level leads to exponential growth in
prediction set size for data with inherent uncertainty. The exponent scales
linearly with the number of samples and is proportional to the conditional
entropy of the data. Additionally, the bound includes a second-order term,
dispersion, defined as the variance of the log conditional probability
distribution. We show that this bound is achievable in an idealized setting.
Finally, we examine a special case of transductive prediction where all test
data points share the same label. We show that this scenario reduces to the
hypothesis testing problem with empirically observed statistics and provide an
asymptotically optimal confidence predictor, along with an analysis of the
error exponent.

</details>


### [63] [Interpreting Transformer Architectures as Implicit Multinomial Regression](https://arxiv.org/abs/2509.04653)
*Jonas A. Actor,Anthony Gruber,Eric C. Cyr*

Main category: cs.LG

TL;DR: 论文揭示了注意力机制与多项式回归之间的新联系，表明优化潜在特征可以得到与注意力块动态一致的解。


<details>
  <summary>Details</summary>
Motivation: 理解注意力机制在Transformer模型中的数学基础及其与特征多义性、叠加和模型性能的关系。

Method: 在固定多项式回归设置中优化潜在特征，分析其与注意力块动态的对应关系。

Result: 发现Transformer中表征的演化可以解释为恢复分类最优特征的轨迹。

Conclusion: 注意力机制与多项式回归的优化特征动态一致，为理解Transformer提供新视角。

Abstract: Mechanistic interpretability aims to understand how internal components of
modern machine learning models, such as weights, activations, and layers, give
rise to the model's overall behavior. One particularly opaque mechanism is
attention: despite its central role in transformer models, its mathematical
underpinnings and relationship to concepts like feature polysemanticity,
superposition, and model performance remain poorly understood. This paper
establishes a novel connection between attention mechanisms and multinomial
regression. Specifically, we show that in a fixed multinomial regression
setting, optimizing over latent features yields optimal solutions that align
with the dynamics induced by attention blocks. In other words, the evolution of
representations through a transformer can be interpreted as a trajectory that
recovers the optimal features for classification.

</details>


### [64] [Flexible inference of learning rules from de novo learning data using neural networks](https://arxiv.org/abs/2509.04661)
*Yuhan Helena Liu,Victor Geadah,Jonathan Pillow*

Main category: cs.LG

TL;DR: 提出了一种非参数框架，通过深度神经网络（DNN）和循环神经网络（RNN）从动物决策数据中推断学习规则，适用于从头学习任务。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常假设特定参数形式或局限于简化任务，无法捕捉动物从头学习新行为时的复杂性。

Method: 使用DNN和RNN参数化策略权重的每轮更新，并在模拟中验证其有效性。

Result: 模型在模拟中恢复真实规则，并在小鼠行为数据中提高预测准确性，揭示了非马尔可夫学习特征。

Conclusion: 该框架为从行为数据中推断生物学习规则提供了灵活性，有助于实验训练协议和行为数字孪生的开发。

Abstract: Understanding how animals learn is a central challenge in neuroscience, with
growing relevance to the development of animal- or human-aligned artificial
intelligence. However, most existing approaches assume specific parametric
forms for the learning rule (e.g., Q-learning, policy gradient) or are limited
to simplified settings like bandit tasks, which do not involve learning a new
input-output mapping from scratch. In contrast, animals must often learn new
behaviors de novo, which poses a rich challenge for learning-rule inference. We
target this problem by inferring learning rules directly from animal
decision-making data during de novo task learning, a setting that requires
models flexible enough to capture suboptimality, history dependence, and rich
external stimulus integration without strong structural priors. We first
propose a nonparametric framework that parameterizes the per-trial update of
policy weights with a deep neural network (DNN), and validate it by recovering
ground-truth rules in simulation. We then extend to a recurrent variant (RNN)
that captures non-Markovian dynamics by allowing updates to depend on trial
history. Applied to a large behavioral dataset of mice learning a sensory
decision-making task over multiple weeks, our models improved predictions on
held-out data. The inferred rules revealed asymmetric updates after correct
versus error trials and history dependence, consistent with non-Markovian
learning. Overall, these results introduce a flexible framework for inferring
biological learning rules from behavioral data in de novo learning tasks,
providing insights to inform experimental training protocols and the
development of behavioral digital twins.

</details>


### [65] [Beyond Ordinary Lipschitz Constraints: Differentially Private Stochastic Optimization with Tsybakov Noise Condition](https://arxiv.org/abs/2509.04668)
*Difei Xu,Meng Ding,Zihang Xiang,Jinhui Xu,Di Wang*

Main category: cs.LG

TL;DR: 研究在差分隐私模型下的随机凸优化问题，提出新的算法和上下界，适用于非Lipschitz损失函数。


<details>
  <summary>Details</summary>
Motivation: 解决在差分隐私下，当损失函数的Lipschitz常数极大或无界时的优化问题。

Method: 提出(ε, δ)-DP算法，并扩展到更一般的θ条件，同时给出隐私预算较小时的改进上界。

Result: 算法在特定条件下独立于Lipschitz常数，且隐私预算小时有更优上界；同时给出下界证明。

Conclusion: 在差分隐私下，即使损失函数非Lipschitz，仍能实现有效的优化，并提供了理论保证。

Abstract: We study Stochastic Convex Optimization in the Differential Privacy model
(DP-SCO). Unlike previous studies, here we assume the population risk function
satisfies the Tsybakov Noise Condition (TNC) with some parameter $\theta>1$,
where the Lipschitz constant of the loss could be extremely large or even
unbounded, but the $\ell_2$-norm gradient of the loss has bounded $k$-th moment
with $k\geq 2$. For the Lipschitz case with $\theta\geq 2$, we first propose an
$(\varepsilon, \delta)$-DP algorithm whose utility bound is
$\Tilde{O}\left(\left(\tilde{r}_{2k}(\frac{1}{\sqrt{n}}+(\frac{\sqrt{d}}{n\varepsilon}))^\frac{k-1}{k}\right)^\frac{\theta}{\theta-1}\right)$
in high probability, where $n$ is the sample size, $d$ is the model dimension,
and $\tilde{r}_{2k}$ is a term that only depends on the $2k$-th moment of the
gradient. It is notable that such an upper bound is independent of the
Lipschitz constant. We then extend to the case where
  $\theta\geq \bar{\theta}> 1$ for some known constant $\bar{\theta}$.
Moreover, when the privacy budget $\varepsilon$ is small enough, we show an
upper bound of
$\tilde{O}\left(\left(\tilde{r}_{k}(\frac{1}{\sqrt{n}}+(\frac{\sqrt{d}}{n\varepsilon}))^\frac{k-1}{k}\right)^\frac{\theta}{\theta-1}\right)$
even if the loss function is not Lipschitz. For the lower bound, we show that
for any $\theta\geq 2$, the private minimax rate for $\rho$-zero Concentrated
Differential Privacy is lower bounded by
$\Omega\left(\left(\tilde{r}_{k}(\frac{1}{\sqrt{n}}+(\frac{\sqrt{d}}{n\sqrt{\rho}}))^\frac{k-1}{k}\right)^\frac{\theta}{\theta-1}\right)$.

</details>


### [66] [Echoes Before Collapse: Deep Learning Detection of Flickering in Complex Systems](https://arxiv.org/abs/2509.04683)
*Yazdan Babazadeh Maghsoodlo,Madhur Anand,Chris T. Bauch*

Main category: cs.LG

TL;DR: 深度学习可以检测复杂系统中的‘闪烁’现象（噪声驱动的状态切换），为预测临界点提供新工具。


<details>
  <summary>Details</summary>
Motivation: 闪烁现象是气候、生态、金融等系统韧性下降的标志，但传统方法难以预测。本文探索深度学习在此领域的潜力。

Method: 使用CNN LSTM模型，基于合成时间序列（含噪声的多项式函数生成）进行训练。

Result: 模型能泛化到多种随机系统，并在实际数据（如非洲湿润期古气候数据）中可靠检测闪烁。

Conclusion: 深度学习可从噪声非线性时间序列中提取预警信号，为广泛动态系统的不稳定性识别提供灵活框架。

Abstract: Deep learning offers powerful tools for anticipating tipping points in
complex systems, yet its potential for detecting flickering (noise-driven
switching between coexisting stable states) remains unexplored. Flickering is a
hallmark of reduced resilience in climate systems, ecosystems, financial
markets, and other systems. It can precede critical regime shifts that are
highly impactful but difficult to predict. Here we show that convolutional long
short-term memory (CNN LSTM) models, trained on synthetic time series generated
from simple polynomial functions with additive noise, can accurately identify
flickering patterns. Despite being trained on simplified dynamics, our models
generalize to diverse stochastic systems and reliably detect flickering in
empirical datasets, including dormouse body temperature records and
palaeoclimate proxies from the African Humid Period. These findings demonstrate
that deep learning can extract early warning signals from noisy, nonlinear time
series, providing a flexible framework for identifying instability across a
wide range of dynamical systems.

</details>


### [67] [KRAFT: A Knowledge Graph-Based Framework for Automated Map Conflation](https://arxiv.org/abs/2509.04684)
*Farnoosh Hashemi,Laks V. S. Lakshmanan*

Main category: cs.LG

TL;DR: 本文提出了一种名为KRAFT的学习方法，用于解决现有地图融合方法在非线性对象和规则驱动匹配上的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有地图融合方法仅适用于线性对象（如道路网络），且依赖预定义规则，无法以数据驱动方式学习实体匹配。

Method: KRAFT包括三个部分：知识图谱构建、地图匹配（使用知识图谱对齐和地理空间特征编码）和地图合并（通过混合整数线性规划实现一致合并）。

Result: 实验表明，KRAFT在地图融合任务中优于现有方法，且其各模块（如地图匹配和合并）也优于传统方法。

Conclusion: KRAFT通过数据驱动的方法有效解决了地图融合中的非线性对象匹配和一致性问题，显著提升了性能。

Abstract: Digital maps play a crucial role in various applications such as navigation,
fleet management, and ride-sharing, necessitating their accuracy and currency,
which require timely updates. While the majority of geospatial databases (GDBs)
provide high-quality information, their data is (i) limited to specific regions
and/or (ii) missing some entities, even in their covered areas. Map conflation
is the process of augmentation of a GDB using another GDB to conflate missing
spatial features. Existing map conflation methods suffer from two main
limitations: (1) They are designed for the conflation of linear objects (e.g.,
road networks) and cannot simply be extended to non-linear objects, thus
missing information about most entities in the map. (2) They are heuristic
algorithmic approaches that are based on pre-defined rules, unable to learn
entities matching in a data-driven manner. To address these limitations, we
design KRAFT, a learning based approach consisting of three parts: (1)
Knowledge Graph Construction - where each GDB is represented by a knowledge
graph, (2) Map Matching - where we use a knowledge graph alignment method as
well as a geospatial feature encoder to match entities in obtained knowledge
graphs, and (3) Map Merging - where we merge matched entities in the previous
modules in a consistent manner, using a mixed integer linear programming
formulation that fully merges the GDBs without adding any inconsistencies. Our
experimental evaluation shows that not only does KRAFT achieve outstanding
performance compared to state-of-the-art and baseline methods in map conflation
tasks, but each of its modules (e.g., Map Matching and Map Merging) also
separately outperforms traditional matching and merging methods.

</details>


### [68] [CPEP: Contrastive Pose-EMG Pre-training Enhances Gesture Generalization on EMG Signals](https://arxiv.org/abs/2509.04699)
*Wenhui Cui,Christopher Sandino,Hadi Pouransari,Ran Liu,Juri Minxha,Ellen L. Zippi,Aman Verma,Anna Sedlackova,Behrooz Mahasseni,Erdrin Azemi*

Main category: cs.LG

TL;DR: 论文提出了一种对比姿态-EMG预训练框架（CPEP），通过对齐EMG和姿态表示，提升了手势分类性能，尤其在零样本分类中表现突出。


<details>
  <summary>Details</summary>
Motivation: 利用低成本、低功耗的生物信号（如sEMG）实现连续手势预测，但弱模态数据的表示质量较低。通过对齐高结构化数据（如姿态）的表示，可以提升弱模态数据的表示质量。

Method: 提出CPEP框架，学习一个EMG编码器，生成高质量且包含姿态信息的表示。通过对比学习对齐EMG和姿态表示。

Result: 模型在分布内手势分类中比基准模型提升21%，在分布外手势分类中提升72%。

Conclusion: 对齐弱模态和高结构化数据的表示可以显著提升手势分类性能，尤其在零样本场景下。

Abstract: Hand gesture classification using high-quality structured data such as
videos, images, and hand skeletons is a well-explored problem in computer
vision. Leveraging low-power, cost-effective biosignals, e.g. surface
electromyography (sEMG), allows for continuous gesture prediction on wearables.
In this paper, we demonstrate that learning representations from weak-modality
data that are aligned with those from structured, high-quality data can improve
representation quality and enables zero-shot classification. Specifically, we
propose a Contrastive Pose-EMG Pre-training (CPEP) framework to align EMG and
pose representations, where we learn an EMG encoder that produces high-quality
and pose-informative representations. We assess the gesture classification
performance of our model through linear probing and zero-shot setups. Our model
outperforms emg2pose benchmark models by up to 21% on in-distribution gesture
classification and 72% on unseen (out-of-distribution) gesture classification.

</details>


### [69] [Natural Spectral Fusion: p-Exponent Cyclic Scheduling and Early Decision-Boundary Alignment in First-Order Optimization](https://arxiv.org/abs/2509.04713)
*Gongyue Zhang,Honghai Liu*

Main category: cs.LG

TL;DR: 论文提出了一种名为自然频谱融合（NSF）的方法，通过动态平衡高低频信息来优化训练过程，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 研究动机是揭示一阶优化器在训练过程中对频谱的偏好，并提出一种可控的频谱覆盖和信息融合方法。

Method: 方法是通过p指数扩展第二矩项，并结合循环调度，动态平衡高低频信息。

Result: 实验表明，该方法能拓宽频谱覆盖范围，提升跨频带融合效果，并在多个基准测试中显著降低测试误差。

Conclusion: 结论是NSF揭示了优化器作为主动频谱控制器的作用，为优化提供了一种统一且高效的框架。

Abstract: Spectral behaviors have been widely discussed in machine learning, yet the
optimizer's own spectral bias remains unclear. We argue that first-order
optimizers exhibit an intrinsic frequency preference that significantly
reshapes the optimization path. To address this, we propose Natural Spectral
Fusion (NSF): reframing training as controllable spectral coverage and
information fusion rather than merely scaling step sizes. NSF has two core
principles: treating the optimizer as a spectral controller that dynamically
balances low- and high-frequency information; and periodically reweighting
frequency bands at negligible cost, without modifying the model, data, or
training pipeline. We realize NSF via a p-exponent extension of the
second-moment term, enabling both positive and negative exponents, and
implement it through cyclic scheduling. Theory and experiments show that
adaptive methods emphasize low frequencies, SGD is near-neutral, and negative
exponents amplify high-frequency information. Cyclic scheduling broadens
spectral coverage, improves cross-band fusion, and induces early
decision-boundary alignment, where accuracy improves even while loss remains
high. Across multiple benchmarks, with identical learning-rate strategies and
fixed hyperparameters, p-exponent cyclic scheduling consistently reduces test
error and demonstrates distinct convergence behavior; on some tasks, it matches
baseline accuracy with only one-quarter of the training cost. Overall, NSF
reveals the optimizer's role as an active spectral controller and provides a
unified, controllable, and efficient framework for first-order optimization.

</details>


### [70] [CoVeR: Conformal Calibration for Versatile and Reliable Autoregressive Next-Token Prediction](https://arxiv.org/abs/2509.04733)
*Yuzhu Chen,Yingjie Wang,Shunyu Liu,Yongcheng Jing,Dacheng Tao*

Main category: cs.LG

TL;DR: 提出了一种名为CoVeR的新型解码策略，结合了紧凑搜索空间和高覆盖概率，解决了现有方法在复杂推理任务中的局限性。


<details>
  <summary>Details</summary>
Motivation: 主流解码策略（如束搜索）缺乏可证明的覆盖保证，且在平衡搜索效率与多样化轨迹需求时表现不佳，尤其是在长尾序列场景中。

Method: 在共形预测框架内提出模型无关的解码策略CoVeR，通过理论分析建立了PAC风格的泛化边界。

Result: 理论证明CoVeR能以至少1-α的覆盖概率渐近地覆盖目标轨迹。

Conclusion: CoVeR在保证搜索效率的同时，提供了高覆盖概率，适用于复杂推理任务。

Abstract: Autoregressive pre-trained models combined with decoding methods have
achieved impressive performance on complex reasoning tasks. While mainstream
decoding strategies such as beam search can generate plausible candidate sets,
they often lack provable coverage guarantees, and struggle to effectively
balance search efficiency with the need for versatile trajectories,
particularly those involving long-tail sequences that are essential in certain
real-world applications. To address these limitations, we propose
\textsc{CoVeR}, a novel model-free decoding strategy wihtin the conformal
prediction framework that simultaneously maintains a compact search space and
ensures high coverage probability over desirable trajectories. Theoretically,
we establish a PAC-style generalization bound, guaranteeing that \textsc{CoVeR}
asymptotically achieves a coverage rate of at least $1 - \alpha$ for any target
level $\alpha \in (0,1)$.

</details>


### [71] [Beyond I-Con: Exploring New Dimension of Distance Measures in Representation Learning](https://arxiv.org/abs/2509.04734)
*Jasmine Shone,Shaden Alshammari,Mark Hamilton,Zhening Li,William Freeman*

Main category: cs.LG

TL;DR: Beyond I-Con框架通过探索替代统计差异和相似性核，系统性地发现新损失函数，在多个任务中超越传统KL散度方法。


<details>
  <summary>Details</summary>
Motivation: KL散度的不对称性和无界性可能导致优化问题，因此需要探索更合适的统计差异和相似性核。

Method: 提出Beyond I-Con框架，使用总变差（TV）距离和有界f-散度替代KL散度，并结合不同相似性核。

Result: 在无监督聚类、监督对比学习和降维任务中均取得优于传统方法的结果。

Conclusion: 选择合适的统计差异和相似性核对表示学习优化至关重要。

Abstract: The Information Contrastive (I-Con) framework revealed that over 23
representation learning methods implicitly minimize KL divergence between data
and learned distributions that encode similarities between data points.
However, a KL-based loss may be misaligned with the true objective, and
properties of KL divergence such as asymmetry and unboundedness may create
optimization challenges. We present Beyond I-Con, a framework that enables
systematic discovery of novel loss functions by exploring alternative
statistical divergences and similarity kernels. Key findings: (1) on
unsupervised clustering of DINO-ViT embeddings, we achieve state-of-the-art
results by modifying the PMI algorithm to use total variation (TV) distance;
(2) on supervised contrastive learning, we outperform the standard approach by
using TV and a distance-based similarity kernel instead of KL and an angular
kernel; (3) on dimensionality reduction, we achieve superior qualitative
results and better performance on downstream tasks than SNE by replacing KL
with a bounded f-divergence. Our results highlight the importance of
considering divergence and similarity kernel choices in representation learning
optimization.

</details>


### [72] [VARMA-Enhanced Transformer for Time Series Forecasting](https://arxiv.org/abs/2509.04782)
*Jiajun Song,Xiaoou Liu*

Main category: cs.LG

TL;DR: VARMAformer结合了交叉注意力框架和经典时间序列分析，通过VFE和VE-atten机制提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有Transformer模型可能忽略局部时间依赖性，VARMAformer旨在融合经典统计方法与现代深度学习。

Method: 提出VARMAformer，包含VFE提取局部特征和VE-atten增强上下文感知。

Result: 在多个基准数据集上表现优于现有方法。

Conclusion: 验证了经典统计方法与深度学习结合对时间序列预测的重要性。

Abstract: Transformer-based models have significantly advanced time series forecasting.
Recent work, like the Cross-Attention-only Time Series transformer (CATS),
shows that removing self-attention can make the model more accurate and
efficient. However, these streamlined architectures may overlook the
fine-grained, local temporal dependencies effectively captured by classical
statistical models like Vector AutoRegressive Moving Average model (VARMA). To
address this gap, we propose VARMAformer, a novel architecture that synergizes
the efficiency of a cross-attention-only framework with the principles of
classical time series analysis. Our model introduces two key innovations: (1) a
dedicated VARMA-inspired Feature Extractor (VFE) that explicitly models
autoregressive (AR) and moving-average (MA) patterns at the patch level, and
(2) a VARMA-Enhanced Attention (VE-atten) mechanism that employs a temporal
gate to make queries more context-aware. By fusing these classical insights
into a modern backbone, VARMAformer captures both global, long-range
dependencies and local, statistical structures. Through extensive experiments
on widely-used benchmark datasets, we demonstrate that our model consistently
outperforms existing state-of-the-art methods. Our work validates the
significant benefit of integrating classical statistical insights into modern
deep learning frameworks for time series forecasting.

</details>


### [73] [Graph Unlearning: Efficient Node Removal in Graph Neural Networks](https://arxiv.org/abs/2509.04785)
*Faqian Guan,Tianqing Zhu,Zhoutian Wang,Wei Ren,Wanlei Zhou*

Main category: cs.LG

TL;DR: 提出三种新的节点遗忘方法，有效利用图拓扑特征，提升图神经网络（GNN）中敏感节点隐私保护。


<details>
  <summary>Details</summary>
Motivation: 现有节点遗忘方法对GNN结构有限制或未充分利用图拓扑，甚至破坏拓扑，需改进性能与复杂度平衡。

Method: 提出三种方法：基于类的标签替换、拓扑引导的邻居平均后验概率、类一致邻居节点过滤。

Result: 实验证明新方法在模型效用、遗忘效用和效率上优于现有方法。

Conclusion: 新方法高效移除敏感节点并保护隐私，增强GNN隐私安全，为节点遗忘领域提供新见解。

Abstract: With increasing concerns about privacy attacks and potential sensitive
information leakage, researchers have actively explored methods to efficiently
remove sensitive training data and reduce privacy risks in graph neural network
(GNN) models. Node unlearning has emerged as a promising technique for
protecting the privacy of sensitive nodes by efficiently removing specific
training node information from GNN models. However, existing node unlearning
methods either impose restrictions on the GNN structure or do not effectively
utilize the graph topology for node unlearning. Some methods even compromise
the graph's topology, making it challenging to achieve a satisfactory
performance-complexity trade-off. To address these issues and achieve efficient
unlearning for training node removal in GNNs, we propose three novel node
unlearning methods: Class-based Label Replacement, Topology-guided Neighbor
Mean Posterior Probability, and Class-consistent Neighbor Node Filtering. Among
these methods, Topology-guided Neighbor Mean Posterior Probability and
Class-consistent Neighbor Node Filtering effectively leverage the topological
features of the graph, resulting in more effective node unlearning. To validate
the superiority of our proposed methods in node unlearning, we conducted
experiments on three benchmark datasets. The evaluation criteria included model
utility, unlearning utility, and unlearning efficiency. The experimental
results demonstrate the utility and efficiency of the proposed methods and
illustrate their superiority compared to state-of-the-art node unlearning
methods. Overall, the proposed methods efficiently remove sensitive training
nodes and protect the privacy information of sensitive nodes in GNNs. The
findings contribute to enhancing the privacy and security of GNN models and
provide valuable insights into the field of node unlearning.

</details>


### [74] [An Arbitration Control for an Ensemble of Diversified DQN variants in Continual Reinforcement Learning](https://arxiv.org/abs/2509.04815)
*Wonseo Jang,Dongjae Kim*

Main category: cs.LG

TL;DR: 提出ACED-DQN框架，通过仲裁控制机制解决深度强化学习在持续学习中的灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 人类大脑在持续学习时通过仲裁控制多个并行RL代理做出决策，启发设计类似机制。

Method: 集成多样化DQN变体，并通过仲裁控制优先选择近期误差较小的代理。

Result: 在静态和持续环境中均表现出显著性能提升。

Conclusion: 受人类大脑启发，ACED-DQN框架有效解决了持续强化学习中的灾难性遗忘问题。

Abstract: Deep reinforcement learning (RL) models, despite their efficiency in learning
an optimal policy in static environments, easily loses previously learned
knowledge (i.e., catastrophic forgetting). It leads RL models to poor
performance in continual reinforcement learning (CRL) scenarios. To address
this, we present an arbitration control mechanism over an ensemble of RL
agents. It is motivated by and closely aligned with how humans make decisions
in a CRL context using an arbitration control of multiple RL agents in parallel
as observed in the prefrontal cortex. We integrated two key ideas into our
model: (1) an ensemble of RLs (i.e., DQN variants) explicitly trained to have
diverse value functions and (2) an arbitration control that prioritizes agents
with higher reliability (i.e., less error) in recent trials. We propose a
framework for CRL, an Arbitration Control for an Ensemble of Diversified DQN
variants (ACED-DQN). We demonstrate significant performance improvements in
both static and continual environments, supported by empirical evidence showing
the effectiveness of arbitration control over diversified DQNs during training.
In this work, we introduced a framework that enables RL agents to continuously
learn, with inspiration from the human brain.

</details>


### [75] [Revolution or Hype? Seeking the Limits of Large Models in Hardware Design](https://arxiv.org/abs/2509.04905)
*Qiang Xu,Leon Stok,Rolf Drechsler,Xi Wang,Grace Li Zhang,Igor L. Markov*

Main category: cs.LG

TL;DR: 论文探讨了大型AI模型（如LLMs和LCMs）在电路设计中的实际能力、局限性和未来前景，并围绕可靠性、可扩展性和可解释性展开讨论。


<details>
  <summary>Details</summary>
Motivation: 研究大型AI模型是否能在硬件设计中真正超越或补充传统EDA方法，解决当前技术趋势中的争议和影响。

Method: 通过汇集学术界和工业界专家的观点，批判性分析大型AI模型的实用性和局限性。

Result: 提供了关于大型AI模型在电路设计中潜力和挑战的权威概述。

Conclusion: 论文为ICCAD 2025小组讨论提供了基础，揭示了这一技术趋势的核心争议和未来方向。

Abstract: Recent breakthroughs in Large Language Models (LLMs) and Large Circuit Models
(LCMs) have sparked excitement across the electronic design automation (EDA)
community, promising a revolution in circuit design and optimization. Yet, this
excitement is met with significant skepticism: Are these AI models a genuine
revolution in circuit design, or a temporary wave of inflated expectations?
This paper serves as a foundational text for the corresponding ICCAD 2025
panel, bringing together perspectives from leading experts in academia and
industry. It critically examines the practical capabilities, fundamental
limitations, and future prospects of large AI models in hardware design. The
paper synthesizes the core arguments surrounding reliability, scalability, and
interpretability, framing the debate on whether these models can meaningfully
outperform or complement traditional EDA methods. The result is an
authoritative overview offering fresh insights into one of today's most
contentious and impactful technology trends.

</details>


### [76] [Scaling Law for Large-Scale Pre-Training Using Chaotic Time Series and Predictability in Financial Time Series](https://arxiv.org/abs/2509.04921)
*Yuki Takemoto*

Main category: cs.LG

TL;DR: 提出了一种通过生成人工混沌时间序列和重采样技术模拟金融时间序列数据的方法，用于大规模预训练模型，并在比特币交易数据上验证了零样本预测的有效性。


<details>
  <summary>Details</summary>
Motivation: 金融时间序列预测具有挑战性，现有方法难以应对混沌特性，因此探索通过人工生成混沌时间序列和重采样技术来改进预测性能。

Method: 生成人工混沌时间序列，应用重采样技术模拟金融数据，进行大规模预训练（100亿样本），并在比特币数据上测试零样本预测。

Result: 预训练模型在比特币交易策略中表现优于自相关模型，并观察到类似扩展定律的现象。

Conclusion: 通过大规模训练和扩展定律，可能实现混沌时间序列的长期预测，未来需验证该定律在其他混沌模型中的适用性。

Abstract: Time series forecasting plays a critical role in decision-making processes
across diverse fields including meteorology, traffic, electricity, economics,
finance, and so on. Especially, predicting returns on financial instruments is
a challenging problem. Some researchers have proposed time series foundation
models applicable to various forecasting tasks. Simultaneously, based on the
recognition that real-world time series exhibit chaotic properties, methods
have been developed to artificially generate synthetic chaotic time series,
construct diverse datasets and train models. In this study, we propose a
methodology for modeling financial time series by generating artificial chaotic
time series and applying resampling techniques to simulate financial time
series data, which we then use as training samples. Increasing the resampling
interval to extend predictive horizons, we conducted large-scale pre-training
using 10 billion training samples for each case. We subsequently created test
datasets for multiple timeframes using actual Bitcoin trade data and performed
zero-shot prediction without re-training the pre-trained model. The results of
evaluating the profitability of a simple trading strategy based on these
predictions demonstrated significant performance improvements over
autocorrelation models. During the large-scale pre-training process, we
observed a scaling law-like phenomenon that we can achieve predictive
performance at a certain level with extended predictive horizons for chaotic
time series by increasing the number of training samples exponentially. If this
scaling law proves robust and holds true across various chaotic models, it
suggests the potential to predict near-future events by investing substantial
computational resources. Future research should focus on further large-scale
training and verifying the applicability of this scaling law to diverse chaotic
models.

</details>


### [77] [A transformer-BiGRU-based framework with data augmentation and confident learning for network intrusion detection](https://arxiv.org/abs/2509.04925)
*Jiale Zhang,Pengfei He,Fei Li,Kewei Li,Yan Wang,Lan Huang,Ruochi Zhang,Fengfeng Zhou*

Main category: cs.LG

TL;DR: TrailGate结合机器学习和深度学习技术，通过Transformer和BiGRU架构提升网络入侵检测能力。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习方法难以处理网络入侵数据中的复杂模式和数据稀缺问题。

Method: 结合Transformer和BiGRU架构，采用高级特征选择策略和数据增强技术。

Result: TrailGate能有效检测常见攻击类型，并快速识别新兴威胁。

Conclusion: TrailGate通过算法融合提升了网络入侵检测的准确性和鲁棒性。

Abstract: In today's fast-paced digital communication, the surge in network traffic
data and frequency demands robust and precise network intrusion solutions.
Conventional machine learning methods struggle to grapple with complex patterns
within the vast network intrusion datasets, which suffer from data scarcity and
class imbalance. As a result, we have integrated machine learning and deep
learning techniques within the network intrusion detection system to bridge
this gap. This study has developed TrailGate, a novel framework that combines
machine learning and deep learning techniques. By integrating Transformer and
Bidirectional Gated Recurrent Unit (BiGRU) architectures with advanced feature
selection strategies and supplemented by data augmentation techniques,
TrailGate can identifies common attack types and excels at detecting and
mitigating emerging threats. This algorithmic fusion excels at detecting common
and well-understood attack types and has the unique ability to swiftly identify
and neutralize emerging threats that stem from existing paradigms.

</details>


### [78] [Ontology-Aligned Embeddings for Data-Driven Labour Market Analytics](https://arxiv.org/abs/2509.04942)
*Heinke Hihn,Dennis A. V. Dittrich,Carl Jeske,Cayo Costa Sobral,Helio Pais,Timm Lochmann*

Main category: cs.LG

TL;DR: 提出了一种基于嵌入对齐的方法，将自由形式的德国职位名称与两个现有本体对齐，解决了跨源职业数据推理的瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 解决不同来源职业数据推理能力有限的问题，传统方法依赖人工维护的本体，计算成本高且维护困难。

Method: 使用Sentence-BERT模型微调，构建相似图结构，将分类问题转化为语义搜索问题。

Result: 实现了灵活的职位分类，支持添加更多类别，并讨论了扩展多语言本体的可能性。

Conclusion: 该方法为职业数据推理提供了可扩展的解决方案，减少了人工维护成本，并具有扩展潜力。

Abstract: The limited ability to reason across occupational data from different sources
is a long-standing bottleneck for data-driven labour market analytics. Previous
research has relied on hand-crafted ontologies that allow such reasoning but
are computationally expensive and require careful maintenance by human experts.
The rise of language processing machine learning models offers a scalable
alternative by learning shared semantic spaces that bridge diverse occupational
vocabularies without extensive human curation. We present an embedding-based
alignment process that links any free-form German job title to two established
ontologies - the German Klassifikation der Berufe and the International
Standard Classification of Education. Using publicly available data from the
German Federal Employment Agency, we construct a dataset to fine-tune a
Sentence-BERT model to learn the structure imposed by the ontologies. The
enriched pairs (job title, embedding) define a similarity graph structure that
we can use for efficient approximate nearest-neighbour search, allowing us to
frame the classification process as a semantic search problem. This allows for
greater flexibility, e.g., adding more classes. We discuss design decisions,
open challenges, and outline ongoing work on extending the graph with other
ontologies and multilingual titles.

</details>


### [79] [Detecting Blinks in Healthy and Parkinson's EEG: A Deep Learning Perspective](https://arxiv.org/abs/2509.04951)
*Artem Lensky,Yiding Qiu*

Main category: cs.LG

TL;DR: 论文提出了一种基于深度学习的EEG信号眨眼检测方法，通过多种模型比较，CNN-RNN混合模型表现最佳。


<details>
  <summary>Details</summary>
Motivation: 眨眼在EEG中常被视为噪声，但其频率和变异性是认知负荷和神经疾病的生理标志，因此需要准确的检测方法。

Method: 使用多种深度学习架构（如RNN、CNN、TCN、Transformer等）对EEG信号进行序列到序列分割，训练和测试基于UCSD的公开数据集。

Result: CNN-RNN混合模型在健康组和帕金森患者组中分别达到最高准确率（健康组：95.8%，患者组：75.8%）。

Conclusion: CNN-RNN混合模型在EEG眨眼检测任务中表现最优，可用于计算眨眼率及相关统计。

Abstract: Blinks in electroencephalography (EEG) are often treated as unwanted
artifacts. However, recent studies have demonstrated that blink rate and its
variability are important physiological markers to monitor cognitive load,
attention, and potential neurological disorders. This paper addresses the
critical task of accurate blink detection by evaluating various deep learning
models for segmenting EEG signals into involuntary blinks and non-blinks. We
present a pipeline for blink detection using 1, 3, or 5 frontal EEG electrodes.
The problem is formulated as a sequence-to-sequence task and tested on various
deep learning architectures including standard recurrent neural networks,
convolutional neural networks (both standard and depth-wise), temporal
convolutional networks (TCN), transformer-based models, and hybrid
architectures. The models were trained on raw EEG signals with minimal
pre-processing. Training and testing was carried out on a public dataset of 31
subjects collected at UCSD. This dataset consisted of 15 healthy participants
and 16 patients with Parkinson's disease allowing us to verify the model's
robustness to tremor. Out of all models, CNN-RNN hybrid model consistently
outperformed other models and achieved the best blink detection accuracy of
93.8%, 95.4% and 95.8% with 1, 3, and 5 channels in the healthy cohort and
correspondingly 73.8%, 75.4% and 75.8% in patients with PD. The paper compares
neural networks for the task of segmenting EEG recordings to involuntary blinks
and no blinks allowing for computing blink rate and other statistics.

</details>


### [80] [On the Normalization of Confusion Matrices: Methods and Geometric Interpretations](https://arxiv.org/abs/2509.04959)
*Johan Erbani,Pierre-Edouard Portier,Elod Egyed-Zsigmond,Sonia Ben Mokhtar,Diana Nurbakova*

Main category: cs.LG

TL;DR: 论文提出了一种双随机归一化方法，通过迭代比例拟合分离混淆矩阵中的类别相似性和分布偏差，从而更准确地诊断模型行为。


<details>
  <summary>Details</summary>
Motivation: 混淆矩阵在评估分类器时受类别相似性和分布偏差的共同影响，难以区分两者的贡献，因此需要一种方法分离这两种因素。

Method: 采用双随机归一化方法，通过迭代比例拟合（IPF）技术，对混淆矩阵进行归一化处理，以恢复类别相似性的潜在结构。

Result: 该方法能够有效分离混淆矩阵中的误差来源，支持更精准的模型行为诊断，并揭示了归一化与模型内部类别表示之间的对应关系。

Conclusion: 双随机归一化方法为分类器评估提供了更深入的理解，支持更有针对性的模型改进。

Abstract: The confusion matrix is a standard tool for evaluating classifiers by
providing insights into class-level errors. In heterogeneous settings, its
values are shaped by two main factors: class similarity -- how easily the model
confuses two classes -- and distribution bias, arising from skewed
distributions in the training and test sets. However, confusion matrix values
reflect a mix of both factors, making it difficult to disentangle their
individual contributions. To address this, we introduce bistochastic
normalization using Iterative Proportional Fitting, a generalization of row and
column normalization. Unlike standard normalizations, this method recovers the
underlying structure of class similarity. By disentangling error sources, it
enables more accurate diagnosis of model behavior and supports more targeted
improvements. We also show a correspondence between confusion matrix
normalizations and the model's internal class representations. Both standard
and bistochastic normalizations can be interpreted geometrically in this space,
offering a deeper understanding of what normalization reveals about a
classifier.

</details>


### [81] [Neuro-Spectral Architectures for Causal Physics-Informed Networks](https://arxiv.org/abs/2509.04966)
*Arthur Bizzi,Leonardo M. Moreira,Márcio Marques,Leonardo Mendonça,Christian Júnior de Oliveira,Vitor Balestro,Lucas dos Santos Fernandez,Daniel Yukimura,Pavel Petrov,João M. Pereira,Tiago Novello,Lucas Nissenbaum*

Main category: cs.LG

TL;DR: NeuSA是一种新型的PINNs架构，通过结合谱方法和NODE解决传统PINNs在复杂初值问题中的收敛问题，提高了高频成分的捕捉能力和因果性。


<details>
  <summary>Details</summary>
Motivation: 传统MLP-based PINNs在处理复杂初值问题时存在收敛困难、违反因果性和低频偏置的问题，NeuSA旨在解决这些问题。

Method: NeuSA将PDE投影到谱基上，形成有限维动态表示，并与NODE结合，利用谱方法的高频捕捉能力和NODE的因果结构。

Result: 在线性和非线性波动方程的基准测试中，NeuSA表现出更快的收敛速度、更好的时间一致性和更高的预测精度。

Conclusion: NeuSA通过谱方法和NODE的结合，显著提升了PINNs的性能，适用于复杂PDE求解。

Abstract: Physics-Informed Neural Networks (PINNs) have emerged as a powerful neural
framework for solving partial differential equations (PDEs). However, standard
MLP-based PINNs often fail to converge when dealing with complex initial-value
problems, leading to solutions that violate causality and suffer from a
spectral bias towards low-frequency components. To address these issues, we
introduce NeuSA (Neuro-Spectral Architectures), a novel class of PINNs inspired
by classical spectral methods, designed to solve linear and nonlinear PDEs with
variable coefficients. NeuSA learns a projection of the underlying PDE onto a
spectral basis, leading to a finite-dimensional representation of the dynamics
which is then integrated with an adapted Neural ODE (NODE). This allows us to
overcome spectral bias, by leveraging the high-frequency components enabled by
the spectral representation; to enforce causality, by inheriting the causal
structure of NODEs, and to start training near the target solution, by means of
an initialization scheme based on classical methods. We validate NeuSA on
canonical benchmarks for linear and nonlinear wave equations, demonstrating
strong performance as compared to other architectures, with faster convergence,
improved temporal consistency and superior predictive accuracy. Code and
pretrained models will be released.

</details>


### [82] [Topology-Aware Graph Reinforcement Learning for Dynamic Routing in Cloud Networks](https://arxiv.org/abs/2509.04973)
*Yuxi Wang,Heyao Liu,Guanzi Yao,Nyutian Long,Yue Kang*

Main category: cs.LG

TL;DR: 提出了一种基于拓扑感知的图强化学习方法，用于优化云服务器环境中的路由策略，通过SASE和PAGU模块解决动态拓扑下的决策不稳定和结构感知不足问题。


<details>
  <summary>Details</summary>
Motivation: 解决动态拓扑环境中路由策略优化的挑战，特别是决策不稳定和结构感知不足的问题。

Method: 结合SASE模块（多层图卷积和结构位置嵌入）和PAGU模块（基于策略行为调整图结构），构建统一的状态表示和结构演化框架。

Result: 在GEANT拓扑数据集上实验表明，该方法在吞吐量、延迟控制和链路平衡等方面优于现有图强化学习模型。

Conclusion: 该方法在动态复杂云网络中实现了高效且稳健的路由优化。

Abstract: This paper proposes a topology-aware graph reinforcement learning approach to
address the routing policy optimization problem in cloud server environments.
The method builds a unified framework for state representation and structural
evolution by integrating a Structure-Aware State Encoding (SASE) module and a
Policy-Adaptive Graph Update (PAGU) mechanism. It aims to tackle the challenges
of decision instability and insufficient structural awareness under dynamic
topologies. The SASE module models node states through multi-layer graph
convolution and structural positional embeddings, capturing high-order
dependencies in the communication topology and enhancing the expressiveness of
state representations. The PAGU module adjusts the graph structure based on
policy behavior shifts and reward feedback, enabling adaptive structural
updates in dynamic environments. Experiments are conducted on the real-world
GEANT topology dataset, where the model is systematically evaluated against
several representative baselines in terms of throughput, latency control, and
link balance. Additional experiments, including hyperparameter sensitivity,
graph sparsity perturbation, and node feature dimensionality variation, further
explore the impact of structure modeling and graph updates on model stability
and decision quality. Results show that the proposed method outperforms
existing graph reinforcement learning models across multiple performance
metrics, achieving efficient and robust routing in dynamic and complex cloud
networks.

</details>


### [83] [Adapt in the Wild: Test-Time Entropy Minimization with Sharpness and Feature Regularization](https://arxiv.org/abs/2509.04977)
*Shuaicheng Niu,Guohao Chen,Deyu Chen,Yifan Zhang,Jiaxiang Wu,Zhiquan Wen,Yaofo Chen,Peilin Zhao,Chunyan Miao,Mingkui Tan*

Main category: cs.LG

TL;DR: SAR和SAR^2方法通过去除噪声样本和平滑权重优化，解决了测试时适应（TTA）中的不稳定问题。


<details>
  <summary>Details</summary>
Motivation: 现有TTA方法在混合分布偏移、小批量数据或在线不平衡标签分布时表现不佳，主要原因是批量归一化层的不稳定性。

Method: 提出SAR方法，通过梯度筛选和平滑权重优化稳定TTA；SAR^2进一步引入冗余和公平性正则化防止表示崩溃。

Result: 实验表明，SAR和SAR^2在复杂测试场景下表现稳定且高效。

Conclusion: SAR和SAR^2显著提升了TTA的稳定性，适用于实际部署。

Abstract: Test-time adaptation (TTA) may fail to improve or even harm the model
performance when test data have: 1) mixed distribution shifts, 2) small batch
sizes, 3) online imbalanced label distribution shifts. This is often a key
obstacle preventing existing TTA methods from being deployed in the real world.
In this paper, we investigate the unstable reasons and find that the batch norm
layer is a crucial factor hindering TTA stability. Conversely, TTA can perform
more stably with batch-agnostic norm layers, i.e., group or layer norm.
However, we observe that TTA with group and layer norms does not always succeed
and still suffers many failure cases, i.e., the model collapses into trivial
solutions by assigning the same class label for all samples. By digging into
this, we find that, during the collapse process: 1) the model gradients often
undergo an initial explosion followed by rapid degradation, suggesting that
certain noisy test samples with large gradients may disrupt adaptation; and 2)
the model representations tend to exhibit high correlations and classification
bias. To address this, we first propose a sharpness-aware and reliable entropy
minimization method, called SAR, for stabilizing TTA from two aspects: 1)
remove partial noisy samples with large gradients, 2) encourage model weights
to go to a flat minimum so that the model is robust to the remaining noisy
samples. Based on SAR, we further introduce SAR^2 to prevent representation
collapse with two regularizers: 1) a redundancy regularizer to reduce
inter-dimensional correlations among centroid-invariant features; and 2) an
inequity regularizer to maximize the prediction entropy of a prototype
centroid, thereby penalizing biased representations toward any specific class.
Promising results demonstrate that our methods perform more stably over prior
methods and are computationally efficient under the above wild test scenarios.

</details>


### [84] [Directed Evolution of Proteins via Bayesian Optimization in Embedding Space](https://arxiv.org/abs/2509.04998)
*Matouš Soldát,Jiří Kléma*

Main category: cs.LG

TL;DR: 提出了一种结合贝叶斯优化和预训练蛋白质语言模型的新方法，用于机器学习辅助的定向进化，显著提高了性能。


<details>
  <summary>Details</summary>
Motivation: 定向进化过程中，生化筛选成本高且耗时，机器学习方法可以优化筛选过程。

Method: 结合贝叶斯优化和预训练蛋白质语言模型的序列嵌入表示。

Result: 新方法显著提升了贝叶斯优化的性能，并在相同筛选次数下取得更好结果。

Conclusion: 该方法在机器学习辅助定向进化中优于现有回归目标方法。

Abstract: Directed evolution is an iterative laboratory process of designing proteins
with improved function by iteratively synthesizing new protein variants and
evaluating their desired property with expensive and time-consuming biochemical
screening. Machine learning methods can help select informative or promising
variants for screening to increase their quality and reduce the amount of
necessary screening. In this paper, we present a novel method for
machine-learning-assisted directed evolution of proteins which combines
Bayesian optimization with informative representation of protein variants
extracted from a pre-trained protein language model. We demonstrate that the
new representation based on the sequence embeddings significantly improves the
performance of Bayesian optimization yielding better results with the same
number of conducted screening in total. At the same time, our method
outperforms the state-of-the-art machine-learning-assisted directed evolution
methods with regression objective.

</details>


### [85] [Depth-Aware Initialization for Stable and Efficient Neural Network Training](https://arxiv.org/abs/2509.05018)
*Vijay Pandey*

Main category: cs.LG

TL;DR: 本文提出了一种新的神经网络初始化方法，结合了每层深度和网络总深度信息，通过灵活增加方差来提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有初始化方法在深层网络中保持单位方差的假设效果不佳，需要从第一层到最后一层逐步增加方差。

Method: 提出了一种结合每层深度信息的新方法，灵活调整网络方差。

Result: 实验表明，该方法优于现有初始化方案。

Conclusion: 结合深度信息的灵活方差调整方法能有效提升深层网络的初始化效果。

Abstract: In past few years, various initialization schemes have been proposed. These
schemes are glorot initialization, He initialization, initialization using
orthogonal matrix, random walk method for initialization. Some of these methods
stress on keeping unit variance of activation and gradient propagation through
the network layer. Few of these methods are independent of the depth
information while some methods has considered the total network depth for
better initialization. In this paper, comprehensive study has been done where
depth information of each layer as well as total network is incorporated for
better initialization scheme. It has also been studied that for deeper networks
theoretical assumption of unit variance throughout the network does not perform
well. It requires the need to increase the variance of the network from first
layer activation to last layer activation. We proposed a novel way to increase
the variance of the network in flexible manner, which incorporates the
information of each layer depth. Experiments shows that proposed method
performs better than the existing initialization scheme.

</details>


### [86] [MultiSurv: A Multimodal Deep Survival Framework for Prostrate and Bladder Cancer](https://arxiv.org/abs/2509.05037)
*Noorul Wahab,Ethar Alzaid,Jiaqi Lv,Adam Shephard,Shan E Ahmed Raza*

Main category: cs.LG

TL;DR: MultiSurv是一种多模态深度生存模型，用于预测前列腺癌和膀胱癌的复发时间，在CHIMERA挑战中表现出色。


<details>
  <summary>Details</summary>
Motivation: 准确预测癌症复发时间对治疗规划和患者管理至关重要。

Method: 采用DeepHit结合投影层和跨模态注意力机制，整合临床、MRI、RNA-seq和病理数据。

Result: 在前列腺癌任务中C-index为0.843（交叉验证）和0.818（开发集），膀胱癌任务中为0.662和0.457。

Conclusion: 多模态深度生存模型为个性化风险分层提供了新途径，适用于多种生物医学数据。

Abstract: Accurate prediction of time-to-event outcomes is a central challenge in
oncology, with significant implications for treatment planning and patient
management. In this work, we present MultiSurv, a multimodal deep survival
model utilising DeepHit with a projection layer and inter-modality
cross-attention, which integrates heterogeneous patient data, including
clinical, MRI, RNA-seq and whole-slide pathology features. The model is
designed to capture complementary prognostic signals across modalities and
estimate individualised time-to-biochemical recurrence in prostate cancer and
time-to-cancer recurrence in bladder cancer. Our approach was evaluated in the
context of the CHIMERA Grand Challenge, across two of the three provided tasks.
For Task 1 (prostate cancer bio-chemical recurrence prediction), the proposed
framework achieved a concordance index (C-index) of 0.843 on 5-folds
cross-validation and 0.818 on CHIMERA development set, demonstrating robust
discriminatory ability. For Task 3 (bladder cancer recurrence prediction), the
model obtained a C-index of 0.662 on 5-folds cross-validation and 0.457 on
development set, highlighting its adaptability and potential for clinical
translation. These results suggest that leveraging multimodal integration with
deep survival learning provides a promising pathway toward personalised risk
stratification in prostate and bladder cancer. Beyond the challenge setting,
our framework is broadly applicable to survival prediction tasks involving
heterogeneous biomedical data.

</details>


### [87] [Recurrent State Encoders for Efficient Neural Combinatorial Optimization](https://arxiv.org/abs/2509.05084)
*Tim Dernedde,Daniela Thyssens,Lars Schmidt-Thieme*

Main category: cs.LG

TL;DR: 论文提出了一种基于循环编码器的神经组合优化方法，通过重用先前步骤的计算来提升效率，并在多个问题上验证了其性能。


<details>
  <summary>Details</summary>
Motivation: 现有神经组合优化方法中，状态变化通常较小，但计算未被有效重用，导致效率低下。

Method: 训练循环编码器，利用前一步的嵌入信息计算当前状态嵌入，减少网络层数。

Result: 循环编码器在减少3倍层数的情况下，性能与或优于非循环编码器，显著降低延迟。

Conclusion: 循环编码器在神经组合优化中具有高效性和实用性，适用于多种问题。

Abstract: The primary paradigm in Neural Combinatorial Optimization (NCO) are
construction methods, where a neural network is trained to sequentially add one
solution component at a time until a complete solution is constructed. We
observe that the typical changes to the state between two steps are small,
since usually only the node that gets added to the solution is removed from the
state. An efficient model should be able to reuse computation done in prior
steps. To that end, we propose to train a recurrent encoder that computes the
state embeddings not only based on the state but also the embeddings of the
step before. We show that the recurrent encoder can achieve equivalent or
better performance than a non-recurrent encoder even if it consists of
$3\times$ fewer layers, thus significantly improving on latency. We demonstrate
our findings on three different problems: the Traveling Salesman Problem (TSP),
the Capacitated Vehicle Routing Problem (CVRP), and the Orienteering Problem
(OP) and integrate the models into a large neighborhood search algorithm, to
showcase the practical relevance of our findings.

</details>


### [88] [HyPINO: Multi-Physics Neural Operators via HyperPINNs and the Method of Manufactured Solutions](https://arxiv.org/abs/2509.05117)
*Rafael Bischof,Michal Piovarči,Michael A. Kraus,Siddhartha Mishra,Bernd Bickel*

Main category: cs.LG

TL;DR: HyPINO是一种多物理神经算子，能够在无需任务特定微调的情况下，对广泛的参数化PDE进行零样本泛化。它结合了Swin Transformer超网络和混合监督，表现优于现有方法，并通过迭代细化进一步提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决参数化PDE的零样本泛化问题，避免任务特定微调的需求，同时提升计算效率和准确性。

Method: 使用Swin Transformer超网络结合混合监督（MMS生成的数据和物理信息目标的无标签样本），并引入迭代细化过程生成PINN集合。

Result: 在七个基准测试中表现优于U-Nets、Poseidon和PINO，迭代细化后误差显著降低，且初始化PINN时收敛更快。

Conclusion: HyPINO为扩展神经算子解决复杂、非线性和高维PDE问题提供了可扩展的基础，显著提升了准确性和计算效率。

Abstract: We present HyPINO, a multi-physics neural operator designed for zero-shot
generalization across a broad class of parametric PDEs without requiring
task-specific fine-tuning. Our approach combines a Swin Transformer-based
hypernetwork with mixed supervision: (i) labeled data from analytical solutions
generated via the Method of Manufactured Solutions (MMS), and (ii) unlabeled
samples optimized using physics-informed objectives. The model maps PDE
parametrizations to target Physics-Informed Neural Networks (PINNs) and can
handle linear elliptic, hyperbolic, and parabolic equations in two dimensions
with varying source terms, geometries, and mixed Dirichlet/Neumann boundary
conditions, including interior boundaries. HyPINO achieves strong zero-shot
accuracy on seven benchmark problems from PINN literature, outperforming
U-Nets, Poseidon, and Physics-Informed Neural Operators (PINO). Further, we
introduce an iterative refinement procedure that compares the physics of the
generated PINN to the requested PDE and uses the discrepancy to generate a
"delta" PINN. Summing their contributions and repeating this process forms an
ensemble whose combined solution progressively reduces the error on six
benchmarks and achieves over 100x gain in average $L_2$ loss in the best case,
while retaining forward-only inference. Additionally, we evaluate the
fine-tuning behavior of PINNs initialized by HyPINO and show that they converge
faster and to lower final error than both randomly initialized and
Reptile-meta-learned PINNs on five benchmarks, performing on par on the
remaining two. Our results highlight the potential of this scalable approach as
a foundation for extending neural operators toward solving increasingly
complex, nonlinear, and high-dimensional PDE problems with significantly
improved accuracy and reduced computational cost.

</details>


### [89] [Should We Always Train Models on Fine-Grained Classes?](https://arxiv.org/abs/2509.05130)
*Davide Pirovano,Federico Milanesio,Michele Caselle,Piero Fariselli,Matteo Osella*

Main category: cs.LG

TL;DR: 研究探讨了在分类问题中使用细粒度标签训练模型的普遍性和效果，发现其效果取决于数据几何结构和标签层次关系。


<details>
  <summary>Details</summary>
Motivation: 探索细粒度标签训练是否普遍提升分类性能，并分析其背后的原因。

Method: 使用真实和合成数据集，分析数据几何结构、标签层次关系、数据集大小和模型容量对细粒度训练效果的影响。

Result: 细粒度标签训练并非普遍有效，其效果取决于数据结构和标签层次关系，且受数据集大小和模型容量影响。

Conclusion: 细粒度标签训练的效果具有条件性，需结合数据结构和任务需求选择是否使用。

Abstract: In classification problems, models must predict a class label based on the
input data features. However, class labels are organized hierarchically in many
datasets. While a classification task is often defined at a specific level of
this hierarchy, training can utilize a finer granularity of labels. Empirical
evidence suggests that such fine-grained training can enhance performance. In
this work, we investigate the generality of this observation and explore its
underlying causes using both real and synthetic datasets. We show that training
on fine-grained labels does not universally improve classification accuracy.
Instead, the effectiveness of this strategy depends critically on the geometric
structure of the data and its relations with the label hierarchy. Additionally,
factors such as dataset size and model capacity significantly influence whether
fine-grained labels provide a performance benefit.

</details>


### [90] [On the Learnability of Distribution Classes with Adaptive Adversaries](https://arxiv.org/abs/2509.05137)
*Tosca Lechner,Alex Bie,Gautam Kamath*

Main category: cs.LG

TL;DR: 论文研究了在自适应对手存在下的分布类可学习性问题，表明其比非自适应对手下的可学习性更强。


<details>
  <summary>Details</summary>
Motivation: 探讨自适应对手（能拦截并修改样本）与非自适应对手（仅能修改底层分布）对学习能力的影响差异。

Method: 提出了一种针对自适应对手的可学习性通用定义，并考虑了对手的预算限制。

Result: 证明了在加性自适应对手下的可学习性比加性非自适应对手下的可学习性条件更严格。

Conclusion: 自适应对手的存在显著增加了学习任务的难度，需要更强的学习条件。

Abstract: We consider the question of learnability of distribution classes in the
presence of adaptive adversaries -- that is, adversaries capable of
intercepting the samples requested by a learner and applying manipulations with
full knowledge of the samples before passing it on to the learner. This stands
in contrast to oblivious adversaries, who can only modify the underlying
distribution the samples come from but not their i.i.d.\ nature. We formulate a
general notion of learnability with respect to adaptive adversaries, taking
into account the budget of the adversary. We show that learnability with
respect to additive adaptive adversaries is a strictly stronger condition than
learnability with respect to additive oblivious adversaries.

</details>


### [91] [Foundational Models and Federated Learning: Survey, Taxonomy, Challenges and Practical Insights](https://arxiv.org/abs/2509.05142)
*Cosmin-Andrei Hatfaludi,Alex Serban*

Main category: cs.LG

TL;DR: 该论文探讨了联邦学习与基础模型的结合，提出了一个分类法，并比较了不同方法的复杂性、效率和可扩展性，特别关注了医疗领域的应用。


<details>
  <summary>Details</summary>
Motivation: 随着基础模型的广泛应用，需要整合私有数据和扩展训练资源，联邦学习提供了不共享私有数据的协作训练方式。

Method: 通过文献调查，构建了一个基于开发生命周期阶段的分类法，并比较了42种方法。

Result: 筛选了4200多篇文章，最终详细审查了250篇，构建了分类法并比较了方法的复杂性、效率和可扩展性。

Conclusion: 论文不仅总结了该领域的现状，还提供了实际应用中的见解，特别是在医疗领域的潜在影响。

Abstract: Federated learning has the potential to unlock siloed data and distributed
resources by enabling collaborative model training without sharing private
data. As more complex foundational models gain widespread use, the need to
expand training resources and integrate privately owned data grows as well. In
this article, we explore the intersection of federated learning and
foundational models, aiming to identify, categorize, and characterize technical
methods that integrate the two paradigms. As a unified survey is currently
unavailable, we present a literature survey structured around a novel taxonomy
that follows the development life-cycle stages, along with a technical
comparison of available methods. Additionally, we provide practical insights
and guidelines for implementing and evolving these methods, with a specific
focus on the healthcare domain as a case study, where the potential impact of
federated learning and foundational models is considered significant. Our
survey covers multiple intersecting topics, including but not limited to
federated learning, self-supervised learning, fine-tuning, distillation, and
transfer learning. Initially, we retrieved and reviewed a set of over 4,200
articles. This collection was narrowed to more than 250 thoroughly reviewed
articles through inclusion criteria, featuring 42 unique methods. The methods
were used to construct the taxonomy and enabled their comparison based on
complexity, efficiency, and scalability. We present these results as a
self-contained overview that not only summarizes the state of the field but
also provides insights into the practical aspects of adopting, evolving, and
integrating foundational models with federated learning.

</details>


### [92] [KVCompose: Efficient Structured KV Cache Compression with Composite Tokens](https://arxiv.org/abs/2509.05165)
*Dmitry Akulov,Mohamed Sana,Antonio De Domenico,Tareq Si Salem,Nicola Piovesan,Fadhel Ayed*

Main category: cs.LG

TL;DR: 提出了一种基于注意力引导的KV缓存压缩框架，显著减少内存占用，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: KV缓存大小随上下文长度和模型深度线性增长，成为长上下文推理的主要瓶颈。现有方法存在局限性。

Method: 通过注意力分数聚合估计token重要性，选择特定token并组合为复合token，同时全局分配机制调整各层保留预算。

Result: 显著减少内存占用，优于现有结构化与半结构化方法，且兼容标准推理流程。

Conclusion: 该方法为高效长上下文LLM部署提供了实用且可扩展的解决方案。

Abstract: Large language models (LLMs) rely on key-value (KV) caches for efficient
autoregressive decoding; however, cache size grows linearly with context length
and model depth, becoming a major bottleneck in long-context inference. Prior
KV cache compression methods either enforce rigid heuristics, disrupt tensor
layouts with per-attention-head variability, or require specialized compute
kernels.
  We propose a simple, yet effective, KV cache compression framework based on
attention-guided, layer-adaptive composite tokens. Our method aggregates
attention scores to estimate token importance, selects head-specific tokens
independently, and aligns them into composite tokens that respect the uniform
cache structure required by existing inference engines. A global allocation
mechanism further adapts retention budgets across layers, assigning more
capacity to layers with informative tokens. This approach achieves significant
memory reduction while preserving accuracy, consistently outperforming prior
structured and semi-structured methods. Crucially, our approach remains fully
compatible with standard inference pipelines, offering a practical and scalable
solution for efficient long-context LLM deployment.

</details>


### [93] [Accuracy-Constrained CNN Pruning for Efficient and Reliable EEG-Based Seizure Detection](https://arxiv.org/abs/2509.05190)
*Mounvik K,N Harshit*

Main category: cs.LG

TL;DR: 提出了一种轻量级的一维CNN模型，通过结构化剪枝提高效率和可靠性，适用于资源受限的EEG癫痫检测。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习模型在实时检测或资源受限环境中的计算和存储挑战。

Method: 采用结构化剪枝去除50%的卷积核，并结合温和的早停策略防止过拟合。

Result: 剪枝后模型在保持预测能力的同时，准确率提升至92.87%，宏F1分数提高至0.8707。

Conclusion: 结构化剪枝结合早停策略能有效去除冗余、提升泛化能力，适用于资源受限的癫痫检测场景。

Abstract: Deep learning models, especially convolutional neural networks (CNNs), have
shown considerable promise for biomedical signals such as EEG-based seizure
detection. However, these models come with challenges, primarily due to their
size and compute requirements in environments where real-time detection or
limited resources are available. In this study, we present a lightweight
one-dimensional CNN model with structured pruning to improve efficiency and
reliability. The model was trained with mild early stopping to address possible
overfitting, achieving an accuracy of 92.78% and a macro-F1 score of 0.8686.
Structured pruning of the baseline CNN involved removing 50% of the
convolutional kernels based on their importance to model predictions.
Surprisingly, after pruning the weights and memory by 50%, the new network was
still able to maintain predictive capabilities, while modestly increasing
precision to 92.87% and improving the macro-F1 score to 0.8707. Overall, we
present a convincing case that structured pruning removes redundancy, improves
generalization, and, in combination with mild early stopping, achieves a
promising way forward to improve seizure detection efficiency and reliability,
which is clear motivation for resource-limited settings.

</details>


### [94] [Shift Before You Learn: Enabling Low-Rank Representations in Reinforcement Learning](https://arxiv.org/abs/2509.05193)
*Bastien Dubail,Stefan Stojanovic,Alexandre Proutière*

Main category: cs.LG

TL;DR: 论文挑战了强化学习中低秩结构的假设，提出移位后继测度具有低秩性，并提供了有限样本性能保证。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习算法假设后继测度具有低秩结构，但作者发现其本身并非低秩，移位后的测度才具备这一特性。

Method: 通过分析移位后继测度的低秩性，提出基于样本的估计方法，并引入Type II Poincaré不等式量化移位需求。

Result: 实验验证移位后继测度能提升目标条件强化学习的性能。

Conclusion: 移位操作能有效揭示低秩结构，且所需移位量通常较小，为强化学习算法设计提供了新思路。

Abstract: Low-rank structure is a common implicit assumption in many modern
reinforcement learning (RL) algorithms. For instance, reward-free and
goal-conditioned RL methods often presume that the successor measure admits a
low-rank representation. In this work, we challenge this assumption by first
remarking that the successor measure itself is not low-rank. Instead, we
demonstrate that a low-rank structure naturally emerges in the shifted
successor measure, which captures the system dynamics after bypassing a few
initial transitions. We provide finite-sample performance guarantees for the
entry-wise estimation of a low-rank approximation of the shifted successor
measure from sampled entries. Our analysis reveals that both the approximation
and estimation errors are primarily governed by the so-called spectral
recoverability of the corresponding matrix. To bound this parameter, we derive
a new class of functional inequalities for Markov chains that we call Type II
Poincar\'e inequalities and from which we can quantify the amount of shift
needed for effective low-rank approximation and estimation. This analysis shows
in particular that the required shift depends on decay of the high-order
singular values of the shifted successor measure and is hence typically small
in practice. Additionally, we establish a connection between the necessary
shift and the local mixing properties of the underlying dynamical system, which
provides a natural way of selecting the shift. Finally, we validate our
theoretical findings with experiments, and demonstrate that shifting the
successor measure indeed leads to improved performance in goal-conditioned RL.

</details>


### [95] [RapidGNN: Energy and Communication-Efficient Distributed Training on Large-Scale Graph Neural Networks](https://arxiv.org/abs/2509.05207)
*Arefin Niam,Tevfik Kosar,M S Q Zulkar Nine*

Main category: cs.LG

TL;DR: RapidGNN是一个分布式GNN训练框架，通过确定性采样调度提高训练效率和能源效率。


<details>
  <summary>Details</summary>
Motivation: 大规模图数据上分布式训练GNN存在计算和通信开销的挑战，传统采样方法无法有效解决。

Method: 提出RapidGNN框架，采用确定性采样调度，优化缓存构建和远程特征预取。

Result: 在基准数据集上，RapidGNN平均训练吞吐量提升2.46x-3.00x，远程特征获取减少9.70x-15.39x，并展示近线性扩展性。

Conclusion: RapidGNN显著提升了分布式GNN训练的效率和能源效率，适用于不同规模和拓扑的图数据。

Abstract: Graph Neural Networks (GNNs) have become popular across a diverse set of
tasks in exploring structural relationships between entities. However, due to
the highly connected structure of the datasets, distributed training of GNNs on
large-scale graphs poses significant challenges. Traditional sampling-based
approaches mitigate the computational loads, yet the communication overhead
remains a challenge. This paper presents RapidGNN, a distributed GNN training
framework with deterministic sampling-based scheduling to enable efficient
cache construction and prefetching of remote features. Evaluation on benchmark
graph datasets demonstrates RapidGNN's effectiveness across different scales
and topologies. RapidGNN improves end-to-end training throughput by 2.46x to
3.00x on average over baseline methods across the benchmark datasets, while
cutting remote feature fetches by over 9.70x to 15.39x. RapidGNN further
demonstrates near-linear scalability with an increasing number of computing
units efficiently. Furthermore, it achieves increased energy efficiency over
the baseline methods for both CPU and GPU by 44% and 32%, respectively.

</details>


### [96] [An Efficient Subspace Algorithm for Federated Learning on Heterogeneous Data](https://arxiv.org/abs/2509.05213)
*Jiaojiao Zhang,Yuqi Xu,Kun Yuan*

Main category: cs.LG

TL;DR: FedSub是一种高效的子空间算法，用于解决联邦学习中数据异构性和高成本问题。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习在大规模深度神经网络中因数据异构性导致的客户端漂移和高通信、计算、内存成本问题。

Method: 利用子空间投影确保客户端在低维子空间内更新，减少成本，并通过低维对偶变量缓解客户端漂移。

Result: 提供了收敛分析，实验结果表明其高效性。

Conclusion: FedSub通过子空间投影和对偶变量有效解决了联邦学习中的关键挑战。

Abstract: This work addresses the key challenges of applying federated learning to
large-scale deep neural networks, particularly the issue of client drift due to
data heterogeneity across clients and the high costs of communication,
computation, and memory. We propose FedSub, an efficient subspace algorithm for
federated learning on heterogeneous data. Specifically, FedSub utilizes
subspace projection to guarantee local updates of each client within
low-dimensional subspaces, thereby reducing communication, computation, and
memory costs. Additionally, it incorporates low-dimensional dual variables to
mitigate client drift. We provide convergence analysis that reveals the impact
of key factors such as step size and subspace projection matrices on
convergence. Experimental results demonstrate its efficiency.

</details>


### [97] [Deep Learning-Enhanced for Amine Emission Monitoring and Performance Analysis in Industrial Carbon Capture Plants](https://arxiv.org/abs/2509.05241)
*Lokendra Poudel,David Tincher,Duy-Nhat Phan,Rahul Bhowmik*

Main category: cs.LG

TL;DR: 本文提出了一种基于数据驱动的深度学习模型，用于预测和监测胺基碳捕集系统中的胺排放和关键性能参数，模型预测准确率超过99%，并揭示了操作参数对排放和性能的影响。


<details>
  <summary>Details</summary>
Motivation: 通过深度学习模型优化胺基碳捕集系统的操作，减少胺排放并提升系统性能，实现环境友好和高效运行。

Method: 使用四种DL架构（Basic LSTM、Stacked LSTM、Bi-directional LSTM和Convolutional LSTM）分析时间依赖性过程行为，并进行因果影响分析。

Result: 模型预测准确率超过99%，发现调整特定操作参数（如贫溶剂温度和水洗条件）可显著减少胺排放并提升性能。

Conclusion: 该研究展示了机器学习在碳捕集系统中的预测和决策支持潜力，为实现高效、稳定和可持续的碳捕集技术提供了实用路径。

Abstract: We present data driven deep learning models for forecasting and monitoring
amine emissions and key performance parameters in amine-based post-combustion
carbon capture systems. Using operational data from the CESAR1 solvent campaign
at Technology Center Mongstad, four DL architectures such as Basic Long
Short-Term Memory (LSTM), Stacked LSTM, Bi-directional LSTM, and Convolutional
LSTM were developed to capture time-dependent process behavior. For emission
prediction, models were designed for 2-amino-2-methyl-1-propanol (AMP) and
Piperazine emissions measured via FTIR and IMR-MS methods. System performance
models target four critical parameters: CO$_2$ product flow, absorber outlet
temperature, depleted flue gas outlet temperature, and RFCC stripper bottom
temperature. These models achieved high predictive accuracy exceeding 99% and
effectively tracked both steady trends and abrupt fluctuations. Additionally,
we conducted causal impact analysis to evaluate how operational variables
influence emissions and system performance. Eight input variables were
systematically perturbed within $\pm$20% of nominal values to simulate
deviations and assess their impact. This analysis revealed that adjusting
specific operational parameters, such as lean solvent temperature and water
wash conditions, can significantly reduce amine emissions and enhance system
performance. This study highlights ML not only as a predictive tool but also as
a decision support system for optimizing carbon capture operations under steady
state and dynamic conditions. By enabling real time monitoring, scenario
testing, and operational optimization, the developed ML framework offers a
practical pathway for mitigating environmental impacts. This work represents a
step toward intelligent, data-driven control strategies that enhance the
efficiency, stability, and sustainability of carbon capture and storage
technologies.

</details>


### [98] [A Kolmogorov-Arnold Network for Interpretable Cyberattack Detection in AGC Systems](https://arxiv.org/abs/2509.05259)
*Jehad Jilan,Niranjana Naveen Nambiar,Ahmad Mohammad Saber,Alok Paranjape,Amr Youssef,Deepa Kundur*

Main category: cs.LG

TL;DR: 提出了一种基于Kolmogorov-Arnold Networks (KAN)的可解释性方法，用于检测电力系统AGC中的虚假数据注入攻击（FDIAs），检测率高达95.97%。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以检测FDIAs，且缺乏可解释性。KAN能处理非线性系统并提供符号化公式，增强检测的透明度和准确性。

Method: 使用KAN模型离线学习AGC测量数据间的非线性关系，并提取符号化公式以提高可解释性。

Result: KAN模型和符号化公式的FDIA检测率分别为95.97%和95.9%，且误报率低。

Conclusion: KAN为AGC系统提供了一种可靠且可解释的网络安全增强方法。

Abstract: Automatic Generation Control (AGC) is essential for power grid stability but
remains vulnerable to stealthy cyberattacks, such as False Data Injection
Attacks (FDIAs), which can disturb the system's stability while evading
traditional detection methods. Unlike previous works that relied on blackbox
approaches, this work proposes Kolmogorov-Arnold Networks (KAN) as an
interpretable and accurate method for FDIA detection in AGC systems,
considering the system nonlinearities. KAN models include a method for
extracting symbolic equations, and are thus able to provide more
interpretability than the majority of machine learning models. The proposed KAN
is trained offline to learn the complex nonlinear relationships between the AGC
measurements under different operating scenarios. After training, symbolic
formulas that describe the trained model's behavior can be extracted and
leveraged, greatly enhancing interpretability. Our findings confirm that the
proposed KAN model achieves FDIA detection rates of up to 95.97% and 95.9% for
the initial model and the symbolic formula, respectively, with a low false
alarm rate, offering a reliable approach to enhancing AGC cybersecurity.

</details>


### [99] [Greener Deep Reinforcement Learning: Analysis of Energy and Carbon Efficiency Across Atari Benchmarks](https://arxiv.org/abs/2509.05273)
*Jason Gardner,Ayan Dutta,Swapnoneel Roy,O. Patrick Kreidl,Ladislau Boloni*

Main category: cs.LG

TL;DR: 论文系统评估了七种DRL算法的能源消耗、碳排放和成本，揭示了算法间的显著差异，并提出了在不牺牲性能的情况下减少环境影响和经济成本的建议。


<details>
  <summary>Details</summary>
Motivation: 随着DRL计算需求的增长，其环境和经济成本未被充分研究，本文旨在填补这一空白。

Method: 对七种DRL算法进行百万步训练，实时测量能耗并估算碳排放和成本。

Result: 不同算法在能效和成本上差异显著，部分算法能减少24%能耗和68%碳排放。

Conclusion: 研究为开发节能高效的DRL实践提供了依据，并建议将可持续性纳入未来算法设计。

Abstract: The growing computational demands of deep reinforcement learning (DRL) have
raised concerns about the environmental and economic costs of training
large-scale models. While algorithmic efficiency in terms of learning
performance has been extensively studied, the energy requirements, greenhouse
gas emissions, and monetary costs of DRL algorithms remain largely unexplored.
In this work, we present a systematic benchmarking study of the energy
consumption of seven state-of-the-art DRL algorithms, namely DQN, TRPO, A2C,
ARS, PPO, RecurrentPPO, and QR-DQN, implemented using Stable Baselines. Each
algorithm was trained for one million steps each on ten Atari 2600 games, and
power consumption was measured in real-time to estimate total energy usage,
CO2-Equivalent emissions, and electricity cost based on the U.S. national
average electricity price. Our results reveal substantial variation in energy
efficiency and training cost across algorithms, with some achieving comparable
performance while consuming up to 24% less energy (ARS vs. DQN), emitting
nearly 68% less CO2, and incurring almost 68% lower monetary cost (QR-DQN vs.
RecurrentPPO) than less efficient counterparts. We further analyze the
trade-offs between learning performance, training time, energy use, and
financial cost, highlighting cases where algorithmic choices can mitigate
environmental and economic impact without sacrificing learning performance.
This study provides actionable insights for developing energy-aware and
cost-efficient DRL practices and establishes a foundation for incorporating
sustainability considerations into future algorithmic design and evaluation.

</details>


### [100] [SpikingBrain Technical Report: Spiking Brain-inspired Large Models](https://arxiv.org/abs/2509.05276)
*Yuqi Pan,Yupeng Feng,Jinghao Zhuang,Siyu Ding,Zehao Liu,Bohan Sun,Yuhong Chou,Han Xu,Xuerui Qiu,Anlin Deng,Anjie Hu,Peng Zhou,Man Yao,Jibin Wu,Jian Yang,Guoliang Sun,Bo Xu,Guoqi Li*

Main category: cs.LG

TL;DR: SpikingBrain是一种受大脑启发的模型家族，旨在解决主流Transformer模型在长上下文处理中的效率瓶颈，通过线性注意力架构、算法优化和系统工程技术，在非NVIDIA平台上实现高效训练和推理。


<details>
  <summary>Details</summary>
Motivation: 主流Transformer模型在长上下文处理中存在训练计算和推理内存的效率瓶颈，且在非NVIDIA平台上训练大型模型面临挑战。

Method: SpikingBrain采用线性注意力架构、自适应脉冲神经元、高效的训练管道和专用脉冲编码框架，结合定制化的训练框架和并行策略。

Result: SpikingBrain-7B和SpikingBrain-76B在非NVIDIA平台上实现了与开源Transformer基线相当的性能，显著提升了长序列训练效率，并支持部分恒定内存的推理。

Conclusion: 这项工作展示了受大脑启发的机制在推动下一代高效、可扩展大型模型设计中的潜力。

Abstract: Mainstream Transformer-based large language models face major efficiency
bottlenecks: training computation scales quadratically with sequence length,
and inference memory grows linearly, limiting long-context processing. Building
large models on non-NVIDIA platforms also poses challenges for stable and
efficient training. To address this, we introduce SpikingBrain, a family of
brain-inspired models designed for efficient long-context training and
inference. SpikingBrain leverages the MetaX GPU cluster and focuses on three
aspects: (1) Model Architecture: linear and hybrid-linear attention
architectures with adaptive spiking neurons; (2) Algorithmic Optimizations: an
efficient, conversion-based training pipeline and a dedicated spike coding
framework; (3) System Engineering: customized training frameworks, operator
libraries, and parallelism strategies tailored to MetaX hardware.
  Using these techniques, we develop two models: SpikingBrain-7B, a linear LLM,
and SpikingBrain-76B, a hybrid-linear MoE LLM. These models demonstrate the
feasibility of large-scale LLM development on non-NVIDIA platforms.
SpikingBrain achieves performance comparable to open-source Transformer
baselines while using only about 150B tokens for continual pre-training. Our
models significantly improve long-sequence training efficiency and deliver
inference with (partially) constant memory and event-driven spiking behavior.
For example, SpikingBrain-7B attains over 100x speedup in Time to First Token
for 4M-token sequences. Training remains stable for weeks on hundreds of MetaX
C550 GPUs, with the 7B model reaching a Model FLOPs Utilization of 23.4
percent. The proposed spiking scheme achieves 69.15 percent sparsity, enabling
low-power operation. Overall, this work demonstrates the potential of
brain-inspired mechanisms to drive the next generation of efficient and
scalable large model design.

</details>


### [101] [Dual-Branch Convolutional Framework for Spatial and Frequency-Based Image Forgery Detection](https://arxiv.org/abs/2509.05281)
*Naman Tyagi*

Main category: cs.LG

TL;DR: 提出了一种结合空间和频率特征的双分支卷积神经网络，用于检测图像伪造，准确率达77.9%，优于传统统计方法。


<details>
  <summary>Details</summary>
Motivation: 随着深度伪造和数字图像伪造的快速增加，确保图像真实性变得更具挑战性。

Method: 使用双分支卷积神经网络，分别提取空间和频率域特征，通过Siamese网络融合和比较，生成64维嵌入进行分类。

Result: 在CASIA 2.0数据集上达到77.9%的准确率，优于传统方法。

Conclusion: 该方法在计算复杂性和检测可靠性之间取得平衡，适用于实际部署，推动了视觉取证技术的发展。

Abstract: With a very rapid increase in deepfakes and digital image forgeries, ensuring
the authenticity of images is becoming increasingly challenging. This report
introduces a forgery detection framework that combines spatial and
frequency-based features for detecting forgeries. We propose a dual branch
convolution neural network that operates on features extracted from spatial and
frequency domains. Features from both branches are fused and compared within a
Siamese network, yielding 64 dimensional embeddings for classification. When
benchmarked on CASIA 2.0 dataset, our method achieves an accuracy of 77.9%,
outperforming traditional statistical methods. Despite its relatively weaker
performance compared to larger, more complex forgery detection pipelines, our
approach balances computational complexity and detection reliability, making it
ready for practical deployment. It provides a strong methodology for forensic
scrutiny of digital images. In a broader sense, it advances the state of the
art in visual forensics, addressing an urgent requirement in media
verification, law enforcement and digital content reliability.

</details>


### [102] [Learning to accelerate distributed ADMM using graph neural networks](https://arxiv.org/abs/2509.05288)
*Henri Doerks,Paul Häusner,Daniel Hernández Escobar,Jens Sjölund*

Main category: cs.LG

TL;DR: 论文提出了一种基于图神经网络（GNN）的自适应分布式ADMM方法，通过学习步长和通信权重来提升收敛速度和解的质量。


<details>
  <summary>Details</summary>
Motivation: 传统ADMM方法收敛慢且对超参数敏感，限制了其在大规模分布式优化中的应用。

Method: 将ADMM迭代与GNN的消息传递框架结合，通过展开固定次数的ADMM迭代，端到端训练GNN预测超参数。

Result: 实验表明，该方法显著提升了收敛速度和解的质量，同时保留了ADMM的收敛性。

Conclusion: 通过GNN学习超参数，可以有效改进分布式ADMM的性能，适用于大规模优化问题。

Abstract: Distributed optimization is fundamental in large-scale machine learning and
control applications. Among existing methods, the Alternating Direction Method
of Multipliers (ADMM) has gained popularity due to its strong convergence
guarantees and suitability for decentralized computation. However, ADMM often
suffers from slow convergence and sensitivity to hyperparameter choices. In
this work, we show that distributed ADMM iterations can be naturally
represented within the message-passing framework of graph neural networks
(GNNs). Building on this connection, we propose to learn adaptive step sizes
and communication weights by a graph neural network that predicts the
hyperparameters based on the iterates. By unrolling ADMM for a fixed number of
iterations, we train the network parameters end-to-end to minimize the final
iterates error for a given problem class, while preserving the algorithm's
convergence properties. Numerical experiments demonstrate that our learned
variant consistently improves convergence speed and solution quality compared
to standard ADMM. The code is available at
https://github.com/paulhausner/learning-distributed-admm.

</details>


### [103] [Deep Reinforcement Learning for Ranking Utility Tuning in the Ad Recommender System at Pinterest](https://arxiv.org/abs/2509.05292)
*Xiao Yang,Mehdi Ben Ayed,Longyu Zhao,Fan Zhou,Yuchen Shen,Abe Engle,Jinfeng Zhuang,Ling Leng,Jiajing Xu,Charles Rosenberg,Prathibha Deshikachar*

Main category: cs.LG

TL;DR: 论文提出了一种基于深度强化学习的个性化效用调优框架（DRL-PUT），用于解决广告推荐系统中的多目标优化问题，显著提升了点击率和长点击率。


<details>
  <summary>Details</summary>
Motivation: 传统的手动调优方法由于缺乏原则性目标、参数组合过多以及无法适应季节性和个性化需求，导致结果不理想。

Method: 将问题建模为强化学习任务，通过在线服务日志直接学习最优策略模型，避免估计价值函数。

Result: 在线A/B测试显示，DRL-PUT比基线方法提升了9.7%的点击率和7.7%的长点击率。

Conclusion: DRL-PUT是一种有效的多目标优化方法，能够显著提升广告推荐系统的性能。

Abstract: The ranking utility function in an ad recommender system, which linearly
combines predictions of various business goals, plays a central role in
balancing values across the platform, advertisers, and users. Traditional
manual tuning, while offering simplicity and interpretability, often yields
suboptimal results due to its unprincipled tuning objectives, the vast amount
of parameter combinations, and its lack of personalization and adaptability to
seasonality. In this work, we propose a general Deep Reinforcement Learning
framework for Personalized Utility Tuning (DRL-PUT) to address the challenges
of multi-objective optimization within ad recommender systems. Our key
contributions include: 1) Formulating the problem as a reinforcement learning
task: given the state of an ad request, we predict the optimal hyperparameters
to maximize a pre-defined reward. 2) Developing an approach to directly learn
an optimal policy model using online serving logs, avoiding the need to
estimate a value function, which is inherently challenging due to the high
variance and unbalanced distribution of immediate rewards. We evaluated DRL-PUT
through an online A/B experiment in Pinterest's ad recommender system. Compared
to the baseline manual utility tuning approach, DRL-PUT improved the
click-through rate by 9.7% and the long click-through rate by 7.7% on the
treated segment. We conducted a detailed ablation study on the impact of
different reward definitions and analyzed the personalization aspect of the
learned policy model.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [104] [In-Context Policy Adaptation via Cross-Domain Skill Diffusion](https://arxiv.org/abs/2509.04535)
*Minjong Yoo,Woo Kyung Kim,Honguk Woo*

Main category: cs.RO

TL;DR: 提出了一个基于扩散技能学习的跨域策略适应框架（ICPAD），适用于长时程多任务环境，能够在有限目标域数据和无模型更新的条件下快速适应。


<details>
  <summary>Details</summary>
Motivation: 解决在跨域环境中，策略适应面临的数据有限和模型更新受限的挑战。

Method: 采用跨域技能扩散方案，学习领域无关的原型技能和领域相关的技能适配器，并通过动态域提示提升适应性能。

Result: 在机器人操作和自动驾驶实验中，ICPAD在有限数据条件下表现出优越的跨域策略适应性能。

Conclusion: ICPAD框架为跨域策略适应提供了一种高效且灵活的方法，适用于多种复杂场景。

Abstract: In this work, we present an in-context policy adaptation (ICPAD) framework
designed for long-horizon multi-task environments, exploring diffusion-based
skill learning techniques in cross-domain settings. The framework enables rapid
adaptation of skill-based reinforcement learning policies to diverse target
domains, especially under stringent constraints on no model updates and only
limited target domain data. Specifically, the framework employs a cross-domain
skill diffusion scheme, where domain-agnostic prototype skills and a
domain-grounded skill adapter are learned jointly and effectively from an
offline dataset through cross-domain consistent diffusion processes. The
prototype skills act as primitives for common behavior representations of
long-horizon policies, serving as a lingua franca to bridge different domains.
Furthermore, to enhance the in-context adaptation performance, we develop a
dynamic domain prompting scheme that guides the diffusion-based skill adapter
toward better alignment with the target domain. Through experiments with
robotic manipulation in Metaworld and autonomous driving in CARLA, we show that
our $\oursol$ framework achieves superior policy adaptation performance under
limited target domain data conditions for various cross-domain configurations
including differences in environment dynamics, agent embodiment, and task
horizon.

</details>


### [105] [Action Chunking with Transformers for Image-Based Spacecraft Guidance and Control](https://arxiv.org/abs/2509.04628)
*Alejandro Posadas-Nava,Andrea Scorsoglio,Luca Ghilardi,Roberto Furfaro,Richard Linares*

Main category: cs.RO

TL;DR: 提出了一种基于模仿学习的航天器GNC方法，仅需100次专家演示即可实现高性能控制。


<details>
  <summary>Details</summary>
Motivation: 解决航天器GNC任务中数据稀缺和高性能控制需求的问题。

Method: 采用Action Chunking with Transformers (ACT)方法，通过视觉和状态观测生成推力与扭矩指令。

Result: ACT在ISS对接任务中表现优于基线方法，控制更平滑且样本效率更高。

Conclusion: ACT是一种高效且性能优越的航天器GNC解决方案。

Abstract: We present an imitation learning approach for spacecraft guidance,
navigation, and control(GNC) that achieves high performance from limited data.
Using only 100 expert demonstrations, equivalent to 6,300 environment
interactions, our method, which implements Action Chunking with Transformers
(ACT), learns a control policy that maps visual and state observations to
thrust and torque commands. ACT generates smoother, more consistent
trajectories than a meta-reinforcement learning (meta-RL) baseline trained with
40 million interactions. We evaluate ACT on a rendezvous task: in-orbit docking
with the International Space Station (ISS). We show that our approach achieves
greater accuracy, smoother control, and greater sample efficiency.

</details>


### [106] [Planning from Point Clouds over Continuous Actions for Multi-object Rearrangement](https://arxiv.org/abs/2509.04645)
*Kallol Saha,Amber Li,Angela Rodriguez-Izquierdo,Lifan Yu,Ben Eisner,Maxim Likhachev,David Held*

Main category: cs.RO

TL;DR: SPOT是一种混合学习和规划方法，通过搜索点云变换序列实现机器人长时程规划，优于传统离散化方法和策略学习。


<details>
  <summary>Details</summary>
Motivation: 解决传统任务规划方法需要离散化连续状态和动作空间的问题，提出利用学习模型作为先验指导高维连续动作空间搜索。

Method: SPOT通过搜索从初始点云到目标点云的变换序列，利用学习模型生成候选动作，避免离散化。

Result: 在模拟和真实环境中，SPOT在多物体重排任务中表现出色，成功生成计划并优于策略学习方法。

Conclusion: SPOT证明了基于搜索的规划在长时程机器人操作中的有效性。

Abstract: Long-horizon planning for robot manipulation is a challenging problem that
requires reasoning about the effects of a sequence of actions on a physical 3D
scene. While traditional task planning methods are shown to be effective for
long-horizon manipulation, they require discretizing the continuous state and
action space into symbolic descriptions of objects, object relationships, and
actions. Instead, we propose a hybrid learning-and-planning approach that
leverages learned models as domain-specific priors to guide search in
high-dimensional continuous action spaces. We introduce SPOT: Search over Point
cloud Object Transformations, which plans by searching for a sequence of
transformations from an initial scene point cloud to a goal-satisfying point
cloud. SPOT samples candidate actions from learned suggesters that operate on
partially observed point clouds, eliminating the need to discretize actions or
object relationships. We evaluate SPOT on multi-object rearrangement tasks,
reporting task planning success and task execution success in both simulation
and real-world environments. Our experiments show that SPOT generates
successful plans and outperforms a policy-learning approach. We also perform
ablations that highlight the importance of search-based planning.

</details>


### [107] [Surformer v2: A Multimodal Classifier for Surface Understanding from Touch and Vision](https://arxiv.org/abs/2509.04658)
*Manish Kansana,Sindhuja Penchala,Shahram Rahimi,Noorbakhsh Amiri Golilarz*

Main category: cs.RO

TL;DR: Surformer v2是一种改进的多模态分类架构，通过决策级融合机制整合视觉和触觉数据，提升了机器人表面材料分类的性能。


<details>
  <summary>Details</summary>
Motivation: 多模态表面材料分类对机器人触觉感知至关重要，需要一种更高效的方法来整合视觉和触觉数据。

Method: Surformer v2采用CNN（Efficient V-Net）处理视觉数据，使用编码器-变压器模型处理触觉数据，并通过可学习的加权和进行决策级融合。

Result: 在Touch and Go数据集上表现优异，保持了实时推理速度，适用于机器人应用。

Conclusion: 决策级融合和基于变压器的触觉建模有效提升了多模态机器人感知的表面理解能力。

Abstract: Multimodal surface material classification plays a critical role in advancing
tactile perception for robotic manipulation and interaction. In this paper, we
present Surformer v2, an enhanced multi-modal classification architecture
designed to integrate visual and tactile sensory streams through a
late(decision level) fusion mechanism. Building on our earlier Surformer v1
framework [1], which employed handcrafted feature extraction followed by
mid-level fusion architecture with multi-head cross-attention layers, Surformer
v2 integrates the feature extraction process within the model itself and shifts
to late fusion. The vision branch leverages a CNN-based classifier(Efficient
V-Net), while the tactile branch employs an encoder-only transformer model,
allowing each modality to extract modality-specific features optimized for
classification. Rather than merging feature maps, the model performs
decision-level fusion by combining the output logits using a learnable weighted
sum, enabling adaptive emphasis on each modality depending on data context and
training dynamics. We evaluate Surformer v2 on the Touch and Go dataset [2], a
multi-modal benchmark comprising surface images and corresponding tactile
sensor readings. Our results demonstrate that Surformer v2 performs well,
maintaining competitive inference speed, suitable for real-time robotic
applications. These findings underscore the effectiveness of decision-level
fusion and transformer-based tactile modeling for enhancing surface
understanding in multi-modal robotic perception.

</details>


### [108] [Bootstrapping Reinforcement Learning with Sub-optimal Policies for Autonomous Driving](https://arxiv.org/abs/2509.04712)
*Zhihao Zhang,Chengyang Peng,Ekim Yurtsever,Keith A. Redmill*

Main category: cs.RO

TL;DR: 提出了一种结合规则控制器与SAC算法的强化学习方法，以提升自动驾驶策略的学习效率和性能。


<details>
  <summary>Details</summary>
Motivation: 强化学习在自动驾驶中面临样本效率和探索效率的挑战，难以找到最优驾驶策略。

Method: 将基于规则的车道变换控制器与SAC算法结合，通过示范策略引导强化学习代理。

Result: 该方法提高了驾驶性能，并可推广到其他类似场景。

Conclusion: 结合示范策略的强化学习方法能有效提升自动驾驶策略的学习效率和性能。

Abstract: Automated vehicle control using reinforcement learning (RL) has attracted
significant attention due to its potential to learn driving policies through
environment interaction. However, RL agents often face training challenges in
sample efficiency and effective exploration, making it difficult to discover an
optimal driving strategy. To address these issues, we propose guiding the RL
driving agent with a demonstration policy that need not be a highly optimized
or expert-level controller. Specifically, we integrate a rule-based lane change
controller with the Soft Actor Critic (SAC) algorithm to enhance exploration
and learning efficiency. Our approach demonstrates improved driving performance
and can be extended to other driving scenarios that can similarly benefit from
demonstration-based guidance.

</details>


### [109] [Hierarchical Reduced-Order Model Predictive Control for Robust Locomotion on Humanoid Robots](https://arxiv.org/abs/2509.04722)
*Adrian B. Ghansah,Sergio A. Esteban,Aaron D. Ames*

Main category: cs.RO

TL;DR: 提出了一种基于降阶模型的计算高效分层控制框架，用于人形机器人运动，通过非线性MPC优化步态参数，并通过线性MPC结合上半身动力学增强稳定性。


<details>
  <summary>Details</summary>
Motivation: 随着人形机器人进入现实环境，确保其在多样化环境中的稳健运动至关重要。

Method: 采用分层控制框架，高层使用ALIP模型的步态动力学通过非线性MPC优化步态参数，中层通过线性MPC结合上半身动力学。

Result: 在Unitree G1机器人上验证，自适应步态时间将推恢复成功率提高36%，上半身控制改善了偏航扰动抑制。

Conclusion: 该框架在多样化地形中表现出稳健的运动能力，包括草地、石板路和不平整的健身垫。

Abstract: As humanoid robots enter real-world environments, ensuring robust locomotion
across diverse environments is crucial. This paper presents a computationally
efficient hierarchical control framework for humanoid robot locomotion based on
reduced-order models -- enabling versatile step planning and incorporating arm
and torso dynamics to better stabilize the walking. At the high level, we use
the step-to-step dynamics of the ALIP model to simultaneously optimize over
step periods, step lengths, and ankle torques via nonlinear MPC. The ALIP
trajectories are used as references to a linear MPC framework that extends the
standard SRB-MPC to also include simplified arm and torso dynamics. We validate
the performance of our approach through simulation and hardware experiments on
the Unitree G1 humanoid robot. In the proposed framework the high-level step
planner runs at 40 Hz and the mid-level MPC at 500 Hz using the onboard
mini-PC. Adaptive step timing increased the push recovery success rate by 36%,
and the upper body control improved the yaw disturbance rejection. We also
demonstrate robust locomotion across diverse indoor and outdoor terrains,
including grass, stone pavement, and uneven gym mats.

</details>


### [110] [Imitation Learning Based on Disentangled Representation Learning of Behavioral Characteristics](https://arxiv.org/abs/2509.04737)
*Ryoga Oishi,Sho Sakaino,Toshiaki Tsuji*

Main category: cs.RO

TL;DR: 提出了一种运动生成模型，通过语言指令调整机器人动作，解决了传统批量方法无法在线适应的问题。


<details>
  <summary>Details</summary>
Motivation: 人类指令通常是定性的，需要探索满足不同条件的行为，因此适应这些指令具有挑战性。

Method: 通过将演示分割为短序列，并为特定修饰符类型分配弱监督标签，学习从修饰符指令到动作的映射。

Result: 在擦拭和拾取放置任务中验证，模型能够在线响应修饰符指令调整动作。

Conclusion: 该方法优于传统批量方法，能够在线适应指令，适用于动态任务执行。

Abstract: In the field of robot learning, coordinating robot actions through language
instructions is becoming increasingly feasible. However, adapting actions to
human instructions remains challenging, as such instructions are often
qualitative and require exploring behaviors that satisfy varying conditions.
This paper proposes a motion generation model that adapts robot actions in
response to modifier directives human instructions imposing behavioral
conditions during task execution. The proposed method learns a mapping from
modifier directives to actions by segmenting demonstrations into short
sequences, assigning weakly supervised labels corresponding to specific
modifier types. We evaluated our method in wiping and pick and place tasks.
Results show that it can adjust motions online in response to modifier
directives, unlike conventional batch-based methods that cannot adapt during
execution.

</details>


### [111] [COMMET: A System for Human-Induced Conflicts in Mobile Manipulation of Everyday Tasks](https://arxiv.org/abs/2509.04836)
*Dongping Li,Shaoting Peng,John Pohovey,Katherine Rose Driggs-Campbell*

Main category: cs.RO

TL;DR: COMMET是一个解决家庭机器人任务中人类冲突的系统，采用混合检测方法，结合多模态检索和模型推理，利用GPT-4o总结用户偏好。


<details>
  <summary>Details</summary>
Motivation: 动态和不可预测的人类活动会与机器人行为冲突，且解决方案依赖用户偏好，需开发适应性强的系统。

Method: 使用混合检测方法（多模态检索和模型推理），结合GPT-4o总结用户偏好。

Result: 检测模块在准确性和延迟上优于GPT模型，并设计了用户友好的数据收集界面。

Conclusion: COMMET为家庭机器人开发提供了有效解决方案，并支持未来研究。

Abstract: Continuous advancements in robotics and AI are driving the integration of
robots from industry into everyday environments. However, dynamic and
unpredictable human activities in daily lives would directly or indirectly
conflict with robot actions. Besides, due to the social attributes of such
human-induced conflicts, solutions are not always unique and depend highly on
the user's personal preferences. To address these challenges and facilitate the
development of household robots, we propose COMMET, a system for human-induced
COnflicts in Mobile Manipulation of Everyday Tasks. COMMET employs a hybrid
detection approach, which begins with multi-modal retrieval and escalates to
fine-tuned model inference for low-confidence cases. Based on collected user
preferred options and settings, GPT-4o will be used to summarize user
preferences from relevant cases. In preliminary studies, our detection module
shows better accuracy and latency compared with GPT models. To facilitate
future research, we also design a user-friendly interface for user data
collection and demonstrate an effective workflow for real-world deployments.

</details>


### [112] [A Knowledge-Driven Diffusion Policy for End-to-End Autonomous Driving Based on Expert Routing](https://arxiv.org/abs/2509.04853)
*Chengkai Xu,Jiaqi Liu,Yicheng Guo,Peng Hang,Jian Sun*

Main category: cs.RO

TL;DR: KDP是一种知识驱动的扩散策略，结合生成扩散模型和稀疏专家混合路由机制，提升自动驾驶的多模态动作生成和时间一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多模态动作生成、长期一致性和模块化适应性方面存在不足，KDP旨在解决这些问题。

Method: KDP结合扩散模型生成时间一致的多模态动作序列，并通过稀疏专家路由机制激活上下文相关的专家模块。

Result: 实验表明，KDP在多种驾驶场景中表现优于现有方法，成功率高、碰撞风险低、控制更平滑。

Conclusion: KDP证明了扩散模型与专家路由结合是一种可扩展且可解释的自动驾驶范式。

Abstract: End-to-end autonomous driving remains constrained by the need to generate
multi-modal actions, maintain temporal stability, and generalize across diverse
scenarios. Existing methods often collapse multi-modality, struggle with
long-horizon consistency, or lack modular adaptability. This paper presents
KDP, a knowledge-driven diffusion policy that integrates generative diffusion
modeling with a sparse mixture-of-experts routing mechanism. The diffusion
component generates temporally coherent and multi-modal action sequences, while
the expert routing mechanism activates specialized and reusable experts
according to context, enabling modular knowledge composition. Extensive
experiments across representative driving scenarios demonstrate that KDP
achieves consistently higher success rates, reduced collision risk, and
smoother control compared to prevailing paradigms. Ablation studies highlight
the effectiveness of sparse expert activation and the Transformer backbone, and
activation analyses reveal structured specialization and cross-scenario reuse
of experts. These results establish diffusion with expert routing as a scalable
and interpretable paradigm for knowledge-driven end-to-end autonomous driving.

</details>


### [113] [Towards an Accurate and Effective Robot Vision (The Problem of Topological Localization for Mobile Robots)](https://arxiv.org/abs/2509.04948)
*Emanuela Boros*

Main category: cs.RO

TL;DR: 该论文研究了在办公室环境中仅使用彩色相机图像进行拓扑定位的方法，评估了多种视觉描述符的性能，并提出了优化配置。


<details>
  <summary>Details</summary>
Motivation: 解决移动机器人在视觉定位和地点识别中面临的感知模糊、传感器噪声和光照变化等挑战。

Method: 评估了多种视觉描述符（如颜色直方图、SIFT、ASIFT等）及其距离度量和分类器，并进行了系统比较。

Result: 结果表明，适当的描述符配置、相似性度量和分类器能显著提升性能，并在ImageCLEF评测中验证了其有效性。

Conclusion: 未来工作将探索分层模型、排序方法和特征组合，以构建更鲁棒的实时定位系统。

Abstract: Topological localization is a fundamental problem in mobile robotics, since
robots must be able to determine their position in order to accomplish tasks.
Visual localization and place recognition are challenging due to perceptual
ambiguity, sensor noise, and illumination variations. This work addresses
topological localization in an office environment using only images acquired
with a perspective color camera mounted on a robot platform, without relying on
temporal continuity of image sequences. We evaluate state-of-the-art visual
descriptors, including Color Histograms, SIFT, ASIFT, RGB-SIFT, and
Bag-of-Visual-Words approaches inspired by text retrieval. Our contributions
include a systematic, quantitative comparison of these features, distance
measures, and classifiers. Performance was analyzed using standard evaluation
metrics and visualizations, extending previous experiments. Results demonstrate
the advantages of proper configurations of appearance descriptors, similarity
measures, and classifiers. The quality of these configurations was further
validated in the Robot Vision task of the ImageCLEF evaluation campaign, where
the system identified the most likely location of novel image sequences. Future
work will explore hierarchical models, ranking methods, and feature
combinations to build more robust localization systems, reducing training and
runtime while avoiding the curse of dimensionality. Ultimately, this aims
toward integrated, real-time localization across varied illumination and longer
routes.

</details>


### [114] [Ground-Aware Octree-A* Hybrid Path Planning for Memory-Efficient 3D Navigation of Ground Vehicles](https://arxiv.org/abs/2509.04950)
*Byeong-Il Ham,Hyun-Bin Kim,Kyung-Soo Kim*

Main category: cs.RO

TL;DR: 提出了一种结合A*算法和八叉树结构的3D路径规划方法，优化了UGV和腿式机器人的导航效率。


<details>
  <summary>Details</summary>
Motivation: UGV和腿式机器人需要高效导航，传统方法将障碍物视为阻碍，而新方法将其视为潜在辅助。

Method: 改进的3D A*算法结合高度惩罚成本函数，利用八叉树压缩地图，减少计算节点。

Result: 实验表明，该方法在保证路径最优的同时显著降低内存和计算时间。

Conclusion: 该方法为复杂环境中的实时路径规划提供了高效解决方案。

Abstract: In this paper, we propose a 3D path planning method that integrates the A*
algorithm with the octree structure. Unmanned Ground Vehicles (UGVs) and legged
robots have been extensively studied, enabling locomotion across a variety of
terrains. Advances in mobility have enabled obstacles to be regarded not only
as hindrances to be avoided, but also as navigational aids when beneficial. A
modified 3D A* algorithm generates an optimal path by leveraging obstacles
during the planning process. By incorporating a height-based penalty into the
cost function, the algorithm enables the use of traversable obstacles to aid
locomotion while avoiding those that are impassable, resulting in more
efficient and realistic path generation. The octree-based 3D grid map achieves
compression by merging high-resolution nodes into larger blocks, especially in
obstacle-free or sparsely populated areas. This reduces the number of nodes
explored by the A* algorithm, thereby improving computational efficiency and
memory usage, and supporting real-time path planning in practical environments.
Benchmark results demonstrate that the use of octree structure ensures an
optimal path while significantly reducing memory usage and computation time.

</details>


### [115] [DeGuV: Depth-Guided Visual Reinforcement Learning for Generalization and Interpretability in Manipulation](https://arxiv.org/abs/2509.04970)
*Tien Pham,Xinyun Chi,Khang Nguyen,Manfred Huber,Angelo Cangelosi*

Main category: cs.RO

TL;DR: DeGuV是一种强化学习框架，通过可学习的掩码网络和对比学习提升泛化能力和样本效率，并在零样本模拟到现实转移中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习在视觉输入中泛化能力不足的问题，同时提高样本效率和训练稳定性。

Method: 使用可学习的掩码网络从深度输入生成掩码，保留关键视觉信息；结合对比学习和稳定的Q值估计。

Result: 在RL-ViGen基准测试中，DeGuV在泛化能力和样本效率上优于现有方法，并提高了可解释性。

Conclusion: DeGuV通过聚焦关键视觉特征，显著提升了强化学习的泛化能力和效率，适用于机器人任务。

Abstract: Reinforcement learning (RL) agents can learn to solve complex tasks from
visual inputs, but generalizing these learned skills to new environments
remains a major challenge in RL application, especially robotics. While data
augmentation can improve generalization, it often compromises sample efficiency
and training stability. This paper introduces DeGuV, an RL framework that
enhances both generalization and sample efficiency. In specific, we leverage a
learnable masker network that produces a mask from the depth input, preserving
only critical visual information while discarding irrelevant pixels. Through
this, we ensure that our RL agents focus on essential features, improving
robustness under data augmentation. In addition, we incorporate contrastive
learning and stabilize Q-value estimation under augmentation to further enhance
sample efficiency and training stability. We evaluate our proposed method on
the RL-ViGen benchmark using the Franka Emika robot and demonstrate its
effectiveness in zero-shot sim-to-real transfer. Our results show that DeGuV
outperforms state-of-the-art methods in both generalization and sample
efficiency while also improving interpretability by highlighting the most
relevant regions in the visual input

</details>


### [116] [Lyapunov-Based Deep Learning Control for Robots with Unknown Jacobian](https://arxiv.org/abs/2509.04984)
*Koji Matsuno,Chien Chern Cheah*

Main category: cs.RO

TL;DR: 提出了一种基于深度学习的实时机器人控制框架，通过模块化学习和Lyapunov分析确保稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习在机器人控制中的黑盒问题，确保系统的可信度和鲁棒性。

Method: 采用模块化学习方法实时更新网络权重，结合Lyapunov分析保证稳定性。

Result: 实验证明该方法在工业机器人上表现良好，解决了黑盒问题。

Conclusion: 为实时深度学习机器人控制提供了稳定解决方案，奠定了未来研究基础。

Abstract: Deep learning, with its exceptional learning capabilities and flexibility,
has been widely applied in various applications. However, its black-box nature
poses a significant challenge in real-time robotic applications, particularly
in robot control, where trustworthiness and robustness are critical in ensuring
safety. In robot motion control, it is essential to analyze and ensure system
stability, necessitating the establishment of methodologies that address this
need. This paper aims to develop a theoretical framework for end-to-end deep
learning control that can be integrated into existing robot control theories.
The proposed control algorithm leverages a modular learning approach to update
the weights of all layers in real time, ensuring system stability based on
Lyapunov-like analysis. Experimental results on industrial robots are presented
to illustrate the performance of the proposed deep learning controller. The
proposed method offers an effective solution to the black-box problem in deep
learning, demonstrating the possibility of deploying real-time deep learning
strategies for robot kinematic control in a stable manner. This achievement
provides a critical foundation for future advancements in deep learning based
real-time robotic applications.

</details>


### [117] [FLOWER: Democratizing Generalist Robot Policies with Efficient Vision-Language-Action Flow Policies](https://arxiv.org/abs/2509.04996)
*Moritz Reuss,Hongyi Zhou,Marcel Rühle,Ömer Erdinç Yağmurlu,Fabian Otto,Rudolf Lioutikov*

Main category: cs.RO

TL;DR: FLOWER是一种高效的视觉-语言-动作（VLA）策略模型，通过中间模态融合和动作特定的全局自适应层归一化（Global-AdaLN）条件化，显著减少了计算资源和参数需求，同时保持高性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于扩散的VLA策略需要庞大的模型和数据集，计算成本高昂，限制了实际机器人部署的效率。

Method: 采用中间模态融合减少LLM层数，并通过Global-AdaLN条件化模块化适应，降低参数数量。

Result: FLOWER在200 H100 GPU小时内完成预训练，在190个任务中表现优异，并在CALVIN ABC基准测试中达到新SoTA（4.53）。

Conclusion: FLOWER展示了高效VLA策略的可行性，为实际机器人应用提供了资源友好的解决方案。

Abstract: Developing efficient Vision-Language-Action (VLA) policies is crucial for
practical robotics deployment, yet current approaches face prohibitive
computational costs and resource requirements. Existing diffusion-based VLA
policies require multi-billion-parameter models and massive datasets to achieve
strong performance. We tackle this efficiency challenge with two contributions:
intermediate-modality fusion, which reallocates capacity to the diffusion head
by pruning up to $50\%$ of LLM layers, and action-specific Global-AdaLN
conditioning, which cuts parameters by $20\%$ through modular adaptation. We
integrate these advances into a novel 950 M-parameter VLA called FLOWER.
Pretrained in just 200 H100 GPU hours, FLOWER delivers competitive performance
with bigger VLAs across $190$ tasks spanning ten simulation and real-world
benchmarks and demonstrates robustness across diverse robotic embodiments. In
addition, FLOWER achieves a new SoTA of 4.53 on the CALVIN ABC benchmark.
Demos, code and pretrained weights are available at
https://intuitive-robots.github.io/flower_vla/.

</details>


### [118] [Pointing-Guided Target Estimation via Transformer-Based Attention](https://arxiv.org/abs/2509.05031)
*Luca Müller,Hassan Ali,Philipp Allgeuer,Lukáš Gajdošech,Stefan Wermter*

Main category: cs.RO

TL;DR: MM-ITF模型通过多模态注意力机制，从单目RGB数据中预测人类指向手势的目标物体，提升人机交互的直观性。


<details>
  <summary>Details</summary>
Motivation: 在HRI中，机器人需要理解人类的非语言意图（如指向手势），以实现更自然的协作。

Method: 提出MM-ITF架构，利用跨模态注意力将2D指向手势映射到物体位置，并计算目标物体的可能性得分。

Result: 模型能准确预测目标物体，并通过提出的patch混淆矩阵评估性能。

Conclusion: MM-ITF为直观的人机协作提供了有效解决方案，代码已开源。

Abstract: Deictic gestures, like pointing, are a fundamental form of non-verbal
communication, enabling humans to direct attention to specific objects or
locations. This capability is essential in Human-Robot Interaction (HRI), where
robots should be able to predict human intent and anticipate appropriate
responses. In this work, we propose the Multi-Modality Inter-TransFormer
(MM-ITF), a modular architecture to predict objects in a controlled tabletop
scenario with the NICOL robot, where humans indicate targets through natural
pointing gestures. Leveraging inter-modality attention, MM-ITF maps 2D pointing
gestures to object locations, assigns a likelihood score to each, and
identifies the most likely target. Our results demonstrate that the method can
accurately predict the intended object using monocular RGB data, thus enabling
intuitive and accessible human-robot collaboration. To evaluate the
performance, we introduce a patch confusion matrix, providing insights into the
model's predictions across candidate object locations. Code available at:
https://github.com/lucamuellercode/MMITF.

</details>


### [119] [Shared Autonomy through LLMs and Reinforcement Learning for Applications to Ship Hull Inspections](https://arxiv.org/abs/2509.05042)
*Cristiano Caissutti,Estelle Gerbier,Ehsan Khorrambakht,Paolo Marinelli,Andrea Munafo',Andrea Caiti*

Main category: cs.RO

TL;DR: 本文探讨了在异构海洋机器人舰队中推进共享自主性的三种互补方法，包括LLM集成、人机交互框架和模块化任务管理器。


<details>
  <summary>Details</summary>
Motivation: 海洋环境中复杂、高风险和不确定性要求有效的人机协作，共享自主性是一个有前景的范式。

Method: 结合LLM实现高级任务指定、多智能体人机交互框架和基于行为树的模块化任务管理器。

Result: 初步结果显示该架构能降低操作员认知负荷、增强透明度和行为对齐。

Conclusion: 研究为安全关键的海事机器人应用提供了模块化和可扩展的基础。

Abstract: Shared autonomy is a promising paradigm in robotic systems, particularly
within the maritime domain, where complex, high-risk, and uncertain
environments necessitate effective human-robot collaboration. This paper
investigates the interaction of three complementary approaches to advance
shared autonomy in heterogeneous marine robotic fleets: (i) the integration of
Large Language Models (LLMs) to facilitate intuitive high-level task
specification and support hull inspection missions, (ii) the implementation of
human-in-the-loop interaction frameworks in multi-agent settings to enable
adaptive and intent-aware coordination, and (iii) the development of a modular
Mission Manager based on Behavior Trees to provide interpretable and flexible
mission control. Preliminary results from simulation and real-world lake-like
environments demonstrate the potential of this multi-layered architecture to
reduce operator cognitive load, enhance transparency, and improve adaptive
behaviour alignment with human intent. Ongoing work focuses on fully
integrating these components, refining coordination mechanisms, and validating
the system in operational port scenarios. This study contributes to
establishing a modular and scalable foundation for trustworthy,
human-collaborative autonomy in safety-critical maritime robotics applications.

</details>


### [120] [Robust Model Predictive Control Design for Autonomous Vehicles with Perception-based Observers](https://arxiv.org/abs/2509.05201)
*Nariman Niknejad,Gokul S. Sankar,Bahare Kiumarsi,Hamidreza Modares*

Main category: cs.RO

TL;DR: 提出了一种鲁棒的模型预测控制（MPC）框架，用于处理深度学习感知模块中的非高斯噪声，通过集合状态估计和线性规划优化计算效率，并在实验中验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 传统MPC假设感知误差为零均值高斯噪声，但实际感知模块的噪声可能是偏态或重尾的，需要更准确的量化以保证安全控制。

Method: 采用基于约束zonotopes的集合状态估计捕获噪声特性，将鲁棒MPC转化为线性规划问题，并通过Minkowski-Lyapunov不等式保证闭环稳定性。

Result: 实验表明，该方法在重尾噪声下仍能实现稳定且精确的控制，显著优于传统高斯噪声假设的设计。

Conclusion: 该框架为处理非高斯噪声的感知-控制问题提供了有效解决方案，提升了控制系统的鲁棒性和性能。

Abstract: This paper presents a robust model predictive control (MPC) framework that
explicitly addresses the non-Gaussian noise inherent in deep learning-based
perception modules used for state estimation. Recognizing that accurate
uncertainty quantification of the perception module is essential for safe
feedback control, our approach departs from the conventional assumption of
zero-mean noise quantification of the perception error. Instead, it employs
set-based state estimation with constrained zonotopes to capture biased,
heavy-tailed uncertainties while maintaining bounded estimation errors. To
improve computational efficiency, the robust MPC is reformulated as a linear
program (LP), using a Minkowski-Lyapunov-based cost function with an added
slack variable to prevent degenerate solutions. Closed-loop stability is
ensured through Minkowski-Lyapunov inequalities and contractive zonotopic
invariant sets. The largest stabilizing terminal set and its corresponding
feedback gain are then derived via an ellipsoidal approximation of the
zonotopes. The proposed framework is validated through both simulations and
hardware experiments on an omnidirectional mobile robot along with a camera and
a convolutional neural network-based perception module implemented within a
ROS2 framework. The results demonstrate that the perception-aware MPC provides
stable and accurate control performance under heavy-tailed noise conditions,
significantly outperforming traditional Gaussian-noise-based designs in terms
of both state estimation error bounding and overall control performance.

</details>
