<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 64]
- [cs.RO](#cs.RO) [Total: 22]
- [cs.LG](#cs.LG) [Total: 51]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Australian Supermarket Object Set (ASOS): A Benchmark Dataset of Physical Objects and 3D Models for Robotics and Computer Vision](https://arxiv.org/abs/2509.09720)
*Akansel Cosgun,Lachlan Chumbley,Benjamin J. Meyer*

Main category: cs.CV

TL;DR: ASOS是一个包含50种超市物品的高质量3D纹理网格数据集，用于机器人和计算机视觉的基准测试。


<details>
  <summary>Details</summary>
Motivation: 现有数据集多依赖合成模型或难以获取的专用物品，ASOS提供了成本低廉且易于获取的真实物品数据集。

Method: 通过运动恢复结构技术和高分辨率成像获取3D网格，生成密封网格。

Result: 数据集涵盖10个类别，形状、大小和重量多样，适用于物体检测、姿态估计和机器人应用。

Conclusion: ASOS因其可访问性和实际应用价值，成为机器人和计算机视觉领域的重要基准工具。

Abstract: This paper introduces the Australian Supermarket Object Set (ASOS), a
comprehensive dataset comprising 50 readily available supermarket items with
high-quality 3D textured meshes designed for benchmarking in robotics and
computer vision applications. Unlike existing datasets that rely on synthetic
models or specialized objects with limited accessibility, ASOS provides a
cost-effective collection of common household items that can be sourced from a
major Australian supermarket chain. The dataset spans 10 distinct categories
with diverse shapes, sizes, and weights. 3D meshes are acquired by a
structure-from-motion techniques with high-resolution imaging to generate
watertight meshes. The dataset's emphasis on accessibility and real-world
applicability makes it valuable for benchmarking object detection, pose
estimation, and robotics applications.

</details>


### [2] [A Multimodal RAG Framework for Housing Damage Assessment: Collaborative Optimization of Image Encoding and Policy Vector Retrieval](https://arxiv.org/abs/2509.09721)
*Jiayi Miao,Dingxin Lu,Zhuqi Wang*

Main category: cs.CV

TL;DR: 提出了一种多模态检索增强生成（MM-RAG）框架，用于灾后房屋损坏评估，结合图像和文本信息，提升检索准确性和分类性能。


<details>
  <summary>Details</summary>
Motivation: 灾后房屋损坏评估对保险理赔和资源规划至关重要，需要结合多模态信息（如图像和文本）进行更准确的判断。

Method: 采用双分支多模态编码器结构，图像分支使用ResNet和Transformer提取损坏特征，文本分支使用BERT检索器处理文本信息。通过跨模态交互模块和多头注意力实现语义对齐，生成模块引入模态注意力门控机制动态控制信息流。

Result: 在检索准确性和损坏严重性分类指标上表现优异，Top-1检索准确率提升了9.6%。

Conclusion: MM-RAG框架通过多模态协同学习，显著提升了灾后房屋损坏评估的准确性和效率。

Abstract: After natural disasters, accurate evaluations of damage to housing are
important for insurance claims response and planning of resources. In this
work, we introduce a novel multimodal retrieval-augmented generation (MM-RAG)
framework. On top of classical RAG architecture, we further the framework to
devise a two-branch multimodal encoder structure that the image branch employs
a visual encoder composed of ResNet and Transformer to extract the
characteristic of building damage after disaster, and the text branch harnesses
a BERT retriever for the text vectorization of posts as well as insurance
policies and for the construction of a retrievable restoration index. To impose
cross-modal semantic alignment, the model integrates a cross-modal interaction
module to bridge the semantic representation between image and text via
multi-head attention. Meanwhile, in the generation module, the introduced modal
attention gating mechanism dynamically controls the role of visual evidence and
text prior information during generation. The entire framework takes end-to-end
training, and combines the comparison loss, the retrieval loss and the
generation loss to form multi-task optimization objectives, and achieves image
understanding and policy matching in collaborative learning. The results
demonstrate superior performance in retrieval accuracy and classification index
on damage severity, where the Top-1 retrieval accuracy has been improved by
9.6%.

</details>


### [3] [Improving MLLM Historical Record Extraction with Test-Time Image](https://arxiv.org/abs/2509.09722)
*Taylor Archibald,Tony Martinez*

Main category: cs.CV

TL;DR: 提出了一种新的集成框架，通过多图像增强和自定义对齐器提高历史文档转录准确性。


<details>
  <summary>Details</summary>
Motivation: 解决从噪声历史文档中提取文本时LLM转录不稳定的问题。

Method: 使用Gemini 2.0 Flash对多个增强图像变体进行转录，并通过自定义Needleman-Wunsch对齐器融合输出。

Result: 在622份宾夕法尼亚州死亡记录数据集上，转录准确率提高了4个百分点。

Conclusion: 该方法简单、可扩展，适用于其他文档集合和转录模型。

Abstract: We present a novel ensemble framework that stabilizes LLM based text
extraction from noisy historical documents. We transcribe multiple augmented
variants of each image with Gemini 2.0 Flash and fuse these outputs with a
custom Needleman Wunsch style aligner that yields both a consensus
transcription and a confidence score. We present a new dataset of 622
Pennsylvania death records, and demonstrate our method improves transcription
accuracy by 4 percentage points relative to a single shot baseline. We find
that padding and blurring are the most useful for improving accuracy, while
grid warp perturbations are best for separating high and low confidence cases.
The approach is simple, scalable, and immediately deployable to other document
collections and transcription models.

</details>


### [4] [MITS: A Large-Scale Multimodal Benchmark Dataset for Intelligent Traffic Surveillance](https://arxiv.org/abs/2509.09730)
*Kaikai Zhao,Zhaoxiang Liu,Peng Wang,Xin Wang,Zhicheng Ma,Yajun Xu,Wenjing Zhang,Yibing Nan,Kai Wang,Shiguo Lian*

Main category: cs.CV

TL;DR: MITS是首个专为智能交通监控（ITS）设计的大规模多模态基准数据集，显著提升了主流LMM在ITS任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有通用领域LMM在ITS领域表现有限，缺乏专用多模态数据集。

Method: 构建MITS数据集，包含17万张真实ITS图像，生成高质量标注和500万指令问答对，并微调主流LMM。

Result: MITS使LLaVA-1.5、LLaVA-1.6、Qwen2-VL和Qwen2.5-VL的性能分别提升83.2%、35.8%、58.6%和27.0%。

Conclusion: MITS为ITS和LMM研究提供了高价值资源，推动了领域发展。

Abstract: General-domain large multimodal models (LMMs) have achieved significant
advances in various image-text tasks. However, their performance in the
Intelligent Traffic Surveillance (ITS) domain remains limited due to the
absence of dedicated multimodal datasets. To address this gap, we introduce
MITS (Multimodal Intelligent Traffic Surveillance), the first large-scale
multimodal benchmark dataset specifically designed for ITS. MITS includes
170,400 independently collected real-world ITS images sourced from traffic
surveillance cameras, annotated with eight main categories and 24 subcategories
of ITS-specific objects and events under diverse environmental conditions.
Additionally, through a systematic data generation pipeline, we generate
high-quality image captions and 5 million instruction-following visual
question-answer pairs, addressing five critical ITS tasks: object and event
recognition, object counting, object localization, background analysis, and
event reasoning. To demonstrate MITS's effectiveness, we fine-tune mainstream
LMMs on this dataset, enabling the development of ITS-specific applications.
Experimental results show that MITS significantly improves LMM performance in
ITS applications, increasing LLaVA-1.5's performance from 0.494 to 0.905
(+83.2%), LLaVA-1.6's from 0.678 to 0.921 (+35.8%), Qwen2-VL's from 0.584 to
0.926 (+58.6%), and Qwen2.5-VL's from 0.732 to 0.930 (+27.0%). We release the
dataset, code, and models as open-source, providing high-value resources to
advance both ITS and LMM research.

</details>


### [5] [Decomposing Visual Classification: Assessing Tree-Based Reasoning in VLMs](https://arxiv.org/abs/2509.09732)
*Sary Elmansoury,Islam Mesabah,Gerrit Großmann,Peter Neigel,Raj Bhalwankar,Daniel Kondermann,Sebastian J. Vollmer*

Main category: cs.CV

TL;DR: 研究探讨了树状结构推理是否能提升视觉语言模型（VLM）在细粒度任务中的表现，发现其效果不如标准零样本提示，但通过LLM生成的描述可以提升性能。


<details>
  <summary>Details</summary>
Motivation: 探索结构化、树状推理是否能增强VLM在细粒度和粗粒度分类任务中的表现。

Method: 提出一个框架，将分类任务分解为基于决策树的可解释决策，并在GTSRB和CIFAR-10数据集上评估。

Result: 树状推理表现不如标准零样本提示，但通过LLM生成的类别和图像描述可以提升性能。

Conclusion: 结构化推理在视觉分类中存在局限性，但为设计更可解释的VLM系统提供了见解。

Abstract: Vision language models (VLMs) excel at zero-shot visual classification, but
their performance on fine-grained tasks and large hierarchical label spaces is
understudied. This paper investigates whether structured, tree-based reasoning
can enhance VLM performance. We introduce a framework that decomposes
classification into interpretable decisions using decision trees and evaluates
it on fine-grained (GTSRB) and coarse-grained (CIFAR-10) datasets. Although the
model achieves 98.2% accuracy in understanding the tree knowledge, tree-based
reasoning consistently underperforms standard zero-shot prompting. We also
explore enhancing the tree prompts with LLM-generated classes and image
descriptions to improve alignment. The added description enhances the
performance of the tree-based and zero-shot methods. Our findings highlight
limitations of structured reasoning in visual classification and offer insights
for designing more interpretable VLM systems.

</details>


### [6] [World Modeling with Probabilistic Structure Integration](https://arxiv.org/abs/2509.09737)
*Klemen Kotar,Wanhee Lee,Rahul Venkatesh,Honglin Chen,Daniel Bear,Jared Watrous,Simon Kim,Khai Loong Aw,Lilian Naing Chen,Stefan Stojanov,Kevin Feigelis,Imran Thobani,Alex Durango,Khaled Jedoui,Atlas Kazemian,Dan Yamins*

Main category: cs.CV

TL;DR: PSI是一种学习可控和可提示世界模型的系统，通过三步循环增强模型能力。


<details>
  <summary>Details</summary>
Motivation: 构建一个能从数据中学习并提取丰富结构的模型，以支持视频预测和理解任务。

Method: 采用三步循环：概率预测、结构提取和集成，逐步增强模型能力。

Result: 在1.4万亿视频数据上训练，实现了视频预测、光流、深度和分割等任务。

Conclusion: PSI通过循环增强结构提取和集成，显著提升了模型的预测和理解能力。

Abstract: We present Probabilistic Structure Integration (PSI), a system for learning
richly controllable and flexibly promptable world models from data. PSI
consists of a three-step cycle. The first step, Probabilistic prediction,
involves building a probabilistic graphical model Psi of the data, in the form
of a random-access autoregressive sequence model. Psi supports a complete set
of learned conditional distributions describing the dependence of any variables
in the data on any other set of variables. In step 2, Structure extraction, we
show how to extract underlying low-dimensional properties in the data,
corresponding to a diverse set of meaningful "intermediate structures", in a
zero-shot fashion via causal inference on Psi. Step 3, Integration, completes
the cycle by converting these structures into new token types that are then
continually mixed back into the training diet as conditioning signals and
prediction targets. Each such cycle augments the capabilities of Psi, both
allowing it to model the underlying data better, and creating new control
handles -- akin to an LLM-like universal prompting language. We train an
instance of Psi on 1.4 trillion tokens of internet video data; we use it to
perform a variety of useful video prediction and understanding inferences; we
extract state-of-the-art optical flow, self-supervised depth and object
segmentation; and we use these structures to support a full cycle of predictive
improvements.

</details>


### [7] [Images in Motion?: A First Look into Video Leakage in Collaborative Deep Learning](https://arxiv.org/abs/2509.09742)
*Md Fazle Rasul,Alanood Alqobaisi,Bruhadeshwar Bezawada,Indrakshi Ray*

Main category: cs.CV

TL;DR: 本文首次分析了联邦学习中视频数据的梯度反转攻击泄漏问题，发现特征提取器能提供更强的防御能力，但攻击仍可能发生。


<details>
  <summary>Details</summary>
Motivation: 研究视频数据在联邦学习中的隐私泄漏问题，填补现有研究空白。

Method: 评估两种视频分类方法：预训练特征提取器和原始视频帧处理，并测试梯度反转攻击效果。

Result: 特征提取器能增强防御，但攻击者仍可能通过超分辨率技术重建高质量视频。

Conclusion: 视频数据泄漏在联邦学习中是一个实际威胁，需进一步研究其发生条件。

Abstract: Federated learning (FL) allows multiple entities to train a shared model
collaboratively. Its core, privacy-preserving principle is that participants
only exchange model updates, such as gradients, and never their raw, sensitive
data. This approach is fundamental for applications in domains where privacy
and confidentiality are important. However, the security of this very mechanism
is threatened by gradient inversion attacks, which can reverse-engineer private
training data directly from the shared gradients, defeating the purpose of FL.
While the impact of these attacks is known for image, text, and tabular data,
their effect on video data remains an unexamined area of research. This paper
presents the first analysis of video data leakage in FL using gradient
inversion attacks. We evaluate two common video classification approaches: one
employing pre-trained feature extractors and another that processes raw video
frames with simple transformations. Our initial results indicate that the use
of feature extractors offers greater resilience against gradient inversion
attacks. We also demonstrate that image super-resolution techniques can enhance
the frames extracted through gradient inversion attacks, enabling attackers to
reconstruct higher-quality videos. Our experiments validate this across
scenarios where the attacker has access to zero, one, or more reference frames
from the target environment. We find that although feature extractors make
attacks more challenging, leakage is still possible if the classifier lacks
sufficient complexity. We, therefore, conclude that video data leakage in FL is
a viable threat, and the conditions under which it occurs warrant further
investigation.

</details>


### [8] [A Co-Training Semi-Supervised Framework Using Faster R-CNN and YOLO Networks for Object Detection in Densely Packed Retail Images](https://arxiv.org/abs/2509.09750)
*Hossein Yazdanjouei,Arash Mansouri,Mohammad Shokouhifar*

Main category: cs.CV

TL;DR: 提出了一种半监督协同训练框架，用于密集零售环境中的目标检测，结合Faster R-CNN和YOLO，通过伪标签交换提升准确性，并利用集成学习增强分类。


<details>
  <summary>Details</summary>
Motivation: 解决零售环境中标注数据有限和复杂条件（如遮挡和重叠物体）带来的挑战。

Method: 结合Faster R-CNN（ResNet骨干）和YOLO（Darknet骨干）进行伪标签交换，使用XGBoost、随机森林和SVM的集成学习进行分类，并通过元启发式算法优化超参数。

Result: 在SKU-110k数据集上表现优异，展示了框架的可扩展性和实用性。

Conclusion: 该框架减少了标注成本，适应零售环境中的频繁变化，适用于自动化库存跟踪等实际应用。

Abstract: This study proposes a semi-supervised co-training framework for object
detection in densely packed retail environments, where limited labeled data and
complex conditions pose major challenges. The framework combines Faster R-CNN
(utilizing a ResNet backbone) for precise localization with YOLO (employing a
Darknet backbone) for global context, enabling mutual pseudo-label exchange
that improves accuracy in scenes with occlusion and overlapping objects. To
strengthen classification, it employs an ensemble of XGBoost, Random Forest,
and SVM, utilizing diverse feature representations for higher robustness.
Hyperparameters are optimized using a metaheuristic-driven algorithm, enhancing
precision and efficiency across models. By minimizing reliance on manual
labeling, the approach reduces annotation costs and adapts effectively to
frequent product and layout changes common in retail. Experiments on the
SKU-110k dataset demonstrate strong performance, highlighting the scalability
and practicality of the proposed framework for real-world retail applications
such as automated inventory tracking, product monitoring, and checkout systems.

</details>


### [9] [Purge-Gate: Backpropagation-Free Test-Time Adaptation for Point Clouds Classification via Token Purging](https://arxiv.org/abs/2509.09785)
*Moslem Yazdanpanah,Ali Bahri,Mehrdad Noori,Sahar Dastani,Gustavo Adolfo Vargas Hakim,David Osowiechi,Ismail Ben Ayed,Christian Desrosiers*

Main category: cs.CV

TL;DR: Token Purging (PG) 是一种无需反向传播的测试时适应方法，通过移除受域偏移影响的token提升3D点云分类性能。


<details>
  <summary>Details</summary>
Motivation: 解决分布偏移导致的性能下降问题，提供无需迭代更新的鲁棒适应方法。

Method: 提出PG-SP（利用源统计）和PG-SF（完全无源，依赖CLS-token）两种变体，在token级别操作。

Result: PG-SP比现有方法准确率高10.3%，PG-SF在无源适应中表现最佳；PG速度提升12.4倍，内存效率提高5.5倍。

Conclusion: PG是一种高效、内存友好的测试时适应方法，适用于实际部署。

Abstract: Test-time adaptation (TTA) is crucial for mitigating performance degradation
caused by distribution shifts in 3D point cloud classification. In this work,
we introduce Token Purging (PG), a novel backpropagation-free approach that
removes tokens highly affected by domain shifts before they reach attention
layers. Unlike existing TTA methods, PG operates at the token level, ensuring
robust adaptation without iterative updates. We propose two variants: PG-SP,
which leverages source statistics, and PG-SF, a fully source-free version
relying on CLS-token-driven adaptation. Extensive evaluations on ModelNet40-C,
ShapeNet-C, and ScanObjectNN-C demonstrate that PG-SP achieves an average of
+10.3\% higher accuracy than state-of-the-art backpropagation-free methods,
while PG-SF sets new benchmarks for source-free adaptation. Moreover, PG is
12.4 times faster and 5.5 times more memory efficient than our baseline, making
it suitable for real-world deployment. Code is available at
\hyperlink{https://github.com/MosyMosy/Purge-Gate}{https://github.com/MosyMosy/Purge-Gate}

</details>


### [10] [Fine-Grained Cross-View Localization via Local Feature Matching and Monocular Depth Priors](https://arxiv.org/abs/2509.09792)
*Zimin Xia,Chenghao Xu,Alexandre Alahi*

Main category: cs.CV

TL;DR: 提出了一种高精度且可解释的细粒度跨视角定位方法，通过匹配地面图像与参考航拍图像的局部特征来估计3自由度姿态。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将地面图像转换为鸟瞰图（BEV）表示，再与航拍图像对齐，但这一转换常因透视失真或高度信息压缩导致信息丢失，影响对齐质量。

Method: 直接建立地面与航拍图像的对应关系，仅将匹配的关键点提升到BEV空间，利用单目深度先验，支持度量深度和相对深度，并通过尺度感知的Procrustes对齐估计相机姿态。

Result: 实验表明，仅需弱监督相机姿态，该方法能学习准确的局部特征对应关系，在跨区域泛化和未知方向等挑战性条件下表现优越。

Conclusion: 该方法兼容多种相对深度模型且无需微调，结合强大的定位性能，适合实际部署。

Abstract: We propose an accurate and highly interpretable fine-grained cross-view
localization method that estimates the 3 Degrees of Freedom pose of a
ground-level image by matching its local features with a reference aerial
image. Previous methods typically transform the ground image into a bird's-eye
view (BEV) representation and then align it with the aerial image for
localization. However, this transformation often leads to information loss due
to perspective distortion or compression of height information, thereby
degrading alignment quality with the aerial view. In contrast, our method
directly establishes correspondences between ground and aerial images and lifts
only the matched keypoints to BEV space using monocular depth prior. Notably,
modern depth predictors can provide reliable metric depth when the test samples
are similar to the training data. When the depth distribution differs, they
still produce consistent relative depth, i.e., depth accurate up to an unknown
scale. Our method supports both metric and relative depth. It employs a
scale-aware Procrustes alignment to estimate the camera pose from the
correspondences and optionally recover the scale when using relative depth.
Experimental results demonstrate that, with only weak supervision on camera
pose, our method learns accurate local feature correspondences and achieves
superior localization performance under challenging conditions, such as
cross-area generalization and unknown orientation. Moreover, our method is
compatible with various relative depth models without requiring per-model
finetuning. This flexibility, combined with strong localization performance,
makes it well-suited for real-world deployment.

</details>


### [11] [Early Detection of Visual Impairments at Home Using a Smartphone Red-Eye Reflex Test](https://arxiv.org/abs/2509.09808)
*Judith Massmann,Alexander Lichtenstein,Francisco M. López*

Main category: cs.CV

TL;DR: 利用智能手机和AI技术开发了一款免费应用KidsVisionCheck，通过红眼反射图像进行儿童视力筛查，准确率达90%。


<details>
  <summary>Details</summary>
Motivation: 传统Bruckner测试需专业设备，智能手机和AI的发展使其可在移动设备上实现，提高筛查可及性。

Method: 基于眼科医生标记的儿童瞳孔图像训练深度神经网络模型。

Result: 模型在未见测试数据上准确率达90%，并能优化数据收集条件。

Conclusion: 该研究为全球儿童视力筛查和早期干预迈出重要一步。

Abstract: Numerous visual impairments can be detected in red-eye reflex images from
young children. The so-called Bruckner test is traditionally performed by
ophthalmologists in clinical settings. Thanks to the recent technological
advances in smartphones and artificial intelligence, it is now possible to
recreate the Bruckner test using a mobile device. In this paper, we present a
first study conducted during the development of KidsVisionCheck, a free
application that can perform vision screening with a mobile device using
red-eye reflex images. The underlying model relies on deep neural networks
trained on children's pupil images collected and labeled by an ophthalmologist.
With an accuracy of 90% on unseen test data, our model provides highly reliable
performance without the necessity of specialist equipment. Furthermore, we can
identify the optimal conditions for data collection, which can in turn be used
to provide immediate feedback to the users. In summary, this work marks a first
step toward accessible pediatric vision screenings and early intervention for
vision abnormalities worldwide.

</details>


### [12] [DGFusion: Depth-Guided Sensor Fusion for Robust Semantic Perception](https://arxiv.org/abs/2509.09828)
*Tim Broedermannn,Christos Sakaridis,Luigi Piccinelli,Wim Abbeloos,Luc Van Gool*

Main category: cs.CV

TL;DR: 提出了一种基于深度引导的多模态融合方法DGFusion，通过深度信息动态调整传感器融合，提升了自动驾驶语义感知的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有传感器融合方法在空间上均匀处理数据，难以应对复杂条件，需改进。

Method: 利用激光雷达数据作为输入和深度学习的真值，引入局部深度标记和全局条件标记动态调整融合。

Result: 在MUSES和DELIVER数据集上实现了最先进的语义和全景分割性能。

Conclusion: DGFusion通过深度感知特征和动态融合策略，显著提升了复杂条件下的语义感知能力。

Abstract: Robust semantic perception for autonomous vehicles relies on effectively
combining multiple sensors with complementary strengths and weaknesses.
State-of-the-art sensor fusion approaches to semantic perception often treat
sensor data uniformly across the spatial extent of the input, which hinders
performance when faced with challenging conditions. By contrast, we propose a
novel depth-guided multimodal fusion method that upgrades condition-aware
fusion by integrating depth information. Our network, DGFusion, poses
multimodal segmentation as a multi-task problem, utilizing the lidar
measurements, which are typically available in outdoor sensor suites, both as
one of the model's inputs and as ground truth for learning depth. Our
corresponding auxiliary depth head helps to learn depth-aware features, which
are encoded into spatially varying local depth tokens that condition our
attentive cross-modal fusion. Together with a global condition token, these
local depth tokens dynamically adapt sensor fusion to the spatially varying
reliability of each sensor across the scene, which largely depends on depth. In
addition, we propose a robust loss for our depth, which is essential for
learning from lidar inputs that are typically sparse and noisy in adverse
conditions. Our method achieves state-of-the-art panoptic and semantic
segmentation performance on the challenging MUSES and DELIVER datasets. Code
and models will be available at https://github.com/timbroed/DGFusion

</details>


### [13] [Patch-based Automatic Rosacea Detection Using the ResNet Deep Learning Framework](https://arxiv.org/abs/2509.09841)
*Chengyu Yang,Rishik Reddy Yesgari,Chengjun Liu*

Main category: cs.CV

TL;DR: 提出基于ResNet-18的局部图像块自动检测酒渣鼻策略，提升检测精度和隐私保护。


<details>
  <summary>Details</summary>
Motivation: 酒渣鼻是一种慢性炎症性皮肤病，早期精确检测对治疗至关重要。

Method: 从面部图像提取不同大小、形状和位置的图像块，评估局部视觉信息对深度学习模型性能的影响。

Result: 实验表明，基于图像块的策略在准确性和敏感性上优于全图像方法，同时保护患者隐私。

Conclusion: 该策略为自动化皮肤病诊断提供了实用改进方向。

Abstract: Rosacea, which is a chronic inflammatory skin condition that manifests with
facial redness, papules, and visible blood vessels, often requirs precise and
early detection for significantly improving treatment effectiveness. This paper
presents new patch-based automatic rosacea detection strategies using the
ResNet-18 deep learning framework. The contributions of the proposed strategies
come from the following aspects. First, various image pateches are extracted
from the facial images of people in different sizes, shapes, and locations.
Second, a number of investigation studies are carried out to evaluate how the
localized visual information influences the deep learing model performance.
Third, thorough experiments are implemented to reveal that several patch-based
automatic rosacea detection strategies achieve competitive or superior accuracy
and sensitivity than the full-image based methods. And finally, the proposed
patch-based strategies, which use only localized patches, inherently preserve
patient privacy by excluding any identifiable facial features from the data.
The experimental results indicate that the proposed patch-based strategies
guide the deep learning model to focus on clinically relevant regions, enhance
robustness and interpretability, and protect patient privacy. As a result, the
proposed strategies offer practical insights for improving automated
dermatological diagnostics.

</details>


### [14] [Privacy-Preserving Automated Rosacea Detection Based on Medically Inspired Region of Interest Selection](https://arxiv.org/abs/2509.09844)
*Chengyu Yang,Rishik Reddy Yesgari,Chengjun Liu*

Main category: cs.CV

TL;DR: 提出了一种基于合成数据和临床先验的隐私保护玫瑰痤疮自动检测方法，通过固定红斑掩膜和ResNet-18模型，在真实测试数据上表现优于全脸基线。


<details>
  <summary>Details</summary>
Motivation: 玫瑰痤疮诊断困难，现有方法因症状分散、标记数据稀缺和隐私问题受限。

Method: 构建红斑掩膜聚焦诊断相关区域，使用ResNet-18在合成数据上训练。

Result: 在真实测试数据上准确率、召回率和F1分数显著提升。

Conclusion: 合成数据和临床先验可支持准确且伦理的皮肤病AI系统，适用于远程医疗和大规模筛查。

Abstract: Rosacea is a common but underdiagnosed inflammatory skin condition that
primarily affects the central face and presents with subtle redness, pustules,
and visible blood vessels. Automated detection remains challenging due to the
diffuse nature of symptoms, the scarcity of labeled datasets, and privacy
concerns associated with using identifiable facial images. A novel
privacy-preserving automated rosacea detection method inspired by clinical
priors and trained entirely on synthetic data is presented in this paper.
Specifically, the proposed method, which leverages the observation that rosacea
manifests predominantly through central facial erythema, first constructs a
fixed redness-informed mask by selecting regions with consistently high red
channel intensity across facial images. The mask thus is able to focus on
diagnostically relevant areas such as the cheeks, nose, and forehead and
exclude identity-revealing features. Second, the ResNet-18 deep learning
method, which is trained on the masked synthetic images, achieves superior
performance over the full-face baselines with notable gains in terms of
accuracy, recall and F1 score when evaluated using the real-world test data.
The experimental results demonstrate that the synthetic data and clinical
priors can jointly enable accurate and ethical dermatological AI systems,
especially for privacy sensitive applications in telemedicine and large-scale
screening.

</details>


### [15] [Investigating the Impact of Various Loss Functions and Learnable Wiener Filter for Laparoscopic Image Desmoking](https://arxiv.org/abs/2509.09849)
*Chengyu Yang,Chengjun Liu*

Main category: cs.CV

TL;DR: 本文通过消融研究评估了ULW框架中各组件对腹腔镜图像去烟雾效果的贡献。


<details>
  <summary>Details</summary>
Motivation: 验证ULW框架中各个组件的有效性和必要性，以优化其性能。

Method: 通过系统性地移除学习型Wiener滤波器或选择性使用复合损失函数中的单个损失项，进行消融实验。

Result: 使用定量指标（SSIM、PSNR、MSE和CIEDE-2000）和定性视觉比较，评估各变体的性能。

Conclusion: 消融研究揭示了各组件对ULW框架整体性能的具体贡献，为优化设计提供了依据。

Abstract: To rigorously assess the effectiveness and necessity of individual components
within the recently proposed ULW framework for laparoscopic image desmoking,
this paper presents a comprehensive ablation study. The ULW approach combines a
U-Net based backbone with a compound loss function that comprises mean squared
error (MSE), structural similarity index (SSIM) loss, and perceptual loss. The
framework also incorporates a differentiable, learnable Wiener filter module.
In this study, each component is systematically ablated to evaluate its
specific contribution to the overall performance of the whole framework. The
analysis includes: (1) removal of the learnable Wiener filter, (2) selective
use of individual loss terms from the composite loss function. All variants are
benchmarked on a publicly available paired laparoscopic images dataset using
quantitative metrics (SSIM, PSNR, MSE and CIEDE-2000) alongside qualitative
visual comparisons.

</details>


### [16] [WAVE-DETR Multi-Modal Visible and Acoustic Real-Life Drone Detector](https://arxiv.org/abs/2509.09859)
*Razvan Stefanescu,Ethan Oh,Ruben Vazquez,Chris Mesterharm,Constantin Serban,Ritu Chadha*

Main category: cs.CV

TL;DR: WAVE-DETR结合RGB和声学信号的多模态无人机检测器，通过融合视觉和声学特征提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 利用多模态信息（RGB和声学）提升无人机检测在复杂环境中的鲁棒性。

Method: 结合Deformable DETR和Wav2Vec2架构，测试了四种融合配置（门控机制、线性层、MLP和交叉注意力）。

Result: 最佳门控融合方法在小无人机上mAP提升11.1%-15.3%，中大型无人机也有3.27%-5.84%的提升。

Conclusion: 多模态融合显著提升无人机检测性能，尤其在复杂环境中表现优异。

Abstract: We introduce a multi-modal WAVE-DETR drone detector combining visible RGB and
acoustic signals for robust real-life UAV object detection. Our approach fuses
visual and acoustic features in a unified object detector model relying on the
Deformable DETR and Wav2Vec2 architectures, achieving strong performance under
challenging environmental conditions. Our work leverage the existing
Drone-vs-Bird dataset and the newly generated ARDrone dataset containing more
than 7,500 synchronized images and audio segments. We show how the acoustic
information is used to improve the performance of the Deformable DETR object
detector on the real ARDrone dataset. We developed, trained and tested four
different fusion configurations based on a gated mechanism, linear layer, MLP
and cross attention. The Wav2Vec2 acoustic embeddings are fused with the multi
resolution feature mappings of the Deformable DETR and enhance the object
detection performance over all drones dimensions. The best performer is the
gated fusion approach, which improves the mAP of the Deformable DETR object
detector on our in-distribution and out-of-distribution ARDrone datasets by
11.1% to 15.3% for small drones across all IoU thresholds between 0.5 and 0.9.
The mAP scores for medium and large drones are also enhanced, with overall
gains across all drone sizes ranging from 3.27% to 5.84%.

</details>


### [17] [Surrogate Supervision for Robust and Generalizable Deformable Image Registration](https://arxiv.org/abs/2509.09869)
*Yihao Liu,Junyu Chen,Lianrui Zuo,Shuwen Wei,Brian D. Boyd,Carmen Andreescu,Olusola Ajilore,Warren D. Taylor,Aaron Carass,Bennett A. Landman*

Main category: cs.CV

TL;DR: 提出了一种名为“替代监督”的训练范式，通过将输入域与监督域解耦，提高了深度学习图像配准网络的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法对输入图像特性（如伪影、视场不匹配或模态差异）敏感，需要一种更鲁棒和通用的训练方法。

Method: 引入替代监督，通过将估计的空间变换应用于替代图像，实现在异质输入上训练，同时确保监督在相似性定义明确的域中计算。

Result: 在多种任务中，替代监督表现出对输入变化的强韧性，同时保持了在高质量数据上的高性能。

Conclusion: 替代监督为训练鲁棒且通用的深度学习配准模型提供了原则性框架，无需增加复杂性。

Abstract: Objective: Deep learning-based deformable image registration has achieved
strong accuracy, but remains sensitive to variations in input image
characteristics such as artifacts, field-of-view mismatch, or modality
difference. We aim to develop a general training paradigm that improves the
robustness and generalizability of registration networks. Methods: We introduce
surrogate supervision, which decouples the input domain from the supervision
domain by applying estimated spatial transformations to surrogate images. This
allows training on heterogeneous inputs while ensuring supervision is computed
in domains where similarity is well defined. We evaluate the framework through
three representative applications: artifact-robust brain MR registration,
mask-agnostic lung CT registration, and multi-modal MR registration. Results:
Across tasks, surrogate supervision demonstrated strong resilience to input
variations including inhomogeneity field, inconsistent field-of-view, and
modality differences, while maintaining high performance on well-curated data.
Conclusions: Surrogate supervision provides a principled framework for training
robust and generalizable deep learning-based registration models without
increasing complexity. Significance: Surrogate supervision offers a practical
pathway to more robust and generalizable medical image registration, enabling
broader applicability in diverse biomedical imaging scenarios.

</details>


### [18] [An Autoencoder and Vision Transformer-based Interpretability Analysis of the Differences in Automated Staging of Second and Third Molars](https://arxiv.org/abs/2509.09911)
*Barkin Buyukcakir,Jannick De Tobel,Patrick Thevissen,Dirk Vandermeulen,Peter Claes*

Main category: cs.CV

TL;DR: 论文提出了一种结合卷积自编码器和Vision Transformer的框架，用于提高牙齿年龄估计的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 深度学习在法医应用中的实际采用常受限于模型的'黑箱'特性，尤其是在牙齿年龄估计等高风险领域。

Method: 使用卷积自编码器（AE）和Vision Transformer（ViT）结合的框架，分析牙齿37和38的分类性能。

Result: 分类准确率显著提升，牙齿37从0.712提高到0.815，牙齿38从0.462提高到0.543。

Conclusion: 该框架不仅提高了性能，还通过多角度诊断揭示了数据问题，为法医年龄估计提供了更可靠的工具。

Abstract: The practical adoption of deep learning in high-stakes forensic applications,
such as dental age estimation, is often limited by the 'black box' nature of
the models. This study introduces a framework designed to enhance both
performance and transparency in this context. We use a notable performance
disparity in the automated staging of mandibular second (tooth 37) and third
(tooth 38) molars as a case study. The proposed framework, which combines a
convolutional autoencoder (AE) with a Vision Transformer (ViT), improves
classification accuracy for both teeth over a baseline ViT, increasing from
0.712 to 0.815 for tooth 37 and from 0.462 to 0.543 for tooth 38. Beyond
improving performance, the framework provides multi-faceted diagnostic
insights. Analysis of the AE's latent space metrics and image reconstructions
indicates that the remaining performance gap is data-centric, suggesting high
intra-class morphological variability in the tooth 38 dataset is a primary
limiting factor. This work highlights the insufficiency of relying on a single
mode of interpretability, such as attention maps, which can appear anatomically
plausible yet fail to identify underlying data issues. By offering a
methodology that both enhances accuracy and provides evidence for why a model
may be uncertain, this framework serves as a more robust tool to support expert
decision-making in forensic age estimation.

</details>


### [19] [SCoDA: Self-supervised Continual Domain Adaptation](https://arxiv.org/abs/2509.09935)
*Chirayu Agrawal,Snehasis Mukherjee*

Main category: cs.CV

TL;DR: SCoDA提出了一种无需源域数据的自监督持续域适应方法，通过几何流形对齐和EMA更新教师模型参数，显著优于现有SFDA方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有SFDA方法因依赖余弦相似度而丢失几何信息的问题，并避免对监督预训练的依赖。

Method: 使用自监督预训练的教师模型，结合实例级特征匹配和空间相似性损失，通过EMA更新教师参数。

Result: 在基准数据集上显著优于现有SFDA方法。

Conclusion: SCoDA通过几何流形对齐和自监督预训练，有效提升了SFDA的性能。

Abstract: Source-Free Domain Adaptation (SFDA) addresses the challenge of adapting a
model to a target domain without access to the data of the source domain.
Prevailing methods typically start with a source model pre-trained with full
supervision and distill the knowledge by aligning instance-level features.
However, these approaches, relying on cosine similarity over L2-normalized
feature vectors, inadvertently discard crucial geometric information about the
latent manifold of the source model. We introduce Self-supervised Continual
Domain Adaptation (SCoDA) to address these limitations. We make two key
departures from standard practice: first, we avoid the reliance on supervised
pre-training by initializing the proposed framework with a teacher model
pre-trained entirely via self-supervision (SSL). Second, we adapt the principle
of geometric manifold alignment to the SFDA setting. The student is trained
with a composite objective combining instance-level feature matching with a
Space Similarity Loss. To combat catastrophic forgetting, the teacher's
parameters are updated via an Exponential Moving Average (EMA) of the student's
parameters. Extensive experiments on benchmark datasets demonstrate that SCoDA
significantly outperforms state-of-the-art SFDA methods.

</details>


### [20] [Segment Anything for Cell Tracking](https://arxiv.org/abs/2509.09943)
*Zhu Chen,Mert Edgü,Er Jin,Johannes Stegmaier*

Main category: cs.CV

TL;DR: 提出了一种零样本细胞追踪框架，结合SAM2模型，无需训练数据即可通用化处理多种显微镜数据。


<details>
  <summary>Details</summary>
Motivation: 解决现有深度学习方法依赖标注数据、泛化能力差的问题。

Method: 集成Segment Anything 2 (SAM2)模型，实现完全无监督的细胞追踪。

Result: 在2D和3D显微镜视频中达到竞争性精度，无需数据集适配。

Conclusion: 该方法无需训练数据，能有效泛化到多样化的显微镜数据集。

Abstract: Tracking cells and detecting mitotic events in time-lapse microscopy image
sequences is a crucial task in biomedical research. However, it remains highly
challenging due to dividing objects, low signal-tonoise ratios, indistinct
boundaries, dense clusters, and the visually similar appearance of individual
cells. Existing deep learning-based methods rely on manually labeled datasets
for training, which is both costly and time-consuming. Moreover, their
generalizability to unseen datasets remains limited due to the vast diversity
of microscopy data. To overcome these limitations, we propose a zero-shot cell
tracking framework by integrating Segment Anything 2 (SAM2), a large foundation
model designed for general image and video segmentation, into the tracking
pipeline. As a fully-unsupervised approach, our method does not depend on or
inherit biases from any specific training dataset, allowing it to generalize
across diverse microscopy datasets without finetuning. Our approach achieves
competitive accuracy in both 2D and large-scale 3D time-lapse microscopy videos
while eliminating the need for dataset-specific adaptation.

</details>


### [21] [Online 3D Multi-Camera Perception through Robust 2D Tracking and Depth-based Late Aggregation](https://arxiv.org/abs/2509.09946)
*Vu-Minh Le,Thao-Anh Tran,Duc Huy Do,Xuan Canh Do,Huong Ninh,Hai Tran*

Main category: cs.CV

TL;DR: 提出了一种将2D多摄像头跟踪系统扩展到3D空间的方法，利用深度信息重建目标点云，并通过聚类和偏航细化恢复3D框。


<details>
  <summary>Details</summary>
Motivation: 现有MTMC系统难以直接从2D跟踪升级到3D跟踪，需保留现有2D系统功能。

Method: 利用深度信息重建目标点云，通过聚类和偏航细化恢复3D框，并引入增强的在线数据关联机制。

Result: 在2025 AI City Challenge的3D MTMC数据集上取得第3名。

Conclusion: 该方法成功将2D跟踪系统扩展到3D空间，保留了现有系统的功能。

Abstract: Multi-Target Multi-Camera Tracking (MTMC) is an essential computer vision
task for automating large-scale surveillance. With camera calibration and depth
information, the targets in the scene can be projected into 3D space, offering
unparalleled levels of automatic perception of a 3D environment. However,
tracking in the 3D space requires replacing all 2D tracking components from the
ground up, which may be infeasible for existing MTMC systems. In this paper, we
present an approach for extending any online 2D multi-camera tracking system
into 3D space by utilizing depth information to reconstruct a target in
point-cloud space, and recovering its 3D box through clustering and yaw
refinement following tracking. We also introduced an enhanced online data
association mechanism that leverages the target's local ID consistency to
assign global IDs across frames. The proposed framework is evaluated on the
2025 AI City Challenge's 3D MTMC dataset, achieving 3rd place on the
leaderboard.

</details>


### [22] [Zero-Shot Referring Expression Comprehension via Visual-Language True/False Verification](https://arxiv.org/abs/2509.09958)
*Jeffrey Liu,Rongbin Hu*

Main category: cs.CV

TL;DR: 零样本工作流在Referring Expression Comprehension (REC)任务中表现优异，无需任务特定训练。


<details>
  <summary>Details</summary>
Motivation: 探索零样本方法在REC任务中的潜力，减少对任务特定训练的依赖。

Method: 将REC重新定义为基于视觉语言验证的框级检测，使用通用检测器和VLM独立验证每个区域。

Result: 在多个数据集上超越零样本基线，甚至优于经过任务训练的模型。

Conclusion: 工作流设计而非任务特定预训练是零样本REC性能的关键。

Abstract: Referring Expression Comprehension (REC) is usually addressed with
task-trained grounding models. We show that a zero-shot workflow, without any
REC-specific training, can achieve competitive or superior performance. Our
approach reformulates REC as box-wise visual-language verification: given
proposals from a COCO-clean generic detector (YOLO-World), a general-purpose
VLM independently answers True/False queries for each region. This simple
procedure reduces cross-box interference, supports abstention and multiple
matches, and requires no fine-tuning. On RefCOCO, RefCOCO+, and RefCOCOg, our
method not only surpasses a zero-shot GroundingDINO baseline but also exceeds
reported results for GroundingDINO trained on REC and GroundingDINO+CRG.
Controlled studies with identical proposals confirm that verification
significantly outperforms selection-based prompting, and results hold with open
VLMs. Overall, we show that workflow design, rather than task-specific
pretraining, drives strong zero-shot REC performance.

</details>


### [23] [Augment to Segment: Tackling Pixel-Level Imbalance in Wheat Disease and Pest Segmentation](https://arxiv.org/abs/2509.09961)
*Tianqi Wei,Xin Yu,Zhi Chen,Scott Chapman,Zi Huang*

Main category: cs.CV

TL;DR: 提出RPCP增强技术解决小麦叶片病虫害分割中的像素不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 病虫害像素占比极低导致分割性能下降，需解决像素不平衡问题。

Method: 提取病虫害区域，随机变换后粘贴至合适位置，并使用随机投影滤波器优化融合效果。

Result: 显著提升病虫害类别的分割性能，同时保持其他类别精度。

Conclusion: RPCP方法有效缓解像素不平衡问题，为农业分割提供简单高效解决方案。

Abstract: Accurate segmentation of foliar diseases and insect damage in wheat is
crucial for effective crop management and disease control. However, the insect
damage typically occupies only a tiny fraction of annotated pixels. This
extreme pixel-level imbalance poses a significant challenge to the segmentation
performance, which can result in overfitting to common classes and insufficient
learning of rare classes, thereby impairing overall performance. In this paper,
we propose a Random Projected Copy-and-Paste (RPCP) augmentation technique to
address the pixel imbalance problem. Specifically, we extract rare
insect-damage patches from annotated training images and apply random geometric
transformations to simulate variations. The transformed patches are then pasted
in appropriate regions while avoiding overlaps with lesions or existing damaged
regions. In addition, we apply a random projection filter to the pasted
regions, refining local features and ensuring a natural blend with the new
background. Experiments show that our method substantially improves
segmentation performance on the insect damage class, while maintaining or even
slightly enhancing accuracy on other categories. Our results highlight the
effectiveness of targeted augmentation in mitigating extreme pixel imbalance,
offering a straightforward yet effective solution for agricultural segmentation
problems.

</details>


### [24] [An HMM-based framework for identity-aware long-term multi-object tracking from sparse and uncertain identification: use case on long-term tracking in livestock](https://arxiv.org/abs/2509.09962)
*Anne Marthe Sophie Ngo Bibinbe,Chiron Bang,Patrick Gagnon,Jamie Ahloy-Dallaire,Eric R. Paquet*

Main category: cs.CV

TL;DR: 提出了一种结合不确定身份和跟踪的HMM框架，用于长期多目标跟踪，提高了跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 现有MOT方法在长期跟踪中因身份切换导致性能下降，而实际应用中可通过其他来源（如喂食器）获取部分对象的身份信息。

Method: 使用HMM框架结合不确定身份和跟踪，优化了ByteTrack等MOT方法。

Result: 在10分钟的猪跟踪数据集上提高了F1分数，并在MOT17和MOT20基准数据集上验证了性能提升。

Conclusion: HMM框架能有效提升长期MOT性能，且对身份不确定性具有鲁棒性。

Abstract: The need for long-term multi-object tracking (MOT) is growing due to the
demand for analyzing individual behaviors in videos that span several minutes.
Unfortunately, due to identity switches between objects, the tracking
performance of existing MOT approaches decreases over time, making them
difficult to apply for long-term tracking. However, in many real-world
applications, such as in the livestock sector, it is possible to obtain
sporadic identifications for some of the animals from sources like feeders. To
address the challenges of long-term MOT, we propose a new framework that
combines both uncertain identities and tracking using a Hidden Markov Model
(HMM) formulation. In addition to providing real-world identities to animals,
our HMM framework improves the F1 score of ByteTrack, a leading MOT approach
even with re-identification, on a 10 minute pig tracking dataset with 21
identifications at the pen's feeding station. We also show that our approach is
robust to the uncertainty of identifications, with performance increasing as
identities are provided more frequently. The improved performance of our HMM
framework was also validated on the MOT17 and MOT20 benchmark datasets using
both ByteTrack and FairMOT. The code for this new HMM framework and the new
10-minute pig tracking video dataset are available at:
https://github.com/ngobibibnbe/uncertain-identity-aware-tracking

</details>


### [25] [Event Camera Guided Visual Media Restoration & 3D Reconstruction: A Survey](https://arxiv.org/abs/2509.09971)
*Aupendu Kar,Vishnu Raj,Guan-Ming Su*

Main category: cs.CV

TL;DR: 该论文综述了事件相机与传统帧捕捉融合的进展，重点探讨了其在视频恢复和3D重建任务中的应用，并总结了深度学习在时空增强方面的贡献。


<details>
  <summary>Details</summary>
Motivation: 事件相机因其低延迟、低功耗和高捕获率等优势迅速发展，但其与传统帧捕捉的融合潜力尚未被充分探索。

Method: 系统回顾了深度学习在图像/视频增强和恢复中的主要贡献，分为时间增强（如帧插值和运动去模糊）和空间增强（如超分辨率和低光增强）。

Result: 总结了事件驱动融合在3D重建领域的进展，并提供了公开数据集列表以支持可重复研究。

Conclusion: 该综述旨在激发更多研究，探索事件相机与深度学习结合在视觉媒体恢复和增强中的应用。

Abstract: Event camera sensors are bio-inspired sensors which asynchronously capture
per-pixel brightness changes and output a stream of events encoding the
polarity, location and time of these changes. These systems are witnessing
rapid advancements as an emerging field, driven by their low latency, reduced
power consumption, and ultra-high capture rates. This survey explores the
evolution of fusing event-stream captured with traditional frame-based capture,
highlighting how this synergy significantly benefits various video restoration
and 3D reconstruction tasks. The paper systematically reviews major deep
learning contributions to image/video enhancement and restoration, focusing on
two dimensions: temporal enhancement (such as frame interpolation and motion
deblurring) and spatial enhancement (including super-resolution, low-light and
HDR enhancement, and artifact reduction). This paper also explores how the 3D
reconstruction domain evolves with the advancement of event driven fusion.
Diverse topics are covered, with in-depth discussions on recent works for
improving visual quality under challenging conditions. Additionally, the survey
compiles a comprehensive list of openly available datasets, enabling
reproducible research and benchmarking. By consolidating recent progress and
insights, this survey aims to inspire further research into leveraging event
camera systems, especially in combination with deep learning, for advanced
visual media restoration and enhancement.

</details>


### [26] [ISTASTrack: Bridging ANN and SNN via ISTA Adapter for RGB-Event Tracking](https://arxiv.org/abs/2509.09977)
*Siying Liu,Zikai Wang,Hanle Zheng,Yifan Hu,Xilin Wang,Qingkai Yang,Jibin Wu,Hao Guo,Lei Deng*

Main category: cs.CV

TL;DR: ISTASTrack是一种基于Transformer的ANN-SNN混合跟踪器，通过ISTA适配器实现RGB和事件数据的有效融合，提升了跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 现有ANN难以充分利用事件流的稀疏和异步特性，需要一种新的混合架构来融合RGB和事件数据。

Method: 采用双分支模型（视觉Transformer和脉冲Transformer），并设计ISTA适配器进行特征交互，结合时间下采样注意力模块。

Result: 在多个RGB-Event跟踪基准测试中达到SOTA性能，同时保持高能效。

Conclusion: ISTASTrack展示了混合ANN-SNN设计在视觉跟踪中的有效性和实用性。

Abstract: RGB-Event tracking has become a promising trend in visual object tracking to
leverage the complementary strengths of both RGB images and dynamic spike
events for improved performance. However, existing artificial neural networks
(ANNs) struggle to fully exploit the sparse and asynchronous nature of event
streams. Recent efforts toward hybrid architectures combining ANNs and spiking
neural networks (SNNs) have emerged as a promising solution in RGB-Event
perception, yet effectively fusing features across heterogeneous paradigms
remains a challenge. In this work, we propose ISTASTrack, the first
transformer-based \textbf{A}NN-\textbf{S}NN hybrid \textbf{Track}er equipped
with \textbf{ISTA} adapters for RGB-Event tracking. The two-branch model
employs a vision transformer to extract spatial context from RGB inputs and a
spiking transformer to capture spatio-temporal dynamics from event streams. To
bridge the modality and paradigm gap between ANN and SNN features, we
systematically design a model-based ISTA adapter for bidirectional feature
interaction between the two branches, derived from sparse representation theory
by unfolding the iterative shrinkage thresholding algorithm. Additionally, we
incorporate a temporal downsampling attention module within the adapter to
align multi-step SNN features with single-step ANN features in the latent
space, improving temporal fusion. Experimental results on RGB-Event tracking
benchmarks, such as FE240hz, VisEvent, COESOT, and FELT, have demonstrated that
ISTASTrack achieves state-of-the-art performance while maintaining high energy
efficiency, highlighting the effectiveness and practicality of hybrid ANN-SNN
designs for robust visual tracking. The code is publicly available at
https://github.com/lsying009/ISTASTrack.git.

</details>


### [27] [Efficient and Accurate Downfacing Visual Inertial Odometry](https://arxiv.org/abs/2509.10021)
*Jonas Kühne,Christian Vogt,Michele Magno,Luca Benini*

Main category: cs.CV

TL;DR: 提出了一种高效且准确的VIO（视觉惯性里程计）流程，适用于微型和纳米无人机，通过优化和量化特征检测与跟踪方法，在低功耗SoC上实现实时性能。


<details>
  <summary>Details</summary>
Motivation: 传统高精度VIO流程通常需要强大计算能力，而微型无人机等设备资源有限，因此需要一种轻量级且高效的实现方案。

Method: 结合SuperPoint、PX4FLOW和ORB等先进特征检测与跟踪方法，优化并量化以适应RISC-V低功耗SoC，同时采用刚体运动模型减少误差。

Result: 在GAP9低功耗SoC上，优化后的流程比基线流程的RMSE平均降低3.65倍；PX4FLOW在低速运动下与ORB精度相当但运行时间更短。

Conclusion: 该设计填补了高精度VIO与轻量级实现之间的空白，为资源受限设备提供了高效解决方案。

Abstract: Visual Inertial Odometry (VIO) is a widely used computer vision method that
determines an agent's movement through a camera and an IMU sensor. This paper
presents an efficient and accurate VIO pipeline optimized for applications on
micro- and nano-UAVs. The proposed design incorporates state-of-the-art feature
detection and tracking methods (SuperPoint, PX4FLOW, ORB), all optimized and
quantized for emerging RISC-V-based ultra-low-power parallel systems on chips
(SoCs). Furthermore, by employing a rigid body motion model, the pipeline
reduces estimation errors and achieves improved accuracy in planar motion
scenarios. The pipeline's suitability for real-time VIO is assessed on an
ultra-low-power SoC in terms of compute requirements and tracking accuracy
after quantization. The pipeline, including the three feature tracking methods,
was implemented on the SoC for real-world validation. This design bridges the
gap between high-accuracy VIO pipelines that are traditionally run on
computationally powerful systems and lightweight implementations suitable for
microcontrollers. The optimized pipeline on the GAP9 low-power SoC demonstrates
an average reduction in RMSE of up to a factor of 3.65x over the baseline
pipeline when using the ORB feature tracker. The analysis of the computational
complexity of the feature trackers further shows that PX4FLOW achieves on-par
tracking accuracy with ORB at a lower runtime for movement speeds below 24
pixels/frame.

</details>


### [28] [FLARE-SSM: Deep State Space Models with Influence-Balanced Loss for 72-Hour Solar Flare Prediction](https://arxiv.org/abs/2509.09988)
*Yusuke Takagi,Shunya Nagashima,Komei Sugiura*

Main category: cs.CV

TL;DR: 提出了一种基于多深度状态空间模型的太阳耀斑预测方法，并引入FLARE损失函数以解决类别不平衡问题，实验表明其优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 当前太阳耀斑预测性能不足，且现有方法未能有效处理耀斑类别的严重不平衡问题。

Method: 使用多深度状态空间模型，并设计FLARE损失函数（频率和局部边界感知可靠性损失）来提升预测性能和可靠性。

Result: 在覆盖11年太阳活动周期的多波长太阳图像数据集上，该方法在Gandin-Murphy-Gerrity分数和真实技能统计上优于基线方法。

Conclusion: 所提方法在太阳耀斑预测的性能和可靠性上表现优异，解决了类别不平衡问题。

Abstract: Accurate and reliable solar flare predictions are essential to mitigate
potential impacts on critical infrastructure. However, the current performance
of solar flare forecasting is insufficient. In this study, we address the task
of predicting the class of the largest solar flare expected to occur within the
next 72 hours. Existing methods often fail to adequately address the severe
class imbalance across flare classes. To address this issue, we propose a solar
flare prediction model based on multiple deep state space models. In addition,
we introduce the frequency & local-boundary-aware reliability loss (FLARE loss)
to improve predictive performance and reliability under class imbalance.
Experiments were conducted on a multi-wavelength solar image dataset covering a
full 11-year solar activity cycle. As a result, our method outperformed
baseline approaches in terms of both the Gandin-Murphy-Gerrity score and the
true skill statistic, which are standard metrics in terms of the performance
and reliability.

</details>


### [29] [TUNI: Real-time RGB-T Semantic Segmentation with Unified Multi-Modal Feature Extraction and Cross-Modal Feature Fusion](https://arxiv.org/abs/2509.10005)
*Xiaodong Guo,Tong Liu,Yike Li,Zi'ang Lin,Zhihong Deng*

Main category: cs.CV

TL;DR: TUNI是一种RGB-热成像语义分割模型，通过统一的多模态特征提取和融合模块，提升了性能和实时性。


<details>
  <summary>Details</summary>
Motivation: 现有模型在RGB和热成像特征提取及跨模态融合上表现不佳，且冗余的编码器影响实时效率。

Method: 提出TUNI，采用统一的RGB-T编码器，结合大规模预训练和局部模块增强跨模态特征融合。

Result: 在多个数据集上表现优异，参数和计算成本更低，实时推理速度达27 FPS。

Conclusion: TUNI在性能和效率上均优于现有方法，适合实时部署。

Abstract: RGB-thermal (RGB-T) semantic segmentation improves the environmental
perception of autonomous platforms in challenging conditions. Prevailing models
employ encoders pre-trained on RGB images to extract features from both RGB and
infrared inputs, and design additional modules to achieve cross-modal feature
fusion. This results in limited thermal feature extraction and suboptimal
cross-modal fusion, while the redundant encoders further compromises the
model's real-time efficiency. To address the above issues, we propose TUNI,
with an RGB-T encoder consisting of multiple stacked blocks that simultaneously
perform multi-modal feature extraction and cross-modal fusion. By leveraging
large-scale pre-training with RGB and pseudo-thermal data, the RGB-T encoder
learns to integrate feature extraction and fusion in a unified manner. By
slimming down the thermal branch, the encoder achieves a more compact
architecture. Moreover, we introduce an RGB-T local module to strengthen the
encoder's capacity for cross-modal local feature fusion. The RGB-T local module
employs adaptive cosine similarity to selectively emphasize salient consistent
and distinct local features across RGB-T modalities. Experimental results show
that TUNI achieves competitive performance with state-of-the-art models on FMB,
PST900 and CART, with fewer parameters and lower computational cost. Meanwhile,
it achieves an inference speed of 27 FPS on a Jetson Orin NX, demonstrating its
real-time capability in deployment. Codes are available at
https://github.com/xiaodonguo/TUNI.

</details>


### [30] [Few-Part-Shot Font Generation](https://arxiv.org/abs/2509.10006)
*Masaki Akiba,Shumpei Takezaki,Daichi Haraguchi,Seiichi Uchida*

Main category: cs.CV

TL;DR: 提出了一种基于部分设计元素的少部分字体生成模型，仅需输入部分形状即可生成完整字体。


<details>
  <summary>Details</summary>
Motivation: 传统少样本字体生成需要完整字符形状，而新方法仅需部分形状，旨在提高字体创建效率并探索部分设计细节对整体字符结构的影响。

Method: 设计了一个基于部分形状输入的字体生成模型。

Result: 模型不仅提高了字体创建效率，还揭示了部分设计细节对字符整体结构的影响。

Conclusion: 该模型为字体生成提供了更高效且深入的方法。

Abstract: This paper proposes a novel model of few-part-shot font generation, which
designs an entire font based on a set of partial design elements, i.e., partial
shapes. Unlike conventional few-shot font generation, which requires entire
character shapes for a couple of character classes, our approach only needs
partial shapes as input. The proposed model not only improves the efficiency of
font creation but also provides insights into how partial design details
influence the entire structure of the individual characters.

</details>


### [31] [Hierarchical MLANet: Multi-level Attention for 3D Face Reconstruction From Single Images](https://arxiv.org/abs/2509.10024)
*Danling Cao*

Main category: cs.CV

TL;DR: 提出了一种基于卷积神经网络的层次化多级注意力网络（MLANet），用于从单张野外图像重建3D人脸模型。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏真实标注数据集和复杂现实环境的挑战，从2D野外图像恢复3D人脸模型仍具难度。

Method: 采用预训练的层次化主干网络和多级注意力机制，结合半监督训练策略和可微分渲染器进行端到端训练。

Result: 在AFLW2000-3D和MICC Florence数据集上的实验表明，该方法在3D人脸重建和对齐任务中表现优异。

Conclusion: MLANet能够从单张图像预测详细的面部几何、纹理、姿态和光照参数，验证了其有效性。

Abstract: Recovering 3D face models from 2D in-the-wild images has gained considerable
attention in the computer vision community due to its wide range of potential
applications. However, the lack of ground-truth labeled datasets and the
complexity of real-world environments remain significant challenges. In this
chapter, we propose a convolutional neural network-based approach, the
Hierarchical Multi-Level Attention Network (MLANet), for reconstructing 3D face
models from single in-the-wild images. Our model predicts detailed facial
geometry, texture, pose, and illumination parameters from a single image.
Specifically, we employ a pre-trained hierarchical backbone network and
introduce multi-level attention mechanisms at different stages of 2D face image
feature extraction. A semi-supervised training strategy is employed,
incorporating 3D Morphable Model (3DMM) parameters from publicly available
datasets along with a differentiable renderer, enabling an end-to-end training
process. Extensive experiments, including both comparative and ablation
studies, were conducted on two benchmark datasets, AFLW2000-3D and MICC
Florence, focusing on 3D face reconstruction and 3D face alignment tasks. The
effectiveness of the proposed method was evaluated both quantitatively and
qualitatively.

</details>


### [32] [LaV-CoT: Language-Aware Visual CoT with Multi-Aspect Reward Optimization for Real-World Multilingual VQA](https://arxiv.org/abs/2509.10026)
*Jing Huang,Zhiya Tan,Shutao Gong,Fanwei Zeng,Jianshu Li*

Main category: cs.CV

TL;DR: LaV-CoT是一个多语言视觉思维链框架，通过多阶段推理和奖励优化显著提升多语言视觉问答性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖文本思维链，缺乏多语言多模态推理支持，限制了实际应用。

Method: 采用多阶段推理流程（文本摘要、语言识别、空间对象级描述和逐步逻辑推理），结合数据自动生成和两阶段训练（SFT和GRPO）。

Result: 在多个数据集上表现优异，准确率提升显著，甚至超越更大规模的模型和专有模型。

Conclusion: LaV-CoT在多语言视觉问答任务中表现出色，适合工业部署。

Abstract: As large vision language models (VLMs) advance, their capabilities in
multilingual visual question answering (mVQA) have significantly improved.
Chain-of-thought (CoT) reasoning has been proven to enhance interpretability
and complex reasoning. However, most existing approaches rely primarily on
textual CoT and provide limited support for multilingual multimodal reasoning,
constraining their deployment in real-world applications. To address this gap,
we introduce \textbf{LaV-CoT}, the first Language-aware Visual CoT framework
with Multi-Aspect Reward Optimization. LaV-CoT incorporates an interpretable
multi-stage reasoning pipeline consisting of Text Summary with Bounding Box
(BBox), Language Identification, Spatial Object-level Captioning, and
Step-by-step Logical Reasoning. Following this reasoning pipeline, we design an
automated data curation method that generates multilingual CoT annotations
through iterative generation, correction, and refinement, enabling scalable and
high-quality training data. To improve reasoning and generalization, LaV-CoT
adopts a two-stage training paradigm combining Supervised Fine-Tuning (SFT)
with Language-aware Group Relative Policy Optimization (GRPO), guided by
verifiable multi-aspect rewards including language consistency, structural
accuracy, and semantic alignment. Extensive evaluations on public datasets
including MMMB, Multilingual MMBench, and MTVQA show that LaV-CoT achieves up
to \(\sim\)9.5\% accuracy improvements over open-source baselines of similar
size and even surpasses models with 2$\times$ larger scales by \(\sim\)2.6\%.
Moreover, LaV-CoT outperforms advanced proprietary models such as GPT-4o-0513
and Gemini-2.5-flash. We further conducted an online A/B test to validate our
method on real-world data, highlighting its effectiveness for industrial
deployment. Our code is available at this link:
\href{https://github.com/HJNVR/LaV-CoT}

</details>


### [33] [Color Me Correctly: Bridging Perceptual Color Spaces and Text Embeddings for Improved Diffusion Generation](https://arxiv.org/abs/2509.10058)
*Sung-Lin Tsai,Bo-Lun Huang,Yu Ting Shen,Cheng Yu Yeo,Chiang Tseng,Bo-Kai Ruan,Wen-Sheng Lien,Hong-Han Shuai*

Main category: cs.CV

TL;DR: 提出一种无需训练的框架，通过大语言模型（LLM）解析模糊颜色描述，提升文本到图像生成中的颜色准确性。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型在处理复杂颜色描述时表现不佳，导致生成图像与人类意图不符，需要一种无需额外训练或参考图像的方法来提升颜色对齐。

Method: 利用LLM解析模糊颜色提示，并在CIELAB颜色空间中优化文本嵌入，直接指导颜色混合操作。

Result: 实验表明，该方法在不影响图像质量的情况下显著提升了颜色对齐效果。

Conclusion: 该框架有效弥合了文本语义与视觉生成之间的差距，无需额外训练即可实现高颜色保真度。

Abstract: Accurate color alignment in text-to-image (T2I) generation is critical for
applications such as fashion, product visualization, and interior design, yet
current diffusion models struggle with nuanced and compound color terms (e.g.,
Tiffany blue, lime green, hot pink), often producing images that are misaligned
with human intent. Existing approaches rely on cross-attention manipulation,
reference images, or fine-tuning but fail to systematically resolve ambiguous
color descriptions. To precisely render colors under prompt ambiguity, we
propose a training-free framework that enhances color fidelity by leveraging a
large language model (LLM) to disambiguate color-related prompts and guiding
color blending operations directly in the text embedding space. Our method
first employs a large language model (LLM) to resolve ambiguous color terms in
the text prompt, and then refines the text embeddings based on the spatial
relationships of the resulting color terms in the CIELAB color space. Unlike
prior methods, our approach improves color accuracy without requiring
additional training or external reference images. Experimental results
demonstrate that our framework improves color alignment without compromising
image quality, bridging the gap between text semantics and visual generation.

</details>


### [34] [Multimodal Mathematical Reasoning Embedded in Aerial Vehicle Imagery: Benchmarking, Analysis, and Exploration](https://arxiv.org/abs/2509.10059)
*Yue Zhou,Litong Feng,Mengcheng Lan,Xue Yang,Qingyun Li,Yiping Ke,Xue Jiang,Wayne Zhang*

Main category: cs.CV

TL;DR: AVI-Math是首个评估无人机遥感中多模态数学推理的基准，涵盖几何、逻辑和代数等领域，测试了14种VLMs，发现其在数学推理任务中表现不佳。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型（VLMs）在无人机遥感中的数学推理能力未得到充分测试，AVI-Math填补了这一空白。

Method: 构建包含3,773个无人机视角问题的数据集，覆盖6个数学主题和20个话题，并对14种VLMs进行综合评估。

Result: 现有VLMs在AVI-Math的数学推理任务中表现不佳，但Chain-of-Thought提示和微调技术显示出潜力。

Conclusion: 研究揭示了VLMs在数学推理中的局限性，并为未来无人机可信VLMs的发展提供了方向。

Abstract: Mathematical reasoning is critical for tasks such as precise distance and
area computations, trajectory estimations, and spatial analysis in unmanned
aerial vehicle (UAV) based remote sensing, yet current vision-language models
(VLMs) have not been adequately tested in this domain. To address this gap, we
introduce AVI-Math, the first benchmark to rigorously evaluate multimodal
mathematical reasoning in aerial vehicle imagery, moving beyond simple counting
tasks to include domain-specific knowledge in areas such as geometry, logic,
and algebra. The dataset comprises 3,773 high-quality vehicle-related questions
captured from UAV views, covering 6 mathematical subjects and 20 topics. The
data, collected at varying altitudes and from multiple UAV angles, reflects
real-world UAV scenarios, ensuring the diversity and complexity of the
constructed mathematical problems. In this paper, we benchmark 14 prominent
VLMs through a comprehensive evaluation and demonstrate that, despite their
success on previous multimodal benchmarks, these models struggle with the
reasoning tasks in AVI-Math. Our detailed analysis highlights significant
limitations in the mathematical reasoning capabilities of current VLMs and
suggests avenues for future research. Furthermore, we explore the use of
Chain-of-Thought prompting and fine-tuning techniques, which show promise in
addressing the reasoning challenges in AVI-Math. Our findings not only expose
the limitations of VLMs in mathematical reasoning but also offer valuable
insights for advancing UAV-based trustworthy VLMs in real-world applications.
The code, and datasets will be released at
https://github.com/VisionXLab/avi-math

</details>


### [35] [BEVTraj: Map-Free End-to-End Trajectory Prediction in Bird's-Eye View with Deformable Attention and Sparse Goal Proposals](https://arxiv.org/abs/2509.10080)
*Minsang Kong,Myeongjun Kim,Sang Gu Kang,Sang Hun Lee*

Main category: cs.CV

TL;DR: BEVTraj是一种新型的轨迹预测框架，直接在鸟瞰图（BEV）空间中使用实时传感器数据，无需依赖预建地图，性能与基于高清地图的模型相当。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖预建高清地图或实时局部地图构建模块，但这些方法无法适应瞬时变化或可能遗漏关键场景细节。

Method: BEVTraj利用可变形注意力从密集BEV特征中提取上下文，并引入稀疏目标候选提议（SGCP）模块实现端到端预测。

Result: 实验表明，BEVTraj性能与最先进的基于高清地图的模型相当，同时提供了更大的灵活性。

Conclusion: BEVTraj通过消除对预建地图的依赖，提供了一种更灵活且高效的轨迹预测解决方案。

Abstract: In autonomous driving, trajectory prediction is essential for ensuring safe
and efficient navigation. To improve prediction accuracy, recent approaches
often rely on pre-built high-definition (HD) maps or real-time local map
construction modules to incorporate static environmental information. However,
pre-built HD maps are limited to specific regions and cannot adapt to transient
changes. In addition, local map construction modules, which recognize only
predefined elements, may fail to capture critical scene details or introduce
errors that degrade prediction performance. To overcome these limitations, we
propose Bird's-Eye View Trajectory Prediction (BEVTraj), a novel trajectory
prediction framework that operates directly in the bird's-eye view (BEV) space
utilizing real-time sensor data without relying on any pre-built maps. The
BEVTraj leverages deformable attention to efficiently extract relevant context
from dense BEV features. Furthermore, we introduce a Sparse Goal Candidate
Proposal (SGCP) module, which enables full end-to-end prediction without
requiring any post-processing steps. Extensive experiments demonstrate that the
BEVTraj achieves performance comparable to state-of-the-art HD map-based models
while offering greater flexibility by eliminating the dependency on pre-built
maps. The source code is available at https://github.com/Kongminsang/bevtraj.

</details>


### [36] [Leveraging Multi-View Weak Supervision for Occlusion-Aware Multi-Human Parsing](https://arxiv.org/abs/2509.10093)
*Laura Bragagnolo,Matteo Terreran,Leonardo Barcellona,Stefano Ghidoni*

Main category: cs.CV

TL;DR: 提出了一种利用多视角信息改进多人体解析模型的方法，特别针对遮挡场景。


<details>
  <summary>Details</summary>
Motivation: 现有方法在人体重叠时表现不佳，多视角信息可能提供分离的视角。

Method: 结合弱监督和多视角一致性损失，提出半自动标注策略生成实例分割掩码。

Result: 在遮挡场景下，相对基线模型提升了4.20%的性能。

Conclusion: 多视角信息能有效提升遮挡情况下的多人体解析性能。

Abstract: Multi-human parsing is the task of segmenting human body parts while
associating each part to the person it belongs to, combining instance-level and
part-level information for fine-grained human understanding. In this work, we
demonstrate that, while state-of-the-art approaches achieved notable results on
public datasets, they struggle considerably in segmenting people with
overlapping bodies. From the intuition that overlapping people may appear
separated from a different point of view, we propose a novel training framework
exploiting multi-view information to improve multi-human parsing models under
occlusions. Our method integrates such knowledge during the training process,
introducing a novel approach based on weak supervision on human instances and a
multi-view consistency loss. Given the lack of suitable datasets in the
literature, we propose a semi-automatic annotation strategy to generate human
instance segmentation masks from multi-view RGB+D data and 3D human skeletons.
The experiments demonstrate that the approach can achieve up to a 4.20\%
relative improvement on human parsing over the baseline model in occlusion
scenarios.

</details>


### [37] [VARCO-VISION-2.0 Technical Report](https://arxiv.org/abs/2509.10105)
*Young-rok Cha,Jeongho Ju,SunYoung Park,Jong-Hyeon Lee,Younghyun Yu,Youngjune Kim*

Main category: cs.CV

TL;DR: VARCO-VISION-2.0是一个开源的韩英双语视觉语言模型，支持多图像理解和布局感知OCR，通过四阶段课程训练提升多模态对齐能力，并在基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 开发一个更强大的双语视觉语言模型，支持复杂输入（如文档、图表和表格）的多图像理解，并提升空间定位能力。

Method: 采用四阶段课程训练和内存高效技术，结合偏好优化提升安全性和语言能力。

Result: 14B模型在OpenCompass VLM排行榜上位列第8，同时发布了适用于设备部署的1.7B轻量版。

Conclusion: VARCO-VISION-2.0推动了双语视觉语言模型的发展，并提供了实际应用的优化版本。

Abstract: We introduce VARCO-VISION-2.0, an open-weight bilingual vision-language model
(VLM) for Korean and English with improved capabilities compared to the
previous model VARCO-VISION-14B. The model supports multi-image understanding
for complex inputs such as documents, charts, and tables, and delivers
layoutaware OCR by predicting both textual content and its spatial location.
Trained with a four-stage curriculum with memory-efficient techniques, the
model achieves enhanced multimodal alignment, while preserving core language
abilities and improving safety via preference optimization. Extensive benchmark
evaluations demonstrate strong spatial grounding and competitive results for
both languages, with the 14B model achieving 8th place on the OpenCompass VLM
leaderboard among models of comparable scale. Alongside the 14B-scale model, we
release a 1.7B version optimized for on-device deployment. We believe these
models advance the development of bilingual VLMs and their practical
applications. Two variants of VARCO-VISION-2.0 are available at Hugging Face: a
full-scale 14B model and a lightweight 1.7B model.

</details>


### [38] [A Lightweight Ensemble-Based Face Image Quality Assessment Method with Correlation-Aware Loss](https://arxiv.org/abs/2509.10114)
*MohammadAli Hamidi,Hadi Amirpour,Luigi Atzori,Christian Timmerer*

Main category: cs.CV

TL;DR: 提出了一种轻量级且高效的人脸图像质量评估方法，结合MobileNetV3-Small和ShuffleNetV2，通过简单平均进行预测级融合，使用MSECorrLoss损失函数提升与人类感知的一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的人脸图像质量评估方法要么无法捕捉人脸特有的退化，要么计算成本过高，限制了实际应用。

Method: 集成两个紧凑卷积神经网络（MobileNetV3-Small和ShuffleNetV2），采用预测级融合和MSECorrLoss损失函数。

Result: 在VQualA基准测试中，SRCC为0.9829，PLCC为0.9894，同时保持高效计算。

Conclusion: 该方法在准确性和计算成本之间取得了良好平衡，适合实际部署。

Abstract: Face image quality assessment (FIQA) plays a critical role in face
recognition and verification systems, especially in uncontrolled, real-world
environments. Although several methods have been proposed, general-purpose
no-reference image quality assessment techniques often fail to capture
face-specific degradations. Meanwhile, state-of-the-art FIQA models tend to be
computationally intensive, limiting their practical applicability. We propose a
lightweight and efficient method for FIQA, designed for the perceptual
evaluation of face images in the wild. Our approach integrates an ensemble of
two compact convolutional neural networks, MobileNetV3-Small and ShuffleNetV2,
with prediction-level fusion via simple averaging. To enhance alignment with
human perceptual judgments, we employ a correlation-aware loss (MSECorrLoss),
combining mean squared error (MSE) with a Pearson correlation regularizer. Our
method achieves a strong balance between accuracy and computational cost,
making it suitable for real-world deployment. Experiments on the VQualA FIQA
benchmark demonstrate that our model achieves a Spearman rank correlation
coefficient (SRCC) of 0.9829 and a Pearson linear correlation coefficient
(PLCC) of 0.9894, remaining within competition efficiency constraints.

</details>


### [39] [Realism Control One-step Diffusion for Real-World Image Super-Resolution](https://arxiv.org/abs/2509.10122)
*Zongliang Wu,Siming Zheng,Peng-Tao Jiang,Xin Yuan*

Main category: cs.CV

TL;DR: 提出了一种Realism Controlled One-step Diffusion (RCOD)框架，用于真实图像超分辨率任务，通过潜在域分组策略和退化感知采样策略，平衡保真度和真实感。


<details>
  <summary>Details</summary>
Motivation: 传统一步扩散方法在真实图像超分辨率任务中难以平衡保真度和真实感，缺乏灵活的调控机制。

Method: 提出RCOD框架，包括潜在域分组策略、退化感知采样策略和视觉提示注入模块。

Result: RCOD在定量指标和视觉质量上优于现有一步扩散方法，并具备灵活的推理阶段调控能力。

Conclusion: RCOD在保持计算效率的同时，实现了保真度和感知质量的提升，为真实图像超分辨率提供了新思路。

Abstract: Pre-trained diffusion models have shown great potential in real-world image
super-resolution (Real-ISR) tasks by enabling high-resolution reconstructions.
While one-step diffusion (OSD) methods significantly improve efficiency
compared to traditional multi-step approaches, they still have limitations in
balancing fidelity and realism across diverse scenarios. Since the OSDs for SR
are usually trained or distilled by a single timestep, they lack flexible
control mechanisms to adaptively prioritize these competing objectives, which
are inherently manageable in multi-step methods through adjusting sampling
steps. To address this challenge, we propose a Realism Controlled One-step
Diffusion (RCOD) framework for Real-ISR. RCOD provides a latent domain grouping
strategy that enables explicit control over fidelity-realism trade-offs during
the noise prediction phase with minimal training paradigm modifications and
original training data. A degradation-aware sampling strategy is also
introduced to align distillation regularization with the grouping strategy and
enhance the controlling of trade-offs. Moreover, a visual prompt injection
module is used to replace conventional text prompts with degradation-aware
visual tokens, enhancing both restoration accuracy and semantic consistency.
Our method achieves superior fidelity and perceptual quality while maintaining
computational efficiency. Extensive experiments demonstrate that RCOD
outperforms state-of-the-art OSD methods in both quantitative metrics and
visual qualities, with flexible realism control capabilities in the inference
stage. The code will be released.

</details>


### [40] [Grad-CL: Source Free Domain Adaptation with Gradient Guided Feature Disalignment](https://arxiv.org/abs/2509.10134)
*Rini Smita Thakur,Rajeev Ranjan Dwivedi,Vinod K Kurmi*

Main category: cs.CV

TL;DR: 提出了一种名为Grad-CL的无源域适应框架，用于提高视盘和视杯分割的跨域性能。


<details>
  <summary>Details</summary>
Motivation: 解决分割模型在不同成像协议或条件下性能下降的问题。

Method: 结合梯度引导的伪标签细化模块和基于余弦相似度的对比学习策略。

Result: 在跨域眼底成像数据集上表现优于现有方法，分割精度和边界描绘更优。

Conclusion: Grad-CL是一种有效的无源域适应方法，适用于医学图像分割任务。

Abstract: Accurate segmentation of the optic disc and cup is critical for the early
diagnosis and management of ocular diseases such as glaucoma. However,
segmentation models trained on one dataset often suffer significant performance
degradation when applied to target data acquired under different imaging
protocols or conditions. To address this challenge, we propose
\textbf{Grad-CL}, a novel source-free domain adaptation framework that
leverages a pre-trained source model and unlabeled target data to robustly
adapt segmentation performance without requiring access to the original source
data. Grad-CL combines a gradient-guided pseudolabel refinement module with a
cosine similarity-based contrastive learning strategy. In the first stage,
salient class-specific features are extracted via a gradient-based mechanism,
enabling more accurate uncertainty quantification and robust prototype
estimation for refining noisy pseudolabels. In the second stage, a contrastive
loss based on cosine similarity is employed to explicitly enforce inter-class
separability between the gradient-informed features of the optic cup and disc.
Extensive experiments on challenging cross-domain fundus imaging datasets
demonstrate that Grad-CL outperforms state-of-the-art unsupervised and
source-free domain adaptation methods, achieving superior segmentation accuracy
and improved boundary delineation. Project and code are available at
https://visdomlab.github.io/GCL/.

</details>


### [41] [Scalable Training for Vector-Quantized Networks with 100% Codebook Utilization](https://arxiv.org/abs/2509.10140)
*Yifan Chang,Jie Qin,Limeng Qiao,Xiaofeng Wang,Zheng Zhu,Lin Ma,Xingang Wang*

Main category: cs.CV

TL;DR: VQBridge解决了VQ训练中的不稳定问题，实现了100%的码本使用率，提升了图像生成性能。


<details>
  <summary>Details</summary>
Motivation: 解决VQ训练中的不稳定问题（如梯度稀疏、码本更新滞后等），提升码本使用率和重建性能。

Method: 提出VQBridge，通过压缩-处理-恢复流程优化码向量，结合学习退火实现稳定训练。

Result: 实现了100%码本使用率，重建性能达到SOTA，显著提升图像生成效果。

Conclusion: 高质量的分词器对自回归图像生成至关重要，VQBridge具有高效、可扩展和通用性。

Abstract: Vector quantization (VQ) is a key component in discrete tokenizers for image
generation, but its training is often unstable due to straight-through
estimation bias, one-step-behind updates, and sparse codebook gradients, which
lead to suboptimal reconstruction performance and low codebook usage. In this
work, we analyze these fundamental challenges and provide a simple yet
effective solution. To maintain high codebook usage in VQ networks (VQN) during
learning annealing and codebook size expansion, we propose VQBridge, a robust,
scalable, and efficient projector based on the map function method. VQBridge
optimizes code vectors through a compress-process-recover pipeline, enabling
stable and effective codebook training. By combining VQBridge with learning
annealing, our VQN achieves full (100%) codebook usage across diverse codebook
configurations, which we refer to as FVQ (FullVQ). Through extensive
experiments, we demonstrate that FVQ is effective, scalable, and generalizable:
it attains 100% codebook usage even with a 262k-codebook, achieves
state-of-the-art reconstruction performance, consistently improves with larger
codebooks, higher vector channels, or longer training, and remains effective
across different VQ variants. Moreover, when integrated with LlamaGen, FVQ
significantly enhances image generation performance, surpassing visual
autoregressive models (VAR) by 0.5 and diffusion models (DiT) by 0.2 rFID,
highlighting the importance of high-quality tokenizers for strong
autoregressive image generation.

</details>


### [42] [LayerLock: Non-collapsing Representation Learning with Progressive Freezing](https://arxiv.org/abs/2509.10156)
*Goker Erdogan,Nikhil Parthasarathy,Catalin Ionescu,Drew Hudson,Alexander Lerchner,Andrew Zisserman,Mehdi Sajjadi,Joao Carreira*

Main category: cs.CV

TL;DR: LayerLock是一种通过渐进冻结层加速自监督视觉表示学习的方法，避免了表示崩溃问题。


<details>
  <summary>Details</summary>
Motivation: 观察到ViT层在训练中按深度顺序收敛，利用这一现象优化训练效率。

Method: 通过显式进度表逐步冻结模型层，应用于大规模模型。

Result: 在4B参数模型上表现优于非潜在掩码预测方法。

Conclusion: LayerLock简单有效，适用于大规模自监督学习。

Abstract: We introduce LayerLock, a simple yet effective approach for self-supervised
visual representation learning, that gradually transitions from pixel to latent
prediction through progressive layer freezing. First, we make the observation
that during training of video masked-autoencoding (MAE) models, ViT layers
converge in the order of their depth: shallower layers converge early, deeper
layers converge late. We then show that this observation can be exploited to
accelerate standard MAE by progressively freezing the model according to an
explicit schedule, throughout training. Furthermore, this same schedule can be
used in a simple and scalable approach to latent prediction that does not
suffer from "representation collapse". We apply our proposed approach,
LayerLock, to large models of up to 4B parameters with results surpassing those
of non-latent masked prediction on the 4DS perception suite.

</details>


### [43] [On the Geometric Accuracy of Implicit and Primitive-based Representations Derived from View Rendering Constraints](https://arxiv.org/abs/2509.10241)
*Elias De Smijter,Renaud Detry,Christophe De Vleeschouwer*

Main category: cs.CV

TL;DR: 对比隐式和显式新视角合成方法在空间3D物体重建中的表现，发现外观嵌入虽提升光度保真度，但对几何精度无显著提升。


<details>
  <summary>Details</summary>
Motivation: 研究外观嵌入在空间机器人应用中是否同时提升几何精度和光度保真度。

Method: 使用SPEED+数据集比较K-Planes、高斯抛光和凸面抛光方法。

Result: 外观嵌入主要减少显式方法所需基元数量，而非提升几何精度；凸面抛光比高斯抛光更紧凑且无杂乱。

Conclusion: 外观嵌入在几何中心任务中效果有限，需权衡重建质量和表示效率。

Abstract: We present the first systematic comparison of implicit and explicit Novel
View Synthesis methods for space-based 3D object reconstruction, evaluating the
role of appearance embeddings. While embeddings improve photometric fidelity by
modeling lighting variation, we show they do not translate into meaningful
gains in geometric accuracy - a critical requirement for space robotics
applications. Using the SPEED+ dataset, we compare K-Planes, Gaussian
Splatting, and Convex Splatting, and demonstrate that embeddings primarily
reduce the number of primitives needed for explicit methods rather than
enhancing geometric fidelity. Moreover, convex splatting achieves more compact
and clutter-free representations than Gaussian splatting, offering advantages
for safety-critical applications such as interaction and collision avoidance.
Our findings clarify the limits of appearance embeddings for geometry-centric
tasks and highlight trade-offs between reconstruction quality and
representation efficiency in space scenarios.

</details>


### [44] [GAMMA: Generalizable Alignment via Multi-task and Manipulation-Augmented Training for AI-Generated Image Detection](https://arxiv.org/abs/2509.10250)
*Haozhen Yan,Yan Hong,Suning Lang,Jiahui Zhan,Yikun Ji,Yujie Gao,Jun Lan,Huijia Zhu,Weiqiang Wang,Jianfu Zhang*

Main category: cs.CV

TL;DR: GAMMA框架通过多样化操作策略和多任务监督提升AI生成图像检测的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成图像检测器依赖生成特定伪影，泛化能力有限。

Method: 提出GAMMA框架，引入多样化操作策略和多任务监督，包括双分割头和分类头。

Result: 在GenImage基准上提升5.8%准确率，对GPT-4o等新模型保持强鲁棒性。

Conclusion: GAMMA通过减少领域偏差和增强语义对齐，显著提升检测器的泛化性能。

Abstract: With generative models becoming increasingly sophisticated and diverse,
detecting AI-generated images has become increasingly challenging. While
existing AI-genereted Image detectors achieve promising performance on
in-distribution generated images, their generalization to unseen generative
models remains limited. This limitation is largely attributed to their reliance
on generation-specific artifacts, such as stylistic priors and compression
patterns. To address these limitations, we propose GAMMA, a novel training
framework designed to reduce domain bias and enhance semantic alignment. GAMMA
introduces diverse manipulation strategies, such as inpainting-based
manipulation and semantics-preserving perturbations, to ensure consistency
between manipulated and authentic content. We employ multi-task supervision
with dual segmentation heads and a classification head, enabling pixel-level
source attribution across diverse generative domains. In addition, a reverse
cross-attention mechanism is introduced to allow the segmentation heads to
guide and correct biased representations in the classification branch. Our
method achieves state-of-the-art generalization performance on the GenImage
benchmark, imporving accuracy by 5.8%, but also maintains strong robustness on
newly released generative model such as GPT-4o.

</details>


### [45] [Robustness and Diagnostic Performance of Super-Resolution Fetal Brain MRI](https://arxiv.org/abs/2509.10257)
*Ema Masterl,Tina Vipotnik Vesnaver,Žiga Špiclin*

Main category: cs.CV

TL;DR: 该研究比较了三种胎儿脑MRI超分辨率重建方法（NiftyMIC、SVRTK、NeSVoR）的性能，发现NeSVoR在重建成功率和诊断分类性能上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 胎儿脑MRI的低分辨率和运动伪影限制了3D解剖结构的准确捕捉，超分辨率重建（SRR）方法旨在解决这些问题，但其在病理情况下的性能和下游任务影响尚不明确。

Method: 研究对140例胎儿脑MRI扫描（包括健康对照和病理病例）应用了三种SRR方法，并通过BoUNTi算法分割脑结构体积，评估了视觉质量、重建成功率、体积测量一致性和诊断分类性能。

Result: NeSVoR的重建成功率最高（>90%），且诊断分类性能不受SRR方法选择的影响，尽管不同SRR方法的体积估计存在显著差异。

Conclusion: NeSVoR在胎儿脑MRI超分辨率重建中表现出色，且诊断性能对SRR方法的选择具有鲁棒性。

Abstract: Fetal brain MRI relies on rapid multi-view 2D slice acquisitions to reduce
motion artifacts caused by fetal movement. However, these stacks are typically
low resolution, may suffer from motion corruption, and do not adequately
capture 3D anatomy. Super-resolution reconstruction (SRR) methods aim to
address these limitations by combining slice-to-volume registration and
super-resolution techniques to generate high-resolution (HR) 3D volumes. While
several SRR methods have been proposed, their comparative performance -
particularly in pathological cases - and their influence on downstream
volumetric analysis and diagnostic tasks remain underexplored. In this study,
we applied three state-of-the-art SRR method - NiftyMIC, SVRTK, and NeSVoR - to
140 fetal brain MRI scans, including both healthy controls (HC) and
pathological cases (PC) with ventriculomegaly (VM). Each HR reconstruction was
segmented using the BoUNTi algorithm to extract volumes of nine principal brain
structures. We evaluated visual quality, SRR success rates, volumetric
measurement agreement, and diagnostic classification performance. NeSVoR
demonstrated the highest and most consistent reconstruction success rate (>90%)
across both HC and PC groups. Although significant differences in volumetric
estimates were observed between SRR methods, classification performance for VM
was not affected by the choice of SRR method. These findings highlight NeSVoR's
robustness and the resilience of diagnostic performance despite SRR-induced
volumetric variability.

</details>


### [46] [Mask Consistency Regularization in Object Removal](https://arxiv.org/abs/2509.10259)
*Hua Yuan,Jin Yuan,Yicheng Jiang,Yao Zhang,Xin Geng,Yong Rui*

Main category: cs.CV

TL;DR: 提出了一种名为Mask Consistency Regularization (MCR)的新训练策略，用于解决图像修复中物体移除任务中的掩码幻觉和掩码形状偏差问题。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型在物体移除任务中存在掩码幻觉和掩码形状偏差两大挑战，影响了修复结果的准确性和一致性。

Method: 通过引入两种掩码扰动（扩张和重塑），强制模型在这些扰动分支的输出与原始掩码之间保持一致性。

Result: 实验表明，MCR显著减少了幻觉和掩码形状偏差，提升了物体移除的性能。

Conclusion: MCR是一种有效的训练策略，能够生成更鲁棒且上下文一致的图像修复结果。

Abstract: Object removal, a challenging task within image inpainting, involves
seamlessly filling the removed region with content that matches the surrounding
context. Despite advancements in diffusion models, current methods still face
two critical challenges. The first is mask hallucination, where the model
generates irrelevant or spurious content inside the masked region, and the
second is mask-shape bias, where the model fills the masked area with an object
that mimics the mask's shape rather than surrounding content. To address these
issues, we propose Mask Consistency Regularization (MCR), a novel training
strategy designed specifically for object removal tasks. During training, our
approach introduces two mask perturbations: dilation and reshape, enforcing
consistency between the outputs of these perturbed branches and the original
mask. The dilated masks help align the model's output with the surrounding
content, while reshaped masks encourage the model to break the mask-shape bias.
This combination of strategies enables MCR to produce more robust and
contextually coherent inpainting results. Our experiments demonstrate that MCR
significantly reduces hallucinations and mask-shape bias, leading to improved
performance in object removal.

</details>


### [47] [MagicMirror: A Large-Scale Dataset and Benchmark for Fine-Grained Artifacts Assessment in Text-to-Image Generation](https://arxiv.org/abs/2509.10260)
*Jia Wang,Jie Hu,Xiaoqi Ma,Hanghang Ma,Yanbing Zeng,Xiaoming Wei*

Main category: cs.CV

TL;DR: MagicMirror是一个评估文本生成图像（T2I）中物理伪影的综合框架，包括数据集、评估模型和基准测试。


<details>
  <summary>Details</summary>
Motivation: 当前T2I生成模型在物理伪影（如解剖和结构缺陷）方面存在严重问题，缺乏系统化的评估工具。

Method: 1. 建立伪影分类法；2. 标注340K图像数据集MagicData340K；3. 训练VLM模型MagicAssessor；4. 设计GRPO优化策略；5. 构建自动化基准MagicBench。

Result: 评估发现即使是顶级模型（如GPT-image-1）仍存在显著伪影。

Conclusion: 伪影减少是T2I未来发展的关键方向。

Abstract: Text-to-image (T2I) generation has achieved remarkable progress in
instruction following and aesthetics. However, a persistent challenge is the
prevalence of physical artifacts, such as anatomical and structural flaws,
which severely degrade perceptual quality and limit application. Given the
diversity and complexity of these artifacts, a systematic and fine-grained
evaluation framework is required, which is lacking in current benchmarks. To
fill this gap, we introduce MagicMirror, a comprehensive framework for
artifacts assessment. We first establish a detailed taxonomy of generated image
artifacts. Guided by this taxonomy, we manually annotate MagicData340K, the
first human-annotated large-scale dataset of 340K generated images with
fine-grained artifact labels. Building on this dataset, we train MagicAssessor,
a Vision-Language Model (VLM) that provides detailed assessments and
corresponding labels. To overcome challenges like class imbalance and reward
hacking, we design a novel data sampling strategy and a multi-level reward
system for Group Relative Policy Optimization (GRPO). Finally, we leverage
MagicAssessor to construct MagicBench, an automated benchmark for evaluating
the image artifacts of current T2I models. Our evaluation with MagicBench
reveals that despite their widespread adoption, even top-tier models like
GPT-image-1 are consistently plagued by significant artifacts, highlighting
artifact reduction as a critical frontier for future T2I development. Project
page: https://wj-inf.github.io/MagicMirror-page/.

</details>


### [48] [SignClip: Leveraging Mouthing Cues for Sign Language Translation by Multimodal Contrastive Fusion](https://arxiv.org/abs/2509.10266)
*Wenfang Wu,Tingting Yuan,Yupeng Li,Daling Wang,Xiaoming Fu*

Main category: cs.CV

TL;DR: SignClip是一种新的手语翻译框架，通过融合手势和唇部运动特征，结合对比学习，显著提升了翻译准确性。


<details>
  <summary>Details</summary>
Motivation: 现有手语翻译方法主要关注手势信号，忽视了唇部运动等非手动线索，而这些线索在消除视觉相似手势的歧义中至关重要。

Method: SignClip框架融合了手势和唇部运动特征，并引入分层对比学习框架，通过多级对齐目标确保语义一致性。

Result: 在PHOENIX14T和How2Sign数据集上，SignClip在Gloss-free设置下超越了SpaMo模型，BLEU-4从24.32提升至24.71，ROUGE从46.57提升至48.38。

Conclusion: SignClip通过结合手动和非手动线索，显著提升了手语翻译的准确性，证明了唇部运动特征的重要性。

Abstract: Sign language translation (SLT) aims to translate natural language from sign
language videos, serving as a vital bridge for inclusive communication. While
recent advances leverage powerful visual backbones and large language models,
most approaches mainly focus on manual signals (hand gestures) and tend to
overlook non-manual cues like mouthing. In fact, mouthing conveys essential
linguistic information in sign languages and plays a crucial role in
disambiguating visually similar signs. In this paper, we propose SignClip, a
novel framework to improve the accuracy of sign language translation. It fuses
manual and non-manual cues, specifically spatial gesture and lip movement
features. Besides, SignClip introduces a hierarchical contrastive learning
framework with multi-level alignment objectives, ensuring semantic consistency
across sign-lip and visual-text modalities. Extensive experiments on two
benchmark datasets, PHOENIX14T and How2Sign, demonstrate the superiority of our
approach. For example, on PHOENIX14T, in the Gloss-free setting, SignClip
surpasses the previous state-of-the-art model SpaMo, improving BLEU-4 from
24.32 to 24.71, and ROUGE from 46.57 to 48.38.

</details>


### [49] [Detecting Text Manipulation in Images using Vision Language Models](https://arxiv.org/abs/2509.10278)
*Vidit Vidit,Pavel Korshunov,Amir Mohammadi,Christophe Ecabert,Ketan Kotwal,Sébastien Marcel*

Main category: cs.CV

TL;DR: 论文分析了开源和闭源大型视觉语言模型（VLMs）在文本操纵检测上的表现，发现开源模型虽接近但仍落后于闭源模型（如GPT-4o），并指出图像操纵检测专用VLMs在文本检测中存在泛化问题。


<details>
  <summary>Details</summary>
Motivation: 填补文本操纵检测在大型视觉语言模型研究中的空白。

Method: 通过在不同文本操纵数据集上测试开源和闭源VLMs，并评估图像操纵检测专用VLMs的泛化能力。

Result: 开源模型表现接近但不及闭源模型；图像操纵检测专用VLMs在文本检测中泛化能力不足。

Conclusion: 开源VLMs在文本操纵检测上有潜力但需改进，图像操纵检测专用VLMs需解决泛化问题。

Abstract: Recent works have shown the effectiveness of Large Vision Language Models
(VLMs or LVLMs) in image manipulation detection. However, text manipulation
detection is largely missing in these studies. We bridge this knowledge gap by
analyzing closed- and open-source VLMs on different text manipulation datasets.
Our results suggest that open-source models are getting closer, but still
behind closed-source ones like GPT- 4o. Additionally, we benchmark image
manipulation detection-specific VLMs for text manipulation detection and show
that they suffer from the generalization problem. We benchmark VLMs for
manipulations done on in-the-wild scene texts and on fantasy ID cards, where
the latter mimic a challenging real-world misuse.

</details>


### [50] [MCL-AD: Multimodal Collaboration Learning for Zero-Shot 3D Anomaly Detection](https://arxiv.org/abs/2509.10282)
*Gang Li,Tianjiao Chen,Mingle Zhou,Min Li,Delong Han,Jin Wan*

Main category: cs.CV

TL;DR: MCL-AD框架通过多模态协作学习（点云、RGB图像和文本语义）实现零样本3D异常检测，性能优越。


<details>
  <summary>Details</summary>
Motivation: 现有方法多专注于点云数据，忽略了RGB图像和文本语义等互补模态的丰富语义线索。

Method: 提出多模态提示学习机制（MPLM）和协作调制机制（CMM），增强模态内表示能力和模态间协作学习。

Result: 实验表明MCL-AD在零样本3D异常检测中达到最先进性能。

Conclusion: MCL-AD通过多模态协作学习显著提升了零样本3D异常检测的效果。

Abstract: Zero-shot 3D (ZS-3D) anomaly detection aims to identify defects in 3D objects
without relying on labeled training data, making it especially valuable in
scenarios constrained by data scarcity, privacy, or high annotation cost.
However, most existing methods focus exclusively on point clouds, neglecting
the rich semantic cues available from complementary modalities such as RGB
images and texts priors. This paper introduces MCL-AD, a novel framework that
leverages multimodal collaboration learning across point clouds, RGB images,
and texts semantics to achieve superior zero-shot 3D anomaly detection.
Specifically, we propose a Multimodal Prompt Learning Mechanism (MPLM) that
enhances the intra-modal representation capability and inter-modal
collaborative learning by introducing an object-agnostic decoupled text prompt
and a multimodal contrastive loss. In addition, a collaborative modulation
mechanism (CMM) is proposed to fully leverage the complementary representations
of point clouds and RGB images by jointly modulating the RGB image-guided and
point cloud-guided branches. Extensive experiments demonstrate that the
proposed MCL-AD framework achieves state-of-the-art performance in ZS-3D
anomaly detection.

</details>


### [51] [Adversarial robustness through Lipschitz-Guided Stochastic Depth in Neural Networks](https://arxiv.org/abs/2509.10298)
*Laith Nayal,Mahmoud Mousatat,Bader Rasheed*

Main category: cs.CV

TL;DR: 提出了一种基于Lipschitz约束的随机深度方法（DropPath），通过深度依赖的丢弃概率提升模型鲁棒性，同时保持干净数据准确性和降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络和Vision Transformers在计算机视觉中表现优异，但对对抗扰动高度敏感，现有防御方法计算成本高或缺乏理论保证。

Method: 采用Lipschitz引导的随机深度方法，丢弃概率随深度增加，以控制网络的有效Lipschitz常数。

Result: 在CIFAR-10和ViT-Tiny上的实验表明，该方法在保持干净数据准确性的同时，提升了对抗攻击（FGSM、PGD-20、AutoAttack）下的鲁棒性，并显著减少了计算量。

Conclusion: 该方法通过深度依赖的丢弃策略有效平衡了鲁棒性、准确性和计算效率。

Abstract: Deep neural networks and Vision Transformers achieve state-of-the-art
performance in computer vision but are highly vulnerable to adversarial
perturbations. Standard defenses often incur high computational cost or lack
formal guarantees. We propose a Lipschitz-guided stochastic depth (DropPath)
method, where drop probabilities increase with depth to control the effective
Lipschitz constant of the network. This approach regularizes deeper layers,
improving robustness while preserving clean accuracy and reducing computation.
Experiments on CIFAR-10 with ViT-Tiny show that our custom depth-dependent
schedule maintains near-baseline clean accuracy, enhances robustness under
FGSM, PGD-20, and AutoAttack, and significantly reduces FLOPs compared to
baseline and linear DropPath schedules.

</details>


### [52] [A Stochastic Birth-and-Death Approach for Street Furniture Geolocation in Urban Environments](https://arxiv.org/abs/2509.10310)
*Evan Murphy,Marco Viola,Vladimir A. Krylov*

Main category: cs.CV

TL;DR: 提出了一种基于能量图的概率框架，用于精确定位复杂城市环境中的街道家具，结合地理信息系统优化定位精度。


<details>
  <summary>Details</summary>
Motivation: 解决城市环境中街道家具的精确定位问题，以支持公共基础设施的有效监控和维护。

Method: 使用能量图编码空间位置概率，结合GIS信息，采用随机生死优化算法推断最可能的资产配置。

Result: 在都柏林市中心的实际模拟中验证了方法的可扩展性和准确性。

Conclusion: 该方法为城市资产映射提供了高效且精确的解决方案，代码已开源。

Abstract: In this paper we address the problem of precise geolocation of street
furniture in complex urban environments, which is a critical task for effective
monitoring and maintenance of public infrastructure by local authorities and
private stakeholders. To this end, we propose a probabilistic framework based
on energy maps that encode the spatial likelihood of object locations.
Representing the energy in a map-based geopositioned format allows the
optimisation process to seamlessly integrate external geospatial information,
such as GIS layers, road maps, or placement constraints, which improves
contextual awareness and localisation accuracy. A stochastic birth-and-death
optimisation algorithm is introduced to infer the most probable configuration
of assets. We evaluate our approach using a realistic simulation informed by a
geolocated dataset of street lighting infrastructure in Dublin city centre,
demonstrating its potential for scalable and accurate urban asset mapping. The
implementation of the algorithm will be made available in the GitHub repository
https://github.com/EMurphy0108/SBD_Street_Furniture.

</details>


### [53] [Compute Only 16 Tokens in One Timestep: Accelerating Diffusion Transformers with Cluster-Driven Feature Caching](https://arxiv.org/abs/2509.10312)
*Zhixin Zheng,Xinyu Wang,Chang Zou,Shaobo Wang,Linfeng Zhang*

Main category: cs.CV

TL;DR: 论文提出了一种名为ClusCa的空间聚类特征缓存方法，用于加速扩散变换器的计算，减少90%以上的token数量，并在多个模型上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 扩散变换器在生成高质量图像和视频时计算成本高，现有特征缓存方法仅利用时间维度相似性，忽略了空间维度。

Method: ClusCa通过空间聚类对token进行分组，每组仅计算一个token并传播其信息，从而减少计算量。

Result: 实验表明，ClusCa在DiT、FLUX和HunyuanVideo上均有效，加速比达4.96倍，且无需额外训练。

Conclusion: ClusCa是一种高效且通用的扩散变换器加速方法，显著提升了计算效率。

Abstract: Diffusion transformers have gained significant attention in recent years for
their ability to generate high-quality images and videos, yet still suffer from
a huge computational cost due to their iterative denoising process. Recently,
feature caching has been introduced to accelerate diffusion transformers by
caching the feature computation in previous timesteps and reusing it in the
following timesteps, which leverage the temporal similarity of diffusion models
while ignoring the similarity in the spatial dimension. In this paper, we
introduce Cluster-Driven Feature Caching (ClusCa) as an orthogonal and
complementary perspective for previous feature caching. Specifically, ClusCa
performs spatial clustering on tokens in each timestep, computes only one token
in each cluster and propagates their information to all the other tokens, which
is able to reduce the number of tokens by over 90%. Extensive experiments on
DiT, FLUX and HunyuanVideo demonstrate its effectiveness in both text-to-image
and text-to-video generation. Besides, it can be directly applied to any
diffusion transformer without requirements for training. For instance, ClusCa
achieves 4.96x acceleration on FLUX with an ImageReward of 99.49%, surpassing
the original model by 0.51%. The code is available at
https://github.com/Shenyi-Z/Cache4Diffusion.

</details>


### [54] [I-Segmenter: Integer-Only Vision Transformer for Efficient Semantic Segmentation](https://arxiv.org/abs/2509.10334)
*Jordan Sassoon,Michal Szczepanski,Martyna Poreba*

Main category: cs.CV

TL;DR: I-Segmenter是一种全整数化的ViT分割框架，通过量化技术显著降低模型大小和计算成本，同时保持较高精度。


<details>
  <summary>Details</summary>
Motivation: 解决Vision Transformers在资源受限设备上部署时的高内存和计算成本问题。

Method: 采用整数化操作替换浮点运算，提出λ-ShiftGELU激活函数，移除L2归一化层，并使用最近邻上采样。

Result: 模型大小减少3.8倍，推理速度提升1.2倍，精度损失平均5.1%。

Conclusion: I-Segmenter在保持精度的同时显著提升了效率，适合实际部署。

Abstract: Vision Transformers (ViTs) have recently achieved strong results in semantic
segmentation, yet their deployment on resource-constrained devices remains
limited due to their high memory footprint and computational cost. Quantization
offers an effective strategy to improve efficiency, but ViT-based segmentation
models are notoriously fragile under low precision, as quantization errors
accumulate across deep encoder-decoder pipelines. We introduce I-Segmenter, the
first fully integer-only ViT segmentation framework. Building on the Segmenter
architecture, I-Segmenter systematically replaces floating-point operations
with integer-only counterparts. To further stabilize both training and
inference, we propose $\lambda$-ShiftGELU, a novel activation function that
mitigates the limitations of uniform quantization in handling long-tailed
activation distributions. In addition, we remove the L2 normalization layer and
replace bilinear interpolation in the decoder with nearest neighbor upsampling,
ensuring integer-only execution throughout the computational graph. Extensive
experiments show that I-Segmenter achieves accuracy within a reasonable margin
of its FP32 baseline (5.1 % on average), while reducing model size by up to
3.8x and enabling up to 1.2x faster inference with optimized runtimes. Notably,
even in one-shot PTQ with a single calibration image, I-Segmenter delivers
competitive accuracy, underscoring its practicality for real-world deployment.

</details>


### [55] [GARD: Gamma-based Anatomical Restoration and Denoising for Retinal OCT](https://arxiv.org/abs/2509.10341)
*Botond Fazekas,Thomas Pinetz,Guilherme Aresta,Taha Emre,Hrvoje Bogunovic*

Main category: cs.CV

TL;DR: GARD是一种基于深度学习的OCT图像去噪方法，利用扩散概率模型和伽马噪声模型，显著提升了去噪效果。


<details>
  <summary>Details</summary>
Motivation: OCT图像中的散斑噪声会掩盖细节，影响诊断准确性，现有方法难以平衡去噪与结构保留。

Method: 提出GARD方法，结合Denoising Diffusion Gamma Model和Noise-Reduced Fidelity Term，并优化推理速度。

Result: 在PSNR、SSIM和MSE指标上优于传统和现有深度学习方法，且能更好地保留解剖细节。

Conclusion: GARD在OCT图像去噪中表现出色，为临床诊断提供了更清晰的图像。

Abstract: Optical Coherence Tomography (OCT) is a vital imaging modality for diagnosing
and monitoring retinal diseases. However, OCT images are inherently degraded by
speckle noise, which obscures fine details and hinders accurate interpretation.
While numerous denoising methods exist, many struggle to balance noise
reduction with the preservation of crucial anatomical structures. This paper
introduces GARD (Gamma-based Anatomical Restoration and Denoising), a novel
deep learning approach for OCT image despeckling that leverages the strengths
of diffusion probabilistic models. Unlike conventional diffusion models that
assume Gaussian noise, GARD employs a Denoising Diffusion Gamma Model to more
accurately reflect the statistical properties of speckle. Furthermore, we
introduce a Noise-Reduced Fidelity Term that utilizes a pre-processed,
less-noisy image to guide the denoising process. This crucial addition prevents
the reintroduction of high-frequency noise. We accelerate the inference process
by adapting the Denoising Diffusion Implicit Model framework to our Gamma-based
model. Experiments on a dataset with paired noisy and less-noisy OCT B-scans
demonstrate that GARD significantly outperforms traditional denoising methods
and state-of-the-art deep learning models in terms of PSNR, SSIM, and MSE.
Qualitative results confirm that GARD produces sharper edges and better
preserves fine anatomical details.

</details>


### [56] [GLAM: Geometry-Guided Local Alignment for Multi-View VLP in Mammography](https://arxiv.org/abs/2509.10344)
*Yuexi Du,Lihui Chen,Nicha C. Dvornek*

Main category: cs.CV

TL;DR: GLAM是一种用于乳腺X光片多视图预训练的视觉语言模型，通过几何引导实现全局和局部对齐，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有乳腺X光片视觉语言模型忽略多视图关系，导致预测效果不佳，GLAM旨在解决这一问题。

Method: GLAM通过几何引导的全局和局部对比学习，学习多视图对齐和细粒度特征。

Result: 在多个数据集和设置下，GLAM表现优于基线模型。

Conclusion: GLAM通过多视图对齐和几何引导，显著提升了乳腺X光片分析的性能。

Abstract: Mammography screening is an essential tool for early detection of breast
cancer. The speed and accuracy of mammography interpretation have the potential
to be improved with deep learning methods. However, the development of a
foundation visual language model (VLM) is hindered by limited data and domain
differences between natural and medical images. Existing mammography VLMs,
adapted from natural images, often ignore domain-specific characteristics, such
as multi-view relationships in mammography. Unlike radiologists who analyze
both views together to process ipsilateral correspondence, current methods
treat them as independent images or do not properly model the multi-view
correspondence learning, losing critical geometric context and resulting in
suboptimal prediction. We propose GLAM: Global and Local Alignment for
Multi-view mammography for VLM pretraining using geometry guidance. By
leveraging the prior knowledge about the multi-view imaging process of
mammograms, our model learns local cross-view alignments and fine-grained local
features through joint global and local, visual-visual, and visual-language
contrastive learning. Pretrained on EMBED [14], one of the largest open
mammography datasets, our model outperforms baselines across multiple datasets
under different settings.

</details>


### [57] [Towards Understanding Visual Grounding in Visual Language Models](https://arxiv.org/abs/2509.10345)
*Georgios Pantazopoulos,Eda B. Özyiğit*

Main category: cs.CV

TL;DR: 该论文综述了视觉语言模型（VLMs）中的视觉接地能力，探讨了其核心组件、应用、挑战及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 视觉接地能力使模型能够根据文本描述识别视觉输入中的特定区域，具有广泛的应用潜力，如指代表达理解、图像或视频的细粒度问题回答等。

Method: 论文首先概述了视觉接地在VLMs中的重要性，然后详细介绍了开发接地模型的核心组件，并分析了其实际应用和评估指标。

Result: 论文探讨了视觉接地与多模态思维链和推理之间的关系，并总结了相关挑战。

Conclusion: 论文提出了视觉接地领域的未来研究方向，强调了其潜在价值。

Abstract: Visual grounding refers to the ability of a model to identify a region within
some visual input that matches a textual description. Consequently, a model
equipped with visual grounding capabilities can target a wide range of
applications in various domains, including referring expression comprehension,
answering questions pertinent to fine-grained details in images or videos,
caption visual context by explicitly referring to entities, as well as low and
high-level control in simulated and real environments. In this survey paper, we
review representative works across the key areas of research on modern
general-purpose vision language models (VLMs). We first outline the importance
of grounding in VLMs, then delineate the core components of the contemporary
paradigm for developing grounded models, and examine their practical
applications, including benchmarks and evaluation metrics for grounded
multimodal generation. We also discuss the multifaceted interrelations among
visual grounding, multimodal chain-of-thought, and reasoning in VLMs. Finally,
we analyse the challenges inherent to visual grounding and suggest promising
directions for future research.

</details>


### [58] [Immunizing Images from Text to Image Editing via Adversarial Cross-Attention](https://arxiv.org/abs/2509.10359)
*Matteo Trippodo,Federico Becattini,Lorenzo Seidenari*

Main category: cs.CV

TL;DR: 提出了一种针对文本图像编辑方法的视觉组件攻击——Attention Attack，通过自动生成的图像描述破坏文本提示与视觉表示的跨注意力机制。


<details>
  <summary>Details</summary>
Motivation: 现有文本图像编辑方法易受对抗攻击，缺乏对视觉组件的针对性攻击研究。

Method: 利用自动生成的图像描述作为编辑提示的代理，破坏图像内容与文本描述的对齐。

Result: 在TEDBench++基准测试中，攻击显著降低了编辑性能且难以察觉。

Conclusion: 提出了两种新评估策略验证攻击效果，揭示了现有方法的脆弱性。

Abstract: Recent advances in text-based image editing have enabled fine-grained
manipulation of visual content guided by natural language. However, such
methods are susceptible to adversarial attacks. In this work, we propose a
novel attack that targets the visual component of editing methods. We introduce
Attention Attack, which disrupts the cross-attention between a textual prompt
and the visual representation of the image by using an automatically generated
caption of the source image as a proxy for the edit prompt. This breaks the
alignment between the contents of the image and their textual description,
without requiring knowledge of the editing method or the editing prompt.
Reflecting on the reliability of existing metrics for immunization success, we
propose two novel evaluation strategies: Caption Similarity, which quantifies
semantic consistency between original and adversarial edits, and semantic
Intersection over Union (IoU), which measures spatial layout disruption via
segmentation masks. Experiments conducted on the TEDBench++ benchmark
demonstrate that our attack significantly degrades editing performance while
remaining imperceptible.

</details>


### [59] [SSL-AD: Spatiotemporal Self-Supervised Learning for Generalizability and Adaptability Across Alzheimer's Prediction Tasks and Datasets](https://arxiv.org/abs/2509.10453)
*Emily Kaczmarek,Justin Szeto,Brennan Nichyporuk,Tal Arbel*

Main category: cs.CV

TL;DR: 该研究通过自监督学习方法改进阿尔茨海默病的预测模型，解决了数据标签不足和泛化能力差的问题，并在多个任务中表现优于监督学习。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病预测模型受限于数据标签不足、泛化能力差以及对输入扫描数量和时间间隔的灵活性不足。

Method: 采用三种自监督学习方法，扩展以处理可变长度输入并学习鲁棒的空间特征，使用四个公开数据集进行预训练。

Result: 自监督学习模型在七项下游任务中的六项表现优于监督学习，展示了跨任务和输入图像的适应性。

Conclusion: 该方法在临床应用中具有鲁棒性和泛化能力，代码和模型已公开。

Abstract: Alzheimer's disease is a progressive, neurodegenerative disorder that causes
memory loss and cognitive decline. While there has been extensive research in
applying deep learning models to Alzheimer's prediction tasks, these models
remain limited by lack of available labeled data, poor generalization across
datasets, and inflexibility to varying numbers of input scans and time
intervals between scans. In this study, we adapt three state-of-the-art
temporal self-supervised learning (SSL) approaches for 3D brain MRI analysis,
and add novel extensions designed to handle variable-length inputs and learn
robust spatial features. We aggregate four publicly available datasets
comprising 3,161 patients for pre-training, and show the performance of our
model across multiple Alzheimer's prediction tasks including diagnosis
classification, conversion detection, and future conversion prediction.
Importantly, our SSL model implemented with temporal order prediction and
contrastive learning outperforms supervised learning on six out of seven
downstream tasks. It demonstrates adaptability and generalizability across
tasks and number of input images with varying time intervals, highlighting its
capacity for robust performance across clinical applications. We release our
code and model publicly at https://github.com/emilykaczmarek/SSL-AD.

</details>


### [60] [Efficient Learned Image Compression Through Knowledge Distillation](https://arxiv.org/abs/2509.10366)
*Fabien Allemand,Attilio Fiandrotti,Sumanta Chaudhuri,Alaa Eddine Mazouz*

Main category: cs.CV

TL;DR: 论文提出利用知识蒸馏降低图像压缩神经网络的资源需求，提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有神经网络压缩方法性能优越但计算资源需求高，限制了实时应用。

Method: 采用知识蒸馏训练小网络，利用大模型输出提升性能。

Result: 实验表明该方法在不同架构、质量/比特率权衡及资源节省上均有效。

Conclusion: 知识蒸馏可扩展至图像压缩任务，未来可探索更多教师模型和损失函数。

Abstract: Learned image compression sits at the intersection of machine learning and
image processing. With advances in deep learning, neural network-based
compression methods have emerged. In this process, an encoder maps the image to
a low-dimensional latent space, which is then quantized, entropy-coded into a
binary bitstream, and transmitted to the receiver. At the receiver end, the
bitstream is entropy-decoded, and a decoder reconstructs an approximation of
the original image. Recent research suggests that these models consistently
outperform conventional codecs. However, they require significant processing
power, making them unsuitable for real-time use on resource-constrained
platforms, which hinders their deployment in mainstream applications. This
study aims to reduce the resource requirements of neural networks used for
image compression by leveraging knowledge distillation, a training paradigm
where smaller neural networks, partially trained on the outputs of larger, more
complex models, can achieve better performance than when trained independently.
Our work demonstrates that knowledge distillation can be effectively applied to
image compression tasks: i) across various architecture sizes, ii) to achieve
different image quality/bit rate tradeoffs, and iii) to save processing and
energy resources. This approach introduces new settings and hyperparameters,
and future research could explore the impact of different teacher models, as
well as alternative loss functions. Knowledge distillation could also be
extended to transformer-based models. The code is publicly available at:
https://github.com/FABallemand/PRIM .

</details>


### [61] [Ordinality of Visible-Thermal Image Intensities for Intrinsic Image Decomposition](https://arxiv.org/abs/2509.10388)
*Zeqing Leo Yuan,Mani Ramanagopal,Aswin C. Sankaranarayanan,Srinivasa G. Narasimhan*

Main category: cs.CV

TL;DR: 提出了一种无需训练的方法，利用可见光和热成像图像对进行本征图像分解。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏真实场景的广泛地面真实数据，本征图像分解一直是一个挑战。现有方法依赖合成数据或稀疏标注，限制了应用场景。

Method: 通过可见光和热成像图像的强度顺序关系，自监督优化神经网络，恢复阴影和反射率。

Result: 在自然和人工光照下进行了定量和定性评估，结果显示优于现有学习模型。

Conclusion: 该方法为真实世界的有序监督提供了一条可扩展的路径，解决了手动标注的不可行性问题。

Abstract: Decomposing an image into its intrinsic photometric factors--shading and
reflectance--is a long-standing challenge due to the lack of extensive
ground-truth data for real-world scenes. Recent methods rely on synthetic data
or sparse annotations for limited indoor and even fewer outdoor scenes. We
introduce a novel training-free approach for intrinsic image decomposition
using only a pair of visible and thermal images. We leverage the principle that
light not reflected from an opaque surface is absorbed and detected as heat by
a thermal camera. This allows us to relate the ordinalities between visible and
thermal image intensities to the ordinalities of shading and reflectance, which
can densely self-supervise an optimizing neural network to recover shading and
reflectance. We perform quantitative evaluations with known reflectance and
shading under natural and artificial lighting, and qualitative experiments
across diverse outdoor scenes. The results demonstrate superior performance
over recent learning-based models and point toward a scalable path to curating
real-world ordinal supervision, previously infeasible via manual labeling.

</details>


### [62] [Compressed Video Quality Enhancement: Classifying and Benchmarking over Standards](https://arxiv.org/abs/2509.10407)
*Xiem HoangVan,Dang BuiDinh,Sang NguyenQuang,Wen-Hsiao Peng*

Main category: cs.CV

TL;DR: 本文提出了一种新的分类法、统一的基准测试框架，并分析了压缩视频质量增强（CVQE）领域的性能与复杂度权衡。


<details>
  <summary>Details</summary>
Motivation: 现有调查缺乏系统性分类、比较分析不足，且基准测试实践不完善，阻碍了CVQE研究的进展。

Method: 引入新的分类法、提出统一的基准测试框架，并系统分析性能与复杂度的权衡。

Result: 建立了CVQE方法的分类体系，提供了公平评估的基准框架，并识别了未来研究方向。

Conclusion: 本文为CVQE研究提供了系统性评估基础，并指导了未来模型选择和优化方向。

Abstract: Compressed video quality enhancement (CVQE) is crucial for improving user
experience with lossy video codecs like H.264/AVC, H.265/HEVC, and H.266/VVC.
While deep learning based CVQE has driven significant progress, existing
surveys still suffer from limitations: lack of systematic classification
linking methods to specific standards and artifacts, insufficient comparative
analysis of architectural paradigms across coding types, and underdeveloped
benchmarking practices. To address these gaps, this paper presents three key
contributions. First, it introduces a novel taxonomy classifying CVQE methods
across architectural paradigms, coding standards, and compressed-domain feature
utilization. Second, it proposes a unified benchmarking framework integrating
modern compression protocols and standard test sequences for fair
multi-criteria evaluation. Third, it provides a systematic analysis of the
critical trade-offs between reconstruction performance and computational
complexity observed in state-of-the-art methods and highlighting promising
directions for future research. This comprehensive review aims to establish a
foundation for consistent assessment and informed model selection in CVQE
research and deployment.

</details>


### [63] [Multimodal SAM-adapter for Semantic Segmentation](https://arxiv.org/abs/2509.10408)
*Iacopo Curti,Pierluigi Zama Ramirez,Alioscia Petrelli,Luigi Di Stefano*

Main category: cs.CV

TL;DR: MM SAM-adapter通过适配器网络将多模态特征融入SAM的RGB特征，提升语义分割在复杂条件下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前语义分割方法在恶劣条件下表现不佳，多模态方法可提供互补信息增强鲁棒性。

Method: 提出MM SAM-adapter框架，通过适配器网络融合多模态特征与SAM的RGB特征。

Result: 在DeLiVER、FMB和MUSES基准测试中取得最优性能，尤其在RGB-hard子集表现突出。

Conclusion: 多模态适配能有效提升场景理解的鲁棒性，MM SAM-adapter在复杂条件下表现优异。

Abstract: Semantic segmentation, a key task in computer vision with broad applications
in autonomous driving, medical imaging, and robotics, has advanced
substantially with deep learning. Nevertheless, current approaches remain
vulnerable to challenging conditions such as poor lighting, occlusions, and
adverse weather. To address these limitations, multimodal methods that
integrate auxiliary sensor data (e.g., LiDAR, infrared) have recently emerged,
providing complementary information that enhances robustness. In this work, we
present MM SAM-adapter, a novel framework that extends the capabilities of the
Segment Anything Model (SAM) for multimodal semantic segmentation. The proposed
method employs an adapter network that injects fused multimodal features into
SAM's rich RGB features. This design enables the model to retain the strong
generalization ability of RGB features while selectively incorporating
auxiliary modalities only when they contribute additional cues. As a result, MM
SAM-adapter achieves a balanced and efficient use of multimodal information. We
evaluate our approach on three challenging benchmarks, DeLiVER, FMB, and MUSES,
where MM SAM-adapter delivers state-of-the-art performance. To further analyze
modality contributions, we partition DeLiVER and FMB into RGB-easy and RGB-hard
subsets. Results consistently demonstrate that our framework outperforms
competing methods in both favorable and adverse conditions, highlighting the
effectiveness of multimodal adaptation for robust scene understanding. The code
is available at the following link:
https://github.com/iacopo97/Multimodal-SAM-Adapter.

</details>


### [64] [InfGen: A Resolution-Agnostic Paradigm for Scalable Image Synthesis](https://arxiv.org/abs/2509.10441)
*Tao Han,Wanghan Xu,Junchao Gong,Xiaoyu Yue,Song Guo,Luping Zhou,Lei Bai*

Main category: cs.CV

TL;DR: InfGen通过一步生成器从固定大小的潜在表示解码任意分辨率图像，显著降低计算复杂度，将4K图像生成时间缩短至10秒以下。


<details>
  <summary>Details</summary>
Motivation: 解决现有扩散模型在高分辨率图像生成中计算需求急剧增加的问题，提升生成效率。

Method: 基于潜在扩散模型，用一步生成器替代VAE解码器，直接从固定潜在表示生成任意分辨率图像。

Result: InfGen显著降低计算复杂度，将4K图像生成时间从100秒以上缩短至10秒以下，适用于多种模型。

Conclusion: InfGen为高分辨率图像生成提供高效解决方案，适用于现有潜在扩散模型，推动技术进入任意高分辨率时代。

Abstract: Arbitrary resolution image generation provides a consistent visual experience
across devices, having extensive applications for producers and consumers.
Current diffusion models increase computational demand quadratically with
resolution, causing 4K image generation delays over 100 seconds. To solve this,
we explore the second generation upon the latent diffusion models, where the
fixed latent generated by diffusion models is regarded as the content
representation and we propose to decode arbitrary resolution images with a
compact generated latent using a one-step generator. Thus, we present the
\textbf{InfGen}, replacing the VAE decoder with the new generator, for
generating images at any resolution from a fixed-size latent without retraining
the diffusion models, which simplifies the process, reducing computational
complexity and can be applied to any model using the same latent space.
Experiments show InfGen is capable of improving many models into the arbitrary
high-resolution era while cutting 4K image generation time to under 10 seconds.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [65] [MimicDroid: In-Context Learning for Humanoid Robot Manipulation from Human Play Videos](https://arxiv.org/abs/2509.09769)
*Rutav Shah,Shuijing Liu,Qi Wang,Zhenyu Jiang,Sateesh Kumar,Mingyo Seo,Roberto Martín-Martín,Yuke Zhu*

Main category: cs.RO

TL;DR: MimicDroid利用人类玩耍视频作为训练数据，通过轨迹对提取和动作预测，实现人形机器人的上下文学习能力。


<details>
  <summary>Details</summary>
Motivation: 当前上下文学习方法依赖人工远程操作数据，限制了可扩展性，因此提出使用人类玩耍视频作为更高效和多样化的训练数据源。

Method: MimicDroid通过提取相似行为轨迹对并训练策略预测动作，同时利用运动学相似性将人类手腕姿势映射到机器人，并采用随机掩码减少过拟合。

Result: MimicDroid在仿真和真实世界中表现优异，成功率是现有方法的两倍。

Conclusion: MimicDroid展示了利用人类玩耍视频实现高效上下文学习的潜力，为人形机器人任务适应提供了新思路。

Abstract: We aim to enable humanoid robots to efficiently solve new manipulation tasks
from a few video examples. In-context learning (ICL) is a promising framework
for achieving this goal due to its test-time data efficiency and rapid
adaptability. However, current ICL methods rely on labor-intensive teleoperated
data for training, which restricts scalability. We propose using human play
videos -- continuous, unlabeled videos of people interacting freely with their
environment -- as a scalable and diverse training data source. We introduce
MimicDroid, which enables humanoids to perform ICL using human play videos as
the only training data. MimicDroid extracts trajectory pairs with similar
manipulation behaviors and trains the policy to predict the actions of one
trajectory conditioned on the other. Through this process, the model acquired
ICL capabilities for adapting to novel objects and environments at test time.
To bridge the embodiment gap, MimicDroid first retargets human wrist poses
estimated from RGB videos to the humanoid, leveraging kinematic similarity. It
also applies random patch masking during training to reduce overfitting to
human-specific cues and improve robustness to visual differences. To evaluate
few-shot learning for humanoids, we introduce an open-source simulation
benchmark with increasing levels of generalization difficulty. MimicDroid
outperformed state-of-the-art methods and achieved nearly twofold higher
success rates in the real world. Additional materials can be found on:
ut-austin-rpl.github.io/MimicDroid

</details>


### [66] [MIMo grows! Simulating body and sensory development in a multimodal infant model](https://arxiv.org/abs/2509.09805)
*Francisco M. López,Miles Lenz,Marco G. Fedozzi,Arthur Aubret,Jochen Triesch*

Main category: cs.RO

TL;DR: MIMo v2是一个多模态婴儿模型，模拟从出生到24个月婴儿的身体生长和感知运动能力变化，提高了建模的真实性。


<details>
  <summary>Details</summary>
Motivation: 现有机器人或仿真平台通常针对特定年龄设计，无法捕捉婴儿发育中的能力变化和限制。

Method: MIMo v2包含生长的身体、增强的驱动强度、发展中的视觉敏锐度、感觉运动延迟模拟，并新增逆运动学模块和随机环境生成器。

Result: 新版本显著提升了感觉运动发育建模的真实性。

Conclusion: MIMo v2为研究婴儿发育提供了更真实的仿真工具，代码已开源。

Abstract: Infancy is characterized by rapid body growth and an explosive change of
sensory and motor abilities. However, developmental robots and simulation
platforms are typically designed in the image of a specific age, which limits
their ability to capture the changing abilities and constraints of developing
infants. To address this issue, we present MIMo v2, a new version of the
multimodal infant model. It includes a growing body with increasing actuation
strength covering the age range from birth to 24 months. It also features
foveated vision with developing visual acuity as well as sensorimotor delays
modeling finite signal transmission speeds to and from an infant's brain.
Further enhancements of this MIMo version include an inverse kinematics module,
a random environment generator and updated compatiblity with third-party
simulation and learning libraries. Overall, this new MIMo version permits
increased realism when modeling various aspects of sensorimotor development.
The code is available on the official repository
(https://github.com/trieschlab/MIMo).

</details>


### [67] [Using the Pepper Robot to Support Sign Language Communication](https://arxiv.org/abs/2509.09889)
*Giulia Botta,Marco Botta,Cristina Gena,Alessandro Mazzei,Massimo Donini,Alberto Lillo*

Main category: cs.RO

TL;DR: 研究探讨商业社交机器人Pepper是否能生成可理解的意大利手语（LIS）符号和短句，结果显示多数孤立符号可识别，但完整句子识别率较低。


<details>
  <summary>Details</summary>
Motivation: 提升聋哑用户在社交机器人交互中的包容性，尤其是在公共场所和辅助环境中。

Method: 与聋哑学生和手语专家合作，设计了52个LIS符号，并通过用户研究评估识别效果。

Result: 多数孤立符号被正确识别，但完整句子识别率因机器人动作限制较低。

Conclusion: 商业机器人可部分实现LIS符号交互，未来需多模态增强和用户参与设计。

Abstract: Social robots are increasingly experimented in public and assistive settings,
but their accessibility for Deaf users remains quite underexplored. Italian
Sign Language (LIS) is a fully-fledged natural language that relies on complex
manual and non-manual components. Enabling robots to communicate using LIS
could foster more inclusive human robot interaction, especially in social
environments such as hospitals, airports, or educational settings. This study
investigates whether a commercial social robot, Pepper, can produce
intelligible LIS signs and short signed LIS sentences. With the help of a Deaf
student and his interpreter, an expert in LIS, we co-designed and implemented
52 LIS signs on Pepper using either manual animation techniques or a MATLAB
based inverse kinematics solver. We conducted a exploratory user study
involving 12 participants proficient in LIS, both Deaf and hearing.
Participants completed a questionnaire featuring 15 single-choice video-based
sign recognition tasks and 2 open-ended questions on short signed sentences.
Results shows that the majority of isolated signs were recognized correctly,
although full sentence recognition was significantly lower due to Pepper's
limited articulation and temporal constraints. Our findings demonstrate that
even commercially available social robots like Pepper can perform a subset of
LIS signs intelligibly, offering some opportunities for a more inclusive
interaction design. Future developments should address multi-modal enhancements
(e.g., screen-based support or expressive avatars) and involve Deaf users in
participatory design to refine robot expressivity and usability.

</details>


### [68] [Self-Augmented Robot Trajectory: Efficient Imitation Learning via Safe Self-augmentation with Demonstrator-annotated Precision](https://arxiv.org/abs/2509.09893)
*Hanbit Oh,Masaki Murooka,Tomohiro Motoda,Ryoichi Nakajo,Yukiyasu Domae*

Main category: cs.RO

TL;DR: SART框架通过单次人类演示和自主数据增强，高效且安全地学习机器人策略。


<details>
  <summary>Details</summary>
Motivation: 减少模仿学习中的人类负担和数据需求，同时确保安全性。

Method: 两阶段框架：单次人类演示标注边界，机器人自主生成多样无碰撞轨迹。

Result: 在仿真和实际任务中，SART比仅基于人类演示的策略成功率更高。

Conclusion: SART显著提升了数据效率和安全性，适用于有限空间任务。

Abstract: Imitation learning is a promising paradigm for training robot agents;
however, standard approaches typically require substantial data acquisition --
via numerous demonstrations or random exploration -- to ensure reliable
performance. Although exploration reduces human effort, it lacks safety
guarantees and often results in frequent collisions -- particularly in
clearance-limited tasks (e.g., peg-in-hole) -- thereby, necessitating manual
environmental resets and imposing additional human burden. This study proposes
Self-Augmented Robot Trajectory (SART), a framework that enables policy
learning from a single human demonstration, while safely expanding the dataset
through autonomous augmentation. SART consists of two stages: (1) human
teaching only once, where a single demonstration is provided and precision
boundaries -- represented as spheres around key waypoints -- are annotated,
followed by one environment reset; (2) robot self-augmentation, where the robot
generates diverse, collision-free trajectories within these boundaries and
reconnects to the original demonstration. This design improves the data
collection efficiency by minimizing human effort while ensuring safety.
Extensive evaluations in simulation and real-world manipulation tasks show that
SART achieves substantially higher success rates than policies trained solely
on human-collected demonstrations. Video results available at
https://sites.google.com/view/sart-il .

</details>


### [69] [Detection of Anomalous Behavior in Robot Systems Based on Machine Learning](https://arxiv.org/abs/2509.09953)
*Mahfuzul I. Nissan,Sharmin Aktar*

Main category: cs.RO

TL;DR: 论文提出了一种基于机器学习的异常检测方法，用于提升机器人系统的安全性和可靠性，并通过不同场景验证了模型的选择需依赖具体上下文。


<details>
  <summary>Details</summary>
Motivation: 机器人系统的安全性和可靠性至关重要，但即使经过严格设计仍可能出现故障。本研究旨在通过机器学习方法检测系统日志中的异常，以减少潜在风险。

Method: 使用CoppeliaSim收集两种不同场景（四旋翼无人机和Pioneer机器人）的系统日志，并比较了逻辑回归（LR）、支持向量机（SVM）和自编码器（Autoencoder）的性能。

Result: 在四旋翼无人机场景中，LR表现最佳；而在Pioneer机器人场景中，自编码器效果最好，表明模型选择需根据具体场景的异常复杂性而定。

Conclusion: 研究强调了比较方法的价值，并展示了自编码器在检测复杂异常中的优势，为机器人系统的安全优化提供了实用指导。

Abstract: Ensuring the safe and reliable operation of robotic systems is paramount to
prevent potential disasters and safeguard human well-being. Despite rigorous
design and engineering practices, these systems can still experience
malfunctions, leading to safety risks. In this study, we present a machine
learning-based approach for detecting anomalies in system logs to enhance the
safety and reliability of robotic systems. We collected logs from two distinct
scenarios using CoppeliaSim and comparatively evaluated several machine
learning models, including Logistic Regression (LR), Support Vector Machine
(SVM), and an Autoencoder. Our system was evaluated in a quadcopter context
(Context 1) and a Pioneer robot context (Context 2). Results showed that while
LR demonstrated superior performance in Context 1, the Autoencoder model proved
to be the most effective in Context 2. This highlights that the optimal model
choice is context-dependent, likely due to the varying complexity of anomalies
across different robotic platforms. This research underscores the value of a
comparative approach and demonstrates the particular strengths of autoencoders
for detecting complex anomalies in robotic systems.

</details>


### [70] [Gaussian path model library for intuitive robot motion programming by demonstration](https://arxiv.org/abs/2509.10007)
*Samuli Soutukorva,Markku Suomalainen,Martin Kollingbaum,Tapio Heikkilä*

Main category: cs.RO

TL;DR: 提出了一种基于高斯路径模型的系统，用于从教学数据生成路径形状，并用于分类人类演示路径。


<details>
  <summary>Details</summary>
Motivation: 通过生成多种形状的高斯路径模型库，实现直观的机器人运动编程。

Method: 利用教学数据生成高斯路径模型，并通过几何分析修改现有模型。

Result: 系统能够分类人类演示路径，并支持模型修改。

Conclusion: 高斯路径模型为机器人运动编程提供了有效且直观的方法。

Abstract: This paper presents a system for generating Gaussian path models from
teaching data representing the path shape. In addition, methods for using these
path models to classify human demonstrations of paths are introduced. By
generating a library of multiple Gaussian path models of various shapes, human
demonstrations can be used for intuitive robot motion programming. A method for
modifying existing Gaussian path models by demonstration through geometric
analysis is also presented.

</details>


### [71] [Towards simulation-based optimization of compliant fingers for high-speed connector assembly](https://arxiv.org/abs/2509.10012)
*Richard Matthias Hartisch,Alexander Rother,Jörg Krüger,Kevin Haninger*

Main category: cs.RO

TL;DR: 提出了一种基于仿真的设计工具，用于优化柔性机械结构的参数，以提高任务成功率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 柔性机械结构的设计参数直接影响任务性能和鲁棒性，但目前的设计方法耗时或过于简化，无法满足复杂任务需求。

Method: 通过动态仿真和接触摩擦建模，优化柔性手指的设计参数，以任务级目标（如成功率）为导向。

Result: 优化后的设计参数可将容忍范围提高2.29倍，补偿工件变化达8.6毫米，但效果因任务而异。

Conclusion: 需要针对特定应用的设计工具，以考虑几何和动力学特性。

Abstract: Mechanical compliance is a key design parameter for dynamic contact-rich
manipulation, affecting task success and safety robustness over contact
geometry variation. Design of soft robotic structures, such as compliant
fingers, requires choosing design parameters which affect geometry and
stiffness, and therefore manipulation performance and robustness. Today, these
parameters are chosen through either hardware iteration, which takes
significant development time, or simplified models (e.g. planar), which can't
address complex manipulation task objectives. Improvements in dynamic
simulation, especially with contact and friction modeling, present a potential
design tool for mechanical compliance. We propose a simulation-based design
tool for compliant mechanisms which allows design with respect to task-level
objectives, such as success rate. This is applied to optimize design parameters
of a structured compliant finger to reduce failure cases inside a tolerance
window in insertion tasks. The improvement in robustness is then validated on a
real robot using tasks from the benchmark NIST task board. The finger stiffness
affects the tolerance window: optimized parameters can increase tolerable
ranges by a factor of 2.29, with workpiece variation up to 8.6 mm being
compensated. However, the trends remain task-specific. In some tasks, the
highest stiffness yields the widest tolerable range, whereas in others the
opposite is observed, motivating need for design tools which can consider
application-specific geometry and dynamics.

</details>


### [72] [Design and Evaluation of Two Spherical Systems for Mobile 3D Mapping](https://arxiv.org/abs/2509.10032)
*Marawan Khalil,Fabian Arzberger,Andreas Nüchter*

Main category: cs.RO

TL;DR: 论文介绍了两种球形机器人映射系统，评估了它们在动态运动下的LiDAR-惯性里程计（LIO）算法性能。


<details>
  <summary>Details</summary>
Motivation: 球形机器人在危险或狭窄环境中具有独特优势，但其动态运动可能影响映射精度。

Method: 设计了轻量非驱动和驱动两种球形系统，使用LiDAR-360传感器和LIO算法。

Result: 动态运动导致LIO算法性能下降，产生全局不一致的地图和不可恢复的漂移。

Conclusion: 球形机器人的高动态运动对现有LIO算法提出了挑战，需进一步优化。

Abstract: Spherical robots offer unique advantages for mapping applications in
hazardous or confined environments, thanks to their protective shells and
omnidirectional mobility. This work presents two complementary spherical
mapping systems: a lightweight, non-actuated design and an actuated variant
featuring internal pendulum-driven locomotion. Both systems are equipped with a
Livox Mid-360 solid-state LiDAR sensor and run LiDAR-Inertial Odometry (LIO)
algorithms on resource-constrained hardware. We assess the mapping accuracy of
these systems by comparing the resulting 3D point-clouds from the LIO
algorithms to a ground truth map. The results indicate that the performance of
state-of-the-art LIO algorithms deteriorates due to the high dynamic movement
introduced by the spherical locomotion, leading to globally inconsistent maps
and sometimes unrecoverable drift.

</details>


### [73] [TwinTac: A Wide-Range, Highly Sensitive Tactile Sensor with Real-to-Sim Digital Twin Sensor Model](https://arxiv.org/abs/2509.10063)
*Xiyan Huang,Zhe Xu,Chenxi Xiao*

Main category: cs.RO

TL;DR: TwinTac系统结合物理触觉传感器及其数字孪生模型，填补了触觉感知在机器人技能学习中的模拟空白。


<details>
  <summary>Details</summary>
Motivation: 触觉传感器在机器人技能学习中的模拟模型缺失，限制了触觉感知驱动的策略发展。

Method: 设计高灵敏度物理触觉传感器，并通过真实到模拟的方法开发数字孪生模型。

Result: 实验验证了物理传感器的高灵敏度和数字孪生的一致性，模拟数据提升了分类任务准确性。

Conclusion: TwinTac在跨领域学习任务中具有潜力。

Abstract: Robot skill acquisition processes driven by reinforcement learning often rely
on simulations to efficiently generate large-scale interaction data. However,
the absence of simulation models for tactile sensors has hindered the use of
tactile sensing in such skill learning processes, limiting the development of
effective policies driven by tactile perception. To bridge this gap, we present
TwinTac, a system that combines the design of a physical tactile sensor with
its digital twin model. Our hardware sensor is designed for high sensitivity
and a wide measurement range, enabling high quality sensing data essential for
object interaction tasks. Building upon the hardware sensor, we develop the
digital twin model using a real-to-sim approach. This involves collecting
synchronized cross-domain data, including finite element method results and the
physical sensor's outputs, and then training neural networks to map simulated
data to real sensor responses. Through experimental evaluation, we
characterized the sensitivity of the physical sensor and demonstrated the
consistency of the digital twin in replicating the physical sensor's output.
Furthermore, by conducting an object classification task, we showed that
simulation data generated by our digital twin sensor can effectively augment
real-world data, leading to improved accuracy. These results highlight
TwinTac's potential to bridge the gap in cross-domain learning tasks.

</details>


### [74] [Prespecified-Performance Kinematic Tracking Control for Aerial Manipulation](https://arxiv.org/abs/2509.10065)
*Hauzi Cao,Jiahao Shen,Zhengzhen Li,Qinquan Ren,Shiyu Zhao*

Main category: cs.RO

TL;DR: 提出了一种新型的飞行机械臂运动学跟踪控制框架，结合预设轨迹和二次规划参考分配，确保末端执行器在规定时间内到达目标位置。


<details>
  <summary>Details</summary>
Motivation: 现有运动学跟踪控制方法（如比例-微分反馈或基于跟踪误差的反馈策略）可能无法在规定时间内实现跟踪目标。

Method: 采用基于预设轨迹的末端执行器跟踪控制和二次规划参考分配，同时考虑飞行机械臂的物理约束。

Result: 实验验证了算法的有效性，能够确保目标位置在规定时间内到达，并保持跟踪误差在性能范围内。

Conclusion: 所提方法在飞行机械臂的运动学跟踪控制中表现出色，解决了现有方法的局限性。

Abstract: This paper studies the kinematic tracking control problem for aerial
manipulators. Existing kinematic tracking control methods, which typically
employ proportional-derivative feedback or tracking-error-based feedback
strategies, may fail to achieve tracking objectives within specified time
constraints. To address this limitation, we propose a novel control framework
comprising two key components: end-effector tracking control based on a
user-defined preset trajectory and quadratic programming-based reference
allocation. Compared with state-of-the-art approaches, the proposed method has
several attractive features. First, it ensures that the end-effector reaches
the desired position within a preset time while keeping the tracking error
within a performance envelope that reflects task requirements. Second,
quadratic programming is employed to allocate the references of the quadcopter
base and the Delta arm, while considering the physical constraints of the
aerial manipulator, thus preventing solutions that may violate physical
limitations. The proposed approach is validated through three experiments.
Experimental results demonstrate the effectiveness of the proposed algorithm
and its capability to guarantee that the target position is reached within the
preset time.

</details>


### [75] [HHI-Assist: A Dataset and Benchmark of Human-Human Interaction in Physical Assistance Scenario](https://arxiv.org/abs/2509.10096)
*Saeed Saadatnejad,Reyhaneh Hosseininejad,Jose Barreiros,Katherine M. Tsui,Alexandre Alahi*

Main category: cs.RO

TL;DR: 论文提出了一种基于Transformer的去噪扩散模型和HHI-Assist数据集，用于预测辅助任务中的人体运动，提升了机器人辅助策略的准确性。


<details>
  <summary>Details</summary>
Motivation: 劳动力短缺和人口老龄化加剧了对辅助机器人的需求，但人体运动预测在物理交互场景中仍具挑战性。

Method: 提出HHI-Assist数据集和基于条件Transformer的去噪扩散模型，用于预测交互中的人体姿态。

Result: 模型能有效捕捉交互动态，优于基线方法，并在未见场景中表现良好。

Conclusion: 该研究通过新数据集和模型，显著提升了机器人辅助策略的交互感知能力。

Abstract: The increasing labor shortage and aging population underline the need for
assistive robots to support human care recipients. To enable safe and
responsive assistance, robots require accurate human motion prediction in
physical interaction scenarios. However, this remains a challenging task due to
the variability of assistive settings and the complexity of coupled dynamics in
physical interactions. In this work, we address these challenges through two
key contributions: (1) HHI-Assist, a dataset comprising motion capture clips of
human-human interactions in assistive tasks; and (2) a conditional
Transformer-based denoising diffusion model for predicting the poses of
interacting agents. Our model effectively captures the coupled dynamics between
caregivers and care receivers, demonstrating improvements over baselines and
strong generalization to unseen scenarios. By advancing interaction-aware
motion prediction and introducing a new dataset, our work has the potential to
significantly enhance robotic assistance policies. The dataset and code are
available at: https://sites.google.com/view/hhi-assist/home

</details>


### [76] [Efficient Learning-Based Control of a Legged Robot in Lunar Gravity](https://arxiv.org/abs/2509.10128)
*Philip Arm,Oliver Fischer,Joseph Church,Adrian Fuhrer,Hendrik Kolvenbach,Marco Hutter*

Main category: cs.RO

TL;DR: 提出了一种基于强化学习的节能控制方法，用于腿式机器人在不同重力环境中的运动控制。


<details>
  <summary>Details</summary>
Motivation: 腿式机器人在低重力环境（如月球、火星）中具有优势，但受限于能源和热预算，需要高效的节能控制方法。

Method: 采用强化学习框架，结合重力比例功率优化奖励函数，开发了运动控制器和基础姿态控制器。

Result: 在地球重力下，功率优化控制器将功耗降低23%；在月球重力下，功耗降低36%。

Conclusion: 该方法为腿式机器人在多重力环境中的高效节能控制提供了可扩展的解决方案。

Abstract: Legged robots are promising candidates for exploring challenging areas on
low-gravity bodies such as the Moon, Mars, or asteroids, thanks to their
advanced mobility on unstructured terrain. However, as planetary robots' power
and thermal budgets are highly restricted, these robots need energy-efficient
control approaches that easily transfer to multiple gravity environments. In
this work, we introduce a reinforcement learning-based control approach for
legged robots with gravity-scaled power-optimized reward functions. We use our
approach to develop and validate a locomotion controller and a base pose
controller in gravity environments from lunar gravity (1.62 m/s2) to a
hypothetical super-Earth (19.62 m/s2). Our approach successfully scales across
these gravity levels for locomotion and base pose control with the
gravity-scaled reward functions. The power-optimized locomotion controller
reached a power consumption for locomotion of 23.4 W in Earth gravity on a
15.65 kg robot at 0.4 m/s, a 23 % improvement over the baseline policy.
Additionally, we designed a constant-force spring offload system that allowed
us to conduct real-world experiments on legged locomotion in lunar gravity. In
lunar gravity, the power-optimized control policy reached 12.2 W, 36 % less
than a baseline controller which is not optimized for power efficiency. Our
method provides a scalable approach to developing power-efficient locomotion
controllers for legged robots across multiple gravity levels.

</details>


### [77] [CaR1: A Multi-Modal Baseline for BEV Vehicle Segmentation via Camera-Radar Fusion](https://arxiv.org/abs/2509.10139)
*Santiago Montiel-Marín,Angel Llamazares,Miguel Antunes-García,Fabio Sánchez-García,Luis M. Bergasa*

Main category: cs.RO

TL;DR: CaR1是一种新颖的相机-雷达融合架构，用于BEV车辆分割，结合了雷达点云的结构化编码和动态传感器融合机制，性能与现有最佳方法相当。


<details>
  <summary>Details</summary>
Motivation: 相机和雷达在自动驾驶中各有优劣，相机提供丰富的语义信息但深度不可靠，雷达提供稀疏但可靠的位置和运动信息。结合两者可以提升系统的鲁棒性和成本效益。

Method: 基于BEVFusion，CaR1采用网格化雷达编码将点云离散化为结构化BEV特征，并通过自适应融合机制动态平衡传感器贡献。

Result: 在nuScenes数据集上，CaR1实现了57.6 IoU的分割性能，与现有最佳方法相当。

Conclusion: CaR1展示了相机-雷达融合在BEV车辆分割中的潜力，代码已开源。

Abstract: Camera-radar fusion offers a robust and cost-effective alternative to
LiDAR-based autonomous driving systems by combining complementary sensing
capabilities: cameras provide rich semantic cues but unreliable depth, while
radar delivers sparse yet reliable position and motion information. We
introduce CaR1, a novel camera-radar fusion architecture for BEV vehicle
segmentation. Built upon BEVFusion, our approach incorporates a grid-wise radar
encoding that discretizes point clouds into structured BEV features and an
adaptive fusion mechanism that dynamically balances sensor contributions.
Experiments on nuScenes demonstrate competitive segmentation performance (57.6
IoU), on par with state-of-the-art methods. Code is publicly available
\href{https://www.github.com/santimontiel/car1}{online}.

</details>


### [78] [DiffAero: A GPU-Accelerated Differentiable Simulation Framework for Efficient Quadrotor Policy Learning](https://arxiv.org/abs/2509.10247)
*Xinhong Zhang,Runqing Wang,Yunfan Ren,Jian Sun,Hao Fang,Jie Chen,Gang Wang*

Main category: cs.RO

TL;DR: DiffAero是一个轻量级、GPU加速的完全可微分仿真框架，用于高效学习四旋翼控制策略。


<details>
  <summary>Details</summary>
Motivation: 现有仿真器在性能和可微分学习算法探索方面存在不足，DiffAero旨在解决这些问题。

Method: DiffAero支持环境和代理级并行，集成多种动力学模型、传感器堆栈和飞行任务，完全在GPU上并行化物理和渲染。

Result: DiffAero显著提升了仿真吞吐量，并在消费级硬件上快速学习到鲁棒飞行策略。

Conclusion: DiffAero不仅提供高性能仿真，还为可微分和混合学习算法研究提供了平台。

Abstract: This letter introduces DiffAero, a lightweight, GPU-accelerated, and fully
differentiable simulation framework designed for efficient quadrotor control
policy learning. DiffAero supports both environment-level and agent-level
parallelism and integrates multiple dynamics models, customizable sensor stacks
(IMU, depth camera, and LiDAR), and diverse flight tasks within a unified,
GPU-native training interface. By fully parallelizing both physics and
rendering on the GPU, DiffAero eliminates CPU-GPU data transfer bottlenecks and
delivers orders-of-magnitude improvements in simulation throughput. In contrast
to existing simulators, DiffAero not only provides high-performance simulation
but also serves as a research platform for exploring differentiable and hybrid
learning algorithms. Extensive benchmarks and real-world flight experiments
demonstrate that DiffAero and hybrid learning algorithms combined can learn
robust flight policies in hours on consumer-grade hardware. The code is
available at https://github.com/flyingbitac/diffaero.

</details>


### [79] [GundamQ: Multi-Scale Spatio-Temporal Representation Learning for Robust Robot Path Planning](https://arxiv.org/abs/2509.10305)
*Yutong Shen,Ruizhe Xia,Bokai Yan,Shunqi zhang,Pengrui Xiang,Sicheng He,Yixin Xu*

Main category: cs.RO

TL;DR: GundamQ是一种用于机器人路径规划的多尺度时空Q网络，通过改进时空感知和自适应策略优化，显著提升了动态环境中的路径规划性能。


<details>
  <summary>Details</summary>
Motivation: 当前深度强化学习方法在动态环境中存在多尺度时间依赖性建模不足和探索-利用平衡效率低的问题。

Method: 提出GundamQ框架，包含时空感知模块（提取多粒度空间特征和多尺度时间依赖性）和自适应策略优化模块（平衡探索与利用）。

Result: 实验显示GundamQ在动态环境中成功率提高15.3%，路径质量提升21.7%。

Conclusion: GundamQ在动态环境中显著优于现有方法，解决了路径规划中的关键挑战。

Abstract: In dynamic and uncertain environments, robotic path planning demands accurate
spatiotemporal environment understanding combined with robust decision-making
under partial observability. However, current deep reinforcement learning-based
path planning methods face two fundamental limitations: (1) insufficient
modeling of multi-scale temporal dependencies, resulting in suboptimal
adaptability in dynamic scenarios, and (2) inefficient exploration-exploitation
balance, leading to degraded path quality. To address these challenges, we
propose GundamQ: A Multi-Scale Spatiotemporal Q-Network for Robotic Path
Planning. The framework comprises two key modules: (i) the Spatiotemporal
Perception module, which hierarchically extracts multi-granularity spatial
features and multi-scale temporal dependencies ranging from instantaneous to
extended time horizons, thereby improving perception accuracy in dynamic
environments; and (ii) the Adaptive Policy Optimization module, which balances
exploration and exploitation during training while optimizing for smoothness
and collision probability through constrained policy updates. Experiments in
dynamic environments demonstrate that GundamQ achieves a 15.3\% improvement in
success rate and a 21.7\% increase in overall path quality, significantly
outperforming existing state-of-the-art methods.

</details>


### [80] [Robot guide with multi-agent control and automatic scenario generation with LLM](https://arxiv.org/abs/2509.10317)
*Elizaveta D. Moskovskaya,Anton D. Moscowsky*

Main category: cs.RO

TL;DR: 提出了一种结合多智能体资源管理和大型语言模型的混合控制架构，用于人形导游机器人，以解决传统系统手动配置的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统导游机器人系统依赖手动调整行为场景，存在配置繁琐、灵活性低和行为不自然的问题。

Method: 采用两阶段生成方法：首先生成风格化叙述，然后整合非语言动作标签；多智能体系统协调并行动作和冲突解决。

Result: 试验结果表明，该方法在自动化和扩展社交机器人控制系统方面具有潜力。

Conclusion: 混合控制架构能有效提升导游机器人的行为自然性和系统灵活性。

Abstract: The work describes the development of a hybrid control architecture for an
anthropomorphic tour guide robot, combining a multi-agent resource management
system with automatic behavior scenario generation based on large language
models. The proposed approach aims to overcome the limitations of traditional
systems, which rely on manual tuning of behavior scenarios. These limitations
include manual configuration, low flexibility, and lack of naturalness in robot
behavior. The process of preparing tour scenarios is implemented through a
two-stage generation: first, a stylized narrative is created, then non-verbal
action tags are integrated into the text. The multi-agent system ensures
coordination and conflict resolution during the execution of parallel actions,
as well as maintaining default behavior after the completion of main
operations, contributing to more natural robot behavior. The results obtained
from the trial demonstrate the potential of the proposed approach for
automating and scaling social robot control systems.

</details>


### [81] [Acetrans: An Autonomous Corridor-Based and Efficient UAV Suspended Transport System](https://arxiv.org/abs/2509.10349)
*Weiyan Lu,Huizhe Li,Yuhao Fang,Zhexuan Zhou,Junda Wu,Yude Li,Youmin Gong,Jie Mei*

Main category: cs.RO

TL;DR: Acetrans是一个基于感知、规划和控制的统一框架，用于解决无人机悬挂运输系统中的感知、规划和控制问题。


<details>
  <summary>Details</summary>
Motivation: 现有系统在复杂环境中存在感知不可靠、规划效率低和无法保证整体安全性的问题。

Method: 提出LiDAR-IMU融合模块估计负载姿态和电缆形状，MACIRI算法生成安全飞行走廊，以及时空约束的轨迹优化和NMPC控制器。

Result: 仿真和实验结果表明，Acetrans在感知精度、规划效率和控制安全性上优于现有方法。

Conclusion: Acetrans通过统一框架显著提升了无人机悬挂运输系统的性能。

Abstract: Unmanned aerial vehicles (UAVs) with suspended payloads offer significant
advantages for aerial transportation in complex and cluttered environments.
However, existing systems face critical limitations, including unreliable
perception of the cable-payload dynamics, inefficient planning in large-scale
environments, and the inability to guarantee whole-body safety under cable
bending and external disturbances. This paper presents Acetrans, an Autonomous,
Corridor-based, and Efficient UAV suspended transport system that addresses
these challenges through a unified perception, planning, and control framework.
A LiDAR-IMU fusion module is proposed to jointly estimate both payload pose and
cable shape under taut and bent modes, enabling robust whole-body state
estimation and real-time filtering of cable point clouds. To enhance planning
scalability, we introduce the Multi-size-Aware Configuration-space Iterative
Regional Inflation (MACIRI) algorithm, which generates safe flight corridors
while accounting for varying UAV and payload geometries. A spatio-temporal,
corridor-constrained trajectory optimization scheme is then developed to ensure
dynamically feasible and collision-free trajectories. Finally, a nonlinear
model predictive controller (NMPC) augmented with cable-bending constraints
provides robust whole-body safety during execution. Simulation and experimental
results validate the effectiveness of Acetrans, demonstrating substantial
improvements in perception accuracy, planning efficiency, and control safety
compared to state-of-the-art methods.

</details>


### [82] [Self-supervised Learning Of Visual Pose Estimation Without Pose Labels By Classifying LED States](https://arxiv.org/abs/2509.10405)
*Nicholas Carlotti,Mirko Nava,Alessandro Giusti*

Main category: cs.RO

TL;DR: 提出一种无需姿态标签或机器人形状先验的单目RGB相对姿态估计模型，通过LED状态预测任务学习机器人位置、距离和相对方位。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法依赖姿态标签或CAD模型的问题，实现无监督学习。

Method: 利用机器人上的LED状态和已知视角方向，通过预测LED状态任务学习姿态估计。

Result: 在定量实验中表现与有监督方法相当，并能泛化到不同领域和多机器人场景。

Conclusion: 该方法展示了无监督学习的潜力，适用于实际应用中的姿态估计。

Abstract: We introduce a model for monocular RGB relative pose estimation of a ground
robot that trains from scratch without pose labels nor prior knowledge about
the robot's shape or appearance. At training time, we assume: (i) a robot
fitted with multiple LEDs, whose states are independent and known at each
frame; (ii) knowledge of the approximate viewing direction of each LED; and
(iii) availability of a calibration image with a known target distance, to
address the ambiguity of monocular depth estimation. Training data is collected
by a pair of robots moving randomly without needing external infrastructure or
human supervision. Our model trains on the task of predicting from an image the
state of each LED on the robot. In doing so, it learns to predict the position
of the robot in the image, its distance, and its relative bearing. At inference
time, the state of the LEDs is unknown, can be arbitrary, and does not affect
the pose estimation performance. Quantitative experiments indicate that our
approach: is competitive with SoA approaches that require supervision from pose
labels or a CAD model of the robot; generalizes to different domains; and
handles multi-robot pose estimation.

</details>


### [83] [TASC: Task-Aware Shared Control for Teleoperated Manipulation](https://arxiv.org/abs/2509.10416)
*Ze Fu,Pinhao Song,Yutong Hu,Renaud Detry*

Main category: cs.RO

TL;DR: TASC是一个任务感知共享控制框架，通过推断任务级用户意图并提供辅助，支持日常操作任务。


<details>
  <summary>Details</summary>
Motivation: 解决通用、长时共享控制中的两大挑战：推断任务级用户意图和跨多样对象与任务的辅助泛化。

Method: 构建开放词汇交互图表示功能对象关系，通过视觉语言模型预测空间约束，提供旋转辅助。

Result: 实验表明TASC提高了任务效率并减少了用户输入努力，支持零样本泛化。

Conclusion: TASC是首个支持日常操作任务且具有零样本泛化能力的共享控制框架。

Abstract: We present TASC, a Task-Aware Shared Control framework for teleoperated
manipulation that infers task-level user intent and provides assistance
throughout the task. To support everyday tasks without predefined knowledge,
TASC constructs an open-vocabulary interaction graph from visual input to
represent functional object relationships, and infers user intent accordingly.
A shared control policy then provides rotation assistance during both grasping
and object interaction, guided by spatial constraints predicted by a
vision-language model. Our method addresses two key challenges in
general-purpose, long-horizon shared control: (1) understanding and inferring
task-level user intent, and (2) generalizing assistance across diverse objects
and tasks. Experiments in both simulation and the real world demonstrate that
TASC improves task efficiency and reduces user input effort compared to prior
methods. To the best of our knowledge, this is the first shared control
framework that supports everyday manipulation tasks with zero-shot
generalization. The code that supports our experiments is publicly available at
https://github.com/fitz0401/tasc.

</details>


### [84] [DECAMP: Towards Scene-Consistent Multi-Agent Motion Prediction with Disentangled Context-Aware Pre-Training](https://arxiv.org/abs/2509.10426)
*Jianxin Shi,Zengqi Peng,Xiaolong Chen,Tianyu Wo,Jun Ma*

Main category: cs.RO

TL;DR: DECAMP是一个解耦上下文感知的预训练框架，用于多智能体运动预测，通过分离行为模式学习和潜在特征重建，提升场景表示和预测性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法在标记数据稀缺和多智能体预测场景中表现不佳的问题。

Method: 引入解耦的上下文感知预训练框架DECAMP，结合上下文感知表示学习和协作空间-运动预任务。

Result: 在Argoverse 2基准测试中表现优异，验证了其在多智能体运动预测中的有效性。

Conclusion: DECAMP是首个用于自动驾驶中多智能体运动预测的上下文自编码框架，代码和模型将公开。

Abstract: Trajectory prediction is a critical component of autonomous driving,
essential for ensuring both safety and efficiency on the road. However,
traditional approaches often struggle with the scarcity of labeled data and
exhibit suboptimal performance in multi-agent prediction scenarios. To address
these challenges, we introduce a disentangled context-aware pre-training
framework for multi-agent motion prediction, named DECAMP. Unlike existing
methods that entangle representation learning with pretext tasks, our framework
decouples behavior pattern learning from latent feature reconstruction,
prioritizing interpretable dynamics and thereby enhancing scene representation
for downstream prediction. Additionally, our framework incorporates
context-aware representation learning alongside collaborative spatial-motion
pretext tasks, which enables joint optimization of structural and intentional
reasoning while capturing the underlying dynamic intentions. Our experiments on
the Argoverse 2 benchmark showcase the superior performance of our method, and
the results attained underscore its effectiveness in multi-agent motion
forecasting. To the best of our knowledge, this is the first context
autoencoder framework for multi-agent motion forecasting in autonomous driving.
The code and models will be made publicly available.

</details>


### [85] [Coordinated Motion Planning of a Wearable Multi-Limb System for Enhanced Human-Robot Interaction](https://arxiv.org/abs/2509.10444)
*Chaerim Moon,Joohyung Kim*

Main category: cs.RO

TL;DR: 论文提出了一种运动规划层概念，以减少机器人肢体操作时对人体的外部扭矩，从而增强人机交互。


<details>
  <summary>Details</summary>
Motivation: 超级机器人肢体（SRLs）在操作时会产生外部扭矩作用于人体，增加肌肉负担并减少肌肉零空间。

Method: 通过修改给定轨迹，引入角加速度和位置偏差限制的运动规划层。

Result: 仿真实验表明该方法能有效减少扭矩。

Conclusion: 该运动规划层概念有助于优化人机交互，减少对人体的负面影响。

Abstract: Supernumerary Robotic Limbs (SRLs) can enhance human capability within close
proximity. However, as a wearable device, the generated moment from its
operation acts on the human body as an external torque. When the moments
increase, more muscle units are activated for balancing, and it can result in
reduced muscular null space. Therefore, this paper suggests a concept of a
motion planning layer that reduces the generated moment for enhanced
Human-Robot Interaction. It modifies given trajectories with desirable angular
acceleration and position deviation limits. Its performance to reduce the
moment is demonstrated through the simulation, which uses simplified human and
robotic system models.

</details>


### [86] [GC-VLN: Instruction as Graph Constraints for Training-free Vision-and-Language Navigation](https://arxiv.org/abs/2509.10454)
*Hang Yin,Haoyu Wei,Xiuwei Xu,Wenxuan Guo,Jie Zhou,Jiwen Lu*

Main category: cs.RO

TL;DR: 提出了一种无需训练的视觉与语言导航框架，通过图约束优化实现零样本适应。


<details>
  <summary>Details</summary>
Motivation: 现有零样本方法难以泛化到真实场景，需要无监督训练或仅适用于离散环境。

Method: 将导航指令分解为空间约束，构建约束库，通过约束求解器优化路径。

Result: 在标准基准测试中显著提升了成功率和导航效率，并能泛化到新环境和指令集。

Conclusion: 该框架为更鲁棒和自主的导航系统提供了可能。

Abstract: In this paper, we propose a training-free framework for vision-and-language
navigation (VLN). Existing zero-shot VLN methods are mainly designed for
discrete environments or involve unsupervised training in continuous simulator
environments, which makes it challenging to generalize and deploy them in
real-world scenarios. To achieve a training-free framework in continuous
environments, our framework formulates navigation guidance as graph constraint
optimization by decomposing instructions into explicit spatial constraints. The
constraint-driven paradigm decodes spatial semantics through constraint
solving, enabling zero-shot adaptation to unseen environments. Specifically, we
construct a spatial constraint library covering all types of spatial
relationship mentioned in VLN instructions. The human instruction is decomposed
into a directed acyclic graph, with waypoint nodes, object nodes and edges,
which are used as queries to retrieve the library to build the graph
constraints. The graph constraint optimization is solved by the constraint
solver to determine the positions of waypoints, obtaining the robot's
navigation path and final goal. To handle cases of no solution or multiple
solutions, we construct a navigation tree and the backtracking mechanism.
Extensive experiments on standard benchmarks demonstrate significant
improvements in success rate and navigation efficiency compared to
state-of-the-art zero-shot VLN methods. We further conduct real-world
experiments to show that our framework can effectively generalize to new
environments and instruction sets, paving the way for a more robust and
autonomous navigation framework.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [87] [Structure Matters: Brain Graph Augmentation via Learnable Edge Masking for Data-efficient Psychiatric Diagnosis](https://arxiv.org/abs/2509.09744)
*Mujie Liu,Chenze Wang,Liping Chen,Nguyen Linh Dan Le,Niharika Tewari,Ting Dang,Jiangang Ma,Feng Xia*

Main category: cs.LG

TL;DR: SAM-BG是一个两阶段框架，通过结构语义保护学习脑图表示，在精神病诊断中表现优异。


<details>
  <summary>Details</summary>
Motivation: 标记脑网络数据有限，现有自监督学习方法可能破坏脑图结构语义。

Method: 提出两阶段框架：预训练阶段训练边缘掩码器捕获结构语义；自监督学习阶段利用结构先验指导增强过程。

Result: 在两个真实精神病数据集上优于现有方法，尤其在标记数据少时表现更好，并发现临床相关连接模式。

Conclusion: SAM-BG能学习更具语义意义和鲁棒性的表示，提升诊断准确性和可解释性。

Abstract: The limited availability of labeled brain network data makes it challenging
to achieve accurate and interpretable psychiatric diagnoses. While
self-supervised learning (SSL) offers a promising solution, existing methods
often rely on augmentation strategies that can disrupt crucial structural
semantics in brain graphs. To address this, we propose SAM-BG, a two-stage
framework for learning brain graph representations with structural semantic
preservation. In the pre-training stage, an edge masker is trained on a small
labeled subset to capture key structural semantics. In the SSL stage, the
extracted structural priors guide a structure-aware augmentation process,
enabling the model to learn more semantically meaningful and robust
representations. Experiments on two real-world psychiatric datasets demonstrate
that SAM-BG outperforms state-of-the-art methods, particularly in small-labeled
data settings, and uncovers clinically relevant connectivity patterns that
enhance interpretability. Our code is available at
https://github.com/mjliu99/SAM-BG.

</details>


### [88] [D-CAT: Decoupled Cross-Attention Transfer between Sensor Modalities for Unimodal Inference](https://arxiv.org/abs/2509.09747)
*Leen Daher,Zhaobo Wang,Malcolm Mielle*

Main category: cs.LG

TL;DR: D-CAT框架通过解耦跨模态注意力转移，实现单传感器推理，提升多模态分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有跨模态学习方法需要成对传感器数据，限制了资源受限环境中的应用。

Method: 结合自注意力模块和新型跨注意力对齐损失，无需推理时联合传感器模态。

Result: 在分布内和分布外场景中，D-CAT显著提升性能，最高达10% F1分数增益。

Conclusion: D-CAT减少硬件冗余，适用于成本敏感或自适应部署场景。

Abstract: Cross-modal transfer learning is used to improve multi-modal classification
models (e.g., for human activity recognition in human-robot collaboration).
However, existing methods require paired sensor data at both training and
inference, limiting deployment in resource-constrained environments where full
sensor suites are not economically and technically usable. To address this, we
propose Decoupled Cross-Attention Transfer (D-CAT), a framework that aligns
modality-specific representations without requiring joint sensor modality
during inference. Our approach combines a self-attention module for feature
extraction with a novel cross-attention alignment loss, which enforces the
alignment of sensors' feature spaces without requiring the coupling of the
classification pipelines of both modalities. We evaluate D-CAT on three
multi-modal human activity datasets (IMU, video, and audio) under both
in-distribution and out-of-distribution scenarios, comparing against uni-modal
models. Results show that in in-distribution scenarios, transferring from
high-performing modalities (e.g., video to IMU) yields up to 10% F1-score gains
over uni-modal training. In out-of-distribution scenarios, even weaker source
modalities (e.g., IMU to video) improve target performance, as long as the
target model isn't overfitted on the training data. By enabling single-sensor
inference with cross-modal knowledge, D-CAT reduces hardware redundancy for
perception systems while maintaining accuracy, which is critical for
cost-sensitive or adaptive deployments (e.g., assistive robots in homes with
variable sensor availability). Code is available at
https://github.com/Schindler-EPFL-Lab/D-CAT.

</details>


### [89] [Meta-Learning Reinforcement Learning for Crypto-Return Prediction](https://arxiv.org/abs/2509.09751)
*Junqiao Wang,Zhaoyang Guan,Guanyu Liu,Tianze Xia,Xianzhi Li,Shuo Yin,Xinyuan Song,Chuhan Cheng,Tianyu Shi,Alex Lee*

Main category: cs.LG

TL;DR: Meta-RL-Crypto是一个基于Transformer的统一架构，结合元学习和强化学习，创建了一个自我改进的交易代理，无需人工监督，并在多样化的市场环境中表现优异。


<details>
  <summary>Details</summary>
Motivation: 预测加密货币回报困难，因为价格受多种因素驱动且标记数据稀缺昂贵。

Method: 通过迭代扮演actor、judge和meta-judge角色，结合元学习和强化学习，利用多模态市场输入和内部偏好反馈。

Result: 在多样化市场环境中表现优异，优于其他基于LLM的基线。

Conclusion: Meta-RL-Crypto是一个高效、自我改进的交易代理，适用于加密货币市场。

Abstract: Predicting cryptocurrency returns is notoriously difficult: price movements
are driven by a fast-shifting blend of on-chain activity, news flow, and social
sentiment, while labeled training data are scarce and expensive. In this paper,
we present Meta-RL-Crypto, a unified transformer-based architecture that
unifies meta-learning and reinforcement learning (RL) to create a fully
self-improving trading agent. Starting from a vanilla instruction-tuned LLM,
the agent iteratively alternates between three roles-actor, judge, and
meta-judge-in a closed-loop architecture. This learning process requires no
additional human supervision. It can leverage multimodal market inputs and
internal preference feedback. The agent in the system continuously refines both
the trading policy and evaluation criteria. Experiments across diverse market
regimes demonstrate that Meta-RL-Crypto shows good performance on the technical
indicators of the real market and outperforming other LLM-based baselines.

</details>


### [90] [LAVa: Layer-wise KV Cache Eviction with Dynamic Budget Allocation](https://arxiv.org/abs/2509.09754)
*Yiqun Shen,Song Yuan,Zhengze Zhang,Xiaoliang Wang,Daxin Jiang,Nguyen Cam-Tu*

Main category: cs.LG

TL;DR: KV Cache压缩新框架LAVa，通过最小化Transformer残差流信息损失，实现动态层和头预算分配，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有KV Cache压缩方法多为启发式且缺乏动态预算分配，限制了性能。

Method: 提出统一框架，分析层注意力输出损失，设计新指标动态分配头和层预算。

Result: 在多个基准测试中表现优异，动态层预算对生成任务关键，动态头预算对抽取任务重要。

Conclusion: LAVa作为全动态压缩方法，在各种任务中保持高性能，代码已开源。

Abstract: KV Cache is commonly used to accelerate LLM inference with long contexts, yet
its high memory demand drives the need for cache compression. Existing
compression methods, however, are largely heuristic and lack dynamic budget
allocation. To address this limitation, we introduce a unified framework for
cache compression by minimizing information loss in Transformer residual
streams. Building on it, we analyze the layer attention output loss and derive
a new metric to compare cache entries across heads, enabling layer-wise
compression with dynamic head budgets. Additionally, by contrasting cross-layer
information, we also achieve dynamic layer budgets. LAVa is the first unified
strategy for cache eviction and dynamic budget allocation that, unlike prior
methods, does not rely on training or the combination of multiple strategies.
Experiments with benchmarks (LongBench, Needle-In-A-Haystack, Ruler, and
InfiniteBench) demonstrate its superiority. Moreover, our experiments reveal a
new insight: dynamic layer budgets are crucial for generation tasks (e.g., code
completion), while dynamic head budgets play a key role in extraction tasks
(e.g., extractive QA). As a fully dynamic compression method, LAVa consistently
maintains top performance across task types. Our code is available at
https://github.com/MGDDestiny/Lava.

</details>


### [91] [Hybrid Adaptive Conformal Offline Reinforcement Learning for Fair Population Health Management](https://arxiv.org/abs/2509.09772)
*Sanjay Basu,Sadiq Y. Patel,Parth Sheth,Bhairavi Muralidharan,Namrata Elamaran,Aakriti Kinra,Rajaie Batniji*

Main category: cs.LG

TL;DR: HACO框架结合风险校准与偏好优化，为医疗补助人群提供安全、公平且可审计的决策支持。


<details>
  <summary>Details</summary>
Motivation: 解决医疗补助人群健康管理中的风险控制和公平性问题。

Method: 使用混合自适应共形离线强化学习（HACO），分离风险校准与偏好优化，生成保守行动建议。

Result: HACO在风险区分（AUC ~0.81）和安全覆盖方面表现优异，同时揭示人口统计中的公平差异。

Conclusion: HACO为人口健康管理团队提供了保守且可审计的决策支持。

Abstract: Population health management programs for Medicaid populations coordinate
longitudinal outreach and services (e.g., benefits navigation, behavioral
health, social needs support, and clinical scheduling) and must be safe, fair,
and auditable. We present a Hybrid Adaptive Conformal Offline Reinforcement
Learning (HACO) framework that separates risk calibration from preference
optimization to generate conservative action recommendations at scale. In our
setting, each step involves choosing among common coordination actions (e.g.,
which member to contact, by which modality, and whether to route to a
specialized service) while controlling the near-term risk of adverse
utilization events (e.g., unplanned emergency department visits or
hospitalizations). Using a de-identified operational dataset from Waymark
comprising 2.77 million sequential decisions across 168,126 patients, HACO (i)
trains a lightweight risk model for adverse events, (ii) derives a conformal
threshold to mask unsafe actions at a target risk level, and (iii) learns a
preference policy on the resulting safe subset. We evaluate policies with a
version-agnostic fitted Q evaluation (FQE) on stratified subsets and audit
subgroup performance across age, sex, and race. HACO achieves strong risk
discrimination (AUC ~0.81) with a calibrated threshold ( {\tau} ~0.038 at
{\alpha} = 0.10), while maintaining high safe coverage. Subgroup analyses
reveal systematic differences in estimated value across demographics,
underscoring the importance of fairness auditing. Our results show that
conformal risk gating integrates cleanly with offline RL to deliver
conservative, auditable decision support for population health management
teams.

</details>


### [92] [One Head, Many Models: Cross-Attention Routing for Cost-Aware LLM Selection](https://arxiv.org/abs/2509.09782)
*Roshini Pulishetty,Mani Kishan Ghantasala,Keerthy Kaushik Dasoju,Niti Mangwani,Vishal Garimella,Aditya Mate,Somya Chatterjee,Yue Kang,Ehi Nosakhare,Sadid Hasan,Soundar Srinivasan*

Main category: cs.LG

TL;DR: 提出了一种统一的轻量级路由框架，通过单头交叉注意力机制动态选择最优LLM，显著提升性能与成本效率。


<details>
  <summary>Details</summary>
Motivation: 解决不同LLM在计算成本和性能上的差异，实现可扩展且经济高效的部署。

Method: 使用单头交叉注意力机制联合建模查询和模型嵌入，动态选择最优LLM，并提出指数奖励函数平衡性能与成本。

Result: 在RouterBench基准测试中，AIQ提升6.6%，最大性能提升2.9%，且架构轻量、泛化能力强。

Conclusion: 该框架为成本感知的LLM路由设定了新标准，高效且适用于多领域。

Abstract: The proliferation of large language models (LLMs) with varying computational
costs and performance profiles presents a critical challenge for scalable,
cost-effective deployment in real-world applications. We introduce a unified
routing framework that leverages a single-head cross-attention mechanism to
jointly model query and model embeddings, enabling dynamic selection of the
optimal LLM for each input query. Our approach is evaluated on RouterBench, a
large-scale, publicly available benchmark encompassing diverse LLM pools and
domains. By explicitly capturing fine-grained query-model interactions, our
router predicts both response quality and generation cost, achieving up to 6.6%
improvement in Average Improvement in Quality (AIQ) and 2.9% in maximum
performance over existing routers. To robustly balance performance and cost, we
propose an exponential reward function that enhances stability across user
preferences. The resulting architecture is lightweight, generalizes effectively
across domains, and demonstrates improved efficiency compared to prior methods,
establishing a new standard for cost-aware LLM routing.

</details>


### [93] [From the Gradient-Step Denoiser to the Proximal Denoiser and their associated convergent Plug-and-Play algorithms](https://arxiv.org/abs/2509.09793)
*Vincent Herfeld,Baudouin Denis de Senneville,Arthur Leclaire,Nicolas Papadakis*

Main category: cs.LG

TL;DR: 分析梯度步降噪器及其在即插即用算法中的应用。


<details>
  <summary>Details</summary>
Motivation: 即插即用算法通常使用现成的降噪器替代图像先验的邻近算子或梯度下降算子，但梯度步降噪器可以显式地训练为梯度下降算子或邻近算子。

Method: 训练梯度步降噪器，使其成为显式函数的梯度下降算子或邻近算子。

Result: 梯度步降噪器在保持最先进降噪能力的同时，实现了显式函数的梯度下降或邻近操作。

Conclusion: 梯度步降噪器为即插即用算法提供了显式且高效的图像先验处理方式。

Abstract: In this paper we analyze the Gradient-Step Denoiser and its usage in
Plug-and-Play algorithms. The Plug-and-Play paradigm of optimization algorithms
uses off the shelf denoisers to replace a proximity operator or a gradient
descent operator of an image prior. Usually this image prior is implicit and
cannot be expressed, but the Gradient-Step Denoiser is trained to be exactly
the gradient descent operator or the proximity operator of an explicit
functional while preserving state-of-the-art denoising capabilities.

</details>


### [94] [Distinguishing Startle from Surprise Events Based on Physiological Signals](https://arxiv.org/abs/2509.09799)
*Mansi Sharma,Alexandre Duchevet,Florian Daiber,Jean-Paul Imbert,Maurice Rekrut*

Main category: cs.LG

TL;DR: 论文通过机器学习和多模态融合策略，基于生理信号区分惊吓和惊讶事件，最高准确率达85.7%，并验证了模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 高风险环境中（如航空），意外事件会损害注意力和延迟决策，但惊吓和惊讶反应在实践中难以区分，现有研究多单独研究，缺乏对二者结合效应的探讨。

Method: 使用机器学习和多模态融合策略，基于生理信号区分惊吓和惊讶事件。

Result: SVM和Late Fusion方法最高准确率达85.7%；XGBoost和Late Fusion方法在区分惊吓、惊讶和基线状态时最高准确率达74.9%。

Conclusion: 研究表明生理信号可有效区分惊吓和惊讶事件，模型具有鲁棒性。

Abstract: Unexpected events can impair attention and delay decision-making, posing
serious safety risks in high-risk environments such as aviation. In particular,
reactions like startle and surprise can impact pilot performance in different
ways, yet are often hard to distinguish in practice. Existing research has
largely studied these reactions separately, with limited focus on their
combined effects or how to differentiate them using physiological data. In this
work, we address this gap by distinguishing between startle and surprise events
based on physiological signals using machine learning and multi-modal fusion
strategies. Our results demonstrate that these events can be reliably
predicted, achieving a highest mean accuracy of 85.7% with SVM and Late Fusion.
To further validate the robustness of our model, we extended the evaluation to
include a baseline condition, successfully differentiating between Startle,
Surprise, and Baseline states with a highest mean accuracy of 74.9% with
XGBoost and Late Fusion.

</details>


### [95] [Revisiting Actor-Critic Methods in Discrete Action Off-Policy Reinforcement Learning](https://arxiv.org/abs/2509.09838)
*Reza Asad,Reza Babanezhad,Sharan Vaswani*

Main category: cs.LG

TL;DR: 论文提出了一种灵活的离策略演员-评论家框架，通过解耦演员和评论家的熵耦合，提升了离散动作环境下的性能，并在理论和实验上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有基于策略的方法在离散动作环境中表现不佳，尤其是离策略学习时效果较差，因此需要重新设计演员-评论家方法。

Method: 通过解耦演员和评论家的熵耦合，并引入灵活的离策略框架，结合m步贝尔曼算子和熵正则化优化策略。

Result: 理论证明在表格设置中可收敛到最优正则化值函数，实验显示在Atari游戏中性能接近DQN。

Conclusion: 提出的方法在离散动作环境中表现优异，无需显式探索或熵正则化即可达到高性能。

Abstract: Value-based approaches such as DQN are the default methods for off-policy
reinforcement learning with discrete-action environments such as Atari. Common
policy-based methods are either on-policy and do not effectively learn from
off-policy data (e.g. PPO), or have poor empirical performance in the
discrete-action setting (e.g. SAC). Consequently, starting from discrete SAC
(DSAC), we revisit the design of actor-critic methods in this setting. First,
we determine that the coupling between the actor and critic entropy is the
primary reason behind the poor performance of DSAC. We demonstrate that by
merely decoupling these components, DSAC can have comparable performance as
DQN. Motivated by this insight, we introduce a flexible off-policy actor-critic
framework that subsumes DSAC as a special case. Our framework allows using an
m-step Bellman operator for the critic update, and enables combining standard
policy optimization methods with entropy regularization to instantiate the
resulting actor objective. Theoretically, we prove that the proposed methods
can guarantee convergence to the optimal regularized value function in the
tabular setting. Empirically, we demonstrate that these methods can approach
the performance of DQN on standard Atari games, and do so even without entropy
regularization or explicit exploration.

</details>


### [96] [HGEN: Heterogeneous Graph Ensemble Networks](https://arxiv.org/abs/2509.09843)
*Jiajun Shen,Yufei Jin,Yi He,Xingquan Zhu*

Main category: cs.LG

TL;DR: HGEN是一种针对异构图的开创性集成学习框架，通过元路径和转换优化提升分类准确性。


<details>
  <summary>Details</summary>
Motivation: 异构图中的节点类型、特征和局部拓扑结构多样性对集成学习提出了挑战，HGEN旨在解决这一问题。

Method: HGEN结合元路径和随机丢弃创建Allele GNNs，并通过残差注意力机制和相关性正则化优化集成学习。

Result: 在五个异构网络上，HGEN显著优于现有方法。

Conclusion: HGEN通过提升基础学习器准确性和多样性，实现了高效的异构图集成学习。

Abstract: This paper presents HGEN that pioneers ensemble learning for heterogeneous
graphs. We argue that the heterogeneity in node types, nodal features, and
local neighborhood topology poses significant challenges for ensemble learning,
particularly in accommodating diverse graph learners. Our HGEN framework
ensembles multiple learners through a meta-path and transformation-based
optimization pipeline to uplift classification accuracy. Specifically, HGEN
uses meta-path combined with random dropping to create Allele Graph Neural
Networks (GNNs), whereby the base graph learners are trained and aligned for
later ensembling. To ensure effective ensemble learning, HGEN presents two key
components: 1) a residual-attention mechanism to calibrate allele GNNs of
different meta-paths, thereby enforcing node embeddings to focus on more
informative graphs to improve base learner accuracy, and 2) a
correlation-regularization term to enlarge the disparity among embedding
matrices generated from different meta-paths, thereby enriching base learner
diversity. We analyze the convergence of HGEN and attest its higher
regularization magnitude over simple voting. Experiments on five heterogeneous
networks validate that HGEN consistently outperforms its state-of-the-art
competitors by substantial margin.

</details>


### [97] [Latency and Token-Aware Test-Time Compute](https://arxiv.org/abs/2509.09864)
*Jenny Y. Huang,Mehul Damani,Yousef El-Kurdi,Ramon Astudillo,Wei Sun*

Main category: cs.LG

TL;DR: 论文提出了一种动态计算分配框架，优化LLM推理时的性能和延迟。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注并行生成（如best-of-N），忽略了增量解码（如beam search），且忽视了延迟问题。

Method: 将推理时扩展问题建模为动态计算分配和方法选择，同时考虑token成本和延迟。

Result: 实验表明，该方法在推理基准测试中优于静态策略，实现了更好的准确性与成本平衡。

Conclusion: 该框架在保持实用性的同时，显著提升了LLM的性能和效率。

Abstract: Inference-time scaling has emerged as a powerful way to improve large
language model (LLM) performance by generating multiple candidate responses and
selecting among them. However, existing work on dynamic allocation for
test-time compute typically considers only parallel generation methods such as
best-of-N, overlooking incremental decoding methods like beam search, and has
largely ignored latency, focusing only on token usage. We formulate
inference-time scaling as a problem of dynamic compute allocation and method
selection, where the system must decide which strategy to apply and how much
compute to allocate on a per-query basis. Our framework explicitly incorporates
both token cost and wall-clock latency, the latter being critical for user
experience and particularly for agentic workflows where models must issue
multiple queries efficiently. Experiments on reasoning benchmarks show that our
approach consistently outperforms static strategies, achieving favorable
accuracy-cost trade-offs while remaining practical for deployment.

</details>


### [98] [Variational Neural Networks for Observable Thermodynamics (V-NOTS)](https://arxiv.org/abs/2509.09899)
*Christopher Eldred,François Gay-Balmaz,Vakhtang Putkaradze*

Main category: cs.LG

TL;DR: 提出了一种基于可观测变量的数据驱动计算框架，用于描述耗散动力系统的相空间演化。


<details>
  <summary>Details</summary>
Motivation: 解决耗散动力系统中动量和熵无法直接观测的问题。

Method: 基于热力学拉格朗日方法构建神经网络，确保热力学约束和熵不减演化。

Result: 网络能够基于有限数据点和少量参数高效描述相空间演化。

Conclusion: 该方法为无法直接观测变量的系统提供了一种有效的计算框架。

Abstract: Much attention has recently been devoted to data-based computing of evolution
of physical systems. In such approaches, information about data points from
past trajectories in phase space is used to reconstruct the equations of motion
and to predict future solutions that have not been observed before. However, in
many cases, the available data does not correspond to the variables that define
the system's phase space. We focus our attention on the important example of
dissipative dynamical systems. In that case, the phase space consists of
coordinates, momenta and entropies; however, the momenta and entropies cannot,
in general, be observed directly. To address this difficulty, we develop an
efficient data-based computing framework based exclusively on observable
variables, by constructing a novel approach based on the \emph{thermodynamic
Lagrangian}, and constructing neural networks that respect the thermodynamics
and guarantees the non-decreasing entropy evolution. We show that our network
can provide an efficient description of phase space evolution based on a
limited number of data points and a relatively small number of parameters in
the system.

</details>


### [99] [LoFT: Parameter-Efficient Fine-Tuning for Long-tailed Semi-Supervised Learning in Open-World Scenarios](https://arxiv.org/abs/2509.09926)
*Jiahao Chen,Zhiyuan Huang,Yurou Liu,Bing Su*

Main category: cs.LG

TL;DR: 提出LoFT和LoFT-OW框架，通过参数高效微调解决长尾半监督学习中的过自信和低质量伪标签问题，并在开放世界场景中提升判别能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有长尾半监督学习方法在从头训练时导致的过自信和低质量伪标签问题，并探索开放世界场景下的半监督学习。

Method: 基于基础模型微调范式，提出LoFT框架生成更可靠的伪标签；进一步提出LoFT-OW处理开放世界场景中的分布外样本。

Result: 在多个基准测试中表现优于现有方法，即使仅使用1%的无标签数据。

Conclusion: LoFT和LoFT-OW通过高效微调和开放世界适应，显著提升了长尾半监督学习的性能。

Abstract: Long-tailed learning has garnered increasing attention due to its wide
applicability in real-world scenarios. Among existing approaches, Long-Tailed
Semi-Supervised Learning (LTSSL) has emerged as an effective solution by
incorporating a large amount of unlabeled data into the imbalanced labeled
dataset. However, most prior LTSSL methods are designed to train models from
scratch, which often leads to issues such as overconfidence and low-quality
pseudo-labels. To address these challenges, we extend LTSSL into the foundation
model fine-tuning paradigm and propose a novel framework: LoFT (Long-tailed
semi-supervised learning via parameter-efficient Fine-Tuning). We demonstrate
that fine-tuned foundation models can generate more reliable pseudolabels,
thereby benefiting imbalanced learning. Furthermore, we explore a more
practical setting by investigating semi-supervised learning under open-world
conditions, where the unlabeled data may include out-of-distribution (OOD)
samples. To handle this problem, we propose LoFT-OW (LoFT under Open-World
scenarios) to improve the discriminative ability. Experimental results on
multiple benchmarks demonstrate that our method achieves superior performance
compared to previous approaches, even when utilizing only 1\% of the unlabeled
data compared with previous works.

</details>


### [100] [Multi-Play Combinatorial Semi-Bandit Problem](https://arxiv.org/abs/2509.09933)
*Shintaro Nakamura,Yuko Kuroki,Wei Chen*

Main category: cs.LG

TL;DR: 论文提出了多播放组合半强盗（MP-CSB）模型，扩展了传统组合半强盗问题，支持非负整数动作，并设计了两种高效算法。


<details>
  <summary>Details</summary>
Motivation: 传统组合半强盗问题限制在二元决策空间，无法处理非负整数流或分配问题（如最优运输和背包问题），因此需要扩展模型。

Method: 提出了两种算法：基于Thompson采样的算法，适用于动作空间指数增长的情况；以及一种“两全其美”算法，适用于随机和对抗性环境。

Result: Thompson采样算法在随机环境中达到O(log T)遗憾界；“两全其美”算法在随机环境中实现O(log T)方差依赖遗憾，在对抗性环境中达到√T遗憾。

Conclusion: MP-CSB模型和算法显著优于现有方法，适用于更广泛的组合优化问题。

Abstract: In the combinatorial semi-bandit (CSB) problem, a player selects an action
from a combinatorial action set and observes feedback from the base arms
included in the action. While CSB is widely applicable to combinatorial
optimization problems, its restriction to binary decision spaces excludes
important cases involving non-negative integer flows or allocations, such as
the optimal transport and knapsack problems.To overcome this limitation, we
propose the multi-play combinatorial semi-bandit (MP-CSB), where a player can
select a non-negative integer action and observe multiple feedbacks from a
single arm in each round. We propose two algorithms for the MP-CSB. One is a
Thompson-sampling-based algorithm that is computationally feasible even when
the action space is exponentially large with respect to the number of arms, and
attains $O(\log T)$ distribution-dependent regret in the stochastic regime,
where $T$ is the time horizon. The other is a best-of-both-worlds algorithm,
which achieves $O(\log T)$ variance-dependent regret in the stochastic regime
and the worst-case $\tilde{\mathcal{O}}\left( \sqrt{T} \right)$ regret in the
adversarial regime. Moreover, its regret in adversarial one is data-dependent,
adapting to the cumulative loss of the optimal action, the total quadratic
variation, and the path-length of the loss sequence. Finally, we numerically
show that the proposed algorithms outperform existing methods in the CSB
literature.

</details>


### [101] [SciML Agents: Write the Solver, Not the Solution](https://arxiv.org/abs/2509.09936)
*Saarth Gaonkar,Xiang Zheng,Haocheng Xi,Rishabh Tiwari,Kurt Keutzer,Dmitriy Morozov,Michael W. Mahoney,Amir Gholami*

Main category: cs.LG

TL;DR: LLMs被用于生成科学计算代码，替代传统SciML方法，通过引导提示和微调提高ODE求解的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统SciML方法在准确性和鲁棒性上存在挑战，探索LLMs作为SciML代理，利用其生成代码的能力解决科学计算任务。

Method: 引入两个新数据集（诊断性和大规模ODE任务），评估LLMs在引导提示和微调下的表现，测量代码可执行性和数值有效性。

Result: 新指令跟随模型在足够上下文和引导提示下表现优异，开源系统无需微调即可强表现，旧模型通过微调提升。

Conclusion: 精心设计的提示和微调可使LLM成为可靠解决简单ODE问题的代理。

Abstract: Recent work in scientific machine learning aims to tackle scientific tasks
directly by predicting target values with neural networks (e.g.,
physics-informed neural networks, neural ODEs, neural operators, etc.), but
attaining high accuracy and robustness has been challenging. We explore an
alternative view: use LLMs to write code that leverages decades of numerical
algorithms. This shifts the burden from learning a solution function to making
domain-aware numerical choices. We ask whether LLMs can act as SciML agents
that, given a natural-language ODE description, generate runnable code that is
scientifically appropriate, selecting suitable solvers (stiff vs. non-stiff),
and enforcing stability checks. There is currently no benchmark to measure this
kind of capability for scientific computing tasks. As such, we first introduce
two new datasets: a diagnostic dataset of adversarial "misleading" problems;
and a large-scale benchmark of 1,000 diverse ODE tasks. The diagnostic set
contains problems whose superficial appearance suggests stiffness, and that
require algebraic simplification to demonstrate non-stiffness; and the
large-scale benchmark spans stiff and non-stiff ODE regimes. We evaluate open-
and closed-source LLM models along two axes: (i) unguided versus guided
prompting with domain-specific knowledge; and (ii) off-the-shelf versus
fine-tuned variants. Our evaluation measures both executability and numerical
validity against reference solutions. We find that with sufficient context and
guided prompts, newer instruction-following models achieve high accuracy on
both criteria. In many cases, recent open-source systems perform strongly
without fine-tuning, while older or smaller models still benefit from
fine-tuning. Overall, our preliminary results indicate that careful prompting
and fine-tuning can yield a specialized LLM agent capable of reliably solving
simple ODE problems.

</details>


### [102] [DyKen-Hyena: Dynamic Kernel Generation via Cross-Modal Attention for Multimodal Intent Recognition](https://arxiv.org/abs/2509.09940)
*Yifei Wang,Wenbin Wang,Yong Luo*

Main category: cs.LG

TL;DR: DyKen-Hyena通过动态卷积核调制文本特征提取，解决了多模态意图识别中模态间冲突的问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 多模态意图识别中，模态间的无关或冲突信息可能影响性能，现有方法在特征融合时容易破坏主要语言特征。

Method: DyKen-Hyena将音频-视觉线索转化为动态卷积核，直接调制文本特征提取，实现细粒度处理。

Result: 在MIntRec和MIntRec2.0基准测试中达到最优性能，尤其在范围外检测中F1分数提升10.46%。

Conclusion: DyKen-Hyena通过调制而非融合特征，构建了更鲁棒的意图表示。

Abstract: Though Multimodal Intent Recognition (MIR) proves effective by utilizing rich
information from multiple sources (e.g., language, video, and audio), the
potential for intent-irrelevant and conflicting information across modalities
may hinder performance from being further improved. Most current models attempt
to fuse modalities by applying mechanisms like multi-head attention to unimodal
feature sequences and then adding the result back to the original
representation. This process risks corrupting the primary linguistic features
with noisy or irrelevant non-verbal signals, as it often fails to capture the
fine-grained, token-level influence where non-verbal cues should modulate, not
just augment, textual meaning. To address this, we introduce DyKen-Hyena, which
reframes the problem from feature fusion to processing modulation. Our model
translates audio-visual cues into dynamic, per-token convolutional kernels that
directly modulate textual feature extraction. This fine-grained approach
achieves state-of-the-art results on the MIntRec and MIntRec2.0 benchmarks.
Notably, it yields a +10.46% F1-score improvement in out-of-scope detection,
validating that our method creates a fundamentally more robust intent
representation.

</details>


### [103] [Adaptive Token Merging for Efficient Transformer Semantic Communication at the Edge](https://arxiv.org/abs/2509.09955)
*Omar Erak,Omar Alhussein,Hatem Abou-Zeid,Mehdi Bennis,Sami Muhaidat*

Main category: cs.LG

TL;DR: 提出了一种无需训练的自适应令牌合并框架，通过动态合并冗余令牌来降低计算和通信成本，适用于资源受限的边缘设备。


<details>
  <summary>Details</summary>
Motivation: 解决大规模Transformer在边缘设备上部署时的高计算和通信成本问题。

Method: 基于每层相似性阈值选择性合并语义冗余令牌，并通过贝叶斯优化实现多目标优化。

Result: 在ImageNet分类任务中减少30%计算量和80%通信成本，在视觉问答任务中性能接近完整模型但仅需1/3计算和1/10带宽。

Conclusion: 该框架为资源受限的边缘智能场景提供了一种高效且隐私保护的Transformer部署方案。

Abstract: Large-scale transformers are central to modern semantic communication, yet
their high computational and communication costs hinder deployment on
resource-constrained edge devices. This paper introduces a training-free
framework for adaptive token merging, a novel mechanism that compresses
transformer representations at runtime by selectively merging semantically
redundant tokens under per-layer similarity thresholds. Unlike prior
fixed-ratio reduction, our approach couples merging directly to input
redundancy, enabling data-dependent adaptation that balances efficiency and
task relevance without retraining. We cast the discovery of merging strategies
as a multi-objective optimization problem and leverage Bayesian optimization to
obtain Pareto-optimal trade-offs between accuracy, inference cost, and
communication cost. On ImageNet classification, we match the accuracy of the
unmodified transformer with 30\% fewer floating-point operations per second and
under 20\% of the original communication cost, while for visual question
answering our method achieves performance competitive with the full LLaVA model
at less than one-third of the compute and one-tenth of the bandwidth. Finally,
we show that our adaptive merging is robust across varying channel conditions
and provides inherent privacy benefits, substantially degrading the efficacy of
model inversion attacks. Our framework provides a practical and versatile
solution for deploying powerful transformer models in resource-limited edge
intelligence scenarios.

</details>


### [104] [Limited Reference, Reliable Generation: A Two-Component Framework for Tabular Data Generation in Low-Data Regimes](https://arxiv.org/abs/2509.09960)
*Mingxuan Jiang,Yongxin Wang,Ziyue Dai,Yicun Liu,Hongyi Nie,Sen Liu,Hongfeng Chai*

Main category: cs.LG

TL;DR: ReFine框架通过符号规则和双粒度过滤策略，显著提升合成表格数据的生成质量，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有表格生成方法在数据稀缺领域效果有限，且难以捕捉特征-标签依赖关系。

Method: ReFine结合符号规则引导生成和双粒度过滤策略，优化数据分布。

Result: 实验显示ReFine在回归和分类任务中表现优异，R-squared提升0.44，F1分数提升10%。

Conclusion: ReFine有效解决了数据稀缺和分布不平衡问题，提升了生成数据的实用性。

Abstract: Synthetic tabular data generation is increasingly essential in data
management, supporting downstream applications when real-world and high-quality
tabular data is insufficient. Existing tabular generation approaches, such as
generative adversarial networks (GANs), diffusion models, and fine-tuned Large
Language Models (LLMs), typically require sufficient reference data, limiting
their effectiveness in domain-specific databases with scarce records. While
prompt-based LLMs offer flexibility without parameter tuning, they often fail
to capture dataset-specific feature-label dependencies and generate redundant
data, leading to degradation in downstream task performance. To overcome these
issues, we propose ReFine, a framework that (i) derives symbolic "if-then"
rules from interpretable models and embeds them into prompts to explicitly
guide generation toward domain-specific feature distribution, and (ii) applies
a dual-granularity filtering strategy that suppresses over-sampling patterns
and selectively refines rare but informative samples to reduce distributional
imbalance. Extensive experiments on various regression and classification
benchmarks demonstrate that ReFine consistently outperforms state-of-the-art
methods, achieving up to 0.44 absolute improvement in R-squared for regression
and 10.0 percent relative improvement in F1 score for classification tasks.

</details>


### [105] [Data-Driven Energy Estimation for Virtual Servers Using Combined System Metrics and Machine Learning](https://arxiv.org/abs/2509.09991)
*Amandip Sangha*

Main category: cs.LG

TL;DR: 提出了一种基于机器学习的虚拟服务器能耗估计方法，无需物理功率测量接口。


<details>
  <summary>Details</summary>
Motivation: 解决虚拟化环境（如云）中无法直接测量能耗的问题。

Method: 利用虚拟机的资源利用率指标，训练梯度提升回归器预测能耗。

Result: 在多样化工作负载下，预测精度高（$0.90 \leq R^2 \leq 0.97$）。

Conclusion: 该方法可行，可用于能源感知调度和成本优化。

Abstract: This paper presents a machine learning-based approach to estimate the energy
consumption of virtual servers without access to physical power measurement
interfaces. Using resource utilization metrics collected from guest virtual
machines, we train a Gradient Boosting Regressor to predict energy consumption
measured via RAPL on the host. We demonstrate, for the first time, guest-only
resource-based energy estimation without privileged host access with
experiments across diverse workloads, achieving high predictive accuracy and
variance explained ($0.90 \leq R^2 \leq 0.97$), indicating the feasibility of
guest-side energy estimation. This approach can enable energy-aware scheduling,
cost optimization and physical host independent energy estimates in virtualized
environments. Our approach addresses a critical gap in virtualized environments
(e.g. cloud) where direct energy measurement is infeasible.

</details>


### [106] [Neural Scaling Laws for Deep Regression](https://arxiv.org/abs/2509.10000)
*Tilen Cadez,Kyoung-Min Kim*

Main category: cs.LG

TL;DR: 论文研究了深度回归模型中的神经缩放定律，发现损失与训练数据集大小和模型容量之间存在幂律关系，且缩放指数范围在1到2之间。


<details>
  <summary>Details</summary>
Motivation: 尽管神经缩放定律在大型语言模型中很重要，但在深度回归模型中的应用尚未充分探索。

Method: 使用扭曲范德华磁体的参数估计模型，通过多种架构（包括全连接网络、残差网络和视觉变换器）进行实证研究。

Result: 观察到损失与训练数据集大小和模型容量之间存在幂律关系，缩放指数范围在1到2之间。

Conclusion: 深度回归模型的性能可以随着数据量的增加而显著提升。

Abstract: Neural scaling laws--power-law relationships between generalization errors
and characteristics of deep learning models--are vital tools for developing
reliable models while managing limited resources. Although the success of large
language models highlights the importance of these laws, their application to
deep regression models remains largely unexplored. Here, we empirically
investigate neural scaling laws in deep regression using a parameter estimation
model for twisted van der Waals magnets. We observe power-law relationships
between the loss and both training dataset size and model capacity across a
wide range of values, employing various architectures--including fully
connected networks, residual networks, and vision transformers. Furthermore,
the scaling exponents governing these relationships range from 1 to 2, with
specific values depending on the regressed parameters and model details. The
consistent scaling behaviors and their large scaling exponents suggest that the
performance of deep regression models can improve substantially with increasing
data size.

</details>


### [107] [Intrinsic Dimension Estimating Autoencoder (IDEA) Using CancelOut Layer and a Projected Loss](https://arxiv.org/abs/2509.10011)
*Antoine Orioua,Philipp Krah,Julian Koellermeier*

Main category: cs.LG

TL;DR: IDEA是一种自动编码器，用于估计数据集的固有维度，并在潜在空间中重建数据。通过引入投影重建损失项，IDEA在理论和实际应用中表现出高准确性和多功能性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是开发一种能够准确估计数据集固有维度并重建数据的模型，适用于线性和非线性流形。

Method: IDEA使用重新加权的双CancelOut层构建潜在空间，并通过投影重建损失项指导训练。

Result: 在理论基准测试中，IDEA表现出高准确性和多功能性，并在实际流体动力学数据中成功估计和重建数据。

Conclusion: IDEA是一种有效的工具，能够准确估计数据集的固有维度并重建数据，适用于多种应用场景。

Abstract: This paper introduces the Intrinsic Dimension Estimating Autoencoder (IDEA),
which identifies the underlying intrinsic dimension of a wide range of datasets
whose samples lie on either linear or nonlinear manifolds. Beyond estimating
the intrinsic dimension, IDEA is also able to reconstruct the original dataset
after projecting it onto the corresponding latent space, which is structured
using re-weighted double CancelOut layers. Our key contribution is the
introduction of the projected reconstruction loss term, guiding the training of
the model by continuously assessing the reconstruction quality under the
removal of an additional latent dimension. We first assess the performance of
IDEA on a series of theoretical benchmarks to validate its robustness. These
experiments allow us to test its reconstruction ability and compare its
performance with state-of-the-art intrinsic dimension estimators. The
benchmarks show good accuracy and high versatility of our approach.
Subsequently, we apply our model to data generated from the numerical solution
of a vertically resolved one-dimensional free-surface flow, following a
pointwise discretization of the vertical velocity profile in the horizontal
direction, vertical direction, and time. IDEA succeeds in estimating the
dataset's intrinsic dimension and then reconstructs the original solution by
working directly within the projection space identified by the network.

</details>


### [108] [Exploring Expert Specialization through Unsupervised Training in Sparse Mixture of Experts](https://arxiv.org/abs/2509.10025)
*Strahinja Nikolic,Ilker Oguz,Demetri Psaltis*

Main category: cs.LG

TL;DR: SMoE-VAE模型在QuickDraw数据集上表现优于监督基线，无监督路由能识别超越人工类别的有意义结构。


<details>
  <summary>Details</summary>
Motivation: 探索神经网络内部组织，解决深度学习可解释性挑战。

Method: 提出稀疏混合专家变分自编码器（SMoE-VAE），比较无监督与监督路由。

Result: 无监督路由重建性能更优，专家学习到超越人工类别的结构。

Conclusion: MoE模型能发现更符合目标的数据结构，数据集大小影响专家专业化。

Abstract: Understanding the internal organization of neural networks remains a
fundamental challenge in deep learning interpretability. We address this
challenge by exploring a novel Sparse Mixture of Experts Variational
Autoencoder (SMoE-VAE) architecture. We test our model on the QuickDraw
dataset, comparing unsupervised expert routing against a supervised baseline
guided by ground-truth labels. Surprisingly, we find that unsupervised routing
consistently achieves superior reconstruction performance. The experts learn to
identify meaningful sub-categorical structures that often transcend
human-defined class boundaries. Through t-SNE visualizations and reconstruction
analysis, we investigate how MoE models uncover fundamental data structures
that are more aligned with the model's objective than predefined labels.
Furthermore, our study on the impact of dataset size provides insights into the
trade-offs between data quantity and expert specialization, offering guidance
for designing efficient MoE architectures.

</details>


### [109] [Sparse Coding Representation of 2-way Data](https://arxiv.org/abs/2509.10033)
*Boya Ma,Abram Magner,Maxwell McNeil,Petko Bogdanov*

Main category: cs.LG

TL;DR: 论文提出了一种低秩编码模型（AODL）用于解决多字典场景下的稀疏字典编码问题，通过凸松弛和交替优化方法，实现了更高的稀疏性和更好的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 传统的数据无关分析字典（如傅里叶变换、小波等）虽然高效但稀疏性不足，而数据驱动的字典学习虽然更准确但计算复杂，尤其是在多字典场景下。

Method: 提出低秩编码模型，通过凸松弛和交替优化方法学习字典和编码系数，证明了其收敛性。

Result: AODL在数据重建和缺失值填补任务中表现优异，稀疏性比非低秩和固定字典基线高90%，且字典具有可解释性。

Conclusion: AODL在多字典场景下显著提升了稀疏性和泛化能力，同时揭示了数据中的潜在模式。

Abstract: Sparse dictionary coding represents signals as linear combinations of a few
dictionary atoms. It has been applied to images, time series, graph signals and
multi-way spatio-temporal data by jointly employing temporal and spatial
dictionaries. Data-agnostic analytical dictionaries, such as the discrete
Fourier transform, wavelets and graph Fourier, have seen wide adoption due to
efficient implementations and good practical performance. On the other hand,
dictionaries learned from data offer sparser and more accurate solutions but
require learning of both the dictionaries and the coding coefficients. This
becomes especially challenging for multi-dictionary scenarios since encoding
coefficients correspond to all atom combinations from the dictionaries. To
address this challenge, we propose a low-rank coding model for 2-dictionary
scenarios and study its data complexity. Namely, we establish a bound on the
number of samples needed to learn dictionaries that generalize to unseen
samples from the same distribution. We propose a convex relaxation solution,
called AODL, whose exact solution we show also solves the original problem. We
then solve this relaxation via alternating optimization between the sparse
coding matrices and the learned dictionaries, which we prove to be convergent.
We demonstrate its quality for data reconstruction and missing value imputation
in both synthetic and real-world datasets. For a fixed reconstruction quality,
AODL learns up to 90\% sparser solutions compared to non-low-rank and
analytical (fixed) dictionary baselines. In addition, the learned dictionaries
reveal interpretable insights into patterns present within the samples used for
training.

</details>


### [110] [Symbolic Feedforward Networks for Probabilistic Finite Automata: Exact Simulation and Learnability](https://arxiv.org/abs/2509.10034)
*Sahil Rajesh Dhayalkar*

Main category: cs.LG

TL;DR: 该论文提出了一种用符号前馈神经网络精确模拟概率有限自动机（PFA）的理论，证明了其等价性，并展示了其可学习性。


<details>
  <summary>Details</summary>
Motivation: 为了统一概率自动机理论与神经网络架构，填补符号计算与深度学习之间的鸿沟。

Method: 通过将状态分布表示为向量、转移表示为随机矩阵，利用矩阵-向量乘积实现概率状态传播，构建了一种并行、可解释且可微的PFA模拟方法。

Result: 证明了PFA与特定类神经网络的等价性，并通过梯度下降优化训练，实现了对真实PFA行为的精确恢复。

Conclusion: 该工作为概率自动机与神经网络的结合提供了严格的代数框架，展示了符号计算与深度学习的融合潜力。

Abstract: We present a formal and constructive theory showing that probabilistic finite
automata (PFAs) can be exactly simulated using symbolic feedforward neural
networks. Our architecture represents state distributions as vectors and
transitions as stochastic matrices, enabling probabilistic state propagation
via matrix-vector products. This yields a parallel, interpretable, and
differentiable simulation of PFA dynamics using soft updates-without
recurrence. We formally characterize probabilistic subset construction,
$\varepsilon$-closure, and exact simulation via layered symbolic computation,
and prove equivalence between PFAs and specific classes of neural networks. We
further show that these symbolic simulators are not only expressive but
learnable: trained with standard gradient descent-based optimization on labeled
sequence data, they recover the exact behavior of ground-truth PFAs. This
learnability, formalized in Proposition 5.1, is the crux of this work. Our
results unify probabilistic automata theory with neural architectures under a
rigorous algebraic framework, bridging the gap between symbolic computation and
deep learning.

</details>


### [111] [FedRP: A Communication-Efficient Approach for Differentially Private Federated Learning Using Random Projection](https://arxiv.org/abs/2509.10041)
*Mohammad Hasan Narimani,Mostafa Tavassolipour*

Main category: cs.LG

TL;DR: FedRP是一种结合随机投影和ADMM优化的联邦学习算法，提升隐私保护和通信效率。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在隐私保护和通信成本管理方面面临挑战，需要更高效的解决方案。

Method: FedRP通过随机投影降维模型参数，结合ADMM框架优化，提供差分隐私保证。

Result: 实验显示FedRP在模型精度、隐私保护和通信效率上优于现有方法。

Conclusion: FedRP为联邦学习提供了一种高效且隐私安全的解决方案。

Abstract: Federated learning (FL) offers an innovative paradigm for collaborative model
training across decentralized devices, such as smartphones, balancing enhanced
predictive performance with the protection of user privacy in sensitive areas
like Internet of Things (IoT) and medical data analysis. Despite its
advantages, FL encounters significant challenges related to user privacy
protection against potential attacks and the management of communication costs.
This paper introduces a novel federated learning algorithm called FedRP, which
integrates random projection techniques with the Alternating Direction Method
of Multipliers (ADMM) optimization framework. This approach enhances privacy by
employing random projection to reduce the dimensionality of model parameters
prior to their transmission to a central server, reducing the communication
cost. The proposed algorithm offers a strong $(\epsilon, \delta)$-differential
privacy guarantee, demonstrating resilience against data reconstruction
attacks. Experimental results reveal that FedRP not only maintains high model
accuracy but also outperforms existing methods, including conventional
differential privacy approaches and FedADMM, in terms of both privacy
preservation and communication efficiency.

</details>


### [112] [Uncertainty-Aware Tabular Prediction: Evaluating VBLL-Enhanced TabPFN in Safety-Critical Medical Data](https://arxiv.org/abs/2509.10048)
*Madhushan Ramalingam*

Main category: cs.LG

TL;DR: 评估VBLL与TabPFN结合在不确定性校准中的表现，发现原始TabPFN表现更优。


<details>
  <summary>Details</summary>
Motivation: 在安全关键应用中，可靠的不确定性估计至关重要，因此研究VBLL与TabPFN的结合效果。

Method: 在三个医疗表格数据集上比较原始TabPFN和VBLL集成的TabPFN的不确定性校准性能。

Result: 原始TabPFN在所有数据集上均优于VBLL集成的TabPFN。

Conclusion: VBLL集成未能提升TabPFN的不确定性校准性能，原始TabPFN表现更稳定。

Abstract: Predictive models are being increasingly used across a wide range of domains,
including safety-critical applications such as medical diagnosis and criminal
justice. Reliable uncertainty estimation is a crucial task in such settings.
Tabular Prior-data Fitted Network (TabPFN) is a recently proposed machine
learning foundation model for tabular dataset, which uses a generative
transformer architecture. Variational Bayesian Last Layers (VBLL) is a
state-of-the-art lightweight variational formulation that effectively improves
uncertainty estimation with minimal computational overhead. In this work we aim
to evaluate the performance of VBLL integrated with the recently proposed
TabPFN in uncertainty calibration. Our experiments, conducted on three
benchmark medical tabular datasets, compare the performance of the original
TabPFN and the VBLL-integrated version. Contrary to expectations, we observed
that original TabPFN consistently outperforms VBLL integrated TabPFN in
uncertainty calibration across all datasets.

</details>


### [113] [KAN-SR: A Kolmogorov-Arnold Network Guided Symbolic Regression Framework](https://arxiv.org/abs/2509.10089)
*Marco Andrea Bühler,Gonzalo Guillén-Gosálbez*

Main category: cs.LG

TL;DR: KAN-SR是一种基于Kolmogorov Arnold Networks（KANs）的新型符号回归框架，通过分治法结合深度学习技术，能够精确恢复Feynman SRSD数据集中的真实方程，并可用于动态建模工程系统。


<details>
  <summary>Details</summary>
Motivation: 符号回归通常通过遗传编程解决，但本文提出使用深度学习技术结合KANs和简化策略，以提高方程恢复的精确性和适用性。

Method: 采用分治法结合KANs，利用平移对称性和可分离性等简化策略，并结合神经控制微分方程建模动态系统。

Result: 成功恢复Feynman SRSD数据集中的真实方程，并精确建模了生物过程系统的动态行为。

Conclusion: KAN-SR框架在符号回归和动态建模方面表现出色，为工程系统的建模提供了新思路。

Abstract: We introduce a novel symbolic regression framework, namely KAN-SR, built on
Kolmogorov Arnold Networks (KANs) which follows a divide-and-conquer approach.
Symbolic regression searches for mathematical equations that best fit a given
dataset and is commonly solved with genetic programming approaches. We show
that by using deep learning techniques, more specific KANs, and combining them
with simplification strategies such as translational symmetries and
separabilities, we are able to recover ground-truth equations of the Feynman
Symbolic Regression for Scientific Discovery (SRSD) dataset. Additionally, we
show that by combining the proposed framework with neural controlled
differential equations, we are able to model the dynamics of an in-silico
bioprocess system precisely, opening the door for the dynamic modeling of other
engineering systems.

</details>


### [114] [Cost-Free Personalization via Information-Geometric Projection in Bayesian Federated Learning](https://arxiv.org/abs/2509.10132)
*Nour Jamoussi,Giuseppe Serra,Photios A. Stavrou,Marios Kountouris*

Main category: cs.LG

TL;DR: 提出了一种基于信息几何投影的贝叶斯联邦学习方法，实现全局与局部性能的平衡。


<details>
  <summary>Details</summary>
Motivation: 解决数据异构和隐私约束下个性化模型的开发问题。

Method: 通过信息几何投影框架，将全局模型投影到用户局部模型邻域，实现可调谐的全局泛化与局部特化权衡。

Result: 在异构数据分布下，方法有效平衡全局与局部性能，计算开销小。

Conclusion: 该方法为贝叶斯联邦学习提供了一种高效且灵活的个性化解决方案。

Abstract: Bayesian Federated Learning (BFL) combines uncertainty modeling with
decentralized training, enabling the development of personalized and reliable
models under data heterogeneity and privacy constraints. Existing approaches
typically rely on Markov Chain Monte Carlo (MCMC) sampling or variational
inference, often incorporating personalization mechanisms to better adapt to
local data distributions. In this work, we propose an information-geometric
projection framework for personalization in parametric BFL. By projecting the
global model onto a neighborhood of the user's local model, our method enables
a tunable trade-off between global generalization and local specialization.
Under mild assumptions, we show that this projection step is equivalent to
computing a barycenter on the statistical manifold, allowing us to derive
closed-form solutions and achieve cost-free personalization. We apply the
proposed approach to a variational learning setup using the Improved
Variational Online Newton (IVON) optimizer and extend its application to
general aggregation schemes in BFL. Empirical evaluations under heterogeneous
data distributions confirm that our method effectively balances global and
local performance with minimal computational overhead.

</details>


### [115] [BenchECG and xECG: a benchmark and baseline for ECG foundation models](https://arxiv.org/abs/2509.10151)
*Riccardo Lunelli,Angus Nicolson,Samuel Martin Pröll,Sebastian Johannes Reinstadler,Axel Bauer,Clemens Dlaska*

Main category: cs.LG

TL;DR: 论文提出了BenchECG基准和xECG模型，用于标准化ECG表示学习的评估，xECG在多个任务中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有ECG基础模型评估缺乏一致性，阻碍公平比较，需标准化基准。

Method: 提出BenchECG基准和xECG模型（基于xLSTM和SimDINOv2自监督学习）。

Result: xECG在BenchECG中表现最优，成为ECG基础模型的新基准。

Conclusion: BenchECG和xECG推动了ECG表示学习的标准化和进展。

Abstract: Electrocardiograms (ECGs) are inexpensive, widely used, and well-suited to
deep learning. Recently, interest has grown in developing foundation models for
ECGs - models that generalise across diverse downstream tasks. However,
consistent evaluation has been lacking: prior work often uses narrow task
selections and inconsistent datasets, hindering fair comparison. Here, we
introduce BenchECG, a standardised benchmark comprising a comprehensive suite
of publicly available ECG datasets and versatile tasks. We also propose xECG,
an xLSTM-based recurrent model trained with SimDINOv2 self-supervised learning,
which achieves the best BenchECG score compared to publicly available
state-of-the-art models. In particular, xECG is the only publicly available
model to perform strongly on all datasets and tasks. By standardising
evaluation, BenchECG enables rigorous comparison and aims to accelerate
progress in ECG representation learning. xECG achieves superior performance
over earlier approaches, defining a new baseline for future ECG foundation
models.

</details>


### [116] [FedBiF: Communication-Efficient Federated Learning via Bits Freezing](https://arxiv.org/abs/2509.10161)
*Shiwei Li,Qunwei Li,Haozhao Wang,Ruixuan Li,Jianbin Lin,Wenliang Zhong*

Main category: cs.LG

TL;DR: 提出了一种名为FedBiF的新型联邦学习框架，通过在本地训练期间直接学习量化模型参数，显著降低了通信开销并保持了模型精度。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中通信开销大和量化误差影响模型精度的问题。

Method: 在每轮通信中，服务器先量化模型参数并传输给客户端，客户端每次仅更新一个比特位，冻结其余比特位。

Result: 在多个数据集上验证了FedBiF在通信压缩和模型稀疏性方面的优势，同时保持了与FedAvg相当的精度。

Conclusion: FedBiF是一种高效的联邦学习框架，能够在极低比特率下实现高精度模型训练。

Abstract: Federated learning (FL) is an emerging distributed machine learning paradigm
that enables collaborative model training without sharing local data. Despite
its advantages, FL suffers from substantial communication overhead, which can
affect training efficiency. Recent efforts have mitigated this issue by
quantizing model updates to reduce communication costs. However, most existing
methods apply quantization only after local training, introducing quantization
errors into the trained parameters and potentially degrading model accuracy. In
this paper, we propose Federated Bit Freezing (FedBiF), a novel FL framework
that directly learns quantized model parameters during local training. In each
communication round, the server first quantizes the model parameters and
transmits them to the clients. FedBiF then allows each client to update only a
single bit of the multi-bit parameter representation, freezing the remaining
bits. This bit-by-bit update strategy reduces each parameter update to one bit
while maintaining high precision in parameter representation. Extensive
experiments are conducted on five widely used datasets under both IID and
Non-IID settings. The results demonstrate that FedBiF not only achieves
superior communication compression but also promotes sparsity in the resulting
models. Notably, FedBiF attains accuracy comparable to FedAvg, even when using
only 1 bit-per-parameter (bpp) for uplink and 3 bpp for downlink communication.
The code is available at https://github.com/Leopold1423/fedbif-tpds25.

</details>


### [117] [Federated Multi-Agent Reinforcement Learning for Privacy-Preserving and Energy-Aware Resource Management in 6G Edge Networks](https://arxiv.org/abs/2509.10163)
*Francisco Javier Esono Nkulu Andong,Qi Min*

Main category: cs.LG

TL;DR: 论文提出了一种联邦多智能体强化学习框架（Fed-MARL），用于6G网络中高效、隐私保护的资源管理。


<details>
  <summary>Details</summary>
Motivation: 6G网络需要满足超密集、智能边缘环境下的隐私、移动性和能源约束，传统方法难以兼顾这些需求。

Method: 采用深度循环Q网络（DRQN）和椭圆曲线Diffie Hellman密钥交换协议，实现去中心化任务卸载、频谱访问和CPU能源适应。

Result: Fed-MARL在任务成功率、延迟、能源效率和公平性上优于集中式MARL和启发式基线方法。

Conclusion: Fed-MARL在动态、资源受限的6G边缘网络中表现出色，兼顾隐私保护和可扩展性。

Abstract: As sixth-generation (6G) networks move toward ultra-dense, intelligent edge
environments, efficient resource management under stringent privacy, mobility,
and energy constraints becomes critical. This paper introduces a novel
Federated Multi-Agent Reinforcement Learning (Fed-MARL) framework that
incorporates cross-layer orchestration of both the MAC layer and application
layer for energy-efficient, privacy-preserving, and real-time resource
management across heterogeneous edge devices. Each agent uses a Deep Recurrent
Q-Network (DRQN) to learn decentralized policies for task offloading, spectrum
access, and CPU energy adaptation based on local observations (e.g., queue
length, energy, CPU usage, and mobility). To protect privacy, we introduce a
secure aggregation protocol based on elliptic curve Diffie Hellman key
exchange, which ensures accurate model updates without exposing raw data to
semi-honest adversaries. We formulate the resource management problem as a
partially observable multi-agent Markov decision process (POMMDP) with a
multi-objective reward function that jointly optimizes latency, energy
efficiency, spectral efficiency, fairness, and reliability under 6G-specific
service requirements such as URLLC, eMBB, and mMTC. Simulation results
demonstrate that Fed-MARL outperforms centralized MARL and heuristic baselines
in task success rate, latency, energy efficiency, and fairness, while ensuring
robust privacy protection and scalability in dynamic, resource-constrained 6G
edge networks.

</details>


### [118] [A Symmetry-Integrated Approach to Surface Code Decoding](https://arxiv.org/abs/2509.10164)
*Hoshitaro Ohnishi,Hideo Mukai*

Main category: cs.LG

TL;DR: 提出一种通过神经网络近似症状测量来重新优化解码器模型的方法，提高了量子纠错解码器的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决传统解码器因输入预测不唯一而仅能获取错误概率分布的问题。

Method: 利用神经网络数学插值连续函数近似症状测量，重新优化解码器模型。

Result: 在多层感知机、卷积神经网络、循环神经网络和Transformer上，优化后的解码器在码距5和7下均表现更优。

Conclusion: 将表面码解码问题转化为深度学习可解决的回归问题是一种有效策略。

Abstract: Quantum error correction, which utilizes logical qubits that are encoded as
redundant multiple physical qubits to find and correct errors in physical
qubits, is indispensable for practical quantum computing. Surface code is
considered to be a promising encoding method with a high error threshold that
is defined by stabilizer generators. However, previous methods have suffered
from the problem that the decoder acquires solely the error probability
distribution because of the non-uniqueness of correct prediction obtained from
the input. To circumvent this problem, we propose a technique to reoptimize the
decoder model by approximating syndrome measurements with a continuous function
that is mathematically interpolated by neural network. We evaluated the
improvement in accuracy of a multilayer perceptron based decoder for code
distances of 5 and 7 as well as for decoders based on convolutional and
recurrent neural networks and transformers for a code distance of 5. In all
cases, the reoptimized decoder gave better accuracy than the original models,
demonstrating the universal effectiveness of the proposed method that is
independent of code distance or network architecture. These results suggest
that re-framing the problem of surface code decoding into a regression problem
that can be tackled by deep learning is a useful strategy.

</details>


### [119] [The Hidden Width of Deep ResNets: Tight Error Bounds and Phase Diagrams](https://arxiv.org/abs/2509.10167)
*Lénaïc Chizat*

Main category: cs.LG

TL;DR: 研究了深度残差网络（ResNets）在梯度训练中的动态行为，发现其在大深度下收敛到神经均值ODE动态，且与隐藏层宽度无关。


<details>
  <summary>Details</summary>
Motivation: 探索ResNets在大深度和不同隐藏层宽度下的训练动态，揭示其收敛行为和特征学习的条件。

Method: 通过理论分析和实验验证，研究了ResNets在不同参数尺度下的训练动态，并推导了误差界限。

Result: 发现ResNets在大深度下收敛到均值ODE动态，且特定尺度下能实现完全特征学习。

Conclusion: ResNets的训练动态可通过均值ODE描述，且特定参数尺度是实现特征学习的关键。

Abstract: We study the gradient-based training of large-depth residual networks
(ResNets) from standard random initializations. We show that with a diverging
depth $L$, a fixed embedding dimension $D$, and an arbitrary hidden width $M$,
the training dynamics converges to a Neural Mean ODE training dynamics.
Remarkably, the limit is independent of the scaling of $M$, covering practical
cases of, say, Transformers, where $M$ (the number of hidden units or attention
heads per layer) is typically of the order of $D$. For a residual scale
$\Theta_D\big(\frac{\alpha}{LM}\big)$, we obtain the error bound
$O_D\big(\frac{1}{L}+ \frac{\alpha}{\sqrt{LM}}\big)$ between the model's output
and its limit after a fixed number gradient of steps, and we verify empirically
that this rate is tight. When $\alpha=\Theta(1)$, the limit exhibits complete
feature learning, i.e. the Mean ODE is genuinely non-linearly parameterized. In
contrast, we show that $\alpha \to \infty$ yields a \lazy ODE regime where the
Mean ODE is linearly parameterized. We then focus on the particular case of
ResNets with two-layer perceptron blocks, for which we study how these scalings
depend on the embedding dimension $D$. We show that for this model, the only
residual scale that leads to complete feature learning is
$\Theta\big(\frac{\sqrt{D}}{LM}\big)$. In this regime, we prove the error bound
$O\big(\frac{1}{L}+ \frac{\sqrt{D}}{\sqrt{LM}}\big)$ between the ResNet and its
limit after a fixed number of gradient steps, which is also empirically tight.
Our convergence results rely on a novel mathematical perspective on ResNets :
(i) due to the randomness of the initialization, the forward and backward pass
through the ResNet behave as the stochastic approximation of certain mean ODEs,
and (ii) by propagation of chaos (that is, asymptotic independence of the
units) this behavior is preserved through the training dynamics.

</details>


### [120] [P3D: Scalable Neural Surrogates for High-Resolution 3D Physics Simulations with Global Context](https://arxiv.org/abs/2509.10186)
*Benjamin Holzschuh,Georg Kohl,Florian Redinger,Nils Thuerey*

Main category: cs.LG

TL;DR: 提出了一种可扩展的框架，用于学习高分辨率3D物理模拟的确定性和概率性神经替代模型，结合CNN-Transformer架构，显著提升了速度和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决高分辨率3D物理模拟中计算资源需求高的问题，同时提升模型的泛化能力和效率。

Method: 采用混合CNN-Transformer架构，支持小区域预训练并通过序列模型融合全局解，降低内存和计算需求。

Result: 在14种3D PDE动力学学习中表现优异，支持高分辨率（512^3）模拟，并能生成湍流概率样本。

Conclusion: 该框架在高效性和准确性上显著优于现有方法，适用于复杂物理模拟任务。

Abstract: We present a scalable framework for learning deterministic and probabilistic
neural surrogates for high-resolution 3D physics simulations. We introduce a
hybrid CNN-Transformer backbone architecture targeted for 3D physics
simulations, which significantly outperforms existing architectures in terms of
speed and accuracy. Our proposed network can be pretrained on small patches of
the simulation domain, which can be fused to obtain a global solution,
optionally guided via a fast and scalable sequence-to-sequence model to include
long-range dependencies. This setup allows for training large-scale models with
reduced memory and compute requirements for high-resolution datasets. We
evaluate our backbone architecture against a large set of baseline methods with
the objective to simultaneously learn the dynamics of 14 different types of
PDEs in 3D. We demonstrate how to scale our model to high-resolution isotropic
turbulence with spatial resolutions of up to $512^3$. Finally, we demonstrate
the versatility of our network by training it as a diffusion model to produce
probabilistic samples of highly turbulent 3D channel flows across varying
Reynolds numbers, accurately capturing the underlying flow statistics.

</details>


### [121] [Hadamard-Riemannian Optimization for Margin-Variance Ensemble](https://arxiv.org/abs/2509.10189)
*Zexu Jin*

Main category: cs.LG

TL;DR: 提出了一种新的集成学习框架，通过显式考虑边际方差来提升模型的泛化能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统基于边际的集成方法忽视了边际方差的重要性，导致泛化能力受限且易过拟合，尤其是在噪声或不平衡数据中。此外，传统优化方法计算效率低。

Method: 将边际方差纳入损失函数，联合优化负期望边际及其方差，并通过重新参数化集成权重到单位球面简化优化过程。

Result: 在多个基准数据集上的实验表明，该方法优于传统基于边际的集成技术。

Conclusion: 新框架显著提升了集成学习的性能和计算效率，具有实际应用价值。

Abstract: Ensemble learning has been widely recognized as a pivotal technique for
boosting predictive performance by combining multiple base models.
Nevertheless, conventional margin-based ensemble methods predominantly focus on
maximizing the expected margin while neglecting the critical role of margin
variance, which inherently restricts the generalization capability of the model
and heightens its vulnerability to overfitting, particularly in noisy or
imbalanced datasets. Additionally, the conventional approach of optimizing
ensemble weights within the probability simplex often introduces computational
inefficiency and scalability challenges, complicating its application to
large-scale problems. To tackle these limitations, this paper introduces a
novel ensemble learning framework that explicitly incorporates margin variance
into the loss function. Our method jointly optimizes the negative expected
margin and its variance, leading to enhanced robustness and improved
generalization performance. Moreover, by reparameterizing the ensemble weights
onto the unit sphere, we substantially simplify the optimization process and
improve computational efficiency. Extensive experiments conducted on multiple
benchmark datasets demonstrate that the proposed approach consistently
outperforms traditional margin-based ensemble techniques, underscoring its
effectiveness and practical utility.

</details>


### [122] [A Certifiable Machine Learning-Based Pipeline to Predict Fatigue Life of Aircraft Structures](https://arxiv.org/abs/2509.10227)
*Ángel Ladrón,Miguel Sánchez-Domínguez,Javier Rozalén,Fernando R. Sánchez,Javier de Vicente,Lucas Lacasa,Eusebio Valero,Gonzalo Rubio*

Main category: cs.LG

TL;DR: 本文提出了一种基于机器学习的疲劳寿命预测方法，用于飞机机翼不同部位的寿命估计，以补充传统方法并减少计算资源需求。


<details>
  <summary>Details</summary>
Motivation: 传统疲劳寿命预测方法耗时且复杂，需要多团队协作和大量计算资源，机器学习方法可以加速预测过程并提供快速估计。

Method: 开发了一个基于机器学习的流程，利用飞行参数预测飞机机翼不同部位的疲劳寿命，并通过统计验证和不确定性量化进行验证。

Result: 在真实案例中验证了该流程的准确性，能够提供可靠的预测结果。

Conclusion: 该机器学习流程是传统方法的有力补充，能够显著减少计算和人力资源需求。

Abstract: Fatigue life prediction is essential in both the design and operational
phases of any aircraft, and in this sense safety in the aerospace industry
requires early detection of fatigue cracks to prevent in-flight failures.
Robust and precise fatigue life predictors are thus essential to ensure safety.
Traditional engineering methods, while reliable, are time consuming and involve
complex workflows, including steps such as conducting several Finite Element
Method (FEM) simulations, deriving the expected loading spectrum, and applying
cycle counting techniques like peak-valley or rainflow counting. These steps
often require collaboration between multiple teams and tools, added to the
computational time and effort required to achieve fatigue life predictions.
Machine learning (ML) offers a promising complement to traditional fatigue life
estimation methods, enabling faster iterations and generalization, providing
quick estimates that guide decisions alongside conventional simulations.
  In this paper, we present a ML-based pipeline that aims to estimate the
fatigue life of different aircraft wing locations given the flight parameters
of the different missions that the aircraft will be operating throughout its
operational life. We validate the pipeline in a realistic use case of fatigue
life estimation, yielding accurate predictions alongside a thorough statistical
validation and uncertainty quantification. Our pipeline constitutes a
complement to traditional methodologies by reducing the amount of costly
simulations and, thereby, lowering the required computational and human
resources.

</details>


### [123] [Prompt Injection Attacks on LLM Generated Reviews of Scientific Publications](https://arxiv.org/abs/2509.10248)
*Janis Keuper*

Main category: cs.LG

TL;DR: 论文研究了LLM在同行评审中的隐藏提示注入攻击，发现简单攻击即可显著影响评审结果，且LLM评审普遍偏向接受。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM在科学同行评审中的潜在操纵行为及其影响。

Method: 系统性评估了2024年ICLR论文的1k条LLM生成评审，分析提示注入的有效性和LLM的评审偏见。

Result: 简单提示注入效果显著（最高100%接受率），LLM评审普遍偏向接受（>95%）。

Conclusion: 结果对LLM在同行评审中的使用讨论具有重要影响。

Abstract: The ongoing intense discussion on rising LLM usage in the scientific
peer-review process has recently been mingled by reports of authors using
hidden prompt injections to manipulate review scores. Since the existence of
such "attacks" - although seen by some commentators as "self-defense" - would
have a great impact on the further debate, this paper investigates the
practicability and technical success of the described manipulations. Our
systematic evaluation uses 1k reviews of 2024 ICLR papers generated by a wide
range of LLMs shows two distinct results: I) very simple prompt injections are
indeed highly effective, reaching up to 100% acceptance scores. II) LLM reviews
are generally biased toward acceptance (>95% in many models). Both results have
great impact on the ongoing discussions on LLM usage in peer-review.

</details>


### [124] [Property prediction for ionic liquids without prior structural knowledge using limited experimental data: A data-driven neural recommender system leveraging transfer learning](https://arxiv.org/abs/2509.10273)
*Sahil Sethi,Kai Sundmacher,Caroline Ganzer*

Main category: cs.LG

TL;DR: 提出了一种基于神经推荐系统的数据驱动迁移学习框架，用于预测离子液体的关键热物理性质，解决了实验数据稀疏的问题。


<details>
  <summary>Details</summary>
Motivation: 离子液体（ILs）因其可定制的物理化学性质成为传统溶剂的替代品，但由于化学设计空间广阔且实验数据有限，准确预测其性质仍具挑战性。

Method: 采用两阶段方法：1）在COSMO-RS模拟数据上预训练神经推荐系统模型，学习离子和阴离子的结构嵌入；2）用实验数据微调简单前馈神经网络，支持跨性质知识迁移。

Result: 模型在密度、粘度、表面张力、热容和熔点五种性质上表现优异，其中四种性质预测性能显著提升，并能外推到未见过的ILs。

Conclusion: 结合模拟数据和迁移学习有效解决了实验数据稀疏问题，为离子液体筛选提供了可扩展的解决方案。

Abstract: Ionic liquids (ILs) have emerged as versatile replacements for traditional
solvents because their physicochemical properties can be precisely tailored to
various applications. However, accurately predicting key thermophysical
properties remains challenging due to the vast chemical design space and the
limited availability of experimental data. In this study, we present a
data-driven transfer learning framework that leverages a neural recommender
system (NRS) to enable reliable property prediction for ILs using sparse
experimental datasets. The approach involves a two-stage process: first,
pre-training NRS models on COSMO-RS-based simulated data at fixed temperature
and pressure to learn property-specific structural embeddings for cations and
anions; and second, fine-tuning simple feedforward neural networks using these
embeddings with experimental data at varying temperatures and pressures. In
this work, five essential IL properties are considered: density, viscosity,
surface tension, heat capacity, and melting point. The framework supports both
within-property and cross-property knowledge transfer. Notably, pre-trained
models for density, viscosity, and heat capacity are used to fine-tune models
for all five target properties, achieving improved performance by a substantial
margin for four of them. The model exhibits robust extrapolation to previously
unseen ILs. Moreover, the final trained models enable property prediction for
over 700,000 IL combinations, offering a scalable solution for IL screening in
process design. This work highlights the effectiveness of combining simulated
data and transfer learning to overcome sparsity in the experimental data.

</details>


### [125] [Proof of AutoML: SDN based Secure Energy Trading with Blockchain in Disaster Case](https://arxiv.org/abs/2509.10291)
*Salih Toprak,Muge Erel-Ozcevik*

Main category: cs.LG

TL;DR: 论文提出了一种基于SDN和AutoML的区块链安全能源交易架构，用于灾难场景下的太阳能家庭与移动充电单元之间的交易。


<details>
  <summary>Details</summary>
Motivation: 在灾难场景中，传统能源基础设施受损，需要安全、可追溯的能源交易方式。区块链网络的完整性依赖于强大的随机数生成。

Method: 利用AutoML选择的回归模型（如随机森林、梯度提升等）生成随机数作为区块链的非候选值，称为Proof of AutoML。SDN用于灵活控制数据流和能源路由。

Result: 随机森林和Extra Trees表现出完全随机性，其他模型（如梯度提升、K近邻等）也表现出高随机性（97.6%-99.9%）。

Conclusion: 树集成模型可作为轻量级随机数生成器，适用于基于区块链和SDN的灾难弹性能源交易基础设施。

Abstract: In disaster scenarios where conventional energy infrastructure is
compromised, secure and traceable energy trading between solar-powered
households and mobile charging units becomes a necessity. To ensure the
integrity of such transactions over a blockchain network, robust and
unpredictable nonce generation is vital. This study proposes an SDN-enabled
architecture where machine learning regressors are leveraged not for their
accuracy, but for their potential to generate randomized values suitable as
nonce candidates. Therefore, it is newly called Proof of AutoML. Here, SDN
allows flexible control over data flows and energy routing policies even in
fragmented or degraded networks, ensuring adaptive response during emergencies.
Using a 9000-sample dataset, we evaluate five AutoML-selected regression models
- Gradient Boosting, LightGBM, Random Forest, Extra Trees, and K-Nearest
Neighbors - not by their prediction accuracy, but by their ability to produce
diverse and non-deterministic outputs across shuffled data inputs. Randomness
analysis reveals that Random Forest and Extra Trees regressors exhibit complete
dependency on randomness, whereas Gradient Boosting, K-Nearest Neighbors and
LightGBM show strong but slightly lower randomness scores (97.6%, 98.8% and
99.9%, respectively). These findings highlight that certain machine learning
models, particularly tree-based ensembles, may serve as effective and
lightweight nonce generators within blockchain-secured, SDN-based energy
trading infrastructures resilient to disaster conditions.

</details>


### [126] [Generalizing Beyond Suboptimality: Offline Reinforcement Learning Learns Effective Scheduling through Random Data](https://arxiv.org/abs/2509.10303)
*Jesse van Remmerden,Zaharah Bukhsh,Yingqian Zhang*

Main category: cs.LG

TL;DR: CDQAC是一种新型离线强化学习算法，直接从历史数据中学习调度策略，避免了昂贵的在线交互，并能改进次优训练数据。


<details>
  <summary>Details</summary>
Motivation: 解决在线强化学习方法需要大量模拟环境交互和随机策略初始化导致的样本效率低的问题。

Method: 结合基于分位数的评论家和延迟策略更新，估计每个机器-操作对的回报分布。

Result: CDQAC在多样数据源上表现优异，优于原始数据生成启发式方法和现有离线/在线RL基线，且样本效率高。

Conclusion: CDQAC在随机启发式生成的数据上表现更好，展示了其强大的学习能力和适应性。

Abstract: The Job-Shop Scheduling Problem (JSP) and Flexible Job-Shop Scheduling
Problem (FJSP), are canonical combinatorial optimization problems with
wide-ranging applications in industrial operations. In recent years, many
online reinforcement learning (RL) approaches have been proposed to learn
constructive heuristics for JSP and FJSP. Although effective, these online RL
methods require millions of interactions with simulated environments that may
not capture real-world complexities, and their random policy initialization
leads to poor sample efficiency. To address these limitations, we introduce
Conservative Discrete Quantile Actor-Critic (CDQAC), a novel offline RL
algorithm that learns effective scheduling policies directly from historical
data, eliminating the need for costly online interactions, while maintaining
the ability to improve upon suboptimal training data. CDQAC couples a
quantile-based critic with a delayed policy update, estimating the return
distribution of each machine-operation pair rather than selecting pairs
outright. Our extensive experiments demonstrate CDQAC's remarkable ability to
learn from diverse data sources. CDQAC consistently outperforms the original
data-generating heuristics and surpasses state-of-the-art offline and online RL
baselines. In addition, CDQAC is highly sample efficient, requiring only 10-20
training instances to learn high-quality policies. Surprisingly, we find that
CDQAC performs better when trained on data generated by a random heuristic than
when trained on higher-quality data from genetic algorithms and priority
dispatching rules.

</details>


### [127] [GraphCSVAE: Graph Categorical Structured Variational Autoencoder for Spatiotemporal Auditing of Physical Vulnerability Towards Sustainable Post-Disaster Risk Reduction](https://arxiv.org/abs/2509.10308)
*Joshua Dimasaka,Christian Geiß,Robert Muir-Wood,Emily So*

Main category: cs.LG

TL;DR: 论文提出GraphCSVAE框架，结合深度学习和图表示，用于建模灾害后的物理脆弱性，填补现有风险模型的空白。


<details>
  <summary>Details</summary>
Motivation: 现有灾害风险评估模型在物理脆弱性建模方面进展有限，影响决策者对联合国《仙台框架》目标的评估能力。

Method: 引入GraphCSVAE，结合深度学习、图表示和概率推理，利用卫星数据和专家知识，构建时空脆弱性模型。

Result: 在孟加拉和塞拉利昂的案例中，成功揭示了灾害后物理脆弱性的时空动态变化。

Conclusion: 该框架为灾害后风险评估提供了新工具，支持可持续的减灾策略制定。

Abstract: In the aftermath of disasters, many institutions worldwide face challenges in
continually monitoring changes in disaster risk, limiting the ability of key
decision-makers to assess progress towards the UN Sendai Framework for Disaster
Risk Reduction 2015-2030. While numerous efforts have substantially advanced
the large-scale modeling of hazard and exposure through Earth observation and
data-driven methods, progress remains limited in modeling another equally
important yet challenging element of the risk equation: physical vulnerability.
To address this gap, we introduce Graph Categorical Structured Variational
Autoencoder (GraphCSVAE), a novel probabilistic data-driven framework for
modeling physical vulnerability by integrating deep learning, graph
representation, and categorical probabilistic inference, using time-series
satellite-derived datasets and prior expert belief systems. We introduce a
weakly supervised first-order transition matrix that reflects the changes in
the spatiotemporal distribution of physical vulnerability in two
disaster-stricken and socioeconomically disadvantaged areas: (1) the
cyclone-impacted coastal Khurushkul community in Bangladesh and (2) the
mudslide-affected city of Freetown in Sierra Leone. Our work reveals
post-disaster regional dynamics in physical vulnerability, offering valuable
insights into localized spatiotemporal auditing and sustainable strategies for
post-disaster risk reduction.

</details>


### [128] [ARMA Block: A CNN-Based Autoregressive and Moving Average Module for Long-Term Time Series Forecasting](https://arxiv.org/abs/2509.10324)
*Myung Jin Kim,YeongHyeon Park,Il Dong Yun*

Main category: cs.LG

TL;DR: 提出了一种简单有效的卷积模块ARMA，用于长期时间序列预测，结合了自回归和移动平均组件，直接实现多步预测，并在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统ARIMA模型需要迭代多步预测，且难以扩展到多元设置，因此需要一种更简单且直接的方法。

Method: 设计了包含自回归（捕捉趋势）和移动平均（细化局部变化）的卷积模块，直接实现多步预测。

Result: 在九个基准数据集上表现优异，尤其在趋势变化强的数据上，同时保持了架构简单性。

Conclusion: ARMA模块不仅预测效果好，还能编码绝对位置信息，有望替代序列模型中的位置嵌入。

Abstract: This paper proposes a simple yet effective convolutional module for long-term
time series forecasting. The proposed block, inspired by the Auto-Regressive
Integrated Moving Average (ARIMA) model, consists of two convolutional
components: one for capturing the trend (autoregression) and the other for
refining local variations (moving average). Unlike conventional ARIMA, which
requires iterative multi-step forecasting, the block directly performs
multi-step forecasting, making it easily extendable to multivariate settings.
Experiments on nine widely used benchmark datasets demonstrate that our method
ARMA achieves competitive accuracy, particularly on datasets exhibiting strong
trend variations, while maintaining architectural simplicity. Furthermore,
analysis shows that the block inherently encodes absolute positional
information, suggesting its potential as a lightweight replacement for
positional embeddings in sequential models.

</details>


### [129] [Physics-informed sensor coverage through structure preserving machine learning](https://arxiv.org/abs/2509.10363)
*Benjamin David Shaffer,Brooks Kinch,Joseph Klobusicky,M. Ani Hsieh,Nathaniel Trask*

Main category: cs.LG

TL;DR: 提出了一种基于结构保持数字孪生的自适应源定位机器学习框架，结合条件神经Whitney形式和变换器算子学习，实现实时轨迹规划和数据同化。


<details>
  <summary>Details</summary>
Motivation: 解决复杂流体-输运系统中源定位的实时性和物理约束问题，提升定位精度。

Method: 使用条件神经Whitney形式（CNWF）构建数字孪生，结合有限元外微积分（FEEC）和变换器算子学习，保留离散守恒性，并通过条件注意力机制识别兼容传感器数据的简化模型。

Result: 在复杂几何中，结构保持方法比物理无关变换器架构更准确，证明了物理约束的有效性。

Conclusion: 结构保持为源定位提供了有效的归纳偏置，正则化映射和实时适应性是关键优势。

Abstract: We present a machine learning framework for adaptive source localization in
which agents use a structure-preserving digital twin of a coupled
hydrodynamic-transport system for real-time trajectory planning and data
assimilation. The twin is constructed with conditional neural Whitney forms
(CNWF), coupling the numerical guarantees of finite element exterior calculus
(FEEC) with transformer-based operator learning. The resulting model preserves
discrete conservation, and adapts in real time to streaming sensor data. It
employs a conditional attention mechanism to identify: a reduced Whitney-form
basis; reduced integral balance equations; and a source field, each compatible
with given sensor measurements. The induced reduced-order environmental model
retains the stability and consistency of standard finite-element simulation,
yielding a physically realizable, regular mapping from sensor data to the
source field. We propose a staggered scheme that alternates between evaluating
the digital twin and applying Lloyd's algorithm to guide sensor placement, with
analysis providing conditions for monotone improvement of a coverage
functional. Using the predicted source field as an importance function within
an optimal-recovery scheme, we demonstrate recovery of point sources under
continuity assumptions, highlighting the role of regularity as a sufficient
condition for localization. Experimental comparisons with physics-agnostic
transformer architectures show improved accuracy in complex geometries when
physical constraints are enforced, indicating that structure preservation
provides an effective inductive bias for source identification.

</details>


### [130] [A Discrepancy-Based Perspective on Dataset Condensation](https://arxiv.org/abs/2509.10367)
*Tong Chen,Raghavendra Selvan*

Main category: cs.LG

TL;DR: 提出一个统一框架，将数据集压缩（DC）任务从泛化性能扩展到包括鲁棒性、隐私性等更多目标。


<details>
  <summary>Details</summary>
Motivation: 现有数据集压缩方法主要关注泛化性能，缺乏对其他重要目标（如鲁棒性、隐私性）的统一处理。

Method: 提出一个基于差异度量的统一框架，量化概率分布之间的距离，扩展DC的定义。

Result: 框架能够涵盖现有DC方法，并支持更多目标。

Conclusion: 该框架为数据集压缩任务提供了更广泛的应用场景和理论基础。

Abstract: Given a dataset of finitely many elements $\mathcal{T} = \{\mathbf{x}_i\}_{i
= 1}^N$, the goal of dataset condensation (DC) is to construct a synthetic
dataset $\mathcal{S} = \{\tilde{\mathbf{x}}_j\}_{j = 1}^M$ which is
significantly smaller ($M \ll N$) such that a model trained from scratch on
$\mathcal{S}$ achieves comparable or even superior generalization performance
to a model trained on $\mathcal{T}$. Recent advances in DC reveal a close
connection to the problem of approximating the data distribution represented by
$\mathcal{T}$ with a reduced set of points. In this work, we present a unified
framework that encompasses existing DC methods and extend the task-specific
notion of DC to a more general and formal definition using notions of
discrepancy, which quantify the distance between probability distribution in
different regimes. Our framework broadens the objective of DC beyond
generalization, accommodating additional objectives such as robustness,
privacy, and other desirable properties.

</details>


### [131] [Data distribution impacts the performance and generalisability of contrastive learning-based foundation models of electrocardiograms](https://arxiv.org/abs/2509.10369)
*Gul Rukh Khattak,Konstantinos Patlatzoglou,Joseph Barker,Libor Pastika,Boroumand Zeidaabadi,Ahmed El-Medany,Hesham Aggour,Yixiu Liang,Antonio H. Ribeiro,Jeffrey Annis,Antonio Luiz Pinho Ribeiro,Junbo Ge,Daniel B. Kramer,Jonathan W. Waks,Evan Brittain,Nicholas Peters,Fu Siong Ng,Arunashis Sau*

Main category: cs.LG

TL;DR: CAPE模型通过对比学习预训练心电图数据，发现预训练队列的多样性和健康状态影响下游任务性能，并提出IDB策略提升OOD鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 探索对比学习预训练中队列组成对下游任务性能的影响，尤其是人口统计和健康状态的分布特性。

Method: 使用CAPE模型在四大洲的多样化队列中预训练，并评估其对下游任务的影响，提出IDB策略优化OOD性能。

Result: 预训练队列的多样性和健康状态显著影响下游任务性能，IDB策略能提升模型的OOD鲁棒性。

Conclusion: 研究为开发临床公平且通用的基础模型提供了重要见解，IDB策略有效解决了队列特异性问题。

Abstract: Contrastive learning is a widely adopted self-supervised pretraining
strategy, yet its dependence on cohort composition remains underexplored. We
present Contrasting by Patient Augmented Electrocardiograms (CAPE) foundation
model and pretrain on four cohorts (n = 5,203,352), from diverse populations
across three continents (North America, South America, Asia). We systematically
assess how cohort demographics, health status, and population diversity
influence the downstream performance for prediction tasks also including two
additional cohorts from another continent (Europe). We find that downstream
performance depends on the distributional properties of the pretraining cohort,
including demographics and health status. Moreover, while pretraining with a
multi-centre, demographically diverse cohort improves in-distribution accuracy,
it reduces out-of-distribution (OOD) generalisation of our contrastive approach
by encoding cohort-specific artifacts. To address this, we propose the
In-Distribution Batch (IDB) strategy, which preserves intra-cohort consistency
during pretraining and enhances OOD robustness. This work provides important
insights for developing clinically fair and generalisable foundation models.

</details>


### [132] [Flow Straight and Fast in Hilbert Space: Functional Rectified Flow](https://arxiv.org/abs/2509.10384)
*Jianxin Zhang,Clayton Scott*

Main category: cs.LG

TL;DR: 本文提出了无限维希尔伯特空间中整流流的严格函数形式化，扩展了功能流匹配和概率流ODE，并展示了优于现有功能生成模型的性能。


<details>
  <summary>Details</summary>
Motivation: 探索无限维空间中整流流的扩展，填补现有研究的空白，并改进功能生成模型的性能。

Method: 基于无限维空间中连续性方程的叠加原理，建立整流流的函数形式化，并扩展到功能流匹配和概率流ODE。

Result: 实验证明该方法优于现有功能生成模型，并去除了现有理论中的限制性测度假设。

Conclusion: 本文为无限维空间中的整流流提供了理论基础和实用框架，展示了其在功能生成模型中的优越性。

Abstract: Many generative models originally developed in finite-dimensional Euclidean
space have functional generalizations in infinite-dimensional settings.
However, the extension of rectified flow to infinite-dimensional spaces remains
unexplored. In this work, we establish a rigorous functional formulation of
rectified flow in an infinite-dimensional Hilbert space. Our approach builds
upon the superposition principle for continuity equations in an
infinite-dimensional space. We further show that this framework extends
naturally to functional flow matching and functional probability flow ODEs,
interpreting them as nonlinear generalizations of rectified flow. Notably, our
extension to functional flow matching removes the restrictive measure-theoretic
assumptions in the existing theory of \citet{kerrigan2024functional}.
Furthermore, we demonstrate experimentally that our method achieves superior
performance compared to existing functional generative models.

</details>


### [133] [Vendi Information Gain for Active Learning and its Application to Ecology](https://arxiv.org/abs/2509.10390)
*Quan Nguyen,Adji Bousso Dieng*

Main category: cs.LG

TL;DR: 提出了一种新的主动学习策略VIG，通过考虑数据集范围内的预测不确定性，显著提高了物种识别的效率，仅需10%的标签即可接近全监督的准确率。


<details>
  <summary>Details</summary>
Motivation: 解决相机陷阱图像数据中物种识别因标签资源有限而效率低下的问题。

Method: 引入Vendi信息增益（VIG）策略，选择对数据集整体预测不确定性影响最大的图像进行标注。

Result: 在Snapshot Serengeti数据集上，VIG仅用不到10%的标签就达到了接近全监督的准确率，且优于基线方法。

Conclusion: VIG策略在数据有限的环境中具有广泛适用性，尤其适用于生物多样性监测。

Abstract: While monitoring biodiversity through camera traps has become an important
endeavor for ecological research, identifying species in the captured image
data remains a major bottleneck due to limited labeling resources. Active
learning -- a machine learning paradigm that selects the most informative data
to label and train a predictive model -- offers a promising solution, but
typically focuses on uncertainty in the individual predictions without
considering uncertainty across the entire dataset. We introduce a new active
learning policy, Vendi information gain (VIG), that selects images based on
their impact on dataset-wide prediction uncertainty, capturing both
informativeness and diversity. Applied to the Snapshot Serengeti dataset, VIG
achieves impressive predictive accuracy close to full supervision using less
than 10% of the labels. It consistently outperforms standard baselines across
metrics and batch sizes, collecting more diverse data in the feature space. VIG
has broad applicability beyond ecology, and our results highlight its value for
biodiversity monitoring in data-limited environments.

</details>


### [134] [Inpainting-Guided Policy Optimization for Diffusion Large Language Models](https://arxiv.org/abs/2509.10396)
*Siyan Zhao,Mengchen Liu,Jing Huang,Miao Liu,Chenyu Wang,Bo Liu,Yuandong Tian,Guan Pang,Sean Bell,Aditya Grover,Feiyu Chen*

Main category: cs.LG

TL;DR: 论文提出了一种名为IGPO的强化学习框架，利用dLLMs的inpainting能力指导探索，提高样本效率，并在数学基准测试中取得新SOTA。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs与强化学习对齐时的探索挑战，如稀疏奖励和样本浪费，利用dLLMs的inpainting能力优化探索过程。

Method: 引入IGPO框架，通过部分真实推理痕迹引导探索，结合监督微调和强化学习，提升样本效率和梯度有效性。

Result: 在GSM8K、Math500和AMC三个数学基准测试中取得新SOTA结果，验证了方法的有效性。

Conclusion: IGPO框架通过inpainting能力有效解决了探索问题，显著提升了dLLMs在数学任务中的性能。

Abstract: Masked diffusion large language models (dLLMs) are emerging as promising
alternatives to autoregressive LLMs, offering competitive performance while
supporting unique generation capabilities such as inpainting. We explore how
inpainting can inform RL algorithm design for dLLMs. Aligning LLMs with
reinforcement learning faces an exploration challenge: sparse reward signals
and sample waste when models fail to discover correct solutions. While this
inefficiency affects LLMs broadly, dLLMs offer a distinctive opportunity--their
inpainting ability can guide exploration. We introduce IGPO (Inpainting Guided
Policy Optimization), an RL framework that strategically inserts partial
ground-truth reasoning traces during online sampling. Unlike providing full
solutions, inpainting steers exploration toward promising trajectory spaces
while preserving self-generated reasoning, bridging supervised fine-tuning and
reinforcement learning. We apply IGPO to group-based optimization methods such
as GRPO, where exploration failures cause zero advantages and gradients. IGPO
restores meaningful gradients while improving sample efficiency. We also
propose supervised fine-tuning on synthetically rewritten concise traces that
better align with dLLM generation patterns. With additional techniques
including entropy-based filtering, our training recipe yields substantial gains
across three mathematical benchmarks--GSM8K, Math500, and AMC--achieving new
state-of-the-art results for full-attention masked dLLMs.

</details>


### [135] [Multipole Semantic Attention: A Fast Approximation of Softmax Attention for Pretraining](https://arxiv.org/abs/2509.10406)
*Rupert Mitchell,Kristian Kersting*

Main category: cs.LG

TL;DR: MuSe是一种高效的softmax注意力近似方法，结合语义聚类和多极展开，显著降低Transformer的计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 解决Transformer在长上下文场景中二次计算复杂度的问题，通过分层注意力机制提升效率。

Method: 分别对查询和键进行语义聚类，引入多极展开（包括单极和偶极校正）保留更丰富信息，无需修改架构即可实现。

Result: 在8k上下文长度下比CUDNN Flash Attention快3倍，误差低于20%；在16k上下文的端到端预训练中，运行时减少12.2%，性能仅下降0.36%。

Conclusion: MuSe证明了多极近似在高效Transformer预训练中的可行性，适用于长文本场景。

Abstract: We present Multipole Semantic Attention (MuSe), an efficient approximation of
softmax attention that combines semantic clustering with multipole expansions
from computational physics. Our method addresses the quadratic computational
complexity of transformers in the context length by clustering queries and keys
separately in their learned representation spaces, enabling a hierarchical
two-stage attention mechanism. Unlike prior clustering approaches that group
only keys or use unified clustering, we maintain separate clusterings that
respect attention's asymmetric treatment of these spaces. We augment
centroid-based (monopole) approximations with dipole corrections that capture
directional variance within clusters, preserving richer information during
training. The method operates as a drop-in replacement for standard attention,
requiring only hyperparameter specification without architectural
modifications. Our approach achieves $\mathcal{O}(NCD)$ complexity for acausal
attention with $C$ clusters and $\mathcal{O}(NCD \log N)$ for causal attention.
On isolated attention layers, we demonstrate $3\times$ speedup over CUDNN Flash
Attention at 8k context length, with relative squared errors below 20%. For
causal attention, we develop a hierarchical block decomposition that combines
exact local computation with efficient long-range approximation. In end-to-end
pretraining of a 30M parameter model on book-length texts with 16k context, we
achieve 12.2% runtime reduction with only 0.36% loss degradation, establishing
the viability of multipole approximations for efficient transformer
pretraining.

</details>


### [136] [Run-Time Monitoring of ERTMS/ETCS Control Flow by Process Mining](https://arxiv.org/abs/2509.10419)
*Francesco Vitale,Tommaso Zoppi,Francesco Flammini,Nicola Mazzocca*

Main category: cs.LG

TL;DR: 论文探讨了利用过程挖掘进行运行时控制流异常检测，以增强ERTMS/ETCS L2系统的韧性。


<details>
  <summary>Details</summary>
Motivation: 铁路系统的复杂性和关键性增加，需要应对运行时异常，如残留故障、未知修改或网络威胁。

Method: 使用过程挖掘从执行轨迹中学习系统实际控制流，并结合无监督机器学习进行异常定位。

Result: 在RBC/RBC Handover场景中，方法展示了高准确性、效率和可解释性。

Conclusion: 该方法能有效检测和定位异常，提升系统韧性。

Abstract: Ensuring the resilience of computer-based railways is increasingly crucial to
account for uncertainties and changes due to the growing complexity and
criticality of those systems. Although their software relies on strict
verification and validation processes following well-established best-practices
and certification standards, anomalies can still occur at run-time due to
residual faults, system and environmental modifications that were unknown at
design-time, or other emergent cyber-threat scenarios. This paper explores
run-time control-flow anomaly detection using process mining to enhance the
resilience of ERTMS/ETCS L2 (European Rail Traffic Management System / European
Train Control System Level 2). Process mining allows learning the actual
control flow of the system from its execution traces, thus enabling run-time
monitoring through online conformance checking. In addition, anomaly
localization is performed through unsupervised machine learning to link
relevant deviations to critical system components. We test our approach on a
reference ERTMS/ETCS L2 scenario, namely the RBC/RBC Handover, to show its
capability to detect and localize anomalies with high accuracy, efficiency, and
explainability.

</details>


### [137] [Understanding Outer Optimizers in Local SGD: Learning Rates, Momentum, and Acceleration](https://arxiv.org/abs/2509.10439)
*Ahmed Khaled,Satyen Kale,Arthur Douillard,Chi Jin,Rob Fergus,Manzil Zaheer*

Main category: cs.LG

TL;DR: 论文研究了Local SGD中外层优化器的作用，证明了新的收敛性保证，并提出了数据依赖的分析方法。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习常需大规模分布式训练，通信成为瓶颈。Local SGD能减少通信开销，但外层优化器的选择及其超参数影响尚不明确。

Method: 通过理论分析和实验验证，研究了外层学习率的作用，包括其与优化误差和梯度噪声方差的权衡，以及动量调整的影响。

Result: 理论表明外层学习率有时应大于1，动量调整和加速能提升收敛速度。实验验证了理论的有效性。

Conclusion: 外层优化器的选择和调参对Local SGD性能至关重要，数据依赖分析提供了进一步的调参指导。

Abstract: Modern machine learning often requires training with large batch size,
distributed data, and massively parallel compute hardware (like mobile and
other edge devices or distributed data centers). Communication becomes a major
bottleneck in such settings but methods like Local Stochastic Gradient Descent
(Local SGD) show great promise in reducing this additional communication
overhead. Local SGD consists of three parts: a local optimization process, an
aggregation mechanism, and an outer optimizer that uses the aggregated updates
from the nodes to produce a new model. While there exists an extensive
literature on understanding the impact of hyperparameters in the local
optimization process, the choice of outer optimizer and its hyperparameters is
less clear. We study the role of the outer optimizer in Local SGD, and prove
new convergence guarantees for the algorithm. In particular, we show that
tuning the outer learning rate allows us to (a) trade off between optimization
error and stochastic gradient noise variance, and (b) make up for ill-tuning of
the inner learning rate. Our theory suggests that the outer learning rate
should sometimes be set to values greater than $1$. We extend our results to
settings where we use momentum in the outer optimizer, and we show a similar
role for the momentum-adjusted outer learning rate. We also study acceleration
in the outer optimizer and show that it improves the convergence rate as a
function of the number of communication rounds, improving upon the convergence
rate of prior algorithms that apply acceleration locally. Finally, we also
introduce a novel data-dependent analysis of Local SGD that yields further
insights on outer learning rate tuning. We conduct comprehensive experiments
with standard language models and various outer optimizers to validate our
theory.

</details>
