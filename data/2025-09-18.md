<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 83]
- [cs.LG](#cs.LG) [Total: 54]
- [cs.RO](#cs.RO) [Total: 64]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Proximity-Based Evidence Retrieval for Uncertainty-Aware Neural Networks](https://arxiv.org/abs/2509.13338)
*Hassan Gharoun,Mohammad Sadegh Khorshidi,Kasra Ranjbarigderi,Fang Chen,Amir H. Gandomi*

Main category: cs.CV

TL;DR: 提出了一种基于证据检索的不确定性感知决策机制，通过实例自适应阈值替代全局固定阈值，提高了决策的可靠性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统方法使用全局固定阈值进行不确定性感知决策，缺乏透明性和可审计性。本文旨在通过证据检索和融合机制，提供更可靠和可解释的决策方法。

Method: 为每个测试实例在嵌入空间中检索邻近样本，通过Dempster-Shafer理论融合其预测分布，生成实例自适应的阈值机制。

Result: 在CIFAR-10/100数据集上，使用BiT和ViT骨干网络，表现出更高或相当的uncertainty-aware性能，同时显著减少错误置信预测，并保持可持续的审查负载。

Conclusion: 证据条件标记为不确定性感知决策提供了比固定预测熵阈值更可靠和可解释的替代方案。

Abstract: This work proposes an evidence-retrieval mechanism for uncertainty-aware
decision-making that replaces a single global cutoff with an
evidence-conditioned, instance-adaptive criterion. For each test instance,
proximal exemplars are retrieved in an embedding space; their predictive
distributions are fused via Dempster-Shafer theory. The resulting fused belief
acts as a per-instance thresholding mechanism. Because the supporting evidences
are explicit, decisions are transparent and auditable. Experiments on
CIFAR-10/100 with BiT and ViT backbones show higher or comparable
uncertainty-aware performance with materially fewer confidently incorrect
outcomes and a sustainable review load compared with applying threshold on
prediction entropy. Notably, only a few evidences are sufficient to realize
these gains; increasing the evidence set yields only modest changes. These
results indicate that evidence-conditioned tagging provides a more reliable and
interpretable alternative to fixed prediction entropy thresholds for
operational uncertainty-aware decision-making.

</details>


### [2] [Hybrid Quantum-Classical Model for Image Classification](https://arxiv.org/abs/2509.13353)
*Muhammad Adnan Shahzad*

Main category: cs.CV

TL;DR: 混合量子-经典神经网络在准确性、训练效率和参数可扩展性上优于纯经典模型，尤其在复杂视觉任务中表现突出。


<details>
  <summary>Details</summary>
Motivation: 比较混合量子-经典神经网络与纯经典模型在性能、效率和鲁棒性上的差异，探索量子计算在深度学习中的潜力。

Method: 在MNIST、CIFAR100和STL10数据集上，对比混合模型（结合参数化量子电路与经典深度学习架构）与纯经典CNN模型的性能。

Result: 混合模型在验证准确率、训练速度、参数效率和资源使用上均优于经典模型，但在复杂数据集上的对抗鲁棒性表现相似。

Conclusion: 混合量子-经典架构在复杂视觉任务中具有显著优势，为量子计算在深度学习中的应用提供了有力支持。

Abstract: This study presents a systematic comparison between hybrid quantum-classical
neural networks and purely classical models across three benchmark datasets
(MNIST, CIFAR100, and STL10) to evaluate their performance, efficiency, and
robustness. The hybrid models integrate parameterized quantum circuits with
classical deep learning architectures, while the classical counterparts use
conventional convolutional neural networks (CNNs). Experiments were conducted
over 50 training epochs for each dataset, with evaluations on validation
accuracy, test accuracy, training time, computational resource usage, and
adversarial robustness (tested with $\epsilon=0.1$ perturbations).Key findings
demonstrate that hybrid models consistently outperform classical models in
final accuracy, achieving {99.38\% (MNIST), 41.69\% (CIFAR100), and 74.05\%
(STL10) validation accuracy, compared to classical benchmarks of 98.21\%,
32.25\%, and 63.76\%, respectively. Notably, the hybrid advantage scales with
dataset complexity, showing the most significant gains on CIFAR100 (+9.44\%)
and STL10 (+10.29\%). Hybrid models also train 5--12$\times$ faster (e.g.,
21.23s vs. 108.44s per epoch on MNIST) and use 6--32\% fewer parameters} while
maintaining superior generalization to unseen test data.Adversarial robustness
tests reveal that hybrid models are significantly more resilient on simpler
datasets (e.g., 45.27\% robust accuracy on MNIST vs. 10.80\% for classical) but
show comparable fragility on complex datasets like CIFAR100 ($\sim$1\%
robustness for both). Resource efficiency analyses indicate that hybrid models
consume less memory (4--5GB vs. 5--6GB for classical) and lower CPU utilization
(9.5\% vs. 23.2\% on average).These results suggest that hybrid
quantum-classical architectures offer compelling advantages in accuracy,
training efficiency, and parameter scalability, particularly for complex vision
tasks.

</details>


### [3] [Research on Expressway Congestion Warning Technology Based on YOLOv11-DIoU and GRU-Attention](https://arxiv.org/abs/2509.13361)
*Tong Yulin,Liang Xuechen*

Main category: cs.CV

TL;DR: 提出了一种解决高速公路交通拥堵感知和预测问题的集成技术框架，优化了车辆检测和跟踪算法，并构建了高效的拥堵预警模型。


<details>
  <summary>Details</summary>
Motivation: 现有系统在遮挡情况下车辆感知精度低，且拥堵预测中丢失长序列依赖关系，亟需改进。

Method: 优化YOLOv11和DeepSort算法，采用GRU-Attention模型捕捉拥堵前兆。

Result: YOLOv11-DIoU的mAP达95.7%，GRU-Attention测试准确率99.7%，预警时间误差≤1分钟。

Conclusion: 该框架为高速公路拥堵控制提供了量化支持，具有智能交通应用潜力。

Abstract: Expressway traffic congestion severely reduces travel efficiency and hinders
regional connectivity. Existing "detection-prediction" systems have critical
flaws: low vehicle perception accuracy under occlusion and loss of
long-sequence dependencies in congestion forecasting. This study proposes an
integrated technical framework to resolve these issues.For traffic flow
perception, two baseline algorithms were optimized. Traditional YOLOv11 was
upgraded to YOLOv11-DIoU by replacing GIoU Loss with DIoU Loss, and DeepSort
was improved by fusing Mahalanobis (motion) and cosine (appearance) distances.
Experiments on Chang-Shen Expressway videos showed YOLOv11-DIoU achieved 95.7\%
mAP (6.5 percentage points higher than baseline) with 5.3\% occlusion miss
rate. DeepSort reached 93.8\% MOTA (11.3 percentage points higher than SORT)
with only 4 ID switches. Using the Greenberg model (for 10-15 vehicles/km
high-density scenarios), speed and density showed a strong negative correlation
(r=-0.97), conforming to traffic flow theory. For congestion warning, a
GRU-Attention model was built to capture congestion precursors. Trained 300
epochs with flow, density, and speed, it achieved 99.7\% test accuracy (7-9
percentage points higher than traditional GRU). In 10-minute advance warnings
for 30-minute congestion, time error was $\leq$ 1 minute. Validation with an
independent video showed 95\% warning accuracy, over 90\% spatial overlap of
congestion points, and stable performance in high-flow ($>$5 vehicles/second)
scenarios.This framework provides quantitative support for expressway
congestion control, with promising intelligent transportation applications.

</details>


### [4] [Parking Space Ground Truth Test Automation by Artificial Intelligence Using Convolutional Neural Networks](https://arxiv.org/abs/2509.13366)
*Tony Rohe,Martin Margreiter,Markus Moertl*

Main category: cs.CV

TL;DR: 研究通过机器学习优化实时路边停车服务，利用卷积神经网络实现自动化测试，减少人力资源99.58%。


<details>
  <summary>Details</summary>
Motivation: 优化现有停车服务质量，替代人工分析工作。

Method: 应用机器学习（尤其是图像模式识别）和卷积神经网络实现自动化。

Result: 自动化测试显著减少人力资源（99.58%）。

Conclusion: 方法有效，未来可进一步扩展应用。

Abstract: This research is part of a study of a real-time, cloud-based on-street
parking service using crowd-sourced in-vehicle fleet data. The service provides
real-time information about available parking spots by classifying
crowd-sourced detections observed via ultrasonic sensors. The goal of this
research is to optimize the current parking service quality by analyzing the
automation of the existing test process for ground truth tests. Therefore,
methods from the field of machine learning, especially image pattern
recognition, are applied to enrich the database and substitute human
engineering work in major areas of the analysis process. After an introduction
into the related areas of machine learning, this paper explains the methods and
implementations made to achieve a high level of automation, applying
convolutional neural networks. Finally, predefined metrics present the
performance level achieved, showing a time reduction of human resources up to
99.58 %. The overall improvements are discussed, summarized, and followed by an
outlook for future development and potential application of the analysis
automation tool.

</details>


### [5] [An Empirical Analysis of VLM-based OOD Detection: Mechanisms, Advantages, and Sensitivity](https://arxiv.org/abs/2509.13375)
*Yuxiao Lee,Xiaofeng Cao,Wei Ye,Jiangchao Yao,Jingkuan Song,Heng Tao Shen*

Main category: cs.CV

TL;DR: 本文系统分析了基于视觉语言模型（VLM）的零样本分布外（OOD）检测，揭示了其工作机制、优势及行为鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管VLM（如CLIP）在零样本OOD检测中表现优异，但其工作机制、相对于单模态方法的优势及行为鲁棒性尚未被充分理解。

Method: 通过系统实验分析，研究了VLM在嵌入空间中的关键操作特性，并对比了单模态方法。

Result: VLM在零样本OOD检测中表现优越，主要得益于其丰富的语义新颖性，但对提示词敏感。

Conclusion: 研究为VLM的OOD检测提供了结构化理解，揭示了其优势与关键脆弱性，为未来设计提供了实证指导。

Abstract: Vision-Language Models (VLMs), such as CLIP, have demonstrated remarkable
zero-shot out-of-distribution (OOD) detection capabilities, vital for reliable
AI systems. Despite this promising capability, a comprehensive understanding of
(1) why they work so effectively, (2) what advantages do they have over
single-modal methods, and (3) how is their behavioral robustness -- remains
notably incomplete within the research community. This paper presents a
systematic empirical analysis of VLM-based OOD detection using in-distribution
(ID) and OOD prompts. (1) Mechanisms: We systematically characterize and
formalize key operational properties within the VLM embedding space that
facilitate zero-shot OOD detection. (2) Advantages: We empirically quantify the
superiority of these models over established single-modal approaches,
attributing this distinct advantage to the VLM's capacity to leverage rich
semantic novelty. (3) Sensitivity: We uncovers a significant and previously
under-explored asymmetry in their robustness profile: while exhibiting
resilience to common image noise, these VLM-based methods are highly sensitive
to prompt phrasing. Our findings contribute a more structured understanding of
the strengths and critical vulnerabilities inherent in VLM-based OOD detection,
offering crucial, empirically-grounded guidance for developing more robust and
reliable future designs.

</details>


### [6] [Curvature as a tool for evaluating dimensionality reduction and estimating intrinsic dimension](https://arxiv.org/abs/2509.13385)
*Charlotte Beylier,Parvaneh Joharinad,Jürgen Jost,Nahid Torbati*

Main category: cs.CV

TL;DR: 提出了一种基于曲率的几何分析方法，用于评估数据表示的有效性和估计数据集的固有维度。


<details>
  <summary>Details</summary>
Motivation: 利用曲率概念捕捉离散度量空间的几何特性，以评估数据表示和维度缩减技术的效果。

Method: 通过曲率剖面分析数据的三元组关系，提出定量评估方法。

Result: 实验证明该方法可用于估计数据集的固有维度和评估维度缩减技术。

Conclusion: 曲率分析为数据表示和网络几何研究提供了有效工具。

Abstract: Utilizing recently developed abstract notions of sectional curvature, we
introduce a method for constructing a curvature-based geometric profile of
discrete metric spaces. The curvature concept that we use here captures the
metric relations between triples of points and other points. More
significantly, based on this curvature profile, we introduce a quantitative
measure to evaluate the effectiveness of data representations, such as those
produced by dimensionality reduction techniques. Furthermore, Our experiments
demonstrate that this curvature-based analysis can be employed to estimate the
intrinsic dimensionality of datasets. We use this to explore the large-scale
geometry of empirical networks and to evaluate the effectiveness of
dimensionality reduction techniques.

</details>


### [7] [Landcover classification and change detection using remote sensing and machine learning: a case study of Western Fiji](https://arxiv.org/abs/2509.13388)
*Yadvendra Gurjar,Ruoni Wan,Ehsan Farahbakhsh,Rohitash Chandra*

Main category: cs.CV

TL;DR: 利用机器学习和遥感技术分析斐济纳迪2013-2024年土地利用变化，支持土地覆盖建模和变化检测。


<details>
  <summary>Details</summary>
Motivation: 斐济作为发展中国家面临快速城市化，需技术支持土地利用变化监测。

Method: 使用Landsat-8卫星图像，结合Google Earth Engine和k-means聚类进行无监督学习，卷积神经网络分类土地覆盖类型。

Result: 生成土地覆盖图，可视化城市区域随时间的变化。

Conclusion: 研究为土地利用建模和变化检测提供了有效技术手段。

Abstract: As a developing country, Fiji is facing rapid urbanisation, which is visible
in the massive development projects that include housing, roads, and civil
works. In this study, we present machine learning and remote sensing frameworks
to compare land use and land cover change from 2013 to 2024 in Nadi, Fiji. The
ultimate goal of this study is to provide technical support in land cover/land
use modelling and change detection. We used Landsat-8 satellite image for the
study region and created our training dataset with labels for supervised
machine learning. We used Google Earth Engine and unsupervised machine learning
via k-means clustering to generate the land cover map. We used convolutional
neural networks to classify the selected regions' land cover types. We present
a visualisation of change detection, highlighting urban area changes over time
to monitor changes in the map.

</details>


### [8] [Real-Time Detection and Tracking of Foreign Object Intrusions in Power Systems via Feature-Based Edge Intelligence](https://arxiv.org/abs/2509.13396)
*Xinan Wang,Di Shi,Fengyu Wang*

Main category: cs.CV

TL;DR: 提出了一种用于电力传输系统中实时异物入侵检测与跟踪的三阶段框架，结合了YOLOv7分割、ConvNeXt特征提取和特征辅助IoU跟踪，并在边缘设备上进行了优化。


<details>
  <summary>Details</summary>
Motivation: 电力传输系统中的异物入侵（FOI）可能导致严重事故，需要实时、准确的检测与跟踪方法。

Method: 1. YOLOv7分割模型定位物体；2. ConvNeXt特征提取器生成判别性嵌入；3. 特征辅助IoU跟踪器处理遮挡和运动。

Result: 在真实监控和无人机视频数据集上表现出高准确性和鲁棒性，并在边缘设备上验证了实用性。

Conclusion: 该框架在多样化的FOI场景中高效且可扩展，适用于实际边缘应用。

Abstract: This paper presents a novel three-stage framework for real-time foreign
object intrusion (FOI) detection and tracking in power transmission systems.
The framework integrates: (1) a YOLOv7 segmentation model for fast and robust
object localization, (2) a ConvNeXt-based feature extractor trained with
triplet loss to generate discriminative embeddings, and (3) a feature-assisted
IoU tracker that ensures resilient multi-object tracking under occlusion and
motion. To enable scalable field deployment, the pipeline is optimized for
deployment on low-cost edge hardware using mixed-precision inference. The
system supports incremental updates by adding embeddings from previously unseen
objects into a reference database without requiring model retraining. Extensive
experiments on real-world surveillance and drone video datasets demonstrate the
framework's high accuracy and robustness across diverse FOI scenarios. In
addition, hardware benchmarks on NVIDIA Jetson devices confirm the framework's
practicality and scalability for real-world edge applications.

</details>


### [9] [EdiVal-Agent: An Object-Centric Framework for Automated, Scalable, Fine-Grained Evaluation of Multi-Turn Editing](https://arxiv.org/abs/2509.13399)
*Tianyu Chen,Yasi Zhang,Zhi Zhang,Peiyu Yu,Shu Wang,Zhendong Wang,Kevin Lin,Xiaofei Wang,Zhengyuan Yang,Linjie Li,Chung-Ching Lin,Jianwen Xie,Oscar Leong,Lijuan Wang,Ying Nian Wu,Mingyuan Zhou*

Main category: cs.CV

TL;DR: EdiVal-Agent是一个自动化、可扩展的评估框架，用于多轮指令编辑，结合视觉语言模型和对象检测器提升评估准确性。


<details>
  <summary>Details</summary>
Motivation: 解决当前指令编辑评估方法依赖有限参考图像或零样本视觉语言模型的不精确问题。

Method: 通过分解图像为语义对象、生成多样化编辑指令，结合VLMs和对象检测器评估指令遵循、内容一致性和视觉质量。

Result: EdiVal-Agent在指令遵循评估中与人类判断更一致，优于单独使用VLMs或CLIP指标。

Conclusion: EdiVal-Agent能识别现有编辑模型的失败模式，推动下一代模型发展。

Abstract: Instruction-based image editing has advanced rapidly, yet reliable and
interpretable evaluation remains a bottleneck. Current protocols either (i)
depend on paired reference images -- resulting in limited coverage and
inheriting biases from prior generative models -- or (ii) rely solely on
zero-shot vision-language models (VLMs), whose prompt-based assessments of
instruction following, content consistency, and visual quality are often
imprecise.
  To address this, we introduce EdiVal-Agent, an automated, scalable, and
fine-grained evaluation framework for multi-turn instruction-based editing from
an object-centric perspective, supported by a suite of expert tools. Given an
image, EdiVal-Agent first decomposes it into semantically meaningful objects,
then synthesizes diverse, context-aware editing instructions. For evaluation,
it integrates VLMs with open-vocabulary object detectors to assess instruction
following, uses semantic-level feature extractors to evaluate content
consistency, and leverages human preference models to judge visual quality. We
show that combining VLMs with object detectors yields stronger agreement with
human judgments in instruction-following evaluation compared to using VLMs
alone and CLIP-based metrics. Furthermore, the pipeline's modular design allows
future tools to be seamlessly integrated, enhancing evaluation accuracy over
time.
  Instantiating this pipeline, we build EdiVal-Bench, a multi-turn editing
benchmark covering 9 instruction types and 11 state-of-the-art editing models
spanning autoregressive (AR) (including Nano Banana, GPT-Image-1),
flow-matching, and diffusion paradigms. We demonstrate that EdiVal-Agent can be
used to identify existing failure modes, thereby informing the development of
the next generation of editing models. Project page:
https://tianyucodings.github.io/EdiVAL-page/.

</details>


### [10] [MapAnything: Universal Feed-Forward Metric 3D Reconstruction](https://arxiv.org/abs/2509.13414)
*Nikhil Keetha,Norman Müller,Johannes Schönberger,Lorenzo Porzi,Yuchen Zhang,Tobias Fischer,Arno Knapitsch,Duncan Zauss,Ethan Weber,Nelson Antunes,Jonathon Luiten,Manuel Lopez-Antequera,Samuel Rota Bulò,Christian Richardt,Deva Ramanan,Sebastian Scherer,Peter Kontschieder*

Main category: cs.CV

TL;DR: MapAnything是一个基于Transformer的统一前馈模型，能够处理图像和几何输入，直接回归3D场景几何和相机参数。


<details>
  <summary>Details</summary>
Motivation: 解决多种3D视觉任务需要不同专用模型的问题，提出一个通用框架。

Method: 使用分解的多视角场景几何表示，标准化监督和训练，支持灵活输入增强。

Result: 在多个任务上表现优于或匹配专用模型，训练效率更高。

Conclusion: MapAnything为通用3D重建框架奠定了基础。

Abstract: We introduce MapAnything, a unified transformer-based feed-forward model that
ingests one or more images along with optional geometric inputs such as camera
intrinsics, poses, depth, or partial reconstructions, and then directly
regresses the metric 3D scene geometry and cameras. MapAnything leverages a
factored representation of multi-view scene geometry, i.e., a collection of
depth maps, local ray maps, camera poses, and a metric scale factor that
effectively upgrades local reconstructions into a globally consistent metric
frame. Standardizing the supervision and training across diverse datasets,
along with flexible input augmentation, enables MapAnything to address a broad
range of 3D vision tasks in a single feed-forward pass, including uncalibrated
structure-from-motion, calibrated multi-view stereo, monocular depth
estimation, camera localization, depth completion, and more. We provide
extensive experimental analyses and model ablations demonstrating that
MapAnything outperforms or matches specialist feed-forward models while
offering more efficient joint training behavior, thus paving the way toward a
universal 3D reconstruction backbone.

</details>


### [11] [Semantic-Enhanced Cross-Modal Place Recognition for Robust Robot Localization](https://arxiv.org/abs/2509.13474)
*Yujia Lin,Nicholas Evans*

Main category: cs.CV

TL;DR: SCM-PR框架结合RGB图像和LiDAR地图的高层语义，通过VMamba骨干网络、SAFF模块和跨模态语义注意力机制，提升了复杂场景下的定位性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有RGB方法对光照、天气和季节变化的敏感性，以及跨模态方法在复杂场景和视角变化中的不足。

Method: 提出SCM-PR框架，包括VMamba特征提取、SAFF模块、LiDAR描述符和跨模态语义注意力机制。

Result: 在KITTI和KITTI-360数据集上，SCM-PR表现优于现有跨模态定位方法。

Conclusion: SCM-PR通过语义增强和几何匹配，显著提升了复杂环境下的定位鲁棒性。

Abstract: Ensuring accurate localization of robots in environments without GPS
capability is a challenging task. Visual Place Recognition (VPR) techniques can
potentially achieve this goal, but existing RGB-based methods are sensitive to
changes in illumination, weather, and other seasonal changes. Existing
cross-modal localization methods leverage the geometric properties of RGB
images and 3D LiDAR maps to reduce the sensitivity issues highlighted above.
Currently, state-of-the-art methods struggle in complex scenes, fine-grained or
high-resolution matching, and situations where changes can occur in viewpoint.
In this work, we introduce a framework we call Semantic-Enhanced Cross-Modal
Place Recognition (SCM-PR) that combines high-level semantics utilizing RGB
images for robust localization in LiDAR maps. Our proposed method introduces: a
VMamba backbone for feature extraction of RGB images; a Semantic-Aware Feature
Fusion (SAFF) module for using both place descriptors and segmentation masks;
LiDAR descriptors that incorporate both semantics and geometry; and a
cross-modal semantic attention mechanism in NetVLAD to improve matching.
Incorporating the semantic information also was instrumental in designing a
Multi-View Semantic-Geometric Matching and a Semantic Consistency Loss, both in
a contrastive learning framework. Our experimental work on the KITTI and
KITTI-360 datasets show that SCM-PR achieves state-of-the-art performance
compared to other cross-modal place recognition methods.

</details>


### [12] [Improving 3D Gaussian Splatting Compression by Scene-Adaptive Lattice Vector Quantization](https://arxiv.org/abs/2509.13482)
*Hao Xu,Xiaolin Wu,Xi Zhang*

Main category: cs.CV

TL;DR: 3D高斯泼溅（3DGS）数据压缩问题通过场景自适应格向量量化（SALVQ）解决，提升压缩性能且低开销。


<details>
  <summary>Details</summary>
Motivation: 3DGS数据量大，现有压缩方法依赖简单均匀标量量化（USQ），探索更高效量化方法。

Method: 用格向量量化（LVQ）替代USQ，优化格基以适应场景特性，实现高效压缩。

Result: SALVQ提升R-D性能，动态调整压缩率，减少训练时间和内存消耗。

Conclusion: SALVQ为3DGS压缩提供高效灵活方案，兼容现有架构。

Abstract: 3D Gaussian Splatting (3DGS) is rapidly gaining popularity for its
photorealistic rendering quality and real-time performance, but it generates
massive amounts of data. Hence compressing 3DGS data is necessary for the cost
effectiveness of 3DGS models. Recently, several anchor-based neural compression
methods have been proposed, achieving good 3DGS compression performance.
However, they all rely on uniform scalar quantization (USQ) due to its
simplicity. A tantalizing question is whether more sophisticated quantizers can
improve the current 3DGS compression methods with very little extra overhead
and minimal change to the system. The answer is yes by replacing USQ with
lattice vector quantization (LVQ). To better capture scene-specific
characteristics, we optimize the lattice basis for each scene, improving LVQ's
adaptability and R-D efficiency. This scene-adaptive LVQ (SALVQ) strikes a
balance between the R-D efficiency of vector quantization and the low
complexity of USQ. SALVQ can be seamlessly integrated into existing 3DGS
compression architectures, enhancing their R-D performance with minimal
modifications and computational overhead. Moreover, by scaling the lattice
basis vectors, SALVQ can dynamically adjust lattice density, enabling a single
model to accommodate multiple bit rate targets. This flexibility eliminates the
need to train separate models for different compression levels, significantly
reducing training time and memory consumption.

</details>


### [13] [MINGLE: VLMs for Semantically Complex Region Detection in Urban Scenes](https://arxiv.org/abs/2509.13484)
*Liu Liu,Alexandra Kudaeva,Marco Cipriano,Fatimeh Al Ghannam,Freya Tan,Gerard de Melo,Andres Sevtsuk*

Main category: cs.CV

TL;DR: 论文提出了一种名为MINGLE的三阶段模块化方法，用于检测图像中的社交群体区域，并发布了一个包含10万张街景图像的新数据集。


<details>
  <summary>Details</summary>
Motivation: 理解公共场所中的群体社交互动对城市规划至关重要，但传统目标检测方法难以捕捉复杂的社交信号。

Method: MINGLE方法整合了现成的人体检测与深度估计、基于VLM的社交关系分类，以及轻量级空间聚合算法。

Result: 提出了一个新数据集，并结合人工标注与MINGLE输出，确保语义丰富性和场景覆盖。

Conclusion: MINGLE为社交群体检测提供了有效方法，新数据集将推动未来研究。

Abstract: Understanding group-level social interactions in public spaces is crucial for
urban planning, informing the design of socially vibrant and inclusive
environments. Detecting such interactions from images involves interpreting
subtle visual cues such as relations, proximity, and co-movement - semantically
complex signals that go beyond traditional object detection. To address this
challenge, we introduce a social group region detection task, which requires
inferring and spatially grounding visual regions defined by abstract
interpersonal relations. We propose MINGLE (Modeling INterpersonal Group-Level
Engagement), a modular three-stage pipeline that integrates: (1) off-the-shelf
human detection and depth estimation, (2) VLM-based reasoning to classify
pairwise social affiliation, and (3) a lightweight spatial aggregation
algorithm to localize socially connected groups. To support this task and
encourage future research, we present a new dataset of 100K urban street-view
images annotated with bounding boxes and labels for both individuals and
socially interacting groups. The annotations combine human-created labels and
outputs from the MINGLE pipeline, ensuring semantic richness and broad coverage
of real-world scenarios.

</details>


### [14] [BiasMap: Leveraging Cross-Attentions to Discover and Mitigate Hidden Social Biases in Text-to-Image Generation](https://arxiv.org/abs/2509.13496)
*Rajatsubhra Chakraborty,Xujun Che,Depeng Xu,Cori Faklaris,Xi Niu,Shuhan Yuan*

Main category: cs.CV

TL;DR: BiasMap是一个模型无关的框架，用于发现稳定扩散模型中的潜在概念级表示偏差，并通过能量引导扩散采样进行偏差缓解。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注输出级人口统计分布，无法保证概念表示的解耦，因此需要更深入的方法来揭示和缓解偏差。

Method: 利用交叉注意力属性图量化人口统计与语义概念的空间纠缠，并通过能量引导扩散采样直接修改潜在噪声空间。

Result: BiasMap能够揭示隐藏的偏差，并在图像生成中缓解概念纠缠，同时补充分布偏差缓解。

Conclusion: BiasMap提供了一种更深入的方法来发现和缓解生成模型中的概念级偏差，优于现有方法。

Abstract: Bias discovery is critical for black-box generative models, especiall
text-to-image (TTI) models. Existing works predominantly focus on output-level
demographic distributions, which do not necessarily guarantee concept
representations to be disentangled post-mitigation. We propose BiasMap, a
model-agnostic framework for uncovering latent concept-level representational
biases in stable diffusion models. BiasMap leverages cross-attention
attribution maps to reveal structural entanglements between demographics (e.g.,
gender, race) and semantics (e.g., professions), going deeper into
representational bias during the image generation. Using attribution maps of
these concepts, we quantify the spatial demographics-semantics concept
entanglement via Intersection over Union (IoU), offering a lens into bias that
remains hidden in existing fairness discovery approaches. In addition, we
further utilize BiasMap for bias mitigation through energy-guided diffusion
sampling that directly modifies latent noise space and minimizes the expected
SoftIoU during the denoising process. Our findings show that existing fairness
interventions may reduce the output distributional gap but often fail to
disentangle concept-level coupling, whereas our mitigation method can mitigate
concept entanglement in image generation while complementing distributional
bias mitigation.

</details>


### [15] [LivePyxel: Accelerating image annotations with a Python-integrated webcam live streaming](https://arxiv.org/abs/2509.13504)
*Uriel Garcilazo-Cruz,Joseph O. Okeme,Rodrigo A. Vargas--Hernández*

Main category: cs.CV

TL;DR: LivePyxel是一个基于Python的图形用户界面工具，支持实时图像标注，适用于实验室环境中的实时数据采集和AI模型开发。


<details>
  <summary>Details</summary>
Motivation: 现有图像标注工具需要预先上传数据集，不支持实时数据采集，限制了科学领域AI模型的部署。

Method: LivePyxel通过集成成像系统（如显微镜、摄像头）和提供易用界面（如Bézier曲线、二进制掩码）实现实时标注。

Result: LivePyxel支持高性能编辑、广泛设备兼容性，并优化了对象检测操作，加速了AI模型开发。

Conclusion: LivePyxel解决了实时标注的需求，为实验工作流中的AI模型开发提供了便利。

Abstract: The lack of flexible annotation tools has hindered the deployment of AI
models in some scientific areas. Most existing image annotation software
requires users to upload a precollected dataset, which limits support for
on-demand pipelines and introduces unnecessary steps to acquire images. This
constraint is particularly problematic in laboratory environments, where
real-time data acquisition from instruments such as microscopes is increasingly
common. In this work, we introduce \texttt{LivePixel}, a Python-based graphical
user interface that integrates with imaging systems, such as webcams,
microscopes, and others, to enable real-time image annotation. LivePyxel is
designed to be easy to use through a simple interface that allows users to
precisely delimit areas for annotation using tools commonly found in commercial
graphics editing software. Of particular interest is the availability of
B\'ezier splines and binary masks, and the software's capacity to work with
non-destructive layers that enable high-performance editing. LivePyxel also
integrates a wide compatibility across video devices, and it's optimized for
object detection operations via the use of OpenCV in combination with
high-performance libraries designed to handle matrix and linear algebra
operations via Numpy effectively. LivePyxel facilitates seamless data
collection and labeling, accelerating the development of AI models in
experimental workflows. LivePyxel freely available at
https://github.com/UGarCil/LivePyxel

</details>


### [16] [DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised H-Transform](https://arxiv.org/abs/2509.13506)
*Xingzi Xu,Qi Li,Shuwen Qiu,Julien Han,Karim Bouyarmane*

Main category: cs.CV

TL;DR: DEFT-VTON方法通过高效微调和自适应一致性损失，在虚拟试穿任务中实现高性能且低成本的训练和推理。


<details>
  <summary>Details</summary>
Motivation: 解决现有虚拟试穿方法因大规模预训练模型的高成本和低效率问题。

Method: 采用Doob's h-transform高效微调（DEFT）和自适应一致性损失，仅训练少量参数。

Result: DEFT-VTON在15步去噪步骤下达到SOTA性能，且训练参数仅占1.42%。

Conclusion: DEFT-VTON是一种高效且高性能的虚拟试穿解决方案。

Abstract: Diffusion models enable high-quality virtual try-on (VTO) with their
established image synthesis abilities. Despite the extensive end-to-end
training of large pre-trained models involved in current VTO methods,
real-world applications often prioritize limited training and inference,
serving, and deployment budgets for VTO. To solve this obstacle, we apply
Doob's h-transform efficient fine-tuning (DEFT) for adapting large pre-trained
unconditional models for downstream image-conditioned VTO abilities. DEFT
freezes the pre-trained model's parameters and trains a small h-transform
network to learn a conditional h-transform. The h-transform network allows
training only 1.42 percent of the frozen parameters, compared to a baseline of
5.52 percent in traditional parameter-efficient fine-tuning (PEFT).
  To further improve DEFT's performance and decrease existing models' inference
time, we additionally propose an adaptive consistency loss. Consistency
training distills slow but high-performing diffusion models into a fast one
while retaining performance by enforcing consistencies along the inference
path. Inspired by constrained optimization, instead of distillation, we combine
the consistency loss and the denoising score matching loss in a data-adaptive
manner for fine-tuning existing VTO models at a low cost. Empirical results
show the proposed DEFT-VTON method achieves state-of-the-art performance on VTO
tasks, with as few as 15 denoising steps, while maintaining competitive
results.

</details>


### [17] [Adversarial Appearance Learning in Augmented Cityscapes for Pedestrian Recognition in Autonomous Driving](https://arxiv.org/abs/2509.13507)
*Artem Savkin,Thomas Lapotre,Kevin Strauss,Uzair Akbar,Federico Tombari*

Main category: cs.CV

TL;DR: 论文提出了一种数据增强方法，通过生成虚拟行人改进行人识别，并设计了对抗学习网络以提升光照条件真实性。


<details>
  <summary>Details</summary>
Motivation: 合成数据在自动驾驶中至关重要，但存在合成与真实数据间的领域差距，需改进行人识别。

Method: 部署数据增强生成虚拟行人，提出对抗学习网络优化光照条件，并在Cityscapes数据集上评估。

Result: 方法在语义和实例分割任务中表现良好。

Conclusion: 数据增强和对抗学习网络有效提升了行人识别的真实性和性能。

Abstract: In the autonomous driving area synthetic data is crucial for cover specific
traffic scenarios which autonomous vehicle must handle. This data commonly
introduces domain gap between synthetic and real domains. In this paper we
deploy data augmentation to generate custom traffic scenarios with VRUs in
order to improve pedestrian recognition. We provide a pipeline for augmentation
of the Cityscapes dataset with virtual pedestrians. In order to improve
augmentation realism of the pipeline we reveal a novel generative network
architecture for adversarial learning of the data-set lighting conditions. We
also evaluate our approach on the tasks of semantic and instance segmentation.

</details>


### [18] [FunKAN: Functional Kolmogorov-Arnold Network for Medical Image Enhancement and Segmentation](https://arxiv.org/abs/2509.13508)
*Maksim Penkin,Andrey Krylov*

Main category: cs.CV

TL;DR: 提出了一种新型可解释神经网络FunKAN，用于医学图像增强和分割，优于传统KAN方法。


<details>
  <summary>Details</summary>
Motivation: 解决传统深度学习方法在医学图像处理中缺乏可解释性和破坏空间结构的问题。

Method: 基于Kolmogorov-Arnold定理，提出FunKAN框架，利用傅里叶分解和Hermite函数学习内部函数。

Result: 在多个医学数据集上验证，FunKAN在图像增强（PSNR、TV）和分割（IoU、F1）中表现优异。

Conclusion: FunKAN为医学图像分析提供了理论支持，兼具鲁棒性和可解释性。

Abstract: Medical image enhancement and segmentation are critical yet challenging tasks
in modern clinical practice, constrained by artifacts and complex anatomical
variations. Traditional deep learning approaches often rely on complex
architectures with limited interpretability. While Kolmogorov-Arnold networks
offer interpretable solutions, their reliance on flattened feature
representations fundamentally disrupts the intrinsic spatial structure of
imaging data. To address this issue we propose a Functional Kolmogorov-Arnold
Network (FunKAN) -- a novel interpretable neural framework, designed
specifically for image processing, that formally generalizes the
Kolmogorov-Arnold representation theorem onto functional spaces and learns
inner functions using Fourier decomposition over the basis Hermite functions.
We explore FunKAN on several medical image processing tasks, including Gibbs
ringing suppression in magnetic resonance images, benchmarking on IXI dataset.
We also propose U-FunKAN as state-of-the-art binary medical segmentation model
with benchmarks on three medical datasets: BUSI (ultrasound images), GlaS
(histological structures) and CVC-ClinicDB (colonoscopy videos), detecting
breast cancer, glands and polyps, respectively. Experiments on those diverse
datasets demonstrate that our approach outperforms other KAN-based backbones in
both medical image enhancement (PSNR, TV) and segmentation (IoU, F1). Our work
bridges the gap between theoretical function approximation and medical image
analysis, offering a robust, interpretable solution for clinical applications.

</details>


### [19] [Multimodal Hate Detection Using Dual-Stream Graph Neural Networks](https://arxiv.org/abs/2509.13515)
*Jiangbei Yue,Shuonan Yang,Tailin Chen,Jianbo Jiao,Zeyu Fu*

Main category: cs.CV

TL;DR: 提出了一种新型多模态双流图神经网络模型，用于仇恨视频分类，通过实例图和权重图突出仇恨内容，性能优越且可解释性强。


<details>
  <summary>Details</summary>
Motivation: 仇恨视频对在线安全和现实福祉构成严重威胁，现有方法忽视仇恨内容的重要性且无法系统捕获结构化信息。

Method: 构建实例图提取实例级特征，通过互补权重图分配重要性权重，结合两者生成视频标签。

Result: 在公开数据集上表现优异，达到最先进的分类效果，并具备强解释性。

Conclusion: 该模型有效解决了现有方法的局限性，为仇恨视频检测提供了新思路。

Abstract: Hateful videos present serious risks to online safety and real-world
well-being, necessitating effective detection methods. Although multimodal
classification approaches integrating information from several modalities
outperform unimodal ones, they typically neglect that even minimal hateful
content defines a video's category. Specifically, they generally treat all
content uniformly, instead of emphasizing the hateful components. Additionally,
existing multimodal methods cannot systematically capture structured
information in videos, limiting the effectiveness of multimodal fusion. To
address these limitations, we propose a novel multimodal dual-stream graph
neural network model. It constructs an instance graph by separating the given
video into several instances to extract instance-level features. Then, a
complementary weight graph assigns importance weights to these features,
highlighting hateful instances. Importance weights and instance features are
combined to generate video labels. Our model employs a graph-based framework to
systematically model structured relationships within and across modalities.
Extensive experiments on public datasets show that our model is
state-of-the-art in hateful video classification and has strong explainability.
Code is available:
https://github.com/Multimodal-Intelligence-Lab-MIL/MultiHateGNN.

</details>


### [20] [ColonCrafter: A Depth Estimation Model for Colonoscopy Videos Using Diffusion Priors](https://arxiv.org/abs/2509.13525)
*Romain Hardy,Tyler Berzin,Pranav Rajpurkar*

Main category: cs.CV

TL;DR: ColonCrafter是一种基于扩散模型的深度估计方法，用于生成结肠镜视频中时间一致的深度图，并在C3VD数据集上实现了零样本性能的领先。


<details>
  <summary>Details</summary>
Motivation: 结肠镜中的三维场景理解需要自动化方法进行准确的深度估计，但现有方法在视频序列中缺乏时间一致性。

Method: 通过从合成结肠镜序列学习几何先验，生成时间一致的深度图，并引入风格迁移技术适配真实临床视频。

Result: 在C3VD数据集上实现了零样本性能的领先，优于通用和结肠镜专用方法。

Conclusion: 尽管完整轨迹的三维重建仍是挑战，但ColonCrafter在临床应用中展示了潜力，如三维点云生成和表面覆盖评估。

Abstract: Three-dimensional (3D) scene understanding in colonoscopy presents
significant challenges that necessitate automated methods for accurate depth
estimation. However, existing depth estimation models for endoscopy struggle
with temporal consistency across video sequences, limiting their applicability
for 3D reconstruction. We present ColonCrafter, a diffusion-based depth
estimation model that generates temporally consistent depth maps from monocular
colonoscopy videos. Our approach learns robust geometric priors from synthetic
colonoscopy sequences to generate temporally consistent depth maps. We also
introduce a style transfer technique that preserves geometric structure while
adapting real clinical videos to match our synthetic training domain.
ColonCrafter achieves state-of-the-art zero-shot performance on the C3VD
dataset, outperforming both general-purpose and endoscopy-specific approaches.
Although full trajectory 3D reconstruction remains a challenge, we demonstrate
clinically relevant applications of ColonCrafter, including 3D point cloud
generation and surface coverage assessment.

</details>


### [21] [MemGS: Memory-Efficient Gaussian Splatting for Real-Time SLAM](https://arxiv.org/abs/2509.13536)
*Yinlong Bai,Hongxin Zhang,Sheng Zhong,Junkai Niu,Hai Li,Yijia He,Yi Zhou*

Main category: cs.CV

TL;DR: 论文提出了一种优化3D高斯泼溅（3DGS）的方法，通过合并冗余的高斯基元和使用Patch-Grid采样提升渲染质量和内存效率。


<details>
  <summary>Details</summary>
Motivation: 当前研究主要关注高性能桌面GPU的渲染和重建，忽略了嵌入式平台（如微型飞行器）的需求。这些设备资源有限，需要在性能和重建质量之间权衡。

Method: 提出在SLAM中基于几何相似性在体素空间合并冗余的3D高斯基元以减少GPU内存使用，并通过Patch-Grid点采样初始化高斯基元以提升渲染质量。

Result: 在公开数据集上的定量和定性评估表明，改进方法在减少内存使用的同时提升了渲染质量。

Conclusion: 该方法有效解决了嵌入式平台在3DGS应用中的资源限制问题，同时提升了渲染质量。

Abstract: Recent advancements in 3D Gaussian Splatting (3DGS) have made a significant
impact on rendering and reconstruction techniques. Current research
predominantly focuses on improving rendering performance and reconstruction
quality using high-performance desktop GPUs, largely overlooking applications
for embedded platforms like micro air vehicles (MAVs). These devices, with
their limited computational resources and memory, often face a trade-off
between system performance and reconstruction quality. In this paper, we
improve existing methods in terms of GPU memory usage while enhancing rendering
quality. Specifically, to address redundant 3D Gaussian primitives in SLAM, we
propose merging them in voxel space based on geometric similarity. This reduces
GPU memory usage without impacting system runtime performance. Furthermore,
rendering quality is improved by initializing 3D Gaussian primitives via
Patch-Grid (PG) point sampling, enabling more accurate modeling of the entire
scene. Quantitative and qualitative evaluations on publicly available datasets
demonstrate the effectiveness of our improvements.

</details>


### [22] [Dynamic Aware: Adaptive Multi-Mode Out-of-Distribution Detection for Trajectory Prediction in Autonomous Vehicles](https://arxiv.org/abs/2509.13577)
*Tongfei Guo,Lili Su*

Main category: cs.CV

TL;DR: 本文提出了一种新的轨迹预测OOD检测框架，通过自适应机制在复杂驾驶环境中实现鲁棒检测，显著提升了检测延迟和误报率。


<details>
  <summary>Details</summary>
Motivation: 轨迹预测在自动驾驶中至关重要，但现有模型在真实场景中面临分布偏移问题，尤其是轨迹级别的OOD检测研究较少。

Method: 通过建模预测误差的模式依赖性分布，引入自适应机制，优化检测性能。

Result: 在多个真实数据集上的实验表明，该方法在检测延迟和误报率上均优于现有UQ和基于视觉的OOD方法。

Conclusion: 该框架为自动驾驶提供了可靠且高效的轨迹预测OOD检测方案。

Abstract: Trajectory prediction is central to the safe and seamless operation of
autonomous vehicles (AVs). In deployment, however, prediction models inevitably
face distribution shifts between training data and real-world conditions, where
rare or underrepresented traffic scenarios induce out-of-distribution (OOD)
cases. While most prior OOD detection research in AVs has concentrated on
computer vision tasks such as object detection and segmentation,
trajectory-level OOD detection remains largely underexplored. A recent study
formulated this problem as a quickest change detection (QCD) task, providing
formal guarantees on the trade-off between detection delay and false alarms
[1]. Building on this foundation, we propose a new framework that introduces
adaptive mechanisms to achieve robust detection in complex driving
environments. Empirical analysis across multiple real-world datasets reveals
that prediction errors -- even on in-distribution samples -- exhibit
mode-dependent distributions that evolve over time with dataset-specific
dynamics. By explicitly modeling these error modes, our method achieves
substantial improvements in both detection delay and false alarm rates.
Comprehensive experiments on established trajectory prediction benchmarks show
that our framework significantly outperforms prior UQ- and vision-based OOD
approaches in both accuracy and computational efficiency, offering a practical
path toward reliable, driving-aware autonomy.

</details>


### [23] [Annotating Satellite Images of Forests with Keywords from a Specialized Corpus in the Context of Change Detection](https://arxiv.org/abs/2509.13586)
*Nathalie Neptune,Josiane Mothe*

Main category: cs.CV

TL;DR: 论文提出了一种基于深度学习的亚马逊雨林砍伐检测方法，通过卫星图像对比和视觉语义模型生成相关注释。


<details>
  <summary>Details</summary>
Motivation: 亚马逊雨林砍伐对全球碳排放和生物多样性有重大影响，需要有效监测工具。

Method: 利用深度学习技术对比不同时间点的卫星图像，结合视觉语义模型自动生成注释。

Result: 在亚马逊图像数据集上验证了方法的有效性，能准确检测砍伐并生成相关注释。

Conclusion: 该方法为监测亚马逊砍伐提供了实用工具，且可推广至其他领域。

Abstract: The Amazon rain forest is a vital ecosystem that plays a crucial role in
regulating the Earth's climate and providing habitat for countless species.
Deforestation in the Amazon is a major concern as it has a significant impact
on global carbon emissions and biodiversity. In this paper, we present a method
for detecting deforestation in the Amazon using image pairs from Earth
observation satellites. Our method leverages deep learning techniques to
compare the images of the same area at different dates and identify changes in
the forest cover. We also propose a visual semantic model that automatically
annotates the detected changes with relevant keywords. The candidate annotation
for images are extracted from scientific documents related to the Amazon
region. We evaluate our approach on a dataset of Amazon image pairs and
demonstrate its effectiveness in detecting deforestation and generating
relevant annotations. Our method provides a useful tool for monitoring and
studying the impact of deforestation in the Amazon. While we focus on
environment applications of our work by using images of deforestation in the
Amazon rain forest to demonstrate the effectiveness of our proposed approach,
it is generic enough to be applied to other domains.

</details>


### [24] [Intelligent Healthcare Imaging Platform An VLM-Based Framework for Automated Medical Image Analysis and Clinical Report Generation](https://arxiv.org/abs/2509.13590)
*Samer Al-Hamadani*

Main category: cs.CV

TL;DR: 提出了一种基于视觉语言模型（VLM）的多模态医疗图像分析框架，结合Google Gemini 2.5 Flash实现肿瘤检测和临床报告生成，支持CT、MRI、X-ray和超声等多种成像模态。


<details>
  <summary>Details</summary>
Motivation: 医疗影像AI的快速发展推动了诊断医学和临床决策的革新，但现有系统在跨模态分析和上下文理解方面仍有不足。

Method: 结合视觉特征提取与自然语言处理，引入坐标验证机制和高斯概率建模，通过多层级可视化技术增强临床信心。

Result: 在多种成像模态中表现出高性能的异常检测能力，位置测量平均偏差为80像素。

Conclusion: 该框架显著提升了自动化诊断支持和放射工作流效率，但需进一步临床验证和多中心评估。

Abstract: The rapid advancement of artificial intelligence (AI) in healthcare imaging
has revolutionized diagnostic medicine and clinical decision-making processes.
This work presents an intelligent multimodal framework for medical image
analysis that leverages Vision-Language Models (VLMs) in healthcare
diagnostics. The framework integrates Google Gemini 2.5 Flash for automated
tumor detection and clinical report generation across multiple imaging
modalities including CT, MRI, X-ray, and Ultrasound. The system combines visual
feature extraction with natural language processing to enable contextual image
interpretation, incorporating coordinate verification mechanisms and
probabilistic Gaussian modeling for anomaly distribution. Multi-layered
visualization techniques generate detailed medical illustrations, overlay
comparisons, and statistical representations to enhance clinical confidence,
with location measurement achieving 80 pixels average deviation. Result
processing utilizes precise prompt engineering and textual analysis to extract
structured clinical information while maintaining interpretability.
Experimental evaluations demonstrated high performance in anomaly detection
across multiple modalities. The system features a user-friendly Gradio
interface for clinical workflow integration and demonstrates zero-shot learning
capabilities to reduce dependence on large datasets. This framework represents
a significant advancement in automated diagnostic support and radiological
workflow efficiency, though clinical validation and multi-center evaluation are
necessary prior to widespread adoption.

</details>


### [25] [A Generalization of CLAP from 3D Localization to Image Processing, A Connection With RANSAC & Hough Transforms](https://arxiv.org/abs/2509.13605)
*Ruochen Hou,Gabriel I. Fernandez,Alex Xu,Dennis W. Hong*

Main category: cs.CV

TL;DR: CLAP算法从2D定位扩展到3D定位和图像拼接，展示了其与RANSAC和Hough变换的关系，适用于处理噪声和不确定性。


<details>
  <summary>Details</summary>
Motivation: 扩展CLAP算法以应对更广泛的定位和图像处理需求，尤其是在噪声和异常值较多的场景。

Method: 通过聚类策略抑制噪声和错误特征匹配，替代传统异常值剔除方法如RANSAC。

Result: CLAP在3D定位和图像拼接中表现优异，展示了其通用性和鲁棒性。

Conclusion: CLAP的扩展框架为多领域提供了处理噪声和不确定性的有效工具。

Abstract: In previous work, we introduced a 2D localization algorithm called CLAP,
Clustering to Localize Across $n$ Possibilities, which was used during our
championship win in RoboCup 2024, an international autonomous humanoid soccer
competition. CLAP is particularly recognized for its robustness against
outliers, where clustering is employed to suppress noise and mitigate against
erroneous feature matches. This clustering-based strategy provides an
alternative to traditional outlier rejection schemes such as RANSAC, in which
candidates are validated by reprojection error across all data points. In this
paper, CLAP is extended to a more general framework beyond 2D localization,
specifically to 3D localization and image stitching. We also show how CLAP,
RANSAC, and Hough transforms are related. The generalization of CLAP is widely
applicable to many different fields and can be a useful tool to deal with noise
and uncertainty.

</details>


### [26] [SAMIR, an efficient registration framework via robust feature learning from SAM](https://arxiv.org/abs/2509.13629)
*Yue He,Min Liu,Qinghao Liu,Jiazheng Wang,Yaonan Wang,Hang Zhang,Xiang Chen*

Main category: cs.CV

TL;DR: SAMIR利用Segment Anything Model（SAM）增强医学图像配准，通过结构感知特征嵌入和分层特征一致性损失，显著提升了配准精度。


<details>
  <summary>Details</summary>
Motivation: 医学图像配准中，弱监督方法依赖难以获取的解剖先验（如分割掩码或标记），限制了实际应用。SAMIR利用视觉基础模型的强大表示学习能力，克服了这一限制。

Method: 设计任务特定的适应管道，利用SAM的图像编码器提取结构感知特征嵌入，并引入轻量级3D头部和分层特征一致性损失优化特征匹配。

Result: 在心脏和腹部CT图像配准任务中，SAMIR分别比现有方法提升了2.68%和6.44%的性能。

Conclusion: SAMIR通过结合SAM的通用视觉表示和任务特定优化，显著提升了医学图像配准的准确性和实用性。

Abstract: Image registration is a fundamental task in medical image analysis.
Deformations are often closely related to the morphological characteristics of
tissues, making accurate feature extraction crucial. Recent weakly supervised
methods improve registration by incorporating anatomical priors such as
segmentation masks or landmarks, either as inputs or in the loss function.
However, such weak labels are often not readily available, limiting their
practical use. Motivated by the strong representation learning ability of
visual foundation models, this paper introduces SAMIR, an efficient medical
image registration framework that utilizes the Segment Anything Model (SAM) to
enhance feature extraction. SAM is pretrained on large-scale natural image
datasets and can learn robust, general-purpose visual representations. Rather
than using raw input images, we design a task-specific adaptation pipeline
using SAM's image encoder to extract structure-aware feature embeddings,
enabling more accurate modeling of anatomical consistency and deformation
patterns. We further design a lightweight 3D head to refine features within the
embedding space, adapting to local deformations in medical images.
Additionally, we introduce a Hierarchical Feature Consistency Loss to guide
coarse-to-fine feature matching and improve anatomical alignment. Extensive
experiments demonstrate that SAMIR significantly outperforms state-of-the-art
methods on benchmark datasets for both intra-subject cardiac image registration
and inter-subject abdomen CT image registration, achieving performance
improvements of 2.68% on ACDC and 6.44% on the abdomen dataset. The source code
will be publicly available on GitHub following the acceptance of this paper.

</details>


### [27] [Federated Learning for Deforestation Detection: A Distributed Approach with Satellite Imagery](https://arxiv.org/abs/2509.13631)
*Yuvraj Dutta,Aaditya Sikder,Basabdatta Palit*

Main category: cs.CV

TL;DR: 论文提出了一种基于联邦学习（FL）的分布式方法，用于从卫星图像中准确识别和定位森林砍伐，同时保护用户数据隐私。


<details>
  <summary>Details</summary>
Motivation: 传统集中式训练方法需要合并数据，可能危及数据安全，而联邦学习可以在分布式网络中协作训练模型，同时保护数据隐私。

Method: 利用FLOWER和RAY框架实现分布式学习，采用YOLOS-small、Faster R-CNN（ResNet50和MobileNetV3）模型在公开数据集上训练和测试。

Result: 该方法为卫星图像的图像分割任务提供了新视角，同时确保了数据安全和高效性。

Conclusion: 联邦学习框架在卫星图像分析中具有潜力，能够平衡数据隐私与模型性能。

Abstract: Accurate identification of deforestation from satellite images is essential
in order to understand the geographical situation of an area. This paper
introduces a new distributed approach to identify as well as locate
deforestation across different clients using Federated Learning (FL). Federated
Learning enables distributed network clients to collaboratively train a model
while maintaining data privacy and security of the active users. In our
framework, a client corresponds to an edge satellite center responsible for
local data processing. Moreover, FL provides an advantage over centralized
training method which requires combining data, thereby compromising with data
security of the clients. Our framework leverages the FLOWER framework with RAY
framework to execute the distributed learning workload. Furthermore, efficient
client spawning is ensured by RAY as it can select definite amount of users to
create an emulation environment. Our FL framework uses YOLOS-small (a Vision
Transformer variant), Faster R-CNN with a ResNet50 backbone, and Faster R-CNN
with a MobileNetV3 backbone models trained and tested on publicly available
datasets. Our approach provides us a different view for image
segmentation-based tasks on satellite imagery.

</details>


### [28] [Gaussian Alignment for Relative Camera Pose Estimation via Single-View Reconstruction](https://arxiv.org/abs/2509.13652)
*Yumin Li,Dylan Campbell*

Main category: cs.CV

TL;DR: GARPS是一种无需训练的方法，通过直接对齐两个独立重建的3D场景，实现度量相对相机姿态估计。


<details>
  <summary>Details</summary>
Motivation: 传统两视图姿态估计方法无法度量相机平移尺度，且在宽基线和纹理缺失或反射表面表现不佳。

Method: 利用度量单目深度估计器和高斯场景重建器生成3D高斯混合模型（GMM），通过优化可微GMM对齐目标来细化初始姿态。

Result: 在Real-Estate10K数据集上，GARPS优于经典和基于学习的最新方法（如MASt3R）。

Conclusion: 结合单视图感知与多视图几何，可实现鲁棒且度量的相对姿态估计。

Abstract: Estimating metric relative camera pose from a pair of images is of great
importance for 3D reconstruction and localisation. However, conventional
two-view pose estimation methods are not metric, with camera translation known
only up to a scale, and struggle with wide baselines and textureless or
reflective surfaces. This paper introduces GARPS, a training-free framework
that casts this problem as the direct alignment of two independently
reconstructed 3D scenes. GARPS leverages a metric monocular depth estimator and
a Gaussian scene reconstructor to obtain a metric 3D Gaussian Mixture Model
(GMM) for each image. It then refines an initial pose from a feed-forward
two-view pose estimator by optimising a differentiable GMM alignment objective.
This objective jointly considers geometric structure, view-independent colour,
anisotropic covariance, and semantic feature consistency, and is robust to
occlusions and texture-poor regions without requiring explicit 2D
correspondences. Extensive experiments on the Real\-Estate10K dataset
demonstrate that GARPS outperforms both classical and state-of-the-art
learning-based methods, including MASt3R. These results highlight the potential
of bridging single-view perception with multi-view geometry to achieve robust
and metric relative pose estimation.

</details>


### [29] [Deep Lookup Network](https://arxiv.org/abs/2509.13662)
*Yulan Guo,Longguang Wang,Wendong Mao,Xiaoyu Dong,Yingqian Wang,Li Liu,Wei An*

Main category: cs.CV

TL;DR: 提出了一种通用的查找操作替代乘法运算，以降低卷积神经网络的计算复杂度和能耗，适用于资源受限的边缘设备。


<details>
  <summary>Details</summary>
Motivation: 乘法运算在卷积神经网络中计算复杂度高、能耗大，限制了在移动设备上的部署。通过查找表简化计算可以降低成本。

Method: 引入可微分的查找表操作替代乘法运算，并提出多种训练策略以优化查找表的收敛性。

Result: 在图像分类、超分辨率和点云分类任务中，查找网络在保持性能的同时显著提升了效率和速度。

Conclusion: 查找网络在不同任务和数据类型上均表现出色，验证了其高效性和通用性。

Abstract: Convolutional neural networks are constructed with massive operations with
different types and are highly computationally intensive. Among these
operations, multiplication operation is higher in computational complexity and
usually requires {more} energy consumption with longer inference time than
other operations, which hinders the deployment of convolutional neural networks
on mobile devices. In many resource-limited edge devices, complicated
operations can be calculated via lookup tables to reduce computational cost.
Motivated by this, in this paper, we introduce a generic and efficient lookup
operation which can be used as a basic operation for the construction of neural
networks. Instead of calculating the multiplication of weights and activation
values, simple yet efficient lookup operations are adopted to compute their
responses. To enable end-to-end optimization of the lookup operation, we
construct the lookup tables in a differentiable manner and propose several
training strategies to promote their convergence. By replacing computationally
expensive multiplication operations with our lookup operations, we develop
lookup networks for the image classification, image super-resolution, and point
cloud classification tasks. It is demonstrated that our lookup networks can
benefit from the lookup operations to achieve higher efficiency in terms of
energy consumption and inference speed while maintaining competitive
performance to vanilla convolutional networks. Extensive experiments show that
our lookup networks produce state-of-the-art performance on different tasks
(both classification and regression tasks) and different data types (both
images and point clouds).

</details>


### [30] [Re-purposing SAM into Efficient Visual Projectors for MLLM-Based Referring Image Segmentation](https://arxiv.org/abs/2509.13676)
*Xiaobo Yang,Xiaojin Gong*

Main category: cs.CV

TL;DR: 提出了一种基于语义超像素的视觉投影器，显著减少了视觉令牌数量，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法在减少视觉令牌数量与保持语义清晰之间难以平衡，导致计算开销大。

Method: 利用SAM生成语义超像素作为视觉单词，结合位置嵌入和聚合器以减少语义损失。

Result: 视觉令牌减少93%，训练和推理速度提升，性能优于现有方法。

Conclusion: 新方法在RIS任务中高效且性能优越。

Abstract: Recently, Referring Image Segmentation (RIS) frameworks that pair the
Multimodal Large Language Model (MLLM) with the Segment Anything Model (SAM)
have achieved impressive results. However, adapting MLLM to segmentation is
computationally intensive, primarily due to visual token redundancy. We observe
that traditional patch-wise visual projectors struggle to strike a balance
between reducing the number of visual tokens and preserving semantic clarity,
often retaining overly long token sequences to avoid performance drops.
Inspired by text tokenizers, we propose a novel semantic visual projector that
leverages semantic superpixels generated by SAM to identify "visual words" in
an image. By compressing and projecting semantic superpixels as visual tokens,
our approach adaptively shortens the token sequence according to scene
complexity while minimizing semantic loss in compression. To mitigate loss of
information, we propose a semantic superpixel positional embedding to
strengthen MLLM's awareness of superpixel geometry and position, alongside a
semantic superpixel aggregator to preserve both fine-grained details inside
superpixels and global context outside. Experiments show that our method cuts
visual tokens by 93% without compromising performance, notably speeding up MLLM
training and inference, and outperforming existing compressive visual
projectors on RIS.

</details>


### [31] [FishBEV: Distortion-Resilient Bird's Eye View Segmentation with Surround-View Fisheye Cameras](https://arxiv.org/abs/2509.13681)
*Hang Li,Dianmo Sheng,Qiankun Dong,Zichun Wang,Zhiwei Xu,Tao Li*

Main category: cs.CV

TL;DR: FishBEV是一个针对鱼眼相机设计的BEV分割框架，通过三个创新模块解决了鱼眼相机的几何失真、多视图对应模糊和时序不稳定问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 鱼眼相机在BEV分割中存在几何失真、多视图对应模糊和时序不稳定等问题，现有方法难以直接应用，因此需要专门设计的解决方案。

Method: FishBEV框架包含三个模块：DRME（抗失真多尺度特征提取）、U-SCA（不确定性感知空间交叉注意力）和D-TSA（距离感知时序自注意力）。

Result: 在Synwoodscapes数据集上，FishBEV显著优于现有方法，证明了其在鱼眼相机BEV分割任务中的优越性。

Conclusion: FishBEV通过针对鱼眼相机的专门设计，有效解决了BEV分割中的关键挑战，为自动驾驶提供了更可靠的视觉感知方案。

Abstract: As a cornerstone technique for autonomous driving, Bird's Eye View (BEV)
segmentation has recently achieved remarkable progress with pinhole cameras.
However, it is non-trivial to extend the existing methods to fisheye cameras
with severe geometric distortion, ambiguous multi-view correspondences and
unstable temporal dynamics, all of which significantly degrade BEV performance.
To address these challenges, we propose FishBEV, a novel BEV segmentation
framework specifically tailored for fisheye cameras. This framework introduces
three complementary innovations, including a Distortion-Resilient Multi-scale
Extraction (DRME) backbone that learns robust features under distortion while
preserving scale consistency, an Uncertainty-aware Spatial Cross-Attention
(U-SCA) mechanism that leverages uncertainty estimation for reliable cross-view
alignment, a Distance-aware Temporal Self-Attention (D-TSA) module that
adaptively balances near field details and far field context to ensure temporal
coherence. Extensive experiments on the Synwoodscapes dataset demonstrate that
FishBEV consistently outperforms SOTA baselines, regarding the performance
evaluation of FishBEV on the surround-view fisheye BEV segmentation tasks.

</details>


### [32] [Taylor-Series Expanded Kolmogorov-Arnold Network for Medical Imaging Classification](https://arxiv.org/abs/2509.13687)
*Kaniz Fatema,Emad A. Mohammed,Sukhjit Singh Sehra*

Main category: cs.CV

TL;DR: 该研究提出了一种基于样条的Kolmogorov-Arnold网络（KANs）用于医学图像分类，在资源有限的情况下表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像分类在资源有限环境中的准确性和可解释性问题。

Method: 开发了三种基于样条的KAN模型（SBTAYLOR-KAN、SBRBF-KAN、SBWAVELET-KAN），结合B样条与其他函数逼近方法。

Result: SBTAYLOR-KAN在多个数据集上表现优异，最高准确率达98.93%，且参数数量远少于传统CNN。

Conclusion: 该框架为医学图像分类提供了轻量级、可解释且泛化能力强的解决方案。

Abstract: Effective and interpretable classification of medical images is a challenge
in computer-aided diagnosis, especially in resource-limited clinical settings.
This study introduces spline-based Kolmogorov-Arnold Networks (KANs) for
accurate medical image classification with limited, diverse datasets. The
models include SBTAYLOR-KAN, integrating B-splines with Taylor series;
SBRBF-KAN, combining B-splines with Radial Basis Functions; and SBWAVELET-KAN,
embedding B-splines in Morlet wavelet transforms. These approaches leverage
spline-based function approximation to capture both local and global
nonlinearities. The models were evaluated on brain MRI, chest X-rays,
tuberculosis X-rays, and skin lesion images without preprocessing,
demonstrating the ability to learn directly from raw data. Extensive
experiments, including cross-dataset validation and data reduction analysis,
showed strong generalization and stability. SBTAYLOR-KAN achieved up to 98.93%
accuracy, with a balanced F1-score, maintaining over 86% accuracy using only
30% of the training data across three datasets. Despite class imbalance in the
skin cancer dataset, experiments on both imbalanced and balanced versions
showed SBTAYLOR-KAN outperforming other models, achieving 68.22% accuracy.
Unlike traditional CNNs, which require millions of parameters (e.g., ResNet50
with 24.18M), SBTAYLOR-KAN achieves comparable performance with just 2,872
trainable parameters, making it more suitable for constrained medical
environments. Gradient-weighted Class Activation Mapping (Grad-CAM) was used
for interpretability, highlighting relevant regions in medical images. This
framework provides a lightweight, interpretable, and generalizable solution for
medical image classification, addressing the challenges of limited datasets and
data-scarce scenarios in clinical AI applications.

</details>


### [33] [StyleProtect: Safeguarding Artistic Identity in Fine-tuned Diffusion Models](https://arxiv.org/abs/2509.13711)
*Qiuyu Tang,Joshua Krinsky,Aparna Bharati*

Main category: cs.CV

TL;DR: 论文提出了一种轻量级保护策略StyleProtect，通过更新特定的交叉注意力层，有效防御针对艺术风格的恶意扩散模型模仿。


<details>
  <summary>Details</summary>
Motivation: 生成模型（尤其是扩散模型）的快速发展可能被滥用，导致艺术家的独特风格被低成本复制，因此需要保护艺术作品免受风格模仿。

Method: 研究发现某些交叉注意力层对艺术风格敏感，基于此提出StyleProtect策略，仅更新选定的交叉注意力层以实现高效保护。

Result: 实验表明，StyleProtect在保护艺术作品和动漫独特风格方面表现优异，同时保持不易察觉性。

Conclusion: StyleProtect是一种高效且轻量级的风格保护方法，能有效对抗恶意扩散模型的风格模仿。

Abstract: The rapid advancement of generative models, particularly diffusion-based
approaches, has inadvertently facilitated their potential for misuse. Such
models enable malicious exploiters to replicate artistic styles that capture an
artist's creative labor, personal vision, and years of dedication in an
inexpensive manner. This has led to a rise in the need and exploration of
methods for protecting artworks against style mimicry. Although generic
diffusion models can easily mimic an artistic style, finetuning amplifies this
capability, enabling the model to internalize and reproduce the style with
higher fidelity and control. We hypothesize that certain cross-attention layers
exhibit heightened sensitivity to artistic styles. Sensitivity is measured
through activation strengths of attention layers in response to style and
content representations, and assessing their correlations with features
extracted from external models. Based on our findings, we introduce an
efficient and lightweight protection strategy, StyleProtect, that achieves
effective style defense against fine-tuned diffusion models by updating only
selected cross-attention layers. Our experiments utilize a carefully curated
artwork dataset based on WikiArt, comprising representative works from 30
artists known for their distinctive and influential styles and cartoon
animations from the Anita dataset. The proposed method demonstrates promising
performance in safeguarding unique styles of artworks and anime from malicious
diffusion customization, while maintaining competitive imperceptibility.

</details>


### [34] [UM-Depth : Uncertainty Masked Self-Supervised Monocular Depth Estimation with Visual Odometry](https://arxiv.org/abs/2509.13713)
*Tae-Wook Um,Ki-Hyeon Kim,Hyun-Duck Choi,Hyo-Sung Ahn*

Main category: cs.CV

TL;DR: UM-Depth框架通过结合运动和不确定性感知的细化，提升了单目深度估计在动态物体边界和低纹理区域的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决自监督单目深度估计中因输入数据不确定性（如低纹理或动态区域）导致的深度精度下降问题。

Method: 采用师生训练策略，将不确定性估计嵌入训练流程和网络架构，利用光流仅在教师网络中进行训练。

Result: 在KITTI和Cityscapes数据集上验证了不确定性感知细化的有效性，并在KITTI数据集上实现了自监督深度和姿态估计的最先进结果。

Conclusion: UM-Depth通过不确定性感知细化显著提升了深度估计的准确性，且无需额外标签或运行时开销。

Abstract: Monocular depth estimation has been increasingly adopted in robotics and
autonomous driving for its ability to infer scene geometry from a single
camera. In self-supervised monocular depth estimation frameworks, the network
jointly generates and exploits depth and pose estimates during training,
thereby eliminating the need for depth labels. However, these methods remain
challenged by uncertainty in the input data, such as low-texture or dynamic
regions, which can cause reduced depth accuracy. To address this, we introduce
UM-Depth, a framework that combines motion- and uncertainty-aware refinement to
enhance depth accuracy at dynamic object boundaries and in textureless regions.
Specifically, we develop a teacherstudent training strategy that embeds
uncertainty estimation into both the training pipeline and network
architecture, thereby strengthening supervision where photometric signals are
weak. Unlike prior motion-aware approaches that incur inference-time overhead
and rely on additional labels or auxiliary networks for real-time generation,
our method uses optical flow exclusively within the teacher network during
training, which eliminating extra labeling demands and any runtime cost.
Extensive experiments on the KITTI and Cityscapes datasets demonstrate the
effectiveness of our uncertainty-aware refinement. Overall, UM-Depth achieves
state-of-the-art results in both self-supervised depth and pose estimation on
the KITTI datasets.

</details>


### [35] [Mitigating Query Selection Bias in Referring Video Object Segmentation](https://arxiv.org/abs/2509.13722)
*Dingwei Zhang,Dong Zhang,Jinhui Tang*

Main category: cs.CV

TL;DR: 论文提出Triple Query Former (TQF)，通过将查询分解为三个专门组件来解决查询选择偏差问题，并引入运动感知聚合模块提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于查询的方法在Referring Video Object Segmentation (RVOS)中因静态查询易受干扰而表现不佳，需解决查询选择偏差问题。

Method: TQF将查询分解为外观查询、帧内交互查询和帧间运动查询，并引入帧内交互聚合和帧间运动聚合模块。

Result: 在多个RVOS基准测试中表现优异，验证了结构化查询设计和运动感知模块的有效性。

Conclusion: TQF通过动态查询构建和运动感知聚合显著提升了RVOS性能。

Abstract: Recently, query-based methods have achieved remarkable performance in
Referring Video Object Segmentation (RVOS) by using textual static object
queries to drive cross-modal alignment. However, these static queries are
easily misled by distractors with similar appearance or motion, resulting in
\emph{query selection bias}. To address this issue, we propose Triple Query
Former (TQF), which factorizes the referring query into three specialized
components: an appearance query for static attributes, an intra-frame
interaction query for spatial relations, and an inter-frame motion query for
temporal association. Instead of relying solely on textual embeddings, our
queries are dynamically constructed by integrating both linguistic cues and
visual guidance. Furthermore, we introduce two motion-aware aggregation modules
that enhance object token representations: Intra-frame Interaction Aggregation
incorporates position-aware interactions among objects within a single frame,
while Inter-frame Motion Aggregation leverages trajectory-guided alignment
across frames to ensure temporal coherence. Extensive experiments on multiple
RVOS benchmarks demonstrate the advantages of TQF and the effectiveness of our
structured query design and motion-aware aggregation modules.

</details>


### [36] [Improving Generalized Visual Grounding with Instance-aware Joint Learning](https://arxiv.org/abs/2509.13747)
*Ming Dai,Wenxuan Cheng,Jiang-Jiang Liu,Lingfeng Yang,Zhenhua Feng,Wankou Yang,Jingdong Wang*

Main category: cs.CV

TL;DR: InstanceVG是一个多任务广义视觉定位框架，通过实例查询统一实例级框和掩码的联合预测，显著提升了GREC和GRES任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常独立处理GREC和GRES任务，忽略了联合训练的优势，且GRES任务中缺乏实例感知能力。

Method: 提出InstanceVG框架，利用实例查询统一实例级框和掩码的预测，并为每个查询分配先验参考点以增强一致性。

Result: 在四个任务的十个数据集上，InstanceVG表现优异，显著超越现有方法。

Conclusion: InstanceVG是首个同时处理GREC和GRES并融入实例感知能力的框架，实验证明了其优越性。

Abstract: Generalized visual grounding tasks, including Generalized Referring
Expression Comprehension (GREC) and Segmentation (GRES), extend the classical
visual grounding paradigm by accommodating multi-target and non-target
scenarios. Specifically, GREC focuses on accurately identifying all referential
objects at the coarse bounding box level, while GRES aims for achieve
fine-grained pixel-level perception. However, existing approaches typically
treat these tasks independently, overlooking the benefits of jointly training
GREC and GRES to ensure consistent multi-granularity predictions and streamline
the overall process. Moreover, current methods often treat GRES as a semantic
segmentation task, neglecting the crucial role of instance-aware capabilities
and the necessity of ensuring consistent predictions between instance-level
boxes and masks. To address these limitations, we propose InstanceVG, a
multi-task generalized visual grounding framework equipped with instance-aware
capabilities, which leverages instance queries to unify the joint and
consistency predictions of instance-level boxes and masks. To the best of our
knowledge, InstanceVG is the first framework to simultaneously tackle both GREC
and GRES while incorporating instance-aware capabilities into generalized
visual grounding. To instantiate the framework, we assign each instance query a
prior reference point, which also serves as an additional basis for target
matching. This design facilitates consistent predictions of points, boxes, and
masks for the same instance. Extensive experiments obtained on ten datasets
across four tasks demonstrate that InstanceVG achieves state-of-the-art
performance, significantly surpassing the existing methods in various
evaluation metrics. The code and model will be publicly available at
https://github.com/Dmmm1997/InstanceVG.

</details>


### [37] [Cross-modal Full-mode Fine-grained Alignment for Text-to-Image Person Retrieval](https://arxiv.org/abs/2509.13754)
*Hao Yin,Xin Man,Feiyu Chen,Jie Shao,Heng Tao Shen*

Main category: cs.CV

TL;DR: FMFA框架通过显式细粒度对齐和隐式关系推理提升跨模态匹配性能，解决了局部特征对齐验证不足和正负样本对优化不平衡的问题。


<details>
  <summary>Details</summary>
Motivation: 解决文本-图像跨模态匹配中局部特征对齐验证不足和正负样本对优化不平衡的挑战。

Method: 提出FMFA框架，包含自适应相似性分布匹配（A-SDM）模块和显式细粒度对齐（EFA）模块，分别优化全局对齐和局部验证。

Result: 在三个公开数据集上达到全局匹配方法中的最优性能。

Conclusion: FMFA通过全模式对齐显著提升了跨模态匹配效果，无需额外监督。

Abstract: Text-to-Image Person Retrieval (TIPR) is a cross-modal matching task that
aims to retrieve the most relevant person images based on a given text query.
The key challenge in TIPR lies in achieving effective alignment between textual
and visual modalities within a common latent space. To address this challenge,
prior approaches incorporate attention mechanisms for implicit cross-modal
local alignment. However, they lack the ability to verify whether all local
features are correctly aligned. Moreover, existing methods primarily focus on
hard negative samples during model updates, with the goal of refining
distinctions between positive and negative pairs, often neglecting incorrectly
matched positive pairs. To alleviate these issues, we propose FMFA, a
cross-modal Full-Mode Fine-grained Alignment framework, which enhances global
matching through explicit fine-grained alignment and existing implicit
relational reasoning -- hence the term ``full-mode" -- without requiring
additional supervision. Specifically, we design an Adaptive Similarity
Distribution Matching (A-SDM) module to rectify unmatched positive sample
pairs. A-SDM adaptively pulls the unmatched positive pairs closer in the joint
embedding space, thereby achieving more precise global alignment. Additionally,
we introduce an Explicit Fine-grained Alignment (EFA) module, which makes up
for the lack of verification capability of implicit relational reasoning. EFA
strengthens explicit cross-modal fine-grained interactions by sparsifying the
similarity matrix and employs a hard coding method for local alignment. Our
proposed method is evaluated on three public datasets, achieving
state-of-the-art performance among all global matching methods. Our code is
available at https://github.com/yinhao1102/FMFA.

</details>


### [38] [Controllable-Continuous Color Editing in Diffusion Model via Color Mapping](https://arxiv.org/abs/2509.13756)
*Yuqi Yang,Dongliang Chang,Yuanchen Fang,Yi-Zhe SonG,Zhanyu Ma,Jun Guo*

Main category: cs.CV

TL;DR: 提出了一种颜色映射模块，通过建模文本嵌入空间与图像RGB值的对应关系，实现精确且连续的颜色编辑。


<details>
  <summary>Details</summary>
Motivation: 自然语言的模糊性和离散性导致颜色编辑精度不足且难以连续控制，现有方法缺乏对颜色变化范围和关系的精确控制。

Method: 引入颜色映射模块，预测给定RGB值对应的嵌入向量，实现精确颜色控制并保持语义一致性。

Result: 实验表明，该方法在颜色连续性和可控性方面表现良好。

Conclusion: 该方法实现了更细粒度、连续且可控的颜色编辑，解决了现有技术的局限性。

Abstract: In recent years, text-driven image editing has made significant progress.
However, due to the inherent ambiguity and discreteness of natural language,
color editing still faces challenges such as insufficient precision and
difficulty in achieving continuous control. Although linearly interpolating the
embedding vectors of different textual descriptions can guide the model to
generate a sequence of images with varying colors, this approach lacks precise
control over the range of color changes in the output images. Moreover, the
relationship between the interpolation coefficient and the resulting image
color is unknown and uncontrollable. To address these issues, we introduce a
color mapping module that explicitly models the correspondence between the text
embedding space and image RGB values. This module predicts the corresponding
embedding vector based on a given RGB value, enabling precise color control of
the generated images while maintaining semantic consistency. Users can specify
a target RGB range to generate images with continuous color variations within
the desired range, thereby achieving finer-grained, continuous, and
controllable color editing. Experimental results demonstrate that our method
performs well in terms of color continuity and controllability.

</details>


### [39] [Iterative Prompt Refinement for Safer Text-to-Image Generation](https://arxiv.org/abs/2509.13760)
*Jinwoo Jeon,JunHyeok Oh,Hayeong Lee,Byung-Jun Lee*

Main category: cs.CV

TL;DR: 提出了一种基于视觉反馈的迭代提示优化算法，结合视觉语言模型（VLM）分析提示和生成图像，提升文本到图像（T2I）模型的安全性和输出质量。


<details>
  <summary>Details</summary>
Motivation: 现有安全方法依赖大型语言模型（LLM）优化提示，但忽略了生成图像的安全性，可能导致不安全输出或过度修改安全提示。

Method: 使用视觉语言模型（VLM）迭代分析提示和生成图像，通过视觉反馈优化提示，同时引入新数据集进行监督微调。

Result: 实验表明，该方法在保持用户意图对齐的同时，显著提升了生成图像的安全性。

Conclusion: 结合视觉反馈的提示优化方法为生成更安全的T2I内容提供了实用解决方案。

Abstract: Text-to-Image (T2I) models have made remarkable progress in generating images
from text prompts, but their output quality and safety still depend heavily on
how prompts are phrased. Existing safety methods typically refine prompts using
large language models (LLMs), but they overlook the images produced, which can
result in unsafe outputs or unnecessary changes to already safe prompts. To
address this, we propose an iterative prompt refinement algorithm that uses
Vision Language Models (VLMs) to analyze both the input prompts and the
generated images. By leveraging visual feedback, our method refines prompts
more effectively, improving safety while maintaining user intent and
reliability comparable to existing LLM-based approaches. Additionally, we
introduce a new dataset labeled with both textual and visual safety signals
using off-the-shelf multi-modal LLM, enabling supervised fine-tuning.
Experimental results demonstrate that our approach produces safer outputs
without compromising alignment with user intent, offering a practical solution
for generating safer T2I content. Our code is available at
https://github.com/ku-dmlab/IPR. \textbf{\textcolor{red}WARNING: This paper
contains examples of harmful or inappropriate images generated by models.

</details>


### [40] [Task-Aware Image Signal Processor for Advanced Visual Perception](https://arxiv.org/abs/2509.13762)
*Kai Chen,Jin Xiao,Leheng Zhang,Kexuan Shi,Shuhang Gu*

Main category: cs.CV

TL;DR: 提出了一种轻量级的RAW-to-RGB框架TA-ISP，通过多尺度调制算子优化视觉任务性能，显著减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有方法在利用RAW数据时面临计算开销大或表达能力受限的问题，需要更高效的解决方案。

Method: TA-ISP通过预测轻量级多尺度调制算子，在全局、区域和像素级别重塑图像统计信息。

Result: 在多个RAW域检测和分割任务中，TA-ISP提高了准确性，同时减少了参数和推理时间。

Conclusion: TA-ISP适合资源受限设备，为RAW数据处理提供了高效解决方案。

Abstract: In recent years, there has been a growing trend in computer vision towards
exploiting RAW sensor data, which preserves richer information compared to
conventional low-bit RGB images. Early studies mainly focused on enhancing
visual quality, while more recent efforts aim to leverage the abundant
information in RAW data to improve the performance of visual perception tasks
such as object detection and segmentation. However, existing approaches still
face two key limitations: large-scale ISP networks impose heavy computational
overhead, while methods based on tuning traditional ISP pipelines are
restricted by limited representational capacity.To address these issues, we
propose Task-Aware Image Signal Processing (TA-ISP), a compact RAW-to-RGB
framework that produces task-oriented representations for pretrained vision
models. Instead of heavy dense convolutional pipelines, TA-ISP predicts a small
set of lightweight, multi-scale modulation operators that act at global,
regional, and pixel scales to reshape image statistics across different spatial
extents. This factorized control significantly expands the range of spatially
varying transforms that can be represented while keeping memory usage,
computation, and latency tightly constrained. Evaluated on several RAW-domain
detection and segmentation benchmarks under both daytime and nighttime
conditions, TA-ISP consistently improves downstream accuracy while markedly
reducing parameter count and inference time, making it well suited for
deployment on resource-constrained devices.

</details>


### [41] [NDLPNet: A Location-Aware Nighttime Deraining Network and a Real-World Benchmark Dataset](https://arxiv.org/abs/2509.13766)
*Huichun Liu,Xiaosong Li,Yang Liu,Xiaoqi Cheng,Haishu Tan*

Main category: cs.CV

TL;DR: 提出了一种夜间去雨网络NDLPNet，通过位置感知模块（PPM）有效捕捉雨条纹的空间位置和密度分布，显著提升了夜间图像去雨效果。


<details>
  <summary>Details</summary>
Motivation: 现有去雨技术主要针对白天场景，在夜间光照条件下表现不佳，影响夜间监控和自动驾驶的性能。

Method: 引入位置感知模块（PPM）捕捉空间上下文信息，增强模型对不同特征通道重要性的识别和校准能力。

Result: 在现有数据集和自建的NSR数据集上，NDLPNet在夜间去雨任务中优于现有最优方法。

Conclusion: NDLPNet能有效去除夜间雨条纹并保留背景信息，为夜间去雨任务提供了新基准。

Abstract: Visual degradation caused by rain streak artifacts in low-light conditions
significantly hampers the performance of nighttime surveillance and autonomous
navigation. Existing image deraining techniques are primarily designed for
daytime conditions and perform poorly under nighttime illumination due to the
spatial heterogeneity of rain distribution and the impact of light-dependent
stripe visibility. In this paper, we propose a novel Nighttime Deraining
Location-enhanced Perceptual Network(NDLPNet) that effectively captures the
spatial positional information and density distribution of rain streaks in
low-light environments. Specifically, we introduce a Position Perception Module
(PPM) to capture and leverage spatial contextual information from input data,
enhancing the model's capability to identify and recalibrate the importance of
different feature channels. The proposed nighttime deraining network can
effectively remove the rain streaks as well as preserve the crucial background
information. Furthermore, We construct a night scene rainy (NSR) dataset
comprising 900 image pairs, all based on real-world nighttime scenes, providing
a new benchmark for nighttime deraining task research. Extensive qualitative
and quantitative experimental evaluations on both existing datasets and the NSR
dataset consistently demonstrate our method outperform the state-of-the-art
(SOTA) methods in nighttime deraining tasks. The source code and dataset is
available at https://github.com/Feecuin/NDLPNet.

</details>


### [42] [VocSegMRI: Multimodal Learning for Precise Vocal Tract Segmentation in Real-time MRI](https://arxiv.org/abs/2509.13767)
*Daiqi Liu,Tomás Arias-Vergara,Johannes Enk,Fangxu Xing,Maureen Stone,Jerry L. Prince,Jana Hutter,Andreas Maier,Jonghye Woo,Paula Andrea Pérez-Toro*

Main category: cs.CV

TL;DR: VocSegMRI是一种多模态框架，结合视频、音频和语音输入，通过跨注意力融合和对比学习提升实时MRI中发音结构的精确分割。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖视觉线索，而同步的声学和语音信号能提供互补信息，提升分割精度。

Method: 提出VocSegMRI框架，整合视频、音频和语音输入，采用跨注意力融合和对比学习目标。

Result: 在USC-75数据集上，Dice分数达0.95，HD_95为4.20 mm，优于单模态和多模态基线。

Conclusion: 多模态建模对精确分析声道结构具有重要价值。

Abstract: Accurately segmenting articulatory structures in real-time magnetic resonance
imaging (rtMRI) remains challenging, as most existing methods rely almost
entirely on visual cues. Yet synchronized acoustic and phonological signals
provide complementary context that can enrich visual information and improve
precision. In this paper, we introduce VocSegMRI, a multimodal framework that
integrates video, audio, and phonological inputs through cross-attention fusion
for dynamic feature alignment. To further enhance cross-modal representation,
we incorporate a contrastive learning objective that improves segmentation
performance even when the audio modality is unavailable at inference. Evaluated
on a sub-set of USC-75 rtMRI dataset, our approach achieves state-of-the-art
performance, with a Dice score of 0.95 and a 95th percentile Hausdorff Distance
(HD_95) of 4.20 mm, outperforming both unimodal and multimodal baselines.
Ablation studies confirm the contributions of cross-attention and contrastive
learning to segmentation precision and robustness. These results highlight the
value of integrative multimodal modeling for accurate vocal tract analysis.

</details>


### [43] [Generative Image Coding with Diffusion Prior](https://arxiv.org/abs/2509.13768)
*Jianhui Chang*

Main category: cs.CV

TL;DR: 提出了一种基于扩散先验的生成编码框架，用于在低比特率下提升压缩性能，并在视觉保真度和泛化能力上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着生成技术的发展，视觉内容变得复杂，传统编码方法在保持主观质量和高压缩比方面存在困难，需要更高效的编码技术。

Method: 采用预优化编码器生成压缩域表示，通过轻量级适配器和注意力融合模块与预训练模型特征结合，并引入分布重归一化方法提升重建保真度。

Result: 在低比特率下视觉保真度优于现有方法，压缩性能比H.266/VVC提升高达79%，适用于AI生成内容并可泛化到更广泛内容类型。

Conclusion: 该框架有效利用预训练扩散模型，以最小重训练成本适应新需求，为高效压缩提供了可行方案。

Abstract: As generative technologies advance, visual content has evolved into a complex
mix of natural and AI-generated images, driving the need for more efficient
coding techniques that prioritize perceptual quality. Traditional codecs and
learned methods struggle to maintain subjective quality at high compression
ratios, while existing generative approaches face challenges in visual fidelity
and generalization. To this end, we propose a novel generative coding framework
leveraging diffusion priors to enhance compression performance at low bitrates.
Our approach employs a pre-optimized encoder to generate generalized
compressed-domain representations, integrated with the pretrained model's
internal features via a lightweight adapter and an attentive fusion module.
This framework effectively leverages existing pretrained diffusion models and
enables efficient adaptation to different pretrained models for new
requirements with minimal retraining costs. We also introduce a distribution
renormalization method to further enhance reconstruction fidelity. Extensive
experiments show that our method (1) outperforms existing methods in visual
fidelity across low bitrates, (2) improves compression performance by up to 79%
over H.266/VVC, and (3) offers an efficient solution for AI-generated content
while being adaptable to broader content types.

</details>


### [44] [AdaThinkDrive: Adaptive Thinking via Reinforcement Learning for Autonomous Driving](https://arxiv.org/abs/2509.13769)
*Yuechen Luo,Fang Li,Shaoqing Xu,Zhiyi Lai,Lei Yang,Qimao Chen,Ziang Luo,Zixun Xie,Shengyin Jiang,Jiaxin Liu,Long Chen,Bing Wang,Zhi-xin Yang*

Main category: cs.CV

TL;DR: AdaThinkDrive提出了一种双模式推理机制，通过自适应选择是否使用CoT推理，在自动驾驶任务中平衡了准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的CoT推理在简单场景中引入不必要的计算开销，未能提升决策质量。

Method: 结合快速和慢速思维的双模式推理机制，通过预训练和自适应奖励策略优化模型。

Result: 在Navsim基准测试中，PDMS达到90.3，推理时间减少14%。

Conclusion: AdaThinkDrive通过自适应推理机制，显著提升了自动驾驶模型的性能和效率。

Abstract: While reasoning technology like Chain of Thought (CoT) has been widely
adopted in Vision Language Action (VLA) models, it demonstrates promising
capabilities in end to end autonomous driving. However, recent efforts to
integrate CoT reasoning often fall short in simple scenarios, introducing
unnecessary computational overhead without improving decision quality. To
address this, we propose AdaThinkDrive, a novel VLA framework with a dual mode
reasoning mechanism inspired by fast and slow thinking. First, our framework is
pretrained on large scale autonomous driving (AD) scenarios using both question
answering (QA) and trajectory datasets to acquire world knowledge and driving
commonsense. During supervised fine tuning (SFT), we introduce a two mode
dataset, fast answering (w/o CoT) and slow thinking (with CoT), enabling the
model to distinguish between scenarios that require reasoning. Furthermore, an
Adaptive Think Reward strategy is proposed in conjunction with the Group
Relative Policy Optimization (GRPO), which rewards the model for selectively
applying CoT by comparing trajectory quality across different reasoning modes.
Extensive experiments on the Navsim benchmark show that AdaThinkDrive achieves
a PDMS of 90.3, surpassing the best vision only baseline by 1.7 points.
Moreover, ablations show that AdaThinkDrive surpasses both the never Think and
always Think baselines, improving PDMS by 2.0 and 1.4, respectively. It also
reduces inference time by 14% compared to the always Think baseline,
demonstrating its ability to balance accuracy and efficiency through adaptive
reasoning.

</details>


### [45] [Morphology-optimized Multi-Scale Fusion: Combining Local Artifacts and Mesoscopic Semantics for Deepfake Detection and Localization](https://arxiv.org/abs/2509.13776)
*Chao Shuai,Gaojian Wang,Kun Pan,Tong Wu,Fanli Jin,Haohan Tan,Mengxiang Li,Zhenguang Liu,Feng Lin,Kui Ren*

Main category: cs.CV

TL;DR: 提出了一种结合局部和全局视角的深度伪造定位方法，通过形态学操作融合输出，提升定位准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在伪造区域定位上表现不佳，忽视了局部细节与全局语义的互补性，且融合策略不理想。

Method: 独立预测局部和全局伪造区域，利用形态学操作融合输出，抑制噪声并增强空间一致性。

Result: 实验证明各模块有效提升了伪造定位的准确性和鲁棒性。

Conclusion: 该方法通过结合局部和全局视角，显著改善了伪造区域的定位性能。

Abstract: While the pursuit of higher accuracy in deepfake detection remains a central
goal, there is an increasing demand for precise localization of manipulated
regions. Despite the remarkable progress made in classification-based
detection, accurately localizing forged areas remains a significant challenge.
A common strategy is to incorporate forged region annotations during model
training alongside manipulated images. However, such approaches often neglect
the complementary nature of local detail and global semantic context, resulting
in suboptimal localization performance. Moreover, an often-overlooked aspect is
the fusion strategy between local and global predictions. Naively combining the
outputs from both branches can amplify noise and errors, thereby undermining
the effectiveness of the localization.
  To address these issues, we propose a novel approach that independently
predicts manipulated regions using both local and global perspectives. We
employ morphological operations to fuse the outputs, effectively suppressing
noise while enhancing spatial coherence. Extensive experiments reveal the
effectiveness of each module in improving the accuracy and robustness of
forgery localization.

</details>


### [46] [CETUS: Causal Event-Driven Temporal Modeling With Unified Variable-Rate Scheduling](https://arxiv.org/abs/2509.13784)
*Hanfang Liang,Bing Wang,Shizhen Zhang,Wen Jiang,Yizhuo Yang,Weixiang Guo,Shenghai Yuan*

Main category: cs.CV

TL;DR: 提出了一种直接处理原始事件流的新型架构，避免了中间表示，通过轻量级空间编码器和Mamba模型实现高效时空建模。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要预定义时间窗口或计算成本高，无法实现实时高效处理。

Method: 采用轻量级因果空间邻域编码器捕获局部几何关系，结合Mamba状态空间模型进行线性复杂度的时序建模。

Result: 通过自适应调整处理速度，实现了窗口延迟和推理延迟的最优平衡。

Conclusion: 该方法在高效处理事件流方面具有显著优势，适用于高速视觉任务。

Abstract: Event cameras capture asynchronous pixel-level brightness changes with
microsecond temporal resolution, offering unique advantages for high-speed
vision tasks. Existing methods often convert event streams into intermediate
representations such as frames, voxel grids, or point clouds, which inevitably
require predefined time windows and thus introduce window latency. Meanwhile,
pointwise detection methods face computational challenges that prevent
real-time efficiency due to their high computational cost. To overcome these
limitations, we propose the Variable-Rate Spatial Event Mamba, a novel
architecture that directly processes raw event streams without intermediate
representations. Our method introduces a lightweight causal spatial
neighborhood encoder to efficiently capture local geometric relations, followed
by Mamba-based state space models for scalable temporal modeling with linear
complexity. During inference, a controller adaptively adjusts the processing
speed according to the event rate, achieving an optimal balance between window
latency and inference latency.

</details>


### [47] [BWCache: Accelerating Video Diffusion Transformers through Block-Wise Caching](https://arxiv.org/abs/2509.13789)
*Hanshuai Cui,Zhiqing Tang,Zhifei Xu,Zhi Yao,Wenyi Zeng,Weijia Jia*

Main category: cs.CV

TL;DR: BWCache是一种无需训练的方法，通过动态缓存和重用DiT块特征来加速基于DiT的视频生成，同时保持视觉质量。


<details>
  <summary>Details</summary>
Motivation: Diffusion Transformers (DiTs)在视频生成中表现出色，但其顺序去噪过程导致延迟高，现有加速方法要么牺牲质量，要么未能有效重用中间特征。

Method: 提出Block-Wise Caching (BWCache)，动态缓存和重用DiT块特征，并引入相似性指标仅在特征差异低于阈值时触发重用。

Result: 在多个视频扩散模型上实验，BWCache实现了最高2.24倍的加速，且视觉质量相当。

Conclusion: BWCache通过减少冗余计算显著加速DiT视频生成，同时保持高质量。

Abstract: Recent advancements in Diffusion Transformers (DiTs) have established them as
the state-of-the-art method for video generation. However, their inherently
sequential denoising process results in inevitable latency, limiting real-world
applicability. Existing acceleration methods either compromise visual quality
due to architectural modifications or fail to reuse intermediate features at
proper granularity. Our analysis reveals that DiT blocks are the primary
contributors to inference latency. Across diffusion timesteps, the feature
variations of DiT blocks exhibit a U-shaped pattern with high similarity during
intermediate timesteps, which suggests substantial computational redundancy. In
this paper, we propose Block-Wise Caching (BWCache), a training-free method to
accelerate DiT-based video generation. BWCache dynamically caches and reuses
features from DiT blocks across diffusion timesteps. Furthermore, we introduce
a similarity indicator that triggers feature reuse only when the differences
between block features at adjacent timesteps fall below a threshold, thereby
minimizing redundant computations while maintaining visual fidelity. Extensive
experiments on several video diffusion models demonstrate that BWCache achieves
up to 2.24$\times$ speedup with comparable visual quality.

</details>


### [48] [Bridging the Synthetic-Real Gap: Supervised Domain Adaptation for Robust Spacecraft 6-DoF Pose Estimation](https://arxiv.org/abs/2509.13792)
*Inder Pal Singh,Nidhal Eddine Chenni,Abd El Rahman Shabayek,Arunkumar Rathinam,Djamila Aouada*

Main category: cs.CV

TL;DR: 提出了一种针对航天器姿态估计（SPE）的监督域适应（SDA）框架，通过联合优化域不变表示和任务特定风险，显著提升了在真实数据上的性能。


<details>
  <summary>Details</summary>
Motivation: 解决合成数据与真实数据之间的域差距问题，尤其是在少量标记目标数据可用时，现有方法表现不佳。

Method: 基于学习不变表示和风险（LIRR）范式，联合优化域不变表示和任务特定风险，利用标记的合成数据和少量标记的真实数据。

Result: 在SPEED+基准测试中，仅用5%标记目标数据即可达到或超过使用更多标记数据的基线性能。

Conclusion: 该方法轻量、与主干网络无关且计算高效，为实际航天器姿态估计提供了实用解决方案。

Abstract: Spacecraft Pose Estimation (SPE) is a fundamental capability for autonomous
space operations such as rendezvous, docking, and in-orbit servicing. Hybrid
pipelines that combine object detection, keypoint regression, and
Perspective-n-Point (PnP) solvers have recently achieved strong results on
synthetic datasets, yet their performance deteriorates sharply on real or
lab-generated imagery due to the persistent synthetic-to-real domain gap.
Existing unsupervised domain adaptation approaches aim to mitigate this issue
but often underperform when a modest number of labeled target samples are
available. In this work, we propose the first Supervised Domain Adaptation
(SDA) framework tailored for SPE keypoint regression. Building on the Learning
Invariant Representation and Risk (LIRR) paradigm, our method jointly optimizes
domain-invariant representations and task-specific risk using both labeled
synthetic and limited labeled real data, thereby reducing generalization error
under domain shift. Extensive experiments on the SPEED+ benchmark demonstrate
that our approach consistently outperforms source-only, fine-tuning, and oracle
baselines. Notably, with only 5% labeled target data, our method matches or
surpasses oracle performance trained on larger fractions of labeled data. The
framework is lightweight, backbone-agnostic, and computationally efficient,
offering a practical pathway toward robust and deployable spacecraft pose
estimation in real-world space environments.

</details>


### [49] [SWA-PF: Semantic-Weighted Adaptive Particle Filter for Memory-Efficient 4-DoF UAV Localization in GNSS-Denied Environments](https://arxiv.org/abs/2509.13795)
*Jiayu Yuan,Ming Dai,Enhui Zheng,Chao Su,Nanxing Chen,Qiming Hu,Shibo Zhu,Yibin Cao*

Main category: cs.CV

TL;DR: 提出了一种新的语义加权自适应粒子滤波方法（SWA-PF），用于GNSS缺失环境下的无人机定位，解决了现有方法的实时性、环境敏感性和泛化能力问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于检索的无人机定位方法在数据集可用性、实时性能、环境敏感性和泛化能力方面存在局限，特别是在动态或时变环境中。

Method: 提出SWA-PF方法，结合无人机图像和卫星图像的语义特征，通过语义加权机制和优化的粒子滤波架构实现高效定位。

Result: 在自建数据集上，方法计算效率提升10倍，全局定位误差低于10米，并能在几秒内完成4自由度姿态估计。

Conclusion: SWA-PF方法显著提升了无人机在GNSS缺失环境中的定位性能，具有高效性和鲁棒性。

Abstract: Vision-based Unmanned Aerial Vehicle (UAV) localization systems have been
extensively investigated for Global Navigation Satellite System (GNSS)-denied
environments. However, existing retrieval-based approaches face limitations in
dataset availability and persistent challenges including suboptimal real-time
performance, environmental sensitivity, and limited generalization capability,
particularly in dynamic or temporally varying environments. To overcome these
limitations, we present a large-scale Multi-Altitude Flight Segments dataset
(MAFS) for variable altitude scenarios and propose a novel Semantic-Weighted
Adaptive Particle Filter (SWA-PF) method. This approach integrates robust
semantic features from both UAV-captured images and satellite imagery through
two key innovations: a semantic weighting mechanism and an optimized particle
filtering architecture. Evaluated using our dataset, the proposed method
achieves 10x computational efficiency gain over feature extraction methods,
maintains global positioning errors below 10 meters, and enables rapid 4 degree
of freedom (4-DoF) pose estimation within seconds using accessible
low-resolution satellite maps. Code and dataset will be available at
https://github.com/YuanJiayuuu/SWA-PF.

</details>


### [50] [Masked Feature Modeling Enhances Adaptive Segmentation](https://arxiv.org/abs/2509.13801)
*Wenlve Zhou,Zhiheng Zhou,Tiantao Xian,Yikui Zhai,Weibin Wu,Biyun Ma*

Main category: cs.CV

TL;DR: 提出了一种名为MFM的新辅助任务，通过特征掩码和重建直接优化特征空间，提升了无监督域自适应语义分割的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法中，掩码建模在无监督域自适应语义分割中未充分探索，主要由于架构不兼容和优化目标不一致。

Method: 提出MFM方法，直接在特征空间进行掩码和重建，并引入轻量级辅助模块Rebuilder，训练时联合优化但推理时丢弃。

Result: 在各种架构和UDA基准测试中，MFM显著提升了分割性能。

Conclusion: MFM是一种简单、高效且通用的策略，适用于无监督域自适应语义分割。

Abstract: Unsupervised domain adaptation (UDA) for semantic segmentation aims to
transfer models from a labeled source domain to an unlabeled target domain.
While auxiliary self-supervised tasks-particularly contrastive learning-have
improved feature discriminability, masked modeling approaches remain
underexplored in this setting, largely due to architectural incompatibility and
misaligned optimization objectives. We propose Masked Feature Modeling (MFM), a
novel auxiliary task that performs feature masking and reconstruction directly
in the feature space. Unlike existing masked modeling methods that reconstruct
low-level inputs or perceptual features (e.g., HOG or visual tokens), MFM
aligns its learning target with the main segmentation task, ensuring
compatibility with standard architectures like DeepLab and DAFormer without
modifying the inference pipeline. To facilitate effective reconstruction, we
introduce a lightweight auxiliary module, Rebuilder, which is trained jointly
but discarded during inference, adding zero computational overhead at test
time. Crucially, MFM leverages the segmentation decoder to classify the
reconstructed features, tightly coupling the auxiliary objective with the
pixel-wise prediction task to avoid interference with the primary task.
Extensive experiments across various architectures and UDA benchmarks
demonstrate that MFM consistently enhances segmentation performance, offering a
simple, efficient, and generalizable strategy for unsupervised domain-adaptive
semantic segmentation.

</details>


### [51] [Data-Efficient Spectral Classification of Hyperspectral Data Using MiniROCKET and HDC-MiniROCKET](https://arxiv.org/abs/2509.13809)
*Nick Theisen,Kenny Schlegel,Dietrich Paulus,Peer Neubert*

Main category: cs.CV

TL;DR: 论文探讨了高光谱图像的光谱分类问题，提出使用MiniROCKET和HDC-MiniROCKET方法在训练数据有限时优于当前最佳模型1D-Justo-LiuNet。


<details>
  <summary>Details</summary>
Motivation: 光谱分类在许多领域有广泛应用，但当前最佳模型在训练数据有限时性能下降，需要改进。

Method: 研究了MiniROCKET和HDC-MiniROCKET方法，这些方法在特征提取部分无需可训练参数，对有限数据更鲁棒。

Result: MiniROCKET在数据有限时优于1D-Justo-LiuNet，在一般情况下性能相当。

Conclusion: MiniROCKET方法在光谱分类中表现出色，尤其在数据有限时更具优势。

Abstract: The classification of pixel spectra of hyperspectral images, i.e. spectral
classification, is used in many fields ranging from agricultural, over medical
to remote sensing applications and is currently also expanding to areas such as
autonomous driving. Even though for full hyperspectral images the
best-performing methods exploit spatial-spectral information, performing
classification solely on spectral information has its own advantages, e.g.
smaller model size and thus less data required for training. Moreover, spectral
information is complementary to spatial information and improvements on either
part can be used to improve spatial-spectral approaches in the future.
Recently, 1D-Justo-LiuNet was proposed as a particularly efficient model with
very few parameters, which currently defines the state of the art in spectral
classification. However, we show that with limited training data the model
performance deteriorates. Therefore, we investigate MiniROCKET and
HDC-MiniROCKET for spectral classification to mitigate that problem. The model
extracts well-engineered features without trainable parameters in the feature
extraction part and is therefore less vulnerable to limited training data. We
show that even though MiniROCKET has more parameters it outperforms
1D-Justo-LiuNet in limited data scenarios and is mostly on par with it in the
general case

</details>


### [52] [Semi-MoE: Mixture-of-Experts meets Semi-Supervised Histopathology Segmentation](https://arxiv.org/abs/2509.13834)
*Nguyen Lan Vi Vu,Thanh-Huy Nguyen,Thien Nguyen,Daisuke Kihara,Tianyang Wang,Xingjian Li,Min Xu*

Main category: cs.CV

TL;DR: Semi-MOE是一种多任务Mixture-of-Experts框架，用于半监督组织病理学图像分割，通过动态聚合专家特征和自适应多目标损失，显著提升了低标签设置下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有半监督学习方法在组织病理学图像分割中因伪标签噪声问题表现不佳，需解决模糊腺体边界和形态学误分类问题。

Method: 提出三个专家网络（分割、距离场回归、边界预测）和Multi-Gating伪标签模块，结合自适应多目标损失动态平衡学习目标。

Result: 在GlaS和CRAG基准测试中，Semi-MOE在低标签设置下优于现有方法。

Conclusion: Semi-MOE展示了基于MoE架构在半监督分割中的潜力，为未来研究提供了新方向。

Abstract: Semi-supervised learning has been employed to alleviate the need for
extensive labeled data for histopathology image segmentation, but existing
methods struggle with noisy pseudo-labels due to ambiguous gland boundaries and
morphological misclassification. This paper introduces Semi-MOE, to the best of
our knowledge, the first multi-task Mixture-of-Experts framework for
semi-supervised histopathology image segmentation. Our approach leverages three
specialized expert networks: A main segmentation expert, a signed distance
field regression expert, and a boundary prediction expert, each dedicated to
capturing distinct morphological features. Subsequently, the Multi-Gating
Pseudo-labeling module dynamically aggregates expert features, enabling a
robust fuse-and-refine pseudo-labeling mechanism. Furthermore, to eliminate
manual tuning while dynamically balancing multiple learning objectives, we
propose an Adaptive Multi-Objective Loss. Extensive experiments on GlaS and
CRAG benchmarks show that our method outperforms state-of-the-art approaches in
low-label settings, highlighting the potential of MoE-based architectures in
advancing semi-supervised segmentation. Our code is available at
https://github.com/vnlvi2k3/Semi-MoE.

</details>


### [53] [Diving into Mitigating Hallucinations from a Vision Perspective for Large Vision-Language Models](https://arxiv.org/abs/2509.13836)
*Weihang Wang,Xinhao Li,Ziyue Wang,Yan Pang,Jielei Zhang,Peiyi Li,Qiang Zhang,Longwen Gao*

Main category: cs.CV

TL;DR: 论文提出VHBench-10基准和VisionWeaver方法，系统分析视觉编码器对LVLMs幻觉的影响，并显著减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）中的物体幻觉问题限制了其实际应用，视觉编码器的选择是关键。不同编码器的训练范式导致其具有不同的归纳偏差，从而影响幻觉表现。

Method: 引入VHBench-10基准，评估10种细粒度幻觉类别；提出VisionWeaver，一种上下文感知路由网络，动态聚合多个专家的视觉特征。

Result: 实验证实不同编码器具有独特的幻觉特征；VisionWeaver显著减少幻觉并提升模型性能。

Conclusion: VisionWeaver通过动态特征聚合有效解决LVLMs的幻觉问题，为未来研究提供了新方向。

Abstract: Object hallucination in Large Vision-Language Models (LVLMs) significantly
impedes their real-world applicability. As the primary component for accurately
interpreting visual information, the choice of visual encoder is pivotal. We
hypothesize that the diverse training paradigms employed by different visual
encoders instill them with distinct inductive biases, which leads to their
diverse hallucination performances. Existing benchmarks typically focus on
coarse-grained hallucination detection and fail to capture the diverse
hallucinations elaborated in our hypothesis. To systematically analyze these
effects, we introduce VHBench-10, a comprehensive benchmark with approximately
10,000 samples for evaluating LVLMs across ten fine-grained hallucination
categories. Our evaluations confirm encoders exhibit unique hallucination
characteristics. Building on these insights and the suboptimality of simple
feature fusion, we propose VisionWeaver, a novel Context-Aware Routing Network.
It employs global visual features to generate routing signals, dynamically
aggregating visual features from multiple specialized experts. Comprehensive
experiments confirm the effectiveness of VisionWeaver in significantly reducing
hallucinations and improving overall model performance.

</details>


### [54] [Consistent View Alignment Improves Foundation Models for 3D Medical Image Segmentation](https://arxiv.org/abs/2509.13846)
*Puru Vaish,Felix Meister,Tobias Heimann,Christoph Brune,Jelmer M. Wolterink*

Main category: cs.CV

TL;DR: 论文提出了一种名为'Consistent View Alignment'的自监督学习方法，通过显式对齐不同数据视图的表示来提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有表示学习方法假设数据点的不相关视图足以学习有意义的表示，但作者发现潜在空间中的有意义结构需要显式诱导。

Method: 提出了一种方法，通过对齐不同数据视图的表示来补充信息，同时避免引入假阳性。

Result: 实验表明，该方法在下游任务中表现优异，并在MICCAI 2025 SSL3D挑战赛中取得第一和第二名。

Conclusion: 结构化视图对齐在学习有效表示中起关键作用，显式诱导潜在空间结构是必要的。

Abstract: Many recent approaches in representation learning implicitly assume that
uncorrelated views of a data point are sufficient to learn meaningful
representations for various downstream tasks. In this work, we challenge this
assumption and demonstrate that meaningful structure in the latent space does
not emerge naturally. Instead, it must be explicitly induced. We propose a
method that aligns representations from different views of the data to align
complementary information without inducing false positives. Our experiments
show that our proposed self-supervised learning method, Consistent View
Alignment, improves performance for downstream tasks, highlighting the critical
role of structured view alignment in learning effective representations. Our
method achieved first and second place in the MICCAI 2025 SSL3D challenge when
using a Primus vision transformer and ResEnc convolutional neural network,
respectively. The code and pretrained model weights are released at
https://github.com/Tenbatsu24/LatentCampus.

</details>


### [55] [SpecDiff: Accelerating Diffusion Model Inference with Self-Speculation](https://arxiv.org/abs/2509.13848)
*Jiayi Pan,Jiaming Xu,Yongkang Zhou,Guohao Dai*

Main category: cs.CV

TL;DR: SpecDiff是一种基于自推测和多级特征缓存的训练免费策略，通过结合历史和未来信息，显著加速扩散模型推理，同时保持高质量。


<details>
  <summary>Details</summary>
Motivation: 现有特征缓存方法仅依赖历史信息，导致速度和准确性受限。

Method: 提出自推测范式，结合历史和未来信息，设计动态重要性评分和多级特征分类算法。

Result: 在Stable Diffusion 3、3.5和FLUX上，SpecDiff实现了2.80×、2.74×和3.17×的加速，质量损失可忽略。

Conclusion: SpecDiff突破了速度与准确性的权衡瓶颈，推动了高效扩散模型推理的Pareto前沿。

Abstract: Feature caching has recently emerged as a promising method for diffusion
model acceleration. It effectively alleviates the inefficiency problem caused
by high computational requirements by caching similar features in the inference
process of the diffusion model. In this paper, we analyze existing feature
caching methods from the perspective of information utilization, and point out
that relying solely on historical information will lead to constrained accuracy
and speed performance. And we propose a novel paradigm that introduces future
information via self-speculation based on the information similarity at the
same time step across different iteration times. Based on this paradigm, we
present \textit{SpecDiff}, a training-free multi-level feature caching strategy
including a cached feature selection algorithm and a multi-level feature
classification algorithm. (1) Feature selection algorithm based on
self-speculative information. \textit{SpecDiff} determines a dynamic importance
score for each token based on self-speculative information and historical
information, and performs cached feature selection through the importance
score. (2) Multi-level feature classification algorithm based on feature
importance scores. \textit{SpecDiff} classifies tokens by leveraging the
differences in feature importance scores and introduces a multi-level feature
calculation strategy. Extensive experiments show that \textit{SpecDiff}
achieves average 2.80 \times, 2.74 \times , and 3.17\times speedup with
negligible quality loss in Stable Diffusion 3, 3.5, and FLUX compared to RFlow
on NVIDIA A800-80GB GPU. By merging speculative and historical information,
\textit{SpecDiff} overcomes the speedup-accuracy trade-off bottleneck, pushing
the Pareto frontier of speedup and accuracy in the efficient diffusion model
inference.

</details>


### [56] [EDITS: Enhancing Dataset Distillation with Implicit Textual Semantics](https://arxiv.org/abs/2509.13858)
*Qianxin Xia,Jiawei Du,Guoming Lu,Zhiyong Shu,Jielei Wang*

Main category: cs.CV

TL;DR: EDITS是一种利用视觉语言模型和大型语言模型提取图像高级语义信息的数据集蒸馏方法，通过双原型引导策略生成合成数据集。


<details>
  <summary>Details</summary>
Motivation: 传统数据集蒸馏方法主要关注低层次视觉特征，忽略了图像中的高层次语义和结构信息。

Method: EDITS通过全局语义查询模块融合图像特征与外部文本，构建先验聚类缓冲区，再通过局部语义感知选择代表性样本，最终利用扩散模型生成合成数据集。

Result: 实验证明EDITS在数据集蒸馏中具有显著效果。

Conclusion: EDITS通过结合文本语义信息，提升了数据集蒸馏的性能。

Abstract: Dataset distillation aims to synthesize a compact dataset from the original
large-scale one, enabling highly efficient learning while preserving
competitive model performance. However, traditional techniques primarily
capture low-level visual features, neglecting the high-level semantic and
structural information inherent in images. In this paper, we propose EDITS, a
novel framework that exploits the implicit textual semantics within the image
data to achieve enhanced distillation. First, external texts generated by a
Vision Language Model (VLM) are fused with image features through a Global
Semantic Query module, forming the prior clustered buffer. Local Semantic
Awareness then selects representative samples from the buffer to construct
image and text prototypes, with the latter produced by guiding a Large Language
Model (LLM) with meticulously crafted prompt. Ultimately, Dual Prototype
Guidance strategy generates the final synthetic dataset through a diffusion
model. Extensive experiments confirm the effectiveness of our method.Source
code is available in: https://github.com/einsteinxia/EDITS.

</details>


### [57] [LamiGauss: Pitching Radiative Gaussian for Sparse-View X-ray Laminography Reconstruction](https://arxiv.org/abs/2509.13863)
*Chu Chen,Ander Biguri,Jean-Michel Morel,Raymond H. Chan,Carola-Bibiane Schönlieb,Jizhou Li*

Main category: cs.CV

TL;DR: LamiGauss是一种结合高斯溅射和专用变换模型的X射线层析成像重建算法，能在稀疏视图条件下高效重建高质量图像。


<details>
  <summary>Details</summary>
Motivation: 传统CT在板状结构（如微芯片和电池材料）的非破坏性检测中受限，稀疏视图下的高质量重建仍具挑战性。

Method: 结合高斯溅射辐射光栅化和包含倾斜角的变换模型，通过初始化策略过滤伪影，优化稀疏投影直接重建。

Result: 在合成和真实数据集上表现优异，仅需3%的完整视图即可超越基于完整数据的迭代方法。

Conclusion: LamiGauss在稀疏视图条件下实现了高效、准确的层析成像重建，优于现有技术。

Abstract: X-ray Computed Laminography (CL) is essential for non-destructive inspection
of plate-like structures in applications such as microchips and composite
battery materials, where traditional computed tomography (CT) struggles due to
geometric constraints. However, reconstructing high-quality volumes from
laminographic projections remains challenging, particularly under highly
sparse-view acquisition conditions. In this paper, we propose a reconstruction
algorithm, namely LamiGauss, that combines Gaussian Splatting radiative
rasterization with a dedicated detector-to-world transformation model
incorporating the laminographic tilt angle. LamiGauss leverages an
initialization strategy that explicitly filters out common laminographic
artifacts from the preliminary reconstruction, preventing redundant Gaussians
from being allocated to false structures and thereby concentrating model
capacity on representing the genuine object. Our approach effectively optimizes
directly from sparse projections, enabling accurate and efficient
reconstruction with limited data. Extensive experiments on both synthetic and
real datasets demonstrate the effectiveness and superiority of the proposed
method over existing techniques. LamiGauss uses only 3$\%$ of full views to
achieve superior performance over the iterative method optimized on a full
dataset.

</details>


### [58] [Distractor-Aware Memory-Based Visual Object Tracking](https://arxiv.org/abs/2509.13864)
*Jovana Videnovic,Matej Kristan,Alan Lukezic*

Main category: cs.CV

TL;DR: DAM4SAM是一种针对SAM2的改进模块，通过引入干扰物感知内存和自省管理方法，显著提升了视觉目标跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于内存的视频分割方法（如SAM2）在分割任务中表现优异，但在视觉目标跟踪中容易受到干扰物影响，导致跟踪漂移。

Method: 提出了一种干扰物感知的drop-in内存模块和基于自省的管理方法，构建了DAM4SAM模型，并创建了DiDi数据集用于分析干扰物场景下的跟踪性能。

Result: DAM4SAM在13个基准测试中优于SAM2.1，并在10个测试中创下新记录；与实时跟踪器EfficientTAM集成后性能提升11%，与非实时SAM2.1-L相当。

Conclusion: DAM4SAM通过干扰物感知内存设计有效解决了跟踪漂移问题，并在多种架构中表现出良好的泛化能力。

Abstract: Recent emergence of memory-based video segmentation methods such as SAM2 has
led to models with excellent performance in segmentation tasks, achieving
leading results on numerous benchmarks. However, these modes are not fully
adjusted for visual object tracking, where distractors (i.e., objects visually
similar to the target) pose a key challenge. In this paper we propose a
distractor-aware drop-in memory module and introspection-based management
method for SAM2, leading to DAM4SAM. Our design effectively reduces the
tracking drift toward distractors and improves redetection capability after
object occlusion. To facilitate the analysis of tracking in the presence of
distractors, we construct DiDi, a Distractor-Distilled dataset. DAM4SAM
outperforms SAM2.1 on thirteen benchmarks and sets new state-of-the-art results
on ten. Furthermore, integrating the proposed distractor-aware memory into a
real-time tracker EfficientTAM leads to 11% improvement and matches tracking
quality of the non-real-time SAM2.1-L on multiple tracking and segmentation
benchmarks, while integration with edge-based tracker EdgeTAM delivers 4%
performance boost, demonstrating a very good generalization across
architectures.

</details>


### [59] [Invisible Yet Detected: PelFANet with Attention-Guided Anatomical Fusion for Pelvic Fracture Diagnosis](https://arxiv.org/abs/2509.13873)
*Siam Tahsin Bhuiyan,Rashedur Rahman,Sefatul Wasi,Naomi Yagi,Syoji Kobashi,Ashraful Islam,Saadia Binte Alam*

Main category: cs.CV

TL;DR: PelFANet是一种双流注意力网络，通过融合原始X光和分割骨图像提升骨盆骨折分类性能，尤其在细微骨折检测中表现优异。


<details>
  <summary>Details</summary>
Motivation: 骨盆骨折在标准X光片中难以诊断，尤其是细微或不可见的骨折。

Method: PelFANet采用双流注意力网络和Fused Attention Blocks（FABlocks）融合特征，通过两阶段训练提升性能。

Result: 在AMERI数据集上，可见骨折准确率88.68%，AUC 0.9334；不可见骨折准确率82.29%，AUC 0.8688。

Conclusion: PelFANet展示了在细微骨折检测中的临床潜力，尤其是解剖感知的双输入架构。

Abstract: Pelvic fractures pose significant diagnostic challenges, particularly in
cases where fracture signs are subtle or invisible on standard radiographs. To
address this, we introduce PelFANet, a dual-stream attention network that fuses
raw pelvic X-rays with segmented bone images to improve fracture
classification. The network em-ploys Fused Attention Blocks (FABlocks) to
iteratively exchange and refine fea-tures from both inputs, capturing global
context and localized anatomical detail. Trained in a two-stage pipeline with a
segmentation-guided approach, PelFANet demonstrates superior performance over
conventional methods. On the AMERI dataset, it achieves 88.68% accuracy and
0.9334 AUC on visible fractures, while generalizing effectively to invisible
fracture cases with 82.29% accuracy and 0.8688 AUC, despite not being trained
on them. These results highlight the clini-cal potential of anatomy-aware
dual-input architectures for robust fracture detec-tion, especially in
scenarios with subtle radiographic presentations.

</details>


### [60] [EvHand-FPV: Efficient Event-Based 3D Hand Tracking from First-Person View](https://arxiv.org/abs/2509.13883)
*Zhen Xu,Guorui Lu,Chang Gao,Qinyu Chen*

Main category: cs.CV

TL;DR: EvHand-FPV是一个轻量级框架，用于从单个事件摄像头进行第一人称视角的3D手部追踪，解决了资源受限设备上的准确性和效率问题。


<details>
  <summary>Details</summary>
Motivation: 传统帧式方法在准确性和效率上难以满足XR设备的需求，事件摄像头提供了高时间分辨率和低功耗的解决方案。

Method: 构建了一个事件数据集，结合合成和真实数据，并引入了手腕ROI和多任务学习策略以减少计算量。

Result: 在真实测试集上，2D-AUCp从0.77提升到0.85，参数和计算量均减少89%，3D-AUCp保持在0.84。

Conclusion: EvHand-FPV展示了适用于XR设备的高效、准确的手部追踪方法。

Abstract: Hand tracking holds great promise for intuitive interaction paradigms, but
frame-based methods often struggle to meet the requirements of accuracy, low
latency, and energy efficiency, especially in resource-constrained settings
such as Extended Reality (XR) devices. Event cameras provide $\mu$s-level
temporal resolution at mW-level power by asynchronously sensing brightness
changes. In this work, we present EvHand-FPV, a lightweight framework for
egocentric First-Person-View 3D hand tracking from a single event camera. We
construct an event-based FPV dataset that couples synthetic training data with
3D labels and real event data with 2D labels for evaluation to address the
scarcity of egocentric benchmarks. EvHand-FPV also introduces a wrist-based
region of interest (ROI) that localizes the hand region via geometric cues,
combined with an end-to-end mapping strategy that embeds ROI offsets into the
network to reduce computation without explicit reconstruction, and a multi-task
learning strategy with an auxiliary geometric feature head that improves
representations without test-time overhead. On our real FPV test set,
EvHand-FPV improves 2D-AUCp from 0.77 to 0.85 while reducing parameters from
11.2M to 1.2M by 89% and FLOPs per inference from 1.648G to 0.185G by 89%. It
also maintains a competitive 3D-AUCp of 0.84 on synthetic data. These results
demonstrate accurate and efficient egocentric event-based hand tracking
suitable for on-device XR applications. The dataset and code are available at
https://github.com/zen5x5/EvHand-FPV.

</details>


### [61] [White Aggregation and Restoration for Few-shot 3D Point Cloud Semantic Segmentation](https://arxiv.org/abs/2509.13907)
*Jiyun Im,SuBeen Lee,Miso Lee,Jae-Pil Heo*

Main category: cs.CV

TL;DR: 论文提出了一种基于注意力机制的原型生成方法WARM，通过白化和着色变换解决原型标记与支持特征之间的分布差异，显著提升了少样本3D点云分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在原型生成过程中存在初始随机性问题且未充分探索，影响了少样本3D点云分割的性能。

Method: 提出WARM模块，通过白化和着色变换夹着交叉注意力，解决原型标记与支持特征的分布差异问题。

Result: 在多个少样本3D点云分割基准测试中取得显著领先的性能。

Conclusion: WARM通过简单有效的设计实现了鲁棒的注意力机制，生成更具代表性的原型。

Abstract: Few-Shot 3D Point Cloud Segmentation (FS-PCS) aims to predict per-point
labels for an unlabeled point cloud, given only a few labeled examples. To
extract discriminative representations from the limited support set, existing
methods have constructed prototypes using conventional algorithms such as
farthest point sampling. However, we point out that its initial randomness
significantly affects FS-PCS performance and that the prototype generation
process remains underexplored despite its prevalence. This motivates us to
investigate an advanced prototype generation method based on attention
mechanism. Despite its potential, we found that vanilla module suffers from the
distributional gap between learnable prototypical tokens and support features.
To overcome this, we propose White Aggregation and Restoration Module (WARM),
which resolves the misalignment by sandwiching cross-attention between
whitening and coloring transformations. Specifically, whitening aligns the
support features to prototypical tokens before attention process, and
subsequently coloring restores the original distribution to the attended
tokens. This simple yet effective design enables robust attention, thereby
generating representative prototypes by capturing the semantic relationships
among support features. Our method achieves state-of-the-art performance with a
significant margin on multiple FS-PCS benchmarks, demonstrating its
effectiveness through extensive experiments.

</details>


### [62] [Towards Rationale-Answer Alignment of LVLMs via Self-Rationale Calibration](https://arxiv.org/abs/2509.13919)
*Yuanchen Wu,Ke Yan,Shouhong Ding,Ziyin Zhou,Xiaoqiang Li*

Main category: cs.CV

TL;DR: SRC框架通过迭代校准理由与答案的对齐，提升大型视觉语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有大型视觉语言模型在理由与答案对齐上存在不一致，导致推理错误。

Method: 采用轻量级理由微调、多样化候选生成及R-Scorer评分策略，进行偏好微调。

Result: 在多个基准测试中显著提升了模型的感知、推理和泛化能力。

Conclusion: 理由导向的对齐对挖掘大型视觉语言模型潜力至关重要。

Abstract: Large Vision-Language Models (LVLMs) have manifested strong visual question
answering capability. However, they still struggle with aligning the rationale
and the generated answer, leading to inconsistent reasoning and incorrect
responses. To this end, this paper introduces the Self-Rationale Calibration
(SRC) framework to iteratively calibrate the alignment between rationales and
answers. SRC begins by employing a lightweight "rationale fine-tuning"
approach, which modifies the model's response format to require a rationale
before deriving an answer without explicit prompts. Next, SRC searches for a
diverse set of candidate responses from the fine-tuned LVLMs for each sample,
followed by a proposed pairwise scoring strategy using a tailored scoring
model, R-Scorer, to evaluate both rationale quality and factual consistency of
candidates. Based on a confidence-weighted preference curation process, SRC
decouples the alignment calibration into a preference fine-tuning manner,
leading to significant improvements of LVLMs in perception, reasoning, and
generalization across multiple benchmarks. Our results emphasize the
rationale-oriented alignment in exploring the potential of LVLMs.

</details>


### [63] [Towards Robust Defense against Customization via Protective Perturbation Resistant to Diffusion-based Purification](https://arxiv.org/abs/2509.13922)
*Wenkui Yang,Jie Cao,Junxian Duan,Ran He*

Main category: cs.CV

TL;DR: 论文提出了一种名为AntiPure的保护性扰动方法，用于抵抗净化技术对图像的恢复，从而防止恶意伪造。


<details>
  <summary>Details</summary>
Motivation: 扩散模型（如Stable Diffusion）的强大定制能力带来了安全风险（如深度伪造和版权侵权），现有保护性扰动方法易被净化技术移除。

Method: 提出AntiPure方法，通过两种引导机制（Patch-wise Frequency Guidance和Erroneous Timestep Guidance）嵌入不可察觉的扰动，抵抗净化。

Result: 实验表明，AntiPure在净化-定制流程中实现了最小的感知差异和最大的失真，优于其他保护性扰动方法。

Conclusion: AntiPure是一种有效的抗净化保护性扰动方法，能够显著提升图像的安全性。

Abstract: Diffusion models like Stable Diffusion have become prominent in visual
synthesis tasks due to their powerful customization capabilities, which also
introduce significant security risks, including deepfakes and copyright
infringement. In response, a class of methods known as protective perturbation
emerged, which mitigates image misuse by injecting imperceptible adversarial
noise. However, purification can remove protective perturbations, thereby
exposing images again to the risk of malicious forgery. In this work, we
formalize the anti-purification task, highlighting challenges that hinder
existing approaches, and propose a simple diagnostic protective perturbation
named AntiPure. AntiPure exposes vulnerabilities of purification within the
"purification-customization" workflow, owing to two guidance mechanisms: 1)
Patch-wise Frequency Guidance, which reduces the model's influence over
high-frequency components in the purified image, and 2) Erroneous Timestep
Guidance, which disrupts the model's denoising strategy across different
timesteps. With additional guidance, AntiPure embeds imperceptible
perturbations that persist under representative purification settings,
achieving effective post-customization distortion. Experiments show that, as a
stress test for purification, AntiPure achieves minimal perceptual discrepancy
and maximal distortion, outperforming other protective perturbation methods
within the purification-customization workflow.

</details>


### [64] [Noise-Level Diffusion Guidance: Well Begun is Half Done](https://arxiv.org/abs/2509.13936)
*Harvey Mannering,Zhiwu Huang,Adam Prugel-Bennett*

Main category: cs.CV

TL;DR: 提出了一种名为噪声水平引导（NLG）的简单高效方法，优化扩散模型中的初始噪声，无需额外数据或网络。


<details>
  <summary>Details</summary>
Motivation: 现有噪声优化方法依赖额外资源或复杂优化，限制了实用性。

Method: 通过增加初始噪声与通用引导的对齐概率来优化噪声水平。

Result: 在五个基准测试中提升了生成质量和条件一致性。

Conclusion: NLG是一种实用且可扩展的扩散模型增强方法。

Abstract: Diffusion models have achieved state-of-the-art image generation. However,
the random Gaussian noise used to start the diffusion process influences the
final output, causing variations in image quality and prompt adherence.
Existing noise-level optimization approaches generally rely on extra dataset
construction, additional networks, or backpropagation-based optimization,
limiting their practicality. In this paper, we propose Noise Level Guidance
(NLG), a simple, efficient, and general noise-level optimization approach that
refines initial noise by increasing the likelihood of its alignment with
general guidance - requiring no additional training data, auxiliary networks,
or backpropagation. The proposed NLG approach provides a unified framework
generalizable to both conditional and unconditional diffusion models,
accommodating various forms of diffusion-level guidance. Extensive experiments
on five standard benchmarks demonstrate that our approach enhances output
generation quality and input condition adherence. By seamlessly integrating
with existing guidance methods while maintaining computational efficiency, our
method establishes NLG as a practical and scalable enhancement to diffusion
models. Code can be found at
https://github.com/harveymannering/NoiseLevelGuidance.

</details>


### [65] [Can Current AI Models Count What We Mean, Not What They See? A Benchmark and Systematic Evaluation](https://arxiv.org/abs/2509.13939)
*Gia Khanh Nguyen,Yifeng Huang,Minh Hoai*

Main category: cs.CV

TL;DR: PairTally是一个专门用于评估细粒度视觉计数的基准数据集，包含681张高分辨率图像，每张图像包含两类物体，要求模型基于形状、大小、颜色或语义的细微差异进行区分和计数。


<details>
  <summary>Details</summary>
Motivation: 当前模型在细粒度和意图驱动的计数任务中表现不佳，因此需要一个新的基准数据集来诊断和改进这些系统。

Method: 构建了PairTally数据集，包含两类物体（跨类别和类别内），并评估了多种先进模型（基于示例的方法、语言提示模型和大规模视觉语言模型）。

Result: 尽管模型有进步，但在细粒度和视觉模糊情况下仍难以可靠计数。

Conclusion: PairTally为诊断和改进细粒度视觉计数系统提供了新的基础。

Abstract: Visual counting is a fundamental yet challenging task, especially when users
need to count objects of a specific type in complex scenes. While recent
models, including class-agnostic counting models and large vision-language
models (VLMs), show promise in counting tasks, their ability to perform
fine-grained, intent-driven counting remains unclear. In this paper, we
introduce PairTally, a benchmark dataset specifically designed to evaluate
fine-grained visual counting. Each of the 681 high-resolution images in
PairTally contains two object categories, requiring models to distinguish and
count based on subtle differences in shape, size, color, or semantics. The
dataset includes both inter-category (distinct categories) and intra-category
(closely related subcategories) settings, making it suitable for rigorous
evaluation of selective counting capabilities. We benchmark a variety of
state-of-the-art models, including exemplar-based methods, language-prompted
models, and large VLMs. Our results show that despite recent advances, current
models struggle to reliably count what users intend, especially in fine-grained
and visually ambiguous cases. PairTally provides a new foundation for
diagnosing and improving fine-grained visual counting systems.

</details>


### [66] [MOCHA: Multi-modal Objects-aware Cross-arcHitecture Alignment](https://arxiv.org/abs/2509.14001)
*Elena Camuffo,Francesco Barbato,Mete Ozay,Simone Milani,Umberto Michieli*

Main category: cs.CV

TL;DR: MOCHA是一种知识蒸馏方法，通过区域级多模态语义将大型视觉-语言教师模型的知识迁移到轻量级视觉学生模型中。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在密集或全局对齐上的局限性，实现无需修改教师模型或推理时文本输入的高效语义迁移。

Method: 使用翻译模块将学生特征映射到联合空间，并通过双目标损失训练学生和翻译模块，实现局部对齐和全局关系一致性。

Result: 在四个个性化检测基准上，MOCHA平均得分提升10.1，性能与大型多模态模型相当。

Conclusion: MOCHA适合实际部署，证明了其在轻量级架构下高效迁移语义的能力。

Abstract: We introduce MOCHA (Multi-modal Objects-aware Cross-arcHitecture Alignment),
a knowledge distillation approach that transfers region-level multimodal
semantics from a large vision-language teacher (e.g., LLaVa) into a lightweight
vision-only object detector student (e.g., YOLO). A translation module maps
student features into a joint space, where the training of the student and
translator is guided by a dual-objective loss that enforces both local
alignment and global relational consistency. Unlike prior approaches focused on
dense or global alignment, MOCHA operates at the object level, enabling
efficient transfer of semantics without modifying the teacher or requiring
textual input at inference. We validate our method across four personalized
detection benchmarks under few-shot regimes. Results show consistent gains over
baselines, with a +10.1 average score improvement. Despite its compact
architecture, MOCHA reaches performance on par with larger multimodal models,
proving its suitability for real-world deployment.

</details>


### [67] [Performance Optimization of YOLO-FEDER FusionNet for Robust Drone Detection in Visually Complex Environments](https://arxiv.org/abs/2509.14012)
*Tamara R. Lenhard,Andreas Weinmann,Tobias Koch*

Main category: cs.CV

TL;DR: 论文提出了一种改进的YOLO-FEDER FusionNet框架，通过结合通用目标检测和伪装目标检测技术，提升了在复杂视觉环境中无人机检测的性能。


<details>
  <summary>Details</summary>
Motivation: 在复杂视觉环境中，无人机检测因背景干扰、目标尺寸小和伪装效果而具有挑战性。现有通用目标检测器（如YOLO）在低纹理场景表现良好，但在复杂环境中性能下降。

Method: 改进的YOLO-FEDER FusionNet通过优化训练数据组成、特征融合策略和骨干网络设计，结合合成数据和真实数据提升鲁棒性，并评估多尺度FEDER特征的贡献。

Result: 实验表明，结合FEDER特征和骨干网络升级显著提升了性能，最佳配置下FNR降低39.1个百分点，mAP提升62.8个百分点（IoU=0.5）。

Conclusion: 该框架有效解决了复杂环境中的无人机检测问题，性能显著优于基线方法。

Abstract: Drone detection in visually complex environments remains challenging due to
background clutter, small object scale, and camouflage effects. While generic
object detectors like YOLO exhibit strong performance in low-texture scenes,
their effectiveness degrades in cluttered environments with low
object-background separability. To address these limitations, this work
presents an enhanced iteration of YOLO-FEDER FusionNet -- a detection framework
that integrates generic object detection with camouflage object detection
techniques. Building upon the original architecture, the proposed iteration
introduces systematic advancements in training data composition, feature fusion
strategies, and backbone design. Specifically, the training process leverages
large-scale, photo-realistic synthetic data, complemented by a small set of
real-world samples, to enhance robustness under visually complex conditions.
The contribution of intermediate multi-scale FEDER features is systematically
evaluated, and detection performance is comprehensively benchmarked across
multiple YOLO-based backbone configurations. Empirical results indicate that
integrating intermediate FEDER features, in combination with backbone upgrades,
contributes to notable performance improvements. In the most promising
configuration -- YOLO-FEDER FusionNet with a YOLOv8l backbone and FEDER
features derived from the DWD module -- these enhancements lead to a FNR
reduction of up to 39.1 percentage points and a mAP increase of up to 62.8
percentage points at an IoU threshold of 0.5, compared to the initial baseline.

</details>


### [68] [SAIL-VL2 Technical Report](https://arxiv.org/abs/2509.14033)
*Weijie Yin,Yongjie Ye,Fangxun Shu,Yue Liao,Zijian Kang,Hongyuan Dong,Haiyang Yu,Dingkang Yang,Jiacong Wang,Han Wang,Wenzhuo Liu,Xiao Liang,Shuicheng Yan,Chao Feng*

Main category: cs.CV

TL;DR: SAIL-VL2是一种先进的视觉-语言基础模型，通过大规模数据筛选、渐进式训练框架和稀疏专家混合设计，在多种基准测试中取得领先性能。


<details>
  <summary>Details</summary>
Motivation: 提升多模态理解和推理能力，推动开源多模态社区发展。

Method: 采用大规模数据筛选、渐进式训练框架和稀疏专家混合设计。

Result: 在106个数据集上表现优异，尤其在MMMU和MathVista等推理任务中领先。

Conclusion: SAIL-VL2是高效、可扩展的开源多模态基础模型，性能卓越。

Abstract: We introduce SAIL-VL2, an open-suite vision-language foundation model (LVM)
for comprehensive multimodal understanding and reasoning. As the successor to
SAIL-VL, SAIL-VL2 achieves state-of-the-art performance at the 2B and 8B
parameter scales across diverse image and video benchmarks, demonstrating
strong capabilities from fine-grained perception to complex reasoning. Three
core innovations drive its effectiveness. First, a large-scale data curation
pipeline with scoring and filtering strategies enhances both quality and
distribution across captioning, OCR, QA, and video data, improving training
efficiency. Second, a progressive training framework begins with a powerful
pre-trained vision encoder (SAIL-ViT), advances through multimodal
pre-training, and culminates in a thinking-fusion SFT-RL hybrid paradigm that
systematically strengthens model capabilities. Third, architectural advances
extend beyond dense LLMs to efficient sparse Mixture-of-Experts (MoE) designs.
With these contributions, SAIL-VL2 demonstrates competitive performance across
106 datasets and achieves state-of-the-art results on challenging reasoning
benchmarks such as MMMU and MathVista. Furthermore, on the OpenCompass
leaderboard, SAIL-VL2-2B ranks first among officially released open-source
models under the 4B parameter scale, while serving as an efficient and
extensible foundation for the open-source multimodal community.

</details>


### [69] [PROFUSEme: PROstate Cancer Biochemical Recurrence Prediction via FUSEd Multi-modal Embeddings](https://arxiv.org/abs/2509.14051)
*Suhang You,Carla Pitarch-Abaigar,Sanket Kachole,Sumedh Sonawane,Juhyung Ha,Anish Sudarshan Gada,David Crandall,Rakesh Shiradkar,Spyridon Bakas*

Main category: cs.CV

TL;DR: PROFUSEme模型通过融合多模态数据（临床、放射学和病理学）来预测前列腺癌术后生化复发（BCR），表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 约30%的前列腺癌患者在根治性前列腺切除术后会经历生化复发（BCR），早期准确预测BCR有助于改善临床决策和患者预后。

Method: 提出PROFUSEme模型，采用中间融合策略结合Cox比例风险回归，学习多模态数据的跨模态交互。

Result: 模型在内部5折交叉验证中C-index为0.861，在CHIMERA 2025挑战赛验证集上为0.7103，优于晚期融合配置。

Conclusion: PROFUSEme通过多模态数据融合显著提升了BCR预测的准确性，具有临床实用价值。

Abstract: Almost 30% of prostate cancer (PCa) patients undergoing radical prostatectomy
(RP) experience biochemical recurrence (BCR), characterized by increased
prostate specific antigen (PSA) and associated with increased mortality.
Accurate early prediction of BCR, at the time of RP, would contribute to prompt
adaptive clinical decision-making and improved patient outcomes. In this work,
we propose prostate cancer BCR prediction via fused multi-modal embeddings
(PROFUSEme), which learns cross-modal interactions of clinical, radiology, and
pathology data, following an intermediate fusion configuration in combination
with Cox Proportional Hazard regressors. Quantitative evaluation of our
proposed approach reveals superior performance, when compared with late fusion
configurations, yielding a mean C-index of 0.861 ($\sigma=0.112$) on the
internal 5-fold nested cross-validation framework, and a C-index of 0.7103 on
the hold out data of CHIMERA 2025 challenge validation leaderboard.

</details>


### [70] [Wan-Animate: Unified Character Animation and Replacement with Holistic Replication](https://arxiv.org/abs/2509.14055)
*Gang Cheng,Xin Gao,Li Hu,Siqi Hu,Mingyang Huang,Chaonan Ji,Ju Li,Dechao Meng,Jinwei Qi,Penchong Qiao,Zhen Shen,Yafei Song,Ke Sun,Linrui Tian,Feng Wang,Guangyuan Wang,Qi Wang,Zhongjian Wang,Jiayu Xiao,Sheng Xu,Bang Zhang,Peng Zhang,Xindi Zhang,Zhe Zhang,Jingren Zhou,Lian Zhuo*

Main category: cs.CV

TL;DR: Wan-Animate是一个统一的角色动画和替换框架，能够根据参考视频生成高保真角色动画或替换原视频中的角色。


<details>
  <summary>Details</summary>
Motivation: 解决角色动画和替换任务中的高保真生成和环境无缝集成问题。

Method: 基于Wan模型，采用改进的输入范式区分参考条件和生成区域，结合空间对齐的骨骼信号和隐式面部特征，并开发辅助的Relighting LoRA模块。

Result: 实验结果表明Wan-Animate达到了最先进的性能。

Conclusion: Wan-Animate在角色动画和替换任务中表现出色，作者承诺开源模型权重和源代码。

Abstract: We introduce Wan-Animate, a unified framework for character animation and
replacement. Given a character image and a reference video, Wan-Animate can
animate the character by precisely replicating the expressions and movements of
the character in the video to generate high-fidelity character videos.
Alternatively, it can integrate the animated character into the reference video
to replace the original character, replicating the scene's lighting and color
tone to achieve seamless environmental integration. Wan-Animate is built upon
the Wan model. To adapt it for character animation tasks, we employ a modified
input paradigm to differentiate between reference conditions and regions for
generation. This design unifies multiple tasks into a common symbolic
representation. We use spatially-aligned skeleton signals to replicate body
motion and implicit facial features extracted from source images to reenact
expressions, enabling the generation of character videos with high
controllability and expressiveness. Furthermore, to enhance environmental
integration during character replacement, we develop an auxiliary Relighting
LoRA. This module preserves the character's appearance consistency while
applying the appropriate environmental lighting and color tone. Experimental
results demonstrate that Wan-Animate achieves state-of-the-art performance. We
are committed to open-sourcing the model weights and its source code.

</details>


### [71] [VSE-MOT: Multi-Object Tracking in Low-Quality Video Scenes Guided by Visual Semantic Enhancement](https://arxiv.org/abs/2509.14060)
*Jun Du,Weiwei Xing,Ming Li,Fei Richard Yu*

Main category: cs.CV

TL;DR: 提出了一种基于视觉语义增强的多目标跟踪框架（VSE-MOT），用于解决低质量视频中的跟踪性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 现有MOT算法在低质量视频中性能显著下降，亟需提升其在真实场景中的应用能力。

Method: 设计了三分支架构，结合视觉语言模型提取全局视觉语义信息，并引入MOT-Adapter和VSFM模块优化特征融合。

Result: 在低质量视频场景中，跟踪性能指标比现有方法提升8%至20%，且在常规场景中表现稳健。

Conclusion: VSE-MOT框架有效提升了MOT算法在低质量视频中的性能，具有实际应用价值。

Abstract: Current multi-object tracking (MOT) algorithms typically overlook issues
inherent in low-quality videos, leading to significant degradation in tracking
performance when confronted with real-world image deterioration. Therefore,
advancing the application of MOT algorithms in real-world low-quality video
scenarios represents a critical and meaningful endeavor. To address the
challenges posed by low-quality scenarios, inspired by vision-language models,
this paper proposes a Visual Semantic Enhancement-guided Multi-Object Tracking
framework (VSE-MOT). Specifically, we first design a tri-branch architecture
that leverages a vision-language model to extract global visual semantic
information from images and fuse it with query vectors. Subsequently, to
further enhance the utilization of visual semantic information, we introduce
the Multi-Object Tracking Adapter (MOT-Adapter) and the Visual Semantic Fusion
Module (VSFM). The MOT-Adapter adapts the extracted global visual semantic
information to suit multi-object tracking tasks, while the VSFM improves the
efficacy of feature fusion. Through extensive experiments, we validate the
effectiveness and superiority of the proposed method in real-world low-quality
video scenarios. Its tracking performance metrics outperform those of existing
methods by approximately 8% to 20%, while maintaining robust performance in
conventional scenarios.

</details>


### [72] [AD-DINOv3: Enhancing DINOv3 for Zero-Shot Anomaly Detection with Anomaly-Aware Calibration](https://arxiv.org/abs/2509.14084)
*Jingyi Yuan,Jianxiong Ye,Wenkang Chen,Chenqiang Gao*

Main category: cs.CV

TL;DR: AD-DINOv3是一种基于DINOv3的零样本异常检测框架，通过多模态对比学习和异常感知校准模块解决特征对齐和语义偏差问题，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统零样本异常检测方法依赖CLIP模型，但DINOv3等视觉基础模型具有更强的迁移能力，然而直接应用存在特征对齐和语义偏差问题。

Method: 提出AD-DINOv3框架，结合DINOv3视觉骨干和CLIP文本编码器，引入轻量适配器和异常感知校准模块（AACM）优化特征表示。

Result: 在八个工业和医学基准测试中，AD-DINOv3表现优于或匹配现有最优方法。

Conclusion: AD-DINOv3是一种通用的零样本异常检测框架，解决了特征对齐和语义偏差问题，具有广泛适用性。

Abstract: Zero-Shot Anomaly Detection (ZSAD) seeks to identify anomalies from arbitrary
novel categories, offering a scalable and annotation-efficient solution.
Traditionally, most ZSAD works have been based on the CLIP model, which
performs anomaly detection by calculating the similarity between visual and
text embeddings. Recently, vision foundation models such as DINOv3 have
demonstrated strong transferable representation capabilities. In this work, we
are the first to adapt DINOv3 for ZSAD. However, this adaptation presents two
key challenges: (i) the domain bias between large-scale pretraining data and
anomaly detection tasks leads to feature misalignment; and (ii) the inherent
bias toward global semantics in pretrained representations often leads to
subtle anomalies being misinterpreted as part of the normal foreground objects,
rather than being distinguished as abnormal regions. To overcome these
challenges, we introduce AD-DINOv3, a novel vision-language multimodal
framework designed for ZSAD. Specifically, we formulate anomaly detection as a
multimodal contrastive learning problem, where DINOv3 is employed as the visual
backbone to extract patch tokens and a CLS token, and the CLIP text encoder
provides embeddings for both normal and abnormal prompts. To bridge the domain
gap, lightweight adapters are introduced in both modalities, enabling their
representations to be recalibrated for the anomaly detection task. Beyond this
baseline alignment, we further design an Anomaly-Aware Calibration Module
(AACM), which explicitly guides the CLS token to attend to anomalous regions
rather than generic foreground semantics, thereby enhancing discriminability.
Extensive experiments on eight industrial and medical benchmarks demonstrate
that AD-DINOv3 consistently matches or surpasses state-of-the-art methods,
verifying its superiority as a general zero-shot anomaly detection framework.

</details>


### [73] [Teacher-Guided Pseudo Supervision and Cross-Modal Alignment for Audio-Visual Video Parsing](https://arxiv.org/abs/2509.14097)
*Yaru Chen,Ruohao Guo,Liting Gao,Yang Xiang,Qingyu Luo,Zhenbo Li,Wenwu Wang*

Main category: cs.CV

TL;DR: 提出两种策略改进弱监督音频-视觉视频解析：EMA引导的伪监督框架和类感知跨模态一致性损失，实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法忽视段级监督和类感知跨模态对齐的问题。

Method: 1. EMA引导的伪监督框架生成可靠段级掩码；2. 类感知跨模态一致性损失对齐音频和视觉嵌入。

Result: 在LLP和UnAV-100数据集上实现SOTA性能。

Conclusion: 提出的方法有效提升弱监督音频-视觉视频解析性能。

Abstract: Weakly-supervised audio-visual video parsing (AVVP) seeks to detect audible,
visible, and audio-visual events without temporal annotations. Previous work
has emphasized refining global predictions through contrastive or collaborative
learning, but neglected stable segment-level supervision and class-aware
cross-modal alignment. To address this, we propose two strategies: (1) an
exponential moving average (EMA)-guided pseudo supervision framework that
generates reliable segment-level masks via adaptive thresholds or top-k
selection, offering stable temporal guidance beyond video-level labels; and (2)
a class-aware cross-modal agreement (CMA) loss that aligns audio and visual
embeddings at reliable segment-class pairs, ensuring consistency across
modalities while preserving temporal structure. Evaluations on LLP and UnAV-100
datasets shows that our method achieves state-of-the-art (SOTA) performance
across multiple metrics.

</details>


### [74] [CSMoE: An Efficient Remote Sensing Foundation Model with Soft Mixture-of-Experts](https://arxiv.org/abs/2509.14104)
*Leonard Hackel,Tom Burgert,Begüm Demir*

Main category: cs.CV

TL;DR: 提出了一种通过集成Soft MoE机制提升遥感基础模型效率的方法，CSMoE模型在计算效率和性能上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有遥感基础模型存在计算复杂度高或表示能力有限的问题，限制了实际应用。

Method: 将Soft MoE机制集成到基础模型中，并结合主题-气候描述符驱动的采样策略构建训练集。

Result: CSMoE模型在计算效率上提升两倍以上，同时保持或提升性能。

Conclusion: 该方法有效提升了遥感基础模型的计算效率，同时保持了高性能。

Abstract: Self-supervised learning through masked autoencoders has attracted great
attention for remote sensing (RS) foundation model (FM) development, enabling
improved representation learning across diverse sensors and downstream tasks.
However, existing RS FMs often either suffer from substantial computational
complexity during both training and inference or exhibit limited
representational capacity. These issues restrict their practical applicability
in RS. To address this limitation, we propose an adaptation for enhancing the
efficiency of RS FMs by integrating the Soft mixture-of-experts (MoE) mechanism
into the FM. The integration of Soft MoEs into the FM allows modality-specific
expert specialization alongside shared cross-sensor representation learning. To
demonstrate the effectiveness of our adaptation, we apply it on the
Cross-Sensor Masked Autoencoder (CSMAE) model, resulting in the Cross-Sensor
Mixture-of-Experts (CSMoE) model. In addition, we introduce a thematic-climatic
descriptor-driven sampling strategy for the construction of a representative
and diverse training set to train our CSMoE model. Extensive experiments on
scene classification, semantic segmentation, and content-based image retrieval
demonstrate that our adaptation yields a reduction in computational
requirements while maintaining or improving representational performance.
Compared to state-of-the-art RS FMs, CSMoE achieves a superior trade-off
between representational capacity, accuracy, and computational efficiency. On
average, CSMoE achieves more than twice the computational efficiency of
existing RS FMs, while maintaining competitive performance across all
experiments. These results show the effectiveness of the proposed adaptation
for creating computationally efficient RS FMs. The code for the model, the
training set creation, and the model weights will be available at
https://git.tu-berlin.de/rsim/csmoe.

</details>


### [75] [Generative AI for Misalignment-Resistant Virtual Staining to Accelerate Histopathology Workflows](https://arxiv.org/abs/2509.14119)
*Jiabo MA,Wenqiang Li,Jinbang Li,Ziyi Liu,Linshan Wu,Fengtao Zhou,Li Liang,Ronald Cheong Kin Chan,Terence T. W. Wong,Hao Chen*

Main category: cs.CV

TL;DR: 提出了一种基于级联配准机制的虚拟染色框架，解决了现有方法因数据对齐问题导致的性能限制，显著提升了染色准确性。


<details>
  <summary>Details</summary>
Motivation: 传统组织染色方法耗时、耗力且不环保，虚拟染色虽有潜力但受限于数据对齐问题。

Method: 采用级联配准机制解决生成输出与真实数据间的空间不匹配问题。

Result: 在五个数据集上显著优于现有方法，内部数据集平均提升3.2%，外部数据集提升10.1%，严重不对齐数据集PSNR提升23.8%。

Conclusion: 该方法简化了虚拟染色的数据获取流程，为技术发展提供了新思路。

Abstract: Accurate histopathological diagnosis often requires multiple differently
stained tissue sections, a process that is time-consuming, labor-intensive, and
environmentally taxing due to the use of multiple chemical stains. Recently,
virtual staining has emerged as a promising alternative that is faster,
tissue-conserving, and environmentally friendly. However, existing virtual
staining methods face significant challenges in clinical applications,
primarily due to their reliance on well-aligned paired data. Obtaining such
data is inherently difficult because chemical staining processes can distort
tissue structures, and a single tissue section cannot undergo multiple staining
procedures without damage or loss of information. As a result, most available
virtual staining datasets are either unpaired or roughly paired, making it
difficult for existing methods to achieve accurate pixel-level supervision. To
address this challenge, we propose a robust virtual staining framework
featuring cascaded registration mechanisms to resolve spatial mismatches
between generated outputs and their corresponding ground truth. Experimental
results demonstrate that our method significantly outperforms state-of-the-art
models across five datasets, achieving an average improvement of 3.2% on
internal datasets and 10.1% on external datasets. Moreover, in datasets with
substantial misalignment, our approach achieves a remarkable 23.8% improvement
in peak signal-to-noise ratio compared to baseline models. The exceptional
robustness of the proposed method across diverse datasets simplifies the data
acquisition process for virtual staining and offers new insights for advancing
its development.

</details>


### [76] [Deceptive Beauty: Evaluating the Impact of Beauty Filters on Deepfake and Morphing Attack Detection](https://arxiv.org/abs/2509.14120)
*Sara Concas,Simone Maurizio La Cava,Andrea Panzino,Ester Masala,Giulia Orrù,Gian Luca Marcialis*

Main category: cs.CV

TL;DR: 研究探讨了美颜滤镜对深度伪造和变形攻击检测器性能的影响，发现滤镜会导致检测性能下降。


<details>
  <summary>Details</summary>
Motivation: 社交媒体滤镜的普及引发了对人脸图像和视频可靠性的担忧，尤其是对自动化人脸分析的准确性提出了挑战。

Method: 通过评估多个先进检测器在应用平滑滤镜前后的性能，进行了全面分析。

Result: 结果显示性能下降，揭示了面部增强引入的漏洞。

Conclusion: 需要开发更鲁棒的检测模型以应对此类面部修饰。

Abstract: Digital beautification through social media filters has become increasingly
popular, raising concerns about the reliability of facial images and videos and
the effectiveness of automated face analysis. This issue is particularly
critical for digital manipulation detectors, systems aiming at distinguishing
between genuine and manipulated data, especially in cases involving deepfakes
and morphing attacks designed to deceive humans and automated facial
recognition. This study examines whether beauty filters impact the performance
of deepfake and morphing attack detectors. We perform a comprehensive analysis,
evaluating multiple state-of-the-art detectors on benchmark datasets before and
after applying various smoothing filters. Our findings reveal performance
degradation, highlighting vulnerabilities introduced by facial enhancements and
underscoring the need for robust detection models resilient to such
alterations.

</details>


### [77] [Dense Video Understanding with Gated Residual Tokenization](https://arxiv.org/abs/2509.14199)
*Haichao Zhang,Wenhao Chai,Shwai He,Ang Li,Yun Fu*

Main category: cs.CV

TL;DR: 论文提出了Dense Video Understanding (DVU)和Gated Residual Tokenization (GRT)方法，用于高效处理高帧率视频理解任务，并提出了DIVE基准测试。


<details>
  <summary>Details</summary>
Motivation: 当前视频大语言模型(VLLMs)和基准测试主要依赖低帧率采样，忽略了密集时间信息，导致在需要精确时间对齐的任务（如讲座理解）中表现不佳。

Method: 提出了GRT框架，包括两阶段：(1) 运动补偿的帧间门控标记化，跳过静态区域；(2) 语义场景的帧内标记化合并，减少冗余。

Result: 在DIVE基准测试中，GRT优于更大的VLLM基线模型，且性能随帧率提升而提高。

Conclusion: 密集时间信息对视频理解至关重要，GRT方法能够高效、可扩展地处理高帧率视频任务。

Abstract: High temporal resolution is essential for capturing fine-grained details in
video understanding. However, current video large language models (VLLMs) and
benchmarks mostly rely on low-frame-rate sampling, such as uniform sampling or
keyframe selection, discarding dense temporal information. This compromise
avoids the high cost of tokenizing every frame, which otherwise leads to
redundant computation and linear token growth as video length increases. While
this trade-off works for slowly changing content, it fails for tasks like
lecture comprehension, where information appears in nearly every frame and
requires precise temporal alignment. To address this gap, we introduce Dense
Video Understanding (DVU), which enables high-FPS video comprehension by
reducing both tokenization time and token overhead. Existing benchmarks are
also limited, as their QA pairs focus on coarse content changes. We therefore
propose DIVE (Dense Information Video Evaluation), the first benchmark designed
for dense temporal reasoning. To make DVU practical, we present Gated Residual
Tokenization (GRT), a two-stage framework: (1) Motion-Compensated Inter-Gated
Tokenization uses pixel-level motion estimation to skip static regions during
tokenization, achieving sub-linear growth in token count and compute. (2)
Semantic-Scene Intra-Tokenization Merging fuses tokens across static regions
within a scene, further reducing redundancy while preserving dynamic semantics.
Experiments on DIVE show that GRT outperforms larger VLLM baselines and scales
positively with FPS. These results highlight the importance of dense temporal
information and demonstrate that GRT enables efficient, scalable high-FPS video
understanding.

</details>


### [78] [MARS2 2025 Challenge on Multimodal Reasoning: Datasets, Methods, Results, Discussion, and Outlook](https://arxiv.org/abs/2509.14142)
*Peng Xu,Shengwu Xiong,Jiajun Zhang,Yaxiong Chen,Bowen Zhou,Chen Change Loy,David A. Clifton,Kyoung Mu Lee,Luc Van Gool,Ruiming He,Ruilin Yao,Xinwei Long,Jirui Huang,Kai Tian,Sa Yang,Yihua Shao,Jin Feng,Yue Zhong,Jiakai Zhou,Cheng Tang,Tianyu Zou,Yifang Zhang,Junming Liang,Guoyou Li,Zhaoxiang Wang,Qiang Zhou,Yichen Zhao,Shili Xiong,Hyeongjin Nam,Jaerin Lee,Jaeyoung Chung,JoonKyu Park,Junghun Oh,Kanggeon Lee,Wooseok Lee,Juneyoung Ro,Turghun Osman,Can Hu,Chaoyang Liao,Cheng Chen,Chengcheng Han,Chenhao Qiu,Chong Peng,Cong Xu,Dailin Li,Feiyu Wang,Feng Gao,Guibo Zhu,Guopeng Tang,Haibo Lu,Han Fang,Han Qi,Hanxiao Wu,Haobo Cheng,Hongbo Sun,Hongyao Chen,Huayong Hu,Hui Li,Jiaheng Ma,Jiang Yu,Jianing Wang,Jie Yang,Jing He,Jinglin Zhou,Jingxuan Li,Josef Kittler,Lihao Zheng,Linnan Zhao,Mengxi Jia,Muyang Yan,Nguyen Thanh Thien,Pu Luo,Qi Li,Shien Song,Shijie Dong,Shuai Shao,Shutao Li,Taofeng Xue,Tianyang Xu,Tianyi Gao,Tingting Li,Wei Zhang,Weiyang Su,Xiaodong Dong,Xiao-Jun Wu,Xiaopeng Zhou,Xin Chen,Xin Wei,Xinyi You,Xudong Kang,Xujie Zhou,Xusheng Liu,Yanan Wang,Yanbin Huang,Yang Liu,Yang Yang,Yanglin Deng,Yashu Kang,Ye Yuan,Yi Wen,Yicen Tian,Yilin Tao,Yin Tang,Yipeng Lin,Yiqing Wang,Yiting Xi,Yongkang Yu,Yumei Li,Yuxin Qin,Yuying Chen,Yuzhe Cen,Zhaofan Zou,Zhaohong Liu,Zhehao Shen,Zhenglin Du,Zhengyang Li,Zhenni Huang,Zhenwei Shao,Zhilong Song,Zhiyong Feng,Zhiyu Wang,Zhou Yu,Ziang Li,Zihan Zhai,Zijian Zhang,Ziyang Peng,Ziyun Xiao,Zongshu Li*

Main category: cs.CV

TL;DR: MARS2 2025挑战赛聚焦多模态推理，通过新数据集和竞赛推动多模态机器学习与LLMs的发展。


<details>
  <summary>Details</summary>
Motivation: 整合多模态机器学习和LLMs的最新进展，提供大规模基准测试以跟踪动态领域的前沿技术。

Method: 发布两个定制数据集Lens和AdsQA，评估40多个基线模型，并开设三个竞赛赛道。

Result: 吸引了76个团队注册，40多个有效提交纳入排名，数据集和代码公开。

Conclusion: MARS2挑战赛成功推动了多模态推理在实际和专业化场景中的应用，资源公开促进后续研究。

Abstract: This paper reviews the MARS2 2025 Challenge on Multimodal Reasoning. We aim
to bring together different approaches in multimodal machine learning and LLMs
via a large benchmark. We hope it better allows researchers to follow the
state-of-the-art in this very dynamic area. Meanwhile, a growing number of
testbeds have boosted the evolution of general-purpose large language models.
Thus, this year's MARS2 focuses on real-world and specialized scenarios to
broaden the multimodal reasoning applications of MLLMs. Our organizing team
released two tailored datasets Lens and AdsQA as test sets, which support
general reasoning in 12 daily scenarios and domain-specific reasoning in
advertisement videos, respectively. We evaluated 40+ baselines that include
both generalist MLLMs and task-specific models, and opened up three competition
tracks, i.e., Visual Grounding in Real-world Scenarios (VG-RS), Visual Question
Answering with Spatial Awareness (VQA-SA), and Visual Reasoning in Creative
Advertisement Videos (VR-Ads). Finally, 76 teams from the renowned academic and
industrial institutions have registered and 40+ valid submissions (out of
1200+) have been included in our ranking lists. Our datasets, code sets (40+
baselines and 15+ participants' methods), and rankings are publicly available
on the MARS2 workshop website and our GitHub organization page
https://github.com/mars2workshop/, where our updates and announcements of
upcoming events will be continuously provided.

</details>


### [79] [An Exploratory Study on Abstract Images and Visual Representations Learned from Them](https://arxiv.org/abs/2509.14149)
*Haotian Li,Jianbo Jiao*

Main category: cs.CV

TL;DR: 论文研究了抽象图像（由基本形状构成）与传统栅格图像在视觉语义信息传递上的性能差距，并探讨了不同抽象层次下高语义内容的捕捉能力。


<details>
  <summary>Details</summary>
Motivation: 探索抽象图像是否能有效传递视觉语义信息，并分析其与传统栅格图像的表现差异。

Method: 引入分层抽象图像数据集（HAID），在不同抽象层次上生成抽象图像，并在分类、分割和检测任务上评估传统视觉系统。

Result: 研究发现抽象图像能传递部分语义信息，但性能仍不及传统栅格图像。

Conclusion: 抽象图像可作为视觉语义信息的潜在有效格式，但需进一步优化以缩小与传统图像的差距。

Abstract: Imagine living in a world composed solely of primitive shapes, could you
still recognise familiar objects? Recent studies have shown that abstract
images-constructed by primitive shapes-can indeed convey visual semantic
information to deep learning models. However, representations obtained from
such images often fall short compared to those derived from traditional raster
images. In this paper, we study the reasons behind this performance gap and
investigate how much high-level semantic content can be captured at different
abstraction levels. To this end, we introduce the Hierarchical Abstraction
Image Dataset (HAID), a novel data collection that comprises abstract images
generated from normal raster images at multiple levels of abstraction. We then
train and evaluate conventional vision systems on HAID across various tasks
including classification, segmentation, and object detection, providing a
comprehensive study between rasterised and abstract image representations. We
also discuss if the abstract image can be considered as a potentially effective
format for conveying visual semantic information and contributing to vision
tasks.

</details>


### [80] [BEVUDA++: Geometric-aware Unsupervised Domain Adaptation for Multi-View 3D Object Detection](https://arxiv.org/abs/2509.14151)
*Rongyu Zhang,Jiaming Liu,Xiaoqi Li,Xiaowei Chi,Dan Wang,Li Du,Yuan Du,Shanghang Zhang*

Main category: cs.CV

TL;DR: 论文提出BEVUDA++框架，解决BEV感知中的域适应问题，通过几何感知的师生模型和不确定性引导方法提升跨域3D目标检测性能。


<details>
  <summary>Details</summary>
Motivation: BEV感知在自动驾驶中潜力巨大，但跨域场景中的域偏移问题被忽视，导致性能下降。论文首次针对多视角3D目标检测的域适应挑战展开研究。

Method: 提出BEVUDA++框架，包含可靠深度教师（RDT）和几何一致学生（GCS）模型，结合不确定性引导的指数移动平均（UEMA）减少域偏移累积。

Result: 在四个跨域场景中实验，BEV 3D目标检测任务表现优异，例如在昼夜适应任务中NDS提升12.9%，mAP提升9.5%。

Conclusion: BEVUDA++通过几何感知和不确定性引导有效缓解域偏移问题，为BEV感知的域适应提供了新思路。

Abstract: Vision-centric Bird's Eye View (BEV) perception holds considerable promise
for autonomous driving. Recent studies have prioritized efficiency or accuracy
enhancements, yet the issue of domain shift has been overlooked, leading to
substantial performance degradation upon transfer. We identify major domain
gaps in real-world cross-domain scenarios and initiate the first effort to
address the Domain Adaptation (DA) challenge in multi-view 3D object detection
for BEV perception. Given the complexity of BEV perception approaches with
their multiple components, domain shift accumulation across multi-geometric
spaces (e.g., 2D, 3D Voxel, BEV) poses a significant challenge for BEV domain
adaptation. In this paper, we introduce an innovative geometric-aware
teacher-student framework, BEVUDA++, to diminish this issue, comprising a
Reliable Depth Teacher (RDT) and a Geometric Consistent Student (GCS) model.
Specifically, RDT effectively blends target LiDAR with dependable depth
predictions to generate depth-aware information based on uncertainty
estimation, enhancing the extraction of Voxel and BEV features that are
essential for understanding the target domain. To collaboratively reduce the
domain shift, GCS maps features from multiple spaces into a unified geometric
embedding space, thereby narrowing the gap in data distribution between the two
domains. Additionally, we introduce a novel Uncertainty-guided Exponential
Moving Average (UEMA) to further reduce error accumulation due to domain shifts
informed by previously obtained uncertainty guidance. To demonstrate the
superiority of our proposed method, we execute comprehensive experiments in
four cross-domain scenarios, securing state-of-the-art performance in BEV 3D
object detection tasks, e.g., 12.9\% NDS and 9.5\% mAP enhancement on Day-Night
adaptation.

</details>


### [81] [Where Do Tokens Go? Understanding Pruning Behaviors in STEP at High Resolutions](https://arxiv.org/abs/2509.14165)
*Michal Szczepanski,Martyna Poreba,Karim Haroun*

Main category: cs.CV

TL;DR: STEP框架结合动态补丁合并和令牌剪枝，显著降低Vision Transformers的计算和内存成本，同时保持高精度。


<details>
  <summary>Details</summary>
Motivation: 解决Vision Transformers在语义分割中计算和内存成本高的问题。

Method: 提出STEP框架，结合动态补丁合并（dCTS）和早期剪枝，减少令牌数量并降低计算负载。

Result: 在1024x1024图像上，令牌数量减少2.5倍，计算成本降低2.6倍，吞吐量提高3.4倍；完整STEP框架进一步将计算复杂度降低4倍，推理速度提升1.7倍，精度损失不超过2%。

Conclusion: STEP框架有效平衡了效率和精度，适用于高分辨率语义分割任务。

Abstract: Vision Transformers (ViTs) achieve state-of-the-art performance in semantic
segmentation but are hindered by high computational and memory costs. To
address this, we propose STEP (SuperToken and Early-Pruning), a hybrid
token-reduction framework that combines dynamic patch merging and token pruning
to enhance efficiency without significantly compromising accuracy. At the core
of STEP is dCTS, a lightweight CNN-based policy network that enables flexible
merging into superpatches. Encoder blocks integrate also early-exits to remove
high-confident supertokens, lowering computational load. We evaluate our method
on high-resolution semantic segmentation benchmarks, including images up to
1024 x 1024, and show that when dCTS is applied alone, the token count can be
reduced by a factor of 2.5 compared to the standard 16 x 16 pixel patching
scheme. This yields a 2.6x reduction in computational cost and a 3.4x increase
in throughput when using ViT-Large as the backbone. Applying the full STEP
framework further improves efficiency, reaching up to a 4x reduction in
computational complexity and a 1.7x gain in inference speed, with a maximum
accuracy drop of no more than 2.0%. With the proposed STEP configurations, up
to 40% of tokens can be confidently predicted and halted before reaching the
final encoder layer.

</details>


### [82] [Cinéaste: A Fine-grained Contextual Movie Question Answering Benchmark](https://arxiv.org/abs/2509.14227)
*Nisarg A. Shah,Amir Ziai,Chaitanya Ekanadham,Vishal M. Patel*

Main category: cs.CV

TL;DR: 论文提出了一个名为$\mathsf{Cin\acute{e}aste}$的新基准测试，用于评估长视频叙事理解能力，填补了现有测试在细粒度推理上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注短视频识别或模板化问题，缺乏对长视频叙事内容的细粒度推理评估。

Method: 通过GPT-4o生成多样化的上下文丰富问题，并采用两阶段过滤流程确保问题质量。

Result: 实验表明现有模型在$\mathsf{Cin\acute{e}aste}$上表现不佳，最高准确率仅63.15%，长时序推理是主要瓶颈。

Conclusion: 该研究揭示了长视频细粒度理解的挑战，并呼吁进一步改进长视频叙事理解技术。

Abstract: While recent advancements in vision-language models have improved video
understanding, diagnosing their capacity for deep, narrative comprehension
remains a challenge. Existing benchmarks often test short-clip recognition or
use template-based questions, leaving a critical gap in evaluating fine-grained
reasoning over long-form narrative content. To address these gaps, we introduce
$\mathsf{Cin\acute{e}aste}$, a comprehensive benchmark for long-form movie
understanding. Our dataset comprises 3,119 multiple-choice question-answer
pairs derived from 1,805 scenes across 200 diverse movies, spanning five novel
fine-grained contextual reasoning categories. We use GPT-4o to generate
diverse, context-rich questions by integrating visual descriptions, captions,
scene titles, and summaries, which require deep narrative understanding. To
ensure high-quality evaluation, our pipeline incorporates a two-stage filtering
process: Context-Independence filtering ensures questions require video
context, while Contextual Veracity filtering validates factual consistency
against the movie content, mitigating hallucinations. Experiments show that
existing MLLMs struggle on $\mathsf{Cin\acute{e}aste}$; our analysis reveals
that long-range temporal reasoning is a primary bottleneck, with the top
open-source model achieving only 63.15\% accuracy. This underscores significant
challenges in fine-grained contextual understanding and the need for
advancements in long-form movie comprehension.

</details>


### [83] [GenExam: A Multidisciplinary Text-to-Image Exam](https://arxiv.org/abs/2509.14232)
*Zhaokai Wang,Penghao Yin,Xiangyu Zhao,Changyao Tian,Yu Qiao,Wenhai Wang,Jifeng Dai,Gen Luo*

Main category: cs.CV

TL;DR: GenExam是首个多学科文本到图像考试基准，包含10个学科的1000个样本，用于评估模型在知识整合、推理和生成方面的能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注理解和推理任务，而生成基准则忽视了对严格绘图考试的评估，GenExam填补了这一空白。

Method: GenExam包含1000个样本，分为10个学科，采用四层分类法组织考试式提示，并提供真实图像和细粒度评分点。

Result: 实验显示，即使是先进模型如GPT-Image-1和Gemini-2.5-Flash-Image，严格得分也低于15%，大多数模型接近0%。

Conclusion: GenExam通过将图像生成视为考试，为评估模型在知识整合、推理和生成方面的能力提供了严格标准，为通用AGI的发展提供了见解。

Abstract: Exams are a fundamental test of expert-level intelligence and require
integrated understanding, reasoning, and generation. Existing exam-style
benchmarks mainly focus on understanding and reasoning tasks, and current
generation benchmarks emphasize the illustration of world knowledge and visual
concepts, neglecting the evaluation of rigorous drawing exams. We introduce
GenExam, the first benchmark for multidisciplinary text-to-image exams,
featuring 1,000 samples across 10 subjects with exam-style prompts organized
under a four-level taxonomy. Each problem is equipped with ground-truth images
and fine-grained scoring points to enable a precise evaluation of semantic
correctness and visual plausibility. Experiments show that even
state-of-the-art models such as GPT-Image-1 and Gemini-2.5-Flash-Image achieve
less than 15% strict scores, and most models yield almost 0%, suggesting the
great challenge of our benchmark. By framing image generation as an exam,
GenExam offers a rigorous assessment of models' ability to integrate knowledge,
reasoning, and generation, providing insights on the path to general AGI.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [84] [Unified Spatiotemopral Physics-Informed Learning (USPIL): A Framework for Modeling Complex Predator-Prey Dynamics](https://arxiv.org/abs/2509.13425)
*Julian Evan Chrisnanto,Yulison Herry Chrisnanto,Ferry Faizal*

Main category: cs.LG

TL;DR: USPIL框架结合物理约束和深度学习，统一建模生态系统的时空动态，显著提升计算效率和精度。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以捕捉生态系统的多尺度动态，需新方法兼顾时间振荡和空间模式。

Method: USPIL整合PINNs和守恒定律，通过自动微分和自适应损失加权统一ODE/PDE建模。

Result: 在Lotka-Volterra系统中，1D动态相关性达98.9%，2D螺旋波模式相关性0.94，计算加速10-50倍。

Conclusion: USPIL为生态建模提供高效、可解释的工具，推动物理信息深度学习在生态学中的应用。

Abstract: Ecological systems exhibit complex multi-scale dynamics that challenge
traditional modeling. New methods must capture temporal oscillations and
emergent spatiotemporal patterns while adhering to conservation principles. We
present the Unified Spatiotemporal Physics-Informed Learning (USPIL) framework,
a deep learning architecture integrating physics-informed neural networks
(PINNs) and conservation laws to model predator-prey dynamics across
dimensional scales. The framework provides a unified solution for both ordinary
(ODE) and partial (PDE) differential equation systems, describing temporal
cycles and reaction-diffusion patterns within a single neural network
architecture. Our methodology uses automatic differentiation to enforce physics
constraints and adaptive loss weighting to balance data fidelity with physical
consistency. Applied to the Lotka-Volterra system, USPIL achieves 98.9%
correlation for 1D temporal dynamics (loss: 0.0219, MAE: 0.0184) and captures
complex spiral waves in 2D systems (loss: 4.7656, pattern correlation: 0.94).
Validation confirms conservation law adherence within 0.5% and shows a 10-50x
computational speedup for inference compared to numerical solvers. USPIL also
enables mechanistic understanding through interpretable physics constraints,
facilitating parameter discovery and sensitivity analysis not possible with
purely data-driven methods. Its ability to transition between dimensional
formulations opens new avenues for multi-scale ecological modeling. These
capabilities make USPIL a transformative tool for ecological forecasting,
conservation planning, and understanding ecosystem resilience, establishing
physics-informed deep learning as a powerful and scientifically rigorous
paradigm.

</details>


### [85] [An Analysis of Optimizer Choice on Energy Efficiency and Performance in Neural Network Training](https://arxiv.org/abs/2509.13516)
*Tom Almog*

Main category: cs.LG

TL;DR: 论文研究了优化器选择对神经网络训练能效的影响，发现AdamW和NAdam是高效选择，而SGD在复杂数据集上表现更好但排放更高。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习模型日益复杂和计算需求增加，理解训练决策对环境的影响对可持续AI发展至关重要。

Method: 在三个基准数据集（MNIST、CIFAR-10、CIFAR-100）上进行了360次对照实验，使用八种优化器，并通过CodeCarbon精确跟踪能耗。

Result: AdamW和NAdam是高效选择，SGD在复杂数据集上表现更好但排放更高。

Conclusion: 研究结果为平衡性能和可持续性的机器学习工作流程提供了实用建议。

Abstract: As machine learning models grow increasingly complex and computationally
demanding, understanding the environmental impact of training decisions becomes
critical for sustainable AI development. This paper presents a comprehensive
empirical study investigating the relationship between optimizer choice and
energy efficiency in neural network training. We conducted 360 controlled
experiments across three benchmark datasets (MNIST, CIFAR-10, CIFAR-100) using
eight popular optimizers (SGD, Adam, AdamW, RMSprop, Adagrad, Adadelta, Adamax,
NAdam) with 15 random seeds each. Using CodeCarbon for precise energy tracking
on Apple M1 Pro hardware, we measured training duration, peak memory usage,
carbon dioxide emissions, and final model performance. Our findings reveal
substantial trade-offs between training speed, accuracy, and environmental
impact that vary across datasets and model complexity. We identify AdamW and
NAdam as consistently efficient choices, while SGD demonstrates superior
performance on complex datasets despite higher emissions. These results provide
actionable insights for practitioners seeking to balance performance and
sustainability in machine learning workflows.

</details>


### [86] [Learning Nonlinear Responses in PET Bottle Buckling with a Hybrid DeepONet-Transolver Framework](https://arxiv.org/abs/2509.13520)
*Varun Kumar,Jing Bi,Cyril Ngo Ngoc,Victor Oancea,George Em Karniadakis*

Main category: cs.LG

TL;DR: 提出了一种混合DeepONet-Transolver框架，用于解决PET瓶屈曲分析中的多任务预测问题，显著提高了计算效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在非参数几何域上的泛化能力有限，而PET瓶屈曲分析传统上依赖计算昂贵的有限元分析（FEA）。

Method: 采用混合DeepONet-Transolver框架，同时预测节点位移场和反应力的时间演化，数据通过非线性FEA模拟生成。

Result: 在四参数瓶家族中，位移场的平均相对L²误差为2.5-13%，时间相关反应力的误差约为2.4%，且能准确捕捉屈曲行为。

Conclusion: 该框架展示了在计算力学和多任务预测中的潜力，为快速设计评估提供了高效且可扩展的替代方案。

Abstract: Neural surrogates and operator networks for solving partial differential
equation (PDE) problems have attracted significant research interest in recent
years. However, most existing approaches are limited in their ability to
generalize solutions across varying non-parametric geometric domains. In this
work, we address this challenge in the context of Polyethylene Terephthalate
(PET) bottle buckling analysis, a representative packaging design problem
conventionally solved using computationally expensive finite element analysis
(FEA). We introduce a hybrid DeepONet-Transolver framework that simultaneously
predicts nodal displacement fields and the time evolution of reaction forces
during top load compression. Our methodology is evaluated on two families of
bottle geometries parameterized by two and four design variables. Training data
is generated using nonlinear FEA simulations in Abaqus for 254 unique designs
per family. The proposed framework achieves mean relative $L^{2}$ errors of
2.5-13% for displacement fields and approximately 2.4% for time-dependent
reaction forces for the four-parameter bottle family. Point-wise error analyses
further show absolute displacement errors on the order of $10^{-4}$-$10^{-3}$,
with the largest discrepancies confined to localized geometric regions.
Importantly, the model accurately captures key physical phenomena, such as
buckling behavior, across diverse bottle geometries. These results highlight
the potential of our framework as a scalable and computationally efficient
surrogate, particularly for multi-task predictions in computational mechanics
and applications requiring rapid design evaluation.

</details>


### [87] [AERIS: Argonne Earth Systems Model for Reliable and Skillful Predictions](https://arxiv.org/abs/2509.13523)
*Väinö Hatanpää,Eugene Ku,Jason Stock,Murali Emani,Sam Foreman,Chunyong Jung,Sandeep Madireddy,Tung Nguyen,Varuni Sastry,Ray A. O. Sinurat,Sam Wheeler,Huihuo Zheng,Troy Arcomano,Venkatram Vishwanath,Rao Kotamarthi*

Main category: cs.LG

TL;DR: AERIS是一种基于扩散变换器的大规模生成模型，用于天气和气候预测，通过SWiPe技术实现高效并行计算，性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决高分辨率天气预测中扩散模型难以稳定扩展的问题。

Method: 使用1.3至80B参数的Swin扩散变换器（AERIS）和SWiPe并行技术。

Result: 在Aurora系统上实现高性能，优于IFS ENS，并在90天季节性尺度上保持稳定。

Conclusion: 十亿参数扩散模型在天气和气候预测中具有潜力。

Abstract: Generative machine learning offers new opportunities to better understand
complex Earth system dynamics. Recent diffusion-based methods address spectral
biases and improve ensemble calibration in weather forecasting compared to
deterministic methods, yet have so far proven difficult to scale stably at high
resolutions. We introduce AERIS, a 1.3 to 80B parameter pixel-level Swin
diffusion transformer to address this gap, and SWiPe, a generalizable technique
that composes window parallelism with sequence and pipeline parallelism to
shard window-based transformers without added communication cost or increased
global batch size. On Aurora (10,080 nodes), AERIS sustains 10.21 ExaFLOPS
(mixed precision) and a peak performance of 11.21 ExaFLOPS with $1 \times 1$
patch size on the 0.25{\deg} ERA5 dataset, achieving 95.5% weak scaling
efficiency, and 81.6% strong scaling efficiency. AERIS outperforms the IFS ENS
and remains stable on seasonal scales to 90 days, highlighting the potential of
billion-parameter diffusion models for weather and climate prediction.

</details>


### [88] [Meta-Learning Linear Models for Molecular Property Prediction](https://arxiv.org/abs/2509.13527)
*Yulia Pimonova,Michael G. Taylor,Alice Allen,Ping Yang,Nicholas Lubbers*

Main category: cs.LG

TL;DR: LAMeL是一种线性元学习算法，旨在提高化学性质预测的准确性和可解释性，优于传统线性方法。


<details>
  <summary>Details</summary>
Motivation: 解决化学领域中高质量数据稀缺和机器学习模型对数据需求增加的问题，同时满足可解释AI的需求。

Method: LAMeL通过元学习框架识别跨任务的共享模型参数，学习共同的功能流形，为新任务提供更优起点。

Result: LAMeL在多个数据集上表现优于标准岭回归，性能提升1.1至25倍，且保持可解释性。

Conclusion: LAMeL是化学性质预测中兼顾准确性和可解释性的可靠工具。

Abstract: Chemists in search of structure-property relationships face great challenges
due to limited high quality, concordant datasets. Machine learning (ML) has
significantly advanced predictive capabilities in chemical sciences, but these
modern data-driven approaches have increased the demand for data. In response
to the growing demand for explainable AI (XAI) and to bridge the gap between
predictive accuracy and human comprehensibility, we introduce LAMeL - a Linear
Algorithm for Meta-Learning that preserves interpretability while improving the
prediction accuracy across multiple properties. While most approaches treat
each chemical prediction task in isolation, LAMeL leverages a meta-learning
framework to identify shared model parameters across related tasks, even if
those tasks do not share data, allowing it to learn a common functional
manifold that serves as a more informed starting point for new unseen tasks.
Our method delivers performance improvements ranging from 1.1- to 25-fold over
standard ridge regression, depending on the domain of the dataset. While the
degree of performance enhancement varies across tasks, LAMeL consistently
outperforms or matches traditional linear methods, making it a reliable tool
for chemical property prediction where both accuracy and interpretability are
critical.

</details>


### [89] [Is GPT-4o mini Blinded by its Own Safety Filters? Exposing the Multimodal-to-Unimodal Bottleneck in Hate Speech Detection](https://arxiv.org/abs/2509.13608)
*Niruthiha Selvanayagam,Ted Kurti*

Main category: cs.LG

TL;DR: 论文分析了GPT-4o mini在检测多模态仇恨言论时的安全架构问题，发现其存在‘单模态瓶颈’缺陷，导致误判。


<details>
  <summary>Details</summary>
Motivation: 理解大型多模态模型的安全架构对AI对齐至关重要。

Method: 使用Hateful Memes Challenge数据集，对500个样本进行多阶段调查。

Result: 发现‘单模态瓶颈’问题，安全过滤器误判率为50%视觉和50%文本内容。

Conclusion: 需更集成的上下文感知对齐策略，以平衡能力与安全性。

Abstract: As Large Multimodal Models (LMMs) become integral to daily digital life,
understanding their safety architectures is a critical problem for AI
Alignment. This paper presents a systematic analysis of OpenAI's GPT-4o mini, a
globally deployed model, on the difficult task of multimodal hate speech
detection. Using the Hateful Memes Challenge dataset, we conduct a multi-phase
investigation on 500 samples to probe the model's reasoning and failure modes.
Our central finding is the experimental identification of a "Unimodal
Bottleneck," an architectural flaw where the model's advanced multimodal
reasoning is systematically preempted by context-blind safety filters. A
quantitative validation of 144 content policy refusals reveals that these
overrides are triggered in equal measure by unimodal visual 50% and textual 50%
content. We further demonstrate that this safety system is brittle, blocking
not only high-risk imagery but also benign, common meme formats, leading to
predictable false positives. These findings expose a fundamental tension
between capability and safety in state-of-the-art LMMs, highlighting the need
for more integrated, context-aware alignment strategies to ensure AI systems
can be deployed both safely and effectively.

</details>


### [90] [Unsupervised Anomaly Detection in ALS EPICS Event Logs](https://arxiv.org/abs/2509.13621)
*Antonin Sulc,Thorsten Hellert,Steven Hunt*

Main category: cs.LG

TL;DR: 论文提出了一种基于语义嵌入和神经网络的自动化故障分析框架，用于实时检测ALS控制系统的异常事件。


<details>
  <summary>Details</summary>
Motivation: 通过实时分析EPICS控制系统的事件日志，快速识别可能导致系统故障的关键事件序列。

Method: 将日志条目视为自然语言，使用语义嵌入技术转换为上下文向量表示，并通过序列感知神经网络实时计算异常分数。

Result: 该方法能够标记与基线行为的偏差，帮助操作员快速识别复杂系统故障的前兆事件序列。

Conclusion: 该框架为ALS控制系统提供了一种高效的实时故障检测方法。

Abstract: This paper introduces an automated fault analysis framework for the Advanced
Light Source (ALS) that processes real-time event logs from its EPICS control
system. By treating log entries as natural language, we transform them into
contextual vector representations using semantic embedding techniques. A
sequence-aware neural network, trained on normal operational data, assigns a
real-time anomaly score to each event. This method flags deviations from
baseline behavior, enabling operators to rapidly identify the critical event
sequences that precede complex system failures.

</details>


### [91] [Privacy-Aware In-Context Learning for Large Language Models](https://arxiv.org/abs/2509.13625)
*Bishnu Bhusal,Manoj Acharya,Ramneet Kaur,Colin Samplawski,Anirban Roy,Adam D. Cobb,Rohit Chadha,Susmit Jha*

Main category: cs.LG

TL;DR: 提出了一种基于差分隐私（DP）的隐私保护文本生成框架，确保信息泄露的理论上限，同时保持高质量文本生成。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型（LLMs）在生成文本时可能泄露敏感信息的隐私问题。

Method: 利用差分隐私框架，对私有记录进行推理并聚合每个令牌的输出分布，结合私有和公共推理以提升实用性。

Result: 在上下文学习（ICL）任务中优于现有方法，实现了隐私保护与高效文本生成的平衡。

Conclusion: 该方法为隐私保护文本生成提供了有前景的方向，同时保持了高实用性。

Abstract: Large language models (LLMs) have significantly transformed natural language
understanding and generation, but they raise privacy concerns due to potential
exposure of sensitive information. Studies have highlighted the risk of
information leakage, where adversaries can extract sensitive information
embedded in the prompts. In this work, we introduce a novel private prediction
framework for generating high-quality synthetic text with strong privacy
guarantees. Our approach leverages the Differential Privacy (DP) framework to
ensure worst-case theoretical bounds on information leakage without requiring
any fine-tuning of the underlying models.The proposed method performs inference
on private records and aggregates the resulting per-token output distributions.
This enables the generation of longer and coherent synthetic text while
maintaining privacy guarantees. Additionally, we propose a simple blending
operation that combines private and public inference to further enhance
utility. Empirical evaluations demonstrate that our approach outperforms
previous state-of-the-art methods on in-context-learning (ICL) tasks, making it
a promising direction for privacy-preserving text generation while maintaining
high utility.

</details>


### [92] [DeepLogit: A sequentially constrained explainable deep learning modeling approach for transport policy analysis](https://arxiv.org/abs/2509.13633)
*Jeremy Oon,Rakhi Manohar Mepparambath,Ling Feng*

Main category: cs.LG

TL;DR: 提出了一种结合线性参数可解释性和深度学习高精度的DeepLogit模型，用于交通政策分析。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在规划和政策领域的应用受限，因其黑箱特性难以解释。

Method: 采用分步约束方法，先估计线性参数的CNN模型，再引入高阶项或Transformer架构，保持部分参数可解释性。

Result: 模型在公交路线选择任务中显著提升了准确性，同时保留了关键参数的可解释性。

Conclusion: 该研究展示了理论驱动的离散选择模型与数据驱动的AI模型结合的可能性，兼具解释性和预测能力。

Abstract: Despite the significant progress of deep learning models in multitude of
applications, their adaption in planning and policy related areas remains
challenging due to the black-box nature of these models. In this work, we
develop a set of DeepLogit models that follow a novel sequentially constrained
approach in estimating deep learning models for transport policy analysis. In
the first step of the proposed approach, we estimate a convolutional neural
network (CNN) model with only linear terms, which is equivalent of a
linear-in-parameter multinomial logit model. We then estimate other deep
learning models by constraining the parameters that need interpretability at
the values obtained in the linear-in-parameter CNN model and including higher
order terms or by introducing advanced deep learning architectures like
Transformers. Our approach can retain the interpretability of the selected
parameters, yet provides significantly improved model accuracy than the
discrete choice model. We demonstrate our approach on a transit route choice
example using real-world transit smart card data from Singapore. This study
shows the potential for a unifying approach, where theory-based discrete choice
model (DCM) and data-driven AI models can leverage each other's strengths in
interpretability and predictive power. With the availability of larger datasets
and more complex constructions, such approach can lead to more accurate models
using discrete choice models while maintaining its applicability in planning
and policy-related areas. Our code is available on
https://github.com/jeremyoon/route-choice/ .

</details>


### [93] [Secure UAV-assisted Federated Learning: A Digital Twin-Driven Approach with Zero-Knowledge Proofs](https://arxiv.org/abs/2509.13634)
*Md Bokhtiar Al Zami,Md Raihan Uddin,Dinh C. Nguyen*

Main category: cs.LG

TL;DR: 提出了一种结合数字孪生（DT）和零知识联邦学习（zkFed）的创新框架，用于解决无人机辅助联邦学习系统中的能源消耗、通信效率和安全性问题。


<details>
  <summary>Details</summary>
Motivation: 无人机辅助联邦学习系统面临能源消耗高、通信效率低和安全漏洞等问题，需要一种高效且安全的解决方案。

Method: 通过数字孪生技术实现实时监控和预测性维护，结合零知识证明（ZKPs）增强安全性，并采用动态资源分配策略优化能源效率。

Result: 系统能耗降低29.6%，学习性能、安全性和可扩展性显著提升。

Conclusion: 该框架为下一代无人机智能网络提供了一种高效、安全的解决方案。

Abstract: Federated learning (FL) has gained popularity as a privacy-preserving method
of training machine learning models on decentralized networks. However to
ensure reliable operation of UAV-assisted FL systems, issues like as excessive
energy consumption, communication inefficiencies, and security vulnerabilities
must be solved. This paper proposes an innovative framework that integrates
Digital Twin (DT) technology and Zero-Knowledge Federated Learning (zkFed) to
tackle these challenges. UAVs act as mobile base stations, allowing scattered
devices to train FL models locally and upload model updates for aggregation. By
incorporating DT technology, our approach enables real-time system monitoring
and predictive maintenance, improving UAV network efficiency. Additionally,
Zero-Knowledge Proofs (ZKPs) strengthen security by allowing model verification
without exposing sensitive data. To optimize energy efficiency and resource
management, we introduce a dynamic allocation strategy that adjusts UAV flight
paths, transmission power, and processing rates based on network conditions.
Using block coordinate descent and convex optimization techniques, our method
significantly reduces system energy consumption by up to 29.6% compared to
conventional FL approaches. Simulation results demonstrate improved learning
performance, security, and scalability, positioning this framework as a
promising solution for next-generation UAV-based intelligent networks.

</details>


### [94] [Multimodal signal fusion for stress detection using deep neural networks: a novel approach for converting 1D signals to unified 2D images](https://arxiv.org/abs/2509.13636)
*Yasin Hasanpoor,Bahram Tarvirdizadeh,Khalil Alipour,Mohammad Ghamari*

Main category: cs.LG

TL;DR: 提出一种将多模态生理信号转换为2D图像矩阵的新方法，通过CNN提升压力检测效果。


<details>
  <summary>Details</summary>
Motivation: 传统方法单独处理信号或依赖固定编码，无法有效捕捉信号间的依赖关系。

Method: 将PPG、GSR和ACC信号融合为结构化图像表示，通过多阶段训练增强模型鲁棒性。

Result: 显著提升分类性能，适用于多模态生理信号领域。

Conclusion: 该方法为可穿戴技术提供更准确、个性化和实时的健康监测方案。

Abstract: This study introduces a novel method that transforms multimodal physiological
signalsphotoplethysmography (PPG), galvanic skin response (GSR), and
acceleration (ACC) into 2D image matrices to enhance stress detection using
convolutional neural networks (CNNs). Unlike traditional approaches that
process these signals separately or rely on fixed encodings, our technique
fuses them into structured image representations that enable CNNs to capture
temporal and cross signal dependencies more effectively. This image based
transformation not only improves interpretability but also serves as a robust
form of data augmentation. To further enhance generalization and model
robustness, we systematically reorganize the fused signals into multiple
formats, combining them in a multi stage training pipeline. This approach
significantly boosts classification performance. While demonstrated here in the
context of stress detection, the proposed method is broadly applicable to any
domain involving multimodal physiological signals, paving the way for more
accurate, personalized, and real time health monitoring through wearable
technologies.

</details>


### [95] [LLM-I: LLMs are Naturally Interleaved Multimodal Creators](https://arxiv.org/abs/2509.13642)
*Zirun Guo,Feng Zhang,Kai Jia,Tao Jin*

Main category: cs.LG

TL;DR: LLM-Interleaved (LLM-I) 是一个动态框架，通过工具使用解决图像-文本交错生成问题，克服现有模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前统一模型在合成图像和需要事实基础或编程精度的任务上表现不佳，LLM-I 旨在解决这一问题。

Method: LLM-I 通过强化学习训练中心代理，智能协调多种视觉工具（如图像搜索、扩散生成、代码执行等）。

Result: 在四个基准测试中，LLM-I 表现优异，大幅超越现有方法。

Conclusion: LLM-I 提供了灵活且高效的解决方案，并通过测试时扩展策略进一步提升性能。

Abstract: We propose LLM-Interleaved (LLM-I), a flexible and dynamic framework that
reframes interleaved image-text generation as a tool-use problem. LLM-I is
designed to overcome the "one-tool" bottleneck of current unified models, which
are limited to synthetic imagery and struggle with tasks requiring factual
grounding or programmatic precision. Our framework empowers a central LLM or
MLLM agent to intelligently orchestrate a diverse toolkit of specialized visual
tools, including online image search, diffusion-based generation, code
execution, and image editing. The agent is trained to select and apply these
tools proficiently via a Reinforcement Learning (RL) framework that features a
hybrid reward system combining rule-based logic with judgments from LLM and
MLLM evaluators. Trained on a diverse new dataset using four different model
backbones, LLM-I demonstrates state-of-the-art performance, outperforming
existing methods by a large margin across four benchmarks. We also introduce a
novel test-time scaling strategy that provides further performance gains.
Project Page: https://github.com/ByteDance-BandAI/LLM-I.

</details>


### [96] [Sequential Data Augmentation for Generative Recommendation](https://arxiv.org/abs/2509.13648)
*Geon Lee,Bhuvesh Kumar,Clark Mingxuan Ju,Tong Zhao,Kijung Shin,Neil Shah,Liam Collins*

Main category: cs.LG

TL;DR: 论文探讨了数据增强在生成推荐系统中的重要性，提出了GenPAS框架以系统化设计数据增强策略，并验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有研究忽视了数据增强对模型性能的关键影响，作者通过实证发现不同增强策略会导致显著性能差异，从而展开深入研究。

Method: 提出GenPAS框架，将数据增强建模为包含序列采样、目标采样和输入采样的随机过程，统一现有策略并灵活控制训练分布。

Result: 在基准和工业数据集上的实验表明，GenPAS在准确性、数据效率和参数效率上优于现有策略。

Conclusion: GenPAS为生成推荐系统中的数据增强提供了系统化指导，显著提升了模型性能。

Abstract: Generative recommendation plays a crucial role in personalized systems,
predicting users' future interactions from their historical behavior sequences.
A critical yet underexplored factor in training these models is data
augmentation, the process of constructing training data from user interaction
histories. By shaping the training distribution, data augmentation directly and
often substantially affects model generalization and performance. Nevertheless,
in much of the existing work, this process is simplified, applied
inconsistently, or treated as a minor design choice, without a systematic and
principled understanding of its effects.
  Motivated by our empirical finding that different augmentation strategies can
yield large performance disparities, we conduct an in-depth analysis of how
they reshape training distributions and influence alignment with future targets
and generalization to unseen inputs. To systematize this design space, we
propose GenPAS, a generalized and principled framework that models augmentation
as a stochastic sampling process over input-target pairs with three
bias-controlled steps: sequence sampling, target sampling, and input sampling.
This formulation unifies widely used strategies as special cases and enables
flexible control of the resulting training distribution. Our extensive
experiments on benchmark and industrial datasets demonstrate that GenPAS yields
superior accuracy, data efficiency, and parameter efficiency compared to
existing strategies, providing practical guidance for principled training data
construction in generative recommendation.

</details>


### [97] [Controllable Pareto Trade-off between Fairness and Accuracy](https://arxiv.org/abs/2509.13651)
*Yongkang Du,Jieyu Zhao,Yijun Yang,Tianyi Zhou*

Main category: cs.LG

TL;DR: 论文提出了一种可控的公平性与准确性权衡方法（CPT），通过多目标优化和梯度修剪技术，实现了根据用户偏好精确调整模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常寻找单一的“最优”解决方案，而忽略了帕累托前沿上的多样性。本文旨在提供根据用户偏好可控的权衡方案。

Method: 采用多目标优化（MOO），并结合梯度移动平均和关键参数梯度修剪技术（CPT），以稳定训练过程并精确控制权衡。

Result: 实验表明，CPT在仇恨言论检测和职业分类任务中，能够生成更高质量的帕累托前沿解，并精确遵循用户定义的参考向量。

Conclusion: CPT方法在公平性与准确性的权衡中表现出更好的可控性和性能，优于基线方法。

Abstract: The fairness-accuracy trade-off is a key challenge in NLP tasks. Current work
focuses on finding a single "optimal" solution to balance the two objectives,
which is limited considering the diverse solutions on the Pareto front. This
work intends to provide controllable trade-offs according to the user's
preference of the two objectives, which is defined as a reference vector. To
achieve this goal, we apply multi-objective optimization (MOO), which can find
solutions from various regions of the Pareto front. However, it is challenging
to precisely control the trade-off due to the stochasticity of the training
process and the high dimentional gradient vectors. Thus, we propose
Controllable Pareto Trade-off (CPT) that can effectively train models to
perform different trade-offs according to users' preferences. CPT 1) stabilizes
the fairness update with a moving average of stochastic gradients to determine
the update direction, and 2) prunes the gradients by only keeping the gradients
of the critical parameters. We evaluate CPT on hate speech detection and
occupation classification tasks. Experiments show that CPT can achieve a
higher-quality set of solutions on the Pareto front than the baseline methods.
It also exhibits better controllability and can precisely follow the
human-defined reference vectors.

</details>


### [98] [RF-LSCM: Pushing Radiance Fields to Multi-Domain Localized Statistical Channel Modeling for Cellular Network Optimization](https://arxiv.org/abs/2509.13686)
*Bingsheng Peng,Shutao Zhang,Xi Zheng,Ye Xue,Xinyu Qin,Tsung-Hui Chang*

Main category: cs.LG

TL;DR: RF-LSCM是一种新型无线信道建模框架，通过联合表示大尺度信号衰减和多径分量，解决了传统方法的局限性，显著提升了预测精度。


<details>
  <summary>Details</summary>
Motivation: 传统局部统计信道建模（LSCM）方法局限于单细胞、单网格和单载波频率分析，无法捕捉复杂的跨域交互。

Method: RF-LSCM结合物理启发的频率相关衰减模型（FDAM）和点云辅助环境增强方法，利用低秩张量表示和分层张量角度建模（HiTAM）算法提高效率。

Result: 在真实多细胞数据集上，RF-LSCM显著优于现有方法，覆盖预测的MAE降低30%，多频数据融合的MAE提升22%。

Conclusion: RF-LSCM通过高效建模和跨域分析，为蜂窝网络优化提供了更准确的信道建模解决方案。

Abstract: Accurate localized wireless channel modeling is a cornerstone of cellular
network optimization, enabling reliable prediction of network performance
during parameter tuning. Localized statistical channel modeling (LSCM) is the
state-of-the-art channel modeling framework tailored for cellular network
optimization. However, traditional LSCM methods, which infer the channel's
Angular Power Spectrum (APS) from Reference Signal Received Power (RSRP)
measurements, suffer from critical limitations: they are typically confined to
single-cell, single-grid and single-carrier frequency analysis and fail to
capture complex cross-domain interactions. To overcome these challenges, we
propose RF-LSCM, a novel framework that models the channel APS by jointly
representing large-scale signal attenuation and multipath components within a
radiance field. RF-LSCM introduces a multi-domain LSCM formulation with a
physics-informed frequency-dependent Attenuation Model (FDAM) to facilitate the
cross frequency generalization as well as a point-cloud-aided environment
enhanced method to enable multi-cell and multi-grid channel modeling.
Furthermore, to address the computational inefficiency of typical neural
radiance fields, RF-LSCM leverages a low-rank tensor representation,
complemented by a novel Hierarchical Tensor Angular Modeling (HiTAM) algorithm.
This efficient design significantly reduces GPU memory requirements and
training time while preserving fine-grained accuracy. Extensive experiments on
real-world multi-cell datasets demonstrate that RF-LSCM significantly
outperforms state-of-the-art methods, achieving up to a 30% reduction in mean
absolute error (MAE) for coverage prediction and a 22% MAE improvement by
effectively fusing multi-frequency data.

</details>


### [99] [A Conformal Prediction Framework for Uncertainty Quantification in Physics-Informed Neural Networks](https://arxiv.org/abs/2509.13717)
*Yifan Yu,Cheuk Hin Ho,Yangshuai Wang*

Main category: cs.LG

TL;DR: 提出了一种基于无分布共形预测的PINNs不确定性量化框架，提供严格的统计保证。


<details>
  <summary>Details</summary>
Motivation: 现有PINNs的不确定性量化方法缺乏严格的统计保证，需要一种更可靠的方法。

Method: 引入无分布共形预测框架，通过校准集构建非共形分数，处理空间异方差性。

Result: 在典型PDE上验证，框架优于启发式方法，提供可靠校准和局部自适应不确定性区间。

Conclusion: 该框架为复杂PDE系统的不确定性建模开辟了新途径。

Abstract: Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework
for solving PDEs, yet existing uncertainty quantification (UQ) approaches for
PINNs generally lack rigorous statistical guarantees. In this work, we bridge
this gap by introducing a distribution-free conformal prediction (CP) framework
for UQ in PINNs. This framework calibrates prediction intervals by constructing
nonconformity scores on a calibration set, thereby yielding distribution-free
uncertainty estimates with rigorous finite-sample coverage guarantees for
PINNs. To handle spatial heteroskedasticity, we further introduce local
conformal quantile estimation, enabling spatially adaptive uncertainty bands
while preserving theoretical guarantee. Through systematic evaluations on
typical PDEs (damped harmonic oscillator, Poisson, Allen-Cahn, and Helmholtz
equations) and comprehensive testing across multiple uncertainty metrics, our
results demonstrate that the proposed framework achieves reliable calibration
and locally adaptive uncertainty intervals, consistently outperforming
heuristic UQ approaches. By bridging PINNs with distribution-free UQ, this work
introduces a general framework that not only enhances calibration and
reliability, but also opens new avenues for uncertainty-aware modeling of
complex PDE systems.

</details>


### [100] [WatchAnxiety: A Transfer Learning Approach for State Anxiety Prediction from Smartwatch Data](https://arxiv.org/abs/2509.13725)
*Md Sabbir Ahmed,Noah French,Mark Rucker,Zhiyuan Wang,Taylor Myers-Brower,Kaitlyn Petz,Mehdi Boukhechba,Bethany A. Teachman,Laura E. Barnes*

Main category: cs.LG

TL;DR: 研究通过智能手表系统监测社交焦虑学生的瞬时焦虑波动，结合心率数据和特质测量，开发了预测模型，准确率60.4%，并在外部数据集验证了泛化能力。


<details>
  <summary>Details</summary>
Motivation: 社交焦虑的瞬时波动对设计实时干预措施至关重要，但此前研究较少关注。

Method: 使用智能手表收集心率数据，结合生态瞬时评估（EMA）和元学习器，开发预测模型。

Result: 模型在内部数据集准确率60.4%，在外部数据集（TILES-18）准确率59.1%，优于先前研究。

Conclusion: 该方法能有效预测社交焦虑的瞬时波动，为个性化干预提供了技术支持。

Abstract: Social anxiety is a common mental health condition linked to significant
challenges in academic, social, and occupational functioning. A core feature is
elevated momentary (state) anxiety in social situations, yet little prior work
has measured or predicted fluctuations in this anxiety throughout the day.
Capturing these intra-day dynamics is critical for designing real-time,
personalized interventions such as Just-In-Time Adaptive Interventions
(JITAIs). To address this gap, we conducted a study with socially anxious
college students (N=91; 72 after exclusions) using our custom smartwatch-based
system over an average of 9.03 days (SD = 2.95). Participants received seven
ecological momentary assessments (EMAs) per day to report state anxiety. We
developed a base model on over 10,000 days of external heart rate data,
transferred its representations to our dataset, and fine-tuned it to generate
probabilistic predictions. These were combined with trait-level measures in a
meta-learner. Our pipeline achieved 60.4% balanced accuracy in state anxiety
detection in our dataset. To evaluate generalizability, we applied the training
approach to a separate hold-out set from the TILES-18 dataset-the same dataset
used for pretraining. On 10,095 once-daily EMAs, our method achieved 59.1%
balanced accuracy, outperforming prior work by at least 7%.

</details>


### [101] [State Space Models over Directed Graphs](https://arxiv.org/abs/2509.13735)
*Junzhi She,Xunkai Li,Rong-Hua Li,Guoren Wang*

Main category: cs.LG

TL;DR: 提出了一种名为DirGraphSSM的新型有向图神经网络架构，通过状态空间模型和消息传递机制，解决了现有方法在长距离因果依赖和训练效率上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有图状态空间模型仅适用于无向图，限制了其性能。本文旨在将有向图学习与状态空间模型结合。

Method: 提出DirEgo2Token方法，通过k-hop ego图将有向图序列化，并在此基础上开发DirGraphSSM架构。

Result: 在三个有向图学习任务中达到最优性能，并在另外两个任务中表现优异，训练速度提升1.5至2倍。

Conclusion: DirGraphSSM成功将有向图学习与状态空间模型结合，显著提升了性能和效率。

Abstract: Directed graphs are ubiquitous across numerous domains, where the
directionality of edges encodes critical causal dependencies. However, existing
GNNs and graph Transformers tailored for directed graphs face two major
challenges: (1) effectively capturing long-range causal dependencies derived
from directed edges; (2) balancing accuracy and training efficiency when
processing large-scale graph datasets. In recent years, state space models
(SSMs) have achieved substantial progress in causal sequence tasks, and their
variants designed for graphs have demonstrated state-of-the-art accuracy while
maintaining high efficiency across various graph learning benchmarks. However,
existing graph state space models are exclusively designed for undirected
graphs, which limits their performance in directed graph learning. To this end,
we propose an innovative approach DirEgo2Token which sequentializes directed
graphs via k-hop ego graphs. This marks the first systematic extension of state
space models to the field of directed graph learning. Building upon this, we
develop DirGraphSSM, a novel directed graph neural network architecture that
implements state space models on directed graphs via the message-passing
mechanism. Experimental results demonstrate that DirGraphSSM achieves
state-of-the-art performance on three representative directed graph learning
tasks while attaining competitive performance on two additional tasks with
1.5$\times $ to 2$\times $ training speed improvements compared to existing
state-of-the-art models.

</details>


### [102] [ParaAegis: Parallel Protection for Flexible Privacy-preserved Federated Learning](https://arxiv.org/abs/2509.13739)
*Zihou Wu,Yuecheng Li,Tianchi Liao,Jian Lou,Chuan Chen*

Main category: cs.LG

TL;DR: ParaAegis框架通过模型分区和分布式投票机制，灵活平衡隐私、效用和效率。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中隐私保护机制（如DP和HE）在模型效用和计算效率之间的刚性权衡问题。

Method: 采用模型分区策略，对低范数部分应用轻量级DP，其余部分使用HE，并通过分布式投票机制达成共识。

Result: 实验表明，通过调整超参数，可以灵活优先考虑模型准确性或训练时间。

Conclusion: ParaAegis为联邦学习提供了可调节的隐私-效用-效率平衡方案。

Abstract: Federated learning (FL) faces a critical dilemma: existing protection
mechanisms like differential privacy (DP) and homomorphic encryption (HE)
enforce a rigid trade-off, forcing a choice between model utility and
computational efficiency. This lack of flexibility hinders the practical
implementation. To address this, we introduce ParaAegis, a parallel protection
framework designed to give practitioners flexible control over the
privacy-utility-efficiency balance. Our core innovation is a strategic model
partitioning scheme. By applying lightweight DP to the less critical, low norm
portion of the model while protecting the remainder with HE, we create a
tunable system. A distributed voting mechanism ensures consensus on this
partitioning. Theoretical analysis confirms the adjustments between efficiency
and utility with the same privacy. Crucially, the experimental results
demonstrate that by adjusting the hyperparameters, our method enables flexible
prioritization between model accuracy and training time.

</details>


### [103] [ST-LINK: Spatially-Aware Large Language Models for Spatio-Temporal Forecasting](https://arxiv.org/abs/2509.13753)
*Hyotaek Jeon,Hyunwook Lee,Juwon Kim,Sungahn Ko*

Main category: cs.LG

TL;DR: ST-LINK框架通过增强LLMs的空间-时间依赖捕捉能力，解决了交通预测中LLMs的空间建模不足问题。


<details>
  <summary>Details</summary>
Motivation: LLMs在交通预测中因空间依赖捕捉不足而受限，ST-LINK旨在解决这一问题。

Method: 提出SE-Attention和MRFFN组件，分别增强空间相关性和动态捕捉时间依赖。

Result: 实验表明ST-LINK优于传统深度学习和LLM方法，能有效捕捉规律和突变。

Conclusion: ST-LINK为LLMs在交通预测中的应用提供了有效解决方案。

Abstract: Traffic forecasting represents a crucial problem within intelligent
transportation systems. In recent research, Large Language Models (LLMs) have
emerged as a promising method, but their intrinsic design, tailored primarily
for sequential token processing, introduces notable challenges in effectively
capturing spatial dependencies. Specifically, the inherent limitations of LLMs
in modeling spatial relationships and their architectural incompatibility with
graph-structured spatial data remain largely unaddressed. To overcome these
limitations, we introduce ST-LINK, a novel framework that enhances the
capability of Large Language Models to capture spatio-temporal dependencies.
Its key components are Spatially-Enhanced Attention (SE-Attention) and the
Memory Retrieval Feed-Forward Network (MRFFN). SE-Attention extends rotary
position embeddings to integrate spatial correlations as direct rotational
transformations within the attention mechanism. This approach maximizes spatial
learning while preserving the LLM's inherent sequential processing structure.
Meanwhile, MRFFN dynamically retrieves and utilizes key historical patterns to
capture complex temporal dependencies and improve the stability of long-term
forecasting. Comprehensive experiments on benchmark datasets demonstrate that
ST-LINK surpasses conventional deep learning and LLM approaches, and
effectively captures both regular traffic patterns and abrupt changes.

</details>


### [104] [Beyond Correlation: Causal Multi-View Unsupervised Feature Selection Learning](https://arxiv.org/abs/2509.13763)
*Zongxin Shen,Yanyong Huang,Bin Wang,Jinyuan Chang,Shiyu Liu,Tianrui Li*

Main category: cs.LG

TL;DR: 论文提出了一种基于因果视角的多视图无监督特征选择方法CAUSA，通过分离混杂因素和平衡分布，解决了现有方法因忽略虚假相关性而选择无关特征的问题。


<details>
  <summary>Details</summary>
Motivation: 现有多视图无监督特征选择方法依赖特征与聚类标签的相关性，但未考虑混杂因素导致的虚假相关性，可能选择无关特征。

Method: 提出CAUSA方法，结合广义无监督谱回归模型和因果正则化模块，分离混杂因素并平衡分布，选择因果信息特征。

Result: 实验表明CAUSA优于现有方法，首次在无监督设置下深入研究因果多视图特征选择。

Conclusion: CAUSA通过因果视角有效解决了多视图无监督特征选择中的虚假相关问题，提升了特征选择的可靠性。

Abstract: Multi-view unsupervised feature selection (MUFS) has recently received
increasing attention for its promising ability in dimensionality reduction on
multi-view unlabeled data. Existing MUFS methods typically select
discriminative features by capturing correlations between features and
clustering labels. However, an important yet underexplored question remains:
\textit{Are such correlations sufficiently reliable to guide feature
selection?} In this paper, we analyze MUFS from a causal perspective by
introducing a novel structural causal model, which reveals that existing
methods may select irrelevant features because they overlook spurious
correlations caused by confounders. Building on this causal perspective, we
propose a novel MUFS method called CAusal multi-view Unsupervised feature
Selection leArning (CAUSA). Specifically, we first employ a generalized
unsupervised spectral regression model that identifies informative features by
capturing dependencies between features and consensus clustering labels. We
then introduce a causal regularization module that can adaptively separate
confounders from multi-view data and simultaneously learn view-shared sample
weights to balance confounder distributions, thereby mitigating spurious
correlations. Thereafter, integrating both into a unified learning framework
enables CAUSA to select causally informative features. Comprehensive
experiments demonstrate that CAUSA outperforms several state-of-the-art
methods. To our knowledge, this is the first in-depth study of causal
multi-view feature selection in the unsupervised setting.

</details>


### [105] [Floating-Body Hydrodynamic Neural Networks](https://arxiv.org/abs/2509.13783)
*Tianshuo Zhang,Wenzhe Zhai,Rui Yann,Jia Gao,He Cao,Xianglei Xing*

Main category: cs.LG

TL;DR: 提出了一种物理结构化的流体动力学神经网络（FHNN），用于预测可解释的水动力参数，并耦合解析运动方程，显著提升了长期预测的稳定性和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统黑盒神经网络在模拟流体-结构相互作用时缺乏可解释性且长期预测不稳定，需要一种更透明且稳定的方法。

Method: 设计了FHNN框架，预测方向性附加质量、阻力系数和基于流函数的流动，并与解析运动方程耦合。

Result: 在合成涡流数据集上，FHNN比神经ODE低一个数量级的误差，并能恢复物理一致的流场。

Conclusion: FHNN有效处理耗散动力学，同时保持可解释性，填补了黑盒学习与透明系统识别之间的空白。

Abstract: Fluid-structure interaction is common in engineering and natural systems,
where floating-body motion is governed by added mass, drag, and background
flows. Modeling these dissipative dynamics is difficult: black-box neural
models regress state derivatives with limited interpretability and unstable
long-horizon predictions. We propose Floating-Body Hydrodynamic Neural Networks
(FHNN), a physics-structured framework that predicts interpretable hydrodynamic
parameters such as directional added masses, drag coefficients, and a
streamfunction-based flow, and couples them with analytic equations of motion.
This design constrains the hypothesis space, enhances interpretability, and
stabilizes integration. On synthetic vortex datasets, FHNN achieves up to an
order-of-magnitude lower error than Neural ODEs, recovers physically consistent
flow fields. Compared with Hamiltonian and Lagrangian neural networks, FHNN
more effectively handles dissipative dynamics while preserving
interpretability, which bridges the gap between black-box learning and
transparent system identification.

</details>


### [106] [Towards a Physics Foundation Model](https://arxiv.org/abs/2509.13805)
*Florian Wiesner,Matthias Wessling,Stephen Baek*

Main category: cs.LG

TL;DR: GPhyT是一种基于Transformer的物理基础模型，通过1.8TB的多样化模拟数据训练，实现了跨多个物理领域的通用模拟能力，无需重新训练即可适应新系统。


<details>
  <summary>Details</summary>
Motivation: 当前基于物理的机器学习方法局限于单一领域且需要针对每个新系统重新训练，限制了其广泛应用。GPhyT旨在通过一个通用模型解决这一问题，推动物理模拟的民主化和科学发现的加速。

Method: 使用Transformer架构，通过上下文学习推断物理规律，训练数据涵盖流体-固体相互作用、冲击波、热对流和多相动力学等多种物理现象。

Result: GPhyT在多个物理领域表现优异，性能最高提升29倍；具备零样本泛化能力，能够稳定进行长期预测（50个时间步）。

Conclusion: GPhyT证明了通过数据学习通用物理规律的可行性，为构建通用的物理基础模型奠定了基础，有望彻底改变计算科学与工程。

Abstract: Foundation models have revolutionized natural language processing through a
``train once, deploy anywhere'' paradigm, where a single pre-trained model
adapts to countless downstream tasks without retraining. Access to a Physics
Foundation Model (PFM) would be transformative -- democratizing access to
high-fidelity simulations, accelerating scientific discovery, and eliminating
the need for specialized solver development. Yet current physics-aware machine
learning approaches remain fundamentally limited to single, narrow domains and
require retraining for each new system. We present the General Physics
Transformer (GPhyT), trained on 1.8 TB of diverse simulation data, that
demonstrates foundation model capabilities are achievable for physics. Our key
insight is that transformers can learn to infer governing dynamics from
context, enabling a single model to simulate fluid-solid interactions, shock
waves, thermal convection, and multi-phase dynamics without being told the
underlying equations. GPhyT achieves three critical breakthroughs: (1) superior
performance across multiple physics domains, outperforming specialized
architectures by up to 29x, (2) zero-shot generalization to entirely unseen
physical systems through in-context learning, and (3) stable long-term
predictions through 50-timestep rollouts. By establishing that a single model
can learn generalizable physical principles from data alone, this work opens
the path toward a universal PFM that could transform computational science and
engineering.

</details>


### [107] [Hybrid Quantum-Classical Neural Networks for Few-Shot Credit Risk Assessment](https://arxiv.org/abs/2509.13818)
*Zheng-an Wang,Yanbo J. Wang,Jiachi Zhang,Qi Xu,Yilun Zhao,Jintao Li,Yipeng Zhang,Bo Yang,Xinkai Gao,Xiaofeng Cao,Kai Xu,Pengpeng Hao,Xuan Yang,Heng Fan*

Main category: cs.LG

TL;DR: 提出了一种混合量子-经典工作流，用于解决小样本信用风险评估问题，量子神经网络在实验中表现优于经典方法。


<details>
  <summary>Details</summary>
Motivation: 解决包容性金融中数据稀缺和不平衡导致的信用风险评估难题。

Method: 结合经典机器学习模型进行特征工程和降维，再使用量子神经网络作为核心分类器。

Result: 在模拟和硬件实验中，量子神经网络分别达到AUC 0.852和0.88，优于经典基准。

Conclusion: 为NISQ时代量子计算在数据受限金融场景中的应用提供了实用方案和实证支持。

Abstract: Quantum Machine Learning (QML) offers a new paradigm for addressing complex
financial problems intractable for classical methods. This work specifically
tackles the challenge of few-shot credit risk assessment, a critical issue in
inclusive finance where data scarcity and imbalance limit the effectiveness of
conventional models. To address this, we design and implement a novel hybrid
quantum-classical workflow. The methodology first employs an ensemble of
classical machine learning models (Logistic Regression, Random Forest, XGBoost)
for intelligent feature engineering and dimensionality reduction. Subsequently,
a Quantum Neural Network (QNN), trained via the parameter-shift rule, serves as
the core classifier. This framework was evaluated through numerical simulations
and deployed on the Quafu Quantum Cloud Platform's ScQ-P21 superconducting
processor. On a real-world credit dataset of 279 samples, our QNN achieved a
robust average AUC of 0.852 +/- 0.027 in simulations and yielded an impressive
AUC of 0.88 in the hardware experiment. This performance surpasses a suite of
classical benchmarks, with a particularly strong result on the recall metric.
This study provides a pragmatic blueprint for applying quantum computing to
data-constrained financial scenarios in the NISQ era and offers valuable
empirical evidence supporting its potential in high-stakes applications like
inclusive finance.

</details>


### [108] [An End-to-End Differentiable, Graph Neural Network-Embedded Pore Network Model for Permeability Prediction](https://arxiv.org/abs/2509.13841)
*Qingqi Zhao,Heng Xiao*

Main category: cs.LG

TL;DR: 提出了一种结合图神经网络（GNN）和孔隙网络模型（PNM）的混合框架，用于预测多孔介质渗透率，克服了纯数据驱动和传统PNM方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 纯数据驱动模型缺乏跨尺度的泛化能力且未包含物理约束，而传统PNM依赖理想化几何假设，限制了其在复杂结构中的准确性。

Method: 将GNN嵌入PNM中，用GNN预测孔喉特征替代传统解析公式，并通过端到端可微分框架实现无标签训练。

Result: 模型在精度和跨尺度泛化能力上优于纯数据驱动和传统PNM方法，且梯度敏感性分析增强了可解释性。

Conclusion: 该框架为复杂多孔介质的渗透率预测提供了可扩展且物理信息化的解决方案，降低了模型不确定性并提高了准确性。

Abstract: Accurate prediction of permeability in porous media is essential for modeling
subsurface flow. While pure data-driven models offer computational efficiency,
they often lack generalization across scales and do not incorporate explicit
physical constraints. Pore network models (PNMs), on the other hand, are
physics-based and efficient but rely on idealized geometric assumptions to
estimate pore-scale hydraulic conductance, limiting their accuracy in complex
structures. To overcome these limitations, we present an end-to-end
differentiable hybrid framework that embeds a graph neural network (GNN) into a
PNM. In this framework, the analytical formulas used for conductance
calculations are replaced by GNN-based predictions derived from pore and throat
features. The predicted conductances are then passed to the PNM solver for
permeability computation. In this way, the model avoids the idealized geometric
assumptions of PNM while preserving the physics-based flow calculations. The
GNN is trained without requiring labeled conductance data, which can number in
the thousands per pore network; instead, it learns conductance values by using
a single scalar permeability as the training target. This is made possible by
backpropagating gradients through both the GNN (via automatic differentiation)
and the PNM solver (via a discrete adjoint method), enabling fully coupled,
end-to-end training. The resulting model achieves high accuracy and generalizes
well across different scales, outperforming both pure data-driven and
traditional PNM approaches. Gradient-based sensitivity analysis further reveals
physically consistent feature influences, enhancing model interpretability.
This approach offers a scalable and physically informed framework for
permeability prediction in complex porous media, reducing model uncertainty and
improving accuracy.

</details>


### [109] [Graph-Regularized Learning of Gaussian Mixture Models](https://arxiv.org/abs/2509.13855)
*Shamsiiat Abdurakhmanova,Alex Jung*

Main category: cs.LG

TL;DR: 提出了一种在分布式环境中基于图正则化的高斯混合模型学习方法，适用于异构和有限本地数据。


<details>
  <summary>Details</summary>
Motivation: 解决分布式环境下异构数据和有限样本的挑战，避免原始数据传输。

Method: 利用相似图指导节点间参数共享，实现邻居参数的灵活聚合。

Result: 在异构和低样本情况下，优于集中式和本地训练的高斯混合模型。

Conclusion: 该方法有效提升了分布式学习中的模型性能，适用于数据受限场景。

Abstract: We present a graph-regularized learning of Gaussian Mixture Models (GMMs) in
distributed settings with heterogeneous and limited local data. The method
exploits a provided similarity graph to guide parameter sharing among nodes,
avoiding the transfer of raw data. The resulting model allows for flexible
aggregation of neighbors' parameters and outperforms both centralized and
locally trained GMMs in heterogeneous, low-sample regimes.

</details>


### [110] [Masked Diffusion Models as Energy Minimization](https://arxiv.org/abs/2509.13866)
*Sitong Chen,Shen Nie,Jiacheng Sun,Zijin Feng,Zhenguo Li,Ji-Rong Wen,Chongxuan Li*

Main category: cs.LG

TL;DR: 论文提出了一个理论框架，将掩码扩散模型（MDMs）解释为离散最优传输中的能量最小化问题，并证明了三种能量公式的数学等价性。通过参数化插值调度，优化了采样效率。


<details>
  <summary>Details</summary>
Motivation: 研究旨在统一掩码扩散模型的理论基础，并通过能量最小化问题优化其采样性能。

Method: 通过数学证明三种能量公式的等价性，并利用Beta分布参数化插值调度，简化调度设计空间。

Result: 实验表明，基于能量的调度在低步采样设置中优于手工设计的基线。

Conclusion: 该框架不仅澄清了MDMs的理论基础，还提供了实用的采样优化方法。

Abstract: We present a systematic theoretical framework that interprets masked
diffusion models (MDMs) as solutions to energy minimization problems in
discrete optimal transport. Specifically, we prove that three distinct energy
formulations--kinetic, conditional kinetic, and geodesic energy--are
mathematically equivalent under the structure of MDMs, and that MDMs minimize
all three when the mask schedule satisfies a closed-form optimality condition.
This unification not only clarifies the theoretical foundations of MDMs, but
also motivates practical improvements in sampling. By parameterizing
interpolation schedules via Beta distributions, we reduce the schedule design
space to a tractable 2D search, enabling efficient post-training tuning without
model modification. Experiments on synthetic and real-world benchmarks
demonstrate that our energy-inspired schedules outperform hand-crafted
baselines, particularly in low-step sampling settings.

</details>


### [111] [FedSSG: Expectation-Gated and History-Aware Drift Alignment for Federated Learning](https://arxiv.org/abs/2509.13895)
*Zhanting Zhou,Jinshan Lai,Fengchun Zhang,Zeqin Wu,Fengli Zhang*

Main category: cs.LG

TL;DR: FedSSG通过历史感知的漂移对齐方法，解决了联邦学习中非独立同分布数据和部分参与导致的客户端漂移问题，显著提升了收敛速度和准确率。


<details>
  <summary>Details</summary>
Motivation: 非独立同分布数据和部分参与导致客户端漂移和不一致的局部最优解，影响联邦学习的稳定性和准确性。

Method: FedSSG利用随机采样引导的历史感知漂移对齐方法，通过客户端漂移记忆和基于参与比率的门控机制，减少局部与全局模型的差距。

Result: 在CIFAR-10/100等基准测试中，FedSSG显著提升了测试准确率（如CIFAR-10提升约0.9，CIFAR-100提升约2.7），并加速了收敛速度（约4.5倍）。

Conclusion: FedSSG证明了采样统计可以转化为一种原则性的历史感知相位控制方法，有效稳定和加速联邦训练。

Abstract: Non-IID data and partial participation induce client drift and inconsistent
local optima in federated learning, causing unstable convergence and accuracy
loss. We present FedSSG, a stochastic sampling-guided, history-aware drift
alignment method. FedSSG maintains a per-client drift memory that accumulates
local model differences as a lightweight sketch of historical gradients;
crucially, it gates both the memory update and the local alignment term by a
smooth function of the observed/expected participation ratio (a
phase-by-expectation signal derived from the server sampler). This
statistically grounded gate stays weak and smooth when sampling noise dominates
early, then strengthens once participation statistics stabilize, contracting
the local-global gap without extra communication. Across CIFAR-10/100 with
100/500 clients and 2-15 percent participation, FedSSG consistently outperforms
strong drift-aware baselines and accelerates convergence; on our benchmarks it
improves test accuracy by up to a few points (e.g., about +0.9 on CIFAR-10 and
about +2.7 on CIFAR-100 on average over the top-2 baseline) and yields about
4.5x faster target-accuracy convergence on average. The method adds only O(d)
client memory and a constant-time gate, and degrades gracefully to a mild
regularizer under near-IID or uniform sampling. FedSSG shows that sampling
statistics can be turned into a principled, history-aware phase control to
stabilize and speed up federated training.

</details>


### [112] [TFMAdapter: Lightweight Instance-Level Adaptation of Foundation Models for Forecasting with Covariates](https://arxiv.org/abs/2509.13906)
*Afrin Dange,Sunita Sarawagi*

Main category: cs.LG

TL;DR: TSFMAdapter是一种轻量级适配器，通过结合协变量信息提升时间序列基础模型的预测性能，无需微调。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列基础模型（TSFMs）无法有效利用协变量信息，限制了其在多领域应用中的准确性。

Method: 采用两阶段方法：首先生成伪预测，再通过高斯过程回归器结合协变量和TSFM预测进行优化。

Result: 实验表明，TSFMAdapter在真实数据集上显著优于基础模型和监督基线，性能提升24-27%。

Conclusion: 轻量级适配器能够弥合通用基础模型与领域特定需求之间的差距。

Abstract: Time Series Foundation Models (TSFMs) have recently achieved state-of-the-art
performance in univariate forecasting on new time series simply by conditioned
on a brief history of past values. Their success demonstrates that large-scale
pretraining across diverse domains can acquire the inductive bias to generalize
from temporal patterns in a brief history. However, most TSFMs are unable to
leverage covariates -- future-available exogenous variables critical for
accurate forecasting in many applications -- due to their domain-specific
nature and the lack of associated inductive bias. We propose TFMAdapter, a
lightweight, instance-level adapter that augments TSFMs with covariate
information without fine-tuning. Instead of retraining, TFMAdapter operates on
the limited history provided during a single model call, learning a
non-parametric cascade that combines covariates with univariate TSFM forecasts.
However, such learning would require univariate forecasts at all steps in the
history, requiring too many calls to the TSFM. To enable training on the full
historical context while limiting TSFM invocations, TFMAdapter uses a two-stage
method: (1) generating pseudo-forecasts with a simple regression model, and (2)
training a Gaussian Process regressor to refine predictions using both pseudo-
and TSFM forecasts alongside covariates. Extensive experiments on real-world
datasets demonstrate that TFMAdapter consistently outperforms both foundation
models and supervised baselines, achieving a 24-27\% improvement over base
foundation models with minimal data and computational overhead. Our results
highlight the potential of lightweight adapters to bridge the gap between
generic foundation models and domain-specific forecasting needs.

</details>


### [113] [APFEx: Adaptive Pareto Front Explorer for Intersectional Fairness](https://arxiv.org/abs/2509.13908)
*Priyobrata Mondal,Faizanuddin Ansari,Swagatam Das*

Main category: cs.LG

TL;DR: APFEx是一个针对机器学习中交叉公平性的框架，通过联合优化敏感属性的笛卡尔积来解决多重偏见问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅针对单一属性的公平性，无法处理交叉子群体面临的复杂偏见。

Method: APFEx结合自适应多目标优化器、可微交叉公平性指标和理论收敛保证。

Result: 在四个真实数据集上，APFEx显著减少公平性违规，同时保持准确性。

Conclusion: APFEx填补了公平机器学习中的关键空白，提供了可扩展的模型无关解决方案。

Abstract: Ensuring fairness in machine learning models is critical, especially when
biases compound across intersecting protected attributes like race, gender, and
age. While existing methods address fairness for single attributes, they fail
to capture the nuanced, multiplicative biases faced by intersectional
subgroups. We introduce Adaptive Pareto Front Explorer (APFEx), the first
framework to explicitly model intersectional fairness as a joint optimization
problem over the Cartesian product of sensitive attributes. APFEx combines
three key innovations- (1) an adaptive multi-objective optimizer that
dynamically switches between Pareto cone projection, gradient weighting, and
exploration strategies to navigate fairness-accuracy trade-offs, (2)
differentiable intersectional fairness metrics enabling gradient-based
optimization of non-smooth subgroup disparities, and (3) theoretical guarantees
of convergence to Pareto-optimal solutions. Experiments on four real-world
datasets demonstrate APFEx's superiority, reducing fairness violations while
maintaining competitive accuracy. Our work bridges a critical gap in fair ML,
providing a scalable, model-agnostic solution for intersectional fairness.

</details>


### [114] [Ensemble of Pre-Trained Models for Long-Tailed Trajectory Prediction](https://arxiv.org/abs/2509.13914)
*Divya Thuremella,Yi Yang,Simon Wanna,Lars Kunze,Daniele De Martini*

Main category: cs.LG

TL;DR: 通过集成建模提升车辆轨迹预测性能，无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 解决如何结合多个先进模型优势而不需昂贵重新训练的问题。

Method: 使用简单的置信度加权平均方法结合现成深度学习模型。

Result: 性能提升10%，尤其在长尾指标上，适用于NuScenes和Argoverse数据集。

Conclusion: 简单方法有效提升预测性能，代码开源。

Abstract: This work explores the application of ensemble modeling to the
multidimensional regression problem of trajectory prediction for vehicles in
urban environments. As newer and bigger state-of-the-art prediction models for
autonomous driving continue to emerge, an important open challenge is the
problem of how to combine the strengths of these big models without the need
for costly re-training. We show how, perhaps surprisingly, combining
state-of-the-art deep learning models out-of-the-box (without retraining or
fine-tuning) with a simple confidence-weighted average method can enhance the
overall prediction. Indeed, while combining trajectory prediction models is not
straightforward, this simple approach enhances performance by 10% over the best
prediction model, especially in the long-tailed metrics. We show that this
performance improvement holds on both the NuScenes and Argoverse datasets, and
that these improvements are made across the dataset distribution. The code for
our work is open source.

</details>


### [115] [Adaptive Client Selection via Q-Learning-based Whittle Index in Wireless Federated Learning](https://arxiv.org/abs/2509.13933)
*Qiyue Li,Yingxin Liu,Hang Qi,Jieping Luo,Zhizhang Liu,Jingjin Wu*

Main category: cs.LG

TL;DR: 提出了一种名为WILF-Q的无线联邦学习客户端选择方法，通过Q学习自适应更新Whittle指数，显著提高了学习效率。


<details>
  <summary>Details</summary>
Motivation: 解决无线联邦学习中客户端动态状态不可观测的问题，以减少达到特定学习精度所需的总时间。

Method: 将客户端选择建模为多臂老虎机问题，提出WILF-Q方法，利用Q学习自适应学习和更新每个客户端的Whittle指数。

Result: 实验表明，WILF-Q在学习效率上显著优于现有基线策略。

Conclusion: WILF-Q是一种适用于实际无线联邦学习环境的鲁棒且高效的客户端选择方法。

Abstract: We consider the client selection problem in wireless Federated Learning (FL),
with the objective of reducing the total required time to achieve a certain
level of learning accuracy. Since the server cannot observe the clients'
dynamic states that can change their computation and communication efficiency,
we formulate client selection as a restless multi-armed bandit problem. We
propose a scalable and efficient approach called the Whittle Index Learning in
Federated Q-learning (WILF-Q), which uses Q-learning to adaptively learn and
update an approximated Whittle index associated with each client, and then
selects the clients with the highest indices. Compared to existing approaches,
WILF-Q does not require explicit knowledge of client state transitions or data
distributions, making it well-suited for deployment in practical FL settings.
Experiment results demonstrate that WILF-Q significantly outperforms existing
baseline policies in terms of learning efficiency, providing a robust and
efficient approach to client selection in wireless FL.

</details>


### [116] [eXtended Physics Informed Neural Network Method for Fracture Mechanics Problems](https://arxiv.org/abs/2509.13952)
*Amin Lotfalian,Mohammad Reza Banan,Pooyan Broumand*

Main category: cs.LG

TL;DR: X-PINN是一种用于解决多裂纹断裂力学问题的新框架，结合了能量损失函数、定制积分方案和域分解方法。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以有效模拟多裂纹问题，X-PINN通过神经网络和XFEM启发的方法填补了这一空白。

Method: 提出基于能量的损失函数、定制积分方案和域分解，并利用神经网络捕捉裂纹不连续性和尖端奇异性。

Result: 数值实验验证了X-PINN在1D和2D多裂纹问题中的有效性和鲁棒性，并可扩展至3D问题。

Conclusion: X-PINN为复杂断裂力学问题提供了灵活且高效的解决方案。

Abstract: This paper presents eXtended Physics-Informed Neural Network (X-PINN), a
novel and robust framework for addressing fracture mechanics problems involving
multiple cracks in fractured media. To address this, an energy-based loss
function, customized integration schemes, and domain decomposition procedures
are proposed. Inspired by the Extended Finite Element Method (XFEM), the neural
network solution space is enriched with specialized functions that allow crack
body discontinuities and singularities at crack tips to be explicitly captured.
Furthermore, a structured framework is introduced in which standard and
enriched solution components are modeled using distinct neural networks,
enabling flexible and effective simulations of complex multiple-crack problems
in 1D and 2D domains, with convenient extensibility to 3D problems. Numerical
experiments are conducted to validate the effectiveness and robustness of the
proposed method.

</details>


### [117] [Personalization on a Budget: Minimally-Labeled Continual Learning for Resource-Efficient Seizure Detection](https://arxiv.org/abs/2509.13974)
*Amirhossein Shahbazinia,Jonathan Dan,Jose A. Miranda,Giovanni Ansaloni,David Atienza*

Main category: cs.LG

TL;DR: 论文提出EpiSMART框架，通过持续学习方法实现个性化癫痫发作检测，显著提升性能并适合实时部署。


<details>
  <summary>Details</summary>
Motivation: 癫痫诊断依赖专家分析EEG信号，耗时且需专业知识，亟需自动化解决方案。

Method: 采用持续学习框架EpiSMART，结合选择性样本保留策略，适应患者特异性EEG信号。

Result: 在CHB-MIT数据集上，F1分数提升21%，每日仅需6.46分钟标记数据和6.28次更新。

Conclusion: EpiSMART在资源受限条件下实现个性化癫痫检测，支持实时部署。

Abstract: Objective: Epilepsy, a prevalent neurological disease, demands careful
diagnosis and continuous care. Seizure detection remains challenging, as
current clinical practice relies on expert analysis of electroencephalography,
which is a time-consuming process and requires specialized knowledge.
Addressing this challenge, this paper explores automated epileptic seizure
detection using deep learning, focusing on personalized continual learning
models that adapt to each patient's unique electroencephalography signal
features, which evolve over time. Methods: In this context, our approach
addresses the challenge of integrating new data into existing models without
catastrophic forgetting, a common issue in static deep learning models. We
propose EpiSMART, a continual learning framework for seizure detection that
uses a size-constrained replay buffer and an informed sample selection strategy
to incrementally adapt to patient-specific electroencephalography signals. By
selectively retaining high-entropy and seizure-predicted samples, our method
preserves critical past information while maintaining high performance with
minimal memory and computational requirements. Results: Validation on the
CHB-MIT dataset, shows that EpiSMART achieves a 21% improvement in the F1 score
over a trained baseline without updates in all other patients. On average,
EpiSMART requires only 6.46 minutes of labeled data and 6.28 updates per day,
making it suitable for real-time deployment in wearable systems.
Conclusion:EpiSMART enables robust and personalized seizure detection under
realistic and resource-constrained conditions by effectively integrating new
data into existing models without degrading past knowledge. Significance: This
framework advances automated seizure detection by providing a continual
learning approach that supports patient-specific adaptation and practical
deployment in wearable healthcare systems.

</details>


### [118] [Deep Temporal Graph Networks for Real-Time Correction of GNSS Jamming-Induced Deviations](https://arxiv.org/abs/2509.14000)
*Ivana Kesić,Aljaž Blatnik,Carolina Fortuna,Blaž Bertalanič*

Main category: cs.LG

TL;DR: 提出了一种基于动态图回归的GNSS干扰缓解方法，通过接收器中心的深度时空图网络实时预测并校正水平偏差。


<details>
  <summary>Details</summary>
Motivation: GNSS系统易受有意干扰影响，导致定位和计时功能失效，需实时校正。

Method: 使用异构星图表示卫星接收环境，通过HeteroGCLSTM模型聚合时空动态信息，预测2D偏差向量。

Result: 在多种干扰场景下，模型表现优于基线方法，MAE最低可达1.65 cm。

Conclusion: 该方法在数据效率和准确性上均优于传统方法，适用于实时干扰缓解。

Abstract: Global Navigation Satellite Systems (GNSS) are increasingly disrupted by
intentional jamming, degrading availability precisely when positioning and
timing must remain operational. We address this by reframing jamming mitigation
as dynamic graph regression and introducing a receiver-centric deep temporal
graph network that predicts, and thus corrects, the receivers horizontal
deviation in real time. At each 1 Hz epoch, the satellite receiver environment
is represented as a heterogeneous star graph (receiver center, tracked
satellites as leaves) with time varying attributes (e.g., SNR, azimuth,
elevation, latitude/longitude). A single layer Heterogeneous Graph ConvLSTM
(HeteroGCLSTM) aggregates one hop spatial context and temporal dynamics over a
short history to output the 2D deviation vector applied for on the fly
correction.
  We evaluate on datasets from two distinct receivers under three jammer
profiles, continuous wave (cw), triple tone (cw3), and wideband FM, each
exercised at six power levels between -45 and -70 dBm, with 50 repetitions per
scenario (prejam/jam/recovery). Against strong multivariate time series
baselines (MLP, uniform CNN, and Seq2Point CNN), our model consistently attains
the lowest mean absolute error (MAE). At -45 dBm, it achieves 3.64 cm
(GP01/cw), 7.74 cm (GP01/cw3), 4.41 cm (ublox/cw), 4.84 cm (ublox/cw3), and
4.82 cm (ublox/FM), improving to 1.65-2.08 cm by -60 to -70 dBm. On mixed mode
datasets pooling all powers, MAE is 3.78 cm (GP01) and 4.25 cm (ublox10),
outperforming Seq2Point, MLP, and CNN. A split study shows superior data
efficiency: with only 10\% training data our approach remains well ahead of
baselines (20 cm vs. 36-42 cm).

</details>


### [119] [Differentially private federated learning for localized control of infectious disease dynamics](https://arxiv.org/abs/2509.14024)
*Raouf Kerkouche,Henrik Zunker,Mario Fritz,Martin J. Kühn*

Main category: cs.LG

TL;DR: 提出了一种基于联邦学习和差分隐私的隐私保护预测方法，用于在流行病期间进行本地化预测，同时保护数据隐私。


<details>
  <summary>Details</summary>
Motivation: 在流行病期间，快速反应需要本地化方法，但数据隐私和有限的数据量使得传统机器学习方法难以应用。

Method: 采用联邦学习框架，结合客户端级差分隐私，训练多层感知机模型预测病例数。

Result: 在适度隐私保护水平下，模型性能接近非差分隐私模型（R²=0.94 vs. 0.95）。

Conclusion: 客户端级差分隐私联邦学习可在保护隐私的同时提供有用的本地预测，隐私预算需根据流行病阶段调整。

Abstract: In times of epidemics, swift reaction is necessary to mitigate epidemic
spreading. For this reaction, localized approaches have several advantages,
limiting necessary resources and reducing the impact of interventions on a
larger scale. However, training a separate machine learning (ML) model on a
local scale is often not feasible due to limited available data. Centralizing
the data is also challenging because of its high sensitivity and privacy
constraints. In this study, we consider a localized strategy based on the
German counties and communities managed by the related local health authorities
(LHA). For the preservation of privacy to not oppose the availability of
detailed situational data, we propose a privacy-preserving forecasting method
that can assist public health experts and decision makers. ML methods with
federated learning (FL) train a shared model without centralizing raw data.
Considering the counties, communities or LHAs as clients and finding a balance
between utility and privacy, we study a FL framework with client-level
differential privacy (DP). We train a shared multilayer perceptron on sliding
windows of recent case counts to forecast the number of cases, while clients
exchange only norm-clipped updates and the server aggregated updates with DP
noise. We evaluate the approach on COVID-19 data on county-level during two
phases. As expected, very strict privacy yields unstable, unusable forecasts.
At a moderately strong level, the DP model closely approaches the non-DP model:
$R^2= 0.94$ (vs. 0.95) and mean absolute percentage error (MAPE) of 26 % in
November 2020; $R^2= 0.88$ (vs. 0.93) and MAPE of 21 % in March 2022. Overall,
client-level DP-FL can deliver useful county-level predictions with strong
privacy guarantees, and viable privacy budgets depend on epidemic phase,
allowing privacy-compliant collaboration among health authorities for local
forecasting.

</details>


### [120] [Deep Learning-Driven Peptide Classification in Biological Nanopores](https://arxiv.org/abs/2509.14029)
*Samuel Tovey,Julian Hoßbach,Sandro Kuppel,Tobias Ensslen,Jan C. Behrends,Christian Holm*

Main category: cs.LG

TL;DR: 将蛋白质电流信号转换为小波变换图像，利用机器学习实现高精度分类，准确率达81%。


<details>
  <summary>Details</summary>
Motivation: 开发一种实时、低成本且高精度的蛋白质分类技术，用于临床疾病诊断。

Method: 通过小波变换将电流信号转换为包含振幅、频率和时间信息的尺度图，利用机器学习算法进行分类。

Result: 在42种肽上测试，分类准确率达到81%，创下新纪录。

Conclusion: 该方法为实时蛋白质诊断提供了可行路径，并展示了模型迁移技术的重要性。

Abstract: A device capable of performing real time classification of proteins in a
clinical setting would allow for inexpensive and rapid disease diagnosis. One
such candidate for this technology are nanopore devices. These devices work by
measuring a current signal that arises when a protein or peptide enters a
nanometer-length-scale pore. Should this current be uniquely related to the
structure of the peptide and its interactions with the pore, the signals can be
used to perform identification. While such a method would allow for real time
identification of peptides and proteins in a clinical setting, to date, the
complexities of these signals limit their accuracy. In this work, we tackle the
issue of classification by converting the current signals into scaleogram
images via wavelet transforms, capturing amplitude, frequency, and time
information in a modality well-suited to machine learning algorithms. When
tested on 42 peptides, our method achieved a classification accuracy of
~$81\,\%$, setting a new state-of-the-art in the field and taking a step toward
practical peptide/protein diagnostics at the point of care. In addition, we
demonstrate model transfer techniques that will be critical when deploying
these models into real hardware, paving the way to a new method for real-time
disease diagnosis.

</details>


### [121] [Queen Detection in Beehives via Environmental Sensor Fusion for Low-Power Edge Computing](https://arxiv.org/abs/2509.14061)
*Chiara De Luca,Elisa Donati*

Main category: cs.LG

TL;DR: 提出了一种基于环境传感器融合的轻量级蜂王检测系统，通过温度和湿度等数据实现高精度检测。


<details>
  <summary>Details</summary>
Motivation: 传统蜂王检测方法劳动密集且干扰性强，现有音频方法功耗高且易受噪声影响，需要更高效、非侵入的解决方案。

Method: 采用环境传感器（温度、湿度、气压差）融合，结合量化决策树推理在STM32微控制器上实现低功耗实时计算。

Result: 系统仅用环境输入即可实现99%以上的蜂王检测准确率，音频特征未显著提升性能。

Conclusion: 该系统为大规模蜂群监测提供了可扩展、可持续的非侵入方案，支持高效精准养蜂。

Abstract: Queen bee presence is essential for the health and stability of honeybee
colonies, yet current monitoring methods rely on manual inspections that are
labor-intensive, disruptive, and impractical for large-scale beekeeping. While
recent audio-based approaches have shown promise, they often require high power
consumption, complex preprocessing, and are susceptible to ambient noise. To
overcome these limitations, we propose a lightweight, multimodal system for
queen detection based on environmental sensor fusion-specifically, temperature,
humidity, and pressure differentials between the inside and outside of the
hive. Our approach employs quantized decision tree inference on a commercial
STM32 microcontroller, enabling real-time, low-power edge computing without
compromising accuracy. We show that our system achieves over 99% queen
detection accuracy using only environmental inputs, with audio features
offering no significant performance gain. This work presents a scalable and
sustainable solution for non-invasive hive monitoring, paving the way for
autonomous, precision beekeeping using off-the-shelf, energy-efficient
hardware.

</details>


### [122] [Online Bayesian Risk-Averse Reinforcement Learning](https://arxiv.org/abs/2509.14077)
*Yuhao Wang,Enlu Zhou*

Main category: cs.LG

TL;DR: 论文研究了强化学习中的贝叶斯风险规避问题，通过BRMDP处理模型参数不确定性，发现贝叶斯风险值函数会悲观低估真实值函数，并提出了在线RL和CMAB中的后验采样方法。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习中因数据不足导致的认知不确定性，通过贝叶斯方法量化模型参数的不确定性。

Method: 采用贝叶斯风险MDP（BRMDP）框架，推导了贝叶斯风险值函数与真实值函数的渐近正态性，并提出了基于后验采样的在线RL和CMAB算法。

Result: 贝叶斯风险规避方法会悲观低估真实值函数，且随着风险规避强度增加或数据量减少，差异增大。实验验证了算法的有效性。

Conclusion: 贝叶斯风险规避方法能有效处理认知不确定性，适用于在线RL和CMAB问题，理论分析和实验均支持其有效性。

Abstract: In this paper, we study the Bayesian risk-averse formulation in reinforcement
learning (RL). To address the epistemic uncertainty due to a lack of data, we
adopt the Bayesian Risk Markov Decision Process (BRMDP) to account for the
parameter uncertainty of the unknown underlying model. We derive the asymptotic
normality that characterizes the difference between the Bayesian risk value
function and the original value function under the true unknown distribution.
The results indicate that the Bayesian risk-averse approach tends to
pessimistically underestimate the original value function. This discrepancy
increases with stronger risk aversion and decreases as more data become
available. We then utilize this adaptive property in the setting of online RL
as well as online contextual multi-arm bandits (CMAB), a special case of online
RL. We provide two procedures using posterior sampling for both the general RL
problem and the CMAB problem. We establish a sub-linear regret bound, with the
regret defined as the conventional regret for both the RL and CMAB settings.
Additionally, we establish a sub-linear regret bound for the CMAB setting with
the regret defined as the Bayesian risk regret. Finally, we conduct numerical
experiments to demonstrate the effectiveness of the proposed algorithm in
addressing epistemic uncertainty and verifying the theoretical properties.

</details>


### [123] [Exploring the Relationship between Brain Hemisphere States and Frequency Bands through Deep Learning Optimization Techniques](https://arxiv.org/abs/2509.14078)
*Robiul Islam,Dmitry I. Ignatov,Karl Kaberg,Roman Nabatchikov*

Main category: cs.LG

TL;DR: 研究比较了不同优化器和神经网络架构在EEG频段分类中的性能，发现Adagrad和RMSprop表现最佳，CNN在空间特征捕捉上表现优异。


<details>
  <summary>Details</summary>
Motivation: 探索优化器和模型架构对EEG频段分类性能的影响，以提升神经影像分类任务的准确性和特征理解。

Method: 使用三种神经网络架构（深度密集网络、浅层三层网络和CNN）和多种优化器（如Adagrad、RMSprop等），在TensorFlow和PyTorch框架下进行实验。

Result: Adagrad在beta频段表现最佳，RMSprop在gamma频段表现优异；CNN在空间特征捕捉上排名第二，深度密集网络在复杂模式学习上表现竞争性。

Conclusion: 优化器选择、模型架构和EEG频段分析对提升分类器性能和特征重要性理解至关重要。

Abstract: This study investigates classifier performance across EEG frequency bands
using various optimizers and evaluates efficient class prediction for the left
and right hemispheres. Three neural network architectures - a deep dense
network, a shallow three-layer network, and a convolutional neural network
(CNN) - are implemented and compared using the TensorFlow and PyTorch
frameworks. Results indicate that the Adagrad and RMSprop optimizers
consistently perform well across different frequency bands, with Adadelta
exhibiting robust performance in cross-model evaluations. Specifically, Adagrad
excels in the beta band, while RMSprop achieves superior performance in the
gamma band. Conversely, SGD and FTRL exhibit inconsistent performance. Among
the models, the CNN demonstrates the second highest accuracy, particularly in
capturing spatial features of EEG data. The deep dense network shows
competitive performance in learning complex patterns, whereas the shallow
three-layer network, sometimes being less accurate, provides computational
efficiency. SHAP (Shapley Additive Explanations) plots are employed to identify
efficient class prediction, revealing nuanced contributions of EEG frequency
bands to model accuracy. Overall, the study highlights the importance of
optimizer selection, model architecture, and EEG frequency band analysis in
enhancing classifier performance and understanding feature importance in
neuroimaging-based classification tasks.

</details>


### [124] [From Distributional to Quantile Neural Basis Models: the case of Electricity Price Forecasting](https://arxiv.org/abs/2509.14113)
*Alessandro Brusaferri,Danial Ramin,Andrea Ballarino*

Main category: cs.LG

TL;DR: 提出Quantile Neural Basis Model，结合可解释性和神经网络框架，用于多时段概率预测。


<details>
  <summary>Details</summary>
Motivation: 理解神经网络在多时段概率预测中的机制仍具挑战性，需提升模型的可解释性。

Method: 引入Quantile Neural Basis Model，结合共享基分解和权重分解，避免参数分布假设。

Result: 在日前电价预测中表现与分布和分位数回归神经网络相当，同时提供输入特征到输出的非线性映射解释。

Conclusion: 模型在保持预测性能的同时，增强了可解释性，为预测行为提供了新见解。

Abstract: While neural networks are achieving high predictive accuracy in multi-horizon
probabilistic forecasting, understanding the underlying mechanisms that lead to
feature-conditioned outputs remains a significant challenge for forecasters. In
this work, we take a further step toward addressing this critical issue by
introducing the Quantile Neural Basis Model, which incorporates the
interpretability principles of Quantile Generalized Additive Models into an
end-to-end neural network training framework. To this end, we leverage shared
basis decomposition and weight factorization, complementing Neural Models for
Location, Scale, and Shape by avoiding any parametric distributional
assumptions. We validate our approach on day-ahead electricity price
forecasting, achieving predictive performance comparable to distributional and
quantile regression neural networks, while offering valuable insights into
model behavior through the learned nonlinear mappings from input features to
output predictions across the horizon.

</details>


### [125] [Breaking the Cycle of Incarceration With Targeted Mental Health Outreach: A Case Study in Machine Learning for Public Policy](https://arxiv.org/abs/2509.14129)
*Kit T. Rodolfa,Erika Salomon,Jin Yao,Steve Yoder,Robert Sullivan,Kevin McGuire,Allie Dickinson,Rob MacDougall,Brian Seidler,Christina Sung,Claire Herdeman,Rayid Ghani*

Main category: cs.LG

TL;DR: 论文探讨了针对监禁人员心理健康问题的主动干预措施，通过预测模型和实地试验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 监禁人员面临心理健康等问题，现有司法系统支持不足，导致再犯罪率上升，尤其对少数族裔社区影响更大。

Method: 采用预测模型和实地试验，评估主动心理健康干预对再监禁率的影响。

Result: 模型能有效预测再监禁风险，干预对高风险个体效果显著，减少了心理健康问题、急救呼叫和司法介入。

Conclusion: 主动心理健康干预对高风险监禁人员有效，可降低再监禁率，改善公共安全。

Abstract: Many incarcerated individuals face significant and complex challenges,
including mental illness, substance dependence, and homelessness, yet jails and
prisons are often poorly equipped to address these needs. With little support
from the existing criminal justice system, these needs can remain untreated and
worsen, often leading to further offenses and a cycle of incarceration with
adverse outcomes both for the individual and for public safety, with
particularly large impacts on communities of color that continue to widen the
already extensive racial disparities in criminal justice outcomes. Responding
to these failures, a growing number of criminal justice stakeholders are
seeking to break this cycle through innovative approaches such as
community-driven and alternative approaches to policing, mentoring, community
building, restorative justice, pretrial diversion, holistic defense, and social
service connections. Here we report on a collaboration between Johnson County,
Kansas, and Carnegie Mellon University to perform targeted, proactive mental
health outreach in an effort to reduce reincarceration rates.
  This paper describes the data used, our predictive modeling approach and
results, as well as the design and analysis of a field trial conducted to
confirm our model's predictive power, evaluate the impact of this targeted
outreach, and understand at what level of reincarceration risk outreach might
be most effective. Through this trial, we find that our model is highly
predictive of new jail bookings, with more than half of individuals in the
trial's highest-risk group returning to jail in the following year. Outreach
was most effective among these highest-risk individuals, with impacts on mental
health utilization, EMS dispatches, and criminal justice involvement.

</details>


### [126] [A Compositional Kernel Model for Feature Learning](https://arxiv.org/abs/2509.14158)
*Feng Ruan,Keli Liu,Michael Jordan*

Main category: cs.LG

TL;DR: 研究了核岭回归的组合变体，通过输入坐标重加权进行预测，验证了特征学习的效果。


<details>
  <summary>Details</summary>
Motivation: 探索组合架构中特征学习的简单测试方法。

Method: 使用变分问题模型，分析变量选择和噪声消除。

Result: 全局最小点和驻点能消除高斯噪声变量，特定核（如拉普拉斯核）能恢复非线性特征。

Conclusion: 拉普拉斯核在非线性特征恢复中优于高斯核。

Abstract: We study a compositional variant of kernel ridge regression in which the
predictor is applied to a coordinate-wise reweighting of the inputs. Formulated
as a variational problem, this model provides a simple testbed for feature
learning in compositional architectures. From the perspective of variable
selection, we show how relevant variables are recovered while noise variables
are eliminated. We establish guarantees showing that both global minimizers and
stationary points discard noise coordinates when the noise variables are
Gaussian distributed. A central finding is that $\ell_1$-type kernels, such as
the Laplace kernel, succeed in recovering features contributing to nonlinear
effects at stationary points, whereas Gaussian kernels recover only linear
ones.

</details>


### [127] [Deconstructing Intraocular Pressure: A Non-invasive Multi-Stage Probabilistic Inverse Framework](https://arxiv.org/abs/2509.14167)
*Md Rezwan Jaher,Abul Mukid Mohammad Mukaddes,A. B. M. Abdul Malek*

Main category: cs.LG

TL;DR: 提出了一种端到端框架，通过稀疏常规数据非侵入性估计不可测量变量，解决了青光眼等逆问题中的临床和计算挑战。


<details>
  <summary>Details</summary>
Motivation: 解决青光眼等疾病中关键参数无法直接测量的问题，同时克服缺乏真实数据和计算成本高的挑战。

Method: 结合多阶段人工智能架构、新型数据生成策略PCDS和贝叶斯引擎，从常规输入中分解眼压测量值。

Result: 非侵入性估计的流出设施与先进眼压测量结果一致，新生物标志物能准确分层临床队列。

Conclusion: 该框架为数据稀缺、计算密集型领域的类似逆问题提供了通用解决方案。

Abstract: Many critical healthcare decisions are challenged by the inability to measure
key underlying parameters. Glaucoma, a leading cause of irreversible blindness
driven by elevated intraocular pressure (IOP), provides a stark example. The
primary determinant of IOP, a tissue property called trabecular meshwork
permeability, cannot be measured in vivo, forcing clinicians to depend on
indirect surrogates. This clinical challenge is compounded by a broader
computational one: developing predictive models for such ill-posed inverse
problems is hindered by a lack of ground-truth data and prohibitive cost of
large-scale, high-fidelity simulations. We address both challenges with an
end-to-end framework to noninvasively estimate unmeasurable variables from
sparse, routine data. Our approach combines a multi-stage artificial
intelligence architecture to functionally separate the problem; a novel data
generation strategy we term PCDS that obviates the need for hundreds of
thousands of costly simulations, reducing the effective computational time from
years to hours; and a Bayesian engine to quantify predictive uncertainty. Our
framework deconstructs a single IOP measurement into its fundamental components
from routine inputs only, yielding estimates for the unmeasurable tissue
permeability and a patient's outflow facility. Our noninvasively estimated
outflow facility achieved excellent agreement with state-of-the-art tonography
with precision comparable to direct physical instruments. Furthermore, the
newly derived permeability biomarker demonstrates high accuracy in stratifying
clinical cohorts by disease risk, highlighting its diagnostic potential. More
broadly, our framework establishes a generalizable blueprint for solving
similar inverse problems in other data-scarce, computationally-intensive
domains.

</details>


### [128] [TopoSizing: An LLM-aided Framework of Topology-based Understanding and Sizing for AMS Circuits](https://arxiv.org/abs/2509.14169)
*Ziming Wei,Zichen Kong,Yuan Wang,David Z. Pan,Xiyuan Tang*

Main category: cs.LG

TL;DR: TopoSizing是一个端到端框架，通过图算法和LLM代理实现电路理解，并将其转化为优化增益。


<details>
  <summary>Details</summary>
Motivation: 模拟和混合信号电路设计面临高质量数据不足和领域知识难以嵌入自动化流程的挑战。

Method: 应用图算法将电路组织为层次结构，LLM代理执行假设-验证-细化循环，并将验证结果整合到贝叶斯优化中。

Result: 提高了优化效率，同时保持了可行性。

Conclusion: TopoSizing通过结合电路理解和优化方法，解决了传统方法的局限性。

Abstract: Analog and mixed-signal circuit design remains challenging due to the
shortage of high-quality data and the difficulty of embedding domain knowledge
into automated flows. Traditional black-box optimization achieves sampling
efficiency but lacks circuit understanding, which often causes evaluations to
be wasted in low-value regions of the design space. In contrast, learning-based
methods embed structural knowledge but are case-specific and costly to retrain.
Recent attempts with large language models show potential, yet they often rely
on manual intervention, limiting generality and transparency. We propose
TopoSizing, an end-to-end framework that performs robust circuit understanding
directly from raw netlists and translates this knowledge into optimization
gains. Our approach first applies graph algorithms to organize circuits into a
hierarchical device-module-stage representation. LLM agents then execute an
iterative hypothesis-verification-refinement loop with built-in consistency
checks, producing explicit annotations. Verified insights are integrated into
Bayesian optimization through LLM-guided initial sampling and
stagnation-triggered trust-region updates, improving efficiency while
preserving feasibility.

</details>


### [129] [TGPO: Tree-Guided Preference Optimization for Robust Web Agent Reinforcement Learning](https://arxiv.org/abs/2509.14172)
*Ziyuan Chen,Zhenghui Zhao,Zhangye Han,Miancan Liu,Xianhang Ye,Yiqing Li,Hongbo Min,Jinkui Ren,Xiantao Zhang,Guitao Cao*

Main category: cs.LG

TL;DR: TGPO是一种离线强化学习框架，通过树形轨迹表示和细粒度奖励模型解决Web Agent训练中的信用分配、标注成本和奖励稀疏问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言和视觉语言模型作为Web Agent的应用面临信用分配不当、高标注成本和奖励稀疏的挑战。

Method: 提出TGPO框架，采用树形轨迹表示合并语义相同状态，结合细粒度奖励模型和动态权重机制。

Result: 在Online-Mind2Web和C-WebShop数据集上表现优于现有方法，成功率高且冗余步骤少。

Conclusion: TGPO有效解决了Web Agent训练中的关键问题，提升了性能。

Abstract: With the rapid advancement of large language models and vision-language
models, employing large models as Web Agents has become essential for automated
web interaction. However, training Web Agents with reinforcement learning faces
critical challenges including credit assignment misallocation, prohibitively
high annotation costs, and reward sparsity. To address these issues, we propose
Tree-Guided Preference Optimization (TGPO), an offline reinforcement learning
framework that proposes a tree-structured trajectory representation merging
semantically identical states across trajectories to eliminate label conflicts.
Our framework incorporates a Process Reward Model that automatically generates
fine-grained rewards through subgoal progress, redundancy detection, and action
verification. Additionally, a dynamic weighting mechanism prioritizes
high-impact decision points during training. Experiments on Online-Mind2Web and
our self-constructed C-WebShop datasets demonstrate that TGPO significantly
outperforms existing methods, achieving higher success rates with fewer
redundant steps.

</details>


### [130] [Bridging Past and Future: Distribution-Aware Alignment for Time Series Forecasting](https://arxiv.org/abs/2509.14181)
*Yifan Hu,Jie Yang,Tian Zhou,Peiyuan Liu,Yujin Tang,Rong Jin,Liang Sun*

Main category: cs.LG

TL;DR: TimeAlign是一个轻量级的表示对齐框架，通过辅助特征学习提升时间序列预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有SOTA预测器很少采用表示学习方法，因为它们表现优势不明显。本文挑战这一观点，认为显式表示对齐能弥补输入历史与未来目标之间的分布差距。

Method: 提出TimeAlign框架，通过简单重构任务学习辅助特征，并将其反馈给基础预测器。

Result: 在八个基准测试中验证了其优越性能，增益主要来自纠正历史输入与未来输出之间的频率不匹配。

Conclusion: TimeAlign是一种架构无关、开销极小的通用对齐模块，可提升现代深度学习时间序列预测系统的性能。

Abstract: Representation learning techniques like contrastive learning have long been
explored in time series forecasting, mirroring their success in computer vision
and natural language processing. Yet recent state-of-the-art (SOTA) forecasters
seldom adopt these representation approaches because they have shown little
performance advantage. We challenge this view and demonstrate that explicit
representation alignment can supply critical information that bridges the
distributional gap between input histories and future targets. To this end, we
introduce TimeAlign, a lightweight, plug-and-play framework that learns
auxiliary features via a simple reconstruction task and feeds them back to any
base forecaster. Extensive experiments across eight benchmarks verify its
superior performance. Further studies indicate that the gains arises primarily
from correcting frequency mismatches between historical inputs and future
outputs. We also provide a theoretical justification for the effectiveness of
TimeAlign in increasing the mutual information between learned representations
and predicted targets. As it is architecture-agnostic and incurs negligible
overhead, TimeAlign can serve as a general alignment module for modern deep
learning time-series forecasting systems. The code is available at
https://github.com/TROUBADOUR000/TimeAlign.

</details>


### [131] [A Variational Framework for Residual-Based Adaptivity in Neural PDE Solvers and Operator Learning](https://arxiv.org/abs/2509.14198)
*Juan Diego Toscano,Daniel T. Chen,Vivek Oommen,George Em Karniadakis*

Main category: cs.LG

TL;DR: 论文提出了一种基于残差的自适应策略的变分框架，统一了不同残差变换方法，并展示了其在降低离散误差和提升学习动态方面的优势。


<details>
  <summary>Details</summary>
Motivation: 科学机器学习中广泛使用的基于残差的自适应策略缺乏理论支持，本文旨在提供一个统一的变分框架来形式化这些方法。

Method: 通过引入凸变换的残差，构建不同的目标函数，将自适应权重选择与误差度量直接关联。

Result: 框架在算子学习中表现出显著性能提升，并提供了理论支持。

Conclusion: 该框架为基于残差的自适应策略提供了理论基础，并为离散化和训练策略的设计提供了指导。

Abstract: Residual-based adaptive strategies are widely used in scientific machine
learning but remain largely heuristic. We introduce a unifying variational
framework that formalizes these methods by integrating convex transformations
of the residual. Different transformations correspond to distinct objective
functionals: exponential weights target the minimization of uniform error,
while linear weights recover the minimization of quadratic error. Within this
perspective, adaptive weighting is equivalent to selecting sampling
distributions that optimize the primal objective, thereby linking
discretization choices directly to error metrics. This principled approach
yields three benefits: (1) it enables systematic design of adaptive schemes
across norms, (2) reduces discretization error through variance reduction of
the loss estimator, and (3) enhances learning dynamics by improving the
gradient signal-to-noise ratio. Extending the framework to operator learning,
we demonstrate substantial performance gains across optimizers and
architectures. Our results provide a theoretical justification of
residual-based adaptivity and establish a foundation for principled
discretization and training strategies.

</details>


### [132] [A Universal Banach--Bregman Framework for Stochastic Iterations: Unifying Stochastic Mirror Descent, Learning and LLM Training](https://arxiv.org/abs/2509.14216)
*Johnny R. Zhang,Xiaomei Mi,Gaoyuan Du,Qianyi Sun,Shiqi Wang,Jiaxuan Li,Wenhua Zhou*

Main category: cs.LG

TL;DR: 本文提出了一种基于Banach-Bregman几何的随机优化框架，适用于非欧几里得空间，显著提升了AI领域的优化效率。


<details>
  <summary>Details</summary>
Motivation: 现有优化理论主要局限于Hilbert空间，无法有效处理非欧几里得环境（如镜像下降、自然梯度下降等），因此需要一种更通用的框架。

Method: 提出Banach-Bregman框架，通过Bregman投影和单调性统一多种优化方法，并引入超松弛技术（λ>2）以支持灵活几何。

Result: 实验表明，该框架在机器学习、深度学习、强化学习和大型语言模型训练中，收敛速度提升20%，方差降低，准确性提高。

Conclusion: Banach-Bregman几何为AI核心领域的优化理论和实践提供了统一基础。

Abstract: Stochastic optimization powers the scalability of modern artificial
intelligence, spanning machine learning, deep learning, reinforcement learning,
and large language model training. Yet, existing theory remains largely
confined to Hilbert spaces, relying on inner-product frameworks and
orthogonality. This paradigm fails to capture non-Euclidean settings, such as
mirror descent on simplices, Bregman proximal methods for sparse learning,
natural gradient descent in information geometry, or
Kullback--Leibler-regularized language model training. Unlike Euclidean-based
Hilbert-space methods, this approach embraces general Banach spaces. This work
introduces a pioneering Banach--Bregman framework for stochastic iterations,
establishing Bregman geometry as a foundation for next-generation optimization.
It (i) provides a unified template via Bregman projections and Bregman--Fejer
monotonicity, encompassing stochastic approximation, mirror descent, natural
gradient, adaptive methods, and mirror-prox; (ii) establishes super-relaxations
($\lambda > 2$) in non-Hilbert settings, enabling flexible geometries and
elucidating their acceleration effect; and (iii) delivers convergence theorems
spanning almost-sure boundedness to geometric rates, validated on synthetic and
real-world tasks. Empirical studies across machine learning (UCI benchmarks),
deep learning (e.g., Transformer training), reinforcement learning
(actor--critic), and large language models (WikiText-2 with distilGPT-2) show
up to 20% faster convergence, reduced variance, and enhanced accuracy over
classical baselines. These results position Banach--Bregman geometry as a
cornerstone unifying optimization theory and practice across core AI paradigms.

</details>


### [133] [Data Denoising and Derivative Estimation for Data-Driven Modeling of Nonlinear Dynamical Systems](https://arxiv.org/abs/2509.14219)
*Jiaqi Yao,Lewis Mitchell,John Maclean,Hemanth Saratchandran*

Main category: cs.LG

TL;DR: 提出了一种基于Runge-Kutta和总变分的隐式神经表示（RKTV-INR）去噪框架，用于非线性动力系统的数据驱动建模。


<details>
  <summary>Details</summary>
Motivation: 测量噪声常阻碍非线性动力系统的数据驱动建模，需要一种有效的去噪方法。

Method: 使用隐式神经表示（INR）拟合噪声观测数据，结合Runge-Kutta积分和总变分约束，确保重构状态接近原始数据且符合动力系统轨迹。

Result: 实验表明，该方法能有效抑制噪声、精确估计导数，并可靠地识别系统方程。

Conclusion: RKTV-INR框架为非线性动力系统的噪声数据建模提供了有效的解决方案。

Abstract: Data-driven modeling of nonlinear dynamical systems is often hampered by
measurement noise. We propose a denoising framework, called Runge-Kutta and
Total Variation Based Implicit Neural Representation (RKTV-INR), that
represents the state trajectory with an implicit neural representation (INR)
fitted directly to noisy observations. Runge-Kutta integration and total
variation are imposed as constraints to ensure that the reconstructed state is
a trajectory of a dynamical system that remains close to the original data. The
trained INR yields a clean, continuous trajectory and provides accurate
first-order derivatives via automatic differentiation. These denoised states
and derivatives are then supplied to Sparse Identification of Nonlinear
Dynamics (SINDy) to recover the governing equations. Experiments demonstrate
effective noise suppression, precise derivative estimation, and reliable system
identification.

</details>


### [134] [Language models' activations linearly encode training-order recency](https://arxiv.org/abs/2509.14223)
*Dmitrii Krasheninnikov,Richard E. Turner,David Krueger*

Main category: cs.LG

TL;DR: 语言模型的激活线性编码了训练过程中信息的学习时间。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型是否能够区分不同时间学习的信息，以及这种能力对模型处理冲突数据和知识更新的影响。

Method: 通过顺序微调Llama-3.2-1B模型在六个不相交但相似的数据集上，分析测试样本的平均激活。

Result: 激活的二维投影显示训练顺序呈直线排列，线性探针能准确区分早期和晚期实体（90%准确率），模型还能微调以报告实体的训练阶段（80%准确率）。

Conclusion: 模型能够区分信息的学习时间，这对处理冲突数据和知识更新具有重要意义。

Abstract: We show that language models' activations linearly encode when information
was learned during training. Our setup involves creating a model with a known
training order by sequentially fine-tuning Llama-3.2-1B on six disjoint but
otherwise similar datasets about named entities. We find that the average
activations of test samples for the six training datasets encode the training
order: when projected into a 2D subspace, these centroids are arranged exactly
in the order of training and lie on a straight line. Further, we show that
linear probes can accurately (~90%) distinguish "early" vs. "late" entities,
generalizing to entities unseen during the probes' own training. The model can
also be fine-tuned to explicitly report an unseen entity's training stage (~80%
accuracy). Interestingly, this temporal signal does not seem attributable to
simple differences in activation magnitudes, losses, or model confidence. Our
paper demonstrates that models are capable of differentiating information by
its acquisition time, and carries significant implications for how they might
manage conflicting data and respond to knowledge modifications.

</details>


### [135] [Defending Diffusion Models Against Membership Inference Attacks via Higher-Order Langevin Dynamics](https://arxiv.org/abs/2509.14225)
*Benjamin Sterling,Yousef El-Laham,Mónica F. Bugallo*

Main category: cs.LG

TL;DR: 本文提出了一种防御扩散模型免受成员推断攻击的方法，通过引入辅助变量和联合扩散过程来增强安全性。


<details>
  <summary>Details</summary>
Motivation: 生成人工智能应用的数据安全问题日益突出，扩散模型虽比其他生成模型更抗攻击，但仍存在成员推断攻击的隐患。

Method: 采用临界阻尼高阶Langevin动力学，引入辅助变量和联合扩散过程，以早期破坏敏感数据。

Result: 在玩具数据集和语音数据集上验证了方法的有效性，使用AUROC曲线和FID指标进行评估。

Conclusion: 该方法通过理论分析和实验验证，有效提升了扩散模型对成员推断攻击的防御能力。

Abstract: Recent advances in generative artificial intelligence applications have
raised new data security concerns. This paper focuses on defending diffusion
models against membership inference attacks. This type of attack occurs when
the attacker can determine if a certain data point was used to train the model.
Although diffusion models are intrinsically more resistant to membership
inference attacks than other generative models, they are still susceptible. The
defense proposed here utilizes critically-damped higher-order Langevin
dynamics, which introduces several auxiliary variables and a joint diffusion
process along these variables. The idea is that the presence of auxiliary
variables mixes external randomness that helps to corrupt sensitive input data
earlier on in the diffusion process. This concept is theoretically investigated
and validated on a toy dataset and a speech dataset using the Area Under the
Receiver Operating Characteristic (AUROC) curves and the FID metric.

</details>


### [136] [NIRVANA: Structured pruning reimagined for large language models compression](https://arxiv.org/abs/2509.14230)
*Mengting Ai,Tianxin Wei,Sirui Chen,Jingrui He*

Main category: cs.LG

TL;DR: NIRVANA是一种新型的结构化剪枝方法，旨在平衡零样本准确性和微调能力，通过理论驱动的策略和自适应稀疏分配机制提升LLM压缩效果。


<details>
  <summary>Details</summary>
Motivation: 当前LLM结构化剪枝方法在零样本设置下性能下降严重，且需要昂贵的恢复技术，NIRVANA旨在解决这些问题。

Method: 利用基于神经切线核的一阶显著性准则和自适应稀疏分配机制，结合KL散度校准数据选择策略。

Result: 在Llama3、Qwen和T5模型上，NIRVANA在相同稀疏度约束下优于现有方法。

Conclusion: NIRVANA为LLM压缩提供了理论支持且实用的解决方案。

Abstract: Structured pruning of large language models (LLMs) offers substantial
efficiency improvements by removing entire hidden units, yet current approaches
often suffer from significant performance degradation, particularly in
zero-shot settings, and necessitate costly recovery techniques such as
supervised fine-tuning (SFT) or adapter insertion. To address these critical
shortcomings, we introduce NIRVANA, a novel pruning method explicitly designed
to balance immediate zero-shot accuracy preservation with robust fine-tuning
capability. Leveraging a first-order saliency criterion derived from the Neural
Tangent Kernel under Adam optimization dynamics, NIRVANA provides a
theoretically grounded pruning strategy that respects essential model training
behaviors. To further address the unique challenges posed by structured
pruning, NIRVANA incorporates an adaptive sparsity allocation mechanism across
layers and modules (attention vs. MLP), which adjusts pruning intensity between
modules in a globally balanced manner. Additionally, to mitigate the high
sensitivity of pruning decisions to calibration data quality, we propose a
simple yet effective KL divergence-based calibration data selection strategy,
ensuring more reliable and task-agnostic pruning outcomes. Comprehensive
experiments conducted on Llama3, Qwen, and T5 models demonstrate that NIRVANA
outperforms existing structured pruning methods under equivalent sparsity
constraints, providing a theoretically sound and practical approach to LLM
compression. The code is available at
https://github.com/iDEA-iSAIL-Lab-UIUC/NIRVANA.

</details>


### [137] [Compute as Teacher: Turning Inference Compute Into Reference-Free Supervision](https://arxiv.org/abs/2509.14234)
*Dulhan Jayalath,Shashwat Goel,Thomas Foster,Parag Jain,Suchin Gururangan,Cheng Zhang,Anirudh Goyal,Alan Schelten*

Main category: cs.LG

TL;DR: 论文提出了一种名为Compute as Teacher (CaT)的方法，通过将模型在推理时的探索转化为无监督信号，从而在没有真实标签的情况下生成学习信号。


<details>
  <summary>Details</summary>
Motivation: 解决在无真实标签的后训练阶段如何生成学习信号的问题。

Method: 通过将模型的推理时探索转化为监督信号，利用冻结的初始策略生成参考，并通过两种奖励机制（可验证任务和非可验证任务）优化模型。

Result: 在多个模型（如Gemma 3 4B、Qwen 3 4B和Llama 3.1 8B）上显著提升了性能（如MATH-500上提升27%，HealthBench上提升12%）。结合强化学习（CaT-RL）进一步提升了效果。

Conclusion: CaT方法有效利用推理时计算资源生成监督信号，显著提升模型性能，且结合强化学习后效果更佳。

Abstract: Where do learning signals come from when there is no ground truth in
post-training? We propose turning exploration into supervision through Compute
as Teacher (CaT), which converts the model's own exploration at inference-time
into reference-free supervision by synthesizing a single reference from a group
of parallel rollouts and then optimizing toward it. Concretely, the current
policy produces a group of rollouts; a frozen anchor (the initial policy)
reconciles omissions and contradictions to estimate a reference, turning extra
inference-time compute into a teacher signal. We turn this into rewards in two
regimes: (i) verifiable tasks use programmatic equivalence on final answers;
(ii) non-verifiable tasks use self-proposed rubrics-binary, auditable criteria
scored by an independent LLM judge, with reward given by the fraction
satisfied. Unlike selection methods (best-of-N, majority, perplexity, or judge
scores), synthesis may disagree with the majority and be correct even when all
rollouts are wrong; performance scales with the number of rollouts. As a
test-time procedure, CaT improves Gemma 3 4B, Qwen 3 4B, and Llama 3.1 8B (up
to +27% on MATH-500; +12% on HealthBench). With reinforcement learning
(CaT-RL), we obtain further gains (up to +33% and +30%), with the trained
policy surpassing the initial teacher signal.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [138] [Maximizing UAV Cellular Connectivity with Reinforcement Learning for BVLoS Path Planning](https://arxiv.org/abs/2509.13336)
*Mehran Behjati,Rosdiadee Nordin,Nor Fadzilah Abdullah*

Main category: cs.RO

TL;DR: 论文提出了一种基于强化学习的无人机路径规划方法，旨在最小化飞行距离并最大化蜂窝链路质量，适用于超视距飞行。


<details>
  <summary>Details</summary>
Motivation: 解决无人机在超视距飞行中蜂窝通信受限的挑战，确保飞行安全和可靠性。

Method: 使用强化学习训练智能体，以无人机与基站通信链路质量作为奖励函数。

Result: 仿真结果表明，该方法能有效训练智能体并生成可行的无人机路径规划。

Conclusion: 该方法可作为离线路径规划模块集成到地面控制系统中，提升无人机操作能力和安全性，适用于复杂长距离应用。

Abstract: This paper presents a reinforcement learning (RL) based approach for path
planning of cellular connected unmanned aerial vehicles (UAVs) operating beyond
visual line of sight (BVLoS). The objective is to minimize travel distance
while maximizing the quality of cellular link connectivity by considering real
world aerial coverage constraints and employing an empirical aerial channel
model. The proposed solution employs RL techniques to train an agent, using the
quality of communication links between the UAV and base stations (BSs) as the
reward function. Simulation results demonstrate the effectiveness of the
proposed method in training the agent and generating feasible UAV path plans.
The proposed approach addresses the challenges due to limitations in UAV
cellular communications, highlighting the need for investigations and
considerations in this area. The RL algorithm efficiently identifies optimal
paths, ensuring maximum connectivity with ground BSs to ensure safe and
reliable BVLoS flight operation. Moreover, the solution can be deployed as an
offline path planning module that can be integrated into future ground control
systems (GCS) for UAV operations, enhancing their capabilities and safety. The
method holds potential for complex long range UAV applications, advancing the
technology in the field of cellular connected UAV path planning.

</details>


### [139] [Real World Robotic Exploration using Deep Neural Networks Trained in Photorealistic Reconstructed Environments](https://arxiv.org/abs/2509.13342)
*Isaac Ronald Ward*

Main category: cs.RO

TL;DR: 改进现有深度神经网络，通过扩展损失函数结合位置和旋转误差，提升机器人视觉定位性能，并在室内场景中实现更高精度。


<details>
  <summary>Details</summary>
Motivation: 提升机器人视觉定位的鲁棒性和准确性，尤其是在存在感知混淆的情况下。

Method: 扩展网络的损失函数，结合位置和旋转误差；利用摄影测量数据生成带标签的数据集进行训练。

Result: 室内场景中，位置误差中位数降低9.64%，旋转误差中位数降低2.99%；训练后模型定位精度达0.11米和0.89度。

Conclusion: 提出了一种完整的导航算法流程，适用于任何室内场景，仅需少量图像数据即可实现高精度定位。

Abstract: In this work, an existing deep neural network approach for determining a
robot's pose from visual information (RGB images) is modified, improving its
localization performance without impacting its ease of training. Explicitly,
the network's loss function is extended in a manner which intuitively combines
the positional and rotational error in order to increase robustness to
perceptual aliasing. An improvement in the localization accuracy for indoor
scenes is observed: with decreases of up to 9.64% and 2.99% in the median
positional and rotational error respectively, when compared to the unmodified
network.
  Additionally, photogrammetry data is used to produce a pose-labelled dataset
which allows the above model to be trained on a local environment, resulting in
localization accuracies of 0.11m & 0.89 degrees. This trained model forms the
basis of a navigation algorithm, which is tested in real-time on a TurtleBot (a
wheeled robotic device). As such, this work introduces a full pipeline for
creating a robust navigational algorithm for any given real world indoor scene;
the only requirement being a collection of images from the scene, which can be
captured in as little as 330 seconds of

</details>


### [140] [Label-Efficient Grasp Joint Prediction with Point-JEPA](https://arxiv.org/abs/2509.13349)
*Jed Guzelkabaagac,Boris Petrović*

Main category: cs.RO

TL;DR: 3D自监督预训练（Point-JEPA）在低标签数据下提升抓取关节角度预测效率，最高减少26%误差。


<details>
  <summary>Details</summary>
Motivation: 研究3D自监督预训练是否能在低标签数据下高效预测抓取关节角度。

Method: 使用点云数据，基于ShapeNet预训练的Point-JEPA编码器，训练轻量级多假设头，采用赢家通吃和top-logit选择评估。

Result: 在DLR-Hand II数据集上，Point-JEPA在低标签数据下减少26% RMSE，达到全监督水平。

Conclusion: JEPA风格预训练是数据高效抓取学习的实用方法。

Abstract: We investigate whether 3D self-supervised pretraining with a Joint-Embedding
Predictive Architecture (Point-JEPA) enables label-efficient grasp joint-angle
prediction. Using point clouds tokenized from meshes and a ShapeNet-pretrained
Point-JEPA encoder, we train a lightweight multi-hypothesis head with
winner-takes-all and evaluate by top-logit selection. On DLR-Hand II with
object-level splits, Point-JEPA reduces RMSE by up to 26% in low-label regimes
and reaches parity with full supervision. These results suggest JEPA-style
pretraining is a practical approach for data-efficient grasp learning.

</details>


### [141] [Using role-play and Hierarchical Task Analysis for designing human-robot interaction](https://arxiv.org/abs/2509.13378)
*Mattias Wingren,Sören Andersson,Sara Rosenberg,Malin Andtfolk,Susanne Hägglund,Prashani Jayasingha Arachchige,Linda Nyholm*

Main category: cs.RO

TL;DR: 论文探讨了角色扮演和层次任务分析在人机交互中的应用，展示了它们在社区药房机器人开发中的优势。


<details>
  <summary>Details</summary>
Motivation: 当前人机交互领域对角色扮演和层次任务分析的应用不足，论文旨在展示这两种方法的潜力。

Method: 通过角色扮演模拟顾客需求，层次任务分析确保机器人行为建模正确，并促进协同设计。

Result: 两种方法提供了可控环境、行为建模准确性和开发便利性。

Conclusion: 未来研究可专注于开发适合社交机器人交互的任务分析方法。

Abstract: We present the use of two methods we believe warrant more use than they
currently have in the field of human-robot interaction: role-play and
Hierarchical Task Analysis. Some of its potential is showcased through our use
of them in an ongoing research project which entails developing a robot
application meant to assist at a community pharmacy. The two methods have
provided us with several advantages. The role-playing provided a controlled and
adjustable environment for understanding the customers' needs where pharmacists
could act as models for the robot's behavior; and the Hierarchical Task
Analysis ensured the behavior displayed was modelled correctly and aided
development through facilitating co-design. Future research could focus on
developing task analysis methods especially suited for social robot
interaction.

</details>


### [142] [ASTREA: Introducing Agentic Intelligence for Orbital Thermal Autonomy](https://arxiv.org/abs/2509.13380)
*Alejandro D. Mousist*

Main category: cs.RO

TL;DR: ASTREA是首个在飞行硬件上部署的自主航天器操作系统，结合了资源受限的LLM代理和强化学习控制器，地面实验表现良好，但在轨验证时因延迟问题性能下降。


<details>
  <summary>Details</summary>
Motivation: 探索在资源受限的航天器硬件上部署自主代理系统的可行性，结合语义推理和自适应控制。

Method: 集成资源受限的LLM代理与强化学习控制器，采用异步架构，以热控制为用例进行验证。

Result: 地面实验显示LLM监督提高了热稳定性，但在轨验证中因延迟问题性能下降。

Conclusion: ASTREA展示了LLM代理在航天自主中的潜力，但也揭示了当前技术在实际飞行环境中的局限性。

Abstract: This paper presents ASTREA, the first agentic system deployed on
flight-heritage hardware (TRL 9) for autonomous spacecraft operations. Using
thermal control as a representative use case, we integrate a
resource-constrained Large Language Model (LLM) agent with a reinforcement
learning controller in an asynchronous architecture tailored for
space-qualified platforms. Ground experiments show that LLM-guided supervision
improves thermal stability and reduces violations, confirming the feasibility
of combining semantic reasoning with adaptive control under hardware
constraints. However, on-orbit validation aboard the International Space
Station (ISS) reveals performance degradation caused by inference latency
mismatched with the rapid thermal cycles characteristic of Low Earth Orbit
(LEO) satellites. These results highlight both the opportunities and current
limitations of agentic LLM-based systems in real flight environments, providing
practical design guidelines for future space autonomy.

</details>


### [143] [Cooperative Target Detection with AUVs: A Dual-Timescale Hierarchical MARDL Approach](https://arxiv.org/abs/2509.13381)
*Zhang Xueyao,Yang Bo,Yu Zhiwen,Cao Xuelin,George C. Alexandropoulos,Merouane Debbah,Chau Yuen*

Main category: cs.RO

TL;DR: 提出了一种双时间尺度的分层多智能体近端策略优化（H-MAPPO）框架，用于水下协作任务，确保隐蔽性和高效性。


<details>
  <summary>Details</summary>
Motivation: 在敌对环境中，协作AUV通信存在暴露风险，如何在确保隐蔽性的同时实现高效协作是关键挑战。

Method: 高层面由中央AUV决定任务参与者，低层面通过功率和轨迹控制降低暴露概率。

Result: 仿真结果表明，该框架收敛快、性能优于基准算法，同时确保隐蔽性和长期协作效率。

Conclusion: H-MAPPO框架有效解决了水下协作任务中的隐蔽性和效率问题。

Abstract: Autonomous Underwater Vehicles (AUVs) have shown great potential for
cooperative detection and reconnaissance. However, collaborative AUV
communications introduce risks of exposure. In adversarial environments,
achieving efficient collaboration while ensuring covert operations becomes a
key challenge for underwater cooperative missions. In this paper, we propose a
novel dual time-scale Hierarchical Multi-Agent Proximal Policy Optimization
(H-MAPPO) framework. The high-level component determines the individuals
participating in the task based on a central AUV, while the low-level component
reduces exposure probabilities through power and trajectory control by the
participating AUVs. Simulation results show that the proposed framework
achieves rapid convergence, outperforms benchmark algorithms in terms of
performance, and maximizes long-term cooperative efficiency while ensuring
covert operations.

</details>


### [144] [VEGA: Electric Vehicle Navigation Agent via Physics-Informed Neural Operator and Proximal Policy Optimization](https://arxiv.org/abs/2509.13386)
*Hansol Lim,Minhyeok Im,Jonathan Boyack,Jee Won Lee,Jongseong Brad Choi*

Main category: cs.RO

TL;DR: VEGA是一个基于强化学习的电动汽车导航系统，结合物理信息神经网络和预算A*算法，优化充电路径和停留时间。


<details>
  <summary>Details</summary>
Motivation: 随着软件定义车辆需求增加，电动汽车需要智能系统优化充电路径，适应车辆状态和环境。

Method: VEGA使用PINO神经网络学习车辆动态，结合PPO强化学习优化路径和充电策略。

Result: VEGA在长距离路线中表现接近特斯拉导航，且能泛化到其他国家。

Conclusion: VEGA成功整合物理学习和强化学习，为电动汽车提供实用的生态路径规划。

Abstract: Demands for software-defined vehicles (SDV) are rising and electric vehicles
(EVs) are increasingly being equipped with powerful computers. This enables
onboard AI systems to optimize charge-aware path optimization customized to
reflect vehicle's current condition and environment. We present VEGA, a
charge-aware EV navigation agent that plans over a charger-annotated road graph
using Proximal Policy Optimization (PPO) with budgeted A* teacher-student
guidance under state-of-charge (SoC) feasibility. VEGA consists of two modules.
First, a physics-informed neural operator (PINO), trained on real vehicle speed
and battery-power logs, uses recent vehicle speed logs to estimate aerodynamic
drag, rolling resistance, mass, motor and regenerative-braking efficiencies,
and auxiliary load by learning a vehicle-custom dynamics. Second, a
Reinforcement Learning (RL) agent uses these dynamics to optimize a path with
optimal charging stops and dwell times under SoC constraints. VEGA requires no
additional sensors and uses only vehicle speed signals. It may serve as a
virtual sensor for power and efficiency to potentially reduce EV cost. In
evaluation on long routes like San Francisco to New York, VEGA's stops, dwell
times, SoC management, and total travel time closely track Tesla Trip Planner
while being slightly more conservative, presumably due to real vehicle
conditions such as vehicle parameter drift due to deterioration. Although
trained only in U.S. regions, VEGA was able to compute optimal charge-aware
paths in France and Japan, demonstrating generalizability. It achieves
practical integration of physics-informed learning and RL for EV eco-routing.

</details>


### [145] [A Convex Formulation of Compliant Contact between Filaments and Rigid Bodies](https://arxiv.org/abs/2509.13434)
*Wei-Chen Li,Glen Chou*

Main category: cs.RO

TL;DR: 提出了一种计算框架，用于模拟细丝与刚体通过接触的相互作用，解决了现有方法中细丝与刚体永久连接的假设问题。


<details>
  <summary>Details</summary>
Motivation: 细丝因其一维结构在三维空间中的复杂性难以模拟，现有方法常假设细丝与刚体永久连接，限制了模拟的准确性。

Method: 结合离散弹性杆模型、压力场接触模型和凸接触公式，实现了细丝与刚体间摩擦相互作用的精确模拟。

Result: 通过凸接触公式，每个时间步可全局优化，验证了摩擦力的准确性，并展示了在软机器人和可变形物体操作中的应用。

Conclusion: 该框架为涉及复杂细丝-细丝和细丝-刚体相互作用的系统提供了多功能模拟器。

Abstract: We present a computational framework for simulating filaments interacting
with rigid bodies through contact. Filaments are challenging to simulate due to
their codimensionality, i.e., they are one-dimensional structures embedded in
three-dimensional space. Existing methods often assume that filaments remain
permanently attached to rigid bodies. Our framework unifies discrete elastic
rod (DER) modeling, a pressure field patch contact model, and a convex contact
formulation to accurately simulate frictional interactions between slender
filaments and rigid bodies - capabilities not previously achievable. Owing to
the convex formulation of contact, each time step can be solved to global
optimality, guaranteeing complementarity between contact velocity and impulse.
We validate the framework by assessing the accuracy of frictional forces and
comparing its physical fidelity against baseline methods. Finally, we
demonstrate its applicability in both soft robotics, such as a stochastic
filament-based gripper, and deformable object manipulation, such as shoelace
tying, providing a versatile simulator for systems involving complex
filament-filament and filament-rigid body interactions.

</details>


### [146] [Trajectory Tracking with Reachability-Guided Quadratic Programming and Freeze-Resume](https://arxiv.org/abs/2509.13501)
*Hossein Gholampour,Logan E. Beaver*

Main category: cs.RO

TL;DR: 提出了一种输出空间方法，用于机器人系统在路径跟踪中安全暂停和恢复，避免重新规划。


<details>
  <summary>Details</summary>
Motivation: 解决机器人系统在路径跟踪中因人或物体干预而需要安全暂停和恢复的问题。

Method: 离线进行可达性检查，在线使用二次规划跟踪运动计划，并通过一步可达性测试限制系统可拒绝的最大干扰。

Result: 系统能够高效处理安全停止和非计划偏差，无需重新规划即可返回运动计划。

Conclusion: 该方法在模拟中表现优于纯追踪方法。

Abstract: Many robotic systems must follow planned paths yet pause safely and resume
when people or objects intervene. We present an output-space method for systems
whose tracked output can be feedback-linearized to a double integrator (e.g.,
manipulators). The approach has two parts. Offline, we perform a pre-run
reachability check to verify that the motion plan respects speed and
acceleration magnitude limits. Online, we apply a quadratic program to track
the motion plan under the same limits. We use a one-step reachability test to
bound the maximum disturbance the system is capable of rejecting. When the
state coincides with the reference path we recover perfect tracking in the
deterministic case, and we correct errors using a KKT-inspired weight. We
demonstrate that safety stops and unplanned deviations are handled efficiently,
and the system returns to the motion plan without replanning. We demonstrate
our system's improved performance over pure pursuit in simulation.

</details>


### [147] [Embracing Bulky Objects with Humanoid Robots: Whole-Body Manipulation with Reinforcement Learning](https://arxiv.org/abs/2509.13534)
*Chunxin Zheng,Kai Chen,Zhihai Bi,Yulin Li,Liang Pan,Jinni Zhou,Haoang Li,Jun Ma*

Main category: cs.RO

TL;DR: 提出了一种结合预训练人类运动先验和神经符号距离场的强化学习框架，用于人形机器人全身拥抱任务。


<details>
  <summary>Details</summary>
Motivation: 传统抓取方法在稳定性和负载能力上受限，无法处理大体积物体的拥抱任务。

Method: 采用师生架构蒸馏大规模人类运动数据，结合神经符号距离场实现自然且物理可行的全身运动。

Result: 在仿真和实际实验中表现出对多样物体的适应性，并成功实现仿真到现实的迁移。

Conclusion: 该框架为人形机器人的多接触和长时程全身操作任务提供了有效解决方案。

Abstract: Whole-body manipulation (WBM) for humanoid robots presents a promising
approach for executing embracing tasks involving bulky objects, where
traditional grasping relying on end-effectors only remains limited in such
scenarios due to inherent stability and payload constraints. This paper
introduces a reinforcement learning framework that integrates a pre-trained
human motion prior with a neural signed distance field (NSDF) representation to
achieve robust whole-body embracing. Our method leverages a teacher-student
architecture to distill large-scale human motion data, generating kinematically
natural and physically feasible whole-body motion patterns. This facilitates
coordinated control across the arms and torso, enabling stable multi-contact
interactions that enhance the robustness in manipulation and also the load
capacity. The embedded NSDF further provides accurate and continuous geometric
perception, improving contact awareness throughout long-horizon tasks. We
thoroughly evaluate the approach through comprehensive simulations and
real-world experiments. The results demonstrate improved adaptability to
diverse shapes and sizes of objects and also successful sim-to-real transfer.
These indicate that the proposed framework offers an effective and practical
solution for multi-contact and long-horizon WBM tasks of humanoid robots.

</details>


### [148] [Semantic 3D Reconstructions with SLAM for Central Airway Obstruction](https://arxiv.org/abs/2509.13541)
*Ayberk Acar,Fangjie Li,Hao Li,Lidia Al-Zogbi,Kanyifeechukwu Jane Oguine,Susheela Sharma Stern,Jesse F. d'Almeida,Robert J. Webster III,Ipek Oguz,Jie Ying Wu*

Main category: cs.RO

TL;DR: 提出了一种结合语义分割与实时单目SLAM的新方法，用于内窥镜下的中央气道阻塞（CAO）实时3D重建，效果优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统治疗中央气道阻塞的方法风险高，机器人干预结合场景理解与自动化潜力大。

Method: 结合DROID-SLAM与分割模型，实时重建气道3D几何并标注阻塞区域。

Result: 重建质量高（0.62 mm Chamfer距离），速度快，能实时标注临床相关区域。

Conclusion: 首次将语义分割与实时单目SLAM结合，模块化设计可推广至其他解剖结构或手术，为自主机器人干预奠定基础。

Abstract: Central airway obstruction (CAO) is a life-threatening condition with
increasing incidence, caused by tumors in and outside of the airway.
Traditional treatment methods such as bronchoscopy and electrocautery can be
used to remove the tumor completely; however, these methods carry a high risk
of complications. Recent advances allow robotic interventions with lesser risk.
The combination of robot interventions with scene understanding and mapping
also opens up the possibilities for automation. We present a novel pipeline
that enables real-time, semantically informed 3D reconstructions of the central
airway using monocular endoscopic video.
  Our approach combines DROID-SLAM with a segmentation model trained to
identify obstructive tissues. The SLAM module reconstructs the 3D geometry of
the airway in real time, while the segmentation masks guide the annotation of
obstruction regions within the reconstructed point cloud. To validate our
pipeline, we evaluate the reconstruction quality using ex vivo models.
  Qualitative and quantitative results show high similarity between ground
truth CT scans and the 3D reconstructions (0.62 mm Chamfer distance). By
integrating segmentation directly into the SLAM workflow, our system produces
annotated 3D maps that highlight clinically relevant regions in real time.
High-speed capabilities of the pipeline allows quicker reconstructions compared
to previous work, reflecting the surgical scene more accurately.
  To the best of our knowledge, this is the first work to integrate semantic
segmentation with real-time monocular SLAM for endoscopic CAO scenarios. Our
framework is modular and can generalize to other anatomies or procedures with
minimal changes, offering a promising step toward autonomous robotic
interventions.

</details>


### [149] [Using Visual Language Models to Control Bionic Hands: Assessment of Object Perception and Grasp Inference](https://arxiv.org/abs/2509.13572)
*Ozan Karaali,Hossam Farag,Strahinja Dosen,Cedomir Stefanovic*

Main category: cs.RO

TL;DR: 研究探讨了利用视觉语言模型（VLMs）提升半自主假肢手的感知能力，通过统一基准测试评估了VLMs在物体识别和抓取参数推断中的表现。


<details>
  <summary>Details</summary>
Motivation: 传统假肢控制需要复杂的多模块流程，本研究旨在探索VLMs是否能简化这一流程，提升感知能力。

Method: 通过统一基准测试，评估8种VLMs在静态图像中识别物体属性（名称、形状、方向、尺寸）和推断抓取参数（抓取类型、手腕旋转、手部开合度、手指数量）的能力。

Result: 大多数模型在物体识别和形状分类上表现优异，但在尺寸估计和抓取参数推断（如手部旋转和开合度）上准确性差异较大。

Conclusion: VLMs在假肢感知模块中展现出潜力，但仍需改进尺寸和抓取参数推断的准确性。

Abstract: This study examines the potential of utilizing Vision Language Models (VLMs)
to improve the perceptual capabilities of semi-autonomous prosthetic hands. We
introduce a unified benchmark for end-to-end perception and grasp inference,
evaluating a single VLM to perform tasks that traditionally require complex
pipelines with separate modules for object detection, pose estimation, and
grasp planning. To establish the feasibility and current limitations of this
approach, we benchmark eight contemporary VLMs on their ability to perform a
unified task essential for bionic grasping. From a single static image, they
should (1) identify common objects and their key properties (name, shape,
orientation, and dimensions), and (2) infer appropriate grasp parameters (grasp
type, wrist rotation, hand aperture, and number of fingers). A corresponding
prompt requesting a structured JSON output was employed with a dataset of 34
snapshots of common objects. Key performance metrics, including accuracy for
categorical attributes (e.g., object name, shape) and errors in numerical
estimates (e.g., dimensions, hand aperture), along with latency and cost, were
analyzed. The results demonstrated that most models exhibited high performance
in object identification and shape recognition, while accuracy in estimating
dimensions and inferring optimal grasp parameters, particularly hand rotation
and aperture, varied more significantly. This work highlights the current
capabilities and limitations of VLMs as advanced perceptual modules for
semi-autonomous control of bionic limbs, demonstrating their potential for
effective prosthetic applications.

</details>


### [150] [Dense-Jump Flow Matching with Non-Uniform Time Scheduling for Robotic Policies: Mitigating Multi-Step Inference Degradation](https://arxiv.org/abs/2509.13574)
*Zidong Chen,Zihao Guo,Peng Wang,ThankGod Itua Egbe,Yan Lyu,Chenghao Qian*

Main category: cs.RO

TL;DR: Flow matching框架在机器人学习中表现优异，但泛化能力早期饱和，且增加推理时的积分步数会降低性能。作者提出非均匀时间调度和密集跳跃积分策略，提升性能23.7%。


<details>
  <summary>Details</summary>
Motivation: 解决Flow matching框架中泛化能力早期饱和和积分步数增加导致性能下降的问题。

Method: 采用非均匀时间调度训练和密集跳跃积分推理策略。

Result: 性能提升23.7%，优于现有基线。

Conclusion: 提出的策略有效解决了Flow matching的局限性，提升了机器人任务的性能。

Abstract: Flow matching has emerged as a competitive framework for learning
high-quality generative policies in robotics; however, we find that
generalisation arises and saturates early along the flow trajectory, in
accordance with recent findings in the literature. We further observe that
increasing the number of Euler integration steps during inference
counter-intuitively and universally degrades policy performance. We attribute
this to (i) additional, uniformly spaced integration steps oversample the
late-time region, thereby constraining actions towards the training
trajectories and reducing generalisation; and (ii) the learned velocity field
becoming non-Lipschitz as integration time approaches 1, causing instability.
To address these issues, we propose a novel policy that utilises non-uniform
time scheduling (e.g., U-shaped) during training, which emphasises both early
and late temporal stages to regularise policy training, and a dense-jump
integration schedule at inference, which uses a single-step integration to
replace the multi-step integration beyond a jump point, to avoid unstable areas
around 1. Essentially, our policy is an efficient one-step learner that still
pushes forward performance through multi-step integration, yielding up to 23.7%
performance gains over state-of-the-art baselines across diverse robotic tasks.

</details>


### [151] [TreeIRL: Safe Urban Driving with Tree Search and Inverse Reinforcement Learning](https://arxiv.org/abs/2509.13579)
*Momchil S. Tomov,Sang Uk Lee,Hansford Hendrago,Jinwook Huh,Teawon Han,Forbes Howington,Rafael da Silva,Gianmarco Bernasconi,Marc Heim,Samuel Findler,Xiaonan Ji,Alexander Boule,Michael Napoli,Kuo Chen,Jesse Miller,Boaz Floor,Yunqing Hu*

Main category: cs.RO

TL;DR: TreeIRL结合MCTS和IRL，在自动驾驶规划中实现最佳性能，平衡安全、进度、舒适度和人性化。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶规划中的瓶颈问题，结合经典方法和学习技术。

Method: 使用MCTS生成安全候选轨迹，通过深度IRL评分选择最人性化的轨迹。

Result: 在仿真和真实驾驶测试中表现最佳，涵盖多种复杂场景。

Conclusion: TreeIRL首次在公共道路上展示MCTS规划，强调多指标和真实环境评估的重要性。

Abstract: We present TreeIRL, a novel planner for autonomous driving that combines
Monte Carlo tree search (MCTS) and inverse reinforcement learning (IRL) to
achieve state-of-the-art performance in simulation and in real-world driving.
The core idea is to use MCTS to find a promising set of safe candidate
trajectories and a deep IRL scoring function to select the most human-like
among them. We evaluate TreeIRL against both classical and state-of-the-art
planners in large-scale simulations and on 500+ miles of real-world autonomous
driving in the Las Vegas metropolitan area. Test scenarios include dense urban
traffic, adaptive cruise control, cut-ins, and traffic lights. TreeIRL achieves
the best overall performance, striking a balance between safety, progress,
comfort, and human-likeness. To our knowledge, our work is the first
demonstration of MCTS-based planning on public roads and underscores the
importance of evaluating planners across a diverse set of metrics and in
real-world environments. TreeIRL is highly extensible and could be further
improved with reinforcement learning and imitation learning, providing a
framework for exploring different combinations of classical and learning-based
approaches to solve the planning bottleneck in autonomous driving.

</details>


### [152] [Object Pose Estimation through Dexterous Touch](https://arxiv.org/abs/2509.13591)
*Amir-Hossein Shahidzadeh,Jiyue Zhu,Kezhou Chen,Sha Yi,Cornelia Fermüller,Yiannis Aloimonos,Xiaolong Wang*

Main category: cs.RO

TL;DR: 使用强化学习和触觉传感器主动探索物体表面，通过迭代优化点云数据估计物体姿态。


<details>
  <summary>Details</summary>
Motivation: 在视觉数据受限或对光照、遮挡敏感的场景中，触觉传感器提供局部接触信息，但难以从部分数据重建物体姿态。

Method: 通过强化学习训练机器人手主动探索物体，收集触觉数据生成3D点云，迭代优化物体形状和姿态。

Result: 方法能主动探索物体表面，识别关键姿态特征，无需物体几何先验知识。

Conclusion: 结合传感器运动探索和强化学习，有效解决了触觉数据局部性带来的姿态估计挑战。

Abstract: Robust object pose estimation is essential for manipulation and interaction
tasks in robotics, particularly in scenarios where visual data is limited or
sensitive to lighting, occlusions, and appearances. Tactile sensors often offer
limited and local contact information, making it challenging to reconstruct the
pose from partial data. Our approach uses sensorimotor exploration to actively
control a robot hand to interact with the object. We train with Reinforcement
Learning (RL) to explore and collect tactile data. The collected 3D point
clouds are used to iteratively refine the object's shape and pose. In our
setup, one hand holds the object steady while the other performs active
exploration. We show that our method can actively explore an object's surface
to identify critical pose features without prior knowledge of the object's
geometry. Supplementary material and more demonstrations will be provided at
https://amirshahid.github.io/BimanualTactilePose .

</details>


### [153] [Leg-Arm Coordinated Operation for Curtain Wall Installation](https://arxiv.org/abs/2509.13595)
*Xiao Liu,Weijun Wang,Tianlun Huang,Zhiyong Wang,Wei Feng*

Main category: cs.RO

TL;DR: 提出了一种基于分层优化的全身控制框架，用于六足幕墙安装机器人的臂腿协调规划，解决了传统幕墙安装方法效率低、风险高的问题。


<details>
  <summary>Details</summary>
Motivation: 传统幕墙安装方法存在地形多变、劳动强度大、效率低和安全风险高等问题，亟需自动化解决方案。

Method: 设计了一种分层优化的全身控制框架，结合六足腿部和折叠臂的运动，针对幕墙安装、天花板安装和地板铺设三种任务进行优化。

Result: 实验验证了该控制方法的有效性，六足机器人能够成功完成幕墙安装任务。

Conclusion: 分层优化的臂腿协调框架为六足机器人在复杂施工环境中的应用奠定了基础。

Abstract: With the acceleration of urbanization, the number of high-rise buildings and
large public facilities is increasing, making curtain walls an essential
component of modern architecture with widespread applications. Traditional
curtain wall installation methods face challenges such as variable on-site
terrain, high labor intensity, low construction efficiency, and significant
safety risks. Large panels often require multiple workers to complete
installation. To address these issues, based on a hexapod curtain wall
installation robot, we design a hierarchical optimization-based whole-body
control framework for coordinated arm-leg planning tailored to three key tasks:
wall installation, ceiling installation, and floor laying. This framework
integrates the motion of the hexapod legs with the operation of the folding arm
and the serial-parallel manipulator. We conduct experiments on the hexapod
curtain wall installation robot to validate the proposed control method,
demonstrating its capability in performing curtain wall installation tasks. Our
results confirm the effectiveness of the hierarchical optimization-based
arm-leg coordination framework for the hexapod robot, laying the foundation for
its further application in complex construction site environments.

</details>


### [154] [Barometer-Aided Attitude Estimation](https://arxiv.org/abs/2509.13649)
*Méloné Nyoba Tchonkeu,Soulaimane Berkane,Tarek Hamel*

Main category: cs.RO

TL;DR: 提出了一种基于气压计的姿态估计方法，利用气压高度测量推断垂直速度和姿态，结合非线性观测器和互补滤波器，确保稳定性和几何一致性。


<details>
  <summary>Details</summary>
Motivation: 在GNSS受限或高动态环境中，IMU单独使用无法可靠估计姿态，而辅助速度传感器可能不可用或成本高。

Method: 采用气压计辅助的姿态估计架构，结合确定性Riccati观测器和互补滤波器，确保几乎全局渐近稳定性。

Result: 气压计辅助估计是一种轻量且有效的补充方式，能够在特定条件下实现稳定和几何一致的姿态估计。

Conclusion: 气压计辅助的姿态估计方法在GNSS受限环境中具有潜力，提供了一种低成本且可靠的解决方案。

Abstract: Accurate and robust attitude estimation is a central challenge for autonomous
vehicles operating in GNSS-denied or highly dynamic environments. In such
cases, Inertial Measurement Units (IMUs) alone are insufficient for reliable
tilt estimation due to the ambiguity between gravitational and inertial
accelerations. While auxiliary velocity sensors, such as GNSS, Pitot tubes,
Doppler radar, or visual odometry, are often used, they can be unavailable,
intermittent, or costly. This work introduces a barometer-aided attitude
estimation architecture that leverages barometric altitude measurements to
infer vertical velocity and attitude within a nonlinear observer on SO(3). The
design cascades a deterministic Riccati observer with a complementary filter,
ensuring Almost Global Asymptotic Stability (AGAS) under a uniform
observability condition while maintaining geometric consistency. The analysis
highlights barometer-aided estimation as a lightweight and effective
complementary modality.

</details>


### [155] [DREAM: Domain-aware Reasoning for Efficient Autonomous Underwater Monitoring](https://arxiv.org/abs/2509.13666)
*Zhenqi Wu,Abhinav Modi,Angelos Mavrogiannis,Kaustubh Joshi,Nikhil Chopra,Yiannis Aloimonos,Nare Karapetyan,Ioannis Rekleitis,Xiaomin Lin*

Main category: cs.RO

TL;DR: DREAM框架利用视觉语言模型（VLM）实现水下机器人自主探索和栖息地监测，显著提高了效率和覆盖率。


<details>
  <summary>Details</summary>
Motivation: 海洋变暖和酸化增加了温度敏感贝类（如牡蛎）的大规模死亡风险，需要长期监测系统。人工成本高且危险，机器人解决方案更安全高效。

Method: 提出DREAM框架，结合VLM技术，使水下机器人能实时、环境感知地自主决策。

Result: 在牡蛎监测任务中，时间减少31.5%，步骤减少23%，覆盖率提高8.88%；在沉船场景中，步骤减少27.5%，覆盖率达100%。

Conclusion: DREAM框架显著提升了水下监测的效率和准确性，适用于长期、大范围的栖息地监测。

Abstract: The ocean is warming and acidifying, increasing the risk of mass mortality
events for temperature-sensitive shellfish such as oysters. This motivates the
development of long-term monitoring systems. However, human labor is costly and
long-duration underwater work is highly hazardous, thus favoring robotic
solutions as a safer and more efficient option. To enable underwater robots to
make real-time, environment-aware decisions without human intervention, we must
equip them with an intelligent "brain." This highlights the need for
persistent,wide-area, and low-cost benthic monitoring. To this end, we present
DREAM, a Vision Language Model (VLM)-guided autonomy framework for long-term
underwater exploration and habitat monitoring. The results show that our
framework is highly efficient in finding and exploring target objects (e.g.,
oysters, shipwrecks) without prior location information. In the
oyster-monitoring task, our framework takes 31.5% less time than the previous
baseline with the same amount of oysters. Compared to the vanilla VLM, it uses
23% fewer steps while covering 8.88% more oysters. In shipwreck scenes, our
framework successfully explores and maps the wreck without collisions,
requiring 27.5% fewer steps than the vanilla model and achieving 100% coverage,
while the vanilla model achieves 60.23% average coverage in our shipwreck
environments.

</details>


### [156] [SPAR: Scalable LLM-based PDDL Domain Generation for Aerial Robotics](https://arxiv.org/abs/2509.13691)
*Songhao Huang,Yuwei Wu,Guangyao Shi,Gaurav S. Sukhatme,Vijay Kumar*

Main category: cs.RO

TL;DR: 利用大型语言模型（LLM）自动生成PDDL领域，特别是针对无人机任务，提出SPAR框架，显著加速复杂规划领域的创建。


<details>
  <summary>Details</summary>
Motivation: 手动设计PDDL领域耗时且易错，阻碍实际应用部署。

Method: 引入系统化验证的无人机规划数据集，设计提示框架生成高质量PDDL领域。

Result: 生成的领域通过语法验证、可执行性、可行性和可解释性评估。

Conclusion: LLM能显著加速复杂规划领域的创建，为无经验专家提供实用工具，推动未来研究。

Abstract: We investigate the problem of automatic domain generation for the Planning
Domain Definition Language (PDDL) using Large Language Models (LLMs), with a
particular focus on unmanned aerial vehicle (UAV) tasks. Although PDDL is a
widely adopted standard in robotic planning, manually designing domains for
diverse applications such as surveillance, delivery, and inspection is
labor-intensive and error-prone, which hinders adoption and real-world
deployment. To address these challenges, we propose SPAR, a framework that
leverages the generative capabilities of LLMs to automatically produce valid,
diverse, and semantically accurate PDDL domains from natural language input. To
this end, we first introduce a systematically formulated and validated UAV
planning dataset, consisting of ground-truth PDDL domains and associated
problems, each paired with detailed domain and action descriptions. Building on
this dataset, we design a prompting framework that generates high-quality PDDL
domains from language input. The generated domains are evaluated through syntax
validation, executability, feasibility, and interpretability. Overall, this
work demonstrates that LLMs can substantially accelerate the creation of
complex planning domains, providing a reproducible dataset and evaluation
pipeline that enables application experts without prior experience to leverage
it for practical tasks and advance future research in aerial robotics and
automated planning.

</details>


### [157] [HGACNet: Hierarchical Graph Attention Network for Cross-Modal Point Cloud Completion](https://arxiv.org/abs/2509.13692)
*Yadan Zeng,Jiadong Zhou,Xiaohan Li,I-Ming Chen*

Main category: cs.RO

TL;DR: HGACNet是一种新颖的点云补全框架，通过分层编码3D几何特征并与单视图RGB图像的图像引导先验融合，显著提升了点云补全的效果。


<details>
  <summary>Details</summary>
Motivation: 点云补全对于机器人感知、物体重建和下游任务至关重要，但自遮挡和传感器限制导致的不完整几何体会显著影响下游推理和交互。

Method: HGACNet采用分层图注意力编码器（HGA）自适应选择关键局部点，并通过多尺度跨模态融合模块（MSCF）实现几何特征与视觉表征的对齐，同时引入对比损失（C-Loss）以显式对齐跨模态特征分布。

Result: 在ShapeNet-ViPC基准和YCB-Complete数据集上的实验表明，HGACNet实现了最先进的性能，并在实际机器人操作任务中表现出强适用性。

Conclusion: HGACNet通过分层几何特征编码和跨模态融合，显著提升了点云补全的准确性和实用性。

Abstract: Point cloud completion is essential for robotic perception, object
reconstruction and supporting downstream tasks like grasp planning, obstacle
avoidance, and manipulation. However, incomplete geometry caused by
self-occlusion and sensor limitations can significantly degrade downstream
reasoning and interaction. To address these challenges, we propose HGACNet, a
novel framework that reconstructs complete point clouds of individual objects
by hierarchically encoding 3D geometric features and fusing them with
image-guided priors from a single-view RGB image. At the core of our approach,
the Hierarchical Graph Attention (HGA) encoder adaptively selects critical
local points through graph attention-based downsampling and progressively
refines hierarchical geometric features to better capture structural continuity
and spatial relationships. To strengthen cross-modal interaction, we further
design a Multi-Scale Cross-Modal Fusion (MSCF) module that performs
attention-based feature alignment between hierarchical geometric features and
structured visual representations, enabling fine-grained semantic guidance for
completion. In addition, we proposed the contrastive loss (C-Loss) to
explicitly align the feature distributions across modalities, improving
completion fidelity under modality discrepancy. Finally, extensive experiments
conducted on both the ShapeNet-ViPC benchmark and the YCB-Complete dataset
confirm the effectiveness of HGACNet, demonstrating state-of-the-art
performance as well as strong applicability in real-world robotic manipulation
tasks.

</details>


### [158] [EZREAL: Enhancing Zero-Shot Outdoor Robot Navigation toward Distant Targets under Varying Visibility](https://arxiv.org/abs/2509.13720)
*Tianle Zeng,Jianwei Peng,Hanjing Ye,Guangcheng Chen,Senzi Luo,Hong Zhang*

Main category: cs.RO

TL;DR: 提出了一种轻量级闭环系统，用于解决大规模户外环境中零样本目标导航的挑战，特别是远距离目标和间歇性可见性问题。


<details>
  <summary>Details</summary>
Motivation: 解决零样本目标导航中远距离目标投影过小和间歇性遮挡的问题。

Method: 基于对齐的多尺度图像瓦片层次结构，通过层次化目标显著性融合，生成稳定的粗层区域显著性，支持可见性感知的航向维护。

Result: 在仿真和真实户外试验中，系统能检测150米外的语义目标，航向维护正确率为82.6%，任务成功率比现有方法提高17.5%。

Conclusion: 系统在远距离和间歇性可见目标导航中表现出鲁棒性，显著提升了零样本目标导航的性能。

Abstract: Zero-shot object navigation (ZSON) in large-scale outdoor environments faces
many challenges; we specifically address a coupled one: long-range targets that
reduce to tiny projections and intermittent visibility due to partial or
complete occlusion. We present a unified, lightweight closed-loop system built
on an aligned multi-scale image tile hierarchy. Through hierarchical
target-saliency fusion, it summarizes localized semantic contrast into a stable
coarse-layer regional saliency that provides the target direction and indicates
target visibility. This regional saliency supports visibility-aware heading
maintenance through keyframe memory, saliency-weighted fusion of historical
headings, and active search during temporary invisibility. The system avoids
whole-image rescaling, enables deterministic bottom-up aggregation, supports
zero-shot navigation, and runs efficiently on a mobile robot. Across simulation
and real-world outdoor trials, the system detects semantic targets beyond 150m,
maintains a correct heading through visibility changes with 82.6% probability,
and improves overall task success by 17.5% compared with the SOTA methods,
demonstrating robust ZSON toward distant and intermittently observable targets.

</details>


### [159] [Reinforcement Learning for Robotic Insertion of Flexible Cables in Industrial Settings](https://arxiv.org/abs/2509.13731)
*Jeongwoo Park,Seabin Lee,Changmin Park,Wonjong Lee,Changjoo Nam*

Main category: cs.RO

TL;DR: 提出了一种基于强化学习的FFC插入算法，利用基础模型实现真实到模拟的转换，减少训练时间并避免物理损坏。


<details>
  <summary>Details</summary>
Motivation: 工业中柔性扁平电缆（FFC）插入插座需要亚毫米级精度，传统方法依赖人工引导，耗时且不安全。

Method: 使用强化学习在模拟环境中训练，通过语义分割掩码和基础模型（SAM2）实现模拟到真实的转换，并利用视觉语言模型（VLM）自动化初始提示。

Result: 实验表明该方法具有零样本能力，可直接部署到真实环境而无需微调。

Conclusion: 该方法有效解决了FFC插入的自动化问题，提高了安全性和效率。

Abstract: The industrial insertion of flexible flat cables (FFCs) into receptacles
presents a significant challenge owing to the need for submillimeter precision
when handling the deformable cables. In manufacturing processes, FFC insertion
with robotic manipulators often requires laborious human-guided trajectory
generation. While Reinforcement Learning (RL) offers a solution to automate
this task without modeling complex properties of FFCs, the nondeterminism
caused by the deformability of FFCs requires significant efforts and time on
training. Moreover, training directly in a real environment is dangerous as
industrial robots move fast and possess no safety measure. We propose an RL
algorithm for FFC insertion that leverages a foundation model-based real-to-sim
approach to reduce the training time and eliminate the risk of physical damages
to robots and surroundings. Training is done entirely in simulation, allowing
for random exploration without the risk of physical damages. Sim-to-real
transfer is achieved through semantic segmentation masks which leave only those
visual features relevant to the insertion tasks such as the geometric and
spatial information of the cables and receptacles. To enhance generality, we
use a foundation model, Segment Anything Model 2 (SAM2). To eleminate human
intervention, we employ a Vision-Language Model (VLM) to automate the initial
prompting of SAM2 to find segmentation masks. In the experiments, our method
exhibits zero-shot capabilities, which enable direct deployments to real
environments without fine-tuning.

</details>


### [160] [FSR-VLN: Fast and Slow Reasoning for Vision-Language Navigation with Hierarchical Multi-modal Scene Graph](https://arxiv.org/abs/2509.13733)
*Xiaolin Zhou,Tingyang Xiao,Liu Liu,Yucheng Wang,Maiyue Chen,Xinrui Meng,Xinjie Wang,Wei Feng,Wei Sui,Zhizhong Su*

Main category: cs.RO

TL;DR: FSR-VLN是一种结合了分层多模态场景图和快速到慢速导航推理的视觉语言导航系统，显著提高了长距离导航的成功率并降低了响应时间。


<details>
  <summary>Details</summary>
Motivation: 现有方法在长距离空间推理上表现不佳，成功率和推理延迟较高，特别是在长距离导航任务中。

Method: FSR-VLN通过分层多模态场景图（HMSG）提供多模态地图表示，支持从粗到细的检索；结合快速匹配和VLM驱动的细化进行目标选择。

Result: 在四个室内数据集上实现了最先进的性能，检索成功率（RSR）显著提升，响应时间减少了82%。

Conclusion: FSR-VLN不仅提升了导航性能，还成功集成到人形机器人中，实现了自然语言交互和实时导航。

Abstract: Visual-Language Navigation (VLN) is a fundamental challenge in robotic
systems, with broad applications for the deployment of embodied agents in
real-world environments. Despite recent advances, existing approaches are
limited in long-range spatial reasoning, often exhibiting low success rates and
high inference latency, particularly in long-range navigation tasks. To address
these limitations, we propose FSR-VLN, a vision-language navigation system that
combines a Hierarchical Multi-modal Scene Graph (HMSG) with Fast-to-Slow
Navigation Reasoning (FSR). The HMSG provides a multi-modal map representation
supporting progressive retrieval, from coarse room-level localization to
fine-grained goal view and object identification. Building on HMSG, FSR first
performs fast matching to efficiently select candidate rooms, views, and
objects, then applies VLM-driven refinement for final goal selection. We
evaluated FSR-VLN across four comprehensive indoor datasets collected by
humanoid robots, utilizing 87 instructions that encompass a diverse range of
object categories. FSR-VLN achieves state-of-the-art (SOTA) performance in all
datasets, measured by the retrieval success rate (RSR), while reducing the
response time by 82% compared to VLM-based methods on tour videos by activating
slow reasoning only when fast intuition fails. Furthermore, we integrate
FSR-VLN with speech interaction, planning, and control modules on a Unitree-G1
humanoid robot, enabling natural language interaction and real-time navigation.

</details>


### [161] [Motion Adaptation Across Users and Tasks for Exoskeletons via Meta-Learning](https://arxiv.org/abs/2509.13736)
*Muyuan Ma,Long Cheng,Lijun Han,Xiuze Xia,Houcheng Li*

Main category: cs.RO

TL;DR: 提出了一种基于元模仿学习的可穿戴外骨骼辅助算法，通过任务特定神经网络预测肘关节运动，提升对新任务和用户的适应性。


<details>
  <summary>Details</summary>
Motivation: 开发个性化和任务通用的辅助算法是可穿戴外骨骼的关键挑战。

Method: 利用公开RGB视频和运动捕捉数据集提取全身关键点运动，在仿真中重定向并训练任务特定神经网络，结合MAML框架快速适应新任务和用户。

Result: 实验表明外骨骼显著降低了新用户执行未训练任务时的肌肉激活和代谢成本。

Conclusion: 该框架有效提升了可穿戴外骨骼系统的任务通用性和用户适应性。

Abstract: Wearable exoskeletons can augment human strength and reduce muscle fatigue
during specific tasks. However, developing personalized and task-generalizable
assistance algorithms remains a critical challenge. To address this, a
meta-imitation learning approach is proposed. This approach leverages a
task-specific neural network to predict human elbow joint movements, enabling
effective assistance while enhancing generalization to new scenarios. To
accelerate data collection, full-body keypoint motions are extracted from
publicly available RGB video and motion-capture datasets across multiple tasks,
and subsequently retargeted in simulation. Elbow flexion trajectories generated
in simulation are then used to train the task-specific neural network within
the model-agnostic meta-learning (MAML) framework, which allows the network to
rapidly adapt to novel tasks and unseen users with only a few gradient updates.
The adapted network outputs personalized references tracked by a
gravity-compensated PD controller to ensure stable assistance. Experimental
results demonstrate that the exoskeleton significantly reduces both muscle
activation and metabolic cost for new users performing untrained tasks,
compared to performing without exoskeleton assistance. These findings suggest
that the proposed framework effectively improves task generalization and user
adaptability for wearable exoskeleton systems.

</details>


### [162] [Dynamic Adaptive Legged Locomotion Policy via Decoupling Reaction Force Control and Gait Control](https://arxiv.org/abs/2509.13737)
*Renjie Wang,Shangke Lyu,Donglin Wang*

Main category: cs.RO

TL;DR: 提出了一种解耦框架，通过分离站立腿和摆动腿控制，增强强化学习在腿式运动控制中的适应性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习在分布外条件和仿真与现实环境差异中的性能下降问题。

Method: 采用解耦框架，分离站立腿和摆动腿控制，实现快速在线适应能力。

Result: 在模拟和真实实验中有效应对水平力干扰、不平坦地形、重载和仿真与现实差距。

Conclusion: 解耦框架显著提升了腿式运动控制的适应性和鲁棒性。

Abstract: While Reinforcement Learning (RL) has achieved remarkable progress in legged
locomotion control, it often suffers from performance degradation in
out-of-distribution (OOD) conditions and discrepancies between the simulation
and the real environments. Instead of mainly relying on domain randomization
(DR) to best cover the real environments and thereby close the sim-to-real gap
and enhance robustness, this work proposes an emerging decoupled framework that
acquires fast online adaptation ability and mitigates the sim-to-real problems
in unfamiliar environments by isolating stance-leg control and swing-leg
control. Various simulation and real-world experiments demonstrate its
effectiveness against horizontal force disturbances, uneven terrains, heavy and
biased payloads, and sim-to-real gap.

</details>


### [163] [CDFlow: Generative Gradient Flows for Configuration Space Distance Fields via Neural ODEs](https://arxiv.org/abs/2509.13771)
*Mengzhu Li,Yunyu Zhou,He Ying,F. Richard Yu*

Main category: cs.RO

TL;DR: CDFlow提出了一种基于神经ODE的连续流框架，解决了高自由度机器人中CDF的多模态和梯度模糊问题。


<details>
  <summary>Details</summary>
Motivation: 现有CDF在高自由度机器人中存在多模态忽略和稀疏采样导致的几何失真问题。

Method: 通过神经ODE学习配置空间的连续流，并引入自适应细化采样策略。

Result: CDFlow显著提高了运动规划的效率和轨迹质量。

Conclusion: CDFlow为复杂环境中的碰撞感知机器人提供了更鲁棒和高效的规划方法。

Abstract: Signed Distance Fields (SDFs) are a fundamental representation in robot
motion planning. Their configuration-space counterpart, the Configuration Space
Distance Field (CDF), directly encodes distances in joint space, offering a
unified representation for optimization and control. However, existing CDF
formulations face two major challenges in high-degree-of-freedom (DoF) robots:
(1) they effectively return only a single nearest collision configuration,
neglecting the multi-modal nature of minimal-distance collision configurations
and leading to gradient ambiguity; and (2) they rely on sparse sampling of the
collision boundary, which often fails to identify the true closest
configurations, producing oversmoothed approximations and geometric distortion
in high-dimensional spaces. We propose CDFlow, a novel framework that addresses
these limitations by learning a continuous flow in configuration space via
Neural Ordinary Differential Equations (Neural ODEs). We redefine the problem
from finding a single nearest point to modeling the distribution of
minimal-distance collision configurations. We also introduce an adaptive
refinement sampling strategy to generate high-fidelity training data for this
distribution. The resulting Neural ODE implicitly models this multi-modal
distribution and produces a smooth, consistent gradient field-derived as the
expected direction towards the distribution-that mitigates gradient ambiguity
and preserves sharp geometric features. Extensive experiments on high-DoF
motion planning tasks demonstrate that CDFlow significantly improves planning
efficiency, trajectory quality, and robustness compared to existing CDF-based
methods, enabling more robust and efficient planning for collision-aware robots
in complex environments.

</details>


### [164] [Dual-Actor Fine-Tuning of VLA Models: A Talk-and-Tweak Human-in-the-Loop Approach](https://arxiv.org/abs/2509.13774)
*Piaopiao Jin,Qi Wang,Guokang Sun,Ziwen Cai,Pinjia He,Yangwei You*

Main category: cs.RO

TL;DR: 提出了一种基于强化学习的人机协作双执行器微调框架，通过语义化语言命令优化策略学习，显著提升了复杂任务的成功率和效率。


<details>
  <summary>Details</summary>
Motivation: 解决视觉-语言-动作模型在复杂现实任务中数据质量受限的问题，探索强化学习作为替代方案。

Method: 采用双执行器框架，主执行器负责多任务性能，细化执行器进行潜在空间适应，并引入轻量级人机交互方案。

Result: 在真实多任务实验中，101分钟内实现100%成功率；长时任务中保持50%成功率；多机器人训练效率提升2倍。

Conclusion: 该框架在复杂任务中表现出色，且可扩展至多机器人场景，具有实际应用潜力。

Abstract: Vision-language-action (VLA) models demonstrate strong generalization in
robotic manipulation but face challenges in complex, real-world tasks. While
supervised fine-tuning with demonstrations is constrained by data quality,
reinforcement learning (RL) offers a promising alternative. We propose a
human-in-the-loop dual-actor fine-tuning framework grounded in RL. The
framework integrates a primary actor for robust multi-task performance with a
refinement actor for latent-space adaptation. Beyond standard physical
interventions, we introduce a lightweight talk-and-tweak scheme that converts
human corrections into semantically grounded language commands, thereby
generating a new dataset for policy learning. In real-world multi-task
experiments, our approach achieves 100% success across three tasks within 101
minutes of online fine-tuning. For long-horizon tasks, it sustains a 50%
success rate over 12 consecutive operations. Furthermore, the framework scales
effectively to multi-robot training, achieving up to a 2 times improvement in
efficiency when using dual robots. The experiment videos are available at
https://sites.google.com/view/hil-daft/.

</details>


### [165] [Behavior Foundation Model for Humanoid Robots](https://arxiv.org/abs/2509.13780)
*Weishuai Zeng,Shunlin Lu,Kangning Yin,Xiaojie Niu,Minyue Dai,Jingbo Wang,Jiangmiao Pang*

Main category: cs.RO

TL;DR: 提出了一种名为行为基础模型（BFM）的生成模型，用于提升人形机器人的全身控制（WBC）能力，实现跨任务和技能的泛化。


<details>
  <summary>Details</summary>
Motivation: 现有WBC框架多为任务专用，依赖人工设计的奖励机制，泛化能力有限，难以应对复杂场景。

Method: 结合掩码在线蒸馏框架和条件变分自编码器（CVAE）建模行为分布，支持灵活控制和快速学习新行为。

Result: 实验表明BFM能泛化多种WBC任务，并快速适应新行为。

Conclusion: BFM是迈向通用人形机器人控制基础模型的重要一步。

Abstract: Whole-body control (WBC) of humanoid robots has witnessed remarkable progress
in skill versatility, enabling a wide range of applications such as locomotion,
teleoperation, and motion tracking. Despite these achievements, existing WBC
frameworks remain largely task-specific, relying heavily on labor-intensive
reward engineering and demonstrating limited generalization across tasks and
skills. These limitations hinder their response to arbitrary control modes and
restrict their deployment in complex, real-world scenarios. To address these
challenges, we revisit existing WBC systems and identify a shared objective
across diverse tasks: the generation of appropriate behaviors that guide the
robot toward desired goal states. Building on this insight, we propose the
Behavior Foundation Model (BFM), a generative model pretrained on large-scale
behavioral datasets to capture broad, reusable behavioral knowledge for
humanoid robots. BFM integrates a masked online distillation framework with a
Conditional Variational Autoencoder (CVAE) to model behavioral distributions,
thereby enabling flexible operation across diverse control modes and efficient
acquisition of novel behaviors without retraining from scratch. Extensive
experiments in both simulation and on a physical humanoid platform demonstrate
that BFM generalizes robustly across diverse WBC tasks while rapidly adapting
to new behaviors. These results establish BFM as a promising step toward a
foundation model for general-purpose humanoid control.

</details>


### [166] [Shell-Type Soft Jig for Holding Objects during Disassembly](https://arxiv.org/abs/2509.13802)
*Takuya Kiyokawa,Ryunosuke Takebayashi,Kensuke Harada*

Main category: cs.RO

TL;DR: 提出一种基于气囊的柔性夹具，用于机器人拆卸，能适应多种形状并减少对高精度感知和规划的需求。


<details>
  <summary>Details</summary>
Motivation: 传统夹具需要专用设计和高精度操作，容易导致部件损坏，因此需要一种更灵活、通用的解决方案。

Method: 设计了一种壳式柔性夹具，利用气囊机制实现稳定夹持，适应不同形状并减少误差影响。

Result: 实验表明，该夹具在多种物体上表现优于传统夹具和软夹具，但也存在一定局限性。

Conclusion: 该柔性夹具具有实际可行性，但需进一步优化以克服其局限性。

Abstract: This study addresses a flexible holding tool for robotic disassembly. We
propose a shell-type soft jig that securely and universally holds objects,
mitigating the risk of component damage and adapting to diverse shapes while
enabling soft fixation that is robust to recognition, planning, and control
errors. The balloon-based holding mechanism ensures proper alignment and stable
holding performance, thereby reducing the need for dedicated jig design, highly
accurate perception, precise grasping, and finely tuned trajectory planning
that are typically required with conventional fixtures. Our experimental
results demonstrate the practical feasibility of the proposed jig through
performance comparisons with a vise and a jamming-gripper-inspired soft jig.
Tests on ten different objects further showed representative successes and
failures, clarifying the jig's limitations and outlook.

</details>


### [167] [Soft Regrasping Tool Inspired by Jamming Gripper](https://arxiv.org/abs/2509.13815)
*Takuya Kiyokawa,Zhengtao Hu,Weiwei Wan,Kensuke Harada*

Main category: cs.RO

TL;DR: 提出了一种基于软夹具的重新抓取方法，通过可变形的软夹具减少机器人装配中的位姿不确定性。


<details>
  <summary>Details</summary>
Motivation: 传统刚性夹具缺乏适应性，需要为每个零件专门设计，限制了灵活性。

Method: 利用堵塞过渡现象设计软夹具，通过三角形金字塔工具压入膜并排出空气形成稳定空腔，优化压入深度以平衡放置稳定性和抓取可达性。

Result: 在10种不同形状的机械零件上进行了放置实验，大多数物体的放置成功率超过80%，圆柱形物体超过90%。

Conclusion: 软夹具实现了通用、准确和可重复的重新抓取，展示了其在装配自动化中替代刚性夹具的潜力，但也指出了当前限制和未来改进方向。

Abstract: Regrasping on fixtures is a promising approach to reduce pose uncertainty in
robotic assembly, but conventional rigid fixtures lack adaptability and require
dedicated designs for each part. To overcome this limitation, we propose a soft
jig inspired by the jamming transition phenomenon, which can be continuously
deformed to accommodate diverse object geometries. By pressing a
triangular-pyramid-shaped tool into the membrane and evacuating the enclosed
air, a stable cavity is formed as a placement space. We further optimize the
stamping depth to balance placement stability and gripper accessibility. In
soft-jig-based regrasping, the key challenge lies in optimizing the cavity size
to achieve precise dropping; once the part is reliably placed, subsequent
grasping can be performed with reduced uncertainty. Accordingly, we conducted
drop experiments on ten mechanical parts of varying shapes, which achieved
placement success rates exceeding 80% for most objects and above 90% for
cylindrical ones, while failures were mainly caused by geometric constraints
and membrane properties. These results demonstrate that the proposed jig
enables general-purpose, accurate, and repeatable regrasping, while also
clarifying its current limitations and future potential as a practical
alternative to rigid fixtures in assembly automation.

</details>


### [168] [Agile in the Face of Delay: Asynchronous End-to-End Learning for Real-World Aerial Navigation](https://arxiv.org/abs/2509.13816)
*Yude Li,Zhexuan Zhou,Huizhe Li,Youmin Gong,Jie Mei*

Main category: cs.RO

TL;DR: 提出了一种异步强化学习框架，解决AAV导航中高频控制与低频感知的冲突，通过TEM模块处理数据延迟，实现100Hz控制频率。


<details>
  <summary>Details</summary>
Motivation: 现代端到端导航中，高频控制与低频感知的冲突导致控制频率降低，影响AAV的敏捷飞行。

Method: 采用异步强化学习框架，解耦感知与控制，引入TEM模块处理感知延迟，并使用两阶段课程训练。

Result: 在仿真和实际部署中，实现了100Hz控制频率，并在复杂环境中表现出鲁棒导航能力。

Conclusion: 该方法有效解决了感知与控制频率不匹配的问题，适用于实际AAV导航。

Abstract: Robust autonomous navigation for Autonomous Aerial Vehicles (AAVs) in complex
environments is a critical capability. However, modern end-to-end navigation
faces a key challenge: the high-frequency control loop needed for agile flight
conflicts with low-frequency perception streams, which are limited by sensor
update rates and significant computational cost. This mismatch forces
conventional synchronous models into undesirably low control rates. To resolve
this, we propose an asynchronous reinforcement learning framework that
decouples perception and control, enabling a high-frequency policy to act on
the latest IMU state for immediate reactivity, while incorporating perception
features asynchronously. To manage the resulting data staleness, we introduce a
theoretically-grounded Temporal Encoding Module (TEM) that explicitly
conditions the policy on perception delays, a strategy complemented by a
two-stage curriculum to ensure stable and efficient training. Validated in
extensive simulations, our method was successfully deployed in zero-shot
sim-to-real transfer on an onboard NUC, where it sustains a 100~Hz control rate
and demonstrates robust, agile navigation in cluttered real-world environments.
Our source code will be released for community reference.

</details>


### [169] [How Fly Neural Perception Mechanisms Enhance Visuomotor Control of Micro Robots](https://arxiv.org/abs/2509.13827)
*Renyuan Liu,Haoting Zhou,Chuankai Fang,Qinbing Fu*

Main category: cs.RO

TL;DR: 论文提出了一种受苍蝇视觉神经元启发的注意力驱动视觉运动控制策略，用于微型机器人的碰撞感知和反应性规避。


<details>
  <summary>Details</summary>
Motivation: 苍蝇的视觉神经感知系统具有卓越的敏捷性，为自主机器人在复杂环境中的高效运动提供了灵感。

Method: 基于苍蝇的LPLC2神经元模型，设计了一种简化的视觉运动控制策略，并优化为70KB内存以适应微型机器人。

Result: 在碰撞检测中成功率高达96.1%，且规避动作更灵活优雅。

Conclusion: 该研究展示了苍蝇神经模型在机器人避障和群体行为研究中的潜力。

Abstract: Anyone who has tried to swat a fly has likely been frustrated by its
remarkable agility.This ability stems from its visual neural perception system,
particularly the collision-selective neurons within its small brain.For
autonomous robots operating in complex and unfamiliar environments, achieving
similar agility is highly desirable but often constrained by the trade-off
between computational cost and performance.In this context, insect-inspired
intelligence offers a parsimonious route to low-power, computationally
efficient frameworks.In this paper, we propose an attention-driven visuomotor
control strategy inspired by a specific class of fly visual projection
neurons-the lobula plate/lobula column type-2 (LPLC2)-and their associated
escape behaviors.To our knowledge, this represents the first embodiment of an
LPLC2 neural model in the embedded vision of a physical mobile robot, enabling
collision perception and reactive evasion.The model was simplified and
optimized at 70KB in memory to suit the computational constraints of a
vision-based micro robot, the Colias, while preserving key neural perception
mechanisms.We further incorporated multi-attention mechanisms to emulate the
distributed nature of LPLC2 responses, allowing the robot to detect and react
to approaching targets both rapidly and selectively.We systematically evaluated
the proposed method against a state-of-the-art locust-inspired collision
detection model.Results showed that the fly-inspired visuomotor model achieved
comparable robustness, at success rate of 96.1% in collision detection while
producing more adaptive and elegant evasive maneuvers.Beyond demonstrating an
effective collision-avoidance strategy, this work highlights the potential of
fly-inspired neural models for advancing research into collective behaviors in
insect intelligence.

</details>


### [170] [UltraHiT: A Hierarchical Transformer Architecture for Generalizable Internal Carotid Artery Robotic Ultrasonography](https://arxiv.org/abs/2509.13832)
*Teng Wang,Haojun Jiang,Yuxuan Wang,Zhenguo Sun,Xiangjie Yan,Xiang Li,Gao Huang*

Main category: cs.RO

TL;DR: 提出了一种基于分层Transformer的决策架构UltraHiT，用于自动化颈动脉超声扫描，特别是针对复杂的颈内动脉（ICA）。


<details>
  <summary>Details</summary>
Motivation: 由于ICA的深度位置、曲折路径和个体差异，传统方法难以自动化扫描，因此提出了一种结合高级变异评估和低级动作决策的方法。

Method: 采用分层Transformer架构，高级模块识别变异并切换至自适应校正器或标准执行器，两者均为因果Transformer。

Result: 在未见过的个体上，成功定位ICA的准确率达到95%，优于基线方法。

Conclusion: UltraHiT有效解决了ICA自动化扫描的挑战，具有较高的实用性和泛化能力。

Abstract: Carotid ultrasound is crucial for the assessment of cerebrovascular health,
particularly the internal carotid artery (ICA). While previous research has
explored automating carotid ultrasound, none has tackled the challenging ICA.
This is primarily due to its deep location, tortuous course, and significant
individual variations, which greatly increase scanning complexity. To address
this, we propose a Hierarchical Transformer-based decision architecture, namely
UltraHiT, that integrates high-level variation assessment with low-level action
decision. Our motivation stems from conceptualizing individual vascular
structures as morphological variations derived from a standard vascular model.
The high-level module identifies variation and switches between two low-level
modules: an adaptive corrector for variations, or a standard executor for
normal cases. Specifically, both the high-level module and the adaptive
corrector are implemented as causal transformers that generate predictions
based on the historical scanning sequence. To ensure generalizability, we
collected the first large-scale ICA scanning dataset comprising 164
trajectories and 72K samples from 28 subjects of both genders. Based on the
above innovations, our approach achieves a 95% success rate in locating the ICA
on unseen individuals, outperforming baselines and demonstrating its
effectiveness. Our code will be released after acceptance.

</details>


### [171] [Track Any Motions under Any Disturbances](https://arxiv.org/abs/2509.13833)
*Zhikai Zhang,Jun Guo,Chao Chen,Jilong Wang,Chenghuai Lin,Yunrui Lian,Han Xue,Zhenrong Wang,Maoqi Liu,Huaping Liu,He Wang,Li Yi*

Main category: cs.RO

TL;DR: Any2Track是一个两阶段强化学习框架，用于在现实世界中跟踪多种运动并应对多种干扰。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够在现实世界中稳定跟踪多样化、高动态和接触丰富运动的人形运动跟踪器。

Method: 提出Any2Track框架，包括AnyTracker（通用运动跟踪器）和AnyAdapter（历史信息适应模块），以增强动态适应能力。

Result: 在Unitree G1硬件上成功实现零样本的模拟到现实迁移，并在多种干扰下表现出色。

Conclusion: Any2Track是一个高效且适应性强的运动跟踪框架，适用于现实世界的多样化场景。

Abstract: A foundational humanoid motion tracker is expected to be able to track
diverse, highly dynamic, and contact-rich motions. More importantly, it needs
to operate stably in real-world scenarios against various dynamics
disturbances, including terrains, external forces, and physical property
changes for general practical use. To achieve this goal, we propose Any2Track
(Track Any motions under Any disturbances), a two-stage RL framework to track
various motions under multiple disturbances in the real world. Any2Track
reformulates dynamics adaptability as an additional capability on top of basic
action execution and consists of two key components: AnyTracker and AnyAdapter.
AnyTracker is a general motion tracker with a series of careful designs to
track various motions within a single policy. AnyAdapter is a history-informed
adaptation module that endows the tracker with online dynamics adaptability to
overcome the sim2real gap and multiple real-world disturbances. We deploy
Any2Track on Unitree G1 hardware and achieve a successful sim2real transfer in
a zero-shot manner. Any2Track performs exceptionally well in tracking various
motions under multiple real-world disturbances.

</details>


### [172] [Pre-Manipulation Alignment Prediction with Parallel Deep State-Space and Transformer Models](https://arxiv.org/abs/2509.13839)
*Motonari Kambara,Komei Sugiura*

Main category: cs.RO

TL;DR: 提出一种预测开放词汇物体操作任务未来成功率的模型，通过多级轨迹融合模块提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法在操作后判断成功与否，难以预防潜在危险且依赖失败触发重规划，效率低。

Method: 结合深度状态空间模型和Transformer编码器，捕捉末端执行器轨迹的多级时间序列自相关性。

Result: 实验表明，该方法优于现有方法，包括基础模型。

Conclusion: 提出的模型能有效预测操作任务的成功率，提升效率和安全性。

Abstract: In this work, we address the problem of predicting the future success of
open-vocabulary object manipulation tasks. Conventional approaches typically
determine success or failure after the action has been carried out. However,
they make it difficult to prevent potential hazards and rely on failures to
trigger replanning, thereby reducing the efficiency of object manipulation
sequences. To overcome these challenges, we propose a model, which predicts the
alignment between a pre-manipulation egocentric image with the planned
trajectory and a given natural language instruction. We introduce a Multi-Level
Trajectory Fusion module, which employs a state-of-the-art deep state-space
model and a transformer encoder in parallel to capture multi-level time-series
self-correlation within the end effector trajectory. Our experimental results
indicate that the proposed method outperformed existing methods, including
foundation models.

</details>


### [173] [InterKey: Cross-modal Intersection Keypoints for Global Localization on OpenStreetMap](https://arxiv.org/abs/2509.13857)
*Nguyen Hoang Khoi Tran,Julie Stephany Berrio,Mao Shan,Stewart Worrall*

Main category: cs.RO

TL;DR: InterKey是一种利用道路交叉口作为标志物的跨模态框架，用于全球定位，在GNSS信号差的环境中表现优异。


<details>
  <summary>Details</summary>
Motivation: 在GNSS信号差的环境中，高精度地图成本高且难以扩展，而OpenStreetMap（OSM）的粗糙抽象难以匹配传感器数据，因此需要一种低成本、可扩展的定位方案。

Method: InterKey通过联合编码点云和OSM中的道路和建筑印记，构建紧凑的二进制描述符，并引入差异缓解、方向确定和面积均衡采样策略，实现跨模态匹配。

Result: 在KITTI数据集上，InterKey表现优于现有基线方法，实现了最先进的定位精度。

Conclusion: InterKey为车辆定位提供了一种低成本、可扩展且鲁棒的解决方案，适用于能生成密集结构点云的传感器。

Abstract: Reliable global localization is critical for autonomous vehicles, especially
in environments where GNSS is degraded or unavailable, such as urban canyons
and tunnels. Although high-definition (HD) maps provide accurate priors, the
cost of data collection, map construction, and maintenance limits scalability.
OpenStreetMap (OSM) offers a free and globally available alternative, but its
coarse abstraction poses challenges for matching with sensor data. We propose
InterKey, a cross-modal framework that leverages road intersections as
distinctive landmarks for global localization. Our method constructs compact
binary descriptors by jointly encoding road and building imprints from point
clouds and OSM. To bridge modality gaps, we introduce discrepancy mitigation,
orientation determination, and area-equalized sampling strategies, enabling
robust cross-modal matching. Experiments on the KITTI dataset demonstrate that
InterKey achieves state-of-the-art accuracy, outperforming recent baselines by
a large margin. The framework generalizes to sensors that can produce dense
structural point clouds, offering a scalable and cost-effective solution for
robust vehicle localization.

</details>


### [174] [Using Petri Nets for Context-Adaptive Robot Explanations](https://arxiv.org/abs/2509.13861)
*Görkem Kılınç Soylu,Neziha Akalin,Maria Riveiro*

Main category: cs.RO

TL;DR: 使用Petri网建模上下文信息，实现机器人自适应解释，验证了其鲁棒性和灵活性。


<details>
  <summary>Details</summary>
Motivation: 在人与机器人交互中，机器人需要自然透明的沟通以建立信任，这要求其根据上下文调整解释方式。

Method: 提出使用Petri网（PNs）建模上下文信息，分析动态交互中的并发动作、因果依赖和系统状态。

Result: 通过场景验证，模型具备无死锁、上下文敏感可达性、有界性和活性等关键属性。

Conclusion: Petri网适用于设计和验证人机交互中的上下文自适应解释，展现了其鲁棒性和灵活性。

Abstract: In human-robot interaction, robots must communicate in a natural and
transparent manner to foster trust, which requires adapting their communication
to the context. In this paper, we propose using Petri nets (PNs) to model
contextual information for adaptive robot explanations. PNs provide a formal,
graphical method for representing concurrent actions, causal dependencies, and
system states, making them suitable for analyzing dynamic interactions between
humans and robots. We demonstrate this approach through a scenario involving a
robot that provides explanations based on contextual cues such as user
attention and presence. Model analysis confirms key properties, including
deadlock-freeness, context-sensitive reachability, boundedness, and liveness,
showing the robustness and flexibility of PNs for designing and verifying
context-adaptive explanations in human-robot interactions.

</details>


### [175] [Repulsive Trajectory Modification and Conflict Resolution for Efficient Multi-Manipulator Motion Planning](https://arxiv.org/abs/2509.13882)
*Junhwa Hong,Beomjoon Lee,Woojin Lee,Changjoo Nam*

Main category: cs.RO

TL;DR: 提出了一种基于冲突搜索（CBS）的高效多机械臂运动规划方法，通过梯度下降和人工势场减少后续冲突，提高成功率和速度。


<details>
  <summary>Details</summary>
Motivation: 多机械臂系统协调运动的高维配置空间导致计算复杂，传统CBS方法因冲突解决导致约束树指数增长。

Method: 在CBS的两层结构中，低层规划器使用人工势场生成排斥力，引导轨迹避开冲突，并开发单步冲突解决策略。

Result: 实验表明，该方法减少了约束树节点扩展，提高了成功率和求解速度。

Conclusion: 提出的方法在多机械臂运动规划中优于现有算法，具有高效性和实用性。

Abstract: We propose an efficient motion planning method designed to efficiently find
collision-free trajectories for multiple manipulators. While multi-manipulator
systems offer significant advantages, coordinating their motions is
computationally challenging owing to the high dimensionality of their composite
configuration space. Conflict-Based Search (CBS) addresses this by decoupling
motion planning, but suffers from subsequent conflicts incurred by resolving
existing conflicts, leading to an exponentially growing constraint tree of CBS.
Our proposed method is based on repulsive trajectory modification within the
two-level structure of CBS. Unlike conventional CBS variants, the low-level
planner applies a gradient descent approach using an Artificial Potential
Field. This field generates repulsive forces that guide the trajectory of the
conflicting manipulator away from those of other robots. As a result,
subsequent conflicts are less likely to occur. Additionally, we develop a
strategy that, under a specific condition, directly attempts to find a
conflict-free solution in a single step without growing the constraint tree.
Through extensive tests including physical robot experiments, we demonstrate
that our method consistently reduces the number of expanded nodes in the
constraint tree, achieves a higher success rate, and finds a solution faster
compared to Enhanced CBS and other state-of-the-art algorithms.

</details>


### [176] [PhysicalAgent: Towards General Cognitive Robotics with Foundation World Models](https://arxiv.org/abs/2509.13903)
*Artem Lykov,Jeffrin Sam,Hung Khang Nguyen,Vladislav Kozlovskiy,Yara Mahmoud,Valerii Serpiva,Miguel Altamirano Cabrera,Mikhail Konenkov,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: PhysicalAgent是一个机器人操作框架，结合迭代推理、扩散视频生成和闭环执行，通过视频演示和迭代重规划实现鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 研究目标是开发一种能够通过视频生成和迭代执行来应对机器人操作中的失败，提高任务成功率的通用框架。

Method: 方法包括生成候选轨迹的视频演示、机器人执行、并根据失败情况迭代重规划。

Result: 实验表明，该方法在多种感知模态和机器人平台上优于现有方法，首次尝试成功率较低（20-30%），但通过迭代修正可提升至80%。

Conclusion: PhysicalAgent展示了视频生成推理在通用机器人操作中的潜力，并强调了迭代执行对初始失败恢复的重要性。

Abstract: We introduce PhysicalAgent, an agentic framework for robotic manipulation
that integrates iterative reasoning, diffusion-based video generation, and
closed-loop execution. Given a textual instruction, our method generates short
video demonstrations of candidate trajectories, executes them on the robot, and
iteratively re-plans in response to failures. This approach enables robust
recovery from execution errors. We evaluate PhysicalAgent across multiple
perceptual modalities (egocentric, third-person, and simulated) and robotic
embodiments (bimanual UR3, Unitree G1 humanoid, simulated GR1), comparing
against state-of-the-art task-specific baselines. Experiments demonstrate that
our method consistently outperforms prior approaches, achieving up to 83%
success on human-familiar tasks. Physical trials reveal that first-attempt
success is limited (20-30%), yet iterative correction increases overall success
to 80% across platforms. These results highlight the potential of video-based
generative reasoning for general-purpose robotic manipulation and underscore
the importance of iterative execution for recovering from initial failures. Our
framework paves the way for scalable, adaptable, and robust robot control.

</details>


### [177] [MAP: End-to-End Autonomous Driving with Map-Assisted Planning](https://arxiv.org/abs/2509.13926)
*Huilin Yin,Yiming Kan,Daniel Watzenig*

Main category: cs.RO

TL;DR: 提出了一种名为MAP的新型地图辅助端到端轨迹规划框架，显著提升了自动驾驶系统的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法未充分利用在线地图模块的潜力，限制了轨迹规划的优化空间。

Method: 通过Plan-enhancing Online Mapping模块、Ego-status-guided Planning模块和Weight Adapter，显式整合地图特征和车辆状态。

Result: 在DAIR-V2X-seq-SPD数据集上，L2位移误差减少16.6%，脱轨率降低56.2%，综合评分提升44.5%。

Conclusion: 显式利用语义地图特征可有效提升端到端自动驾驶系统的规划性能，为系统设计提供了新方向。

Abstract: In recent years, end-to-end autonomous driving has attracted increasing
attention for its ability to jointly model perception, prediction, and planning
within a unified framework. However, most existing approaches underutilize the
online mapping module, leaving its potential to enhance trajectory planning
largely untapped. This paper proposes MAP (Map-Assisted Planning), a novel
map-assisted end-to-end trajectory planning framework. MAP explicitly
integrates segmentation-based map features and the current ego status through a
Plan-enhancing Online Mapping module, an Ego-status-guided Planning module, and
a Weight Adapter based on current ego status. Experiments conducted on the
DAIR-V2X-seq-SPD dataset demonstrate that the proposed method achieves a 16.6%
reduction in L2 displacement error, a 56.2% reduction in off-road rate, and a
44.5% improvement in overall score compared to the UniV2X baseline, even
without post-processing. Furthermore, it achieves top ranking in Track 2 of the
End-to-End Autonomous Driving through V2X Cooperation Challenge of MEIS
Workshop @CVPR2025, outperforming the second-best model by 39.5% in terms of
overall score. These results highlight the effectiveness of explicitly
leveraging semantic map features in planning and suggest new directions for
improving structure design in end-to-end autonomous driving systems. Our code
is available at https://gitee.com/kymkym/map.git

</details>


### [178] [Reinforcement Learning for Autonomous Point-to-Point UAV Navigation](https://arxiv.org/abs/2509.13943)
*Salim Oyinlola,Nitesh Subedi,Soumik Sarkar*

Main category: cs.RO

TL;DR: 使用强化学习（RL）训练无人机（UAV）实现自主点对点导航，减少人工干预。


<details>
  <summary>Details</summary>
Motivation: 无人机在自动化任务中需要可靠自主性，但传统方法依赖人工干预。

Method: 通过RL和自定义奖励函数训练无人机，结合ROS和Gym环境进行部署与测试。

Result: 无人机在实际条件下成功实现自主导航，验证了RL控制的可行性。

Conclusion: RL方法适用于现实场景中的无人机点对点导航任务。

Abstract: Unmanned Aerial Vehicles (UAVs) are increasingly used in automated
inspection, delivery, and navigation tasks that require reliable autonomy. This
project develops a reinforcement learning (RL) approach to enable a single UAV
to autonomously navigate between predefined points without manual intervention.
The drone learns navigation policies through trial-and-error interaction, using
a custom reward function that encourages goal-reaching efficiency while
penalizing collisions and unsafe behavior. The control system integrates ROS
with a Gym-compatible training environment, enabling flexible deployment and
testing. After training, the learned policy is deployed on a real UAV platform
and evaluated under practical conditions. Results show that the UAV can
successfully perform autonomous navigation with minimal human oversight,
demonstrating the viability of RL-based control for point-to-point drone
operations in real-world scenarios.

</details>


### [179] [The Influence of Facial Features on the Perceived Trustworthiness of a Social Robot](https://arxiv.org/abs/2509.13948)
*Benedict Barrow,Roger K. Moore*

Main category: cs.RO

TL;DR: 研究探讨了社交机器人面部特征对人类信任感的影响，发现‘婴儿脸’特征（如眼睛形状和大小）显著提升信任感。


<details>
  <summary>Details</summary>
Motivation: 理解人类对机器人信任的影响因素，以优化人机交互设计。

Method: 通过调整Furhat机器人的面部投影，研究不同面部特征对信任感的影响。

Result: 眼睛形状和大小对信任感有显著影响。

Conclusion: 研究为社交机器人设计提供了重要参考，以提升人机交互效果。

Abstract: Trust and the perception of trustworthiness play an important role in
decision-making and our behaviour towards others, and this is true not only of
human-human interactions but also of human-robot interactions. While
significant advances have been made in recent years in the field of social
robotics, there is still some way to go before we fully understand the factors
that influence human trust in robots. This paper presents the results of a
study into the first impressions created by a social robot's facial features,
based on the hypothesis that a `babyface' engenders trust. By manipulating the
back-projected face of a Furhat robot, the study confirms that eye shape and
size have a significant impact on the perception of trustworthiness. The work
thus contributes to an understanding of the design choices that need to be made
when developing social robots so as to optimise the effectiveness of
human-robot interaction.

</details>


### [180] [SHaRe-RL: Structured, Interactive Reinforcement Learning for Contact-Rich Industrial Assembly Tasks](https://arxiv.org/abs/2509.13949)
*Jannick Stranghöner,Philipp Hartmann,Marco Braun,Sebastian Wrede,Klaus Neumann*

Main category: cs.RO

TL;DR: SHaRe-RL是一个强化学习框架，结合多种先验知识，高效安全地解决高混合低产量工业装配任务。


<details>
  <summary>Details</summary>
Motivation: 当前机器人系统在高混合低产量工业装配中难以兼顾灵活性、安全性和效率，SHaRe-RL旨在解决这一问题。

Method: 通过结构化技能、结合人类演示和在线修正、限制交互力，实现安全和高效学习。

Result: 在工业Harting连接器插入任务中，SHaRe-RL在0.2-0.4毫米间隙下表现可靠。

Conclusion: SHaRe-RL证明过程专业知识可提升强化学习在工业装配中的安全性和经济性。

Abstract: High-mix low-volume (HMLV) industrial assembly, common in small and
medium-sized enterprises (SMEs), requires the same precision, safety, and
reliability as high-volume automation while remaining flexible to product
variation and environmental uncertainty. Current robotic systems struggle to
meet these demands. Manual programming is brittle and costly to adapt, while
learning-based methods suffer from poor sample efficiency and unsafe
exploration in contact-rich tasks. To address this, we present SHaRe-RL, a
reinforcement learning framework that leverages multiple sources of prior
knowledge. By (i) structuring skills into manipulation primitives, (ii)
incorporating human demonstrations and online corrections, and (iii) bounding
interaction forces with per-axis compliance, SHaRe-RL enables efficient and
safe online learning for long-horizon, contact-rich industrial assembly tasks.
Experiments on the insertion of industrial Harting connector modules with
0.2-0.4 mm clearance demonstrate that SHaRe-RL achieves reliable performance
within practical time budgets. Our results show that process expertise, without
requiring robotics or RL knowledge, can meaningfully contribute to learning,
enabling safer, more robust, and more economically viable deployment of RL for
industrial assembly.

</details>


### [181] [SEG-Parking: Towards Safe, Efficient, and Generalizable Autonomous Parking via End-to-End Offline Reinforcement Learning](https://arxiv.org/abs/2509.13956)
*Zewei Yang,Zengqi Peng,Jun Ma*

Main category: cs.RO

TL;DR: SEG-Parking是一种基于离线强化学习的端到端框架，用于解决自动驾驶中的停车问题，具有高成功率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 非结构化环境和动态交互对自动驾驶停车任务提出了挑战，需要一种能够处理交互感知的解决方案。

Method: 构建专用停车数据集，预训练目标条件状态编码器，并通过保守正则化优化离线RL策略。

Result: 在CARLA模拟器中表现出高成功率和良好的泛化能力。

Conclusion: SEG-Parking框架在复杂停车场景中表现优异，数据集和代码将公开。

Abstract: Autonomous parking is a critical component for achieving safe and efficient
urban autonomous driving. However, unstructured environments and dynamic
interactions pose significant challenges to autonomous parking tasks. To
address this problem, we propose SEG-Parking, a novel end-to-end offline
reinforcement learning (RL) framework to achieve interaction-aware autonomous
parking. Notably, a specialized parking dataset is constructed for parking
scenarios, which include those without interference from the opposite vehicle
(OV) and complex ones involving interactions with the OV. Based on this
dataset, a goal-conditioned state encoder is pretrained to map the fused
perception information into the latent space. Then, an offline RL policy is
optimized with a conservative regularizer that penalizes out-of-distribution
actions. Extensive closed-loop experiments are conducted in the high-fidelity
CARLA simulator. Comparative results demonstrate the superior performance of
our framework with the highest success rate and robust generalization to
out-of-distribution parking scenarios. The related dataset and source code will
be made publicly available after the paper is accepted.

</details>


### [182] [MetricNet: Recovering Metric Scale in Generative Navigation Policies](https://arxiv.org/abs/2509.13965)
*Abhijeet Nayak,Débora N. P. Oliveira,Samiran Gode,Cordelia Schmid,Wolfram Burgard*

Main category: cs.RO

TL;DR: 论文提出MetricNet和MetricNav，解决生成导航策略中的无度量基础和短视行为问题，显著提升导航性能。


<details>
  <summary>Details</summary>
Motivation: 生成导航策略存在两个问题：轨迹缺乏度量基础，控制策略忽视完整路径导致短视行为。

Method: 提出MetricNet预测路标点间的度量距离，并整合为MetricNav导航策略。

Result: 在仿真和真实实验中验证了MetricNet和MetricNav的有效性，显著提升导航和探索性能。

Conclusion: MetricNet和MetricNav解决了生成导航策略的关键问题，提升了导航的安全性和效率。

Abstract: Generative navigation policies have made rapid progress in improving
end-to-end learned navigation. Despite their promising results, this paradigm
has two structural problems. First, the sampled trajectories exist in an
abstract, unscaled space without metric grounding. Second, the control strategy
discards the full path, instead moving directly towards a single waypoint. This
leads to short-sighted and unsafe actions, moving the robot towards obstacles
that a complete and correctly scaled path would circumvent. To address these
issues, we propose MetricNet, an effective add-on for generative navigation
that predicts the metric distance between waypoints, grounding policy outputs
in real-world coordinates. We evaluate our method in simulation with a new
benchmarking framework and show that executing MetricNet-scaled waypoints
significantly improves both navigation and exploration performance. Beyond
simulation, we further validate our approach in real-world experiments.
Finally, we propose MetricNav, which integrates MetricNet into a navigation
policy to guide the robot away from obstacles while still moving towards the
goal.

</details>


### [183] [BIM Informed Visual SLAM for Construction Monitoring](https://arxiv.org/abs/2509.13972)
*Asier Bikandi,Miguel Fernandez-Cortizas,Muhammad Shaheer,Ali Tourani,Holger Voos,Jose Luis Sanchez-Lopez*

Main category: cs.RO

TL;DR: 提出了一种结合BIM的RGB-D SLAM系统，用于建筑工地监控，显著减少了轨迹和地图误差。


<details>
  <summary>Details</summary>
Motivation: 解决视觉SLAM在建筑环境中因重复布局、遮挡和低纹理结构导致的漂移问题。

Method: 利用BIM作为结构先验知识，通过建立检测到的墙与BIM对应关系，作为后端优化的约束。

Result: 在真实工地验证，轨迹误差平均减少23.71%，地图RMSE减少7.14%。

Conclusion: BIM约束能可靠对齐数字设计与实际场景，适用于部分施工条件。

Abstract: Simultaneous Localization and Mapping (SLAM) is a key tool for monitoring
construction sites, where aligning the evolving as-built state with the
as-planned design enables early error detection and reduces costly rework.
LiDAR-based SLAM achieves high geometric precision, but its sensors are
typically large and power-demanding, limiting their use on portable platforms.
Visual SLAM offers a practical alternative with lightweight cameras already
embedded in most mobile devices. however, visually mapping construction
environments remains challenging: repetitive layouts, occlusions, and
incomplete or low-texture structures often cause drift in the trajectory map.
To mitigate this, we propose an RGB-D SLAM system that incorporates the
Building Information Model (BIM) as structural prior knowledge. Instead of
relying solely on visual cues, our system continuously establishes
correspondences between detected wall and their BIM counterparts, which are
then introduced as constraints in the back-end optimization. The proposed
method operates in real time and has been validated on real construction sites,
reducing trajectory error by an average of 23.71% and map RMSE by 7.14%
compared to visual SLAM baselines. These results demonstrate that BIM
constraints enable reliable alignment of the digital plan with the as-built
scene, even under partially constructed conditions.

</details>


### [184] [Flexible and Foldable: Workspace Analysis and Object Manipulation Using a Soft, Interconnected, Origami-Inspired Actuator Array](https://arxiv.org/abs/2509.13998)
*Bailey Dacre,Rodrigo Moreno,Serhat Demirtas,Ziqiao Wang,Yuhao Jiang,Jamie Paik,Kasper Stoy,Andrés Faíña*

Main category: cs.RO

TL;DR: 提出了一种基于折纸灵感的分布式操纵系统（DMS），通过柔性连接表面降低执行器密度，提升操纵能力。


<details>
  <summary>Details</summary>
Motivation: 现有DMS设计依赖高执行器密度且对物体与执行器比例有限制，缺乏适应性。

Method: 使用3自由度折纸式机器人瓦片阵列，通过柔性表面连接，形成连续可控的操纵表面。

Result: 系统操纵面积增加1.84倍，无需增加执行器数量，降低了成本和复杂性。

Conclusion: 该设计为传统高密度阵列提供了低成本替代方案，并拓展了柔性连接的操纵策略。

Abstract: Object manipulation is a fundamental challenge in robotics, where systems
must balance trade-offs among manipulation capabilities, system complexity, and
throughput. Distributed manipulator systems (DMS) use the coordinated motion of
actuator arrays to perform complex object manipulation tasks, seeing widespread
exploration within the literature and in industry. However, existing DMS
designs typically rely on high actuator densities and impose constraints on
object-to-actuator scale ratios, limiting their adaptability. We present a
novel DMS design utilizing an array of 3-DoF, origami-inspired robotic tiles
interconnected by a compliant surface layer. Unlike conventional DMS, our
approach enables manipulation not only at the actuator end effectors but also
across a flexible surface connecting all actuators; creating a continuous,
controllable manipulation surface. We analyse the combined workspace of such a
system, derive simple motion primitives, and demonstrate its capabilities to
translate simple geometric objects across an array of tiles. By leveraging the
inter-tile connective material, our approach significantly reduces actuator
density, increasing the area over which an object can be manipulated by x1.84
without an increase in the number of actuators. This design offers a lower cost
and complexity alternative to traditional high-density arrays, and introduces
new opportunities for manipulation strategies that leverage the flexibility of
the interconnected surface.

</details>


### [185] [Whole-body Motion Control of an Omnidirectional Wheel-Legged Mobile Manipulator via Contact-Aware Dynamic Optimization](https://arxiv.org/abs/2509.14010)
*Zong Chen,Shaoyang Li,Ben Liu,Min Li,Zhouping Yin,Yiqun Li*

Main category: cs.RO

TL;DR: 该论文提出了一种全向轮腿四足机器人及其全身运动控制框架，解决了自由度冗余和复杂接触动力学问题，实现了敏捷移动和精确操作。


<details>
  <summary>Details</summary>
Motivation: 轮腿机器人结合机械臂在物流和工业自动化中潜力巨大，但统一控制因自由度冗余和复杂接触动力学而具有挑战性。

Method: 设计了全向轮腿四足机器人，提出接触感知的全身动态优化框架，结合点接触和线接触模型，并引入热启动策略加速优化。

Result: 仿真和实验验证了框架的有效性，展示了敏捷地形穿越、高速全向移动和精确操作能力。

Conclusion: 该系统在半结构化环境中具有工厂自动化、城市物流和服务机器人的应用潜力。

Abstract: Wheel-legged robots with integrated manipulators hold great promise for
mobile manipulation in logistics, industrial automation, and human-robot
collaboration. However, unified control of such systems remains challenging due
to the redundancy in degrees of freedom, complex wheel-ground contact dynamics,
and the need for seamless coordination between locomotion and manipulation. In
this work, we present the design and whole-body motion control of an
omnidirectional wheel-legged quadrupedal robot equipped with a dexterous
manipulator. The proposed platform incorporates independently actuated steering
modules and hub-driven wheels, enabling agile omnidirectional locomotion with
high maneuverability in structured environments. To address the challenges of
contact-rich interaction, we develop a contact-aware whole-body dynamic
optimization framework that integrates point-contact modeling for manipulation
with line-contact modeling for wheel-ground interactions. A warm-start strategy
is introduced to accelerate online optimization, ensuring real-time feasibility
for high-dimensional control. Furthermore, a unified kinematic model tailored
for the robot's 4WIS-4WID actuation scheme eliminates the need for mode
switching across different locomotion strategies, improving control consistency
and robustness. Simulation and experimental results validate the effectiveness
of the proposed framework, demonstrating agile terrain traversal, high-speed
omnidirectional mobility, and precise manipulation under diverse scenarios,
underscoring the system's potential for factory automation, urban logistics,
and service robotics in semi-structured environments.

</details>


### [186] [TransforMARS: Fault-Tolerant Self-Reconfiguration for Arbitrarily Shaped Modular Aerial Robot Systems](https://arxiv.org/abs/2509.14025)
*Rui Huang,Zhiyu Gao,Siyu Tang,Jialin Zhang,Lei He,Ziqian Zhang,Lin Zhao*

Main category: cs.RO

TL;DR: TransforMARS提出了一种通用的故障容忍重构框架，用于处理任意形状的模块化空中机器人系统（MARS）在多转子或单元故障下的重构问题，确保飞行稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有MARS的自重构方法仅针对矩形形状且容忍单一转子或单元故障，无法满足复杂形状和多故障场景的需求。

Method: 开发算法识别和构建最小可控装配体，规划可行的拆装序列以实现目标配置。

Result: 在复杂形状MARS配置中验证了TransforMARS的优越性，显著提升了处理多样配置和容忍多故障的能力。

Conclusion: TransforMARS提供了更灵活和实用的重构方法，优于现有技术。

Abstract: Modular Aerial Robot Systems (MARS) consist of multiple drone modules that
are physically bound together to form a single structure for flight. Exploiting
structural redundancy, MARS can be reconfigured into different formations to
mitigate unit or rotor failures and maintain stable flight. Prior work on MARS
self-reconfiguration has solely focused on maximizing controllability margins
to tolerate a single rotor or unit fault for rectangular-shaped MARS. We
propose TransforMARS, a general fault-tolerant reconfiguration framework that
transforms arbitrarily shaped MARS under multiple rotor and unit faults while
ensuring continuous in-air stability. Specifically, we develop algorithms to
first identify and construct minimum controllable assemblies containing faulty
units. We then plan feasible disassembly-assembly sequences to transport MARS
units or subassemblies to form target configuration. Our approach enables more
flexible and practical feasible reconfiguration. We validate TransforMARS in
challenging arbitrarily shaped MARS configurations, demonstrating substantial
improvements over prior works in both the capacity of handling diverse
configurations and the number of faults tolerated. The videos and source code
of this work are available at the anonymous repository:
https://anonymous.4open.science/r/TransforMARS-1030/

</details>


### [187] [Prompt2Auto: From Motion Prompt to Automated Control via Geometry-Invariant One-Shot Gaussian Process Learning](https://arxiv.org/abs/2509.14040)
*Zewen Yang,Xiaobing Dai,Dongfa Zhang,Yu Li,Ziyang Meng,Bingkun Huang,Hamid Sadeghian,Sami Haddadin*

Main category: cs.RO

TL;DR: Prompt2Auto是一种几何不变的单次高斯过程学习框架，通过单次运动提示实现机器人的人导自动控制。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要大量数据集且难以跨坐标变换泛化，Prompt2Auto旨在解决这一问题。

Method: 提出基于坐标变换的数据集构建策略，确保平移、旋转和缩放不变性，支持多步预测。

Result: 通过数值模拟和真实机器人实验验证，方法有效、泛化能力强且显著减少演示负担。

Conclusion: Prompt2Auto是一种高效、通用的机器人学习框架。

Abstract: Learning from demonstration allows robots to acquire complex skills from
human demonstrations, but conventional approaches often require large datasets
and fail to generalize across coordinate transformations. In this paper, we
propose Prompt2Auto, a geometry-invariant one-shot Gaussian process (GeoGP)
learning framework that enables robots to perform human-guided automated
control from a single motion prompt. A dataset-construction strategy based on
coordinate transformations is introduced that enforces invariance to
translation, rotation, and scaling, while supporting multi-step predictions.
Moreover, GeoGP is robust to variations in the user's motion prompt and
supports multi-skill autonomy. We validate the proposed approach through
numerical simulations with the designed user graphical interface and two
real-world robotic experiments, which demonstrate that the proposed method is
effective, generalizes across tasks, and significantly reduces the
demonstration burden. Project page is available at:
https://prompt2auto.github.io

</details>


### [188] [Language Conditioning Improves Accuracy of Aircraft Goal Prediction in Untowered Airspace](https://arxiv.org/abs/2509.14063)
*Sundhar Vinodh Sangeetha,Chih-Yuan Chiu,Sarah H. Q. Li,Shreyas Kousik*

Main category: cs.RO

TL;DR: 论文提出了一种多模态框架，结合自然语言理解和空间推理，用于预测飞机在无塔台空域的目标位置，显著提高了预测准确性。


<details>
  <summary>Details</summary>
Motivation: 在无塔台空域，飞机需通过语音通信协调，预测其他飞机的意图和目标位置对安全至关重要。

Method: 结合自动语音识别和大语言模型解析飞行员无线电通话，提取意图标签，并与轨迹数据融合，通过时间卷积网络和高斯混合模型进行概率目标预测。

Result: 相比仅依赖运动历史的基线方法，该方法显著降低了目标预测误差。

Conclusion: 语言条件预测提高了预测准确性，为社交感知的机器人运动规划提供了潜力。

Abstract: Autonomous aircraft must safely operate in untowered airspace, where
coordination relies on voice-based communication among human pilots. Safe
operation requires an aircraft to predict the intent, and corresponding goal
location, of other aircraft. This paper introduces a multimodal framework for
aircraft goal prediction that integrates natural language understanding with
spatial reasoning to improve autonomous decision-making in such environments.
We leverage automatic speech recognition and large language models to
transcribe and interpret pilot radio calls, identify aircraft, and extract
discrete intent labels. These intent labels are fused with observed
trajectories to condition a temporal convolutional network and Gaussian mixture
model for probabilistic goal prediction. Our method significantly reduces goal
prediction error compared to baselines that rely solely on motion history,
demonstrating that language-conditioned prediction increases prediction
accuracy. Experiments on a real-world dataset from an untowered airport
validate the approach and highlight its potential to enable socially aware,
language-conditioned robotic motion planning.

</details>


### [189] [Constraint-Consistent Control of Task-Based and Kinematic RCM Constraints for Surgical Robots](https://arxiv.org/abs/2509.14075)
*Yu Li,Hamid Sadeghian,Zewen Yang,Valentin Le Mesle,Sami Haddadin*

Main category: cs.RO

TL;DR: 提出了一种基于投影逆动力学的约束一致扭矩控制器，用于机器人辅助微创手术中的远程运动中心约束，提高了安全性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在动态和交互条件下难以保证远程运动中心（RCM）约束的鲁棒性和一致性，影响手术安全性。

Method: 将RCM视为流形约束，嵌入投影逆动力学框架，统一任务级和运动学公式，实现精确工具尖端跟踪和扭矩平滑。

Result: 在仿真和实验平台上验证，显示RCM约束满足度提高、所需扭矩减少，且在临床相关场景下表现鲁棒。

Conclusion: 约束一致扭矩控制可提升手术机器人的安全性和可靠性，具有临床应用潜力。

Abstract: Robotic-assisted minimally invasive surgery (RAMIS) requires precise
enforcement of the remote center of motion (RCM) constraint to ensure safe tool
manipulation through a trocar. Achieving this constraint under dynamic and
interactive conditions remains challenging, as existing control methods either
lack robustness at the torque level or do not guarantee consistent RCM
constraint satisfaction. This paper proposes a constraint-consistent torque
controller that treats the RCM as a rheonomic holonomic constraint and embeds
it into a projection-based inverse-dynamics framework. The method unifies
task-level and kinematic formulations, enabling accurate tool-tip tracking
while maintaining smooth and efficient torque behavior. The controller is
validated both in simulation and on a RAMIS training platform, and is
benchmarked against state-of-the-art approaches. Results show improved RCM
constraint satisfaction, reduced required torque, and robust performance by
improving joint torque smoothness through the consistency formulation under
clinically relevant scenarios, including spiral trajectories, variable
insertion depths, moving trocars, and human interaction. These findings
demonstrate the potential of constraint-consistent torque control to enhance
safety and reliability in surgical robotics. The project page is available at:
https://rcmpc-cube.github.io

</details>


### [190] [FlightDiffusion: Revolutionising Autonomous Drone Training with Diffusion Models Generating FPV Video](https://arxiv.org/abs/2509.14082)
*Valerii Serpiva,Artem Lykov,Faryal Batool,Vladislav Kozlovskiy,Miguel Altamirano Cabrera,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: FlightDiffusion是一个基于扩散模型的框架，用于从第一人称视角（FPV）视频训练自主无人机。它生成逼真的视频序列和动作空间，支持动态环境中的推理导航，同时通过合成数据降低真实数据收集成本。


<details>
  <summary>Details</summary>
Motivation: 解决自主无人机训练中真实数据收集成本高的问题，同时提升导航策略的学习效果和数据集的可扩展性。

Method: 利用扩散模型生成FPV视频序列和对应的动作空间，合成多样化的轨迹和状态-动作对，用于大规模训练数据集。

Result: 生成的轨迹物理上可行，位置误差0.25米，方向误差0.19弧度。模拟与真实环境性能无显著差异（p=0.541），成功率为0.628（模拟）和0.617（真实）。

Conclusion: FlightDiffusion展示了扩散模型在无人机导航、动作生成和数据合成中的潜力，为未来研究提供了宝贵资源。

Abstract: We present FlightDiffusion, a diffusion-model-based framework for training
autonomous drones from first-person view (FPV) video. Our model generates
realistic video sequences from a single frame, enriched with corresponding
action spaces to enable reasoning-driven navigation in dynamic environments.
Beyond direct policy learning, FlightDiffusion leverages its generative
capabilities to synthesize diverse FPV trajectories and state-action pairs,
facilitating the creation of large-scale training datasets without the high
cost of real-world data collection. Our evaluation demonstrates that the
generated trajectories are physically plausible and executable, with a mean
position error of 0.25 m (RMSE 0.28 m) and a mean orientation error of 0.19 rad
(RMSE 0.24 rad). This approach enables improved policy learning and dataset
scalability, leading to superior performance in downstream navigation tasks.
Results in simulated environments highlight enhanced robustness, smoother
trajectory planning, and adaptability to unseen conditions. An ANOVA revealed
no statistically significant difference between performance in simulation and
reality (F(1, 16) = 0.394, p = 0.541), with success rates of M = 0.628 (SD =
0.162) and M = 0.617 (SD = 0.177), respectively, indicating strong sim-to-real
transfer. The generated datasets provide a valuable resource for future UAV
research. This work introduces diffusion-based reasoning as a promising
paradigm for unifying navigation, action generation, and data synthesis in
aerial robotics.

</details>


### [191] [GeoAware-VLA: Implicit Geometry Aware Vision-Language-Action Model](https://arxiv.org/abs/2509.14117)
*Ali Abouzeid,Malak Mansour,Zezhou Sun,Dezhen Song*

Main category: cs.RO

TL;DR: GeoAware-VLA通过引入几何先验增强视觉-语言-动作模型在未知视角下的泛化能力，显著提升零样本性能。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型因难以从2D图像推断3D几何而泛化能力不足，尤其在未知视角下表现不佳。

Method: 利用预训练的几何视觉模型提取特征，通过可训练投影层适配策略解码器，避免从头学习3D一致性。

Result: 在LIBERO基准测试中零样本性能提升2倍以上，真实机器人实验中也显著优于基线。

Conclusion: 几何先验是提升机器人代理泛化能力的关键因素，适用于连续和离散动作空间。

Abstract: Vision-Language-Action (VLA) models often fail to generalize to novel camera
viewpoints, a limitation stemming from their difficulty in inferring robust 3D
geometry from 2D images. We introduce GeoAware-VLA, a simple yet effective
approach that enhances viewpoint invariance by integrating strong geometric
priors into the vision backbone. Instead of training a visual encoder or
relying on explicit 3D data, we leverage a frozen, pretrained geometric vision
model as a feature extractor. A trainable projection layer then adapts these
geometrically-rich features for the policy decoder, relieving it of the burden
of learning 3D consistency from scratch. Through extensive evaluations on
LIBERO benchmark subsets, we show GeoAware-VLA achieves substantial
improvements in zero-shot generalization to novel camera poses, boosting
success rates by over 2x in simulation. Crucially, these benefits translate to
the physical world; our model shows a significant performance gain on a real
robot, especially when evaluated from unseen camera angles. Our approach proves
effective across both continuous and discrete action spaces, highlighting that
robust geometric grounding is a key component for creating more generalizable
robotic agents.

</details>


### [192] [CrazyMARL: Decentralized Direct Motor Control Policies for Cooperative Aerial Transport of Cable-Suspended Payloads](https://arxiv.org/abs/2509.14126)
*Viktor Lorentz,Khaled Wahba,Sayantan Auddy,Marc Toussaint,Wolfgang Hönig*

Main category: cs.RO

TL;DR: CrazyMARL是一个去中心化的强化学习框架，用于多无人机协同运输电缆悬挂的负载，解决了非线性负载动力学和电缆松弛-紧绷模式转换的挑战。


<details>
  <summary>Details</summary>
Motivation: 多无人机协同运输负载在灾害救援和精准物流中有广泛应用潜力，但现有方法未能解决电缆模式转换问题。

Method: 提出CrazyMARL框架，利用去中心化强化学习训练策略，处理非线性负载动力学和电缆模式转换。

Result: 仿真结果显示，该方法在抗干扰和跟踪精度上优于传统控制器，恢复率从44%提升至80%，并成功实现零样本仿真到现实的迁移。

Conclusion: CrazyMARL为无人机团队在非结构化环境中执行复杂负载任务提供了自主性和鲁棒性。

Abstract: Collaborative transportation of cable-suspended payloads by teams of Unmanned
Aerial Vehicles (UAVs) has the potential to enhance payload capacity, adapt to
different payload shapes, and provide built-in compliance, making it attractive
for applications ranging from disaster relief to precision logistics. However,
multi-UAV coordination under disturbances, nonlinear payload dynamics, and
slack--taut cable modes remains a challenging control problem. To our
knowledge, no prior work has addressed these cable mode transitions in the
multi-UAV context, instead relying on simplifying rigid-link assumptions. We
propose CrazyMARL, a decentralized Reinforcement Learning (RL) framework for
multi-UAV cable-suspended payload transport. Simulation results demonstrate
that the learned policies can outperform classical decentralized controllers in
terms of disturbance rejection and tracking precision, achieving an 80%
recovery rate from harsh conditions compared to 44% for the baseline method. We
also achieve successful zero-shot sim-to-real transfer and demonstrate that our
policies are highly robust under harsh conditions, including wind, random
external disturbances, and transitions between slack and taut cable dynamics.
This work paves the way for autonomous, resilient UAV teams capable of
executing complex payload missions in unstructured environments.

</details>


### [193] [Energy Efficient Multi Robot Package Delivery under Capacity-Constraints via Voronoi-Constrained Networks](https://arxiv.org/abs/2509.14127)
*Alkesh K. Srivastava,Jared Michael Levin,Philip Dames*

Main category: cs.RO

TL;DR: VCST-RCP框架通过Steiner树优化和稀疏中继主干构建，显著提升多机器人配送效率。


<details>
  <summary>Details</summary>
Motivation: 解决有限承载能力的同构机器人车队从单一取货点到多个目标位置的配送问题。

Method: 提出VCST-RCP框架，利用Voronoi约束的Steiner树优化构建中继主干，并合成机器人级的取货、中继和配送计划。

Result: 实验显示，相比传统方法，效率提升高达34%，能源效率显著提高。

Conclusion: 中继协调是提升多机器人配送效率的关键，VCST-RCP为实际物流提供了可扩展的解决方案。

Abstract: We consider the problem of delivering multiple packages from a single pickup
depot to distinct goal locations using a homogeneous fleet of robots with
limited carrying capacity. We propose VCST-RCP, a Voronoi-Constrained Steiner
Tree Relay Coordination Planning framework that constructs sparse relay trunks
using Steiner tree optimization and then synthesizes robot-level pickup, relay,
and delivery schedules. This framework reframes relays from incidental
byproducts into central elements of coordination, offering a contrast with
traditional delivery methods that rely on direct source-to-destination
transport. Extensive experiments show consistent improvements of up to 34%
compared to conventional baselines, underscoring the benefits of incorporating
relays into the delivery process. These improvements translate directly to
enhanced energy efficiency in multi-robot delivery under capacity constraints,
providing a scalable framework for real-world logistics.

</details>


### [194] [SeqVLA: Sequential Task Execution for Long-Horizon Manipulation with Completion-Aware Vision-Language-Action Model](https://arxiv.org/abs/2509.14138)
*Ran Yang,Zijian An,Lifeng ZHou,Yiming Feng*

Main category: cs.RO

TL;DR: SeqVLA通过增加轻量级检测头来感知子任务完成情况，显著提升了长序列机器人操作任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型缺乏子任务完成检测信号，导致在序列任务中表现脆弱。

Method: SeqVLA在π0基础上增加检测头，支持子任务自动切换，研究了四种微调策略。

Result: SeqVLA在沙拉和糖果包装任务中显著优于基线，联合微调效果最佳。

Conclusion: 结合动作生成和子任务感知检测对可扩展的序列操作至关重要。

Abstract: Long-horizon robotic manipulation tasks require executing multiple
interdependent subtasks in strict sequence, where errors in detecting subtask
completion can cascade into downstream failures. Existing
Vision-Language-Action (VLA) models such as $\pi_0$ excel at continuous
low-level control but lack an internal signal for identifying when a subtask
has finished, making them brittle in sequential settings. We propose SeqVLA, a
completion-aware extension of $\pi_0$ that augments the base architecture with
a lightweight detection head perceiving whether the current subtask is
complete. This dual-head design enables SeqVLA not only to generate
manipulation actions but also to autonomously trigger transitions between
subtasks. We investigate four finetuning strategies that vary in how the action
and detection heads are optimized (joint vs. sequential finetuning) and how
pretrained knowledge is preserved (full finetuning vs. frozen backbone).
Experiments are performed on two multi-stage tasks: salad packing with seven
distinct subtasks and candy packing with four distinct subtasks. Results show
that SeqVLA significantly outperforms the baseline $\pi_0$ and other strong
baselines in overall success rate. In particular, joint finetuning with an
unfrozen backbone yields the most decisive and statistically reliable
completion predictions, eliminating sequence-related failures and enabling
robust long-horizon execution. Our results highlight the importance of coupling
action generation with subtask-aware detection for scalable sequential
manipulation.

</details>


### [195] [CLAW: A Vision-Language-Action Framework for Weight-Aware Robotic Grasping](https://arxiv.org/abs/2509.14143)
*Zijian An,Ran Yang,Yiming Feng,Lifeng Zhou*

Main category: cs.RO

TL;DR: CLAW框架通过解耦条件评估与动作生成，结合符号化重量推理与高频视觉运动控制，提升了机器人执行精确任务的能力。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言-动作（VLA）模型在满足精确任务约束（如基于数值阈值的停止）方面表现不佳，缺乏显式的条件监测机制。

Method: CLAW利用微调的CLIP模型作为轻量级提示生成器，监测数字读数并生成离散指令，再由VLA策略整合多视角摄像头观测生成连续动作。

Result: CLAW在单物体抓取和双臂操作任务中表现优于原始和微调的VLA模型，可靠执行重量感知行为。

Conclusion: CLAW通过显式条件监测与动作生成的分离，有效提升了机器人执行精确任务的能力。

Abstract: Vision-language-action (VLA) models have recently emerged as a promising
paradigm for robotic control, enabling end-to-end policies that ground natural
language instructions into visuomotor actions. However, current VLAs often
struggle to satisfy precise task constraints, such as stopping based on numeric
thresholds, since their observation-to-action mappings are implicitly shaped by
training data and lack explicit mechanisms for condition monitoring. In this
work, we propose CLAW (CLIP-Language-Action for Weight), a framework that
decouples condition evaluation from action generation. CLAW leverages a
fine-tuned CLIP model as a lightweight prompt generator, which continuously
monitors the digital readout of a scale and produces discrete directives based
on task-specific weight thresholds. These prompts are then consumed by $\pi_0$,
a flow-based VLA policy, which integrates the prompts with multi-view camera
observations to produce continuous robot actions. This design enables CLAW to
combine symbolic weight reasoning with high-frequency visuomotor control. We
validate CLAW on three experimental setups: single-object grasping and
mixed-object tasks requiring dual-arm manipulation. Across all conditions, CLAW
reliably executes weight-aware behaviors and outperforms both raw-$\pi_0$ and
fine-tuned $\pi_0$ models. We have uploaded the videos as supplementary
materials.

</details>


### [196] [StableTracker: Learning to Stably Track Target via Differentiable Simulation](https://arxiv.org/abs/2509.14147)
*Fanxing Li,Shengyang Wang,Fangyu Sun,Shuyu Wu,Dexin Zuo,Wenxian Yu,Danping Zou*

Main category: cs.RO

TL;DR: StableTracker是一种基于学习的控制策略，用于解决FPV目标跟踪中的硬件过载和累积误差问题，通过可微分模拟训练，实现稳定跟踪。


<details>
  <summary>Details</summary>
Motivation: 传统FPV目标跟踪方法依赖手工模块设计，导致硬件过载和累积误差，影响跟踪性能，尤其是对快速加速或减速的目标。

Method: 使用基于时间的反向传播通过可微分模拟训练控制策略，使无人机能够从任意视角稳定跟踪目标。

Result: 仿真和真实实验表明，StableTracker在准确性、稳定性和泛化能力上优于传统算法和学习基线。

Conclusion: StableTracker是一种高效且实用的自主空中相机解决方案。

Abstract: FPV object tracking methods heavily rely on handcraft modular designs,
resulting in hardware overload and cumulative error, which seriously degrades
the tracking performance, especially for rapidly accelerating or decelerating
targets. To address these challenges, we present \textbf{StableTracker}, a
learning-based control policy that enables quadrotors to robustly follow the
moving target from arbitrary perspectives. The policy is trained using
backpropagation-through-time via differentiable simulation, allowing the
quadrotor to maintain the target at the center of the visual field in both
horizontal and vertical directions, while keeping a fixed relative distance,
thereby functioning as an autonomous aerial camera. We compare StableTracker
against both state-of-the-art traditional algorithms and learning baselines.
Simulation experiments demonstrate that our policy achieves superior accuracy,
stability and generalization across varying safe distances, trajectories, and
target velocities. Furthermore, a real-world experiment on a quadrotor with an
onboard computer validated practicality of the proposed approach.

</details>


### [197] [MIMIC-D: Multi-modal Imitation for MultI-agent Coordination with Decentralized Diffusion Policies](https://arxiv.org/abs/2509.14159)
*Dayi Dong,Maulik Bhatt,Seoyeon Choi,Negar Mehr*

Main category: cs.RO

TL;DR: 论文提出MIMIC-D方法，通过扩散策略实现多模态多智能体模仿学习，解决了专家演示多模态时标准模仿学习方法的不足。


<details>
  <summary>Details</summary>
Motivation: 机器人需要与人类和其他机器人协调完成多模态任务，但标准模仿学习方法难以捕捉多模态策略，影响协调效果。

Method: 采用集中训练分散执行（CTDE）范式，利用扩散策略训练智能体，使其仅依赖局部信息实现隐式协调。

Result: 在仿真和硬件实验中，MIMIC-D成功恢复了智能体间的多模态协调行为，并优于现有基线方法。

Conclusion: MIMIC-D方法在多任务和环境中有效实现了多智能体的隐式协调，提升了多模态模仿学习的性能。

Abstract: As robots become more integrated in society, their ability to coordinate with
other robots and humans on multi-modal tasks (those with multiple valid
solutions) is crucial. We propose to learn such behaviors from expert
demonstrations via imitation learning (IL). However, when expert demonstrations
are multi-modal, standard IL approaches can struggle to capture the diverse
strategies, hindering effective coordination. Diffusion models are known to be
effective at handling complex multi-modal trajectory distributions in
single-agent systems. Diffusion models have also excelled in multi-agent
scenarios where multi-modality is more common and crucial to learning
coordinated behaviors. Typically, diffusion-based approaches require a
centralized planner or explicit communication among agents, but this assumption
can fail in real-world scenarios where robots must operate independently or
with agents like humans that they cannot directly communicate with. Therefore,
we propose MIMIC-D, a Centralized Training, Decentralized Execution (CTDE)
paradigm for multi-modal multi-agent imitation learning using diffusion
policies. Agents are trained jointly with full information, but execute
policies using only local information to achieve implicit coordination. We
demonstrate in both simulation and hardware experiments that our method
recovers multi-modal coordination behavior among agents in a variety of tasks
and environments, while improving upon state-of-the-art baselines.

</details>


### [198] [\textsc{Gen2Real}: Towards Demo-Free Dexterous Manipulation by Harnessing Generated Video](https://arxiv.org/abs/2509.14178)
*Kai Ye,Yuhang Wu,Shuyuan Hu,Junliang Li,Meng Liu,Yongquan Chen,Rui Huang*

Main category: cs.RO

TL;DR: Gen2Real利用生成视频替代人类演示，通过轨迹优化和学习策略实现机器人抓取任务的高成功率。


<details>
  <summary>Details</summary>
Motivation: 解决机器人灵巧操作中人类演示数据收集困难的问题。

Method: 结合视频生成、轨迹优化（PIOM）和基于锚点的PPO策略学习。

Result: 在模拟中达到77.3%的成功率，并在真实机器人上展示连贯执行。

Conclusion: Gen2Real展示了从生成视频到真实执行的灵活性和鲁棒性。

Abstract: Dexterous manipulation remains a challenging robotics problem, largely due to
the difficulty of collecting extensive human demonstrations for learning. In
this paper, we introduce \textsc{Gen2Real}, which replaces costly human demos
with one generated video and drives robot skill from it: it combines
demonstration generation that leverages video generation with pose and depth
estimation to yield hand-object trajectories, trajectory optimization that uses
Physics-aware Interaction Optimization Model (PIOM) to impose physics
consistency, and demonstration learning that retargets human motions to a robot
hand and stabilizes control with an anchor-based residual Proximal Policy
Optimization (PPO) policy. Using only generated videos, the learned policy
achieves a 77.3\% success rate on grasping tasks in simulation and demonstrates
coherent executions on a real robot. We also conduct ablation studies to
validate the contribution of each component and demonstrate the ability to
directly specify tasks using natural language, highlighting the flexibility and
robustness of \textsc{Gen2Real} in generalizing grasping skills from imagined
videos to real-world execution.

</details>


### [199] [MCGS-SLAM: A Multi-Camera SLAM Framework Using Gaussian Splatting for High-Fidelity Mapping](https://arxiv.org/abs/2509.14191)
*Zhihao Cao,Hanyu Wu,Li Wa Tang,Zizhou Luo,Zihan Zhu,Wei Zhang,Marc Pollefeys,Martin R. Oswald*

Main category: cs.RO

TL;DR: MCGS-SLAM是一种基于多摄像头和3D高斯泼溅的RGB SLAM系统，通过多视角融合和尺度一致性模块实现高精度轨迹和逼真重建。


<details>
  <summary>Details</summary>
Motivation: 现有密集SLAM方法多针对单目设置，牺牲了鲁棒性和几何覆盖。MCGS-SLAM旨在通过多摄像头输入提升重建质量和覆盖范围。

Method: 系统利用多摄像头束调整（MCBA）联合优化位姿和深度，并通过尺度一致性模块实现多视角度量对齐。

Result: 实验表明，MCGS-SLAM在合成和真实数据集上表现优于单目基线，能够重建单目系统遗漏的侧视区域。

Conclusion: 多摄像头高斯泼溅SLAM在机器人和自动驾驶领域具有高保真映射的潜力。

Abstract: Recent progress in dense SLAM has primarily targeted monocular setups, often
at the expense of robustness and geometric coverage. We present MCGS-SLAM, the
first purely RGB-based multi-camera SLAM system built on 3D Gaussian Splatting
(3DGS). Unlike prior methods relying on sparse maps or inertial data, MCGS-SLAM
fuses dense RGB inputs from multiple viewpoints into a unified, continuously
optimized Gaussian map. A multi-camera bundle adjustment (MCBA) jointly refines
poses and depths via dense photometric and geometric residuals, while a scale
consistency module enforces metric alignment across views using low-rank
priors. The system supports RGB input and maintains real-time performance at
large scale. Experiments on synthetic and real-world datasets show that
MCGS-SLAM consistently yields accurate trajectories and photorealistic
reconstructions, usually outperforming monocular baselines. Notably, the wide
field of view from multi-camera input enables reconstruction of side-view
regions that monocular setups miss, critical for safe autonomous operation.
These results highlight the promise of multi-camera Gaussian Splatting SLAM for
high-fidelity mapping in robotics and autonomous driving.

</details>


### [200] [GLIDE: A Coordinated Aerial-Ground Framework for Search and Rescue in Unknown Environments](https://arxiv.org/abs/2509.14210)
*Seth Farrell,Chenghao Li,Hongzhan Yu,Hesam Mojtahedi,Sicun Gao,Henrik I. Christensen*

Main category: cs.RO

TL;DR: GLIDE框架通过无人机与地面车辆协作，实现快速受害者定位和障碍感知导航。


<details>
  <summary>Details</summary>
Motivation: 在未知环境中，快速定位受害者并安全导航是搜救任务的关键挑战。

Method: 使用两架无人机（一架搜索目标，一架侦察地形）与地面车辆协作，结合实时规划和传感器融合。

Result: 实验证明，明确角色分工和地形侦察能显著提高搜救任务的效率和安全性。

Conclusion: GLIDE框架在时间紧迫的搜救任务中表现出色，提升了到达时间和导航安全性。

Abstract: We present a cooperative aerial-ground search-and-rescue (SAR) framework that
pairs two unmanned aerial vehicles (UAVs) with an unmanned ground vehicle (UGV)
to achieve rapid victim localization and obstacle-aware navigation in unknown
environments. We dub this framework Guided Long-horizon Integrated Drone Escort
(GLIDE), highlighting the UGV's reliance on UAV guidance for long-horizon
planning. In our framework, a goal-searching UAV executes real-time onboard
victim detection and georeferencing to nominate goals for the ground platform,
while a terrain-scouting UAV flies ahead of the UGV's planned route to provide
mid-level traversability updates. The UGV fuses aerial cues with local sensing
to perform time-efficient A* planning and continuous replanning as information
arrives. Additionally, we present a hardware demonstration (using a GEM e6 golf
cart as the UGV and two X500 UAVs) to evaluate end-to-end SAR mission
performance and include simulation ablations to assess the planning stack in
isolation from detection. Empirical results demonstrate that explicit role
separation across UAVs, coupled with terrain scouting and guided planning,
improves reach time and navigation safety in time-critical SAR missions.

</details>


### [201] [Multi-robot Multi-source Localization in Complex Flows with Physics-Preserving Environment Models](https://arxiv.org/abs/2509.14228)
*Benjamin Shaffer,Victoria Edwards,Brooks Kinch,Nathaniel Trask,M. Ani Hsieh*

Main category: cs.RO

TL;DR: 提出了一种分布式移动传感框架，用于复杂流场中的源定位，通过机器学习模型和信息驱动策略提高定位速度和准确性。


<details>
  <summary>Details</summary>
Motivation: 复杂流场中的源定位（如化学泄漏或油污扩散）因流动力学和环境几何复杂性而极具挑战性，需要高效且计算轻量的方法。

Method: 每个机器人携带机器学习的环境有限元模型，基于近似互信息准则驱动信息控制策略，选择信息量最大的采样区域。

Result: 相比基线方法，该方法能更快减少误差并提高源定位准确性。

Conclusion: 分布式机器学习模型结合信息驱动策略在复杂流场源定位中表现优越。

Abstract: Source localization in a complex flow poses a significant challenge for
multi-robot teams tasked with localizing the source of chemical leaks or
tracking the dispersion of an oil spill. The flow dynamics can be time-varying
and chaotic, resulting in sporadic and intermittent sensor readings, and
complex environmental geometries further complicate a team's ability to model
and predict the dispersion. To accurately account for the physical processes
that drive the dispersion dynamics, robots must have access to computationally
intensive numerical models, which can be difficult when onboard computation is
limited. We present a distributed mobile sensing framework for source
localization in which each robot carries a machine-learned, finite element
model of its environment to guide information-based sampling. The models are
used to evaluate an approximate mutual information criterion to drive an
infotaxis control strategy, which selects sensing regions that are expected to
maximize informativeness for the source localization objective. Our approach
achieves faster error reduction compared to baseline sensing strategies and
results in more accurate source localization compared to baseline machine
learning approaches.

</details>
