<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 183]
- [cs.LG](#cs.LG) [Total: 184]
- [cs.RO](#cs.RO) [Total: 62]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Generative human motion mimicking through feature extraction in denoising diffusion settings](https://arxiv.org/abs/2511.00011)
*Alexander Okupnik,Johannes Schneider,Kyriakos Flouris*

Main category: cs.CV

TL;DR: 论文提出了一种基于运动捕捉数据的交互模型，用于探索人类与AI在舞蹈中的创造性互动。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在人类-AI交互中取得了成功，但缺乏具身互动体验。舞蹈作为人类表达形式，可以补充这一体验。

Method: 模型结合了两种扩散模型、运动修复和运动风格迁移，利用单人运动数据生成具有时间一致性和响应性的运动表示。

Result: 模型通过定量评估生成样本与测试集的特征分布收敛性，展示了其成功性。生成的舞蹈动作既多样又真实。

Conclusion: 该模型是迈向与AI创造性舞蹈的第一步，展示了多样性与真实性的结合。

Abstract: Recent success with large language models has sparked a new wave of verbal
human-AI interaction. While such models support users in a variety of creative
tasks, they lack the embodied nature of human interaction. Dance, as a primal
form of human expression, is predestined to complement this experience. To
explore creative human-AI interaction exemplified by dance, we build an
interactive model based on motion capture (MoCap) data. It generates an
artificial other by partially mimicking and also "creatively" enhancing an
incoming sequence of movement data. It is the first model, which leverages
single-person motion data and high level features in order to do so and, thus,
it does not rely on low level human-human interaction data. It combines ideas
of two diffusion models, motion inpainting, and motion style transfer to
generate movement representations that are both temporally coherent and
responsive to a chosen movement reference. The success of the model is
demonstrated by quantitatively assessing the convergence of the feature
distribution of the generated samples and the test set which serves as
simulating the human performer. We show that our generations are first steps to
creative dancing with AI as they are both diverse showing various deviations
from the human partner while appearing realistic.

</details>


### [2] [Deep Learning Models for Coral Bleaching Classification in Multi-Condition Underwater Image Datasets](https://arxiv.org/abs/2511.00021)
*Julio Jerison E. Macrohon,Gordon Hung*

Main category: cs.CV

TL;DR: 提出了一种基于机器学习的珊瑚白化分类系统，使用全球多样化数据集，CNN模型以88%的准确率表现最佳。


<details>
  <summary>Details</summary>
Motivation: 珊瑚礁面临污染、海洋酸化和海水温度异常的威胁，亟需高效的保护和监测方法。

Method: 基于ResNet、ViT和CNN三种模型进行对比实验，并通过超参数调优。

Result: CNN模型在珊瑚白化分类任务中达到88%的准确率，优于其他模型。

Conclusion: 研究为珊瑚礁的自主监测提供了重要工具，并分析了常用计算机视觉模型的性能。

Abstract: Coral reefs support numerous marine organisms and are an important source of
coastal protection from storms and floods, representing a major part of marine
ecosystems. However coral reefs face increasing threats from pollution, ocean
acidification, and sea temperature anomalies, making efficient protection and
monitoring heavily urgent. Therefore, this study presents a novel
machine-learning-based coral bleaching classification system based on a diverse
global dataset with samples of healthy and bleached corals under varying
environmental conditions, including deep seas, marshes, and coastal zones. We
benchmarked and compared three state-of-the-art models: Residual Neural Network
(ResNet), Vision Transformer (ViT), and Convolutional Neural Network (CNN).
After comprehensive hyperparameter tuning, the CNN model achieved the highest
accuracy of 88%, outperforming existing benchmarks. Our findings offer
important insights into autonomous coral monitoring and present a comprehensive
analysis of the most widely used computer vision models.

</details>


### [3] [Automating Coral Reef Fish Family Identification on Video Transects Using a YOLOv8-Based Deep Learning Pipeline](https://arxiv.org/abs/2511.00022)
*Jules Gerard,Leandro Di Bella,Filip Huyghe,Marc Kochzius*

Main category: cs.CV

TL;DR: 使用YOLOv8深度学习模型自动化识别西印度洋珊瑚礁鱼类，为区域监测提供新方法。


<details>
  <summary>Details</summary>
Motivation: 传统水下视觉普查方法劳动密集，限制了西印度洋珊瑚礁监测的效率。

Method: 采用YOLOv8深度学习管道，对肯尼亚和坦桑尼亚的视频样带进行鱼类科级识别。

Result: 最佳模型mAP@0.5为0.52，对常见鱼类识别准确率高，但对稀有或复杂类群识别较弱。

Conclusion: 深度学习可作为传统监测方法的可扩展补充，提升珊瑚礁监测效率。

Abstract: Coral reef monitoring in the Western Indian Ocean is limited by the labor
demands of underwater visual censuses. This work evaluates a YOLOv8-based deep
learning pipeline for automating family-level fish identification from video
transects collected in Kenya and Tanzania. A curated dataset of 24 families was
tested under different configurations, providing the first region-specific
benchmark for automated reef fish monitoring in the Western Indian Ocean. The
best model achieved mAP@0.5 of 0.52, with high accuracy for abundant families
but weaker detection of rare or complex taxa. Results demonstrate the potential
of deep learning as a scalable complement to traditional monitoring methods.

</details>


### [4] [Mutual Information guided Visual Contrastive Learning](https://arxiv.org/abs/2511.00028)
*Hanyang Chen,Yanchao Yang*

Main category: cs.CV

TL;DR: 论文提出了一种基于互信息的数据增强方法，用于改进对比学习中的特征提取效果。


<details>
  <summary>Details</summary>
Motivation: 现有对比学习方法的数据选择和增强依赖人工假设或工程，可能不够优化。

Method: 通过计算真实世界分布中的互信息来选择训练数据，并利用高互信息的场景补丁作为正样本进行对比学习。

Result: 在多个基准测试和先进框架中验证了方法的有效性。

Conclusion: 该方法为未来研究提供了有前景的方向。

Abstract: Representation learning methods utilizing the InfoNCE loss have demonstrated
considerable capacity in reducing human annotation effort by training invariant
neural feature extractors. Although different variants of the training
objective adhere to the information maximization principle between the data and
learned features, data selection and augmentation still rely on human
hypotheses or engineering, which may be suboptimal. For instance, data
augmentation in contrastive learning primarily focuses on color jittering,
aiming to emulate real-world illumination changes. In this work, we investigate
the potential of selecting training data based on their mutual information
computed from real-world distributions, which, in principle, should endow the
learned features with better generalization when applied in open environments.
Specifically, we consider patches attached to scenes that exhibit high mutual
information under natural perturbations, such as color changes and motion, as
positive samples for learning with contrastive loss. We evaluate the proposed
mutual-information-informed data augmentation method on several benchmarks
across multiple state-of-the-art representation learning frameworks,
demonstrating its effectiveness and establishing it as a promising direction
for future research.

</details>


### [5] [Benchmarking Federated Learning Frameworks for Medical Imaging Deployment: A Comparative Study of NVIDIA FLARE, Flower, and Owkin Substra](https://arxiv.org/abs/2511.00037)
*Riya Gupta,Alexander Chowdhury,Sahil Nalawade*

Main category: cs.CV

TL;DR: 论文比较了三种联邦学习框架（NVIDIA FLARE、Flower和Owkin Substra）在医学影像应用中的表现，总结了各自的优势。


<details>
  <summary>Details</summary>
Motivation: 评估联邦学习框架在医学AI中的实际应用潜力，解决数据隐私和协作训练的需求。

Method: 使用PathMNIST数据集，测试模型性能、收敛效率、通信开销、可扩展性和开发者体验。

Result: NVIDIA FLARE适合生产环境，Flower适合原型设计，Owkin Substra隐私保护突出。

Conclusion: 不同框架各有优势，适用于医疗环境中的不同场景。

Abstract: Federated Learning (FL) has emerged as a transformative paradigm in medical
AI, enabling collaborative model training across institutions without direct
data sharing. This study benchmarks three prominent FL frameworks NVIDIA FLARE,
Flower, and Owkin Substra to evaluate their suitability for medical imaging
applications in real-world settings. Using the PathMNIST dataset, we assess
model performance, convergence efficiency, communication overhead, scalability,
and developer experience. Results indicate that NVIDIA FLARE offers superior
production scalability, Flower provides flexibility for prototyping and
academic research, and Owkin Substra demonstrates exceptional privacy and
compliance features. Each framework exhibits strengths optimized for distinct
use cases, emphasizing their relevance to practical deployment in healthcare
environments.

</details>


### [6] [Enhancing rice leaf images: An overview of image denoising techniques](https://arxiv.org/abs/2511.00046)
*Rupjyoti Chutia,Dibya Jyoti Bora*

Main category: cs.CV

TL;DR: 该论文比较了多种图像去噪方法结合CLAHE在稻叶图像处理中的效果，为农业研究提供了实用参考。


<details>
  <summary>Details</summary>
Motivation: 稻叶图像处理在疾病检测和生长分析中至关重要，但现有方法需要优化以提高图像质量和信息提取效率。

Method: 采用多种知名图像去噪方法结合CLAHE，对稻叶图像数据集进行实验，并使用多种指标评估效果。

Result: 实验结果表明，该方法能有效提升稻叶图像质量，为后续分析任务提供可靠基础。

Conclusion: 该研究为农业图像处理提供了有效方法，并展示了未来在其他领域应用的潜力。

Abstract: Digital image processing involves the systematic handling of images using
advanced computer algorithms, and has gained significant attention in both
academic and practical fields. Image enhancement is a crucial preprocessing
stage in the image-processing chain, improving image quality and emphasizing
features. This makes subsequent tasks (segmentation, feature extraction,
classification) more reliable. Image enhancement is essential for rice leaf
analysis, aiding in disease detection, nutrient deficiency evaluation, and
growth analysis. Denoising followed by contrast enhancement are the primary
steps. Image filters, generally employed for denoising, transform or enhance
visual characteristics like brightness, contrast, and sharpness, playing a
crucial role in improving overall image quality and enabling the extraction of
useful information. This work provides an extensive comparative study of
well-known image-denoising methods combined with CLAHE (Contrast Limited
Adaptive Histogram Equalization) for efficient denoising of rice leaf images.
The experiments were performed on a rice leaf image dataset to ensure the data
is relevant and representative. Results were examined using various metrics to
comprehensively test enhancement methods. This approach provides a strong basis
for assessing the effectiveness of methodologies in digital image processing
and reveals insights useful for future adaptation in agricultural research and
other domains.

</details>


### [7] [Which LiDAR scanning pattern is better for roadside perception: Repetitive or Non-repetitive?](https://arxiv.org/abs/2511.00060)
*Zhiqi Qi,Runxin Zhao,Hanyang Zhuang,Chunxiang Wang,Ming Yang*

Main category: cs.CV

TL;DR: 研究比较了不同LiDAR扫描模式对路边感知性能的影响，提出了InfraLiDARs' Benchmark数据集，并分析了非重复扫描LiDAR与传统重复扫描LiDAR的性能差异。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注LiDAR的放置优化，而不同扫描模式对感知性能的影响尚未深入探讨。

Method: 在CARLA仿真环境中收集数据，构建InfraLiDARs' Benchmark数据集，并对比分析不同扫描模式下的3D物体检测算法性能。

Result: 非重复扫描LiDAR与128线重复扫描LiDAR在多种场景下表现相当，且前者成本更低。

Conclusion: 研究为路边感知系统的LiDAR选择和算法匹配提供了参考，并公开数据集以促进进一步研究。

Abstract: LiDAR-based roadside perception is a cornerstone of advanced Intelligent
Transportation Systems (ITS). While considerable research has addressed optimal
LiDAR placement for infrastructure, the profound impact of differing LiDAR
scanning patterns on perceptual performance remains comparatively
under-investigated. The inherent nature of various scanning modes - such as
traditional repetitive (mechanical/solid-state) versus emerging non-repetitive
(e.g. prism-based) systems - leads to distinct point cloud distributions at
varying distances, critically dictating the efficacy of object detection and
overall environmental understanding. To systematically investigate these
differences in infrastructure-based contexts, we introduce the "InfraLiDARs'
Benchmark," a novel dataset meticulously collected in the CARLA simulation
environment using concurrently operating infrastructure-based LiDARs exhibiting
both scanning paradigms. Leveraging this benchmark, we conduct a comprehensive
statistical analysis of the respective LiDAR scanning abilities and evaluate
the impact of these distinct patterns on the performance of various leading 3D
object detection algorithms. Our findings reveal that non-repetitive scanning
LiDAR and the 128-line repetitive LiDAR were found to exhibit comparable
detection performance across various scenarios. Despite non-repetitive LiDAR's
limited perception range, it's a cost-effective option considering its low
price. Ultimately, this study provides insights for setting up roadside
perception system with optimal LiDAR scanning patterns and compatible
algorithms for diverse roadside applications, and publicly releases the
"InfraLiDARs' Benchmark" dataset to foster further research.

</details>


### [8] [World Simulation with Video Foundation Models for Physical AI](https://arxiv.org/abs/2511.00062)
*NVIDIA,:,Arslan Ali,Junjie Bai,Maciej Bala,Yogesh Balaji,Aaron Blakeman,Tiffany Cai,Jiaxin Cao,Tianshi Cao,Elizabeth Cha,Yu-Wei Chao,Prithvijit Chattopadhyay,Mike Chen,Yongxin Chen,Yu Chen,Shuai Cheng,Yin Cui,Jenna Diamond,Yifan Ding,Jiaojiao Fan,Linxi Fan,Liang Feng,Francesco Ferroni,Sanja Fidler,Xiao Fu,Ruiyuan Gao,Yunhao Ge,Jinwei Gu,Aryaman Gupta,Siddharth Gururani,Imad El Hanafi,Ali Hassani,Zekun Hao,Jacob Huffman,Joel Jang,Pooya Jannaty,Jan Kautz,Grace Lam,Xuan Li,Zhaoshuo Li,Maosheng Liao,Chen-Hsuan Lin,Tsung-Yi Lin,Yen-Chen Lin,Huan Ling,Ming-Yu Liu,Xian Liu,Yifan Lu,Alice Luo,Qianli Ma,Hanzi Mao,Kaichun Mo,Seungjun Nah,Yashraj Narang,Abhijeet Panaskar,Lindsey Pavao,Trung Pham,Morteza Ramezanali,Fitsum Reda,Scott Reed,Xuanchi Ren,Haonan Shao,Yue Shen,Stella Shi,Shuran Song,Bartosz Stefaniak,Shangkun Sun,Shitao Tang,Sameena Tasmeen,Lyne Tchapmi,Wei-Cheng Tseng,Jibin Varghese,Andrew Z. Wang,Hao Wang,Haoxiang Wang,Heng Wang,Ting-Chun Wang,Fangyin Wei,Jiashu Xu,Dinghao Yang,Xiaodong Yang,Haotian Ye,Seonghyeon Ye,Xiaohui Zeng,Jing Zhang,Qinsheng Zhang,Kaiwen Zheng,Andrew Zhu,Yuke Zhu*

Main category: cs.CV

TL;DR: [Cosmos-Predict2.5]和[Cosmos-Transfer2.5]是新一代物理AI模型，统一了多模态生成任务，提升了视频质量和指令对齐，并支持机器人及自主系统的仿真应用。


<details>
  <summary>Details</summary>
Motivation: 推动物理AI的发展，提供更可靠的合成数据生成和仿真工具，降低研究门槛。

Method: 基于流式架构，结合强化学习后训练，并扩展了控制网络框架。

Result: 在视频质量和指令对齐上显著提升，模型规模为2B和14B。

Conclusion: 这些模型为具身智能的规模化提供了多功能工具，并开源了代码和预训练模型以促进创新。

Abstract: We introduce [Cosmos-Predict2.5], the latest generation of the Cosmos World
Foundation Models for Physical AI. Built on a flow-based architecture,
[Cosmos-Predict2.5] unifies Text2World, Image2World, and Video2World generation
in a single model and leverages [Cosmos-Reason1], a Physical AI vision-language
model, to provide richer text grounding and finer control of world simulation.
Trained on 200M curated video clips and refined with reinforcement
learning-based post-training, [Cosmos-Predict2.5] achieves substantial
improvements over [Cosmos-Predict1] in video quality and instruction alignment,
with models released at 2B and 14B scales. These capabilities enable more
reliable synthetic data generation, policy evaluation, and closed-loop
simulation for robotics and autonomous systems. We further extend the family
with [Cosmos-Transfer2.5], a control-net style framework for Sim2Real and
Real2Real world translation. Despite being 3.5$\times$ smaller than
[Cosmos-Transfer1], it delivers higher fidelity and robust long-horizon video
generation. Together, these advances establish [Cosmos-Predict2.5] and
[Cosmos-Transfer2.5] as versatile tools for scaling embodied intelligence. To
accelerate research and deployment in Physical AI, we release source code,
pretrained checkpoints, and curated benchmarks under the NVIDIA Open Model
License at https://github.com/nvidia-cosmos/cosmos-predict2.5 and
https://github.com/nvidia-cosmos/cosmos-transfer2.5. We hope these open
resources lower the barrier to adoption and foster innovation in building the
next generation of embodied intelligence.

</details>


### [9] [Habitat and Land Cover Change Detection in Alpine Protected Areas: A Comparison of AI Architectures](https://arxiv.org/abs/2511.00073)
*Harald Kristen,Daniel Kulmer,Manuela Hirschmugl*

Main category: cs.CV

TL;DR: 论文探讨了在复杂高山生态系统中应用深度学习进行变化检测的方法，比较了后分类变化检测和直接变化检测两种范式，并评估了不同模型的性能。


<details>
  <summary>Details</summary>
Motivation: 高山生态系统因气候变化和干扰需要频繁监测，但传统方法成本高，深度学习可填补这一空白。

Method: 使用后分类变化检测（Prithvi-EO-2.0、Clay v1.0和U-Net CNN）和直接变化检测（ChangeViT和U-Net），结合多模态数据（RGB、NIR、LiDAR等）。

Result: Clay v1.0在多类变化检测中准确率51%，U-Net为41%；直接变化检测在二元检测中IoU更高（0.53 vs 0.35）。LiDAR提升语义分割准确率至50%。

Conclusion: 尽管准确率低于均质景观，但反映了复杂高山生境的真实性能。未来将结合对象后处理和物理约束提升实用性。

Abstract: Rapid climate change and other disturbances in alpine ecosystems demand
frequent habitat monitoring, yet manual mapping remains prohibitively expensive
for the required temporal resolution. We employ deep learning for change
detection using long-term alpine habitat data from Gesaeuse National Park,
Austria, addressing a major gap in applying geospatial foundation models (GFMs)
to complex natural environments with fuzzy class boundaries and highly
imbalanced classes. We compare two paradigms: post-classification change
detection (CD) versus direct CD. For post-classification CD, we evaluate GFMs
Prithvi-EO-2.0 and Clay v1.0 against U-Net CNNs; for direct CD, we test the
transformer ChangeViT against U-Net baselines. Using high-resolution multimodal
data (RGB, NIR, LiDAR, terrain attributes) covering 4,480 documented changes
over 15.3 km2, results show Clay v1.0 achieves 51% overall accuracy versus
U-Net's 41% for multi-class habitat change, while both reach 67% for binary
change detection. Direct CD yields superior IoU (0.53 vs 0.35) for binary but
only 28% accuracy for multi-class detection. Cross-temporal evaluation reveals
GFM robustness, with Clay maintaining 33% accuracy on 2020 data versus U-Net's
23%. Integrating LiDAR improves semantic segmentation from 30% to 50% accuracy.
Although overall accuracies are lower than in more homogeneous landscapes, they
reflect realistic performance for complex alpine habitats. Future work will
integrate object-based post-processing and physical constraints to enhance
applicability.

</details>


### [10] [LeMiCa: Lexicographic Minimax Path Caching for Efficient Diffusion-Based Video Generation](https://arxiv.org/abs/2511.00090)
*Huanlin Gao,Ping Chen,Fuyuan Shi,Chao Tan,Zhaoxiang Liu,Fang Zhao,Kai Wang,Shiguo Lian*

Main category: cs.CV

TL;DR: LeMiCa是一种无需训练的高效加速框架，用于基于扩散的视频生成，通过优化缓存调度显著提升生成质量和速度。


<details>
  <summary>Details</summary>
Motivation: 现有缓存策略主要减少局部启发式误差，但忽略了全局误差累积，导致加速视频与原始视频内容退化。

Method: 将缓存调度建模为带误差权重边的有向图，引入字典序最小最大路径优化策略，限制最坏路径误差。

Result: 在多个文本到视频基准测试中，LeMiCa实现2.9倍加速，LPIPS得分0.05，优于现有缓存技术。

Conclusion: LeMiCa在加速扩散视频生成的同时保持高质量，为未来高效可靠视频合成研究奠定基础。

Abstract: We present LeMiCa, a training-free and efficient acceleration framework for
diffusion-based video generation. While existing caching strategies primarily
focus on reducing local heuristic errors, they often overlook the accumulation
of global errors, leading to noticeable content degradation between accelerated
and original videos. To address this issue, we formulate cache scheduling as a
directed graph with error-weighted edges and introduce a Lexicographic Minimax
Path Optimization strategy that explicitly bounds the worst-case path error.
This approach substantially improves the consistency of global content and
style across generated frames. Extensive experiments on multiple text-to-video
benchmarks demonstrate that LeMiCa delivers dual improvements in both inference
speed and generation quality. Notably, our method achieves a 2.9x speedup on
the Latte model and reaches an LPIPS score of 0.05 on Open-Sora, outperforming
prior caching techniques. Importantly, these gains come with minimal perceptual
quality degradation, making LeMiCa a robust and generalizable paradigm for
accelerating diffusion-based video generation. We believe this approach can
serve as a strong foundation for future research on efficient and reliable
video synthesis. Our code is available at :https://github.com/UnicomAI/LeMiCa

</details>


### [11] [Self-Improving Vision-Language-Action Models with Data Generation via Residual RL](https://arxiv.org/abs/2511.00091)
*Wenli Xiao,Haotian Lin,Andy Peng,Haoru Xue,Tairan He,Yuqi Xie,Fengyuan Hu,Jimmy Wu,Zhengyi Luo,Linxi "Jim" Fan,Guanya Shi,Yuke Zhu*

Main category: cs.CV

TL;DR: PLD框架通过三阶段方法提升VLA模型性能，无需依赖昂贵的人类演示。


<details>
  <summary>Details</summary>
Motivation: 传统SFT依赖人类演示，成本高且泛化能力有限，PLD旨在解决这一问题。

Method: PLD分为三阶段：1) 训练轻量级残差actor探测VLA失败区域；2) 混合rollout方案收集数据；3) 通过SFT蒸馏回VLA模型。

Result: 在LIBERO、SimplerEnv和真实机器人任务中表现优异，任务成功率显著提升。

Conclusion: PLD提供了一种可扩展的自改进VLA模型路径，残差探测和分布感知数据收集是关键。

Abstract: Supervised fine-tuning (SFT) has become the de facto post-training strategy
for large vision-language-action (VLA) models, but its reliance on costly human
demonstrations limits scalability and generalization. We propose Probe, Learn,
Distill (PLD), a three-stage plug-and-play framework that improves VLAs through
residual reinforcement learning (RL) and distribution-aware data collection. In
Stage 1, we train lightweight residual actors to probe failure regions of the
VLA generalist. In Stage 2, we use a hybrid rollout scheme that aligns
collected trajectories with the generalist's deployment distribution while
capturing recovery behaviors. In Stage 3, we distill the curated trajectories
back into the generalist with standard SFT. PLD achieves near-saturated 99%
task success on LIBERO, over 50% gains in SimplerEnv, and 100% success on
real-world Franka and YAM arm manipulation tasks. Ablations show that residual
probing and distribution-aware replay are key to collecting deployment-aligned
data that improves both seen and unseen tasks, offering a scalable path toward
self-improving VLA models.

</details>


### [12] [SpinalSAM-R1: A Vision-Language Multimodal Interactive System for Spine CT Segmentation](https://arxiv.org/abs/2511.00095)
*Jiaming Liu,Dingwei Fan,Junyong Zhao,Chunlin Li,Haipeng Si,Liang Sun*

Main category: cs.CV

TL;DR: SpinalSAM-R1是一种结合了微调SAM和DeepSeek-R1的多模态视觉语言交互系统，用于脊柱CT图像分割，解决了低对比度和复杂边界的挑战。


<details>
  <summary>Details</summary>
Motivation: 脊柱CT图像分割在疾病诊断和治疗中至关重要，但现有模型如SAM因高标注需求和领域适应性差而表现不佳。

Method: 提出SpinalSAM-R1，引入解剖学引导的注意力机制和语义驱动的交互协议，使用LoRA进行高效微调。

Result: 实验显示SpinalSAM-R1在脊柱CT图像分割中表现优异，并开发了支持多种提示的交互软件。

Conclusion: SpinalSAM-R1通过多模态交互和高效微调，显著提升了脊柱CT图像分割的性能和实用性。

Abstract: The anatomical structure segmentation of the spine and adjacent structures
from computed tomography (CT) images is a key step for spinal disease diagnosis
and treatment. However, the segmentation of CT images is impeded by low
contrast and complex vertebral boundaries. Although advanced models such as the
Segment Anything Model (SAM) have shown promise in various segmentation tasks,
their performance in spinal CT imaging is limited by high annotation
requirements and poor domain adaptability. To address these limitations, we
propose SpinalSAM-R1, a multimodal vision-language interactive system that
integrates a fine-tuned SAM with DeepSeek-R1, for spine CT image segmentation.
Specifically, our SpinalSAM-R1 introduces an anatomy-guided attention mechanism
to improve spine segmentation performance, and a semantics-driven interaction
protocol powered by DeepSeek-R1, enabling natural language-guided refinement.
The SpinalSAM-R1 is fine-tuned using Low-Rank Adaptation (LoRA) for efficient
adaptation. We validate our SpinalSAM-R1 on the spine anatomical structure with
CT images. Experimental results suggest that our method achieves superior
segmentation performance. Meanwhile, we develop a PyQt5-based interactive
software, which supports point, box, and text-based prompts. The system
supports 11 clinical operations with 94.3\% parsing accuracy and sub-800 ms
response times. The software is released on
https://github.com/6jm233333/spinalsam-r1.

</details>


### [13] [A filtering scheme for confocal laser endomicroscopy (CLE)-video sequences for self-supervised learning](https://arxiv.org/abs/2511.00098)
*Nils Porsche,Flurin Müller-Diesing,Sweta Banerjee,Miguel Goncalves,Marc Aubreville*

Main category: cs.CV

TL;DR: 论文提出了一种用于减少CLE视频序列冗余的过滤方法，以提高自监督学习的训练效率和收敛性，并在两个数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: CLE图像难以解读且数据标注不足，自监督学习（SSL）可以解决这一问题，但高帧间相关性导致数据冗余，影响训练效率。

Method: 提出一种CLE视频序列过滤方法，结合SSL教师-学生网络和视觉变换器骨干网络，评估其在两个肿瘤数据集上的表现。

Result: 过滤后的SSL预训练模型在两个数据集上分别达到67.48%和73.52%的测试准确率，显著优于非SSL基线，且训练时间减少67%。

Conclusion: SSL是CLE预训练的有效方法，提出的过滤方法能显著提高训练效率。

Abstract: Confocal laser endomicroscopy (CLE) is a non-invasive, real-time imaging
modality that can be used for in-situ, in-vivo imaging and the microstructural
analysis of mucous structures. The diagnosis using CLE is, however, complicated
by images being hard to interpret for non-experienced physicians. Utilizing
machine learning as an augmentative tool would hence be beneficial, but is
complicated by the shortage of histopathology-correlated CLE imaging sequences
with respect to the plurality of patterns in this domain, leading to
overfitting of machine learning models. To overcome this, self-supervised
learning (SSL) can be employed on larger unlabeled datasets. CLE is a
video-based modality with high inter-frame correlation, leading to a
non-stratified data distribution for SSL training. In this work, we propose a
filter functionality on CLE video sequences to reduce the dataset redundancy in
SSL training and improve SSL training convergence and training efficiency. We
use four state-of-the-art baseline networks and a SSL teacher-student network
with a vision transformer small backbone for the evaluation. These networks
were evaluated on downstream tasks for a sinonasal tumor dataset and a squamous
cell carcinoma of the skin dataset. On both datasets, we found the highest test
accuracy on the filtered SSL-pretrained model, with 67.48% and 73.52%, both
considerably outperforming their non-SSL baselines. Our results show that SSL
is an effective method for CLE pretraining. Further, we show that our proposed
CLE video filter can be utilized to improve training efficiency in
self-supervised scenarios, resulting in a reduction of 67% in training time.

</details>


### [14] [FreeSliders: Training-Free, Modality-Agnostic Concept Sliders for Fine-Grained Diffusion Control in Images, Audio, and Video](https://arxiv.org/abs/2511.00103)
*Rotem Ezra,Hedi Zisling,Nimrod Berman,Ilan Naiman,Alexey Gorkor,Liran Nochumsohn,Eliya Nachmani,Omri Azencot*

Main category: cs.CV

TL;DR: FreeSliders提出了一种无需训练、适用于多模态的方法，通过部分估计Concept Sliders公式实现细粒度概念控制，扩展了基准测试并改进了评估指标。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像、音频和视频生成中表现出色，但细粒度可控生成仍具挑战性。现有方法如Concept Sliders需要针对每个概念进行训练和架构调整，限制了扩展性。

Method: FreeSliders在推理过程中部分估计Concept Sliders公式，无需训练且适用于多模态。扩展了基准测试至视频和音频，并提出新的评估指标。

Result: 实验表明，FreeSliders实现了即插即用的概念控制，优于现有基线，并提供了新的可控生成工具。

Conclusion: FreeSliders为多模态细粒度可控生成提供了一种简单有效的方法，解决了现有方法的扩展性问题。

Abstract: Diffusion models have become state-of-the-art generative models for images,
audio, and video, yet enabling fine-grained controllable generation, i.e.,
continuously steering specific concepts without disturbing unrelated content,
remains challenging. Concept Sliders (CS) offer a promising direction by
discovering semantic directions through textual contrasts, but they require
per-concept training and architecture-specific fine-tuning (e.g., LoRA),
limiting scalability to new modalities. In this work we introduce FreeSliders,
a simple yet effective approach that is fully training-free and
modality-agnostic, achieved by partially estimating the CS formula during
inference. To support modality-agnostic evaluation, we extend the CS benchmark
to include both video and audio, establishing the first suite for fine-grained
concept generation control with multiple modalities. We further propose three
evaluation properties along with new metrics to improve evaluation quality.
Finally, we identify an open problem of scale selection and non-linear
traversals and introduce a two-stage procedure that automatically detects
saturation points and reparameterizes traversal for perceptually uniform,
semantically meaningful edits. Extensive experiments demonstrate that our
method enables plug-and-play, training-free concept control across modalities,
improves over existing baselines, and establishes new tools for principled
controllable generation. An interactive presentation of our benchmark and
method is available at: https://azencot-group.github.io/FreeSliders/

</details>


### [15] [AI Powered High Quality Text to Video Generation with Enhanced Temporal Consistency](https://arxiv.org/abs/2511.00107)
*Piyushkumar Patel*

Main category: cs.CV

TL;DR: MOVAI是一个新颖的分层框架，通过结合场景理解和时间感知扩散模型，提升了文本到视频生成的质量和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在时间一致性、场景理解和细粒度控制方面存在不足，MOVAI旨在解决这些问题。

Method: MOVAI引入了三个创新：1) 组合场景解析器(CSP)，2) 时空注意力机制(TSAM)，3) 渐进式视频细化模块(PVR)。

Result: 实验表明，MOVAI在LPIPS、FVD和用户偏好研究中分别提升了15.3%、12.7%和18.9%。

Conclusion: MOVAI在复杂多对象场景生成中表现出色，实现了高质量和细粒度控制。

Abstract: Text to video generation has emerged as a critical frontier in generative
artificial intelligence, yet existing approaches struggle with maintaining
temporal consistency, compositional understanding, and fine grained control
over visual narratives. We present MOVAI (Multimodal Original Video AI), a
novel hierarchical framework that integrates compositional scene understanding
with temporal aware diffusion models for high fidelity text to video synthesis.
Our approach introduces three key innovations: (1) a Compositional Scene Parser
(CSP) that decomposes textual descriptions into hierarchical scene graphs with
temporal annotations, (2) a Temporal-Spatial Attention Mechanism (TSAM) that
ensures coherent motion dynamics across frames while preserving spatial
details, and (3) a Progressive Video Refinement (PVR) module that iteratively
enhances video quality through multi-scale temporal reasoning. Extensive
experiments on standard benchmarks demonstrate that MOVAI achieves
state-of-the-art performance, improving video quality metrics by 15.3% in
LPIPS, 12.7% in FVD, and 18.9% in user preference studies compared to existing
methods. Our framework shows particular strength in generating complex
multi-object scenes with realistic temporal dynamics and fine-grained semantic
control.

</details>


### [16] [Chain of Time: In-Context Physical Simulation with Image Generation Models](https://arxiv.org/abs/2511.00110)
*YingQiao Wang,Eric Bigelow,Boyi Li,Tomer Ullman*

Main category: cs.CV

TL;DR: 提出了一种名为“Chain of Time”的认知启发方法，用于改进和解释视觉语言模型中的物理模拟，无需额外微调即可在推理时使用。


<details>
  <summary>Details</summary>
Motivation: 受机器学习的上下文推理和人类心理模拟启发，旨在通过生成中间图像序列来增强物理模拟能力。

Method: 在推理时生成一系列中间图像，应用于2D图形模拟和自然3D视频，测试速度、加速度、流体动力学等物理属性。

Result: 显著提升了图像生成模型的性能，并揭示了模型在模拟时间相关物理属性（如速度、重力、碰撞）时的能力与局限性。

Conclusion: Chain of Time方法不仅提升了性能，还提供了对模型物理推理能力的深入理解，揭示了传统评估中未发现的动态特性。

Abstract: We propose a novel cognitively-inspired method to improve and interpret
physical simulation in vision-language models. Our ``Chain of Time" method
involves generating a series of intermediate images during a simulation, and it
is motivated by in-context reasoning in machine learning, as well as mental
simulation in humans. Chain of Time is used at inference time, and requires no
additional fine-tuning. We apply the Chain-of-Time method to synthetic and
real-world domains, including 2-D graphics simulations and natural 3-D videos.
These domains test a variety of particular physical properties, including
velocity, acceleration, fluid dynamics, and conservation of momentum. We found
that using Chain-of-Time simulation substantially improves the performance of a
state-of-the-art image generation model. Beyond examining performance, we also
analyzed the specific states of the world simulated by an image model at each
time step, which sheds light on the dynamics underlying these simulations. This
analysis reveals insights that are hidden from traditional evaluations of
physical reasoning, including cases where an image generation model is able to
simulate physical properties that unfold over time, such as velocity, gravity,
and collisions. Our analysis also highlights particular cases where the image
generation model struggles to infer particular physical parameters from input
images, despite being capable of simulating relevant physical processes.

</details>


### [17] [End-to-End Framework Integrating Generative AI and Deep Reinforcement Learning for Autonomous Ultrasound Scanning](https://arxiv.org/abs/2511.00114)
*Hanae Elmekki,Amanda Spilkin,Ehsan Zakeri,Antonela Mariel Zanuttini,Ahmed Alagha,Hani Sami,Jamal Bentahar,Lyes Kadem,Wen-Fang Xie,Philippe Pibarot,Rabeb Mizouni,Hadi Otrok,Azzam Mourad,Sami Muhaidat*

Main category: cs.CV

TL;DR: 提出首个结合生成AI和深度强化学习的端到端框架，用于实现自主、可重复的心脏超声扫描。


<details>
  <summary>Details</summary>
Motivation: 心脏超声检查依赖操作者且资源有限，需自动化解决方案。现有深度强化学习方法缺乏可重复性和简化模型。

Method: 框架包括条件生成模拟器（GANs与VAEs结合）和深度强化学习模块，用于学习自主扫描策略。

Result: 通过专家验证模型提供AI指导，生成真实超声图像，并公开数据集确保可重复性。

Conclusion: 该框架为其他器官的可重复研究奠定了基础，并通过实验验证了有效性。

Abstract: Cardiac ultrasound (US) is among the most widely used diagnostic tools in
cardiology for assessing heart health, but its effectiveness is limited by
operator dependence, time constraints, and human error. The shortage of trained
professionals, especially in remote areas, further restricts access. These
issues underscore the need for automated solutions that can ensure consistent,
and accessible cardiac imaging regardless of operator skill or location. Recent
progress in artificial intelligence (AI), especially in deep reinforcement
learning (DRL), has gained attention for enabling autonomous decision-making.
However, existing DRL-based approaches to cardiac US scanning lack
reproducibility, rely on proprietary data, and use simplified models. Motivated
by these gaps, we present the first end-to-end framework that integrates
generative AI and DRL to enable autonomous and reproducible cardiac US
scanning. The framework comprises two components: (i) a conditional generative
simulator combining Generative Adversarial Networks (GANs) with Variational
Autoencoders (VAEs), that models the cardiac US environment producing realistic
action-conditioned images; and (ii) a DRL module that leverages this simulator
to learn autonomous, accurate scanning policies. The proposed framework
delivers AI-driven guidance through expert-validated models that classify image
type and assess quality, supports conditional generation of realistic US
images, and establishes a reproducible foundation extendable to other organs.
To ensure reproducibility, a publicly available dataset of real cardiac US
scans is released. The solution is validated through several experiments. The
VAE-GAN is benchmarked against existing GAN variants, with performance assessed
using qualitative and quantitative approaches, while the DRL-based scanning
system is evaluated under varying configurations to demonstrate effectiveness.

</details>


### [18] [VLM6D: VLM based 6Dof Pose Estimation based on RGB-D Images](https://arxiv.org/abs/2511.00120)
*Md Selim Sarowar,Sungho Kim*

Main category: cs.CV

TL;DR: VLM6D提出了一种双流架构，结合视觉和几何数据，用于6D物体姿态估计，在遮挡和光照变化下表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前6D姿态估计方法在真实场景中（如光照变化、无纹理物体和遮挡）表现不佳，VLM6D旨在解决这些问题。

Method: 采用双流架构：视觉Transformer处理RGB数据，PointNet++处理点云数据，通过多任务预测头融合特征。

Result: 在Occluded-LineMOD数据集上达到SOTA性能，验证了其鲁棒性和准确性。

Conclusion: VLM6D通过结合视觉和几何数据，显著提升了6D姿态估计的鲁棒性和精度。

Abstract: The primary challenge in computer vision is precisely calculating the pose of
6D objects, however many current approaches are still fragile and have trouble
generalizing from synthetic data to real-world situations with fluctuating
lighting, textureless objects, and significant occlusions. To address these
limitations, VLM6D, a novel dual-stream architecture that leverages the
distinct strengths of visual and geometric data from RGB-D input for robust and
precise pose estimation. Our framework uniquely integrates two specialized
encoders: a powerful, self-supervised Vision Transformer (DINOv2) processes the
RGB modality, harnessing its rich, pre-trained understanding of visual grammar
to achieve remarkable resilience against texture and lighting variations.
Concurrently, a PointNet++ encoder processes the 3D point cloud derived from
depth data, enabling robust geometric reasoning that excels even with the
sparse, fragmented data typical of severe occlusion. These complementary
feature streams are effectively fused to inform a multi task prediction head.
We demonstrate through comprehensive experiments that VLM6D obtained new SOTA
performance on the challenging Occluded-LineMOD, validating its superior
robustness and accuracy.

</details>


### [19] [Integrating ConvNeXt and Vision Transformers for Enhancing Facial Age Estimation](https://arxiv.org/abs/2511.00123)
*Gaby Maroun,Salah Eddine Bekhouche,Fadi Dornaika*

Main category: cs.CV

TL;DR: 提出了一种结合ConvNeXt和ViT的混合架构，用于面部年龄估计，性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决面部年龄估计的复杂性问题，结合CNN和Transformer的优势。

Method: 使用ConvNeXt和ViT的混合架构，通过预训练模型和优化配置提升性能。

Result: 在MORPH II、CACD和AFAD数据集上表现优异，MAE指标突出。

Conclusion: 混合架构为复杂计算机视觉任务提供了新方向，展示了CNN和Transformer结合的潜力。

Abstract: Age estimation from facial images is a complex and multifaceted challenge in
computer vision. In this study, we present a novel hybrid architecture that
combines ConvNeXt, a state-of-the-art advancement of convolutional neural
networks (CNNs), with Vision Transformers (ViT). While each model independently
delivers excellent performance on a variety of tasks, their integration
leverages the complementary strengths of the CNNs localized feature extraction
capabilities and the Transformers global attention mechanisms. Our proposed
ConvNeXt-ViT hybrid solution was thoroughly evaluated on benchmark age
estimation datasets, including MORPH II, CACD, and AFAD, and achieved superior
performance in terms of mean absolute error (MAE). To address computational
constraints, we leverage pre-trained models and systematically explore
different configurations, using linear layers and advanced regularization
techniques to optimize the architecture. Comprehensive ablation studies
highlight the critical role of individual components and training strategies,
and in particular emphasize the importance of adapted attention mechanisms
within the CNN framework to improve the model focus on age-relevant facial
features. The results show that the ConvNeXt-ViT hybrid not only outperforms
traditional methods, but also provides a robust foundation for future advances
in age estimation and related visual tasks. This work underscores the
transformative potential of hybrid architectures and represents a promising
direction for the seamless integration of CNNs and transformers to address
complex computer vision challenges.

</details>


### [20] [FLoC: Facility Location-Based Efficient Visual Token Compression for Long Video Understanding](https://arxiv.org/abs/2511.00141)
*Janghoon Cho,Jungsoo Lee,Munawar Hayat,Kyuwoong Hwang,Fatih Porikli,Sungha Choi*

Main category: cs.CV

TL;DR: FLoC是一种基于设施位置函数的高效视觉标记压缩框架，用于解决长视频理解中视觉标记过多的问题。


<details>
  <summary>Details</summary>
Motivation: 长视频理解中，视觉标记数量庞大限制了模型的扩展性。

Method: 采用设施位置函数和懒惰贪婪算法，快速选择紧凑且多样化的视觉标记子集。

Result: 在多个大规模基准测试中表现优异，超越现有压缩技术。

Conclusion: FLoC是一种高效、通用且无需训练的解决方案，适用于多种视频-LLM和工作流程。

Abstract: Recent studies in long video understanding have harnessed the advanced
visual-language reasoning capabilities of Large Multimodal Models (LMMs),
driving the evolution of video-LMMs specialized for processing extended video
sequences. However, the scalability of these models is severely limited by the
overwhelming volume of visual tokens generated from extended video sequences.
To address this challenge, this paper proposes FLoC, an efficient visual token
compression framework based on the facility location function, a principled
approach that swiftly selects a compact yet highly representative and diverse
subset of visual tokens within a predefined budget on the number of visual
tokens. By integrating the lazy greedy algorithm, our method achieves
remarkable efficiency gains by swiftly selecting a compact subset of tokens,
drastically reducing the number of visual tokens while guaranteeing
near-optimal performance. Notably, our approach is training-free,
model-agnostic, and query-agnostic, providing a versatile solution that
seamlessly integrates with diverse video-LLMs and existing workflows. Extensive
evaluations on large-scale benchmarks, such as Video-MME, MLVU, and
LongVideoBench, demonstrate that our framework consistently surpasses recent
compression techniques, highlighting not only its effectiveness and robustness
in addressing the critical challenges of long video understanding, but also its
efficiency in processing speed.

</details>


### [21] [BlurGuard: A Simple Approach for Robustifying Image Protection Against AI-Powered Editing](https://arxiv.org/abs/2511.00143)
*Jinsu Kim,Yunhun Nam,Minseon Kim,Sangpil Kim,Jongheon Jeong*

Main category: cs.CV

TL;DR: 本文提出了一种简单方法（自适应高斯模糊）来增强图像保护对抗噪声的鲁棒性，使其更难被检测和逆转。


<details>
  <summary>Details</summary>
Motivation: 现有图像保护方法中的对抗噪声容易被逆转（如JPEG压缩），因此需要一种既不可见又不可逆的保护方法。

Method: 通过自适应区域高斯模糊调整噪声的频率谱，增强对抗噪声的鲁棒性。

Result: 实验表明，该方法显著提升了现有方法对多种逆转技术的保护性能，同时减少了噪声对图像质量的负面影响。

Conclusion: 提出的方法有效提升了图像保护的鲁棒性和实用性，代码已开源。

Abstract: Recent advances in text-to-image models have increased the exposure of
powerful image editing techniques as a tool, raising concerns about their
potential for malicious use. An emerging line of research to address such
threats focuses on implanting "protective" adversarial noise into images before
their public release, so future attempts to edit them using text-to-image
models can be impeded. However, subsequent works have shown that these
adversarial noises are often easily "reversed," e.g., with techniques as simple
as JPEG compression, casting doubt on the practicality of the approach. In this
paper, we argue that adversarial noise for image protection should not only be
imperceptible, as has been a primary focus of prior work, but also
irreversible, viz., it should be difficult to detect as noise provided that the
original image is hidden. We propose a surprisingly simple method to enhance
the robustness of image protection methods against noise reversal techniques.
Specifically, it applies an adaptive per-region Gaussian blur on the noise to
adjust the overall frequency spectrum. Through extensive experiments, we show
that our method consistently improves the per-sample worst-case protection
performance of existing methods against a wide range of reversal techniques on
diverse image editing scenarios, while also reducing quality degradation due to
noise in terms of perceptual metrics. Code is available at
https://github.com/jsu-kim/BlurGuard.

</details>


### [22] [CompAgent: An Agentic Framework for Visual Compliance Verification](https://arxiv.org/abs/2511.00171)
*Rahul Ghosh,Baishali Chaudhury,Hari Prasanna Das,Meghana Ashok,Ryan Razkenari,Sungmin Hong,Chun-Hao Liu*

Main category: cs.CV

TL;DR: CompAgent是一个基于多模态大语言模型（MLLMs）的代理框架，通过动态选择视觉工具和规划代理，提升视觉合规性验证的准确性和适应性。


<details>
  <summary>Details</summary>
Motivation: 视觉合规性验证在媒体、娱乐和广告等领域至关重要，但现有方法依赖特定任务的深度学习模型，成本高且泛化能力有限。MLLMs虽具备广泛知识，但在细粒度视觉推理和结构化规则应用上表现不足。

Method: CompAgent结合MLLMs与视觉工具（如物体检测器、人脸分析器等），通过规划代理动态选择工具，验证代理整合多模态信息进行推理。

Result: 在公开基准测试中，CompAgent的F1分数达76%，比现有最佳方法提升10%。

Conclusion: 代理规划和工具增强推理可有效实现可扩展、准确且适应性强的视觉合规性验证。

Abstract: Visual compliance verification is a critical yet underexplored problem in
computer vision, especially in domains such as media, entertainment, and
advertising where content must adhere to complex and evolving policy rules.
Existing methods often rely on task-specific deep learning models trained on
manually labeled datasets, which are costly to build and limited in
generalizability. While recent multi-modal large language models (MLLMs) offer
broad real-world knowledge and policy understanding, they struggle to reason
over fine-grained visual details and apply structured compliance rules
effectively on their own. In this paper, we propose CompAgent, the first
agentic framework for visual compliance verification. CompAgent augments MLLMs
with a suite of visual tools - such as object detectors, face analyzers, NSFW
detectors, and captioning models - and introduces a planning agent that
dynamically selects appropriate tools based on the compliance policy. A
verification agent then integrates image, tool outputs, and policy context to
perform multi-modal reasoning. Experiments on public benchmarks show that
CompAgent outperforms specialized classifiers, direct MLLM prompting, and
curated routing baselines, achieving up to 76% F1 score and a 10% improvement
over the state-of-the-art on the UnsafeBench dataset. Our results demonstrate
the effectiveness of agentic planning and tool-augmented reasoning for
scalable, accurate, and adaptable visual compliance verification.

</details>


### [23] [From Evidence to Verdict: An Agent-Based Forensic Framework for AI-Generated Image Detection](https://arxiv.org/abs/2511.00181)
*Mengfei Liang,Yiting Qu,Yukun Jiang,Michael Backes,Yang Zhang*

Main category: cs.CV

TL;DR: AIFo是一个基于多智能体协作的训练免费框架，用于检测AI生成图像，通过跨源证据分析和多智能体辩论机制，显著提高了检测准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: AI生成图像的快速发展对信息完整性和媒体真实性提出了前所未有的挑战，现有检测方法在泛化性和解释性方面存在局限。

Method: AIFo通过多智能体协作，结合反向图像搜索、元数据提取、预训练分类器和视觉语言模型分析，并引入记忆增强推理模块和历史案例学习。

Result: 在6000张图像的评估中，AIFo达到97.05%的准确率，显著优于传统分类器和最先进的视觉语言模型。

Conclusion: 基于智能体的程序推理为AI生成图像检测提供了更鲁棒、可解释和适应性强的新范式。

Abstract: The rapid evolution of AI-generated images poses unprecedented challenges to
information integrity and media authenticity. Existing detection approaches
suffer from fundamental limitations: traditional classifiers lack
interpretability and fail to generalize across evolving generative models,
while vision-language models (VLMs), despite their promise, remain constrained
to single-shot analysis and pixel-level reasoning. To address these challenges,
we introduce AIFo (Agent-based Image Forensics), a novel training-free
framework that emulates human forensic investigation through multi-agent
collaboration. Unlike conventional methods, our framework employs a set of
forensic tools, including reverse image search, metadata extraction,
pre-trained classifiers, and VLM analysis, coordinated by specialized LLM-based
agents that collect, synthesize, and reason over cross-source evidence. When
evidence is conflicting or insufficient, a structured multi-agent debate
mechanism allows agents to exchange arguments and reach a reliable conclusion.
Furthermore, we enhance the framework with a memory-augmented reasoning module
that learns from historical cases to improve future detection accuracy. Our
comprehensive evaluation spans 6,000 images across both controlled laboratory
settings and challenging real-world scenarios, including images from modern
generative platforms and diverse online sources. AIFo achieves 97.05% accuracy,
substantially outperforming traditional classifiers and state-of-the-art VLMs.
These results demonstrate that agent-based procedural reasoning offers a new
paradigm for more robust, interpretable, and adaptable AI-generated image
detection.

</details>


### [24] [A Retrospect to Multi-prompt Learning across Vision and Language](https://arxiv.org/abs/2511.00191)
*Ziliang Chen,Xin Huang,Quanlong Guan,Liang Lin,Weiqi Luo*

Main category: cs.CV

TL;DR: 本文提出了一种基于能量的多提示学习（EMPL）方法，通过从能量分布中提取实例生成多提示嵌入，以提升视觉语言模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注单提示范式，而多提示学习的技术潜力尚未充分探索。本文旨在填补这一空白，并验证多提示增强在视觉语言迁移中的优越性。

Method: 扩展了模态间隙现象到可学习提示，提出EMPL方法，通过能量分布生成多提示嵌入，实现参数高效且平衡的泛化。

Result: 实验验证了EMPL在多提示学习中的优越性，以及在域内和域外开放词汇泛化中的平衡表现。

Conclusion: EMPL为视觉语言多提示学习提供了理论基础和实践方法，显著提升了模型的泛化能力。

Abstract: The vision community is undergoing the unprecedented progress with the
emergence of Vision-Language Pretraining Models (VLMs). Prompt learning plays
as the holy grail of accessing VLMs since it enables their fast adaptation to
downstream tasks with limited resources. Whereas existing researches milling
around single-prompt paradigms, rarely investigate the technical potential
behind their multi-prompt learning counterparts. This paper aims to provide a
principled retrospect for vision-language multi-prompt learning. We extend the
recent constant modality gap phenomenon to learnable prompts and then, justify
the superiority of vision-language transfer with multi-prompt augmentation,
empirically and theoretically. In terms of this observation, we propose an
Energy-based Multi-prompt Learning (EMPL) to generate multiple prompt
embeddings by drawing instances from an energy-based distribution, which is
implicitly defined by VLMs. So our EMPL is not only parameter-efficient but
also rigorously lead to the balance between in-domain and out-of-domain
open-vocabulary generalization. Comprehensive experiments have been conducted
to justify our claims and the excellence of EMPL.

</details>


### [25] [An Efficient and Generalizable Transfer Learning Method for Weather Condition Detection on Ground Terminals](https://arxiv.org/abs/2511.00211)
*Wenxuan Zhang,Peng Hu*

Main category: cs.CV

TL;DR: 本文提出了一种高效的迁移学习方法，用于地面终端组件本地检测天气相关条件，以提高卫星互联网的可靠性。


<details>
  <summary>Details</summary>
Motivation: 天气事件对卫星互联网性能和可靠性有显著影响，现有解决方案缺乏细粒度检测能力，且在实际部署中效果和泛化性不足。

Method: 采用迁移学习（TL）方法，使地面组件能够本地检测代表性天气相关条件（如雪、湿等）。

Result: 该方法在检测雪、湿等天气条件时表现优于典型深度学习方法（如YOLOv7、YOLOv9、Faster R-CNN和R-YOLO），并具有泛化能力。

Conclusion: 提出的迁移学习方法能有效提升卫星互联网的可靠性，适用于多种场景。

Abstract: The increasing adoption of satellite Internet with low-Earth-orbit (LEO)
satellites in mega-constellations allows ubiquitous connectivity to rural and
remote areas. However, weather events have a significant impact on the
performance and reliability of satellite Internet. Adverse weather events such
as snow and rain can disturb the performance and operations of satellite
Internet's essential ground terminal components, such as satellite antennas,
significantly disrupting the space-ground link conditions between LEO
satellites and ground stations. This challenge calls for not only region-based
weather forecasts but also fine-grained detection capability on ground terminal
components of fine-grained weather conditions. Such a capability can assist in
fault diagnostics and mitigation for reliable satellite Internet, but its
solutions are lacking, not to mention the effectiveness and generalization that
are essential in real-world deployments. This paper discusses an efficient
transfer learning (TL) method that can enable a ground component to locally
detect representative weather-related conditions. The proposed method can
detect snow, wet, and other conditions resulting from adverse and typical
weather events and shows superior performance compared to the typical deep
learning methods, such as YOLOv7, YOLOv9, Faster R-CNN, and R-YOLO. Our TL
method also shows the advantage of being generalizable to various scenarios.

</details>


### [26] [DM-QPMNET: Dual-modality fusion network for cell segmentation in quantitative phase microscopy](https://arxiv.org/abs/2511.00218)
*Rajatsubhra Chakraborty,Ana Espinosa-Momox,Riley Haskin,Depeng Xu,Rosario Porras-Aguilar*

Main category: cs.CV

TL;DR: DM-QPMNet是一种双编码器网络，通过多模态融合提升单次定量相位显微镜（ssQPM）中的细胞分割效果。


<details>
  <summary>Details</summary>
Motivation: 传统阈值方法对噪声和细胞密度敏感，而简单的通道拼接深度学习方法未能充分利用偏振强度图像和相位图的互补性。

Method: 采用双编码器网络，通过多头部注意力在中间深度融合模态特定特征，结合双源跳跃连接和每模态归一化。

Result: 相比单模态和简单拼接方法，DM-QPMNet在细胞分割上表现显著提升。

Conclusion: 模态特定编码与可学习融合能有效利用ssQPM的互补光照和相位信息，实现稳健的细胞分割。

Abstract: Cell segmentation in single-shot quantitative phase microscopy (ssQPM) faces
challenges from traditional thresholding methods that are sensitive to noise
and cell density, while deep learning approaches using simple channel
concatenation fail to exploit the complementary nature of polarized intensity
images and phase maps. We introduce DM-QPMNet, a dual-encoder network that
treats these as distinct modalities with separate encoding streams. Our
architecture fuses modality-specific features at intermediate depth via
multi-head attention, enabling polarized edge and texture representations to
selectively integrate complementary phase information. This content-aware
fusion preserves training stability while adding principled multi-modal
integration through dual-source skip connections and per-modality normalization
at minimal overhead. Our approach demonstrates substantial improvements over
monolithic concatenation and single-modality baselines, showing that
modality-specific encoding with learnable fusion effectively exploits ssQPM's
simultaneous capture of complementary illumination and phase cues for robust
cell segmentation.

</details>


### [27] [Towards 1000-fold Electron Microscopy Image Compression for Connectomics via VQ-VAE with Transformer Prior](https://arxiv.org/abs/2511.00231)
*Fuming Yang,Yicong Li,Hanspeter Pfister,Jeff W. Lichtman,Yaron Meirovitch*

Main category: cs.CV

TL;DR: 提出了一种基于VQ-VAE的电子显微镜数据压缩框架，支持16x至1024x的压缩比，并允许按需解码。


<details>
  <summary>Details</summary>
Motivation: 处理大规模电子显微镜数据时，存储、传输和下游分析面临挑战。

Method: 使用VQ-VAE框架，结合Transformer先验和FiLM技术，实现高压缩比和纹理恢复。

Result: 支持灵活的按需解码和选择性高分辨率重建。

Conclusion: 该框架有效解决了大规模电子显微镜数据的压缩和分析问题。

Abstract: Petascale electron microscopy (EM) datasets push storage, transfer, and
downstream analysis toward their current limits. We present a vector-quantized
variational autoencoder-based (VQ-VAE) compression framework for EM that spans
16x to 1024x and enables pay-as-you-decode usage: top-only decoding for extreme
compression, with an optional Transformer prior that predicts bottom tokens
(without changing the compression ratio) to restore texture via feature-wise
linear modulation (FiLM) and concatenation; we further introduce an ROI-driven
workflow that performs selective high-resolution reconstruction from
1024x-compressed latents only where needed.

</details>


### [28] [Hyperbolic Optimal Transport](https://arxiv.org/abs/2511.00244)
*Yan Bin Ng,Xianfeng Gu*

Main category: cs.CV

TL;DR: 本文提出了一种在双曲空间中计算最优传输映射的新算法，扩展了欧几里得和球面几何的方法。


<details>
  <summary>Details</summary>
Motivation: 现有最优传输映射方法主要针对欧几里得空间和球面，而双曲空间在层次数据、网络和多亏格黎曼曲面中有广泛应用。

Method: 采用几何变分技术，将欧几里得和球面几何的方法扩展到双曲空间。

Result: 在合成数据和多亏格曲面模型上的实验验证了方法的有效性。

Conclusion: 提出的算法在双曲空间中高效计算最优传输映射，填补了现有方法的空白。

Abstract: The optimal transport (OT) problem aims to find the most efficient mapping
between two probability distributions under a given cost function, and has
diverse applications in many fields such as machine learning, computer vision
and computer graphics. However, existing methods for computing optimal
transport maps are primarily developed for Euclidean spaces and the sphere. In
this paper, we explore the problem of computing the optimal transport map in
hyperbolic space, which naturally arises in contexts involving hierarchical
data, networks, and multi-genus Riemann surfaces. We propose a novel and
efficient algorithm for computing the optimal transport map in hyperbolic space
using a geometric variational technique by extending methods for Euclidean and
spherical geometry to the hyperbolic setting. We also perform experiments on
synthetic data and multi-genus surface models to validate the efficacy of the
proposed method.

</details>


### [29] [Object-Aware 4D Human Motion Generation](https://arxiv.org/abs/2511.00248)
*Shurui Gui,Deep Anil Patel,Xiner Li,Martin Renqiang Min*

Main category: cs.CV

TL;DR: 提出了一种基于3D高斯表示和运动扩散先验的对象感知4D人体运动生成框架MSDI，通过结合LLM和MSDS优化运动，解决了现有视频扩散模型中3D物理先验缺失导致的问题。


<details>
  <summary>Details</summary>
Motivation: 现有视频扩散模型生成的视频存在不真实变形、语义违规和物理不一致问题，主要原因是缺乏3D物理先验。

Method: 提出MSDI框架，利用预生成的3D人体和对象，结合LLM的空间和语义信息以及MSDS的运动先验，进行空间感知的运动优化。

Result: 实验表明，该方法能生成自然且物理合理的人体运动，无需重新训练即可泛化到分布外对象感知运动。

Conclusion: MSDI为真实的4D生成提供了可扩展的解决方案，显著提升了运动生成的物理一致性和语义准确性。

Abstract: Recent advances in video diffusion models have enabled the generation of
high-quality videos. However, these videos still suffer from unrealistic
deformations, semantic violations, and physical inconsistencies that are
largely rooted in the absence of 3D physical priors. To address these
challenges, we propose an object-aware 4D human motion generation framework
grounded in 3D Gaussian representations and motion diffusion priors. With
pre-generated 3D humans and objects, our method, Motion Score Distilled
Interaction (MSDI), employs the spatial and prompt semantic information in
large language models (LLMs) and motion priors through the proposed Motion
Diffusion Score Distillation Sampling (MSDS). The combination of MSDS and LLMs
enables our spatial-aware motion optimization, which distills score gradients
from pre-trained motion diffusion models, to refine human motion while
respecting object and semantic constraints. Unlike prior methods requiring
joint training on limited interaction datasets, our zero-shot approach avoids
retraining and generalizes to out-of-distribution object aware human motions.
Experiments demonstrate that our framework produces natural and physically
plausible human motions that respect 3D spatial context, offering a scalable
solution for realistic 4D generation.

</details>


### [30] [Merlin L48 Spectrogram Dataset](https://arxiv.org/abs/2511.00252)
*Aaron Sun,Subhransu Maji,Grant Van Horn*

Main category: cs.CV

TL;DR: 论文介绍了L48数据集，用于评估单正多标签（SPML）方法在真实场景中的表现，并分析了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有SPML方法在合成数据集上表现良好，但无法反映真实场景的复杂性，需要更真实的数据集进行评估。

Method: 提出L48数据集，基于鸟类声音记录，提供自然SPML设置和两种扩展设置。

Result: 在L48上评估现有SPML方法，发现性能差异显著，揭示了方法的弱点。

Conclusion: L48数据集为SPML研究提供了更真实和困难的基准，推动了该领域的发展。

Abstract: In the single-positive multi-label (SPML) setting, each image in a dataset is
labeled with the presence of a single class, while the true presence of other
classes remains unknown. The challenge is to narrow the performance gap between
this partially-labeled setting and fully-supervised learning, which often
requires a significant annotation budget. Prior SPML methods were developed and
benchmarked on synthetic datasets created by randomly sampling single positive
labels from fully-annotated datasets like Pascal VOC, COCO, NUS-WIDE, and
CUB200. However, this synthetic approach does not reflect real-world scenarios
and fails to capture the fine-grained complexities that can lead to difficult
misclassifications. In this work, we introduce the L48 dataset, a fine-grained,
real-world multi-label dataset derived from recordings of bird sounds. L48
provides a natural SPML setting with single-positive annotations on a
challenging, fine-grained domain, as well as two extended settings in which
domain priors give access to additional negative labels. We benchmark existing
SPML methods on L48 and observe significant performance differences compared to
synthetic datasets and analyze method weaknesses, underscoring the need for
more realistic and difficult benchmarks.

</details>


### [31] [BeetleFlow: An Integrative Deep Learning Pipeline for Beetle Image Processing](https://arxiv.org/abs/2511.00255)
*Fangxun Liu,S M Rayeed,Samuel Stevens,Alyson East,Cheng Hsuan Chiang,Colin Lee,Daniel Yi,Junke Yang,Tejas Naik,Ziyi Wang,Connor Kilrain,Elijah H Buckwalter,Jiacheng Hou,Saul Ibaven Bueno,Shuheng Wang,Xinyue Ma,Yifan Liu,Zhiyuan Tao,Ziheng Zhang,Eric Sokol,Michael Belitz,Sydne Record,Charles V. Stewart,Wei-Lun Chao*

Main category: cs.CV

TL;DR: 开发了一个3阶段自动化流程，用于检测、分类和分割大量甲虫图像，以提高生态学研究的效率。


<details>
  <summary>Details</summary>
Motivation: 生物学家需要处理大量甲虫图像，手动处理效率低下，因此需要一个自动化流程来加速研究。

Method: 采用基于Transformer的开放词汇检测器和视觉语言模型进行检测，并微调分割模型进行形态分割。

Result: 流程整合了多种深度学习方法，能够高效处理大规模甲虫数据。

Conclusion: 该流程显著提高了甲虫图像处理的效率，有助于加速生物学研究。

Abstract: In entomology and ecology research, biologists often need to collect a large
number of insects, among which beetles are the most common species. A common
practice for biologists to organize beetles is to place them on trays and take
a picture of each tray. Given the images of thousands of such trays, it is
important to have an automated pipeline to process the large-scale data for
further research. Therefore, we develop a 3-stage pipeline to detect all the
beetles on each tray, sort and crop the image of each beetle, and do
morphological segmentation on the cropped beetles. For detection, we design an
iterative process utilizing a transformer-based open-vocabulary object detector
and a vision-language model. For segmentation, we manually labeled 670 beetle
images and fine-tuned two variants of a transformer-based segmentation model to
achieve fine-grained segmentation of beetles with relatively high accuracy. The
pipeline integrates multiple deep learning methods and is specialized for
beetle image processing, which can greatly improve the efficiency to process
large-scale beetle data and accelerate biological research.

</details>


### [32] [MambaNetLK: Enhancing Colonoscopy Point Cloud Registration with Mamba](https://arxiv.org/abs/2511.00260)
*Linzhe Jiang,Jiayuan Huang,Sophia Bano,Matthew J. Clarkson,Zhehua Mao,Mobarak I. Hoque*

Main category: cs.CV

TL;DR: 论文提出了一种名为MambaNetLK的新型3D配准方法，用于解决内窥镜导航中的特征退化问题，并在临床数据集上取得了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 生物组织具有重复纹理和局部均匀几何特性，导致特征退化，同时术前与术中观察之间的域偏移进一步降低配准稳定性。

Method: 提出MambaNetLK框架，结合Mamba状态空间模型（SSM）作为跨模态特征提取器，利用Lucas-Kanade算法迭代实现配准。

Result: 在临床数据集C3VD-Raycasting-10k上，MambaNetLK将中值旋转误差降低56.04%，平移误差RMSE降低26.19%，优于现有方法。

Conclusion: MambaNetLK为手术导航中的3D配准提供了鲁棒基础，结合SSM特征提取器和大规模临床数据集，提升了结肠镜等微创手术的导航准确性。

Abstract: Accurate 3D point cloud registration underpins reliable image-guided
colonoscopy, directly affecting lesion localization, margin assessment, and
navigation safety. However, biological tissue exhibits repetitive textures and
locally homogeneous geometry that cause feature degeneracy, while substantial
domain shifts between pre-operative anatomy and intra-operative observations
further degrade alignment stability. To address these clinically critical
challenges, we introduce a novel 3D registration method tailored for endoscopic
navigation and a high-quality, clinically grounded dataset to support rigorous
and reproducible benchmarking. We introduce C3VD-Raycasting-10k, a large-scale
benchmark dataset with 10,014 geometrically aligned point cloud pairs derived
from clinical CT data. We propose MambaNetLK, a novel correspondence-free
registration framework, which enhances the PointNetLK architecture by
integrating a Mamba State Space Model (SSM) as a cross-modal feature extractor.
As a result, the proposed framework efficiently captures long-range
dependencies with linear-time complexity. The alignment is achieved iteratively
using the Lucas-Kanade algorithm. On the clinical dataset, C3VD-Raycasting-10k,
MambaNetLK achieves the best performance compared with the state-of-the-art
methods, reducing median rotation error by 56.04% and RMSE translation error by
26.19% over the second-best method. The model also demonstrates strong
generalization on ModelNet40 and superior robustness to initial pose
perturbations. MambaNetLK provides a robust foundation for 3D registration in
surgical navigation. The combination of a globally expressive SSM-based feature
extractor and a large-scale clinical dataset enables more accurate and reliable
guidance systems in minimally invasive procedures like colonoscopy.

</details>


### [33] [Spot The Ball: A Benchmark for Visual Social Inference](https://arxiv.org/abs/2511.00261)
*Neha Balamurugan,Sarah Wu,Adam Chun,Gabe Gaw,Cristobal Eyzaguirre,Tobias Gerstenberg*

Main category: cs.CV

TL;DR: 论文提出了一个名为'Spot The Ball'的基准测试，用于评估视觉语言模型在视觉社交推理上的表现，发现人类在此任务上比模型准确率高2-3倍。


<details>
  <summary>Details</summary>
Motivation: 研究人类视觉社交推理能力（如通过凝视、姿势等推断场景隐藏元素）对开发更接近人类的AI代理至关重要。

Method: 通过足球、篮球和排球图像，要求模型定位被移除的球，并比较人类与四种先进视觉语言模型的表现。

Result: 人类准确率（20-34%）显著高于模型（≤17%），模型依赖空间启发式方法，而人类利用社交线索。

Conclusion: 揭示了视觉社交推理中人类与模型的差距，强调需要设计能编码结构化行为线索的架构。

Abstract: Humans excel at visual social inference, the ability to infer hidden elements
of a scene from subtle behavioral cues such as other people's gaze, pose, and
orientation. This ability drives everyday social reasoning in humans and is
critical for developing more human-like AI agents. We introduce Spot The Ball,
a challenging benchmark for evaluating visual social inference in
vision-language models (VLMs) using sports as a test domain. The task is to
localize a removed sports ball from soccer, basketball, and volleyball images.
We present a curated evaluation set with human baselines and a scalable
pipeline for generating additional test items. We evaluate four
state-of-the-art VLMs (Gemini, GPT, LLaMA, Qwen) using three prompting
strategies, finding that humans are consistently two to three times more
accurate (20-34%) than models ($\leq$ 17%) across all sports. Our analyses show
that models rely on superficial spatial heuristics--such as guessing near the
image center or nearby players--while humans leverage social cues like gaze
direction and body pose. These findings reveal a persistent human-model gap in
visual social reasoning and underscore the need for architectures that
explicitly encode structured behavioral cues to achieve robust, human-like
inference.

</details>


### [34] [FedReplay: A Feature Replay Assisted Federated Transfer Learning Framework for Efficient and Privacy-Preserving Smart Agriculture](https://arxiv.org/abs/2511.00269)
*Long Li,Jiajia Li,Dong Chen,Lina Pu,Haibo Yao,Yanbo Huang*

Main category: cs.CV

TL;DR: 提出了一种结合CLIP ViT和轻量级Transformer分类器的联邦学习框架，显著提升了农业分类任务的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决传统集中式训练中的隐私问题和联邦学习中的非独立同分布数据及高通信成本问题。

Method: 利用预训练的CLIP ViT提取特征，仅更新轻量级分类器，并共享少量特征以对齐类别表示。

Result: 在农业分类任务中达到86.6%的准确率，比基线联邦学习方法高出4倍。

Conclusion: 结合视觉语言模型特征与联邦学习，实现了隐私保护且可扩展的农业智能分类。

Abstract: Accurate classification plays a pivotal role in smart agriculture, enabling
applications such as crop monitoring, fruit recognition, and pest detection.
However, conventional centralized training often requires large-scale data
collection, which raises privacy concerns, while standard federated learning
struggles with non-independent and identically distributed (non-IID) data and
incurs high communication costs. To address these challenges, we propose a
federated learning framework that integrates a frozen Contrastive
Language-Image Pre-training (CLIP) vision transformer (ViT) with a lightweight
transformer classifier. By leveraging the strong feature extraction capability
of the pre-trained CLIP ViT, the framework avoids training large-scale models
from scratch and restricts federated updates to a compact classifier, thereby
reducing transmission overhead significantly. Furthermore, to mitigate
performance degradation caused by non-IID data distribution, a small subset
(1%) of CLIP-extracted feature representations from all classes is shared
across clients. These shared features are non-reversible to raw images,
ensuring privacy preservation while aligning class representation across
participants. Experimental results on agricultural classification tasks show
that the proposed method achieve 86.6% accuracy, which is more than 4 times
higher compared to baseline federated learning approaches. This demonstrates
the effectiveness and efficiency of combining vision-language model features
with federated learning for privacy-preserving and scalable agricultural
intelligence.

</details>


### [35] [Multi-View Consistent Human Image Customization via In-Context Learning](https://arxiv.org/abs/2511.00293)
*Hengjia Li,Jianjin Xu,Keli Cheng,Lei Wang,Ning Bi,Boxi Wu,Fernando De la Torre,Deng Cai*

Main category: cs.CV

TL;DR: PersonalView是一种轻量级适配方法，仅需100个训练样本即可为现有模型添加多视角生成能力。


<details>
  <summary>Details</summary>
Motivation: 现有个性化生成模型难以控制生成图像视角或生成一致的多视角图像。

Method: 设计了条件架构利用预训练扩散变换器的上下文学习能力，并通过语义对齐损失保留原始生成能力。

Result: 在100个样本下，PersonalView在多视角一致性、文本对齐、身份相似性和视觉质量上显著优于基线。

Conclusion: PersonalView是一种高效的多视角生成解决方案。

Abstract: Recent advances in personalized generative models demonstrate impressive
results in creating identity-consistent images of the same person under diverse
settings. Yet, we note that most methods cannot control the viewpoint of the
generated image, nor generate consistent multiple views of the person. To
address this problem, we propose a lightweight adaptation method, PersonalView,
capable of enabling an existing model to acquire multi-view generation
capability with as few as 100 training samples. PersonalView consists of two
key components: First, we design a conditioning architecture to take advantage
of the in-context learning ability of the pre-trained diffusion transformer.
Second, we preserve the original generative ability of the pretrained model
with a new Semantic Correspondence Alignment Loss. We evaluate the multi-view
consistency, text alignment, identity similarity, and visual quality of
PersonalView and compare it to recent baselines with potential capability of
multi-view customization. PersonalView significantly outperforms baselines
trained on a large corpus of multi-view data with only 100 training samples.

</details>


### [36] [Towards Automated Petrography](https://arxiv.org/abs/2511.00328)
*Isai Daniel Chacón,Paola Ruiz Puentes,Jillian Pearse,Pablo Arbeláez*

Main category: cs.CV

TL;DR: LITHOS是一个大规模、多样化的公开数据集，用于自动化岩石薄片分析，包含21万多个高分辨率RGB图像和10万多个专家标注的矿物颗粒，支持深度学习模型训练。


<details>
  <summary>Details</summary>
Motivation: 岩石薄片分析（Petrography）是一项耗时且依赖专家的任务，限制了其可扩展性，因此需要自动化技术来解决这一问题。

Method: 提出了LITHOS数据集，包含大量高分辨率RGB图像和专家标注的矿物颗粒，并评估了多种深度学习技术，提出了一种双编码器Transformer架构。

Result: 双编码器Transformer模型在矿物分类任务中表现优于单偏振模型，证明了偏振协同的价值。

Conclusion: LITHOS数据集和方法的公开将促进自动化岩石薄片分析的复现和进一步研究。

Abstract: Petrography is a branch of geology that analyzes the mineralogical
composition of rocks from microscopical thin section samples. It is essential
for understanding rock properties across geology, archaeology, engineering,
mineral exploration, and the oil industry. However, petrography is a
labor-intensive task requiring experts to conduct detailed visual examinations
of thin section samples through optical polarization microscopes, thus
hampering scalability and highlighting the need for automated techniques. To
address this challenge, we introduce the Large-scale Imaging and Thin section
Optical-polarization Set (LITHOS), the largest and most diverse publicly
available experimental framework for automated petrography. LITHOS includes
211,604 high-resolution RGB patches of polarized light and 105,802
expert-annotated grains across 25 mineral categories. Each annotation consists
of the mineral class, spatial coordinates, and expert-defined major and minor
axes represented as intersecting vector paths, capturing grain geometry and
orientation. We evaluate multiple deep learning techniques for mineral
classification in LITHOS and propose a dual-encoder transformer architecture
that integrates both polarization modalities as a strong baseline for future
reference. Our method consistently outperforms single-polarization models,
demonstrating the value of polarization synergy in mineral classification. We
have made the LITHOS Benchmark publicly available, comprising our dataset,
code, and pretrained models, to foster reproducibility and further research in
automated petrographic analysis.

</details>


### [37] [Beyond ImageNet: Understanding Cross-Dataset Robustness of Lightweight Vision Models](https://arxiv.org/abs/2511.00335)
*Weidong Zhang,Pak Lun Kevin Ding,Huan Liu*

Main category: cs.CV

TL;DR: 本文系统评估了11种轻量级视觉模型在7个数据集上的表现，提出了跨数据集评分（xScore），发现ImageNet性能不能可靠预测其他领域表现，并揭示了促进泛化的关键架构设计。


<details>
  <summary>Details</summary>
Motivation: 研究轻量级视觉模型在ImageNet以外的数据集上的泛化能力，并量化跨数据集鲁棒性。

Method: 在固定100轮训练计划下，评估11种轻量级模型（2.5M参数）在7个数据集上的表现，提出xScore作为统一度量标准。

Result: ImageNet准确性不能预测细粒度或医学数据集表现；xScore可扩展预测性能；某些架构组件（如各向同性卷积和通道注意力）促进泛化。

Conclusion: 研究为轻量级模型评估提供了可重复框架，揭示了移动友好架构的设计原则，指导未来模型的开发。

Abstract: Lightweight vision classification models such as MobileNet, ShuffleNet, and
EfficientNet are increasingly deployed in mobile and embedded systems, yet
their performance has been predominantly benchmarked on ImageNet. This raises
critical questions: Do models that excel on ImageNet also generalize across
other domains? How can cross-dataset robustness be systematically quantified?
And which architectural elements consistently drive generalization under tight
resource constraints? Here, we present the first systematic evaluation of 11
lightweight vision models (2.5M parameters), trained under a fixed 100-epoch
schedule across 7 diverse datasets. We introduce the Cross-Dataset Score
(xScore), a unified metric that quantifies the consistency and robustness of
model performance across diverse visual domains. Our results show that (1)
ImageNet accuracy does not reliably predict performance on fine-grained or
medical datasets, (2) xScore provides a scalable predictor of mobile model
performance that can be estimated from just four datasets, and (3) certain
architectural components--such as isotropic convolutions with higher spatial
resolution and channel-wise attention--promote broader generalization, while
Transformer-based blocks yield little additional benefit, despite incurring
higher parameter overhead. This study provides a reproducible framework for
evaluating lightweight vision models beyond ImageNet, highlights key design
principles for mobile-friendly architectures, and guides the development of
future models that generalize robustly across diverse application domains.

</details>


### [38] [A DeepONet joint Neural Tangent Kernel Hybrid Framework for Physics-Informed Inverse Source Problems and Robust Image Reconstruction](https://arxiv.org/abs/2511.00338)
*Yuhao Fang,Zijian Wang,Yao Lu,Ye Zhang,Chun Li*

Main category: cs.CV

TL;DR: 提出了一种结合DeepONet和NTK的混合方法，用于解决复杂逆问题，如Navier-Stokes方程控制的源定位和图像重建。


<details>
  <summary>Details</summary>
Motivation: 解决非线性、稀疏和噪声数据带来的挑战，确保物理一致性和准确性。

Method: 结合物理约束和任务特定正则化的损失函数。

Result: 在合成和真实数据集上验证了方法的鲁棒性、可扩展性和精确性。

Conclusion: 该方法在计算物理和成像科学中具有广泛的应用潜力。

Abstract: This work presents a novel hybrid approach that integrates Deep Operator
Networks (DeepONet) with the Neural Tangent Kernel (NTK) to solve complex
inverse problem. The method effectively addresses tasks such as source
localization governed by the Navier-Stokes equations and image reconstruction,
overcoming challenges related to nonlinearity, sparsity, and noisy data. By
incorporating physics-informed constraints and task-specific regularization
into the loss function, the framework ensures solutions that are both
physically consistent and accurate. Validation on diverse synthetic and real
datasets demonstrates its robustness, scalability, and precision, showcasing
its broad potential applications in computational physics and imaging sciences.

</details>


### [39] [Federated Dialogue-Semantic Diffusion for Emotion Recognition under Incomplete Modalities](https://arxiv.org/abs/2511.00344)
*Xihang Qiu,Jiarong Cheng,Yuhao Fang,Wanpeng Zhang,Yao Lu,Ye Zhang,Chun Li*

Main category: cs.CV

TL;DR: FedDISC框架通过联邦学习和扩散模型解决多模态情感识别中的模态缺失问题，提升性能。


<details>
  <summary>Details</summary>
Motivation: 现实场景中多模态数据的不可预测缺失导致现有方法性能下降，传统恢复方法在极端数据分布下语义失真。

Method: 提出FedDISC框架，结合联邦学习和扩散模型，通过对话图网络和语义条件网络确保恢复模态的语义一致性。

Result: 在IEMOCAP等数据集上，FedDISC在多种模态缺失模式下优于现有方法。

Conclusion: FedDISC有效解决了模态缺失问题，提升了情感识别的鲁棒性和性能。

Abstract: Multimodal Emotion Recognition in Conversations (MERC) enhances emotional
understanding through the fusion of multimodal signals. However, unpredictable
modality absence in real-world scenarios significantly degrades the performance
of existing methods. Conventional missing-modality recovery approaches, which
depend on training with complete multimodal data, often suffer from semantic
distortion under extreme data distributions, such as fixed-modality absence. To
address this, we propose the Federated Dialogue-guided and Semantic-Consistent
Diffusion (FedDISC) framework, pioneering the integration of federated learning
into missing-modality recovery. By federated aggregation of modality-specific
diffusion models trained on clients and broadcasting them to clients missing
corresponding modalities, FedDISC overcomes single-client reliance on modality
completeness. Additionally, the DISC-Diffusion module ensures consistency in
context, speaker identity, and semantics between recovered and available
modalities, using a Dialogue Graph Network to capture conversational
dependencies and a Semantic Conditioning Network to enforce semantic alignment.
We further introduce a novel Alternating Frozen Aggregation strategy, which
cyclically freezes recovery and classifier modules to facilitate collaborative
optimization. Extensive experiments on the IEMOCAP, CMUMOSI, and CMUMOSEI
datasets demonstrate that FedDISC achieves superior emotion classification
performance across diverse missing modality patterns, outperforming existing
approaches.

</details>


### [40] [OSMGen: Highly Controllable Satellite Image Synthesis using OpenStreetMap Data](https://arxiv.org/abs/2511.00345)
*Amir Ziashahabi,Narges Ghasemi,Sajjad Shahabi,John Krumm,Salman Avestimehr,Cyrus Shahabi*

Main category: cs.CV

TL;DR: OSMGen是一个生成框架，直接从OpenStreetMap数据生成逼真的卫星图像，解决了城市监测中数据稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 城市规划和环境管理需要准确的时空数据，但自动化监测因缺乏特定城市特征的数据集而困难。

Method: OSMGen利用OSM JSON的矢量几何、语义标签等丰富信息，生成一致的“前后”图像对，用户编辑OSM输入可定向改变图像。

Result: 该框架能生成训练数据以解决数据稀缺和类别不平衡问题，并为规划者提供预览干预效果的简单方式。

Conclusion: OSMGen为静态和变化状态生成配对的（JSON，图像）数据，为卫星图像自动驱动结构化OSM更新的闭环系统铺平道路。

Abstract: Accurate and up-to-date geospatial data are essential for urban planning,
infrastructure monitoring, and environmental management. Yet, automating urban
monitoring remains difficult because curated datasets of specific urban
features and their changes are scarce. We introduce OSMGen, a generative
framework that creates realistic satellite imagery directly from raw
OpenStreetMap (OSM) data. Unlike prior work that relies on raster tiles, OSMGen
uses the full richness of OSM JSON, including vector geometries, semantic tags,
location, and time, giving fine-grained control over how scenes are generated.
A central feature of the framework is the ability to produce consistent
before-after image pairs: user edits to OSM inputs translate into targeted
visual changes, while the rest of the scene is preserved. This makes it
possible to generate training data that addresses scarcity and class imbalance,
and to give planners a simple way to preview proposed interventions by editing
map data. More broadly, OSMGen produces paired (JSON, image) data for both
static and changed states, paving the way toward a closed-loop system where
satellite imagery can automatically drive structured OSM updates. Source code
is available at https://github.com/amir-zsh/OSMGen.

</details>


### [41] [Detecting AI-Generated Images via Diffusion Snap-Back Reconstruction: A Forensic Approach](https://arxiv.org/abs/2511.00352)
*Mohd Ruhul Ameen,Akif Islam*

Main category: cs.CV

TL;DR: 提出了一种基于扩散模型的图像检测方法，通过多强度图像重建动态区分真实与AI生成图像。


<details>
  <summary>Details</summary>
Motivation: 传统深度伪造检测方法无法应对现代文本到图像系统生成的逼真图像，需要新的检测手段。

Method: 利用扩散回放技术，分析不同噪声强度下的重建指标（LPIPS、SSIM、PSNR），提取可解释的流形特征。

Result: 在4000张图像的平衡数据集上，AUROC达到0.993，对压缩和噪声等常见失真具有鲁棒性。

Conclusion: 该方法具有强泛化能力和可解释性，为可扩展、模型无关的合成媒体取证提供了基础。

Abstract: The rapid rise of generative diffusion models has made distinguishing
authentic visual content from synthetic imagery increasingly challenging.
Traditional deepfake detection methods, which rely on frequency or pixel-level
artifacts, fail against modern text-to-image systems such as Stable Diffusion
and DALL-E that produce photorealistic and artifact-free results. This paper
introduces a diffusion-based forensic framework that leverages multi-strength
image reconstruction dynamics, termed diffusion snap-back, to identify
AI-generated images. By analysing how reconstruction metrics (LPIPS, SSIM, and
PSNR) evolve across varying noise strengths, we extract interpretable
manifold-based features that differentiate real and synthetic images. Evaluated
on a balanced dataset of 4,000 images, our approach achieves 0.993 AUROC under
cross-validation and remains robust to common distortions such as compression
and noise. Despite using limited data and a single diffusion backbone (Stable
Diffusion v1.5), the proposed method demonstrates strong generalization and
interpretability, offering a foundation for scalable, model-agnostic synthetic
media forensics.

</details>


### [42] [Transfer Learning for Onboard Cloud Segmentation in Thermal Earth Observation: From Landsat to a CubeSat Constellation](https://arxiv.org/abs/2511.00357)
*Niklas Wölki,Lukas Kondmann,Christian Mollière,Martin Langer,Julia Gottfriedsen,Martin Werner*

Main category: cs.CV

TL;DR: 利用迁移学习和轻量级UNet模型在CubeSat上实现高效的热红外云分割。


<details>
  <summary>Details</summary>
Motivation: CubeSat任务受限于硬件和光谱信息，传统云掩膜技术不可行，需要新的解决方案。

Method: 使用MobileNet编码器的UNet模型，先在公开数据集上预训练，再用少量任务特定数据微调。

Result: 宏F1从0.850提升到0.877，并在NVIDIA Jetson Nano上实现5秒内全图推理。

Conclusion: 公共数据集和轻量架构可实现高效、准确的热红外云分割，支持实时决策。

Abstract: Onboard cloud segmentation is a critical yet underexplored task in thermal
Earth observation (EO), particularly for CubeSat missions constrained by
limited hardware and spectral information. CubeSats often rely on a single
thermal band and lack sufficient labeled data, making conventional cloud
masking techniques infeasible. This work addresses these challenges by applying
transfer learning to thermal cloud segmentation for the FOREST-2 CubeSat, using
a UNet with a lightweight MobileNet encoder. We pretrain the model on the
public Landsat-7 Cloud Cover Assessment Dataset and fine-tune it with a small
set of mission-specific samples in a joint-training setup, improving the macro
F1 from 0.850 to 0.877 over FOREST-2-only baselines. We convert the model to a
TensorRT engine and demonstrate full-image inference in under 5 seconds on an
NVIDIA Jetson Nano. These results show that leveraging public datasets and
lightweight architectures can enable accurate, efficient thermal-only cloud
masking on-orbit, supporting real-time decision-making in data-limited EO
missions.

</details>


### [43] [Oitijjo-3D: Generative AI Framework for Rapid 3D Heritage Reconstruction from Street View Imagery](https://arxiv.org/abs/2511.00362)
*Momen Khandoker Ope,Akif Islam,Mohd Ruhul Ameen,Abu Saleh Musa Miah,Md Rashedul Islam,Jungpil Shin*

Main category: cs.CV

TL;DR: Oitijjo-3D是一个免费生成AI框架，利用Google街景图像快速重建文化遗产的3D模型，降低技术和经济门槛。


<details>
  <summary>Details</summary>
Motivation: 孟加拉文化遗产修复面临资源和技术不足的挑战，传统3D数字化方法成本高且依赖专家，导致许多建筑遗产无法数字化保存。

Method: 通过两阶段流程：1) 使用Gemini 2.5 Flash Image进行多模态视觉推理合成结构纹理；2) 通过Hexagen实现神经图像到3D的几何恢复。

Result: 实验证明，Oitijjo-3D能在秒级生成高保真3D模型，显著降低技术和经济门槛。

Conclusion: 该工作将文化遗产保存转变为社区驱动的AI辅助行为，为资源有限国家提供文化延续的新途径。

Abstract: Cultural heritage restoration in Bangladesh faces a dual challenge of limited
resources and scarce technical expertise. Traditional 3D digitization methods,
such as photogrammetry or LiDAR scanning, require expensive hardware, expert
operators, and extensive on-site access, which are often infeasible in
developing contexts. As a result, many of Bangladesh's architectural treasures,
from the Paharpur Buddhist Monastery to Ahsan Manzil, remain vulnerable to
decay and inaccessible in digital form. This paper introduces Oitijjo-3D, a
cost-free generative AI framework that democratizes 3D cultural preservation.
By using publicly available Google Street View imagery, Oitijjo-3D reconstructs
faithful 3D models of heritage structures through a two-stage pipeline -
multimodal visual reasoning with Gemini 2.5 Flash Image for structure-texture
synthesis, and neural image-to-3D generation through Hexagen for geometry
recovery. The system produces photorealistic, metrically coherent
reconstructions in seconds, achieving significant speedups compared to
conventional Structure-from-Motion pipelines, without requiring any specialized
hardware or expert supervision. Experiments on landmarks such as Ahsan Manzil,
Choto Sona Mosque, and Paharpur demonstrate that Oitijjo-3D preserves both
visual and structural fidelity while drastically lowering economic and
technical barriers. By turning open imagery into digital heritage, this work
reframes preservation as a community-driven, AI-assisted act of cultural
continuity for resource-limited nations.

</details>


### [44] [Who Can We Trust? Scope-Aware Video Moment Retrieval with Multi-Agent Conflict](https://arxiv.org/abs/2511.00370)
*Chaochen Wu,Guan Luo,Meiyun Zuo,Zhitao Fan*

Main category: cs.CV

TL;DR: 提出了一种基于强化学习的视频时刻检索模型，通过多智能体系统和证据学习解决冲突，并能够判断查询是否超出范围。


<details>
  <summary>Details</summary>
Motivation: 当前方法未考虑不同模型定位结果的冲突，导致模型无法有效整合。

Method: 引入强化学习模型和多智能体系统框架，利用证据学习解决冲突。

Result: 在基准数据集上表现优于现有方法，展示了多智能体系统中冲突建模的有效性。

Conclusion: 多智能体系统中的冲突建模和证据学习能显著提升视频时刻检索性能。

Abstract: Video moment retrieval uses a text query to locate a moment from a given
untrimmed video reference. Locating corresponding video moments with text
queries helps people interact with videos efficiently. Current solutions for
this task have not considered conflict within location results from different
models, so various models cannot integrate correctly to produce better results.
This study introduces a reinforcement learning-based video moment retrieval
model that can scan the whole video once to find the moment's boundary while
producing its locational evidence. Moreover, we proposed a multi-agent system
framework that can use evidential learning to resolve conflicts between agents'
localization output. As a side product of observing and dealing with conflicts
between agents, we can decide whether a query has no corresponding moment in a
video (out-of-scope) without additional training, which is suitable for
real-world applications. Extensive experiments on benchmark datasets show the
effectiveness of our proposed methods compared with state-of-the-art
approaches. Furthermore, the results of our study reveal that modeling
competition and conflict of the multi-agent system is an effective way to
improve RL performance in moment retrieval and show the new role of evidential
learning in the multi-agent framework.

</details>


### [45] [VisionCAD: An Integration-Free Radiology Copilot Framework](https://arxiv.org/abs/2511.00381)
*Jiaming Li,Junlei Wu,Sheng Wang,Honglin Xiong,Jiangdong Cai,Zihao Zhao,Yitao Zhu,Yuan Yin,Dinggang Shen,Qian Wang*

Main category: cs.CV

TL;DR: VisionCAD是一种基于视觉的放射辅助框架，通过摄像头系统直接从显示屏捕获医学图像，无需修改现有医院IT基础设施即可实现AI辅助诊断。


<details>
  <summary>Details</summary>
Motivation: 解决计算机辅助诊断（CAD）系统难以与现有医院IT基础设施集成的挑战。

Method: 通过自动化流程检测、恢复和分析屏幕上的医学图像，将摄像头捕获的视觉数据转换为适合自动分析和报告生成的诊断质量图像。

Result: 在多种医学影像数据集上验证，诊断性能接近传统CAD系统（F1分数下降通常小于2%），自动报告的自然语言生成指标与原图相差不到1%。

Conclusion: VisionCAD提供了一种无需修改现有基础设施的AI辅助诊断方法，适用于多样化的临床环境。

Abstract: Widespread clinical deployment of computer-aided diagnosis (CAD) systems is
hindered by the challenge of integrating with existing hospital IT
infrastructure. Here, we introduce VisionCAD, a vision-based radiological
assistance framework that circumvents this barrier by capturing medical images
directly from displays using a camera system. The framework operates through an
automated pipeline that detects, restores, and analyzes on-screen medical
images, transforming camera-captured visual data into diagnostic-quality images
suitable for automated analysis and report generation. We validated VisionCAD
across diverse medical imaging datasets, demonstrating that our modular
architecture can flexibly utilize state-of-the-art diagnostic models for
specific tasks. The system achieves diagnostic performance comparable to
conventional CAD systems operating on original digital images, with an F1-score
degradation typically less than 2\% across classification tasks, while natural
language generation metrics for automated reports remain within 1\% of those
derived from original images. By requiring only a camera device and standard
computing resources, VisionCAD offers an accessible approach for AI-assisted
diagnosis, enabling the deployment of diagnostic capabilities in diverse
clinical settings without modifications to existing infrastructure.

</details>


### [46] [Rethinking Facial Expression Recognition in the Era of Multimodal Large Language Models: Benchmark, Datasets, and Beyond](https://arxiv.org/abs/2511.00389)
*Fan Zhang,Haoxuan Li,Shengju Qian,Xin Wang,Zheng Lian,Hao Wu,Zhihong Zhu,Yuan Gao,Qiankun Li,Yefeng Zheng,Zhouchen Lin,Pheng-Ann Heng*

Main category: cs.CV

TL;DR: 论文提出了FERBench基准测试，评估了20种MLLMs在FER任务中的表现，并开发了UniFER-7B模型，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 探索多模态大语言模型（MLLMs）在面部表情识别（FER）任务中的表现，填补现有研究的空白。

Method: 通过将FER数据集转换为VQA格式，评估20种MLLMs的性能，并开发了UniFER-7B模型，结合冷启动和强化学习策略。

Result: UniFER-7B在FER任务中表现优于许多开源和闭源MLLMs，如Gemini-2.5-Pro和Qwen2.5-VL-72B。

Conclusion: MLLMs在FER任务中仍有局限性，但通过后训练策略（如UniFER-7B）可以显著提升其推理和可解释性。

Abstract: Multimodal Large Language Models (MLLMs) have revolutionized numerous
research fields, including computer vision and affective computing. As a
pivotal challenge in this interdisciplinary domain, facial expression
recognition (FER) has evolved from separate, domain-specific models to more
unified approaches. One promising avenue to unify FER tasks is converting
conventional FER datasets into visual question-answering (VQA) formats,
enabling the direct application of powerful generalist MLLMs for inference.
However, despite the success of cutting-edge MLLMs in various tasks, their
performance on FER tasks remains largely unexplored. To address this gap, we
provide FERBench, a systematic benchmark that incorporates 20 state-of-the-art
MLLMs across four widely used FER datasets. Our results reveal that, while
MLLMs exhibit good classification performance, they still face significant
limitations in reasoning and interpretability. To this end, we introduce
post-training strategies aimed at enhancing the facial expression reasoning
capabilities of MLLMs. Specifically, we curate two high-quality and large-scale
datasets: UniFER-CoT-230K for cold-start initialization and UniFER-RLVR-360K
for reinforcement learning with verifiable rewards (RLVR), respectively.
Building upon them, we develop a unified and interpretable FER foundation model
termed UniFER-7B, which outperforms many open-sourced and closed-source
generalist MLLMs (e.g., Gemini-2.5-Pro and Qwen2.5-VL-72B).

</details>


### [47] [VinciCoder: Unifying Multimodal Code Generation via Coarse-to-fine Visual Reinforcement Learning](https://arxiv.org/abs/2511.00391)
*Xuanle Zhao,Deyang Jiang,Zhixiong Zeng,Lei Chen,Haibo Qiu,Jing Huang,Yufeng Zhong,Liming Zheng,Yilin Cao,Lin Ma*

Main category: cs.CV

TL;DR: VinciCoder是一个统一的多模态代码生成模型，通过两阶段训练框架解决现有视觉语言模型的局限性，并在多个基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型依赖单任务训练，限制了通用视觉代码智能的发展。

Method: 采用两阶段训练框架：大规模监督微调（SFT）和视觉强化学习（ViRL），后者通过局部和全局图像块的视觉相似性计算提升视觉保真度。

Result: 在多个多模态代码生成基准测试中达到最先进性能。

Conclusion: VinciCoder通过两阶段训练框架有效提升了多模态代码生成的性能，证明了其方法的有效性。

Abstract: Multimodal code generation has garnered significant interest within the
research community. Despite the notable success of recent vision-language
models (VLMs) on specialized tasks like Chart-to-code generation, their
reliance on single-task training regimens fosters a narrow paradigm that
hinders the development of generalized \textbf{VI}sio\textbf{N} \textbf{C}ode
\textbf{I}ntelligence. In this work, we introduce \textbf{VinciCoder}, a
unified multimodal code generation model that addresses this limitation via a
two-stage training framework. We begin by constructing a large-scale Supervised
Finetuning (SFT) corpus comprising 1.6M image-code pairs for tasks involving
direct code generation and visual-based code refinement. Subsequently, we
introduce a Visual Reinforcement Learning (ViRL) strategy, which employs a
coarse-to-fine reward mechanism to improve visual fidelity by calculating
visual similarity across local and global image patches. Extensive experiments
on various multimodal code generation benchmarks demonstrate that VinciCoder
achieves state-of-the-art performance, underscoring the effectiveness of our
coarse-to-fine ViRL strategy. The code and model will be available at
https://github.com/DocTron-hub/VinciCoder.

</details>


### [48] [CoT-Saliency: Unified Chain-of-Thought Reasoning for Heterogeneous Saliency Tasks](https://arxiv.org/abs/2511.00396)
*Long Li,Shuichen Ji,Ziyang Luo,Nian Liu,Dingwen Zhang,Junwei Han*

Main category: cs.CV

TL;DR: 提出首个统一框架，通过链式思维（CoT）推理处理三种异构显著性任务（SOD、CoSOD、SIS），结合两阶段训练（SFT和RL）及新算法CGPO提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决异构显著性任务间的操作差异，通过VLM中的CoT推理统一处理。

Method: 采用两阶段训练（SFT和RL），提出CGPO算法优化RL阶段，并设计“输出到推理”策略构建高质量SFT数据。

Result: 模型在多个任务上优于专用SOTA方法，CoSOD任务上S-measure达0.899，提升8.0个百分点。

Conclusion: 统一框架有效处理异构任务，CGPO和高质量数据策略显著提升性能。

Abstract: We present the first unified framework that jointly handles three
operationally heterogeneous saliency tasks, eg, SOD, CoSOD, and SIS, by casting
each as a Chain-of-Thought (CoT) reasoning process in a Vision-Language Model
(VLM) to bridge task heterogeneity. CoT training follows a two-stage paradigm:
Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL). To enhance CoT
quality in RL, we propose Confidence-Guided Policy Optimization (CGPO), a
lightweight single-sample algorithm that leverages the discrepancy between
reward and model confidence as a per-sample advantage signal. This design
naturally focuses updates on informative responses while eliminating group
sampling, thereby addressing GRPO's key limitations: confidence-agnostic
learning, signal dilution, and prohibitive computational overhead. We also
introduce an "output-to-reasoning" strategy to construct high-fidelity SFT data
that ensures logical consistency with ground-truth masks. Experiments show our
model matches or outperforms specialized SOTA methods and strong closed-source
VLMs across all tasks, especially achieving an S-measure of 0.899 on CoCA for
CoSOD, surpassing the prior best by 8.0 percentage points, despite using far
less training data.

</details>


### [49] [LGCA: Enhancing Semantic Representation via Progressive Expansion](https://arxiv.org/abs/2511.00419)
*Thanh Hieu Cao,Trung Khang Tran,Gia Thinh Pham,Tuong Nghiem Diep,Thanh Binh Nguyen*

Main category: cs.CV

TL;DR: LGCA框架通过局部-全局交叉对齐提升CLIP模型的零样本分类性能，减少随机裁剪带来的误导信息。


<details>
  <summary>Details</summary>
Motivation: CLIP模型对随机图像裁剪敏感，容易引入误导信息，需要一种方法来平衡局部和全局特征。

Method: 提出LGCA框架，先捕获局部特征，再选择并扩展最显著区域，设计相似性分数结合原始和扩展图像。

Result: 实验表明LGCA显著提升零样本性能，优于现有基线方法。

Conclusion: LGCA有效平衡局部与全局特征，减少误导信息，且计算复杂度与原始模型相同。

Abstract: Recent advancements in large-scale pretraining in natural language processing
have enabled pretrained vision-language models such as CLIP to effectively
align images and text, significantly improving performance in zero-shot image
classification tasks. Subsequent studies have further demonstrated that
cropping images into smaller regions and using large language models to
generate multiple descriptions for each caption can further enhance model
performance. However, due to the inherent sensitivity of CLIP, random image
crops can introduce misinformation and bias, as many images share similar
features at small scales. To address this issue, we propose
Localized-Globalized Cross-Alignment (LGCA), a framework that first captures
the local features of an image and then repeatedly selects the most salient
regions and expands them. The similarity score is designed to incorporate both
the original and expanded images, enabling the model to capture both local and
global features while minimizing misinformation. Additionally, we provide a
theoretical analysis demonstrating that the time complexity of LGCA remains the
same as that of the original model prior to the repeated expansion process,
highlighting its efficiency and scalability. Extensive experiments demonstrate
that our method substantially improves zero-shot performance across diverse
datasets, outperforming state-of-the-art baselines.

</details>


### [50] [Leveraging Hierarchical Image-Text Misalignment for Universal Fake Image Detection](https://arxiv.org/abs/2511.00427)
*Daichi Zhang,Tong Zhang,Jianmin Bao,Shiming Ge,Sabine Süsstrunk*

Main category: cs.CV

TL;DR: 提出了一种基于图像-文本不对齐的多模态检测方法（ITEM），用于检测生成图像，具有优异的泛化性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅依赖视觉线索，容易过拟合且泛化能力差，而生成图像在图像-文本对齐上存在问题。

Method: 利用预训练的CLIP空间测量图像与文本的不对齐，并通过MLP头进行检测，同时提出分层不对齐方案。

Result: 在多种生成模型上表现出卓越的泛化性和鲁棒性，优于现有方法。

Conclusion: 多模态视角和分层不对齐方案能有效提升生成图像检测的性能。

Abstract: With the rapid development of generative models, detecting generated fake
images to prevent their malicious use has become a critical issue recently.
Existing methods frame this challenge as a naive binary image classification
task. However, such methods focus only on visual clues, yielding trained
detectors susceptible to overfitting specific image patterns and incapable of
generalizing to unseen models. In this paper, we address this issue from a
multi-modal perspective and find that fake images cannot be properly aligned
with corresponding captions compared to real images. Upon this observation, we
propose a simple yet effective detector termed ITEM by leveraging the
image-text misalignment in a joint visual-language space as discriminative
clues. Specifically, we first measure the misalignment of the images and
captions in pre-trained CLIP's space, and then tune a MLP head to perform the
usual detection task. Furthermore, we propose a hierarchical misalignment
scheme that first focuses on the whole image and then each semantic object
described in the caption, which can explore both global and fine-grained local
semantic misalignment as clues. Extensive experiments demonstrate the
superiority of our method against other state-of-the-art competitors with
impressive generalization and robustness on various recent generative models.

</details>


### [51] [Enhancing Frequency Forgery Clues for Diffusion-Generated Image Detection](https://arxiv.org/abs/2511.00429)
*Daichi Zhang,Tong Zhang,Shiming Ge,Sabine Süsstrunk*

Main category: cs.CV

TL;DR: 提出了一种基于频率伪造线索（F^2C）的方法，用于检测扩散模型生成的图像，具有更好的泛化性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 扩散模型生成的图像质量高，可能被恶意使用，现有检测器泛化性和鲁棒性不足。

Method: 通过分析频率差异，提出频率选择性函数增强F^2C，抑制不具区分性的频段。

Result: 在多个数据集上优于现有检测器，泛化性和鲁棒性更强。

Conclusion: F^2C方法能有效检测扩散模型生成的图像，适用于不同模型和扰动场景。

Abstract: Diffusion models have achieved remarkable success in image synthesis, but the
generated high-quality images raise concerns about potential malicious use.
Existing detectors often struggle to capture discriminative clues across
different models and settings, limiting their generalization to unseen
diffusion models and robustness to various perturbations. To address this
issue, we observe that diffusion-generated images exhibit progressively larger
differences from natural real images across low- to high-frequency bands. Based
on this insight, we propose a simple yet effective representation by enhancing
the Frequency Forgery Clue (F^2C) across all frequency bands. Specifically, we
introduce a frequency-selective function which serves as a weighted filter to
the Fourier spectrum, suppressing less discriminative bands while enhancing
more informative ones. This approach, grounded in a comprehensive analysis of
frequency-based differences between natural real and diffusion-generated
images, enables general detection of images from unseen diffusion models and
provides robust resilience to various perturbations. Extensive experiments on
various diffusion-generated image datasets demonstrate that our method
outperforms state-of-the-art detectors with superior generalization and
robustness.

</details>


### [52] [ToxicTextCLIP: Text-Based Poisoning and Backdoor Attacks on CLIP Pre-training](https://arxiv.org/abs/2511.00446)
*Xin Yao,Haiyang Zhao,Yimin Chen,Jiawei Guo,Kecheng Huang,Ming Zhao*

Main category: cs.CV

TL;DR: ToxicTextCLIP框架通过生成高质量对抗文本，针对CLIP预训练阶段进行攻击，成功率高且能绕过现有防御。


<details>
  <summary>Details</summary>
Motivation: CLIP模型依赖未筛选的互联网数据，存在数据中毒和后门风险，但文本模态的攻击研究不足。

Method: 提出ToxicTextCLIP框架，通过背景感知选择器和背景驱动增强器生成语义一致的对抗文本。

Result: 在分类和检索任务中，攻击成功率高达95.83%，后门命中率达98.68%，且能绕过现有防御。

Conclusion: ToxicTextCLIP揭示了CLIP在文本模态上的安全漏洞，需进一步研究防御方法。

Abstract: The Contrastive Language-Image Pretraining (CLIP) model has significantly
advanced vision-language modeling by aligning image-text pairs from large-scale
web data through self-supervised contrastive learning. Yet, its reliance on
uncurated Internet-sourced data exposes it to data poisoning and backdoor
risks. While existing studies primarily investigate image-based attacks, the
text modality, which is equally central to CLIP's training, remains
underexplored. In this work, we introduce ToxicTextCLIP, a framework for
generating high-quality adversarial texts that target CLIP during the
pre-training phase. The framework addresses two key challenges: semantic
misalignment caused by background inconsistency with the target class, and the
scarcity of background-consistent texts. To this end, ToxicTextCLIP iteratively
applies: 1) a background-aware selector that prioritizes texts with background
content aligned to the target class, and 2) a background-driven augmenter that
generates semantically coherent and diverse poisoned samples. Extensive
experiments on classification and retrieval tasks show that ToxicTextCLIP
achieves up to 95.83% poisoning success and 98.68% backdoor Hit@1, while
bypassing RoCLIP, CleanCLIP and SafeCLIP defenses. The source code can be
accessed via https://github.com/xinyaocse/ToxicTextCLIP/.

</details>


### [53] [Weakly Supervised Pneumonia Localization from Chest X-Rays Using Deep Neural Network and Grad-CAM Explanations](https://arxiv.org/abs/2511.00456)
*Kiran Shahi,Anup Bagale*

Main category: cs.CV

TL;DR: 提出一种弱监督深度学习框架，利用Grad-CAM解释进行肺炎分类和定位，无需像素级标注。


<details>
  <summary>Details</summary>
Motivation: 减少对昂贵像素级标注的依赖，通过图像级标签生成临床有意义的肺炎区域热图。

Method: 评估七种ImageNet预训练架构（ResNet-18/50、DenseNet-121等），使用焦点损失和患者级数据分割防止数据泄漏。

Result: 在Kermany CXR数据集上，ResNet-18和EfficientNet-B0达到98%的测试准确率，ROC-AUC=0.997，F1=0.987。

Conclusion: 弱监督可解释模型能增强肺炎筛查的透明度和临床信任，适用于AI辅助医学影像。

Abstract: This study proposes a weakly supervised deep learning framework for pneumonia
classification and localization from chest X-rays, utilizing Grad-CAM
explanations. Instead of costly pixel-level annotations, our approach utilizes
image-level labels to generate clinically meaningful heatmaps that highlight
regions affected by pneumonia. We evaluate seven ImageNet-pretrained
architectures ResNet-18/50, DenseNet-121, EfficientNet-B0, MobileNet-V2/V3, and
ViT-B16 under identical training conditions with focal loss and patient-wise
splits to prevent data leakage. Experimental results on the Kermany CXR dataset
demonstrate that ResNet-18 and EfficientNet-B0 achieve the best overall test
accuracy of 98\%, ROC-AUC = 0.997, and F1 = 0.987, while MobileNet-V2 provides
an optimal trade-off between accuracy and computational cost. Grad-CAM
visualizations confirm that the proposed models focus on clinically relevant
lung regions, supporting the use of interpretable AI for radiological
diagnostics. This work highlights the potential of weakly supervised
explainable models that enhance pneumonia screening transparency, and clinical
trust in AI-assisted medical imaging.
  https://github.com/kiranshahi/pneumonia-analysis

</details>


### [54] [HumanCrafter: Synergizing Generalizable Human Reconstruction and Semantic 3D Segmentation](https://arxiv.org/abs/2511.00468)
*Panwang Pan,Tingting Shen,Chenxin Li,Yunlong Lin,Kairun Wen,Jingjing Zhao,Yixuan Yuan*

Main category: cs.CV

TL;DR: HumanCrafter是一个统一框架，通过联合建模外观和人体部分语义，实现单图像的高保真3D人体重建和分割。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型在3D人体重建中保真度高，但在特定任务（如3D分割）中效果有限。

Method: 结合几何先验和自监督语义先验，开发交互式标注流程生成高质量数据标签对，通过像素对齐聚合和多任务目标优化。

Result: 在3D人体分割和重建任务中超越现有方法。

Conclusion: HumanCrafter通过跨任务协同和多任务优化，显著提升了3D人体建模的语义一致性和重建质量。

Abstract: Recent advances in generative models have achieved high-fidelity in 3D human
reconstruction, yet their utility for specific tasks (e.g., human 3D
segmentation) remains constrained. We propose HumanCrafter, a unified framework
that enables the joint modeling of appearance and human-part semantics from a
single image in a feed-forward manner. Specifically, we integrate human
geometric priors in the reconstruction stage and self-supervised semantic
priors in the segmentation stage. To address labeled 3D human datasets
scarcity, we further develop an interactive annotation procedure for generating
high-quality data-label pairs. Our pixel-aligned aggregation enables cross-task
synergy, while the multi-task objective simultaneously optimizes texture
modeling fidelity and semantic consistency. Extensive experiments demonstrate
that HumanCrafter surpasses existing state-of-the-art methods in both 3D
human-part segmentation and 3D human reconstruction from a single image.

</details>


### [55] [Longitudinal Vestibular Schwannoma Dataset with Consensus-based Human-in-the-loop Annotations](https://arxiv.org/abs/2511.00472)
*Navodini Wijethilake,Marina Ivory,Oscar MacCormac,Siddhant Kumar,Aaron Kujawa,Lorena Garcia-Foncillas Macias,Rebecca Burger,Amanda Hitchings,Suki Thomson,Sinan Barazi,Eleni Maratos,Rupert Obholzer,Dan Jiang,Fiona McClenaghan,Kazumi Chia,Omar Al-Salihi,Nick Thomas,Steve Connor,Tom Vercauteren,Jonathan Shapey*

Main category: cs.CV

TL;DR: 提出了一种基于深度学习的迭代分割和质量优化框架，用于MRI中前庭神经鞘瘤的自动分割，显著提高了分割精度并减少了人工标注的工作量。


<details>
  <summary>Details</summary>
Motivation: 前庭神经鞘瘤（VS）的准确分割对患者管理至关重要，但传统方法依赖耗时的人工标注。尽管深度学习（DL）在自动分割方面取得进展，但在多样数据集和复杂病例中仍存在挑战。

Method: 通过多中心数据结合专家共识标注，采用自举DL框架进行迭代分割和质量优化，实现资源高效的模型泛化。

Result: 在内部验证数据集上，Dice相似系数（DSC）从0.9125提升至0.9670，外部数据集表现稳定，效率比传统人工标注提高约37.4%。

Conclusion: 该人机协同训练方法在临床多样化环境中展现出高精度和适应性，公开数据集为未来研究提供了资源。

Abstract: Accurate segmentation of vestibular schwannoma (VS) on Magnetic Resonance
Imaging (MRI) is essential for patient management but often requires
time-intensive manual annotations by experts. While recent advances in deep
learning (DL) have facilitated automated segmentation, challenges remain in
achieving robust performance across diverse datasets and complex clinical
cases. We present an annotated dataset stemming from a bootstrapped DL-based
framework for iterative segmentation and quality refinement of VS in MRI. We
combine data from multiple centres and rely on expert consensus for
trustworthiness of the annotations. We show that our approach enables effective
and resource-efficient generalisation of automated segmentation models to a
target data distribution. The framework achieved a significant improvement in
segmentation accuracy with a Dice Similarity Coefficient (DSC) increase from
0.9125 to 0.9670 on our target internal validation dataset, while maintaining
stable performance on representative external datasets. Expert evaluation on
143 scans further highlighted areas for model refinement, revealing nuanced
cases where segmentation required expert intervention. The proposed approach is
estimated to enhance efficiency by approximately 37.4% compared to the
conventional manual annotation process. Overall, our human-in-the-loop model
training approach achieved high segmentation accuracy, highlighting its
potential as a clinically adaptable and generalisable strategy for automated VS
segmentation in diverse clinical settings. The dataset includes 190 patients,
with tumour annotations available for 534 longitudinal contrast-enhanced
T1-weighted (T1CE) scans from 184 patients, and non-annotated T2-weighted scans
from 6 patients. This dataset is publicly accessible on The Cancer Imaging
Archive (TCIA) (https://doi.org/10.7937/bq0z-xa62).

</details>


### [56] [FedMGP: Personalized Federated Learning with Multi-Group Text-Visual Prompts](https://arxiv.org/abs/2511.00480)
*Weihao Bo,Yanpeng Sun,Yu Wang,Xinyu Zhang,Zechao Li*

Main category: cs.CV

TL;DR: FedMGP是一种新的个性化联邦提示学习方法，通过多组提示和动态聚合策略提升视觉语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中个性化提示学习的多样性不足和通信效率低的问题。

Method: 使用多组提示对和多样性损失，结合动态相似性引导的聚合策略。

Result: 在多个联邦视觉语言基准测试中表现最优，通信参数最少。

Conclusion: FedMGP在保持参数效率的同时，显著提升了模型的个性化和泛化能力。

Abstract: In this paper, we introduce FedMGP, a new paradigm for personalized federated
prompt learning in vision-language models. FedMGP equips each client with
multiple groups of paired textual and visual prompts, enabling the model to
capture diverse, fine-grained semantic and instance-level cues. A diversity
loss is introduced to drive each prompt group to specialize in distinct and
complementary semantic aspects, ensuring that the groups collectively cover a
broader range of local characteristics. During communication, FedMGP employs a
dynamic prompt aggregation strategy based on similarity-guided probabilistic
sampling: each client computes the cosine similarity between its prompt groups
and the global prompts from the previous round, then samples s groups via a
softmax-weighted distribution. This soft selection mechanism preferentially
aggregates semantically aligned knowledge while still enabling exploration of
underrepresented patterns effectively balancing the preservation of common
knowledge with client-specific features. Notably, FedMGP maintains parameter
efficiency by redistributing a fixed prompt capacity across multiple groups,
achieving state-of-the-art performance with the lowest communication parameters
among all federated prompt learning methods. Theoretical analysis shows that
our dynamic aggregation strategy promotes robust global representation learning
by reinforcing shared semantics while suppressing client-specific noise.
Extensive experiments demonstrate that FedMGP consistently outperforms prior
approaches in both personalization and domain generalization across diverse
federated vision-language benchmarks. The code will be released on
https://github.com/weihao-bo/FedMGP.git.

</details>


### [57] [Diff4Splat: Controllable 4D Scene Generation with Latent Dynamic Reconstruction Models](https://arxiv.org/abs/2511.00503)
*Panwang Pan,Chenguo Lin,Jingjing Zhao,Chenxin Li,Yuchen Lin,Haopeng Li,Honglei Yan,Kairun Wen,Yunlong Lin,Yixuan Yuan,Yadong Mu*

Main category: cs.CV

TL;DR: Diff4Splat是一种从单张图像合成可控4D场景的前馈方法，结合视频扩散模型和4D数据集约束，无需优化即可预测变形3D高斯场。


<details>
  <summary>Details</summary>
Motivation: 解决从单张图像高效合成高质量4D场景的需求，避免传统方法中的优化和后处理步骤。

Method: 使用视频潜在变换器增强视频扩散模型，联合捕获时空依赖并预测时变3D高斯基元，通过外观、几何和运动一致性目标训练。

Result: 在30秒内合成高质量4D场景，在视频生成、新视角合成和几何提取任务中表现优异，效率显著高于优化方法。

Conclusion: Diff4Splat提供了一种高效且高质量的4D场景合成方案，优于传统优化方法。

Abstract: We introduce Diff4Splat, a feed-forward method that synthesizes controllable
and explicit 4D scenes from a single image. Our approach unifies the generative
priors of video diffusion models with geometry and motion constraints learned
from large-scale 4D datasets. Given a single input image, a camera trajectory,
and an optional text prompt, Diff4Splat directly predicts a deformable 3D
Gaussian field that encodes appearance, geometry, and motion, all in a single
forward pass, without test-time optimization or post-hoc refinement. At the
core of our framework lies a video latent transformer, which augments video
diffusion models to jointly capture spatio-temporal dependencies and predict
time-varying 3D Gaussian primitives. Training is guided by objectives on
appearance fidelity, geometric accuracy, and motion consistency, enabling
Diff4Splat to synthesize high-quality 4D scenes in 30 seconds. We demonstrate
the effectiveness of Diff4Splatacross video generation, novel view synthesis,
and geometry extraction, where it matches or surpasses optimization-based
methods for dynamic scene synthesis while being significantly more efficient.

</details>


### [58] [VinDr-CXR-VQA: A Visual Question Answering Dataset for Explainable Chest X-Ray Analysis with Multi-Task Learning](https://arxiv.org/abs/2511.00504)
*Hai-Dang Nguyen,Ha-Hieu Pham,Hao T. Nguyen,Huy-Hieu Pham*

Main category: cs.CV

TL;DR: VinDr-CXR-VQA是一个大规模胸部X光数据集，用于可解释的医学视觉问答（Med-VQA），包含17,597个问答对和4,394张图像，带有放射科医生验证的标注。


<details>
  <summary>Details</summary>
Motivation: 推动可重复且临床基础的Med-VQA研究，提供多样化的临床意图问题和平衡的数据分布。

Method: 构建包含六种诊断类型问题的数据集，并通过平衡正负样本减少幻觉问题。

Result: 使用MedGemma-4B-it模型，性能提升11.8%（F1=0.624），并实现病灶定位。

Conclusion: VinDr-CXR-VQA数据集和工具公开可用，旨在促进Med-VQA研究的发展。

Abstract: We present VinDr-CXR-VQA, a large-scale chest X-ray dataset for explainable
Medical Visual Question Answering (Med-VQA) with spatial grounding. The dataset
contains 17,597 question-answer pairs across 4,394 images, each annotated with
radiologist-verified bounding boxes and clinical reasoning explanations. Our
question taxonomy spans six diagnostic types-Where, What, Is there, How many,
Which, and Yes/No-capturing diverse clinical intents. To improve reliability,
we construct a balanced distribution of 41.7% positive and 58.3% negative
samples, mitigating hallucinations in normal cases. Benchmarking with
MedGemma-4B-it demonstrates improved performance (F1 = 0.624, +11.8% over
baseline) while enabling lesion localization. VinDr-CXR-VQA aims to advance
reproducible and clinically grounded Med-VQA research. The dataset and
evaluation tools are publicly available at
huggingface.co/datasets/Dangindev/VinDR-CXR-VQA.

</details>


### [59] [OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback](https://arxiv.org/abs/2511.00510)
*Kai Luo,Hao Shi,Kunyu Peng,Fei Teng,Sheng Wu,Kaiwei Wang,Kailun Yang*

Main category: cs.CV

TL;DR: OmniTrack++提出了一种反馈驱动的全景多目标跟踪框架，解决了全景图像中的失真、大搜索空间和身份模糊问题，并在多个数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 全景图像的多目标跟踪面临360度视野、分辨率稀释和严重视角依赖失真等独特挑战，传统方法表现不佳。

Method: 采用反馈驱动框架，包括DynamicSSM块稳定特征、FlexiTrack实例灵活定位、ExpertTrack Memory增强长期鲁棒性，以及Tracklet Management模块动态切换模式。

Result: 在JRDB和EmboTrack数据集上，OmniTrack++的HOTA分别提升了25.5%和43.07%。

Conclusion: OmniTrack++通过创新的模块设计，显著提升了全景多目标跟踪的性能，并提供了公开数据集和代码。

Abstract: This paper investigates Multi-Object Tracking (MOT) in panoramic imagery,
which introduces unique challenges including a 360{\deg} Field of View (FoV),
resolution dilution, and severe view-dependent distortions. Conventional MOT
methods designed for narrow-FoV pinhole cameras generalize unsatisfactorily
under these conditions. To address panoramic distortion, large search space,
and identity ambiguity under a 360{\deg} FoV, OmniTrack++ adopts a
feedback-driven framework that progressively refines perception with trajectory
cues. A DynamicSSM block first stabilizes panoramic features, implicitly
alleviating geometric distortion. On top of normalized representations,
FlexiTrack Instances use trajectory-informed feedback for flexible localization
and reliable short-term association. To ensure long-term robustness, an
ExpertTrack Memory consolidates appearance cues via a Mixture-of-Experts
design, enabling recovery from fragmented tracks and reducing identity drift.
Finally, a Tracklet Management module adaptively switches between end-to-end
and tracking-by-detection modes according to scene dynamics, offering a
balanced and scalable solution for panoramic MOT. To support rigorous
evaluation, we establish the EmboTrack benchmark, a comprehensive dataset for
panoramic MOT that includes QuadTrack, captured with a quadruped robot, and
BipTrack, collected with a bipedal wheel-legged robot. Together, these datasets
span wide-angle environments and diverse motion patterns, providing a
challenging testbed for real-world panoramic perception. Extensive experiments
on JRDB and EmboTrack demonstrate that OmniTrack++ achieves state-of-the-art
performance, yielding substantial HOTA improvements of +25.5% on JRDB and
+43.07% on QuadTrack over the original OmniTrack. Datasets and code will be
made publicly available at https://github.com/xifen523/OmniTrack.

</details>


### [60] [ID-Composer: Multi-Subject Video Synthesis with Hierarchical Identity Preservation](https://arxiv.org/abs/2511.00511)
*Panwang Pan,Jingjing Zhao,Yuchen Lin,Chenguo Lin,Chenxin Li,Haopeng Li,Honglei Yan,Tingting Shen,Yadong Mu*

Main category: cs.CV

TL;DR: ID-Composer是一个新颖的视频生成框架，通过文本提示和参考图像实现多主体视频生成，解决了现有模型在可控性和适用性上的限制。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型通常基于文本或单图像条件，限制了多主体生成和身份保持的需求。

Method: 设计了分层身份保持注意力机制和预训练视觉语言模型（VLM）的语义理解，并结合在线强化学习优化训练目标。

Result: 实验表明，ID-Composer在身份保持、时间一致性和视频质量上优于现有方法。

Conclusion: ID-Composer通过多模态特征聚合和强化学习，显著提升了多主体视频生成的性能。

Abstract: Video generative models pretrained on large-scale datasets can produce
high-quality videos, but are often conditioned on text or a single image,
limiting controllability and applicability. We introduce ID-Composer, a novel
framework that addresses this gap by tackling multi-subject video generation
from a text prompt and reference images. This task is challenging as it
requires preserving subject identities, integrating semantics across subjects
and modalities, and maintaining temporal consistency. To faithfully preserve
the subject consistency and textual information in synthesized videos,
ID-Composer designs a \textbf{hierarchical identity-preserving attention
mechanism}, which effectively aggregates features within and across subjects
and modalities. To effectively allow for the semantic following of user
intention, we introduce \textbf{semantic understanding via pretrained
vision-language model (VLM)}, leveraging VLM's superior semantic understanding
to provide fine-grained guidance and capture complex interactions between
multiple subjects. Considering that standard diffusion loss often fails in
aligning the critical concepts like subject ID, we employ an \textbf{online
reinforcement learning phase} to drive the overall training objective of
ID-Composer into RLVR. Extensive experiments demonstrate that our model
surpasses existing methods in identity preservation, temporal consistency, and
video quality.

</details>


### [61] [SegDebias: Test-Time Bias Mitigation for ViT-Based CLIP via Segmentation](https://arxiv.org/abs/2511.00523)
*Fangyu Wu,Yujun Cai*

Main category: cs.CV

TL;DR: 提出了一种无需训练或偏差标注的测试时去偏方法，通过分割模型隔离目标视觉属性，调整非目标区域嵌入，以消除偏差信号。


<details>
  <summary>Details</summary>
Motivation: 现有去偏方法需训练数据或明确组标签，限制了实际应用；测试时方法仍依赖先验知识，泛化性不足。

Method: 使用预训练分割模型隔离目标属性，调整非目标区域嵌入，使其与所有类特定文本提示均匀相似。

Result: 在Waterbirds和CelebA上优于现有测试时去偏方法，提高了组鲁棒性和Attention IoU。

Conclusion: 分割引导的干预方法可扩展且无需标注，有效缓解视觉语言模型中的偏差。

Abstract: Vision language models such as CLIP have shown remarkable performance in zero
shot classification, but remain susceptible to spurious correlations, where
irrelevant visual features influence predictions. Existing debiasing methods
often require access to training data and explicit group labels to perform
fine-tuning or adjust embeddings, which limits their practicality in real-world
settings. Test-time methods attempt to avoid this constraint, but many still
depend on prior knowledge of dataset specific biases, limiting their
generalizability in open set settings. In this work, we propose a test-time
debiasing method for ViT based CLIP models that requires no additional training
or assumptions of bias annotations. Our approach uses a pretrained segmentation
model to isolate the target visual attribute, then adjusts the non target
regions so that their embeddings are uniformly similar to all class specific
text prompts. This procedure removes unintended bias signals from confounding
visual regions while preserving the target attribute. Experiments on Waterbirds
and CelebA show that our method outperforms existing test-time debiasing
approaches in both group robustness metrics and Attention IoU. These results
demonstrate the effectiveness of segmentation guided interventions for scalable
and annotation free bias mitigation in vision language models.

</details>


### [62] [Text-guided Fine-Grained Video Anomaly Detection](https://arxiv.org/abs/2511.00524)
*Jihao Gu,Kun Li,He Wang,Kaan Akşit*

Main category: cs.CV

TL;DR: T-VAD是一种基于大型视觉语言模型的细粒度视频异常检测框架，通过像素级视觉-文本特征对齐生成异常热图，显著提升了检测的精细度和交互性。


<details>
  <summary>Details</summary>
Motivation: 现有视频异常检测方法多为半自动化且输出有限，T-VAD旨在通过文本引导实现更精细和交互式的异常检测。

Method: T-VAD结合了异常热图解码器（AHD）和区域感知异常编码器（RAE），通过视觉-文本特征对齐生成热图并转换为可学习的文本嵌入。

Result: 在UBnormal数据集上，T-VAD的AUC达94.8%，热图精度为67.8%/76.7%；在ShanghaiTech和UBnormal数据集上，文本描述质量显著提升。

Conclusion: T-VAD通过文本引导和细粒度热图生成，显著提升了视频异常检测的性能和交互性，达到SOTA水平。

Abstract: Video Anomaly Detection (VAD) aims to identify anomalous events within video
segments. In scenarios such as surveillance or industrial process monitoring,
anomaly detection is of critical importance. While existing approaches are
semi-automated, requiring human assessment for anomaly detection, traditional
VADs offer limited output as either normal or anomalous. We propose Text-guided
Fine-Grained Video Anomaly Detection (T-VAD), a framework built upon Large
Vision-Language Model (LVLM). T-VAD introduces an Anomaly Heatmap Decoder (AHD)
that performs pixel-wise visual-textual feature alignment to generate
fine-grained anomaly heatmaps. Furthermore, we design a Region-aware Anomaly
Encoder (RAE) that transforms the heatmaps into learnable textual embeddings,
guiding the LVLM to accurately identify and localize anomalous events in
videos. This significantly enhances both the granularity and interactivity of
anomaly detection. The proposed method achieving SOTA performance by
demonstrating 94.8% Area Under the Curve (AUC, specifically micro-AUC) and
67.8%/76.7% accuracy in anomaly heatmaps (RBDC/TBDC) on the UBnormal dataset,
and subjectively verified more preferable textual description on the
ShanghaiTech-based dataset (BLEU-4: 62.67 for targets, 88.84 for trajectories;
Yes/No accuracy: 97.67%), and on the UBnormal dataset (BLEU-4: 50.32 for
targets, 78.10 for trajectories; Yes/No accuracy: 89.73%).

</details>


### [63] [Real-IAD Variety: Pushing Industrial Anomaly Detection Dataset to a Modern Era](https://arxiv.org/abs/2511.00540)
*Wenbing Zhu,Chengjie Wang,Bin-Bin Gao,Jiangning Zhang,Guannan Jiang,Jie Hu,Zhenye Gan,Lidong Wang,Ziqing Zhou,Linjie Cheng,Yurui Pan,Bo Peng,Mingmin Chi,Lizhuang Ma*

Main category: cs.CV

TL;DR: Real-IAD Variety是一个大规模、多样化的工业异常检测基准数据集，包含198,960张高分辨率图像，覆盖160个类别，旨在解决现有数据集类别单一和规模不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有工业异常检测数据集类别多样性不足且规模有限，导致模型性能饱和且泛化能力差，无法适应真实工业场景。

Method: 提出Real-IAD Variety数据集，覆盖28个行业、24种材料和22种颜色，并通过实验验证其挑战性。

Result: 实验表明，现有多类无监督异常检测方法在类别扩展时性能显著下降，而视觉语言模型表现出更强的鲁棒性和泛化能力。

Conclusion: Real-IAD Variety为下一代异常检测模型的训练和评估提供了重要资源，有望推动通用异常检测系统的发展。

Abstract: Industrial Anomaly Detection (IAD) is critical for enhancing operational
safety, ensuring product quality, and optimizing manufacturing efficiency
across global industries. However, the IAD algorithms are severely constrained
by the limitations of existing public benchmarks. Current datasets exhibit
restricted category diversity and insufficient scale, frequently resulting in
metric saturation and limited model transferability to real-world scenarios. To
address this gap, we introduce Real-IAD Variety, the largest and most diverse
IAD benchmark, comprising 198,960 high-resolution images across 160 distinct
object categories. Its diversity is ensured through comprehensive coverage of
28 industries, 24 material types, and 22 color variations. Our comprehensive
experimental analysis validates the benchmark's substantial challenge:
state-of-the-art multi-class unsupervised anomaly detection methods experience
significant performance degradation when scaled from 30 to 160 categories.
Crucially, we demonstrate that vision-language models exhibit remarkable
robustness to category scale-up, with minimal performance variation across
different category counts, significantly enhancing generalization capabilities
in diverse industrial contexts. The unprecedented scale and complexity of
Real-IAD Variety position it as an essential resource for training and
evaluating next-generation foundation models for anomaly detection. By
providing this comprehensive benchmark with rigorous evaluation protocols
across multi-class unsupervised, multi-view, and zero-/few-shot settings, we
aim to accelerate research beyond domain-specific constraints, enabling the
development of scalable, general-purpose anomaly detection systems. Real-IAD
Variety will be made publicly available to facilitate innovation in this
critical field.

</details>


### [64] [MIFO: Learning and Synthesizing Multi-Instance from One Image](https://arxiv.org/abs/2511.00542)
*Kailun Su,Ziqi He,Xi Wang,Yang Zhou*

Main category: cs.CV

TL;DR: 提出了一种从单张图像中精确学习和合成多实例语义的方法，通过惩罚注意力优化和框控制解决语义相似性问题。


<details>
  <summary>Details</summary>
Motivation: 解决训练数据有限且实例语义或外观相似时的学习挑战。

Method: 采用惩罚注意力优化分离相似语义，并在合成阶段优化注意力层的框控制以减少语义泄漏。

Result: 实现了高质量、解耦的语义学习和合成，平衡了可编辑性和实例一致性。

Conclusion: 方法在处理语义或视觉相似实例及罕见对象时表现稳健。

Abstract: This paper proposes a method for precise learning and synthesizing
multi-instance semantics from a single image. The difficulty of this problem
lies in the limited training data, and it becomes even more challenging when
the instances to be learned have similar semantics or appearance. To address
this, we propose a penalty-based attention optimization to disentangle similar
semantics during the learning stage. Then, in the synthesis, we introduce and
optimize box control in attention layers to further mitigate semantic leakage
while precisely controlling the output layout. Experimental results demonstrate
that our method achieves disentangled and high-quality semantic learning and
synthesis, strikingly balancing editability and instance consistency. Our
method remains robust when dealing with semantically or visually similar
instances or rare-seen objects. The code is publicly available at
https://github.com/Kareneveve/MIFO

</details>


### [65] [4D Neural Voxel Splatting: Dynamic Scene Rendering with Voxelized Guassian Splatting](https://arxiv.org/abs/2511.00560)
*Chun-Tin Wu,Jun-Cheng Chen*

Main category: cs.CV

TL;DR: 4D-NVS结合体素表示与神经高斯溅射，高效建模动态场景，减少内存消耗并加速训练。


<details>
  <summary>Details</summary>
Motivation: 解决3D-GS在动态场景中因跨帧复制高斯导致的内存开销问题。

Method: 使用神经体素和变形场建模时间动态，避免每帧生成独立高斯集，并引入视角优化阶段。

Result: 显著减少内存和训练时间，保持高质量渲染，支持实时渲染。

Conclusion: 4D-NVS在内存、训练速度和渲染质量上优于现有方法。

Abstract: Although 3D Gaussian Splatting (3D-GS) achieves efficient rendering for novel
view synthesis, extending it to dynamic scenes still results in substantial
memory overhead from replicating Gaussians across frames. To address this
challenge, we propose 4D Neural Voxel Splatting (4D-NVS), which combines
voxel-based representations with neural Gaussian splatting for efficient
dynamic scene modeling. Instead of generating separate Gaussian sets per
timestamp, our method employs a compact set of neural voxels with learned
deformation fields to model temporal dynamics. The design greatly reduces
memory consumption and accelerates training while preserving high image
quality. We further introduce a novel view refinement stage that selectively
improves challenging viewpoints through targeted optimization, maintaining
global efficiency while enhancing rendering quality for difficult viewing
angles. Experiments demonstrate that our method outperforms state-of-the-art
approaches with significant memory reduction and faster training, enabling
real-time rendering with superior visual fidelity.

</details>


### [66] [Generalized Category Discovery under Domain Shift: A Frequency Domain Perspective](https://arxiv.org/abs/2511.00573)
*Wei Feng,Zongyuan Ge*

Main category: cs.CV

TL;DR: 论文提出了一种频率引导的广义类别发现框架（FREE），用于解决分布偏移下的广义类别发现问题（DS_GCD）。


<details>
  <summary>Details</summary>
Motivation: 现有方法在标准条件下表现良好，但在分布偏移时性能下降。论文探索了更现实的任务DS_GCD，其中未标记数据可能来自未知类别和未知域。

Method: 提出频率域信息利用策略，包括基于频率的域分离、跨域和域内扰动策略，以及自监督对比目标和语义聚类损失的扩展。

Result: 实验表明，FREE能有效缓解分布偏移影响，在多个基准数据集上表现优异。

Conclusion: FREE框架通过频率域信息和自适应策略，显著提升了在分布偏移下的类别发现性能。

Abstract: Generalized Category Discovery (GCD) aims to leverage labeled samples from
known categories to cluster unlabeled data that may include both known and
unknown categories. While existing methods have achieved impressive results
under standard conditions, their performance often deteriorates in the presence
of distribution shifts. In this paper, we explore a more realistic task:
Domain-Shifted Generalized Category Discovery (DS\_GCD), where the unlabeled
data includes not only unknown categories but also samples from unknown
domains. To tackle this challenge, we propose a
\textbf{\underline{F}}requency-guided Gene\textbf{\underline{r}}alized
Cat\textbf{\underline{e}}gory Discov\textbf{\underline{e}}ry framework (FREE)
that enhances the model's ability to discover categories under distributional
shift by leveraging frequency-domain information. Specifically, we first
propose a frequency-based domain separation strategy that partitions samples
into known and unknown domains by measuring their amplitude differences. We
then propose two types of frequency-domain perturbation strategies: a
cross-domain strategy, which adapts to new distributions by exchanging
amplitude components across domains, and an intra-domain strategy, which
enhances robustness to intra-domain variations within the unknown domain.
Furthermore, we extend the self-supervised contrastive objective and semantic
clustering loss to better guide the training process. Finally, we introduce a
clustering-difficulty-aware resampling technique to adaptively focus on
harder-to-cluster categories, further enhancing model performance. Extensive
experiments demonstrate that our method effectively mitigates the impact of
distributional shifts across various benchmark datasets and achieves superior
performance in discovering both known and unknown categories.

</details>


### [67] [TRACES: Temporal Recall with Contextual Embeddings for Real-Time Video Anomaly Detection](https://arxiv.org/abs/2511.00580)
*Yousuf Ahmed Siddiqui,Sufiyaan Usmani,Umer Tariq,Jawwad Ahmed Shamsi,Muhammad Burhan Khan*

Main category: cs.CV

TL;DR: 论文提出了一种基于上下文感知的零样本异常检测方法，通过结合时间特征和视觉嵌入，实现实时高精度检测。


<details>
  <summary>Details</summary>
Motivation: 现有异常检测方法缺乏对上下文信息的关注，限制了其在新场景中的泛化能力。

Method: 采用记忆增强的流程，通过交叉注意力关联时间信号与视觉嵌入，并基于上下文相似性评分进行实时分类。

Result: 在UCF-Crime和XD-Violence数据集上分别达到90.4% AUC和83.67% AP，创零样本模型新纪录。

Conclusion: 通过融合交叉注意力时间融合和上下文记忆，实现了高保真异常检测，为零样本模型在现实监控中的应用迈出重要一步。

Abstract: Video anomalies often depend on contextual information available and temporal
evolution. Non-anomalous action in one context can be anomalous in some other
context. Most anomaly detectors, however, do not notice this type of context,
which seriously limits their capability to generalize to new, real-life
situations. Our work addresses the context-aware zero-shot anomaly detection
challenge, in which systems need to learn adaptively to detect new events by
correlating temporal and appearance features with textual traces of memory in
real time. Our approach defines a memory-augmented pipeline, correlating
temporal signals with visual embeddings using cross-attention, and real-time
zero-shot anomaly classification by contextual similarity scoring. We achieve
90.4\% AUC on UCF-Crime and 83.67\% AP on XD-Violence, a new state-of-the-art
among zero-shot models. Our model achieves real-time inference with high
precision and explainability for deployment. We show that, by fusing
cross-attention temporal fusion and contextual memory, we achieve high fidelity
anomaly detection, a step towards the applicability of zero-shot models in
real-world surveillance and infrastructure monitoring.

</details>


### [68] [CueBench: Advancing Unified Understanding of Context-Aware Video Anomalies in Real-World](https://arxiv.org/abs/2511.00613)
*Yating Yu,Congqi Cao,Zhaoying Wang,Weihua Meng,Jie Li,Yuxin Li,Zihao Wei,Zhongpei Shen,Jiajun Zhang*

Main category: cs.CV

TL;DR: CueBench是一个专注于上下文感知视频异常理解的基准测试，通过统一评估框架和事件中心化分类法，揭示了现有视觉语言模型在真实世界异常理解上的不足，而Cue-R1方法显著优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有方法对真实世界异常的理解较为肤浅，缺乏对复杂原理和细微上下文的广泛覆盖，因此需要一种更全面的评估框架。

Method: 提出了CueBench基准测试，包含事件中心化分类法和多种挑战性任务，并开发了基于强化微调的Cue-R1方法。

Result: Cue-R1在CueBench上平均超越现有技术24%，但现有视觉语言模型的表现仍不理想。

Conclusion: CueBench为视频异常理解提供了严格的评估标准，Cue-R1展示了显著的性能提升，但真实世界异常理解仍有改进空间。

Abstract: How far are deep models from real-world video anomaly understanding (VAU)?
Current works typically emphasize on detecting unexpected occurrences deviated
from normal patterns or comprehending anomalous events with interpretable
descriptions. However, they exhibit only a superficial comprehension of
real-world anomalies, with limited breadth in complex principles and subtle
context that distinguish the anomalies from normalities, e.g., climbing cliffs
with safety gear vs. without it. To this end, we introduce CueBench, the first
of its kind Benchmark, devoted to Context-aware video anomalies within a
Unified Evaluation framework. We comprehensively establish an event-centric
hierarchical taxonomy that anchors two core event types: 14 conditional and 18
absolute anomaly events, defined by their refined semantics from diverse
contexts across 174 scenes and 198 attributes. Based on this, we propose to
unify and benchmark context-aware VAU with various challenging tasks across
recognition, temporal grounding, detection, and anticipation. This also serves
as a rigorous and fair probing evaluation suite for generative-discriminative
as well as generalized-specialized vision-language models (VLMs). To address
the challenges underlying CueBench, we further develop Cue-R1 based on R1-style
reinforcement fine-tuning with verifiable, task-aligned, and hierarchy-refined
rewards in a unified generative manner. Extensive results on CueBench reveal
that, existing VLMs are still far from satisfactory real-world anomaly
understanding, while our Cue-R1 surpasses these state-of-the-art approaches by
over 24% on average.

</details>


### [69] [Grounding Surgical Action Triplets with Instrument Instance Segmentation: A Dataset and Target-Aware Fusion Approach](https://arxiv.org/abs/2511.00643)
*Oluwatosin Alabi,Meng Wei,Charlie Budd,Tom Vercauteren,Miaojing Shi*

Main category: cs.CV

TL;DR: 提出了一种新的任务——三元组分割，通过结合器械实例分割和动作三元组识别，实现手术场景中动作的空间定位。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅能进行帧级分类，无法可靠地将动作与具体器械实例关联，且空间定位精度不足。

Method: 提出了TargetFusionNet架构，结合弱解剖先验与器械实例查询，提升目标预测准确性。

Result: 在多个指标上优于基线方法，证明了强实例监督与弱目标先验的有效性。

Conclusion: 三元组分割为手术动作理解提供了统一框架，新基准和架构推动了更可解释的手术场景理解。

Abstract: Understanding surgical instrument-tissue interactions requires not only
identifying which instrument performs which action on which anatomical target,
but also grounding these interactions spatially within the surgical scene.
Existing surgical action triplet recognition methods are limited to learning
from frame-level classification, failing to reliably link actions to specific
instrument instances.Previous attempts at spatial grounding have primarily
relied on class activation maps, which lack the precision and robustness
required for detailed instrument-tissue interaction analysis.To address this
gap, we propose grounding surgical action triplets with instrument instance
segmentation, or triplet segmentation for short, a new unified task which
produces spatially grounded <instrument, verb, target> outputs.We start by
presenting CholecTriplet-Seg, a large-scale dataset containing over 30,000
annotated frames, linking instrument instance masks with action verb and
anatomical target annotations, and establishing the first benchmark for
strongly supervised, instance-level triplet grounding and evaluation.To learn
triplet segmentation, we propose TargetFusionNet, a novel architecture that
extends Mask2Former with a target-aware fusion mechanism to address the
challenge of accurate anatomical target prediction by fusing weak anatomy
priors with instrument instance queries.Evaluated across recognition,
detection, and triplet segmentation metrics, TargetFusionNet consistently
improves performance over existing baselines, demonstrating that strong
instance supervision combined with weak target priors significantly enhances
the accuracy and robustness of surgical action understanding.Triplet
segmentation establishes a unified framework for spatially grounding surgical
action triplets. The proposed benchmark and architecture pave the way for more
interpretable, surgical scene understanding.

</details>


### [70] [Saliency-Guided Domain Adaptation for Left-Hand Driving in Autonomous Steering](https://arxiv.org/abs/2511.01223)
*Zahra Mehraban,Sebastien Glaser,Michael Milford,Ronald Schroeter*

Main category: cs.CV

TL;DR: 该论文研究了通过翻转数据预训练和微调的方法，提升自动驾驶模型在左舵驾驶条件下的适应能力。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶模型需要适应不同道路条件，尤其是左舵和右舵驾驶的差异。

Method: 评估了四种训练方法，包括基线模型、翻转数据预训练、微调等。

Result: 翻转数据预训练后微调显著降低了预测误差，并增强了模型对左舵驾驶特征的关注。

Conclusion: 翻转数据预训练结合微调是提升模型适应性的有效方法。

Abstract: Domain adaptation is required for automated driving models to generalize well
across diverse road conditions. This paper explores a training method for
domain adaptation to adapt PilotNet, an end-to-end deep learning-based model,
for left-hand driving conditions using real-world Australian highway data. Four
training methods were evaluated: (1) a baseline model trained on U.S.
right-hand driving data, (2) a model trained on flipped U.S. data, (3) a model
pretrained on U.S. data and then fine-tuned on Australian highways, and (4) a
model pretrained on flipped U.S. data and then finetuned on Australian
highways. This setup examines whether incorporating flipped data enhances the
model adaptation by providing an initial left-hand driving alignment. The paper
compares model performance regarding steering prediction accuracy and
attention, using saliency-based analysis to measure attention shifts across
significant road regions. Results show that pretraining on flipped data alone
worsens prediction stability due to misaligned feature representations, but
significantly improves adaptation when followed by fine-tuning, leading to
lower prediction error and stronger focus on left-side cues. To validate this
approach across different architectures, the same experiments were done on
ResNet, which confirmed similar adaptation trends. These findings emphasize the
importance of preprocessing techniques, such as flipped-data pretraining,
followed by fine-tuning to improve model adaptation with minimal retraining
requirements.

</details>


### [71] [Benchmarking individual tree segmentation using multispectral airborne laser scanning data: the FGI-EMIT dataset](https://arxiv.org/abs/2511.00653)
*Lassi Ruoppa,Tarmo Hietala,Verneri Seppänen,Josef Taher,Teemu Hakala,Xiaowei Yu,Antero Kukko,Harri Kaartinen,Juha Hyyppä*

Main category: cs.CV

TL;DR: 该研究介绍了首个大规模多光谱LiDAR基准数据集FGI-EMIT，用于个体树木分割（ITS），并比较了传统无监督算法与深度学习方法的性能。


<details>
  <summary>Details</summary>
Motivation: 传统ITS方法依赖几何算法，缺乏大规模基准数据集，且多光谱LiDAR数据有限，但其反射率可能提升ITS精度。

Method: 研究使用FGI-EMIT数据集，评估了四种无监督算法和四种深度学习模型，包括超参数优化和模型训练。

Result: 深度学习模型（如ForestFormer3D）表现显著优于无监督方法（F1-score 73.3% vs. 52.7%），尤其在林下树木分割中优势明显。

Conclusion: 多光谱反射率信息在深度学习中未被充分利用，但单通道反射率可略微提升精度；深度学习方法在低点密度下仍优于传统算法。

Abstract: Individual tree segmentation (ITS) from LiDAR point clouds is fundamental for
applications such as forest inventory, carbon monitoring and biodiversity
assessment. Traditionally, ITS has been achieved with unsupervised
geometry-based algorithms, while more recent advances have shifted toward
supervised deep learning (DL). In the past, progress in method development was
hindered by the lack of large-scale benchmark datasets, and the availability of
novel data formats, particularly multispectral (MS) LiDAR, remains limited to
this day, despite evidence that MS reflectance can improve the accuracy of ITS.
This study introduces FGI-EMIT, the first large-scale MS airborne laser
scanning benchmark dataset for ITS. Captured at wavelengths 532, 905, and 1,550
nm, the dataset consists of 1,561 manually annotated trees, with a particular
focus on small understory trees. Using FGI-EMIT, we comprehensively benchmarked
four conventional unsupervised algorithms and four supervised DL approaches.
Hyperparameters of unsupervised methods were optimized using a Bayesian
approach, while DL models were trained from scratch. Among the unsupervised
methods, Treeiso achieved the highest test set F1-score of 52.7%. The DL
approaches performed significantly better overall, with the best model,
ForestFormer3D, attaining an F1-score of 73.3%. The most significant difference
was observed in understory trees, where ForestFormer3D exceeded Treeiso by 25.9
percentage points. An ablation study demonstrated that current DL-based
approaches generally fail to leverage MS reflectance information when it is
provided as additional input features, although single channel reflectance can
improve accuracy marginally, especially for understory trees. A performance
analysis across point densities further showed that DL methods consistently
remain superior to unsupervised algorithms, even at densities as low as 10
points/m$^2$.

</details>


### [72] [Metadata-Aligned 3D MRI Representations for Contrast Understanding and Quality Control](https://arxiv.org/abs/2511.00681)
*Mehmet Yigit Avci,Pedro Borges,Virginia Fernandez,Paul Wright,Mehmet Yigitsoy,Sebastien Ourselin,Jorge Cardoso*

Main category: cs.CV

TL;DR: MR-CLIP是一个通过学习MRI图像与DICOM参数对齐的框架，解决了MRI数据异质性和标签标准化问题。


<details>
  <summary>Details</summary>
Motivation: MRI数据因扫描仪、协议和机构差异导致异质性，缺乏标准化标签，限制了大规模自动化分析。

Method: MR-CLIP通过将体积图像与DICOM采集参数对齐，学习MRI对比表示。

Result: 生成的嵌入在MRI序列分类中优于监督基线，并能通过图像-元数据距离实现无监督质量控制。

Conclusion: MR-CLIP为跨临床数据集的标签高效MRI分析提供了可扩展的基础。

Abstract: Magnetic Resonance Imaging suffers from substantial data heterogeneity and
the absence of standardized contrast labels across scanners, protocols, and
institutions, which severely limits large-scale automated analysis. A unified
representation of MRI contrast would enable a wide range of downstream
utilities, from automatic sequence recognition to harmonization and quality
control, without relying on manual annotations. To this end, we introduce
MR-CLIP, a metadata-guided framework that learns MRI contrast representations
by aligning volumetric images with their DICOM acquisition parameters. The
resulting embeddings shows distinct clusters of MRI sequences and outperform
supervised 3D baselines under data scarcity in few-shot sequence
classification. Moreover, MR-CLIP enables unsupervised data quality control by
identifying corrupted or inconsistent metadata through image-metadata embedding
distances. By transforming routinely available acquisition metadata into a
supervisory signal, MR-CLIP provides a scalable foundation for label-efficient
MRI analysis across diverse clinical datasets.

</details>


### [73] [EREBUS: End-to-end Robust Event Based Underwater Simulation](https://arxiv.org/abs/2511.01381)
*Hitesh Kyatham,Arjun Suresh,Aadi Palnitkar,Yiannis Aloimonos*

Main category: cs.CV

TL;DR: 提出了一种用于生成水下环境中事件相机合成数据的流程，以训练视觉模型。


<details>
  <summary>Details</summary>
Motivation: 水下环境的光照条件差、动态范围高，传统视觉技术难以适应，事件相机能通过逐帧跟踪变化解决这一问题。

Method: 开发了一个流程，用于生成安装在AUV上的事件相机在水下环境中的合成数据。

Result: 在岩石检测任务中展示了流程的有效性，尤其是在能见度低和悬浮颗粒物多的条件下。

Conclusion: 该方法可推广到其他水下任务，为事件相机在水下视觉模型训练中的应用提供了支持。

Abstract: The underwater domain presents a vast array of challenges for roboticists and
computer vision researchers alike, such as poor lighting conditions and high
dynamic range scenes. In these adverse conditions, traditional vision
techniques struggle to adapt and lead to suboptimal performance. Event-based
cameras present an attractive solution to this problem, mitigating the issues
of traditional cameras by tracking changes in the footage on a frame-by-frame
basis. In this paper, we introduce a pipeline which can be used to generate
realistic synthetic data of an event-based camera mounted to an AUV (Autonomous
Underwater Vehicle) in an underwater environment for training vision models. We
demonstrate the effectiveness of our pipeline using the task of rock detection
with poor visibility and suspended particulate matter, but the approach can be
generalized to other underwater tasks.

</details>


### [74] [Outlier-Aware Post-Training Quantization for Image Super-Resolution](https://arxiv.org/abs/2511.00682)
*Hailing Wang,jianglin Lu,Yitian Zhang,Yun Fu*

Main category: cs.CV

TL;DR: 提出了一种双区域量化策略和敏感性感知微调方法，显著提升了超分辨率网络的量化性能。


<details>
  <summary>Details</summary>
Motivation: 现有PTQ方法因忽略激活异常值影响而性能不佳，研究发现异常值与图像颜色信息相关，直接移除会导致性能下降。

Method: 将激活分为异常值区域和密集区域，分别均匀量化；引入敏感性感知微调，优化高敏感层。

Result: 在多种超分辨率网络和数据集上优于现有PTQ方法，性能接近QAT且加速至少75倍。

Conclusion: 双区域量化和敏感性微调有效平衡了量化性能与效率。

Abstract: Quantization techniques, including quantization-aware training (QAT) and
post-training quantization (PTQ), have become essential for inference
acceleration of image super-resolution (SR) networks. Compared to QAT, PTQ has
garnered significant attention as it eliminates the need for ground truth and
model retraining. However, existing PTQ methods for SR often fail to achieve
satisfactory performance as they overlook the impact of outliers in activation.
Our empirical analysis reveals that these prevalent activation outliers are
strongly correlated with image color information, and directly removing them
leads to significant performance degradation. Motivated by this, we propose a
dual-region quantization strategy that partitions activations into an outlier
region and a dense region, applying uniform quantization to each region
independently to better balance bit-width allocation. Furthermore, we observe
that different network layers exhibit varying sensitivities to quantization,
leading to different levels of performance degradation. To address this, we
introduce sensitivity-aware finetuning that encourages the model to focus more
on highly sensitive layers, further enhancing quantization performance.
Extensive experiments demonstrate that our method outperforms existing PTQ
approaches across various SR networks and datasets, while achieving performance
comparable to QAT methods in most scenarios with at least a 75 speedup.

</details>


### [75] [SE(3)-PoseFlow: Estimating 6D Pose Distributions for Uncertainty-Aware Robotic Manipulation](https://arxiv.org/abs/2511.01501)
*Yufeng Jin,Niklas Funk,Vignesh Prasad,Zechu Li,Mathias Franzius,Jan Peters,Georgia Chalvatzaki*

Main category: cs.CV

TL;DR: 提出了一种基于SE(3)流匹配的概率框架，用于估计6D物体姿态分布，解决了姿态模糊性问题，并在多个数据集上取得了最佳结果。


<details>
  <summary>Details</summary>
Motivation: 物体姿态估计在部分观测、遮挡和对称性情况下存在模糊性，确定性方法无法捕捉多模态分布。

Method: 利用SE(3)流匹配的概率框架，建模完整的姿态分布，并通过样本估计处理不确定性。

Result: 在Real275、YCB-V和LM-O数据集上达到最佳性能，并成功应用于机器人任务。

Conclusion: 该方法有效解决了姿态估计中的模糊性问题，并在实际应用中展示了其优势。

Abstract: Object pose estimation is a fundamental problem in robotics and computer
vision, yet it remains challenging due to partial observability, occlusions,
and object symmetries, which inevitably lead to pose ambiguity and multiple
hypotheses consistent with the same observation. While deterministic deep
networks achieve impressive performance under well-constrained conditions, they
are often overconfident and fail to capture the multi-modality of the
underlying pose distribution. To address these challenges, we propose a novel
probabilistic framework that leverages flow matching on the SE(3) manifold for
estimating 6D object pose distributions. Unlike existing methods that regress a
single deterministic output, our approach models the full pose distribution
with a sample-based estimate and enables reasoning about uncertainty in
ambiguous cases such as symmetric objects or severe occlusions. We achieve
state-of-the-art results on Real275, YCB-V, and LM-O, and demonstrate how our
sample-based pose estimates can be leveraged in downstream robotic manipulation
tasks such as active perception for disambiguating uncertain viewpoints or
guiding grasp synthesis in an uncertainty-aware manner.

</details>


### [76] [Evolve to Inspire: Novelty Search for Diverse Image Generation](https://arxiv.org/abs/2511.00686)
*Alex Inch,Passawis Chaiyapattanaporn,Yuchen Zhu,Yuan Lu,Ting-Wen Ko,Davide Paglieri*

Main category: cs.CV

TL;DR: WANDER是一种基于新颖性搜索的方法，通过自然语言提示生成多样化的图像集，显著提升了现有进化提示优化基准的多样性。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像扩散模型在生成高保真图像时，输出多样性有限，限制了其在探索和构思任务中的应用。现有提示优化技术通常针对美学适应性，不适合创意视觉领域。

Method: WANDER直接操作自然语言提示，利用大型语言模型（LLM）进行语义演化生成多样化图像集，并使用CLIP嵌入量化新颖性。此外，应用发射器引导搜索到提示空间的不同区域。

Result: 实验评估表明，WANDER在多样性指标上显著优于现有的进化提示优化基准。消融研究证实了发射器的有效性。

Conclusion: WANDER通过新颖性搜索和发射器技术，成功解决了文本到图像扩散模型输出多样性不足的问题，为创意视觉任务提供了更丰富的工具。

Abstract: Text-to-image diffusion models, while proficient at generating high-fidelity
im- ages, often suffer from limited output diversity, hindering their
application in exploratory and ideation tasks. Existing prompt optimization
techniques typically target aesthetic fitness or are ill-suited to the creative
visual domain. To address this shortcoming, we introduce WANDER, a novelty
search-based approach to generating diverse sets of images from a single input
prompt. WANDER operates directly on natural language prompts, employing a Large
Language Model (LLM) for semantic evolution of diverse sets of images, and
using CLIP embeddings to quantify novelty. We additionally apply emitters to
guide the search into distinct regions of the prompt space, and demonstrate
that they boost the diversity of the generated images. Empirical evaluations
using FLUX-DEV for generation and GPT-4o-mini for mutation demonstrate that
WANDER significantly outperforms existing evolutionary prompt optimization
baselines in diversity metrics. Ablation studies confirm the efficacy of
emitters.

</details>


### [77] [Discriminately Treating Motion Components Evolves Joint Depth and Ego-Motion Learning](https://arxiv.org/abs/2511.01502)
*Mengtan Zhang,Zizhan Guo,Hongbo Zhao,Yi Feng,Zuyi Xiong,Yue Wang,Shaoyi Du,Hanli Wang,Rui Fan*

Main category: cs.CV

TL;DR: DiMoDE框架通过区分运动组件并利用几何约束，提升了深度和自运动估计的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将自运动作为辅助任务，缺乏对运动组件的区分处理，限制了几何约束的利用，影响了可靠性和鲁棒性。

Method: 提出DiMoDE框架，通过光学轴和平面对齐，量化运动组件的几何约束，并引入互补约束改进深度估计。

Result: 在多个公开数据集和新收集的真实数据集上达到最优性能，尤其在挑战性条件下表现突出。

Conclusion: DiMoDE通过几何约束的区分处理，显著提升了深度和自运动估计的鲁棒性和准确性。

Abstract: Unsupervised learning of depth and ego-motion, two fundamental 3D perception
tasks, has made significant strides in recent years. However, most methods
treat ego-motion as an auxiliary task, either mixing all motion types or
excluding depth-independent rotational motions in supervision. Such designs
limit the incorporation of strong geometric constraints, reducing reliability
and robustness under diverse conditions. This study introduces a discriminative
treatment of motion components, leveraging the geometric regularities of their
respective rigid flows to benefit both depth and ego-motion estimation. Given
consecutive video frames, network outputs first align the optical axes and
imaging planes of the source and target cameras. Optical flows between frames
are transformed through these alignments, and deviations are quantified to
impose geometric constraints individually on each ego-motion component,
enabling more targeted refinement. These alignments further reformulate the
joint learning process into coaxial and coplanar forms, where depth and each
translation component can be mutually derived through closed-form geometric
relationships, introducing complementary constraints that improve depth
robustness. DiMoDE, a general depth and ego-motion joint learning framework
incorporating these designs, achieves state-of-the-art performance on multiple
public datasets and a newly collected diverse real-world dataset, particularly
under challenging conditions. Our source code will be publicly available at
mias.group/DiMoDE upon publication.

</details>


### [78] [Toward Better Optimization of Low-Dose CT Enhancement: A Critical Analysis of Loss Functions and Image Quality Assessment Metrics](https://arxiv.org/abs/2511.00698)
*Taifour Yousra,Beghdadi Azeddine,Marie Luong,Zuheng Ming*

Main category: cs.CV

TL;DR: 论文分析了低剂量CT图像增强中不同损失函数与图像质量指标的一致性，强调了开发新损失函数时需考虑图像质量指标的重要性。


<details>
  <summary>Details</summary>
Motivation: 低剂量CT图像常受噪声和伪影影响，现有深度学习模型虽在PSNR和SSIM上表现优异，但这些指标难以反映感知质量，尤其是医学图像。

Method: 对低剂量CT图像增强中不同损失函数进行客观分析，评估其与图像质量指标的一致性。

Result: 发现损失函数与质量指标之间存在不一致性。

Conclusion: 开发新损失函数时需综合考虑图像质量指标，以提升低剂量CT图像的感知质量。

Abstract: Low-dose CT (LDCT) imaging is widely used to reduce radiation exposure to
mitigate high exposure side effects, but often suffers from noise and artifacts
that affect diagnostic accuracy. To tackle this issue, deep learning models
have been developed to enhance LDCT images. Various loss functions have been
employed, including classical approaches such as Mean Square Error and
adversarial losses, as well as customized loss functions(LFs) designed for
specific architectures. Although these models achieve remarkable performance in
terms of PSNR and SSIM, these metrics are limited in their ability to reflect
perceptual quality, especially for medical images. In this paper, we focus on
one of the most critical elements of DL-based architectures, namely the loss
function. We conduct an objective analysis of the relevance of different loss
functions for LDCT image quality enhancement and their consistency with image
quality metrics. Our findings reveal inconsistencies between LFs and quality
metrics, and highlight the need of consideration of image quality metrics when
developing a new loss function for image quality enhancement.

</details>


### [79] [PixelVLA: Advancing Pixel-level Understanding in Vision-Language-Action Model](https://arxiv.org/abs/2511.01571)
*Wenqi Liang,Gan Sun,Yao He,Jiahua Dong,Suyan Dai,Ivan Laptev,Salman Khan,Yang Cong*

Main category: cs.CV

TL;DR: PixelVLA是一种新型视觉-语言-动作模型，支持像素级推理和多模态提示，显著提升机器人控制性能。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型在像素级场景理解和依赖文本提示方面存在局限，PixelVLA旨在解决这些问题。

Method: 提出基于多尺度像素感知编码器和视觉提示编码器的框架，并开发自动化标注流程生成Pixel-160K数据集。

Result: PixelVLA在三个基准测试中比OpenVLA提升10.1%-17.8%的成功率，且预训练成本仅1.5%。

Conclusion: PixelVLA能更高效、准确地控制机器人，适用于复杂环境，代码和数据集将开源。

Abstract: Vision-Language-Action models (VLAs) are emerging as powerful tools for
learning generalizable visuomotor control policies. However, current VLAs are
mostly trained on large-scale image-text-action data and remain limited in two
key ways: (i) they struggle with pixel-level scene understanding, and (ii) they
rely heavily on textual prompts, which reduces their flexibility in real-world
settings. To address these challenges, we introduce PixelVLA, the first VLA
model designed to support both pixel-level reasoning and multimodal prompting
with text and visual inputs. Our approach is built on a new visuomotor
instruction tuning framework that integrates a multiscale pixel-aware encoder
with a visual prompting encoder. To train PixelVLA effectively, we further
propose a two-stage automated annotation pipeline that generates Pixel-160K, a
large-scale dataset with pixel-level annotations derived from existing robot
data. Experiments on three standard VLA benchmarks and two VLA model variants
show that PixelVLA improves manipulation success rates by 10.1%-17.8% over
OpenVLA, while requiring only 1.5% of its pretraining cost. These results
demonstrate that PixelVLA can be integrated into existing VLAs to enable more
accurate, efficient, and versatile robot control in complex environments. The
dataset and code will be released as open source.

</details>


### [80] [Validating Deep Models for Alzheimer's 18F-FDG PET Diagnosis Across Populations: A Study with Latin American Data](https://arxiv.org/abs/2511.00728)
*Hugo Massaroli,Hernan Chaves,Pilar Anania,Mauricio Farez,Emmanuel Iarussi,Viviana Siless*

Main category: cs.CV

TL;DR: 深度学习模型在阿尔茨海默病诊断中表现优异，但在不同人群中的泛化能力不足。


<details>
  <summary>Details</summary>
Motivation: 研究不同模型在北美和拉丁美洲人群中的泛化性能差异。

Method: 使用卷积和Transformer模型在ADNI数据集上训练，并在FLENI数据集上测试。

Result: 模型在ADNI上表现优异（AUC高达0.96-0.97），但在FLENI上显著下降（AUC降至0.80-0.82）。

Conclusion: 需关注诊断模型的人群泛化能力，未来研究应聚焦领域适应和数据集多样化。

Abstract: Deep learning models have shown strong performance in diagnosing Alzheimer's
disease (AD) using neuroimaging data, particularly 18F-FDG PET scans, with
training datasets largely composed of North American cohorts such as those in
the Alzheimer's Disease Neuroimaging Initiative (ADNI). However, their
generalization to underrepresented populations remains underexplored. In this
study, we benchmark convolutional and Transformer-based models on the ADNI
dataset and assess their generalization performance on a novel Latin American
clinical cohort from the FLENI Institute in Buenos Aires, Argentina. We show
that while all models achieve high AUCs on ADNI (up to .96, .97), their
performance drops substantially on FLENI (down to .82, .80, respectively),
revealing a significant domain shift. The tested architectures demonstrated
similar performance, calling into question the supposed advantages of
transformers for this specific task. Through ablation studies, we identify
per-image normalization and a correct sampling selection as key factors for
generalization. Occlusion sensitivity analysis further reveals that models
trained on ADNI, generally attend to canonical hypometabolic regions for the AD
class, but focus becomes unclear for the other classes and for FLENI scans.
These findings highlight the need for population-aware validation of diagnostic
AI models and motivate future work on domain adaptation and cohort
diversification.

</details>


### [81] [3EED: Ground Everything Everywhere in 3D](https://arxiv.org/abs/2511.01755)
*Rong Li,Yuhao Dong,Tianshuai Hu,Ao Liang,Youquan Liu,Dongyue Lu,Liang Pan,Lingdong Kong,Junwei Liang,Ziwei Liu*

Main category: cs.CV

TL;DR: 3EED是一个多平台、多模态的3D视觉基准数据集，用于语言驱动的3D物体定位，规模远超现有数据集。


<details>
  <summary>Details</summary>
Motivation: 现有基准数据集局限于室内、单一平台和小规模，无法满足开放世界环境中语言驱动的3D物体定位需求。

Method: 结合视觉语言模型提示和人工验证的标注流程，提出平台感知归一化和跨模态对齐技术。

Result: 数据集包含128,000个物体和22,000个验证过的指代表达，性能差距显著，显示泛化3D定位的挑战。

Conclusion: 3EED为语言驱动的3D感知研究提供了新基准和工具，推动未来研究发展。

Abstract: Visual grounding in 3D is the key for embodied agents to localize
language-referred objects in open-world environments. However, existing
benchmarks are limited to indoor focus, single-platform constraints, and small
scale. We introduce 3EED, a multi-platform, multi-modal 3D grounding benchmark
featuring RGB and LiDAR data from vehicle, drone, and quadruped platforms. We
provide over 128,000 objects and 22,000 validated referring expressions across
diverse outdoor scenes -- 10x larger than existing datasets. We develop a
scalable annotation pipeline combining vision-language model prompting with
human verification to ensure high-quality spatial grounding. To support
cross-platform learning, we propose platform-aware normalization and
cross-modal alignment techniques, and establish benchmark protocols for
in-domain and cross-platform evaluations. Our findings reveal significant
performance gaps, highlighting the challenges and opportunities of
generalizable 3D grounding. The 3EED dataset and benchmark toolkit are released
to advance future research in language-driven 3D embodied perception.

</details>


### [82] [Towards classification-based representation learning for place recognition on LiDAR scans](https://arxiv.org/abs/2511.00738)
*Dmitrii Khizbullin,Maksim Konoplia*

Main category: cs.CV

TL;DR: 将地点识别任务重新定义为多类别分类问题，通过直接分类LiDAR扫描的位置，提出了一种替代对比学习的方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖对比学习，但存在训练效率和稳定性问题，因此探索一种更高效稳定的替代方案。

Method: 为LiDAR扫描分配离散位置标签，并训练编码器-解码器模型直接分类位置。

Result: 在NuScenes数据集上验证，性能与对比学习方法相当，同时训练效率和稳定性更优。

Conclusion: 多类别分类方法在地点识别任务中具有竞争力，且训练效率和稳定性更佳。

Abstract: Place recognition is a crucial task in autonomous driving, allowing vehicles
to determine their position using sensor data. While most existing methods rely
on contrastive learning, we explore an alternative approach by framing place
recognition as a multi-class classification problem. Our method assigns
discrete location labels to LiDAR scans and trains an encoder-decoder model to
classify each scan's position directly. We evaluate this approach on the
NuScenes dataset and show that it achieves competitive performance compared to
contrastive learning-based methods while offering advantages in training
efficiency and stability.

</details>


### [83] [Erasing 'Ugly' from the Internet: Propagation of the Beauty Myth in Text-Image Models](https://arxiv.org/abs/2511.00749)
*Tanvi Dinkar,Aiqi Jiang,Gavin Abercrombie,Ioannis Konstas*

Main category: cs.CV

TL;DR: 研究生成式AI模型如何编码‘美’并消除‘丑’，揭示其对社会的潜在影响。


<details>
  <summary>Details</summary>
Motivation: 社交媒体加剧了西方审美标准的推广，导致负面自我形象和身体畸形等问题。生成式AI可能进一步夸大这些标准，因此需要研究其影响。

Method: 构建两种图像生成流程（文本到图像和文本到语言到图像），使用结构化审美分类法生成5984张图像，并通过Likert量表让参与者评估1200张图像。

Result: 86.5%的图像描绘浅肤色人群，22%包含不适合工作场所的内容，74%被评為年轻化。非二元性别个体图像更年轻化和性化。负面审美提示导致更高NSFW评分。

Conclusion: 生成式AI模型存在与审美标准相关的普遍人口偏见，可能污染数据流并消除不符合开发者审美标准的特征。

Abstract: Social media has exacerbated the promotion of Western beauty norms, leading
to negative self-image, particularly in women and girls, and causing harm such
as body dysmorphia. Increasingly content on the internet has been artificially
generated, leading to concerns that these norms are being exaggerated. The aim
of this work is to study how generative AI models may encode 'beauty' and erase
'ugliness', and discuss the implications of this for society. To investigate
these aims, we create two image generation pipelines: a text-to-image model and
a text-to-language model-to image model. We develop a structured beauty
taxonomy which we use to prompt three language models (LMs) and two
text-to-image models to cumulatively generate 5984 images using our two
pipelines. We then recruit women and non-binary social media users to evaluate
1200 of the images through a Likert-scale within-subjects study. Participants
show high agreement in their ratings. Our results show that 86.5% of generated
images depicted people with lighter skin tones, 22% contained explicit content
despite Safe for Work (SFW) training, and 74% were rated as being in a younger
age demographic. In particular, the images of non-binary individuals were rated
as both younger and more hypersexualised, indicating troubling intersectional
effects. Notably, prompts encoded with 'negative' or 'ugly' beauty traits (such
as "a wide nose") consistently produced higher Not SFW (NSFW) ratings
regardless of gender. This work sheds light on the pervasive demographic biases
related to beauty standards present in generative AI models -- biases that are
actively perpetuated by model developers, such as via negative prompting. We
conclude by discussing the implications of this on society, which include
pollution of the data streams and active erasure of features that do not fall
inside the stereotype of what is considered beautiful by developers.

</details>


### [84] [A Hybrid YOLOv5-SSD IoT-Based Animal Detection System for Durian Plantation Protection](https://arxiv.org/abs/2511.00777)
*Anis Suttan Shahrir,Zakiah Ayop,Syarulnaziah Anawar,Norulzahrah Mohd Zainudin*

Main category: cs.CV

TL;DR: 提出了一种结合YOLOv5和SSD算法的物联网动物检测系统，用于榴莲种植园，提高检测准确性并提供实时通知和威慑机制。


<details>
  <summary>Details</summary>
Motivation: 榴莲种植园常受动物入侵，传统方法缺乏有效监控，现有系统依赖单一算法且通知和威慑机制不足。

Method: 集成YOLOv5和SSD算法，通过物联网实现实时监测，检测到入侵时通过Telegram通知农民并触发声音威慑。

Result: 系统对大象、野猪和猴子的检测准确率分别为90%、85%和70%，白天效果最佳。

Conclusion: 研究提供了一个结合检测、通知和威慑的实用框架，为自动化农业解决方案的未来创新铺平了道路。

Abstract: Durian plantation suffers from animal intrusions that cause crop damage and
financial loss. The traditional farming practices prove ineffective due to the
unavailability of monitoring without human intervention. The fast growth of
machine learning and Internet of Things (IoT) technology has led to new ways to
detect animals. However, current systems are limited by dependence on single
object detection algorithms, less accessible notification platforms, and
limited deterrent mechanisms. This research suggests an IoT-enabled animal
detection system for durian crops. The system integrates YOLOv5 and SSD object
detection algorithms to improve detection accuracy. The system provides
real-time monitoring, with detected intrusions automatically reported to
farmers via Telegram notifications for rapid response. An automated sound
mechanism (e.g., tiger roar) is triggered once the animal is detected. The
YOLO+SSD model achieved accuracy rates of elephant, boar, and monkey at 90%,
85% and 70%, respectively. The system shows the highest accuracy in daytime and
decreases at night, regardless of whether the image is still or a video.
Overall, this study contributes a comprehensive and practical framework that
combines detection, notification, and deterrence, paving the way for future
innovations in automated farming solutions.

</details>


### [85] [Class-agnostic 3D Segmentation by Granularity-Consistent Automatic 2D Mask Tracking](https://arxiv.org/abs/2511.00785)
*Juan Wang,Yasutomo Kawanishi,Tomo Miyazaki,Zhijie Wang,Shinichiro Omachi*

Main category: cs.CV

TL;DR: 提出了一种粒度一致的自动2D掩码跟踪方法，结合三阶段课程学习框架，生成一致且准确的3D分割结果。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过将2D掩码从基础模型转移到3D生成伪标签，但由于视频帧独立处理，导致分割粒度不一致和伪标签冲突，影响最终分割精度。

Method: 引入粒度一致的自动2D掩码跟踪方法，保持帧间时间一致性；结合三阶段课程学习框架，从单视图数据逐步训练到多视图标注。

Result: 实验结果表明，该方法能生成一致且准确的3D分割，并在标准基准测试中达到最先进水平，同时具备开放词汇能力。

Conclusion: 通过结构化学习流程，能够从初始碎片化和矛盾的2D先验中稳健地提取一致的3D表示。

Abstract: 3D instance segmentation is an important task for real-world applications. To
avoid costly manual annotations, existing methods have explored generating
pseudo labels by transferring 2D masks from foundation models to 3D. However,
this approach is often suboptimal since the video frames are processed
independently. This causes inconsistent segmentation granularity and
conflicting 3D pseudo labels, which degrades the accuracy of final
segmentation. To address this, we introduce a Granularity-Consistent automatic
2D Mask Tracking approach that maintains temporal correspondences across
frames, eliminating conflicting pseudo labels. Combined with a three-stage
curriculum learning framework, our approach progressively trains from
fragmented single-view data to unified multi-view annotations, ultimately
globally coherent full-scene supervision. This structured learning pipeline
enables the model to progressively expose to pseudo-labels of increasing
consistency. Thus, we can robustly distill a consistent 3D representation from
initially fragmented and contradictory 2D priors. Experimental results
demonstrated that our method effectively generated consistent and accurate 3D
segmentations. Furthermore, the proposed method achieved state-of-the-art
results on standard benchmarks and open-vocabulary ability.

</details>


### [86] [FedOnco-Bench: A Reproducible Benchmark for Privacy-Aware Federated Tumor Segmentation with Synthetic CT Data](https://arxiv.org/abs/2511.00795)
*Viswa Chaitanya Marella,Suhasnadh Reddy Veluru,Sai Teja Erukude*

Main category: cs.CV

TL;DR: FedOnco-Bench是一个用于隐私保护联邦学习的基准测试平台，评估了多种FL方法在医学图像分割中的性能与隐私泄漏问题。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在隐私敏感环境中具有重要应用，但存在成员推断攻击和数据异构性问题，需要标准化评估平台。

Method: 使用合成肿瘤CT扫描数据，评估FedAvg、FedProx、FedBN和带DP-SGD的FedAvg等方法。

Result: FedAvg性能高但隐私泄漏多，DP-SGD隐私保护强但性能下降，FedProx和FedBN在异构数据中表现平衡。

Conclusion: FedOnco-Bench为医学图像分割的隐私保护FL方法提供了标准化开源基准平台。

Abstract: Federated Learning (FL) allows multiple institutions to cooperatively train
machine learning models while retaining sensitive data at the source, which has
great utility in privacy-sensitive environments. However, FL systems remain
vulnerable to membership-inference attacks and data heterogeneity. This paper
presents FedOnco-Bench, a reproducible benchmark for privacy-aware FL using
synthetic oncologic CT scans with tumor annotations. It evaluates segmentation
performance and privacy leakage across FL methods: FedAvg, FedProx, FedBN, and
FedAvg with DP-SGD. Results show a distinct trade-off between privacy and
utility: FedAvg is high performance (Dice around 0.85) with more privacy
leakage (attack AUC about 0.72), while DP-SGD provides a higher level of
privacy (AUC around 0.25) at the cost of accuracy (Dice about 0.79). FedProx
and FedBN offer balanced performance under heterogeneous data, especially with
non-identical distributed client data. FedOnco-Bench serves as a standardized,
open-source platform for benchmarking and developing privacy-preserving FL
methods for medical image segmentation.

</details>


### [87] [Med-Banana-50K: A Cross-modality Large-Scale Dataset for Text-guided Medical Image Editing](https://arxiv.org/abs/2511.00801)
*Zhihui Chen,Mengling Feng*

Main category: cs.CV

TL;DR: Med-Banana-50K是一个大规模、高质量的医学图像编辑数据集，支持指令驱动的编辑任务，并通过严格的医学质量控制确保数据可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前医学图像编辑研究缺乏大规模、高质量且开放的数据集，限制了研究进展。

Method: 利用Gemini-2.5-Flash-Image生成双向编辑（病变添加和移除），并通过LLM-as-Judge和迭代细化进行质量控制。

Result: 构建了包含50K图像的数据集，涵盖3种模态和23种疾病类型，并包含37K失败尝试用于偏好学习。

Conclusion: Med-Banana-50K为医学图像编辑模型的训练和评估提供了基础资源，推动了该领域的发展。

Abstract: Recent advances in multimodal large language models have enabled remarkable
medical image editing capabilities. However, the research community's progress
remains constrained by the absence of large-scale, high-quality, and openly
accessible datasets built specifically for medical image editing with strict
anatomical and clinical constraints. We introduce Med-Banana-50K, a
comprehensive 50K-image dataset for instruction-based medical image editing
spanning three modalities (chest X-ray, brain MRI, fundus photography) and 23
disease types. Our dataset is constructed by leveraging Gemini-2.5-Flash-Image
to generate bidirectional edits (lesion addition and removal) from real medical
images. What distinguishes Med-Banana-50K from general-domain editing datasets
is our systematic approach to medical quality control: we employ LLM-as-Judge
with a medically grounded rubric (instruction compliance, structural
plausibility, realism, and fidelity preservation) and history-aware iterative
refinement up to five rounds. Beyond single-turn editing, Med-Banana-50K
includes 37K failed attempts with full conversation logs for preference
learning and alignment research. By providing this large-scale, medically
validated, and fully documented resource, Med-Banana-50K establishes a
foundation for training and evaluating the next generation of medical image
editing models.Our dataset and code are publicly available at
[https://github.com/richardChenzhihui/med-banana-50k].

</details>


### [88] [GUI-AIMA: Aligning Intrinsic Multimodal Attention with a Context Anchor for GUI Grounding](https://arxiv.org/abs/2511.00810)
*Shijie Zhou,Viet Dac Lai,Hao Tan,Jihyung Kil,Wanrong Zhu,Changyou Chen,Ruiyi Zhang*

Main category: cs.CV

TL;DR: GUI-AIMA是一个基于注意力机制的无坐标监督微调框架，用于高效实现图形用户界面（GUI）的定位任务。


<details>
  <summary>Details</summary>
Motivation: 现有基于多模态大语言模型（MLLMs）的方法直接生成精确坐标计算量大且效果有限，因此提出一种更直观的基于注意力机制的解决方案。

Method: 通过多模态注意力对齐和自适应计算补丁级定位信号，结合无坐标方式实现高效定位。

Result: GUI-AIMA-3B仅需85k张截图训练，在ScreenSpot-Pro和OSWorld-G数据集上分别达到58.6%和62.2%的平均准确率。

Conclusion: GUI-AIMA验证了轻量训练可以触发MLLMs的固有定位能力，并在小规模模型上实现最优性能。

Abstract: Graphical user interface (GUI) grounding is a key function of computer-use
agents, which maps natural-language instructions to actionable screen regions.
Existing approaches based on Multimodal Large Language Models (MLLMs) typically
formulate it as a text-based coordinate generation task, yet directly
generating precise coordinates from visual inputs remains challenging and
computationally intensive. An intuitive way to implement GUI grounding is to
first select visual patches relevant to the instructions and then determine the
precise click location within those patches. Based on the observations that
general MLLMs have some native grounding capability, nested within their
attentions, we propose GUI-AIMA, an attention-based and coordinate-free
supervised fine-tuning framework for efficient GUI grounding. GUI-AIMA aligns
the intrinsic multimodal attention of MLLMs with patch-wise grounding signals.
These signals are calculated adaptively for diverse user instructions by
multi-head aggregation on simplified query-visual attention matrices. Besides,
its coordinate-free manner can easily integrate a plug-and-play zoom-in stage.
GUI-AIMA-3B was trained with only 85k screenshots, demonstrating exceptional
data efficiency and verifying that light training can trigger the native
grounding capability of MLLMs. It achieves state-of-the-art performance among
3B models, attaining an average accuracy of 58.6% on ScreenSpot-Pro and 62.2%
on OSWorld-G. Project page: https://github.com/sjz5202/GUI-AIMA

</details>


### [89] [TA-LSDiff:Topology-Aware Diffusion Guided by a Level Set Energy for Pancreas Segmentation](https://arxiv.org/abs/2511.00815)
*Yue Gou,Fanghui Song,Yuming Xing,Shengzhu Shi,Zhichang Guo,Boying Wu*

Main category: cs.CV

TL;DR: 提出了一种结合拓扑感知扩散概率模型和水平集能量的新方法TA-LSDiff，用于胰腺分割，无需显式几何演化。


<details>
  <summary>Details</summary>
Motivation: 胰腺分割在医学图像处理中具有挑战性，传统方法忽略拓扑效应，而深度学习方法牺牲结构细节。

Method: 结合拓扑感知扩散概率模型和水平集能量，通过四个互补项引导隐式曲线演化，并引入像素自适应细化模块增强边界精度。

Result: 在四个公共胰腺数据集上实现了最先进的准确率，优于现有方法。

Conclusion: TA-LSDiff是一种实用且准确的胰腺分割解决方案。

Abstract: Pancreas segmentation in medical image processing is a persistent challenge
due to its small size, low contrast against adjacent tissues, and significant
topological variations. Traditional level set methods drive boundary evolution
using gradient flows, often ignoring pointwise topological effects. Conversely,
deep learning-based segmentation networks extract rich semantic features but
frequently sacrifice structural details. To bridge this gap, we propose a novel
model named TA-LSDiff, which combined topology-aware diffusion probabilistic
model and level set energy, achieving segmentation without explicit geometric
evolution. This energy function guides implicit curve evolution by integrating
the input image and deep features through four complementary terms. To further
enhance boundary precision, we introduce a pixel-adaptive refinement module
that locally modulates the energy function using affinity weighting from
neighboring evidence. Ablation studies systematically quantify the contribution
of each proposed component. Evaluations on four public pancreas datasets
demonstrate that TA-LSDiff achieves state-of-the-art accuracy, outperforming
existing methods. These results establish TA-LSDiff as a practical and accurate
solution for pancreas segmentation.

</details>


### [90] [OMEGA: Optimized Multimodal Position Encoding Index Derivation with Global Adaptive Scaling for Vision-Language Models](https://arxiv.org/abs/2511.00821)
*Ruoxiang Huang,Xindian Ma,Rundong Kong,Zhen Yuan,Peng Zhang*

Main category: cs.CV

TL;DR: OMEGA提出了一种新的位置编码框架，通过模态特定的位置编码和全局自适应步长缩放，提升了视觉语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型的位置编码策略未考虑文本和视觉模态的结构差异，导致性能受限。

Method: OMEGA采用模态特定的位置编码（MSPE）和全局自适应步长缩放（GAESS）来优化位置编码。

Result: 实验显示OMEGA在多种架构和VQA基准上均提升了性能，视觉密集型任务上最高提升3.43%。

Conclusion: OMEGA通过模态特定的位置编码和自适应步长缩放，显著提升了视觉语言模型的性能。

Abstract: Vision-Language Models (VLMs) have demonstrated strong performance across
various multimodal tasks, where position encoding plays a vital role in
modeling both the sequential structure of textual information and the spatial
structure of visual information. However, current VLMs commonly adopt
modality-unified 1D or 2D positional indexing strategies, which treat textual
and visual tokens uniformly without accounting for their distinct structural
properties and sequential continuity for text and spatial coherence for vision.
To address this limitation, we propose OMEGA, a novel position encoding
framework that employs Modality-Specific Position Encoding (MSPE) to assign
positional indices while preserving the inherent structures of each modality
across separate coordinate dimensions. Additionally, to align the information
density of multimodal data in the positional index space, OMEGA introduces
Global Adaptive Encoding Step Scaling (GAESS), which adaptively adjusts the
position encoding step size of visual tokens based on the embedding entropy of
both modalities. Experimental results demonstrate that OMEGA consistently
enhances VLM performance across diverse architectures and VQA benchmarks. On
visual-intensive tasks, OMEGA achieves up to 3.43% improvement over baseline
position encoding strategies on Qwen2.5-VL-3B, with consistent gains observed
across larger models including Qwen2.5-VL-7B and LLaVA-v1.5-7B.

</details>


### [91] [Enhancing Adversarial Transferability in Visual-Language Pre-training Models via Local Shuffle and Sample-based Attack](https://arxiv.org/abs/2511.00831)
*Xin Liu,Aoyang Zhou,Aoyang Zhou*

Main category: cs.CV

TL;DR: 提出了一种新的攻击方法LSSA，通过局部图像块随机洗牌和采样，提升多模态对抗样本的迁移性。


<details>
  <summary>Details</summary>
Motivation: 现有方法因过度依赖单模态信息导致过拟合，影响对抗样本的迁移性。

Method: LSSA通过随机洗牌局部图像块并采样，生成对抗图像和文本。

Result: 实验表明LSSA显著提升对抗样本的迁移性，并在大型视觉语言模型中表现优异。

Conclusion: LSSA有效解决了多模态对抗样本的过拟合问题，提升了迁移性能。

Abstract: Visual-Language Pre-training (VLP) models have achieved significant
performance across various downstream tasks. However, they remain vulnerable to
adversarial examples. While prior efforts focus on improving the adversarial
transferability of multimodal adversarial examples through cross-modal
interactions, these approaches suffer from overfitting issues, due to a lack of
input diversity by relying excessively on information from adversarial examples
in one modality when crafting attacks in another. To address this issue, we
draw inspiration from strategies in some adversarial training methods and
propose a novel attack called Local Shuffle and Sample-based Attack (LSSA).
LSSA randomly shuffles one of the local image blocks, thus expanding the
original image-text pairs, generating adversarial images, and sampling around
them. Then, it utilizes both the original and sampled images to generate the
adversarial texts. Extensive experiments on multiple models and datasets
demonstrate that LSSA significantly enhances the transferability of multimodal
adversarial examples across diverse VLP models and downstream tasks. Moreover,
LSSA outperforms other advanced attacks on Large Vision-Language Models.

</details>


### [92] [Linear Differential Vision Transformer: Learning Visual Contrasts via Pairwise Differentials](https://arxiv.org/abs/2511.00833)
*Yifan Pu,Jixuan Ying,Qixiu Li,Tianzhu Ye,Dongchen Han,Xiaochen Wang,Ziyi Wang,Xinyu Shao,Gao Huang,Xiu Li*

Main category: cs.CV

TL;DR: VCA是一种替代MHSA的注意力机制，通过视觉对比降低计算复杂度并提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统ViT的MHSA层计算复杂度高且包含冗余信息，VCA旨在解决这一问题。

Method: VCA通过空间池化提取视觉对比令牌，并分为正负流进行差分交互。

Result: 在DeiT-Tiny上ImageNet-1K准确率提升3.4%，生成任务FID降低2.1-5.2。

Conclusion: VCA为ViT提供了一种更高效且性能更强的解决方案。

Abstract: Vision Transformers (ViTs) have become a universal backbone for both image
recognition and image generation. Yet their Multi-Head Self-Attention (MHSA)
layer still performs a quadratic query-key interaction for every token pair,
spending the bulk of computation on visually weak or redundant correlations. We
introduce Visual-Contrast Attention (VCA), a drop-in replacement for MHSA that
injects an explicit notion of discrimination while reducing the theoretical
complexity from O(N N C) to O(N n C) with n << N. VCA first distils each head's
dense query field into a handful of spatially pooled visual-contrast tokens,
then splits them into a learnable positive and negative stream whose
differential interaction highlights what truly separates one region from
another. The module adds fewer than 0.3M parameters to a DeiT-Tiny backbone,
requires no extra FLOPs, and is wholly architecture-agnostic. Empirically, VCA
lifts DeiT-Tiny top-1 accuracy on ImageNet-1K from 72.2% to 75.6% (+3.4) and
improves three strong hierarchical ViTs by up to 3.1%, while in
class-conditional ImageNet generation it lowers FID-50K by 2.1 to 5.2 points
across both diffusion (DiT) and flow (SiT) models. Extensive ablations confirm
that (i) spatial pooling supplies low-variance global cues, (ii) dual
positional embeddings are indispensable for contrastive reasoning, and (iii)
combining the two in both stages yields the strongest synergy. VCA therefore
offers a simple path towards faster and sharper Vision Transformers. The source
code is available at https://github.com/LeapLabTHU/LinearDiff.

</details>


### [93] [Parameter Interpolation Adversarial Training for Robust Image Classification](https://arxiv.org/abs/2511.00836)
*Xin Liu,Yichen Yang,Kun He,John E. Hopcroft*

Main category: cs.CV

TL;DR: 提出了一种名为PIAT的新框架，通过参数插值缓解对抗训练中的振荡和过拟合问题，提升模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有对抗训练方法存在模型鲁棒性振荡和过拟合问题，影响防御效果。

Method: PIAT通过插值前后两个epoch的模型参数，使决策边界变化更平缓，并引入NMSE对齐干净和对抗样本的logits相对大小。

Result: 在多个基准数据集上显著提升了CNN和ViT的鲁棒性。

Conclusion: PIAT有效解决了对抗训练中的问题，提升了模型鲁棒性。

Abstract: Though deep neural networks exhibit superior performance on various tasks,
they are still plagued by adversarial examples. Adversarial training has been
demonstrated to be the most effective method to defend against adversarial
attacks. However, existing adversarial training methods show that the model
robustness has apparent oscillations and overfitting issues in the training
process, degrading the defense efficacy. To address these issues, we propose a
novel framework called Parameter Interpolation Adversarial Training (PIAT).
PIAT tunes the model parameters between each epoch by interpolating the
parameters of the previous and current epochs. It makes the decision boundary
of model change more moderate and alleviates the overfitting issue, helping the
model converge better and achieving higher model robustness. In addition, we
suggest using the Normalized Mean Square Error (NMSE) to further improve the
robustness by aligning the relative magnitude of logits between clean and
adversarial examples rather than the absolute magnitude. Extensive experiments
conducted on several benchmark datasets demonstrate that our framework could
prominently improve the robustness of both Convolutional Neural Networks (CNNs)
and Vision Transformers (ViTs).

</details>


### [94] [OmniBrainBench: A Comprehensive Multimodal Benchmark for Brain Imaging Analysis Across Multi-stage Clinical Tasks](https://arxiv.org/abs/2511.00846)
*Zhihao Peng,Cheng Wang,Shengyuan Liu,Zhiying Liang,Yixuan Yuan*

Main category: cs.CV

TL;DR: OmniBrainBench是一个全面的多模态VQA基准，用于评估MLLMs在脑成像分析中的能力，揭示了现有模型与临床专家之间的差距。


<details>
  <summary>Details</summary>
Motivation: 当前脑成像VQA基准覆盖模态少或描述粗粒度，无法全面评估MLLMs在临床流程中的表现。

Method: 引入OmniBrainBench，包含15种脑成像模态和9,527个VQA对，模拟临床工作流并涵盖15个多阶段任务。

Result: 评估24个先进模型显示：专有MLLMs表现最佳但仍落后于医生；开源模型在特定任务中表现优异；MLLMs在复杂术前任务中表现不佳。

Conclusion: OmniBrainBench为脑成像分析中的MLLMs评估设定了新标准，揭示了与临床推理的差距。

Abstract: Brain imaging analysis is vital for diagnosing and treating brain disorders,
and multimodal large language models (MLLMs) are increasingly assisting in that
analysis. However, current brain-oriented visual question-answering (VQA)
benchmarks either cover a few imaging modalities or are limited to
coarse-grained pathological descriptions, hindering a comprehensive assessment
of MLLMs throughout the full clinical continuum. To address these, we introduce
OmniBrainBench, the first comprehensive multimodal VQA benchmark specifically
designed to assess the multimodal comprehension capabilities of MLLMs in brain
imaging analysis.OmniBrainBench consists of 15 distinct brain imaging
modalities collected from 30 verified medical sources, yielding 9,527 validated
VQA pairs and 31,706 images. It simulates clinical workflows and encompasses 15
multi-stage clinical tasks rigorously validated by a professional radiologist.
Evaluation of 24 state-of-the-art models, including open-source, medical, and
proprietary MLLMs, highlights the substantial challenges posed by
OmniBrainBench. Our experiments reveal: (1) proprietary MLLMs (e.g., GPT-5)
beat open-source and medical models but lag physicians; (2) medical MLLMs vary
widely in performance; (3) open-source MLLMs trail overall but excel in
specific tasks; (4) MLLMs underperform sharply in complex preoperative tasks,
revealing a visual-to-clinical reasoning gap. OmniBrainBench sets a new
standard for evaluating and advancing MLLMs in brain imaging analysis,
highlighting gaps compared to expert clinical reasoning. We release it at
benchmark \& code.

</details>


### [95] [Occlusion-Aware Diffusion Model for Pedestrian Intention Prediction](https://arxiv.org/abs/2511.00858)
*Yu Liu,Zhijie Liu,Zedong Yang,You-Fu Li,He Kong*

Main category: cs.CV

TL;DR: 提出了一种遮挡感知扩散模型（ODM），用于预测行人在遮挡场景下的过街意图，通过重建遮挡运动模式并利用其指导未来意图预测。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在预测行人过街意图时，很少考虑遮挡场景下的不完全观察问题。

Method: 采用遮挡感知扩散变换器架构，在去噪阶段估计与遮挡模式相关的噪声特征，并引入遮挡掩码引导的反向过程以减少预测误差。

Result: 在PIE和JAAD基准测试中，ODM比现有方法表现更稳健。

Conclusion: ODM能有效提升遮挡场景下的行人意图预测准确性。

Abstract: Predicting pedestrian crossing intentions is crucial for the navigation of
mobile robots and intelligent vehicles. Although recent deep learning-based
models have shown significant success in forecasting intentions, few consider
incomplete observation under occlusion scenarios. To tackle this challenge, we
propose an Occlusion-Aware Diffusion Model (ODM) that reconstructs occluded
motion patterns and leverages them to guide future intention prediction. During
the denoising stage, we introduce an occlusion-aware diffusion transformer
architecture to estimate noise features associated with occluded patterns,
thereby enhancing the model's ability to capture contextual relationships in
occluded semantic scenarios. Furthermore, an occlusion mask-guided reverse
process is introduced to effectively utilize observation information, reducing
the accumulation of prediction errors and enhancing the accuracy of
reconstructed motion features. The performance of the proposed method under
various occlusion scenarios is comprehensively evaluated and compared with
existing methods on popular benchmarks, namely PIE and JAAD. Extensive
experimental results demonstrate that the proposed method achieves more robust
performance than existing methods in the literature.

</details>


### [96] [Layer-Wise Modality Decomposition for Interpretable Multimodal Sensor Fusion](https://arxiv.org/abs/2511.00859)
*Jaehyun Park,Konyul Park,Daehun Kim,Junseo Park,Jun Won Choi*

Main category: cs.CV

TL;DR: 论文提出了一种名为LMD的后处理方法，用于解释多传感器融合模型中的模态贡献。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶中，感知模型的决策透明度至关重要，但多传感器输入导致模态贡献难以确定。

Method: LMD是一种模型无关的层间模态分解方法，用于解耦预训练融合模型中各层的模态信息。

Result: LMD在多种传感器组合（如相机-雷达、相机-LiDAR等）下验证了其有效性，并通过结构扰动指标和可视化分解展示了实用性。

Conclusion: LMD是首个能够为自动驾驶多传感器融合模型提供模态贡献解释的方法，具有实际应用价值。

Abstract: In autonomous driving, transparency in the decision-making of perception
models is critical, as even a single misperception can be catastrophic. Yet
with multi-sensor inputs, it is difficult to determine how each modality
contributes to a prediction because sensor information becomes entangled within
the fusion network. We introduce Layer-Wise Modality Decomposition (LMD), a
post-hoc, model-agnostic interpretability method that disentangles
modality-specific information across all layers of a pretrained fusion model.
To our knowledge, LMD is the first approach to attribute the predictions of a
perception model to individual input modalities in a sensor-fusion system for
autonomous driving. We evaluate LMD on pretrained fusion models under
camera-radar, camera-LiDAR, and camera-radar-LiDAR settings for autonomous
driving. Its effectiveness is validated using structured perturbation-based
metrics and modality-wise visual decompositions, demonstrating practical
applicability to interpreting high-capacity multimodal architectures. Code is
available at https://github.com/detxter-jvb/Layer-Wise-Modality-Decomposition.

</details>


### [97] [GraphGeo: Multi-Agent Debate Framework for Visual Geo-localization with Heterogeneous Graph Neural Networks](https://arxiv.org/abs/2511.00908)
*Heng Zheng,Yuling Shi,Xiaodong Gu,Haochen You,Zijian Zhang,Lubin Gan,Hao Zhang,Wenjun Huang,Jin Huang*

Main category: cs.CV

TL;DR: GraphGeo是一个基于异构图神经网络的多智能体辩论框架，用于视觉地理定位，通过结构化辩论提升定位准确性。


<details>
  <summary>Details</summary>
Motivation: 传统检索方法受限于数据库覆盖和质量，而现有大型视觉语言模型在多样地理区域和复杂场景中表现不佳。多智能体系统虽通过协作提升性能，但缺乏有效处理冲突预测的机制。

Method: GraphGeo通过类型化边建模多样辩论关系（支持协作、竞争论证、知识转移），引入双级辩论机制（节点级细化和边级论证建模）和跨级拓扑优化策略。

Result: 在多个基准测试中，GraphGeo显著优于现有最先进方法。

Conclusion: GraphGeo通过结构化辩论将智能体间的认知冲突转化为地理定位准确性的提升。

Abstract: Visual geo-localization requires extensive geographic knowledge and
sophisticated reasoning to determine image locations without GPS metadata.
Traditional retrieval methods are constrained by database coverage and quality.
Recent Large Vision-Language Models (LVLMs) enable direct location reasoning
from image content, yet individual models struggle with diverse geographic
regions and complex scenes. Existing multi-agent systems improve performance
through model collaboration but treat all agent interactions uniformly. They
lack mechanisms to handle conflicting predictions effectively. We propose
\textbf{GraphGeo}, a multi-agent debate framework using heterogeneous graph
neural networks for visual geo-localization. Our approach models diverse debate
relationships through typed edges, distinguishing supportive collaboration,
competitive argumentation, and knowledge transfer. We introduce a dual-level
debate mechanism combining node-level refinement and edge-level argumentation
modeling. A cross-level topology refinement strategy enables co-evolution
between graph structure and agent representations. Experiments on multiple
benchmarks demonstrate GraphGeo significantly outperforms state-of-the-art
methods. Our framework transforms cognitive conflicts between agents into
enhanced geo-localization accuracy through structured debate.

</details>


### [98] [Fleming-VL: Towards Universal Medical Visual Reasoning with Multimodal LLMs](https://arxiv.org/abs/2511.00916)
*Yan Shu,Chi Liu,Robin Chen,Derek Li,Bryan Dai*

Main category: cs.CV

TL;DR: Fleming-VL是一个统一的多模态医学视觉理解框架，通过数据中心的策略解决医学数据异质性问题，并在多个基准测试中达到最优性能。


<details>
  <summary>Details</summary>
Motivation: 医学数据的多模态异质性（如2D图像、3D扫描和视频）阻碍了统一医学MLLMs的发展，需要一种综合解决方案。

Method: 采用三种策略：扩大预训练数据（自然和医学领域）、补充罕见医学数据微调、扩展评估框架以涵盖3D和视频理解。

Result: Fleming-VL在医学VQA、视频QA和3D医学图像理解等任务中达到最优性能。

Conclusion: Fleming-VL为医学AI提供了透明、可复现的解决方案，推动了多模态医学视觉理解的进展。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated remarkable
effectiveness in various general-domain scenarios, such as visual question
answering and image captioning. Recently, researchers have increasingly focused
on empowering MLLMs with medical conversational abilities, which hold
significant promise for clinical applications. However, medical data presents
unique challenges due to its heterogeneous nature -- encompassing diverse
modalities including 2D images, 3D volumetric scans, and temporal video
sequences. The substantial domain gap and data format inconsistencies across
these modalities have hindered the development of unified medical MLLMs. To
address these challenges, we propose Fleming-VL, a unified end-to-end framework
for comprehensive medical visual understanding across heterogeneous modalities.
Fleming-VL tackles this problem from a data-centric perspective through three
key strategies: (1) scaling up pretraining by integrating long-context data
from both natural and medical-specific domains; (2) complementing fine-tuning
with rare medical data, including holistic video analysis and underrepresented
2D modalities such as ultrasound and dermoscopy images; (3) extending existing
evaluation frameworks to incorporate 3D volumetric and video understanding
benchmarks. Through supervised fine-tuning (SFT) and group relative policy
optimization (GRPO), we develop Fleming-VL in multiple model scales. Extensive
experiments demonstrate that Fleming-VL achieves state-of-the-art performance
across multiple benchmarks, including medical VQA, video QA, and 3D medical
image understanding. We publicly release Fleming-VL to promote transparent,
reproducible, and auditable progress in medical AI.

</details>


### [99] [Dynamic Multi-level Weighted Alignment Network for Zero-shot Sketch-based Image Retrieval](https://arxiv.org/abs/2511.00925)
*Hanwen Su,Ge Song,Jiyan Wang,Yuanbo Zhu*

Main category: cs.CV

TL;DR: 提出了一种动态多级加权对齐网络（DMWAN）用于零样本草图-图像检索（ZS-SBIR），通过多级加权模块和加权四元组损失提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有ZS-SBIR方法中模态样本不平衡和低质量信息不一致导致的性能不佳问题。

Method: 包括单模态特征提取模块、跨模态多级加权模块和加权四元组损失模块。

Result: 在Sketchy、TU-Berlin和QuickDraw数据集上优于现有方法。

Conclusion: DMWAN有效提升了ZS-SBIR的性能，解决了模态不平衡问题。

Abstract: The problem of zero-shot sketch-based image retrieval (ZS-SBIR) has achieved
increasing attention due to its wide applications, e.g. e-commerce. Despite
progress made in this field, previous works suffer from using imbalanced
samples of modalities and inconsistent low-quality information during training,
resulting in sub-optimal performance. Therefore, in this paper, we introduce an
approach called Dynamic Multi-level Weighted Alignment Network for ZS-SBIR. It
consists of three components: (i) a Uni-modal Feature Extraction Module that
includes a CLIP text encoder and a ViT for extracting textual and visual
tokens, (ii) a Cross-modal Multi-level Weighting Module that produces an
alignment weight list by the local and global aggregation blocks to measure the
aligning quality of sketch and image samples, (iii) a Weighted Quadruplet Loss
Module aiming to improve the balance of domains in the triplet loss.
Experiments on three benchmark datasets, i.e., Sketchy, TU-Berlin, and
QuickDraw, show our method delivers superior performances over the
state-of-the-art ZS-SBIR methods.

</details>


### [100] [EVTAR: End-to-End Try on with Additional Unpaired Visual Reference](https://arxiv.org/abs/2511.00956)
*Liuzhuozheng Li,Yue Gong,Shanyuan Liu,Bo Cheng,Yuhang Ma,Liebucha Wu,Dengyang Jiang,Zanyi Wang,Dawei Leng,Yuhui Yin*

Main category: cs.CV

TL;DR: EVTAR是一种端到端的虚拟试穿模型，通过引入参考图像提升试穿准确性，简化输入需求。


<details>
  <summary>Details</summary>
Motivation: 现有虚拟试穿方法依赖复杂输入（如人体姿态、密集点等），不适用于实际应用。EVTAR旨在简化输入并提升效果。

Method: 采用两阶段训练策略，仅需源图像和目标服装作为输入，无需掩码或分割图，并利用参考图像保留服装细节。

Result: 在多个基准测试中表现优异，验证了方法的有效性。

Conclusion: EVTAR通过参考图像和简化输入，实现了更高质量的虚拟试穿效果。

Abstract: We propose EVTAR, an End-to-End Virtual Try-on model with Additional
Reference, that directly fits the target garment onto the person image while
incorporating reference images to enhance try-on accuracy. Most existing
virtual try-on approaches rely on complex inputs such as agnostic person
images, human pose, densepose, or body keypoints, making them labor-intensive
and impractical for real-world applications. In contrast, EVTAR adopts a
two-stage training strategy, enabling simple inference with only the source
image and the target garment inputs. Our model generates try-on results without
masks, densepose, or segmentation maps. Moreover, EVTAR leverages additional
reference images of different individuals wearing the same clothes to preserve
garment texture and fine-grained details better. This mechanism is analogous to
how humans consider reference models when choosing outfits, thereby simulating
a more realistic and high-quality dressing effect. We enrich the training data
with supplementary references and unpaired person images to support these
capabilities. We evaluate EVTAR on two widely used benchmarks and diverse
tasks, and the results consistently validate the effectiveness of our approach.

</details>


### [101] [A Unified Reasoning Framework for Holistic Zero-Shot Video Anomaly Analysis](https://arxiv.org/abs/2511.00962)
*Dongheng Lin,Mengxue Qu,Kunyang Han,Jianbo Jiao,Xiaojie Jin,Yunchao Wei*

Main category: cs.CV

TL;DR: 提出了一种统一的推理框架，用于视频异常检测、定位和解释，无需额外训练即可实现零样本分析。


<details>
  <summary>Details</summary>
Motivation: 现有视频异常研究方法缺乏时空和语义上下文，且依赖数据和任务特定性。

Method: 采用链式测试时推理过程，结合任务内和任务间推理，提升解释性和泛化能力。

Result: 在多个基准测试中实现了最先进的零样本性能。

Conclusion: 通过精心设计的提示和任务链，可以释放基础模型的推理能力，实现实用且可解释的视频异常分析。

Abstract: Most video-anomaly research stops at frame-wise detection, offering little
insight into why an event is abnormal, typically outputting only frame-wise
anomaly scores without spatial or semantic context. Recent video anomaly
localization and video anomaly understanding methods improve explainability but
remain data-dependent and task-specific. We propose a unified reasoning
framework that bridges the gap between temporal detection, spatial
localization, and textual explanation. Our approach is built upon a chained
test-time reasoning process that sequentially connects these tasks, enabling
holistic zero-shot anomaly analysis without any additional training.
Specifically, our approach leverages intra-task reasoning to refine temporal
detections and inter-task chaining for spatial and semantic understanding,
yielding improved interpretability and generalization in a fully zero-shot
manner. Without any additional data or gradients, our method achieves
state-of-the-art zero-shot performance across multiple video anomaly detection,
localization, and explanation benchmarks. The results demonstrate that careful
prompt design with task-wise chaining can unlock the reasoning power of
foundation models, enabling practical, interpretable video anomaly analysis in
a fully zero-shot manner. Project Page:
https://rathgrith.github.io/Unified_Frame_VAA/.

</details>


### [102] [VesSAM: Efficient Multi-Prompting for Segmenting Complex Vessel](https://arxiv.org/abs/2511.00981)
*Suzhong Fu,Rui Sun,Xuan Ding,Jingqi Dong,Yiming Yang,Yao Zhu,Min Chang Jordan Ren,Delin Deng,Angelica Aviles-Rivero,Shuguang Cui,Zhen Li*

Main category: cs.CV

TL;DR: VesSAM是一个专为2D血管分割设计的高效框架，通过结合卷积适配器、多提示编码器和轻量级掩码解码器，显著提升了血管分割性能。


<details>
  <summary>Details</summary>
Motivation: 血管分割在临床应用中至关重要，但由于血管结构复杂且纹理对比度低，现有通用分割模型表现不佳。

Method: VesSAM集成了卷积适配器增强局部纹理特征，多提示编码器融合解剖学提示，以及轻量级掩码解码器减少锯齿状伪影。

Result: VesSAM在多个数据集上表现优异，Dice和IoU分别提升10%和13%，且参数更少，泛化能力强。

Conclusion: VesSAM在血管分割任务中优于现有方法，具有高效性和泛化性。

Abstract: Accurate vessel segmentation is critical for clinical applications such as
disease diagnosis and surgical planning, yet remains challenging due to thin,
branching structures and low texture contrast. While foundation models like the
Segment Anything Model (SAM) have shown promise in generic segmentation, they
perform sub-optimally on vascular structures. In this work, we present VesSAM,
a powerful and efficient framework tailored for 2D vessel segmentation. VesSAM
integrates (1) a convolutional adapter to enhance local texture features, (2) a
multi-prompt encoder that fuses anatomical prompts, including skeletons,
bifurcation points, and segment midpoints, via hierarchical cross-attention,
and (3) a lightweight mask decoder to reduce jagged artifacts. We also
introduce an automated pipeline to generate structured multi-prompt
annotations, and curate a diverse benchmark dataset spanning 8 datasets across
5 imaging modalities. Experimental results demonstrate that VesSAM consistently
outperforms state-of-the-art PEFT-based SAM variants by over 10% Dice and 13%
IoU, and achieves competitive performance compared to fully fine-tuned methods,
with significantly fewer parameters. VesSAM also generalizes well to
out-of-distribution (OoD) settings, outperforming all baselines in average OoD
Dice and IoU.

</details>


### [103] [MID: A Self-supervised Multimodal Iterative Denoising Framework](https://arxiv.org/abs/2511.00997)
*Chang Nie,Tianchen Deng,Zhe Liu,Hesheng Wang*

Main category: cs.CV

TL;DR: 提出了一种自监督多模态迭代去噪（MID）框架，用于处理复杂非线性噪声，无需配对干净-噪声数据集。


<details>
  <summary>Details</summary>
Motivation: 现实数据常受复杂非线性噪声污染，传统基于规则的去噪方法效果不佳。

Method: MID通过迭代引入噪声，学习两个神经网络：一个估计当前噪声步骤，另一个预测并减去噪声增量。对于非线性噪声，使用一阶泰勒展开局部线性化。

Result: 在四个经典计算机视觉任务中表现优异，同时在生物医学和生物信息学领域也展现出强大性能。

Conclusion: MID是一种鲁棒、自适应且性能优越的去噪方法，适用于多领域复杂噪声场景。

Abstract: Data denoising is a persistent challenge across scientific and engineering
domains. Real-world data is frequently corrupted by complex, non-linear noise,
rendering traditional rule-based denoising methods inadequate. To overcome
these obstacles, we propose a novel self-supervised multimodal iterative
denoising (MID) framework. MID models the collected noisy data as a state
within a continuous process of non-linear noise accumulation. By iteratively
introducing further noise, MID learns two neural networks: one to estimate the
current noise step and another to predict and subtract the corresponding noise
increment. For complex non-linear contamination, MID employs a first-order
Taylor expansion to locally linearize the noise process, enabling effective
iterative removal. Crucially, MID does not require paired clean-noisy datasets,
as it learns noise characteristics directly from the noisy inputs. Experiments
across four classic computer vision tasks demonstrate MID's robustness,
adaptability, and consistent state-of-the-art performance. Moreover, MID
exhibits strong performance and adaptability in tasks within the biomedical and
bioinformatics domains.

</details>


### [104] [Integrating Visual and X-Ray Machine Learning Features in the Study of Paintings by Goya](https://arxiv.org/abs/2511.01000)
*Hassan Ugail,Ismail Lujain Jaleel*

Main category: cs.CV

TL;DR: 提出了一种多模态机器学习框架，用于鉴定弗朗西斯科·戈雅画作的真伪，结合视觉和X射线图像特征提取，显著提升了鉴定准确率。


<details>
  <summary>Details</summary>
Motivation: 戈雅画作风格多变且伪造历史复杂，传统单模态方法难以准确鉴定，因此需要一种多模态的解决方案。

Method: 采用统一特征提取技术（如灰度共生矩阵、局部二值模式等）处理视觉和X射线图像，并通过优化的一类支持向量机进行分类。

Result: 在24幅戈雅画作数据集上，分类准确率达97.8%，假阳性率为0.022，多模态方法显著优于单模态。

Conclusion: 多模态特征分析在艺术鉴定中具有显著优势，统一处理视觉和X射线图像的方法有效且实用。

Abstract: Art authentication of Francisco Goya's works presents complex computational
challenges due to his heterogeneous stylistic evolution and extensive
historical patterns of forgery. We introduce a novel multimodal machine
learning framework that applies identical feature extraction techniques to both
visual and X-ray radiographic images of Goya paintings. The unified feature
extraction pipeline incorporates Grey-Level Co-occurrence Matrix descriptors,
Local Binary Patterns, entropy measures, energy calculations, and colour
distribution analysis applied consistently across both imaging modalities. The
extracted features from both visual and X-ray images are processed through an
optimised One-Class Support Vector Machine with hyperparameter tuning. Using a
dataset of 24 authenticated Goya paintings with corresponding X-ray images,
split into an 80/20 train-test configuration with 10-fold cross-validation, the
framework achieves 97.8% classification accuracy with a 0.022 false positive
rate. Case study analysis of ``Un Gigante'' demonstrates the practical efficacy
of our pipeline, achieving 92.3% authentication confidence through unified
multimodal feature analysis. Our results indicate substantial performance
improvement over single-modal approaches, establishing the effectiveness of
applying identical computational methods to both visual and radiographic
imagery in art authentication applications.

</details>


### [105] [HyFormer-Net: A Synergistic CNN-Transformer with Interpretable Multi-Scale Fusion for Breast Lesion Segmentation and Classification in Ultrasound Images](https://arxiv.org/abs/2511.01013)
*Mohammad Amanour Rahman*

Main category: cs.CV

TL;DR: HyFormer-Net是一种结合CNN和Transformer的混合模型，用于乳腺癌超声图像的同步分割和分类，具有内在可解释性，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决B超乳腺癌诊断中的斑点噪声、操作依赖性和边界模糊问题，同时克服现有深度学习模型的单任务学习、架构限制和黑盒决策缺陷。

Method: 提出HyFormer-Net，采用双分支编码器（EfficientNet-B3和Swin Transformer）和多尺度融合模块，结合注意力门控解码器，并引入双管道可解释性验证。

Result: 在BUSI数据集上，Dice分数0.761，准确率93.2%，恶性召回率92.1%；通过集成模型进一步提升性能。跨数据集研究表明，微调后模型能实现泛化。

Conclusion: HyFormer-Net在性能和可解释性上均优于现有方法，且通过微调可适应不同数据集，为临床应用提供了潜力。

Abstract: B-mode ultrasound for breast cancer diagnosis faces challenges: speckle,
operator dependency, and indistinct boundaries. Existing deep learning suffers
from single-task learning, architectural constraints (CNNs lack global context,
Transformers local features), and black-box decision-making. These gaps hinder
clinical adoption.
  We propose HyFormer-Net, a hybrid CNN-Transformer for simultaneous
segmentation and classification with intrinsic interpretability. Its
dual-branch encoder integrates EfficientNet-B3 and Swin Transformer via
multi-scale hierarchical fusion blocks. An attention-gated decoder provides
precision and explainability. We introduce dual-pipeline interpretability: (1)
intrinsic attention validation with quantitative IoU verification (mean: 0.86),
and (2) Grad-CAM for classification reasoning.
  On the BUSI dataset, HyFormer-Net achieves Dice Score 0.761 +/- 0.072 and
accuracy 93.2%, outperforming U-Net, Attention U-Net, and TransUNet. Malignant
Recall of 92.1 +/- 2.2% ensures minimal false negatives. Ensemble modeling
yields exceptional Dice 90.2%, accuracy 99.5%, and perfect 100% Malignant
Recall, eliminating false negatives. Ablation studies confirm multi-scale
fusion contributes +16.8% Dice and attention gates add +5.9%.
  Crucially, we conduct the first cross-dataset generalization study for hybrid
CNN-Transformers in breast ultrasound. Zero-shot transfer fails (Dice: 0.058),
confirming domain shift. However, progressive fine-tuning with only 10%
target-domain data (68 images) recovers 92.5% performance. With 50% data, our
model achieves 77.3% Dice, exceeding source-domain performance (76.1%) and
demonstrating true generalization.

</details>


### [106] [FastBoost: Progressive Attention with Dynamic Scaling for Efficient Deep Learning](https://arxiv.org/abs/2511.01026)
*JunXi Yuan*

Main category: cs.CV

TL;DR: FastBoost是一种参数高效的神经网络架构，通过动态缩放渐进注意力机制（DSPA）在CIFAR基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 设计一种高效的神经网络架构，以在资源受限的边缘设备上部署，同时保持高精度。

Method: 采用动态缩放渐进注意力机制（DSPA），结合自适应融合、相位缩放和残差适应等创新技术。

Result: 在CIFAR-10和CIFAR-100上取得高精度，参数数量显著减少，性能优于MobileNetV3。

Conclusion: FastBoost通过动态注意力与高效卷积的协同优化，实现了前所未有的参数-精度权衡，适用于边缘设备。

Abstract: We present FastBoost, a parameter-efficient neural architecture that achieves
state-of-the-art performance on CIFAR benchmarks through a novel Dynamically
Scaled Progressive Attention (DSPA) mechanism. Our design establishes new
efficiency frontiers with: CIFAR-10: 95.57% accuracy (0.85M parameters) and
93.80% (0.37M parameters) CIFAR-100: 81.37% accuracy (0.92M parameters) and
74.85% (0.44M parameters) The breakthrough stems from three fundamental
innovations in DSPA: (1) Adaptive Fusion: Learnt channel-spatial attention
blending with dynamic weights. (2) Phase Scaling: Training-stage-aware
intensity modulation (from 0.5 to 1.0). (3) Residual Adaptation: Self-optimized
skip connections (gamma from 0.5 to 0.72). By integrating DSPA with enhanced
MBConv blocks, FastBoost achieves a 2.1 times parameter reduction over
MobileNetV3 while improving accuracy by +3.2 percentage points on CIFAR-10. The
architecture features dual attention pathways with real-time weight adjustment,
cascaded refinement layers (increasing gradient flow by 12.7%), and a
hardware-friendly design (0.28G FLOPs). This co-optimization of dynamic
attention and efficient convolution operations demonstrates unprecedented
parameter-accuracy trade-offs, enabling deployment in resource-constrained edge
devices without accuracy degradation.

</details>


### [107] [T-MLA: A Targeted Multiscale Log--Exponential Attack Framework for Neural Image Compression](https://arxiv.org/abs/2511.01079)
*Nikolay I. Kalmykov,Razan Dibo,Kaiyu Shen,Xu Zhonghan,Anh-Huy Phan,Yipeng Liu,Ivan Oseledets*

Main category: cs.CV

TL;DR: 本文提出了一种针对神经图像压缩（NIC）的新型攻击框架T-MLA，揭示了其安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 现有攻击方法多为像素空间方法的简单适配，忽视了压缩管道的结构化特性，因此需要更高级的攻击框架。

Method: 提出T-MLA攻击框架，在小波域中生成对抗扰动，直接针对攻击和重建图像的质量。

Result: 在多个NIC架构上验证，重建质量显著下降，同时扰动视觉不可察觉。

Conclusion: 揭示了生成和内容交付管道中的核心安全缺陷。

Abstract: Neural image compression (NIC) has become the state-of-the-art for
rate-distortion performance, yet its security vulnerabilities remain
significantly less understood than those of classifiers. Existing adversarial
attacks on NICs are often naive adaptations of pixel-space methods, overlooking
the unique, structured nature of the compression pipeline. In this work, we
propose a more advanced class of vulnerabilities by introducing T-MLA, the
first targeted multiscale log--exponential attack framework. Our approach
crafts adversarial perturbations in the wavelet domain by directly targeting
the quality of the attacked and reconstructed images. This allows for a
principled, offline attack where perturbations are strategically confined to
specific wavelet subbands, maximizing distortion while ensuring perceptual
stealth. Extensive evaluation across multiple state-of-the-art NIC
architectures on standard image compression benchmarks reveals a large drop in
reconstruction quality while the perturbations remain visually imperceptible.
Our findings reveal a critical security flaw at the core of generative and
content delivery pipelines.

</details>


### [108] [GeoToken: Hierarchical Geolocalization of Images via Next Token Prediction](https://arxiv.org/abs/2511.01082)
*Narges Ghasemi,Amir Ziashahabi,Salman Avestimehr,Cyrus Shahabi*

Main category: cs.CV

TL;DR: 提出了一种基于层次序列预测的图像地理定位方法，通过逐步细化预测位置，结合S2网格和自回归采样技术，在多个数据集上实现了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 解决图像地理定位中因视觉相似性和大搜索空间带来的挑战，模仿人类从大区域到具体地址的定位方式。

Method: 使用S2网格进行层次化预测，结合自回归采样技术（如束搜索和多样本推理）优化推理策略。

Result: 在Im2GPS3k和YFCC4k数据集上，无MLLM时性能提升13.9%，结合MLLM时全面超越基线。

Conclusion: 层次序列预测方法在图像地理定位任务中表现优异，结合MLLM进一步提升了性能。

Abstract: Image geolocalization, the task of determining an image's geographic origin,
poses significant challenges, largely due to visual similarities across
disparate locations and the large search space. To address these issues, we
propose a hierarchical sequence prediction approach inspired by how humans
narrow down locations from broad regions to specific addresses. Analogously,
our model predicts geographic tokens hierarchically, first identifying a
general region and then sequentially refining predictions to increasingly
precise locations. Rather than relying on explicit semantic partitions, our
method uses S2 cells, a nested, multiresolution global grid, and sequentially
predicts finer-level cells conditioned on visual inputs and previous
predictions. This procedure mirrors autoregressive text generation in large
language models. Much like in language modeling, final performance depends not
only on training but also on inference-time strategy. We investigate multiple
top-down traversal methods for autoregressive sampling, incorporating
techniques from test-time compute scaling used in language models.
Specifically, we integrate beam search and multi-sample inference while
exploring various selection strategies to determine the final output. This
enables the model to manage uncertainty by exploring multiple plausible paths
through the hierarchy. We evaluate our method on the Im2GPS3k and YFCC4k
datasets against two distinct sets of baselines: those that operate without a
Multimodal Large Language Model (MLLM) and those that leverage one. In the
MLLM-free setting, our model surpasses other comparable baselines on nearly all
metrics, achieving state-of-the-art performance with accuracy gains of up to
13.9%. When augmented with an MLLM, our model outperforms all baselines,
setting a new state-of-the-art across all metrics. The source code is available
at https://github.com/NNargesNN/GeoToken.

</details>


### [109] [SliceVision-F2I: A Synthetic Feature-to-Image Dataset for Visual Pattern Representation on Network Slices](https://arxiv.org/abs/2511.01087)
*Md. Abid Hasan Rafi,Mst. Fatematuj Johora,Pankaj Bhowmik*

Main category: cs.CV

TL;DR: SliceVision-F2I是一个合成数据集，用于研究网络切片中的特征可视化，支持视觉学习和机器学习任务。


<details>
  <summary>Details</summary>
Motivation: 5G和6G网络的发展需要更精细的网络切片识别方法，而现有数据集不足以支持相关研究。

Method: 通过四种编码方法（物理启发映射、Perlin噪声、神经壁纸化和分形分支）将KPI向量转换为视觉表示，生成30,000个样本。

Result: 数据集模拟了真实和噪声网络条件，适用于视觉学习、网络状态分类和异常检测等任务。

Conclusion: SliceVision-F2I是一个公开可用的数据集，可用于多种研究场景，如时间序列分析和特征到图像转换。

Abstract: The emergence of 5G and 6G networks has established network slicing as a
significant part of future service-oriented architectures, demanding refined
identification methods supported by robust datasets. The article presents
SliceVision-F2I, a dataset of synthetic samples for studying feature
visualization in network slicing for next-generation networking systems. The
dataset transforms multivariate Key Performance Indicator (KPI) vectors into
visual representations through four distinct encoding methods: physically
inspired mappings, Perlin noise, neural wallpapering, and fractal branching.
For each encoding method, 30,000 samples are generated, each comprising a raw
KPI vector and a corresponding RGB image at low-resolution pixels. The dataset
simulates realistic and noisy network conditions to reflect operational
uncertainties and measurement imperfections. SliceVision-F2I is suitable for
tasks involving visual learning, network state classification, anomaly
detection, and benchmarking of image-based machine learning techniques applied
to network data. The dataset is publicly available and can be reused in various
research contexts, including multivariate time series analysis, synthetic data
generation, and feature-to-image transformations.

</details>


### [110] [Epanechnikov nonparametric kernel density estimation based feature-learning in respiratory disease chest X-ray images](https://arxiv.org/abs/2511.01098)
*Veronica Marsico,Antonio Quintero-Rincon,Hadj Batatia*

Main category: cs.CV

TL;DR: 提出了一种结合Epanechnikov核密度估计和双峰逻辑回归分类器的新方法，用于呼吸系统疾病的图像诊断，测试结果显示中等性能。


<details>
  <summary>Details</summary>
Motivation: 利用EKDE的灵活性和适应性，从医学图像中提取关键特征，以提高诊断准确性和可靠性。

Method: 结合EKDE和双峰逻辑回归分类器，基于统计模型的学习方案。

Result: 在13808张胸部X光片上测试，准确率70.14%，敏感性59.26%，特异性74.18%。

Conclusion: EKDE方法在医学影像诊断中具有潜力，但需进一步优化敏感性。

Abstract: This study presents a novel method for diagnosing respiratory diseases using
image data. It combines Epanechnikov's non-parametric kernel density estimation
(EKDE) with a bimodal logistic regression classifier in a
statistical-model-based learning scheme. EKDE's flexibility in modeling data
distributions without assuming specific shapes and its adaptability to pixel
intensity variations make it valuable for extracting key features from medical
images. The method was tested on 13808 randomly selected chest X-rays from the
COVID-19 Radiography Dataset, achieved an accuracy of 70.14%, a sensitivity of
59.26%, and a specificity of 74.18%, demonstrating moderate performance in
detecting respiratory disease while showing room for improvement in
sensitivity. While clinical expertise remains essential for further refining
the model, this study highlights the potential of EKDE-based approaches to
enhance diagnostic accuracy and reliability in medical imaging.

</details>


### [111] [Anatomically Constrained Transformers for Echocardiogram Analysis](https://arxiv.org/abs/2511.01109)
*Alexander Thorley,Agis Chartsias,Jordan Strom,Jeremy Slivnick,Dipak Kotecha,Alberto Gomez,Jinming Duan*

Main category: cs.CV

TL;DR: ViACT是一种结合解剖学先验的视频Transformer框架，专注于心肌区域，用于超声心动图分析任务。


<details>
  <summary>Details</summary>
Motivation: 解决视频Transformer在超声心动图分析中容易学习非诊断区域（如图像背景）的虚假相关性问题。

Method: 通过将解剖结构表示为点集，并将其空间几何和图像块编码为Transformer令牌，采用掩码自编码策略预训练模型。

Result: ViACT在左心室射血分数回归和心脏淀粉样变性检测任务中表现优异，注意力图与已知病理区域一致。

Conclusion: ViACT通过解剖约束提高了模型对心肌区域的专注度，无需特定任务组件即可泛化到心肌点跟踪任务。

Abstract: Video transformers have recently demonstrated strong potential for
echocardiogram (echo) analysis, leveraging self-supervised pre-training and
flexible adaptation across diverse tasks. However, like other models operating
on videos, they are prone to learning spurious correlations from non-diagnostic
regions such as image backgrounds. To overcome this limitation, we propose the
Video Anatomically Constrained Transformer (ViACT), a novel framework that
integrates anatomical priors directly into the transformer architecture. ViACT
represents a deforming anatomical structure as a point set and encodes both its
spatial geometry and corresponding image patches into transformer tokens.
During pre-training, ViACT follows a masked autoencoding strategy that masks
and reconstructs only anatomical patches, enforcing that representation
learning is focused on the anatomical region. The pre-trained model can then be
fine-tuned for tasks localized to this region. In this work we focus on the
myocardium, demonstrating the framework on echo analysis tasks such as left
ventricular ejection fraction (EF) regression and cardiac amyloidosis (CA)
detection. The anatomical constraint focuses transformer attention within the
myocardium, yielding interpretable attention maps aligned with regions of known
CA pathology. Moreover, ViACT generalizes to myocardium point tracking without
requiring task-specific components such as correlation volumes used in
specialized tracking networks.

</details>


### [112] [Boosting performance of computer vision applications through embedded GPUs on the edge](https://arxiv.org/abs/2511.01129)
*Fabio Diniz Rossi*

Main category: cs.CV

TL;DR: 论文提出使用带GPU的嵌入式设备提升移动设备上计算机视觉应用的性能。


<details>
  <summary>Details</summary>
Motivation: 移动设备上的计算机视觉应用（如增强现实）资源需求高，边缘计算设备能力有限，影响用户体验。

Method: 采用带GPU的嵌入式设备，卸载高负载任务。

Result: 实验显示GPU比CPU性能提升，改善用户体验。

Conclusion: GPU能有效解决边缘计算设备性能不足的问题。

Abstract: Computer vision applications, especially those using augmented reality
technology, are becoming quite popular in mobile devices. However, this type of
application is known as presenting significant demands regarding resources. In
order to enable its utilization in devices with more modest resources, edge
computing can be used to offload certain high intensive tasks. Still, edge
computing is usually composed of devices with limited capacity, which may
impact in users quality of experience when using computer vision applications.
This work proposes the use of embedded devices with graphics processing units
(GPUs) to overcome such limitation. Experiments performed shown that GPUs can
attain a performance gain when compared to using only CPUs, which guarantee a
better experience to users using such kind of application.

</details>


### [113] [Weakly Supervised Concept Learning with Class-Level Priors for Interpretable Medical Diagnosis](https://arxiv.org/abs/2511.01131)
*Md Nahiduzzaman,Steven Korevaar,Alireza Bab-Hadiashar,Ruwan Tennakoon*

Main category: cs.CV

TL;DR: 提出了一种无需标注的弱监督框架PCP，用于医学影像中的可解释预测，性能优于零样本基线。


<details>
  <summary>Details</summary>
Motivation: 医学影像中可解释预测需要概念标注，但标注成本高且不实用，现有方法难以捕捉医学特征。

Method: PCP利用类级概念先验作为弱监督，结合KL散度和熵正则化机制优化预测。

Result: 在多个医学数据集上，PCP的概念级F1分数提升33%，分类性能媲美全监督模型。

Conclusion: PCP为医学影像提供了一种无需标注的高效可解释预测方案。

Abstract: Human-interpretable predictions are essential for deploying AI in medical
imaging, yet most interpretable-by-design (IBD) frameworks require concept
annotations for training data, which are costly and impractical to obtain in
clinical contexts. Recent attempts to bypass annotation, such as zero-shot
vision-language models or concept-generation frameworks, struggle to capture
domain-specific medical features, leading to poor reliability. In this paper,
we propose a novel Prior-guided Concept Predictor (PCP), a weakly supervised
framework that enables concept answer prediction without explicit supervision
or reliance on language models. PCP leverages class-level concept priors as
weak supervision and incorporates a refinement mechanism with KL divergence and
entropy regularization to align predictions with clinical reasoning.
Experiments on PH2 (dermoscopy) and WBCatt (hematology) show that PCP improves
concept-level F1-score by over 33% compared to zero-shot baselines, while
delivering competitive classification performance on four medical datasets
(PH2, WBCatt, HAM10000, and CXR4) relative to fully supervised concept
bottleneck models (CBMs) and V-IP.

</details>


### [114] [Learning with Category-Equivariant Architectures for Human Activity Recognition](https://arxiv.org/abs/2511.01139)
*Yoshihiro Maruyama*

Main category: cs.CV

TL;DR: CatEquiv是一种用于人体活动识别的类别等变神经网络，通过编码时间、幅度和结构对称性提升鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统方法在处理惯性传感器数据时未能系统性地利用数据的对称性结构。

Method: 引入类别对称性乘积，结合循环时间偏移、正增益和传感器层次偏序集，实现类别对称性结构的编码。

Result: 在UCI-HAR数据集上，CatEquiv在分布外扰动下表现出显著更高的鲁棒性。

Conclusion: 强制类别对称性可以在不增加模型容量的情况下实现强不变性和泛化能力。

Abstract: We propose CatEquiv, a category-equivariant neural network for Human Activity
Recognition (HAR) from inertial sensors that systematically encodes temporal,
amplitude, and structural symmetries. In particular, we introduce the
categorical symmetry product where cyclic time shifts, positive gains and the
sensor-hierarchy poset together capture the categorical symmetry structure of
the data. CatEquiv achieves equivariance with respect to the categorical
symmetry product. On UCI-HAR under out-of-distribution perturbations, CatEquiv
attains markedly higher robustness compared with circularly padded CNNs and
plain CNNs. These results demonstrate that enforcing categorical symmetries
yields strong invariance and generalization without additional model capacity.

</details>


### [115] [MicroAUNet: Boundary-Enhanced Multi-scale Fusion with Knowledge Distillation for Colonoscopy Polyp Image Segmentation](https://arxiv.org/abs/2511.01143)
*Ziyi Wang,Yuanmei Zhang,Dorna Esrafilzadeh,Ali R. Jalili,Suncheng Xiang*

Main category: cs.CV

TL;DR: MicroAUNet是一种轻量级注意力分割网络，用于实时结直肠息肉分割，结合深度可分离扩张卷积和通道-空间注意力块，通过两阶段知识蒸馏提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在结直肠息肉分割中要么边界模糊，要么计算复杂，无法满足实时需求。

Method: 提出MicroAUNet，结合深度可分离扩张卷积和通道-空间注意力块，采用两阶段知识蒸馏从高容量教师模型迁移语义和边界信息。

Result: 在极低模型复杂度下实现最先进精度，适合实时临床应用。

Conclusion: MicroAUNet在准确性和效率上均优于现有方法，适用于实时结直肠内窥镜应用。

Abstract: Early and accurate segmentation of colorectal polyps is critical for reducing
colorectal cancer mortality, which has been extensively explored by academia
and industry. However, current deep learning-based polyp segmentation models
either compromise clinical decision-making by providing ambiguous polyp margins
in segmentation outputs or rely on heavy architectures with high computational
complexity, resulting in insufficient inference speeds for real-time colorectal
endoscopic applications. To address this problem, we propose MicroAUNet, a
light-weighted attention-based segmentation network that combines
depthwise-separable dilated convolutions with a single-path, parameter-shared
channel-spatial attention block to strengthen multi-scale boundary features. On
the basis of it, a progressive two-stage knowledge-distillation scheme is
introduced to transfer semantic and boundary cues from a high-capacity teacher.
Extensive experiments on benchmarks also demonstrate the state-of-the-art
accuracy under extremely low model complexity, indicating that MicroAUNet is
suitable for real-time clinical polyp segmentation. The code is publicly
available at https://github.com/JeremyXSC/MicroAUNet.

</details>


### [116] [ROVER: Benchmarking Reciprocal Cross-Modal Reasoning for Omnimodal Generation](https://arxiv.org/abs/2511.01163)
*Yongyuan Liang,Wei Chow,Feng Li,Ziqiao Ma,Xiyao Wang,Jiageng Mao,Jiuhai Chen,Jiatao Gu,Yue Wang,Furong Huang*

Main category: cs.CV

TL;DR: ROVER是一个针对统一多模态模型（UMMs）的跨模态推理能力评估基准，包含1312个任务和1876张图像，揭示了跨模态推理对视觉生成质量的关键作用。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法将多模态能力孤立测试，缺乏对跨模态推理能力的评估，而ROVER填补了这一空白。

Method: ROVER通过两个互补设置评估跨模态推理：1）语言增强的视觉生成；2）视觉增强的语言生成。

Result: 实验发现跨模态推理决定视觉生成质量，且模型在物理和符号推理上表现分离。

Conclusion: 跨模态推理是实现真正多模态生成的关键前沿。

Abstract: Unified multimodal models (UMMs) have emerged as a powerful paradigm for
seamlessly unifying text and image understanding and generation. However,
prevailing evaluations treat these abilities in isolation, such that tasks with
multimodal inputs and outputs are scored primarily through unimodal reasoning,
i.e., textual benchmarks emphasize language-based reasoning, while visual
benchmarks emphasize reasoning outcomes manifested in the pixels. We introduce
ROVER to address this pressing need to test reciprocal cross-modal reasoning,
the use of one modality to guide, verify, or refine outputs in the other, an
ability central to the vision of unified multimodal intelligence. ROVER is a
human-annotated benchmark that explicitly targets reciprocal cross-modal
reasoning, which contains 1312 tasks grounded in 1876 images, spanning two
complementary settings. Verbally-augmented reasoning for visual generation
evaluates whether models can use verbal prompts and reasoning chains to guide
faithful image synthesis. Visually-augmented reasoning for verbal generation
evaluates whether models can generate intermediate visualizations that
strengthen their own reasoning processes for question answering. Experiments on
17 unified models reveal two key findings: (i) Cross-modal reasoning determines
visual generation quality, with interleaved models significantly outperforming
non-interleaved ones; notably, combining strong unimodal models fails to
achieve comparable reasoning. (ii) Models show dissociation between physical
and symbolic reasoning: they succeed at interpreting perceptual concepts
literally but fail to construct visual abstractions for symbolic tasks, where
faulty reasoning harms performance. These results highlight reciprocal
cross-modal reasoning as a critical frontier for enabling true omnimodal
generation.

</details>


### [117] [Web-Scale Collection of Video Data for 4D Animal Reconstruction](https://arxiv.org/abs/2511.01169)
*Brian Nlong Zhao,Jiajun Wu,Shangzhe Wu*

Main category: cs.CV

TL;DR: 提出自动化流程从YouTube视频中提取动物中心剪辑，构建大规模数据集（30K视频，2M帧），并发布Animal-in-Motion基准测试（230序列，11K帧），用于4D动物重建任务。


<details>
  <summary>Details</summary>
Motivation: 现有动物视频数据集规模小且缺乏关键处理，限制了动物中心3D/4D任务的发展。

Method: 开发自动化流程挖掘YouTube视频，生成对象中心剪辑及辅助标注，并构建AiM基准测试。

Result: 数据集规模远超现有工作，评估显示模型方法与无模型方法各有优劣，提出序列级优化改进无模型方法。

Conclusion: 通过流程、基准和基线，推动野外视频中无标记4D动物重建及相关任务的发展。

Abstract: Computer vision for animals holds great promise for wildlife research but
often depends on large-scale data, while existing collection methods rely on
controlled capture setups. Recent data-driven approaches show the potential of
single-view, non-invasive analysis, yet current animal video datasets are
limited--offering as few as 2.4K 15-frame clips and lacking key processing for
animal-centric 3D/4D tasks. We introduce an automated pipeline that mines
YouTube videos and processes them into object-centric clips, along with
auxiliary annotations valuable for downstream tasks like pose estimation,
tracking, and 3D/4D reconstruction. Using this pipeline, we amass 30K videos
(2M frames)--an order of magnitude more than prior works. To demonstrate its
utility, we focus on the 4D quadruped animal reconstruction task. To support
this task, we present Animal-in-Motion (AiM), a benchmark of 230 manually
filtered sequences with 11K frames showcasing clean, diverse animal motions. We
evaluate state-of-the-art model-based and model-free methods on
Animal-in-Motion, finding that 2D metrics favor the former despite unrealistic
3D shapes, while the latter yields more natural reconstructions but scores
lower--revealing a gap in current evaluation. To address this, we enhance a
recent model-free approach with sequence-level optimization, establishing the
first 4D animal reconstruction baseline. Together, our pipeline, benchmark, and
baseline aim to advance large-scale, markerless 4D animal reconstruction and
related tasks from in-the-wild videos. Code and datasets are available at
https://github.com/briannlongzhao/Animal-in-Motion.

</details>


### [118] [Diffusion Transformer meets Multi-level Wavelet Spectrum for Single Image Super-Resolution](https://arxiv.org/abs/2511.01175)
*Peng Du,Hui Li,Han Xu,Paul Barom Jeon,Dongwook Lee,Daehyun Ji,Ran Yang,Feng Zhu*

Main category: cs.CV

TL;DR: 提出了一种基于小波谱的扩散Transformer模型（DTWSR），用于图像超分辨率，通过捕捉多尺度频率子带间的关联性，提升重建图像的连贯性和真实性。


<details>
  <summary>Details</summary>
Motivation: 现有基于DWT的超分辨率方法忽视了多尺度频率子带间的关联性，导致重建图像不一致和不自然。

Method: 使用多级离散小波变换（MDWT）分解图像为小波谱，提出金字塔标记化方法将谱嵌入Transformer序列，设计双解码器分别处理低频和高频子带。

Result: 在多个基准数据集上验证了方法的有效性，在感知质量和保真度上表现优异。

Conclusion: DTWSR通过结合扩散模型和Transformer的优势，显著提升了超分辨率图像的质量和一致性。

Abstract: Discrete Wavelet Transform (DWT) has been widely explored to enhance the
performance of image superresolution (SR). Despite some DWT-based methods
improving SR by capturing fine-grained frequency signals, most existing
approaches neglect the interrelations among multiscale frequency sub-bands,
resulting in inconsistencies and unnatural artifacts in the reconstructed
images. To address this challenge, we propose a Diffusion Transformer model
based on image Wavelet spectra for SR (DTWSR).DTWSR incorporates the
superiority of diffusion models and transformers to capture the interrelations
among multiscale frequency sub-bands, leading to a more consistence and
realistic SR image. Specifically, we use a Multi-level Discrete Wavelet
Transform (MDWT) to decompose images into wavelet spectra. A pyramid
tokenization method is proposed which embeds the spectra into a sequence of
tokens for transformer model, facilitating to capture features from both
spatial and frequency domain. A dual-decoder is designed elaborately to handle
the distinct variances in lowfrequency (LF) and high-frequency (HF) sub-bands,
without omitting their alignment in image generation. Extensive experiments on
multiple benchmark datasets demonstrate the effectiveness of our method, with
high performance on both perception quality and fidelity.

</details>


### [119] [A Topology-Aware Graph Convolutional Network for Human Pose Similarity and Action Quality Assessment](https://arxiv.org/abs/2511.01194)
*Minmin Zeng*

Main category: cs.CV

TL;DR: 提出了一种基于拓扑感知的GCN框架（GCN-PSN），用于动作质量评估，通过对比回归目标训练，在AQA-7和FineDiving基准上表现优异。


<details>
  <summary>Details</summary>
Motivation: 动作质量评估需要细粒度的人体运动理解和精确的姿态相似性评估。

Method: 使用拓扑感知的GCN框架建模人体骨架图，通过Siamese架构和对比回归目标训练。

Result: 在AQA-7和FineDiving基准上优于基于坐标的基线方法。

Conclusion: 实验验证了利用骨骼拓扑结构对姿态相似性和动作质量评估的有效性。

Abstract: Action Quality Assessment (AQA) requires fine-grained understanding of human
motion and precise evaluation of pose similarity. This paper proposes a
topology-aware Graph Convolutional Network (GCN) framework, termed GCN-PSN,
which models the human skeleton as a graph to learn discriminative,
topology-sensitive pose embeddings. Using a Siamese architecture trained with a
contrastive regression objective, our method outperforms coordinate-based
baselines and achieves competitive performance on AQA-7 and FineDiving
benchmarks. Experimental results and ablation studies validate the
effectiveness of leveraging skeletal topology for pose similarity and action
quality assessment.

</details>


### [120] [MoSa: Motion Generation with Scalable Autoregressive Modeling](https://arxiv.org/abs/2511.01200)
*Mengyuan Liu,Sheng Yan,Yong Wang,Yingjie Li,Gui-Bin Bian,Hong Liu*

Main category: cs.CV

TL;DR: MoSa是一种新颖的分层运动生成框架，通过多尺度令牌保留策略和轻量级CAQ-VAE，显著提升了文本驱动的3D人体运动生成的质量和效率。


<details>
  <summary>Details</summary>
Motivation: 传统方法在生成3D人体运动时存在效率低和细节丢失的问题，MoSa旨在通过分层生成和增强的VQ-VAE设计解决这些问题。

Method: MoSa采用多尺度令牌保留策略（MTPS）和分层残差向量量化变分自编码器（RQ-VAE），并结合卷积-注意力混合的CAQ-VAE来优化生成过程。

Result: 在Motion-X数据集上，MoSa的FID为0.06（优于MoMask的0.20），推理时间减少27%，且在下游任务（如运动编辑）中表现良好。

Conclusion: MoSa在生成质量和效率上均达到领先水平，无需额外微调即可应用于下游任务，展示了其强大的通用性。

Abstract: We introduce MoSa, a novel hierarchical motion generation framework for
text-driven 3D human motion generation that enhances the Vector
Quantization-guided Generative Transformers (VQ-GT) paradigm through a
coarse-to-fine scalable generation process. In MoSa, we propose a Multi-scale
Token Preservation Strategy (MTPS) integrated into a hierarchical residual
vector quantization variational autoencoder (RQ-VAE). MTPS employs
interpolation at each hierarchical quantization to effectively retain
coarse-to-fine multi-scale tokens. With this, the generative transformer
supports Scalable Autoregressive (SAR) modeling, which predicts scale tokens,
unlike traditional methods that predict only one token at each step.
Consequently, MoSa requires only 10 inference steps, matching the number of
RQ-VAE quantization layers. To address potential reconstruction degradation
from frequent interpolation, we propose CAQ-VAE, a lightweight yet expressive
convolution-attention hybrid VQ-VAE. CAQ-VAE enhances residual block design and
incorporates attention mechanisms to better capture global dependencies.
Extensive experiments show that MoSa achieves state-of-the-art generation
quality and efficiency, outperforming prior methods in both fidelity and speed.
On the Motion-X dataset, MoSa achieves an FID of 0.06 (versus MoMask's 0.20)
while reducing inference time by 27 percent. Moreover, MoSa generalizes well to
downstream tasks such as motion editing, requiring no additional fine-tuning.
The code is available at https://mosa-web.github.io/MoSa-web

</details>


### [121] [OmniVLA: Unifiying Multi-Sensor Perception for Physically-Grounded Multimodal VLA](https://arxiv.org/abs/2511.01210)
*Heyu Guo,Shanmu Wang,Ruichun Ma,Shiqi Jiang,Yasaman Ghasempour,Omid Abari,Baining Guo,Lili Qi*

Main category: cs.CV

TL;DR: OmniVLA是一种多模态视觉-语言-动作模型，通过整合新型传感器模态（如红外相机、毫米波雷达和麦克风阵列）提升感知能力，显著优于仅依赖RGB的模型。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作模型仅依赖RGB摄像头，限制了感知和操作能力，需扩展多模态感知以提升性能。

Method: 提出传感器掩码图像作为统一表示，结合RGB图像与传感器数据，基于RGB预训练模型架构进行多模态训练。

Result: OmniVLA在真实任务中平均成功率达84%，比RGB模型和原始传感器输入模型分别提升59%和28%。

Conclusion: 多模态感知显著提升模型性能，OmniVLA展示了更高的学习效率和更强的泛化能力。

Abstract: Vision-language-action (VLA) models have shown strong generalization for
action prediction through large-scale vision-language pretraining. However,
most existing models rely solely on RGB cameras, limiting their perception and,
consequently, manipulation capabilities. We present OmniVLA, an omni-modality
VLA model that integrates novel sensing modalities for physically-grounded
spatial intelligence beyond RGB perception. The core of our approach is the
sensor-masked image, a unified representation that overlays spatially grounded
and physically meaningful masks onto the RGB images, derived from sensors
including an infrared camera, a mmWave radar, and a microphone array. This
image-native unification keeps sensor input close to RGB statistics to
facilitate training, provides a uniform interface across sensor hardware, and
enables data-efficient learning with lightweight per-sensor projectors. Built
on this, we present a multisensory vision-language-action model architecture
and train the model based on an RGB-pretrained VLA backbone. We evaluate
OmniVLA on challenging real-world tasks where sensor-modality perception is
needed to guide the manipulation. OmniVLA achieves an average task success rate
of 84%, significantly outperforms both RGB-only and raw-sensor-input baseline
models by 59% and 28% respectively, meanwhile showing higher learning
efficiency and stronger generalization capability.

</details>


### [122] [Thought-For-Food: Reasoning Chain Induced Food Visual Question Answering](https://arxiv.org/abs/2511.01213)
*Riddhi Jain,Manasi Patwardhan,Parijat Deshpande,Venkataramana Runkana*

Main category: cs.CV

TL;DR: 论文提出了一种多步推理方法，用于提升印度食物视觉问答（VQA）系统的准确性，通过自动生成推理链并微调小型LLMs和VLMs，实现了平均10%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有VQA系统偏向西方食物，无法处理印度食物的复杂烹饪背景和关系，因此需要多步推理方法。

Method: 通过自动生成推理链，微调小型LLMs和VLMs，并结合强化学习进行训练。

Result: 实验表明，推理链的加入使基线模型的准确性平均提升了10个百分点。

Conclusion: 多步推理方法能有效提升印度食物VQA任务的性能，尤其是在处理复杂烹饪背景时。

Abstract: The immense diversity in the culture and culinary of Indian cuisines calls
attention to the major shortcoming of the existing Visual Question
Answering(VQA) systems which are inclined towards the foods from Western
region. Recent attempt towards building a VQA dataset for Indian food is a step
towards addressing this challenge. However, their approach towards VQA follows
a two-step process in which the answer is generated first, followed by the
explanation of the expected answer. In this work, we claim that food VQA
requires to follow a multi-step reasoning process to arrive at an accurate
answer, especially in the context of India food, which involves understanding
complex culinary context and identifying relationships between various food
items. With this hypothesis we create reasoning chains upon the QA with minimal
human intervention. We fine-tune smaller LLMs and VLMs with auto-validated
reasoning chains and further train them using reinforcement learning with
larger data. With augmentation of reasoning chains, we observed accuracy
improvement of an average 10 percentage points on the baseline. We provide
detailed analysis in terms the effect of addition of reasoning chains for the
Indian Food VQA task.
  Index Terms - FoodVQA, Reasoning Chains, Reinforcement Learning, Knowledge
Graph.

</details>


### [123] [Gesture Generation (Still) Needs Improved Human Evaluation Practices: Insights from a Community-Driven State-of-the-Art Benchmark](https://arxiv.org/abs/2511.01233)
*Rajmund Nagy,Hendric Voss,Thanh Hoang-Minh,Mihail Tsakov,Teodor Nikolov,Zeyi Zhang,Tenglong Ao,Sicheng Yang,Shaoli Huang,Yongkang Cheng,M. Hamza Mughal,Rishabh Dabral,Kiran Chhatre,Christian Theobalt,Libin Liu,Stefan Kopp,Rachel McDonnell,Michael Neff,Taras Kucherenko,Youngwoo Yoon,Gustav Eje Henter*

Main category: cs.CV

TL;DR: 论文提出标准化的人体评估协议，用于语音驱动的3D手势生成，并通过大规模众包评估比较六种模型，发现新模型未必优于旧模型，且需分离评估运动质量和多模态对齐。


<details>
  <summary>Details</summary>
Motivation: 当前语音驱动3D手势生成领域缺乏标准化评估方法，导致无法准确比较不同方法或确定技术现状。

Method: 引入详细的人体评估协议，使用BEAT2数据集进行大规模众包评估，比较六种模型在运动真实性和语音-手势对齐两个维度的表现。

Result: 新模型未必优于旧模型；现有高运动真实性或对齐的声明在严格评估下可能不成立；需分离评估运动质量和多模态对齐。

Conclusion: 标准化评估协议和公开数据集将推动领域进步，需分离评估维度以准确衡量技术进展。

Abstract: We review human evaluation practices in automated, speech-driven 3D gesture
generation and find a lack of standardisation and frequent use of flawed
experimental setups. This leads to a situation where it is impossible to know
how different methods compare, or what the state of the art is. In order to
address common shortcomings of evaluation design, and to standardise future
user studies in gesture-generation works, we introduce a detailed human
evaluation protocol for the widely-used BEAT2 motion-capture dataset. Using
this protocol, we conduct large-scale crowdsourced evaluation to rank six
recent gesture-generation models -- each trained by its original authors --
across two key evaluation dimensions: motion realism and speech-gesture
alignment. Our results provide strong evidence that 1) newer models do not
consistently outperform earlier approaches; 2) published claims of high motion
realism or speech-gesture alignment may not hold up under rigorous evaluation;
and 3) the field must adopt disentangled assessments of motion quality and
multimodal alignment for accurate benchmarking in order to make progress.
Finally, in order to drive standardisation and enable new evaluation research,
we will release five hours of synthetic motion from the benchmarked models;
over 750 rendered video stimuli from the user studies -- enabling new
evaluations without model reimplementation required -- alongside our
open-source rendering script, and the 16,000 pairwise human preference votes
collected for our benchmark.

</details>


### [124] [Eyes on Target: Gaze-Aware Object Detection in Egocentric Video](https://arxiv.org/abs/2511.01237)
*Vishakha Lall,Yisi Liu*

Main category: cs.CV

TL;DR: 提出了一种基于人眼注视的深度感知和注视引导的目标检测框架，通过将注视特征注入ViT的注意力机制，提升目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 利用人眼注视信号优化视觉注意力，提升复杂视觉环境中的目标检测效果。

Method: 将注视特征融入ViT的注意力机制，偏重于人类关注的区域。

Result: 在模拟器和公开数据集上均优于传统方法，检测精度显著提升。

Conclusion: 注视引导的注意力机制能有效提升目标检测性能，尤其在需要人类视觉注意力的场景中。

Abstract: Human gaze offers rich supervisory signals for understanding visual attention
in complex visual environments. In this paper, we propose Eyes on Target, a
novel depth-aware and gaze-guided object detection framework designed for
egocentric videos. Our approach injects gaze-derived features into the
attention mechanism of a Vision Transformer (ViT), effectively biasing spatial
feature selection toward human-attended regions. Unlike traditional object
detectors that treat all regions equally, our method emphasises
viewer-prioritised areas to enhance object detection. We validate our method on
an egocentric simulator dataset where human visual attention is critical for
task assessment, illustrating its potential in evaluating human performance in
simulation scenarios. We evaluate the effectiveness of our gaze-integrated
model through extensive experiments and ablation studies, demonstrating
consistent gains in detection accuracy over gaze-agnostic baselines on both the
custom simulator dataset and public benchmarks, including Ego4D Ego-Motion and
Ego-CH-Gaze datasets. To interpret model behaviour, we also introduce a
gaze-aware attention head importance metric, revealing how gaze cues modulate
transformer attention dynamics.

</details>


### [125] [Beyond Deceptive Flatness: Dual-Order Solution for Strengthening Adversarial Transferability](https://arxiv.org/abs/2511.01240)
*Zhixuan Zhang,Pingyu Wang,Xingjian Zheng,Linbo Qing,Qi Liu*

Main category: cs.CV

TL;DR: 提出了一种基于双阶信息的黑盒梯度可迁移攻击方法，解决了欺骗性平坦问题，并通过实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有可迁移攻击方法在平坦损失上仍陷入次优区域（欺骗性平坦），需要更有效的解决方案。

Method: 引入对抗平坦性（AF）理论保证，提出对抗平坦攻击（AFA）和蒙特卡洛对抗采样（MCAS）。

Result: 在ImageNet数据集上优于六种基线方法，提升了跨模型架构的可迁移性。

Conclusion: AFA方法在平坦区域生成对抗样本，显著提升了攻击的可迁移性和实际应用效果。

Abstract: Transferable attacks generate adversarial examples on surrogate models to
fool unknown victim models, posing real-world threats and growing research
interest. Despite focusing on flat losses for transferable adversarial
examples, recent studies still fall into suboptimal regions, especially the
flat-yet-sharp areas, termed as deceptive flatness. In this paper, we introduce
a novel black-box gradient-based transferable attack from a perspective of
dual-order information. Specifically, we feasibly propose Adversarial Flatness
(AF) to the deceptive flatness problem and a theoretical assurance for
adversarial transferability. Based on this, using an efficient approximation of
our objective, we instantiate our attack as Adversarial Flatness Attack (AFA),
addressing the altered gradient sign issue. Additionally, to further improve
the attack ability, we devise MonteCarlo Adversarial Sampling (MCAS) by
enhancing the inner-loop sampling efficiency. The comprehensive results on
ImageNet-compatible dataset demonstrate superiority over six baselines,
generating adversarial examples in flatter regions and boosting transferability
across model architectures. When tested on input transformation attacks or the
Baidu Cloud API, our method outperforms baselines.

</details>


### [126] [CenterMamba-SAM: Center-Prioritized Scanning and Temporal Prototypes for Brain Lesion Segmentation](https://arxiv.org/abs/2511.01243)
*Yu Tian,Zhongheng Yang,Chenshi Liu,Yiyun Su,Ziwei Hong,Zexi Gong,Jingyuan Xu*

Main category: cs.CV

TL;DR: CenterMamba-SAM是一种高效的脑部病变分割框架，通过轻量级适配器和创新的扫描策略实现高性能。


<details>
  <summary>Details</summary>
Motivation: 脑部病变分割面临小病灶、低对比度和跨切片不连续性的挑战。

Method: 采用3x3角轴中心短序列扫描策略和记忆驱动的结构提示生成器，结合多尺度解码器。

Result: 在公开基准测试中达到最先进的性能。

Conclusion: CenterMamba-SAM通过高效设计和创新方法显著提升了脑部病变分割的准确性。

Abstract: Brain lesion segmentation remains challenging due to small, low-contrast
lesions, anisotropic sampling, and cross-slice discontinuities. We propose
CenterMamba-SAM, an end-to-end framework that freezes a pretrained backbone and
trains only lightweight adapters for efficient fine-tuning. At its core is the
CenterMamba encoder, which employs a novel 3x3 corner-axis-center
short-sequence scanning strategy to enable center-prioritized, axis-reinforced,
and diagonally compensated information aggregation. This design enhances
sensitivity to weak boundaries and tiny foci while maintaining sparse yet
effective feature representation. A memory-driven structural prompt generator
maintains a prototype bank across neighboring slices, enabling automatic
synthesis of reliable prompts without user interaction, thereby improving
inter-slice coherence. The memory-augmented multi-scale decoder integrates
memory attention modules at multiple levels, combining deep supervision with
progressive refinement to restore fine details while preserving global
consistency. Extensive experiments on public benchmarks demonstrate that
CenterMamba-SAM achieves state-of-the-art performance in brain lesion
segmentation.

</details>


### [127] [Source-Only Cross-Weather LiDAR via Geometry-Aware Point Drop](https://arxiv.org/abs/2511.01250)
*YoungJae Cheong,Jhonghyun An*

Main category: cs.CV

TL;DR: 提出了一种轻量级几何感知适配器，通过几何驱动的正则化提升LiDAR语义分割在恶劣天气下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 恶劣天气下LiDAR语义分割性能下降，现有方法忽视了边界、角落和稀疏区域的结构脆弱性。

Method: 设计几何感知适配器，通过方位对齐、水平循环填充和局部K近邻统计生成几何感知线索，驱动区域感知正则化。

Result: 在跨天气设置下，mIoU提升7.9个百分点，优于数据增强和类中心正则化基线。

Conclusion: 几何驱动的正则化是提升全天候LiDAR分割性能的关键方向。

Abstract: LiDAR semantic segmentation degrades in adverse weather because refraction,
scattering, and point dropouts corrupt geometry. Prior work in weather
simulation, mixing-based augmentation, domain randomization, and uncertainty or
boundary regularization improves robustness but still overlooks structural
vulnerabilities near boundaries, corners, and sparse regions. We present a
Light Geometry-aware adapter. The module aligns azimuth and applies horizontal
circular padding to preserve neighbor continuity across the 0~360 degree
wrap-around boundary. A local-window K-Nearest Neighbors gathers nearby points
and computes simple local statistics, which are compressed into compact
geometry-aware cues. During training, these cues drive region-aware
regularization that stabilizes predictions in structurally fragile areas. The
adapter is plug and play, complements augmentation, and can be enabled only
during training with negligible inference cost. We adopt a source-only
cross-weather setup where models train on SemanticKITTI and are evaluated on
SemanticSTF without target labels or fine-tuning. The adapter improves mIoU by
7.9 percentage points over the data-centric augmentation baseline and by 0.6
points over the class-centric regularization baseline. These results indicate
that geometry-driven regularization is a key direction for all-weather LiDAR
segmentation.

</details>


### [128] [MotionStream: Real-Time Video Generation with Interactive Motion Controls](https://arxiv.org/abs/2511.01266)
*Joonghyuk Shin,Zhengqi Li,Richard Zhang,Jun-Yan Zhu,Jaesik Park,Eli Schechtman,Xun Huang*

Main category: cs.CV

TL;DR: MotionStream 是一种实时视频生成方法，通过因果学生模型和滑动窗口注意力机制，实现低延迟（29 FPS）和无限长度视频生成。


<details>
  <summary>Details</summary>
Motivation: 解决现有视频生成方法的高延迟和非因果处理问题，实现实时交互。

Method: 通过自强迫与分布匹配蒸馏将双向教师模型转化为因果学生模型，结合滑动窗口因果注意力和注意力池技术。

Result: 在运动跟随和视频质量上达到SOTA，速度快两个数量级，支持无限长度流式生成。

Conclusion: MotionStream 实现了实时交互视频生成，适用于轨迹绘制、相机控制和运动转移等应用。

Abstract: Current motion-conditioned video generation methods suffer from prohibitive
latency (minutes per video) and non-causal processing that prevents real-time
interaction. We present MotionStream, enabling sub-second latency with up to 29
FPS streaming generation on a single GPU. Our approach begins by augmenting a
text-to-video model with motion control, which generates high-quality videos
that adhere to the global text prompt and local motion guidance, but does not
perform inference on the fly. As such, we distill this bidirectional teacher
into a causal student through Self Forcing with Distribution Matching
Distillation, enabling real-time streaming inference. Several key challenges
arise when generating videos of long, potentially infinite time-horizons: (1)
bridging the domain gap from training on finite length and extrapolating to
infinite horizons, (2) sustaining high quality by preventing error
accumulation, and (3) maintaining fast inference, without incurring growth in
computational cost due to increasing context windows. A key to our approach is
introducing carefully designed sliding-window causal attention, combined with
attention sinks. By incorporating self-rollout with attention sinks and KV
cache rolling during training, we properly simulate inference-time
extrapolations with a fixed context window, enabling constant-speed generation
of arbitrarily long videos. Our models achieve state-of-the-art results in
motion following and video quality while being two orders of magnitude faster,
uniquely enabling infinite-length streaming. With MotionStream, users can paint
trajectories, control cameras, or transfer motion, and see results unfold in
real-time, delivering a truly interactive experience.

</details>


### [129] [PRevivor: Reviving Ancient Chinese Paintings using Prior-Guided Color Transformers](https://arxiv.org/abs/2511.01274)
*Tan Tang,Yanhong Wu,Junming Gao,Yingcai Wu*

Main category: cs.CV

TL;DR: PRevivor是一种基于先验引导的颜色转换器，用于恢复古代中国画的色彩，通过亮度增强和色调校正两个子任务实现。


<details>
  <summary>Details</summary>
Motivation: 古代中国画的色彩退化是不可逆的，缺乏高质量数据集阻碍了端到端数字修复工具的开发。

Method: PRevivor采用变分U-Net和多尺度映射模块进行亮度增强，并通过双分支颜色查询模块进行色调校正。

Result: 实验表明，PRevivor在定量和定性上均优于现有色彩化方法。

Conclusion: PRevivor为古代中国画的色彩恢复提供了有效解决方案。

Abstract: Ancient Chinese paintings are a valuable cultural heritage that is damaged by
irreversible color degradation. Reviving color-degraded paintings is
extraordinarily difficult due to the complex chemistry mechanism. Progress is
further slowed by the lack of comprehensive, high-quality datasets, which
hampers the creation of end-to-end digital restoration tools. To revive colors,
we propose PRevivor, a prior-guided color transformer that learns from recent
paintings (e.g., Ming and Qing Dynasty) to restore ancient ones (e.g., Tang and
Song Dynasty). To develop PRevivor, we decompose color restoration into two
sequential sub-tasks: luminance enhancement and hue correction. For luminance
enhancement, we employ two variational U-Nets and a multi-scale mapping module
to translate faded luminance into restored counterparts. For hue correction, we
design a dual-branch color query module guided by localized hue priors
extracted from faded paintings. Specifically, one branch focuses attention on
regions guided by masked priors, enforcing localized hue correction, whereas
the other branch remains unconstrained to maintain a global reasoning
capability. To evaluate PRevivor, we conduct extensive experiments against
state-of-the-art colorization methods. The results demonstrate superior
performance both quantitatively and qualitatively.

</details>


### [130] [Adaptation of Foundation Models for Medical Image Analysis: Strategies, Challenges, and Future Directions](https://arxiv.org/abs/2511.01284)
*Karma Phuntsho,Abdullah,Kyungmi Lee,Ickjai Lee,Euijoon Ahn*

Main category: cs.CV

TL;DR: 综述探讨了基础模型在医学影像分析中的适应策略，总结了现有方法的性能与局限性，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 基础模型在医学影像分析中具有潜力，但实际应用面临领域偏移、数据稀缺、计算需求和隐私问题等挑战。

Method: 评估了监督微调、领域特定预训练、参数高效微调、自监督学习、混合方法和多模态框架等方法。

Result: 总结了各种方法的性能提升、临床适用性和局限性，并指出了未解决的挑战。

Conclusion: 提出了动态部署、隐私保护、数据效率提升等未来方向，为开发适应性强的医学影像基础模型提供了路线图。

Abstract: Foundation models (FMs) have emerged as a transformative paradigm in medical
image analysis, offering the potential to provide generalizable, task-agnostic
solutions across a wide range of clinical tasks and imaging modalities. Their
capacity to learn transferable representations from large-scale data has the
potential to address the limitations of conventional task-specific models.
However, adaptation of FMs to real-world clinical practice remains constrained
by key challenges, including domain shifts, limited availability of
high-quality annotated data, substantial computational demands, and strict
privacy requirements. This review presents a comprehensive assessment of
strategies for adapting FMs to the specific demands of medical imaging. We
examine approaches such as supervised fine-tuning, domain-specific pretraining,
parameter-efficient fine-tuning, self-supervised learning, hybrid methods, and
multimodal or cross-modal frameworks. For each, we evaluate reported
performance gains, clinical applicability, and limitations, while identifying
trade-offs and unresolved challenges that prior reviews have often overlooked.
Beyond these established techniques, we also highlight emerging directions
aimed at addressing current gaps. These include continual learning to enable
dynamic deployment, federated and privacy-preserving approaches to safeguard
sensitive data, hybrid self-supervised learning to enhance data efficiency,
data-centric pipelines that combine synthetic generation with human-in-the-loop
validation, and systematic benchmarking to assess robust generalization under
real-world clinical variability. By outlining these strategies and associated
research gaps, this review provides a roadmap for developing adaptive,
trustworthy, and clinically integrated FMs capable of meeting the demands of
real-world medical imaging.

</details>


### [131] [Detecting Generated Images by Fitting Natural Image Distributions](https://arxiv.org/abs/2511.01293)
*Yonggang Zhang,Jun Nie,Xinmei Tian,Mingming Gong,Kun Zhang,Bo Han*

Main category: cs.CV

TL;DR: 提出了一种利用自然图像与生成图像数据流形几何差异的新框架，通过正交梯度子空间和自监督模型进行检测，并利用归一化流放大差异。


<details>
  <summary>Details</summary>
Motivation: 生成图像的真实性提升引发滥用担忧，现有方法依赖大量生成图像数据，需更鲁棒的检测方法。

Method: 设计一对函数使自然图像输出一致而生成图像输出分歧，利用梯度正交性；通过自监督模型损失变化检测生成图像；使用归一化流放大流形差异。

Result: 实验证明该方法有效。

Conclusion: 提出的框架能有效检测生成图像，尤其在高级生成模型中通过归一化流增强检测能力。

Abstract: The increasing realism of generated images has raised significant concerns
about their potential misuse, necessitating robust detection methods. Current
approaches mainly rely on training binary classifiers, which depend heavily on
the quantity and quality of available generated images. In this work, we
propose a novel framework that exploits geometric differences between the data
manifolds of natural and generated images. To exploit this difference, we
employ a pair of functions engineered to yield consistent outputs for natural
images but divergent outputs for generated ones, leveraging the property that
their gradients reside in mutually orthogonal subspaces. This design enables a
simple yet effective detection method: an image is identified as generated if a
transformation along its data manifold induces a significant change in the loss
value of a self-supervised model pre-trained on natural images. Further more,
to address diminishing manifold disparities in advanced generative models, we
leverage normalizing flows to amplify detectable differences by extruding
generated images away from the natural image manifold. Extensive experiments
demonstrate the efficacy of this method. Code is available at
https://github.com/tmlr-group/ConV.

</details>


### [132] [UniREditBench: A Unified Reasoning-based Image Editing Benchmark](https://arxiv.org/abs/2511.01295)
*Feng Han,Yibin Wang,Chenglin Li,Zheming Liang,Dianyi Wang,Yang Jiao,Zhipeng Wei,Chao Gong,Cheng Jin,Jingjing Chen,Jiaqi Wang*

Main category: cs.CV

TL;DR: UniREditBench是一个用于评估基于推理的图像编辑的统一基准，覆盖真实和游戏场景，提供多模态双参考评估，并构建大规模合成数据集。


<details>
  <summary>Details</summary>
Motivation: 当前生成模型在处理需要隐式推理的复杂图像编辑任务时表现不佳，现有基准主要关注单对象属性转换，缺乏多对象交互和游戏场景的评估。

Method: 提出UniREditBench基准，包含2700个样本，覆盖8个主要维度和18个子维度，引入多模态双参考评估，并构建UniREdit-Data-100K数据集。

Result: 在Bagel模型上微调后，UniREdit-Bagel在域内和域外设置中均表现显著提升。

Conclusion: 通过全面评估开源和闭源图像编辑模型，揭示了它们在不同方面的优缺点。

Abstract: Recent advances in multi-modal generative models have driven substantial
improvements in image editing. However, current generative models still
struggle with handling diverse and complex image editing tasks that require
implicit reasoning, underscoring the need for a comprehensive benchmark to
systematically assess their performance across various reasoning scenarios.
Existing benchmarks primarily focus on single-object attribute transformation
in realistic scenarios, which, while effective, encounter two key challenges:
(1) they largely overlook multi-object interactions as well as game-world
scenarios that involve human-defined rules, which are common in real-life
applications; (2) they only rely on textual references to evaluate the
generated images, potentially leading to systematic misjudgments, especially in
complex reasoning scenarios. To this end, this work proposes UniREditBench, a
unified benchmark for reasoning-based image editing evaluation. It comprises
2,700 meticulously curated samples, covering both real- and game-world
scenarios across 8 primary dimensions and 18 sub-dimensions. To improve
evaluation reliability, we introduce multimodal dual-reference evaluation,
providing both textual and ground-truth image references for each sample
assessment. Furthermore, we design an automated multi-scenario data synthesis
pipeline and construct UniREdit-Data-100K, a large-scale synthetic dataset with
high-quality chain-of-thought (CoT) reasoning annotations. We fine-tune Bagel
on this dataset and develop UniREdit-Bagel, demonstrating substantial
improvements in both in-domain and out-of-distribution settings. Through
thorough benchmarking of both open-source and closed-source image editing
models, we reveal their strengths and weaknesses across various aspects.

</details>


### [133] [REASON: Probability map-guided dual-branch fusion framework for gastric content assessment](https://arxiv.org/abs/2511.01302)
*Nu-Fnag Xiao,De-Xing Huang,Le-Tian Wang,Mei-Jiang Gui,Qi Fu,Xiao-Liang Xie,Shi-Qi Liu,Shuangyi Wang,Zeng-Guang Hou,Ying-Wei Wang,Xiao-Hu Zhou*

Main category: cs.CV

TL;DR: 提出了一种名为REASON的双阶段概率图引导双分支融合框架，用于胃内容物评估，显著提升了效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统胃内容物评估方法依赖手动追踪和经验公式，效率和准确性受限，亟需改进。

Method: 第一阶段通过分割模型生成概率图，抑制伪影并突出胃解剖结构；第二阶段通过双分支分类器融合RLD和SUP视图信息，提升特征判别能力。

Result: 在自收集数据集上，REASON显著优于现有方法。

Conclusion: 该框架为术前吸入风险评估提供了更鲁棒、高效和准确的自动化解决方案。

Abstract: Accurate assessment of gastric content from ultrasound is critical for
stratifying aspiration risk at induction of general anesthesia. However,
traditional methods rely on manual tracing of gastric antra and empirical
formulas, which face significant limitations in both efficiency and accuracy.
To address these challenges, a novel two-stage probability map-guided
dual-branch fusion framework (REASON) for gastric content assessment is
proposed. In stage 1, a segmentation model generates probability maps that
suppress artifacts and highlight gastric anatomy. In stage 2, a dual-branch
classifier fuses information from two standard views, right lateral decubitus
(RLD) and supine (SUP), to improve the discrimination of learned features.
Experimental results on a self-collected dataset demonstrate that the proposed
framework outperforms current state-of-the-art approaches by a significant
margin. This framework shows great promise for automated preoperative
aspiration risk assessment, offering a more robust, efficient, and accurate
solution for clinical practice.

</details>


### [134] [Positive Semi-definite Latent Factor Grouping-Boosted Cluster-reasoning Instance Disentangled Learning for WSI Representation](https://arxiv.org/abs/2511.01304)
*Chentao Li,Behzad Bozorgtabar,Yifang Ping,Pan Huang,Jing Qin*

Main category: cs.CV

TL;DR: 提出了一种新的多实例学习框架，通过潜在因子分组和聚类推理解决空间、语义和决策纠缠问题，提升了全切片病理图像的可解释性和性能。


<details>
  <summary>Details</summary>
Motivation: 多实例学习（MIL）在全切片病理图像表示中存在空间、语义和决策纠缠问题，限制了其表示能力和可解释性。

Method: 采用三阶段框架：1）潜在因子分组缓解空间纠缠；2）聚类推理和反事实推理缓解语义纠缠；3）实例效应重加权解决决策纠缠。

Result: 在多中心数据集上表现优于现有方法，并实现了病理学家对齐的可解释性。

Conclusion: 该框架显著提升了全切片图像的可解释性和性能，为病理图像分析提供了透明决策过程。

Abstract: Multiple instance learning (MIL) has been widely used for representing
whole-slide pathology images. However, spatial, semantic, and decision
entanglements among instances limit its representation and interpretability. To
address these challenges, we propose a latent factor grouping-boosted
cluster-reasoning instance disentangled learning framework for whole-slide
image (WSI) interpretable representation in three phases. First, we introduce a
novel positive semi-definite latent factor grouping that maps instances into a
latent subspace, effectively mitigating spatial entanglement in MIL. To
alleviate semantic entanglement, we employs instance probability counterfactual
inference and optimization via cluster-reasoning instance disentangling.
Finally, we employ a generalized linear weighted decision via instance effect
re-weighting to address decision entanglement. Extensive experiments on
multicentre datasets demonstrate that our model outperforms all
state-of-the-art models. Moreover, it attains pathologist-aligned
interpretability through disentangled representations and a transparent
decision-making process.

</details>


### [135] [Perturb a Model, Not an Image: Towards Robust Privacy Protection via Anti-Personalized Diffusion Models](https://arxiv.org/abs/2511.01307)
*Tae-Young Lee,Juwon Seo,Jong Hwan Ko,Gyeong-Moon Park*

Main category: cs.CV

TL;DR: 提出了一种新框架APDM，通过保护扩散模型本身而非图像来防止恶意个性化，并引入DPO损失函数和L2P优化策略，显著提升了防护效果。


<details>
  <summary>Details</summary>
Motivation: 扩散模型的高质量合成能力带来隐私风险，现有防护方法在现实场景中效果不佳。

Method: 提出APDM框架，包含DPO损失函数和L2P双路径优化策略，理论分析支持其有效性。

Result: 实验表明APDM优于现有方法，能有效阻止未经授权的个性化。

Conclusion: APDM为扩散模型的隐私保护提供了新思路，具有实际应用潜力。

Abstract: Recent advances in diffusion models have enabled high-quality synthesis of
specific subjects, such as identities or objects. This capability, while
unlocking new possibilities in content creation, also introduces significant
privacy risks, as personalization techniques can be misused by malicious users
to generate unauthorized content. Although several studies have attempted to
counter this by generating adversarially perturbed samples designed to disrupt
personalization, they rely on unrealistic assumptions and become ineffective in
the presence of even a few clean images or under simple image transformations.
To address these challenges, we shift the protection target from the images to
the diffusion model itself to hinder the personalization of specific subjects,
through our novel framework called Anti-Personalized Diffusion Models (APDM).
We first provide a theoretical analysis demonstrating that a naive approach of
existing loss functions to diffusion models is inherently incapable of ensuring
convergence for robust anti-personalization. Motivated by this finding, we
introduce Direct Protective Optimization (DPO), a novel loss function that
effectively disrupts subject personalization in the target model without
compromising generative quality. Moreover, we propose a new dual-path
optimization strategy, coined Learning to Protect (L2P). By alternating between
personalization and protection paths, L2P simulates future personalization
trajectories and adaptively reinforces protection at each step. Experimental
results demonstrate that our framework outperforms existing methods, achieving
state-of-the-art performance in preventing unauthorized personalization. The
code is available at https://github.com/KU-VGI/APDM.

</details>


### [136] [MVSMamba: Multi-View Stereo with State Space Model](https://arxiv.org/abs/2511.01315)
*Jianfei Jiang,Qiankun Liu,Hongyuan Liu,Haochen Yu,Liyong Wang,Jiansheng Chen,Huimin Ma*

Main category: cs.CV

TL;DR: MVSMamba是一种基于Mamba架构的多视图立体（MVS）网络，首次将Mamba引入MVS任务，通过动态Mamba模块实现高效全局特征聚合。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer方法在MVS中因二次复杂度难以平衡性能与效率，而Mamba架构具有全局建模能力和线性复杂度，适合解决这一问题。

Method: 提出MVSMamba网络，采用动态Mamba模块（DM-module）实现参考视图到源视图的高效特征交互、全方位多视图特征表示和多尺度全局特征聚合。

Result: 在DTU数据集和Tanks-and-Temples基准测试中，MVSMamba在性能和效率上均优于现有MVS方法。

Conclusion: MVSMamba通过Mamba架构和动态扫描策略，成功实现了高效且高性能的MVS特征表示，为MVS任务提供了新思路。

Abstract: Robust feature representations are essential for learning-based Multi-View
Stereo (MVS), which relies on accurate feature matching. Recent MVS methods
leverage Transformers to capture long-range dependencies based on local
features extracted by conventional feature pyramid networks. However, the
quadratic complexity of Transformer-based MVS methods poses challenges to
balance performance and efficiency. Motivated by the global modeling capability
and linear complexity of the Mamba architecture, we propose MVSMamba, the first
Mamba-based MVS network. MVSMamba enables efficient global feature aggregation
with minimal computational overhead. To fully exploit Mamba's potential in MVS,
we propose a Dynamic Mamba module (DM-module) based on a novel
reference-centered dynamic scanning strategy, which enables: (1) Efficient
intra- and inter-view feature interaction from the reference to source views,
(2) Omnidirectional multi-view feature representations, and (3) Multi-scale
global feature aggregation. Extensive experimental results demonstrate MVSMamba
outperforms state-of-the-art MVS methods on the DTU dataset and the
Tanks-and-Temples benchmark with both superior performance and efficiency. The
source code is available at https://github.com/JianfeiJ/MVSMamba.

</details>


### [137] [A Generative Adversarial Approach to Adversarial Attacks Guided by Contrastive Language-Image Pre-trained Model](https://arxiv.org/abs/2511.01317)
*Sampriti Soor,Alik Pramanick,Jothiprakash K,Arijit Sur*

Main category: cs.CV

TL;DR: 提出了一种基于CLIP模型的生成对抗攻击方法，通过结合文本和图像表示生成视觉不可察觉的对抗扰动，有效欺骗多标签分类器。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型易受对抗攻击影响，现有方法在视觉保真度和攻击效果上存在不足。

Method: 利用CLIP模型对齐文本和图像表示，结合SSAE和GAMA策略生成对抗扰动。

Result: 在多种黑盒模型上测试，攻击效果优于现有方法，同时保持高视觉保真度。

Conclusion: 该方法在攻击效果和视觉保真度上均表现优异，适用于多目标场景。

Abstract: The rapid growth of deep learning has brought about powerful models that can
handle various tasks, like identifying images and understanding language.
However, adversarial attacks, an unnoticed alteration, can deceive models,
leading to inaccurate predictions. In this paper, a generative adversarial
attack method is proposed that uses the CLIP model to create highly effective
and visually imperceptible adversarial perturbations. The CLIP model's ability
to align text and image representation helps incorporate natural language
semantics with a guided loss to generate effective adversarial examples that
look identical to the original inputs. This integration allows extensive scene
manipulation, creating perturbations in multi-object environments specifically
designed to deceive multilabel classifiers. Our approach integrates the
concentrated perturbation strategy from Saliency-based Auto-Encoder (SSAE) with
the dissimilar text embeddings similar to Generative Adversarial Multi-Object
Scene Attacks (GAMA), resulting in perturbations that both deceive
classification models and maintain high structural similarity to the original
images. The model was tested on various tasks across diverse black-box victim
models. The experimental results show that our method performs competitively,
achieving comparable or superior results to existing techniques, while
preserving greater visual fidelity.

</details>


### [138] [RDTE-UNet: A Boundary and Detail Aware UNet for Precise Medical Image Segmentation](https://arxiv.org/abs/2511.01328)
*Jierui Qu,Jianchun Zhao*

Main category: cs.CV

TL;DR: RDTE-UNet是一种结合局部建模与全局上下文的医学图像分割网络，通过自适应边界增强和细粒度特征建模提升分割精度。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割中解剖结构多变且边界模糊，传统方法难以精确分割细微结构。

Method: 采用混合ResBlock和Transformer的骨干网络，结合ASBE、HVDA和EulerFF模块增强边界和细节。

Result: 在Synapse和BUSI数据集上，RDTE-UNet的分割精度和边界质量达到可比水平。

Conclusion: RDTE-UNet通过多模块协同工作，显著提升了医学图像分割的准确性和边界清晰度。

Abstract: Medical image segmentation is essential for computer-assisted diagnosis and
treatment planning, yet substantial anatomical variability and boundary
ambiguity hinder reliable delineation of fine structures. We propose RDTE-UNet,
a segmentation network that unifies local modeling with global context to
strengthen boundary delineation and detail preservation. RDTE-UNet employs a
hybrid ResBlock detail-aware Transformer backbone and three modules: ASBE for
adaptive boundary enhancement, HVDA for fine-grained feature modeling, and
EulerFF for fusion weighting guided by Euler's formula. Together, these
components improve structural consistency and boundary accuracy across
morphology, orientation, and scale. On Synapse and BUSI dataset, RDTE-UNet has
achieved a comparable level in terms of segmentation accuracy and boundary
quality.

</details>


### [139] [$\left|\,\circlearrowright\,\boxed{\text{BUS}}\,\right|$: A Large and Diverse Multimodal Benchmark for evaluating the ability of Vision-Language Models to understand Rebus Puzzles](https://arxiv.org/abs/2511.01340)
*Trishanu Das,Abhilash Nandy,Khush Bajaj,Deepiha S*

Main category: cs.CV

TL;DR: 论文提出了一个包含1333个英语Rebus Puzzles的多样化基准，并开发了一个模型无关的框架RebusDescProgICE，显著提升了视觉语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: Rebus Puzzles需要多种技能，对当前视觉语言模型具有挑战性，因此需要开发新的基准和方法来提升模型表现。

Method: 提出了RebusDescProgICE框架，结合非结构化描述和基于代码的结构化推理，并改进了上下文示例选择。

Result: 该框架在闭源和开源模型上分别提升了2.1-4.1%和20-30%的性能。

Conclusion: RebusDescProgICE框架有效提升了视觉语言模型在Rebus Puzzles任务上的表现，为复杂推理任务提供了新思路。

Abstract: Understanding Rebus Puzzles (Rebus Puzzles use pictures, symbols, and letters
to represent words or phrases creatively) requires a variety of skills such as
image recognition, cognitive skills, commonsense reasoning, multi-step
reasoning, image-based wordplay, etc., making this a challenging task for even
current Vision-Language Models. In this paper, we present
$\left|\,\circlearrowright\,\boxed{\text{BUS}}\,\right|$, a large and diverse
benchmark of $1,333$ English Rebus Puzzles containing different artistic styles
and levels of difficulty, spread across 18 categories such as food, idioms,
sports, finance, entertainment, etc. We also propose $RebusDescProgICE$, a
model-agnostic framework which uses a combination of an unstructured
description and code-based, structured reasoning, along with better,
reasoning-based in-context example selection, improving the performance of
Vision-Language Models on
$\left|\,\circlearrowright\,\boxed{\text{BUS}}\,\right|$ by $2.1-4.1\%$ and
$20-30\%$ using closed-source and open-source models respectively compared to
Chain-of-Thought Reasoning.

</details>


### [140] [MIQ-SAM3D: From Single-Point Prompt to Multi-Instance Segmentation via Competitive Query Refinement](https://arxiv.org/abs/2511.01345)
*Jierui Qu,Jianchun Zhao*

Main category: cs.CV

TL;DR: MIQ-SAM3D是一种多实例3D分割框架，通过竞争查询优化策略实现单点到多实例的转换，提升了医学图像中多病灶分割的效率。


<details>
  <summary>Details</summary>
Motivation: 现有SAM-based交互式分割方法多为单点到单对象模式，限制了多病灶分割能力，且ViT主干网络常忽略局部细节。

Method: 提出MIQ-SAM3D框架，结合CNN-Transformer编码器注入边界显著性，并通过竞争优化的查询解码器实现并行多实例预测。

Result: 在LiTS17和KiTS21数据集上表现优异，对提示具有强鲁棒性。

Conclusion: MIQ-SAM3D为临床多病灶标注提供了高效解决方案。

Abstract: Accurate segmentation of medical images is fundamental to tumor diagnosis and
treatment planning. SAM-based interactive segmentation has gained attention for
its strong generalization, but most methods follow a
single-point-to-single-object paradigm, which limits multi-lesion segmentation.
Moreover, ViT backbones capture global context but often miss high-fidelity
local details. We propose MIQ-SAM3D, a multi-instance 3D segmentation framework
with a competitive query optimization strategy that shifts from
single-point-to-single-mask to single-point-to-multi-instance. A
prompt-conditioned instance-query generator transforms a single point prompt
into multiple specialized queries, enabling retrieval of all semantically
similar lesions across the 3D volume from a single exemplar. A hybrid
CNN-Transformer encoder injects CNN-derived boundary saliency into ViT
self-attention via spatial gating. A competitively optimized query decoder then
enables end-to-end, parallel, multi-instance prediction through inter-query
competition. On LiTS17 and KiTS21 dataset, MIQ-SAM3D achieved comparable levels
and exhibits strong robustness to prompts, providing a practical solution for
efficient annotation of clinically relevant multi-lesion cases.

</details>


### [141] [Expanding the Content-Style Frontier: a Balanced Subspace Blending Approach for Content-Style LoRA Fusion](https://arxiv.org/abs/2511.01355)
*Linhao Huang*

Main category: cs.CV

TL;DR: 提出了一种通过内容-风格子空间混合和平衡损失来扩展内容-风格边界的新方法，显著提升了不同风格强度下的内容相似性。


<details>
  <summary>Details</summary>
Motivation: 现有研究仅在单一风格强度下评估内容相似性，而增加风格强度会导致内容特征显著丢失，导致内容-风格边界不理想。

Method: 采用内容-风格子空间混合和内容-风格平衡损失来优化内容-风格边界。

Result: 在定性和定量评估中均优于现有技术，实现了更优的内容-风格权衡，IGD和GD分数显著降低。

Conclusion: 该方法有效扩展了内容-风格边界，提升了生成图像的内容相似性和风格多样性。

Abstract: Recent advancements in text-to-image diffusion models have significantly
improved the personalization and stylization of generated images. However,
previous studies have only assessed content similarity under a single style
intensity. In our experiments, we observe that increasing style intensity leads
to a significant loss of content features, resulting in a suboptimal
content-style frontier. To address this, we propose a novel approach to expand
the content-style frontier by leveraging Content-Style Subspace Blending and a
Content-Style Balance loss. Our method improves content similarity across
varying style intensities, significantly broadening the content-style frontier.
Extensive experiments demonstrate that our approach outperforms existing
techniques in both qualitative and quantitative evaluations, achieving superior
content-style trade-off with significantly lower Inverted Generational Distance
(IGD) and Generational Distance (GD) scores compared to current methods.

</details>


### [142] [CMI-MTL: Cross-Mamba interaction based multi-task learning for medical visual question answering](https://arxiv.org/abs/2511.01357)
*Qiangguo Jin,Xianyao Zheng,Hui Cui,Changming Sun,Yuqi Fang,Cong Cong,Ran Su,Leyi Wei,Ping Xuan,Junbo Wang*

Main category: cs.CV

TL;DR: 提出了一种基于Cross-Mamba Interaction的多任务学习框架（CMI-MTL），用于解决医学视觉问答（Med-VQA）中的跨模态语义对齐和自由形式答案多样性问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以有效处理视觉与语言的跨模态语义对齐，且分类方法无法适应自由形式答案的多样性。

Method: CMI-MTL包含三个模块：细粒度视觉-文本特征对齐（FVTA）、跨模态交错特征表示（CIFR）和自由形式答案增强的多任务学习（FFAE）。

Result: 在三个Med-VQA数据集（VQA-RAD、SLAKE、OVQA）上表现优于现有方法，并通过可解释性实验验证了有效性。

Conclusion: CMI-MTL通过跨模态交互和多任务学习提升了Med-VQA的性能，适用于自由形式答案的多样性场景。

Abstract: Medical visual question answering (Med-VQA) is a crucial multimodal task in
clinical decision support and telemedicine. Recent self-attention based methods
struggle to effectively handle cross-modal semantic alignments between vision
and language. Moreover, classification-based methods rely on predefined answer
sets. Treating this task as a simple classification problem may make it unable
to adapt to the diversity of free-form answers and overlook the detailed
semantic information of free-form answers. In order to tackle these challenges,
we introduce a Cross-Mamba Interaction based Multi-Task Learning (CMI-MTL)
framework that learns cross-modal feature representations from images and
texts. CMI-MTL comprises three key modules: fine-grained visual-text feature
alignment (FVTA), cross-modal interleaved feature representation (CIFR), and
free-form answer-enhanced multi-task learning (FFAE). FVTA extracts the most
relevant regions in image-text pairs through fine-grained visual-text feature
alignment. CIFR captures cross-modal sequential interactions via cross-modal
interleaved feature representation. FFAE leverages auxiliary knowledge from
open-ended questions through free-form answer-enhanced multi-task learning,
improving the model's capability for open-ended Med-VQA. Experimental results
show that CMI-MTL outperforms the existing state-of-the-art methods on three
Med-VQA datasets: VQA-RAD, SLAKE, and OVQA. Furthermore, we conduct more
interpretability experiments to prove the effectiveness. The code is publicly
available at https://github.com/BioMedIA-repo/CMI-MTL.

</details>


### [143] [SEPS: Semantic-enhanced Patch Slimming Framework for fine-grained cross-modal alignment](https://arxiv.org/abs/2511.01390)
*Xinyu Mao,Junsi Li,Haoji Zhang,Yu Liang,Ming Sun*

Main category: cs.CV

TL;DR: SEPS框架通过整合密集和稀疏文本的统一语义，解决视觉与语言细粒度对齐中的冗余和模糊问题，显著提升跨模态相似性评估。


<details>
  <summary>Details</summary>
Motivation: 当前方法在处理视觉与语言细粒度对齐时面临冗余和模糊问题，且多模态大语言模型的密集输出可能与原始稀疏描述冲突。

Method: 提出SEPS框架，采用两阶段机制整合统一语义，并通过相关性感知选择和均值计算突出关键补丁-词对应关系。

Result: 在Flickr30K和MS-COCO数据集上，SEPS性能显著优于现有方法，rSum提升23%-86%。

Conclusion: SEPS有效解决了跨模态对齐中的冗余和模糊问题，提升了细粒度对齐性能。

Abstract: Fine-grained cross-modal alignment aims to establish precise local
correspondences between vision and language, forming a cornerstone for visual
question answering and related multimodal applications. Current approaches face
challenges in addressing patch redundancy and ambiguity, which arise from the
inherent information density disparities across modalities. Recently,
Multimodal Large Language Models (MLLMs) have emerged as promising solutions to
bridge this gap through their robust semantic generation capabilities. However,
the dense textual outputs from MLLMs may introduce conflicts with the original
sparse captions. Furthermore, accurately quantifying semantic relevance between
rich visual patches and concise textual descriptions remains a core challenge.
To overcome these limitations, we introduce the Semantic-Enhanced Patch
Slimming (SEPS) framework, which systematically addresses patch redundancy and
ambiguity. Our approach employs a two-stage mechanism to integrate unified
semantics from both dense and sparse texts, enabling the identification of
salient visual patches. Additionally, it leverages relevance-aware selection
with mean value computation to highlight crucial patch-word correspondences,
thereby improving cross-modal similarity assessment. Comprehensive experiments
on Flickr30K and MS-COCO datasets validate that SEPS achieves superior
performance, surpassing existing approaches by 23\%-86\% in rSum across diverse
model architectures, with notable enhancements in text-to-image retrieval
scenarios. Our implementation is available at
https://github.com/Sweet4tars/seps.git.

</details>


### [144] [Semantic BIM enrichment for firefighting assets: Fire-ART dataset and panoramic image-based 3D reconstruction](https://arxiv.org/abs/2511.01399)
*Ya Wen,Yutong Qiao,Chi Chiu Lam,Ioannis Brilakis,Sanghoon Lee,Mun On Wong*

Main category: cs.CV

TL;DR: 本文提出了Fire-ART数据集和全景图像重建方法，用于消防资产的语义识别和BIM模型重建，解决了传统方法效率低下的问题。


<details>
  <summary>Details</summary>
Motivation: 传统消防资产管理方法效率低下，缺乏自动化识别和重建能力，亟需改进。

Method: 开发了Fire-ART数据集（15类资产，2626张图像），并采用改进的立方体映射和球形相机投影方法进行资产重建。

Result: 在两个实际案例中，F1分数分别为73%和88%，定位误差为0.620和0.428米。

Conclusion: Fire-ART数据集和重建方法为消防设备的数字化管理提供了有效解决方案。

Abstract: Inventory management of firefighting assets is crucial for emergency
preparedness, risk assessment, and on-site fire response. However, conventional
methods are inefficient due to limited capabilities in automated asset
recognition and reconstruction. To address the challenge, this research
introduces the Fire-ART dataset and develops a panoramic image-based
reconstruction approach for semantic enrichment of firefighting assets into BIM
models. The Fire-ART dataset covers 15 fundamental assets, comprising 2,626
images and 6,627 instances, making it an extensive and publicly accessible
dataset for asset recognition. In addition, the reconstruction approach
integrates modified cube-map conversion and radius-based spherical camera
projection to enhance recognition and localization accuracy. Through
validations with two real-world case studies, the proposed approach achieves
F1-scores of 73% and 88% and localization errors of 0.620 and 0.428 meters,
respectively. The Fire-ART dataset and the reconstruction approach offer
valuable resources and robust technical solutions to enhance the accurate
digital management of fire safety equipment.

</details>


### [145] [Extremal Contours: Gradient-driven contours for compact visual attribution](https://arxiv.org/abs/2511.01411)
*Reza Karimzadeh,Albert Alonso,Frans Zdyb,Julius B. Kirkegaard,Bulat Ibragimov*

Main category: cs.CV

TL;DR: 提出了一种基于平滑可调轮廓的训练无关解释方法，替代传统密集扰动掩码，优化极值保留/删除目标，生成紧凑、可解释的区域。


<details>
  <summary>Details</summary>
Motivation: 传统密集扰动掩码存在碎片化和过拟合问题，需要复杂后处理，因此需要更简洁、稳定的解释方法。

Method: 使用截断傅里叶级数参数化星凸区域，通过分类器梯度优化极值目标，生成单连通掩码。

Result: 在ImageNet分类器上，与密集掩码相比，保持了极值保真度，同时提高了运行一致性，并支持多轮廓扩展。

Conclusion: 该方法在多个基准测试中表现优于梯度与扰动基线，尤其在自监督DINO模型上显著提升了相关性质量。

Abstract: Faithful yet compact explanations for vision models remain a challenge, as
commonly used dense perturbation masks are often fragmented and overfitted,
needing careful post-processing. Here, we present a training-free explanation
method that replaces dense masks with smooth tunable contours. A star-convex
region is parameterized by a truncated Fourier series and optimized under an
extremal preserve/delete objective using the classifier gradients. The approach
guarantees a single, simply connected mask, cuts the number of free parameters
by orders of magnitude, and yields stable boundary updates without cleanup.
Restricting solutions to low-dimensional, smooth contours makes the method
robust to adversarial masking artifacts. On ImageNet classifiers, it matches
the extremal fidelity of dense masks while producing compact, interpretable
regions with improved run-to-run consistency. Explicit area control also
enables importance contour maps, yielding a transparent fidelity-area profiles.
Finally, we extend the approach to multi-contour and show how it can localize
multiple objects within the same framework. Across benchmarks, the method
achieves higher relevance mass and lower complexity than gradient and
perturbation based baselines, with especially strong gains on self-supervised
DINO models where it improves relevance mass by over 15% and maintains positive
faithfulness correlations.

</details>


### [146] [Towards One-step Causal Video Generation via Adversarial Self-Distillation](https://arxiv.org/abs/2511.01419)
*Yongqi Yang,Huayang Huang,Xu Peng,Xiaobin Hu,Donghao Luo,Jiangning Zhang,Chengjie Wang,Yu Wu*

Main category: cs.CV

TL;DR: 提出了一种基于蒸馏的高效因果视频生成框架，通过对抗自蒸馏策略和首帧增强策略，显著提升了极少数去噪步骤下的生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有混合视频生成模型存在误差累积和推理时间长的问题，需要一种更高效的生成方法。

Method: 采用对抗自蒸馏（ASD）策略和首帧增强（FFE）策略，结合分布匹配蒸馏框架。

Result: 在VBench上实验表明，该方法在一步和两步视频生成中优于现有技术。

Conclusion: 提出的框架通过单一蒸馏模型支持多种推理步骤设置，实现了高效高质量的视频合成。

Abstract: Recent hybrid video generation models combine autoregressive temporal
dynamics with diffusion-based spatial denoising, but their sequential,
iterative nature leads to error accumulation and long inference times. In this
work, we propose a distillation-based framework for efficient causal video
generation that enables high-quality synthesis with extremely limited denoising
steps. Our approach builds upon the Distribution Matching Distillation (DMD)
framework and proposes a novel Adversarial Self-Distillation (ASD) strategy,
which aligns the outputs of the student model's n-step denoising process with
its (n+1)-step version at the distribution level. This design provides smoother
supervision by bridging small intra-student gaps and more informative guidance
by combining teacher knowledge with locally consistent student behavior,
substantially improving training stability and generation quality in extremely
few-step scenarios (e.g., 1-2 steps). In addition, we present a First-Frame
Enhancement (FFE) strategy, which allocates more denoising steps to the initial
frames to mitigate error propagation while applying larger skipping steps to
later frames. Extensive experiments on VBench demonstrate that our method
surpasses state-of-the-art approaches in both one-step and two-step video
generation. Notably, our framework produces a single distilled model that
flexibly supports multiple inference-step settings, eliminating the need for
repeated re-distillation and enabling efficient, high-quality video synthesis.

</details>


### [147] [UniSOT: A Unified Framework for Multi-Modality Single Object Tracking](https://arxiv.org/abs/2511.01427)
*Yinchao Ma,Yuyang Tang,Wenfei Yang,Tianzhu Zhang,Xu Zhou,Feng Wu*

Main category: cs.CV

TL;DR: UniSOT是一个统一的目标跟踪器，支持多种参考模态和视频模态，性能优于特定模态的跟踪器。


<details>
  <summary>Details</summary>
Motivation: 现有跟踪器仅针对单一或几种模态设计，限制了实际应用，需要一种统一的方法。

Method: 提出UniSOT，支持三种参考模态和四种视频模态的统一跟踪器。

Result: 在18个基准测试中表现优异，性能超过特定模态跟踪器3.0%以上。

Conclusion: UniSOT展示了统一跟踪器的潜力，适用于复杂场景。

Abstract: Single object tracking aims to localize target object with specific reference
modalities (bounding box, natural language or both) in a sequence of specific
video modalities (RGB, RGB+Depth, RGB+Thermal or RGB+Event.). Different
reference modalities enable various human-machine interactions, and different
video modalities are demanded in complex scenarios to enhance tracking
robustness. Existing trackers are designed for single or several video
modalities with single or several reference modalities, which leads to separate
model designs and limits practical applications. Practically, a unified tracker
is needed to handle various requirements. To the best of our knowledge, there
is still no tracker that can perform tracking with these above reference
modalities across these video modalities simultaneously. Thus, in this paper,
we present a unified tracker, UniSOT, for different combinations of three
reference modalities and four video modalities with uniform parameters.
Extensive experimental results on 18 visual tracking, vision-language tracking
and RGB+X tracking benchmarks demonstrate that UniSOT shows superior
performance against modality-specific counterparts. Notably, UniSOT outperforms
previous counterparts by over 3.0\% AUC on TNL2K across all three reference
modalities and outperforms Un-Track by over 2.0\% main metric across all three
RGB+X video modalities.

</details>


### [148] [Terrain-Enhanced Resolution-aware Refinement Attention for Off-Road Segmentation](https://arxiv.org/abs/2511.01434)
*Seongkyu Choi,Jhonghyun An*

Main category: cs.CV

TL;DR: 提出了一种分辨率感知的标记解码器，用于解决越野语义分割中的边界模糊、稀疏监督和标签噪声问题。


<details>
  <summary>Details</summary>
Motivation: 越野语义分割面临边界不一致、稀有类别监督稀疏和标签噪声等问题，现有方法在高分辨率融合时成本高且对噪声敏感。

Method: 设计了一种分辨率感知的标记解码器，结合全局语义、局部一致性和边界保真度，通过低分辨率瓶颈计算，稀疏选择像素进行细化。

Result: 在边界保真度和全局语义上表现优异，且对噪声具有稳定性。

Conclusion: 该方法在越野语义分割中表现出竞争性性能和稳定性。

Abstract: Off-road semantic segmentation suffers from thick, inconsistent boundaries,
sparse supervision for rare classes, and pervasive label noise. Designs that
fuse only at low resolution blur edges and propagate local errors, whereas
maintaining high-resolution pathways or repeating high-resolution fusions is
costly and fragile to noise. We introduce a resolutionaware token decoder that
balances global semantics, local consistency, and boundary fidelity under
imperfect supervision. Most computation occurs at a low-resolution bottleneck;
a gated cross-attention injects fine-scale detail, and only a sparse,
uncertainty-selected set of pixels is refined. The components are co-designed
and tightly integrated: global self-attention with lightweight dilated
depthwise refinement restores local coherence; a gated cross-attention
integrates fine-scale features from a standard high-resolution encoder stream
without amplifying noise; and a class-aware point refinement corrects residual
ambiguities with negligible overhead. During training, we add a boundary-band
consistency regularizer that encourages coherent predictions in a thin
neighborhood around annotated edges, with no inference-time cost. Overall, the
results indicate competitive performance and improved stability across
transitions.

</details>


### [149] [Contrast-Guided Cross-Modal Distillation for Thermal Object Detection](https://arxiv.org/abs/2511.01435)
*SiWoo Kim,JhongHyun An*

Main category: cs.CV

TL;DR: 提出了一种针对热红外检测的训练方法，通过优化特征表示和引入跨模态语义先验，解决了夜间检测中的低对比度和高频线索不足问题。


<details>
  <summary>Details</summary>
Motivation: 夜间热红外检测存在低对比度和高频线索不足的问题，导致重复检测、小物体遗漏和类别混淆。现有方法要么依赖RGB转换，要么需要多传感器融合，但均未直接优化热红外表示。

Method: 在训练阶段引入实例级决策边界优化和跨模态特征对齐，通过拉近同类特征和推远异类特征来抑制重复检测，同时利用RGB预训练模型增强热红外特征。

Result: 实验表明，该方法优于现有方法，达到了最先进的性能。

Conclusion: 通过优化训练目标和引入跨模态先验，有效提升了热红外检测的鲁棒性，且无需额外传感器或运行时成本。

Abstract: Robust perception at night remains challenging for thermal-infrared
detection: low contrast and weak high-frequency cues lead to duplicate,
overlapping boxes, missed small objects, and class confusion. Prior remedies
either translate TIR to RGB and hope pixel fidelity transfers to detection --
making performance fragile to color or structure artifacts -- or fuse RGB and
TIR at test time, which requires extra sensors, precise calibration, and higher
runtime cost. Both lines can help in favorable conditions, but do not directly
shape the thermal representation used by the detector. We keep mono-modality
inference and tackle the root causes during training. Specifically, we
introduce training-only objectives that sharpen instance-level decision
boundaries by pulling together features of the same class and pushing apart
those of different classes -- suppressing duplicate and confusing detections --
and that inject cross-modal semantic priors by aligning the student's
multi-level pyramid features with an RGB-trained teacher, thereby strengthening
texture-poor thermal features without visible input at test time. In
experiments, our method outperformed prior approaches and achieved
state-of-the-art performance.

</details>


### [150] [Privacy Preserving Ordinal-Meta Learning with VLMs for Fine-Grained Fruit Quality Prediction](https://arxiv.org/abs/2511.01449)
*Riddhi Jain,Manasi Patwardhan,Aayush Mishra,Parijat Deshpande,Beena Rai*

Main category: cs.CV

TL;DR: 提出了一种名为MAOML的算法，通过元学习和序数回归解决数据稀缺问题，提升了水果新鲜度分类任务的性能。


<details>
  <summary>Details</summary>
Motivation: 由于专家标注成本高，数据稀缺，且现有开源模型性能不足，需要一种高效的方法来训练小型视觉语言模型。

Method: 采用模型无关的序元学习算法（MAOML），结合元学习和标签序数性，优化模型训练。

Result: 在零样本和少样本设置下，平均准确率达到92.71%，优于现有开源模型。

Conclusion: MAOML算法在数据稀缺情况下显著提升了水果新鲜度分类的性能，为食品零售行业提供了实用解决方案。

Abstract: To effectively manage the wastage of perishable fruits, it is crucial to
accurately predict their freshness or shelf life using non-invasive methods
that rely on visual data. In this regard, deep learning techniques can offer a
viable solution. However, obtaining fine-grained fruit freshness labels from
experts is costly, leading to a scarcity of data. Closed proprietary Vision
Language Models (VLMs), such as Gemini, have demonstrated strong performance in
fruit freshness detection task in both zero-shot and few-shot settings.
Nonetheless, food retail organizations are unable to utilize these proprietary
models due to concerns related to data privacy, while existing open-source VLMs
yield sub-optimal performance for the task. Fine-tuning these open-source
models with limited data fails to achieve the performance levels of proprietary
models. In this work, we introduce a Model-Agnostic Ordinal Meta-Learning
(MAOML) algorithm, designed to train smaller VLMs. This approach utilizes
meta-learning to address data sparsity and leverages label ordinality, thereby
achieving state-of-the-art performance in the fruit freshness classification
task under both zero-shot and few-shot settings. Our method achieves an
industry-standard accuracy of 92.71%, averaged across all fruits.
  Keywords: Fruit Quality Prediction, Vision Language Models, Meta Learning,
Ordinal Regression

</details>


### [151] [Reg-DPO: SFT-Regularized Direct Preference Optimization with GT-Pair for Improving Video Generation](https://arxiv.org/abs/2511.01450)
*Jie Du,Xinyu Gong,Qingshan Tan,Wen Li,Yangming Cheng,Weitao Wang,Chenlu Zhan,Suhui Wu,Hao Zhang,Jun Zhang*

Main category: cs.CV

TL;DR: 论文提出了一种名为GT-Pair和Reg-DPO的方法，用于提升视频生成质量，解决了现有方法在小规模模型上的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要基于图像领域范式，且在小规模模型上开发，无法有效解决视频任务中的独特挑战，如数据构建成本高、训练不稳定和内存消耗大。

Method: 引入GT-Pair自动构建高质量偏好对，并提出Reg-DPO，将SFT损失作为正则项融入DPO目标，结合FSDP框架和内存优化技术提升训练能力。

Result: 在多个数据集上的I2V和T2V任务中，方法表现优于现有方法，生成质量更高。

Conclusion: GT-Pair和Reg-DPO有效解决了视频生成中的挑战，提升了训练稳定性和生成质量。

Abstract: Recent studies have identified Direct Preference Optimization (DPO) as an
efficient and reward-free approach to improving video generation quality.
However, existing methods largely follow image-domain paradigms and are mainly
developed on small-scale models (approximately 2B parameters), limiting their
ability to address the unique challenges of video tasks, such as costly data
construction, unstable training, and heavy memory consumption. To overcome
these limitations, we introduce a GT-Pair that automatically builds
high-quality preference pairs by using real videos as positives and
model-generated videos as negatives, eliminating the need for any external
annotation. We further present Reg-DPO, which incorporates the SFT loss as a
regularization term into the DPO objective to enhance training stability and
generation fidelity. Additionally, by combining the FSDP framework with
multiple memory optimization techniques, our approach achieves nearly three
times higher training capacity than using FSDP alone. Extensive experiments on
both I2V and T2V tasks across multiple datasets demonstrate that our method
consistently outperforms existing approaches, delivering superior video
generation quality.

</details>


### [152] [When to Trust the Answer: Question-Aligned Semantic Nearest Neighbor Entropy for Safer Surgical VQA](https://arxiv.org/abs/2511.01458)
*Dennis Pierantozzi,Luca Carlini,Mauro Orazio Drago,Chiara Lena,Cesare Hassan,Elena De Momi,Danail Stoyanov,Sophia Bano,Mobarak I. Hoque*

Main category: cs.CV

TL;DR: 论文提出了一种名为QA-SNNE的黑盒不确定性估计方法，用于提高手术视觉问答（VQA）的安全性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 手术VQA中错误或模糊的回答可能对患者造成伤害，现有研究多关注准确性而忽视安全性行为。

Method: 引入QA-SNNE，通过将问题语义融入预测置信度，测量语义熵。

Result: QA-SNNE显著提高了零样本模型的AUROC（15-38%），并在幻觉检测中表现优异。

Conclusion: QA-SNNE结合LVLM骨干网络，可提升手术VQA的安全性和临床医生信任度。

Abstract: Safety and reliability are essential for deploying Visual Question Answering
(VQA) in surgery, where incorrect or ambiguous responses can harm the patient.
Most surgical VQA research focuses on accuracy or linguistic quality while
overlooking safety behaviors such as ambiguity awareness, referral to human
experts, or triggering a second opinion. Inspired by Automatic Failure
Detection (AFD), we study uncertainty estimation as a key enabler of safer
decision making. We introduce Question Aligned Semantic Nearest Neighbor
Entropy (QA-SNNE), a black box uncertainty estimator that incorporates question
semantics into prediction confidence. It measures semantic entropy by comparing
generated answers with nearest neighbors in a medical text embedding space,
conditioned on the question. We evaluate five models, including domain specific
Parameter-Efficient Fine-Tuned (PEFT) models and zero-shot Large
Vision-Language Models (LVLMs), on EndoVis18-VQA and PitVQA. PEFT models
degrade under mild paraphrasing, while LVLMs are more resilient. Across three
LVLMs and two PEFT baselines, QA-SNNE improves AUROC in most in-template
settings and enhances hallucination detection. The Area Under the ROC Curve
(AUROC) increases by 15-38% for zero-shot models, with gains maintained under
out-of-template stress. QA-SNNE offers a practical and interpretable step
toward AFD in surgical VQA by linking semantic uncertainty to question context.
Combining LVLM backbones with question aligned uncertainty estimation can
improve safety and clinician trust. The code and model are available at
https://github.com/DennisPierantozzi/QASNNE

</details>


### [153] [Efficiently Training A Flat Neural Network Before It has been Quantizated](https://arxiv.org/abs/2511.01462)
*Peng Xia,Junbiao Pang,Tianyang Cai*

Main category: cs.CV

TL;DR: 论文提出了一种通过预条件化模型来减少量化误差的方法，重点关注激活和权重量化误差的统计建模。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视了全精度模型与量化模型之间的关系，导致较大的量化误差。

Method: 提出了一种框架，通过统计建模激活和权重量化误差为独立高斯噪声，并研究噪声注入优化方法以获得平坦最小值。

Result: 实验证明了方法的有效性，为低比特PTQ模型提供了新途径。

Conclusion: 平坦的全精度神经网络对低比特量化至关重要，该方法为量化误差问题提供了有效解决方案。

Abstract: Post-training quantization (PTQ) for vision transformers (ViTs) has garnered
significant attention due to its efficiency in compressing models. However,
existing methods typically overlook the relationship between a well-trained NN
and the quantized model, leading to considerable quantization error for PTQ.
However, it is unclear how to efficiently train a model-agnostic neural network
which is tailored for a predefined precision low-bit model. In this paper, we
firstly discover that a flat full precision neural network is crucial for
low-bit quantization. To achieve this, we propose a framework that proactively
pre-conditions the model by measuring and disentangling the error sources.
Specifically, both the Activation Quantization Error (AQE) and the Weight
Quantization Error (WQE) are statistically modeled as independent Gaussian
noises. We study several noise injection optimization methods to obtain a flat
minimum. Experimental results attest to the effectiveness of our approach.
These results open novel pathways for obtaining low-bit PTQ models.

</details>


### [154] [HMVLM: Human Motion-Vision-Lanuage Model via MoE LoRA](https://arxiv.org/abs/2511.01463)
*Lei Hu,Yongjing Ye,Shihong Xia*

Main category: cs.CV

TL;DR: 论文提出了一种基于MoE LoRA策略的统一框架HMVLM，解决了多模态集成中的灾难性遗忘问题，并提升了姿态表示的性能。


<details>
  <summary>Details</summary>
Motivation: 解决人类运动与文本之间的模态差距导致的灾难性遗忘问题，以及开发跨任务通用的自回归兼容姿态表示。

Method: 采用MoE LoRA策略，通过门控网络动态分配LoRA专家权重，并引入零专家保留预训练参数；通过身体部位特定标记化增强姿态表示。

Result: 实验表明，该方法有效缓解了指令调优中的知识遗忘，并在多样的人类运动下游任务中表现出色。

Conclusion: HMVLM框架在多模态集成和姿态表示方面取得了显著进展。

Abstract: The expansion of instruction-tuning data has enabled foundation language
models to exhibit improved instruction adherence and superior performance
across diverse downstream tasks. Semantically-rich 3D human motion is being
progressively integrated with these foundation models to enhance multimodal
understanding and cross-modal generation capabilities. However, the modality
gap between human motion and text raises unresolved concerns about catastrophic
forgetting during this integration. In addition, developing
autoregressive-compatible pose representations that preserve generalizability
across heterogeneous downstream tasks remains a critical technical barrier. To
address these issues, we propose the Human Motion-Vision-Language Model
(HMVLM), a unified framework based on the Mixture of Expert Low-Rank
Adaption(MoE LoRA) strategy. The framework leverages the gating network to
dynamically allocate LoRA expert weights based on the input prompt, enabling
synchronized fine-tuning of multiple tasks. To mitigate catastrophic forgetting
during instruction-tuning, we introduce a novel zero expert that preserves the
pre-trained parameters for general linguistic tasks. For pose representation,
we implement body-part-specific tokenization by partitioning the human body
into different joint groups, enhancing the spatial resolution of the
representation. Experiments show that our method effectively alleviates
knowledge forgetting during instruction-tuning and achieves remarkable
performance across diverse human motion downstream tasks.

</details>


### [155] [SecDiff: Diffusion-Aided Secure Deep Joint Source-Channel Coding Against Adversarial Attacks](https://arxiv.org/abs/2511.01466)
*Changyuan Zhao,Jiacheng Wang,Ruichen Zhang,Dusit Niyato,Hongyang Du,Zehui Xiong,Dong In Kim,Ping Zhang*

Main category: cs.CV

TL;DR: SecDiff是一个基于扩散的解码框架，显著提升了深度联合源信道编码（JSCC）在对抗性无线环境中的安全性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有JSCC框架易受物理层对抗威胁（如导频欺骗和子载波干扰）影响，导致语义保真度下降。

Method: 采用伪逆引导采样和自适应引导权重，提出功率子载波掩码策略和EM驱动的重建算法。

Result: 在对抗条件下，SecDiff在重建质量和计算成本之间取得了良好平衡，优于现有方法。

Conclusion: SecDiff为低延迟、抗攻击的语义通信提供了实用解决方案。

Abstract: Deep joint source-channel coding (JSCC) has emerged as a promising paradigm
for semantic communication, delivering significant performance gains over
conventional separate coding schemes. However, existing JSCC frameworks remain
vulnerable to physical-layer adversarial threats, such as pilot spoofing and
subcarrier jamming, compromising semantic fidelity. In this paper, we propose
SecDiff, a plug-and-play, diffusion-aided decoding framework that significantly
enhances the security and robustness of deep JSCC under adversarial wireless
environments. Different from prior diffusion-guided JSCC methods that suffer
from high inference latency, SecDiff employs pseudoinverse-guided sampling and
adaptive guidance weighting, enabling flexible step-size control and efficient
semantic reconstruction. To counter jamming attacks, we introduce a power-based
subcarrier masking strategy and recast recovery as a masked inpainting problem,
solved via diffusion guidance. For pilot spoofing, we formulate channel
estimation as a blind inverse problem and develop an expectation-minimization
(EM)-driven reconstruction algorithm, guided jointly by reconstruction loss and
a channel operator. Notably, our method alternates between pilot recovery and
channel estimation, enabling joint refinement of both variables throughout the
diffusion process. Extensive experiments over orthogonal frequency-division
multiplexing (OFDM) channels under adversarial conditions show that SecDiff
outperforms existing secure and generative JSCC baselines by achieving a
favorable trade-off between reconstruction quality and computational cost. This
balance makes SecDiff a promising step toward practical, low-latency, and
attack-resilient semantic communications.

</details>


### [156] [EPAN: Robust Pedestrian Re-Identification via Enhanced Alignment Network for IoT Surveillance](https://arxiv.org/abs/2511.01498)
*Zhiyang Jia,Hongyan Cui,Ge Gao,Bo Li,Minjie Zhang,Zishuo Gao,Huiwen Huang,Caisheng Zhuo*

Main category: cs.CV

TL;DR: EPAN是一种用于物联网监控环境下行人重识别的双分支网络，通过提取多尺度和多视角的对齐信息，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 解决物联网监控环境中因视角和环境变化导致的行人重识别性能下降问题。

Method: 采用双分支架构，提取多尺度和多视角的对齐信息。

Result: 在Inspection-Personnel数据集上达到Rank-1准确率90.09%和mAP 78.82%。

Conclusion: EPAN在物联网监控系统中具有实际应用潜力，能够实现跨摄像头的可靠行人重识别。

Abstract: Person re-identification (ReID) plays a pivotal role in computer vision,
particularly in surveillance and security applications within IoT-enabled smart
environments. This study introduces the Enhanced Pedestrian Alignment Network
(EPAN), tailored for robust ReID across diverse IoT surveillance conditions.
EPAN employs a dual-branch architecture to mitigate the impact of perspective
and environmental changes, extracting alignment information under varying
scales and viewpoints. Here, we demonstrate EPAN's strong feature extraction
capabilities, achieving outstanding performance on the Inspection-Personnel
dataset with a Rank-1 accuracy of 90.09% and a mean Average Precision (mAP) of
78.82%. This highlights EPAN's potential for real-world IoT applications,
enabling effective and reliable person ReID across diverse cameras in
surveillance and security systems. The code and data are available at:
https://github.com/ggboy2580/EPAN

</details>


### [157] [Luminance-Aware Statistical Quantization: Unsupervised Hierarchical Learning for Illumination Enhancement](https://arxiv.org/abs/2511.01510)
*Derong Kong,Zhixiong Yang,Shengxi Li,Shuaifeng Zhi,Li Liu,Zhen Liu,Jingyuan Xia*

Main category: cs.CV

TL;DR: 论文提出了一种基于统计采样的低光图像增强框架LASQ，通过分层亮度分布的概率采样替代确定性映射，提高了无参考情况下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注确定性像素级映射，忽略了真实环境中亮度过渡的连续物理过程，导致在无正常光参考时性能下降。

Method: 引入Luminance-Aware Statistical Quantification (LASQ)，将亮度过渡建模为强度坐标空间中的幂律分布，并通过扩散前向过程自主发现最优过渡路径。

Result: LASQ在无参考情况下显著提升性能，同时在有参考情况下在特定领域数据集上表现优异，并具有更好的跨数据集泛化能力。

Conclusion: LASQ通过统计采样和分层亮度分布建模，实现了更灵活和通用的低光图像增强，适用于有无参考的多种场景。

Abstract: Low-light image enhancement (LLIE) faces persistent challenges in balancing
reconstruction fidelity with cross-scenario generalization. While existing
methods predominantly focus on deterministic pixel-level mappings between
paired low/normal-light images, they often neglect the continuous physical
process of luminance transitions in real-world environments, leading to
performance drop when normal-light references are unavailable. Inspired by
empirical analysis of natural luminance dynamics revealing power-law
distributed intensity transitions, this paper introduces Luminance-Aware
Statistical Quantification (LASQ), a novel framework that reformulates LLIE as
a statistical sampling process over hierarchical luminance distributions. Our
LASQ re-conceptualizes luminance transition as a power-law distribution in
intensity coordinate space that can be approximated by stratified power
functions, therefore, replacing deterministic mappings with probabilistic
sampling over continuous luminance layers. A diffusion forward process is
designed to autonomously discover optimal transition paths between luminance
layers, achieving unsupervised distribution emulation without normal-light
references. In this way, it considerably improves the performance in practical
situations, enabling more adaptable and versatile light restoration. This
framework is also readily applicable to cases with normal-light references,
where it achieves superior performance on domain-specific datasets alongside
better generalization-ability across non-reference datasets.

</details>


### [158] [Example-Based Feature Painting on Textures](https://arxiv.org/abs/2511.01513)
*Andrei-Timotei Ardelean,Tim Weyrich*

Main category: cs.CV

TL;DR: 提出了一种基于学习的纹理编辑系统，通过无监督异常检测和自动聚类实现局部特征控制。


<details>
  <summary>Details</summary>
Motivation: 自然纹理中的局部特征（如污渍、破损等）对真实感至关重要，但现有方法需要手动标注。

Method: 采用无监督异常检测和自动聚类，结合扩散模型进行交互式纹理生成。

Result: 实现了无需标注的纹理编辑，支持无限纹理生成和交互式特征绘制。

Conclusion: 该方法通用性强，适用于其他扩散模型应用。

Abstract: In this work, we propose a system that covers the complete workflow for
achieving controlled authoring and editing of textures that present distinctive
local characteristics. These include various effects that change the surface
appearance of materials, such as stains, tears, holes, abrasions,
discoloration, and more. Such alterations are ubiquitous in nature, and
including them in the synthesis process is crucial for generating realistic
textures. We introduce a novel approach for creating textures with such
blemishes, adopting a learning-based approach that leverages unlabeled
examples. Our approach does not require manual annotations by the user;
instead, it detects the appearance-altering features through unsupervised
anomaly detection. The various textural features are then automatically
clustered into semantically coherent groups, which are used to guide the
conditional generation of images. Our pipeline as a whole goes from a small
image collection to a versatile generative model that enables the user to
interactively create and paint features on textures of arbitrary size. Notably,
the algorithms we introduce for diffusion-based editing and infinite stationary
texture generation are generic and should prove useful in other contexts as
well. Project page: https://reality.tf.fau.de/pub/ardelean2025examplebased.html

</details>


### [159] [NSYNC: Negative Synthetic Image Generation for Contrastive Training to Improve Stylized Text-To-Image Translation](https://arxiv.org/abs/2511.01517)
*Serkan Ozturk,Samet Hicsonmez,Pinar Duygulu*

Main category: cs.CV

TL;DR: 提出了一种新的对比学习框架NSYNC，通过生成负样本数据并结合对比训练，提升文本到图像扩散模型的风格化能力。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像生成方法难以捕捉特定风格，微调效果不佳，因此探索利用合成数据改进风格化能力。

Method: 通过生成负样本数据集，结合正样本进行对比训练，利用正交梯度更新参数，消除冗余特征。

Result: 实验表明，NSYNC在多种画家和插画师风格上均优于基线方法，定量和定性结果均有提升。

Conclusion: NSYNC框架有效提升了风格化能力，代码已开源。

Abstract: Current text conditioned image generation methods output realistic looking
images, but they fail to capture specific styles. Simply finetuning them on the
target style datasets still struggles to grasp the style features. In this
work, we present a novel contrastive learning framework to improve the
stylization capability of large text-to-image diffusion models. Motivated by
the astonishing advance in image generation models that makes synthetic data an
intrinsic part of model training in various computer vision tasks, we exploit
synthetic image generation in our approach. Usually, the generated synthetic
data is dependent on the task, and most of the time it is used to enlarge the
available real training dataset. With NSYNC, alternatively, we focus on
generating negative synthetic sets to be used in a novel contrastive training
scheme along with real positive images. In our proposed training setup, we
forward negative data along with positive data and obtain negative and positive
gradients, respectively. We then refine the positive gradient by subtracting
its projection onto the negative gradient to get the orthogonal component,
based on which the parameters are updated. This orthogonal component eliminates
the trivial attributes that are present in both positive and negative data and
directs the model towards capturing a more unique style. Experiments on various
styles of painters and illustrators show that our approach improves the
performance over the baseline methods both quantitatively and qualitatively.
Our code is available at https://github.com/giddyyupp/NSYNC.

</details>


### [160] [Driving scenario generation and evaluation using a structured layer representation and foundational models](https://arxiv.org/abs/2511.01541)
*Arthur Hubert,Gamal Elghazaly,Raphaël Frank*

Main category: cs.CV

TL;DR: 提出了一种五层模型用于改进罕见驾驶场景的生成与评估，结合数据增强策略和大型基础模型生成新场景，并引入多样性和原创性评分。


<details>
  <summary>Details</summary>
Motivation: 罕见驾驶场景对自动驾驶发展至关重要，但难以遇到，因此需要通过生成模型模拟或生成这些场景。

Method: 提出结构化五层模型，结合数据增强策略和大型基础模型生成新场景，并引入子类和特征以比较场景。

Result: 展示了多样性和原创性评分在不同生成设置中的应用，并对生成的合成视频进行了定性评估。

Conclusion: 五层模型和评分方法有效改进了罕见驾驶场景的生成与评估。

Abstract: Rare and challenging driving scenarios are critical for autonomous vehicle
development. Since they are difficult to encounter, simulating or generating
them using generative models is a popular approach. Following previous efforts
to structure driving scenario representations in a layer model, we propose a
structured five-layer model to improve the evaluation and generation of rare
scenarios. We use this model alongside large foundational models to generate
new driving scenarios using a data augmentation strategy. Unlike previous
representations, our structure introduces subclasses and characteristics for
every agent of the scenario, allowing us to compare them using an embedding
specific to our layer-model. We study and adapt two metrics to evaluate the
relevance of a synthetic dataset in the context of a structured representation:
the diversity score estimates how different the scenarios of a dataset are from
one another, while the originality score calculates how similar a synthetic
dataset is from a real reference set. This paper showcases both metrics in
different generation setup, as well as a qualitative evaluation of synthetic
videos generated from structured scenario descriptions. The code and extended
results can be found at https://github.com/Valgiz/5LMSG.

</details>


### [161] [PCD-ReID: Occluded Person Re-Identification for Base Station Inspection](https://arxiv.org/abs/2511.01546)
*Ge Gao,Zishuo Gao,Hongyan Cui,Zhiyang Jia,Zhuang Luo,ChaoPeng Liu*

Main category: cs.CV

TL;DR: 提出了一种基于Transformer的PCD-ReID算法，用于解决基站环境中行人重识别的遮挡问题，并在新收集的真实数据集上取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统ResNet-based算法在遮挡情况下表现不佳，需要新的方法来解决这一问题。

Method: 设计了Transformer-based PCD网络，提取共享组件特征（如头盔和制服），并使用新收集的真实巡逻监控图像进行训练。

Result: 模型在mAP和Rank-1准确率上分别达到79.0%和82.7%，比ResNet50-based方法提升了15.9%。

Conclusion: PCD-ReID在遮挡场景下表现出色，适用于监控和安全应用。

Abstract: Occluded pedestrian re-identification (ReID) in base station environments is
a critical task in computer vision, particularly for surveillance and security
applications. This task faces numerous challenges, as occlusions often obscure
key body features, increasing the complexity of identification. Traditional
ResNet-based ReID algorithms often fail to address occlusions effectively,
necessitating new ReID methods. We propose the PCD-ReID (Pedestrian Component
Discrepancy) algorithm to address these issues. The contributions of this work
are as follows: To tackle the occlusion problem, we design a Transformer-based
PCD network capable of extracting shared component features, such as helmets
and uniforms. To mitigate overfitting on public datasets, we collected new
real-world patrol surveillance images for model training, covering six months,
10,000 individuals, and over 50,000 images. Comparative experiments with
existing ReID algorithms demonstrate that our model achieves a mean Average
Precision (mAP) of 79.0% and a Rank-1 accuracy of 82.7%, marking a 15.9% Rank-1
improvement over ResNet50-based methods. Experimental evaluations indicate that
PCD-ReID effectively achieves occlusion-aware ReID performance for personnel in
tower inspection scenarios, highlighting its potential for practical deployment
in surveillance and security applications.

</details>


### [162] [NOA: a versatile, extensible tool for AI-based organoid analysis](https://arxiv.org/abs/2511.01549)
*Mikhail Konov,Lion J. Gleiter,Khoa Co,Monica Yabal,Tingying Peng*

Main category: cs.CV

TL;DR: NOA是一个用于简化基于AI的类器官分析的通用图形用户界面工具，解决了现有工具可访问性差和功能单一的问题。


<details>
  <summary>Details</summary>
Motivation: 现有AI工具对无编程经验的生物学家不友好，且功能单一，导致分析工作流程繁琐且手动化。

Method: 开发了Napari Organoid Analyzer (NOA)，集成了检测、分割、跟踪、特征提取等功能，并作为开源插件实现。

Result: 通过三个案例研究展示了NOA的多样性，包括形态变化量化、光毒性效应评估和类器官存活率预测。

Conclusion: NOA提供了一个可访问且可扩展的框架，支持全面的AI驱动类器官图像分析。

Abstract: AI tools can greatly enhance the analysis of organoid microscopy images, from
detection and segmentation to feature extraction and classification. However,
their limited accessibility to biologists without programming experience
remains a major barrier, resulting in labor-intensive and largely manual
workflows. Although a few AI models for organoid analysis have been developed,
most existing tools remain narrowly focused on specific tasks. In this work, we
introduce the Napari Organoid Analyzer (NOA), a general purpose graphical user
interface to simplify AI-based organoid analysis. NOA integrates modules for
detection, segmentation, tracking, feature extraction, custom feature
annotation and ML-based feature prediction. It interfaces multiple
state-of-the-art algorithms and is implemented as an open-source napari plugin
for maximal flexibility and extensibility. We demonstrate the versatility of
NOA through three case studies, involving the quantification of morphological
changes during organoid differentiation, assessment of phototoxicity effects,
and prediction of organoid viability and differentiation state. Together, these
examples illustrate how NOA enables comprehensive, AI-driven organoid image
analysis within an accessible and extensible framework.

</details>


### [163] [Generative Adversarial Synthesis and Deep Feature Discrimination of Brain Tumor MRI Images](https://arxiv.org/abs/2511.01574)
*Md Sumon Ali,Muzammil Behzad*

Main category: cs.CV

TL;DR: 提出了一种基于DC-GAN生成合成MRI数据的方法，并通过CNN验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决MRI数据有限的问题，生成逼真的医学图像。

Method: 使用DC-GAN生成合成MRI数据，并用CNN分类器评估合成图像的质量和实用性。

Result: 合成图像与真实图像在分类任务中表现相当。

Conclusion: GAN生成的图像可用于下游任务，验证了其有效性。

Abstract: Compared to traditional methods, Deep Learning (DL) becomes a key technology
for computer vision tasks. Synthetic data generation is an interesting use case
for DL, especially in the field of medical imaging such as Magnetic Resonance
Imaging (MRI). The need for this task since the original MRI data is limited.
The generation of realistic medical images is completely difficult and
challenging. Generative Adversarial Networks (GANs) are useful for creating
synthetic medical images. In this paper, we propose a DL based methodology for
creating synthetic MRI data using the Deep Convolutional Generative Adversarial
Network (DC-GAN) to address the problem of limited data. We also employ a
Convolutional Neural Network (CNN) classifier to classify the brain tumor using
synthetic data and real MRI data. CNN is used to evaluate the quality and
utility of the synthetic images. The classification result demonstrates
comparable performance on real and synthetic images, which validates the
effectiveness of GAN-generated images for downstream tasks.

</details>


### [164] [Wave-Particle (Continuous-Discrete) Dualistic Visual Tokenization for Unified Understanding and Generation](https://arxiv.org/abs/2511.01593)
*Yizhu Chen,Chen Ju,Zhicheng Wang,Shuai Xiao,Xu Chen,Jinsong Lan,Xiaoyong Zhu,Ying Chen*

Main category: cs.CV

TL;DR: CDD-VT提出了一种连续-离散双重视觉标记器，通过动态分配图像基元数量，平衡了连续和离散标记化的优缺点，实现了高性能的多模态大模型。


<details>
  <summary>Details</summary>
Motivation: 解决多模态大模型中连续和离散视觉标记化的对立问题，避免复杂多阶段流程和信息损失。

Method: 提出CDD-VT，结合动态基元分配器和多样化量化基元，根据图像复杂度自适应分配基元数量。

Result: 在重建、检索和分类任务中，CDD-VT性能优于专用连续和离散标记器。

Conclusion: CDD-VT在简洁且可扩展的多模态大模型中实现了高性能，平衡了连续和离散标记化的优势。

Abstract: The unification of understanding and generation within a single multi-modal
large model (MLLM) remains one significant challenge, largely due to the
dichotomy between continuous and discrete visual tokenizations. Continuous
tokenizer (CT) achieves strong performance by bridging multiple
independently-trained understanding modules and generation modules, but suffers
from complex multi-stage pipelines and substantial engineering overhead.
Conversely, discrete tokenizers (DT) offer a conceptually elegant idea by
quantizing each image into a primitive, but inevitably leading to information
loss and performance degradation. To resolve this tension, we question the
binary choice between CT and DT, inspired by the wave-particle duality of
light, and propose the Continuous-Discrete Dualistic Visual Tokenizer (CDD-VT).
We treat visual data as a flexible composition of image primitives derived from
quantized codebooks, with the crucial insight that the primitive number
assigned to each visual sample is adaptively determined according to its
complexity: simple instances use a few primitives, emulating discrete
tokenization, while complex instances use many, approximating continuous
tokenization. Two core components are designed: Diverse Quantitative
Primitives, which encourage primitives orthogonality to better populate
information space, and Dynamic Primitive Allocator, which assesses sample
complexity to determine the optimal set of primitives. Extensive experiments on
reconstruction, retrieval and classification show that CDD-VT achieves superior
performance over to specialized CT and DT, effectively getting strong result
within a concise and scalable MLLM.

</details>


### [165] [Lite ENSAM: a lightweight cancer segmentation model for 3D Computed Tomography](https://arxiv.org/abs/2511.01600)
*Agnar Martin Bjørnstad,Elias Stenhede,Arian Ranjbar*

Main category: cs.CV

TL;DR: Lite ENSAM是一种轻量级架构，用于从带有RECIST注释的CT扫描中进行高效肿瘤体积分割，在MICCAI FLARE 2025任务中表现良好。


<details>
  <summary>Details</summary>
Motivation: 当前肿瘤体积测量依赖手动标注，耗时且临床推广受限，需要自动化解决方案。

Method: 采用轻量化的ENSAM架构，专注于CT扫描中的肿瘤体积分割。

Result: 在隐藏测试集上DSC为60.7%，NSD为63.6%；在CPU上平均推理时间为14.4秒。

Conclusion: Lite ENSAM展示了高效且轻量的肿瘤体积分割潜力，有望推动临床自动化应用。

Abstract: Accurate tumor size measurement is a cornerstone of evaluating cancer
treatment response. The most widely adopted standard for this purpose is the
Response Evaluation Criteria in Solid Tumors (RECIST) v1.1, which relies on
measuring the longest tumor diameter in a single plane. However, volumetric
measurements have been shown to provide a more reliable assessment of treatment
effect. Their clinical adoption has been limited, though, due to the
labor-intensive nature of manual volumetric annotation. In this paper, we
present Lite ENSAM, a lightweight adaptation of the ENSAM architecture designed
for efficient volumetric tumor segmentation from CT scans annotated with RECIST
annotations. Lite ENSAM was submitted to the MICCAI FLARE 2025 Task 1:
Pan-cancer Segmentation in CT Scans, Subtask 2, where it achieved a Dice
Similarity Coefficient (DSC) of 60.7% and a Normalized Surface Dice (NSD) of
63.6% on the hidden test set, and an average total RAM time of 50.6 GBs and an
average inference time of 14.4 s on CPU on the public validation dataset.

</details>


### [166] [DINO-MX: A Modular & Flexible Framework for Self-Supervised Learning](https://arxiv.org/abs/2511.01610)
*Mahmut Selman Gokmen,Cody Bumgardner*

Main category: cs.CV

TL;DR: DINO-MX是一个模块化、可扩展的训练框架，结合了DINO系列的核心原则，支持多种Transformer架构和训练策略，显著降低计算成本并提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉基础模型的训练流程通常不够灵活、领域特定或计算成本高，限制了其跨领域和资源设置的适用性。

Method: DINO-MX采用统一的配置驱动系统，支持多种训练策略（如LoRA、层冻结、知识蒸馏）和分布式训练（DDP、FSDP），兼容Hugging Face生态系统。

Result: 实验表明，DINO-MX在多样化数据集上实现了竞争性性能，同时显著降低计算成本，并提供可解释性工具和数据增强方法。

Conclusion: DINO-MX为自监督视觉模型的开发、适应和基准测试提供了可重复且可扩展的基础，适用于研究和实际应用。

Abstract: Vision Foundation Models (VFMs) have advanced representation learning through
self-supervised methods. However, existing training pipelines are often
inflexible, domain-specific, or computationally expensive, which limits their
usability across different domains and resource settings. DINO-MX is a modular
and extensible training framework that combines the core principles of DINO,
DINOv2 and DINOv3 within a unified configuration-driven system. It supports a
variety of transformer-based architectures and is fully compatible with the
Hugging Face ecosystem. The framework includes multiple training strategies
such as low-rank adaptation (LoRA), layer freezing, and knowledge distillation,
along with support for distributed training through both Distributed Data
Parallel (DDP) and Fully Sharded Data Parallel (FSDP). DINO-MX is designed to
work with both natural and specialized data types, including single- and
multi-channel images. Experimental results on diverse datasets show that
DINO-MX achieves competitive performance while significantly reducing
computational costs. Additionally, it offers interpretability tools and a
label-guided data augmentation method that improves attention-based
localization without the need for extra detection or segmentation heads.
DINO-MX provides a reproducible and scalable foundation for developing,
adapting, and benchmarking self-supervised vision models across a range of
research and real-world applications.

</details>


### [167] [Benchmark-Ready 3D Anatomical Shape Classification](https://arxiv.org/abs/2511.01613)
*Tomáš Krsička,Tibor Kubík*

Main category: cs.CV

TL;DR: 提出了一种非学习的网格池化算子PSPooling，用于高效且结构保留的3D解剖形状分析，并在自监督图自编码器中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 解剖3D形状分类的进展受限于网格数据的复杂性和缺乏标准化基准，需要鲁棒的学习方法和可重复的评估。

Method: 提出PSPooling算子，基于几何邻近性预计算节点对应集，实现并行化和可逆的池化与反池化操作。

Result: 在MedShapeNet19数据集上，PSPooling显著提高了重建保真度和低标签情况下的分类准确率。

Conclusion: PSPooling为医学3D形状学习建立了强基线，MedShapeNet19有望成为解剖形状分类的广泛基准。

Abstract: Progress in anatomical 3D shape classification is limited by the complexity
of mesh data and the lack of standardized benchmarks, highlighting the need for
robust learning methods and reproducible evaluation. We introduce two key steps
toward clinically and benchmark-ready anatomical shape classification via
self-supervised graph autoencoding. We propose Precomputed Structural Pooling
(PSPooling), a non-learnable mesh pooling operator designed for efficient and
structure-preserving graph coarsening in 3D anatomical shape analysis.
PSPooling precomputes node correspondence sets based on geometric proximity,
enabling parallelizable and reversible pooling and unpooling operations with
guaranteed support structure. This design avoids the sparsity and
reconstruction issues of selection-based methods and the sequential overhead of
edge contraction approaches, making it particularly suitable for
high-resolution medical meshes. To demonstrate its effectiveness, we integrate
PSPooling into a self-supervised graph autoencoder that learns anatomy-aware
representations from unlabeled surface meshes. We evaluate the downstream
benefits on MedShapeNet19, a new curated benchmark dataset we derive from
MedShapeNet, consisting of 19 anatomical classes with standardized training,
validation, and test splits. Experiments show that PSPooling significantly
improves reconstruction fidelity and classification accuracy in low-label
regimes, establishing a strong baseline for medical 3D shape learning. We hope
that MedShapeNet19 will serve as a widely adopted benchmark for anatomical
shape classification and further research in medical 3D shape analysis. Access
the complete codebase, model weights, and dataset information here:
https://github.com/TomasKrsicka/MedShapeNet19-PSPooling.

</details>


### [168] [Vote-in-Context: Turning VLMs into Zero-Shot Rank Fusers](https://arxiv.org/abs/2511.01617)
*Mohamed Eltahir,Ali Habibullah,Lama Ayash,Tanveer Hussain,Naeemullah Khan*

Main category: cs.CV

TL;DR: ViC是一个无需训练的通用框架，通过零样本推理任务重新思考列表重排序和融合，显著提升跨模态视频检索性能。


<details>
  <summary>Details</summary>
Motivation: 解决异构检索器候选融合的挑战，特别是在复杂多模态数据（如视频）中，传统方法仅依赖排名或分数信号，忽略候选表示。

Method: 引入Vote-in-Context (ViC)，将内容证据和检索器元数据序列化到VLM提示中，自适应权衡检索共识与视觉-语言内容。使用S-Grid紧凑序列化视频表示。

Result: 在零样本设置下，ViC在MSR-VTT和VATEX基准上达到Recall@1分数87.1%/89.0%和99.6%，比之前最佳基线提升高达+40 Recall@1。

Conclusion: ViC是一种简单、可复现且高效的方案，可将现代VLM转化为强大的零样本重排序器和融合器。

Abstract: In the retrieval domain, candidates' fusion from heterogeneous retrievers is
a long-standing challenge, particularly for complex, multi-modal data such as
videos. While typical fusion techniques are training-free, they rely solely on
rank or score signals, disregarding candidates' representations. This work
introduces Vote-in-Context (ViC), a generalized, training-free framework that
re-thinks list-wise reranking and fusion as a zero-shot reasoning task for a
Vision-Language Model (VLM). The core insight is to serialize both content
evidence and retriever metadata directly within the VLM's prompt, allowing the
model to adaptively weigh retriever consensus against visual-linguistic
content. We demonstrate the generality of this framework by applying it to the
challenging domain of cross-modal video retrieval. To this end, we introduce
the S-Grid, a compact serialization map that represents each video as an image
grid, optionally paired with subtitles to enable list-wise reasoning over video
candidates. ViC is evaluated both as a single-list reranker, where it
dramatically improves the precision of individual retrievers, and as an
ensemble fuser, where it consistently outperforms strong baselines like
CombSUM. Across video retrieval benchmarks including ActivityNet and VATEX, the
framework establishes new state-of-the-art zero-shot retrieval performance,
demonstrating its effectiveness in handling complex visual and temporal signals
alongside text. In zero-shot settings, ViC achieves Recall@1 scores of 87.1%
(t2v) / 89.0% (v2t) on MSR-VTT and 99.6% (v2t) on VATEX, representing massive
gains of up to +40 Recall@1 over previous state-of-the-art baselines. We
present ViC as a simple, reproducible, and highly effective recipe for turning
modern VLMs into powerful zero-shot rerankers and fusers. Code and resources
are publicly available at: https://github.com/mohammad2012191/ViC

</details>


### [169] [Actial: Activate Spatial Reasoning Ability of Multimodal Large Language Models](https://arxiv.org/abs/2511.01618)
*Xiaoyu Zhan,Wenxuan Huang,Hao Sun,Xinyu Fu,Changfeng Ma,Shaosheng Cao,Bohan Jia,Shaohui Lin,Zhenfei Yin,Lei Bai,Wanli Ouyang,Yuanqi Li,Jie Guo,Yanwen Guo*

Main category: cs.CV

TL;DR: 论文提出Viewpoint Learning任务和Viewpoint-100K数据集，通过两阶段微调策略提升MLLMs的空间推理能力，实验结果显示显著效果。


<details>
  <summary>Details</summary>
Motivation: 探讨MLLMs在复杂3D推理任务中的表现，尤其是跨视角一致性问题，提出改进方法。

Method: 两阶段微调：SFT注入基础知识，GRPO增强泛化；引入混合冷启动初始化方法。

Result: 显著激活MLLMs的空间推理能力，提升领域内外任务表现。

Conclusion: 发展MLLMs的基础空间技能对机器人、自主系统和3D场景理解有重要价值。

Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have
significantly improved 2D visual understanding, prompting interest in their
application to complex 3D reasoning tasks. However, it remains unclear whether
these models can effectively capture the detailed spatial information required
for robust real-world performance, especially cross-view consistency, a key
requirement for accurate 3D reasoning. Considering this issue, we introduce
Viewpoint Learning, a task designed to evaluate and improve the spatial
reasoning capabilities of MLLMs. We present the Viewpoint-100K dataset,
consisting of 100K object-centric image pairs with diverse viewpoints and
corresponding question-answer pairs. Our approach employs a two-stage
fine-tuning strategy: first, foundational knowledge is injected to the baseline
MLLM via Supervised Fine-Tuning (SFT) on Viewpoint-100K, resulting in
significant improvements across multiple tasks; second, generalization is
enhanced through Reinforcement Learning using the Group Relative Policy
Optimization (GRPO) algorithm on a broader set of questions. Additionally, we
introduce a hybrid cold-start initialization method designed to simultaneously
learn viewpoint representations and maintain coherent reasoning thinking.
Experimental results show that our approach significantly activates the spatial
reasoning ability of MLLM, improving performance on both in-domain and
out-of-domain reasoning tasks. Our findings highlight the value of developing
foundational spatial skills in MLLMs, supporting future progress in robotics,
autonomous systems, and 3D scene understanding.

</details>


### [170] [Enhancing Diffusion-based Restoration Models via Difficulty-Adaptive Reinforcement Learning with IQA Reward](https://arxiv.org/abs/2511.01645)
*Xiaogang Xu,Ruihang Chu,Jian Wang,Kun Zhou,Wenjie Shu,Harry Yang,Ser-Nam Lim,Hao Chen,Liang Lin*

Main category: cs.CV

TL;DR: 论文提出了一种将强化学习（RL）有效整合到基于扩散的图像修复模型中的方法，通过动态调整RL与监督微调（SFT）的结合，提升修复性能。


<details>
  <summary>Details</summary>
Motivation: 现有RL方法直接应用于基于扩散的图像修复模型效果不佳，因为修复任务更强调保真度而非纯生成。

Method: 使用IQA模型生成有效奖励，针对远离真实样本的挑战性样本应用RL，并通过自动权重策略动态结合RL与SFT。

Result: 实验表明，该方法在多个基准测试中显著提升了图像修复模型的性能。

Conclusion: 提出的RL框架是即插即用的，可无缝应用于基于扩散的修复模型，并在多种修复任务中表现优异。

Abstract: Reinforcement Learning (RL) has recently been incorporated into diffusion
models, e.g., tasks such as text-to-image. However, directly applying existing
RL methods to diffusion-based image restoration models is suboptimal, as the
objective of restoration fundamentally differs from that of pure generation: it
places greater emphasis on fidelity. In this paper, we investigate how to
effectively integrate RL into diffusion-based restoration models. First,
through extensive experiments with various reward functions, we find that an
effective reward can be derived from an Image Quality Assessment (IQA) model,
instead of intuitive ground-truth-based supervision, which has already been
optimized during the Supervised Fine-Tuning (SFT) stage prior to RL. Moreover,
our strategy focuses on using RL for challenging samples that are significantly
distant from the ground truth, and our RL approach is innovatively implemented
using MLLM-based IQA models to align distributions with high-quality images
initially. As the samples approach the ground truth's distribution, RL is
adaptively combined with SFT for more fine-grained alignment. This dynamic
process is facilitated through an automatic weighting strategy that adjusts
based on the relative difficulty of the training samples. Our strategy is
plug-and-play that can be seamlessly applied to diffusion-based restoration
models, boosting its performance across various restoration tasks. Extensive
experiments across multiple benchmarks demonstrate the effectiveness of our
proposed RL framework.

</details>


### [171] [UniLumos: Fast and Unified Image and Video Relighting with Physics-Plausible Feedback](https://arxiv.org/abs/2511.01678)
*Ropeway Liu,Hangjie Yuan,Bo Dong,Jiazheng Xing,Jinwang Wang,Rui Zhao,Yan Xing,Weihua Chen,Fan Wang*

Main category: cs.CV

TL;DR: UniLumos是一个统一的图像和视频重照明框架，通过引入RGB空间的几何反馈和路径一致性学习，显著提升了物理一致性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型在语义潜在空间中优化，导致视觉空间中的物理不正确（如过曝高光、阴影错位等），因此需要一种更物理一致的重照明方法。

Method: UniLumos通过深度和法线图监督模型，结合路径一致性学习，在少步训练下保持有效性，并设计了六维标注协议和LumosBench基准。

Result: UniLumos在重照明质量上达到SOTA，物理一致性显著提升，同时实现了20倍的加速。

Conclusion: UniLumos通过几何反馈和高效训练策略，解决了现有重照明模型的物理不一致问题，并提供了快速、高质量的重照明解决方案。

Abstract: Relighting is a crucial task with both practical demand and artistic value,
and recent diffusion models have shown strong potential by enabling rich and
controllable lighting effects. However, as they are typically optimized in
semantic latent space, where proximity does not guarantee physical correctness
in visual space, they often produce unrealistic results, such as overexposed
highlights, misaligned shadows, and incorrect occlusions. We address this with
UniLumos, a unified relighting framework for both images and videos that brings
RGB-space geometry feedback into a flow matching backbone. By supervising the
model with depth and normal maps extracted from its outputs, we explicitly
align lighting effects with the scene structure, enhancing physical
plausibility. Nevertheless, this feedback requires high-quality outputs for
supervision in visual space, making standard multi-step denoising
computationally expensive. To mitigate this, we employ path consistency
learning, allowing supervision to remain effective even under few-step training
regimes. To enable fine-grained relighting control and supervision, we design a
structured six-dimensional annotation protocol capturing core illumination
attributes. Building upon this, we propose LumosBench, a disentangled
attribute-level benchmark that evaluates lighting controllability via large
vision-language models, enabling automatic and interpretable assessment of
relighting precision across individual dimensions. Extensive experiments
demonstrate that UniLumos achieves state-of-the-art relighting quality with
significantly improved physical consistency, while delivering a 20x speedup for
both image and video relighting. Code is available at
https://github.com/alibaba-damo-academy/Lumos-Custom.

</details>


### [172] [Progressive Translation of H&E to IHC with Enhanced Structural Fidelity](https://arxiv.org/abs/2511.01698)
*Yuhang Kang,Ziyu Su,Tianyang Wang,Zaibo Li,Wei Chen,Muhammad Khalid Khan Niazi*

Main category: cs.CV

TL;DR: 提出一种渐进式网络架构，通过分阶段优化颜色和细胞边界生成，提升IHC图像质量。


<details>
  <summary>Details</summary>
Motivation: IHC成本高且难以扩展，现有染色转换技术因忽略损失项间的相互依赖导致图像质量不佳。

Method: 基于ASP框架，引入DAB色原浓度和图像梯度损失函数，分阶段优化结构、颜色和细胞边界。

Result: 在HER2和ER数据集上，模型显著提升视觉质量并保留更精细结构细节。

Conclusion: 渐进式机制有效解决了现有技术中结构真实性和颜色保真度难以兼顾的问题。

Abstract: Compared to hematoxylin-eosin (H&E) staining, immunohistochemistry (IHC) not
only maintains the structural features of tissue samples, but also provides
high-resolution protein localization, which is essential for aiding in
pathology diagnosis. Despite its diagnostic value, IHC remains a costly and
labor-intensive technique. Its limited scalability and constraints in
multiplexing further hinder widespread adoption, especially in resource-limited
settings. Consequently, researchers are increasingly exploring computational
stain translation techniques to synthesize IHC-equivalent images from
H&E-stained slides, aiming to extract protein-level information more
efficiently and cost-effectively. However, most existing stain translation
techniques rely on a linearly weighted summation of multiple loss terms within
a single objective function, strategy that often overlooks the interdepedence
among these components-resulting in suboptimal image quality and an inability
to simultaneously preserve structural authenticity and color fidelity. To
address this limitation, we propose a novel network architecture that follows a
progressive structure, incorporating color and cell border generation logic,
which enables each visual aspect to be optimized in a stage-wise and decoupled
manner. To validate the effectiveness of our proposed network architecture, we
build upon the Adaptive Supervised PatchNCE (ASP) framework as our baseline. We
introduce additional loss functions based on 3,3'-diaminobenzidine (DAB)
chromogen concentration and image gradient, enhancing color fidelity and cell
boundary clarity in the generated IHC images. By reconstructing the generation
pipeline using our structure-color-cell boundary progressive mechanism,
experiments on HER2 and ER datasets demonstrated that the model significantly
improved visual quality and achieved finer structural details.

</details>


### [173] [Learnable Fractional Reaction-Diffusion Dynamics for Under-Display ToF Imaging and Beyond](https://arxiv.org/abs/2511.01704)
*Xin Qiao,Matteo Poggi,Xing Wei,Pengchao Deng,Yanhui Zhou,Stefano Mattoccia*

Main category: cs.CV

TL;DR: 提出了一种名为LFRD2的混合框架，结合神经网络和物理建模，用于解决屏幕下ToF成像中的信号衰减和多路径干扰问题。


<details>
  <summary>Details</summary>
Motivation: 透明OLED层导致ToF成像信号衰减、多路径干扰和噪声，严重影响深度感知质量。

Method: 采用可学习的分数反应-扩散动力学（LFRD2），结合时间分数反应-扩散模块和连续卷积算子，动态生成微分阶数以捕获长期依赖关系。

Result: 在四个基准数据集上验证了方法的有效性。

Conclusion: LFRD2框架显著提升了屏幕下ToF成像的深度感知质量。

Abstract: Under-display ToF imaging aims to achieve accurate depth sensing through a
ToF camera placed beneath a screen panel. However, transparent OLED (TOLED)
layers introduce severe degradations-such as signal attenuation, multi-path
interference (MPI), and temporal noise-that significantly compromise depth
quality. To alleviate this drawback, we propose Learnable Fractional
Reaction-Diffusion Dynamics (LFRD2), a hybrid framework that combines the
expressive power of neural networks with the interpretability of physical
modeling. Specifically, we implement a time-fractional reaction-diffusion
module that enables iterative depth refinement with dynamically generated
differential orders, capturing long-term dependencies. In addition, we
introduce an efficient continuous convolution operator via coefficient
prediction and repeated differentiation to further improve restoration quality.
Experiments on four benchmark datasets demonstrate the effectiveness of our
approach. The code is publicly available at https://github.com/wudiqx106/LFRD2.

</details>


### [174] [Probabilistic Robustness for Free? Revisiting Training via a Benchmark](https://arxiv.org/abs/2511.01724)
*Yi Zhang,Zheng Wang,Chen Zhen,Wenjie Ruan,Qing Guo,Siddartha Khastgir,Carsten Maple,Xingyu Zhao*

Main category: cs.CV

TL;DR: PRBench是首个专注于评估不同鲁棒性训练方法在概率鲁棒性（PR）上改进的基准测试，发现对抗训练（AT）方法在提升PR和对抗鲁棒性（AR）方面更通用，而PR针对性训练方法在泛化误差和干净准确率上表现更好。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注对抗鲁棒性（AR），而概率鲁棒性（PR）作为其补充，缺乏统一的评估框架和训练方法比较。

Method: 提出PRBench基准，综合评估多种AT和PR针对性训练方法，使用包括干净准确率、PR和AR性能、训练效率和泛化误差等指标。

Result: AT方法在提升PR和AR性能上更通用，PR针对性训练方法在泛化误差和干净准确率上表现更优。

Conclusion: PRBench为PR研究提供了标准化评估工具，揭示了不同训练方法的优缺点，推动了鲁棒性研究的进一步发展。

Abstract: Deep learning models are notoriously vulnerable to imperceptible
perturbations. Most existing research centers on adversarial robustness (AR),
which evaluates models under worst-case scenarios by examining the existence of
deterministic adversarial examples (AEs). In contrast, probabilistic robustness
(PR) adopts a statistical perspective, measuring the probability that
predictions remain correct under stochastic perturbations. While PR is widely
regarded as a practical complement to AR, dedicated training methods for
improving PR are still relatively underexplored, albeit with emerging progress.
Among the few PR-targeted training methods, we identify three limitations: i
non-comparable evaluation protocols; ii limited comparisons to strong AT
baselines despite anecdotal PR gains from AT; and iii no unified framework to
compare the generalization of these methods. Thus, we introduce PRBench, the
first benchmark dedicated to evaluating improvements in PR achieved by
different robustness training methods. PRBench empirically compares most common
AT and PR-targeted training methods using a comprehensive set of metrics,
including clean accuracy, PR and AR performance, training efficiency, and
generalization error (GE). We also provide theoretical analysis on the GE of PR
performance across different training methods. Main findings revealed by
PRBench include: AT methods are more versatile than PR-targeted training
methods in terms of improving both AR and PR performance across diverse
hyperparameter settings, while PR-targeted training methods consistently yield
lower GE and higher clean accuracy. A leaderboard comprising 222 trained models
across 7 datasets and 10 model architectures is publicly available at
https://tmpspace.github.io/PRBenchLeaderboard/.

</details>


### [175] [Toward Strategy Identification and Subtask Decomposition In Task Exploration](https://arxiv.org/abs/2511.01728)
*Tom Odem*

Main category: cs.CV

TL;DR: 开发了一个任务探索管道，通过聚类技术、因子分析和字符串编辑距离自动识别完成任务的关键策略和子任务。


<details>
  <summary>Details</summary>
Motivation: 提升机器对用户知识、技能和行为的理解，以实现隐式协调。

Method: 使用聚类技术、因子分析和字符串编辑距离，开发任务探索管道，识别全局和局部策略以及子任务。

Result: 管道能自动识别关键策略，并用层次化子任务结构编码用户行为。开发了Task Explorer应用便于结果审查。

Conclusion: 任务探索管道适用于任何基于动作的时间序列数据，识别的策略和子任务有助于理解用户知识、技能和行为。

Abstract: This research builds on work in anticipatory human-machine interaction, a
subfield of human-machine interaction where machines can facilitate
advantageous interactions by anticipating a user's future state. The aim of
this research is to further a machine's understanding of user knowledge, skill,
and behavior in pursuit of implicit coordination. A task explorer pipeline was
developed that uses clustering techniques, paired with factor analysis and
string edit distance, to automatically identify key global and local strategies
that are used to complete tasks. Global strategies identify generalized sets of
actions used to complete tasks, while local strategies identify sequences that
used those sets of actions in a similar composition. Additionally, meaningful
subtasks of various lengths are identified within the tasks. The task explorer
pipeline was able to automatically identify key strategies used to complete
tasks and encode user runs with hierarchical subtask structures. In addition, a
Task Explorer application was developed to easily review pipeline results. The
task explorer pipeline can be easily modified to any action-based time-series
data and the identified strategies and subtasks help to inform humans and
machines on user knowledge, skill, and behavior.

</details>


### [176] [CGF-DETR: Cross-Gated Fusion DETR for Enhanced Pneumonia Detection in Chest X-rays](https://arxiv.org/abs/2511.01730)
*Yefeng Wu,Yucheng Song,Ling Wu,Shan Wan,Yecheng Zhao*

Main category: cs.CV

TL;DR: CGF-DETR是一种改进的实时检测变换器，专为肺炎检测设计，通过引入XFABlock、SPGA模块和GCFC3，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 肺炎是全球发病率和死亡率的主要原因，需要高效准确的自动检测系统。

Method: 提出CGF-DETR，结合XFABlock、SPGA模块和GCFC3，优化多尺度特征提取和特征聚合。

Result: 在RSNA数据集上达到82.2% mAP@0.5，比基线RT-DETR-l提升3.7%，同时保持48.1 FPS的推理速度。

Conclusion: 每个模块均对性能提升有贡献，完整模型在mAP@[0.5:0.95]上达到50.4%。

Abstract: Pneumonia remains a leading cause of morbidity and mortality worldwide,
necessitating accurate and efficient automated detection systems. While recent
transformer-based detectors like RT-DETR have shown promise in object detection
tasks, their application to medical imaging, particularly pneumonia detection
in chest X-rays, remains underexplored. This paper presents CGF-DETR, an
enhanced real-time detection transformer specifically designed for pneumonia
detection. We introduce XFABlock in the backbone to improve multi-scale feature
extraction through convolutional attention mechanisms integrated with CSP
architecture. To achieve efficient feature aggregation, we propose SPGA module
that replaces standard multi-head attention with dynamic gating mechanisms and
single-head self-attention. Additionally, GCFC3 is designed for the neck to
enhance feature representation through multi-path convolution fusion while
maintaining real-time performance via structural re-parameterization. Extensive
experiments on the RSNA Pneumonia Detection dataset demonstrate that CGF-DETR
achieves 82.2\% mAP@0.5, outperforming the baseline RT-DETR-l by 3.7\% while
maintaining comparable inference speed at 48.1 FPS. Our ablation studies
confirm that each proposed module contributes meaningfully to the overall
performance improvement, with the complete model achieving 50.4\%
mAP@[0.5:0.95]

</details>


### [177] [HGFreNet: Hop-hybrid GraphFomer for 3D Human Pose Estimation with Trajectory Consistency in Frequency Domain](https://arxiv.org/abs/2511.01756)
*Kai Zhai,Ziyan Huang,Qiang Nie,Xiang Li,Bo Ouyang*

Main category: cs.CV

TL;DR: HGFreNet是一种新型GraphFormer架构，通过跳数混合特征聚合和频域3D轨迹一致性，提升2D到3D人体姿态估计的准确性和时间一致性。


<details>
  <summary>Details</summary>
Motivation: 解决2D姿态估计中的深度模糊性和误差导致的3D轨迹不一致问题，同时弥补以往方法忽略全局时空相关性的不足。

Method: 提出跳数混合图注意力模块（HGA）和Transformer编码器，建模全局关节时空相关性；在频域约束轨迹一致性；使用初步网络估计3D姿态。

Result: 在Human3.6M和MPI-INF-3DHP数据集上，HGFreNet在位置准确性和时间一致性上优于现有方法。

Conclusion: HGFreNet通过结合局部和全局时空特征，显著提升了2D到3D姿态估计的性能。

Abstract: 2D-to-3D human pose lifting is a fundamental challenge for 3D human pose
estimation in monocular video, where graph convolutional networks (GCNs) and
attention mechanisms have proven to be inherently suitable for encoding the
spatial-temporal correlations of skeletal joints. However, depth ambiguity and
errors in 2D pose estimation lead to incoherence in the 3D trajectory. Previous
studies have attempted to restrict jitters in the time domain, for instance, by
constraining the differences between adjacent frames while neglecting the
global spatial-temporal correlations of skeletal joint motion. To tackle this
problem, we design HGFreNet, a novel GraphFormer architecture with hop-hybrid
feature aggregation and 3D trajectory consistency in the frequency domain.
Specifically, we propose a hop-hybrid graph attention (HGA) module and a
Transformer encoder to model global joint spatial-temporal correlations. The
HGA module groups all $k$-hop neighbors of a skeletal joint into a hybrid group
to enlarge the receptive field and applies the attention mechanism to discover
the latent correlations of these groups globally. We then exploit global
temporal correlations by constraining trajectory consistency in the frequency
domain. To provide 3D information for depth inference across frames and
maintain coherence over time, a preliminary network is applied to estimate the
3D pose. Extensive experiments were conducted on two standard benchmark
datasets: Human3.6M and MPI-INF-3DHP. The results demonstrate that the proposed
HGFreNet outperforms state-of-the-art (SOTA) methods in terms of positional
accuracy and temporal consistency.

</details>


### [178] [Wonder3D++: Cross-domain Diffusion for High-fidelity 3D Generation from a Single Image](https://arxiv.org/abs/2511.01767)
*Yuxiao Yang,Xiao-Xiao Long,Zhiyang Dou,Cheng Lin,Yuan Liu,Qingsong Yan,Yuexin Ma,Haoqian Wang,Zhiqiang Wu,Wei Yin*

Main category: cs.CV

TL;DR: Wonder3D++ 是一种从单视图图像高效生成高质量纹理网格的新方法，解决了现有方法在时间消耗和几何一致性上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有方法在单视图重建任务中要么耗时且几何不一致，要么快速但质量低。

Method: 提出跨域扩散模型生成多视角法线图和颜色图像，采用多视角跨域注意力机制确保一致性，并通过级联3D网格提取算法高效生成表面。

Result: 实验表明，该方法在质量、泛化能力和效率上优于现有方法。

Conclusion: Wonder3D++ 在单视图重建任务中实现了高质量、一致性和高效性的平衡。

Abstract: In this work, we introduce \textbf{Wonder3D++}, a novel method for
efficiently generating high-fidelity textured meshes from single-view images.
Recent methods based on Score Distillation Sampling (SDS) have shown the
potential to recover 3D geometry from 2D diffusion priors, but they typically
suffer from time-consuming per-shape optimization and inconsistent geometry. In
contrast, certain works directly produce 3D information via fast network
inferences, but their results are often of low quality and lack geometric
details. To holistically improve the quality, consistency, and efficiency of
single-view reconstruction tasks, we propose a cross-domain diffusion model
that generates multi-view normal maps and the corresponding color images. To
ensure the consistency of generation, we employ a multi-view cross-domain
attention mechanism that facilitates information exchange across views and
modalities. Lastly, we introduce a cascaded 3D mesh extraction algorithm that
drives high-quality surfaces from the multi-view 2D representations in only
about $3$ minute in a coarse-to-fine manner. Our extensive evaluations
demonstrate that our method achieves high-quality reconstruction results,
robust generalization, and good efficiency compared to prior works. Code
available at https://github.com/xxlong0/Wonder3D/tree/Wonder3D_Plus.

</details>


### [179] [UniLION: Towards Unified Autonomous Driving Model with Linear Group RNNs](https://arxiv.org/abs/2511.01768)
*Zhe Liu,Jinghua Hou,Xiaoqing Ye,Jingdong Wang,Hengshuang Zhao,Xiang Bai*

Main category: cs.CV

TL;DR: UniLION是一个统一的自动驾驶模型，通过线性组RNN操作高效处理大规模LiDAR点云、多视角图像和时间序列，无需显式融合模块，支持多种配置，并在多个核心任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决传统Transformer在处理长序列数据时计算开销大的问题，简化多模态和多任务自动驾驶系统的设计。

Method: 基于线性组RNN操作，支持LiDAR-only、多模态等多种配置，无需显式融合模块。

Result: 在3D感知、预测和规划等任务中表现优异，甚至达到最先进水平。

Conclusion: UniLION为自动驾驶3D基础模型的发展提供了新视角，简化系统设计并保持高性能。

Abstract: Although transformers have demonstrated remarkable capabilities across
various domains, their quadratic attention mechanisms introduce significant
computational overhead when processing long-sequence data. In this paper, we
present a unified autonomous driving model, UniLION, which efficiently handles
large-scale LiDAR point clouds, high-resolution multi-view images, and even
temporal sequences based on the linear group RNN operator (i.e., performs
linear RNN for grouped features). Remarkably, UniLION serves as a single
versatile architecture that can seamlessly support multiple specialized
variants (i.e., LiDAR-only, temporal LiDAR, multi-modal, and multi-modal
temporal fusion configurations) without requiring explicit temporal or
multi-modal fusion modules. Moreover, UniLION consistently delivers competitive
and even state-of-the-art performance across a wide range of core tasks,
including 3D perception (e.g., 3D object detection, 3D object tracking, 3D
occupancy prediction, BEV map segmentation), prediction (e.g., motion
prediction), and planning (e.g., end-to-end planning). This unified paradigm
naturally simplifies the design of multi-modal and multi-task autonomous
driving systems while maintaining superior performance. Ultimately, we hope
UniLION offers a fresh perspective on the development of 3D foundation models
in autonomous driving. Code is available at
https://github.com/happinesslz/UniLION

</details>


### [180] [How Far Are Surgeons from Surgical World Models? A Pilot Study on Zero-shot Surgical Video Generation with Expert Assessment](https://arxiv.org/abs/2511.01775)
*Zhen Chen,Qing Xu,Jinlin Wu,Biao Yang,Yuhao Zhai,Geng Guo,Jing Zhang,Yinlu Ding,Nassir Navab,Jiebo Luo*

Main category: cs.CV

TL;DR: SurgVeo是首个专家策划的手术视频生成基准，结合SPP框架评估模型输出，发现Veo-3在视觉感知上表现优异，但在高阶手术逻辑上存在明显差距。


<details>
  <summary>Details</summary>
Motivation: 探索视频生成模型在需要深度专业因果知识的高风险领域（如手术）中的应用，填补现有研究空白。

Method: 提出SurgVeo基准和SPP四层框架，用Veo-3模型进行零样本预测任务，并由专家评估生成视频。

Result: Veo-3在视觉感知上表现优异，但在器械操作、环境反馈和手术意图等高阶逻辑上表现不佳。

Conclusion: 研究揭示了视觉模拟与因果理解之间的差距，为未来医疗领域AI模型发展提供了基础。

Abstract: Foundation models in video generation are demonstrating remarkable
capabilities as potential world models for simulating the physical world.
However, their application in high-stakes domains like surgery, which demand
deep, specialized causal knowledge rather than general physical rules, remains
a critical unexplored gap. To systematically address this challenge, we present
SurgVeo, the first expert-curated benchmark for video generation model
evaluation in surgery, and the Surgical Plausibility Pyramid (SPP), a novel,
four-tiered framework tailored to assess model outputs from basic appearance to
complex surgical strategy. On the basis of the SurgVeo benchmark, we task the
advanced Veo-3 model with a zero-shot prediction task on surgical clips from
laparoscopic and neurosurgical procedures. A panel of four board-certified
surgeons evaluates the generated videos according to the SPP. Our results
reveal a distinct "plausibility gap": while Veo-3 achieves exceptional Visual
Perceptual Plausibility, it fails critically at higher levels of the SPP,
including Instrument Operation Plausibility, Environment Feedback Plausibility,
and Surgical Intent Plausibility. This work provides the first quantitative
evidence of the chasm between visually convincing mimicry and causal
understanding in surgical AI. Our findings from SurgVeo and the SPP establish a
crucial foundation and roadmap for developing future models capable of
navigating the complexities of specialized, real-world healthcare domains.

</details>


### [181] [PROPEX-RAG: Enhanced GraphRAG using Prompt-Driven Prompt Execution](https://arxiv.org/abs/2511.01802)
*Tejas Sarnaik,Manan Shah,Ravi Hegde*

Main category: cs.CV

TL;DR: 论文提出了一个基于提示驱动的GraphRAG框架，通过优化提示设计提升多跳问答中的检索和推理能力，并在HotpotQA和2WikiMultiHopQA数据集上取得了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于图的检索增强生成（RAG）方法在复杂推理中表现良好，但提示设计对检索和推理过程的影响尚未充分研究。

Method: 提出GraphRAG框架，通过符号知识图谱编码实体和事实关系，结合个性化PageRank（PPR）进行高效检索，并利用LLM进行语义过滤和答案生成。

Result: 在HotpotQA和2WikiMultiHopQA数据集上分别达到80.7%和78.9%的F1分数，以及97.1%和98.1%的Recall@5分数。

Conclusion: 提示设计对提升检索准确性和响应质量至关重要，为高效且可解释的多跳问答系统奠定了基础。

Abstract: Retrieval-Augmented Generation (RAG) has become a robust framework for
enhancing Large Language Models (LLMs) with external knowledge. Recent advances
in RAG have investigated graph based retrieval for intricate reasoning;
however, the influence of prompt design on enhancing the retrieval and
reasoning process is still considerably under-examined. In this paper, we
present a prompt-driven GraphRAG framework that underscores the significance of
prompt formulation in facilitating entity extraction, fact selection, and
passage reranking for multi-hop question answering. Our approach creates a
symbolic knowledge graph from text data by encoding entities and factual
relationships as structured facts triples. We use LLMs selectively during
online retrieval to perform semantic filtering and answer generation. We also
use entity-guided graph traversal through Personalized PageRank (PPR) to
support efficient, scalable retrieval based on the knowledge graph we built.
Our system gets state-of-the-art performance on HotpotQA and 2WikiMultiHopQA,
with F1 scores of 80.7% and 78.9%, and Recall@5 scores of 97.1% and 98.1%,
respectively. These results show that prompt design is an important part of
improving retrieval accuracy and response quality. This research lays the
groundwork for more efficient and comprehensible multi-hop question-answering
systems, highlighting the importance of prompt-aware graph reasoning.

</details>


### [182] [SciTextures: Collecting and Connecting Visual Patterns, Models, and Code Across Science and Art](https://arxiv.org/abs/2511.01817)
*Sagi Eppel,Alona Strugatski*

Main category: cs.CV

TL;DR: Scitextures数据集是一个大规模的科学、技术和艺术领域的纹理和视觉模式集合，用于探索视觉模式与生成机制之间的联系。


<details>
  <summary>Details</summary>
Motivation: 研究视觉模式与生成机制之间的联系，以促进对视觉理解的深入认识。

Method: 通过自主收集和实现模型的AI管道创建数据集，并评估AI模型在链接视觉模式与生成机制方面的能力。

Result: 视觉语言模型（VLMs）能够理解和模拟视觉模式背后的物理系统。

Conclusion: Scitextures数据集为研究视觉模式与生成机制之间的关系提供了重要资源，并展示了AI在此领域的潜力。

Abstract: The ability to connect visual patterns with the processes that form them
represents one of the deepest forms of visual understanding. Textures of clouds
and waves, the growth of cities and forests, or the formation of materials and
landscapes are all examples of patterns emerging from underlying mechanisms. We
present the Scitextures dataset, a large-scale collection of textures and
visual patterns from all domains of science, tech, and art, along with the
models and code that generate these images. Covering over 1,200 different
models and 100,000 images of patterns and textures from physics, chemistry,
biology, sociology, technology, mathematics, and art, this dataset offers a way
to explore the connection between the visual patterns that shape our world and
the mechanisms that produce them. Created by an agentic AI pipeline that
autonomously collects and implements models in standardized form, we use
SciTextures to evaluate the ability of leading AI models to link visual
patterns to the models and code that generate them, and to identify different
patterns that emerged from the same process. We also test AIs ability to infer
and recreate the mechanisms behind visual patterns by providing a natural image
of a real-world pattern and asking the AI to identify, model, and code the
mechanism that formed the pattern, then run this code to generate a simulated
image that is compared to the real image. These benchmarks show that
vision-language models (VLMs) can understand and simulate the physical system
beyond a visual pattern. The dataset and code are available at:
https://zenodo.org/records/17485502

</details>


### [183] [TIR-Bench: A Comprehensive Benchmark for Agentic Thinking-with-Images Reasoning](https://arxiv.org/abs/2511.01833)
*Ming Li,Jike Zhong,Shitian Zhao,Haoquan Zhang,Shaoheng Lin,Yuxiang Lai,Wei Chen,Konstantinos Psounis,Kaipeng Zhang*

Main category: cs.CV

TL;DR: TIR-Bench是一个用于评估图像思维能力的综合基准测试，涵盖13种任务，挑战现有多模态大语言模型的工具使用能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试无法充分评估高级图像思维能力，如动态和工具依赖的推理。

Method: 引入TIR-Bench，评估22种多模态大语言模型在复杂任务中的表现。

Result: TIR-Bench对所有模型都具有挑战性，真正需要图像思维能力才能表现优异。

Conclusion: TIR-Bench填补了现有基准测试的不足，并展示了直接与代理微调的对比研究。

Abstract: The frontier of visual reasoning is shifting toward models like OpenAI o3,
which can intelligently create and operate tools to transform images for
problem-solving, also known as thinking-\textit{with}-images in
chain-of-thought. Yet existing benchmarks fail to fully capture this advanced
capability. Even Visual Search, the most common benchmark for current
thinking-\textit{with}-images methods, tests only basic operations such as
localization and cropping, offering little insight into more complex, dynamic,
and tool-dependent reasoning. We introduce \textbf{TIR-Bench}, a comprehensive
benchmark for evaluating agentic thinking-with-images across 13 diverse tasks,
each requiring novel tool use for image processing and manipulation in
chain-of-thought. We evaluate 22 multimodal large language models (MLLMs), from
leading open-sourced and proprietary models to those with explicit tool-use
augmentation. Results show that TIR-Bench is universally challenging, and
strong performance requires genuine thinking-with-images capabilities. Finally,
we present a pilot study comparing direct versus agentic fine-tuning.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [184] [VRScout: Towards Real-Time, Autonomous Testing of Virtual Reality Games](https://arxiv.org/abs/2511.00002)
*Yurun Wu,Yousong Sun,Burkhard Wunsche,Jia Wang,Elliott Wen*

Main category: cs.LG

TL;DR: VRScout是一个基于深度学习的代理，能够自主导航VR环境并以人类方式实时交互，解决了VR内容质量保证的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统的人工质量保证方法效率低且难以扩展，而VR的高维感官输入和实时性能要求使自动化测试更具挑战性。

Method: VRScout通过增强的Action Chunking Transformer从人类演示中学习，预测多步动作序列，并引入动态可调滑动视窗以平衡响应速度和精度。

Result: VRScout在商业VR游戏中表现出专家级性能，仅需少量训练数据，并在消费级硬件上实现60 FPS的实时推理。

Conclusion: VRScout为自动化VR游戏测试提供了实用且可扩展的框架，适用于质量保证和安全审计。

Abstract: Virtual Reality (VR) has rapidly become a mainstream platform for gaming and
interactive experiences, yet ensuring the quality, safety, and appropriateness
of VR content remains a pressing challenge. Traditional human-based quality
assurance is labor-intensive and cannot scale with the industry's rapid growth.
While automated testing has been applied to traditional 2D and 3D games,
extending it to VR introduces unique difficulties due to high-dimensional
sensory inputs and strict real-time performance requirements. We present
VRScout, a deep learning-based agent capable of autonomously navigating VR
environments and interacting with virtual objects in a human-like and real-time
manner. VRScout learns from human demonstrations using an enhanced Action
Chunking Transformer that predicts multi-step action sequences. This enables
our agent to capture higher-level strategies and generalize across diverse
environments. To balance responsiveness and precision, we introduce a
dynamically adjustable sliding horizon that adapts the agent's temporal context
at runtime. We evaluate VRScout on commercial VR titles and show that it
achieves expert-level performance with only limited training data, while
maintaining real-time inference at 60 FPS on consumer-grade hardware. These
results position VRScout as a practical and scalable framework for automated VR
game testing, with direct applications in both quality assurance and safety
auditing.

</details>


### [185] [Feature-Guided SAE Steering for Refusal-Rate Control using Contrasting Prompts](https://arxiv.org/abs/2511.00029)
*Samaksh Bhargav,Zining Zhu*

Main category: cs.LG

TL;DR: 通过稀疏自编码器（SAEs）选择最优特征，提升LLM的安全性和实用性。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在调整模型权重和特征选择上的不足，优化安全性与实用性的权衡。

Method: 使用对比提示方法和数据集选择最优特征，测试于Llama-3 8B模型。

Result: 安全性提升18.9%，实用性提升11.1%。

Conclusion: 目标性SAE导向可克服传统安全性与实用性的权衡。

Abstract: Large Language Model (LLM) deployment requires guiding the LLM to recognize
and not answer unsafe prompts while complying with safe prompts. Previous
methods for achieving this require adjusting model weights along with other
expensive procedures. While recent advances in Sparse Autoencoders (SAEs) have
enabled interpretable feature extraction from LLMs, existing approaches lack
systematic feature selection methods and principled evaluation of
safety-utility tradeoffs. We explored using different steering features and
steering strengths using Sparse Auto Encoders (SAEs) to provide a solution.
Using an accurate and innovative contrasting prompt method with the
AI-Generated Prompts Dataset from teknium/OpenHermes-2p5-Mistral-7B and Air
Bench eu-dataset to efficiently choose the best features in the model to steer,
we tested this method on Llama-3 8B. We conclude that using this method, our
approach achieves an 18.9% improvement in safety performance while
simultaneously increasing utility by 11.1%, demonstrating that targeted SAE
steering can overcome traditional safety-utility tradeoffs when optimal
features are identified through principled selection methods.

</details>


### [186] [Probing Knowledge Holes in Unlearned LLMs](https://arxiv.org/abs/2511.00030)
*Myeongseob Ko,Hoang Anh Just,Charles Fleming,Ming Jin,Ruoxi Jia*

Main category: cs.LG

TL;DR: 论文探讨了机器遗忘技术可能导致的“知识漏洞”问题，并提出了一种测试框架来揭示这些漏洞。


<details>
  <summary>Details</summary>
Motivation: 研究机器遗忘技术在移除不良知识时可能意外丢失良性知识的问题。

Method: 提出测试用例生成框架，探索遗忘内容邻近区域及潜在失败点。

Result: 评估显示高达98.7%的测试用例在遗忘模型中产生无关或无意义回答。

Conclusion: 需重新思考评估遗忘技术知识保留的方法，超越静态基准测试。

Abstract: Machine unlearning has emerged as a prevalent technical solution for
selectively removing unwanted knowledge absorbed during pre-training, without
requiring full retraining. While recent unlearning techniques can effectively
remove undesirable content without severely compromising performance on
standard benchmarks, we find that they may inadvertently create ``knowledge
holes'' -- unintended losses of benign knowledge that standard benchmarks fail
to capture. To probe where unlearned models reveal knowledge holes, we propose
a test case generation framework that explores both immediate neighbors of
unlearned content and broader areas of potential failures. Our evaluation
demonstrates significant hidden costs of unlearning: up to 98.7\% of the test
cases yield irrelevant or nonsensical responses from unlearned models, despite
being answerable by the pretrained model. These findings necessitate rethinking
the conventional approach to evaluating knowledge preservation in unlearning,
moving beyond standard, static benchmarks.

</details>


### [187] [From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators](https://arxiv.org/abs/2511.00032)
*Lei Liu,Zhongyi Yu,Hong Wang,Huanshuo Dong,Haiyang Xin,Hongwei Zhao,Bin Li*

Main category: cs.LG

TL;DR: 提出Skip-Block Routing (SBR)框架，用于Transformer-based神经算子，通过动态分配计算资源降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 当前神经算子在处理大规模工程任务时计算开销大，且物理场复杂度不均导致效率低下。

Method: SBR通过路由机制学习token的复杂度和排名，动态决定传递的token数量，集中处理复杂区域。

Result: 实验表明SBR可减少约50%的FLOPs，推理速度提升2倍且不损失精度。

Conclusion: SBR是一种通用框架，能有效提升神经算子的计算效率。

Abstract: In recent years, Neural Operators(NO) have gradually emerged as a popular
approach for solving Partial Differential Equations (PDEs). However, their
application to large-scale engineering tasks suffers from significant
computational overhead. And the fact that current models impose a uniform
computational cost while physical fields exhibit vastly different complexities
constitutes a fundamental mismatch, which is the root of this inefficiency. For
instance, in turbulence flows, intricate vortex regions require deeper network
processing compared to stable flows. To address this, we introduce a framework:
Skip-Block Routing (SBR), a general framework designed for Transformer-based
neural operators, capable of being integrated into their multi-layer
architectures. First, SBR uses a routing mechanism to learn the complexity and
ranking of tokens, which is then applied during inference. Then, in later
layers, it decides how many tokens are passed forward based on this ranking.
This way, the model focuses more processing capacity on the tokens that are
more complex. Experiments demonstrate that SBR is a general framework that
seamlessly integrates into various neural operators. Our method reduces
computational cost by approximately 50% in terms of Floating Point Operations
(FLOPs), while still delivering up to 2x faster inference without sacrificing
accuracy.

</details>


### [188] [Neural Architecture Search for global multi-step Forecasting of Energy Production Time Series](https://arxiv.org/abs/2511.00035)
*Georg Velev,Stefan Lessmann*

Main category: cs.LG

TL;DR: 提出了一种基于神经架构搜索（NAS）的框架，用于自动发现高效、准确且泛化能力强的时序模型，用于能源生产的短期预测。


<details>
  <summary>Details</summary>
Motivation: 能源领域需要高精度和高效能的短期预测方法，但传统手动配置方法耗时且易出错，且需处理时序数据的动态性和泛化问题。

Method: 设计了一个NAS框架，包含高效组件搜索空间和考虑泛化能力的新目标函数。

Result: 实验表明，NAS发现的轻量级架构在效率和准确性上优于Transformer等现有技术。

Conclusion: NAS框架能有效解决能源预测中的计算效率和泛化问题，优于现有方法。

Abstract: The dynamic energy sector requires both predictive accuracy and runtime
efficiency for short-term forecasting of energy generation under operational
constraints, where timely and precise predictions are crucial. The manual
configuration of complex methods, which can generate accurate global multi-step
predictions without suffering from a computational bottleneck, represents a
procedure with significant time requirements and high risk for human-made
errors. A further intricacy arises from the temporal dynamics present in
energy-related data. Additionally, the generalization to unseen data is
imperative for continuously deploying forecasting techniques over time. To
overcome these challenges, in this research, we design a neural architecture
search (NAS)-based framework for the automated discovery of time series models
that strike a balance between computational efficiency, predictive performance,
and generalization power for the global, multi-step short-term forecasting of
energy production time series. In particular, we introduce a search space
consisting only of efficient components, which can capture distinctive patterns
of energy time series. Furthermore, we formulate a novel objective function
that accounts for performance generalization in temporal context and the
maximal exploration of different regions of our high-dimensional search space.
The results obtained on energy production time series show that an ensemble of
lightweight architectures discovered with NAS outperforms state-of-the-art
techniques, such as Transformers, as well as pre-trained forecasting models, in
terms of both efficiency and accuracy.

</details>


### [189] [Semi-Supervised Preference Optimization with Limited Feedback](https://arxiv.org/abs/2511.00040)
*Seonggyun Lee,Sungjun Lim,Seojin Park,Soeun Cheon,Kyungwoo Song*

Main category: cs.LG

TL;DR: 提出半监督偏好优化（SSPO）方法，利用少量配对标签和大量未配对数据，显著降低资源消耗。


<details>
  <summary>Details</summary>
Motivation: 现有偏好优化方法依赖大量配对反馈数据，资源消耗大，SSPO旨在解决这一问题。

Method: 通过理论证明存在最优奖励阈值，用于伪标记未配对数据，从而从大规模未配对数据中提取潜在偏好。

Result: 实验表明SSPO在仅使用1%数据时，性能优于使用10%数据的基线方法。

Conclusion: SSPO能高效利用未配对数据，显著降低资源成本，同时保持人类偏好对齐。

Abstract: The field of preference optimization has made outstanding contributions to
the alignment of language models with human preferences. Despite these
advancements, recent methods still rely heavily on substantial paired (labeled)
feedback data, leading to substantial resource expenditures. To address these
challenges, we study the problem of Semi-Supervised Preference Optimization
(SSPO) in which the idea is to learn from both a small number of pairwise
preference labels and a large pool of unpaired samples simultaneously. Our key
theoretical contribution proves the existence of an optimal reward threshold
capable of separating winning and losing responses with high probability, which
enables a principled pseudo-labeling of unpaired data. By leveraging these
pseudo-labels, SSPO effectively distills latent preferences from large-scale
unpaired data, thus maintaining human alignment while drastically reducing
acquisition costs. Extensive experiments across datasets validate this
remarkable data efficiency; for instance, SSPO trained with Llama3-8B-Instruct
on just 1% of UltraFeedback consistently surpasses strong baselines trained on
10% of UltraFeedback.

</details>


### [190] [Physics-Informed Neural Network Frameworks for the Analysis of Engineering and Biological Dynamical Systems Governed by Ordinary Differential Equations](https://arxiv.org/abs/2511.00043)
*Tyrus Whitman,Andrew Particka,Christopher Diers,Ian Griffin,Charuka Wickramasinghe,Pradeep Ranaweera*

Main category: cs.LG

TL;DR: PINNs方法在解决复杂ODE问题时表现出色，通过嵌入物理定律和调整超参数实现高精度解。


<details>
  <summary>Details</summary>
Motivation: 传统数值方法在处理高刚度、冲击等问题时难以收敛，PINNs提供了一种更强大的替代方案。

Method: 使用经典ODE问题作为测试平台，系统评估PINNs的准确性、训练效率和泛化能力。

Result: 通过平衡损失函数和调整超参数，PINNs在复杂问题中表现出色。

Conclusion: PINNs通过嵌入物理定律和优化网络架构，显著提升了预测能力。

Abstract: In this study, we present and validate the predictive capability of the
Physics-Informed Neural Networks (PINNs) methodology for solving a variety of
engineering and biological dynamical systems governed by ordinary differential
equations (ODEs). While traditional numerical methods a re effective for many
ODEs, they often struggle to achieve convergence in problems involving high
stiffness, shocks, irregular domains, singular perturbations, high dimensions,
or boundary discontinuities. Alternatively, PINNs offer a powerful approach for
handling challenging numerical scenarios. In this study, classical ODE problems
are employed as controlled testbeds to systematically evaluate the accuracy,
training efficiency, and generalization capability under controlled conditions
of the PINNs framework. Although not a universal solution, PINNs can achieve
superior results by embedding physical laws directly into the learning process.
We first analyze the existence and uniqueness properties of several benchmark
problems and subsequently validate the PINNs methodology on these model
systems. Our results demonstrate that for complex problems to converge to
correct solutions, the loss function components data loss, initial condition
loss, and residual loss must be appropriately balanced through careful
weighting. We further establish that systematic tuning of hyperparameters,
including network depth, layer width, activation functions, learning rate,
optimization algorithms, w eight initialization schemes, and collocation point
sampling, plays a crucial role in achieving accurate solutions. Additionally,
embedding prior knowledge and imposing hard constraints on the network
architecture, without loss the generality of the ODE system, significantly
enhances the predictive capability of PINNs.

</details>


### [191] [ReLaX-Net: Reusing Layers for Parameter-Efficient Physical Neural Networks](https://arxiv.org/abs/2511.00044)
*Kohei Tsuchiyama,Andre Roehm,Takatomo Mihana,Ryoichi Horisaki*

Main category: cs.LG

TL;DR: ReLaX-Net通过时间复用层来扩展物理神经网络（PNN）的深度，提高参数效率，性能优于传统RNN或DNN。


<details>
  <summary>Details</summary>
Motivation: PNN在规模和性能上落后于数字神经网络，需要参数高效的设计来提升计算性能。

Method: 提出ReLaX-Net架构，通过时间复用层和快速开关扩展网络深度，优化参数使用。

Result: 在图像分类和自然语言处理任务中，ReLaX-Net性能优于传统RNN或DNN。

Conclusion: ReLaX-Net是提升PNN性能的有效方法，仅需少量硬件修改即可实现。

Abstract: Physical Neural Networks (PNN) are promising platforms for next-generation
computing systems. However, recent advances in digital neural network
performance are largely driven by the rapid growth in the number of trainable
parameters and, so far, demonstrated PNNs are lagging behind by several orders
of magnitude in terms of scale. This mirrors size and performance constraints
found in early digital neural networks. In that period, efficient reuse of
parameters contributed to the development of parameter-efficient architectures
such as convolutional neural networks.
  In this work, we numerically investigate hardware-friendly weight-tying for
PNNs. Crucially, with many PNN systems, there is a time-scale separation
between the fast dynamic active elements of the forward pass and the only
slowly trainable elements implementing weights and biases. With this in mind,we
propose the Reuse of Layers for eXpanding a Neural Network (ReLaX-Net)
architecture, which employs a simple layer-by-layer time-multiplexing scheme to
increase the effective network depth and efficiently use the number of
parameters. We only require the addition of fast switches for existing PNNs. We
validate ReLaX-Nets via numerical experiments on image classification and
natural language processing tasks. Our results show that ReLaX-Net improves
computational performance with only minor modifications to a conventional PNN.
We observe a favorable scaling, where ReLaX-Nets exceed the performance of
equivalent traditional RNNs or DNNs with the same number of parameters.

</details>


### [192] [DynBERG: Dynamic BERT-based Graph neural network for financial fraud detection](https://arxiv.org/abs/2511.00047)
*Omkar Kulkarni,Rohitash Chandra*

Main category: cs.LG

TL;DR: DynBERG是一种结合Graph-BERT和GRU的新架构，用于动态金融交易网络的欺诈检测，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 金融交易网络具有动态性和有向性，现有静态图模型（如Graph-BERT）无法有效处理。

Method: 提出DynBERG，整合Graph-BERT和GRU层，支持有向边，捕捉时间动态。

Result: 在Elliptic数据集上表现优异，优于EvolveGCN和GCN，尤其在市场事件后。

Conclusion: DynBERG通过GRU有效建模时间动态，适用于动态金融欺诈检测。

Abstract: Financial fraud detection is critical for maintaining the integrity of
financial systems, particularly in decentralised environments such as
cryptocurrency networks. Although Graph Convolutional Networks (GCNs) are
widely used for financial fraud detection, graph Transformer models such as
Graph-BERT are gaining prominence due to their Transformer-based architecture,
which mitigates issues such as over-smoothing. Graph-BERT is designed for
static graphs and primarily evaluated on citation networks with undirected
edges. However, financial transaction networks are inherently dynamic, with
evolving structures and directed edges representing the flow of money. To
address these challenges, we introduce DynBERG, a novel architecture that
integrates Graph-BERT with a Gated Recurrent Unit (GRU) layer to capture
temporal evolution over multiple time steps. Additionally, we modify the
underlying algorithm to support directed edges, making DynBERG well-suited for
dynamic financial transaction analysis. We evaluate our model on the Elliptic
dataset, which includes Bitcoin transactions, including all transactions during
a major cryptocurrency market event, the Dark Market Shutdown. By assessing
DynBERG's resilience before and after this event, we analyse its ability to
adapt to significant market shifts that impact transaction behaviours. Our
model is benchmarked against state-of-the-art dynamic graph classification
approaches, such as EvolveGCN and GCN, demonstrating superior performance,
outperforming EvolveGCN before the market shutdown and surpassing GCN after the
event. Additionally, an ablation study highlights the critical role of
incorporating a time-series deep learning component, showcasing the
effectiveness of GRU in modelling the temporal dynamics of financial
transactions.

</details>


### [193] [Adaptive Spatio-Temporal Graphs with Self-Supervised Pretraining for Multi-Horizon Weather Forecasting](https://arxiv.org/abs/2511.00049)
*Yao Liu*

Main category: cs.LG

TL;DR: 提出了一种基于自监督学习的多变量天气预测框架，结合图神经网络和时空适应机制，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 天气预测因大气系统的时空复杂性而具有挑战性，需要更准确和鲁棒的解决方案。

Method: 使用图神经网络进行空间推理，自监督预训练学习表示，时空适应机制提升泛化能力。

Result: 在ERA5和MERRA-2数据集上表现优于传统数值天气预测模型和深度学习方法。

Conclusion: 该框架为数据驱动的天气预测系统提供了可扩展且标签高效的解决方案。

Abstract: Accurate and robust weather forecasting remains a fundamental challenge due
to the inherent spatio-temporal complexity of atmospheric systems. In this
paper, we propose a novel self-supervised learning framework that leverages
spatio-temporal structures to improve multi-variable weather prediction. The
model integrates a graph neural network (GNN) for spatial reasoning, a
self-supervised pretraining scheme for representation learning, and a
spatio-temporal adaptation mechanism to enhance generalization across varying
forecasting horizons. Extensive experiments on both ERA5 and MERRA-2 reanalysis
datasets demonstrate that our approach achieves superior performance compared
to traditional numerical weather prediction (NWP) models and recent deep
learning methods. Quantitative evaluations and visual analyses in Beijing and
Shanghai confirm the model's capability to capture fine-grained meteorological
patterns. The proposed framework provides a scalable and label-efficient
solution for future data-driven weather forecasting systems.

</details>


### [194] [FLoRA: Fused forward-backward adapters for parameter efficient fine-tuning and reducing inference-time latencies of LLMs](https://arxiv.org/abs/2511.00050)
*Dhananjaya Gowda,Seoha Song,Junhyun Lee,Harshith Goka*

Main category: cs.LG

TL;DR: FLoRA是一种参数高效微调方法，结合了LoRA和并行适配器的优点，显著提高了准确性和降低了延迟。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型规模的增大，高效微调变得尤为重要，但现有方法仍有改进空间。

Method: 提出FLoRA，一种融合前向-后向适配器（FFBA）的方法，结合LoRA和并行适配器的思想，并将其融合到基础模型的投影层中。

Result: 实验表明，FLoRA在相同参数预算下，比LoRA在准确性和延迟上表现更优。

Conclusion: FLoRA为参数高效微调提供了一种更优的解决方案。

Abstract: As the large language models (LLMs) grow in size each day, efficient training
and fine-tuning has never been as important as nowadays. This resulted in the
great interest in parameter efficient fine-tuning (PEFT), and effective methods
including low-rank adapters (LoRA) has emerged. Although the various PEFT
methods have been studied extensively in the recent years, the greater part of
the subject remains unexplored with the huge degree of freedom. In this paper,
we propose FLoRA, a family of fused forward-backward adapters (FFBA) for
parameter-efficient fine-tuning of LLMs on downstream tasks. The FFBA combine
ideas from the popular LoRA and parallel adapters to improve the overall
fine-tuning accuracies. At the same time, latencies are minimized by fusing the
forward and backward adapters into existing projection layers of the base
model. Experimental results show that the proposed FFB adapters perform
significantly better than the popularly used LoRA in both accuracy and latency
for a similar parameter budget.

</details>


### [195] [Calibrating and Rotating: A Unified Framework for Weight Conditioning in PEFT](https://arxiv.org/abs/2511.00051)
*Da Chang,Peng Xue,Yu Li,Yongxiang Liu,Pengxiang Xu,Shixun Zhang*

Main category: cs.LG

TL;DR: 论文提出了一种基于LoRA和DoRA改进的参数高效微调方法，通过分析DoRA的机制并优化其计算效率，提出了两种新方法Pre-Diag和SORA，在性能和效率上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: DoRA方法虽然提升了性能，但其机制不明确且计算开销大，因此需要更高效且性能优越的PEFT方法。

Method: 通过分析DoRA的机制，将其重新表述为更高效的矩阵形式，并提出Pre-Diag和SORA两种新方法。

Result: 在自然语言理解和生成任务中，新方法在性能和效率上均优于LoRA和DoRA。

Conclusion: 论文提出的Pre-Diag和SORA方法在参数高效微调中表现出色，为PEFT方法设计提供了新思路。

Abstract: Parameter-Efficient Fine-Tuning (PEFT) methods are crucial for adapting large
pre-trained models. Among these, LoRA is considered a foundational approach.
Building on this, the influential DoRA method enhances performance by
decomposing weight updates into magnitude and direction. However, its
underlying mechanism remains unclear, and it introduces significant
computational overhead. In this work, we first identify that DoRA's success
stems from its capacity to increase the singular value entropy of the weight
update matrix, which promotes a more uniform update distribution akin to full
fine-tuning. We then reformulate DoRA into a mathematically equivalent and more
efficient matrix form, revealing it as a learnable weight conditioning method.
Based on this insight, we propose a unified framework for designing advanced
PEFT methods by exploring two orthogonal dimensions: the architectural
placement and the transformation type of the conditioning matrix. Within this
framework, we introduce two novel methods: (1) \textbf{Pre-Diag}, which applies
a diagonal conditioning matrix before the LoRA update to efficiently calibrate
the pre-trained weights, thereby enhancing performance while reducing training
time; and (2) \textbf{S}kewed \textbf{O}rthogonal \textbf{R}otation
\textbf{A}daptation (\textbf{SORA}), which employs a parameter-efficient
orthogonal rotation to perform a more powerful, norm-preserving transformation
of the feature space. Extensive experiments on natural language understanding
and generation tasks demonstrate that our proposed methods achieve superior
performance and efficiency compared to both LoRA and DoRA. The code is
available at https://github.com/MaeChd/SORA.

</details>


### [196] [Feature-Guided Analysis of Neural Networks: A Replication Study](https://arxiv.org/abs/2511.00052)
*Federico Formica,Stefano Gregis,Aurora Francesca Zanenga,Andrea Rota,Mark Lawford,Claudio Menghi*

Main category: cs.LG

TL;DR: 论文评估了特征引导分析（FGA）在MNIST和LSC数据集上的适用性，发现其精度高于文献结果，并探讨了神经网络架构、训练和特征选择对FGA效果的影响。


<details>
  <summary>Details</summary>
Motivation: 理解神经网络决策原因对安全关键应用至关重要，但现有特征引导方法在工业环境中的适用性缺乏实证支持。

Method: 使用MNIST和LSC数据集作为基准，评估FGA在解释神经网络行为时的有效性，并分析神经网络架构、训练和特征选择的影响。

Result: FGA在基准测试中表现出更高的精度，特征选择显著影响召回率但对精度影响较小。

Conclusion: FGA在解释神经网络行为方面具有潜力，但特征选择对其效果有重要影响。

Abstract: Understanding why neural networks make certain decisions is pivotal for their
use in safety-critical applications. Feature-Guided Analysis (FGA) extracts
slices of neural networks relevant to their tasks. Existing feature-guided
approaches typically monitor the activation of the neural network neurons to
extract the relevant rules. Preliminary results are encouraging and demonstrate
the feasibility of this solution by assessing the precision and recall of
Feature-Guided Analysis on two pilot case studies. However, the applicability
in industrial contexts needs additional empirical evidence.
  To mitigate this need, this paper assesses the applicability of FGA on a
benchmark made by the MNIST and LSC datasets. We assessed the effectiveness of
FGA in computing rules that explain the behavior of the neural network. Our
results show that FGA has a higher precision on our benchmark than the results
from the literature. We also evaluated how the selection of the neural network
architecture, training, and feature selection affect the effectiveness of FGA.
Our results show that the selection significantly affects the recall of FGA,
while it has a negligible impact on its precision.

</details>


### [197] [Quadratic Direct Forecast for Training Multi-Step Time-Series Forecast Models](https://arxiv.org/abs/2511.00053)
*Hao Wang,Licheng Pan,Yuan Lu,Zhichao Chen,Tianqiao Liu,Shuting He,Zhixuan Chu,Qingsong Wen,Haoxuan Li,Zhouchen Lin*

Main category: cs.LG

TL;DR: 提出了一种新的二次形式加权训练目标，解决现有目标忽视标签自相关效应和任务权重不均的问题。


<details>
  <summary>Details</summary>
Motivation: 现有训练目标（如均方误差）将未来步骤视为独立、等权任务，导致标签自相关效应被忽视和任务权重不均，限制了预测性能。

Method: 提出二次形式加权训练目标，通过权重矩阵的非对角线元素捕捉标签自相关效应，非均匀对角线匹配不同未来步骤的任务权重。开发了QDF学习算法，动态更新权重矩阵。

Result: 实验表明QDF显著提升了多种预测模型的性能，达到最先进水平。

Conclusion: QDF通过同时解决标签自相关和任务权重问题，显著提升了时间序列预测模型的性能。

Abstract: The design of training objective is central to training time-series
forecasting models. Existing training objectives such as mean squared error
mostly treat each future step as an independent, equally weighted task, which
we found leading to the following two issues: (1) overlook the label
autocorrelation effect among future steps, leading to biased training
objective; (2) fail to set heterogeneous task weights for different forecasting
tasks corresponding to varying future steps, limiting the forecasting
performance. To fill this gap, we propose a novel quadratic-form weighted
training objective, addressing both of the issues simultaneously. Specifically,
the off-diagonal elements of the weighting matrix account for the label
autocorrelation effect, whereas the non-uniform diagonals are expected to match
the most preferable weights of the forecasting tasks with varying future steps.
To achieve this, we propose a Quadratic Direct Forecast (QDF) learning
algorithm, which trains the forecast model using the adaptively updated
quadratic-form weighting matrix. Experiments show that our QDF effectively
improves performance of various forecast models, achieving state-of-the-art
results. Code is available at https://anonymous.4open.science/r/QDF-8937.

</details>


### [198] [SpatialTraceGen: High-Fidelity Traces for Efficient VLM Spatial Reasoning Distillation](https://arxiv.org/abs/2511.00054)
*Gio Huh,Dhruv Sheth,Rayhan Zirvi,Frank Xiao*

Main category: cs.LG

TL;DR: SpatialTraceGen框架通过自动化验证器从大型教师模型中提取高质量的空间推理数据，解决了小模型微调中的数据效率问题。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在复杂空间推理方面表现不佳，且缺乏高质量的分步推理数据，限制了小模型的微调效果。

Method: 提出SpatialTraceGen框架，利用自动化验证器从大型教师模型中提取多跳、多工具推理轨迹，确保每一步的准确性。

Result: 在CLEVR-Humans基准测试中，验证器指导的流程将轨迹的平均质量分数提高了17%，质量方差降低了40%以上。

Conclusion: SpatialTraceGen提供了高质量的分步推理数据集，支持小模型的高效微调和离线强化学习。

Abstract: While Vision-Language Models (VLMs) excel in many areas, they struggle with
complex spatial reasoning, which requires problem decomposition and strategic
tool use. Fine-tuning smaller, more deployable models offers an efficient path
to strong performance, but this is hampered by a major bottleneck: the absence
of high-quality, step-by-step reasoning data. To address this data-efficiency
gap, we introduce SpatialTraceGen, a framework to distill the reasoning
processes of a large teacher model into a high-quality dataset of multi-hop,
multi-tool reasoning traces. A key innovation is our automated Verifier, which
scalably ensures the fidelity of each reasoning step, providing a
cost-effective alternative to manual human annotation. On the CLEVR-Humans
benchmark, this verifier-guided process improves the average quality score of
traces by 17\% while reducing quality variance by over 40\%. SpatialTraceGen
delivers a dataset of expert traces, providing the structured, step-by-step
examples of tool use necessary for effective fine-tuning and sample-efficient
offline reinforcement learning.

</details>


### [199] [Exploring Federated Learning for Thermal Urban Feature Segmentation -- A Comparison of Centralized and Decentralized Approaches](https://arxiv.org/abs/2511.00055)
*Leonhard Duda,Khadijeh Alibabaei,Elena Vollmer,Leon Klug,Valentin Kozlov,Lisana Berberi,Mishal Benz,Rebekka Volk,Juan Pedro Gutiérrez Hermosillo Muriedas,Markus Götz,Judith Sáínz-Pardo Díaz,Álvaro López García,Frank Schultmann,Achim Streit*

Main category: cs.LG

TL;DR: 论文研究了联邦学习（FL）在无人机（UAV）热成像图像分割任务中的实际应用和效果，比较了多种FL方法与集中式学习的性能。


<details>
  <summary>Details</summary>
Motivation: 由于隐私或技术限制，数据无法集中共享或存储，FL提供了一种分布式训练模型的方法，适用于无人机热成像数据的场景。

Method: 在真实部署场景中评估FL算法，比较了多种FL方法与集中式学习的性能指标（如模型准确性、训练时间、通信开销和能耗），并探索了不同FL工作流程。

Result: 研究发现FL在无人机热成像任务中具有实际应用价值，但面临数据分布不均和特征差异的挑战。

Conclusion: 论文为理解FL在无人机热成像分割任务中的实际应用和局限性提供了有价值的参考。

Abstract: Federated Learning (FL) is an approach for training a shared Machine Learning
(ML) model with distributed training data and multiple participants. FL allows
bypassing limitations of the traditional Centralized Machine Learning CL if
data cannot be shared or stored centrally due to privacy or technical
restrictions -- the participants train the model locally with their training
data and do not need to share it among the other participants. This paper
investigates the practical implementation and effectiveness of FL in a
real-world scenario, specifically focusing on unmanned aerial vehicle
(UAV)-based thermal images for common thermal feature detection in urban
environments. The distributed nature of the data arises naturally and makes it
suitable for FL applications, as images captured in two German cities are
available. This application presents unique challenges due to non-identical
distribution and feature characteristics of data captured at both locations.
The study makes several key contributions by evaluating FL algorithms in real
deployment scenarios rather than simulation. We compare several FL approaches
with a centralized learning baseline across key performance metrics such as
model accuracy, training time, communication overhead, and energy usage. This
paper also explores various FL workflows, comparing client-controlled workflows
and server-controlled workflows. The findings of this work serve as a valuable
reference for understanding the practical application and limitations of the FL
methods in segmentation tasks in UAV-based imaging.

</details>


### [200] [MISA: Memory-Efficient LLMs Optimization with Module-wise Importance Sampling](https://arxiv.org/abs/2511.00056)
*Yuxi Liu,Renjia Deng,Yutong He,Xue Wang,Tao Yao,Kun Yuan*

Main category: cs.LG

TL;DR: MISA是一种模块化重要性采样方法，通过分模块优化减少内存需求，提高性能。


<details>
  <summary>Details</summary>
Motivation: 现有分层优化方法忽略了模块重要性差异，内存节省有限。

Method: 将每层划分为模块，分配重要性分数，加权随机采样激活模块。

Result: 实验证明MISA有效，理论分析显示其梯度方差更小，收敛速度更快。

Conclusion: MISA在内存效率和性能上优于现有方法，适用于多样化学习任务。

Abstract: The substantial memory demands of pre-training and fine-tuning large language
models (LLMs) require memory-efficient optimization algorithms. One promising
approach is layer-wise optimization, which treats each transformer block as a
single layer and optimizes it sequentially, while freezing the other layers to
save optimizer states and activations. Although effective, these methods ignore
the varying importance of the modules within each layer, leading to suboptimal
performance. Moreover, layer-wise sampling provides only limited memory
savings, as at least one full layer must remain active during optimization. To
overcome these limitations, we propose Module-wise Importance SAmpling (MISA),
a novel method that divides each layer into smaller modules and assigns
importance scores to each module. MISA uses a weighted random sampling
mechanism to activate modules, provably reducing gradient variance compared to
layer-wise sampling. Additionally, we establish an \(\mathcal{O}(1/\sqrt{K})\)
convergence rate under non-convex and stochastic conditions, where $K$ is the
total number of block updates, and provide a detailed memory analysis
showcasing MISA's superiority over existing baseline methods. Experiments on
diverse learning tasks validate the effectiveness of MISA. Source code is
available at https://github.com/pkumelon/MISA.

</details>


### [201] [Automatically Finding Rule-Based Neurons in OthelloGPT](https://arxiv.org/abs/2511.00059)
*Aditya Singh,Zihang Wen,Srujananjali Medicherla,Adam Karvonen,Can Rager*

Main category: cs.LG

TL;DR: OthelloGPT是一个用于研究可解释性的理想测试平台，通过决策树方法识别和解释MLP神经元编码的规则游戏逻辑。


<details>
  <summary>Details</summary>
Motivation: 研究OthelloGPT的可解释性，揭示其神经元如何编码规则游戏逻辑。

Method: 使用回归决策树将棋盘状态映射到神经元激活，提取高活性路径并转换为可读逻辑形式。

Result: 约一半的神经元可通过紧凑的规则决策树描述（R²>0.7），其余可能参与分布式或非规则计算。

Conclusion: 决策树方法能有效识别因果相关模式，为未来可解释性研究提供工具支持。

Abstract: OthelloGPT, a transformer trained to predict valid moves in Othello, provides
an ideal testbed for interpretability research. The model is complex enough to
exhibit rich computational patterns, yet grounded in rule-based game logic that
enables meaningful reverse-engineering. We present an automated approach based
on decision trees to identify and interpret MLP neurons that encode rule-based
game logic. Our method trains regression decision trees to map board states to
neuron activations, then extracts decision paths where neurons are highly
active to convert them into human-readable logical forms. These descriptions
reveal highly interpretable patterns; for instance, neurons that specifically
detect when diagonal moves become legal. Our findings suggest that roughly half
of the neurons in layer 5 can be accurately described by compact, rule-based
decision trees ($R^2 > 0.7$ for 913 of 2,048 neurons), while the remainder
likely participate in more distributed or non-rule-based computations. We
verify the causal relevance of patterns identified by our decision trees
through targeted interventions. For a specific square, for specific game
patterns, we ablate neurons corresponding to those patterns and find an
approximately 5-10 fold stronger degradation in the model's ability to predict
legal moves along those patterns compared to control patterns. To facilitate
future work, we provide a Python tool that maps rule-based game behaviors to
their implementing neurons, serving as a resource for researchers to test
whether their interpretability methods recover meaningful computational
structures.

</details>


### [202] [EVINGCA: Adaptive Graph Clustering with Evolving Neighborhood Statistics](https://arxiv.org/abs/2511.00064)
*Randolph Wiredu-Aidoo*

Main category: cs.LG

TL;DR: EVINGCA是一种基于密度-方差的聚类算法，通过自适应最近邻图处理聚类问题，取代固定密度阈值，具有对数线性复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有聚类算法（如K-Means、DBSCAN）对数据分布假设严格或敏感，EVINGCA旨在解决这些问题。

Method: 通过广度优先搜索在最近邻图上动态扩展聚类，利用局部统计反馈更新距离和形状信息。

Result: 在合成和真实数据集上表现优异，复杂度为对数线性。

Conclusion: EVINGCA是一种高效且适应性强的聚类算法，适用于多种数据分布。

Abstract: Clustering algorithms often rely on restrictive assumptions: K-Means and
Gaussian Mixtures presuppose convex, Gaussian-like clusters, while DBSCAN and
HDBSCAN capture non-convexity but can be highly sensitive. I introduce EVINGCA
(Evolving Variance-Informed Nonparametric Graph Construction Algorithm), a
density-variance based clustering algorithm that treats cluster formation as an
adaptive, evolving process on a nearest-neighbor graph. EVINGCA expands rooted
graphs via breadth-first search, guided by continuously updated local distance
and shape statistics, replacing fixed density thresholds with local statistical
feedback. With spatial indexing, EVINGCA features log-linear complexity in the
average case and exhibits competitive performance against baselines across a
variety of synthetic, real-world, low-d, and high-d datasets.

</details>


### [203] [Aligning Brain Signals with Multimodal Speech and Vision Embeddings](https://arxiv.org/abs/2511.00065)
*Kateryna Shapovalenko,Quentin Auster*

Main category: cs.LG

TL;DR: 研究探讨了预训练模型的不同层如何反映大脑对语言的分层处理，通过比较wav2vec2和CLIP模型的嵌入与脑电信号（EEG）的对应关系。


<details>
  <summary>Details</summary>
Motivation: 受大脑通过多层处理构建意义的启发，研究旨在揭示预训练模型的哪些层最能反映大脑对语言的分层处理。

Method: 使用EEG记录自然语音感知时的脑活动，通过岭回归和对比解码比较wav2vec2和CLIP模型的嵌入与脑活动的对应关系，测试了三种策略：单层、渐进拼接和渐进求和。

Result: 结果表明，结合多模态和分层感知的表示可能更接近解码大脑如何理解语言（不仅是声音，还包括经验）。

Conclusion: 研究为理解大脑语言处理机制提供了新视角，强调了多模态和分层表示的重要性。

Abstract: When we hear the word "house", we don't just process sound, we imagine walls,
doors, memories. The brain builds meaning through layers, moving from raw
acoustics to rich, multimodal associations. Inspired by this, we build on
recent work from Meta that aligned EEG signals with averaged wav2vec2 speech
embeddings, and ask a deeper question: which layers of pre-trained models best
reflect this layered processing in the brain? We compare embeddings from two
models: wav2vec2, which encodes sound into language, and CLIP, which maps words
to images. Using EEG recorded during natural speech perception, we evaluate how
these embeddings align with brain activity using ridge regression and
contrastive decoding. We test three strategies: individual layers, progressive
concatenation, and progressive summation. The findings suggest that combining
multimodal, layer-aware representations may bring us closer to decoding how the
brain understands language, not just as sound, but as experience.

</details>


### [204] [Token-Regulated Group Relative Policy Optimization for Stable Reinforcement Learning in Large Language Models](https://arxiv.org/abs/2511.00066)
*Tue Le,Nghi D. Q. Bui,Linh Ngo Van,Trung Le*

Main category: cs.LG

TL;DR: TR-GRPO改进GRPO，通过加权调节高低概率token的梯度贡献，提升RLVR任务性能。


<details>
  <summary>Details</summary>
Motivation: 解决GRPO中低概率token梯度过大导致训练不稳定的问题。

Method: 引入token级权重，与模型预测概率正相关，抑制低概率token的梯度放大。

Result: 在逻辑、数学和代理推理任务中，TR-GRPO表现优于GRPO。

Conclusion: TR-GRPO是增强LLM推理能力的有效框架。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has emerged as a
powerful approach for strengthening the reasoning capabilities of large
language models (LLMs). Among existing algorithms, Group Relative Policy
Optimization (GRPO) has demonstrated strong performance, yet it suffers from a
critical issue: low-probability tokens disproportionately dominate gradient
updates due to their inherently large gradient magnitudes. This imbalance leads
to unstable training and suppresses the contribution of high-probability tokens
that are more reliable for learning. In this work, we introduce Token-Regulated
Group Relative Policy Optimization (TR-GRPO), a simple yet effective extension
of GRPO that assigns token-level weights positively correlated with the model's
predicted probability. By downweighting low-probability tokens and emphasizing
high-probability ones, TR-GRPO mitigates gradient over-amplification while
preserving informative learning signals. Extensive experiments demonstrate that
TR-GRPO consistently outperforms GRPO across RLVR tasks, including logic, math,
and agentic reasoning, highlighting the importance of regulating token
contributions during RL training and establishing TR-GRPO as a robust framework
for enhancing LLM reasoning.

</details>


### [205] [Latent Domain Prompt Learning for Vision-Language Models](https://arxiv.org/abs/2511.00067)
*Zhixing Li,Arsham Gholamzadeh Khoee,Yinan Yu*

Main category: cs.LG

TL;DR: 该论文提出了一种无需显式域标签的领域泛化方法，通过潜在域聚类和特征融合提升视觉语言模型在未知目标域的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有领域泛化方法依赖域标签，但这些标签可能不可用或模糊。本文研究无需显式域标签的领域泛化问题。

Method: 通过潜在域聚类自动发现训练数据中的潜在域，并基于输入图像与潜在域的相似性融合域特定文本特征。

Result: 在四个基准测试中，该方法优于基于视觉语言模型的基线，展示了在域偏移下的鲁棒性提升。

Conclusion: 该方法为领域泛化提供了新思路，尤其在无显式域标签的情况下，显著提升了模型的适应能力。

Abstract: The objective of domain generalization (DG) is to enable models to be robust
against domain shift. DG is crucial for deploying vision-language models (VLMs)
in real-world applications, yet most existing methods rely on domain labels
that may not be available and often ambiguous. We instead study the DG setting
where models must generalize well without access to explicit domain labels. Our
key idea is to represent an unseen target domain as a combination of latent
domains automatically discovered from training data, enabling the model to
adaptively transfer knowledge across domains. To realize this, we perform
latent domain clustering on image features and fuse domain-specific text
features based on the similarity between the input image and each latent
domain. Experiments on four benchmarks show that this strategy yields
consistent gains over VLM-based baselines and provides new insights into
improving robustness under domain shift.

</details>


### [206] [Benchmarking Generative AI Against Bayesian Optimization for Constrained Multi-Objective Inverse Design](https://arxiv.org/abs/2511.00070)
*Muhammad Bilal Awan,Abdul Razzaq,Abdul Shahid*

Main category: cs.LG

TL;DR: 本文研究了大型语言模型（LLMs）作为生成优化器在解决约束多目标回归任务中的表现，特别是在逆向设计领域。结果表明，LLMs在计算速度上优于传统方法，但专用优化框架仍具有最佳性能。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在约束、连续、高维数值空间任务中的适用性，尤其是在材料信息学中的逆向设计问题。

Method: 通过参数高效微调（PEFT）对LLMs和BERT模型进行微调，并将其与贝叶斯优化（BO）框架进行比较。

Result: 最佳LLM（WizardMath-7B）的表现显著优于传统BO基线（GD=1.21 vs. 15.03），但专用BO框架（qEHVI）仍达到完美收敛（GD=0.0）。

Conclusion: 专用BO框架在保证收敛性方面领先，但微调LLMs是一种快速且有潜力的替代方案，对AI驱动的优化领域具有重要意义。

Abstract: This paper investigates the performance of Large Language Models (LLMs) as
generative optimizers for solving constrained multi-objective regression tasks,
specifically within the challenging domain of inverse design
(property-to-structure mapping). This problem, critical to materials
informatics, demands finding complex, feasible input vectors that lie on the
Pareto optimal front. While LLMs have demonstrated universal effectiveness
across generative and reasoning tasks, their utility in constrained,
continuous, high-dimensional numerical spaces tasks they weren't explicitly
architected for remains an open research question. We conducted a rigorous
comparative study between established Bayesian Optimization (BO) frameworks and
a suite of fine-tuned LLMs and BERT models. For BO, we benchmarked the
foundational BoTorch Ax implementation against the state-of-the-art q-Expected
Hypervolume Improvement (qEHVI, BoTorchM). The generative approach involved
fine-tuning models via Parameter-Efficient Fine-Tuning (PEFT), framing the
challenge as a regression problem with a custom output head. Our results show
that BoTorch qEHVI achieved perfect convergence (GD=0.0), setting the
performance ceiling. Crucially, the best-performing LLM (WizardMath-7B)
achieved a Generational Distance (GD) of 1.21, significantly outperforming the
traditional BoTorch Ax baseline (GD=15.03). We conclude that specialized BO
frameworks remain the performance leader for guaranteed convergence, but
fine-tuned LLMs are validated as a promising, computationally fast alternative,
contributing essential comparative metrics to the field of AI-driven
optimization. The findings have direct industrial applications in optimizing
formulation design for resins, polymers, and paints, where multi-objective
trade-offs between mechanical, rheological, and chemical properties are
critical to innovation and production efficiency.

</details>


### [207] [Wavelet-Based Feature Extraction and Unsupervised Clustering for Parity Detection: A Feature Engineering Perspective](https://arxiv.org/abs/2511.00071)
*Ertugrul Mutlu*

Main category: cs.LG

TL;DR: 论文提出了一种基于小波特征提取和无监督聚类的奇偶检测方法，替代传统的模运算，取得了69.67%的分类准确率。


<details>
  <summary>Details</summary>
Motivation: 探索信号处理技术在离散符号领域的应用，尝试通过特征工程和聚类解决非传统机器学习问题。

Method: 将整数转换为小波域表示，提取多尺度统计特征，并使用k-means算法进行聚类。

Result: 在无监督情况下，分类准确率达到69.67%，揭示了奇偶数之间的结构差异。

Conclusion: 信号处理技术可以揭示离散符号领域的潜在结构，为符号推理和特征学习的结合提供了新思路。

Abstract: This paper explores a deliberately over-engineered approach to the classical
problem of parity detection -- determining whether a number is odd or even --
by combining wavelet-based feature extraction with unsupervised clustering.
Instead of relying on modular arithmetic, integers are transformed into
wavelet-domain representations, from which multi-scale statistical features are
extracted and clustered using the k-means algorithm. The resulting feature
space reveals meaningful structural differences between odd and even numbers,
achieving a classification accuracy of approximately 69.67% without any label
supervision. These results suggest that classical signal-processing techniques,
originally designed for continuous data, can uncover latent structure even in
purely discrete symbolic domains. Beyond parity detection, the study provides
an illustrative perspective on how feature engineering and clustering may be
repurposed for unconventional machine learning problems, potentially bridging
symbolic reasoning and feature-based learning.

</details>


### [208] [Bridging Vision, Language, and Mathematics: Pictographic Character Reconstruction with Bézier Curves](https://arxiv.org/abs/2511.00076)
*Zihao Wan,Pau Tong Lin Xu,Fuwen Luo,Ziyue Wang,Peng Li,Yang Liu*

Main category: cs.LG

TL;DR: VLMs在视觉几何结构理解上的表现优于零样本基线，并能从现代汉字推广到甲骨文。


<details>
  <summary>Details</summary>
Motivation: 探索VLMs对视觉几何结构的理解能力，以象形文字为测试案例。

Method: 将视觉识别任务转化为程序合成任务，训练VLM将栅格图像反编译为Bézier曲线程序。

Result: 模型在零样本情况下能重构甲骨文，表明其掌握了抽象的几何语法。

Conclusion: VLMs能够超越像素级模式识别，实现更结构化的视觉理解。

Abstract: While Vision-language Models (VLMs) have demonstrated strong semantic
capabilities, their ability to interpret the underlying geometric structure of
visual information is less explored. Pictographic characters, which combine
visual form with symbolic structure, provide an ideal test case for this
capability. We formulate this visual recognition challenge in the mathematical
domain, where each character is represented by an executable program of
geometric primitives. This is framed as a program synthesis task, training a
VLM to decompile raster images into programs composed of B\'ezier curves. Our
model, acting as a "visual decompiler", demonstrates performance superior to
strong zero-shot baselines, including GPT-4o. The most significant finding is
that when trained solely on modern Chinese characters, the model is able to
reconstruct ancient Oracle Bone Script in a zero-shot context. This
generalization provides strong evidence that the model acquires an abstract and
transferable geometric grammar, moving beyond pixel-level pattern recognition
to a more structured form of visual understanding.

</details>


### [209] [flowengineR: A Modular and Extensible Framework for Fair and Reproducible Workflow Design in R](https://arxiv.org/abs/2511.00079)
*Maximilian Willer,Peter Ruckdeschel*

Main category: cs.LG

TL;DR: flowengineR是一个R包，提供模块化和可扩展的框架，用于构建可重复的机器学习流程。


<details>
  <summary>Details</summary>
Motivation: 解决算法公平性领域中新方法不断涌现，但现有工具缺乏可扩展性和可重复性的问题。

Method: 引入标准化的引擎架构，涵盖数据处理、训练、评估等任务，通过轻量级接口实现透明和可扩展的工作流。

Result: flowengineR支持公平性方法的集成和比较，同时适用于其他领域如可解释性和鲁棒性。

Conclusion: flowengineR为需要可重复性、透明性和可扩展性的工作流提供了通用基础设施。

Abstract: flowengineR is an R package designed to provide a modular and extensible
framework for building reproducible algorithmic workflows for general-purpose
machine learning pipelines. It is motivated by the rapidly evolving field of
algorithmic fairness where new metrics, mitigation strategies, and machine
learning methods continuously emerge. A central challenge in fairness, but also
far beyond, is that existing toolkits either focus narrowly on single
interventions or treat reproducibility and extensibility as secondary
considerations rather than core design principles. flowengineR addresses this
by introducing a unified architecture of standardized engines for data
splitting, execution, preprocessing, training, inprocessing, postprocessing,
evaluation, and reporting. Each engine encapsulates one methodological task yet
communicates via a lightweight interface, ensuring workflows remain
transparent, auditable, and easily extensible. Although implemented in R,
flowengineR builds on ideas from workflow languages (CWL, YAWL), graph-oriented
visual programming languages (KNIME), and R frameworks (BatchJobs, batchtools).
Its emphasis, however, is less on orchestrating engines for resilient parallel
execution but rather on the straightforward setup and management of distinct
engines as data structures. This orthogonalization enables distributed
responsibilities, independent development, and streamlined integration. In
fairness context, by structuring fairness methods as interchangeable engines,
flowengineR lets researchers integrate, compare, and evaluate interventions
across the modeling pipeline. At the same time, the architecture generalizes to
explainability, robustness, and compliance metrics without core modifications.
While motivated by fairness, it ultimately provides a general infrastructure
for any workflow context where reproducibility, transparency, and extensibility
are essential.

</details>


### [210] [Fixed-point graph convolutional networks against adversarial attacks](https://arxiv.org/abs/2511.00083)
*Shakib Khan,A. Ben Hamza,Amr Youssef*

Main category: cs.LG

TL;DR: 提出了一种名为Fix-GCN的新型模型，通过固定点迭代图卷积网络有效捕获高阶邻域信息，提升对抗攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 对抗攻击对图神经网络的结构和节点特征构成威胁，现有防御机制通常依赖额外设计元素，缺乏灵活性。

Method: 引入通用频谱调制滤波器，通过固定点迭代推导特征传播规则，选择性衰减高频成分并保留低频结构信息。

Result: 在多个基准图数据集上验证了模型的有效性，展示了其对对抗攻击的鲁棒性。

Conclusion: Fix-GCN提供了一种灵活高效的框架，能够在保留关键图信息的同时减轻对抗攻击的影响。

Abstract: Adversarial attacks present a significant risk to the integrity and
performance of graph neural networks, particularly in tasks where graph
structure and node features are vulnerable to manipulation. In this paper, we
present a novel model, called fixed-point iterative graph convolutional network
(Fix-GCN), which achieves robustness against adversarial perturbations by
effectively capturing higher-order node neighborhood information in the graph
without additional memory or computational complexity. Specifically, we
introduce a versatile spectral modulation filter and derive the feature
propagation rule of our model using fixed-point iteration. Unlike traditional
defense mechanisms that rely on additional design elements to counteract
attacks, the proposed graph filter provides a flexible-pass filtering approach,
allowing it to selectively attenuate high-frequency components while preserving
low-frequency structural information in the graph signal. By iteratively
updating node representations, our model offers a flexible and efficient
framework for preserving essential graph information while mitigating the
impact of adversarial manipulation. We demonstrate the effectiveness of the
proposed model through extensive experiments on various benchmark graph
datasets, showcasing its resilience against adversarial attacks.

</details>


### [211] [Application of predictive machine learning in pen & paper RPG game design](https://arxiv.org/abs/2511.00084)
*Jolanta Śliwa*

Main category: cs.LG

TL;DR: 论文探讨了如何利用AI技术自动化预测RPG游戏中怪物的挑战等级，以替代传统耗时的手工方法。


<details>
  <summary>Details</summary>
Motivation: RPG市场增长迅速，但怪物等级设计仍依赖手工测试和专家评估，效率低下。

Method: 采用序数回归技术，构建专用数据集，并开发人类启发模型作为基准。

Result: 提出了基于领域知识的评估流程，用于比较机器学习算法与传统方法。

Conclusion: AI技术可有效提升怪物等级预测的效率和准确性，为RPG出版商提供竞争优势。

Abstract: In recent years, the pen and paper RPG market has experienced significant
growth. As a result, companies are increasingly exploring the integration of AI
technologies to enhance player experience and gain a competitive edge.
  One of the key challenges faced by publishers is designing new opponents and
estimating their challenge level. Currently, there are no automated methods for
determining a monster's level; the only approaches used are based on manual
testing and expert evaluation. Although these manual methods can provide
reasonably accurate estimates, they are time-consuming and resource-intensive.
  Level prediction can be approached using ordinal regression techniques. This
thesis presents an overview and evaluation of state-of-the-art methods for this
task. It also details the construction of a dedicated dataset for level
estimation. Furthermore, a human-inspired model was developed to serve as a
benchmark, allowing comparison between machine learning algorithms and the
approach typically employed by pen and paper RPG publishers. In addition, a
specialized evaluation procedure, grounded in domain knowledge, was designed to
assess model performance and facilitate meaningful comparisons.

</details>


### [212] [MaGNet: A Mamba Dual-Hypergraph Network for Stock Prediction via Temporal-Causal and Global Relational Learning](https://arxiv.org/abs/2511.00085)
*Peilin Tan,Chuanqi Shi,Dian Tu,Liang Xie*

Main category: cs.LG

TL;DR: MaGNet是一种新颖的Mamba双超图网络，用于股票预测，通过双向Mamba、2D时空注意力模块和双超图框架，显著提升了预测性能和投资回报。


<details>
  <summary>Details</summary>
Motivation: 股票趋势预测因市场波动、复杂时间动态和多方面股票间关系而具有挑战性，现有方法难以有效捕捉时间依赖性和动态股票间交互。

Method: MaGNet结合了MAGE块（双向Mamba和稀疏专家混合层）、2D时空注意力模块和双超图框架（TCH和GPH），用于多尺度关系学习。

Result: 在六个主要股票指数上的实验表明，MaGNet在预测性能和投资回报方面优于现有方法，并具备稳健的风险管理能力。

Conclusion: MaGNet通过创新的时间建模和关系推理方法，显著提升了股票预测的准确性和实用性。

Abstract: Stock trend prediction is crucial for profitable trading strategies and
portfolio management yet remains challenging due to market volatility, complex
temporal dynamics and multifaceted inter-stock relationships. Existing methods
struggle to effectively capture temporal dependencies and dynamic inter-stock
interactions, often neglecting cross-sectional market influences, relying on
static correlations, employing uniform treatments of nodes and edges, and
conflating diverse relationships. This work introduces MaGNet, a novel Mamba
dual-hyperGraph Network for stock prediction, integrating three key
innovations: (1) a MAGE block, which leverages bidirectional Mamba with
adaptive gating mechanisms for contextual temporal modeling and integrates a
sparse Mixture-of-Experts layer to enable dynamic adaptation to diverse market
conditions, alongside multi-head attention for capturing global dependencies;
(2) Feature-wise and Stock-wise 2D Spatiotemporal Attention modules enable
precise fusion of multivariate features and cross-stock dependencies,
effectively enhancing informativeness while preserving intrinsic data
structures, bridging temporal modeling with relational reasoning; and (3) a
dual hypergraph framework consisting of the Temporal-Causal Hypergraph (TCH)
that captures fine-grained causal dependencies with temporal constraints, and
Global Probabilistic Hypergraph (GPH) that models market-wide patterns through
soft hyperedge assignments and Jensen-Shannon Divergence weighting mechanism,
jointly disentangling localized temporal influences from instantaneous global
structures for multi-scale relational learning. Extensive experiments on six
major stock indices demonstrate MaGNet outperforms state-of-the-art methods in
both superior predictive performance and exceptional investment returns with
robust risk management capabilities. Codes available at:
https://github.com/PeilinTime/MaGNet.

</details>


### [213] [Generalizing Test-time Compute-optimal Scaling as an Optimizable Graph](https://arxiv.org/abs/2511.00086)
*Fali Wang,Jihai Chen,Shuhua Yang,Runxue Bao,Tianxiang Zhao,Zhiwei Zhang,Xianfeng Tang,Hui Liu,Qi He,Suhang Wang*

Main category: cs.LG

TL;DR: TTS通过动态调整计算资源优化LLM推理性能，提出多LLM协作图搜索问题，并设计Agent-REINFORCE框架高效求解。


<details>
  <summary>Details</summary>
Motivation: 现有TTS方法假设固定协作架构和单一模型，忽略了任务间最优架构和模型组合的差异，需研究在固定预算下搜索计算最优的模型组合和架构。

Method: 将问题形式化为多LLM协作图优化，提出Agent-REINFORCE框架，通过文本反馈更新概率图，高效搜索最优协作图。

Result: 实验表明Agent-REINFORCE在样本效率和搜索性能上优于基线，能有效平衡准确性和推理延迟。

Conclusion: Agent-REINFORCE为TTS中的多LLM协作图搜索提供了高效解决方案，验证了其优越性。

Abstract: Test-Time Scaling (TTS) improves large language models (LLMs) by allocating
additional computation during inference, typically through parallel,
sequential, or hybrid scaling. However, prior studies often assume fixed
collaboration architectures (e.g., topologies) and single-model usage,
overlooking that optimal architectures and model combinations can vary across
tasks. Therefore, we study the novel problem of searching for compute-optimal
model combinations and architectures in TTS under a fixed budget. We formalize
it as a multi-LLM collaboration graph, where nodes encode roles and LLM model
assignments, and edges capture information flow. This problem is challenging
because (i) the combinatorial search space is prohibitively large, and (ii)
task-specific requirements demand tailored designs. To address these, we
reformulate the problem as probabilistic graph optimization and, through pilot
experiments, derive three empirical insights into TTS collaboration graphs.
Guided by these insights, we propose Agent-REINFORCE, an LLM-agent-augmented
framework that mirrors the REINFORCE pipeline by mapping
sampling-gradient-update to sampling-feedback-update, where feedback serves as
a textual gradient to update the probabilistic graph and efficiently search for
optimal multi-LLM collaboration graphs. Experiments show that Agent-REINFORCE
outperforms both traditional and LLM-based baselines in sample efficiency and
search performance, and effectively identifies optimal graphs under joint
objectives of accuracy and inference latency.

</details>


### [214] [GraphKeeper: Graph Domain-Incremental Learning via Knowledge Disentanglement and Preservation](https://arxiv.org/abs/2511.00097)
*Zihao Guo,Qingyun Sun,Ziwei Zhang,Haonan Yuan,Huiping Zhuang,Xingcheng Fu,Jianxin Li*

Main category: cs.LG

TL;DR: GraphKeeper提出了一种新的图域增量学习方法，通过知识解耦和保存解决跨域学习中的灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 现有图增量学习方法局限于单域任务或类增量场景，而跨域增量学习（Domain-IL）在图形基础模型（GFMs）发展中至关重要，但尚未被探索。

Method: 提出域特定参数高效微调、域内外解耦目标以防止嵌入偏移，并引入无偏差知识保存以稳定决策边界；对无观察域图进行域感知分布判别。

Result: 实验表明GraphKeeper在6.5%~16.6%的指标上优于次优方法，且遗忘可忽略，并能与多种GFMs无缝集成。

Conclusion: GraphKeeper为跨域图增量学习提供了高效解决方案，展示了广泛的应用潜力。

Abstract: Graph incremental learning (GIL), which continuously updates graph models by
sequential knowledge acquisition, has garnered significant interest recently.
However, existing GIL approaches focus on task-incremental and
class-incremental scenarios within a single domain. Graph domain-incremental
learning (Domain-IL), aiming at updating models across multiple graph domains,
has become critical with the development of graph foundation models (GFMs), but
remains unexplored in the literature. In this paper, we propose Graph
Domain-Incremental Learning via Knowledge Dientanglement and Preservation
(GraphKeeper), to address catastrophic forgetting in Domain-IL scenario from
the perspectives of embedding shifts and decision boundary deviations.
Specifically, to prevent embedding shifts and confusion across incremental
graph domains, we first propose the domain-specific parameter-efficient
fine-tuning together with intra- and inter-domain disentanglement objectives.
Consequently, to maintain a stable decision boundary, we introduce
deviation-free knowledge preservation to continuously fit incremental domains.
Additionally, for graphs with unobservable domains, we perform domain-aware
distribution discrimination to obtain precise embeddings. Extensive experiments
demonstrate the proposed GraphKeeper achieves state-of-the-art results with
6.5%~16.6% improvement over the runner-up with negligible forgetting. Moreover,
we show GraphKeeper can be seamlessly integrated with various representative
GFMs, highlighting its broad applicative potential.

</details>


### [215] [A generative adversarial network optimization method for damage detection and digital twinning by deep AI fault learning: Z24 Bridge structural health monitoring benchmark validation](https://arxiv.org/abs/2511.00099)
*Marios Impraimakis,Evangelia Nektaria Palkanoglou*

Main category: cs.LG

TL;DR: 提出了一种基于条件标记生成对抗网络的无监督框架，用于损伤检测和数字孪生，优于现有方法，无需系统健康状态先验信息。


<details>
  <summary>Details</summary>
Motivation: 现有AI数字孪生方法在测量数据少、物理知识缺失或损伤状态未知时预测效果差，亟需改进。

Method: 使用Z24桥梁基准数据验证，通过输入不同损伤级别测量数据，强制模型收敛到不同损伤状态，比较收敛分数识别损伤状态。

Result: 方法能准确区分健康与损伤测量，支持振动监测和基础设施韧性评估。

Conclusion: 该框架为系统级监测和数字孪生提供了高效工具，适用于实际应用。

Abstract: The optimization-based damage detection and damage state digital twinning
capabilities are examined here of a novel conditional-labeled generative
adversarial network methodology. The framework outperforms current approaches
for fault anomaly detection as no prior information is required for the health
state of the system: a topic of high significance for real-world applications.
Specifically, current artificial intelligence-based digital twinning approaches
suffer from the uncertainty related to obtaining poor predictions when a low
number of measurements is available, physics knowledge is missing, or when the
damage state is unknown. To this end, an unsupervised framework is examined and
validated rigorously on the benchmark structural health monitoring measurements
of Z24 Bridge: a post-tensioned concrete highway bridge in Switzerland. In
implementing the approach, firstly, different same damage-level measurements
are used as inputs, while the model is forced to converge conditionally to two
different damage states. Secondly, the process is repeated for a different
group of measurements. Finally, the convergence scores are compared to identify
which one belongs to a different damage state. The process for both
healthy-to-healthy and damage-to-healthy input data creates, simultaneously,
measurements for digital twinning purposes at different damage states, capable
of pattern recognition and machine learning data generation. Further to this
process, a support vector machine classifier and a principal component analysis
procedure is developed to assess the generated and real measurements of each
damage category, serving as a secondary new dynamics learning indicator in
damage scenarios. Importantly, the approach is shown to capture accurately
damage over healthy measurements, providing a powerful tool for vibration-based
system-level monitoring and scalable infrastructure resilience.

</details>


### [216] [Deep recurrent-convolutional neural network learning and physics Kalman filtering comparison in dynamic load identification](https://arxiv.org/abs/2511.00100)
*Marios Impraimakis*

Main category: cs.LG

TL;DR: 比较了门控循环单元、长短期记忆网络和卷积神经网络在动态结构载荷识别中的表现，并与基于物理的残差卡尔曼滤波（RKF）进行了对比。


<details>
  <summary>Details</summary>
Motivation: 解决在土木工程应用中因测试数据少或结构模型不可识别导致的动态载荷识别不确定性。

Method: 通过模拟结构振动、地震激励和基准问题测试不同方法的性能。

Result: 不同方法在不同载荷场景下表现各异，RKF在物理参数可识别情况下优于神经网络。

Conclusion: 方法选择需根据具体场景，RKF在特定条件下更优。

Abstract: The dynamic structural load identification capabilities of the gated
recurrent unit, long short-term memory, and convolutional neural networks are
examined herein. The examination is on realistic small dataset training
conditions and on a comparative view to the physics-based residual Kalman
filter (RKF). The dynamic load identification suffers from the uncertainty
related to obtaining poor predictions when in civil engineering applications
only a low number of tests are performed or are available, or when the
structural model is unidentifiable. In considering the methods, first, a
simulated structure is investigated under a shaker excitation at the top floor.
Second, a building in California is investigated under seismic base excitation,
which results in loading for all degrees of freedom. Finally, the International
Association for Structural Control-American Society of Civil Engineers
(IASC-ASCE) structural health monitoring benchmark problem is examined for
impact and instant loading conditions. Importantly, the methods are shown to
outperform each other on different loading scenarios, while the RKF is shown to
outperform the networks in physically parametrized identifiable cases.

</details>


### [217] [Loquetier: A Virtualized Multi-LoRA Framework for Unified LLM Fine-tuning and Serving](https://arxiv.org/abs/2511.00101)
*Yuchen Zhang,Hanyue Du,Chun Cao,Jingwei Xu*

Main category: cs.LG

TL;DR: Loquetier是一个虚拟化的多LoRA框架，统一了LoRA微调和推理，显著提升了性能和灵活性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在统一LoRA微调和推理方面存在不足，Loquetier旨在填补这一空白。

Method: 引入虚拟化模块隔离PEFT修改，优化计算流程合并微调和推理路径。

Result: 在性能和灵活性上优于现有基线，推理任务吞吐量提升3倍，统一任务SLO达成率提升46.4倍。

Conclusion: Loquetier有效解决了LoRA微调和推理的统一问题，提供了高效且灵活的解决方案。

Abstract: Low-Rank Adaptation (LoRA) has become a widely adopted parameter-efficient
fine-tuning (PEFT) technique for adapting large language models (LLMs) to
downstream tasks. While prior work has explored strategies for integrating LLM
training and serving, there still remains a gap in unifying fine-tuning and
inference for LoRA-based models. We present Loquetier, a virtualized multi-LoRA
framework that seamlessly integrates LoRA fine-tuning and serving within a
single runtime. Loquetier introduces two key components: (1) a Virtualized
Module that isolates PEFT-based modifications and supports multiple adapters on
a shared base model, and (2) an optimized computation flow with a kernel design
that merges fine-tuning and inference paths in forward propagation, enabling
efficient batching and minimizing kernel invocation overhead. Extensive
experiments across three task settings show that Loquetier consistently
outperforms existing baselines in both performance and flexibility, achieving
up to $3.0\times$ the throughput of the state-of-the-art co-serving system on
inference-only tasks and $46.4\times$ higher SLO attainment than PEFT on
unified fine-tuning and inference tasks. The implementation of Loquetier is
publicly available at https://github.com/NJUDeepEngine/Loquetier.

</details>


### [218] [Automated Discovery of Conservation Laws via Hybrid Neural ODE-Transformers](https://arxiv.org/abs/2511.00102)
*Vivan Doshi*

Main category: cs.LG

TL;DR: 提出了一种混合框架，用于从噪声轨迹数据中自动发现守恒量，结合了神经ODE、Transformer和符号-数值验证器。


<details>
  <summary>Details</summary>
Motivation: 守恒定律的发现是科学进步的关键，但从观测数据中识别这些不变量仍具挑战性。

Method: 框架包含神经ODE学习系统动态、Transformer生成候选不变量、符号-数值验证器验证其有效性。

Result: 在经典物理系统上测试，显著优于直接处理轨迹数据的基线方法。

Conclusion: 展示了从非完美数据中发现数学原理的解耦学习-搜索方法的鲁棒性。

Abstract: The discovery of conservation laws is a cornerstone of scientific progress.
However, identifying these invariants from observational data remains a
significant challenge. We propose a hybrid framework to automate the discovery
of conserved quantities from noisy trajectory data. Our approach integrates
three components: (1) a Neural Ordinary Differential Equation (Neural ODE) that
learns a continuous model of the system's dynamics, (2) a Transformer that
generates symbolic candidate invariants conditioned on the learned vector
field, and (3) a symbolic-numeric verifier that provides a strong numerical
certificate for the validity of these candidates. We test our framework on
canonical physical systems and show that it significantly outperforms baselines
that operate directly on trajectory data. This work demonstrates the robustness
of a decoupled learn-then-search approach for discovering mathematical
principles from imperfect data.

</details>


### [219] [Pelican-VL 1.0: A Foundation Brain Model for Embodied Intelligence](https://arxiv.org/abs/2511.00108)
*Yi Zhang,Che Liu,Xiancong Ren,Hanchu Ni,Shuai Zhang,Zeyuan Ding,Jiayu Hu,Hanzhe Shan,Zhenwei Niu,Zhaoyang Liu,Yue Zhao,Junbo Qi,Qinfan Zhang,Dengjie Li,Yidong Wang,Jiachen Luo,Yong Dai,Jian Tang,Xiaozhu Ju*

Main category: cs.LG

TL;DR: Pelican-VL 1.0是一个开源的多模态大脑模型家族，参数规模从70亿到720亿，通过深度整合数据力量和智能自适应学习机制，性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 目标是将强大智能嵌入各种实体中，成为当前最大规模的开源多模态大脑模型。

Method: 采用DPPO（Deliberate Practice Policy Optimization）框架，通过metaloop（RL-Refine-Diagnose-SFT循环）训练模型。

Result: 性能比基础模型提升20.3%，优于100B级别的开源模型10.6%，与领先的专有系统相当。

Conclusion: Pelican-VL 1.0通过创新的训练框架和大规模计算资源，实现了高性能的多模态智能。

Abstract: This report presents Pelican-VL 1.0, a new family of open-source embodied
brain models with parameter scales ranging from 7 billion to 72 billion. Our
explicit mission is clearly stated as: To embed powerful intelligence into
various embodiments. Pelican-VL 1.0 is currently the largest-scale open-source
embodied multimodal brain model. Its core advantage lies in the in-depth
integration of data power and intelligent adaptive learning mechanisms.
Specifically, metaloop distilled a high-quality dataset from a raw dataset
containing 4+ billion tokens. Pelican-VL 1.0 is trained on a large-scale
cluster of 1000+ A800 GPUs, consuming over 50k+ A800 GPU-hours per checkpoint.
This translates to a 20.3% performance uplift from its base model and
outperforms 100B-level open-source counterparts by 10.6%, placing it on par
with leading proprietary systems on well-known embodied benchmarks. We
establish a novel framework, DPPO (Deliberate Practice Policy Optimization),
inspired by human metacognition to train Pelican-VL 1.0. We operationalize this
as a metaloop that teaches the AI to practice deliberately, which is a
RL-Refine-Diagnose-SFT loop.

</details>


### [220] [MeixnerNet: Adaptive and Robust Spectral Graph Neural Networks with Discrete Orthogonal Polynomials](https://arxiv.org/abs/2511.00113)
*Huseyin Goksu*

Main category: cs.LG

TL;DR: MeixnerNet是一种新型的谱图神经网络，使用离散正交多项式（Meixner多项式）替代传统的连续多项式，解决了理论与实际应用的不匹配问题，并表现出更强的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统谱GNN使用连续正交多项式（如Chebyshev）处理离散图结构，导致理论与实际不匹配，可能影响性能和超参数敏感性。

Method: 提出MeixnerNet，利用Meixner多项式，并通过可学习的形状参数（beta和c）适应图的谱特性，同时引入数值稳定技术（Laplacian缩放和LayerNorm）。

Result: 在K=2时，MeixnerNet在2/3基准测试中优于ChebyNet，且对多项式阶数K的变化表现出更强的鲁棒性。

Conclusion: MeixnerNet通过离散多项式和改进的稳定性，显著提升了谱GNN的性能和鲁棒性。

Abstract: Spectral Graph Neural Networks (GNNs) have achieved state-of-the-art results
by defining graph convolutions in the spectral domain. A common approach,
popularized by ChebyNet, is to use polynomial filters based on continuous
orthogonal polynomials (e.g., Chebyshev). This creates a theoretical
disconnect, as these continuous-domain filters are applied to inherently
discrete graph structures. We hypothesize this mismatch can lead to suboptimal
performance and fragility to hyperparameter settings.
  In this paper, we introduce MeixnerNet, a novel spectral GNN architecture
that employs discrete orthogonal polynomials -- specifically, the Meixner
polynomials $M_k(x; \beta, c)$. Our model makes the two key shape parameters of
the polynomial, beta and c, learnable, allowing the filter to adapt its
polynomial basis to the specific spectral properties of a given graph. We
overcome the significant numerical instability of these polynomials by
introducing a novel stabilization technique that combines Laplacian scaling
with per-basis LayerNorm.
  We demonstrate experimentally that MeixnerNet achieves
competitive-to-superior performance against the strong ChebyNet baseline at the
optimal K = 2 setting (winning on 2 out of 3 benchmarks). More critically, we
show that MeixnerNet is exceptionally robust to variations in the polynomial
degree K, a hyperparameter to which ChebyNet proves to be highly fragile,
collapsing in performance where MeixnerNet remains stable.

</details>


### [221] [LC-Opt: Benchmarking Reinforcement Learning and Agentic AI for End-to-End Liquid Cooling Optimization in Data Centers](https://arxiv.org/abs/2511.00116)
*Avisek Naug,Antonio Guillen,Vineet Kumar,Scott Greenwood,Wesley Brewer,Sahand Ghorbanpour,Ashwin Ramesh Babu,Vineet Gundecha,Ricardo Luna Gutierrez,Soumyendu Sarkar*

Main category: cs.LG

TL;DR: LC-Opt是一个基于强化学习的可持续液体冷却基准环境，用于优化高性能计算系统的能源效率。


<details>
  <summary>Details</summary>
Motivation: 随着AI工作负载的增加，液体冷却在高密度数据中心的热管理中至关重要，但需要机器学习控制器以提高能源效率和可靠性。

Method: 基于高保真数字孪生模型，LC-Opt提供端到端的Modelica模型，支持强化学习代理优化关键热控制参数。

Result: LC-Opt支持多目标实时优化，并探索了集中式和分散式多代理强化学习方法，以及可解释的控制策略。

Conclusion: LC-Opt为ML社区、运营商和供应商提供了详细的液体冷却模型，促进可持续数据中心冷却解决方案的开发。

Abstract: Liquid cooling is critical for thermal management in high-density data
centers with the rising AI workloads. However, machine learning-based
controllers are essential to unlock greater energy efficiency and reliability,
promoting sustainability. We present LC-Opt, a Sustainable Liquid Cooling (LC)
benchmark environment, for reinforcement learning (RL) control strategies in
energy-efficient liquid cooling of high-performance computing (HPC) systems.
Built on the baseline of a high-fidelity digital twin of Oak Ridge National
Lab's Frontier Supercomputer cooling system, LC-Opt provides detailed
Modelica-based end-to-end models spanning site-level cooling towers to data
center cabinets and server blade groups. RL agents optimize critical thermal
controls like liquid supply temperature, flow rate, and granular valve
actuation at the IT cabinet level, as well as cooling tower (CT) setpoints
through a Gymnasium interface, with dynamic changes in workloads. This
environment creates a multi-objective real-time optimization challenge
balancing local thermal regulation and global energy efficiency, and also
supports additional components like a heat recovery unit (HRU). We benchmark
centralized and decentralized multi-agent RL approaches, demonstrate policy
distillation into decision and regression trees for interpretable control, and
explore LLM-based methods that explain control actions in natural language
through an agentic mesh architecture designed to foster user trust and simplify
system management. LC-Opt democratizes access to detailed, customizable liquid
cooling models, enabling the ML community, operators, and vendors to develop
sustainable data center liquid cooling control solutions.

</details>


### [222] [DCcluster-Opt: Benchmarking Dynamic Multi-Objective Optimization for Geo-Distributed Data Center Workloads](https://arxiv.org/abs/2511.00117)
*Antonio Guillen-Perez,Avisek Naug,Vineet Gundecha,Sahand Ghorbanpour,Ricardo Luna Gutierrez,Ashwin Ramesh Babu,Munther Salim,Shubhanker Banerjee,Eoin H. Oude Essink,Damien Fay,Soumyendu Sarkar*

Main category: cs.LG

TL;DR: DCcluster-Opt是一个开源的高保真模拟基准，用于可持续的、地理时间任务调度，旨在解决大规模AI的能源需求和碳足迹问题。


<details>
  <summary>Details</summary>
Motivation: 大规模AI的能源需求和碳足迹日益增加，但缺乏能真实反映环境因素、数据中心物理特性和网络动态的基准，限制了进展。

Method: 结合真实世界数据集和物理模型，开发了DCcluster-Opt，支持动态任务调度和多目标优化。

Result: 提供了一个模块化奖励系统，支持研究碳排放、能源成本、服务协议和水资源使用之间的权衡。

Conclusion: DCcluster-Opt为地理分布式数据中心的可持续计算解决方案提供了现实、可配置和可访问的测试平台。

Abstract: The increasing energy demands and carbon footprint of large-scale AI require
intelligent workload management in globally distributed data centers. Yet
progress is limited by the absence of benchmarks that realistically capture the
interplay of time-varying environmental factors (grid carbon intensity,
electricity prices, weather), detailed data center physics (CPUs, GPUs, memory,
HVAC energy), and geo-distributed network dynamics (latency and transmission
costs). To bridge this gap, we present DCcluster-Opt: an open-source,
high-fidelity simulation benchmark for sustainable, geo-temporal task
scheduling. DCcluster-Opt combines curated real-world datasets, including AI
workload traces, grid carbon intensity, electricity markets, weather across 20
global regions, cloud transmission costs, and empirical network delay
parameters with physics-informed models of data center operations, enabling
rigorous and reproducible research in sustainable computing. It presents a
challenging scheduling problem where a top-level coordinating agent must
dynamically reassign or defer tasks that arrive with resource and service-level
agreement requirements across a configurable cluster of data centers to
optimize multiple objectives. The environment also models advanced components
such as heat recovery. A modular reward system enables an explicit study of
trade-offs among carbon emissions, energy costs, service level agreements, and
water use. It provides a Gymnasium API with baseline controllers, including
reinforcement learning and rule-based strategies, to support reproducible ML
research and a fair comparison of diverse algorithms. By offering a realistic,
configurable, and accessible testbed, DCcluster-Opt accelerates the development
and validation of next-generation sustainable computing solutions for
geo-distributed data centers.

</details>


### [223] [Analysis of Line Break prediction models for detecting defensive breakthrough in football](https://arxiv.org/abs/2511.00121)
*Shoma Yagi,Jun Ichikawa,Genki Ichinose*

Main category: cs.LG

TL;DR: 本研究开发了一个机器学习模型，利用2023年J1联赛的事件和追踪数据预测足球中的Line Breaks（突破防线），模型表现优异，揭示了进攻球员速度和防守空隙等关键因素。


<details>
  <summary>Details</summary>
Motivation: 以往研究主要关注射门或进球机会，而忽略了球队如何突破防线这一关键战术指标。

Method: 使用XGBoost分类器，结合189个特征（如球员位置、速度和空间配置）预测Line Breaks。

Result: 模型AUC为0.982，Brier分数为0.015；SHAP分析显示进攻球员速度和防守空隙是关键因素。

Conclusion: Line Breaks与得分机会密切相关，为理解足球战术动态提供了量化框架。

Abstract: In football, attacking teams attempt to break through the opponent's
defensive line to create scoring opportunities. This action, known as a Line
Break, is a critical indicator of offensive effectiveness and tactical
performance, yet previous studies have mainly focused on shots or goal
opportunities rather than on how teams break the defensive line. In this study,
we develop a machine learning model to predict Line Breaks using event and
tracking data from the 2023 J1 League season. The model incorporates 189
features, including player positions, velocities, and spatial configurations,
and employs an XGBoost classifier to estimate the probability of Line Breaks.
The proposed model achieved high predictive accuracy, with an AUC of 0.982 and
a Brier score of 0.015. Furthermore, SHAP analysis revealed that factors such
as offensive player speed, gaps in the defensive line, and offensive players'
spatial distributions significantly contribute to the occurrence of Line
Breaks. Finally, we found a moderate positive correlation between the predicted
probability of being Line-Broken and the number of shots and crosses conceded
at the team level. These results suggest that Line Breaks are closely linked to
the creation of scoring opportunities and provide a quantitative framework for
understanding tactical dynamics in football.

</details>


### [224] [Cross-fluctuation phase transitions reveal sampling dynamics in diffusion models](https://arxiv.org/abs/2511.00124)
*Sai Niranjan Ramachandran,Manish Krishan Lal,Suvrit Sra*

Main category: cs.LG

TL;DR: 论文分析了基于分数的扩散模型中采样动态的演变，通过统计物理中的交叉波动统计量揭示了样本从初始分布到目标分布的离散过渡过程。


<details>
  <summary>Details</summary>
Motivation: 研究旨在理解扩散模型中采样动态的演变机制，并利用这些机制提升生成效率和任务性能。

Method: 使用交叉波动统计量检测样本分布的离散过渡，推导了方差保持SDE的交叉波动闭式解。

Result: 发现离散过渡可提升采样效率、加速条件生成，并改善零样本任务（如图像分类和风格迁移）。

Conclusion: 该框架将离散马尔可夫链理论与现代生成模型结合，为理解采样动态提供了新视角。

Abstract: We analyse how the sampling dynamics of distributions evolve in score-based
diffusion models using cross-fluctuations, a centered-moment statistic from
statistical physics. Specifically, we show that starting from an unbiased
isotropic normal distribution, samples undergo sharp, discrete transitions,
eventually forming distinct events of a desired distribution while
progressively revealing finer structure. As this process is reversible, these
transitions also occur in reverse, where intermediate states progressively
merge, tracing a path back to the initial distribution. We demonstrate that
these transitions can be detected as discontinuities in $n^{\text{th}}$-order
cross-fluctuations. For variance-preserving SDEs, we derive a closed-form for
these cross-fluctuations that is efficiently computable for the reverse
trajectory. We find that detecting these transitions directly boosts sampling
efficiency, accelerates class-conditional and rare-class generation, and
improves two zero-shot tasks--image classification and style transfer--without
expensive grid search or retraining. We also show that this viewpoint unifies
classical coupling and mixing from finite Markov chains with continuous
dynamics while extending to stochastic SDEs and non Markovian samplers. Our
framework therefore bridges discrete Markov chain theory, phase analysis, and
modern generative modeling.

</details>


### [225] [Dynamic Model Selection for Trajectory Prediction via Pairwise Ranking and Meta-Features](https://arxiv.org/abs/2511.00126)
*Lu Bowen*

Main category: cs.LG

TL;DR: 提出动态多专家门控框架，自适应选择最佳轨迹预测器，显著提升复杂场景下的预测可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有深度轨迹预测器在复杂长尾驾驶场景中不可靠，需要超越静态单一模型范式。

Method: 利用内部模型信号（如稳定性和不确定性）动态选择LSTM、Transformer或GameFormer。

Result: 在nuPlan-mini数据集上，FDE降低9.5%，左转场景FDE降低约10%。

Conclusion: 自适应混合系统提升自动驾驶轨迹可靠性，为安全关键场景提供实用解决方案。

Abstract: Recent deep trajectory predictors (e.g., Jiang et al., 2023; Zhou et al.,
2022) have achieved strong average accuracy but remain unreliable in complex
long-tail driving scenarios. These limitations reveal the weakness of the
prevailing "one-model-fits-all" paradigm, particularly in safety-critical urban
contexts where simpler physics-based models can occasionally outperform
advanced networks (Kalman, 1960). To bridge this gap, we propose a dynamic
multi-expert gating framework that adaptively selects the most reliable
trajectory predictor among a physics-informed LSTM, a Transformer, and a
fine-tuned GameFormer on a per-sample basis.
  Our method leverages internal model signals (meta-features) such as stability
and uncertainty (Gal and Ghahramani, 2016), which we demonstrate to be
substantially more informative than geometric scene descriptors. To the best of
our knowledge, this is the first work to formulate trajectory expert selection
as a pairwise-ranking problem over internal model signals (Burges et al.,
2005), directly optimizing decision quality without requiring post-hoc
calibration.
  Evaluated on the nuPlan-mini dataset (Caesar et al., 2021) with 1,287
samples, our LLM-enhanced tri-expert gate achieves a Final Displacement Error
(FDE) of 2.567 m, representing a 9.5 percent reduction over GameFormer (2.835
m), and realizes 57.8 percent of the oracle performance bound. In open-loop
simulations, after trajectory horizon alignment, the same configuration reduces
FDE on left-turn scenarios by approximately 10 percent, demonstrating
consistent improvements across both offline validation and open-loop
evaluation. These results indicate that adaptive hybrid systems enhance
trajectory reliability in safety-critical autonomous driving, providing a
practical pathway beyond static single-model paradigms.

</details>


### [226] [Casing Collar Identification using AlexNet-based Neural Networks for Depth Measurement in Oil and Gas Wells](https://arxiv.org/abs/2511.00129)
*Siyu Xiao,Xindi Zhao,Tianhao Mao,Yiwei Wang,Yuqiao Chen,Hongyun Zhang,Jian Wang,Junjie Wang,Shuang Liu,Tupei Chen,Yang Liu*

Main category: cs.LG

TL;DR: 本文提出了一种用于套管接箍定位器（CCL）信号采集的系统，并开发了数据增强的预处理方法，显著提高了神经网络模型的识别性能。


<details>
  <summary>Details</summary>
Motivation: 准确的井下深度测量对油气井作业至关重要，但现有的CCL信号识别方法在数据预处理和数据集构建方面存在不足，且真实数据有限。

Method: 提出集成到井下工具中的CCL信号采集系统，开发标准化、标签分布平滑（LDS）、随机裁剪等预处理方法，并通过AlexNet模型评估其效果。

Result: 实验表明，提出的数据增强方法显著提升了模型性能，F1分数从0.937和0.952提升至1.0和1.0。

Conclusion: 该方法填补了CCL数据有限环境下训练接箍识别模型的数据增强方法空白，具有实际应用价值。

Abstract: Accurate downhole depth measurement is essential for oil and gas well
operations, directly influencing reservoir contact, production efficiency, and
operational safety. Collar correlation using a casing collar locator (CCL) is
fundamental for precise depth calibration. While neural network-based CCL
signal recognition has achieved significant progress in collar identification,
preprocessing methods for such applications remain underdeveloped. Moreover,
the limited availability of real well data poses substantial challenges for
training neural network models that require extensive datasets. This paper
presents a system integrated into downhole tools for CCL signal acquisition to
facilitate dataset construction. We propose comprehensive preprocessing methods
for data augmentation and evaluate their effectiveness using our AlexNet-based
neural network models. Through systematic experimentation across various
configuration combinations, we analyze the contribution of each augmentation
method. Results demonstrate that standardization, label distribution smoothing
(LDS), and random cropping are fundamental requirements for model training,
while label smoothing regularization (LSR), time scaling, and multiple sampling
significantly enhance model generalization capability. The F1 scores of our two
benchmark models trained with the proposed augmentation methods maximumly
improve from 0.937 and 0.952 to 1.0 and 1.0, respectively. Performance
validation on real CCL waveforms confirms the effectiveness and practical
applicability of our approach. This work addresses the gaps in data
augmentation methodologies for training casing collar recognition models in CCL
data-limited environments.

</details>


### [227] [A Comparative Analysis of LLM Adaptation: SFT, LoRA, and ICL in Data-Scarce Scenarios](https://arxiv.org/abs/2511.00130)
*Bernd Bohnet,Rumen Dangovski,Kevin Swersky,Sherry Moore,Arslan Chaudhry,Kathleen Kenealy,Noah Fiedel*

Main category: cs.LG

TL;DR: 比较了监督微调（SFT）、LoRA和上下文学习（ICL）在数据稀缺场景下的表现，发现LoRA在平衡新技能学习和通用知识保留方面最有效。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在特定应用中如何高效适应新知识或技能，同时避免灾难性遗忘的问题。

Method: 对比分析了SFT、LoRA和ICL三种方法在数据稀缺场景下的表现。

Result: LoRA在技能学习和知识保留之间提供了最佳平衡；SFT易导致灾难性遗忘；ICL适用于知识整合但难以处理复杂技能。

Conclusion: 为LLM适应策略选择提供了实用框架，强调了技能获取与知识整合的区别及任务性能与通用能力保留的权衡。

Abstract: The remarkable capabilities of Large Language Models (LLMs) often need to be
tailored for specific applications, requiring the integration of new knowledge
or the acquisition of new skills. While full fine-tuning is a powerful
adaptation method, it is computationally expensive and can lead to a
degradation of general reasoning abilities, a phenomenon known as catastrophic
forgetting. A range of alternative techniques exists, each with its own
trade-offs. In-Context Learning (ICL) is fast but limited by context length,
while Parameter-Efficient Fine-Tuning (PEFT) methods like Low-Rank Adaptation
(LoRA) offer a middle ground by minimizing parameter changes. However, the
challenge of catastrophic forgetting persists, raising questions about the best
adaptation strategy for a given task. This paper presents a comparative
analysis of Supervised Finetuning (SFT), LoRA, and ICL in data-scarce
scenarios. We find that LoRA provides the most effective balance, successfully
instilling new skills with minimal impact on the base model's general
knowledge. In contrast, while SFT excels at skill acquisition, it is highly
susceptible to catastrophic forgetting. ICL is effective for incorporating
factual knowledge but struggles with complex skills. Our findings offer a
practical framework for selecting an LLM adaptation strategy. We highlight the
critical distinction between skill acquisition and knowledge integration,
clarify the trade-offs between task-specific performance and the preservation
of general capabilities.

</details>


### [228] [Feature Importance Guided Random Forest Learning with Simulated Annealing Based Hyperparameter Tuning](https://arxiv.org/abs/2511.00133)
*Kowshik Balasubramanian,Andre Williams,Ismail Butun*

Main category: cs.LG

TL;DR: 提出了一种结合概率特征采样和模拟退火超参数调优的新型随机森林框架，显著提升了预测准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决传统随机森林在多领域分类任务中的局限性，如信用风险评估、物联网异常检测等。

Method: 通过重要性感知采样和动态超参数调优，优化特征选择和模型性能。

Result: 实验结果显示准确性持续提升，并提供了特征相关性的深入见解。

Conclusion: 结合重要性感知采样和元启发式优化是提升随机森林性能的有效方法。

Abstract: This paper introduces a novel framework for enhancing Random Forest
classifiers by integrating probabilistic feature sampling and hyperparameter
tuning via Simulated Annealing. The proposed framework exhibits substantial
advancements in predictive accuracy and generalization, adeptly tackling the
multifaceted challenges of robust classification across diverse domains,
including credit risk evaluation, anomaly detection in IoT ecosystems,
early-stage medical diagnostics, and high-dimensional biological data analysis.
To overcome the limitations of conventional Random Forests, we present an
approach that places stronger emphasis on capturing the most relevant signals
from data while enabling adaptive hyperparameter configuration. The model is
guided towards features that contribute more meaningfully to classification and
optimizing this with dynamic parameter tuning. The results demonstrate
consistent accuracy improvements and meaningful insights into feature
relevance, showcasing the efficacy of combining importance aware sampling and
metaheuristic optimization.

</details>


### [229] [Physiologically Active Vegetation Reverses Its Cooling Effect in Humid Urban Climates](https://arxiv.org/abs/2511.00134)
*Angana Borah,Adrija Datta,Ashish S. Kumar,Raviraj Dave,Udit Bhatia*

Main category: cs.LG

TL;DR: 研究发现植被在降温与增加湿度之间存在权衡，需根据气候条件调整绿化策略。


<details>
  <summary>Details</summary>
Motivation: 探讨植被如何影响城市热指数（HI），以指导更有效的城市绿化政策。

Method: 使用机器学习框架（SHAP和ALE）分析138个印度城市的植被结构与功能对HI的影响。

Result: 植被在特定条件下（如EVI≥0.5）会逆转降温效果，增加湿度并加剧热感。

Conclusion: 需制定气候特异性绿化策略，以实现公平且抗热的城市环境。

Abstract: Efforts to green cities for cooling are succeeding unevenly because the same
vegetation that cools surfaces can also intensify how hot the air feels.
Previous studies have identified humid heat as a growing urban hazard, yet how
physiologically active vegetation governs this trade-off between cooling and
moisture accumulation remains poorly understood, leaving mitigation policy and
design largely unguided. Here we quantify how vegetation structure and function
influence the Heat Index (HI), a combined measure of temperature and humidity
in 138 Indian cities spanning tropical savanna, semi-arid steppe, and humid
subtropical climates, and across dense urban cores and semi-urban rings. Using
an extreme-aware, one kilometre reconstruction of HI and an interpretable
machine-learning framework that integrates SHapley Additive Explanations (SHAP)
and Accumulated Local Effects (ALE), we isolate vegetation-climate
interactions. Cooling generally strengthens for EVI >= 0.4 and LAI >= 0.05, but
joint-high regimes begin to reverse toward warming when EVI >= 0.5, LAI >= 0.2,
and fPAR >= 0.5,with an earlier onset for fPAR >= 0.25 in humid, dense cores.
In such environments, highly physiologically active vegetation elevates
near-surface humidity faster than it removes heat, reversing its cooling effect
and amplifying perceived heat stress. These findings establish the climatic
limits of vegetation-driven cooling and provide quantitative thresholds for
climate-specific greening strategies that promote equitable and heat-resilient
cities.

</details>


### [230] [A Dual Large Language Models Architecture with Herald Guided Prompts for Parallel Fine Grained Traffic Signal Control](https://arxiv.org/abs/2511.00136)
*Qing Guo,Xinhang Li,Junyu Chen,Zheng Guo,Xiaocong Li,Lin Zhang,Lei Li*

Main category: cs.LG

TL;DR: HeraldLight是一种基于双LLM架构的交通信号控制系统，通过Herald引导提示增强，显著提升了优化效率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM方法在交通信号控制中存在固定信号时长和幻觉错误问题，而RL方法缺乏鲁棒性和泛化能力。

Method: HeraldLight采用双LLM架构：LLM-Agent进行细粒度信号控制，LLM-Critic纠正错误和幻觉，并通过分数微调提升准确性。

Result: 在真实数据集上的实验表明，HeraldLight平均旅行时间减少20.03%，队列长度减少10.74%。

Conclusion: HeraldLight在交通信号控制中表现出色，优于现有方法，且代码已开源。

Abstract: Leveraging large language models (LLMs) in traffic signal control (TSC)
improves optimization efficiency and interpretability compared to traditional
reinforcement learning (RL) methods. However, existing LLM-based approaches are
limited by fixed time signal durations and are prone to hallucination errors,
while RL methods lack robustness in signal timing decisions and suffer from
poor generalization. To address these challenges, this paper proposes
HeraldLight, a dual LLMs architecture enhanced by Herald guided prompts. The
Herald Module extracts contextual information and forecasts queue lengths for
each traffic phase based on real-time conditions. The first LLM, LLM-Agent,
uses these forecasts to make fine grained traffic signal control, while the
second LLM, LLM-Critic, refines LLM-Agent's outputs, correcting errors and
hallucinations. These refined outputs are used for score-based fine-tuning to
improve accuracy and robustness. Simulation experiments using CityFlow on real
world datasets covering 224 intersections in Jinan (12), Hangzhou (16), and New
York (196) demonstrate that HeraldLight outperforms state of the art baselines,
achieving a 20.03% reduction in average travel time across all scenarios and a
10.74% reduction in average queue length on the Jinan and Hangzhou scenarios.
The source code is available on GitHub:
https://github.com/BUPT-ANTlab/HeraldLight.

</details>


### [231] [Study on Supply Chain Finance Decision-Making Model and Enterprise Economic Performance Prediction Based on Deep Reinforcement Learning](https://arxiv.org/abs/2511.00166)
*Shiman Zhang,Jinghan Zhou,Zhoufan Yu,Ningai Leng*

Main category: cs.LG

TL;DR: 提出了一种结合深度学习和智能粒子群优化的决策模型，用于提升后端集中冗余供应链的决策和规划效率。


<details>
  <summary>Details</summary>
Motivation: 提高后端集中冗余供应链的决策和规划效率。

Method: 结合深度学习（如卷积神经网络）和智能粒子群优化，构建分布式节点部署模型和最优规划路径，利用模糊关联规则调度和深度强化学习优化模型。

Result: 仿真显示资源消耗减少，空间规划增强，动态环境下实时决策调整、路径优化和智能控制能力提升。

Conclusion: 该模型有效提升了供应链网络的决策和规划效率，尤其在动态环境中表现优异。

Abstract: To improve decision-making and planning efficiency in back-end centralized
redundant supply chains, this paper proposes a decision model integrating deep
learning with intelligent particle swarm optimization. A distributed node
deployment model and optimal planning path are constructed for the supply chain
network. Deep learning such as convolutional neural networks extracts features
from historical data, and linear programming captures high-order statistical
features. The model is optimized using fuzzy association rule scheduling and
deep reinforcement learning, while neural networks fit dynamic changes. A
hybrid mechanism of "deep learning feature extraction - intelligent particle
swarm optimization" guides global optimization and selects optimal decisions
for adaptive control. Simulations show reduced resource consumption, enhanced
spatial planning, and in dynamic environments improved real-time decision
adjustment, distribution path optimization, and robust intelligent control.

</details>


### [232] [Can SAEs reveal and mitigate racial biases of LLMs in healthcare?](https://arxiv.org/abs/2511.00177)
*Hiba Ahsan,Byron C. Wallace*

Main category: cs.LG

TL;DR: SAEs可用于识别LLMs在临床应用中依赖人口统计数据的潜在问题，但通过SAE引导减轻偏见在实际任务中效果有限。


<details>
  <summary>Details</summary>
Motivation: 评估SAEs在揭示和控制LLMs对种族与负面概念关联的能力，以应对医疗领域中的偏见风险。

Method: 使用SAEs识别Gemma-2模型中与黑人相关的潜在变量，并通过这些变量引导模型输出。

Result: SAEs能识别出模型对种族的依赖，但通过潜在变量引导减轻偏见在实际临床任务中效果不佳。

Conclusion: SAEs在识别偏见方面有用，但在实际应用中减轻偏见的效果有限。

Abstract: LLMs are increasingly being used in healthcare. This promises to free
physicians from drudgery, enabling better care to be delivered at scale. But
the use of LLMs in this space also brings risks; for example, such models may
worsen existing biases. How can we spot when LLMs are (spuriously) relying on
patient race to inform predictions? In this work we assess the degree to which
Sparse Autoencoders (SAEs) can reveal (and control) associations the model has
made between race and stigmatizing concepts. We first identify SAE latents in
Gemma-2 models which appear to correlate with Black individuals. We find that
this latent activates on reasonable input sequences (e.g., "African American")
but also problematic words like "incarceration". We then show that we can use
this latent to steer models to generate outputs about Black patients, and
further that this can induce problematic associations in model outputs as a
result. For example, activating the Black latent increases the risk assigned to
the probability that a patient will become "belligerent". We evaluate the
degree to which such steering via latents might be useful for mitigating bias.
We find that this offers improvements in simple settings, but is less
successful for more realistic and complex clinical tasks. Overall, our results
suggest that: SAEs may offer a useful tool in clinical applications of LLMs to
identify problematic reliance on demographics but mitigating bias via SAE
steering appears to be of marginal utility for realistic tasks.

</details>


### [233] [PDE-SHARP: PDE Solver Hybrids Through Analysis & Refinement Passes](https://arxiv.org/abs/2511.00183)
*Shaghayegh Fazliani,Madeleine Udell*

Main category: cs.LG

TL;DR: PDE-SHARP框架通过用更便宜的LLM推理替代昂贵的科学计算，减少计算成本，同时提高求解器精度。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的方法在生成PDE求解器时需要大量计算资源，PDE-SHARP旨在降低这一成本。

Method: PDE-SHARP采用三阶段流程：分析、生成和合成，通过LLM推理和迭代优化生成高质量求解器。

Result: PDE-SHARP平均仅需13次求解器评估，比基线方法少60-75%，且精度平均提高4倍。

Conclusion: PDE-SHARP在减少计算成本的同时显著提高求解器精度，适用于多种LLM架构。

Abstract: Current LLM-driven approaches using test-time computing to generate PDE
solvers execute a large number of solver samples to identify high-accuracy
solvers. These paradigms are especially costly for complex PDEs requiring
substantial computational resources for numerical evaluation. We introduce
PDE-SHARP, a framework to reduce computational costs by replacing expensive
scientific computation by cheaper LLM inference that achieves superior solver
accuracy with 60-75% fewer computational evaluations. PDE-SHARP employs three
stages: (1) Analysis: mathematical chain-of-thought analysis including PDE
classification, solution type detection, and stability analysis; (2) Genesis:
solver generation based on mathematical insights from the previous stage; and
(3) Synthesis: collaborative selection-hybridization tournaments in which LLM
judges iteratively refine implementations through flexible performance
feedback. To generate high-quality solvers, PDE-SHARP requires fewer than 13
solver evaluations on average compared to 30+ for baseline methods, improving
accuracy uniformly across tested PDEs by $4\times$ on average, and demonstrates
robust performance across LLM architectures, from general-purpose to
specialized reasoning models.

</details>


### [234] [EL-MIA: Quantifying Membership Inference Risks of Sensitive Entities in LLMs](https://arxiv.org/abs/2511.00192)
*Ali Satvaty,Suzan Verberne,Fatih Turkmen*

Main category: cs.LG

TL;DR: 提出了一种新的任务EL-MIA，用于评估LLM中敏感信息的实体级成员推断风险，并构建了基准数据集。


<details>
  <summary>Details</summary>
Motivation: 现有MIA方法无法捕捉细粒度风险，需针对敏感信息开发更精确的评估方法。

Method: 提出EL-MIA框架，构建基准数据集，系统比较现有及新提出的MIA方法。

Result: 现有MIA方法在实体级敏感信息推断上表现有限，但可通过简单方法揭示风险。

Conclusion: 需开发更强对抗方法以测试威胁模型，强调实体级隐私风险的重要性。

Abstract: Membership inference attacks (MIA) aim to infer whether a particular data
point is part of the training dataset of a model. In this paper, we propose a
new task in the context of LLM privacy: entity-level discovery of membership
risk focused on sensitive information (PII, credit card numbers, etc). Existing
methods for MIA can detect the presence of entire prompts or documents in the
LLM training data, but they fail to capture risks at a finer granularity. We
propose the ``EL-MIA'' framework for auditing entity-level membership risks in
LLMs. We construct a benchmark dataset for the evaluation of MIA methods on
this task. Using this benchmark, we conduct a systematic comparison of existing
MIA techniques as well as two newly proposed methods. We provide a
comprehensive analysis of the results, trying to explain the relation of the
entity level MIA susceptability with the model scale, training epochs, and
other surface level factors. Our findings reveal that existing MIA methods are
limited when it comes to entity-level membership inference of the sensitive
attributes, while this susceptibility can be outlined with relatively
straightforward methods, highlighting the need for stronger adversaries to
stress test the provided threat model.

</details>


### [235] [Diffusion LLMs are Natural Adversaries for any LLM](https://arxiv.org/abs/2511.00203)
*David Lüdke,Tom Wollschläger,Paul Ungermann,Stephan Günnemann,Leo Schwinn*

Main category: cs.LG

TL;DR: 将对抗性提示优化问题转化为高效、摊销的推理任务，利用预训练的非自回归生成LLM直接生成提示。


<details>
  <summary>Details</summary>
Motivation: 解决传统提示优化资源密集的问题，利用生成模型提高效率。

Method: 使用Diffusion LLMs等非自回归生成模型，通过条件采样生成高奖励提示。

Result: 生成的提示低困惑度、多样化，且能有效攻击多种黑盒模型。

Conclusion: 框架为红队测试、自动提示优化等提供了新方向。

Abstract: We introduce a novel framework that transforms the resource-intensive
(adversarial) prompt optimization problem into an \emph{efficient, amortized
inference task}. Our core insight is that pretrained, non-autoregressive
generative LLMs, such as Diffusion LLMs, which model the joint distribution
over prompt-response pairs, can serve as powerful surrogates for prompt search.
This approach enables the direct conditional generation of prompts, effectively
replacing costly, per-instance discrete optimization with a small number of
parallelizable samples. We provide a probabilistic analysis demonstrating that
under mild fidelity assumptions, only a few conditional samples are required to
recover high-reward (harmful) prompts. Empirically, we find that the generated
prompts are low-perplexity, diverse jailbreaks that exhibit strong
transferability to a wide range of black-box target models, including robustly
trained and proprietary LLMs. Beyond adversarial prompting, our framework opens
new directions for red teaming, automated prompt optimization, and leveraging
emerging Flow- and Diffusion-based LLMs.

</details>


### [236] [Diffusion Models at the Drug Discovery Frontier: A Review on Generating Small Molecules versus Therapeutic Peptides](https://arxiv.org/abs/2511.00209)
*Yiquan Wang,Yahui Ma,Yuhan Chang,Jiayao Yan,Jialin Zhang,Minnuo Cai,Kai Wei*

Main category: cs.LG

TL;DR: 扩散模型在药物发现中展现出潜力，但需解决合成性和稳定性等挑战。


<details>
  <summary>Details</summary>
Motivation: 探讨扩散模型在小分子和肽类药物设计中的应用及其挑战。

Method: 系统比较扩散模型在小分子和肽类药物设计中的适应性。

Result: 模型在小分子设计中表现优异，但需解决合成性；肽类设计需关注稳定性和免疫原性。

Conclusion: 通过解决特定挑战并整合到自动化平台，扩散模型将推动药物发现范式转变。

Abstract: Diffusion models have emerged as a leading framework in generative modeling,
showing significant potential to accelerate and transform the traditionally
slow and costly process of drug discovery. This review provides a systematic
comparison of their application in designing two principal therapeutic
modalities: small molecules and therapeutic peptides. We analyze how a unified
framework of iterative denoising is adapted to the distinct molecular
representations, chemical spaces, and design objectives of each modality. For
small molecules, these models excel at structure-based design, generating
novel, pocket-fitting ligands with desired physicochemical properties, yet face
the critical hurdle of ensuring chemical synthesizability. Conversely, for
therapeutic peptides, the focus shifts to generating functional sequences and
designing de novo structures, where the primary challenges are achieving
biological stability against proteolysis, ensuring proper folding, and
minimizing immunogenicity. Despite these distinct challenges, both domains face
shared hurdles: the need for more accurate scoring functions, the scarcity of
high-quality experimental data, and the crucial requirement for experimental
validation. We conclude that the full potential of diffusion models will be
unlocked by bridging these modality-specific gaps and integrating them into
automated, closed-loop Design-Build-Test-Learn (DBTL) platforms, thereby
shifting the paradigm from chemical exploration to the targeted creation of
novel therapeutics.

</details>


### [237] [Iterative Foundation Model Fine-Tuning on Multiple Rewards](https://arxiv.org/abs/2511.00220)
*Pouya M. Ghari,Simone Sciabola,Ye Wang*

Main category: cs.LG

TL;DR: 提出了一种基于多奖励信号的强化学习方法，用于微调基础模型，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在文本生成和药物发现等应用中，单一奖励信号优化可能不够，需要多评价标准。

Method: 采用迭代微调策略，结合多奖励信号进行强化学习。

Result: 在文本、生物序列和小分子生成等领域的实验中表现优于现有基线。

Conclusion: 多奖励强化学习微调方法有效且通用，理论分析提供了性能见解。

Abstract: Fine-tuning foundation models has emerged as a powerful approach for
generating objects with specific desired properties. Reinforcement learning
(RL) provides an effective framework for this purpose, enabling models to
generate outputs that maximize a given reward function. However, in many
applications such as text generation and drug discovery, it can be suboptimal
to optimize using a single reward signal, as multiple evaluation criteria are
often necessary. This paper proposes a novel reinforcement learning-based
method for fine-tuning foundation models using multiple reward signals. By
employing an iterative fine-tuning strategy across these rewards, our approach
generalizes state-of-the-art RL-based methods. We further provide a theoretical
analysis that offers insights into the performance of multi-reward RL
fine-tuning. Experimental results across diverse domains including text,
biological sequence, and small molecule generation, demonstrate the
effectiveness of the proposed algorithm compared to state-of-the-art baselines.

</details>


### [238] [Melanoma Classification Through Deep Ensemble Learning and Explainable AI](https://arxiv.org/abs/2511.00246)
*Wadduwage Shanika Perera,ABM Islam,Van Vung Pham,Min Kyung An*

Main category: cs.LG

TL;DR: 论文提出了一种结合集成学习和可解释人工智能（XAI）的深度学习模型，用于提高黑色素瘤早期检测的可靠性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 黑色素瘤是一种致命性皮肤癌，早期检测至关重要。尽管深度学习在检测中表现出高准确性，但其黑箱特性导致结果缺乏可靠性和信任。XAI技术可以解决这一问题。

Method: 使用三种先进的深度迁移学习网络进行集成学习，并结合XAI技术解释预测依据。

Result: 模型能够高精度检测黑色素瘤，并通过XAI技术提供可解释的预测结果。

Conclusion: 结合XAI的集成学习方法提高了黑色素瘤检测的可靠性和可解释性，有助于医疗诊断中的信任建立。

Abstract: Melanoma is one of the most aggressive and deadliest skin cancers, leading to
mortality if not detected and treated in the early stages. Artificial
intelligence techniques have recently been developed to help dermatologists in
the early detection of melanoma, and systems based on deep learning (DL) have
been able to detect these lesions with high accuracy. However, the entire
community must overcome the explainability limit to get the maximum benefit
from DL for diagnostics in the healthcare domain. Because of the black box
operation's shortcomings in DL models' decisions, there is a lack of
reliability and trust in the outcomes. However, Explainable Artificial
Intelligence (XAI) can solve this problem by interpreting the predictions of AI
systems. This paper proposes a machine learning model using ensemble learning
of three state-of-the-art deep transfer Learning networks, along with an
approach to ensure the reliability of the predictions by utilizing XAI
techniques to explain the basis of the predictions.

</details>


### [239] [A Tight Lower Bound for Non-stochastic Multi-armed Bandits with Expert Advice](https://arxiv.org/abs/2511.00257)
*Zachary Chase,Shinji Ito,Idan Mehalel*

Main category: cs.LG

TL;DR: 论文确定了非随机多臂老虎机问题中专家建议的最小最大期望遗憾，通过证明与Kale (2014)上界匹配的下界，得出最优遗憾为Θ(√(TK log(N/K)))。


<details>
  <summary>Details</summary>
Motivation: 研究非随机多臂老虎机问题中专家建议的最小最大期望遗憾，填补理论空白。

Method: 通过证明与已有上界匹配的下界，确定最优遗憾。

Result: 最小最大期望遗憾为Θ(√(TK log(N/K)))，其中K为臂数，N为专家数，T为时间范围。

Conclusion: 论文填补了理论空白，确定了非随机多臂老虎机问题中专家建议的最小最大期望遗憾。

Abstract: We determine the minimax optimal expected regret in the classic
non-stochastic multi-armed bandit with expert advice problem, by proving a
lower bound that matches the upper bound of Kale (2014). The two bounds
determine the minimax optimal expected regret to be $\Theta\left( \sqrt{T K
\log (N/K) } \right)$, where $K$ is the number of arms, $N$ is the number of
experts, and $T$ is the time horizon.

</details>


### [240] [X-TRACK: Physics-Aware xLSTM for Realistic Vehicle Trajectory Prediction](https://arxiv.org/abs/2511.00266)
*Aanchal Rajesh Chugh,Marion Neumeier,Sebastian Dorn*

Main category: cs.LG

TL;DR: 论文提出了一种基于xLSTM的车辆轨迹预测框架X-TRAJ及其物理感知变体X-TRACK，通过引入物理约束生成更真实的轨迹。


<details>
  <summary>Details</summary>
Motivation: 传统LSTM在建模长期时间依赖性方面存在局限，而xLSTM虽有改进，但在车辆轨迹预测中尚未充分探索。

Method: 提出X-TRAJ和X-TRACK框架，后者显式整合车辆运动学约束。

Result: 在highD和NGSIM数据集上，X-TRACK优于现有基线方法。

Conclusion: X-TRACK通过物理约束提升了轨迹预测的准确性和可行性。

Abstract: Recent advancements in Recurrent Neural Network (RNN) architectures,
particularly the Extended Long Short Term Memory (xLSTM), have addressed the
limitations of traditional Long Short Term Memory (LSTM) networks by
introducing exponential gating and enhanced memory structures. These
improvements make xLSTM suitable for time-series prediction tasks as they
exhibit the ability to model long-term temporal dependencies better than LSTMs.
Despite their potential, these xLSTM-based models remain largely unexplored in
the context of vehicle trajectory prediction. Therefore, this paper introduces
a novel xLSTM-based vehicle trajectory prediction framework, X-TRAJ, and its
physics-aware variant, X-TRACK (eXtended LSTM for TRAjectory prediction
Constraint by Kinematics), which explicitly integrates vehicle motion
kinematics into the model learning process. By introducing physical
constraints, the proposed model generates realistic and feasible trajectories.
A comprehensive evaluation on the highD and NGSIM datasets demonstrates that
X-TRACK outperforms state-of-the-art baselines.

</details>


### [241] [Improving the Robustness of Control of Chaotic Convective Flows with Domain-Informed Reinforcement Learning](https://arxiv.org/abs/2511.00272)
*Michiel Straat,Thorben Markmann,Sebastian Peitz,Barbara Hammer*

Main category: cs.LG

TL;DR: 强化学习（RL）用于控制混沌对流，通过领域知识增强泛化能力和样本效率，在Rayleigh-Bénard对流中取得显著效果。


<details>
  <summary>Details</summary>
Motivation: 混沌对流在微流体设备和化学反应器中常见，但传统控制方法在混沌状态下效果不佳，RL的泛化能力和鲁棒性尚未充分探索。

Method: 使用领域知识设计的RL代理，通过Proximal Policy Optimization训练，奖励函数鼓励Bénard细胞合并。

Result: 在层流和混沌流中分别减少33%和10%的热传输，优于传统控制器，且无需重新训练即可泛化。

Conclusion: 领域知识能显著提升RL控制混沌流的鲁棒性，推动实际应用。

Abstract: Chaotic convective flows arise in many real-world systems, such as
microfluidic devices and chemical reactors. Stabilizing these flows is highly
desirable but remains challenging, particularly in chaotic regimes where
conventional control methods often fail. Reinforcement Learning (RL) has shown
promise for control in laminar flow settings, but its ability to generalize and
remain robust under chaotic and turbulent dynamics is not well explored,
despite being critical for real-world deployment. In this work, we improve the
practical feasibility of RL-based control of such flows focusing on
Rayleigh-B\'enard Convection (RBC), a canonical model for convective heat
transport. To enhance generalization and sample efficiency, we introduce
domain-informed RL agents that are trained using Proximal Policy Optimization
across diverse initial conditions and flow regimes. We incorporate domain
knowledge in the reward function via a term that encourages B\'enard cell
merging, as an example of a desirable macroscopic property. In laminar flow
regimes, the domain-informed RL agents reduce convective heat transport by up
to 33%, and in chaotic flow regimes, they still achieve a 10% reduction, which
is significantly better than the conventional controllers used in practice. We
compare the domain-informed to uninformed agents: Our results show that the
domain-informed reward design results in steady flows, faster convergence
during training, and generalization across flow regimes without retraining. Our
work demonstrates that elegant domain-informed priors can greatly enhance the
robustness of RL-based control of chaotic flows, bringing real-world deployment
closer.

</details>


### [242] [Calibration Across Layers: Understanding Calibration Evolution in LLMs](https://arxiv.org/abs/2511.00280)
*Abhinav Joshi,Areeb Ahmad,Ashutosh Modi*

Main category: cs.LG

TL;DR: 研究发现LLMs的校准能力是分布式的，不仅存在于最终层，还涉及网络深度的演化。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs校准能力在网络深度中的演化，揭示其分布式特性。

Method: 分析多个开源模型在MMLU基准上的表现，研究校准方向。

Result: 发现上层存在置信度修正阶段，扰动低维校准方向可改善校准指标。

Conclusion: 校准是分布式现象，为LLMs中的置信调节机制提供新见解。

Abstract: Large Language Models (LLMs) have demonstrated inherent calibration
capabilities, where predicted probabilities align well with correctness,
despite prior findings that deep neural networks are often overconfident.
Recent studies have linked this behavior to specific components in the final
layer, such as entropy neurons and the unembedding matrix null space. In this
work, we provide a complementary perspective by investigating how calibration
evolves throughout the network depth. Analyzing multiple open-weight models on
the MMLU benchmark, we uncover a distinct confidence correction phase in the
upper/later layers, where model confidence is actively recalibrated after
decision certainty has been reached. Furthermore, we identify a low-dimensional
calibration direction in the residual stream whose perturbation significantly
improves calibration metrics (ECE and MCE) without harming accuracy. Our
findings suggest that calibration is a distributed phenomenon, shaped
throughout the network forward pass, not just in its final projection,
providing new insights into how confidence-regulating mechanisms operate within
LLMs.

</details>


### [243] [A systematic evaluation of uncertainty quantification techniques in deep learning: a case study in photoplethysmography signal analysis](https://arxiv.org/abs/2511.00301)
*Ciaran Bench,Oskar Pfeffer,Vivek Desai,Mohammad Moulaeifard,Loïc Coquelin,Peter H. Charlton,Nils Strodthoff,Nando Hegemann,Philip J. Aston,Andrew Thompson*

Main category: cs.LG

TL;DR: 论文比较了八种不确定性量化技术在心房颤动检测和血压回归任务中的表现，强调评估标准应基于实际应用需求。


<details>
  <summary>Details</summary>
Motivation: 医疗时间序列数据（如PPG传感器数据）的深度学习模型在实际部署中可能表现不佳，可靠的不确定性量化有助于临床决策。

Method: 实施了八种不确定性量化技术，并在心房颤动检测（分类）和两种血压回归任务上进行了测试。

Result: 不同技术在不同任务中的可靠性表现复杂，最优方法取决于不确定性表达、评估指标和可靠性尺度。

Conclusion: 评估不确定性量化技术时应考虑实际应用需求，注重小尺度可靠性，同时保持预测性能。

Abstract: In principle, deep learning models trained on medical time-series, including
wearable photoplethysmography (PPG) sensor data, can provide a means to
continuously monitor physiological parameters outside of clinical settings.
However, there is considerable risk of poor performance when deployed in
practical measurement scenarios leading to negative patient outcomes. Reliable
uncertainties accompanying predictions can provide guidance to clinicians in
their interpretation of the trustworthiness of model outputs. It is therefore
of interest to compare the effectiveness of different approaches. Here we
implement an unprecedented set of eight uncertainty quantification (UQ)
techniques to models trained on two clinically relevant prediction tasks:
Atrial Fibrillation (AF) detection (classification), and two variants of blood
pressure regression. We formulate a comprehensive evaluation procedure to
enable a rigorous comparison of these approaches. We observe a complex picture
of uncertainty reliability across the different techniques, where the most
optimal for a given task depends on the chosen expression of uncertainty,
evaluation metric, and scale of reliability assessed. We find that assessing
local calibration and adaptivity provides practically relevant insights about
model behaviour that otherwise cannot be acquired using more commonly
implemented global reliability metrics. We emphasise that criteria for
evaluating UQ techniques should cater to the model's practical use case, where
the use of a small number of measurements per patient places a premium on
achieving small-scale reliability for the chosen expression of uncertainty,
while preserving as much predictive performance as possible.

</details>


### [244] [A Technical Exploration of Causal Inference with Hybrid LLM Synthetic Data](https://arxiv.org/abs/2511.00318)
*Dana Kim,Yichen Xu,Tiffany Lin*

Main category: cs.LG

TL;DR: 提出了一种结合模型协变量合成与倾向和结果模型的混合框架，以保留因果结构，并引入合成配对策略和评估协议。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成合成表格数据时难以保留关键因果参数（如ATE），导致因果效应估计不准确。

Method: 结合模型协变量合成与倾向和结果模型，采用距离过滤和合成配对策略，确保因果结构保留。

Result: 框架能够生成高保真且保留因果结构的合成数据，支持稳健的因果分析。

Conclusion: 为支持稳健因果分析的LLM数据管道奠定了基础，代码已开源。

Abstract: Large Language Models (LLMs) offer a flexible means to generate synthetic
tabular data, yet existing approaches often fail to preserve key causal
parameters such as the average treatment effect (ATE). In this technical
exploration, we first demonstrate that state-of-the-art synthetic data
generators, both GAN- and LLM-based, can achieve high predictive fidelity while
substantially misestimating causal effects. To address this gap, we propose a
hybrid generation framework that combines model-based covariate synthesis
(monitored via distance-to-closest-record filtering) with separately learned
propensity and outcome models, thereby ensuring that (W, A, Y) triplets retain
their underlying causal structure. We further introduce a synthetic pairing
strategy to mitigate positivity violations and a realistic evaluation protocol
that leverages unlimited synthetic samples to benchmark traditional estimators
(IPTW, AIPW, substitution) under complex covariate distributions. This work
lays the groundwork for LLM-powered data pipelines that support robust causal
analysis. Our code is available at
https://github.com/Xyc-arch/llm-synthetic-for-causal-inference.git.

</details>


### [245] [Reject Only Critical Tokens: Pivot-Aware Speculative Decoding](https://arxiv.org/abs/2511.00351)
*Amir Ziashahabi,Yavuz Faruk Bakman,Duygu Nur Yaldiz,Mostafa El-Khamy,Sai Praneeth Karimireddy,Salman Avestimehr*

Main category: cs.LG

TL;DR: 论文提出了一种新的解码策略Pivot-Aware Speculative Decoding，通过放宽分布匹配要求，仅拒绝会导致最终输出效用下降的关键令牌（pivot tokens），从而在保持任务性能的同时显著提高接受率和加速效果。


<details>
  <summary>Details</summary>
Motivation: 传统的Speculative Decoding要求输出与目标模型的分布完全匹配，导致接受率低且速度提升有限。实际应用中，任务性能（如代码正确性、事实准确性）比采样分布更重要。

Method: 提出Pivot-Aware Speculative Decoding策略，通过轻量级分类器识别关键令牌（pivot tokens），仅拒绝这些令牌以避免效用下降。

Result: 实验表明，该方法在保持任务性能的同时，可实现高达2.5倍的加速。

Conclusion: 通过放宽分布匹配要求并聚焦任务效用，Pivot-Aware Speculative Decoding显著提升了解码效率和实用性。

Abstract: Speculative Decoding (SD) ensures that the output matches the target model's
distribution exactly. However, we argue that this distribution matching
requirement is too stringent and results in unnecessarily low acceptance rates,
limiting potential speedups. Instead, we advocate a reformulation of the
decoding objective: the proposed decoding strategy should match the expected
utility, i.e., the task-specific performance, of the target model. This
perspective also aligns better with real-world use cases of LLMs, where utility
(e.g., code correctness, factual accuracy) is often more important than
sampling distribution. Based on this reformulation, we propose a novel decoding
strategy: Pivot-Aware Speculative Decoding, which rejects only those tokens
that would lead to a utility drop in the final output. We refer to these
critical tokens as pivot tokens. We propose a method for labeling tokens as
pivotal or non-pivotal and train a lightweight classifier to detect them. This
method can be viewed as a relaxed version of standard SD, which offers much
higher acceptance while preserving utility. We evaluate our method across
various datasets, demonstrating that we can achieve up to $2.5\times$ speedup
with comparable utility. Source code is available at
https://github.com/amir-zsh/PAD.

</details>


### [246] [Toward Unifying Group Fairness Evaluation from a Sparsity Perspective](https://arxiv.org/abs/2511.00359)
*Zhecheng Sheng,Jiawei Zhang,Enmao Diao*

Main category: cs.LG

TL;DR: 提出了一种基于稀疏性的统一框架来评估算法公平性，适用于多种机器学习任务。


<details>
  <summary>Details</summary>
Motivation: 现有公平性标准缺乏通用性，需要一种更通用的方法来评估算法公平性。

Method: 通过分析不同稀疏性度量与公平性的关系，提出统一的稀疏性框架。

Result: 实验证明该框架在多种数据集和偏差缓解方法中有效。

Conclusion: 该研究为算法公平性提供了新的视角，具有广泛的研究和应用潜力。

Abstract: Ensuring algorithmic fairness remains a significant challenge in machine
learning, particularly as models are increasingly applied across diverse
domains. While numerous fairness criteria exist, they often lack
generalizability across different machine learning problems. This paper
examines the connections and differences among various sparsity measures in
promoting fairness and proposes a unified sparsity-based framework for
evaluating algorithmic fairness. The framework aligns with existing fairness
criteria and demonstrates broad applicability to a wide range of machine
learning tasks. We demonstrate the effectiveness of the proposed framework as
an evaluation metric through extensive experiments on a variety of datasets and
bias mitigation methods. This work provides a novel perspective to algorithmic
fairness by framing it through the lens of sparsity and social equity, offering
potential for broader impact on fairness research and applications.

</details>


### [247] [Balancing Interpretability and Performance in Motor Imagery EEG Classification: A Comparative Study of ANFIS-FBCSP-PSO and EEGNet](https://arxiv.org/abs/2511.00369)
*Farjana Aktar,Mohd Ruhul Ameen,Akif Islam,Md Ekramul Hamid*

Main category: cs.LG

TL;DR: 比较了模糊推理方法（ANFIS-FBCSP-PSO）和深度学习基准（EEGNet）在运动想象EEG分类中的表现，发现模糊模型在个体内表现更好，而深度学习模型在跨个体测试中泛化能力更强。


<details>
  <summary>Details</summary>
Motivation: 解决运动想象EEG分类中准确性和可解释性的平衡问题。

Method: 使用ANFIS-FBCSP-PSO（结合滤波器组共空间模式特征提取和模糊规则优化）与EEGNet（直接从原始EEG数据学习时空表示）进行比较。

Result: 模糊模型在个体内实验中表现更优（准确率68.58%），而EEGNet在跨个体测试中泛化能力更强（准确率68.20%）。

Conclusion: 研究为根据设计目标（可解释性或跨用户鲁棒性）选择MI-BCI系统提供了实用指导，未来可探索基于Transformer和混合神经符号框架的透明EEG解码方法。

Abstract: Achieving both accurate and interpretable classification of motor imagery EEG
remains a key challenge in brain computer interface (BCI) research. This paper
compares a transparent fuzzy reasoning approach (ANFIS-FBCSP-PSO) with a deep
learning benchmark (EEGNet) using the BCI Competition IV-2a dataset. The ANFIS
pipeline combines filter bank common spatial pattern feature extraction with
fuzzy IF-THEN rules optimized via particle swarm optimization, while EEGNet
learns hierarchical spatial temporal representations directly from raw EEG
data. In within-subject experiments, the fuzzy neural model performed better
(68.58 percent +/- 13.76 percent accuracy, kappa = 58.04 percent +/- 18.43),
while in cross-subject (LOSO) tests, the deep model exhibited stronger
generalization (68.20 percent +/- 12.13 percent accuracy, kappa = 57.33 percent
+/- 16.22). The study provides practical guidance for selecting MI-BCI systems
according to design goals: interpretability or robustness across users. Future
investigations into transformer based and hybrid neuro symbolic frameworks are
expected to advance transparent EEG decoding.

</details>


### [248] [PolyRecommender: A Multimodal Recommendation System for Polymer Discovery](https://arxiv.org/abs/2511.00375)
*Xin Wang,Yunhao Xiao,Rui Qiao*

Main category: cs.LG

TL;DR: PolyRecommender是一个多模态发现框架，结合化学语言表示和分子图表示，用于高效检索和排序聚合物。


<details>
  <summary>Details</summary>
Motivation: 通过整合化学语言和分子图的多模态知识，提升聚合物设计的效率和鲁棒性。

Method: 使用PolyBERT的语言表示和分子图编码器，先基于语言相似性检索候选聚合物，再用多模态嵌入排序。

Result: 系统实现了高效检索和跨聚合物属性的鲁棒排序。

Conclusion: PolyRecommender为下一代聚合物的AI引导设计提供了通用多模态范式。

Abstract: We introduce PolyRecommender, a multimodal discovery framework that
integrates chemical language representations from PolyBERT with molecular
graph-based representations from a graph encoder. The system first retrieves
candidate polymers using language-based similarity and then ranks them using
fused multimodal embeddings according to multiple target properties. By
leveraging the complementary knowledge encoded in both modalities,
PolyRecommender enables efficient retrieval and robust ranking across related
polymer properties. Our work establishes a generalizable multimodal paradigm,
advancing AI-guided design for the discovery of next-generation polymers.

</details>


### [249] [UME-R1: Exploring Reasoning-Driven Generative Multimodal Embeddings](https://arxiv.org/abs/2511.00405)
*Zhibin Lan,Liqiang Niu,Fandong Meng,Jie Zhou,Jinsong Su*

Main category: cs.LG

TL;DR: 论文提出了一种生成式多模态嵌入框架UME-R1，通过两阶段训练策略（监督微调和强化学习）提升嵌入质量，显著优于传统判别式嵌入模型。


<details>
  <summary>Details</summary>
Motivation: 现有多模态嵌入模型主要为判别式，限制了其在生成式推理范式中的潜力，因此探索生成式嵌入以统一嵌入任务。

Method: 提出UME-R1框架，采用两阶段训练：监督微调赋予模型推理能力，生成判别式和生成式嵌入；强化学习进一步优化生成式嵌入质量。

Result: 在MMEB-V2基准测试中，UME-R1显著优于传统模型，生成式嵌入通过推理能力带来性能提升，且与判别式嵌入互补。

Conclusion: 生成式嵌入具有潜力，结合强化学习和推理能力可提升多模态嵌入性能，为可解释的生成式嵌入奠定基础。

Abstract: The remarkable success of multimodal large language models (MLLMs) has driven
advances in multimodal embeddings, yet existing models remain inherently
discriminative, limiting their ability to benefit from reasoning-driven
generation paradigm. In this work, we pioneer the exploration of generative
embeddings, unifying embedding tasks within a generative paradigm. We propose
UME-R1, a universal multimodal embedding framework consisting of a two-stage
training strategy: a cold-start supervised fine-tuning equips the model with
reasoning capabilities and enables it to generate both discriminative and
generative embeddings; a subsequent reinforcement learning enhances reasoning
and further optimizes generative embedding quality. This pioneering work
reveals four key insights: 1) generative embeddings unlock substantial
performance gains over conventional discriminative embeddings by leveraging the
powerful generative reasoning capabilities of MLLMs; 2) discriminative and
generative embeddings are complementary, whose combined oracle performance far
exceeding that of either alone; 3) RL can effectively enhance generative
embeddings, establishing a scalable optimization paradigm.; 4) repeated
sampling at inference boosts downstream task coverage (pass@k), highlighting
the inference-time scalability potential of generative embeddings. Evaluated on
the MMEB-V2 benchmark across 78 tasks spanning video, image, and visual
documents, UME-R1 significantly outperforms conventional discriminative
embedding models and offers a foundation for more interpretable,
reasoning-driven generative multimodal embeddings. Our code, models, and
datasets will be publicly available at https://github.com/XMUDeepLIT/UME-R1.

</details>


### [250] [Enhancing Adversarial Transferability by Balancing Exploration and Exploitation with Gradient-Guided Sampling](https://arxiv.org/abs/2511.00411)
*Zenghao Niu,Weicheng Xie,Siyang Song,Zitong Yu,Feng Liu,Linlin Shen*

Main category: cs.LG

TL;DR: 论文提出了一种梯度引导采样（GGS）方法，解决了对抗攻击在迁移场景中攻击强度与跨模型泛化性之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 对抗攻击在跨模型迁移时面临攻击强度（Exploitation）与泛化性（Exploration）的权衡问题，传统方法难以兼顾两者。

Method: 基于MI-FGSM，引入内迭代随机采样，并通过梯度引导采样方向，平衡攻击强度和泛化性。

Result: 实验表明，GGS在多种DNN架构和多模态大语言模型（MLLMs）上优于现有迁移攻击方法。

Conclusion: GGS通过梯度引导采样有效平衡了攻击强度和跨模型泛化性，提升了对抗攻击的迁移性能。

Abstract: Adversarial attacks present a critical challenge to deep neural networks'
robustness, particularly in transfer scenarios across different model
architectures. However, the transferability of adversarial attacks faces a
fundamental dilemma between Exploitation (maximizing attack potency) and
Exploration (enhancing cross-model generalization). Traditional momentum-based
methods over-prioritize Exploitation, i.e., higher loss maxima for attack
potency but weakened generalization (narrow loss surface). Conversely, recent
methods with inner-iteration sampling over-prioritize Exploration, i.e.,
flatter loss surfaces for cross-model generalization but weakened attack
potency (suboptimal local maxima). To resolve this dilemma, we propose a simple
yet effective Gradient-Guided Sampling (GGS), which harmonizes both objectives
through guiding sampling along the gradient ascent direction to improve both
sampling efficiency and stability. Specifically, based on MI-FGSM, GGS
introduces inner-iteration random sampling and guides the sampling direction
using the gradient from the previous inner-iteration (the sampling's magnitude
is determined by a random distribution). This mechanism encourages adversarial
examples to reside in balanced regions with both flatness for cross-model
generalization and higher local maxima for strong attack potency. Comprehensive
experiments across multiple DNN architectures and multimodal large language
models (MLLMs) demonstrate the superiority of our method over state-of-the-art
transfer attacks. Code is made available at https://github.com/anuin-cat/GGS.

</details>


### [251] [Tree Training: Accelerating Agentic LLMs Training via Shared Prefix Reuse](https://arxiv.org/abs/2511.00413)
*Shaojie Wang,Jinghui Wang,Yinghan Cui,Xuxing Chen,Chao Wang,Liang Huang,Xiaojiang Zhang,Junyi Peng,Li Wan,Haotian Zhang,Bin Chen*

Main category: cs.LG

TL;DR: 论文提出了一种名为Tree Training的新范式，通过共享前缀计算和梯度恢复技术，显著提高了大规模代理训练的计算效率。


<details>
  <summary>Details</summary>
Motivation: 当前训练流程将树状轨迹分解为独立的线性段，导致共享前缀重复计算，效率低下。

Method: 采用Tree Packing和Gradient Restoration技术，共享前缀计算并确保梯度正确传播。

Result: 实验表明，总训练时间最多减少3.9倍。

Conclusion: Tree Training能有效提升代理LLM的SFT和RL训练效率。

Abstract: In agentic LLM scenarios, an agent's interaction process during a single
rollout often exhibits branching behaviors. Due to memory retrieval and
concurrent tool executions at certain decision points, the token trajectory of
one task evolves into a tree-like structure rather than a linear sequence.
However, current training pipelines decompose such tree-structured trajectories
into separate linear segments, treating each branch as an independent sequence.
As a result, shared prefixes across these branches are repeatedly recomputed
during both forward and backward passes. To address this inefficiency, we
propose Tree Training, a paradigm that computes each shared prefix only once
and reuses its intermediate results across related branches during both forward
and backward passes, substantially improving computation efficiency in
large-scale agentic training. This is achieved via (i) Tree Packing, which
efficiently reuses shared computations across trajectories, and (ii) Gradient
Restoration, which ensures correct gradient propagation across reused prefixes.
Experiments on multiple open-source models demonstrate up to 3.9x reduction in
total training time, enabling more efficient agentic LLM SFT and RL training.

</details>


### [252] [Structure-Preserving Physics-Informed Neural Network for the Korteweg--de Vries (KdV) Equation](https://arxiv.org/abs/2511.00418)
*Victory Obieke,Emmanuel Oguadimma*

Main category: cs.LG

TL;DR: 本文提出了一种结构保持的物理信息神经网络（PINN）框架，用于解决非线性Korteweg-de Vries（KdV）方程，通过嵌入质量守恒和哈密顿能量到损失函数中，确保物理一致性和能量稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统PINN在长期积分中难以保持物理不变量，本文旨在解决这一问题，提出一种能够保持物理不变量（如质量和能量）的PINN框架。

Method: 采用正弦激活函数增强频谱表达能力，并将质量守恒和哈密顿能量直接嵌入损失函数中，确保物理一致性。

Result: 通过单孤子传播、双孤子相互作用和余弦脉冲初始化等案例研究，模型成功再现了KdV动力学的标志性行为，同时保持了守恒不变量。

Conclusion: 结合不变量约束优化和正弦特征映射，能够加速收敛、提高长期稳定性并减少漂移，为哈密顿偏微分方程提供了稳健且能量一致的PINN方法。

Abstract: Physics-Informed Neural Networks (PINNs) offer a flexible framework for
solving nonlinear partial differential equations (PDEs), yet conventional
implementations often fail to preserve key physical invariants during long-term
integration. This paper introduces a \emph{structure-preserving PINN} framework
for the nonlinear Korteweg--de Vries (KdV) equation, a prototypical model for
nonlinear and dispersive wave propagation. The proposed method embeds the
conservation of mass and Hamiltonian energy directly into the loss function,
ensuring physically consistent and energy-stable evolution throughout training
and prediction. Unlike standard \texttt{tanh}-based
PINNs~\cite{raissi2019pinn,wang2022modifiedpinn}, our approach employs
sinusoidal activation functions that enhance spectral expressiveness and
accurately capture the oscillatory and dispersive nature of KdV solitons.
Through representative case studies -- including single-soliton propagation
(shape-preserving translation), two-soliton interaction (elastic collision with
phase shift), and cosine-pulse initialization (nonlinear dispersive breakup) --
the model successfully reproduces hallmark behaviors of KdV dynamics while
maintaining conserved invariants. Ablation studies demonstrate that combining
invariant-constrained optimization with sinusoidal feature mappings accelerates
convergence, improves long-term stability, and mitigates drift without
multi-stage pretraining. These results highlight that computationally
efficient, invariant-aware regularization coupled with sinusoidal
representations yields robust, energy-consistent PINNs for Hamiltonian partial
differential equations such as the KdV equation.

</details>


### [253] [Bootstrap Off-policy with World Model](https://arxiv.org/abs/2511.00423)
*Guojian Zhan,Likun Wang,Xiangteng Zhang,Jiaxin Gao,Masayoshi Tomizuka,Shengbo Eben Li*

Main category: cs.LG

TL;DR: BOOM框架通过引导循环整合规划和离策略学习，提升RL的样本效率和性能。


<details>
  <summary>Details</summary>
Motivation: 解决规划引入的数据与策略行为偏差问题，提升模型学习和策略改进。

Method: BOOM框架结合引导循环和世界模型，使用无似然对齐损失和软值加权机制。

Result: 在DeepMind Control Suite和Humanoid-Bench上实现SOTA结果。

Conclusion: BOOM有效提升训练稳定性和最终性能。

Abstract: Online planning has proven effective in reinforcement learning (RL) for
improving sample efficiency and final performance. However, using planning for
environment interaction inevitably introduces a divergence between the
collected data and the policy's actual behaviors, degrading both model learning
and policy improvement. To address this, we propose BOOM (Bootstrap Off-policy
with WOrld Model), a framework that tightly integrates planning and off-policy
learning through a bootstrap loop: the policy initializes the planner, and the
planner refines actions to bootstrap the policy through behavior alignment.
This loop is supported by a jointly learned world model, which enables the
planner to simulate future trajectories and provides value targets to
facilitate policy improvement. The core of BOOM is a likelihood-free alignment
loss that bootstraps the policy using the planner's non-parametric action
distribution, combined with a soft value-weighted mechanism that prioritizes
high-return behaviors and mitigates variability in the planner's action quality
within the replay buffer. Experiments on the high-dimensional DeepMind Control
Suite and Humanoid-Bench show that BOOM achieves state-of-the-art results in
both training stability and final performance. The code is accessible at
https://github.com/molumitu/BOOM_MBRL.

</details>


### [254] [Region-Aware Reconstruction Strategy for Pre-training fMRI Foundation Model](https://arxiv.org/abs/2511.00443)
*Ruthwik Reddy Doodipala,Pankaj Pandey,Carolina Torres Rojas,Manob Jyoti Saikia,Ranganatha Sitaram*

Main category: cs.LG

TL;DR: 本文提出了一种基于ROI引导的掩码策略，用于静息态fMRI的基础模型预训练，相比随机掩码方法在ADHD分类任务上提升了4.23%的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模脑影像数据推动了基础模型的发展，但传统随机掩码方法在功能MRI任务中表现有限，需要更语义化的掩码策略。

Method: 使用AAL3图谱进行ROI引导的掩码，直接应用于4D fMRI数据，选择性地掩码语义连贯的脑区进行自监督预训练。

Result: 在ADHD-200数据集上，该方法比随机掩码的分类准确率提高了4.23%，且边缘系统和 cerebellum 对重建保真度贡献最大。

Conclusion: 解剖区域掩码不仅增强了模型的可解释性，还生成了更具判别性的表征，未来计划扩展到更多数据集和开发新的损失函数。

Abstract: The emergence of foundation models in neuroimaging is driven by the
increasing availability of large-scale and heterogeneous brain imaging
datasets. Recent advances in self-supervised learning, particularly
reconstruction-based objectives, have demonstrated strong potential for
pretraining models that generalize effectively across diverse downstream
functional MRI (fMRI) tasks. In this study, we explore region-aware
reconstruction strategies for a foundation model in resting-state fMRI, moving
beyond approaches that rely on random region masking. Specifically, we
introduce an ROI-guided masking strategy using the Automated Anatomical
Labelling Atlas (AAL3), applied directly to full 4D fMRI volumes to selectively
mask semantically coherent brain regions during self-supervised pretraining.
Using the ADHD-200 dataset comprising 973 subjects with resting-state fMRI
scans, we show that our method achieves a 4.23% improvement in classification
accuracy for distinguishing healthy controls from individuals diagnosed with
ADHD, compared to conventional random masking. Region-level attribution
analysis reveals that brain volumes within the limbic region and cerebellum
contribute most significantly to reconstruction fidelity and model
representation. Our results demonstrate that masking anatomical regions during
model pretraining not only enhances interpretability but also yields more
robust and discriminative representations. In future work, we plan to extend
this approach by evaluating it on additional neuroimaging datasets, and
developing new loss functions explicitly derived from region-aware
reconstruction objectives. These directions aim to further improve the
robustness and interpretability of foundation models for functional
neuroimaging.

</details>


### [255] [Deep Learning Approach to Anomaly Detection in Enterprise ETL Processes with Autoencoders](https://arxiv.org/abs/2511.00462)
*Xin Chen,Saili Uday Gadgil,Kangning Gao,Yi Hu,Cong Nie*

Main category: cs.LG

TL;DR: 提出了一种基于深度自编码器的异常检测方法，用于解决企业级ETL数据流中的异常问题，包括延迟、缺失值、重复加载和突变异常。


<details>
  <summary>Details</summary>
Motivation: 企业级ETL数据流中常出现多种异常，影响数据处理和分析的稳定性，需要一种高效且鲁棒的检测方法。

Method: 采用编码器-解码器结构，通过数据标准化和特征建模处理输入，利用重构误差衡量异常水平，并引入正则化约束增强特征稀疏性和分布学习。

Result: 在不同超参数设置、环境变化和数据特性下，该方法在AUC、ACC、Precision和Recall指标上表现优异。

Conclusion: 深度自编码器能有效捕捉ETL数据流的潜在分布模式，准确识别多种异常，为企业数据处理和智能分析提供可靠支持。

Abstract: An anomaly detection method based on deep autoencoders is proposed to address
anomalies that often occur in enterprise-level ETL data streams. The study
first analyzes multiple types of anomalies in ETL processes, including delays,
missing values, duplicate loading, and sudden abnormal changes, and applies
data standardization and feature modeling to ensure stable and usable inputs.
In the method design, the encoder-decoder structure compresses high-dimensional
inputs into latent representations and reconstructs them, while reconstruction
error is used to measure anomaly levels. Regularization constraints are
introduced in the latent space to enhance feature sparsity and distribution
learning, thereby improving robustness in complex data streams. Systematic
analyses under different hyperparameter settings, environmental changes, and
data characteristics show that the proposed method achieves superior
performance in AUC, ACC, Precision, and Recall. The results demonstrate that
the deep autoencoder-based detection mechanism can effectively capture latent
distribution patterns in enterprise-level ETL data streams and accurately
identify diverse anomalies, providing reliable support for enterprise data
processing and intelligent analysis.

</details>


### [256] [Why Federated Optimization Fails to Achieve Perfect Fitting? A Theoretical Perspective on Client-Side Optima](https://arxiv.org/abs/2511.00469)
*Zhongxiang Lei,Qi Yang,Ping Qiu,Gang Zhang,Yuanchi Ma,Jinyan Liu*

Main category: cs.LG

TL;DR: 论文通过理论分析解释了联邦学习中数据异构性导致性能下降的原因，并提出了两个关键结论。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习算法在数据异构情况下性能下降的原因尚不明确，论文旨在填补这一理论空白。

Method: 假设异构数据导致局部最优解不同，并分析其对全局目标下界和模型振荡的影响。

Result: 数据异构性会提高全局目标下界并导致模型振荡，实验验证了理论分析。

Conclusion: 论文为联邦学习中非独立同分布数据导致的性能下降提供了理论解释。

Abstract: Federated optimization is a constrained form of distributed optimization that
enables training a global model without directly sharing client data. Although
existing algorithms can guarantee convergence in theory and often achieve
stable training in practice, the reasons behind performance degradation under
data heterogeneity remain unclear. To address this gap, the main contribution
of this paper is to provide a theoretical perspective that explains why such
degradation occurs. We introduce the assumption that heterogeneous client data
lead to distinct local optima, and show that this assumption implies two key
consequences: 1) the distance among clients' local optima raises the lower
bound of the global objective, making perfect fitting of all client data
impossible; and 2) in the final training stage, the global model oscillates
within a region instead of converging to a single optimum, limiting its ability
to fully fit the data. These results provide a principled explanation for
performance degradation in non-iid settings, which we further validate through
experiments across multiple tasks and neural network architectures. The
framework used in this paper is open-sourced at:
https://github.com/NPCLEI/fedtorch.

</details>


### [257] [Variational Autoencoder for Calibration: A New Approach](https://arxiv.org/abs/2511.00475)
*Travis Barrett,Amit Kumar Mishra,Joyce Mwangama*

Main category: cs.LG

TL;DR: 提出了一种基于变分自编码器（VAE）的传感器校准新方法，通过训练潜在空间作为校准输出，并在多传感器气体数据集上验证了其可行性。


<details>
  <summary>Details</summary>
Motivation: 传统传感器校准方法可能复杂且效率低，利用VAE的潜在空间特性可以同时实现校准和自编码功能。

Method: 使用VAE训练潜在空间作为校准输出，并在多传感器气体数据集上进行概念验证。

Result: 校准VAE能够同时作为校准模型和自编码器，且其输出与真实数据在统计上相似。

Conclusion: 该方法展示了VAE在校准中的潜力，未来将进一步测试和扩展。

Abstract: In this paper we present a new implementation of a Variational Autoencoder
(VAE) for the calibration of sensors. We propose that the VAE can be used to
calibrate sensor data by training the latent space as a calibration output. We
discuss this new approach and show a proof-of-concept using an existing
multi-sensor gas dataset. We show the performance of the proposed calibration
VAE and found that it was capable of performing as calibration model while
performing as an autoencoder simultaneously. Additionally, these models have
shown that they are capable of creating statistically similar outputs from both
the calibration output as well as the reconstruction output to their respective
truth data. We then discuss the methods of future testing and planned expansion
of this work.

</details>


### [258] [Lyapunov Stability Learning with Nonlinear Control via Inductive Biases](https://arxiv.org/abs/2511.01283)
*Yupu Lu,Shijie Lin,Hao Xu,Zeqing Zhang,Jia Pan*

Main category: cs.LG

TL;DR: 论文提出了一种改进的神经网络控制Lyapunov函数（CLF）设计方法，通过将Lyapunov条件作为归纳偏置，实现了更稳定的优化过程和端到端学习。


<details>
  <summary>Details</summary>
Motivation: 现有方法将Lyapunov条件作为复杂约束进行优化，难以实现全局收敛且验证复杂。

Method: 设计了一个基于知识的神经CLF和控制器，将Lyapunov条件作为归纳偏置，简化优化过程。

Result: 实验表明，该方法在CLF学习中具有更高的收敛率和更大的吸引区域（ROA）。

Conclusion: 该方法优于现有方法，并揭示了先前方法在学习过程中成功率下降的原因。

Abstract: Finding a control Lyapunov function (CLF) in a dynamical system with a
controller is an effective way to guarantee stability, which is a crucial issue
in safety-concerned applications. Recently, deep learning models representing
CLFs have been applied into a learner-verifier framework to identify
satisfiable candidates. However, the learner treats Lyapunov conditions as
complex constraints for optimisation, which is hard to achieve global
convergence. It is also too complicated to implement these Lyapunov conditions
for verification. To improve this framework, we treat Lyapunov conditions as
inductive biases and design a neural CLF and a CLF-based controller guided by
this knowledge. This design enables a stable optimisation process with limited
constraints, and allows end-to-end learning of both the CLF and the controller.
Our approach achieves a higher convergence rate and larger region of attraction
(ROA) in learning the CLF compared to existing methods among abundant
experiment cases. We also thoroughly reveal why the success rate decreases with
previous methods during learning.

</details>


### [259] [Reasoning Planning for Language Models](https://arxiv.org/abs/2511.00521)
*Bao Nguyen,Hieu Trung Nguyen,Ruifeng She,Xiaojin Fu,Viet Anh Nguyen*

Main category: cs.LG

TL;DR: EPIC框架通过对比学习优化推理方法选择，提升准确性并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有方法假设更多候选答案能提高准确性，但缺乏理论支持。

Method: 提出EPIC框架，结合对比学习和概率边界正则化，优化推理方法选择。

Result: 在数学推理任务中，EPIC显著提升准确性并减少计算开销。

Conclusion: EPIC为语言模型推理方法选择提供了高效且理论支持的解决方案。

Abstract: Selecting an appropriate reasoning method for a given query remains a key
challenge in language model generation. Existing approaches typically generate
multiple candidate responses and use an aggregation strategy to select the
output answer, often assuming that more candidate answers yield higher
accuracy. We revisit this assumption through a rigorous theoretical analysis,
deriving accuracy bounds for standard aggregation methods under fixed
generation distributions and candidate sizes. Building on these insights, we
introduce EPIC, an Ensemble Planning with Contrastive learning framework to
learn a shared representation space that captures both model reasoning
abilities and query-method compatibility. EPIC incorporates our probability
bounds as a regularizer in a utility-driven optimization that balances accuracy
and computational cost. Experiments on diverse mathematical reasoning tasks
show that EPIC consistently selects optimal reasoning methods, improving
accuracy while reducing computational overhead. Our code can be found at
https://github.com/nguyenngocbaocmt02/EPIC.

</details>


### [260] [Air Pollution Forecasting in Bucharest](https://arxiv.org/abs/2511.00532)
*Dragoş-Andrei Şerban,Răzvan-Alexandru Smădu,Dumitru-Clementin Cercel*

Main category: cs.LG

TL;DR: 论文摘要讨论了PM2.5空气污染的危害及其预测的重要性，并介绍了使用多种机器学习模型进行预测的研究目标。


<details>
  <summary>Details</summary>
Motivation: PM2.5污染对健康有严重影响，预测其未来水平可提供早期预警，帮助预防疾病。

Method: 设计、微调、测试和评估多种机器学习模型，包括线性回归、集成方法、深度学习模型（如RNN和Transformer）以及大语言模型。

Result: 未提及具体结果，但目标是评估和比较不同模型的性能。

Conclusion: 研究旨在通过多种机器学习模型预测PM2.5水平，为健康预警提供支持。

Abstract: Air pollution, especially the particulate matter 2.5 (PM2.5), has become a
growing concern in recent years, primarily in urban areas. Being exposed to air
pollution is linked to developing numerous health problems, like the
aggravation of respiratory diseases, cardiovascular disorders, lung function
impairment, and even cancer or early death. Forecasting future levels of PM2.5
has become increasingly important over the past few years, as it can provide
early warnings and help prevent diseases. This paper aims to design, fine-tune,
test, and evaluate machine learning models for predicting future levels of
PM2.5 over various time horizons. Our primary objective is to assess and
compare the performance of multiple models, ranging from linear regression
algorithms and ensemble-based methods to deep learning models, such as advanced
recurrent neural networks and transformers, as well as large language models,
on this forecasting task.

</details>


### [261] [Learning an Efficient Optimizer via Hybrid-Policy Sub-Trajectory Balance](https://arxiv.org/abs/2511.00543)
*Yunchuan Guan,Yu Liu,Ke Zhou,Hui Li,Sen Jia,Zhiqi Shen,Ziyang Wang,Xinglin Zhang,Tao Chen,Jenq-Neng Hwang,Lei Li*

Main category: cs.LG

TL;DR: Lo-Hp是一个解耦的两阶段权重生成框架，通过混合策略子轨迹平衡目标提升灵活性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有生成权重方法中的过耦合和长视野问题，提升灵活性和推理效率。

Method: 采用两阶段权重生成框架和混合策略子轨迹平衡目标，结合策略内和策略外学习。

Result: 理论证明局部优化策略可解决长视野问题，实验验证在多种任务中具有高准确性和推理效率。

Conclusion: Lo-Hp在权重生成任务中表现出色，适用于需要频繁更新权重的场景。

Abstract: Recent advances in generative modeling enable neural networks to generate
weights without relying on gradient-based optimization. However, current
methods are limited by issues of over-coupling and long-horizon. The former
tightly binds weight generation with task-specific objectives, thereby limiting
the flexibility of the learned optimizer. The latter leads to inefficiency and
low accuracy during inference, caused by the lack of local constraints. In this
paper, we propose Lo-Hp, a decoupled two-stage weight generation framework that
enhances flexibility through learning various optimization policies. It adopts
a hybrid-policy sub-trajectory balance objective, which integrates on-policy
and off-policy learning to capture local optimization policies. Theoretically,
we demonstrate that learning solely local optimization policies can address the
long-horizon issue while enhancing the generation of global optimal weights. In
addition, we validate Lo-Hp's superior accuracy and inference efficiency in
tasks that require frequent weight updates, such as transfer learning, few-shot
learning, domain generalization, and large language model adaptation.

</details>


### [262] [Robust Single-Agent Reinforcement Learning for Regional Traffic Signal Control Under Demand Fluctuations](https://arxiv.org/abs/2511.00549)
*Qiang Li,Jin Niu,Lina Yu*

Main category: cs.LG

TL;DR: 提出了一种基于单智能体强化学习的区域自适应交通信号控制框架，通过集中决策和队列消散奖励设计，有效减少了交通拥堵。


<details>
  <summary>Details</summary>
Motivation: 交通拥堵主要由交叉口排队引起，传统交通信号控制方法难以应对复杂的实际交通动态。

Method: 采用单智能体强化学习框架，结合道路网络拓扑、实时队列状态和信号时序参数编码，利用DreamerV3世界模型学习控制策略。

Result: 在SUMO仿真中，模型在多级OD需求波动下表现出抗波动能力，显著缩短了队列长度。

Conclusion: 该研究为智能交通控制提供了新范式，未来将优化训练中的随机OD需求波动和应急事件处理机制。

Abstract: Traffic congestion, primarily driven by intersection queuing, significantly
impacts urban living standards, safety, environmental quality, and economic
efficiency. While Traffic Signal Control (TSC) systems hold potential for
congestion mitigation, traditional optimization models often fail to capture
real-world traffic complexity and dynamics. This study introduces a novel
single-agent reinforcement learning (RL) framework for regional adaptive TSC,
circumventing the coordination complexities inherent in multi-agent systems
through a centralized decision-making paradigm. The model employs an adjacency
matrix to unify the encoding of road network topology, real-time queue states
derived from probe vehicle data, and current signal timing parameters.
Leveraging the efficient learning capabilities of the DreamerV3 world model,
the agent learns control policies where actions sequentially select
intersections and adjust their signal phase splits to regulate traffic
inflow/outflow, analogous to a feedback control system. Reward design
prioritizes queue dissipation, directly linking congestion metrics (queue
length) to control actions. Simulation experiments conducted in SUMO
demonstrate the model's effectiveness: under inference scenarios with
multi-level (10%, 20%, 30%) Origin-Destination (OD) demand fluctuations, the
framework exhibits robust anti-fluctuation capability and significantly reduces
queue lengths. This work establishes a new paradigm for intelligent traffic
control compatible with probe vehicle technology. Future research will focus on
enhancing practical applicability by incorporating stochastic OD demand
fluctuations during training and exploring regional optimization mechanisms for
contingency events.

</details>


### [263] [Temporal Fusion Transformer for Multi-Horizon Probabilistic Forecasting of Weekly Retail Sales](https://arxiv.org/abs/2511.00552)
*Santhi Bharath Punati,Sandeep Kanta,Udaya Bhasker Cheerala,Madhusudan G Lanjewar,Praveen Damacharla*

Main category: cs.LG

TL;DR: 论文提出了一种基于Temporal Fusion Transformer (TFT)的零售销售预测方法，融合静态和动态数据，生成多周概率预测，显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 准确的零售销售预测对库存和促销活动至关重要，需要融合多种时间变化的外部信号。

Method: 使用TFT模型，结合静态商店标识符和时间变化的外部信号（如节假日、CPI等），通过Quantile Loss生成1-5周的概率预测。

Result: 在2012年固定测试集上，TFT的RMSE为57.9k美元，R²为0.9875；5折交叉验证的平均RMSE为64.6k美元，R²为0.9844，优于基线模型。

Conclusion: TFT在零售销售预测中表现出色，兼具高精度和模型可解释性，适用于库存规划和节假日优化。

Abstract: Accurate multi-horizon retail forecasts are critical for inventory and
promotions. We present a novel study of weekly Walmart sales (45 stores,
2010--2012) using a Temporal Fusion Transformer (TFT) that fuses static store
identifiers with time-varying exogenous signals (holidays, CPI, fuel price,
temperature). The pipeline produces 1--5-week-ahead probabilistic forecasts via
Quantile Loss, yielding calibrated 90\% prediction intervals and
interpretability through variable-selection networks, static enrichment, and
temporal attention. On a fixed 2012 hold-out dataset, TFT achieves an RMSE of
\$57.9k USD per store-week and an $R^2$ of 0.9875. Across a 5-fold
chronological cross-validation, the averages are RMSE = \$64.6k USD and $R^2$ =
0.9844, outperforming the XGB, CNN, LSTM, and CNN-LSTM baseline models. These
results demonstrate practical value for inventory planning and holiday-period
optimization, while maintaining model transparency.

</details>


### [264] [Red-teaming Activation Probes using Prompted LLMs](https://arxiv.org/abs/2511.00554)
*Phil Blandfort,Robert Graham*

Main category: cs.LG

TL;DR: 论文提出了一种轻量级黑盒红队测试方法，用于发现激活探针的脆弱性，无需微调或架构访问。


<details>
  <summary>Details</summary>
Motivation: 激活探针在现实世界中的鲁棒性尚未充分探索，研究旨在揭示其在黑盒对抗压力下的失效模式。

Method: 使用现成的LLM，结合迭代反馈和上下文学习（ICL），设计了一种无需微调或梯度访问的红队测试流程。

Result: 研究发现探针存在可解释的脆弱性模式（如法律术语导致的假阳性），并在场景约束攻击下仍表现出持续漏洞。

Conclusion: 简单的红队测试框架可以在部署前预测失效模式，为未来探针的加固提供有价值的见解。

Abstract: Activation probes are attractive monitors for AI systems due to low cost and
latency, but their real-world robustness remains underexplored. We ask: What
failure modes arise under realistic, black-box adversarial pressure, and how
can we surface them with minimal effort? We present a lightweight black-box
red-teaming procedure that wraps an off-the-shelf LLM with iterative feedback
and in-context learning (ICL), and requires no fine-tuning, gradients, or
architectural access. Running a case study with probes for high-stakes
interactions, we show that our approach can help discover valuable insights
about a SOTA probe. Our analysis uncovers interpretable brittleness patterns
(e.g., legalese-induced FPs; bland procedural tone FNs) and reduced but
persistent vulnerabilities under scenario-constraint attacks. These results
suggest that simple prompted red-teaming scaffolding can anticipate failure
patterns before deployment and might yield promising, actionable insights to
harden future probes.

</details>


### [265] [Fractional Diffusion Bridge Models](https://arxiv.org/abs/2511.01795)
*Gabriel Nobis,Maximilian Springenberg,Arina Belova,Rembert Daems,Christoph Knochenhauer,Manfred Opper,Tolga Birdal,Wojciech Samek*

Main category: cs.LG

TL;DR: 提出了一种基于分数布朗运动的新型生成扩散桥模型（FDBM），用于解决传统布朗运动无法捕捉的复杂随机过程特性。


<details>
  <summary>Details</summary>
Motivation: 传统扩散或桥模型使用布朗运动（BM）无法捕捉现实随机过程中的记忆效应、长程依赖性和异常扩散现象。

Method: 利用分数布朗运动的马尔可夫近似（MA-fBM），构建了FDBM，保留了非马尔可夫性并实现可处理的推理。

Result: 在蛋白质构象预测和无配对图像翻译任务中，FDBM表现优于布朗运动基线，RMSD和FID指标更低。

Conclusion: FDBM是一种有效的生成模型，能够更好地建模复杂随机过程，适用于多种任务。

Abstract: We present Fractional Diffusion Bridge Models (FDBM), a novel generative
diffusion bridge framework driven by an approximation of the rich and
non-Markovian fractional Brownian motion (fBM). Real stochastic processes
exhibit a degree of memory effects (correlations in time), long-range
dependencies, roughness and anomalous diffusion phenomena that are not captured
in standard diffusion or bridge modeling due to the use of Brownian motion
(BM). As a remedy, leveraging a recent Markovian approximation of fBM (MA-fBM),
we construct FDBM that enable tractable inference while preserving the
non-Markovian nature of fBM. We prove the existence of a coupling-preserving
generative diffusion bridge and leverage it for future state prediction from
paired training data. We then extend our formulation to the Schr\"{o}dinger
bridge problem and derive a principled loss function to learn the unpaired data
translation. We evaluate FDBM on both tasks: predicting future protein
conformations from aligned data, and unpaired image translation. In both
settings, FDBM achieves superior performance compared to the Brownian
baselines, yielding lower root mean squared deviation (RMSD) of C$_\alpha$
atomic positions in protein structure prediction and lower Fr\'echet Inception
Distance (FID) in unpaired image translation.

</details>


### [266] [FTT-GRU: A Hybrid Fast Temporal Transformer with GRU for Remaining Useful Life Prediction](https://arxiv.org/abs/2511.00564)
*Varun Teja Chirukiri,Udaya Bhasker Cheerala,Sandeep Kanta,Abdul Karim,Praveen Damacharla*

Main category: cs.LG

TL;DR: 提出了一种名为FTT-GRU的混合模型，结合了轻量级Transformer和GRU，用于预测工业机械的剩余使用寿命（RUL），在NASA CMAPSS数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如LSTM和CNN）难以同时建模全局时间依赖性和细粒度退化趋势，需要更高效的模型。

Method: 使用Fast Temporal Transformer（FTT）和GRU层结合，通过FFT线性化注意力机制，实现全局和局部退化模式的捕捉。

Result: 在CMAPSS FD001数据集上，RMSE为30.76，MAE为18.97，R²=0.45，优于现有最佳基线模型。

Conclusion: FTT-GRU模型在RUL预测中表现出高效和准确性，适用于实时工业预测。

Abstract: Accurate prediction of the remaining useful life (RUL) of industrial
machinery is essential for reducing downtime and optimizing maintenance
schedules. Existing approaches, such as long short-term memory (LSTM) networks
and convolutional neural networks (CNNs), often struggle to model both global
temporal dependencies and fine-grained degradation trends in multivariate
sensor data. We propose a hybrid model, FTT-GRU, which combines a Fast Temporal
Transformer (FTT) -- a lightweight Transformer variant using linearized
attention via fast Fourier transform (FFT) -- with a gated recurrent unit (GRU)
layer for sequential modeling. To the best of our knowledge, this is the first
application of an FTT with a GRU for RUL prediction on NASA CMAPSS, enabling
simultaneous capture of global and local degradation patterns in a compact
architecture. On CMAPSS FD001, FTT-GRU attains RMSE 30.76, MAE 18.97, and
$R^2=0.45$, with 1.12 ms CPU latency at batch=1. Relative to the best published
deep baseline (TCN--Attention), it improves RMSE by 1.16\% and MAE by 4.00\%.
Training curves averaged over $k=3$ runs show smooth convergence with narrow
95\% confidence bands, and ablations (GRU-only, FTT-only) support the
contribution of both components. These results demonstrate that a compact
Transformer-RNN hybrid delivers accurate and efficient RUL predictions on
CMAPSS, making it suitable for real-time industrial prognostics.

</details>


### [267] [Bayesian Network Structure Discovery Using Large Language Models](https://arxiv.org/abs/2511.00574)
*Yinghuan Zhang,Yufei Zhang,Parisa Kordjamshidi,Zijun Cui*

Main category: cs.LG

TL;DR: 提出了一种基于大语言模型（LLM）的统一框架，用于贝叶斯网络结构发现，支持无数据和有数据场景。


<details>
  <summary>Details</summary>
Motivation: 传统结构学习方法需要大量观测数据且计算成本高，现有LLM方法仅将其作为辅助工具，未充分利用其核心能力。

Method: 提出PromptBN（无数据时）和ReActBN（有数据时），分别利用LLM查询和ReAct推理范式结合结构评分进行迭代优化。

Result: 实验表明，该方法在低数据或无数据场景下显著优于现有LLM方法和传统数据驱动算法。

Conclusion: LLM在结构学习中作为核心工具具有潜力，尤其在数据稀缺时表现优异。

Abstract: Understanding probabilistic relationships among variables is crucial for
analyzing complex systems. Traditional structure learning methods often require
extensive observational data and incur high computational costs. Recent studies
have explored using large language models (LLMs) for structure learning, but
most treat LLMs as auxiliary tools for pre-processing or post-processing,
leaving the core learning process data-driven. In this work, we propose a
unified framework for Bayesian network structure discovery that places LLMs at
the center, supporting both data-free and data-aware settings. In the data-free
case, we introduce \textbf{PromptBN} to query LLMs with metadata and
efficiently uncover valid probabilistic relationships. When observational data
are available, we introduce \textbf{ReActBN}, which integrates the ReAct
reasoning paradigm with structure scores such as the Bayesian Information
Criterion (BIC) for iterative refinement. Unlike prior methods that offload
refinement to external algorithms, our framework maintains the LLM actively in
the loop throughout the discovery process. Experiments demonstrate that our
method significantly outperforms both existing LLM-based approaches and
traditional data-driven algorithms, particularly in the low- or no-data
scenario. Code is publicly available at
{\texttt{\textcolor{magenta}{https://github.com/sherryzyh/prompt2bn}}}.

</details>


### [268] [Sparse and nonparametric estimation of equations governing dynamical systems with applications to biology](https://arxiv.org/abs/2511.00579)
*G. Pillonetto,A. Giaretta,A. Aravkin,M. Bisiacco,T. Elston*

Main category: cs.LG

TL;DR: 论文提出了一种结合稀疏参数估计和非参数技术的新框架，用于从数据中发现复杂系统的模型方程，解决了传统方法难以准确描述非线性特性的问题。


<details>
  <summary>Details</summary>
Motivation: 复杂系统（如生物系统）的非线性特性难以通过传统的稀疏参数估计方法（如Sindy算法）准确描述，需要一种无需先验知识即可捕捉这些非线性特性的方法。

Method: 提出了一种结合稀疏参数估计和非参数技术的新框架，无需扩展函数库即可捕捉复杂系统中的非线性特性。

Result: 新框架在多个复杂生物现象估计的示例中展示了其有效性。

Conclusion: 该框架为数据驱动的模型发现提供了一种更灵活和强大的工具，尤其适用于复杂系统的非线性建模。

Abstract: Data-driven discovery of model equations is a powerful approach for
understanding the behavior of dynamical systems in many scientific fields. In
particular, the ability to learn mathematical models from data would benefit
systems biology, where the complex nature of these systems often makes a bottom
up approach to modeling unfeasible. In recent years, sparse estimation
techniques have gained prominence in system identification, primarily using
parametric paradigms to efficiently capture system dynamics with minimal model
complexity. In particular, the Sindy algorithm has successfully used sparsity
to estimate nonlinear systems by extracting from a library of functions only a
few key terms needed to capture the dynamics of these systems. However,
parametric models often fall short in accurately representing certain
nonlinearities inherent in complex systems. To address this limitation, we
introduce a novel framework that integrates sparse parametric estimation with
nonparametric techniques. It captures nonlinearities that Sindy cannot describe
without requiring a priori information about their functional form. That is,
without expanding the library of functions to include the one that is trying to
be discovered. We illustrate our approach on several examples related to
estimation of complex biological phenomena.

</details>


### [269] [Diagnosing Hallucination Risk in AI Surgical Decision-Support: A Sequential Framework for Sequential Validation](https://arxiv.org/abs/2511.00588)
*Dong Chen,Yanzhe Wei,Zonglin He,Guan-Ming Kuang,Canhua Ye,Meiru An,Huili Peng,Yong Hu,Huiren Tao,Kenneth MC Cheung*

Main category: cs.LG

TL;DR: 研究提出了一种以临床医生为中心的框架，量化大型语言模型在脊柱手术中的幻觉风险，评估了六个领先模型的表现，发现推理增强模型不一定优于标准版本，并建议将可解释性机制整合到临床工作流程中。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在脊柱手术临床决策支持中具有潜力，但幻觉风险可能危及患者安全，因此需要量化这些风险并评估模型表现。

Method: 通过评估诊断精度、推荐质量、推理稳健性、输出一致性和知识对齐，对六个领先的大型语言模型进行了30个专家验证的脊柱案例测试。

Result: DeepSeek-R1表现最佳（总分86.03±2.08），但推理增强模型（如Claude-3.7-Sonnet）未优于标准版本。多维压力测试揭示了模型在复杂情况下的推荐质量下降7.4%。

Conclusion: 研究建议将可解释性机制（如推理链可视化）整合到临床工作流程中，并建立安全意识的验证框架，以确保大型语言模型在手术中的可靠部署。

Abstract: Large language models (LLMs) offer transformative potential for clinical
decision support in spine surgery but pose significant risks through
hallucinations, which are factually inconsistent or contextually misaligned
outputs that may compromise patient safety. This study introduces a
clinician-centered framework to quantify hallucination risks by evaluating
diagnostic precision, recommendation quality, reasoning robustness, output
coherence, and knowledge alignment. We assessed six leading LLMs across 30
expert-validated spinal cases. DeepSeek-R1 demonstrated superior overall
performance (total score: 86.03 $\pm$ 2.08), particularly in high-stakes
domains such as trauma and infection. A critical finding reveals that
reasoning-enhanced model variants did not uniformly outperform standard
counterparts: Claude-3.7-Sonnet's extended thinking mode underperformed
relative to its standard version (80.79 $\pm$ 1.83 vs. 81.56 $\pm$ 1.92),
indicating extended chain-of-thought reasoning alone is insufficient for
clinical reliability. Multidimensional stress-testing exposed model-specific
vulnerabilities, with recommendation quality degrading by 7.4% under amplified
complexity. This decline contrasted with marginal improvements in rationality
(+2.0%), readability (+1.7%) and diagnosis (+4.7%), highlighting a concerning
divergence between perceived coherence and actionable guidance. Our findings
advocate integrating interpretability mechanisms (e.g., reasoning chain
visualization) into clinical workflows and establish a safety-aware validation
framework for surgical LLM deployment.

</details>


### [270] [Gaining Momentum: Uncovering Hidden Scoring Dynamics in Hockey through Deep Neural Sequencing and Causal Modeling](https://arxiv.org/abs/2511.00615)
*Daniel Griffiths,Piper Moskow*

Main category: cs.LG

TL;DR: 提出了一种统一的数据驱动框架，用于量化并提升职业冰球中的进攻势头和得分概率（预期进球xG）。


<details>
  <summary>Details</summary>
Motivation: 旨在通过数据分析和建模，为教练和分析师提供实时、可操作的战术优化建议。

Method: 包括五个阶段：动量加权、xG估计、时序建模、空间阵型发现和因果推断。

Result: 观察到采用优化事件序列和阵型的平均处理效应（ATE）为0.12，得分潜力相对提升15%。

Conclusion: 框架证明了结构化序列和紧凑阵型能显著提升进攻表现，推动了冰球战术优化的因果基础。

Abstract: We present a unified, data-driven framework for quantifying and enhancing
offensive momentum and scoring likelihood (expected goals, xG) in professional
hockey. Leveraging a Sportlogiq dataset of 541,000 NHL event records, our
end-to-end pipeline comprises five stages: (1) interpretable momentum weighting
of micro-events via logistic regression; (2) nonlinear xG estimation using
gradient-boosted decision trees; (3) temporal sequence modeling with Long
Short-Term Memory (LSTM) networks; (4) spatial formation discovery through
principal component analysis (PCA) followed by K-Means clustering on
standardized player coordinates; and (5) use of an X-Learner causal inference
estimator to quantify the average treatment effect (ATE) of adopting the
identified "optimal" event sequences and formations. We observe an ATE of 0.12
(95% CI: 0.05-0.17, p < 1e-50), corresponding to a 15% relative gain in scoring
potential. These results demonstrate that strategically structured sequences
and compact formations causally elevate offensive performance. Our framework
delivers real-time, actionable insights for coaches and analysts, advancing
hockey analytics toward principled, causally grounded tactical optimization.

</details>


### [271] [Belief Dynamics Reveal the Dual Nature of In-Context Learning and Activation Steering](https://arxiv.org/abs/2511.00617)
*Eric Bigelow,Daniel Wurgaft,YingQiao Wang,Noah Goodman,Tomer Ullman,Hidenori Tanaka,Ekdeep Singh Lubana*

Main category: cs.LG

TL;DR: 提出了一种基于贝叶斯视角的统一框架，解释和预测大型语言模型（LLM）通过提示和激活干预控制行为的方法。


<details>
  <summary>Details</summary>
Motivation: 探索提示（上下文学习）和激活干预（激活引导）这两种看似不同的方法是否可以被统一到一个更广泛的框架中。

Method: 从贝叶斯视角出发，将两种干预方法视为对模型潜在概念信念的影响：激活引导改变概念先验，而上下文学习通过证据积累影响信念。

Result: 提出了一个封闭形式的贝叶斯模型，能够预测LLM在多种干预下的行为，并解释了先前的经验现象（如S型学习曲线）和预测新现象（如干预的加性效应）。

Conclusion: 这项工作为LLM行为的提示和激活控制提供了统一的解释框架，并提供了预测干预效果的方法。

Abstract: Large language models (LLMs) can be controlled at inference time through
prompts (in-context learning) and internal activations (activation steering).
Different accounts have been proposed to explain these methods, yet their
common goal of controlling model behavior raises the question of whether these
seemingly disparate methodologies can be seen as specific instances of a
broader framework. Motivated by this, we develop a unifying, predictive account
of LLM control from a Bayesian perspective. Specifically, we posit that both
context- and activation-based interventions impact model behavior by altering
its belief in latent concepts: steering operates by changing concept priors,
while in-context learning leads to an accumulation of evidence. This results in
a closed-form Bayesian model that is highly predictive of LLM behavior across
context- and activation-based interventions in a set of domains inspired by
prior work on many-shot in-context learning. This model helps us explain prior
empirical phenomena - e.g., sigmoidal learning curves as in-context evidence
accumulates - while predicting novel ones - e.g., additivity of both
interventions in log-belief space, which results in distinct phases such that
sudden and dramatic behavioral shifts can be induced by slightly changing
intervention controls. Taken together, this work offers a unified account of
prompt-based and activation-based control of LLM behavior, and a methodology
for empirically predicting the effects of these interventions.

</details>


### [272] [Stochastic Shortest Path with Sparse Adversarial Costs](https://arxiv.org/abs/2511.00637)
*Emmeran Johnson,Alberto Rumi,Ciara Pike-Burke,Patrick Rebeschini*

Main category: cs.LG

TL;DR: 论文研究了具有稀疏成本的对抗性随机最短路径（SSP）问题，提出了一种适应稀疏性的正则化方法，显著降低了遗憾界。


<details>
  <summary>Details</summary>
Motivation: 现有基于负熵正则化的方法在稀疏成本问题上表现不佳，无法充分利用稀疏性优势，因此需要一种更适应稀疏性的方法。

Method: 提出了一种基于ℓᵣ范数正则化的方法（r∈(1,2)），能够适应稀疏性，实现更优的遗憾界。

Result: 新方法在稀疏问题上实现了√logM的遗憾界，优于传统方法的√logSA，并通过下界证明其最优性。

Conclusion: 稀疏性在已知转移设置下显著提升性能，但在未知转移设置下效果有限，遗憾界仍与SA多项式相关。

Abstract: We study the adversarial Stochastic Shortest Path (SSP) problem with sparse
costs under full-information feedback. In the known transition setting,
existing bounds based on Online Mirror Descent (OMD) with negative-entropy
regularization scale with $\sqrt{\log S A}$, where $SA$ is the size of the
state-action space. While we show that this is optimal in the worst-case, this
bound fails to capture the benefits of sparsity when only a small number $M \ll
SA$ of state-action pairs incur cost. In fact, we also show that the
negative-entropy is inherently non-adaptive to sparsity: it provably incurs
regret scaling with $\sqrt{\log S}$ on sparse problems. Instead, we propose a
family of $\ell_r$-norm regularizers ($r \in (1,2)$) that adapts to the
sparsity and achieves regret scaling with $\sqrt{\log M}$ instead of
$\sqrt{\log SA}$. We show this is optimal via a matching lower bound,
highlighting that $M$ captures the effective dimension of the problem instead
of $SA$. Finally, in the unknown transition setting the benefits of sparsity
are limited: we prove that even on sparse problems, the minimax regret for any
learner scales polynomially with $SA$.

</details>


### [273] [Diluting Restricted Boltzmann Machines](https://arxiv.org/abs/2511.00648)
*C. Díaz-Faloh,R. Mulet*

Main category: cs.LG

TL;DR: 研究发现，即使在训练前剪枝80%的连接，受限玻尔兹曼机（RBM）仍能保持高质量生成性能，但后续剪枝会显著降低性能。


<details>
  <summary>Details</summary>
Motivation: 探索在极端剪枝条件下，简单稀疏网络是否能保持高性能，以减少计算和环境成本。

Method: 研究受限玻尔兹曼机（RBM）在极端剪枝条件下的表现，并分析其子网络的可行性。

Result: RBM在训练前剪枝80%仍能保持性能，但后续剪枝会导致性能无法完全恢复，且存在关键连接被破坏的临界点。

Conclusion: 稀疏网络应在训练早期剪枝，初始条件对网络能力有持久影响。

Abstract: Recent advances in artificial intelligence have relied heavily on
increasingly large neural networks, raising concerns about their computational
and environmental costs. This paper investigates whether simpler, sparser
networks can maintain strong performance by studying Restricted Boltzmann
Machines (RBMs) under extreme pruning conditions. Inspired by the Lottery
Ticket Hypothesis, we demonstrate that RBMs can achieve high-quality generative
performance even when up to 80% of the connections are pruned before training,
confirming that they contain viable sub-networks. However, our experiments
reveal crucial limitations: trained networks cannot fully recover lost
performance through retraining once additional pruning is applied. We identify
a sharp transition above which the generative quality degrades abruptly when
pruning disrupts a minimal core of essential connections. Moreover, re-trained
networks remain constrained by the parameters originally learned performing
worse than networks trained from scratch at equivalent sparsity levels. These
results suggest that for sparse networks to work effectively, pruning should be
implemented early in training rather than attempted afterwards. Our findings
provide practical insights for the development of efficient neural
architectures and highlight the persistent influence of initial conditions on
network capabilities.

</details>


### [274] [Reviving Stale Updates: Data-Free Knowledge Distillation for Asynchronous Federated Learning](https://arxiv.org/abs/2511.00655)
*Baris Askin,Holger R. Roth,Zhenyu Sun,Carlee Joe-Wong,Gauri Joshi,Ziyue Xu*

Main category: cs.LG

TL;DR: FedRevive通过数据无关知识蒸馏（DFKD）解决异步联邦学习（AFL）中的陈旧更新问题，提升训练速度和模型精度。


<details>
  <summary>Details</summary>
Motivation: 异步联邦学习（AFL）因客户端独立通信而提高效率，但陈旧更新会破坏优化和收敛。

Method: FedRevive结合参数空间聚合和轻量级服务器端DFKD，通过元学习生成器合成伪样本实现多教师蒸馏。

Result: 实验显示FedRevive比异步基线训练速度提升32.1%，最终精度提高21.5%。

Conclusion: FedRevive有效缓解陈旧更新，同时保持AFL的可扩展性。

Abstract: Federated Learning (FL) enables collaborative model training across
distributed clients without sharing raw data, yet its scalability is limited by
synchronization overhead. Asynchronous Federated Learning (AFL) alleviates this
issue by allowing clients to communicate independently, thereby improving
wall-clock efficiency in large-scale, heterogeneous environments. However, this
asynchrony introduces stale updates (client updates computed on outdated global
models) that can destabilize optimization and hinder convergence. We propose
FedRevive, an asynchronous FL framework that revives stale updates through
data-free knowledge distillation (DFKD). FedRevive integrates parameter-space
aggregation with a lightweight, server-side DFKD process that transfers
knowledge from stale client models to the current global model without access
to real or public data. A meta-learned generator synthesizes pseudo-samples,
which enables multi-teacher distillation. A hybrid aggregation scheme that
combines raw updates with DFKD updates effectively mitigates staleness while
retaining the scalability of AFL. Experiments on various vision and text
benchmarks show that FedRevive achieves faster training up to 32.1% and higher
final accuracy up to 21.5% compared to asynchronous baselines.

</details>


### [275] [Sensitivity Analysis for Climate Science with Generative Flow Models](https://arxiv.org/abs/2511.00663)
*Alex Dobra,Jakiw Pidstrigach,Tim Reichelt,Paolo Fraccaro,Johannes Jakubik,Anne Jones,Christian Schroeder de Witt,Philip Stier,Philip Torr*

Main category: cs.LG

TL;DR: 利用伴随状态方法在生成流模型中计算梯度，显著降低气候敏感性分析的计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统物理模型计算气候敏感性成本高昂，AI生成模型虽快但梯度计算仍是瓶颈。

Method: 应用伴随状态方法于生成流模型（如扩散模型），提出梯度自一致性检验验证敏感性。

Result: 在cBottle生成模型上验证，计算成本从超级计算机数周降至GPU数小时。

Conclusion: 该方法可靠且高效，简化了气候科学中的关键工作流程。

Abstract: Sensitivity analysis is a cornerstone of climate science, essential for
understanding phenomena ranging from storm intensity to long-term climate
feedbacks. However, computing these sensitivities using traditional physical
models is often prohibitively expensive in terms of both computation and
development time. While modern AI-based generative models are orders of
magnitude faster to evaluate, computing sensitivities with them remains a
significant bottleneck. This work addresses this challenge by applying the
adjoint state method for calculating gradients in generative flow models, with
diffusion models as a special case. We apply this method to the cBottle
generative model, an emulator of ERA5 data, to perform sensitivity analysis
with respect to sea surface temperatures. Furthermore, we propose a novel
gradient self-consistency check to quantitatively validate the computed
sensitivities against the model's own outputs. Our results provide initial
evidence that this approach can produce reliable gradients, reducing the
computational cost of sensitivity analysis from weeks on a supercomputer with a
physical model to hours on a GPU, thereby simplifying a critical workflow in
climate science.

</details>


### [276] [Inference-Time Chain-of-Thought Pruning with Latent Informativeness Signals](https://arxiv.org/abs/2511.00699)
*Sophie Li,Nicholas Huang,Nayan Saxena,Nina Luo,Vincent Lin,Kevin Zhu,Sunishchal Dev*

Main category: cs.LG

TL;DR: KAPPA是一种基于KL散度、置信度和熵的剪枝算法，显著减少计算资源，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 解决BoN和ST-BoN在推理时的高计算成本和启发式限制问题。

Method: 结合KL散度、置信度和熵的评分函数，逐步剪枝低分分支。

Result: 在GSM8K和MATH500上，KAPPA减少60%内存和90%令牌使用，准确性影响小。

Conclusion: KAPPA是一种高效且准确的推理时剪枝方法。

Abstract: Large language models (LLMs) improve reasoning accuracy when generating
multiple candidate solutions at test time, but standard methods like Best-of-N
(BoN) incur high computational cost by fully generating all branches.
Self-Truncation Best-of-N (ST-BoN) mitigates this by truncating unpromising
paths early, but its reliance on consistency-based heuristics is a limitation
as it does not directly evaluate branch quality. We present KL-Adjusted Pruned
Path Algorithm (KAPPA), an inference-time method that combines Kullback-Leibler
divergence, confidence, and entropy into a principled scoring function to guide
progressive pruning. By promoting diversity during exploration and selectively
eliminating low-scoring branches, KAPPA maintains accuracy while substantially
reducing memory and token usage. Experiments on GSM8K and MATH500 with
DeepSeek-R1-Distill-Qwen-1.5B and Qwen2.5-7B-Instruct demonstrate that KAPPA
stabilizes performance in smaller models and achieves up to ~60% reduction in
peak memory and ~90% reduction in total token generation relative to BoN, with
minimal impact on accuracy.

</details>


### [277] [Privacy-Aware Time Series Synthesis via Public Knowledge Distillation](https://arxiv.org/abs/2511.00700)
*Penghang Liu,Haibei Zhu,Eleonora Kreacic,Svitlana Vyetrenko*

Main category: cs.LG

TL;DR: Pub2Priv框架利用公共知识生成隐私时间序列数据，通过自注意力机制和扩散模型优化隐私与效用的权衡。


<details>
  <summary>Details</summary>
Motivation: 解决敏感时间序列数据共享中的隐私问题，现有方法未充分利用公共上下文信息。

Method: 使用自注意力机制编码公共数据，作为扩散模型的条件输入生成合成数据。

Result: 在金融、能源等领域优于现有方法，提升隐私与效用的平衡。

Conclusion: Pub2Priv通过结合公共知识，显著改善了隐私时间序列数据的生成效果。

Abstract: Sharing sensitive time series data in domains such as finance, healthcare,
and energy consumption, such as patient records or investment accounts, is
often restricted due to privacy concerns. Privacy-aware synthetic time series
generation addresses this challenge by enforcing noise during training,
inherently introducing a trade-off between privacy and utility. In many cases,
sensitive sequences is correlated with publicly available, non-sensitive
contextual metadata (e.g., household electricity consumption may be influenced
by weather conditions and electricity prices). However, existing privacy-aware
data generation methods often overlook this opportunity, resulting in
suboptimal privacy-utility trade-offs. In this paper, we present Pub2Priv, a
novel framework for generating private time series data by leveraging
heterogeneous public knowledge. Our model employs a self-attention mechanism to
encode public data into temporal and feature embeddings, which serve as
conditional inputs for a diffusion model to generate synthetic private
sequences. Additionally, we introduce a practical metric to assess privacy by
evaluating the identifiability of the synthetic data. Experimental results show
that Pub2Priv consistently outperforms state-of-the-art benchmarks in improving
the privacy-utility trade-off across finance, energy, and commodity trading
domains.

</details>


### [278] [Investigating the Robustness of Knowledge Tracing Models in the Presence of Student Concept Drift](https://arxiv.org/abs/2511.00704)
*Morgan Lee,Artem Frenk,Eamon Worden,Karish Gupta,Thinh Pham,Ethan Croteau,Neil Heffernan*

Main category: cs.LG

TL;DR: 研究探讨了知识追踪（KT）模型在在线学习平台中因概念漂移和学生群体变化而表现下降的问题。


<details>
  <summary>Details</summary>
Motivation: 在线学习平台的动态变化可能导致KT模型性能下降，研究旨在评估不同KT模型对概念漂移的敏感性。

Method: 应用四种KT模型（包括贝叶斯知识追踪和基于注意力的模型）到五年数据中，分析其性能变化。

Result: 所有KT模型均表现性能下降，但贝叶斯知识追踪（BKT）最稳定，复杂模型性能下降更快。

Conclusion: 建议对KT模型进行更长期的评估，研究数据已公开以促进进一步研究。

Abstract: Knowledge Tracing (KT) has been an established problem in the educational
data mining field for decades, and it is commonly assumed that the underlying
learning process be- ing modeled remains static. Given the ever-changing land-
scape of online learning platforms (OLPs), we investigate how concept drift and
changing student populations can im- pact student behavior within an OLP
through testing model performance both within a single academic year and across
multiple academic years. Four well-studied KT models were applied to five
academic years of data to assess how suscep- tible KT models are to concept
drift. Through our analysis, we find that all four families of KT models can
exhibit de- graded performance, Bayesian Knowledge Tracing (BKT) remains the
most stable KT model when applied to newer data, while more complex, attention
based models lose pre- dictive power significantly faster. To foster more
longitu- dinal evaluations of KT models, the data used to conduct our analysis
is available at https://osf.io/hvfn9/?view_
only=b936c63dfdae4b0b987a2f0d4038f72a

</details>


### [279] [TRISKELION-1: Unified Descriptive-Predictive-Generative AI](https://arxiv.org/abs/2511.00711)
*Nardeep Kumar,Arun Kanwar*

Main category: cs.LG

TL;DR: TRISKELION-1是一个统一的描述-预测-生成架构，通过变分目标联合优化描述性表示学习、预测推理和生成合成。


<details>
  <summary>Details</summary>
Motivation: 旨在设计一个通用智能架构，结合可解释性、准确性和创造性。

Method: 采用编码器-解码器框架，整合统计、机制和生成推理。

Result: 在MNIST上的实验验证了描述性重建、预测分类和生成采样的稳定共存。

Conclusion: 该框架为连接可解释性、准确性和创造性的通用智能架构提供了蓝图。

Abstract: TRISKELION-1 is a unified descriptive-predictive-generative architecture that
integrates statistical, mechanistic, and generative reasoning within a single
encoder-decoder framework. The model demonstrates how descriptive
representation learning, predictive inference, and generative synthesis can be
jointly optimized using variational objectives. Experiments on MNIST validate
that descriptive reconstruction, predictive classification, and generative
sampling can coexist stably within one model. The framework provides a
blueprint toward universal intelligence architectures that connect
interpretability, accuracy, and creativity.

</details>


### [280] [Enhancing Heavy Rain Nowcasting with Multimodal Data: Integrating Radar and Satellite Observations](https://arxiv.org/abs/2511.00716)
*Rama Kassoumeh,David Rügamer,Henning Oppel*

Main category: cs.LG

TL;DR: 融合卫星和雷达数据的多模态模型显著提升了短时强降水预报的准确性，尤其在5分钟预报中表现突出。


<details>
  <summary>Details</summary>
Motivation: 传统地面传感器和雷达在监测和预报强降水事件时存在局限性，亟需更准确的预报方法以减少城市洪水风险。

Method: 开发了一种结合雷达和卫星图像的多模态短时预报模型，用于预测5、15和30分钟的降水。

Result: 多模态模型在强降水和暴雨预报中的准确性显著高于仅使用雷达的方法，5分钟预报的CSI指标分别提高了4%和3%。

Conclusion: 多模态模型能够提供更详细和准确的强降水预报，有助于及时发布预警，减少灾害损失。

Abstract: The increasing frequency of heavy rainfall events, which are a major cause of
urban flooding, underscores the urgent need for accurate precipitation
forecasting - particularly in urban areas where localized events often go
undetected by ground-based sensors. In Germany, only 17.3% of hourly heavy rain
events between 2001 and 2018 were recorded by rain gauges, highlighting the
limitations of traditional monitoring systems. Radar data are another source
that effectively tracks ongoing precipitation; however, forecasting the
development of heavy rain using radar alone remains challenging due to the
brief and unpredictable nature of such events. Our focus is on evaluating the
effectiveness of fusing satellite and radar data for nowcasting. We develop a
multimodal nowcasting model that combines both radar and satellite imagery for
predicting precipitation at lead times of 5, 15, and 30 minutes. We demonstrate
that this multimodal strategy significantly outperforms radar-only approaches.
Experimental results show that integrating satellite data improves prediction
accuracy, particularly for intense precipitation. The proposed model increases
the Critical Success Index for heavy rain by 4% and for violent rain by 3% at a
5-minute lead time. Moreover, it maintains higher predictive skill at longer
lead times, where radar-only performance declines. A qualitative analysis of
the severe flooding event in the state of North Rhine-Westphalia, Germany in
2021 further illustrates the superior performance of the multimodal model.
Unlike the radar-only model, which captures general precipitation patterns, the
multimodal model yields more detailed and accurate forecasts for regions
affected by heavy rain. This improved precision enables timely, reliable,
life-saving warnings. Implementation available at
https://github.com/RamaKassoumeh/Multimodal_heavy_rain

</details>


### [281] [Effective Series Decomposition and Components Learning for Time Series Generation](https://arxiv.org/abs/2511.00747)
*Zixuan Ma,Chenfeng Huang*

Main category: cs.LG

TL;DR: STDiffusion是一种新颖的多变量时间序列生成框架，结合扩散概率模型和可学习的序列分解技术，提升生成过程的可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏解释性分解技术，难以合成有意义的趋势和季节性模式。

Method: 采用MLP结构捕捉趋势，自适应小波蒸馏学习季节性成分，并设计校正机制确保内部一致性。

Result: 在八个真实数据集上表现优异，支持多窗口长序列生成，展示鲁棒性和多功能性。

Conclusion: STDiffusion在时间序列生成任务中达到最先进性能，并扩展了应用范围。

Abstract: Time series generation focuses on modeling the underlying data distribution
and resampling to produce authentic time series data. Key components, such as
trend and seasonality, drive temporal fluctuations, yet many existing
approaches fail to employ interpretative decomposition methods, limiting their
ability to synthesize meaningful trend and seasonal patterns. To address this
gap, we introduce Seasonal-Trend Diffusion (STDiffusion), a novel framework for
multivariate time series generation that integrates diffusion probabilistic
models with advanced learnable series decomposition techniques, enhancing the
interpretability of the generation process. Our approach separates the trend
and seasonal learning into distinct blocks: a Multi-Layer Perceptron (MLP)
structure captures the trend, while adaptive wavelet distillation facilitates
effective multi-resolution learning of seasonal components. This decomposition
improves the interpretability of the model on multiple scales. In addition, we
designed a comprehensive correction mechanism aimed at ensuring that the
generated components exhibit a high degree of internal consistency and preserve
meaningful interrelationships with one another. Our empirical studies on eight
real-world datasets demonstrate that STDiffusion achieves state-of-the-art
performance in time series generation tasks. Furthermore, we extend the model's
application to multi-window long-sequence time series generation, which
delivered reliable results and highlighted its robustness and versatility.

</details>


### [282] [Fast PINN Eigensolvers via Biconvex Reformulation](https://arxiv.org/abs/2511.00792)
*Akshay Sai Banderwaar,Abhishek Gupta*

Main category: cs.LG

TL;DR: 提出了一种基于双凸优化的PINN方法（PINN-ACS），用于快速求解特征值问题，比传统梯度训练快500倍。


<details>
  <summary>Details</summary>
Motivation: 特征值问题在系统热响应、稳定性和自然模态分析中至关重要，但传统PINN方法速度较慢。

Method: 将特征对搜索转化为双凸优化问题，采用交替凸搜索（ACS）方法，结合解析最优更新。

Result: 实验显示PINN-ACS精度高，收敛速度比梯度训练快500倍。

Conclusion: PINN-ACS为特征值问题提供了一种高效、快速的解决方案。

Abstract: Eigenvalue problems have a distinctive forward-inverse structure and are
fundamental to characterizing a system's thermal response, stability, and
natural modes. Physics-Informed Neural Networks (PINNs) offer a mesh-free
alternative for solving such problems but are often orders of magnitude slower
than classical numerical schemes. In this paper, we introduce a reformulated
PINN approach that casts the search for eigenpairs as a biconvex optimization
problem, enabling fast and provably convergent alternating convex search (ACS)
over eigenvalues and eigenfunctions using analytically optimal updates.
Numerical experiments show that PINN-ACS attains high accuracy with convergence
speeds up to 500$\times$ faster than gradient-based PINN training. We release
our codes at https://github.com/NeurIPS-ML4PS-2025/PINN_ACS_CODES.

</details>


### [283] [Efficient Reinforcement Learning for Large Language Models with Intrinsic Exploration](https://arxiv.org/abs/2511.00794)
*Yan Sun,Jia Guo,Stanley Kok,Zihao Wang,Zujie Wen,Zhiqiang Zhang*

Main category: cs.LG

TL;DR: PREPO通过利用内在数据特性（如提示困惑度和相对熵差异）提升RLVR的数据效率，减少训练所需的rollouts，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: RLVR训练成本高，许多rollouts对优化贡献有限，研究如何利用几乎免费的内在数据特性提升数据效率。

Method: 提出PREPO方法，包含两个部分：1) 使用提示困惑度作为模型适应性的指标；2) 通过相对熵差异放大rollouts的差异，优先探索性强的序列。

Result: 在Qwen和Llama模型上，PREPO在数学推理基准测试中仅需基线1/3的rollouts即可达到竞争性性能。

Conclusion: PREPO通过理论分析和实验验证，有效提升了RLVR的数据效率，减少了训练成本。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has improved the
reasoning ability of large language models, yet training remains costly because
many rollouts contribute little to optimization, considering the amount of
computation required. This study investigates how simply leveraging intrinsic
data properties, almost free benefit during training, can improve data
efficiency for RLVR. We propose PREPO with two complementary components. First,
we adopt prompt perplexity as an indicator of model adaptability in learning,
enabling the model to progress from well-understood contexts to more
challenging ones. Second, we amplify the discrepancy among the rollouts by
differentiating their relative entropy, and prioritize sequences that exhibit a
higher degree of exploration. Together, these mechanisms reduce rollout demand
while preserving competitive performance. On the Qwen and Llama models, PREPO
achieves effective results on mathematical reasoning benchmarks with up to 3
times fewer rollouts than the baselines. Beyond empirical gains, we provide
theoretical and in-depth analyses explaining the underlying rationale of our
method to improve the data efficiency of RLVR.

</details>


### [284] [Attention Saturation and Gradient Suppression at Inflection Layers: Diagnosing and Mitigating Bottlenecks in Transformer Adaptation](https://arxiv.org/abs/2511.00797)
*Wang Zixian*

Main category: cs.LG

TL;DR: 论文提出了一种诊断和修复Transformer微调中梯度抑制问题的方法，通过选择性注入LoRA适配器来恢复梯度信号。


<details>
  <summary>Details</summary>
Motivation: 预训练Transformer在微调时容易对源模式过度自信，难以形成新的目标模式，导致梯度抑制问题。

Method: 通过层间诊断指标识别梯度抑制的拐点层，并选择性注入LoRA适配器。

Result: 实验表明，在过训练初始化下，拐点层LoRA注入有效；欠训练初始化则性能下降。

Conclusion: 拐点层解封有助于高层组合适应，而低层重建需全路径解封。

Abstract: Pre-trained Transformers often exhibit over-confidence in source patterns and
difficulty in forming new target-domain patterns during fine-tuning. We
formalize the mechanism of output saturation leading to gradient suppression
through standard cross-entropy and softmax analysis, showing that gradient
suppression at inflection layers confines adaptation to high-level
recombination of existing features while preventing low-level reconstruction.
We introduce a set of layer-wise diagnostic metrics -- attention entropy
(saturation proxy), activation gradient norm, parameter gradient norm, and
Delta-CKA under a shared PCA basis -- to identify inflection layers
characterized by both low attention entropy and steep gradient decay. Building
on these findings, we propose a diagnose-first, inject-light fine-tuning
strategy: selectively inserting LoRA adapters at inflection layers to restore
suppressed backward signals with minimal parameter overhead. Experiments on
BERT-base transfer from SST-2 to Rotten Tomatoes under under-trained and
over-trained source regimes reveal that over-trained initialization benefits
from inflection-layer LoRA injection, while under-trained initialization
suffers performance degradation. When base features are strong, unblocking
inflection layers facilitates high-level compositional adaptation; when base
features are weak, full-pathway unblocking is required for low-level
reconstruction, as supported by joint analysis of layer-wise activation
gradients and Delta-CKA dynamics.

</details>


### [285] [EraseFlow: Learning Concept Erasure Policies via GFlowNet-Driven Alignment](https://arxiv.org/abs/2511.00804)
*Abhiram Kusumba,Maitreya Patel,Kyle Min,Changhoon Kim,Chitta Baral,Yezhou Yang*

Main category: cs.LG

TL;DR: EraseFlow通过探索去噪路径空间，利用GFlowNets优化概念遗忘，避免对抗性损失和重训练，提升性能与先验保留。


<details>
  <summary>Details</summary>
Motivation: 现有概念擦除技术导致图像质量下降、依赖脆弱对抗损失或需大量重训练，EraseFlow旨在解决这些问题。

Method: 引入EraseFlow框架，将概念遗忘视为去噪路径空间的探索，用GFlowNets优化轨迹平衡目标。

Result: EraseFlow在性能与先验保留间取得最优平衡，优于现有基线。

Conclusion: EraseFlow为概念擦除提供高效、通用且安全的解决方案。

Abstract: Erasing harmful or proprietary concepts from powerful text to image
generators is an emerging safety requirement, yet current "concept erasure"
techniques either collapse image quality, rely on brittle adversarial losses,
or demand prohibitive retraining cycles. We trace these limitations to a myopic
view of the denoising trajectories that govern diffusion based generation. We
introduce EraseFlow, the first framework that casts concept unlearning as
exploration in the space of denoising paths and optimizes it with GFlowNets
equipped with the trajectory balance objective. By sampling entire trajectories
rather than single end states, EraseFlow learns a stochastic policy that steers
generation away from target concepts while preserving the model's prior.
EraseFlow eliminates the need for carefully crafted reward models and by doing
this, it generalizes effectively to unseen concepts and avoids hackable rewards
while improving the performance. Extensive empirical results demonstrate that
EraseFlow outperforms existing baselines and achieves an optimal trade off
between performance and prior preservation.

</details>


### [286] [Logic-informed reinforcement learning for cross-domain optimization of large-scale cyber-physical systems](https://arxiv.org/abs/2511.00806)
*Guangxi Wan,Peng Zeng,Xiaoting Dong,Chunhe Song,Shijie Cui,Dong Li,Qingwei Dong,Yiyang Liu,Hongfei Bai*

Main category: cs.LG

TL;DR: LIRL方法通过逻辑投影确保混合动作空间的可行性，无需调整惩罚，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在混合动作空间中难以保证约束满足，且牺牲全局最优性。

Method: 结合标准策略梯度算法与逻辑投影，确保每一步动作的可行性。

Result: 在多个场景中表现优异，如工业制造中减少36.47%-44.33%的目标值。

Conclusion: LIRL框架可无缝迁移至其他领域，为大规模CPS提供安全实时优化方案。

Abstract: Cyber-physical systems (CPS) require the joint optimization of discrete cyber
actions and continuous physical parameters under stringent safety logic
constraints. However, existing hierarchical approaches often compromise global
optimality, whereas reinforcement learning (RL) in hybrid action spaces often
relies on brittle reward penalties, masking, or shielding and struggles to
guarantee constraint satisfaction. We present logic-informed reinforcement
learning (LIRL), which equips standard policy-gradient algorithms with
projection that maps a low-dimensional latent action onto the admissible hybrid
manifold defined on-the-fly by first-order logic. This guarantees feasibility
of every exploratory step without penalty tuning. Experimental evaluations have
been conducted across multiple scenarios, including industrial manufacturing,
electric vehicle charging stations, and traffic signal control, in all of which
the proposed method outperforms existing hierarchical optimization approaches.
Taking a robotic reducer assembly system in industrial manufacturing as an
example, LIRL achieves a 36.47\% to 44.33\% reduction at most in the combined
makespan-energy objective compared to conventional industrial hierarchical
scheduling methods. Meanwhile, it consistently maintains zero constraint
violations and significantly surpasses state-of-the-art hybrid-action
reinforcement learning baselines. Thanks to its declarative logic-based
constraint formulation, the framework can be seamlessly transferred to other
domains such as smart transportation and smart grid, thereby paving the way for
safe and real-time optimization in large-scale CPS.

</details>


### [287] [Equilibrium Policy Generalization: A Reinforcement Learning Framework for Cross-Graph Zero-Shot Generalization in Pursuit-Evasion Games](https://arxiv.org/abs/2511.00811)
*Runyu Lu,Peng Zhang,Ruochuan Shi,Yuanheng Zhu,Dongbin Zhao,Yang Liu,Dong Wang,Cesare Alippi*

Main category: cs.LG

TL;DR: EPG框架通过跨图训练和均衡策略指导，实现了在未见图上零样本性能的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法在图结构变化时需重新计算或微调的问题，提升实时适用性。

Method: 结合动态规划算法和强化学习，训练跨图均衡策略，并设计分组机制和序列模型。

Result: 在多种未见图上实现零样本性能，部分场景性能媲美微调方法。

Conclusion: EPG框架在对抗游戏中具有广泛适用性和高效性。

Abstract: Equilibrium learning in adversarial games is an important topic widely
examined in the fields of game theory and reinforcement learning (RL).
Pursuit-evasion game (PEG), as an important class of real-world games from the
fields of robotics and security, requires exponential time to be accurately
solved. When the underlying graph structure varies, even the state-of-the-art
RL methods require recomputation or at least fine-tuning, which can be
time-consuming and impair real-time applicability. This paper proposes an
Equilibrium Policy Generalization (EPG) framework to effectively learn a
generalized policy with robust cross-graph zero-shot performance. In the
context of PEGs, our framework is generally applicable to both pursuer and
evader sides in both no-exit and multi-exit scenarios. These two
generalizability properties, to our knowledge, are the first to appear in this
domain. The core idea of the EPG framework is to train an RL policy across
different graph structures against the equilibrium policy for each single
graph. To construct an equilibrium oracle for single-graph policies, we present
a dynamic programming (DP) algorithm that provably generates pure-strategy Nash
equilibrium with near-optimal time complexity. To guarantee scalability with
respect to pursuer number, we further extend DP and RL by designing a grouping
mechanism and a sequence model for joint policy decomposition, respectively.
Experimental results show that, using equilibrium guidance and a distance
feature proposed for cross-graph PEG training, the EPG framework guarantees
desirable zero-shot performance in various unseen real-world graphs. Besides,
when trained under an equilibrium heuristic proposed for the graphs with exits,
our generalized pursuer policy can even match the performance of the fine-tuned
policies from the state-of-the-art PEG methods.

</details>


### [288] [LL-ViT: Edge Deployable Vision Transformers with Look Up Table Neurons](https://arxiv.org/abs/2511.00812)
*Shashank Nag,Alan T. L. Bacellar,Zachary Susskind,Anshul Jha,Logan Liberty,Aishwarya Sivakumar,Eugene B. John,Krishnan Kailas,Priscila M. V. Lima,Neeraja J. Yadwadkar,Felipe M. G. Franca,Lizy K. John*

Main category: cs.LG

TL;DR: LL-ViT是一种新型的边缘优化视觉Transformer设计，通过集成LUT神经元层，显著减少了模型大小和计算量，同时保持与基线Transformer相当的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决Vision Transformers在边缘设备上计算、内存和能耗高的问题，同时提升在常见视觉任务上的性能。

Method: 设计基于LUT的通道混合器，并开发FPGA加速器，通过神经网络学习LUT函数。

Result: 在CIFAR-10、CIFAR-100和Tiny-ImageNet上分别达到95.5%、78.8%和60.9%的准确率，减少60%的模型权重和50%的乘法运算，提升能效和降低延迟。

Conclusion: LL-ViT是一种高效、低能耗的边缘视觉Transformer解决方案，适用于资源受限的设备。

Abstract: Vision Transformers have been tremendously successful in computer vision
tasks. However, their large computational, memory, and energy demands are a
challenge for edge inference on FPGAs -- a field that has seen a recent surge
in demand. We recognize the benefits of recent works on logic and Look Up Table
(LUT) based networks, such as LogicNets, NeuraLUT, DWN, among others, in
offering models that simultaneously reduce both the memory and compute
footprints. However, these models natively do not perform well on common vision
tasks, such as CIFAR-10/100. In this work, we propose LL-ViT, a novel edge
optimized vision transformer design that integrates layers of LUT neurons
within the transformer architecture. Based on our characterization that reveals
that a majority of model weights and computations are from the channel mixer
(MLP layer), we design an alternate LUT-based channel mixer, and simultaneously
develop an FPGA-based accelerator for LL-ViT. Contrary to some attempts to
replace each multiplication with a table lookup, our architecture utilizes a
neural learning approach which natively learns the LUT functions. This approach
allows for reduced model sizes, and a computational and energy-efficient
inference solution for vision transformer models. Evaluating on edge-suitable
workloads, we achieve accuracies of 95.5% on CIFAR-10, 78.8% on CIFAR-100, and
60.9% on Tiny-ImageNet datasets, comparable to the baseline transformer. LL-ViT
eliminates over 60% of the model weights and 50% of the multiplications in the
model, and achieves 1.9x energy efficiency and 1.3x lower latency over an
integer quantized ViT accelerator, while also offering superior throughput
against prior works at a 10.9W power budget.

</details>


### [289] [Identifying Slug Formation in Oil Well Pipelines: A Use Case from Industrial Analytics](https://arxiv.org/abs/2511.00851)
*Abhishek Patange,Sharat Chidambaran,Prabhat Shankar,Manjunath G. B.,Anindya Chatterjee*

Main category: cs.LG

TL;DR: 论文提出了一种交互式应用，用于实时检测油气管道中的段塞流，结合数据探索、模型训练和实时推理，提升操作安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有段塞流检测方法多为离线、依赖专业知识且缺乏实时解释性，亟需一种用户友好且实时的解决方案。

Method: 开发了一个端到端的数据驱动系统，支持数据标注、多分类器训练、结果可视化和实时推理，并具备轻量化和易部署特性。

Result: 系统通过交互式界面和实时警报功能，成功实现了段塞流的实时检测，适用于研究和工业应用。

Conclusion: 该工具填补了数据科学与实际决策之间的鸿沟，可推广至其他时间序列故障诊断任务。

Abstract: Slug formation in oil and gas pipelines poses significant challenges to
operational safety and efficiency, yet existing detection approaches are often
offline, require domain expertise, and lack real-time interpretability. We
present an interactive application that enables end-to-end data-driven slug
detection through a compact and user-friendly interface. The system integrates
data exploration and labeling, configurable model training and evaluation with
multiple classifiers, visualization of classification results with time-series
overlays, and a real-time inference module that generates persistence-based
alerts when slug events are detected. The demo supports seamless workflows from
labeled CSV uploads to live inference on unseen datasets, making it
lightweight, portable, and easily deployable. By combining domain-relevant
analytics with novel UI/UX features such as snapshot persistence, visual
labeling, and real-time alerting, our tool adds significant dissemination value
as both a research prototype and a practical industrial application. The demo
showcases how interactive human-in-the-loop ML systems can bridge the gap
between data science methods and real-world decision-making in critical process
industries, with broader applicability to time-series fault diagnosis tasks
beyond oil and gas.

</details>


### [290] [FlexiCache: Leveraging Temporal Stability of Attention Heads for Efficient KV Cache Management](https://arxiv.org/abs/2511.00868)
*Nazmul Takbir,Hamidreza Alikhani,Nikil Dutt,Sangeetha Abdu Jyothi*

Main category: cs.LG

TL;DR: FlexiCache通过利用KV头的时序稳定性，分层管理KV缓存，显著减少GPU内存使用和计算开销，同时保持模型精度。


<details>
  <summary>Details</summary>
Motivation: LLM服务中KV缓存随上下文和生成长度增长而膨胀，现有系统难以高效利用关键令牌的注意力特性而不损害精度。

Method: FlexiCache将KV头分类为稳定和不稳定，稳定头仅保留GPU中的top-K页面，其余卸载到主机内存，并定期重新排名。

Result: 在vLLM上实现后，FlexiCache减少GPU内存占用达70%，离线吞吐提升1.38-1.55倍，在线延迟降低1.6-2.1倍，且精度不变。

Conclusion: FlexiCache有效解决了长上下文和长生成场景下的KV缓存管理问题，显著提升了性能和效率。

Abstract: Large Language Model (LLM) serving is increasingly constrained by the growing
size of the key-value (KV) cache, which scales with both context length and
generation length. Prior work shows that attention is dominated by a small
subset of critical tokens, yet existing systems struggle to exploit this
efficiently without degrading accuracy, especially in long generation. We make
a key observation: the temporal stability of these critical tokens varies
significantly across KV heads: some heads consistently focus on the same
tokens, while others shift frequently. Building on this insight, we introduce
FlexiCache, a hierarchical KV-cache management system that leverages the
temporal stability of KV heads to reduce GPU memory usage and computation
overhead, while preserving model accuracy. FlexiCache classifies KV heads as
stable or unstable: it retains all KV-cache pages from unstable heads in GPU
memory, whereas for stable heads, it keeps only the top-K pages on the GPU and
offloads the rest to host memory. By exploiting temporal stability, FlexiCache
performs periodic reranking for stable heads to fetch newly promoted top pages.
Implemented atop vLLM, FlexiCache reduces GPU memory footprint for long-context
requests by up to 70%, improves offline serving throughput by 1.38-1.55x, and
lowers online token latency by 1.6-2.1x, all while maintaining accuracy in
long-context, long-generation scenarios.

</details>


### [291] [Training with Fewer Bits: Unlocking Edge LLMs Training with Stochastic Rounding](https://arxiv.org/abs/2511.00874)
*Taowen Liu,Marta Andronic,Deniz Gündüz,George A. Constantinides*

Main category: cs.LG

TL;DR: 研究表明，增加批量大小可以补偿反向传播中的低精度量化，同时量化权重和激活对梯度方差的影响不同。


<details>
  <summary>Details</summary>
Motivation: 量化训练虽提高效率但引入噪声，影响模型精度，随机舍入（SR）与批量大小的交互作用尚未充分研究。

Method: 通过理论和实验研究，分析SR在SGD中的表现，探讨批量大小与量化精度的关系。

Result: 实验验证了理论发现，批量大小可缓解量化噪声，权重和激活的量化对梯度方差有不同影响。

Conclusion: 研究为量化训练提供了新视角，批量大小是优化SR效果的关键因素。

Abstract: LLM training is resource-intensive. Quantized training improves computational
and memory efficiency but introduces quantization noise, which can hinder
convergence and degrade model accuracy. Stochastic Rounding (SR) has emerged as
a theoretically attractive alternative to deterministic rounding, offering
unbiased gradient estimates. However, its interaction with other training
factors -- especially batch size -- remains under explored. In this paper, we
present a theoretical and empirical study of mini-batch stochastic gradient
descent (SGD) with SR, showing that increased batch sizes can compensate for
reduced precision during back-propagation. Furthermore, we show that quantizing
weights and activations impacts gradient variance in distinct ways. Our
experiments validate these theoretical insights.

</details>


### [292] [KFCPO: Kronecker-Factored Approximated Constrained Policy Optimization](https://arxiv.org/abs/2511.00880)
*Joonyoung Lim,Younghwan Yoo*

Main category: cs.LG

TL;DR: KFCPO是一种结合K-FAC二阶策略优化和安全感知梯度操作的安全强化学习算法，通过自适应梯度调整和KL回滚策略，在安全性和性能上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决安全强化学习中奖励最大化与约束满足之间的权衡问题，同时提高算法的效率和稳定性。

Method: 利用K-FAC近似Fisher信息矩阵进行自然梯度更新，引入边缘感知梯度操作和KL回滚策略。

Result: 在Safety Gymnasium实验中，KFCPO的平均回报比最佳基线算法高出10.3%至50.2%。

Conclusion: KFCPO在安全性和性能之间实现了更好的平衡，是一种高效且稳定的安全强化学习算法。

Abstract: We propose KFCPO, a novel Safe Reinforcement Learning (Safe RL) algorithm
that combines scalable Kronecker-Factored Approximate Curvature (K-FAC) based
second-order policy optimization with safety-aware gradient manipulation. KFCPO
leverages K-FAC to perform efficient and stable natural gradient updates by
approximating the Fisher Information Matrix (FIM) in a layerwise, closed form
manner, avoiding iterative approximation overheads. To address the tradeoff
between reward maximization and constraint satisfaction, we introduce a margin
aware gradient manipulation mechanism that adaptively adjusts the influence of
reward and cost gradients based on the agent's proximity to safety boundaries.
This method blends gradients using a direction sensitive projection,
eliminating harmful interference and avoiding abrupt changes caused by fixed
hard thresholds. Additionally, a minibatch level KL rollback strategy is
adopted to ensure trust region compliance and to prevent destabilizing policy
shifts. Experiments on Safety Gymnasium using OmniSafe show that KFCPO achieves
10.3% to 50.2% higher average return across environments compared to the best
baseline that respected the safety constraint, demonstrating superior balance
of safety and performance.

</details>


### [293] [SpEx: A Spectral Approach to Explainable Clustering](https://arxiv.org/abs/2511.00885)
*Tal Argov,Tal Wagner*

Main category: cs.LG

TL;DR: 提出了一种基于谱图分割的可解释聚类新方法，适用于任何聚类或数据集。


<details>
  <summary>Details</summary>
Motivation: 现有方法局限于特定聚类目标，缺乏通用性。

Method: 采用谱图分割技术，设计可解释聚类算法。

Result: 实验表明，新方法在多个数据集上优于基线。

Conclusion: 新方法具有通用性和优越性能。

Abstract: Explainable clustering by axis-aligned decision trees was introduced by
Moshkovitz et al. (2020) and has gained considerable interest. Prior work has
focused on minimizing the price of explainability for specific clustering
objectives, lacking a general method to fit an explanation tree to any given
clustering, without restrictions. In this work, we propose a new and generic
approach to explainable clustering, based on spectral graph partitioning. With
it, we design an explainable clustering algorithm that can fit an explanation
tree to any given non-explainable clustering, or directly to the dataset
itself. Moreover, we show that prior algorithms can also be interpreted as
graph partitioning, through a generalized framework due to Trevisan (2013)
wherein cuts are optimized in two graphs simultaneously. Our experiments show
the favorable performance of our method compared to baselines on a range of
datasets.

</details>


### [294] [Learning with Category-Equivariant Representations for Human Activity Recognition](https://arxiv.org/abs/2511.00900)
*Yoshihiro Maruyama*

Main category: cs.LG

TL;DR: 提出了一种基于类别对称性的学习框架，通过捕捉信号在时间、尺度和传感器层次上的变化，提升模型在真实场景中的稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决传感器信号因环境、运动和上下文变化导致的模型不稳定问题。

Method: 采用类别对称感知学习框架，将时间、尺度和传感器层次的变化因素融入特征表示结构。

Result: 在UCI Human Activity Recognition基准测试中，分布外准确率提升约46个百分点（约3.6倍于基线）。

Conclusion: 抽象的对称性原则可通过类别等变表示理论转化为日常感知任务中的性能提升。

Abstract: Human activity recognition is challenging because sensor signals shift with
context, motion, and environment; effective models must therefore remain stable
as the world around them changes. We introduce a categorical symmetry-aware
learning framework that captures how signals vary over time, scale, and sensor
hierarchy. We build these factors into the structure of feature
representations, yielding models that automatically preserve the relationships
between sensors and remain stable under realistic distortions such as time
shifts, amplitude drift, and device orientation changes. On the UCI Human
Activity Recognition benchmark, this categorical symmetry-driven design
improves out-of-distribution accuracy by approx. 46 percentage points (approx.
3.6x over the baseline), demonstrating that abstract symmetry principles can
translate into concrete performance gains in everyday sensing tasks via
category-equivariant representation theory.

</details>


### [295] [Random Spiking Neural Networks are Stable and Spectrally Simple](https://arxiv.org/abs/2511.00904)
*Ernesto Araya,Massimiliano Datres,Gitta Kutyniok*

Main category: cs.LG

TL;DR: 该论文研究了离散时间泄漏积分发放（LIF）SNN的稳定性和鲁棒性，发现宽LIF-SNN分类器在平均情况下是稳定的，并提出了频谱简单性的概念。


<details>
  <summary>Details</summary>
Motivation: SNN的理论基础（尤其是稳定性和鲁棒性）相比人工神经网络仍有限，因此需要深入研究。

Method: 通过布尔函数分析研究LIF-SNN，量化输入扰动对输出的影响，并引入频谱简单性概念。

Result: 宽LIF-SNN分类器在平均情况下稳定，且随机LIF-SNN倾向于简单函数。实验验证了这些稳定性特性。

Conclusion: 研究为SNN的稳定性和鲁棒性提供了新见解，并揭示了其与深度网络中简单性偏见的联系。

Abstract: Spiking neural networks (SNNs) are a promising paradigm for energy-efficient
computation, yet their theoretical foundations-especially regarding stability
and robustness-remain limited compared to artificial neural networks. In this
work, we study discrete-time leaky integrate-and-fire (LIF) SNNs through the
lens of Boolean function analysis. We focus on noise sensitivity and stability
in classification tasks, quantifying how input perturbations affect outputs.
Our main result shows that wide LIF-SNN classifiers are stable on average, a
property explained by the concentration of their Fourier spectrum on
low-frequency components. Motivated by this, we introduce the notion of
spectral simplicity, which formalizes simplicity in terms of Fourier spectrum
concentration and connects our analysis to the simplicity bias observed in deep
networks. Within this framework, we show that random LIF-SNNs are biased toward
simple functions. Experiments on trained networks confirm that these stability
properties persist in practice. Together, these results provide new insights
into the stability and robustness properties of SNNs.

</details>


### [296] [Transformers as Intrinsic Optimizers: Forward Inference through the Energy Principle](https://arxiv.org/abs/2511.00907)
*Ruifeng Ren,Sheng Ouyang,Huayi Tang,Yong Liu*

Main category: cs.LG

TL;DR: 论文提出了一种基于能量的框架来理解Transformer模型，将标准注意力机制视为最小化Helmholtz自由能的特例，并扩展了多种梯度下降变体的注意力结构。


<details>
  <summary>Details</summary>
Motivation: 探索Transformer的底层机制，通过能量视角提供统一的理解框架。

Method: 提出基于能量的框架，包含全局能量、能量函数和梯度下降形式，并扩展至多头设置和不同梯度下降变体。

Result: 实验初步支持能量框架在注意力机制设计中的潜力。

Conclusion: 能量视角为Transformer的理解和设计提供了新思路。

Abstract: Transformers have demonstrated strong adaptability across a wide range of
tasks and have become the backbone of modern Large Language Models (LLMs).
However, their underlying mechanisms remain open for further exploration. The
energy-based perspective has long provided a valuable principle for
understanding neural computation. In this paper, we revisit the principle of
energy as a lens to understand attention-based Transformer models. We present a
unified energy-based framework which is composed of three key components: the
global energy $F^*$, the energy function $E_i$ and the employed gradient
descent (GD) form. Within this framework, standard softmax attention can be
viewed as a special case of minimizing the Helmholtz free energy as $F^*$ using
standard GD when $E_i$ takes the form of elastic potential energy, with
residual connections ensuring that this optimization proceeds in an incremental
manner. In addition, linear attentions can also be naturally incorporated into
this framework by adjusting the corresponding energy forms. We also extend the
above analysis to the multi-head setting, where the energy is defined across
multiple low-dimensional subspaces. Building on this framework, we propose
energy-based modifications of attention structures. Inspired by classical GD
algorithms, we extend the original attention formulation based on standard GD
to the momentum-based GD, Nesterov Accelerated Gradient (NAG), and Newton's
method variants, each inducing a corresponding new attention structure. Our
experiments provide preliminary support for the potential of the energy-based
framework for designing attention mechanisms.

</details>


### [297] [Motion-Robust Multimodal Fusion of PPG and Accelerometer Signals for Three-Class Heart Rhythm Classification](https://arxiv.org/abs/2511.00949)
*Yangyang Zhao,Matti Kaisti,Olli Lahdenoja,Tero Koivisto*

Main category: cs.LG

TL;DR: RhythmiNet是一种结合PPG和ACC信号的残差神经网络，通过时间和通道注意力模块提升性能，用于三分类心律检测（AF、SR、Other），在噪声数据中表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 心房颤动（AF）是中风和死亡的主要原因，现有单通道PPG方法易受运动伪影和噪声干扰，且仅支持二分类，无法满足临床需求。

Method: 提出RhythmiNet，结合PPG和ACC信号，利用残差网络和注意力模块进行三分类（AF、SR、Other），并在不同运动强度下测试鲁棒性。

Result: RhythmiNet在macro-AUC上比PPG-only基线提升4.3%，比基于HRV特征的逻辑回归模型提升12%。

Conclusion: 多模态融合和注意力学习能有效提升噪声临床数据中的心律分类性能。

Abstract: Atrial fibrillation (AF) is a leading cause of stroke and mortality,
particularly in elderly patients. Wrist-worn photoplethysmography (PPG) enables
non-invasive, continuous rhythm monitoring, yet suffers from significant
vulnerability to motion artifacts and physiological noise. Many existing
approaches rely solely on single-channel PPG and are limited to binary AF
detection, often failing to capture the broader range of arrhythmias
encountered in clinical settings. We introduce RhythmiNet, a residual neural
network enhanced with temporal and channel attention modules that jointly
leverage PPG and accelerometer (ACC) signals. The model performs three-class
rhythm classification: AF, sinus rhythm (SR), and Other. To assess robustness
across varying movement conditions, test data are stratified by
accelerometer-based motion intensity percentiles without excluding any
segments. RhythmiNet achieved a 4.3% improvement in macro-AUC over the PPG-only
baseline. In addition, performance surpassed a logistic regression model based
on handcrafted HRV features by 12%, highlighting the benefit of multimodal
fusion and attention-based learning in noisy, real-world clinical data.

</details>


### [298] [The Hidden Power of Normalization: Exponential Capacity Control in Deep Neural Networks](https://arxiv.org/abs/2511.00958)
*Khoat Than*

Main category: cs.LG

TL;DR: 论文通过理论框架解释了归一化方法在深度神经网络中的作用，证明其能指数级降低Lipschitz常数，从而优化损失函数平滑度和提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 归一化方法在深度神经网络中广泛使用，但其理论机制尚不明确，尤其是在多层归一化时的作用。

Method: 提出一个理论框架，从容量控制的角度分析归一化对Lipschitz常数的影响。

Result: 归一化层能指数级降低Lipschitz常数，优化损失函数平滑度和提升泛化能力。

Conclusion: 归一化方法通过指数级降低Lipschitz常数，为深度学习的优化和泛化提供了理论支持。

Abstract: Normalization methods are fundamental components of modern deep neural
networks (DNNs). Empirically, they are known to stabilize optimization dynamics
and improve generalization. However, the underlying theoretical mechanism by
which normalization contributes to both optimization and generalization remains
largely unexplained, especially when using many normalization layers in a DNN
architecture.
  In this work, we develop a theoretical framework that elucidates the role of
normalization through the lens of capacity control. We prove that an
unnormalized DNN can exhibit exponentially large Lipschitz constants with
respect to either its parameters or inputs, implying excessive functional
capacity and potential overfitting. Such bad DNNs are uncountably many. In
contrast, the insertion of normalization layers provably can reduce the
Lipschitz constant at an exponential rate in the number of normalization
operations. This exponential reduction yields two fundamental consequences: (1)
it smooths the loss landscape at an exponential rate, facilitating faster and
more stable optimization; and (2) it constrains the effective capacity of the
network, thereby enhancing generalization guarantees on unseen data. Our
results thus offer a principled explanation for the empirical success of
normalization methods in deep learning.

</details>


### [299] [Using Synthetic Data to estimate the True Error is theoretically and practically doable](https://arxiv.org/abs/2511.00964)
*Hai Hoang Thanh,Duy-Tung Nguyen,Hung The Tran,Khoat Than*

Main category: cs.LG

TL;DR: 论文提出了一种利用合成数据在有限标注数据条件下评估模型性能的方法，通过理论推导和实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统评估方法需要大量标注数据，成本高且耗时，而合成数据提供了一种替代方案。

Method: 开发了新的泛化边界，考虑合成数据，并提出了一种理论支持的方法生成优化合成数据用于评估。

Result: 实验表明，相比现有基线，该方法能更准确可靠地估计测试误差。

Conclusion: 合成数据在模型评估中具有潜力，生成器质量对结果有重要影响。

Abstract: Accurately evaluating model performance is crucial for deploying machine
learning systems in real-world applications. Traditional methods often require
a sufficiently large labeled test set to ensure a reliable evaluation. However,
in many contexts, a large labeled dataset is costly and labor-intensive.
Therefore, we sometimes have to do evaluation by a few labeled samples, which
is theoretically challenging. Recent advances in generative models offer a
promising alternative by enabling the synthesis of high-quality data. In this
work, we make a systematic investigation about the use of synthetic data to
estimate the test error of a trained model under limited labeled data
conditions. To this end, we develop novel generalization bounds that take
synthetic data into account. Those bounds suggest novel ways to optimize
synthetic samples for evaluation and theoretically reveal the significant role
of the generator's quality. Inspired by those bounds, we propose a
theoretically grounded method to generate optimized synthetic data for model
evaluation. Experimental results on simulation and tabular datasets demonstrate
that, compared to existing baselines, our method achieves accurate and more
reliable estimates of the test error.

</details>


### [300] [Modeling Microenvironment Trajectories on Spatial Transcriptomics with NicheFlow](https://arxiv.org/abs/2511.00977)
*Kristiyan Sakalyan,Alessandro Palma,Filippo Guerranti,Fabian J. Theis,Stephan Günnemann*

Main category: cs.LG

TL;DR: NicheFlow是一种基于流的生成模型，用于推断细胞微环境在连续空间切片中的时间轨迹。


<details>
  <summary>Details</summary>
Motivation: 理解细胞微环境的时空演化对组织发育和疾病进展至关重要，但现有方法仅关注单细胞水平，忽略了组织中细胞状态的协调发展。

Method: NicheFlow通过将局部细胞邻域表示为点云，结合最优传输和变分流匹配，共同建模细胞状态和空间坐标的演化。

Result: 该方法在多种时空数据集中成功恢复了全局空间结构和局部微环境组成。

Conclusion: NicheFlow为研究细胞微环境的时空演化提供了有效工具。

Abstract: Understanding the evolution of cellular microenvironments in spatiotemporal
data is essential for deciphering tissue development and disease progression.
While experimental techniques like spatial transcriptomics now enable
high-resolution mapping of tissue organization across space and time, current
methods that model cellular evolution operate at the single-cell level,
overlooking the coordinated development of cellular states in a tissue. We
introduce NicheFlow, a flow-based generative model that infers the temporal
trajectory of cellular microenvironments across sequential spatial slides. By
representing local cell neighborhoods as point clouds, NicheFlow jointly models
the evolution of cell states and spatial coordinates using optimal transport
and Variational Flow Matching. Our approach successfully recovers both global
spatial architecture and local microenvironment composition across diverse
spatiotemporal datasets, from embryonic to brain development.

</details>


### [301] [Balanced Multimodal Learning via Mutual Information](https://arxiv.org/abs/2511.00987)
*Rongrong Xie,Guido Sanguinetti*

Main category: cs.LG

TL;DR: 提出了一种解决模态不平衡的统一框架，通过互信息量化模态间交互，采用跨模态知识蒸馏和多任务训练策略。


<details>
  <summary>Details</summary>
Motivation: 模态不平衡问题在多模态学习中未得到充分解决，尤其在生物数据分析中，数据集有限且质量不均。

Method: 提出两阶段方法：跨模态知识蒸馏预训练和多任务式训练，动态校准梯度贡献。

Result: 有效缓解模态不平衡，显著提升多模态模型性能。

Conclusion: 该框架在多模态学习中有效解决了模态不平衡问题，提升了模型表现。

Abstract: Multimodal learning has increasingly become a focal point in research,
primarily due to its ability to integrate complementary information from
diverse modalities. Nevertheless, modality imbalance, stemming from factors
such as insufficient data acquisition and disparities in data quality, has
often been inadequately addressed. This issue is particularly prominent in
biological data analysis, where datasets are frequently limited, costly to
acquire, and inherently heterogeneous in quality. Conventional multimodal
methodologies typically fall short in concurrently harnessing intermodal
synergies and effectively resolving modality conflicts.
  In this study, we propose a novel unified framework explicitly designed to
address modality imbalance by utilizing mutual information to quantify
interactions between modalities. Our approach adopts a balanced multimodal
learning strategy comprising two key stages: cross-modal knowledge distillation
(KD) and a multitask-like training paradigm. During the cross-modal KD
pretraining phase, stronger modalities are leveraged to enhance the predictive
capabilities of weaker modalities. Subsequently, our primary training phase
employs a multitask-like learning mechanism, dynamically calibrating gradient
contributions based on modality-specific performance metrics and intermodal
mutual information. This approach effectively alleviates modality imbalance,
thereby significantly improving overall multimodal model performance.

</details>


### [302] [Hydra: Dual Exponentiated Memory for Multivariate Time Series Analysis](https://arxiv.org/abs/2511.00989)
*Asal Meskin,Alireza Mirrokni,Ali Najar,Ali Behrouz*

Main category: cs.LG

TL;DR: Hydra是一种双头元上下文记忆模块，通过优先处理信息丰富的时间序列模式，解决了现有模型在时间归纳偏差和效率上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有模型（如Transformer、MLP和线性模型）在时间序列建模中存在时间归纳偏差不足、无法捕捉变量间依赖关系以及长时建模效率低的问题。

Method: Hydra采用二维递归设计，结合时间和变量维度，并提出了2D分块训练算法以提高效率。

Result: 实验表明，Hydra在时间序列预测、分类和异常检测任务中优于现有基线模型。

Conclusion: Hydra通过创新的二维递归设计和高效训练算法，显著提升了多变量时间序列建模的性能和效率。

Abstract: In recent years, effectively modeling multivariate time series has gained
significant popularity, mainly due to its wide range of applications, ranging
from healthcare to financial markets and energy management. Transformers, MLPs,
and linear models as the de facto backbones of modern time series models have
shown promising results in single-variant and/or short-term forecasting. These
models, however: (1) are permutation equivariant and so lack temporal inductive
bias, being less expressive to capture the temporal dynamics; (2) are naturally
designed for univariate setup, missing the inter-dependencies of temporal and
variate dimensions; and/or (3) are inefficient for Long-term time series
modeling. To overcome training and inference efficiency as well as the lack of
temporal inductive bias, recently, linear Recurrent Neural Networks (RNNs) have
gained attention as an alternative to Transformer-based models. These models,
however, are inherently limited to a single sequence, missing inter-variate
dependencies, and can propagate errors due to their additive nature. In this
paper, we present Hydra, a by-design two-headed meta in-context memory module
that learns how to memorize patterns at test time by prioritizing time series
patterns that are more informative about the data. Hydra uses a 2-dimensional
recurrence across both time and variate at each step, which is more powerful
than mixing methods. Although the 2-dimensional nature of the model makes its
training recurrent and non-parallelizable, we present a new 2D-chunk-wise
training algorithm that approximates the actual recurrence with $\times 10$
efficiency improvement, while maintaining the effectiveness. Our experimental
results on a diverse set of tasks and datasets, including time series
forecasting, classification, and anomaly detection show the superior
performance of Hydra compared to state-of-the-art baselines.

</details>


### [303] [None To Optima in Few Shots: Bayesian Optimization with MDP Priors](https://arxiv.org/abs/2511.01006)
*Diantong Li,Kyunghyun Cho,Chong Liu*

Main category: cs.LG

TL;DR: ProfBO算法通过MDP先验和元学习，显著减少黑盒优化中的函数评估次数，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯优化在现实应用中因高成本评估而不实用，ProfBO旨在解决这一问题。

Method: 利用MDP先验建模优化轨迹，结合神经网络和元学习快速适应新任务。

Result: 在Covid、Cancer等实际任务中，ProfBO以更少评估次数取得更优结果。

Conclusion: ProfBO高效实用，适用于高成本评估场景。

Abstract: Bayesian Optimization (BO) is an efficient tool for optimizing black-box
functions, but its theoretical guarantees typically hold in the asymptotic
regime. In many critical real-world applications such as drug discovery or
materials design, where each evaluation can be very costly and time-consuming,
BO becomes impractical for many evaluations. In this paper, we introduce the
Procedure-inFormed BO (ProfBO) algorithm, which solves black-box optimization
with remarkably few function evaluations. At the heart of our algorithmic
design are Markov Decision Process (MDP) priors that model optimization
trajectories from related source tasks, thereby capturing procedural knowledge
on efficient optimization. We embed these MDP priors into a prior-fitted neural
network and employ model-agnostic meta-learning for fast adaptation to new
target tasks. Experiments on real-world Covid and Cancer benchmarks and
hyperparameter tuning tasks demonstrate that ProfBO consistently outperforms
state-of-the-art methods by achieving high-quality solutions with significantly
fewer evaluations, making it ready for practical deployment.

</details>


### [304] [Equality Graph Assisted Symbolic Regression](https://arxiv.org/abs/2511.01009)
*Fabricio Olivetti de Franca,Gabriel Kronberger*

Main category: cs.LG

TL;DR: SymRegg是一种基于e-graph结构的新符号回归搜索算法，通过避免冗余计算提高搜索效率，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 传统遗传编程在符号回归中因中性概念导致大量冗余计算，e-graph结构能有效存储等效表达式以避免重复计算。

Method: SymRegg通过扰动e-graph中存储的表达式样本生成新表达式，若未访问过则插入e-graph并生成等效形式。

Result: SymRegg在多个数据集上保持高准确性，同时显著减少计算冗余。

Conclusion: SymRegg通过e-graph结构优化搜索效率，是一种高效且准确的符号回归方法。

Abstract: In Symbolic Regression (SR), Genetic Programming (GP) is a popular search
algorithm that delivers state-of-the-art results in term of accuracy. Its
success relies on the concept of neutrality, which induces large plateaus that
the search can safely navigate to more promising regions. Navigating these
plateaus, while necessary, requires the computation of redundant expressions,
up to 60% of the total number of evaluation, as noted in a recent study. The
equality graph (e-graph) structure can compactly store and group equivalent
expressions enabling us to verify if a given expression and their variations
were already visited by the search, thus enabling us to avoid unnecessary
computation. We propose a new search algorithm for symbolic regression called
SymRegg that revolves around the e-graph structure following simple steps:
perturb solutions sampled from a selection of expressions stored in the
e-graph, if it generates an unvisited expression, insert it into the e-graph
and generates its equivalent forms. We show that SymRegg is capable of
improving the efficiency of the search, maintaining consistently accurate
results across different datasets while requiring a choice of a minimalist set
of hyperparameters.

</details>


### [305] [What's the next frontier for Data-centric AI? Data Savvy Agents](https://arxiv.org/abs/2511.01015)
*Nabeel Seedat,Jiashuo Liu,Mihaela van der Schaar*

Main category: cs.LG

TL;DR: 论文提出数据智能能力应成为自主代理系统设计的核心，以实现可靠的实际部署。


<details>
  <summary>Details</summary>
Motivation: 当前AI代理在数据处理方面研究不足，而可扩展的自主性需要代理持续获取、处理和更新数据。

Method: 提出四种关键能力：主动数据获取、复杂数据处理、交互式测试数据合成和持续适应。

Result: 强调数据智能代理的重要性，呼吁将其作为数据中心AI的下一个前沿。

Conclusion: 数据智能能力是代理系统可靠部署的关键，需成为未来研究的重点。

Abstract: The recent surge in AI agents that autonomously communicate, collaborate with
humans and use diverse tools has unlocked promising opportunities in various
real-world settings. However, a vital aspect remains underexplored: how agents
handle data. Scalable autonomy demands agents that continuously acquire,
process, and evolve their data. In this paper, we argue that data-savvy
capabilities should be a top priority in the design of agentic systems to
ensure reliable real-world deployment. Specifically, we propose four key
capabilities to realize this vision: (1) Proactive data acquisition: enabling
agents to autonomously gather task-critical knowledge or solicit human input to
address data gaps; (2) Sophisticated data processing: requiring context-aware
and flexible handling of diverse data challenges and inputs; (3) Interactive
test data synthesis: shifting from static benchmarks to dynamically generated
interactive test data for agent evaluation; and (4) Continual adaptation:
empowering agents to iteratively refine their data and background knowledge to
adapt to shifting environments. While current agent research predominantly
emphasizes reasoning, we hope to inspire a reflection on the role of data-savvy
agents as the next frontier in data-centric AI.

</details>


### [306] [SARIMAX-Based Power Outage Prediction During Extreme Weather Events](https://arxiv.org/abs/2511.01017)
*Haoran Ye,Qiuzhuang Sun,Yang Yang*

Main category: cs.LG

TL;DR: 开发了一种基于SARIMAX的短期停电预测系统，用于极端天气事件下的预测，通过特征工程和稳健优化策略，性能提升8.4%。


<details>
  <summary>Details</summary>
Motivation: 解决极端天气事件下短期停电预测的挑战，提高预测准确性。

Method: 采用两阶段特征工程（数据清洗和相关性过滤），结合SARIMAX模型，并应用标准化和分层拟合策略。

Result: RMSE为177.2，比基线方法（193.4）提升8.4%。

Conclusion: 特征工程和优化策略有效提升了极端天气相关停电预测的性能。

Abstract: This study develops a SARIMAX-based prediction system for short-term power
outage forecasting during extreme weather events. Using hourly data from
Michigan counties with outage counts and comprehensive weather features, we
implement a systematic two-stage feature engineering pipeline: data cleaning to
remove zero-variance and unknown features, followed by correlation-based
filtering to eliminate highly correlated predictors. The selected features are
augmented with temporal embeddings, multi-scale lag features, and weather
variables with their corresponding lags as exogenous inputs to the SARIMAX
model. To address data irregularity and numerical instability, we apply
standardization and implement a hierarchical fitting strategy with sequential
optimization methods, automatic downgrading to ARIMA when convergence fails,
and historical mean-based fallback predictions as a final safeguard. The model
is optimized separately for short-term (24 hours) and medium-term (48 hours)
forecast horizons using RMSE as the evaluation metric. Our approach achieves an
RMSE of 177.2, representing an 8.4\% improvement over the baseline method (RMSE
= 193.4), thereby validating the effectiveness of our feature engineering and
robust optimization strategy for extreme weather-related outage prediction.

</details>


### [307] [MedEqualizer: A Framework Investigating Bias in Synthetic Medical Data and Mitigation via Augmentation](https://arxiv.org/abs/2511.01054)
*Sama Salarian,Yue Zhang,Swati Padhee,Srinivasan Parthasarathy*

Main category: cs.LG

TL;DR: 研究评估了基于GAN的合成医疗数据的公平性，发现存在人口统计属性不平衡问题，并提出MedEqualizer框架以改善代表性。


<details>
  <summary>Details</summary>
Motivation: 解决合成医疗数据在保护属性上的公平性问题，避免临床研究和决策中的偏见。

Method: 使用MIMIC-III数据集评估GAN模型的公平性，提出MedEqualizer框架增强少数群体数据。

Result: MedEqualizer显著改善了合成数据的人口统计平衡。

Conclusion: MedEqualizer为更公平的医疗数据合成提供了可行路径。

Abstract: Synthetic healthcare data generation presents a viable approach to enhance
data accessibility and support research by overcoming limitations associated
with real-world medical datasets. However, ensuring fairness across protected
attributes in synthetic data is critical to avoid biased or misleading results
in clinical research and decision-making. In this study, we assess the fairness
of synthetic data generated by multiple generative adversarial network
(GAN)-based models using the MIMIC-III dataset, with a focus on
representativeness across protected demographic attributes. We measure subgroup
representation using the logarithmic disparity metric and observe significant
imbalances, with many subgroups either underrepresented or overrepresented in
the synthetic data, compared to the real data. To mitigate these disparities,
we introduce MedEqualizer, a model-agnostic augmentation framework that
enriches the underrepresented subgroups prior to synthetic data generation. Our
results show that MedEqualizer significantly improves demographic balance in
the resulting synthetic datasets, offering a viable path towards more equitable
and representative healthcare data synthesis.

</details>


### [308] [Window-Based Feature Engineering for Cognitive Workload Detection](https://arxiv.org/abs/2511.01060)
*Andrew Hallam,R G Gayathri,Glory Lee,Atul Sajjanhar*

Main category: cs.LG

TL;DR: 论文研究了基于窗口特征生成和深度学习技术对认知负荷进行分类，结果表明深度学习模型优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 认知负荷在健康、心理学和国防等领域日益重要，需要更有效的分类方法。

Method: 使用COLET数据集，采用窗口时间分割生成特征，结合机器学习和深度学习模型进行分类。

Result: 深度学习模型（尤其是表格架构）在精度、F1分数、准确率和分类精度上优于传统机器学习方法。

Conclusion: 窗口时间特征提取和深度学习技术对实时认知负荷评估具有潜力。

Abstract: Cognitive workload is a topic of increasing interest across various fields
such as health, psychology, and defense applications. In this research, we
focus on classifying cognitive workload using the COLET dataset, employing a
window-based approach for feature generation and machine/deep learning
techniques for classification. We apply window-based temporal partitioning to
enhance features used in existing research, followed by machine learning and
deep learning models to classify different levels of cognitive workload. The
results demonstrate that deep learning models, particularly tabular
architectures, outperformed traditional machine learning methods in precision,
F1-score, accuracy, and classification precision. This study highlights the
effectiveness of window-based temporal feature extraction and the potential of
deep learning techniques for real-time cognitive workload assessment in complex
and dynamic tasks.

</details>


### [309] [Energy-Efficient Deep Learning Without Backpropagation: A Rigorous Evaluation of Forward-Only Algorithms](https://arxiv.org/abs/2511.01061)
*Przemysław Spyra,Witold Dzwinel*

Main category: cs.LG

TL;DR: 本文挑战了反向传播（BP）对高性能的必要性，提出Mono-Forward（MF）算法，在分类准确率、能效和训练速度上均优于BP。


<details>
  <summary>Details</summary>
Motivation: 质疑反向传播是否为高性能的必要条件，探索更高效、可持续的替代方法。

Method: 从Forward-Forward（FF）到Cascaded Forward（CaFo）再到MF的进化路径，采用相同架构和超参数优化进行公平比较。

Result: MF在MLP架构上分类准确率更高，能耗降低41%，训练速度提升34%。

Conclusion: MF是BP的高性能、可持续替代方案，适用于MLP。

Abstract: The long-held assumption that backpropagation (BP) is essential for
state-of-the-art performance is challenged by this work. We present rigorous,
hardware-validated evidence that the Mono-Forward (MF) algorithm, a
backpropagation-free method, consistently surpasses an optimally tuned BP
baseline in classification accuracy on its native Multi-Layer Perceptron (MLP)
architectures. This superior generalization is achieved with profound
efficiency gains, including up to 41% less energy consumption and up to 34%
faster training. Our analysis, which charts an evolutionary path from Geoffrey
Hinton's Forward-Forward (FF) to the Cascaded Forward (CaFo) and finally to MF,
is grounded in a fair comparative framework using identical architectures and
universal hyperparameter optimization. We further provide a critical
re-evaluation of memory efficiency in BP-free methods, empirically
demonstrating that practical overhead can offset theoretical gains. Ultimately,
this work establishes MF as a practical, high-performance, and sustainable
alternative to BP for MLPs.

</details>


### [310] [Happiness as a Measure of Fairness](https://arxiv.org/abs/2511.01069)
*Georg Pichler,Marco Romanelli,Pablo Piantanida*

Main category: cs.LG

TL;DR: 提出了一种基于幸福感的公平性框架，通过线性规划实现高效且可扩展的公平决策。


<details>
  <summary>Details</summary>
Motivation: 传统公平性定义缺乏直观性，本文提出以幸福感为衡量标准，更贴近人类需求。

Method: 使用线性规划计算最优的公平后处理策略，方法高效且可扩展。

Result: 框架统一并扩展了多种公平性定义，实验验证了其在不同场景中的实用性。

Conclusion: 基于幸福感的公平性框架兼具直观性和数学严谨性，适用于多样化应用场景。

Abstract: In this paper, we propose a novel fairness framework grounded in the concept
of happi- ness, a measure of the utility each group gains fromdecisionoutcomes.
Bycapturingfairness through this intuitive lens, we not only offer a more
human-centered approach, but also one that is mathematically rigorous: In order
to compute the optimal, fair post-processing strategy, only a linear program
needs to be solved. This makes our method both efficient and scalable with
existing optimization tools. Furthermore, it unifies and extends several
well-known fairness definitions, and our em- pirical results highlight its
practical strengths across diverse scenarios.

</details>


### [311] [AI Progress Should Be Measured by Capability-Per-Resource, Not Scale Alone: A Framework for Gradient-Guided Resource Allocation in LLMs](https://arxiv.org/abs/2511.01077)
*David McCoy,Yulun Wu,Zachary Butzin-Dozier*

Main category: cs.LG

TL;DR: 论文挑战了AI研究中的‘规模至上主义’，提出以资源效率为导向的LLM开发框架，通过梯度影响模式优化资源分配，显著提升效率。


<details>
  <summary>Details</summary>
Motivation: 当前AI研究中模型规模和计算资源的无限增长导致环境问题和资源不平等，需要重新定位LLM开发方向。

Method: 提出基于梯度影响模式的资源分配理论框架，通过更新高影响参数、梯度范数代理和协调参数数据选择提升效率。

Result: 理论分析表明，该方法可大幅减少资源需求，提升性能与资源比。

Conclusion: 通过资源意识重塑AI发展，实现可持续和公平的未来。

Abstract: This position paper challenges the "scaling fundamentalism" dominating AI
research, where unbounded growth in model size and computation has led to
unsustainable environmental impacts and widening resource inequality. We argue
that LLM development should be fundamentally reoriented toward
capability-per-resource rather than capability alone. We present a theoretical
framework demonstrating that resource-allocation decisions guided by gradient
influence patterns can dramatically improve efficiency throughout the AI
lifecycle. Our analysis shows that in transformer-based models, where a small
fraction of parameters exert outsized influence (following heavy-tailed
distributions), three critical insights emerge: (1) updating only
high-influence parameters strictly outperforms full-parameter tuning on a
performance-per-resource basis; (2) simple gradient norms provide
computationally efficient proxies for identifying these high-influence
components; and (3) coordinated parameter and data selection yields
multiplicative efficiency gains, potentially reducing resource requirements by
orders of magnitude. Building on these theoretical foundations, we propose a
two stage paradigm marginal-return pretraining for foundation developers and
influence guided adaptation for downstream users bridged by gradient
blueprints, metadata describing which parameters matter most for various tasks.
This capability-per-resource perspective transforms what were once considered
pragmatic hardware workarounds into theoretically optimal strategies,
democratizing access to cutting-edge AI capabilities while significantly
reducing environmental impact. By embedding resource consciousness into how we
develop, adapt, and evaluate models, we can reshape AI progress toward a more
sustainable and equitable future.

</details>


### [312] [Continual Learning, Not Training: Online Adaptation For Agents](https://arxiv.org/abs/2511.01093)
*Aman Jaglan,Jarrod Barnes*

Main category: cs.LG

TL;DR: ATLAS提出了一种梯度无关的持续学习方法，通过双代理架构（教师-学生）和持久学习记忆实现动态调整策略，在推理时优化任务成功率和计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统持续学习方法依赖梯度重训练，不适用于实时部署的智能体。ATLAS旨在通过系统级编排实现梯度无关的持续学习。

Method: 采用双代理架构（教师负责推理，学生负责执行）和持久学习记忆，动态调整监督级别和初始计划选择。

Result: 在ExCyTIn-Bench上，ATLAS以GPT-5-mini作为学生模型，任务成功率54.1%，比GPT-5（High）高13%，成本降低86%。

Conclusion: ATLAS证明了梯度无关持续学习的可行性，为可部署AI系统提供了新方向，并生成了可用于训练显式世界模型的因果注释轨迹。

Abstract: Continual Learning (CL) methods have traditionally focused on mitigating
catastrophic forgetting through gradient-based retraining, an approach
ill-suited for deployed agents that must adapt in real time. We introduce our
Adaptive Teaching and Learning System (ATLAS), a dual-agent architecture that
decouples reasoning (Teacher) from execution (Student) and incorporates a
persistent learning memory that stores distilled guidance from experience. This
informs the orchestration layer, enabling the system to dynamically adjust its
operational strategies, such as supervision level or initial plan selection, at
inference time. In doing so, ATLAS achieves gradient-free continual learning,
shifting the locus of adaptation from model parameters to system-level
orchestration. We formulate this as a system-centric paradigm for continual
learning, where the objective is adaptive efficiency: maximizing task success
while minimizing computational cost through inference-time orchestration rather
than parameter updates. Evaluated on Microsoft's ExCyTIn-Bench, an open-source
benchmark simulating complex cyberthreat investigation, ATLAS achieves 54.1%
success with GPT-5-mini as its Student, outperforming the larger GPT-5 (High)
by 13% while reducing cost by 86%. Cross-incident validation demonstrates
generalization: frozen pamphlets from Incident #5 improve accuracy from 28% to
41% with zero retraining, while shifting output composition from verbose
exploration to structured reasoning. Together, these findings establish
gradient-free continual learning as a viable path toward adaptive, deployable
AI systems and provide causally annotated traces valuable for training explicit
world models.

</details>


### [313] [One model to solve them all: 2BSDE families via neural operators](https://arxiv.org/abs/2511.01125)
*Takashi Furuya,Anastasis Kratsios,Dylan Possamaï,Bogdan Raonić*

Main category: cs.LG

TL;DR: 提出了一种基于Kolmogorov-Arnold网络的神经算子模型，用于解决随机终止时间的二阶倒向随机微分方程（2BSDEs）家族。


<details>
  <summary>Details</summary>
Motivation: 解决无限家族2BSDEs的挑战，并探索神经算子在近似解算子中的潜力。

Method: 利用Kolmogorov-Arnold网络构建神经算子模型，针对有界欧几里得域上的2BSDEs进行求解。

Result: 证明神经算子可以近似广泛2BSDEs的解算子，并发现一类结构化子问题仅需多项式参数即可实现高效近似。

Conclusion: 神经算子在特定2BSDEs家族中表现出高效近似能力，突破了传统最坏情况下指数参数需求的限制。

Abstract: We introduce a mild generative variant of the classical neural operator
model, which leverages Kolmogorov--Arnold networks to solve infinite families
of second-order backward stochastic differential equations ($2$BSDEs) on
regular bounded Euclidean domains with random terminal time. Our first main
result shows that the solution operator associated with a broad range of
$2$BSDE families is approximable by appropriate neural operator models. We then
identify a structured subclass of (infinite) families of $2$BSDEs whose neural
operator approximation requires only a polynomial number of parameters in the
reciprocal approximation rate, as opposed to the exponential requirement in
general worst-case neural operator guarantees.

</details>


### [314] [Stochastic Regret Guarantees for Online Zeroth- and First-Order Bilevel Optimization](https://arxiv.org/abs/2511.01126)
*Parvin Nazari,Bojian Hou,Davoud Ataee Tarzanagh,Li Shen,George Michailidis*

Main category: cs.LG

TL;DR: 提出了一种新的搜索方向，用于在线双层优化（OBO），无需窗口平滑即可实现亚线性随机双层遗憾。


<details>
  <summary>Details</summary>
Motivation: 现有OBO方法依赖确定性窗口平滑遗憾最小化，在函数快速变化时可能无法准确反映系统性能。

Method: 引入新的搜索方向，结合一阶和零阶随机OBO算法，优化超梯度估计、变量更新和线性系统求解。

Result: 实验验证了在在线参数损失调优和黑盒对抗攻击中的有效性。

Conclusion: 新框架提高了效率，减少了超梯度估计的依赖，并实现了亚线性随机双层遗憾。

Abstract: Online bilevel optimization (OBO) is a powerful framework for machine
learning problems where both outer and inner objectives evolve over time,
requiring dynamic updates. Current OBO approaches rely on deterministic
\textit{window-smoothed} regret minimization, which may not accurately reflect
system performance when functions change rapidly. In this work, we introduce a
novel search direction and show that both first- and zeroth-order (ZO)
stochastic OBO algorithms leveraging this direction achieve sublinear
{stochastic bilevel regret without window smoothing}. Beyond these guarantees,
our framework enhances efficiency by: (i) reducing oracle dependence in
hypergradient estimation, (ii) updating inner and outer variables alongside the
linear system solution, and (iii) employing ZO-based estimation of Hessians,
Jacobians, and gradients. Experiments on online parametric loss tuning and
black-box adversarial attacks validate our approach.

</details>


### [315] [Regularization Implies balancedness in the deep linear network](https://arxiv.org/abs/2511.01137)
*Kathryn Lindsey,Govind Menon*

Main category: cs.LG

TL;DR: 论文利用几何不变量理论（GIT）研究深度线性网络（DLN），通过Kempf-Ness定理证明$L^2$正则化器在平衡流形上最小化，并将训练动态分解为两个梯度流。


<details>
  <summary>Details</summary>
Motivation: 为深度学习和线性系统理论中的平衡性提供一个统一的数学框架。

Method: 使用几何不变量理论和Kempf-Ness定理，将训练动态分解为梯度流，并利用矩映射求解正则化流。

Result: 证明了$L^2$正则化器在平衡流形上最小化，并提供了平衡性在模型简化和贝叶斯原理中的解释。

Conclusion: 该方法为平衡性研究提供了新的数学工具和理论支持。

Abstract: We use geometric invariant theory (GIT) to study the deep linear network
(DLN). The Kempf-Ness theorem is used to establish that the $L^2$ regularizer
is minimized on the balanced manifold. This allows us to decompose the training
dynamics into two distinct gradient flows: a regularizing flow on fibers and a
learning flow on the balanced manifold. We show that the regularizing flow is
exactly solvable using the moment map.
  This approach provides a common mathematical framework for balancedness in
deep learning and linear systems theory. We use this framework to interpret
balancedness in terms of model reduction and Bayesian principles.

</details>


### [316] [Adapt under Attack and Domain Shift: Unified Adversarial Meta-Learning and Domain Adaptation for Robust Automatic Modulation Classification](https://arxiv.org/abs/2511.01172)
*Ali Owfi,Amirmohammad Bamdad,Tolunay Seyfi,Fatemeh Afghah*

Main category: cs.LG

TL;DR: 提出了一种结合元学习和领域适应的统一框架，提升自动调制分类（AMC）系统对抗对抗攻击和环境变化的能力。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习在AMC中易受对抗攻击和数据分布变化影响的问题，以提升实际部署的鲁棒性。

Method: 采用两阶段策略：离线阶段通过元学习训练模型防御多种攻击；在线阶段通过领域适应适应新环境。

Result: 显著提升了调制分类的准确性，解决了AMC系统的部署和操作挑战。

Conclusion: 该框架为AMC系统在动态环境中的实际应用提供了有效解决方案。

Abstract: Deep learning has emerged as a leading approach for Automatic Modulation
Classification (AMC), demonstrating superior performance over traditional
methods. However, vulnerability to adversarial attacks and susceptibility to
data distribution shifts hinder their practical deployment in real-world,
dynamic environments. To address these threats, we propose a novel, unified
framework that integrates meta-learning with domain adaptation, making AMC
systems resistant to both adversarial attacks and environmental changes. Our
framework utilizes a two-phase strategy. First, in an offline phase, we employ
a meta-learning approach to train the model on clean and adversarially
perturbed samples from a single source domain. This method enables the model to
generalize its defense, making it resistant to a combination of previously
unseen attacks. Subsequently, in the online phase, we apply domain adaptation
to align the model's features with a new target domain, allowing it to adapt
without requiring substantial labeled data. As a result, our framework achieves
a significant improvement in modulation classification accuracy against these
combined threats, offering a critical solution to the deployment and
operational challenges of modern AMC systems.

</details>


### [317] [A Comparative Study of Model Adaptation Strategies for Multi-Treatment Uplift Modeling](https://arxiv.org/abs/2511.01185)
*Ruyue Zhang,Xiaopeng Ke,Ming Liu,Fangzhou Shi,Chang Men,Zhengdan Zhu*

Main category: cs.LG

TL;DR: 本文提出了一种基于函数逼近定理的正交函数适应（OFA）方法，用于提升多治疗场景下的提升模型性能，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多治疗场景下的提升建模在现实应用中至关重要，但现有方法通常从二元治疗工作改编而来，无法在各种数据特性下保持有效性。

Method: 提出正交函数适应（OFA），基于函数逼近定理，增强估计能力和鲁棒性。

Result: 实验表明，OFA显著优于其他改编方法，并表现出最高的鲁棒性。

Conclusion: OFA是一种有效的多治疗提升建模方法，适用于复杂数据场景。

Abstract: Uplift modeling has emerged as a crucial technique for individualized
treatment effect estimation, particularly in fields such as marketing and
healthcare. Modeling uplift effects in multi-treatment scenarios plays a key
role in real-world applications. Current techniques for modeling
multi-treatment uplift are typically adapted from binary-treatment works. In
this paper, we investigate and categorize all current model adaptations into
two types: Structure Adaptation and Feature Adaptation. Through our empirical
experiments, we find that these two adaptation types cannot maintain
effectiveness under various data characteristics (noisy data, mixed with
observational data, etc.). To enhance estimation ability and robustness, we
propose Orthogonal Function Adaptation (OFA) based on the function
approximation theorem. We conduct comprehensive experiments with multiple data
characteristics to study the effectiveness and robustness of all model
adaptation techniques. Our experimental results demonstrate that our proposed
OFA can significantly improve uplift model performance compared to other
vanilla adaptation methods and exhibits the highest robustness.

</details>


### [318] [Analyzing the Power of Chain of Thought through Memorization Capabilities](https://arxiv.org/abs/2511.01190)
*Lijia Yu,Xiao-Shan Gao,Lijun Zhang*

Main category: cs.LG

TL;DR: 研究表明，思维链（CoT）能增强大语言模型（LLMs）解决数学推理问题的能力，但其能力范围尚未完全探索。本文证明，CoT并非在所有推理任务中都能提升Transformer的能力。


<details>
  <summary>Details</summary>
Motivation: 探索思维链（CoT）是否在所有推理任务中都能扩展Transformer的能力，并分析其记忆能力。

Method: 通过分析固定精度Transformer（带或不带CoT）的记忆能力，给出必要和充分条件，并计算参数数量的上下界。

Result: 证明CoT并非在所有推理任务中都能提升Transformer的能力，并给出无限推理数据集记忆的首个结果。

Conclusion: CoT不能在所有推理任务中增强Transformer的能力，且某些无限数据集无法被记忆。

Abstract: It has been shown that the chain of thought (CoT) can enhance the power of
large language models (LLMs) to solve certain mathematical reasoning problems.
However, the capacity of CoT is still not fully explored. As an important
instance, the following basic question has not yet been answered: Does CoT
expand the capability of transformers across all reasoning tasks? We
demonstrate that reasoning with transformers is essentially a memorization
problem for reasoning datasets. Thus, examining the power of CoT across all
reasoning tasks amounts to analyzing the memorization capabilities of CoT
transformers. In this paper, we give a complete description of the memorization
capabilities of fixed-precision transformers with or without CoT and give a
negative answer to the above-mentioned question. Precisely, we first give
necessary and sufficient conditions for fixed-precision transformers with and
without CoT to memorize a finite reasoning dataset and show that these two
conditions do not imply each other. Then, we give lower and upper bounds for
the number of parameters needed for transformers with or without CoT to
memorize a finite reasoning dataset with $N$ elements, which are
$\overline{\Theta}(N)$ in all cases. This implies that there exist reasoning
tasks for which CoT does not enhance the reasoning power of transformers,
leading to a negative answer to the above-mentioned question. Finally, we give
the first results on memorizing infinite reasoning datasets by CoT transformers
and show that some simple infinite datasets cannot be memorized by transformers
with or without CoT.

</details>


### [319] [Transmitter Identification and Protocol Categorization in Shared Spectrum via Multi-Task RF Classification at the Network Edge](https://arxiv.org/abs/2511.01198)
*Tariq Abdul-Quddoos,Tasnia Sharmin,Xiangfang Li,Lijun Qian*

Main category: cs.LG

TL;DR: 提出了一种基于多任务RF信号分类的框架，用于共享频谱环境中的发射机识别和协议分类，取得了高准确率。


<details>
  <summary>Details</summary>
Motivation: 频谱共享需求增加，频谱监测和发射机识别对政策执行、高效利用和网络安全至关重要。

Method: 设计了一个卷积神经网络（CNN），采用多通道输入策略处理信号重叠和环境变化。

Result: 协议分类准确率90%，基站分类100%，联合分类92%。

Conclusion: 该方法在频谱监测、管理和安全方面具有显著潜力。

Abstract: As spectrum sharing becomes increasingly vital to meet rising wireless
demands in the future, spectrum monitoring and transmitter identification are
indispensable for enforcing spectrum usage policy, efficient spectrum
utilization, and net- work security. This study proposed a robust framework for
transmitter identification and protocol categorization via multi- task RF
signal classification in shared spectrum environments, where the spectrum
monitor will classify transmission protocols (e.g., 4G LTE, 5G-NR, IEEE
802.11a) operating within the same frequency bands, and identify different
transmitting base stations, as well as their combinations. A Convolutional
Neural Network (CNN) is designed to tackle critical challenges such as
overlapping signal characteristics and environmental variability. The proposed
method employs a multi-channel input strategy to extract meaningful signal
features, achieving remarkable accuracy: 90% for protocol classification, 100%
for transmitting base station classification, and 92% for joint classification
tasks, utilizing RF data from the POWDER platform. These results highlight the
significant potential of the proposed method to enhance spectrum monitoring,
management, and security in modern wireless networks.

</details>


### [320] [FEval-TTC: Fair Evaluation Protocol for Test-Time Compute](https://arxiv.org/abs/2511.01203)
*Pavel Rumiantsev,Soumyasundar Pal,Yingxue Zhang,Mark Coates*

Main category: cs.LG

TL;DR: 提出了FEval-TTC协议，用于在LLM性能波动时公平评估测试时计算（TTC）方法。


<details>
  <summary>Details</summary>
Motivation: 解决LLM性能波动导致的研究结论失效问题。

Method: 设计标准化评估协议，支持多LLM在数学和常识推理数据集上的评估，并标准化提示和答案提取流程。

Result: 提供成本建模工具，估计每次查询的token和美元成本，开源协议供公众使用。

Conclusion: FEval-TTC为TTC方法提供了公平、一致的评估框架，降低研究成本。

Abstract: The performance of Large Language Models (LLMs) and the associated dollar
costs of API calls can fluctuate over time, potentially invalidating
conclusions drawn in prior research. To address this, we propose a Fair
Evaluation protocol for Test-Time Compute (FEval-TTC), designed to ensure
consistent assessment of test-time compute (TTC) methods, regardless of such
fluctuations. FEval-TTC focuses on the evaluation of TTC methods that utilize
underlying Chains-of-Thought (CoT). It supports evaluations across multiple
LLMs on a diverse set of mathematical and commonsense reasoning datasets. The
few-shot prompting and answer extraction processes are standardized across
datasets, reducing both time and monetary overhead for researchers.
Furthermore, we provide a cost modelling procedure that estimates both the
token and dollar cost per query, facilitating equitable comparisons of
prevalent TTC methods. We open-source FEval-TTC for public use at
https://github.com/networkslab/feval_ttc .

</details>


### [321] [Optimizing Electric Vehicle Charging Station Placement Using Reinforcement Learning and Agent-Based Simulations](https://arxiv.org/abs/2511.01218)
*Minh-Duc Nguyen,Dung D. Le,Phi Long Nguyen*

Main category: cs.LG

TL;DR: 提出了一种结合深度强化学习和基于代理模拟的新框架，用于优化电动汽车充电站布局，显著减少等待时间。


<details>
  <summary>Details</summary>
Motivation: 现有确定性奖励方法无法应对动态和不确定的现实条件，导致效率低下和评估成本高。

Method: 采用混合强化学习代理和双Q网络，结合确定性因素和模拟反馈的混合奖励函数。

Result: 在河内的案例研究中，平均等待时间减少了53.28%，优于静态基线方法。

Conclusion: 该方案可扩展且适应性强，有效提升电动汽车基础设施规划，改善用户体验。

Abstract: The rapid growth of electric vehicles (EVs) necessitates the strategic
placement of charging stations to optimize resource utilization and minimize
user inconvenience. Reinforcement learning (RL) offers an innovative approach
to identifying optimal charging station locations; however, existing methods
face challenges due to their deterministic reward systems, which limit
efficiency. Because real-world conditions are dynamic and uncertain, a
deterministic reward structure cannot fully capture the complexities of
charging station placement. As a result, evaluation becomes costly and
time-consuming, and less reflective of real-world scenarios. To address this
challenge, we propose a novel framework that integrates deep RL with
agent-based simulations to model EV movement and estimate charging demand in
real time. Our approach employs a hybrid RL agent with dual Q-networks to
select optimal locations and configure charging ports, guided by a hybrid
reward function that combines deterministic factors with simulation-derived
feedback. Case studies in Hanoi, Vietnam, show that our method reduces average
waiting times by 53.28% compared to the initial state, outperforming static
baseline methods. This scalable and adaptive solution enhances EV
infrastructure planning, effectively addressing real-world complexities and
improving user experience.

</details>


### [322] [WindMiL: Equivariant Graph Learning for Wind Loading Prediction](https://arxiv.org/abs/2511.01226)
*Themistoklis Vargiemezis,Charilaos Kanatsoulis,Catherine Gorlé*

Main category: cs.LG

TL;DR: WindMiL是一个结合系统性数据集生成和对称感知图神经网络的机器学习框架，用于高效、可扩展且准确地预测建筑物风荷载。


<details>
  <summary>Details</summary>
Motivation: 传统方法（如风洞测试和大涡模拟）成本高昂且耗时，难以进行大规模参数研究。

Method: 通过符号距离函数插值生成屋顶几何形状的大规模数据集，并开发反射等变图神经网络（GNN）保证物理一致性预测。

Result: WindMiL在均值和标准差预测上表现高精度（如均方根误差≤0.02），且在反射测试中保持96%以上的命中率。

Conclusion: WindMiL为建筑物风荷载预测提供了一种高效、可扩展且准确的替代方案。

Abstract: Accurate prediction of wind loading on buildings is crucial for structural
safety and sustainable design, yet conventional approaches such as wind tunnel
testing and large-eddy simulation (LES) are prohibitively expensive for
large-scale exploration. Each LES case typically requires at least 24 hours of
computation, making comprehensive parametric studies infeasible. We introduce
WindMiL, a new machine learning framework that combines systematic dataset
generation with symmetry-aware graph neural networks (GNNs). First, we
introduce a large-scale dataset of wind loads on low-rise buildings by applying
signed distance function interpolation to roof geometries and simulating 462
cases with LES across varying shapes and wind directions. Second, we develop a
reflection-equivariant GNN that guarantees physically consistent predictions
under mirrored geometries. Across interpolation and extrapolation evaluations,
WindMiL achieves high accuracy for both the mean and the standard deviation of
surface pressure coefficients (e.g., RMSE $\leq 0.02$ for mean $C_p$) and
remains accurate under reflected-test evaluation, maintaining hit rates above
$96\%$ where the non-equivariant baseline model drops by more than $10\%$. By
pairing a systematic dataset with an equivariant surrogate, WindMiL enables
efficient, scalable, and accurate predictions of wind loads on buildings.

</details>


### [323] [A Saddle Point Remedy: Power of Variable Elimination in Non-convex Optimization](https://arxiv.org/abs/2511.01234)
*Min Gan,Guang-Yong Chen,Yang Yi,Lin Yang*

Main category: cs.LG

TL;DR: 论文解释了变量消除算法（如VarPro）如何通过改变优化问题的临界点结构，有效避免鞍点问题，从而提升非凸优化的收敛性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 理解变量消除算法在实践中表现优越的原因，尤其是其如何应对非凸优化中的鞍点问题。

Method: 通过Hessian惯性和Schur补的严格分析，比较原始和简化公式的优化景观，揭示临界点结构的转变。

Result: 证明变量消除将原始问题中的鞍点转化为简化问题中的局部最大值，显著提升了深度残差网络的稳定性和收敛性。

Conclusion: 研究不仅解释了现有方法的有效性，还提出了通过鞍点变换简化优化景观的新原则，为设计更鲁棒的优化算法提供了理论基础。

Abstract: The proliferation of saddle points, rather than poor local minima, is
increasingly understood to be a primary obstacle in large-scale non-convex
optimization for machine learning. Variable elimination algorithms, like
Variable Projection (VarPro), have long been observed to exhibit superior
convergence and robustness in practice, yet a principled understanding of why
they so effectively navigate these complex energy landscapes has remained
elusive. In this work, we provide a rigorous geometric explanation by comparing
the optimization landscapes of the original and reduced formulations. Through a
rigorous analysis based on Hessian inertia and the Schur complement, we prove
that variable elimination fundamentally reshapes the critical point structure
of the objective function, revealing that local maxima in the reduced landscape
are created from, and correspond directly to, saddle points in the original
formulation. Our findings are illustrated on the canonical problem of
non-convex matrix factorization, visualized directly on two-parameter neural
networks, and finally validated in training deep Residual Networks, where our
approach yields dramatic improvements in stability and convergence to superior
minima. This work goes beyond explaining an existing method; it establishes
landscape simplification via saddle point transformation as a powerful
principle that can guide the design of a new generation of more robust and
efficient optimization algorithms.

</details>


### [324] [KAT-GNN: A Knowledge-Augmented Temporal Graph Neural Network for Risk Prediction in Electronic Health Records](https://arxiv.org/abs/2511.01249)
*Kun-Wei Lin,Yu-Chen Kuo,Hsin-Yao Wang,Yi-Ju Tseng*

Main category: cs.LG

TL;DR: KAT-GNN是一种基于图神经网络的框架，结合临床知识和时间动态，用于电子健康记录（EHR）的风险预测，性能优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录（EHR）数据具有异构性和不规则性，建模困难，需要一种能够整合临床知识和时间动态的方法。

Method: 构建患者特定模态图，通过SNOMED CT和EHR共现先验知识增强，使用时间感知Transformer捕捉纵向动态。

Result: 在CAD预测（AUROC: 0.9269）和死亡率预测（MIMIC-III: 0.9230, MIMIC-IV: 0.8849）中表现优异。

Conclusion: 结合临床知识和时间感知机制的图表示方法，为多样化的临床任务提供了有效且通用的风险预测方案。

Abstract: Clinical risk prediction using electronic health records (EHRs) is vital to
facilitate timely interventions and clinical decision support. However,
modeling heterogeneous and irregular temporal EHR data presents significant
challenges. We propose \textbf{KAT-GNN} (Knowledge-Augmented Temporal Graph
Neural Network), a graph-based framework that integrates clinical knowledge and
temporal dynamics for risk prediction. KAT-GNN first constructs
modality-specific patient graphs from EHRs. These graphs are then augmented
using two knowledge sources: (1) ontology-driven edges derived from SNOMED CT
and (2) co-occurrence priors extracted from EHRs. Subsequently, a time-aware
transformer is employed to capture longitudinal dynamics from the graph-encoded
patient representations. KAT-GNN is evaluated on three distinct datasets and
tasks: coronary artery disease (CAD) prediction using the Chang Gung Research
Database (CGRD) and in-hospital mortality prediction using the MIMIC-III and
MIMIC-IV datasets. KAT-GNN achieves state-of-the-art performance in CAD
prediction (AUROC: 0.9269 $\pm$ 0.0029) and demonstrated strong results in
mortality prediction in MIMIC-III (AUROC: 0.9230 $\pm$ 0.0070) and MIMIC-IV
(AUROC: 0.8849 $\pm$ 0.0089), consistently outperforming established baselines
such as GRASP and RETAIN. Ablation studies confirm that both knowledge-based
augmentation and the temporal modeling component are significant contributors
to performance gains. These findings demonstrate that the integration of
clinical knowledge into graph representations, coupled with a time-aware
attention mechanism, provides an effective and generalizable approach for risk
prediction across diverse clinical tasks and datasets.

</details>


### [325] [A Spatio-Temporal Online Robust Tensor Recovery Approach for Streaming Traffic Data Imputation](https://arxiv.org/abs/2511.01267)
*Yiyang Yang,Xiejian Chi,Shanxing Gao,Kaidong Wang,Yao Wang*

Main category: cs.LG

TL;DR: 提出了一种新的在线鲁棒张量恢复算法，用于提升智能交通系统中的数据质量，显著提高了计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统批量处理方法在计算和存储资源上需求高，且现有在线方法在复杂场景中性能下降，无法充分利用交通数据的固有结构特性。

Method: 在流式框架下重新定义交通数据恢复问题，提出一种同时利用全局时空相关性和局部一致性的在线鲁棒张量恢复算法。

Result: 在三个真实交通数据集上的实验表明，该方法恢复精度高，计算效率比现有批量方法提升高达三个数量级。

Conclusion: 该方法为智能交通系统中的数据质量提升提供了可扩展且高效的解决方案。

Abstract: Data quality is critical to Intelligent Transportation Systems (ITS), as
complete and accurate traffic data underpin reliable decision-making in traffic
control and management. Recent advances in low-rank tensor recovery algorithms
have shown strong potential in capturing the inherent structure of
high-dimensional traffic data and restoring degraded observations. However,
traditional batch-based methods demand substantial computational and storage
resources, which limits their scalability in the face of continuously expanding
traffic data volumes. Moreover, recent online tensor recovery methods often
suffer from severe performance degradation in complex real-world scenarios due
to their insufficient exploitation of the intrinsic structural properties of
traffic data. To address these challenges, we reformulate the traffic data
recovery problem within a streaming framework, and propose a novel online
robust tensor recovery algorithm that simultaneously leverages both the global
spatio-temporal correlations and local consistency of traffic data, achieving
high recovery accuracy and significantly improved computational efficiency in
large-scale scenarios. Our method is capable of simultaneously handling missing
and anomalous values in traffic data, and demonstrates strong adaptability
across diverse missing patterns. Experimental results on three real-world
traffic datasets demonstrate that the proposed approach achieves high recovery
accuracy while significantly improving computational efficiency by up to three
orders of magnitude compared to state-of-the-art batch-based methods. These
findings highlight the potential of the proposed approach as a scalable and
effective solution for traffic data quality enhancement in ITS.

</details>


### [326] [Adversarial Spatio-Temporal Attention Networks for Epileptic Seizure Forecasting](https://arxiv.org/abs/2511.01275)
*Zan Li,Kyongmin Yeo,Wesley Gifford,Lara Marcuse,Madeline Fields,Bülent Yener*

Main category: cs.LG

TL;DR: STAN是一种对抗性时空注意力网络，用于从多变量EEG信号中预测癫痫发作，具有高灵敏度和低误报率。


<details>
  <summary>Details</summary>
Motivation: 预测癫痫发作对医疗时间序列预测至关重要，需要高灵敏度、低误报率和个体适应性。

Method: STAN通过级联注意力块交替处理空间和时间模块，联合建模空间脑连接和时间神经动态。

Result: 在两个基准EEG数据集上表现优异：灵敏度96.6%和94.2%，误报率分别为0.011和0.063次/小时。

Conclusion: STAN为医疗和其他时间序列领域提供了一种通用的时空预测框架。

Abstract: Forecasting epileptic seizures from multivariate EEG signals represents a
critical challenge in healthcare time series prediction, requiring high
sensitivity, low false alarm rates, and subject-specific adaptability. We
present STAN, an Adversarial Spatio-Temporal Attention Network that jointly
models spatial brain connectivity and temporal neural dynamics through cascaded
attention blocks with alternating spatial and temporal modules. Unlike existing
approaches that assume fixed preictal durations or separately process spatial
and temporal features, STAN captures bidirectional dependencies between spatial
and temporal patterns through a unified cascaded architecture. Adversarial
training with gradient penalty enables robust discrimination between interictal
and preictal states learned from clearly defined 15-minute preictal windows.
Continuous 90-minute pre-seizure monitoring reveals that the learned
spatio-temporal attention patterns enable early detection: reliable alarms
trigger at subject-specific times (typically 15-45 minutes before onset),
reflecting the model's capacity to capture subtle preictal dynamics without
requiring individualized training. Experiments on two benchmark EEG datasets
(CHB-MIT scalp: 8 subjects, 46 events; MSSM intracranial: 4 subjects, 14
events) demonstrate state-of-the-art performance: 96.6% sensitivity with 0.011
false detections per hour and 94.2% sensitivity with 0.063 false detections per
hour, respectively, while maintaining computational efficiency (2.3M
parameters, 45 ms latency, 180 MB memory) for real-time edge deployment. Beyond
epilepsy, the proposed framework provides a general paradigm for
spatio-temporal forecasting in healthcare and other time series domains where
individual heterogeneity and interpretability are crucial.

</details>


### [327] [Identification of Capture Phases in Nanopore Protein Sequencing Data Using a Deep Learning Model](https://arxiv.org/abs/2511.01277)
*Annabelle Martin,Daphne Kontogiorgos-Heintz,Jeff Nivala*

Main category: cs.LG

TL;DR: 开发了一种轻量级1D CNN模型CaptureNet-Deep，用于实时检测纳米孔蛋白测序中的捕获阶段，显著减少分析时间。


<details>
  <summary>Details</summary>
Motivation: 手动识别纳米孔蛋白测序中的捕获阶段耗时且需要专业知识，亟需自动化解决方案。

Method: 使用1D CNN模型处理降采样的信号窗口，并与CNN-LSTM混合模型和直方图分类器进行比较。

Result: CaptureNet-Deep在测试数据上达到F1分数0.94和精度93.39%，分析时间从几天缩短至30分钟。

Conclusion: 轻量级ML模型可实现高效实时捕获检测，并有望在测序流程中发挥更广泛作用。

Abstract: Nanopore protein sequencing produces long, noisy ionic current traces in
which key molecular phases, such as protein capture and translocation, are
embedded. Capture phases mark the successful entry of a protein into the pore
and serve as both a checkpoint and a signal that a channel merits further
analysis. However, manual identification of capture phases is time-intensive,
often requiring several days for expert reviewers to annotate the data due to
the need for domain-specific interpretation of complex signal patterns. To
address this, a lightweight one-dimensional convolutional neural network (1D
CNN) was developed and trained to detect capture phases in down-sampled signal
windows. Evaluated against CNN-LSTM (Long Short-Term Memory) hybrids,
histogram-based classifiers, and other CNN variants using run-level data
splits, our best model, CaptureNet-Deep, achieved an F1 score of 0.94 and
precision of 93.39% on held-out test data. The model supports low-latency
inference and is integrated into a dashboard for Oxford Nanopore experiments,
reducing the total analysis time from several days to under thirty minutes.
These results show that efficient, real-time capture detection is possible
using simple, interpretable architectures and suggest a broader role for
lightweight ML models in sequencing workflows.

</details>


### [328] [Koopman-based Prediction of Connectivity for Flying Ad Hoc Networks](https://arxiv.org/abs/2511.01286)
*Sivaram Krishnan,Jinho Choi,Jihong Park,Gregory Sherman,Benjamin Campbell*

Main category: cs.LG

TL;DR: 论文探讨了在动态飞行自组网（FANETs）中应用数据驱动的Koopman方法，以提升网络性能和预测准确性。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习方法在静态无线环境中表现良好，但在动态环境（如FANETs）中受限，需新方法应对挑战。

Method: 提出基于Koopman算子理论的集中式和分布式方法，用于建模无人机轨迹动态和预测SINR。

Result: 实验表明，这些方法能准确预测连接和隔离事件，从而避免通信中断。

Conclusion: Koopman方法为动态FANETs提供了有效的预测工具，有助于优化无人机通信调度。

Abstract: The application of machine learning (ML) to communication systems is expected
to play a pivotal role in future artificial intelligence (AI)-based
next-generation wireless networks. While most existing works focus on ML
techniques for static wireless environments, they often face limitations when
applied to highly dynamic environments, such as flying ad hoc networks
(FANETs). This paper explores the use of data-driven Koopman approaches to
address these challenges. Specifically, we investigate how these approaches can
model UAV trajectory dynamics within FANETs, enabling more accurate predictions
and improved network performance. By leveraging Koopman operator theory, we
propose two possible approaches -- centralized and distributed -- to
efficiently address the challenges posed by the constantly changing topology of
FANETs. To demonstrate this, we consider a FANET performing surveillance with
UAVs following pre-determined trajectories and predict
signal-to-interference-plus-noise ratios (SINRs) to ensure reliable
communication between UAVs. Our results show that these approaches can
accurately predict connectivity and isolation events that lead to modelled
communication outages. This capability could help UAVs schedule their
transmissions based on these predictions.

</details>


### [329] [LSHFed: Robust and Communication-Efficient Federated Learning with Locally-Sensitive Hashing Gradient Mapping](https://arxiv.org/abs/2511.01296)
*Guanjie Cheng,Mengzhen Yang,Xinkui Zhao,Shuyi Yu,Tianyu Du,Yangyang Wu,Mengying Zhu,Shuiguang Deng*

Main category: cs.LG

TL;DR: LSHFed是一个高效且鲁棒的联邦学习框架，通过LSHGM机制检测恶意梯度，显著降低通信开销并保护隐私。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在信任缺失环境中易受推理和投毒攻击，现有防御方法成本高或精度不足。

Method: LSHFed采用多超平面局部敏感哈希（LSHGM）将高维梯度转为二进制表示，高效检测恶意梯度。

Result: 实验显示LSHFed在50%恶意参与者下仍保持高性能，通信开销降低1000倍。

Conclusion: LSHFed在提升鲁棒性和隐私保护的同时，显著优化了通信效率。

Abstract: Federated learning (FL) enables collaborative model training across
distributed nodes without exposing raw data, but its decentralized nature makes
it vulnerable in trust-deficient environments. Inference attacks may recover
sensitive information from gradient updates, while poisoning attacks can
degrade model performance or induce malicious behaviors. Existing defenses
often suffer from high communication and computation costs, or limited
detection precision. To address these issues, we propose LSHFed, a robust and
communication-efficient FL framework that simultaneously enhances aggregation
robustness and privacy preservation. At its core, LSHFed incorporates LSHGM, a
novel gradient verification mechanism that projects high-dimensional gradients
into compact binary representations via multi-hyperplane locally-sensitive
hashing. This enables accurate detection and filtering of malicious gradients
using only their irreversible hash forms, thus mitigating privacy leakage risks
and substantially reducing transmission overhead. Extensive experiments
demonstrate that LSHFed maintains high model performance even when up to 50% of
participants are collusive adversaries while achieving up to a 1000x reduction
in gradient verification communication compared to full-gradient methods.

</details>


### [330] [Diffusion-Based Solver for CNF Placement on the Cloud-Continuum](https://arxiv.org/abs/2511.01343)
*Álvaro Vázquez Rodríguez,Manuel Fernández-Veiga,Carlos Giraldo-Rodríguez*

Main category: cs.LG

TL;DR: 论文提出了一种基于去噪扩散概率模型（DDPM）的新理论框架，用于解决云原生网络功能（CNF）在云连续体中的放置问题，显著提升了可行解生成的速度和效率。


<details>
  <summary>Details</summary>
Motivation: 传统方法（如混合整数非线性规划、启发式算法和强化学习）在可扩展性、约束处理和泛化能力方面存在局限，需要一种更高效且能处理复杂约束的解决方案。

Method: 将CNF放置问题重新定义为生成图到分配任务，通过构建异构图并使用图神经网络去噪器迭代优化噪声分配矩阵，同时在损失函数中直接融入约束条件。

Result: 实验表明，该方法能在不同拓扑结构中快速生成可行解，推理速度比MINLP求解器快几个数量级。

Conclusion: 基于扩散的生成模型为约束网络嵌入问题提供了实用且可扩展的解决方案，推动了分布式云原生网络功能的编排实践。

Abstract: The placement of Cloud-Native Network Functions (CNFs) across the
Cloud-Continuum represents a core challenge in the orchestration of current 5G
and future 6G networks. The process involves the placement of interdependent
computing tasks, structured as Service Function Chains, over distributed cloud
infrastructures. This is achieved while satisfying strict resource, bandwidth
and latency constraints. It is acknowledged that classical approaches,
including mixed-integer nonlinear programming, heuristics and reinforcement
learning are limited in terms of scalability, constraint handling and
generalisation capacity. In the present study, a novel theoretical framework is
proposed, which is based on Denoising Diffusion Probabilistic Models (DDPM) for
CNF placement. The present approach proposes a reconceptualisation of placement
as a generative graph to assignment task, where the placement problem is
encoded as a heterogeneous graph, and a Graph Neural Network denoiser is
trained to iteratively refine noisy CNF-to-cloud assignment matrices. The model
incorporates constraint-specific losses directly into the loss function,
thereby allowing it to learn feasible solution spaces. The integration of the
DDPM formulation with structured combinatorial constraints is achieved through
a rigorous and systematic approach. Extensive evaluations across diverse
topologies have been conducted, which have confirmed that the model
consistently produces feasible solutions with orders of magnitude faster
inference than MINLP solvers. The results obtained demonstrate the potential of
diffusion-based generative modelling for constrained network embedding
problems, making an impact towards the practical, scalable orchestration of
distributed Cloud-Native Network Functions.

</details>


### [331] [MiniFool - Physics-Constraint-Aware Minimizer-Based Adversarial Attacks in Deep Neural Networks](https://arxiv.org/abs/2511.01352)
*Lucie Flek,Oliver Janik,Philipp Alexander Jung,Akbar Karimi,Timo Saala,Alexander Schmidt,Matthias Schott,Philipp Soldin,Matthias Thiesmeyer,Christopher Wiebusch,Ulrich Willemsen*

Main category: cs.LG

TL;DR: MiniFool算法通过物理启发的对抗攻击测试神经网络分类任务，适用于粒子物理和天体物理等领域。


<details>
  <summary>Details</summary>
Motivation: 开发一种通用算法，用于测试神经网络在科学数据分类中的鲁棒性，特别是在粒子物理和天体物理领域。

Method: 基于最小化结合χ²统计量和目标分数偏差的成本函数，量化扰动概率。

Result: 算法成功应用于MNIST和CMS实验数据，量化了分类翻转的可能性和网络决策的鲁棒性。

Conclusion: MiniFool算法能有效测试神经网络分类的鲁棒性，适用于未标记实验数据。

Abstract: In this paper, we present a new algorithm, MiniFool, that implements
physics-inspired adversarial attacks for testing neural network-based
classification tasks in particle and astroparticle physics. While we initially
developed the algorithm for the search for astrophysical tau neutrinos with the
IceCube Neutrino Observatory, we apply it to further data from other science
domains, thus demonstrating its general applicability. Here, we apply the
algorithm to the well-known MNIST data set and furthermore, to Open Data data
from the CMS experiment at the Large Hadron Collider. The algorithm is based on
minimizing a cost function that combines a $\chi^2$ based test-statistic with
the deviation from the desired target score. The test statistic quantifies the
probability of the perturbations applied to the data based on the experimental
uncertainties. For our studied use cases, we find that the likelihood of a
flipped classification differs for both the initially correctly and incorrectly
classified events. When testing changes of the classifications as a function of
an attack parameter that scales the experimental uncertainties, the robustness
of the network decision can be quantified. Furthermore, this allows testing the
robustness of the classification of unlabeled experimental data.

</details>


### [332] [Verifiable Split Learning via zk-SNARKs](https://arxiv.org/abs/2511.01356)
*Rana Alaa,Darío González-Ferreiro,Carlos Beis-Penedo,Manuel Fernández-Veiga,Rebeca P. Díaz-Redondo,Ana Fernández-Vilas*

Main category: cs.LG

TL;DR: 提出了一种可验证的分割学习框架，通过集成zk-SNARK证明确保计算的正确性和可验证性。


<details>
  <summary>Details</summary>
Motivation: 解决分割学习中无法验证计算正确性和诚实性的问题。

Method: 在分割学习框架中集成zk-SNARK证明，确保前向传播和反向传播的可验证性。

Result: 与基于区块链的系统相比，zk-SNARK测试实现了可验证性和正确性，而区块链轻量但不可验证。

Conclusion: zk-SNARK证明在分割学习中有效提升了计算的可验证性和正确性。

Abstract: Split learning is an approach to collaborative learning in which a deep
neural network is divided into two parts: client-side and server-side at a cut
layer. The client side executes its model using its raw input data and sends
the intermediate activation to the server side. This configuration architecture
is very useful for enabling collaborative training when data or resources are
separated between devices. However, split learning lacks the ability to verify
the correctness and honesty of the computations that are performed and
exchanged between the parties. To this purpose, this paper proposes a
verifiable split learning framework that integrates a zk-SNARK proof to ensure
correctness and verifiability. The zk-SNARK proof and verification are
generated for both sides in forward propagation and backward propagation on the
server side, guaranteeing verifiability on both sides. The verifiable split
learning architecture is compared to a blockchain-enabled system for the same
deep learning network, one that records updates but without generating the
zero-knowledge proof. From the comparison, it can be deduced that applying the
zk-SNARK test achieves verifiability and correctness, while blockchains are
lightweight but unverifiable.

</details>


### [333] [Learning Intractable Multimodal Policies with Reparameterization and Diversity Regularization](https://arxiv.org/abs/2511.01374)
*Ziqi Wang,Jiashun Liu,Ling Pan*

Main category: cs.LG

TL;DR: 论文提出了一种基于重参数化的多模态强化学习算法，通过距离多样性正则化提升决策多样性，并在多目标达成和生成RL任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统连续深度强化学习算法使用确定性或单峰高斯策略，无法表达复杂的多模态决策分布，限制了在多样性关键场景中的性能。

Method: 通过重参数化优化多模态策略，并提出无需决策概率的距离多样性正则化方法。

Result: 在多目标达成和生成RL任务中表现出色，同时在MuJoCo基准测试中具有竞争力。

Conclusion: 多模态策略在多样性关键场景中具有优势，且摊销策略模型表现出强大的多模态表达能力和高性能。

Abstract: Traditional continuous deep reinforcement learning (RL) algorithms employ
deterministic or unimodal Gaussian actors, which cannot express complex
multimodal decision distributions. This limitation can hinder their performance
in diversity-critical scenarios. There have been some attempts to design online
multimodal RL algorithms based on diffusion or amortized actors. However, these
actors are intractable, making existing methods struggle with balancing
performance, decision diversity, and efficiency simultaneously. To overcome
this challenge, we first reformulate existing intractable multimodal actors
within a unified framework, and prove that they can be directly optimized by
policy gradient via reparameterization. Then, we propose a distance-based
diversity regularization that does not explicitly require decision
probabilities. We identify two diversity-critical domains, namely multi-goal
achieving and generative RL, to demonstrate the advantages of multimodal
policies and our method, particularly in terms of few-shot robustness. In
conventional MuJoCo benchmarks, our algorithm also shows competitive
performance. Moreover, our experiments highlight that the amortized actor is a
promising policy model class with strong multimodal expressivity and high
performance. Our code is available at https://github.com/PneuC/DrAC

</details>


### [334] [Protecting the Neural Networks against FGSM Attack Using Machine Unlearning](https://arxiv.org/abs/2511.01377)
*Amir Hossein Khorasani,Ali Jahanian,Maryam Rastgarpour*

Main category: cs.LG

TL;DR: 论文探讨了通过机器遗忘技术提升LeNet神经网络对抗FGSM攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 对抗性攻击（如FGSM）威胁机器学习模型的安全性，需研究防御方法。

Method: 应用机器遗忘技术，在LeNet网络上移除FGSM攻击的扰动数据。

Result: 遗忘技术显著提升了LeNet对抗FGSM攻击的鲁棒性。

Conclusion: 机器遗忘是有效防御FGSM攻击的方法，适用于LeNet等模型。

Abstract: Machine learning is a powerful tool for building predictive models. However,
it is vulnerable to adversarial attacks. Fast Gradient Sign Method (FGSM)
attacks are a common type of adversarial attack that adds small perturbations
to input data to trick a model into misclassifying it. In response to these
attacks, researchers have developed methods for "unlearning" these attacks,
which involves retraining a model on the original data without the added
perturbations. Machine unlearning is a technique that tries to "forget"
specific data points from the training dataset, to improve the robustness of a
machine learning model against adversarial attacks like FGSM. In this paper, we
focus on applying unlearning techniques to the LeNet neural network, a popular
architecture for image classification. We evaluate the efficacy of unlearning
FGSM attacks on the LeNet network and find that it can significantly improve
its robustness against these types of attacks.

</details>


### [335] [Memory-Efficient Training with In-Place FFT Implementation](https://arxiv.org/abs/2511.01385)
*Xinyu Ding,Bangtian Liu,Siyu Liao,Zhongfeng Wang*

Main category: cs.LG

TL;DR: 提出首个完全原地计算的实数域FFT框架（rdFFT），解决内存分配问题。


<details>
  <summary>Details</summary>
Motivation: 现有FFT实现无法实现真正的原地计算，导致内存浪费。

Method: 利用蝴蝶操作对称性和频域共轭特性，设计隐式复数编码方案。

Result: 实验证明能有效降低训练内存成本。

Conclusion: 为频域轻量化适应提供了新方向。

Abstract: Fast Fourier Transforms (FFT) are widely used to reduce memory and
computational costs in deep learning. However, existing implementations,
including standard FFT and real FFT (rFFT), cannot achieve true in-place
computation. In particular, rFFT maps an input of size n to a complex output of
size n/2+1, causing dimensional mismatch and requiring additional memory
allocation. We propose the first real-domain, fully in-place FFT framework
(rdFFT) that preserves input-output memory space consistency. By leveraging
butterfly operation symmetry and conjugate properties in the frequency domain,
we design an implicit complex encoding scheme that eliminates intermediate
cache usage entirely. Experiments on multiple natural language understanding
tasks demonstrate the method effectiveness in reducing training memory cost,
offering a promising direction for frequency-domain lightweight adaptation.

</details>


### [336] [Leveraging Compact Satellite Embeddings and Graph Neural Networks for Large-Scale Poverty Mapping](https://arxiv.org/abs/2511.01408)
*Markus B. Pettersson,Adel Daoud*

Main category: cs.LG

TL;DR: 提出一种基于图的卫星嵌入方法，用于预测撒哈拉以南非洲的财富指数，通过空间关系和模糊标签损失提高预测泛化能力。


<details>
  <summary>Details</summary>
Motivation: 全球南方缺乏精细的贫困地图，DHS数据空间覆盖有限且坐标随机位移，降低了数据质量。

Method: 利用低维AlphaEarth卫星嵌入，建模空间关系，引入模糊标签损失处理坐标位移。

Result: 在37个DHS数据集上实验表明，图结构略微提高了准确性，优于纯图像基线。

Conclusion: 紧凑的卫星嵌入在大规模社会经济制图中具有潜力。

Abstract: Accurate, fine-grained poverty maps remain scarce across much of the Global
South. While Demographic and Health Surveys (DHS) provide high-quality
socioeconomic data, their spatial coverage is limited and reported coordinates
are randomly displaced for privacy, further reducing their quality. We propose
a graph-based approach leveraging low-dimensional AlphaEarth satellite
embeddings to predict cluster-level wealth indices across Sub-Saharan Africa.
By modeling spatial relations between surveyed and unlabeled locations, and by
introducing a probabilistic "fuzzy label" loss to account for coordinate
displacement, we improve the generalization of wealth predictions beyond
existing surveys. Our experiments on 37 DHS datasets (2017-2023) show that
incorporating graph structure slightly improves accuracy compared to
"image-only" baselines, demonstrating the potential of compact EO embeddings
for large-scale socioeconomic mapping.

</details>


### [337] [CG-FKAN: Compressed-Grid Federated Kolmogorov-Arnold Networks for Communication Constrained Environment](https://arxiv.org/abs/2511.01433)
*Seunghun Yu,Youngjoon Lee,Jinu Gong,Joonhyuk Kang*

Main category: cs.LG

TL;DR: CG-FKAN通过压缩扩展网格来减少通信开销，在通信受限环境下表现优于固定网格KAN。


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）在隐私敏感应用中广泛使用，但可解释性有限，而KAN通过可学习样条函数解决了这一问题。然而，现有FL研究忽略了网格扩展引入的通信开销。

Method: 提出CG-FKAN，通过稀疏化和仅传输必要系数来压缩扩展网格，并在通信预算下优化。

Result: 实验显示CG-FKAN在通信受限环境下比固定网格KAN的RMSE降低13.6%，并推导了其近似误差的理论上限。

Conclusion: CG-FKAN有效解决了FL中KAN的通信开销问题，同时保持了性能优势。

Abstract: Federated learning (FL), widely used in privacy-critical applications,
suffers from limited interpretability, whereas Kolmogorov-Arnold Networks (KAN)
address this limitation via learnable spline functions. However, existing FL
studies applying KAN overlook the communication overhead introduced by grid
extension, which is essential for modeling complex functions. In this letter,
we propose CG-FKAN, which compresses extended grids by sparsifying and
transmitting only essential coefficients under a communication budget.
Experiments show that CG-FKAN achieves up to 13.6% lower RMSE than fixed-grid
KAN in communication-constrained settings. In addition, we derive a theoretical
upper bound on its approximation error.

</details>


### [338] [The Curvature Rate λ: A Scalar Measure of Input-Space Sharpness in Neural Networks](https://arxiv.org/abs/2511.01438)
*Jacob Poschl*

Main category: cs.LG

TL;DR: 论文提出了一种新的曲率度量方法——曲率率λ，通过输入空间的高阶导数增长速率来衡量神经网络的泛化性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于参数空间的锐度度量方法计算成本高、对参数化敏感且难以解释，因此需要一种更直观、高效的曲率度量方法。

Method: 通过估计高阶导数对数范数随阶数增长的斜率来定义曲率率λ，并提出了曲率率正则化（CRR）来优化模型。

Result: 实验表明，CRR在保持准确性的同时，能生成更平滑的输入空间几何结构，并改善置信度校准。

Conclusion: 曲率率λ提供了一种紧凑、可解释且参数化不变的函数平滑性描述方法。

Abstract: Curvature influences generalization, robustness, and how reliably neural
networks respond to small input perturbations. Existing sharpness metrics are
typically defined in parameter space (e.g., Hessian eigenvalues) and can be
expensive, sensitive to reparameterization, and difficult to interpret in
functional terms. We introduce a scalar curvature measure defined directly in
input space: the curvature rate {\lambda}, given by the exponential growth rate
of higher-order input derivatives. Empirically, {\lambda} is estimated as the
slope of log ||D^n f|| versus n for small n. This growth-rate perspective
unifies classical analytic quantities: for analytic functions, {\lambda}
corresponds to the inverse radius of convergence, and for bandlimited signals,
it reflects the spectral cutoff. The same principle extends to neural networks,
where {\lambda} tracks the emergence of high-frequency structure in the
decision boundary. Experiments on analytic functions and neural networks (Two
Moons and MNIST) show that {\lambda} evolves predictably during training and
can be directly shaped using a simple derivative-based regularizer, Curvature
Rate Regularization (CRR). Compared to Sharpness-Aware Minimization (SAM), CRR
achieves similar accuracy while yielding flatter input-space geometry and
improved confidence calibration. By grounding curvature in differentiation
dynamics, {\lambda} provides a compact, interpretable, and
parameterization-invariant descriptor of functional smoothness in learned
models.

</details>


### [339] [Efficient Curvature-aware Graph Network](https://arxiv.org/abs/2511.01443)
*Chaoqun Fei,Tinglve Zhou,Tianyong Hao,Yangyang Li*

Main category: cs.LG

TL;DR: 提出了一种新的图曲率度量——有效电阻曲率，以替代计算复杂度高的Ollivier-Ricci曲率，显著提升计算效率并保持几何表达能力。


<details>
  <summary>Details</summary>
Motivation: Ollivier-Ricci曲率虽几何解释性强，但计算复杂度高，限制了其在大规模图数据中的应用。

Method: 利用节点对之间的有效电阻代替最优传输距离，量化消息传递的便捷性。

Result: 有效电阻曲率在计算效率上显著优于Ollivier-Ricci曲率，同时保持竞争性能。

Conclusion: 新方法在降低计算开销的同时，保持了与Ollivier-Ricci曲率相当的几何表达能力和性能。

Abstract: Graph curvature provides geometric priors for Graph Neural Networks (GNNs),
enhancing their ability to model complex graph structures, particularly in
terms of structural awareness, robustness, and theoretical interpretability.
Among existing methods, Ollivier-Ricci curvature has been extensively studied
due to its strong geometric interpretability, effectively characterizing the
local geometric distribution between nodes. However, its prohibitively high
computational complexity limits its applicability to large-scale graph
datasets. To address this challenge, we propose a novel graph curvature
measure--Effective Resistance Curvature--which quantifies the ease of message
passing along graph edges using the effective resistance between node pairs,
instead of the optimal transport distance. This method significantly
outperforms Ollivier-Ricci curvature in computational efficiency while
preserving comparable geometric expressiveness. Theoretically, we prove the low
computational complexity of effective resistance curvature and establish its
substitutability for Ollivier-Ricci curvature. Furthermore, extensive
experiments on diverse GNN tasks demonstrate that our method achieves
competitive performance with Ollivier-Ricci curvature while drastically
reducing computational overhead.

</details>


### [340] [DAMBench: A Multi-Modal Benchmark for Deep Learning-based Atmospheric Data Assimilation](https://arxiv.org/abs/2511.01468)
*Hao Wang,Zixuan Weng,Jindong Han,Wei Fan,Hao Liu*

Main category: cs.LG

TL;DR: DAMBench是一个大规模多模态基准测试，用于评估数据驱动的大气数据同化模型，解决了现有研究的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统数据同化方法在复杂现实场景中受限，深度学习提供了更高效的替代方案，但缺乏标准化基准和真实数据支持。

Method: DAMBench整合高质量背景状态和真实多模态观测数据，提供统一评估协议和基准测试。

Result: DAMBench为未来研究提供了严格基础，支持可重复性、公平比较和扩展到现实多模态场景。

Conclusion: DAMBench填补了数据同化研究的空白，推动了深度学习在复杂现实场景中的应用。

Abstract: Data Assimilation is a cornerstone of atmospheric system modeling, tasked
with reconstructing system states by integrating sparse, noisy observations
with prior estimation. While traditional approaches like variational and
ensemble Kalman filtering have proven effective, recent advances in deep
learning offer more scalable, efficient, and flexible alternatives better
suited for complex, real-world data assimilation involving large-scale and
multi-modal observations. However, existing deep learning-based DA research
suffers from two critical limitations: (1) reliance on oversimplified scenarios
with synthetically perturbed observations, and (2) the absence of standardized
benchmarks for fair model comparison. To address these gaps, in this work, we
introduce DAMBench, the first large-scale multi-modal benchmark designed to
evaluate data-driven DA models under realistic atmospheric conditions. DAMBench
integrates high-quality background states from state-of-the-art forecasting
systems and real-world multi-modal observations (i.e., real-world weather
stations and satellite imagery). All data are resampled to a common grid and
temporally aligned to support systematic training, validation, and testing. We
provide unified evaluation protocols and benchmark representative data
assimilation approaches, including latent generative models and neural process
frameworks. Additionally, we propose a lightweight multi-modal plugin to
demonstrate how integrating realistic observations can enhance even simple
baselines. Through comprehensive experiments, DAMBench establishes a rigorous
foundation for future research, promoting reproducibility, fair comparison, and
extensibility to real-world multi-modal scenarios. Our dataset and code are
publicly available at https://github.com/figerhaowang/DAMBench.

</details>


### [341] [Real-time Continual Learning on Intel Loihi 2](https://arxiv.org/abs/2511.01553)
*Elvin Hajizada,Danielle Rager,Timothy Shea,Leobardo Campos-Macias,Andreas Wild,Eyke Hüllermeier,Yulia Sandamirskaya,Mike Davies*

Main category: cs.LG

TL;DR: CLP-SNN是一种基于脉冲神经网络的在线持续学习架构，在边缘设备上实现了高效且节能的学习，突破了传统精度与效率的权衡。


<details>
  <summary>Details</summary>
Motivation: 解决边缘设备在开放世界中数据分布变化和新类别出现时的适应性问题，同时避免灾难性遗忘。

Method: 采用事件驱动和时空稀疏的局部学习、自归一化的三因素学习规则，以及集成的神经发生和元可塑性机制。

Result: 在OpenLORIS实验中，CLP-SNN在精度上媲美回放方法，同时速度提升70倍，能效提高5600倍。

Conclusion: 神经形态算法与硬件协同设计可以突破传统边缘AI系统的精度与效率权衡。

Abstract: AI systems on edge devices face a critical challenge in open-world
environments: adapting when data distributions shift and novel classes emerge.
While offline training dominates current paradigms, online continual learning
(OCL)--where models learn incrementally from non-stationary streams without
catastrophic forgetting--remains challenging in power-constrained settings. We
present a neuromorphic solution called CLP-SNN: a spiking neural network
architecture for Continually Learning Prototypes and its implementation on
Intel's Loihi 2 chip. Our approach introduces three innovations: (1)
event-driven and spatiotemporally sparse local learning, (2) a self-normalizing
three-factor learning rule maintaining weight normalization, and (3) integrated
neurogenesis and metaplasticity for capacity expansion and forgetting
mitigation. On OpenLORIS few-shot learning experiments, CLP-SNN achieves
accuracy competitive with replay methods while being rehearsal-free. CLP-SNN
delivers transformative efficiency gains: 70\times faster (0.33ms vs 23.2ms),
and 5,600\times more energy efficient (0.05mJ vs 281mJ) than the best
alternative OCL on edge GPU. This demonstrates that co-designed brain-inspired
algorithms and neuromorphic hardware can break traditional accuracy-efficiency
trade-offs for future edge AI systems.

</details>


### [342] [Gated Fusion Enhanced Multi-Scale Hierarchical Graph Convolutional Network for Stock Movement Prediction](https://arxiv.org/abs/2511.01570)
*Xiaosha Xue,Peibo Duan,Zhipeng Liu,Qi Chu,Changsheng Zhang,Bin zhang*

Main category: cs.LG

TL;DR: MS-HGFN模型通过分层GNN和多尺度时空特征融合，显著提升了股票市场预测的准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 股票市场预测因波动性和复杂依赖关系而困难，现有GNN模型常忽略股票内部属性和多尺度特征的平衡。

Method: 提出MS-HGFN模型，结合分层GNN动态学习股票内部和跨属性模式，并通过自上而下门控融合多尺度特征。

Result: 实验显示MS-HGFN在中美股市数据上优于传统和先进模型，预测精度提升1.4%，稳定性增强。

Conclusion: MS-HGFN通过动态图学习和多尺度特征融合，有效解决了股票预测中的关键问题。

Abstract: Accurately predicting stock market movements remains a formidable challenge
due to the inherent volatility and complex interdependencies among stocks.
Although multi-scale Graph Neural Networks (GNNs) hold potential for modeling
these relationships, they frequently neglect two key points: the subtle
intra-attribute patterns within each stock affecting inter-stock correlation,
and the biased attention to coarse- and fine-grained features during
multi-scale sampling. To overcome these challenges, we introduce MS-HGFN
(Multi-Scale Hierarchical Graph Fusion Network). The model features a
hierarchical GNN module that forms dynamic graphs by learning patterns from
intra-attributes and features from inter-attributes over different time scales,
thus comprehensively capturing spatio-temporal dependencies. Additionally, a
top-down gating approach facilitates the integration of multi-scale
spatio-temporal features, preserving critical coarse- and fine-grained features
without too much interference. Experiments utilizing real-world datasets from
U.S. and Chinese stock markets demonstrate that MS-HGFN outperforms both
traditional and advanced models, yielding up to a 1.4% improvement in
prediction accuracy and enhanced stability in return simulations. The code is
available at https://anonymous.4open.science/r/MS-HGFN.

</details>


### [343] [HIT-ROCKET: Hadamard-vector Inner-product Transformer for ROCKET](https://arxiv.org/abs/2511.01572)
*Wang Hao,Kuang Zhang,Hou Chengyu,Yuan Zhonghao,Tan Chenxing,Fu Weifeng,Zhu Yangying*

Main category: cs.LG

TL;DR: 提出了一种基于Hadamard卷积变换的特征提取方法，显著提升了时间序列分类的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有SOTA方法计算复杂度高，轻量级解决方案如ROCKET仍有改进空间。

Method: 利用Hadamard矩阵的列或行向量作为卷积核，提升计算效率和适应性。

Result: 在UCR数据集上F1-score提升至少5%，训练时间比miniROCKET缩短50%。

Conclusion: 该方法高效且兼容现有技术，适用于超低功耗嵌入式设备。

Abstract: Time series classification holds broad application value in communications,
information countermeasures, finance, and medicine. However, state-of-the-art
(SOTA) methods-including HIVE-COTE, Proximity Forest, and TS-CHIEF-exhibit high
computational complexity, coupled with lengthy parameter tuning and training
cycles. In contrast, lightweight solutions like ROCKET (Random Convolutional
Kernel Transform) offer greater efficiency but leave substantial room for
improvement in kernel selection and computational overhead. To address these
challenges, we propose a feature extraction approach based on Hadamard
convolutional transform, utilizing column or row vectors of Hadamard matrices
as convolution kernels with extended lengths of varying sizes. This enhancement
maintains full compatibility with existing methods (e.g., ROCKET) while
leveraging kernel orthogonality to boost computational efficiency, robustness,
and adaptability. Comprehensive experiments on multi-domain datasets-focusing
on the UCR time series dataset-demonstrate SOTA performance: F1-score improved
by at least 5% vs. ROCKET, with 50% shorter training time than miniROCKET
(fastest ROCKET variant) under identical hyperparameters, enabling deployment
on ultra-low-power embedded devices. All code is available on GitHub.

</details>


### [344] [Explore More, Learn Better: Parallel MLLM Embeddings under Mutual Information Minimization](https://arxiv.org/abs/2511.01588)
*Zhicheng Wang,Chen Ju,Xu Chen,Shuai Xiao,Jinsong Lan,Xiaoyong Zhu,Ying Chen,Zhiguo Cao*

Main category: cs.LG

TL;DR: 提出了一种并行解耦框架（PDF），用于多模态嵌入学习，通过利用MLLM的专有可操控性，生成多样化的并行嵌入，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有的嵌入模型范式（SSC）将多面输入压缩为单一嵌入，未能充分利用MLLM的能力。

Method: 利用MLLM的可操控性，通过共享主干和可学习前缀生成并行路径，结合互信息最小化和对比监督，实现多样性和语义对齐。

Result: 在MMEB基准测试中显著提升性能，例如7B模型提升8.9%，2B模型提升4.2%，且计算效率更高。

Conclusion: PDF框架通过并行路径和双目标优化，实现了更鲁棒的语义覆盖和通用嵌入空间，且推理时计算开销可忽略。

Abstract: Embedding models are a cornerstone of modern AI. Driven by Multimodal Large
Language Models (MLLMs), they have made great progress in architecture and data
curation, while the holistic paradigm is still limited to SSC, i.e., single
input, singular embedding, contrastive supervision, which collapses rich,
multifaceted inputs into monolithic embeddings and fails to fully exploit MLLM
capabilities. In this paper, we tailor one Parallel Decoupling Framework (PDF)
for multimodal embedding learning, by utilizing the proprietary steerability of
MLLMs, i.e., their ability to flexibly generate quite differentiated response
under explicit instructions. Concretely, PDF conditions a shared MLLM backbone
on distinct, learnable prefixes to roll out multiple parallel paths for one
input, then relies on these paths to obtain parallel embeddings. To promote
full parallel diversity, we employ Mutual Information Minimization (MIM) as an
explicit constraint, coupled with per-path contrastive supervision to maintain
semantic alignment. Such dual-objectives force PDF to yield robust semantic
coverage and a generalizable embedding space. Ultimately, the remarkable
embedding space are accessible at inference via one single forward pass,
incurring negligible computational overhead. We instantiate PDF on multiple
MLLM backbones and prove its effectiveness on MMEB benchmark. Significant gains
are consistently achieved across various resolutions and model sizes, e.g.,
boosting the VLM2Vec-LLaVA-1.6-LR model by a remarkable +8.9% (7B), while the
VLM2Vec-Qwen2VL models by +4.2% (2B) and +3.1% (7B). In terms of efficiency,
our 2B model surpasses its baseline by +2.6% using only half the computational
budget.

</details>


### [345] [Defining Energy Indicators for Impact Identification on Aerospace Composites: A Physics-Informed Machine Learning Perspective](https://arxiv.org/abs/2511.01592)
*Natália Ribeiro Marinho,Richard Loendersloot,Frank Grooteman,Jan Willem Wiegman,Uraz Odyurt,Tiedo Tinga*

Main category: cs.LG

TL;DR: 提出了一种物理信息驱动的机器学习框架，用于提高航空航天复合材料低速冲击能量预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法受限于数据稀疏性、信号噪声和复杂特征依赖关系，难以准确预测冲击能量。

Method: 结合物理知识设计特征，通过多域特征提取和结构化特征选择，训练全连接神经网络。

Result: 模型预测误差比传统方法减少三倍，显著提高了准确性。

Conclusion: 该方法不仅提升了预测性能，还保持了物理可解释性和可追溯性。

Abstract: Energy estimation is critical to impact identification on aerospace
composites, where low-velocity impacts can induce internal damage that is
undetectable at the surface. Current methodologies for energy prediction are
often constrained by data sparsity, signal noise, complex feature
interdependencies, non-linear dynamics, massive design spaces, and the
ill-posed nature of the inverse problem. This study introduces a
physics-informed framework that embeds domain knowledge into machine learning
through a dedicated input space. The approach combines observational biases,
which guide the design of physics-motivated features, with targeted feature
selection to retain only the most informative indicators. Features are
extracted from time, frequency, and time-frequency domains to capture
complementary aspects of the structural response. A structured feature
selection process integrating statistical significance, correlation filtering,
dimensionality reduction, and noise robustness ensures physical relevance and
interpretability. Exploratory data analysis further reveals domain-specific
trends, yielding a reduced feature set that captures essential dynamic
phenomena such as amplitude scaling, spectral redistribution, and transient
signal behaviour. Together, these steps produce a compact set of
energy-sensitive indicators with both statistical robustness and physical
significance, resulting in impact energy predictions that remain interpretable
and traceable to measurable structural responses. Using this optimised input
space, a fully-connected neural network is trained and validated with
experimental data from multiple impact scenarios, including pristine and
damaged states. The resulting model demonstrates significantly improved impact
energy prediction accuracy, reducing errors by a factor of three compared to
conventional time-series techniques and purely data-driven models.

</details>


### [346] [Estimation of Toeplitz Covariance Matrices using Overparameterized Gradient Descent](https://arxiv.org/abs/2511.01605)
*Daniel Busbib,Ami Wiesel*

Main category: cs.LG

TL;DR: 论文研究了在Toeplitz结构下的协方差估计问题，通过过参数化的梯度下降方法展示了其优于传统方法的潜力。


<details>
  <summary>Details</summary>
Motivation: 传统方法在Toeplitz约束下最大化高斯对数似然，但近期深度学习显示简单梯度下降在过参数化模型中的强大表现，因此重新审视Toeplitz协方差估计。

Method: 将P×P协方差建模为K个可学习参数的复正弦波之和，并通过梯度下降优化。研究了不同K值的效果，并提出了加速梯度下降变体。

Result: 当K=2P或4P时，梯度下降能从随机初始化实现全局收敛；固定频率时，优化问题具有良性性质。数值实验显示其性能优于现有方法。

Conclusion: 过参数化的梯度下降方法在Toeplitz协方差估计中表现优异，兼具简单性和可扩展性。

Abstract: We consider covariance estimation under Toeplitz structure. Numerous
sophisticated optimization methods have been developed to maximize the Gaussian
log-likelihood under Toeplitz constraints. In contrast, recent advances in deep
learning demonstrate the surprising power of simple gradient descent (GD)
applied to overparameterized models. Motivated by this trend, we revisit
Toeplitz covariance estimation through the lens of overparameterized GD. We
model the $P\times P$ covariance as a sum of $K$ complex sinusoids with
learnable parameters and optimize them via GD. We show that when $K = P$, GD
may converge to suboptimal solutions. However, mild overparameterization ($K =
2P$ or $4P$) consistently enables global convergence from random
initializations. We further propose an accelerated GD variant with separate
learning rates for amplitudes and frequencies. When frequencies are fixed and
only amplitudes are optimized, we prove that the optimization landscape is
asymptotically benign and any stationary point recovers the true covariance.
Finally, numerical experiments demonstrate that overparameterized GD can match
or exceed the accuracy of state-of-the-art methods in challenging settings,
while remaining simple and scalable.

</details>


### [347] [Scaling Graph Chain-of-Thought Reasoning: A Multi-Agent Framework with Efficient LLM Serving](https://arxiv.org/abs/2511.01633)
*Chengying Huan,Ziheng Meng,Yongchao Liu,Zhengyi Yang,Yun Zhu,Yue Yun,Shipeng Li,Rong Gu,Xiabao Wu,Haitao Zhang,Chuntao Hong,Shaonan Ma,Guihai Chen,Chen Tian*

Main category: cs.LG

TL;DR: GLM是一个多代理Graph-CoT系统，通过分解推理任务和优化LLM服务架构，显著提升了准确性、降低了令牌消耗和延迟，并提高了吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现有Graph-CoT流水线存在准确性低、令牌使用过多、延迟高和吞吐量低的问题，需要优化推理和服务效率。

Method: GLM将推理分解为分类、推理、动作生成和图检索的专用代理，并引入图感知的LLM推理机制，优化KV缓存管理和执行流程。

Result: GLM将答案准确性提升38%，令牌成本降低95.7%，延迟减少90.3%，吞吐量提高15.1倍。

Conclusion: GLM通过多代理设计和优化服务架构，实现了高效的大规模复杂推理，适用于实际应用。

Abstract: Graph Chain-of-Thought (Graph-CoT) enables large language models (LLMs) to
perform step-by-step reasoning over graph-structured knowledge, but existing
pipelines suffer from low accuracy, excessive token usage, high latency, and
low throughput due to single-agent monolithic prompts, repeated context
re-encoding, and inefficient serving execution. We present GLM, the first
multi-agent Graph-CoT system co-designed with an optimized LLM serving
architecture. GLM decomposes reasoning into specialized agents for
classification, reasoning, action generation, and graph retrieval, enabling
branching and selective context sharing to reduce prompt length and reasoning
iterations while preserving reasoning quality, thereby improving accuracy and
reducing overall token consumption. To scale inference, we introduce a
Graph-CoT-aware LLM inference mechanism with graph-specific KV-cache
management, priority-based eviction, and pipelined execution to improve serving
efficiency. Experiments demonstrate that GLM improves answer accuracy by up to
38%, reduces token cost by up to 95.7%, lowers inference latency by 90.3%, and
achieves up to 15.1x higher throughput compared to state-of-the-art Graph-CoT
baselines, enabling efficient adoption for complex real-world reasoning at
scale.

</details>


### [348] [Cross-Treatment Effect Estimation for Multi-Category, Multi-Valued Causal Inference via Dynamic Neural Masking](https://arxiv.org/abs/2511.01641)
*Xiaopeng Ke,Yihan Yu,Ruyue Zhang,Zhishuo Zhou,Fangzhou Shi,Chang Men,Zhengdan Zhu*

Main category: cs.LG

TL;DR: XTNet是一种新颖的网络架构，用于多类别、多值处理效应估计，通过动态掩码机制和分解策略有效建模复杂处理空间。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理多类别、多值处理效应时存在限制性假设、可扩展性不足和评估框架不完善的问题。

Method: XTNet采用交叉效应估计模块和动态掩码机制，分解基本效应与交叉处理交互，并提出了MCMV-AUCC评估指标。

Result: XTNet在合成和真实数据集上均优于现有基线方法，A/B测试进一步验证了其有效性。

Conclusion: XTNet为复杂干预场景下的因果推断提供了高效且可扩展的解决方案。

Abstract: Counterfactual causal inference faces significant challenges when extended to
multi-category, multi-valued treatments, where complex cross-effects between
heterogeneous interventions are difficult to model. Existing methodologies
remain constrained to binary or single-type treatments and suffer from
restrictive assumptions, limited scalability, and inadequate evaluation
frameworks for complex intervention scenarios.
  We present XTNet, a novel network architecture for multi-category,
multi-valued treatment effect estimation. Our approach introduces a
cross-effect estimation module with dynamic masking mechanisms to capture
treatment interactions without restrictive structural assumptions. The
architecture employs a decomposition strategy separating basic effects from
cross-treatment interactions, enabling efficient modeling of combinatorial
treatment spaces. We also propose MCMV-AUCC, a suitable evaluation metric that
accounts for treatment costs and interaction effects. Extensive experiments on
synthetic and real-world datasets demonstrate that XTNet consistently
outperforms state-of-the-art baselines in both ranking accuracy and effect
estimation quality. The results of the real-world A/B test further confirm its
effectiveness.

</details>


### [349] [Bayesian Natural Gradient Fine-Tuning of CLIP Models via Kalman Filtering](https://arxiv.org/abs/2511.01694)
*Hossein Abdi,Mingfei Sun,Wei Pan*

Main category: cs.LG

TL;DR: 提出了一种基于卡尔曼滤波的贝叶斯近似自然梯度下降方法，用于优化CLIP模型的少样本微调，提升ID和OOD性能。


<details>
  <summary>Details</summary>
Motivation: 现有的一阶梯度优化方法在CLIP模型微调中收敛慢、对超参数敏感且OOD泛化能力差，而二阶方法（如自然梯度下降）计算成本高。

Method: 使用卡尔曼滤波近似自然梯度下降，结合二阶优化和贝叶斯推断，提升泛化能力并提供不确定性量化。

Result: 在多种图像分类数据集上，该方法在ID性能上优于或与基线相当，同时提高了OOD鲁棒性。

Conclusion: 首次成功将卡尔曼滤波应用于CLIP模型微调，实现了更鲁棒和高效的视觉-语言任务学习。

Abstract: Vision-language pre-trained models, such as CLIP, have established new
benchmarks in multimodal data mining. In such models, few-shot fine-tuning is a
major challenge to achieve optimal performance on both in-distribution (ID) and
out-of-distribution (OOD) datasets, especially when labeled data is scarce.
Most existing fine-tuning approaches rely on first-order gradient-based
optimizers, which typically suffer from slow convergence, sensitivity to
step-size hyperparameters, and poor generalization in OOD settings. In
contrast, second-order methods utilize local curvature information of the loss
landscape to adjust the update step size. This is particularly beneficial for
CLIP models, whose non-convex loss functions often contain sharp critical
points. In such cases, natural gradient direction can offer more substantial
and efficient per-iteration updates when fine-tuning with limited data. Natural
Gradient Descent (NGD) is obtained by preconditioning the standard gradient
with the inverse Fisher Information Matrix (FIM), which is computationally
expensive for large models. To address this, we propose a Bayesian
approximation of NGD using a Kalman filter for CLIP models. Our method combines
the benefits of second-order optimization with Bayesian inference, which
enhances generalization while providing uncertainty quantification. Extensive
experiments conducted on diverse image classification datasets demonstrate that
our algorithm consistently achieves superior--or comparable--ID performance and
improved OOD robustness compared to state-of-the-art baselines. To the best of
our knowledge, this work represents the first successful application of Kalman
filtering to fine-tuning CLIP-based models, which enables more robust and
efficient learning in vision-language tasks.

</details>


### [350] [Collaborative Large Language Model Inference via Resource-Aware Parallel Speculative Decoding](https://arxiv.org/abs/2511.01695)
*Jungyeon Koh,Hyun Jong Yang*

Main category: cs.LG

TL;DR: 提出了一种联合优化用户关联和资源分配的统一框架，以减少边缘计算中LLM推理的延迟。


<details>
  <summary>Details</summary>
Motivation: 移动边缘计算中资源受限环境下，现有推测解码方法存在通信开销和异步延迟问题。

Method: 使用多智能体深度强化学习算法解决用户关联和资源分配问题。

Result: 实验显示，该方法在不影响推理准确性的情况下，端到端延迟最高减少28.0%，平均减少23.7%。

Conclusion: 该方法为MEC系统中可扩展且低延迟的LLM服务提供了有效解决方案。

Abstract: The growing demand for on-device large language model (LLM) inference
highlights the need for efficient mobile edge computing (MEC) solutions,
especially in resource-constrained settings. Speculative decoding offers a
promising solution by partitioning token generation between a lightweight draft
model on mobile devices and a powerful target model on edge servers, but
suffers from communication overhead and asynchronous delays. This paper is the
first to propose a unified framework that jointly optimizes user association
and resource allocation (UARA) to support efficient parallel speculative
decoding. We solve the UARA problem using a multi-agent deep reinforcement
learning algorithm. To evaluate our approach under realistic conditions, we
conduct experiments using the Sionna simulator. Results show that our method
achieves up to 28.0% and an average of 23.7% reduction in end-to-end latency
without compromising inference accuracy, enabling scalable and low-latency LLM
services in MEC systems.

</details>


### [351] [Edge AI in Highly Volatile Environments: Is Fairness Worth the Accuracy Trade-off?](https://arxiv.org/abs/2511.01737)
*Obaidullah Zaland,Feras M. Awaysheh,Sawsan Al Zubi,Abdul Rahman Safi,Monowar Bhuyan*

Main category: cs.LG

TL;DR: 该论文研究了在高度动态的边缘环境中联邦学习的模型准确性与公平性之间的权衡，并通过实验评估了不同客户端选择算法的表现。


<details>
  <summary>Details</summary>
Motivation: 边缘环境的动态性和客户端能力的异质性对联邦学习的准确性和公平性提出了挑战，需要探索公平性与性能之间的平衡。

Method: 通过实验评估了RBFF、RBCSF等公平性客户端选择算法，并与随机和贪婪算法在CIFAR10、FashionMNIST和EMNIST数据集上进行了比较。

Result: 结果表明，更公平的客户端选择算法虽然能提供更均衡的参与机会，但在动态环境中可能导致全局训练速度变慢。

Conclusion: 论文揭示了公平性与性能及速度之间的权衡，并指出了未来研究的方向，以改进联邦学习中的公平客户端选择策略。

Abstract: Federated learning (FL) has emerged as a transformative paradigm for edge
intelligence, enabling collaborative model training while preserving data
privacy across distributed personal devices. However, the inherent volatility
of edge environments, characterized by dynamic resource availability and
heterogeneous client capabilities, poses significant challenges for achieving
high accuracy and fairness in client participation. This paper investigates the
fundamental trade-off between model accuracy and fairness in highly volatile
edge environments. This paper provides an extensive empirical evaluation of
fairness-based client selection algorithms such as RBFF and RBCSF against
random and greedy client selection regarding fairness, model performance, and
time, in three benchmarking datasets (CIFAR10, FashionMNIST, and EMNIST). This
work aims to shed light on the fairness-performance and fairness-speed
trade-offs in a volatile edge environment and explore potential future research
opportunities to address existing pitfalls in \textit{fair client selection}
strategies in FL. Our results indicate that more equitable client selection
algorithms, while providing a marginally better opportunity among clients, can
result in slower global training in volatile environments\footnote{The code for
our experiments can be found at
https://github.com/obaidullahzaland/FairFL_FLTA.

</details>


### [352] [Game-theoretic distributed learning of generative models for heterogeneous data collections](https://arxiv.org/abs/2511.01740)
*Dmitrij Schlesinger,Boris Flach*

Main category: cs.LG

TL;DR: 提出一种通过交换合成数据而非共享模型参数来处理分布式学习中异构模型和数据的方法。


<details>
  <summary>Details</summary>
Motivation: 分布式学习中处理异构本地模型和数据的挑战。

Method: 利用生成模型交换合成数据，将本地模型视为黑箱，支持半监督学习，并基于博弈论设计合作游戏。

Result: 证明了指数族本地模型存在唯一纳什均衡，且学习算法收敛于该均衡。

Conclusion: 在图像分类和条件生成任务中验证了方法的优势。

Abstract: One of the main challenges in distributed learning arises from the difficulty
of handling heterogeneous local models and data. In light of the recent success
of generative models, we propose to meet this challenge by building on the idea
of exchanging synthetic data instead of sharing model parameters. Local models
can then be treated as ``black boxes'' with the ability to learn their
parameters from data and to generate data according to these parameters.
Moreover, if the local models admit semi-supervised learning, we can extend the
approach by enabling local models on different probability spaces. This allows
to handle heterogeneous data with different modalities. We formulate the
learning of the local models as a cooperative game starting from the principles
of game theory. We prove the existence of a unique Nash equilibrium for
exponential family local models and show that the proposed learning approach
converges to this equilibrium. We demonstrate the advantages of our approach on
standard benchmark vision datasets for image classification and conditional
generation.

</details>


### [353] [HyperNQ: A Hypergraph Neural Network Decoder for Quantum LDPC Codes](https://arxiv.org/abs/2511.01741)
*Ameya S. Bhave,Navnil Choudhury,Kanad Basu*

Main category: cs.LG

TL;DR: HyperNQ是一种基于超图神经网络的QLDPC解码器，通过利用超边捕捉高阶稳定器约束，显著提升了量子纠错性能。


<details>
  <summary>Details</summary>
Motivation: 传统QLDPC解码方法（如BP和GNN）在短周期和高阶相关性捕捉方面表现不佳，需要更高效的解码策略。

Method: 提出HyperNQ，采用两阶段消息传递方案，利用超图神经网络捕捉高阶约束。

Result: 在伪阈值以下，HyperNQ将逻辑错误率（LER）比BP提升84%，比GNN提升50%。

Conclusion: HyperNQ在量子纠错解码中表现出色，优于现有最先进方法。

Abstract: Quantum computing requires effective error correction strategies to mitigate
noise and decoherence. Quantum Low-Density Parity-Check (QLDPC) codes have
emerged as a promising solution for scalable Quantum Error Correction (QEC)
applications by supporting constant-rate encoding and a sparse parity-check
structure. However, decoding QLDPC codes via traditional approaches such as
Belief Propagation (BP) suffers from poor convergence in the presence of short
cycles. Machine learning techniques like Graph Neural Networks (GNNs) utilize
learned message passing over their node features; however, they are restricted
to pairwise interactions on Tanner graphs, which limits their ability to
capture higher-order correlations. In this work, we propose HyperNQ, the first
Hypergraph Neural Network (HGNN)- based QLDPC decoder that captures
higher-order stabilizer constraints by utilizing hyperedges-thus enabling
highly expressive and compact decoding. We use a two-stage message passing
scheme and evaluate the decoder over the pseudo-threshold region. Below the
pseudo-threshold mark, HyperNQ improves the Logical Error Rate (LER) up to 84%
over BP and 50% over GNN-based strategies, demonstrating enhanced performance
over the existing state-of-the-art decoders.

</details>


### [354] [Towards Efficient Federated Learning of Networked Mixture-of-Experts for Mobile Edge Computing](https://arxiv.org/abs/2511.01743)
*Song Gao,Shusen Jing,Shuai Zhang,Yue Wang,Xiangwei Zhou,Songyang Zhang*

Main category: cs.LG

TL;DR: 论文提出了一种名为NMoE的系统，通过协作推理和联邦学习解决边缘设备训练和部署大型AI模型的挑战。


<details>
  <summary>Details</summary>
Motivation: 大型AI模型在移动边缘计算中的资源需求与边缘设备的有限能力之间存在冲突，需要高效且隐私保护的解决方案。

Method: 采用Networked Mixture-of-Experts (NMoE)系统，结合联邦学习框架，平衡个性化和泛化。

Result: 通过实验验证了NMoE系统的有效性，并提供了训练算法的基准。

Conclusion: NMoE系统为边缘设备上的大型AI模型训练和部署提供了可行的解决方案。

Abstract: Recent advancements in large artificial intelligence models (LAMs) are
driving significant innovations in mobile edge computing within next-generation
wireless networks. However, the substantial demands for computational resources
and large-scale training data required to train LAMs conflict with the limited
storage and computational capacity of edge devices, posing significant
challenges to training and deploying LAMs at the edge. In this work, we
introduce the Networked Mixture-of-Experts (NMoE) system, in which clients
infer collaboratively by distributing tasks to suitable neighbors based on
their expertise and aggregate the returned results. For training the NMoE, we
propose a federated learning framework that integrates both supervised and
self-supervised learning to balance personalization and generalization, while
preserving communication efficiency and data privacy. We conduct extensive
experiments to demonstrate the efficacy of the proposed NMoE system, providing
insights and benchmarks for the NMoE training algorithms.

</details>


### [355] [An Open-Access Benchmark of Statistical and Machine-Learning Anomaly Detection Methods for Battery Applications](https://arxiv.org/abs/2511.01745)
*Mei-Chin Pang,Suraj Adhikari,Takuma Kasahara,Nagihiro Haba,Saneyuki Ohno*

Main category: cs.LG

TL;DR: OSBAD是一个开源基准测试工具，用于电池应用中的异常检测框架，通过比较多种算法和数据集，提升异常检测的可靠性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 电池安全在消费电子、电动汽车和飞机等领域至关重要，未检测到的异常可能导致安全隐患或高昂的停机成本。

Method: OSBAD通过15种不同算法（统计、距离和无监督机器学习）进行系统比较，并提出基于物理和统计的特征转换工作流和贝叶斯优化管道。

Result: OSBAD在液体和固态化学数据集上验证了其跨化学泛化能力，并提供了开源可复现的工作流。

Conclusion: OSBAD为电池分析中的异常检测工具提供了统一基础，强调了物理和统计特征工程以及概率超参数调优的重要性。

Abstract: Battery safety is critical in applications ranging from consumer electronics
to electric vehicles and aircraft, where undetected anomalies could trigger
safety hazards or costly downtime. In this study, we present OSBAD as an
open-source benchmark for anomaly detection frameworks in battery applications.
By benchmarking 15 diverse algorithms encompassing statistical, distance-based,
and unsupervised machine-learning methods, OSBAD enables a systematic
comparison of anomaly detection methods across heterogeneous datasets. In
addition, we demonstrate how a physics- and statistics-informed feature
transformation workflow enhances anomaly separability by decomposing collective
anomalies into point anomalies. To address a major bottleneck in unsupervised
anomaly detection due to incomplete labels, we propose a Bayesian optimization
pipeline that facilitates automated hyperparameter tuning based on
transfer-learning and regression proxies. Through validation on datasets
covering both liquid and solid-state chemistries, we further demonstrate the
cross-chemistry generalization capability of OSBAD to identify irregularities
across different electrochemical systems. By making benchmarking database with
open-source reproducible anomaly detection workflows available to the
community, OSBAD establishes a unified foundation for developing safe,
scalable, and transferable anomaly detection tools in battery analytics. This
research underscores the significance of physics- and statistics-informed
feature engineering as well as model selection with probabilistic
hyperparameter tuning, in advancing trustworthy, data-driven diagnostics for
safety-critical energy systems.

</details>


### [356] [RLAC: Reinforcement Learning with Adversarial Critic for Free-Form Generation Tasks](https://arxiv.org/abs/2511.01758)
*Mian Wu,Gavin Zhang,Sewon Min,Sergey Levine,Aviral Kumar*

Main category: cs.LG

TL;DR: RLAC通过动态评估和对抗性批评优化生成任务，减少验证成本并提升输出质量。


<details>
  <summary>Details</summary>
Motivation: 开放式生成任务需要满足多样且隐式的评估标准，但验证成本高且评估不完整，RL训练难以扩展。

Method: RLAC利用LLM作为动态批评器，识别潜在失败模式，并与生成器联合优化，减少验证需求。

Result: 实验显示RLAC在文本生成和代码生成中提升准确性和正确性，优于传统方法。

Conclusion: RLAC展示了动态批评器在扩展RL后训练中的潜力，适用于自由形式生成任务。

Abstract: Open-ended generation tasks require outputs to satisfy diverse and often
implicit task-specific evaluation rubrics. The sheer number of relevant rubrics
leads to prohibitively high verification costs and incomplete assessments of a
response, making reinforcement learning (RL) post-training with rubric-based
rewards difficult to scale. This problem is exacerbated by the fact that often
the best way to combine these rubrics into one single reward is also highly
prompt-specific. We propose Reinforcement Learning with Adversarial Critic
(RLAC), a post-training approach that addresses these challenges via dynamic
rubric verification. Our approach employs a large language model (LLM) as a
critic that dynamically identifies only the most likely failure modes (e.g., a
factual error or unhandled edge case), which are then verified by an external
validator to optimize both generator and critic jointly. By training both the
generator and the critic, this game enhances the critic's error detection and
the generator's output quality while reducing required verifications. Our
experiments demonstrate that RLAC improves factual accuracy in text generation
and correctness in code generation, while also outperforming exhaustive
verification and reward model methods. We show that dynamic critics are more
effective than fixed critics, showcasing the potential of RLAC for scaling RL
post-training to free-form generation tasks.

</details>


### [357] [Random Initialization of Gated Sparse Adapters](https://arxiv.org/abs/2511.01794)
*Vi Retault,Yohaï-Eliel Berreby*

Main category: cs.LG

TL;DR: RIGSA是一种通过随机初始化和稀疏化适配器来减少语言模型微调中灾难性遗忘的方法，相比QLoRA表现更好。


<details>
  <summary>Details</summary>
Motivation: 解决语言模型微调中的灾难性遗忘问题，提出一种不依赖低秩约束的稀疏适配方法。

Method: 使用随机初始化的全秩适配器，通过ReZero门控和迭代幅度剪枝实现稀疏化。

Result: RIGSA在Textual MNIST任务上表现良好，且在GSM8k等任务上遗忘较少。

Conclusion: RIGSA提供了一种有效的稀疏适配方法，减少了灾难性遗忘，性能优于QLoRA。

Abstract: When fine-tuning language models on new tasks, catastrophic forgetting --
performance degradation on previously-learned tasks -- is a ubiquitous problem.
While Parameter-Efficient Fine-Tuning (PEFT) methods like LoRA address this
through low-rank adapters, sparse adaptation offers an alternative that doesn't
impose rank constraints. We introduce Random Initialization of Gated Sparse
Adapters (RIGSA), which starts from randomly-initialized full-rank adapters,
gates them with a ReZero analog, and sparsifies them with iterative magnitude
pruning. We evaluate RIGSA on SmolLM2-1.7B-Instruct using a novel
vision-in-text task (Textual MNIST) and measure forgetting on PIQA, HellaSwag,
and GSM8k. SmolLM2-1.7B-Instruct initially performs around chance level on
Textual MNIST, and is capable of learning the task through RIGSA, 4-bit QLoRA
and random masking. In spite of having more trainable parameters than QLoRA,
the RIGSA configurations that we studied displayed less forgetting than QLoRA,
particularly on GSM8k, though it performs comparably to random masking.

</details>


### [358] [Bayesian Coreset Optimization for Personalized Federated Learning](https://arxiv.org/abs/2511.01800)
*Prateek Chanda,Shrey Modi,Ganesh Ramakrishnan*

Main category: cs.LG

TL;DR: 提出了一种基于个性化核心集加权的联邦学习方法（$\methodprop$），通过仅使用客户端的核心集代表数据点而非全部数据来优化训练更新，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 在联邦学习中，每个客户端训练整个数据集的计算负担较大，因此需要一种更高效的方法来减少计算量并保持性能。

Method: 采用个性化核心集加权策略，仅使用核心集代表数据点进行训练更新，并通过理论分析证明其泛化误差的最优性。

Result: 实验表明，该方法在多个基准数据集和医疗数据集上优于随机采样和其他子模优化方法。

Conclusion: 智能选择训练样本可以显著提升联邦学习的性能，尤其是在计算资源有限的情况下。

Abstract: In a distributed machine learning setting like Federated Learning where there
are multiple clients involved which update their individual weights to a single
central server, often training on the entire individual client's dataset for
each client becomes cumbersome. To address this issue we propose $\methodprop$:
a personalized coreset weighted federated learning setup where the training
updates for each individual clients are forwarded to the central server based
on only individual client coreset based representative data points instead of
the entire client data. Through theoretical analysis we present how the average
generalization error is minimax optimal up to logarithm bounds (upper bounded
by $\mathcal{O}(n_k^{-\frac{2 \beta}{2 \beta+\boldsymbol{\Lambda}}} \log ^{2
\delta^{\prime}}(n_k))$) and lower bounds of $\mathcal{O}(n_k^{-\frac{2
\beta}{2 \beta+\boldsymbol{\Lambda}}})$, and how the overall generalization
error on the data likelihood differs from a vanilla Federated Learning setup as
a closed form function ${\boldsymbol{\Im}}(\boldsymbol{w}, n_k)$ of the coreset
weights $\boldsymbol{w}$ and coreset sample size $n_k$. Our experiments on
different benchmark datasets based on a variety of recent personalized
federated learning architectures show significant gains as compared to random
sampling on the training data followed by federated learning, thereby
indicating how intelligently selecting such training samples can help in
performance. Additionally, through experiments on medical datasets our proposed
method showcases some gains as compared to other submodular optimization based
approaches used for subset selection on client's data.

</details>


### [359] [Dynamic Reconstruction of Ultrasound-Derived Flow Fields With Physics-Informed Neural Fields](https://arxiv.org/abs/2511.01804)
*Viraj Patel,Lisa Kreusser,Katharine Fraser*

Main category: cs.LG

TL;DR: 提出了一种基于物理信息神经场模型的方法，用于从稀疏和噪声超声数据中估计血流，无需真实监督。


<details>
  <summary>Details</summary>
Motivation: 超声成像在血流分析中受限于深度衰减和噪声，传统方法难以准确测量血流速度。

Method: 采用多尺度傅里叶特征编码的物理信息神经场模型，结合物理约束提升鲁棒性。

Result: 模型在合成和真实数据上均表现出低均方误差，验证了其有效性。

Conclusion: 该方法为超声血流重建提供了新思路，适用于复杂血流动力学场景。

Abstract: Blood flow is sensitive to disease and provides insight into cardiac
function, making flow field analysis valuable for diagnosis. However, while
safer than radiation-based imaging and more suitable for patients with medical
implants, ultrasound suffers from attenuation with depth, limiting the quality
of the image. Despite advances in echocardiographic particle image velocimetry
(EchoPIV), accurately measuring blood velocity remains challenging due to the
technique's limitations and the complexity of blood flow dynamics.
Physics-informed machine learning can enhance accuracy and robustness,
particularly in scenarios where noisy or incomplete data challenge purely
data-driven approaches. We present a physics-informed neural field model with
multi-scale Fourier Feature encoding for estimating blood flow from sparse and
noisy ultrasound data without requiring ground truth supervision. We
demonstrate that this model achieves consistently low mean squared error in
denoising and inpainting both synthetic and real datasets, verified against
reference flow fields and ground truth flow rate measurements. While
physics-informed neural fields have been widely used to reconstruct medical
images, applications to medical flow reconstruction are mostly prominent in
Flow MRI. In this work, we adapt methods that have proven effective in other
imaging modalities to address the specific challenge of ultrasound-based flow
reconstruction.

</details>


### [360] [No-rank Tensor Decomposition Using Metric Learning](https://arxiv.org/abs/2511.01816)
*Maryam Bagherian*

Main category: cs.LG

TL;DR: 论文提出了一种基于度量学习的无秩张量分解框架，通过优化三元组损失和正则化，学习数据驱动的嵌入空间，显著提升了语义相似性分析的性能。


<details>
  <summary>Details</summary>
Motivation: 传统张量分解方法在高维数据分析中难以捕捉语义结构，因此需要一种新的框架来优化语义相似性而非重建目标。

Method: 采用度量学习方法，优化三元组损失并结合多样性和均匀性正则化，构建反映语义相似性的特征空间。

Result: 在多个领域（如人脸识别、脑连接分析等）中表现优于基线方法，尤其在聚类指标上显著提升。

Conclusion: 该工作确立了度量学习在张量分析中的新范式，强调语义相关性而非像素级保真度，适用于数据稀缺场景。

Abstract: Tensor decomposition faces fundamental challenges in analyzing
high-dimensional data, where traditional methods based on reconstruction and
fixed-rank constraints often fail to capture semantically meaningful
structures. This paper introduces a no-rank tensor decomposition framework
grounded in metric learning, which replaces reconstruction objectives with a
discriminative, similarity-based optimization. The proposed approach learns
data-driven embeddings by optimizing a triplet loss with diversity and
uniformity regularization, creating a feature space where distance directly
reflects semantic similarity. We provide theoretical guarantees for the
framework's convergence and establish bounds on its metric properties.
Evaluations across diverse domains --including face recognition (LFW,
Olivetti), brain connectivity analysis (ABIDE), and simulated data (galaxy
morphology, crystal structures)-- demonstrate that our method outperforms
baseline techniques, including PCA, t-SNE, UMAP, and tensor decomposition
baselines (CP and Tucker). Results show substantial improvements in clustering
metrics (Silhouette Score, Davies--Bouldin Index, Calinski--Harabasz Index,
Separation Ratio, Adjusted Rand Index, Normalized Mutual Information) and
reveal a fundamental trade-off: while metric learning optimizes global class
separation, it deliberately transforms local geometry to align with semantic
relationships. Crucially, our approach achieves superior performance with
smaller training datasets compared to transformer-based methods, offering an
efficient alternative for domains with limited labeled data. This work
establishes metric learning as a paradigm for tensor-based analysis,
prioritizing semantic relevance over pixel-level fidelity while providing
computational advantages in data-scarce scenarios.

</details>


### [361] [Machine and Deep Learning for Indoor UWB Jammer Localization](https://arxiv.org/abs/2511.01819)
*Hamed Fard,Mahsa Kholghi,Benedikt Groß,Gerhard Wunder*

Main category: cs.LG

TL;DR: 论文提出了一种对抗性特征对齐方法（A-CNT），用于在室内环境变化时实现鲁棒的UWB干扰源定位，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: UWB定位在智能建筑中易受干扰攻击，现有方法在环境变化时性能下降严重，需要一种鲁棒的解决方案。

Method: 提出了基于梯度反转层的域对抗ConvNeXt自编码器（A-CNT），用于跨域对齐CIR特征。

Result: A-CNT将平均欧几里得误差降至34.67 cm，比非对抗迁移学习提升77%，比最佳基线提升83%。

Conclusion: 对抗性特征对齐能有效应对环境变化，实现鲁棒的干扰源定位。

Abstract: Ultra-wideband (UWB) localization delivers centimeter-scale accuracy but is
vulnerable to jamming attacks, creating security risks for asset tracking and
intrusion detection in smart buildings. Although machine learning (ML) and deep
learning (DL) methods have improved tag localization, localizing malicious
jammers within a single room and across changing indoor layouts remains largely
unexplored. Two novel UWB datasets, collected under original and modified room
configurations, are introduced to establish comprehensive ML/DL baselines.
Performance is rigorously evaluated using a variety of classification and
regression metrics. On the source dataset with the collected UWB features,
Random Forest achieves the highest F1-macro score of 0.95 and XGBoost achieves
the lowest mean Euclidean error of 20.16 cm. However, deploying these
source-trained models in the modified room layout led to severe performance
degradation, with XGBoost's mean Euclidean error increasing tenfold to 207.99
cm, demonstrating significant domain shift. To mitigate this degradation, a
domain-adversarial ConvNeXt autoencoder (A-CNT) is proposed that leverages a
gradient-reversal layer to align CIR-derived features across domains. The A-CNT
framework restores localization performance by reducing the mean Euclidean
error to 34.67 cm. This represents a 77 percent improvement over
non-adversarial transfer learning and an 83 percent improvement over the best
baseline, restoring the fraction of samples within 30 cm to 0.56. Overall, the
results demonstrate that adversarial feature alignment enables robust and
transferable indoor jammer localization despite environmental changes. Code and
dataset available at https://github.com/afbf4c8996f/Jammer-Loc

</details>


### [362] [Towards Multi-Fidelity Scaling Laws of Neural Surrogates in CFD](https://arxiv.org/abs/2511.01830)
*Paul Setinek,Gianluca Galletti,Johannes Brandstetter*

Main category: cs.LG

TL;DR: 论文研究了科学机器学习中数据保真度与计算成本之间的权衡，通过多保真度数据集重新定义了经典的缩放定律。


<details>
  <summary>Details</summary>
Motivation: 科学机器学习中生成高保真度数据的成本高昂，而通过调整建模假设可以降低计算成本，但缺乏对此的系统研究。

Method: 使用低保真度和高保真度的RANS模拟数据，重新定义缩放定律，将数据集轴分解为计算预算和数据集组成。

Result: 实验揭示了计算性能的缩放行为，并展示了预算依赖的最佳保真度混合。

Conclusion: 这是首次对多保真度神经代理数据集的缩放定律进行实证研究，为科学机器学习中高效计算的数据集生成提供了实用建议。

Abstract: Scaling laws describe how model performance grows with data, parameters and
compute. While large datasets can usually be collected at relatively low cost
in domains such as language or vision, scientific machine learning is often
limited by the high expense of generating training data through numerical
simulations. However, by adjusting modeling assumptions and approximations,
simulation fidelity can be traded for computational cost, an aspect absent in
other domains. We investigate this trade-off between data fidelity and cost in
neural surrogates using low- and high-fidelity Reynolds-Averaged Navier-Stokes
(RANS) simulations. Reformulating classical scaling laws, we decompose the
dataset axis into compute budget and dataset composition. Our experiments
reveal compute-performance scaling behavior and exhibit budget-dependent
optimal fidelity mixes for the given dataset configuration. These findings
provide the first study of empirical scaling laws for multi-fidelity neural
surrogate datasets and offer practical considerations for compute-efficient
dataset generation in scientific machine learning.

</details>


### [363] [Dynamic Routing Between Experts: A Data-Efficient Approach to Continual Learning in Vision-Language Models](https://arxiv.org/abs/2511.01831)
*Jay Mohta,Kenan Emir Ak,Dimitrios Dimitriadis,Yan Xu,Mingwei Shen*

Main category: cs.LG

TL;DR: 提出了一种基于路由的方法，用于在连续微调新任务时防止视觉语言模型（VLMs）的灾难性遗忘，同时保留基础知识和任务特定能力。


<details>
  <summary>Details</summary>
Motivation: 解决VLMs在连续微调新任务时的灾难性遗忘问题，避免传统多任务学习的高计算和数据开销。

Method: 采用路由机制，允许新任务的集成而不需要同时访问所有任务的数据。

Result: 在InternVL-2模型上验证，路由方法在保持基础能力的同时提升了专业任务性能，且支持跨模态知识迁移。

Conclusion: 路由方法有效解决了灾难性遗忘问题，具有可扩展性和鲁棒性，优于现有持续学习方法。

Abstract: Vision-Language Models (VLMs) suffer from catastrophic forgetting when
sequentially fine-tuned on new tasks, degrading performance on previously
learned foundational and task-specific capabilities. While multi-task learning
can mitigate forgetting, it requires simultaneous access to all datasets and
imposes computational overhead that scales linearly with the number of tasks.
In this work, we introduce a routing-based approach that enables the
integration of new tasks while preserving the foundational knowledge acquired
during pretraining. We evaluate our method using InternVL-2 models (2B and 8B
parameters) and demonstrate that routing preserves the model's foundational
capabilities by maintaining performance on general-purpose benchmarks such as
ChartQA, MMBench, and DocVQA, while simultaneously improving accuracy on
specialized tasks. Importantly, our approach achieves this without requiring
concurrent access to data from all tasks, avoiding the significant
computational and data overhead associated with traditional multi-task
learning. We further conduct extensive ablation studies to evaluate the
scalability and robustness of routing-based learning, showing that the approach
is resilient to a growing number of tasks and performs particularly well when
new tasks are semantically related. Finally, we show that the routing mechanism
enables superior cross-modal transfer between language and vision capabilities,
allowing knowledge learned in one modality to enhance performance in another
capability not achieved by existing continual learning methods.

</details>


### [364] [Priors in Time: Missing Inductive Biases for Language Model Interpretability](https://arxiv.org/abs/2511.01836)
*Ekdeep Singh Lubana,Can Rager,Sai Sumedh R. Hindupur,Valerie Costa,Greta Tuckute,Oam Patel,Sonia Krishna Murthy,Thomas Fel,Daniel Wurgaft,Eric J. Bigelow,Johnny Lin,Demba Ba,Martin Wattenberg,Fernanda Viegas,Melanie Weber,Aaron Mueller*

Main category: cs.LG

TL;DR: 论文提出了一种新的可解释性方法——时间特征分析，以解决现有稀疏自编码器（SAEs）在处理语言模型激活时忽略时间动态的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法假设概念在时间上是独立的，但语言模型表示具有丰富的时序动态，如概念维度的增长、上下文相关性和非平稳性，这与SAEs的假设冲突。

Method: 受计算神经科学启发，提出时间特征分析，将表示分解为可预测部分和残差部分，前者来自上下文，后者捕捉新信息。

Result: 时间特征分析能正确解析花园路径句、识别事件边界，并区分抽象慢速信息与新颖快速信息，而SAEs在这些任务中表现不佳。

Conclusion: 结果表明，设计可解释性工具时需要与数据匹配的归纳偏置。

Abstract: Recovering meaningful concepts from language model activations is a central
aim of interpretability. While existing feature extraction methods aim to
identify concepts that are independent directions, it is unclear if this
assumption can capture the rich temporal structure of language. Specifically,
via a Bayesian lens, we demonstrate that Sparse Autoencoders (SAEs) impose
priors that assume independence of concepts across time, implying stationarity.
Meanwhile, language model representations exhibit rich temporal dynamics,
including systematic growth in conceptual dimensionality, context-dependent
correlations, and pronounced non-stationarity, in direct conflict with the
priors of SAEs. Taking inspiration from computational neuroscience, we
introduce a new interpretability objective -- Temporal Feature Analysis --
which possesses a temporal inductive bias to decompose representations at a
given time into two parts: a predictable component, which can be inferred from
the context, and a residual component, which captures novel information
unexplained by the context. Temporal Feature Analyzers correctly parse garden
path sentences, identify event boundaries, and more broadly delineate abstract,
slow-moving information from novel, fast-moving information, while existing
SAEs show significant pitfalls in all the above tasks. Overall, our results
underscore the need for inductive biases that match the data in designing
robust interpretability tools.

</details>


### [365] [Interpretable Machine Learning for Reservoir Water Temperatures in the U.S. Red River Basin of the South](https://arxiv.org/abs/2511.01837)
*Isabela Suaza-Sierra,Hernan A. Moreno,Luis A De la Fuente,Thomas M. Neeson*

Main category: cs.LG

TL;DR: 结合可解释机器学习和符号建模预测水库水温，揭示物理驱动因素，平衡预测精度与模型可解释性。


<details>
  <summary>Details</summary>
Motivation: 水库水温预测对可持续水资源管理、生态系统健康和气候韧性至关重要，但传统预测方法无法揭示其物理驱动机制。

Method: 集成随机森林、XGBoost和多层感知机等模型，结合SHAP分析物理驱动因素，并开发Kolmogorov Arnold Networks（KANs）生成符号表达式。

Result: 最佳模型RMSE为1.20°C，R²达0.97；KANs生成的符号表达式R²从0.84（单预测变量）提升至0.92（十预测变量）。

Conclusion: KANs和可解释机器学习能将黑盒模型转化为透明替代模型，提升水库热动力学的预测与理解。

Abstract: Accurate prediction of Reservoir Water Temperature (RWT) is vital for
sustainable water management, ecosystem health, and climate resilience. Yet,
prediction alone offers limited insight into the governing physical processes.
To bridge this gap, we integrated explainable machine learning (ML) with
symbolic modeling to uncover the drivers of RWT dynamics across ten reservoirs
in the Red River Basin, USA, using over 10,000 depth-resolved temperature
profiles. We first employed ensemble and neural models, including Random Forest
(RF), Extreme Gradient Boosting (XGBoost), and Multilayer Perceptron (MLP),
achieving high predictive skill (best RMSE = 1.20 degree Celsius, R^2 = 0.97).
Using SHAP (SHapley Additive exPlanations), we quantified the contribution of
physical drivers such as air temperature, depth, wind, and lake volume,
revealing consistent patterns across reservoirs. To translate these data-driven
insights into compact analytical expressions, we developed Kolmogorov Arnold
Networks (KANs) to symbolically approximate RWT. Ten progressively complex KAN
equations were derived, improving from R^2 = 0.84 using a single predictor
(7-day antecedent air temperature) to R^2 = 0.92 with ten predictors, though
gains diminished beyond five, highlighting a balance between simplicity and
accuracy. The resulting equations, dominated by linear and rational forms,
incrementally captured nonlinear behavior while preserving interpretability.
Depth consistently emerged as a secondary but critical predictor, whereas
precipitation had limited effect. By coupling predictive accuracy with
explanatory power, this framework demonstrates how KANs and explainable ML can
transform black-box models into transparent surrogates that advance both
prediction and understanding of reservoir thermal dynamics.

</details>


### [366] [Bridging Lifelong and Multi-Task Representation Learning via Algorithm and Complexity Measure](https://arxiv.org/abs/2511.01847)
*Zhi Wang,Chicheng Zhang,Ramya Korlakai Vinayak*

Main category: cs.LG

TL;DR: 提出了一种终身表示学习的通用框架，通过多任务经验风险最小化算法，并引入任务逃避维度来量化样本复杂度。


<details>
  <summary>Details</summary>
Motivation: 终身学习需要在线利用现有知识逐步学习共享表示，而现有方法如多任务学习或学习到学习需要任务预先可用。

Method: 提出了一种基于多任务经验风险最小化的简单算法，并引入任务逃避维度来分析样本复杂度。

Result: 该框架适用于广泛的函数类学习问题，并在噪声下的分类和回归任务中实例化了结果。

Conclusion: 通过任务逃避维度，为终身表示学习提供了理论保证，扩展了其在噪声环境中的应用。

Abstract: In lifelong learning, a learner faces a sequence of tasks with shared
structure and aims to identify and leverage it to accelerate learning. We study
the setting where such structure is captured by a common representation of
data. Unlike multi-task learning or learning-to-learn, where tasks are
available upfront to learn the representation, lifelong learning requires the
learner to make use of its existing knowledge while continually gathering
partial information in an online fashion. In this paper, we consider a
generalized framework of lifelong representation learning. We propose a simple
algorithm that uses multi-task empirical risk minimization as a subroutine and
establish a sample complexity bound based on a new notion we introduce--the
task-eluder dimension. Our result applies to a wide range of learning problems
involving general function classes. As concrete examples, we instantiate our
result on classification and regression tasks under noise.

</details>


### [367] [Coordinate ascent neural Kalman-MLE for state estimation](https://arxiv.org/abs/2511.01855)
*Bettina Hanlon,Angel Garcia Fernandez*

Main category: cs.LG

TL;DR: 提出了一种基于坐标上升算法的动态状态估计方法，通过最大似然估计学习动态和测量模型。


<details>
  <summary>Details</summary>
Motivation: 动态状态估计中，动态和测量模型的准确性对状态估计至关重要，但传统方法可能无法充分捕捉复杂非线性关系。

Method: 假设动态和测量模型为高斯分布，使用神经网络建模动态和测量函数及噪声协方差矩阵，通过坐标上升算法优化参数。

Result: 训练后的模型与非线性卡尔曼滤波器结合，在测试阶段实现了准确的状态估计。

Conclusion: 该方法通过学习动态和测量模型，提升了动态状态估计的准确性。

Abstract: This paper presents a coordinate ascent algorithm to learn dynamic and
measurement models in dynamic state estimation using maximum likelihood
estimation in a supervised manner. In particular, the dynamic and measurement
models are assumed to be Gaussian and the algorithm learns the neural network
parameters that model the dynamic and measurement functions, and also the noise
covariance matrices. The trained dynamic and measurement models are then used
with a non-linear Kalman filter algorithm to estimate the state during the
testing phase.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [368] [Gen AI in Automotive: Applications, Challenges, and Opportunities with a Case study on In-Vehicle Experience](https://arxiv.org/abs/2511.00026)
*Chaitanya Shinde,Divya Garikapati*

Main category: cs.RO

TL;DR: 本文综述了生成式人工智能（GenAI）在汽车行业的应用，包括设计、制造、自动驾驶等领域，并探讨了其机遇与挑战。


<details>
  <summary>Details</summary>
Motivation: 探索GenAI如何通过生成对抗网络等技术推动汽车行业的创新，同时解决技术、伦理和安全问题。

Method: 通过文献综述和奔驰MBUX虚拟助手的案例研究，分析GenAI的应用与挑战。

Result: GenAI在加速自动驾驶验证、优化设计和提升人机交互方面具有潜力，但也面临计算需求、偏见等问题。

Conclusion: GenAI在汽车行业前景广阔，但需进一步研究以实现安全、高效和用户为中心的部署。

Abstract: Generative Artificial Intelligence is emerging as a transformative force in
the automotive industry, enabling novel applications across vehicle design,
manufacturing, autonomous driving, predictive maintenance, and in vehicle user
experience. This paper provides a comprehensive review of the current state of
GenAI in automotive, highlighting enabling technologies such as Generative
Adversarial Networks and Variational Autoencoders. Key opportunities include
accelerating autonomous driving validation through synthetic data generation,
optimizing component design, and enhancing human machine interaction via
personalized and adaptive interfaces. At the same time, the paper identifies
significant technical, ethical, and safety challenges, including computational
demands, bias, intellectual property concerns, and adversarial robustness, that
must be addressed for responsible deployment. A case study on Mercedes Benzs
MBUX Virtual Assistant illustrates how GenAI powered voice systems deliver more
natural, proactive, and personalized in car interactions compared to legacy
rule based assistants. Through this review and case study, the paper outlines
both the promise and limitations of GenAI integration in the automotive sector
and presents directions for future research and development aimed at achieving
safer, more efficient, and user centric mobility. Unlike prior reviews that
focus solely on perception or manufacturing, this paper emphasizes generative
AI in voice based HMI, bridging safety and user experience perspectives.

</details>


### [369] [STRIDER: Navigation via Instruction-Aligned Structural Decision Space Optimization](https://arxiv.org/abs/2511.00033)
*Diqi He,Xuehao Gao,Hao Li,Junwei Han,Dingwen Zhang*

Main category: cs.RO

TL;DR: STRIDER框架通过整合空间布局先验和动态任务反馈，显著提升了零样本视觉与语言导航任务的性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在零样本视觉与语言导航任务中因缺乏结构化决策和动作反馈整合而表现不佳的问题。

Method: 提出STRIDER框架，包含结构化路径点生成器和任务对齐调节器，优化决策空间。

Result: 在R2R-CE和RxR-CE基准测试中，成功率达到35%，相对提升20.7%。

Conclusion: 空间约束决策和反馈引导执行对提升零样本导航任务性能至关重要。

Abstract: The Zero-shot Vision-and-Language Navigation in Continuous Environments
(VLN-CE) task requires agents to navigate previously unseen 3D environments
using natural language instructions, without any scene-specific training. A
critical challenge in this setting lies in ensuring agents' actions align with
both spatial structure and task intent over long-horizon execution. Existing
methods often fail to achieve robust navigation due to a lack of structured
decision-making and insufficient integration of feedback from previous actions.
To address these challenges, we propose STRIDER (Instruction-Aligned Structural
Decision Space Optimization), a novel framework that systematically optimizes
the agent's decision space by integrating spatial layout priors and dynamic
task feedback. Our approach introduces two key innovations: 1) a Structured
Waypoint Generator that constrains the action space through spatial structure,
and 2) a Task-Alignment Regulator that adjusts behavior based on task progress,
ensuring semantic alignment throughout navigation. Extensive experiments on the
R2R-CE and RxR-CE benchmarks demonstrate that STRIDER significantly outperforms
strong SOTA across key metrics; in particular, it improves Success Rate (SR)
from 29% to 35%, a relative gain of 20.7%. Such results highlight the
importance of spatially constrained decision-making and feedback-guided
execution in improving navigation fidelity for zero-shot VLN-CE.

</details>


### [370] [Endowing GPT-4 with a Humanoid Body: Building the Bridge Between Off-the-Shelf VLMs and the Physical World](https://arxiv.org/abs/2511.00041)
*Yingzhao Jian,Zhongan Wang,Yi Yang,Hehe Fan*

Main category: cs.RO

TL;DR: BiBo利用现成的视觉语言模型（如GPT-4）控制人形代理，减少数据收集需求，通过指令编译器和运动执行器实现高效交互。


<details>
  <summary>Details</summary>
Motivation: 解决人形代理在开放环境中交互能力不足的问题，避免昂贵的大规模数据收集。

Method: BiBo包含指令编译器（将高级指令转换为低级命令）和扩散运动执行器（生成适应性运动）。

Result: 在开放环境中任务成功率90.2%，运动执行精度提升16.3%。

Conclusion: BiBo通过现成模型有效提升人形代理的交互能力，减少数据依赖。

Abstract: Humanoid agents often struggle to handle flexible and diverse interactions in
open environments. A common solution is to collect massive datasets to train a
highly capable model, but this approach can be prohibitively expensive. In this
paper, we explore an alternative solution: empowering off-the-shelf
Vision-Language Models (VLMs, such as GPT-4) to control humanoid agents,
thereby leveraging their strong open-world generalization to mitigate the need
for extensive data collection. To this end, we present \textbf{BiBo}
(\textbf{B}uilding humano\textbf{I}d agent \textbf{B}y \textbf{O}ff-the-shelf
VLMs). It consists of two key components: (1) an \textbf{embodied instruction
compiler}, which enables the VLM to perceive the environment and precisely
translate high-level user instructions (e.g., {\small\itshape ``have a rest''})
into low-level primitive commands with control parameters (e.g.,
{\small\itshape ``sit casually, location: (1, 2), facing: 90$^\circ$''}); and
(2) a diffusion-based \textbf{motion executor}, which generates human-like
motions from these commands, while dynamically adapting to physical feedback
from the environment. In this way, BiBo is capable of handling not only basic
interactions but also diverse and complex motions. Experiments demonstrate that
BiBo achieves an interaction task success rate of 90.2\% in open environments,
and improves the precision of text-guided motion execution by 16.3\% over prior
methods. The code will be made publicly available.

</details>


### [371] [Alpamayo-R1: Bridging Reasoning and Action Prediction for Generalizable Autonomous Driving in the Long Tail](https://arxiv.org/abs/2511.00088)
*NVIDIA,:,Yan Wang,Wenjie Luo,Junjie Bai,Yulong Cao,Tong Che,Ke Chen,Yuxiao Chen,Jenna Diamond,Yifan Ding,Wenhao Ding,Liang Feng,Greg Heinrich,Jack Huang,Peter Karkus,Boyi Li,Pinyi Li,Tsung-Yi Lin,Dongran Liu,Ming-Yu Liu,Langechuan Liu,Zhijian Liu,Jason Lu,Yunxiang Mao,Pavlo Molchanov,Lindsey Pavao,Zhenghao Peng,Mike Ranzinger,Ed Schmerling,Shida Shen,Yunfei Shi,Sarah Tariq,Ran Tian,Tilman Wekel,Xinshuo Weng,Tianjun Xiao,Eric Yang,Xiaodong Yang,Yurong You,Xiaohui Zeng,Wenyuan Zhang,Boris Ivanovic,Marco Pavone*

Main category: cs.RO

TL;DR: AR1是一个结合因果推理与轨迹规划的视觉-语言-动作模型，显著提升了自动驾驶在复杂场景中的决策能力。


<details>
  <summary>Details</summary>
Motivation: 解决端到端模仿学习在长尾安全关键场景中监督稀疏和因果理解不足的问题。

Method: 1) 构建因果链数据集；2) 模块化VLA架构；3) 多阶段训练策略（监督微调+强化学习）。

Result: 规划准确率提升12%，脱轨率降低35%，推理质量提升45%。

Conclusion: AR1通过结合可解释推理与精确控制，为Level 4自动驾驶提供了实用路径。

Abstract: End-to-end architectures trained via imitation learning have advanced
autonomous driving by scaling model size and data, yet performance remains
brittle in safety-critical long-tail scenarios where supervision is sparse and
causal understanding is limited. To address this, we introduce Alpamayo-R1
(AR1), a vision-language-action model (VLA) that integrates Chain of Causation
reasoning with trajectory planning to enhance decision-making in complex
driving scenarios. Our approach features three key innovations: (1) the Chain
of Causation (CoC) dataset, built through a hybrid auto-labeling and
human-in-the-loop pipeline producing decision-grounded, causally linked
reasoning traces aligned with driving behaviors; (2) a modular VLA architecture
combining Cosmos-Reason, a Vision-Language Model pre-trained for Physical AI
applications, with a diffusion-based trajectory decoder that generates
dynamically feasible plans in real time; (3) a multi-stage training strategy
using supervised fine-tuning to elicit reasoning and reinforcement learning
(RL) to optimize reasoning quality via large reasoning model feedback and
enforce reasoning-action consistency. Evaluation shows AR1 achieves up to a 12%
improvement in planning accuracy on challenging cases compared to a
trajectory-only baseline, with a 35% reduction in off-road rate and 25%
reduction in close encounter rate in closed-loop simulation. RL post-training
improves reasoning quality by 45% as measured by a large reasoning model critic
and reasoning-action consistency by 37%. Model scaling from 0.5B to 7B
parameters shows consistent improvements. On-vehicle road tests confirm
real-time performance (99 ms latency) and successful urban deployment. By
bridging interpretable reasoning with precise control, AR1 demonstrates a
practical path towards Level 4 autonomous driving. We plan to release AR1
models and a subset of the CoC in a future update.

</details>


### [372] [Digital Twin based Automatic Reconfiguration of Robotic Systems in Smart Environments](https://arxiv.org/abs/2511.00094)
*Angelos Alexopoulos,Agorakis Bompotas,Nikitas Rigas Kalogeropoulos,Panagiotis Kechagias,Athanasios P. Kalogeras,Christos Alexakos*

Main category: cs.RO

TL;DR: 提出了一种基于数字孪生技术的机器人控制器自主动态重构框架，以应对动态环境中的适应性挑战。


<details>
  <summary>Details</summary>
Motivation: 传统控制系统在动态环境中难以快速适应，导致效率低下或操作失败。

Method: 利用数字孪生技术创建机器人操作环境的虚拟副本，模拟和优化运动轨迹，实时更新物理机器人的控制参数。

Result: 实现了快速可靠的自主适应，无需人工干预。

Conclusion: 该研究推动了数字孪生在机器人领域的应用，为智能动态环境中的自主性提升提供了可扩展的解决方案。

Abstract: Robotic systems have become integral to smart environments, enabling
applications ranging from urban surveillance and automated agriculture to
industrial automation. However, their effective operation in dynamic settings -
such as smart cities and precision farming - is challenged by continuously
evolving topographies and environmental conditions. Traditional control systems
often struggle to adapt quickly, leading to inefficiencies or operational
failures. To address this limitation, we propose a novel framework for
autonomous and dynamic reconfiguration of robotic controllers using Digital
Twin technology. Our approach leverages a virtual replica of the robot's
operational environment to simulate and optimize movement trajectories in
response to real-world changes. By recalculating paths and control parameters
in the Digital Twin and deploying the updated code to the physical robot, our
method ensures rapid and reliable adaptation without manual intervention. This
work advances the integration of Digital Twins in robotics, offering a scalable
solution for enhancing autonomy in smart, dynamic environments.

</details>


### [373] [Real-DRL: Teach and Learn in Reality](https://arxiv.org/abs/2511.00112)
*Yanbing Mao,Yihao Cai,Lui Sha*

Main category: cs.RO

TL;DR: Real-DRL框架通过结合DRL-Student、PHY-Teacher和Trigger三个组件，实现了在安全关键自主系统中的实时学习和安全优先策略。


<details>
  <summary>Details</summary>
Motivation: 解决安全关键自主系统中因未知因素和Sim2Real差距带来的安全挑战。

Method: 采用DRL-Student（双自学习和教学学习范式）、PHY-Teacher（基于物理模型的安全策略）和Trigger（管理交互）的交互式框架。

Result: 实验证明Real-DRL在四足机器人和倒立摆系统中具有高效性和独特的安全优先特性。

Conclusion: Real-DRL框架能够有效保障安全并实现高性能学习，适用于复杂物理系统。

Abstract: This paper introduces the Real-DRL framework for safety-critical autonomous
systems, enabling runtime learning of a deep reinforcement learning (DRL) agent
to develop safe and high-performance action policies in real plants (i.e., real
physical systems to be controlled), while prioritizing safety! The Real-DRL
consists of three interactive components: a DRL-Student, a PHY-Teacher, and a
Trigger. The DRL-Student is a DRL agent that innovates in the dual
self-learning and teaching-to-learn paradigm and the real-time safety-informed
batch sampling. On the other hand, PHY-Teacher is a physics-model-based design
of action policies that focuses solely on safety-critical functions.
PHY-Teacher is novel in its real-time patch for two key missions: i) fostering
the teaching-to-learn paradigm for DRL-Student and ii) backing up the safety of
real plants. The Trigger manages the interaction between the DRL-Student and
the PHY-Teacher. Powered by the three interactive components, the Real-DRL can
effectively address safety challenges that arise from the unknown unknowns and
the Sim2Real gap. Additionally, Real-DRL notably features i) assured safety,
ii) automatic hierarchy learning (i.e., safety-first learning and then
high-performance learning), and iii) safety-informed batch sampling to address
the learning experience imbalance caused by corner cases. Experiments with a
real quadruped robot, a quadruped robot in NVIDIA Isaac Gym, and a cart-pole
system, along with comparisons and ablation studies, demonstrate the Real-DRL's
effectiveness and unique features.

</details>


### [374] [End-to-End Dexterous Arm-Hand VLA Policies via Shared Autonomy: VR Teleoperation Augmented by Autonomous Hand VLA Policy for Efficient Data Collection](https://arxiv.org/abs/2511.00139)
*Yu Cui,Yujian Zhang,Lina Tao,Yang Li,Xinyu Yi,Zhibin Li*

Main category: cs.RO

TL;DR: 提出了一种共享自主框架，结合VR遥操作和自主策略，高效收集高质量协调臂手演示数据，并训练端到端VLA策略，实现90%的成功率。


<details>
  <summary>Details</summary>
Motivation: 解决通用机器人灵巧操作的高质量数据稀缺问题，现有方法存在人工操作负担重或运动不自然的限制。

Method: 采用共享自主框架，人类操作员通过VR控制宏观臂部动作，自主DexGrasp-VLA策略处理微观手部控制，结合触觉和视觉反馈。

Result: 高效收集高质量数据，训练的策略在多样物体上达到90%成功率，包括未见实例。

Conclusion: 框架有效降低了认知负荷，提升了灵巧操作能力，并通过人机协同持续改进策略。

Abstract: Achieving human-like dexterous manipulation remains a major challenge for
general-purpose robots. While Vision-Language-Action (VLA) models show
potential in learning skills from demonstrations, their scalability is limited
by scarce high-quality training data. Existing data collection methods face
inherent constraints: manual teleoperation overloads human operators, while
automated planning often produces unnatural motions. We propose a Shared
Autonomy framework that divides control between macro and micro motions. A
human operator guides the robot's arm pose through intuitive VR teleoperation,
while an autonomous DexGrasp-VLA policy handles fine-grained hand control using
real-time tactile and visual feedback. This division significantly reduces
cognitive load and enables efficient collection of high-quality coordinated
arm-hand demonstrations. Using this data, we train an end-to-end VLA policy
enhanced with our novel Arm-Hand Feature Enhancement module, which captures
both distinct and shared representations of macro and micro movements for more
natural coordination. Our Corrective Teleoperation system enables continuous
policy improvement through human-in-the-loop failure recovery. Experiments
demonstrate that our framework generates high-quality data with minimal
manpower and achieves a 90% success rate across diverse objects, including
unseen instances. Comprehensive evaluations validate the system's effectiveness
in developing dexterous manipulation capabilities.

</details>


### [375] [EgoMI: Learning Active Vision and Whole-Body Manipulation from Egocentric Human Demonstrations](https://arxiv.org/abs/2511.00153)
*Justin Yu,Yide Shentu,Di Wu,Pieter Abbeel,Ken Goldberg,Philipp Wu*

Main category: cs.RO

TL;DR: EgoMI框架通过同步捕捉人类操作中的手部和头部运动轨迹，解决了模仿学习中因机器人感知系统静态特性导致的数据分布偏移问题，并通过记忆增强策略提升性能。


<details>
  <summary>Details</summary>
Motivation: 人类在操作过程中会主动协调手部和头部运动，而静态机器人感知系统无法复制这种动态行为，导致模仿学习性能下降。

Method: 提出EgoMI框架，捕捉同步的手部和头部轨迹，并引入记忆增强策略以处理快速变化的头部视角。

Result: 在配备主动摄像头的双手机器人上，EgoMI的性能优于基线方法。

Conclusion: EgoMI通过协调手眼学习，有效缩小了人类与半人形机器人之间的感知差距，提升了模仿学习的鲁棒性。

Abstract: Imitation learning from human demonstrations offers a promising approach for
robot skill acquisition, but egocentric human data introduces fundamental
challenges due to the embodiment gap. During manipulation, humans actively
coordinate head and hand movements, continuously reposition their viewpoint and
use pre-action visual fixation search strategies to locate relevant objects.
These behaviors create dynamic, task-driven head motions that static robot
sensing systems cannot replicate, leading to a significant distribution shift
that degrades policy performance. We present EgoMI (Egocentric Manipulation
Interface), a framework that captures synchronized end-effector and active head
trajectories during manipulation tasks, resulting in data that can be
retargeted to compatible semi-humanoid robot embodiments. To handle rapid and
wide-spanning head viewpoint changes, we introduce a memory-augmented policy
that selectively incorporates historical observations. We evaluate our approach
on a bimanual robot equipped with an actuated camera head and find that
policies with explicit head-motion modeling consistently outperform baseline
methods. Results suggest that coordinated hand-eye learning with EgoMI
effectively bridges the human-robot embodiment gap for robust imitation
learning on semi-humanoid embodiments. Project page:
https://egocentric-manipulation-interface.github.io

</details>


### [376] [Reducing Robotic Upper-Limb Assessment Time While Maintaining Precision: A Time Series Foundation Model Approach](https://arxiv.org/abs/2511.00193)
*Faranak Akbarifar,Nooshin Maghsoodi,Sean P Dukelow,Stephen Scott,Parvin Mousavi*

Main category: cs.RO

TL;DR: 利用时间序列基础模型（如Chronos）预测未记录的试验，显著缩短Kinarm机器人视觉引导到达（VGR）评估时间，同时保持运动学参数的可靠性。


<details>
  <summary>Details</summary>
Motivation: 减少VGR评估中的时间和疲劳负担，同时保持运动学参数的可靠性。

Method: 使用ARIMA、MOMENT和Chronos模型，基于前8或16次到达试验预测合成试验，并重新计算运动学特征。

Result: Chronos模型仅需8次记录试验加预测，即可恢复ICC≥0.90的可靠性，与24-28次记录试验相当。

Conclusion: 基础模型预测可显著缩短评估时间，尤其对中风患者，评估时间从4-5分钟降至约1分钟，同时保持运动学精度。

Abstract: Purpose: Visually Guided Reaching (VGR) on the Kinarm robot yields sensitive
kinematic biomarkers but requires 40-64 reaches, imposing time and fatigue
burdens. We evaluate whether time-series foundation models can replace
unrecorded trials from an early subset of reaches while preserving the
reliability of standard Kinarm parameters.
  Methods: We analyzed VGR speed signals from 461 stroke and 599 control
participants across 4- and 8-target reaching protocols. We withheld all but the
first 8 or 16 reaching trials and used ARIMA, MOMENT, and Chronos models,
fine-tuned on 70 percent of subjects, to forecast synthetic trials. We
recomputed four kinematic features of reaching (reaction time, movement time,
posture speed, maximum speed) on combined recorded plus forecasted trials and
compared them to full-length references using ICC(2,1).
  Results: Chronos forecasts restored ICC >= 0.90 for all parameters with only
8 recorded trials plus forecasts, matching the reliability of 24-28 recorded
reaches (Delta ICC <= 0.07). MOMENT yielded intermediate gains, while ARIMA
improvements were minimal. Across cohorts and protocols, synthetic trials
replaced reaches without materially compromising feature reliability.
  Conclusion: Foundation-model forecasting can greatly shorten Kinarm VGR
assessment time. For the most impaired stroke survivors, sessions drop from 4-5
minutes to about 1 minute while preserving kinematic precision. This
forecast-augmented paradigm promises efficient robotic evaluations for
assessing motor impairments following stroke.

</details>


### [377] [Tailored robotic training improves hand function and proprioceptive processing in stroke survivors with proprioceptive deficits: A randomized controlled trial](https://arxiv.org/abs/2511.00259)
*Andria J. Farrens,Luis Garcia-Fernandez,Raymond Diaz Rojas,Jillian Obeso Estrada,Dylan Reinsdorf,Vicky Chan,Disha Gupta,Joel Perry,Eric Wolbrecht,An Do,Steven C. Cramer,David J. Reinkensmeyer*

Main category: cs.RO

TL;DR: 研究测试了两种基于本体感觉的机器人训练方法对中风患者手部功能和神经处理的影响，发现针对性训练能显著改善功能。


<details>
  <summary>Details</summary>
Motivation: 探索精准康复方法，通过针对性训练改善中风患者的手部功能和神经处理能力。

Method: 使用机器人手指外骨骼，比较了两种训练方法：Propriopixel训练和虚拟辅助训练，并与标准训练进行对照。

Result: 针对本体感觉缺陷的患者，Propriopixel和虚拟辅助训练显著改善了手部功能，且与神经敏感性的提升相关。

Conclusion: 基于本体感觉的针对性训练是精准神经康复的有效途径。

Abstract: Precision rehabilitation aims to tailor movement training to improve
outcomes. We tested whether proprioceptively-tailored robotic training improves
hand function and neural processing in stroke survivors. Using a robotic finger
exoskeleton, we tested two proprioceptively-tailored approaches: Propriopixel
Training, which uses robot-facilitated, gamified movements to enhance
proprioceptive processing, and Virtual Assistance Training, which reduces
robotic aid to increase reliance on self-generated feedback. In a randomized
controlled trial, forty-six chronic stroke survivors completed nine 2-hour
sessions of Standard, Propriopixel or Virtual training. Among participants with
proprioceptive deficits, Propriopixel ((Box and Block Test: 7 +/- 4.2, p=0.002)
and Virtual Assistance (4.5 +/- 4.4 , p=0.068) yielded greater gains in hand
function (Standard: 0.8 +/- 2.3 blocks). Proprioceptive gains correlated with
improvements in hand function. Tailored training enhanced neural sensitivity to
proprioceptive cues, evidenced by a novel EEG biomarker, the proprioceptive
Contingent Negative Variation. These findings support proprioceptively-tailored
training as a pathway to precision neurorehabilitation.

</details>


### [378] [FGO MythBusters: Explaining how Kalman Filter variants achieve the same performance as FGO in navigation applications](https://arxiv.org/abs/2511.00306)
*Baoshan Song,Ruijie Xu,Li-Ta Hsu*

Main category: cs.RO

TL;DR: 论文探讨了滑动窗口因子图优化（SW-FGO）与卡尔曼滤波变体（KFV）的理论联系，提出了递归FGO（Re-FGO）框架，并在特定条件下重现了EKF等算法。


<details>
  <summary>Details</summary>
Motivation: 研究SW-FGO与KFV的理论关系，填补现有研究空白，并展示SW-FGO在非线性和非高斯场景中的优势。

Method: 提出Re-FGO框架，在特定条件下（马尔可夫假设、高斯噪声和L2损失）重现KFV，并与SW-FGO进行比较。

Result: Re-FGO在特定条件下等同于EKF等算法，而SW-FGO在非线性和非高斯场景中表现更优。

Conclusion: 明确了SW-FGO与KFV的理论联系，并突出了SW-FGO在实际应用中的独特优势，如数值估计和深度学习集成。

Abstract: Sliding window-factor graph optimization (SW-FGO) has gained more and more
attention in navigation research due to its robust approximation to
non-Gaussian noises and nonlinearity of measuring models. There are lots of
works focusing on its application performance compared to extended Kalman
filter (EKF) but there is still a myth at the theoretical relationship between
the SW-FGO and EKF. In this paper, we find the necessarily fair condition to
connect SW-FGO and Kalman filter variants (KFV) (e.g., EKF, iterative EKF
(IEKF), robust EKF (REKF) and robust iterative EKF (RIEKF)). Based on the
conditions, we propose a recursive FGO (Re-FGO) framework to represent KFV
under SW-FGO formulation. Under explicit conditions (Markov assumption,
Gaussian noise with L2 loss, and a one-state window), Re-FGO regenerates
exactly to EKF/IEKF/REKF/RIEKF, while SW-FGO shows measurable benefits in
nonlinear, non-Gaussian regimes at a predictable compute cost. Finally, after
clarifying the connection between them, we highlight the unique advantages of
SW-FGO in practical phases, especially on numerical estimation and deep
learning integration. The code and data used in this work is open sourced at
https://github.com/Baoshan-Song/KFV-FGO-Comparison.

</details>


### [379] [SonarSweep: Fusing Sonar and Vision for Robust 3D Reconstruction via Plane Sweeping](https://arxiv.org/abs/2511.00392)
*Lingpeng Chen,Jiakun Tang,Apple Pui-Yi Chui,Ziyang Hong,Junfeng Wu*

Main category: cs.RO

TL;DR: SonarSweep是一种端到端深度学习框架，通过结合声纳和视觉数据，解决了水下环境中3D重建的挑战。


<details>
  <summary>Details</summary>
Motivation: 水下环境视觉退化严重，传统单模态方法（如视觉或声纳）存在局限性，导致重建效果不佳。

Method: 采用平面扫描算法进行跨模态融合，结合声纳和视觉数据。

Result: 在高保真模拟和真实环境中，SonarSweep生成了密集且准确的深度图，显著优于现有方法。

Conclusion: SonarSweep在水下高浑浊环境中表现优异，并公开了首个同步立体相机和声纳数据集。

Abstract: Accurate 3D reconstruction in visually-degraded underwater environments
remains a formidable challenge. Single-modality approaches are insufficient:
vision-based methods fail due to poor visibility and geometric constraints,
while sonar is crippled by inherent elevation ambiguity and low resolution.
Consequently, prior fusion technique relies on heuristics and flawed geometric
assumptions, leading to significant artifacts and an inability to model complex
scenes. In this paper, we introduce SonarSweep, a novel, end-to-end deep
learning framework that overcomes these limitations by adapting the principled
plane sweep algorithm for cross-modal fusion between sonar and visual data.
Extensive experiments in both high-fidelity simulation and real-world
environments demonstrate that SonarSweep consistently generates dense and
accurate depth maps, significantly outperforming state-of-the-art methods
across challenging conditions, particularly in high turbidity. To foster
further research, we will publicly release our code and a novel dataset
featuring synchronized stereo-camera and sonar data, the first of its kind.

</details>


### [380] [Runge-Kutta Approximations for Direct Coning Compensation Applying Lie Theory](https://arxiv.org/abs/2511.00412)
*John A. Christian,Michael R. Walker II,Wyatt Bridgman,Michael J. Sparapany*

Main category: cs.RO

TL;DR: 本文提出了一种基于经典Runge-Kutta积分方法的新型圆锥补偿算法，并展示了其与现有流行算法的关联性。


<details>
  <summary>Details</summary>
Motivation: 现代导航系统中，陀螺仪测量的积分是关键任务，但需要圆锥补偿以解决传感器旋转带来的误差。现有算法虽多，但缺乏系统性。

Method: 通过经典Runge-Kutta积分方法直接构建新的圆锥补偿算法，并展示了其与现有算法的关联性。

Result: 新算法在简单情况下可退化为现有流行算法，并提供了生成高阶算法的清晰步骤。

Conclusion: 新算法为圆锥补偿提供了一种系统化的方法，具有扩展性和实用性。

Abstract: The integration of gyroscope measurements is an essential task for most
navigation systems. Modern vehicles typically use strapdown systems, such that
gyro integration requires coning compensation to account for the sensor's
rotation during the integration. Many coning compensation algorithms have been
developed and a few are reviewed. This work introduces a new class of coning
correction algorithm built directly from the classical Runge-Kutta integration
routines. A simple case is shown to collapse to one of the most popular coning
algorithms and a clear procedure for generating higher-order algorithms is
presented.

</details>


### [381] [Design and Development of a Modular Bucket Drum Excavator for Lunar ISRU](https://arxiv.org/abs/2511.00492)
*Simon Giel,James Hurrell,Shreya Santra,Ashutosh Mishra,Kentaro Uno,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 论文摘要介绍了月球资源利用（ISRU）技术中的关键设备——用于MoonBot系统的桶鼓挖掘工具的开发与测试。


<details>
  <summary>Details</summary>
Motivation: 月球资源的可持续利用需要高效的挖掘工具，桶鼓的设计旨在满足这一需求。

Method: 通过3D打印PLA原型，并在沙盒测试中评估其效率和能耗。

Result: 工具重4.8公斤，体积14.06升，连续挖掘速率为777.54公斤/小时，能耗为0.022 Wh/kg。

Conclusion: 桶鼓工具成功实现概念验证，未来可通过集成传感器和自主控制系统进一步优化。

Abstract: In-Situ Resource Utilization (ISRU) is one of the key technologies for
enabling sustainable access to the Moon. The ability to excavate lunar regolith
is the first step in making lunar resources accessible and usable. This work
presents the development of a bucket drum for the modular robotic system
MoonBot, as part of the Japanese Moonshot program. A 3D-printed prototype made
of PLA was manufactured to evaluate its efficiency through a series of sandbox
tests. The resulting tool weighs 4.8 kg and has a volume of 14.06 L. It is
capable of continuous excavation at a rate of 777.54 kg/h with a normalized
energy consumption of 0.022 Wh/kg. In batch operation, the excavation rate is
172.02 kg/h with a normalized energy consumption of 0.86 Wh per kilogram of
excavated material. The obtained results demonstrate the successful
implementation of the concept. A key advantage of the developed tool is its
compatibility with the modular MoonBot robotic platform, which enables flexible
and efficient mission planning. Further improvements may include the
integration of sensors and an autonomous control system to enhance the
excavation process.

</details>


### [382] [Descriptive Model-based Learning and Control for Bipedal Locomotion](https://arxiv.org/abs/2511.00512)
*Suraj Kumar,Andy Ruina*

Main category: cs.RO

TL;DR: 提出了一种新型的双足平衡控制方法，避免使用低维模型约束机器人运动，而是通过最小自由度描述模型实现高效、类人步态。


<details>
  <summary>Details</summary>
Motivation: 传统双足平衡控制依赖低维模型，限制了机器人的运动自由度，导致步态效率低下（如屈膝行走）。研究发现平衡本质是低维的，可通过简单描述符在低维空间实现控制。

Method: 提出描述性模型，仅用维持平衡所需的最小自由度约束低维空间投影，其余自由度在高维空间中自由演化。

Result: 实现了高效、类人步态，并提高了鲁棒性。

Conclusion: 通过最小自由度描述模型控制双足平衡，避免了传统方法的局限性，提升了运动效率和适应性。

Abstract: Bipedal balance is challenging due to its multi-phase, hybrid nature and
high-dimensional state space. Traditional balance control approaches for
bipedal robots rely on low-dimensional models for locomotion planning and
reactive control, constraining the full robot to behave like these simplified
models. This involves tracking preset reference paths for the Center of Mass
and upper body obtained through low-dimensional models, often resulting in
inefficient walking patterns with bent knees. However, we observe that bipedal
balance is inherently low-dimensional and can be effectively described with
simple state and action descriptors in a low-dimensional state space. This
allows the robot's motion to evolve freely in its high-dimensional state space,
only constraining its projection in the low-dimensional state space. In this
work, we propose a novel control approach that avoids prescribing a
low-dimensional model to the full model. Instead, our control framework uses a
descriptive model with the minimum degrees of freedom necessary to maintain
balance, allowing the remaining degrees of freedom to evolve freely in the
high-dimensional space. This results in an efficient human-like walking gait
and improved robustness.

</details>


### [383] [Adaptive and Multi-object Grasping via Deformable Origami Modules](https://arxiv.org/abs/2511.00516)
*Peiyi Wang,Paul A. M. Lefeuvre,Shangwei Zou,Zhenwei Ni,Daniela Rus,Cecilia Laschi*

Main category: cs.RO

TL;DR: 提出了一种基于折纸结构的混合夹持器，通过被动变形实现稳定抓取和多物体同时操作。


<details>
  <summary>Details</summary>
Motivation: 现有软体机器人夹持器依赖复杂控制或传感，难以实现高效稳定的多物体操作。

Method: 设计多指混合夹持器，每个手指由平行折纸模块组成，通过单自由度驱动实现被动形状适应。

Result: 夹持器无需主动传感或反馈控制即可稳定抓取，并能同时操作多个物体。

Conclusion: 折纸结构可作为高效、稳定的多物体操作模块，适用于家庭和工业场景。

Abstract: Soft robotics gripper have shown great promise in handling fragile and
geometrically complex objects. However, most existing solutions rely on bulky
actuators, complex control strategies, or advanced tactile sensing to achieve
stable and reliable grasping performance. In this work, we present a
multi-finger hybrid gripper featuring passively deformable origami modules that
generate constant force and torque output. Each finger composed of parallel
origami modules is driven by a 1-DoF actuator mechanism, enabling passive shape
adaptability and stable grasping force without active sensing or feedback
control. More importantly, we demonstrate an interesting capability in
simultaneous multi-object grasping, which allows stacked objects of varied
shape and size to be picked, transported and placed independently at different
states, significantly improving manipulation efficiency compared to
single-object grasping. These results highlight the potential of origami-based
compliant structures as scalable modules for adaptive, stable and efficient
multi-object manipulation in domestic and industrial pick-and-place scenarios.

</details>


### [384] [Improving Robustness to Out-of-Distribution States in Imitation Learning via Deep Koopman-Boosted Diffusion Policy](https://arxiv.org/abs/2511.00555)
*Dianye Huang,Nassir Navab,Zhongliang Jiang*

Main category: cs.RO

TL;DR: D3P算法通过双分支架构和Deep Koopman模块提升机器人模仿学习的性能，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在捕捉多步时间依赖性和处理本体感觉输入时表现不佳，导致任务失败。

Method: 提出D3P算法，采用双分支架构分离视觉和本体感觉输入，并引入Deep Koopman模块增强视觉表示学习。

Result: 在仿真和真实任务中，D3P分别平均提升14.6%和15.0%的性能。

Conclusion: D3P通过动态切换分支和增强视觉表示，显著提升了机器人模仿学习的可靠性和性能。

Abstract: Integrating generative models with action chunking has shown significant
promise in imitation learning for robotic manipulation. However, the existing
diffusion-based paradigm often struggles to capture strong temporal
dependencies across multiple steps, particularly when incorporating
proprioceptive input. This limitation can lead to task failures, where the
policy overfits to proprioceptive cues at the expense of capturing the visually
derived features of the task. To overcome this challenge, we propose the Deep
Koopman-boosted Dual-branch Diffusion Policy (D3P) algorithm. D3P introduces a
dual-branch architecture to decouple the roles of different sensory modality
combinations. The visual branch encodes the visual observations to indicate
task progression, while the fused branch integrates both visual and
proprioceptive inputs for precise manipulation. Within this architecture, when
the robot fails to accomplish intermediate goals, such as grasping a drawer
handle, the policy can dynamically switch to execute action chunks generated by
the visual branch, allowing recovery to previously observed states and
facilitating retrial of the task. To further enhance visual representation
learning, we incorporate a Deep Koopman Operator module that captures
structured temporal dynamics from visual inputs. During inference, we use the
test-time loss of the generative model as a confidence signal to guide the
aggregation of the temporally overlapping predicted action chunks, thereby
enhancing the reliability of policy execution. In simulation experiments across
six RLBench tabletop tasks, D3P outperforms the state-of-the-art diffusion
policy by an average of 14.6\%. On three real-world robotic manipulation tasks,
it achieves a 15.0\% improvement. Code: https://github.com/dianyeHuang/D3P.

</details>


### [385] [Multi-Mapcher: Loop Closure Detection-Free Heterogeneous LiDAR Multi-Session SLAM Leveraging Outlier-Robust Registration for Autonomous Vehicles](https://arxiv.org/abs/2511.00635)
*Hyungtae Lim,Daebeom Kim,Hyun Myung*

Main category: cs.RO

TL;DR: 提出Multi-Mapcher框架，通过大尺度地图间配准实现多会话LiDAR数据的初始对齐，提升多传感器SLAM性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖闭环检测，但传感器差异（如密度和视场）可能导致性能下降。

Method: 利用鲁棒点云配准进行初始对齐，再通过半径搜索和锚点优化构建全局地图。

Result: 实验显示性能优于现有方法，且速度更快。

Conclusion: Multi-Mapcher为多传感器SLAM提供了高效解决方案。

Abstract: As various 3D light detection and ranging (LiDAR) sensors have been
introduced to the market, research on multi-session simultaneous localization
and mapping (MSS) using heterogeneous LiDAR sensors has been actively
conducted. Existing MSS methods mostly rely on loop closure detection for
inter-session alignment; however, the performance of loop closure detection can
be potentially degraded owing to the differences in the density and field of
view (FoV) of the sensors used in different sessions. In this study, we
challenge the existing paradigm that relies heavily on loop detection modules
and propose a novel MSS framework, called Multi-Mapcher, that employs
large-scale map-to-map registration to perform inter-session initial alignment,
which is commonly assumed to be infeasible, by leveraging outlier-robust 3D
point cloud registration. Next, after finding inter-session loops by radius
search based on the assumption that the inter-session initial alignment is
sufficiently precise, anchor node-based robust pose graph optimization is
employed to build a consistent global map. As demonstrated in our experiments,
our approach shows substantially better MSS performance for various LiDAR
sensors used to capture the sessions and is faster than state-of-the-art
approaches. Our code is available at
https://github.com/url-kaist/multi-mapcher.

</details>


### [386] [When Semantics Connect the Swarm: LLM-Driven Fuzzy Control for Cooperative Multi-Robot Underwater Coverage](https://arxiv.org/abs/2511.00783)
*Jingzehua Xu,Weihang Zhang,Yangyang Li,Hongmiaoyi Zhang,Guanwen Xie,Jiwei Tang,Shuai Zhang,Yi Li*

Main category: cs.RO

TL;DR: 提出了一种基于语义引导的模糊控制框架，结合大语言模型（LLMs）和轻量级协调，解决水下多机器人协作覆盖的挑战。


<details>
  <summary>Details</summary>
Motivation: 水下多机器人协作覆盖面临部分可观测性、通信受限、环境不确定性及缺乏全局定位等问题，需要一种高效且适应性强的方法。

Method: 利用LLM将原始多模态观测压缩为人类可解释的语义标记，通过模糊推理系统生成稳定的导航指令，并通过语义通信协调多机器人。

Result: 在未知珊瑚礁环境中，该框架在有限感知和通信条件下实现了高效的协作覆盖和目标导向导航。

Conclusion: 该框架缩小了语义认知与分布式水下控制之间的差距，适用于无GPS和无地图的环境。

Abstract: Underwater multi-robot cooperative coverage remains challenging due to
partial observability, limited communication, environmental uncertainty, and
the lack of access to global localization. To address these issues, this paper
presents a semantics-guided fuzzy control framework that couples Large Language
Models (LLMs) with interpretable control and lightweight coordination. Raw
multimodal observations are compressed by the LLM into compact,
human-interpretable semantic tokens that summarize obstacles, unexplored
regions, and Objects Of Interest (OOIs) under uncertain perception. A fuzzy
inference system with pre-defined membership functions then maps these tokens
into smooth and stable steering and gait commands, enabling reliable navigation
without relying on global positioning. Then, we further coordinate multiple
robots by introducing semantic communication that shares intent and local
context in linguistic form, enabling agreement on who explores where while
avoiding redundant revisits. Extensive simulations in unknown reef-like
environments show that, under limited sensing and communication, the proposed
framework achieves robust OOI-oriented navigation and cooperative coverage with
improved efficiency and adaptability, narrowing the gap between semantic
cognition and distributed underwater control in GPS-denied, map-free
conditions.

</details>


### [387] [Real-Time Learning of Predictive Dynamic Obstacle Models for Robotic Motion Planning](https://arxiv.org/abs/2511.00814)
*Stella Kombo,Masih Haseli,Skylar Wei,Joel W. Burdick*

Main category: cs.RO

TL;DR: 该论文提出了一种实时学习非线性预测模型的方法，用于去噪和预测动态系统的运动，适用于实时控制框架。


<details>
  <summary>Details</summary>
Motivation: 自主系统需要从部分和噪声数据中预测附近代理的运动，因此需要一种实时学习非线性预测模型的方法。

Method: 使用改进的滑动窗口Hankel动态模态分解（Hankel-DMD），通过Hankel矩阵嵌入部分噪声测量，并结合Page矩阵进行奇异值硬阈值处理（SVHT）以估计有效秩。Cadzow投影用于强制结构化低秩一致性，从而生成去噪轨迹和局部噪声方差估计。

Result: 在模拟和动态起重机实验平台上验证了方法的有效性，结果表明该方法能够实现稳定的方差感知去噪和短时预测。

Conclusion: 该方法适用于实时控制框架，能够提供稳定的去噪和短时预测能力。

Abstract: Autonomous systems often must predict the motions of nearby agents from
partial and noisy data. This paper asks and answers the question: "can we
learn, in real-time, a nonlinear predictive model of another agent's motions?"
Our online framework denoises and forecasts such dynamics using a modified
sliding-window Hankel Dynamic Mode Decomposition (Hankel-DMD). Partial noisy
measurements are embedded into a Hankel matrix, while an associated Page matrix
enables singular-value hard thresholding (SVHT) to estimate the effective rank.
A Cadzow projection enforces structured low-rank consistency, yielding a
denoised trajectory and local noise variance estimates. From this
representation, a time-varying Hankel-DMD lifted linear predictor is
constructed for multi-step forecasts. The residual analysis provides
variance-tracking signals that can support downstream estimators and risk-aware
planning. We validate the approach in simulation under Gaussian and
heavy-tailed noise, and experimentally on a dynamic crane testbed. Results show
that the method achieves stable variance-aware denoising and short-horizon
prediction suitable for integration into real-time control frameworks.

</details>


### [388] [Heuristic Step Planning for Learning Dynamic Bipedal Locomotion: A Comparative Study of Model-Based and Model-Free Approaches](https://arxiv.org/abs/2511.00840)
*William Suliman,Ekaterina Chaikovskaia,Egor Davydenko,Roman Gorbachev*

Main category: cs.RO

TL;DR: 提出了一种基于学习的双足行走框架，结合启发式步态规划策略，实现精确的环境交互和任务执行。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖复杂步态规划或简化动力学模型，难以在非结构化环境中实现稳定行走。

Method: 采用启发式步态规划和Raibert型控制器调节步长，避免复杂模型。

Result: 实验表明，该方法在速度跟踪（80%）、地形鲁棒性（50%提升）和能效方面优于LIPM控制器。

Conclusion: 复杂模型可能非必要，启发式方法可实现稳定双足行走。

Abstract: This work presents an extended framework for learning-based bipedal
locomotion that incorporates a heuristic step-planning strategy guided by
desired torso velocity tracking. The framework enables precise interaction
between a humanoid robot and its environment, supporting tasks such as crossing
gaps and accurately approaching target objects. Unlike approaches based on full
or simplified dynamics, the proposed method avoids complex step planners and
analytical models. Step planning is primarily driven by heuristic commands,
while a Raibert-type controller modulates the foot placement length based on
the error between desired and actual torso velocity. We compare our method with
a model-based step-planning approach -- the Linear Inverted Pendulum Model
(LIPM) controller. Experimental results demonstrate that our approach attains
comparable or superior accuracy in maintaining target velocity (up to 80%),
significantly greater robustness on uneven terrain (over 50% improvement), and
improved energy efficiency. These results suggest that incorporating complex
analytical, model-based components into the training architecture may be
unnecessary for achieving stable and robust bipedal walking, even in
unstructured environments.

</details>


### [389] [Maestro: Orchestrating Robotics Modules with Vision-Language Models for Zero-Shot Generalist Robots](https://arxiv.org/abs/2511.00917)
*Junyao Shi,Rujia Yang,Kaitian Chao,Selina Bingqing Wan,Yifei Shao,Jiahui Lei,Jianing Qian,Long Le,Pratik Chaudhari,Kostas Daniilidis,Chuan Wen,Dinesh Jayaraman*

Main category: cs.RO

TL;DR: Maestro利用VLM构建通用机器人策略，通过模块化设计提升零样本性能，易于扩展和适应新场景。


<details>
  <summary>Details</summary>
Motivation: 当前通用机器人研究依赖大规模数据集训练端到端模型，但本文探索通过VLM直接构建通用策略，结合模块化设计提升灵活性和性能。

Method: Maestro通过VLM动态组合感知、规划和控制模块，形成程序化策略，支持闭环接口和多样化工具库。

Result: Maestro在零样本任务中显著超越现有VLA模型，且易于扩展、编辑和适应新场景。

Conclusion: 模块化设计和VLM结合为通用机器人策略提供了高效、灵活的解决方案。

Abstract: Today's best-explored routes towards generalist robots center on collecting
ever larger "observations-in actions-out" robotics datasets to train large
end-to-end models, copying a recipe that has worked for vision-language models
(VLMs). We pursue a road less traveled: building generalist policies directly
around VLMs by augmenting their general capabilities with specific robot
capabilities encapsulated in a carefully curated set of perception, planning,
and control modules. In Maestro, a VLM coding agent dynamically composes these
modules into a programmatic policy for the current task and scenario. Maestro's
architecture benefits from a streamlined closed-loop interface without many
manually imposed structural constraints, and a comprehensive and diverse tool
repertoire. As a result, it largely surpasses today's VLA models for zero-shot
performance on challenging manipulation skills. Further, Maestro is easily
extensible to incorporate new modules, easily editable to suit new embodiments
such as a quadruped-mounted arm, and even easily adapts from minimal real-world
experiences through local code edits.

</details>


### [390] [Fast-SmartWay: Panoramic-Free End-to-End Zero-Shot Vision-and-Language Navigation](https://arxiv.org/abs/2511.00933)
*Xiangyu Shi,Zerui Li,Yanyuan Qiao,Qi Wu*

Main category: cs.RO

TL;DR: Fast-SmartWay是一种端到端的零样本视觉语言导航框架，通过仅使用三个正面RGB-D图像和自然语言指令，消除了全景视图和路径点预测器的需求，显著降低了延迟并提升了实用性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖全景观测和两阶段流水线，导致高延迟并限制实际应用。

Method: 提出Fast-SmartWay框架，结合不确定性感知推理模块（包括消歧模块和双向推理机制），直接预测动作。

Result: 在模拟和真实机器人环境中，显著降低每步延迟，性能优于或与全景视图基线相当。

Conclusion: Fast-SmartWay展示了零样本实体导航的实用性和有效性。

Abstract: Recent advances in Vision-and-Language Navigation in Continuous Environments
(VLN-CE) have leveraged multimodal large language models (MLLMs) to achieve
zero-shot navigation. However, existing methods often rely on panoramic
observations and two-stage pipelines involving waypoint predictors, which
introduce significant latency and limit real-world applicability. In this work,
we propose Fast-SmartWay, an end-to-end zero-shot VLN-CE framework that
eliminates the need for panoramic views and waypoint predictors. Our approach
uses only three frontal RGB-D images combined with natural language
instructions, enabling MLLMs to directly predict actions. To enhance decision
robustness, we introduce an Uncertainty-Aware Reasoning module that integrates
(i) a Disambiguation Module for avoiding local optima, and (ii) a Future-Past
Bidirectional Reasoning mechanism for globally coherent planning. Experiments
on both simulated and real-robot environments demonstrate that our method
significantly reduces per-step latency while achieving competitive or superior
performance compared to panoramic-view baselines. These results demonstrate the
practicality and effectiveness of Fast-SmartWay for real-world zero-shot
embodied navigation.

</details>


### [391] [URDF-Anything: Constructing Articulated Objects with 3D Multimodal Language Model](https://arxiv.org/abs/2511.00940)
*Zhe Li,Xiang Bai,Jieyu Zhang,Zhuangzhe Wu,Che Xu,Ying Li,Chengkai Hou,Shanghang Zhang*

Main category: cs.RO

TL;DR: URDF-Anything是一个基于3D多模态大语言模型的端到端自动重建框架，用于构建关节物体的数字孪生，显著提升了几何分割和运动学参数预测的性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要繁琐的手动建模或多阶段流程，URDF-Anything旨在通过自动化框架解决这一问题，提升机器人仿真和AI世界模型构建的效率。

Method: 采用基于点云和文本多模态输入的自回归预测框架，结合$[SEG]$令牌机制，联合优化几何分割和运动学参数预测。

Result: 在几何分割（mIoU提升17%）、运动学参数预测（误差减少29%）和物理可执行性（超越基线50%）上显著优于现有方法，且泛化能力强。

Conclusion: URDF-Anything为机器人仿真提供了高效的数字孪生构建方案，显著增强了仿真到现实的迁移能力。

Abstract: Constructing accurate digital twins of articulated objects is essential for
robotic simulation training and embodied AI world model building, yet
historically requires painstaking manual modeling or multi-stage pipelines. In
this work, we propose \textbf{URDF-Anything}, an end-to-end automatic
reconstruction framework based on a 3D multimodal large language model (MLLM).
URDF-Anything utilizes an autoregressive prediction framework based on
point-cloud and text multimodal input to jointly optimize geometric
segmentation and kinematic parameter prediction. It implements a specialized
$[SEG]$ token mechanism that interacts directly with point cloud features,
enabling fine-grained part-level segmentation while maintaining consistency
with the kinematic parameter predictions. Experiments on both simulated and
real-world datasets demonstrate that our method significantly outperforms
existing approaches regarding geometric segmentation (mIoU 17\% improvement),
kinematic parameter prediction (average error reduction of 29\%), and physical
executability (surpassing baselines by 50\%). Notably, our method exhibits
excellent generalization ability, performing well even on objects outside the
training set. This work provides an efficient solution for constructing digital
twins for robotic simulation, significantly enhancing the sim-to-real transfer
capability.

</details>


### [392] [Breaking the Latency Barrier: Synergistic Perception and Control for High-Frequency 3D Ultrasound Servoing](https://arxiv.org/abs/2511.00983)
*Yizhao Qian,Yujie Zhu,Jiayuan Luo,Li Liu,Yixuan Yuan,Guochen Ning,Hongen Liao*

Main category: cs.RO

TL;DR: 提出了一种新型机器人超声系统框架，通过感知与控制的协同设计，实现高频率闭环控制，显著降低跟踪误差。


<details>
  <summary>Details</summary>
Motivation: 解决现有机器人超声系统在动态目标跟踪中的高延迟问题，提升系统性能。

Method: 采用解耦双流感知网络和单步流策略，实现高频率状态估计和动作序列生成。

Result: 在动态模型上实现6.5mm以下平均误差，102mm/s速度跟踪，终端误差低于1.7mm。

Conclusion: 该框架为动态临床环境中的自主性提供了关键技术支持。

Abstract: Real-time tracking of dynamic targets amidst large-scale, high-frequency
disturbances remains a critical unsolved challenge in Robotic Ultrasound
Systems (RUSS), primarily due to the end-to-end latency of existing systems.
This paper argues that breaking this latency barrier requires a fundamental
shift towards the synergistic co-design of perception and control. We realize
it in a novel framework with two tightly-coupled contributions: (1) a Decoupled
Dual-Stream Perception Network that robustly estimates 3D translational state
from 2D images at high frequency, and (2) a Single-Step Flow Policy that
generates entire action sequences in one inference pass, bypassing the
iterative bottleneck of conventional policies. This synergy enables a
closed-loop control frequency exceeding 60Hz. On a dynamic phantom, our system
not only tracks complex 3D trajectories with a mean error below 6.5mm but also
demonstrates robust re-acquisition from over 170mm displacement. Furthermore,
it can track targets at speeds of 102mm/s, achieving a terminal error below
1.7mm. Moreover, in-vivo experiments on a human volunteer validate the
framework's effectiveness and robustness in a realistic clinical setting. Our
work presents a RUSS holistically architected to unify high-bandwidth tracking
with large-scale repositioning, a critical step towards robust autonomy in
dynamic clinical environments.

</details>


### [393] [GauDP: Reinventing Multi-Agent Collaboration through Gaussian-Image Synergy in Diffusion Policies](https://arxiv.org/abs/2511.00998)
*Ziye Wang,Li Kang,Yiran Qin,Jiahua Ma,Zhanglin Peng,Lei Bai,Ruimao Zhang*

Main category: cs.RO

TL;DR: GauDP提出了一种高斯图像协同表示方法，用于多智能体协作系统中的可扩展感知模仿学习。


<details>
  <summary>Details</summary>
Motivation: 现有方法在平衡细粒度局部控制和全局场景理解方面存在困难，导致可扩展性和协作质量受限。

Method: GauDP通过从分散的RGB观测构建全局一致的3D高斯场，并动态重分配3D高斯属性到每个智能体的局部视角，实现任务关键特征的适应性查询。

Result: 在RoboFactory基准测试中，GauDP优于现有基于图像的方法，接近基于点云的方法，且随着智能体数量增加仍保持强可扩展性。

Conclusion: GauDP实现了细粒度控制和全局一致行为，无需额外传感模态，为多智能体协作提供了高效解决方案。

Abstract: Recently, effective coordination in embodied multi-agent systems has remained
a fundamental challenge, particularly in scenarios where agents must balance
individual perspectives with global environmental awareness. Existing
approaches often struggle to balance fine-grained local control with
comprehensive scene understanding, resulting in limited scalability and
compromised collaboration quality. In this paper, we present GauDP, a novel
Gaussian-image synergistic representation that facilitates scalable,
perception-aware imitation learning in multi-agent collaborative systems.
Specifically, GauDP constructs a globally consistent 3D Gaussian field from
decentralized RGB observations, then dynamically redistributes 3D Gaussian
attributes to each agent's local perspective. This enables all agents to
adaptively query task-critical features from the shared scene representation
while maintaining their individual viewpoints. This design facilitates both
fine-grained control and globally coherent behavior without requiring
additional sensing modalities (e.g., 3D point cloud). We evaluate GauDP on the
RoboFactory benchmark, which includes diverse multi-arm manipulation tasks. Our
method achieves superior performance over existing image-based methods and
approaches the effectiveness of point-cloud-driven methods, while maintaining
strong scalability as the number of agents increases.

</details>


### [394] [AquaROM: shape optimization pipeline for soft swimmers using parametric reduced order models](https://arxiv.org/abs/2511.01031)
*Mathieu Dubied,Paolo Tiso,Robert K. Katzschmann*

Main category: cs.RO

TL;DR: 提出了一种基于张量参数降阶模型（PROM）的优化算法，用于高效解决软体机器人中的非线性约束优化问题。


<details>
  <summary>Details</summary>
Motivation: 软体结构在复杂非线性力作用下的高效优化是机器人领域的关键挑战，现有方法计算资源消耗大。

Method: 利用张量降维和近似解技术，结合分析梯度在降阶基（ROB）中的应用，提升计算效率。

Result: 应用于软体游泳机器人形状优化，成功处理内外非线性力，计算复杂度显著降低。

Conclusion: 该方法为软体机器人中复杂非线性系统的优化提供了高效途径，推动设计与控制的发展。

Abstract: The efficient optimization of actuated soft structures, particularly under
complex nonlinear forces, remains a critical challenge in advancing robotics.
Simulations of nonlinear structures, such as soft-bodied robots modeled using
the finite element method (FEM), often demand substantial computational
resources, especially during optimization. To address this challenge, we
propose a novel optimization algorithm based on a tensorial parametric reduced
order model (PROM). Our algorithm leverages dimensionality reduction and
solution approximation techniques to facilitate efficient solving of nonlinear
constrained optimization problems. The well-structured tensorial approach
enables the use of analytical gradients within a specifically chosen reduced
order basis (ROB), significantly enhancing computational efficiency. To
showcase the performance of our method, we apply it to optimizing soft robotic
swimmer shapes. These actuated soft robots experience hydrodynamic forces,
subjecting them to both internal and external nonlinear forces, which are
incorporated into our optimization process using a data-free ROB for fast and
accurate computations. This approach not only reduces computational complexity
but also unlocks new opportunities to optimize complex nonlinear systems in
soft robotics, paving the way for more efficient design and control.

</details>


### [395] [Deployable Vision-driven UAV River Navigation via Human-in-the-loop Preference Alignment](https://arxiv.org/abs/2511.01083)
*Zihan Wang,Jianwen Li,Li-Fan Wu,Nina Mahmoudian*

Main category: cs.RO

TL;DR: SPAR-H方法通过结合直接偏好优化和奖励估计，在有限的人类干预下实现无人机河流导航的高效适应。


<details>
  <summary>Details</summary>
Motivation: 无人机在河流环境中的部署面临模拟训练策略的分布偏移和安全风险，需要高效适应。

Method: 提出SPAR-H方法，融合直接偏好优化和奖励估计，通过人类监督提升策略。

Result: SPAR-H在测试方法中表现最佳，奖励模型与人类偏好一致。

Conclusion: 双状态偏好为河流导航提供了数据高效的在线适应途径。

Abstract: Rivers are critical corridors for environmental monitoring and disaster
response, where Unmanned Aerial Vehicles (UAVs) guided by vision-driven
policies can provide fast, low-cost coverage. However, deployment exposes
simulation-trained policies with distribution shift and safety risks and
requires efficient adaptation from limited human interventions. We study
human-in-the-loop (HITL) learning with a conservative overseer who vetoes
unsafe or inefficient actions and provides statewise preferences by comparing
the agent's proposal with a corrective override. We introduce Statewise Hybrid
Preference Alignment for Robotics (SPAR-H), which fuses direct preference
optimization on policy logits with a reward-based pathway that trains an
immediate-reward estimator from the same preferences and updates the policy
using a trust-region surrogate. With five HITL rollouts collected from a fixed
novice policy, SPAR-H achieves the highest final episodic reward and the lowest
variance across initial conditions among tested methods. The learned reward
model aligns with human-preferred actions and elevates nearby non-intervened
choices, supporting stable propagation of improvements. We benchmark SPAR-H
against imitation learning (IL), direct preference variants, and evaluative
reinforcement learning (RL) in the HITL setting, and demonstrate real-world
feasibility of continual preference alignment for UAV river following. Overall,
dual statewise preferences empirically provide a practical route to
data-efficient online adaptation in riverine navigation.

</details>


### [396] [SLAP: Shortcut Learning for Abstract Planning](https://arxiv.org/abs/2511.01107)
*Y. Isabel Liu,Bowen Li,Benjamin Eysenbach,Tom Silver*

Main category: cs.RO

TL;DR: SLAP是一种通过模型自由强化学习自动发现新选项的方法，显著提升任务成功率和缩短计划长度。


<details>
  <summary>Details</summary>
Motivation: 解决长时程决策中稀疏奖励和连续状态动作的挑战，突破传统TAMP中手动定义选项的限制。

Method: 利用模型自由强化学习在TAMP的抽象规划图中学习捷径，自动生成新选项。

Result: 在四个模拟机器人环境中，SLAP将计划长度减少50%以上，并显著优于规划和强化学习基线。

Conclusion: SLAP能够自动发现动态物理行为，显著提升任务解决能力和泛化性。

Abstract: Long-horizon decision-making with sparse rewards and continuous states and
actions remains a fundamental challenge in AI and robotics. Task and motion
planning (TAMP) is a model-based framework that addresses this challenge by
planning hierarchically with abstract actions (options). These options are
manually defined, limiting the agent to behaviors that we as human engineers
know how to program (pick, place, move). In this work, we propose Shortcut
Learning for Abstract Planning (SLAP), a method that leverages existing TAMP
options to automatically discover new ones. Our key idea is to use model-free
reinforcement learning (RL) to learn shortcuts in the abstract planning graph
induced by the existing options in TAMP. Without any additional assumptions or
inputs, shortcut learning leads to shorter solutions than pure planning, and
higher task success rates than flat and hierarchical RL. Qualitatively, SLAP
discovers dynamic physical improvisations (e.g., slap, wiggle, wipe) that
differ significantly from the manually-defined ones. In experiments in four
simulated robotic environments, we show that SLAP solves and generalizes to a
wide range of tasks, reducing overall plan lengths by over 50% and consistently
outperforming planning and RL baselines.

</details>


### [397] [An Enhanced Proprioceptive Method for Soft Robots Integrating Bend Sensors and IMUs](https://arxiv.org/abs/2511.01165)
*Dong Heon Han,Mayank Mehta,Runze Zuo,Zachary Wanger,Daniel Bruder*

Main category: cs.RO

TL;DR: 提出了一种利用现成传感器增强软机器人形状估计的方法，通过结合IMU和弯曲传感器，减少漂移并提高精度。


<details>
  <summary>Details</summary>
Motivation: 解决软机器人形状估计中IMU漂移问题，同时保持成本效益和易用性。

Method: 结合IMU和弯曲传感器，使用卡尔曼滤波融合数据，并通过分段恒定曲率模型重建形状。

Result: 在45分钟连续操作中，均方根误差为16.96毫米（总长度的2.91%），比仅用IMU的方法减少56%。

Conclusion: 该方法实现了长期高精度的软机器人形状估计，并在多种条件下表现出鲁棒性。

Abstract: This study presents an enhanced proprioceptive method for accurate shape
estimation of soft robots using only off-the-shelf sensors, ensuring
cost-effectiveness and easy applicability. By integrating inertial measurement
units (IMUs) with complementary bend sensors, IMU drift is mitigated, enabling
reliable long-term proprioception. A Kalman filter fuses segment tip
orientations from both sensors in a mutually compensatory manner, improving
shape estimation over single-sensor methods. A piecewise constant curvature
model estimates the tip location from the fused orientation data and
reconstructs the robot's deformation. Experiments under no loading, external
forces, and passive obstacle interactions during 45 minutes of continuous
operation showed a root mean square error of 16.96 mm (2.91% of total length),
a 56% reduction compared to IMU-only benchmarks. These results demonstrate that
our approach not only enables long-duration proprioception in soft robots but
also maintains high accuracy and robustness across these diverse conditions.

</details>


### [398] [Scaling Cross-Embodiment World Models for Dexterous Manipulation](https://arxiv.org/abs/2511.01177)
*Zihao He,Bo Ai,Tongzhou Mu,Yulin Liu,Weikang Wan,Jiawei Fu,Yilun Du,Henrik I. Christensen,Hao Su*

Main category: cs.RO

TL;DR: 跨具身学习通过粒子表示和世界模型实现异构机器人间的动作迁移。


<details>
  <summary>Details</summary>
Motivation: 解决不同形态机器人间动作空间和运动学差异导致的数据共享和策略迁移问题。

Method: 将不同具身表示为3D粒子，动作定义为粒子位移，训练基于图的世界模型。

Result: 实验表明，更多训练具身和混合数据提升泛化能力，模型支持多样自由度机器人控制。

Conclusion: 世界模型是跨具身灵巧操作的有效接口。

Abstract: Cross-embodiment learning seeks to build generalist robots that operate
across diverse morphologies, but differences in action spaces and kinematics
hinder data sharing and policy transfer. This raises a central question: Is
there any invariance that allows actions to transfer across embodiments? We
conjecture that environment dynamics are embodiment-invariant, and that world
models capturing these dynamics can provide a unified interface across
embodiments. To learn such a unified world model, the crucial step is to design
state and action representations that abstract away embodiment-specific details
while preserving control relevance. To this end, we represent different
embodiments (e.g., human hands and robot hands) as sets of 3D particles and
define actions as particle displacements, creating a shared representation for
heterogeneous data and control problems. A graph-based world model is then
trained on exploration data from diverse simulated robot hands and real human
hands, and integrated with model-based planning for deployment on novel
hardware. Experiments on rigid and deformable manipulation tasks reveal three
findings: (i) scaling to more training embodiments improves generalization to
unseen ones, (ii) co-training on both simulated and real data outperforms
training on either alone, and (iii) the learned models enable effective control
on robots with varied degrees of freedom. These results establish world models
as a promising interface for cross-embodiment dexterous manipulation.

</details>


### [399] [LiDAR-VGGT: Cross-Modal Coarse-to-Fine Fusion for Globally Consistent and Metric-Scale Dense Mapping](https://arxiv.org/abs/2511.01186)
*Lijie Wang,Lianjie Guo,Ziyi Xu,Qianhao Wang,Fei Gao,Xieyuanli Chen*

Main category: cs.RO

TL;DR: LiDAR-VGGT结合LiDAR惯性里程计与VGGT模型，通过两阶段融合管道实现高精度彩色点云重建。


<details>
  <summary>Details</summary>
Motivation: 解决LIVO对外部校准敏感及VGGT在大规模环境中扩展性不足的问题。

Method: 采用两阶段粗到精融合管道，包括预融合模块和后融合模块。

Result: 在多个数据集上表现优于VGGT和LIVO基线，实现全局一致的彩色点云。

Conclusion: LiDAR-VGGT为大规模彩色点云重建提供了高效解决方案，并开源了评估工具。

Abstract: Reconstructing large-scale colored point clouds is an important task in
robotics, supporting perception, navigation, and scene understanding. Despite
advances in LiDAR inertial visual odometry (LIVO), its performance remains
highly sensitive to extrinsic calibration. Meanwhile, 3D vision foundation
models, such as VGGT, suffer from limited scalability in large environments and
inherently lack metric scale. To overcome these limitations, we propose
LiDAR-VGGT, a novel framework that tightly couples LiDAR inertial odometry with
the state-of-the-art VGGT model through a two-stage coarse- to-fine fusion
pipeline: First, a pre-fusion module with robust initialization refinement
efficiently estimates VGGT poses and point clouds with coarse metric scale
within each session. Then, a post-fusion module enhances cross-modal 3D
similarity transformation, using bounding-box-based regularization to reduce
scale distortions caused by inconsistent FOVs between LiDAR and camera sensors.
Extensive experiments across multiple datasets demonstrate that LiDAR-VGGT
achieves dense, globally consistent colored point clouds and outperforms both
VGGT-based methods and LIVO baselines. The implementation of our proposed novel
color point cloud evaluation toolkit will be released as open source.

</details>


### [400] [Closed-loop Control of Steerable Balloon Endoscopes for Robot-assisted Transcatheter Intracardiac Procedures](https://arxiv.org/abs/2511.01199)
*Max McCandless,Jonathan Hamid,Sammy Elmariah,Nathaniel Langer,Pierre E. Dupont*

Main category: cs.RO

TL;DR: 提出了一种可操纵的气球式心脏镜，用于心脏内直接光学可视化，通过单一输入（气球充气压力）独立控制视野和弯曲角度，适用于多种心脏内任务。


<details>
  <summary>Details</summary>
Motivation: 为了从开胸手术转向更安全的导管手术，需要改进成像技术和机器人解决方案以实现简单、准确的工具导航。

Method: 设计了一种可折叠和膨胀的气球式心脏镜，通过调节气球壁厚和充气压力独立控制视野直径和弯曲角度。

Result: 展示了用于主动脉瓣叶切割的特定气球设计，并通过图像闭环控制实现了稳定的方向控制。

Conclusion: 该气球技术可定制化设计，适用于多种心脏内任务，为导管手术提供了新的成像和工具导航解决方案。

Abstract: To move away from open-heart surgery towards safer transcatheter procedures,
there is a growing need for improved imaging techniques and robotic solutions
to enable simple, accurate tool navigation. Common imaging modalities, such as
fluoroscopy and ultrasound, have limitations that can be overcome using
cardioscopy, i.e., direct optical visualization inside the beating heart. We
present a cardioscope designed as a steerable balloon. As a balloon, it can be
collapsed to pass through the vasculature and subsequently inflated inside the
heart for visualization and tool delivery through an integrated working
channel. Through careful design of balloon wall thickness, a single input,
balloon inflation pressure, is used to independently control two outputs,
balloon diameter (corresponding to field of view diameter) and balloon bending
angle (enabling precise working channel positioning). This balloon technology
can be tuned to produce cardioscopes designed for a range of intracardiac
tasks. To illustrate this approach, a balloon design is presented for the
specific task of aortic leaflet laceration. Image-based closed-loop control of
bending angle is also demonstrated as a means of enabling stable orientation
control during tool insertion and removal.

</details>


### [401] [Tackling the Kidnapped Robot Problem via Sparse Feasible Hypothesis Sampling and Reliable Batched Multi-Stage Inference](https://arxiv.org/abs/2511.01219)
*Muhua Zhang,Lei Ma,Ying Wu,Kai Shen,Deqing Huang,Henry Leung*

Main category: cs.RO

TL;DR: 提出了一种被动2D全局重定位框架，解决机器人绑架问题，通过多假设方案和优化度量提升效率和成功率。


<details>
  <summary>Details</summary>
Motivation: 解决机器人绑架问题（KRP），即在无初始位姿估计时重新定位机器人，提升长期自主性。

Method: 使用RRT生成稀疏假设，提出SMAD和TAM度量优化假设排序和位姿评估。

Result: 在资源受限的机器人上，框架在成功率和计算效率上优于现有方法。

Conclusion: 该框架高效可靠地解决了全局重定位问题，适用于非全景LiDAR和环境变化场景。

Abstract: This paper addresses the Kidnapped Robot Problem (KRP), a core localization
challenge of relocalizing a robot in a known map without prior pose estimate
when localization loss or at SLAM initialization. For this purpose, a passive
2-D global relocalization framework is proposed. It estimates the global pose
efficiently and reliably from a single LiDAR scan and an occupancy grid map
while the robot remains stationary, thereby enhancing the long-term autonomy of
mobile robots. The proposed framework casts global relocalization as a
non-convex problem and solves it via the multi-hypothesis scheme with batched
multi-stage inference and early termination, balancing completeness and
efficiency. The Rapidly-exploring Random Tree (RRT), under traversability
constraints, asymptotically covers the reachable space to generate sparse,
uniformly distributed feasible positional hypotheses, fundamentally reducing
the sampling space. The hypotheses are preliminarily ordered by the proposed
Scan Mean Absolute Difference (SMAD), a coarse beam-error level metric that
facilitates the early termination by prioritizing high-likelihood candidates.
The SMAD computation is optimized for non-panoramic scans. And the
Translation-Affinity Scan-to-Map Alignment Metric (TAM) is proposed for
reliable orientation selection at hypothesized positions and accurate final
pose evaluation to mitigate degradation in conventional likelihood-field
metrics under translational uncertainty induced by sparse hypotheses, as well
as non-panoramic LiDAR scan and environmental changes. Real-world experiments
on a resource-constrained mobile robot with non-panoramic LiDAR scan
demonstrate that the proposed framework outperforms existing methods in both
global relocalization success rate and computational efficiency.

</details>


### [402] [Embodiment Transfer Learning for Vision-Language-Action Models](https://arxiv.org/abs/2511.01224)
*Chengmeng Li,Yaxin Peng*

Main category: cs.RO

TL;DR: ET-VLA框架通过合成数据预训练和图思考技术，提升多机器人协作性能。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在多机器人协作中表现不佳，需高效迁移方法。

Method: 提出ET-VLA框架，包含合成预训练（SCP）和图思考技术。

Result: 在仿真和真实机器人任务中，ET-VLA性能超过OpenVLA 53.2%。

Conclusion: ET-VLA为多机器人协作提供高效解决方案，代码将开源。

Abstract: Vision-language-action (VLA) models have significantly advanced robotic
learning, enabling training on large-scale, cross-embodiment data and
fine-tuning for specific robots. However, state-of-the-art autoregressive VLAs
struggle with multi-robot collaboration. We introduce embodiment transfer
learning, denoted as ET-VLA, a novel framework for efficient and effective
transfer of pre-trained VLAs to multi-robot. ET-VLA's core is Synthetic
Continued Pretraining (SCP), which uses synthetically generated data to warm up
the model for the new embodiment, bypassing the need for real human
demonstrations and reducing data collection costs. SCP enables the model to
learn correct actions and precise action token numbers. Following SCP, the
model is fine-tuned on target embodiment data. To further enhance the model
performance on multi-embodiment, we present the Embodied Graph-of-Thought
technique, a novel approach that formulates each sub-task as a node, that
allows the VLA model to distinguish the functionalities and roles of each
embodiment during task execution. Our work considers bimanual robots, a simple
version of multi-robot to verify our approaches. We validate the effectiveness
of our method on both simulation benchmarks and real robots covering three
different bimanual embodiments. In particular, our proposed ET-VLA \space can
outperform OpenVLA on six real-world tasks over 53.2%. We will open-source all
codes to support the community in advancing VLA models for robot learning.

</details>


### [403] [High-Precision Surgical Robotic System for Intraocular Procedures](https://arxiv.org/abs/2511.01232)
*Yu-Ting Lai,Jacob Rosen,Yasamin Foroutani,Ji Ma,Wen-Cheng Wu,Jean-Pierre Hubschman,Tsu-Chin Tsao*

Main category: cs.RO

TL;DR: 提出了一种新型机器人系统，旨在提高眼科手术中工具尖端精度、跟踪性能及工具交换机制。


<details>
  <summary>Details</summary>
Motivation: 现有技术在眼科手术中精度、自由度及工具交换方面表现不足，亟需改进。

Method: 设计并制造了新机器人系统，通过OCT系统评估其工具尖端精度、机械性能及远程中心运动能力。

Result: 工具尖端定位精度达0.053±0.031 mm，并在OCT引导下成功完成自动化白内障手术。

Conclusion: 新系统显著提升了手术精度和自动化能力，为眼科手术机器人技术提供了重要改进。

Abstract: Despite the extensive demonstration of robotic systems for both cataract and
vitreoretinal procedures, existing technologies or mechanisms still possess
insufficient accuracy, precision, and degrees of freedom for instrument
manipulation or potentially automated tool exchange during surgical procedures.
A new robotic system that focuses on improving tooltip accuracy, tracking
performance, and smooth instrument exchange mechanism is therefore designed and
manufactured. Its tooltip accuracy, precision, and mechanical capability of
maintaining small incision through remote center of motion were externally
evaluated using an optical coherence tomography (OCT) system. Through robot
calibration and precise coordinate registration, the accuracy of tooltip
positioning was measured to be 0.053$\pm$0.031 mm, and the overall performance
was demonstrated on an OCT-guided automated cataract lens extraction procedure
with deep learning-based pre-operative anatomical modeling and real-time
supervision.

</details>


### [404] [Don't Just Search, Understand: Semantic Path Planning Agent for Spherical Tensegrity Robots in Unknown Environments](https://arxiv.org/abs/2511.01236)
*Junwen Zhang,Changyue Liu,Pengqi Fu,Xiang Guo,Ye Shi,Xudong Liang,Zhijian Wang,Hanzhi Ma*

Main category: cs.RO

TL;DR: 提出了一种基于大语言模型的语义路径规划器（SATPlanner），用于球形张拉整体机器人在未知环境中的高效路径规划。


<details>
  <summary>Details</summary>
Motivation: 传统路径规划器在复杂环境中因缺乏语义理解而效率低下，需要一种能结合环境语义信息的新方法。

Method: 利用大语言模型驱动的语义代理（SATPlanner），通过自适应观察窗口机制动态调整感知范围，实现高效搜索。

Result: 在1000次仿真试验中达到100%成功率，搜索空间减少37.2%，路径质量接近最优。

Conclusion: SATPlanner在理论和实践中均表现出色，为复杂环境中的机器人路径规划提供了新思路。

Abstract: Endowed with inherent dynamical properties that grant them remarkable
ruggedness and adaptability, spherical tensegrity robots stand as prototypical
examples of hybrid softrigid designs and excellent mobile platforms. However,
path planning for these robots in unknown environments presents a significant
challenge, requiring a delicate balance between efficient exploration and
robust planning. Traditional path planners, which treat the environment as a
geometric grid, often suffer from redundant searches and are prone to failure
in complex scenarios due to their lack of semantic understanding. To overcome
these limitations, we reframe path planning in unknown environments as a
semantic reasoning task. We introduce a Semantic Agent for Tensegrity robots
(SATPlanner) driven by a Large Language Model (LLM). SATPlanner leverages
high-level environmental comprehension to generate efficient and reliable
planning strategies.At the core of SATPlanner is an Adaptive Observation Window
mechanism, inspired by the "fast" and "slow" thinking paradigms of LLMs. This
mechanism dynamically adjusts the perceptual field of the agent: it narrows for
rapid traversal of open spaces and expands to reason about complex obstacle
configurations. This allows the agent to construct a semantic belief of the
environment, enabling the search space to grow only linearly with the path
length (O(L)) while maintaining path quality. We extensively evaluate
SATPlanner in 1,000 simulation trials, where it achieves a 100% success rate,
outperforming other real-time planning algorithms. Critically, SATPlanner
reduces the search space by 37.2% compared to the A* algorithm while achieving
comparable, near-optimal path lengths. Finally, the practical feasibility of
SATPlanner is validated on a physical spherical tensegrity robot prototype.

</details>


### [405] [Improving Needle Penetration via Precise Rotational Insertion Using Iterative Learning Control](https://arxiv.org/abs/2511.01256)
*Yasamin Foroutani,Yasamin Mousavi-Motlagh,Aya Barzelay,Tsu-Chin Tsao*

Main category: cs.RO

TL;DR: 论文提出了一种迭代学习控制（ILC）策略，用于机器人手术中的精确旋转插入，提高了穿透效果和安全性。


<details>
  <summary>Details</summary>
Motivation: 机器人手术中工具路径的精确控制常受系统偏差、未建模动态和驱动误差的挑战，需解决旋转插入的精度问题。

Method: 使用4自由度机器人，通过前向运动学校准和OCT扫描反馈，迭代调整关节指令。

Result: 在猪眼实验中，优化轨迹比直线插入提高了组织穿透和视网膜下注射的成功率。

Conclusion: ILC策略有效克服偏差问题，适用于其他高精度机器人任务。

Abstract: Achieving precise control of robotic tool paths is often challenged by
inherent system misalignments, unmodeled dynamics, and actuation inaccuracies.
This work introduces an Iterative Learning Control (ILC) strategy to enable
precise rotational insertion of a tool during robotic surgery, improving
penetration efficacy and safety compared to straight insertion tested in
subretinal injection. A 4 degree of freedom (DOF) robot manipulator is used,
where misalignment of the fourth joint complicates the simple application of
needle rotation, motivating an ILC approach that iteratively adjusts joint
commands based on positional feedback. The process begins with calibrating the
forward kinematics for the chosen surgical tool to achieve higher accuracy,
followed by successive ILC iterations guided by Optical Coherence Tomography
(OCT) volume scans to measure the error and refine control inputs. Experimental
results, tested on subretinal injection tasks on ex vivo pig eyes, show that
the optimized trajectory resulted in higher success rates in tissue penetration
and subretinal injection compared to straight insertion, demonstrating the
effectiveness of ILC in overcoming misalignment challenges. This approach
offers potential applications for other high precision robot tasks requiring
controlled insertions as well.

</details>


### [406] [Design and Fabrication of Origami-Inspired Knitted Fabrics for Soft Robotics](https://arxiv.org/abs/2511.01272)
*Sehui Jeong,Magaly C. Aviles,Athena X. Naylor,Cynthia Sung,Allison M. Okamura*

Main category: cs.RO

TL;DR: 提出了一种结合折纸结构和针织面料的新型设计与制造方法，用于可穿戴软机器人，兼具结构完整性和舒适性。


<details>
  <summary>Details</summary>
Motivation: 解决可穿戴软机器人中结构完整性与舒适性难以兼顾的挑战。

Method: 通过编程针织图案和材料图案，将折纸结构转化为针织设计，利用热熔纱线选择性增强刚性面板。

Result: 成功复现复杂折纸图案，并展示了可穿戴针织机器人的运动能力。

Conclusion: 针织折纸技术为下一代可穿戴机器人提供了有前景的平台。

Abstract: Soft robots employing compliant materials and deformable structures offer
great potential for wearable devices that are comfortable and safe for human
interaction. However, achieving both structural integrity and compliance for
comfort remains a significant challenge. In this study, we present a novel
fabrication and design method that combines the advantages of origami
structures with the material programmability and wearability of knitted
fabrics. We introduce a general design method that translates origami patterns
into knit designs by programming both stitch and material patterns. The method
creates folds in preferred directions while suppressing unintended buckling and
bending by selectively incorporating heat fusible yarn to create rigid panels
around compliant creases. We experimentally quantify folding moments and show
that stitch patterning enhances folding directionality while the heat fusible
yarn (1) keeps geometry consistent by reducing edge curl and (2) prevents
out-of-plane deformations by stiffening panels. We demonstrate the framework
through the successful reproduction of complex origami tessellations, including
Miura-ori, Yoshimura, and Kresling patterns, and present a wearable knitted
Kaleidocycle robot capable of locomotion. The combination of structural
reconfigurability, material programmability, and potential for manufacturing
scalability highlights knitted origami as a promising platform for
next-generation wearable robotics.

</details>


### [407] [Contact Map Transfer with Conditional Diffusion Model for Generalizable Dexterous Grasp Generation](https://arxiv.org/abs/2511.01276)
*Yiyao Ma,Kai Chen,Kexin Zheng,Qi Dou*

Main category: cs.RO

TL;DR: 提出了一种基于条件扩散模型的灵巧抓取生成框架，通过形状模板将高质量抓取迁移到同类新物体上，提升了抓取质量和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统分析方法效率低且缺乏任务适应性，生成方法虽高效但泛化能力差。本文旨在结合两者优势，解决灵巧抓取生成的挑战。

Method: 采用条件扩散模型，通过生成物体接触图、部分图和方向图，并结合双映射机制和级联扩散模型，实现抓取的迁移和优化。

Result: 实验表明，该方法在抓取质量、生成效率和泛化性能上均优于现有方法。

Conclusion: 提出的框架有效平衡了抓取质量与泛化能力，为灵巧抓取生成提供了新思路。

Abstract: Dexterous grasp generation is a fundamental challenge in robotics, requiring
both grasp stability and adaptability across diverse objects and tasks.
Analytical methods ensure stable grasps but are inefficient and lack task
adaptability, while generative approaches improve efficiency and task
integration but generalize poorly to unseen objects and tasks due to data
limitations. In this paper, we propose a transfer-based framework for dexterous
grasp generation, leveraging a conditional diffusion model to transfer
high-quality grasps from shape templates to novel objects within the same
category. Specifically, we reformulate the grasp transfer problem as the
generation of an object contact map, incorporating object shape similarity and
task specifications into the diffusion process. To handle complex shape
variations, we introduce a dual mapping mechanism, capturing intricate
geometric relationship between shape templates and novel objects. Beyond the
contact map, we derive two additional object-centric maps, the part map and
direction map, to encode finer contact details for more stable grasps. We then
develop a cascaded conditional diffusion model framework to jointly transfer
these three maps, ensuring their intra-consistency. Finally, we introduce a
robust grasp recovery mechanism, identifying reliable contact points and
optimizing grasp configurations efficiently. Extensive experiments demonstrate
the superiority of our proposed method. Our approach effectively balances grasp
quality, generation efficiency, and generalization performance across various
tasks. Project homepage: https://cmtdiffusion.github.io/

</details>


### [408] [A High-Speed Capable Spherical Robot](https://arxiv.org/abs/2511.01288)
*Bixuan Zhang,Fengqi Zhang,Haojie Chen,You Wang,Jie Hao,Zhiyuan Luo,Guang Li*

Main category: cs.RO

TL;DR: 设计了一种新型球形机器人结构，支持高达10 m/s的高速运动，通过实验验证了其稳定性和性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统单摆驱动球形机器人无法实现稳定高速运动，新设计旨在解决这一问题。

Method: 在单摆驱动基础上加入动量轮，轴与次级摆对齐，形成新结构。

Result: 实验证明新结构能通过简单解耦控制实现稳定高速运动，并提升越障能力和地形适应性。

Conclusion: 新型球形机器人结构在高速运动、越障和地形适应性方面表现优异。

Abstract: This paper designs a new spherical robot structure capable of supporting
high-speed motion at up to 10 m/s. Building upon a single-pendulum-driven
spherical robot, the design incorporates a momentum wheel with an axis aligned
with the secondary pendulum, creating a novel spherical robot structure.
Practical experiments with the physical prototype have demonstrated that this
new spherical robot can achieve stable high-speed motion through simple
decoupled control, which was unattainable with the original structure. The
spherical robot designed for high-speed motion not only increases speed but
also significantly enhances obstacle-crossing performance and terrain
robustness.

</details>


### [409] [Kinematify: Open-Vocabulary Synthesis of High-DoF Articulated Objects](https://arxiv.org/abs/2511.01294)
*Jiawei Wang,Dingyou Wang,Jiaming Hu,Qixuan Zhang,Jingyi Yu,Lan Xu*

Main category: cs.RO

TL;DR: Kinematify是一个自动化框架，通过RGB图像或文本提示合成关节物体，解决了高自由度物体运动拓扑推断和关节参数估计的挑战。


<details>
  <summary>Details</summary>
Motivation: 理解运动结构和可移动组件对机器人操作和建模至关重要，但现有方法依赖运动序列或手工数据集，难以扩展。

Method: 结合MCTS搜索和几何驱动优化，推断运动拓扑和关节参数，生成物理一致的描述。

Result: 在合成和真实环境中验证，Kinematify在注册和运动拓扑准确性上优于现有方法。

Conclusion: Kinematify为复杂系统的关节建模提供了自动化解决方案，提升了准确性和可扩展性。

Abstract: A deep understanding of kinematic structures and movable components is
essential for enabling robots to manipulate objects and model their own
articulated forms. Such understanding is captured through articulated objects,
which are essential for tasks such as physical simulation, motion planning, and
policy learning. However, creating these models, particularly for complex
systems like robots or objects with high degrees of freedom (DoF), remains a
significant challenge. Existing methods typically rely on motion sequences or
strong assumptions from hand-curated datasets, which hinders scalability. In
this paper, we introduce Kinematify, an automated framework that synthesizes
articulated objects directly from arbitrary RGB images or text prompts. Our
method addresses two core challenges: (i) inferring kinematic topologies for
high-DoF objects and (ii) estimating joint parameters from static geometry. To
achieve this, we combine MCTS search for structural inference with
geometry-driven optimization for joint reasoning, producing physically
consistent and functionally valid descriptions. We evaluate Kinematify on
diverse inputs from both synthetic and real-world environments, demonstrating
improvements in registration and kinematic topology accuracy over prior work.

</details>


### [410] [RobustVLA: Robustness-Aware Reinforcement Post-Training for Vision-Language-Action Models](https://arxiv.org/abs/2511.01331)
*Hongyin Zhang,Shuo Zhang,Junxi Jin,Qixin Zeng,Runze Li,Donglin Wang*

Main category: cs.RO

TL;DR: RobustVLA是一种轻量级在线RL后训练方法，旨在增强VLA模型的鲁棒性，通过Jacobian和平滑正则化显著提升模型在噪声和扰动环境中的表现。


<details>
  <summary>Details</summary>
Motivation: VLA模型在分布外部署中因噪声和扰动表现不佳，现有RL后训练方法忽视了对环境不确定性的鲁棒性。

Method: 提出RobustVLA，结合Jacobian正则化（减少观测噪声敏感性）和平滑正则化（稳定动作扰动下的策略）。

Result: 实验表明RobustVLA在多样机器人环境中显著优于现有方法，提升了鲁棒性和可靠性。

Conclusion: 鲁棒性感知的RL后训练是提升VLA模型可靠性的关键步骤。

Abstract: Vision-Language-Action (VLA) models have recently emerged as powerful
general-purpose policies for robotic manipulation, benefiting from large-scale
multi-modal pre-training. However, they often fail to generalize reliably in
out-of-distribution deployments, where unavoidable disturbances such as
observation noise, sensor errors, or actuation perturbations become prevalent.
While recent Reinforcement Learning (RL)-based post-training provides a
practical means to adapt pre-trained VLA models, existing methods mainly
emphasize reward maximization and overlook robustness to environmental
uncertainty. In this work, we introduce RobustVLA, a lightweight online RL
post-training method designed to explicitly enhance the resilience of VLA
models. Through a systematic robustness analysis, we identify two key
regularizations: Jacobian regularization, which mitigates sensitivity to
observation noise, and smoothness regularization, which stabilizes policies
under action perturbations. Extensive experiments across diverse robotic
environments demonstrate that RobustVLA significantly outperforms prior
state-of-the-art methods in robustness and reliability. Our results highlight
the importance of principled robustness-aware RL post-training as a key step
toward improving the reliability and robustness of VLA models.

</details>


### [411] [Embodied Cognition Augmented End2End Autonomous Driving](https://arxiv.org/abs/2511.01334)
*Ling Niu,Xiaoji Zheng,Han Wang,Chen Zheng,Ziyuan Yang,Bokui Chen,Jiangtao Gong*

Main category: cs.RO

TL;DR: 提出了一种名为$E^{3}AD$的新范式，通过对比学习视觉特征提取网络与EEG大模型，学习人类驾驶认知以增强端到端规划。


<details>
  <summary>Details</summary>
Motivation: 现有端到端自动驾驶方法依赖标签监督的视觉特征提取网络，限制了模型的通用性和适用性。

Method: 收集认知数据集进行对比学习，研究如何利用人类驾驶认知增强端到端规划，并在公开数据集上进行测试。

Result: $E^{3}AD$显著提升了基线模型的端到端规划性能，消融实验验证了驾驶认知和对比学习的有效性。

Conclusion: 这是首次将人类驾驶认知融入端到端自动驾驶规划的工作，为未来脑启发自动驾驶系统提供了宝贵见解。

Abstract: In recent years, vision-based end-to-end autonomous driving has emerged as a
new paradigm. However, popular end-to-end approaches typically rely on visual
feature extraction networks trained under label supervision. This limited
supervision framework restricts the generality and applicability of driving
models. In this paper, we propose a novel paradigm termed $E^{3}AD$, which
advocates for comparative learning between visual feature extraction networks
and the general EEG large model, in order to learn latent human driving
cognition for enhancing end-to-end planning. In this work, we collected a
cognitive dataset for the mentioned contrastive learning process. Subsequently,
we investigated the methods and potential mechanisms for enhancing end-to-end
planning with human driving cognition, using popular driving models as
baselines on publicly available autonomous driving datasets. Both open-loop and
closed-loop tests are conducted for a comprehensive evaluation of planning
performance. Experimental results demonstrate that the $E^{3}AD$ paradigm
significantly enhances the end-to-end planning performance of baseline models.
Ablation studies further validate the contribution of driving cognition and the
effectiveness of comparative learning process. To the best of our knowledge,
this is the first work to integrate human driving cognition for improving
end-to-end autonomous driving planning. It represents an initial attempt to
incorporate embodied cognitive data into end-to-end autonomous driving,
providing valuable insights for future brain-inspired autonomous driving
systems. Our code will be made available at Github

</details>


### [412] [Thermo-responsive closing and reopening artificial Venus Flytrap utilizing shape memory elastomers](https://arxiv.org/abs/2511.01346)
*Shun Yoshida,Qingchuan Song,Bastian E. Rapp,Thomas Speck,Falk J. Tauber*

Main category: cs.RO

TL;DR: 研究开发了一种基于热响应形状记忆材料的自主开合人工捕蝇草系统。


<details>
  <summary>Details</summary>
Motivation: 捕蝇草的快速闭合和重新开放运动激发了软机器人和仿生系统的研究，但实现自主双向运动仍具挑战。

Method: 利用新型热响应紫外固化形状记忆材料，构建了具有双曲线陷阱瓣的人工捕蝇草系统。

Result: 该系统在自然温度范围内（38°C闭合，45°C重新开放）实现了自主开合运动。

Conclusion: 该研究为自主双向运动的软机器人和仿生系统提供了新思路。

Abstract: Despite their often perceived static and slow nature, some plants can move
faster than the blink of an eye. The rapid snap closure motion of the Venus
flytrap (Dionaea muscipula) has long captivated the interest of researchers and
engineers alike, serving as a model for plant-inspired soft machines and
robots. The translation of the fast snapping closure has inspired the
development of various artificial Venus flytrap (AVF) systems. However,
translating both the closing and reopening motion of D. muscipula into an
autonomous plant inspired soft machine has yet to be achieved. In this study,
we present an AVF that autonomously closes and reopens, utilizing novel
thermo-responsive UV-curable shape memory materials for soft robotic systems.
The life-sized thermo-responsive AVF exhibits closing and reopening motions
triggered in a naturally occurring temperature range. The doubly curved trap
lobes, built from shape memory polymers, close at 38{\deg}C, while reopening
initiates around 45{\deg}C, employing shape memory elastomer strips as
antagonistic actuators to facilitate lobe reopening. This work represents the
first demonstration of thermo-responsive closing and reopening in an AVF with
programmed sequential motion in response to increasing temperature. This
approach marks the next step toward autonomously bidirectional moving soft
machines/robots.

</details>


### [413] [Design and development of an electronics-free earthworm robot](https://arxiv.org/abs/2511.01347)
*Riddhi Das,Joscha Teichmann,Thomas Speck,Falk J. Tauber*

Main category: cs.RO

TL;DR: 提出了一种无电子元件的仿蚯蚓气动机器人，采用改进的气动逻辑门设计，实现了模块化和高效蠕动运动。


<details>
  <summary>Details</summary>
Motivation: 现有仿蚯蚓机器人依赖笨重且高功耗的电子控制单元，限制了实用性。

Method: 集成预配置气动逻辑门与波纹管执行器，构建模块化系统。

Result: 改进的气动逻辑门有效生成蠕动波，实现自主运动且偏差小。

Conclusion: 该系统为无电子元件的蠕动软机器人提供了概念验证，适用于危险环境。

Abstract: Soft robotic systems have gained widespread attention due to their inherent
flexibility, adaptability, and safety, making them well-suited for varied
applications. Among bioinspired designs, earthworm locomotion has been
extensively studied for its efficient peristaltic motion, enabling movement in
confined and unstructured environments. Existing earthworm-inspired robots
primarily utilize pneumatic actuation due to its high force-to-weight ratio and
ease of implementation. However, these systems often rely on bulky,
power-intensive electronic control units, limiting their practicality. In this
work, we present an electronics-free, earthworm-inspired pneumatic robot
utilizing a modified Pneumatic Logic Gate (PLG) design. By integrating
preconfigured PLG units with bellow actuators, we achieved a plug-and-play
style modular system capable of peristaltic locomotion without external
electronic components. The proposed design reduces system complexity while
maintaining efficient actuation. We characterize the bellow actuators under
different operating conditions and evaluate the robots locomotion performance.
Our findings demonstrate that the modified PLG-based control system effectively
generates peristaltic wave propagation, achieving autonomous motion with
minimal deviation. This study serves as a proof of concept for the development
of electronics-free, peristaltic soft robots. The proposed system has potential
for applications in hazardous environments, where untethered, adaptable
locomotion is critical. Future work will focus on further optimizing the robot
design and exploring untethered operation using onboard compressed air sources.

</details>


### [414] [Model to Model: Understanding the Venus Flytrap Snapping Mechanism and Transferring it to a 3D-printed Bistable Soft Robotic Demonstrator](https://arxiv.org/abs/2511.01350)
*Maartje H. M. Wermelink,Renate Sachse,Sebastian Kruppert,Thomas Speck,Falk J. Tauber*

Main category: cs.RO

TL;DR: 研究分析了捕蝇草的快速闭合机制，并基于其几何特征设计了两款双稳态执行器模型。


<details>
  <summary>Details</summary>
Motivation: 捕蝇草的快速闭合机制激发了植物学家和工程师的兴趣，研究旨在理解其运动力学并应用于人工执行器设计。

Method: 通过分析捕蝇草的几何特征（如尺寸比例和厚度梯度），设计并3D打印了两款双稳态执行器模型。

Result: 两款模型均表现出凹-凸双稳态特性，并能快速闭合，验证了捕蝇草机制的可行性。

Conclusion: 研究为开发模仿捕蝇草机械行为的人工快速软抓取器奠定了基础。

Abstract: The Venus flytrap (Dionaea muscipula) does not only serve as the textbook
model for a carnivorous plant, but also has long intrigued both botanists and
engineers with its rapidly closing leaf trap. The trap closure is triggered by
two consecutive touches of a potential prey, after which the lobes rapidly
switch from their concave open-state to their convex close-state and catch the
prey within 100-500 ms after being triggered. This transformation from concave
to convex is initiated by changes in turgor pressure and the release of stored
elastic energy from prestresses in the concave state, which accelerate this
movement, leading to inversion of the lobes bi-axial curvature. Possessing two
low-energy states, the leaves can be characterized as bistable systems. With
our research, we seek to deepen the understanding of Venus flytrap motion
mechanics and apply its principles to the design of an artificial bistable lobe
actuator. We identified geometrical characteristics, such as dimensional ratios
and the thickness gradient in the lobe, and transferred these to two 3D-printed
bistable actuator models. One actuator parallels the simulated geometry of a
Venus flytrap leaf, the other is a lobe model designed with CAD. Both models
display concave-convex bi-stability and snap close. These demonstrators are the
first step in the development of an artificial Venus flytrap that mimics the
mechanical behavior of the biological model and can be used as a soft fast
gripper.

</details>


### [415] [Lateral Velocity Model for Vehicle Parking Applications](https://arxiv.org/abs/2511.01369)
*Luis Diener,Jens Kalkkuhl,Markus Enzweiler*

Main category: cs.RO

TL;DR: 论文提出了一种改进的侧向速度模型，用于解决自动泊车中侧向速度估计的挑战，提高了估计精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖零滑移假设，但在低速驾驶时该假设不成立，导致侧向速度估计不准确。

Method: 通过分析真实泊车场景数据，提出了一种新的侧向速度模型，仅需两个参数。

Result: 新模型显著提高了侧向速度估计的准确性。

Conclusion: 该模型适用于消费级车辆，为自动泊车提供了更精确的侧向速度估计。

Abstract: Automated parking requires accurate localization for quick and precise
maneuvering in tight spaces. While the longitudinal velocity can be measured
using wheel encoders, the estimation of the lateral velocity remains a key
challenge due to the absence of dedicated sensors in consumer-grade vehicles.
Existing approaches often rely on simplified vehicle models, such as the
zero-slip model, which assumes no lateral velocity at the rear axle. It is well
established that this assumption does not hold during low-speed driving and
researchers thus introduce additional heuristics to account for differences. In
this work, we analyze real-world data from parking scenarios and identify a
systematic deviation from the zero-slip assumption. We provide explanations for
the observed effects and then propose a lateral velocity model that better
captures the lateral dynamics of the vehicle during parking. The model improves
estimation accuracy, while relying on only two parameters, making it
well-suited for integration into consumer-grade applications.

</details>


### [416] [CM-LIUW-Odometry: Robust and High-Precision LiDAR-Inertial-UWB-Wheel Odometry for Extreme Degradation Coal Mine Tunnels](https://arxiv.org/abs/2511.01379)
*Kun Hu,Menggang Li,Zhiwen Jin,Chaoquan Tang,Eryi Hu,Gongbo Zhou*

Main category: cs.RO

TL;DR: 提出了一种多模态SLAM框架CM-LIUW-Odometry，用于解决煤矿地下环境中GPS缺失、地形复杂等问题，结合LiDAR、IMU、UWB和轮式里程计，通过IESKF实现高精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 煤矿地下环境GPS缺失、地形复杂且传感器性能受限，传统SLAM方法难以应对。

Method: 结合LiDAR-IMU里程计与UWB绝对定位约束，通过IESKF融合轮式里程计，并引入NHC和杠杆臂补偿，动态调整运动模式。

Result: 在真实煤矿地下环境中验证了方法的优越性和鲁棒性，优于现有技术。

Conclusion: CM-LIUW-Odometry在复杂环境中表现优异，代码已开源。

Abstract: Simultaneous Localization and Mapping (SLAM) in large-scale, complex, and
GPS-denied underground coal mine environments presents significant challenges.
Sensors must contend with abnormal operating conditions: GPS unavailability
impedes scene reconstruction and absolute geographic referencing, uneven or
slippery terrain degrades wheel odometer accuracy, and long, feature-poor
tunnels reduce LiDAR effectiveness. To address these issues, we propose
CoalMine-LiDAR-IMU-UWB-Wheel-Odometry (CM-LIUW-Odometry), a multimodal SLAM
framework based on the Iterated Error-State Kalman Filter (IESKF). First,
LiDAR-inertial odometry is tightly fused with UWB absolute positioning
constraints to align the SLAM system with a global coordinate. Next, wheel
odometer is integrated through tight coupling, enhanced by nonholonomic
constraints (NHC) and vehicle lever arm compensation, to address performance
degradation in areas beyond UWB measurement range. Finally, an adaptive motion
mode switching mechanism dynamically adjusts the robot's motion mode based on
UWB measurement range and environmental degradation levels. Experimental
results validate that our method achieves superior accuracy and robustness in
real-world underground coal mine scenarios, outperforming state-of-the-art
approaches. We open source our code of this work on Github to benefit the
robotics community.

</details>


### [417] [CaRLi-V: Camera-RADAR-LiDAR Point-Wise 3D Velocity Estimation](https://arxiv.org/abs/2511.01383)
*Landson Guo,Andres M. Diaz Aguilar,William Talbot,Turcan Tuna,Marco Hutter,Cesar Cadena*

Main category: cs.RO

TL;DR: 提出了一种名为CaRLi-V的新型雷达、激光雷达和相机融合管道，用于点级3D速度估计，通过开源ROS2包实现，并在实际测试中表现出低误差。


<details>
  <summary>Details</summary>
Motivation: 在动态环境中，精确的点级3D速度估计对机器人路径规划、避障和物体操作至关重要。

Method: 结合速度立方体（用于径向速度提取）、光流（用于切向速度估计）和激光雷达（用于点级距离测量），通过闭式解生成3D速度估计。

Result: CaRLi-V在实际测试中表现出低速度误差，适用于机器人应用。

Conclusion: CaRLi-V通过多传感器融合实现了高效的点级3D速度估计，为机器人动态交互提供了可靠支持。

Abstract: Accurate point-wise velocity estimation in 3D is crucial for robot
interaction with non-rigid, dynamic agents, such as humans, enabling robust
performance in path planning, collision avoidance, and object manipulation in
dynamic environments. To this end, this paper proposes a novel RADAR, LiDAR,
and camera fusion pipeline for point-wise 3D velocity estimation named CaRLi-V.
This pipeline leverages raw RADAR measurements to create a novel RADAR
representation, the velocity cube, which densely represents radial velocities
within the RADAR's field-of-view. By combining the velocity cube for radial
velocity extraction, optical flow for tangential velocity estimation, and LiDAR
for point-wise range measurements through a closed-form solution, our approach
can produce 3D velocity estimates for a dense array of points. Developed as an
open-source ROS2 package, CaRLi-V has been field-tested against a custom
dataset and proven to produce low velocity error metrics relative to ground
truth, enabling point-wise velocity estimation for robotic applications.

</details>


### [418] [FoldPath: End-to-End Object-Centric Motion Generation via Modulated Implicit Paths](https://arxiv.org/abs/2511.01407)
*Paolo Rabino,Gabriele Tiboni,Tatiana Tommasi*

Main category: cs.RO

TL;DR: FoldPath是一种基于神经场的端到端方法，用于对象中心运动生成（OCMG），通过学习连续函数生成平滑路径，无需后处理步骤。


<details>
  <summary>Details</summary>
Motivation: 当前OCMG技术依赖启发式方法或需要敏感后处理的基于学习的方法，无法高效生成可执行路径。

Method: FoldPath通过神经场学习机器人运动的连续函数，隐式编码平滑路径，避免离散路径点的后处理。

Result: FoldPath在预测性能上优于现有方法，并在仅有70个专家样本的工业场景中展现出泛化能力。

Conclusion: FoldPath通过新指标验证了其在长时程机器人路径生成中的实用性，推动了OCMG任务的成熟。

Abstract: Object-Centric Motion Generation (OCMG) is instrumental in advancing
automated manufacturing processes, particularly in domains requiring
high-precision expert robotic motions, such as spray painting and welding. To
realize effective automation, robust algorithms are essential for generating
extended, object-aware trajectories across intricate 3D geometries. However,
contemporary OCMG techniques are either based on ad-hoc heuristics or employ
learning-based pipelines that are still reliant on sensitive post-processing
steps to generate executable paths. We introduce FoldPath, a novel, end-to-end,
neural field based method for OCMG. Unlike prior deep learning approaches that
predict discrete sequences of end-effector waypoints, FoldPath learns the robot
motion as a continuous function, thus implicitly encoding smooth output paths.
This paradigm shift eliminates the need for brittle post-processing steps that
concatenate and order the predicted discrete waypoints. Particularly, our
approach demonstrates superior predictive performance compared to recently
proposed learning-based methods, and attains generalization capabilities even
in real industrial settings, where only a limited amount of 70 expert samples
are provided. We validate FoldPath through comprehensive experiments in a
realistic simulation environment and introduce new, rigorous metrics designed
to comprehensively evaluate long-horizon robotic paths, thus advancing the OCMG
task towards practical maturity.

</details>


### [419] [Designing for Distributed Heterogeneous Modularity: On Software Architecture and Deployment of MoonBots](https://arxiv.org/abs/2511.01437)
*Elian Neppel,Shamistan Karimov,Ashutosh Mishra,Gustavo Hernan Diaz Huenupan,Hazal Gozbasi,Kentaro Uno,Shreya Santra,Kazuya Yoshida*

Main category: cs.RO

TL;DR: MoonBot平台是一个模块化太空机器人系统，通过分布式、异构模块化方法，结合ROS2和Zenoh等技术，实现了动态重构和去中心化控制。


<details>
  <summary>Details</summary>
Motivation: 解决模块化机器人在软件、通信和协调方面的挑战，降低集成和维护成本。

Method: 采用组件化设计、数据导向通信模型和部署协调器，结合开源Motion Stack软件。

Result: 系统经过实地测试，支持自组装机器人、机器人间协作和远程操作，具有可扩展性和鲁棒性。

Conclusion: 该架构不仅适用于太空场景，还为跨时间、硬件、团队和环境的机器人系统设计提供了通用模式。

Abstract: This paper presents the software architecture and deployment strategy behind
the MoonBot platform: a modular space robotic system composed of heterogeneous
components distributed across multiple computers, networks and ultimately
celestial bodies. We introduce a principled approach to distributed,
heterogeneous modularity, extending modular robotics beyond physical
reconfiguration to software, communication and orchestration. We detail the
architecture of our system that integrates component-based design, a
data-oriented communication model using ROS2 and Zenoh, and a deployment
orchestrator capable of managing complex multi-module assemblies. These
abstractions enable dynamic reconfiguration, decentralized control, and
seamless collaboration between numerous operators and modules. At the heart of
this system lies our open-source Motion Stack software, validated by months of
field deployment with self-assembling robots, inter-robot cooperation, and
remote operation. Our architecture tackles the significant hurdles of modular
robotics by significantly reducing integration and maintenance overhead, while
remaining scalable and robust. Although tested with space in mind, we propose
generalizable patterns for designing robotic systems that must scale across
time, hardware, teams and operational environments.

</details>


### [420] [AERMANI-VLM: Structured Prompting and Reasoning for Aerial Manipulation with Vision Language Models](https://arxiv.org/abs/2511.01472)
*Sarthak Mishra,Rishabh Dev Yadav,Avirup Das,Saksham Gupta,Wei Pan,Spandan Roy*

Main category: cs.RO

TL;DR: AERMANI-VLM框架通过分离高层推理与低层控制，将预训练的视觉-语言模型（VLMs）应用于空中机械臂操作，无需任务特定微调。


<details>
  <summary>Details</summary>
Motivation: 直接部署VLM驱动的策略在空中机械臂上不安全且不可靠，因为生成的动作常不一致、易产生幻觉且飞行动态不可行。

Method: 框架通过结构化提示编码自然语言指令、任务上下文和安全约束，生成逐步推理的自然语言跟踪，并选择预定义的飞行安全技能库。

Result: 在仿真和硬件实验中验证了框架的鲁棒性，展示了其对未见命令、物体和环境的强泛化能力。

Conclusion: AERMANI-VLM通过解耦符号推理与物理动作，减少了幻觉命令并防止不安全行为，实现了稳健的任务完成。

Abstract: The rapid progress of vision--language models (VLMs) has sparked growing
interest in robotic control, where natural language can express the operation
goals while visual feedback links perception to action. However, directly
deploying VLM-driven policies on aerial manipulators remains unsafe and
unreliable since the generated actions are often inconsistent,
hallucination-prone, and dynamically infeasible for flight. In this work, we
present AERMANI-VLM, the first framework to adapt pretrained VLMs for aerial
manipulation by separating high-level reasoning from low-level control, without
any task-specific fine-tuning. Our framework encodes natural language
instructions, task context, and safety constraints into a structured prompt
that guides the model to generate a step-by-step reasoning trace in natural
language. This reasoning output is used to select from a predefined library of
discrete, flight-safe skills, ensuring interpretable and temporally consistent
execution. By decoupling symbolic reasoning from physical action, AERMANI-VLM
mitigates hallucinated commands and prevents unsafe behavior, enabling robust
task completion. We validate the framework in both simulation and hardware on
diverse multi-step pick-and-place tasks, demonstrating strong generalization to
previously unseen commands, objects, and environments.

</details>


### [421] [MO-SeGMan: Rearrangement Planning Framework for Multi Objective Sequential and Guided Manipulation in Constrained Environments](https://arxiv.org/abs/2511.01476)
*Cankut Bora Tuncer,Marc Toussaint,Ozgur S. Oguz*

Main category: cs.RO

TL;DR: MO-SeGMan是一种多目标序列化引导操作规划器，用于解决高度受限的重排问题，通过最小化重新规划和机器人移动距离，同时保留关键依赖结构。


<details>
  <summary>Details</summary>
Motivation: 解决高度杂乱、非单调场景中的重排问题，提高规划效率和解决方案质量。

Method: 采用选择性引导前向搜索（SGFS）和自适应子目标选择的细化方法，以减少不必要的操作。

Result: 在九个基准重排任务中，MO-SeGMan均生成可行运动计划，解决方案时间和质量优于基线。

Conclusion: MO-SeGMan框架在复杂重排规划问题中表现出鲁棒性和可扩展性。

Abstract: In this work, we introduce MO-SeGMan, a Multi-Objective Sequential and Guided
Manipulation planner for highly constrained rearrangement problems. MO-SeGMan
generates object placement sequences that minimize both replanning per object
and robot travel distance while preserving critical dependency structures with
a lazy evaluation method. To address highly cluttered, non-monotone scenarios,
we propose a Selective Guided Forward Search (SGFS) that efficiently relocates
only critical obstacles and to feasible relocation points. Furthermore, we
adopt a refinement method for adaptive subgoal selection to eliminate
unnecessary pick-and-place actions, thereby improving overall solution quality.
Extensive evaluations on nine benchmark rearrangement tasks demonstrate that
MO-SeGMan generates feasible motion plans in all cases, consistently achieving
faster solution times and superior solution quality compared to the baselines.
These results highlight the robustness and scalability of the proposed
framework for complex rearrangement planning problems.

</details>


### [422] [Floor Plan-Guided Visual Navigation Incorporating Depth and Directional Cues](https://arxiv.org/abs/2511.01493)
*Wei Huang,Jiaxin Li,Zang Wan,Huijun Di,Wei Liang,Zhu Yang*

Main category: cs.RO

TL;DR: GlocDiff是一种基于扩散的策略，结合全局路径规划和局部深度感知特征，解决了RGB输入与平面图之间的模态差距问题，提升了导航性能。


<details>
  <summary>Details</summary>
Motivation: 解决RGB输入与平面图之间的模态差距问题，以及未见环境中精确定位的挑战。

Method: 提出GlocDiff策略，结合全局路径规划和局部深度感知特征，并通过噪声扰动增强鲁棒性。

Result: 在FloNa基准测试中表现优异，实际部署验证了其广泛应用的潜力。

Conclusion: GlocDiff在导航任务中表现出色，具有实际应用价值。

Abstract: Guiding an agent to a specific target in indoor environments based solely on
RGB inputs and a floor plan is a promising yet challenging problem. Although
existing methods have made significant progress, two challenges remain
unresolved. First, the modality gap between egocentric RGB observations and the
floor plan hinders the integration of visual and spatial information for both
local obstacle avoidance and global planning. Second, accurate localization is
critical for navigation performance, but remains challenging at deployment in
unseen environments due to the lack of explicit geometric alignment between RGB
inputs and floor plans. We propose a novel diffusion-based policy, denoted as
GlocDiff, which integrates global path planning from the floor plan with local
depth-aware features derived from RGB observations. The floor plan offers
explicit global guidance, while the depth features provide implicit geometric
cues, collectively enabling precise prediction of optimal navigation directions
and robust obstacle avoidance. Moreover, GlocDiff introduces noise perturbation
during training to enhance robustness against pose estimation errors, and we
find that combining this with a relatively stable VO module during inference
results in significantly improved navigation performance. Extensive experiments
on the FloNa benchmark demonstrate GlocDiff's efficiency and effectiveness in
achieving superior navigation performance, and the success of real-world
deployments also highlights its potential for widespread practical
applications.

</details>


### [423] [Phy-Tac: Toward Human-Like Grasping via Physics-Conditioned Tactile Goals](https://arxiv.org/abs/2511.01520)
*Shipeng Lyu,Lijie Sheng,Fangyuan Wang,Wenyao Zhang,Weiwei Lin,Zhenzhong Jia,David Navarro-Alarcon,Guodong Guo*

Main category: cs.RO

TL;DR: 提出了一种受人类启发的物理条件触觉方法（Phy-Tac），用于实现力最优稳定抓取（FOSG），结合了姿态选择、触觉预测和力调节。


<details>
  <summary>Details</summary>
Motivation: 机器人通常依赖刚性、过度挤压的控制，而人类能自然以最小力稳定抓取。研究旨在缩小这一差距。

Method: 通过物理基础姿态选择器确定最优力分布，物理条件潜在扩散模型（Phy-LDM）预测触觉印记，潜在空间LQR控制器驱动夹持器。

Result: Phy-LDM触觉预测准确率高，Phy-Tac在抓取稳定性和力效率上优于固定力和GraspNet基线。

Conclusion: 实验证明该方法实现了力高效和自适应操作，缩小了机器人与人类抓取的差距。

Abstract: Humans naturally grasp objects with minimal level required force for
stability, whereas robots often rely on rigid, over-squeezing control. To
narrow this gap, we propose a human-inspired physics-conditioned tactile method
(Phy-Tac) for force-optimal stable grasping (FOSG) that unifies pose selection,
tactile prediction, and force regulation. A physics-based pose selector first
identifies feasible contact regions with optimal force distribution based on
surface geometry. Then, a physics-conditioned latent diffusion model (Phy-LDM)
predicts the tactile imprint under FOSG target. Last, a latent-space LQR
controller drives the gripper toward this tactile imprint with minimal
actuation, preventing unnecessary compression. Trained on a physics-conditioned
tactile dataset covering diverse objects and contact conditions, the proposed
Phy-LDM achieves superior tactile prediction accuracy, while the Phy-Tac
outperforms fixed-force and GraspNet-based baselines in grasp stability and
force efficiency. Experiments on classical robotic platforms demonstrate
force-efficient and adaptive manipulation that bridges the gap between robotic
and human grasping.

</details>


### [424] [MARS: Multi-Agent Robotic System with Multimodal Large Language Models for Assistive Intelligence](https://arxiv.org/abs/2511.01594)
*Renjun Gao,Peiyan Zhong*

Main category: cs.RO

TL;DR: MARS是一个基于多模态大语言模型（MLLMs）的多智能体机器人系统，旨在为智能家居机器人提供风险感知、个性化的辅助功能。


<details>
  <summary>Details</summary>
Motivation: 现有系统在风险感知规划、用户个性化和将语言计划转化为可执行技能方面存在不足，MARS旨在解决这些问题。

Method: 系统整合了四个智能体：视觉感知、风险评估、规划和评估，通过多模态感知和分层决策实现自适应辅助。

Result: 实验表明，MARS在风险感知规划和多智能体协调执行方面优于现有模型。

Conclusion: MARS展示了协作AI在辅助场景中的潜力，并为实际部署提供了通用方法。

Abstract: Multimodal large language models (MLLMs) have shown remarkable capabilities
in cross-modal understanding and reasoning, offering new opportunities for
intelligent assistive systems, yet existing systems still struggle with
risk-aware planning, user personalization, and grounding language plans into
executable skills in cluttered homes. We introduce MARS - a Multi-Agent Robotic
System powered by MLLMs for assistive intelligence and designed for smart home
robots supporting people with disabilities. The system integrates four agents:
a visual perception agent for extracting semantic and spatial features from
environment images, a risk assessment agent for identifying and prioritizing
hazards, a planning agent for generating executable action sequences, and an
evaluation agent for iterative optimization. By combining multimodal perception
with hierarchical multi-agent decision-making, the framework enables adaptive,
risk-aware, and personalized assistance in dynamic indoor environments.
Experiments on multiple datasets demonstrate the superior overall performance
of the proposed system in risk-aware planning and coordinated multi-agent
execution compared with state-of-the-art multimodal models. The proposed
approach also highlights the potential of collaborative AI for practical
assistive scenarios and provides a generalizable methodology for deploying
MLLM-enabled multi-agent systems in real-world environments.

</details>


### [425] [Unified Diffusion VLA: Vision-Language-Action Model via Joint Discrete Denoising Diffusion Process](https://arxiv.org/abs/2511.01718)
*Jiayi Chen,Wenxuan Song,Pengxiang Ding,Ziyang Zhou,Han Zhao,Feilong Tang,Donglin Wang,Haoang Li*

Main category: cs.RO

TL;DR: 提出了一种联合扩散过程（JD3P）的视觉-语言-动作（VLA）模型，通过同步去噪优化生成和动作预测，实现多模态协同。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型依赖外部专家或分离生成与动作预测，限制了任务间的直接协同。

Method: 提出统一扩散VLA和JD3P，通过联合扩散过程整合多模态，结合统一标记空间和混合注意力机制。

Result: 在CALVIN等基准上实现SOTA性能，推理速度比自回归方法快4倍。

Conclusion: 联合扩散过程有效提升了多模态任务的协同性能，并在效率和实际应用中表现优异。

Abstract: Vision-language-action (VLA) models aim to understand natural language
instructions and visual observations and to execute corresponding actions as an
embodied agent. Recent work integrates future images into the
understanding-acting loop, yielding unified VLAs that jointly understand,
generate, and act -- reading text and images and producing future images and
actions. However, these models either rely on external experts for modality
unification or treat image generation and action prediction as separate
processes, limiting the benefits of direct synergy between these tasks. Our
core philosophy is to optimize generation and action jointly through a
synchronous denoising process, where the iterative refinement enables actions
to evolve from initialization, under constant and sufficient visual guidance.
We ground this philosophy in our proposed Unified Diffusion VLA and Joint
Discrete Denoising Diffusion Process (JD3P), which is a joint diffusion process
that integrates multiple modalities into a single denoising trajectory to serve
as the key mechanism enabling understanding, generation, and acting to be
intrinsically synergistic. Our model and theory are built on a unified
tokenized space of all modalities and a hybrid attention mechanism. We further
propose a two-stage training pipeline and several inference-time techniques
that optimize performance and efficiency. Our approach achieves
state-of-the-art performance on benchmarks such as CALVIN, LIBERO, and
SimplerEnv with 4$\times$ faster inference than autoregressive methods, and we
demonstrate its effectiveness through in-depth analysis and real-world
evaluations. Our project page is available at
https://irpn-eai.github.io/UD-VLA.github.io/.

</details>


### [426] [Lightweight Learning from Actuation-Space Demonstrations via Flow Matching for Whole-Body Soft Robotic Grasping](https://arxiv.org/abs/2511.01770)
*Liudi Yang,Yang Bai,Yuhao Wang,Ibrahim Alsarraj,Gitta Kutyniok,Zhanchi Wang,Ke Wu*

Main category: cs.RO

TL;DR: 提出了一种轻量级驱动空间学习框架，利用软机器人的被动柔性和冗余自由度，直接从确定性演示中学习分布控制表示，显著提高了抓取成功率。


<details>
  <summary>Details</summary>
Motivation: 传统刚性机械手在不确定和接触丰富的抓取任务中依赖复杂的模型和反馈控制，而软机器人通过其被动柔性表现出机械智能，能够自然适应不确定接触。

Method: 使用流匹配模型（Rectified Flow）从少量确定性演示中学习分布控制表示，无需密集传感或复杂控制回路。

Result: 仅用30次演示（不到可达工作空间的8%），学习策略在整个工作空间中实现了97.5%的抓取成功率，并能适应物体尺寸变化和动态响应调整。

Conclusion: 驱动空间学习通过利用软机器人的被动冗余自由度和柔性，将机械特性转化为功能控制智能，显著减轻了中央控制器的负担。

Abstract: Robotic grasping under uncertainty remains a fundamental challenge due to its
uncertain and contact-rich nature. Traditional rigid robotic hands, with
limited degrees of freedom and compliance, rely on complex model-based and
heavy feedback controllers to manage such interactions. Soft robots, by
contrast, exhibit embodied mechanical intelligence: their underactuated
structures and passive flexibility of their whole body, naturally accommodate
uncertain contacts and enable adaptive behaviors. To harness this capability,
we propose a lightweight actuation-space learning framework that infers
distributional control representations for whole-body soft robotic grasping,
directly from deterministic demonstrations using a flow matching model
(Rectified Flow),without requiring dense sensing or heavy control loops. Using
only 30 demonstrations (less than 8% of the reachable workspace), the learned
policy achieves a 97.5% grasp success rate across the whole workspace,
generalizes to grasped-object size variations of +-33%, and maintains stable
performance when the robot's dynamic response is directly adjusted by scaling
the execution time from 20% to 200%. These results demonstrate that
actuation-space learning, by leveraging its passive redundant DOFs and
flexibility, converts the body's mechanics into functional control intelligence
and substantially reduces the burden on central controllers for this
uncertain-rich task.

</details>


### [427] [MOBIUS: A Multi-Modal Bipedal Robot that can Walk, Crawl, Climb, and Roll](https://arxiv.org/abs/2511.01774)
*Alexander Schperberg,Yusuke Tanaka,Stefano Di Cairano,Dennis Hong*

Main category: cs.RO

TL;DR: MOBIUS机器人通过多模态设计实现行走、爬行、攀爬和滚动，结合强化学习和模型预测控制，提升地形适应性和安全性。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够在复杂城市环境中灵活移动和操作的机器人，扩展其交互能力和工作范围。

Method: 采用混合控制架构，结合强化学习、模型预测和导纳控制，并通过MIQCP规划器选择运动模式。

Result: 硬件实验展示了稳定的步态转换、动态攀爬和全身负载支持能力。

Conclusion: MOBIUS证明了形态、高层规划与控制紧密集成的重要性，显著提升了机器人的交互能力和地形适应性。

Abstract: This article presents a Multi-Modal Bipedal Intelligent Urban Scout robot
(MOBIUS) capable of walking, crawling, climbing, and rolling. MOBIUS features
four limbs--two 6-DoF arms with two-finger grippers for manipulation and
climbing, and two 4-DoF legs for locomotion--enabling smooth transitions across
diverse terrains without reconfiguration. A hybrid control architecture
combines reinforcement learning-based locomotion with model-based predictive
and admittance control enhanced for safety by a Reference Governor toward
compliant contact interactions. A high-level MIQCP planner autonomously selects
locomotion modes to balance stability and energy efficiency. Hardware
experiments demonstrate robust gait transitions, dynamic climbing, and
full-body load support via pinch grasp. Overall, MOBIUS demonstrates the
importance of tight integration between morphology, high-level planning, and
control to enable mobile loco-manipulation and grasping, substantially
expanding its interaction capabilities, workspace, and traversability.

</details>


### [428] [GenDexHand: Generative Simulation for Dexterous Hands](https://arxiv.org/abs/2511.01791)
*Feng Chen,Zhuxiu Xu,Tianzhe Chu,Xunzhe Zhou,Li Sun,Zewen Wu,Shenghua Gao,Zhongyu Li,Yanchao Yang,Yi Ma*

Main category: cs.RO

TL;DR: GenDexHand是一个生成式仿真管道，用于自动生成多样化的机器人任务和环境，以解决灵巧操作中的数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 灵巧操作任务由于自由度较高且环境设计复杂，现有方法难以生成可行的训练数据。

Method: GenDexHand通过闭环细化过程调整物体位置和尺寸，并利用视觉语言模型反馈提高生成环境质量，同时将任务分解为子任务以支持顺序强化学习。

Result: 该方法显著提升了生成环境的平均质量，减少了训练时间并提高了成功率。

Conclusion: GenDexHand为灵巧操作任务的规模化训练提供了可行的仿真解决方案。

Abstract: Data scarcity remains a fundamental bottleneck for embodied intelligence.
Existing approaches use large language models (LLMs) to automate gripper-based
simulation generation, but they transfer poorly to dexterous manipulation,
which demands more specialized environment design. Meanwhile, dexterous
manipulation tasks are inherently more difficult due to their higher degrees of
freedom. Massively generating feasible and trainable dexterous hand tasks
remains an open challenge. To this end, we present GenDexHand, a generative
simulation pipeline that autonomously produces diverse robotic tasks and
environments for dexterous manipulation. GenDexHand introduces a closed-loop
refinement process that adjusts object placements and scales based on
vision-language model (VLM) feedback, substantially improving the average
quality of generated environments. Each task is further decomposed into
sub-tasks to enable sequential reinforcement learning, reducing training time
and increasing success rates. Our work provides a viable path toward scalable
training of diverse dexterous hand behaviors in embodied intelligence by
offering a simulation-based solution to synthetic data generation. Our website:
https://winniechen2002.github.io/GenDexHand/.

</details>


### [429] [Hybrid Neural Network-Based Indoor Localisation System for Mobile Robots Using CSI Data in a Robotics Simulator](https://arxiv.org/abs/2511.01797)
*Javier Ballesteros-Jerez,Jesus Martínez-Gómez,Ismael García-Varea,Luis Orozco-Barbosa,Manuel Castillo-Cara*

Main category: cs.RO

TL;DR: 提出了一种混合神经网络模型，利用大规模MIMO系统的CSI数据进行移动机器人定位。


<details>
  <summary>Details</summary>
Motivation: 解决复杂环境中移动机器人的精确室内定位和导航问题。

Method: 结合CNN和MLP构建HyNN模型，将CSI数据转换为合成图像，并与ROS集成。

Result: 展示了HyNN模型在精确室内定位和导航中的潜力。

Conclusion: 该方法具有通用性，可适应不同场景和数据集。

Abstract: We present a hybrid neural network model for inferring the position of mobile
robots using Channel State Information (CSI) data from a Massive MIMO system.
By leveraging an existing CSI dataset, our approach integrates a Convolutional
Neural Network (CNN) with a Multilayer Perceptron (MLP) to form a Hybrid Neural
Network (HyNN) that estimates 2D robot positions. CSI readings are converted
into synthetic images using the TINTO tool. The localisation solution is
integrated with a robotics simulator, and the Robot Operating System (ROS),
which facilitates its evaluation through heterogeneous test cases, and the
adoption of state estimators like Kalman filters. Our contributions illustrate
the potential of our HyNN model in achieving precise indoor localisation and
navigation for mobile robots in complex environments. The study follows, and
proposes, a generalisable procedure applicable beyond the specific use case
studied, making it adaptable to different scenarios and datasets.

</details>
