<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 217]
- [cs.LG](#cs.LG) [Total: 219]
- [cs.RO](#cs.RO) [Total: 55]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Randomized-MLP Regularization Improves Domain Adaptation and Interpretability in DINOv2](https://arxiv.org/abs/2511.05509)
*Joel Valdivia Ortega,Lorenz Lamm,Franziska Eckardt,Benedikt Schworm,Marion Jasnin,Tingying Peng*

Main category: cs.CV

TL;DR: 本文提出了一种基于对比学习的RMLP正则化方法，用于改进DINOv2等Vision Transformer在医学图像领域的可解释性，同时保持或提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers（如DINOv2）在跨领域应用中表现优异，但常常会重新利用低信息量的patch token，导致注意力图和特征图的可解释性降低。这一问题在医学成像领域尤为突出，因为领域偏移会同时影响性能和透明度。

Method: 提出Randomized-MLP（RMLP）正则化方法，这是一种基于对比学习的技术。在微调DINOv2模型时应用RMLP，该方法鼓励模型产生更具语义对齐的表征。

Result: 实验表明，RMLP在医学图像和自然图像模态上都能够改进或保持下游任务性能，同时产生更可解释的注意力图。

Conclusion: RMLP正则化方法不仅提升了ViT模型的可解释性，还通过数学分析为理解对比学习在ViT模型中的作用提供了新的见解。

Abstract: Vision Transformers (ViTs), such as DINOv2, achieve strong performance across
domains but often repurpose low-informative patch tokens in ways that reduce
the interpretability of attention and feature maps. This challenge is
especially evident in medical imaging, where domain shifts can degrade both
performance and transparency. In this paper, we introduce Randomized-MLP (RMLP)
regularization, a contrastive learning-based method that encourages more
semantically aligned representations. We use RMLPs when fine-tuning DINOv2 to
both medical and natural image modalities, showing that it improves or
maintains downstream performance while producing more interpretable attention
maps. We also provide a mathematical analysis of RMLPs, offering insights into
its role in enhancing ViT-based models and advancing our understanding of
contrastive learning.

</details>


### [2] [Token Is All You Need: Cognitive Planning through Sparse Intent Alignment](https://arxiv.org/abs/2511.05540)
*Shiyao Sang*

Main category: cs.CV

TL;DR: 论文挑战了端到端自动驾驶需要详尽场景建模的传统假设，提出仅需少量语义丰富的token即可实现高效规划，在nuPlan基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 挑战传统端到端自动驾驶需要完整场景建模的假设，探索更高效的规划方法，避免计算密集的未来场景生成或受马尔可夫假设限制的VLA系统。

Method: 使用感知信息的BEV表示，基于稀疏语义token进行规划，实验对比了有无未来预测token的条件轨迹解码效果。

Result: 在nuPlan基准测试中：无未来预测时ADE为0.548m；加入未来token预测后ADE降至0.479m，提升12.6%；显式重建损失无益且可能降低性能。观察到时间模糊性现象。

Conclusion: "token即所需"原则标志着从重建世界到理解世界的范式转变，为基于想象而非反应的认知启发系统奠定基础。

Abstract: We challenge the long-standing assumption that exhaustive scene modeling is
required for high-performance end-to-end autonomous driving (E2EAD). Unlike
world-model approaches that rely on computationally intensive future scene
generation or vision-language-action (VLA) systems constrained by Markov
assumptions, we show that a minimal set of semantically rich tokens is
sufficient for effective planning. Experiments on the nuPlan benchmark (720
scenarios, over 11,000 samples) using perception-informed BEV representations
yield three key findings: (1) even without future prediction, our sparse
representation achieves 0.548 m ADE, comparable to or surpassing prior methods
reporting around 0.75 m on nuScenes; (2) conditioning trajectory decoding on
predicted future tokens reduces ADE to 0.479 m, a 12.6% improvement over
current-state baselines; and (3) explicit reconstruction loss offers no benefit
and may degrade performance under reliable perception inputs. Notably, we
observe the emergence of temporal fuzziness, where the model adaptively attends
to task-relevant semantics rather than aligning rigidly to fixed timestamps,
providing a cognitive advantage for planning under uncertainty. Our "token is
all you need" principle marks a paradigm shift from reconstructing the world to
understanding it, laying a foundation for cognitively inspired systems that
plan through imagination rather than reaction.

</details>


### [3] [Automated Invoice Data Extraction: Using LLM and OCR](https://arxiv.org/abs/2511.05547)
*Advait Thakur,Khushi Khanchandani,Akshita Shetty,Chaitravi Reddy,Ritisa Behera*

Main category: cs.CV

TL;DR: 本文提出了一种结合OCR、深度学习、LLM和图分析的全新AI平台，用于解决传统OCR系统在发票布局、手写文本和低质量扫描方面的局限性，实现前所未有的信息提取质量和一致性。


<details>
  <summary>Details</summary>
Motivation: 传统OCR系统对模板依赖性强，难以处理不同发票布局、手写文本和低质量扫描等挑战，限制了其在多样化文档结构中的灵活性。

Method: 采用混合架构，结合OCR技术、深度学习模型（如CNN和Transformer）、大语言模型（LLM）以及图分析技术，通过视觉命名实体识别（NER）能力实现上下文敏感的精准提取。

Result: 该平台能够以更高的准确率和上下文敏感性从发票图像中提取信息，支持复杂的上下文关系映射，无需直接编程规范。

Conclusion: 这种整体AI平台通过整合多种先进技术，实现了信息提取质量和一致性的显著提升，为发票处理提供了更高效、可扩展的解决方案。

Abstract: Conventional Optical Character Recognition (OCR) systems are challenged by
variant invoice layouts, handwritten text, and low- quality scans, which are
often caused by strong template dependencies that restrict their flexibility
across different document structures and layouts. Newer solutions utilize
advanced deep learning models such as Convolutional Neural Networks (CNN) as
well as Transformers, and domain-specific models for better layout analysis and
accuracy across various sections over varied document types. Large Language
Models (LLMs) have revolutionized extraction pipelines at their core with
sophisticated entity recognition and semantic comprehension to support complex
contextual relationship mapping without direct programming specification.
Visual Named Entity Recognition (NER) capabilities permit extraction from
invoice images with greater contextual sensitivity and much higher accuracy
rates than older approaches. Existing industry best practices utilize hybrid
architectures that blend OCR technology and LLM for maximum scalability and
minimal human intervention. This work introduces a holistic Artificial
Intelligence (AI) platform combining OCR, deep learning, LLMs, and graph
analytics to achieve unprecedented extraction quality and consistency.

</details>


### [4] [In-Context-Learning-Assisted Quality Assessment Vision-Language Models for Metal Additive Manufacturing](https://arxiv.org/abs/2511.05551)
*Qiaojie Zheng,Jiucai Zhang,Xiaoli Zhang*

Main category: cs.CV

TL;DR: 本文提出使用视觉语言模型（VLM）和上下文学习（ICL）进行增材制造质量评估，无需大量应用特定数据集即可达到与传统机器学习模型相当的分类精度，同时提供可解释的决策依据。


<details>
  <summary>Details</summary>
Motivation: 传统基于视觉的质量评估方法需要专门的数据集和模型训练，成本高且耗时。本文旨在利用VLM的推理能力，通过ICL提供应用特定知识，减少对大规模训练数据的需求。

Method: 采用Gemini-2.5-flash和Gemma3:27b两种VLM模型，结合不同的ICL采样策略，在金属线激光直接能量沉积工艺中进行质量评估实验。

Result: ICL辅助的VLM仅需少量样本即可达到与传统机器学习模型相当的分类精度（相对较高准确率），同时能生成有效的支持理由。

Conclusion: ICL辅助的VLM能够用有限数据解决应用特定任务，在保证较高准确性的同时提供可解释的决策依据，提高了制造应用的透明度和可信度。

Abstract: Vision-based quality assessment in additive manufacturing often requires
dedicated machine learning models and application-specific datasets. However,
data collection and model training can be expensive and time-consuming. In this
paper, we leverage vision-language models' (VLMs') reasoning capabilities to
assess the quality of printed parts and introduce in-context learning (ICL) to
provide VLMs with necessary application-specific knowledge and demonstration
samples. This method eliminates the requirement for large application-specific
datasets for training models. We explored different sampling strategies for ICL
to search for the optimal configuration that makes use of limited samples. We
evaluated these strategies on two VLMs, Gemini-2.5-flash and Gemma3:27b, with
quality assessment tasks in wire-laser direct energy deposition processes. The
results show that ICL-assisted VLMs can reach quality classification accuracies
similar to those of traditional machine learning models while requiring only a
minimal number of samples. In addition, unlike traditional classification
models that lack transparency, VLMs can generate human-interpretable rationales
to enhance trust. Since there are no metrics to evaluate their interpretability
in manufacturing applications, we propose two metrics, knowledge relevance and
rationale validity, to evaluate the quality of VLMs' supporting rationales. Our
results show that ICL-assisted VLMs can address application-specific tasks with
limited data, achieving relatively high accuracy while also providing valid
supporting rationales for improved decision transparency.

</details>


### [5] [EVLP:Learning Unified Embodied Vision-Language Planner with Reinforced Supervised Fine-Tuning](https://arxiv.org/abs/2511.05553)
*Xinyan Cai,Shiguang Wu,Dafeng Chi,Yuzheng Zhuang,Xingyue Quan,Jianye Hao,Qiang Guan*

Main category: cs.CV

TL;DR: EVLP是一个创新的多模态统一生成框架，通过联合建模语言推理和视觉生成来解决长时程操作任务中的多模态规划问题。


<details>
  <summary>Details</summary>
Motivation: 当前方法缺乏统一的多模态规划生成框架，导致多模态规划不一致。复杂的长时程操作任务需要文本逻辑推理和视觉空间想象的协同整合。

Method: 提出统一多模态生成框架、动态感知预训练和强化监督微调三个核心创新：1）整合语义信息和空间特征进行视觉感知，学习离散图像的联合分布；2）采用双向动态对齐策略强化多模态关联；3）构建强化损失对齐文本动作和生成图像的空间逻辑。

Result: 该方法实现了长时程任务的多模态规划，通过可学习的跨模态注意力机制实现协调的语言-视觉建模。

Conclusion: EVLP框架能够有效解决多模态规划不一致问题，使模型获得空间感知的多模态规划能力。

Abstract: In complex embodied long-horizon manipulation tasks, effective task
decomposition and execution require synergistic integration of textual logical
reasoning and visual-spatial imagination to ensure efficient and accurate
operation. Current methods fail to adopt a unified generation framework for
multimodal planning, lead to inconsistent in multimodal planning. To address
this challenge, we present \textbf{EVLP (Embodied Vision-Language Planner)}, an
innovative multimodal unified generation framework that jointly models
linguistic reasoning and visual generation. Our approach achieves multimodal
planning for long-horizon tasks through a novel training pipeline incorporating
dynamic pretraining and reinforced alignment. Our core innovations consist of
three key components: \textbf{1) Unified Multimodal Generation Framework}: For
understanding, We integrate semantic information with spatial features to
provide comprehensive visual perception. For generation, we directly learn the
joint distribution of discrete images for one-step visual synthesis, enabling
coordinated language-visual modeling through learnable cross-modal attention
mechanisms. \textbf{2) Dynamic Perception Pretraining}: We propose a
bidirectional dynamic alignment strategy employing inverse dynamics tasks and
forward dynamics tasks, effectively strengthening multimodal correlations
within a unified feature space. \textbf{3) Reinforced Supervised Fine-Tuning}:
While conducting instruction-based fine-tuning in the unified generation space,
we construct a reinforce loss to align the spatial logic between textual
actions and generated images, enabling the model to acquire spatio-awared
multimodal planning capabilities.

</details>


### [6] [MCFCN: Multi-View Clustering via a Fusion-Consensus Graph Convolutional Network](https://arxiv.org/abs/2511.05554)
*Chenping Pei,Fadi Dornaika,Jingjun Bi*

Main category: cs.CV

TL;DR: 该论文提出了一种基于融合共识图卷积网络的多视图聚类方法MCFCN，通过端到端学习多视图数据的共识图，解决了现有方法忽视数据拓扑结构、易受噪声干扰、跨视图一致性不足等问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于子空间学习的多视图聚类方法忽视了数据的固有拓扑结构，基于图神经网络的方法输入图结构易受噪声干扰，基于多视图图优化的方法存在跨视图一致性考虑不足、难以处理特征空间中难以区分的样本以及图构建算法导致的优化过程不连贯等问题。

Method: 提出MCFCN方法，通过视图特征融合模型和统一图结构适配器(UGA)学习有效共识表示，设计了相似度矩阵对齐损失(SMAL)和特征表示对齐损失(FRAL)，在共识指导下优化视图特定图，保持跨视图拓扑一致性，促进类内边构建，借助GCN实现有效共识表示学习。

Result: MCFCN在八个多视图基准数据集上表现出最先进的性能，通过广泛的定性和定量实验验证了其有效性。

Conclusion: MCFCN方法能够有效解决多视图聚类中的关键问题，显著提升聚类性能，代码已在GitHub上开源。

Abstract: Existing Multi-view Clustering (MVC) methods based on subspace learning focus
on consensus representation learning while neglecting the inherent topological
structure of data. Despite the integration of Graph Neural Networks (GNNs) into
MVC, their input graph structures remain susceptible to noise interference.
Methods based on Multi-view Graph Refinement (MGRC) also have limitations such
as insufficient consideration of cross-view consistency, difficulty in handling
hard-to-distinguish samples in the feature space, and disjointed optimization
processes caused by graph construction algorithms. To address these issues, a
Multi-View Clustering method via a Fusion-Consensus Graph Convolutional Network
(MCFCN) is proposed. The network learns the consensus graph of multi-view data
in an end-to-end manner and learns effective consensus representations through
a view feature fusion model and a Unified Graph Structure Adapter (UGA). It
designs Similarity Matrix Alignment Loss (SMAL) and Feature Representation
Alignment Loss (FRAL). With the guidance of consensus, it optimizes
view-specific graphs, preserves cross-view topological consistency, promotes
the construction of intra-class edges, and realizes effective consensus
representation learning with the help of GCN to improve clustering performance.
MCFCN demonstrates state-of-the-art performance on eight multi-view benchmark
datasets, and its effectiveness is verified by extensive qualitative and
quantitative implementations. The code will be provided at
https://github.com/texttao/MCFCN.

</details>


### [7] [Compressing Multi-Task Model for Autonomous Driving via Pruning and Knowledge Distillation](https://arxiv.org/abs/2511.05557)
*Jiayuan Wang,Q. M. Jonathan Wu,Ning Zhang,Katsuya Suto,Lei Zhong*

Main category: cs.CV

TL;DR: 提出了一种多任务模型压缩框架，结合任务感知安全剪枝和特征级知识蒸馏，用于自动驾驶的全景感知任务压缩。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统需要全景感知来同时处理物体检测、可行驶区域分割和车道线分割，但多任务学习模型参数多、复杂度高，难以部署到车载设备上。

Method: 使用任务感知安全剪枝策略（结合泰勒基通道重要性和梯度冲突惩罚）来保留重要通道并移除冗余冲突通道；设计任务头无关的蒸馏方法，将教师模型的中间骨干和编码器特征转移到学生模型。

Result: 在BDD100K数据集上，压缩模型参数减少32.7%，分割性能损失可忽略，检测性能轻微下降（召回率-1.2%，mAP50 -1.8%），实时运行速度32.7 FPS。

Conclusion: 结合剪枝和知识蒸馏为多任务全景感知提供了有效的压缩解决方案。

Abstract: Autonomous driving systems rely on panoptic perception to jointly handle
object detection, drivable area segmentation, and lane line segmentation.
Although multi-task learning is an effective way to integrate these tasks, its
increasing model parameters and complexity make deployment on on-board devices
difficult. To address this challenge, we propose a multi-task model compression
framework that combines task-aware safe pruning with feature-level knowledge
distillation. Our safe pruning strategy integrates Taylor-based channel
importance with gradient conflict penalty to keep important channels while
removing redundant and conflicting channels. To mitigate performance
degradation after pruning, we further design a task head-agnostic distillation
method that transfers intermediate backbone and encoder features from a teacher
to a student model as guidance. Experiments on the BDD100K dataset demonstrate
that our compressed model achieves a 32.7% reduction in parameters while
segmentation performance shows negligible accuracy loss and only a minor
decrease in detection (-1.2% for Recall and -1.8% for mAP50) compared to the
teacher. The compressed model still runs at 32.7 FPS in real-time. These
results show that combining pruning and knowledge distillation provides an
effective compression solution for multi-task panoptic perception.

</details>


### [8] [FilletRec: A Lightweight Graph Neural Network with Intrinsic Features for Automated Fillet Recognition](https://arxiv.org/abs/2511.05561)
*Jiali Gao,Taoran Liu,Hongfei Ye,Jianjun Chen*

Main category: cs.CV

TL;DR: 本文提出了一种端到端的数据驱动框架，专门用于CAD模型中的圆角特征识别与简化。通过构建大规模基准数据集和轻量级图神经网络FilletRec，实现了高精度识别和高效模型简化。


<details>
  <summary>Details</summary>
Motivation: 传统基于规则的方法缺乏鲁棒性，现有深度学习模型在复杂圆角上泛化能力差且精度低，主要原因是通用设计不足和训练数据不足。

Method: 1) 构建并发布大规模多样化圆角识别基准数据集；2) 提出轻量级图神经网络FilletRec，使用姿态不变的内在几何特征（如曲率）学习基本几何模式；3) 集成有效的几何简化算法完成自动化工作流。

Result: FilletRec在精度和泛化能力上均超越现有最优方法，同时仅使用基线模型0.2%-5.4%的参数，展示了高模型效率。

Conclusion: 该框架成功解决了CAD模型中圆角特征识别与简化的挑战，为CAE分析提供了有效的自动化解决方案。

Abstract: Automated recognition and simplification of fillet features in CAD models is
critical for CAE analysis, yet it remains an open challenge. Traditional
rule-based methods lack robustness, while existing deep learning models suffer
from poor generalization and low accuracy on complex fillets due to their
generic design and inadequate training data. To address these issues, this
paper proposes an end-to-end, data-driven framework specifically for fillet
features. We first construct and release a large-scale, diverse benchmark
dataset for fillet recognition to address the inadequacy of existing data.
Based on it, we propose FilletRec, a lightweight graph neural network. The core
innovation of this network is its use of pose-invariant intrinsic geometric
features, such as curvature, enabling it to learn more fundamental geometric
patterns and thereby achieve high-precision recognition of complex geometric
topologies. Experiments show that FilletRec surpasses state-of-the-art methods
in both accuracy and generalization, while using only 0.2\%-5.4\% of the
parameters of baseline models, demonstrating high model efficiency. Finally,
the framework completes the automated workflow from recognition to
simplification by integrating an effective geometric simplification algorithm.

</details>


### [9] [M2S2L: Mamba-based Multi-Scale Spatial-temporal Learning for Video Anomaly Detection](https://arxiv.org/abs/2511.05564)
*Yang Liu,Boan Chen,Xiaoguang Zhu,Jing Liu,Peng Sun,Wei Zhou*

Main category: cs.CV

TL;DR: 提出基于Mamba的多尺度时空学习框架M2S2L，用于视频异常检测，在保持高效计算的同时实现高精度检测


<details>
  <summary>Details</summary>
Motivation: 视频异常检测面临检测精度与计算效率的平衡挑战，传统方法缺乏全面的时空建模或计算资源需求过高

Method: 采用分层空间编码器处理多粒度空间信息，多时间编码器捕捉不同时间尺度的运动动态，引入特征分解机制进行任务特定优化

Result: 在三个基准数据集上分别达到98.5%、92.1%和77.9%的帧级AUC，计算效率为20.1G FLOPs和45 FPS

Conclusion: M2S2L框架在保持高效率的同时实现了优异的检测性能，适合实际监控部署

Abstract: Video anomaly detection (VAD) is an essential task in the image processing
community with prospects in video surveillance, which faces fundamental
challenges in balancing detection accuracy with computational efficiency. As
video content becomes increasingly complex with diverse behavioral patterns and
contextual scenarios, traditional VAD approaches struggle to provide robust
assessment for modern surveillance systems. Existing methods either lack
comprehensive spatial-temporal modeling or require excessive computational
resources for real-time applications. In this regard, we present a Mamba-based
multi-scale spatial-temporal learning (M2S2L) framework in this paper. The
proposed method employs hierarchical spatial encoders operating at multiple
granularities and multi-temporal encoders capturing motion dynamics across
different time scales. We also introduce a feature decomposition mechanism to
enable task-specific optimization for appearance and motion reconstruction,
facilitating more nuanced behavioral modeling and quality-aware anomaly
assessment. Experiments on three benchmark datasets demonstrate that M2S2L
framework achieves 98.5%, 92.1%, and 77.9% frame-level AUCs on UCSD Ped2, CUHK
Avenue, and ShanghaiTech respectively, while maintaining efficiency with 20.1G
FLOPs and 45 FPS inference speed, making it suitable for practical surveillance
deployment.

</details>


### [10] [In-Context Adaptation of VLMs for Few-Shot Cell Detection in Optical Microscopy](https://arxiv.org/abs/2511.05565)
*Shreyan Ganguly,Angona Biswas,Jaydeep Rade,Md Hasibul Hasan Hasib,Nabila Masud,Nitish Singla,Abhipsa Dash,Ushashi Bhattacharjee,Aditya Balu,Anwesha Sarkar,Adarsh Krishnamurthy,Soumik Sarkar*

Main category: cs.CV

TL;DR: 该论文研究了基础视觉语言模型在生物医学显微镜图像中的少样本目标检测能力，提出了Micro-OD基准测试，并发现上下文学习能有效提升模型在显微镜领域的检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基础视觉语言模型在自然图像上表现优异，但在生物医学显微镜领域的应用尚未充分探索。由于显微镜图像通常缺乏大规模标注数据集，研究如何通过少样本学习提升模型性能具有重要价值。

Method: 提出了Micro-OD基准测试（包含252张图像和11种细胞类型），系统评估了8种视觉语言模型在少样本条件下的表现。开发了混合少样本目标检测管道，结合检测头和基于VLM的少样本分类器。比较了带推理令牌和不带推理令牌的模型变体。

Result: 零样本性能较弱（存在领域差距），但少样本支持能持续提升检测性能，6个样本后增益趋于稳定。带推理令牌的模型在端到端定位中更有效，而简单变体更适合分类预定位的裁剪区域。

Conclusion: 上下文适应是显微镜领域的实用路径，Micro-OD基准为生物医学成像中的开放词汇检测提供了可复现的测试平台。

Abstract: Foundation vision-language models (VLMs) excel on natural images, but their
utility for biomedical microscopy remains underexplored. In this paper, we
investigate how in-context learning enables state-of-the-art VLMs to perform
few-shot object detection when large annotated datasets are unavailable, as is
often the case with microscopic images. We introduce the Micro-OD benchmark, a
curated collection of 252 images specifically curated for in-context learning,
with bounding-box annotations spanning 11 cell types across four sources,
including two in-lab expert-annotated sets. We systematically evaluate eight
VLMs under few-shot conditions and compare variants with and without implicit
test-time reasoning tokens. We further implement a hybrid Few-Shot Object
Detection (FSOD) pipeline that combines a detection head with a VLM-based
few-shot classifier, which enhances the few-shot performance of recent VLMs on
our benchmark. Across datasets, we observe that zero-shot performance is weak
due to the domain gap; however, few-shot support consistently improves
detection, with marginal gains achieved after six shots. We observe that models
with reasoning tokens are more effective for end-to-end localization, whereas
simpler variants are more suitable for classifying pre-localized crops. Our
results highlight in-context adaptation as a practical path for microscopy, and
our benchmark provides a reproducible testbed for advancing open-vocabulary
detection in biomedical imaging.

</details>


### [11] [Efficient Online Continual Learning in Sensor-Based Human Activity Recognition](https://arxiv.org/abs/2511.05566)
*Yao Zhang,Souza Leite Clayton,Yu Xiao*

Main category: cs.CV

TL;DR: PTRN-HAR是首个成功将预训练模型（PTM）应用于传感器人类活动识别（HAR）在线持续学习（OCL）的方法，通过对比学习预训练特征提取器并冻结，采用关系模块网络替代传统分类层，显著降低资源消耗和标注数据需求，在三个公共数据集上超越现有最佳方法。


<details>
  <summary>Details</summary>
Motivation: 现有传感器HAR的在线持续学习方法计算密集且需要大量标注样本，而基于预训练模型的OCL方法在计算机视觉中表现优异但难以直接应用于HAR，主要挑战在于HAR数据集的异构性和部署后标注数据稀缺。

Method: PTRN-HAR使用对比损失在有限数据上预训练特征提取器并在流式阶段冻结，用关系模块网络替代传统密集分类层，实现高效持续学习。

Result: 在三个公共数据集上的实验表明，PTRN-HAR在保持高性能的同时显著降低了模型训练的资源消耗，并提高了数据效率，减少了有效持续学习所需的标注数据量，性能优于现有最佳方法。

Conclusion: PTRN-HAR成功解决了PTM-based OCL在传感器HAR中的应用挑战，为资源受限环境下的高效持续学习提供了可行方案。

Abstract: Machine learning models for sensor-based human activity recognition (HAR) are
expected to adapt post-deployment to recognize new activities and different
ways of performing existing ones. To address this need, Online Continual
Learning (OCL) mechanisms have been proposed, allowing models to update their
knowledge incrementally as new data become available while preserving
previously acquired information. However, existing OCL approaches for
sensor-based HAR are computationally intensive and require extensive labeled
samples to represent new changes. Recently, pre-trained model-based (PTM-based)
OCL approaches have shown significant improvements in performance and
efficiency for computer vision applications. These methods achieve strong
generalization capabilities by pre-training complex models on large datasets,
followed by fine-tuning on downstream tasks for continual learning. However,
applying PTM-based OCL approaches to sensor-based HAR poses significant
challenges due to the inherent heterogeneity of HAR datasets and the scarcity
of labeled data in post-deployment scenarios. This paper introduces PTRN-HAR,
the first successful application of PTM-based OCL to sensor-based HAR. Unlike
prior PTM-based OCL approaches, PTRN-HAR pre-trains the feature extractor using
contrastive loss with a limited amount of data. This extractor is then frozen
during the streaming stage. Furthermore, it replaces the conventional dense
classification layer with a relation module network. Our design not only
significantly reduces the resource consumption required for model training
while maintaining high performance, but also improves data efficiency by
reducing the amount of labeled data needed for effective continual learning, as
demonstrated through experiments on three public datasets, outperforming the
state-of-the-art. The code can be found here:
https://anonymous.4open.science/r/PTRN-HAR-AF60/

</details>


### [12] [Automatic Extraction of Road Networks by using Teacher-Student Adaptive Structural Deep Belief Network and Its Application to Landslide Disaster](https://arxiv.org/abs/2511.05567)
*Shin Kamada,Takumi Ichimura*

Main category: cs.CV

TL;DR: 本文提出了一种基于自适应深度信念网络（DBN）的RoadTracer道路检测方法，通过自适应结构学习和集成学习技术，显著提升了道路网络识别的准确率，并成功应用于灾害后可用道路检测。


<details>
  <summary>Details</summary>
Motivation: 传统道路地图识别方法难以处理复杂的道路特征，需要具有高表示能力的模型来准确检测地面道路网络。特别是在自然灾害后快速识别可用道路的需求日益迫切。

Method: 采用自适应结构学习的限制玻尔兹曼机（RBM）和深度信念网络（DBN），结合神经元生成-消亡算法和层生成算法。提出基于Teacher-Student集成学习的自适应DBN模型，并在嵌入式边缘设备上实现轻量级深度学习。

Result: 在七个主要城市的测试数据集上，检测准确率从40.0%提升到89.0%。成功应用于日本降雨灾害前后的卫星图像分析，实现了灾害后可用道路的快速检测。

Conclusion: 提出的自适应DBN模型在道路网络识别任务中表现出色，不仅显著提高了检测精度，而且通过轻量化部署实现了灾害应急场景下的快速推理能力。

Abstract: An adaptive structural learning method of Restricted Boltzmann Machine (RBM)
and Deep Belief Network (DBN) has been developed as one of prominent deep
learning models. The neuron generation-annihilation algorithm in RBM and layer
generation algorithm in DBN make an optimal network structure for given input
during the learning. In this paper, our model is applied to an automatic
recognition method of road network system, called RoadTracer. RoadTracer can
generate a road map on the ground surface from aerial photograph data. A novel
method of RoadTracer using the Teacher-Student based ensemble learning model of
Adaptive DBN is proposed, since the road maps contain many complicated features
so that a model with high representation power to detect should be required.
The experimental results showed the detection accuracy of the proposed model
was improved from 40.0\% to 89.0\% on average in the seven major cities among
the test dataset. In addition, we challenged to apply our method to the
detection of available roads when landslide by natural disaster is occurred, in
order to rapidly obtain a way of transportation. For fast inference, a small
size of the trained model was implemented on a small embedded edge device as
lightweight deep learning. We reported the detection results for the satellite
image before and after the rainfall disaster in Japan.

</details>


### [13] [Do Street View Imagery and Public Participation GIS align: Comparative Analysis of Urban Attractiveness](https://arxiv.org/abs/2511.05570)
*Milad Malekzadeh,Elias Willberg,Jussi Torkko,Silviya Korpilo,Kamyar Hasanzadeh,Olle Järv,Tuuli Toivonen*

Main category: cs.CV

TL;DR: 该研究比较了街景图像（SVI）和公众参与GIS（PPGIS）在捕捉城市感知方面的差异，发现两种方法仅部分一致，非视觉因素对感知有重要影响。


<details>
  <summary>Details</summary>
Motivation: 随着数字工具日益影响空间规划实践，理解不同数据源如何反映人类对城市环境的体验至关重要。SVI和PPGIS是两种主要方法，但它们的可比性尚未充分探索。

Method: 使用参与者评分的SVI数据和语义图像分割，训练机器学习模型预测感知吸引力，并与PPGIS调查结果进行比较，计算严格和中等标准下的匹配度。

Result: 研究发现两种数据集仅部分一致：中等标准下吸引力地点匹配率为67%，不吸引力地点为77%；严格标准下分别降至27%和29%。非视觉线索（如噪音、交通、人口密度）是导致不匹配的主要因素。

Conclusion: SVI提供了可扩展的视觉代理，但无法完全替代PPGIS捕捉的体验丰富性。两种方法各有价值但服务于不同目的，需要更综合的方法来全面捕捉人们对城市环境的感知。

Abstract: As digital tools increasingly shape spatial planning practices, understanding
how different data sources reflect human experiences of urban environments is
essential. Street View Imagery (SVI) and Public Participation GIS (PPGIS)
represent two prominent approaches for capturing place-based perceptions that
can support urban planning decisions, yet their comparability remains
underexplored. This study investigates the alignment between SVI-based
perceived attractiveness and residents' reported experiences gathered via a
city-wide PPGIS survey in Helsinki, Finland. Using participant-rated SVI data
and semantic image segmentation, we trained a machine learning model to predict
perceived attractiveness based on visual features. We compared these
predictions to PPGIS-identified locations marked as attractive or unattractive,
calculating agreement using two sets of strict and moderate criteria. Our
findings reveal only partial alignment between the two datasets. While
agreement (with a moderate threshold) reached 67% for attractive and 77% for
unattractive places, agreement (with a strict threshold) dropped to 27% and
29%, respectively. By analysing a range of contextual variables, including
noise, traffic, population presence, and land use, we found that non-visual
cues significantly contributed to mismatches. The model failed to account for
experiential dimensions such as activity levels and environmental stressors
that shape perceptions but are not visible in images. These results suggest
that while SVI offers a scalable and visual proxy for urban perception, it
cannot fully substitute the experiential richness captured through PPGIS. We
argue that both methods are valuable but serve different purposes; therefore, a
more integrated approach is needed to holistically capture how people perceive
urban environments.

</details>


### [14] [C3-Diff: Super-resolving Spatial Transcriptomics via Cross-modal Cross-content Contrastive Diffusion Modelling](https://arxiv.org/abs/2511.05571)
*Xiaofei Wang,Stephen Price,Chao Li*

Main category: cs.CV

TL;DR: C3-Diff是一个基于跨模态跨内容对比扩散框架的空间转录组增强方法，通过整合组织学图像和基因表达数据来提升空间转录组图谱的分辨率。


<details>
  <summary>Details</summary>
Motivation: 当前空间转录组平台分辨率较低，限制了深入理解空间基因表达。虽然超分辨率方法有望通过整合组织学图像和基因表达来增强ST图谱，但如何有效建模两者之间的交互仍然是一个挑战。

Method: 提出C3-Diff框架：1）改进传统对比学习范式，提取模态不变和内容不变特征；2）在特征单元超球面上进行基于噪声的信息增强；3）提出动态跨模态插补训练策略缓解数据稀缺问题。

Result: 在四个公共数据集上测试，C3-Diff相比竞争方法有显著提升。在下游任务（细胞类型定位、基因表达相关性、单细胞级基因表达预测）中也表现出色。

Conclusion: C3-Diff促进了AI增强生物技术在生物医学研究和临床应用中的发展，代码已开源。

Abstract: The rapid advancement of spatial transcriptomics (ST), i.e., spatial gene
expressions, has made it possible to measure gene expression within original
tissue, enabling us to discover molecular mechanisms. However, current ST
platforms frequently suffer from low resolution, limiting the in-depth
understanding of spatial gene expression. Super-resolution approaches promise
to enhance ST maps by integrating histology images with gene expressions of
profiled tissue spots. However, it remains a challenge to model the
interactions between histology images and gene expressions for effective ST
enhancement. This study presents a cross-modal cross-content contrastive
diffusion framework, called C3-Diff, for ST enhancement with histology images
as guidance. In C3-Diff, we firstly analyze the deficiency of traditional
contrastive learning paradigm, which is then refined to extract both
modal-invariant and content-invariant features of ST maps and histology images.
Further, to overcome the problem of low sequencing sensitivity in ST maps, we
perform nosing-based information augmentation on the surface of feature unit
hypersphere. Finally, we propose a dynamic cross-modal imputation-based
training strategy to mitigate ST data scarcity. We tested C3-Diff by
benchmarking its performance on four public datasets, where it achieves
significant improvements over competing methods. Moreover, we evaluate C3-Diff
on downstream tasks of cell type localization, gene expression correlation and
single-cell-level gene expression prediction, promoting AI-enhanced
biotechnology for biomedical research and clinical applications. Codes are
available at https://github.com/XiaofeiWang2018/C3-Diff.

</details>


### [15] [Video Text Preservation with Synthetic Text-Rich Videos](https://arxiv.org/abs/2511.05573)
*Ziyang Liu,Kevin Valencia,Justin Cui*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级方法来改善文本到视频(T2V)扩散模型中的文本可读性问题，通过使用合成数据进行监督训练，无需改变模型架构。


<details>
  <summary>Details</summary>
Motivation: 现有的T2V模型在生成包含可读文本的视频时表现不佳，即使是短短语或单词也难以正确渲染，而之前的解决方案计算成本高昂且不适合视频生成。

Method: 首先使用文本到图像(T2I)扩散模型生成富含文本的图像，然后使用文本无关的图像到视频(I2V)模型将其动画化为短视频，利用这些合成的视频-提示对来微调预训练的Wan2.1 T2V模型。

Result: 结果显示在短文本可读性和时间一致性方面有所改善，并为长文本提供了新兴的结构先验。

Conclusion: 精心策划的合成数据和弱监督为改善T2V生成中的文本保真度提供了一条实用路径。

Abstract: While Text-To-Video (T2V) models have advanced rapidly, they continue to
struggle with generating legible and coherent text within videos. In
particular, existing models often fail to render correctly even short phrases
or words and previous attempts to address this problem are computationally
expensive and not suitable for video generation. In this work, we investigate a
lightweight approach to improve T2V diffusion models using synthetic
supervision. We first generate text-rich images using a text-to-image (T2I)
diffusion model, then animate them into short videos using a text-agnostic
image-to-video (I2v) model. These synthetic video-prompt pairs are used to
fine-tune Wan2.1, a pre-trained T2V model, without any architectural changes.
Our results show improvement in short-text legibility and temporal consistency
with emerging structural priors for longer text. These findings suggest that
curated synthetic data and weak supervision offer a practical path toward
improving textual fidelity in T2V generation.

</details>


### [16] [Elements of Active Continuous Learning and Uncertainty Self-Awareness: a Narrow Implementation for Face and Facial Expression Recognition](https://arxiv.org/abs/2511.05574)
*Stanislav Selitskiy*

Main category: cs.CV

TL;DR: 提出了一种模拟自我意识机制的方法，通过监督神经网络观察底层神经网络激活模式来评估预测不确定性，并在高不确定性时触发主动学习模式寻求人类帮助。


<details>
  <summary>Details</summary>
Motivation: 反思思维过程并在性能不满意时进行纠正是智能的重要特征，虽然这是高级抽象概念，但可以在窄机器学习算法层面进行建模。

Method: 使用监督ANN观察底层CNN集成网络的激活模式，检测高不确定性指示。监督ANN具有存储过去性能信息的内存区域，可训练参数在训练期间优化性能。

Result: 建立了能够评估预测可信度的自我意识机制，在高不确定性条件下能够触发主动学习模式向人类求助。

Conclusion: 即使在窄机器学习算法层面，也能成功模拟自我意识的关键特征，为人工通用智能的发展提供了有价值的参考。

Abstract: Reflection on one's thought process and making corrections to it if there
exists dissatisfaction in its performance is, perhaps, one of the essential
traits of intelligence. However, such high-level abstract concepts mandatory
for Artificial General Intelligence can be modelled even at the low level of
narrow Machine Learning algorithms. Here, we present the self-awareness
mechanism emulation in the form of a supervising artificial neural network
(ANN) observing patterns in activations of another underlying ANN in a search
for indications of the high uncertainty of the underlying ANN and, therefore,
the trustworthiness of its predictions. The underlying ANN is a convolutional
neural network (CNN) ensemble employed for face recognition and facial
expression tasks. The self-awareness ANN has a memory region where its past
performance information is stored, and its learnable parameters are adjusted
during the training to optimize the performance. The trustworthiness verdict
triggers the active learning mode, giving elements of agency to the machine
learning algorithm that asks for human help in high uncertainty and confusion
conditions.

</details>


### [17] [DiffSwap++: 3D Latent-Controlled Diffusion for Identity-Preserving Face Swapping](https://arxiv.org/abs/2511.05575)
*Weston Bondurant,Arkaprava Sinha,Hieu Le,Srijan Das,Stephanie Schuckers*

Main category: cs.CV

TL;DR: DiffSwap++是一种基于扩散模型的人脸交换方法，通过引入3D面部潜在特征和双重条件（身份嵌入和面部关键点）来提升几何一致性和身份保持能力，在多个数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的人脸交换方法在挑战性姿态和表情下存在细粒度伪影和身份保持不佳的问题，主要原因是未能有效利用3D面部结构来解耦身份与姿态/表情。

Method: 提出DiffSwap++管道，在训练中融入3D面部潜在特征，设计扩散架构使去噪过程同时基于身份嵌入和面部关键点进行条件化。

Result: 在CelebA、FFHQ和CelebV-Text数据集上的实验表明，DiffSwap++在保持源身份和维持目标姿态/表情方面优于现有方法，并通过生物特征评估和用户研究验证了方法的真实性和有效性。

Conclusion: DiffSwap++通过3D感知表示和双重条件化机制，显著提升了人脸交换的质量和身份保持能力，为扩散模型在人脸交换领域的应用提供了新思路。

Abstract: Diffusion-based approaches have recently achieved strong results in face
swapping, offering improved visual quality over traditional GAN-based methods.
However, even state-of-the-art models often suffer from fine-grained artifacts
and poor identity preservation, particularly under challenging poses and
expressions. A key limitation of existing approaches is their failure to
meaningfully leverage 3D facial structure, which is crucial for disentangling
identity from pose and expression. In this work, we propose DiffSwap++, a novel
diffusion-based face-swapping pipeline that incorporates 3D facial latent
features during training. By guiding the generation process with 3D-aware
representations, our method enhances geometric consistency and improves the
disentanglement of facial identity from appearance attributes. We further
design a diffusion architecture that conditions the denoising process on both
identity embeddings and facial landmarks, enabling high-fidelity and
identity-preserving face swaps. Extensive experiments on CelebA, FFHQ, and
CelebV-Text demonstrate that DiffSwap++ outperforms prior methods in preserving
source identity while maintaining target pose and expression. Additionally, we
introduce a biometric-style evaluation and conduct a user study to further
validate the realism and effectiveness of our approach. Code will be made
publicly available at https://github.com/WestonBond/DiffSwapPP

</details>


### [18] [Beyond Softmax: Dual-Branch Sigmoid Architecture for Accurate Class Activation Maps](https://arxiv.org/abs/2511.05590)
*Yoojin Oh,Junhyug Noh*

Main category: cs.CV

TL;DR: 提出了一种双分支sigmoid头部方法，解决了传统CAM方法由于softmax分类器导致的两种基本失真问题，提高了可视化解释的保真度。


<details>
  <summary>Details</summary>
Motivation: 传统CAM方法依赖softmax分类器，存在加性logit偏移和符号崩溃两个基本失真问题，这些失真会任意偏置重要性分数并混淆兴奋性和抑制性特征。

Method: 提出架构无关的双分支sigmoid头部方法：克隆预训练模型的分类头到并行分支，使用sigmoid输出，冻结原始softmax头，仅用类别平衡的二元监督微调sigmoid分支。

Result: 在细粒度任务和WSOL基准测试中显示出改进的解释保真度和一致的Top-1定位增益，且分类准确率没有下降。

Conclusion: 该方法与大多数CAM变体无缝集成，计算开销可忽略，能有效提高深度网络预测证据的可视化质量。

Abstract: Class Activation Mapping (CAM) and its extensions have become indispensable
tools for visualizing the evidence behind deep network predictions. However, by
relying on a final softmax classifier, these methods suffer from two
fundamental distortions: additive logit shifts that arbitrarily bias importance
scores, and sign collapse that conflates excitatory and inhibitory features. We
propose a simple, architecture-agnostic dual-branch sigmoid head that decouples
localization from classification. Given any pretrained model, we clone its
classification head into a parallel branch ending in per-class sigmoid outputs,
freeze the original softmax head, and fine-tune only the sigmoid branch with
class-balanced binary supervision. At inference, softmax retains recognition
accuracy, while class evidence maps are generated from the sigmoid branch --
preserving both magnitude and sign of feature contributions. Our method
integrates seamlessly with most CAM variants and incurs negligible overhead.
Extensive evaluations on fine-grained tasks (CUB-200-2011, Stanford Cars) and
WSOL benchmarks (ImageNet-1K, OpenImages30K) show improved explanation fidelity
and consistent Top-1 Localization gains -- without any drop in classification
accuracy. Code is available at https://github.com/finallyupper/beyond-softmax.

</details>


### [19] [Google-MedGemma Based Abnormality Detection in Musculoskeletal radiographs](https://arxiv.org/abs/2511.05600)
*Soumyajit Maity,Pranjal Kamboj,Sneha Maity,Rajat Singh,Sankhadeep Chatterjee*

Main category: cs.CV

TL;DR: 提出基于MedGemma框架的肌肉骨骼X光片自动异常检测方法，性能优于传统卷积网络和自编码器


<details>
  <summary>Details</summary>
Motivation: 传统自编码器和神经网络管道在医学图像异常检测中存在局限性，需要利用现代医学基础模型提升特征学习和泛化能力

Method: 使用MedGemma基础模型，结合SigLIP视觉编码器预处理X光图像，通过轻量级多层感知机进行二分类

Result: MedGemma驱动的分类器表现出强劲性能，超过传统卷积和自编码器指标，具有良好的泛化能力

Conclusion: MedGemma驱动的分类系统可通过提供可扩展且准确的异常检测来推进临床X光片分诊，在自动化医学图像分析中具有广泛应用潜力

Abstract: This paper proposes a MedGemma-based framework for automatic abnormality
detection in musculoskeletal radiographs. Departing from conventional
autoencoder and neural network pipelines, the proposed method leverages the
MedGemma foundation model, incorporating a SigLIP-derived vision encoder
pretrained on diverse medical imaging modalities. Preprocessed X-ray images are
encoded into high-dimensional embeddings using the MedGemma vision backbone,
which are subsequently passed through a lightweight multilayer perceptron for
binary classification. Experimental assessment reveals that the MedGemma-driven
classifier exhibits strong performance, exceeding conventional convolutional
and autoencoder-based metrics. Additionally, the model leverages MedGemma's
transfer learning capabilities, enhancing generalization and optimizing feature
engineering. The integration of a modern medical foundation model not only
enhances representation learning but also facilitates modular training
strategies such as selective encoder block unfreezing for efficient domain
adaptation. The findings suggest that MedGemma-powered classification systems
can advance clinical radiograph triage by providing scalable and accurate
abnormality detection, with potential for broader applications in automated
medical image analysis.
  Keywords: Google MedGemma, MURA, Medical Image, Classification.

</details>


### [20] [In-process 3D Deviation Mapping and Defect Monitoring (3D-DM2) in High Production-rate Robotic Additive Manufacturing](https://arxiv.org/abs/2511.05604)
*Subash Gautam,Alejandro Vargas-Uscategui,Peter King,Hans Lohr,Alireza Bab-Hadiashar,Ivan Cole,Ehsan Asadi*

Main category: cs.CV

TL;DR: 提出了一种实时监测系统，用于检测增材制造过程中的形状偏差，通过对比实时重建的零件与参考模型来实现早期偏差识别和跟踪。


<details>
  <summary>Details</summary>
Motivation: 高沉积率机器人增材制造过程中，保持形状精度是一个关键挑战，当前开环系统的过程不稳定性导致形状偏差，需要实时检测以防止误差传播。

Method: 开发实时监测系统，采集和重建正在生长的零件，直接与近净参考模型比较，检测制造过程中的形状偏差，并对每个偏差区域进行分割和跟踪。

Result: 实现了制造过程中形状偏差的早期识别和跟踪，为及时干预和补偿提供了基础。

Conclusion: 该监测系统能够有效检测增材制造过程中的形状偏差，为实现一致的零件质量提供了可行的解决方案。

Abstract: Additive manufacturing (AM) is an emerging digital manufacturing technology
to produce complex and freeform objects through a layer-wise deposition. High
deposition rate robotic AM (HDRRAM) processes, such as cold spray additive
manufacturing (CSAM), offer significantly increased build speeds by delivering
large volumes of material per unit time. However, maintaining shape accuracy
remains a critical challenge, particularly due to process instabilities in
current open-loop systems. Detecting these deviations as they occur is
essential to prevent error propagation, ensure part quality, and minimize
post-processing requirements. This study presents a real-time monitoring system
to acquire and reconstruct the growing part and directly compares it with a
near-net reference model to detect the shape deviation during the manufacturing
process. The early identification of shape inconsistencies, followed by
segmenting and tracking each deviation region, paves the way for timely
intervention and compensation to achieve consistent part quality.

</details>


### [21] [Walking the Schrödinger Bridge: A Direct Trajectory for Text-to-3D Generation](https://arxiv.org/abs/2511.05609)
*Ziying Li,Xuequan Lu,Xinkui Zhao,Guanjie Cheng,Shuiguang Deng,Jianwei Yin*

Main category: cs.CV

TL;DR: 本文提出TraCe框架，通过Schrödinger Bridge理论优化文本到3D生成过程，解决了传统SDS方法中的过饱和和过平滑问题，实现了更高质量的3D资产生成。


<details>
  <summary>Details</summary>
Motivation: 基于优化的文本到3D生成方法主要依赖从预训练文本到图像扩散模型中提取知识，但常用的SDS技术会引入过饱和和过平滑等伪影。本文旨在解决这一关键问题。

Method: 将生成过程建模为学习从当前渲染分布到目标分布的最优直接传输轨迹，引入TraCe框架，基于Schrödinger Bridge理论显式构建扩散桥，并训练LoRA自适应模型来优化3D生成。

Result: 综合实验表明，TraCe在质量和保真度上始终优于现有最先进技术，能够使用较小的CFG值实现高质量生成。

Conclusion: TraCe通过理论重构SDS为Schrödinger Bridge的特例，提出了更稳健的3D优化方法，为文本到3D生成提供了新的解决方案。

Abstract: Recent advancements in optimization-based text-to-3D generation heavily rely
on distilling knowledge from pre-trained text-to-image diffusion models using
techniques like Score Distillation Sampling (SDS), which often introduce
artifacts such as over-saturation and over-smoothing into the generated 3D
assets. In this paper, we address this essential problem by formulating the
generation process as learning an optimal, direct transport trajectory between
the distribution of the current rendering and the desired target distribution,
thereby enabling high-quality generation with smaller Classifier-free Guidance
(CFG) values. At first, we theoretically establish SDS as a simplified instance
of the Schr\"odinger Bridge framework. We prove that SDS employs the reverse
process of an Schr\"odinger Bridge, which, under specific conditions (e.g., a
Gaussian noise as one end), collapses to SDS's score function of the
pre-trained diffusion model. Based upon this, we introduce Trajectory-Centric
Distillation (TraCe), a novel text-to-3D generation framework, which
reformulates the mathematically trackable framework of Schr\"odinger Bridge to
explicitly construct a diffusion bridge from the current rendering to its
text-conditioned, denoised target, and trains a LoRA-adapted model on this
trajectory's score dynamics for robust 3D optimization. Comprehensive
experiments demonstrate that TraCe consistently achieves superior quality and
fidelity to state-of-the-art techniques.

</details>


### [22] [Pose-Aware Multi-Level Motion Parsing for Action Quality Assessment](https://arxiv.org/abs/2511.05611)
*Shuaikang Zhu,Yang Yang,Chen Sun*

Main category: cs.CV

TL;DR: 提出了一种基于增强时空姿态特征的多层次运动解析框架，用于动作质量评估，在动作分割和评分任务上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 在高级别竞赛中，姿态的细微时空变化是评分的关键因素，这些微妙差异往往区分优秀与平庸表现。

Method: 采用三级解析框架：第一级动作单元解析器实现精确动作分割和局部-全局姿态表示；第二级运动解析器通过时空特征学习捕捉每个动作单元的姿态变化和外观细节；第三级条件解析器处理非身体相关因素（如水花）；最后引入权重调整评分模块适应不同动作类型需求。

Result: 在大规模跳水运动数据集上的广泛评估表明，该框架在动作分割和动作评分任务上均达到最先进性能。

Conclusion: 提出的多层次运动解析框架能够有效捕捉动作质量的细微差异，为动作质量评估提供了灵活且高性能的解决方案。

Abstract: Human pose serves as a cornerstone of action quality assessment (AQA), where
subtle spatial-temporal variations in pose often distinguish excellence from
mediocrity. In high-level competitions, these nuanced differences become
decisive factors in scoring. In this paper, we propose a novel multi-level
motion parsing framework for AQA based on enhanced spatial-temporal pose
features. On the first level, the Action-Unit Parser is designed with the help
of pose extraction to achieve precise action segmentation and comprehensive
local-global pose representations. On the second level, Motion Parser is used
by spatial-temporal feature learning to capture pose changes and appearance
details for each action-unit. Meanwhile, some special conditions other than
body-related will impact action scoring, like water splash in diving. In this
work, we design an additional Condition Parser to offer users more flexibility
in their choices. Finally, Weight-Adjust Scoring Module is introduced to better
accommodate the diverse requirements of various action types and the
multi-scale nature of action-units. Extensive evaluations on large-scale diving
sports datasets demonstrate that our multi-level motion parsing framework
achieves state-of-the-art performance in both action segmentation and action
scoring tasks.

</details>


### [23] [Personalized Image Editing in Text-to-Image Diffusion Models via Collaborative Direct Preference Optimization](https://arxiv.org/abs/2511.05616)
*Connor Dunlop,Matthew Zheng,Kavana Venkatesh,Pinar Yanardag*

Main category: cs.CV

TL;DR: 提出首个个性化图像编辑框架C-DPO，通过动态偏好图和图神经网络实现用户偏好对齐和协同信号利用


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型无法适应个体用户的细微审美偏好，需要个性化编辑能力

Method: C-DPO方法：将用户编码为动态偏好图节点，通过轻量级图神经网络学习嵌入，结合新型DPO目标实现个体对齐和邻域一致性优化

Result: 综合实验（用户研究和定量基准）显示该方法在生成符合用户偏好的编辑结果上持续优于基线方法

Conclusion: C-DPO框架成功实现了扩散模型的个性化图像编辑，通过协同学习机制提升了用户偏好对齐效果

Abstract: Text-to-image (T2I) diffusion models have made remarkable strides in
generating and editing high-fidelity images from text. Yet, these models remain
fundamentally generic, failing to adapt to the nuanced aesthetic preferences of
individual users. In this work, we present the first framework for personalized
image editing in diffusion models, introducing Collaborative Direct Preference
Optimization (C-DPO), a novel method that aligns image edits with user-specific
preferences while leveraging collaborative signals from like-minded
individuals. Our approach encodes each user as a node in a dynamic preference
graph and learns embeddings via a lightweight graph neural network, enabling
information sharing across users with overlapping visual tastes. We enhance a
diffusion model's editing capabilities by integrating these personalized
embeddings into a novel DPO objective, which jointly optimizes for individual
alignment and neighborhood coherence. Comprehensive experiments, including user
studies and quantitative benchmarks, demonstrate that our method consistently
outperforms baselines in generating edits that are aligned with user
preferences.

</details>


### [24] [Convolutional Fully-Connected Capsule Network (CFC-CapsNet): A Novel and Fast Capsule Network](https://arxiv.org/abs/2511.05617)
*Pouya Shiri,Amirali Baniasadi*

Main category: cs.CV

TL;DR: 提出了一种新的卷积全连接胶囊网络（CFC-CapsNet）来解决传统胶囊网络在复杂数据集上性能不佳、训练速度慢和参数过多的问题。


<details>
  <summary>Details</summary>
Motivation: 胶囊网络（CapsNet）虽然在小规模数据集如MNIST上表现良好，但在复杂数据集和实际应用中性能不佳，训练速度慢且参数过多。

Method: 引入新的CFC层作为创建胶囊的替代方法，通过卷积全连接方式生成更少但更强大的胶囊。

Result: 在CIFAR-10、SVHN和Fashion-MNIST数据集上，CFC-CapsNet实现了竞争性的准确率，更快的训练和推理速度，以及更少的参数使用。

Conclusion: CFC-CapsNet有效解决了传统胶囊网络的局限性，在保持性能的同时提升了效率。

Abstract: A Capsule Network (CapsNet) is a relatively new classifier and one of the
possible successors of Convolutional Neural Networks (CNNs). CapsNet maintains
the spatial hierarchies between the features and outperforms CNNs at
classifying images including overlapping categories. Even though CapsNet works
well on small-scale datasets such as MNIST, it fails to achieve a similar level
of performance on more complicated datasets and real applications. In addition,
CapsNet is slow compared to CNNs when performing the same task and relies on a
higher number of parameters. In this work, we introduce Convolutional
Fully-Connected Capsule Network (CFC-CapsNet) to address the shortcomings of
CapsNet by creating capsules using a different method. We introduce a new layer
(CFC layer) as an alternative solution to creating capsules. CFC-CapsNet
produces fewer, yet more powerful capsules resulting in higher network
accuracy. Our experiments show that CFC-CapsNet achieves competitive accuracy,
faster training and inference and uses less number of parameters on the
CIFAR-10, SVHN and Fashion-MNIST datasets compared to conventional CapsNet.

</details>


### [25] [Grounding Foundational Vision Models with 3D Human Poses for Robust Action Recognition](https://arxiv.org/abs/2511.05622)
*Nicholas Babey,Tiffany Gu,Yiheng Li,Cristian Meo,Kevin Zhu*

Main category: cs.CV

TL;DR: 该论文提出了一种融合V-JEPA 2的世界动态预测和CoMotion人体姿态数据的动作识别模型，通过在物理空间中理解动作来提升复杂遮挡场景下的识别性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于RGB视频的动作识别模型仅学习模式与动作标签之间的表面相关性，难以捕捉物理交互动态和人体姿态，特别是在复杂遮挡场景下表现不佳。

Method: 提出融合V-JEPA 2的上下文预测世界动态和CoMotion的显式、抗遮挡人体姿态数据的模型架构，将动作识别建立在物理空间理解基础上。

Result: 在InHARD和UCF-19-Y-OCC基准测试中优于三个基线模型，在复杂遮挡场景下表现尤为突出。

Conclusion: 动作识别需要基于空间理解而非统计模式识别，物理空间的grounding对提升动作识别性能至关重要。

Abstract: For embodied agents to effectively understand and interact within the world
around them, they require a nuanced comprehension of human actions grounded in
physical space. Current action recognition models, often relying on RGB video,
learn superficial correlations between patterns and action labels, so they
struggle to capture underlying physical interaction dynamics and human poses in
complex scenes. We propose a model architecture that grounds action recognition
in physical space by fusing two powerful, complementary representations: V-JEPA
2's contextual, predictive world dynamics and CoMotion's explicit,
occlusion-tolerant human pose data. Our model is validated on both the InHARD
and UCF-19-Y-OCC benchmarks for general action recognition and high-occlusion
action recognition, respectively. Our model outperforms three other baselines,
especially within complex, occlusive scenes. Our findings emphasize a need for
action recognition to be supported by spatial understanding instead of
statistical pattern recognition.

</details>


### [26] [Registration-Free Monitoring of Unstructured Point Cloud Data via Intrinsic Geometrical Properties](https://arxiv.org/abs/2511.05623)
*Mariafrancesca Patalano,Giovanna Capizzi,Kamran Paynabar*

Main category: cs.CV

TL;DR: 提出了一种无需配准和网格重建的点云数据监控方法，利用拉普拉斯和测地距离提取内在几何特征，通过阈值技术识别异常状态。


<details>
  <summary>Details</summary>
Motivation: 传统点云数据预处理步骤（配准和网格重建）容易出错、耗时且可能引入伪影，影响监控结果的准确性。

Method: 开发了两种基于拉普拉斯距离和测地距离的特征学习方法，结合阈值选择技术来监控复杂形状的点云数据。

Result: 数值实验和案例研究表明该方法能有效识别不同类型的缺陷。

Conclusion: 该方法无需配准和网格重建，简化了监控流程，提高了点云数据监控的效率和准确性。

Abstract: Modern sensing technologies have enabled the collection of unstructured point
cloud data (PCD) of varying sizes, which are used to monitor the geometric
accuracy of 3D objects. PCD are widely applied in advanced manufacturing
processes, including additive, subtractive, and hybrid manufacturing. To ensure
the consistency of analysis and avoid false alarms, preprocessing steps such as
registration and mesh reconstruction are commonly applied prior to monitoring.
However, these steps are error-prone, time-consuming and may introduce
artifacts, potentially affecting monitoring outcomes. In this paper, we present
a novel registration-free approach for monitoring PCD of complex shapes,
eliminating the need for both registration and mesh reconstruction. Our
proposal consists of two alternative feature learning methods and a common
monitoring scheme. Feature learning methods leverage intrinsic geometric
properties of the shape, captured via the Laplacian and geodesic distances. In
the monitoring scheme, thresholding techniques are used to further select
intrinsic features most indicative of potential out-of-control conditions.
Numerical experiments and case studies highlight the effectiveness of the
proposed approach in identifying different types of defects.

</details>


### [27] [Culture in Action: Evaluating Text-to-Image Models through Social Activities](https://arxiv.org/abs/2511.05681)
*Sina Malakouti,Boqing Gong,Adriana Kovashka*

Main category: cs.CV

TL;DR: CULTIVate是一个用于评估文本到图像扩散模型在跨文化活动表现上的基准测试，包含16个国家、576个提示和超过19,000张图像，提出了四个可解释的文化对齐度量指标。


<details>
  <summary>Details</summary>
Motivation: 现有文化基准主要关注物体中心类别，忽视了更能反映文化规范的社会和日常活动，且缺乏衡量文化忠实度的指标。

Method: 构建了涵盖问候、用餐、游戏、传统舞蹈和文化庆典等跨文化活动的基准数据集，并提出了基于描述符的可解释评估框架，包括文化对齐、幻觉、夸张元素和多样性四个度量指标。

Result: 研究发现模型在北方国家表现优于南方国家，不同T2I系统存在明显的失败模式，且提出的指标与人类判断的相关性优于现有文本-图像度量指标。

Conclusion: CULTIVate基准揭示了文本到图像模型在文化表现上的系统性差异，为评估和改进模型的文化忠实度提供了有效工具。

Abstract: Text-to-image (T2I) diffusion models achieve impressive photorealism by
training on large-scale web data, but models inherit cultural biases and fail
to depict underrepresented regions faithfully. Existing cultural benchmarks
focus mainly on object-centric categories (e.g., food, attire, and
architecture), overlooking the social and daily activities that more clearly
reflect cultural norms. Few metrics exist for measuring cultural faithfulness.
We introduce CULTIVate, a benchmark for evaluating T2I models on cross-cultural
activities (e.g., greetings, dining, games, traditional dances, and cultural
celebrations). CULTIVate spans 16 countries with 576 prompts and more than
19,000 images, and provides an explainable descriptor-based evaluation
framework across multiple cultural dimensions, including background, attire,
objects, and interactions. We propose four metrics to measure cultural
alignment, hallucination, exaggerated elements, and diversity. Our findings
reveal systematic disparities: models perform better for global north countries
than for the global south, with distinct failure modes across T2I systems.
Human studies confirm that our metrics correlate more strongly with human
judgments than existing text-image metrics.

</details>


### [28] [VMDT: Decoding the Trustworthiness of Video Foundation Models](https://arxiv.org/abs/2511.05682)
*Yujin Potter,Zhun Wang,Nicholas Crispino,Kyle Montgomery,Alexander Xiong,Ethan Y. Chang,Francesco Pinto,Yuqi Chen,Rahul Gupta,Morteza Ziyadi,Christos Christodoulopoulos,Bo Li,Chenguang Wang,Dawn Song*

Main category: cs.CV

TL;DR: VMDT是首个统一评估文本到视频和视频到文本模型在五个关键可信度维度的平台，包括安全性、幻觉、公平性、隐私和对抗鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着基础模型日益复杂，确保其可信度变得至关重要，但视频模态目前缺乏全面的可信度基准测试。

Method: 开发了VMDT平台，对7个T2V模型和19个V2T模型在五个可信度维度进行了广泛评估。

Result: 开源T2V模型无法识别有害查询并经常生成有害视频，公平性低于图像模态模型；V2T模型规模越大公平性和隐私风险越高，但幻觉和对抗鲁棒性有所改善；安全性表现与模型规模无关。

Conclusion: 研究结果强调了开发更鲁棒和可信的视频基础模型的紧迫性，VMDT为衡量和跟踪这一目标的进展提供了系统性框架。

Abstract: As foundation models become more sophisticated, ensuring their
trustworthiness becomes increasingly critical; yet, unlike text and image, the
video modality still lacks comprehensive trustworthiness benchmarks. We
introduce VMDT (Video-Modal DecodingTrust), the first unified platform for
evaluating text-to-video (T2V) and video-to-text (V2T) models across five key
trustworthiness dimensions: safety, hallucination, fairness, privacy, and
adversarial robustness. Through our extensive evaluation of 7 T2V models and 19
V2T models using VMDT, we uncover several significant insights. For instance,
all open-source T2V models evaluated fail to recognize harmful queries and
often generate harmful videos, while exhibiting higher levels of unfairness
compared to image modality models. In V2T models, unfairness and privacy risks
rise with scale, whereas hallucination and adversarial robustness improve --
though overall performance remains low. Uniquely, safety shows no correlation
with model size, implying that factors other than scale govern current safety
levels. Our findings highlight the urgent need for developing more robust and
trustworthy video foundation models, and VMDT provides a systematic framework
for measuring and tracking progress toward this goal. The code is available at
https://sunblaze-ucb.github.io/VMDT-page/.

</details>


### [29] [Pedicle Screw Pairing and Registration for Screw Pose Estimation from Dual C-arm Images Using CAD Models](https://arxiv.org/abs/2511.05702)
*Yehyun Suh,Lin Li,Aric Plumley,Chaochao Zhou,Daniel Moyer,Kongbin Kang*

Main category: cs.CV

TL;DR: 提出了一种从双C臂图像中解决椎弓根螺钉对应关系和姿态估计的方法，通过比较螺钉组合和2D-3D配准技术，在螺钉配对和配准任务中表现出一致准确性。


<details>
  <summary>Details</summary>
Motivation: 在脊柱手术中，准确匹配前后位和侧位图像中的椎弓根螺钉对于手术成功至关重要，但特别是在侧位视图中建立螺钉对应关系仍然是一个重大临床挑战。

Method: 通过比较螺钉组合，采用2D-3D配准技术与螺钉CAD 3D模型进行精确配对和姿态估计，从双视图图像中解决螺钉对应关系问题。

Result: 正确螺钉组合在所有测试案例中始终优于错误配对，即使在配准前也是如此。配准后，正确组合进一步增强了投影与图像之间的对齐，显著减少了投影误差。

Conclusion: 该方法通过提供可靠的螺钉定位反馈，有望改善脊柱手术的手术效果。

Abstract: Accurate matching of pedicle screws in both anteroposterior (AP) and lateral
(LAT) images is critical for successful spinal decompression and stabilization
during surgery. However, establishing screw correspondence, especially in LAT
views, remains a significant clinical challenge. This paper introduces a method
to address pedicle screw correspondence and pose estimation from dual C-arm
images. By comparing screw combinations, the approach demonstrates consistent
accuracy in both pairing and registration tasks. The method also employs 2D-3D
alignment with screw CAD 3D models to accurately pair and estimate screw pose
from dual views. Our results show that the correct screw combination
consistently outperforms incorrect pairings across all test cases, even prior
to registration. After registration, the correct combination further enhances
alignment between projections and images, significantly reducing projection
error. This approach shows promise for improving surgical outcomes in spinal
procedures by providing reliable feedback on screw positioning.

</details>


### [30] [Long Grounded Thoughts: Distilling Compositional Visual Reasoning Chains at Scale](https://arxiv.org/abs/2511.05705)
*David Acuna,Chao-Han Huck Yang,Yuntian Deng,Jaehun Jung,Ximing Lu,Prithviraj Ammanabrolu,Hyunwoo Kim,Yuan-Hong Liao,Yejin Choi*

Main category: cs.CV

TL;DR: 本文提出了一个包含超过100万高质量合成视觉中心问题的新推理数据生成框架，该框架通过两阶段合成过程生成推理轨迹，在多个视觉推理基准测试中表现优异，并展现出跨模态迁移能力。


<details>
  <summary>Details</summary>
Motivation: 当前多模态推理领域的进展主要依赖于未公开的数据集和专有数据合成方法，缺乏系统构建大规模视觉中心推理数据集的方法，特别是针对超越视觉数学任务的挑战。

Method: 采用两阶段合成框架：规模扩展和复杂度提升。利用视觉语言模型和推理大语言模型生成推理轨迹，产生包含丰富认知行为的思维链轨迹。支持离线和在线强化学习。

Result: 在Qwen2.5-VL-7B模型上微调后，在所有评估的视觉中心基准测试中均优于所有开源基线，甚至超过MiMo-VL-7B-RL等强封闭数据模型。尽管完全基于视觉，但数据在纯文本推理和音频推理上也有正向迁移效果。

Conclusion: 高质量数据上的监督微调对于有效的在线强化学习至关重要；分阶段离线强化学习可以匹配在线强化学习的性能同时降低计算需求；精心设计的监督微调可以显著改善跨域、跨模态的迁移效果。

Abstract: Recent progress in multimodal reasoning has been driven largely by
undisclosed datasets and proprietary data synthesis recipes, leaving open
questions about how to systematically build large-scale, vision-centric
reasoning datasets, particularly for tasks that go beyond visual math. In this
work, we introduce a new reasoning data generation framework spanning diverse
skills and levels of complexity with over 1M high-quality synthetic
vision-centric questions. The dataset also includes preference data and
instruction prompts supporting both offline and online RL. Our synthesis
framework proceeds in two stages: (1) scale; and (2) complexity. Reasoning
traces are then synthesized through a two-stage process that leverages VLMs and
reasoning LLMs, producing CoT traces for VLMs that capture the richness and
diverse cognitive behaviors found in frontier reasoning models. Remarkably, we
show that finetuning Qwen2.5-VL-7B on our data outperforms all open-data
baselines across all evaluated vision-centric benchmarks, and even surpasses
strong closed-data models such as MiMo-VL-7B-RL on V* Bench, CV-Bench and
MMStar-V. Perhaps most surprising, despite being entirely vision-centric, our
data transfers positively to text-only reasoning (MMLU-Pro) and audio reasoning
(MMAU), demonstrating its effectiveness. Similarly, despite not containing
videos or embodied visual data, we observe notable gains when evaluating on a
single-evidence embodied QA benchmark (NiEH). Finally, we use our data to
analyze the entire VLM post-training pipeline. Our empirical analysis
highlights that (i) SFT on high-quality data with non-linear reasoning traces
is essential for effective online RL, (ii) staged offline RL matches online
RL's performance while reducing compute demands, and (iii) careful SFT on high
quality data can substantially improve out-of-domain, cross-modality transfer.

</details>


### [31] [Towards Better Ultrasound Video Segmentation Foundation Model: An Empirical study on SAM2 Finetuning from Data Perspective](https://arxiv.org/abs/2511.05731)
*Xing Yao,Ahana Gangopadhyay,Hsi-Ming Chang,Ravi Soni*

Main category: cs.CV

TL;DR: 该论文系统研究了SAM2模型在超声视频分割中的适应性问题，发现数据规模和时间上下文比模型架构或初始化更重要，联合训练在模态对齐和任务专业化之间提供了有效平衡。


<details>
  <summary>Details</summary>
Motivation: 超声视频分割面临数据变异大、运动伪影和标注数据有限等挑战。虽然SAM2等基础模型具有强大的零样本分割能力，但在医学影像领域性能显著下降。当前研究主要关注架构修改，而数据特性和训练策略的影响尚未系统研究。

Method: 进行了数据中心的SAM2适应研究，分析训练集大小、视频时长和增强方案对三种适应范式（任务特定微调、中间适应、多任务联合训练）的影响，设计了六种超声特定增强策略，并在三个超声数据集上进行实验。

Result: 实验表明数据规模和时间上下文对适应性能起决定性作用，联合训练在模态对齐和任务专业化之间提供了高效折衷，超声特定增强策略优于通用增强方法。

Conclusion: 本研究为开发高效、数据感知的SAM2超声视频分析适应管道提供了实证见解，强调了数据特性在医学影像模型适应中的关键作用。

Abstract: Ultrasound (US) video segmentation remains a challenging problem due to
strong inter- and intra-dataset variability, motion artifacts, and limited
annotated data. Although foundation models such as Segment Anything Model 2
(SAM2) demonstrate strong zero-shot and prompt-guided segmentation
capabilities, their performance deteriorates substantially when transferred to
medical imaging domains. Current adaptation studies mainly emphasize
architectural modifications, while the influence of data characteristics and
training regimes has not been systematically examined. In this study, we
present a comprehensive, data-centric investigation of SAM2 adaptation for
ultrasound video segmentation. We analyze how training-set size, video
duration, and augmentation schemes affect adaptation performance under three
paradigms: task-specific fine-tuning, intermediate adaptation, and multi-task
joint training, across five SAM2 variants and multiple prompting modes. We
further design six ultrasound-specific augmentations, assessing their effect
relative to generic strategies. Experiments on three representative ultrasound
datasets reveal that data scale and temporal context play a more decisive role
than model architecture or initialization. Moreover, joint training offers an
efficient compromise between modality alignment and task specialization. This
work aims to provide empirical insights for developing efficient, data-aware
adaptation pipelines for SAM2 in ultrasound video analysis.

</details>


### [32] [A Second-Order Attention Mechanism For Prostate Cancer Segmentation and Detection in Bi-Parametric MRI](https://arxiv.org/abs/2511.05760)
*Mateo Ortiz,Juan Olmos,Fabio Martínez*

Main category: cs.CV

TL;DR: 提出了一种基于黎曼流形的二阶几何注意力机制（SOGA），用于引导分割网络检测前列腺癌病变，在PI-CAI和Prostate158数据集上表现出优于基线方法和注意力方法的性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于双参数MRI的前列腺癌病变检测依赖主观专家解读，深度学习方法的局限性在于需要大量标注数据，且前列腺区域病变变异性高，给准确检测带来挑战。

Method: 开发了二阶几何注意力机制，在黎曼流形上建模，学习对称正定表示，通过跳跃连接引导分割网络，并集成到标准U-Net和nnU-Net主干网络中。

Result: 在PI-CAI数据集上达到AP 0.37和AUC-ROC 0.83，在Prostate158数据集上达到AP 0.37和AUC-ROC 0.75，优于基线网络和注意力方法。

Conclusion: 该方法表现出强大的泛化能力和判别性学习表示，为前列腺癌病变检测提供了有效的解决方案。

Abstract: The detection of clinically significant prostate cancer lesions (csPCa) from
biparametric magnetic resonance imaging (bp-MRI) has emerged as a noninvasive
imaging technique for improving accurate diagnosis. Nevertheless, the analysis
of such images remains highly dependent on the subjective expert
interpretation. Deep learning approaches have been proposed for csPCa lesions
detection and segmentation, but they remain limited due to their reliance on
extensively annotated datasets. Moreover, the high lesion variability across
prostate zones poses additional challenges, even for expert radiologists. This
work introduces a second-order geometric attention (SOGA) mechanism that guides
a dedicated segmentation network, through skip connections, to detect csPCa
lesions. The proposed attention is modeled on the Riemannian manifold, learning
from symmetric positive definitive (SPD) representations. The proposed
mechanism was integrated into standard U-Net and nnU-Net backbones, and was
validated on the publicly available PI-CAI dataset, achieving an Average
Precision (AP) of 0.37 and an Area Under the ROC Curve (AUC-ROC) of 0.83,
outperforming baseline networks and attention-based methods. Furthermore, the
approach was evaluated on the Prostate158 dataset as an independent test
cohort, achieving an AP of 0.37 and an AUC-ROC of 0.75, confirming robust
generalization and suggesting discriminative learned representations.

</details>


### [33] [Sign language recognition from skeletal data using graph and recurrent neural networks](https://arxiv.org/abs/2511.05772)
*B. Mederos,J. Mejía,A. Medina-Reyes,Y. Espinosa-Almeyda,J. D. Díaz-Roman,I. Rodríguez-Mederos,M. Mejía-Carreon,F. Gonzalez-Lopez*

Main category: cs.CV

TL;DR: 提出了一种基于骨架姿态数据的孤立手语手势识别方法，使用Graph-GRU时空网络建模空间和时间依赖关系，在AUTSL数据集上取得高准确率。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够同时捕捉手语手势空间和时间特征的有效识别方法，为手语理解提供可扩展的框架。

Method: 使用从视频序列提取的骨架姿态数据，构建Graph-GRU时空网络来建模帧间的空间和时间依赖关系，实现准确分类。

Result: 在AUTSL数据集上的实验结果表明该方法取得了高准确率，证明了基于图的空问表示与时间建模结合的有效性。

Conclusion: 基于姿态驱动的方法在手语理解方面具有巨大潜力，该方法为手语识别提供了可扩展的解决方案。

Abstract: This work presents an approach for recognizing isolated sign language
gestures using skeleton-based pose data extracted from video sequences. A
Graph-GRU temporal network is proposed to model both spatial and temporal
dependencies between frames, enabling accurate classification. The model is
trained and evaluated on the AUTSL (Ankara university Turkish sign language)
dataset, achieving high accuracy. Experimental results demonstrate the
effectiveness of integrating graph-based spatial representations with temporal
modeling, providing a scalable framework for sign language recognition. The
results of this approach highlight the potential of pose-driven methods for
sign language understanding.

</details>


### [34] [TCSA-UDA: Text-Driven Cross-Semantic Alignment for Unsupervised Domain Adaptation in Medical Image Segmentation](https://arxiv.org/abs/2511.05782)
*Lalit Maurya,Honghai Liu,Reyer Zwiggelaar*

Main category: cs.CV

TL;DR: TCSA-UDA是一个基于文本驱动的跨语义对齐框架，利用领域不变的文本类别描述来指导视觉表示学习，用于医学图像分割的无监督领域自适应任务。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像分割中由于成像模态（如CT和MRI）差异导致的显著领域偏移问题，同时探索视觉-语言表示学习方法在UDA分割任务中的潜力。

Method: 提出视觉-语言协方差余弦损失直接对齐图像编码器特征与类间文本语义关系；引入原型对齐模块，使用高级语义原型跨域对齐类级像素级特征分布。

Result: 在心脏、腹部和脑肿瘤分割基准测试中，TCSA-UDA显著减少领域偏移，并持续优于最先进的UDA方法。

Conclusion: 该框架为将语言驱动语义集成到领域自适应医学图像分析中建立了新范式。

Abstract: Unsupervised domain adaptation for medical image segmentation remains a
significant challenge due to substantial domain shifts across imaging
modalities, such as CT and MRI. While recent vision-language representation
learning methods have shown promise, their potential in UDA segmentation tasks
remains underexplored. To address this gap, we propose TCSA-UDA, a Text-driven
Cross-Semantic Alignment framework that leverages domain-invariant textual
class descriptions to guide visual representation learning. Our approach
introduces a vision-language covariance cosine loss to directly align image
encoder features with inter-class textual semantic relations, encouraging
semantically meaningful and modality-invariant feature representations.
Additionally, we incorporate a prototype alignment module that aligns
class-wise pixel-level feature distributions across domains using high-level
semantic prototypes. This mitigates residual category-level discrepancies and
enhances cross-modal consistency. Extensive experiments on challenging
cross-modality cardiac, abdominal, and brain tumor segmentation benchmarks
demonstrate that our TCSA-UDA framework significantly reduces domain shift and
consistently outperforms state-of-the-art UDA methods, establishing a new
paradigm for integrating language-driven semantics into domain-adaptive medical
image analysis.

</details>


### [35] [Position-Prior-Guided Network for System Matrix Super-Resolution in Magnetic Particle Imaging](https://arxiv.org/abs/2511.05795)
*Xuqing Geng,Lei Su,Zhongwei Bian,Zewen Sun,Jiaxuan Wen,Jie Tian,Yang Du*

Main category: cs.CV

TL;DR: 本文提出了一种在磁粒子成像系统矩阵校准中整合位置先验的方法，以提高校准效率并充分利用物理先验知识。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习超分辨率方法在系统矩阵校准中未能充分利用物理先验知识（如对称位置先验），导致校准过程耗时且需要重复测量。

Method: 将位置先验整合到现有框架中，通过理论论证和实验验证，在2D和3D系统矩阵超分辨率方法中应用位置先验。

Result: 实验证明整合位置先验能有效提高系统矩阵校准的效率。

Conclusion: 位置先验的整合能显著提升磁粒子成像系统矩阵校准的性能，充分利用物理知识优化重建过程。

Abstract: Magnetic Particle Imaging (MPI) is a novel medical imaging modality. One of
the established methods for MPI reconstruction is based on the System Matrix
(SM). However, the calibration of the SM is often time-consuming and requires
repeated measurements whenever the system parameters change. Current
methodologies utilize deep learning-based super-resolution (SR) techniques to
expedite SM calibration; nevertheless, these strategies do not fully exploit
physical prior knowledge associated with the SM, such as symmetric positional
priors. Consequently, we integrated positional priors into existing frameworks
for SM calibration. Underpinned by theoretical justification, we empirically
validated the efficacy of incorporating positional priors through experiments
involving both 2D and 3D SM SR methods.

</details>


### [36] [MACMD: Multi-dilated Contextual Attention and Channel Mixer Decoding for Medical Image Segmentation](https://arxiv.org/abs/2511.05803)
*Lalit Maurya,Honghai Liu,Reyer Zwiggelaar*

Main category: cs.CV

TL;DR: 本文提出了一种MACMD-based解码器，通过增强注意力机制和通道混合来解决医学图像分割中局部细节和全局上下文整合效率低的问题。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割面临解剖结构变化的挑战。CNN擅长捕捉局部特征但难以建模长距离依赖，Transformer能解决长距离依赖但缺乏局部上下文信息保留能力。现有编码器-解码器架构存在两个关键局限：浅层细节信息在深层传播中丢失，以及局部细节与全局上下文整合效率低下。

Method: 提出MACMD-based解码器，通过分层扩张卷积、注意力驱动调制和跨通道混合模块来增强注意力机制，利用跳跃连接促进编码器和解码器阶段之间的通道混合，从而在保留局部上下文细节的同时捕捉长距离依赖。

Result: 在二值和多器官分割任务上使用多种Transformer编码器进行评估，结果表明该方法在Dice分数和计算效率方面均优于最先进方法。

Conclusion: MACMD-based解码器能够实现精确且鲁棒的医学图像分割性能，有效解决了局部细节保留和全局上下文建模的平衡问题。

Abstract: Medical image segmentation faces challenges due to variations in anatomical
structures. While convolutional neural networks (CNNs) effectively capture
local features, they struggle with modeling long-range dependencies.
Transformers mitigate this issue with self-attention mechanisms but lack the
ability to preserve local contextual information. State-of-the-art models
primarily follow an encoder-decoder architecture, achieving notable success.
However, two key limitations remain: (1) Shallow layers, which are closer to
the input, capture fine-grained details but suffer from information loss as
data propagates through deeper layers. (2) Inefficient integration of local
details and global context between the encoder and decoder stages. To address
these challenges, we propose the MACMD-based decoder, which enhances attention
mechanisms and facilitates channel mixing between encoder and decoder stages
via skip connections. This design leverages hierarchical dilated convolutions,
attention-driven modulation, and a cross channel-mixing module to capture
long-range dependencies while preserving local contextual details, essential
for precise medical image segmentation. We evaluated our approach using
multiple transformer encoders on both binary and multi-organ segmentation
tasks. The results demonstrate that our method outperforms state-of-the-art
approaches in terms of Dice score and computational efficiency, highlighting
its effectiveness in achieving accurate and robust segmentation performance.
The code available at https://github.com/lalitmaurya47/MACMD

</details>


### [37] [LRANet++: Low-Rank Approximation Network for Accurate and Efficient Text Spotting](https://arxiv.org/abs/2511.05818)
*Yuchen Su,Zhineng Chen,Yongkun Du,Zuxuan Wu,Hongtao Xie,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: LRANet++是一种端到端任意形状文本检测识别框架，通过低秩参数化文本形状表示和三元分配检测头，实现了准确高效的文本检测识别。


<details>
  <summary>Details</summary>
Motivation: 现有端到端文本检测识别方法在处理任意形状文本时存在瓶颈，主要是缺乏可靠高效的文本检测方法。

Method: 提出基于低秩近似的参数化文本形状方法，使用ℓ1-范数重构算法从标注文本边界推导低秩子空间；采用三元分配检测头架构，包含深度稀疏分支、超轻量稀疏分支和密集分支。

Result: 在多个挑战性基准测试上的广泛实验表明，LRANet++相比最先进方法具有优越性。

Conclusion: LRANet++通过改进的检测模块与轻量识别分支集成，能够准确高效地检测任意形状文本。

Abstract: End-to-end text spotting aims to jointly optimize text detection and
recognition within a unified framework. Despite significant progress, designing
an accurate and efficient end-to-end text spotter for arbitrary-shaped text
remains largely unsolved. We identify the primary bottleneck as the lack of a
reliable and efficient text detection method. To address this, we propose a
novel parameterized text shape method based on low-rank approximation for
precise detection and a triple assignment detection head to enable fast
inference. Specifically, unlike other shape representation methods that employ
data-irrelevant parameterization, our data-driven approach derives a low-rank
subspace directly from labeled text boundaries. To ensure this process is
robust against the inherent annotation noise in this data, we utilize a
specialized recovery method based on an $\ell_1$-norm formulation, which
accurately reconstructs the text shape with only a few key orthogonal vectors.
By exploiting the inherent shape correlation among different text contours, our
method achieves consistency and compactness in shape representation. Next, the
triple assignment scheme introduces a novel architecture where a deep sparse
branch (for stabilized training) is used to guide the learning of an
ultra-lightweight sparse branch (for accelerated inference), while a dense
branch provides rich parallel supervision. Building upon these advancements, we
integrate the enhanced detection module with a lightweight recognition branch
to form an end-to-end text spotting framework, termed LRANet++, capable of
accurately and efficiently spotting arbitrary-shaped text. Extensive
experiments on several challenging benchmarks demonstrate the superiority of
LRANet++ compared to state-of-the-art methods. Code will be available at:
https://github.com/ychensu/LRANet-PP.git

</details>


### [38] [Hilbert-Guided Block-Sparse Local Attention](https://arxiv.org/abs/2511.05832)
*Yunge Li,Lanyu Xu*

Main category: cs.CV

TL;DR: 提出基于希尔伯特曲线的窗口注意力机制，通过重新排列图像token来增加块稀疏性，显著提升2D局部注意力的效率。


<details>
  <summary>Details</summary>
Motivation: 全局自注意力的二次计算和内存成本限制了其在高分辨率图像中的应用，而传统局部注意力模式由于token在1D序列中不连续，难以实现显著加速。

Method: 使用希尔伯特曲线对图像token进行重新排序，在重排序后的1D序列上构建窗口和邻域，结合现有的块稀疏核来提高2D局部注意力的效率。

Result: 希尔伯特窗口注意力和希尔伯特滑动注意力分别实现了约4倍和18倍的加速，基于此策略的Hilbert Window Transformer和Hilbert Neighborhood Transformer在保持精度的同时实现了端到端加速。

Conclusion: 希尔伯特引导的局部注意力与块稀疏核相结合，为提升图像2D局部注意力效率提供了一种通用且实用的方法。

Abstract: The quadratic compute and memory costs of global self-attention severely
limit its use in high-resolution images. Local attention reduces complexity by
restricting attention to neighborhoods. Block-sparse kernels can further
improve the efficiency of local attention, but conventional local attention
patterns often fail to deliver significant speedups because tokens within a
window are not contiguous in the 1D sequence. This work proposes a novel method
for constructing windows and neighborhoods based on the Hilbert curve. Image
tokens are first reordered along a Hilbert curve, and windows and neighborhoods
are then formed on the reordered 1D sequence. From a block-sparse perspective,
this strategy significantly increases block sparsity and can be combined with
existing block-sparse kernels to improve the efficiency of 2D local attention.
Experiments show that the proposed Hilbert Window Attention and Hilbert Slide
Attention can accelerate window attention and slide attention by about
$4\times$ and $18\times$, respectively. To assess practicality, the strategy is
instantiated as the Hilbert Window Transformer and the Hilbert Neighborhood
Transformer, both of which achieve end-to-end speedups with minimal accuracy
loss. Overall, combining Hilbert-guided local attention with block-sparse
kernels offers a general and practical approach to enhancing the efficiency of
2D local attention for images. The code is available at
https://github.com/Yunge6666/Hilbert-Local-Attention.

</details>


### [39] [TYrPPG: Uncomplicated and Enhanced Learning Capability rPPG for Remote Heart Rate Estimation](https://arxiv.org/abs/2511.05833)
*Taixi Chen,Yiu-ming Cheung*

Main category: cs.CV

TL;DR: 提出了一种基于Mambaout结构的新型rPPG算法TYrPPG，通过创新的门控视频理解块和综合监督损失函数，在远程心率估计中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的rPPG模型计算效率低，而Mamba模型在视觉任务中证明其核心SSM模块不必要，因此探索基于Mambaout结构的简化高效方案。

Method: 提出TYrPPG算法，包含创新的门控视频理解块(GVB)结合2D-CNN和3D-CNN进行视频分析，以及综合监督损失函数(CSL)及其弱监督变体。

Result: 实验表明TYrPPG在常用数据集上达到了最先进的性能，证明了其在远程心率估计中的优越性。

Conclusion: 基于Mambaout结构的TYrPPG算法在保持高性能的同时提高了计算效率，为远程心率监测提供了有前景的解决方案。

Abstract: Remote photoplethysmography (rPPG) can remotely extract physiological signals
from RGB video, which has many advantages in detecting heart rate, such as low
cost and no invasion to patients. The existing rPPG model is usually based on
the transformer module, which has low computation efficiency. Recently, the
Mamba model has garnered increasing attention due to its efficient performance
in natural language processing tasks, demonstrating potential as a substitute
for transformer-based algorithms. However, the Mambaout model and its variants
prove that the SSM module, which is the core component of the Mamba model, is
unnecessary for the vision task. Therefore, we hope to prove the feasibility of
using the Mambaout-based module to remotely learn the heart rate. Specifically,
we propose a novel rPPG algorithm called uncomplicated and enhanced learning
capability rPPG (TYrPPG). This paper introduces an innovative gated video
understanding block (GVB) designed for efficient analysis of RGB videos. Based
on the Mambaout structure, this block integrates 2D-CNN and 3D-CNN to enhance
video understanding for analysis. In addition, we propose a comprehensive
supervised loss function (CSL) to improve the model's learning capability,
along with its weakly supervised variants. The experiments show that our TYrPPG
can achieve state-of-the-art performance in commonly used datasets, indicating
its prospects and superiority in remote heart rate estimation. The source code
is available at https://github.com/Taixi-CHEN/TYrPPG.

</details>


### [40] [Understanding Cross Task Generalization in Handwriting-Based Alzheimer's Screening via Vision Language Adaptation](https://arxiv.org/abs/2511.05841)
*Changqing Gong,Huafeng Qin,Mounim A. El-Yacoubi*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级跨层融合适配器框架（CLFA），利用CLIP模型进行基于笔迹的阿尔茨海默病筛查，通过多级融合适配器实现无需提示的高效零样本推理，并系统研究了跨任务泛化能力。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病早期检测至关重要，笔迹变化可作为非侵入性筛查指标。现有研究未系统分析任务类型对诊断性能的影响，且大规模视觉语言模型在笔迹疾病检测领域尚未充分探索。

Method: 提出CLFA框架，在CLIP视觉编码器中植入多级融合适配器，逐步对齐笔迹特异性医学特征，实现无需提示的零样本推理。通过跨任务泛化实验评估不同笔迹任务的鉴别效果。

Result: 系统揭示了哪些任务类型和书写模式能最有效区分阿尔茨海默病，分析了特征性笔画模式和任务级别因素对早期识别的贡献。

Conclusion: 该研究为基于笔迹的认知评估提供了诊断见解和基准，证明了CLFA框架在笔迹基阿尔茨海默病筛查中的有效性和适应性。

Abstract: Alzheimer's disease is a prevalent neurodegenerative disorder for which early
detection is critical. Handwriting-often disrupted in prodromal AD-provides a
non-invasive and cost-effective window into subtle motor and cognitive decline.
Existing handwriting-based AD studies, mostly relying on online trajectories
and hand-crafted features, have not systematically examined how task type
influences diagnostic performance and cross-task generalization. Meanwhile,
large-scale vision language models have demonstrated remarkable zero or
few-shot anomaly detection in natural images and strong adaptability across
medical modalities such as chest X-ray and brain MRI. However,
handwriting-based disease detection remains largely unexplored within this
paradigm. To close this gap, we introduce a lightweight Cross-Layer Fusion
Adapter framework that repurposes CLIP for handwriting-based AD screening. CLFA
implants multi-level fusion adapters within the visual encoder to progressively
align representations toward handwriting-specific medical cues, enabling
prompt-free and efficient zero-shot inference. Using this framework, we
systematically investigate cross-task generalization-training on a specific
handwriting task and evaluating on unseen ones-to reveal which task types and
writing patterns most effectively discriminate AD. Extensive analyses further
highlight characteristic stroke patterns and task-level factors that contribute
to early AD identification, offering both diagnostic insights and a benchmark
for handwriting-based cognitive assessment.

</details>


### [41] [Enhancing Diffusion Model Guidance through Calibration and Regularization](https://arxiv.org/abs/2511.05844)
*Seyed Alireza Javid,Amirhossein Bagheri,Nuria González-Prelcic*

Main category: cs.CV

TL;DR: 本文针对分类器引导扩散模型在早期去噪步骤中预测过于自信导致梯度消失的问题，提出了两种互补的解决方案：基于平滑期望校准误差的可微校准目标和增强采样引导方法。


<details>
  <summary>Details</summary>
Motivation: 分类器引导扩散模型在条件图像生成中表现强大，但存在早期去噪步骤中预测过于自信导致引导梯度消失的问题，影响生成质量。

Method: 1. 提出基于平滑期望校准误差的可微校准目标，通过最小化微调改善分类器校准；2. 开发增强采样引导方法，包括倾斜采样与批级重加权、自适应熵正则化采样和基于f-散度的采样策略。

Result: 在ImageNet 128x128数据集上，使用ResNet-101分类器的f-散度正则化引导方法实现了2.13的FID分数，优于现有分类器引导扩散方法，且无需扩散模型重新训练。

Conclusion: 原则性校准和散度感知采样为分类器引导扩散提供了实用有效的改进，显著提升了生成质量。

Abstract: Classifier-guided diffusion models have emerged as a powerful approach for
conditional image generation, but they suffer from overconfident predictions
during early denoising steps, causing the guidance gradient to vanish. This
paper introduces two complementary contributions to address this issue. First,
we propose a differentiable calibration objective based on the Smooth Expected
Calibration Error (Smooth ECE), which improves classifier calibration with
minimal fine-tuning and yields measurable improvements in Frechet Inception
Distance (FID). Second, we develop enhanced sampling guidance methods that
operate on off-the-shelf classifiers without requiring retraining. These
include tilted sampling with batch-level reweighting, adaptive
entropy-regularized sampling to preserve diversity, and a novel
f-divergence-based sampling strategy that strengthens class-consistent guidance
while maintaining mode coverage. Experiments on ImageNet 128x128 demonstrate
that our divergence-regularized guidance achieves an FID of 2.13 using a
ResNet-101 classifier, improving upon existing classifier-guided diffusion
methods while requiring no diffusion model retraining. The results show that
principled calibration and divergence-aware sampling provide practical and
effective improvements for classifier-guided diffusion.

</details>


### [42] [Point Cloud Segmentation of Integrated Circuits Package Substrates Surface Defects Using Causal Inference: Dataset Construction and Methodology](https://arxiv.org/abs/2511.05853)
*Bingyang Guo,Qiang Zuo,Ruiyun Yu*

Main category: cs.CV

TL;DR: 本文构建了一个高质量的3D点云数据集CPS3D-Seg用于陶瓷封装基板表面缺陷检测，并提出了基于因果推理的新型3D分割方法CINet，在性能上显著优于现有算法。


<details>
  <summary>Details</summary>
Motivation: 陶瓷封装基板(CPS)在集成电路封装中至关重要，但其复杂结构和微小缺陷检测面临挑战，且缺乏公开数据集，阻碍了CPS表面缺陷检测技术的发展。

Method: 1) 构建CPS3D-Seg数据集，包含1300个点云样本和精确的点级标注；2) 提出基于因果推理的CINet方法，通过结构细化(SR)和质量评估(QA)模块量化点云中的潜在混淆因素。

Result: CINet在mIoU和准确率指标上显著优于现有最先进的点云分割算法，证明了数据集和方法的有效性。

Conclusion: CPS3D-Seg数据集填补了3D工业缺陷检测领域的空白，CINet方法为复杂结构的微小缺陷检测提供了有效解决方案，推动了工业质量控制技术的发展。

Abstract: The effective segmentation of 3D data is crucial for a wide range of
industrial applications, especially for detecting subtle defects in the field
of integrated circuits (IC). Ceramic package substrates (CPS), as an important
electronic material, are essential in IC packaging owing to their superior
physical and chemical properties. However, the complex structure and minor
defects of CPS, along with the absence of a publically available dataset,
significantly hinder the development of CPS surface defect detection. In this
study, we construct a high-quality point cloud dataset for 3D segmentation of
surface defects in CPS, i.e., CPS3D-Seg, which has the best point resolution
and precision compared to existing 3D industrial datasets. CPS3D-Seg consists
of 1300 point cloud samples under 20 product categories, and each sample
provides accurate point-level annotations. Meanwhile, we conduct a
comprehensive benchmark based on SOTA point cloud segmentation algorithms to
validate the effectiveness of CPS3D-Seg. Additionally, we propose a novel 3D
segmentation method based on causal inference (CINet), which quantifies
potential confounders in point clouds through Structural Refine (SR) and
Quality Assessment (QA) Modules. Extensive experiments demonstrate that CINet
significantly outperforms existing algorithms in both mIoU and accuracy.

</details>


### [43] [CGCE: Classifier-Guided Concept Erasure in Generative Models](https://arxiv.org/abs/2511.05865)
*Viet Nguyen,Vishal M. Patel*

Main category: cs.CV

TL;DR: 提出了一种名为CGCE的高效即插即用框架，通过轻量级分类器在文本嵌入层面检测和优化包含不良概念的提示，实现无需修改模型权重的鲁棒概念擦除。


<details>
  <summary>Details</summary>
Motivation: 现有概念擦除方法存在两个主要问题：1）容易受到对抗攻击而重新生成被擦除内容；2）鲁棒擦除往往会降低模型对安全无关概念的生成质量，导致安全性和性能之间的困难权衡。

Method: CGCE使用在文本嵌入上操作的轻量级分类器，首先检测然后优化包含不良概念的提示。该方法具有高度可扩展性，可以通过聚合多个分类器的指导来实现多概念擦除。仅在推理时修改不安全的嵌入，防止有害内容生成同时保持模型在良性提示上的原始质量。

Result: 广泛实验表明，CGCE在各种红队攻击下实现了最先进的鲁棒性。该方法还保持了高生成效用，在安全性和性能之间实现了优越的平衡。成功应用于各种现代T2I和T2V模型，展示了其多功能性。

Conclusion: CGCE是一个实用有效的安全生成AI解决方案，为各种生成模型提供了无需修改权重的鲁棒概念擦除框架。

Abstract: Recent advancements in large-scale generative models have enabled the
creation of high-quality images and videos, but have also raised significant
safety concerns regarding the generation of unsafe content. To mitigate this,
concept erasure methods have been developed to remove undesirable concepts from
pre-trained models. However, existing methods remain vulnerable to adversarial
attacks that can regenerate the erased content. Moreover, achieving robust
erasure often degrades the model's generative quality for safe, unrelated
concepts, creating a difficult trade-off between safety and performance. To
address this challenge, we introduce Classifier-Guided Concept Erasure (CGCE),
an efficient plug-and-play framework that provides robust concept erasure for
diverse generative models without altering their original weights. CGCE uses a
lightweight classifier operating on text embeddings to first detect and then
refine prompts containing undesired concepts. This approach is highly scalable,
allowing for multi-concept erasure by aggregating guidance from several
classifiers. By modifying only unsafe embeddings at inference time, our method
prevents harmful content generation while preserving the model's original
quality on benign prompts. Extensive experiments show that CGCE achieves
state-of-the-art robustness against a wide range of red-teaming attacks. Our
approach also maintains high generative utility, demonstrating a superior
balance between safety and performance. We showcase the versatility of CGCE
through its successful application to various modern T2I and T2V models,
establishing it as a practical and effective solution for safe generative AI.

</details>


### [44] [Light-Field Dataset for Disparity Based Depth Estimation](https://arxiv.org/abs/2511.05866)
*Suresh Nehra,Aupendu Kar,Jayanta Mukhopadhyay,Prabir Kumar Biswas*

Main category: cs.CV

TL;DR: 本文介绍了一个公开可用的光场图像数据集，包含285张Lytro Illum相机拍摄的真实光场图像和13张合成光场图像，用于支持光场深度估计算法的开发与测试。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏适合光场深度估计算法开发的光场图像数据集，且现有数据集存在局限性，需要提供包含真实和合成光场数据的综合数据集。

Method: 使用Lytro Illum光场相机采集285张真实光场图像，同时生成13张合成光场图像。还创建了真实和合成的立体光场数据集，使用机械龙门系统和Blender软件。

Result: 构建了一个包含真实和合成光场图像的公开数据集，展示了焦距位置对3D点视差的影响，并指出了现有数据集的不足。

Conclusion: 该数据集为光场深度估计算法的研究提供了重要资源，有助于推动光场成像技术的发展和应用。

Abstract: A Light Field (LF) camera consists of an additional two-dimensional array of
micro-lenses placed between the main lens and sensor, compared to a
conventional camera. The sensor pixels under each micro-lens receive light from
a sub-aperture of the main lens. This enables the image sensor to capture both
spatial information and the angular resolution of a scene point. This
additional angular information is used to estimate the depth of a 3-D scene.
The continuum of virtual viewpoints in light field data enables efficient depth
estimation using Epipolar Line Images (EPIs) with robust occlusion handling.
However, the trade-off between angular information and spatial information is
very critical and depends on the focal position of the camera. To design,
develop, implement, and test novel disparity-based light field depth estimation
algorithms, the availability of suitable light field image datasets is
essential. In this paper, a publicly available light field image dataset is
introduced and thoroughly described. We have also demonstrated the effect of
focal position on the disparity of a 3-D point as well as the shortcomings of
the currently available light field dataset. The proposed dataset contains 285
light field images captured using a Lytro Illum LF camera and 13 synthetic LF
images. The proposed dataset also comprises a synthetic dataset with similar
disparity characteristics to those of a real light field camera. A real and
synthetic stereo light field dataset is also created by using a mechanical
gantry system and Blender. The dataset is available at
https://github.com/aupendu/light-field-dataset.

</details>


### [45] [MoEGCL: Mixture of Ego-Graphs Contrastive Representation Learning for Multi-View Clustering](https://arxiv.org/abs/2511.05876)
*Jian Zhu,Xin Zou,Jun Sun,Cheng Luo,Lei Liu,Lingfang Zeng,Ning Zhang,Bian Wu,Chang Tang,Lirong Dai*

Main category: cs.CV

TL;DR: 提出MoEGCL方法，通过样本级别的自我图融合和对比学习解决多视图聚类中图融合粒度粗糙的问题


<details>
  <summary>Details</summary>
Motivation: 现有多视图聚类方法在视图级别进行图结构融合，融合粒度较粗糙，限制了模型性能

Method: MoEGCL包含两个模块：MoEGF（混合自我图融合）使用Mixture-of-Experts网络在样本级别进行细粒度自我图融合；EGCL（自我图对比学习）通过对比学习增强表示相似性

Result: 在深度多视图聚类任务中达到了最先进的结果

Conclusion: MoEGCL通过细粒度的图融合策略有效提升了多视图聚类的性能

Abstract: In recent years, the advancement of Graph Neural Networks (GNNs) has
significantly propelled progress in Multi-View Clustering (MVC). However,
existing methods face the problem of coarse-grained graph fusion. Specifically,
current approaches typically generate a separate graph structure for each view
and then perform weighted fusion of graph structures at the view level, which
is a relatively rough strategy. To address this limitation, we present a novel
Mixture of Ego-Graphs Contrastive Representation Learning (MoEGCL). It mainly
consists of two modules. In particular, we propose an innovative Mixture of
Ego-Graphs Fusion (MoEGF), which constructs ego graphs and utilizes a
Mixture-of-Experts network to implement fine-grained fusion of ego graphs at
the sample level, rather than the conventional view-level fusion. Additionally,
we present the Ego Graph Contrastive Learning (EGCL) module to align the fused
representation with the view-specific representation. The EGCL module enhances
the representation similarity of samples from the same cluster, not merely from
the same sample, further boosting fine-grained graph representation. Extensive
experiments demonstrate that MoEGCL achieves state-of-the-art results in deep
multi-view clustering tasks. The source code is publicly available at
https://github.com/HackerHyper/MoEGCL.

</details>


### [46] [Towards Frequency-Adaptive Learning for SAR Despeckling](https://arxiv.org/abs/2511.05890)
*Ziqing Ma,Chang Yang,Zhichang Guo,Yao Li*

Main category: cs.CV

TL;DR: SAR-FAH是一种基于分治架构的频率自适应异构去斑模型，通过小波分解将图像分离为不同频率子带，针对不同频率特性设计专门子网络，有效解决传统单一网络处理SAR图像时导致的边缘模糊和纹理失真问题。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法使用单一统一网络处理整个SAR图像，未能考虑不同空间物理特性对应的独特斑点噪声统计特性，导致伪影、边缘模糊和纹理失真。

Method: 1. 使用小波分解将图像分离为不同频率子带；2. 针对低频部分采用神经常微分方程构建连续动态系统进行去噪；3. 针对高频部分采用增强型U-Net网络结合可变形卷积进行噪声抑制和特征增强。

Result: 在合成和真实SAR图像上的大量实验验证了该模型在噪声去除和结构保持方面的优越性能。

Conclusion: SAR-FAH模型通过频率自适应异构设计，有效改善了SAR图像去斑效果，在保持结构完整性的同时实现了更好的噪声抑制。

Abstract: Synthetic Aperture Radar (SAR) images are inherently corrupted by speckle
noise, limiting their utility in high-precision applications. While deep
learning methods have shown promise in SAR despeckling, most methods employ a
single unified network to process the entire image, failing to account for the
distinct speckle statistics associated with different spatial physical
characteristics. It often leads to artifacts, blurred edges, and texture
distortion. To address these issues, we propose SAR-FAH, a frequency-adaptive
heterogeneous despeckling model based on a divide-and-conquer architecture.
First, wavelet decomposition is used to separate the image into frequency
sub-bands carrying different intrinsic characteristics. Inspired by their
differing noise characteristics, we design specialized sub-networks for
different frequency components. The tailored approach leverages statistical
variations across frequencies, improving edge and texture preservation while
suppressing noise. Specifically, for the low-frequency part, denoising is
formulated as a continuous dynamic system via neural ordinary differential
equations, ensuring structural fidelity and sufficient smoothness that prevents
artifacts. For high-frequency sub-bands rich in edges and textures, we
introduce an enhanced U-Net with deformable convolutions for noise suppression
and enhanced features. Extensive experiments on synthetic and real SAR images
validate the superior performance of the proposed model in noise removal and
structural preservation.

</details>


### [47] [Hybrid second-order gradient histogram based global low-rank sparse regression for robust face recognition](https://arxiv.org/abs/2511.05893)
*Hongxia Li,Ying Ji,Yongxin Dong,Yuehua Feng*

Main category: cs.CV

TL;DR: 本文提出了一种基于混合二阶梯度直方图的全局低秩稀疏回归模型（H2H-GLRSR），用于解决人脸识别中复杂遮挡和光照变化的挑战。


<details>
  <summary>Details</summary>
Motivation: 针对人脸识别中复杂遮挡和光照变化带来的挑战，需要更有效的特征描述和回归模型来提升识别性能。

Method: 首先设计了一种新的混合二阶梯度直方图（H2H）特征描述符来表征面部图像的局部结构特征，然后将其与稀疏正则化核范数矩阵回归（SR_NMR）结合，并在残差矩阵上施加全局低秩约束以捕捉结构化噪声的全局相关性。

Result: 实验结果表明，该方法在遮挡、光照变化和非约束环境等挑战性场景下显著优于现有的基于回归的分类方法。

Conclusion: H2H-GLRSR模型通过结合新型特征描述符和全局低秩约束，有效提升了人脸识别在复杂条件下的性能。

Abstract: Low-rank sparse regression models have been widely applied in the field of
face recognition. To further address the challenges caused by complex
occlusions and illumination variations, this paper proposes a Hybrid
Second-Order Gradient Histogram based Global Low-Rank Sparse Regression
(H2H-GLRSR) model. Specifically, a novel feature descriptor called the Hybrid
Second-Order Gradient Histogram (H2H) is first designed to more effectively
characterize the local structural features of facial images. Then, this
descriptor is integrated with the Sparse Regularized Nuclear Norm based Matrix
Regression (SR$\_$NMR). Moreover, a global low-rank constraint is imposed on
the residual matrix, enabling the model to better capture the global
correlations inherent in structured noise. Experimental results demonstrate
that the proposed method significantly outperforms existing regression-based
classification approaches under challenging scenarios involving occlusions,
illumination changes, and unconstrained environments.

</details>


### [48] [Open-World 3D Scene Graph Generation for Retrieval-Augmented Reasoning](https://arxiv.org/abs/2511.05894)
*Fei Yu,Quan Deng,Shengeng Tang,Yuehua Li,Lechao Cheng*

Main category: cs.CV

TL;DR: 提出了一种用于开放世界3D场景图生成的统一框架，结合检索增强推理，实现可泛化的交互式3D场景理解


<details>
  <summary>Details</summary>
Motivation: 解决开放世界3D场景理解中的封闭词汇监督和静态标注限制问题

Method: 整合视觉语言模型与检索推理，包含动态场景图生成模块和检索增强推理管道

Result: 在3DSSG和Replica基准测试的四个任务上表现出稳健泛化能力和优越性能

Conclusion: 结合开放词汇感知与检索推理对可扩展3D场景理解具有有效性

Abstract: Understanding 3D scenes in open-world settings poses fundamental challenges
for vision and robotics, particularly due to the limitations of
closed-vocabulary supervision and static annotations. To address this, we
propose a unified framework for Open-World 3D Scene Graph Generation with
Retrieval-Augmented Reasoning, which enables generalizable and interactive 3D
scene understanding. Our method integrates Vision-Language Models (VLMs) with
retrieval-based reasoning to support multimodal exploration and language-guided
interaction. The framework comprises two key components: (1) a dynamic scene
graph generation module that detects objects and infers semantic relationships
without fixed label sets, and (2) a retrieval-augmented reasoning pipeline that
encodes scene graphs into a vector database to support text/image-conditioned
queries. We evaluate our method on 3DSSG and Replica benchmarks across four
tasks-scene question answering, visual grounding, instance retrieval, and task
planning-demonstrating robust generalization and superior performance in
diverse environments. Our results highlight the effectiveness of combining
open-vocabulary perception with retrieval-based reasoning for scalable 3D scene
understanding.

</details>


### [49] [GABFusion: Rethinking Feature Fusion for Low-Bit Quantization of Multi-Task Networks](https://arxiv.org/abs/2511.05898)
*Zhaoyang Wang,Dong Wang*

Main category: cs.CV

TL;DR: 提出GABFusion和ADA方法，解决多任务架构中量化感知训练的性能下降问题，通过动态平衡梯度幅度和特征融合提升量化模型性能。


<details>
  <summary>Details</summary>
Motivation: 多任务架构的量化感知训练由于任务特定特征差异和梯度冲突导致性能显著下降，需要新的方法来平衡这些冲突。

Method: Gradient-Aware Balanced Feature Fusion (GABFusion) 动态平衡梯度幅度和任务特定特征融合，Attention Distribution Alignment (ADA) 作为特征级蒸馏策略。

Result: 在PASCAL VOC和COCO数据集上分别实现平均mAP提升3.3%和1.6%，4位量化YOLOv5与全精度模型差距缩小至1.7%。

Conclusion: 该方法具有模块化、易集成、兼容现有QAT技术的优势，能有效提升量化模型性能而不需要修改原始网络架构。

Abstract: Despite the effectiveness of quantization-aware training (QAT) in compressing
deep neural networks, its performance on multi-task architectures often
degrades significantly due to task-specific feature discrepancies and gradient
conflicts. To address these challenges, we propose Gradient-Aware Balanced
Feature Fusion (GABFusion), which dynamically balances gradient magnitudes and
fuses task-specific features in a quantization-friendly manner. We further
introduce Attention Distribution Alignment (ADA), a feature-level distillation
strategy tailored for quantized models. Our method demonstrates strong
generalization across network architectures and QAT algorithms, with
theoretical guarantees on gradient bias reduction. Extensive experiments
demonstrate that our strategy consistently enhances a variety of QAT methods
across different network architectures and bit-widths. On PASCAL VOC and COCO
datasets, the proposed approach achieves average mAP improvements of
approximately 3.3% and 1.6%, respectively. When applied to YOLOv5 under 4-bit
quantization, our method narrows the accuracy gap with the full-precision model
to only 1.7% on VOC, showcasing its effectiveness in preserving performance
under low-bit constraints. Notably, the proposed framework is modular, easy to
integrate, and compatible with any existing QAT technique-enhancing the
performance of quantized models without requiring modifications to the original
network architecture.

</details>


### [50] [Causal Tracing of Object Representations in Large Vision Language Models: Mechanistic Interpretability and Hallucination Mitigation](https://arxiv.org/abs/2511.05923)
*Qiming Li,Zekai Ye,Xiaocheng Feng,Weihong Zhong,Weitao Ma,Xiachong Feng*

Main category: cs.CV

TL;DR: 该论文提出了细粒度跨模态因果追踪框架，系统分析大视觉语言模型中视觉目标感知的因果机制，并基于此开发了无需训练的中介表示注入技术来增强视觉感知和减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 现有的大视觉语言模型机理可解释性研究不够全面，缺乏对视觉和文本标记、模型组件及全层级的系统分析，限制了改进模型输出忠实度和下游任务开发的洞察力。

Method: 提出Fine-grained Cross-modal Causal Tracing框架，对全范围的视觉和文本标记、多头自注意力机制、前馈网络和隐藏状态等核心组件在所有解码器层进行细粒度分析。基于分析结果开发了Intermediate Representation Injection技术，通过在特定组件和层级精确干预跨模态表示来增强视觉信息流。

Result: 首次证明中间层的最后标记的多头自注意力在聚合跨模态信息中起关键作用，前馈网络呈现三阶段层次化进展用于存储和传输视觉目标表示。在五个广泛使用的基准测试和大视觉语言模型上取得一致改进，实现了最先进性能，同时保持推理速度和其他基础性能。

Conclusion: FCCT框架为理解大视觉语言模型的内部工作机制提供了系统性方法，IRI技术展示了基于机理分析开发高效干预策略的可行性，为提升模型感知能力和减少幻觉提供了新途径。

Abstract: Despite the remarkable advancements of Large Vision-Language Models (LVLMs),
the mechanistic interpretability remains underexplored. Existing analyses are
insufficiently comprehensive and lack examination covering visual and textual
tokens, model components, and the full range of layers. This limitation
restricts actionable insights to improve the faithfulness of model output and
the development of downstream tasks, such as hallucination mitigation. To
address this limitation, we introduce Fine-grained Cross-modal Causal Tracing
(FCCT) framework, which systematically quantifies the causal effects on visual
object perception. FCCT conducts fine-grained analysis covering the full range
of visual and textual tokens, three core model components including multi-head
self-attention (MHSA), feed-forward networks (FFNs), and hidden states, across
all decoder layers. Our analysis is the first to demonstrate that MHSAs of the
last token in middle layers play a critical role in aggregating cross-modal
information, while FFNs exhibit a three-stage hierarchical progression for the
storage and transfer of visual object representations. Building on these
insights, we propose Intermediate Representation Injection (IRI), a
training-free inference-time technique that reinforces visual object
information flow by precisely intervening on cross-modal representations at
specific components and layers, thereby enhancing perception and mitigating
hallucination. Consistent improvements across five widely used benchmarks and
LVLMs demonstrate IRI achieves state-of-the-art performance, while preserving
inference speed and other foundational performance.

</details>


### [51] [CoMA: Complementary Masking and Hierarchical Dynamic Multi-Window Self-Attention in a Unified Pre-training Framework](https://arxiv.org/abs/2511.05929)
*Jiaxuan Li,Qing Xu,Xiangjian He,Ziyu Liu,Chang Xing,Zhen Chen,Daokun Zhang,Rong Qu,Chang Wen Chen*

Main category: cs.CV

TL;DR: CoMA采用互补掩码策略确保所有像素均匀采样，结合DyViT的动态多窗口自注意力机制，在仅需12%预训练周期的情况下达到与MAE相当的下游任务性能，并减少10%每轮预训练时间。


<details>
  <summary>Details</summary>
Motivation: 解决MAE随机掩码需要更多预训练周期的问题，以及ViT在MAE中固定空间分辨率导致的参数使用效率低下问题。

Method: 提出互补掩码自编码器(CoMA)确保均匀像素采样，结合分层视觉Transformer(DyViT)使用动态多窗口自注意力(DM-MSA)机制。

Result: 在ImageNet-1K上预训练，仅需12%的预训练周期即可匹配MAE性能，每轮预训练时间减少10%，参数和FLOPs显著降低。

Conclusion: CoMA+DyViT组合实现了更高效的预训练和更好的特征学习能力，在保持性能的同时大幅提升训练效率。

Abstract: Masked Autoencoders (MAE) achieve self-supervised learning of image
representations by randomly removing a portion of visual tokens and
reconstructing the original image as a pretext task, thereby significantly
enhancing pretraining efficiency and yielding excellent adaptability across
downstream tasks. However, MAE and other MAE-style paradigms that adopt random
masking generally require more pre-training epochs to maintain adaptability.
Meanwhile, ViT in MAE suffers from inefficient parameter use due to fixed
spatial resolution across layers. To overcome these limitations, we propose the
Complementary Masked Autoencoders (CoMA), which employ a complementary masking
strategy to ensure uniform sampling across all pixels, thereby improving
effective learning of all features and enhancing the model's adaptability.
Furthermore, we introduce DyViT, a hierarchical vision transformer that employs
a Dynamic Multi-Window Self-Attention (DM-MSA), significantly reducing the
parameters and FLOPs while improving fine-grained feature learning. Pre-trained
on ImageNet-1K with CoMA, DyViT matches the downstream performance of MAE using
only 12% of the pre-training epochs, demonstrating more effective learning. It
also attains a 10% reduction in pre-training time per epoch, further
underscoring its superior pre-training efficiency.

</details>


### [52] [AD-DAE: Unsupervised Modeling of Longitudinal Alzheimer's Disease Progression with Diffusion Auto-Encoder](https://arxiv.org/abs/2511.05934)
*Ayantika Das,Arunima Sarkar,Keerthi Ram,Mohanasankar Sivaprakasam*

Main category: cs.CV

TL;DR: 提出了一种可条件化的扩散自编码器框架，用于在无监督情况下从基线图像生成疾病进展图像，通过限制潜在空间中的偏移来控制生成过程。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型在捕捉疾病进展时对分布学习施加约束，导致潜在空间的可控性有限，需要特定受试者的纵向图像监督。

Method: 利用图像扩散自编码器的显式编码机制形成紧凑的潜在空间，通过限制偏移到子空间来分离进展相关因素和身份保持组件，无需纵向监督。

Result: 在阿尔茨海默病数据集上通过图像质量指标、体积进展分析和下游分类验证了生成效果，证明了该方法在疾病进展建模和纵向图像生成方面的有效性。

Conclusion: 该方法能够实现无监督的疾病进展图像生成，为阿尔茨海默病等疾病的纵向建模提供了有效工具。

Abstract: Generative modeling frameworks have emerged as an effective approach to
capture high-dimensional image distributions from large datasets without
requiring domain-specific knowledge, a capability essential for longitudinal
disease progression modeling. Recent generative modeling approaches have
attempted to capture progression by mapping images into a latent
representational space and then controlling and guiding the representations to
generate follow-up images from a baseline image. However, existing approaches
impose constraints on distribution learning, leading to latent spaces with
limited controllability to generate follow-up images without explicit
supervision from subject-specific longitudinal images. In order to enable
controlled movements in the latent representational space and generate
progression images from a baseline image in an unsupervised manner, we
introduce a conditionable Diffusion Auto-encoder framework. The explicit
encoding mechanism of image-diffusion auto-encoders forms a compact latent
space capturing high-level semantics, providing means to disentangle
information relevant for progression. Our approach leverages this latent space
to condition and apply controlled shifts to baseline representations for
generating follow-up. Controllability is induced by restricting these shifts to
a subspace, thereby isolating progression-related factors from subject
identity-preserving components. The shifts are implicitly guided by correlating
with progression attributes, without requiring subject-specific longitudinal
supervision. We validate the generations through image quality metrics,
volumetric progression analysis, and downstream classification in Alzheimer's
disease datasets from two different sources and disease categories. This
demonstrates the effectiveness of our approach for Alzheimer's progression
modeling and longitudinal image generation.

</details>


### [53] [Interaction-Centric Knowledge Infusion and Transfer for Open-Vocabulary Scene Graph Generation](https://arxiv.org/abs/2511.05935)
*Lin Li,Chuhan Zhang,Dong Zhang,Chong Sun,Chen Li,Long Chen*

Main category: cs.CV

TL;DR: 本文提出了一种名为ACC的交互中心端到端开放词汇场景图生成框架，通过双向交互提示和交互引导的知识蒸馏来解决现有方法在区分交互和非交互对象方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇场景图生成方法缺乏显式的交互建模，难以区分同一对象类别的交互和非交互实例，导致知识注入阶段产生噪声伪监督，知识迁移阶段出现模糊查询匹配问题。

Method: ACC框架采用交互驱动范式：1）使用双向交互提示进行交互中心知识注入，增强模型交互知识；2）采用交互引导查询选择和交互一致知识蒸馏进行交互中心知识迁移。

Result: 在三个基准测试上的广泛实验结果表明，ACC实现了最先进的性能。

Conclusion: ACC展示了交互中心范式在现实世界应用中的潜力，有效解决了开放词汇场景图生成中的关键问题。

Abstract: Open-vocabulary scene graph generation (OVSGG) extends traditional SGG by
recognizing novel objects and relationships beyond predefined categories,
leveraging the knowledge from pre-trained large-scale models. Existing OVSGG
methods always adopt a two-stage pipeline: 1) \textit{Infusing knowledge} into
large-scale models via pre-training on large datasets; 2) \textit{Transferring
knowledge} from pre-trained models with fully annotated scene graphs during
supervised fine-tuning. However, due to a lack of explicit interaction
modeling, these methods struggle to distinguish between interacting and
non-interacting instances of the same object category. This limitation induces
critical issues in both stages of OVSGG: it generates noisy pseudo-supervision
from mismatched objects during knowledge infusion, and causes ambiguous query
matching during knowledge transfer. To this end, in this paper, we propose an
inter\textbf{AC}tion-\textbf{C}entric end-to-end OVSGG framework (\textbf{ACC})
in an interaction-driven paradigm to minimize these mismatches. For
\textit{interaction-centric knowledge infusion}, ACC employs a bidirectional
interaction prompt for robust pseudo-supervision generation to enhance the
model's interaction knowledge. For \textit{interaction-centric knowledge
transfer}, ACC first adopts interaction-guided query selection that prioritizes
pairing interacting objects to reduce interference from non-interacting ones.
Then, it integrates interaction-consistent knowledge distillation to bolster
robustness by pushing relational foreground away from the background while
retaining general knowledge. Extensive experimental results on three benchmarks
show that ACC achieves state-of-the-art performance, demonstrating the
potential of interaction-centric paradigms for real-world applications.

</details>


### [54] [Global Multiple Extraction Network for Low-Resolution Facial Expression Recognition](https://arxiv.org/abs/2511.05938)
*Jingyi Shi*

Main category: cs.CV

TL;DR: 提出了GME-Net网络用于低分辨率面部表情识别，通过混合注意力局部特征提取和多尺度全局特征提取模块，解决了低分辨率图像细节缺失和全局建模不足的问题，在多个数据集上取得优越性能。


<details>
  <summary>Details</summary>
Motivation: 当前面部表情识别算法在高分辨率图像上表现良好，但在低分辨率图像上性能下降，主要原因是低分辨率图像缺乏细节信息，且现有方法全局建模能力不足。

Method: 提出了GME-Net网络，包含：1）基于混合注意力的局部特征提取模块，通过注意力相似性知识蒸馏从高分辨率网络学习图像细节；2）多尺度全局特征提取模块，采用准对称结构缓解局部噪声影响并捕获全局特征。

Result: 在多个广泛使用的数据集上的实验表明，GME-Net能够更好地识别低分辨率面部表情，性能优于现有解决方案。

Conclusion: GME-Net能够有效提取表情相关的判别性特征，为低分辨率面部表情识别提供了有效的解决方案。

Abstract: Facial expression recognition, as a vital computer vision task, is garnering
significant attention and undergoing extensive research. Although facial
expression recognition algorithms demonstrate impressive performance on
high-resolution images, their effectiveness tends to degrade when confronted
with low-resolution images. We find it is because: 1) low-resolution images
lack detail information; 2) current methods complete weak global modeling,
which make it difficult to extract discriminative features. To alleviate the
above issues, we proposed a novel global multiple extraction network (GME-Net)
for low-resolution facial expression recognition, which incorporates 1) a
hybrid attention-based local feature extraction module with attention
similarity knowledge distillation to learn image details from high-resolution
network; 2) a multi-scale global feature extraction module with quasi-symmetric
structure to mitigate the influence of local image noise and facilitate
capturing global image features. As a result, our GME-Net is capable of
extracting expression-related discriminative features. Extensive experiments
conducted on several widely-used datasets demonstrate that the proposed GME-Net
can better recognize low-resolution facial expression and obtain superior
performance than existing solutions.

</details>


### [55] [Polymap: generating high definition map based on rasterized polygons](https://arxiv.org/abs/2511.05944)
*Shiyu Gao,Hao Jiang*

Main category: cs.CV

TL;DR: 本文提出了一种基于实例分割的高清地图感知方法，将道路元素重新解释为栅格化多边形，通过端到端的Transformer分割和Potrace后处理来生成矢量地图元素，旨在提高检测方法的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于检测的高清地图构建方法（如Maptr系列）虽然能够实时构建，但缺乏鲁棒的泛化能力，这限制了它们在自动标注系统中的应用。因此需要改进泛化性能。

Method: 将道路元素重新解释为栅格化多边形，设计基于实例分割的简洁框架：首先使用基于分割的Transformer端到端输出实例掩码，然后通过Potrace后处理模块最终生成矢量地图元素。

Result: 在Nuscene数据集上的定量结果验证了该方法的有效性和泛化能力。

Conclusion: 该方法通过实例分割路径显著提高了高清地图感知的泛化性能，为自动驾驶系统的环境感知提供了更可靠的解决方案。

Abstract: The perception of high-definition maps is an integral component of
environmental perception in autonomous driving systems. Existing research have
often focused on online construction of high-definition maps. For instance, the
Maptr[9] series employ a detection-based method to output vectorized map
instances parallelly in an end-to-end manner. However, despite their capability
for real-time construction, detection-based methods are observed to lack robust
generalizability[19], which hampers their applicability in auto-labeling
systems. Therefore, aiming to improve the generalizability, we reinterpret road
elements as rasterized polygons and design a concise framework based on
instance segmentation. Initially, a segmentation-based transformer is employed
to deliver instance masks in an end-to-end manner; succeeding this step, a
Potrace-based[17] post-processing module is used to ultimately yield vectorized
map elements. Quantitative results attained on the Nuscene[1] dataset
substantiate the effectiveness and generaliz-ability of our method.

</details>


### [56] [Runtime Safety Monitoring of Deep Neural Networks for Perception: A Survey](https://arxiv.org/abs/2511.05982)
*Albert Schotschneider,Svetlana Pavlitska,J. Marius Zöllner*

Main category: cs.CV

TL;DR: 这是一篇关于深度神经网络运行时安全监控方法的综述论文，主要介绍了在不修改DNN本身的情况下，通过监控输入、内部表示和输出来检测各种安全问题的技术。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在安全关键应用中广泛使用，但容易受到泛化错误、分布外输入和对抗攻击等安全问题的影响，可能导致危险故障。需要开发有效的运行时监控方法来确保系统安全。

Method: 将现有方法分为三类：监控输入、监控内部表示和监控输出。对每个类别的最新技术进行分析，识别优缺点，并将方法与它们解决的安全问题进行映射。

Result: 提供了运行时安全监控方法的全面概述，系统性地分类和分析了现有技术，识别了不同方法在处理各种安全问题时的适用性和局限性。

Conclusion: 论文总结了当前运行时安全监控技术的发展现状，指出了开放挑战和未来研究方向，为DNN在安全关键应用中的安全部署提供了重要参考。

Abstract: Deep neural networks (DNNs) are widely used in perception systems for
safety-critical applications, such as autonomous driving and robotics. However,
DNNs remain vulnerable to various safety concerns, including generalization
errors, out-of-distribution (OOD) inputs, and adversarial attacks, which can
lead to hazardous failures. This survey provides a comprehensive overview of
runtime safety monitoring approaches, which operate in parallel to DNNs during
inference to detect these safety concerns without modifying the DNN itself. We
categorize existing methods into three main groups: Monitoring inputs, internal
representations, and outputs. We analyze the state-of-the-art for each
category, identify strengths and limitations, and map methods to the safety
concerns they address. In addition, we highlight open challenges and future
research directions.

</details>


### [57] [Reperio-rPPG: Relational Temporal Graph Neural Networks for Periodicity Learning in Remote Physiological Measurement](https://arxiv.org/abs/2511.05946)
*Ba-Thinh Nguyen,Thach-Ha Ngoc Pham,Hoang-Long Duc Nguyen,Thi-Duyen Ngo,Thanh-Ha Le*

Main category: cs.CV

TL;DR: Reperio-rPPG是一个新颖的远程光电容积描记法框架，通过整合关系卷积网络和图变换器来有效捕捉生理信号的周期性结构，并在多种真实场景下表现出卓越的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的远程生理信号测量方法往往忽视或不足够建模内在的周期性特征，这限制了它们在真实世界条件下捕捉细粒度时间动态的能力。

Method: 提出Reperio-rPPG框架，策略性地整合关系卷积网络和图变换器来捕捉生理信号的周期性结构，并引入定制的CutMix增强技术来提高模型的泛化能力。

Result: 在PURE、UBFC-rPPG和MMPD三个基准数据集上的广泛实验表明，Reperio-rPPG不仅达到了最先进的性能，而且在各种运动（如静止、旋转、说话、行走）和光照条件（如自然光、低LED、高LED）下表现出显著的鲁棒性。

Conclusion: Reperio-rPPG框架有效解决了现有方法对生理信号周期性建模不足的问题，在多个基准数据集上实现了优异的性能，为远程生理监测提供了更可靠的解决方案。

Abstract: Remote photoplethysmography (rPPG) is an emerging contactless physiological
sensing technique that leverages subtle color variations in facial videos to
estimate vital signs such as heart rate and respiratory rate. This non-invasive
method has gained traction across diverse domains, including telemedicine,
affective computing, driver fatigue detection, and health monitoring, owing to
its scalability and convenience. Despite significant progress in remote
physiological signal measurement, a crucial characteristic - the intrinsic
periodicity - has often been underexplored or insufficiently modeled in
previous approaches, limiting their ability to capture fine-grained temporal
dynamics under real-world conditions. To bridge this gap, we propose
Reperio-rPPG, a novel framework that strategically integrates Relational
Convolutional Networks with a Graph Transformer to effectively capture the
periodic structure inherent in physiological signals. Additionally, recognizing
the limited diversity of existing rPPG datasets, we further introduce a
tailored CutMix augmentation to enhance the model's generalizability. Extensive
experiments conducted on three widely used benchmark datasets - PURE,
UBFC-rPPG, and MMPD - demonstrate that Reperio-rPPG not only achieves
state-of-the-art performance but also exhibits remarkable robustness under
various motion (e.g., stationary, rotation, talking, walking) and illumination
conditions (e.g., nature, low LED, high LED). The code is publicly available at
https://github.com/deconasser/Reperio-rPPG.

</details>


### [58] [U(PM)$^2$:Unsupervised polygon matching with pre-trained models for challenging stereo images](https://arxiv.org/abs/2511.05949)
*Chang Li,Xingtao Peng*

Main category: cs.CV

TL;DR: 提出U(PM)^2：一种无需训练的低成本无监督多边形匹配方法，结合预训练模型和手工特征，解决了立体图像中多边形匹配的挑战。


<details>
  <summary>Details</summary>
Motivation: 立体图像匹配是计算机视觉的基础任务，但多边形匹配领域几乎未被探索，面临视差不连续性、尺度变化、训练需求和泛化能力等挑战。

Method: 1) 使用SAM预训练模型获取掩码；2) 将掩码转换为多边形和图形结构；3) 基于LoFTR预训练模型的双向金字塔策略进行全局匹配；4) 使用局部联合几何和多特征匹配策略结合匈牙利算法进行局部匹配。

Result: 在ScanNet和SceneFlow数据集上使用新评估指标，达到了最先进的精度，具有竞争性的速度、满意的泛化性能和低成本，无需任何训练。

Conclusion: U(PM)^2方法有效解决了多边形匹配的关键挑战，在多个数据集上表现出色，为立体图像多边形匹配提供了可行的解决方案。

Abstract: Stereo image matching is a fundamental task in computer vision,
photogrammetry and remote sensing, but there is an almost unexplored field,
i.e., polygon matching, which faces the following challenges: disparity
discontinuity, scale variation, training requirement, and generalization. To
address the above-mentioned issues, this paper proposes a novel U(PM)$^2$:
low-cost unsupervised polygon matching with pre-trained models by uniting
automatically learned and handcrafted features, of which pipeline is as
follows: firstly, the detector leverages the pre-trained segment anything model
to obtain masks; then, the vectorizer converts the masks to polygons and
graphic structure; secondly, the global matcher addresses challenges from
global viewpoint changes and scale variation based on bidirectional-pyramid
strategy with pre-trained LoFTR; finally, the local matcher further overcomes
local disparity discontinuity and topology inconsistency of polygon matching by
local-joint geometry and multi-feature matching strategy with Hungarian
algorithm. We benchmark our U(PM)$^2$ on the ScanNet and SceneFlow datasets
using our proposed new metric, which achieved state-of-the-art accuracy at a
competitive speed and satisfactory generalization performance at low cost
without any training requirement.

</details>


### [59] [On Accurate and Robust Estimation of 3D and 2D Circular Center: Method and Application to Camera-Lidar Calibration](https://arxiv.org/abs/2511.06611)
*Jiajun Jiang,Xiao Hu,Wancheng Liu,Wei Jiang*

Main category: cs.CV

TL;DR: 提出了一种基于几何原理的LiDAR-相机外参标定框架，通过鲁棒的3D圆中心估计和2D投影中心恢复方法，显著提高了圆形目标的3D-2D对应关系精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法在LiDAR-相机外参标定中难以实现准确的3D-2D圆形中心对应，主要由于解耦的3D拟合和错误的2D椭圆中心估计问题。

Method: 1）基于共形几何代数和RANSAC的鲁棒3D圆中心估计器；2）通过弦长方差最小化方法恢复真实2D投影中心，解决双最小值模糊问题。

Result: 在合成和真实数据集上的评估表明，该框架显著优于现有最先进方法，减少了外参估计误差，并在不同传感器和目标类型上实现鲁棒标定。

Conclusion: 该几何原理框架为LiDAR-相机标定提供了更准确可靠的解决方案，支持包括自然圆形物体在内的多样化标定场景，代码将公开以确保可复现性。

Abstract: Circular targets are widely used in LiDAR-camera extrinsic calibration due to
their geometric consistency and ease of detection. However, achieving accurate
3D-2D circular center correspondence remains challenging. Existing methods
often fail due to decoupled 3D fitting and erroneous 2D ellipse-center
estimation. To address this, we propose a geometrically principled framework
featuring two innovations: (i) a robust 3D circle center estimator based on
conformal geometric algebra and RANSAC; and (ii) a chord-length variance
minimization method to recover the true 2D projected center, resolving its
dual-minima ambi- guity via homography validation or a quasi-RANSAC fallback.
Evaluated on synthetic and real-world datasets, our framework significantly
outperforms state-of-the-art approaches. It reduces extrinsic estimation error
and enables robust calibration across diverse sensors and target types,
including natural circular objects. Our code will be publicly released for
reproducibility.

</details>


### [60] [CSGaze: Context-aware Social Gaze Prediction](https://arxiv.org/abs/2511.05955)
*Surbhi Madan,Shreya Ghosh,Ramanathan Subramanian,Abhinav Dhall,Tom Gedeon*

Main category: cs.CV

TL;DR: CSGaze是一个基于上下文感知的多模态方法，利用面部和场景信息来预测对话互动中的社交注视模式，通过注意力机制增强对主要说话者的建模，在多个数据集上达到竞争性性能。


<details>
  <summary>Details</summary>
Motivation: 人的注视行为能够反映其注意力焦点、社交参与度和自信程度，研究如何结合上下文线索、视觉场景和面部信息来预测和解释对话中的社交注视模式。

Method: 提出CSGaze模型，整合面部信息和场景信息作为互补输入，采用以主要说话者为中心的细粒度注意力机制来更好地建模社交注视动态。

Result: 在GP-Static、UCO-LAEO和AVA-LAEO数据集上达到与最先进方法竞争的性能，生成的注意力分数提供了模型决策过程的解释性，并在开放数据集上展示了良好的泛化能力。

Conclusion: 上下文线索在改善社交注视预测中发挥重要作用，CSGaze模型具有强大的泛化能力和解释性，能够适应多样化的场景。

Abstract: A person's gaze offers valuable insights into their focus of attention, level
of social engagement, and confidence. In this work, we investigate how
contextual cues combined with visual scene and facial information can be
effectively utilized to predict and interpret social gaze patterns during
conversational interactions. We introduce CSGaze, a context aware multimodal
approach that leverages facial, scene information as complementary inputs to
enhance social gaze pattern prediction from multi-person images. The model also
incorporates a fine-grained attention mechanism centered on the principal
speaker, which helps in better modeling social gaze dynamics. Experimental
results show that CSGaze performs competitively with state-of-the-art methods
on GP-Static, UCO-LAEO and AVA-LAEO. Our findings highlight the role of
contextual cues in improving social gaze prediction. Additionally, we provide
initial explainability through generated attention scores, offering insights
into the model's decision-making process. We also demonstrate our model's
generalizability by testing our model on open set datasets that demonstrating
its robustness across diverse scenarios.

</details>


### [61] [PanoNav: Mapless Zero-Shot Object Navigation with Panoramic Scene Parsing and Dynamic Memory](https://arxiv.org/abs/2511.06840)
*Qunchao Jin,Yilin Wu,Changhao Chen*

Main category: cs.CV

TL;DR: PanoNav是一个仅使用RGB输入的无地图零样本目标导航框架，通过全景场景解析和记忆引导决策机制，在未见环境中实现高效导航。


<details>
  <summary>Details</summary>
Motivation: 解决现有零样本目标导航方法依赖深度传感器或预建地图的问题，以及无地图方法因缺乏历史上下文而导致的短视决策和局部死锁问题。

Method: 提出PanoNav框架，包含全景场景解析模块（利用MLLMs从全景RGB输入中解析空间信息）和记忆引导决策机制（通过动态有界内存队列整合探索历史）。

Result: 在公共导航基准测试中，PanoNav在SR（成功率）和SPL（路径长度加权成功率）指标上显著优于代表性基线方法。

Conclusion: PanoNav证明了仅使用RGB输入的无地图导航方法的有效性，通过全景场景解析和记忆机制解决了空间推理和局部死锁问题。

Abstract: Zero-shot object navigation (ZSON) in unseen environments remains a
challenging problem for household robots, requiring strong perceptual
understanding and decision-making capabilities. While recent methods leverage
metric maps and Large Language Models (LLMs), they often depend on depth
sensors or prebuilt maps, limiting the spatial reasoning ability of Multimodal
Large Language Models (MLLMs). Mapless ZSON approaches have emerged to address
this, but they typically make short-sighted decisions, leading to local
deadlocks due to a lack of historical context. We propose PanoNav, a fully
RGB-only, mapless ZSON framework that integrates a Panoramic Scene Parsing
module to unlock the spatial parsing potential of MLLMs from panoramic RGB
inputs, and a Memory-guided Decision-Making mechanism enhanced by a Dynamic
Bounded Memory Queue to incorporate exploration history and avoid local
deadlocks. Experiments on the public navigation benchmark show that PanoNav
significantly outperforms representative baselines in both SR and SPL metrics.

</details>


### [62] [Adaptive Agent Selection and Interaction Network for Image-to-point cloud Registration](https://arxiv.org/abs/2511.05965)
*Zhixin Cheng,Xiaotian Yin,Jiacheng Deng,Bohao Liao,Yujia Chen,Xu Zhou,Baoqun Yin,Tianzhu Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的跨模态配准框架，通过迭代代理选择和可靠代理交互模块，解决了噪声干扰和跨模态特征选择困难的问题，在RGB-D Scenes v2和7-Scenes基准测试中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的无检测图像到点云配准方法在挑战性条件下容易受噪声干扰，导致相似性计算错误和错误对应关系，且缺乏有效的跨模态信息选择机制，限制了配准的鲁棒性和准确性。

Method: 提出包含两个关键模块的框架：1）迭代代理选择模块：通过相位图增强结构特征感知，并利用强化学习原理选择可靠代理；2）可靠代理交互模块：利用选定代理指导跨模态交互，减少误匹配。

Result: 在RGB-D Scenes v2和7-Scenes基准测试上的大量实验表明，该方法始终达到最先进的性能。

Conclusion: 所提出的方法通过有效的代理选择和交互机制，显著提高了跨模态配准的鲁棒性和准确性，在挑战性条件下表现出色。

Abstract: Typical detection-free methods for image-to-point cloud registration leverage
transformer-based architectures to aggregate cross-modal features and establish
correspondences. However, they often struggle under challenging conditions,
where noise disrupts similarity computation and leads to incorrect
correspondences. Moreover, without dedicated designs, it remains difficult to
effectively select informative and correlated representations across
modalities, thereby limiting the robustness and accuracy of registration. To
address these challenges, we propose a novel cross-modal registration framework
composed of two key modules: the Iterative Agents Selection (IAS) module and
the Reliable Agents Interaction (RAI) module. IAS enhances structural feature
awareness with phase maps and employs reinforcement learning principles to
efficiently select reliable agents. RAI then leverages these selected agents to
guide cross-modal interactions, effectively reducing mismatches and improving
overall robustness. Extensive experiments on the RGB-D Scenes v2 and 7-Scenes
benchmarks demonstrate that our method consistently achieves state-of-the-art
performance.

</details>


### [63] [Aerial Image Stitching Using IMU Data from a UAV](https://arxiv.org/abs/2511.06841)
*Selim Ahmet Iz,Mustafa Unel*

Main category: cs.CV

TL;DR: 本文提出了一种结合IMU数据和计算机视觉技术的无人机图像拼接新方法，通过估计位移和旋转、校正透视畸变、计算单应性矩阵，在挑战性场景下优于传统特征匹配方法。


<details>
  <summary>Details</summary>
Motivation: 传统基于特征匹配的图像拼接算法在特征检测和匹配中容易出错，特别是在无人机拍摄存在大位移、旋转和相机姿态变化时，需要更鲁棒的方法来提高拼接准确性和可靠性。

Method: 结合IMU数据和计算机视觉技术，通过估计无人机在连续图像间的位移和旋转，校正透视畸变，计算单应性矩阵，最后使用标准图像拼接算法进行对齐和融合。

Result: 实验证明该方法在准确性和可靠性方面优于现有的基于特征的图像拼接算法，特别是在大位移、旋转和相机姿态变化等挑战性场景下表现优异。

Conclusion: 该方法利用IMU数据提供的额外信息，校正各种畸变源，易于集成到现有无人机工作流程中，为无人机航拍和遥感应用提供了更鲁棒的图像拼接解决方案。

Abstract: Unmanned Aerial Vehicles (UAVs) are widely used for aerial photography and
remote sensing applications. One of the main challenges is to stitch together
multiple images into a single high-resolution image that covers a large area.
Featurebased image stitching algorithms are commonly used but can suffer from
errors and ambiguities in feature detection and matching. To address this,
several approaches have been proposed, including using bundle adjustment
techniques or direct image alignment. In this paper, we present a novel method
that uses a combination of IMU data and computer vision techniques for
stitching images captured by a UAV. Our method involves several steps such as
estimating the displacement and rotation of the UAV between consecutive images,
correcting for perspective distortion, and computing a homography matrix. We
then use a standard image stitching algorithm to align and blend the images
together. Our proposed method leverages the additional information provided by
the IMU data, corrects for various sources of distortion, and can be easily
integrated into existing UAV workflows. Our experiments demonstrate the
effectiveness and robustness of our method, outperforming some of the existing
feature-based image stitching algorithms in terms of accuracy and reliability,
particularly in challenging scenarios such as large displacements, rotations,
and variations in camera pose.

</details>


### [64] [Commonality in Few: Few-Shot Multimodal Anomaly Detection via Hypergraph-Enhanced Memory](https://arxiv.org/abs/2511.05966)
*Yuxuan Lin,Hanjing Yan,Xuan Tong,Yang Chang,Huanzhen Wang,Ziheng Zhou,Shuyong Gao,Yan Wang,Wenqiang Zhang*

Main category: cs.CV

TL;DR: 提出了一种基于结构共性的少样本多模态工业异常检测方法CIF，利用超图提取训练样本的结构共性，并通过记忆库存储这种先验知识，在测试时通过超图消息传递和超边引导记忆搜索来降低误报率。


<details>
  <summary>Details</summary>
Motivation: 少样本多模态工业异常检测是一个重要但研究不足的任务，在训练样本不足的情况下，难以覆盖测试样本的多样模式，需要从少量训练样本中提取结构共性来解决这一问题。

Method: 1. 设计语义感知超图构建模块提取单语义工业图像的结构共性；2. 使用训练无关的超图消息传递模块更新测试样本特征；3. 提出超边引导记忆搜索模块利用结构信息辅助记忆搜索。

Result: 在MVTec 3D-AD和Eyecandies数据集上的实验结果表明，该方法在少样本设置下优于现有最先进方法。

Conclusion: CIF方法通过提取和利用结构共性，有效解决了少样本工业异常检测中的挑战，在多个数据集上取得了优异性能。

Abstract: Few-shot multimodal industrial anomaly detection is a critical yet
underexplored task, offering the ability to quickly adapt to complex industrial
scenarios. In few-shot settings, insufficient training samples often fail to
cover the diverse patterns present in test samples. This challenge can be
mitigated by extracting structural commonality from a small number of training
samples. In this paper, we propose a novel few-shot unsupervised multimodal
industrial anomaly detection method based on structural commonality, CIF
(Commonality In Few). To extract intra-class structural information, we employ
hypergraphs, which are capable of modeling higher-order correlations, to
capture the structural commonality within training samples, and use a memory
bank to store this intra-class structural prior. Firstly, we design a
semantic-aware hypergraph construction module tailored for single-semantic
industrial images, from which we extract common structures to guide the
construction of the memory bank. Secondly, we use a training-free hypergraph
message passing module to update the visual features of test samples, reducing
the distribution gap between test features and features in the memory bank. We
further propose a hyperedge-guided memory search module, which utilizes
structural information to assist the memory search process and reduce the false
positive rate. Experimental results on the MVTec 3D-AD dataset and the
Eyecandies dataset show that our method outperforms the state-of-the-art (SOTA)
methods in few-shot settings. Code is available at
https://github.com/Sunny5250/CIF.

</details>


### [65] [Real-Time LiDAR Super-Resolution via Frequency-Aware Multi-Scale Fusion](https://arxiv.org/abs/2511.07377)
*June Moh Goo,Zichao Zeng,Jan Boehm*

Main category: cs.CV

TL;DR: FLASH是一个新颖的LiDAR超分辨率框架，通过双域处理（空间域+频率域）和自适应多尺度融合，在KITTI数据集上实现了最先进的性能，超越了基于Transformer的方法，同时保持单次前向传播的实时效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有LiDAR超分辨率方法（如基于Transformer的TULIP）仅限于空间域处理且感受野受限的问题，通过双域处理来提升3D感知质量。

Method: FLASH框架包含两个关键创新：1）频率感知窗口注意力，结合局部空间注意力和全局频率域分析（通过FFT）；2）自适应多尺度融合，用学习的位置特定特征聚合替代传统跳跃连接，并通过CBAM注意力进行动态特征选择。

Result: 在KITTI数据集上的广泛实验表明，FLASH在所有评估指标上都达到了最先进的性能，超越了包括不确定性增强基线在内的所有方法，并在所有距离范围内都表现出色。

Conclusion: FLASH通过架构设计而非计算昂贵的随机推理有效处理不确定性，使其适用于自动驾驶系统的实时部署。

Abstract: LiDAR super-resolution addresses the challenge of achieving high-quality 3D
perception from cost-effective, low-resolution sensors. While recent
transformer-based approaches like TULIP show promise, they remain limited to
spatial-domain processing with restricted receptive fields. We introduce FLASH
(Frequency-aware LiDAR Adaptive Super-resolution with Hierarchical fusion), a
novel framework that overcomes these limitations through dual-domain
processing. FLASH integrates two key innovations: (i) Frequency-Aware Window
Attention that combines local spatial attention with global frequency-domain
analysis via FFT, capturing both fine-grained geometry and periodic scanning
patterns at log-linear complexity. (ii) Adaptive Multi-Scale Fusion that
replaces conventional skip connections with learned position-specific feature
aggregation, enhanced by CBAM attention for dynamic feature selection.
Extensive experiments on KITTI demonstrate that FLASH achieves state-of-the-art
performance across all evaluation metrics, surpassing even uncertainty-enhanced
baselines that require multiple forward passes. Notably, FLASH outperforms
TULIP with Monte Carlo Dropout while maintaining single-pass efficiency, which
enables real-time deployment. The consistent superiority across all distance
ranges validates that our dual-domain approach effectively handles uncertainty
through architectural design rather than computationally expensive stochastic
inference, making it practical for autonomous systems.

</details>


### [66] [Adapted Foundation Models for Breast MRI Triaging in Contrast-Enhanced and Non-Contrast Enhanced Protocols](https://arxiv.org/abs/2511.05967)
*Tri-Thien Nguyen,Lorenz A. Kapsner,Tobias Hepp,Shirin Heidarikahkesh,Hannes Schreiter,Luise Brock,Dominika Skwierawska,Dominique Hadler,Julian Hossbach,Evelyn Wenkel,Sabine Ohlmeyer,Frederik B. Laun,Andrzej Liebert,Andreas Maier,Michael Uder,Sebastian Bickelhaupt*

Main category: cs.CV

TL;DR: 本研究评估了基于DINOv2的医学切片Transformer（MST）在乳腺MRI中排除显著病变（BI-RADS≥4）的能力，发现T1sub+T2w组合在97.5%灵敏度下达到19%特异性，展示了AI在乳腺MRI预筛查中的潜力。


<details>
  <summary>Details</summary>
Motivation: 乳腺MRI解读耗时较长，人工智能可能有助于预筛查，提高诊断效率。

Method: 回顾性研究纳入1,847例乳腺MRI检查，测试四种简化协议（T1sub、DWI1500、DWI1500+T2w、T1sub+T2w），使用五折交叉验证和AUC分析评估性能，并通过DeLong检验比较差异。

Result: T1sub+T2w组合达到AUC 0.77±0.04，在97.5%灵敏度下特异性为19%；DWI1500+T2w组合AUC为0.74±0.04，特异性17%。外部验证AUC为0.77，88%的注意力图被评为良好或中等。

Conclusion: MST框架在97.5%灵敏度下能正确分类无BI-RADS≥4的病例，对比增强和非对比增强MRI分别达到19%和17%的特异性，但临床实施前需要进一步研究。

Abstract: Background: Magnetic resonance imaging (MRI) has high sensitivity for breast
cancer detection, but interpretation is time-consuming. Artificial intelligence
may aid in pre-screening. Purpose: To evaluate the DINOv2-based Medical Slice
Transformer (MST) for ruling out significant findings (Breast Imaging Reporting
and Data System [BI-RADS] >=4) in contrast-enhanced and non-contrast-enhanced
abbreviated breast MRI. Materials and Methods: This institutional review board
approved retrospective study included 1,847 single-breast MRI examinations (377
BI-RADS >=4) from an in-house dataset and 924 from an external validation
dataset (Duke). Four abbreviated protocols were tested: T1-weighted early
subtraction (T1sub), diffusion-weighted imaging with b=1500 s/mm2 (DWI1500),
DWI1500+T2-weighted (T2w), and T1sub+T2w. Performance was assessed at 90%, 95%,
and 97.5% sensitivity using five-fold cross-validation and area under the
receiver operating characteristic curve (AUC) analysis. AUC differences were
compared with the DeLong test. False negatives were characterized, and
attention maps of true positives were rated in the external dataset. Results: A
total of 1,448 female patients (mean age, 49 +/- 12 years) were included.
T1sub+T2w achieved an AUC of 0.77 +/- 0.04; DWI1500+T2w, 0.74 +/- 0.04
(p=0.15). At 97.5% sensitivity, T1sub+T2w had the highest specificity (19% +/-
7%), followed by DWI1500+T2w (17% +/- 11%). Missed lesions had a mean diameter
<10 mm at 95% and 97.5% thresholds for both T1sub and DWI1500, predominantly
non-mass enhancements. External validation yielded an AUC of 0.77, with 88% of
attention maps rated good or moderate. Conclusion: At 97.5% sensitivity, the
MST framework correctly triaged cases without BI-RADS >=4, achieving 19%
specificity for contrast-enhanced and 17% for non-contrast-enhanced MRI.
Further research is warranted before clinical implementation.

</details>


### [67] [TwinOR: Photorealistic Digital Twins of Dynamic Operating Rooms for Embodied AI Research](https://arxiv.org/abs/2511.07412)
*Han Zhang,Yiqing Shen,Roger D. Soberanis-Mukul,Ankita Ghosh,Hao Ding,Lalithkumar Seenivasan,Jose L. Porras,Zhekai Mao,Chenjia Li,Wenjie Xiao,Lonny Yarmus,Angela Christine Argento,Masaru Ishii,Mathias Unberath*

Main category: cs.CV

TL;DR: TwinOR是一个用于构建手术室动态数字孪生的框架，通过多视角感知重建静态几何和动态运动，为AI手术系统提供安全可控的训练环境。


<details>
  <summary>Details</summary>
Motivation: 手术室的安全规定和操作限制限制了AI代理在真实环境中感知和交互，需要创建高保真、无风险的数字孪生环境来支持持续学习和评估。

Method: 从预扫描视频重建静态几何，通过多视角感知持续建模人和设备运动，将静态和动态组件融合到沉浸式3D环境中，支持可控模拟和具身探索。

Result: TwinOR以厘米级精度重建完整手术室几何，在几何理解和视觉定位任务中，FoundationStereo和ORB-SLAM3模型在合成数据上的性能接近其在真实室内数据集上的报告精度。

Conclusion: TwinOR建立了从真实到模拟的管道，构建动态、逼真的手术室数字孪生，为具身AI提供安全、可扩展且数据高效的发展和基准测试，加速从模拟到现实的部署。

Abstract: Developing embodied AI for intelligent surgical systems requires safe,
controllable environments for continual learning and evaluation. However,
safety regulations and operational constraints in operating rooms (ORs) limit
embodied agents from freely perceiving and interacting in realistic settings.
Digital twins provide high-fidelity, risk-free environments for exploration and
training. How we may create photorealistic and dynamic digital representations
of ORs that capture relevant spatial, visual, and behavioral complexity remains
unclear. We introduce TwinOR, a framework for constructing photorealistic,
dynamic digital twins of ORs for embodied AI research. The system reconstructs
static geometry from pre-scan videos and continuously models human and
equipment motion through multi-view perception of OR activities. The static and
dynamic components are fused into an immersive 3D environment that supports
controllable simulation and embodied exploration. The proposed framework
reconstructs complete OR geometry with centimeter level accuracy while
preserving dynamic interaction across surgical workflows, enabling realistic
renderings and a virtual playground for embodied AI systems. In our
experiments, TwinOR simulates stereo and monocular sensor streams for geometry
understanding and visual localization tasks. Models such as FoundationStereo
and ORB-SLAM3 on TwinOR-synthesized data achieve performance within their
reported accuracy on real indoor datasets, demonstrating that TwinOR provides
sensor-level realism sufficient for perception and localization challenges. By
establishing a real-to-sim pipeline for constructing dynamic, photorealistic
digital twins of OR environments, TwinOR enables the safe, scalable, and
data-efficient development and benchmarking of embodied AI, ultimately
accelerating the deployment of embodied AI from sim-to-real.

</details>


### [68] [DiA-gnostic VLVAE: Disentangled Alignment-Constrained Vision Language Variational AutoEncoder for Robust Radiology Reporting with Missing Modalities](https://arxiv.org/abs/2511.05968)
*Nagur Shareef Shaik,Teja Krishna Cherukuri,Adnan Masood,Dong Hye Ye*

Main category: cs.CV

TL;DR: 本文提出DiA-gnostic VLVAE框架，通过解耦对齐方法解决医学影像报告中缺失模态和特征纠缠问题，在IU X-Ray和MIMIC-CXR数据集上取得优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 当前自动化医学影像报告方法面临两个关键挑战：1）临床上下文信息缺失；2）模态特定特征与共享特征纠缠导致融合效果不佳和临床不真实的幻觉发现。需要开发能够处理不完整临床数据并确保临床准确性的鲁棒方法。

Method: 提出DiA-gnostic VLVAE框架，使用基于专家混合的视觉语言变分自编码器解耦共享和模态特定特征，通过约束优化目标强制潜在表示的正交性和对齐，最后使用紧凑的LLaMA-X解码器生成报告。

Result: 在IU X-Ray和MIMIC-CXR数据集上分别获得0.266和0.134的BLEU@4分数，显著优于现有最先进模型，证明该方法对缺失模态具有鲁棒性。

Conclusion: DiA框架通过解耦对齐方法有效解决了医学影像报告中的关键挑战，在保持临床准确性的同时实现了高效报告生成，为实际临床应用提供了可行解决方案。

Abstract: The integration of medical images with clinical context is essential for
generating accurate and clinically interpretable radiology reports. However,
current automated methods often rely on resource-heavy Large Language Models
(LLMs) or static knowledge graphs and struggle with two fundamental challenges
in real-world clinical data: (1) missing modalities, such as incomplete
clinical context , and (2) feature entanglement, where mixed modality-specific
and shared information leads to suboptimal fusion and clinically unfaithful
hallucinated findings. To address these challenges, we propose the DiA-gnostic
VLVAE, which achieves robust radiology reporting through Disentangled
Alignment. Our framework is designed to be resilient to missing modalities by
disentangling shared and modality-specific features using a Mixture-of-Experts
(MoE) based Vision-Language Variational Autoencoder (VLVAE). A constrained
optimization objective enforces orthogonality and alignment between these
latent representations to prevent suboptimal fusion. A compact LLaMA-X decoder
then uses these disentangled representations to generate reports efficiently.
On the IU X-Ray and MIMIC-CXR datasets, DiA has achieved competetive BLEU@4
scores of 0.266 and 0.134, respectively. Experimental results show that the
proposed method significantly outperforms state-of-the-art models.

</details>


### [69] [A Dual-Mode ViT-Conditioned Diffusion Framework with an Adaptive Conditioning Bridge for Breast Cancer Segmentation](https://arxiv.org/abs/2511.05989)
*Prateek Singh,Moumita Dholey,P. K. Vinod*

Main category: cs.CV

TL;DR: 提出了一种基于条件去噪扩散模型的乳腺超声图像病灶分割方法，通过ViT编码器提取全局特征，结合自适应条件桥和多尺度融合，使用拓扑去噪一致性损失进行训练，在多个公开数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 乳腺超声图像中病灶分割对于早期诊断至关重要，但由于低对比度、斑点噪声和模糊边界等问题，传统卷积架构难以捕获足够的全局上下文信息，导致分割结果在解剖学上不一致。

Method: 采用条件去噪扩散模型，结合ViT编码器和改进的UNet生成解码器，提出自适应条件桥实现多尺度语义特征融合，使用拓扑去噪一致性损失进行正则化训练，采用双头架构实现快速准确推理。

Result: 在三个公开乳腺超声数据集上取得最优结果：BUSI数据集Dice分数0.96，BrEaST数据集0.90，BUS-UCLM数据集0.97。消融实验验证了各组件的重要性。

Conclusion: 该方法不仅实现了高精度分割，还产生了在解剖学上合理的分割结果，为医学图像分割提供了新的解决方案。

Abstract: In breast ultrasound images, precise lesion segmentation is essential for
early diagnosis; however, low contrast, speckle noise, and unclear boundaries
make this difficult. Even though deep learning models have demonstrated
potential, standard convolutional architectures frequently fall short in
capturing enough global context, resulting in segmentations that are
anatomically inconsistent. To overcome these drawbacks, we suggest a flexible,
conditional Denoising Diffusion Model that combines an enhanced UNet-based
generative decoder with a Vision Transformer (ViT) encoder for global feature
extraction. We introduce three primary innovations: 1) an Adaptive Conditioning
Bridge (ACB) for efficient, multi-scale fusion of semantic features; 2) a novel
Topological Denoising Consistency (TDC) loss component that regularizes
training by penalizing structural inconsistencies during denoising; and 3) a
dual-head architecture that leverages the denoising objective as a powerful
regularizer, enabling a lightweight auxiliary head to perform rapid and
accurate inference on smaller datasets and a noise prediction head. Our
framework establishes a new state-of-the-art on public breast ultrasound
datasets, achieving Dice scores of 0.96 on BUSI, 0.90 on BrEaST and 0.97 on
BUS-UCLM. Comprehensive ablation studies empirically validate that the model
components are critical for achieving these results and for producing
segmentations that are not only accurate but also anatomically plausible.

</details>


### [70] [Exploring Category-level Articulated Object Pose Tracking on SE(3) Manifolds](https://arxiv.org/abs/2511.05996)
*Xianhui Meng,Yukang Huo,Li Zhang,Liu Liu,Haonan Jiang,Yan Zhong,Pingrui Zhang,Cewu Lu,Jun Liu*

Main category: cs.CV

TL;DR: PPF-Tracker是一个基于点对特征的铰接物体姿态跟踪框架，通过在SE(3)李群空间进行准规范化处理，利用SE(3)不变性预测姿态投票参数，并引入关节轴语义信息施加统一的运动学约束。


<details>
  <summary>Details</summary>
Motivation: 铰接物体在日常生活中和机器人操作任务中普遍存在，但相比刚性物体，由于其固有的运动学约束，铰接物体的姿态跟踪问题仍未得到充分探索。

Method: 提出点对特征(PPF)姿态跟踪框架：1）在SE(3)李群空间对点云进行准规范化；2）利用PPF建模铰接物体，基于SE(3)不变性预测姿态投票参数；3）引入关节轴语义信息施加统一的运动学约束。

Result: 在合成数据集和真实场景中系统评估，PPF-Tracker在多样化挑战性环境中展现出强大的泛化能力，实验结果表明该方法在铰接物体多帧姿态跟踪中具有有效性和鲁棒性。

Conclusion: 该工作能够推动机器人技术、具身智能和增强现实领域的发展，代码已开源。

Abstract: Articulated objects are prevalent in daily life and robotic manipulation
tasks. However, compared to rigid objects, pose tracking for articulated
objects remains an underexplored problem due to their inherent kinematic
constraints. To address these challenges, this work proposes a novel
point-pair-based pose tracking framework, termed \textbf{PPF-Tracker}. The
proposed framework first performs quasi-canonicalization of point clouds in the
SE(3) Lie group space, and then models articulated objects using Point Pair
Features (PPF) to predict pose voting parameters by leveraging the invariance
properties of SE(3). Finally, semantic information of joint axes is
incorporated to impose unified kinematic constraints across all parts of the
articulated object. PPF-Tracker is systematically evaluated on both synthetic
datasets and real-world scenarios, demonstrating strong generalization across
diverse and challenging environments. Experimental results highlight the
effectiveness and robustness of PPF-Tracker in multi-frame pose tracking of
articulated objects. We believe this work can foster advances in robotics,
embodied intelligence, and augmented reality. Codes are available at
https://github.com/mengxh20/PPFTracker.

</details>


### [71] [MALeR: Improving Compositional Fidelity in Layout-Guided Generation](https://arxiv.org/abs/2511.06002)
*Shivank Saxena,Dhruv Srivastava,Makarand Tapaswi*

Main category: cs.CV

TL;DR: MALeR是一种解决文本到图像生成中多主体多属性组合场景挑战的方法，通过布局引导和属性感知绑定机制，防止主体超出布局范围、分布外生成和属性泄漏问题。


<details>
  <summary>Details</summary>
Motivation: 现有的布局引导方法在生成组合场景时面临挑战：主体出现在布局外、生成图像分布外且包含不自然伪影、属性在不同主体间泄漏导致视觉输出错误。

Method: 提出MALeR方法，给定文本提示和对应布局，防止主体出现在给定布局外同时保持分布内生成；提出掩码属性感知绑定机制防止属性泄漏。

Result: 定性和定量评估表明，MALeR在组合准确性、生成一致性和属性绑定方面优于先前工作，特别擅长生成具有多个主体和每个主体多个属性的场景图像。

Conclusion: MALeR有效解决了组合场景生成中的关键挑战，为多主体多属性图像生成提供了更精确的控制能力。

Abstract: Recent advances in text-to-image models have enabled a new era of creative
and controllable image generation. However, generating compositional scenes
with multiple subjects and attributes remains a significant challenge. To
enhance user control over subject placement, several layout-guided methods have
been proposed. However, these methods face numerous challenges, particularly in
compositional scenes. Unintended subjects often appear outside the layouts,
generated images can be out-of-distribution and contain unnatural artifacts, or
attributes bleed across subjects, leading to incorrect visual outputs. In this
work, we propose MALeR, a method that addresses each of these challenges. Given
a text prompt and corresponding layouts, our method prevents subjects from
appearing outside the given layouts while being in-distribution. Additionally,
we propose a masked, attribute-aware binding mechanism that prevents attribute
leakage, enabling accurate rendering of subjects with multiple attributes, even
in complex compositional scenes. Qualitative and quantitative evaluation
demonstrates that our method achieves superior performance in compositional
accuracy, generation consistency, and attribute binding compared to previous
work. MALeR is particularly adept at generating images of scenes with multiple
subjects and multiple attributes per subject.

</details>


### [72] [How Reasoning Influences Intersectional Biases in Vision Language Models](https://arxiv.org/abs/2511.06005)
*Adit Desai,Sudipta Roy,Mohna Chakraborty*

Main category: cs.CV

TL;DR: 本文分析了五种开源视觉语言模型在职业预测任务中的社会偏见，发现模型推理模式存在系统性偏见，需要在下游部署前与人类价值观对齐。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型的训练数据编码了社会偏见，这些偏见在输出中显现。与人类通过上下文和社会线索解释图像不同，VLM通过统计关联处理图像，导致推理与人类推理存在差异。

Method: 在FairFace数据集上，对五种开源VLM进行职业预测任务的系统性分析，涵盖32种职业和三种提示风格，获取预测结果和推理过程。

Result: 研究发现偏见的推理模式系统地导致了交叉性差异，模型在处理不同人口特征组合时表现出系统性偏见。

Conclusion: 需要在VLM下游部署前将其推理与人类价值观对齐，以减少社会偏见对模型性能的负面影响。

Abstract: Vision Language Models (VLMs) are increasingly deployed across downstream
tasks, yet their training data often encode social biases that surface in
outputs. Unlike humans, who interpret images through contextual and social
cues, VLMs process them through statistical associations, often leading to
reasoning that diverges from human reasoning. By analyzing how a VLM reasons,
we can understand how inherent biases are perpetuated and can adversely affect
downstream performance. To examine this gap, we systematically analyze social
biases in five open-source VLMs for an occupation prediction task, on the
FairFace dataset. Across 32 occupations and three different prompting styles,
we elicit both predictions and reasoning. Our findings reveal that the biased
reasoning patterns systematically underlie intersectional disparities,
highlighting the need to align VLM reasoning with human values prior to its
downstream deployment.

</details>


### [73] [Distributed Deep Learning for Medical Image Denoising with Data Obfuscation](https://arxiv.org/abs/2511.06006)
*Sulaimon Oyeniyi Adebayo,Ayaz H. Khan*

Main category: cs.CV

TL;DR: 该研究探索了分布式深度学习在胸部X射线图像去噪中的应用，使用U-Net和U-Net++架构，结合分布式训练优化技术，实现了60%以上的训练时间减少，同时保持较好的去噪性能。


<details>
  <summary>Details</summary>
Motivation: 医学图像去噪对于提高图像质量同时保护敏感信息至关重要，特别是在处理大规模临床数据集时。本研究旨在探索分布式深度学习在医学图像去噪中的实际应用价值。

Method: 使用NIH Chest X-ray14数据集，采用加性高斯噪声作为轻量级混淆技术。评估U-Net和U-Net++架构在单GPU、标准多GPU和优化多GPU训练配置下的性能，使用PyTorch的DistributedDataParallel和自动混合精度技术。

Result: U-Net++在去噪性能上表现更优，在PSNR和SSIM指标上取得竞争性分数，但在LPIPS指标上略逊于U-Net。优化训练管道使训练时间减少60%以上，比标准DataParallel快40%以上，仅有轻微精度损失。

Conclusion: 该研究证明了在医学成像中结合架构设计、轻量级混淆和先进分布式训练策略的实用可行性，能够加速和增强医学图像处理流程。

Abstract: Medical image denoising is essential for improving image quality while
minimizing the exposure of sensitive information, particularly when working
with large-scale clinical datasets. This study explores distributed deep
learning for denoising chest X-ray images from the NIH Chest X-ray14 dataset,
using additive Gaussian noise as a lightweight obfuscation technique. We
implement and evaluate U-Net and U-Net++ architectures under single-GPU,
standard multi-GPU (DataParallel), and optimized multi-GPU training
configurations using PyTorch's DistributedDataParallel (DDP) and Automatic
Mixed Precision (AMP). Our results show that U-Net++ consistently delivers
superior denoising performance, achieving competitive Peak Signal to Noise
Ratio (PSNR) and Structured Similarity Index Method (SSIM) scores, though with
less performance in Learned Perceptual Image Patch Similarity (LPIPS) compared
to U-Net under low and moderate noise levels. This indicates U-Net++'s enhanced
structural fidelity and low perceptual similarity. Meanwhile, our optimized
training pipeline reduces training time by over 60% for both models compared to
single-GPU training, and outperforms standard DataParallel by over 40%, with
only a minor accuracy drop for both models (trading some accuracy for speed).
These findings highlight the effectiveness of software-level optimization in
distributed learning for medical imaging. This work demonstrates the practical
viability of combining architectural design, lightweight obfuscation, and
advanced distributed training strategies to accelerate and enhance medical
image processing pipelines in real-world clinical and research environments.
The full implementation is publicly available at:
https://github.com/Suadey/medical-image-denoising-ddp.

</details>


### [74] [One-Shot Knowledge Transfer for Scalable Person Re-Identification](https://arxiv.org/abs/2511.06016)
*Longhua Li,Lei Qi,Xin Geng*

Main category: cs.CV

TL;DR: 提出了一种名为OSKT（One-Shot Knowledge Transfer）的新型知识继承方法，通过权重链技术实现一次性知识转移，避免为不同资源约束重复计算多个模型。


<details>
  <summary>Details</summary>
Motivation: 边缘计算中的人员重识别需要不同大小的模型以适应不同资源条件，传统压缩方法需要为每个学生模型单独计算，导致重复繁琐的计算负担。

Method: OSKT方法将教师模型的知识整合到称为权重链的中间载体中，当需要特定资源约束的模型时，权重链可以扩展到目标模型大小而无需额外计算。

Result: OSKT显著优于最先进的压缩方法，并具有一次性知识转移的优势，消除了为每个目标模型频繁计算的需求。

Conclusion: 该方法有效解决了边缘计算中人员重识别模型压缩的重复计算问题，提供了一种高效的知识继承解决方案。

Abstract: Edge computing in person re-identification (ReID) is crucial for reducing the
load on central cloud servers and ensuring user privacy. Conventional
compression methods for obtaining compact models require computations for each
individual student model. When multiple models of varying sizes are needed to
accommodate different resource conditions, this leads to repetitive and
cumbersome computations. To address this challenge, we propose a novel
knowledge inheritance approach named OSKT (One-Shot Knowledge Transfer), which
consolidates the knowledge of the teacher model into an intermediate carrier
called a weight chain. When a downstream scenario demands a model that meets
specific resource constraints, this weight chain can be expanded to the target
model size without additional computation. OSKT significantly outperforms
state-of-the-art compression methods, with the added advantage of one-time
knowledge transfer that eliminates the need for frequent computations for each
target model.

</details>


### [75] [MiVID: Multi-Strategic Self-Supervision for Video Frame Interpolation using Diffusion Model](https://arxiv.org/abs/2511.06019)
*Priyansh Srivastava,Romit Chatterjee,Abir Sen,Aradhana Behura,Ratnakar Dash*

Main category: cs.CV

TL;DR: MiVID是一个轻量级的自监督扩散框架，用于视频帧插值，无需显式运动估计或高帧率监督，在有限资源下实现竞争性性能


<details>
  <summary>Details</summary>
Motivation: 传统视频帧插值方法依赖光流或密集真值，难以处理遮挡、域偏移和模糊运动问题，需要开发更鲁棒的自监督方法

Method: 结合3D U-Net主干和Transformer时序注意力，采用混合掩码机制模拟遮挡和运动不确定性，使用余弦渐进掩码和自适应损失调度

Result: 在UCF101-7和DAVIS-7数据集上评估，仅需50个epoch在CPU上训练即可达到与多个监督基线竞争的结果

Conclusion: 证明了自监督扩散先验在时间一致性帧合成中的有效性，为可访问和可泛化的视频帧插值系统提供了可扩展路径

Abstract: Video Frame Interpolation (VFI) remains a cornerstone in video enhancement,
enabling temporal upscaling for tasks like slow-motion rendering, frame rate
conversion, and video restoration. While classical methods rely on optical flow
and learning-based models assume access to dense ground-truth, both struggle
with occlusions, domain shifts, and ambiguous motion. This article introduces
MiVID, a lightweight, self-supervised, diffusion-based framework for video
interpolation. Our model eliminates the need for explicit motion estimation by
combining a 3D U-Net backbone with transformer-style temporal attention,
trained under a hybrid masking regime that simulates occlusions and motion
uncertainty. The use of cosine-based progressive masking and adaptive loss
scheduling allows our network to learn robust spatiotemporal representations
without any high-frame-rate supervision. Our framework is evaluated on UCF101-7
and DAVIS-7 datasets. MiVID is trained entirely on CPU using the datasets and
9-frame video segments, making it a low-resource yet highly effective pipeline.
Despite these constraints, our model achieves optimal results at just 50
epochs, competitive with several supervised baselines.This work demonstrates
the power of self-supervised diffusion priors for temporally coherent frame
synthesis and provides a scalable path toward accessible and generalizable VFI
systems.

</details>


### [76] [Towards Implicit Aggregation: Robust Image Representation for Place Recognition in the Transformer Era](https://arxiv.org/abs/2511.06024)
*Feng Lu,Tong Jin,Canming Ye,Yunpeng Liu,Xiangyuan Lan,Chun Yuan*

Main category: cs.CV

TL;DR: 本文提出在Transformer时代，视觉地点识别（VPR）无需专门的聚合器，仅通过主干网络即可获得鲁棒的全局描述符。通过引入可学习的聚合标记，利用自注意力机制隐式聚合信息，实现了更高效且性能优越的VPR方法。


<details>
  <summary>Details</summary>
Motivation: 传统VPR方法采用主干网络加聚合器的范式，但在Transformer时代，这种范式可能不再必要。作者认为可以通过Transformer的自注意力机制隐式完成聚合，从而简化模型结构并提升效率。

Method: 引入可学习的聚合标记，在特定Transformer块前预加到图像块标记中。通过自注意力机制让所有标记全局交互，隐式将有用信息聚合到聚合标记中。最后仅取聚合标记作为全局表示。

Result: 在多个VPR数据集上超越现有最先进方法，效率更高，在MSLS挑战赛排行榜上排名第一。

Conclusion: 证明了在Transformer架构中，专门的聚合器不是必需的，隐式聚合方法能够以更简单的方式获得鲁棒的全局描述符，为VPR任务提供了新的思路。

Abstract: Visual place recognition (VPR) is typically regarded as a specific image
retrieval task, whose core lies in representing images as global descriptors.
Over the past decade, dominant VPR methods (e.g., NetVLAD) have followed a
paradigm that first extracts the patch features/tokens of the input image using
a backbone, and then aggregates these patch features into a global descriptor
via an aggregator. This backbone-plus-aggregator paradigm has achieved
overwhelming dominance in the CNN era and remains widely used in
transformer-based models. In this paper, however, we argue that a dedicated
aggregator is not necessary in the transformer era, that is, we can obtain
robust global descriptors only with the backbone. Specifically, we introduce
some learnable aggregation tokens, which are prepended to the patch tokens
before a particular transformer block. All these tokens will be jointly
processed and interact globally via the intrinsic self-attention mechanism,
implicitly aggregating useful information within the patch tokens to the
aggregation tokens. Finally, we only take these aggregation tokens from the
last output tokens and concatenate them as the global representation. Although
implicit aggregation can provide robust global descriptors in an extremely
simple manner, where and how to insert additional tokens, as well as the
initialization of tokens, remains an open issue worthy of further exploration.
To this end, we also propose the optimal token insertion strategy and token
initialization method derived from empirical studies. Experimental results show
that our method outperforms state-of-the-art methods on several VPR datasets
with higher efficiency and ranks 1st on the MSLS challenge leaderboard. The
code is available at https://github.com/lu-feng/image.

</details>


### [77] [S2ML: Spatio-Spectral Mutual Learning for Depth Completion](https://arxiv.org/abs/2511.06033)
*Zihui Zhao,Yifei Zhang,Zheng Wang,Yang Li,Kui Jiang,Zihan Geng,Chia-Wen Lin*

Main category: cs.CV

TL;DR: 该论文提出了一种空间-频谱互学习框架(S2ML)，用于解决RGB-D相机原始深度图像中因弱反射、边界阴影和伪影导致的深度值不完整问题。该方法通过融合空间域和频率域的优势，利用振幅和相位谱的独特特性，在统一嵌入空间中计算特征相关性，实现了更准确的深度补全。


<details>
  <summary>Details</summary>
Motivation: 现有深度补全方法主要在图像域进行处理，但忽略了原始深度图像的物理特性。研究发现无效深度区域会改变频率分布模式，因此需要同时考虑空间域和频率域的特性来改善深度补全效果。

Method: 提出了Spatio-Spectral Mutual Learning框架(S2ML)，包含专门的频谱融合模块，分别处理振幅和相位谱。在统一嵌入空间中计算空间域和频率域特征的局部和全局相关性，通过渐进式互表示和细化来充分利用互补的物理特性和先验知识。

Result: 在NYU-Depth V2和SUN RGB-D数据集上的实验表明，S2ML方法优于当前最先进的CFormer方法，分别提升了0.828 dB和0.834 dB。

Conclusion: S2ML框架通过空间域和频率域的互学习，有效利用了深度图像的物理特性，为深度补全任务提供了更准确的解决方案，证明了多域特征融合在计算机视觉任务中的重要性。

Abstract: The raw depth images captured by RGB-D cameras using Time-of-Flight (TOF) or
structured light often suffer from incomplete depth values due to weak
reflections, boundary shadows, and artifacts, which limit their applications in
downstream vision tasks. Existing methods address this problem through depth
completion in the image domain, but they overlook the physical characteristics
of raw depth images. It has been observed that the presence of invalid depth
areas alters the frequency distribution pattern. In this work, we propose a
Spatio-Spectral Mutual Learning framework (S2ML) to harmonize the advantages of
both spatial and frequency domains for depth completion. Specifically, we
consider the distinct properties of amplitude and phase spectra and devise a
dedicated spectral fusion module. Meanwhile, the local and global correlations
between spatial-domain and frequency-domain features are calculated in a
unified embedding space. The gradual mutual representation and refinement
encourage the network to fully explore complementary physical characteristics
and priors for more accurate depth completion. Extensive experiments
demonstrate the effectiveness of our proposed S2ML method, outperforming the
state-of-the-art method CFormer by 0.828 dB and 0.834 dB on the NYU-Depth V2
and SUN RGB-D datasets, respectively.

</details>


### [78] [StreamSTGS: Streaming Spatial and Temporal Gaussian Grids for Real-Time Free-Viewpoint Video](https://arxiv.org/abs/2511.06046)
*Zhihui Ke,Yuyang Liu,Xiaobo Zhou,Tie Qiu*

Main category: cs.CV

TL;DR: StreamSTGS是一种用于实时流式自由视点视频的新表示方法，通过将3D高斯属性编码为2D图像和时间特征编码为视频，显著降低存储需求至170KB/帧，同时提升PSNR约1dB。


<details>
  <summary>Details</summary>
Motivation: 解决现有3DGS-based FVV方法存储需求过高（达10MB/帧）导致无法实时流式传输的问题。

Method: 使用规范3D高斯、时间特征和变形场表示动态场景；采用滑动窗口方案聚合相邻时间特征学习局部运动；引入transformer引导的辅助训练模块学习全局运动。

Result: 在多样化FVV基准测试中表现优异，平均帧大小降至170KB，PSNR平均提升1dB，支持基于网络条件的自适应比特率控制。

Conclusion: StreamSTGS在保持竞争力的同时实现了实时流式传输，为自由视点视频的实际应用提供了可行解决方案。

Abstract: Streaming free-viewpoint video~(FVV) in real-time still faces significant
challenges, particularly in training, rendering, and transmission efficiency.
Harnessing superior performance of 3D Gaussian Splatting~(3DGS), recent
3DGS-based FVV methods have achieved notable breakthroughs in both training and
rendering. However, the storage requirements of these methods can reach up to
$10$MB per frame, making stream FVV in real-time impossible. To address this
problem, we propose a novel FVV representation, dubbed StreamSTGS, designed for
real-time streaming. StreamSTGS represents a dynamic scene using canonical 3D
Gaussians, temporal features, and a deformation field. For high compression
efficiency, we encode canonical Gaussian attributes as 2D images and temporal
features as a video. This design not only enables real-time streaming, but also
inherently supports adaptive bitrate control based on network condition without
any extra training. Moreover, we propose a sliding window scheme to aggregate
adjacent temporal features to learn local motions, and then introduce a
transformer-guided auxiliary training module to learn global motions. On
diverse FVV benchmarks, StreamSTGS demonstrates competitive performance on all
metrics compared to state-of-the-art methods. Notably, StreamSTGS increases the
PSNR by an average of $1$dB while reducing the average frame size to just
$170$KB. The code is publicly available on https://github.com/kkkzh/StreamSTGS.

</details>


### [79] [Neodragon: Mobile Video Generation using Diffusion Transformer](https://arxiv.org/abs/2511.06055)
*Animesh Karnewar,Denis Korzhenkov,Ioannis Lelekas,Adil Karjauv,Noor Fathima,Hanwen Xiong,Vancheeswaran Vaidyanathan,Will Zeng,Rafael Esteves,Tushar Singhal,Fatih Porikli,Mohsen Ghafoorian,Amirhossein Habibian*

Main category: cs.CV

TL;DR: Neodragon是一个在移动设备上实现高效文本到视频生成的系统，在Qualcomm Hexagon NPU上6.7秒内生成2秒640x1024分辨率视频，是首个专门为移动硬件优化的文本到视频模型。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的文本到视频生成模型主要面向云端部署，缺乏针对移动设备的优化方案。Neodragon旨在实现低成本、私密、设备端的视频合成，降低对云服务的依赖。

Method: 采用四个关键技术：1) 文本编码器蒸馏（用0.2B DT5替代4.762B T5xxl）；2) 非对称解码器蒸馏；3) 基于重要性的MMDiT块剪枝；4) 基于DMD的步长蒸馏减少NFE需求。结合优化的SSD1B首帧生成器和QuickSRNet超分辨率。

Result: 实现了参数高效（4.945B）、内存高效（3.5GB峰值RAM）和运行时高效（6.7秒端到端延迟）的移动友好模型，VBench总得分81.61。

Conclusion: Neodragon通过移动端优化技术实现了高质量的设备端视频生成，为创作者提供了不依赖云服务的高质量视频创作工具，推动了AI视频内容创作的民主化。

Abstract: We introduce Neodragon, a text-to-video system capable of generating 2s (49
frames @24 fps) videos at the 640x1024 resolution directly on a Qualcomm
Hexagon NPU in a record 6.7s (7 FPS). Differing from existing transformer-based
offline text-to-video generation models, Neodragon is the first to have been
specifically optimised for mobile hardware to achieve efficient and
high-fidelity video synthesis. We achieve this through four key technical
contributions: (1) Replacing the original large 4.762B T5xxl Text-Encoder with
a much smaller 0.2B DT5 (DistilT5) with minimal quality loss, enabled through a
novel Text-Encoder Distillation procedure. (2) Proposing an Asymmetric Decoder
Distillation approach allowing us to replace the native codec-latent-VAE
decoder with a more efficient one, without disturbing the generative
latent-space of the generation pipeline. (3) Pruning of MMDiT blocks within the
denoiser backbone based on their relative importance, with recovery of original
performance through a two-stage distillation process. (4) Reducing the NFE
(Neural Functional Evaluation) requirement of the denoiser by performing step
distillation using DMD adapted for pyramidal flow-matching, thereby
substantially accelerating video generation. When paired with an optimised
SSD1B first-frame image generator and QuickSRNet for 2x super-resolution, our
end-to-end Neodragon system becomes a highly parameter (4.945B full model),
memory (3.5GB peak RAM usage), and runtime (6.7s E2E latency) efficient
mobile-friendly model, while achieving a VBench total score of 81.61. By
enabling low-cost, private, and on-device text-to-video synthesis, Neodragon
democratizes AI-based video content creation, empowering creators to generate
high-quality videos without reliance on cloud services. Code and model will be
made publicly available at our website:
https://qualcomm-ai-research.github.io/neodragon

</details>


### [80] [LoopExpose: An Unsupervised Framework for Arbitrary-Length Exposure Correction](https://arxiv.org/abs/2511.06066)
*Ao Li,Chen Chen,Zhenyu Wang,Tao Huang,Fangfang Wu,Weisheng Dong*

Main category: cs.CV

TL;DR: 提出了一种名为LoopExpose的无监督曝光校正方法，通过嵌套循环优化策略和伪标签生成，解决了传统方法对大规模标注数据的依赖问题。


<details>
  <summary>Details</summary>
Motivation: 监督学习方法在曝光校正领域取得了显著进展，但严重依赖大规模标注数据集，而这些数据在实际场景中难以获取。

Method: 采用嵌套循环优化策略：上层训练校正模型使用下层多曝光融合生成的伪标签；引入反馈机制，将校正后的图像重新输入融合过程以优化伪标签；提出亮度排序损失函数，利用输入序列的相对亮度顺序作为自监督约束。

Result: 在不同基准数据集上的大量实验表明，LoopExpose在曝光校正和融合性能上优于现有的最先进无监督方法。

Conclusion: LoopExpose通过创新的循环优化框架和自监督约束，实现了有效的无监督曝光校正，为实际应用提供了可行的解决方案。

Abstract: Exposure correction is essential for enhancing image quality under
challenging lighting conditions. While supervised learning has achieved
significant progress in this area, it relies heavily on large-scale labeled
datasets, which are difficult to obtain in practical scenarios. To address this
limitation, we propose a pseudo label-based unsupervised method called
LoopExpose for arbitrary-length exposure correction. A nested loop optimization
strategy is proposed to address the exposure correction problem, where the
correction model and pseudo-supervised information are jointly optimized in a
two-level framework. Specifically, the upper-level trains a correction model
using pseudo-labels generated through multi-exposure fusion at the lower level.
A feedback mechanism is introduced where corrected images are fed back into the
fusion process to refine the pseudo-labels, creating a self-reinforcing
learning loop. Considering the dominant role of luminance calibration in
exposure correction, a Luminance Ranking Loss is introduced to leverage the
relative luminance ordering across the input sequence as a self-supervised
constraint. Extensive experiments on different benchmark datasets demonstrate
that LoopExpose achieves superior exposure correction and fusion performance,
outperforming existing state-of-the-art unsupervised methods. Code is available
at https://github.com/FALALAS/LoopExpose.

</details>


### [81] [An Artificial Intelligence-based Assistant for the Visually Impaired](https://arxiv.org/abs/2511.06080)
*Luis Marquez-Carpintero,Francisco Gomez-Donoso,Zuria Bauer,Bessie Dominguez-Dager,Alvaro Belmonte-Baeza,Mónica Pina-Navarro,Francisco Morillas-Espejo,Felix Escalona,Miguel Cazorla*

Main category: cs.CV

TL;DR: AIDEN是一个基于人工智能的辅助应用，旨在通过先进机器学习算法帮助视障人士识别物体、阅读文本和导航环境，从而提高他们的生活质量。


<details>
  <summary>Details</summary>
Motivation: 视障人士在识别物体、阅读文本和导航陌生环境方面面临挑战，现有解决方案如盲文、有声读物和屏幕阅读器在某些情况下效果有限，因此需要更智能的辅助工具来提升他们的独立性和生活质量。

Method: 应用采用最先进的机器学习算法，包括YOLO（You Only Look Once）架构和大型语言视觉助手（LLaVA），通过多种方法促进用户与系统的交互，并以适当方式访问文本和视觉信息。

Result: AIDEN系统旨在增强用户自主性和信息获取能力，用户反馈支持其对日常可用性的积极感知改善。

Conclusion: AIDEN作为人工智能辅助应用，通过整合先进技术成功帮助视障人士更好地与环境互动，为提升他们的独立性和生活质量提供了有效解决方案。

Abstract: This paper describes an artificial intelligence-based assistant application,
AIDEN, developed during 2023 and 2024, aimed at improving the quality of life
for visually impaired individuals. Visually impaired individuals face
challenges in identifying objects, reading text, and navigating unfamiliar
environments, which can limit their independence and reduce their quality of
life. Although solutions such as Braille, audio books, and screen readers
exist, they may not be effective in all situations. This application leverages
state-of-the-art machine learning algorithms to identify and describe objects,
read text, and answer questions about the environment. Specifically, it uses
You Only Look Once architectures and a Large Language and Vision Assistant. The
system incorporates several methods to facilitate the user's interaction with
the system and access to textual and visual information in an appropriate
manner. AIDEN aims to enhance user autonomy and access to information,
contributing to an improved perception of daily usability, as supported by user
feedback.

</details>


### [82] [Hybrid CNN-ViT Framework for Motion-Blurred Scene Text Restoration](https://arxiv.org/abs/2511.06087)
*Umar Rashid,Muhammad Arslan Arshad,Ghulam Ahmad,Muhammad Zeeshan Anjum,Rizwan Khan,Muhammad Akmal*

Main category: cs.CV

TL;DR: 提出一种结合CNN和ViT的混合深度学习框架，用于处理运动模糊场景文本图像恢复，在保持轻量化的同时实现高效的去模糊效果。


<details>
  <summary>Details</summary>
Motivation: 运动模糊严重影响场景文本图像的可读性和计算机视觉任务的可靠性，传统去模糊方法难以处理空间变化模糊和长距离依赖关系。

Method: 使用CNN编码器-解码器结构保留结构细节，通过Transformer模块增强全局上下文推理能力，在TextOCR数据集上训练，采用复合损失函数进行优化。

Result: 该方法在PSNR上达到32.20 dB，SSIM为0.934，仅需283万参数和61ms平均推理时间，表现出优异的计算效率。

Conclusion: CNN-ViT混合设计在运动模糊场景文本恢复中具有有效性和实用性，适合实际应用。

Abstract: Motion blur in scene text images severely impairs readability and hinders the
reliability of computer vision tasks, including autonomous driving, document
digitization, and visual information retrieval. Conventional deblurring
approaches are often inadequate in handling spatially varying blur and
typically fall short in modeling the long-range dependencies necessary for
restoring textual clarity. To overcome these limitations, we introduce a hybrid
deep learning framework that combines convolutional neural networks (CNNs) with
vision transformers (ViTs), thereby leveraging both local feature extraction
and global contextual reasoning. The architecture employs a CNN-based
encoder-decoder to preserve structural details, while a transformer module
enhances global awareness through self-attention. Training is conducted on a
curated dataset derived from TextOCR, where sharp scene-text samples are paired
with synthetically blurred versions generated using realistic motion-blur
kernels of multiple sizes and orientations. Model optimization is guided by a
composite loss that incorporates mean absolute error (MAE), squared error
(MSE), perceptual similarity, and structural similarity (SSIM). Quantitative
eval- uations show that the proposed method attains 32.20 dB in PSNR and 0.934
in SSIM, while remaining lightweight with 2.83 million parameters and an
average inference time of 61 ms. These results highlight the effectiveness and
computational efficiency of the CNN-ViT hybrid design, establishing its
practicality for real-world motion-blurred scene-text restoration.

</details>


### [83] [DiLO: Disentangled Latent Optimization for Learning Shape and Deformation in Grouped Deforming 3D Objects](https://arxiv.org/abs/2511.06115)
*Mostofa Rafid Uddin,Jana Armouti,Umong Sain,Md Asib Rahman,Xingjian Li,Min Xu*

Main category: cs.CV

TL;DR: 提出了一种基于解缠潜在优化的方法，用于无监督地将分组变形3D对象参数化为形状和变形因子。该方法通过联合优化生成器网络和形状/变形因子，结合特定正则化技术，实现了高效的无监督解缠学习。


<details>
  <summary>Details</summary>
Motivation: 现有的3D对象变形参数化方法通常需要监督学习或具有较高复杂度。本文旨在开发一种简单有效的无监督方法，能够自动分离形状和变形因子，便于下游应用如变形迁移、分类和可解释性分析。

Method: 采用两阶段方法：第一阶段联合优化生成器网络与形状/变形因子，配合正则化技术；第二阶段训练两个基于PoinNet的编码器网络，实现解缠形状和变形码的高效摊销推理。

Result: 在3D人体、动物和面部表情数据集上的大量实验表明，该方法在无监督变形迁移、变形分类和可解释性分析等下游任务中表现优异，性能与复杂度更高的现有方法相当或更优。

Conclusion: 该方法提供了一种简单而高效的无监督解缠学习框架，成功实现了3D对象的形状和变形因子分离，为多种下游应用提供了有力支持。

Abstract: In this work, we propose a disentangled latent optimization-based method for
parameterizing grouped deforming 3D objects into shape and deformation factors
in an unsupervised manner. Our approach involves the joint optimization of a
generator network along with the shape and deformation factors, supported by
specific regularization techniques. For efficient amortized inference of
disentangled shape and deformation codes, we train two order-invariant
PoinNet-based encoder networks in the second stage of our method. We
demonstrate several significant downstream applications of our method,
including unsupervised deformation transfer, deformation classification, and
explainability analysis. Extensive experiments conducted on 3D human, animal,
and facial expression datasets demonstrate that our simple approach is highly
effective in these downstream tasks, comparable or superior to existing methods
with much higher complexity.

</details>


### [84] [Latent Refinement via Flow Matching for Training-free Linear Inverse Problem Solving](https://arxiv.org/abs/2511.06138)
*Hossein Askari,Yadan Luo,Hongfu Sun,Fred Roosta*

Main category: cs.CV

TL;DR: LFow是一种基于预训练潜在流先验的训练免费框架，用于解决线性逆问题，通过在潜在空间进行ODE采样并使用理论推导的后验协方差来提高重建质量。


<details>
  <summary>Details</summary>
Motivation: 当前基于流的逆问题求解器存在两个主要限制：直接在像素空间操作导致计算资源需求高且难以扩展到高分辨率图像；使用先验无关的后验协方差策略可能削弱与生成轨迹的对齐并降低后验覆盖范围。

Method: LFow利用流匹配的效率在潜在空间进行ODE采样，并引入基于最优向量场理论推导的后验协方差来实现有效的流引导。

Result: 实验结果表明，该方法在大多数任务上的重建质量优于最先进的潜在扩散求解器。

Conclusion: LFow通过潜在空间优化和理论推导的后验协方差，有效解决了现有流基逆问题求解器的局限性，在保持高效性的同时提升了重建性能。

Abstract: Recent advances in inverse problem solving have increasingly adopted flow
priors over diffusion models due to their ability to construct straight
probability paths from noise to data, thereby enhancing efficiency in both
training and inference. However, current flow-based inverse solvers face two
primary limitations: (i) they operate directly in pixel space, which demands
heavy computational resources for training and restricts scalability to
high-resolution images, and (ii) they employ guidance strategies with
prior-agnostic posterior covariances, which can weaken alignment with the
generative trajectory and degrade posterior coverage. In this paper, we propose
LFlow (Latent Refinement via Flows), a training-free framework for solving
linear inverse problems via pretrained latent flow priors. LFlow leverages the
efficiency of flow matching to perform ODE sampling in latent space along an
optimal path. This latent formulation further allows us to introduce a
theoretically grounded posterior covariance, derived from the optimal vector
field, enabling effective flow guidance. Experimental results demonstrate that
our proposed method outperforms state-of-the-art latent diffusion solvers in
reconstruction quality across most tasks. The code will be publicly available
at https://github.com/hosseinaskari-cs/LFlow .

</details>


### [85] [Real-Time Bundle Adjustment for Ultra-High-Resolution UAV Imagery Using Adaptive Patch-Based Feature Tracking](https://arxiv.org/abs/2511.06152)
*Selim Ahmet Iz,Francesco Nex,Norman Kerle,Henry Meissner,Ralf Berger*

Main category: cs.CV

TL;DR: 提出了一种新型实时光束法平差框架，能够在无人机上直接处理全分辨率图像，通过分块处理和动态跟踪实现实时性能，同时保持全局BA的精度。


<details>
  <summary>Details</summary>
Motivation: 实时处理无人机高分辨率图像对于灾害响应等紧急应用至关重要，但传统BA方法要么需要降采样损失细节，要么处理时间过长，无法满足实时任务需求。

Method: 将图像划分为用户定义的补丁（如150x150像素），利用无人机GNSS/IMU数据和全球DSM进行动态跟踪，通过滑动窗口方式对重叠图像簇进行局部优化。

Result: 在50MP图像数据集上验证，该方法能在2秒内完成完整光束法平差，无需GPU加速，保持了精确的相机定向和高保真度映射。

Conclusion: 该方法成功实现了实时全分辨率无人机图像处理，为灾害响应、基础设施监测等应用提供了有效的解决方案。

Abstract: Real-time processing of UAV imagery is crucial for applications requiring
urgent geospatial information, such as disaster response, where rapid
decision-making and accurate spatial data are essential. However, processing
high-resolution imagery in real time presents significant challenges due to the
computational demands of feature extraction, matching, and bundle adjustment
(BA). Conventional BA methods either downsample images, sacrificing important
details, or require extensive processing time, making them unsuitable for
time-critical missions. To overcome these limitations, we propose a novel
real-time BA framework that operates directly on fullresolution UAV imagery
without downsampling. Our lightweight, onboard-compatible approach divides each
image into user-defined patches (e.g., NxN grids, default 150x150 pixels) and
dynamically tracks them across frames using UAV GNSS/IMU data and a coarse,
globally available digital surface model (DSM). This ensures spatial
consistency for robust feature extraction and matching between patches.
Overlapping relationships between images are determined in real time using UAV
navigation system, enabling the rapid selection of relevant neighbouring images
for localized BA. By limiting optimization to a sliding cluster of overlapping
images, including those from adjacent flight strips, the method achieves
real-time performance while preserving the accuracy of global BA. The proposed
algorithm is designed for seamless integration into the DLR Modular Aerial
Camera System (MACS), supporting largearea mapping in real time for disaster
response, infrastructure monitoring, and coastal protection. Validation on MACS
datasets with 50MP images demonstrates that the method maintains precise camera
orientations and high-fidelity mapping across multiple strips, running full
bundle adjustment in under 2 seconds without GPU acceleration.

</details>


### [86] [MambaOVSR: Multiscale Fusion with Global Motion Modeling for Chinese Opera Video Super-Resolution](https://arxiv.org/abs/2511.06172)
*Hua Chang,Xin Xu,Wei Liu,Wei Wang,Xin Yuan,Kui Jiang*

Main category: cs.CV

TL;DR: 提出了MambaOVSR方法，针对中国戏曲视频的超分辨率重建问题，通过多尺度融合和全局建模解决大运动场景下的视觉质量问题。


<details>
  <summary>Details</summary>
Motivation: 早期戏曲视频因拍摄设备限制存在帧率低、分辨率差等问题，传统时空超分辨率方法在处理戏曲特有的大幅度动作时效果不佳，且缺乏高质量数据集。

Method: 构建了大规模中国戏曲视频数据集COVC，提出了基于Mamba的多尺度融合网络MambaOVSR，包含全局融合模块(GFM)、多尺度协同Mamba模块(MSMM)和MambaVR块。

Result: 在COVC数据集上，MambaOVSR在PSNR指标上比现有最佳STVSR方法平均提升1.86 dB。

Conclusion: 该方法有效解决了戏曲视频超分辨率重建中的挑战，显著提升了视频质量，数据集和代码将公开。

Abstract: Chinese opera is celebrated for preserving classical art. However, early
filming equipment limitations have degraded videos of last-century performances
by renowned artists (e.g., low frame rates and resolution), hindering archival
efforts. Although space-time video super-resolution (STVSR) has advanced
significantly, applying it directly to opera videos remains challenging. The
scarcity of datasets impedes the recovery of high frequency details, and
existing STVSR methods lack global modeling capabilities, compromising visual
quality when handling opera's characteristic large motions. To address these
challenges, we pioneer a large scale Chinese Opera Video Clip (COVC) dataset
and propose the Mamba-based multiscale fusion network for space-time Opera
Video Super-Resolution (MambaOVSR). Specifically, MambaOVSR involves three
novel components: the Global Fusion Module (GFM) for motion modeling through a
multiscale alternating scanning mechanism, and the Multiscale Synergistic Mamba
Module (MSMM) for alignment across different sequence lengths. Additionally,
our MambaVR block resolves feature artifacts and positional information loss
during alignment. Experimental results on the COVC dataset show that MambaOVSR
significantly outperforms the SOTA STVSR method by an average of 1.86 dB in
terms of PSNR. Dataset and Code will be publicly released.

</details>


### [87] [NURBGen: High-Fidelity Text-to-CAD Generation through LLM-Driven NURBS Modeling](https://arxiv.org/abs/2511.06194)
*Muhammad Usama,Mohammad Sadil Khan,Didier Stricker,Muhammad Zeshan Afzal*

Main category: cs.CV

TL;DR: NURBGen是首个从文本直接生成高质量3D CAD模型的框架，使用NURBS曲面参数，通过LLM将文本转换为可编辑的CAD表示。


<details>
  <summary>Details</summary>
Motivation: 现有文本到CAD系统要么生成网格，要么依赖稀缺的设计历史数据，无法直接生成可编辑的3D CAD模型。

Method: 微调大语言模型将文本翻译为包含NURBS曲面参数的JSON表示，提出混合表示法结合未修剪NURBS和解析基元，并创建partABC数据集。

Result: 在多样化提示上表现出色，在几何保真度和尺寸精度方面超越现有方法，专家评估确认了其优势。

Conclusion: 该框架能够直接从文本生成高质量的CAD模型，代码和数据集将公开发布。

Abstract: Generating editable 3D CAD models from natural language remains challenging,
as existing text-to-CAD systems either produce meshes or rely on scarce
design-history data. We present NURBGen, the first framework to generate
high-fidelity 3D CAD models directly from text using Non-Uniform Rational
B-Splines (NURBS). To achieve this, we fine-tune a large language model (LLM)
to translate free-form texts into JSON representations containing NURBS surface
parameters (\textit{i.e}, control points, knot vectors, degrees, and rational
weights) which can be directly converted into BRep format using Python. We
further propose a hybrid representation that combines untrimmed NURBS with
analytic primitives to handle trimmed surfaces and degenerate regions more
robustly, while reducing token complexity. Additionally, we introduce partABC,
a curated subset of the ABC dataset consisting of individual CAD components,
annotated with detailed captions using an automated annotation pipeline.
NURBGen demonstrates strong performance on diverse prompts, surpassing prior
methods in geometric fidelity and dimensional accuracy, as confirmed by expert
evaluations. Code and dataset will be released publicly.

</details>


### [88] [Scene-Aware Urban Design: A Human-AI Recommendation Framework Using Co-Occurrence Embeddings and Vision-Language Models](https://arxiv.org/abs/2511.06201)
*Rodrigo Gallardo,Oz Fishman,Alexander Htet Kyaw*

Main category: cs.CV

TL;DR: 提出了一个人机协作的计算机视觉框架，利用生成式AI为公共空间提供微观设计干预建议，支持更持续的地方参与。


<details>
  <summary>Details</summary>
Motivation: 超越自上而下的总体规划，将选择基于日常模式和生活经验，让人们在选择和细化过程中保持控制权。

Method: 使用Grounding DINO和ADE20K数据集作为城市建成环境的代理，检测城市物体并构建共现嵌入，揭示常见空间配置。用户选择锚定物体后，系统提供五个统计上可能的补充对象，视觉语言模型基于场景图像和选定对建议第三个对象以完成更复杂的城市策略。

Result: 开发了一个工作流程，能够生成基于统计概率的微观设计干预建议，支持用户参与式的城市设计。

Conclusion: 该框架通过结合生成式AI和人类参与，为公共空间设计提供了新的自下而上的方法，增强了设计的本地化和参与性。

Abstract: This paper introduces a human-in-the-loop computer vision framework that uses
generative AI to propose micro-scale design interventions in public space and
support more continuous, local participation. Using Grounding DINO and a
curated subset of the ADE20K dataset as a proxy for the urban built
environment, the system detects urban objects and builds co-occurrence
embeddings that reveal common spatial configurations. From this analysis, the
user receives five statistically likely complements to a chosen anchor object.
A vision language model then reasons over the scene image and the selected pair
to suggest a third object that completes a more complex urban tactic. The
workflow keeps people in control of selection and refinement and aims to move
beyond top-down master planning by grounding choices in everyday patterns and
lived experience.

</details>


### [89] [MoRA: Missing Modality Low-Rank Adaptation for Visual Recognition](https://arxiv.org/abs/2511.06225)
*Shu Zhao,Nilesh Ahuja,Tan Yu,Tianyi Shen,Vijaykrishnan Narayanan*

Main category: cs.CV

TL;DR: MoRA是一种参数高效的微调方法，用于处理视觉语言模型中模态缺失问题，通过显式建模跨模态交互同时保持模态特定适配，在缺失模态场景下实现性能提升并显著减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 现实场景中模态可能因隐私约束、收集困难或资源限制而缺失，现有基于提示学习的方法无法有效捕捉跨模态关系且存在计算开销问题。

Method: MoRA在文本和视觉编码器之间引入模态通用参数实现双向知识迁移，同时结合模态特定参数保持跨模态交互和模态内灵活性。

Result: 在标准基准测试中，MoRA在缺失模态场景下平均性能提升5.24%，推理时间仅为SOTA方法的25.90%，可训练参数仅为全微调的0.11%。

Conclusion: MoRA通过参数高效的微调方法有效解决了模态缺失问题，在保持性能的同时显著降低了计算成本。

Abstract: Pre-trained vision language models have shown remarkable performance on
visual recognition tasks, but they typically assume the availability of
complete multimodal inputs during both training and inference. In real-world
scenarios, however, modalities may be missing due to privacy constraints,
collection difficulties, or resource limitations. While previous approaches
have addressed this challenge using prompt learning techniques, they fail to
capture the cross-modal relationships necessary for effective multimodal visual
recognition and suffer from inevitable computational overhead. In this paper,
we introduce MoRA, a parameter-efficient fine-tuning method that explicitly
models cross-modal interactions while maintaining modality-specific
adaptations. MoRA introduces modality-common parameters between text and vision
encoders, enabling bidirectional knowledge transfer. Additionally, combined
with the modality-specific parameters, MoRA allows the backbone model to
maintain inter-modality interaction and enable intra-modality flexibility.
Extensive experiments on standard benchmarks demonstrate that MoRA achieves an
average performance improvement in missing-modality scenarios by 5.24% and uses
only 25.90% of the inference time compared to the SOTA method while requiring
only 0.11% of trainable parameters compared to full fine-tuning.

</details>


### [90] [Temporal-Guided Visual Foundation Models for Event-Based Vision](https://arxiv.org/abs/2511.06238)
*Ruihao Xia,Junhong Cai,Luziwei Leng,Liuyi Wang,Chengju Liu,Ran Cheng,Yang Tang,Pan Zhou*

Main category: cs.CV

TL;DR: 提出TGVFM框架，将视觉基础模型与时间上下文融合模块结合，用于事件相机视觉任务，在语义分割、深度估计和目标检测上实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 事件相机在挑战性环境中具有独特优势，但处理异步事件流仍面临挑战。现有方法依赖专用架构或资源密集型训练，基于图像的视觉基础模型在事件视觉中的潜力尚未充分探索。

Method: TGVFM框架包含三个关键组件：长程时间注意力建模全局时间依赖、双时空注意力进行多尺度帧关联、深度特征引导机制融合语义-时间特征。通过重训练事件到视频模型并利用基于Transformer的视觉基础模型。

Result: 在语义分割、深度估计和目标检测任务上分别比现有方法提升16%、21%和16%，达到SOTA性能。

Conclusion: 这项工作解锁了基于图像的视觉基础模型在事件视觉中的跨模态潜力，实现了时间推理能力。

Abstract: Event cameras offer unique advantages for vision tasks in challenging
environments, yet processing asynchronous event streams remains an open
challenge. While existing methods rely on specialized architectures or
resource-intensive training, the potential of leveraging modern Visual
Foundation Models (VFMs) pretrained on image data remains under-explored for
event-based vision. To address this, we propose Temporal-Guided VFM (TGVFM), a
novel framework that integrates VFMs with our temporal context fusion block
seamlessly to bridge this gap. Our temporal block introduces three key
components: (1) Long-Range Temporal Attention to model global temporal
dependencies, (2) Dual Spatiotemporal Attention for multi-scale frame
correlation, and (3) Deep Feature Guidance Mechanism to fuse semantic-temporal
features. By retraining event-to-video models on real-world data and leveraging
transformer-based VFMs, TGVFM preserves spatiotemporal dynamics while
harnessing pretrained representations. Experiments demonstrate SoTA performance
across semantic segmentation, depth estimation, and object detection, with
improvements of 16%, 21%, and 16% over existing methods, respectively. Overall,
this work unlocks the cross-modality potential of image-based VFMs for
event-based vision with temporal reasoning. Code is available at
https://github.com/XiaRho/TGVFM.

</details>


### [91] [Physics-Informed Image Restoration via Progressive PDE Integration](https://arxiv.org/abs/2511.06244)
*Shamika Likhite,Santiago López-Tapia,Aggelos K. Katsaggelos*

Main category: cs.CV

TL;DR: 提出了一种结合物理先验的渐进式训练框架，通过PDE动力学增强现有去模糊架构，有效捕捉运动模糊的长距离空间依赖关系，在多个基准测试中显著提升PSNR和SSIM指标。


<details>
  <summary>Details</summary>
Motivation: 传统卷积方法受限于有限感受野，难以建模运动模糊的全局空间关系，需要引入物理先验来指导特征演化过程。

Method: 将物理信息PDE动力学集成到先进恢复架构中，利用平流-扩散方程建模特征演化，自然捕捉运动模糊的方向流特性。

Result: 在FFTformer、NAFNet、Restormer和Stripformer四种架构上均显著提升PSNR和SSIM，推理计算量仅增加约1%。

Conclusion: 通过PDE全局层融入数学物理原理能有效增强基于深度学习的图像恢复，为计算机视觉中的物理信息神经网络设计开辟了新方向。

Abstract: Motion blur, caused by relative movement between camera and scene during
exposure, significantly degrades image quality and impairs downstream computer
vision tasks such as object detection, tracking, and recognition in dynamic
environments. While deep learning-based motion deblurring methods have achieved
remarkable progress, existing approaches face fundamental challenges in
capturing the long-range spatial dependencies inherent in motion blur patterns.
Traditional convolutional methods rely on limited receptive fields and require
extremely deep networks to model global spatial relationships. These
limitations motivate the need for alternative approaches that incorporate
physical priors to guide feature evolution during restoration. In this paper,
we propose a progressive training framework that integrates physics-informed
PDE dynamics into state-of-the-art restoration architectures. By leveraging
advection-diffusion equations to model feature evolution, our approach
naturally captures the directional flow characteristics of motion blur while
enabling principled global spatial modeling. Our PDE-enhanced deblurring models
achieve superior restoration quality with minimal overhead, adding only
approximately 1\% to inference GMACs while providing consistent improvements in
perceptual quality across multiple state-of-the-art architectures.
Comprehensive experiments on standard motion deblurring benchmarks demonstrate
that our physics-informed approach improves PSNR and SSIM significantly across
four diverse architectures, including FFTformer, NAFNet, Restormer, and
Stripformer. These results validate that incorporating mathematical physics
principles through PDE-based global layers can enhance deep learning-based
image restoration, establishing a promising direction for physics-informed
neural network design in computer vision applications.

</details>


### [92] [Gait Recognition via Collaborating Discriminative and Generative Diffusion Models](https://arxiv.org/abs/2511.06245)
*Haijun Xiong,Bin Feng,Bang Wang,Xinggang Wang,Wenyu Liu*

Main category: cs.CV

TL;DR: CoD²是一个结合扩散模型数据分布建模能力和判别模型语义表示学习的新型步态识别框架，通过多级条件控制策略实现身份一致的步态序列生成和特征提取。


<details>
  <summary>Details</summary>
Motivation: 虽然判别模型在步态识别领域取得了显著成功，但生成模型的潜力尚未充分探索。作者希望结合扩散模型和判别模型的优势来提取更鲁棒的步态特征。

Method: 提出多级条件控制策略：高层条件（身份感知语义）指导生成身份一致的步态序列，低层条件（外观和运动细节）保持视觉一致性。生成的序列反过来促进判别提取器学习更全面的高层语义特征。

Result: 在四个数据集（SUSTech1K、CCPG、GREW、Gait3D）上的实验表明，CoD²达到了最先进的性能，并能与现有判别方法无缝集成，带来一致改进。

Conclusion: CoD²框架成功融合了生成和判别模型的优势，为步态识别提供了有效的解决方案，展示了生成模型在该领域的巨大潜力。

Abstract: Gait recognition offers a non-intrusive biometric solution by identifying
individuals through their walking patterns. Although discriminative models have
achieved notable success in this domain, the full potential of generative
models remains largely underexplored. In this paper, we introduce
\textbf{CoD$^2$}, a novel framework that combines the data distribution
modeling capabilities of diffusion models with the semantic representation
learning strengths of discriminative models to extract robust gait features. We
propose a Multi-level Conditional Control strategy that incorporates both
high-level identity-aware semantic conditions and low-level visual details.
Specifically, the high-level condition, extracted by the discriminative
extractor, guides the generation of identity-consistent gait sequences, whereas
low-level visual details, such as appearance and motion, are preserved to
enhance consistency. Furthermore, the generated sequences facilitate the
discriminative extractor's learning, enabling it to capture more comprehensive
high-level semantic features. Extensive experiments on four datasets
(SUSTech1K, CCPG, GREW, and Gait3D) demonstrate that CoD$^2$ achieves
state-of-the-art performance and can be seamlessly integrated with existing
discriminative methods, yielding consistent improvements.

</details>


### [93] [AdaDrive: Self-Adaptive Slow-Fast System for Language-Grounded Autonomous Driving](https://arxiv.org/abs/2511.06253)
*Ruifei Zhang,Junlin Xie,Wei Zhang,Weikai Chen,Xiao Tan,Xiang Wan,Guanbin Li*

Main category: cs.CV

TL;DR: AdaDrive是一个自适应协作的慢快框架，通过动态确定何时以及如何让LLM参与决策，平衡自动驾驶中高级推理和实时效率的需求。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么频繁激活LLM导致计算开销过大，要么使用固定调度无法适应动态驾驶条件，需要解决这些挑战。

Method: 1) 自适应激活机制：基于比较学习动态确定LLM调用时机；2) 自适应融合策略：根据场景复杂度和预测置信度调节LLM的连续影响程度。

Result: 在语言基础自动驾驶基准测试中，AdaDrive在驾驶准确性和计算效率方面都达到了最先进的性能。

Conclusion: AdaDrive提供了一个灵活、上下文感知的框架，在不影响实时性能的情况下最大化决策准确性。

Abstract: Effectively integrating Large Language Models (LLMs) into autonomous driving
requires a balance between leveraging high-level reasoning and maintaining
real-time efficiency. Existing approaches either activate LLMs too frequently,
causing excessive computational overhead, or use fixed schedules, failing to
adapt to dynamic driving conditions. To address these challenges, we propose
AdaDrive, an adaptively collaborative slow-fast framework that optimally
determines when and how LLMs contribute to decision-making. (1) When to
activate the LLM: AdaDrive employs a novel adaptive activation loss that
dynamically determines LLM invocation based on a comparative learning
mechanism, ensuring activation only in complex or critical scenarios. (2) How
to integrate LLM assistance: Instead of rigid binary activation, AdaDrive
introduces an adaptive fusion strategy that modulates a continuous, scaled LLM
influence based on scene complexity and prediction confidence, ensuring
seamless collaboration with conventional planners. Through these strategies,
AdaDrive provides a flexible, context-aware framework that maximizes decision
accuracy without compromising real-time performance. Extensive experiments on
language-grounded autonomous driving benchmarks demonstrate that AdaDrive
state-of-the-art performance in terms of both driving accuracy and
computational efficiency. Code is available at
https://github.com/ReaFly/AdaDrive.

</details>


### [94] [VLDrive: Vision-Augmented Lightweight MLLMs for Efficient Language-grounded Autonomous Driving](https://arxiv.org/abs/2511.06256)
*Ruifei Zhang,Wei Zhang,Xiao Tan,Sibei Yang,Xiang Wan,Xiaonan Luo,Guanbin Li*

Main category: cs.CV

TL;DR: VLDrive是一种轻量级多模态大语言模型架构，通过创新的视觉剪枝和特征聚合技术，显著减少参数量的同时提升自动驾驶性能。


<details>
  <summary>Details</summary>
Motivation: 解决当前LLM方法在自动驾驶中存在的两大挑战：视觉表示不足导致的碰撞和障碍问题，以及LLM参数过大带来的部署困难。

Method: 采用轻量级MLLM架构，包含循环一致性动态视觉剪枝、内存增强特征聚合和距离解耦指令注意力机制。

Result: 在CARLA模拟器中实现SOTA性能，参数减少81%（从7B到1.3B），在闭环评估中驾驶分数分别提升15.4%（短距离）、16.8%（中距离）和7.6%（长距离）。

Conclusion: VLDrive证明了轻量级架构在语言驱动的自动驾驶中的有效性，平衡了性能与部署效率。

Abstract: Recent advancements in language-grounded autonomous driving have been
significantly promoted by the sophisticated cognition and reasoning
capabilities of large language models (LLMs). However, current LLM-based
approaches encounter critical challenges: (1) Failure analysis reveals that
frequent collisions and obstructions, stemming from limitations in visual
representations, remain primary obstacles to robust driving performance. (2)
The substantial parameters of LLMs pose considerable deployment hurdles. To
address these limitations, we introduce VLDrive, a novel approach featuring a
lightweight MLLM architecture with enhanced vision components. VLDrive achieves
compact visual tokens through innovative strategies, including cycle-consistent
dynamic visual pruning and memory-enhanced feature aggregation. Furthermore, we
propose a distance-decoupled instruction attention mechanism to improve joint
visual-linguistic feature learning, particularly for long-range visual tokens.
Extensive experiments conducted in the CARLA simulator demonstrate VLDrive`s
effectiveness. Notably, VLDrive achieves state-of-the-art driving performance
while reducing parameters by 81% (from 7B to 1.3B), yielding substantial
driving score improvements of 15.4%, 16.8%, and 7.6% at tiny, short, and long
distances, respectively, in closed-loop evaluations. Code is available at
https://github.com/ReaFly/VLDrive.

</details>


### [95] [Robust Nearest Neighbour Retrieval Using Targeted Manifold Manipulation](https://arxiv.org/abs/2511.06261)
*B. Ghosh,H. Harikumar,S. Rana*

Main category: cs.CV

TL;DR: TMM-NN是一种新的最近邻检索方法，通过评估样本对目标扰动的响应程度来定义邻域，而非传统的几何距离。该方法使用轻量级的查询特定触发补丁来引导样本向虚拟类别移动，从而实现更鲁棒的语义检索。


<details>
  <summary>Details</summary>
Motivation: 传统的最近邻检索依赖于手动调整特征层和距离度量，存在对噪声敏感和语义理解不足的问题。作者希望开发一种更鲁棒、语义感知的检索方法。

Method: 提出TMM-NN方法：1）为查询图像生成轻量级触发补丁；2）将网络弱"后门化"，使带有补丁的输入被引导到虚拟类别；3）通过样本对补丁的响应程度（被分类为虚拟类别的概率）来定义相似性。

Result: 鲁棒性分析和基准实验表明，基于触发补丁的排序方法在噪声环境下优于传统度量，并在多样化任务中表现更好。

Conclusion: TMM-NN通过重新定义邻域概念，基于样本对目标扰动的响应性进行检索，提供了一种更语义感知和鲁棒的最近邻检索方法。

Abstract: Nearest-neighbour retrieval is central to classification and explainable-AI
pipelines, but current practice relies on hand-tuning feature layers and
distance metrics. We propose Targeted Manifold Manipulation-Nearest Neighbour
(TMM-NN), which reconceptualises retrieval by assessing how readily each sample
can be nudged into a designated region of the feature manifold; neighbourhoods
are defined by a sample's responsiveness to a targeted perturbation rather than
absolute geometric distance. TMM-NN implements this through a lightweight,
query-specific trigger patch. The patch is added to the query image, and the
network is weakly ``backdoored'' so that any input with the patch is steered
toward a dummy class. Images similar to the query need only a slight shift and
are classified as the dummy class with high probability, while dissimilar ones
are less affected. By ranking candidates by this confidence, TMM-NN retrieves
the most semantically related neighbours. Robustness analysis and benchmark
experiments confirm this trigger-based ranking outperforms traditional metrics
under noise and across diverse tasks.

</details>


### [96] [A Mixture-of-Experts Framework with Log-Logistic Components for Survival Analysis on Histopathology Images](https://arxiv.org/abs/2511.06266)
*Ardhendu Sekhar,Vasu Soni,Keshav Aske,Shivam Madnoorkar,Pranav Jeevan,Amit Sethi*

Main category: cs.CV

TL;DR: 提出了一种模块化框架，用于从全切片病理图像预测癌症特异性生存率，包含四个关键组件：分位数门控补丁选择、图引导聚类、分层上下文注意力和专家驱动的混合对数逻辑分布框架，在多个癌症数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的癌症生存预测方法通常无法充分捕捉病理图像中的预后信息异质性和复杂的生存分布模式，需要一种更全面的框架来整合空间、形态和层次信息。

Method: 采用四模块集成方法：1) 分位数门控补丁选择通过分位数阈值分离预后信息组织区域；2) 图引导聚类使用k近邻图捕获表型异质性；3) 分层上下文注意力学习簇内和簇间交互；4) 专家驱动的混合对数逻辑分布框架估计复杂生存分布。

Result: 在TCGA LUAD数据集上获得0.644的C指数，TCGA KIRC上0.751，TCGA BRCA上0.752，均优于现有最先进方法。

Conclusion: 该模块化框架能够有效整合病理图像的多层次信息，显著提升癌症特异性生存预测性能，为临床预后评估提供了更准确的工具。

Abstract: We propose a modular framework for predicting cancer specific survival from
whole slide pathology images (WSIs). The method integrates four components: (i)
Quantile Gated Patch Selection via quantile based thresholding to isolate
prognostically informative tissue regions; (ii) Graph Guided Clustering using a
k nearest neighbor graph to capture phenotype level heterogeneity through
spatial and morphological coherence; (iii) Hierarchical Context Attention to
learn intra and inter cluster interactions; and (iv) an Expert Driven Mixture
of Log logistics framework to estimate complex survival distributions using Log
logistics distributions. The model attains a concordance index of 0.644 on TCGA
LUAD, 0.751 on TCGA KIRC, and 0.752 on TCGA BRCA respectively, outperforming
existing state of the art approaches.

</details>


### [97] [LLM-Driven Completeness and Consistency Evaluation for Cultural Heritage Data Augmentation in Cross-Modal Retrieval](https://arxiv.org/abs/2511.06268)
*Jian Zhang,Junyi Guo,Junyi Yuan,Huanda Lu,Yanlin Zhou,Fangyu Wu,Qiufeng Wang,Dongming Lu*

Main category: cs.CV

TL;DR: 提出了C³框架，通过提升LLM生成描述的完整性和一致性来增强跨模态检索性能，在文化遗产和通用数据集上均取得SOTA结果


<details>
  <summary>Details</summary>
Motivation: 解决文化遗产数据中文本描述不完整、不一致的问题，以及LLM生成描述存在幻觉和视觉细节缺失的挑战

Method: 引入完整性评估模块和基于马尔可夫决策过程的Chain-of-Thought监督机制，通过自适应查询控制来指导一致性评估

Result: 在CulTi、TimeTravel文化遗产数据集以及MSCOCO、Flickr30K通用基准上，C³在微调和零样本设置下均达到最先进性能

Conclusion: C³框架有效解决了文化遗产数据跨模态检索中的描述质量问题，为LLM在文化遗产领域的应用提供了可靠解决方案

Abstract: Cross-modal retrieval is essential for interpreting cultural heritage data,
but its effectiveness is often limited by incomplete or inconsistent textual
descriptions, caused by historical data loss and the high cost of expert
annotation. While large language models (LLMs) offer a promising solution by
enriching textual descriptions, their outputs frequently suffer from
hallucinations or miss visually grounded details. To address these challenges,
we propose $C^3$, a data augmentation framework that enhances cross-modal
retrieval performance by improving the completeness and consistency of
LLM-generated descriptions. $C^3$ introduces a completeness evaluation module
to assess semantic coverage using both visual cues and language-model outputs.
Furthermore, to mitigate factual inconsistencies, we formulate a Markov
Decision Process to supervise Chain-of-Thought reasoning, guiding consistency
evaluation through adaptive query control. Experiments on the cultural heritage
datasets CulTi and TimeTravel, as well as on general benchmarks MSCOCO and
Flickr30K, demonstrate that $C^3$ achieves state-of-the-art performance in both
fine-tuned and zero-shot settings.

</details>


### [98] [RelightMaster: Precise Video Relighting with Multi-plane Light Images](https://arxiv.org/abs/2511.06271)
*Weikang Bian,Xiaoyu Shi,Zhaoyang Huang,Jianhong Bai,Qinghe Wang,Xintao Wang,Pengfei Wan,Kun Gai,Hongsheng Li*

Main category: cs.CV

TL;DR: RelightMaster是一个用于视频精确重照明的创新框架，通过构建RelightVideo数据集和引入多平面光照图像(MPLI)视觉提示，解决了现有文本到视频模型在光照控制方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有文本到视频模型缺乏细粒度的光照控制能力，文本描述难以精确表达光照细节，且训练数据中光照相关提示不足。高质量重照明训练数据的构建也面临挑战。

Method: 1) 基于Unreal Engine构建RelightVideo数据集；2) 提出多平面光照图像(MPLI)作为视觉提示；3) 设计光照图像适配器将MPLI注入预训练的视频扩散变换器。

Result: 实验表明RelightMaster能够生成物理合理的光照和阴影，同时保持原始场景内容的一致性。

Conclusion: 该框架为视频重照明提供了有效的解决方案，支持多光源场景并能泛化到未见过的光照设置。

Abstract: Recent advances in diffusion models enable high-quality video generation and
editing, but precise relighting with consistent video contents, which is
critical for shaping scene atmosphere and viewer attention, remains unexplored.
Mainstream text-to-video (T2V) models lack fine-grained lighting control due to
text's inherent limitation in describing lighting details and insufficient
pre-training on lighting-related prompts. Additionally, constructing
high-quality relighting training data is challenging, as real-world
controllable lighting data is scarce. To address these issues, we propose
RelightMaster, a novel framework for accurate and controllable video
relighting. First, we build RelightVideo, the first dataset with identical
dynamic content under varying precise lighting conditions based on the Unreal
Engine. Then, we introduce Multi-plane Light Image (MPLI), a novel visual
prompt inspired by Multi-Plane Image (MPI). MPLI models lighting via K
depth-aligned planes, representing 3D light source positions, intensities, and
colors while supporting multi-source scenarios and generalizing to unseen light
setups. Third, we design a Light Image Adapter that seamlessly injects MPLI
into pre-trained Video Diffusion Transformers (DiT): it compresses MPLI via a
pre-trained Video VAE and injects latent light features into DiT blocks,
leveraging the base model's generative prior without catastrophic forgetting.
Experiments show that RelightMaster generates physically plausible lighting and
shadows and preserves original scene content. Demos are available at
https://wkbian.github.io/Projects/RelightMaster/.

</details>


### [99] [LaneDiffusion: Improving Centerline Graph Learning via Prior Injected BEV Feature Generation](https://arxiv.org/abs/2511.06272)
*Zijie Wang,Weiming Zhang,Wei Zhang,Xiao Tan,Hongxing Liu,Yaowei Wang,Guanbin Li*

Main category: cs.CV

TL;DR: LaneDiffusion提出了一种基于扩散模型的中心线图生成新方法，通过BEV特征级别的扩散生成先验，解决了传统确定性方法在空间推理和遮挡处理方面的不足。


<details>
  <summary>Details</summary>
Motivation: 传统确定性方法在自动驾驶路径规划中缺乏空间推理能力，难以处理被遮挡或不可见的中心线。生成式方法在此领域尚未充分探索，具有巨大潜力。

Method: LaneDiffusion创新性地使用扩散模型在BEV特征级别生成车道中心线先验，包含车道先验注入模块(LPIM)和车道先验扩散模块(LPDM)，然后从这些先验注入的BEV特征解码向量化中心线和拓扑结构。

Result: 在nuScenes和Argoverse2数据集上的评估显示，LaneDiffusion在点级指标(GEO F1, TOPO F1等)和段级指标(IoU, mAP_cf等)上均显著优于现有方法，实现了最先进的性能。

Conclusion: 该方法为中心线图学习任务提供了新的生成模型思路，证明了扩散模型在此领域的有效性，为自动驾驶路径规划提供了更强大的解决方案。

Abstract: Centerline graphs, crucial for path planning in autonomous driving, are
traditionally learned using deterministic methods. However, these methods often
lack spatial reasoning and struggle with occluded or invisible centerlines.
Generative approaches, despite their potential, remain underexplored in this
domain. We introduce LaneDiffusion, a novel generative paradigm for centerline
graph learning. LaneDiffusion innovatively employs diffusion models to generate
lane centerline priors at the Bird's Eye View (BEV) feature level, instead of
directly predicting vectorized centerlines. Our method integrates a Lane Prior
Injection Module (LPIM) and a Lane Prior Diffusion Module (LPDM) to effectively
construct diffusion targets and manage the diffusion process. Furthermore,
vectorized centerlines and topologies are then decoded from these
prior-injected BEV features. Extensive evaluations on the nuScenes and
Argoverse2 datasets demonstrate that LaneDiffusion significantly outperforms
existing methods, achieving improvements of 4.2%, 4.6%, 4.7%, 6.4% and 1.8% on
fine-grained point-level metrics (GEO F1, TOPO F1, JTOPO F1, APLS and SDA) and
2.3%, 6.4%, 6.8% and 2.1% on segment-level metrics (IoU, mAP_cf, DET_l and
TOP_ll). These results establish state-of-the-art performance in centerline
graph learning, offering new insights into generative models for this task.

</details>


### [100] [VideoSSR: Video Self-Supervised Reinforcement Learning](https://arxiv.org/abs/2511.06281)
*Zefeng He,Xiaoye Qu,Yafu Li,Siyuan Huang,Daizong Liu,Yu Cheng*

Main category: cs.CV

TL;DR: 该论文提出了一种名为VideoSSR的自监督强化学习框架，通过利用视频内在信息自动生成可验证的训练数据，解决了高质量视频数据标注成本高昂的问题。


<details>
  <summary>Details</summary>
Motivation: 现有视频数据集的复杂性跟不上多模态大语言模型的发展速度，而人工标注高质量新数据成本过高。论文旨在探索是否可以利用视频内在信息自生成高质量、可验证的训练数据。

Method: 提出了三种自监督预训练任务（异常定位、物体计数和时间拼图），构建了VideoSSR-30K数据集，并开发了VideoSSR视频自监督强化学习框架。

Result: 在17个基准测试中，VideoSSR在四个主要视频理解领域（通用视频问答、长视频问答、时间定位和复杂推理）上平均提升模型性能超过5%。

Conclusion: VideoSSR为开发更先进的MLLM视频理解能力提供了一个强大的基础框架，证明了自监督方法在视频理解领域的有效性。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has substantially
advanced the video understanding capabilities of Multimodal Large Language
Models (MLLMs). However, the rapid progress of MLLMs is outpacing the
complexity of existing video datasets, while the manual annotation of new,
high-quality data remains prohibitively expensive. This work investigates a
pivotal question: Can the rich, intrinsic information within videos be
harnessed to self-generate high-quality, verifiable training data? To
investigate this, we introduce three self-supervised pretext tasks: Anomaly
Grounding, Object Counting, and Temporal Jigsaw. We construct the Video
Intrinsic Understanding Benchmark (VIUBench) to validate their difficulty,
revealing that current state-of-the-art MLLMs struggle significantly on these
tasks. Building upon these pretext tasks, we develop the VideoSSR-30K dataset
and propose VideoSSR, a novel video self-supervised reinforcement learning
framework for RLVR. Extensive experiments across 17 benchmarks, spanning four
major video domains (General Video QA, Long Video QA, Temporal Grounding, and
Complex Reasoning), demonstrate that VideoSSR consistently enhances model
performance, yielding an average improvement of over 5\%. These results
establish VideoSSR as a potent foundational framework for developing more
advanced video understanding in MLLMs. The code is available at
https://github.com/lcqysl/VideoSSR.

</details>


### [101] [From ACR O-RADS 2022 to Explainable Deep Learning: Comparative Performance of Expert Radiologists, Convolutional Neural Networks, Vision Transformers, and Fusion Models in Ovarian Masses](https://arxiv.org/abs/2511.06282)
*Ali Abbasian Ardakani,Afshin Mohammadi,Alisa Mohebbi,Anushya Vijayananthan,Sook Sam Leong,Lim Yi Ting,Mohd Kamil Bin Mohamad Fabell,U Rajendra Acharya,Sepideh Hatamikia*

Main category: cs.CV

TL;DR: 该研究评估了放射科医生应用O-RADS v2022系统的表现，并与深度学习模型进行比较，发现深度学习模型显著优于人工评估，人机混合框架能进一步提高诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 人类对卵巢附件病变的超声分类存在变异性，而深度学习模型在卵巢病变表征方面显示出潜力，需要评估人工与AI方法的性能差异及人机协作的价值。

Method: 单中心回顾性队列研究，包含512个附件肿块图像，训练了16个深度学习模型（包括CNN和ViT），并构建了结合放射科医生评分与AI预测概率的混合模型。

Result: 放射科医生单独评估的AUC为0.683，准确率68.0%；CNN模型AUC为0.620-0.908，准确率59.2%-86.4%；ViT模型表现最佳（AUC 0.941，准确率87.4%）；人机混合框架显著提升了CNN模型性能。

Conclusion: 深度学习模型显著优于放射科医生的O-RADS评估，人机混合框架能获得最高诊断准确性，具有标准化盆腔超声解读、减少假阳性和改善高危病变检测的潜力。

Abstract: Background: The 2022 update of the Ovarian-Adnexal Reporting and Data System
(O-RADS) ultrasound classification refines risk stratification for adnexal
lesions, yet human interpretation remains subject to variability and
conservative thresholds. Concurrently, deep learning (DL) models have
demonstrated promise in image-based ovarian lesion characterization. This study
evaluates radiologist performance applying O-RADS v2022, compares it to leading
convolutional neural network (CNN) and Vision Transformer (ViT) models, and
investigates the diagnostic gains achieved by hybrid human-AI frameworks.
Methods: In this single-center, retrospective cohort study, a total of 512
adnexal mass images from 227 patients (110 with at least one malignant cyst)
were included. Sixteen DL models, including DenseNets, EfficientNets, ResNets,
VGGs, Xception, and ViTs, were trained and validated. A hybrid model
integrating radiologist O-RADS scores with DL-predicted probabilities was also
built for each scheme. Results: Radiologist-only O-RADS assessment achieved an
AUC of 0.683 and an overall accuracy of 68.0%. CNN models yielded AUCs of 0.620
to 0.908 and accuracies of 59.2% to 86.4%, while ViT16-384 reached the best
performance, with an AUC of 0.941 and an accuracy of 87.4%. Hybrid human-AI
frameworks further significantly enhanced the performance of CNN models;
however, the improvement for ViT models was not statistically significant
(P-value >0.05). Conclusions: DL models markedly outperform radiologist-only
O-RADS v2022 assessment, and the integration of expert scores with AI yields
the highest diagnostic accuracy and discrimination. Hybrid human-AI paradigms
hold substantial potential to standardize pelvic ultrasound interpretation,
reduce false positives, and improve detection of high-risk lesions.

</details>


### [102] [TinyChemVL: Advancing Chemical Vision-Language Models via Efficient Visual Token Reduction and Complex Reaction Tasks](https://arxiv.org/abs/2511.06283)
*Xuanle Zhao,Shuxin Zeng,Yinyuan Cai,Xiang Cheng,Duzhen Zhang,Xiuyi Chen,Bo Xu*

Main category: cs.CV

TL;DR: TinyChemVL是一个高效化学视觉语言模型，通过视觉令牌减少和反应级任务提升效率和推理能力，在仅4B参数下超越现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有化学VLMs存在计算效率低（处理含非信息背景的化学图像）和任务范围窄（仅关注分子级任务）的问题，限制了化学推理的发展。

Method: 提出TinyChemVL模型，采用视觉令牌减少技术和反应级任务设计；同时构建ChemRxn-V基准用于评估视觉反应识别和预测任务。

Result: TinyChemVL在仅4B参数下，在分子和反应任务上均表现优异，推理和训练速度更快，仅使用1/16视觉令牌就超越ChemVLM。

Conclusion: 通过模型架构和任务复杂度的协同设计，成功构建了高效且强大的化学领域VLMs。

Abstract: While Vision Language Models (VLMs) have demonstrated remarkable capabilities
in general visual understanding, their application in the chemical domain has
been limited, with previous works predominantly focusing on text and thus
overlooking critical visual information, such as molecular structures. Current
approaches that directly adopt standard VLMs for chemical tasks suffer from two
primary issues: (i) computational inefficiency of processing entire chemical
images with non-informative backgrounds. (ii) a narrow scope on molecular-level
tasks that restricts progress in chemical reasoning. In this work, we propose
\textbf{TinyChemVL}, an efficient and powerful chemical VLM that leverages
visual token reduction and reaction-level tasks to improve model efficiency and
reasoning capacity. Also, we propose \textbf{ChemRxn-V}, a reaction-level
benchmark for assessing vision-based reaction recognition and prediction tasks.
Directly predicting reaction products from molecular images poses a non-trivial
challenge, as it requires models to integrate both recognition and reasoning
capacities. Our results demonstrate that with only 4B parameters, TinyChemVL
achieves superior performance on both molecular and reaction tasks while
demonstrating faster inference and training speeds compared to existing models.
Notably, TinyChemVL outperforms ChemVLM while utilizing only 1/16th of the
visual tokens. This work builds efficient yet powerful VLMs for chemical
domains by co-designing model architecture and task complexity.

</details>


### [103] [Enhancing Multimodal Misinformation Detection by Replaying the Whole Story from Image Modality Perspective](https://arxiv.org/abs/2511.06284)
*Bing Wang,Ximing Li,Yanjun Wang,Changchun Li,Lin Yuanbo Wu,Buyu Wang,Shengsheng Wang*

Main category: cs.CV

TL;DR: 本文提出RETSIMD方法，通过将文本分割成多个片段并利用预训练的文本-图像生成器生成图像序列，结合图神经网络进行多模态虚假信息检测，实验证明该方法有效。


<details>
  <summary>Details</summary>
Motivation: 研究发现多模态虚假信息检测中文本模态比图像模态更具信息量，因为文本通常描述完整事件而图像仅呈现部分场景，初步实验表明图像模态贡献较小。

Method: 将文本分割成多个片段，使用预训练文本-图像生成器生成对应图像序列，引入文本-图像和图像-标签互信息辅助目标，通过图神经网络融合图像特征。

Result: 大量实验结果表明RETSIMD方法在多模态虚假信息检测任务上表现有效。

Conclusion: 基于文本模态在虚假信息检测中的主导作用，提出的RETSIMD方法通过文本引导的图像生成和图结构融合策略，显著提升了检测性能。

Abstract: Multimodal Misinformation Detection (MMD) refers to the task of detecting
social media posts involving misinformation, where the post often contains text
and image modalities. However, by observing the MMD posts, we hold that the
text modality may be much more informative than the image modality because the
text generally describes the whole event/story of the current post but the
image often presents partial scenes only. Our preliminary empirical results
indicate that the image modality exactly contributes less to MMD. Upon this
idea, we propose a new MMD method named RETSIMD. Specifically, we suppose that
each text can be divided into several segments, and each text segment describes
a partial scene that can be presented by an image. Accordingly, we split the
text into a sequence of segments, and feed these segments into a pre-trained
text-to-image generator to augment a sequence of images. We further incorporate
two auxiliary objectives concerning text-image and image-label mutual
information, and further post-train the generator over an auxiliary
text-to-image generation benchmark dataset. Additionally, we propose a graph
structure by defining three heuristic relationships between images, and use a
graph neural network to generate the fused features. Extensive empirical
results validate the effectiveness of RETSIMD.

</details>


### [104] [Learning-Based Vision Systems for Semi-Autonomous Forklift Operation in Industrial Warehouse Environments](https://arxiv.org/abs/2511.06295)
*Vamshika Sutar,Mahek Maheshwari,Archak Mittal*

Main category: cs.CV

TL;DR: 提出基于视觉的货盘和货盘孔检测与映射框架，使用YOLOv8和YOLOv11架构，通过超参数优化和空间后处理提升检测精度，实现低成本、可扩展的仓库自动化感知系统。


<details>
  <summary>Details</summary>
Motivation: 仓库自动化对低成本、鲁棒的感知系统需求日益增长，特别是叉车和自动导引车的货盘处理需要准确的视觉检测能力。

Method: 使用单目标准摄像头，采用YOLOv8和YOLOv11架构，结合Optuna驱动的超参数优化和空间后处理，开发创新的货盘孔映射模块将检测结果转换为可操作的空间表示。

Result: 在自定义数据集上的实验显示，YOLOv8实现高精度检测，YOLOv11在优化配置下提供更优的精度和稳定收敛性，验证了低成本视觉感知模块的可行性。

Conclusion: 该研究为仓库自动化提供了一种可扩展的方法，促进了更安全、经济、智能的物流操作，展示了低成本视觉感知系统的实用价值。

Abstract: The automation of material handling in warehouses increasingly relies on
robust, low cost perception systems for forklifts and Automated Guided Vehicles
(AGVs). This work presents a vision based framework for pallet and pallet hole
detection and mapping using a single standard camera. We utilized YOLOv8 and
YOLOv11 architectures, enhanced through Optuna driven hyperparameter
optimization and spatial post processing. An innovative pallet hole mapping
module converts the detections into actionable spatial representations,
enabling accurate pallet and pallet hole association for forklift operation.
Experiments on a custom dataset augmented with real warehouse imagery show that
YOLOv8 achieves high pallet and pallet hole detection accuracy, while YOLOv11,
particularly under optimized configurations, offers superior precision and
stable convergence. The results demonstrate the feasibility of a cost
effective, retrofittable visual perception module for forklifts. This study
proposes a scalable approach to advancing warehouse automation, promoting
safer, economical, and intelligent logistics operations.

</details>


### [105] [SFFR: Spatial-Frequency Feature Reconstruction for Multispectral Aerial Object Detection](https://arxiv.org/abs/2511.06298)
*Xin Zuo,Yuchen Qu,Haibo Zhan,Jifeng Shen,Wankou Yang*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的空间和频率特征重建方法（SFFR），利用Kolmogorov-Arnold网络的空间-频率特征表示机制，在特征融合前重建空间和频率域的互补表示。


<details>
  <summary>Details</summary>
Motivation: 当前多光谱目标检测方法主要关注基于CNN或Transformer的空间域特征融合，而频率域特征的潜力尚未充分探索。

Method: SFFR方法包含两个核心模块：频率成分交换KAN（FCEKAN）模块和多尺度高斯KAN（MSGKAN）模块。FCEKAN采用选择性频率成分交换策略增强跨模态特征的互补性和一致性；MSGKAN利用多尺度高斯基函数捕捉不同无人机飞行高度引起的尺度变化特征。

Result: 在SeaDroneSee、DroneVehicle和DVTOD数据集上的实验表明，该方法在无人机多光谱目标感知任务中具有优越性能和显著优势。

Conclusion: FCEKAN和MSGKAN模块互补，能有效分别捕捉频率和空间语义特征，实现更好的特征融合。

Abstract: Recent multispectral object detection methods have primarily focused on
spatial-domain feature fusion based on CNNs or Transformers, while the
potential of frequency-domain feature remains underexplored. In this work, we
propose a novel Spatial and Frequency Feature Reconstruction method (SFFR)
method, which leverages the spatial-frequency feature representation mechanisms
of the Kolmogorov-Arnold Network (KAN) to reconstruct complementary
representations in both spatial and frequency domains prior to feature fusion.
The core components of SFFR are the proposed Frequency Component Exchange KAN
(FCEKAN) module and Multi-Scale Gaussian KAN (MSGKAN) module. The FCEKAN
introduces an innovative selective frequency component exchange strategy that
effectively enhances the complementarity and consistency of cross-modal
features based on the frequency feature of RGB and IR images. The MSGKAN module
demonstrates excellent nonlinear feature modeling capability in the spatial
domain. By leveraging multi-scale Gaussian basis functions, it effectively
captures the feature variations caused by scale changes at different UAV flight
altitudes, significantly enhancing the model's adaptability and robustness to
scale variations. It is experimentally validated that our proposed FCEKAN and
MSGKAN modules are complementary and can effectively capture the frequency and
spatial semantic features respectively for better feature fusion. Extensive
experiments on the SeaDroneSee, DroneVehicle and DVTOD datasets demonstrate the
superior performance and significant advantages of the proposed method in UAV
multispectral object perception task. Code will be available at
https://github.com/qchenyu1027/SFFR.

</details>


### [106] [Physics-Informed Deformable Gaussian Splatting: Towards Unified Constitutive Laws for Time-Evolving Material Field](https://arxiv.org/abs/2511.06299)
*Haoqin Hong,Ding Fan,Fubin Dou,Zhi-Li Zhou,Haoran Sun,Congcong Zhu,Jingrun Chen*

Main category: cs.CV

TL;DR: 提出PIDG方法，将3D高斯粒子视为拉格朗日材料点，通过物理约束和光学流监督来提升动态场景重建的物理一致性


<details>
  <summary>Details</summary>
Motivation: 纯数据驱动的3D高斯泼溅在捕捉动态场景中多样化的物理驱动运动模式方面存在困难

Method: 采用静态-动态解耦的4D分解哈希编码重建几何和运动，施加柯西动量残差作为物理约束，通过时间演化的材料场预测粒子速度和本构应力，并用拉格朗日粒子流与相机补偿光学流匹配进行数据监督

Result: 在自定义物理驱动数据集以及标准合成和真实世界数据集上实验显示，物理一致性和单目动态重建质量显著提升

Conclusion: PIDG方法通过引入物理约束和光学流监督，有效提升了动态场景重建的物理准确性和泛化能力

Abstract: Recently, 3D Gaussian Splatting (3DGS), an explicit scene representation
technique, has shown significant promise for dynamic novel-view synthesis from
monocular video input. However, purely data-driven 3DGS often struggles to
capture the diverse physics-driven motion patterns in dynamic scenes. To fill
this gap, we propose Physics-Informed Deformable Gaussian Splatting (PIDG),
which treats each Gaussian particle as a Lagrangian material point with
time-varying constitutive parameters and is supervised by 2D optical flow via
motion projection. Specifically, we adopt static-dynamic decoupled 4D
decomposed hash encoding to reconstruct geometry and motion efficiently.
Subsequently, we impose the Cauchy momentum residual as a physics constraint,
enabling independent prediction of each particle's velocity and constitutive
stress via a time-evolving material field. Finally, we further supervise data
fitting by matching Lagrangian particle flow to camera-compensated optical
flow, which accelerates convergence and improves generalization. Experiments on
a custom physics-driven dataset as well as on standard synthetic and real-world
datasets demonstrate significant gains in physical consistency and monocular
dynamic reconstruction quality.

</details>


### [107] [Adaptive 3D Reconstruction via Diffusion Priors and Forward Curvature-Matching Likelihood Updates](https://arxiv.org/abs/2511.06310)
*Seunghyeok Shin,Dabin Kim,Hongki Lim*

Main category: cs.CV

TL;DR: 该论文提出了一种新的Forward Curvature-Matching (FCM)方法，用于改进基于扩散模型的点云重建技术，通过动态优化步长提高重建质量和效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的点云重建方法存在灵活性不足的问题：需要训练时的条件信号、仅支持固定数量的输入视图，且对不同测量方式需要重新训练。现有方法使用启发式固定步长进行似然更新，导致收敛慢和重建质量不理想。

Method: 提出Forward Curvature-Matching (FCM)更新方法，结合扩散采样，仅使用前向自动微分和有限差分曲率估计来动态确定最优步长，实现似然更新的精确优化。

Result: 在ShapeNet和CO3D数据集上的实验表明，该方法在相同或更少的NFEs下实现了更优的重建质量，获得了更高的F-score和更低的CD和EMD指标。

Conclusion: FCM方法验证了其在点云重建中的高效性和适应性，支持单视图和多视图输入，并能通过简单算子替换支持多种输入模态，无需重新训练。

Abstract: Reconstructing high-quality point clouds from images remains challenging in
computer vision. Existing generative-model-based approaches, particularly
diffusion-model approaches that directly learn the posterior, may suffer from
inflexibility -- they require conditioning signals during training, support
only a fixed number of input views, and need complete retraining for different
measurements. Recent diffusion-based methods have attempted to address this by
combining prior models with likelihood updates, but they rely on heuristic
fixed step sizes for the likelihood update that lead to slow convergence and
suboptimal reconstruction quality. We advance this line of approach by
integrating our novel Forward Curvature-Matching (FCM) update method with
diffusion sampling. Our method dynamically determines optimal step sizes using
only forward automatic differentiation and finite-difference curvature
estimates, enabling precise optimization of the likelihood update. This
formulation enables high-fidelity reconstruction from both single-view and
multi-view inputs, and supports various input modalities through simple
operator substitution -- all without retraining. Experiments on ShapeNet and
CO3D datasets demonstrate that our method achieves superior reconstruction
quality at matched or lower NFEs, yielding higher F-score and lower CD and EMD,
validating its efficiency and adaptability for practical applications. Code is
available at https://github.com/Seunghyeok0715/FCM

</details>


### [108] [Seq2Seq Models Reconstruct Visual Jigsaw Puzzles without Seeing Them](https://arxiv.org/abs/2511.06315)
*Gur Elkn,Ofir Itzhak Shahar,Ohad Ben-Shahar*

Main category: cs.CV

TL;DR: 该论文提出了一种不使用视觉输入，仅依赖语言模型解决方形拼图的新方法，通过专门的分词器将拼图块转换为离散标记序列，将拼图重组任务转化为序列到序列预测问题。


<details>
  <summary>Details</summary>
Motivation: 传统拼图算法主要基于视觉方法，本文探索从语言角度解决拼图问题的全新途径，研究语言模型在非语言领域的应用潜力。

Method: 设计专门的分词器将每个拼图块转换为离散标记序列，使用编码器-解码器transformer模型作为"盲"求解器，仅基于标记序列进行推理来完成拼图重组。

Result: 尽管刻意限制视觉输入访问，该方法在多个基准测试中达到了最先进水平，甚至优于基于视觉的方法。

Conclusion: 研究结果表明语言模型具有解决其原生领域之外问题的惊人能力，非常规方法可以为拼图求解研究提供有前景的新方向。

Abstract: Jigsaw puzzles are primarily visual objects, whose algorithmic solutions have
traditionally been framed from a visual perspective. In this work, however, we
explore a fundamentally different approach: solving square jigsaw puzzles using
language models, without access to raw visual input. By introducing a
specialized tokenizer that converts each puzzle piece into a discrete sequence
of tokens, we reframe puzzle reassembly as a sequence-to-sequence prediction
task. Treated as "blind" solvers, encoder-decoder transformers accurately
reconstruct the original layout by reasoning over token sequences alone.
Despite being deliberately restricted from accessing visual input, our models
achieve state-of-the-art results across multiple benchmarks, often
outperforming vision-based methods. These findings highlight the surprising
capability of language models to solve problems beyond their native domain, and
suggest that unconventional approaches can inspire promising directions for
puzzle-solving research.

</details>


### [109] [CINEMAE: Leveraging Frozen Masked Autoencoders for Cross-Generator AI Image Detection](https://arxiv.org/abs/2511.06325)
*Minsuk Jang,Hyeonseo Jeong,Minseok Son,Changick Kim*

Main category: cs.CV

TL;DR: CINEMAE是一种基于上下文条件重建不确定性的AIGC图像检测新方法，通过在视觉领域应用文本检测的核心原理，实现了强大的跨生成器泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于图像的AIGC检测器容易过拟合到特定生成器的特征上，而基于文本的检测器通过测量分布不一致性已经实现了强大的泛化能力。

Method: 利用掩码自编码器(MAE)在重建被掩码补丁时自然编码语义一致性期望的特性，通过计算条件负对数似然来量化局部语义异常，并将补丁级统计与全局MAE特征通过学习融合进行聚合。

Result: 仅在Stable Diffusion v1.4上训练，CINEMAE在GenImage基准测试的八个未见生成器上达到了超过95%的准确率，显著优于最先进的检测器。

Conclusion: 上下文条件重建不确定性为AIGC检测提供了鲁棒且可迁移的信号，证明了将文本检测原理成功迁移到视觉领域的可行性。

Abstract: While context-based detectors have achieved strong generalization for
AI-generated text by measuring distributional inconsistencies, image-based
detectors still struggle with overfitting to generator-specific artifacts. We
introduce CINEMAE, a novel paradigm for AIGC image detection that adapts the
core principles of text detection methods to the visual domain. Our key insight
is that Masked AutoEncoder (MAE), trained to reconstruct masked patches
conditioned on visible context, naturally encodes semantic consistency
expectations. We formalize this reconstruction process probabilistically,
computing conditional Negative Log-Likelihood (NLL, p(masked | visible)) to
quantify local semantic anomalies. By aggregating these patch-level statistics
with global MAE features through learned fusion, CINEMAE achieves strong
cross-generator generalization. Trained exclusively on Stable Diffusion v1.4,
our method achieves over 95% accuracy on all eight unseen generators in the
GenImage benchmark, substantially outperforming state-of-the-art detectors.
This demonstrates that context-conditional reconstruction uncertainty provides
a robust, transferable signal for AIGC detection.

</details>


### [110] [Improving Multimodal Sentiment Analysis via Modality Optimization and Dynamic Primary Modality Selection](https://arxiv.org/abs/2511.06328)
*Dingkang Yang,Mingcheng Li,Xuecheng Wu,Zhaoyu Chen,Kaixun Jiang,Keliang Liu,Peng Zhai,Lihua Zhang*

Main category: cs.CV

TL;DR: 提出MODS框架，通过动态主模态选择和模态优化解决多模态情感分析中模态性能不平衡问题


<details>
  <summary>Details</summary>
Motivation: 现有方法采用固定主模态策略无法适应不同样本中模态重要性的动态变化，且非语言模态存在序列冗余和噪声问题

Method: 构建基于图的动态序列压缩器(GDC)减少声学/视觉模态冗余，开发样本自适应主模态选择器(MSelector)，设计主模态中心交叉注意力(PCCA)模块

Result: 在四个基准数据集上的实验表明MODS优于现有最优方法，通过有效平衡模态贡献和消除冗余噪声实现卓越性能

Conclusion: MODS框架能够动态适应不同样本的模态重要性变化，有效解决多模态情感分析中的模态不平衡问题

Abstract: Multimodal Sentiment Analysis (MSA) aims to predict sentiment from language,
acoustic, and visual data in videos. However, imbalanced unimodal performance
often leads to suboptimal fused representations. Existing approaches typically
adopt fixed primary modality strategies to maximize dominant modality
advantages, yet fail to adapt to dynamic variations in modality importance
across different samples. Moreover, non-language modalities suffer from
sequential redundancy and noise, degrading model performance when they serve as
primary inputs. To address these issues, this paper proposes a modality
optimization and dynamic primary modality selection framework (MODS). First, a
Graph-based Dynamic Sequence Compressor (GDC) is constructed, which employs
capsule networks and graph convolution to reduce sequential redundancy in
acoustic/visual modalities. Then, we develop a sample-adaptive Primary Modality
Selector (MSelector) for dynamic dominance determination. Finally, a
Primary-modality-Centric Cross-Attention (PCCA) module is designed to enhance
dominant modalities while facilitating cross-modal interaction. Extensive
experiments on four benchmark datasets demonstrate that MODS outperforms
state-of-the-art methods, achieving superior performance by effectively
balancing modality contributions and eliminating redundant noise.

</details>


### [111] [Label-Efficient 3D Forest Mapping: Self-Supervised and Transfer Learning for Individual, Structural, and Species Analysis](https://arxiv.org/abs/2511.06331)
*Aldino Rizaldy,Fabian Ewald Fassnacht,Ahmed Jamal Afifi,Hua Jiang,Richard Gloaguen,Pedram Ghamisi*

Main category: cs.CV

TL;DR: 该论文探索使用自监督学习和迁移学习来减少对大量标注数据的依赖，提高从激光扫描点云中提取单棵树信息的性能，包括实例分割、语义分割和树种分类任务。


<details>
  <summary>Details</summary>
Motivation: 精确林业、生物多样性保护和碳测绘需要详细的单棵树结构信息，但深度学习模型需要大量标注数据，而3D点云的标注工作耗时且难以扩展。

Method: 采用自监督学习和迁移学习架构，结合领域自适应技术，构建统一框架实现从原始点云到树划分、结构分析和树种分类的完整流程。

Result: 自监督学习结合领域自适应显著提升实例分割性能（AP50 +16.98%），自监督学习对语义分割足够有效（mIoU +1.79%），层次迁移学习能准确分类未见过的树种（Jaccard +6.07%），预训练模型降低能耗约21%。

Conclusion: 该开源框架通过减少标注数据需求，加速了从激光扫描点云中提取单棵树信息的操作化应用，支持林业、生物多样性和碳测绘领域的发展。

Abstract: Detailed structural and species information on individual tree level is
increasingly important to support precision forestry, biodiversity
conservation, and provide reference data for biomass and carbon mapping. Point
clouds from airborne and ground-based laser scanning are currently the most
suitable data source to rapidly derive such information at scale. Recent
advancements in deep learning improved segmenting and classifying individual
trees and identifying semantic tree components. However, deep learning models
typically require large amounts of annotated training data which limits further
improvement. Producing dense, high-quality annotations for 3D point clouds,
especially in complex forests, is labor-intensive and challenging to scale. We
explore strategies to reduce dependence on large annotated datasets using
self-supervised and transfer learning architectures. Our objective is to
improve performance across three tasks: instance segmentation, semantic
segmentation, and tree classification using realistic and operational training
sets. Our findings indicate that combining self-supervised learning with domain
adaptation significantly enhances instance segmentation compared to training
from scratch (AP50 +16.98%), self-supervised learning suffices for semantic
segmentation (mIoU +1.79%), and hierarchical transfer learning enables accurate
classification of unseen species (Jaccard +6.07%). To simplify use and
encourage uptake, we integrated the tasks into a unified framework,
streamlining the process from raw point clouds to tree delineation, structural
analysis, and species classification. Pretrained models reduce energy
consumption and carbon emissions by ~21%. This open-source contribution aims to
accelerate operational extraction of individual tree information from laser
scanning point clouds to support forestry, biodiversity, and carbon mapping.

</details>


### [112] [BuildingWorld: A Structured 3D Building Dataset for Urban Foundation Models](https://arxiv.org/abs/2511.06337)
*Shangfeng Huang,Ruisheng Wang,Xin Wang*

Main category: cs.CV

TL;DR: BuildingWorld是一个全面的3D建筑数据集，旨在解决现有数据集建筑风格多样性不足的问题，包含来自全球五大洲约500万个LOD2建筑模型，并配有真实和模拟的机载LiDAR点云数据。


<details>
  <summary>Details</summary>
Motivation: 随着数字孪生在现代城市转型中的重要性日益凸显，精确且结构化的3D建筑模型成为高保真、可更新城市表示的关键支撑。然而，现有学习模型大多在建筑多样性有限的数据集上训练，严重影响了其在异构城市环境中的泛化能力。

Method: 通过收集来自北美、欧洲、亚洲、非洲和大洋洲等地理和建筑多样化区域的建筑数据，构建了包含约500万个LOD2建筑模型的全球代表性数据集。同时引入Cyber City虚拟城市模型来生成具有定制化点云分布的无限训练数据。

Result: BuildingWorld数据集提供了全面的3D建筑重建、检测和分割研究基础，并为大规模视觉模型和基础模型在结构化3D城市环境中的训练、评估和比较提供了标准化评估指标。

Conclusion: BuildingWorld填补了3D建筑数据集在风格多样性方面的空白，为城市级基础建模和分析提供了全球代表性的数据资源，有望推动3D城市建模技术的进一步发展。

Abstract: As digital twins become central to the transformation of modern cities,
accurate and structured 3D building models emerge as a key enabler of
high-fidelity, updatable urban representations. These models underpin diverse
applications including energy modeling, urban planning, autonomous navigation,
and real-time reasoning. Despite recent advances in 3D urban modeling, most
learning-based models are trained on building datasets with limited
architectural diversity, which significantly undermines their generalizability
across heterogeneous urban environments. To address this limitation, we present
BuildingWorld, a comprehensive and structured 3D building dataset designed to
bridge the gap in stylistic diversity. It encompasses buildings from
geographically and architecturally diverse regions -- including North America,
Europe, Asia, Africa, and Oceania -- offering a globally representative dataset
for urban-scale foundation modeling and analysis. Specifically, BuildingWorld
provides about five million LOD2 building models collected from diverse
sources, accompanied by real and simulated airborne LiDAR point clouds. This
enables comprehensive research on 3D building reconstruction, detection and
segmentation. Cyber City, a virtual city model, is introduced to enable the
generation of unlimited training data with customized and structurally diverse
point cloud distributions. Furthermore, we provide standardized evaluation
metrics tailored for building reconstruction, aiming to facilitate the
training, evaluation, and comparison of large-scale vision models and
foundation models in structured 3D urban environments.

</details>


### [113] [GazeVLM: A Vision-Language Model for Multi-Task Gaze Understanding](https://arxiv.org/abs/2511.06348)
*Athul M. Mathew,Haithem Hermassi,Thariq Khalid,Arshad Ali Khan,Riad Souissi*

Main category: cs.CV

TL;DR: GazeVLM是一个新颖的视觉语言模型，首次将人员检测、注视目标检测和注视物体识别统一到一个框架中，通过融合RGB图像和HHA编码深度图，在GazeFollow和VideoAttentionTarget数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的注视理解研究虽然能够建模视觉场景中的注视线索，但缺乏一个能够同时利用视觉和语言提示的统一系统来处理多任务注视理解。

Method: 提出GazeVLM模型，集成视觉（RGB和深度）和文本模态，通过文本提示引导的RGB图像与HHA编码深度图融合来实现多任务注视理解。

Result: 在GazeFollow和VideoAttentionTarget数据集上实现了最先进的评估分数，消融研究表明RGB与HHA深度图融合结合文本提示能获得最佳性能。

Conclusion: GazeVLM成功展示了视觉语言模型在多任务注视理解中的有效性，为视觉注意力和意图估计提供了重要洞察。

Abstract: Gaze understanding unifies the detection of people, their gaze targets, and
objects of interest into a single framework, offering critical insight into
visual attention and intent estimation. Although prior research has modelled
gaze cues in visual scenes, a unified system is still needed for gaze
understanding using both visual and language prompts. This paper introduces
GazeVLM, a novel Vision-Language Model (VLM) for multi-task gaze understanding
in images, addressing person detection, gaze target detection, and gaze object
identification. While other transformer-based methods exist for gaze analysis,
GazeVLM represents, to our knowledge, the first application of a VLM to these
combined tasks, allowing for selective execution of each task. Through the
integration of visual (RGB and depth) and textual modalities, our ablation
study on visual input combinations revealed that a fusion of RGB images with
HHA-encoded depth maps, guided by text prompts, yields superior performance. We
also introduce an object-level gaze detection metric for gaze object
identification ($AP_{ob}$). Through experiments, GazeVLM demonstrates
significant improvements, notably achieving state-of-the-art evaluation scores
on GazeFollow and VideoAttentionTarget datasets.

</details>


### [114] [AesTest: Measuring Aesthetic Intelligence from Perception to Production](https://arxiv.org/abs/2511.06360)
*Guolong Wang,Heng Huang,Zhiqiang Zhang,Wentian Li,Feilong Ma,Xin Jin*

Main category: cs.CV

TL;DR: AesTest是一个全面的多模态美学感知与生成基准测试，包含十个任务，涵盖感知、欣赏、创作和摄影，基于生成学习心理学理论，整合了多样化数据源，支持多种美学查询类型。


<details>
  <summary>Details</summary>
Motivation: 现有的图像美学评估基准在感知范围上较窄或缺乏多样性，无法系统评估美学生成能力，因此需要构建更全面的基准来推动多模态大语言模型的美学能力发展。

Method: 构建AesTest基准，包含精心策划的十个多项选择题任务，整合专业编辑流程、摄影构图教程和众包偏好等多样化数据源，支持基于属性的分析、情感共鸣、构图选择和风格推理等美学查询类型。

Result: 评估了指令调优的IAA MLLMs和通用MLLMs，发现在构建美学智能方面存在显著挑战。

Conclusion: AesTest基准将公开发布，以支持该领域未来的研究。

Abstract: Perceiving and producing aesthetic judgments is a fundamental yet
underexplored capability for multimodal large language models (MLLMs). However,
existing benchmarks for image aesthetic assessment (IAA) are narrow in
perception scope or lack the diversity needed to evaluate systematic aesthetic
production. To address this gap, we introduce AesTest, a comprehensive
benchmark for multimodal aesthetic perception and production, distinguished by
the following features: 1) It consists of curated multiple-choice questions
spanning ten tasks, covering perception, appreciation, creation, and
photography. These tasks are grounded in psychological theories of generative
learning. 2) It integrates data from diverse sources, including professional
editing workflows, photographic composition tutorials, and crowdsourced
preferences. It ensures coverage of both expert-level principles and real-world
variation. 3) It supports various aesthetic query types, such as
attribute-based analysis, emotional resonance, compositional choice, and
stylistic reasoning. We evaluate both instruction-tuned IAA MLLMs and general
MLLMs on AesTest, revealing significant challenges in building aesthetic
intelligence. We will publicly release AesTest to support future research in
this area.

</details>


### [115] [V-Shuffle: Zero-Shot Style Transfer via Value Shuffle](https://arxiv.org/abs/2511.06365)
*Haojun Tang,Qiwei Lin,Tongda Xu,Lida Huang,Yan Wang*

Main category: cs.CV

TL;DR: V-Shuffle是一种基于注意力注入的零样本风格迁移方法，通过打乱扩散模型自注意力层中的值特征来破坏风格图像的语义内容，同时保留低层风格表示，有效解决了内容泄漏问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于注意力注入的风格迁移方法存在内容泄漏问题，即风格图像中不需要的语义内容会错误地出现在风格化输出中。

Method: V-Shuffle通过打乱扩散模型自注意力层中的值特征来隐式破坏风格图像的语义内容，同时保留低层风格表示。此外，还引入了混合风格正则化，用高层风格纹理补充这些低层表示以增强风格保真度。

Result: 实验结果表明，V-Shuffle在使用多个风格图像时表现出色，在单张风格图像应用时也优于之前的最先进方法。

Conclusion: V-Shuffle通过创新的值特征打乱机制和混合风格正则化，有效平衡了内容保持和风格保真度之间的权衡，在零样本风格迁移任务中取得了优异性能。

Abstract: Attention injection-based style transfer has achieved remarkable progress in
recent years. However, existing methods often suffer from content leakage,
where the undesired semantic content of the style image mistakenly appears in
the stylized output. In this paper, we propose V-Shuffle, a zero-shot style
transfer method that leverages multiple style images from the same style domain
to effectively navigate the trade-off between content preservation and style
fidelity. V-Shuffle implicitly disrupts the semantic content of the style
images by shuffling the value features within the self-attention layers of the
diffusion model, thereby preserving low-level style representations. We further
introduce a Hybrid Style Regularization that complements these low-level
representations with high-level style textures to enhance style fidelity.
Empirical results demonstrate that V-Shuffle achieves excellent performance
when utilizing multiple style images. Moreover, when applied to a single style
image, V-Shuffle outperforms previous state-of-the-art methods.

</details>


### [116] [InfoAffect: A Dataset for Affective Analysis of Infographics](https://arxiv.org/abs/2511.06404)
*Zihang Fu,Yunchao Wang,Chenyu Huang,Guodao Sun,Ronghua Liang*

Main category: cs.CV

TL;DR: 本文提出了InfoAffect数据集，这是一个包含3.5k个样本的情感标注数据集，结合了文本内容和真实世界的信息图表，用于探索信息图表的情感维度。


<details>
  <summary>Details</summary>
Motivation: 信息图表被广泛用于传达复杂信息，但由于数据资源的稀缺，其情感维度仍未得到充分探索。

Method: 从六个领域收集原始数据，通过预处理、伴随文本优先方法和三种策略进行对齐和质量保证。构建情感表来约束标注，使用五种最先进的多模态大语言模型分析两种模态，并通过RRF算法融合输出以获得稳健的情感和置信度。

Result: 通过用户研究验证可用性，并使用CACI评估InfoAffect数据集，总体得分达到0.986，表明高准确性。

Conclusion: InfoAffect数据集为信息图表的情感分析提供了高质量的资源，并通过多模态分析和融合方法实现了高准确性的情感标注。

Abstract: Infographics are widely used to convey complex information, yet their
affective dimensions remain underexplored due to the scarcity of data
resources. We introduce a 3.5k-sample affect-annotated InfoAffect dataset,
which combines textual content with real-world infographics. We first collect
the raw data from six domains and aligned them via preprocessing, the
accompanied-text-priority method, and three strategies to guarantee the quality
and compliance. After that we construct an affect table and use it to constrain
annotation. Five state-of-the-art multimodal large language models (MLLMs) then
analyze both modalities, and their outputs are fused with Reciprocal Rank
Fusion (RRF) algorithm to yield robust affects and confidences. We conducted a
user study with two experiments to validate usability and assess InfoAffect
dataset using the Composite Affect Consistency Index (CACI), achieving an
overall score of 0.986, which indicates high accuracy.

</details>


### [117] [On Modality Incomplete Infrared-Visible Object Detection: An Architecture Compatibility Perspective](https://arxiv.org/abs/2511.06406)
*Shuo Yang,Yinghui Xing,Shizhou Zhang,Zhilong Niu*

Main category: cs.CV

TL;DR: 本文提出了一种名为Scarf-DETR的模块化方法，用于解决红外和可见光目标检测中的模态不完整问题，通过模态无关的可变形注意力机制和伪模态丢弃策略，使检测器能够灵活适应单模态或双模态场景。


<details>
  <summary>Details</summary>
Motivation: 当前的红外和可见光目标检测模型在面对不完整模态数据时性能显著下降，特别是在主导模态缺失的情况下。本文旨在从架构兼容性角度解决模态不完整的IVOD问题。

Method: 提出了一个即插即用的Scarf Neck模块，引入模态无关的可变形注意力机制；设计了伪模态丢弃策略来充分利用多模态信息；建立了一个全面的基准测试来评估模态不完整的IVOD任务。

Result: Scarf-DETR不仅在模态缺失场景下表现优异，在标准IVOD模态完整基准测试中也取得了优越性能。

Conclusion: 该方法有效解决了模态不完整问题，提升了检测器的鲁棒性和适应性，为全天候应用提供了可靠解决方案。

Abstract: Infrared and visible object detection (IVOD) is essential for numerous
around-the-clock applications. Despite notable advancements, current IVOD
models exhibit notable performance declines when confronted with incomplete
modality data, particularly if the dominant modality is missing. In this paper,
we take a thorough investigation on modality incomplete IVOD problem from an
architecture compatibility perspective. Specifically, we propose a
plug-and-play Scarf Neck module for DETR variants, which introduces a
modality-agnostic deformable attention mechanism to enable the IVOD detector to
flexibly adapt to any single or double modalities during training and
inference. When training Scarf-DETR, we design a pseudo modality dropout
strategy to fully utilize the multi-modality information, making the detector
compatible and robust to both working modes of single and double modalities.
Moreover, we introduce a comprehensive benchmark for the modality-incomplete
IVOD task aimed at thoroughly assessing situations where the absent modality is
either dominant or secondary. Our proposed Scarf-DETR not only performs
excellently in missing modality scenarios but also achieves superior
performances on the standard IVOD modality complete benchmarks. Our code will
be available at https://github.com/YinghuiXing/Scarf-DETR.

</details>


### [118] [VDNeRF: Vision-only Dynamic Neural Radiance Field for Urban Scenes](https://arxiv.org/abs/2511.06408)
*Zhengyu Zou,Jingfeng Li,Hao Li,Xiaolei Hou,Jinwen Hu,Jingkun Chen,Lechao Cheng,Dingwen Zhang*

Main category: cs.CV

TL;DR: VDNeRF是一种无需相机姿态信息的动态NeRF方法，能够准确恢复相机轨迹并学习动态城市场景的时空表示，在相机姿态估计和动态新视角合成方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有NeRF方法在自动驾驶和机器人感知应用中面临的挑战，包括难以获取准确相机姿态以及处理大规模动态环境的局限性。

Method: 使用两个独立的NeRF模型联合重建场景：静态NeRF模型优化相机姿态和静态背景，动态NeRF模型结合3D场景流确保动态对象的准确重建，通过有效训练框架解决相机运动与物体运动之间的模糊性。

Result: 在主流城市驾驶数据集上的广泛评估表明，VDNeRF在相机姿态估计和动态新视角合成方面超越了最先进的基于NeRF的无姿态方法。

Conclusion: VDNeRF成功解决了动态场景中相机姿态估计和场景重建的挑战，为自动驾驶和机器人感知应用提供了有效的解决方案。

Abstract: Neural Radiance Fields (NeRFs) implicitly model continuous three-dimensional
scenes using a set of images with known camera poses, enabling the rendering of
photorealistic novel views. However, existing NeRF-based methods encounter
challenges in applications such as autonomous driving and robotic perception,
primarily due to the difficulty of capturing accurate camera poses and
limitations in handling large-scale dynamic environments. To address these
issues, we propose Vision-only Dynamic NeRF (VDNeRF), a method that accurately
recovers camera trajectories and learns spatiotemporal representations for
dynamic urban scenes without requiring additional camera pose information or
expensive sensor data. VDNeRF employs two separate NeRF models to jointly
reconstruct the scene. The static NeRF model optimizes camera poses and static
background, while the dynamic NeRF model incorporates the 3D scene flow to
ensure accurate and consistent reconstruction of dynamic objects. To address
the ambiguity between camera motion and independent object motion, we design an
effective and powerful training framework to achieve robust camera pose
estimation and self-supervised decomposition of static and dynamic elements in
a scene. Extensive evaluations on mainstream urban driving datasets demonstrate
that VDNeRF surpasses state-of-the-art NeRF-based pose-free methods in both
camera pose estimation and dynamic novel view synthesis.

</details>


### [119] [DiffusionUavLoc: Visually Prompted Diffusion for Cross-View UAV Localization](https://arxiv.org/abs/2511.06422)
*Tao Liu,Kan Ren,Qian Chen*

Main category: cs.CV

TL;DR: 提出了DiffusionUavLoc框架，用于解决GNSS拒止环境下无人机与卫星图像的跨视角定位问题，通过训练无关的几何渲染和文本无关的条件扩散模型实现鲁棒特征学习。


<details>
  <summary>Details</summary>
Motivation: 随着低空经济的发展，无人机在智能巡检系统中应用广泛，但在GNSS拒止环境中，依赖卫星信号的定位方案容易失效。现有跨视角图像检索方法存在几何和外观域差距，且依赖复杂网络架构或大量标注。

Method: 使用训练无关的几何渲染从无人机图像合成伪卫星图像作为结构提示，设计文本无关的条件扩散模型融合多模态结构线索，在固定时间步t计算描述符并使用余弦相似度进行比较。

Result: 在University-1652和SUES-200数据集上表现优异，特别是在University-1652的卫星到无人机定位任务中具有竞争力。

Conclusion: DiffusionUavLoc框架为GNSS拒止环境下的无人机定位提供了有效的解决方案，通过扩散模型和统一表示学习实现了鲁棒的跨视角定位性能。

Abstract: With the rapid growth of the low-altitude economy, unmanned aerial vehicles
(UAVs) have become key platforms for measurement and tracking in intelligent
patrol systems. However, in GNSS-denied environments, localization schemes that
rely solely on satellite signals are prone to failure. Cross-view image
retrieval-based localization is a promising alternative, yet substantial
geometric and appearance domain gaps exist between oblique UAV views and nadir
satellite orthophotos. Moreover, conventional approaches often depend on
complex network architectures, text prompts, or large amounts of annotation,
which hinders generalization. To address these issues, we propose
DiffusionUavLoc, a cross-view localization framework that is image-prompted,
text-free, diffusion-centric, and employs a VAE for unified representation. We
first use training-free geometric rendering to synthesize pseudo-satellite
images from UAV imagery as structural prompts. We then design a text-free
conditional diffusion model that fuses multimodal structural cues to learn
features robust to viewpoint changes. At inference, descriptors are computed at
a fixed time step t and compared using cosine similarity. On University-1652
and SUES-200, the method performs competitively for cross-view localization,
especially for satellite-to-drone in University-1652.Our data and code will be
published at the following URL:
https://github.com/liutao23/DiffusionUavLoc.git.

</details>


### [120] [Diagnose Like A REAL Pathologist: An Uncertainty-Focused Approach for Trustworthy Multi-Resolution Multiple Instance Learning](https://arxiv.org/abs/2511.06433)
*Sungrae Hong,Sol Lee,Jisu Shin,Mun Yong Yi*

Main category: cs.CV

TL;DR: 本文提出了UFC-MIL方法，通过多分辨率图像和不确定性校准来提升多实例学习在病理诊断中的可靠性和性能。


<details>
  <summary>Details</summary>
Motivation: 当前的多分辨率MIL方法只关注性能提升，缺乏对校准MIL的研究，而临床专家需要可信赖的诊断结果。

Method: UFC-MIL包括一个新颖的基于补丁的损失函数来学习实例的潜在模式并表达其分类不确定性，以及带有邻域补丁聚合模块的注意力架构。

Result: 在挑战性公共数据集上，UFC-MIL在模型校准方面表现出优越性能，同时实现了与最先进方法相当的分类准确率。

Conclusion: UFC-MIL更接近病理学家的检查行为，提供校准的诊断预测，且无需多次迭代推理，具有重要的实际优势。

Abstract: With the increasing demand for histopathological specimen examination and
diagnostic reporting, Multiple Instance Learning (MIL) has received heightened
research focus as a viable solution for AI-centric diagnostic aid. Recently, to
improve its performance and make it work more like a pathologist, several MIL
approaches based on the use of multiple-resolution images have been proposed,
delivering often higher performance than those that use single-resolution
images. Despite impressive recent developments of multiple-resolution MIL,
previous approaches only focus on improving performance, thereby lacking
research on well-calibrated MIL that clinical experts can rely on for
trustworthy diagnostic results. In this study, we propose Uncertainty-Focused
Calibrated MIL (UFC-MIL), which more closely mimics the pathologists'
examination behaviors while providing calibrated diagnostic predictions, using
multiple images with different resolutions. UFC-MIL includes a novel patch-wise
loss that learns the latent patterns of instances and expresses their
uncertainty for classification. Also, the attention-based architecture with a
neighbor patch aggregation module collects features for the classifier. In
addition, aggregated predictions are calibrated through patch-level uncertainty
without requiring multiple iterative inferences, which is a key practical
advantage. Against challenging public datasets, UFC-MIL shows superior
performance in model calibration while achieving classification accuracy
comparable to that of state-of-the-art methods.

</details>


### [121] [Countering Multi-modal Representation Collapse through Rank-targeted Fusion](https://arxiv.org/abs/2511.06450)
*Seulgi Kim,Kiran Kokilepersaud,Mohit Prabhushankar,Ghassan AlRegib*

Main category: cs.CV

TL;DR: 该论文提出了一种新的多模态融合方法，通过有效秩来量化并解决特征崩溃和模态崩溃问题，在动作预测任务中取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 多模态融合方法常面临特征崩溃和模态崩溃问题，现有方法分别处理这两种崩溃，缺乏统一框架。作者认为有效秩可以作为统一指标来同时解决这两种崩溃问题。

Method: 提出了Rank-enhancing Token Fuser框架，选择性地将较少信息量的特征与互补特征融合，提高融合表示的有效秩。同时评估模态组合的相互增强效果，避免模态崩溃。

Result: 在NTURGBD、UTKinect和DARai数据集上的实验表明，该方法显著优于现有最先进方法，性能提升最高达3.74%。深度信息与RGB融合能保持表示平衡。

Conclusion: 有效秩是量化多模态融合中表示崩溃的有效指标，提出的R3D框架能够同时解决特征崩溃和模态崩溃问题，在多模态动作预测任务中表现出色。

Abstract: Multi-modal fusion methods often suffer from two types of representation
collapse: feature collapse where individual dimensions lose their
discriminative power (as measured by eigenspectra), and modality collapse where
one dominant modality overwhelms the other. Applications like human action
anticipation that require fusing multifarious sensor data are hindered by both
feature and modality collapse. However, existing methods attempt to counter
feature collapse and modality collapse separately. This is because there is no
unifying framework that efficiently addresses feature and modality collapse in
conjunction. In this paper, we posit the utility of effective rank as an
informative measure that can be utilized to quantify and counter both the
representation collapses. We propose \textit{Rank-enhancing Token Fuser}, a
theoretically grounded fusion framework that selectively blends less
informative features from one modality with complementary features from another
modality. We show that our method increases the effective rank of the fused
representation. To address modality collapse, we evaluate modality combinations
that mutually increase each others' effective rank. We show that depth
maintains representational balance when fused with RGB, avoiding modality
collapse. We validate our method on action anticipation, where we present
\texttt{R3D}, a depth-informed fusion framework. Extensive experiments on
NTURGBD, UTKinect, and DARai demonstrate that our approach significantly
outperforms prior state-of-the-art methods by up to 3.74\%. Our code is
available at:
\href{https://github.com/olivesgatech/R3D}{https://github.com/olivesgatech/R3D}.

</details>


### [122] [EIDSeg: A Pixel-Level Semantic Segmentation Dataset for Post-Earthquake Damage Assessment from Social Media Images](https://arxiv.org/abs/2511.06456)
*Huili Huang,Chengeng Liu,Danrong Zhang,Shail Patel,Anastasiya Masalava,Sagar Sadak,Parisa Babolhavaeji,WeiHong Low,Max Mahdi Roozbahani,J. David Frost*

Main category: cs.CV

TL;DR: EIDSeg是首个针对震后社交媒体图像的大规模语义分割数据集，包含3,266张图像和五类基础设施损坏标注，通过三阶段跨学科标注协议实现非专家标注一致性，最佳模型EoMT达到80.8% mIoU。


<details>
  <summary>Details</summary>
Motivation: 现有遥感方法依赖昂贵的航空图像和专家标注，且仅能生成二值损伤图用于早期评估。社交媒体图像可填补这一空白，但缺乏大规模像素级标注数据集。

Method: 提出EIDSeg数据集，涵盖9次大地震的3,266张图像，采用五类基础设施损坏标注（未损坏建筑、损坏建筑、毁坏建筑、未损坏道路、损坏道路）。设计三阶段跨学科标注协议，使非专家标注者达成超过70%的一致性。

Result: 在多个最先进分割模型上进行了基准测试，Encoder-only Mask Transformer (EoMT)表现最佳，达到80.8%的mIoU。

Conclusion: 通过利用社交媒体丰富的地面视角，本研究为震后场景中更快、更细粒度的损伤评估铺平了道路。

Abstract: Rapid post-earthquake damage assessment is crucial for rescue and resource
planning. Still, existing remote sensing methods depend on costly aerial
images, expert labeling, and produce only binary damage maps for early-stage
evaluation. Although ground-level images from social networks provide a
valuable source to fill this gap, a large pixel-level annotated dataset for
this task is still unavailable. We introduce EIDSeg, the first large-scale
semantic segmentation dataset specifically for post-earthquake social media
imagery. The dataset comprises 3,266 images from nine major earthquakes
(2008-2023), annotated across five classes of infrastructure damage: Undamaged
Building, Damaged Building, Destroyed Building, Undamaged Road, and Damaged
Road. We propose a practical three-phase cross-disciplinary annotation protocol
with labeling guidelines that enables consistent segmentation by non-expert
annotators, achieving over 70% inter-annotator agreement. We benchmark several
state-of-the-art segmentation models, identifying Encoder-only Mask Transformer
(EoMT) as the top-performing method with a Mean Intersection over Union (mIoU)
of 80.8%. By unlocking social networks' rich ground-level perspective, our work
paves the way for a faster, finer-grained damage assessment in the
post-earthquake scenario.

</details>


### [123] [Inpaint360GS: Efficient Object-Aware 3D Inpainting via Gaussian Splatting for 360° Scenes](https://arxiv.org/abs/2511.06457)
*Shaoxiang Wang,Shihong Zhang,Christen Millerdurai,Rüdiger Westermann,Didier Stricker,Alain Pagani*

Main category: cs.CV

TL;DR: Inpaint360GS是一个基于3D高斯泼溅的360度编辑框架，解决了复杂360度场景中多目标移除和修复的三个关键挑战：目标识别、严重遮挡处理和多视角一致性保持。


<details>
  <summary>Details</summary>
Motivation: 目前基于NeRF和3DGS的单目标正面修复已有进展，但复杂360度场景的修复仍未被充分探索，主要面临三个挑战：360度环境中3D目标识别、多目标场景严重遮挡导致的修复区域定义困难、跨视角一致高质量外观保持。

Method: 通过将2D分割蒸馏到3D空间，并利用虚拟相机视角提供上下文指导，实现准确的目标级编辑和一致的场景补全。还提出了专门针对360度修复的新数据集。

Result: 实验表明Inpaint360GS优于现有基线方法，达到了最先进的性能。

Conclusion: Inpaint360GS是一个灵活的360度编辑框架，能够有效支持多目标移除和3D空间中的高保真修复，解决了复杂360度场景修复的关键技术难题。

Abstract: Despite recent advances in single-object front-facing inpainting using NeRF
and 3D Gaussian Splatting (3DGS), inpainting in complex 360{\deg} scenes
remains largely underexplored. This is primarily due to three key challenges:
(i) identifying target objects in the 3D field of 360{\deg} environments, (ii)
dealing with severe occlusions in multi-object scenes, which makes it hard to
define regions to inpaint, and (iii) maintaining consistent and high-quality
appearance across views effectively. To tackle these challenges, we propose
Inpaint360GS, a flexible 360{\deg} editing framework based on 3DGS that
supports multi-object removal and high-fidelity inpainting in 3D space. By
distilling 2D segmentation into 3D and leveraging virtual camera views for
contextual guidance, our method enables accurate object-level editing and
consistent scene completion. We further introduce a new dataset tailored for
360{\deg} inpainting, addressing the lack of ground truth object-free scenes.
Experiments demonstrate that Inpaint360GS outperforms existing baselines and
achieves state-of-the-art performance. Project page:
https://dfki-av.github.io/inpaint360gs/

</details>


### [124] [NOAH: Benchmarking Narrative Prior driven Hallucination and Omission in Video Large Language Models](https://arxiv.org/abs/2511.06475)
*Kyuho Lee,Euntae Kim,Jinwoo Choi,Buru Chang*

Main category: cs.CV

TL;DR: 论文提出了NOAH基准，用于评估视频大语言模型中的叙事先验引起的幻觉和遗漏错误，发现大多数模型都存在这类问题且错误模式受架构、事件相似性和插入位置影响。


<details>
  <summary>Details</summary>
Motivation: 视频大语言模型为提高叙事连贯性而引入的连续性偏好导致模型优先考虑故事情节一致性而非严格视觉证据，从而产生幻觉和遗漏错误。

Method: 构建NOAH基准，通过将其他来源的片段插入目标视频来创建复合视频，设计包含captioning和三种QA任务（存在性、时序性、叙事性）的评估体系，包含超过6万个样本。

Result: 实验发现：(i)大多数视频大语言模型存在叙事先验驱动的幻觉和遗漏；(ii)错误模式因架构、事件相似性和插入位置而异；(iii)帧数较少时叙事先验依赖增强，弱事件连续性会放大错误。

Conclusion: NOAH是首个标准化评估视频大语言模型中叙事先验引起幻觉和遗漏的基准，为开发更可靠可信的模型奠定了基础。

Abstract: Video large language models (Video LLMs) have recently achieved strong
performance on tasks such as captioning, summarization, and question answering.
Many models and training methods explicitly encourage continuity across events
to enhance narrative coherence. While this improves fluency, it also introduces
an inductive bias that prioritizes storyline consistency over strict grounding
in visual evidence. We identify this bias, which we call narrative prior, as a
key driver of two errors: hallucinations, where non-existent events are
introduced or existing ones are misinterpreted, and omissions, where factual
events are suppressed because they are misaligned with surrounding context. To
systematically evaluate narrative prior-induced errors, we introduce NOAH, a
large-scale benchmark that constructs composite videos by inserting clips from
other sources into target videos. By varying semantic similarity and insertion
position, our benchmark enables controlled and scalable analysis of narrative
priors. We design one captioning task with tailored metrics and three QA tasks
- Existence, Temporal, and Narrative - yielding more than 60K evaluation
samples. Extensive experiments yield three key findings: (i) most Video LLMs
exhibit hallucinations and omissions driven by narrative priors, (ii) the
patterns of these errors vary across architectures and depend on event
similarity and insertion position, and (iii) reliance on narrative priors
intensifies under sampling with fewer frames, amplifying errors when event
continuity is weak. We establish NOAH as the first standardized evaluation of
narrative prior-induced hallucination and omission in Video LLMs, providing a
foundation for developing more reliable and trustworthy models. Our benchmark
and code are available at https://anonymous550520.github.io/.

</details>


### [125] [Zooming into Comics: Region-Aware RL Improves Fine-Grained Comic Understanding in Vision-Language Models](https://arxiv.org/abs/2511.06490)
*Yule Chen,Yufan Ren,Sabine Süsstrunk*

Main category: cs.CV

TL;DR: 该论文提出了AI4VA-FG基准测试，用于评估视觉语言模型在漫画理解方面的能力，并开发了区域感知强化学习(RARL)方法来提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型在自然图像上表现优秀，但在处理漫画这种复杂视觉叙事时面临挑战，包括风格化线条艺术、拟声词和密集多面板布局等难点。

Method: 创建了细粒度漫画理解基准AI4VA-FG，评估了GPT-4o、Gemini-2.5和Qwen2.5-VL等模型，并提出了监督微调(SFT-S、SFT-R)、强化学习(RL)以及创新的区域感知强化学习(RARL)方法。

Result: 实验表明现有模型在漫画理解任务上存在显著性能缺陷，而RL和RARL方法在Qwen2.5-VL模型上显著提升了低层实体识别和高层故事情节排序能力。

Conclusion: 漫画理解仍是一个未解决的挑战，但提出的RARL方法为提升视觉语言模型在漫画领域的应用效果提供了有效途径。

Abstract: Complex visual narratives, such as comics, present a significant challenge to
Vision-Language Models (VLMs). Despite excelling on natural images, VLMs often
struggle with stylized line art, onomatopoeia, and densely packed multi-panel
layouts. To address this gap, we introduce AI4VA-FG, the first fine-grained and
comprehensive benchmark for VLM-based comic understanding. It spans tasks from
foundational recognition and detection to high-level character reasoning and
narrative construction, supported by dense annotations for characters, poses,
and depth. Beyond that, we evaluate state-of-the-art proprietary models,
including GPT-4o and Gemini-2.5, and open-source models such as Qwen2.5-VL,
revealing substantial performance deficits across core tasks of our benchmarks
and underscoring that comic understanding remains an unsolved challenge. To
enhance VLMs' capabilities in this domain, we systematically investigate
post-training strategies, including supervised fine-tuning on solutions
(SFT-S), supervised fine-tuning on reasoning trajectories (SFT-R), and
reinforcement learning (RL). Beyond that, inspired by the emerging "Thinking
with Images" paradigm, we propose Region-Aware Reinforcement Learning (RARL)
for VLMs, which trains models to dynamically attend to relevant regions through
zoom-in operations. We observe that when applied to the Qwen2.5-VL model, RL
and RARL yield significant gains in low-level entity recognition and high-level
storyline ordering, paving the way for more accurate and efficient VLM
applications in the comics domain.

</details>


### [126] [SportR: A Benchmark for Multimodal Large Language Model Reasoning in Sports](https://arxiv.org/abs/2511.06499)
*Haotian Xia,Haonan Ge,Junbo Zou,Hyun Woo Choi,Xuebin Zhang,Danny Suradja,Botao Rui,Ethan Tran,Wendy Jin,Zhen Ye,Xiyang Lin,Christopher Lai,Shengjie Zhang,Junwen Miao,Shichao Chen,Rhys Tracy,Vicente Ordonez,Weining Shen,Hanjie Chen*

Main category: cs.CV

TL;DR: SportR是首个多运动大规模基准测试，旨在训练和评估多模态大模型在体育智能推理方面的能力，包含5017张图片和2101个视频，提供渐进式难度的问题-答案对和7118条人工标注的思维链。


<details>
  <summary>Details</summary>
Motivation: 当前体育基准测试要么只覆盖单一运动，要么缺乏详细的推理链和精确的视觉基础，无法在多运动背景下全面评估模型的核心能力。

Method: 构建包含图像和视频模态的数据集，采用渐进式难度的问题层次结构，从简单违规识别到复杂判罚预测，并提供高质量人工标注的思维链和边界框注释。

Result: 实验表明该基准测试极具挑战性，最先进的基线模型在最具挑战性的任务上表现不佳，即使通过监督微调和强化学习进行训练，得分仍然相对较低。

Conclusion: SportR为社区提供了新的挑战，是推动多模态体育推理未来研究的关键资源。

Abstract: Deeply understanding sports requires an intricate blend of fine-grained
visual perception and rule-based reasoning - a challenge that pushes the limits
of current multimodal models. To succeed, models must master three critical
capabilities: perceiving nuanced visual details, applying abstract sport rule
knowledge, and grounding that knowledge in specific visual evidence. Current
sports benchmarks either cover single sports or lack the detailed reasoning
chains and precise visual grounding needed to robustly evaluate these core
capabilities in a multi-sport context. To address this gap, we introduce
SportR, the first multi-sports large-scale benchmark designed to train and
evaluate MLLMs on the fundamental reasoning required for sports intelligence.
Our benchmark provides a dataset of 5,017 images and 2,101 videos. To enable
granular evaluation, we structure our benchmark around a progressive hierarchy
of question-answer (QA) pairs designed to probe reasoning at increasing depths
- from simple infraction identification to complex penalty prediction. For the
most advanced tasks requiring multi-step reasoning, such as determining
penalties or explaining tactics, we provide 7,118 high-quality, human-authored
Chain of Thought (CoT) annotations. In addition, our benchmark incorporates
both image and video modalities and provides manual bounding box annotations to
test visual grounding in the image part directly. Extensive experiments
demonstrate the profound difficulty of our benchmark. State-of-the-art baseline
models perform poorly on our most challenging tasks. While training on our data
via Supervised Fine-Tuning and Reinforcement Learning improves these scores,
they remain relatively low, highlighting a significant gap in current model
capabilities. SportR presents a new challenge for the community, providing a
critical resource to drive future research in multimodal sports reasoning.

</details>


### [127] [Video Dataset for Surgical Phase, Keypoint, and Instrument Recognition in Laparoscopic Surgery (PhaKIR)](https://arxiv.org/abs/2511.06549)
*Tobias Rueckert,Raphaela Maerkl,David Rauber,Leonard Klausmann,Max Gutbrod,Daniel Rueckert,Hubertus Feussner,Dirk Wilhelm,Christoph Palm*

Main category: cs.CV

TL;DR: PhaKIR数据集是首个多中心联合提供手术阶段标签、器械姿态信息和像素级器械分割的数据集，包含8个完整腹腔镜胆囊切除术视频，支持手术阶段识别、器械关键点估计和器械实例分割三个任务。


<details>
  <summary>Details</summary>
Motivation: 现有手术数据集往往只关注孤立任务、忽略时间依赖性或缺乏多中心变异性，无法满足机器人辅助微创手术对可靠器械识别和手术流程理解的需求。

Method: 收集来自三个医疗中心的8个完整腹腔镜胆囊切除术视频，提供帧级标注，包括手术阶段识别（485,875帧）、器械关键点估计（19,435帧）和器械实例分割（19,435帧）。

Result: 创建了首个多机构数据集，可同时利用时间上下文信息，为MICCAI 2024的PhaKIR挑战赛提供基准，验证了数据集的质量和相关性。

Conclusion: PhaKIR数据集通过Zenodo平台公开可用，为手术场景理解方法提供了重要基准，推动了计算机视觉在机器人辅助微创手术中的应用。

Abstract: Robotic- and computer-assisted minimally invasive surgery (RAMIS) is
increasingly relying on computer vision methods for reliable instrument
recognition and surgical workflow understanding. Developing such systems often
requires large, well-annotated datasets, but existing resources often address
isolated tasks, neglect temporal dependencies, or lack multi-center
variability. We present the Surgical Procedure Phase, Keypoint, and Instrument
Recognition (PhaKIR) dataset, comprising eight complete laparoscopic
cholecystectomy videos recorded at three medical centers. The dataset provides
frame-level annotations for three interconnected tasks: surgical phase
recognition (485,875 frames), instrument keypoint estimation (19,435 frames),
and instrument instance segmentation (19,435 frames). PhaKIR is, to our
knowledge, the first multi-institutional dataset to jointly provide phase
labels, instrument pose information, and pixel-accurate instrument
segmentations, while also enabling the exploitation of temporal context since
full surgical procedure sequences are available. It served as the basis for the
PhaKIR Challenge as part of the Endoscopic Vision (EndoVis) Challenge at MICCAI
2024 to benchmark methods in surgical scene understanding, thereby further
validating the dataset's quality and relevance. The dataset is publicly
available upon request via the Zenodo platform.

</details>


### [128] [Spatial-Frequency Enhanced Mamba for Multi-Modal Image Fusion](https://arxiv.org/abs/2511.06593)
*Hui Sun,Long Lv,Pingping Zhang,Tongdan Tang,Feng Tian,Weibing Sun,Huchuan Lu*

Main category: cs.CV

TL;DR: 提出SFMFusion框架，通过空间-频率增强的Mamba块和动态融合机制，解决多模态图像融合中CNN感受野受限和Transformer计算成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于CNN和Transformer的多模态图像融合方法存在感受野有限和计算成本高的问题，而Mamba虽然能有效建模长距离依赖但缺乏空间和频率感知能力。

Method: 采用三分支结构耦合图像融合和图像重建任务，设计空间-频率增强Mamba块（SFMB）和动态融合Mamba块（DFMB）进行特征提取和融合。

Result: 在六个多模态图像融合数据集上取得优于现有最先进方法的结果。

Conclusion: SFMFusion框架通过增强Mamba的空间-频率感知能力和动态融合机制，有效提升了多模态图像融合的性能。

Abstract: Multi-Modal Image Fusion (MMIF) aims to integrate complementary image
information from different modalities to produce informative images. Previous
deep learning-based MMIF methods generally adopt Convolutional Neural Networks
(CNNs) or Transformers for feature extraction. However, these methods deliver
unsatisfactory performances due to the limited receptive field of CNNs and the
high computational cost of Transformers. Recently, Mamba has demonstrated a
powerful potential for modeling long-range dependencies with linear complexity,
providing a promising solution to MMIF. Unfortunately, Mamba lacks full spatial
and frequency perceptions, which are very important for MMIF. Moreover,
employing Image Reconstruction (IR) as an auxiliary task has been proven
beneficial for MMIF. However, a primary challenge is how to leverage IR
efficiently and effectively. To address the above issues, we propose a novel
framework named Spatial-Frequency Enhanced Mamba Fusion (SFMFusion) for MMIF.
More specifically, we first propose a three-branch structure to couple MMIF and
IR, which can retain complete contents from source images. Then, we propose the
Spatial-Frequency Enhanced Mamba Block (SFMB), which can enhance Mamba in both
spatial and frequency domains for comprehensive feature extraction. Finally, we
propose the Dynamic Fusion Mamba Block (DFMB), which can be deployed across
different branches for dynamic feature fusion. Extensive experiments show that
our method achieves better results than most state-of-the-art methods on six
MMIF datasets. The source code is available at
https://github.com/SunHui1216/SFMFusion.

</details>


### [129] [Explainable Cross-Disease Reasoning for Cardiovascular Risk Assessment from LDCT](https://arxiv.org/abs/2511.06625)
*Yifei Zhang,Jiashuo Zhang,Xiaofeng Yang,Liang Zhao*

Main category: cs.CV

TL;DR: 提出了一个可解释的跨疾病推理框架，通过单次低剂量胸部CT扫描进行心肺风险评估，整合肺部感知、知识引导推理和心脏表征三个模块，实现准确且生理学基础的心血管风险预测。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将肺部和心脏疾病视为独立任务，忽略了它们之间的生理相互作用和共享成像生物标志物。LDCT扫描天然包含心肺结构信息，为联合评估提供了独特机会。

Method: 框架包含三个协同组件：肺部感知模块总结肺部异常，知识引导推理模块推断其心血管影响，心脏表征模块编码结构生物标志物。通过模拟临床诊断思维过程，先感知肺部发现，再通过医学知识推理，最后得出心血管判断。

Result: 在NLST队列上的实验表明，该框架在心脑血管疾病筛查和死亡率预测方面达到最先进性能，优于单疾病和纯图像基线方法。

Conclusion: 这项工作建立了一个统一且可解释的范式，用于从LDCT进行心血管分析，弥合了基于图像的预测和基于机制的医学解释之间的差距。

Abstract: Low-dose chest computed tomography (LDCT) inherently captures both pulmonary
and cardiac structures, offering a unique opportunity for joint assessment of
lung and cardiovascular health. However, most existing approaches treat these
domains as independent tasks, overlooking their physiological interplay and
shared imaging biomarkers. We propose an Explainable Cross-Disease Reasoning
Framework that enables interpretable cardiopulmonary risk assessment from a
single LDCT scan. The framework introduces an agentic reasoning process that
emulates clinical diagnostic thinking-first perceiving pulmonary findings, then
reasoning through established medical knowledge, and finally deriving a
cardiovascular judgment with explanatory rationale. It integrates three
synergistic components: a pulmonary perception module that summarizes lung
abnormalities, a knowledge-guided reasoning module that infers their
cardiovascular implications, and a cardiac representation module that encodes
structural biomarkers. Their outputs are fused to produce a holistic
cardiovascular risk prediction that is both accurate and physiologically
grounded. Experiments on the NLST cohort demonstrate that the proposed
framework achieves state-of-the-art performance for CVD screening and mortality
prediction, outperforming single-disease and purely image-based baselines.
Beyond quantitative gains, the framework provides human-verifiable reasoning
that aligns with cardiological understanding, revealing coherent links between
pulmonary abnormalities and cardiac stress mechanisms. Overall, this work
establishes a unified and explainable paradigm for cardiovascular analysis from
LDCT, bridging the gap between image-based prediction and mechanism-based
medical interpretation.

</details>


### [130] [DIAL-GS: Dynamic Instance Aware Reconstruction for Label-free Street Scenes with 4D Gaussian Splatting](https://arxiv.org/abs/2511.06632)
*Chenpeng Su,Wenhua Wu,Chensheng Peng,Tianchen Deng,Zhe Liu,Hesheng Wang*

Main category: cs.CV

TL;DR: DIAL-GS是一种基于4D高斯泼溅的动态实例感知重建方法，用于无标签街景重建，通过外观-位置不一致性准确识别动态实例，实现动态自适应和实例感知的重建。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶中城市场景重建问题，现有监督方法依赖昂贵人工标注且缺乏可扩展性，自监督方法难以区分静态和动态元素及单个动态对象，限制了细粒度编辑能力。

Method: 利用扭曲渲染与实际观察之间的外观-位置不一致性准确识别动态实例；采用实例感知的4D高斯作为统一体积表示；引入身份和动态相互增强的互惠机制。

Result: 在城市驾驶场景实验中，DIAL-GS在重建质量和实例级编辑方面优于现有自监督基线方法。

Conclusion: DIAL-GS为城市场景建模提供了一个简洁而强大的解决方案，实现了高质量的重建和实例级编辑能力。

Abstract: Urban scene reconstruction is critical for autonomous driving, enabling
structured 3D representations for data synthesis and closed-loop testing.
Supervised approaches rely on costly human annotations and lack scalability,
while current self-supervised methods often confuse static and dynamic elements
and fail to distinguish individual dynamic objects, limiting fine-grained
editing. We propose DIAL-GS, a novel dynamic instance-aware reconstruction
method for label-free street scenes with 4D Gaussian Splatting. We first
accurately identify dynamic instances by exploiting appearance-position
inconsistency between warped rendering and actual observation. Guided by
instance-level dynamic perception, we employ instance-aware 4D Gaussians as the
unified volumetric representation, realizing dynamic-adaptive and
instance-aware reconstruction. Furthermore, we introduce a reciprocal mechanism
through which identity and dynamics reinforce each other, enhancing both
integrity and consistency. Experiments on urban driving scenarios show that
DIAL-GS surpasses existing self-supervised baselines in reconstruction quality
and instance-level editing, offering a concise yet powerful solution for urban
scene modeling.

</details>


### [131] [UniADC: A Unified Framework for Anomaly Detection and Classification](https://arxiv.org/abs/2511.06644)
*Ximiao Zhang,Min Xu,Zheng Zhang,Junlin Hu,Xiuzhuang Zhou*

Main category: cs.CV

TL;DR: 本文提出UniADC模型，实现统一异常检测与分类，通过可控修复网络生成异常图像，多任务判别器实现精准异常检测和分类，在多个数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法将异常检测和分类作为独立任务处理，忽略了它们的固有相关性，限制了信息共享，导致性能不佳。

Method: UniADC包含训练免费的可控修复网络和多任务判别器。修复网络通过异常先验指导修复正常区域生成特定类别异常图像，多任务判别器通过对齐细粒度图像特征与异常类别嵌入实现精准检测分类。

Result: 在MVTec-FS、MTD和WFDD三个数据集上的实验表明，UniADC在异常检测、定位和分类方面一致优于现有方法。

Conclusion: UniADC模型有效解决了统一异常检测与分类问题，在少量甚至无异常图像情况下仍能取得优异性能。

Abstract: In this paper, we introduce the task of unified anomaly detection and
classification, which aims to simultaneously detect anomalous regions in images
and identify their specific categories. Existing methods typically treat
anomaly detection and classification as separate tasks, thereby neglecting
their inherent correlation, limiting information sharing, and resulting in
suboptimal performance. To address this, we propose UniADC, a unified anomaly
detection and classification model that can effectively perform both tasks with
only a few or even no anomaly images. Specifically, UniADC consists of two key
components: a training-free controllable inpainting network and a multi-task
discriminator. The inpainting network can synthesize anomaly images of specific
categories by repainting normal regions guided by anomaly priors, and can also
repaint few-shot anomaly samples to augment the available anomaly data. The
multi-task discriminator is then trained on these synthesized samples, enabling
precise anomaly detection and classification by aligning fine-grained image
features with anomaly-category embeddings. We conduct extensive experiments on
three anomaly detection and classification datasets, including MVTec-FS, MTD,
and WFDD, and the results demonstrate that UniADC consistently outperforms
existing methods in anomaly detection, localization, and classification. The
code is available at https://github.com/cnulab/UniADC.

</details>


### [132] [FreqGRL: Suppressing Low-Frequency Bias and Mining High-Frequency Knowledge for Cross-Domain Few-Shot Learning](https://arxiv.org/abs/2511.06648)
*Siqi Hui,Sanping Zhou,Ye deng,Wenli Huang,Jinjun Wang*

Main category: cs.CV

TL;DR: 本文提出FreqGRL框架，通过频率空间视角解决跨域小样本学习中的数据不平衡问题，使用低频替换和高频增强模块来提升跨域泛化性能。


<details>
  <summary>Details</summary>
Motivation: 跨域小样本学习中，丰富的源域数据和稀缺的目标域数据之间存在严重不平衡，导致模型容易偏向源域特定知识，而目标数据的稀疏性阻碍了高频、可泛化特征的学习。

Method: 提出FreqGRL框架，包含三个模块：低频替换模块用目标域低频成分替换源任务低频成分以减少源域偏见；高频增强模块在频率空间直接学习高频特征以提升泛化能力；全局频率滤波器抑制噪声频率并强调信息频率。

Result: 在五个标准CD-FSL基准测试上的广泛实验表明，该频率引导框架实现了最先进的性能。

Conclusion: 频率空间视角为跨域小样本学习提供了新的解决方案，通过频率成分的针对性处理有效缓解了数据不平衡带来的挑战。

Abstract: Cross-domain few-shot learning (CD-FSL) aims to recognize novel classes with
only a few labeled examples under significant domain shifts. While recent
approaches leverage a limited amount of labeled target-domain data to improve
performance, the severe imbalance between abundant source data and scarce
target data remains a critical challenge for effective representation learning.
We present the first frequency-space perspective to analyze this issue and
identify two key challenges: (1) models are easily biased toward
source-specific knowledge encoded in the low-frequency components of source
data, and (2) the sparsity of target data hinders the learning of
high-frequency, domain-generalizable features. To address these challenges, we
propose \textbf{FreqGRL}, a novel CD-FSL framework that mitigates the impact of
data imbalance in the frequency space. Specifically, we introduce a
Low-Frequency Replacement (LFR) module that substitutes the low-frequency
components of source tasks with those from the target domain to create new
source tasks that better align with target characteristics, thus reducing
source-specific biases and promoting generalizable representation learning. We
further design a High-Frequency Enhancement (HFE) module that filters out
low-frequency components and performs learning directly on high-frequency
features in the frequency space to improve cross-domain generalization.
Additionally, a Global Frequency Filter (GFF) is incorporated to suppress noisy
or irrelevant frequencies and emphasize informative ones, mitigating
overfitting risks under limited target supervision. Extensive experiments on
five standard CD-FSL benchmarks demonstrate that our frequency-guided framework
achieves state-of-the-art performance.

</details>


### [133] [NOVO: Bridging LLaVA and SAM with Visual-only Prompts for Reasoning Segmentation](https://arxiv.org/abs/2511.06651)
*Kyung-Yoon Yoon,Yeong-Jun Cho*

Main category: cs.CV

TL;DR: NOVO是一个新颖的框架，通过纯视觉提示连接视觉语言模型和分割模型，利用VLM输出生成粗掩码和点提示，与SAM兼容，并引入无训练细化模块提升分割质量。


<details>
  <summary>Details</summary>
Motivation: 现有的方法通常将文本衍生的SEG标记嵌入输入分割模型，但这种方法可能无法充分利用SAM的预训练能力。NOVO旨在通过纯视觉提示更好地桥接VLMs和分割模型。

Method: 1. 从VLM输出生成粗掩码和点提示作为视觉提示
2. 使用与SAM兼容的视觉提示进行分割
3. 引入无训练细化模块减少视觉伪影并提升边界质量
4. 创建RISeg基准进行评估

Result: 实验表明NOVO在多个指标和模型大小上均达到最先进性能，证明了其在推理分割任务中的有效性和可扩展性。

Conclusion: NOVO框架通过视觉提示有效连接VLMs和分割模型，在保持SAM预训练能力的同时实现了高质量的分割结果，为推理分割任务提供了新的解决方案。

Abstract: In this study, we propose NOVO (NO text, Visual-Only prompts), a novel
framework that bridges vision-language models (VLMs) and segmentation models
through visual-only prompts. Unlike prior approaches that feed text-derived SEG
token embeddings into segmentation models, NOVO instead generates a coarse mask
and point prompts from the VLM output. These visual prompts are compatible with
the Segment Anything Model (SAM), preserving alignment with its pretrained
capabilities. To further enhance boundary quality and enable instance-level
segmentation, we introduce a training-free refinement module that reduces
visual artifacts and improves the quality of segmentation masks. We also
present RISeg, a new benchmark comprising 918 images, 2,533 instance-level
masks, and diverse reasoning queries to evaluate this task. Experiments
demonstrate that NOVO achieves state-of-the-art performance across multiple
metrics and model sizes, demonstrating its effectiveness and scalability in
reasoning segmentation.

</details>


### [134] [HiMo-CLIP: Modeling Semantic Hierarchy and Monotonicity in Vision-Language Alignment](https://arxiv.org/abs/2511.06653)
*Ruijia Wu,Ping Chen,Fei Shen,Shaoan Zhao,Qiang Hui,Huanlin Gao,Ting Lu,Zhaoxiang Liu,Fang Zhao,Kai Wang,Shiguo Lian*

Main category: cs.CV

TL;DR: HiMo-CLIP通过层次分解和单调性感知对比损失增强CLIP模型，提升对复杂长文本描述的处理能力


<details>
  <summary>Details</summary>
Motivation: 现有CLIP模型将文本视为扁平序列，无法有效处理复杂、组合性和长文本描述，缺乏对语义层次结构和语义单调性的捕捉能力

Method: 提出HiDe模块通过批内PCA提取文本的潜在语义组件，实现跨语义粒度的灵活对齐；设计MoLo损失联合对齐全局和组件级表示，鼓励模型学习语义排序和对齐强度

Result: 在多个图像-文本检索基准测试中，HiMo-CLIP均优于强基线模型，特别是在长文本或组合性描述场景下表现突出

Conclusion: HiMo-CLIP能够产生结构化、认知对齐的跨模态表示，有效解决了CLIP模型在处理复杂语言结构时的局限性

Abstract: Contrastive vision-language models like CLIP have achieved impressive results
in image-text retrieval by aligning image and text representations in a shared
embedding space. However, these models often treat text as flat sequences,
limiting their ability to handle complex, compositional, and long-form
descriptions. In particular, they fail to capture two essential properties of
language: semantic hierarchy, which reflects the multi-level compositional
structure of text, and semantic monotonicity, where richer descriptions should
result in stronger alignment with visual content.To address these limitations,
we propose HiMo-CLIP, a representation-level framework that enhances CLIP-style
models without modifying the encoder architecture. HiMo-CLIP introduces two key
components: a hierarchical decomposition (HiDe) module that extracts latent
semantic components from long-form text via in-batch PCA, enabling flexible,
batch-aware alignment across different semantic granularities, and a
monotonicity-aware contrastive loss (MoLo) that jointly aligns global and
component-level representations, encouraging the model to internalize semantic
ordering and alignment strength as a function of textual completeness.These
components work in concert to produce structured, cognitively-aligned
cross-modal representations. Experiments on multiple image-text retrieval
benchmarks show that HiMo-CLIP consistently outperforms strong baselines,
particularly under long or compositional descriptions. The code is available at
https://github.com/UnicomAI/HiMo-CLIP.

</details>


### [135] [Active Learning for Animal Re-Identification with Ambiguity-Aware Sampling](https://arxiv.org/abs/2511.06658)
*Depanshu Sani,Mehar Khurana,Saket Anand*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的主动学习动物重识别框架，通过互补聚类方法挖掘嵌入空间中结构模糊区域，仅需0.033%的标注就能显著超越现有基础模型、无监督和主动学习方法。


<details>
  <summary>Details</summary>
Motivation: 动物重识别面临物种间细微差异、新物种处理和开放集特性等挑战，现有基础模型的零样本性能存在显著差距，而无监督和主动学习方法在动物重识别任务上表现不佳。

Method: 提出主动学习重识别框架，利用互补聚类方法识别嵌入空间中的结构模糊区域，挖掘既具信息性又具代表性的样本对，通过must-link和cannot-link约束进行简单标注，并与无监督方法集成。

Result: 在13个野生动物数据集上，相比基础模型、无监督和主动学习方法分别平均提升10.49%、11.19%和3.99%的mAP，在开放世界设置中对未知个体也有11.09%、8.2%和2.06%的改进。

Conclusion: 该方法仅需极少量标注就能实现state-of-the-art性能，有效解决了动物重识别中的标注成本高和性能不足问题。

Abstract: Animal Re-ID has recently gained substantial attention in the AI research
community due to its high impact on biodiversity monitoring and unique research
challenges arising from environmental factors. The subtle distinguishing
patterns, handling new species and the inherent open-set nature make the
problem even harder. To address these complexities, foundation models trained
on labeled, large-scale and multi-species animal Re-ID datasets have recently
been introduced to enable zero-shot Re-ID. However, our benchmarking reveals
significant gaps in their zero-shot Re-ID performance for both known and
unknown species. While this highlights the need for collecting labeled data in
new domains, exhaustive annotation for Re-ID is laborious and requires domain
expertise. Our analyses show that existing unsupervised (USL) and AL Re-ID
methods underperform for animal Re-ID. To address these limitations, we
introduce a novel AL Re-ID framework that leverages complementary clustering
methods to uncover and target structurally ambiguous regions in the embedding
space for mining pairs of samples that are both informative and broadly
representative. Oracle feedback on these pairs, in the form of must-link and
cannot-link constraints, facilitates a simple annotation interface, which
naturally integrates with existing USL methods through our proposed constrained
clustering refinement algorithm. Through extensive experiments, we demonstrate
that, by utilizing only 0.033% of all annotations, our approach consistently
outperforms existing foundational, USL and AL baselines. Specifically, we
report an average improvement of 10.49%, 11.19% and 3.99% (mAP) on 13 wildlife
datasets over foundational, USL and AL methods, respectively, while attaining
state-of-the-art performance on each dataset. Furthermore, we also show an
improvement of 11.09%, 8.2% and 2.06% for unknown individuals in an open-world
setting.

</details>


### [136] [Sim4Seg: Boosting Multimodal Multi-disease Medical Diagnosis Segmentation with Region-Aware Vision-Language Similarity Masks](https://arxiv.org/abs/2511.06665)
*Lingran Song,Yucheng Zhou,Jianbing Shen*

Main category: cs.CV

TL;DR: 提出医学诊断分割（MDS）任务，结合医学图像分割和诊断，并引入M3DS数据集和Sim4Seg框架，通过区域感知视觉语言相似性提升分割和诊断性能。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像分割模型很少联合探索分割和诊断任务，但患者需要模型在提供分割结果的同时给出可解释的诊断。

Method: 提出Sim4Seg框架，利用区域感知视觉语言相似性到掩码（RVLS2M）模块，并研究测试时缩放策略。

Result: 实验结果表明，该方法在分割和诊断方面均优于基线模型。

Conclusion: MDS任务和Sim4Seg框架有效提升了医学图像分割和诊断的联合性能，为医学图像分析提供了新的方向。

Abstract: Despite significant progress in pixel-level medical image analysis, existing
medical image segmentation models rarely explore medical segmentation and
diagnosis tasks jointly. However, it is crucial for patients that models can
provide explainable diagnoses along with medical segmentation results. In this
paper, we introduce a medical vision-language task named Medical Diagnosis
Segmentation (MDS), which aims to understand clinical queries for medical
images and generate the corresponding segmentation masks as well as diagnostic
results. To facilitate this task, we first present the Multimodal Multi-disease
Medical Diagnosis Segmentation (M3DS) dataset, containing diverse multimodal
multi-disease medical images paired with their corresponding segmentation masks
and diagnosis chain-of-thought, created via an automated diagnosis
chain-of-thought generation pipeline. Moreover, we propose Sim4Seg, a novel
framework that improves the performance of diagnosis segmentation by taking
advantage of the Region-Aware Vision-Language Similarity to Mask (RVLS2M)
module. To improve overall performance, we investigate a test-time scaling
strategy for MDS tasks. Experimental results demonstrate that our method
outperforms the baselines in both segmentation and diagnosis.

</details>


### [137] [REOcc: Camera-Radar Fusion with Radar Feature Enrichment for 3D Occupancy Prediction](https://arxiv.org/abs/2511.06666)
*Chaehee Song,Sanmin Kim,Hyeonjun Jeong,Juyeb Shin,Joonhee Lim,Dongsuk Kum*

Main category: cs.CV

TL;DR: REOcc是一种新型的相机-雷达融合网络，通过雷达增强器和雷达放大器组件来丰富雷达特征表示，解决雷达数据稀疏和噪声问题，提升3D占用预测性能。


<details>
  <summary>Details</summary>
Motivation: 基于视觉的3D占用预测在挑战性环境中表现不佳，相机-雷达融合具有互补优势但受限于雷达数据的稀疏性和噪声，导致融合效果不理想。

Method: 提出REOcc网络，包含雷达增强器和雷达放大器两个主要组件，通过整合空间和上下文信息来细化雷达特征，提高空间密度和质量。

Result: 在Occ3D-nuScenes基准测试上的广泛实验表明，REOcc相比仅使用相机的基线模型取得了显著性能提升，特别是在动态物体类别上。

Conclusion: REOcc能够有效缓解雷达数据的稀疏性和噪声问题，使雷达更好地补充相机数据，充分发挥相机-雷达融合在3D占用预测中的潜力。

Abstract: Vision-based 3D occupancy prediction has made significant advancements, but
its reliance on cameras alone struggles in challenging environments. This
limitation has driven the adoption of sensor fusion, among which camera-radar
fusion stands out as a promising solution due to their complementary strengths.
However, the sparsity and noise of the radar data limits its effectiveness,
leading to suboptimal fusion performance. In this paper, we propose REOcc, a
novel camera-radar fusion network designed to enrich radar feature
representations for 3D occupancy prediction. Our approach introduces two main
components, a Radar Densifier and a Radar Amplifier, which refine radar
features by integrating spatial and contextual information, effectively
enhancing spatial density and quality. Extensive experiments on the
Occ3D-nuScenes benchmark demonstrate that REOcc achieves significant
performance gains over the camera-only baseline model, particularly in dynamic
object classes. These results underscore REOcc's capability to mitigate the
sparsity and noise of the radar data. Consequently, radar complements camera
data more effectively, unlocking the full potential of camera-radar fusion for
robust and reliable 3D occupancy prediction.

</details>


### [138] [Flexible Concept Bottleneck Model](https://arxiv.org/abs/2511.06678)
*Xingbo Du,Qiantong Dou,Lei Fan,Rui Zhang*

Main category: cs.CV

TL;DR: 提出了灵活概念瓶颈模型（FCBM），通过超网络生成预测权重和可学习温度参数的稀疏最大模块，支持动态概念适应而无需重新训练整个模型。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉语言模型的概念瓶颈模型在涉及新概念时需要完全重新训练，限制了在现实场景中的适应性和灵活性。

Method: 设计超网络基于概念嵌入生成预测权重，引入带可学习温度参数的改进稀疏最大模块动态选择最相关概念。

Result: 在五个公共基准测试中达到与最先进基线相当的准确率，仅需单轮微调即可很好地泛化到未见概念。

Conclusion: FCBM展示了强大的适应性和灵活性，能够有效支持动态概念替换和集成。

Abstract: Concept bottleneck models (CBMs) improve neural network interpretability by
introducing an intermediate layer that maps human-understandable concepts to
predictions. Recent work has explored the use of vision-language models (VLMs)
to automate concept selection and annotation. However, existing VLM-based CBMs
typically require full model retraining when new concepts are involved, which
limits their adaptability and flexibility in real-world scenarios, especially
considering the rapid evolution of vision-language foundation models. To
address these issues, we propose Flexible Concept Bottleneck Model (FCBM),
which supports dynamic concept adaptation, including complete replacement of
the original concept set. Specifically, we design a hypernetwork that generates
prediction weights based on concept embeddings, allowing seamless integration
of new concepts without retraining the entire model. In addition, we introduce
a modified sparsemax module with a learnable temperature parameter that
dynamically selects the most relevant concepts, enabling the model to focus on
the most informative features. Extensive experiments on five public benchmarks
demonstrate that our method achieves accuracy comparable to state-of-the-art
baselines with a similar number of effective concepts. Moreover, the model
generalizes well to unseen concepts with just a single epoch of fine-tuning,
demonstrating its strong adaptability and flexibility.

</details>


### [139] [AnoStyler: Text-Driven Localized Anomaly Generation via Lightweight Style Transfer](https://arxiv.org/abs/2511.06687)
*Yulim So,Seokho Kang*

Main category: cs.CV

TL;DR: AnoStyler是一种轻量级零样本异常生成方法，通过文本引导的风格转换将正常图像转换为视觉逼真的异常图像，解决了现有方法在视觉真实性、数据依赖性和模型复杂性方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有异常生成方法存在三个主要问题：生成的异常图像视觉真实性不足、依赖大量真实图像数据、使用内存密集型的大型模型架构，这限制了它们的实际部署应用。

Method: 提出AnoStyler方法，将零样本异常生成建模为文本引导的风格转换。使用单张正常图像及其类别标签，通过类别无关程序生成异常掩码和两类文本提示，然后利用基于CLIP损失训练的轻量级U-Net模型进行风格化转换。

Result: 在MVTec-AD和VisA数据集上的实验表明，AnoStyler在生成高质量和多样化异常图像方面优于现有方法，且生成的异常图像能够有效提升异常检测性能。

Conclusion: AnoStyler提供了一种有效且轻量级的异常生成解决方案，克服了现有方法的局限性，为实际应用中的异常检测提供了可靠的数据增强手段。

Abstract: Anomaly generation has been widely explored to address the scarcity of
anomaly images in real-world data. However, existing methods typically suffer
from at least one of the following limitations, hindering their practical
deployment: (1) lack of visual realism in generated anomalies; (2) dependence
on large amounts of real images; and (3) use of memory-intensive, heavyweight
model architectures. To overcome these limitations, we propose AnoStyler, a
lightweight yet effective method that frames zero-shot anomaly generation as
text-guided style transfer. Given a single normal image along with its category
label and expected defect type, an anomaly mask indicating the localized
anomaly regions and two-class text prompts representing the normal and anomaly
states are generated using generalizable category-agnostic procedures. A
lightweight U-Net model trained with CLIP-based loss functions is used to
stylize the normal image into a visually realistic anomaly image, where
anomalies are localized by the anomaly mask and semantically aligned with the
text prompts. Extensive experiments on the MVTec-AD and VisA datasets show that
AnoStyler outperforms existing anomaly generation methods in generating
high-quality and diverse anomaly images. Furthermore, using these generated
anomalies helps enhance anomaly detection performance.

</details>


### [140] [SPAN: Spatial-Projection Alignment for Monocular 3D Object Detection](https://arxiv.org/abs/2511.06702)
*Yifan Wang,Yian Zhao,Fanqi Pu,Xiaochen Yang,Yang Tang,Xi Chen,Wenming Yang*

Main category: cs.CV

TL;DR: SPAN方法通过空间投影对齐解决单目3D检测中解耦预测导致的几何一致性缺失问题，包含空间点对齐和3D-2D投影对齐两个关键组件，并采用分层任务学习策略确保训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有单目3D检测器采用解耦预测范式分别估计几何中心、深度、尺寸和旋转角，但忽略了不同属性间的几何协同约束，导致缺乏几何一致性先验，性能次优。

Method: 提出空间投影对齐(SPAN)方法：1) 空间点对齐在预测和真实3D边界框间施加显式全局空间约束；2) 3D-2D投影对齐确保投影3D框与对应2D检测框紧密对齐；3) 分层任务学习策略逐步引入对齐约束。

Result: 该方法可轻松集成到任何现有单目3D检测器中，并带来显著性能提升。

Conclusion: SPAN方法通过几何协同约束解决了单目3D检测中的空间漂移和投影不对齐问题，有效提升了检测性能。

Abstract: Existing monocular 3D detectors typically tame the pronounced nonlinear
regression of 3D bounding box through decoupled prediction paradigm, which
employs multiple branches to estimate geometric center, depth, dimensions, and
rotation angle separately. Although this decoupling strategy simplifies the
learning process, it inherently ignores the geometric collaborative constraints
between different attributes, resulting in the lack of geometric consistency
prior, thereby leading to suboptimal performance. To address this issue, we
propose novel Spatial-Projection Alignment (SPAN) with two pivotal components:
(i). Spatial Point Alignment enforces an explicit global spatial constraint
between the predicted and ground-truth 3D bounding boxes, thereby rectifying
spatial drift caused by decoupled attribute regression. (ii). 3D-2D Projection
Alignment ensures that the projected 3D box is aligned tightly within its
corresponding 2D detection bounding box on the image plane, mitigating
projection misalignment overlooked in previous works. To ensure training
stability, we further introduce a Hierarchical Task Learning strategy that
progressively incorporates spatial-projection alignment as 3D attribute
predictions refine, preventing early stage error propagation across attributes.
Extensive experiments demonstrate that the proposed method can be easily
integrated into any established monocular 3D detector and delivers significant
performance improvements.

</details>


### [141] [K-Stain: Keypoint-Driven Correspondence for H&E-to-IHC Virtual Staining](https://arxiv.org/abs/2511.06709)
*Sicheng Yang,Zhaohu Xing,Haipeng Zhou,Lei Zhu*

Main category: cs.CV

TL;DR: K-Stain是一种基于关键点的虚拟染色框架，通过层次化空间关键点检测器和关键点感知增强生成器，有效解决H&E到IHC图像转换中的空间对齐问题。


<details>
  <summary>Details</summary>
Motivation: 现有虚拟染色方法在处理组织切片空间错位时难以有效利用空间信息，导致合成的IHC图像质量不佳。

Method: 提出K-Stain框架，包含三个核心组件：层次化空间关键点检测器(HSKD)用于识别染色图像中的关键点；关键点感知增强生成器(KEG)在图像生成过程中整合关键点信息；关键点引导判别器(KGD)提升判别器对空间细节的敏感性。

Result: 实验表明K-Stain在定量指标和视觉质量上均优于现有最先进方法。

Conclusion: 基于关键点的空间和语义关系可以有效提升虚拟染色中IHC图像的保真度和一致性。

Abstract: Virtual staining offers a promising method for converting Hematoxylin and
Eosin (H&E) images into Immunohistochemical (IHC) images, eliminating the need
for costly chemical processes. However, existing methods often struggle to
utilize spatial information effectively due to misalignment in tissue slices.
To overcome this challenge, we leverage keypoints as robust indicators of
spatial correspondence, enabling more precise alignment and integration of
structural details in synthesized IHC images. We introduce K-Stain, a novel
framework that employs keypoint-based spatial and semantic relationships to
enhance synthesized IHC image fidelity. K-Stain comprises three main
components: (1) a Hierarchical Spatial Keypoint Detector (HSKD) for identifying
keypoints in stain images, (2) a Keypoint-aware Enhancement Generator (KEG)
that integrates these keypoints during image generation, and (3) a Keypoint
Guided Discriminator (KGD) that improves the discriminator's sensitivity to
spatial details. Our approach leverages contextual information from adjacent
slices, resulting in more accurate and visually consistent IHC images.
Extensive experiments show that K-Stain outperforms state-of-the-art methods in
quantitative metrics and visual quality.

</details>


### [142] [MirrorMamba: Towards Scalable and Robust Mirror Detection in Videos](https://arxiv.org/abs/2511.06716)
*Rui Song,Jiaying Lin,Rynson W. H. Lau*

Main category: cs.CV

TL;DR: 提出了MirrorMamba方法，利用Mamba架构解决视频镜面检测中现有方法性能有限、过度依赖单一动态特征以及计算复杂度高的问题。


<details>
  <summary>Details</summary>
Motivation: 现有视频镜面检测方法性能有限且鲁棒性不足，主要问题包括过度依赖不可靠的单一动态特征，以及基于CNN的方法感受野有限或基于Transformer的方法计算复杂度高。

Method: 提出MirrorMamba方法，整合感知深度、对应关系和光流等多线索，设计基于Mamba的多方向对应关系提取器和边界增强解码器，利用Mamba的全局感受野和线性复杂度优势。

Result: 在基准数据集上超越现有最优方法，在最具挑战性的图像镜面检测数据集上也达到最优性能，证明了方法的鲁棒性和泛化能力。

Conclusion: 这是Mamba架构在镜面检测领域的首次成功应用，展示了该方法在视频镜面检测任务中的有效性和可扩展性。

Abstract: Video mirror detection has received significant research attention, yet
existing methods suffer from limited performance and robustness. These
approaches often over-rely on single, unreliable dynamic features, and are
typically built on CNNs with limited receptive fields or Transformers with
quadratic computational complexity. To address these limitations, we propose a
new effective and scalable video mirror detection method, called MirrorMamba.
Our approach leverages multiple cues to adapt to diverse conditions,
incorporating perceived depth, correspondence and optical. We also introduce an
innovative Mamba-based Multidirection Correspondence Extractor, which benefits
from the global receptive field and linear complexity of the emerging Mamba
spatial state model to effectively capture correspondence properties.
Additionally, we design a Mamba-based layer-wise boundary enforcement decoder
to resolve the unclear boundary caused by the blurred depth map. Notably, this
work marks the first successful application of the Mamba-based architecture in
the field of mirror detection. Extensive experiments demonstrate that our
method outperforms existing state-of-the-art approaches for video mirror
detection on the benchmark datasets. Furthermore, on the most challenging and
representative image-based mirror detection dataset, our approach achieves
state-of-the-art performance, proving its robustness and generalizability.

</details>


### [143] [MRT: Learning Compact Representations with Mixed RWKV-Transformer for Extreme Image Compression](https://arxiv.org/abs/2511.06717)
*Han Liu,Hengyu Man,Xingtao Wang,Wenrui Li,Debin Zhao*

Main category: cs.CV

TL;DR: 提出了一种混合RWKV-Transformer架构，将图像编码为1-D潜在表示，相比传统2-D方法显著提升压缩效率


<details>
  <summary>Details</summary>
Motivation: 现有方法将图像压缩为2-D潜在空间时仍保留大量空间冗余，限制了压缩性能

Method: 使用混合RWKV-Transformer架构，通过RWKV模块捕获窗口间全局依赖，Transformer块建模窗口内局部冗余，并引入专门的RWKV压缩模型

Result: 在0.02bpp以下比特率下实现优越重建质量，在Kodak和CLIC2020数据集上分别节省43.75%和30.59%比特率

Conclusion: MRT框架通过1-D潜在表示学习有效减少空间冗余，在极低比特率下显著优于现有最先进方法

Abstract: Recent advances in extreme image compression have revealed that mapping pixel
data into highly compact latent representations can significantly improve
coding efficiency. However, most existing methods compress images into 2-D
latent spaces via convolutional neural networks (CNNs) or Swin Transformers,
which tend to retain substantial spatial redundancy, thereby limiting overall
compression performance. In this paper, we propose a novel Mixed
RWKV-Transformer (MRT) architecture that encodes images into more compact 1-D
latent representations by synergistically integrating the complementary
strengths of linear-attention-based RWKV and self-attention-based Transformer
models. Specifically, MRT partitions each image into fixed-size windows,
utilizing RWKV modules to capture global dependencies across windows and
Transformer blocks to model local redundancies within each window. The
hierarchical attention mechanism enables more efficient and compact
representation learning in the 1-D domain. To further enhance compression
efficiency, we introduce a dedicated RWKV Compression Model (RCM) tailored to
the structure characteristics of the intermediate 1-D latent features in MRT.
Extensive experiments on standard image compression benchmarks validate the
effectiveness of our approach. The proposed MRT framework consistently achieves
superior reconstruction quality at bitrates below 0.02 bits per pixel (bpp).
Quantitative results based on the DISTS metric show that MRT significantly
outperforms the state-of-the-art 2-D architecture GLC, achieving bitrate
savings of 43.75%, 30.59% on the Kodak and CLIC2020 test datasets,
respectively.

</details>


### [144] [Relative Energy Learning for LiDAR Out-of-Distribution Detection](https://arxiv.org/abs/2511.06720)
*Zizhao Li,Zhengkang Xiang,Jiayang Ao,Joseph West,Kourosh Khoshelham*

Main category: cs.CV

TL;DR: 提出了REL框架，通过相对能量学习和轻量级数据合成策略Point Raise，有效解决LiDAR点云中的OOD检测问题，在SemanticKITTI和STU基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中的安全依赖于识别超出训练分布的障碍物和意外物体，但现有LiDAR OOD方法难以区分罕见异常和常见类别，导致高误报率和安全关键环境中的过度自信错误。

Method: REL框架利用正负logits之间的能量差作为相对评分函数，缓解原始能量值的校准问题；提出Point Raise数据合成策略，通过扰动现有点云生成辅助异常而不改变内点语义。

Result: 在SemanticKITTI和STU基准测试中，REL始终以较大优势超越现有方法。

Conclusion: 建模相对能量结合简单合成异常，为开放世界自动驾驶中的可靠OOD检测提供了原则性和可扩展的解决方案。

Abstract: Out-of-distribution (OOD) detection is a critical requirement for reliable
autonomous driving, where safety depends on recognizing road obstacles and
unexpected objects beyond the training distribution. Despite extensive research
on OOD detection in 2D images, direct transfer to 3D LiDAR point clouds has
been proven ineffective. Current LiDAR OOD methods struggle to distinguish rare
anomalies from common classes, leading to high false-positive rates and
overconfident errors in safety-critical settings. We propose Relative Energy
Learning (REL), a simple yet effective framework for OOD detection in LiDAR
point clouds. REL leverages the energy gap between positive (in-distribution)
and negative logits as a relative scoring function, mitigating calibration
issues in raw energy values and improving robustness across various scenes. To
address the absence of OOD samples during training, we propose a lightweight
data synthesis strategy called Point Raise, which perturbs existing point
clouds to generate auxiliary anomalies without altering the inlier semantics.
Evaluated on SemanticKITTI and the Spotting the Unexpected (STU) benchmark, REL
consistently outperforms existing methods by a large margin. Our results
highlight that modeling relative energy, combined with simple synthetic
outliers, provides a principled and scalable solution for reliable OOD
detection in open-world autonomous driving.

</details>


### [145] [AvatarTex: High-Fidelity Facial Texture Reconstruction from Single-Image Stylized Avatars](https://arxiv.org/abs/2511.06721)
*Yuda Qiu,Zitong Xiao,Yiwei Zuo,Zisheng Ye,Weikai Chen,Xiaoguang Han*

Main category: cs.CV

TL;DR: AvatarTex是一个高保真面部纹理重建框架，通过三阶段扩散-GAN混合管道实现从单张图像生成风格化和逼真纹理，解决了现有方法在风格化虚拟形象上的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在风格化虚拟形象上表现不佳，主要因为缺乏多样化的多风格数据集以及在非标准纹理中保持几何一致性的挑战。

Method: 采用三阶段扩散到GAN管道：首先通过基于扩散的修复完成缺失纹理区域，然后使用基于GAN的潜在优化精炼风格和结构一致性，最后通过基于扩散的重绘增强细节。

Result: AvatarTex在多风格面部纹理重建方面达到了新的最先进水平，能够生成具有艺术和几何一致性的高质量拓扑对齐纹理。

Conclusion: 通过结合扩散模型和GAN的优势，AvatarTex成功解决了风格化纹理重建的挑战，并引入了TexHub数据集来促进该领域的未来研究。

Abstract: We present AvatarTex, a high-fidelity facial texture reconstruction framework
capable of generating both stylized and photorealistic textures from a single
image. Existing methods struggle with stylized avatars due to the lack of
diverse multi-style datasets and challenges in maintaining geometric
consistency in non-standard textures. To address these limitations, AvatarTex
introduces a novel three-stage diffusion-to-GAN pipeline. Our key insight is
that while diffusion models excel at generating diversified textures, they lack
explicit UV constraints, whereas GANs provide a well-structured latent space
that ensures style and topology consistency. By integrating these strengths,
AvatarTex achieves high-quality topology-aligned texture synthesis with both
artistic and geometric coherence. Specifically, our three-stage pipeline first
completes missing texture regions via diffusion-based inpainting, refines style
and structure consistency using GAN-based latent optimization, and enhances
fine details through diffusion-based repainting. To address the need for a
stylized texture dataset, we introduce TexHub, a high-resolution collection of
20,000 multi-style UV textures with precise UV-aligned layouts. By leveraging
TexHub and our structured diffusion-to-GAN pipeline, AvatarTex establishes a
new state-of-the-art in multi-style facial texture reconstruction. TexHub will
be released upon publication to facilitate future research in this field.

</details>


### [146] [Revisiting the Data Sampling in Multimodal Post-training from a Difficulty-Distinguish View](https://arxiv.org/abs/2511.06722)
*Jianyu Qi,Ding Zou,Wenrui Yan,Rui Ma,Jiaxu Li,Zhijie Zheng,Zhiguo Yang,Rongchang Zhao*

Main category: cs.CV

TL;DR: 论文提出两种难度感知采样策略（PISM和CMAB）来量化样本难度，并设计分层训练框架，在六个基准数据集上验证了GRPO在难度分层样本上的优越性。


<details>
  <summary>Details</summary>
Motivation: 现有后训练范式存在两个关键问题：缺乏可量化的难度指标来筛选样本进行后训练优化，以及次优的后训练范式未能联合优化感知和推理能力。

Method: 提出渐进式图像语义掩码（PISM）和跨模态注意力平衡（CMAB）两种难度量化策略，设计包含GRPO-only和SFT+GRPO混合训练的分层训练框架。

Result: 实验表明，相比传统SFT+GRPO流程，GRPO应用于难度分层样本具有一致优越性，策略性数据采样可避免监督微调需求同时提高模型准确性。

Conclusion: 策略性难度采样能有效提升多模态推理模型的性能，GRPO在难度分层样本上的应用显示出优于传统方法的潜力。

Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have spurred
significant progress in Chain-of-Thought (CoT) reasoning. Building on the
success of Deepseek-R1, researchers extended multimodal reasoning to
post-training paradigms based on reinforcement learning (RL), focusing
predominantly on mathematical datasets. However, existing post-training
paradigms tend to neglect two critical aspects: (1) The lack of quantifiable
difficulty metrics capable of strategically screening samples for post-training
optimization. (2) Suboptimal post-training paradigms that fail to jointly
optimize perception and reasoning capabilities. To address this gap, we propose
two novel difficulty-aware sampling strategies: Progressive Image Semantic
Masking (PISM) quantifies sample hardness through systematic image degradation,
while Cross-Modality Attention Balance (CMAB) assesses cross-modal interaction
complexity via attention distribution analysis. Leveraging these metrics, we
design a hierarchical training framework that incorporates both GRPO-only and
SFT+GRPO hybrid training paradigms, and evaluate them across six benchmark
datasets. Experiments demonstrate consistent superiority of GRPO applied to
difficulty-stratified samples compared to conventional SFT+GRPO pipelines,
indicating that strategic data sampling can obviate the need for supervised
fine-tuning while improving model accuracy. Our code will be released at
https://github.com/qijianyu277/DifficultySampling.

</details>


### [147] [Argus: Quality-Aware High-Throughput Text-to-Image Inference Serving System](https://arxiv.org/abs/2511.06724)
*Shubham Agarwal,Subrata Mitra,Saud Iqbal*

Main category: cs.CV

TL;DR: Argus是一个高性能文本到图像推理系统，通过智能选择不同近似策略来平衡质量和吞吐量，相比基线减少10倍延迟SLO违规，提高10%平均质量和40%吞吐量。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像模型推理时间高，设计高吞吐量系统面临挑战。研究发现大部分提示词可以使用更快的近似模型服务，但需要精确校准以避免质量下降。

Method: Argus系统为每个提示词选择适当的模型和兼容的近似设置，智能切换不同近似策略来满足吞吐量和质量要求。

Result: 在两个真实世界工作负载跟踪上，Argus相比基线实现10倍更少的延迟SLO违规、10%更高的平均质量和40%更高的吞吐量。

Conclusion: Argus证明了通过智能近似策略选择可以有效解决文本到图像模型的高吞吐量推理挑战，在固定规模集群上实现质量和吞吐量的平衡。

Abstract: Text-to-image (T2I) models have gained significant popularity. Most of these
are diffusion models with unique computational characteristics, distinct from
both traditional small-scale ML models and large language models. They are
highly compute-bound and use an iterative denoising process to generate images,
leading to very high inference time. This creates significant challenges in
designing a high-throughput system. We discovered that a large fraction of
prompts can be served using faster, approximated models. However, the
approximation setting must be carefully calibrated for each prompt to avoid
quality degradation. Designing a high-throughput system that assigns each
prompt to the appropriate model and compatible approximation setting remains a
challenging problem. We present Argus, a high-throughput T2I inference system
that selects the right level of approximation for each prompt to maintain
quality while meeting throughput targets on a fixed-size cluster. Argus
intelligently switches between different approximation strategies to satisfy
both throughput and quality requirements. Overall, Argus achieves 10x fewer
latency service-level objective (SLO) violations, 10% higher average quality,
and 40% higher throughput compared to baselines on two real-world workload
traces.

</details>


### [148] [Rethinking Rainy 3D Scene Reconstruction via Perspective Transforming and Brightness Tuning](https://arxiv.org/abs/2511.06734)
*Qianfeng Yang,Xiang Chen,Pengpeng Li,Qiyuan Guan,Guiyue Jin,Jiyu Jin*

Main category: cs.CV

TL;DR: 提出了OmniRain3D数据集和REVR-GSNet框架，用于解决雨天多视角图像对3D场景重建的负面影响，通过考虑雨滴的视角依赖性和环境亮度变化，实现了高质量的雨天场景重建。


<details>
  <summary>Details</summary>
Motivation: 现有的数据集忽略了真实雨天3D场景的两个关键特征：雨滴在2D图像上的投影导致的视角依赖性外观变化，以及降雨时云层覆盖导致的环境亮度降低。这些因素影响了3D重建的准确性和完整性。

Method: 构建了包含视角异质性和亮度动态性的OmniRain3D数据集，并提出了REVR-GSNet框架，该框架通过递归亮度增强、高斯基元优化和GS引导的雨滴消除的联合交替优化，实现端到端的干净3D场景重建。

Result: 大量实验证明了数据集和方法的有效性，能够从雨退化的输入中实现高保真度的3D场景重建。

Conclusion: 该研究为多视角图像去雨和雨天3D场景重建的未来研究提供了基础，通过更真实的数据模拟和统一的优化架构解决了雨天重建的挑战。

Abstract: Rain degrades the visual quality of multi-view images, which are essential
for 3D scene reconstruction, resulting in inaccurate and incomplete
reconstruction results. Existing datasets often overlook two critical
characteristics of real rainy 3D scenes: the viewpoint-dependent variation in
the appearance of rain streaks caused by their projection onto 2D images, and
the reduction in ambient brightness resulting from cloud coverage during
rainfall. To improve data realism, we construct a new dataset named OmniRain3D
that incorporates perspective heterogeneity and brightness dynamicity, enabling
more faithful simulation of rain degradation in 3D scenes. Based on this
dataset, we propose an end-to-end reconstruction framework named REVR-GSNet
(Rain Elimination and Visibility Recovery for 3D Gaussian Splatting).
Specifically, REVR-GSNet integrates recursive brightness enhancement, Gaussian
primitive optimization, and GS-guided rain elimination into a unified
architecture through joint alternating optimization, achieving high-fidelity
reconstruction of clean 3D scenes from rain-degraded inputs. Extensive
experiments show the effectiveness of our dataset and method. Our dataset and
method provide a foundation for future research on multi-view image deraining
and rainy 3D scene reconstruction.

</details>


### [149] [SinSEMI: A One-Shot Image Generation Model and Data-Efficient Evaluation Framework for Semiconductor Inspection Equipment](https://arxiv.org/abs/2511.06740)
*ChunLiang Wu,Xiaochun Li*

Main category: cs.CV

TL;DR: SinSEMI是一种新颖的单样本学习框架，用于解决半导体制造中光学图像数据稀缺问题，通过多尺度流模型和LPIPS能量引导生成多样且逼真的图像。


<details>
  <summary>Details</summary>
Motivation: 半导体设备开发早期阶段难以获取大量原始光学图像，数据稀缺阻碍了AI解决方案在半导体制造中的发展。

Method: 采用多尺度流模型结合LPIPS能量引导采样，确保感知真实性和输出多样性，并提出了专门针对该应用的评估框架。

Result: 与多种单样本生成技术相比，SinSEMI在视觉质量、定量指标和下游任务方面表现出优越性能，生成的图像具有高保真度和有意义的多样性。

Conclusion: SinSEMI生成的图像适合作为半导体AI应用的训练数据，有效解决了数据稀缺问题。

Abstract: In the early stages of semiconductor equipment development, obtaining large
quantities of raw optical images poses a significant challenge. This data
scarcity hinder the advancement of AI-powered solutions in semiconductor
manufacturing. To address this challenge, we introduce SinSEMI, a novel
one-shot learning approach that generates diverse and highly realistic images
from single optical image. SinSEMI employs a multi-scale flow-based model
enhanced with LPIPS (Learned Perceptual Image Patch Similarity) energy guidance
during sampling, ensuring both perceptual realism and output variety. We also
introduce a comprehensive evaluation framework tailored for this application,
which enables a thorough assessment using just two reference images. Through
the evaluation against multiple one-shot generation techniques, we demonstrate
SinSEMI's superior performance in visual quality, quantitative measures, and
downstream tasks. Our experimental results demonstrate that SinSEMI-generated
images achieve both high fidelity and meaningful diversity, making them
suitable as training data for semiconductor AI applications.

</details>


### [150] [Otter: Mitigating Background Distractions of Wide-Angle Few-Shot Action Recognition with Enhanced RWKV](https://arxiv.org/abs/2511.06741)
*Wenbo Huang,Jinghui Zhang,Zhenghao Chen,Guang Li,Lei Zhang,Yang Cao,Fang Dong,Takahiro Ogawa,Miki Haseyama*

Main category: cs.CV

TL;DR: 提出Otter方法，通过复合分割和时序重建RWKV来提升宽视角视频中的少样本动作识别性能，有效解决背景干扰和时序关系退化问题。


<details>
  <summary>Details</summary>
Motivation: 宽视角视频中的少样本动作识别面临背景干扰和时序关系退化挑战，需要全局理解主体和背景，但现有方法难以有效突出主体并重建时序关系。

Method: 设计Otter方法，包含复合分割模块(CSM)分割并强调关键图像块以突出主体，时序重建模块(TRM)通过双向扫描重建时序关系，结合常规原型和时序增强原型提升性能。

Result: 在SSv2、Kinetics、UCF101、HMDB51等基准测试中达到state-of-the-art性能，在VideoBadminton数据集上的额外评估进一步验证了Otter在宽视角FSAR中的优越性。

Conclusion: Otter通过有效的主题强调和时序建模，显著提升了宽视角少样本动作识别的性能，为解决背景干扰和时序退化问题提供了有效方案。

Abstract: Wide-angle videos in few-shot action recognition (FSAR) effectively express
actions within specific scenarios. However, without a global understanding of
both subjects and background, recognizing actions in such samples remains
challenging because of the background distractions. Receptance Weighted Key
Value (RWKV), which learns interaction between various dimensions, shows
promise for global modeling. While directly applying RWKV to wide-angle FSAR
may fail to highlight subjects due to excessive background information.
Additionally, temporal relation degraded by frames with similar backgrounds is
difficult to reconstruct, further impacting performance. Therefore, we design
the CompOund SegmenTation and Temporal REconstructing RWKV (Otter).
Specifically, the Compound Segmentation Module~(CSM) is devised to segment and
emphasize key patches in each frame, effectively highlighting subjects against
background information. The Temporal Reconstruction Module (TRM) is
incorporated into the temporal-enhanced prototype construction to enable
bidirectional scanning, allowing better reconstruct temporal relation.
Furthermore, a regular prototype is combined with the temporal-enhanced
prototype to simultaneously enhance subject emphasis and temporal modeling,
improving wide-angle FSAR performance. Extensive experiments on benchmarks such
as SSv2, Kinetics, UCF101, and HMDB51 demonstrate that Otter achieves
state-of-the-art performance. Extra evaluation on the VideoBadminton dataset
further validates the superiority of Otter in wide-angle FSAR.

</details>


### [151] [PointCubeNet: 3D Part-level Reasoning with 3x3x3 Point Cloud Blocks](https://arxiv.org/abs/2511.06744)
*Da-Yeong Kim,Yeong-Jun Cho*

Main category: cs.CV

TL;DR: PointCubeNet是一个无需部件标注的多模态3D理解框架，通过全局和局部分支实现部件级推理，采用无监督训练方式


<details>
  <summary>Details</summary>
Motivation: 现有3D理解方法需要部件级标注，这限制了应用范围。本文旨在实现无需部件标注的部件级3D理解，提升整体3D物体的理解能力

Method: 提出PointCubeNet框架，包含全局分支和局部分支。局部分支采用3x3x3局部块结构，结合伪标签方法和局部损失函数进行无监督训练

Result: 实验结果表明，理解3D物体部件能够增强对整体3D物体的理解。这是首次实现无监督3D部件级推理，获得了可靠且有意义的结果

Conclusion: PointCubeNet成功实现了无需部件标注的部件级3D理解，证明了部件级分析对提升3D物体理解的重要性，为无监督3D理解开辟了新方向

Abstract: In this paper, we propose PointCubeNet, a novel multi-modal 3D understanding
framework that achieves part-level reasoning without requiring any part
annotations. PointCubeNet comprises global and local branches. The proposed
local branch, structured into 3x3x3 local blocks, enables part-level analysis
of point cloud sub-regions with the corresponding local text labels. Leveraging
the proposed pseudo-labeling method and local loss function, PointCubeNet is
effectively trained in an unsupervised manner. The experimental results
demonstrate that understanding 3D object parts enhances the understanding of
the overall 3D object. In addition, this is the first attempt to perform
unsupervised 3D part-level reasoning and achieves reliable and meaningful
results.

</details>


### [152] [Image Restoration via Primal Dual Hybrid Gradient and Flow Generative Model](https://arxiv.org/abs/2511.06748)
*Ji Li,Chao Wang*

Main category: cs.CV

TL;DR: 本文提出了一种基于原始-对偶混合梯度(PDHG)的通用高效PnP算法，将流匹配生成模型作为先验，支持ℓ₁和ℓ₂范数损失函数，能够处理非高斯噪声的图像恢复问题。


<details>
  <summary>Details</summary>
Motivation: 现有PnP方法主要适用于高斯噪声的平滑平方ℓ₂数据保真项，对更一般的数据保真项适用性不足。为了解决非高斯噪声（如泊松噪声和脉冲噪声）下的图像逆问题，需要开发支持更广泛保真项的通用算法。

Method: 将流匹配生成模型的先验知识集成到基于近端分裂的PnP框架中，用生成模型推导的时间相关去噪器替代正则化项的近端算子。提出基于PDHG的通用高效PnP算法，支持ℓ₁和ℓ₂范数损失。

Result: 在去噪、超分辨率、去模糊和修复等多个图像恢复任务上验证了方法的有效性，证明ℓ₁和ℓ₂保真项在非高斯噪声情况下优于传统的平方ℓ₂损失。

Conclusion: 所提出的PDHG-inspired PnP算法计算高效、内存友好，能够处理多种保真项，特别适用于非高斯噪声环境下的图像恢复问题，为更广泛的逆问题求解提供了通用框架。

Abstract: Regularized optimization has been a classical approach to solving imaging
inverse problems, where the regularization term enforces desirable properties
of the unknown image. Recently, the integration of flow matching generative
models into image restoration has garnered significant attention, owing to
their powerful prior modeling capabilities. In this work, we incorporate such
generative priors into a Plug-and-Play (PnP) framework based on proximal
splitting, where the proximal operator associated with the regularizer is
replaced by a time-dependent denoiser derived from the generative model. While
existing PnP methods have achieved notable success in inverse problems with
smooth squared $\ell_2$ data fidelity--typically associated with Gaussian
noise--their applicability to more general data fidelity terms remains
underexplored. To address this, we propose a general and efficient PnP
algorithm inspired by the primal-dual hybrid gradient (PDHG) method. Our
approach is computationally efficient, memory-friendly, and accommodates a wide
range of fidelity terms. In particular, it supports both $\ell_1$ and $\ell_2$
norm-based losses, enabling robustness to non-Gaussian noise types such as
Poisson and impulse noise. We validate our method on several image restoration
tasks, including denoising, super-resolution, deblurring, and inpainting, and
demonstrate that $\ell_1$ and $\ell_2$ fidelity terms outperform the
conventional squared $\ell_2$ loss in the presence of non-Gaussian noise.

</details>


### [153] [Med-SORA: Symptom to Organ Reasoning in Abdomen CT Images](https://arxiv.org/abs/2511.06752)
*You-Kyoung Na,Yeong-Jun Cho*

Main category: cs.CV

TL;DR: Med-SORA是一个用于腹部CT图像中症状-器官推理的框架，通过RAG数据集构建、可学习器官锚点的软标签和2D-3D交叉注意力架构来解决现有医学多模态模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有医学多模态模型依赖简单的一对一硬标签标注，过度简化了临床现实中症状与多个器官相关的复杂关系，且主要使用单切片2D特征而缺乏3D信息，限制了全面解剖上下文的理解能力。

Method: 引入基于RAG的数据集构建方法，使用可学习器官锚点的软标签来捕捉一对多的症状-器官关系，并采用2D-3D交叉注意力架构融合局部和全局图像特征。

Result: 实验结果表明，Med-SORA在性能上优于现有医学多模态模型，能够实现准确的3D临床推理。

Conclusion: 这是医学多模态学习中首个解决症状-器官推理问题的工作，Med-SORA框架在症状-图像关联理解方面取得了显著进展。

Abstract: Understanding symptom-image associations is crucial for clinical reasoning.
However, existing medical multimodal models often rely on simple one-to-one
hard labeling, oversimplifying clinical reality where symptoms relate to
multiple organs. In addition, they mainly use single-slice 2D features without
incorporating 3D information, limiting their ability to capture full anatomical
context. In this study, we propose Med-SORA, a framework for symptom-to-organ
reasoning in abdominal CT images. Med-SORA introduces RAG-based dataset
construction, soft labeling with learnable organ anchors to capture one-to-many
symptom-organ relationships, and a 2D-3D cross-attention architecture to fuse
local and global image features. To our knowledge, this is the first work to
address symptom-to-organ reasoning in medical multimodal learning. Experimental
results show that Med-SORA outperforms existing medical multimodal models and
enables accurate 3D clinical reasoning.

</details>


### [154] [CAST-LUT: Tokenizer-Guided HSV Look-Up Tables for Purple Flare Removal](https://arxiv.org/abs/2511.06764)
*Pu Wang,Shuning Sun,Jialang Lu,Chen Wu,Zhihua Zhang,Youshan Zhang,Chenggang Shan,Dianjie Lu,Guijuan Zhang,Zhuoran Zheng*

Main category: cs.CV

TL;DR: 提出基于解耦HSV查找表的网络来解决紫边伪影问题，通过两阶段架构实现独立颜色通道校正，并构建了首个大规模紫边数据集。


<details>
  <summary>Details</summary>
Motivation: 紫边伪影严重影响图像质量，传统方法依赖手工特征缺乏灵活性，而深度学习面临配对训练数据稀缺的问题。

Method: 采用两阶段架构：首先使用色度感知频谱标记器将RGB转换为HSV空间并独立编码H和V通道；然后HSV-LUT模块动态生成三个通道的独立校正曲线。

Result: 实验表明该方法在视觉效果上显著优于现有方法，在所有定量指标上达到最先进性能。

Conclusion: 该方法有效解决了紫边伪影问题，为颜色校正任务提供了新的解决方案。

Abstract: Purple flare, a diffuse chromatic aberration artifact commonly found around
highlight areas, severely degrades the tone transition and color of the image.
Existing traditional methods are based on hand-crafted features, which lack
flexibility and rely entirely on fixed priors, while the scarcity of paired
training data critically hampers deep learning. To address this issue, we
propose a novel network built upon decoupled HSV Look-Up Tables (LUTs). The
method aims to simplify color correction by adjusting the Hue (H), Saturation
(S), and Value (V) components independently. This approach resolves the
inherent color coupling problems in traditional methods. Our model adopts a
two-stage architecture: First, a Chroma-Aware Spectral Tokenizer (CAST)
converts the input image from RGB space to HSV space and independently encodes
the Hue (H) and Value (V) channels into a set of semantic tokens describing the
Purple flare status; second, the HSV-LUT module takes these tokens as input and
dynamically generates independent correction curves (1D-LUTs) for the three
channels H, S, and V. To effectively train and validate our model, we built the
first large-scale purple flare dataset with diverse scenes. We also proposed
new metrics and a loss function specifically designed for this task. Extensive
experiments demonstrate that our model not only significantly outperforms
existing methods in visual effects but also achieves state-of-the-art
performance on all quantitative metrics.

</details>


### [155] [Robust and High-Fidelity 3D Gaussian Splatting: Fusing Pose Priors and Geometry Constraints for Texture-Deficient Outdoor Scenes](https://arxiv.org/abs/2511.06765)
*Meijun Guo,Yongliang Shi,Caiyun Liu,Yixiao Feng,Ming Ma,Tinghai Yan,Weining Lu,Bin Liang*

Main category: cs.CV

TL;DR: 本文提出了一种改进的3D高斯泼溅方法，通过结合LiDAR-IMU里程计的先验位姿约束以及引入法向量约束和有效秩正则化，解决了大尺度户外场景中弱纹理或重复纹理导致的位姿估计不稳定和场景表示失真问题。


<details>
  <summary>Details</summary>
Motivation: 大尺度户外场景中弱纹理或重复纹理会导致几何纹理不一致，从而引起位姿估计不稳定和场景表示失真，需要从位姿估计和场景表示两方面来解决这一问题。

Method: 在位姿估计方面，利用LiDAR-IMU里程计提供先验位姿约束，并将其整合到COLMAP的三角测量过程中；在场景表示方面，引入法向量约束和有效秩正则化来保证高斯基元的方向和形状一致性，与现有的光度损失联合优化。

Result: 在公开和自采集数据集上的实验表明，该方法在位姿优化方面仅需三分之一的时间就能保持准确性和鲁棒性；在场景表示方面显著优于传统3DGS方法，特别是在弱纹理或重复纹理场景中表现出更好的可视化效果和整体性能。

Conclusion: 该方法通过结合先验位姿约束和几何一致性约束，有效解决了大尺度户外场景中的位姿估计和场景表示问题，在保持效率的同时显著提升了渲染质量。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a key rendering pipeline for
digital asset creation due to its balance between efficiency and visual
quality. To address the issues of unstable pose estimation and scene
representation distortion caused by geometric texture inconsistency in large
outdoor scenes with weak or repetitive textures, we approach the problem from
two aspects: pose estimation and scene representation. For pose estimation, we
leverage LiDAR-IMU Odometry to provide prior poses for cameras in large-scale
environments. These prior pose constraints are incorporated into COLMAP's
triangulation process, with pose optimization performed via bundle adjustment.
Ensuring consistency between pixel data association and prior poses helps
maintain both robustness and accuracy. For scene representation, we introduce
normal vector constraints and effective rank regularization to enforce
consistency in the direction and shape of Gaussian primitives. These
constraints are jointly optimized with the existing photometric loss to enhance
the map quality. We evaluate our approach using both public and self-collected
datasets. In terms of pose optimization, our method requires only one-third of
the time while maintaining accuracy and robustness across both datasets. In
terms of scene representation, the results show that our method significantly
outperforms conventional 3DGS pipelines. Notably, on self-collected datasets
characterized by weak or repetitive textures, our approach demonstrates
enhanced visualization capabilities and achieves superior overall performance.
Codes and data will be publicly available at
https://github.com/justinyeah/normal_shape.git.

</details>


### [156] [ConeGS: Error-Guided Densification Using Pixel Cones for Improved Reconstruction with Fewer Primitives](https://arxiv.org/abs/2511.06810)
*Bartłomiej Baranowski,Stefano Esposito,Patricia Gschoßmann,Anpei Chen,Andreas Geiger*

Main category: cs.CV

TL;DR: ConeGS提出了一种基于图像空间信息的3D高斯分布优化框架，通过使用iNGP作为几何代理来估计深度，在高误差像素处沿视锥插入新高斯，解决了传统3DGS中基于克隆的致密化导致的次优空间分布问题。


<details>
  <summary>Details</summary>
Motivation: 传统3D高斯分布方法存在高斯分布不理想的问题，主要源于基于克隆的致密化策略，这种策略会沿着现有几何结构传播高斯，限制了探索能力，需要大量基元才能充分覆盖场景。

Method: 1. 使用iNGP快速重建作为几何代理估计每像素深度
2. 在3DGS优化过程中识别高误差像素
3. 沿预测深度值的对应视锥插入新高斯
4. 使用预激活不透明度惩罚快速移除冗余高斯
5. 采用基元预算策略控制总基元数量

Result: ConeGS在不同高斯预算下都能提升重建质量和渲染性能，特别是在基元约束严格的情况下效果尤为显著，其中高效的基元布局至关重要。

Conclusion: ConeGS框架通过独立于现有场景几何状态的图像空间信息引导的致密化，有效解决了3D高斯分布的空间优化问题，实现了更好的重建质量和渲染效率。

Abstract: 3D Gaussian Splatting (3DGS) achieves state-of-the-art image quality and
real-time performance in novel view synthesis but often suffers from a
suboptimal spatial distribution of primitives. This issue stems from
cloning-based densification, which propagates Gaussians along existing
geometry, limiting exploration and requiring many primitives to adequately
cover the scene. We present ConeGS, an image-space-informed densification
framework that is independent of existing scene geometry state. ConeGS first
creates a fast Instant Neural Graphics Primitives (iNGP) reconstruction as a
geometric proxy to estimate per-pixel depth. During the subsequent 3DGS
optimization, it identifies high-error pixels and inserts new Gaussians along
the corresponding viewing cones at the predicted depth values, initializing
their size according to the cone diameter. A pre-activation opacity penalty
rapidly removes redundant Gaussians, while a primitive budgeting strategy
controls the total number of primitives, either by a fixed budget or by
adapting to scene complexity, ensuring high reconstruction quality. Experiments
show that ConeGS consistently enhances reconstruction quality and rendering
performance across Gaussian budgets, with especially strong gains under tight
primitive constraints where efficient placement is crucial.

</details>


### [157] [TiS-TSL: Image-Label Supervised Surgical Video Stereo Matching via Time-Switchable Teacher-Student Learning](https://arxiv.org/abs/2511.06817)
*Rui Wang,Ying Zhou,Hao Wang,Wenwei Zhang,Qiang Li,Zhiwei Wang*

Main category: cs.CV

TL;DR: TiS-TSL是一个新颖的时间可切换师生学习框架，用于最小监督下的视频立体匹配，通过统一模型实现图像和视频预测模式，显著提升时间一致性和减少闪烁伪影。


<details>
  <summary>Details</summary>
Motivation: 现有师生学习方法仅提供图像级监督，缺乏时间一致性估计，导致立体匹配预测不稳定和帧间闪烁伪影严重。

Method: 提出TiS-TSL框架，包含统一模型支持三种预测模式（IP、FVP、BVP），采用两阶段学习策略：I2V阶段从稀疏图像知识初始化时间建模，V2V阶段通过双向时空一致性过滤噪声伪标签并强制时间一致性。

Result: 在两个公共数据集上的实验表明，TiS-TSL在TEPE和EPE指标上分别比现有图像级方法至少提升2.11%和4.54%。

Conclusion: TiS-TSL通过引入时间可切换机制和双向时空一致性估计，有效解决了手术视频立体匹配中的时间不稳定问题，为最小监督下的立体匹配提供了新思路。

Abstract: Stereo matching in minimally invasive surgery (MIS) is essential for
next-generation navigation and augmented reality. Yet, dense disparity
supervision is nearly impossible due to anatomical constraints, typically
limiting annotations to only a few image-level labels acquired before the
endoscope enters deep body cavities. Teacher-Student Learning (TSL) offers a
promising solution by leveraging a teacher trained on sparse labels to generate
pseudo labels and associated confidence maps from abundant unlabeled surgical
videos. However, existing TSL methods are confined to image-level supervision,
providing only spatial confidence and lacking temporal consistency estimation.
This absence of spatio-temporal reliability results in unstable disparity
predictions and severe flickering artifacts across video frames. To overcome
these challenges, we propose TiS-TSL, a novel time-switchable teacher-student
learning framework for video stereo matching under minimal supervision. At its
core is a unified model that operates in three distinct modes: Image-Prediction
(IP), Forward Video-Prediction (FVP), and Backward Video-Prediction (BVP),
enabling flexible temporal modeling within a single architecture. Enabled by
this unified model, TiS-TSL adopts a two-stage learning strategy. The
Image-to-Video (I2V) stage transfers sparse image-level knowledge to initialize
temporal modeling. The subsequent Video-to-Video (V2V) stage refines temporal
disparity predictions by comparing forward and backward predictions to
calculate bidirectional spatio-temporal consistency. This consistency
identifies unreliable regions across frames, filters noisy video-level pseudo
labels, and enforces temporal coherence. Experimental results on two public
datasets demonstrate that TiS-TSL exceeds other image-based state-of-the-arts
by improving TEPE and EPE by at least 2.11% and 4.54%, respectively..

</details>


### [158] [Integrating Reweighted Least Squares with Plug-and-Play Diffusion Priors for Noisy Image Restoration](https://arxiv.org/abs/2511.06823)
*Ji Li,Chao Wang*

Main category: cs.CV

TL;DR: 提出了一种基于生成扩散先验的即插即用图像恢复框架，用于处理包括脉冲噪声在内的非高斯噪声类型。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要针对高斯噪声，对非高斯噪声（如脉冲噪声）的处理研究不足，需要开发能够适应多种噪声类型的通用图像恢复方法。

Method: 在MAP估计框架下，采用广义高斯尺度混合损失函数来适应不同噪声模型，使用迭代重加权最小二乘法（IRLS）进行优化，并通过扩散去噪器高效执行生成先验的邻近步骤。

Result: 在基准数据集上的实验结果表明，该方法能有效去除非高斯脉冲噪声，并实现优越的恢复性能。

Conclusion: 该方法为处理非高斯噪声提供了一种有效的解决方案，扩展了生成先验在图像恢复中的应用范围。

Abstract: Existing plug-and-play image restoration methods typically employ
off-the-shelf Gaussian denoisers as proximal operators within classical
optimization frameworks based on variable splitting. Recently, denoisers
induced by generative priors have been successfully integrated into regularized
optimization methods for image restoration under Gaussian noise. However, their
application to non-Gaussian noise--such as impulse noise--remains largely
unexplored. In this paper, we propose a plug-and-play image restoration
framework based on generative diffusion priors for robust removal of general
noise types, including impulse noise. Within the maximum a posteriori (MAP)
estimation framework, the data fidelity term is adapted to the specific noise
model. Departing from the conventional least-squares loss used for Gaussian
noise, we introduce a generalized Gaussian scale mixture-based loss, which
approximates a wide range of noise distributions and leads to an $\ell_q$-norm
($0<q\leq2$) fidelity term. This optimization problem is addressed using an
iteratively reweighted least squares (IRLS) approach, wherein the proximal step
involving the generative prior is efficiently performed via a diffusion-based
denoiser. Experimental results on benchmark datasets demonstrate that the
proposed method effectively removes non-Gaussian impulse noise and achieves
superior restoration performance.

</details>


### [159] [MUGSQA: Novel Multi-Uncertainty-Based Gaussian Splatting Quality Assessment Method, Dataset, and Benchmarks](https://arxiv.org/abs/2511.06830)
*Tianang Chen,Jian Jin,Shilv Cai,Zhuangzi Li,Weisi Lin*

Main category: cs.CV

TL;DR: 该论文提出了一个统一的多距离主观质量评估方法，用于评估基于高斯泼溅(GS)的3D重建方法的感知质量，并构建了名为MUGSQA的新数据集和两个基准测试。


<details>
  <summary>Details</summary>
Motivation: 随着高斯泼溅(GS)技术在3D物体重建中的快速发展，评估不同GS方法重建的3D物体的感知质量成为一个重要挑战。现有方法缺乏对实际应用中人类观看行为的模拟。

Method: 1. 提出统一的多距离主观质量评估方法，模拟人类在实际应用中的观看行为
2. 构建MUGSQA数据集，考虑输入数据的多种不确定性因素
3. 建立两个基准测试：评估GS重建方法的鲁棒性和现有质量评估指标的性能

Result: 开发了一个新的质量评估数据集和基准测试框架，能够更准确地评估GS重建方法的感知质量。

Conclusion: 该研究为解决GS重建方法的质量评估问题提供了有效工具，数据集和代码将公开发布以促进相关研究发展。

Abstract: Gaussian Splatting (GS) has recently emerged as a promising technique for 3D
object reconstruction, delivering high-quality rendering results with
significantly improved reconstruction speed. As variants continue to appear,
assessing the perceptual quality of 3D objects reconstructed with different
GS-based methods remains an open challenge. To address this issue, we first
propose a unified multi-distance subjective quality assessment method that
closely mimics human viewing behavior for objects reconstructed with GS-based
methods in actual applications, thereby better collecting perceptual
experiences. Based on it, we also construct a novel GS quality assessment
dataset named MUGSQA, which is constructed considering multiple uncertainties
of the input data. These uncertainties include the quantity and resolution of
input views, the view distance, and the accuracy of the initial point cloud.
Moreover, we construct two benchmarks: one to evaluate the robustness of
various GS-based reconstruction methods under multiple uncertainties, and the
other to evaluate the performance of existing quality assessment metrics. Our
dataset and benchmark code will be released soon.

</details>


### [160] [ConsistTalk: Intensity Controllable Temporally Consistent Talking Head Generation with Diffusion Noise Search](https://arxiv.org/abs/2511.06833)
*Zhenjie Liu,Jianzhang Lu,Renjie Lu,Cong Liang,Shangfei Wang*

Main category: cs.CV

TL;DR: ConsistTalk是一个强度可控、时序一致的人脸动画生成框架，通过解耦外观-运动表示和稳定推理策略，解决了现有方法存在的闪烁、身份漂移和音视频同步问题。


<details>
  <summary>Details</summary>
Motivation: 当前视频扩散模型在音频驱动的人脸动画生成中存在闪烁、身份漂移和音视频同步不佳的问题，主要源于纠缠的外观-运动表示和不稳定的推理策略。

Method: 提出三个关键技术：1）光流引导时序模块（OFT）通过面部光流解耦运动特征；2）音频-强度模型（A2I）通过多模态知识蒸馏实现帧级强度控制；3）扩散噪声初始化策略（IC-Init）在推理时对背景一致性和运动连续性施加约束。

Result: 大量实验表明，ConsistTalk在减少闪烁、保持身份特征和生成时序稳定的高保真说话人视频方面显著优于现有方法。

Conclusion: 该框架通过解耦表示和稳定推理策略，有效解决了音频驱动人脸动画中的关键问题，实现了高质量的时序一致生成。

Abstract: Recent advancements in video diffusion models have significantly enhanced
audio-driven portrait animation. However, current methods still suffer from
flickering, identity drift, and poor audio-visual synchronization. These issues
primarily stem from entangled appearance-motion representations and unstable
inference strategies. In this paper, we introduce \textbf{ConsistTalk}, a novel
intensity-controllable and temporally consistent talking head generation
framework with diffusion noise search inference. First, we propose \textbf{an
optical flow-guided temporal module (OFT)} that decouples motion features from
static appearance by leveraging facial optical flow, thereby reducing visual
flicker and improving temporal consistency. Second, we present an
\textbf{Audio-to-Intensity (A2I) model} obtained through multimodal
teacher-student knowledge distillation. By transforming audio and facial
velocity features into a frame-wise intensity sequence, the A2I model enables
joint modeling of audio and visual motion, resulting in more natural dynamics.
This further enables fine-grained, frame-wise control of motion dynamics while
maintaining tight audio-visual synchronization. Third, we introduce a
\textbf{diffusion noise initialization strategy (IC-Init)}. By enforcing
explicit constraints on background coherence and motion continuity during
inference-time noise search, we achieve better identity preservation and refine
motion dynamics compared to the current autoregressive strategy. Extensive
experiments demonstrate that ConsistTalk significantly outperforms prior
methods in reducing flicker, preserving identity, and delivering temporally
stable, high-fidelity talking head videos.

</details>


### [161] [NeuroBridge: Bio-Inspired Self-Supervised EEG-to-Image Decoding via Cognitive Priors and Bidirectional Semantic Alignment](https://arxiv.org/abs/2511.06836)
*Wenjiang Zhang,Sifeng Wang,Yuwei Su,Xinyu Li,Chen Zhang,Suyu Zhong*

Main category: cs.CV

TL;DR: 本文提出了一种名为NeuroBridge的自监督架构，通过认知先验增强和共享语义投影器解决视觉神经解码中的语义不匹配问题，在脑电图信号和图像之间建立有效的跨模态对齐。


<details>
  <summary>Details</summary>
Motivation: 当前视觉神经解码方法受限于高质量刺激-脑响应对的稀缺性以及神经表示与视觉内容之间的语义不匹配问题。受到生物系统感知可变性和共适应策略的启发，作者旨在开发更有效的跨模态对齐方法。

Method: NeuroBridge架构包含两个核心组件：认知先验增强通过不对称的模态特定变换增强语义多样性；共享语义投影器通过共适应策略建立双向对齐过程，将两种模态的特征映射到共享语义空间。

Result: 在200路零样本检索任务中，NeuroBridge在受试者内设置下实现了12.3%的top-1准确率和10.2%的top-5准确率提升，分别达到63.2%和89.9%，超越了现有最先进方法。

Conclusion: NeuroBridge框架在神经视觉解码方面表现出有效性、鲁棒性和可扩展性，为脑机接口和人工智能应用提供了重要进展。

Abstract: Visual neural decoding seeks to reconstruct or infer perceived visual stimuli
from brain activity patterns, providing critical insights into human cognition
and enabling transformative applications in brain-computer interfaces and
artificial intelligence. Current approaches, however, remain constrained by the
scarcity of high-quality stimulus-brain response pairs and the inherent
semantic mismatch between neural representations and visual content. Inspired
by perceptual variability and co-adaptive strategy of the biological systems,
we propose a novel self-supervised architecture, named NeuroBridge, which
integrates Cognitive Prior Augmentation (CPA) with Shared Semantic Projector
(SSP) to promote effective cross-modality alignment. Specifically, CPA
simulates perceptual variability by applying asymmetric, modality-specific
transformations to both EEG signals and images, enhancing semantic diversity.
Unlike previous approaches, SSP establishes a bidirectional alignment process
through a co-adaptive strategy, which mutually aligns features from two
modalities into a shared semantic space for effective cross-modal learning.
NeuroBridge surpasses previous state-of-the-art methods under both
intra-subject and inter-subject settings. In the intra-subject scenario, it
achieves the improvements of 12.3% in top-1 accuracy and 10.2% in top-5
accuracy, reaching 63.2% and 89.9% respectively on a 200-way zero-shot
retrieval task. Extensive experiments demonstrate the effectiveness,
robustness, and scalability of the proposed framework for neural visual
decoding.

</details>


### [162] [Gaussian-Augmented Physics Simulation and System Identification with Complex Colliders](https://arxiv.org/abs/2511.06846)
*Federico Vasile,Ri-Zhao Qiu,Lorenzo Natale,Xiaolong Wang*

Main category: cs.CV

TL;DR: AS-DiffMPM是一个可微分MPM框架，支持任意形状碰撞体的物理属性估计，解决了现有方法在非平面碰撞场景中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于可微分MPM的方法局限于简化的平面碰撞体交互，无法处理物体与非平面表面的复杂碰撞场景。

Method: 通过引入可微分碰撞处理机制，扩展现有方法，使目标物体能够与复杂刚体交互，同时保持端到端优化能力。

Result: AS-DiffMPM可与多种新视角合成方法接口，作为从视觉观测进行系统识别的框架。

Conclusion: 该框架在机器人学和图形学应用中具有潜力，能够处理更复杂的物体-环境交互场景。

Abstract: System identification involving the geometry, appearance, and physical
properties from video observations is a challenging task with applications in
robotics and graphics. Recent approaches have relied on fully differentiable
Material Point Method (MPM) and rendering for simultaneous optimization of
these properties. However, they are limited to simplified object-environment
interactions with planar colliders and fail in more challenging scenarios where
objects collide with non-planar surfaces. We propose AS-DiffMPM, a
differentiable MPM framework that enables physical property estimation with
arbitrarily shaped colliders. Our approach extends existing methods by
incorporating a differentiable collision handling mechanism, allowing the
target object to interact with complex rigid bodies while maintaining
end-to-end optimization. We show AS-DiffMPM can be easily interfaced with
various novel view synthesis methods as a framework for system identification
from visual observations.

</details>


### [163] [Distillation Dynamics: Towards Understanding Feature-Based Distillation in Vision Transformers](https://arxiv.org/abs/2511.06848)
*Huiyuan Tian,Bonan Xu Shijian Li*

Main category: cs.CV

TL;DR: 本文分析了特征蒸馏在Vision Transformers（ViTs）压缩中失效的原因，发现ViTs呈现U形信息处理模式，教师模型与学生模型之间存在表示范式不匹配，导致负迁移。


<details>
  <summary>Details</summary>
Motivation: 特征蒸馏在压缩CNNs时非常有效，但在ViTs中却意外失效，甚至比简单的logit蒸馏效果更差。本文旨在通过系统分析揭示这一现象的根本原因。

Method: 提出了"蒸馏动力学"分析框架，结合频谱分析、信息熵度量和激活幅度跟踪，研究ViTs的信息处理模式。通过频域分析揭示教师模型与学生模型在表示范式上的不匹配。

Result: 发现ViTs具有独特的U形信息处理模式（先压缩后扩展），教师模型在后期层采用分布式高维编码策略，而学生模型由于通道容量有限无法复制，导致后期层特征对齐反而损害学生性能。

Conclusion: ViTs中的成功知识传递需要超越简单的特征模仿，开发尊重表示范式约束的方法，为设计有效的ViTs压缩策略提供了重要理论指导。

Abstract: While feature-based knowledge distillation has proven highly effective for
compressing CNNs, these techniques unexpectedly fail when applied to Vision
Transformers (ViTs), often performing worse than simple logit-based
distillation. We provide the first comprehensive analysis of this phenomenon
through a novel analytical framework termed as ``distillation dynamics",
combining frequency spectrum analysis, information entropy metrics, and
activation magnitude tracking. Our investigation reveals that ViTs exhibit a
distinctive U-shaped information processing pattern: initial compression
followed by expansion. We identify the root cause of negative transfer in
feature distillation: a fundamental representational paradigm mismatch between
teacher and student models. Through frequency-domain analysis, we show that
teacher models employ distributed, high-dimensional encoding strategies in
later layers that smaller student models cannot replicate due to limited
channel capacity. This mismatch causes late-layer feature alignment to actively
harm student performance. Our findings reveal that successful knowledge
transfer in ViTs requires moving beyond naive feature mimicry to methods that
respect these fundamental representational constraints, providing essential
theoretical guidance for designing effective ViTs compression strategies. All
source code and experimental logs are provided in the supplementary material.

</details>


### [164] [Ambiguity-aware Truncated Flow Matching for Ambiguous Medical Image Segmentation](https://arxiv.org/abs/2511.06857)
*Fanding Li,Xiangyu Li,Xianghe Su,Xingyu Qiu,Suyu Dong,Wei Wang,Kuanquan Wang,Gongning Luo,Shuo Li*

Main category: cs.CV

TL;DR: ATFM是一种用于模糊医学图像分割的新方法，通过数据层次推理、高斯截断表示和分割流匹配技术，在准确性和多样性之间实现有效解耦，显著提升了分割性能。


<details>
  <summary>Details</summary>
Motivation: 解决模糊医学图像分割中准确性和多样性之间的权衡问题，现有截断扩散概率模型存在预测准确性和多样性纠缠、保真度和合理性不足的挑战。

Method: 1. 数据层次推理：在数据分布层面增强准确性，在数据样本层面增强多样性；2. 高斯截断表示：将截断分布显式建模为高斯分布；3. 分割流匹配：扩展语义感知流变换来增强预测合理性。

Result: 在LIDC和ISIC3数据集上的评估显示，ATFM优于现有最先进方法，推理效率更高，GED和HM-IoU指标分别提升高达12%和7.3%。

Conclusion: ATFM通过创新的推理范式和模型组件，成功解决了模糊医学图像分割中的准确性与多样性权衡问题，实现了同时提升分割性能和推理效率的目标。

Abstract: A simultaneous enhancement of accuracy and diversity of predictions remains a
challenge in ambiguous medical image segmentation (AMIS) due to the inherent
trade-offs. While truncated diffusion probabilistic models (TDPMs) hold strong
potential with a paradigm optimization, existing TDPMs suffer from entangled
accuracy and diversity of predictions with insufficient fidelity and
plausibility. To address the aforementioned challenges, we propose
Ambiguity-aware Truncated Flow Matching (ATFM), which introduces a novel
inference paradigm and dedicated model components. Firstly, we propose
Data-Hierarchical Inference, a redefinition of AMIS-specific inference
paradigm, which enhances accuracy and diversity at data-distribution and
data-sample level, respectively, for an effective disentanglement. Secondly,
Gaussian Truncation Representation (GTR) is introduced to enhance both fidelity
of predictions and reliability of truncation distribution, by explicitly
modeling it as a Gaussian distribution at $T_{\text{trunc}}$ instead of using
sampling-based approximations.Thirdly, Segmentation Flow Matching (SFM) is
proposed to enhance the plausibility of diverse predictions by extending
semantic-aware flow transformation in Flow Matching (FM). Comprehensive
evaluations on LIDC and ISIC3 datasets demonstrate that ATFM outperforms SOTA
methods and simultaneously achieves a more efficient inference. ATFM improves
GED and HM-IoU by up to $12\%$ and $7.3\%$ compared to advanced methods.

</details>


### [165] [VAEVQ: Enhancing Discrete Visual Tokenization through Variational Modeling](https://arxiv.org/abs/2511.06863)
*Sicheng Yang,Xing Hu,Qiang Wu,Dawei Yang*

Main category: cs.CV

TL;DR: VAEVQ是一种改进的向量量化方法，通过变分自编码器、表示一致性策略和分布一致性正则化解决传统VQ方法的潜在空间不连续、表示对齐弱和连续-离散域一致性差等问题。


<details>
  <summary>Details</summary>
Motivation: 传统向量量化方法存在潜在空间不连续、量化前后表示对齐弱、连续-离散域一致性差等问题，导致码字学习不稳定和码本利用率低，影响重建和生成任务性能。

Method: 提出VAEVQ框架，包含三个核心组件：(1)变分潜在量化(VLQ)用VAE替代AE以获得平滑潜在空间；(2)表示一致性策略(RCS)自适应调节量化前后特征对齐强度；(3)分布一致性正则化(DCR)对齐码本分布与连续潜在分布。

Result: 在两个基准数据集上的实验表明，VAEVQ在性能上优于现有最先进方法。

Conclusion: VAEVQ通过改进的量化框架有效解决了传统VQ方法的问题，提升了码本利用率和生成任务性能。

Abstract: Vector quantization (VQ) transforms continuous image features into discrete
representations, providing compressed, tokenized inputs for generative models.
However, VQ-based frameworks suffer from several issues, such as non-smooth
latent spaces, weak alignment between representations before and after
quantization, and poor coherence between the continuous and discrete domains.
These issues lead to unstable codeword learning and underutilized codebooks,
ultimately degrading the performance of both reconstruction and downstream
generation tasks. To this end, we propose VAEVQ, which comprises three key
components: (1) Variational Latent Quantization (VLQ), replacing the AE with a
VAE for quantization to leverage its structured and smooth latent space,
thereby facilitating more effective codeword activation; (2) Representation
Coherence Strategy (RCS), adaptively modulating the alignment strength between
pre- and post-quantization features to enhance consistency and prevent
overfitting to noise; and (3) Distribution Consistency Regularization (DCR),
aligning the entire codebook distribution with the continuous latent
distribution to improve utilization. Extensive experiments on two benchmark
datasets demonstrate that VAEVQ outperforms state-of-the-art methods.

</details>


### [166] [Generating an Image From 1,000 Words: Enhancing Text-to-Image With Structured Captions](https://arxiv.org/abs/2511.06876)
*Eyal Gutflaish,Eliran Kachlon,Hezi Zisman,Tal Hacham,Nimrod Sarid,Alexander Visheratin,Saar Huberman,Gal Davidi,Guy Bukchin,Kfir Goldberg,Ron Mokady*

Main category: cs.CV

TL;DR: 本文提出FIBO模型，通过长结构化字幕训练实现更精确的文本到图像生成控制，引入DimFusion融合机制和TaBR评估协议，在开源模型中达到最先进的提示对齐效果。


<details>
  <summary>Details</summary>
Motivation: 传统文本到图像模型在稀疏文本输入和丰富视觉输出之间存在不匹配，导致控制性不足，模型往往基于平均用户偏好随意填充细节，限制了专业使用的精确性。

Method: 1. 使用长结构化字幕训练首个开源文本到图像模型，每个训练样本都用相同的细粒度属性集标注；2. 提出DimFusion融合机制，在不增加令牌长度的情况下集成轻量级LLM的中间令牌；3. 引入TaBR评估协议，通过字幕生成循环评估真实图像的重建质量。

Result: 训练的大规模模型FIBO在开源模型中实现了最先进的提示对齐效果，模型权重已公开。

Conclusion: 通过长结构化字幕训练和创新的融合机制，显著提升了文本到图像生成的控制性和表达能力，为专业应用提供了更精确的解决方案。

Abstract: Text-to-image models have rapidly evolved from casual creative tools to
professional-grade systems, achieving unprecedented levels of image quality and
realism. Yet, most models are trained to map short prompts into detailed
images, creating a gap between sparse textual input and rich visual outputs.
This mismatch reduces controllability, as models often fill in missing details
arbitrarily, biasing toward average user preferences and limiting precision for
professional use. We address this limitation by training the first open-source
text-to-image model on long structured captions, where every training sample is
annotated with the same set of fine-grained attributes. This design maximizes
expressive coverage and enables disentangled control over visual factors. To
process long captions efficiently, we propose DimFusion, a fusion mechanism
that integrates intermediate tokens from a lightweight LLM without increasing
token length. We also introduce the Text-as-a-Bottleneck Reconstruction (TaBR)
evaluation protocol. By assessing how well real images can be reconstructed
through a captioning-generation loop, TaBR directly measures controllability
and expressiveness, even for very long captions where existing evaluation
methods fail. Finally, we demonstrate our contributions by training the
large-scale model FIBO, achieving state-of-the-art prompt alignment among
open-source models. Model weights are publicly available at
https://huggingface.co/briaai/FIBO

</details>


### [167] [A Two-Stage System for Layout-Controlled Image Generation using Large Language Models and Diffusion Models](https://arxiv.org/abs/2511.06888)
*Jan-Hendrik Koch,Jonas Krumme,Konrad Gadzicki*

Main category: cs.CV

TL;DR: 该论文提出了一个两阶段系统来解决文本到图像扩散模型在物体计数和空间布局控制方面的局限性，通过LLM生成结构化布局和布局条件扩散模型合成图像，实现了对物体数量和空间排列的精确控制。


<details>
  <summary>Details</summary>
Motivation: 文本到图像扩散模型虽然具有强大的生成能力，但在控制物体数量和空间布局方面存在不足，无法精确满足复杂场景的构图需求。

Method: 采用两阶段方法：第一阶段使用大型语言模型（LLM）从物体列表生成结构化布局；第二阶段使用布局条件扩散模型（对比ControlNet和GLIGEN）合成符合布局的真实感图像。通过任务分解和规则化插入提升物体召回率。

Result: 通过简化初始生成和规则化插入，物体召回率从57.2%提升到99.9%。ControlNet保持文本风格控制但存在物体幻觉问题，GLIGEN提供更好的布局保真度但牺牲了提示可控性。

Conclusion: 端到端系统成功生成具有指定物体数量和合理空间布局的图像，证明了分离式方法在组合控制合成中的可行性。

Abstract: Text-to-image diffusion models exhibit remarkable generative capabilities,
but lack precise control over object counts and spatial arrangements. This work
introduces a two-stage system to address these compositional limitations. The
first stage employs a Large Language Model (LLM) to generate a structured
layout from a list of objects. The second stage uses a layout-conditioned
diffusion model to synthesize a photorealistic image adhering to this layout.
We find that task decomposition is critical for LLM-based spatial planning; by
simplifying the initial generation to core objects and completing the layout
with rule-based insertion, we improve object recall from 57.2% to 99.9% for
complex scenes. For image synthesis, we compare two leading conditioning
methods: ControlNet and GLIGEN. After domain-specific finetuning on
table-setting datasets, we identify a key trade-off: ControlNet preserves
text-based stylistic control but suffers from object hallucination, while
GLIGEN provides superior layout fidelity at the cost of reduced prompt-based
controllability. Our end-to-end system successfully generates images with
specified object counts and plausible spatial arrangements, demonstrating the
viability of a decoupled approach for compositionally controlled synthesis.

</details>


### [168] [Adaptive Morph-Patch Transformer for Arotic Vessel Segmentation](https://arxiv.org/abs/2511.06897)
*Zhenxi Zhang,Fuchen Zheng,Adnan Iltaf,Yifei Han,Zhenyu Cheng,Yue Du,Bin Li,Tianyong Liu,Shoujun Zhou*

Main category: cs.CV

TL;DR: 提出自适应形态补丁变换器（MPT），通过形态感知补丁划分和语义聚类注意力机制，改进主动脉血管结构分割精度


<details>
  <summary>Details</summary>
Motivation: 传统Transformer模型使用固定大小的矩形补丁会破坏复杂血管结构的完整性，导致分割精度不理想

Method: MPT引入自适应补丁划分策略动态生成与血管结构对齐的形态感知补丁，并提出语义聚类注意力机制聚合相似语义特征

Result: 在三个开源数据集上的实验表明MPT达到最先进性能，在复杂血管结构分割方面有显著改进

Conclusion: MPT通过自适应补丁划分和语义聚类注意力有效解决了血管结构分割中的完整性保持问题

Abstract: Accurate segmentation of aortic vascular structures is critical for
diagnosing and treating cardiovascular diseases.Traditional Transformer-based
models have shown promise in this domain by capturing long-range dependencies
between vascular features. However, their reliance on fixed-size rectangular
patches often influences the integrity of complex vascular structures, leading
to suboptimal segmentation accuracy. To address this challenge, we propose the
adaptive Morph Patch Transformer (MPT), a novel architecture specifically
designed for aortic vascular segmentation. Specifically, MPT introduces an
adaptive patch partitioning strategy that dynamically generates
morphology-aware patches aligned with complex vascular structures. This
strategy can preserve semantic integrity of complex vascular structures within
individual patches. Moreover, a Semantic Clustering Attention (SCA) method is
proposed to dynamically aggregate features from various patches with similar
semantic characteristics. This method enhances the model's capability to
segment vessels of varying sizes, preserving the integrity of vascular
structures. Extensive experiments on three open-source dataset(AVT, AortaSeg24
and TBAD) demonstrate that MPT achieves state-of-the-art performance, with
improvements in segmenting intricate vascular structures.

</details>


### [169] [Classification of Microplastic Particles in Water using Polarized Light Scattering and Machine Learning Methods](https://arxiv.org/abs/2511.06901)
*Leonard Saur,Marc von Pawlowski,Ulrich Gengenbach,Ingo Sieber,Hossein Shirali,Lorenz Wührl,Rainer Kiko,Christian Pylatiuk*

Main category: cs.CV

TL;DR: 提出基于偏振光散射的反射式方法，用于水体中微塑料的原位分类识别，克服传统透射方法的干扰问题


<details>
  <summary>Details</summary>
Motivation: 面对水体环境中微塑料连续大规模监测的迫切需求，传统金标准方法存在局限性，需要开发新的原位检测技术

Method: 使用线性偏振激光照射无色微塑料颗粒（50-300μm），通过偏振敏感相机捕获反射信号，采用深度卷积神经网络进行图像分类

Result: 成功识别三种常见聚合物类型（高密度聚乙烯、低密度聚乙烯、聚丙烯），测试集平均分类准确率达80%，AOLP信号比DOLP信号对上下文噪声更鲁棒

Conclusion: 反射式偏振光散射技术为水体微塑料原位监测提供了可行方案，AOLP和DOLP信号在不同聚合物分类中各有优势

Abstract: Facing the critical need for continuous, large-scale microplastic monitoring,
which is hindered by the limitations of gold-standard methods in aquatic
environments, this paper introduces and validates a novel, reflection-based
approach for the in-situ classification and identification of microplastics
directly in water bodies, which is based on polarized light scattering. In this
experiment, we classify colorless microplastic particles (50-300 $\mu$m) by
illuminating them with linearly polarized laser light and capturing their
reflected signals using a polarization-sensitive camera. This reflection-based
technique successfully circumvents the transmission-based interference issues
that plague many conventional methods when applied in water. Using a deep
convolutional neural network (CNN) for image-based classification, we
successfully identified three common polymer types, high-density polyethylene,
low-density polyethylene, and polypropylene, achieving a peak mean
classification accuracy of 80% on the test dataset. A subsequent feature
hierarchy analysis demonstrated that the CNN's decision-making process relies
mainly on the microstructural integrity and internal texture (polarization
patterns) of the particle rather than its macroshape. Critically, we found that
the Angle of Linear Polarization (AOLP) signal is significantly more robust
against contextual noise than the Degree of Linear Polarization (DOLP) signal.
While the AOLP-based classification achieved superior overall performance, its
strength lies in distinguishing between the two polyethylene plastics, showing
a lower confusion rate between high-density and low-density polyethylene.
Conversely, the DOLP signal demonstrated slightly worse overall classification
results but excels at accurately identifying the polypropylene class, which it
isolated with greater success than AOLP.

</details>


### [170] [Mono3DVG-EnSD: Enhanced Spatial-aware and Dimension-decoupled Text Encoding for Monocular 3D Visual Grounding](https://arxiv.org/abs/2511.06908)
*Yuzhen Li,Min Liu,Zhaoyang Li,Yuan Bian,Xueping Wang,Erbo Zhai,Yaonan Wang*

Main category: cs.CV

TL;DR: Mono3DVG-EnSD是一个解决单目3D视觉定位任务的新框架，通过CLIP-LCA和D2M模块解决现有方法过度依赖高确定性关键词和跨维度干扰的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在两个关键局限：过度依赖显式识别目标对象的高确定性关键词而忽视空间描述；广义文本特征包含2D和3D信息导致跨维度干扰。

Method: 提出Mono3DVG-EnSD框架，包含CLIP引导的词法确定性适配器（CLIP-LCA）和维度解耦模块（D2M）。CLIP-LCA动态掩码高确定性关键词保留空间描述，D2M从广义文本特征中解耦维度特定特征以指导对应视觉特征。

Result: 在Mono3DRefer数据集上达到最先进性能，所有指标均优于现有方法，特别是具有挑战性的Far(Acc@0.5)场景提升了13.54%。

Conclusion: 该方法通过增强空间关系理解和减少跨维度干扰，有效提升了单目3D视觉定位的性能。

Abstract: Monocular 3D Visual Grounding (Mono3DVG) is an emerging task that locates 3D
objects in RGB images using text descriptions with geometric cues. However,
existing methods face two key limitations. Firstly, they often over-rely on
high-certainty keywords that explicitly identify the target object while
neglecting critical spatial descriptions. Secondly, generalized textual
features contain both 2D and 3D descriptive information, thereby capturing an
additional dimension of details compared to singular 2D or 3D visual features.
This characteristic leads to cross-dimensional interference when refining
visual features under text guidance. To overcome these challenges, we propose
Mono3DVG-EnSD, a novel framework that integrates two key components: the
CLIP-Guided Lexical Certainty Adapter (CLIP-LCA) and the Dimension-Decoupled
Module (D2M). The CLIP-LCA dynamically masks high-certainty keywords while
retaining low-certainty implicit spatial descriptions, thereby forcing the
model to develop a deeper understanding of spatial relationships in captions
for object localization. Meanwhile, the D2M decouples dimension-specific
(2D/3D) textual features from generalized textual features to guide
corresponding visual features at same dimension, which mitigates
cross-dimensional interference by ensuring dimensionally-consistent cross-modal
interactions. Through comprehensive comparisons and ablation studies on the
Mono3DRefer dataset, our method achieves state-of-the-art (SOTA) performance
across all metrics. Notably, it improves the challenging Far(Acc@0.5) scenario
by a significant +13.54%.

</details>


### [171] [DTTNet: Improving Video Shadow Detection via Dark-Aware Guidance and Tokenized Temporal Modeling](https://arxiv.org/abs/2511.06925)
*Zhicheng Li,Kunyang Sun,Rui Yao,Hancheng Zhu,Fuyuan Hu,Jiaqi Zhao,Zhiwen Shao,Yong Zhou*

Main category: cs.CV

TL;DR: 提出DTTNet方法解决视频阴影检测的两个核心挑战：阴影与复杂背景的区分，以及动态阴影形变的建模。通过视觉语言匹配模块和暗感知语义块解决阴影-背景模糊问题，通过令牌化时序块进行高效的时空建模。


<details>
  <summary>Details</summary>
Motivation: 视频阴影检测面临两个相互交织的困难：在复杂背景下区分阴影，以及在不同光照条件下建模动态阴影变形。现有方法在处理阴影-背景模糊和动态阴影形变方面存在不足。

Method: 1. 视觉语言匹配模块(VMM)和暗感知语义块(DSB)：利用语言先验提取文本引导特征，明确区分阴影和暗色物体；2. 自适应掩码重加权：在训练期间对半影区域进行降权；3. 令牌化时序块(TTB)：将跨帧阴影语义总结为可学习的时序令牌，实现高效的序列编码。

Result: 在多个基准数据集上的综合实验表明，该方法达到了最先进的准确性和实时推理效率。

Conclusion: 提出的DTTNet方法有效解决了视频阴影检测的关键挑战，在保持高精度的同时实现了实时性能，为视频阴影检测提供了新的解决方案。

Abstract: Video shadow detection confronts two entwined difficulties: distinguishing
shadows from complex backgrounds and modeling dynamic shadow deformations under
varying illumination. To address shadow-background ambiguity, we leverage
linguistic priors through the proposed Vision-language Match Module (VMM) and a
Dark-aware Semantic Block (DSB), extracting text-guided features to explicitly
differentiate shadows from dark objects. Furthermore, we introduce adaptive
mask reweighting to downweight penumbra regions during training and apply edge
masks at the final decoder stage for better supervision. For temporal modeling
of variable shadow shapes, we propose a Tokenized Temporal Block (TTB) that
decouples spatiotemporal learning. TTB summarizes cross-frame shadow semantics
into learnable temporal tokens, enabling efficient sequence encoding with
minimal computation overhead. Comprehensive Experiments on multiple benchmark
datasets demonstrate state-of-the-art accuracy and real-time inference
efficiency. Codes are available at https://github.com/city-cheng/DTTNet.

</details>


### [172] [PlantTraitNet: An Uncertainty-Aware Multimodal Framework for Global-Scale Plant Trait Inference from Citizen Science Data](https://arxiv.org/abs/2511.06943)
*Ayushi Sharma,Johanna Trost,Daniel Lusk,Johannes Dollinger,Julian Schrader,Christian Rossi,Javier Lopatin,Etienne Laliberté,Simon Haberstroh,Jana Eichel,Daniel Mederer,Jose Miguel Cerda-Paredes,Shyam S. Phartyal,Lisa-Maricia Schwarz,Anja Linstädter,Maria Conceição Caldeira,Teja Kattenborn*

Main category: cs.CV

TL;DR: PlantTraitNet利用公民科学照片通过多模态深度学习预测植物性状，生成全球性状分布图，在准确性上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有植物性状地图受限于野外测量成本高和地理覆盖稀疏，而全球5000万张地理标记植物照片提供了丰富的视觉信息资源。

Method: 提出PlantTraitNet框架，采用多模态、多任务不确定性感知深度学习，利用弱监督从公民科学照片预测四种关键植物性状（株高、叶面积、比叶面积和氮含量）。

Result: 与独立植被调查数据验证对比，PlantTraitNet在所有评估性状上均优于现有全球性状产品。

Conclusion: 公民科学图像与计算机视觉和地理空间AI结合，不仅可实现可扩展的全球性状制图，还能提供更准确的结果，为生态研究和地球系统建模开辟新途径。

Abstract: Global plant maps of plant traits, such as leaf nitrogen or plant height, are
essential for understanding ecosystem processes, including the carbon and
energy cycles of the Earth system. However, existing trait maps remain limited
by the high cost and sparse geographic coverage of field-based measurements.
Citizen science initiatives offer a largely untapped resource to overcome these
limitations, with over 50 million geotagged plant photographs worldwide
capturing valuable visual information on plant morphology and physiology. In
this study, we introduce PlantTraitNet, a multi-modal, multi-task
uncertainty-aware deep learning framework that predictsfour key plant traits
(plant height, leaf area, specific leaf area, and nitrogen content) from
citizen science photos using weak supervision. By aggregating individual trait
predictions across space, we generate global maps of trait distributions. We
validate these maps against independent vegetation survey data (sPlotOpen) and
benchmark them against leading global trait products. Our results show that
PlantTraitNet consistently outperforms existing trait maps across all evaluated
traits, demonstrating that citizen science imagery, when integrated with
computer vision and geospatial AI, enables not only scalable but also more
accurate global trait mapping. This approach offers a powerful new pathway for
ecological research and Earth system modeling.

</details>


### [173] [From Attribution to Action: Jointly ALIGNing Predictions and Explanations](https://arxiv.org/abs/2511.06944)
*Dongsheng Hong,Chao Chen,Yanhui Chen,Shanshan Lin,Zhihao Chen,Xiangwen Liao*

Main category: cs.CV

TL;DR: ALIGN框架通过联合训练分类器和掩码器，使用高质量掩码作为指导，在提高模型可解释性的同时增强了泛化能力，在多个领域泛化基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的解释引导学习方法依赖外部注释或启发式分割来监督模型解释，这些监督信号通常质量较低、不精确且难以扩展，可能反而降低模型性能。

Method: 提出ALIGN框架，通过迭代方式联合训练分类器和掩码器。掩码器学习生成任务相关的软掩码来突出信息区域，分类器同时优化预测准确性和其显著图与学习掩码之间的对齐。

Result: 在VLCS和Terra Incognita两个领域泛化基准测试中，ALIGN在分布内和分布外设置下均优于六个强基线方法，同时在充分性和全面性方面产生更高质量的解释。

Conclusion: ALIGN框架通过利用高质量掩码作为指导，有效提高了模型的可解释性和泛化能力，证明了在保持准确性的同时生产可解释模型的可行性。

Abstract: Explanation-guided learning (EGL) has shown promise in aligning model
predictions with interpretable reasoning, particularly in computer vision
tasks. However, most approaches rely on external annotations or heuristic-based
segmentation to supervise model explanations, which can be noisy, imprecise and
difficult to scale. In this work, we provide both empirical and theoretical
evidence that low-quality supervision signals can degrade model performance
rather than improve it. In response, we propose ALIGN, a novel framework that
jointly trains a classifier and a masker in an iterative manner. The masker
learns to produce soft, task-relevant masks that highlight informative regions,
while the classifier is optimized for both prediction accuracy and alignment
between its saliency maps and the learned masks. By leveraging high-quality
masks as guidance, ALIGN improves both interpretability and generalizability,
showing its superiority across various settings. Experiments on the two domain
generalization benchmarks, VLCS and Terra Incognita, show that ALIGN
consistently outperforms six strong baselines in both in-distribution and
out-of-distribution settings. Besides, ALIGN also yields superior explanation
quality concerning sufficiency and comprehensiveness, highlighting its
effectiveness in producing accurate and interpretable models.

</details>


### [174] [FoCLIP: A Feature-Space Misalignment Framework for CLIP-Based Image Manipulation and Detection](https://arxiv.org/abs/2511.06947)
*Yulin Chen,Zeyuan Wang,Tianyuan Yu,Yingmei Wei,Liang Bai*

Main category: cs.CV

TL;DR: FoCLIP是一个针对CLIP-based图像质量评估指标的对抗攻击框架，通过特征空间错位来欺骗CLIPscore评分，同时提出基于颜色通道敏感性的防御检测方法。


<details>
  <summary>Details</summary>
Motivation: CLIP-based模型虽然具有良好的多模态对齐特性，但其图像质量评估指标CLIPscore容易受到精心设计的对抗攻击。现有方法在欺骗CLIPscore时往往会导致图像质量下降，需要开发既能有效欺骗评分又保持视觉质量的攻击方法。

Method: 基于随机梯度下降技术，FoCLIP包含三个核心组件：特征对齐模块（减少图像-文本模态差异）、分数分布平衡模块和像素保护正则化，共同优化CLIPscore性能与图像质量之间的多模态输出平衡。

Result: 在十个艺术杰作提示和ImageNet子集上的实验表明，优化后的图像在CLIPscore上获得显著提升的同时保持高视觉保真度。此外发现灰度转换会导致欺骗图像特征退化，基于此提出的颜色通道敏感性检测机制在标准基准上达到91%的准确率。

Conclusion: 本研究为CLIP-based多模态系统建立了实用的特征错位攻击路径和相应的防御方法，揭示了多模态对齐系统的脆弱性并提供了有效的检测机制。

Abstract: The well-aligned attribute of CLIP-based models enables its effective
application like CLIPscore as a widely adopted image quality assessment metric.
However, such a CLIP-based metric is vulnerable for its delicate multimodal
alignment. In this work, we propose \textbf{FoCLIP}, a feature-space
misalignment framework for fooling CLIP-based image quality metric. Based on
the stochastic gradient descent technique, FoCLIP integrates three key
components to construct fooling examples: feature alignment as the core module
to reduce image-text modality gaps, the score distribution balance module and
pixel-guard regularization, which collectively optimize multimodal output
equilibrium between CLIPscore performance and image quality. Such a design can
be engineered to maximize the CLIPscore predictions across diverse input
prompts, despite exhibiting either visual unrecognizability or semantic
incongruence with the corresponding adversarial prompts from human perceptual
perspectives. Experiments on ten artistic masterpiece prompts and ImageNet
subsets demonstrate that optimized images can achieve significant improvement
in CLIPscore while preserving high visual fidelity. In addition, we found that
grayscale conversion induces significant feature degradation in fooling images,
exhibiting noticeable CLIPscore reduction while preserving statistical
consistency with original images. Inspired by this phenomenon, we propose a
color channel sensitivity-driven tampering detection mechanism that achieves
91% accuracy on standard benchmarks. In conclusion, this work establishes a
practical pathway for feature misalignment in CLIP-based multimodal systems and
the corresponding defense method.

</details>


### [175] [PADM: A Physics-aware Diffusion Model for Attenuation Correction](https://arxiv.org/abs/2511.06948)
*Trung Kien Pham,Hoang Minh Vu,Anh Duc Chu,Dac Thai Nguyen,Trung Thanh Nguyen,Thao Nguyen Truong,Mai Hong Son,Thanh Trung Nguyen,Phi Le Nguyen*

Main category: cs.CV

TL;DR: 提出了PADM模型，一种基于扩散的生成方法，用于心脏SPECT成像中的无CT衰减校正，通过物理先验知识改进图像质量。


<details>
  <summary>Details</summary>
Motivation: 传统SPECT/CT系统成本高、可及性有限且辐射剂量大，限制了临床广泛应用。现有方法在衰减伪影校正方面存在不足。

Method: 引入物理感知衰减校正扩散模型（PADM），采用师生蒸馏机制融入物理先验，仅需非衰减校正输入即可进行衰减伪影校正。

Result: PADM在定量指标和视觉评估上均优于现有最先进生成模型，提供更优的重建保真度。

Conclusion: PADM为心脏SPECT成像提供了一种有效的无CT衰减校正解决方案，具有临床推广潜力。

Abstract: Attenuation artifacts remain a significant challenge in cardiac Myocardial
Perfusion Imaging (MPI) using Single-Photon Emission Computed Tomography
(SPECT), often compromising diagnostic accuracy and reducing clinical
interpretability. While hybrid SPECT/CT systems mitigate these artifacts
through CT-derived attenuation maps, their high cost, limited accessibility,
and added radiation exposure hinder widespread clinical adoption. In this
study, we propose a novel CT-free solution to attenuation correction in cardiac
SPECT. Specifically, we introduce Physics-aware Attenuation Correction
Diffusion Model (PADM), a diffusion-based generative method that incorporates
explicit physics priors via a teacher--student distillation mechanism. This
approach enables attenuation artifact correction using only
Non-Attenuation-Corrected (NAC) input, while still benefiting from
physics-informed supervision during training. To support this work, we also
introduce CardiAC, a comprehensive dataset comprising 424 patient studies with
paired NAC and Attenuation-Corrected (AC) reconstructions, alongside
high-resolution CT-based attenuation maps. Extensive experiments demonstrate
that PADM outperforms state-of-the-art generative models, delivering superior
reconstruction fidelity across both quantitative metrics and visual assessment.

</details>


### [176] [GFix: Perceptually Enhanced Gaussian Splatting Video Compression](https://arxiv.org/abs/2511.06953)
*Siyue Teng,Ge Gao,Duolikun Danier,Yuxuan Jiang,Fan Zhang,Thomas Davis,Zoe Liu,David Bull*

Main category: cs.CV

TL;DR: GFix是一个基于3D高斯泼溅的视频压缩感知增强框架，通过单步扩散模型和调制LoRA方案，显著提升压缩效率和视觉质量。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS视频编解码器存在明显视觉伪影和低压缩比问题，作者假设3DGS渲染和量化的伪影类似于扩散训练中的噪声潜变量，因此利用扩散模型进行感知增强。

Method: 提出内容自适应框架GFix：1）使用简化的单步扩散模型作为即插即用的神经增强器；2）提出调制LoRA方案，冻结低秩分解并调制中间隐藏状态，实现高效适应和高度可压缩的更新。

Result: 实验结果显示GFix在感知质量增强方面表现优异，相比GSVC在LPIPS指标上节省72.1%的BD-rate，在FID指标上节省21.4%。

Conclusion: GFix框架成功解决了3DGS视频压缩中的视觉伪影问题，通过扩散模型和调制LoRA技术实现了高效的感知质量增强和压缩效率提升。

Abstract: 3D Gaussian Splatting (3DGS) enhances 3D scene reconstruction through
explicit representation and fast rendering, demonstrating potential benefits
for various low-level vision tasks, including video compression. However,
existing 3DGS-based video codecs generally exhibit more noticeable visual
artifacts and relatively low compression ratios. In this paper, we specifically
target the perceptual enhancement of 3DGS-based video compression, based on the
assumption that artifacts from 3DGS rendering and quantization resemble noisy
latents sampled during diffusion training. Building on this premise, we propose
a content-adaptive framework, GFix, comprising a streamlined, single-step
diffusion model that serves as an off-the-shelf neural enhancer. Moreover, to
increase compression efficiency, We propose a modulated LoRA scheme that
freezes the low-rank decompositions and modulates the intermediate hidden
states, thereby achieving efficient adaptation of the diffusion backbone with
highly compressible updates. Experimental results show that GFix delivers
strong perceptual quality enhancement, outperforming GSVC with up to 72.1%
BD-rate savings in LPIPS and 21.4% in FID.

</details>


### [177] [Learning from the Right Patches: A Two-Stage Wavelet-Driven Masked Autoencoder for Histopathology Representation Learning](https://arxiv.org/abs/2511.06958)
*Raneen Younis,Louay Hamdi,Lukas Chavez,Zahra Ahmadi*

Main category: cs.CV

TL;DR: WISE-MAE提出了一种基于小波变换的patch选择策略，通过粗到细的两步过程筛选结构丰富的组织区域，提升MAE在数字病理学中的表示学习效果。


<details>
  <summary>Details</summary>
Motivation: 传统MAE预训练中的随机patch采样常包含无关或噪声区域，限制了模型捕捉有意义的组织模式的能力。数字病理学中全切片图像尺寸极大且标注稀缺，需要更有效的自监督学习方法。

Method: 采用小波信息指导的patch选择策略：1）在低倍镜下基于小波变换筛选结构丰富区域；2）在高分辨率下提取细节进行建模。这种方法模拟病理学家的诊断流程。

Result: 在肺、肾和结直肠等多个癌症数据集上的评估表明，WISE-MAE在弱监督下保持效率的同时，实现了有竞争力的表示质量和下游分类性能。

Conclusion: WISE-MAE通过引入结构化和生物学相关性的patch选择机制，有效提升了MAE在数字病理学中的表示学习能力，为大规模病理图像分析提供了更高效的解决方案。

Abstract: Whole-slide images are central to digital pathology, yet their extreme size
and scarce annotations make self-supervised learning essential. Masked
Autoencoders (MAEs) with Vision Transformer backbones have recently shown
strong potential for histopathology representation learning. However,
conventional random patch sampling during MAE pretraining often includes
irrelevant or noisy regions, limiting the model's ability to capture meaningful
tissue patterns. In this paper, we present a lightweight and domain-adapted
framework that brings structure and biological relevance into MAE-based
learning through a wavelet-informed patch selection strategy. WISE-MAE applies
a two-step coarse-to-fine process: wavelet-based screening at low magnification
to locate structurally rich regions, followed by high-resolution extraction for
detailed modeling. This approach mirrors the diagnostic workflow of
pathologists and improves the quality of learned representations. Evaluations
across multiple cancer datasets, including lung, renal, and colorectal tissues,
show that WISE-MAE achieves competitive representation quality and downstream
classification performance while maintaining efficiency under weak supervision.

</details>


### [178] [Exploring the "Great Unseen" in Medieval Manuscripts: Instance-Level Labeling of Legacy Image Collections with Zero-Shot Models](https://arxiv.org/abs/2511.07004)
*Christofer Meinecke,Estelle Guéville,David Joseph Wrisley*

Main category: cs.CV

TL;DR: 使用先进技术对中世纪手稿页面进行全面分割和描述，为计算机视觉技术创建更丰富的训练数据


<details>
  <summary>Details</summary>
Motivation: 更全面地理论化中世纪手稿页面及其内容，为计算机视觉技术提供更好的训练数据

Method: 使用最先进的技术对中世纪手稿的整个页面进行分割和描述

Result: 创建了用于实例分割和多模态模型的中世纪视觉内容训练数据

Conclusion: 该方法有助于提升计算机视觉技术在中世纪手稿研究中的应用效果

Abstract: We aim to theorize the medieval manuscript page and its contents more
holistically, using state-of-the-art techniques to segment and describe the
entire manuscript folio, for the purpose of creating richer training data for
computer vision techniques, namely instance segmentation, and multimodal models
for medieval-specific visual content.

</details>


### [179] [TrueCity: Real and Simulated Urban Data for Cross-Domain 3D Scene Understanding](https://arxiv.org/abs/2511.07007)
*Duc Nguyen,Yan-Ling Lai,Qilin Zhang,Prabin Gyawali,Benedikt Schwab,Olaf Wysocki,Thomas H. Kolbe*

Main category: cs.CV

TL;DR: TrueCity是首个城市语义分割基准数据集，提供厘米级精度的真实世界点云、语义3D城市模型和标注的模拟点云，用于量化合成到真实领域的差距。


<details>
  <summary>Details</summary>
Motivation: 解决3D语义场景理解中真实标注数据有限的问题，以及现有方法因合成数据与真实世界复杂性不匹配导致的领域差距。

Method: 创建TrueCity基准数据集，包含同步的真实和模拟点云数据，采用与国际3D城市建模标准一致的语义分割类别。

Result: 通过广泛实验量化了领域偏移，并提出了利用合成数据增强真实世界3D场景理解的策略。

Conclusion: TrueCity数据集将促进合成到真实领域差距的量化研究，并支持开发通用数据驱动模型。

Abstract: 3D semantic scene understanding remains a long-standing challenge in the 3D
computer vision community. One of the key issues pertains to limited real-world
annotated data to facilitate generalizable models. The common practice to
tackle this issue is to simulate new data. Although synthetic datasets offer
scalability and perfect labels, their designer-crafted scenes fail to capture
real-world complexity and sensor noise, resulting in a synthetic-to-real domain
gap. Moreover, no benchmark provides synchronized real and simulated point
clouds for segmentation-oriented domain shift analysis. We introduce TrueCity,
the first urban semantic segmentation benchmark with cm-accurate annotated
real-world point clouds, semantic 3D city models, and annotated simulated point
clouds representing the same city. TrueCity proposes segmentation classes
aligned with international 3D city modeling standards, enabling consistent
evaluation of synthetic-to-real gap. Our extensive experiments on common
baselines quantify domain shift and highlight strategies for exploiting
synthetic data to enhance real-world 3D scene understanding. We are convinced
that the TrueCity dataset will foster further development of sim-to-real gap
quantification and enable generalizable data-driven models. The data, code, and
3D models are available online: https://tum-gis.github.io/TrueCity/

</details>


### [180] [Performance Decay in Deepfake Detection: The Limitations of Training on Outdated Data](https://arxiv.org/abs/2511.07009)
*Jack Richings,Margaux Leblanc,Ian Groves,Victoria Nockles*

Main category: cs.CV

TL;DR: 本文提出了一种简单有效的两阶段深度伪造检测方法，在当代深度伪造上达到99.8%的AUROC，但性能会随时间快速衰减，六个月后召回率下降超过30%。


<details>
  <summary>Details</summary>
Motivation: 深度伪造技术的不断进步加剧了虚假信息、欺诈和骚扰的威胁，恶意生成的合成内容越来越难以与现实区分。

Method: 采用简单但有效的两阶段检测方法，通过分析发现预测能力主要来自静态的帧级伪影而非时间不一致性。

Result: 检测方法在当代深度伪造上表现优异（AUROC > 99.8%），但面对六个月后的新生成技术时，召回率下降超过30%，显示出显著的性能衰减。

Conclusion: 稳健的深度伪造检测需要持续收集大型多样化数据集，并开发先进的帧级特征检测器，未来有效检测取决于快速数据收集和帧级检测技术的发展。

Abstract: The continually advancing quality of deepfake technology exacerbates the
threats of disinformation, fraud, and harassment by making
maliciously-generated synthetic content increasingly difficult to distinguish
from reality. We introduce a simple yet effective two-stage detection method
that achieves an AUROC of over 99.8% on contemporary deepfakes. However, this
high performance is short-lived. We show that models trained on this data
suffer a recall drop of over 30% when evaluated on deepfakes created with
generation techniques from just six months later, demonstrating significant
decay as threats evolve. Our analysis reveals two key insights for robust
detection. Firstly, continued performance requires the ongoing curation of
large, diverse datasets. Second, predictive power comes primarily from static,
frame-level artifacts, not temporal inconsistencies. The future of effective
deepfake detection therefore depends on rapid data collection and the
development of advanced frame-level feature detectors.

</details>


### [181] [Certified L2-Norm Robustness of 3D Point Cloud Recognition in the Frequency Domain](https://arxiv.org/abs/2511.07029)
*Liang Zhou,Qiming Wang,Tianze Chen*

Main category: cs.CV

TL;DR: FreqCert是一个针对3D点云分类的认证防御框架，通过在频域分析鲁棒性来对抗结构化对抗扰动和几何失真，相比传统空间域方法提供更好的认证准确性。


<details>
  <summary>Details</summary>
Motivation: 现有认证防御方法主要限制点级扰动，但忽略了保持单个点不变却改变整体结构的几何失真，这在安全关键应用中存在风险。

Method: 通过图傅里叶变换将点云转换到频域，基于频谱相似性进行结构化频率感知子采样生成多个子点云，使用标准模型独立分类并通过多数投票获得最终预测。

Result: 在ModelNet40和ScanObjectNN数据集上的实验表明，FreqCert在强扰动下实现了更高的认证准确性和经验准确性。

Conclusion: 频谱表示为3D点云识别中的可认证鲁棒性提供了有效途径，频域分析能够更好地处理结构化扰动。

Abstract: 3D point cloud classification is a fundamental task in safety-critical
applications such as autonomous driving, robotics, and augmented reality.
However, recent studies reveal that point cloud classifiers are vulnerable to
structured adversarial perturbations and geometric corruptions, posing risks to
their deployment in safety-critical scenarios. Existing certified defenses
limit point-wise perturbations but overlook subtle geometric distortions that
preserve individual points yet alter the overall structure, potentially leading
to misclassification. In this work, we propose FreqCert, a novel certification
framework that departs from conventional spatial domain defenses by shifting
robustness analysis to the frequency domain, enabling structured certification
against global L2-bounded perturbations. FreqCert first transforms the input
point cloud via the graph Fourier transform (GFT), then applies structured
frequency-aware subsampling to generate multiple sub-point clouds. Each
sub-cloud is independently classified by a standard model, and the final
prediction is obtained through majority voting, where sub-clouds are
constructed based on spectral similarity rather than spatial proximity, making
the partitioning more stable under L2 perturbations and better aligned with the
object's intrinsic structure. We derive a closed-form lower bound on the
certified L2 robustness radius and prove its tightness under minimal and
interpretable assumptions, establishing a theoretical foundation for frequency
domain certification. Extensive experiments on the ModelNet40 and ScanObjectNN
datasets demonstrate that FreqCert consistently achieves higher certified
accuracy and empirical accuracy under strong perturbations. Our results suggest
that spectral representations provide an effective pathway toward certifiable
robustness in 3D point cloud recognition.

</details>


### [182] [3D-ANC: Adaptive Neural Collapse for Robust 3D Point Cloud Recognition](https://arxiv.org/abs/2511.07040)
*Yuanmin Huang,Wenxuan Li,Mi Zhang,Xiaohan Zhang,Xiaoyu You,Min Yang*

Main category: cs.CV

TL;DR: 3D-ANC是一种利用神经崩溃机制的新型防御方法，通过解耦特征空间来显著提高3D点云识别模型对抗对抗性攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有3D点云识别防御机制在处理多变的攻击模式时表现不佳，主要原因是特征空间纠缠，使得对抗性攻击容易实施。

Method: 结合ETF对齐分类模块和自适应训练框架（包括表示平衡学习和动态特征方向损失），利用神经崩溃机制构建最大可分离的类原型。

Result: 在ModelNet40数据集上，DGCNN的分类准确率从27.2%提升到80.9%，绝对增益53.7%，超越领先基线34.0%。

Conclusion: 3D-ANC能有效解决3D点云识别中的对抗性攻击问题，为实际部署提供可靠的防御方案。

Abstract: Deep neural networks have recently achieved notable progress in 3D point
cloud recognition, yet their vulnerability to adversarial perturbations poses
critical security challenges in practical deployments. Conventional defense
mechanisms struggle to address the evolving landscape of multifaceted attack
patterns. Through systematic analysis of existing defenses, we identify that
their unsatisfactory performance primarily originates from an entangled feature
space, where adversarial attacks can be performed easily. To this end, we
present 3D-ANC, a novel approach that capitalizes on the Neural Collapse (NC)
mechanism to orchestrate discriminative feature learning. In particular, NC
depicts where last-layer features and classifier weights jointly evolve into a
simplex equiangular tight frame (ETF) arrangement, establishing maximally
separable class prototypes. However, leveraging this advantage in 3D
recognition confronts two substantial challenges: (1) prevalent class imbalance
in point cloud datasets, and (2) complex geometric similarities between object
categories. To tackle these obstacles, our solution combines an ETF-aligned
classification module with an adaptive training framework consisting of
representation-balanced learning (RBL) and dynamic feature direction loss
(FDL). 3D-ANC seamlessly empowers existing models to develop disentangled
feature spaces despite the complexity in 3D data distribution. Comprehensive
evaluations state that 3D-ANC significantly improves the robustness of models
with various structures on two datasets. For instance, DGCNN's classification
accuracy is elevated from 27.2% to 80.9% on ModelNet40 -- a 53.7% absolute gain
that surpasses leading baselines by 34.0%.

</details>


### [183] [From Pretrain to Pain: Adversarial Vulnerability of Video Foundation Models Without Task Knowledge](https://arxiv.org/abs/2511.07049)
*Hui Lu,Yi Yu,Song Xia,Yiming Yang,Deepu Rajan,Boon Poh Ng,Alex Kot,Xudong Jiang*

Main category: cs.CV

TL;DR: 本文提出了一种针对视频基础模型的新型对抗攻击方法TVA，能够在无需访问受害者任务、训练数据、模型查询和架构的情况下，攻击基于开源VFMs微调的下游模型或MLLMs。


<details>
  <summary>Details</summary>
Motivation: 随着大规模视频基础模型的开放可访问性增强，其安全风险日益突出。攻击者可以利用VFMs的完整知识发起有效攻击，但目前缺乏针对下游微调模型的实用攻击方法。

Method: 提出了TVA（可迁移视频攻击）方法，这是一种时间感知的对抗攻击技术。它利用VFMs的时间表示动态来生成有效扰动，结合双向对比学习机制最大化干净特征和对抗特征之间的差异，并引入时间一致性损失来利用运动线索增强扰动的序列影响。

Result: 在24个视频相关任务上的广泛实验表明，TVA能够有效攻击下游模型和MLLMs，揭示了视频模型部署中一个先前未被充分探索的安全漏洞。

Conclusion: TVA提供了一种更实用和高效的攻击策略，无需训练昂贵的代理模型或访问领域特定数据，为视频基础模型的安全性研究提供了重要启示。

Abstract: Large-scale Video Foundation Models (VFMs) has significantly advanced various
video-related tasks, either through task-specific models or Multi-modal Large
Language Models (MLLMs). However, the open accessibility of VFMs also
introduces critical security risks, as adversaries can exploit full knowledge
of the VFMs to launch potent attacks. This paper investigates a novel and
practical adversarial threat scenario: attacking downstream models or MLLMs
fine-tuned from open-source VFMs, without requiring access to the victim task,
training data, model query, and architecture. In contrast to conventional
transfer-based attacks that rely on task-aligned surrogate models, we
demonstrate that adversarial vulnerabilities can be exploited directly from the
VFMs. To this end, we propose the Transferable Video Attack (TVA), a
temporal-aware adversarial attack method that leverages the temporal
representation dynamics of VFMs to craft effective perturbations. TVA
integrates a bidirectional contrastive learning mechanism to maximize the
discrepancy between the clean and adversarial features, and introduces a
temporal consistency loss that exploits motion cues to enhance the sequential
impact of perturbations. TVA avoids the need to train expensive surrogate
models or access to domain-specific data, thereby offering a more practical and
efficient attack strategy. Extensive experiments across 24 video-related tasks
demonstrate the efficacy of TVA against downstream models and MLLMs, revealing
a previously underexplored security vulnerability in the deployment of video
models.

</details>


### [184] [Improving Deepfake Detection with Reinforcement Learning-Based Adaptive Data Augmentation](https://arxiv.org/abs/2511.07051)
*Yuxuan Zhou,Tao Yu,Wen Huang,Yuheng Zhang,Tao Dai,Shu-Tao Xia*

Main category: cs.CV

TL;DR: CRDA是一个基于强化学习和因果推理的动态数据增强框架，通过从简单到复杂的渐进式学习策略提升深度伪造检测器的泛化能力，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的深度伪造检测器数据增强方法采用固定策略，无法充分模拟现实世界中不断演变的复杂伪造特征（如面部扭曲、表情操纵等），导致泛化能力不足。

Method: 提出CRDA框架，包含：1）可配置的伪造操作池生成增强样本；2）基于强化学习的智能体动态选择增强策略；3）结合因果推理抑制虚假相关性，聚焦因果不变特征；4）渐进式学习从简单到复杂的多域伪造特征。

Result: 在多个跨域数据集上的大量实验表明，该方法显著提升了检测器的泛化性能，全面超越了现有最先进方法。

Conclusion: 动态、渐进式的数据增强策略结合强化学习和因果推理，能够有效解决深度伪造检测中的泛化挑战，为实际应用提供了更可靠的解决方案。

Abstract: The generalization capability of deepfake detectors is critical for
real-world use. Data augmentation via synthetic fake face generation
effectively enhances generalization, yet current SoTA methods rely on fixed
strategies-raising a key question: Is a single static augmentation sufficient,
or does the diversity of forgery features demand dynamic approaches? We argue
existing methods overlook the evolving complexity of real-world forgeries
(e.g., facial warping, expression manipulation), which fixed policies cannot
fully simulate. To address this, we propose CRDA (Curriculum
Reinforcement-Learning Data Augmentation), a novel framework guiding detectors
to progressively master multi-domain forgery features from simple to complex.
CRDA synthesizes augmented samples via a configurable pool of forgery
operations and dynamically generates adversarial samples tailored to the
detector's current learning state. Central to our approach is integrating
reinforcement learning (RL) and causal inference. An RL agent dynamically
selects augmentation actions based on detector performance to efficiently
explore the vast augmentation space, adapting to increasingly challenging
forgeries. Simultaneously, the agent introduces action space variations to
generate heterogeneous forgery patterns, guided by causal inference to mitigate
spurious correlations-suppressing task-irrelevant biases and focusing on
causally invariant features. This integration ensures robust generalization by
decoupling synthetic augmentation patterns from the model's learned
representations. Extensive experiments show our method significantly improves
detector generalizability, outperforming SOTA methods across multiple
cross-domain datasets.

</details>


### [185] [RaLD: Generating High-Resolution 3D Radar Point Clouds with Latent Diffusion](https://arxiv.org/abs/2511.07067)
*Ruijie Zhang,Bixin Zeng,Shengpeng Wang,Fuhui Zhou,Wei Wang*

Main category: cs.CV

TL;DR: RaLD是一个基于潜在扩散模型的框架，用于从稀疏的毫米波雷达点云生成密集准确的3D点云，解决了雷达感知中分辨率和密度不足的问题。


<details>
  <summary>Details</summary>
Motivation: 毫米波雷达在恶劣条件下具有鲁棒性和低成本优势，但其点云稀疏且分辨率低，限制了在需要密集3D感知任务中的应用。现有生成方法依赖低效的体素表示且难以保持结构细节。

Method: 通过场景级视锥体LiDAR自编码、顺序不变潜在表示和直接雷达频谱条件化，将潜在扩散模型应用于雷达3D生成，实现更紧凑和表达性更强的生成过程。

Result: 实验表明RaLD能够从原始雷达频谱生成密集准确的3D点云，为恶劣环境下的鲁棒感知提供了有前景的解决方案。

Conclusion: RaLD框架成功地将潜在扩散模型应用于雷达3D生成，填补了该领域的技术空白，为自动驾驶系统在挑战性环境中的感知能力提供了有效提升。

Abstract: Millimeter-wave radar offers a promising sensing modality for autonomous
systems thanks to its robustness in adverse conditions and low cost. However,
its utility is significantly limited by the sparsity and low resolution of
radar point clouds, which poses challenges for tasks requiring dense and
accurate 3D perception. Despite that recent efforts have shown great potential
by exploring generative approaches to address this issue, they often rely on
dense voxel representations that are inefficient and struggle to preserve
structural detail. To fill this gap, we make the key observation that latent
diffusion models (LDMs), though successful in other modalities, have not been
effectively leveraged for radar-based 3D generation due to a lack of compatible
representations and conditioning strategies. We introduce RaLD, a framework
that bridges this gap by integrating scene-level frustum-based LiDAR
autoencoding, order-invariant latent representations, and direct radar spectrum
conditioning. These insights lead to a more compact and expressive generation
process. Experiments show that RaLD produces dense and accurate 3D point clouds
from raw radar spectrums, offering a promising solution for robust perception
in challenging environments.

</details>


### [186] [ClusterMine: Robust Label-Free Visual Out-Of-Distribution Detection via Concept Mining from Text Corpora](https://arxiv.org/abs/2511.07068)
*Nikolas Adaloglou,Diana Petrusheva,Mohamed Asker,Felix Michels,Markus Kollmann*

Main category: cs.CV

TL;DR: ClusterMine是一种无需预定义正样本标签的无监督OOD检测方法，通过从文本语料库中挖掘正概念，结合视觉样本聚类和零样本图像-文本一致性，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 当前大规模视觉OOD检测方法依赖于预定义的正样本标签名称，但这些标签在实际应用中可能不可用、不可靠或因分布偏移而失效，需要真正的无监督方法。

Method: 提出ClusterMine方法，利用广泛可用的文本语料库进行正标签挖掘，结合视觉样本聚类和零样本图像-文本一致性来提取正概念，无需正样本标签。

Result: ClusterMine在多种CLIP模型上具有可扩展性，对协变量分布偏移具有最先进的鲁棒性，是首个无需正标签就能达到最先进OOD检测性能的方法。

Conclusion: 该研究证明了从文本语料库中挖掘正概念的有效性，为真正的无监督OOD检测提供了可行方案，具有实际应用价值。

Abstract: Large-scale visual out-of-distribution (OOD) detection has witnessed
remarkable progress by leveraging vision-language models such as CLIP. However,
a significant limitation of current methods is their reliance on a pre-defined
set of in-distribution (ID) ground-truth label names (positives). These fixed
label names can be unavailable, unreliable at scale, or become less relevant
due to in-distribution shifts after deployment. Towards truly unsupervised OOD
detection, we utilize widely available text corpora for positive label mining,
bypassing the need for positives. In this paper, we utilize widely available
text corpora for positive label mining under a general concept mining paradigm.
Within this framework, we propose ClusterMine, a novel positive label mining
method. ClusterMine is the first method to achieve state-of-the-art OOD
detection performance without access to positive labels. It extracts positive
concepts from a large text corpus by combining visual-only sample consistency
(via clustering) and zero-shot image-text consistency. Our experimental study
reveals that ClusterMine is scalable across a plethora of CLIP models and
achieves state-of-the-art robustness to covariate in-distribution shifts. The
code is available at https://github.com/HHU-MMBS/clustermine_wacv_official.

</details>


### [187] [LeCoT: revisiting network architecture for two-view correspondence pruning](https://arxiv.org/abs/2511.07078)
*Luanyuan Dai,Xiaoyu Du,Jinhui Tang*

Main category: cs.CV

TL;DR: LeCoT是一种新颖的双视角对应点剪枝网络，通过Spatial-Channel Fusion Transformer块和渐进式预测块，无需额外模块即可有效利用全局上下文信息，在多个计算机视觉任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前方法主要使用MLP作为主干网络，需要额外模块来增强上下文信息处理能力，但MLP在处理上下文信息方面存在固有局限性。

Method: 设计了LeCoT网络，核心是Spatial-Channel Fusion Transformer块，能够同时利用稀疏对应点的空间和通道全局上下文信息。还集成了渐进式预测块，利用中间阶段特征生成概率集作为后续学习指导。

Result: 大量实验证明LeCoT在对应点剪枝、相对位姿估计、单应性估计、视觉定位和3D重建任务中优于最先进方法。

Conclusion: LeCoT提供了一种无需额外模块即可有效捕获对应点上下文信息的新视角，通过渐进式预测机制缓解了传统方法的信息丢失问题。

Abstract: Two-view correspondence pruning aims to accurately remove incorrect
correspondences (outliers) from initial ones and is widely applied to various
computer vision tasks. Current popular strategies adopt multilayer perceptron
(MLP) as the backbone, supplemented by additional modules to enhance the
network ability to handle context information, which is a known limitation of
MLPs. In contrast, we introduce a novel perspective for capturing
correspondence context information without extra design modules. To this end,
we design a two-view correspondence pruning network called LeCoT, which can
naturally leverage global context information at different stages.
Specifically, the core design of LeCoT is the Spatial-Channel Fusion
Transformer block, a newly proposed component that efficiently utilizes both
spatial and channel global context information among sparse correspondences. In
addition, we integrate the proposed prediction block that utilizes
correspondence features from intermediate stages to generate a probability set,
which acts as guiding information for subsequent learning phases, allowing the
network to more effectively capture robust global context information. Notably,
this prediction block progressively refines the probability set, thereby
mitigating the issue of information loss that is common in the traditional one.
Extensive experiments prove that the proposed LeCoT outperforms
state-of-the-art methods in correspondence pruning, relative pose estimation,
homography estimation, visual localization, and $3$D~reconstruction tasks. The
code is provided in
https://github.com/Dailuanyuan2024/LeCoT-Revisiting-Network-Architecture-for-Two-View-Correspondence-Pruning.

</details>


### [188] [Pandar128 dataset for lane line detection](https://arxiv.org/abs/2511.07084)
*Filip Beránek,Václav Diviš,Ivan Gruber*

Main category: cs.CV

TL;DR: Pandar128是最大的128线激光雷达车道线检测公开数据集，包含52,000+相机帧和34,000+激光雷达扫描，并提出了轻量级基准方法SimpleLidarLane和新的评估指标IAM-F1。


<details>
  <summary>Details</summary>
Motivation: 解决激光雷达车道线检测领域缺乏大规模公开数据集和标准化评估方法的问题，促进该领域的研究发展。

Method: 1) 构建Pandar128数据集，包含多传感器数据和完整标定；2) 提出SimpleLidarLane方法，结合BEV分割、聚类和折线拟合；3) 设计IAM-F1评估指标，采用插值感知的横向匹配。

Result: 数据集在德国各种真实场景下采集，方法在挑战性条件下表现良好，证明了模块化管道与高质量数据结合的有效性。

Conclusion: 该工作为激光雷达车道线检测提供了重要的数据集、基准方法和评估标准，所有数据和代码均已公开以支持可复现性研究。

Abstract: We present Pandar128, the largest public dataset for lane line detection
using a 128-beam LiDAR. It contains over 52,000 camera frames and 34,000 LiDAR
scans, captured in diverse real-world conditions in Germany. The dataset
includes full sensor calibration (intrinsics, extrinsics) and synchronized
odometry, supporting tasks such as projection, fusion, and temporal modeling.
  To complement the dataset, we also introduce SimpleLidarLane, a light-weight
baseline method for lane line reconstruction that combines BEV segmentation,
clustering, and polyline fitting. Despite its simplicity, our method achieves
strong performance under challenging various conditions (e.g., rain, sparse
returns), showing that modular pipelines paired with high-quality data and
principled evaluation can compete with more complex approaches.
  Furthermore, to address the lack of standardized evaluation, we propose a
novel polyline-based metric - Interpolation-Aware Matching F1 (IAM-F1) - that
employs interpolation-aware lateral matching in BEV space.
  All data and code are publicly released to support reproducibility in
LiDAR-based lane detection.

</details>


### [189] [How Bias Binds: Measuring Hidden Associations for Bias Control in Text-to-Image Compositions](https://arxiv.org/abs/2511.07091)
*Jeng-Lin Li,Ming-Ching Chang,Wei-Chao Chen*

Main category: cs.CV

TL;DR: 本文研究了文本到图像生成模型中语义绑定（对象-属性关联）对偏见的影响，提出了偏见依从性评分和训练无关的上下文偏见控制框架，在组合生成任务中实现了超过10%的去偏见改进。


<details>
  <summary>Details</summary>
Motivation: 当前去偏见方法主要关注单对象提示，忽视了现实场景中多个对象和属性之间的语义绑定关系会共同影响偏见表现，导致现有方法在复杂语义绑定情境下失效。

Method: 提出了偏见依从性评分来量化对象-属性绑定激活偏见的程度，并开发了训练无关的上下文偏见控制框架，通过令牌解耦来实现语义绑定的去偏见。

Result: 该框架在组合生成任务中实现了超过10%的去偏见改进，分析显示不同属性-对象绑定的偏见评分存在显著差异，令牌去相关能有效降低偏见。

Conclusion: 当前去偏见方法在处理语义绑定情境时存在根本性挑战，需要在降低偏见的同时保持必要的语义关系，这要求重新评估主流的偏见缓解策略。

Abstract: Text-to-image generative models often exhibit bias related to sensitive
attributes. However, current research tends to focus narrowly on single-object
prompts with limited contextual diversity. In reality, each object or attribute
within a prompt can contribute to bias. For example, the prompt "an assistant
wearing a pink hat" may reflect female-inclined biases associated with a pink
hat. The neglected joint effects of the semantic binding in the prompts cause
significant failures in current debiasing approaches. This work initiates a
preliminary investigation on how bias manifests under semantic binding, where
contextual associations between objects and attributes influence generative
outcomes. We demonstrate that the underlying bias distribution can be amplified
based on these associations. Therefore, we introduce a bias adherence score
that quantifies how specific object-attribute bindings activate bias. To delve
deeper, we develop a training-free context-bias control framework to explore
how token decoupling can facilitate the debiasing of semantic bindings. This
framework achieves over 10% debiasing improvement in compositional generation
tasks. Our analysis of bias scores across various attribute-object bindings and
token decorrelation highlights a fundamental challenge: reducing bias without
disrupting essential semantic relationships. These findings expose critical
limitations in current debiasing approaches when applied to semantically bound
contexts, underscoring the need to reassess prevailing bias mitigation
strategies.

</details>


### [190] [GEWDiff: Geometric Enhanced Wavelet-based Diffusion Model for Hyperspectral Image Super-resolution](https://arxiv.org/abs/2511.07103)
*Sirui Wang,Jiang He,Natàlia Blasco Andreo,Xiao Xiang Zhu*

Main category: cs.CV

TL;DR: 提出GEWDiff框架，通过小波编码器和几何增强扩散过程实现高光谱图像4倍超分辨率重建，解决了传统扩散模型内存消耗大、几何结构理解不足和收敛不稳定的问题。


<details>
  <summary>Details</summary>
Motivation: 高光谱图像超分辨率面临三大挑战：高光谱维度导致内存消耗大、传统生成模型缺乏对遥感图像几何结构的理解、扩散模型在噪声级别优化导致收敛行为不直观和生成质量欠佳。

Method: 1. 小波编码器-解码器压缩高光谱图像到潜在空间；2. 几何增强扩散过程保持几何特征；3. 多级损失函数指导扩散过程，促进稳定收敛。

Result: 在保真度、光谱精度、视觉真实性和清晰度等多个维度上达到最先进水平。

Conclusion: GEWDiff框架有效解决了高光谱图像生成中的内存、几何结构和收敛稳定性问题，实现了高质量的超分辨率重建。

Abstract: Improving the quality of hyperspectral images (HSIs), such as through
super-resolution, is a crucial research area. However, generative modeling for
HSIs presents several challenges. Due to their high spectral dimensionality,
HSIs are too memory-intensive for direct input into conventional diffusion
models. Furthermore, general generative models lack an understanding of the
topological and geometric structures of ground objects in remote sensing
imagery. In addition, most diffusion models optimize loss functions at the
noise level, leading to a non-intuitive convergence behavior and suboptimal
generation quality for complex data. To address these challenges, we propose a
Geometric Enhanced Wavelet-based Diffusion Model (GEWDiff), a novel framework
for reconstructing hyperspectral images at 4-times super-resolution. A
wavelet-based encoder-decoder is introduced that efficiently compresses HSIs
into a latent space while preserving spectral-spatial information. To avoid
distortion during generation, we incorporate a geometry-enhanced diffusion
process that preserves the geometric features. Furthermore, a multi-level loss
function was designed to guide the diffusion process, promoting stable
convergence and improved reconstruction fidelity. Our model demonstrated
state-of-the-art results across multiple dimensions, including fidelity,
spectral accuracy, visual realism, and clarity.

</details>


### [191] [HENet++: Hybrid Encoding and Multi-task Learning for 3D Perception and End-to-end Autonomous Driving](https://arxiv.org/abs/2511.07106)
*Zhongyu Xia,Zhiwei Lin,Yongtao Wang,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: 本文提出了HENet和HENet++框架，通过混合图像编码网络和同时提取稠密与稀疏特征的方法，解决了自动驾驶中多任务3D感知的兼容性和效率问题。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统中的3D特征提取面临计算资源限制和多任务特征表示不兼容的问题，现有方法难以在保持精度的同时实现端到端多任务推理。

Method: 提出混合图像编码网络（大编码器处理短期帧，小编码器处理长期帧），同时提取稠密和稀疏特征，兼容现有3D特征提取方法并支持多模态输入。

Result: HENet++在nuScenes基准测试中实现了最先进的端到端多任务3D感知结果，并在nuScenes端到端自动驾驶基准中获得了最低碰撞率。

Conclusion: 该框架有效解决了多任务3D感知的兼容性问题，在保持高性能的同时降低了计算成本，为自动驾驶系统提供了更全面的规划信息。

Abstract: Three-dimensional feature extraction is a critical component of autonomous
driving systems, where perception tasks such as 3D object detection,
bird's-eye-view (BEV) semantic segmentation, and occupancy prediction serve as
important constraints on 3D features. While large image encoders,
high-resolution images, and long-term temporal inputs can significantly enhance
feature quality and deliver remarkable performance gains, these techniques are
often incompatible in both training and inference due to computational resource
constraints. Moreover, different tasks favor distinct feature representations,
making it difficult for a single model to perform end-to-end inference across
multiple tasks while maintaining accuracy comparable to that of single-task
models. To alleviate these issues, we present the HENet and HENet++ framework
for multi-task 3D perception and end-to-end autonomous driving. Specifically,
we propose a hybrid image encoding network that uses a large image encoder for
short-term frames and a small one for long-term frames. Furthermore, our
framework simultaneously extracts both dense and sparse features, providing
more suitable representations for different tasks, reducing cumulative errors,
and delivering more comprehensive information to the planning module. The
proposed architecture maintains compatibility with various existing 3D feature
extraction methods and supports multimodal inputs. HENet++ achieves
state-of-the-art end-to-end multi-task 3D perception results on the nuScenes
benchmark, while also attaining the lowest collision rate on the nuScenes
end-to-end autonomous driving benchmark.

</details>


### [192] [Sparse4DGS: 4D Gaussian Splatting for Sparse-Frame Dynamic Scene Reconstruction](https://arxiv.org/abs/2511.07122)
*Changyue Shi,Chuxiao Yang,Xinyuan Hu,Minghao Chen,Wenwen Pan,Yan Yang,Jiajun Ding,Zhou Yu,Jun Yu*

Main category: cs.CV

TL;DR: Sparse4DGS是一种针对稀疏帧动态场景重建的新方法，通过纹理感知的变形正则化和纹理感知的规范优化，解决了在稀疏帧设置下动态高斯分布重建的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有动态高斯分布方法依赖密集帧视频序列，但在实际场景中由于设备限制只能获取稀疏帧，导致重建效果不佳，特别是在纹理丰富区域。

Method: 提出纹理感知变形正则化（引入基于纹理的深度对齐损失来调节高斯变形）和纹理感知规范优化（在规范高斯梯度下降过程中加入基于纹理的噪声）。

Result: 在NeRF-Synthetic、HyperNeRF、NeRF-DS和iPhone-4D数据集上的实验表明，该方法在稀疏帧输入下优于现有动态或少量样本技术。

Conclusion: Sparse4DGS成功解决了稀疏帧动态场景重建问题，特别是在纹理丰富区域表现出色，为实际应用场景提供了有效解决方案。

Abstract: Dynamic Gaussian Splatting approaches have achieved remarkable performance
for 4D scene reconstruction. However, these approaches rely on dense-frame
video sequences for photorealistic reconstruction. In real-world scenarios, due
to equipment constraints, sometimes only sparse frames are accessible. In this
paper, we propose Sparse4DGS, the first method for sparse-frame dynamic scene
reconstruction. We observe that dynamic reconstruction methods fail in both
canonical and deformed spaces under sparse-frame settings, especially in areas
with high texture richness. Sparse4DGS tackles this challenge by focusing on
texture-rich areas. For the deformation network, we propose Texture-Aware
Deformation Regularization, which introduces a texture-based depth alignment
loss to regulate Gaussian deformation. For the canonical Gaussian field, we
introduce Texture-Aware Canonical Optimization, which incorporates
texture-based noise into the gradient descent process of canonical Gaussians.
Extensive experiments show that when taking sparse frames as inputs, our method
outperforms existing dynamic or few-shot techniques on NeRF-Synthetic,
HyperNeRF, NeRF-DS, and our iPhone-4D datasets.

</details>


### [193] [MPJudge: Towards Perceptual Assessment of Music-Induced Paintings](https://arxiv.org/abs/2511.07137)
*Shiqi Jiang,Tianyi Liang,Changbo Wang,Chenhui Li*

Main category: cs.CV

TL;DR: 提出了一种基于感知一致性的音乐诱导绘画评估框架，通过构建大规模数据集和引入偏好优化方法，解决了现有基于情感识别的评估方法存在的噪声问题。


<details>
  <summary>Details</summary>
Motivation: 现有音乐诱导绘画评估方法主要依赖情感识别模型，但这种方法会引入大量噪声且忽略了情感之外的更广泛感知线索。

Method: 构建了首个大规模音乐绘画配对数据集MPD，并提出MPJudge模型，通过基于调制的融合机制将音乐特征整合到视觉编码器中，采用直接偏好优化方法处理模糊案例。

Result: 大量实验表明该方法优于现有方法，定性结果显示模型能更准确地识别绘画中与音乐相关的区域。

Conclusion: 该框架通过直接建模音乐与视觉艺术之间的感知一致性，为音乐诱导绘画评估提供了更准确和全面的解决方案。

Abstract: Music induced painting is a unique artistic practice, where visual artworks
are created under the influence of music. Evaluating whether a painting
faithfully reflects the music that inspired it poses a challenging perceptual
assessment task. Existing methods primarily rely on emotion recognition models
to assess the similarity between music and painting, but such models introduce
considerable noise and overlook broader perceptual cues beyond emotion. To
address these limitations, we propose a novel framework for music induced
painting assessment that directly models perceptual coherence between music and
visual art. We introduce MPD, the first large scale dataset of music painting
pairs annotated by domain experts based on perceptual coherence. To better
handle ambiguous cases, we further collect pairwise preference annotations.
Building on this dataset, we present MPJudge, a model that integrates music
features into a visual encoder via a modulation based fusion mechanism. To
effectively learn from ambiguous cases, we adopt Direct Preference Optimization
for training. Extensive experiments demonstrate that our method outperforms
existing approaches. Qualitative results further show that our model more
accurately identifies music relevant regions in paintings.

</details>


### [194] [ProcGen3D: Learning Neural Procedural Graph Representations for Image-to-3D Reconstruction](https://arxiv.org/abs/2511.07142)
*Xinyi Zhang,Daoyi Gao,Naiqi Li,Angela Dai*

Main category: cs.CV

TL;DR: ProcGen3D是一种基于程序化图抽象生成3D内容的新方法，通过将3D对象表示为序列化的图结构，并使用Transformer和MCTS引导采样实现从RGB图像到复杂3D资产的重建。


<details>
  <summary>Details</summary>
Motivation: 受生产级3D应用中程序化生成器的广泛使用启发，旨在学习程序化生成器的表示空间，实现基于图像的3D重建，并提升对真实世界图像的泛化能力。

Method: 采用基于边的标记化方法编码程序化图，训练Transformer先验模型预测下一个标记，并引入蒙特卡洛树搜索引导采样以更好地对齐输入图像。

Result: 在仙人掌、树木和桥梁等对象上的实验表明，该方法在生成质量和图像保真度方面优于现有最先进的生成式3D方法和领域特定建模技术。

Conclusion: ProcGen3D能够仅使用合成数据训练，却实现对真实世界输入图像的改进泛化，证明了程序化图表示在3D内容创建中的有效性。

Abstract: We introduce ProcGen3D, a new approach for 3D content creation by generating
procedural graph abstractions of 3D objects, which can then be decoded into
rich, complex 3D assets. Inspired by the prevalent use of procedural generators
in production 3D applications, we propose a sequentialized, graph-based
procedural graph representation for 3D assets. We use this to learn to
approximate the landscape of a procedural generator for image-based 3D
reconstruction. We employ edge-based tokenization to encode the procedural
graphs, and train a transformer prior to predict the next token conditioned on
an input RGB image. Crucially, to enable better alignment of our generated
outputs to an input image, we incorporate Monte Carlo Tree Search (MCTS) guided
sampling into our generation process, steering output procedural graphs towards
more image-faithful reconstructions. Our approach is applicable across a
variety of objects that can be synthesized with procedural generators.
Extensive experiments on cacti, trees, and bridges show that our neural
procedural graph generation outperforms both state-of-the-art generative 3D
methods and domain-specific modeling techniques. Furthermore, this enables
improved generalization on real-world input images, despite training only on
synthetic data.

</details>


### [195] [Federated Learning for Video Violence Detection: Complementary Roles of Lightweight CNNs and Vision-Language Models for Energy-Efficient Use](https://arxiv.org/abs/2511.07171)
*Sébastien Thuau,Siba Haidar,Rachid Chelouah*

Main category: cs.CV

TL;DR: 本文比较了三种联邦学习暴力检测方法：零样本VLM推理、LoRA微调LLaVA-NeXT-Video-7B和个性化联邦学习3D CNN。3D CNN在能耗减半的情况下达到92.59% ROC AUC，而VLM提供更丰富的多模态推理能力。


<details>
  <summary>Details</summary>
Motivation: 深度学习视频监控需要隐私保护架构，但部署大型视觉语言模型会带来能源和可持续性挑战。本文旨在比较不同联邦学习策略在暴力检测中的性能与能耗。

Method: 在RWF-2000和RLVS数据集上比较三种策略：预训练VLM的零样本推理、LoRA微调LLaVA-NeXT-Video-7B、个性化联邦学习65.8M参数3D CNN。使用层次类别分组提升VLM多类分类准确率。

Result: 所有方法在二元暴力检测中准确率超过90%。3D CNN能耗仅为240Wh（LoRA为570Wh），ROC AUC达92.59%。层次类别分组将VLM多类准确率从65.31%提升至81%。

Conclusion: 研究提出了混合部署策略：常规推理使用高效CNN，复杂情境推理选择性使用VLM。这是首个量化LoRA调优VLM与个性化CNN在联邦暴力检测中能耗与CO2e的比较研究。

Abstract: Deep learning-based video surveillance increasingly demands
privacy-preserving architectures with low computational and environmental
overhead. Federated learning preserves privacy but deploying large
vision-language models (VLMs) introduces major energy and sustainability
challenges. We compare three strategies for federated violence detection under
realistic non-IID splits on the RWF-2000 and RLVS datasets: zero-shot inference
with pretrained VLMs, LoRA-based fine-tuning of LLaVA-NeXT-Video-7B, and
personalized federated learning of a 65.8M-parameter 3D CNN. All methods exceed
90% accuracy in binary violence detection. The 3D CNN achieves superior
calibration (ROC AUC 92.59%) at roughly half the energy cost (240 Wh vs. 570
Wh) of federated LoRA, while VLMs provide richer multimodal reasoning.
Hierarchical category grouping (based on semantic similarity and class
exclusion) boosts VLM multiclass accuracy from 65.31% to 81% on the UCF-Crime
dataset. To our knowledge, this is the first comparative simulation study of
LoRA-tuned VLMs and personalized CNNs for federated violence detection, with
explicit energy and CO2e quantification. Our results inform hybrid deployment
strategies that default to efficient CNNs for routine inference and selectively
engage VLMs for complex contextual reasoning.

</details>


### [196] [LiteUpdate: A Lightweight Framework for Updating AI-Generated Image Detectors](https://arxiv.org/abs/2511.07192)
*Jiajie Lu,Zhenkan Fu,Na Zhao,Long Xing,Kejiang Chen,Weiming Zhang,Nenghai Yu*

Main category: cs.CV

TL;DR: LiteUpdate是一个轻量级框架，用于高效更新AI生成图像检测器，通过边界样本选择和模型融合技术解决检测器更新中的低效率和灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 生成式AI快速发展导致新模型不断涌现，现有检测方法难以跟上节奏，检测性能显著下降，迫切需要持续更新检测器以适应新生成器。

Method: 采用代表性样本选择模块（基于图像置信度和梯度特征选择边界样本）和模型融合模块（融合预训练、代表性和随机更新的权重），平衡新生成器适应性和先验知识保留。

Result: 实验表明LiteUpdate显著提升检测性能，在AIDE数据集上对Midjourney的平均检测准确率从87.63%提升至93.03%，相对提升6.16%。

Conclusion: LiteUpdate框架有效解决了AI生成图像检测器更新中的效率和遗忘问题，为持续适应新生成模型提供了可行方案。

Abstract: The rapid progress of generative AI has led to the emergence of new
generative models, while existing detection methods struggle to keep pace,
resulting in significant degradation in the detection performance. This
highlights the urgent need for continuously updating AI-generated image
detectors to adapt to new generators. To overcome low efficiency and
catastrophic forgetting in detector updates, we propose LiteUpdate, a
lightweight framework for updating AI-generated image detectors. LiteUpdate
employs a representative sample selection module that leverages image
confidence and gradient-based discriminative features to precisely select
boundary samples. This approach improves learning and detection accuracy on new
distributions with limited generated images, significantly enhancing detector
update efficiency. Additionally, LiteUpdate incorporates a model merging module
that fuses weights from multiple fine-tuning trajectories, including
pre-trained, representative, and random updates. This balances the adaptability
to new generators and mitigates the catastrophic forgetting of prior knowledge.
Experiments demonstrate that LiteUpdate substantially boosts detection
performance in various detectors. Specifically, on AIDE, the average detection
accuracy on Midjourney improved from 87.63% to 93.03%, a 6.16% relative
increase.

</details>


### [197] [Automated Estimation of Anatomical Risk Metrics for Endoscopic Sinus Surgery Using Deep Learning](https://arxiv.org/abs/2511.07199)
*Konrad Reuter,Lennart Thaysen,Bilkay Doruk,Sarah Latus,Brigitte Holst,Benjamin Becker,Dennis Eggert,Christian Betz,Anna-Sophie Hoffmann,Alexander Schlaefer*

Main category: cs.CV

TL;DR: 提出了一种基于深度学习的自动化管道，用于通过热图回归定位关键解剖标志来估计内窥镜鼻窦手术的解剖风险评分。


<details>
  <summary>Details</summary>
Motivation: 内窥镜鼻窦手术需要仔细的术前评估以最小化风险，但现有的解剖风险评分需要耗时的手动测量。

Method: 比较了直接方法和专门的全局到局部学习策略，通过热图回归定位关键解剖标志。

Result: 在相关解剖测量上的平均绝对误差为：Keros评分0.506mm，Gera评分4.516°，TMS分类0.802mm/0.777mm。

Conclusion: 该自动化深度学习管道能够准确估计解剖风险评分，减少手动测量的时间消耗。

Abstract: Endoscopic sinus surgery requires careful preoperative assessment of the
skull base anatomy to minimize risks such as cerebrospinal fluid leakage.
Anatomical risk scores like the Keros, Gera and Thailand-Malaysia-Singapore
score offer a standardized approach but require time-consuming manual
measurements on coronal CT or CBCT scans. We propose an automated deep learning
pipeline that estimates these risk scores by localizing key anatomical
landmarks via heatmap regression. We compare a direct approach to a specialized
global-to-local learning strategy and find mean absolute errors on the relevant
anatomical measurements of 0.506mm for the Keros, 4.516{\deg} for the Gera and
0.802mm / 0.777mm for the TMS classification.

</details>


### [198] [Geometric implicit neural representations for signed distance functions](https://arxiv.org/abs/2511.07206)
*Luiz Schirmer,Tiago Novello,Vinícius da Silva,Guilherme Schardong,Daniel Perazzo,Hélio Lopes,Nuno Gonçalves,Luiz Velho*

Main category: cs.CV

TL;DR: 这篇综述论文回顾了使用几何隐式神经表示(INRs)来近似符号距离函数(SDFs)的3D表面重建方法，重点介绍了在损失函数中融入微分几何工具的正则化技术。


<details>
  <summary>Details</summary>
Motivation: 隐式神经表示在低维空间中表示信号方面显示出巨大潜力，但需要确保重建的表面满足特定的几何性质，如SDFs的单位梯度约束。

Method: 通过将微分几何工具（如法线和曲率）融入损失函数中作为正则化项，构建几何INRs来保证函数满足全局几何性质。

Result: 几何INRs在从定向点云和姿态图像进行表面重建方面取得了显著进展，提高了重建质量。

Conclusion: 几何INRs为3D表面重建提供了一种有前景的框架，通过微分几何视角的正则化方法能够有效提升重建精度和几何一致性。

Abstract: \textit{Implicit neural representations} (INRs) have emerged as a promising
framework for representing signals in low-dimensional spaces. This survey
reviews the existing literature on the specialized INR problem of approximating
\textit{signed distance functions} (SDFs) for surface scenes, using either
oriented point clouds or a set of posed images. We refer to neural SDFs that
incorporate differential geometry tools, such as normals and curvatures, in
their loss functions as \textit{geometric} INRs. The key idea behind this 3D
reconstruction approach is to include additional \textit{regularization} terms
in the loss function, ensuring that the INR satisfies certain global properties
that the function should hold -- such as having unit gradient in the case of
SDFs. We explore key methodological components, including the definition of
INR, the construction of geometric loss functions, and sampling schemes from a
differential geometry perspective. Our review highlights the significant
advancements enabled by geometric INRs in surface reconstruction from oriented
point clouds and posed images.

</details>


### [199] [Breaking the Stealth-Potency Trade-off in Clean-Image Backdoors with Generative Trigger Optimization](https://arxiv.org/abs/2511.07210)
*Binyan Xu,Fan Yang,Di Tang,Xilin Dai,Kehuan Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种新的干净图像后门攻击范式GCB，通过使用条件InfoGAN识别自然图像特征作为隐蔽触发器，在极低毒化率下实现有效攻击，同时保持清洁准确率下降小于1%。


<details>
  <summary>Details</summary>
Motivation: 现有干净图像后门攻击方法需要较高的毒化率才能成功，这会导致清洁准确率显著下降，影响攻击的隐蔽性。

Method: 使用条件InfoGAN框架识别自然图像特征作为隐蔽触发器，确保这些触发器与良性任务特征易于分离，从而在极少数毒化样本上学习后门。

Result: GCB在6个数据集、5种架构和4种任务上表现出色，首次在回归和分割任务中实现干净图像后门攻击，且对现有防御方法具有抵抗力。

Conclusion: GCB提供了一种高效且隐蔽的干净图像后门攻击方法，显著降低了攻击所需的毒化率，同时最小化了对模型清洁性能的影响。

Abstract: Clean-image backdoor attacks, which use only label manipulation in training
datasets to compromise deep neural networks, pose a significant threat to
security-critical applications. A critical flaw in existing methods is that the
poison rate required for a successful attack induces a proportional, and thus
noticeable, drop in Clean Accuracy (CA), undermining their stealthiness. This
paper presents a new paradigm for clean-image attacks that minimizes this
accuracy degradation by optimizing the trigger itself. We introduce Generative
Clean-Image Backdoors (GCB), a framework that uses a conditional InfoGAN to
identify naturally occurring image features that can serve as potent and
stealthy triggers. By ensuring these triggers are easily separable from benign
task-related features, GCB enables a victim model to learn the backdoor from an
extremely small set of poisoned examples, resulting in a CA drop of less than
1%. Our experiments demonstrate GCB's remarkable versatility, successfully
adapting to six datasets, five architectures, and four tasks, including the
first demonstration of clean-image backdoors in regression and segmentation.
GCB also exhibits resilience against most of the existing backdoor defenses.

</details>


### [200] [Omni-View: Unlocking How Generation Facilitates Understanding in Unified 3D Model based on Multiview images](https://arxiv.org/abs/2511.07222)
*JiaKui Hu,Shanshan Zhao,Qing-Guo Chen,Xuerui Qiu,Jialun Liu,Zhao Xu,Weihua Luo,Kaifu Zhang,Yanye Lu*

Main category: cs.CV

TL;DR: Omni-View是一个基于多视角图像的3D场景统一多模态理解与生成框架，通过“生成促进理解”原则，在VSI-Bench基准上达到55.4分的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 探索“生成促进理解”原则，将统一多模态理解与生成扩展到3D场景，实现3D场景理解与生成任务的协同交互。

Method: 由理解模型、纹理模块和几何模块组成，采用两阶段训练策略，联合建模场景理解、新视角合成和几何估计。

Result: 在VSI-Bench基准上达到55.4分的SOTA性能，优于现有专用3D理解模型，同时在新视角合成和3D场景生成方面表现强劲。

Conclusion: Omni-View通过联合建模理解与生成任务，证明了生成任务对3D场景理解的促进作用，实现了统一的3D多模态理解与生成框架。

Abstract: This paper presents Omni-View, which extends the unified multimodal
understanding and generation to 3D scenes based on multiview images, exploring
the principle that "generation facilitates understanding". Consisting of
understanding model, texture module, and geometry module, Omni-View jointly
models scene understanding, novel view synthesis, and geometry estimation,
enabling synergistic interaction between 3D scene understanding and generation
tasks. By design, it leverages the spatiotemporal modeling capabilities of its
texture module responsible for appearance synthesis, alongside the explicit
geometric constraints provided by its dedicated geometry module, thereby
enriching the model's holistic understanding of 3D scenes. Trained with a
two-stage strategy, Omni-View achieves a state-of-the-art score of 55.4 on the
VSI-Bench benchmark, outperforming existing specialized 3D understanding
models, while simultaneously delivering strong performance in both novel view
synthesis and 3D scene generation.

</details>


### [201] [Mapping Reduced Accessibility to WASH Facilities in Rohingya Refugee Camps with Sub-Meter Imagery](https://arxiv.org/abs/2511.07231)
*Kyeongjin Ahn,YongHun Suh,Sungwon Han,Jeasurk Yang,Hannes Taubenböck,Meeyoung Cha*

Main category: cs.CV

TL;DR: 本研究开发了一个基于遥感技术的框架，用于量化罗兴亚难民营中WASH设施的获取情况，发现由于人口增长和设施减少，WASH获取性正在下降，特别是对妇女和女童而言。


<details>
  <summary>Details</summary>
Motivation: 难民难民营中的水、环境卫生和个人卫生（WASH）服务获取是一个重要的公共卫生问题，尤其是在罗兴亚难民营这样高密度的人口安置环境中，需要有效的方法来监测和评估WASH设施的获取情况。

Method: 使用亚米级卫星图像，开发了一个半监督分割框架来检测难民庇护所，并应用该框架分析多年数据，评估WASH设施的获取性。

Result: 框架在检测难民庇护所方面达到76.4%的F1分数；WASH获取性从2022年的每设施25人下降到2025年的29.4人；性别分析显示妇女和女童的获取性更低。

Conclusion: 研究表明高分辨率遥感和机器学习在检测不平等和指导资源规划方面的价值，强调需要需求响应的分配策略，特别是在预算有限的环境中确保基础设施服务于最多人群。

Abstract: Access to Water, Sanitation, and Hygiene (WASH) services remains a major
public health concern in refugee camps. This study introduces a remote
sensing-driven framework to quantify WASH accessibility-specifically to water
pumps, latrines, and bathing cubicles-in the Rohingya camps of Cox's Bazar, one
of the world's most densely populated displacement settings. Detecting refugee
shelters in such emergent camps presents substantial challenges, primarily due
to their dense spatial configuration and irregular geometric patterns. Using
sub-meter satellite images, we develop a semi-supervised segmentation framework
that achieves an F1-score of 76.4% in detecting individual refugee shelters.
Applying the framework across multi-year data reveals declining WASH
accessibility, driven by rapid refugee population growth and reduced facility
availability, rising from 25 people per facility in 2022 to 29.4 in 2025.
Gender-disaggregated analysis further shows that women and girls experience
reduced accessibility, in scenarios with inadequate safety-related segregation
in WASH facilities. These findings suggest the importance of demand-responsive
allocation strategies that can identify areas with under-served
populations-such as women and girls-and ensure that limited infrastructure
serves the greatest number of people in settings with fixed or shrinking
budgets. We also discuss the value of high-resolution remote sensing and
machine learning to detect inequality and inform equitable resource planning in
complex humanitarian environments.

</details>


### [202] [Noise & pattern: identity-anchored Tikhonov regularization for robust structural anomaly detection](https://arxiv.org/abs/2511.07233)
*Alexander Bauer,Klaus-Robert Müller*

Main category: cs.CV

TL;DR: 提出了一种基于自监督自编码器的结构异常检测方法，通过注入结构化扰动和保留高斯噪声来提升检测性能，在MVTec AD基准上达到SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 工业检测中难以收集所有可能的异常样本，因此需要一种能够有效检测细微或罕见缺陷的方法，特别是在结构异常检测方面。

Method: 使用自监督自编码器学习修复被破坏的输入，引入结构化扰动模拟结构缺陷，并保留高斯噪声作为正则化器稳定重建过程。

Result: 在MVTec AD基准测试中取得最佳性能（I/P-AUROC: 99.9/99.4），验证了理论框架的有效性。

Conclusion: 该方法通过结构化扰动和身份锚定正则化，在自动工业检测中表现出优异的异常检测和分割能力。

Abstract: Anomaly detection plays a pivotal role in automated industrial inspection,
aiming to identify subtle or rare defects in otherwise uniform visual patterns.
As collecting representative examples of all possible anomalies is infeasible,
we tackle structural anomaly detection using a self-supervised autoencoder that
learns to repair corrupted inputs. To this end, we introduce a corruption model
that injects artificial disruptions into training images to mimic structural
defects. While reminiscent of denoising autoencoders, our approach differs in
two key aspects. First, instead of unstructured i.i.d.\ noise, we apply
structured, spatially coherent perturbations that make the task a hybrid of
segmentation and inpainting. Second, and counterintuitively, we add and
preserve Gaussian noise on top of the occlusions, which acts as a Tikhonov
regularizer anchoring the Jacobian of the reconstruction function toward
identity. This identity-anchored regularization stabilizes reconstruction and
further improves both detection and segmentation accuracy. On the MVTec AD
benchmark, our method achieves state-of-the-art results (I/P-AUROC: 99.9/99.4),
supporting our theoretical framework and demonstrating its practical relevance
for automatic inspection.

</details>


### [203] [Leveraging Text-Driven Semantic Variation for Robust OOD Segmentation](https://arxiv.org/abs/2511.07238)
*Seungheon Song,Jaekoo Lee*

Main category: cs.CV

TL;DR: 提出了一种基于视觉语言模型的文本驱动OOD分割方法，通过结合视觉语言编码器和Transformer解码器，利用距离基OOD提示和语义增强技术，在自动驾驶场景中实现先进的异常物体分割性能。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶和机器人领域，确保道路安全和可靠决策关键依赖于OOD分割。虽然已有多种方法检测道路异常物体，但利用视觉语言空间提供的丰富语言知识仍是一个未被充分探索的领域。作者假设在复杂自动驾驶场景中，融入语言线索将特别有益。

Method: 训练文本驱动OOD分割模型，结合视觉语言模型编码器和Transformer解码器，采用距离基OOD提示（位于不同语义距离）和OOD语义增强技术，通过对齐视觉和文本信息实现有效泛化。

Result: 在Fishyscapes、Segment-Me-If-You-Can和Road Anomaly等公开数据集上的广泛实验表明，该方法在像素级和物体级评估中均达到最先进性能。

Conclusion: 基于视觉语言的OOD分割具有增强未来自动驾驶系统安全性和可靠性的潜力。

Abstract: In autonomous driving and robotics, ensuring road safety and reliable
decision-making critically depends on out-of-distribution (OOD) segmentation.
While numerous methods have been proposed to detect anomalous objects on the
road, leveraging the vision-language space-which provides rich linguistic
knowledge-remains an underexplored field. We hypothesize that incorporating
these linguistic cues can be especially beneficial in the complex contexts
found in real-world autonomous driving scenarios.
  To this end, we present a novel approach that trains a Text-Driven OOD
Segmentation model to learn a semantically diverse set of objects in the
vision-language space. Concretely, our approach combines a vision-language
model's encoder with a transformer decoder, employs Distance-Based OOD prompts
located at varying semantic distances from in-distribution (ID) classes, and
utilizes OOD Semantic Augmentation for OOD representations. By aligning visual
and textual information, our approach effectively generalizes to unseen objects
and provides robust OOD segmentation in diverse driving environments.
  We conduct extensive experiments on publicly available OOD segmentation
datasets such as Fishyscapes, Segment-Me-If-You-Can, and Road Anomaly datasets,
demonstrating that our approach achieves state-of-the-art performance across
both pixel-level and object-level evaluations. This result underscores the
potential of vision-language-based OOD segmentation to bolster the safety and
reliability of future autonomous driving systems.

</details>


### [204] [4DSTR: Advancing Generative 4D Gaussians with Spatial-Temporal Rectification for High-Quality and Consistent 4D Generation](https://arxiv.org/abs/2511.07241)
*Mengmeng Liu,Jiuming Liu,Yunpeng Zhang,Jiangtao Li,Michael Ying Yang,Francesco Nex,Hao Cheng*

Main category: cs.CV

TL;DR: 4DSTR是一个新的4D生成网络，通过时空校正来调制生成式4D高斯泼溅，解决了现有方法在时空一致性和快速时间变化适应方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的4D生成方法在保持时空一致性和适应快速时间变化方面存在困难，主要原因是缺乏有效的时空建模。

Method: 提出了4DSTR网络，采用时空校正调制生成式4D高斯泼溅。具体包括：设计跨生成4D序列的时间相关性来校正可变形尺度和旋转以保证时间一致性；提出自适应空间密集化和剪枝策略，通过动态添加或删除高斯点来处理显著的时间变化。

Result: 大量实验表明，4DSTR在视频到4D生成任务中达到了最先进的性能，在重建质量、时空一致性和对快速时间运动的适应方面表现出色。

Conclusion: 4DSTR通过有效的时空建模方法，成功解决了4D生成中的时空一致性和时间变化适应问题，为动态4D内容生成提供了有效的解决方案。

Abstract: Remarkable advances in recent 2D image and 3D shape generation have induced a
significant focus on dynamic 4D content generation. However, previous 4D
generation methods commonly struggle to maintain spatial-temporal consistency
and adapt poorly to rapid temporal variations, due to the lack of effective
spatial-temporal modeling. To address these problems, we propose a novel 4D
generation network called 4DSTR, which modulates generative 4D Gaussian
Splatting with spatial-temporal rectification. Specifically, temporal
correlation across generated 4D sequences is designed to rectify deformable
scales and rotations and guarantee temporal consistency. Furthermore, an
adaptive spatial densification and pruning strategy is proposed to address
significant temporal variations by dynamically adding or deleting Gaussian
points with the awareness of their pre-frame movements. Extensive experiments
demonstrate that our 4DSTR achieves state-of-the-art performance in video-to-4D
generation, excelling in reconstruction quality, spatial-temporal consistency,
and adaptation to rapid temporal movements.

</details>


### [205] [MVU-Eval: Towards Multi-Video Understanding Evaluation for Multimodal LLMs](https://arxiv.org/abs/2511.07250)
*Tianhao Peng,Haochen Wang,Yuanxing Zhang,Zekun Wang,Zili Wang,Ge Zhang,Jian Yang,Shihao Li,Yanghai Wang,Xintao Wang,Houyi Li,Wei Ji,Pengfei Wan,Wenhao Huang,Zhaoxiang Zhang,Jiaheng Liu*

Main category: cs.CV

TL;DR: MVU-Eval是首个针对多模态大语言模型的多视频理解综合评估基准，包含1,824个精心策划的问答对，涵盖4,959个视频，评估8项核心能力。


<details>
  <summary>Details</summary>
Motivation: 现有评估基准仅限于单视频理解，无法满足现实场景（如体育分析和自动驾驶）中对多视频理解的关键需求。

Method: 构建MVU-Eval基准，通过来自不同领域的4,959个视频和1,824个问答对，评估MLLMs在基础感知任务和高阶推理任务中的8项核心能力。

Result: 对领先的开源和闭源模型进行广泛评估，揭示了当前MLLMs在多视频理解能力上存在显著性能差距和局限性。

Conclusion: MVU-Eval基准将公开提供，以促进未来研究，解决当前MLLMs在多视频理解方面的不足。

Abstract: The advent of Multimodal Large Language Models (MLLMs) has expanded AI
capabilities to visual modalities, yet existing evaluation benchmarks remain
limited to single-video understanding, overlooking the critical need for
multi-video understanding in real-world scenarios (e.g., sports analytics and
autonomous driving). To address this significant gap, we introduce MVU-Eval,
the first comprehensive benchmark for evaluating Multi-Video Understanding for
MLLMs. Specifically, our MVU-Eval mainly assesses eight core competencies
through 1,824 meticulously curated question-answer pairs spanning 4,959 videos
from diverse domains, addressing both fundamental perception tasks and
high-order reasoning tasks. These capabilities are rigorously aligned with
real-world applications such as multi-sensor synthesis in autonomous systems
and cross-angle sports analytics. Through extensive evaluation of
state-of-the-art open-source and closed-source models, we reveal significant
performance discrepancies and limitations in current MLLMs' ability to perform
understanding across multiple videos. The benchmark will be made publicly
available to foster future research.

</details>


### [206] [StreamKV: Streaming Video Question-Answering with Segment-based KV Cache Retrieval and Compression](https://arxiv.org/abs/2511.07278)
*Yilong Chen,Xiang Bai,Zhibin Wang,Chengyu Bai,Yuhan Dai,Ming Lu,Shanghang Zhang*

Main category: cs.CV

TL;DR: StreamKV是一个无需训练的视频大语言模型框架，通过动态语义分割和层自适应机制，实现了KV缓存的检索和压缩，显著提升了长视频问答的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 当前视频大语言模型在处理长视频时面临挑战，现有的KV缓存检索和压缩方法尚未充分探索，需要更有效的解决方案来提升长视频问答的性能。

Method: StreamKV采用动态语义分割视频流，为每个片段计算摘要向量保留检索信息，并通过引导提示压缩KV缓存，在单一模块中统一实现层自适应的检索和压缩。

Result: 在StreamingVQA基准测试中，StreamKV显著优于现有在线视频大语言模型，在准确性和效率方面均取得优异表现。

Conclusion: StreamKV通过创新的KV缓存管理机制，有效解决了长视频处理中的挑战，为视频大语言模型的实际应用提供了重要技术支撑。

Abstract: Video Large Language Models (Video-LLMs) have demonstrated significant
potential in the areas of video captioning, search, and summarization. However,
current Video-LLMs still face challenges with long real-world videos. Recent
methods have introduced a retrieval mechanism that retrieves query-relevant KV
caches for question answering, enhancing the efficiency and accuracy of long
real-world videos. However, the compression and retrieval of KV caches are
still not fully explored. In this paper, we propose \textbf{StreamKV}, a
training-free framework that seamlessly equips Video-LLMs with advanced KV
cache retrieval and compression. Compared to previous methods that used uniform
partitioning, StreamKV dynamically partitions video streams into semantic
segments, which better preserves semantic information. For KV cache retrieval,
StreamKV calculates a summary vector for each segment to retain segment-level
information essential for retrieval. For KV cache compression, StreamKV
introduces a guidance prompt designed to capture the key semantic elements
within each segment, ensuring only the most informative KV caches are retained
for answering questions. Moreover, StreamKV unifies KV cache retrieval and
compression within a single module, performing both in a layer-adaptive manner,
thereby further improving the effectiveness of streaming video question
answering. Extensive experiments on public StreamingVQA benchmarks demonstrate
that StreamKV significantly outperforms existing Online Video-LLMs, achieving
superior accuracy while substantially improving both memory efficiency and
computational latency. The code has been released at
https://github.com/sou1p0wer/StreamKV.

</details>


### [207] [Segmentation of Ischemic Stroke Lesions using Transfer Learning on Multi-sequence MRI](https://arxiv.org/abs/2511.07281)
*R. P. Chowdhury,T. Rahman*

Main category: cs.CV

TL;DR: 本文提出了一种基于Res-Unet架构的自动分割框架，用于在多种MRI序列上快速准确地分割缺血性卒中病灶，并在ISLES 2015数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 手动分割缺血性卒中病灶耗时且易产生观察者间差异，现有自动方法依赖手工特征难以捕捉病灶的不规则复杂形状。

Method: 使用Res-Unet架构，分别采用预训练权重和无预训练权重进行训练以探索迁移学习效果，并集成多数投票分类器融合各轴分割结果。

Result: 在ISLES 2015数据集上获得80.5%的Dice分数和74.03%的准确率。

Conclusion: 该方法能有效自动分割缺血性卒中病灶，为临床诊断提供可靠工具。

Abstract: The accurate understanding of ischemic stroke lesions is critical for
efficient therapy and prognosis of stroke patients. Magnetic resonance imaging
(MRI) is sensitive to acute ischemic stroke and is a common diagnostic method
for stroke. However, manual lesion segmentation performed by experts is
tedious, time-consuming, and prone to observer inconsistency. Automatic medical
image analysis methods have been proposed to overcome this challenge. However,
previous approaches have relied on hand-crafted features that may not capture
the irregular and physiologically complex shapes of ischemic stroke lesions. In
this study, we present a novel framework for quickly and automatically
segmenting ischemic stroke lesions on various MRI sequences, including
T1-weighted, T2-weighted, DWI, and FLAIR. The proposed methodology is validated
on the ISLES 2015 Brain Stroke sequence dataset, where we trained our model
using the Res-Unet architecture twice: first, with pre-existing weights, and
then without, to explore the benefits of transfer learning. Evaluation metrics,
including the Dice score and sensitivity, were computed across 3D volumes.
Finally, a Majority Voting Classifier was integrated to amalgamate the outcomes
from each axis, resulting in a comprehensive segmentation method. Our efforts
culminated in achieving a Dice score of 80.5\% and an accuracy of 74.03\%,
showcasing the efficacy of our segmentation approach.

</details>


### [208] [Glioma C6: A Novel Dataset for Training and Benchmarking Cell Segmentation](https://arxiv.org/abs/2511.07286)
*Roman Malashin,Svetlana Pashkevich,Daniil Ilyukhin,Arseniy Volkov,Valeria Yachnaya,Andrey Denisov,Maria Mikhalkova*

Main category: cs.CV

TL;DR: Glioma C6是一个用于胶质瘤C6细胞实例分割的新开放数据集，包含75张高分辨率相衬显微镜图像和超过12,000个标注细胞，可作为深度学习模型的基准和训练资源。


<details>
  <summary>Details</summary>
Motivation: 为生物医学图像分析提供现实的测试平台，通过形态学细胞分类增强癌细胞研究中的图像数据利用价值。

Method: 数据集分为两部分：第一部分用于基准测试，第二部分用于不同条件下的泛化测试。评估了多个通用分割模型在数据集上的性能。

Result: 实验表明，在Glioma C6上训练显著提高了分割性能，证明了该数据集对于开发鲁棒和可泛化模型的价值。

Conclusion: Glioma C6数据集公开可用，为研究人员提供了有价值的资源，有助于推动胶质瘤细胞分割研究的发展。

Abstract: We present Glioma C6, a new open dataset for instance segmentation of glioma
C6 cells, designed as both a benchmark and a training resource for deep
learning models. The dataset comprises 75 high-resolution phase-contrast
microscopy images with over 12,000 annotated cells, providing a realistic
testbed for biomedical image analysis. It includes soma annotations and
morphological cell categorization provided by biologists. Additional
categorization of cells, based on morphology, aims to enhance the utilization
of image data for cancer cell research. Glioma C6 consists of two parts: the
first is curated with controlled parameters for benchmarking, while the second
supports generalization testing under varying conditions. We evaluate the
performance of several generalist segmentation models, highlighting their
limitations on our dataset. Our experiments demonstrate that training on Glioma
C6 significantly enhances segmentation performance, reinforcing its value for
developing robust and generalizable models. The dataset is publicly available
for researchers.

</details>


### [209] [LMM-IQA: Image Quality Assessment for Low-Dose CT Imaging](https://arxiv.org/abs/2511.07298)
*Kagan Celik,Mehmet Ozan Unal,Metin Ertas,Isa Yildirim*

Main category: cs.CV

TL;DR: 提出了基于LLM的低剂量CT图像质量评估系统，能够生成数值评分和文本描述，并通过多种推理策略提升性能。


<details>
  <summary>Details</summary>
Motivation: 低剂量CT虽然降低了辐射剂量，但图像质量下降（噪声、模糊、对比度损失）会影响诊断质量，因此需要可靠的质量评估方法。

Method: 使用LLM构建质量评估系统，采用零样本学习、元数据集成和错误反馈等多种推理策略，系统生成数值评分和退化描述。

Result: 评估结果显示出高度相关性，并提供可解释的输出，有助于临床工作流程。源代码已开源。

Conclusion: LLM-based方法能够有效评估低剂量CT图像质量，提供数值和文本双重评估，为临床应用提供价值。

Abstract: Low-dose computed tomography (CT) represents a significant improvement in
patient safety through lower radiation doses, but increased noise, blur, and
contrast loss can diminish diagnostic quality. Therefore, consistency and
robustness in image quality assessment become essential for clinical
applications. In this study, we propose an LLM-based quality assessment system
that generates both numerical scores and textual descriptions of degradations
such as noise, blur, and contrast loss. Furthermore, various inference
strategies - from the zero-shot approach to metadata integration and error
feedback - are systematically examined, demonstrating the progressive
contribution of each method to overall performance. The resultant assessments
yield not only highly correlated scores but also interpretable output, thereby
adding value to clinical workflows. The source codes of our study are available
at https://github.com/itu-biai/lmms_ldct_iqa.

</details>


### [210] [VADER: Towards Causal Video Anomaly Understanding with Relation-Aware Large Language Models](https://arxiv.org/abs/2511.07299)
*Ying Cheng,Yu-Ho Lin,Min-Hung Chen,Fu-En Yang,Shang-Hong Lai*

Main category: cs.CV

TL;DR: VADER是一个基于大语言模型的视频异常理解框架，通过整合关键帧对象关系特征和视觉线索来增强对视频中异常行为的理解。


<details>
  <summary>Details</summary>
Motivation: 传统方法仅关注异常检测和定位，忽略了更深层次的因果关系和对象间交互，这些对于理解异常行为至关重要。

Method: 首先使用异常评分器分配每帧异常分数，然后通过上下文感知采样策略捕获异常事件的因果上下文。关系特征提取器和对比关系编码器共同建模动态对象交互，生成紧凑的关系表示。最后将这些视觉和关系线索与大语言模型集成。

Result: 在多个真实世界VAU基准测试中，VADER在异常描述、解释和因果推理任务上取得了强劲结果。

Conclusion: VADER推动了可解释视频异常分析的前沿，能够生成详细、因果基础化的描述并支持稳健的异常相关问答。

Abstract: Video anomaly understanding (VAU) aims to provide detailed interpretation and
semantic comprehension of anomalous events within videos, addressing
limitations of traditional methods that focus solely on detecting and
localizing anomalies. However, existing approaches often neglect the deeper
causal relationships and interactions between objects, which are critical for
understanding anomalous behaviors. In this paper, we propose VADER, an
LLM-driven framework for Video Anomaly unDErstanding, which integrates keyframe
object Relation features with visual cues to enhance anomaly comprehension from
video. Specifically, VADER first applies an Anomaly Scorer to assign per-frame
anomaly scores, followed by a Context-AwarE Sampling (CAES) strategy to capture
the causal context of each anomalous event. A Relation Feature Extractor and a
COntrastive Relation Encoder (CORE) jointly model dynamic object interactions,
producing compact relational representations for downstream reasoning. These
visual and relational cues are integrated with LLMs to generate detailed,
causally grounded descriptions and support robust anomaly-related question
answering. Experiments on multiple real-world VAU benchmarks demonstrate that
VADER achieves strong results across anomaly description, explanation, and
causal reasoning tasks, advancing the frontier of explainable video anomaly
analysis.

</details>


### [211] [Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection](https://arxiv.org/abs/2511.07301)
*Huizai Yao,Sicheng Zhao,Pengteng Li,Yi Cui,Shuo Lu,Weiyu Guo,Yunfan Lu,Yijie Xu,Hui Xiong*

Main category: cs.CV

TL;DR: 本文提出了一种新的源自由目标检测框架，利用视觉基础模型作为外部知识源，通过三个模块联合增强特征对齐和标签质量，在六个基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有的源自由目标检测方法主要依赖源模型的内部知识，这限制了跨域泛化能力并导致有偏伪标签。视觉基础模型具有强大的感知能力和广泛泛化性，但在SFOD场景中潜力尚未被充分挖掘。

Method: 设计了三个VFM模块：1) 基于补丁相似性加权的全局特征对齐模块；2) 基于动量更新原型的实例级对比学习模块；3) 通过熵感知策略融合检测VFM和教师模型预测的双源增强伪标签融合模块。

Result: 在六个基准测试上的广泛实验表明，该方法实现了最先进的SFOD性能，验证了整合VFM同时提高可迁移性和判别性的有效性。

Conclusion: 通过利用视觉基础模型作为外部知识源，成功解决了源自由目标检测中的特征对齐和标签质量问题，显著提升了模型性能。

Abstract: Source-Free Object Detection (SFOD) aims to adapt a source-pretrained object
detector to a target domain without access to source data. However, existing
SFOD methods predominantly rely on internal knowledge from the source model,
which limits their capacity to generalize across domains and often results in
biased pseudo-labels, thereby hindering both transferability and
discriminability. In contrast, Vision Foundation Models (VFMs), pretrained on
massive and diverse data, exhibit strong perception capabilities and broad
generalization, yet their potential remains largely untapped in the SFOD
setting. In this paper, we propose a novel SFOD framework that leverages VFMs
as external knowledge sources to jointly enhance feature alignment and label
quality. Specifically, we design three VFM-based modules: (1) Patch-weighted
Global Feature Alignment (PGFA) distills global features from VFMs using
patch-similarity-based weighting to enhance global feature transferability; (2)
Prototype-based Instance Feature Alignment (PIFA) performs instance-level
contrastive learning guided by momentum-updated VFM prototypes; and (3)
Dual-source Enhanced Pseudo-label Fusion (DEPF) fuses predictions from
detection VFMs and teacher models via an entropy-aware strategy to yield more
reliable supervision. Extensive experiments on six benchmarks demonstrate that
our method achieves state-of-the-art SFOD performance, validating the
effectiveness of integrating VFMs to simultaneously improve transferability and
discriminability.

</details>


### [212] [YoNoSplat: You Only Need One Model for Feedforward 3D Gaussian Splatting](https://arxiv.org/abs/2511.07321)
*Botao Ye,Boqi Chen,Haofei Xu,Daniel Barath,Marc Pollefeys*

Main category: cs.CV

TL;DR: YoNoSplat是一个前馈模型，能够从任意数量的无结构图像中快速重建高质量的3D高斯泼溅表示，支持有姿态和无姿态、有标定和无标定的输入。


<details>
  <summary>Details</summary>
Motivation: 解决从无结构图像集合中进行快速灵活3D场景重建的挑战，特别是处理姿态和标定信息不完整的情况。

Method: 采用混合训练策略，预测局部高斯和相机姿态，通过成对相机距离归一化方案解决尺度模糊问题，并嵌入相机内参到网络中。

Result: 在NVIDIA GH200 GPU上仅需2.69秒即可从100张视图重建场景，在标准基准测试中达到最先进性能。

Conclusion: YoNoSplat展示了高效且灵活的三维重建能力，为无结构图像的三维重建提供了实用解决方案。

Abstract: Fast and flexible 3D scene reconstruction from unstructured image collections
remains a significant challenge. We present YoNoSplat, a feedforward model that
reconstructs high-quality 3D Gaussian Splatting representations from an
arbitrary number of images. Our model is highly versatile, operating
effectively with both posed and unposed, calibrated and uncalibrated inputs.
YoNoSplat predicts local Gaussians and camera poses for each view, which are
aggregated into a global representation using either predicted or provided
poses. To overcome the inherent difficulty of jointly learning 3D Gaussians and
camera parameters, we introduce a novel mixing training strategy. This approach
mitigates the entanglement between the two tasks by initially using
ground-truth poses to aggregate local Gaussians and gradually transitioning to
a mix of predicted and ground-truth poses, which prevents both training
instability and exposure bias. We further resolve the scale ambiguity problem
by a novel pairwise camera-distance normalization scheme and by embedding
camera intrinsics into the network. Moreover, YoNoSplat also predicts intrinsic
parameters, making it feasible for uncalibrated inputs. YoNoSplat demonstrates
exceptional efficiency, reconstructing a scene from 100 views (at 280x518
resolution) in just 2.69 seconds on an NVIDIA GH200 GPU. It achieves
state-of-the-art performance on standard benchmarks in both pose-free and
pose-dependent settings. Our project page is at
https://botaoye.github.io/yonosplat/.

</details>


### [213] [Garbage Vulnerable Point Monitoring using IoT and Computer Vision](https://arxiv.org/abs/2511.07325)
*R. Kumar,A. Lall,S. Chaudhari,M. Kale,A. Vattem*

Main category: cs.CV

TL;DR: 提出一种基于物联网和计算机视觉的智能城市固体废物管理系统，用于监控垃圾易发点的非法倾倒行为。通过街景摄像头和物体检测算法快速检测和监控倾倒的垃圾，并在印度Sangareddy地区进行了实验验证。


<details>
  <summary>Details</summary>
Motivation: 解决城市地区非法垃圾倾倒问题，提高垃圾管理的效率和监控能力，特别是在垃圾易发点（GVPs）进行全天候监测。

Method: 使用物联网（IoT）和计算机视觉（CV）技术，结合街景摄像头和物体检测算法（包括YOLOv8、YOLOv10、YOLO11m和RT-DETR）来检测和监控垃圾倾倒。

Result: YOLO11m模型在垃圾检测中达到最高准确率92.39%，mAP@50为0.91，能够有效捕捉垃圾倾倒的小时、每日和每周模式，实现全天候监控。

Conclusion: 物体检测模型非常适合用于监控和跟踪垃圾易发点的倾倒事件，系统能够全面捕捉垃圾处理模式，确保日常和夜间监控的有效性。

Abstract: This paper proposes a smart way to manage municipal solid waste by using the
Internet of Things (IoT) and computer vision (CV) to monitor illegal waste
dumping at garbage vulnerable points (GVPs) in urban areas. The system can
quickly detect and monitor dumped waste using a street-level camera and object
detection algorithm. Data was collected from the Sangareddy district in
Telangana, India. A series of comprehensive experiments was carried out using
the proposed dataset to assess the accuracy and overall performance of various
object detection models. Specifically, we performed an in-depth evaluation of
YOLOv8, YOLOv10, YOLO11m, and RT-DETR on our dataset. Among these models,
YOLO11m achieved the highest accuracy of 92.39\% in waste detection,
demonstrating its effectiveness in detecting waste. Additionally, it attains an
mAP@50 of 0.91, highlighting its high precision. These findings confirm that
the object detection model is well-suited for monitoring and tracking waste
dumping events at GVP locations. Furthermore, the system effectively captures
waste disposal patterns, including hourly, daily, and weekly dumping trends,
ensuring comprehensive daily and nightly monitoring.

</details>


### [214] [Inference-Time Scaling of Diffusion Models for Infrared Data Generation](https://arxiv.org/abs/2511.07362)
*Kai A. Horstmann,Maxim Clouser,Kia Khezeli*

Main category: cs.CV

TL;DR: 本文提出了一种基于推理时缩放的方法，使用领域适应的CLIP验证器来提升红外图像生成质量，通过微调FLUX.1-dev模型在红外图像上，并在推理时使用验证器引导扩散采样过程。


<details>
  <summary>Details</summary>
Motivation: 红外图像在低能见度条件下具有优势，但高质量标注数据稀缺，限制了红外视觉模型的发展。合成红外图像生成面临数据有限的问题，难以训练基础级生成扩散模型。

Method: 采用参数高效技术在小样本红外图像上微调FLUX.1-dev文本到图像扩散模型，训练领域适应的CLIP验证器，在推理时使用验证器引导扩散采样过程，提升生成质量与文本提示的对齐度。

Result: 实验表明该方法在KAIST多光谱行人检测基准数据集上，相比无引导基线样本，FID分数降低了10%，生成质量得到一致提升。

Conclusion: 推理时引导为在低数据红外设置中弥合领域差距提供了有前景的方向。

Abstract: Infrared imagery enables temperature-based scene understanding using passive
sensors, particularly under conditions of low visibility where traditional RGB
imaging fails. Yet, developing downstream vision models for infrared
applications is hindered by the scarcity of high-quality annotated data, due to
the specialized expertise required for infrared annotation. While synthetic
infrared image generation has the potential to accelerate model development by
providing large-scale, diverse training data, training foundation-level
generative diffusion models in the infrared domain has remained elusive due to
limited datasets. In light of such data constraints, we explore an
inference-time scaling approach using a domain-adapted CLIP-based verifier for
enhanced infrared image generation quality. We adapt FLUX.1-dev, a
state-of-the-art text-to-image diffusion model, to the infrared domain by
finetuning it on a small sample of infrared images using parameter-efficient
techniques. The trained verifier is then employed during inference to guide the
diffusion sampling process toward higher quality infrared generations that
better align with input text prompts. Empirically, we find that our approach
leads to consistent improvements in generation quality, reducing FID scores on
the KAIST Multispectral Pedestrian Detection Benchmark dataset by 10% compared
to unguided baseline samples. Our results suggest that inference-time guidance
offers a promising direction for bridging the domain gap in low-data infrared
settings.

</details>


### [215] [StreamDiffusionV2: A Streaming System for Dynamic and Interactive Video Generation](https://arxiv.org/abs/2511.07399)
*Tianrui Feng,Zhi Li,Shuo Yang,Haocheng Xi,Muyang Li,Xiuyu Li,Lvmin Zhang,Keting Yang,Kelly Peng,Song Han,Maneesh Agrawala,Kurt Keutzer,Akio Kodaira,Chenfeng Xu*

Main category: cs.CV

TL;DR: StreamDiffusionV2是一个面向实时视频流生成的训练无关流水线系统，通过SLO感知的批处理调度、块调度、滚动KV缓存等技术，在保证低延迟的同时实现高帧率生成。


<details>
  <summary>Details</summary>
Motivation: 现有图像扩散模型在实时流媒体中存在时间一致性不足的问题，而离线视频生成系统无法满足直播场景对首帧时间和每帧截止时间的严格SLO要求。

Method: 集成SLO感知批处理调度器和块调度器，采用sink-token引导的滚动KV缓存、运动感知噪声控制器等系统级优化，并通过可扩展的流水线编排实现跨去噪步骤和网络层的并行化。

Result: 在4个H100 GPU上，14B参数模型达到58.28 FPS，1.3B参数模型达到64.52 FPS，首帧渲染时间小于0.5秒，支持1-4步去噪的灵活配置。

Conclusion: StreamDiffusionV2使最先进的生成式直播变得实用且可扩展，从个人创作者到企业级平台都能受益。

Abstract: Generative models are reshaping the live-streaming industry by redefining how
content is created, styled, and delivered. Previous image-based streaming
diffusion models have powered efficient and creative live streaming products
but have hit limits on temporal consistency due to the foundation of
image-based designs. Recent advances in video diffusion have markedly improved
temporal consistency and sampling efficiency for offline generation. However,
offline generation systems primarily optimize throughput by batching large
workloads. In contrast, live online streaming operates under strict
service-level objectives (SLOs): time-to-first-frame must be minimal, and every
frame must meet a per-frame deadline with low jitter. Besides, scalable
multi-GPU serving for real-time streams remains largely unresolved so far. To
address this, we present StreamDiffusionV2, a training-free pipeline for
interactive live streaming with video diffusion models. StreamDiffusionV2
integrates an SLO-aware batching scheduler and a block scheduler, together with
a sink-token--guided rolling KV cache, a motion-aware noise controller, and
other system-level optimizations. Moreover, we introduce a scalable pipeline
orchestration that parallelizes the diffusion process across denoising steps
and network layers, achieving near-linear FPS scaling without violating latency
guarantees. The system scales seamlessly across heterogeneous GPU environments
and supports flexible denoising steps (e.g., 1--4), enabling both
ultra-low-latency and higher-quality modes. Without TensorRT or quantization,
StreamDiffusionV2 renders the first frame within 0.5s and attains 58.28 FPS
with a 14B-parameter model and 64.52 FPS with a 1.3B-parameter model on four
H100 GPUs, making state-of-the-art generative live streaming practical and
accessible--from individual creators to enterprise-scale platforms.

</details>


### [216] [SpatialThinker: Reinforcing 3D Reasoning in Multimodal LLMs via Spatial Rewards](https://arxiv.org/abs/2511.07403)
*Hunar Batra,Haoqin Tu,Hardy Chen,Yuanze Lin,Cihang Xie,Ronald Clark*

Main category: cs.CV

TL;DR: SpatialThinker是一个3D感知的多模态大语言模型，通过强化学习结合结构化空间基础和多步推理来解决MLLMs在空间理解方面的局限性，在空间理解和真实世界VQA基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的空间MLLMs依赖显式3D输入或特定架构修改，且受限于大规模数据集或稀疏监督，在空间理解方面仍有困难。

Method: 提出SpatialThinker模型，包含两个关键贡献：(1)生成高质量空间VQA数据集STVQA-7K的数据合成管道；(2)使用多目标密集空间奖励的在线强化学习来强化空间基础。模型通过构建任务相关对象和空间关系的场景图，模拟人类空间感知。

Result: SpatialThinker-7B在空间理解和真实世界VQA基准测试中优于监督微调和稀疏RL基线，相比稀疏RL几乎将基础模型增益翻倍，并超越了GPT-4o。

Conclusion: 结果表明，将空间监督与奖励对齐推理相结合，能够在有限数据下实现鲁棒的3D空间理解，推动MLLMs向人类水平的视觉推理迈进。

Abstract: Multimodal large language models (MLLMs) have achieved remarkable progress in
vision-language tasks, but they continue to struggle with spatial
understanding. Existing spatial MLLMs often rely on explicit 3D inputs or
architecture-specific modifications, and remain constrained by large-scale
datasets or sparse supervision. To address these limitations, we introduce
SpatialThinker, a 3D-aware MLLM trained with RL to integrate structured spatial
grounding with multi-step reasoning. The model simulates human-like spatial
perception by constructing a scene graph of task-relevant objects and spatial
relations, and reasoning towards an answer via dense spatial rewards.
SpatialThinker consists of two key contributions: (1) a data synthesis pipeline
that generates STVQA-7K, a high-quality spatial VQA dataset, and (2) online RL
with a multi-objective dense spatial reward enforcing spatial grounding.
SpatialThinker-7B outperforms supervised fine-tuning and the sparse RL baseline
on spatial understanding and real-world VQA benchmarks, nearly doubling the
base-model gain compared to sparse RL, and surpassing GPT-4o. These results
showcase the effectiveness of combining spatial supervision with reward-aligned
reasoning in enabling robust 3D spatial understanding with limited data and
advancing MLLMs towards human-level visual reasoning.

</details>


### [217] [DIMO: Diverse 3D Motion Generation for Arbitrary Objects](https://arxiv.org/abs/2511.07409)
*Linzhan Mou,Jiahui Lei,Chen Wang,Lingjie Liu,Kostas Daniilidis*

Main category: cs.CV

TL;DR: DIMO是一种从单张图像生成任意物体多样化3D运动的生成方法，通过利用视频模型的先验知识提取运动模式并嵌入到共享低维潜在空间。


<details>
  <summary>Details</summary>
Motivation: 解决从单张图像生成多样化3D运动的挑战，利用预训练视频模型的丰富先验知识来提取通用运动模式。

Method: 首先生成具有多样化运动的多个视频，将每个运动嵌入到潜在向量中，训练共享运动解码器学习由神经关键点轨迹表示的运动分布，然后使用3D高斯模型驱动关键点。

Result: 能够在推理时通过单次前向传播即时采样多样化3D运动，支持3D运动插值和语言引导的运动生成等应用。

Conclusion: DIMO提供了一种有效的框架，能够从单张图像生成高质量且多样化的3D运动，展示了在3D运动生成领域的潜力。

Abstract: We present DIMO, a generative approach capable of generating diverse 3D
motions for arbitrary objects from a single image. The core idea of our work is
to leverage the rich priors in well-trained video models to extract the common
motion patterns and then embed them into a shared low-dimensional latent space.
Specifically, we first generate multiple videos of the same object with diverse
motions. We then embed each motion into a latent vector and train a shared
motion decoder to learn the distribution of motions represented by a structured
and compact motion representation, i.e., neural key point trajectories. The
canonical 3D Gaussians are then driven by these key points and fused to model
the geometry and appearance. During inference time with learned latent space,
we can instantly sample diverse 3D motions in a single-forward pass and support
several interesting applications including 3D motion interpolation and
language-guided motion generation. Our project page is available at
https://linzhanm.github.io/dimo.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [218] [AGRAG: Advanced Graph-based Retrieval-Augmented Generation for LLMs](https://arxiv.org/abs/2511.05549)
*Yubo Wang,Haoyang Li,Fei Teng,Lei Chen*

Main category: cs.LG

TL;DR: AGRAG是一个先进的基于图的检索增强生成框架，通过统计方法构建图避免LLM幻觉，使用MCMI子图生成问题提高推理能力，并支持复杂图结构提升推理路径的全面性。


<details>
  <summary>Details</summary>
Motivation: 现有基于图的RAG方法面临三个关键挑战：LLM幻觉导致图构建不准确、缺乏显式推理路径导致推理能力差、LLM推理不足导致回答不充分，使得某些任务上性能落后于NaiveRAG。

Method: AGRAG使用统计方法替代LLM实体提取来构建图，将图推理过程建模为最小成本最大影响力子图生成问题，提出贪心算法求解，生成的MCMI子图作为显式推理路径。

Result: AGRAG能够避免LLM幻觉和错误传播，生成更全面的推理路径，支持复杂图结构如循环，提高LLM对查询相关内容的关注度，减少噪声影响。

Conclusion: AGRAG通过改进图构建和推理路径生成，有效解决了现有图基RAG方法的三个关键挑战，提升了推理能力和回答质量。

Abstract: Graph-based retrieval-augmented generation (Graph-based RAG) has demonstrated
significant potential in enhancing Large Language Models (LLMs) with structured
knowledge. However, existing methods face three critical challenges: Inaccurate
Graph Construction, caused by LLM hallucination; Poor Reasoning Ability, caused
by failing to generate explicit reasons telling LLM why certain chunks were
selected; and Inadequate Answering, which only partially answers the query due
to the inadequate LLM reasoning, making their performance lag behind NaiveRAG
on certain tasks. To address these issues, we propose AGRAG, an advanced
graph-based retrieval-augmented generation framework. When constructing the
graph, AGRAG substitutes the widely used LLM entity extraction method with a
statistics-based method, avoiding hallucination and error propagation. When
retrieval, AGRAG formulates the graph reasoning procedure as the Minimum Cost
Maximum Influence (MCMI) subgraph generation problem, where we try to include
more nodes with high influence score, but with less involving edge cost, to
make the generated reasoning paths more comprehensive. We prove this problem to
be NP-hard, and propose a greedy algorithm to solve it. The MCMI subgraph
generated can serve as explicit reasoning paths to tell LLM why certain chunks
were retrieved, thereby making the LLM better focus on the query-related part
contents of the chunks, reducing the impact of noise, and improving AGRAG's
reasoning ability. Furthermore, compared with the simple tree-structured
reasoning paths, our MCMI subgraph can allow more complex graph structures,
such as cycles, and improve the comprehensiveness of the generated reasoning
paths.

</details>


### [219] [Deep one-gate per layer networks with skip connections are universal classifiers](https://arxiv.org/abs/2511.05552)
*Raul Rojas*

Main category: cs.LG

TL;DR: 将双层隐藏层的多层感知机转换为带门控层和跳跃连接的深度神经网络


<details>
  <summary>Details</summary>
Motivation: 探索如何将简单的多层感知机结构转换为更复杂的深度神经网络架构

Method: 通过添加门控层和跳跃连接，将双层隐藏层的多层感知机转换为深度神经网络

Result: 成功实现了从简单网络到复杂深度网络的转换

Conclusion: 这种转换方法为神经网络架构设计提供了新的思路

Abstract: This paper shows how a multilayer perceptron with two hidden layers, which
has been designed to classify two classes of data points, can easily be
transformed into a deep neural network with one-gate layers and skip
connections.

</details>


### [220] [Daily Forecasting for Annual Time Series Datasets Using Similarity-Based Machine Learning Methods: A Case Study in the Energy Market](https://arxiv.org/abs/2511.05556)
*Mahdi Goldani*

Main category: cs.LG

TL;DR: 该研究提出了一个能源安全指数的每日代理指标，通过时间序列相似性度量和机器学习方法实现15天前的高频预测，以解决年度指数响应滞后的问题。


<details>
  <summary>Details</summary>
Motivation: 政策环境快速变化影响能源安全指数等宏观指标，但该指数仅年度报告，限制了其对短期波动的响应能力。

Method: 采用两阶段方法：首先应用六种时间序列相似性度量从关键能源相关变量中识别合适的每日代理指标，然后使用XGBoost算法建模生成15天前预测。

Result: 布伦特原油交易量被确定为最合适的代理指标，模型表现优异（训练集R²=0.981，测试集R²=0.945），15天预测显示短期波动模式。

Conclusion: 该研究提供了一个将低频宏观经济指标转化为高频可操作信号的新框架，为决策者提供实时监测工具，特别适用于数据稀缺环境。

Abstract: The policy environment of countries changes rapidly, influencing macro-level
indicators such as the Energy Security Index. However, this index is only
reported annually, limiting its responsiveness to short-term fluctuations. To
address this gap, the present study introduces a daily proxy for the Energy
Security Index and applies it to forecast energy security at a daily
frequency.The study employs a two stage approach first, a suitable daily proxy
for the annual Energy Security Index is identified by applying six time series
similarity measures to key energy related variables. Second, the selected proxy
is modeled using the XGBoost algorithm to generate 15 day ahead forecasts,
enabling high frequency monitoring of energy security dynamics.As the result of
proxy choosing, Volume Brent consistently emerged as the most suitable proxy
across the majority of methods. The model demonstrated strong performance, with
an R squared of 0.981 on the training set and 0.945 on the test set, and
acceptable error metrics . The 15 day forecast of Brent volume indicates short
term fluctuations, with a peak around day 4, a decline until day 8, a rise near
day 10, and a downward trend toward day 15, accompanied by prediction
intervals.By integrating time series similarity measures with machine learning
based forecasting, this study provides a novel framework for converting low
frequency macroeconomic indicators into high frequency, actionable signals. The
approach enables real time monitoring of the Energy Security Index, offering
policymakers and analysts a scalable and practical tool to respond more rapidly
to fast changing policy and market conditions, especially in data scarce
environments.

</details>


### [221] [Diversified Flow Matching with Translation Identifiability](https://arxiv.org/abs/2511.05558)
*Sagar Shrestha,Xiao Fu*

Main category: cs.LG

TL;DR: 本文提出了多样化流匹配（DFM），一种基于ODE的框架，用于解决DDM在GAN实现中的不稳定性和缺乏轨迹信息的问题。


<details>
  <summary>Details</summary>
Motivation: DDM虽然能解决无配对域翻译中的内容对齐问题，但仅通过GAN实现，存在训练不稳定且无法提供传输轨迹信息的局限性。

Method: 通过定制化的双层优化训练损失、非线性插值和结构重构，将流匹配（FM）适应于DDM的统一翻译函数要求。

Result: 在合成和真实数据集上的实验验证了所提方法的有效性。

Conclusion: DFM是首个基于ODE且保证翻译可识别性的方法，为单细胞进化分析和机器人路径规划等应用提供了有用的轨迹信息。

Abstract: Diversified distribution matching (DDM) finds a unified translation function
mapping a diverse collection of conditional source distributions to their
target counterparts. DDM was proposed to resolve content misalignment issues in
unpaired domain translation, achieving translation identifiability. However,
DDM has only been implemented using GANs due to its constraints on the
translation function. GANs are often unstable to train and do not provide the
transport trajectory information -- yet such trajectories are useful in
applications such as single-cell evolution analysis and robot route planning.
This work introduces diversified flow matching (DFM), an ODE-based framework
for DDM. Adapting flow matching (FM) to enforce a unified translation function
as in DDM is challenging, as FM learns the translation function's velocity
rather than the translation function itself. A custom bilevel
optimization-based training loss, a nonlinear interpolant, and a structural
reformulation are proposed to address these challenges, offering a tangible
implementation. To our knowledge, DFM is the first ODE-based approach
guaranteeing translation identifiability. Experiments on synthetic and
real-world datasets validate the proposed method.

</details>


### [222] [Effective Test-Time Scaling of Discrete Diffusion through Iterative Refinement](https://arxiv.org/abs/2511.05562)
*Sanghyun Lee,Sunwoo Kim,Seungryong Kim,Jongho Park,Dongmin Park*

Main category: cs.LG

TL;DR: 提出了Iterative Reward-Guided Refinement (IterRef)方法，一种针对离散扩散模型的测试时缩放技术，通过奖励引导的噪声-去噪转换逐步优化未对齐的中间状态


<details>
  <summary>Details</summary>
Motivation: 测试时缩放通过奖励引导生成在离散扩散模型中尚未充分探索，但具有作为有前景替代方案的潜力

Method: 将过程形式化为Multiple-Try Metropolis (MTM)框架，利用奖励引导的噪声-去噪转换逐步优化中间状态，不同于先前方法假设当前状态已对齐奖励分布

Result: 在文本和图像领域的多种离散扩散模型上评估，观察到奖励引导生成质量的持续改进，特别是在低计算预算下取得显著提升

Conclusion: IterRef方法在离散扩散模型的奖励引导生成方面表现出色，明显优于现有最先进基线方法

Abstract: Test-time scaling through reward-guided generation remains largely unexplored
for discrete diffusion models despite its potential as a promising alternative.
In this work, we introduce Iterative Reward-Guided Refinement (IterRef), a
novel test-time scaling method tailored to discrete diffusion that leverages
reward- guided noising-denoising transitions to progressively refine misaligned
intermediate states. We formalize this process within a Multiple-Try Metropolis
(MTM) framework, proving convergence to the reward-aligned distribution. Unlike
prior methods that assume the current state is already aligned with the reward
distribution and only guide the subsequent transition, our approach explicitly
refines each state in situ, progressively steering it toward the optimal
intermediate distribution. Across both text and image domains, we evaluate
IterRef on diverse discrete diffusion models and observe consistent
improvements in reward-guided generation quality. In particular, IterRef
achieves striking gains under low compute budgets, far surpassing prior
state-of-the-art baselines.

</details>


### [223] [Lookahead Unmasking Elicits Accurate Decoding in Diffusion Language Models](https://arxiv.org/abs/2511.05563)
*Sanghyun Lee,Seungryong Kim,Jongho Park,Dongmin Park*

Main category: cs.LG

TL;DR: 提出了Lookahead Unmasking (LookUM)方法，通过路径生成和验证来优化掩码扩散模型的解码顺序，在数学、规划和编程等任务上实现性能提升


<details>
  <summary>Details</summary>
Motivation: 现有基于置信度的采样方法存在短视问题，无法利用额外计算资源，且早期解码错误会级联传播，需要更智能的路径选择策略

Method: 将采样重新定义为路径选择问题，包含路径生成器（从解掩码集合池中采样路径）和验证器（计算路径不确定性并进行重要性采样）

Result: 在六个基准测试中实现一致性能提升，仅需2-3条路径即可达到峰值性能，LLaDA+LookUM可与RL调优的LLaDA 1.5相媲美

Conclusion: 基于不确定性的验证为强化学习提供正交收益，证明了该框架的通用性

Abstract: Masked Diffusion Models (MDMs) as language models generate by iteratively
unmasking tokens, yet their performance crucially depends on the inference time
order of unmasking. Prevailing heuristics, such as confidence based sampling,
are myopic: they optimize locally, fail to leverage extra test-time compute,
and let early decoding mistakes cascade. We propose Lookahead Unmasking
(LookUM), which addresses these concerns by reformulating sampling as path
selection over all possible unmasking orders without the need for an external
reward model. Our framework couples (i) a path generator that proposes paths by
sampling from pools of unmasking sets with (ii) a verifier that computes the
uncertainty of the proposed paths and performs importance sampling to
subsequently select the final paths. Empirically, erroneous unmasking
measurably inflates sequence level uncertainty, and our method exploits this to
avoid error-prone trajectories. We validate our framework across six
benchmarks, such as mathematics, planning, and coding, and demonstrate
consistent performance improvements. LookUM requires only two to three paths to
achieve peak performance, demonstrating remarkably efficient path selection.
The consistent improvements on both LLaDA and post-trained LLaDA 1.5 are
particularly striking: base LLaDA with LookUM rivals the performance of
RL-tuned LLaDA 1.5, while LookUM further enhances LLaDA 1.5 itself showing that
uncertainty based verification provides orthogonal benefits to reinforcement
learning and underscoring the versatility of our framework. Code will be
publicly released.

</details>


### [224] [Adaptive Sample-Level Framework Motivated by Distributionally Robust Optimization with Variance-Based Radius Assignment for Enhanced Neural Network Generalization Under Distribution Shift](https://arxiv.org/abs/2511.05568)
*Aheer Sravon,Devdyuti Mazumder,Md. Ibrahim*

Main category: cs.LG

TL;DR: 提出了Var-DRO框架，通过自适应样本级鲁棒性预算分配解决传统DRO方法全局鲁棒性预算导致的过度保守或资源分配不当问题。


<details>
  <summary>Details</summary>
Motivation: 传统分布鲁棒优化方法依赖单一全局鲁棒性预算，这会导致模型过于保守或鲁棒性资源分配不当，无法有效应对分布偏移和少数子群体问题。

Method: 基于在线损失方差自动识别高风险训练样本，为每个样本分配个性化鲁棒性预算；使用KL散度风格的双边约束构建凸多面体优化问题，采用高效的水填充算法求解；引入预热阶段和线性增长调度策略稳定训练。

Result: 在CIFAR-10-C上达到最高平均准确率；在Waterbirds上提升整体性能；在原始CIFAR-10上保持竞争力，体现了鲁棒性优先的适度权衡。

Conclusion: Var-DRO框架无需组标签、易于实现、理论可靠且计算高效，能够有效提升模型在分布偏移和少数子群体场景下的鲁棒性。

Abstract: Distribution shifts and minority subpopulations frequently undermine the
reliability of deep neural networks trained using Empirical Risk Minimization
(ERM). Distributionally Robust Optimization (DRO) addresses this by optimizing
for the worst-case risk within a neighborhood of the training distribution.
However, conventional methods depend on a single, global robustness budget,
which can lead to overly conservative models or a misallocation of robustness.
We propose a variance-driven, adaptive, sample-level DRO (Var-DRO) framework
that automatically identifies high-risk training samples and assigns a
personalized robustness budget to each based on its online loss variance. Our
formulation employs two-sided, KL-divergence-style bounds to constrain the
ratio between adversarial and empirical weights for every sample. This results
in a linear inner maximization problem over a convex polytope, which admits an
efficient water-filling solution. To stabilize training, we introduce a warmup
phase and a linear ramp schedule for the global cap on per-sample budgets,
complemented by label smoothing for numerical robustness. Evaluated on
CIFAR-10-C (corruptions), our method achieves the highest overall mean accuracy
compared to ERM and KL-DRO. On Waterbirds, Var-DRO improves overall performance
while matching or surpassing KL-DRO. On the original CIFAR-10 dataset, Var-DRO
remains competitive, exhibiting the modest trade-off anticipated when
prioritizing robustness. The proposed framework is unsupervised (requiring no
group labels), straightforward to implement, theoretically sound, and
computationally efficient.

</details>


### [225] [Data-driven jet fuel demand forecasting: A case study of Copenhagen Airport](https://arxiv.org/abs/2511.05569)
*Alessandro Contini,Davide Cacciarelli,Murat Kulahci*

Main category: cs.LG

TL;DR: 本文评估了机器学习模型在航空燃油需求预测中的表现，比较了传统时间序列模型、Prophet、LSTM序列到序列神经网络和混合模型，使用丹麦主要航空燃油分销商的大量数据进行分析。


<details>
  <summary>Details</summary>
Motivation: 航空燃油需求的准确预测对优化航空市场供应链运营至关重要，但目前缺乏使用机器学习模型分析该问题的研究，行业从业者多依赖确定性或基于经验的模型。

Method: 使用丹麦主要航空燃油分销商的大量数据，比较传统时间序列模型、Prophet、LSTM序列到序列神经网络和混合模型的预测能力，分析三个不同数据集以确保可靠性。

Result: 研究展示了数据驱动模型在燃油需求预测中的优势，并强调了在预测模型中纳入额外变量的影响。

Conclusion: 本研究为航空燃油需求预测提供了一个全面的案例研究，证明了采用数据驱动模型的优势，并为从业者提供了有价值的见解。

Abstract: Accurate forecasting of jet fuel demand is crucial for optimizing supply
chain operations in the aviation market. Fuel distributors specifically require
precise estimates to avoid inventory shortages or excesses. However, there is a
lack of studies that analyze the jet fuel demand forecasting problem using
machine learning models. Instead, many industry practitioners rely on
deterministic or expertise-based models. In this research, we evaluate the
performance of data-driven approaches using a substantial amount of data
obtained from a major aviation fuel distributor in the Danish market. Our
analysis compares the predictive capabilities of traditional time series
models, Prophet, LSTM sequence-to-sequence neural networks, and hybrid models.
A key challenge in developing these models is the required forecasting horizon,
as fuel demand needs to be predicted for the next 30 days to optimize sourcing
strategies. To ensure the reliability of the data-driven approaches and provide
valuable insights to practitioners, we analyze three different datasets. The
primary objective of this study is to present a comprehensive case study on jet
fuel demand forecasting, demonstrating the advantages of employing data-driven
models and highlighting the impact of incorporating additional variables in the
predictive models.

</details>


### [226] [Fine-Tuning Vision-Language Models for Multimodal Polymer Property Prediction](https://arxiv.org/abs/2511.05577)
*An Vuong,Minh-Hao Van,Prateek Verma,Chen Zhao,Xintao Wu*

Main category: cs.LG

TL;DR: 本文通过指令微调视觉语言模型，构建了一个多模态聚合物数据集，用于聚合物属性预测，证明了多模态学习的优势。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在科学领域（如材料科学）的有效性有限，缺乏针对聚合物属性预测等多模态任务的基座模型。

Method: 使用LoRA方法对视觉语言模型进行指令微调，利用多模态聚合物数据集进行训练。

Result: 微调后的模型在性能上优于单模态和基线方法，展示了多模态学习的益处。

Conclusion: 该方法减少了对不同属性训练单独模型的需求，降低了部署和维护成本。

Abstract: Vision-Language Models (VLMs) have shown strong performance in tasks like
visual question answering and multimodal text generation, but their
effectiveness in scientific domains such as materials science remains limited.
While some machine learning methods have addressed specific challenges in this
field, there is still a lack of foundation models designed for broad tasks like
polymer property prediction using multimodal data. In this work, we present a
multimodal polymer dataset to fine-tune VLMs through instruction-tuning pairs
and assess the impact of multimodality on prediction performance. Our
fine-tuned models, using LoRA, outperform unimodal and baseline approaches,
demonstrating the benefits of multimodal learning. Additionally, this approach
reduces the need to train separate models for different properties, lowering
deployment and maintenance costs.

</details>


### [227] [Distillation-Accelerated Uncertainty Modeling for Multi-Objective RTA Interception](https://arxiv.org/abs/2511.05582)
*Gaoxiang Zhao,Ruina Qiu,Pengpeng Zhao,Rongjin Wang,Zhangang Lin,Xiaoqiang Wang*

Main category: cs.LG

TL;DR: DAUM是一个联合建模框架，通过集成多目标学习和不确定性建模来解决实时竞价拦截中的两个关键挑战：准确估计流量质量和降低不确定性建模的计算开销。


<details>
  <summary>Details</summary>
Motivation: 实时竞价拦截需要过滤无效或不相关流量以提高下游数据的完整性和可靠性，但面临准确估计流量质量（需要不确定性建模）和实时应用中重复推理导致的效率瓶颈这两个挑战。

Method: 提出DAUM框架，集成多目标学习和不确定性建模，同时获得流量质量预测和可靠的置信度估计。在此基础上应用知识蒸馏来降低不确定性建模的计算开销，同时保持预测准确性和不确定性估计的优势。

Result: 在JD广告数据集上的实验表明，DAUM持续提高了预测性能，蒸馏后的模型实现了推理速度的十倍提升。

Conclusion: DAUM框架有效解决了实时竞价拦截中的质量和效率平衡问题，通过知识蒸馏技术在不牺牲准确性的前提下显著提升了推理效率。

Abstract: Real-Time Auction (RTA) Interception aims to filter out invalid or irrelevant
traffic to enhance the integrity and reliability of downstream data. However,
two key challenges remain: (i) the need for accurate estimation of traffic
quality together with sufficiently high confidence in the model's predictions,
typically addressed through uncertainty modeling, and (ii) the efficiency
bottlenecks that such uncertainty modeling introduces in real-time applications
due to repeated inference. To address these challenges, we propose DAUM, a
joint modeling framework that integrates multi-objective learning with
uncertainty modeling, yielding both traffic quality predictions and reliable
confidence estimates. Building on DAUM, we further apply knowledge distillation
to reduce the computational overhead of uncertainty modeling, while largely
preserving predictive accuracy and retaining the benefits of uncertainty
estimation. Experiments on the JD advertisement dataset demonstrate that DAUM
consistently improves predictive performance, with the distilled model
delivering a tenfold increase in inference speed.

</details>


### [228] [Depth-induced NTK: Bridging Over-parameterized Neural Networks and Deep Neural Kernels](https://arxiv.org/abs/2511.05585)
*Yong-Ming Tian,Shuang Liang,Shao-Qun Zhang,Feng-Lei Fan*

Main category: cs.LG

TL;DR: 提出了基于快捷连接架构的深度诱导神经正切核，该核在网络深度趋于无穷时收敛到高斯过程，理论上分析了其训练不变性和谱特性，扩展了神经核理论并深化了对深度学习和缩放定律的理解。


<details>
  <summary>Details</summary>
Motivation: 现有神经正切核主要局限于无限宽度机制，忽视了网络深度的表示作用，需要填补这一理论空白。

Method: 基于快捷连接架构构建深度诱导神经正切核，理论分析其训练不变性和谱特性，通过实验验证方法有效性。

Result: 提出的深度诱导神经正切核能够稳定核动力学并缓解退化问题，实验结果表明该方法具有显著效果。

Conclusion: 该研究显著扩展了神经核理论的现有格局，为深度学习和缩放定律提供了深入理解。

Abstract: While deep learning has achieved remarkable success across a wide range of
applications, its theoretical understanding of representation learning remains
limited. Deep neural kernels provide a principled framework to interpret
over-parameterized neural networks by mapping hierarchical feature
transformations into kernel spaces, thereby combining the expressive power of
deep architectures with the analytical tractability of kernel methods. Recent
advances, particularly neural tangent kernels (NTKs) derived by gradient inner
products, have established connections between infinitely wide neural networks
and nonparametric Bayesian inference. However, the existing NTK paradigm has
been predominantly confined to the infinite-width regime, while overlooking the
representational role of network depth. To address this gap, we propose a
depth-induced NTK kernel based on a shortcut-related architecture, which
converges to a Gaussian process as the network depth approaches infinity. We
theoretically analyze the training invariance and spectrum properties of the
proposed kernel, which stabilizes the kernel dynamics and mitigates
degeneration. Experimental results further underscore the effectiveness of our
proposed method. Our findings significantly extend the existing landscape of
the neural kernel theory and provide an in-depth understanding of deep learning
and the scaling law.

</details>


### [229] [Prompting Neural-Guided Equation Discovery Based on Residuals](https://arxiv.org/abs/2511.05586)
*Jannis Brugger,Viktor Pfanschilling,David Richter,Mira Mezini,Stefan Kramer*

Main category: cs.LG

TL;DR: RED是一种后处理方法，通过分析初始方程的残差来改进方程发现系统输出的方程，无需大量搜索即可生成更好的方程建议。


<details>
  <summary>Details</summary>
Motivation: 现有神经引导方程发现系统在方程不符合用户期望时，缺乏有效方法获取其他方程建议，需要大量人工干预。

Method: 将初始方程解析为语法树，使用基于节点的计算规则计算每个子方程的残差，将残差作为新目标变量生成新提示，用更好的子方程替换原有子方程。

Result: 在Feynman基准测试的53个方程上，RED不仅改进了所有测试的神经引导系统，也改进了所有经典遗传编程系统。

Conclusion: RED是一种通用、快速且易于扩展的方法，可与任何方程发现系统配合使用，有效提升方程发现质量。

Abstract: Neural-guided equation discovery systems use a data set as prompt and predict
an equation that describes the data set without extensive search. However, if
the equation does not meet the user's expectations, there are few options for
getting other equation suggestions without intensive work with the system. To
fill this gap, we propose Residuals for Equation Discovery (RED), a
post-processing method that improves a given equation in a targeted manner,
based on its residuals. By parsing the initial equation to a syntax tree, we
can use node-based calculation rules to compute the residual for each
subequation of the initial equation. It is then possible to use this residual
as new target variable in the original data set and generate a new prompt. If,
with the new prompt, the equation discovery system suggests a subequation
better than the old subequation on a validation set, we replace the latter by
the former. RED is usable with any equation discovery system, is fast to
calculate, and is easy to extend for new mathematical operations. In
experiments on 53 equations from the Feynman benchmark, we show that it not
only helps to improve all tested neural-guided systems, but also all tested
classical genetic programming systems.

</details>


### [230] [CoPRIS: Efficient and Stable Reinforcement Learning via Concurrency-Controlled Partial Rollout with Importance Sampling](https://arxiv.org/abs/2511.05589)
*Zekai Qu,Yinxu Pan,Ao Sun,Chaojun Xiao,Xu Han*

Main category: cs.LG

TL;DR: CoPRIS提出了一种异步RL训练方法，通过控制并发rollout数量和重用未完成轨迹，解决了传统同步RL系统因长轨迹导致的效率低下问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM的RL训练系统采用完全同步方式，长轨迹会阻塞整个rollout过程，导致GPU资源闲置和训练效率低下。

Method: CoPRIS采用并发控制部分rollout和重要性采样：1）维持固定数量的并发rollout；2）收集足够样本后提前终止；3）重用未完成轨迹；4）使用跨阶段重要性采样校正来减少off-policy轨迹的影响。

Result: 在数学推理基准测试中，CoPRIS实现了最高1.94倍的训练加速，同时保持了与同步RL系统相当或更优的性能。

Conclusion: CoPRIS有效解决了RL训练中的长尾效率问题，显著提升了训练效率而不牺牲模型性能。

Abstract: Reinforcement learning (RL) post-training has become a trending paradigm for
enhancing the capabilities of large language models (LLMs). Most existing RL
systems for LLMs operate in a fully synchronous manner, where training must
wait for the rollout of an entire batch to complete. This design leads to
severe inefficiencies, as extremely long trajectories can stall the entire
rollout process and leave many GPUs idle. To address this issue, we propose
Concurrency- Controlled Partial Rollout with Importance Sampling (CoPRIS),
which mitigates long-tail inefficiencies by maintaining a fixed number of
concurrent rollouts, early-terminating once sufficient samples are collected,
and reusing unfinished trajectories in subsequent rollouts. To mitigate the
impact of off-policy trajectories, we introduce Cross-stage Importance Sampling
Correction, which concatenates buffered log probabilities from the previous
policy with those recomputed under the current policy for importance sampling
correction. Experiments on challenging mathematical reasoning benchmarks show
that CoPRIS achieves up to 1.94x faster training while maintaining comparable
or superior performance to synchronous RL systems. The code of CoPRIS is
available at https://github.com/777pomingzi/CoPRIS.

</details>


### [231] [FedSparQ: Adaptive Sparse Quantization with Error Feedback for Robust & Efficient Federated Learning](https://arxiv.org/abs/2511.05591)
*Chaimaa Medjadji,Sadi Alawadi,Feras M. Awaysheh,Guilain Leduc,Sylvain Kubler,Yves Le Traon*

Main category: cs.LG

TL;DR: FedSparQ是一个轻量级的联邦学习压缩框架，通过动态稀疏化、半精度量化和误差反馈来减少90%的通信开销，同时保持或提高模型精度。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在保护数据隐私的同时面临显著的通信开销问题，因为需要在受限网络上频繁交换高维模型更新。

Method: FedSparQ通过自适应阈值动态稀疏化每个客户端的梯度，对保留的条目应用半精度量化，并集成误差反馈来防止信息丢失。该方法无需手动调整稀疏率或量化计划，适应同质和异质数据分布，且与模型架构无关。

Result: 在IID和非IID数据下的视觉基准测试中，FedSparQ显著减少了通信开销（相比FedAvg减少90%的字节传输），同时保持或提高了模型精度（相比FedAvg或最先进的压缩模型提高6%），并增强了收敛鲁棒性（相比其他基线提高50%）。

Conclusion: FedSparQ为带宽受限的联邦学习部署提供了一个实用、易于部署的解决方案，并为未来自适应精度和隐私保护协议的扩展奠定了基础。

Abstract: Federated Learning (FL) enables collaborative model training across
decentralized clients while preserving data privacy by keeping raw data local.
However, FL suffers from significant communication overhead due to the frequent
exchange of high-dimensional model updates over constrained networks. In this
paper, we present FedSparQ, a lightweight compression framework that
dynamically sparsifies the gradient of each client through an adaptive
threshold, applies half-precision quanti- zation to retained entries and
integrates residuals from error feedback to prevent loss of information.
FedSparQ requires no manual tuning of sparsity rates or quantization schedules,
adapts seamlessly to both homogeneous and heterogeneous data distributions, and
is agnostic to model architecture. Through extensive empirical evaluation on
vision benchmarks under independent and identically distributed (IID) and
non-IID data, we show that FedSparQ substantially reduces communication
overhead (reducing by 90% of bytes sent compared to FedAvg) while preserving or
improving model accuracy (improving by 6% compared to FedAvg non-compressed
solution or to state-of-the- art compression models) and enhancing convergence
robustness (by 50%, compared to the other baselines). Our approach provides a
practical, easy-to-deploy solution for bandwidth- constrained federated
deployments and lays the groundwork for future extensions in adaptive precision
and privacy-preserving protocols.

</details>


### [232] [GRAVER: Generative Graph Vocabularies for Robust Graph Foundation Models Fine-tuning](https://arxiv.org/abs/2511.05592)
*Haonan Yuan,Qingyun Sun,Junhua Shi,Xingcheng Fu,Bryan Hooi,Jianxin Li,Philip S. Yu*

Main category: cs.LG

TL;DR: 提出GRAVER框架，通过生成式增强解决图基础模型在少样本微调中的不稳定性问题，提升跨领域知识迁移的鲁棒性和效率


<details>
  <summary>Details</summary>
Motivation: 现有图基础模型在少样本微调中存在性能波动大、适应效率低的问题，主要源于支持样本选择的随机性以及预训练图与目标图之间的结构差异

Method: 通过自我图解耦提取关键类特定子图模式，基于图相似度的通用任务模板构建图词汇表，利用轻量级MoE-CoE网络进行知识路由

Result: 在少样本节点和图分类任务上优于15个最先进基线方法，在效果、鲁棒性和效率方面表现出色

Conclusion: GRAVER框架通过生成式图词汇表实现了稳定高效的图基础模型微调，为跨领域知识迁移提供了可靠解决方案

Abstract: Inspired by the remarkable success of foundation models in language and
vision, Graph Foundation Models (GFMs) hold significant promise for broad
applicability across diverse graph tasks and domains. However, existing GFMs
struggle with unstable few-shot fine-tuning, where both performance and
adaptation efficiency exhibit significant fluctuations caused by the randomness
in the support sample selection and structural discrepancies between the
pre-trained and target graphs. How to fine-tune GFMs robustly and efficiently
to enable trustworthy knowledge transfer across domains and tasks is the major
challenge. In this paper, we propose GRAVER, a novel Generative gRAph
VocabulariEs for Robust GFM fine-tuning framework that tackles the
aforementioned instability via generative augmentations. Specifically, to
identify transferable units, we analyze and extract key class-specific subgraph
patterns by ego-graph disentanglement and validate their transferability both
theoretically and empirically. To enable effective pre-training across diverse
domains, we leverage a universal task template based on ego-graph similarity
and construct graph vocabularies via graphon-based generative experts. To
facilitate robust and efficient prompt fine-tuning, we grave the support
samples with in-context vocabularies, where the lightweight MoE-CoE network
attentively routes knowledge from source domains. Extensive experiments
demonstrate the superiority of GRAVER over effectiveness, robustness, and
efficiency on downstream few-shot node and graph classification tasks compared
with 15 state-of-the-art baselines.

</details>


### [233] [Gradient Projection onto Historical Descent Directions for Communication-Efficient Federated Learning](https://arxiv.org/abs/2511.05593)
*Arnaud Descours,Léonard Deroose,Jan Ramon*

Main category: cs.LG

TL;DR: 提出了ProjFL和ProjFL+EF两种联邦学习算法，通过将本地梯度投影到历史下降方向张成的共享子空间，显著降低通信开销，同时保持模型精度。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中通信效率是主要瓶颈，特别是对于大规模模型，需要设计高效的通信压缩方法。

Method: ProjFL用于无偏压缩器，ProjFL+EF通过误差反馈机制适用于有偏压缩器，两种方法都基于将本地梯度投影到客户端-服务器共享子空间。

Result: 在标准联邦学习分类基准测试中，两种算法在保持与现有基线相当精度的同时，显著降低了通信成本。

Conclusion: 提出的投影方法有效解决了联邦学习的通信效率问题，在强凸、凸和非凸设置下都具有收敛保证。

Abstract: Federated Learning (FL) enables decentralized model training across multiple
clients while optionally preserving data privacy. However, communication
efficiency remains a critical bottleneck, particularly for large-scale models.
In this work, we introduce two complementary algorithms: ProjFL, designed for
unbiased compressors, and ProjFL+EF, tailored for biased compressors through an
Error Feedback mechanism. Both methods rely on projecting local gradients onto
a shared client-server subspace spanned by historical descent directions,
enabling efficient information exchange with minimal communication overhead. We
establish convergence guarantees for both algorithms under strongly convex,
convex, and non-convex settings. Empirical evaluations on standard FL
classification benchmarks with deep neural networks show that ProjFL and
ProjFL+EF achieve accuracy comparable to existing baselines while substantially
reducing communication costs.

</details>


### [234] [Optimizing Predictive Maintenance in Intelligent Manufacturing: An Integrated FNO-DAE-GNN-PPO MDP Framework](https://arxiv.org/abs/2511.05594)
*Shiqing Qiu*

Main category: cs.LG

TL;DR: 本文提出了一种结合傅里叶神经算子、去噪自编码器、图神经网络和近端策略优化的MDP框架，用于智能制造中的预测性维护，实验显示可降低13%成本。


<details>
  <summary>Details</summary>
Motivation: 智能制造时代下，预测性维护对提高设备可靠性和降低运营成本至关重要，但复杂制造系统中的多维挑战需要创新解决方案。

Method: 提出新颖的MDP框架，集成FNO捕捉高维时间模式、DAE实现鲁棒潜状态嵌入、GNN表示设备间依赖关系，并利用PPO优化长期维护策略。

Result: 实验验证表明该方法显著优于多个深度学习基线模型，成本降低达13%，具有强收敛性和模块间协同效应。

Conclusion: 该框架通过数据驱动策略有效减少停机时间和运营成本，具有重要工业应用潜力。

Abstract: In the era of smart manufacturing, predictive maintenance (PdM) plays a
pivotal role in improving equipment reliability and reducing operating costs.
In this paper, we propose a novel Markov Decision Process (MDP) framework that
integrates advanced soft computing techniques - Fourier Neural Operator (FNO),
Denoising Autoencoder (DAE), Graph Neural Network (GNN), and Proximal Policy
Optimisation (PPO) - to address the multidimensional challenges of predictive
maintenance in complex manufacturing systems. Specifically, the proposed
framework innovatively combines the powerful frequency-domain representation
capability of FNOs to capture high-dimensional temporal patterns; DAEs to
achieve robust, noise-resistant latent state embedding from complex
non-Gaussian sensor data; and GNNs to accurately represent inter-device
dependencies for coordinated system-wide maintenance decisions. Furthermore, by
exploiting PPO, the framework ensures stable and efficient optimisation of
long-term maintenance strategies to effectively handle uncertainty and
non-stationary dynamics. Experimental validation demonstrates that the approach
significantly outperforms multiple deep learning baseline models with up to 13%
cost reduction, as well as strong convergence and inter-module synergy. The
framework has considerable industrial potential to effectively reduce downtime
and operating expenses through data-driven strategies.

</details>


### [235] [FlowNet: Modeling Dynamic Spatio-Temporal Systems via Flow Propagation](https://arxiv.org/abs/2511.05595)
*Yutong Feng,Xu Liu,Yutong Xia,Yuxuan Liang*

Main category: cs.LG

TL;DR: 提出了Spatio-Temporal Flow范式，通过FlowNet架构显式建模动态节点间的流量传输，基于守恒原理实现物理可解释的复杂时空系统建模


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖相似性驱动的连接假设，忽略了支配系统演化的非对称流量交换，需要更符合物理规律的建模方法

Method: FlowNet架构使用流量令牌作为信息载体，通过流量分配模块模拟源到目的地的传输，采用自适应空间掩码动态调整交互半径，级联架构增强可扩展性

Result: 在三个真实世界系统的七个指标上显著优于现有最先进方法，验证了效率和物理可解释性

Conclusion: 建立了通过时空流量交互建模复杂系统的原则性方法

Abstract: Accurately modeling complex dynamic spatio-temporal systems requires
capturing flow-mediated interdependencies and context-sensitive interaction
dynamics. Existing methods, predominantly graph-based or attention-driven, rely
on similarity-driven connectivity assumptions, neglecting asymmetric flow
exchanges that govern system evolution. We propose Spatio-Temporal Flow, a
physics-inspired paradigm that explicitly models dynamic node couplings through
quantifiable flow transfers governed by conservation principles. Building on
this, we design FlowNet, a novel architecture leveraging flow tokens as
information carriers to simulate source-to-destination transfers via Flow
Allocation Modules, ensuring state redistribution aligns with conservation
laws. FlowNet dynamically adjusts the interaction radius through an Adaptive
Spatial Masking module, suppressing irrelevant noise while enabling
context-aware propagation. A cascaded architecture enhances scalability and
nonlinear representation capacity. Experiments demonstrate that FlowNet
significantly outperforms existing state-of-the-art approaches on seven metrics
in the modeling of three real-world systems, validating its efficiency and
physical interpretability. We establish a principled methodology for modeling
complex systems through spatio-temporal flow interactions.

</details>


### [236] [AutoHood3D: A Multi-Modal Benchmark for Automotive Hood Design and Fluid-Structure Interaction](https://arxiv.org/abs/2511.05596)
*Vansh Sharma,Harish Jai Ganesh,Maryam Akram,Wanjiao Liu,Venkat Raman*

Main category: cs.LG

TL;DR: 提出了AutoHood3D数据集，包含16000+个汽车引擎盖几何变体，用于多物理场模拟和机器学习应用，特别关注旋转浸涂过程中的流体-结构耦合问题。


<details>
  <summary>Details</summary>
Motivation: 现有数据集局限于2D案例、几何变化有限或缺乏多模态标注，无法满足复杂多物理场机器学习应用的需求。

Method: 使用耦合的大涡模拟-有限元分析（LES-FEA）方法，总网格数达120万，提供时间分辨的物理场、STL网格和结构化自然语言提示。

Result: 验证了数值方法，建立了五种神经架构的定量基线，展示了位移和力预测中的系统代理误差。

Conclusion: AutoHood3D支持物理感知的机器学习开发，加速生成设计迭代，并为新的流体-结构相互作用基准测试提供基础。

Abstract: This study presents a new high-fidelity multi-modal dataset containing 16000+
geometric variants of automotive hoods useful for machine learning (ML)
applications such as engineering component design and process optimization, and
multiphysics system surrogates. The dataset is centered on a practical
multiphysics problem-hood deformation from fluid entrapment and inertial
loading during rotary-dip painting. Each hood is numerically modeled with a
coupled Large-Eddy Simulation (LES)-Finite Element Analysis (FEA), using 1.2M
cells in total to ensure spatial and temporal accuracy. The dataset provides
time-resolved physical fields, along with STL meshes and structured natural
language prompts for text-to-geometry synthesis. Existing datasets are either
confined to 2D cases, exhibit limited geometric variations, or lack the
multi-modal annotations and data structures - shortcomings we address with
AutoHood3D. We validate our numerical methodology, establish quantitative
baselines across five neural architectures, and demonstrate systematic
surrogate errors in displacement and force predictions. These findings motivate
the design of novel approaches and multiphysics loss functions that enforce
fluid-solid coupling during model training. By providing fully reproducible
workflows, AutoHood3D enables physics-aware ML development, accelerates
generative-design iteration, and facilitates the creation of new FSI
benchmarks. Dataset and code URLs in Appendix.

</details>


### [237] [FiCABU: A Fisher-Based, Context-Adaptive Machine Unlearning Processor for Edge AI](https://arxiv.org/abs/2511.05605)
*Eun-Su Cho,Jongin Choi,Jeongmin Jin,Jae-Jin Lee,Woojoo Lee*

Main category: cs.LG

TL;DR: FiCABU是一种面向边缘AI处理器的机器遗忘软件-硬件协同设计方法，通过上下文自适应遗忘和平衡阻尼技术，在保持准确性的同时显著降低计算和能耗。


<details>
  <summary>Details</summary>
Motivation: 随着隐私法规和"被遗忘权"的需求增加，机器遗忘在边缘计算中变得越来越重要，但传统的服务器中心化或重训练方法在计算和能源预算紧张的情况下不实用。

Method: FiCABU结合了上下文自适应遗忘（从后端层开始编辑，达到目标遗忘后停止）和平衡阻尼（根据深度缩放阻尼强度以保持准确性），并在RISC-V边缘AI处理器中实现，集成了Fisher估计和阻尼的轻量级IP。

Result: 在CIFAR-20和PinsFaceRecognition数据集上，FiCABU实现了随机猜测的遗忘准确性，同时与SSD基线在保持准确性上相当，计算量减少高达87.52%（ResNet-18）和71.03%（ViT）。硬件原型上能耗降低至基线的6.48%和0.13%。

Conclusion: FiCABU证明后端优先、深度感知的遗忘方法可以变得实用且高效，适用于资源受限的边缘AI设备。

Abstract: Machine unlearning, driven by privacy regulations and the "right to be
forgotten", is increasingly needed at the edge, yet server-centric or
retraining-heavy methods are impractical under tight computation and energy
budgets. We present FiCABU (Fisher-based Context-Adaptive Balanced Unlearning),
a software-hardware co-design that brings unlearning to edge AI processors.
FiCABU combines (i) Context-Adaptive Unlearning, which begins edits from
back-end layers and halts once the target forgetting is reached, with (ii)
Balanced Dampening, which scales dampening strength by depth to preserve retain
accuracy. These methods are realized in a full RTL design of a RISC-V edge AI
processor that integrates two lightweight IPs for Fisher estimation and
dampening into a GEMM-centric streaming pipeline, validated on an FPGA
prototype and synthesized in 45 nm for power analysis. Across CIFAR-20 and
PinsFaceRecognition with ResNet-18 and ViT, FiCABU achieves random-guess forget
accuracy while matching the retraining-free Selective Synaptic Dampening (SSD)
baseline on retain accuracy, reducing computation by up to 87.52 percent
(ResNet-18) and 71.03 percent (ViT). On the INT8 hardware prototype, FiCABU
further improves retain preservation and reduces energy to 6.48 percent
(CIFAR-20) and 0.13 percent (PinsFaceRecognition) of the SSD baseline. In sum,
FiCABU demonstrates that back-end-first, depth-aware unlearning can be made
both practical and efficient for resource-constrained edge AI devices.

</details>


### [238] [Conformal Prediction-Driven Adaptive Sampling for Digital Twins of Water Distribution Networks](https://arxiv.org/abs/2511.05610)
*Mohammadhossein Homaei,Oscar Mogollon Gutierrez,Ruben Molano,Andres Caro,Mar Avila*

Main category: cs.LG

TL;DR: 提出了一种结合LSTM预测和保形预测的自适应框架，用于水分配网络数字孪生中的状态估计，通过聚焦不确定性最高的节点来优化传感器部署。


<details>
  <summary>Details</summary>
Motivation: 传统均匀采样在水分配网络节点间浪费资源，不同节点具有不同的不确定性，需要更高效的传感器部署策略。

Method: 使用LSTM进行预测，结合边际保形预测（Conformal Prediction）来估计节点级不确定性，实时识别最不确定的节点进行重点监测。

Result: 在Hanoi、Net3和CTOWN数据集上实验显示，在40%覆盖率下需求误差比均匀采样降低33-34%，仅增加5-10%计算量即可保持89.4-90.2%的经验覆盖率。

Conclusion: 该自适应框架能够有效优化水分配网络数字孪生的传感器资源分配，在保证精度的同时显著降低需求估计误差。

Abstract: Digital Twins (DTs) for Water Distribution Networks (WDNs) require accurate
state estimation with limited sensors. Uniform sampling often wastes resources
across nodes with different uncertainty. We propose an adaptive framework
combining LSTM forecasting and Conformal Prediction (CP) to estimate node-wise
uncertainty and focus sensing on the most uncertain points. Marginal CP is used
for its low computational cost, suitable for real-time DTs. Experiments on
Hanoi, Net3, and CTOWN show 33-34% lower demand error than uniform sampling at
40% coverage and maintain 89.4-90.2% empirical coverage with only 5-10% extra
computation.

</details>


### [239] [An MLCommons Scientific Benchmarks Ontology](https://arxiv.org/abs/2511.05614)
*Ben Hawks,Gregor von Laszewski,Matthew D. Sinclair,Marco Colombo,Shivaram Venkataraman,Rutwik Jain,Yiwei Jiang,Nhan Tran,Geoffrey Fox*

Main category: cs.LG

TL;DR: 本文提出了一个用于科学机器学习基准测试的本体论，通过统一的社区驱动努力扩展MLCommons生态系统，覆盖物理、化学、材料科学、生物学、气候科学等多个领域。


<details>
  <summary>Details</summary>
Motivation: 现有的科学机器学习基准测试工作各自为政且缺乏标准化，导致机器学习在关键科学应用中的新应用更加分散，影响路径不清晰。

Method: 基于XAI-BENCH、FastML Science Benchmarks、PDEBench和SciMLBench框架等先前倡议，将大量不同的基准测试和框架整合到一个统一的分类法中，通过开放提交工作流程添加新基准，并使用六类评级标准评估基准质量。

Result: MLCommons Science Benchmarks Ontology为科学机器学习提供了一个标准化、可扩展的跨领域基准测试基础，支持未来的科学和AI/ML模式识别。

Conclusion: 该本体论为科学机器学习提供了可重现、跨领域的基准测试标准化基础，并建立了配套网页持续更新工作进展。

Abstract: Scientific machine learning research spans diverse domains and data
modalities, yet existing benchmark efforts remain siloed and lack
standardization. This makes novel and transformative applications of machine
learning to critical scientific use-cases more fragmented and less clear in
pathways to impact. This paper introduces an ontology for scientific
benchmarking developed through a unified, community-driven effort that extends
the MLCommons ecosystem to cover physics, chemistry, materials science,
biology, climate science, and more. Building on prior initiatives such as
XAI-BENCH, FastML Science Benchmarks, PDEBench, and the SciMLBench framework,
our effort consolidates a large set of disparate benchmarks and frameworks into
a single taxonomy of scientific, application, and system-level benchmarks. New
benchmarks can be added through an open submission workflow coordinated by the
MLCommons Science Working Group and evaluated against a six-category rating
rubric that promotes and identifies high-quality benchmarks, enabling
stakeholders to select benchmarks that meet their specific needs. The
architecture is extensible, supporting future scientific and AI/ML motifs, and
we discuss methods for identifying emerging computing patterns for unique
scientific workloads. The MLCommons Science Benchmarks Ontology provides a
standardized, scalable foundation for reproducible, cross-domain benchmarking
in scientific machine learning. A companion webpage for this work has also been
developed as the effort evolves: https://mlcommons-science.github.io/benchmark/

</details>


### [240] [wa-hls4ml: A Benchmark and Surrogate Models for hls4ml Resource and Latency Estimation](https://arxiv.org/abs/2511.05615)
*Benjamin Hawks,Jason Weitz,Dmitri Demler,Karla Tame-Narvaez,Dennis Plotnikov,Mohammad Mehdi Rahimifar,Hamza Ezzaoui Rahali,Audrey C. Therrien,Donovan Sproule,Elham E Khoda,Keegan A. Smith,Russell Marroquin,Giuseppe Di Guglielmo,Nhan Tran,Javier Duarte,Vladimir Loncar*

Main category: cs.LG

TL;DR: wa-hls4ml基准测试和数据集，用于评估机器学习加速器的资源使用和延迟预测模型，包含超过68万个神经网络模型，并提出了基于GNN和Transformer的代理模型。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习在硬件中的实现增加，硬件合成等过程成为设计迭代的瓶颈，需要开发基于ML的代理模型来估计加速器资源使用。

Method: 引入wa-hls4ml基准测试和数据集，包含68万+全连接和卷积神经网络，使用hls4ml合成并针对Xilinx FPGA。开发基于GNN和Transformer的代理模型来预测延迟和资源。

Result: 模型在合成测试数据集上，对75%百分位数的延迟和资源预测误差在几个百分点以内。

Conclusion: wa-hls4ml基准测试为ML加速器资源预测提供了标准评估框架，提出的代理模型能够有效预测硬件资源使用。

Abstract: As machine learning (ML) is increasingly implemented in hardware to address
real-time challenges in scientific applications, the development of advanced
toolchains has significantly reduced the time required to iterate on various
designs. These advancements have solved major obstacles, but also exposed new
challenges. For example, processes that were not previously considered
bottlenecks, such as hardware synthesis, are becoming limiting factors in the
rapid iteration of designs. To mitigate these emerging constraints, multiple
efforts have been undertaken to develop an ML-based surrogate model that
estimates resource usage of ML accelerator architectures. We introduce
wa-hls4ml, a benchmark for ML accelerator resource and latency estimation, and
its corresponding initial dataset of over 680,000 fully connected and
convolutional neural networks, all synthesized using hls4ml and targeting
Xilinx FPGAs. The benchmark evaluates the performance of resource and latency
predictors against several common ML model architectures, primarily originating
from scientific domains, as exemplar models, and the average performance across
a subset of the dataset. Additionally, we introduce GNN- and transformer-based
surrogate models that predict latency and resources for ML accelerators. We
present the architecture and performance of the models and find that the models
generally predict latency and resources for the 75% percentile within several
percent of the synthesized resources on the synthetic test dataset.

</details>


### [241] [Frequency Matters: When Time Series Foundation Models Fail Under Spectral Shift](https://arxiv.org/abs/2511.05619)
*Tianze Wang,Sofiane Ennadir,John Pertoft,Gabriela Zarzar Gandler,Lele Cao,Zineb Senane,Styliani Katsarou,Sahar Asadi,Axel Karlsson,Oleg Smirnov*

Main category: cs.LG

TL;DR: 时间序列基础模型在工业应用中存在泛化问题，主要原因是频谱偏移（下游任务与预训练数据频率成分不匹配），导致在工业场景中表现不佳。


<details>
  <summary>Details</summary>
Motivation: 探究时间序列基础模型在工业环境中表现不佳的原因，特别是频谱不匹配对模型泛化能力的影响。

Method: 通过工业规模移动游戏玩家参与度预测任务进行实证分析，并设计受控合成实验对比已见和未见频率带信号的性能差异。

Result: 发现时间序列基础模型在频谱不匹配情况下系统性性能下降，在工业任务中表现不如领域适配的基线模型。

Conclusion: 频率感知对于时间序列基础模型的稳健部署至关重要，需要开发考虑频谱多样性的新预训练和评估协议。

Abstract: Time series foundation models (TSFMs) have shown strong results on public
benchmarks, prompting comparisons to a "BERT moment" for time series. Their
effectiveness in industrial settings, however, remains uncertain. We examine
why TSFMs often struggle to generalize and highlight spectral shift (a mismatch
between the dominant frequency components in downstream tasks and those
represented during pretraining) as a key factor. We present evidence from an
industrial-scale player engagement prediction task in mobile gaming, where
TSFMs underperform domain-adapted baselines. To isolate the mechanism, we
design controlled synthetic experiments contrasting signals with seen versus
unseen frequency bands, observing systematic degradation under spectral
mismatch. These findings position frequency awareness as critical for robust
TSFM deployment and motivate new pretraining and evaluation protocols that
explicitly account for spectral diversity.

</details>


### [242] [Fooling Algorithms in Non-Stationary Bandits using Belief Inertia](https://arxiv.org/abs/2511.05620)
*Gal Mendelson,Eyal Tadmor*

Main category: cs.LG

TL;DR: 本文提出了一种基于信念惯性的新方法，用于分析非平稳多臂老虎机问题中的最坏情况遗憾下界，证明即使对经典算法进行参数调优，其最坏情况遗憾仍会随T线性增长。


<details>
  <summary>Details</summary>
Motivation: 现有非平稳老虎机问题的下界分析主要依赖稀疏采样假设，而本文旨在通过信念惯性这一新视角来理解算法在时间变化环境中的根本局限性。

Method: 提出信念惯性分析方法，通过算法历史奖励平均值形成的经验信念动量来构造对抗性实例，证明经典算法如ETC、ε-greedy和UCB在单变点情况下也会产生线性遗憾。

Result: 证明即使对算法进行参数调优，经典算法在最坏情况下仍会遭受与T成线性关系的遗憾，且具有相当大的常数因子。该结果也适用于周期性重启的算法。

Conclusion: 信念惯性是推导非平稳老虎机问题尖锐下界的有力方法，揭示了现有算法在应对环境变化时的根本局限性。

Abstract: We study the problem of worst case regret in piecewise stationary multi armed
bandits. While the minimax theory for stationary bandits is well established,
understanding analogous limits in time-varying settings is challenging.
Existing lower bounds rely on what we refer to as infrequent sampling
arguments, where long intervals without exploration allow adversarial reward
changes that induce large regret.
  In this paper, we introduce a fundamentally different approach based on a
belief inertia argument. Our analysis captures how an algorithm's empirical
beliefs, encoded through historical reward averages, create momentum that
resists new evidence after a change. We show how this inertia can be exploited
to construct adversarial instances that mislead classical algorithms such as
Explore Then Commit, epsilon greedy, and UCB, causing them to suffer regret
that grows linearly with T and with a substantial constant factor, regardless
of how their parameters are tuned, even with a single change point.
  We extend the analysis to algorithms that periodically restart to handle non
stationarity and prove that, even then, the worst case regret remains linear in
T. Our results indicate that utilizing belief inertia can be a powerful method
for deriving sharp lower bounds in non stationary bandits.

</details>


### [243] [Unveiling the Training Dynamics of ReLU Networks through a Linear Lens](https://arxiv.org/abs/2511.05628)
*Longqing Ye*

Main category: cs.LG

TL;DR: 提出了一种将多层ReLU网络转化为等效单层线性模型的分析框架，通过输入依赖的"有效权重"揭示网络内部学习机制


<details>
  <summary>Details</summary>
Motivation: 深度神经网络特别是ReLU网络的复杂性给理解其内部学习机制带来了挑战，需要新的分析工具来揭示其工作原理

Method: 通过分析ReLU单元的激活模式，为每个输入样本构建唯一的计算路径，将多层网络的有效权重组合成单层线性模型的权重矩阵W_eff(x)

Result: 训练过程中，同一类别样本的有效权重会收敛，不同类别样本的有效权重会发散，这揭示了类特定决策边界的形成过程

Conclusion: 通过跟踪样本级有效权重的轨迹，为理解网络中语义表示的形成提供了新的视角，有助于解释深度学习的内部机制

Abstract: Deep neural networks, particularly those employing Rectified Linear Units
(ReLU), are often perceived as complex, high-dimensional, non-linear systems.
This complexity poses a significant challenge to understanding their internal
learning mechanisms. In this work, we propose a novel analytical framework that
recasts a multi-layer ReLU network into an equivalent single-layer linear model
with input-dependent "effective weights". For any given input sample, the
activation pattern of ReLU units creates a unique computational path,
effectively zeroing out a subset of weights in the network. By composing the
active weights across all layers, we can derive an effective weight matrix,
$W_{\text{eff}}(x)$, that maps the input directly to the output for that
specific sample. We posit that the evolution of these effective weights reveals
fundamental principles of representation learning. Our work demonstrates that
as training progresses, the effective weights corresponding to samples from the
same class converge, while those from different classes diverge. By tracking
the trajectories of these sample-wise effective weights, we provide a new lens
through which to interpret the formation of class-specific decision boundaries
and the emergence of semantic representations within the network.

</details>


### [244] [SSTODE: Ocean-Atmosphere Physics-Informed Neural ODEs for Sea Surface Temperature Prediction](https://arxiv.org/abs/2511.05629)
*Zheng Jiang,Wei Wang,Gaowei Zhang,Yi Wang*

Main category: cs.LG

TL;DR: SSTODE是一个基于物理信息的神经常微分方程框架，用于海表温度预测，通过结合流体输运原理和能量交换积分器，在保持物理一致性的同时提高预测精度和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统数据驱动模型的黑箱性质限制了可解释性并忽略了关键物理过程，而现有物理信息神经网络在处理复杂海洋-大气动力学时存在海水运动表征不足和外部SST驱动因素整合不充分的问题。

Method: 首先从流体输运原理推导ODE，结合平流和扩散模拟海洋时空动力学；通过变分优化恢复控制SST时间动态的潜速度场；引入基于海洋热收支方程的能量交换积分器来考虑外部强迫因素。

Result: 在全局和区域SST预测基准测试中达到最先进性能，并可视化展示了平流动力学、热扩散模式和昼夜加热-冷却循环对SST演变的影响。

Conclusion: SSTODE模型在保持物理一致性的同时实现了高精度预测，其可解释性为理解SST动力学提供了更深入的洞察。

Abstract: Sea Surface Temperature (SST) is crucial for understanding upper-ocean
thermal dynamics and ocean-atmosphere interactions, which have profound
economic and social impacts. While data-driven models show promise in SST
prediction, their black-box nature often limits interpretability and overlooks
key physical processes. Recently, physics-informed neural networks have been
gaining momentum but struggle with complex ocean-atmosphere dynamics due to 1)
inadequate characterization of seawater movement (e.g., coastal upwelling) and
2) insufficient integration of external SST drivers (e.g., turbulent heat
fluxes). To address these challenges, we propose SSTODE, a physics-informed
Neural Ordinary Differential Equations (Neural ODEs) framework for SST
prediction. First, we derive ODEs from fluid transport principles,
incorporating both advection and diffusion to model ocean spatiotemporal
dynamics. Through variational optimization, we recover a latent velocity field
that explicitly governs the temporal dynamics of SST. Building upon ODE, we
introduce an Energy Exchanges Integrator (EEI)-inspired by ocean heat budget
equations-to account for external forcing factors. Thus, the variations in the
components of these factors provide deeper insights into SST dynamics.
Extensive experiments demonstrate that SSTODE achieves state-of-the-art
performances in global and regional SST forecasting benchmarks. Furthermore,
SSTODE visually reveals the impact of advection dynamics, thermal diffusion
patterns, and diurnal heating-cooling cycles on SST evolution. These findings
demonstrate the model's interpretability and physical consistency.

</details>


### [245] [Physics-Guided Machine Learning for Uncertainty Quantification in Turbulence Models](https://arxiv.org/abs/2511.05633)
*Minghan Chu,Weicheng Qian*

Main category: cs.LG

TL;DR: 提出了一种基于卷积神经网络（CNN）的EPM扰动幅度调制方法，结合机器学习与物理模型，改善了湍流模型不确定性估计的校准精度。


<details>
  <summary>Details</summary>
Motivation: 传统Eigenspace Perturbation Method（EPM）作为纯物理方法在量化湍流模型不确定性时可能过度预测不确定性边界，需要改进校准精度。

Method: 采用卷积神经网络对EPM的扰动幅度进行调制，构建混合ML-EPM框架，在保持物理一致性的同时优化不确定性估计。

Result: 在典型测试案例中，混合ML-EPM框架相比基线EPM方法产生了更紧凑、校准更好的不确定性估计。

Conclusion: 机器学习与物理模型的结合能够有效改善湍流模型不确定性量化，为科学和工程应用提供更可靠的不确定性边界预测。

Abstract: Predicting the evolution of turbulent flows is central across science and
engineering. Most studies rely on simulations with turbulence models, whose
empirical simplifications introduce epistemic uncertainty. The Eigenspace
Perturbation Method (EPM) is a widely used physics-based approach to quantify
model-form uncertainty, but being purely physics-based it can overpredict
uncertainty bounds. We propose a convolutional neural network (CNN)-based
modulation of EPM perturbation magnitudes to improve calibration while
preserving physical consistency. Across canonical cases, the hybrid ML-EPM
framework yields substantially tighter, better-calibrated uncertainty estimates
than baseline EPM alone.

</details>


### [246] [Blind Inverse Game Theory: Jointly Decoding Rewards and Rationality in Entropy-Regularized Competitive Games](https://arxiv.org/abs/2511.05640)
*Hamza Virk,Sandro Amaglobeli,Zuhayr Syed*

Main category: cs.LG

TL;DR: Blind-IGT是一个新的统计框架，用于在不知道智能体理性参数（温度τ）的情况下，从观察到的行为中联合恢复奖励参数θ和τ，解决了传统逆博弈理论中的尺度模糊性问题。


<details>
  <summary>Details</summary>
Motivation: 传统基于熵正则化QRE的逆博弈理论方法假设智能体的理性参数τ是已知的，但当τ未知时，会出现尺度模糊性，导致奖励参数θ和τ统计上不可识别。

Method: 提出了Blind-IGT框架，通过引入归一化约束解决尺度模糊性，使用归一化最小二乘估计器进行联合参数恢复，并扩展到马尔可夫博弈场景。

Result: 证明了NLS估计器达到最优的O(N^{-1/2})收敛速率，在强可识别性条件不满足时提供部分识别保证，并在未知转移动态下仍表现出强实证性能。

Conclusion: Blind-IGT是第一个能够从观察行为中联合恢复θ和τ的统计框架，解决了逆博弈理论中的关键识别问题，为竞争性环境提供了更实用的解决方案。

Abstract: Inverse Game Theory (IGT) methods based on the entropy-regularized Quantal
Response Equilibrium (QRE) offer a tractable approach for competitive settings,
but critically assume the agents' rationality parameter (temperature $\tau$) is
known a priori. When $\tau$ is unknown, a fundamental scale ambiguity emerges
that couples $\tau$ with the reward parameters ($\theta$), making them
statistically unidentifiable. We introduce Blind-IGT, the first statistical
framework to jointly recover both $\theta$ and $\tau$ from observed behavior.
We analyze this bilinear inverse problem and establish necessary and sufficient
conditions for unique identification by introducing a normalization constraint
that resolves the scale ambiguity. We propose an efficient Normalized Least
Squares (NLS) estimator and prove it achieves the optimal
$\mathcal{O}(N^{-1/2})$ convergence rate for joint parameter recovery. When
strong identifiability conditions fail, we provide partial identification
guarantees through confidence set construction. We extend our framework to
Markov games and demonstrate optimal convergence rates with strong empirical
performance even when transition dynamics are unknown.

</details>


### [247] [KLASS: KL-Guided Fast Inference in Masked Diffusion Models](https://arxiv.org/abs/2511.05664)
*Seo Hyun Kim,Sunwoo Hong,Hojung Jung,Youngrok Park,Se-Young Yun*

Main category: cs.LG

TL;DR: KLASS是一种快速采样方法，通过利用标记级KL散度识别稳定预测，在保持样本质量的同时显著加速扩散模型的生成过程。


<details>
  <summary>Details</summary>
Motivation: 由于扩散模型的迭代优化过程，推理速度往往受限于采样速度慢且固定的问题。

Method: KL-Adaptive Stability Sampling (KLASS)方法在每次迭代中同时解掩多个标记，无需额外模型训练，通过标记级KL散度识别高置信度预测。

Result: 在推理基准测试中，KLASS实现了最高2.78倍的加速，同时性能优于标准贪婪解码，在基于扩散的采样器中达到最先进水平。该方法在文本、图像和分子生成等多个领域都表现有效。

Conclusion: KLASS是一种广泛适用的采样器，能够在保持样本质量的同时显著提升扩散模型的生成速度。

Abstract: Masked diffusion models have demonstrated competitive results on various
tasks including language generation. However, due to its iterative refinement
process, the inference is often bottlenecked by slow and static sampling speed.
To overcome this problem, we introduce `KL-Adaptive Stability Sampling'
(KLASS), a fast yet effective sampling method that exploits token-level KL
divergence to identify stable, high-confidence predictions. By unmasking
multiple tokens in each iteration without any additional model training, our
approach speeds up generation significantly while maintaining sample quality.
On reasoning benchmarks, KLASS achieves up to $2.78\times$ wall-clock speedups
while improving performance over standard greedy decoding, attaining
state-of-the-art results among diffusion-based samplers. We further validate
KLASS across diverse domains, including text, image, and molecular generation,
showing its effectiveness as a broadly applicable sampler across different
models.

</details>


### [248] [Distributionally Robust Self Paced Curriculum Reinforcement Learning](https://arxiv.org/abs/2511.05694)
*Anirudh Satheesh,Keenan Powell,Vaneet Aggarwal*

Main category: cs.LG

TL;DR: DR-SPCRL通过将鲁棒性预算ε作为连续课程，自适应调度来平衡名义性能和鲁棒性能，解决了DRRL中固定ε导致的性能-鲁棒性权衡问题。


<details>
  <summary>Details</summary>
Motivation: 强化学习策略在受控环境中训练后，在真实世界部署时经常因分布偏移而失效。传统DRRL方法固定鲁棒性预算ε会导致性能与鲁棒性之间的权衡问题。

Method: 提出分布鲁棒自步课程强化学习(DR-SPCRL)，将ε作为连续课程，根据智能体进度自适应调度鲁棒性预算，实现名义性能与鲁棒性能的平衡。

Result: 在多个环境中，DR-SPCRL不仅稳定了训练，还实现了更优的鲁棒性-性能权衡，在变化扰动下平均episodic回报提高11.8%，性能约为对应名义RL算法的1.9倍。

Conclusion: DR-SPCRL方法通过自适应课程调度有效解决了DRRL的性能-鲁棒性权衡问题，显著提升了策略在分布偏移下的鲁棒性。

Abstract: A central challenge in reinforcement learning is that policies trained in
controlled environments often fail under distribution shifts at deployment into
real-world environments. Distributionally Robust Reinforcement Learning (DRRL)
addresses this by optimizing for worst-case performance within an uncertainty
set defined by a robustness budget $\epsilon$. However, fixing $\epsilon$
results in a tradeoff between performance and robustness: small values yield
high nominal performance but weak robustness, while large values can result in
instability and overly conservative policies. We propose Distributionally
Robust Self-Paced Curriculum Reinforcement Learning (DR-SPCRL), a method that
overcomes this limitation by treating $\epsilon$ as a continuous curriculum.
DR-SPCRL adaptively schedules the robustness budget according to the agent's
progress, enabling a balance between nominal and robust performance. Empirical
results across multiple environments demonstrate that DR-SPCRL not only
stabilizes training but also achieves a superior robustness-performance
trade-off, yielding an average 11.8\% increase in episodic return under varying
perturbations compared to fixed or heuristic scheduling strategies, and
achieving approximately 1.9$\times$ the performance of the corresponding
nominal RL algorithms.

</details>


### [249] [AI-assisted workflow enables rapid, high-fidelity breast cancer clinical trial eligibility prescreening](https://arxiv.org/abs/2511.05696)
*Jacob T. Rosenthal,Emma Hahesy,Sulov Chalise,Menglei Zhu,Mert R. Sabuncu,Lior Z. Braunstein,Anyi Li*

Main category: cs.LG

TL;DR: MSK-MATCH是一个基于AI的临床试验资格筛查系统，通过整合大语言模型和肿瘤学知识库，实现了61.9%病例的自动处理和98.6%的准确率，显著提高了筛查效率。


<details>
  <summary>Details</summary>
Motivation: 临床试验参与率低，需要开发自动化工具来提高筛查效率和准确性。

Method: 开发MSK-MATCH系统，整合大语言模型与肿瘤学知识库，采用检索增强架构，为所有AI预测提供基于源文本的解释。

Result: 在731名患者的88,518份临床文档中，系统自动处理61.9%的病例，AI辅助工作流达到98.6%的准确率，人工筛查时间从20分钟减少到43秒。

Conclusion: MSK-MATCH系统能够有效提高临床试验筛查的效率和准确性，降低成本，具有重要的临床应用价值。

Abstract: Clinical trials play an important role in cancer care and research, yet
participation rates remain low. We developed MSK-MATCH (Memorial Sloan
Kettering Multi-Agent Trial Coordination Hub), an AI system for automated
eligibility screening from clinical text. MSK-MATCH integrates a large language
model with a curated oncology trial knowledge base and retrieval-augmented
architecture providing explanations for all AI predictions grounded in source
text. In a retrospective dataset of 88,518 clinical documents from 731 patients
across six breast cancer trials, MSK-MATCH automatically resolved 61.9% of
cases and triaged 38.1% for human review. This AI-assisted workflow achieved
98.6% accuracy, 98.4% sensitivity, and 98.7% specificity for patient-level
eligibility classification, matching or exceeding performance of the human-only
and AI-only comparisons. For the triaged cases requiring manual review,
prepopulating eligibility screens with AI-generated explanations reduced
screening time from 20 minutes to 43 seconds at an average cost of $0.96 per
patient-trial pair.

</details>


### [250] [TabDistill: Distilling Transformers into Neural Nets for Few-Shot Tabular Classification](https://arxiv.org/abs/2511.05704)
*Pasan Dissanayake,Sanghamitra Dutta*

Main category: cs.LG

TL;DR: TabDistill是一种将复杂Transformer模型的知识蒸馏到简单神经网络中的新策略，用于表格数据分类，在参数效率和数据有限的情况下都表现优异。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在少量训练数据的表格数据上表现优异，但存在复杂性和参数量大的问题，需要解决这一权衡问题。

Method: 提出TabDistill框架，通过知识蒸馏将预训练Transformer模型的知识转移到简单的神经网络中。

Result: 蒸馏后的神经网络在同等训练数据下超越了传统基线方法（如常规神经网络、XGBoost和逻辑回归），在某些情况下甚至超过了原始Transformer模型。

Conclusion: TabDistill框架实现了参数效率和有限数据性能的最佳平衡，为表格数据分类提供了有效的解决方案。

Abstract: Transformer-based models have shown promising performance on tabular data
compared to their classical counterparts such as neural networks and Gradient
Boosted Decision Trees (GBDTs) in scenarios with limited training data. They
utilize their pre-trained knowledge to adapt to new domains, achieving
commendable performance with only a few training examples, also called the
few-shot regime. However, the performance gain in the few-shot regime comes at
the expense of significantly increased complexity and number of parameters. To
circumvent this trade-off, we introduce TabDistill, a new strategy to distill
the pre-trained knowledge in complex transformer-based models into simpler
neural networks for effectively classifying tabular data. Our framework yields
the best of both worlds: being parameter-efficient while performing well with
limited training data. The distilled neural networks surpass classical
baselines such as regular neural networks, XGBoost and logistic regression
under equal training data, and in some cases, even the original
transformer-based models that they were distilled from.

</details>


### [251] [Distributionally Robust Multimodal Machine Learning](https://arxiv.org/abs/2511.05716)
*Peilin Yang,Yu Ma*

Main category: cs.LG

TL;DR: 本文提出了一个分布鲁棒多模态机器学习框架，通过理论分析和实验验证，为高不确定性应用场景提供了性能保证。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖特征级融合或启发式不确定性建模，忽视了模态感知效应且缺乏理论洞察。

Method: 提出新颖的分布鲁棒优化框架，通过复杂度分析、泛化上界和极小极大下界理论分析，并考虑编码器特定误差传播。

Result: 实验证明该方法在仿真环境和真实数据集上均提升了鲁棒性。

Conclusion: 为高风险应用中不可避免的不确定性场景提供了使用多模态机器学习模型的原则性基础。

Abstract: We consider the problem of distributionally robust multimodal machine
learning. Existing approaches often rely on merging modalities on the feature
level (early fusion) or heuristic uncertainty modeling, which downplays
modality-aware ef- fects and provide limited insights. We propose a novel
distributionally robust optimization (DRO) framework that aims to study both
the theoretical and practical insights of multimodal machine learning. We first
justify this setup and show the significance of this problem through complexity
analysis. We then establish both generalization upper bounds and minimax lower
bounds which provide perfor- mance guarantees. These results are further
extended in settings where we consider encoder-specific error propogations.
Empirically, we demonstrate that our approach improves robustness in both
simulation settings and real-world datasets. Together, these findings provide a
principled foundation for employing multimodal machine learning models in
high-stakes applications where uncertainty is unavoidable.

</details>


### [252] [GastroDL-Fusion: A Dual-Modal Deep Learning Framework Integrating Protein-Ligand Complexes and Gene Sequences for Gastrointestinal Disease Drug Discovery](https://arxiv.org/abs/2511.05726)
*Ziyang Gao,Annie Cheung,Yihao Ou*

Main category: cs.LG

TL;DR: GastroDL-Fusion是一种双模态深度学习框架，通过整合蛋白质-配体复合物数据和疾病相关基因序列信息，显著提高了胃肠道疾病相关药物和疫苗开发中蛋白质-配体结合亲和力的预测准确性。


<details>
  <summary>Details</summary>
Motivation: 传统计算模型仅依赖结构信息，无法捕捉影响疾病机制和治疗反应的遗传决定因素，这限制了胃肠道疾病药物开发的效率。

Method: 提出GastroDL-Fusion框架：将蛋白质-配体复合物表示为分子图并使用图同构网络(GIN)建模；通过预训练Transformer(ProtBERT/ESM)将基因序列编码为生物学有意义的嵌入；通过多层感知机融合这两种互补模态以实现跨模态交互学习。

Result: 在胃肠道疾病相关靶点的基准数据集上评估，模型达到MAE 1.12和RMSE 1.75，显著优于CNN、BiLSTM、GIN和仅使用Transformer的基线方法。

Conclusion: 同时整合结构和遗传特征能够更准确地预测结合亲和力，为加速胃肠道疾病靶向治疗和疫苗设计提供了可靠的计算工具。

Abstract: Accurate prediction of protein-ligand binding affinity plays a pivotal role
in accelerating the discovery of novel drugs and vaccines, particularly for
gastrointestinal (GI) diseases such as gastric ulcers, Crohn's disease, and
ulcerative colitis. Traditional computational models often rely on structural
information alone and thus fail to capture the genetic determinants that
influence disease mechanisms and therapeutic responses. To address this gap, we
propose GastroDL-Fusion, a dual-modal deep learning framework that integrates
protein-ligand complex data with disease-associated gene sequence information
for drug and vaccine development. In our approach, protein-ligand complexes are
represented as molecular graphs and modeled using a Graph Isomorphism Network
(GIN), while gene sequences are encoded into biologically meaningful embeddings
via a pre-trained Transformer (ProtBERT/ESM). These complementary modalities
are fused through a multi-layer perceptron to enable robust cross-modal
interaction learning. We evaluate the model on benchmark datasets of GI
disease-related targets, demonstrating that GastroDL-Fusion significantly
improves predictive performance over conventional methods. Specifically, the
model achieves a mean absolute error (MAE) of 1.12 and a root mean square error
(RMSE) of 1.75, outperforming CNN, BiLSTM, GIN, and Transformer-only baselines.
These results confirm that incorporating both structural and genetic features
yields more accurate predictions of binding affinities, providing a reliable
computational tool for accelerating the design of targeted therapies and
vaccines in the context of gastrointestinal diseases.

</details>


### [253] [Compressing Chemistry Reveals Functional Groups](https://arxiv.org/abs/2511.05728)
*Ruben Sharma,Ross D. King*

Main category: cs.LG

TL;DR: 该研究首次对传统化学功能基团在化学解释中的效用进行大规模评估，基于最小消息长度(MML)原则开发无监督学习算法，发现新型功能基团并显著提升生物活性预测性能


<details>
  <summary>Details</summary>
Motivation: 评估传统化学功能基团作为化学解释工具的效用，探索更有效的分子表示方法

Method: 使用基于最小消息长度(MML)原则的无监督学习算法，在约300万个生物相关分子中搜索压缩数据的子结构

Result: 发现的子结构包含大多数人工筛选的功能基团以及新颖的更大模式；在24个生物活性预测数据集上，基于数据集特定功能基团的指纹表示显著优于MACCS和Morgan指纹

Conclusion: 传统功能基团是有用的解释工具，但算法发现的新型功能基团能提供更优的分子表示和预测性能

Abstract: We introduce the first formal large-scale assessment of the utility of
traditional chemical functional groups as used in chemical explanations. Our
assessment employs a fundamental principle from computational learning theory:
a good explanation of data should also compress the data. We introduce an
unsupervised learning algorithm based on the Minimum Message Length (MML)
principle that searches for substructures that compress around three million
biologically relevant molecules. We demonstrate that the discovered
substructures contain most human-curated functional groups as well as novel
larger patterns with more specific functions. We also run our algorithm on 24
specific bioactivity prediction datasets to discover dataset-specific
functional groups. Fingerprints constructed from dataset-specific functional
groups are shown to significantly outperform other fingerprint representations,
including the MACCS and Morgan fingerprint, when training ridge regression
models on bioactivity regression tasks.

</details>


### [254] [QiVC-Net: Quantum-Inspired Variational Convolutional Network, with Application to Biosignal Classification](https://arxiv.org/abs/2511.05730)
*Amin Golnari,Jamileh Yousefi,Reza Moheimani,Saeid Sanei*

Main category: cs.LG

TL;DR: 本文提出了量子启发的变分卷积框架，通过量子旋转集成机制实现卷积权重的可微分子空间旋转，在生物信号分类任务中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 解决生物信号分析中高噪声、个体差异和数据不平衡等挑战，需要开发更具表达力、稳定性和不确定性感知的深度学习模型。

Method: QiVC框架包含量子旋转集成机制，对卷积权重进行可微分的低维子空间旋转，模拟量子态演化过程，在不增加参数的情况下增强模型表达能力。

Result: 在两个基准数据集上分别达到97.84%和97.89%的准确率，超越了现有最先进方法。

Conclusion: QiVC框架展示了在真实世界生物医学信号分析中推进不确定性感知建模的潜力，具有实际应用价值。

Abstract: This work introduces the quantum-inspired variational convolution (QiVC)
framework, a novel learning paradigm that integrates principles of
probabilistic inference, variational optimization, and quantum-inspired
transformations within convolutional architectures. The central innovation of
QiVC lies in its quantum-inspired rotated ensemble (QiRE) mechanism. QiRE
performs differentiable low-dimensional subspace rotations of convolutional
weights, analogously to quantum state evolution. This approach enables
structured uncertainty modeling while preserving the intrinsic geometry of the
parameter space, resulting in more expressive, stable, and uncertainty-aware
representations. To demonstrate its practical potential, the concept is
instantiated in a QiVC-based convolutional network (QiVC-Net) and evaluated in
the context of biosignal classification, focusing on phonocardiogram (PCG)
recordings, a challenging domain characterized by high noise, inter-subject
variability, and often imbalanced data. The proposed QiVC-Net integrates an
architecture in which the QiVC layer does not introduce additional parameters,
instead performing an ensemble rotation of the convolutional weights through a
structured mechanism ensuring robustness without added highly computational
burden. Experiments on two benchmark datasets, PhysioNet CinC 2016 and
PhysioNet CirCor DigiScope 2022, show that QiVC-Net achieves state-of-the-art
performance, reaching accuracies of 97.84% and 97.89%, respectively. These
findings highlight the versatility of the QiVC framework and its promise for
advancing uncertainty-aware modeling in real-world biomedical signal analysis.
The implementation of the QiVConv layer is openly available in GitHub.

</details>


### [255] [Near-Exponential Savings for Mean Estimation with Active Learning](https://arxiv.org/abs/2511.05736)
*Julian M. Morimoto,Jacob Goldin,Daniel E. Ho*

Main category: cs.LG

TL;DR: 提出了一种名为PartiBandits的主动学习算法，用于在有限标签数量下利用辅助信息高效估计多类别随机变量的均值。


<details>
  <summary>Details</summary>
Motivation: 解决在标签数量有限但存在辅助协变量的情况下，如何高效估计随机变量均值的问题。

Method: 两阶段算法：第一阶段学习未标记数据的划分以减少Y的条件方差；第二阶段使用UCB风格子程序WarmStart-UCB轮询请求各分层的标签。

Result: 算法估计误差平方为Õ((ν + exp(-cN/logN))/N)，其中ν为贝叶斯最优分类器风险，在经典设置下达到极小极大最优收敛率。

Conclusion: PartiBandits桥接了UCB和基于分歧的主动学习方法，可通过R包实现，并在电子健康记录数据上验证了有效性。

Abstract: We study the problem of efficiently estimating the mean of a $k$-class random
variable, $Y$, using a limited number of labels, $N$, in settings where the
analyst has access to auxiliary information (i.e.: covariates) $X$ that may be
informative about $Y$. We propose an active learning algorithm ("PartiBandits")
to estimate $\mathbb{E}[Y]$. The algorithm yields an estimate,
$\widehat{\mu}_{\text{PB}}$, such that $\left( \widehat{\mu}_{\text{PB}} -
\mathbb{E}[Y]\right)^2$ is $\tilde{\mathcal{O}}\left( \frac{\nu + \exp(c \cdot
(-N/\log(N))) }{N} \right)$, where $c > 0$ is a constant and $\nu$ is the risk
of the Bayes-optimal classifier. PartiBandits is essentially a two-stage
algorithm. In the first stage, it learns a partition of the unlabeled data that
shrinks the average conditional variance of $Y$. In the second stage it uses a
UCB-style subroutine ("WarmStart-UCB") to request labels from each stratum
round-by-round. Both the main algorithm's and the subroutine's convergence
rates are minimax optimal in classical settings. PartiBandits bridges the UCB
and disagreement-based approaches to active learning despite these two
approaches being designed to tackle very different tasks. We illustrate our
methods through simulation using nationwide electronic health records. Our
methods can be implemented using the PartiBandits package in R.

</details>


### [256] [Beyond Redundancy: Diverse and Specialized Multi-Expert Sparse Autoencoder](https://arxiv.org/abs/2511.05745)
*Zhen Xu,Zhen Tan,Song Wang,Kaidi Xu,Tianlong Chen*

Main category: cs.LG

TL;DR: 本文提出了一种改进的MoE-SAE方法，通过多重专家激活和特征缩放技术解决专家网络特征重叠问题，显著降低了重建误差和特征冗余。


<details>
  <summary>Details</summary>
Motivation: 稀疏自编码器(SAE)在解释大语言模型时面临可解释性与效率的权衡问题。现有的MoE-SAE方法中专家网络经常学习重叠特征，限制了其实际应用效果。

Method: 提出双重创新：(1)多重专家激活机制，同时激活语义加权的专家子集以促进专业化；(2)特征缩放技术，通过自适应高频缩放增强特征多样性。

Result: 实验结果显示重建误差降低24%，特征冗余减少99%，显著优于现有MoE-SAE方法。

Conclusion: 这项工作弥合了LLM分析中的可解释性-效率差距，使得在不牺牲计算可行性的前提下实现透明模型检查成为可能。

Abstract: Sparse autoencoders (SAEs) have emerged as a powerful tool for interpreting
large language models (LLMs) by decomposing token activations into combinations
of human-understandable features. While SAEs provide crucial insights into LLM
explanations, their practical adoption faces a fundamental challenge: better
interpretability demands that SAEs' hidden layers have high dimensionality to
satisfy sparsity constraints, resulting in prohibitive training and inference
costs. Recent Mixture of Experts (MoE) approaches attempt to address this by
partitioning SAEs into narrower expert networks with gated activation, thereby
reducing computation. In a well-designed MoE, each expert should focus on
learning a distinct set of features. However, we identify a \textit{critical
limitation} in MoE-SAE: Experts often fail to specialize, which means they
frequently learn overlapping or identical features. To deal with it, we propose
two key innovations: (1) Multiple Expert Activation that simultaneously engages
semantically weighted expert subsets to encourage specialization, and (2)
Feature Scaling that enhances diversity through adaptive high-frequency
scaling. Experiments demonstrate a 24\% lower reconstruction error and a 99\%
reduction in feature redundancy compared to existing MoE-SAE methods. This work
bridges the interpretability-efficiency gap in LLM analysis, allowing
transparent model inspection without compromising computational feasibility.

</details>


### [257] [Primal-Only Actor Critic Algorithm for Robust Constrained Average Cost MDPs](https://arxiv.org/abs/2511.05758)
*Anirudh Satheesh,Sooraj Sathish,Swetha Ganesh,Keenan Powell,Vaneet Aggarwal*

Main category: cs.LG

TL;DR: 提出了一个演员-评论家算法来解决平均成本鲁棒约束马尔可夫决策过程（RCMDPs）中的鲁棒安全策略问题，克服了强对偶性缺失和贝尔曼算子非收缩的挑战。


<details>
  <summary>Details</summary>
Motivation: 在RCMDPs中，强对偶性的缺失阻碍了标准对偶方法在约束强化学习中的直接应用，同时平均成本设置下鲁棒贝尔曼算子在任何范数下都不是收缩的，这增加了求解难度。

Method: 设计了一个演员-评论家算法，专门针对平均成本RCMDPs，通过新的理论分析框架来处理非收缩性和对偶性问题。

Result: 算法实现了ε-可行性和ε-最优性，在有无松弛假设下的样本复杂度分别为Õ(ε⁻⁴)和Õ(ε⁻⁶)，与折扣设置相当。

Conclusion: 该工作成功解决了平均成本RCMDPs中的关键挑战，为鲁棒约束强化学习提供了有效的算法和理论保证。

Abstract: In this work, we study the problem of finding robust and safe policies in
Robust Constrained Average-Cost Markov Decision Processes (RCMDPs). A key
challenge in this setting is the lack of strong duality, which prevents the
direct use of standard primal-dual methods for constrained RL. Additional
difficulties arise from the average-cost setting, where the Robust Bellman
operator is not a contraction under any norm. To address these challenges, we
propose an actor-critic algorithm for Average-Cost RCMDPs. We show that our
method achieves both \(\epsilon\)-feasibility and \(\epsilon\)-optimality, and
we establish a sample complexities of \(\tilde{O}\left(\epsilon^{-4}\right)\)
and \(\tilde{O}\left(\epsilon^{-6}\right)\) with and without slackness
assumption, which is comparable to the discounted setting.

</details>


### [258] [An Efficient Gradient-Aware Error-Bounded Lossy Compressor for Federated Learning](https://arxiv.org/abs/2511.05770)
*Zhijing Ye,Sheng Di,Jiamin Wang,Zhiqing Zhong,Zhaorui Zhang,Xiaodong Yu*

Main category: cs.LG

TL;DR: 提出针对联邦学习梯度数据的误差有界有损压缩框架，通过跨轮次时间相关性和卷积核结构规律性提高压缩比，在保持模型精度的同时显著减少通信时间


<details>
  <summary>Details</summary>
Motivation: 联邦学习的通信成本限制了其部署，特别是系统异构性下低带宽客户端成为性能瓶颈。现有误差有界有损压缩方法对梯度数据效果不佳，因为梯度张量缺乏空间局部性和平滑性

Method: 开发创新的预测机制：1）基于归一化指数移动平均的跨轮次幅度预测器；2）利用梯度振荡和核级符号一致性的符号预测器。该方法与标准量化器和熵编码器兼容

Result: 新EBLC方法比SZ3压缩比提高1.53倍，精度损失更低。集成到真实FL框架APPFL中，在受限带宽场景下端到端通信时间减少76.1%-96.2%

Conclusion: 该方法为现实世界联邦学习部署提供了强大的可扩展性，通过专门针对梯度数据特性的压缩技术有效解决了通信瓶颈问题

Abstract: Federated learning (FL) enables collaborative model training without exposing
clients' private data, but its deployment is often constrained by the
communication cost of transmitting gradients between clients and the central
server, especially under system heterogeneity where low-bandwidth clients
bottleneck overall performance. Lossy compression of gradient data can mitigate
this overhead, and error-bounded lossy compression (EBLC) is particularly
appealing for its fine-grained utility-compression tradeoff. However, existing
EBLC methods (e.g., SZ), originally designed for smooth scientific data with
strong spatial locality, rely on generic predictors such as Lorenzo and
interpolation for entropy reduction to improve compression ratio. Gradient
tensors, in contrast, exhibit low smoothness and weak spatial correlation,
rendering these predictors ineffective and leading to poor compression ratios.
To address this limitation, we propose an EBLC framework tailored for FL
gradient data to achieve high compression ratios while preserving model
accuracy. The core of it is an innovative prediction mechanism that exploits
temporal correlations across FL training rounds and structural regularities
within convolutional kernels to reduce residual entropy. The predictor is
compatible with standard quantizers and entropy coders and comprises (1) a
cross-round magnitude predictor based on a normalized exponential moving
average, and (2) a sign predictor that leverages gradient oscillation and
kernel-level sign consistency. Experiments show that this new EBLC yields up to
1.53x higher compression ratios than SZ3 with lower accuracy loss. Integrated
into a real-world FL framework, APPFL, it reduces end-to-end communication time
by 76.1%-96.2% under various constrained-bandwidth scenarios, demonstrating
strong scalability for real-world FL deployments.

</details>


### [259] [MARAuder's Map: Motion-Aware Real-time Activity Recognition with Layout-Based Trajectories](https://arxiv.org/abs/2511.05773)
*Zishuai Liu,Weihang You,Jin Lu,Fei Dou*

Main category: cs.LG

TL;DR: 提出了MARAuder's Map框架，通过将传感器数据投影到物理平面图来生成轨迹感知的图像序列，结合混合深度学习模型和可学习时间嵌入模块，实现了实时活动识别。


<details>
  <summary>Details</summary>
Motivation: 解决智能家居中基于环境传感器的人类活动识别面临的实时推理、空间定位推理和上下文感知时间建模等挑战。现有方法依赖预分割数据且忽略物理环境布局，限制了在连续真实场景中的鲁棒性。

Method: 将传感器激活投影到物理平面图生成轨迹感知的图像序列；使用混合深度学习模型联合捕捉空间结构和时间依赖；引入可学习时间嵌入模块编码上下文线索；采用基于注意力的编码器选择性关注信息丰富的片段。

Result: 在多个真实世界智能家居数据集上的广泛实验表明，该方法优于强基线方法。

Conclusion: MARAuder's Map为环境传感器环境中的实时人类活动识别提供了实用解决方案，能够有效处理跨活动转换和时间模糊性。

Abstract: Ambient sensor-based human activity recognition (HAR) in smart homes remains
challenging due to the need for real-time inference, spatially grounded
reasoning, and context-aware temporal modeling. Existing approaches often rely
on pre-segmented, within-activity data and overlook the physical layout of the
environment, limiting their robustness in continuous, real-world deployments.
In this paper, we propose MARAuder's Map, a novel framework for real-time
activity recognition from raw, unsegmented sensor streams. Our method projects
sensor activations onto the physical floorplan to generate trajectory-aware,
image-like sequences that capture the spatial flow of human movement. These
representations are processed by a hybrid deep learning model that jointly
captures spatial structure and temporal dependencies. To enhance temporal
awareness, we introduce a learnable time embedding module that encodes
contextual cues such as hour-of-day and day-of-week. Additionally, an
attention-based encoder selectively focuses on informative segments within each
observation window, enabling accurate recognition even under cross-activity
transitions and temporal ambiguity. Extensive experiments on multiple
real-world smart home datasets demonstrate that our method outperforms strong
baselines, offering a practical solution for real-time HAR in ambient sensor
environments.

</details>


### [260] [SymLight: Exploring Interpretable and Deployable Symbolic Policies for Traffic Signal Control](https://arxiv.org/abs/2511.05790)
*Xiao-Cheng Liao,Yi Mei,Mengjie Zhang*

Main category: cs.LG

TL;DR: SymLight是一个基于蒙特卡洛树搜索的符号化优先级函数搜索框架，用于生成可解释且可部署的交通信号控制策略，解决了深度强化学习策略参数过多和不可解释的问题。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习在交通信号控制中取得了成功，但神经网络策略往往参数过多且不透明，阻碍了其可解释性和在资源受限边缘设备上的部署。

Method: 使用蒙特卡洛树搜索来发现符号化优先级函数，提出简洁但表达能力强的优先级函数表示方法，并引入概率结构rollout策略来利用高质量优先级函数的结构模式。

Result: 在真实世界数据集上的实验表明，SymLight在多个基线方法上表现出优越性能，能够生成可解释且可部署的交通信号控制策略。

Conclusion: SymLight能够在保持优异性能的同时，生成可解释和可部署的交通信号控制策略，解决了深度强化学习策略的部署和解释性问题。

Abstract: Deep Reinforcement Learning have achieved significant success in
automatically devising effective traffic signal control (TSC) policies. Neural
policies, however, tend to be over-parameterized and non-transparent, hindering
their interpretability and deployability on resource-limited edge devices. This
work presents SymLight, a priority function search framework based on Monte
Carlo Tree Search (MCTS) for discovering inherently interpretable and
deployable symbolic priority functions to serve as the TSC policies. The
priority function, in particular, accepts traffic features as input and then
outputs a priority for each traffic signal phase, which subsequently directs
the phase transition. For effective search, we propose a concise yet expressive
priority function representation. This helps mitigate the combinatorial
explosion of the action space in MCTS. Additionally, a probabilistic structural
rollout strategy is introduced to leverage structural patterns from previously
discovered high-quality priority functions, guiding the rollout process. Our
experiments on real-world datasets demonstrate SymLight's superior performance
across a range of baselines. A key advantage is SymLight's ability to produce
interpretable and deployable TSC policies while maintaining excellent
performance.

</details>


### [261] [Beyond the Lower Bound: Bridging Regret Minimization and Best Arm Identification in Lexicographic Bandits](https://arxiv.org/abs/2511.05802)
*Bo Xue,Yuanyu Wan,Zhichao Lu,Qingfu Zhang*

Main category: cs.LG

TL;DR: 该论文在具有分层偏好的多目标决策中，提出了两种基于消除的算法来同时解决遗憾最小化和最佳臂识别问题，其中第二种算法通过跨目标信息共享超越了单目标老虎机问题的已知下界。


<details>
  <summary>Details</summary>
Motivation: 在多目标分层偏好决策中，虽然现有研究主要关注遗憾最小化，但本文旨在填补遗憾最小化和最佳臂识别之间的空白，探索如何在优先目标顺序下同时优化这两个目标。

Method: 提出了两种基于消除的算法：第一种算法按目标优先级逐层顺序消除次优臂；第二种算法在每轮中同时利用所有目标的奖励信息，有效利用跨目标依赖关系。

Result: 第一种算法实现了与最佳单目标算法相当的样本复杂度和遗憾界；第二种算法显著超越了单目标老虎机问题的已知下界，证明了多目标设置中跨目标信息共享的优势。实证结果进一步验证了两种算法相对于基线的优越性能。

Conclusion: 该研究证明了在多目标分层偏好设置中，通过精心设计的算法可以同时实现遗憾最小化和最佳臂识别，特别是跨目标信息共享能够带来显著的性能提升，为多目标决策问题提供了新的解决方案。

Abstract: In multi-objective decision-making with hierarchical preferences,
lexicographic bandits provide a natural framework for optimizing multiple
objectives in a prioritized order. In this setting, a learner repeatedly
selects arms and observes reward vectors, aiming to maximize the reward for the
highest-priority objective, then the next, and so on. While previous studies
have primarily focused on regret minimization, this work bridges the gap
between \textit{regret minimization} and \textit{best arm identification} under
lexicographic preferences. We propose two elimination-based algorithms to
address this joint objective. The first algorithm eliminates suboptimal arms
sequentially, layer by layer, in accordance with the objective priorities, and
achieves sample complexity and regret bounds comparable to those of the best
single-objective algorithms. The second algorithm simultaneously leverages
reward information from all objectives in each round, effectively exploiting
cross-objective dependencies. Remarkably, it outperforms the known lower bound
for the single-objective bandit problem, highlighting the benefit of
cross-objective information sharing in the multi-objective setting. Empirical
results further validate their superior performance over baselines.

</details>


### [262] [Catching Contamination Before Generation: Spectral Kill Switches for Agents](https://arxiv.org/abs/2511.05804)
*Valentin Noël*

Main category: cs.LG

TL;DR: 提出一种无需额外训练的实时诊断方法，通过分析注意力机制产生的token图，在早期层计算高频能量比和谱熵来检测上下文不一致性，实现毫秒级错误检测。


<details>
  <summary>Details</summary>
Motivation: 多步推理链中的中间步骤可能因上下文不一致、检索错误或对抗性输入而损坏，传统事后评估为时已晚，错误会在检测前传播。

Method: 利用前向传播分析注意力诱导的token图，计算早期层的两个谱统计量（高频能量比和谱熵），基于双机制混合假设建立单阈值贝叶斯最优检测器。

Result: 高频能量比在多个模型家族中表现出稳健的双峰性，可实现低于1毫秒的决策延迟，成功集成到检索增强代理管道中作为内联安全监控器。

Conclusion: 该方法能在模型处理文本时实时检测污染，在错误固化到推理链之前进行干预，为代理语言模型提供了有效的实时安全监控方案。

Abstract: Agentic language models compose multi step reasoning chains, yet intermediate
steps can be corrupted by inconsistent context, retrieval errors, or
adversarial inputs, which makes post hoc evaluation too late because errors
propagate before detection. We introduce a diagnostic that requires no
additional training and uses only the forward pass to emit a binary accept or
reject signal during agent execution. The method analyzes token graphs induced
by attention and computes two spectral statistics in early layers, namely the
high frequency energy ratio and spectral entropy. We formalize these signals,
establish invariances, and provide finite sample estimators with uncertainty
quantification. Under a two regime mixture assumption with a monotone
likelihood ratio property, we show that a single threshold on the high
frequency energy ratio is optimal in the Bayes sense for detecting context
inconsistency. Empirically, the high frequency energy ratio exhibits robust
bimodality during context verification across multiple model families, which
enables gating decisions with overhead below one millisecond on our hardware
and configurations. We demonstrate integration into retrieval augmented agent
pipelines and discuss deployment as an inline safety monitor. The approach
detects contamination while the model is still processing the text, before
errors commit to the reasoning chain.

</details>


### [263] [Measuring Model Performance in the Presence of an Intervention](https://arxiv.org/abs/2511.05805)
*Winston Chen,Michael W. Sjoding,Jenna Wiens*

Main category: cs.LG

TL;DR: 论文提出了一种利用RCT所有数据进行无偏模型评估的方法NPW，解决了传统方法忽略治疗组数据导致效率低下的问题。


<details>
  <summary>Details</summary>
Motivation: 在AI社会影响应用中，干预措施的存在会偏倚模型评估结果。传统方法仅使用对照组数据进行评估，浪费了宝贵的治疗组数据，特别是在复杂且昂贵的RCT场景下效率低下。

Method: 提出了NPW方法，通过重新加权治疗组数据，模拟在无干预情况下样本的分布，从而实现无偏的模型评估。

Result: 在合成和真实数据集上的实验表明，NPW方法在各种干预效应和样本量设置下，都比忽略治疗组数据的标准方法具有更好的模型选择性能。

Conclusion: 该研究为现实场景中更高效的模型评估提供了有效解决方案，能够充分利用RCT数据，提高评估的准确性和效率。

Abstract: AI models are often evaluated based on their ability to predict the outcome
of interest. However, in many AI for social impact applications, the presence
of an intervention that affects the outcome can bias the evaluation. Randomized
controlled trials (RCTs) randomly assign interventions, allowing data from the
control group to be used for unbiased model evaluation. However, this approach
is inefficient because it ignores data from the treatment group. Given the
complexity and cost often associated with RCTs, making the most use of the data
is essential. Thus, we investigate model evaluation strategies that leverage
all data from an RCT. First, we theoretically quantify the estimation bias that
arises from na\"ively aggregating performance estimates from treatment and
control groups, and derive the condition under which this bias leads to
incorrect model selection. Leveraging these theoretical insights, we propose
nuisance parameter weighting (NPW), an unbiased model evaluation approach that
reweights data from the treatment group to mimic the distributions of samples
that would or would not experience the outcome under no intervention. Using
synthetic and real-world datasets, we demonstrate that our proposed evaluation
approach consistently yields better model selection than the standard approach,
which ignores data from the treatment group, across various intervention effect
and sample size settings. Our contribution represents a meaningful step towards
more efficient model evaluation in real-world contexts.

</details>


### [264] [MOSS: Efficient and Accurate FP8 LLM Training with Microscaling and Automatic Scaling](https://arxiv.org/abs/2511.05811)
*Yu Zhang,Hui-Ling Zhen,Mingxuan Yuan,Bei Yu*

Main category: cs.LG

TL;DR: MOSS是一个新型FP8训练框架，通过两级微缩放策略和自动权重缩放，在保持训练稳定性的同时显著提升效率，7B参数模型训练吞吐量比BF16基线提高34%。


<details>
  <summary>Details</summary>
Motivation: FP8训练具有显著效率优势，但现有方法存在去量化开销大和在线量化效率低的问题，需要平衡精度与效率。

Method: 提出两级微缩放策略（高精度全局缩放+紧凑的幂次局部缩放）和线性层自动权重缩放，避免昂贵的最大缩减操作。

Result: 在7B参数模型上实现与BF16基线相当的性能，训练吞吐量提升高达34%。

Conclusion: MOSS框架成功解决了FP8训练中的精度与效率平衡问题，为大规模语言模型训练提供了高效解决方案。

Abstract: Training large language models with FP8 formats offers significant efficiency
gains. However, the reduced numerical precision of FP8 poses challenges for
stable and accurate training. Current frameworks preserve training performance
using mixed-granularity quantization, i.e., applying per-group quantization for
activations and per-tensor/block quantization for weights. While effective,
per-group quantization requires scaling along the inner dimension of matrix
multiplication, introducing additional dequantization overhead. Moreover, these
frameworks often rely on just-in-time scaling to dynamically adjust scaling
factors based on the current data distribution. However, this online
quantization is inefficient for FP8 training, as it involves multiple memory
reads and writes that negate the performance benefits of FP8. To overcome these
limitations, we propose MOSS, a novel FP8 training framework that ensures both
efficiency and numerical stability. MOSS introduces two key innovations: (1) a
two-level microscaling strategy for quantizing sensitive activations, which
balances precision and dequantization cost by combining a high-precision global
scale with compact, power-of-two local scales; and (2) automatic scaling for
weights in linear layers, which eliminates the need for costly max-reduction
operations by predicting and adjusting scaling factors during training.
Leveraging these techniques, MOSS enables efficient FP8 training of a 7B
parameter model, achieving performance comparable to the BF16 baseline while
achieving up to 34% higher training throughput.

</details>


### [265] [In-depth Analysis on Caching and Pre-fetching in Mixture of Experts Offloading](https://arxiv.org/abs/2511.05814)
*Shuning Lin,Yifan He,Yitong Chen*

Main category: cs.LG

TL;DR: 本文深入研究了MoE模型的卸载技术，提出了基于LFU的缓存优化和推测性专家预取方法，显著提升了MoE模型在内存受限环境下的部署效率。


<details>
  <summary>Details</summary>
Motivation: MoE模型由于其独特的架构需要比密集模型更多的内存，在GPU内存受限的环境（如边缘设备）中部署困难。现有的MoE卸载技术缓存算法不够优化，缺乏深入分析。

Method: 1. 详细分析专家激活和LRU缓存行为并提供跟踪数据；2. 基于分析提出LFU缓存优化；3. 实现并实验推测性专家预取；4. 全面研究MoE架构本身的行为特性。

Result: LFU缓存优化相比LRU取得了显著改进，推测性专家预取显示出巨大潜力。研究还提供了关于门控网络和专家特性的详细信息。

Conclusion: 本研究为MoE模型的解释和剪枝技术开发提供了基础，有助于在保持最小性能损失的前提下优化MoE架构。

Abstract: In today's landscape, Mixture of Experts (MoE) is a crucial architecture that
has been used by many of the most advanced models. One of the major challenges
of MoE models is that they usually require much more memory than their dense
counterparts due to their unique architecture, and hence are harder to deploy
in environments with limited GPU memory, such as edge devices. MoE offloading
is a promising technique proposed to overcome this challenge, especially if it
is enhanced with caching and pre-fetching, but prior work stopped at suboptimal
caching algorithm and offered limited insights. In this work, we study MoE
offloading in depth and make the following contributions: 1. We analyze the
expert activation and LRU caching behavior in detail and provide traces. 2. We
propose LFU caching optimization based on our analysis and obtain strong
improvements from LRU. 3. We implement and experiment speculative expert
pre-fetching, providing detailed trace showing its huge potential . 4. In
addition, our study extensively covers the behavior of the MoE architecture
itself, offering information on the characteristic of the gating network and
experts. This can inspire future work on the interpretation of MoE models and
the development of pruning techniques for MoE architecture with minimal
performance loss.

</details>


### [266] [AiEDA: An Open-Source AI-Aided Design Library for Design-to-Vector](https://arxiv.org/abs/2511.05823)
*Yihang Qiu,Zengrong Huang,Simin Tao,Hongda Zhang,Weiguo Li,Xinhua Lai,Rui Wang,Weiqiang Wang,Xingquan Li*

Main category: cs.LG

TL;DR: AiEDA是一个统一的开源EDA库，通过将芯片设计数据转换为通用多级向量表示，解决了AI-EDA基础设施碎片化问题，并生成了600GB的结构化数据集iDATA。


<details>
  <summary>Details</summary>
Motivation: 当前AI-EDA基础设施存在碎片化问题，包括流程引擎分散、数据交换格式异构、数据提取方法不标准化以及数据存储组织混乱，缺乏从设计执行到AI集成的完整数据管道解决方案。

Method: 开发AiEDA统一开源库，集成多种设计到向量的数据表示技术，将不同的芯片设计数据转换为通用多级向量表示，建立AI辅助设计范式，提供完整的物理设计流程和标准化Python接口。

Result: 基于AiEDA生成了iDATA数据集，包含600GB结构化数据，来自50个真实芯片设计（28nm），在7个代表性AAD任务中验证了有效性，涵盖预测、生成、优化和分析任务。

Conclusion: AiEDA为AI-EDA研究提供了统一的基础设施，代码已开源，iDATA数据集即将公开发布，为未来AI-EDA研究奠定了基础。

Abstract: Recent research has demonstrated that artificial intelligence (AI) can assist
electronic design automation (EDA) in improving both the quality and efficiency
of chip design. But current AI for EDA (AI-EDA) infrastructures remain
fragmented, lacking comprehensive solutions for the entire data pipeline from
design execution to AI integration. Key challenges include fragmented flow
engines that generate raw data, heterogeneous file formats for data exchange,
non-standardized data extraction methods, and poorly organized data storage.
This work introduces a unified open-source library for EDA (AiEDA) that
addresses these issues. AiEDA integrates multiple design-to-vector data
representation techniques that transform diverse chip design data into
universal multi-level vector representations, establishing an AI-aided design
(AAD) paradigm optimized for AI-EDA workflows. AiEDA provides complete physical
design flows with programmatic data extraction and standardized Python
interfaces bridging EDA datasets and AI frameworks. Leveraging the AiEDA
library, we generate iDATA, a 600GB dataset of structured data derived from 50
real chip designs (28nm), and validate its effectiveness through seven
representative AAD tasks spanning prediction, generation, optimization and
analysis. The code is publicly available at
https://github.com/OSCC-Project/AiEDA, while the full iDATA dataset is being
prepared for public release, providing a foundation for future AI-EDA research.

</details>


### [267] [CADM: Cluster-customized Adaptive Distance Metric for Categorical Data Clustering](https://arxiv.org/abs/2511.05826)
*Taixi Chen,Yiu-ming Cheung,Yiqun Zhang*

Main category: cs.LG

TL;DR: 提出了一种针对分类数据聚类的聚类定制距离度量方法，能够根据每个聚类中属性的不同分布竞争性地更新距离，并扩展到混合数据类型。


<details>
  <summary>Details</summary>
Motivation: 分类数据聚类中合适的距离度量至关重要，但由于分类数据无法直接计算距离，且不同聚类中属性值之间的距离通常因分布不同而变化，现有方法未考虑这一点导致距离测量不合理。

Method: 开发了一种聚类定制距离度量方法，基于每个聚类中属性的不同分布来竞争性地更新距离，并将该方法扩展到包含数值和分类属性的混合数据。

Result: 实验表明该方法有效，在14个数据集上平均排名约为第一。

Conclusion: 提出的聚类定制距离度量方法能够有效解决分类数据聚类中的距离测量问题，并在多个数据集上表现出优越性能。

Abstract: An appropriate distance metric is crucial for categorical data clustering, as
the distance between categorical data cannot be directly calculated. However,
the distances between attribute values usually vary in different clusters
induced by their different distributions, which has not been taken into
account, thus leading to unreasonable distance measurement. Therefore, we
propose a cluster-customized distance metric for categorical data clustering,
which can competitively update distances based on different distributions of
attributes in each cluster. In addition, we extend the proposed distance metric
to the mixed data that contains both numerical and categorical attributes.
Experiments demonstrate the efficacy of the proposed method, i.e., achieving an
average ranking of around first in fourteen datasets. The source code is
available at https://anonymous.4open.science/r/CADM-47D8

</details>


### [268] [Predicting the Future by Retrieving the Past](https://arxiv.org/abs/2511.05859)
*Dazhao Du,Tao Han,Song Guo*

Main category: cs.LG

TL;DR: 提出PFRP方法，通过检索全局历史数据来增强时间序列预测准确性，解决现有模型无法显式利用全局历史信息的问题


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型（如MLP、Transformer、TCN）在单变量时间序列预测中仅依赖滑动窗口的局部上下文，无法显式动态访问训练过程中学到的全局历史知识，导致全局丰富模式未被充分利用

Method: 构建全局记忆库(GMB)存储和管理全局历史模式，使用检索机制从GMB中提取相似模式生成全局预测，然后将全局预测与任何局部预测模型的输出自适应结合

Result: 在7个真实世界数据集上的实验表明，PFRP能将先进单变量预测模型的平均性能提升8.4%

Conclusion: PFRP通过显式整合全局历史数据，能够产生更准确和可解释的预测，有效弥补了现有模型在利用全局历史信息方面的不足

Abstract: Deep learning models such as MLP, Transformer, and TCN have achieved
remarkable success in univariate time series forecasting, typically relying on
sliding window samples from historical data for training. However, while these
models implicitly compress historical information into their parameters during
training, they are unable to explicitly and dynamically access this global
knowledge during inference, relying only on the local context within the
lookback window. This results in an underutilization of rich patterns from the
global history. To bridge this gap, we propose Predicting the Future by
Retrieving the Past (PFRP), a novel approach that explicitly integrates global
historical data to enhance forecasting accuracy. Specifically, we construct a
Global Memory Bank (GMB) to effectively store and manage global historical
patterns. A retrieval mechanism is then employed to extract similar patterns
from the GMB, enabling the generation of global predictions. By adaptively
combining these global predictions with the outputs of any local prediction
model, PFRP produces more accurate and interpretable forecasts. Extensive
experiments conducted on seven real-world datasets demonstrate that PFRP
significantly enhances the average performance of advanced univariate
forecasting models by 8.4\%. Codes can be found in
https://github.com/ddz16/PFRP.

</details>


### [269] [EMOD: A Unified EEG Emotion Representation Framework Leveraging V-A Guided Contrastive Learning](https://arxiv.org/abs/2511.05863)
*Yuning Chen,Sha Zhao,Shijian Li,Gang Pan*

Main category: cs.LG

TL;DR: 提出EMOD框架，通过基于效价-唤醒度的对比学习统一处理多源EEG情感数据，解决跨数据集泛化问题


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在单一EEG情感数据集上表现良好，但由于标注方案和数据格式的异质性，跨数据集泛化能力有限，需要统一的表示学习框架

Method: 使用V-A空间统一情感标签，设计软加权监督对比损失；采用三重域编码器和时空Transformer的灵活架构提取时频空特征

Result: 在8个公开EEG数据集上预训练，在3个基准数据集上达到SOTA性能，表现出强大的适应性和泛化能力

Conclusion: EMOD框架能够有效学习可迁移的情感感知表示，为跨数据集EEG情感识别提供了统一解决方案

Abstract: Emotion recognition from EEG signals is essential for affective computing and
has been widely explored using deep learning. While recent deep learning
approaches have achieved strong performance on single EEG emotion datasets,
their generalization across datasets remains limited due to the heterogeneity
in annotation schemes and data formats. Existing models typically require
dataset-specific architectures tailored to input structure and lack semantic
alignment across diverse emotion labels. To address these challenges, we
propose EMOD: A Unified EEG Emotion Representation Framework Leveraging
Valence-Arousal (V-A) Guided Contrastive Learning. EMOD learns transferable and
emotion-aware representations from heterogeneous datasets by bridging both
semantic and structural gaps. Specifically, we project discrete and continuous
emotion labels into a unified V-A space and formulate a soft-weighted
supervised contrastive loss that encourages emotionally similar samples to
cluster in the latent space. To accommodate variable EEG formats, EMOD employs
a flexible backbone comprising a Triple-Domain Encoder followed by a
Spatial-Temporal Transformer, enabling robust extraction and integration of
temporal, spectral, and spatial features. We pretrain EMOD on eight public EEG
datasets and evaluate its performance on three benchmark datasets. Experimental
results show that EMOD achieves state-of-the-art performance, demonstrating
strong adaptability and generalization across diverse EEG-based emotion
recognition scenarios.

</details>


### [270] [Adaptation and Fine-tuning with TabPFN for Travelling Salesman Problem](https://arxiv.org/abs/2511.05872)
*Nguyen Gia Hien Vu,Yifan Tang,Rey Lim,Yifan Yang,Hang Ma,Ke Wang,G. Gary Wang*

Main category: cs.LG

TL;DR: 该论文首次将TabPFN基础模型应用于组合优化问题，特别是旅行商问题(TSP)，以解决传统方法在时间和数据密集型训练方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 减轻传统组合优化方法（包括精确算法、启发式算法和基于机器学习的模型）在时间和数据密集型训练方面的挑战，探索在训练资源受限和快速部署需求下高效解决结构化问题的可能性。

Method: 采用基于节点的方法和节点预测适应策略来构建完整的TSP路径，对TabPFN模型进行适应和微调，使用单个样本进行训练。

Result: TabPFN需要最少的训练，使用单个样本即可适应TSP，在不同规模的TSP实例上表现出更好的泛化能力，减少性能下降，训练过程在几分钟内完成，即使没有后处理也能获得强解质量。

Conclusion: TabPFN模型是在训练资源受限和快速部署需求下解决结构化和组合优化问题的有前景的方法，其性能可与经过后处理精炼的其他模型相媲美。

Abstract: Tabular Prior-Data Fitted Network (TabPFN) is a foundation model designed for
small to medium-sized tabular data, which has attracted much attention
recently. This paper investigates the application of TabPFN in Combinatorial
Optimization (CO) problems. The aim is to lessen challenges in time and
data-intensive training requirements often observed in using traditional
methods including exact and heuristic algorithms, Machine Learning (ML)-based
models, to solve CO problems. Proposing possibly the first ever application of
TabPFN for such a purpose, we adapt and fine-tune the TabPFN model to solve the
Travelling Salesman Problem (TSP), one of the most well-known CO problems.
Specifically, we adopt the node-based approach and the node-predicting
adaptation strategy to construct the entire TSP route. Our evaluation with
varying instance sizes confirms that TabPFN requires minimal training, adapts
to TSP using a single sample, performs better generalization across varying TSP
instance sizes, and reduces performance degradation. Furthermore, the training
process with adaptation and fine-tuning is completed within minutes. The
methodology leads to strong solution quality even without post-processing and
achieves performance comparable to other models with post-processing
refinement. Our findings suggest that the TabPFN model is a promising approach
to solve structured and CO problems efficiently under training resource
constraints and rapid deployment requirements.

</details>


### [271] [FusionLog: Cross-System Log-based Anomaly Detection via Fusion of General and Proprietary Knowledge](https://arxiv.org/abs/2511.05878)
*Xinlong Zhao,Tong Jia,Minghua He,Xixuan Yang,Ying Li*

Main category: cs.LG

TL;DR: FusionLog是一种零标签跨系统日志异常检测方法，通过融合通用知识和专有知识，无需目标系统标注数据即可实现高性能异常检测


<details>
  <summary>Details</summary>
Motivation: 解决现有跨系统日志异常检测方法仅关注通用知识迁移，忽视通用知识与目标系统专有知识之间不匹配的问题

Method: 设计基于语义相似度的无训练路由器将目标日志分为通用日志和专有日志，对通用日志使用系统无关表示元学习的小模型，对专有日志通过LLM和SM的多轮协同知识蒸馏生成伪标签并微调模型

Result: 在三个公共日志数据集上的实验结果显示，FusionLog在完全零标签设置下达到超过90%的F1分数，显著优于现有最先进方法

Conclusion: FusionLog通过有效融合通用和专有知识，实现了无需目标系统标注的高性能跨系统日志异常检测

Abstract: Log-based anomaly detection is critical for ensuring the stability and
reliability of web systems. One of the key problems in this task is the lack of
sufficient labeled logs, which limits the rapid deployment in new systems.
Existing works usually leverage large-scale labeled logs from a mature web
system and a small amount of labeled logs from a new system, using transfer
learning to extract and generalize general knowledge across both domains.
However, these methods focus solely on the transfer of general knowledge and
neglect the disparity and potential mismatch between such knowledge and the
proprietary knowledge of target system, thus constraining performance. To
address this limitation, we propose FusionLog, a novel zero-label cross-system
log-based anomaly detection method that effectively achieves the fusion of
general and proprietary knowledge, enabling cross-system generalization without
any labeled target logs. Specifically, we first design a training-free router
based on semantic similarity that dynamically partitions unlabeled target logs
into 'general logs' and 'proprietary logs.' For general logs, FusionLog employs
a small model based on system-agnostic representation meta-learning for direct
training and inference, inheriting the general anomaly patterns shared between
the source and target systems. For proprietary logs, we iteratively generate
pseudo-labels and fine-tune the small model using multi-round collaborative
knowledge distillation and fusion based on large language model (LLM) and small
model (SM) to enhance its capability to recognize anomaly patterns specific to
the target system. Experimental results on three public log datasets from
different systems show that FusionLog achieves over 90% F1-score under a fully
zero-label setting, significantly outperforming state-of-the-art cross-system
log-based anomaly detection methods.

</details>


### [272] [Physics-Informed Neural Networks for Real-Time Gas Crossover Prediction in PEM Electrolyzers: First Application with Multi-Membrane Validation](https://arxiv.org/abs/2511.05879)
*Yong-Woon Kim,Chulung Kang,Yung-Cheol Byun*

Main category: cs.LG

TL;DR: 本文提出了首个基于物理信息神经网络（PINN）的氢交叉预测模型，将物理定律与神经网络结合，实现了高精度、实时的电解槽安全监测。


<details>
  <summary>Details</summary>
Motivation: PEM水电解制氢过程中氢交叉问题威胁安全和经济性，现有物理模型计算复杂，数据驱动方法泛化能力差，无法满足动态电解槽操作的实时监测需求。

Method: 采用物理信息神经网络（PINN），整合质量守恒、菲克扩散定律和亨利溶解度定律，构建紧凑架构（17,793参数），在工业相关条件下验证。

Result: 模型在6种膜上验证，达到极高精度（R²=99.84%，RMSE=0.0348%），推理时间亚毫秒级，压力预测范围超出训练数据2.5倍时仍保持R²>86%，显著优于纯神经网络（R²=43.4%）。

Conclusion: 该工作建立了实时电解槽监测新范式，通过结合物理严谨性和计算效率，加速安全高效绿色氢基础设施的部署，助力净零排放目标。

Abstract: Green hydrogen production via polymer electrolyte membrane (PEM) water
electrolysis is pivotal for energy transition, yet hydrogen crossover through
membranes threatens safety and economic viability-approaching explosive limits
(4 mol% H$_2$ in O$_2$) while reducing Faradaic efficiency by 2.5%. Current
physics-based models require extensive calibration and computational resources
that preclude real-time implementation, while purely data-driven approaches
fail to extrapolate beyond training conditions-critical for dynamic
electrolyzer operation. Here we present the first application of
physics-informed neural networks (PINNs) for hydrogen crossover prediction,
integrating mass conservation, Fick's diffusion law, and Henry's solubility law
within a compact architecture (17,793 parameters). Validated across six
membranes under industrially relevant conditions (0.05-5.0 A/cm$^2$, 1-200 bar,
25-85{\deg}C), our PINN achieves exceptional accuracy (R$^2$ = 99.84%, RMSE =
0.0348%) with sub-millisecond inference times suitable for real-time control.
Remarkably, the model maintains R$^2$ > 86% when predicting crossover at
pressures 2.5x beyond training range-substantially outperforming pure neural
networks (R$^2$ = 43.4%). The hardware-agnostic deployment, from desktop CPUs
to edge devices (Raspberry Pi 4), enables distributed safety monitoring
essential for gigawatt-scale installations. By bridging physical rigor and
computational efficiency, this work establishes a new paradigm for real-time
electrolyzer monitoring, accelerating deployment of safe, efficient green
hydrogen infrastructure crucial for net-zero emissions targets.

</details>


### [273] [From Kernels to Attention: A Transformer Framework for Density and Score Estimation](https://arxiv.org/abs/2511.05924)
*Vasily Ilin,Peter Sushko*

Main category: cs.LG

TL;DR: 本文提出了一个统一的基于注意力的框架，用于联合分数和密度估计。该方法将问题构建为序列到序列任务，开发了一个置换和仿射等变的transformer，能够直接从i.i.d.样本中估计概率密度f(x)及其分数∇x log f(x)。


<details>
  <summary>Details</summary>
Motivation: 传统分数匹配方法需要为每个分布训练单独的模型，缺乏通用性。本文旨在开发一个分布无关的算子，能够跨密度和样本大小进行泛化。

Method: 使用基于注意力的transformer架构，通过交叉注意力连接观测样本与任意查询点，内置对称约束确保对置换和仿射变换的等变性。分析表明注意力权重可以恢复经典核密度估计(KDE)。

Result: 实验证明该模型相比KDE和分数去偏KDE(SD-KDE)实现了显著更低的误差和更好的缩放性能，同时具有更好的运行时缩放特性。

Conclusion: 这些结果确立了transformer作为非参数密度和分数估计的通用、数据自适应算子。

Abstract: We introduce a unified attention-based framework for joint score and density
estimation. Framing the problem as a sequence-to-sequence task, we develop a
permutation- and affine-equivariant transformer that estimates both the
probability density $f(x)$ and its score $\nabla_x \log f(x)$ directly from
i.i.d. samples. Unlike traditional score-matching methods that require training
a separate model for each distribution, our approach learns a single
distribution-agnostic operator that generalizes across densities and sample
sizes. The architecture employs cross-attention to connect observed samples
with arbitrary query points, enabling generalization beyond the training data,
while built-in symmetry constraints ensure equivariance to permutation and
affine transformations. Analytically, we show that the attention weights can
recover classical kernel density estimation (KDE), and verify it empirically,
establishing a principled link between classical KDE and the transformer
architecture. Empirically, the model achieves substantially lower error and
better scaling than KDE and score-debiased KDE (SD-KDE), while exhibiting
better runtime scaling. Together, these results establish transformers as
general-purpose, data-adaptive operators for nonparametric density and score
estimation.

</details>


### [274] [Scalable Verification of Neural Control Barrier Functions Using Linear Bound Propagation](https://arxiv.org/abs/2511.06341)
*Nikolaus Vertovec,Frederik Baymler Mathiesen,Thom Badings,Luca Laurenti,Alessandro Abate*

Main category: cs.LG

TL;DR: 提出了一种基于分段线性上下界的新型神经网络控制屏障函数验证框架，解决了传统验证方法计算效率低的问题，能够扩展到更大的神经网络。


<details>
  <summary>Details</summary>
Motivation: 神经网络控制屏障函数在非线性动力系统安全认证中表现出色，但验证神经网络是否为有效CBF存在计算瓶颈，限制了网络规模的应用。

Method: 结合线性边界传播和McCormick松弛技术，计算神经网络梯度的线性上下界，并通过并行化细化策略自适应优化边界计算区域。

Result: 该方法适用于任意控制仿射系统和广泛非线性激活函数，在数值实验中显示出比现有验证方法更好的可扩展性。

Conclusion: 提出的验证框架有效解决了神经网络CBF验证的计算瓶颈问题，为大规模神经网络在安全关键系统中的应用提供了可行方案。

Abstract: Control barrier functions (CBFs) are a popular tool for safety certification
of nonlinear dynamical control systems. Recently, CBFs represented as neural
networks have shown great promise due to their expressiveness and applicability
to a broad class of dynamics and safety constraints. However, verifying that a
trained neural network is indeed a valid CBF is a computational bottleneck that
limits the size of the networks that can be used. To overcome this limitation,
we present a novel framework for verifying neural CBFs based on piecewise
linear upper and lower bounds on the conditions required for a neural network
to be a CBF. Our approach is rooted in linear bound propagation (LBP) for
neural networks, which we extend to compute bounds on the gradients of the
network. Combined with McCormick relaxation, we derive linear upper and lower
bounds on the CBF conditions, thereby eliminating the need for computationally
expensive verification procedures. Our approach applies to arbitrary
control-affine systems and a broad range of nonlinear activation functions. To
reduce conservatism, we develop a parallelizable refinement strategy that
adaptively refines the regions over which these bounds are computed. Our
approach scales to larger neural networks than state-of-the-art verification
procedures for CBFs, as demonstrated by our numerical experiments.

</details>


### [275] [Deep Survival Analysis of Longitudinal EHR Data for Joint Prediction of Hospitalization and Death in COPD Patients](https://arxiv.org/abs/2511.05960)
*Enrico Manzini,Thomas Gonzalez Saito,Joan Escudero,Ana Génova,Cristina Caso,Tomas Perez-Porcuna,Alexandre Perera-Lluna*

Main category: cs.LG

TL;DR: 该研究使用深度学习模型预测COPD患者的住院和死亡风险，发现基于循环架构的深度学习模型在预测准确性上优于传统统计和机器学习方法。


<details>
  <summary>Details</summary>
Motivation: COPD患者住院风险高且与生存率下降密切相关，但预测这些事件发生时间具有挑战性，现有文献对此关注有限。

Method: 使用西班牙加泰罗尼亚SIDIAP数据库2013-2017年超过15万患者的纵向电子健康记录，采用生存分析方法比较统计模型、机器学习和深度学习模型，将住院作为首要事件，死亡作为半竞争性终点事件。

Result: 深度学习模型（特别是基于循环架构的模型）在一致性和时间依赖性AUC方面优于机器学习和线性方法，尤其是对较难预测的住院事件。

Conclusion: 这是首个在COPD患者纵向EHR数据上应用深度生存分析联合预测多时间事件的研究，表明深度学习方法能有效捕捉时间模式并改善风险分层。

Abstract: Patients with chronic obstructive pulmonary disease (COPD) have an increased
risk of hospitalizations, strongly associated with decreased survival, yet
predicting the timing of these events remains challenging and has received
limited attention in the literature. In this study, we performed survival
analysis to predict hospitalization and death in COPD patients using
longitudinal electronic health records (EHRs), comparing statistical models,
machine learning (ML), and deep learning (DL) approaches. We analyzed data from
more than 150k patients from the SIDIAP database in Catalonia, Spain, from 2013
to 2017, modeling hospitalization as a first event and death as a
semi-competing terminal event. Multiple models were evaluated, including Cox
proportional hazards, SurvivalBoost, DeepPseudo, SurvTRACE, Dynamic Deep-Hit,
and Deep Recurrent Survival Machine. Results showed that DL models utilizing
recurrent architectures outperformed both ML and linear approaches in
concordance and time-dependent AUC, especially for hospitalization, which
proved to be the harder event to predict. This study is, to our knowledge, the
first to apply deep survival analysis on longitudinal EHR data to jointly
predict multiple time-to-event outcomes in COPD patients, highlighting the
potential of DL approaches to capture temporal patterns and improve risk
stratification.

</details>


### [276] [Next-Latent Prediction Transformers Learn Compact World Models](https://arxiv.org/abs/2511.05963)
*Jayden Teoh,Manan Tomar,Kwangjun Ahn,Edward S. Hu,Pratyusha Sharma,Riashat Islam,Alex Lamb,John Langford*

Main category: cs.LG

TL;DR: NextLat通过引入潜在空间的自监督预测来增强Transformer，使其学习压缩的历史表示（信念状态），从而改善泛化能力。


<details>
  <summary>Details</summary>
Motivation: 标准Transformer缺乏压缩历史信息的固有机制，导致学习到的解决方案泛化能力差。

Method: 在标准下一个标记预测的基础上，增加潜在空间中的自监督预测目标，训练Transformer预测其下一个潜在状态。

Result: 在多个基准测试中，NextLat在下游准确性、表示压缩和前瞻规划方面显著优于标准训练方法。

Conclusion: NextLat是一种简单高效的范式，能够引导Transformer形成更强大的泛化表示。

Abstract: Transformers replace recurrence with a memory that grows with sequence length
and self-attention that enables ad-hoc look ups over past tokens. Consequently,
they lack an inherent incentive to compress history into compact latent states
with consistent transition rules. This often leads to learning solutions that
generalize poorly. We introduce Next-Latent Prediction (NextLat), which extends
standard next-token training with self-supervised predictions in the latent
space. Specifically, NextLat trains a transformer to learn latent
representations that are predictive of its next latent state given the next
output token. Theoretically, we show that these latents provably converge to
belief states, compressed information of the history necessary to predict the
future. This simple auxiliary objective also injects a recurrent inductive bias
into transformers, while leaving their architecture, parallel training, and
inference unchanged. NextLat effectively encourages the transformer to form
compact internal world models with its own belief states and transition
dynamics -- a crucial property absent in standard next-token prediction
transformers. Empirically, across benchmarks targeting core sequence modeling
competencies -- world modeling, reasoning, planning, and language modeling --
NextLat demonstrates significant gains over standard next-token training in
downstream accuracy, representation compression, and lookahead planning.
NextLat stands as a simple and efficient paradigm for shaping transformer
representations toward stronger generalization.

</details>


### [277] [Explainable Deep Learning-based Classification of Wolff-Parkinson-White Electrocardiographic Signals](https://arxiv.org/abs/2511.05973)
*Alice Ragonesi,Stefania Fresca,Karli Gillette,Stefan Kurath-Koller,Gernot Plank,Elena Zappon*

Main category: cs.LG

TL;DR: 该研究提出了一种结合心脏数字孪生和可解释深度学习的WPW综合征旁路定位方法，在24个心脏区域实现95%以上的定位准确率，并通过XAI方法增强模型透明度。


<details>
  <summary>Details</summary>
Motivation: 传统诊断树和机器学习方法在WPW综合征旁路定位中存在解剖定位分辨率有限、可解释性差、数据集小等问题，需要更准确透明的非侵入性定位方案。

Method: 使用个性化虚拟心脏模型生成大量生理逼真的合成ECG数据，训练深度学习模型进行24区域旁路定位，并集成引导反向传播、Grad-CAM等XAI方法解释模型决策。

Result: 模型定位准确率超过95%，敏感性94.32%，特异性99.78%。XAI验证显示V2导联最关键，其次为aVF、V1和aVL导联。

Conclusion: 心脏数字孪生与可解释深度学习结合能够实现准确、透明、非侵入性的WPW综合征旁路定位，具有临床转化潜力。

Abstract: Wolff-Parkinson-White (WPW) syndrome is a cardiac electrophysiology (EP)
disorder caused by the presence of an accessory pathway (AP) that bypasses the
atrioventricular node, faster ventricular activation rate, and provides a
substrate for atrio-ventricular reentrant tachycardia (AVRT). Accurate
localization of the AP is critical for planning and guiding catheter ablation
procedures. While traditional diagnostic tree (DT) methods and more recent
machine learning (ML) approaches have been proposed to predict AP location from
surface electrocardiogram (ECG), they are often constrained by limited
anatomical localization resolution, poor interpretability, and the use of small
clinical datasets. In this study, we present a Deep Learning (DL) model for the
localization of single manifest APs across 24 cardiac regions, trained on a
large, physiologically realistic database of synthetic ECGs generated using a
personalized virtual heart model. We also integrate eXplainable Artificial
Intelligence (XAI) methods, Guided Backpropagation, Grad-CAM, and Guided
Grad-CAM, into the pipeline. This enables interpretation of DL decision-making
and addresses one of the main barriers to clinical adoption: lack of
transparency in ML predictions. Our model achieves localization accuracy above
95%, with a sensitivity of 94.32% and specificity of 99.78%. XAI outputs are
physiologically validated against known depolarization patterns, and a novel
index is introduced to identify the most informative ECG leads for AP
localization. Results highlight lead V2 as the most critical, followed by aVF,
V1, and aVL. This work demonstrates the potential of combining cardiac digital
twins with explainable DL to enable accurate, transparent, and non-invasive AP
localization.

</details>


### [278] [Kunlun Anomaly Troubleshooter: Enabling Kernel-Level Anomaly Detection and Causal Reasoning for Large Model Distributed Inference](https://arxiv.org/abs/2511.05978)
*Yuyang Liu,Jingjing Cai,Jiayi Ren,Peng Zhou,Danyang Zhang,Yin Du,Shijian Li*

Main category: cs.LG

TL;DR: KAT是首个针对大模型分布式推理的异常诊断框架，通过GPU工作同步性和函数追踪数据实现纳秒级异常检测，结合领域适应LLM提供因果推理，在阿里云生产环境中达到高精度和召回率。


<details>
  <summary>Details</summary>
Motivation: 大模型分布式推理中的异常诊断需要大量专家手动处理，过程耗时且准确率低，亟需自动化解决方案。

Method: KAT采用两个核心创新：1）利用GPU工作同步性和一致性，通过函数追踪数据精确检测内核级异常和硬件组件；2）将检测结果集成到领域适应LLM中，提供系统性因果推理和自然语言解释。

Result: 在阿里云生产环境评估中，KAT在异常检测方面达到0.884的精确度和0.936的召回率，显著缩小诊断范围并提高故障排除效率。

Conclusion: KAT框架有效解决了大模型分布式推理中的异常诊断难题，通过自动化检测和智能分析显著提升了故障排除的效率和成功率。

Abstract: Anomaly troubleshooting for large model distributed inference (LMDI) remains
a critical challenge. Resolving anomalies such as inference performance
degradation or latency jitter in distributed system demands significant manual
efforts from domain experts, resulting in extremely time-consuming diagnosis
processes with relatively low accuracy. In this paper, we introduce Kunlun
Anomaly Troubleshooter (KAT), the first anomaly troubleshooting framework
tailored for LMDI. KAT addresses this problem through two core innovations.
First, KAT exploits the synchronicity and consistency of GPU workers,
innovatively leverages function trace data to precisely detect kernel-level
anomalies and associated hardware components at nanosecond resolution. Second,
KAT integrates these detection results into a domain-adapted LLM, delivering
systematic causal reasoning and natural language interpretation of complex
anomaly symptoms. Evaluations conducted in Alibaba Cloud Service production
environment indicate that KAT achieves over 0.884 precision and 0.936 recall in
anomaly detection, providing detail anomaly insights that significantly narrow
down the diagnostic scope and improve both the efficiency and success rate of
troubleshooting.

</details>


### [279] [Are Time-Indexed Foundation Models the Future of Time Series Imputation?](https://arxiv.org/abs/2511.05980)
*Etienne Le Naour,Tahar Nabil,Adrien Petralia,Ghislain Agoua*

Main category: cs.LG

TL;DR: 本文首次对TabPFN-TS和MoTM这两种时间索引基础模型进行了大规模零样本插补实证研究，展示了它们在不同场景下无需重新训练即可进行缺失值恢复的能力。


<details>
  <summary>Details</summary>
Motivation: 时间序列插补的基础模型研究仍处于探索阶段，TabPFN-TS和MoTM作为新兴的时间索引基础模型，需要系统评估其零样本插补性能。

Method: 在33个域外数据集（约130万个插补窗口）上进行了广泛的单变量实验，评估模型在推理时整合协变量以提高准确性的能力，无需微调。

Result: 研究结果表明，时间索引基础模型是实现现实世界时间序列通用零样本插补的强大且实用的步骤。

Conclusion: 时间索引基础模型为零样本时间序列插补提供了有效解决方案，具有实际应用价值。

Abstract: Foundation models for time series imputation remain largely unexplored.
Recently, two such models, TabPFN-TS and MoTM, have emerged. These models share
a common philosophy that places them within the family of time-indexed
foundation models. This paper presents the first large-scale empirical study of
these models for zero-shot imputation, which enables missing value recovery
without retraining across a wide range of scenarios. We conduct extensive
univariate experiments across 33 out-of-domain datasets (approximately 1.3M
imputation windows) and evaluate their ability to integrate covariates at
inference time to improve accuracy without fine-tuning. Our results demonstrate
that time-indexed foundation models are a powerful and practical step toward
achieving general-purpose, zero-shot imputation for real-world time series.

</details>


### [280] [Bespoke Co-processor for Energy-Efficient Health Monitoring on RISC-V-based Flexible Wearables](https://arxiv.org/abs/2511.05985)
*Theofanis Vergos,Polykarpos Vergos,Mehdi B. Tahoori,Georgios Zervakis*

Main category: cs.LG

TL;DR: 本文提出了一种机械柔性RISC-V处理器，集成定制乘积累加协处理器，通过联合优化协处理器常数和MLP推理操作映射，实现了在柔性电子设备上的高效机器学习分类。


<details>
  <summary>Details</summary>
Motivation: 柔性电子设备在医疗可穿戴领域具有独特优势，但现有系统存在门电路数量有限、特征尺寸大、静态功耗高等问题，难以实现高效的机载机器学习分类。现有可弯曲RISC-V系统缺乏所需的能效。

Method: 设计机械柔性RISC-V处理器，集成定制乘积累加协处理器；通过约束编程问题联合确定协处理器常数和优化MLP推理操作映射；利用柔性技术的低制造成本优势实现紧凑的模型专用硬件。

Result: 后布局结果显示在多个医疗数据集上实现近实时性能，电路功耗符合现有柔性电池预算，面积仅2.42 mm²；相比现有技术平均加速2.35倍，能耗降低2.15倍。

Conclusion: 该技术为可访问、可持续和贴合性医疗可穿戴设备提供了有前景的解决方案，实现了高性能和低功耗的平衡。

Abstract: Flexible electronics offer unique advantages for conformable, lightweight,
and disposable healthcare wearables. However, their limited gate count, large
feature sizes, and high static power consumption make on-body machine learning
classification highly challenging. While existing bendable RISC-V systems
provide compact solutions, they lack the energy efficiency required. We present
a mechanically flexible RISC-V that integrates a bespoke multiply-accumulate
co-processor with fixed coefficients to maximize energy efficiency and minimize
latency. Our approach formulates a constrained programming problem to jointly
determine co-processor constants and optimally map Multi-Layer Perceptron (MLP)
inference operations, enabling compact, model-specific hardware by leveraging
the low fabrication and non-recurring engineering costs of flexible
technologies. Post-layout results demonstrate near-real-time performance across
several healthcare datasets, with our circuits operating within the power
budget of existing flexible batteries and occupying only 2.42 mm^2, offering a
promising path toward accessible, sustainable, and conformable healthcare
wearables. Our microprocessors achieve an average 2.35x speedup and 2.15x lower
energy consumption compared to the state of the art.

</details>


### [281] [MoSKA: Mixture of Shared KV Attention for Efficient Long-Sequence LLM Inference](https://arxiv.org/abs/2511.06010)
*Myunghyun Rhee,Sookyung Choi,Euiseok Kim,Joonseop Sim,Youngpyo Joo,Hoshik Kim*

Main category: cs.LG

TL;DR: MoSKA是一种解决LLM中KV缓存性能瓶颈的新架构，通过区分唯一序列和共享序列，将共享数据的注意力计算从内存受限的GEMV操作转换为计算受限的GEMM操作。


<details>
  <summary>Details</summary>
Motivation: 随着LLM上下文长度的增加，KV缓存成为严重的性能瓶颈，其内存受限特性导致GPU利用率低下。

Method: 采用混合共享KV注意力机制，通过批处理并发请求将共享数据的注意力计算转换为GEMM操作，结合MoE启发的稀疏注意力策略和专门化硬件基础设施。

Result: 在高上下文共享的工作负载中，吞吐量比基线提高了最高538.7倍。

Conclusion: MoSKA为可扩展的LLM推理提供了一条清晰的架构路径，有效解决了KV缓存瓶颈问题。

Abstract: The escalating context length in Large Language Models (LLMs) creates a
severe performance bottleneck around the Key-Value (KV) cache, whose
memory-bound nature leads to significant GPU under-utilization. This paper
introduces Mixture of Shared KV Attention (MoSKA), an architecture that
addresses this challenge by exploiting the heterogeneity of context data. It
differentiates between per-request unique and massively reused shared
sequences. The core of MoSKA is a novel Shared KV Attention mechanism that
transforms the attention on shared data from a series of memory-bound GEMV
operations into a single, compute-bound GEMM by batching concurrent requests.
This is supported by an MoE-inspired sparse attention strategy that prunes the
search space and a tailored Disaggregated Infrastructure that specializes
hardware for unique and shared data. This comprehensive approach demonstrates a
throughput increase of up to 538.7x over baselines in workloads with high
context sharing, offering a clear architectural path toward scalable LLM
inference.

</details>


### [282] [Lethe: Layer- and Time-Adaptive KV Cache Pruning for Reasoning-Intensive LLM Serving](https://arxiv.org/abs/2511.06029)
*Hui Zeng,Daming Zhao,Pengfei Yang,Wenxuan Hou,Tianyang Zheng,Hui Li,Weiye Ji,Jidong Zhai*

Main category: cs.LG

TL;DR: Lethe是一个动态KV缓存管理框架，通过空间维度的层级稀疏感知分配和时间维度的多轮token剪枝来优化长序列生成推理的效率，在保持生成质量的同时将吞吐量提升最高2.56倍。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在长序列生成推理时，KV缓存会占用大量内存和延迟，现有压缩方法主要关注长输入序列的预填充阶段，无法有效处理长格式生成的动态性和层级敏感性。

Method: Lethe框架在空间维度进行层级稀疏感知分配，根据注意力冗余度为每个transformer层分配token剪枝预算；在时间维度通过基于最近性和相关性的选择性保留机制进行多轮token剪枝。

Result: 实验结果表明Lethe在不同模型和任务上实现了效率与生成质量的良好平衡，吞吐量最高提升2.56倍。

Conclusion: Lethe通过动态KV缓存管理有效解决了长序列生成推理中的内存和延迟问题，为LLM推理优化提供了新思路。

Abstract: Generative reasoning with large language models (LLMs) often involves long
decoding sequences, leading to substantial memory and latency overheads from
accumulating key-value (KV) caches. While existing KV compression methods
primarily focus on reducing prefill memory from long input sequences, they fall
short in addressing the dynamic and layer-sensitive nature of long-form
generation, which is central to reasoning tasks. We propose Lethe, a dynamic KV
cache management framework that introduces adaptivity along both the spatial
and temporal dimensions of decoding. Along the spatial dimension, Lethe
performs layerwise sparsity-aware allocation, assigning token pruning budgets
to each transformer layer based on estimated attention redundancy. Along the
temporal dimension, Lethe conducts multi-round token pruning during generation,
driven by a Recency-Aware Selective Retention} (RASR) mechanism. RASR extends
traditional recency-based heuristics by also considering token relevance
derived from evolving attention patterns, enabling informed decisions about
which tokens to retain or evict. Empirical results demonstrate that Lethe
achieves a favorable balance between efficiency and generation quality across
diverse models and tasks, increases throughput by up to 2.56x.

</details>


### [283] [ITPP: Learning Disentangled Event Dynamics in Marked Temporal Point Processes](https://arxiv.org/abs/2511.06032)
*Wang-Tao Zhou,Zhao Kang,Ke Yan,Ling Tian*

Main category: cs.LG

TL;DR: ITPP是一种新型的通道独立MTPP建模架构，通过解耦事件类型信息，使用ODE骨干网络和类型感知的自注意力机制，显著提升了预测准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有MTPP模型依赖通道混合策略，将不同事件类型信息编码到单一固定大小的潜在表示中，这种纠缠会模糊类型特定的动态，导致性能下降和过拟合风险增加。

Method: 提出ITPP架构，采用编码器-解码器框架和ODE骨干网络，核心是类型感知的反转自注意力机制，显式建模异构事件类型间的通道间相关性。

Result: 在多个真实世界和合成数据集上的综合实验表明，ITPP在预测准确性和泛化能力方面持续优于最先进的MTPP模型。

Conclusion: ITPP通过通道独立设计有效解决了MTPP模型中的类型信息纠缠问题，提高了模型的鲁棒性和抗过拟合能力。

Abstract: Marked Temporal Point Processes (MTPPs) provide a principled framework for
modeling asynchronous event sequences by conditioning on the history of past
events. However, most existing MTPP models rely on channel-mixing strategies
that encode information from different event types into a single, fixed-size
latent representation. This entanglement can obscure type-specific dynamics,
leading to performance degradation and increased risk of overfitting. In this
work, we introduce ITPP, a novel channel-independent architecture for MTPP
modeling that decouples event type information using an encoder-decoder
framework with an ODE-based backbone. Central to ITPP is a type-aware inverted
self-attention mechanism, designed to explicitly model inter-channel
correlations among heterogeneous event types. This architecture enhances
effectiveness and robustness while reducing overfitting. Comprehensive
experiments on multiple real-world and synthetic datasets demonstrate that ITPP
consistently outperforms state-of-the-art MTPP models in both predictive
accuracy and generalization.

</details>


### [284] [Advancing Ocean State Estimation with efficient and scalable AI](https://arxiv.org/abs/2511.06041)
*Yanfei Xiang,Yuan Gao,Hao Wu,Quan Zhang,Ruiqi Shu,Xiao Zhou,Xi Wu,Xiaomeng Huang*

Main category: cs.LG

TL;DR: ADAF-Ocean是一个AI驱动的海洋数据同化框架，能够直接同化多源多尺度观测数据，通过AI超分辨率重建高分辨率海洋状态，显著提升预报能力。


<details>
  <summary>Details</summary>
Motivation: 传统数据同化和深度学习方法在计算可扩展性和数据保真度方面存在瓶颈，需要开发更准确高效的全球海洋状态估计方法。

Method: 受神经过程启发，学习从异构输入到海洋状态的连续映射，通过AI驱动的超分辨率从1度粗分辨率场重建0.25度中尺度动力学。

Result: 与DL预报系统耦合时，相比无同化基线，ADAF-Ocean将全球预报技能延长达20天，参数仅增加3.7%。

Conclusion: 该框架为实时高分辨率地球系统监测建立了计算可行且科学严谨的途径。

Abstract: Accurate and efficient global ocean state estimation remains a grand
challenge for Earth system science, hindered by the dual bottlenecks of
computational scalability and degraded data fidelity in traditional data
assimilation (DA) and deep learning (DL) approaches. Here we present an
AI-driven Data Assimilation Framework for Ocean (ADAF-Ocean) that directly
assimilates multi-source and multi-scale observations, ranging from sparse
in-situ measurements to 4 km satellite swaths, without any interpolation or
data thinning. Inspired by Neural Processes, ADAF-Ocean learns a continuous
mapping from heterogeneous inputs to ocean states, preserving native data
fidelity. Through AI-driven super-resolution, it reconstructs 0.25$^\circ$
mesoscale dynamics from coarse 1$^\circ$ fields, which ensures both efficiency
and scalability, with just 3.7\% more parameters than the 1$^\circ$
configuration. When coupled with a DL forecasting system, ADAF-Ocean extends
global forecast skill by up to 20 days compared to baselines without
assimilation. This framework establishes a computationally viable and
scientifically rigorous pathway toward real-time, high-resolution Earth system
monitoring.

</details>


### [285] [Physics-Informed Design of Input Convex Neural Networks for Consistency Optimal Transport Flow Matching](https://arxiv.org/abs/2511.06042)
*Fanghui Song,Zhongjian Wang,Jiebao Sun*

Main category: cs.LG

TL;DR: 基于最优传输流的一致性模型，通过物理信息驱动的部分输入凸神经网络设计构建流场，避免内层优化子问题，支持单步和多步ODE采样


<details>
  <summary>Details</summary>
Motivation: 解决以往一步最优传输流匹配方法中存在内层优化子问题，利用最优传输流的直线性实现高效采样

Method: 结合哈密顿-雅可比残差与原始流匹配损失函数，使用部分输入凸神经网络构建流场模拟位移插值

Result: 在标准最优传输基准测试中验证了方法的可扩展性和性能

Conclusion: 该方法避免了内层优化问题，支持灵活的采样策略，在最优传输任务中表现出良好性能

Abstract: We propose a consistency model based on the optimal-transport flow. A
physics-informed design of partially input-convex neural networks (PICNN) plays
a central role in constructing the flow field that emulates the displacement
interpolation. During the training stage, we couple the Hamilton-Jacobi (HJ)
residual in the OT formulation with the original flow matching loss function.
Our approach avoids inner optimization subproblems that are present in previous
one-step OFM approaches. During the prediction stage, our approach supports
both one-step (Brenier-map) and multi-step ODE sampling from the same learned
potential, leveraging the straightness of the OT flow. We validate scalability
and performance on standard OT benchmarks.

</details>


### [286] [How Particle-System Random Batch Methods Enhance Graph Transformer: Memory Efficiency and Parallel Computing Strategy](https://arxiv.org/abs/2511.06044)
*Hanwen Liu,Yixuan Ma,Shi Jin,Yuguang Wang*

Main category: cs.LG

TL;DR: 提出Random Batch Attention (RBA)，一种线性自注意力机制，在保持表达能力的同时具有线性时间复杂度，并提供了理论支持。


<details>
  <summary>Details</summary>
Motivation: 传统的注意力机制具有二次复杂度，限制了其实用性。现有的稀疏注意力机制缺乏理论分析来证明在降低复杂度的同时保持表达能力。

Method: 基于计算数学中的Random Batch Methods，提出RBA机制，通过随机批次处理实现线性复杂度，并支持并行计算以节省内存。

Result: 在大规模图数据上的实验证明了RBA的优势，包括线性时间复杂度和内存节省，且能提升现有模型的性能。

Conclusion: RBA不仅是一种高效的注意力机制，还为注意力机制的理论分析提供了新工具。

Abstract: Attention mechanism is a significant part of Transformer models. It helps
extract features from embedded vectors by adding global information and its
expressivity has been proved to be powerful. Nevertheless, the quadratic
complexity restricts its practicability. Although several researches have
provided attention mechanism in sparse form, they are lack of theoretical
analysis about the expressivity of their mechanism while reducing complexity.
In this paper, we put forward Random Batch Attention (RBA), a linear
self-attention mechanism, which has theoretical support of the ability to
maintain its expressivity. Random Batch Attention has several significant
strengths as follows: (1) Random Batch Attention has linear time complexity.
Other than this, it can be implemented in parallel on a new dimension, which
contributes to much memory saving. (2) Random Batch Attention mechanism can
improve most of the existing models by replacing their attention mechanisms,
even many previously improved attention mechanisms. (3) Random Batch Attention
mechanism has theoretical explanation in convergence, as it comes from Random
Batch Methods on computation mathematics. Experiments on large graphs have
proved advantages mentioned above. Also, the theoretical modeling of
self-attention mechanism is a new tool for future research on
attention-mechanism analysis.

</details>


### [287] [Function Based Isolation Forest (FuBIF): A Unifying Framework for Interpretable Isolation-Based Anomaly Detection](https://arxiv.org/abs/2511.06054)
*Alessio Arcudi,Alessandro Ferreri,Francesco Borsatti,Gian Antonio Susto*

Main category: cs.LG

TL;DR: 本文提出了Function-based Isolation Forest (FuBIF)算法，这是Isolation Forest (IF)的泛化版本，通过使用实值函数进行数据集分支来增强异常检测的灵活性，并开发了FuBIFFI算法来提供特征重要性评估。


<details>
  <summary>Details</summary>
Motivation: Isolation Forest (IF)作为异常检测的关键技术存在适应性限制和偏差问题，需要更灵活的分支方法和更好的可解释性。

Method: 提出了FuBIF算法，允许使用实值函数进行数据集分支，改进了评估树构建的灵活性；同时开发了FuBIFFI算法来提供特征重要性评分。

Result: 论文详细介绍了FuBIF的操作框架，评估了其与现有方法的性能对比，并探讨了理论贡献。提供了开源实现以确保可复现性。

Conclusion: FuBIF是对IF算法的有效泛化，显著提升了异常检测的灵活性和可解释性，为后续研究提供了基础。

Abstract: Anomaly Detection (AD) is evolving through algorithms capable of identifying
outliers in complex datasets. The Isolation Forest (IF), a pivotal AD
technique, exhibits adaptability limitations and biases. This paper introduces
the Function-based Isolation Forest (FuBIF), a generalization of IF that
enables the use of real-valued functions for dataset branching, significantly
enhancing the flexibility of evaluation tree construction. Complementing this,
the FuBIF Feature Importance (FuBIFFI) algorithm extends the interpretability
in IF-based approaches by providing feature importance scores across possible
FuBIF models. This paper details the operational framework of FuBIF, evaluates
its performance against established methods, and explores its theoretical
contributions. An open-source implementation is provided to encourage further
research and ensure reproducibility.

</details>


### [288] [CatBack: Universal Backdoor Attacks on Tabular Data via Categorical Encoding](https://arxiv.org/abs/2511.06072)
*Behrad Tajalli,Stefanos Koffas,Stjepan Picek*

Main category: cs.LG

TL;DR: 本文提出了一种针对表格数据的后门攻击方法，通过将分类值转换为浮点表示，实现了对包含数值和分类特征的表格数据的有效攻击，在多种模型和数据集上达到100%攻击成功率，并能绕过现有防御机制。


<details>
  <summary>Details</summary>
Motivation: 现有的后门攻击研究主要集中在图像等同质数据上，而表格数据由于包含数值和分类特征的混合特性，具有独特的挑战性。本文旨在填补这一研究空白。

Method: 提出将分类值转换为浮点表示的新技术，保留足够信息以维持干净模型精度，同时创建适用于所有特征（包括分类特征）的基于梯度的通用扰动。

Result: 在五个数据集和四个流行模型上的评估显示，在白盒和黑盒设置下攻击成功率高达100%，且能成功绕过Spectral Signatures、Neural Cleanse、Beatrix、Fine-Pruning等先进防御机制。

Conclusion: 该方法揭示了表格数据的严重安全漏洞，性能优于之前的Tabdoor等方法，同时对现有防御机制具有高度隐蔽性。

Abstract: Backdoor attacks in machine learning have drawn significant attention for
their potential to compromise models stealthily, yet most research has focused
on homogeneous data such as images. In this work, we propose a novel backdoor
attack on tabular data, which is particularly challenging due to the presence
of both numerical and categorical features. Our key idea is a novel technique
to convert categorical values into floating-point representations. This
approach preserves enough information to maintain clean-model accuracy compared
to traditional methods like one-hot or ordinal encoding. By doing this, we
create a gradient-based universal perturbation that applies to all features,
including categorical ones.
  We evaluate our method on five datasets and four popular models. Our results
show up to a 100% attack success rate in both white-box and black-box settings
(including real-world applications like Vertex AI), revealing a severe
vulnerability for tabular data. Our method is shown to surpass the previous
works like Tabdoor in terms of performance, while remaining stealthy against
state-of-the-art defense mechanisms. We evaluate our attack against Spectral
Signatures, Neural Cleanse, Beatrix, and Fine-Pruning, all of which fail to
defend successfully against it. We also verify that our attack successfully
bypasses popular outlier detection mechanisms.

</details>


### [289] [Make It Long, Keep It Fast: End-to-End 10k-Sequence Modeling at Billion Scale on Douyin](https://arxiv.org/abs/2511.06077)
*Lin Guan,Jia-Qi Yang,Zhishan Zhao,Beichuan Zhang,Bo Sun,Xuanyuan Luo,Jinan Ni,Xiaowen Li,Yuhang Qi,Zhifang Fan,Hangyu Wang,Qiwei Chen,Yi Cheng,Feng Zhang,Xiao Yang*

Main category: cs.LG

TL;DR: 提出了一种能够处理10k长度用户历史记录的短视频推荐系统，通过线性复杂度注意力机制、用户级批处理和长度外推训练策略，在抖音生产环境中实现高效的长序列建模。


<details>
  <summary>Details</summary>
Motivation: 短视频推荐系统需要处理极长的用户历史记录，但传统方法在延迟和成本方面存在限制，需要开发能够扩展到10k长度历史记录的高效解决方案。

Method: 1. STCA（堆叠目标到历史交叉注意力）：用目标到历史的堆叠交叉注意力替代历史自注意力，将复杂度从二次降低到线性；2. RLB（请求级批处理）：同一用户/请求的多个目标共享用户侧编码；3. 长度外推训练策略：在较短窗口上训练，在更长窗口上推理。

Result: 在离线和在线实验中观察到可预测的单调增益，部署在抖音全流量上显著提升了关键参与度指标，同时满足生产延迟要求。

Conclusion: 该系统为将端到端长序列推荐扩展到10k级别提供了一条实用路径，展示了类似于大语言模型中观察到的缩放定律行为。

Abstract: Short-video recommenders such as Douyin must exploit extremely long user
histories without breaking latency or cost budgets. We present an end-to-end
system that scales long-sequence modeling to 10k-length histories in
production. First, we introduce Stacked Target-to-History Cross Attention
(STCA), which replaces history self-attention with stacked cross-attention from
the target to the history, reducing complexity from quadratic to linear in
sequence length and enabling efficient end-to-end training. Second, we propose
Request Level Batching (RLB), a user-centric batching scheme that aggregates
multiple targets for the same user/request to share the user-side encoding,
substantially lowering sequence-related storage, communication, and compute
without changing the learning objective. Third, we design a
length-extrapolative training strategy -- train on shorter windows, infer on
much longer ones -- so the model generalizes to 10k histories without
additional training cost. Across offline and online experiments, we observe
predictable, monotonic gains as we scale history length and model capacity,
mirroring the scaling law behavior observed in large language models. Deployed
at full traffic on Douyin, our system delivers significant improvements on key
engagement metrics while meeting production latency, demonstrating a practical
path to scaling end-to-end long-sequence recommendation to the 10k regime.

</details>


### [290] [Event-driven physics-informed operator learning for reliability analysis](https://arxiv.org/abs/2511.06083)
*Shailesh Garg,Souvik Chakraborty*

Main category: cs.LG

TL;DR: NeuroPOL是首个神经科学启发的物理信息算子学习框架，用于工程系统可靠性分析，通过变脉冲神经元实现稀疏通信，显著降低计算负载和能耗。


<details>
  <summary>Details</summary>
Motivation: 传统代理模型方法在资源受限环境中存在高能耗问题，限制了其在不确定性工程系统可靠性分析中的可扩展性和部署能力。

Method: 将变脉冲神经元集成到物理信息算子架构中，用事件驱动的脉冲动力学替代连续激活，嵌入控制物理定律构建物理一致的代理模型。

Result: 在五个基准测试中，NeuroPOL实现了与标准物理信息算子相当的可靠性度量，同时引入显著的通信稀疏性，支持可扩展、分布式和节能的部署。

Conclusion: NeuroPOL框架降低了计算和功耗需求，支持实时可靠性评估和在边缘设备及数字孪生上的部署，为高维问题的可靠性分析提供了高效解决方案。

Abstract: Reliability analysis of engineering systems under uncertainty poses
significant computational challenges, particularly for problems involving
high-dimensional stochastic inputs, nonlinear system responses, and
multiphysics couplings. Traditional surrogate modeling approaches often incur
high energy consumption, which severely limits their scalability and
deployability in resource-constrained environments. We introduce NeuroPOL,
\textit{the first neuroscience-inspired physics-informed operator learning
framework} for reliability analysis. NeuroPOL incorporates Variable Spiking
Neurons into a physics-informed operator architecture, replacing continuous
activations with event-driven spiking dynamics. This innovation promotes sparse
communication, significantly reduces computational load, and enables an
energy-efficient surrogate model. The proposed framework lowers both
computational and power demands, supporting real-time reliability assessment
and deployment on edge devices and digital twins. By embedding governing
physical laws into operator learning, NeuroPOL builds physics-consistent
surrogates capable of accurate uncertainty propagation and efficient failure
probability estimation, even for high-dimensional problems. We evaluate
NeuroPOL on five canonical benchmarks, the Burgers equation, Nagumo equation,
two-dimensional Poisson equation, two-dimensional Darcy equation, and
incompressible Navier-Stokes equation with energy coupling. Results show that
NeuroPOL achieves reliability measures comparable to standard physics-informed
operators, while introducing significant communication sparsity, enabling
scalable, distributed, and energy-efficient deployment.

</details>


### [291] [Approximating Shapley Explanations in Reinforcement Learning](https://arxiv.org/abs/2511.06094)
*Daniel Beechey,Özgür Şimşek*

Main category: cs.LG

TL;DR: FastSVERL是一种可扩展的方法，用于通过近似Shapley值来解释强化学习，解决了传统Shapley值计算成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 强化学习在复杂决策环境中取得了显著成功，但其缺乏透明度限制了在实际应用中的部署，特别是在安全关键场景中。

Method: FastSVERL引入了可扩展的Shapley值近似方法，专门处理强化学习中的独特挑战，包括多步轨迹中的时间依赖性、从离策略数据中学习以及实时适应演化中的智能体行为。

Result: 该方法提供了一种实用、可扩展的方法，为强化学习提供了原则性和严格的解释性。

Conclusion: FastSVERL为强化学习的可解释性提供了一个可行的解决方案，克服了传统Shapley值计算的计算成本障碍。

Abstract: Reinforcement learning has achieved remarkable success in complex
decision-making environments, yet its lack of transparency limits its
deployment in practice, especially in safety-critical settings. Shapley values
from cooperative game theory provide a principled framework for explaining
reinforcement learning; however, the computational cost of Shapley explanations
is an obstacle to their use. We introduce FastSVERL, a scalable method for
explaining reinforcement learning by approximating Shapley values. FastSVERL is
designed to handle the unique challenges of reinforcement learning, including
temporal dependencies across multi-step trajectories, learning from off-policy
data, and adapting to evolving agent behaviours in real time. FastSVERL
introduces a practical, scalable approach for principled and rigorous
interpretability in reinforcement learning.

</details>


### [292] [Adapting Web Agents with Synthetic Supervision](https://arxiv.org/abs/2511.06101)
*Zhaoyang Wang,Yiming Liang,Xuchao Zhang,Qianhui Wu,Siwei Han,Anson Bastos,Rujia Wang,Chetan Bansal,Baolin Peng,Jianfeng Gao,Saravan Rajmohan,Huaxiu Yao*

Main category: cs.LG

TL;DR: SynthAgent是一个全合成监督框架，通过双重精炼任务和轨迹来提高合成数据质量，以解决网络代理在新网站上的适应问题。


<details>
  <summary>Details</summary>
Motivation: 现有的合成数据生成方法存在数据质量问题，合成的任务包含无法执行的幻觉，收集的轨迹存在冗余或不对齐的噪声动作。

Method: 通过分类探索网页元素合成多样化任务，在轨迹收集过程中检测冲突并精炼任务，收集后使用全局上下文进行轨迹精炼，最后在精炼的合成数据上微调开源网络代理。

Result: 实验结果表明SynthAgent优于现有的合成数据方法，验证了高质量合成监督的重要性。

Conclusion: SynthAgent框架通过任务和轨迹的双重精炼有效提升了合成数据质量，使网络代理能更好地适应新网站环境。

Abstract: Web agents struggle to adapt to new websites due to the scarcity of
environment specific tasks and demonstrations. Recent works have explored
synthetic data generation to address this challenge, however, they suffer from
data quality issues where synthesized tasks contain hallucinations that cannot
be executed, and collected trajectories are noisy with redundant or misaligned
actions. In this paper, we propose SynthAgent, a fully synthetic supervision
framework that aims at improving synthetic data quality via dual refinement of
both tasks and trajectories. Our approach begins by synthesizing diverse tasks
through categorized exploration of web elements, ensuring efficient coverage of
the target environment. During trajectory collection, we refine tasks when
conflicts with actual observations are detected, mitigating hallucinations
while maintaining task consistency. After collection, we conduct trajectory
refinement with a global context to mitigate potential noise or misalignments.
Finally, we fine-tune open-source web agents on the refined synthetic data to
adapt them to the target environment. Experimental results demonstrate that
SynthAgent outperforms existing synthetic data methods, validating the
importance of high-quality synthetic supervision. The code will be publicly
available at https://github.com/aiming-lab/SynthAgent.

</details>


### [293] [Guardian-regularized Safe Offline Reinforcement Learning for Smart Weaning of Mechanical Circulatory Devices](https://arxiv.org/abs/2511.06111)
*Aysin Tumay,Sophia Sun,Sonia Fereidooni,Aaron Dumas,Elise Jortberg,Rose Yu*

Main category: cs.LG

TL;DR: 提出了CORMPO框架，通过离线强化学习实现机械循环支持设备的自动化撤机决策，解决了医疗场景中数据有限、禁止在线交互等挑战


<details>
  <summary>Details</summary>
Motivation: 当前MCS设备撤机策略缺乏数据驱动方法，且不同医疗团队差异较大。医疗场景存在禁止在线患者交互、循环动力学高度不确定、数据有限等特殊挑战

Method: 开发了临床感知的OOD正则化模型策略优化(CORMPO)算法，结合Transformer概率数字孪生模型。CORMPO包含密度正则化离线RL、临床奖励塑造，数字孪生用于策略评估

Result: CORMPO在真实和合成数据集上比基线离线RL方法奖励提高28%，临床指标得分提高82.6%。理论证明在温和假设下具有性能保证

Conclusion: 该框架为高风险医疗应用提供了原则性的安全离线策略学习方法，在需要领域专业知识和安全约束的场景中具有重要价值

Abstract: We study the sequential decision-making problem for automated weaning of
mechanical circulatory support (MCS) devices in cardiogenic shock patients. MCS
devices are percutaneous micro-axial flow pumps that provide left ventricular
unloading and forward blood flow, but current weaning strategies vary
significantly across care teams and lack data-driven approaches. Offline
reinforcement learning (RL) has proven to be successful in sequential
decision-making tasks, but our setting presents challenges for training and
evaluating traditional offline RL methods: prohibition of online patient
interaction, highly uncertain circulatory dynamics due to concurrent
treatments, and limited data availability. We developed an end-to-end machine
learning framework with two key contributions (1) Clinically-aware
OOD-regularized Model-based Policy Optimization (CORMPO), a density-regularized
offline RL algorithm for out-of-distribution suppression that also incorporates
clinically-informed reward shaping and (2) a Transformer-based probabilistic
digital twin that models MCS circulatory dynamics for policy evaluation with
rich physiological and clinical metrics. We prove that \textsf{CORMPO} achieves
theoretical performance guarantees under mild assumptions. CORMPO attains a
higher reward than the offline RL baselines by 28% and higher scores in
clinical metrics by 82.6% on real and synthetic datasets. Our approach offers a
principled framework for safe offline policy learning in high-stakes medical
applications where domain expertise and safety constraints are essential.

</details>


### [294] [On the Convergence and Stability of Distributed Sub-model Training](https://arxiv.org/abs/2511.06132)
*Yuyang Deng,Fuli Qiao,Mehrdad Mahdavi*

Main category: cs.LG

TL;DR: 本文提出了一种分布式洗牌子模型训练方法，通过预先将完整模型划分为多个子模型，并在每个训练轮次中洗牌分配给客户端，解决了联邦学习中随机子模型采样收敛性能不佳的问题。


<details>
  <summary>Details</summary>
Motivation: 随着模型规模不断增大，联邦学习中的设备端本地训练面临挑战。现有的随机子模型采样方法可能无法提供令人满意的收敛性能。

Method: 提出分布式洗牌子模型训练：将完整模型预先划分为多个子模型，服务器在每个轮次洗牌这些子模型并分配给客户端，客户端更新后返回子模型，服务器进行平均聚合。

Result: 建立了该算法的收敛率，并通过稳定性分析发现子模型训练可以通过放大训练过程的稳定性来改善泛化性能。大量实验验证了理论发现。

Conclusion: 分布式洗牌子模型训练方法有效解决了联邦学习中的大规模模型训练问题，在收敛性能和泛化能力方面都表现出色。

Abstract: As learning models continue to grow in size, enabling on-device local
training of these models has emerged as a critical challenge in federated
learning. A popular solution is sub-model training, where the server only
distributes randomly sampled sub-models to the edge clients, and clients only
update these small models. However, those random sampling of sub-models may not
give satisfying convergence performance. In this paper, observing the success
of SGD with shuffling, we propose a distributed shuffled sub-model training,
where the full model is partitioned into several sub-models in advance, and the
server shuffles those sub-models, sends each of them to clients at each round,
and by the end of local updating period, clients send back the updated
sub-models, and server averages them. We establish the convergence rate of this
algorithm. We also study the generalization of distributed sub-model training
via stability analysis, and find that the sub-model training can improve the
generalization via amplifying the stability of training process. The extensive
experiments also validate our theoretical findings.

</details>


### [295] [Enhancing Robustness of Graph Neural Networks through p-Laplacian](https://arxiv.org/abs/2511.06143)
*Anuj Kumar Sirohi,Subhanu Halder,Kabir Kumar,Sandeep Kumar*

Main category: cs.LG

TL;DR: 本文提出了一种基于加权p-Laplacian的计算高效框架pLAPGNN，用于增强图神经网络（GNNs）对抗攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着数据量的增加，图数据分析成为理解复杂关系的重要工具。图神经网络在各种应用中显示出巨大潜力，但容易受到对抗攻击（训练时的投毒攻击和测试时的规避攻击）的影响。现有的鲁棒性方法计算量大且在攻击强度增加时性能下降。

Method: 提出了pLAPGNN框架，基于加权p-Laplacian方法，旨在以计算高效的方式增强GNNs的鲁棒性。

Result: 在真实数据集上的实证评估表明，所提出的方法在效能和效率方面都具有显著优势。

Conclusion: pLAPGNN框架为图神经网络提供了一种计算高效的鲁棒性解决方案，能够有效应对对抗攻击。

Abstract: With the increase of data in day-to-day life, businesses and different
stakeholders need to analyze the data for better pre- dictions. Traditionally,
relational data has been a source of various insights, but with the increase in
computational power and the need to understand deeper relationships between en-
tities, the need to design new techniques has arisen. For this graph data
analysis has become an extraordinary tool for un- derstanding the data, which
reveals more realistic and flexible modelling of complex relationships.
Recently, Graph Neural Networks (GNNs) have shown great promise in various ap-
plications, such as social network analysis, recommendation systems, drug
discovery, and more. However, many adversar- ial attacks can happen over the
data, whether during training (poisoning attack) or during testing (evasion
attack), which can adversely manipulate the desired outcome from the GNN model.
Therefore, it is crucial to make the GNNs robust to such attacks. The existing
robustness methods are computa- tionally demanding and perform poorly when the
intensity of attack increases. This paper presents a computationally ef-
ficient framework, namely, pLAPGNN, based on weighted p-Laplacian for making
GNNs robust. Empirical evaluation on real datasets establishes the efficacy and
efficiency of the proposed method.

</details>


### [296] [Models Got Talent: Identifying High Performing Wearable Human Activity Recognition Models Without Training](https://arxiv.org/abs/2511.06157)
*Richard Goldman,Varun Komperla,Thomas Ploetz,Harish Haresamudram*

Main category: cs.LG

TL;DR: 本文研究了零成本代理（ZCPs）在人类活动识别（HAR）中的有效性，证明ZCPs能够以最小训练成本发现高性能网络架构，性能可达完整训练的95%以内。


<details>
  <summary>Details</summary>
Motivation: 神经架构搜索（NAS）计算成本高昂，而ZCPs作为替代方案，通过单次前向/反向传播就能评估架构性能，有望大幅降低计算开销。

Method: 在六个基准数据集上评估ZCPs的有效性，通过1500个随机采样架构的对比实验验证ZCPs的性能相关性。

Result: ZCPs发现的架构性能可达完整训练的95%以内，计算节省显著，且对数据噪声具有鲁棒性。

Conclusion: ZCPs适用于传感器基HAR的实践场景，能以最小训练成本高效发现高性能架构。

Abstract: A promising alternative to the computationally expensive Neural Architecture
Search (NAS) involves the development of \textit{Zero Cost Proxies (ZCPs)},
which correlate well to trained performance, but can be computed through a
single forward/backward pass on a randomly sampled batch of data. In this
paper, we investigate the effectiveness of ZCPs for HAR on six benchmark
datasets, and demonstrate that they discover network architectures that obtain
within 5\% of performance attained by full scale training involving 1500
randomly sampled architectures. This results in substantial computational
savings as high performing architectures can be discovered with minimal
training. Our experiments not only introduce ZCPs to sensor-based HAR, but also
demonstrate that they are robust to data noise, further showcasing their
suitability for practical scenarios.

</details>


### [297] [LLM Attention Transplant for Transfer Learning of Tabular Data Across Disparate Domains](https://arxiv.org/abs/2511.06161)
*Ibna Kowsar,Kazi F. Akhter,Manar D. Samad*

Main category: cs.LG

TL;DR: 提出了一种轻量级迁移学习框架LATTLE，通过将LLM的注意力权重移植到专门为表格数据设计的gFTT模型中，实现跨域表格数据的有效迁移学习。


<details>
  <summary>Details</summary>
Motivation: 表格数据的迁移学习面临特征空间异构性的挑战，传统深度学习方法效果有限，而LLM在处理混合数据类型的表格时也存在效率瓶颈。

Method: 首先使用源表格数据微调LLM，然后将其选择性key和value投影权重移植到gFTT模型中，最后使用目标表格数据微调带跨域注意力的gFTT模型。

Result: 在10对源-目标数据集和12个基线方法的实验中，LATTLE方法优于传统ML模型、最先进的深度表格架构和基于大规模预训练模型的迁移学习方法。

Conclusion: 提出的注意力移植方法为在低资源学习环境中使用LLM学习数据表间关系提供了有效解决方案。

Abstract: Transfer learning of tabular data is non-trivial due to heterogeneity in the
feature space across disparate domains. The limited success of traditional deep
learning in tabular knowledge transfer can be advanced by leveraging large
language models (LLMs). However, the efficacy of LLMs often stagnates for mixed
data types structured in tables due to the limitations of text prompts and
in-context learning. We propose a lightweight transfer learning framework that
fine-tunes an LLM using source tabular data and transplants the LLM's selective
$key$ and $value$ projection weights into a gated feature tokenized transformer
(gFTT) built for tabular data. The gFTT model with cross-domain attention is
fine-tuned using target tabular data for transfer learning, eliminating the
need for shared features, LLM prompt engineering, and large-scale pretrained
models. Our experiments using ten pairs of source-target data sets and 12
baselines demonstrate the superiority of the proposed LLM-attention transplant
for transfer learning (LATTLE) method over traditional ML models,
state-of-the-art deep tabular architectures, and transfer learning models
trained on thousands to billions of tabular samples. The proposed attention
transfer demonstrates an effective solution to learning relationships between
data tables using an LLM in a low-resource learning environment. The source
code for the proposed method is publicly available.

</details>


### [298] [Learning Gaussian DAG Models without Condition Number Bounds](https://arxiv.org/abs/2511.06164)
*Constantinos Daskalakis,Vardis Kandiros,Rui Yao*

Main category: cs.LG

TL;DR: 本文提出了一种学习有向高斯图模型拓扑结构的新算法，该算法的样本复杂度与协方差矩阵的条件数无关，解决了先前方法在高维设置中因条件数增长而变得不实用的问题。


<details>
  <summary>Details</summary>
Motivation: 先前的方法在学习有向高斯图模型拓扑时，样本复杂度随协方差矩阵条件数多项式增长，这在高维设置中（条件数可能随节点数n多项式增长）变得不切实际。

Method: 设计了一种新算法来恢复底层图结构，该算法的样本复杂度独立于条件数。在变量方差有界的进一步假设下，还设计了一个多项式时间算法，但样本复杂度对d有额外的多项式依赖。

Result: 证明了所需的样本数量与条件数无关，并建立了与上限几乎匹配的下界，从而提供了问题真实样本复杂度的几乎紧致刻画。仿真实验验证了理论结果。

Conclusion: 该工作解决了有向高斯图模型学习中的关键限制，提供了条件数无关的样本复杂度保证，并通过理论分析和实验验证了方法的有效性。

Abstract: We study the problem of learning the topology of a directed Gaussian
Graphical Model under the equal-variance assumption, where the graph has $n$
nodes and maximum in-degree $d$. Prior work has established that $O(d \log n)$
samples are sufficient for this task. However, an important factor that is
often overlooked in these analyses is the dependence on the condition number of
the covariance matrix of the model. Indeed, all algorithms from prior work
require a number of samples that grows polynomially with this condition number.
In many cases this is unsatisfactory, since the condition number could grow
polynomially with $n$, rendering these prior approaches impractical in
high-dimensional settings. In this work, we provide an algorithm that recovers
the underlying graph and prove that the number of samples required is
independent of the condition number. Furthermore, we establish lower bounds
that nearly match the upper bound up to a $d$-factor, thus providing an almost
tight characterization of the true sample complexity of the problem. Moreover,
under a further assumption that all the variances of the variables are bounded,
we design a polynomial-time algorithm that recovers the underlying graph, at
the cost of an additional polynomial dependence of the sample complexity on
$d$. We complement our theoretical findings with simulations on synthetic
datasets that confirm our predictions.

</details>


### [299] [Local K-Similarity Constraint for Federated Learning with Label Noise](https://arxiv.org/abs/2511.06169)
*Sanskar Amgain,Prashant Shrestha,Bidur Khanal,Alina Devkota,Yash Raj Shrestha,Seungryul Baek,Prashnna Gyawali,Binod Bhattarai*

Main category: cs.LG

TL;DR: 本文提出了一种针对联邦学习中噪声标签客户端的新正则化方法，通过解耦预训练模型和分类模型，在客户端本地实施数据点相似性约束，有效提升全局模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法假设存在足够多的干净标签客户端，但在高比例异构噪声客户端场景下失效。需要本地正则化来防止噪声客户端污染全局模型，但基于预训练模型的集中式方法在联邦学习中通信成本过高。

Method: 提出客户端模型的正则化目标，利用自监督预训练模型的表示空间评估数据点相似性，在标准下游任务目标函数基础上添加相似性约束，实现预训练模型与分类模型的架构解耦。

Result: 在多个计算机视觉和医学图像分类基准测试中显著提升性能，优于现有最先进的联邦学习方法，且不要求预训练模型和分类器架构相同。

Conclusion: 该方法有效解决了高比例噪声客户端场景下的联邦学习问题，具有架构无关性和实用性优势。

Abstract: Federated learning on clients with noisy labels is a challenging problem, as
such clients can infiltrate the global model, impacting the overall
generalizability of the system. Existing methods proposed to handle noisy
clients assume that a sufficient number of clients with clean labels are
available, which can be leveraged to learn a robust global model while
dampening the impact of noisy clients. This assumption fails when a high number
of heterogeneous clients contain noisy labels, making the existing approaches
ineffective. In such scenarios, it is important to locally regularize the
clients before communication with the global model, to ensure the global model
isn't corrupted by noisy clients. While pre-trained self-supervised models can
be effective for local regularization, existing centralized approaches relying
on pretrained initialization are impractical in a federated setting due to the
potentially large size of these models, which increases communication costs. In
that line, we propose a regularization objective for client models that
decouples the pre-trained and classification models by enforcing similarity
between close data points within the client. We leverage the representation
space of a self-supervised pretrained model to evaluate the closeness among
examples. This regularization, when applied with the standard objective
function for the downstream task in standard noisy federated settings,
significantly improves performance, outperforming existing state-of-the-art
federated methods in multiple computer vision and medical image classification
benchmarks. Unlike other techniques that rely on self-supervised pretrained
initialization, our method does not require the pretrained model and classifier
backbone to share the same architecture, making it architecture-agnostic.

</details>


### [300] [Resilience Inference for Supply Chains with Hypergraph Neural Network](https://arxiv.org/abs/2511.06208)
*Zetian Shen,Hongjun Wang,Jiyuan Chen,Xuan Song*

Main category: cs.LG

TL;DR: 本文提出了一种新的供应链韧性推断问题（SCRI）和基于超图的模型SC-RIHN，用于在不依赖显式系统动力学方程的情况下预测供应链韧性。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏有效的机制来推断供应链韧性，且难以表示供应链网络中固有的高阶多实体依赖关系，这限制了主动风险缓解和稳健网络设计的能力。

Method: 提出了SC-RIHN模型，利用基于集合的编码和超图消息传递来捕捉多方企业-产品交互，通过超图拓扑和观察到的库存轨迹来预测供应链韧性。

Result: 综合实验表明，SC-RIHN在合成基准测试中显著优于传统的MLP、代表性图神经网络变体和ResInf基线方法。

Conclusion: SC-RIHN展示了在复杂供应链系统中进行实际早期预警风险评估的潜力，为供应链韧性推断提供了有效的解决方案。

Abstract: Supply chains are integral to global economic stability, yet disruptions can
swiftly propagate through interconnected networks, resulting in substantial
economic impacts. Accurate and timely inference of supply chain resilience the
capability to maintain core functions during disruptions is crucial for
proactive risk mitigation and robust network design. However, existing
approaches lack effective mechanisms to infer supply chain resilience without
explicit system dynamics and struggle to represent the higher-order,
multi-entity dependencies inherent in supply chain networks. These limitations
motivate the definition of a novel problem and the development of targeted
modeling solutions. To address these challenges, we formalize a novel problem:
Supply Chain Resilience Inference (SCRI), defined as predicting supply chain
resilience using hypergraph topology and observed inventory trajectories
without explicit dynamic equations. To solve this problem, we propose the
Supply Chain Resilience Inference Hypergraph Network (SC-RIHN), a novel
hypergraph-based model leveraging set-based encoding and hypergraph message
passing to capture multi-party firm-product interactions. Comprehensive
experiments demonstrate that SC-RIHN significantly outperforms traditional MLP,
representative graph neural network variants, and ResInf baselines across
synthetic benchmarks, underscoring its potential for practical, early-warning
risk assessment in complex supply chain systems.

</details>


### [301] [Sparse Linear Regression is Easy on Random Supports](https://arxiv.org/abs/2511.06211)
*Gautam Chandrasekaran,Raghu Meka,Konstantinos Stavropoulos*

Main category: cs.LG

TL;DR: 该论文提出了针对稀疏线性回归问题的首个通用正结果，能够在最坏情况设计矩阵下，通过随机选择支持集，实现多项式样本复杂度和运行时间。


<details>
  <summary>Details</summary>
Motivation: 解决稀疏线性回归中计算复杂度与样本复杂度之间的指数差距问题，即在最坏情况设计矩阵下实现多项式时间算法和亚线性样本复杂度。

Method: 采用随机支持集选择策略，对任意设计矩阵X，只要w*的支持集是随机选择的，就能在条件数高达2^poly(d)的情况下实现多项式时间算法。

Result: 证明了对于任意设计矩阵X，当w*的支持集随机选择时，可以用poly(k, log d, 1/ε)样本和poly(d,N)运行时间达到预测误差ε。

Conclusion: 该工作打破了先前结果对设计矩阵的严格限制，为最坏情况下的稀疏线性回归提供了首个通用多项式时间算法。

Abstract: Sparse linear regression is one of the most basic questions in machine
learning and statistics. Here, we are given as input a design matrix $X \in
\mathbb{R}^{N \times d}$ and measurements or labels ${y} \in \mathbb{R}^N$
where ${y} = {X} {w}^* + {\xi}$, and ${\xi}$ is the noise in the measurements.
Importantly, we have the additional constraint that the unknown signal vector
${w}^*$ is sparse: it has $k$ non-zero entries where $k$ is much smaller than
the ambient dimension. Our goal is to output a prediction vector
$\widehat{{w}}$ that has small prediction error: $\frac{1}{N}\cdot \|{X} {w}^*
- {X} \widehat{{w}}\|^2_2$.
  Information-theoretically, we know what is best possible in terms of
measurements: under most natural noise distributions, we can get prediction
error at most $\epsilon$ with roughly $N = O(k \log d/\epsilon)$ samples.
Computationally, this currently needs $d^{\Omega(k)}$ run-time. Alternately,
with $N = O(d)$, we can get polynomial-time. Thus, there is an exponential gap
(in the dependence on $d$) between the two and we do not know if it is possible
to get $d^{o(k)}$ run-time and $o(d)$ samples.
  We give the first generic positive result for worst-case design matrices
${X}$: For any ${X}$, we show that if the support of ${w}^*$ is chosen at
random, we can get prediction error $\epsilon$ with $N = \text{poly}(k, \log d,
1/\epsilon)$ samples and run-time $\text{poly}(d,N)$. This run-time holds for
any design matrix ${X}$ with condition number up to $2^{\text{poly}(d)}$.
  Previously, such results were known for worst-case ${w}^*$, but only for
random design matrices from well-behaved families, matrices that have a very
low condition number ($\text{poly}(\log d)$; e.g., as studied in compressed
sensing), or those with special structural properties.

</details>


### [302] [Adaptive Multi-view Graph Contrastive Learning via Fractional-order Neural Diffusion Networks](https://arxiv.org/abs/2511.06216)
*Yanan Zhao,Feng Ji,Jingyang Dai,Jiaze Ma,Keyue Jiang,Kai Zhao,Wee Peng Tay*

Main category: cs.LG

TL;DR: 本文提出了一种基于分数阶连续动力学的无增强多视图图对比学习框架，通过可学习的分数阶导数参数自动生成多尺度视图，无需手动数据增强。


<details>
  <summary>Details</summary>
Motivation: 现有图对比学习方法通常依赖固定的手工视图（局部和全局视角），限制了捕捉多尺度结构模式的能力。

Method: 使用分数阶连续动力学，通过变化分数阶导数参数α∈(0,1]生成连续谱的视图：小α产生局部特征，大α产生全局聚合。将α作为可学习参数，使模型能够自适应扩散尺度。

Result: 在标准基准测试上的广泛实验表明，该方法产生更鲁棒和表达性更强的嵌入，优于最先进的图对比学习基线。

Conclusion: 这种基于分数阶动力学的原则性方法能够自动发现信息丰富的视图，无需手动增强即可生成多样互补的表示。

Abstract: Graph contrastive learning (GCL) learns node and graph representations by
contrasting multiple views of the same graph. Existing methods typically rely
on fixed, handcrafted views-usually a local and a global perspective, which
limits their ability to capture multi-scale structural patterns. We present an
augmentation-free, multi-view GCL framework grounded in fractional-order
continuous dynamics. By varying the fractional derivative order $\alpha \in
(0,1]$, our encoders produce a continuous spectrum of views: small $\alpha$
yields localized features, while large $\alpha$ induces broader, global
aggregation. We treat $\alpha$ as a learnable parameter so the model can adapt
diffusion scales to the data and automatically discover informative views. This
principled approach generates diverse, complementary representations without
manual augmentations. Extensive experiments on standard benchmarks demonstrate
that our method produces more robust and expressive embeddings and outperforms
state-of-the-art GCL baselines.

</details>


### [303] [Deep Reinforcement Learning for Dynamic Origin-Destination Matrix Estimation in Microscopic Traffic Simulations Considering Credit Assignment](https://arxiv.org/abs/2511.06229)
*Donggyu Min,Seongjin Choi,Dong-Kyu Kim*

Main category: cs.LG

TL;DR: 论文提出了一种基于深度强化学习的动态OD矩阵估计方法，通过将问题建模为马尔可夫决策过程，解决了微观交通仿真中的信用分配问题，在Nguyen-Dupuis网络上验证显示比传统方法MSE降低43.2%。


<details>
  <summary>Details</summary>
Motivation: 微观交通仿真中的动态OD矩阵估计面临复杂的时间动态性和车辆个体不确定性，导致OD矩阵与链路流量之间的因果关系不明确，形成信用分配问题。传统方法难以有效解决这一挑战。

Method: 将动态OD矩阵估计问题建模为马尔可夫决策过程，采用无模型的深度强化学习框架。智能体通过与仿真环境交互学习最优策略，顺序生成OD矩阵。

Result: 在SUMO仿真环境中使用Nguyen-Dupuis网络进行验证，以5分钟为间隔的30分钟时间范围内的真实链路流量作为评估标准。实验结果表明，该方法相比最佳传统基线方法，均方误差降低了43.2%。

Conclusion: 通过将动态OD矩阵估计重新定义为序列决策问题，深度强化学习方法通过学习到的策略有效解决了信用分配挑战，克服了传统方法的局限性，为微观交通仿真校准提供了新框架。

Abstract: This paper focuses on dynamic origin-destination matrix estimation (DODE), a
crucial calibration process necessary for the effective application of
microscopic traffic simulations. The fundamental challenge of the DODE problem
in microscopic simulations stems from the complex temporal dynamics and
inherent uncertainty of individual vehicle dynamics. This makes it highly
challenging to precisely determine which vehicle traverses which link at any
given moment, resulting in intricate and often ambiguous relationships between
origin-destination (OD) matrices and their contributions to resultant link
flows. This phenomenon constitutes the credit assignment problem, a central
challenge addressed in this study. We formulate the DODE problem as a Markov
Decision Process (MDP) and propose a novel framework that applies model-free
deep reinforcement learning (DRL). Within our proposed framework, the agent
learns an optimal policy to sequentially generate OD matrices, refining its
strategy through direct interaction with the simulation environment. The
proposed method is validated on the Nguyen-Dupuis network using SUMO, where its
performance is evaluated against ground-truth link flows aggregated at 5-minute
intervals over a 30-minute horizon. Experimental results demonstrate that our
approach achieves a 43.2% reduction in mean squared error (MSE) compared to the
best-performing conventional baseline. By reframing DODE as a sequential
decision-making problem, our approach addresses the credit assignment challenge
through its learned policy, thereby overcoming the limitations of conventional
methods and proposing a novel framework for calibration of microscopic traffic
simulations.

</details>


### [304] [Synheart Emotion: Privacy-Preserving On-Device Emotion Recognition from Biosignals](https://arxiv.org/abs/2511.06231)
*Henok Ademtew,Israel Goytom*

Main category: cs.LG

TL;DR: 本文系统评估了多种机器学习架构在腕部光电容积脉搏波（PPG）情绪识别任务上的表现，发现传统集成方法在小规模生理数据集上显著优于深度学习方法，并通过ONNX优化实现了高效轻量的设备端部署。


<details>
  <summary>Details</summary>
Motivation: 当前情绪识别系统大多依赖云端推理，存在隐私泄露和延迟问题，无法满足实时应用需求。本文旨在探索隐私保护的设备端情绪识别方案。

Method: 在WESAD压力检测数据集上系统比较了传统集成方法、深度神经网络和Transformer模型在腕部PPG信号情绪识别中的性能，并对最佳模型进行ONNX优化部署。

Result: ExtraTrees集成方法表现最佳（F1=0.826），显著优于Transformer模型（F1=0.509-0.577）。ONNX优化后模型仅4.08MB，推理延迟0.05ms，存储减少30.5%，速度提升40.1倍。

Conclusion: 传统集成方法在小规模生理数据上更适合设备端情绪识别，ONNX优化可显著提升部署效率，证明了隐私保护设备端情绪识别在可穿戴设备中的可行性。

Abstract: Human-computer interaction increasingly demands systems that recognize not
only explicit user inputs but also implicit emotional states. While substantial
progress has been made in affective computing, most emotion recognition systems
rely on cloud-based inference, introducing privacy vulnerabilities and latency
constraints unsuitable for real-time applications. This work presents a
comprehensive evaluation of machine learning architectures for on-device
emotion recognition from wrist-based photoplethysmography (PPG), systematically
comparing different models spanning classical ensemble methods, deep neural
networks, and transformers on the WESAD stress detection dataset. Results
demonstrate that classical ensemble methods substantially outperform deep
learning on small physiological datasets, with ExtraTrees achieving F1 = 0.826
on combined features and F1 = 0.623 on wrist-only features, compared to
transformers achieving only F1 = 0.509-0.577. We deploy the wrist-only
ExtraTrees model optimized via ONNX conversion, achieving a 4.08 MB footprint,
0.05 ms inference latency, and 152x speedup over the original implementation.
Furthermore, ONNX optimization yields a 30.5% average storage reduction and
40.1x inference speedup, highlighting the feasibility of privacy-preserving
on-device emotion recognition for real-world wearables.

</details>


### [305] [Scaling Laws and In-Context Learning: A Unified Theoretical Framework](https://arxiv.org/abs/2511.06232)
*Sushant Mehta,Ishan Gupta*

Main category: cs.LG

TL;DR: 本文提出了一个统一的理论框架，将缩放定律与Transformer中的上下文学习（ICL）涌现联系起来，建立了ICL性能与模型深度、宽度、上下文长度和训练数据的幂律关系，并揭示了Transformer在前向传播中实现基于梯度的元学习机制。


<details>
  <summary>Details</summary>
Motivation: 尽管有大量实证研究，但对大规模上下文学习涌现的原理性理解仍然不够清晰。本文旨在建立一个理论框架来解释ICL如何在Transformer模型中涌现。

Method: 通过理论分析建立ICL性能与模型参数（深度L、宽度d、上下文长度k、训练数据D）的幂律关系，推导出Transformer在前向传播中实现梯度元学习的条件，并分析临界尺度下的相变现象。

Result: 理论预测与合成任务的系统实验结果高度吻合，测量得到的缩放指数与理论推导一致，验证了所提出的理论框架。

Conclusion: 这项工作为ICL的涌现提供了必要和充分条件，并建立了Transformer在上下文学习方面的基本计算极限。

Abstract: In-context learning (ICL) enables large language models to adapt to new tasks
from demonstrations without parameter updates. Despite extensive empirical
studies, a principled understanding of ICL emergence at scale remains more
elusive. We present a unified theoretical framework connecting scaling laws to
ICL emergence in transformers. Our analysis establishes that ICL performance
follows power-law relationships with model depth $L$, width $d$, context length
$k$, and training data $D$, with exponents determined by task structure. We
show that under specific conditions, transformers implement gradient-based
metalearning in their forward pass, with an effective learning rate
$\eta_{\text{eff}} = \Theta(1/\sqrt{Ld})$. We demonstrate sharp phase
transitions at critical scales and derive optimal depth-width allocations
favoring $L^* \propto N^{2/3}$, $d^* \propto N^{1/3}$ for the fixed parameter
budget $N = Ld$. Systematic experiments on synthetic tasks validate our
predictions, with measured scaling exponents closely matching theory. This work
provides both necessary and sufficient conditions for the emergence of ICLs and
establishes fundamental computational limits on what transformers can learn
in-context.

</details>


### [306] [Mixtures of SubExperts for Large Language Continual Learning](https://arxiv.org/abs/2511.06237)
*Haeyong Kang*

Main category: cs.LG

TL;DR: 提出MoSEs方法解决LLMs持续学习中的灾难性遗忘和参数线性增长问题，通过混合子专家和任务特定路由实现最小遗忘和高效扩展


<details>
  <summary>Details</summary>
Motivation: 解决参数高效微调方法在持续学习中的两难困境：重用参数导致灾难性遗忘，分配不同参数导致模型尺寸线性增长且无法实现任务间知识迁移

Method: 提出MoSEs框架，在transformer层中集成稀疏混合子专家，由任务特定路由机制控制，可自适应选择和组合先前学习的稀疏参数

Result: 在TRACE基准数据集上显著优于传统持续学习方法，在知识保留和新任务扩展性方面达到最先进性能，大幅节省内存和计算资源

Conclusion: MoSEs是解决LLMs持续学习挑战的有效框架，实现了最小遗忘和高效扩展的平衡

Abstract: Adapting Large Language Models (LLMs) to a continuous stream of tasks is a
critical yet challenging endeavor. While Parameter-Efficient Fine-Tuning (PEFT)
methods have become a standard for this, they face a fundamental dilemma in
continual learning. Reusing a single set of PEFT parameters for new tasks often
leads to catastrophic forgetting of prior knowledge. Conversely, allocating
distinct parameters for each task prevents forgetting but results in a linear
growth of the model's size and fails to facilitate knowledge transfer between
related tasks. To overcome these limitations, we propose a novel adaptive PEFT
method referred to as \textit{Mixtures of SubExperts (MoSEs)}, a novel
continual learning framework designed for minimal forgetting and efficient
scalability. MoSEs integrate a sparse Mixture of SubExperts into the
transformer layers, governed by a task-specific routing mechanism. This
architecture allows the model to isolate and protect knowledge within dedicated
SubExperts, thereby minimizing parameter interference and catastrophic
forgetting. Crucially, the router can adaptively select and combine previously
learned sparse parameters for new tasks, enabling effective knowledge transfer
while ensuring that the model's capacity grows sublinearly. We evaluate MoSEs
on the comprehensive TRACE benchmark datasets. Our experiments demonstrate that
MoSEs significantly outperform conventional continual learning approaches in
both knowledge retention and scalability to new tasks, achieving
state-of-the-art performance with substantial memory and computational savings.

</details>


### [307] [Constraint-Informed Active Learning for End-to-End ACOPF Optimization Proxies](https://arxiv.org/abs/2511.06248)
*Miao Li,Michael Klamkin,Pascal Van Hentenryck,Wenting Li,Russell Bent*

Main category: cs.LG

TL;DR: 本文提出了一种针对AC最优潮流优化代理的新型主动采样框架，通过优化特定量（有效约束集）来生成更真实多样的训练数据，显著提升代理模型的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 当前优化代理的性能严重依赖训练数据质量，现有采样方法难以生成足够多样和真实的训练数据，限制了优化代理的可靠性和泛化能力。

Method: 提出主动采样框架，通过探索变化灵活的问题规范来反映实际运行情况，并利用优化特定量（有效约束集）来更好地捕捉AC最优潮流问题的关键特征。

Result: 数值结果表明，在同等训练预算下，该方法相比现有采样方法具有更优的泛化性能，显著推进了可信赖AC最优潮流优化代理的实践水平。

Conclusion: 该主动采样框架有效解决了优化代理训练数据质量不足的问题，为AC最优潮流优化代理的实际应用提供了更可靠的技术支撑。

Abstract: This paper studies optimization proxies, machine learning (ML) models trained
to efficiently predict optimal solutions for AC Optimal Power Flow (ACOPF)
problems. While promising, optimization proxy performance heavily depends on
training data quality. To address this limitation, this paper introduces a
novel active sampling framework for ACOPF optimization proxies designed to
generate realistic and diverse training data. The framework actively explores
varied, flexible problem specifications reflecting plausible operational
realities. More importantly, the approach uses optimization-specific quantities
(active constraint sets) that better capture the salient features of an ACOPF
that lead to the optimal solution. Numerical results show superior
generalization over existing sampling methods with an equivalent training
budget, significantly advancing the state-of-practice for trustworthy ACOPF
optimization proxies.

</details>


### [308] [Test-Time Iterative Error Correction for Efficient Diffusion Models](https://arxiv.org/abs/2511.06250)
*Yunshan Zhong,Yanwei Qi,Yuxin Zhang*

Main category: cs.LG

TL;DR: 提出了IEC方法，通过迭代误差校正来减少高效扩散模型中的近似误差累积，将误差传播从指数增长降低到线性增长，无需重新训练或架构修改。


<details>
  <summary>Details</summary>
Motivation: 资源受限设备上的高效扩散模型因效率技术引入的近似误差导致生成质量下降，这些误差在部署后难以修正且会指数级累积。

Method: 提出迭代误差校正(IEC)方法，在推理时通过迭代精炼模型输出来减轻推理时误差，可无缝集成到现有扩散模型的推理过程中。

Result: 实验表明IEC在各种数据集、效率技术和模型架构上都能持续提高生成质量。

Conclusion: IEC是一种实用且可泛化的解决方案，可用于高效扩散模型的测试时增强。

Abstract: With the growing demand for high-quality image generation on
resource-constrained devices, efficient diffusion models have received
increasing attention. However, such models suffer from approximation errors
introduced by efficiency techniques, which significantly degrade generation
quality. Once deployed, these errors are difficult to correct, as modifying the
model is typically infeasible in deployment environments. Through an analysis
of error propagation across diffusion timesteps, we reveal that these
approximation errors can accumulate exponentially, severely impairing output
quality. Motivated by this insight, we propose Iterative Error Correction
(IEC), a novel test-time method that mitigates inference-time errors by
iteratively refining the model's output. IEC is theoretically proven to reduce
error propagation from exponential to linear growth, without requiring any
retraining or architectural changes. IEC can seamlessly integrate into the
inference process of existing diffusion models, enabling a flexible trade-off
between performance and efficiency. Extensive experiments show that IEC
consistently improves generation quality across various datasets, efficiency
techniques, and model architectures, establishing it as a practical and
generalizable solution for test-time enhancement of efficient diffusion models.

</details>


### [309] [MrCoM: A Meta-Regularized World-Model Generalizing Across Multi-Scenarios](https://arxiv.org/abs/2511.06252)
*Xuantang Xiong,Ni Mu,Runpeng Xie,Senhao Yang,Yaqing Wang,Lexiang Wang,Yao Luan,Siyuan Li,Shuang Xu,Yiqin Yang,Bo Xu*

Main category: cs.LG

TL;DR: 该论文提出了一种名为Meta-Regularized Contextual World-Model (MrCoM)的统一世界模型方法，旨在解决当前基于模型的强化学习方法在跨场景泛化方面的不足。


<details>
  <summary>Details</summary>
Motivation: 当前基于模型的强化学习方法主要关注单一任务的世界模型构建，很少处理不同场景间的泛化问题。作者观察到同一仿真引擎中的动态具有内在共性，因此尝试构建能够跨场景泛化的统一世界模型。

Method: MrCoM方法首先根据动态特性将潜在状态空间分解为不同组件，提高世界模型预测精度。然后采用元状态正则化提取场景相关信息的统一表示，以及元价值正则化在不同场景目标下对齐世界模型优化与策略学习。

Result: 论文从理论上分析了MrCoM在多场景设置下的泛化误差上界，并通过系统评估证明该方法在多样化场景中的泛化能力显著优于现有最先进方法。

Conclusion: MrCoM通过动态分解和元正则化技术成功构建了跨场景泛化的统一世界模型，在理论和实验上都表现出优越的性能。

Abstract: Model-based reinforcement learning (MBRL) is a crucial approach to enhance
the generalization capabilities and improve the sample efficiency of RL
algorithms. However, current MBRL methods focus primarily on building world
models for single tasks and rarely address generalization across different
scenarios. Building on the insight that dynamics within the same simulation
engine share inherent properties, we attempt to construct a unified world model
capable of generalizing across different scenarios, named Meta-Regularized
Contextual World-Model (MrCoM). This method first decomposes the latent state
space into various components based on the dynamic characteristics, thereby
enhancing the accuracy of world-model prediction. Further, MrCoM adopts
meta-state regularization to extract unified representation of
scenario-relevant information, and meta-value regularization to align
world-model optimization with policy learning across diverse scenario
objectives. We theoretically analyze the generalization error upper bound of
MrCoM in multi-scenario settings. We systematically evaluate our algorithm's
generalization ability across diverse scenarios, demonstrating significantly
better performance than previous state-of-the-art methods.

</details>


### [310] [Breaking the Modality Barrier: Generative Modeling for Accurate Molecule Retrieval from Mass Spectra](https://arxiv.org/abs/2511.06259)
*Yiwen Zhang,Keyan Ding,Yihang Wu,Xiang Zhuang,Yi Yang,Qiang Zhang,Huajun Chen*

Main category: cs.LG

TL;DR: GLMR是一个基于生成语言模型的检索框架，通过两阶段过程解决跨模态对齐问题，显著提升分子结构检索性能


<details>
  <summary>Details</summary>
Motivation: 现有检索方法存在谱库覆盖有限和跨模态对齐不佳的问题，导致检索精度和泛化能力不足

Method: 采用两阶段检索：预检索阶段使用对比学习模型识别候选分子作为上下文先验；生成检索阶段将候选分子与质谱整合，通过生成模型产生精炼分子结构进行重排序

Result: 在MassSpecGym和MassRET-20k数据集上，GLMR显著优于现有方法，top-1准确率提升超过40%，并表现出强泛化能力

Conclusion: GLMR通过缓解跨模态对齐问题，有效提升了分子结构检索的准确性和泛化性能

Abstract: Retrieving molecular structures from tandem mass spectra is a crucial step in
rapid compound identification. Existing retrieval methods, such as traditional
mass spectral library matching, suffer from limited spectral library coverage,
while recent cross-modal representation learning frameworks often encounter
modality misalignment, resulting in suboptimal retrieval accuracy and
generalization. To address these limitations, we propose GLMR, a Generative
Language Model-based Retrieval framework that mitigates the cross-modal
misalignment through a two-stage process. In the pre-retrieval stage, a
contrastive learning-based model identifies top candidate molecules as
contextual priors for the input mass spectrum. In the generative retrieval
stage, these candidate molecules are integrated with the input mass spectrum to
guide a generative model in producing refined molecular structures, which are
then used to re-rank the candidates based on molecular similarity. Experiments
on both MassSpecGym and the proposed MassRET-20k dataset demonstrate that GLMR
significantly outperforms existing methods, achieving over 40% improvement in
top-1 accuracy and exhibiting strong generalizability.

</details>


### [311] [CAMP-HiVe: Cyclic Pair Merging based Efficient DNN Pruning with Hessian-Vector Approximation for Resource-Constrained Systems](https://arxiv.org/abs/2511.06265)
*Mohammad Helal Uddin,Sai Krishna Ghanta,Liam Seymour,Sabur Baidya*

Main category: cs.LG

TL;DR: 提出了一种基于Hessian向量乘积的神经网络剪枝方法CAMP-HiVe，通过循环对合并和权重整合，在保持模型性能的同时显著降低计算需求。


<details>
  <summary>Details</summary>
Motivation: 深度学习算法在资源受限系统上的高效部署需求，现有神经网络剪枝方法需要更有效的压缩技术来平衡模型复杂度和性能。

Method: 利用Hessian-向量乘积近似损失函数的关键曲率信息，通过幂迭代方法识别和保留关键信息，采用循环对合并策略整合权重对。

Result: 在ResNet18、ResNet56、MobileNetv2等架构和CIFAR10、CIFAR-100、ImageNet数据集上，该方法在保持高性能的同时显著降低计算需求，优于现有最先进的剪枝方法。

Conclusion: CAMP-HiVe方法通过动态自适应框架实现了模型复杂度和性能的良好平衡，为资源受限环境下的神经网络部署提供了有效解决方案。

Abstract: Deep learning algorithms are becoming an essential component of many
artificial intelligence (AI) driven applications, many of which run on
resource-constrained and energy-constrained systems. For efficient deployment
of these algorithms, although different techniques for the compression of
neural network models are proposed, neural pruning is one of the fastest and
effective methods, which can provide a high compression gain with minimal cost.
To harness enhanced performance gain with respect to model complexity, we
propose a novel neural network pruning approach utilizing Hessian-vector
products that approximate crucial curvature information in the loss function,
which significantly reduces the computation demands. By employing a power
iteration method, our algorithm effectively identifies and preserves the
essential information, ensuring a balanced trade-off between model accuracy and
computational efficiency. Herein, we introduce CAMP-HiVe, a cyclic pair
merging-based pruning with Hessian Vector approximation by iteratively
consolidating weight pairs, combining significant and less significant weights,
thus effectively streamlining the model while preserving its performance. This
dynamic, adaptive framework allows for real-time adjustment of weight
significance, ensuring that only the most critical parameters are retained. Our
experimental results demonstrate that our proposed method achieves significant
reductions in computational requirements while maintaining high performance
across different neural network architectures, e.g., ResNet18, ResNet56, and
MobileNetv2, on standard benchmark datasets, e.g., CIFAR10, CIFAR-100, and
ImageNet, and it outperforms the existing state-of-the-art neural pruning
methods.

</details>


### [312] [LLM$^3$-DTI: A Large Language Model and Multi-modal data co-powered framework for Drug-Target Interaction prediction](https://arxiv.org/abs/2511.06269)
*Yuhao Zhang,Qinghong Guo,Qixian Chen,Liuwei Zhang,Hongyan Cui,Xiyi Chen*

Main category: cs.LG

TL;DR: 该论文提出了LLM^3-DTI框架，利用大语言模型和多模态数据来预测药物-靶点相互作用，通过双交叉注意力机制和TSFusion模块融合多模态嵌入，实验表明该方法优于对比模型。


<details>
  <summary>Details</summary>
Motivation: 药物-靶点相互作用预测对药物发现和药物再利用具有重要意义。随着大量有价值数据的积累，数据驱动方法被越来越多地用于预测DTI，以降低各方面成本。

Method: 提出LLM^3-DTI框架，构建多模态数据嵌入：使用领域特定LLM编码药物和靶点的文本语义嵌入；提出双交叉注意力机制和TSFusion模块来有效对齐和融合多模态嵌入；通过输出网络利用多模态数据进行DTI预测。

Result: 实验结果表明，LLM^3-DTI能够熟练识别经过验证的DTI，在不同场景下均优于对比模型。

Conclusion: LLM^3-DTI能够出色地完成DTI预测任务，数据代码已在GitHub开源。

Abstract: Drug-target interaction (DTI) prediction is of great significance for drug
discovery and drug repurposing. With the accumulation of a large volume of
valuable data, data-driven methods have been increasingly harnessed to predict
DTIs, reducing costs across various dimensions. Therefore, this paper proposes
a $\textbf{L}$arge $\textbf{L}$anguage $\textbf{M}$odel and
$\textbf{M}$ulti-$\textbf{M}$odel data co-powered $\textbf{D}$rug
$\textbf{T}$arget $\textbf{I}$nteraction prediction framework, named
LLM$^3$-DTI. LLM$^3$-DTI constructs multi-modal data embedding to enhance DTI
prediction performance. In this framework, the text semantic embeddings of
drugs and targets are encoded by a domain-specific LLM. To effectively align
and fuse multi-modal embedding. We propose the dual cross-attention mechanism
and the TSFusion module. Finally, these multi-modal data are utilized for the
DTI task through an output network. The experimental results indicate that
LLM$^3$-DTI can proficiently identify validated DTIs, surpassing the
performance of the models employed for comparison across diverse scenarios.
Consequently, LLM$^3$-DTI is adept at fulfilling the task of DTI prediction
with excellence. The data and code are available at
https://github.com/chaser-gua/LLM3DTI.

</details>


### [313] [COTN: A Chaotic Oscillatory Transformer Network for Complex Volatile Systems under Extreme Conditions](https://arxiv.org/abs/2511.06273)
*Boyan Tang,Yilong Zeng,Xuanhao Ren,Peng Xiao,Yuhan Zhao,Raymond Lee,Jianghua Wu*

Main category: cs.LG

TL;DR: 提出Chaotic Oscillatory Transformer Network (COTN)模型，结合Transformer架构和Lee Oscillator激活函数，有效预测金融市场和电力市场的极端波动情况。


<details>
  <summary>Details</summary>
Motivation: 金融市场和电力市场具有非线性、快速波动和混沌特性，传统激活函数在极端波动期间容易饱和，需要专门的方法来捕捉混沌动态。

Method: COTN将Transformer架构与新型Lee Oscillator激活函数结合，使用Max-over-Time池化和lambda-gating机制，并加入Autoencoder Self-Regressive模块来检测异常市场模式。

Result: 在电力现货市场和金融市场的实验中，COTN比最先进的深度学习模型Informer性能提升达17%，比传统统计方法GARCH提升高达40%。

Conclusion: COTN能够有效应对现实市场的不确定性和复杂性，为高度波动系统在压力条件下的预测提供了强大工具。

Abstract: Accurate prediction of financial and electricity markets, especially under
extreme conditions, remains a significant challenge due to their intrinsic
nonlinearity, rapid fluctuations, and chaotic patterns. To address these
limitations, we propose the Chaotic Oscillatory Transformer Network (COTN).
COTN innovatively combines a Transformer architecture with a novel Lee
Oscillator activation function, processed through Max-over-Time pooling and a
lambda-gating mechanism. This design is specifically tailored to effectively
capture chaotic dynamics and improve responsiveness during periods of
heightened volatility, where conventional activation functions (e.g., ReLU,
GELU) tend to saturate. Furthermore, COTN incorporates an Autoencoder
Self-Regressive (ASR) module to detect and isolate abnormal market patterns,
such as sudden price spikes or crashes, thereby preventing corruption of the
core prediction process and enhancing robustness. Extensive experiments across
electricity spot markets and financial markets demonstrate the practical
applicability and resilience of COTN. Our approach outperforms state-of-the-art
deep learning models like Informer by up to 17% and traditional statistical
methods like GARCH by as much as 40%. These results underscore COTN's
effectiveness in navigating real-world market uncertainty and complexity,
offering a powerful tool for forecasting highly volatile systems under duress.

</details>


### [314] [Achieving Fairness Without Harm via Selective Demographic Experts](https://arxiv.org/abs/2511.06293)
*Xuwei Tan,Yuanlong Wang,Thai-Hoang Pham,Ping Zhang,Xueru Zhang*

Main category: cs.LG

TL;DR: 提出了一种在医疗等高风险领域中实现公平性而不损害性能的方法，通过学习不同人口群体的特定表示和个性化分类器，并通过无伤害约束选择来应用人口专家。


<details>
  <summary>Details</summary>
Motivation: 现有偏见缓解技术通常在公平性和准确性之间进行权衡，可能无意中降低某些人口群体的性能。在临床诊断等高风险领域，这种权衡在伦理和实践上都是不可接受的。

Method: 学习不同人口群体的特定表示，构建由群体特定表示和个性化分类器组成的人口专家，通过无伤害约束选择来选择性应用这些专家。

Result: 在三个真实世界医疗数据集（眼病、皮肤癌和X射线诊断）以及两个人脸数据集上的广泛实证结果证明了该方法在实现公平性而不造成伤害方面的有效性。

Conclusion: 该方法能够在不损害任何人口群体性能的前提下实现公平性，特别适用于医疗等高风险领域。

Abstract: As machine learning systems become increasingly integrated into
human-centered domains such as healthcare, ensuring fairness while maintaining
high predictive performance is critical. Existing bias mitigation techniques
often impose a trade-off between fairness and accuracy, inadvertently degrading
performance for certain demographic groups. In high-stakes domains like
clinical diagnosis, such trade-offs are ethically and practically unacceptable.
In this study, we propose a fairness-without-harm approach by learning distinct
representations for different demographic groups and selectively applying
demographic experts consisting of group-specific representations and
personalized classifiers through a no-harm constrained selection. We evaluate
our approach on three real-world medical datasets -- covering eye disease, skin
cancer, and X-ray diagnosis -- as well as two face datasets. Extensive
empirical results demonstrate the effectiveness of our approach in achieving
fairness without harm.

</details>


### [315] [Transolver is a Linear Transformer: Revisiting Physics-Attention through the Lens of Linear Attention](https://arxiv.org/abs/2511.06294)
*Wenjie Hu,Sidun Liu,Peng Qiao,Zhenglun Sun,Yong Dou*

Main category: cs.LG

TL;DR: 该论文提出了一种名为Linear Attention Neural Operator (LinearNO)的新方法，通过将Transolver中的Physics-Attention重新设计为标准的线性注意力，在保持性能的同时显著降低了计算成本和参数数量。


<details>
  <summary>Details</summary>
Motivation: 作者观察到现有的Transolver方法中的Physics-Attention实际上是线性注意力的一个特例，而且切片注意力操作可能会损害模型性能。他们认为Physics-Attention的有效性主要来自于切片和反切片操作，而非切片间的交互。

Method: 提出了一个两步变换方法，将Physics-Attention重新设计为标准的线性注意力形式。该方法通过数学重构避免了复杂的切片注意力机制，简化了计算流程。

Result: 在六个标准PDE基准测试中达到了最先进的性能，平均减少40.0%的参数和36.2%的计算成本。在两个工业级数据集AirfRANS和Shape-Net Car上也表现出优越性能。

Conclusion: LinearNO方法证明了通过重新设计注意力机制可以同时实现性能提升和效率优化，为神经算子在PDE求解中的应用提供了更高效的解决方案。

Abstract: Recent advances in Transformer-based Neural Operators have enabled
significant progress in data-driven solvers for Partial Differential Equations
(PDEs). Most current research has focused on reducing the quadratic complexity
of attention to address the resulting low training and inference efficiency.
Among these works, Transolver stands out as a representative method that
introduces Physics-Attention to reduce computational costs. Physics-Attention
projects grid points into slices for slice attention, then maps them back
through deslicing. However, we observe that Physics-Attention can be
reformulated as a special case of linear attention, and that the slice
attention may even hurt the model performance. Based on these observations, we
argue that its effectiveness primarily arises from the slice and deslice
operations rather than interactions between slices. Building on this insight,
we propose a two-step transformation to redesign Physics-Attention into a
canonical linear attention, which we call Linear Attention Neural Operator
(LinearNO). Our method achieves state-of-the-art performance on six standard
PDE benchmarks, while reducing the number of parameters by an average of 40.0%
and computational cost by 36.2%. Additionally, it delivers superior performance
on two challenging, industrial-level datasets: AirfRANS and Shape-Net Car.

</details>


### [316] [3dSAGER: Geospatial Entity Resolution over 3D Objects (Technical Report)](https://arxiv.org/abs/2511.06300)
*Bar Genossar,Sagi Dalyot,Roee Shraga,Avigdor Gal*

Main category: cs.LG

TL;DR: 提出了3dSAGER，一种基于3D对象几何特征的端到端地理空间实体解析方法，解决了跨源数据中传统空间方法失效的问题。


<details>
  <summary>Details</summary>
Motivation: 现有地理空间实体解析方法依赖空间邻近性、文本元数据或外部标识符，但这些信号在跨源场景中常常不可用、不可靠或不对齐，特别是在坐标系不兼容的数据集之间。

Method: 3dSAGER采用空间参考无关的特征提取机制，捕捉匹配对的复杂几何特征；提出轻量级可解释的BKAFI阻塞方法，利用训练模型高效生成高召回候选集。

Result: 在真实城市数据集上的广泛实验验证了3dSAGER在准确性和效率上相对于强基线的显著提升。

Conclusion: 3dSAGER通过关注3D空间对象的内在几何特性，实现了在坐标系不兼容数据集间的鲁棒比较，为地理空间实体解析提供了新的解决方案。

Abstract: Urban environments are continuously mapped and modeled by various data
collection platforms, including satellites, unmanned aerial vehicles and street
cameras. The growing availability of 3D geospatial data from multiple
modalities has introduced new opportunities and challenges for integrating
spatial knowledge at scale, particularly in high-impact domains such as urban
planning and rapid disaster management. Geospatial entity resolution is the
task of identifying matching spatial objects across different datasets, often
collected independently under varying conditions. Existing approaches typically
rely on spatial proximity, textual metadata, or external identifiers to
determine correspondence. While useful, these signals are often unavailable,
unreliable, or misaligned, especially in cross-source scenarios. To address
these limitations, we shift the focus to the intrinsic geometry of 3D spatial
objects and present 3dSAGER (3D Spatial-Aware Geospatial Entity Resolution), an
end-to-end pipeline for geospatial entity resolution over 3D objects. 3dSAGER
introduces a novel, spatial-reference-independent featurization mechanism that
captures intricate geometric characteristics of matching pairs, enabling robust
comparison even across datasets with incompatible coordinate systems where
traditional spatial methods fail. As a key component of 3dSAGER, we also
propose a new lightweight and interpretable blocking method, BKAFI, that
leverages a trained model to efficiently generate high-recall candidate sets.
We validate 3dSAGER through extensive experiments on real-world urban datasets,
demonstrating significant gains in both accuracy and efficiency over strong
baselines. Our empirical study further dissects the contributions of each
component, providing insights into their impact and the overall design choices.

</details>


### [317] [Kaggle Chronicles: 15 Years of Competitions, Community and Data Science Innovation](https://arxiv.org/abs/2511.06304)
*Kevin Bönisch,Leandro Losaria*

Main category: cs.LG

TL;DR: 对Kaggle平台15年发展历程的元数据分析研究，探索数据科学竞赛、技术趋势和社区演变


<details>
  <summary>Details</summary>
Motivation: 利用Kaggle元数据和元代码库，深入分析数据科学竞赛平台的发展历程、技术趋势和社区影响

Method: 通过分析数百万个内核和讨论线程，进行纵向趋势分析和标准探索性数据分析

Result: 发现Kaggle是一个稳定增长且用例日益多样化的平台，参赛者能快速适应新趋势并应用于现实挑战，平均产生具有良好泛化能力的模型

Conclusion: 研究提供了平台的整体快照，突出了其历史和技术演变，并伴随视频和Kaggle写作供参考

Abstract: Since 2010, Kaggle has been a platform where data scientists from around the
world come together to compete, collaborate, and push the boundaries of Data
Science. Over these 15 years, it has grown from a purely competition-focused
site into a broader ecosystem with forums, notebooks, models, datasets, and
more. With the release of the Kaggle Meta Code and Kaggle Meta Datasets, we now
have a unique opportunity to explore these competitions, technologies, and
real-world applications of Machine Learning and AI. And so in this study, we
take a closer look at 15 years of data science on Kaggle - through metadata,
shared code, community discussions, and the competitions themselves. We explore
Kaggle's growth, its impact on the data science community, uncover hidden
technological trends, analyze competition winners, how Kagglers approach
problems in general, and more. We do this by analyzing millions of kernels and
discussion threads to perform both longitudinal trend analysis and standard
exploratory data analysis. Our findings show that Kaggle is a steadily growing
platform with increasingly diverse use cases, and that Kagglers are quick to
adapt to new trends and apply them to real-world challenges, while producing -
on average - models with solid generalization capabilities. We also offer a
snapshot of the platform as a whole, highlighting its history and technological
evolution. Finally, this study is accompanied by a video
(https://www.youtube.com/watch?v=YVOV9bIUNrM) and a Kaggle write-up
(https://kaggle.com/competitions/meta-kaggle-hackathon/writeups/kaggle-chronicles-15-years-of-competitions-communi)
for your convenience.

</details>


### [318] [DRIVE: Data Curation Best Practices for Reinforcement Learning with Verifiable Reward in Competitive Code Generation](https://arxiv.org/abs/2511.06307)
*Speed Zhu,Jianwei Cai,Guang Chen,Lulu Wu,Saiyong Yang,Wiggin Zhou*

Main category: cs.LG

TL;DR: 该论文提出了一种针对竞争性编程代码生成的RLVR（强化学习验证推理）方法，通过两阶段训练流程和精心设计的数据集构建策略，在Qwen2.5-32B模型上实现了与顶尖系统相当的性能。


<details>
  <summary>Details</summary>
Motivation: 当前推理优先模型在数学领域取得显著进展，但竞争性编程代码生成领域研究不足，数据构建受到的关注少于RL算法设计。

Method: 采用两阶段RL训练：第一阶段使用GRPO在大规模均匀分布的问题集上进行训练，第二阶段进行Pre-GRPO，在高质量挑战性问题集上采用硬焦点课程学习。整个流程从SFT开始，结合可执行测试用例驱动的奖励机制。

Result: 在LeetCode和Codeforces周赛上的评估显示，该方法在相似规模模型中达到最先进性能，与DeepSeek v3.1和Doubao-1.5-Thinking等领先系统相当。

Conclusion: 研究总结了数据构建、熵扩展和课程设计在竞争性编程代码生成RLVR中的最佳实践，并观察到在大规模MoE模型上具有强大的RL扩展性。

Abstract: Recent reasoning-first models (e.g., OpenAI o1, DeepSeek R1) have spurred a
resurgence of interest in RLVR. Nevertheless, advances are dominated by
mathematics (e.g., AIME), with competitive-programming code generation
underexplored and data curation receiving less attention than RL algorithm
design. We investigate how to construct RLVR datasets (i.e., RL prompts) and
present practical training techniques that yield strong performance on
competitive-programming code generation. Our pipeline begins with supervised
fine-tuning (SFT) distilled from strong open-source models, augmented with
general-purpose and reasoning-intensive data. RL then follows a two-stage
process with executable, testcase-driven rewards: first, training on a large,
uniformly distributed set of competitive-programming problems using Group
Relative Policy Optimization (GRPO) with 8 rollouts per prompt and a relatively
short response-generation window (e.g., 32k during SFT and 24k in this stage)
to expand entropy and mitigate repetition and truncation; second, we perform
\textbf{Pre-GRPO}: updating on a small, high-quality set of challenging
problems with a large rollout budget (64 rollouts per prompt) under a
hard-focus curriculum that continuously retains the most difficult instances
throughout training. We implement our method on Qwen2.5-32B and evaluate on
LeetCode and Codeforces weekly contests to avoid data leakage. The resulting
model achieves state-of-the-art performance among models of similar scale and
is comparable to leading systems such as DeepSeek v3.1 and Doubao-1.5-Thinking.
We also examine scaling trends and observe strong RL scaling on an internal
large-scale MoE model. Our study distills concise best practices for data
curation, entropy expansion, and curriculum design in RLVR for
competitive-programming code generation.

</details>


### [319] [Reaction Prediction via Interaction Modeling of Symmetric Difference Shingle Sets](https://arxiv.org/abs/2511.06356)
*Runhan Shi,Letian Chen,Gufeng Yu,Yang Yang*

Main category: cs.LG

TL;DR: ReaDISH是一个新颖的化学反应预测模型，通过对称差分shingle编码和几何结构交互注意力机制，解决了现有模型对输入排列敏感和子结构交互建模不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习模型在化学反应预测中存在两个关键局限：对输入排列（分子/原子顺序）的敏感性，以及对控制反应性的子结构交互建模不足，导致预测不一致和泛化能力差。

Method: 1. 对称差分shingle编码：计算分子shingle差异以捕捉反应特异性结构变化，同时消除顺序敏感性；2. 几何结构交互注意力：在shingle级别建模分子内和分子间交互。

Result: 大量实验表明，ReaDISH在多种基准测试中提高了反应预测性能。在排列扰动下，R²平均提高了8.76%，显示出增强的鲁棒性。

Conclusion: ReaDISH通过创新的编码和注意力机制，有效解决了化学反应预测中的排列敏感性和交互建模问题，显著提升了预测性能和鲁棒性。

Abstract: Chemical reaction prediction remains a fundamental challenge in organic
chemistry, where existing machine learning models face two critical
limitations: sensitivity to input permutations (molecule/atom orderings) and
inadequate modeling of substructural interactions governing reactivity. These
shortcomings lead to inconsistent predictions and poor generalization to
real-world scenarios. To address these challenges, we propose ReaDISH, a novel
reaction prediction model that learns permutation-invariant representations
while incorporating interaction-aware features. It introduces two innovations:
(1) symmetric difference shingle encoding, which computes molecular shingle
differences to capture reaction-specific structural changes while eliminating
order sensitivity; and (2) geometry-structure interaction attention, a
mechanism that models intra- and inter-molecular interactions at the shingle
level. Extensive experiments demonstrate that ReaDISH improves reaction
prediction performance across diverse benchmarks. It shows enhanced robustness
with an average improvement of 8.76% on R$^2$ under permutation perturbations.

</details>


### [320] [Privacy-Preserving Federated Learning for Fair and Efficient Urban Traffic Optimization](https://arxiv.org/abs/2511.06363)
*Rathin Chandra Shit,Sharmila Subudhi*

Main category: cs.LG

TL;DR: FedFair-Traffic是一个隐私保护的联邦学习框架，首次将出行效率、交通公平性和差分隐私保护三个冲突目标联合优化，在METR-LA数据集上实现了7%的旅行时间减少、73%的公平性提升和0.8的隐私评分。


<details>
  <summary>Details</summary>
Motivation: 当前集中式交通管理方案侵犯用户位置隐私并加剧交通不平等，而现有联邦学习框架未考虑多目标交通环境中的公平性约束。

Method: 整合图神经网络与差分隐私机制（ε-隐私保证）和基尼系数公平约束，采用梯度裁剪和噪声注入的联邦聚合方法进行多目标优化。

Result: 在METR-LA数据集上，平均旅行时间减少7%（14.2分钟），交通公平性提升73%（基尼系数0.78），隐私保护评分0.8，通信开销降低89%。

Conclusion: FedFair-Traffic是一个可扩展的隐私感知智慧城市基础设施，适用于大都市交通流控制和联邦交通网络。

Abstract: The optimization of urban traffic is threatened by the complexity of
achieving a balance between transport efficiency and the maintenance of
privacy, as well as the equitable distribution of traffic based on
socioeconomically diverse neighborhoods. Current centralized traffic management
schemes invade user location privacy and further entrench traffic disparity by
offering disadvantaged route suggestions, whereas current federated learning
frameworks do not consider fairness constraints in multi-objective traffic
settings. This study presents a privacy-preserving federated learning
framework, termed FedFair-Traffic, that jointly and simultaneously optimizes
travel efficiency, traffic fairness, and differential privacy protection. This
is the first attempt to integrate three conflicting objectives to improve urban
transportation systems. The proposed methodology enables collaborative learning
between related vehicles with data locality by integrating Graph Neural
Networks with differential privacy mechanisms ($\epsilon$-privacy guarantees)
and Gini coefficient-based fair constraints using multi-objective optimization.
The framework uses federated aggregation methods of gradient clipping and noise
injection to provide differential privacy and optimize Pareto-efficient
solutions for the efficiency-fairness tradeoff. Real-world comprehensive
experiments on the METR-LA traffic dataset showed that FedFair-Traffic can
reduce the average travel time by 7\% (14.2 minutes) compared with their
centralized baselines, promote traffic fairness by 73\% (Gini coefficient,
0.78), and offer high privacy protection (privacy score, 0.8) with an 89\%
reduction in communication overhead. These outcomes demonstrate that
FedFair-Traffic is a scalable privacy-aware smart city infrastructure with
possible use-cases in metropolitan traffic flow control and federated
transportation networks.

</details>


### [321] [Adaptive Regularization for Large-Scale Sparse Feature Embedding Models](https://arxiv.org/abs/2511.06374)
*Mang Li,Wei Lyu*

Main category: cs.LG

TL;DR: 本文分析了使用大规模稀疏分类特征的模型在多个训练周期中性能下降的问题，提出了理论解释和自适应正则化方法来解决这一问题。


<details>
  <summary>Details</summary>
Motivation: 在搜索、广告和推荐领域的CTR和CVR预估模型中，使用大规模稀疏分类特征的模型在多个训练周期中经常出现性能显著下降的过拟合问题，现有启发式解决方案未能明确根本原因。

Method: 基于理论分析，提出了一种自适应正则化方法，该方法不仅防止多周期训练中的性能下降，还能在单周期内提升模型性能。

Result: 该方法已在在线生产系统中部署，有效解决了过拟合问题。

Conclusion: 通过理论分析揭示了过拟合的根本原因，提出的自适应正则化方法在实践中证明了其有效性。

Abstract: The one-epoch overfitting problem has drawn widespread attention, especially
in CTR and CVR estimation models in search, advertising, and recommendation
domains. These models which rely heavily on large-scale sparse categorical
features, often suffer a significant decline in performance when trained for
multiple epochs. Although recent studies have proposed heuristic solutions,
they have not clearly identified the fundamental cause of this phenomenon. In
this work, we provide a theoretical analysis that explains why overfitting
occurs in models that use large-scale sparse categorical features. Based on
this analysis, we propose an adaptive regularization method to address it. Our
approach not only prevents the severe performance degradation observed during
multi-epoch training, but also improves model performance within a single
epoch. This method has already been deployed in online production systems.

</details>


### [322] [Vocabulary In-Context Learning in Transformers: Benefits of Positional Encoding](https://arxiv.org/abs/2511.06376)
*Qian Ma,Ruoxiang Xu,Yongqiang Cai*

Main category: cs.LG

TL;DR: 本文研究了词汇上下文学习（VICL）在Transformer架构中的通用逼近性质（UAP），发现无位置编码的单层Transformer不具备UAP，但加入位置编码后可以实现UAP。


<details>
  <summary>Details</summary>
Motivation: 探讨Transformer架构在词汇上下文学习场景下的逼近能力，特别关注位置编码对模型表达能力的影响。

Method: 通过理论分析研究单层Transformer在词汇上下文学习中的通用逼近性质，比较有无位置编码情况下的表达能力差异。

Result: 无位置编码的单层Transformer在VICL中不具备UAP，但加入位置编码后可以实现UAP，并提供了位置编码的若干充分条件。

Conclusion: 位置编码在上下文学习中具有重要的理论价值，能够显著提升模型的逼近能力。

Abstract: Numerous studies have demonstrated that the Transformer architecture
possesses the capability for in-context learning (ICL). In scenarios involving
function approximation, context can serve as a control parameter for the model,
endowing it with the universal approximation property (UAP). In practice,
context is represented by tokens from a finite set, referred to as a
vocabulary, which is the case considered in this paper, \emph{i.e.}, vocabulary
in-context learning (VICL). We demonstrate that VICL in single-layer
Transformers, without positional encoding, does not possess the UAP; however,
it is possible to achieve the UAP when positional encoding is included. Several
sufficient conditions for the positional encoding are provided. Our findings
reveal the benefits of positional encoding from an approximation theory
perspective in the context of ICL.

</details>


### [323] [CG-TTRL: Context-Guided Test-Time Reinforcement Learning for On-Device Large Language Models](https://arxiv.org/abs/2511.06430)
*Peyman Hosseini,Ondrej Bohdal,Taha Ceritli,Ignacio Castro,Matthew Purver,Mete Ozay,Umberto Michieli*

Main category: cs.LG

TL;DR: CG-TTRL通过动态整合上下文到两阶段采样策略中，提升测试时强化学习的性能与效率


<details>
  <summary>Details</summary>
Motivation: 现有TTRL方法未充分利用上下文指导，而上下文学习在推理时已证明能提升模型性能

Method: 提出上下文引导的TTRL（CG-TTRL），在初始利用阶段通过上下文提升伪标签准确性，在第二阶段通过上下文调节探索过程，并提出高效上下文选择方法

Result: 在数学和科学QA基准测试中，CG-TTRL相比TTRL获得额外7%的相对准确率提升，仅需3步训练即可获得8%相对改进

Conclusion: 动态整合上下文到TTRL的两阶段采样策略能显著提升性能与效率，适用于设备端应用

Abstract: Test-time Reinforcement Learning (TTRL) has shown promise in adapting
foundation models for complex tasks at test-time, resulting in large
performance improvements. TTRL leverages an elegant two-phase sampling
strategy: first, multi-sampling derives a pseudo-label via majority voting,
while subsequent downsampling and reward-based fine-tuning encourages the model
to explore and learn diverse valid solutions, with the pseudo-label modulating
the reward signal. Meanwhile, in-context learning has been widely explored at
inference time and demonstrated the ability to enhance model performance
without weight updates. However, TTRL's two-phase sampling strategy
under-utilizes contextual guidance, which can potentially improve pseudo-label
accuracy in the initial exploitation phase while regulating exploration in the
second. To address this, we propose context-guided TTRL (CG-TTRL), integrating
context dynamically into both sampling phases and propose a method for
efficient context selection for on-device applications. Our evaluations on
mathematical and scientific QA benchmarks show CG-TTRL outperforms TTRL (e.g.
additional 7% relative accuracy improvement over TTRL), while boosting
efficiency by obtaining strong performance after only a few steps of test-time
training (e.g. 8% relative improvement rather than 1% over TTRL after 3 steps).

</details>


### [324] [How Wide and How Deep? Mitigating Over-Squashing of GNNs via Channel Capacity Constrained Estimation](https://arxiv.org/abs/2511.06443)
*Zinuo You,Jin Zheng,John Cartlidge*

Main category: cs.LG

TL;DR: 提出C3E框架，通过信息论方法解决GNN中隐藏维度和传播深度的启发式选择问题，缓解信息过压缩现象


<details>
  <summary>Details</summary>
Motivation: 现有图神经网络依赖启发式选择隐藏维度和传播深度，导致传播过程中严重的信息损失（过压缩问题）

Method: 提出C3E框架，将隐藏维度和深度选择建模为基于信息论的非线性规划问题，将谱图神经网络建模为通信信道

Result: 在9个公共数据集上的实验表明，C3E估计的隐藏维度和深度能缓解过压缩并提升表示学习性能

Conclusion: 发现过压缩源于表示矩阵中信息的累积压缩，增加隐藏维度确实缓解信息压缩，而传播深度的作用更微妙，揭示了信息压缩与表示复杂性之间的基本平衡

Abstract: Existing graph neural networks typically rely on heuristic choices for hidden
dimensions and propagation depths, which often lead to severe information loss
during propagation, known as over-squashing. To address this issue, we propose
Channel Capacity Constrained Estimation (C3E), a novel framework that
formulates the selection of hidden dimensions and depth as a nonlinear
programming problem grounded in information theory. Through modeling spectral
graph neural networks as communication channels, our approach directly connects
channel capacity to hidden dimensions, propagation depth, propagation
mechanism, and graph structure. Extensive experiments on nine public datasets
demonstrate that hidden dimensions and depths estimated by C3E can mitigate
over-squashing and consistently improve representation learning. Experimental
results show that over-squashing occurs due to the cumulative compression of
information in representation matrices. Furthermore, our findings show that
increasing hidden dimensions indeed mitigate information compression, while the
role of propagation depth is more nuanced, uncovering a fundamental balance
between information compression and representation complexity.

</details>


### [325] [FLEX: Continuous Agent Evolution via Forward Learning from Experience](https://arxiv.org/abs/2511.06449)
*Zhicheng Cai,Xinyuan Guo,Yu Pei,JiangTao Feng,Jiangjie Chen,Ya-Qin Zhang,Wei-Ying Ma,Mingxuan Wang,Hao Zhou*

Main category: cs.LG

TL;DR: FLEX是一种无需梯度的学习范式，使LLM驱动的自主智能体能够通过积累经验持续进化，在数学推理、化学逆合成和蛋白质适应性预测等任务上取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的自主智能体在训练后保持静态，无法像智能生物一样在部署过程中通过经验积累实现成长。

Method: FLEX通过构建结构化的经验库，在智能体与环境交互过程中持续反思成功和失败的经验，实现可扩展和可继承的进化。

Result: 在AIME25上提升23%，USPTO50k上提升10%，ProteinGym上提升14%，并发现了经验增长的扩展规律和跨智能体经验继承现象。

Conclusion: FLEX标志着向可扩展和可继承的连续智能体进化迈出了重要一步。

Abstract: Autonomous agents driven by Large Language Models (LLMs) have revolutionized
reasoning and problem-solving but remain static after training, unable to grow
with experience as intelligent beings do during deployment. We introduce
Forward Learning with EXperience (FLEX), a gradient-free learning paradigm that
enables LLM agents to continuously evolve through accumulated experience.
Specifically, FLEX cultivates scalable and inheritable evolution by
constructing a structured experience library through continual reflection on
successes and failures during interaction with the environment. FLEX delivers
substantial improvements on mathematical reasoning, chemical retrosynthesis,
and protein fitness prediction (up to 23% on AIME25, 10% on USPTO50k, and 14%
on ProteinGym). We further identify a clear scaling law of experiential growth
and the phenomenon of experience inheritance across agents, marking a step
toward scalable and inheritable continuous agent evolution. Project Page:
https://flex-gensi-thuair.github.io.

</details>


### [326] [A Risk-Neutral Neural Operator for Arbitrage-Free SPX-VIX Term Structures](https://arxiv.org/abs/2511.06451)
*Jian'an Zhang*

Main category: cs.LG

TL;DR: ARBITER是一个风险中性的神经算子，用于在无套利约束下学习SPX-VIX联合期限结构，通过约束解码器和投影技术确保静态套利约束。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以同时处理SPX和VIX的期限结构并保证无套利条件，需要开发能够自动执行这些约束的神经网络模型。

Method: 结合算子学习与约束解码器，使用外梯度风格更新加投影进行训练，强制实施日历套利、垂直套利、蝶式套利等约束以及Lipschitz边界和单调性。

Result: 在历史SPX和VIX数据上优于傅里叶神经算子、DeepONet和状态空间序列模型，通过绑定SPX和VIX腿减少对偶间隙并改善数值积分。

Conclusion: ARBITER提供了可识别的近似结果，以及跨期限和行权价的无套利插值和外推的实用方法，Lipschitz投影稳定了校准过程。

Abstract: We propose ARBITER, a risk-neutral neural operator for learning joint SPX-VIX
term structures under no-arbitrage constraints. ARBITER maps market states to
an operator that outputs implied volatility and variance curves while enforcing
static arbitrage (calendar, vertical, butterfly), Lipschitz bounds, and
monotonicity. The model couples operator learning with constrained decoders and
is trained with extragradient-style updates plus projection. We introduce
evaluation metrics for derivatives term structures (NAS, CNAS, NI, Dual-Gap,
Stability Rate) and show gains over Fourier Neural Operator, DeepONet, and
state-space sequence models on historical SPX and VIX data. Ablation studies
indicate that tying the SPX and VIX legs reduces Dual-Gap and improves NI,
Lipschitz projection stabilizes calibration, and selective state updates
improve long-horizon generalization. We provide identifiability and
approximation results and describe practical recipes for arbitrage-free
interpolation and extrapolation across maturities and strikes.

</details>


### [327] [MULTIBENCH++: A Unified and Comprehensive Multimodal Fusion Benchmarking Across Specialized Domains](https://arxiv.org/abs/2511.06452)
*Leyan Xue,Zongbo Han,Kecheng Xue,Xiaohong Liu,Guangyu Wang,Changqing Zhang*

Main category: cs.LG

TL;DR: 该论文针对多模态融合领域缺乏充分评估基准的问题，开发了一个大规模、领域自适应的多模态评估基准和开源评估管道，旨在推动多模态AI发展。


<details>
  <summary>Details</summary>
Motivation: 当前多模态融合方法在有限的数据集上进行评估，无法充分代表现实世界的复杂性和多样性，导致评估偏差，阻碍了通用高性能融合模型的发展。

Method: 开发了集成30多个数据集、涵盖15种模态和20种预测任务的大规模基准，并建立了开源、统一、自动化的评估管道，包含标准化实现的最先进模型和多样化融合范式。

Result: 通过大规模实验成功建立了多个任务的新性能基线，为学术社区提供了严格可复现的多模态模型评估平台。

Conclusion: 该工作为解决多模态融合评估不足的问题提供了重要解决方案，有望推动多模态人工智能领域达到新的高度。

Abstract: Although multimodal fusion has made significant progress, its advancement is
severely hindered by the lack of adequate evaluation benchmarks. Current fusion
methods are typically evaluated on a small selection of public datasets, a
limited scope that inadequately represents the complexity and diversity of
real-world scenarios, potentially leading to biased evaluations. This issue
presents a twofold challenge. On one hand, models may overfit to the biases of
specific datasets, hindering their generalization to broader practical
applications. On the other hand, the absence of a unified evaluation standard
makes fair and objective comparisons between different fusion methods
difficult. Consequently, a truly universal and high-performance fusion model
has yet to emerge. To address these challenges, we have developed a
large-scale, domain-adaptive benchmark for multimodal evaluation. This
benchmark integrates over 30 datasets, encompassing 15 modalities and 20
predictive tasks across key application domains. To complement this, we have
also developed an open-source, unified, and automated evaluation pipeline that
includes standardized implementations of state-of-the-art models and diverse
fusion paradigms. Leveraging this platform, we have conducted large-scale
experiments, successfully establishing new performance baselines across
multiple tasks. This work provides the academic community with a crucial
platform for rigorous and reproducible assessment of multimodal models, aiming
to propel the field of multimodal artificial intelligence to new heights.

</details>


### [328] [Reconstruction and Secrecy under Approximate Distance Queries](https://arxiv.org/abs/2511.06461)
*Shay Moran,Elizaveta Nesterova*

Main category: cs.LG

TL;DR: 该论文研究了使用近似距离查询定位未知目标点的问题，从学习理论的角度分析了最佳可能重建误差的速率和极限。


<details>
  <summary>Details</summary>
Motivation: 该问题自然出现在GPS定位、传感器网络、隐私感知数据访问等各种场景中，涉及多种度量空间。从重建者（寻求准确恢复）和响应者（旨在限制信息泄露）的角度都具有相关性。

Method: 通过学习理论视角研究重建博弈，重点关注最优误差的几何特征和渐近行为。第一个结果使用Chebyshev半径对最优误差进行几何表征，第二个结果区分伪有限空间和具有非平凡衰减的近似曲线空间。

Result: 得到了对所有紧致度量空间（甚至所有完全有界空间）适用的最优误差的紧致几何表征，并给出了自然度量空间的显式公式。同时刻画了凸欧几里得空间的伪有限性。

Conclusion: 该研究为距离查询定位问题提供了理论框架，揭示了最优重建误差的几何本质和空间结构的渐近行为特征。

Abstract: Consider the task of locating an unknown target point using approximate
distance queries: in each round, a reconstructor selects a query point and
receives a noisy version of its distance to the target. This problem arises
naturally in various contexts ranging from localization in GPS and sensor
networks to privacy-aware data access, and spans a wide variety of metric
spaces. It is relevant from the perspective of both the reconstructor (seeking
accurate recovery) and the responder (aiming to limit information disclosure,
e.g., for privacy or security reasons). We study this reconstruction game
through a learning-theoretic lens, focusing on the rate and limits of the best
possible reconstruction error. Our first result provides a tight geometric
characterization of the optimal error in terms of the Chebyshev radius, a
classical concept from geometry. This characterization applies to all compact
metric spaces (in fact, even to all totally bounded spaces) and yields explicit
formulas for natural metric spaces. Our second result addresses the asymptotic
behavior of reconstruction, distinguishing between pseudo-finite spaces --
where the optimal error is attained after finitely many queries -- and spaces
where the approximation curve exhibits nontrivial decay. We characterize
pseudo-finiteness for convex Euclidean spaces.

</details>


### [329] [Error Estimate and Convergence Analysis for Data Valuation](https://arxiv.org/abs/2511.06463)
*Zhangyong Liang,Huanhuan Gao,Ji Zhang*

Main category: cs.LG

TL;DR: 本文提出了神经动态数据估值（NDDV）方法，首次在数据估值中探索误差估计和收敛性分析，证明了在Lipschitz和平滑性假设下损失差异的二次误差界，以及训练损失梯度范数的渐近消失和元损失的次线性收敛。


<details>
  <summary>Details</summary>
Motivation: 现有数据估值方法无法在单次训练过程中确保有效性，NDDV方法旨在解决这一局限性。

Method: 基于神经动态数据估值（NDDV）方法，在Lipschitz和平滑性假设下进行误差估计和收敛性分析。

Result: 推导出损失差异的二次误差界（与时间步长成反比，与控制变量变化成二次关系），证明了训练损失梯度范数的渐近消失和元损失的次线性收敛。

Conclusion: NDDV方法实现了次线性收敛，为数据估值提供了理论保证和稳定性。

Abstract: Data valuation quantifies data importance, but existing methods cannot ensure
validity in a single training process. The neural dynamic data valuation (NDDV)
method [3] addresses this limitation. Based on NDDV, we are the first to
explore error estimation and convergence analysis in data valuation. Under
Lipschitz and smoothness assumptions, we derive quadratic error bounds for loss
differences that scale inversely with time steps and quadratically with control
variations, ensuring stability. We also prove that the expected squared
gradient norm for the training loss vanishes asymptotically, and that the meta
loss converges sublinearly over iterations. In particular, NDDV achieves
sublinear convergence.

</details>


### [330] [DyKAF: Dynamical Kronecker Approximation of the Fisher Information Matrix for Gradient Preconditioning](https://arxiv.org/abs/2511.06477)
*Nikolay Yudin,Ekaterina Grishina,Andrey Veprikov,Alexandr Beznosikov,Maxim Rakhuba*

Main category: cs.LG

TL;DR: 提出DyKAF优化器，利用投影器分裂积分器构建有效的预处理器，在大型语言模型预训练和微调中优于现有优化器


<details>
  <summary>Details</summary>
Motivation: 现有将权重视为矩阵而非展平向量的优化器虽然有效，但Fisher矩阵的结构化近似方法在效率和准确性方面仍面临挑战，最优分解资源密集且依赖启发式设计

Method: 引入投影器分裂积分器来构建有效的预处理器，开发DyKAF优化器，动态改进Fisher矩阵近似质量

Result: 实验表明DyKAF在大型语言模型预训练和微调任务中，在一系列评估指标上均优于现有优化器

Conclusion: DyKAF方法通过新颖的投影器分裂积分器技术，成功解决了Fisher矩阵结构化近似的效率与准确性平衡问题

Abstract: Recently, optimizers that explicitly treat weights as matrices, rather than
flattened vectors, have demonstrated their effectiveness. This perspective
naturally leads to structured approximations of the Fisher matrix as
preconditioners, where the matrix view induces a Kronecker-factorized form that
enables memory-efficient representation. However, constructing such
approximations both efficiently and accurately remains an open challenge, since
obtaining the optimal factorization is resource-intensive and practical methods
therefore rely on heuristic design choices. In this work, we introduce a novel
approach that leverages projector-splitting integrators to construct effective
preconditioners. Our optimizer, DyKAF (Dynamical Kronecker Approximation of the
Fisher Matrix), consistently improves the Fisher matrix approximation quality.
Experiments on large language model pre-training and fine-tuning demonstrate
that DyKAF outperforms existing optimizers across a range of evaluation
metrics.

</details>


### [331] [Explainable AI For Early Detection Of Sepsis](https://arxiv.org/abs/2511.06492)
*Atharva Thakur,Shruti Dhumal*

Main category: cs.LG

TL;DR: 提出一种可解释的AI方法用于脓毒症分析，将机器学习与临床知识相结合，提高预测准确性和临床可信度


<details>
  <summary>Details</summary>
Motivation: 脓毒症是一种危及生命的疾病，需要快速检测和治疗。虽然现有的机器学习模型在预测脓毒症发作方面显示出潜力，但其黑盒性质限制了可解释性和临床信任度

Method: 开发一种可解释的AI方法，整合机器学习与临床知识，使临床医生能够理解、验证并使模型输出与既定的医学专业知识保持一致

Result: 该方法不仅能够准确预测脓毒症发作，还提供了可解释的预测结果

Conclusion: 可解释的AI方法有助于提高脓毒症预测的临床适用性和可信度，促进机器学习在医疗领域的更广泛应用

Abstract: Sepsis is a life-threatening condition that requires rapid detection and
treatment to prevent progression to severe sepsis, septic shock, or multi-organ
failure. Despite advances in medical technology, it remains a major challenge
for clinicians. While recent machine learning models have shown promise in
predicting sepsis onset, their black-box nature limits interpretability and
clinical trust. In this study, we present an interpretable AI approach for
sepsis analysis that integrates machine learning with clinical knowledge. Our
method not only delivers accurate predictions of sepsis onset but also enables
clinicians to understand, validate, and align model outputs with established
medical expertise.

</details>


### [332] [Learning Time-Varying Graph Signals via Koopman](https://arxiv.org/abs/2511.06493)
*Sivaram Krishnan,Jinho Choi,Jihong Park*

Main category: cs.LG

TL;DR: 提出基于Koopman自编码器（KAE）的框架处理时变图数据，通过图嵌入将图结构转换为向量时间序列，在潜在空间中学习非线性动力学，实现图数据的预测和重建。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据（如海洋传感器温度测量、无人机轨迹）常表示为具有非欧几里得结构的图，且这些图会随时间演化。有效建模和分析动态图数据对预测图演化和重建缺失图数据至关重要。

Method: 1. 将时变图数据通过图嵌入转换为向量时间序列；2. 在潜在空间中应用KAE学习控制图特征时间演化的非线性动力学；3. 假设存在隐藏的非线性动力系统，状态向量对应图嵌入。

Result: 框架能够同时处理图结构的时变特性和图信号的时间演化，支持预测和重建任务。

Conclusion: KAE框架为处理时变图数据提供了一种有效方法，通过结合图嵌入和Koopman理论，能够捕捉复杂的动态图演化模式。

Abstract: A wide variety of real-world data, such as sea measurements, e.g.,
temperatures collected by distributed sensors and multiple unmanned aerial
vehicles (UAV) trajectories, can be naturally represented as graphs, often
exhibiting non-Euclidean structures. These graph representations may evolve
over time, forming time-varying graphs. Effectively modeling and analyzing such
dynamic graph data is critical for tasks like predicting graph evolution and
reconstructing missing graph data. In this paper, we propose a framework based
on the Koopman autoencoder (KAE) to handle time-varying graph data.
Specifically, we assume the existence of a hidden non-linear dynamical system,
where the state vector corresponds to the graph embedding of the time-varying
graph signals. To capture the evolving graph structures, the graph data is
first converted into a vector time series through graph embedding, representing
the structural information in a finite-dimensional latent space. In this latent
space, the KAE is applied to learn the underlying non-linear dynamics governing
the temporal evolution of graph features, enabling both prediction and
reconstruction tasks.

</details>


### [333] [Route Experts by Sequence, not by Token](https://arxiv.org/abs/2511.06494)
*Tiansheng Wen,Yifei Wang,Aosong Feng,Long Ma,Xinyang Liu,Yifan Wang,Lixuan Guo,Bo Chen,Stefanie Jegelka,Chenyu You*

Main category: cs.LG

TL;DR: SeqTopK是一种改进的MoE路由策略，将专家预算从令牌级别转移到序列级别，实现动态专家分配，无需额外参数或重新训练。


<details>
  <summary>Details</summary>
Motivation: 标准TopK路由为所有令牌分配固定数量的专家，忽略了令牌复杂度的差异。现有自适应方法需要额外模块和重新训练，成本高昂。

Method: 通过选择序列中所有令牌的前T·K个专家，实现端到端学习的动态分配，困难令牌获得更多专家，简单令牌获得更少专家。

Result: 在数学、编程、法律和写作任务上均优于TopK和现有参数自由方法，在高稀疏度下提升显著（最高达16.9%）。

Conclusion: SeqTopK是一种简单、高效、可扩展的路由策略，特别适合下一代LLM的极端稀疏场景。

Abstract: Mixture-of-Experts (MoE) architectures scale large language models (LLMs) by
activating only a subset of experts per token, but the standard TopK routing
assigns the same fixed number of experts to all tokens, ignoring their varying
complexity. Prior adaptive routing methods introduce additional modules and
hyperparameters, often requiring costly retraining from scratch. We propose
Sequence-level TopK (SeqTopK), a minimal modification that shifts the expert
budget from the token level to the sequence level. By selecting the top $T
\cdot K$ experts across all $T$ tokens, SeqTopK enables end-to-end learned
dynamic allocation -- assigning more experts to difficult tokens and fewer to
easy ones -- while preserving the same overall budget. SeqTopK requires only a
few lines of code, adds less than 1% overhead, and remains fully compatible
with pretrained MoE models. Experiments across math, coding, law, and writing
show consistent improvements over TopK and prior parameter-free adaptive
methods, with gains that become substantially larger under higher sparsity (up
to 16.9%). These results highlight SeqTopK as a simple, efficient, and scalable
routing strategy, particularly well-suited for the extreme sparsity regimes of
next-generation LLMs. Code is available at
https://github.com/Y-Research-SBU/SeqTopK.

</details>


### [334] [Probably Approximately Global Robustness Certification](https://arxiv.org/abs/2511.06495)
*Peter Blohm,Patrick Indri,Thomas Gärtner,Sagar Malhotra*

Main category: cs.LG

TL;DR: 提出一种概率性对抗鲁棒性保证方法，通过采样ε-net并调用局部鲁棒性预言机来高效验证分类算法的概率鲁棒性


<details>
  <summary>Details</summary>
Motivation: 传统形式化验证方法计算复杂度过高，而基于采样的方法缺乏形式化保证，需要一种既能提供概率保证又高效的方法

Method: 采样ε-net并调用局部鲁棒性预言机，样本大小与输入维度、类别数和学习算法无关

Result: 方法可应用于大型神经网络，实验证明比现有采样方法更好地表征鲁棒性，比形式化方法更具可扩展性

Conclusion: 该方法为对抗鲁棒性提供了有效的概率性验证框架，解决了传统方法的局限性

Abstract: We propose and investigate probabilistic guarantees for the adversarial
robustness of classification algorithms. While traditional formal verification
approaches for robustness are intractable and sampling-based approaches do not
provide formal guarantees, our approach is able to efficiently certify a
probabilistic relaxation of robustness. The key idea is to sample an
$\epsilon$-net and invoke a local robustness oracle on the sample. Remarkably,
the size of the sample needed to achieve probably approximately global
robustness guarantees is independent of the input dimensionality, the number of
classes, and the learning algorithm itself. Our approach can, therefore, be
applied even to large neural networks that are beyond the scope of traditional
formal verification. Experiments empirically confirm that it characterizes
robustness better than state-of-the-art sampling-based approaches and scales
better than formal methods.

</details>


### [335] [Efficient Approximation of Volterra Series for High-Dimensional Systems](https://arxiv.org/abs/2511.06527)
*Navin Khoshnan,Claudia K Petritsch,Bryce-Allen Bagley*

Main category: cs.LG

TL;DR: 提出了Tensor Head Averaging (THA)算法，通过构建局部MVMALS模型集合来显著降低高维非线性系统辨识的计算复杂度，并提供了理论误差界限和性能分析。


<details>
  <summary>Details</summary>
Motivation: 解决Tensor Network方法（如MVMALS）在高维非线性系统辨识中因多项式计算复杂度而面临的计算和内存瓶颈问题。

Method: THA算法通过训练输入空间小子集上的局部MVMALS模型集合，利用包含和省略动态之间的相关性来优化性能。

Result: 建立了THA集合与完整MVMALS模型之间的有限样本误差界限，证明了THA在精度上优于简单截断的完整模型。

Conclusion: THA为识别先前难以处理的高维系统提供了一种可扩展且理论可靠的方法。

Abstract: The identification of high-dimensional nonlinear dynamical systems via the
Volterra series has significant potential, but has been severely hindered by
the curse of dimensionality. Tensor Network (TN) methods such as the Modified
Alternating Linear Scheme (MVMALS) have been a breakthrough for the field,
offering a tractable approach by exploiting the low-rank structure in Volterra
kernels. However, these techniques still encounter prohibitive computational
and memory bottlenecks due to high-order polynomial scaling with respect to
input dimension. To overcome this barrier, we introduce the Tensor Head
Averaging (THA) algorithm, which significantly reduces complexity by
constructing an ensemble of localized MVMALS models trained on small subsets of
the input space. In this paper, we present a theoretical foundation for the THA
algorithm. We establish observable, finite-sample bounds on the error between
the THA ensemble and a full MVMALS model, and we derive an exact decomposition
of the squared error. This decomposition is used to analyze the manner in which
subset models implicitly compensate for omitted dynamics. We quantify this
effect, and prove that correlation between the included and omitted dynamics
creates an optimization incentive which drives THA's performance toward
accuracy superior to a simple truncation of a full MVMALS model. THA thus
offers a scalable and theoretically grounded approach for identifying
previously intractable high-dimensional systems.

</details>


### [336] [TriShGAN: Enhancing Sparsity and Robustness in Multivariate Time Series Counterfactuals Explanation](https://arxiv.org/abs/2511.06529)
*Hongnan Ma,Yiwei Shi,Guanxiong Sun,Mengyue Yang,Weiru Liu*

Main category: cs.LG

TL;DR: 提出TriShGAN方法，在CounteRGAN框架基础上引入三元组损失，用于生成多变量时间序列的鲁棒反事实解释，同时集成Shapelet提取器提升稀疏性和训练效率。


<details>
  <summary>Details</summary>
Motivation: 传统反事实解释方法在多变量时间序列中存在局限性：基于最近异类邻居的方法直接替换子序列不现实；基于生成对抗网络的方法过于关注最小化成本而忽视与决策边界的距离，导致解释不够鲁棒。

Method: TriShGAN方法在CounteRGAN框架中引入三元组损失进行无监督学习，通过距离度量学习使反事实解释既接近查询时间序列，又捕获期望结果实例的特征分布。同时集成Shapelet提取器选择最具判别性的子序列部分。

Result: 该方法在最小成本和鲁棒性之间实现更好平衡，生成的解释更具稀疏性且训练效率更高。

Conclusion: TriShGAN通过三元组损失和Shapelet提取器的结合，有效解决了多变量时间序列反事实解释的鲁棒性和效率问题。

Abstract: In decision-making processes, stakeholders often rely on counterfactual
explanations, which provide suggestions about what should be changed in the
queried instance to alter the outcome of an AI system. However, generating
these explanations for multivariate time series presents challenges due to
their complex, multi-dimensional nature. Traditional Nearest Unlike
Neighbor-based methods typically substitute subsequences in a queried time
series with influential subsequences from an NUN, which is not always realistic
in real-world scenarios due to the rigid direct substitution. Counterfactual
with Residual Generative Adversarial Networks-based methods aim to address this
by learning from the distribution of observed data to generate synthetic
counterfactual explanations. However, these methods primarily focus on
minimizing the cost from the queried time series to the counterfactual
explanations and often neglect the importance of distancing the counterfactual
explanation from the decision boundary. This oversight can result in
explanations that no longer qualify as counterfactual if minor changes occur
within the model. To generate a more robust counterfactual explanation, we
introduce TriShGAN, under the CounteRGAN framework enhanced by the
incorporation of triplet loss. This unsupervised learning approach uses
distance metric learning to encourage the counterfactual explanations not only
to remain close to the queried time series but also to capture the feature
distribution of the instance with the desired outcome, thereby achieving a
better balance between minimal cost and robustness. Additionally, we integrate
a Shapelet Extractor that strategically selects the most discriminative parts
of the high-dimensional queried time series to enhance the sparsity of
counterfactual explanation and efficiency of the training process.

</details>


### [337] [Bayesian Uncertainty Quantification with Anchored Ensembles for Robust EV Power Consumption Prediction](https://arxiv.org/abs/2511.06538)
*Ghazal Farhani,Taufiq Rahman,Kieran Humphries*

Main category: cs.LG

TL;DR: 提出了一种基于锚定集成LSTM和Student-t似然的电动汽车功率估计方法，能同时捕捉认知不确定性和偶然不确定性，在保持高精度的同时提供可靠的不确定性量化。


<details>
  <summary>Details</summary>
Motivation: 电动汽车功率估计需要同时保证点估计精度和可信的不确定性量化，以支持可靠的续航预测和能源管理决策。

Method: 使用锚定集成LSTM网络，结合Student-t似然函数，通过高斯权重先验（MAP训练）实现后验多样性，无需测试时采样。

Result: 在车辆运动学时间序列数据上，模型达到RMSE 3.36±1.10，MAE 2.21±0.89，R²=0.93±0.02，且提供良好校准的不确定性区间和接近标称的覆盖范围。

Conclusion: 该方法在匹配或改进对数分数的同时，生成更尖锐的区间，且推理只需单次确定性前向传播，适合实时部署，为电动汽车能源管理提供可靠估计。

Abstract: Accurate EV power estimation underpins range prediction and energy
management, yet practitioners need both point accuracy and trustworthy
uncertainty. We propose an anchored-ensemble Long Short-Term Memory (LSTM) with
a Student-t likelihood that jointly captures epistemic (model) and aleatoric
(data) uncertainty. Anchoring imposes a Gaussian weight prior (MAP training),
yielding posterior-like diversity without test-time sampling, while the t-head
provides heavy-tailed robustness and closed-form prediction intervals. Using
vehicle-kinematic time series (e.g., speed, motor RPM), our model attains
strong accuracy: RMSE 3.36 +/- 1.10, MAE 2.21 +/- 0.89, R-squared = 0.93 +/-
0.02, explained variance 0.93 +/- 0.02, and delivers well-calibrated
uncertainty bands with near-nominal coverage. Against competitive baselines
(Student-t MC dropout; quantile regression with/without anchoring), our method
matches or improves log-scores while producing sharper intervals at the same
coverage. Crucially for real-time deployment, inference is a single
deterministic pass per ensemble member (or a weight-averaged collapse),
eliminating Monte Carlo latency. The result is a compact, theoretically
grounded estimator that couples accuracy, calibration, and systems efficiency,
enabling reliable range estimation and decision-making for production EV energy
management.

</details>


### [338] [Practical Policy Distillation for Reinforcement Learning in Radio Access Networks](https://arxiv.org/abs/2511.06563)
*Sara Khosravi,Burak Demirel,Linghui Zhou,Javier Rasines,Pablo Soldati*

Main category: cs.LG

TL;DR: 本文研究了在RAN硬件计算和内存限制下，通过策略蒸馏技术实现轻量级AI模型部署的方法，解决了5G网络中强化学习模型的实际应用难题。


<details>
  <summary>Details</summary>
Motivation: RAN网络部署AI面临多重挑战：链路测量数据有限、实时处理要求高（亚毫秒级）、网络异构性强，而传统4G硬件缺乏神经网络加速器，只能部署轻量模型（<1Mb，推理时间<100μs），但强泛化能力需要大规模模型，存在性能与资源限制的矛盾。

Method: 采用策略蒸馏技术，研究两种策略：1）单策略蒸馏 - 将场景无关的教师模型压缩为通用学生模型；2）多策略蒸馏 - 将多个场景特定的教师模型整合为单一通用学生模型。在5G兼容的高保真模拟器中进行实验评估。

Result: 实验证明两种策略都能生成紧凑的学生模型，在保持教师模型泛化能力的同时，满足现有RAN硬件的计算和内存限制要求。

Conclusion: 策略蒸馏技术有效解决了RAN网络中AI模型部署的资源限制问题，为在计算受限的通信硬件上实现高性能AI应用提供了可行方案。

Abstract: Adopting artificial intelligence (AI) in radio access networks (RANs)
presents several challenges, including limited availability of link-level
measurements (e.g., CQI reports), stringent real-time processing constraints
(e.g., sub-1 ms per TTI), and network heterogeneity (different spectrum bands,
cell types, and vendor equipment). A critical yet often overlooked barrier lies
in the computational and memory limitations of RAN baseband hardware,
particularly in legacy 4th Generation (4G) systems, which typically lack
on-chip neural accelerators. As a result, only lightweight AI models (under 1
Mb and sub-100~\mu s inference time) can be effectively deployed, limiting both
their performance and applicability. However, achieving strong generalization
across diverse network conditions often requires large-scale models with
substantial resource demands. To address this trade-off, this paper
investigates policy distillation in the context of a reinforcement
learning-based link adaptation task. We explore two strategies: single-policy
distillation, where a scenario-agnostic teacher model is compressed into one
generalized student model; and multi-policy distillation, where multiple
scenario-specific teachers are consolidated into a single generalist student.
Experimental evaluations in a high-fidelity, 5th Generation (5G)-compliant
simulator demonstrate that both strategies produce compact student models that
preserve the teachers' generalization capabilities while complying with the
computational and memory limitations of existing RAN hardware.

</details>


### [339] [Breaking the Dyadic Barrier: Rethinking Fairness in Link Prediction Beyond Demographic Parity](https://arxiv.org/abs/2511.06568)
*João Mattos,Debolina Halder Lina,Arlei Silva*

Main category: cs.LG

TL;DR: 本文分析了图机器学习中链接预测任务的公平性问题，指出现有基于成对公平性的方法存在局限性，提出了新的评估框架和轻量级后处理方法来解决偏见问题。


<details>
  <summary>Details</summary>
Motivation: 链接预测在社交推荐和知识图谱补全等应用中具有重要作用，但存在偏见问题会加剧社会不平等。现有工作采用成对公平性定义，但这种方法可能掩盖子群体间的潜在差异。

Method: 提出一个更具表达力的评估框架，并设计了一种轻量级后处理方法，结合解耦的链接预测器来有效缓解偏见。

Result: 该方法在公平性与效用之间达到了最先进的权衡效果。

Conclusion: 研究表明现有基于人口统计均等的公平性评估在链接预测等排序任务中存在不足，提出的新框架和方法能更好地检测和缓解系统性偏见。

Abstract: Link prediction is a fundamental task in graph machine learning with
applications, ranging from social recommendation to knowledge graph completion.
Fairness in this setting is critical, as biased predictions can exacerbate
societal inequalities. Prior work adopts a dyadic definition of fairness,
enforcing fairness through demographic parity between intra-group and
inter-group link predictions. However, we show that this dyadic framing can
obscure underlying disparities across subgroups, allowing systemic biases to go
undetected. Moreover, we argue that demographic parity does not meet desired
properties for fairness assessment in ranking-based tasks such as link
prediction. We formalize the limitations of existing fairness evaluations and
propose a framework that enables a more expressive assessment. Additionally, we
propose a lightweight post-processing method combined with decoupled link
predictors that effectively mitigates bias and achieves state-of-the-art
fairness-utility trade-offs.

</details>


### [340] [Optimistic Online-to-Batch Conversions for Accelerated Convergence and Universality](https://arxiv.org/abs/2511.06597)
*Yu-Hu Yan,Peng Zhao,Zhi-Hua Zhou*

Main category: cs.LG

TL;DR: 本文提出了新颖的乐观在线到批量转换方法，将乐观主义理论融入分析，显著简化在线算法设计并保持最优收敛速率。


<details>
  <summary>Details</summary>
Motivation: 从在线学习和在线到批量转换的角度理解Nesterov加速梯度方法，研究乐观在线算法在加速中的作用。

Method: 提出乐观在线到批量转换方法，结合简单在线梯度下降，适用于平滑和非平滑目标，无需平滑系数知识。

Result: 实现了平滑目标的优化加速收敛，强凸和平滑目标的最优加速收敛率，以及平滑度的普适性。

Conclusion: 乐观在线到批量转换方法有效简化了算法设计，与Nesterov加速梯度方法存在精确对应关系。

Abstract: In this work, we study offline convex optimization with smooth objectives,
where the classical Nesterov's Accelerated Gradient (NAG) method achieves the
optimal accelerated convergence. Extensive research has aimed to understand NAG
from various perspectives, and a recent line of work approaches this from the
viewpoint of online learning and online-to-batch conversion, emphasizing the
role of optimistic online algorithms for acceleration. In this work, we
contribute to this perspective by proposing novel optimistic online-to-batch
conversions that incorporate optimism theoretically into the analysis, thereby
significantly simplifying the online algorithm design while preserving the
optimal convergence rates. Specifically, we demonstrate the effectiveness of
our conversions through the following results: (i) when combined with simple
online gradient descent, our optimistic conversion achieves the optimal
accelerated convergence; (ii) our conversion also applies to strongly convex
objectives, and by leveraging both optimistic online-to-batch conversion and
optimistic online algorithms, we achieve the optimal accelerated convergence
rate for strongly convex and smooth objectives, for the first time through the
lens of online-to-batch conversion; (iii) our optimistic conversion can achieve
universality to smoothness -- applicable to both smooth and non-smooth
objectives without requiring knowledge of the smoothness coefficient -- and
remains efficient as non-universal methods by using only one gradient query in
each iteration. Finally, we highlight the effectiveness of our optimistic
online-to-batch conversions by a precise correspondence with NAG.

</details>


### [341] [Adaptive Initial Residual Connections for GNNs with Theoretical Guarantees](https://arxiv.org/abs/2511.06598)
*Mohammad Shirzadi,Ali Safarpoor Dehkordi,Ahad N. Zehmakan*

Main category: cs.LG

TL;DR: 该论文提出了一种自适应残差方案，通过为不同节点设置不同的残差强度来防止图神经网络中的过度平滑问题，并提供了理论保证和实验验证。


<details>
  <summary>Details</summary>
Motivation: 图神经网络中的消息传递操作在深层架构中会导致表达力下降和过度平滑问题。现有的残差连接方法虽然能缓解这一问题，但缺乏对不同节点特性的适应性。

Method: 提出自适应残差方案，让不同节点具有不同的残差强度；证明该方法能防止过度平滑，确保嵌入的Dirichlet能量有界远离零；还提出了一个启发式变体来降低时间复杂度。

Result: 理论证明该方法有效防止过度平滑；实验表明自适应方法在异配图等场景下优于标准和最先进的消息传递机制；启发式变体与可学习版本性能相当但更高效。

Conclusion: 自适应残差方案为图神经网络提供了有效的过度平滑预防机制，特别是在异配图上表现优异，同时提供了理论保证和实用变体。

Abstract: Message passing is the core operation in graph neural networks, where each
node updates its embeddings by aggregating information from its neighbors.
However, in deep architectures, this process often leads to diminished
expressiveness. A popular solution is to use residual connections, where the
input from the current (or initial) layer is added to aggregated neighbor
information to preserve embeddings across layers. Following a recent line of
research, we investigate an adaptive residual scheme in which different nodes
have varying residual strengths. We prove that this approach prevents
oversmoothing; particularly, we show that the Dirichlet energy of the
embeddings remains bounded away from zero. This is the first theoretical
guarantee not only for the adaptive setting, but also for static residual
connections (where residual strengths are shared across nodes) with activation
functions. Furthermore, extensive experiments show that this adaptive approach
outperforms standard and state-of-the-art message passing mechanisms,
especially on heterophilic graphs. To improve the time complexity of our
approach, we introduce a variant in which residual strengths are not learned
but instead set heuristically, a choice that performs as well as the learnable
version.

</details>


### [342] [Explainable Probabilistic Machine Learning for Predicting Drilling Fluid Loss of Circulation in Marun Oil Field](https://arxiv.org/abs/2511.06607)
*Seshu Kumar Damarla,Xiuli Zhu*

Main category: cs.LG

TL;DR: 提出了基于高斯过程回归的概率机器学习框架，用于预测复杂地层中的钻井液漏失，通过量化预测不确定性提高决策可靠性。


<details>
  <summary>Details</summary>
Motivation: 钻井作业中的漏失问题导致井筒不稳定、卡管和非生产时间延长，准确预测流体损失对提高钻井安全性和效率至关重要。

Method: 使用高斯过程回归模型捕获钻井参数间的非线性依赖关系，采用LBFGS算法优化超参数，并利用LIME方法提高模型可解释性。

Result: 结果表明该概率学习框架能够主动识别漏失风险，优化堵漏材料设计，并降低钻井作业中的操作不确定性。

Conclusion: 可解释的概率学习在钻井应用中具有重要潜力，能够有效预测和预防漏失问题。

Abstract: Lost circulation remains a major and costly challenge in drilling operations,
often resulting in wellbore instability, stuck pipe, and extended
non-productive time. Accurate prediction of fluid loss is therefore essential
for improving drilling safety and efficiency. This study presents a
probabilistic machine learning framework based on Gaussian Process Regression
(GPR) for predicting drilling fluid loss in complex formations. The GPR model
captures nonlinear dependencies among drilling parameters while quantifying
predictive uncertainty, offering enhanced reliability for high-risk
decision-making. Model hyperparameters are optimized using the Limited memory
Broyden Fletcher Goldfarb Shanno (LBFGS) algorithm to ensure numerical
stability and robust generalization. To improve interpretability, Local
Interpretable Model agnostic Explanations (LIME) are employed to elucidate how
individual features influence model predictions. The results highlight the
potential of explainable probabilistic learning for proactive identification of
lost-circulation risks, optimized design of lost circulation materials (LCM),
and reduction of operational uncertainties in drilling applications.

</details>


### [343] [Beyond Fixed Depth: Adaptive Graph Neural Networks for Node Classification Under Varying Homophily](https://arxiv.org/abs/2511.06608)
*Asela Hevapathige,Asiri Wijesinghe,Ahad N. Zehmakan*

Main category: cs.LG

TL;DR: 提出了一种自适应深度的图神经网络架构，能够根据节点的局部同质性水平动态选择最优聚合深度，解决传统GNN在异质图上的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 传统GNN在异质图上效果不佳，现有方法存在固定聚合深度和无法同时适应同质/异质场景的局限性。

Method: 开发理论框架分析节点局部结构与信息传播的关系，提出基于理论指标的自适应深度GNN架构，动态选择节点特定的聚合深度。

Result: 在多个基准测试中，该方法显著提升了标准GNN骨干网络的性能。

Conclusion: 自适应深度聚合策略能够有效提升GNN在异质图上的表现，并为同质和异质场景提供统一的解决方案。

Abstract: Graph Neural Networks (GNNs) have achieved significant success in addressing
node classification tasks. However, the effectiveness of traditional GNNs
degrades on heterophilic graphs, where connected nodes often belong to
different labels or properties. While recent work has introduced mechanisms to
improve GNN performance under heterophily, certain key limitations still exist.
Most existing models apply a fixed aggregation depth across all nodes,
overlooking the fact that nodes may require different propagation depths based
on their local homophily levels and neighborhood structures. Moreover, many
methods are tailored to either homophilic or heterophilic settings, lacking the
flexibility to generalize across both regimes. To address these challenges, we
develop a theoretical framework that links local structural and label
characteristics to information propagation dynamics at the node level. Our
analysis shows that optimal aggregation depth varies across nodes and is
critical for preserving class-discriminative information. Guided by this
insight, we propose a novel adaptive-depth GNN architecture that dynamically
selects node-specific aggregation depths using theoretically grounded metrics.
Our method seamlessly adapts to both homophilic and heterophilic patterns
within a unified model. Extensive experiments demonstrate that our approach
consistently enhances the performance of standard GNN backbones across diverse
benchmarks.

</details>


### [344] [A Weak Penalty Neural ODE for Learning Chaotic Dynamics from Noisy Time Series](https://arxiv.org/abs/2511.06609)
*Xuyang Li,John Harlim,Romit Maulik*

Main category: cs.LG

TL;DR: 本文提出了一种弱惩罚神经ODE（WP-NODE）方法，通过结合弱形式和强形式来提升混沌动力系统在噪声数据下的预测精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的测量数据通常包含噪声，这会严重降低数据驱动模型的性能。特别是在混沌动力系统中，小误差会迅速放大，难以从噪声数据中识别出既能保持短期精度又能保持长期不变性的数据驱动模型。

Method: 提出了弱惩罚神经ODE（WP-NODE）方法，将弱形式作为惩罚项与传统的强形式学习相结合。弱形式通过时间子域上的积分残差来约束模型，而强形式则基于NODE的离散化进行优化。

Result: 数值实验表明，WP-NODE在基准混沌动力系统上实现了最先进的预测精度和卓越的鲁棒性。

Conclusion: 弱形式作为强形式的补充方法，能够有效提升神经ODE在噪声数据下的性能，特别是在混沌动力系统的建模中表现出色。

Abstract: Accurate forecasting of complex high-dimensional dynamical systems from
observational data is essential for several applications across science and
engineering. A key challenge, however, is that real-world measurements are
often corrupted by noise, which severely degrades the performance of
data-driven models. Particularly, in chaotic dynamical systems, where small
errors amplify rapidly, it is challenging to identify a data-driven model from
noisy data that achieves short-term accuracy while preserving long-term
invariant properties. In this paper, we propose the use of the weak formulation
as a complementary approach to the classical strong formulation of data-driven
time-series forecasting models. Specifically, we focus on the neural ordinary
differential equation (NODE) architecture. Unlike the standard strong
formulation, which relies on the discretization of the NODE followed by
optimization, the weak formulation constrains the model using a set of
integrated residuals over temporal subdomains. While such a formulation yields
an effective NODE model, we discover that the performance of a NODE can be
further enhanced by employing this weak formulation as a penalty alongside the
classical strong formulation-based learning. Through numerical demonstrations,
we illustrate that our proposed training strategy, which we coined as the
Weak-Penalty NODE (WP-NODE), achieves state-of-the-art forecasting accuracy and
exceptional robustness across benchmark chaotic dynamical systems.

</details>


### [345] [Non-Rival Data as Rival Products: An Encapsulation-Forging Approach for Data Synthesis](https://arxiv.org/abs/2511.06610)
*Kaidong Wang,Jiale Li,Shao-Bo Lin,Yao Wang*

Main category: cs.LG

TL;DR: EnFo框架通过生成具有不对称效用的竞争性合成数据，解决数据共享中的价值流失问题。


<details>
  <summary>Details</summary>
Motivation: 数据具有非竞争性，企业共享数据可以释放价值但会削弱竞争优势。现有合成数据方法往往产生对称效用的数据，任何方都能提取价值。

Method: EnFo框架分两阶段：首先将原始数据的预测知识封装到指定的'关键'模型中，然后通过优化数据故意过拟合该关键模型来伪造合成数据集。

Result: EnFo表现出显著的样本效率，仅用原始数据的一小部分就能达到同等性能，同时提供强大的隐私保护和抗滥用能力。

Conclusion: EnFo为企业提供了一种实用的解决方案，可以在不损害核心分析优势的情况下进行战略合作。

Abstract: The non-rival nature of data creates a dilemma for firms: sharing data
unlocks value but risks eroding competitive advantage. Existing data synthesis
methods often exacerbate this problem by creating data with symmetric utility,
allowing any party to extract its value. This paper introduces the
Encapsulation-Forging (EnFo) framework, a novel approach to generate rival
synthetic data with asymmetric utility. EnFo operates in two stages: it first
encapsulates predictive knowledge from the original data into a designated
``key'' model, and then forges a synthetic dataset by optimizing the data to
intentionally overfit this key model. This process transforms non-rival data
into a rival product, ensuring its value is accessible only to the intended
model, thereby preventing unauthorized use and preserving the data owner's
competitive edge. Our framework demonstrates remarkable sample efficiency,
matching the original data's performance with a fraction of its size, while
providing robust privacy protection and resistance to misuse. EnFo offers a
practical solution for firms to collaborate strategically without compromising
their core analytical advantage.

</details>


### [346] [Dual-branch Spatial-Temporal Self-supervised Representation for Enhanced Road Network Learning](https://arxiv.org/abs/2511.06633)
*Qinghong Guo,Yu Wang,Ji Cao,Tongya Zheng,Junshu Dai,Bingde Hu,Shunyu Liu,Canghong Jin*

Main category: cs.LG

TL;DR: 提出了一个双分支时空自监督表示框架DST，用于增强道路网络表示学习，通过结合动态关系和长程空间关系，以及时间动态建模，解决了现有方法在处理空间异质性和时间动态方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 道路网络的空间异质性和时间动态给自监督图神经网络的邻域平滑机制带来了严重挑战，需要开发能够同时处理空间和时间特征的增强表示方法。

Method: DST框架包含两个分支：空间分支使用混合跳转转移矩阵进行图卷积，并构建超图通过三种超边捕获长程关系；时间分支基于因果Transformer进行下一令牌预测，并通过区分工作日和周末的交通模式进行正则化。

Result: 大量实验验证了DST框架相对于最先进方法的优越性，特别是在零样本学习场景中表现出色。

Conclusion: DST通过综合的时空建模有效解决了道路网络表示学习中的关键挑战，为各种时空任务提供了强大的基础表示。

Abstract: Road network representation learning (RNRL) has attracted increasing
attention from both researchers and practitioners as various spatiotemporal
tasks are emerging. Recent advanced methods leverage Graph Neural Networks
(GNNs) and contrastive learning to characterize the spatial structure of road
segments in a self-supervised paradigm. However, spatial heterogeneity and
temporal dynamics of road networks raise severe challenges to the neighborhood
smoothing mechanism of self-supervised GNNs. To address these issues, we
propose a $\textbf{D}$ual-branch $\textbf{S}$patial-$\textbf{T}$emporal
self-supervised representation framework for enhanced road representations,
termed as DST. On one hand, DST designs a mix-hop transition matrix for graph
convolution to incorporate dynamic relations of roads from trajectories.
Besides, DST contrasts road representations of the vanilla road network against
that of the hypergraph in a spatial self-supervised way. The hypergraph is
newly built based on three types of hyperedges to capture long-range relations.
On the other hand, DST performs next token prediction as the temporal
self-supervised task on the sequences of traffic dynamics based on a causal
Transformer, which is further regularized by differentiating traffic modes of
weekdays from those of weekends. Extensive experiments against state-of-the-art
methods verify the superiority of our proposed framework. Moreover, the
comprehensive spatiotemporal modeling facilitates DST to excel in zero-shot
learning scenarios.

</details>


### [347] [CaberNet: Causal Representation Learning for Cross-Domain HVAC Energy Prediction](https://arxiv.org/abs/2511.06634)
*Kaiyuan Zhai,Jiacheng Cui,Zhehao Zhang,Junyu Xue,Yang Deng,Kui Wu,Guoming Tang*

Main category: cs.LG

TL;DR: CaberNet是一个基于因果关系的可解释深度序列模型，用于跨域HVAC能耗预测，通过识别不变特征和域平衡训练实现鲁棒预测


<details>
  <summary>Details</summary>
Motivation: 解决跨建筑HVAC能耗预测中数据稀缺、异构性以及现有方法容易过拟合、依赖专家干预或牺牲数据多样性的问题

Method: 提出CaberNet模型，包含全局特征门控（使用自监督伯努利正则化）和域平衡训练方案，无需先验知识即可学习不变表示

Result: 在三个不同气候城市的真实数据集上测试，CaberNet相比最佳基准模型将归一化均方误差降低了22.9%

Conclusion: CaberNet在跨域HVAC能耗预测任务中表现出色，证明了因果不变表示学习方法的有效性

Abstract: Cross-domain HVAC energy prediction is essential for scalable building energy
management, particularly because collecting extensive labeled data for every
new building is both costly and impractical. Yet, this task remains highly
challenging due to the scarcity and heterogeneity of data across different
buildings, climate zones, and seasonal patterns. In particular, buildings
situated in distinct climatic regions introduce variability that often leads
existing methods to overfit to spurious correlations, rely heavily on expert
intervention, or compromise on data diversity. To address these limitations, we
propose CaberNet, a causal and interpretable deep sequence model that learns
invariant (Markov blanket) representations for robust cross-domain prediction.
In a purely data-driven fashion and without requiring any prior knowledge,
CaberNet integrates i) a global feature gate trained with a self-supervised
Bernoulli regularization to distinguish superior causal features from inferior
ones, and ii) a domain-wise training scheme that balances domain contributions,
minimizes cross-domain loss variance, and promotes latent factor independence.
We evaluate CaberNet on real-world datasets collected from three buildings
located in three climatically diverse cities, and it consistently outperforms
all baselines, achieving a 22.9\% reduction in normalized mean squared error
(NMSE) compared to the best benchmark. Our code is available at
https://github.com/rickzky1001/CaberNet-CRL.

</details>


### [348] [Neyman-Pearson Classification under Both Null and Alternative Distributions Shift](https://arxiv.org/abs/2511.06641)
*Mohammadreza M. Kalan,Yuyang Deng,Eitan J. Neugut,Samory Kpotufe*

Main category: cs.LG

TL;DR: 本文提出了一种针对Neyman-Pearson分类中迁移学习的自适应方法，能够同时控制两类错误，避免负迁移，并具有统计和计算保证。


<details>
  <summary>Details</summary>
Motivation: 传统迁移学习主要关注平衡分类问题，而在Neyman-Pearson分类这种不平衡分类场景中，迁移学习研究较少。现有方法仅处理μ1分布的偏移，但实际应用中μ0和μ1可能同时发生偏移，需要同时控制两类错误。

Method: 开发了一种自适应迁移学习程序，当源域信息丰富时能改善Type-I和Type-II错误，当源域信息不足时能自动适应，避免负迁移。

Result: 该方法不仅提供了统计保证（改进两类错误），还具备计算效率保证。

Conclusion: 该自适应迁移学习方法有效解决了Neyman-Pearson分类中双分布偏移的挑战，实现了统计性能和计算效率的平衡。

Abstract: We consider the problem of transfer learning in Neyman-Pearson
classification, where the objective is to minimize the error w.r.t. a
distribution $\mu_1$, subject to the constraint that the error w.r.t. a
distribution $\mu_0$ remains below a prescribed threshold. While transfer
learning has been extensively studied in traditional classification, transfer
learning in imbalanced classification such as Neyman-Pearson classification has
received much less attention. This setting poses unique challenges, as both
types of errors must be simultaneously controlled. Existing works address only
the case of distribution shift in $\mu_1$, whereas in many practical scenarios
shifts may occur in both $\mu_0$ and $\mu_1$. We derive an adaptive procedure
that not only guarantees improved Type-I and Type-II errors when the source is
informative, but also automatically adapt to situations where the source is
uninformative, thereby avoiding negative transfer. In addition to such
statistical guarantees, the procedures is efficient, as shown via complementary
computational guarantees.

</details>


### [349] [Improving Asset Allocation in a Fast Moving Consumer Goods B2B Company: An Interpretable Machine Learning Framework for Commercial Cooler Assignment Based on Multi-Tier Growth Targets](https://arxiv.org/abs/2511.06642)
*Renato Castro,Rodrigo Paredes,Douglas Kahn*

Main category: cs.LG

TL;DR: 本文提出了一个机器学习框架，用于预测B2B饮料客户在获得冷柜后最可能实现销量增长的客户，从而提高资产分配的投资回报率。


<details>
  <summary>Details</summary>
Motivation: 在快速消费品行业，物理资产（如商业饮料冷柜）的放置位置直接影响收入增长和执行效率。虽然客户流失预测和需求预测在B2B环境中已被广泛研究，但使用机器学习指导资产分配的研究相对较少。

Method: 使用来自中美洲知名酿酒饮料公司的3,119个B2B传统贸易渠道客户的私有数据集，跟踪冷柜安装前后12个月的销售交易数据。定义了10%、30%和50%三个销量增长阈值，比较了XGBoost、LightGBM和CatBoost等机器学习模型，并结合SHAP进行可解释的特征分析。

Result: 最佳模型在验证集上的AUC得分分别为0.857、0.877和0.898。模拟表明，与传统基于销量的方法相比，该方法能更好地选择具有增长潜力的客户，提高投资回报率，并通过避免分配给不会增长的客户来增加成本节约。

Conclusion: 该机器学习框架能够有效指导冷柜分配决策，提供显著的商业管理改进建议，在资产分配优化方面具有重要应用价值。

Abstract: In the fast-moving consumer goods (FMCG) industry, deciding where to place
physical assets, such as commercial beverage coolers, can directly impact
revenue growth and execution efficiency. Although churn prediction and demand
forecasting have been widely studied in B2B contexts, the use of machine
learning to guide asset allocation remains relatively unexplored. This paper
presents a framework focused on predicting which beverage clients are most
likely to deliver strong returns in volume after receiving a cooler. Using a
private dataset from a well-known Central American brewing and beverage company
of 3,119 B2B traditional trade channel clients that received a cooler from
2022-01 to 2024-07, and tracking 12 months of sales transactions before and
after cooler installation, three growth thresholds were defined: 10%, 30% and
50% growth in sales volume year over year. The analysis compares results of
machine learning models such as XGBoost, LightGBM, and CatBoost combined with
SHAP for interpretable feature analysis in order to have insights into
improving business operations related to cooler allocation; the results show
that the best model has AUC scores of 0.857, 0.877, and 0.898 across the
thresholds on the validation set. Simulations suggest that this approach can
improve ROI because it better selects potential clients to grow at the expected
level and increases cost savings by not assigning clients that will not grow,
compared to traditional volume-based approaches with substantial business
management recommendations

</details>


### [350] [Dual-Pathway Fusion of EHRs and Knowledge Graphs for Predicting Unseen Drug-Drug Interactions](https://arxiv.org/abs/2511.06662)
*Franklin Lee,Tengfei Ma*

Main category: cs.LG

TL;DR: 本文提出了首个将知识图谱关系评分与患者级电子健康记录上下文相结合的系统，并通过蒸馏技术实现仅使用EHR的零样本推理，用于药物相互作用检测。


<details>
  <summary>Details</summary>
Motivation: 现有药物相互作用检测模型要么依赖知识图谱（无法处理未见药物），要么依赖电子健康记录（噪声大、时间依赖性强、站点依赖性高），需要一种能够结合两者优势并实现零样本推理的方法。

Method: 采用教师-学生蒸馏框架：融合教师模型学习知识图谱和EHR中的机制特定关系，蒸馏学生模型仅使用EHR进行零样本推理。系统在共享药理学机制本体下运行，产生可解释的警报而非不透明的风险评分。

Result: 在多机构EHR语料库和DrugBank DDI图谱上训练，系统在保持整体检测性能（F1）的同时提高了精度，减少了假警报，漏检更少的真实相互作用。案例研究显示能够零样本识别KG中未包含药物的临床认可机制。

Conclusion: 该系统支持临床决策支持和药物警戒的实际应用，能够产生机制特异性、临床一致的预测，并在多机构测试数据上保持精度。

Abstract: Drug-drug interactions (DDIs) remain a major source of preventable harm, and
many clinically important mechanisms are still unknown. Existing models either
rely on pharmacologic knowledge graphs (KGs), which fail on unseen drugs, or on
electronic health records (EHRs), which are noisy, temporal, and
site-dependent. We introduce, to our knowledge, the first system that
conditions KG relation scoring on patient-level EHR context and distills that
reasoning into an EHR-only model for zero-shot inference. A fusion "Teacher"
learns mechanism-specific relations for drug pairs represented in both sources,
while a distilled "Student" generalizes to new or rarely used drugs without KG
access at inference. Both operate under a shared ontology (set) of
pharmacologic mechanisms (drug relations) to produce interpretable, auditable
alerts rather than opaque risk scores. Trained on a multi-institution EHR
corpus paired with a curated DrugBank DDI graph, and evaluated using a
clinically aligned, decision-focused protocol with leakage-safe negatives that
avoid artificially easy pairs, the system maintains precision across
multi-institutuion test data, produces mechanism-specific, clinically
consistent predictions, reduces false alerts (higher precision) at comparable
overall detection performance (F1), and misses fewer true interactions compared
to prior methods. Case studies further show zero-shot identification of
clinically recognized CYP-mediated and pharmacodynamic mechanisms for drugs
absent from the KG, supporting real-world use in clinical decision support and
pharmacovigilance.

</details>


### [351] [An Adaptive Machine Learning Triage Framework for Predicting Alzheimer's Disease Progression](https://arxiv.org/abs/2511.06681)
*Richard Hou,Shengpu Tang,Wei Jin*

Main category: cs.LG

TL;DR: 该研究开发了一个两阶段机器学习框架，用于预测轻度认知障碍（MCI）向阿尔茨海默病（AD）的转化，通过选择性获取高成本特征来平衡准确性和成本。


<details>
  <summary>Details</summary>
Motivation: 解决AD预测中的成本-准确性困境，常规认知测试和临床数据预测能力不足，而PET扫描和CSF生物标志物分析成本过高，无法对所有患者实施。

Method: 设计了一个两阶段机器学习框架，基于预测的"信息价值"选择性获取高级、昂贵的特征。使用ADNI数据进行MCI患者AD进展预测。

Result: 该框架将高级测试需求减少20%，测试AUROC达到0.929，与使用所有特征的模型性能相当（AUROC=0.915，p=0.1010）。

Conclusion: 该研究提供了一个可解释的数据驱动框架，优化了AD诊断路径，平衡了准确性和成本，使早期可靠的AD预测在真实世界实践中更加可行。

Abstract: Accurate predictions of conversion from mild cognitive impairment (MCI) to
Alzheimer's disease (AD) can enable effective personalized therapy. While
cognitive tests and clinical data are routinely collected, they lack the
predictive power of PET scans and CSF biomarker analysis, which are
prohibitively expensive to obtain for every patient. To address this
cost-accuracy dilemma, we design a two-stage machine learning framework that
selectively obtains advanced, costly features based on their predicted "value
of information". We apply our framework to predict AD progression for MCI
patients using data from the Alzheimer's Disease Neuroimaging Initiative
(ADNI). Our framework reduces the need for advanced testing by 20% while
achieving a test AUROC of 0.929, comparable to the model that uses both basic
and advanced features (AUROC=0.915, p=0.1010). We also provide an example
interpretability analysis showing how one may explain the triage decision. Our
work presents an interpretable, data-driven framework that optimizes AD
diagnostic pathways and balances accuracy with cost, representing a step
towards making early, reliable AD prediction more accessible in real-world
practice. Future work should consider multiple categories of advanced features
and larger-scale validation.

</details>


### [352] [Mitigating Modality Imbalance in Multi-modal Learning via Multi-objective Optimization](https://arxiv.org/abs/2511.06686)
*Heshan Fernando,Parikshit Ram,Yi Zhou,Soham Dan,Horst Samulowitz,Nathalie Baracaldo,Tianyi Chen*

Main category: cs.LG

TL;DR: 该论文将多模态学习重新表述为多目标优化问题，提出梯度算法解决模态间学习不平衡问题，在保持性能的同时大幅减少计算时间。


<details>
  <summary>Details</summary>
Motivation: 传统多模态学习方法存在模态间学习不平衡问题，导致性能甚至不如单模态方法，且现有平衡方法计算成本高。

Method: 将多模态学习问题重新表述为多目标优化问题，提出基于梯度的算法来解决模态间的不平衡学习问题。

Result: 在主流多模态学习基准测试中表现优于现有平衡方法和多目标优化基线，子程序计算时间减少约20倍。

Conclusion: 该方法有效解决了多模态学习中的不平衡问题，提供了收敛保证，并在性能和计算效率方面均有显著提升。

Abstract: Multi-modal learning (MML) aims to integrate information from multiple
modalities, which is expected to lead to superior performance over
single-modality learning. However, recent studies have shown that MML can
underperform, even compared to single-modality approaches, due to imbalanced
learning across modalities. Methods have been proposed to alleviate this
imbalance issue using different heuristics, which often lead to computationally
intensive subroutines. In this paper, we reformulate the MML problem as a
multi-objective optimization (MOO) problem that overcomes the imbalanced
learning issue among modalities and propose a gradient-based algorithm to solve
the modified MML problem. We provide convergence guarantees for the proposed
method, and empirical evaluations on popular MML benchmarks showcasing the
improved performance of the proposed method over existing balanced MML and MOO
baselines, with up to ~20x reduction in subroutine computation time. Our code
is available at https://github.com/heshandevaka/MIMO.

</details>


### [353] [Peeling Context from Cause for Multimodal Molecular Property Prediction](https://arxiv.org/abs/2511.06692)
*Tao Li,Kaiyuan Hou,Tuan Vinh,Carl Yang,Monika Raj*

Main category: cs.LG

TL;DR: CLaP框架通过分层分离因果信号与上下文，提升分子性质预测的准确性和可解释性


<details>
  <summary>Details</summary>
Motivation: 解决深度模型在分子性质预测中依赖虚假上下文而非因果结构的问题，提高分布偏移下的可靠性

Method: CLaP框架在每个层级进行软分割，将输入分为因果分支和非因果分支，融合多模态因果证据，逐步去除批次耦合的上下文，聚焦标签相关结构

Result: 在四个分子基准测试中，CLaP在MAE、MSE和R²指标上均优于竞争基线，并生成原子级因果显著性图谱

Conclusion: 通过分层剥离上下文与因果信号，CLaP实现了既准确又可解释的分子性质预测模型

Abstract: Deep models are used for molecular property prediction, yet they are often
difficult to interpret and may rely on spurious context rather than causal
structure, which reduces reliability under distribution shift and harms
predictive performance. We introduce CLaP (Causal Layerwise Peeling), a
framework that separates causal signal from context in a layerwise manner and
integrates diverse graph representations of molecules. At each layer, a causal
block performs a soft split into causal and non-causal branches, fuses causal
evidence across modalities, and progressively removes batch-coupled context to
focus on label-relevant structure, thereby limiting shortcut signals and
stabilizing layerwise refinement. Across four molecular benchmarks, CLaP
consistently improves MAE, MSE, and $R^2$ over competitive baselines. The model
also produces atom-level causal saliency maps that highlight substructures
responsible for predictions, providing actionable guidance for targeted
molecular edits. Case studies confirm the accuracy of these maps and their
alignment with chemical intuition. By peeling context from cause at every
layer, the model yields predictors that are both accurate and interpretable for
molecular design.

</details>


### [354] [ML-EcoLyzer: Quantifying the Environmental Cost of Machine Learning Inference Across Frameworks and Hardware](https://arxiv.org/abs/2511.06694)
*Jose Marie Antonio Minoza,Rex Gregor Laylo,Christian F Villarin,Sebastian C. Ibanez*

Main category: cs.LG

TL;DR: ML-EcoLyzer是一个跨框架工具，用于测量机器学习推理在CPU、消费级GPU和数据中心加速器上的碳排放、能耗、热耗和水耗，并引入环境可持续性评分(ESS)来量化每克CO2排放可服务的有效参数数量。


<details>
  <summary>Details</summary>
Motivation: 机器学习推理规模巨大但其环境影响缺乏量化，特别是在低资源硬件上，需要系统性的环境成本评估工具。

Method: 开发ML-EcoLyzer工具，支持经典和现代模型，采用自适应监控和硬件感知评估方法，覆盖1900多种推理配置。

Result: 量化可提高ESS，大型加速器在轻量级应用中效率低下，小型模型若实施不当也会产生显著成本。

Conclusion: ML-EcoLyzer为可持续性模型选择设定了标准，提供了推理阶段环境成本的广泛实证评估。

Abstract: Machine learning inference occurs at a massive scale, yet its environmental
impact remains poorly quantified, especially on low-resource hardware. We
present ML-EcoLyzer, a cross-framework tool for measuring the carbon, energy,
thermal, and water costs of inference across CPUs, consumer GPUs, and
datacenter accelerators. The tool supports both classical and modern models,
applying adaptive monitoring and hardware-aware evaluation.
  We introduce the Environmental Sustainability Score (ESS), which quantifies
the number of effective parameters served per gram of CO$_2$ emitted. Our
evaluation covers over 1,900 inference configurations, spanning diverse model
architectures, task modalities (text, vision, audio, tabular), hardware types,
and precision levels. These rigorous and reliable measurements demonstrate that
quantization enhances ESS, huge accelerators can be inefficient for lightweight
applications, and even small models may incur significant costs when
implemented suboptimally. ML-EcoLyzer sets a standard for
sustainability-conscious model selection and offers an extensive empirical
evaluation of environmental costs during inference.

</details>


### [355] [Magnitude-Modulated Equivariant Adapter for Parameter-Efficient Fine-Tuning of Equivariant Graph Neural Networks](https://arxiv.org/abs/2511.06696)
*Dian Jin,Yancheng Yuan,Xiaoming Tao*

Main category: cs.LG

TL;DR: 提出了MMEA方法，一种新的等变参数高效微调技术，通过轻量级标量门控调节特征幅度，在保持严格等变性的同时提升性能


<details>
  <summary>Details</summary>
Motivation: 现有的等变图神经网络微调方法如ELoRA虽然保持等变性，但每个张量阶内的自由度较高，会扰动预训练特征分布并降低性能

Method: MMEA采用轻量级标量门控，按阶和多重性调节特征幅度，严格保持等变性，训练参数更少

Result: 在多个基准测试中，MMEA持续改进能量和力预测至最先进水平，同时训练参数少于竞争方法

Conclusion: 在许多实际场景中，调节通道幅度足以使等变模型适应新化学环境而不破坏对称性，为等变PEFT设计指明了新方向

Abstract: Pretrained equivariant graph neural networks based on spherical harmonics
offer efficient and accurate alternatives to computationally expensive
ab-initio methods, yet adapting them to new tasks and chemical environments
still requires fine-tuning. Conventional parameter-efficient fine-tuning (PEFT)
techniques, such as Adapters and LoRA, typically break symmetry, making them
incompatible with those equivariant architectures. ELoRA, recently proposed, is
the first equivariant PEFT method. It achieves improved parameter efficiency
and performance on many benchmarks. However, the relatively high degrees of
freedom it retains within each tensor order can still perturb pretrained
feature distributions and ultimately degrade performance. To address this, we
present Magnitude-Modulated Equivariant Adapter (MMEA), a novel equivariant
fine-tuning method which employs lightweight scalar gating to modulate feature
magnitudes on a per-order and per-multiplicity basis. We demonstrate that MMEA
preserves strict equivariance and, across multiple benchmarks, consistently
improves energy and force predictions to state-of-the-art levels while training
fewer parameters than competing approaches. These results suggest that, in many
practical scenarios, modulating channel magnitudes is sufficient to adapt
equivariant models to new chemical environments without breaking symmetry,
pointing toward a new paradigm for equivariant PEFT design.

</details>


### [356] [Sensor Calibration Model Balancing Accuracy, Real-time, and Efficiency](https://arxiv.org/abs/2511.06715)
*Jinyong Yun,Hyungjin Kim,Seokho Ahn,Euijong Lee,Young-Duk Seo*

Main category: cs.LG

TL;DR: SCARE是一个超压缩的Transformer模型，专门用于设备端传感器校准，通过三个核心组件同时满足八个微观需求，在精度、实时性和效率之间实现平衡。


<details>
  <summary>Details</summary>
Motivation: 现有的设备端传感器校准研究只关注三个宏观需求（精度、实时性和资源效率），而忽略了部署瓶颈如瞬时误差和最坏情况延迟。因此需要将这些宏观需求分解为更细致的微观要求。

Method: SCARE包含三个核心组件：(1)序列透镜投影器(SLP)对数压缩时间序列数据并保留边界信息；(2)高效位注意力(EBA)模块用位运算替代昂贵乘法；(3)哈希优化策略确保稳定训练。

Result: 在大规模空气质量数据集和真实微控制器部署上的实验表明，SCARE优于现有的线性、混合和深度学习基线，是首个同时满足所有八个微观需求的模型。

Conclusion: SCARE通过创新的压缩和优化技术，成功解决了设备端传感器校准的部署瓶颈，为资源受限环境下的高效模型部署提供了有效解决方案。

Abstract: Most on-device sensor calibration studies benchmark models only against three
macroscopic requirements (i.e., accuracy, real-time, and resource efficiency),
thereby hiding deployment bottlenecks such as instantaneous error and
worst-case latency. We therefore decompose this triad into eight microscopic
requirements and introduce Scare (Sensor Calibration model balancing Accuracy,
Real-time, and Efficiency), an ultra-compressed transformer that fulfills them
all. SCARE comprises three core components: (1) Sequence Lens Projector (SLP)
that logarithmically compresses time-series data while preserving boundary
information across bins, (2) Efficient Bitwise Attention (EBA) module that
replaces costly multiplications with bitwise operations via binary hash codes,
and (3) Hash optimization strategy that ensures stable training without
auxiliary loss terms. Together, these components minimize computational
overhead while maintaining high accuracy and compatibility with microcontroller
units (MCUs). Extensive experiments on large-scale air-quality datasets and
real microcontroller deployments demonstrate that Scare outperforms existing
linear, hybrid, and deep-learning baselines, making Scare, to the best of our
knowledge, the first model to meet all eight microscopic requirements
simultaneously.

</details>


### [357] [MobileLLM-Pro Technical Report](https://arxiv.org/abs/2511.06719)
*Patrick Huber,Ernie Chang,Wei Wen,Igor Fedorov,Tarek Elgamal,Hanxian Huang,Naveen Suda,Chinnadhurai Sankar,Vish Vogeti,Yanghan Wang,Alex Gladkov,Kai Sheng Tai,Abdelrahman Elogeel,Tarek Hefny,Vikas Chandra,Ahmed Aly,Anuj Kumar,Raghuraman Krishnamoorthi,Adithya Sagar*

Main category: cs.LG

TL;DR: MobileLLM-Pro是一个10亿参数的设备端语言模型，通过四项创新技术在11个标准基准测试中达到最先进水平，支持128,000个token的长上下文窗口，并在4位量化下仅显示轻微性能下降。


<details>
  <summary>Details</summary>
Motivation: 在移动和可穿戴设备上部署高效的语言模型需要解决1B参数模型在保持强性能、支持长上下文窗口和实际部署方面的挑战。

Method: 采用四项核心技术：1）隐式位置蒸馏技术；2）专家模型融合框架；3）基于效用估计的模拟驱动数据混合；4）4位量化感知训练与自蒸馏。

Result: 在11个标准基准测试中显著优于Gemma 3-1B和Llama 3.2-1B，支持128K token上下文，4位量化下性能下降极小。

Conclusion: MobileLLM-Pro为设备端语言模型提供了有效的解决方案，通过创新技术实现了性能与效率的平衡，并发布了模型权重和代码以支持后续研究。

Abstract: Efficient on-device language models around 1 billion parameters are essential
for powering low-latency AI applications on mobile and wearable devices.
However, achieving strong performance in this model class, while supporting
long context windows and practical deployment remains a significant challenge.
We introduce MobileLLM-Pro, a 1-billion-parameter language model optimized for
on-device deployment. MobileLLM-Pro achieves state-of-the-art results across 11
standard benchmarks, significantly outperforming both Gemma 3-1B and Llama
3.2-1B, while supporting context windows of up to 128,000 tokens and showing
only minor performance regressions at 4-bit quantization. These improvements
are enabled by four core innovations: (1) implicit positional distillation, a
novel technique that effectively instills long-context capabilities through
knowledge distillation; (2) a specialist model merging framework that fuses
multiple domain experts into a compact model without parameter growth; (3)
simulation-driven data mixing using utility estimation; and (4) 4-bit
quantization-aware training with self-distillation. We release our model
weights and code to support future research in efficient on-device language
models.

</details>


### [358] [Multi-Modal Continual Learning via Cross-Modality Adapters and Representation Alignment with Knowledge Preservation](https://arxiv.org/abs/2511.06723)
*Evelyn Chee,Wynne Hsu,Mong Li Lee*

Main category: cs.LG

TL;DR: 提出了一种基于预训练模型的多模态持续学习框架，通过跨模态适配器和表示对齐损失来解决多模态持续学习中的灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 现有的持续学习方法主要关注单模态数据，而多模态学习可以利用多样化的感官输入，类似于人类感知。但多模态持续学习面临额外挑战，需要有效整合不同模态的新信息同时防止灾难性遗忘。

Method: 提出了一个预训练模型框架，包含具有专家混合结构的跨模态适配器来促进多模态信息整合，以及表示对齐损失来学习鲁棒的多模态表示，并正则化学习表示之间的关系以保留先前任务的知识。

Result: 在多个多模态数据集上的实验表明，该方法在类增量学习和域增量学习中均优于基线方法，实现了更高的准确率和更低的遗忘率。

Conclusion: 该框架为多模态持续学习提供了一种有效的解决方案，能够更好地整合多模态信息并减轻灾难性遗忘问题。

Abstract: Continual learning is essential for adapting models to new tasks while
retaining previously acquired knowledge. While existing approaches
predominantly focus on uni-modal data, multi-modal learning offers substantial
benefits by utilizing diverse sensory inputs, akin to human perception.
However, multi-modal continual learning presents additional challenges, as the
model must effectively integrate new information from various modalities while
preventing catastrophic forgetting. In this work, we propose a pre-trained
model-based framework for multi-modal continual learning. Our framework
includes a novel cross-modality adapter with a mixture-of-experts structure to
facilitate effective integration of multi-modal information across tasks. We
also introduce a representation alignment loss that fosters learning of robust
multi-modal representations, and regularize relationships between learned
representations to preserve knowledge from previous tasks. Experiments on
several multi-modal datasets demonstrate that our approach consistently
outperforms baselines in both class-incremental and domain-incremental
learning, achieving higher accuracy and reduced forgetting.

</details>


### [359] [Rank-1 LoRAs Encode Interpretable Reasoning Signals](https://arxiv.org/abs/2511.06739)
*Jake Ward,Paul Riechers,Adam Shai*

Main category: cs.LG

TL;DR: 研究发现推理模型性能提升主要来自对基础模型参数的微小单秩变化，使用rank-1 LoRA适配器即可恢复73-90%的推理基准性能，这些变化具有可解释性。


<details>
  <summary>Details</summary>
Motivation: 尽管推理模型被广泛采用，但其性能提升机制尚未被充分理解，本研究旨在探索推理能力增强背后的参数变化机制。

Method: 使用rank-1 LoRA创建最小参数适配器，在Qwen-2.5-32B-Instruct模型上进行实验，并训练稀疏自编码器分析LoRA激活状态。

Result: 单秩LoRA适配器可恢复73-90%的推理基准性能，其激活具有可解释性，能够识别推理特定行为，发现细粒度和单义性特征。

Conclusion: 推理性能主要源于对基础模型参数的微小变化，参数高效训练方法可作为揭示语言模型行为动态的有力工具。

Abstract: Reasoning models leverage inference-time compute to significantly enhance the
performance of language models on difficult logical tasks, and have become a
dominating paradigm in frontier LLMs. Despite their wide adoption, the
mechanisms underpinning the enhanced performance of these reasoning models are
not well understood. In this work, we show that the majority of new
capabilities in reasoning models can be elicited by small, single-rank changes
to base model parameters, with many of these changes being interpretable.
Specifically, we use a rank-1 LoRA to create a minimal parameter adapter for
Qwen-2.5-32B-Instruct which recovers 73-90% of reasoning-benchmark performance
compared to a full parameter finetune. We find that the activations of this
LoRA are as interpretable as MLP neurons, and fire for reasoning-specific
behaviors. Finally, we train a sparse autoencoder on the entire activation
state of this LoRA and identify fine-grained and monosemantic features. Our
findings highlight that reasoning performance can arise largely from minimal
changes to base model parameters, and explore what these changes affect. More
broadly, our work shows that parameter-efficient training methods can be used
as a targeted lens for uncovering fundamental insights about language model
behavior and dynamics.

</details>


### [360] [Dual Mamba for Node-Specific Representation Learning: Tackling Over-Smoothing with Selective State Space Modeling](https://arxiv.org/abs/2511.06756)
*Xin He,Yili Wang,Yiwei Dai,Xin Wang*

Main category: cs.LG

TL;DR: 该论文提出了一种名为DMbaGCN的双Mamba增强图卷积网络，通过整合Mamba模型从局部和全局两个角度解决深度图神经网络中的过平滑问题。


<details>
  <summary>Details</summary>
Motivation: 现有的解决方案如残差连接和跳跃层虽然在一定程度上缓解了过平滑问题，但未能显式建模节点表示在层间的节点特定和渐进演化方式，且未考虑全局信息。

Method: DMbaGCN包含两个模块：局部状态演化Mamba（LSEMba）用于局部邻域聚合，利用Mamba的选择性状态空间建模捕获层间节点特定表示动态；全局上下文感知Mamba（GCAMba）利用Mamba的全局注意力能力为每个节点融入全局上下文。

Result: 在多个基准测试上的广泛实验证明了该方法的有效性和效率。

Conclusion: 通过结合局部和全局组件，DMbaGCN增强了深度图神经网络中节点的可区分性，从而有效缓解了过平滑问题。

Abstract: Over-smoothing remains a fundamental challenge in deep Graph Neural Networks
(GNNs), where repeated message passing causes node representations to become
indistinguishable. While existing solutions, such as residual connections and
skip layers, alleviate this issue to some extent, they fail to explicitly model
how node representations evolve in a node-specific and progressive manner
across layers. Moreover, these methods do not take global information into
account, which is also crucial for mitigating the over-smoothing problem. To
address the aforementioned issues, in this work, we propose a Dual
Mamba-enhanced Graph Convolutional Network (DMbaGCN), which is a novel
framework that integrates Mamba into GNNs to address over-smoothing from both
local and global perspectives. DMbaGCN consists of two modules: the Local
State-Evolution Mamba (LSEMba) for local neighborhood aggregation and utilizing
Mamba's selective state space modeling to capture node-specific representation
dynamics across layers, and the Global Context-Aware Mamba (GCAMba) that
leverages Mamba's global attention capabilities to incorporate global context
for each node. By combining these components, DMbaGCN enhances node
discriminability in deep GNNs, thereby mitigating over-smoothing. Extensive
experiments on multiple benchmarks demonstrate the effectiveness and efficiency
of our method.

</details>


### [361] [Implicit Federated In-context Learning For Task-Specific LLM Fine-Tuning](https://arxiv.org/abs/2511.06757)
*Dongcheng Li,Junhan Chen,Aoxiang Zhou,Chunpei Li,Youquan Xian,Peng Liu,Xianxian Li*

Main category: cs.LG

TL;DR: 提出了隐式联邦上下文学习（IFed-ICL）框架，通过将客户端本地上下文示例转换为隐式向量表示，在推理阶段实现分布式协同计算，避免传统微调方法的大量参数更新，同时减少联邦学习中的数据传输和本地计算开销。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的发展，公共数据面临枯竭风险，如何利用组织内部私有数据提升大模型性能成为关键挑战。传统联邦学习结合模型微调虽然减少了可训练参数数量，但处理高维特征空间仍带来巨大计算开销。

Method: IFed-ICL框架借鉴联邦学习思想，建立新型分布式协同范式，将客户端本地上下文示例转换为隐式向量表示，在推理阶段实现分布式协同计算，并通过注入模型残差流来增强模型性能。

Result: 实验表明，该方法在多个文本分类任务中表现出色，相比传统方法，避免了传统微调方法的大量参数更新，同时减少了联邦学习中客户端级别的数据传输和本地计算。

Conclusion: IFed-ICL能够利用本地私有域数据实现高效的分布式上下文学习，显著提升模型在特定任务上的性能。

Abstract: As large language models continue to develop and expand, the extensive public
data they rely on faces the risk of depletion. Consequently, leveraging private
data within organizations to enhance the performance of large models has
emerged as a key challenge. The federated learning paradigm, combined with
model fine-tuning techniques, effectively reduces the number of trainable
parameters. However,the necessity to process high-dimensional feature spaces
results in substantial overall computational overhead. To address this issue,
we propose the Implicit Federated In-Context Learning (IFed-ICL) framework.
IFed-ICL draws inspiration from federated learning to establish a novel
distributed collaborative paradigm, by converting client local context examples
into implicit vector representations, it enables distributed collaborative
computation during the inference phase and injects model residual streams to
enhance model performance. Experiments demonstrate that our proposed method
achieves outstanding performance across multiple text classification tasks.
Compared to traditional methods, IFed-ICL avoids the extensive parameter
updates required by conventional fine-tuning methods while reducing data
transmission and local computation at the client level in federated learning.
This enables efficient distributed context learning using local private-domain
data, significantly improving model performance on specific tasks.

</details>


### [362] [QUARK: Quantization-Enabled Circuit Sharing for Transformer Acceleration by Exploiting Common Patterns in Nonlinear Operations](https://arxiv.org/abs/2511.06767)
*Zhixiong Zhao,Haomin Li,Fangxin Liu,Yuncheng Lu,Zongwu Wang,Tao Yang,Li Jiang,Haibing Guan*

Main category: cs.LG

TL;DR: QUARK是一个针对Transformer模型中非线性操作的量化加速框架，通过电路共享设计在FPGA上实现高效加速，相比GPU实现速度提升1.96倍，硬件开销降低50%以上。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在CV和NLP领域表现出色，但其中的非线性操作会显著增加推理延迟，给硬件加速带来挑战。

Method: 提出QUARK框架，利用非线性操作中的共性模式进行电路共享，设计专门针对非线性操作的量化加速方案。

Result: QUARK显著降低了主流Transformer架构中非线性算子的计算开销，端到端速度比GPU实现快1.96倍，硬件开销降低50%以上，在超低位量化下还能提升模型精度。

Conclusion: QUARK框架有效解决了Transformer模型中非线性操作的加速问题，在保持高精度的同时实现了显著的性能提升和硬件效率优化。

Abstract: Transformer-based models have revolutionized computer vision (CV) and natural
language processing (NLP) by achieving state-of-the-art performance across a
range of benchmarks. However, nonlinear operations in models significantly
contribute to inference latency, presenting unique challenges for efficient
hardware acceleration. To this end, we propose QUARK, a quantization-enabled
FPGA acceleration framework that leverages common patterns in nonlinear
operations to enable efficient circuit sharing, thereby reducing hardware
resource requirements. QUARK targets all nonlinear operations within
Transformer-based models, achieving high-performance approximation through a
novel circuit-sharing design tailored to accelerate these operations. Our
evaluation demonstrates that QUARK significantly reduces the computational
overhead of nonlinear operators in mainstream Transformer architectures,
achieving up to a 1.96 times end-to-end speedup over GPU implementations.
Moreover, QUARK lowers the hardware overhead of nonlinear modules by more than
50% compared to prior approaches, all while maintaining high model accuracy --
and even substantially boosting accuracy under ultra-low-bit quantization.

</details>


### [363] [Data Trajectory Alignment for LLM Domain Adaptation: A Two-Phase Synthesis Framework for Telecommunications Mathematics](https://arxiv.org/abs/2511.06776)
*Zhicheng Zhou,Jing Li,Suming Qiu,Junjie Huang,Linyuan Qiu,Zhijie Sun*

Main category: cs.LG

TL;DR: DTA是一个两阶段数据整理框架，通过对齐解决过程（不仅是最终答案）来提升语言模型在电信等垂直领域的适应能力，在TELEMATH数据集上达到72.45%的准确率，同时显著提升推理效率。


<details>
  <summary>Details</summary>
Motivation: 通用大语言模型在电信等垂直领域部署时面临数据稀缺、信息密度低和移动/边缘计算资源受限的挑战，需要高效的领域适应方法。

Method: 两阶段框架：第一阶段使用强教师模型合成多样化候选解；第二阶段将教师解决方案重写以对齐中间步骤和呈现风格，通过一致性检查和反思性判断进行信号感知的示例选择。

Result: 在TELEMATH数据集上达到72.45% pass@1准确率，比蒸馏训练提升17.65个百分点，比Qwen3-32B（思考模式启用）提升2.94个百分点；在边缘推理设置下，能耗降低42%，端到端延迟降低60%。

Conclusion: 对齐解决方案生成过程能够实现紧凑高效的监督，在准确性和效率方面都表现出色，为低资源垂直领域的领域适应提供了实用方案。

Abstract: General-purpose large language models (LLMs) are increasingly deployed in
verticals such as telecommunications, where adaptation is hindered by scarce,
low-information-density corpora and tight mobile/edge constraints. We propose
Data Trajectory Alignment (DTA), a two-phase, model-agnostic data curation
framework that treats solution processes - not only final answers - as
first-class supervision. Phase I (Initializing) synthesizes diverse,
high-coverage candidates using an ensemble of strong teachers. Phase II (DTA)
rewrites teacher solutions to align intermediate steps and presentation style
with the target student's inductive biases and then performs signal-aware
exemplar selection via agreement checks and reflection-based judging.
Instantiated on telecommunications mathematics (e.g., link budgets, SNR/AMC
selection, and power-control feasibility), DTA yields state-of-the-art (SOTA)
accuracy on TELEMATH without enabling explicit "thinking" modes: 72.45% pass@1,
surpassing distilled-only training by +17.65 points and outperforming a strong
baseline (Qwen3-32B with thinking enabled) by +2.94 points. Token-shift
analyses indicate that DTA concentrates gains on logical-structural discourse
markers rather than merely amplifying domain nouns, indicating improved
reasoning scaffolding. Under edge-like inference settings, DTA improves
efficiency by reducing reliance on multi-sample voting and disabling expensive
reasoning heuristics, cutting energy per output token by ~42% versus Qwen3-32B
(thinking mode enabled) and end-to-end latency by ~60% versus Qwen3-32B
(thinking mode disabled). These results demonstrate that aligning how solutions
are produced enables compact, high-yield supervision that is effective for both
accuracy and efficiency, offering a practical recipe for domain adaptation in
low-resource verticals beyond telecom.

</details>


### [364] [On the Mechanisms of Collaborative Learning in VAE Recommenders](https://arxiv.org/abs/2511.06781)
*Tung-Long Vuong,Julien Monteil,Hien Dang,Volodymyr Vaskovych,Trung Le,Vu Nguyen*

Main category: cs.LG

TL;DR: 该论文分析了VAE在协同过滤中的协作机制，提出了潜在共享半径概念，比较了两种全局混合机制，并提出了锚点正则化器来稳定用户身份和促进全局一致性。


<details>
  <summary>Details</summary>
Motivation: 研究VAE在协同过滤中如何产生协作，特别是二进制输入掩码对性能提升的理论机制，以及如何更好地利用全局协作。

Method: 分析潜在邻近性概念，推导潜在共享半径，比较β-KL正则化和输入掩码两种全局混合机制，提出锚点正则化器来对齐用户后验和物品嵌入。

Result: 在Netflix、MovieLens-20M和Million Song数据集上验证了分析，并在亚马逊流媒体平台上成功部署了提出的算法。

Conclusion: VAE协同过滤主要利用局部协作，通过锚点正则化器可以有效促进全局协作同时保持用户身份稳定性。

Abstract: Variational Autoencoders (VAEs) are a powerful alternative to matrix
factorization for recommendation. A common technique in VAE-based collaborative
filtering (CF) consists in applying binary input masking to user interaction
vectors, which improves performance but remains underexplored theoretically. In
this work, we analyze how collaboration arises in VAE-based CF and show it is
governed by latent proximity: we derive a latent sharing radius that informs
when an SGD update on one user strictly reduces the loss on another user, with
influence decaying as the latent Wasserstein distance increases. We further
study the induced geometry: with clean inputs, VAE-based CF primarily exploits
\emph{local} collaboration between input-similar users and under-utilizes
global collaboration between far-but-related users. We compare two mechanisms
that encourage \emph{global} mixing and characterize their trade-offs: (1)
$\beta$-KL regularization directly tightens the information bottleneck,
promoting posterior overlap but risking representational collapse if too large;
(2) input masking induces stochastic geometric contractions and expansions,
which can bring distant users onto the same latent neighborhood but also
introduce neighborhood drift. To preserve user identity while enabling global
consistency, we propose an anchor regularizer that aligns user posteriors with
item embeddings, stabilizing users under masking and facilitating signal
sharing across related items. Our analyses are validated on the Netflix,
MovieLens-20M, and Million Song datasets. We also successfully deployed our
proposed algorithm on an Amazon streaming platform following a successful
online experiment.

</details>


### [365] [Resource Efficient Sleep Staging via Multi-Level Masking and Prompt Learning](https://arxiv.org/abs/2511.06785)
*Lejun Ai,Yulong Li,Haodong Yi,Jixuan Xie,Yue Wang,Jia Liu,Min Chen,Rui Wang*

Main category: cs.LG

TL;DR: 提出MASS框架，通过多级掩码和分层提示学习，在资源受限环境下实现高效睡眠分期，减少数据采集需求的同时保持分类性能


<details>
  <summary>Details</summary>
Motivation: 传统睡眠分期方法依赖连续长时EEG记录，在可穿戴或家庭监测等资源受限系统中数据采集困难

Method: 采用掩码和提示学习策略，设计多级掩码策略促进部分不规则观测下的特征建模，通过分层提示学习机制聚合未掩码数据作为语义锚点

Result: 在四个数据集上评估显示达到最先进性能，特别是在数据量非常有限时表现优异

Conclusion: MASS框架在真实世界低资源睡眠监测环境中具有高效可扩展部署潜力

Abstract: Automatic sleep staging plays a vital role in assessing sleep quality and
diagnosing sleep disorders. Most existing methods rely heavily on long and
continuous EEG recordings, which poses significant challenges for data
acquisition in resource-constrained systems, such as wearable or home-based
monitoring systems. In this paper, we propose the task of resource-efficient
sleep staging, which aims to reduce the amount of signal collected per sleep
epoch while maintaining reliable classification performance. To solve this
task, we adopt the masking and prompt learning strategy and propose a novel
framework called Mask-Aware Sleep Staging (MASS). Specifically, we design a
multi-level masking strategy to promote effective feature modeling under
partial and irregular observations. To mitigate the loss of contextual
information introduced by masking, we further propose a hierarchical prompt
learning mechanism that aggregates unmasked data into a global prompt, serving
as a semantic anchor for guiding both patch-level and epoch-level feature
modeling. MASS is evaluated on four datasets, demonstrating state-of-the-art
performance, especially when the amount of data is very limited. This result
highlights its potential for efficient and scalable deployment in real-world
low-resource sleep monitoring environments.

</details>


### [366] [Rethinking Parameter Sharing as Graph Coloring for Structured Compression](https://arxiv.org/abs/2511.06786)
*Boyang Zhang,Daning Cheng,Yunquan Zhang*

Main category: cs.LG

TL;DR: 该论文提出了一种基于几何准则的参数共享方法Geo-Sharing，通过二阶泰勒展开和Hessian谱分析来系统化地确定跨层参数共享配置，有效解决了传统启发式方法在多层共享时面临的指数级配置空间搜索问题。


<details>
  <summary>Details</summary>
Motivation: 现代深度模型参数规模庞大导致推理时内存占用过高，限制了实际部署。现有参数共享方法仅限于相邻层之间的启发式共享，缺乏对跨层共享的系统分析，且多层共享时的指数级配置空间使得穷举搜索计算不可行。

Method: 从群论视角将参数共享重构为在模型参数空间中引入结构对称性，提出基于二阶泰勒展开和Hessian谱的几何准则，通过将扰动投影到Hessian的低曲率特征子空间来选择最小化性能影响的共享组。

Result: 在不同架构和任务上，Geo-Sharing consistently outperforms state-of-the-art heuristic sharing strategies, achieving higher compression ratios with smaller accuracy degradation。

Conclusion: Geo-Sharing提供了一种原则性和可扩展的配置程序，通过几何准则系统化地解决了参数共享中的配置选择问题，在保持模型性能的同时实现了更高的压缩比。

Abstract: Modern deep models have massive parameter sizes, leading to high
inference-time memory usage that limits practical deployment. Parameter
sharing, a form of structured compression, effectively reduces redundancy, but
existing approaches remain heuristic-restricted to adjacent layers and lacking
a systematic analysis for cross-layer sharing. However, extending sharing
across multiple layers leads to an exponentially expanding configuration space,
making exhaustive search computationally infeasible and forming a critical
bottleneck for parameter sharing. We recast parameter sharing from a
group-theoretic perspective as introducing structural symmetries in the model's
parameter space. A sharing configuration can be described by a coloring
function $\alpha:L\rightarrow C$ (L: layer indices and C: sharing classes),
which determines inter-layer sharing groups while preserving structural
symmetry. To determine the coloring function, we propose a second-order
geometric criterion based on Taylor expansion and the Hessian spectrum. By
projecting perturbations onto the Hessian's low-curvature eigensubspace, the
criterion provides an analytic rule for selecting sharing groups that minimize
performance impact, yielding a principled and scalable configuration procedure.
Across diverse architectures and tasks, Geo-Sharing consistently outperforms
state-of-the-art heuristic sharing strategies, achieving higher compression
ratios with smaller accuracy degradation.

</details>


### [367] [Robust Causal Discovery under Imperfect Structural Constraints](https://arxiv.org/abs/2511.06790)
*Zidong Wang,Xi Lin,Chuchao He,Xiaoguang Gao*

Main category: cs.LG

TL;DR: 提出了一种在结构约束不完美的情况下进行鲁棒因果发现的方法，通过先验对齐和冲突解决来协调知识和数据。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常假设完美先验或只能处理特定类型的错误，当面对未知位置和类型的错误约束时性能会大幅下降。

Method: 首先通过代理模型评估不完美结构约束的可信度，然后指导稀疏惩罚项；引入多任务学习框架通过多梯度下降联合优化，解决知识驱动和数据驱动目标之间的冲突。

Result: 在多种噪声条件和结构方程模型类型下进行广泛实验，证明了该方法在不完美结构约束下的有效性和效率。

Conclusion: 该方法在线性和非线性设置下都具有鲁棒性，能够有效处理不完美的先验知识。

Abstract: Robust causal discovery from observational data under imperfect prior
knowledge remains a significant and largely unresolved challenge. Existing
methods typically presuppose perfect priors or can only handle specific,
pre-identified error types. And their performance degrades substantially when
confronted with flawed constraints of unknown location and type. This decline
arises because most of them rely on inflexible and biased thresholding
strategies that may conflict with the data distribution. To overcome these
limitations, we propose to harmonizes knowledge and data through prior
alignment and conflict resolution. First, we assess the credibility of
imperfect structural constraints through a surrogate model, which then guides a
sparse penalization term measuring the loss between the learned and constrained
adjacency matrices. We theoretically prove that, under ideal assumption, the
knowledge-driven objective aligns with the data-driven objective. Furthermore,
to resolve conflicts when this assumption is violated, we introduce a
multi-task learning framework optimized via multi-gradient descent, jointly
minimizing both objectives. Our proposed method is robust to both linear and
nonlinear settings. Extensive experiments, conducted under diverse noise
conditions and structural equation model types, demonstrate the effectiveness
and efficiency of our method under imperfect structural constraints.

</details>


### [368] [Coupling Agent-based Modeling and Life Cycle Assessment to Analyze Trade-offs in Resilient Energy Transitions](https://arxiv.org/abs/2511.06791)
*Beichen Zhang,Mohammed T. Zaki,Hanna Breunig,Newsha K. Ajami*

Main category: cs.LG

TL;DR: 提出了一个结合基于代理的建模和生命周期评估的集成建模框架，用于模拟能源转型路径与区域资源竞争、生态约束和社区负担的相互作用，并在南加州案例研究中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有评估往往孤立地评估新兴能源路径及其影响，忽视了区域资源竞争和累积影响等关键相互作用，这可能导致跨部门的意外后果。

Method: 开发了一个集成建模框架，耦合了基于代理的建模和生命周期评估方法，模拟能源转型路径与多维度约束的相互作用。

Result: 在南加州的案例研究中，该框架展示了综合多尺度决策如何塑造能源路径部署，并揭示了在情景驱动约束下的空间显式权衡。

Conclusion: 该建模框架可以进一步支持在空间和制度尺度上实现更具适应性和韧性的能源转型规划。

Abstract: Transitioning to sustainable and resilient energy systems requires navigating
complex and interdependent trade-offs across environmental, social, and
resource dimensions. Neglecting these trade-offs can lead to unintended
consequences across sectors. However, existing assessments often evaluate
emerging energy pathways and their impacts in silos, overlooking critical
interactions such as regional resource competition and cumulative impacts. We
present an integrated modeling framework that couples agent-based modeling and
Life Cycle Assessment (LCA) to simulate how energy transition pathways interact
with regional resource competition, ecological constraints, and community-level
burdens. We apply the model to a case study in Southern California. The results
demonstrate how integrated and multiscale decision making can shape energy
pathway deployment and reveal spatially explicit trade-offs under
scenario-driven constraints. This modeling framework can further support more
adaptive and resilient energy transition planning on spatial and institutional
scales.

</details>


### [369] [Cross-Modal Unlearning via Influential Neuron Path Editing in Multimodal Large Language Models](https://arxiv.org/abs/2511.06793)
*Kunhao Li,Wenhao Li,Di Wu,Lei Yang,Jun Bai,Ju Jia,Jason Xue*

Main category: cs.LG

TL;DR: 提出了MIP-Editor方法，通过模态特定归因分数识别影响神经元路径，在多模态大语言模型中实现选择性遗忘，解决了现有方法在跨模态遗忘不一致和通用知识性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型存在隐私泄露、毒性缓解和知识产权侵权等担忧，机器遗忘提供了一种选择性遗忘目标知识同时保持模型整体效用的实用解决方案。现有基于神经元编辑的遗忘方法面临跨模态遗忘不一致和通用知识性能下降的挑战。

Method: 提出多模态影响神经元路径编辑器（MIP-Editor），引入模态特定归因分数来识别负责编码遗忘集知识的影响神经元路径，并通过表示误导应用路径感知的神经元编辑。

Result: 在多模态任务上达到87.75%的最大遗忘率，通用知识保留提升54.26%；在文本任务上达到80.65%的遗忘率，保留77.9%的通用性能。

Conclusion: MIP-Editor在多模态任务中实现了优越的遗忘性能，同时有效保持了模型的通用能力，为解决多模态大语言模型的知识遗忘问题提供了有效方案。

Abstract: Multimodal Large Language Models (MLLMs) extend foundation models to
real-world applications by integrating inputs such as text and vision. However,
their broad knowledge capacity raises growing concerns about privacy leakage,
toxicity mitigation, and intellectual property violations. Machine Unlearning
(MU) offers a practical solution by selectively forgetting targeted knowledge
while preserving overall model utility. When applied to MLLMs, existing
neuron-editing-based MU approaches face two fundamental challenges: (1)
forgetting becomes inconsistent across modalities because existing point-wise
attribution methods fail to capture the structured, layer-by-layer information
flow that connects different modalities; and (2) general knowledge performance
declines when sensitive neurons that also support important reasoning paths are
pruned, as this disrupts the model's ability to generalize. To alleviate these
limitations, we propose a multimodal influential neuron path editor
(MIP-Editor) for MU. Our approach introduces modality-specific attribution
scores to identify influential neuron paths responsible for encoding forget-set
knowledge and applies influential-path-aware neuron-editing via representation
misdirection. This strategy also enables effective and coordinated forgetting
across modalities while preserving the model's general capabilities.
Experimental results demonstrate that MIP-Editor achieves a superior unlearning
performance on multimodal tasks, with a maximum forgetting rate of 87.75% and
up to 54.26% improvement in general knowledge retention. On textual tasks,
MIP-Editor achieves up to 80.65% forgetting and preserves 77.9% of general
performance. Codes are available at https://github.com/PreckLi/MIP-Editor.

</details>


### [370] [Beyond Uniform Deletion: A Data Value-Weighted Framework for Certified Machine Unlearning](https://arxiv.org/abs/2511.06794)
*Lisong He,Yi Yang,Xiangyu Chang*

Main category: cs.LG

TL;DR: 提出了一种考虑数据价值异质性的机器遗忘框架DVWU，通过基于数据价值的加权策略实现差异化遗忘，提升模型性能


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘算法忽视不同数据点对模型性能的贡献差异，平等对待所有数据点可能导致更新后模型性能下降

Method: 设计基于数据价值的加权策略，将其整合到遗忘过程中，实现差异化遗忘。以一阶牛顿更新为例，开发输出扰动和目标扰动算法实现认证遗忘

Result: 在合成和真实数据集上的实验表明，该方法相比传统遗忘方法具有更优的预测性能和鲁棒性

Conclusion: DVWU框架具有良好的扩展性，可适应更广泛的基于梯度的深度遗忘方法

Abstract: As the right to be forgotten becomes legislated worldwide, machine unlearning
mechanisms have emerged to efficiently update models for data deletion and
enhance user privacy protection. However, existing machine unlearning
algorithms frequently neglect the fact that different data points may
contribute unequally to model performance (i.e., heterogeneous data values).
Treat them equally in machine unlearning procedure can potentially degrading
the performance of updated models. To address this limitation, we propose Data
Value-Weighted Unlearning (DVWU), a general unlearning framework that accounts
for data value heterogeneity into the unlearning process. Specifically, we
design a weighting strategy based on data values, which are then integrated
into the unlearning procedure to enable differentiated unlearning for data
points with varying utility to the model. The DVWU framework can be broadly
adapted to various existing machine unlearning methods. We use the one-step
Newton update as an example for implementation, developing both output and
objective perturbation algorithms to achieve certified unlearning. Experiments
on both synthetic and real-world datasets demonstrate that our methods achieve
superior predictive performance and robustness compared to conventional
unlearning approaches. We further show the extensibility of our framework on
gradient ascent method by incorporating the proposed weighting strategy into
the gradient terms, highlighting the adaptability of DVWU for broader
gradient-based deep unlearning methods.

</details>


### [371] [FedNET: Federated Learning for Proactive Traffic Management and Network Capacity Planning](https://arxiv.org/abs/2511.06797)
*Saroj Kumar Panda,Basabdatta Palit,Sadananda Behera*

Main category: cs.LG

TL;DR: FedNET是一个基于联邦学习的主动隐私保护框架，用于大规模通信网络中高风险链路的早期识别，通过分布式多步流量预测实现提前预警。


<details>
  <summary>Details</summary>
Motivation: 传统集中式流量预测方法需要暴露敏感网络数据，存在隐私风险。FedNET旨在实现准确的多步流量预测（几小时到几天）同时保护网络数据的隐私性。

Method: 采用联邦学习对节点级流量进行分布式建模，结合已知路由信息聚合源-目的地对的流量贡献来估计未来链路级利用率，根据预测负载强度和时序变异性对链路进行排序。

Result: 联邦学习预测精度接近集中式训练，短预测周期精度最高（R²>0.92），长预测周期仍能提供有意义的预测（R²≈0.45-0.55）。在真实网络拓扑上验证表明能提前三天识别高风险链路。

Conclusion: FedNET是一个实用的工具，能够有效预测网络利用率并在关键压力状态出现前提前识别高风险链路，适用于前瞻性流量工程和容量规划。

Abstract: We propose FedNET, a proactive and privacy-preserving framework for early
identification of high-risk links in large-scale communication networks, that
leverages a distributed multi-step traffic forecasting method. FedNET employs
Federated Learning (FL) to model the temporal evolution of node-level traffic
in a distributed manner, enabling accurate multi-step-ahead predictions (e.g.,
several hours to days) without exposing sensitive network data. Using these
node-level forecasts and known routing information, FedNET estimates the future
link-level utilization by aggregating traffic contributions across all
source-destination pairs. The links are then ranked according to the predicted
load intensity and temporal variability, providing an early warning signal for
potential high-risk links. We compare the federated traffic prediction of
FedNET against a centralized multi-step learning baseline and then
systematically analyze the impact of history and prediction window sizes on
forecast accuracy using the $R^2$ score. Results indicate that FL achieves
accuracy close to centralized training, with shorter prediction horizons
consistently yielding the highest accuracy ($R^2 >0.92$), while longer horizons
providing meaningful forecasts ($R^2 \approx 0.45\text{--}0.55$). We further
validate the efficacy of the FedNET framework in predicting network utilization
on a realistic network topology and demonstrate that it consistently identifies
high-risk links well in advance (i.e., three days ahead) of the critical stress
states emerging, making it a practical tool for anticipatory traffic
engineering and capacity planning.

</details>


### [372] [Recursive Dynamics in Fast-Weights Homeostatic Reentry Networks: Toward Reflective Intelligence](https://arxiv.org/abs/2511.06798)
*B. G. Chae*

Main category: cs.LG

TL;DR: 本文提出了FH-RL机制，结合快速权重联想记忆、稳态正则化和学习重入反馈，在神经网络中实现自指计算。实验发现γ≈0.10-0.20时出现稳定反射带，内部反馈既表达性强又光谱稳定。


<details>
  <summary>Details</summary>
Motivation: 解决标准Transformer架构在推理时纯前馈操作的局限性，实现无需外部循环的内部递归，让先验潜在状态动态重入计算流。

Method: 设计FH-RL机制，包含快速权重联想记忆、稳态正则化和学习重入反馈。通过控制重入增益γ进行实验，使用IRR、ESRI和RDP三个新指标评估内部动态。

Result: 重入量随γ比例增加，学习反馈矩阵Wr保持有界且在中等增益时更结构化。γ≈0.10-0.20时出现稳定反射带，IRR平滑上升，ESRI接近零，RDP呈现一致低频周期。

Conclusion: 反馈放大和稳态调节的平衡可以产生反射性、类思维的内部处理，将现代快速权重架构与皮层重入和递归认知理论联系起来。

Abstract: This study introduces the Fast-Weights Homeostatic Reentry Layer (FH-RL), a
neural mechanism that integrates fast-weight associative memory, homeostatic
regularization, and learned reentrant feedback to approximate self-referential
computation in neural networks. Unlike standard transformer architectures that
operate in a purely feedforward manner during inference, FH-RL enables internal
recurrence without external looping, allowing prior latent states to be
dynamically re-entered into the ongoing computation stream. We conduct
controlled experiments sweeping the reentry gain $\gamma$ and evaluate emergent
internal dynamics using three novel metrics: the Information Reentry Ratio
(IRR), Eigen-Spectrum Recursion Index (ESRI), and Representational Drift
Periodicity (RDP). Results show that reentry quantity increases proportionally
with~$\gamma$, while the learned feedback matrix $W_r$ remains bounded and
becomes more structured at moderate gains. Critically, a stable reflective band
emerges around $\gamma \approx 0.10-0.20$, where internal feedback is maximally
expressive yet spectrally stable: IRR rises smoothly, ESRI remains near zero,
and RDP exhibits consistent low-frequency cycles. These findings provide
quantitative evidence that reflective, thought-like internal processing can
arise from a principled balance between feedback amplification and homeostatic
regulation, linking modern fast-weight architectures to theories of cortical
reentry and recursive cognition.

</details>


### [373] [Neural-Initialized Newton: Accelerating Nonlinear Finite Elements via Operator Learning](https://arxiv.org/abs/2511.06802)
*Kianoosh Taghikhani,Yusuke Yamazaki,Jerry Paul Varghese,Markus Apel,Reza Najian Asl,Shahed Rezaei*

Main category: cs.LG

TL;DR: 提出神经初始化牛顿方法，结合神经网络快速推理和牛顿法的精度，加速计算固体力学中的非线性问题求解


<details>
  <summary>Details</summary>
Motivation: 传统牛顿-拉弗森方法虽然稳健准确但计算成本高，而纯神经网络方法虽然快速但可能在训练分布外失去精度，需要结合两者优势

Method: 先训练物理信息条件神经场建立参数到解的连续映射，然后用神经网络的输出初始化牛顿校正进行精炼

Result: 神经初始化牛顿策略在保持精度的同时显著降低了计算成本，优于纯牛顿法和纯神经网络方法

Conclusion: 混合方法结合了神经算子的效率和NFEM的稳健性，有望加速大规模非线性模拟

Abstract: We propose a Newton-based scheme, initialized by neural operator predictions,
to accelerate the parametric solution of nonlinear problems in computational
solid mechanics. First, a physics informed conditional neural field is trained
to approximate the nonlinear parametric solutionof the governing equations.
This establishes a continuous mapping between the parameter and solution
spaces, which can then be evaluated for a given parameter at any spatial
resolution. Second, since the neural approximation may not be exact, it is
subsequently refined using a Newton-based correction initialized by the neural
output. To evaluate the effectiveness of this hybrid approach, we compare three
solution strategies: (i) the standard Newton-Raphson solver used in NFEM, which
is robust and accurate but computationally demanding; (ii) physics-informed
neural operators, which provide rapid inference but may lose accuracy outside
the training distribution and resolution; and (iii) the neural-initialized
Newton (NiN) strategy, which combines the efficiency of neural operators with
the robustness of NFEM. The results demonstrate that the proposed hybrid
approach reduces computational cost while preserving accuracy, highlighting its
potential to accelerate large-scale nonlinear simulations.

</details>


### [374] [Controllable Flow Matching for Online Reinforcement Learning](https://arxiv.org/abs/2511.06816)
*Bin Wang,Boxiang Tao,Haifeng Jing,Hongbo Dou,Zijian Wang*

Main category: cs.LG

TL;DR: CtrlFlow是一种基于条件流匹配的轨迹级合成方法，直接建模从初始状态到高回报终端状态的轨迹分布，避免了传统MBRL方法中环境动态建模导致的长期误差累积问题。


<details>
  <summary>Details</summary>
Motivation: 传统基于模型的强化学习方法依赖环境动态建模，但由于模型误差在长期rollout中的累积，往往面临建模稳定性挑战。

Method: 使用条件流匹配直接建模轨迹分布，通过最小化由非线性可控性格拉姆矩阵控制的控制能量来确保最优轨迹采样，生成的多样化轨迹数据增强策略学习的鲁棒性和跨任务泛化能力。

Result: 在在线设置中，CtrlFlow在MuJoCo基准任务上表现出比动态模型更好的性能，并实现了比标准MBRL方法更优的样本效率。

Conclusion: CtrlFlow通过直接建模轨迹分布的方法，有效解决了传统MBRL中的模型误差累积问题，在性能和样本效率方面都表现出优势。

Abstract: Model-based reinforcement learning (MBRL) typically relies on modeling
environment dynamics for data efficiency. However, due to the accumulation of
model errors over long-horizon rollouts, such methods often face challenges in
maintaining modeling stability. To address this, we propose CtrlFlow, a
trajectory-level synthetic method using conditional flow matching (CFM), which
directly modeling the distribution of trajectories from initial states to
high-return terminal states without explicitly modeling the environment
transition function. Our method ensures optimal trajectory sampling by
minimizing the control energy governed by the non-linear Controllability
Gramian Matrix, while the generated diverse trajectory data significantly
enhances the robustness and cross-task generalization of policy learning. In
online settings, CtrlFlow demonstrates the better performance on common MuJoCo
benchmark tasks than dynamics models and achieves superior sample efficiency
compared to standard MBRL methods.

</details>


### [375] [DeepRWCap: Neural-Guided Random-Walk Capacitance Solver for IC Design](https://arxiv.org/abs/2511.06831)
*Hector R. Rodriguez,Jiechen Huang,Wenjian Yu*

Main category: cs.LG

TL;DR: DeepRWCap是一种机器学习引导的随机行走求解器，用于电容提取，通过神经网络预测行走步骤中的过渡量，在工业设计上相比传统方法实现了显著的精度提升和速度加速。


<details>
  <summary>Details</summary>
Motivation: 现代半导体技术中密集堆叠结构给蒙特卡洛随机行走方法带来了挑战，特别是在多高对比度介电材料中无偏采样过渡域存在困难。

Method: 采用两阶段神经网络架构，将结构化输出分解为面分布和空间核函数，使用3D卷积网络捕获体积介电相互作用，2D深度可分离卷积建模局部核行为，结合网格位置编码和立方体对称性结构设计。

Result: 在10个工业设计上测试，与商业Raphael求解器相比，平均相对误差为1.24±0.53%；与最先进的随机差分方法Microwalk相比，平均加速23%，复杂设计上加速达49%。

Conclusion: DeepRWCap通过机器学习方法有效解决了传统随机行走在复杂半导体结构中的采样挑战，实现了高精度和显著的速度提升。

Abstract: Monte Carlo random walk methods are widely used in capacitance extraction for
their mesh-free formulation and inherent parallelism. However, modern
semiconductor technologies with densely packed structures present significant
challenges in unbiasedly sampling transition domains in walk steps with
multiple high-contrast dielectric materials. We present DeepRWCap, a machine
learning-guided random walk solver that predicts the transition quantities
required to guide each step of the walk. These include Poisson kernels,
gradient kernels, signs and magnitudes of weights. DeepRWCap employs a
two-stage neural architecture that decomposes structured outputs into face-wise
distributions and spatial kernels on cube faces. It uses 3D convolutional
networks to capture volumetric dielectric interactions and 2D depthwise
separable convolutions to model localized kernel behavior. The design
incorporates grid-based positional encodings and structural design choices
informed by cube symmetries to reduce learning redundancy and improve
generalization. Trained on 100,000 procedurally generated dielectric
configurations, DeepRWCap achieves a mean relative error of $1.24\pm0.53$\%
when benchmarked against the commercial Raphael solver on the self-capacitance
estimation of 10 industrial designs spanning 12 to 55 nm nodes. Compared to the
state-of-the-art stochastic difference method Microwalk, DeepRWCap achieves an
average 23\% speedup. On complex designs with runtimes over 10 s, it reaches an
average 49\% acceleration.

</details>


### [376] [Minimum Width of Deep Narrow Networks for Universal Approximation](https://arxiv.org/abs/2511.06837)
*Xiao-Song Yang,Qi Zhou,Xuan Zhou*

Main category: cs.LG

TL;DR: 该论文研究了全连接神经网络的最小宽度上下界，针对不同激活函数（ELU、SELU、LeakyReLU等）给出了具体的数学界限，并利用几何方法基于Poincaré-Miranda定理提供了新的证明。


<details>
  <summary>Details</summary>
Motivation: 确定全连接神经网络的最小宽度是深度神经网络理论研究的核心问题，对网络设计和训练具有重要意义，特别是关于通用逼近能力的最小宽度要求。

Method: 通过数学分析和几何方法，针对不同激活函数类型（可逆函数、可被可逆函数序列逼近的函数如ReLU）分别推导最小宽度界限，并利用Poincaré-Miranda定理构造直观的几何示例。

Result: 证明了对于ELU、SELU网络，w_min ≤ max(2d_x+1, d_y)，当d_y=2d_x时达到上界；对于LeakyReLU、ELU等网络，d_x+1 ≤ w_min ≤ d_x+d_y；对于可逆激活函数，w_min ≥ d_y + 1_{d_x<d_y≤2d_x}。

Conclusion: 该研究为不同激活函数的神经网络提供了最小宽度的理论界限，这些结果对神经网络结构设计和理论分析具有重要指导意义，特别是通过几何方法提供了更直观的理解。

Abstract: Determining the minimum width of fully connected neural networks has become a
fundamental problem in recent theoretical studies of deep neural networks. In
this paper, we study the lower bounds and upper bounds of the minimum width
required for fully connected neural networks in order to have universal
approximation capability, which is important in network design and training. We
show that $w_{min}\leq\max(2d_x+1, d_y)$ for networks with ELU, SELU, and the
upper bound of this inequality is attained when $d_y=2d_x$, where $d_x$, $d_y$
denote the input and output dimensions, respectively. Besides, we show that
$d_x+1\leq w_{min}\leq d_x+d_y$ for networks with LeakyReLU, ELU, CELU, SELU,
Softplus, by proving that ReLU can be approximated by these activation
functions. In addition, in the case that the activation function is injective
or can be uniformly approximated by a sequence of injective functions (e.g.,
ReLU), we present a new proof of the inequality $w_{min}\ge
d_y+\mathbf{1}_{d_x<d_y\leq2d_x}$ by constructing a more intuitive example via
a new geometric approach based on Poincar$\acute{\text{e}}$-Miranda Theorem.

</details>


### [377] [MI-to-Mid Distilled Compression (M2M-DC): An Hybrid-Information-Guided-Block Pruning with Progressive Inner Slicing Approach to Model Compression](https://arxiv.org/abs/2511.06842)
*Lionel Levine,Sajjad Ghiasvand,Haniyeh Ehsani Oskouie,Majid Sarrafzadeh*

Main category: cs.LG

TL;DR: M2M-DC是一种两阶段、形状安全的压缩框架，通过互信息引导的块剪枝和渐进式内部切片结合知识蒸馏，实现高效的模型压缩。


<details>
  <summary>Details</summary>
Motivation: 为了解决深度神经网络模型在部署时计算资源消耗大的问题，需要一种既能保持模型精度又能大幅减少计算量的压缩方法。

Method: 首先基于标签感知的互信息对残差块进行排序并剪枝，然后交替进行短知识蒸馏和阶段一致的通道切片，包括阶段平面切片和可选的中通道修剪。

Result: 在CIFAR-100上，ResNet-18达到85.46%准确率，参数减少72%，计算量减少63%；MobileNetV2准确率提升2.5个百分点，参数减少73%。

Conclusion: M2M-DC提供了一个紧凑实用的压缩方案，能够在保持或超越教师模型精度的同时大幅减少计算量，适用于各种残差CNN架构。

Abstract: We introduce MI-to-Mid Distilled Compression (M2M-DC), a two-scale,
shape-safe compression framework that interleaves information-guided block
pruning with progressive inner slicing and staged knowledge distillation (KD).
First, M2M-DC ranks residual (or inverted-residual) blocks by a label-aware
mutual information (MI) signal and removes the least informative units
(structured prune-after-training). It then alternates short KD phases with
stage-coherent, residual-safe channel slicing: (i) stage "planes" (co-slicing
conv2 out-channels with the downsample path and next-stage inputs), and (ii) an
optional mid-channel trim (conv1 out / bn1 / conv2 in). This targets
complementary redundancy, whole computational motifs and within-stage width
while preserving residual shape invariants. On CIFAR-100, M2M-DC yields a clean
accuracy-compute frontier. For ResNet-18, we obtain 85.46% Top-1 with 3.09M
parameters and 0.0139 GMacs (72% params, 63% GMacs vs. teacher; mean final
85.29% over three seeds). For ResNet-34, we reach 85.02% Top-1 with 5.46M
params and 0.0195 GMacs (74% / 74% vs. teacher; mean final 84.62%). Extending
to inverted-residuals, MobileNetV2 achieves a mean final 68.54% Top-1 at 1.71M
params (27%) and 0.0186 conv GMacs (24%), improving over the teacher's 66.03%
by +2.5 points across three seeds. Because M2M-DC exposes only a thin,
architecture-aware interface (blocks, stages, and down sample/skip wiring), it
generalizes across residual CNNs and extends to inverted-residual families with
minor legalization rules. The result is a compact, practical recipe for
deployment-ready models that match or surpass teacher accuracy at a fraction of
the compute.

</details>


### [378] [Beyond Observations: Reconstruction Error-Guided Irregularly Sampled Time Series Representation Learning](https://arxiv.org/abs/2511.06854)
*Jiexi Liu,Meng Cao,Songcan Chen*

Main category: cs.LG

TL;DR: iTimER是一个针对不规则采样时间序列的自监督预训练框架，利用重建误差分布和混合策略生成伪观测值，通过Wasserstein距离和对比学习提升表示学习效果


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖观测值来插补缺失值，但忽略了重建误差这一重要学习信号，该误差隐含反映了模型对数据结构的捕捉能力

Method: 提出iTimER框架，建模观测值的重建误差分布，通过误差采样和最后观测值的混合策略生成伪观测值，使用Wasserstein距离对齐误差分布，并结合对比学习目标

Result: 在分类、插值和预测任务上的大量实验表明，iTimER在不规则采样时间序列设置下持续优于现有最先进方法

Conclusion: iTimER通过利用重建误差作为学习信号，有效提升了不规则采样时间序列的表示学习性能，证明了该方法在真实世界应用中的有效性

Abstract: Irregularly sampled time series (ISTS), characterized by non-uniform time
intervals with natural missingness, are prevalent in real-world applications.
Existing approaches for ISTS modeling primarily rely on observed values to
impute unobserved ones or infer latent dynamics. However, these methods
overlook a critical source of learning signal: the reconstruction error
inherently produced during model training. Such error implicitly reflects how
well a model captures the underlying data structure and can serve as an
informative proxy for unobserved values. To exploit this insight, we propose
iTimER, a simple yet effective self-supervised pre-training framework for ISTS
representation learning. iTimER models the distribution of reconstruction
errors over observed values and generates pseudo-observations for unobserved
timestamps through a mixup strategy between sampled errors and the last
available observations. This transforms unobserved timestamps into noise-aware
training targets, enabling meaningful reconstruction signals. A Wasserstein
metric aligns reconstruction error distributions between observed and
pseudo-observed regions, while a contrastive learning objective enhances the
discriminability of learned representations. Extensive experiments on
classification, interpolation, and forecasting tasks demonstrate that iTimER
consistently outperforms state-of-the-art methods under the ISTS setting.

</details>


### [379] [Contact Wasserstein Geodesics for Non-Conservative Schrodinger Bridges](https://arxiv.org/abs/2511.06856)
*Andrea Testa,Soren Hauberg,Tamim Asfour,Leonel Rozo*

Main category: cs.LG

TL;DR: 提出了一种非保守广义薛定谔桥（NCGSB），通过接触哈密顿力学允许能量随时间变化，解决了传统薛定谔桥能量守恒假设的限制，能够建模更丰富的真实世界随机过程。


<details>
  <summary>Details</summary>
Motivation: 传统薛定谔桥受限于能量守恒假设，无法建模能量变化的随机过程，限制了其在现实世界现象中的应用。

Method: 基于接触哈密顿力学提出NCGSB框架，通过参数化Wasserstein流形将桥问题转化为有限维空间中的测地线计算，采用接触Wasserstein测地线（CWG）方法，使用ResNet架构实现非迭代求解。

Result: 在流形导航、分子动力学预测和图像生成等任务上验证了框架的有效性，展示了其实际优势和多功能性。

Conclusion: NCGSB框架突破了传统薛定谔桥的能量守恒限制，为建模能量变化的随机过程提供了更强大和通用的工具。

Abstract: The Schr\"odinger Bridge provides a principled framework for modeling
stochastic processes between distributions; however, existing methods are
limited by energy-conservation assumptions, which constrains the bridge's shape
preventing it from model varying-energy phenomena. To overcome this, we
introduce the non-conservative generalized Schr\"odinger bridge (NCGSB), a
novel, energy-varying reformulation based on contact Hamiltonian mechanics. By
allowing energy to change over time, the NCGSB provides a broader class of
real-world stochastic processes, capturing richer and more faithful
intermediate dynamics. By parameterizing the Wasserstein manifold, we lift the
bridge problem to a tractable geodesic computation in a finite-dimensional
space. Unlike computationally expensive iterative solutions, our contact
Wasserstein geodesic (CWG) is naturally implemented via a ResNet architecture
and relies on a non-iterative solver with near-linear complexity. Furthermore,
CWG supports guided generation by modulating a task-specific distance metric.
We validate our framework on tasks including manifold navigation, molecular
dynamics predictions, and image generation, demonstrating its practical
benefits and versatility.

</details>


### [380] [TuckA: Hierarchical Compact Tensor Experts for Efficient Fine-Tuning](https://arxiv.org/abs/2511.06859)
*Qifeng Lei,Zhiyong Yang,Qianqian Xu,Cong Hua,Peisong Wen,Qingming Huang*

Main category: cs.LG

TL;DR: 提出了Tucker Adaptation (TuckA)方法，通过多专家机制解决传统参数高效微调方法在复杂任务中无法充分捕捉数据多样性的问题。


<details>
  <summary>Details</summary>
Motivation: 传统PEFT方法依赖单一专家，但复杂任务中数据的多样性使得单个适配权重无法充分捕捉所有样本特征，需要更强大的多专家机制。

Method: 使用Tucker分解创建紧凑3D张量作为专家集合；采用分层策略组织专家；开发高效的批量级路由机制；提出数据感知初始化实现专家负载均衡。

Result: 在自然语言理解、图像分类和数学推理等基准测试中表现出色，为PEFT问题提供了新的有效解决方案。

Conclusion: TuckA通过多专家机制和高效的路由策略，在保持参数效率的同时显著提升了复杂任务中的适应能力。

Abstract: Efficiently fine-tuning pre-trained models for downstream tasks is a key
challenge in the era of foundation models. Parameter-efficient fine-tuning
(PEFT) presents a promising solution, achieving performance comparable to full
fine-tuning by updating only a small number of adaptation weights per layer.
Traditional PEFT methods typically rely on a single expert, where the
adaptation weight is a low-rank matrix. However, for complex tasks, the data's
inherent diversity poses a significant challenge for such models, as a single
adaptation weight cannot adequately capture the features of all samples. To
address this limitation, we explore how to integrate multiple small adaptation
experts into a compact structure to defeat a large adapter. Specifically, we
propose Tucker Adaptation (TuckA), a method with four key properties: (i) We
use Tucker decomposition to create a compact 3D tensor where each slice
naturally serves as an expert. The low-rank nature of this decomposition
ensures that the number of parameters scales efficiently as more experts are
added. (ii) We introduce a hierarchical strategy that organizes these experts
into groups at different granularities, allowing the model to capture both
local and global data patterns. (iii) We develop an efficient batch-level
routing mechanism, which reduces the router's parameter size by a factor of $L$
compared to routing at every adapted layer (where $L$ is the number of adapted
layers) (iv) We propose data-aware initialization to achieve loss-free expert
load balancing based on theoretical analysis. Extensive experiments on
benchmarks in natural language understanding, image classification, and
mathematical reasoning speak to the efficacy of TuckA, offering a new and
effective solution to the PEFT problem.

</details>


### [381] [DeepBooTS: Dual-Stream Residual Boosting for Drift-Resilient Time-Series Forecasting](https://arxiv.org/abs/2511.06893)
*Daojun Liang,Jing Chen,Xiao Wang,Yinglong Wang,Suo Li*

Main category: cs.LG

TL;DR: DeepBooTS是一种新颖的双流残差递减增强方法，通过块级集成学习逐步重构时间序列的内在信号，显著提高了对概念漂移的鲁棒性，在多个数据集上平均性能提升15.8%。


<details>
  <summary>Details</summary>
Motivation: 时间序列存在显著的非平稳性，现有预测方法对概念漂移的鲁棒性不足，即使应用了实例归一化。作者从偏差-方差角度分析概念漂移，证明加权集成可以降低方差而不增加偏差。

Method: DeepBooTS是端到端的双流残差递减增强方法，每个深度模型块都成为学习器的集成，带有辅助输出分支形成到最终预测的高速通路。块级输出修正前一个块的残差，实现输入和目标的分解。

Result: 在大规模数据集上的广泛实验表明，该方法大幅优于现有方法，在各种数据集上平均性能提升15.8%，为时间序列预测建立了新的基准。

Conclusion: DeepBooTS通过学习驱动的分解方法增强了模型的多样性和可解释性，同时显著提高了对概念漂移的鲁棒性，是时间序列预测领域的重要进展。

Abstract: Time-Series (TS) exhibits pronounced non-stationarity. Consequently, most
forecasting methods display compromised robustness to concept drift, despite
the prevalent application of instance normalization. We tackle this challenge
by first analysing concept drift through a bias-variance lens and proving that
weighted ensemble reduces variance without increasing bias. These insights
motivate DeepBooTS, a novel end-to-end dual-stream residual-decreasing boosting
method that progressively reconstructs the intrinsic signal. In our design,
each block of a deep model becomes an ensemble of learners with an auxiliary
output branch forming a highway to the final prediction. The block-wise outputs
correct the residuals of previous blocks, leading to a learning-driven
decomposition of both inputs and targets. This method enhances versatility and
interpretability while substantially improving robustness to concept drift.
Extensive experiments, including those on large-scale datasets, show that the
proposed method outperforms existing methods by a large margin, yielding an
average performance improvement of 15.8% across various datasets, establishing
a new benchmark for TS forecasting.

</details>


### [382] [COGNOS: Universal Enhancement for Time Series Anomaly Detection via Constrained Gaussian-Noise Optimization and Smoothing](https://arxiv.org/abs/2511.06894)
*Wenlong Shang,Peng Chang*

Main category: cs.LG

TL;DR: COGNOS提出了一种基于高斯白噪声正则化和卡尔曼平滑的通用框架，显著提升时间序列异常检测的重建方法性能，平均F-score提升57.9%。


<details>
  <summary>Details</summary>
Motivation: 现有基于重建的时间序列异常检测方法普遍依赖MSE损失，导致重建残差存在统计缺陷，产生噪声大、不稳定的异常分数，影响检测可靠性。

Method: COGNOS包含两个核心组件：1）高斯白噪声正则化策略，在训练时约束模型输出残差符合高斯白噪声分布；2）卡尔曼平滑后处理器，作为统计最优估计器对原始异常分数进行去噪。

Result: 在多个真实世界基准数据集上对12种不同骨干模型的实验表明，COGNOS平均F-score提升57.9%，证明其有效性。

Conclusion: 直接正则化输出统计是显著改进异常检测系统的强大且可泛化的策略。

Abstract: Reconstruction-based methods are a dominant paradigm in time series anomaly
detection (TSAD), however, their near-universal reliance on Mean Squared Error
(MSE) loss results in statistically flawed reconstruction residuals. This
fundamental weakness leads to noisy, unstable anomaly scores with a poor
signal-to-noise ratio, hindering reliable detection. To address this, we
propose Constrained Gaussian-Noise Optimization and Smoothing (COGNOS), a
universal, model-agnostic enhancement framework that tackles this issue at its
source. COGNOS introduces a novel Gaussian-White Noise Regularization strategy
during training, which directly constrains the model's output residuals to
conform to a Gaussian white noise distribution. This engineered statistical
property creates the ideal precondition for our second contribution: a Kalman
Smoothing Post-processor that provably operates as a statistically optimal
estimator to denoise the raw anomaly scores. The synergy between these two
components allows COGNOS to robustly separate the true anomaly signal from
random fluctuations. Extensive experiments demonstrate that COGNOS is highly
effective, delivering an average F-score uplift of 57.9% when applied to 12
diverse backbone models across multiple real-world benchmark datasets. Our work
reveals that directly regularizing output statistics is a powerful and
generalizable strategy for significantly improving anomaly detection systems.

</details>


### [383] [On The Presence of Double-Descent in Deep Reinforcement Learning](https://arxiv.org/abs/2511.06895)
*Viktor Veselý,Aleksandar Todorov,Matthia Sabatelli*

Main category: cs.LG

TL;DR: 该论文发现深度强化学习中存在双下降现象，过参数化模型在超过插值点后泛化能力继续提升，政策熵的持续降低表明过参数化起到了隐式正则化作用。


<details>
  <summary>Details</summary>
Motivation: 双下降悖论在非平稳的深度强化学习领域尚未被充分探索，研究者希望验证模型无关的DRL中是否存在这一现象。

Method: 使用Actor-Critic框架，通过系统改变模型容量，采用信息论指标政策熵来测量训练过程中的政策不确定性。

Result: 初步结果显示存在明显的epoch-wise双下降曲线，政策进入第二个下降区域与政策熵的持续显著降低相关。

Conclusion: 研究确立了双下降作为DRL中的一个因素，并为设计更通用、可迁移和鲁棒的智能体提供了基于信息的机制。

Abstract: The double descent (DD) paradox, where over-parameterized models see
generalization improve past the interpolation point, remains largely unexplored
in the non-stationary domain of Deep Reinforcement Learning (DRL). We present
preliminary evidence that DD exists in model-free DRL, investigating it
systematically across varying model capacity using the Actor-Critic framework.
We rely on an information-theoretic metric, Policy Entropy, to measure policy
uncertainty throughout training. Preliminary results show a clear epoch-wise DD
curve; the policy's entrance into the second descent region correlates with a
sustained, significant reduction in Policy Entropy. This entropic decay
suggests that over-parameterization acts as an implicit regularizer, guiding
the policy towards robust, flatter minima in the loss landscape. These findings
establish DD as a factor in DRL and provide an information-based mechanism for
designing agents that are more general, transferable, and robust.

</details>


### [384] [A Hybrid Autoencoder-Transformer Model for Robust Day-Ahead Electricity Price Forecasting under Extreme Conditions](https://arxiv.org/abs/2511.06898)
*Boyan Tang,Xuanhao Ren,Peng Xiao,Shunbo Lei,Xiaorong Sun,Jianghua Wu*

Main category: cs.LG

TL;DR: 提出一种结合蒸馏注意力Transformer和自编码器自回归模型的混合深度学习框架，用于提高日前电价预测在极端条件和市场异常情况下的准确性。


<details>
  <summary>Details</summary>
Motivation: 日前电价预测对电力系统高效运行至关重要，但极端条件和市场异常给现有预测方法带来重大挑战。

Method: 使用蒸馏注意力Transformer模型通过自注意力机制动态分配历史数据关键段的权重，捕捉长期趋势和短期波动；同时使用自编码器自回归模型通过无监督学习检测和隔离极端条件引发的异常模式。

Result: 在加州和山东省数据集上的实验表明，该框架在预测精度、鲁棒性和计算效率方面显著优于现有最先进方法。

Conclusion: 该框架有望增强未来电力系统的电网韧性和优化市场运营。

Abstract: Accurate day-ahead electricity price forecasting (DAEPF) is critical for the
efficient operation of power systems, but extreme condition and market
anomalies pose significant challenges to existing forecasting methods. To
overcome these challenges, this paper proposes a novel hybrid deep learning
framework that integrates a Distilled Attention Transformer (DAT) model and an
Autoencoder Self-regression Model (ASM). The DAT leverages a self-attention
mechanism to dynamically assign higher weights to critical segments of
historical data, effectively capturing both long-term trends and short-term
fluctuations. Concurrently, the ASM employs unsupervised learning to detect and
isolate anomalous patterns induced by extreme conditions, such as heavy rain,
heat waves, or human festivals. Experiments on datasets sampled from California
and Shandong Province demonstrate that our framework significantly outperforms
state-of-the-art methods in prediction accuracy, robustness, and computational
efficiency. Our framework thus holds promise for enhancing grid resilience and
optimizing market operations in future power systems.

</details>


### [385] [A Closer Look at Knowledge Distillation in Spiking Neural Network Training](https://arxiv.org/abs/2511.06902)
*Xu Liu,Na Xia,Jinxing Zhou,Jingyuan Xu,Dan Guo*

Main category: cs.LG

TL;DR: 该论文提出了两种创新的知识蒸馏策略来改善脉冲神经网络(SNN)的训练效果，通过解决ANN和SNN之间固有的架构差异问题。


<details>
  <summary>Details</summary>
Motivation: 现有的知识蒸馏方法通常简单地对齐ANN和SNN的中间特征和预测logits，但忽视了ANN输出连续分布而SNN输出稀疏离散的本质差异。

Method: 提出了SAMD（显著性缩放激活图蒸馏）和NLD（噪声平滑logits蒸馏）两种策略：SAMD将SNN的脉冲激活图与ANN的类感知激活图对齐；NLD使用高斯噪声平滑SNN的稀疏logits以对齐ANN的连续logits。

Result: 在多个数据集上的广泛实验证明了所提方法的有效性。

Conclusion: 通过考虑ANN和SNN的固有差异，提出的SAMD和NLD策略能够有效提升SNN的知识蒸馏效果，改善模型训练。

Abstract: Spiking Neural Networks (SNNs) become popular due to excellent energy
efficiency, yet facing challenges for effective model training. Recent works
improve this by introducing knowledge distillation (KD) techniques, with the
pre-trained artificial neural networks (ANNs) used as teachers and the target
SNNs as students. This is commonly accomplished through a straightforward
element-wise alignment of intermediate features and prediction logits from ANNs
and SNNs, often neglecting the intrinsic differences between their
architectures. Specifically, ANN's outputs exhibit a continuous distribution,
whereas SNN's outputs are characterized by sparsity and discreteness. To
mitigate this issue, we introduce two innovative KD strategies. Firstly, we
propose the Saliency-scaled Activation Map Distillation (SAMD), which aligns
the spike activation map of the student SNN with the class-aware activation map
of the teacher ANN. Rather than performing KD directly on the raw %and distinct
features of ANN and SNN, our SAMD directs the student to learn from saliency
activation maps that exhibit greater semantic and distribution consistency.
Additionally, we propose a Noise-smoothed Logits Distillation (NLD), which
utilizes Gaussian noise to smooth the sparse logits of student SNN,
facilitating the alignment with continuous logits from teacher ANN. Extensive
experiments on multiple datasets demonstrate the effectiveness of our methods.
Code is available~\footnote{https://github.com/SinoLeu/CKDSNN.git}.

</details>


### [386] [Counterfactual Explanation for Multivariate Time Series Forecasting with Exogenous Variables](https://arxiv.org/abs/2511.06906)
*Keita Kinjo*

Main category: cs.LG

TL;DR: 提出一种使用外生变量为时间序列预测生成反事实解释的方法，解决机器学习模型可解释性问题


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在时间序列数据分析中广泛使用，但很多模型是黑箱，可解释性成为关键问题。反事实解释是解决这一问题的方法，但时间序列预测领域的反事实解释研究相对不足

Method: 使用外生变量提取时间序列预测的反事实解释，包括分析各变量对整个时间序列的影响、通过仅改变特定变量生成反事实解释，以及评估生成的反事实解释质量

Result: 通过理论分析和实证实验验证了所提方法的准确性和实际适用性

Conclusion: 该方法有望支持基于时间序列数据分析的实际决策制定

Abstract: Currently, machine learning is widely used across various domains, including
time series data analysis. However, some machine learning models function as
black boxes, making interpretability a critical concern. One approach to
address this issue is counterfactual explanation (CE), which aims to provide
insights into model predictions. This study focuses on the relatively
underexplored problem of generating counterfactual explanations for time series
forecasting. We propose a method for extracting CEs in time series forecasting
using exogenous variables, which are frequently encountered in fields such as
business and marketing. In addition, we present methods for analyzing the
influence of each variable over an entire time series, generating CEs by
altering only specific variables, and evaluating the quality of the resulting
CEs. We validate the proposed method through theoretical analysis and empirical
experiments, showcasing its accuracy and practical applicability. These
contributions are expected to support real-world decision-making based on time
series data analysis.

</details>


### [387] [Sampling and Loss Weights in Multi-Domain Training](https://arxiv.org/abs/2511.06913)
*Mahdi Salmani,Pratik Worah,Meisam Razaviyayn,Vahab Mirrokni*

Main category: cs.LG

TL;DR: 本文研究了多域数据训练中采样权重和损失权重的互补作用，通过线性回归理论分析表明这两种权重可以降低梯度估计方差并改善泛化性能。


<details>
  <summary>Details</summary>
Motivation: 大规模深度神经网络训练需要从多个异构域收集数据，这些域在数据质量和信息多样性上存在差异，因此需要研究如何合理分配不同域数据的权重。

Method: 通过线性回归的严格理论研究，分析采样权重（控制每个域在批次中的贡献）和损失权重（缩放训练期间每个域的损失）的联合动态。

Result: 理论分析和实证支持表明，采样权重和损失权重可以互补地降低随机梯度下降中的梯度估计方差，并减少泛化差距。

Conclusion: 采样权重和损失权重在多域数据训练中具有互补作用，可以共同优化训练过程的稳定性和泛化性能。

Abstract: In the training of large deep neural networks, there is a need for vast
amounts of training data. To meet this need, data is collected from multiple
domains, such as Wikipedia and GitHub. These domains are heterogeneous in both
data quality and the diversity of information they provide. This raises the
question of how much we should rely on each domain. Several methods have
attempted to address this issue by assigning sampling weights to each data
domain using heuristics or approximations. As a first step toward a deeper
understanding of the role of data mixing, this work revisits the problem by
studying two kinds of weights: sampling weights, which control how much each
domain contributes in a batch, and loss weights, which scale the loss from each
domain during training. Through a rigorous study of linear regression, we show
that these two weights play complementary roles. First, they can reduce the
variance of gradient estimates in iterative methods such as stochastic gradient
descent (SGD). Second, they can improve generalization performance by reducing
the generalization gap. We provide both theoretical and empirical support for
these claims. We further study the joint dynamics of sampling weights and loss
weights, examining how they can be combined to capture both contributions.

</details>


### [388] [Learning to Focus: Prioritizing Informative Histories with Structured Attention Mechanisms in Partially Observable Reinforcement Learning](https://arxiv.org/abs/2511.06946)
*Daniel De Dios Allegue,Jinke He,Frans A. Oliehoek*

Main category: cs.LG

TL;DR: 该论文提出在Transformer的自注意力机制中引入结构化归纳先验，以改进基于模型的强化学习在部分可观测环境下的动态建模效率。


<details>
  <summary>Details</summary>
Motivation: 标准自注意力机制在RL轨迹中效率低下，因为RL轨迹稀疏且奖励驱动，而自注意力会均匀分配权重给所有历史标记，而不是强调对控制关键的少数转换。

Method: 引入两种结构化归纳先验：(i) 每个头的记忆长度先验，将注意力限制在任务特定窗口内；(ii) 分布先验，学习对过去状态-动作对的平滑高斯加权。这些机制集成到UniZero模型基RL代理中。

Result: 在Atari 100k基准测试中，高斯先验实现了77%的相对改进，而记忆长度先验往往因限制性截断而削弱有用信号。

Conclusion: 在具有非平稳时间依赖性的部分可观测RL领域，离散记忆窗口难以可靠学习，而平滑分布先验能灵活适应不同时间范围并产生更稳健的数据效率。

Abstract: Transformers have shown strong ability to model long-term dependencies and
are increasingly adopted as world models in model-based reinforcement learning
(RL) under partial observability. However, unlike natural language corpora, RL
trajectories are sparse and reward-driven, making standard self-attention
inefficient because it distributes weight uniformly across all past tokens
rather than emphasizing the few transitions critical for control. To address
this, we introduce structured inductive priors into the self-attention
mechanism of the dynamics head: (i) per-head memory-length priors that
constrain attention to task-specific windows, and (ii) distributional priors
that learn smooth Gaussian weightings over past state-action pairs. We
integrate these mechanisms into UniZero, a model-based RL agent with a
Transformer-based world model that supports planning under partial
observability. Experiments on the Atari 100k benchmark show that most
efficiency gains arise from the Gaussian prior, which smoothly allocates
attention to informative transitions, while memory-length priors often truncate
useful signals with overly restrictive cut-offs. In particular, Gaussian
Attention achieves a 77% relative improvement in mean human-normalized scores
over UniZero. These findings suggest that in partially observable RL domains
with non-stationary temporal dependencies, discrete memory windows are
difficult to learn reliably, whereas smooth distributional priors flexibly
adapt across horizons and yield more robust data efficiency. Overall, our
results demonstrate that encoding structured temporal priors directly into
self-attention improves the prioritization of informative histories for
dynamics modeling under partial observability.

</details>


### [389] [Hybrid Autoencoders for Tabular Data: Leveraging Model-Based Augmentation in Low-Label Settings](https://arxiv.org/abs/2511.06961)
*Erel Naor,Ofir Lindenbaum*

Main category: cs.LG

TL;DR: 提出了一种混合自编码器，结合神经网络编码器和软决策树编码器，通过模型特定的特征选择实现模型增强，在少标签表格数据分类和回归任务中优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在表格数据上表现不佳，因为它们对无关特征敏感且偏向低频函数，难以捕捉表格数据中的高频信号，特别是在标记样本有限的情况下。

Method: 使用混合自编码器架构，包含神经网络编码器和软决策树编码器，每个编码器有自己随机门控网络进行特征选择。通过共享解码器和交叉重构损失训练，软决策树编码器引导神经网络编码器学习更适合表格数据的表示。

Result: 该方法在多个表格数据集上的少标签分类和回归任务中取得了稳定提升，优于深度学习和基于树的监督基线方法。

Conclusion: 提出的混合自编码器方法有效解决了深度神经网络在表格数据上的局限性，通过模型增强和互补表示学习提升了少标签场景下的性能。

Abstract: Deep neural networks often under-perform on tabular data due to their
sensitivity to irrelevant features and a spectral bias toward smooth,
low-frequency functions. These limitations hinder their ability to capture the
sharp, high-frequency signals that often define tabular structure, especially
under limited labeled samples. While self-supervised learning (SSL) offers
promise in such settings, it remains challenging in tabular domains due to the
lack of effective data augmentations. We propose a hybrid autoencoder that
combines a neural encoder with an oblivious soft decision tree (OSDT) encoder,
each guided by its own stochastic gating network that performs sample-specific
feature selection. Together, these structurally different encoders and
model-specific gating networks implement model-based augmentation, producing
complementary input views tailored to each architecture. The two encoders,
trained with a shared decoder and cross-reconstruction loss, learn distinct yet
aligned representations that reflect their respective inductive biases. During
training, the OSDT encoder (robust to noise and effective at modeling
localized, high-frequency structure) guides the neural encoder toward
representations more aligned with tabular data. At inference, only the neural
encoder is used, preserving flexibility and SSL compatibility. Spectral
analysis highlights the distinct inductive biases of each encoder. Our method
achieves consistent gains in low-label classification and regression across
diverse tabular datasets, outperforming deep and tree-based supervised
baselines.

</details>


### [390] [Oh That Looks Familiar: A Novel Similarity Measure for Spreadsheet Template Discovery](https://arxiv.org/abs/2511.06973)
*Ananad Krishnakumar,Vengadesh Ravikumaran*

Main category: cs.LG

TL;DR: 提出了一种结合语义嵌入、数据类型和空间位置的混合距离度量方法，用于量化电子表格的结构相似性，相比传统方法能更好地识别模板。


<details>
  <summary>Details</summary>
Motivation: 传统方法无法有效捕捉电子表格的空间布局和类型模式来定义模板，需要一种新的相似性度量方法。

Method: 将电子表格转换为单元格级嵌入，然后使用Chamfer和Hausdorff距离等聚合技术计算相似度。

Result: 在FUSTE数据集上实现了完美的模板重建（调整兰德指数1.00 vs 0.90），优于基于图的Mondrian基线方法。

Conclusion: 该方法支持大规模自动化模板发现，为表格集合的检索增强生成、模型训练和批量数据清洗等下游应用提供支持。

Abstract: Traditional methods for identifying structurally similar spreadsheets fail to
capture the spatial layouts and type patterns defining templates. To quantify
spreadsheet similarity, we introduce a hybrid distance metric that combines
semantic embeddings, data type information, and spatial positioning. In order
to calculate spreadsheet similarity, our method converts spreadsheets into
cell-level embeddings and then uses aggregation techniques like Chamfer and
Hausdorff distances. Experiments across template families demonstrate superior
unsupervised clustering performance compared to the graph-based Mondrian
baseline, achieving perfect template reconstruction (Adjusted Rand Index of
1.00 versus 0.90) on the FUSTE dataset. Our approach facilitates large-scale
automated template discovery, which in turn enables downstream applications
such as retrieval-augmented generation over tabular collections, model
training, and bulk data cleaning.

</details>


### [391] [Rethinking Crystal Symmetry Prediction: A Decoupled Perspective](https://arxiv.org/abs/2511.06976)
*Liheng Yu,Zhe Zhao,Xucong Wang,Di Wu,Pengkun Wang*

Main category: cs.LG

TL;DR: XRDecoupler框架通过解耦视角解决晶体对称性分析中的子属性混淆问题，模仿化学家思维过程，结合多维对称信息作为超类指导，实现高性能、可解释性和泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有方法盲目应用深度学习模型而忽略化学规则，且面临严重的子属性混淆问题，需要更符合化学直觉的对称性分析方法

Method: 引入XRDecoupler框架，创新性地融入多维晶体对称信息作为超类指导，设计分层PXRD模式学习模型和多目标优化方法

Result: 在CCDC、CoREMOF和InorganicData三个主流数据库上的综合评估显示，XRDecoupler在性能、可解释性和泛化性方面表现优异

Conclusion: XRDecoupler通过解耦视角和化学直觉指导，有效解决了晶体对称性分析中的SPC问题，为结构分析提供了高质量的解决方案

Abstract: Efficiently and accurately determining the symmetry is a crucial step in the
structural analysis of crystalline materials. Existing methods usually
mindlessly apply deep learning models while ignoring the underlying chemical
rules. More importantly, experiments show that they face a serious sub-property
confusion SPC problem. To address the above challenges, from a decoupled
perspective, we introduce the XRDecoupler framework, a problem-solving arsenal
specifically designed to tackle the SPC problem. Imitating the thinking process
of chemists, we innovatively incorporate multidimensional crystal symmetry
information as superclass guidance to ensure that the model's prediction
process aligns with chemical intuition. We further design a hierarchical PXRD
pattern learning model and a multi-objective optimization approach to achieve
high-quality representation and balanced optimization. Comprehensive
evaluations on three mainstream databases (e.g., CCDC, CoREMOF, and
InorganicData) demonstrate that XRDecoupler excels in performance,
interpretability, and generalization.

</details>


### [392] [Fast Bayesian Updates via Harmonic Representations](https://arxiv.org/abs/2511.06978)
*Di Zhang*

Main category: cs.LG

TL;DR: 提出了一种基于谐波分析的快速贝叶斯更新统一框架，将贝叶斯更新转化为谱卷积，利用FFT实现O(N log N)复杂度的确定性算法


<details>
  <summary>Details</summary>
Motivation: 传统贝叶斯推断方法（如MCMC和变分推断）存在计算复杂度和可扩展性限制，特别是难以处理证据积分问题

Method: 在正交基中表示先验和似然函数，将贝叶斯更新规则转化为谱卷积，引入谱截断方案，利用FFT实现高效计算

Result: 该方法在平滑函数上可获得高精度有限维近似，计算复杂度从O(N^2)降至O(N log N)，显著提升计算效率

Conclusion: 该工作实现了贝叶斯计算范式的转变，将贝叶斯计算与信号处理联系起来，为实时顺序推断开辟了新途径

Abstract: Bayesian inference, while foundational to probabilistic reasoning, is often
hampered by the computational intractability of posterior distributions,
particularly through the challenging evidence integral. Conventional approaches
like Markov Chain Monte Carlo (MCMC) and Variational Inference (VI) face
significant scalability and efficiency limitations. This paper introduces a
novel, unifying framework for fast Bayesian updates by leveraging harmonic
analysis. We demonstrate that representing the prior and likelihood in a
suitable orthogonal basis transforms the Bayesian update rule into a spectral
convolution. Specifically, the Fourier coefficients of the posterior are shown
to be the normalized convolution of the prior and likelihood coefficients. To
achieve computational feasibility, we introduce a spectral truncation scheme,
which, for smooth functions, yields an exceptionally accurate
finite-dimensional approximation and reduces the update to a circular
convolution. This formulation allows us to exploit the Fast Fourier Transform
(FFT), resulting in a deterministic algorithm with O(N log N) complexity -- a
substantial improvement over the O(N^2) cost of naive methods. We establish
rigorous mathematical criteria for the applicability of our method, linking its
efficiency to the smoothness and spectral decay of the involved distributions.
The presented work offers a paradigm shift, connecting Bayesian computation to
signal processing and opening avenues for real-time, sequential inference in a
wide class of problems.

</details>


### [393] [Breaking the Gradient Barrier: Unveiling Large Language Models for Strategic Classification](https://arxiv.org/abs/2511.06979)
*Xinpeng Lv,Yunxin Mao,Haoxuan Li,Ke Liang,Jinxuan Yang,Wanrong Huang,Haoang Chi,Huan Chen,Long Lan,Yuanlong Chen,Wenjing Yang,Haotian Wang*

Main category: cs.LG

TL;DR: 提出GLIM方法，利用大语言模型的上下文学习能力实现无梯度的战略分类框架，解决传统方法在真实世界数据集上的可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 现有战略分类方法主要基于线性模型或浅层神经网络，在处理金融和互联网领域大规模数据集时面临可扩展性和容量限制。

Method: GLIM（梯度自由战略分类方法），基于大语言模型的上下文学习，在自注意力前向传播过程中隐式模拟战略分类的双层优化过程，无需微调LLM。

Result: 在真实世界和合成数据集上的实验验证表明，GLIM在金融和互联网领域展现出鲁棒性和高效性，能够适应广泛的战略操纵。

Conclusion: GLIM为大规模战略分类任务提供了有效的解决方案，具备成本效益高的动态适应能力。

Abstract: Strategic classification~(SC) explores how individuals or entities modify
their features strategically to achieve favorable classification outcomes.
However, existing SC methods, which are largely based on linear models or
shallow neural networks, face significant limitations in terms of scalability
and capacity when applied to real-world datasets with significantly increasing
scale, especially in financial services and the internet sector. In this paper,
we investigate how to leverage large language models to design a more scalable
and efficient SC framework, especially in the case of growing individuals
engaged with decision-making processes. Specifically, we introduce GLIM, a
gradient-free SC method grounded in in-context learning. During the
feed-forward process of self-attention, GLIM implicitly simulates the typical
bi-level optimization process of SC, including both the feature manipulation
and decision rule optimization. Without fine-tuning the LLMs, our proposed GLIM
enjoys the advantage of cost-effective adaptation in dynamic strategic
environments. Theoretically, we prove GLIM can support pre-trained LLMs to
adapt to a broad range of strategic manipulations. We validate our approach
through experiments with a collection of pre-trained LLMs on real-world and
synthetic datasets in financial and internet domains, demonstrating that our
GLIM exhibits both robustness and efficiency, and offering an effective
solution for large-scale SC tasks.

</details>


### [394] [HCFSLN: Adaptive Hyperbolic Few-Shot Learning for Multimodal Anxiety Detection](https://arxiv.org/abs/2511.06988)
*Aditya Sneh,Nilesh Kumar Sahu,Anushka Sanjay Shelke,Arya Adyasha,Haroon R. Lone*

Main category: cs.LG

TL;DR: 提出双曲曲率少样本学习网络（HCFSLN），通过双曲嵌入、跨模态注意力和自适应门控网络增强特征可分性，在仅需少量数据的情况下实现88%的焦虑检测准确率，优于最佳基线14%。


<details>
  <summary>Details</summary>
Motivation: 传统焦虑障碍诊断依赖临床访谈，机器学习模型因数据有限易过拟合，大规模数据收集成本高且耗时，限制了可及性。

Method: HCFSLN框架整合语音、生理信号和视频数据，利用双曲嵌入提升特征可分性，结合跨模态注意力和自适应门控网络实现少样本学习。

Result: 在108名参与者的多模态焦虑数据集上，HCFSLN达到88%的准确率，比六种少样本学习基线方法的最佳结果高出14%。

Conclusion: 双曲空间能有效建模焦虑相关语音模式，少样本学习在焦虑分类中具有巨大潜力。

Abstract: Anxiety disorders impact millions globally, yet traditional diagnosis relies
on clinical interviews, while machine learning models struggle with overfitting
due to limited data. Large-scale data collection remains costly and
time-consuming, restricting accessibility. To address this, we introduce the
Hyperbolic Curvature Few-Shot Learning Network (HCFSLN), a novel Few-Shot
Learning (FSL) framework for multimodal anxiety detection, integrating speech,
physiological signals, and video data. HCFSLN enhances feature separability
through hyperbolic embeddings, cross-modal attention, and an adaptive gating
network, enabling robust classification with minimal data. We collected a
multimodal anxiety dataset from 108 participants and benchmarked HCFSLN against
six FSL baselines, achieving 88% accuracy, outperforming the best baseline by
14%. These results highlight the effectiveness of hyperbolic space for modeling
anxiety-related speech patterns and demonstrate FSL's potential for anxiety
classification.

</details>


### [395] [CoLM: Collaborative Large Models via A Client-Server Paradigm](https://arxiv.org/abs/2511.06991)
*Siqi Huang,Sida Huang,Hongyuan Zhang*

Main category: cs.LG

TL;DR: CoLM是一个从客户端-服务器视角重新定义大模型协作的新框架，通过聚合多模型输出来让每个客户端模型独立优化自身生成，相比传统集成方法更符合实际部署需求。


<details>
  <summary>Details</summary>
Motivation: 现有的大模型集成方法通常采用服务器到服务器模式，不符合现代互联网架构下少量服务器模型被多个客户端共享的实际部署场景。

Method: CoLM框架允许多个模型的输出被聚合或共享，使每个客户端模型能够基于这些高质量输出独立地优化和更新自身的生成结果，充分利用客户端和服务器端模型资源。

Result: 在多个基准测试上的实验结果表明，CoLM能够持续提升模型在先前失败查询上的性能，证明了协作指导在增强单模型能力方面的有效性。

Conclusion: CoLM框架通过客户端-服务器协作模式有效提升了大模型的推理性能，并成功扩展到视觉语言模型领域，展示了其广泛适用性。

Abstract: Large models have achieved remarkable performance across a range of reasoning
and understanding tasks. Prior work often utilizes model ensembles or
multi-agent systems to collaboratively generate responses, effectively
operating in a server-to-server paradigm. However, such approaches do not align
well with practical deployment settings, where a limited number of server-side
models are shared by many clients under modern internet architectures. In this
paper, we introduce \textbf{CoLM} (\textbf{Co}llaboration in
\textbf{L}arge-\textbf{M}odels), a novel framework for collaborative reasoning
that redefines cooperation among large models from a client-server perspective.
Unlike traditional ensemble methods that rely on simultaneous inference from
multiple models to produce a single output, CoLM allows the outputs of multiple
models to be aggregated or shared, enabling each client model to independently
refine and update its own generation based on these high-quality outputs. This
design enables collaborative benefits by fully leveraging both client-side and
shared server-side models. We further extend CoLM to vision-language models
(VLMs), demonstrating its applicability beyond language tasks. Experimental
results across multiple benchmarks show that CoLM consistently improves model
performance on previously failed queries, highlighting the effectiveness of
collaborative guidance in enhancing single-model capabilities.

</details>


### [396] [S$^2$Drug: Bridging Protein Sequence and 3D Structure in Contrastive Representation Learning for Virtual Screening](https://arxiv.org/abs/2511.07006)
*Bowei He,Bowen Gao,Yankai Chen,Yanyan Lan,Chen Ma,Philip S. Yu,Ya-Qin Zhang,Wei-Ying Ma*

Main category: cs.LG

TL;DR: S²Drug是一个两阶段框架，通过结合蛋白质序列信息和3D结构上下文来改进虚拟筛选性能，在多个基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法主要依赖结构数据而忽略更易获取的蛋白质序列信息，直接整合序列面临冗余和噪声的挑战。

Method: 第一阶段在ChemBL上进行蛋白质序列预训练，第二阶段在PDBBind上通过残基级门控模块融合序列和结构信息，并引入结合位点预测辅助任务。

Result: 在多个基准测试中，S²Drug持续提升虚拟筛选性能，并在结合位点预测上取得强结果。

Conclusion: 通过桥接序列和结构的对比学习具有重要价值，能有效改进蛋白质-配体匹配精度。

Abstract: Virtual screening (VS) is an essential task in drug discovery, focusing on
the identification of small-molecule ligands that bind to specific protein
pockets. Existing deep learning methods, from early regression models to recent
contrastive learning approaches, primarily rely on structural data while
overlooking protein sequences, which are more accessible and can enhance
generalizability. However, directly integrating protein sequences poses
challenges due to the redundancy and noise in large-scale protein-ligand
datasets. To address these limitations, we propose \textbf{S$^2$Drug}, a
two-stage framework that explicitly incorporates protein \textbf{S}equence
information and 3D \textbf{S}tructure context in protein-ligand contrastive
representation learning. In the first stage, we perform protein sequence
pretraining on ChemBL using an ESM2-based backbone, combined with a tailored
data sampling strategy to reduce redundancy and noise on both protein and
ligand sides. In the second stage, we fine-tune on PDBBind by fusing sequence
and structure information through a residue-level gating module, while
introducing an auxiliary binding site prediction task. This auxiliary task
guides the model to accurately localize binding residues within the protein
sequence and capture their 3D spatial arrangement, thereby refining
protein-ligand matching. Across multiple benchmarks, S$^2$Drug consistently
improves virtual screening performance and achieves strong results on binding
site prediction, demonstrating the value of bridging sequence and structure in
contrastive learning.

</details>


### [397] [Correcting False Alarms from Unseen: Adapting Graph Anomaly Detectors at Test Time](https://arxiv.org/abs/2511.07023)
*Junjun Pan,Yixin Liu,Chuan Zhou,Fei Xiong,Alan Wee-Chung Liew,Shirui Pan*

Main category: cs.LG

TL;DR: 本文提出了TUNE框架，用于解决图异常检测中的分布偏移问题，通过测试时自适应来校正未见正常模式，提升预训练模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现实场景中图异常检测模型面临训练和测试分布不一致的问题，特别是新出现的正常样本会导致语义混淆和聚合污染，降低模型性能。

Method: 提出轻量级即插即用框架TUNE，使用图对齐器在属性层面对齐偏移数据，并通过最小化表示层偏移作为监督信号来训练对齐器。

Result: 在10个真实数据集上的实验表明，TUNE显著提升了预训练GAD模型对合成和真实未见正常模式的泛化能力。

Conclusion: TUNE框架有效解决了图异常检测中的分布偏移问题，为实际应用提供了实用的解决方案。

Abstract: Graph anomaly detection (GAD), which aims to detect outliers in
graph-structured data, has received increasing research attention recently.
However, existing GAD methods assume identical training and testing
distributions, which is rarely valid in practice. In real-world scenarios,
unseen but normal samples may emerge during deployment, leading to a normality
shift that degrades the performance of GAD models trained on the original data.
Through empirical analysis, we reveal that the degradation arises from (1)
semantic confusion, where unseen normal samples are misinterpreted as anomalies
due to their novel patterns, and (2) aggregation contamination, where the
representations of seen normal nodes are distorted by unseen normals through
message aggregation. While retraining or fine-tuning GAD models could be a
potential solution to the above challenges, the high cost of model retraining
and the difficulty of obtaining labeled data often render this approach
impractical in real-world applications. To bridge the gap, we proposed a
lightweight and plug-and-play Test-time adaptation framework for correcting
Unseen Normal pattErns (TUNE) in GAD. To address semantic confusion, a graph
aligner is employed to align the shifted data to the original one at the graph
attribute level. Moreover, we utilize the minimization of representation-level
shift as a supervision signal to train the aligner, which leverages the
estimated aggregation contamination as a key indicator of normality shift.
Extensive experiments on 10 real-world datasets demonstrate that TUNE
significantly enhances the generalizability of pre-trained GAD models to both
synthetic and real unseen normal patterns.

</details>


### [398] [Fair Bayesian Data Selection via Generalized Discrepancy Measures](https://arxiv.org/abs/2511.07032)
*Yixuan Zhang,Jiabin Luo,Zhenggang Wang,Feng Zhou,Quyu Kong*

Main category: cs.LG

TL;DR: 提出了一种贝叶斯数据选择框架，通过对齐组特定后验分布与共享中心分布来确保公平性，避免了显式公平约束，并在公平性和准确性上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有公平性方法通常在模型层面干预，存在计算成本高、可扩展性差和泛化能力弱的问题。

Method: 采用贝叶斯数据选择框架，支持通过Wasserstein距离、最大均值差异和f-散度等分布差异度量进行灵活对齐，实现几何感知的公平控制。

Result: 在基准数据集上的实验表明，该方法在公平性和准确性方面均优于现有的数据选择和模型基公平方法。

Conclusion: 这种数据中心的方法能够减轻训练数据中的组特定偏差，并在下游任务中提高公平性，且具有理论保证。

Abstract: Fairness concerns are increasingly critical as machine learning models are
deployed in high-stakes applications. While existing fairness-aware methods
typically intervene at the model level, they often suffer from high
computational costs, limited scalability, and poor generalization. To address
these challenges, we propose a Bayesian data selection framework that ensures
fairness by aligning group-specific posterior distributions of model parameters
and sample weights with a shared central distribution. Our framework supports
flexible alignment via various distributional discrepancy measures, including
Wasserstein distance, maximum mean discrepancy, and $f$-divergence, allowing
geometry-aware control without imposing explicit fairness constraints. This
data-centric approach mitigates group-specific biases in training data and
improves fairness in downstream tasks, with theoretical guarantees. Experiments
on benchmark datasets show that our method consistently outperforms existing
data selection and model-based fairness methods in both fairness and accuracy.

</details>


### [399] [Learning Quantized Continuous Controllers for Integer Hardware](https://arxiv.org/abs/2511.07046)
*Fabian Kresse,Christoph H. Lampert*

Main category: cs.LG

TL;DR: 该论文研究如何在嵌入式硬件上部署连续控制强化学习策略，通过量化感知训练实现整数推理，自动选择低比特策略并合成到Artix-7 FPGA上，在保持性能的同时显著降低延迟和功耗。


<details>
  <summary>Details</summary>
Motivation: 在嵌入式硬件上部署连续控制强化学习策略需要满足严格的延迟和功耗预算，小型FPGA可以实现这些要求，但需要避免昂贵的浮点运算管道。

Method: 采用量化感知训练方法进行策略训练，实现整数推理，开发了一个从学习到硬件的自动化流程，能够自动选择低比特策略并将其合成到Artix-7 FPGA上。

Result: 在五个MuJoCo任务中，获得的策略网络与全精度策略性能相当，但每个权重和内部激活值仅需3位甚至2位。在目标硬件上，推理延迟达到微秒级别，每次动作消耗微焦耳能量，且量化策略比浮点基线具有更好的输入噪声鲁棒性。

Conclusion: 量化感知训练可以有效实现低比特策略在嵌入式硬件上的高效部署，显著降低延迟和功耗，同时保持甚至提升性能表现。

Abstract: Deploying continuous-control reinforcement learning policies on embedded
hardware requires meeting tight latency and power budgets. Small FPGAs can
deliver these, but only if costly floating point pipelines are avoided. We
study quantization-aware training (QAT) of policies for integer inference and
we present a learning-to-hardware pipeline that automatically selects low-bit
policies and synthesizes them to an Artix-7 FPGA. Across five MuJoCo tasks, we
obtain policy networks that are competitive with full precision (FP32) policies
but require as few as 3 or even only 2 bits per weight, and per internal
activation value, as long as input precision is chosen carefully. On the target
hardware, the selected policies achieve inference latencies on the order of
microseconds and consume microjoules per action, favorably comparing to a
quantized reference. Last, we observe that the quantized policies exhibit
increased input noise robustness compared to the floating-point baseline.

</details>


### [400] [Breaking Privacy in Federated Clustering: Perfect Input Reconstruction via Temporal Correlations](https://arxiv.org/abs/2511.07073)
*Guang Yang,Lixia Luo,Qiongxiu Li*

Main category: cs.LG

TL;DR: 论文揭示了联邦聚类中发布中间质心会导致隐私泄露，提出了一种基于轨迹感知的重建攻击方法，能够完美恢复原始输入数据。


<details>
  <summary>Details</summary>
Motivation: 现有联邦聚类协议为了降低开销而发布中间质心，但关于这种披露是否真正安全仍然存在疑问。之前的研究认为质心发布可能是安全的，因为经典攻击方法无法恢复输入。

Method: 提出轨迹感知重建（TAR）攻击方法，该方法结合k-means迭代过程中的时间规律性和代数分析，利用质心轨迹中的可被利用的结构来恢复原始输入。

Result: TAR攻击能够完美恢复原始输入数据，提供了第一个有实际攻击支持的严格证据，证明联邦聚类中的质心披露会显著损害隐私。

Conclusion: 研究发现揭示了联邦聚类中隐私与效率之间的根本矛盾，质心披露会严重破坏隐私保护。

Abstract: Federated clustering allows multiple parties to discover patterns in
distributed data without sharing raw samples. To reduce overhead, many
protocols disclose intermediate centroids during training. While often treated
as harmless for efficiency, whether such disclosure compromises privacy remains
an open question. Prior analyses modeled the problem as a so-called Hidden
Subset Sum Problem (HSSP) and argued that centroid release may be safe, since
classical HSSP attacks fail to recover inputs.
  We revisit this question and uncover a new leakage mechanism: temporal
regularities in $k$-means iterations create exploitable structure that enables
perfect input reconstruction. Building on this insight, we propose
Trajectory-Aware Reconstruction (TAR), an attack that combines temporal
assignment information with algebraic analysis to recover exact original
inputs. Our findings provide the first rigorous evidence, supported by a
practical attack, that centroid disclosure in federated clustering
significantly compromises privacy, exposing a fundamental tension between
privacy and efficiency.

</details>


### [401] [Direct Molecular Polarizability Prediction with SO(3) Equivariant Local Frame GNNs](https://arxiv.org/abs/2511.07087)
*Jean Philip Filling,Felix Post,Michael Wand,Denis Andrienko*

Main category: cs.LG

TL;DR: 提出一种新颖的等变图神经网络架构，用于直接预测分子的张量响应特性，而非通过标量回归求导获得张量特性。


<details>
  <summary>Details</summary>
Motivation: 传统方法主要关注标量特性回归，并通过导数获得张量特性，这限制了模型对分子几何结构的直接建模能力。

Method: 使用局部坐标系保持SO(3)等变性，在局部消息传递框架中集成标量、矢量和张量通道来有效捕捉几何信息。

Result: 在QM7-X数据集上预测分子极化率，张量消息传递模型优于标量消息传递模型。

Conclusion: 这项工作推动了开发结构化、几何感知的神经模型用于分子特性预测的进展。

Abstract: We introduce a novel equivariant graph neural network (GNN) architecture
designed to predict the tensorial response properties of molecules. Unlike
traditional frameworks that focus on regressing scalar quantities and derive
tensorial properties from their derivatives, our approach maintains
$SO(3)$-equivariance through the use of local coordinate frames. Our GNN
effectively captures geometric information by integrating scalar, vector, and
tensor channels within a local message-passing framework. To assess the
accuracy of our model, we apply it to predict the polarizabilities of molecules
in the QM7-X dataset and show that tensorial message passing outperforms scalar
message passing models. This work marks an advancement towards developing
structured, geometry-aware neural models for molecular property prediction.

</details>


### [402] [On the Joint Minimization of Regularization Loss Functions in Deep Variational Bayesian Methods for Attribute-Controlled Symbolic Music Generation](https://arxiv.org/abs/2511.07118)
*Matteo Pettenó,Alessandro Ilic Mezza,Alberto Bernardini*

Main category: cs.LG

TL;DR: 该论文探讨了显式潜变量模型中KLD和AR损失平衡的难题，提出了通过属性变换来实现可控性和潜空间正则化的方法。


<details>
  <summary>Details</summary>
Motivation: 在变分信息瓶颈模型中，KLD和AR损失的线性组合平衡非常困难：KLD主导时模型缺乏可控性，AR主导时编码器会违反标准正态先验。这种平衡问题影响了符号音乐生成中连续音乐属性的可控性。

Method: 研究了现有方法在联合最小化两个正则化目标时的困难，发现合适的属性变换可以帮助同时实现目标潜维度的可控性和正则化。

Result: 展示了现有方法在平衡KLD和AR损失方面的局限性，证明了属性变换策略的有效性。

Conclusion: 通过适当的属性变换，可以在符号音乐生成中同时实现良好的可控性和潜空间的正则化，解决了传统线性组合损失函数的平衡难题。

Abstract: Explicit latent variable models provide a flexible yet powerful framework for
data synthesis, enabling controlled manipulation of generative factors. With
latent variables drawn from a tractable probability density function that can
be further constrained, these models enable continuous and semantically rich
exploration of the output space by navigating their latent spaces. Structured
latent representations are typically obtained through the joint minimization of
regularization loss functions. In variational information bottleneck models,
reconstruction loss and Kullback-Leibler Divergence (KLD) are often linearly
combined with an auxiliary Attribute-Regularization (AR) loss. However,
balancing KLD and AR turns out to be a very delicate matter. When KLD dominates
over AR, generative models tend to lack controllability; when AR dominates over
KLD, the stochastic encoder is encouraged to violate the standard normal prior.
We explore this trade-off in the context of symbolic music generation with
explicit control over continuous musical attributes. We show that existing
approaches struggle to jointly minimize both regularization objectives, whereas
suitable attribute transformations can help achieve both controllability and
regularization of the target latent dimensions.

</details>


### [403] [REACT-LLM: A Benchmark for Evaluating LLM Integration with Causal Features in Clinical Prognostic Tasks](https://arxiv.org/abs/2511.07127)
*Linna Wang,Zhixuan You,Qihui Zhang,Jiunan Wen,Ji Shi,Yimin Chen,Yusen Wang,Fanqi Ding,Ziliang Feng,Li Lu*

Main category: cs.LG

TL;DR: REACT-LLM是一个评估LLMs与因果特征结合在临床风险预测中性能的基准测试，涵盖7个临床结局和多种模型比较。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏系统评估LLMs与因果学习在临床决策中协同作用的基准测试，特别是在识别对结局有因果影响的特征方面。

Method: 引入REACT-LLM基准，评估15个LLMs、6个传统ML模型和3个因果发现算法在2个真实世界数据集上的7个临床结局预测性能。

Result: LLMs在临床预后中表现尚可但未超越传统ML模型；将因果特征整合到LLMs中性能提升有限，主要因为因果发现方法的严格假设在复杂临床数据中常被违反。

Conclusion: 虽然直接整合效果有限，但基准测试揭示了更有前景的协同作用，为未来研究指明了方向。

Abstract: Large Language Models (LLMs) and causal learning each hold strong potential
for clinical decision making (CDM). However, their synergy remains poorly
understood, largely due to the lack of systematic benchmarks evaluating their
integration in clinical risk prediction. In real-world healthcare, identifying
features with causal influence on outcomes is crucial for actionable and
trustworthy predictions. While recent work highlights LLMs' emerging causal
reasoning abilities, there lacks comprehensive benchmarks to assess their
causal learning and performance informed by causal features in clinical risk
prediction. To address this, we introduce REACT-LLM, a benchmark designed to
evaluate whether combining LLMs with causal features can enhance clinical
prognostic performance and potentially outperform traditional machine learning
(ML) methods. Unlike existing LLM-clinical benchmarks that often focus on a
limited set of outcomes, REACT-LLM evaluates 7 clinical outcomes across 2
real-world datasets, comparing 15 prominent LLMs, 6 traditional ML models, and
3 causal discovery (CD) algorithms. Our findings indicate that while LLMs
perform reasonably in clinical prognostics, they have not yet outperformed
traditional ML models. Integrating causal features derived from CD algorithms
into LLMs offers limited performance gains, primarily due to the strict
assumptions of many CD methods, which are often violated in complex clinical
data. While the direct integration yields limited improvement, our benchmark
reveals a more promising synergy.

</details>


### [404] [Conditional Diffusion as Latent Constraints for Controllable Symbolic Music Generation](https://arxiv.org/abs/2511.07156)
*Matteo Pettenó,Alessandro Ilic Mezza,Alberto Bernardini*

Main category: cs.LG

TL;DR: 本文提出了一种基于扩散模型的潜在约束方法，用于符号音乐生成，通过小型条件扩散模型作为隐式概率先验，实现对多种音乐属性的精确控制。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖音乐上下文或自然语言作为生成过程的交互方式，不适合需要精确控制特定音乐属性的专家用户。

Method: 使用冻结的无条件主干网络，结合小型条件扩散模型库作为潜在约束，通过去噪扩散过程实现plug-and-play的隐式概率先验控制。

Result: 扩散驱动的约束方法在目标属性与生成属性之间实现了显著更强的相关性，同时保持了高感知质量和多样性，优于传统属性正则化和其他潜在约束架构。

Conclusion: 该方法首次展示了在多种音乐属性（如音符密度、音高范围、轮廓和节奏复杂性）上的通用性，为符号音乐生成提供了更精确的控制手段。

Abstract: Recent advances in latent diffusion models have demonstrated state-of-the-art
performance in high-dimensional time-series data synthesis while providing
flexible control through conditioning and guidance. However, existing
methodologies primarily rely on musical context or natural language as the main
modality of interacting with the generative process, which may not be ideal for
expert users who seek precise fader-like control over specific musical
attributes. In this work, we explore the application of denoising diffusion
processes as plug-and-play latent constraints for unconditional symbolic music
generation models. We focus on a framework that leverages a library of small
conditional diffusion models operating as implicit probabilistic priors on the
latents of a frozen unconditional backbone. While previous studies have
explored domain-specific use cases, this work, to the best of our knowledge, is
the first to demonstrate the versatility of such an approach across a diverse
array of musical attributes, such as note density, pitch range, contour, and
rhythm complexity. Our experiments show that diffusion-driven constraints
outperform traditional attribute regularization and other latent constraints
architectures, achieving significantly stronger correlations between target and
generated attributes while maintaining high perceptual quality and diversity.

</details>


### [405] [Guiding Generative Models to Uncover Diverse and Novel Crystals via Reinforcement Learning](https://arxiv.org/abs/2511.07158)
*Hyunsoo Park,Aron Walsh*

Main category: cs.LG

TL;DR: 提出强化学习框架指导扩散模型生成新颖且热力学稳定的晶体材料，解决生成模型与目标探索区域之间的目标错位问题


<details>
  <summary>Details</summary>
Motivation: 传统生成模型基于似然采样与目标探索新颖化合物区域之间存在目标错位，需要开发能够平衡创造性和稳定性的可控生成方法

Method: 结合群相对策略优化和可验证的多目标奖励函数的强化学习框架，指导潜在去噪扩散模型生成多样化、新颖且热力学可行的晶体化合物

Result: 实现了增强的属性引导设计，在保持化学有效性的同时靶向所需功能特性，建立了可控AI驱动逆向设计的模块化基础

Conclusion: 该方法为生成模型在科学发现应用中解决新颖性-有效性权衡问题提供了有效解决方案

Abstract: Discovering functional crystalline materials entails navigating an immense
combinatorial design space. While recent advances in generative artificial
intelligence have enabled the sampling of chemically plausible compositions and
structures, a fundamental challenge remains: the objective misalignment between
likelihood-based sampling in generative modelling and targeted focus on
underexplored regions where novel compounds reside. Here, we introduce a
reinforcement learning framework that guides latent denoising diffusion models
toward diverse and novel, yet thermodynamically viable crystalline compounds.
Our approach integrates group relative policy optimisation with verifiable,
multi-objective rewards that jointly balance creativity, stability, and
diversity. Beyond de novo generation, we demonstrate enhanced property-guided
design that preserves chemical validity, while targeting desired functional
properties. This approach establishes a modular foundation for controllable
AI-driven inverse design that addresses the novelty-validity trade-off across
scientific discovery applications of generative models.

</details>


### [406] [LLMscape](https://arxiv.org/abs/2511.07161)
*Gottfried Haider,Jie Zhang*

Main category: cs.LG

TL;DR: LLMscape是一个互动装置，探索人类和AI在共享不确定性条件下如何构建意义。通过可变的投影映射景观，人类参与者重塑世界并与多个AI代理互动，每个代理都对其环境形成不完整和临时的理解。


<details>
  <summary>Details</summary>
Motivation: 研究人类和AI在不确定性条件下的意义构建过程，将AI定位为具有身体性的共同见证者而非确定性工具，探索人类与人工意义创造的相似性。

Method: 创建可变的投影映射景观装置，让人类参与者与多个AI代理在共享环境中互动，每个AI代理都基于有限信息形成对环境的临时理解。

Result: 该作品在上海展出并持续演化，展示了人类和AI如何在不确定环境中共同构建意义，揭示了人类与人工系统在认知限制上的相似性。

Conclusion: LLMscape将AI定位为不稳定世界的共同见证者，邀请人们反思我们共享的认知限制，强调了人类与AI在意义构建过程中的相似性和相互影响。

Abstract: LLMscape is an interactive installation that investigates how humans and AI
construct meaning under shared conditions of uncertainty. Within a mutable,
projection-mapped landscape, human participants reshape the world and engage
with multiple AI agents, each developing incomplete and provisional accounts of
their environment. Exhibited in Shanghai and continually evolving, the work
positions AI not as deterministic tools but as embodied co-witnesses to an
unstable world, examining the parallels between human and artificial
meaning-making and inviting reflection on our shared epistemic limits.

</details>


### [407] [Combining digital data streams and epidemic networks for real time outbreak detection](https://arxiv.org/abs/2511.07163)
*Ruiqi Lyu,Alistair Turcan,Bryan Wilder*

Main category: cs.LG

TL;DR: LRTrend是一个可解释的机器学习框架，通过聚合多源健康和行为数据来实时识别疾病爆发，能够在疫情早期阶段（2周内）有效检测区域疫情波峰。


<details>
  <summary>Details</summary>
Motivation: 疾病爆发监测受限于流行病时间序列的高噪声，而跨数据源的信息聚合方法在其他领域已展现强大去噪能力，但在流行病学中尚未充分探索。

Method: LRTrend框架在一个区域内聚合多样化的健康和行为数据流，并学习疾病特定的流行病网络来跨区域聚合信息。

Result: 在美国305个医院转诊区域应用LRTrend分析2年COVID-19数据，发现与常用人类移动网络解释不同的流行病集群和连接，并能在Delta和Omicron波峰开始的2周内检测到疫情。

Conclusion: LRTrend能够有效识别疫情爆发，揭示的流行病集群和连接可能为未来公共卫生协调提供信息。

Abstract: Responding to disease outbreaks requires close surveillance of their
trajectories, but outbreak detection is hindered by the high noise in epidemic
time series. Aggregating information across data sources has shown great
denoising ability in other fields, but remains underexplored in epidemiology.
Here, we present LRTrend, an interpretable machine learning framework to
identify outbreaks in real time. LRTrend effectively aggregates diverse health
and behavioral data streams within one region and learns disease-specific
epidemic networks to aggregate information across regions. We reveal diverse
epidemic clusters and connections across the United States that are not well
explained by commonly used human mobility networks and may be informative for
future public health coordination. We apply LRTrend to 2 years of COVID-19 data
in 305 hospital referral regions and frequently detect regional Delta and
Omicron waves within 2 weeks of the outbreak's start, when case counts are a
small fraction of the wave's resulting peak.

</details>


### [408] [Fuzzy Label: From Concept to Its Application in Label Learning](https://arxiv.org/abs/2511.07165)
*Chenxi Luoa,Zhuangzhuang Zhaoa,Zhaohong Denga,Te Zhangb*

Main category: cs.LG

TL;DR: 提出模糊标签概念以克服传统二元逻辑标签在表示不确定性方面的局限性，通过模糊集理论增强标签学习模型的表达能力


<details>
  <summary>Details</summary>
Motivation: 传统标签学习方法使用二元逻辑标签（如"是/否"）无法有效处理实际应用中由于数据噪声、实体模糊性和标注者主观性带来的标签不确定性，限制了模型的表达能力

Method: 基于模糊集理论提出模糊标签概念，开发高效的模糊标签生成方法从原始数据中挖掘生成模糊标签，并以KNN和多标签KNN算法为例构建模糊标签增强的标签学习算法

Result: 实验结果表明模糊标签能更有效地表征真实世界的标注信息，显著提升标签学习模型的性能

Conclusion: 模糊标签能够更好地捕捉和表示标签不确定性，为标签学习提供了更丰富和细致的信息表示，显著提升了模型性能

Abstract: Label learning is a fundamental task in machine learning that aims to
construct intelligent models using labeled data, encompassing traditional
single-label and multi-label classification models. Traditional methods
typically rely on logical labels, such as binary indicators (e.g., "yes/no")
that specify whether an instance belongs to a given category. However, in
practical applications, label annotations often involve significant uncertainty
due to factors such as data noise, inherent ambiguity in the observed entities,
and the subjectivity of human annotators. Therefore, representing labels using
simplistic binary logic can obscure valuable information and limit the
expressiveness of label learning models. To overcome this limitation, this
paper introduces the concept of fuzzy labels, grounded in fuzzy set theory, to
better capture and represent label uncertainty. We further propose an efficient
fuzzy labeling method that mines and generates fuzzy labels from the original
data, thereby enriching the label space with more informative and nuanced
representations. Based on this foundation, we present fuzzy-label-enhanced
algorithms for both single-label and multi-label learning, using the classical
K-Nearest Neighbors (KNN) and multi-label KNN algorithms as illustrative
examples. Experimental results indicate that fuzzy labels can more effectively
characterize the real-world labeling information and significantly enhance the
performance of label learning models.

</details>


### [409] [On Stealing Graph Neural Network Models](https://arxiv.org/abs/2511.07170)
*Marcin Podhajski,Jan Dubiński,Franziska Boenisch,Adam Dziedzic,Agnieszka Pręgowska,Tomasz P. Michalak*

Main category: cs.LG

TL;DR: 提出一种在严格查询限制下仍能有效窃取图神经网络模型的方法，无需直接查询受害者模型即可获取模型骨干，并策略性地利用有限查询提取最有效信息


<details>
  <summary>Details</summary>
Motivation: 现有GNN模型窃取方法严重依赖对受害者模型的查询，假设没有硬性查询限制，但现实中允许的查询数量可能严重受限

Method: 首先让攻击者无需直接查询受害者模型即可获取模型骨干，然后策略性地利用固定查询限制提取最具信息量的数据

Result: 在八个真实世界数据集上的实验证明，即使在非常严格的查询限制和存在模型提取防御措施的情况下，攻击仍然有效

Conclusion: 研究结果强调了需要针对GNN模型提取威胁开发更强大的防御措施

Abstract: Current graph neural network (GNN) model-stealing methods rely heavily on
queries to the victim model, assuming no hard query limits. However, in
reality, the number of allowed queries can be severely limited. In this paper,
we demonstrate how an adversary can extract the GNN with very limited
interactions with the model. Our approach first enables the adversary to obtain
the model backbone without making direct queries to the victim model and then
to strategically utilize a fixed query limit to extract the most informative
data. The experiments on eight real-world datasets demonstrate the
effectiveness of the attack, even under a very restricted query limit and under
defense against model extraction in place. Our findings underscore the need for
robust defenses against GNN model extraction threats.

</details>


### [410] [Synergy over Discrepancy: A Partition-Based Approach to Multi-Domain LLM Fine-Tuning](https://arxiv.org/abs/2511.07198)
*Hua Ye,Siyuan Chen,Haoliang Zhang,Weihao Luo,Yanbin Li,Xuan Zhang*

Main category: cs.LG

TL;DR: 提出了一种基于分区的多阶段微调框架，通过平衡领域差异、协同效应和模型容量约束来优化LLM在多异构领域的适应能力


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在多个异构领域适应时面临的领域间干扰问题，利用领域间协同效应同时最小化负迁移

Method: 将领域划分为子集（阶段），通过平衡领域差异、协同效应和模型容量约束的策略性分区方法，并进行理论分析和泛化边界推导

Result: 在各种语言理解任务上的广泛实证评估表明，该方法始终优于最先进的基线方法

Conclusion: 提出的分区多阶段微调框架能够有效利用领域间协同效应，减少负迁移，在多领域适应任务中表现出优越性能

Abstract: Large language models (LLMs) demonstrate impressive generalization abilities,
yet adapting them effectively across multiple heterogeneous domains remains
challenging due to inter-domain interference. To overcome this challenge, we
propose a partition-based multi-stage fine-tuning framework designed to exploit
inter-domain synergies while minimizing negative transfer. Our approach
strategically partitions domains into subsets (stages) by balancing domain
discrepancy, synergy, and model capacity constraints. We theoretically analyze
the proposed framework and derive novel generalization bounds that justify our
partitioning strategy. Extensive empirical evaluations on various language
understanding tasks show that our method consistently outperforms
state-of-the-art baselines.

</details>


### [411] [SMiLE: Provably Enforcing Global Relational Properties in Neural Networks](https://arxiv.org/abs/2511.07208)
*Matteo Francobaldi,Michele Lombardi,Andrea Lodi*

Main category: cs.LG

TL;DR: SMiLE框架扩展支持全局关系属性，为神经网络提供全保证的属性执行方法


<details>
  <summary>Details</summary>
Motivation: AI系统部署需要确保鲁棒性、公平性等属性，但现有方法局限于特定约束或局部属性，缺乏全局属性保证

Method: 扩展SMiLE框架以支持全局关系属性，该方法可适应通用属性和网络架构，提供完全满足保证

Result: 在单调性、全局鲁棒性和个体公平性等任务上验证，在准确性和运行时与专用基线竞争，在通用性和保证级别上更优

Conclusion: SMiLE框架作为未来研究和应用的平台具有巨大潜力

Abstract: Artificial Intelligence systems are increasingly deployed in settings where
ensuring robustness, fairness, or domain-specific properties is essential for
regulation compliance and alignment with human values. However, especially on
Neural Networks, property enforcement is very challenging, and existing methods
are limited to specific constraints or local properties (defined around
datapoints), or fail to provide full guarantees. We tackle these limitations by
extending SMiLE, a recently proposed enforcement framework for NNs, to support
global relational properties (defined over the entire input space). The
proposed approach scales well with model complexity, accommodates general
properties and backbones, and provides full satisfaction guarantees. We
evaluate SMiLE on monotonicity, global robustness, and individual fairness, on
synthetic and real data, for regression and classification tasks. Our approach
is competitive with property-specific baselines in terms of accuracy and
runtime, and strictly superior in terms of generality and level of guarantees.
Overall, our results emphasize the potential of the SMiLE framework as a
platform for future research and applications.

</details>


### [412] [DETECT: Data-Driven Evaluation of Treatments Enabled by Classification Transformers](https://arxiv.org/abs/2511.07213)
*Yuanheng Mao,Lillian Yang,Stephen Yang,Ethan Shao,Zihan Li*

Main category: cs.LG

TL;DR: DETECT是一个数据驱动的框架，通过比较患者治疗前后的日常生活活动来评估治疗效果，使用智能手机传感器数据，为临床决策提供客观轻量的评估工具。


<details>
  <summary>Details</summary>
Motivation: 慢性疼痛是全球健康挑战，传统的主观评估方法（如数字评分量表）存在局限性，需要更客观的功能影响评估方法来支持临床治疗决策。

Method: 提出DETECT框架，利用分类变换器对患者治疗前后的日常生活活动数据进行对比分析，使用公开基准数据集和智能手机传感器模拟的患者数据。

Result: DETECT被证明是客观且轻量的，能够显著改善临床决策，可以单独使用或与其他自我报告指标结合使用。

Conclusion: DETECT为医生提供了更好的治疗影响理解工具，有助于实现更个性化和响应性的患者护理，是临床决策支持的重要创新。

Abstract: Chronic pain is a global health challenge affecting millions of individuals,
making it essential for physicians to have reliable and objective methods to
measure the functional impact of clinical treatments. Traditionally used
methods, like the numeric rating scale, while personalized and easy to use, are
subjective due to their self-reported nature. Thus, this paper proposes DETECT
(Data-Driven Evaluation of Treatments Enabled by Classification Transformers),
a data-driven framework that assesses treatment success by comparing patient
activities of daily life before and after treatment. We use DETECT on public
benchmark datasets and simulated patient data from smartphone sensors. Our
results demonstrate that DETECT is objective yet lightweight, making it a
significant and novel contribution to clinical decision-making. By using
DETECT, independently or together with other self-reported metrics, physicians
can improve their understanding of their treatment impacts, ultimately leading
to more personalized and responsive patient care.

</details>


### [413] [Deep Neural Operator Learning for Probabilistic Models](https://arxiv.org/abs/2511.07235)
*Erhan Bayraktar,Qi Feng,Zecheng Zhang,Zhaoyu Zhang*

Main category: cs.LG

TL;DR: 本文提出了一个深度神经算子框架用于概率模型，建立了在全局Lipschitz条件下的通用逼近定理，并在欧式和美式期权定价问题中验证了该框架的有效性。


<details>
  <summary>Details</summary>
Motivation: 为解决概率模型中的算子逼近问题，特别是在金融衍生品定价等应用中，需要一种能够处理广泛概率模型的通用神经网络架构。

Method: 提出深度神经算子框架，在全局Lipschitz条件下建立通用逼近定理，要求随机过程满足可积性和尾部概率条件，并在FBSDE框架下验证欧式和美式期权定价问题。

Result: 理论分析证明了网络规模界限的显式表达，数值实验表明学习到的模型能够为新的执行价格生成最优停止边界而无需重新训练。

Conclusion: 该框架为抛物型PDE相关的算子提供了有效的神经网络逼近方法，特别适用于美式期权等具有自由边界的问题。

Abstract: We propose a deep neural-operator framework for a general class of
probability models. Under global Lipschitz conditions on the operator over the
entire Euclidean space-and for a broad class of probabilistic models-we
establish a universal approximation theorem with explicit network-size bounds
for the proposed architecture. The underlying stochastic processes are required
only to satisfy integrability and general tail-probability conditions. We
verify these assumptions for both European and American option-pricing problems
within the forward-backward SDE (FBSDE) framework, which in turn covers a broad
class of operators arising from parabolic PDEs, with or without free
boundaries. Finally, we present a numerical example for a basket of American
options, demonstrating that the learned model produces optimal stopping
boundaries for new strike prices without retraining.

</details>


### [414] [Does TabPFN Understand Causal Structures?](https://arxiv.org/abs/2511.07236)
*Omar Swelam,Lennart Purucker,Jake Robertson,Hanne Raum,Joschka Boedecker,Frank Hutter*

Main category: cs.LG

TL;DR: TabPFN（基于Transformer的表格基础模型）的嵌入中包含因果信息，通过适配器框架提取后可用于因果发现，性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 因果发现对多个科学领域至关重要，但如何从真实世界数据中提取因果信息仍是一个挑战。TabPFN在合成数据集上预训练后，其内部表示是否编码了因果信息值得研究。

Method: 开发了一个适配器框架，使用可学习解码器和因果标记，从TabPFN的冻结嵌入中提取因果信号，并将其解码为因果发现的邻接矩阵。

Result: 评估表明TabPFN的嵌入确实包含因果信息，性能优于几种传统因果发现算法，且因果信息主要集中在中层网络层。

Conclusion: 这些发现为基础模型的可解释性和适应性开辟了新方向，展示了利用预训练表格模型进行因果发现的潜力。

Abstract: Causal discovery is fundamental for multiple scientific domains, yet
extracting causal information from real world data remains a significant
challenge. Given the recent success on real data, we investigate whether
TabPFN, a transformer-based tabular foundation model pre-trained on synthetic
datasets generated from structural causal models, encodes causal information in
its internal representations. We develop an adapter framework using a learnable
decoder and causal tokens that extract causal signals from TabPFN's frozen
embeddings and decode them into adjacency matrices for causal discovery. Our
evaluations demonstrate that TabPFN's embeddings contain causal information,
outperforming several traditional causal discovery algorithms, with such causal
information being concentrated in mid-range layers. These findings establish a
new direction for interpretable and adaptable foundation models and demonstrate
the potential for leveraging pre-trained tabular models for causal discovery.

</details>


### [415] [The Few Govern the Many:Unveiling Few-Layer Dominance for Time Series Models](https://arxiv.org/abs/2511.07237)
*Xin Qiu,Junlong Tong,Yirong Sun,Yunpu Ma,Xiaoyu Shen*

Main category: cs.LG

TL;DR: 本文发现时间序列预测模型存在"规模悖论"——模型规模增大反而性能下降，并揭示了"少数层主导"现象，提出了一种自动识别和保留关键层的方法，大幅提升效率和性能。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为扩大模型容量和数据规模能提升时间序列预测性能，但作者观察到实际存在规模悖论，即更大模型反而表现更差，需要探究其根本原因并找到解决方案。

Method: 通过分析四个规模等级（100M到1.7B参数）的模型内部表示，发现少数层主导现象，提出自动识别功能重要层的方法，仅保留这些关键层来构建更高效的模型。

Result: 实验表明仅保留21%参数就能实现12%精度提升和2.7倍推理加速，在8个SOTA模型上验证了方法的普适性，95%任务中保留不到30%层就能达到相当或更优精度。

Conclusion: 时间序列预测模型的规模悖论源于层冗余问题，通过识别和保留少数关键层可以显著提升模型效率和性能，这一发现对大规模时间序列模型设计具有重要指导意义。

Abstract: Large-scale models are at the forefront of time series (TS) forecasting,
dominated by two paradigms: fine-tuning text-based Large Language Models
(LLM4TS) and training Time Series Foundation Models (TSFMs) from scratch. Both
approaches share a foundational assumption that scaling up model capacity and
data volume leads to improved performance. However, we observe a
\textit{\textbf{scaling paradox}} in TS models, revealing a puzzling phenomenon
that larger models do \emph{NOT} achieve better performance. Through extensive
experiments on two model families across four scales (100M to 1.7B parameters)
and diverse data (up to 6B observations), we rigorously confirm that the
scaling paradox is a pervasive issue. We then diagnose its root cause by
analyzing internal representations, identifying a phenomenon we call
\textit{few-layer dominance}: only a small subset of layers are functionally
important, while the majority are redundant, under-utilized, and can even
distract training. Based on this discovery, we propose a practical method to
automatically identify and retain only these dominant layers. In our models,
retaining only 21\% of the parameters achieves up to a 12\% accuracy
improvement and a 2.7$\times$ inference speedup. We validate the universality
of our method on 8 prominent SOTA models (LLM4TS and TSFMs, 90M to 6B), showing
that retaining less than 30\% of layers achieves comparable or superior
accuracy in over 95\% of tasks.

</details>


### [416] [Understanding the role of depth in the neural tangent kernel for overparameterized neural networks](https://arxiv.org/abs/2511.07272)
*William St-Arnaud,Margarida Carvalho,Golnoosh Farnadi*

Main category: cs.LG

TL;DR: 该论文分析了深度ReLU网络在过参数化情况下的极限行为，发现随着深度增加，归一化极限核趋近于全1矩阵，而对应的闭式解在球面上趋近于固定极限。


<details>
  <summary>Details</summary>
Motivation: 研究过参数化全连接神经网络在梯度下降训练下的极限行为，特别是深度增加对网络性能的影响，以及闭式解在深度变化时的收敛特性。

Method: 通过理论分析深度ReLU网络的极限核特性，使用归一化处理来研究深度增加时的核矩阵变化，并通过实证评估观察收敛行为所需的网络深度量级。

Result: 理论结果表明归一化极限核趋近于全1矩阵，闭式解在球面上趋近于固定极限。实证研究确定了观察到这种收敛行为所需的网络深度范围。

Conclusion: 深度ReLU网络在过参数化情况下具有明确的极限行为特征，这一发现为理解深度神经网络的理论性质提供了重要见解，并可推广到其他核函数。

Abstract: Overparameterized fully-connected neural networks have been shown to behave
like kernel models when trained with gradient descent, under mild conditions on
the width, the learning rate, and the parameter initialization. In the limit of
infinitely large widths and small learning rate, the kernel that is obtained
allows to represent the output of the learned model with a closed-form
solution. This closed-form solution hinges on the invertibility of the limiting
kernel, a property that often holds on real-world datasets. In this work, we
analyze the sensitivity of large ReLU networks to increasing depths by
characterizing the corresponding limiting kernel. Our theoretical results
demonstrate that the normalized limiting kernel approaches the matrix of ones.
In contrast, they show the corresponding closed-form solution approaches a
fixed limit on the sphere. We empirically evaluate the order of magnitude in
network depth required to observe this convergent behavior, and we describe the
essential properties that enable the generalization of our results to other
kernels.

</details>


### [417] [Multi-modal Dynamic Proxy Learning for Personalized Multiple Clustering](https://arxiv.org/abs/2511.07274)
*Jinfeng Xu,Zheyu Chen,Shuo Yang,Jinze Li,Ziyue Peng,Zewei Liu,Hewei Wang,Jiayi Zhang,Edith C. H. Ngai*

Main category: cs.LG

TL;DR: Multi-DProxy是一个多模态动态代理学习框架，通过可学习的文本代理实现跨模态对齐，解决了现有多聚类方法无法适应特定数据集概念和固定融合策略的问题。


<details>
  <summary>Details</summary>
Motivation: 现有多聚类方法生成大量聚类结果但无法识别用户兴趣，需要人工筛选；当前多模态解决方案存在静态语义刚性，预定义候选词无法适应数据集特定概念，固定融合策略忽略动态特征交互。

Method: 提出Multi-DProxy框架：1）门控跨模态融合，自适应建模特征交互合成判别性联合表示；2）双约束代理优化，用户兴趣约束确保语义一致性，概念约束通过困难样本挖掘增强聚类判别力；3）动态候选管理，通过迭代聚类反馈优化文本代理。

Result: 大量实验证明Multi-DProxy在多聚类基准测试中达到最先进性能，相比现有方法有显著改进。

Conclusion: Multi-DProxy不仅能有效通过代理捕获用户兴趣，还能以更高精度识别相关聚类，解决了多聚类中的语义适应性和动态交互问题。

Abstract: Multiple clustering aims to discover diverse latent structures from different
perspectives, yet existing methods generate exhaustive clusterings without
discerning user interest, necessitating laborious manual screening. Current
multi-modal solutions suffer from static semantic rigidity: predefined
candidate words fail to adapt to dataset-specific concepts, and fixed fusion
strategies ignore evolving feature interactions. To overcome these limitations,
we propose Multi-DProxy, a novel multi-modal dynamic proxy learning framework
that leverages cross-modal alignment through learnable textual proxies.
Multi-DProxy introduces 1) gated cross-modal fusion that synthesizes
discriminative joint representations by adaptively modeling feature
interactions. 2) dual-constraint proxy optimization where user interest
constraints enforce semantic consistency with domain concepts while concept
constraints employ hard example mining to enhance cluster discrimination. 3)
dynamic candidate management that refines textual proxies through iterative
clustering feedback. Therefore, Multi-DProxy not only effectively captures a
user's interest through proxies but also enables the identification of relevant
clusterings with greater precision. Extensive experiments demonstrate
state-of-the-art performance with significant improvements over existing
methods across a broad set of multi-clustering benchmarks.

</details>


### [418] [RobustA: Robust Anomaly Detection in Multimodal Data](https://arxiv.org/abs/2511.07276)
*Salem AlMarri,Muhammad Irzam Liaqat,Muhammad Zaigham Zaheer,Shah Nawaz,Karthik Nandakumar,Markus Schedl*

Main category: cs.LG

TL;DR: 该论文首次全面研究了模态损坏对多模态异常检测的负面影响，提出了包含损坏模态的评估数据集RobustA，并开发了一种具有抗损坏能力的多模态异常检测方法。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的多模态数据经常因环境干扰而损坏，但现有研究忽视了模态损坏对异常检测系统的影响，这限制了多模态异常检测在实际场景中的应用。

Method: 提出了一种多模态异常检测方法，通过学习不同模态的共享表示空间，并在推理时基于估计的损坏程度采用动态权重分配策略。

Result: 所提出的方法在面对损坏模态时表现出显著的鲁棒性，为多模态异常检测的实际应用提供了重要保障。

Conclusion: 这项工作推动了多模态异常检测在现实世界中的应用，解决了模态损坏可能发生的情况，相关数据集和特征将公开提供。

Abstract: In recent years, multimodal anomaly detection methods have demonstrated
remarkable performance improvements over video-only models. However, real-world
multimodal data is often corrupted due to unforeseen environmental distortions.
In this paper, we present the first-of-its-kind work that comprehensively
investigates the adverse effects of corrupted modalities on multimodal anomaly
detection task. To streamline this work, we propose RobustA, a carefully
curated evaluation dataset to systematically observe the impacts of audio and
visual corruptions on the overall effectiveness of anomaly detection systems.
Furthermore, we propose a multimodal anomaly detection method, which shows
notable resilience against corrupted modalities. The proposed method learns a
shared representation space for different modalities and employs a dynamic
weighting scheme during inference based on the estimated level of corruption.
Our work represents a significant step forward in enabling the real-world
application of multimodal anomaly detection, addressing situations where the
likely events of modality corruptions occur. The proposed evaluation dataset
with corrupted modalities and respective extracted features will be made
publicly available.

</details>


### [419] [MG-HGNN: A Heterogeneous GNN Framework for Indoor Wi-Fi Fingerprint-Based Localization](https://arxiv.org/abs/2511.07282)
*Yibu Wang,Zhaoxin Zhang,Ning Li,Xinlong Zhao,Dong Zhao,Tianzi Zhao*

Main category: cs.LG

TL;DR: 提出了一种多图异构图神经网络框架（MG-HGNN），用于提升Wi-Fi指纹室内定位的准确性，通过多类型任务导向的图构建和异构图神经网络结构来解决环境复杂性和多源信息处理挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的RSSI定位方法因环境复杂性和多源信息处理困难而导致定位精度下降，需要一种能够增强空间感知并提升定位性能的新方法。

Method: MG-HGNN框架包含两个图构建分支进行节点和边嵌入，生成信息丰富的图结构，然后使用异构图神经网络进行图表示学习，实现准确定位。关键创新包括多类型任务导向的图构建和异质GNN结构。

Result: 在UJIIndoorLoc和UTSIndoorLoc公开数据集上的评估表明，MG-HGNN不仅优于多种先进方法，还为基于GNN的定位方法提供了新视角。消融研究进一步验证了框架的合理性和有效性。

Conclusion: MG-HGNN框架通过创新的图构建和异质GNN结构，有效提升了室内定位性能，为相关领域提供了新的解决方案。

Abstract: Received signal strength indicator (RSSI) is the primary representation of
Wi-Fi fingerprints and serves as a crucial tool for indoor localization.
However, existing RSSI-based positioning methods often suffer from reduced
accuracy due to environmental complexity and challenges in processing
multi-source information. To address these issues, we propose a novel
multi-graph heterogeneous GNN framework (MG-HGNN) to enhance spatial awareness
and improve positioning performance. In this framework, two graph construction
branches perform node and edge embedding, respectively, to generate informative
graphs. Subsequently, a heterogeneous graph neural network is employed for
graph representation learning, enabling accurate positioning. The MG-HGNN
framework introduces the following key innovations: 1) multi-type task-directed
graph construction that combines label estimation and feature encoding for
richer graph information; 2) a heterogeneous GNN structure that enhances the
performance of conventional GNN models. Evaluations on the UJIIndoorLoc and
UTSIndoorLoc public datasets demonstrate that MG-HGNN not only achieves
superior performance compared to several state-of-the-art methods, but also
provides a novel perspective for enhancing GNN-based localization methods.
Ablation studies further confirm the rationality and effectiveness of the
proposed framework.

</details>


### [420] [Enabling Off-Policy Imitation Learning with Deep Actor Critic Stabilization](https://arxiv.org/abs/2511.07288)
*Sayambhu Sen,Shalabh Bhatnagar*

Main category: cs.LG

TL;DR: 提出一种结合离线学习的对抗性模仿学习算法，通过离线策略框架和辅助技术（双Q网络稳定化和无需奖励函数推断的价值学习）来提高样本效率。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习存在不稳定和收敛慢的问题，而最先进的模仿学习方法（如GAIL）由于基于在线策略算法导致样本效率低下。

Method: 采用离线学习框架，结合双Q网络稳定化技术和无需奖励函数推断的价值学习方法。

Result: 算法能够显著减少匹配专家行为所需的样本数量。

Conclusion: 该离线对抗模仿学习方法有效解决了样本效率问题，为复杂策略学习提供了更高效的解决方案。

Abstract: Learning complex policies with Reinforcement Learning (RL) is often hindered
by instability and slow convergence, a problem exacerbated by the difficulty of
reward engineering. Imitation Learning (IL) from expert demonstrations bypasses
this reliance on rewards. However, state-of-the-art IL methods, exemplified by
Generative Adversarial Imitation Learning (GAIL)Ho et. al, suffer from severe
sample inefficiency. This is a direct consequence of their foundational
on-policy algorithms, such as TRPO Schulman et.al. In this work, we introduce
an adversarial imitation learning algorithm that incorporates off-policy
learning to improve sample efficiency. By combining an off-policy framework
with auxiliary techniques specifically, double Q network based stabilization
and value learning without reward function inference we demonstrate a reduction
in the samples required to robustly match expert behavior.

</details>


### [421] [Can Training Dynamics of Scale-Invariant Neural Networks Be Explained by the Thermodynamics of an Ideal Gas?](https://arxiv.org/abs/2511.07308)
*Ildus Sadrtdinov,Ekaterina Lobacheva,Ivan Klimov,Mikhail I. Katsnelson,Dmitry Vetrov*

Main category: cs.LG

TL;DR: 本文提出了一种热力学框架来描述具有权重衰减的随机梯度下降（SGD）在尺度不变神经网络中的平稳分布，将训练超参数（如学习率、权重衰减）类比为温度、压力和体积等热力学变量。


<details>
  <summary>Details</summary>
Motivation: 理解深度神经网络的训练动态是一个重要的开放问题，物理启发的方法提供了有前景的见解。本文基于这一视角，旨在为尺度不变神经网络（反映具有归一化层的实际架构）的SGD训练动态提供理论分析框架。

Method: 开发热力学框架，首先在简化的各向同性噪声模型下建立SGD动态与理想气体行为之间的对应关系，并通过理论和模拟验证。然后将该框架扩展到神经网络训练，分析平稳熵等关键预测指标。

Result: 理论框架的关键预测（包括平稳熵的行为）与实验观察结果高度一致，验证了热力学类比的有效性。

Conclusion: 该框架为解释训练动态提供了原则性基础，可能指导未来超参数调整和学习率调度器的设计工作。

Abstract: Understanding the training dynamics of deep neural networks remains a major
open problem, with physics-inspired approaches offering promising insights.
Building on this perspective, we develop a thermodynamic framework to describe
the stationary distributions of stochastic gradient descent (SGD) with weight
decay for scale-invariant neural networks, a setting that both reflects
practical architectures with normalization layers and permits theoretical
analysis. We establish analogies between training hyperparameters (e.g.,
learning rate, weight decay) and thermodynamic variables such as temperature,
pressure, and volume. Starting with a simplified isotropic noise model, we
uncover a close correspondence between SGD dynamics and ideal gas behavior,
validated through theory and simulation. Extending to training of neural
networks, we show that key predictions of the framework, including the behavior
of stationary entropy, align closely with experimental observations. This
framework provides a principled foundation for interpreting training dynamics
and may guide future work on hyperparameter tuning and the design of learning
rate schedulers.

</details>


### [422] [Superhuman AI for Stratego Using Self-Play Reinforcement Learning and Test-Time Search](https://arxiv.org/abs/2511.07312)
*Samuel Sokota,Eugene Vinitsky,Hengyuan Hu,J. Zico Kolter,Gabriele Farina*

Main category: cs.LG

TL;DR: 该研究在Stratego游戏中实现了性能突破，仅用数千美元成本就达到了远超人类顶尖水平的AI表现，解决了传统方法需要数百万美元训练成本却无法达到人类顶级水平的问题。


<details>
  <summary>Details</summary>
Motivation: Stratego作为具有大量隐藏信息的战略决策游戏，一直是AI的重要基准测试，但之前的方法即使投入数百万美元训练成本也无法达到人类顶尖水平。

Method: 开发了自博弈强化学习和不完全信息下测试时搜索的通用方法。

Result: 不仅达到了人类顶尖水平，而且实现了远超人类的表现，同时将训练成本从数百万美元降低到数千美元。

Conclusion: Stratego游戏现在可以通过经济高效的方法实现超人类水平的AI性能，这为不完全信息游戏领域带来了重大突破。

Abstract: Few classical games have been regarded as such significant benchmarks of
artificial intelligence as to have justified training costs in the millions of
dollars. Among these, Stratego -- a board wargame exemplifying the challenge of
strategic decision making under massive amounts of hidden information -- stands
apart as a case where such efforts failed to produce performance at the level
of top humans. This work establishes a step change in both performance and cost
for Stratego, showing that it is now possible not only to reach the level of
top humans, but to achieve vastly superhuman level -- and that doing so
requires not an industrial budget, but merely a few thousand dollars. We
achieved this result by developing general approaches for self-play
reinforcement learning and test-time search under imperfect information.

</details>


### [423] [Q-RAG: Long Context Multi-step Retrieval via Value-based Embedder Training](https://arxiv.org/abs/2511.07328)
*Artyom Sorokin,Nazar Buzun,Alexander Anokhin,Oleg Inozemcev,Egor Vedernikov,Petr Anokhin,Mikhail Burtsev,Trushkov Alexey,Yin Wenshuai,Evgeny Burnaev*

Main category: cs.LG

TL;DR: Q-RAG提出了一种基于强化学习微调嵌入模型的多步检索方法，相比传统方法更高效且能利用更大模型，在长文本问答任务上达到SOTA效果。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法多为单步检索，难以处理复杂问题；多步检索方法通常需要微调小模型，资源消耗大且无法使用大模型。

Method: 使用强化学习微调嵌入模型实现多步检索，提供资源高效的替代方案。

Result: 在Babilong和RULER等长文本基准测试中（上下文达1000万tokens）取得最优结果。

Conclusion: Q-RAG为多步检索提供了一种竞争性强且资源效率高的解决方案。

Abstract: Retrieval-Augmented Generation (RAG) methods enhance LLM performance by
efficiently filtering relevant context for LLMs, reducing hallucinations and
inference cost. However, most existing RAG methods focus on single-step
retrieval, which is often insufficient for answering complex questions that
require multi-step search. Recently, multi-step retrieval approaches have
emerged, typically involving the fine-tuning of small LLMs to perform
multi-step retrieval. This type of fine-tuning is highly resource-intensive and
does not enable the use of larger LLMs. In this work, we propose Q-RAG, a novel
approach that fine-tunes the Embedder model for multi-step retrieval using
reinforcement learning (RL). Q-RAG offers a competitive, resource-efficient
alternative to existing multi-step retrieval methods for open-domain question
answering and achieves state-of-the-art results on the popular long-context
benchmarks Babilong and RULER for contexts up to 10M tokens.

</details>


### [424] [Preparation of Fractal-Inspired Computational Architectures for Advanced Large Language Model Analysis](https://arxiv.org/abs/2511.07329)
*Yash Mittal,Dmitry Ignatov,Radu Timofte*

Main category: cs.LG

TL;DR: FractalNet是一种基于分形结构的计算架构，用于高效大规模探索神经网络架构多样性，通过模板化生成器创建1200多种网络变体。


<details>
  <summary>Details</summary>
Motivation: 挑战大规模模型多样性问题，通过分形设计实现高效自动化的架构探索。

Method: 使用模板驱动的生成器、运行器和评估框架，系统性地对卷积、归一化、激活和dropout层进行排列组合，创建分形模板支持结构递归和多列路径。

Result: 在CIFAR-10数据集上训练5个epoch，分形架构展现出强大性能和计算效率。

Conclusion: 分形设计是一种可行且资源高效的自动化架构探索方法。

Abstract: It introduces FractalNet, a fractal-inspired computational architectures for
advanced large language model analysis that mainly challenges model diversity
on a large scale in an efficient manner. The new set-up involves a
template-driven generator, runner, and evaluation framework that, through
systematic permutations of convolutional, normalization, activation, and
dropout layers, can create more than 1,200 variants of neural networks. Fractal
templates allow for structural recursion and multi-column pathways, thus,
models become deeper and wider in a balanced way. Training utilizes PyTorch,
Automatic Mixed Precision (AMP), and gradient checkpointing and is carried out
on the CIFAR-10 dataset for five epochs. The outcomes show that fractal-based
architectures are capable of strong performance and are computationally
efficient. The paper positions fractal design as a feasible and
resource-efficient method of automated architecture exploration.

</details>


### [425] [Grounding Computer Use Agents on Human Demonstrations](https://arxiv.org/abs/2511.07332)
*Aarash Feizi,Shravan Nayak,Xiangru Jian,Kevin Qinghong Lin,Kaixin Li,Rabiul Awal,Xing Han Lù,Johan Obando-Ceron,Juan A. Rodriguez,Nicolas Chapados,David Vazquez,Adriana Romero-Soriano,Reihaneh Rabbany,Perouz Taslakian,Christopher Pal,Spandana Gella,Sai Rajeswar*

Main category: cs.LG

TL;DR: 论文提出了GroundCUA数据集和GroundNext模型，解决了桌面环境中自然语言指令与UI元素准确连接的问题，在少量训练数据下实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 构建可靠的计算机使用代理需要准确的指令-界面元素连接（grounding），但现有高质量桌面环境数据集有限，需要填补这一空白。

Method: 从专家人类演示构建大规模桌面grounding数据集GroundCUA，包含87个应用的56K截图和356万标注；基于此训练GroundNext模型家族，采用监督微调和强化学习后训练。

Result: GroundNext在3B和7B规模下，在五个基准测试中均达到SOTA，仅需不到先前工作十分之一的训练数据；在OSWorld基准测试中与使用更多数据训练的模型性能相当或更优。

Conclusion: 高质量、专家驱动的数据集在推进通用计算机使用代理发展中起着关键作用。

Abstract: Building reliable computer-use agents requires grounding: accurately
connecting natural language instructions to the correct on-screen elements.
While large datasets exist for web and mobile interactions, high-quality
resources for desktop environments are limited. To address this gap, we
introduce GroundCUA, a large-scale desktop grounding dataset built from expert
human demonstrations. It covers 87 applications across 12 categories and
includes 56K screenshots, with every on-screen element carefully annotated for
a total of over 3.56M human-verified annotations. From these demonstrations, we
generate diverse instructions that capture a wide range of real-world tasks,
providing high-quality data for model training. Using GroundCUA, we develop the
GroundNext family of models that map instructions to their target UI elements.
At both 3B and 7B scales, GroundNext achieves state-of-the-art results across
five benchmarks using supervised fine-tuning, while requiring less than
one-tenth the training data of prior work. Reinforcement learning post-training
further improves performance, and when evaluated in an agentic setting on the
OSWorld benchmark using o3 as planner, GroundNext attains comparable or
superior results to models trained with substantially more data,. These results
demonstrate the critical role of high-quality, expert-driven datasets in
advancing general-purpose computer-use agents.

</details>


### [426] [TNT: Improving Chunkwise Training for Test-Time Memorization](https://arxiv.org/abs/2511.07343)
*Zeman Li,Ali Behrouz,Yuan Deng,Peilin Zhong,Praneeth Kacham,Mahdi Karami,Meisam Razaviyayn,Vahab Mirrokni*

Main category: cs.LG

TL;DR: TNT是一种新的训练范式，通过两阶段过程解决深度测试时记忆RNN的训练效率问题，在保持性能的同时实现17倍训练加速


<details>
  <summary>Details</summary>
Motivation: 现有的深度测试时记忆RNN（如Titans和TTT）具有线性扩展优势，但训练速度极慢且硬件利用率低。现有并行化方法存在块大小权衡冲突：大块提升速度但降低性能，小块保持性能但训练缓慢

Method: TNT采用两阶段训练：第一阶段是效率导向的预训练，使用分层内存架构，全局模块处理大块长距离上下文，多个并行局部模块处理细粒度细节，通过定期重置局部内存状态打破顺序依赖实现并行化；第二阶段是简短微调，仅调整局部内存模块到小块大小以最大化精度

Result: 在Titans和TTT模型上评估，TNT实现了高达17倍的训练加速，同时提高了模型精度

Conclusion: TNT消除了深度测试时记忆RNN的关键可扩展性障碍，为开发表达性RNN奠定了实用基础，有助于未来缩小与Transformer的性能差距

Abstract: Recurrent neural networks (RNNs) with deep test-time memorization modules,
such as Titans and TTT, represent a promising, linearly-scaling paradigm
distinct from Transformers. While these expressive models do not yet match the
peak performance of state-of-the-art Transformers, their potential has been
largely untapped due to prohibitively slow training and low hardware
utilization. Existing parallelization methods force a fundamental conflict
governed by the chunksize hyperparameter: large chunks boost speed but degrade
performance, necessitating a fixed, suboptimal compromise. To solve this
challenge, we introduce TNT, a novel training paradigm that decouples training
efficiency from inference performance through a two-stage process. Stage one is
an efficiency-focused pre-training phase utilizing a hierarchical memory. A
global module processes large, hardware-friendly chunks for long-range context,
while multiple parallel local modules handle fine-grained details. Crucially,
by periodically resetting local memory states, we break sequential dependencies
to enable massive context parallelization. Stage two is a brief fine-tuning
phase where only the local memory modules are adapted to a smaller,
high-resolution chunksize, maximizing accuracy with minimal overhead. Evaluated
on Titans and TTT models, TNT achieves a substantial acceleration in training
speed-up to 17 times faster than the most accurate baseline configuration -
while simultaneously improving model accuracy. This improvement removes a
critical scalability barrier, establishing a practical foundation for
developing expressive RNNs and facilitating future work to close the
performance gap with Transformers.

</details>


### [427] [Self-Evaluating LLMs for Multi-Step Tasks: Stepwise Confidence Estimation for Failure Detection](https://arxiv.org/abs/2511.07364)
*Vaibhav Mavi,Shubh Jaroria,Weiqi Sun*

Main category: cs.LG

TL;DR: 该研究将LLM自我评估技术扩展到多步推理任务，比较了整体评分和逐步评分两种方法，发现逐步评估在错误检测方面表现更好。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多步推理任务中的可靠性至关重要，但现有方法主要关注单步输出，忽视了多步推理的挑战。

Method: 在两种多步基准数据集上测试了整体评分和逐步评分两种直观方法，通过比较它们在错误检测方面的性能。

Result: 逐步评估通常优于整体评分，在AUC-ROC指标上相对提高了15%，能够有效检测潜在错误。

Conclusion: 自我评估的LLM系统能够为复杂推理提供有意义的置信度估计，提高了模型的可信度，并为失败检测提供了实用框架。

Abstract: Reliability and failure detection of large language models (LLMs) is critical
for their deployment in high-stakes, multi-step reasoning tasks. Prior work
explores confidence estimation for self-evaluating LLM-scorer systems, with
confidence scorers estimating the likelihood of errors in LLM responses.
However, most methods focus on single-step outputs and overlook the challenges
of multi-step reasoning. In this work, we extend self-evaluation techniques to
multi-step tasks, testing two intuitive approaches: holistic scoring and
step-by-step scoring. Using two multi-step benchmark datasets, we show that
stepwise evaluation generally outperforms holistic scoring in detecting
potential errors, with up to 15% relative increase in AUC-ROC. Our findings
demonstrate that self-evaluating LLM systems provide meaningful confidence
estimates in complex reasoning, improving their trustworthiness and providing a
practical framework for failure detection.

</details>


### [428] [Private Sketches for Linear Regression](https://arxiv.org/abs/2511.07365)
*Shrutimoy Das,Debanuj Nayak,Anirban Dasgupta*

Main category: cs.LG

TL;DR: 提出了一种用于线性回归的差分隐私草图方法，通过发布数据集的隐私保护摘要而非噪声参数向量，来解决敏感数据统计分析中的隐私泄露问题。


<details>
  <summary>Details</summary>
Motivation: 线性回归广泛应用于各个领域，但某些领域包含敏感数据，需要在不泄露隐私信息的前提下应用统计方法。现有的差分隐私线性回归方法通常通过估计带噪声的参数向量来缓解隐私问题，但这种方法存在局限性。

Method: 提出差分隐私草图方法，为最小二乘回归和最小绝对偏差回归问题生成隐私保护的数据集摘要。这些私有草图便于应用常用的回归求解器，同时避免隐私泄露风险。

Result: 开发了针对最小二乘回归和最小绝对偏差回归的差分隐私草图技术，能够有效保护敏感数据隐私。

Conclusion: 通过发布私有草图而非噪声参数向量，该方法为敏感数据的线性回归分析提供了更安全有效的隐私保护解决方案，便于实际应用中的回归求解器使用。

Abstract: Linear regression is frequently applied in a variety of domains. In order to
improve the efficiency of these methods, various methods have been developed
that compute summaries or \emph{sketches} of the datasets. Certain domains,
however, contain sensitive data which necessitates that the application of
these statistical methods does not reveal private information. Differentially
private (DP) linear regression methods have been developed for mitigating this
problem. These techniques typically involve estimating a noisy version of the
parameter vector. Instead, we propose releasing private sketches of the
datasets. We present differentially private sketches for the problems of least
squares regression, as well as least absolute deviations regression. The
availability of these private sketches facilitates the application of commonly
available solvers for regression, without the risk of privacy leakage.

</details>


### [429] [Consistency Is Not Always Correct: Towards Understanding the Role of Exploration in Post-Training Reasoning](https://arxiv.org/abs/2511.07368)
*Dake Bu,Wei Huang,Andi Han,Atsushi Nitanda,Bo Xue,Qingfu Zhang,Hau-San Wong,Taiji Suzuki*

Main category: cs.LG

TL;DR: 本文通过多任务树状马尔可夫链模型解释了基础模型后训练中的探索悖论：RLVR和ORM/PRM会强化现有推理路径而非扩展推理范围，但探索仍至关重要，因为它保留了解决困难问题所需的罕见推理路径。


<details>
  <summary>Details</summary>
Motivation: 解决基础模型后训练中的探索悖论——尽管RLVR和ORM/PRM通常强化现有推理路径而非扩展推理范围，但实证显示探索仍能提升性能，需要理论解释这一现象。

Method: 采用多任务树状马尔可夫链模型，将预训练视为树扩展，后训练视为思维链重加权，理论分析RLVR、ORM/PRM和探索策略的动态效应。

Result: 理论分析揭示：(1)RLVR会挤压推理熵，遗忘正确路径；(2)ORM/PRM鼓励一致性而非准确性；(3)基础模型的罕见高不确定性推理路径对解决困难问题至关重要。

Conclusion: 探索之所以重要，是因为它保留了被RLVR挤压或被推理缩放忽略的罕见但关键的推理路径，这些路径对解决困难问题实例至关重要。

Abstract: Foundation models exhibit broad knowledge but limited task-specific
reasoning, motivating post-training strategies such as RLVR and inference
scaling with outcome or process reward models (ORM/PRM). While recent work
highlights the role of exploration and entropy stability in improving pass@K,
empirical evidence points to a paradox: RLVR and ORM/PRM typically reinforce
existing tree-like reasoning paths rather than expanding the reasoning scope,
raising the question of why exploration helps at all if no new patterns emerge.
  To reconcile this paradox, we adopt the perspective of Kim et al. (2025),
viewing easy (e.g., simplifying a fraction) versus hard (e.g., discovering a
symmetry) reasoning steps as low- versus high-probability Markov transitions,
and formalize post-training dynamics through Multi-task Tree-structured Markov
Chains (TMC). In this tractable model, pretraining corresponds to tree
expansion, while post-training corresponds to chain-of-thought reweighting. We
show that several phenomena recently observed in empirical studies arise
naturally in this setting: (1) RLVR induces a squeezing effect, reducing
reasoning entropy and forgetting some correct paths; (2) population rewards of
ORM/PRM encourage consistency rather than accuracy, thereby favoring common
patterns; and (3) certain rare, high-uncertainty reasoning paths by the base
model are responsible for solving hard problem instances.
  Together, these explain why exploration -- even when confined to the base
model's reasoning scope -- remains essential: it preserves access to rare but
crucial reasoning traces needed for difficult cases, which are squeezed out by
RLVR or unfavored by inference scaling. Building on this, we further show that
exploration strategies such as rejecting easy instances and KL regularization
help preserve rare reasoning traces. Empirical simulations corroborate our
theoretical results.

</details>


### [430] [Provable Benefit of Curriculum in Transformer Tree-Reasoning Post-Training](https://arxiv.org/abs/2511.07372)
*Dake Bu,Wei Huang,Andi Han,Atsushi Nitanda,Hau-San Wong,Qingfu Zhang,Taiji Suzuki*

Main category: cs.LG

TL;DR: 该论文提出了一个理论框架来解释为什么课程学习在LLM后训练阶段能提升推理性能，证明了在适当复杂度条件下，课程学习能避免指数级复杂度瓶颈。


<details>
  <summary>Details</summary>
Motivation: 理解课程学习技术为何以及多大程度上优于非课程方法，填补对课程学习原理性理解的理论空白。

Method: 建立基于状态条件自回归推理树的理论框架，将CoT生成建模为推理树，定义深度增加和提示减少两种课程阶段，分析强化学习微调的样本复杂度。

Result: 理论分析表明，在仅结果奖励信号下，课程学习能以多项式样本复杂度实现高准确率，而直接学习存在指数级瓶颈。测试时课程感知查询也能将计算成本从指数级降至多项式级。

Conclusion: 课程学习通过渐进式学习策略有效避免了指数级复杂度瓶颈，为LLM推理能力提升提供了理论依据和实用指导。

Abstract: Recent curriculum techniques in the post-training stage of LLMs have been
widely observed to outperform non-curriculum approaches in enhancing reasoning
performance, yet a principled understanding of why and to what extent they work
remains elusive. To address this gap, we develop a theoretical framework
grounded in the intuition that progressively learning through manageable steps
is more efficient than directly tackling a hard reasoning task, provided each
stage stays within the model's effective competence. Under mild complexity
conditions linking consecutive curriculum stages, we show that curriculum
post-training avoids the exponential complexity bottleneck.
  To substantiate this result, drawing insights from the Chain-of-Thoughts
(CoTs) solving mathematical problems such as Countdown and parity, we model CoT
generation as a states-conditioned autoregressive reasoning tree, define a
uniform-branching base model to capture pretrained behavior, and formalize
curriculum stages as either depth-increasing (longer reasoning chains) or
hint-decreasing (shorter prefixes) subtasks. Our analysis shows that, under
outcome-only reward signals, reinforcement learning finetuning achieves high
accuracy with polynomial sample complexity, whereas direct learning suffers
from an exponential bottleneck. We further establish analogous guarantees for
test-time scaling, where curriculum-aware querying reduces both reward oracle
calls and sampling cost from exponential to polynomial order.

</details>


### [431] [Transformers Provably Learn Chain-of-Thought Reasoning with Length Generalization](https://arxiv.org/abs/2511.07378)
*Yu Huang,Zixin Wen,Aarti Singh,Yuejie Chi,Yuxin Chen*

Main category: cs.LG

TL;DR: 该论文对Transformer模型在状态跟踪任务上的长度泛化能力进行了理论分析，证明了注意力集中机制如何影响思维链推理的泛化，并提出了递归自训练方案来扩展可解决问题的长度范围。


<details>
  <summary>Details</summary>
Motivation: 研究人工智能推理能力的核心问题：模型能否将学习到的推理模式外推到更复杂的思维链任务上，以解决更具挑战性的问题。

Method: 使用理论分析方法，在合成状态跟踪任务上分析Transformer的梯度下降学习过程，通过注意力集中机制来理解长度泛化，并提出递归自训练方案。

Result: 证明了恒定深度Transformer可以学习NC^1完全问题，超越了之前局限于TC^0的研究，并通过实验验证了理论结果。

Conclusion: Transformer模型通过注意力集中机制能够实现有效的长度泛化，递归自训练可以显著扩展模型的可解问题长度范围，为AI推理能力提供了理论保证。

Abstract: The ability to reason lies at the core of artificial intelligence (AI), and
challenging problems usually call for deeper and longer reasoning to tackle. A
crucial question about AI reasoning is whether models can extrapolate learned
reasoning patterns to solve harder tasks with longer chain-of-thought (CoT). In
this work, we present a theoretical analysis of transformers learning on
synthetic state-tracking tasks with gradient descent. We mathematically prove
how the algebraic structure of state-tracking problems governs the degree of
extrapolation of the learned CoT. Specifically, our theory characterizes the
length generalization of transformers through the mechanism of attention
concentration, linking the retrieval robustness of the attention layer to the
state-tracking task structure of long-context reasoning. Moreover, for
transformers with limited reasoning length, we prove that a recursive
self-training scheme can progressively extend the range of solvable problem
lengths. To our knowledge, we provide the first optimization guarantee that
constant-depth transformers provably learn $\mathsf{NC}^1$-complete problems
with CoT, significantly going beyond prior art confined in $\mathsf{TC}^0$,
unless the widely held conjecture $\mathsf{TC}^0 \neq \mathsf{NC}^1$ fails.
Finally, we present a broad set of experiments supporting our theoretical
results, confirming the length generalization behaviors and the mechanism of
attention concentration.

</details>


### [432] [LoReTTA: A Low Resource Framework To Poison Continuous Time Dynamic Graphs](https://arxiv.org/abs/2511.07379)
*Himanshu Pal,Venkata Sai Pranav Bachina,Ankit Gangwal,Charu Sharma*

Main category: cs.LG

TL;DR: LoReTTA是一种针对时序图神经网络(TGNNs)的新型对抗攻击框架，通过两阶段方法在连续时间动态图上进行攻击，平均降低模型性能29.47%，且具有不可检测性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 时序图神经网络在金融预测、推荐系统等高风险领域应用广泛，但其对投毒攻击的脆弱性带来了严重的安全风险。

Method: 采用两阶段方法：1）使用16种时序重要性指标移除高影响力边来稀疏化图；2）通过创新的度保持负采样算法策略性地用对抗性负边替换移除的边。

Result: 在4个基准数据集和4个SotA模型上，LoReTTA平均降低性能29.47%，最高在MOOC数据集上降低42.0%。优于11个攻击基线，对4个异常检测系统不可检测，对4个SotA防御方法具有鲁棒性。

Conclusion: LoReTTA是一种有效的、不可察觉且鲁棒的TGNN对抗攻击框架，无需昂贵的代理模型，符合现实不可察觉性约束。

Abstract: Temporal Graph Neural Networks (TGNNs) are increasingly used in high-stakes
domains, such as financial forecasting, recommendation systems, and fraud
detection. However, their susceptibility to poisoning attacks poses a critical
security risk. We introduce LoReTTA (Low Resource Two-phase Temporal Attack), a
novel adversarial framework on Continuous-Time Dynamic Graphs, which degrades
TGNN performance by an average of 29.47% across 4 widely benchmark datasets and
4 State-of-the-Art (SotA) models. LoReTTA operates through a two-stage
approach: (1) sparsify the graph by removing high-impact edges using any of the
16 tested temporal importance metrics, (2) strategically replace removed edges
with adversarial negatives via LoReTTA's novel degree-preserving negative
sampling algorithm. Our plug-and-play design eliminates the need for expensive
surrogate models while adhering to realistic unnoticeability constraints.
LoReTTA degrades performance by upto 42.0% on MOOC, 31.5% on Wikipedia, 28.8%
on UCI, and 15.6% on Enron. LoReTTA outperforms 11 attack baselines, remains
undetectable to 4 leading anomaly detection systems, and is robust to 4 SotA
adversarial defense training methods, establishing its effectiveness,
unnoticeability, and robustness.

</details>


### [433] [A Diffusion Model to Shrink Proteins While Maintaining Their Function](https://arxiv.org/abs/2511.07390)
*Ethan Baron,Alan N. Amin,Ruben Weitzman,Debora Marks,Andrew Gordon Wilson*

Main category: cs.LG

TL;DR: SCISOR是一种新型离散扩散模型，通过删除蛋白质序列中的字母来生成类似自然界的蛋白质样本，解决了长蛋白质序列难以合成、融合和递送的问题。


<details>
  <summary>Details</summary>
Motivation: 现代医学和生物工程中许多有用的蛋白质由于序列过长而难以在实验室中合成、与细胞中其他蛋白质融合或递送到体内组织。传统缩短序列的方法成本高、耗时，而现有模型难以有效搜索所有删除的组合空间。

Method: SCISOR训练一个去噪器来逆转在自然序列中添加随机插入的前向噪声过程。该模型通过离散扩散过程学习如何删除蛋白质序列中的字母。

Result: SCISOR在进化序列数据拟合方面与先前大型模型竞争激烈；在ProteinGym上实现了对删除功能效应的最先进预测；其建议的删除能产生更真实的蛋白质，并更常保留功能基序。

Conclusion: SCISOR模型能够有效缩短长蛋白质序列，生成更接近自然界的蛋白质样本，在保持功能性的同时提高了蛋白质工程的效率。

Abstract: Many proteins useful in modern medicine or bioengineering are challenging to
make in the lab, fuse with other proteins in cells, or deliver to tissues in
the body, because their sequences are too long. Shortening these sequences
typically involves costly, time-consuming experimental campaigns. Ideally, we
could instead use modern models of massive databases of sequences from nature
to learn how to propose shrunken proteins that resemble sequences found in
nature. Unfortunately, these models struggle to efficiently search the
combinatorial space of all deletions, and are not trained with inductive biases
to learn how to delete. To address this gap, we propose SCISOR, a novel
discrete diffusion model that deletes letters from sequences to generate
protein samples that resemble those found in nature. To do so, SCISOR trains a
de-noiser to reverse a forward noising process that adds random insertions to
natural sequences. As a generative model, SCISOR fits evolutionary sequence
data competitively with previous large models. In evaluation, SCISOR achieves
state-of-the-art predictions of the functional effects of deletions on
ProteinGym. Finally, we use the SCISOR de-noiser to shrink long protein
sequences, and show that its suggested deletions result in significantly more
realistic proteins and more often preserve functional motifs than previous
models of evolutionary sequences.

</details>


### [434] [C3PO: Optimized Large Language Model Cascades with Probabilistic Cost Constraints for Reasoning](https://arxiv.org/abs/2511.07396)
*Antonios Valkanas,Soumyasundar Pal,Pavel Rumiantsev,Yingxue Zhang,Mark Coates*

Main category: cs.LG

TL;DR: C3PO是一个自监督的LLM级联优化框架，通过概率成本约束和置信预测来控制推理成本，无需标注数据即可实现高效的大语言模型部署。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在复杂推理任务上表现出色，但高推理成本限制了实际部署。现有级联方法需要监督训练，缺乏理论保证，且对测试时计算成本控制有限。

Method: 提出C3PO框架，使用自监督方式优化LLM级联，基于最强大模型的最小化遗憾原则，利用置信预测来约束推理成本不超过用户指定预算。

Result: 在GSM8K、MATH-500、BigBench-Hard和AIME等多个推理基准测试中达到最先进性能，在准确性和成本效率方面优于现有级联基线。

Conclusion: 研究表明，基于原理的无标签级联优化能够实现可扩展的LLM部署，为实际应用提供了理论保证和实用解决方案。

Abstract: Large language models (LLMs) have achieved impressive results on complex
reasoning tasks, but their high inference cost remains a major barrier to
real-world deployment. A promising solution is to use cascaded inference, where
small, cheap models handle easy queries, and only the hardest examples are
escalated to more powerful models. However, existing cascade methods typically
rely on supervised training with labeled data, offer no theoretical
generalization guarantees, and provide limited control over test-time
computational cost. We introduce C3PO (Cost Controlled Cascaded Prediction
Optimization), a self-supervised framework for optimizing LLM cascades under
probabilistic cost constraints. By focusing on minimizing regret with respect
to the most powerful model (MPM), C3PO avoids the need for labeled data by
constructing a cascade using only unlabeled model outputs. It leverages
conformal prediction to bound the probability that inference cost exceeds a
user-specified budget. We provide theoretical guarantees on both cost control
and generalization error, and show that our optimization procedure is effective
even with small calibration sets. Empirically, C3PO achieves state-of-the-art
performance across a diverse set of reasoning benchmarks including GSM8K,
MATH-500, BigBench-Hard and AIME, outperforming strong LLM cascading baselines
in both accuracy and cost-efficiency. Our results demonstrate that principled,
label-free cascade optimization can enable scalable LLM deployment.

</details>


### [435] [Entangled Schrödinger Bridge Matching](https://arxiv.org/abs/2511.07406)
*Sophia Tang,Yinuo Zhang,Pranam Chatterjee*

Main category: cs.LG

TL;DR: 提出了Entangled Schrödinger Bridge Matching (EntangledSBM)框架，用于学习多粒子系统中相互作用的随机动力学，解决了传统方法无法捕捉动态交互的问题。


<details>
  <summary>Details</summary>
Motivation: 多粒子系统在复杂能量景观上的轨迹模拟是分子动力学和药物发现的核心任务，但现有方法只能通过静态快照学习联合轨迹，无法捕捉动态演化的相互作用。

Method: 引入Entangled Schrödinger Bridge (EntangledSB)问题，通过求解耦合的偏置力系统来纠缠粒子速度，学习粒子路径相互依赖的第一阶和第二阶随机动力学。

Result: 该框架能够准确模拟扰动下的异质细胞群体和高维生物分子系统中的罕见转变。

Conclusion: EntangledSBM为模拟具有动态相互作用的多粒子系统提供了一种有效方法，特别是在生物分子系统和异质细胞群体等复杂场景中表现出良好性能。

Abstract: Simulating trajectories of multi-particle systems on complex energy
landscapes is a central task in molecular dynamics (MD) and drug discovery, but
remains challenging at scale due to computationally expensive and long
simulations. Previous approaches leverage techniques such as flow or
Schr\"odinger bridge matching to implicitly learn joint trajectories through
data snapshots. However, many systems, including biomolecular systems and
heterogeneous cell populations, undergo dynamic interactions that evolve over
their trajectory and cannot be captured through static snapshots. To close this
gap, we introduce Entangled Schr\"odinger Bridge Matching (EntangledSBM), a
framework that learns the first- and second-order stochastic dynamics of
interacting, multi-particle systems where the direction and magnitude of each
particle's path depend dynamically on the paths of the other particles. We
define the Entangled Schr\"odinger Bridge (EntangledSB) problem as solving a
coupled system of bias forces that entangle particle velocities. We show that
our framework accurately simulates heterogeneous cell populations under
perturbations and rare transitions in high-dimensional biomolecular systems.

</details>


### [436] [Routing Manifold Alignment Improves Generalization of Mixture-of-Experts LLMs](https://arxiv.org/abs/2511.07419)
*Zhongyang Li,Ziyue Li,Tianyi Zhou*

Main category: cs.LG

TL;DR: RoMA方法通过路由流形对齐技术，在冻结其他参数的情况下仅微调路由器，显著提升了MoE LLMs的泛化性能，在多个基准测试中取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有MoE LLMs中的路由器存在一致性的次优问题，导致与最优路由之间存在10-20%的性能差距，影响了模型的泛化能力。

Method: 提出路由流形对齐(RoMA)方法，在训练目标中引入流形正则化项，通过轻量级微调路由器，使样本的路由权重在任务嵌入空间中接近其成功邻居的路由权重。

Result: 在OLMoE、DeepSeekMoE和Qwen3-MoE上的实验表明，RoMA在多样化基准测试中带来了显著改进，验证了方法的有效性。

Conclusion: RoMA成功地将任务理解与解决方案生成统一起来，通过建立任务与专家之间的绑定关系，实现了更好的泛化性能，为MoE LLMs的优化提供了有效途径。

Abstract: Sparse Mixture-of-Experts (MoE) have been widely adopted in recent large
language models since it can efficiently scale up the model capability without
increasing the inference cost. However, evaluations on broad downstream tasks
reveal a consistent suboptimality of the routers in existing MoE LLMs, which
results in a severe performance gap (e.g., 10-20% in accuracy) to the optimal
routing. In this paper, we show that aligning the manifold of routing weights
with that of task embedding can effectively reduce the gap and improve MoE
LLMs' generalization performance. Our method, "Routing Manifold Alignment
(RoMA)", introduces an additional manifold regularization term in the
post-training objective and only requires lightweight finetuning of routers
(with other parameters frozen). Specifically, the regularization encourages the
routing weights of each sample to be close to those of its successful neighbors
(whose routing weights lead to correct answers) in a task embedding space.
Consequently, samples targeting similar tasks will share similar expert choices
across layers. Building such bindings between tasks and experts over different
samples is essential to achieve better generalization. Moreover, RoMA
demonstrates the advantage of unifying the task understanding (by embedding
models) with solution generation (by MoE LLMs). In experiments, we finetune
routers in OLMoE, DeepSeekMoE, and Qwen3-MoE using RoMA. Evaluations on diverse
benchmarks and extensive comparisons with baselines show the substantial
improvement brought by RoMA.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [437] [Lite VLA: Efficient Vision-Language-Action Control on CPU-Bound Edge Robots](https://arxiv.org/abs/2511.05642)
*Justin Williams,Kishor Datta Gupta,Roy George,Mrinmoy Sarkar*

Main category: cs.RO

TL;DR: 该论文展示了在移动机器人上部署小型视觉语言模型（VLM）实现实时场景理解和推理的可行性，解决了GPS受限环境中边缘AI部署的挑战。


<details>
  <summary>Details</summary>
Motivation: 在GPS受限环境中，自主机器人需要本地化、资源高效的推理能力。现有方法通常将感知与移动分离，无法在动态环境中实现同时移动和推理。

Method: 提出一个集成紧凑VLM与多模态感知的框架，直接在嵌入式硬件上进行上下文解释，消除对云连接的依赖。

Result: 实验验证了计算效率、任务准确性和系统响应性之间的平衡，在移动机器人上成功实现了并发推理和移动的部署。

Conclusion: 这项工作为服务机器人、灾难响应和国防行动等应用中的可扩展、可靠自主性奠定了基础。

Abstract: The deployment of artificial intelligence models at the edge is increasingly
critical for autonomous robots operating in GPS-denied environments where
local, resource-efficient reasoning is essential. This work demonstrates the
feasibility of deploying small Vision-Language Models (VLMs) on mobile robots
to achieve real-time scene understanding and reasoning under strict
computational constraints. Unlike prior approaches that separate perception
from mobility, the proposed framework enables simultaneous movement and
reasoning in dynamic environments using only on-board hardware. The system
integrates a compact VLM with multimodal perception to perform contextual
interpretation directly on embedded hardware, eliminating reliance on cloud
connectivity. Experimental validation highlights the balance between
computational efficiency, task accuracy, and system responsiveness.
Implementation on a mobile robot confirms one of the first successful
deployments of small VLMs for concurrent reasoning and mobility at the edge.
This work establishes a foundation for scalable, assured autonomy in
applications such as service robotics, disaster response, and defense
operations.

</details>


### [438] [VLM-driven Skill Selection for Robotic Assembly Tasks](https://arxiv.org/abs/2511.05680)
*Jeong-Jung Kim,Doo-Yeol Koh,Chang-Hyun Kim*

Main category: cs.RO

TL;DR: 本文提出了一个结合视觉语言模型和模仿学习的机器人装配框架，通过视觉感知、自然语言理解和学习的基本技能实现灵活的机器人装配操作。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够整合视觉感知和自然语言理解的机器人装配系统，实现更灵活和自适应的装配操作。

Method: 使用配备夹爪的机器人在3D空间中执行装配操作，结合视觉语言模型进行视觉感知和自然语言理解，通过模仿学习训练基本技能。

Result: 实验结果表明该方法在装配场景中具有高效性，实现了高成功率，并通过结构化的基本技能分解保持了可解释性。

Conclusion: 该框架成功地将视觉语言模型与模仿学习结合，为机器人装配任务提供了一种有效且可解释的解决方案。

Abstract: This paper presents a robotic assembly framework that combines
Vision-Language Models (VLMs) with imitation learning for assembly manipulation
tasks. Our system employs a gripper-equipped robot that moves in 3D space to
perform assembly operations. The framework integrates visual perception,
natural language understanding, and learned primitive skills to enable flexible
and adaptive robotic manipulation. Experimental results demonstrate the
effectiveness of our approach in assembly scenarios, achieving high success
rates while maintaining interpretability through the structured primitive skill
decomposition.

</details>


### [439] [TumorMap: A Laser-based Surgical Platform for 3D Tumor Mapping and Fully-Automated Tumor Resection](https://arxiv.org/abs/2511.05723)
*Guangshen Ma,Ravi Prakash,Beatrice Schleupner,Jeffrey Everitt,Arpit Mishra,Junqin Chen,Brian Mann,Boyuan Chen,Leila Bridgeman,Pei Zhong,Mark Draelos,William C. Eward,Patrick J. Codd*

Main category: cs.RO

TL;DR: TumorMap是一个手术机器人平台，通过集成三种激光机制（光学相干断层扫描、激光诱导内源性荧光和切割激光手术刀）结合深度学习模型，实现术中3D肿瘤边界重建和自主组织切除。


<details>
  <summary>Details</summary>
Motivation: 恶性实体瘤手术切除面临缺乏高保真肿瘤重建、难以开发通用组织模型处理肿瘤诊断复杂性，以及手术中双手操作、生理震颤和疲劳等自然物理限制的挑战。

Method: 集成三激光机制：光学相干断层扫描用于成像，激光诱导内源性荧光用于肿瘤识别，切割激光手术刀用于切除；结合深度学习模型实现全自动非接触式肿瘤切除。

Result: 在鼠骨肉瘤和软组织肉瘤模型中验证，建立了新的组织病理学工作流程评估传感器性能，实现了亚毫米级激光切除精度和多模态传感器引导的自主肿瘤手术。

Conclusion: TumorMap平台能够克服传统手术挑战，实现无需人工干预的自主肿瘤切除手术。

Abstract: Surgical resection of malignant solid tumors is critically dependent on the
surgeon's ability to accurately identify pathological tissue and remove the
tumor while preserving surrounding healthy structures. However, building an
intraoperative 3D tumor model for subsequent removal faces major challenges due
to the lack of high-fidelity tumor reconstruction, difficulties in developing
generalized tissue models to handle the inherent complexities of tumor
diagnosis, and the natural physical limitations of bimanual operation,
physiologic tremor, and fatigue creep during surgery. To overcome these
challenges, we introduce "TumorMap", a surgical robotic platform to formulate
intraoperative 3D tumor boundaries and achieve autonomous tissue resection
using a set of multifunctional lasers. TumorMap integrates a three-laser
mechanism (optical coherence tomography, laser-induced endogenous fluorescence,
and cutting laser scalpel) combined with deep learning models to achieve
fully-automated and noncontact tumor resection. We validated TumorMap in murine
osteoscarcoma and soft-tissue sarcoma tumor models, and established a novel
histopathological workflow to estimate sensor performance. With submillimeter
laser resection accuracy, we demonstrated multimodal sensor-guided autonomous
tumor surgery without any human intervention.

</details>


### [440] [A Unified Stochastic Mechanism Underlying Collective Behavior in Ants, Physical Systems, and Robotic Swarms](https://arxiv.org/abs/2511.05785)
*Lianhao Yin,Haiping Yu,Pascal Spino,Daniela Rus*

Main category: cs.RO

TL;DR: 提出了一个统一随机模型，将生物、物理和机器人群体联系起来，揭示了在能量函数约束下的最大化机制。


<details>
  <summary>Details</summary>
Motivation: 生物群体（如蚁群）通过分散的随机行为实现集体目标，而物理系统（如气体、液体）中的粒子随机运动虽受熵最大化支配，却不实现集体目标。目前缺乏解释这两种系统随机行为的统一框架。

Method: 通过分析Formica polyctena蚂蚁的经验证据，发现生物和物理系统共享的统计机制：在不同能量函数约束下的最大化。进一步在机器人群体中应用这一原理，实现分散合作。

Result: 机器人群体遵循该原理可展现出可扩展的分散合作行为，模拟物理相变行为，且个体计算需求极低。

Conclusion: 建立了一个连接生物、物理和机器人群体的统一随机模型，为设计鲁棒智能的群体机器人提供了可扩展原则。

Abstract: Biological swarms, such as ant colonies, achieve collective goals through
decentralized and stochastic individual behaviors. Similarly, physical systems
composed of gases, liquids, and solids exhibit random particle motion governed
by entropy maximization, yet do not achieve collective objectives. Despite this
analogy, no unified framework exists to explain the stochastic behavior in both
biological and physical systems. Here, we present empirical evidence from
\textit{Formica polyctena} ants that reveals a shared statistical mechanism
underlying both systems: maximization under different energy function
constraints. We further demonstrate that robotic swarms governed by this
principle can exhibit scalable, decentralized cooperation, mimicking physical
phase-like behaviors with minimal individual computation. These findings
established a unified stochastic model linking biological, physical, and
robotic swarms, offering a scalable principle for designing robust and
intelligent swarm robotics.

</details>


### [441] [VLAD-Grasp: Zero-shot Grasp Detection via Vision-Language Models](https://arxiv.org/abs/2511.05791)
*Manav Kulshrestha,S. Talha Bukhari,Damon Conover,Aniket Bera*

Main category: cs.RO

TL;DR: VLAD-Grasp是一个基于视觉语言模型的零样本抓取检测方法，无需训练或专家标注即可实现竞争性抓取性能。


<details>
  <summary>Details</summary>
Motivation: 现有机器人抓取方法依赖大规模专家标注，需要重新训练才能处理新物体，限制了实际应用。

Method: 从单张RGB-D图像出发：(1)使用大视觉语言模型生成目标图像，用直杆"刺穿"物体表示抓取点；(2)预测深度和分割将生成图像提升到3D；(3)通过主成分分析和无对应优化对齐生成和观测点云，恢复可执行抓取姿态。

Result: 在Cornell和Jacquard数据集上达到或超越最先进监督模型的性能，并在Franka Research 3机器人上展示了对新物体的零样本泛化能力。

Conclusion: 视觉语言基础模型可作为机器人操作的强大先验，VLAD-Grasp展示了无需训练即可实现竞争性抓取性能的可行性。

Abstract: Robotic grasping is a fundamental capability for autonomous manipulation;
however, most existing methods rely on large-scale expert annotations and
necessitate retraining to handle new objects. We present VLAD-Grasp, a
Vision-Language model Assisted zero-shot approach for Detecting grasps. From a
single RGB-D image, our method (1) prompts a large vision-language model to
generate a goal image where a straight rod "impales" the object, representing
an antipodal grasp, (2) predicts depth and segmentation to lift this generated
image into 3D, and (3) aligns generated and observed object point clouds via
principal component analysis and correspondence-free optimization to recover an
executable grasp pose. Unlike prior work, our approach is training-free and
does not rely on curated grasp datasets. Despite this, VLAD-Grasp achieves
performance that is competitive with or superior to that of state-of-the-art
supervised models on the Cornell and Jacquard datasets. We further demonstrate
zero-shot generalization to novel real-world objects on a Franka Research 3
robot, highlighting vision-language foundation models as powerful priors for
robotic manipulation.

</details>


### [442] [An Open-Source, Reproducible Tensegrity Robot that can Navigate Among Obstacles](https://arxiv.org/abs/2511.05798)
*William R. Johnson III,Patrick Meng,Nelson Chen,Luca Cimatti,Augustin Vercoutere,Mridul Aanjaneya,Rebecca Kramer-Bottiglio,Kostas E. Bekris*

Main category: cs.RO

TL;DR: 本文提出了一个完整、开源、可复现的3杆张拉整体机器人导航系统，包括硬件设计和软件栈，实现了在已知障碍物环境中的路径规划和避障。


<details>
  <summary>Details</summary>
Motivation: 张拉整体机器人具有抗冲击、低质量和适应非结构化地形的优势，但其柔顺性和复杂的耦合动力学给建模和控制带来了挑战，阻碍了路径规划和避障能力的发展。

Method: 系统包含：(i) 低成本开源硬件设计；(ii) 集成的开源软件栈，涵盖物理建模、系统辨识、状态估计、路径规划和控制。所有硬件和软件均公开可用。

Result: 实验证明系统能够跟踪机器人位姿并执行无碰撞路径规划，在未建模环境挑战（如垂直跌落、斜坡和颗粒介质）中表现出鲁棒性，并在两个不同实验室的机器人实例上验证了可复现性。

Conclusion: 这项工作为机器人社区提供了一个完整的柔顺、抗冲击和形状变形机器人导航系统，旨在作为推进其他非常规机器人平台导航能力的跳板。

Abstract: Tensegrity robots, composed of rigid struts and elastic tendons, provide
impact resistance, low mass, and adaptability to unstructured terrain. Their
compliance and complex, coupled dynamics, however, present modeling and control
challenges, hindering path planning and obstacle avoidance. This paper presents
a complete, open-source, and reproducible system that enables navigation for a
3-bar tensegrity robot. The system comprises: (i) an inexpensive, open-source
hardware design, and (ii) an integrated, open-source software stack for
physics-based modeling, system identification, state estimation, path planning,
and control. All hardware and software are publicly available at
https://sites.google.com/view/tensegrity-navigation/. The proposed system
tracks the robot's pose and executes collision-free paths to a specified goal
among known obstacle locations. System robustness is demonstrated through
experiments involving unmodeled environmental challenges, including a vertical
drop, an incline, and granular media, culminating in an outdoor field
demonstration. To validate reproducibility, experiments were conducted using
robot instances at two different laboratories. This work provides the robotics
community with a complete navigation system for a compliant, impact-resistant,
and shape-morphing robot. This system is intended to serve as a springboard for
advancing the navigation capabilities of other unconventional robotic
platforms.

</details>


### [443] [Adversarial Game-Theoretic Algorithm for Dexterous Grasp Synthesis](https://arxiv.org/abs/2511.05809)
*Yu Chen,Botao He,Yuemin Mao,Arthur Jakobsson,Jeffrey Ke,Yiannis Aloimonos,Guanya Shi,Howie Choset,Jiayuan Mao,Jeffrey Ichnowski*

Main category: cs.RO

TL;DR: 提出了一种基于双玩家博弈的多指机器人抓取合成方法，通过模拟机器人抓取和物体逃逸的对抗过程，显著提高了抓取成功率。


<details>
  <summary>Details</summary>
Motivation: 现有多指机器人抓取方法通常只关注抵抗单一力矩，忽略了物体可能逃逸的对抗性运动，导致抓取不稳定和失败。

Method: 将抓取合成问题建模为双玩家博弈：一个玩家控制机器人生成可行抓取配置，另一个玩家控制物体寻求逃逸运动。

Result: 仿真实验中成功率75.78%，比现有方法提高19.61%；真实实验中ShadowHand成功率85.0%，LeapHand成功率87.5%；生成时间仅需0.28-1.04秒。

Conclusion: 双玩家博弈机制能有效提升抓取稳定性，方法具有实际部署可行性，为多指机器人抓取提供了新思路。

Abstract: For many complex tasks, multi-finger robot hands are poised to revolutionize
how we interact with the world, but reliably grasping objects remains a
significant challenge. We focus on the problem of synthesizing grasps for
multi-finger robot hands that, given a target object's geometry and pose,
computes a hand configuration. Existing approaches often struggle to produce
reliable grasps that sufficiently constrain object motion, leading to
instability under disturbances and failed grasps. A key reason is that during
grasp generation, they typically focus on resisting a single wrench, while
ignoring the object's potential for adversarial movements, such as escaping. We
propose a new grasp-synthesis approach that explicitly captures and leverages
the adversarial object motion in grasp generation by formulating the problem as
a two-player game. One player controls the robot to generate feasible grasp
configurations, while the other adversarially controls the object to seek
motions that attempt to escape from the grasp. Simulation experiments on
various robot platforms and target objects show that our approach achieves a
success rate of 75.78%, up to 19.61% higher than the state-of-the-art baseline.
The two-player game mechanism improves the grasping success rate by 27.40% over
the method without the game formulation. Our approach requires only 0.28-1.04
seconds on average to generate a grasp configuration, depending on the robot
platform, making it suitable for real-world deployment. In real-world
experiments, our approach achieves an average success rate of 85.0% on
ShadowHand and 87.5% on LeapHand, which confirms its feasibility and
effectiveness in real robot setups.

</details>


### [444] [3D Mapping Using a Lightweight and Low-Power Monocular Camera Embedded inside a Gripper of Limbed Climbing Robots](https://arxiv.org/abs/2511.05816)
*Taku Okawara,Ryo Nishibe,Mao Kasano,Kentaro Uno,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 提出一种用于太空探索的3D地形测绘系统，使用单目手眼相机结合肢体前向运动学来解决单目SLAM的尺度模糊问题，实现轻量、低功耗的实时3D地图构建和自主抓取。


<details>
  <summary>Details</summary>
Motivation: 传统攀爬机器人使用RGB-D相机进行3D地形测绘和抓取点检测，但RGB-D相机体积大、功耗高。单目相机更轻量、紧凑且功耗低，但单目SLAM存在尺度模糊问题。

Method: 提出一种SLAM方法，将单目视觉约束与肢体前向运动学融合，基于因子图优化联合估计抓手的位姿序列和3D地图的全局度量尺度。

Result: 通过物理仿真和真实实验验证，该框架能够实时构建度量尺度的3D地形地图，并实现使用单目手眼相机自主抓取凸起地形表面，无需依赖RGB-D相机。

Conclusion: 该方法为未来涉及有腿攀爬机器人的太空任务提供了可扩展且节能的感知解决方案。

Abstract: Limbed climbing robots are designed to explore challenging vertical walls,
such as the skylights of the Moon and Mars. In such robots, the primary role of
a hand-eye camera is to accurately estimate 3D positions of graspable points
(i.e., convex terrain surfaces) thanks to its close-up views. While
conventional climbing robots often employ RGB-D cameras as hand-eye cameras to
facilitate straightforward 3D terrain mapping and graspable point detection,
RGB-D cameras are large and consume considerable power.
  This work presents a 3D terrain mapping system designed for space exploration
using limbed climbing robots equipped with a monocular hand-eye camera.
Compared to RGB-D cameras, monocular cameras are more lightweight, compact
structures, and have lower power consumption. Although monocular SLAM can be
used to construct 3D maps, it suffers from scale ambiguity. To address this
limitation, we propose a SLAM method that fuses monocular visual constraints
with limb forward kinematics. The proposed method jointly estimates time-series
gripper poses and the global metric scale of the 3D map based on factor graph
optimization.
  We validate the proposed framework through both physics-based simulations and
real-world experiments. The results demonstrate that our framework constructs a
metrically scaled 3D terrain map in real-time and enables autonomous grasping
of convex terrain surfaces using a monocular hand-eye camera, without relying
on RGB-D cameras. Our method contributes to scalable and energy-efficient
perception for future space missions involving limbed climbing robots. See the
video summary here: https://youtu.be/fMBrrVNKJfc

</details>


### [445] [Gentle Manipulation Policy Learning via Demonstrations from VLM Planned Atomic Skills](https://arxiv.org/abs/2511.05855)
*Jiayu Zhou,Qiwei Wu,Jian Li,Zhe Chen,Xiaogang Xiong,Renjing Xu*

Main category: cs.RO

TL;DR: 提出了一种结合分层语义分解、强化学习、视觉语言模型和知识蒸馏的新框架，用于自主执行长时程、接触丰富的操作任务，无需昂贵的人类演示。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法需要大量真实世界数据和专家工程带来的成本和可扩展性挑战。

Method: 将复杂任务分解为原子技能，在模拟环境中用强化学习训练每个技能的策略，并融入力约束防止物体损坏。使用VLM进行高级任务分解和技能规划，通过视觉-触觉扩散策略将专家演示蒸馏为统一策略。

Result: 通过全面的消融研究和系统实验验证，该方法能够实现长时程操作策略学习，并具有可扩展的泛化能力。

Conclusion: 该框架有效解决了传统方法的局限性，实现了无需人类演示的自主长时程操作学习，具有重要的实际应用价值。

Abstract: Autonomous execution of long-horizon, contact-rich manipulation tasks
traditionally requires extensive real-world data and expert engineering, posing
significant cost and scalability challenges. This paper proposes a novel
framework integrating hierarchical semantic decomposition, reinforcement
learning (RL), visual language models (VLMs), and knowledge distillation to
overcome these limitations. Complex tasks are decomposed into atomic skills,
with RL-trained policies for each primitive exclusively in simulation.
Crucially, our RL formulation incorporates explicit force constraints to
prevent object damage during delicate interactions. VLMs perform high-level
task decomposition and skill planning, generating diverse expert
demonstrations. These are distilled into a unified policy via Visual-Tactile
Diffusion Policy for end-to-end execution. We conduct comprehensive ablation
studies exploring different VLM-based task planners to identify optimal
demonstration generation pipelines, and systematically compare imitation
learning algorithms for skill distillation. Extensive simulation experiments
and physical deployment validate that our approach achieves policy learning for
long-horizon manipulation without costly human demonstrations, while the
VLM-guided atomic skill framework enables scalable generalization to diverse
tasks.

</details>


### [446] [ViTaMIn-B: A Reliable and Efficient Visuo-Tactile Bimanual Manipulation Interface](https://arxiv.org/abs/2511.05858)
*Chuanyu Li,Chaoyi Liu,Daotan Wang,Shuyu Zhang,Lusong Li,Zecui Zeng,Fangchen Liu,Jing Xu,Rui Chen*

Main category: cs.RO

TL;DR: ViTaMIn-B是一个用于双手机器人操作的手持数据采集系统，通过新型触觉传感器和姿态跟踪技术解决现有系统在复杂交互场景中的局限性


<details>
  <summary>Details</summary>
Motivation: 现有手持设备在采集大规模演示数据时缺乏强大的触觉感知和可靠的姿态跟踪能力，特别是在处理双手机接触丰富的复杂交互任务时存在明显不足

Method: 设计了DuoTact柔性视觉触觉传感器来承受大接触力并捕捉高分辨率接触几何；提出将传感器全局变形重建为3D点云作为策略输入；开发了基于Meta Quest控制器的鲁棒6-DoF双手姿态获取流程

Result: 用户研究证实了ViTaMIn-B在新手和专家操作者中的高效性和高可用性；在四个双手机器人操作任务上的实验显示其相对于现有系统的优越性能

Conclusion: ViTaMIn-B系统为双手机接触丰富的操作任务提供了更强大、更高效的数据采集解决方案，在触觉感知和姿态跟踪方面都有显著改进

Abstract: Handheld devices have opened up unprecedented opportunities to collect
large-scale, high-quality demonstrations efficiently. However, existing systems
often lack robust tactile sensing or reliable pose tracking to handle complex
interaction scenarios, especially for bimanual and contact-rich tasks. In this
work, we propose ViTaMIn-B, a more capable and efficient handheld data
collection system for such tasks. We first design DuoTact, a novel compliant
visuo-tactile sensor built with a flexible frame to withstand large contact
forces during manipulation while capturing high-resolution contact geometry. To
enhance the cross-sensor generalizability, we propose reconstructing the
sensor's global deformation as a 3D point cloud and using it as the policy
input. We further develop a robust, unified 6-DoF bimanual pose acquisition
process using Meta Quest controllers, which eliminates the trajectory drift
issue in common SLAM-based methods. Comprehensive user studies confirm the
efficiency and high usability of ViTaMIn-B among novice and expert operators.
Furthermore, experiments on four bimanual manipulation tasks demonstrate its
superior task performance relative to existing systems.

</details>


### [447] [Fair and Safe: A Real-Time Hierarchical Control Framework for Intersections](https://arxiv.org/abs/2511.05886)
*Lei Shi,Yongju Kim,Xinzhi Zhong,Wissam Kontar,Qichao Liu,Soyoung Ahn*

Main category: cs.RO

TL;DR: 提出了一个公平感知的分层控制框架，用于联网自动驾驶车辆在交叉路口的协调，通过显式整合不平等厌恶来实现公平性、安全性和实时性能的平衡。


<details>
  <summary>Details</summary>
Motivation: 确保自动驾驶车辆在交叉路口协调的公平性对于公平接入、社会接受度和长期系统效率至关重要，但在安全关键、实时交通控制中仍未被充分探索。

Method: 采用分层控制框架：顶层集中分配模块通过最大化考虑等待时间、紧急程度、控制历史和速度偏差的效用来分配控制权；底层授权车辆使用LQR执行预计算轨迹，并应用基于高阶控制屏障函数的安全滤波器进行实时碰撞避免。

Result: 在不同交通需求和需求分布下的仿真结果表明，该框架实现了近乎完美的公平性，消除了碰撞，减少了平均延迟，并保持了实时可行性。

Conclusion: 公平性可以系统地融入自动驾驶交通系统，而不会牺牲安全性或性能，为未来自动驾驶交通系统实现可扩展和公平的协调。

Abstract: Ensuring fairness in the coordination of connected and automated vehicles at
intersections is essential for equitable access, social acceptance, and
long-term system efficiency, yet it remains underexplored in safety-critical,
real-time traffic control. This paper proposes a fairness-aware hierarchical
control framework that explicitly integrates inequity aversion into
intersection management. At the top layer, a centralized allocation module
assigns control authority (i.e., selects a single vehicle to execute its
trajectory) by maximizing a utility that accounts for waiting time, urgency,
control history, and velocity deviation. At the bottom layer, the authorized
vehicle executes a precomputed trajectory using a Linear Quadratic Regulator
(LQR) and applies a high-order Control Barrier Function (HOCBF)-based safety
filter for real-time collision avoidance. Simulation results across varying
traffic demands and demand distributions demonstrate that the proposed
framework achieves near-perfect fairness, eliminates collisions, reduces
average delay, and maintains real-time feasibility. These results highlight
that fairness can be systematically incorporated without sacrificing safety or
performance, enabling scalable and equitable coordination for future autonomous
traffic systems.

</details>


### [448] [From Words to Safety: Language-Conditioned Safety Filtering for Robot Navigation](https://arxiv.org/abs/2511.05889)
*Zeyuan Feng,Haimingyue Zhang,Somil Bansal*

Main category: cs.RO

TL;DR: 提出了一个模块化框架，用于机器人导航中的语言条件安全，将自然语言指令转换为结构化安全规范，并通过感知和控制模块实时执行约束。


<details>
  <summary>Details</summary>
Motivation: 随着机器人在开放世界环境中广泛应用，需要能够理解自然语言指令并遵守安全约束，现有方法局限于特定约束类型或只关注奖励函数而非安全规范。

Method: 框架包含三个核心组件：基于大语言模型的指令解析模块、基于感知的环境物体3D表示模块、以及基于模型预测控制的安全过滤器模块。

Result: 通过仿真和硬件实验验证，该框架能够稳健地解释和执行各种语言指定的约束，适用于多种环境和场景。

Conclusion: 该模块化框架有效解决了机器人导航中的语言条件安全问题，提升了在复杂环境中的安全性和可靠性。

Abstract: As robots become increasingly integrated into open-world, human-centered
environments, their ability to interpret natural language instructions and
adhere to safety constraints is critical for effective and trustworthy
interaction. Existing approaches often focus on mapping language to reward
functions instead of safety specifications or address only narrow constraint
classes (e.g., obstacle avoidance), limiting their robustness and
applicability. We propose a modular framework for language-conditioned safety
in robot navigation. Our framework is composed of three core components: (1) a
large language model (LLM)-based module that translates free-form instructions
into structured safety specifications, (2) a perception module that grounds
these specifications by maintaining object-level 3D representations of the
environment, and (3) a model predictive control (MPC)-based safety filter that
enforces both semantic and geometric constraints in real time. We evaluate the
effectiveness of the proposed framework through both simulation studies and
hardware experiments, demonstrating that it robustly interprets and enforces
diverse language-specified constraints across a wide range of environments and
scenarios.

</details>


### [449] [10 Open Challenges Steering the Future of Vision-Language-Action Models](https://arxiv.org/abs/2511.05936)
*Soujanya Poria,Navonil Majumder,Chia-Yu Hung,Amir Ali Bagherzadeh,Chuan Li,Kenneth Kwok,Ziwei Wang,Cheston Tan,Jiajun Wu,David Hsu*

Main category: cs.RO

TL;DR: 本文讨论了视觉-语言-动作（VLA）模型发展的10个关键里程碑和新兴趋势，旨在推动VLA模型更广泛的应用。


<details>
  <summary>Details</summary>
Motivation: 随着VLA模型在具身AI领域的日益普及，需要系统梳理其发展路径和关键挑战，以加速该技术的成熟和推广应用。

Method: 通过分析VLA模型发展的10个主要里程碑（多模态、推理、数据、评估等）和4个新兴趋势（空间理解、世界动态建模等），构建了该领域的发展框架。

Result: 提出了VLA模型发展的系统性路线图，识别了关键研究方向和挑战，为未来研究提供了明确指导。

Conclusion: 通过关注这些研究路径，可以加速VLA模型的发展，使其在更广泛的应用场景中被接受和使用。

Abstract: Due to their ability of follow natural language instructions,
vision-language-action (VLA) models are increasingly prevalent in the embodied
AI arena, following the widespread success of their precursors -- LLMs and
VLMs. In this paper, we discuss 10 principal milestones in the ongoing
development of VLA models -- multimodality, reasoning, data, evaluation,
cross-robot action generalization, efficiency, whole-body coordination, safety,
agents, and coordination with humans. Furthermore, we discuss the emerging
trends of using spatial understanding, modeling world dynamics, post training,
and data synthesis -- all aiming to reach these milestones. Through these
discussions, we hope to bring attention to the research avenues that may
accelerate the development of VLA models into wider acceptability.

</details>


### [450] [Robustness study of the bio-inspired musculoskeletal arm robot based on the data-driven iterative learning algorithm](https://arxiv.org/abs/2511.05995)
*Jianbo Yuan,Jing Dai,Yerui Fan,Yaxiong Wu,Yunpeng Liang,Weixin Yan*

Main category: cs.RO

TL;DR: 本研究开发了一种新型轻量化肌腱驱动肌肉骨骼手臂（LTDM-Arm），采用7自由度骨骼关节系统和模块化人工肌肉系统，通过Hilly型肌肉模型和数据驱动迭代学习控制实现重复任务的精确轨迹跟踪，在仿真和实验中验证了其抗干扰能力。


<details>
  <summary>Details</summary>
Motivation: 人类手臂在非结构化环境中展现出卓越的灵活性、顺应性和鲁棒性，开发具有类似人类操作特性的肌肉骨骼结构机器人系统一直是研究重点。

Method: 设计7自由度骨骼关节系统和包含15个执行器的模块化人工肌肉系统，采用Hilly型肌肉模型和数据驱动迭代学习控制（DDILC）来学习和优化有限时间内的重复任务激活信号。

Result: 仿真和实验验证表明，LTDM-Arm系统能够有效实现期望轨迹跟踪任务，在仿真中承受20%负载干扰，实验中承受15%负载干扰仍能保持良好性能。

Conclusion: 这项研究为开发具有人类操作性能的先进机器人系统奠定了基础。

Abstract: The human arm exhibits remarkable capabilities, including both explosive
power and precision, which demonstrate dexterity, compliance, and robustness in
unstructured environments. Developing robotic systems that emulate human-like
operational characteristics through musculoskeletal structures has long been a
research focus. In this study, we designed a novel lightweight tendon-driven
musculoskeletal arm (LTDM-Arm), featuring a seven degree-of-freedom (DOF)
skeletal joint system and a modularized artificial muscular system (MAMS) with
15 actuators. Additionally, we employed a Hilly-type muscle model and
data-driven iterative learning control (DDILC) to learn and refine activation
signals for repetitive tasks within a finite time frame. We validated the
anti-interference capabilities of the musculoskeletal system through both
simulations and experiments. The results show that the LTDM-Arm system can
effectively achieve desired trajectory tracking tasks, even under load
disturbances of 20 % in simulation and 15 % in experiments. This research lays
the foundation for developing advanced robotic systems with human-like
operational performance.

</details>


### [451] [Development and testing of novel soft sleeve actuators](https://arxiv.org/abs/2511.06102)
*Mohammed Abboodi*

Main category: cs.RO

TL;DR: 本研究开发了一种柔软套筒驱动架构，能够贴合肢体并高效传递力和力矩，解决了传统刚性辅助设备存在的力传递障碍和穿戴舒适性问题。


<details>
  <summary>Details</summary>
Motivation: 老龄化人口增长和神经肌肉骨骼疾病患病率上升，对有效、舒适且解剖学兼容的可穿戴移动辅助设备需求增加。现有系统多采用刚性机构和笨重接口，阻碍力传递并降低可穿戴性。

Method: 开发了三种柔软套筒驱动器（线性、弯曲和扭转运动），以及结合这些运动的 omnidirectional 设计。采用定制熔丝制造工艺用热塑性弹性体制造气密柔性结构，解决了传统方法的泄漏问题。通过专用实验平台量化运动学和动力学输出。

Result: 结果显示在低气压下可重现多轴运动，改善了向肢体的力传递，减少了对复杂附件的需求。参数研究表明几何特征和材料特性对性能有显著影响。

Conclusion: 该研究建立了一个统一且可制造的柔软套筒驱动框架，为紧凑型、以用户为中心的辅助技术提供了增强的运动学和动力学性能。

Abstract: Aging populations and the rising prevalence of neurological and
musculoskeletal disorders increase the demand for wearable mobility assistive
devices that are effective, comfortable, and anatomically compatible. Many
existing systems use rigid mechanisms and bulky interfaces that impede force
transmission and reduce wearability. This study introduces a soft sleeve
actuation architecture that conforms to the limb while transmitting forces and
moments efficiently. We develop three soft sleeve actuators that produce
linear, bending, and twisting motion, and an omnidirectional design that
combines these motions in one device. Actuators are fabricated from
thermoplastic elastomers using a customized fused filament fabrication process
that produces airtight and compliant structures and resolves leakage observed
with conventional methods. A dedicated experimental platform quantifies
kinematic outputs such as displacement, angle, and twist, and kinetic outputs
such as force and torque under low pneumatic pressures. A parametric study
varies geometric features and material properties to determine their influence
on performance. Results show reproducible multi axis motion with improved
transfer of force to the limb and reduced need for complex attachment hardware.
The work establishes a unified and manufacturable framework for soft sleeve
actuation that enables compact and user centered assistive technologies with
enhanced kinematic and kinetic performance.

</details>


### [452] [PlaCo: a QP-based robot planning and control framework](https://arxiv.org/abs/2511.06141)
*Marc Duclusaud,Grégoire Passault,Vincent Padois,Olivier Ly*

Main category: cs.RO

TL;DR: PlaCo是一个用于简化机器人系统QP规划和控制问题的软件框架，提供高层接口抽象底层数学公式，支持Python和C++实现。


<details>
  <summary>Details</summary>
Motivation: 简化QP问题的制定和求解过程，让用户能够以模块化和直观的方式指定任务和约束，无需关注底层数学细节。

Method: 提供高层接口抽象QP问题的底层数学公式，支持Python绑定用于快速原型开发，C++实现用于实时性能。

Result: 开发了一个软件框架，能够简化机器人系统QP规划和控制问题的制定和求解。

Conclusion: PlaCo框架成功简化了QP问题的处理，为机器人系统的规划和控制提供了高效且易用的工具。

Abstract: This article introduces PlaCo, a software framework designed to simplify the
formulation and solution of Quadratic Programming (QP)-based planning and
control problems for robotic systems. PlaCo provides a high-level interface
that abstracts away the low-level mathematical formulation of QP problems,
allowing users to specify tasks and constraints in a modular and intuitive
manner. The framework supports both Python bindings for rapid prototyping and a
C++ implementation for real-time performance.

</details>


### [453] [OpenVLN: Open-world aerial Vision-Language Navigation](https://arxiv.org/abs/2511.06182)
*Peican Lin,Gan Sun,Chenxi Liu,Fazeng Li,Weihong Ren,Yang Cong*

Main category: cs.RO

TL;DR: 提出了OpenVLN框架，通过强化学习优化视觉语言模型，结合长时程规划器，在有限数据条件下实现无人机语言导航，在复杂空中环境中提升长距离轨迹规划能力。


<details>
  <summary>Details</summary>
Motivation: 解决户外空中环境中视觉语言导航面临的数据获取困难和长距离轨迹规划复杂性的挑战。

Method: 重新配置强化学习框架优化视觉语言模型，使用规则策略进行高效微调；引入基于价值奖励的长时程规划器动态生成精确无人机动作。

Result: 在TravelUAV基准测试中，成功率提升4.34%，Oracle成功率提升6.19%，路径长度加权成功率提升4.07%。

Conclusion: 验证了该方法在复杂空中环境中长距离无人机导航部署的有效性。

Abstract: Vision-language models (VLMs) have been widely-applied in ground-based
vision-language navigation (VLN). However, the vast complexity of outdoor
aerial environments compounds data acquisition challenges and imposes
long-horizon trajectory planning requirements on Unmanned Aerial Vehicles
(UAVs), introducing novel complexities for aerial VLN. To address these
challenges, we propose a data-efficient Open-world aerial Vision-Language
Navigation (i.e., OpenVLN) framework, which could execute language-guided
flight with limited data constraints and enhance long-horizon trajectory
planning capabilities in complex aerial environments. Specifically, we
reconfigure a reinforcement learning framework to optimize the VLM for UAV
navigation tasks, which can efficiently fine-tune VLM by using rule-based
policies under limited training data. Concurrently, we introduce a long-horizon
planner for trajectory synthesis that dynamically generates precise UAV actions
via value-based rewards. To the end, we conduct sufficient navigation
experiments on the TravelUAV benchmark with dataset scaling across diverse
reward settings. Our method demonstrates consistent performance gains of up to
4.34% in Success Rate, 6.19% in Oracle Success Rate, and 4.07% in Success
weighted by Path Length over baseline methods, validating its deployment
efficacy for long-horizon UAV navigation in complex aerial environments.

</details>


### [454] [ExpReS-VLA: Specializing Vision-Language-Action Models Through Experience Replay and Retrieval](https://arxiv.org/abs/2511.06202)
*Shahram Najam Syed,Yatharth Ahuja,Arthur Jakobsson,Jeff Ichnowski*

Main category: cs.RO

TL;DR: ExpReS-VLA通过经验回放和检索方法，专门化预训练的VLA模型，在防止灾难性遗忘的同时实现高效适应新环境，显著提升任务成功率。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在零样本泛化方面表现优异，但难以高效适应新部署环境，而实际应用中在有限任务集上保持高性能比广泛泛化更重要。

Method: 使用冻结视觉骨干网络存储紧凑特征表示而非原始图像-动作对，通过余弦相似度检索相关历史经验指导适应，采用优先经验回放强调成功轨迹，并引入阈值混合对比损失从成功和失败尝试中学习。

Result: 在LIBERO仿真基准上，空间推理任务成功率从82.6%提升至93.1%，长时域任务从61%提升至72.3%；物理机器人实验中，在已见和未见设置下均达到98%成功率，远超基准方法的84.7%和32%。

Conclusion: ExpReS-VLA能够在单GPU上31秒内完成适应，内存使用减少约97%，为实际机器人部署提供了实用高效的解决方案。

Abstract: Vision-Language-Action models such as OpenVLA show impressive zero-shot
generalization across robotic manipulation tasks but often fail to adapt
efficiently to new deployment environments. In many real-world applications,
consistent high performance on a limited set of tasks is more important than
broad generalization. We propose ExpReS-VLA, a method for specializing
pre-trained VLA models through experience replay and retrieval while preventing
catastrophic forgetting. ExpReS-VLA stores compact feature representations from
the frozen vision backbone instead of raw image-action pairs, reducing memory
usage by approximately 97 percent. During deployment, relevant past experiences
are retrieved using cosine similarity and used to guide adaptation, while
prioritized experience replay emphasizes successful trajectories. We also
introduce Thresholded Hybrid Contrastive Loss, which enables learning from both
successful and failed attempts. On the LIBERO simulation benchmark, ExpReS-VLA
improves success rates from 82.6 to 93.1 percent on spatial reasoning tasks and
from 61 to 72.3 percent on long-horizon tasks. On physical robot experiments
with five manipulation tasks, it reaches 98 percent success on both seen and
unseen settings, compared to 84.7 and 32 percent for naive fine-tuning.
Adaptation takes 31 seconds using 12 demonstrations on a single RTX 5090 GPU,
making the approach practical for real robot deployment.

</details>


### [455] [Affordance-Guided Coarse-to-Fine Exploration for Base Placement in Open-Vocabulary Mobile Manipulation](https://arxiv.org/abs/2511.06240)
*Tzu-Jung Lin,Jia-Fong Yeh,Hung-Ting Su,Chung-Yi Lin,Yi-Ting Chen,Winston H. Hsu*

Main category: cs.RO

TL;DR: 提出了一个零样本框架Affordance-Guided Coarse-to-Fine Exploration，用于开放词汇移动机器人操作中的基座位置选择，通过结合视觉语言模型的语义理解和几何可行性来提升任务成功率。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常基于接近度导航而不考虑功能可供性，导致频繁的操作失败。需要一种能够同时考虑语义理解和几何约束的基座位置选择方法。

Method: 构建跨模态表示（Affordance RGB和Obstacle Map+），将语义与空间上下文对齐。利用VLM的粗粒度语义先验指导搜索任务相关区域，并通过几何约束细化位置选择，避免陷入局部最优。

Result: 在五个不同的开放词汇移动操作任务上评估，系统达到85%的成功率，显著优于传统几何规划器和基于VLM的方法。

Conclusion: 该方法展示了功能可供性感知和多模态推理在通用化、指令条件规划中的潜力，为开放词汇移动操作提供了有效解决方案。

Abstract: In open-vocabulary mobile manipulation (OVMM), task success often hinges on
the selection of an appropriate base placement for the robot. Existing
approaches typically navigate to proximity-based regions without considering
affordances, resulting in frequent manipulation failures. We propose
Affordance-Guided Coarse-to-Fine Exploration, a zero-shot framework for base
placement that integrates semantic understanding from vision-language models
(VLMs) with geometric feasibility through an iterative optimization process.
Our method constructs cross-modal representations, namely Affordance RGB and
Obstacle Map+, to align semantics with spatial context. This enables reasoning
that extends beyond the egocentric limitations of RGB perception. To ensure
interaction is guided by task-relevant affordances, we leverage coarse semantic
priors from VLMs to guide the search toward task-relevant regions and refine
placements with geometric constraints, thereby reducing the risk of convergence
to local optima. Evaluated on five diverse open-vocabulary mobile manipulation
tasks, our system achieves an 85% success rate, significantly outperforming
classical geometric planners and VLM-based methods. This demonstrates the
promise of affordance-aware and multimodal reasoning for generalizable,
instruction-conditioned planning in OVMM.

</details>


### [456] [Robust Differentiable Collision Detection for General Objects](https://arxiv.org/abs/2511.06267)
*Jiayi Chen,Wei Zhao,Liangwang Ruan,Baoquan Chen,He Wang*

Main category: cs.RO

TL;DR: 本文提出了一种鲁棒且高效的可微分碰撞检测框架，支持凸面和非凸面物体，通过距离基的一阶随机平滑、自适应采样和等效梯度传输来实现鲁棒的梯度计算。


<details>
  <summary>Details</summary>
Motivation: 传统碰撞检测算法（如GJK+EPA）本质上是不可微分的，阻碍了梯度流，限制了在接触丰富的任务（如抓取和操作）中基于梯度的优化。现有可微分方法仅限于凸面物体且对复杂几何形状缺乏鲁棒性。

Method: 提出了距离基的一阶随机平滑、自适应采样和等效梯度传输技术，构建了一个支持凸面和非凸面物体的可微分碰撞检测框架。

Result: 在DexGraspNet和Objaverse的复杂网格上进行的实验显示，相比现有基线方法有显著改进。

Conclusion: 该方法成功应用于灵巧抓取合成任务，可直接用于提升抓取质量，代码已开源。

Abstract: Collision detection is a core component of robotics applications such as
simulation, control, and planning. Traditional algorithms like GJK+EPA compute
witness points (i.e., the closest or deepest-penetration pairs between two
objects) but are inherently non-differentiable, preventing gradient flow and
limiting gradient-based optimization in contact-rich tasks such as grasping and
manipulation. Recent work introduced efficient first-order randomized smoothing
to make witness points differentiable; however, their direction-based
formulation is restricted to convex objects and lacks robustness for complex
geometries. In this work, we propose a robust and efficient differentiable
collision detection framework that supports both convex and concave objects
across diverse scales and configurations. Our method introduces distance-based
first-order randomized smoothing, adaptive sampling, and equivalent gradient
transport for robust and informative gradient computation. Experiments on
complex meshes from DexGraspNet and Objaverse show significant improvements
over existing baselines. Finally, we demonstrate a direct application of our
method for dexterous grasp synthesis to refine the grasp quality. The code is
available at https://github.com/JYChen18/DiffCollision.

</details>


### [457] [External Photoreflective Tactile Sensing Based on Surface Deformation Measurement](https://arxiv.org/abs/2511.06311)
*Seiichi Yamamoto,Hiroki Ishizuka,Takumi Kawasetsu,Koh Hosoda,Takayuki Kameoka,Kango Yanagida,Takato Horii,Sei Ikeda,Osamu Oshiro*

Main category: cs.RO

TL;DR: 提出了一种基于软机器人机械柔顺性的触觉传感方法，通过外部附加的光反射模块读取硅胶皮肤表面变形来估计接触力，无需嵌入触觉传感器。


<details>
  <summary>Details</summary>
Motivation: 将传感器定位在接触界面之外可以降低损坏风险、保持柔软性，并简化制造和维护过程。相比液体填充或导线嵌入的触觉皮肤，该模块化附加架构增强了耐用性，减少了布线复杂性。

Method: 首先表征光学传感元件和柔顺皮肤，然后确定原型触觉传感器的设计。通过压缩实验验证方法，并演示在软机器人抓手上的集成应用。

Result: 压缩实验显示力输出关系与理论一致，具有单调性、低滞后性、高重复性，且对压痕速度响应小。在软机器人抓手上能可靠检测抓取事件。

Conclusion: 利用表面柔顺性与外部光学模块为软机器人提供力感知，同时保持结构灵活性和可制造性，为机器人应用和安全人机协作铺平了道路。

Abstract: We present a tactile sensing method enabled by the mechanical compliance of
soft robots; an externally attachable photoreflective module reads surface
deformation of silicone skin to estimate contact force without embedding
tactile transducers. Locating the sensor off the contact interface reduces
damage risk, preserves softness, and simplifies fabrication and maintenance. We
first characterize the optical sensing element and the compliant skin,
thendetermine the design of a prototype tactile sensor. Compression experiments
validate the approach, exhibiting a monotonic force output relationship
consistent with theory, low hysteresis, high repeatability over repeated
cycles, and small response indentation speeds. We further demonstrate
integration on a soft robotic gripper, where the module reliably detects grasp
events. Compared with liquid filled or wireembedded tactile skins, the proposed
modular add on architecture enhances durability, reduces wiring complexity, and
supports straightforward deployment across diverse robot geometries. Because
the sensing principle reads skin strain patterns, it also suggests extensions
to other somatosensory cues such as joint angle or actuator state estimation
from surface deformation. Overall, leveraging surface compliance with an
external optical module provides a practical and robust route to equip soft
robots with force perception while preserving structural flexibility and
manufacturability, paving the way for robotic applications and safe human robot
collaboration.

</details>


### [458] [Towards Adaptive Humanoid Control via Multi-Behavior Distillation and Reinforced Fine-Tuning](https://arxiv.org/abs/2511.06371)
*Yingnan Zhao,Xinmiao Wang,Dewei Wang,Xinzhe Liu,Dan Lu,Qilong Han,Peng Liu,Chenjia Bai*

Main category: cs.RO

TL;DR: 提出了Adaptive Humanoid Control (AHC)方法，通过两阶段框架学习跨技能和地形的自适应人形机器人运动控制器，解决了现有方法需要为每个技能单独训练策略、泛化能力差的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的人形机器人运动控制方法主要为每个技能训练独立策略，导致控制器行为特定、泛化能力有限，在复杂地形和多样化场景中表现脆弱。

Method: 采用两阶段框架：1）先训练多个主要运动策略，通过多行为蒸馏获得基础多行为控制器，实现基于环境的行为自适应切换；2）在更多样化地形上收集在线反馈进行强化微调，增强控制器的地形适应性。

Result: 在Unitree G1机器人上的仿真和真实世界实验表明，该方法在各种场景和地形上都表现出强大的适应性。

Conclusion: AHC方法能够有效学习跨技能和地形的自适应人形机器人运动控制，显著提升了在复杂环境中的适应能力。

Abstract: Humanoid robots are promising to learn a diverse set of human-like locomotion
behaviors, including standing up, walking, running, and jumping. However,
existing methods predominantly require training independent policies for each
skill, yielding behavior-specific controllers that exhibit limited
generalization and brittle performance when deployed on irregular terrains and
in diverse situations. To address this challenge, we propose Adaptive Humanoid
Control (AHC) that adopts a two-stage framework to learn an adaptive humanoid
locomotion controller across different skills and terrains. Specifically, we
first train several primary locomotion policies and perform a multi-behavior
distillation process to obtain a basic multi-behavior controller, facilitating
adaptive behavior switching based on the environment. Then, we perform
reinforced fine-tuning by collecting online feedback in performing adaptive
behaviors on more diverse terrains, enhancing terrain adaptability for the
controller. We conduct experiments in both simulation and real-world
experiments in Unitree G1 robots. The results show that our method exhibits
strong adaptability across various situations and terrains. Project website:
https://ahc-humanoid.github.io.

</details>


### [459] [ArtReg: Visuo-Tactile based Pose Tracking and Manipulation of Unseen Articulated Objects](https://arxiv.org/abs/2511.06378)
*Prajval Kumar Murali,Mohsen Kaboli*

Main category: cs.RO

TL;DR: 提出了一种名为ArtReg的视觉-触觉跟踪方法，用于在机器人交互过程中跟踪未知物体（单个、多个或铰接式）的位姿，无需先验几何或运动学知识。


<details>
  <summary>Details</summary>
Motivation: 机器人在真实环境中经常遇到具有复杂结构和铰接部件的未知物体（如门、抽屉、工具等），如何在没有先验知识的情况下感知、跟踪和操作这些物体是机器人学的基本挑战。

Method: ArtReg方法在SE(3)李群中集成视觉-触觉点云，采用无迹卡尔曼滤波器进行点云配准，通过推拉等操作检测铰接关节，并开发了闭环控制器进行目标驱动的铰接物体操作。

Result: 在真实机器人实验中广泛评估了该方法，验证了其在质心变化、低光照条件和挑战性视觉背景下的鲁棒性，在标准铰接物体数据集上相比最先进方法具有更高的位姿精度。

Conclusion: 利用视觉-触觉信息的鲁棒精确位姿跟踪使机器人能够感知和交互未见过的复杂铰接物体（具有旋转或棱柱关节）。

Abstract: Robots operating in real-world environments frequently encounter unknown
objects with complex structures and articulated components, such as doors,
drawers, cabinets, and tools. The ability to perceive, track, and manipulate
these objects without prior knowledge of their geometry or kinematic properties
remains a fundamental challenge in robotics. In this work, we present a novel
method for visuo-tactile-based tracking of unseen objects (single, multiple, or
articulated) during robotic interaction without assuming any prior knowledge
regarding object shape or dynamics. Our novel pose tracking approach termed
ArtReg (stands for Articulated Registration) integrates visuo-tactile point
clouds in an unscented Kalman Filter formulation in the SE(3) Lie Group for
point cloud registration. ArtReg is used to detect possible articulated joints
in objects using purposeful manipulation maneuvers such as pushing or
hold-pulling with a two-robot team. Furthermore, we leverage ArtReg to develop
a closed-loop controller for goal-driven manipulation of articulated objects to
move the object into the desired pose configuration. We have extensively
evaluated our approach on various types of unknown objects through real robot
experiments. We also demonstrate the robustness of our method by evaluating
objects with varying center of mass, low-light conditions, and with challenging
visual backgrounds. Furthermore, we benchmarked our approach on a standard
dataset of articulated objects and demonstrated improved performance in terms
of pose accuracy compared to state-of-the-art methods. Our experiments indicate
that robust and accurate pose tracking leveraging visuo-tactile information
enables robots to perceive and interact with unseen complex articulated objects
(with revolute or prismatic joints).

</details>


### [460] [From Demonstrations to Safe Deployment: Path-Consistent Safety Filtering for Diffusion Policies](https://arxiv.org/abs/2511.06385)
*Ralf Römer,Julian Balletshofer,Jakob Thumm,Marco Pavone,Angela P. Schoellig,Matthias Althoff*

Main category: cs.RO

TL;DR: 提出了路径一致性安全过滤（PACS）方法，为扩散策略提供形式化安全保证，同时保持任务完成性能


<details>
  <summary>Details</summary>
Motivation: 扩散策略在复杂操作任务中表现优异，但无法保证安全行为，外部安全机制会改变动作导致性能下降

Method: 在扩散策略生成的轨迹上执行路径一致性制动，使用基于集合的可达性分析进行实时安全验证

Result: PACS在动态环境中提供形式化安全保证，保持任务成功率，比反应式安全方法任务成功率提升最高68%

Conclusion: PACS方法成功解决了扩散策略的安全问题，同时保持了其优秀的任务完成能力

Abstract: Diffusion policies (DPs) achieve state-of-the-art performance on complex
manipulation tasks by learning from large-scale demonstration datasets, often
spanning multiple embodiments and environments. However, they cannot guarantee
safe behavior, so external safety mechanisms are needed. These, however, alter
actions in ways unseen during training, causing unpredictable behavior and
performance degradation. To address these problems, we propose path-consistent
safety filtering (PACS) for DPs. Our approach performs path-consistent braking
on a trajectory computed from the sequence of generated actions. In this way,
we keep execution consistent with the policy's training distribution,
maintaining the learned, task-completing behavior. To enable a real-time
deployment and handle uncertainties, we verify safety using set-based
reachability analysis. Our experimental evaluation in simulation and on three
challenging real-world human-robot interaction tasks shows that PACS (a)
provides formal safety guarantees in dynamic environments, (b) preserves task
success rates, and (c) outperforms reactive safety approaches, such as control
barrier functions, by up to 68% in terms of task success. Videos are available
at our project website: https://tum-lsy.github.io/pacs/.

</details>


### [461] [Whole-Body Control With Terrain Estimation of A 6-DoF Wheeled Bipedal Robot](https://arxiv.org/abs/2511.06397)
*Cong Wen,Yunfei Li,Kexin Liu,Yixin Qiu,Xuanhong Liao,Tianyu Wang,Dingchuan Liu,Tao Zhang,Ximin Lyu*

Main category: cs.RO

TL;DR: 本文针对轮式双足机器人开发了完整动力学模型和全身控制框架，通过地形估计解决了不平坦地形通行问题


<details>
  <summary>Details</summary>
Motivation: 现有研究大多忽略腿部动力学简化计算，限制了机器人的运动潜力，且机器人在不平坦地形上面临通行挑战

Method: 建立包含闭环动力学和地面接触模型的完整动力学模型，使用LiDAR惯性里程计和改进的主成分分析进行地形估计，采用PD控制和LQR进行姿态控制和平衡控制，使用分层优化方法解决全身控制问题

Result: 通过仿真和真实实验验证了地形估计算法的性能，证明了算法的鲁棒性和在不平坦地形上的通行能力

Conclusion: 所提出的完整动力学模型和全身控制框架有效解决了轮式双足机器人在不平坦地形上的运动控制问题

Abstract: Wheeled bipedal robots have garnered increasing attention in exploration and
inspection. However, most research simplifies calculations by ignoring leg
dynamics, thereby restricting the robot's full motion potential. Additionally,
robots face challenges when traversing uneven terrain. To address the
aforementioned issue, we develop a complete dynamics model and design a
whole-body control framework with terrain estimation for a novel 6 degrees of
freedom wheeled bipedal robot. This model incorporates the closed-loop dynamics
of the robot and a ground contact model based on the estimated ground normal
vector. We use a LiDAR inertial odometry framework and improved Principal
Component Analysis for terrain estimation. Task controllers, including PD
control law and LQR, are employed for pose control and centroidal
dynamics-based balance control, respectively. Furthermore, a hierarchical
optimization approach is used to solve the whole-body control problem. We
validate the performance of the terrain estimation algorithm and demonstrate
the algorithm's robustness and ability to traverse uneven terrain through both
simulation and real-world experiments.

</details>


### [462] [Real Garment Benchmark (RGBench): A Comprehensive Benchmark for Robotic Garment Manipulation featuring a High-Fidelity Scalable Simulator](https://arxiv.org/abs/2511.06434)
*Wenkang Hu,Xincheng Tang,Yanzhi E,Yitong Li,Zhengjie Shu,Wei Li,Huamin Wang,Ruigang Yang*

Main category: cs.RO

TL;DR: RGBench是一个用于机器人衣物操作的综合基准，包含6000多个衣物网格模型、高性能模拟器以及模拟质量评估协议，显著优于现有布料模拟器。


<details>
  <summary>Details</summary>
Motivation: 当前模拟数据在刚性物体机器人操作方面取得了显著进展，但在可变形物体（如衣物）上的应用受到缺乏真实非刚体模拟器的限制。

Method: 开发了RGBench基准，包含多样化的衣物网格模型库、新的高性能模拟器，以及基于真实衣物动力学测量的模拟质量评估协议。

Result: 实验表明，该模拟器大幅优于现有布料模拟器，模拟误差降低20%，同时速度快3倍。

Conclusion: RGBench将公开发布，以加速未来机器人衣物操作的研究。

Abstract: While there has been significant progress to use simulated data to learn
robotic manipulation of rigid objects, applying its success to deformable
objects has been hindered by the lack of both deformable object models and
realistic non-rigid body simulators. In this paper, we present Real Garment
Benchmark (RGBench), a comprehensive benchmark for robotic manipulation of
garments. It features a diverse set of over 6000 garment mesh models, a new
high-performance simulator, and a comprehensive protocol to evaluate garment
simulation quality with carefully measured real garment dynamics. Our
experiments demonstrate that our simulator outperforms currently available
cloth simulators by a large margin, reducing simulation error by 20% while
maintaining a speed of 3 times faster. We will publicly release RGBench to
accelerate future research in robotic garment manipulation. Website:
https://rgbench.github.io/

</details>


### [463] [Sim-to-Real Transfer in Deep Reinforcement Learning for Bipedal Locomotion](https://arxiv.org/abs/2511.06465)
*Lingfan Bao,Tianhu Peng,Chengxu Zhou*

Main category: cs.RO

TL;DR: 本章分析双足机器人深度强化学习中的仿真到现实转移问题，识别仿真差距的主要来源，并提出通过提高仿真器物理保真度和增强策略鲁棒性两种互补方法来解决该问题。


<details>
  <summary>Details</summary>
Motivation: 双足机器人深度强化学习面临仿真到现实转移的挑战，仿真器中的模型不准确导致训练的策略无法在真实环境中有效工作，需要系统性地解决这一关键问题。

Method: 通过分析机器人动力学、接触建模、状态估计和数值求解器等仿真差距来源，提出两种互补策略：提高仿真器物理保真度的模型中心方法，以及通过鲁棒性训练和部署后适应来增强策略弹性的方法。

Result: 建立了一个解决仿真到现实转移问题的战略框架，为开发和评估鲁棒的仿真到现实解决方案提供了清晰的路线图。

Conclusion: 结合提高仿真器保真度和增强策略鲁棒性的双重方法，可以有效解决双足机器人深度强化学习中的仿真到现实转移挑战，为实际应用提供可行路径。

Abstract: This chapter addresses the critical challenge of simulation-to-reality
(sim-to-real) transfer for deep reinforcement learning (DRL) in bipedal
locomotion. After contextualizing the problem within various control
architectures, we dissect the ``curse of simulation'' by analyzing the primary
sources of sim-to-real gap: robot dynamics, contact modeling, state estimation,
and numerical solvers. Building on this diagnosis, we structure the solutions
around two complementary philosophies. The first is to shrink the gap through
model-centric strategies that systematically improve the simulator's physical
fidelity. The second is to harden the policy, a complementary approach that
uses in-simulation robustness training and post-deployment adaptation to make
the policy inherently resilient to model inaccuracies. The chapter concludes by
synthesizing these philosophies into a strategic framework, providing a clear
roadmap for developing and evaluating robust sim-to-real solutions.

</details>


### [464] [A Low-Rank Method for Vision Language Model Hallucination Mitigation in Autonomous Driving](https://arxiv.org/abs/2511.06496)
*Keke Long,Jiacheng Guo,Tianyun Zhang,Hongkai Yu,Xiaopeng Li*

Main category: cs.RO

TL;DR: 提出了一种基于低秩分解的自包含方法，仅使用多个VLM生成的候选描述本身来排序其幻觉程度，无需外部参考或模型访问，在自动驾驶场景中实现87%的幻觉检测准确率。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中使用的视觉语言模型会产生幻觉（虚假细节），但在缺乏真实参考和模型内部访问的情况下，检测和缓解幻觉具有挑战性。

Method: 通过构建句子嵌入矩阵并分解为低秩共识分量和稀疏残差，利用残差大小对描述进行排序，选择残差最小的作为最无幻觉的描述。

Result: 在NuScenes数据集上达到87%的选择准确率，比未过滤基线提高19%，比多智能体辩论方法提高6-10%；推理时间减少51-67%。

Conclusion: 该方法通过稀疏残差大小排序与人类幻觉判断强相关，验证了评分机制的有效性，且易于并行化，适合实时自动驾驶应用。

Abstract: Vision Language Models (VLMs) are increasingly used in autonomous driving to
help understand traffic scenes, but they sometimes produce hallucinations,
which are false details not grounded in the visual input. Detecting and
mitigating hallucinations is challenging when ground-truth references are
unavailable and model internals are inaccessible. This paper proposes a novel
self-contained low-rank approach to automatically rank multiple candidate
captions generated by multiple VLMs based on their hallucination levels, using
only the captions themselves without requiring external references or model
access. By constructing a sentence-embedding matrix and decomposing it into a
low-rank consensus component and a sparse residual, we use the residual
magnitude to rank captions: selecting the one with the smallest residual as the
most hallucination-free. Experiments on the NuScenes dataset demonstrate that
our approach achieves 87% selection accuracy in identifying hallucination-free
captions, representing a 19% improvement over the unfiltered baseline and a
6-10% improvement over multi-agent debate method. The sorting produced by
sparse error magnitudes shows strong correlation with human judgments of
hallucinations, validating our scoring mechanism. Additionally, our method,
which can be easily parallelized, reduces inference time by 51-67% compared to
debate approaches, making it practical for real-time autonomous driving
applications.

</details>


### [465] [Adaptive PID Control for Robotic Systems via Hierarchical Meta-Learning and Reinforcement Learning with Physics-Based Data Augmentation](https://arxiv.org/abs/2511.06500)
*JiaHao Wu,ShengWen Yu*

Main category: cs.RO

TL;DR: 提出了一种结合元学习和强化学习的层次控制框架，用于PID控制器的自动调参，解决了传统手动调参耗时且需要专业知识的问题。


<details>
  <summary>Details</summary>
Motivation: PID控制器在工业机器人中广泛应用，但手动调参过程耗时且需要专业知识。需要一种能够自动适应不同机器人平台的智能调参方法。

Method: 采用分层控制框架：元学习用于PID参数初始化，强化学习用于在线自适应。引入基于物理的数据增强策略，通过系统扰动物理参数生成虚拟机器人配置，提高元学习效率。

Result: 在Franka Panda机械臂上实现16.6%平均改进（6.26° MAE），高负载关节J2改进80.4%。发现优化天花板效应：当元学习存在局部高误差关节时RL效果显著，但在Laikago四足机器人上基线性能均匀时RL无改进。方法在参数不确定性和干扰下表现稳健，仅需10分钟训练时间。

Conclusion: RL的有效性高度依赖于元学习基线质量和误差分布，为分层控制系统设计提供了重要指导。该方法实现了高效、稳健的PID自动调参。

Abstract: Proportional-Integral-Derivative (PID) controllers remain the predominant
choice in industrial robotics due to their simplicity and reliability. However,
manual tuning of PID parameters for diverse robotic platforms is time-consuming
and requires extensive domain expertise. This paper presents a novel
hierarchical control framework that combines meta-learning for PID
initialization and reinforcement learning (RL) for online adaptation. To
address the sample efficiency challenge, a \textit{physics-based data
augmentation} strategy is introduced that generates virtual robot
configurations by systematically perturbing physical parameters, enabling
effective meta-learning with limited real robot data. The proposed approach is
evaluated on two heterogeneous platforms: a 9-DOF Franka Panda manipulator and
a 12-DOF Laikago quadruped robot. Experimental results demonstrate that the
proposed method achieves 16.6\% average improvement on Franka Panda (6.26{\deg}
MAE), with exceptional gains in high-load joints (J2: 80.4\% improvement from
12.36{\deg} to 2.42{\deg}). Critically, this work discovers the
\textit{optimization ceiling effect}: RL achieves dramatic improvements when
meta-learning exhibits localized high-error joints, but provides no benefit
(0.0\%) when baseline performance is uniformly strong, as observed in Laikago.
The method demonstrates robust performance under disturbances (parameter
uncertainty: +19.2\%, no disturbance: +16.6\%, average: +10.0\%) with only 10
minutes of training time. Multi-seed analysis across 100 random initializations
confirms stable performance (4.81+/-1.64\% average). These results establish
that RL effectiveness is highly dependent on meta-learning baseline quality and
error distribution, providing important design guidance for hierarchical
control systems.

</details>


### [466] [Koopman global linearization of contact dynamics for robot locomotion and manipulation enables elaborate control](https://arxiv.org/abs/2511.06515)
*Cormac O'Neill,Jasmine Terrones,H. Harry Asada*

Main category: cs.RO

TL;DR: 该论文提出了一种基于Koopman算子的方法，将机器人接触动力学中的分段非线性问题转化为统一的全局线性模型，从而实现对接触控制的实时凸优化预测控制。


<details>
  <summary>Details</summary>
Motivation: 机器人动态接触控制面临的主要挑战是接触边界处的动力学切换导致非线性优化问题，传统预测控制器难以处理这种非凸问题。

Method: 应用Koopman算子将分段接触动力学嵌入到统一的全局线性模型中，利用粘弹性接触特性实现无近似的控制输入，从而将问题转化为凸优化问题。

Result: 该方法成功实现了腿式机器人的凸模型预测控制，以及机械臂动态推动任务的实时控制，能够发现包含多次接触变化的复杂控制策略。

Conclusion: 该方法不仅适用于机器人控制，还具有广泛的应用前景，能够有效处理接触动力学中的非线性问题。

Abstract: Controlling robots that dynamically engage in contact with their environment
is a pressing challenge. Whether a legged robot making-and-breaking contact
with a floor, or a manipulator grasping objects, contact is everywhere.
Unfortunately, the switching of dynamics at contact boundaries makes control
difficult. Predictive controllers face non-convex optimization problems when
contact is involved. Here, we overcome this difficulty by applying Koopman
operators to subsume the segmented dynamics due to contact changes into a
unified, globally-linear model in an embedding space. We show that viscoelastic
contact at robot-environment interactions underpins the use of Koopman
operators without approximation to control inputs. This methodology enables the
convex Model Predictive Control of a legged robot, and the real-time control of
a manipulator engaged in dynamic pushing. In this work, we show that our method
allows robots to discover elaborate control strategies in real-time over time
horizons with multiple contact changes, and the method is applicable to broad
fields beyond robotics.

</details>


### [467] [CoFineLLM: Conformal Finetuning of LLMs for Language-Instructed Robot Planning](https://arxiv.org/abs/2511.06575)
*Jun Wang,Yevgeniy Vorobeychik,Yiannis Kantaros*

Main category: cs.RO

TL;DR: 提出了CoFineLLM框架，通过CP感知的微调减少LLM规划器的预测集大小和用户干预需求


<details>
  <summary>Details</summary>
Motivation: LLM规划器在长时程任务中可靠性不足，现有方法使用CP保证正确性但会产生过大的预测集，导致频繁人工干预

Method: CoFineLLM——首个CP感知的LLM微调框架，显式优化预测集大小，减少用户干预需求

Result: 在多个语言指令机器人规划任务中，相比不确定性感知和不确定性无关的微调基线，预测集大小和求助率均有持续改进

Conclusion: 该方法在硬件实验中对分布外场景也表现出鲁棒性，为LLM规划器的自主部署提供了有效解决方案

Abstract: Large Language Models (LLMs) have recently emerged as planners for
language-instructed agents, generating sequences of actions to accomplish
natural language tasks. However, their reliability remains a challenge,
especially in long-horizon tasks, since they often produce overconfident yet
wrong outputs. Conformal Prediction (CP) has been leveraged to address this
issue by wrapping LLM outputs into prediction sets that contain the correct
action with a user-defined confidence. When the prediction set is a singleton,
the planner executes that action; otherwise, it requests help from a user. This
has led to LLM-based planners that can ensure plan correctness with a
user-defined probability. However, as LLMs are trained in an
uncertainty-agnostic manner, without awareness of prediction sets, they tend to
produce unnecessarily large sets, particularly at higher confidence levels,
resulting in frequent human interventions limiting autonomous deployment. To
address this, we introduce CoFineLLM (Conformal Finetuning for LLMs), the first
CP-aware finetuning framework for LLM-based planners that explicitly reduces
prediction-set size and, in turn, the need for user interventions. We evaluate
our approach on multiple language-instructed robot planning problems and show
consistent improvements over uncertainty-aware and uncertainty-agnostic
finetuning baselines in terms of prediction-set size, and help rates. Finally,
we demonstrate robustness of our method to out-of-distribution scenarios in
hardware experiments.

</details>


### [468] [Underactuated Biomimetic Autonomous Underwater Vehicle for Ecosystem Monitoring](https://arxiv.org/abs/2511.06578)
*Kaustubh Singh,Shivam Kumar,Shashikant Pawar,Sandeep Manjanna*

Main category: cs.RO

TL;DR: 介绍了一种适用于海洋和淡水环境生态监测的欠驱动仿生水下机器人，包括改进的机械设计和基于强化学习的最小驱动行为。


<details>
  <summary>Details</summary>
Motivation: 开发适用于海洋和淡水环境生态监测的仿生水下机器人，通过最小化驱动实现高效游泳行为。

Method: 提出改进的鱼形机器人机械设计，特别是尾部摆动机制，并在FishGym模拟器中使用强化学习技术学习最小驱动行为。

Result: 初步完成了尾部摆动机制的机械设计，并在模拟器中展示了游泳行为，为后续强化学习测试奠定了基础。

Conclusion: 该欠驱动仿生水下机器人设计为生态监测应用提供了有前景的解决方案，强化学习方法有望实现高效的最小驱动游泳行为。

Abstract: In this paper, we present an underactuated biomimetic underwater robot that
is suitable for ecosystem monitoring in both marine and freshwater
environments. We present an updated mechanical design for a fish-like robot and
propose minimal actuation behaviors learned using reinforcement learning
techniques. We present our preliminary mechanical design of the tail
oscillation mechanism and illustrate the swimming behaviors on FishGym
simulator, where the reinforcement learning techniques will be tested on

</details>


### [469] [How Do VLAs Effectively Inherit from VLMs?](https://arxiv.org/abs/2511.06619)
*Chuheng Zhang,Rushuai Yang,Xiaoyu Chen,Kaixin Wang,Li Zhao,Yi Chen,Jiang Bian*

Main category: cs.RO

TL;DR: 提出GrinningFace诊断基准，通过表情符号桌面操作任务评估VLA模型从VLM继承先验知识的能力，为开发可泛化具身AI系统提供指导


<details>
  <summary>Details</summary>
Motivation: 解决VLA模型如何有效继承VLM先验知识的关键问题，表情符号在互联网数据中普遍存在但在机器人数据中缺失，是理想的测试代理

Method: 在模拟环境和真实机器人上实现表情符号桌面操作任务，比较参数高效微调、VLM冻结、联合训练、离散动作预测和潜在动作预测等技术

Result: 系统评估表明保持VLM先验对VLA泛化能力至关重要

Conclusion: 建立了开发真正可泛化具身AI系统的研究指南

Abstract: Vision-language-action (VLA) models hold the promise to attain generalizable
embodied control. To achieve this, a pervasive paradigm is to leverage the rich
vision-semantic priors of large vision-language models (VLMs). However, the
fundamental question persists: How do VLAs effectively inherit the prior
knowledge from VLMs? To address this critical question, we introduce a
diagnostic benchmark, GrinningFace, an emoji tabletop manipulation task where
the robot arm is asked to place objects onto printed emojis corresponding to
language instructions. This task design is particularly revealing -- knowledge
associated with emojis is ubiquitous in Internet-scale datasets used for VLM
pre-training, yet emojis themselves are largely absent from standard robotics
datasets. Consequently, they provide a clean proxy: successful task completion
indicates effective transfer of VLM priors to embodied control. We implement
this diagnostic task in both simulated environment and a real robot, and
compare various promising techniques for knowledge transfer. Specifically, we
investigate the effects of parameter-efficient fine-tuning, VLM freezing,
co-training, predicting discretized actions, and predicting latent actions.
Through systematic evaluation, our work not only demonstrates the critical
importance of preserving VLM priors for the generalization of VLA but also
establishes guidelines for future research in developing truly generalizable
embodied AI systems.

</details>


### [470] [Rapidly Learning Soft Robot Control via Implicit Time-Stepping](https://arxiv.org/abs/2511.06667)
*Andrew Choi,Dezhong Tong*

Main category: cs.RO

TL;DR: 本文提出了一种基于隐式时间步进的软体机器人快速策略学习方法，使用DisMech仿真器实现了比传统方法快6-40倍的仿真速度，同时保持了精度。


<details>
  <summary>Details</summary>
Motivation: 软体机器人仿真框架稀缺且计算成本高，导致策略学习不可行，而刚性机器人仿真已成熟。

Method: 采用DisMech隐式软体仿真器，引入delta自然曲率控制方法，与Elastica框架进行对比实验。

Result: 隐式时间步进在500个并行环境中，非接触情况下速度提升6倍，接触丰富场景提升40倍，且仿真精度不受影响。

Conclusion: 隐式时间步进为软体机器人策略学习提供了显著的速度优势，实现了速度与精度的双重提升。

Abstract: With the explosive growth of rigid-body simulators, policy learning in
simulation has become the de facto standard for most rigid morphologies. In
contrast, soft robotic simulation frameworks remain scarce and are seldom
adopted by the soft robotics community. This gap stems partly from the lack of
easy-to-use, general-purpose frameworks and partly from the high computational
cost of accurately simulating continuum mechanics, which often renders policy
learning infeasible. In this work, we demonstrate that rapid soft robot policy
learning is indeed achievable via implicit time-stepping. Our simulator of
choice, DisMech, is a general-purpose, fully implicit soft-body simulator
capable of handling both soft dynamics and frictional contact. We further
introduce delta natural curvature control, a method analogous to delta joint
position control in rigid manipulators, providing an intuitive and effective
means of enacting control for soft robot learning. To highlight the benefits of
implicit time-stepping and delta curvature control, we conduct extensive
comparisons across four diverse soft manipulator tasks against one of the most
widely used soft-body frameworks, Elastica. With implicit time-stepping,
parallel stepping of 500 environments achieves up to 6x faster speeds for
non-contact cases and up to 40x faster for contact-rich scenarios. Finally, a
comprehensive sim-to-sim gap evaluation--training policies in one simulator and
evaluating them in another--demonstrates that implicit time-stepping provides a
rare free lunch: dramatic speedups achieved without sacrificing accuracy.

</details>


### [471] [Programmable Telescopic Soft Pneumatic Actuators for Deployable and Shape Morphing Soft Robots](https://arxiv.org/abs/2511.06673)
*Joel Kemp,Andre Farinha,David Howard,Krishna Manaswi Digumarti,Josh Pinskier*

Main category: cs.RO

TL;DR: 本文提出了一种参数化的软体致动器PTSPA，通过参数化几何生成器实现定制化设计，探索了设计空间并建立了关键参数与性能的清晰关系，展示了在可部署软体四足机器人中的应用。


<details>
  <summary>Details</summary>
Motivation: 软体机器人具有丰富的自由形态和连续体特性，但目前缺乏有效利用这种设计自由度的方法。参数化设计集为可处理的模块化软体机器人提供了途径。

Method: 提出了可编程伸缩软体气动致动器（PTSPA），引入参数化几何生成器从高级输入定制致动器模型，通过半自动化实验和系统参数探索来研究设计空间。

Result: 表征了致动器的伸缩/弯曲、膨胀和刚度特性，揭示了关键设计参数与性能之间的明确关系，并在可部署软体四足机器人中成功应用。

Conclusion: PTSPA为可部署和形状变形结构提供了新的设计范式，特别适用于需要大长度变化的场景。

Abstract: Soft Robotics presents a rich canvas for free-form and continuum devices
capable of exerting forces in any direction and transforming between arbitrary
configurations. However, there is no current way to tractably and directly
exploit the design freedom due to the curse of dimensionality. Parameterisable
sets of designs offer a pathway towards tractable, modular soft robotics that
appropriately harness the behavioural freeform of soft structures to create
rich embodied behaviours. In this work, we present a parametrised class of soft
actuators, Programmable Telescopic Soft Pneumatic Actuators (PTSPAs). PTSPAs
expand axially on inflation for deployable structures and manipulation in
challenging confined spaces. We introduce a parametric geometry generator to
customise actuator models from high-level inputs, and explore the new design
space through semi-automated experimentation and systematic exploration of key
parameters. Using it we characterise the actuators' extension/bending,
expansion, and stiffness and reveal clear relationships between key design
parameters and performance. Finally we demonstrate the application of the
actuators in a deployable soft quadruped whose legs deploy to walk, enabling
automatic adaptation to confined spaces. PTSPAs present new design paradigm for
deployable and shape morphing structures and wherever large length changes are
required.

</details>


### [472] [Physically-Grounded Goal Imagination: Physics-Informed Variational Autoencoder for Self-Supervised Reinforcement Learning](https://arxiv.org/abs/2511.06745)
*Lan Thi Ha Nguyen,Kien Ton Manh,Anh Do Duc,Nam Pham Hai*

Main category: cs.RO

TL;DR: 提出PI-RIG方法，通过增强的物理信息变分自编码器将物理约束集成到VAE训练中，生成物理一致且可达的目标，解决现有方法生成物理不可行目标的问题。


<details>
  <summary>Details</summary>
Motivation: 现有自监督目标条件强化学习方法（如RIG）使用VAE在潜在空间中生成目标，但存在生成物理不可行目标的问题，影响学习效率。

Method: PI-RIG方法核心是增强的物理信息变分自编码器（Enhanced p3-VAE），将潜在空间显式分离为控制物体动力学的物理变量和捕捉视觉外观的环境因素，并通过微分方程约束和守恒定律强制物理一致性。

Result: 实验表明，这种物理信息目标生成显著提高了提议目标的质量，在视觉机器人操作任务（包括到达、推动和抓放场景）中实现了更有效的探索和更好的技能获取。

Conclusion: 通过将物理约束直接集成到目标生成过程中，PI-RIG能够生成尊重基本物理原理的物理一致且可达的目标，从而提升机器人自主技能获取的效果。

Abstract: Self-supervised goal-conditioned reinforcement learning enables robots to
autonomously acquire diverse skills without human supervision. However, a
central challenge is the goal setting problem: robots must propose feasible and
diverse goals that are achievable in their current environment. Existing
methods like RIG (Visual Reinforcement Learning with Imagined Goals) use
variational autoencoder (VAE) to generate goals in a learned latent space but
have the limitation of producing physically implausible goals that hinder
learning efficiency. We propose Physics-Informed RIG (PI-RIG), which integrates
physical constraints directly into the VAE training process through a novel
Enhanced Physics-Informed Variational Autoencoder (Enhanced p3-VAE), enabling
the generation of physically consistent and achievable goals. Our key
innovation is the explicit separation of the latent space into physics
variables governing object dynamics and environmental factors capturing visual
appearance, while enforcing physical consistency through differential equation
constraints and conservation laws. This enables the generation of physically
consistent and achievable goals that respect fundamental physical principles
such as object permanence, collision constraints, and dynamic feasibility.
Through extensive experiments, we demonstrate that this physics-informed goal
generation significantly improves the quality of proposed goals, leading to
more effective exploration and better skill acquisition in visual robotic
manipulation tasks including reaching, pushing, and pick-and-place scenarios.

</details>


### [473] [Semi-distributed Cross-modal Air-Ground Relative Localization](https://arxiv.org/abs/2511.06749)
*Weining Lu,Deer Bin,Lian Ma,Ming Ma,Zhihao Ma,Xiangyang Chen,Longfei Wang,Yixiao Feng,Zhouxian Jiang,Yongliang Shi,Bin Liang*

Main category: cs.RO

TL;DR: 提出了一种半分布式跨模态空地相对定位框架，通过解耦相对定位与状态估计，实现了高效、准确且灵活的相对定位。


<details>
  <summary>Details</summary>
Motivation: 当前机器人相对定位方法主要采用分布式多机器人SLAM系统，传感器配置相同且与所有机器人状态估计紧密耦合，限制了灵活性和准确性。

Method: UGV和UAV独立执行SLAM并提取深度学习关键点和全局描述符。UGV使用LiDAR、相机和IMU进行局部BA优化，采用两阶段优化策略：先优化从LIO插值的相机位姿，再估计UGV与UAV的相对相机位姿。使用基于深度学习的描述符实现增量闭环检测。

Result: 实验结果表明该方法在准确性和效率方面表现优异，通信带宽可控制在0.3 Mbps以下，相比传统方法仅传输关键点像素和描述符。

Conclusion: 该方法为空地协同任务提供了一种高效、准确且灵活的相对定位解决方案，代码和数据将公开。

Abstract: Efficient, accurate, and flexible relative localization is crucial in
air-ground collaborative tasks. However, current approaches for robot relative
localization are primarily realized in the form of distributed multi-robot SLAM
systems with the same sensor configuration, which are tightly coupled with the
state estimation of all robots, limiting both flexibility and accuracy. To this
end, we fully leverage the high capacity of Unmanned Ground Vehicle (UGV) to
integrate multiple sensors, enabling a semi-distributed cross-modal air-ground
relative localization framework. In this work, both the UGV and the Unmanned
Aerial Vehicle (UAV) independently perform SLAM while extracting deep
learning-based keypoints and global descriptors, which decouples the relative
localization from the state estimation of all agents. The UGV employs a local
Bundle Adjustment (BA) with LiDAR, camera, and an IMU to rapidly obtain
accurate relative pose estimates. The BA process adopts sparse keypoint
optimization and is divided into two stages: First, optimizing camera poses
interpolated from LiDAR-Inertial Odometry (LIO), followed by estimating the
relative camera poses between the UGV and UAV. Additionally, we implement an
incremental loop closure detection algorithm using deep learning-based
descriptors to maintain and retrieve keyframes efficiently. Experimental
results demonstrate that our method achieves outstanding performance in both
accuracy and efficiency. Unlike traditional multi-robot SLAM approaches that
transmit images or point clouds, our method only transmits keypoint pixels and
their descriptors, effectively constraining the communication bandwidth under
0.3 Mbps. Codes and data will be publicly available on
https://github.com/Ascbpiac/cross-model-relative-localization.git.

</details>


### [474] [SlotVLA: Towards Modeling of Object-Relation Representations in Robotic Manipulation](https://arxiv.org/abs/2511.06754)
*Taisei Hanyu,Nhat Chung,Huy Le,Toan Nguyen,Yuki Ikebe,Anthony Gunderman,Duy Nguyen Ho Minh,Khoa Vo,Tung Kieu,Kashu Yamazaki,Chase Rainwater,Anh Nguyen,Ngan Le*

Main category: cs.RO

TL;DR: 本文探索了基于对象和对象关系的紧凑表示作为多任务机器人操作的基础，提出了LIBERO+数据集和SlotVLA框架，实现了更结构化、高效和可解释的视觉运动控制。


<details>
  <summary>Details</summary>
Motivation: 现有机器人多任务模型依赖密集嵌入，将对象和背景线索纠缠在一起，存在效率和可解释性问题。受人类推理离散对象及其关系的启发，研究对象关系中心表示作为更结构化、高效和可解释的视觉运动控制途径。

Method: 1）提出LIBERO+数据集，提供对象中心标注（边界框、掩码标签和实例级时序跟踪）；2）提出SlotVLA框架，包含基于槽注意力的视觉标记器、关系中心解码器和LLM驱动的动作生成模块。

Result: 在LIBERO+上的实验表明，对象中心槽和对象关系槽表示大幅减少了所需视觉标记数量，同时保持了竞争力的泛化性能。

Conclusion: LIBERO+和SlotVLA为推进对象关系中心的机器人操作提供了紧凑、可解释且有效的基础。

Abstract: Inspired by how humans reason over discrete objects and their relationships,
we explore whether compact object-centric and object-relation representations
can form a foundation for multitask robotic manipulation. Most existing robotic
multitask models rely on dense embeddings that entangle both object and
background cues, raising concerns about both efficiency and interpretability.
In contrast, we study object-relation-centric representations as a pathway to
more structured, efficient, and explainable visuomotor control. Our
contributions are two-fold. First, we introduce LIBERO+, a fine-grained
benchmark dataset designed to enable and evaluate object-relation reasoning in
robotic manipulation. Unlike prior datasets, LIBERO+ provides object-centric
annotations that enrich demonstrations with box- and mask-level labels as well
as instance-level temporal tracking, supporting compact and interpretable
visuomotor representations. Second, we propose SlotVLA, a slot-attention-based
framework that captures both objects and their relations for action decoding.
It uses a slot-based visual tokenizer to maintain consistent temporal object
representations, a relation-centric decoder to produce task-relevant
embeddings, and an LLM-driven module that translates these embeddings into
executable actions. Experiments on LIBERO+ demonstrate that object-centric slot
and object-relation slot representations drastically reduce the number of
required visual tokens, while providing competitive generalization. Together,
LIBERO+ and SlotVLA provide a compact, interpretable, and effective foundation
for advancing object-relation-centric robotic manipulation.

</details>


### [475] [Human-Level Actuation for Humanoids](https://arxiv.org/abs/2511.06796)
*MD-Nazmus Sunbeam*

Main category: cs.RO

TL;DR: 提出一个量化评估人形机器人驱动系统是否达到"人类水平"的综合框架，包括标准化关节坐标系、人类等效包络和人类水平驱动评分三个核心组件。


<details>
  <summary>Details</summary>
Motivation: 当前人形机器人领域常声称达到"人类水平"驱动能力，但缺乏可量化的比较标准。峰值扭矩或速度规格无法反映任务相关姿态和速率下的综合性能。

Method: 1）DoF图谱标准化关节坐标系和运动范围；2）人类等效包络(HEE)评估机器人是否能在相同关节角度和速率下同时满足人类扭矩和功率要求；3）人类水平驱动评分(HLAS)综合六个物理因素进行量化评分。

Result: 开发了详细的测量协议，包括测力法、电功率监测和热测试，可通过可重复实验获得所有HLAS输入。示例展示了多关节人形机器人的HLAS计算。

Conclusion: 该框架既可作为人形机器人开发的设计规范，也可作为比较驱动系统的基准标准，所有组件均基于已发表的人类生物力学数据。

Abstract: Claims that humanoid robots achieve ``human-level'' actuation are common but
rarely quantified. Peak torque or speed specifications tell us little about
whether a joint can deliver the right combination of torque, power, and
endurance at task-relevant postures and rates. We introduce a comprehensive
framework that makes ``human-level'' measurable and comparable across systems.
Our approach has three components. First, a kinematic \emph{DoF atlas}
standardizes joint coordinate systems and ranges of motion using ISB-based
conventions, ensuring that human and robot joints are compared in the same
reference frames. Second, \emph{Human-Equivalence Envelopes (HEE)} define
per-joint requirements by measuring whether a robot meets human torque
\emph{and} power simultaneously at the same joint angle and rate $(q,\omega)$,
weighted by positive mechanical work in task-specific bands (walking, stairs,
lifting, reaching, and hand actions). Third, the \emph{Human-Level Actuation
Score (HLAS)} aggregates six physically grounded factors: workspace coverage
(ROM and DoF), HEE coverage, torque-mode bandwidth, efficiency, and thermal
sustainability. We provide detailed measurement protocols using dynamometry,
electrical power monitoring, and thermal testing that yield every HLAS input
from reproducible experiments. A worked example demonstrates HLAS computation
for a multi-joint humanoid, showing how the score exposes actuator trade-offs
(gearing ratio versus bandwidth and efficiency) that peak-torque specifications
obscure. The framework serves as both a design specification for humanoid
development and a benchmarking standard for comparing actuation systems, with
all components grounded in published human biomechanics data.

</details>


### [476] [Vision-Aided Online A* Path Planning for Efficient and Safe Navigation of Service Robots](https://arxiv.org/abs/2511.06801)
*Praveen Kumar,Tushar Sandhan*

Main category: cs.RO

TL;DR: 提出了一种将轻量级语义感知模块与实时A*路径规划器紧密集成的框架，使低成本机器人能够在复杂环境中基于上下文重要性进行导航，而不仅仅是物理尺寸。


<details>
  <summary>Details</summary>
Motivation: 传统导航系统依赖昂贵的LiDAR，虽然几何精确但缺乏语义感知能力，无法区分重要物品（如办公室文件）和无害杂物，导致两者都被视为可穿越的物理障碍。

Method: 采用轻量级语义分割模型识别用户定义的视觉约束，将这些语义约束投影为非几何障碍物到全局地图中，并与几何数据融合，通过在线A*规划器实现实时路径规划。

Result: 在高保真仿真和真实机器人平台上的实验证明，该框架能够实现鲁棒的实时性能，使低成本机器人能够安全导航复杂环境并尊重传统规划器无法识别的关键视觉线索。

Conclusion: 该研究成功地将语义感知集成到实时路径规划中，解决了传统导航系统的语义盲点问题，为低成本机器人在人机环境中的部署提供了可行方案。

Abstract: The deployment of autonomous service robots in human-centric environments is
hindered by a critical gap in perception and planning. Traditional navigation
systems rely on expensive LiDARs that, while geometrically precise, are seman-
tically unaware, they cannot distinguish a important document on an office
floor from a harmless piece of litter, treating both as physically traversable.
While advanced semantic segmentation exists, no prior work has successfully
integrated this visual intelligence into a real-time path planner that is
efficient enough for low-cost, embedded hardware. This paper presents a frame-
work to bridge this gap, delivering context-aware navigation on an affordable
robotic platform. Our approach centers on a novel, tight integration of a
lightweight perception module with an online A* planner. The perception system
employs a semantic segmentation model to identify user-defined visual
constraints, enabling the robot to navigate based on contextual importance
rather than physical size alone. This adaptability allows an operator to define
what is critical for a given task, be it sensitive papers in an office or
safety lines in a factory, thus resolving the ambiguity of what to avoid. This
semantic perception is seamlessly fused with geometric data. The identified
visual constraints are projected as non-geometric obstacles onto a global map
that is continuously updated from sensor data, enabling robust navigation
through both partially known and unknown environments. We validate our
framework through extensive experiments in high-fidelity simulations and on a
real-world robotic platform. The results demonstrate robust, real-time
performance, proving that a cost- effective robot can safely navigate complex
environments while respecting critical visual cues invisible to traditional
planners.

</details>


### [477] [Vision-Based System Identification of a Quadrotor](https://arxiv.org/abs/2511.06839)
*Selim Ahmet Iz,Mustafa Unel*

Main category: cs.RO

TL;DR: 本文探讨了基于视觉的系统辨识技术在四旋翼建模与控制中的应用，通过灰箱建模和机载视觉系统验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决四旋翼建模中推力和阻力系数的复杂性和局限性问题，探索视觉技术在提升四旋翼性能方面的潜力。

Method: 采用灰箱建模方法处理不确定性，设计基于机载视觉系统数据的LQR控制器，通过实验验证模型一致性。

Result: 模型间表现一致，验证了基于视觉的系统辨识技术的有效性，展示了其在四旋翼性能提升方面的应用前景。

Conclusion: 视觉技术能有效增强四旋翼建模与控制，为未来性能优化、故障检测和决策过程研究提供了新方向。

Abstract: This paper explores the application of vision-based system identification
techniques in quadrotor modeling and control. Through experiments and analysis,
we address the complexities and limitations of quadrotor modeling, particularly
in relation to thrust and drag coefficients. Grey-box modeling is employed to
mitigate uncertainties, and the effectiveness of an onboard vision system is
evaluated. An LQR controller is designed based on a system identification model
using data from the onboard vision system. The results demonstrate consistent
performance between the models, validating the efficacy of vision based system
identification. This study highlights the potential of vision-based techniques
in enhancing quadrotor modeling and control, contributing to improved
performance and operational capabilities. Our findings provide insights into
the usability and consistency of these techniques, paving the way for future
research in quadrotor performance enhancement, fault detection, and
decision-making processes.

</details>


### [478] [Multi-Agent AI Framework for Road Situation Detection and C-ITS Message Generation](https://arxiv.org/abs/2511.06892)
*Kailin Tong,Selim Solmaz,Kenan Mujkic,Gottfried Allmer,Bo Leng*

Main category: cs.RO

TL;DR: 提出多智能体AI框架，结合MLLMs和视觉感知进行道路状况监控，在自定义数据集上评估Gemini模型，发现2.5版本虽能力更强但在检测准确性和语义理解上表现不如2.0版本。


<details>
  <summary>Details</summary>
Motivation: 传统道路状况检测方法在预定义场景下表现良好，但在未知场景中失效且缺乏语义解释能力，这对可靠的交通推荐至关重要。

Method: 开发多智能体AI框架，集成多模态大语言模型和基于视觉的感知系统，处理摄像头数据并协调专门智能体进行状况检测、距离估计、决策制定和C-ITS消息生成。

Result: 在103张图像数据集上评估显示100%召回率和完美消息模式正确性，但存在误报检测问题，且在车道数、行驶车道状态和原因代码方面性能下降。Gemini-2.5-Flash在检测准确性和语义理解上不如2.0版本，且延迟更高。

Conclusion: 研究结果激励进一步开发专门针对智能交通应用优化的专用LLMs或MLLMs。

Abstract: Conventional road-situation detection methods achieve strong performance in
predefined scenarios but fail in unseen cases and lack semantic interpretation,
which is crucial for reliable traffic recommendations. This work introduces a
multi-agent AI framework that combines multimodal large language models (MLLMs)
with vision-based perception for road-situation monitoring. The framework
processes camera feeds and coordinates dedicated agents for situation
detection, distance estimation, decision-making, and Cooperative Intelligent
Transport System (C-ITS) message generation. Evaluation is conducted on a
custom dataset of 103 images extracted from 20 videos of the TAD dataset. Both
Gemini-2.0-Flash and Gemini-2.5-Flash were evaluated. The results show 100\%
recall in situation detection and perfect message schema correctness; however,
both models suffer from false-positive detections and have reduced performance
in terms of number of lanes, driving lane status and cause code. Surprisingly,
Gemini-2.5-Flash, though more capable in general tasks, underperforms
Gemini-2.0-Flash in detection accuracy and semantic understanding and incurs
higher latency (Table II). These findings motivate further work on fine-tuning
specialized LLMs or MLLMs tailored for intelligent transportation applications.

</details>


### [479] [Integration of Visual SLAM into Consumer-Grade Automotive Localization](https://arxiv.org/abs/2511.06919)
*Luis Diener,Jens Kalkkuhl,Markus Enzweiler*

Main category: cs.RO

TL;DR: 提出一种融合视觉SLAM与车辆横向动力学模型的框架，用于在线校准陀螺仪，提高消费级车辆的定位精度


<details>
  <summary>Details</summary>
Motivation: 当前消费级车辆依赖轮式里程计和IMU进行自运动估计，但存在系统误差和校准限制。视觉SLAM在机器人领域成熟，但在汽车定位中的应用尚未充分探索

Method: 融合视觉SLAM与车辆横向动力学模型，实现真实驾驶条件下的在线陀螺仪校准

Result: 视觉融合显著提高了陀螺仪校准精度，在公开基准测试中优于现有最先进方法

Conclusion: 该方法为提高汽车定位精度提供了有前景的技术路径

Abstract: Accurate ego-motion estimation in consumer-grade vehicles currently relies on
proprioceptive sensors, i.e. wheel odometry and IMUs, whose performance is
limited by systematic errors and calibration. While visual-inertial SLAM has
become a standard in robotics, its integration into automotive ego-motion
estimation remains largely unexplored. This paper investigates how visual SLAM
can be integrated into consumer-grade vehicle localization systems to improve
performance. We propose a framework that fuses visual SLAM with a lateral
vehicle dynamics model to achieve online gyroscope calibration under realistic
driving conditions. Experimental results demonstrate that vision-based
integration significantly improves gyroscope calibration accuracy and thus
enhances overall localization performance, highlighting a promising path toward
higher automotive localization accuracy. We provide results on both proprietary
and public datasets, showing improved performance and superior localization
accuracy on a public benchmark compared to state-of-the-art methods.

</details>


### [480] [Raspi$^2$USBL: An open-source Raspberry Pi-Based Passive Inverted Ultra-Short Baseline Positioning System for Underwater Robotics](https://arxiv.org/abs/2511.06998)
*Jin Huang,Yingqiang Wang,Ying Chen*

Main category: cs.RO

TL;DR: Raspi²USBL是一个开源的、基于树莓派的被动倒置超短基线定位系统，为水下机器人研究提供低成本解决方案，在实验验证中实现了0.1%的斜距精度和0.1°的方位角精度。


<details>
  <summary>Details</summary>
Motivation: 解决水下精确定位难题，因为GNSS信号无法穿透海面，需要为水下机器人研究提供低成本且易于获取的定位解决方案。

Method: 采用模块化硬件架构，包括水听器阵列、多通道前置放大器、恒温晶体振荡器、树莓派5和DAQ板，结合开源C++软件框架实现高精度时钟同步、实时信号处理和波束成形。

Result: 在消声水池、淡水湖和开放海域试验中验证，斜距精度优于0.1%，方位角精度在0.1°以内，在1.3公里距离内保持稳定性能。

Conclusion: 低成本可复现硬件能够提供研究级的水下定位精度，开源平台降低了水下机器人实验室的入门门槛，促进了水下声学导航和群体机器人技术的协作创新。

Abstract: Precise underwater positioning remains a fundamental challenge for underwater
robotics since global navigation satellite system (GNSS) signals cannot
penetrate the sea surface. This paper presents Raspi$^2$USBL, an open-source,
Raspberry Pi-based passive inverted ultra-short baseline (piUSBL) positioning
system designed to provide a low-cost and accessible solution for underwater
robotic research. The system comprises a passive acoustic receiver and an
active beacon. The receiver adopts a modular hardware architecture that
integrates a hydrophone array, a multichannel preamplifier, an oven-controlled
crystal oscillator (OCXO), a Raspberry Pi 5, and an MCC-series data acquisition
(DAQ) board. Apart from the Pi 5, OCXO, and MCC board, the beacon comprises an
impedance-matching network, a power amplifier, and a transmitting transducer.
An open-source C++ software framework provides high-precision clock
synchronization and triggering for one-way travel-time (OWTT) messaging, while
performing real-time signal processing, including matched filtering, array
beamforming, and adaptive gain control, to estimate the time of flight (TOF)
and direction of arrival (DOA) of received signals. The Raspi$^2$USBL system
was experimentally validated in an anechoic tank, freshwater lake, and open-sea
trials. Results demonstrate a slant-range accuracy better than 0.1%, a bearing
accuracy within 0.1$^\circ$, and stable performance over operational distances
up to 1.3 km. These findings confirm that low-cost, reproducible hardware can
deliver research-grade underwater positioning accuracy. By releasing both the
hardware and software as open-source, Raspi$^2$USBL provides a unified
reference platform that lowers the entry barrier for underwater robotics
laboratories, fosters reproducibility, and promotes collaborative innovation in
underwater acoustic navigation and swarm robotics.

</details>


### [481] [HDCNet: A Hybrid Depth Completion Network for Grasping Transparent and Reflective Objects](https://arxiv.org/abs/2511.07081)
*Guanghu Xie,Mingxu Li,Songwei Wu,Yang Liu,Zongwu Xie,Baoshi Cao,Hong Liu*

Main category: cs.RO

TL;DR: HDCNet是一个用于透明和反射物体深度感知的新型深度补全网络，结合了Transformer、CNN和Mamba架构的优势，在多个公开数据集上达到SOTA性能，并将机器人抓取成功率提升60%。


<details>
  <summary>Details</summary>
Motivation: 传统深度传感器在透明和反射表面上无法提供可靠测量，限制了机器人在感知和抓取任务中的性能。

Method: 设计双分支Transformer-CNN编码器提取模态特定特征，浅层引入轻量级多模态融合模块，网络瓶颈处开发Transformer-Mamba混合融合模块，实现高层语义和全局上下文信息的深度融合。

Result: 在多个公开数据集上实现最先进的深度补全性能，机器人抓取实验显示对透明和反射物体的抓取成功率显著提升，最高达60%的增长。

Conclusion: HDCNet有效解决了透明和反射物体的深度感知难题，显著提升了机器人抓取性能，为相关应用提供了可靠解决方案。

Abstract: Depth perception of transparent and reflective objects has long been a
critical challenge in robotic manipulation.Conventional depth sensors often
fail to provide reliable measurements on such surfaces, limiting the
performance of robots in perception and grasping tasks. To address this issue,
we propose a novel depth completion network,HDCNet,which integrates the
complementary strengths of Transformer,CNN and Mamba
architectures.Specifically,the encoder is designed as a dual-branch
Transformer-CNN framework to extract modality-specific features. At the shallow
layers of the encoder, we introduce a lightweight multimodal fusion module to
effectively integrate low-level features. At the network bottleneck,a
Transformer-Mamba hybrid fusion module is developed to achieve deep integration
of high-level semantic and global contextual information, significantly
enhancing depth completion accuracy and robustness. Extensive evaluations on
multiple public datasets demonstrate that HDCNet achieves
state-of-the-art(SOTA) performance in depth completion
tasks.Furthermore,robotic grasping experiments show that HDCNet substantially
improves grasp success rates for transparent and reflective objects,achieving
up to a 60% increase.

</details>


### [482] [Dynamics-Decoupled Trajectory Alignment for Sim-to-Real Transfer in Reinforcement Learning for Autonomous Driving](https://arxiv.org/abs/2511.07155)
*Thomas Steinecker,Alexander Bienemann,Denis Trescher,Thorsten Luettel,Mirko Maehlisch*

Main category: cs.RO

TL;DR: 提出了一种通过空间和时间对齐策略将运动规划与车辆控制解耦的框架，实现RL从仿真到现实的零样本迁移


<details>
  <summary>Details</summary>
Motivation: 强化学习在机器人领域有潜力，但部署到真实车辆上仍面临挑战，主要由于车辆动力学复杂性和仿真与现实之间的不匹配，如轮胎特性、路面条件、空气动力扰动和车辆负载等因素使得难以准确建模真实世界动力学

Method: 使用运动学自行车模型在仿真中训练RL智能体输出连续控制动作，然后将其行为蒸馏为预测轨迹的智能体生成有限范围内的自车轨迹，实现虚拟和真实车辆的同步。部署时使用Stanley控制器控制横向动力学，通过自适应更新机制维持纵向对齐以补偿虚拟和真实轨迹之间的偏差

Result: 在真实车辆上验证了该方法，证明所提出的对齐策略能够实现基于RL的运动规划从仿真到现实的鲁棒零样本迁移

Conclusion: 成功将高层轨迹生成与低层车辆控制解耦，为RL在真实车辆上的部署提供了可行方案

Abstract: Reinforcement learning (RL) has shown promise in robotics, but deploying RL
on real vehicles remains challenging due to the complexity of vehicle dynamics
and the mismatch between simulation and reality. Factors such as tire
characteristics, road surface conditions, aerodynamic disturbances, and vehicle
load make it infeasible to model real-world dynamics accurately, which hinders
direct transfer of RL agents trained in simulation. In this paper, we present a
framework that decouples motion planning from vehicle control through a spatial
and temporal alignment strategy between a virtual vehicle and the real system.
An RL agent is first trained in simulation using a kinematic bicycle model to
output continuous control actions. Its behavior is then distilled into a
trajectory-predicting agent that generates finite-horizon ego-vehicle
trajectories, enabling synchronization between virtual and real vehicles. At
deployment, a Stanley controller governs lateral dynamics, while longitudinal
alignment is maintained through adaptive update mechanisms that compensate for
deviations between virtual and real trajectories. We validate our approach on a
real vehicle and demonstrate that the proposed alignment strategy enables
robust zero-shot transfer of RL-based motion planning from simulation to
reality, successfully decoupling high-level trajectory generation from
low-level vehicle control.

</details>


### [483] [Automated Generation of Continuous-Space Roadmaps for Routing Mobile Robot Fleets](https://arxiv.org/abs/2511.07175)
*Marvin Rüdt,Constantin Enke,Kai Furmans*

Main category: cs.RO

TL;DR: 提出了一种自动化路线图生成方法，结合连续空间操作、站点间运输需求和最小距离约束，为移动机器人车队提供高效路径规划


<details>
  <summary>Details</summary>
Motivation: 解决现有路径规划方法在几何精度和实际约束之间的差距，提升物流系统中移动机器人车队的路由效率和系统吞吐量

Method: 结合自由空间离散化、运输需求驱动的K最短路径优化和路径平滑技术，生成针对物流应用的定制化路线图

Result: 在多个物流用例中，该方法在结构复杂度、冗余度和路径长度方面均优于传统基线方法（4连接网格、8连接网格和随机采样）

Conclusion: 该方法能够生成高效且鲁棒的移动机器人车队路线图，显著提升物流系统的路由性能

Abstract: Efficient routing of mobile robot fleets is crucial in intralogistics, where
delays and deadlocks can substantially reduce system throughput. Roadmap
design, specifying feasible transport routes, directly affects fleet
coordination and computational performance. Existing approaches are either
grid-based, compromising geometric precision, or continuous-space approaches
that disregard practical constraints. This paper presents an automated roadmap
generation approach that bridges this gap by operating in continuous-space,
integrating station-to-station transport demand and enforcing minimum distance
constraints for nodes and edges. By combining free space discretization,
transport demand-driven $K$-shortest-path optimization, and path smoothing, the
approach produces roadmaps tailored to intralogistics applications. Evaluation
across multiple intralogistics use cases demonstrates that the proposed
approach consistently outperforms established baselines (4-connected grid,
8-connected grid, and random sampling), achieving lower structural complexity,
higher redundancy, and near-optimal path lengths, enabling efficient and robust
routing of mobile robot fleets.

</details>


### [484] [Robotic versus Human Teleoperation for Remote Ultrasound](https://arxiv.org/abs/2511.07275)
*David Black,Septimiu Salcudean*

Main category: cs.RO

TL;DR: 本文比较了人类远程操作与机器人远程操作在远程超声检查中的性能差异，发现两者在完成时间和位置精度上无显著差异，人类远程操作在力控制一致性方面表现更好，且更具实用性和可及性。


<details>
  <summary>Details</summary>
Motivation: 解决农村地区缺乏超声检查专业人员的医疗资源不平等问题，通过比较人类远程操作和机器人远程操作两种远程超声技术的性能，为小型社区提供更实用的解决方案。

Method: 通过实验比较人类远程操作和机器人远程操作的性能指标，包括完成时间、位置跟踪精度和力控制一致性，同时评估实际应用方面的设置时间和灵活性。

Result: 人类远程操作在完成时间（平均差异1.8%）和位置精度（平均差异0.5%）上与机器人远程操作无显著统计学差异，且在力控制应用方面表现更一致。

Conclusion: 人类远程操作在性能上与机器人远程操作相当，但具有更低的成本和复杂性，更适合小型社区的医疗应用，为解决农村地区医疗资源不平等提供了实用方案。

Abstract: Diagnostic medical ultrasound is widely used, safe, and relatively low cost
but requires a high degree of expertise to acquire and interpret the images.
Personnel with this expertise are often not available outside of larger cities,
leading to difficult, costly travel and long wait times for rural populations.
To address this issue, tele-ultrasound techniques are being developed,
including robotic teleoperation and recently human teleoperation, in which a
novice user is remotely guided in a hand-over-hand manner through mixed reality
to perform an ultrasound exam. These methods have not been compared, and their
relative strengths are unknown. Human teleoperation may be more practical than
robotics for small communities due to its lower cost and complexity, but this
is only relevant if the performance is comparable. This paper therefore
evaluates the differences between human and robotic teleoperation, examining
practical aspects such as setup time and flexibility and experimentally
comparing performance metrics such as completion time, position tracking, and
force consistency. It is found that human teleoperation does not lead to
statistically significant differences in completion time or position accuracy,
with mean differences of 1.8% and 0.5%, respectively, and provides more
consistent force application despite being substantially more practical and
accessible.

</details>


### [485] [PlanT 2.0: Exposing Biases and Structural Flaws in Closed-Loop Driving](https://arxiv.org/abs/2511.07292)
*Simon Gerstenecker,Andreas Geiger,Katrin Renz*

Main category: cs.RO

TL;DR: PlanT 2.0是一个轻量级的物体中心规划变换器，用于CARLA自动驾驶研究。论文通过系统性地扰动模型输入来深入分析模型失败原因，发现场景理解不足、专家行为僵化导致可利用捷径、对固定专家轨迹过拟合等问题，主张转向数据为中心的开发。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶研究过于关注基准性能和方法创新，缺乏对模型失败、偏见和捷径学习的深入分析。虽然容易观察到模型失败的情况，但难以理解根本原因，因此需要系统研究来揭示底层问题。

Method: 引入PlanT 2.0，一个轻量级的物体中心规划变换器。通过物体级表示实现可控分析，可以轻松扰动输入（如改变物体位置或增减物体）。针对CARLA Leaderboard 2.0的挑战性场景，对PlanT进行了多项升级。

Result: 在Longest6 v2、Bench2Drive和CARLA验证路线上实现了最先进的性能。分析揭示了关键失败原因：障碍物多样性不足导致场景理解缺乏、僵化的专家行为产生可利用捷径、对固定专家轨迹过拟合。

Conclusion: 基于研究发现，主张转向数据为中心的开发，重点关注更丰富、更鲁棒、偏见更少的数据集。开源了代码和模型以促进社区发展。

Abstract: Most recent work in autonomous driving has prioritized benchmark performance
and methodological innovation over in-depth analysis of model failures, biases,
and shortcut learning. This has led to incremental improvements without a deep
understanding of the current failures. While it is straightforward to look at
situations where the model fails, it is hard to understand the underlying
reason. This motivates us to conduct a systematic study, where inputs to the
model are perturbed and the predictions observed. We introduce PlanT 2.0, a
lightweight, object-centric planning transformer designed for autonomous
driving research in CARLA. The object-level representation enables controlled
analysis, as the input can be easily perturbed (e.g., by changing the location
or adding or removing certain objects), in contrast to sensor-based models. To
tackle the scenarios newly introduced by the challenging CARLA Leaderboard 2.0,
we introduce multiple upgrades to PlanT, achieving state-of-the-art performance
on Longest6 v2, Bench2Drive, and the CARLA validation routes. Our analysis
exposes insightful failures, such as a lack of scene understanding caused by
low obstacle diversity, rigid expert behaviors leading to exploitable
shortcuts, and overfitting to a fixed set of expert trajectories. Based on
these findings, we argue for a shift toward data-centric development, with a
focus on richer, more robust, and less biased datasets. We open-source our code
and model at https://github.com/autonomousvision/plant2.

</details>


### [486] [Exact Smooth Reformulations for Trajectory Optimization Under Signal Temporal Logic Specifications](https://arxiv.org/abs/2511.07375)
*Shaohang Han,Joris Verhagen,Jana Tumova*

Main category: cs.RO

TL;DR: 提出了一种基于信号时序逻辑（STL）的运动规划方法，通过精确重构max和min算子实现可微优化问题


<details>
  <summary>Details</summary>
Motivation: STL是一种用于指定时空需求的有用形式化语言，但现有的STL合成方法存在近似误差或不可微问题

Method: 将STL合成建模为轨迹优化问题，利用STL鲁棒性语义，引入max和min算子的精确重构方法

Result: 该方法精确、平滑且可靠，在数值仿真中验证了其实际性能

Conclusion: 提出的方法为STL运动规划提供了一种精确可微的解决方案，具有良好的实用性能

Abstract: We study motion planning under Signal Temporal Logic (STL), a useful
formalism for specifying spatial-temporal requirements. We pose STL synthesis
as a trajectory optimization problem leveraging the STL robustness semantics.
To obtain a differentiable problem without approximation error, we introduce an
exact reformulation of the max and min operators. The resulting method is
exact, smooth, and sound. We validate it in numerical simulations,
demonstrating its practical performance.

</details>


### [487] [Residual Rotation Correction using Tactile Equivariance](https://arxiv.org/abs/2511.07381)
*Yizhe Zhu,Zhang Ye,Boce Hu,Haibo Zhao,Yu Qi,Dian Wang,Robert Platt*

Main category: cs.RO

TL;DR: EquiTac是一个利用SO(2)对称性提升视觉触觉策略学习样本效率和泛化能力的框架，通过SO(2)-等变网络实现实时旋转校正，在少量训练样本下实现零样本泛化。


<details>
  <summary>Details</summary>
Motivation: 触觉数据收集成本高昂，因此样本效率成为开发视觉触觉策略的关键要求。现有方法在接触丰富的操作任务中缺乏对触觉等变性的显式编码。

Method: 1. 从视觉触觉传感器的RGB输入重建表面法向量
2. 使用SO(2)-等变网络预测残差旋转动作
3. 在测试时增强基础视觉运动策略，实现实时旋转校正

Result: 在真实机器人上，EquiTac仅需极少训练样本就能准确实现未见过的抓取方向的零样本泛化，而基线方法即使使用更多训练数据也会失败。

Conclusion: 这是首个显式编码触觉等变性进行策略学习的方法，提供了一个轻量级、对称感知的模块，显著提升了接触丰富任务的可靠性。

Abstract: Visuotactile policy learning augments vision-only policies with tactile
input, facilitating contact-rich manipulation. However, the high cost of
tactile data collection makes sample efficiency the key requirement for
developing visuotactile policies. We present EquiTac, a framework that exploits
the inherent SO(2) symmetry of in-hand object rotation to improve sample
efficiency and generalization for visuotactile policy learning. EquiTac first
reconstructs surface normals from raw RGB inputs of vision-based tactile
sensors, so rotations of the normal vector field correspond to in-hand object
rotations. An SO(2)-equivariant network then predicts a residual rotation
action that augments a base visuomotor policy at test time, enabling real-time
rotation correction without additional reorientation demonstrations. On a real
robot, EquiTac accurately achieves robust zero-shot generalization to unseen
in-hand orientations with very few training samples, where baselines fail even
with more training data. To our knowledge, this is the first tactile learning
method to explicitly encode tactile equivariance for policy learning, yielding
a lightweight, symmetry-aware module that improves reliability in contact-rich
tasks.

</details>


### [488] [Unified Humanoid Fall-Safety Policy from a Few Demonstrations](https://arxiv.org/abs/2511.07407)
*Zhengjie Xu,Ye Li,Kwan-yee Lin,Stella X. Yu*

Main category: cs.RO

TL;DR: 本文提出了一种统一策略，将跌倒预防、冲击缓解和快速恢复整合到一个策略中，通过融合稀疏人类演示、强化学习和自适应扩散记忆，实现人形机器人安全自主的跌倒-恢复全过程。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅关注跌倒的孤立方面（避免跌倒、控制下降或站立恢复），缺乏对真实跌倒情况的综合应对策略。人形机器人需要完整的跌倒-恢复安全解决方案。

Method: 融合稀疏人类演示与强化学习，结合自适应扩散记忆的安全反应机制，学习自适应全身行为，统一处理跌倒预防、冲击缓解和快速恢复。

Result: 在仿真和Unitree G1机器人上的实验显示，实现了稳健的仿真到现实迁移，降低了冲击力，并在各种干扰下实现了一致的快速恢复。

Conclusion: 该方法为实现更安全、更具韧性的人形机器人在真实环境中的部署提供了有效途径。

Abstract: Falling is an inherent risk of humanoid mobility. Maintaining stability is
thus a primary safety focus in robot control and learning, yet no existing
approach fully averts loss of balance. When instability does occur, prior work
addresses only isolated aspects of falling: avoiding falls, choreographing a
controlled descent, or standing up afterward. Consequently, humanoid robots
lack integrated strategies for impact mitigation and prompt recovery when real
falls defy these scripts. We aim to go beyond keeping balance to make the
entire fall-and-recovery process safe and autonomous: prevent falls when
possible, reduce impact when unavoidable, and stand up when fallen. By fusing
sparse human demonstrations with reinforcement learning and an adaptive
diffusion-based memory of safe reactions, we learn adaptive whole-body
behaviors that unify fall prevention, impact mitigation, and rapid recovery in
one policy. Experiments in simulation and on a Unitree G1 demonstrate robust
sim-to-real transfer, lower impact forces, and consistently fast recovery
across diverse disturbances, pointing towards safer, more resilient humanoids
in real environments. Videos are available at https://firm2025.github.io/.

</details>


### [489] [Using Vision Language Models as Closed-Loop Symbolic Planners for Robotic Applications: A Control-Theoretic Perspective](https://arxiv.org/abs/2511.07410)
*Hao Wang,Sathwik Karnik,Bea Lim,Somil Bansal*

Main category: cs.RO

TL;DR: 该论文研究了如何从控制理论视角使用视觉语言模型作为闭环符号规划器，重点分析了控制视野和热启动对规划性能的影响。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型和视觉语言模型已广泛用于具身符号规划，但它们在闭环符号规划中的有效使用方法尚未充分探索，且这些模型作为黑箱会产生不可预测或代价高昂的错误，给机器人高层规划带来挑战。

Method: 设计并进行了受控实验，研究控制视野和热启动如何影响VLM符号规划器的性能，以获得适用于VLM作为闭环符号规划器的广泛见解。

Result: 通过实验获得了关于控制视野和热启动对VLM符号规划器性能影响的具体见解，并提出了改进建议。

Conclusion: 从控制理论角度为使用VLM作为闭环符号规划器提供了实验依据和性能改进建议，有助于提升VLM在机器人规划中的应用效果。

Abstract: Large Language Models (LLMs) and Vision Language Models (VLMs) have been
widely used for embodied symbolic planning. Yet, how to effectively use these
models for closed-loop symbolic planning remains largely unexplored. Because
they operate as black boxes, LLMs and VLMs can produce unpredictable or costly
errors, making their use in high-level robotic planning especially challenging.
In this work, we investigate how to use VLMs as closed-loop symbolic planners
for robotic applications from a control-theoretic perspective. Concretely, we
study how the control horizon and warm-starting impact the performance of VLM
symbolic planners. We design and conduct controlled experiments to gain
insights that are broadly applicable to utilizing VLMs as closed-loop symbolic
planners, and we discuss recommendations that can help improve the performance
of VLM symbolic planners.

</details>


### [490] [Robot Learning from a Physical World Model](https://arxiv.org/abs/2511.07416)
*Jiageng Mao,Sicheng He,Hao-Ning Wu,Yang You,Shuyang Sun,Zhicheng Wang,Yanan Bao,Huizhong Chen,Leonidas Guibas,Vitor Guizilini,Howard Zhou,Yue Wang*

Main category: cs.RO

TL;DR: PhysWorld是一个通过物理世界建模实现机器人从视频生成中学习的框架，将视频生成与物理世界重建相结合，将生成的视频运动转化为物理上准确的动作。


<details>
  <summary>Details</summary>
Motivation: 现有的视频生成模型可以从语言命令和图像合成逼真的视觉演示，为机器人学习提供了强大的训练信号来源，但直接将像素运动重定向到机器人忽略了物理约束，导致操作不准确。

Method: PhysWorld方法结合视频生成与物理世界重建：给定单张图像和任务命令，生成任务条件视频并从中重建底层物理世界，通过基于对象的残差强化学习将生成的视频运动转化为物理上准确的动作。

Result: 在多样化真实世界任务上的实验表明，PhysWorld相比之前的方法显著提高了操作准确性。

Conclusion: PhysWorld将隐式视觉指导转化为物理上可执行的机器人轨迹，无需真实机器人数据收集，实现了零样本可泛化的机器人操作。

Abstract: We introduce PhysWorld, a framework that enables robot learning from video
generation through physical world modeling. Recent video generation models can
synthesize photorealistic visual demonstrations from language commands and
images, offering a powerful yet underexplored source of training signals for
robotics. However, directly retargeting pixel motions from generated videos to
robots neglects physics, often resulting in inaccurate manipulations. PhysWorld
addresses this limitation by coupling video generation with physical world
reconstruction. Given a single image and a task command, our method generates
task-conditioned videos and reconstructs the underlying physical world from the
videos, and the generated video motions are grounded into physically accurate
actions through object-centric residual reinforcement learning with the
physical world model. This synergy transforms implicit visual guidance into
physically executable robotic trajectories, eliminating the need for real robot
data collection and enabling zero-shot generalizable robotic manipulation.
Experiments on diverse real-world tasks demonstrate that PhysWorld
substantially improves manipulation accuracy compared to previous approaches.
Visit \href{https://pointscoder.github.io/PhysWorld_Web/}{the project webpage}
for details.

</details>


### [491] [Lightning Grasp: High Performance Procedural Grasp Synthesis with Contact Fields](https://arxiv.org/abs/2511.07418)
*Zhao-Heng Yin,Pieter Abbeel*

Main category: cs.RO

TL;DR: Lightning Grasp是一个高性能的程序化抓取合成算法，实现了比现有方法快几个数量级的速度提升，能够为不规则工具类物体生成无监督抓取。


<details>
  <summary>Details</summary>
Motivation: 尽管经过多年研究，实时多样化的灵巧手抓取合成仍然是机器人和计算机图形学中未解决的核心挑战。现有方法存在需要精心调整能量函数和敏感初始化等局限性。

Method: 通过关键洞察：使用简单高效的数据结构——接触场（Contact Field）将复杂几何计算与搜索过程解耦。这种抽象降低了问题复杂度，实现了前所未有的程序化搜索速度。

Result: 算法实现了数量级的速度提升，避免了先前方法的许多局限性，能够为不规则工具类物体进行无监督抓取生成。

Conclusion: 该方法在抓取合成领域取得了突破性进展，作者开源了系统以推动机器人操作领域的进一步创新。

Abstract: Despite years of research, real-time diverse grasp synthesis for dexterous
hands remains an unsolved core challenge in robotics and computer graphics. We
present Lightning Grasp, a novel high-performance procedural grasp synthesis
algorithm that achieves orders-of-magnitude speedups over state-of-the-art
approaches, while enabling unsupervised grasp generation for irregular,
tool-like objects. The method avoids many limitations of prior approaches, such
as the need for carefully tuned energy functions and sensitive initialization.
This breakthrough is driven by a key insight: decoupling complex geometric
computation from the search process via a simple, efficient data structure -
the Contact Field. This abstraction collapses the problem complexity, enabling
a procedural search at unprecedented speeds. We open-source our system to
propel further innovation in robotic manipulation.

</details>
