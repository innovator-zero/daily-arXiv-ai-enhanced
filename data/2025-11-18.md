<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 295]
- [cs.LG](#cs.LG) [Total: 281]
- [cs.RO](#cs.RO) [Total: 55]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Psychological stress during Examination and its estimation by handwriting in answer script](https://arxiv.org/abs/2511.11633)
*Abhijeet Kumar,Chetan Agarwal,Pronoy B. Neogi,Mayank Goswami*

Main category: cs.CV

TL;DR: 本文提出了一种结合笔迹学和人工智能的方法，通过分析学生手写考试文本来量化心理压力水平，使用OCR和基于Transformer的情感分析模型生成压力指数。


<details>
  <summary>Details</summary>
Motivation: 传统评分系统无法深入理解学生在考试期间的认知和情感状态，需要一种能够量化心理压力的创新方法。

Method: 采用高分辨率图像处理、TrOCR技术和基于RoBERTa模型的情感熵融合，通过五模型投票机制和无监督异常检测确保系统鲁棒性。

Result: 开发出一个能够生成数值化压力指数的创新框架，在学术取证领域具有应用价值。

Conclusion: 该方法为评估学生考试期间的心理状态提供了数据驱动的解决方案，超越了传统评分系统的局限性。

Abstract: This research explores the fusion of graphology and artificial intelligence to quantify psychological stress levels in students by analyzing their handwritten examination scripts. By leveraging Optical Character Recognition and transformer based sentiment analysis models, we present a data driven approach that transcends traditional grading systems, offering deeper insights into cognitive and emotional states during examinations. The system integrates high resolution image processing, TrOCR, and sentiment entropy fusion using RoBERTa based models to generate a numerical Stress Index. Our method achieves robustness through a five model voting mechanism and unsupervised anomaly detection, making it an innovative framework in academic forensics.

</details>


### [2] [Real-time pothole detection with onboard sensors and camera on vehicles](https://arxiv.org/abs/2511.11643)
*Aswath Muthuselvam,Jeevak Raj S,Mohanaprasad K*

Main category: cs.CV

TL;DR: 本文提出了一种基于车载传感器和SVM分类器的实时道路坑洼检测方法，在2公里路段上实现了98.1%的检测准确率


<details>
  <summary>Details</summary>
Motivation: 随着车辆数量增加，频繁评估道路状况对交通流畅至关重要。道路上的微小裂缝可能因温度变化和车辆压力发展成大坑洼，需要实时检测

Method: 使用车载传感器采集数据，采用SVM分类器进行坑洼检测

Result: 在包含26个坑洼的2公里本地道路上测试，达到了98.1%的检测准确率

Conclusion: 该方法能够有效实时检测道路坑洼，为大规模坑洼管理提供数据支持

Abstract: Road conditions play an important role in our everyday commute. With the proliferating number of vehicles on the road each year, it has become necessary to access the road conditions very frequently, this would ensure that the traffic also flows smoothly. Even the smallest crack in the road could be easily be chipped into a large pothole due to changing surface temperatures of the road and from the force of vehicles riding over it. In this paper, we have addressed how we could better identify these potholes in realtime with the help of onboard sensors in vehicles so that the data could be useful for analysis and better management of potholes on a large scale. For the implementation, we used an SVM classifier to detect potholes, we achieved 98.1% accuracy based on data collected from a local road for about 2 km which had 26 potholes distributed along the road. Code is available at: https://github.com/aswathselvam/Potholes

</details>


### [3] [A Method for Identifying Farmland System Habitat Types Based on the Dynamic-Weighted Feature Fusion Network Model](https://arxiv.org/abs/2511.11659)
*Kesong Zheng,Zhi Song,Peizhou Li,Shuyi Yao,Zhenxing Bian*

Main category: cs.CV

TL;DR: 针对耕地生态系统缺乏标准化栖息地分类系统的问题，本研究开发了包含15类耕地系统栖息地的超高清遥感图像数据集，并提出动态加权特征融合网络（DWFF-Net），通过自适应多层级特征融合实现亚米级精度的栖息地制图。


<details>
  <summary>Details</summary>
Motivation: 当前耕地生态系统缺乏标准化的栖息地分类系统，现有模型无法有效整合语义和纹理特征，导致多尺度栖息地分割精度不足和边界模糊。

Method: 提出动态加权特征融合网络（DWFF-Net），编码器使用冻结参数的DINOv3提取基础特征，引入数据级自适应动态加权策略进行特征融合，解码器包含动态权重计算网络实现多层特征融合，采用混合损失函数优化训练。

Result: 在构建的数据集上，模型达到平均交并比（mIoU）0.6979和F1分数0.8049，分别比基线网络提升0.021和0.0161。消融实验证实多层特征融合的有效性，特别是对田埂等微栖息地类别的IoU提升明显。

Conclusion: 本研究建立了基于自适应多层特征融合的耕地系统栖息地识别框架，能够以低成本实现亚米级精度的栖息地制图，为耕地景观的细粒度栖息地监测提供技术支持。

Abstract: Addressing the current lack of a standardized habitat classification system for cultivated land ecosystems, incomplete coverage of habitat types, and the inability of existing models to effectively integrate semantic and texture features-resulting in insufficient segmentation accuracy and blurred boundaries for multi-scale habitats (e.g., large-scale field plots and micro-habitats)-this study developed a comprehensively annotated ultra-high-resolution remote sensing image dataset encompassing 15 categories of cultivated land system habitats. Furthermore, we propose a Dynamic-Weighted Feature Fusion Network (DWFF-Net). The encoder of this model utilizes a frozen-parameter DINOv3 to extract foundational features. By analyzing the relationships between different category images and feature maps, we introduce a data-level adaptive dynamic weighting strategy for feature fusion. The decoder incorporates a dynamic weight computation network to achieve thorough integration of multi-layer features, and a hybrid loss function is adopted to optimize model training. Experimental results on the constructed dataset demonstrate that the proposed model achieves a mean Intersection over Union (mIoU) of 0.6979 and an F1-score of 0.8049, outperforming the baseline network by 0.021 and 0.0161, respectively. Ablation studies further confirm the complementary nature of multi-layer feature fusion, which effectively improves the IoU for micro-habitat categories such as field ridges. This study establishes a habitat identification framework for cultivated land systems based on adaptive multi-layer feature fusion, enabling sub-meter precision habitat mapping at a low cost and providing robust technical support for fine-grained habitat monitoring in cultivated landscapes.

</details>


### [4] [AGENet: Adaptive Edge-aware Geodesic Distance Learning for Few-Shot Medical Image Segmentation](https://arxiv.org/abs/2511.11662)
*Ziyuan Gao*

Main category: cs.CV

TL;DR: AGENet是一个用于医学图像分割的新型框架，通过边缘感知的测地距离学习来改善少样本分割中的边界精度问题，在计算效率高的同时提升分割准确性。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割需要大量标注数据，现有少样本分割方法在医学图像边界划分上表现不佳，特别是当解剖结构相似且缺乏足够空间上下文时。

Method: AGENet结合三个核心组件：边缘感知测地距离学习模块（通过迭代快速行进细化）、自适应原型提取（通过空间加权聚合捕获全局结构和局部边界细节）、自适应参数学习（自动适应不同器官特性）。

Result: 在多个医学影像数据集上的实验表明，该方法在减少边界误差方面优于现有最先进方法，同时保持计算效率。

Conclusion: AGENet适合需要精确分割但标注数据有限的临床应用，通过轻量级几何建模有效利用医学结构的可预测几何模式。

Abstract: Medical image segmentation requires large annotated datasets, creating a significant bottleneck for clinical applications. While few-shot segmentation methods can learn from minimal examples, existing approaches demonstrate suboptimal performance in precise boundary delineation for medical images, particularly when anatomically similar regions appear without sufficient spatial context. We propose AGENet (Adaptive Geodesic Edge-aware Network), a novel framework that incorporates spatial relationships through edge-aware geodesic distance learning. Our key insight is that medical structures follow predictable geometric patterns that can guide prototype extraction even with limited training data. Unlike methods relying on complex architectural components or heavy neural networks, our approach leverages computationally lightweight geometric modeling. The framework combines three main components: (1) An edge-aware geodesic distance learning module that respects anatomical boundaries through iterative Fast Marching refinement, (2) adaptive prototype extraction that captures both global structure and local boundary details via spatially-weighted aggregation, and (3) adaptive parameter learning that automatically adjusts to different organ characteristics. Extensive experiments across diverse medical imaging datasets demonstrate improvements over state-of-the-art methods. Notably, our method reduces boundary errors compared to existing approaches while maintaining computational efficiency, making it highly suitable for clinical applications requiring precise segmentation with limited annotated data.

</details>


### [5] [EPSegFZ: Efficient Point Cloud Semantic Segmentation for Few- and Zero-Shot Scenarios with Language Guidance](https://arxiv.org/abs/2511.11700)
*Jiahui Wang,Haiyue Zhu,Haoren Guo,Abdullah Al Mamun,Cheng Xiang,Tong Heng Lee*

Main category: cs.CV

TL;DR: 提出了一种无需预训练的高效点云语义分割网络EPSegFZ，通过引入ProERA模块、DRPE跨注意力机制和LGPE模块，在少样本和零样本场景下显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有少样本3D点云语义分割方法过度依赖预训练阶段，限制了模型的灵活性和适应性。同时，现有方法主要关注视觉信息而忽视了文本标注等有用数据，导致性能受限且缺乏零样本能力。

Method: EPSegFZ网络包含三个核心组件：1）Prototype-Enhanced Registers Attention模块和基于Dual Relative Positional Encoding的跨注意力机制，用于无需预训练的特征提取和查询-原型对应关系构建；2）Language-Guided Prototype Embedding模块，有效利用支持集中的文本信息提升少样本性能并实现零样本推理。

Result: 在S3DIS和ScanNet基准测试中，该方法分别比现有最优方法提升了5.68%和3.82%的性能。

Conclusion: EPSegFZ通过创新的模块设计成功解决了预训练依赖问题，并充分利用了多模态信息，在少样本和零样本3D点云语义分割任务中取得了显著优势。

Abstract: Recent approaches for few-shot 3D point cloud semantic segmentation typically require a two-stage learning process, i.e., a pre-training stage followed by a few-shot training stage. While effective, these methods face overreliance on pre-training, which hinders model flexibility and adaptability. Some models tried to avoid pre-training yet failed to capture ample information. In addition, current approaches focus on visual information in the support set and neglect or do not fully exploit other useful data, such as textual annotations. This inadequate utilization of support information impairs the performance of the model and restricts its zero-shot ability. To address these limitations, we present a novel pre-training-free network, named Efficient Point Cloud Semantic Segmentation for Few- and Zero-shot scenarios. Our EPSegFZ incorporates three key components. A Prototype-Enhanced Registers Attention (ProERA) module and a Dual Relative Positional Encoding (DRPE)-based cross-attention mechanism for improved feature extraction and accurate query-prototype correspondence construction without pre-training. A Language-Guided Prototype Embedding (LGPE) module that effectively leverages textual information from the support set to improve few-shot performance and enable zero-shot inference. Extensive experiments show that our method outperforms the state-of-the-art method by 5.68% and 3.82% on the S3DIS and ScanNet benchmarks, respectively.

</details>


### [6] [Task-Aware 3D Affordance Segmentation via 2D Guidance and Geometric Refinement](https://arxiv.org/abs/2511.11702)
*Lian He,Meng Liu,Qilang Ye,Yu Zhou,Xiang Deng,Gangyi Ding*

Main category: cs.CV

TL;DR: TASA是一个几何优化的3D场景级可操作性分割框架，通过联合利用2D语义线索和3D几何推理，在粗到细的方式下实现高效准确的可操作性检测。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注对象级可操作性或将2D预测简单提升到3D，忽略了点云中的丰富几何结构信息且计算成本高。需要解决语义推理和空间定位的挑战。

Method: TASA框架包含任务感知的2D可操作性检测模块（识别可操作点并指导任务相关视图选择）和3D可操作性细化模块（整合2D语义先验与局部3D几何信息）。

Result: 在SceneFun3D数据集上的实验表明，TASA在场景级可操作性分割的准确性和效率方面显著优于基线方法。

Conclusion: TASA通过几何优化方法有效解决了3D场景级可操作性理解问题，为具身智能体在复杂环境中的交互提供了有力支持。

Abstract: Understanding 3D scene-level affordances from natural language instructions is essential for enabling embodied agents to interact meaningfully in complex environments. However, this task remains challenging due to the need for semantic reasoning and spatial grounding. Existing methods mainly focus on object-level affordances or merely lift 2D predictions to 3D, neglecting rich geometric structure information in point clouds and incurring high computational costs. To address these limitations, we introduce Task-Aware 3D Scene-level Affordance segmentation (TASA), a novel geometry-optimized framework that jointly leverages 2D semantic cues and 3D geometric reasoning in a coarse-to-fine manner. To improve the affordance detection efficiency, TASA features a task-aware 2D affordance detection module to identify manipulable points from language and visual inputs, guiding the selection of task-relevant views. To fully exploit 3D geometric information, a 3D affordance refinement module is proposed to integrate 2D semantic priors with local 3D geometry, resulting in accurate and spatially coherent 3D affordance masks. Experiments on SceneFun3D demonstrate that TASA significantly outperforms the baselines in both accuracy and efficiency in scene-level affordance segmentation.

</details>


### [7] [LE-CapsNet: A Light and Enhanced Capsule Network](https://arxiv.org/abs/2511.11708)
*Pouya Shiri,Amirali Baniasadi*

Main category: cs.CV

TL;DR: LE-CapsNet是一种轻量级、增强且更准确的Capsule Network变体，相比原始CapsNet在保持重叠类别检测优势的同时，显著提升了推理速度和准确率。


<details>
  <summary>Details</summary>
Motivation: 原始CapsNet虽然具有优于CNN的重叠类别检测和变换图像识别能力，但存在速度慢、参数多、资源消耗大以及准确率低于CNN的问题。

Method: 提出LE-CapsNet作为CapsNet的轻量级增强版本，通过优化网络结构减少参数数量，同时保持胶囊网络的特性。

Result: 使用380万参数，在CIFAR-10数据集上达到76.73%准确率，推理速度比CapsNet快4倍；在AffNIST数据集上达到94.3%准确率，优于CapsNet的90.52%。

Conclusion: LE-CapsNet在保持CapsNet优势的同时，显著提升了性能效率，为胶囊网络的实际应用提供了可行的解决方案。

Abstract: Capsule Network (CapsNet) classifier has several advantages over CNNs, including better detection of images containing overlapping categories and higher accuracy on transformed images. Despite the advantages, CapsNet is slow due to its different structure. In addition, CapsNet is resource-hungry, includes many parameters and lags in accuracy compared to CNNs. In this work, we propose LE-CapsNet as a light, enhanced and more accurate variant of CapsNet. Using 3.8M weights, LECapsNet obtains 76.73% accuracy on the CIFAR-10 dataset while performing inference 4x faster than CapsNet. In addition, our proposed network is more robust at detecting images with affine transformations compared to CapsNet. We achieve 94.3% accuracy on the AffNIST dataset (compared to CapsNet 90.52%).

</details>


### [8] [Target-Balanced Score Distillation](https://arxiv.org/abs/2511.11710)
*Zhou Xu,Qi Wang,Yuxiao Yang,Luyuan Zhang,Zhang Liang,Yang Li*

Main category: cs.CV

TL;DR: 本文提出Target-Balanced Score Distillation (TBSD)方法，解决了SDS方法在3D资产生成中纹理优化与形状保真度的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有的SDS方法在3D生成中存在过饱和和过平滑问题，虽然通过负提示词进行改进，但面临纹理优化有限或纹理增强但形状失真的关键权衡。

Method: 通过系统分析发现目标负提示词(TNP)是问题的关键，提出TBSD方法将生成建模为多目标优化问题，并引入自适应策略来平衡纹理和形状。

Result: 大量实验表明TBSD显著优于现有最先进方法，能够生成具有高保真纹理和几何精确形状的3D资产。

Conclusion: TBSD方法有效解决了SDS方法中的关键权衡问题，为3D资产生成提供了更优的解决方案。

Abstract: Score Distillation Sampling (SDS) enables 3D asset generation by distilling priors from pretrained 2D text-to-image diffusion models, but vanilla SDS suffers from over-saturation and over-smoothing. To mitigate this issue, recent variants have incorporated negative prompts. However, these methods face a critical trade-off: limited texture optimization, or significant texture gains with shape distortion. In this work, we first conduct a systematic analysis and reveal that this trade-off is fundamentally governed by the utilization of the negative prompts, where Target Negative Prompts (TNP) that embed target information in the negative prompts dramatically enhancing texture realism and fidelity but inducing shape distortions. Informed by this key insight, we introduce the Target-Balanced Score Distillation (TBSD). It formulates generation as a multi-objective optimization problem and introduces an adaptive strategy that effectively resolves the aforementioned trade-off. Extensive experiments demonstrate that TBSD significantly outperforms existing state-of-the-art methods, yielding 3D assets with high-fidelity textures and geometrically accurate shape.

</details>


### [9] [CompressNAS : A Fast and Efficient Technique for Model Compression using Decomposition](https://arxiv.org/abs/2511.11716)
*Sudhakar Sah,Nikhil Chabbra,Matthieu Durnerin*

Main category: cs.CV

TL;DR: CompressNAS是一个受MicroNAS启发的框架，将秩选择作为全局搜索问题，通过快速精度估计器评估候选分解，在内存和精度约束下实现高效且彻底的秩探索。


<details>
  <summary>Details</summary>
Motivation: 深度卷积神经网络（CNN）在微控制器（MCU）和轻量级NPU上部署越来越困难，因为其规模和计算需求不断增长。现有的低秩张量分解方法通常局部选择秩，忽略了压缩与精度之间的全局权衡。

Method: 引入CompressNAS框架，将秩选择视为全局搜索问题，使用快速精度估计器评估候选分解，实现高效的秩探索。

Result: 在ImageNet上，CompressNAS将ResNet-18压缩8倍，精度下降小于4%；在COCO上，YOLOv5s实现2倍压缩且无精度下降，YOLOv5n实现2倍压缩且精度下降2.5%。同时提出了新的压缩模型家族STResNet，性能与其他高效模型相当。

Conclusion: CompressNAS通过全局秩搜索和快速精度估计，有效解决了CNN模型在资源受限设备上的部署问题，实现了高压缩比和低精度损失的平衡。

Abstract: Deep Convolutional Neural Networks (CNNs) are increasingly difficult to deploy on microcontrollers (MCUs) and lightweight NPUs (Neural Processing Units) due to their growing size and compute demands. Low-rank tensor decomposition, such as Tucker factorization, is a promising way to reduce parameters and operations with reasonable accuracy loss. However, existing approaches select ranks locally and often ignore global trade-offs between compression and accuracy. We introduce CompressNAS, a MicroNAS-inspired framework that treats rank selection as a global search problem. CompressNAS employs a fast accuracy estimator to evaluate candidate decompositions, enabling efficient yet exhaustive rank exploration under memory and accuracy constraints. In ImageNet, CompressNAS compresses ResNet-18 by 8x with less than 4% accuracy drop; on COCO, we achieve 2x compression of YOLOv5s without any accuracy drop and 2x compression of YOLOv5n with a 2.5% drop. Finally, we present a new family of compressed models, STResNet, with competitive performance compared to other efficient models.

</details>


### [10] [AdaptFly: Prompt-Guided Adaptation of Foundation Models for Low-Altitude UAV Networks](https://arxiv.org/abs/2511.11720)
*Jiao Chen,Haoyi Wang,Jianhua Tang,Junyi Wang*

Main category: cs.CV

TL;DR: AdaptFly是一个基于提示的无权重更新测试时适应框架，用于提升无人机网络中语义分割模型的鲁棒性，支持资源受限和资源充足两种无人机的互补适应模式。


<details>
  <summary>Details</summary>
Motivation: 无人机网络中的语义分割模型在天气、光照和视角变化下性能下降严重，资源受限的无人机无法进行基于梯度的测试时适应，而资源充足的无人机独立适应会浪费共享经验。

Method: AdaptFly采用两种互补适应模式：对资源受限无人机使用轻量级令牌提示检索共享全局记忆；对资源充足无人机使用基于协方差矩阵自适应进化策略的无梯度稀疏视觉提示优化。通过激活统计检测器触发适应，跨无人机知识池整合提示知识实现机队协作。

Result: 在UAVid和VDD基准测试及真实世界无人机部署中的实验表明，AdaptFly相比静态模型和最先进的TTA基线显著提高了分割精度和鲁棒性。

Conclusion: AdaptFly为新兴低空经济中的弹性、通信高效感知提供了一条实用路径。

Abstract: Low-altitude Unmanned Aerial Vehicle (UAV) networks rely on robust semantic segmentation as a foundational enabler for distributed sensing-communication-control co-design across heterogeneous agents within the network. However, segmentation foundation models deteriorate quickly under weather, lighting, and viewpoint drift. Resource-limited UAVs cannot run gradient-based test-time adaptation, while resource-massive UAVs adapt independently, wasting shared experience. To address these challenges, we propose AdaptFly, a prompt-guided test-time adaptation framework that adjusts segmentation models without weight updates. AdaptFly features two complementary adaptation modes. For resource-limited UAVs, it employs lightweight token-prompt retrieval from a shared global memory. For resource-massive UAVs, it uses gradient-free sparse visual prompt optimization via Covariance Matrix Adaptation Evolution Strategy. An activation-statistic detector triggers adaptation, while cross-UAV knowledge pool consolidates prompt knowledge and enables fleet-wide collaboration with negligible bandwidth overhead. Extensive experiments on UAVid and VDD benchmarks, along with real-world UAV deployments under diverse weather conditions, demonstrate that AdaptFly significantly improves segmentation accuracy and robustness over static models and state-of-the-art TTA baselines. The results highlight a practical path to resilient, communication-efficient perception in the emerging low-altitude economy.

</details>


### [11] [Do Blind Spots Matter for Word-Referent Mapping? A Computational Study with Infant Egocentric Video](https://arxiv.org/abs/2511.11725)
*Zekai Shi,Zhixi Cai,Kalin Stefanov*

Main category: cs.CV

TL;DR: 提出了一种基于生物启发的自监督视觉表示学习方法，通过模拟人眼盲点填补机制来改进掩码策略，用于学习婴儿单词-指代映射


<details>
  <summary>Details</summary>
Motivation: 解决婴儿首次学习单词时面临的指代模糊问题，即一个单词可能指代环境中的任何物体、组件或属性，需要从有限的生态有效数据中学习

Method: 使用基于掩码自编码器的视觉骨干网络，结合人眼盲点知识定义新型掩码策略，模仿人脑填补视野空白的方式，然后通过对比学习视频-文本模型学习单词-指代映射

Result: 广泛评估表明，所提出的生物合理掩码策略在学习跨情境和时间扩展情节的单词-指代映射方面至少与随机掩码同样有效

Conclusion: 生物启发的掩码策略提供了一种更符合生物学原理的替代方案，能够有效学习视觉表示和单词-指代关系

Abstract: Typically, children start to learn their first words between 6 and 9 months, linking spoken utterances to their visual referents. Without prior knowledge, a word encountered for the first time can be interpreted in countless ways; it might refer to any of the objects in the environment, their components, or attributes. Using longitudinal, egocentric, and ecologically valid data from the experience of one child, in this work, we propose a self-supervised and biologically plausible strategy to learn strong visual representations. Our masked autoencoder-based visual backbone incorporates knowledge about the blind spot in human eyes to define a novel masking strategy. This mask and reconstruct approach attempts to mimic the way the human brain fills the gaps in the eyes' field of view. This represents a significant shift from standard random masking strategies, which are difficult to justify from a biological perspective. The pretrained encoder is utilized in a contrastive learning-based video-text model capable of acquiring word-referent mappings. Extensive evaluation suggests that the proposed biologically plausible masking strategy is at least as effective as random masking for learning word-referent mappings from cross-situational and temporally extended episodes.

</details>


### [12] [GROVER: Graph-guided Representation of Omics and Vision with Expert Regulation for Adaptive Spatial Multi-omics Fusion](https://arxiv.org/abs/2511.11730)
*Yongjun Xiao,Dian Meng,Xinlei Huang,Yanran Liu,Shiwei Ruan,Ziyue Qiao,Xubin Zheng*

Main category: cs.CV

TL;DR: GROVER是一个用于空间多组学数据自适应融合的新框架，通过图卷积网络和对比学习解决多模态异构数据整合的挑战。


<details>
  <summary>Details</summary>
Motivation: 空间转录组学、蛋白质组学和表观基因组学缺乏病理形态学背景，需要与组织病理学图像整合以实现全面的疾病组织分析，但多模态数据的异质性和分辨率不匹配带来了重大挑战。

Method: GROVER使用基于Kolmogorov-Arnold网络的图卷积网络编码器捕获模态间非线性依赖关系，采用spot-feature-pair对比学习策略对齐表示，并通过动态专家路由机制自适应选择信息丰富的模态。

Result: 在真实世界空间组学数据集上的实验表明，GROVER优于现有最先进基线方法。

Conclusion: GROVER为多模态整合提供了一个稳健可靠的解决方案，能够有效处理空间多组学数据的融合挑战。

Abstract: Effectively modeling multimodal spatial omics data is critical for understanding tissue complexity and underlying biological mechanisms. While spatial transcriptomics, proteomics, and epigenomics capture molecular features, they lack pathological morphological context. Integrating these omics with histopathological images is therefore essential for comprehensive disease tissue analysis. However, substantial heterogeneity across omics, imaging, and spatial modalities poses significant challenges. Naive fusion of semantically distinct sources often leads to ambiguous representations. Additionally, the resolution mismatch between high-resolution histology images and lower-resolution sequencing spots complicates spatial alignment. Biological perturbations during sample preparation further distort modality-specific signals, hindering accurate integration. To address these challenges, we propose Graph-guided Representation of Omics and Vision with Expert Regulation for Adaptive Spatial Multi-omics Fusion (GROVER), a novel framework for adaptive integration of spatial multi-omics data. GROVER leverages a Graph Convolutional Network encoder based on Kolmogorov-Arnold Networks to capture the nonlinear dependencies between each modality and its associated spatial structure, thereby producing expressive, modality-specific embeddings. To align these representations, we introduce a spot-feature-pair contrastive learning strategy that explicitly optimizes the correspondence across modalities at each spot. Furthermore, we design a dynamic expert routing mechanism that adaptively selects informative modalities for each spot while suppressing noisy or low-quality inputs. Experiments on real-world spatial omics datasets demonstrate that GROVER outperforms state-of-the-art baselines, providing a robust and reliable solution for multimodal integration.

</details>


### [13] [Exposing DeepFakes via Hyperspectral Domain Mapping](https://arxiv.org/abs/2511.11732)
*Aditya Mehta,Swarnim Chaudhary,Pratik Narang,Jagat Sesh Challa*

Main category: cs.CV

TL;DR: HSI-Detect是一个两阶段深度伪造检测方法，通过将RGB图像重建为31通道高光谱图像，在光谱域中放大操纵伪影，显著提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 当前生成和扩散模型能产生高度逼真的图像，误导人类感知和自动化检测系统。大多数检测方法仅分析RGB三通道，而操纵伪影在特定频段可能更明显。

Method: 提出HSI-Detect两阶段流水线：1）从标准RGB输入重建31通道高光谱图像；2）在高光谱域进行检测。通过扩展光谱带放大RGB域中微弱或不可见的操纵伪影。

Result: 在FaceForensics++数据集上的评估显示，HSI-Detect相比仅使用RGB的基线方法取得一致改进。

Conclusion: 光谱域映射在深度伪造检测中具有良好前景，高光谱分析能有效增强检测能力。

Abstract: Modern generative and diffusion models produce highly realistic images that can mislead human perception and even sophisticated automated detection systems. Most detection methods operate in RGB space and thus analyze only three spectral channels. We propose HSI-Detect, a two-stage pipeline that reconstructs a 31-channel hyperspectral image from a standard RGB input and performs detection in the hyperspectral domain. Expanding the input representation into denser spectral bands amplifies manipulation artifacts that are often weak or invisible in the RGB domain, particularly in specific frequency bands. We evaluate HSI-Detect across FaceForensics++ dataset and show the consistent improvements over RGB-only baselines, illustrating the promise of spectral-domain mapping for Deepfake detection.

</details>


### [14] [Toward bilipshiz geometric models](https://arxiv.org/abs/2511.11735)
*Yonatan Sverdlov,Eitan Rosen,Nadav Dym*

Main category: cs.CV

TL;DR: 该论文研究了点云神经网络在保持对称感知距离方面的特性，通过双Lipschitz等价性分析，发现现有不变网络与Procrustes匹配度量不具双Lipschitz等价性，并提出了改进方法。


<details>
  <summary>Details</summary>
Motivation: 受等变学习文献启发，探究对称不变网络是否能保持点云空间上的自然对称感知距离，这对于提升模型在对称变换下的稳定性具有重要意义。

Method: 分析两种对称感知度量（Procrustes匹配度量和硬Gromov-Wasserstein距离）的双Lipschitz等价性，修改现有不变网络结构以获得双Lipschitz保证。

Result: 证明两种度量本身不具双Lipschitz等价性，现有不变网络与PM度量不具双Lipschitz等价性，改进后的模型在3D点云对应任务中优于标准不变模型。

Conclusion: 通过双Lipschitz分析揭示了点云不变网络的局限性，提出的改进方法能有效提升模型在对称变换下的稳定性，为对称感知学习提供了新思路。

Abstract: Many neural networks for point clouds are, by design, invariant to the symmetries of this datatype: permutations and rigid motions. The purpose of this paper is to examine whether such networks preserve natural symmetry aware distances on the point cloud spaces, through the notion of bi-Lipschitz equivalence. This inquiry is motivated by recent work in the Equivariant learning literature which highlights the advantages of bi-Lipschitz models in other scenarios.
  We consider two symmetry aware metrics on point clouds: (a) The Procrustes Matching (PM) metric and (b) Hard Gromov Wasserstien distances. We show that these two distances themselves are not bi-Lipschitz equivalent, and as a corollary deduce that popular invariant networks for point clouds are not bi-Lipschitz with respect to the PM metric. We then show how these networks can be modified so that they do obtain bi-Lipschitz guarantees. Finally, we provide initial experiments showing the advantage of the proposed bi-Lipschitz model over standard invariant models, for the tasks of finding correspondences between 3D point clouds.

</details>


### [15] [Concept-RuleNet: Grounded Multi-Agent Neurosymbolic Reasoning in Vision Language Models](https://arxiv.org/abs/2511.11751)
*Sanchit Sinha,Guangzhi Xiong,Zhenghao He,Aidong Zhang*

Main category: cs.CV

TL;DR: Concept-RuleNet是一个多智能体系统，通过视觉概念挖掘和符号推理增强视觉语言模型的解释性，减少幻觉符号，提高性能


<details>
  <summary>Details</summary>
Motivation: 解决当前视觉语言模型缺乏可解释性、容易产生幻觉的问题，特别是在分布外数据上表现不佳

Method: 多智能体系统：1) 多模态概念生成器从训练图像中挖掘视觉概念；2) 基于视觉概念进行符号发现；3) 大语言模型推理器将符号组合成一阶规则；4) 视觉验证器量化符号存在度并执行规则推理

Result: 在5个基准测试中，包括2个医学影像任务和3个自然图像数据集，平均性能提升5%，幻觉符号减少达50%

Conclusion: 该方法成功地将视觉基础与符号推理结合，提供可解释的推理路径，同时提高了神经符号方法的性能

Abstract: Modern vision-language models (VLMs) deliver impressive predictive accuracy yet offer little insight into 'why' a decision is reached, frequently hallucinating facts, particularly when encountering out-of-distribution data. Neurosymbolic frameworks address this by pairing black-box perception with interpretable symbolic reasoning, but current methods extract their symbols solely from task labels, leaving them weakly grounded in the underlying visual data. In this paper, we introduce a multi-agent system - Concept-RuleNet that reinstates visual grounding while retaining transparent reasoning. Specifically, a multimodal concept generator first mines discriminative visual concepts directly from a representative subset of training images. Next, these visual concepts are utilized to condition symbol discovery, anchoring the generations in real image statistics and mitigating label bias. Subsequently, symbols are composed into executable first-order rules by a large language model reasoner agent - yielding interpretable neurosymbolic rules. Finally, during inference, a vision verifier agent quantifies the degree of presence of each symbol and triggers rule execution in tandem with outputs of black-box neural models, predictions with explicit reasoning pathways. Experiments on five benchmarks, including two challenging medical-imaging tasks and three underrepresented natural-image datasets, show that our system augments state-of-the-art neurosymbolic baselines by an average of 5% while also reducing the occurrence of hallucinated symbols in rules by up to 50%.

</details>


### [16] [Batch Transformer Architecture: Case of Synthetic Image Generation for Emotion Expression Facial Recognition](https://arxiv.org/abs/2511.11754)
*Stanislav Selitskiy*

Main category: cs.CV

TL;DR: 提出了一种隐式稀疏风格的Transformer变体架构——Batch Transformers，通过对重要维度进行注意力机制，显著减少编码器-解码器ANN架构中的瓶颈大小。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer对序列或批次实体进行全维度注意力计算效率较低，希望通过关注重要维度来减少计算瓶颈。

Method: 采用对主要成分（重要维度）的注意力机制，实现特征选择，在面部识别任务中测试合成图像生成，特别是针对化妆和遮挡数据集。

Result: 在有限原始数据集的情况下，实现了数据可变性的增加，有效提升了模型性能。

Conclusion: Batch Transformers通过维度选择性注意力机制，在保持性能的同时显著降低了计算复杂度，为稀疏注意力机制提供了新思路。

Abstract: A novel Transformer variation architecture is proposed in the implicit sparse style. Unlike "traditional" Transformers, instead of attention to sequential or batch entities in their entirety of whole dimensionality, in the proposed Batch Transformers, attention to the "important" dimensions (primary components) is implemented. In such a way, the "important" dimensions or feature selection allows for a significant reduction of the bottleneck size in the encoder-decoder ANN architectures. The proposed architecture is tested on the synthetic image generation for the face recognition task in the case of the makeup and occlusion data set, allowing for increased variability of the limited original data set.

</details>


### [17] [Image-POSER: Reflective RL for Multi-Expert Image Generation and Editing](https://arxiv.org/abs/2511.11780)
*Hossein Mohebbi,Mohammed Abdulrahman,Yanting Miao,Pascal Poupart,Suraj Kothawade*

Main category: cs.CV

TL;DR: Image-POSER是一个基于强化学习的框架，通过动态任务分解和专家模型协作来处理长文本提示的图像生成任务，在多个指标上优于现有基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像生成模型在单个提示下表现良好，但无法可靠地处理创意工作流中常见的复杂、组合式长提示。

Method: 采用反射式强化学习框架，将图像合成和编辑建模为马尔可夫决策过程，通过动态任务分解协调预训练专家模型，并使用视觉语言模型进行结构化反馈监督。

Result: 实验表明Image-POSER在行业标准和自定义基准测试中，在图像对齐度、保真度和美学质量方面均优于基线模型，并在人类评估中持续获得偏好。

Conclusion: 强化学习能够赋予AI系统自主分解、重组和组合视觉模型的能力，为实现通用视觉助手迈出了重要一步。

Abstract: Recent advances in text-to-image generation have produced strong single-shot models, yet no individual system reliably executes the long, compositional prompts typical of creative workflows. We introduce Image-POSER, a reflective reinforcement learning framework that (i) orchestrates a diverse registry of pretrained text-to-image and image-to-image experts, (ii) handles long-form prompts end-to-end through dynamic task decomposition, and (iii) supervises alignment at each step via structured feedback from a vision-language model critic. By casting image synthesis and editing as a Markov Decision Process, we learn non-trivial expert pipelines that adaptively combine strengths across models. Experiments show that Image-POSER outperforms baselines, including frontier models, across industry-standard and custom benchmarks in alignment, fidelity, and aesthetics, and is consistently preferred in human evaluations. These results highlight that reinforcement learning can endow AI systems with the capacity to autonomously decompose, reorder, and combine visual models, moving towards general-purpose visual assistants.

</details>


### [18] [SOTFormer: A Minimal Transformer for Unified Object Tracking and Trajectory Prediction](https://arxiv.org/abs/2511.11824)
*Zhongping Dong,Pengyang Yu,Shuangjian Li,Liming Chen,Mohand Tahar Kechadi*

Main category: cs.CV

TL;DR: SOTFormer是一个统一的端到端框架，集成了目标检测、跟踪和短期轨迹预测，通过轻量级时序注意力层实现实时推理和固定GPU内存使用。


<details>
  <summary>Details</summary>
Motivation: 解决在遮挡、尺度变化和时间漂移等挑战下，单目标跟踪和短期运动预测的时序一致性问题。

Method: 采用基于真实标签初始化的记忆机制和烧录锚点损失来稳定身份传播，使用单个轻量级时序注意力层跨帧优化嵌入表示。

Result: 在Mini-LaSOT（20%）基准测试中达到76.3 AUC和53.7 FPS（AMP，4.3 GB VRAM），在快速运动、尺度变化和遮挡情况下优于TrackFormer和MOTRv2等Transformer基线。

Conclusion: SOTFormer通过最小化常数内存的时序Transformer设计，有效提升了复杂场景下的跟踪性能和实时性。

Abstract: Accurate single-object tracking and short-term motion forecasting remain challenging under occlusion, scale variation, and temporal drift, which disrupt the temporal coherence required for real-time perception. We introduce \textbf{SOTFormer}, a minimal constant-memory temporal transformer that unifies object detection, tracking, and short-horizon trajectory prediction within a single end-to-end framework. Unlike prior models with recurrent or stacked temporal encoders, SOTFormer achieves stable identity propagation through a ground-truth-primed memory and a burn-in anchor loss that explicitly stabilizes initialization. A single lightweight temporal-attention layer refines embeddings across frames, enabling real-time inference with fixed GPU memory. On the Mini-LaSOT (20%) benchmark, SOTFormer attains 76.3 AUC and 53.7 FPS (AMP, 4.3 GB VRAM), outperforming transformer baselines such as TrackFormer and MOTRv2 under fast motion, scale change, and occlusion.

</details>


### [19] [MP-GFormer: A 3D-Geometry-Aware Dynamic Graph Transformer Approach for Machining Process Planning](https://arxiv.org/abs/2511.11837)
*Fatemeh Elhambakhsh,Gaurav Ameta,Aditi Roy,Hyunwoong Ko*

Main category: cs.CV

TL;DR: 提出MP-GFormer方法，通过3D几何感知的动态图变换器整合演化中的3D几何表示，在加工工艺规划中预测加工操作序列，相比现有方法在主操作和子操作预测准确率上分别提升24%和36%。


<details>
  <summary>Details</summary>
Motivation: 现有动态图学习方法在加工工艺规划中虽能捕捉特征间依赖关系，但无法整合零件3D几何信息，缺乏领域感知能力，导致预测精度受限。

Method: MP-GFormer：基于注意力机制的3D几何感知动态图变换器，利用StereoLithography表面网格表示每次加工操作后的零件3D几何，通过边界表示法处理初始3D设计。

Result: 在合成数据集上评估显示，主操作预测准确率提升24%，子操作预测准确率提升36%，显著优于现有最优方法。

Conclusion: 将3D几何信息整合到动态图学习中能有效提升加工操作序列预测的准确性，MP-GFormer为加工工艺规划提供了更强大的领域感知能力。

Abstract: Machining process planning (MP) is inherently complex due to structural and geometrical dependencies among part features and machining operations. A key challenge lies in capturing dynamic interdependencies that evolve with distinct part geometries as operations are performed. Machine learning has been applied to address challenges in MP, such as operation selection and machining sequence prediction. Dynamic graph learning (DGL) has been widely used to model dynamic systems, thanks to its ability to integrate spatio-temporal relationships. However, in MP, while existing DGL approaches can capture these dependencies, they fail to incorporate three-dimensional (3D) geometric information of parts and thus lack domain awareness in predicting machining operation sequences. To address this limitation, we propose MP-GFormer, a 3D-geometry-aware dynamic graph transformer that integrates evolving 3D geometric representations into DGL through an attention mechanism to predict machining operation sequences. Our approach leverages StereoLithography surface meshes representing the 3D geometry of a part after each machining operation, with the boundary representation method used for the initial 3D designs. We evaluate MP-GFormer on a synthesized dataset and demonstrate that the method achieves improvements of 24\% and 36\% in accuracy for main and sub-operation predictions, respectively, compared to state-of-the-art approaches.

</details>


### [20] [Defending Unauthorized Model Merging via Dual-Stage Weight Protection](https://arxiv.org/abs/2511.11851)
*Wei-Jia Chen,Min-Yen Tsai,Cheng-Yi Lee,Chia-Mu Yu*

Main category: cs.CV

TL;DR: MergeGuard是一个双阶段权重保护框架，通过破坏模型合并的兼容性来防止未经授权的模型合并，同时保持原始模型的性能。


<details>
  <summary>Details</summary>
Motivation: 预训练模型和开放存储库的快速发展使得模型合并成为一种方便但有风险的做法，未经授权的模型合并不仅侵犯知识产权，还破坏模型所有权和问责制。

Method: 第一阶段通过L2正则化优化重新分布任务相关信息，第二阶段注入结构化扰动来错位任务子空间，破坏损失景观中的曲率兼容性。

Result: 在视觉和语言模型上的广泛实验表明，MergeGuard可将合并模型准确率降低高达90%，同时保护模型的性能损失小于1.5%。

Conclusion: MergeGuard通过重塑模型参数几何结构，有效防止未经授权的模型合并，同时保持原始模型的功能完整性。

Abstract: The rapid proliferation of pretrained models and open repositories has made model merging a convenient yet risky practice, allowing free-riders to combine fine-tuned models into a new multi-capability model without authorization. Such unauthorized model merging not only violates intellectual property rights but also undermines model ownership and accountability. To address this issue, we present MergeGuard, a proactive dual-stage weight protection framework that disrupts merging compatibility while maintaining task fidelity. In the first stage, we redistribute task-relevant information across layers via L2-regularized optimization, ensuring that important gradients are evenly dispersed. In the second stage, we inject structured perturbations to misalign task subspaces, breaking curvature compatibility in the loss landscape. Together, these stages reshape the model's parameter geometry such that merged models collapse into destructive interference while the protected model remains fully functional. Extensive experiments on both vision (ViT-L-14) and language (Llama2, Gemma2, Mistral) models demonstrate that MergeGuard reduces merged model accuracy by up to 90% with less than 1.5% performance loss on the protected model.

</details>


### [21] [FocusSDF: Boundary-Aware Learning for Medical Image Segmentation via Signed Distance Supervision](https://arxiv.org/abs/2511.11864)
*Muzammal Shafique,Nasir Rahim,Jamil Ahmad,Mohammad Siadat,Khalid Malik,Ghaus Malik*

Main category: cs.CV

TL;DR: FocusSDF是一种基于符号距离函数(SDF)的新型损失函数，通过自适应分配更高权重给边界附近像素，使网络专注于边界区域，解决医学图像分割中边界保留的挑战。


<details>
  <summary>Details</summary>
Motivation: 当前大多数医学图像分割模型没有显式编码边界信息，导致边界保留成为持续挑战，需要专门针对边界区域优化的损失函数。

Method: 提出FocusSDF损失函数，基于符号距离函数自适应地为靠近病变或器官边界的像素分配更高权重，使网络具备边界感知能力。

Result: 在涵盖脑动脉瘤、中风、肝脏和乳腺肿瘤等多个分割任务的广泛评估中，FocusSDF在五种最先进模型上表现优于现有基于距离变换的损失函数。

Conclusion: FocusSDF损失函数能够有效提升医学图像分割的边界保留性能，在多种成像模态和分割任务中均表现出优越性。

Abstract: Segmentation of medical images constitutes an essential component of medical image analysis, providing the foundation for precise diagnosis and efficient therapeutic interventions in clinical practices. Despite substantial progress, most segmentation models do not explicitly encode boundary information; as a result, making boundary preservation a persistent challenge in medical image segmentation. To address this challenge, we introduce FocusSDF, a novel loss function based on the signed distance functions (SDFs), which redirects the network to concentrate on boundary regions by adaptively assigning higher weights to pixels closer to the lesion or organ boundary, effectively making it boundary aware. To rigorously validate FocusSDF, we perform extensive evaluations against five state-of-the-art medical image segmentation models, including the foundation model MedSAM, using four distance-based loss functions across diverse datasets covering cerebral aneurysm, stroke, liver, and breast tumor segmentation tasks spanning multiple imaging modalities. The experimental results consistently demonstrate the superior performance of FocusSDF over existing distance transform based loss functions.

</details>


### [22] [Lacking Data? No worries! How synthetic images can alleviate image scarcity in wildlife surveys: a case study with muskox (Ovibos moschatus)](https://arxiv.org/abs/2511.11882)
*Simon Durand,Samuel Foucher,Alexandre Delplanque,Joëlle Taillon,Jérôme Théau*

Main category: cs.CV

TL;DR: 本研究探讨了使用合成图像来补充有限训练数据，以提高在零样本和少样本设置下对麝牛的检测性能。研究发现，在零样本模型中，添加合成图像可以提高检测性能，但存在收益递减效应；在少样本模型中，结合真实和合成图像可以带来更好的召回率和略高的准确率。


<details>
  <summary>Details</summary>
Motivation: 传统野生动物调查方法资源密集且受限于后勤挑战，而深度学习目标检测模型在稀疏分布物种（如麝牛）上的应用受到小数据集的限制。本研究旨在探索合成图像在数据稀缺情况下训练准确目标检测模型的潜力。

Method: 比较了在真实图像上训练的基线模型与5个零样本和5个少样本模型，这些模型在训练集中逐步加入了更多合成图像。零样本模型不包含真实图像，少样本模型结合了真实和合成图像。

Result: 对于零样本模型，添加合成图像提高了检测性能（精确率、召回率和F1分数），但当合成图像超过基线模型训练数据集的100%时，性能趋于稳定。对于少样本模型，结合真实和合成图像带来了更好的召回率和略高的准确率，但改进不具统计学显著性。

Conclusion: 合成图像在数据稀缺时训练准确目标检测模型具有潜力，可用于启动没有真实数据的目标检测模型，并随着时间推移获取真实图像而进行细化。这为野生动物监测提供了重要视角，特别是对于稀有或难以接近的物种。

Abstract: Accurate population estimates are essential for wildlife management, providing critical insights into species abundance and distribution. Traditional survey methods, including visual aerial counts and GNSS telemetry tracking, are widely used to monitor muskox populations in Arctic regions. These approaches are resource intensive and constrained by logistical challenges. Advances in remote sensing, artificial intelligence, and high resolution aerial imagery offer promising alternatives for wildlife detection. Yet, the effectiveness of deep learning object detection models (ODMs) is often limited by small datasets, making it challenging to train robust ODMs for sparsely distributed species like muskoxen. This study investigates the integration of synthetic imagery (SI) to supplement limited training data and improve muskox detection in zero shot (ZS) and few-shot (FS) settings. We compared a baseline model trained on real imagery with 5 ZS and 5 FS models that incorporated progressively more SI in the training set. For the ZS models, where no real images were included in the training set, adding SI improved detection performance. As more SI were added, performance in precision, recall and F1 score increased, but eventually plateaued, suggesting diminishing returns when SI exceeded 100% of the baseline model training dataset. For FS models, combining real and SI led to better recall and slightly higher overall accuracy compared to using real images alone, though these improvements were not statistically significant. Our findings demonstrate the potential of SI to train accurate ODMs when data is scarce, offering important perspectives for wildlife monitoring by enabling rare or inaccessible species to be monitored and to increase monitoring frequency. This approach could be used to initiate ODMs without real data and refine it as real images are acquired over time.

</details>


### [23] [Advancing Annotat3D with Harpia: A CUDA-Accelerated Library For Large-Scale Volumetric Data Segmentation](https://arxiv.org/abs/2511.11890)
*Camila Machado de Araujo,Egon P. B. S. Borges,Ricardo Marcelo Canteiro Grangeiro,Allan Pinto*

Main category: cs.CV

TL;DR: 该论文介绍了Harpia——一个新的基于CUDA的处理库，用于支持大规模3D数据集的可扩展、交互式分割工作流，显著提升了处理速度、内存效率和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 高分辨率体积成像技术生成的数据集规模越来越大，现有工具在处理、分割和交互式探索方面面临效率挑战。

Method: 开发了Harpia库，具有严格的内存控制、原生分块执行功能，以及一套GPU加速的过滤、注释和量化工具，支持在超出单GPU内存容量的数据集上可靠运行。

Result: 实验结果显示，与NVIDIA cuCIM和scikit-image等广泛使用的框架相比，Harpia在处理速度、内存效率和可扩展性方面都有显著提升。

Conclusion: 该系统结合了交互式人机交互界面和高效的GPU资源管理，特别适合在共享HPC基础设施中进行协作科学成像工作流。

Abstract: High-resolution volumetric imaging techniques, such as X-ray tomography and advanced microscopy, generate increasingly large datasets that challenge existing tools for efficient processing, segmentation, and interactive exploration. This work introduces new capabilities to Annotat3D through Harpia, a new CUDA-based processing library designed to support scalable, interactive segmentation workflows for large 3D datasets in high-performance computing (HPC) and remote-access environments. Harpia features strict memory control, native chunked execution, and a suite of GPU-accelerated filtering, annotation, and quantification tools, enabling reliable operation on datasets exceeding single-GPU memory capacity. Experimental results demonstrate significant improvements in processing speed, memory efficiency, and scalability compared to widely used frameworks such as NVIDIA cuCIM and scikit-image. The system's interactive, human-in-the-loop interface, combined with efficient GPU resource management, makes it particularly suitable for collaborative scientific imaging workflows in shared HPC infrastructures.

</details>


### [24] [Prompt Triage: Structured Optimization Enhances Vision-Language Model Performance on Medical Imaging Benchmarks](https://arxiv.org/abs/2511.11898)
*Arnav Singhvi,Vasiliki Bikia,Asad Aali,Akshay Chaudhari,Roxana Daneshjou*

Main category: cs.CV

TL;DR: 该论文提出了一种基于DSPy框架的自动化提示优化方法，用于提升视觉语言模型在医学影像任务中的性能，无需大量领域数据或人工提示工程，在多个医学专业领域实现了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在医学任务上表现不佳，而微调需要大量领域数据和计算资源，人工提示工程难以泛化且对医疗机构不友好，因此需要开发权重无关、可扩展的自动化性能提升方法。

Method: 采用DSPy框架进行结构化自动提示优化，构建了五个医学影像任务（放射学、胃肠病学、皮肤病学）的提示管道，评估了10个开源视觉语言模型和四种提示优化技术。

Result: 优化后的管道相比零样本提示基线实现了53%的中位数相对提升，在零样本性能较低的任务上最大提升达300%-3,400%，同时保持了数据隐私和可扩展性。

Conclusion: 自动化提示优化技术显著提升了医学AI系统的性能，减少了依赖人工提示设计，使临床医生能专注于患者护理和临床决策，并为医学任务的可重复研究提供了开源评估管道。

Abstract: Vision-language foundation models (VLMs) show promise for diverse imaging tasks but often underperform on medical benchmarks. Prior efforts to improve performance include model finetuning, which requires large domain-specific datasets and significant compute, or manual prompt engineering, which is hard to generalize and often inaccessible to medical institutions seeking to deploy these tools. These challenges motivate interest in approaches that draw on a model's embedded knowledge while abstracting away dependence on human-designed prompts to enable scalable, weight-agnostic performance improvements. To explore this, we adapt the Declarative Self-improving Python (DSPy) framework for structured automated prompt optimization in medical vision-language systems through a comprehensive, formal evaluation. We implement prompting pipelines for five medical imaging tasks across radiology, gastroenterology, and dermatology, evaluating 10 open-source VLMs with four prompt optimization techniques. Optimized pipelines achieved a median relative improvement of 53% over zero-shot prompting baselines, with the largest gains ranging from 300% to 3,400% on tasks where zero-shot performance is low. These results highlight the substantial potential of applying automated prompt optimization to medical AI systems, demonstrating significant gains for vision-based applications requiring accurate clinical image interpretation. By reducing dependence on prompt design to elicit intended outputs, these techniques allow clinicians to focus on patient care and clinical decision-making. Furthermore, our experiments offer scalability and preserve data privacy, demonstrating performance improvement on open-source VLMs. We publicly release our evaluation pipelines to support reproducible research on specialized medical tasks, available at https://github.com/DaneshjouLab/prompt-triage-lab.

</details>


### [25] [PI-NAIM: Path-Integrated Neural Adaptive Imputation Model](https://arxiv.org/abs/2511.11908)
*Afifa Khaled,Ebrahim Hamid Sumiea*

Main category: cs.CV

TL;DR: PI-NAIM提出了一种双路径架构，根据缺失复杂度动态路由样本到优化的插补方法，在医学影像和多模态临床数据中实现高效缺失值填补


<details>
  <summary>Details</summary>
Motivation: 解决医学影像和多模态临床环境中缺失模态的问题，现有插补方法要么缺乏表示能力，要么计算成本高

Method: 双路径架构：1)智能路径路由，低缺失样本使用MICE统计插补，复杂模式使用GAIN神经网络；2)跨路径注意力融合；3)端到端联合优化插补精度和下游任务性能

Result: 在MIMIC-III和多模态基准测试中达到最先进性能，RMSE为0.108，死亡率预测AUROC为0.812

Conclusion: PI-NAIM的模块化设计能够无缝集成到处理不完整传感器测量、缺失模态或损坏输入的视觉管道中，为现实场景提供统一解决方案

Abstract: Medical imaging and multi-modal clinical settings often face the challange of missing modality in their diagnostic pipelines. Existing imputation methods either lack representational capacity or are computationally expensive. We propose PI-NAIM, a novel dual-path architecture that dynamically routes samples to optimized imputation approaches based on missingness complexity. Our framework integrates: (1) intelligent path routing that directs low missingness samples to efficient statistical imputation (MICE) and complex patterns to powerful neural networks (GAIN with temporal analysis); (2) cross-path attention fusion that leverages missingness-aware embeddings to intelligently combine both branches; and (3) end-to-end joint optimization of imputation accuracy and downstream task performance. Extensive experiments on MIMIC-III and multimodal benchmarks demonstrate state-of-the-art performance, achieving RMSE of 0.108 (vs. baselines' 0.119-0.152) and substantial gains in downstream tasks with an AUROC of 0.812 for mortality prediction. PI-NAIM's modular design enables seamless integration into vision pipelines handling incomplete sensor measurements, missing modalities, or corrupted inputs, providing a unified solution for real-world scenario. The code is publicly available at https://github.com/AfifaKhaled/PI-NAIM-Path-Integrated-Neural-Adaptive-Imputation-Model

</details>


### [26] [Seeing the Forest and the Trees: Query-Aware Tokenizer for Long-Video Multimodal Language Models](https://arxiv.org/abs/2511.11910)
*Siyou Li,Huanan Wu,Juexi Shao,Yinghao Ma,Yujian Gan,Yihao Luo,Yuwei Wang,Dong Nie,Lu Wang,Wengqing Wu,Le Zhang,Massimo Poesio,Juntao Yu*

Main category: cs.CV

TL;DR: QTSplus是一种轻量级视觉令牌选择模块，通过动态选择与文本查询最相关的视觉证据，解决长视频理解中视觉令牌数量线性增长导致的注意力成本、内存和延迟问题。


<details>
  <summary>Details</summary>
Motivation: 解决多模态大语言模型在长视频理解中面临的视觉令牌数量线性增长问题，该问题导致注意力成本、内存使用和延迟显著增加。

Method: QTSplus通过(i)交叉注意力对视觉令牌评分，(ii)基于查询复杂度预测实例特定的保留预算，(iii)在训练时使用可微分直通估计器选择Top-n令牌，在推理时使用硬门控。此外，小型重新编码器使用绝对时间信息保持时间顺序。

Result: 集成到Qwen2.5-VL后，QTSplus将视觉流压缩高达89%，长视频端到端延迟降低28%。在八个长视频理解基准测试中，整体准确率接近原始Qwen模型，在TempCompass方向和顺序准确率上分别比原始模型提高20.5和5.6个百分点。

Conclusion: QTSplus是一种有效、通用的机制，能够在保持任务相关证据的同时，将MLLMs扩展到现实世界长视频场景。

Abstract: Despite the recent advances in the video understanding ability of multimodal large language models (MLLMs), long video understanding remains a challenge. One of the main issues is that the number of vision tokens grows linearly with video length, which causes an explosion in attention cost, memory, and latency. To solve this challenge, we present Query-aware Token Selector (\textbf{QTSplus}), a lightweight yet powerful visual token selection module that serves as an information gate between the vision encoder and LLMs. Given a text query and video tokens, QTSplus dynamically selects the most important visual evidence for the input text query by (i) scoring visual tokens via cross-attention, (ii) \emph{predicting} an instance-specific retention budget based on the complexity of the query, and (iii) \emph{selecting} Top-$n$ tokens with a differentiable straight-through estimator during training and a hard gate at inference. Furthermore, a small re-encoder preserves temporal order using absolute time information, enabling second-level localization while maintaining global coverage.
  Integrated into Qwen2.5-VL, QTSplus compresses the vision stream by up to \textbf{89\%} and reduces end-to-end latency by \textbf{28\%} on long videos. The evaluation on eight long video understanding benchmarks shows near-parity accuracy overall when compared with the original Qwen models and outperforms the original model by \textbf{+20.5} and \textbf{+5.6} points respectively on TempCompass direction and order accuracies. These results show that QTSplus is an effective, general mechanism for scaling MLLMs to real-world long-video scenarios while preserving task-relevant evidence.
  We will make all code, data, and trained models' weights publicly available.

</details>


### [27] [From Events to Clarity: The Event-Guided Diffusion Framework for Dehazing](https://arxiv.org/abs/2511.11944)
*Ling Wang,Yunfan Lu,Wenzong Ma,Huizai Yao,Pengteng Li,Hui Xiong*

Main category: cs.CV

TL;DR: 首次将事件相机用于图像去雾，通过事件引导的扩散模型，利用事件相机的高动态范围特性来提升去雾效果。


<details>
  <summary>Details</summary>
Motivation: 传统RGB图像动态范围有限，去雾任务存在信息丢失问题。事件相机具有更高动态范围和微秒级延迟，适合雾霾场景。

Method: 提出事件引导的扩散模型，将稀疏的HDR事件特征映射到扩散潜在空间，为生成过程提供精确的结构指导。

Result: 在两个基准测试和自建数据集上实现了最先进的去雾效果，特别是在重度雾霾条件下表现优异。

Conclusion: 事件相机为图像去雾提供了新的解决方案，通过事件引导的扩散模型能够有效恢复雾霾图像中的结构和光照细节。

Abstract: Clear imaging under hazy conditions is a critical task. Prior-based and neural methods have improved results. However, they operate on RGB frames, which suffer from limited dynamic range. Therefore, dehazing remains ill-posed and can erase structure and illumination details. To address this, we use event cameras for dehazing for the \textbf{first time}. Event cameras offer much higher HDR ($120 dBvs.60 dB$) and microsecond latency, therefore they suit hazy scenes. In practice, transferring HDR cues from events to frames is hard because real paired data are scarce. To tackle this, we propose an event-guided diffusion model that utilizes the strong generative priors of diffusion models to reconstruct clear images from hazy inputs by effectively transferring HDR information from events. Specifically, we design an event-guided module that maps sparse HDR event features, \textit{e.g.,} edges, corners, into the diffusion latent space. This clear conditioning provides precise structural guidance during generation, improves visual realism, and reduces semantic drift. For real-world evaluation, we collect a drone dataset in heavy haze (AQI = 341) with synchronized RGB and event sensors. Experiments on two benchmarks and our dataset achieve state-of-the-art results.

</details>


### [28] [Evaluation of Attention Mechanisms in U-Net Architectures for Semantic Segmentation of Brazilian Rock Art Petroglyphs](https://arxiv.org/abs/2511.11959)
*Leonardi Melo,Luís Gustavo,Dimmy Magalhães,Lucciani Vieira,Mauro Araújo*

Main category: cs.CV

TL;DR: 本研究比较了三种基于U-Net的架构用于巴西考古遗址岩画岩刻的语义分割，其中结合残差块和门控注意力机制的Attention-Residual BEGL-UNet表现最佳。


<details>
  <summary>Details</summary>
Motivation: 为了探索注意力机制在考古遗产数字保护中的有效性，特别是针对岩画岩刻的语义分割任务。

Method: 比较了三种U-Net变体：BEGL-UNet、Attention-Residual BEGL-UNet（含残差块和门控注意力）和Spatial Channel Attention BEGL-UNet（基于CBAM的空间通道注意力模块），均使用结合二元交叉熵和高斯边缘增强的BEGL损失函数。

Result: Attention-Residual BEGL-UNet获得最佳性能：Dice分数0.710，验证损失0.067，召回率0.854；相比基线BEGL-UNet（DSC 0.690），Dice分数提升2.5-2.9%。

Conclusion: 注意力机制能有效提升岩画岩刻分割性能，对考古遗产数字保护具有重要价值。

Abstract: This study presents a comparative analysis of three U-Net-based architectures for semantic segmentation of rock art petroglyphs from Brazilian archaeological sites. The investigated architectures were: (1) BEGL-UNet with Border-Enhanced Gaussian Loss function; (2) Attention-Residual BEGL-UNet, incorporating residual blocks and gated attention mechanisms; and (3) Spatial Channel Attention BEGL-UNet, which employs spatial-channel attention modules based on Convolutional Block Attention Module. All implementations employed the BEGL loss function combining binary cross-entropy with Gaussian edge enhancement. Experiments were conducted on images from the Poço da Bebidinha Archaeological Complex, Piauí, Brazil, using 5-fold cross-validation. Among the architectures, Attention-Residual BEGL-UNet achieved the best overall performance with Dice Score of 0.710, validation loss of 0.067, and highest recall of 0.854. Spatial Channel Attention BEGL-UNet obtained comparable performance with DSC of 0.707 and recall of 0.857. The baseline BEGL-UNet registered DSC of 0.690. These results demonstrate the effectiveness of attention mechanisms for archaeological heritage digital preservation, with Dice Score improvements of 2.5-2.9% over the baseline.

</details>


### [29] [From Classification to Cross-Modal Understanding: Leveraging Vision-Language Models for Fine-Grained Renal Pathology](https://arxiv.org/abs/2511.11984)
*Zhenhao Guo,Rachit Saluja,Tianyuan Yao,Quan Liu,Junchao Zhu,Haibo Wang,Daniel Reisenbüchler,Yuankai Huo,Benjamin Liechty,David J. Pisapia,Kenji Ikemura,Steven Salvatoree,Surya Seshane,Mert R. Sabuncu,Yihe Yang,Ruining Deng*

Main category: cs.CV

TL;DR: 该研究评估了在临床数据稀缺情况下，专业病理视觉语言模型在细粒度肾小球亚型分类中的表现，发现专业模型配合微调是最有效的起点，即使只有4-8个标注样本也能显著提升分类性能。


<details>
  <summary>Details</summary>
Motivation: 细粒度肾小球亚型分类对肾脏活检至关重要，但临床上有价值的标注数据稀缺且难以获取。现有计算方法多采用全监督的图像模型进行粗粒度分类，不清楚视觉语言模型在数据受限情况下如何适应临床有意义的亚型分类。

Method: 将细粒度肾小球亚型分类建模为临床现实的少样本问题，系统评估专业病理和通用视觉语言模型，分析分类性能（准确率、AUC、F1）和学习表示的几何特性，包括图像-文本嵌入对齐和亚型可分性。

Result: 病理专业视觉语言骨干网络配合标准微调是最有效的起点，即使每亚型只有4-8个标注样本，这些模型就能开始捕捉差异，在区分度和校准方面取得显著提升。正负样本区分与图像-文本对齐同等重要。

Conclusion: 监督水平和适应策略共同影响诊断性能和多模态结构，为模型选择、适应策略和标注投入提供了指导。专业模型在少样本设置下表现出色，但额外监督仍能带来增量改进。

Abstract: Fine-grained glomerular subtyping is central to kidney biopsy interpretation, but clinically valuable labels are scarce and difficult to obtain. Existing computational pathology approaches instead tend to evaluate coarse diseased classification under full supervision with image-only models, so it remains unclear how vision-language models (VLMs) should be adapted for clinically meaningful subtyping under data constraints. In this work, we model fine-grained glomerular subtyping as a clinically realistic few-shot problem and systematically evaluate both pathology-specialized and general-purpose vision-language models under this setting. We assess not only classification performance (accuracy, AUC, F1) but also the geometry of the learned representations, examining feature alignment between image and text embeddings and the separability of glomerular subtypes. By jointly analyzing shot count, model architecture and domain knowledge, and adaptation strategy, this study provides guidance for future model selection and training under real clinical data constraints. Our results indicate that pathology-specialized vision-language backbones, when paired with the vanilla fine-tuning, are the most effective starting point. Even with only 4-8 labeled examples per glomeruli subtype, these models begin to capture distinctions and show substantial gains in discrimination and calibration, though additional supervision continues to yield incremental improvements. We also find that the discrimination between positive and negative examples is as important as image-text alignment. Overall, our results show that supervision level and adaptation strategy jointly shape both diagnostic performance and multimodal structure, providing guidance for model selection, adaptation strategies, and annotation investment.

</details>


### [30] [BeyondFacial: Identity-Preserving Personalized Generation Beyond Facial Close-ups](https://arxiv.org/abs/2511.11989)
*Songsong Zhang,Chuanqi Tang,Hongguang Zhang,Guijian Tang,Minglong Li,Xueqiong Li,Shaowu Yang,Yuanxi Peng,Wenjing Yang,Jing Zhao*

Main category: cs.CV

TL;DR: 本文提出了一种突破面部特写限制的IPPG方法，通过身份-语义分离的双线推理管道和自适应融合策略，解决了传统方法中身份特征嵌入削弱生成模型语义表达能力的问题。


<details>
  <summary>Details</summary>
Motivation: 现有IPPG方法过度关注面部区域，导致输出以面部特写为主，视觉叙事性弱且在复杂文本提示下语义一致性差。核心问题在于身份特征嵌入干扰了生成模型的语义表达能力。

Method: 设计了双线推理（DLI）管道实现身份-语义分离，提出身份自适应融合（IdAF）策略将身份-语义融合推迟到噪声预测阶段，并引入身份聚合预置（IdAP）模块增强身份保持。

Result: 实验验证该方法在超越面部特写的IPPG任务中实现稳定有效性能，无需手动遮罩或微调即可高效生成，可作为即插即用组件快速部署到现有框架。

Conclusion: 该方法解决了对面部特写的过度依赖，促进了电影级角色-场景创作，为相关领域提供了更丰富的个性化生成能力。

Abstract: Identity-Preserving Personalized Generation (IPPG) has advanced film production and artistic creation, yet existing approaches overemphasize facial regions, resulting in outputs dominated by facial close-ups.These methods suffer from weak visual narrativity and poor semantic consistency under complex text prompts, with the core limitation rooted in identity (ID) feature embeddings undermining the semantic expressiveness of generative models. To address these issues, this paper presents an IPPG method that breaks the constraint of facial close-ups, achieving synergistic optimization of identity fidelity and scene semantic creation. Specifically, we design a Dual-Line Inference (DLI) pipeline with identity-semantic separation, resolving the representation conflict between ID and semantics inherent in traditional single-path architectures. Further, we propose an Identity Adaptive Fusion (IdAF) strategy that defers ID-semantic fusion to the noise prediction stage, integrating adaptive attention fusion and noise decision masking to avoid ID embedding interference on semantics without manual masking. Finally, an Identity Aggregation Prepending (IdAP) module is introduced to aggregate ID information and replace random initializations, further enhancing identity preservation. Experimental results validate that our method achieves stable and effective performance in IPPG tasks beyond facial close-ups, enabling efficient generation without manual masking or fine-tuning. As a plug-and-play component, it can be rapidly deployed in existing IPPG frameworks, addressing the over-reliance on facial close-ups, facilitating film-level character-scene creation, and providing richer personalized generation capabilities for related domains.

</details>


### [31] [Dynamic Parameter Optimization for Highly Transferable Transformation-Based Attacks](https://arxiv.org/abs/2511.11993)
*Jiaming Liang,Chi-Man Pun*

Main category: cs.CV

TL;DR: 本文提出了一种高效的动态参数优化方法，通过分析转换攻击中参数强度的动态模式，显著提高了迁移攻击的转移性能。


<details>
  <summary>Details</summary>
Motivation: 现有转换攻击存在参数优化的盲点：低迭代设置下的性能评估不准确、统一参数策略损害迁移性、传统网格搜索计算复杂度高。

Method: 提出基于上升-下降模式的动态参数优化方法，利用同心衰减模型解释参数强度模式，将复杂度从O(mn)降低到O(nlogm)。

Result: 在不同代理模型、迭代次数和任务上的综合实验表明，DPO能显著提升现有转换攻击的迁移性。

Conclusion: 动态参数优化方法有效解决了转换攻击中的参数优化问题，为深度神经网络的安全研究提供了新思路。

Abstract: Despite their wide application, the vulnerabilities of deep neural networks raise societal concerns. Among them, transformation-based attacks have demonstrated notable success in transfer attacks. However, existing attacks suffer from blind spots in parameter optimization, limiting their full potential. Specifically, (1) prior work generally considers low-iteration settings, yet attacks perform quite differently at higher iterations, so characterizing overall performance based only on low-iteration results is misleading. (2) Existing attacks use uniform parameters for different surrogate models, iterations, and tasks, which greatly impairs transferability. (3) Traditional transformation parameter optimization relies on grid search. For n parameters with m steps each, the complexity is O(mn). Large computational overhead limits further optimization of parameters. To address these limitations, we conduct an empirical study with various transformations as baselines, revealing three dynamic patterns of transferability with respect to parameter strength. We further propose a novel Concentric Decay Model (CDM) to effectively explain these patterns. Building on these insights, we propose an efficient Dynamic Parameter Optimization (DPO) based on the rise-then-fall pattern, reducing the complexity to O(nlogm). Comprehensive experiments on existing transformation-based attacks across different surrogate models, iterations, and tasks demonstrate that our DPO can significantly improve transferability.

</details>


### [32] [LithoSeg: A Coarse-to-Fine Framework for High-Precision Lithography Segmentation](https://arxiv.org/abs/2511.12005)
*Xinyu He,Botong Zhao,Bingbing Li,Shujing Lyu,Jiwei Shen,Yue Lu*

Main category: cs.CV

TL;DR: 提出LithoSeg，一种用于光刻SEM图像分割的粗到细网络，通过人机交互引导的SAM和1D回归方法实现高精度分割和测量


<details>
  <summary>Details</summary>
Motivation: 现有光刻SEM图像分割方法缺乏足够的精度和鲁棒性，限制了在实际半导体制造中的应用

Method: 1. 粗阶段：采用人机交互引导的SAM进行初步分割；2. 细阶段：将2D分割转化为1D回归问题，使用轻量级MLP进行点级细化

Result: LithoSeg在分割精度和计量精度方面均优于现有方法，且需要更少的监督

Conclusion: 该方法为光刻SEM图像分割提供了高精度、低监督的解决方案，具有实际应用前景

Abstract: Accurate segmentation and measurement of lithography scanning electron microscope (SEM) images are crucial for ensuring precise process control, optimizing device performance, and advancing semiconductor manufacturing yield. Lithography segmentation requires pixel-level delineation of groove contours and consistent performance across diverse pattern geometries and process window. However, existing methods often lack the necessary precision and robustness, limiting their practical applicability. To overcome this challenge, we propose LithoSeg, a coarse-to-fine network tailored for lithography segmentation. In the coarse stage, we introduce a Human-in-the-Loop Bootstrapping scheme for the Segment Anything Model (SAM) to attain robustness with minimal supervision. In the subsequent fine stage, we recast 2D segmentation as 1D regression problem by sampling groove-normal profiles using the coarse mask and performing point-wise refinement with a lightweight MLP. LithoSeg outperforms previous approaches in both segmentation accuracy and metrology precision while requiring less supervision, offering promising prospects for real-world applications.

</details>


### [33] [Uncertainty-Guided Selective Adaptation Enables Cross-Platform Predictive Fluorescence Microscopy](https://arxiv.org/abs/2511.12006)
*Kai-Wen K. Yang,Andrew Bai,Alexandra Bermudez,Yunqi Hong,Zoe Latham,Iris Sloan,Michael Liu,Vishrut Goyal,Cho-Jui Hsieh,Neil Y. C. Lin*

Main category: cs.CV

TL;DR: 提出了SIT-ADDA-Auto框架，通过仅调整网络浅层而非整个网络来实现显微镜图像的无标签域适应，在多种场景下优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统对抗域适应方法需要重新训练整个网络，这会破坏已学习的语义表示，导致在新仪器或采集设置下的图像上表现不佳。

Method: SIT-ADDA-Auto框架仅调整最早的卷积层，冻结更深层，结合浅层对抗对齐和预测不确定性来自动选择适应深度，无需目标标签。

Result: 在曝光和光照变化、跨仪器迁移以及多种染色条件下，SIT-ADDA在重建和下游分割任务上优于全编码器适应和非对抗基线方法，语义特征漂移减少。

Conclusion: 该研究为显微镜领域的无标签适应提供了设计原则，并为实际应用场景提供了解决方案，代码已公开。

Abstract: Deep learning is transforming microscopy, yet models often fail when applied to images from new instruments or acquisition settings. Conventional adversarial domain adaptation (ADDA) retrains entire networks, often disrupting learned semantic representations. Here, we overturn this paradigm by showing that adapting only the earliest convolutional layers, while freezing deeper layers, yields reliable transfer. Building on this principle, we introduce Subnetwork Image Translation ADDA with automatic depth selection (SIT-ADDA-Auto), a self-configuring framework that integrates shallow-layer adversarial alignment with predictive uncertainty to automatically select adaptation depth without target labels. We demonstrate robustness via multi-metric evaluation, blinded expert assessment, and uncertainty-depth ablations. Across exposure and illumination shifts, cross-instrument transfer, and multiple stains, SIT-ADDA improves reconstruction and downstream segmentation over full-encoder adaptation and non-adversarial baselines, with reduced drift of semantic features. Our results provide a design rule for label-free adaptation in microscopy and a recipe for field settings; the code is publicly available.

</details>


### [34] [Enhancing Road Safety Through Multi-Camera Image Segmentation with Post-Encroachment Time Analysis](https://arxiv.org/abs/2511.12018)
*Shounak Ray Chaudhuri,Arash Jahangiri,Christopher Paolini*

Main category: cs.CV

TL;DR: 本文提出了一种基于多摄像头计算机视觉的实时交通安全评估框架，通过计算后侵入时间（PET）来识别信号交叉口的高风险区域，解决了传统碰撞研究数据稀疏和延迟的问题。


<details>
  <summary>Details</summary>
Motivation: 传统基于碰撞的交通安全研究受限于数据稀疏性和延迟性，无法实现实时风险评估。需要开发能够连续监测并提供高分辨率安全数据的自动化系统。

Method: 使用四个同步摄像头覆盖交叉口，通过YOLOv11分割进行车辆检测，利用单应性矩阵将车辆多边形转换为统一的鸟瞰图，开发了像素级PET算法生成动态热力图。

Result: 系统在边缘设备上实现了平均2.68 FPS的实时处理，能够以亚秒精度识别高风险区域，生成800×800像素的对数热力图，精度达到3.3平方厘米。

Conclusion: 该研究验证了基于去中心化视觉的PET分析在智能交通系统中的可行性，为高分辨率、实时和可扩展的交叉口安全评估提供了可复制的方法论。

Abstract: Traffic safety analysis at signalized intersections is vital for reducing vehicle and pedestrian collisions, yet traditional crash-based studies are limited by data sparsity and latency. This paper presents a novel multi-camera computer vision framework for real-time safety assessment through Post-Encroachment Time (PET) computation, demonstrated at the intersection of H Street and Broadway in Chula Vista, California. Four synchronized cameras provide continuous visual coverage, with each frame processed on NVIDIA Jetson AGX Xavier devices using YOLOv11 segmentation for vehicle detection. Detected vehicle polygons are transformed into a unified bird's-eye map using homography matrices, enabling alignment across overlapping camera views. A novel pixel-level PET algorithm measures vehicle position without reliance on fixed cells, allowing fine-grained hazard visualization via dynamic heatmaps, accurate to 3.3 sq-cm. Timestamped vehicle and PET data is stored in an SQL database for long-term monitoring. Results over various time intervals demonstrate the framework's ability to identify high-risk regions with sub-second precision and real-time throughput on edge devices, producing data for an 800 x 800 pixel logarithmic heatmap at an average of 2.68 FPS. This study validates the feasibility of decentralized vision-based PET analysis for intelligent transportation systems, offering a replicable methodology for high-resolution, real-time, and scalable intersection safety evaluation.

</details>


### [35] [LIHE: Linguistic Instance-Split Hyperbolic-Euclidean Framework for Generalized Weakly-Supervised Referring Expression Comprehension](https://arxiv.org/abs/2511.12020)
*Xianglong Shi,Silin Cheng,Sirui Zhao,Yunhan Jiang,Enhong Chen,Yang Liu,Sebastien Ourselin*

Main category: cs.CV

TL;DR: 本文提出了LIHE框架，解决弱监督广义指称表达理解任务中的信号模糊和语义表示崩溃问题，通过解耦表达和混合相似度模块实现多目标定位。


<details>
  <summary>Details</summary>
Motivation: 现有弱监督指称表达理解方法受限于一对一映射假设，无法处理现实场景中零个或多个目标的表达，需要更实用的广义任务范式。

Method: 提出两阶段LIHE框架：1）指称解耦阶段预测目标数量并分解复杂表达；2）指称定位阶段使用HEMix混合相似度模块，结合欧几里得精确对齐和双曲几何层次建模优势。

Result: 在gRefCOCO和Ref-ZOM数据集上建立了首个有效的弱监督WGREC基线，HEMix在标准REC基准上IoU@0.5提升达2.5%。

Conclusion: LIHE框架成功解决了WGREC任务的核心挑战，混合相似度设计有效防止语义崩溃，为弱监督广义指称理解提供了可行解决方案。

Abstract: Existing Weakly-Supervised Referring Expression Comprehension (WREC) methods, while effective, are fundamentally limited by a one-to-one mapping assumption, hindering their ability to handle expressions corresponding to zero or multiple targets in realistic scenarios. To bridge this gap, we introduce the Weakly-Supervised Generalized Referring Expression Comprehension task (WGREC), a more practical paradigm that handles expressions with variable numbers of referents. However, extending WREC to WGREC presents two fundamental challenges: supervisory signal ambiguity, where weak image-level supervision is insufficient for training a model to infer the correct number and identity of referents, and semantic representation collapse, where standard Euclidean similarity forces hierarchically-related concepts into non-discriminative clusters, blurring categorical boundaries. To tackle these challenges, we propose a novel WGREC framework named Linguistic Instance-Split Hyperbolic-Euclidean (LIHE), which operates in two stages. The first stage, Referential Decoupling, predicts the number of target objects and decomposes the complex expression into simpler sub-expressions. The second stage, Referent Grounding, then localizes these sub-expressions using HEMix, our innovative hybrid similarity module that synergistically combines the precise alignment capabilities of Euclidean proximity with the hierarchical modeling strengths of hyperbolic geometry. This hybrid approach effectively prevents semantic collapse while preserving fine-grained distinctions between related concepts. Extensive experiments demonstrate LIHE establishes the first effective weakly supervised WGREC baseline on gRefCOCO and Ref-ZOM, while HEMix achieves consistent improvements on standard REC benchmarks, improving IoU@0.5 by up to 2.5\%. The code is available at https://anonymous.4open.science/r/LIHE.

</details>


### [36] [Null-Space Diffusion Distillation for Efficient Photorealistic Lensless Imaging](https://arxiv.org/abs/2511.12024)
*Jose Reinaldo Cunha Santos A V Silva Neto,Hodaka Kawachi,Yasushi Yagi,Tomoya Nakamura*

Main category: cs.CV

TL;DR: NSDD是一种单步扩散蒸馏方法，通过分离空域扩散先验更新和值域空间约束，实现无需配对监督的快速、逼真的无透镜成像重建。


<details>
  <summary>Details</summary>
Motivation: 现有无透镜相机重建方法依赖配对监督（存在镜头-无透镜域不匹配偏差）或通用扩散先验（在噪声大、高度复用、病态的无透镜反卷积场景中失效），需要一种稳定且无需真实值监督的逼真重建方案。

Method: 提出空域扩散蒸馏（NSDD）：单步学生模型蒸馏迭代DDNM+求解器的空域分量，以无透镜测量值和值域空间锚点为条件，保持测量一致性并实现逼真重建。

Result: 在Lensless-FFHQ和PhlatCam数据集上，NSDD速度仅次于Wiener方法，感知质量接近教师模型（LPIPS第二优，低于DDNM+），优于DPS和经典凸优化基线。

Conclusion: NSDD为快速、无需真实值监督、逼真的无透镜成像提供了一条实用路径。

Abstract: State-of-the-art photorealistic reconstructions for lensless cameras often rely on paired lensless-lensed supervision, which can bias models due to lens-lensless domain mismatch. To avoid this, ground-truth-free diffusion priors are attractive; however, generic formulations tuned for conventional inverse problems often break under the noisy, highly multiplexed, and ill-posed lensless deconvolution setting. We observe that methods which separate range-space enforcement from null-space diffusion-prior updates yield stable, realistic reconstructions. Building on this, we introduce Null-Space Diffusion Distillation (NSDD): a single-pass student that distills the null-space component of an iterative DDNM+ solver, conditioned on the lensless measurement and on a range-space anchor. NSDD preserves measurement consistency and achieves photorealistic results without paired supervision at a fraction of the runtime and memory. On Lensless-FFHQ and PhlatCam, NSDD is the second fastest, behind Wiener, and achieves near-teacher perceptual quality (second-best LPIPS, below DDNM+), outperforming DPS and classical convex baselines. These results suggest a practical path toward fast, ground-truth-free, photorealistic lensless imaging.

</details>


### [37] [Bridging Vision and Language for Robust Context-Aware Surgical Point Tracking: The VL-SurgPT Dataset and Benchmark](https://arxiv.org/abs/2511.12026)
*Rulin Zhou,Wenlong He,An Wang,Jianhang Zhang,Xuanhui Zeng,Xi Zhang,Chaowei Zhu,Haijun Hu,Hongliang Ren*

Main category: cs.CV

TL;DR: VL-SurgPT是首个将视觉跟踪与手术场景中点状态文本描述相结合的大规模多模态数据集，通过引入语义上下文信息显著提升了手术环境下的点跟踪准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决手术环境中复杂视觉条件（如烟雾遮挡、镜面反射、组织变形）下点跟踪的挑战，现有数据集缺乏理解跟踪失败机制所需的语义上下文。

Method: 提出VL-SurgPT数据集（908个体内视频片段，包含组织跟踪和器械跟踪）和TG-SurgPT方法，这是一种利用语义描述在视觉挑战条件下提高鲁棒性的文本引导跟踪方法。

Result: 实验结果表明，结合点状态信息显著提高了跟踪准确性和可靠性，特别是在传统纯视觉方法难以应对的不利视觉场景中。

Conclusion: 通过桥接视觉和语言模态，VL-SurgPT能够开发上下文感知的跟踪系统，这对于推进计算机辅助手术应用至关重要，即使在挑战性术中条件下也能保持性能。

Abstract: Accurate point tracking in surgical environments remains challenging due to complex visual conditions, including smoke occlusion, specular reflections, and tissue deformation. While existing surgical tracking datasets provide coordinate information, they lack the semantic context necessary to understand tracking failure mechanisms. We introduce VL-SurgPT, the first large-scale multimodal dataset that bridges visual tracking with textual descriptions of point status in surgical scenes. The dataset comprises 908 in vivo video clips, including 754 for tissue tracking (17,171 annotated points across five challenging scenarios) and 154 for instrument tracking (covering seven instrument types with detailed keypoint annotations). We establish comprehensive benchmarks using eight state-of-the-art tracking methods and propose TG-SurgPT, a text-guided tracking approach that leverages semantic descriptions to improve robustness in visually challenging conditions. Experimental results demonstrate that incorporating point status information significantly improves tracking accuracy and reliability, particularly in adverse visual scenarios where conventional vision-only methods struggle. By bridging visual and linguistic modalities, VL-SurgPT enables the development of context-aware tracking systems crucial for advancing computer-assisted surgery applications that can maintain performance even under challenging intraoperative conditions.

</details>


### [38] [GCAgent: Long-Video Understanding via Schematic and Narrative Episodic Memory](https://arxiv.org/abs/2511.12027)
*Jeong Hun Yeo,Sangyun Chung,Sungjune Park,Dae Hoe Kim,Jinyoung Moon,Yong Man Ro*

Main category: cs.CV

TL;DR: GCAgent框架通过创新的Schematic and Narrative Episodic Memory结构，解决了MLLMs在长视频理解中的长期依赖问题，在Video-MME基准测试中取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在长视频理解中存在token限制和长期依赖捕捉困难的问题，无法有效捕获全局上下文和复杂事件关系。

Method: 提出GCAgent框架，核心创新是Schematic and Narrative Episodic Memory，通过结构化建模事件及其因果时序关系，采用多阶段的Perception-Action-Reflection循环和Memory Manager进行上下文检索。

Result: 在Video-MME Long split上相比强基线MLLM提升23.5%准确率，在7B规模MLLMs中达到SOTA性能，Long split准确率73.4%，整体平均71.9%。

Conclusion: 基于智能体的推理范式和结构化记忆为认知启发的长视频理解提供了有效解决方案。

Abstract: Long-video understanding remains a significant challenge for Multimodal Large Language Models (MLLMs) due to inherent token limitations and the complexity of capturing long-term temporal dependencies. Existing methods often fail to capture the global context and complex event relationships necessary for deep video reasoning. To address this, we introduce GCAgent, a novel Global-Context-Aware Agent framework that achieves comprehensive long-video understanding. Our core innovation is the Schematic and Narrative Episodic Memory. This memory structurally models events and their causal and temporal relations into a concise, organized context, fundamentally resolving the long-term dependency problem. Operating in a multi-stage Perception-Action-Reflection cycle, our GCAgent utilizes a Memory Manager to retrieve relevant episodic context for robust, context-aware inference. Extensive experiments confirm that GCAgent significantly enhances long-video understanding, achieving up to 23.5\% accuracy improvement on the Video-MME Long split over a strong MLLM baseline. Furthermore, our framework establishes state-of-the-art performance among comparable 7B-scale MLLMs, achieving 73.4\% accuracy on the Long split and the highest overall average (71.9\%) on the Video-MME benchmark, validating our agent-based reasoning paradigm and structured memory for cognitively-inspired long-video understanding.

</details>


### [39] [VPHO: Joint Visual-Physical Cue Learning and Aggregation for Hand-Object Pose Estimation](https://arxiv.org/abs/2511.12030)
*Jun Zhou,Chi Xu,Kaifeng Tang,Yuting Ge,Tingrui Guo,Li Cheng*

Main category: cs.CV

TL;DR: 提出了一种结合视觉和物理线索的联合手-物体姿态估计框架，通过视觉-物理线索联合学习和候选姿态聚合，显著提升了姿态估计的准确性和物理合理性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖视觉线索，容易产生违反物理约束的结果（如穿透或非接触），而现有的物理推理方法通常依赖后优化或不可微物理引擎，影响视觉一致性和端到端训练能力。

Method: 1）视觉-物理线索联合学习：训练模型提取2D视觉线索和3D物理线索，实现更全面的手-物体交互表示学习；2）候选姿态聚合：通过扩散生成多个候选姿态，结合视觉和物理预测进行聚合，得到视觉一致且物理合理的最终估计。

Result: 大量实验表明，该方法在姿态准确性和物理合理性方面显著优于现有最先进方法。

Conclusion: 提出的联合视觉-物理框架有效解决了手-物体姿态估计中的物理约束问题，实现了视觉一致性和物理合理性的平衡。

Abstract: Estimating the 3D poses of hands and objects from a single RGB image is a fundamental yet challenging problem, with broad applications in augmented reality and human-computer interaction. Existing methods largely rely on visual cues alone, often producing results that violate physical constraints such as interpenetration or non-contact. Recent efforts to incorporate physics reasoning typically depend on post-optimization or non-differentiable physics engines, which compromise visual consistency and end-to-end trainability. To overcome these limitations, we propose a novel framework that jointly integrates visual and physical cues for hand-object pose estimation. This integration is achieved through two key ideas: 1) joint visual-physical cue learning: The model is trained to extract 2D visual cues and 3D physical cues, thereby enabling more comprehensive representation learning for hand-object interactions; 2) candidate pose aggregation: A novel refinement process that aggregates multiple diffusion-generated candidate poses by leveraging both visual and physical predictions, yielding a final estimate that is visually consistent and physically plausible. Extensive experiments demonstrate that our method significantly outperforms existing state-of-the-art approaches in both pose accuracy and physical plausibility.

</details>


### [40] [Improved Masked Image Generation with Knowledge-Augmented Token Representations](https://arxiv.org/abs/2511.12032)
*Guotao Liang,Baoquan Zhang,Zhiyuan Wen,Zihao Han,Yunming Ye*

Main category: cs.CV

TL;DR: 提出KA-MIG框架，通过引入token级语义依赖的先验知识来增强掩码图像生成的语义理解能力


<details>
  <summary>Details</summary>
Motivation: 现有方法仅依赖模型自身学习视觉token序列的语义依赖关系，但直接学习存在挑战，因为单个token缺乏明确语义且序列通常较长

Method: 构建三种token知识图谱（共现图、语义相似图、位置token不兼容图），设计图感知编码器学习token和位置感知表示，通过轻量级融合机制集成到现有MIG方法中

Result: 在ImageNet上的类条件图像生成任务中，该方法相比现有MIG方法有所提升

Conclusion: 通过引入先验知识图谱，KA-MIG有效增强了模型捕捉语义依赖的能力，提高了生成质量

Abstract: Masked image generation (MIG) has demonstrated remarkable efficiency and high-fidelity images by enabling parallel token prediction. Existing methods typically rely solely on the model itself to learn semantic dependencies among visual token sequences. However, directly learning such semantic dependencies from data is challenging because the individual tokens lack clear semantic meanings, and these sequences are usually long. To address this limitation, we propose a novel Knowledge-Augmented Masked Image Generation framework, named KA-MIG, which introduces explicit knowledge of token-level semantic dependencies (\emph{i.e.}, extracted from the training data) as priors to learn richer representations for improving performance. In particular, we explore and identify three types of advantageous token knowledge graphs, including two positive and one negative graphs (\emph{i.e.}, the co-occurrence graph, the semantic similarity graph, and the position-token incompatibility graph). Based on three prior knowledge graphs, we design a graph-aware encoder to learn token and position-aware representations. After that, a lightweight fusion mechanism is introduced to integrate these enriched representations into the existing MIG methods. Resorting to such prior knowledge, our method effectively enhances the model's ability to capture semantic dependencies, leading to improved generation quality. Experimental results demonstrate that our method improves upon existing MIG for class-conditional image generation on ImageNet.

</details>


### [41] [Calibrated Multimodal Representation Learning with Missing Modalities](https://arxiv.org/abs/2511.12034)
*Xiaohao Liu,Xiaobo Xia,Jiaheng Wei,Shuo Yang,Xiu Su,See-Kiong Ng,Tat-Seng Chua*

Main category: cs.CV

TL;DR: CalMRL是一种多模态表示学习方法，通过校准因缺失模态引起的不完整对齐来解决现有方法需要所有模态同时存在的限制。


<details>
  <summary>Details</summary>
Motivation: 现有多模态表示学习方法需要所有模态同时存在，这限制了在常见缺失模态数据集上的应用。从锚点偏移的理论视角出发，发现缺失模态会导致观测模态与最优锚点之间的偏差。

Method: 提出CalMRL方法，利用模态间的先验和内在联系在表示层面对缺失模态进行建模。采用双步学习方法，通过后验分布的闭式解解决优化困境。

Result: 理论验证了CalMRL能够缓解锚点偏移并保证收敛。实验表明该方法能够有效利用缺失模态数据，为现有先进方法提供新的灵活性。

Conclusion: CalMRL通过校准不完全对齐，成功解决了多模态表示学习中缺失模态的问题，在理论和实验上都表现出优越性。

Abstract: Multimodal representation learning harmonizes distinct modalities by aligning them into a unified latent space. Recent research generalizes traditional cross-modal alignment to produce enhanced multimodal synergy but requires all modalities to be present for a common instance, making it challenging to utilize prevalent datasets with missing modalities. We provide theoretical insights into this issue from an anchor shift perspective. Observed modalities are aligned with a local anchor that deviates from the optimal one when all modalities are present, resulting in an inevitable shift. To address this, we propose CalMRL for multimodal representation learning to calibrate incomplete alignments caused by missing modalities. Specifically, CalMRL leverages the priors and the inherent connections among modalities to model the imputation for the missing ones at the representation level. To resolve the optimization dilemma, we employ a bi-step learning method with the closed-form solution of the posterior distribution of shared latents. We validate its mitigation of anchor shift and convergence with theoretical guidance. By equipping the calibrated alignment with the existing advanced method, we offer new flexibility to absorb data with missing modalities, which is originally unattainable. Extensive experiments and comprehensive analyses demonstrate the superiority of CalMRL. Our code, model checkpoints, and evaluation raw data will be publicly available.

</details>


### [42] [SRSplat: Feed-Forward Super-Resolution Gaussian Splatting from Sparse Multi-View Images](https://arxiv.org/abs/2511.12040)
*Xinyuan Hu,Changyue Shi,Chuxiao Yang,Minghao Chen,Jiajun Ding,Tao Wei,Chen Wei,Zhou Yu,Min Tan*

Main category: cs.CV

TL;DR: SRSplat是一个前馈式3D重建框架，能从少量低分辨率图像重建高分辨率3D场景，通过结合外部参考图像和内部纹理线索来弥补纹理细节缺失问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在从稀疏低分辨率图像进行3D重建时，由于缺乏高频信息，难以恢复精细纹理细节。

Method: 使用MLLMs和扩散模型构建场景特定参考图库；引入参考引导特征增强模块对齐融合LR图像和参考图像特征；训练解码器预测高斯基元；使用纹理感知密度控制自适应调整高斯密度。

Result: 在RealEstate10K、ACID和DTU等多个数据集上优于现有方法，并展现出强大的跨数据集和跨分辨率泛化能力。

Conclusion: SRSplat通过结合外部参考和内部纹理信息，有效解决了低分辨率输入下的3D重建纹理细节恢复问题。

Abstract: Feed-forward 3D reconstruction from sparse, low-resolution (LR) images is a crucial capability for real-world applications, such as autonomous driving and embodied AI. However, existing methods often fail to recover fine texture details. This limitation stems from the inherent lack of high-frequency information in LR inputs. To address this, we propose \textbf{SRSplat}, a feed-forward framework that reconstructs high-resolution 3D scenes from only a few LR views. Our main insight is to compensate for the deficiency of texture information by jointly leveraging external high-quality reference images and internal texture cues. We first construct a scene-specific reference gallery, generated for each scene using Multimodal Large Language Models (MLLMs) and diffusion models. To integrate this external information, we introduce the \textit{Reference-Guided Feature Enhancement (RGFE)} module, which aligns and fuses features from the LR input images and their reference twin image. Subsequently, we train a decoder to predict the Gaussian primitives using the multi-view fused feature obtained from \textit{RGFE}. To further refine predicted Gaussian primitives, we introduce \textit{Texture-Aware Density Control (TADC)}, which adaptively adjusts Gaussian density based on the internal texture richness of the LR inputs. Extensive experiments demonstrate that our SRSplat outperforms existing methods on various datasets, including RealEstate10K, ACID, and DTU, and exhibits strong cross-dataset and cross-resolution generalization capabilities.

</details>


### [43] [FedSDA: Federated Stain Distribution Alignment for Non-IID Histopathological Image Classification](https://arxiv.org/abs/2511.12044)
*Cheng-Chang Tsai,Kai-Wen Cheng,Chun-Shien Lu*

Main category: cs.CV

TL;DR: 提出FedSDA方法，通过扩散模型和染色分离技术来对齐联邦学习中非IID病理图像的染色分布，解决数据分布偏移问题，同时保护隐私。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中非IID病理图像数据存在分布偏移问题，传统方法关注有限。本文从数据分布角度出发，通过调整客户端数据分布来解决这一挑战。

Method: 基于扩散模型的数据分布拟合能力和染色分离技术，提出FedSDA方法，将每个客户端的染色分布与目标分布对齐，同时规避隐私泄露风险。

Result: 实验表明FedSDA不仅能有效提升关注客户端模型更新差异的基线方法，还优于从数据分布角度处理非IID问题的基线方法。

Conclusion: FedSDA为计算病理学社区提供了有价值的实践见解，能有效缓解联邦学习中的非IID数据问题。

Abstract: Federated learning (FL) has shown success in collaboratively training a model among decentralized data resources without directly sharing privacy-sensitive training data. Despite recent advances, non-IID (non-independent and identically distributed) data poses an inevitable challenge that hinders the use of FL. In this work, we address the issue of non-IID histopathological images with feature distribution shifts from an intuitive perspective that has only received limited attention. Specifically, we address this issue from the perspective of data distribution by solely adjusting the data distributions of all clients. Building on the success of diffusion models in fitting data distributions and leveraging stain separation to extract the pivotal features that are closely related to the non-IID properties of histopathological images, we propose a Federated Stain Distribution Alignment (FedSDA) method. FedSDA aligns the stain distribution of each client with a target distribution in an FL framework to mitigate distribution shifts among clients. Furthermore, considering that training diffusion models on raw data in FL has been shown to be susceptible to privacy leakage risks, we circumvent this problem while still effectively achieving alignment. Extensive experimental results show that FedSDA is not only effective in improving baselines that focus on mitigating disparities across clients' model updates but also outperforms baselines that address the non-IID data issues from the perspective of data distribution. We show that FedSDA provides valuable and practical insights for the computational pathology community.

</details>


### [44] [DCMM-Transformer: Degree-Corrected Mixed-Membership Attention for Medical Imaging](https://arxiv.org/abs/2511.12047)
*Huimin Cheng,Xiaowei Yu,Shushan Wu,Luyang Fang,Chao Cao,Jing Zhang,Tianming Liu,Dajiang Zhu,Wenxuan Zhong,Ping Ma*

Main category: cs.CV

TL;DR: DCMM-Transformer是一种新型ViT架构，通过Degree-Corrected Mixed-Membership模型在自注意力中引入可解释的解剖结构偏置，解决了传统ViT无法利用医学图像潜在解剖分组的问题。


<details>
  <summary>Details</summary>
Motivation: 医学图像包含器官、组织和病理区域等潜在解剖结构，但标准Vision Transformers无法有效利用这些结构。现有方法如SBM-Transformer存在不可微分、训练不稳定和无法建模复杂社区结构的问题。

Method: 提出DCMM-Transformer，在自注意力机制中引入Degree-Corrected Mixed-Membership模型作为加性偏置，以完全可微分和可解释的方式整合社区结构和度异质性，避免了乘性掩码和二元采样。

Result: 在脑部、胸部、乳腺和眼部等多种医学影像数据集上的实验表明，该方法具有优越的性能和泛化能力。

Conclusion: 学习的群组结构和结构化注意力调制显著增强了可解释性，产生了解剖学意义明确且语义连贯的注意力图。

Abstract: Medical images exhibit latent anatomical groupings, such as organs, tissues, and pathological regions, that standard Vision Transformers (ViTs) fail to exploit. While recent work like SBM-Transformer attempts to incorporate such structures through stochastic binary masking, they suffer from non-differentiability, training instability, and the inability to model complex community structure. We present DCMM-Transformer, a novel ViT architecture for medical image analysis that incorporates a Degree-Corrected Mixed-Membership (DCMM) model as an additive bias in self-attention. Unlike prior approaches that rely on multiplicative masking and binary sampling, our method introduces community structure and degree heterogeneity in a fully differentiable and interpretable manner. Comprehensive experiments across diverse medical imaging datasets, including brain, chest, breast, and ocular modalities, demonstrate the superior performance and generalizability of the proposed approach. Furthermore, the learned group structure and structured attention modulation substantially enhance interpretability by yielding attention maps that are anatomically meaningful and semantically coherent.

</details>


### [45] [DeiTFake: Deepfake Detection Model using DeiT Multi-Stage Training](https://arxiv.org/abs/2511.12048)
*Saksham Kumar,Ashish Singh,Srinivasarao Thota,Sunil Kumar Singh,Chandan Kumar*

Main category: cs.CV

TL;DR: 提出DeiTFake方法，基于DeiT变换器和两阶段渐进训练策略，用于深度伪造检测，在OpenForensics数据集上达到99.22%准确率


<details>
  <summary>Details</summary>
Motivation: 深度伪造对数字媒体完整性构成重大威胁，需要更有效的检测方法

Method: 使用DeiT变换器架构，采用两阶段渐进训练策略：第一阶段标准数据增强的迁移学习，第二阶段使用高级仿射和深度伪造特定增强的微调

Result: 在OpenForensics数据集（190,335张图像）上，第一阶段达到98.71%准确率，第二阶段达到99.22%准确率和0.9997 AUROC，优于最新基线

Conclusion: 该方法通过知识蒸馏捕捉细微篡改痕迹，增强检测模型的鲁棒性，为面部深度伪造检测提供了实用基准

Abstract: Deepfakes are major threats to the integrity of digital media. We propose DeiTFake, a DeiT-based transformer and a novel two-stage progressive training strategy with increasing augmentation complexity. The approach applies an initial transfer-learning phase with standard augmentations followed by a fine-tuning phase using advanced affine and deepfake-specific augmentations. DeiT's knowledge distillation model captures subtle manipulation artifacts, increasing robustness of the detection model. Trained on the OpenForensics dataset (190,335 images), DeiTFake achieves 98.71\% accuracy after stage one and 99.22\% accuracy with an AUROC of 0.9997, after stage two, outperforming the latest OpenForensics baselines. We analyze augmentation impact and training schedules, and provide practical benchmarks for facial deepfake detection.

</details>


### [46] [UniABG: Unified Adversarial View Bridging and Graph Correspondence for Unsupervised Cross-View Geo-Localization](https://arxiv.org/abs/2511.12054)
*Cuiqun Chen,Qi Chen,Bin Yang,Xingyi Zhang*

Main category: cs.CV

TL;DR: UniABG是一种新颖的双阶段无监督跨视角地理定位框架，通过结合对抗性视图桥接和图基对应校准来解决跨视角域差距问题，在无监督设置下实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 传统监督方法依赖大量成对标注，扩展性受限；无监督方法则因跨视角域差距导致伪标签噪声问题。需要一种既能避免标注成本又能提升伪标签质量的方法。

Method: 提出双阶段框架：1）视图感知对抗桥接(VAAB)建模视图不变特征；2）异构图过滤校准(HGFC)构建双视图结构图来精化跨视角关联。

Result: 在University-1652数据集上卫星→无人机AP提升10.63%，在SUES-200上提升16.73%，甚至超越监督基线方法。

Conclusion: UniABG通过对抗学习和图结构建模有效解决了无监督跨视角地理定位中的伪标签噪声问题，证明了其在无监督设置下的优越性能。

Abstract: Cross-view geo-localization (CVGL) matches query images ($\textit{e.g.}$, drone) to geographically corresponding opposite-view imagery ($\textit{e.g.}$, satellite). While supervised methods achieve strong performance, their reliance on extensive pairwise annotations limits scalability. Unsupervised alternatives avoid annotation costs but suffer from noisy pseudo-labels due to intrinsic cross-view domain gaps. To address these limitations, we propose $\textit{UniABG}$, a novel dual-stage unsupervised cross-view geo-localization framework integrating adversarial view bridging with graph-based correspondence calibration. Our approach first employs View-Aware Adversarial Bridging (VAAB) to model view-invariant features and enhance pseudo-label robustness. Subsequently, Heterogeneous Graph Filtering Calibration (HGFC) refines cross-view associations by constructing dual inter-view structure graphs, achieving reliable view correspondence. Extensive experiments demonstrate state-of-the-art unsupervised performance, showing that UniABG improves Satellite $\rightarrow$ Drone AP by +10.63\% on University-1652 and +16.73\% on SUES-200, even surpassing supervised baselines. The source code is available at https://github.com/chenqi142/UniABG

</details>


### [47] [PipeDiT: Accelerating Diffusion Transformers in Video Generation with Task Pipelining and Model Decoupling](https://arxiv.org/abs/2511.12056)
*Sijie Wang,Qiang Wang,Shaohuai Shi*

Main category: cs.CV

TL;DR: PipeDiT是一个用于加速视频生成的流水线框架，通过三个创新点显著提升推理速度和降低内存消耗。


<details>
  <summary>Details</summary>
Motivation: 基于扩散变换器（DiT）的视频生成模型虽然性能出色，但实际部署受到推理速度慢和内存消耗高的限制。

Method: 1. 设计序列并行流水线算法（PipeSP）实现多GPU间的计算和通信流水线化；2. 提出DeDiVAE将扩散模块和VAE模块解耦到不同GPU组并行执行；3. 提出注意力协同处理（Aco）方法更好地利用VAE组GPU资源。

Result: 在8-GPU系统上的实验表明，PipeDiT在常见分辨率和时间步配置下，相比OpenSoraPlan和HunyuanVideo实现了1.06倍到4.02倍的加速。

Conclusion: PipeDiT框架有效解决了DiT模型部署中的性能瓶颈，为视频生成的实际应用提供了可行的加速方案。

Abstract: Video generation has been advancing rapidly, and diffusion transformer (DiT) based models have demonstrated remark- able capabilities. However, their practical deployment is of- ten hindered by slow inference speeds and high memory con- sumption. In this paper, we propose a novel pipelining frame- work named PipeDiT to accelerate video generation, which is equipped with three main innovations. First, we design a pipelining algorithm (PipeSP) for sequence parallelism (SP) to enable the computation of latent generation and commu- nication among multiple GPUs to be pipelined, thus reduc- ing inference latency. Second, we propose DeDiVAE to de- couple the diffusion module and the variational autoencoder (VAE) module into two GPU groups, whose executions can also be pipelined to reduce memory consumption and infer- ence latency. Third, to better utilize the GPU resources in the VAE group, we propose an attention co-processing (Aco) method to further reduce the overall video generation latency. We integrate our PipeDiT into both OpenSoraPlan and Hun- yuanVideo, two state-of-the-art open-source video generation frameworks, and conduct extensive experiments on two 8- GPU systems. Experimental results show that, under many common resolution and timestep configurations, our PipeDiT achieves 1.06x to 4.02x speedups over OpenSoraPlan and HunyuanVideo.

</details>


### [48] [MovSemCL: Movement-Semantics Contrastive Learning for Trajectory Similarity](https://arxiv.org/abs/2511.12061)
*Zhichen Lai,Hua Lu,Huan Li,Jialiang Li,Christian S. Jensen*

Main category: cs.CV

TL;DR: MovSemCL是一个用于轨迹相似度计算的运动语义对比学习框架，通过运动语义特征提取、分块注意力机制和曲率引导增强策略，解决了现有方法在语义建模、计算效率和物理合理性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的轨迹相似度计算方法存在三个主要问题：(1) 对轨迹语义和层次结构建模不足，缺乏运动动态提取和多尺度结构表示；(2) 逐点编码导致计算成本高；(3) 使用物理上不合理的增强方法扭曲轨迹语义。

Method: MovSemCL首先将原始GPS轨迹转换为运动语义特征并分割为块，然后使用块内和块间注意力机制编码局部和全局轨迹模式，实现高效的分层表示。此外，还设计了曲率引导的增强策略，保留信息丰富的轨迹段（如转弯和交叉口）并掩蔽冗余部分。

Result: 在真实数据集上的实验表明，MovSemCL在相似性搜索任务中平均排名接近理想值1，在启发式近似任务中性能提升高达20.3%，同时推理延迟降低高达43.4%。

Conclusion: MovSemCL通过运动语义特征提取、分层注意力机制和物理合理的增强策略，有效解决了轨迹相似度计算中的关键挑战，在性能和效率方面均优于现有最先进方法。

Abstract: Trajectory similarity computation is fundamental functionality that is used for, e.g., clustering, prediction, and anomaly detection. However, existing learning-based methods exhibit three key limitations: (1) insufficient modeling of trajectory semantics and hierarchy, lacking both movement dynamics extraction and multi-scale structural representation; (2) high computational costs due to point-wise encoding; and (3) use of physically implausible augmentations that distort trajectory semantics. To address these issues, we propose MovSemCL, a movement-semantics contrastive learning framework for trajectory similarity computation. MovSemCL first transforms raw GPS trajectories into movement-semantics features and then segments them into patches. Next, MovSemCL employs intra- and inter-patch attentions to encode local as well as global trajectory patterns, enabling efficient hierarchical representation and reducing computational costs. Moreover, MovSemCL includes a curvature-guided augmentation strategy that preserves informative segments (e.g., turns and intersections) and masks redundant ones, generating physically plausible augmented views. Experiments on real-world datasets show that MovSemCL is capable of outperforming state-of-the-art methods, achieving mean ranks close to the ideal value of 1 at similarity search tasks and improvements by up to 20.3% at heuristic approximation, while reducing inference latency by up to 43.4%.

</details>


### [49] [DCA-LUT: Deep Chromatic Alignment with 5D LUT for Purple Fringing Removal](https://arxiv.org/abs/2511.12066)
*Jialang Lu,Shuning Sun,Pu Wang,Chen Wu,Feng Gao,Lina Gong,Dianjie Lu,Guijuan Zhang,Zhuoran Zheng*

Main category: cs.CV

TL;DR: DCA-LUT是首个基于深度学习的紫边去除框架，通过色度感知坐标变换模块和5D查找表，有效解决相机镜头色差导致的紫边问题


<details>
  <summary>Details</summary>
Motivation: 传统紫边去除方法依赖昂贵的消色差镜头硬件和手工特征提取，忽略了数据驱动方法。紫边由镜头色散引起的RGB通道空间错位造成，需要更智能的解决方案

Method: 提出色度感知坐标变换(CA-CT)模块，学习图像自适应的颜色空间来解耦和隔离紫边；使用5D查找表进行非线性颜色映射；构建大规模合成紫边数据集(PF-Synth)进行训练

Result: 在合成和真实数据集上的广泛实验表明，该方法在紫边去除方面达到了最先进的性能

Conclusion: DCA-LUT框架通过深度学习方法有效解决了紫边问题，为数字成像质量提升提供了新的技术路径

Abstract: Purple fringing, a persistent artifact caused by Longitudinal Chromatic Aberration (LCA) in camera lenses, has long degraded the clarity and realism of digital imaging. Traditional solutions rely on complex and expensive apochromatic (APO) lens hardware and the extraction of handcrafted features, ignoring the data-driven approach. To fill this gap, we introduce DCA-LUT, the first deep learning framework for purple fringing removal. Inspired by the physical root of the problem, the spatial misalignment of RGB color channels due to lens dispersion, we introduce a novel Chromatic-Aware Coordinate Transformation (CA-CT) module, learning an image-adaptive color space to decouple and isolate fringing into a dedicated dimension. This targeted separation allows the network to learn a precise ``purple fringe channel", which then guides the accurate restoration of the luminance channel. The final color correction is performed by a learned 5D Look-Up Table (5D LUT), enabling efficient and powerful% non-linear color mapping. To enable robust training and fair evaluation, we constructed a large-scale synthetic purple fringing dataset (PF-Synth). Extensive experiments in synthetic and real-world datasets demonstrate that our method achieves state-of-the-art performance in purple fringing removal.

</details>


### [50] [Learning to Hear by Seeing: It's Time for Vision Language Models to Understand Artistic Emotion from Sight and Sound](https://arxiv.org/abs/2511.12077)
*Dengming Zhang,Weitao You,Jingxiong Li,Weishen Lin,Wenda Shi,Xue Zhao,Heda Zuo,Junxian Wu,Lingyun Sun*

Main category: cs.CV

TL;DR: VAEmotionLLM是一个两阶段框架，通过有限音频预训练让视觉语言模型具备听觉能力，并增强跨模态情感理解。该方法在艺术情感基准测试中达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 当前音频-视觉语言模型通常需要大规模音频预训练，限制了可扩展性。同时，现有工作大多是人类中心或单模态的，忽视了艺术作品有意表达的情感。

Method: 两阶段框架：1）VG-Align通过同步音频-视频片段对齐共享LLM的下一个标记分布，将冻结的视觉路径蒸馏到新的音频路径；2）轻量级EmoAdapter注入情感敏感残差并应用情感监督来增强跨模态情感理解。

Result: 在ArtEmoBenchmark基准测试中，VAEmotionLLM超越了音频、视觉和音频-视觉基线，达到最先进水平。消融实验表明各组件具有互补性。

Conclusion: 该研究提出了一种无需大规模音频预训练即可让视觉语言模型具备听觉能力的方法，显著提升了跨模态情感理解能力，为LLM的情感理解提供了新思路。

Abstract: Emotion understanding is critical for making Large Language Models (LLMs) more general, reliable, and aligned with humans. Art conveys emotion through the joint design of visual and auditory elements, yet most prior work is human-centered or single-modality, overlooking the emotion intentionally expressed by the artwork. Meanwhile, current Audio-Visual Language Models (AVLMs) typically require large-scale audio pretraining to endow Visual Language Models (VLMs) with hearing, which limits scalability. We present Vision Anchored Audio-Visual Emotion LLM (VAEmotionLLM), a two-stage framework that teaches a VLM to hear by seeing with limited audio pretraining and to understand emotion across modalities. In Stage 1, Vision-Guided Audio Alignment (VG-Align) distills the frozen visual pathway into a new audio pathway by aligning next-token distributions of the shared LLM on synchronized audio-video clips, enabling hearing without a large audio dataset. In Stage 2, a lightweight Cross-Modal Emotion Adapter (EmoAdapter), composed of the Emotion Enhancer and the Emotion Supervisor, injects emotion-sensitive residuals and applies emotion supervision to enhance cross-modal emotion understanding. We also construct ArtEmoBenchmark, an art-centric emotion benchmark that evaluates content and emotion understanding under audio-only, visual-only, and audio-visual inputs. VAEmotionLLM achieves state-of-the-art results on ArtEmoBenchmark, outperforming audio-only, visual-only, and audio-visual baselines. Ablations show that the proposed components are complementary.

</details>


### [51] [Point Cloud Quantization through Multimodal Prompting for 3D Understanding](https://arxiv.org/abs/2511.12079)
*Hongxuan Li,Wencheng Zhu,Huiying Xu,Xinzhong Zhu,Pengfei Zhu*

Main category: cs.CV

TL;DR: 提出了一种基于多模态提示驱动的点云量化框架，利用文本嵌入作为原型先验，通过双约束量化空间和Gumbel-Softmax松弛实现几何和语义信息的联合编码。


<details>
  <summary>Details</summary>
Motivation: 当前基于可训练向量或聚类质心的原型量化方法在代表性和可解释性方面存在不足，需要更鲁棒的码本设计来提升多模态模型的性能。

Method: 1) 利用预训练模型的文本嵌入作为视觉语义原型先验；2) 通过多模态提示自适应优化原型；3) 构建双约束量化空间（紧凑性和分离性正则化）；4) 使用Gumbel-Softmax实现可微分离散化。

Result: 在ModelNet40和ScanObjectNN数据集上的大量实验证明了该方法的优越有效性。

Conclusion: 该方法通过多模态提示驱动的量化框架，有效解决了视觉-语言语义鸿沟问题，实现了点云分析中几何和语义信息的统一表示。

Abstract: Vector quantization has emerged as a powerful tool in large-scale multimodal models, unifying heterogeneous representations through discrete token encoding. However, its effectiveness hinges on robust codebook design. Current prototype-based approaches relying on trainable vectors or clustered centroids fall short in representativeness and interpretability, even as multimodal alignment demonstrates its promise in vision-language models. To address these limitations, we propose a simple multimodal prompting-driven quantization framework for point cloud analysis. Our methodology is built upon two core insights: 1) Text embeddings from pre-trained models inherently encode visual semantics through many-to-one contrastive alignment, naturally serving as robust prototype priors; and 2) Multimodal prompts enable adaptive refinement of these prototypes, effectively mitigating vision-language semantic gaps. The framework introduces a dual-constrained quantization space, enforced by compactness and separation regularization, which seamlessly integrates visual and prototype features, resulting in hybrid representations that jointly encode geometric and semantic information. Furthermore, we employ Gumbel-Softmax relaxation to achieve differentiable discretization while maintaining quantization sparsity. Extensive experiments on the ModelNet40 and ScanObjectNN datasets clearly demonstrate the superior effectiveness of the proposed method.

</details>


### [52] [Supervised Multilabel Image Classification Using Residual Networks with Probabilistic Reasoning](https://arxiv.org/abs/2511.12082)
*Lokender Singh,Saksham Kumar,Chandan Kumar*

Main category: cs.CV

TL;DR: 该论文提出了一种基于改进ResNet-101架构和概率推理的多标签图像分类方法，在COCO-2014数据集上取得了优于现有技术的性能表现。


<details>
  <summary>Details</summary>
Motivation: 多标签图像分类在计算机视觉应用中具有重要意义，但现有方法在处理标签依赖性和不确定性方面存在挑战。

Method: 使用改进的ResNet-101架构，通过概率推理模拟标签依赖性和不确定性，提升多标签分类的预测准确性。

Result: 在COCO-2014数据集上达到0.794 mAP，优于ResNet-SRN（0.771）和Vision Transformer基线（0.785）。

Conclusion: 将概率推理集成到深度学习模型中，能够有效解决多标签场景带来的挑战，取得了state-of-the-art的结果。

Abstract: Multilabel image categorization has drawn interest recently because of its numerous computer vision applications. The proposed work introduces a novel method for classifying multilabel images using the COCO-2014 dataset and a modified ResNet-101 architecture. By simulating label dependencies and uncertainties, the approach uses probabilistic reasoning to improve prediction accuracy. Extensive tests show that the model outperforms earlier techniques and approaches to state-of-the-art outcomes in multilabel categorization. The work also thoroughly assesses the model's performance using metrics like precision-recall score and achieves 0.794 mAP on COCO-2014, outperforming ResNet-SRN (0.771) and Vision Transformer baselines (0.785). The novelty of the work lies in integrating probabilistic reasoning into deep learning models to effectively address the challenges presented by multilabel scenarios.

</details>


### [53] [SemanticStitch: Enhancing Image Coherence through Foreground-Aware Seam Carving](https://arxiv.org/abs/2511.12084)
*Ji-Ping Jin,Chen-Bin Feng,Rui Fan,Chi-Man Vong*

Main category: cs.CV

TL;DR: SemanticStitch是一个基于深度学习的图像拼接框架，通过引入语义先验信息来保护前景对象的完整性，显著提升拼接质量。


<details>
  <summary>Details</summary>
Motivation: 传统图像拼接方法因拍摄角度、位置差异和物体运动导致错位和视觉不一致问题，且传统接缝雕刻方法忽略语义信息，破坏前景连续性。

Method: 提出SemanticStitch框架，包含新颖的损失函数，强调显著对象的语义完整性，并构建了两个专门的真实世界数据集进行评估。

Result: 实验结果表明，该方法相比传统技术有显著改进，为实际应用提供有力支持。

Conclusion: SemanticStitch通过语义信息整合有效解决了图像拼接中的前景连续性破坏问题，具有实际应用价值。

Abstract: Image stitching often faces challenges due to varying capture angles, positional differences, and object movements, leading to misalignments and visual discrepancies. Traditional seam carving methods neglect semantic information, causing disruptions in foreground continuity. We introduce SemanticStitch, a deep learning-based framework that incorporates semantic priors of foreground objects to preserve their integrity and enhance visual coherence. Our approach includes a novel loss function that emphasizes the semantic integrity of salient objects, significantly improving stitching quality. We also present two specialized real-world datasets to evaluate our method's effectiveness. Experimental results demonstrate substantial improvements over traditional techniques, providing robust support for practical applications.

</details>


### [54] [OPFormer: Object Pose Estimation leveraging foundation model with geometric encoding](https://arxiv.org/abs/2511.12614)
*Artem Moroz,Vít Zeman,Martin Mikšík,Elizaveta Isianova,Miroslav David,Pavel Burget,Varun Burde*

Main category: cs.CV

TL;DR: 提出了一个统一的端到端框架，将物体检测和姿态估计与灵活的初始化过程相结合，支持基于CAD模型和神经辐射场（NeRF）的物体表示，并在BOP基准测试中表现出良好的准确性和效率平衡。


<details>
  <summary>Details</summary>
Motivation: 为了解决物体检测和6D姿态估计在实际应用中的灵活性问题，特别是在缺乏传统3D CAD模型的情况下，需要一种能够快速生成高质量物体表示并实现精确姿态估计的统一框架。

Method: 采用CNOS检测器进行物体定位，结合新型姿态估计模块OPFormer（基于Transformer架构），利用基础模型进行特征提取，通过多模板视图联合编码和NOCS几何先验来学习全面的物体表示，最终通过解码器建立2D-3D对应关系来确定姿态。

Result: 在具有挑战性的BOP基准测试中，该集成系统在准确性和效率之间取得了良好的平衡，展示了其在基于模型和无模型场景中的实际应用能力。

Conclusion: 该框架成功实现了物体检测和姿态估计的端到端集成，支持灵活的物体初始化方式，为实际应用提供了高效且准确的解决方案。

Abstract: We introduce a unified, end-to-end framework that seamlessly integrates object detection and pose estimation with a versatile onboarding process. Our pipeline begins with an onboarding stage that generates object representations from either traditional 3D CAD models or, in their absence, by rapidly reconstructing a high-fidelity neural representation (NeRF) from multi-view images. Given a test image, our system first employs the CNOS detector to localize target objects. For each detection, our novel pose estimation module, OPFormer, infers the precise 6D pose. The core of OPFormer is a transformer-based architecture that leverages a foundation model for robust feature extraction. It uniquely learns a comprehensive object representation by jointly encoding multiple template views and enriches these features with explicit 3D geometric priors using Normalized Object Coordinate Space (NOCS). A decoder then establishes robust 2D-3D correspondences to determine the final pose. Evaluated on the challenging BOP benchmarks, our integrated system demonstrates a strong balance between accuracy and efficiency, showcasing its practical applicability in both model-based and model-free scenarios.

</details>


### [55] [Teaching Prompts to Coordinate: Hierarchical Layer-Grouped Prompt Tuning for Continual Learning](https://arxiv.org/abs/2511.12090)
*Shengqin Jiang,Tianqi Kong,Yuankai Qi,Haokui Zhang,Lina Yao,Quan Z. Sheng,Qingshan Liu,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: 提出了一种分层分组提示调优方法，通过共享层组提示和基于根提示生成子提示的方式，减少层间过度独立调优，从而降低灾难性遗忘风险。


<details>
  <summary>Details</summary>
Motivation: 现有的基于提示的持续学习方法在每个层独立添加任务特定提示，虽然灵活性高，但容易导致层间不必要更新，增加灾难性遗忘风险。

Method: 分层分组提示调优：1）同组层共享经过位置编码调整的提示，保持预训练模型特征关系；2）使用单一任务特定根提示生成各层组的子提示，增强协同性。

Result: 在四个基准测试上的广泛实验表明，该方法相比多种先进方法取得了更优性能。

Conclusion: 所提出的分层分组提示调优方法通过增强层间协同性和保持预训练模型结构，有效提升了持续学习中的模型稳定性。

Abstract: Prompt-based continual learning methods fine-tune only a small set of additional learnable parameters while keeping the pre-trained model's parameters frozen. It enables efficient adaptation to new tasks while mitigating the risk of catastrophic forgetting. These methods typically attach one independent task-specific prompt to each layer of pre-trained models to locally modulate its features, ensuring that the layer's representation aligns with the requirements of the new task. However, although introducing learnable prompts independently at each layer provides high flexibility for adapting to new tasks, this overly flexible tuning could make certain layers susceptible to unnecessary updates. As all prompts till the current task are added together as a final prompt for all seen tasks, the model may easily overwrite feature representations essential to previous tasks, which increases the risk of catastrophic forgetting. To address this issue, we propose a novel hierarchical layer-grouped prompt tuning method for continual learning. It improves model stability in two ways: (i) Layers in the same group share roughly the same prompts, which are adjusted by position encoding. This helps preserve the intrinsic feature relationships and propagation pathways of the pre-trained model within each group. (ii) It utilizes a single task-specific root prompt to learn to generate sub-prompts for each layer group. In this way, all sub-prompts are conditioned on the same root prompt, enhancing their synergy and reducing independence. Extensive experiments across four benchmarks demonstrate that our method achieves favorable performance compared with several state-of-the-art methods.

</details>


### [56] [Learning from Dense Events: Towards Fast Spiking Neural Networks Training via Event Dataset Distillatio](https://arxiv.org/abs/2511.12095)
*Shuhan Ye,Yi Yu,Qixin Zhang,Chenqi Kong,Qiangqiang Wu,Kun Wang,Xudong Jiang*

Main category: cs.CV

TL;DR: PACE是首个面向SNN和事件视觉的数据集蒸馏框架，通过ST-DSM和PEQ-N模块将大型训练数据集压缩为紧凑的合成数据集，实现快速SNN训练，在保持高性能的同时大幅降低训练时间和存储成本。


<details>
  <summary>Details</summary>
Motivation: SNN由于时间编码导致训练成本高昂，限制了实际部署。PACE旨在通过数据集蒸馏方法解决SNN训练成本高的问题。

Method: PACE包含两个核心模块：ST-DSM使用残差膜电位来密集化基于尖峰的特征并进行细粒度的时空匹配，PEQ-N提供即插即用的概率整数量化器。

Result: 在DVS-Gesture、CIFAR10-DVS和N-MNIST数据集上，PACE优于现有方法，在N-MNIST上达到84.4%准确率（约为完整训练集性能的85%），同时减少50倍训练时间和6000倍存储成本。

Conclusion: PACE提供了一种高效的SNN训练解决方案，能够实现分钟级的SNN训练和高效的边缘部署。

Abstract: Event cameras sense brightness changes and output binary asynchronous event streams, attracting increasing attention. Their bio-inspired dynamics align well with spiking neural networks (SNNs), offering a promising energy-efficient alternative to conventional vision systems. However, SNNs remain costly to train due to temporal coding, which limits their practical deployment. To alleviate the high training cost of SNNs, we introduce \textbf{PACE} (Phase-Aligned Condensation for Events), the first dataset distillation framework to SNNs and event-based vision. PACE distills a large training dataset into a compact synthetic one that enables fast SNN training, which is achieved by two core modules: \textbf{ST-DSM} and \textbf{PEQ-N}. ST-DSM uses residual membrane potentials to densify spike-based features (SDR) and to perform fine-grained spatiotemporal matching of amplitude and phase (ST-SM), while PEQ-N provides a plug-and-play straight through probabilistic integer quantizer compatible with standard event-frame pipelines. Across DVS-Gesture, CIFAR10-DVS, and N-MNIST datasets, PACE outperforms existing coreset selection and dataset distillation baselines, with particularly strong gains on dynamic event streams and at low or moderate IPC. Specifically, on N-MNIST, it achieves \(84.4\%\) accuracy, about \(85\%\) of the full training set performance, while reducing training time by more than \(50\times\) and storage cost by \(6000\times\), yielding compact surrogates that enable minute-scale SNN training and efficient edge deployment.

</details>


### [57] [Uni-Hand: Universal Hand Motion Forecasting in Egocentric Views](https://arxiv.org/abs/2511.12878)
*Junyi Ma,Wentao Bao,Jingyi Xu,Guanzhong Sun,Yu Zheng,Erhang Zhang,Xieyuanli Chen,Hesheng Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为EgoLoc的零样本方法，用于在自我中心视频中定位手与物体接触和分离的时间点，解决了现有方法在物体定位和时序交互定位方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注交互动作的行为范式（即“如何交互”），但对手与目标物体接触和分离的关键时刻（即“何时交互”）这一更挑战性和细粒度的问题研究不足，而这对混合现实中的沉浸式交互体验和机器人运动规划至关重要。

Method: EgoLoc引入手动力学引导采样生成高质量视觉提示，利用视觉语言模型识别接触/分离属性、定位特定时间点，并提供闭环反馈进行进一步优化。该方法无需物体掩码和动词-名词分类法，实现了可推广的零样本实施。

Result: 在公共数据集和新基准上的综合实验表明，EgoLoc在自我中心视频中实现了合理的时序交互定位，并有效促进了自我中心视觉和机器人操作任务中的多个下游应用。

Conclusion: EgoLoc通过零样本方法成功解决了手-物体交互关键时刻的定位问题，为VR/AR应用和机器人策略转移提供了有效工具。

Abstract: Analyzing hand-object interaction in egocentric vision facilitates VR/AR applications and human-robot policy transfer. Existing research has mostly focused on modeling the behavior paradigm of interactive actions (i.e., "how to interact"). However, the more challenging and fine-grained problem of capturing the critical moments of contact and separation between the hand and the target object (i.e., "when to interact") is still underexplored, which is crucial for immersive interactive experiences in mixed reality and robotic motion planning. Therefore, we formulate this problem as temporal interaction localization (TIL). Some recent works extract semantic masks as TIL references, but suffer from inaccurate object grounding and cluttered scenarios. Although current temporal action localization (TAL) methods perform well in detecting verb-noun action segments, they rely on category annotations during training and exhibit limited precision in localizing hand-object contact/separation moments. To address these issues, we propose a novel zero-shot approach dubbed EgoLoc to localize hand-object contact and separation timestamps in egocentric videos. EgoLoc introduces hand-dynamics-guided sampling to generate high-quality visual prompts. It exploits the vision-language model to identify contact/separation attributes, localize specific timestamps, and provide closed-loop feedback for further refinement. EgoLoc eliminates the need for object masks and verb-noun taxonomies, leading to generalizable zero-shot implementation. Comprehensive experiments on the public dataset and our novel benchmarks demonstrate that EgoLoc achieves plausible TIL for egocentric videos. It is also validated to effectively facilitate multiple downstream applications in egocentric vision and robotic manipulation tasks. Code and relevant data will be released at https://github.com/IRMVLab/EgoLoc.

</details>


### [58] [Sparse by Rule: Probability-Based N:M Pruning for Spiking Neural Networks](https://arxiv.org/abs/2511.12097)
*Shuhan Ye,Yi Yu,Qixin Zhang,Chenqi Kong,Qiangqiang Wu,Xudong Jiang,Dacheng Tao*

Main category: cs.CV

TL;DR: SpikeNM是首个面向SNN的半结构化(N:M)剪枝框架，通过M路基对数参数化和可微top-k采样器，将复杂度从指数级降低到线性级，并结合神经科学启发的资格蒸馏方法，在保持精度的同时实现硬件友好的稀疏模式。


<details>
  <summary>Details</summary>
Motivation: 解决SNN深度架构参数和计算成本过高的问题，现有非结构化剪枝难以硬件加速，而结构化剪枝缺乏灵活性且精度下降，需要一种兼顾硬件效率和精度的剪枝方法。

Method: 采用半结构化(N:M)剪枝框架，使用M路基对数参数化和可微top-k采样器线性化复杂度，并提出资格启发蒸馏(EID)方法将时间累积信用转换为块级软目标，稳定高稀疏度下的搜索。

Result: 在2:4稀疏度下，SpikeNM在主流数据集上保持甚至提升了精度，同时产生硬件友好的稀疏模式，与内在脉冲稀疏性互补。

Conclusion: SpikeNM成功实现了SNN的高效半结构化剪枝，在硬件部署友好性和模型精度之间取得了良好平衡，为边缘计算中的SNN应用提供了可行方案。

Abstract: Brain-inspired Spiking neural networks (SNNs) promise energy-efficient intelligence via event-driven, sparse computation, but deeper architectures inflate parameters and computational cost, hindering their edge deployment. Recent progress in SNN pruning helps alleviate this burden, yet existing efforts fall into only two families: \emph{unstructured} pruning, which attains high sparsity but is difficult to accelerate on general hardware, and \emph{structured} pruning, which eases deployment but lack flexibility and often degrades accuracy at matched sparsity. In this work, we introduce \textbf{SpikeNM}, the first SNN-oriented \emph{semi-structured} \(N{:}M\) pruning framework that learns sparse SNNs \emph{from scratch}, enforcing \emph{at most \(N\)} non-zeros per \(M\)-weight block. To avoid the combinatorial space complexity \(\sum_{k=1}^{N}\binom{M}{k}\) growing exponentially with \(M\), SpikeNM adopts an \(M\)-way basis-logit parameterization with a differentiable top-\(k\) sampler, \emph{linearizing} per-block complexity to \(\mathcal O(M)\) and enabling more aggressive sparsification. Further inspired by neuroscience, we propose \emph{eligibility-inspired distillation} (EID), which converts temporally accumulated credits into block-wise soft targets to align mask probabilities with spiking dynamics, reducing sampling variance and stabilizing search under high sparsity. Experiments show that at \(2{:}4\) sparsity, SpikeNM maintains and even with gains across main-stream datasets, while yielding hardware-amenable patterns that complement intrinsic spike sparsity.

</details>


### [59] [DiffPixelFormer: Differential Pixel-Aware Transformer for RGB-D Indoor Scene Segmentation](https://arxiv.org/abs/2511.13047)
*Yan Gong,Jianli Lu,Yongsheng Gao,Jie Zhao,Xiaojuan Zhang,Susanto Rahardja*

Main category: cs.CV

TL;DR: DiffPixelFormer是一种用于RGB-D室内场景分割的差分像素感知Transformer，通过增强模态内表示和建模模态间交互来提高分割精度。


<details>
  <summary>Details</summary>
Motivation: 现有RGB-D融合方法依赖计算密集的跨注意力机制，且对模态内和模态间特征关系建模不足，导致特征对齐不精确和判别表示有限。

Method: 提出Intra-Inter Modal Interaction Block (IIMIB)，通过自注意力捕获模态内长程依赖，使用Differential-Shared Inter-Modal (DSIM)模块解耦模态特定和共享线索，实现像素级跨模态对齐，并采用动态融合策略平衡模态贡献。

Result: 在SUN RGB-D和NYUDv2基准测试中，DiffPixelFormer-L分别达到54.28%和59.95%的mIoU，比DFormer-L分别提升1.78%和2.75%。

Conclusion: DiffPixelFormer通过有效的模态内和模态间交互建模，显著提升了RGB-D室内语义分割性能。

Abstract: Indoor semantic segmentation is fundamental to computer vision and robotics, supporting applications such as autonomous navigation, augmented reality, and smart environments. Although RGB-D fusion leverages complementary appearance and geometric cues, existing methods often depend on computationally intensive cross-attention mechanisms and insufficiently model intra- and inter-modal feature relationships, resulting in imprecise feature alignment and limited discriminative representation. To address these challenges, we propose DiffPixelFormer, a differential pixel-aware Transformer for RGB-D indoor scene segmentation that simultaneously enhances intra-modal representations and models inter-modal interactions. At its core, the Intra-Inter Modal Interaction Block (IIMIB) captures intra-modal long-range dependencies via self-attention and models inter-modal interactions with the Differential-Shared Inter-Modal (DSIM) module to disentangle modality-specific and shared cues, enabling fine-grained, pixel-level cross-modal alignment. Furthermore, a dynamic fusion strategy balances modality contributions and fully exploits RGB-D information according to scene characteristics. Extensive experiments on the SUN RGB-D and NYUDv2 benchmarks demonstrate that DiffPixelFormer-L achieves mIoU scores of 54.28% and 59.95%, outperforming DFormer-L by 1.78% and 2.75%, respectively. Code is available at https://github.com/gongyan1/DiffPixelFormer.

</details>


### [60] [DINOv3-Guided Cross Fusion Framework for Semantic-aware CT generation from MRI and CBCT](https://arxiv.org/abs/2511.12098)
*Xianhao Zhou,Jianghao Wu,Ku Zhao,Jinlong He,Huangxuan Zhao,Lei Chen,Shaoting Zhang,Guotai Wang*

Main category: cs.CV

TL;DR: 该论文提出了一种DINOv3引导的交叉融合框架，用于从CBCT或MRI生成合成CT图像，解决了CNN缺乏全局语义理解和Transformer在小数据集上过拟合的问题。


<details>
  <summary>Details</summary>
Motivation: 现有CNN模型缺乏全局语义理解，而Transformer在小规模医学数据集上容易过拟合。作者旨在开发一个能够平衡局部外观和上下文表示的框架，以提高合成CT图像的质量。

Method: 提出DGCF框架，将冻结的自监督DINOv3 Transformer与可训练的CNN编码器-解码器集成，通过可学习的交叉融合模块分层融合全局表示和局部特征，并引入多级DINOv3感知损失。

Result: 在SynthRAD2023盆腔数据集上的实验表明，DGCF在MRI→CT和CBCT→CT转换任务中，在MS-SSIM、PSNR和基于分割的指标上均达到了最先进的性能。

Conclusion: 这是首个将DINOv3表示用于医学图像转换的工作，展示了自监督Transformer引导在语义感知CT合成中的潜力。

Abstract: Generating synthetic CT images from CBCT or MRI has a potential for efficient radiation dose planning and adaptive radiotherapy. However, existing CNN-based models lack global semantic understanding, while Transformers often overfit small medical datasets due to high model capacity and weak inductive bias. To address these limitations, we propose a DINOv3-Guided Cross Fusion (DGCF) framework that integrates a frozen self-supervised DINOv3 Transformer with a trainable CNN encoder-decoder. It hierarchically fuses global representation of Transformer and local features of CNN via a learnable cross fusion module, achieving balanced local appearance and contextual representation. Furthermore, we introduce a Multi-Level DINOv3 Perceptual (MLDP) loss that encourages semantic similarity between synthetic CT and the ground truth in DINOv3's feature space. Experiments on the SynthRAD2023 pelvic dataset demonstrate that DGCF achieved state-of-the-art performance in terms of MS-SSIM, PSNR and segmentation-based metrics on both MRI$\rightarrow$CT and CBCT$\rightarrow$CT translation tasks. To the best of our knowledge, this is the first work to employ DINOv3 representations for medical image translation, highlighting the potential of self-supervised Transformer guidance for semantic-aware CT synthesis. The code is available at https://github.com/HiLab-git/DGCF.

</details>


### [61] [PhysX-Anything: Simulation-Ready Physical 3D Assets from Single Image](https://arxiv.org/abs/2511.13648)
*Ziang Cao,Fangzhou Hong,Zhaoxi Chen,Liang Pan,Ziwei Liu*

Main category: cs.CV

TL;DR: PhysX-Anything是首个面向仿真的物理3D生成框架，能从单张图像生成具有明确几何、关节和物理属性的高质量仿真就绪3D资产


<details>
  <summary>Details</summary>
Motivation: 现有3D生成方法忽视物理和关节属性，限制了在具身AI中的应用价值

Method: 提出首个基于VLM的物理3D生成模型，采用新型3D表示方法将几何标记化减少193倍，并构建PhysX-Mobility数据集（包含2000+真实物体）

Result: 在PhysX-Mobility和真实图像上表现出强生成性能和鲁棒泛化能力，仿真实验验证资产可直接用于接触密集型机器人策略学习

Conclusion: PhysX-Anything能显著赋能具身AI和物理仿真等下游应用

Abstract: 3D modeling is shifting from static visual representations toward physical, articulated assets that can be directly used in simulation and interaction. However, most existing 3D generation methods overlook key physical and articulation properties, thereby limiting their utility in embodied AI. To bridge this gap, we introduce PhysX-Anything, the first simulation-ready physical 3D generative framework that, given a single in-the-wild image, produces high-quality sim-ready 3D assets with explicit geometry, articulation, and physical attributes. Specifically, we propose the first VLM-based physical 3D generative model, along with a new 3D representation that efficiently tokenizes geometry. It reduces the number of tokens by 193x, enabling explicit geometry learning within standard VLM token budgets without introducing any special tokens during fine-tuning and significantly improving generative quality. In addition, to overcome the limited diversity of existing physical 3D datasets, we construct a new dataset, PhysX-Mobility, which expands the object categories in prior physical 3D datasets by over 2x and includes more than 2K common real-world objects with rich physical annotations. Extensive experiments on PhysX-Mobility and in-the-wild images demonstrate that PhysX-Anything delivers strong generative performance and robust generalization. Furthermore, simulation-based experiments in a MuJoCo-style environment validate that our sim-ready assets can be directly used for contact-rich robotic policy learning. We believe PhysX-Anything can substantially empower a broad range of downstream applications, especially in embodied AI and physics-based simulation.

</details>


### [62] [Adaptive Begin-of-Video Tokens for Autoregressive Video Diffusion Models](https://arxiv.org/abs/2511.12099)
*Tianle Cheng,Zeyan Zhang,Kaifeng Gao,Jun Xiao*

Main category: cs.CV

TL;DR: 本文提出了一种名为Adaptive Begin-of-Video Tokens (ada-BOV)的新方法，用于改进自回归视频扩散模型的长视频生成质量，解决了现有方法在一致性和运动动态方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的视频扩散模型在生成长视频时存在两个主要问题：基于块的扩展方法存在去噪延迟和误差累积，而流式去噪方法则面临一致性脆弱和运动动态差的问题。需要一种能够保持全局一致性同时提供灵活条件的方法。

Method: 提出了自适应视频开始标记(ada-BOV)，通过类似自适应层归一化的调制机制吸收前面去噪的帧；提出了流式去噪的细化策略，将采样轨迹长度与注意力窗口大小约束解耦；设计了扰动增强的训练噪声调度，平衡收敛速度与模型鲁棒性。

Result: 大量实验表明，该方法在多个指标上取得了令人信服的定性和定量结果，显著提升了长视频生成的质量和一致性。

Conclusion: ada-BOV方法有效解决了自回归视频扩散模型在长视频生成中的关键挑战，通过自适应调制和细化策略实现了更好的全局一致性和局部动态质量。

Abstract: Recent advancements in diffusion-based video generation have produced impressive and high-fidelity short videos. To extend these successes to generate coherent long videos, most video diffusion models (VDMs) generate videos in an autoregressive manner, i.e., generating subsequent frames conditioned on previous ones. There are generally two primary paradigms: chunk-based extension and stream denoising. The former directly concatenates previous clean frames as conditioning, suffering from denoising latency and error accumulation. The latter maintains the denoising sequence with monotonically increasing noise levels. In each denoising iteration, one clean frame is produced while a new pure noise is simultaneously appended, enabling live-stream sampling. However, it struggles with fragile consistency and poor motion dynamics. In this paper, we propose Adaptive Begin-of-Video Tokens (ada-BOV) for autoregressive VDMs. The BOV tokens are special learnable embeddings on VDMs. They adaptively absorb denoised preceding frames via an adaptive-layer-norm-like modulation. This design preserves the global consistency while allowing for flexible conditioning in dynamic scenarios. To ensure the quality of local dynamics essential in modulating BOV tokens, we further propose a refinement strategy for stream denoising. It decouples the sampling trajectory length from the attention window size constraint, leading to improved local guidance and overall imaging quality. We also propose a disturbance-augmented training noise schedule, which balances the convergence speed with model robustness for the stream denoising. Extensive experiments demonstrate that our method achieves compelling qualitative and quantitative results across multiple metrics.

</details>


### [63] [Scaling Spatial Intelligence with Multimodal Foundation Models](https://arxiv.org/abs/2511.13719)
*Zhongang Cai,Ruisi Wang,Chenyang Gu,Fanyi Pu,Junxiang Xu,Yubo Wang,Wanqi Yin,Zhitao Yang,Chen Wei,Qingping Sun,Tongxi Zhou,Jiaqi Li,Hui En Pang,Oscar Qian,Yukun Wei,Zhiqian Lin,Xuanke Shi,Kewang Deng,Xiaoyang Han,Zukai Chen,Xiangyu Fan,Hanming Deng,Lewei Lu,Liang Pan,Bo Li,Ziwei Liu,Quan Wang,Dahua Lin,Lei Yang*

Main category: cs.CV

TL;DR: SenseNova-SI项目通过系统构建800万样本的数据集，显著提升了多模态基础模型的空间智能能力，在多个基准测试中达到领先水平。


<details>
  <summary>Details</summary>
Motivation: 当前多模态基础模型在空间智能方面仍存在明显不足，需要专门的方法来提升其空间理解和推理能力。

Method: 基于Qwen3-VL、InternVL3和Bagel等多模态基础模型，系统构建了包含800万多样化样本的SenseNova-SI-8M数据集，采用严格的空间能力分类法。

Result: 在多个空间智能基准测试中取得突破性成绩：VSI-Bench 68.7%、MMSI 43.3%、MindCube 85.6%、ViewSpatial 54.6%、SITE 50.1%，同时保持强大多模态理解能力（MMBench-En 84.9%）。

Conclusion: SenseNova-SI展示了通过大规模多样化数据训练可以有效提升空间智能，并发现早期涌现的泛化能力，该项目将持续更新并开源所有模型以促进相关研究。

Abstract: Despite remarkable progress, multimodal foundation models still exhibit surprising deficiencies in spatial intelligence. In this work, we explore scaling up multimodal foundation models to cultivate spatial intelligence within the SenseNova-SI family, built upon established multimodal foundations including visual understanding models (i.e., Qwen3-VL and InternVL3) and unified understanding and generation models (i.e., Bagel). We take a principled approach to constructing high-performing and robust spatial intelligence by systematically curating SenseNova-SI-8M: eight million diverse data samples under a rigorous taxonomy of spatial capabilities. SenseNova-SI demonstrates unprecedented performance across a broad range of spatial intelligence benchmarks: 68.7% on VSI-Bench, 43.3% on MMSI, 85.6% on MindCube, 54.6% on ViewSpatial, and 50.1% on SITE, while maintaining strong general multimodal understanding (e.g., 84.9% on MMBench-En). More importantly, we analyze the impact of data scaling, discuss early signs of emergent generalization capabilities enabled by diverse data training, analyze the risk of overfitting and language shortcuts, present a preliminary study on spatial chain-of-thought reasoning, and validate the potential downstream application. SenseNova-SI is an ongoing project, and this report will be updated continuously. All newly trained multimodal foundation models are publicly released to facilitate further research in this direction.

</details>


### [64] [Did Models Sufficient Learn? Attribution-Guided Training via Subset-Selected Counterfactual Augmentation](https://arxiv.org/abs/2511.12100)
*Yannan Chen,Ruoyu Chen,Bin Zeng,Wei Wang,Shiming Liu,Qunli Zhang,Zheng Hu,Laiyuan Wang,Yaowei Wang,Xiaochun Cao*

Main category: cs.CV

TL;DR: 提出SS-CA方法，通过反事实增强训练解决视觉模型依赖有限因果特征的问题，提升模型泛化能力和鲁棒性


<details>
  <summary>Details</summary>
Motivation: 当前视觉模型仅依赖有限的充分原因进行预测，导致对分布偏移或关键特征缺失敏感。模型与人类在识别反事实样本时存在差异，表明模型学习到的依赖关系可能不够因果

Method: 基于LIMA归因方法开发Counterfactual LIMA，识别最小空间区域集，其移除可选择性改变模型预测。使用数据增强策略将识别区域替换为自然背景，并在增强样本和原始样本上联合训练模型

Result: 在多个ImageNet变体上的实验表明，SS-CA提高了在分布内测试数据的泛化能力，在ImageNet-R和ImageNet-S等分布外基准上表现优异。在噪声等扰动下，SS-CA训练的模型也表现出增强的泛化能力

Conclusion: SS-CA方法有效利用可解释性洞察来纠正模型缺陷，同时提高性能和鲁棒性，为解决模型因果学习不完整问题提供了有效途径

Abstract: In current visual model training, models often rely on only limited sufficient causes for their predictions, which makes them sensitive to distribution shifts or the absence of key features. Attribution methods can accurately identify a model's critical regions. However, masking these areas to create counterfactuals often causes the model to misclassify the target, while humans can still easily recognize it. This divergence highlights that the model's learned dependencies may not be sufficiently causal. To address this issue, we propose Subset-Selected Counterfactual Augmentation (SS-CA), which integrates counterfactual explanations directly into the training process for targeted intervention. Building on the subset-selection-based LIMA attribution method, we develop Counterfactual LIMA to identify minimal spatial region sets whose removal can selectively alter model predictions. Leveraging these attributions, we introduce a data augmentation strategy that replaces the identified regions with natural background, and we train the model jointly on both augmented and original samples to mitigate incomplete causal learning. Extensive experiments across multiple ImageNet variants show that SS-CA improves generalization on in-distribution (ID) test data and achieves superior performance on out-of-distribution (OOD) benchmarks such as ImageNet-R and ImageNet-S. Under perturbations including noise, models trained with SS-CA also exhibit enhanced generalization, demonstrating that our approach effectively uses interpretability insights to correct model deficiencies and improve both performance and robustness.

</details>


### [65] [BdSL-SPOTER: A Transformer-Based Framework for Bengali Sign Language Recognition with Cultural Adaptation](https://arxiv.org/abs/2511.12103)
*Sayad Ibna Azad,Md. Atiqur Rahman*

Main category: cs.CV

TL;DR: BdSL-SPOTER是一个基于姿态的Transformer框架，用于准确高效地识别孟加拉手语，在BdSLW60基准测试中达到97.92%的Top-1验证准确率，比Bi-LSTM基线提升22.82%，同时保持低计算成本。


<details>
  <summary>Details</summary>
Motivation: 为孟加拉手语（BdSL）开发一个准确且高效的识别框架，解决低资源区域手语识别中的计算效率和泛化能力问题。

Method: 扩展SPOTER范式，采用文化特定的预处理和紧凑的四层Transformer编码器，优化可学习位置编码，并使用课程学习增强有限数据下的泛化能力和加速收敛。

Result: 在BdSLW60基准测试中达到97.92%的Top-1验证准确率，参数数量减少，FLOPs降低，FPS提高，计算成本低。

Conclusion: BdSL-SPOTER为现实世界的无障碍应用提供了实用框架，并可作为其他低资源区域手语的可扩展模型。

Abstract: We introduce BdSL-SPOTER, a pose-based transformer framework for accurate and efficient recognition of Bengali Sign Language (BdSL). BdSL-SPOTER extends the SPOTER paradigm with cultural specific preprocessing and a compact four-layer transformer encoder featuring optimized learnable positional encodings, while employing curriculum learning to enhance generalization on limited data and accelerate convergence. On the BdSLW60 benchmark, it achieves 97.92% Top-1 validation accuracy, representing a 22.82% improvement over the Bi-LSTM baseline, all while keeping computational costs low. With its reduced number of parameters, lower FLOPs, and higher FPS, BdSL-SPOTER provides a practical framework for real-world accessibility applications and serves as a scalable model for other low-resource regional sign languages.

</details>


### [66] [TEMPO: Global Temporal Building Density and Height Estimation from Satellite Imagery](https://arxiv.org/abs/2511.12104)
*Tammy Glazer,Gilles Q. Hacheme,Akram Zaytar,Luana Marotti,Amy Michaels,Girmaw Abebe Tadesse,Kevin White,Rahul Dodhia,Andrew Zolli,Inbal Becker-Reshef,Juan M. Lavista Ferres,Caleb Robinson*

Main category: cs.CV

TL;DR: TEMPO是一个基于深度学习的高分辨率全球建筑密度和高度数据集，能够提供从2018年第一季度到2025年第二季度的季度更新数据。


<details>
  <summary>Details</summary>
Motivation: 需要大规模监测全球发展模式和气候影响，以支持全球韧性和适应工作，但现有方法计算成本高昂。

Method: 利用现有建筑足迹和高度数据与季度PlanetScope卫星图像配对，训练多任务深度学习模型，预测37.6米像素分辨率的建筑密度和高度。

Result: 模型在不同手工标记子集上达到85%至88%的F1分数，时间稳定性高，五年趋势一致性得分为0.96，计算成本远低于可比方法。

Conclusion: TEMPO能够以较低成本捕获建成区的季度变化，为大规模监测发展模式和气候影响提供了有效工具。

Abstract: We present TEMPO, a global, temporally resolved dataset of building density and height derived from high-resolution satellite imagery using deep learning models. We pair building footprint and height data from existing datasets with quarterly PlanetScope basemap satellite images to train a multi-task deep learning model that predicts building density and building height at a 37.6-meter per pixel resolution. We apply this model to global PlanetScope basemaps from Q1 2018 through Q2 2025 to create global, temporal maps of building density and height. We validate these maps by comparing against existing building footprint datasets. Our estimates achieve an F1 score between 85% and 88% on different hand-labeled subsets, and are temporally stable, with a 0.96 five-year trend-consistency score. TEMPO captures quarterly changes in built settlements at a fraction of the computational cost of comparable approaches, unlocking large-scale monitoring of development patterns and climate impacts essential for global resilience and adaptation efforts.

</details>


### [67] [Fine-Grained DINO Tuning with Dual Supervision for Face Forgery Detection](https://arxiv.org/abs/2511.12107)
*Tianxiang Zhang,Peipeng Yu,Zhihua Xia,Longchen Dai,Xiaoyu Zhou,Hui Gao*

Main category: cs.CV

TL;DR: 本文提出DFF-Adapter方法，通过轻量级多头部LoRA模块增强DINOv2的深度伪造检测能力，同时处理真实性检测和细粒度伪造方法分类，仅需350万参数即可达到或超越现有SOTA方法的检测精度。


<details>
  <summary>Details</summary>
Motivation: 现有基于DINOv2的深度伪造检测方法仅将其视为通用二分类问题，忽视了不同伪造方法产生的独特伪影特征，限制了检测性能。

Method: 在DINOv2的每个Transformer块中嵌入轻量级多头部LoRA模块，设计共享分支将细粒度伪造方法分类的线索传播到真实性检测头，实现多任务协同优化。

Result: 该方法仅使用350万可训练参数，在检测准确率上达到或超越了当前复杂的SOTA方法。

Conclusion: DFF-Adapter通过参数高效的方式显式利用伪造方法特异性知识，显著提升了深度伪造检测的鉴别能力。

Abstract: The proliferation of sophisticated deepfakes poses significant threats to information integrity. While DINOv2 shows promise for detection, existing fine-tuning approaches treat it as generic binary classification, overlooking distinct artifacts inherent to different deepfake methods. To address this, we propose a DeepFake Fine-Grained Adapter (DFF-Adapter) for DINOv2. Our method incorporates lightweight multi-head LoRA modules into every transformer block, enabling efficient backbone adaptation. DFF-Adapter simultaneously addresses authenticity detection and fine-grained manipulation type classification, where classifying forgery methods enhances artifact sensitivity. We introduce a shared branch propagating fine-grained manipulation cues to the authenticity head. This enables multi-task cooperative optimization, explicitly enhancing authenticity discrimination with manipulation-specific knowledge. Utilizing only 3.5M trainable parameters, our parameter-efficient approach achieves detection accuracy comparable to or even surpassing that of current complex state-of-the-art methods.

</details>


### [68] [MediRound: Multi-Round Entity-Level Reasoning Segmentation in Medical Images](https://arxiv.org/abs/2511.12110)
*Qinyue Tong,Ziqian Lu,Jun Liu,Rui Zuo,Zheming Lu*

Main category: cs.CV

TL;DR: 本文提出MEMR-Seg任务，通过多轮实体级推理实现医学图像分割，构建了MR-MedSeg数据集和MediRound基线模型，并引入轻量级判断校正机制来减少错误传播。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像分割方法缺乏交互性，文本提示方法仅限于单轮对话，无法进行多轮推理。

Method: 提出MEMR-Seg任务框架，构建包含17.7万条多轮医学分割对话的MR-MedSeg数据集，开发MediRound模型，并在推理阶段引入判断校正机制来优化链式分割流程。

Result: 实验结果表明该方法有效解决了MEMR-Seg任务，性能优于传统医学参考分割方法。

Conclusion: 多轮实体级推理分割是医学图像分析的重要方向，提出的方法为解决这一任务提供了有效解决方案。

Abstract: Despite the progress in medical image segmentation, most existing methods remain task-specific and lack interactivity. Although recent text-prompt-based segmentation approaches enhance user-driven and reasoning-based segmentation, they remain confined to single-round dialogues and fail to perform multi-round reasoning. In this work, we introduce Multi-Round Entity-Level Medical Reasoning Segmentation (MEMR-Seg), a new task that requires generating segmentation masks through multi-round queries with entity-level reasoning. To support this task, we construct MR-MedSeg, a large-scale dataset of 177K multi-round medical segmentation dialogues, featuring entity-based reasoning across rounds. Furthermore, we propose MediRound, an effective baseline model designed for multi-round medical reasoning segmentation. To mitigate the inherent error propagation in the chain-like pipeline of multi-round segmentation, we introduce a lightweight yet effective Judgment & Correction Mechanism during model inference. Experimental results demonstrate that our method effectively addresses the MEMR-Seg task and outperforms conventional medical referring segmentation methods.

</details>


### [69] [RadarMP: Motion Perception for 4D mmWave Radar in Autonomous Driving](https://arxiv.org/abs/2511.12117)
*Ruiqi Cheng,Huijun Di,Jian Li,Feng Liu,Wei Liang*

Main category: cs.CV

TL;DR: RadarMP是一种基于4D毫米波雷达低层回波信号的3D场景运动感知方法，通过联合建模雷达目标检测和运动估计任务，在恶劣天气条件下实现精确的运动感知。


<details>
  <summary>Details</summary>
Motivation: 现有雷达点云稀疏且噪声大，导致运动感知不精确，在光学传感器性能下降的恶劣天气条件下，自动驾驶系统的感知能力受限。4D毫米波雷达具有全天候工作能力，但需要解决稀疏噪声问题。

Method: 提出RadarMP方法，使用两帧连续的低层雷达回波信号，在统一架构中联合建模雷达目标检测和运动估计任务。设计了基于多普勒频移和回波强度的自监督损失函数，无需显式标注即可监督空间和运动一致性。

Result: 在公共数据集上的实验表明，RadarMP在各种天气和光照条件下都能实现可靠的运动感知，性能优于基于雷达的解耦运动感知流水线。

Conclusion: RadarMP通过联合建模和自监督学习，有效提升了4D毫米波雷达在恶劣条件下的运动感知能力，为全场景自动驾驶系统提供了增强的感知能力。

Abstract: Accurate 3D scene motion perception significantly enhances the safety and reliability of an autonomous driving system. Benefiting from its all-weather operational capability and unique perceptual properties, 4D mmWave radar has emerged as an essential component in advanced autonomous driving. However, sparse and noisy radar points often lead to imprecise motion perception, leaving autonomous vehicles with limited sensing capabilities when optical sensors degrade under adverse weather conditions. In this paper, we propose RadarMP, a novel method for precise 3D scene motion perception using low-level radar echo signals from two consecutive frames. Unlike existing methods that separate radar target detection and motion estimation, RadarMP jointly models both tasks in a unified architecture, enabling consistent radar point cloud generation and pointwise 3D scene flow prediction. Tailored to radar characteristics, we design specialized self-supervised loss functions guided by Doppler shifts and echo intensity, effectively supervising spatial and motion consistency without explicit annotations. Extensive experiments on the public dataset demonstrate that RadarMP achieves reliable motion perception across diverse weather and illumination conditions, outperforming radar-based decoupled motion perception pipelines and enhancing perception capabilities for full-scenario autonomous driving systems.

</details>


### [70] [OAD-Promoter: Enhancing Zero-shot VQA using Large Language Models with Object Attribute Description](https://arxiv.org/abs/2511.12131)
*Quanxing Xu,Ling Zhou,Feifei Zhang,Jinyu Tian,Rubing Huang*

Main category: cs.CV

TL;DR: OAD-Promoter是一种解决LLM在VQA任务中语言偏见和OOD泛化问题的新方法，通过对象聚焦示例生成、记忆知识辅助和优化提示来提高性能


<details>
  <summary>Details</summary>
Motivation: LLM在VQA任务中依赖大规模训练数据会导致语言偏见，影响预测可靠性，且在分布外样本上泛化能力不足

Method: 提出OAD-Promoter框架，包含三个模块：OEG模块生成全局和区域视觉描述，MKA模块从存储示例中检索相关知识，OAD Prompt整合模块输出优化LLM推理

Result: 实验表明OAD-Promoter在少样本和零样本设置下显著提升了LLM-based VQA方法的性能，达到了新的SOTA结果

Conclusion: 该方法有效缓解了语言偏见问题，提高了域外泛化能力，为知识密集型VQA任务提供了可靠解决方案

Abstract: Large Language Models (LLMs) have become a crucial tool in Visual Question Answering (VQA) for handling knowledge-intensive questions in few-shot or zero-shot scenarios. However, their reliance on massive training datasets often causes them to inherit language biases during the acquisition of knowledge. This limitation imposes two key constraints on existing methods: (1) LLM predictions become less reliable due to bias exploitation, and (2) despite strong knowledge reasoning capabilities, LLMs still struggle with out-of-distribution (OOD) generalization. To address these issues, we propose Object Attribute Description Promoter (OAD-Promoter), a novel approach for enhancing LLM-based VQA by mitigating language bias and improving domain-shift robustness. OAD-Promoter comprises three components: the Object-concentrated Example Generation (OEG) module, the Memory Knowledge Assistance (MKA) module, and the OAD Prompt. The OEG module generates global captions and object-concentrated samples, jointly enhancing visual information input to the LLM and mitigating bias through complementary global and regional visual cues. The MKA module assists the LLM in handling OOD samples by retrieving relevant knowledge from stored examples to support questions from unseen domains. Finally, the OAD Prompt integrates the outputs of the preceding modules to optimize LLM inference. Experiments demonstrate that OAD-Promoter significantly improves the performance of LLM-based VQA methods in few-shot or zero-shot settings, achieving new state-of-the-art results.

</details>


### [71] [Compression and Inference of Spiking Neural Networks on Resource-Constrained Hardware](https://arxiv.org/abs/2511.12136)
*Karol C. Jurzec,Tomasz Szydlo,Maciej Wielgosz*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级的C语言运行时系统，用于在边缘设备上高效执行脉冲神经网络（SNN）推理，通过优化技术降低延迟和内存使用，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 脉冲神经网络具有事件驱动特性，适合时序处理和能效优化，但在资源受限的硬件上训练和部署仍面临挑战。现有方法存在解释器和内存分配开销，限制了在嵌入式平台上的应用。

Method: 将SNNTorch训练的模型转换为紧凑的C语言表示；采用静态、缓存友好的数据布局和预分配策略避免解释器和分配开销；利用稀疏脉冲活动剪枝不活跃的神经元和突触，减少上游卷积层的计算量。

Result: 在N-MNIST和ST-MNIST数据集上的实验显示，与Python基线功能一致，在桌面CPU上实现约10倍加速，剪枝带来额外增益，内存大幅减少，可在微控制器（如Arduino Portenta H7）上部署。

Conclusion: 结果表明，结合优化的运行时和脉冲驱动模型压缩，SNN可以在传统嵌入式平台上高效执行，为边缘计算提供可行的解决方案。

Abstract: Spiking neural networks (SNNs) communicate via discrete spikes in time rather than continuous activations. Their event-driven nature offers advantages for temporal processing and energy efficiency on resource-constrained hardware, but training and deployment remain challenging. We present a lightweight C-based runtime for SNN inference on edge devices and optimizations that reduce latency and memory without sacrificing accuracy. Trained models exported from SNNTorch are translated to a compact C representation; static, cache-friendly data layouts and preallocation avoid interpreter and allocation overheads. We further exploit sparse spiking activity to prune inactive neurons and synapses, shrinking computation in upstream convolutional layers. Experiments on N-MNIST and ST-MNIST show functional parity with the Python baseline while achieving ~10 speedups on desktop CPU and additional gains with pruning, together with large memory reductions that enable microcontroller deployment (Arduino Portenta H7). Results indicate that SNNs can be executed efficiently on conventional embedded platforms when paired with an optimized runtime and spike-driven model compression. Code: https://github.com/karol-jurzec/snn-generator/

</details>


### [72] [MAVIS: A Benchmark for Multimodal Source Attribution in Long-form Visual Question Answering](https://arxiv.org/abs/2511.12142)
*Seokwon Song,Minsu Park,Gunhee Kim*

Main category: cs.CV

TL;DR: MAVIS是首个评估多模态源归属系统的基准，包含157K视觉问答实例，通过自动指标评估回答的信息性、可验证性和流畅性，发现多模态RAG在图像文档上的可验证性较弱，并提出了缓解上下文偏见的未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 现有源归属研究主要关注纯文本场景，忽视了多模态的重要性，需要开发能够理解视觉问题意图、检索多模态证据并生成带引用的长答案的系统。

Method: 构建包含157K视觉问答实例的数据集，每个答案都标注了指向多模态文档的事实级引用；开发了信息性、可验证性和流畅性三个维度的自动评估指标；比较了多模态RAG与单模态RAG的性能差异。

Result: 多模态RAG生成的信息性和流畅性优于单模态RAG，但在图像文档上的可验证性较弱；不同提示方法在信息性和可验证性之间存在权衡；图像文档的上下文偏见是需要解决的关键问题。

Conclusion: 多模态源归属系统在图像文档的可验证性方面存在挑战，缓解上下文偏见是未来重要研究方向，MAVIS基准为相关研究提供了数据集和评估框架。

Abstract: Source attribution aims to enhance the reliability of AI-generated answers by including references for each statement, helping users validate the provided answers. However, existing work has primarily focused on text-only scenario and largely overlooked the role of multimodality. We introduce MAVIS, the first benchmark designed to evaluate multimodal source attribution systems that understand user intent behind visual questions, retrieve multimodal evidence, and generate long-form answers with citations. Our dataset comprises 157K visual QA instances, where each answer is annotated with fact-level citations referring to multimodal documents. We develop fine-grained automatic metrics along three dimensions of informativeness, groundedness, and fluency, and demonstrate their strong correlation with human judgments. Our key findings are threefold: (1) LVLMs with multimodal RAG generate more informative and fluent answers than unimodal RAG, but they exhibit weaker groundedness for image documents than for text documents, a gap amplified in multimodal settings. (2) Given the same multimodal documents, there is a trade-off between informativeness and groundedness across different prompting methods. (3) Our proposed method highlights mitigating contextual bias in interpreting image documents as a crucial direction for future research. The dataset and experimental code are available at https://github.com/seokwon99/MAVIS

</details>


### [73] [Breaking the Modality Wall: Time-step Mixup for Efficient Spiking Knowledge Transfer from Static to Event Domain](https://arxiv.org/abs/2511.12150)
*Yuqi Xie,Shuhan Ye,Yi Yu,Chong Wang,Qixin Zhang,Jiazhen Xu,Le Shen,Yuanbin Qian,Jiangbo Qian,Guoqi Li*

Main category: cs.CV

TL;DR: TMKT是一个跨模态训练框架，通过时间步混合策略将RGB和DVS数据进行插值，实现更平滑的知识迁移，提升脉冲神经网络在事件相机图像分类任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 事件相机和脉冲神经网络结合具有能效优势，但事件数据稀缺且DVS输出稀疏，传统RGB到DVS的知识迁移方法因模态分布差异大而效果不佳。

Method: 提出时间步混合知识迁移框架，包含概率性时间步混合策略和两个轻量级模态感知目标：模态感知引导和混合比感知，通过插值RGB和DVS输入并显式对齐时间特征与混合计划。

Result: 在多个基准测试和不同SNN骨干网络上的实验表明，该方法能有效减少梯度方差、稳定优化过程，在脉冲图像分类任务中取得优异性能。

Conclusion: TMKT通过创新的时间步混合策略和模态感知目标，成功解决了跨模态知识迁移中的模态不匹配问题，为事件相机和脉冲神经网络的结合提供了有效的训练框架。

Abstract: The integration of event cameras and spiking neural networks (SNNs) promises energy-efficient visual intelligence, yet scarce event data and the sparsity of DVS outputs hinder effective training. Prior knowledge transfers from RGB to DVS often underperform because the distribution gap between modalities is substantial. In this work, we present Time-step Mixup Knowledge Transfer (TMKT), a cross-modal training framework with a probabilistic Time-step Mixup (TSM) strategy. TSM exploits the asynchronous nature of SNNs by interpolating RGB and DVS inputs at various time steps to produce a smooth curriculum within each sequence, which reduces gradient variance and stabilizes optimization with theoretical analysis. To employ auxiliary supervision from TSM, TMKT introduces two lightweight modality-aware objectives, Modality Aware Guidance (MAG) for per-frame source supervision and Mixup Ratio Perception (MRP) for sequence-level mix ratio estimation, which explicitly align temporal features with the mixing schedule. TMKT enables smoother knowledge transfer, helps mitigate modality mismatch during training, and achieves superior performance in spiking image classification tasks. Extensive experiments across diverse benchmarks and multiple SNN backbones, together with ablations, demonstrate the effectiveness of our method.

</details>


### [74] [FIA-Edit: Frequency-Interactive Attention for Efficient and High-Fidelity Inversion-Free Text-Guided Image Editing](https://arxiv.org/abs/2511.12151)
*Kaixiang Yang,Boyang Shen,Xin Li,Yuchen Dai,Yuxuan Luo,Yueran Ma,Wei Fang,Qiang Li,Zhiwei Wang*

Main category: cs.CV

TL;DR: FIA-Edit是一个基于频率交互注意力的反演自由图像编辑框架，通过频率表示交互和特征注入模块实现高保真编辑，并在医学图像编辑中取得突破。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于流的反演自由方法在背景保留、空间一致性和过度编辑方面的问题，提升文本引导图像编辑的质量和效率。

Method: 提出频率交互注意力机制，包含频率表示交互模块（FRI）增强跨域对齐，以及特征注入模块（FIJ）显式整合源图像信息到目标分支的交叉注意力中。

Result: 在RTX 4090上每张512×512图像编辑耗时约6秒，在视觉质量、背景保真度和可控性方面优于现有方法，并首次将文本引导编辑应用于临床医学图像增强。

Conclusion: FIA-Edit实现了高效高保真的图像编辑，为医学数据增强开辟了新途径，在出血分类等下游任务中表现出显著优势。

Abstract: Text-guided image editing has advanced rapidly with the rise of diffusion models. While flow-based inversion-free methods offer high efficiency by avoiding latent inversion, they often fail to effectively integrate source information, leading to poor background preservation, spatial inconsistencies, and over-editing due to the lack of effective integration of source information. In this paper, we present FIA-Edit, a novel inversion-free framework that achieves high-fidelity and semantically precise edits through a Frequency-Interactive Attention. Specifically, we design two key components: (1) a Frequency Representation Interaction (FRI) module that enhances cross-domain alignment by exchanging frequency components between source and target features within self-attention, and (2) a Feature Injection (FIJ) module that explicitly incorporates source-side queries, keys, values, and text embeddings into the target branch's cross-attention to preserve structure and semantics. Comprehensive and extensive experiments demonstrate that FIA-Edit supports high-fidelity editing at low computational cost (~6s per 512 * 512 image on an RTX 4090) and consistently outperforms existing methods across diverse tasks in visual quality, background fidelity, and controllability. Furthermore, we are the first to extend text-guided image editing to clinical applications. By synthesizing anatomically coherent hemorrhage variations in surgical images, FIA-Edit opens new opportunities for medical data augmentation and delivers significant gains in downstream bleeding classification. Our project is available at: https://github.com/kk42yy/FIA-Edit.

</details>


### [75] [Codebook-Centric Deep Hashing: End-to-End Joint Learning of Semantic Hash Centers and Neural Hash Function](https://arxiv.org/abs/2511.12162)
*Shuo Yin,Zhiyuan Yin,Yuqing Hou,Rui Liu,Yong Chen,Dell Zhang*

Main category: cs.CV

TL;DR: 提出了一种端到端的中心重分配哈希（CRH）方法，通过动态重分配预设码本中的哈希中心来避免传统两阶段方法的复杂性和性能损失，同时使用多头机制增强哈希中心的表示能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于哈希中心的方法存在随机初始化忽略类间语义关系的问题，而两阶段方法虽然能缓解此问题但引入了额外的复杂性和计算开销，且存在阶段间差异导致的次优性能。

Method: CRH框架从预设码本中动态重分配哈希中心，并联合优化哈希函数，无需显式的中心优化阶段；采用多头机制增强哈希中心的语义表示能力。

Result: 在三个基准数据集上的实验表明，CRH能够学习到语义上有意义的哈希中心，并在检索任务中优于现有的深度哈希方法。

Conclusion: CRH通过端到端的动态中心重分配和多头机制，有效解决了传统哈希中心方法的局限性，实现了更好的语义保持和检索性能。

Abstract: Hash center-based deep hashing methods improve upon pairwise or triplet-based approaches by assigning fixed hash centers to each class as learning targets, thereby avoiding the inefficiency of local similarity optimization. However, random center initialization often disregards inter-class semantic relationships. While existing two-stage methods mitigate this by first refining hash centers with semantics and then training the hash function, they introduce additional complexity, computational overhead, and suboptimal performance due to stage-wise discrepancies. To address these limitations, we propose $\textbf{Center-Reassigned Hashing (CRH)}$, an end-to-end framework that $\textbf{dynamically reassigns hash centers}$ from a preset codebook while jointly optimizing the hash function. Unlike previous methods, CRH adapts hash centers to the data distribution $\textbf{without explicit center optimization phases}$, enabling seamless integration of semantic relationships into the learning process. Furthermore, $\textbf{a multi-head mechanism}$ enhances the representational capacity of hash centers, capturing richer semantic structures. Extensive experiments on three benchmarks demonstrate that CRH learns semantically meaningful hash centers and outperforms state-of-the-art deep hashing methods in retrieval tasks.

</details>


### [76] [Rethinking Multimodal Point Cloud Completion: A Completion-by-Correction Perspective](https://arxiv.org/abs/2511.12170)
*Wang Luo,Di Wu,Hengyuan Na,Yinlin Zhu,Miao Hu,Guocong Quan*

Main category: cs.CV

TL;DR: 本文提出了一种新的点云补全范式Completion-by-Correction，通过从预训练图像到3D模型生成拓扑完整的形状先验，并在特征空间进行校正，实现结构一致和观测对齐的重建。


<details>
  <summary>Details</summary>
Motivation: 传统基于修复的补全方法由于几何和语义约束有限，容易产生结构不一致和拓扑伪影。作者通过实证研究发现了这一局限性，因此重新思考任务并提出了更稳健的补全范式。

Method: 提出PGNet多阶段框架：1）双特征编码以锚定生成先验；2）合成结构对齐的粗粒度支架；3）通过分层校正逐步细化几何细节。

Result: 在ShapeNetViPC数据集上的实验表明，PGNet在平均Chamfer Distance上比现有最优方法降低23.5%，F-score提高7.1%。

Conclusion: Completion-by-Correction范式将补全任务从无约束合成转向引导式细化，能够实现结构一致和观测对齐的重建，显著优于传统方法。

Abstract: Point cloud completion aims to reconstruct complete 3D shapes from partial observations, which is a challenging problem due to severe occlusions and missing geometry. Despite recent advances in multimodal techniques that leverage complementary RGB images to compensate for missing geometry, most methods still follow a Completion-by-Inpainting paradigm, synthesizing missing structures from fused latent features. We empirically show that this paradigm often results in structural inconsistencies and topological artifacts due to limited geometric and semantic constraints. To address this, we rethink the task and propose a more robust paradigm, termed Completion-by-Correction, which begins with a topologically complete shape prior generated by a pretrained image-to-3D model and performs feature-space correction to align it with the partial observation. This paradigm shifts completion from unconstrained synthesis to guided refinement, enabling structurally consistent and observation-aligned reconstruction. Building upon this paradigm, we introduce PGNet, a multi-stage framework that conducts dual-feature encoding to ground the generative prior, synthesizes a coarse yet structurally aligned scaffold, and progressively refines geometric details via hierarchical correction. Experiments on the ShapeNetViPC dataset demonstrate the superiority of PGNet over state-of-the-art baselines in terms of average Chamfer Distance (-23.5%) and F-score (+7.1%).

</details>


### [77] [MixAR: Mixture Autoregressive Image Generation](https://arxiv.org/abs/2511.12181)
*Jinyuan Hu,Jiayou Zhang,Shaobo Cui,Kun Zhang,Guangyi Chen*

Main category: cs.CV

TL;DR: MixAR是一个利用混合训练范式的框架，通过离散token作为先验指导来改进连续自回归建模，解决了连续表示空间过大带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 连续自回归建模能提供更高的生成质量，但连续表示存在于广阔无结构的空间中，给高效自回归建模带来重大挑战。

Method: 提出MixAR框架，采用离散-连续混合策略（DC-SA、DC-CA、DC-Mix），并使用训练-推理混合（TI-Mix）来保持训练和生成分布的一致性。

Result: 实验表明DC-Mix策略在计算效率和生成保真度之间取得了良好平衡，TI-Mix带来了持续改进。

Conclusion: MixAR通过混合训练范式有效解决了连续自回归建模的挑战，在保持效率的同时提升了生成质量。

Abstract: Autoregressive (AR) approaches, which represent images as sequences of discrete tokens from a finite codebook, have achieved remarkable success in image generation. However, the quantization process and the limited codebook size inevitably discard fine-grained information, placing bottlenecks on fidelity. Motivated by this limitation, recent studies have explored autoregressive modeling in continuous latent spaces, which offers higher generation quality. Yet, unlike discrete tokens constrained by a fixed codebook, continuous representations lie in a vast and unstructured space, posing significant challenges for efficient autoregressive modeling. To address these challenges, we introduce MixAR, a novel framework that leverages mixture training paradigms to inject discrete tokens as prior guidance for continuous AR modeling. MixAR is a factorized formulation that leverages discrete tokens as prior guidance for continuous autoregressive prediction. We investigate several discrete-continuous mixture strategies, including self-attention (DC-SA), cross-attention (DC-CA), and a simple approach (DC-Mix) that replaces homogeneous mask tokens with informative discrete counterparts. Moreover, to bridge the gap between ground-truth training tokens and inference tokens produced by the pre-trained AR model, we propose Training-Inference Mixture (TI-Mix) to achieve consistent training and generation distributions. In our experiments, we demonstrate a favorable balance of the DC-Mix strategy between computational efficiency and generation fidelity, and consistent improvement of TI-Mix.

</details>


### [78] [MMRINet: Efficient Mamba-Based Segmentation with Dual-Path Refinement for Low-Resource MRI Analysis](https://arxiv.org/abs/2511.12193)
*Abdelrahman Elsayed,Ahmed Jaheen,Mohammad Yaqub*

Main category: cs.CV

TL;DR: MMRINet：一种轻量级脑肿瘤分割网络，使用线性复杂度的Mamba状态空间模型替代传统注意力机制，在资源受限环境中实现高效3D MRI分割


<details>
  <summary>Details</summary>
Motivation: 解决资源受限环境下3D深度网络计算成本高的问题，为低资源临床环境提供高效准确的脑肿瘤分割方案

Method: 使用线性复杂度的Mamba状态空间模型替代二次复杂度的注意力机制；提出双路径特征细化模块最大化特征多样性；采用渐进式特征聚合实现有效的多尺度融合

Result: 在BraTS-Lighthouse SSA 2025竞赛中，仅使用约250万参数，达到平均Dice分数0.752和平均HD95 12.23的强性能

Conclusion: MMRINet证明了在低资源临床环境中实现高效准确脑肿瘤分割的可行性，为资源受限的医疗环境提供了实用的解决方案

Abstract: Automated brain tumor segmentation in multi-parametric MRI remains challenging in resource-constrained settings where deep 3D networks are computationally prohibitive. We propose MMRINet, a lightweight architecture that replaces quadratic-complexity attention with linear-complexity Mamba state-space models for efficient volumetric context modeling. Novel Dual-Path Feature Refinement (DPFR) modules maximize feature diversity without additional data requirements, while Progressive Feature Aggregation (PFA) enables effective multi-scale fusion. In the BraTS-Lighthouse SSA 2025, our model achieves strong performance with an average Dice score of (0.752) and an average HD95 of (12.23) with only ~2.5M parameters, demonstrating efficient and accurate segmentation suitable for low-resource clinical environments. Our GitHub repository can be accessed here: github.com/BioMedIA-MBZUAI/MMRINet.

</details>


### [79] [Cross-View Cross-Modal Unsupervised Domain Adaptation for Driver Monitoring System](https://arxiv.org/abs/2511.12196)
*Aditi Bhalla,Christian Hellert,Enkelejda Kasneci*

Main category: cs.CV

TL;DR: 提出了一种两阶段跨视角、跨模态的无监督域适应框架，用于解决驾驶员活动识别中的视角变化和域偏移问题，显著提升了模型在真实部署中的性能。


<details>
  <summary>Details</summary>
Motivation: 驾驶员分心是交通事故的主要原因，现有深度学习方法在真实部署中面临视角变化和域偏移的挑战，现有方法通常单独处理这两个问题，缺乏联合解决方案。

Method: 两阶段框架：第一阶段使用对比学习在多视角数据中学习视角不变和动作判别特征；第二阶段使用信息瓶颈损失进行跨模态域适应，无需新域标注数据。

Result: 使用Video Swin和MViT视频变压器在Drive&Act数据集上评估，相比监督对比学习的跨视角方法，RGB视频数据的top-1准确率提升近50%；相比仅使用无监督域适应的方法，性能提升达5%。

Conclusion: 提出的联合框架有效解决了驾驶员活动识别中的跨视角和跨模态适应问题，为模型在多样化车辆配置中的鲁棒部署提供了可行方案。

Abstract: Driver distraction remains a leading cause of road traffic accidents, contributing to thousands of fatalities annually across the globe. While deep learning-based driver activity recognition methods have shown promise in detecting such distractions, their effectiveness in real-world deployments is hindered by two critical challenges: variations in camera viewpoints (cross-view) and domain shifts such as change in sensor modality or environment. Existing methods typically address either cross-view generalization or unsupervised domain adaptation in isolation, leaving a gap in the robust and scalable deployment of models across diverse vehicle configurations. In this work, we propose a novel two-phase cross-view, cross-modal unsupervised domain adaptation framework that addresses these challenges jointly on real-time driver monitoring data. In the first phase, we learn view-invariant and action-discriminative features within a single modality using contrastive learning on multi-view data. In the second phase, we perform domain adaptation to a new modality using information bottleneck loss without requiring any labeled data from the new domain. We evaluate our approach using state-of-the art video transformers (Video Swin, MViT) and multi modal driver activity dataset called Drive&Act, demonstrating that our joint framework improves top-1 accuracy on RGB video data by almost 50% compared to a supervised contrastive learning-based cross-view method, and outperforms unsupervised domain adaptation-only methods by up to 5%, using the same video transformer backbone.

</details>


### [80] [Bridging Granularity Gaps: Hierarchical Semantic Learning for Cross-domain Few-shot Segmentation](https://arxiv.org/abs/2511.12200)
*Sujun Sun,Haowen Gu,Cheng Xie,Yanxu Ren,Mingwu Ren,Haofeng Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种分层语义学习框架来解决跨域少样本分割中的语义粒度差异问题，通过双风格随机化和分层语义挖掘模块来增强模型对不同粒度语义的识别能力。


<details>
  <summary>Details</summary>
Motivation: 现有跨域少样本分割方法主要关注源域和目标域之间的风格差异，而忽略了分割粒度差异，导致对目标域中新类别的语义区分能力不足。

Method: 提出分层语义学习框架，包含双风格随机化模块模拟目标域数据风格差异，分层语义挖掘模块利用多尺度超像素挖掘不同粒度下的类内一致性和类间区分性，以及原型置信度调制阈值模块缓解分割模糊问题。

Result: 在四个流行目标域数据集上的实验表明，该方法取得了最先进的性能。

Conclusion: 所提出的分层语义学习框架有效解决了跨域少样本分割中的语义粒度差异问题，显著提升了模型性能。

Abstract: Cross-domain Few-shot Segmentation (CD-FSS) aims to segment novel classes from target domains that are not involved in training and have significantly different data distributions from the source domain, using only a few annotated samples, and recent years have witnessed significant progress on this task. However, existing CD-FSS methods primarily focus on style gaps between source and target domains while ignoring segmentation granularity gaps, resulting in insufficient semantic discriminability for novel classes in target domains. Therefore, we propose a Hierarchical Semantic Learning (HSL) framework to tackle this problem. Specifically, we introduce a Dual Style Randomization (DSR) module and a Hierarchical Semantic Mining (HSM) module to learn hierarchical semantic features, thereby enhancing the model's ability to recognize semantics at varying granularities. DSR simulates target domain data with diverse foreground-background style differences and overall style variations through foreground and global style randomization respectively, while HSM leverages multi-scale superpixels to guide the model to mine intra-class consistency and inter-class distinction at different granularities. Additionally, we also propose a Prototype Confidence-modulated Thresholding (PCMT) module to mitigate segmentation ambiguity when foreground and background are excessively similar. Extensive experiments are conducted on four popular target domain datasets, and the results demonstrate that our method achieves state-of-the-art performance.

</details>


### [81] [OmniSparse: Training-Aware Fine-Grained Sparse Attention for Long-Video MLLMs](https://arxiv.org/abs/2511.12201)
*Feng Chen,Yefei He,Shaoxuan He,Yuanyu He,Jing Liu,Lequan Lin,Akide Liu,Zhaoyang Li,Jiyuan Zhang,Zhenbang Sun,Bohan Zhuang,Qi Wu*

Main category: cs.CV

TL;DR: OmniSparse是一个针对长视频多模态大语言模型的训练感知细粒度稀疏注意力框架，通过动态token预算分配在训练和推理中实现高效加速。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏注意力方法主要针对推理加速，但存在训练-推理差距，且缺乏跨查询、键值对和注意力头的细粒度token选择能力，导致性能次优和加速效果有限。

Method: OmniSparse包含三个自适应互补机制：1）通过惰性-主动分类进行查询选择；2）基于最平坦头部的动态预算分配进行KV选择；3）KV缓存精简以减少头部冗余。

Result: 实验结果显示，OmniSparse在保持全注意力性能的同时，实现了预填充阶段2.7倍加速和解码阶段2.4倍内存减少。

Conclusion: 该框架有效解决了长视频MLLMs中的注意力效率问题，在保持性能的同时显著提升了计算和内存效率。

Abstract: Existing sparse attention methods primarily target inference-time acceleration by selecting critical tokens under predefined sparsity patterns. However, they often fail to bridge the training-inference gap and lack the capacity for fine-grained token selection across multiple dimensions such as queries, key-values (KV), and heads, leading to suboptimal performance and limited acceleration gains. In this paper, we introduce OmniSparse, a training-aware fine-grained sparse attention framework for long-video MLLMs, which operates in both training and inference with dynamic token budget allocation. Specifically, OmniSparse contains three adaptive and complementary mechanisms: (1) query selection via lazy-active classification, retaining active queries that capture broad semantic similarity while discarding most lazy ones that focus on limited local context and exhibit high functional redundancy; (2) KV selection with head-level dynamic budget allocation, where a shared budget is determined based on the flattest head and applied uniformly across all heads to ensure attention recall; and (3) KV cache slimming to reduce head-level redundancy by selectively fetching visual KV cache according to the head-level decoding query pattern. Experimental results show that OmniSparse matches the performance of full attention while achieving up to 2.7x speedup during prefill and 2.4x memory reduction during decoding.

</details>


### [82] [LSS3D: Learnable Spatial Shifting for Consistent and High-Quality 3D Generation from Single-Image](https://arxiv.org/abs/2511.12202)
*Zhuojiang Cai,Yiheng Zhang,Meitong Guo,Mingdao Wang,Yuwang Wang*

Main category: cs.CV

TL;DR: 本文提出LSS3D方法，通过可学习空间偏移解决多视图3D生成中的视图不一致和非正面输入问题，实现高质量3D生成


<details>
  <summary>Details</summary>
Motivation: 当前多视图扩散3D生成方法存在形状和纹理对齐问题，导致几何细节不完整和纹理重影，且对倾斜视角输入鲁棒性差

Method: 为每个视图分配可学习空间偏移参数，通过重建网格引导调整各视图实现空间一致性，并加入输入视图作为额外约束增强对非正面角度的鲁棒性

Result: 实验表明该方法在几何和纹理评估指标上均取得领先结果，对更灵活的输入视角具有良好适应性

Conclusion: LSS3D方法有效解决了多视图不一致问题，提升了3D生成质量，特别是对非正面输入视角的鲁棒性

Abstract: Recently, multi-view diffusion-based 3D generation methods have gained significant attention. However, these methods often suffer from shape and texture misalignment across generated multi-view images, leading to low-quality 3D generation results, such as incomplete geometric details and textural ghosting. Some methods are mainly optimized for the frontal perspective and exhibit poor robustness to oblique perspective inputs. In this paper, to tackle the above challenges, we propose a high-quality image-to-3D approach, named LSS3D, with learnable spatial shifting to explicitly and effectively handle the multiview inconsistencies and non-frontal input view. Specifically, we assign learnable spatial shifting parameters to each view, and adjust each view towards a spatially consistent target, guided by the reconstructed mesh, resulting in high-quality 3D generation with more complete geometric details and clean textures. Besides, we include the input view as an extra constraint for the optimization, further enhancing robustness to non-frontal input angles, especially for elevated viewpoint inputs. We also provide a comprehensive quantitative evaluation pipeline that can contribute to the community in performance comparisons. Extensive experiments demonstrate that our method consistently achieves leading results in both geometric and texture evaluation metrics across more flexible input viewpoints.

</details>


### [83] [GeoMVD: Geometry-Enhanced Multi-View Generation Model Based on Geometric Information Extraction](https://arxiv.org/abs/2511.12204)
*Jiaqi Wu,Yaosen Chen,Shuyuan Zhu*

Main category: cs.CV

TL;DR: 提出了Geometry-guided Multi-View Diffusion Model，通过提取多视角几何信息并调整几何特征强度，解决多视角图像生成中的一致性和高分辨率问题。


<details>
  <summary>Details</summary>
Motivation: 多视角图像生成在3D重建、虚拟现实等领域有重要应用价值，但现有方法在保持跨视角一致性和生成高分辨率输出方面存在计算挑战。

Method: 设计了多视角几何信息提取模块（深度图、法线图、前景分割掩码），解耦几何增强注意力机制，自适应学习策略，迭代精炼过程和动态几何信息强度调整机制。

Result: 模型能够生成跨视角一致且细节丰富的图像，确保形状和结构一致性，同时优化整体质量和自然度。

Conclusion: 该方法通过几何引导有效解决了多视角图像生成的关键挑战，为相关应用提供了高质量的解决方案。

Abstract: Multi-view image generation holds significant application value in computer vision, particularly in domains like 3D reconstruction, virtual reality, and augmented reality. Most existing methods, which rely on extending single images, face notable computational challenges in maintaining cross-view consistency and generating high-resolution outputs. To address these issues, we propose the Geometry-guided Multi-View Diffusion Model, which incorporates mechanisms for extracting multi-view geometric information and adjusting the intensity of geometric features to generate images that are both consistent across views and rich in detail. Specifically, we design a multi-view geometry information extraction module that leverages depth maps, normal maps, and foreground segmentation masks to construct a shared geometric structure, ensuring shape and structural consistency across different views. To enhance consistency and detail restoration during generation, we develop a decoupled geometry-enhanced attention mechanism that strengthens feature focus on key geometric details, thereby improving overall image quality and detail preservation. Furthermore, we apply an adaptive learning strategy that fine-tunes the model to better capture spatial relationships and visual coherence between the generated views, ensuring realistic results. Our model also incorporates an iterative refinement process that progressively improves the output quality through multiple stages of image generation. Finally, a dynamic geometry information intensity adjustment mechanism is proposed to adaptively regulate the influence of geometric data, optimizing overall quality while ensuring the naturalness of generated images. More details can be found on the project page: https://github.com/SobeyMIL/GeoMVD.com.

</details>


### [84] [A Novel AI-Driven System for Real-Time Detection of Mirror Absence, Helmet Non-Compliance, and License Plates Using YOLOv8 and OCR](https://arxiv.org/abs/2511.12206)
*Nishant Vasantkumar Hegde,Aditi Agarwal,Minal Moharir*

Main category: cs.CV

TL;DR: 该论文提出了一个基于AI的自动化交通违规检测系统，使用YOLOv8进行目标检测和EasyOCR进行车牌识别，能够检测头盔违规、摩托车后视镜缺失等违规行为，并提取车辆注册号码。


<details>
  <summary>Details</summary>
Motivation: 传统手动执法交通法规（如头盔法和车辆安全标准）资源消耗大且不一致，需要自动化解决方案来提高执法效率和道路安全。

Method: 系统采用YOLOv8进行目标检测和EasyOCR进行车牌识别，使用增强的自定义标注数据集进行训练，通过Streamlit界面实现实时监控和违规记录，并采用先进的图像预处理技术提升车牌识别性能。

Result: 模型整体精确度为0.9147，召回率为0.886，平均精度（mAP@50）为0.843，mAP@50-95为0.503，表明在严格IoU阈值下仍具有较强的检测能力。

Conclusion: 该研究展示了一个实用有效的自动化交通规则执法解决方案，并讨论了实际部署的考虑因素。

Abstract: Road safety is a critical global concern, with manual enforcement of helmet laws and vehicle safety standards (e.g., rear-view mirror presence) being resource-intensive and inconsistent. This paper presents an AI-powered system to automate traffic violation detection, significantly enhancing enforcement efficiency and road safety. The system leverages YOLOv8 for robust object detection and EasyOCR for license plate recognition. Trained on a custom dataset of annotated images (augmented for diversity), it identifies helmet non-compliance, the absence of rear-view mirrors on motorcycles, an innovative contribution to automated checks, and extracts vehicle registration numbers. A Streamlit-based interface facilitates real-time monitoring and violation logging. Advanced image preprocessing enhances license plate recognition, particularly under challenging conditions. Based on evaluation results, the model achieves an overall precision of 0.9147, a recall of 0.886, and a mean Average Precision (mAP@50) of 0.843. The mAP@50 95 of 0.503 further indicates strong detection capability under stricter IoU thresholds. This work demonstrates a practical and effective solution for automated traffic rule enforcement, with considerations for real-world deployment discussed.

</details>


### [85] [Mixture of States: Routing Token-Level Dynamics for Multimodal Generation](https://arxiv.org/abs/2511.12207)
*Haozhe Liu,Ding Liu,Mingchen Zhuge,Zijian Zhou,Tian Xie,Sen He,Yukang Yang,Shuming Liu,Yuren Cong,Jiadong Guo,Hongyu Xu,Ke Xu,Kam-Woh Ng,Juan C. Pérez,Juan-Manuel~Pérez-Rúa,Tao Xiang,Wei Liu,Shikun Liu,Jürgen Schmidhuber*

Main category: cs.CV

TL;DR: MoS是一种新型的多模态扩散模型融合范式，通过可学习的token级路由器实现模态间状态交互，在文本到图像生成和编辑任务中达到SOTA效果，仅用3B-5B参数即可匹配或超越4倍大的模型。


<details>
  <summary>Details</summary>
Motivation: 解决多模态扩散模型中模态融合效率低、参数利用率不高的问题，旨在开发一种灵活且计算高效的融合范式。

Method: 使用可学习的token级路由器，基于去噪时间步和输入创建模态间隐藏状态的交互，通过稀疏选择top-k隐藏状态和ε-greedy训练策略实现高效特征对齐。

Result: 在文本到图像生成(MoS-Image)和编辑(MoS-Editing)任务中取得SOTA结果，仅用3B-5B参数即可匹配或超越参数规模达4倍的对比模型。

Conclusion: MoS为多模态扩散模型提供了一种灵活且计算高效的扩展范式，在保持高性能的同时显著降低了计算开销。

Abstract: We introduce MoS (Mixture of States), a novel fusion paradigm for multimodal diffusion models that merges modalities using flexible, state-based interactions. The core of MoS is a learnable, token-wise router that creates denoising timestep- and input-dependent interactions between modalities' hidden states, precisely aligning token-level features with the diffusion trajectory. This router sparsely selects the top-$k$ hidden states and is trained with an $ε$-greedy strategy, efficiently selecting contextual features with minimal learnable parameters and negligible computational overhead. We validate our design with text-to-image generation (MoS-Image) and editing (MoS-Editing), which achieve state-of-the-art results. With only 3B to 5B parameters, our models match or surpass counterparts up to $4\times$ larger. These findings establish MoS as a flexible and compute-efficient paradigm for scaling multimodal diffusion models.

</details>


### [86] [FaNe: Towards Fine-Grained Cross-Modal Contrast with False-Negative Reduction and Text-Conditioned Sparse Attention](https://arxiv.org/abs/2511.12215)
*Peng Zhang,Zhihui Lai,Wenting Chen,Xu Wu,Heng Kong*

Main category: cs.CV

TL;DR: FaNe是一个语义增强的医学视觉-语言预训练框架，通过语义感知的正样本挖掘和文本条件稀疏注意力池化解决假阴性和细粒度对齐问题，在多个医学影像任务上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有医学视觉-语言预训练方法存在语义相似文本导致的假阴性问题，以及细粒度跨模态对齐不足的局限性。

Method: 1. 基于文本相似度的语义感知正样本挖掘策略；2. 文本条件稀疏注意力池化模块实现细粒度对齐；3. 硬负样本感知对比损失增强模态内区分度。

Result: 在五个下游医学影像基准测试中，FaNe在图像分类、目标检测和语义分割任务上均取得了最先进的性能。

Conclusion: FaNe框架通过解决假阴性和细粒度对齐问题，有效提升了医学视觉-语言预训练的性能。

Abstract: Medical vision-language pre-training (VLP) offers significant potential for advancing medical image understanding by leveraging paired image-report data. However, existing methods are limited by Fa}lse Negatives (FaNe) induced by semantically similar texts and insufficient fine-grained cross-modal alignment. To address these limitations, we propose FaNe, a semantic-enhanced VLP framework. To mitigate false negatives, we introduce a semantic-aware positive pair mining strategy based on text-text similarity with adaptive normalization. Furthermore, we design a text-conditioned sparse attention pooling module to enable fine-grained image-text alignment through localized visual representations guided by textual cues. To strengthen intra-modal discrimination, we develop a hard-negative aware contrastive loss that adaptively reweights semantically similar negatives. Extensive experiments on five downstream medical imaging benchmarks demonstrate that FaNe achieves state-of-the-art performance across image classification, object detection, and semantic segmentation, validating the effectiveness of our framework.

</details>


### [87] [Suppressing VLM Hallucinations with Spectral Representation Filtering](https://arxiv.org/abs/2511.12220)
*Ameen Ali,Tamim Zoabi,Lior Wolf*

Main category: cs.CV

TL;DR: SRF是一种无需训练的后处理方法，通过分析模型表示协方差结构来抑制视觉语言模型中的幻觉现象，在多个VLM模型上实现最先进的忠实度且不降低描述质量。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型经常产生对象、属性或关系的幻觉描述，这是由于过度依赖语言先验和跨模态基础不精确导致的。

Method: Spectral Representation Filtering (SRF)：通过特征分解识别幻觉模式，使用软谱滤波器在更深层VLM层的前馈投影权重中衰减这些模式，均衡特征方差同时保持语义保真度。

Result: 在三个VLM家族（LLaVA-1.5、MiniGPT-4和mPLUG-Owl2）上，SRF在MSCOCO、POPE-VQA等视觉任务基准上持续降低幻觉率。

Conclusion: SRF是一种轻量级、无需训练的方法，完全后处理操作，零推理开销，无需架构修改，在保持描述质量的同时实现最先进的忠实度。

Abstract: Vision-language models (VLMs) frequently produce hallucinations in the form of descriptions of objects, attributes, or relations that do not exist in the image due to over-reliance on language priors and imprecise cross-modal grounding. We introduce Spectral Representation Filtering (SRF), a lightweight, training-free method to suppress such hallucinations by analyzing and correcting the covariance structure of the model's representations. SRF identifies low-rank hallucination modes through eigendecomposition of the covariance of the differences between features collected for truthful and hallucinatory captions, revealing structured biases in the feature space. A soft spectral filter then attenuates these modes in the feed-forward projection weights of deeper vLLM layers, equalizing feature variance while preserving semantic fidelity. Unlike decoding or retraining-based approaches, SRF operates entirely post-hoc, incurs zero inference overhead, and requires no architectural modifications. Across three families of VLMs (LLaVA-1.5, MiniGPT-4, and mPLUG-Owl2), SRF consistently reduces hallucination rates on MSCOCO, POPE-VQA, and other visual tasks benchmarks, achieving state-of-the-art faithfulness without degrading caption quality.

</details>


### [88] [Model Inversion Attack Against Deep Hashing](https://arxiv.org/abs/2511.12233)
*Dongdong Zhao,Qiben Xu,Ranxin Fang,Baogang Song*

Main category: cs.CV

TL;DR: 本文提出了DHMI，首个针对深度哈希的扩散模型反演框架，揭示了深度哈希系统存在的严重隐私风险。


<details>
  <summary>Details</summary>
Motivation: 深度哈希虽然提高了检索效率，但存在被忽视的隐私风险——攻击者可能从哈希码重构原始训练数据，导致生物特征伪造和隐私泄露。目前针对深度哈希的模型反演攻击研究仍为空白。

Method: DHMI首先对辅助数据集进行聚类得到语义哈希中心作为代理锚点，然后引入代理引导的去噪优化方法，结合分类一致性和哈希接近度的新攻击指标动态选择候选样本，通过代理模型簇指导候选样本的细化。

Result: 在多个数据集上的实验表明，DHMI即使在最具挑战性的黑盒设置下也能成功重构高分辨率、高质量的图像，在黑盒场景下优于现有最先进的模型反演攻击方法。

Conclusion: DHMI证实了深度哈希系统存在的关键隐私风险，其方法具有实际有效性，为深度哈希模型的安全性评估提供了重要参考。

Abstract: Deep hashing improves retrieval efficiency through compact binary codes, yet it introduces severe and often overlooked privacy risks. The ability to reconstruct original training data from hash codes could lead to serious threats such as biometric forgery and privacy breaches. However, model inversion attacks specifically targeting deep hashing models remain unexplored, leaving their security implications unexamined. This research gap stems from the inaccessibility of genuine training hash codes and the highly discrete Hamming space, which prevents existing methods from adapting to deep hashing. To address these challenges, we propose DHMI, the first diffusion-based model inversion framework designed for deep hashing. DHMI first clusters an auxiliary dataset to derive semantic hash centers as surrogate anchors. It then introduces a surrogate-guided denoising optimization method that leverages a novel attack metric (fusing classification consistency and hash proximity) to dynamically select candidate samples. A cluster of surrogate models guides the refinement of these candidates, ensuring the generation of high-fidelity and semantically consistent images. Experiments on multiple datasets demonstrate that DHMI successfully reconstructs high-resolution, high-quality images even under the most challenging black-box setting, where no training hash codes are available. Our method outperforms the existing state-of-the-art model inversion attacks in black-box scenarios, confirming both its practical efficacy and the critical privacy risks inherent in deep hashing systems.

</details>


### [89] [Fusionista2.0: Efficiency Retrieval System for Large-Scale Datasets](https://arxiv.org/abs/2511.12255)
*Huy M. Le,Dat Tien Nguyen,Phuc Binh Nguyen,Gia-Bao Le-Tran,Phu Truong Thien,Cuong Dinh,Minh Nguyen,Nga Nguyen,Thuy T. N. Nguyen,Huy Gia Ngo,Tan Nhat Nguyen,Binh T. Nguyen,Monojit Choudhury*

Main category: cs.CV

TL;DR: Fusionista2.0是一个针对视频浏览器展示挑战优化的视频检索系统，通过重新设计核心模块实现了75%的检索时间减少，同时提高了准确性和用户满意度。


<details>
  <summary>Details</summary>
Motivation: 视频浏览器展示挑战要求系统在严格时间限制下提供准确结果，需要开发一个兼顾速度和可用性的视频检索系统。

Method: 重新设计核心模块：使用ffmpeg进行快速关键帧提取，Vintern-1B-v3.5进行多语言OCR，faster-whisper进行实时语音识别，轻量级视觉语言模型进行问答。同时改进用户界面响应性和可访问性。

Result: 检索时间减少高达75%，准确性和用户满意度均有提升，证明系统在大规模视频搜索中具有竞争力。

Conclusion: Fusionista2.0是一个高效、用户友好的视频检索系统，在速度和准确性方面均表现出色，适合大规模视频搜索应用。

Abstract: The Video Browser Showdown (VBS) challenges systems to deliver accurate results under strict time constraints. To meet this demand, we present Fusionista2.0, a streamlined video retrieval system optimized for speed and usability. All core modules were re-engineered for efficiency: preprocessing now relies on ffmpeg for fast keyframe extraction, optical character recognition uses Vintern-1B-v3.5 for robust multilingual text recognition, and automatic speech recognition employs faster-whisper for real-time transcription. For question answering, lightweight vision-language models provide quick responses without the heavy cost of large models. Beyond these technical upgrades, Fusionista2.0 introduces a redesigned user interface with improved responsiveness, accessibility, and workflow efficiency, enabling even non-expert users to retrieve relevant content rapidly. Evaluations demonstrate that retrieval time was reduced by up to 75% while accuracy and user satisfaction both increased, confirming Fusionista2.0 as a competitive and user-friendly system for large-scale video search.

</details>


### [90] [Prompt-Conditioned FiLM and Multi-Scale Fusion on MedSigLIP for Low-Dose CT Quality Assessment](https://arxiv.org/abs/2511.12256)
*Tolga Demiroglu,Mehmet Ozan Unal,Metin Ertas,Isa Yildirim*

Main category: cs.CV

TL;DR: 提出了基于MedSigLIP的提示条件框架，通过FiLM和多尺度池化注入文本先验，在LDCTIQA2023挑战中取得优异性能


<details>
  <summary>Details</summary>
Motivation: 开发能够通过文本提示条件临床意图的数据高效学习方法，实现快速适应LDCT图像质量评估

Method: 使用Feature-wise Linear Modulation（FiLM）和多尺度池化将文本提示注入到patch-token特征中，结合全局、局部和纹理感知池化，通过轻量级MLP融合回归头，使用成对排序损失训练

Result: 在LDCTIQA2023挑战（1000张训练图像）上达到PLCC=0.9575、SROCC=0.9561、KROCC=0.8301，超越已发表的最佳挑战提交结果

Conclusion: 提示引导方法在LDCT图像质量评估中表现出色，证明了文本条件特征的有效性和数据高效学习能力

Abstract: We propose a prompt-conditioned framework built on MedSigLIP that injects textual priors via Feature-wise Linear Modulation (FiLM) and multi-scale pooling. Text prompts condition patch-token features on clinical intent, enabling data-efficient learning and rapid adaptation. The architecture combines global, local, and texture-aware pooling through separate regression heads fused by a lightweight MLP, trained with pairwise ranking loss. Evaluated on the LDCTIQA2023 (a public LDCT quality assessment challenge) with 1,000 training images, we achieve PLCC = 0.9575, SROCC = 0.9561, and KROCC = 0.8301, surpassing the top-ranked published challenge submissions and demonstrating the effectiveness of our prompt-guided approach.

</details>


### [91] [A Disease-Aware Dual-Stage Framework for Chest X-ray Report Generation](https://arxiv.org/abs/2511.12259)
*Puzhen Wu,Hexin Dong,Yi Lin,Yihao Ding,Yifan Peng*

Main category: cs.CV

TL;DR: 提出了一个新颖的双阶段疾病感知框架用于胸部X光报告生成，通过疾病感知语义标记和视觉-语言对齐来提高临床准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在医学图像分析中缺乏足够的疾病感知能力和视觉-语言对齐，导致忽视关键病理特征且难以生成临床准确的报告。

Method: 第一阶段学习疾病感知语义标记（DASTs）并通过对比学习对齐视觉和语言表示；第二阶段引入疾病-视觉注意力融合模块和双模态相似性检索机制。

Result: 在CheXpert Plus、IU X-ray和MIMIC-CXR基准数据集上实现了最先进的性能，在临床准确性和语言质量方面有显著提升。

Conclusion: 该疾病感知框架能有效解决现有方法的局限性，为胸部X光报告生成提供了更准确和实用的解决方案。

Abstract: Radiology report generation from chest X-rays is an important task in artificial intelligence with the potential to greatly reduce radiologists' workload and shorten patient wait times. Despite recent advances, existing approaches often lack sufficient disease-awareness in visual representations and adequate vision-language alignment to meet the specialized requirements of medical image analysis. As a result, these models usually overlook critical pathological features on chest X-rays and struggle to generate clinically accurate reports. To address these limitations, we propose a novel dual-stage disease-aware framework for chest X-ray report generation. In Stage~1, our model learns Disease-Aware Semantic Tokens (DASTs) corresponding to specific pathology categories through cross-attention mechanisms and multi-label classification, while simultaneously aligning vision and language representations via contrastive learning. In Stage~2, we introduce a Disease-Visual Attention Fusion (DVAF) module to integrate disease-aware representations with visual features, along with a Dual-Modal Similarity Retrieval (DMSR) mechanism that combines visual and disease-specific similarities to retrieve relevant exemplars, providing contextual guidance during report generation. Extensive experiments on benchmark datasets (i.e., CheXpert Plus, IU X-ray, and MIMIC-CXR) demonstrate that our disease-aware framework achieves state-of-the-art performance in chest X-ray report generation, with significant improvements in clinical accuracy and linguistic quality.

</details>


### [92] [CrossVid: A Comprehensive Benchmark for Evaluating Cross-Video Reasoning in Multimodal Large Language Models](https://arxiv.org/abs/2511.12263)
*Jingyao Li,Jingyun Wang,Molin Tan,Haochen Wang,Cilin Yan,Likun Shi,Jiayin Cai,Xiaolong Jiang,Yao Hu*

Main category: cs.CV

TL;DR: CrossVid是首个专门评估多模态大语言模型在跨视频推理能力上的基准测试，包含4个高层维度和10个具体任务，提供5331个视频和9015个问答对，实验表明当前MLLMs在跨视频推理任务上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现有视频理解基准主要关注单视频分析，无法评估MLLMs同时处理多个视频的能力，而现实世界需要跨视频的时空推理能力。

Method: 构建CrossVid基准测试，包含广泛的层次化任务、多样化的视频数据集和问答格式，通过实验评估多种开源和闭源MLLMs的表现。

Result: Gemini-2.5-Pro在CrossVid上表现最佳，平均准确率为50.4%，但大多数MLLMs在跨视频推理任务上表现不佳，主要原因是无法整合或比较跨多个视频的证据。

Conclusion: CrossVid基准测试能够指导未来提升MLLMs跨视频推理能力的研究，当前模型在整合跨视频信息方面存在明显不足。

Abstract: Cross-Video Reasoning (CVR) presents a significant challenge in video understanding, which requires simultaneous understanding of multiple videos to aggregate and compare information across groups of videos. Most existing video understanding benchmarks focus on single-video analysis, failing to assess the ability of multimodal large language models (MLLMs) to simultaneously reason over various videos. Recent benchmarks evaluate MLLMs' capabilities on multi-view videos that capture different perspectives of the same scene. However, their limited tasks hinder a thorough assessment of MLLMs in diverse real-world CVR scenarios. To this end, we introduce CrossVid, the first benchmark designed to comprehensively evaluate MLLMs' spatial-temporal reasoning ability in cross-video contexts. Firstly, CrossVid encompasses a wide spectrum of hierarchical tasks, comprising four high-level dimensions and ten specific tasks, thereby closely reflecting the complex and varied nature of real-world video understanding. Secondly, CrossVid provides 5,331 videos, along with 9,015 challenging question-answering pairs, spanning single-choice, multiple-choice, and open-ended question formats. Through extensive experiments on various open-source and closed-source MLLMs, we observe that Gemini-2.5-Pro performs best on CrossVid, achieving an average accuracy of 50.4%. Notably, our in-depth case study demonstrates that most current MLLMs struggle with CVR tasks, primarily due to their inability to integrate or compare evidence distributed across multiple videos for reasoning. These insights highlight the potential of CrossVid to guide future advancements in enhancing MLLMs' CVR capabilities.

</details>


### [93] [ZoomEarth: Active Perception for Ultra-High-Resolution Geospatial Vision-Language Tasks](https://arxiv.org/abs/2511.12267)
*Ruixun Liu,Bowen Fu,Jiayi Song,Kaiyu Li,Wanchen Li,Lanxuan Xue,Hui Qiao,Weizhan Zhang,Deyu Meng,Xiangyong Cao*

Main category: cs.CV

TL;DR: 本文提出了一种新的主动感知范式ZoomEarth，通过自适应裁剪放大框架处理超高分辨率遥感图像，在LRS-GRO基准数据集上实现最先进性能，并展示出色的下游任务扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有动态分辨率和token剪枝方法受限于被动感知范式，在处理更精细视觉输入时会产生冗余。本文探索主动感知范式，让模型能够重新访问信息丰富区域。

Method: 提出ZoomEarth自适应裁剪放大框架，采用区域引导奖励机制，通过监督微调(SFT)和组相对策略优化(GRPO)进行训练。

Result: 在LRS-GRO基准上达到最先进性能，在三个公共UHR遥感基准的零样本设置中也表现优异。

Conclusion: ZoomEarth可无缝集成到下游模型中，通过简单工具接口实现云去除、去噪、分割和图像编辑等任务，展示了强大的多功能性和可扩展性。

Abstract: Ultra-high-resolution (UHR) remote sensing (RS) images offer rich fine-grained information but also present challenges in effective processing. Existing dynamic resolution and token pruning methods are constrained by a passive perception paradigm, suffering from increased redundancy when obtaining finer visual inputs. In this work, we explore a new active perception paradigm that enables models to revisit information-rich regions. First, we present LRS-GRO, a large-scale benchmark dataset tailored for active perception in UHR RS processing, encompassing 17 question types across global, region, and object levels, annotated via a semi-automatic pipeline. Building on LRS-GRO, we propose ZoomEarth, an adaptive cropping-zooming framework with a novel Region-Guided reward that provides fine-grained guidance. Trained via supervised fine-tuning (SFT) and Group Relative Policy Optimization (GRPO), ZoomEarth achieves state-of-the-art performance on LRS-GRO and, in the zero-shot setting, on three public UHR remote sensing benchmarks. Furthermore, ZoomEarth can be seamlessly integrated with downstream models for tasks such as cloud removal, denoising, segmentation, and image editing through simple tool interfaces, demonstrating strong versatility and extensibility.

</details>


### [94] [TM-UNet: Token-Memory Enhanced Sequential Modeling for Efficient Medical Image Segmentation](https://arxiv.org/abs/2511.12270)
*Yaxuan Jiao,Qing Xu,Yuxiang Luo,Xiangjian He,Zhen Chen,Wenting Duan*

Main category: cs.CV

TL;DR: TM-UNet是一种轻量级医学图像分割框架，通过多尺度令牌-内存机制实现高效全局推理，显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的基于Transformer的医学图像分割方法虽然效果显著，但计算成本过高，阻碍了临床部署。

Method: 提出多尺度令牌-内存（MSTM）块，将2D空间特征转换为令牌序列，利用矩阵内存单元选择性保留和传播判别性上下文信息，通过指数门控和并行池化操作实现多尺度上下文提取。

Result: 在多个医学分割任务上超越现有最先进方法，同时大幅降低计算成本。

Conclusion: TM-UNet通过创新的令牌-内存机制实现了高效的长距离依赖建模，为临床部署提供了可行的轻量级解决方案。

Abstract: Medical image segmentation is essential for clinical diagnosis and treatment planning. Although transformer-based methods have achieved remarkable results, their high computational cost hinders clinical deployment. To address this issue, we propose TM-UNet, a novel lightweight framework that integrates token sequence modeling with an efficient memory mechanism for efficient medical segmentation. Specifically, we introduce a multi-scale token-memory (MSTM) block that transforms 2D spatial features into token sequences through strategic spatial scanning, leveraging matrix memory cells to selectively retain and propagate discriminative contextual information across tokens. This novel token-memory mechanism acts as a dynamic knowledge store that captures long-range dependencies with linear complexity, enabling efficient global reasoning without redundant computation. Our MSTM block further incorporates exponential gating to identify token effectiveness and multi-scale contextual extraction via parallel pooling operations, enabling hierarchical representation learning without computational overhead. Extensive experiments demonstrate that TM-UNet outperforms state-of-the-art methods across diverse medical segmentation tasks with substantially reduced computation cost. The code is available at https://github.com/xq141839/TM-UNet.

</details>


### [95] [D$^{3}$ToM: Decider-Guided Dynamic Token Merging for Accelerating Diffusion MLLMs](https://arxiv.org/abs/2511.12280)
*Shuochen Chang,Xiaofeng Zhang,Qingyang Liu,Li Niu*

Main category: cs.CV

TL;DR: D^3ToM是一种用于扩散多模态大语言模型的动态令牌合并方法，通过在每个去噪步骤中动态合并冗余视觉令牌来加速推理，同时保持竞争性能。


<details>
  <summary>Details</summary>
Motivation: 扩散多模态大语言模型虽然具有强大的非自回归生成能力，但推理速度明显慢于自回归模型，主要原因是每个去噪步骤都需要对整个序列进行全双向自注意力计算，导致立方级的解码复杂度。

Method: 提出基于决策器引导的动态令牌合并方法，使用前一步生成的决策器令牌构建重要性映射，保留最显著的令牌并通过相似性聚合合并冗余令牌，采用随去噪步骤动态变化的合并比例。

Result: 大量实验表明D^3ToM在保持竞争性能的同时显著加速了推理过程。

Conclusion: D^3ToM是一种即插即用的模块，能够有效解决扩散多模态大语言模型的推理效率问题，为实际应用提供了可行的加速方案。

Abstract: Diffusion-based multimodal large language models (Diffusion MLLMs) have recently demonstrated impressive non-autoregressive generative capabilities across vision-and-language tasks. However, Diffusion MLLMs exhibit substantially slower inference than autoregressive models: Each denoising step employs full bidirectional self-attention over the entire sequence, resulting in cubic decoding complexity that becomes computationally impractical with thousands of visual tokens. To address this challenge, we propose D$^{3}$ToM, a Decider-guided dynamic token merging method that dynamically merges redundant visual tokens at different denoising steps to accelerate inference in Diffusion MLLMs. At each denoising step, D$^{3}$ToM uses decider tokens-the tokens generated in the previous denoising step-to build an importance map over all visual tokens. Then it maintains a proportion of the most salient tokens and merges the remainder through similarity-based aggregation. This plug-and-play module integrates into a single transformer layer, physically shortening the visual token sequence for all subsequent layers without altering model parameters. Moreover, D$^{3}$ToM employs a merge ratio that dynamically varies with each denoising step, aligns with the native decoding process of Diffusion MLLMs, achieving superior performance under equivalent computational budgets. Extensive experiments show that D$^{3}$ToM accelerates inference while preserving competitive performance. The code is released at https://github.com/bcmi/D3ToM-Diffusion-MLLM.

</details>


### [96] [One target to align them all: LiDAR, RGB and event cameras extrinsic calibration for Autonomous Driving](https://arxiv.org/abs/2511.12291)
*Andrea Bertogalli,Giacomo Boracchi,Luca Magri*

Main category: cs.CV

TL;DR: 提出了一种新颖的多模态外参标定框架，可同时估计事件相机、LiDAR和RGB相机之间的相对位姿，特别关注事件相机的标定挑战。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶等复杂视觉系统中，精确的多传感器对齐至关重要。现有方法通常依赖分步的成对标定，而本文旨在实现一次性联合标定。

Method: 设计并构建了新型3D标定靶标，包含平面特征、ChArUco图案和主动LED模式，分别针对LiDAR、RGB相机和事件相机的特性。通过该靶标实现一次性联合外参标定。

Result: 在定制数据集上进行了广泛实验评估，验证了方法的准确性和鲁棒性。

Conclusion: 该方法能够准确标定自动驾驶场景中的复杂视觉系统，解决了多模态传感器联合标定的挑战。

Abstract: We present a novel multi-modal extrinsic calibration framework designed to simultaneously estimate the relative poses between event cameras, LiDARs, and RGB cameras, with particular focus on the challenging event camera calibration. Core of our approach is a novel 3D calibration target, specifically designed and constructed to be concurrently perceived by all three sensing modalities. The target encodes features in planes, ChArUco, and active LED patterns, each tailored to the unique characteristics of LiDARs, RGB cameras, and event cameras respectively. This unique design enables a one-shot, joint extrinsic calibration process, in contrast to existing approaches that typically rely on separate, pairwise calibrations. Our calibration pipeline is designed to accurately calibrate complex vision systems in the context of autonomous driving, where precise multi-sensor alignment is critical. We validate our approach through an extensive experimental evaluation on a custom built dataset, recorded with an advanced autonomous driving sensor setup, confirming the accuracy and robustness of our method.

</details>


### [97] [Rethinking Bias in Generative Data Augmentation for Medical AI: a Frequency Recalibration Method](https://arxiv.org/abs/2511.12301)
*Chi Liu,Jincheng Liu,Congcong Zhu,Minghao Wang,Sheng Shen,Jia Gu,Tianqing Zhu,Wanlei Zhou*

Main category: cs.CV

TL;DR: 本文提出频率重新校准（FreRec）方法来解决生成式数据增强（GDA）中频率分布不匹配的问题，通过高频分量对齐和重建来提升医学图像合成质量。


<details>
  <summary>Details</summary>
Motivation: 医学AI开发面临数据稀缺问题，生成式数据增强存在频率分布偏差风险，可能损害下游任务性能。

Method: FreRec包含两个步骤：统计高频替换（SHR）粗略对齐高频分量，重建高频映射（RHM）提升图像质量并重建高频细节。

Result: 在脑部MRI、胸部X光、眼底图像等多个医学数据集上的实验表明，FreRec显著提升了下游医学图像分类性能。

Conclusion: FreRec是一个独立的后处理步骤，兼容任何生成模型，可无缝集成到医学GDA流程中，有效改善生成图像的可靠性。

Abstract: Developing Medical AI relies on large datasets and easily suffers from data scarcity. Generative data augmentation (GDA) using AI generative models offers a solution to synthesize realistic medical images. However, the bias in GDA is often underestimated in medical domains, with concerns about the risk of introducing detrimental features generated by AI and harming downstream tasks. This paper identifies the frequency misalignment between real and synthesized images as one of the key factors underlying unreliable GDA and proposes the Frequency Recalibration (FreRec) method to reduce the frequency distributional discrepancy and thus improve GDA. FreRec involves (1) Statistical High-frequency Replacement (SHR) to roughly align high-frequency components and (2) Reconstructive High-frequency Mapping (RHM) to enhance image quality and reconstruct high-frequency details. Extensive experiments were conducted in various medical datasets, including brain MRIs, chest X-rays, and fundus images. The results show that FreRec significantly improves downstream medical image classification performance compared to uncalibrated AI-synthesized samples. FreRec is a standalone post-processing step that is compatible with any generative model and can integrate seamlessly with common medical GDA pipelines.

</details>


### [98] [LiDAR-GS++:Improving LiDAR Gaussian Reconstruction via Diffusion Priors](https://arxiv.org/abs/2511.12304)
*Qifeng Chen,Jiarun Liu,Rengan Xie,Tao Tang,Sicong Du,Yiru Zhao,Yuchi Huo,Sheng Yang*

Main category: cs.CV

TL;DR: LiDAR-GS++是一种基于高斯溅射的LiDAR重建方法，通过扩散先验增强，解决了单次扫描重建不完整导致的视点外推伪影问题，实现了实时高保真重模拟。


<details>
  <summary>Details</summary>
Motivation: 现有的基于高斯溅射的LiDAR渲染方法在视点外推时会出现伪影，主要原因是单次扫描重建不完整。

Method: 提出可控LiDAR生成模型，基于粗略外推渲染生成几何一致的额外扫描；采用有效蒸馏机制进行扩展重建；通过扩散先验增强重建效果。

Result: 在多个公开数据集上的实验表明，LiDAR-GS++在插值和外推视点下均达到最先进性能，超越现有GS和NeRF方法。

Conclusion: 该方法通过扩展重建到欠拟合区域，确保外推新视点的全局几何一致性，同时保留传感器捕获的详细场景表面。

Abstract: Recent GS-based rendering has made significant progress for LiDAR, surpassing Neural Radiance Fields (NeRF) in both quality and speed. However, these methods exhibit artifacts in extrapolated novel view synthesis due to the incomplete reconstruction from single traversal scans. To address this limitation, we present LiDAR-GS++, a LiDAR Gaussian Splatting reconstruction method enhanced by diffusion priors for real-time and high-fidelity re-simulation on public urban roads. Specifically, we introduce a controllable LiDAR generation model conditioned on coarsely extrapolated rendering to produce extra geometry-consistent scans and employ an effective distillation mechanism for expansive reconstruction. By extending reconstruction to under-fitted regions, our approach ensures global geometric consistency for extrapolative novel views while preserving detailed scene surfaces captured by sensors. Experiments on multiple public datasets demonstrate that LiDAR-GS++ achieves state-of-the-art performance for both interpolated and extrapolated viewpoints, surpassing existing GS and NeRF-based methods.

</details>


### [99] [Learning Time in Static Classifiers](https://arxiv.org/abs/2511.12321)
*Xi Ding,Lei Wang,Piotr Koniusz,Yongsheng Gao*

Main category: cs.CV

TL;DR: 本文提出了一种简单有效的框架，通过SEQ学习范式为前馈分类器添加时序推理能力，无需修改模型架构或引入循环模块。该方法在静态和时序任务中均表现出色。


<details>
  <summary>Details</summary>
Motivation: 现实世界视觉数据通常具有时序演化特性，但传统分类器基于时序独立性假设训练，无法有效捕捉动态变化。需要一种能够处理时序演化的方法。

Method: 采用支持-示例-查询(SEQ)学习范式，将训练数据组织成时序连贯的轨迹。通过学习类特定时序原型和使用可微分软DTW损失对齐预测序列，多目标函数促进语义一致性和时序平滑性。

Result: 该方法在细粒度和超细粒度图像分类任务中提升性能，在视频异常检测中提供精确且时序一致的预测，实现了静态与时序学习的有效结合。

Conclusion: 尽管方法简单，但通过损失设计引入强时序归纳偏置，以模块化和数据高效的方式桥接了静态和时序学习，仅需在预提取特征上使用简单分类器。

Abstract: Real-world visual data rarely presents as isolated, static instances. Instead, it often evolves gradually over time through variations in pose, lighting, object state, or scene context. However, conventional classifiers are typically trained under the assumption of temporal independence, limiting their ability to capture such dynamics. We propose a simple yet effective framework that equips standard feedforward classifiers with temporal reasoning, all without modifying model architectures or introducing recurrent modules. At the heart of our approach is a novel Support-Exemplar-Query (SEQ) learning paradigm, which structures training data into temporally coherent trajectories. These trajectories enable the model to learn class-specific temporal prototypes and align prediction sequences via a differentiable soft-DTW loss. A multi-term objective further promotes semantic consistency and temporal smoothness. By interpreting input sequences as evolving feature trajectories, our method introduces a strong temporal inductive bias through loss design alone. This proves highly effective in both static and temporal tasks: it enhances performance on fine-grained and ultra-fine-grained image classification, and delivers precise, temporally consistent predictions in video anomaly detection. Despite its simplicity, our approach bridges static and temporal learning in a modular and data-efficient manner, requiring only a simple classifier on top of pre-extracted features.

</details>


### [100] [SpaceVLM: Sub-Space Modeling of Negation in Vision-Language Models](https://arxiv.org/abs/2511.12331)
*Sepehr Kazemi Ranjbar,Kumail Alhamoud,Marzyeh Ghassemi*

Main category: cs.CV

TL;DR: 提出了一种无需训练的框架，通过将否定建模为联合嵌入空间中的子空间而非单点，有效解决视觉语言模型在否定理解上的局限性，同时保持零样本性能


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在处理否定提示时表现不佳，现有方法通过微调大型否定数据集往往会损害模型在肯定提示上的零样本性能

Method: 将CLIP等VLM的嵌入空间划分为语义一致的子空间，通过构建围绕A和N嵌入的两个球面帽区域，对图像进行评分，选择靠近A且远离N的中心方向

Result: 在检索、多选题和文本到图像任务中，该方法比现有方法平均提升约30%的否定理解能力，缩小了肯定和否定提示之间的差距

Conclusion: 该方法在不损害零样本性能的前提下，显著提升了视觉语言模型的否定理解能力，为处理复杂语言结构提供了有效解决方案

Abstract: Vision-Language Models (VLMs) struggle with negation. Given a prompt like "retrieve (or generate) a street scene without pedestrians," they often fail to respect the "not." Existing methods address this limitation by fine-tuning on large negation datasets, but such retraining often compromises the model's zero-shot performance on affirmative prompts. We show that the embedding space of VLMs, such as CLIP, can be divided into semantically consistent subspaces. Based on this property, we propose a training-free framework that models negation as a subspace in the joint embedding space rather than a single point (Figure 1). To find the matching image for a caption such as "A but not N," we construct two spherical caps around the embeddings of A and N, and we score images by the central direction of the region that is close to A and far from N. Across retrieval, MCQ, and text-to-image tasks, our method improves negation understanding by about 30% on average over prior methods. It closes the gap between affirmative and negated prompts while preserving the zero-shot performance that fine-tuned models fail to maintain. Code will be released upon publication.

</details>


### [101] [Ground Plane Projection for Improved Traffic Analytics at Intersections](https://arxiv.org/abs/2511.12342)
*Sajjad Pakdamansavoji,Kumar Vaibhav Jha,Baher Abdulhai,James H Elder*

Main category: cs.CV

TL;DR: 该论文探索了将基础设施摄像头检测到的车辆反投影到地面平面进行3D坐标分析的优势，发现单摄像头系统反投影能提高轨迹分类和转向运动计数的准确性，多摄像头弱融合可进一步提升精度。


<details>
  <summary>Details</summary>
Motivation: 交叉口的准确转向运动计数对信号控制、交通管理和城市规划至关重要，传统基于图像平面的计算机视觉系统存在局限性。

Method: 通过将车辆检测从图像平面反投影到地面平面，在真实世界3D坐标中进行分析，并探索单摄像头和多摄像头弱融合的方法。

Result: 单摄像头反投影能获得更准确的轨迹分类和转向运动计数，多摄像头弱融合可达到更高精度。

Conclusion: 交通分析应在地面平面而非图像平面上进行，反投影方法能显著提升转向运动计数的准确性。

Abstract: Accurate turning movement counts at intersections are important for signal control, traffic management and urban planning. Computer vision systems for automatic turning movement counts typically rely on visual analysis in the image plane of an infrastructure camera. Here we explore potential advantages of back-projecting vehicles detected in one or more infrastructure cameras to the ground plane for analysis in real-world 3D coordinates. For single-camera systems we find that back-projection yields more accurate trajectory classification and turning movement counts. We further show that even higher accuracy can be achieved through weak fusion of back-projected detections from multiple cameras. These results suggeest that traffic should be analyzed on the ground plane, not the image plane

</details>


### [102] [CLAReSNet: When Convolution Meets Latent Attention for Hyperspectral Image Classification](https://arxiv.org/abs/2511.12346)
*Asmit Bandyopadhyay,Anindita Das Bhattacharjee,Rakesh Das*

Main category: cs.CV

TL;DR: 提出了CLAReSNet混合架构，结合CNN和Transformer优势，通过自适应潜在瓶颈降低计算复杂度，在高光谱图像分类任务中实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决高光谱图像分类面临的三大挑战：高光谱维度、复杂光谱-空间相关性、训练样本有限且类别不平衡。CNN擅长局部特征提取但Transformer能捕获长程依赖，但单独使用效果不佳。

Method: CLAReSNet集成多尺度卷积提取和Transformer式注意力机制，包含多尺度卷积主干、增强的CBAM模块、双向RNN光谱编码器，以及创新的多尺度光谱潜在注意力(MSLA)模块，将复杂度从O(T²D)降至O(Tlog(T)D)。

Result: 在Indian Pines和Salinas数据集上分别达到99.71%和99.96%的总体准确率，显著超越HybridSN、SSRN和SpectralFormer等现有方法。

Conclusion: CLAReSNet在有限样本和严重类别不平衡条件下表现出色，学习到的嵌入具有优异的类间可分性和紧凑的类内聚类效果。

Abstract: Hyperspectral image (HSI) classification faces critical challenges, including high spectral dimensionality, complex spectral-spatial correlations, and limited training samples with severe class imbalance. While CNNs excel at local feature extraction and transformers capture long-range dependencies, their isolated application yields suboptimal results due to quadratic complexity and insufficient inductive biases. We propose CLAReSNet (Convolutional Latent Attention Residual Spectral Network), a hybrid architecture that integrates multi-scale convolutional extraction with transformer-style attention via an adaptive latent bottleneck. The model employs a multi-scale convolutional stem with deep residual blocks and an enhanced Convolutional Block Attention Module for hierarchical spatial features, followed by spectral encoder layers combining bidirectional RNNs (LSTM/GRU) with Multi-Scale Spectral Latent Attention (MSLA). MSLA reduces complexity from $\mathcal{O}(T^2D)$ to $\mathcal{O}(T\log(T)D)$ by adaptive latent token allocation (8-64 tokens) that scales logarithmically with the sequence length. Hierarchical cross-attention fusion dynamically aggregates multi-level representations for robust classification. Experiments conducted on the Indian Pines and Salinas datasets show state-of-the-art performance, achieving overall accuracies of 99.71% and 99.96%, significantly surpassing HybridSN, SSRN, and SpectralFormer. The learned embeddings exhibit superior inter-class separability and compact intra-class clustering, validating CLAReSNet's effectiveness under limited samples and severe class imbalance.

</details>


### [103] [Explainable AI-Generated Image Detection RewardBench](https://arxiv.org/abs/2511.12363)
*Michael Yang,Shijian Deng,William T. Doan,Kai Wang,Tianyu Yang,Harsh Singh,Yapeng Tian*

Main category: cs.CV

TL;DR: 该论文提出了第一个评估多模态大语言模型判断AI生成图像检测解释质量的基准——XAIGID-RewardBench，发现当前最佳模型得分88.76%，与人类98.30%的标注一致性存在明显差距。


<details>
  <summary>Details</summary>
Motivation: 传统基于分类的AI生成图像检测方法无法提供人类专家可理解的解释，降低了检测工具的可信度。虽然MLLMs被用于生成解释，但它们在判断自身或其他MLLMs生成的解释质量方面的能力尚未得到充分研究。

Method: 构建包含约3000个标注三元组的基准数据集，这些数据来自不同图像生成模型和作为检测器的MLLMs，用于评估MLLMs作为评判模型的能力。

Result: 当前最佳奖励模型在该基准上得分为88.76%，而人类标注者间一致性达到98.30%，表明MLLMs与人类水平推理能力仍存在明显差距。

Conclusion: 需要进一步改进MLLMs的推理能力以缩小与人类水平的差距，论文还分析了模型常见的错误类型，为未来研究提供了方向。

Abstract: Conventional, classification-based AI-generated image detection methods cannot explain why an image is considered real or AI-generated in a way a human expert would, which reduces the trustworthiness and persuasiveness of these detection tools for real-world applications. Leveraging Multimodal Large Language Models (MLLMs) has recently become a trending solution to this issue. Further, to evaluate the quality of generated explanations, a common approach is to adopt an "MLLM as a judge" methodology to evaluate explanations generated by other MLLMs. However, how well those MLLMs perform when judging explanations for AI-generated image detection generated by themselves or other MLLMs has not been well studied. We therefore propose \textbf{XAIGID-RewardBench}, the first benchmark designed to evaluate the ability of current MLLMs to judge the quality of explanations about whether an image is real or AI-generated. The benchmark consists of approximately 3,000 annotated triplets sourced from various image generation models and MLLMs as policy models (detectors) to assess the capabilities of current MLLMs as reward models (judges). Our results show that the current best reward model scored 88.76\% on this benchmark (while human inter-annotator agreement reaches 98.30\%), demonstrating that a visible gap remains between the reasoning abilities of today's MLLMs and human-level performance. In addition, we provide an analysis of common pitfalls that these models frequently encounter. Code and benchmark are available at https://github.com/RewardBench/XAIGID-RewardBench.

</details>


### [104] [Constructing and Interpreting Digital Twin Representations for Visual Reasoning via Reinforcement Learning](https://arxiv.org/abs/2511.12365)
*Yiqing Shen,Mathias Unberath*

Main category: cs.CV

TL;DR: DT-R1是一个基于强化学习的框架，通过训练大语言模型构建复杂多模态视觉输入的数字化孪生表示，作为视觉推理的统一方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于任务特定的架构和监督微调，每种视觉推理任务需要不同的模型设计和训练，阻碍了统一解决方案并限制了跨任务和跨模态的泛化能力。

Method: 使用GRPO（可能指某种强化学习算法）和一种新颖的奖励函数来训练DT-R1，该奖励同时验证结构完整性和输出准确性。

Result: 在六个视觉推理基准测试中（涵盖两种模态和四种任务类型），DT-R1始终优于最先进的任务特定模型。

Conclusion: DT-R1开辟了一个新方向，即视觉推理通过强化学习与数字化孪生表示相结合来实现。

Abstract: Visual reasoning may require models to interpret images and videos and respond to implicit text queries across diverse output formats, from pixel-level segmentation masks to natural language descriptions. Existing approaches rely on supervised fine-tuning with task-specific architectures. For example, reasoning segmentation, grounding, summarization, and visual question answering each demand distinct model designs and training, preventing unified solutions and limiting cross-task and cross-modality generalization. Hence, we propose DT-R1, a reinforcement learning framework that trains large language models to construct digital twin representations of complex multi-modal visual inputs and then reason over these high-level representations as a unified approach to visual reasoning. Specifically, we train DT-R1 using GRPO with a novel reward that validates both structural integrity and output accuracy. Evaluations in six visual reasoning benchmarks, covering two modalities and four task types, demonstrate that DT-R1 consistently achieves improvements over state-of-the-art task-specific models. DT-R1 opens a new direction where visual reasoning emerges from reinforcement learning with digital twin representations.

</details>


### [105] [Fast Reasoning Segmentation for Images and Videos](https://arxiv.org/abs/2511.12368)
*Yiqing Shen,Mathias Unberath*

Main category: cs.CV

TL;DR: FastReasonSeg提出了一种基于数字孪生表示的分割模型蒸馏方法，通过解耦感知和推理，实现了在资源受限设备上的实时推理分割，性能超越参数量大20倍的模型。


<details>
  <summary>Details</summary>
Motivation: 现有的推理分割方法需要数十亿参数的多模态大语言模型，超出了边缘设备的计算能力。传统蒸馏方法无法有效传递多步推理能力，因为它们只关注输出预测和中间特征的匹配，而不是保留推理链。

Method: 采用数字孪生表示将感知与推理解耦，首先在教师生成的推理链上进行监督微调，然后通过强化微调联合评估分割精度和推理质量对齐。

Result: 在四个基准测试上达到最先进的推理分割性能，蒸馏后的0.6B版本性能超越参数量大20倍的模型，同时实现7.79 FPS吞吐量和仅2.1GB内存消耗。

Conclusion: 该方法实现了在资源受限环境中的实时推理分割部署，为边缘设备上的自主智能体操作提供了可行方案。

Abstract: Reasoning segmentation enables open-set object segmentation via implicit text queries, therefore serving as a foundation for embodied agents that should operate autonomously in real-world environments. However, existing methods for reasoning segmentation require multimodal large language models with billions of parameters that exceed the computational capabilities of edge devices that typically deploy the embodied AI systems. Distillation offers a pathway to compress these models while preserving their capabilities. Yet, existing distillation approaches fail to transfer the multi-step reasoning capabilities that reasoning segmentation demands, as they focus on matching output predictions and intermediate features rather than preserving reasoning chains. The emerging paradigm of reasoning over digital twin representations presents an opportunity for more effective distillation by re-framing the problem. Consequently, we propose FastReasonSeg, which employs digital twin representations that decouple perception from reasoning to enable more effective distillation. Our distillation scheme first relies on supervised fine-tuning on teacher-generated reasoning chains. Then it is followed by reinforcement fine-tuning with joint rewards evaluating both segmentation accuracy and reasoning quality alignment. Experiments on two video (JiTBench, RVTBench) and two image benchmarks (ReasonSeg, LLM-Seg40K) demonstrate that our FastReasonSeg achieves state-of-the-art reasoning segmentation performance. Moreover, the distilled 0.6B variant outperforms models with 20 times more parameters while achieving 7.79 FPS throughput with only 2.1GB memory consumption. This efficiency enables deployment in resource-constrained environments to enable real-time reasoning segmentation.

</details>


### [106] [Changes in Real Time: Online Scene Change Detection with Multi-View Fusion](https://arxiv.org/abs/2511.12370)
*Chamuditha Jayanga Galappaththige,Jason Lai,Lloyd Windrim,Donald Dansereau,Niko Sünderhauf,Dimity Miller*

Main category: cs.CV

TL;DR: 提出首个姿态无关、无标签、多视角一致性的在线场景变化检测方法，达到10+FPS，性能超越最佳离线方法。


<details>
  <summary>Details</summary>
Motivation: 现有在线场景变化检测方法准确性远低于离线方法，需要解决姿态无关、无标签约束下的实时检测问题。

Method: 引入自监督融合损失从多线索推断场景变化，基于PnP的快速姿态估计，以及针对3D高斯泼溅场景表示的快速变化引导更新策略。

Result: 在复杂真实世界数据集上的大量实验表明，该方法在性能和速度上都优于在线和离线基线方法。

Conclusion: 该方法实现了实时、高精度的在线场景变化检测，为动态环境感知提供了有效解决方案。

Abstract: Online Scene Change Detection (SCD) is an extremely challenging problem that requires an agent to detect relevant changes on the fly while observing the scene from unconstrained viewpoints. Existing online SCD methods are significantly less accurate than offline approaches. We present the first online SCD approach that is pose-agnostic, label-free, and ensures multi-view consistency, while operating at over 10 FPS and achieving new state-of-the-art performance, surpassing even the best offline approaches. Our method introduces a new self-supervised fusion loss to infer scene changes from multiple cues and observations, PnP-based fast pose estimation against the reference scene, and a fast change-guided update strategy for the 3D Gaussian Splatting scene representation. Extensive experiments on complex real-world datasets demonstrate that our approach outperforms both online and offline baselines.

</details>


### [107] [Reasoning Text-to-Video Retrieval via Digital Twin Video Representations and Large Language Models](https://arxiv.org/abs/2511.12371)
*Yiqing Shen,Chenxiao Fan,Chenjia Li,Mathias Unberath*

Main category: cs.CV

TL;DR: 本文提出了一种新的文本到视频检索方法，通过数字孪生表示和大型语言模型推理来处理需要推理的隐式查询，在多个基准测试中取得了显著优于现有方法的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到视频检索方法主要处理显式查询，但无法有效处理需要推理的隐式查询。本文旨在解决这一局限性，扩展检索能力以处理需要推理的查询。

Method: 提出两阶段框架：首先使用数字孪生（结构化场景表示）进行组合对齐识别候选视频，然后应用大型语言模型进行推理，并通过即时细化调用专业模型填补信息空白。

Result: 在ReasonT2VBench-135上达到81.2%的R@1，比最强基线提升超过50个百分点；在扩展配置上保持81.7%的R@1，并在三个传统基准测试（MSR-VTT、MSVD、VATEX）上取得最优结果。

Conclusion: 该方法通过数字孪生表示和LLM推理成功解决了隐式查询的文本到视频检索问题，显著提升了检索性能，为复杂推理任务提供了有效解决方案。

Abstract: The goal of text-to-video retrieval is to search large databases for relevant videos based on text queries. Existing methods have progressed to handling explicit queries where the visual content of interest is described explicitly; however, they fail with implicit queries where identifying videos relevant to the query requires reasoning. We introduce reasoning text-to-video retrieval, a paradigm that extends traditional retrieval to process implicit queries through reasoning while providing object-level grounding masks that identify which entities satisfy the query conditions. Instead of relying on vision-language models directly, we propose representing video content as digital twins, i.e., structured scene representations that decompose salient objects through specialist vision models. This approach is beneficial because it enables large language models to reason directly over long-horizon video content without visual token compression. Specifically, our two-stage framework first performs compositional alignment between decomposed sub-queries and digital twin representations for candidate identification, then applies large language model-based reasoning with just-in-time refinement that invokes additional specialist models to address information gaps. We construct a benchmark of 447 manually created implicit queries with 135 videos (ReasonT2VBench-135) and another more challenging version of 1000 videos (ReasonT2VBench-1000). Our method achieves 81.2% R@1 on ReasonT2VBench-135, outperforming the strongest baseline by greater than 50 percentage points, and maintains 81.7% R@1 on the extended configuration while establishing state-of-the-art results in three conventional benchmarks (MSR-VTT, MSVD, and VATEX).

</details>


### [108] [AGGRNet: Selective Feature Extraction and Aggregation for Enhanced Medical Image Classification](https://arxiv.org/abs/2511.12382)
*Ansh Makwe,Akansh Agrawal,Prateek Jain,Akshan Agrawal,Priyanka Bagade*

Main category: cs.CV

TL;DR: AGGRNet框架通过提取信息性和非信息性特征来解决医学图像分析中复杂任务的挑战，在多个数据集上实现最先进性能，在Kvasir数据集上比SOTA模型提升高达5%。


<details>
  <summary>Details</summary>
Motivation: 医学图像分析面临类间相似性高、类内变异性大、标注数据稀缺等挑战，现有注意力模型难以有效区分细微类别，导致诊断错误。

Method: 提出AGGRNet框架，通过提取信息性和非信息性特征来理解细粒度视觉模式，改进复杂医学图像分析任务的分类性能。

Result: 实验结果表明，该模型在多个医学影像数据集上达到最先进性能，在Kvasir数据集上比现有最佳模型提升高达5%。

Conclusion: AGGRNet框架能够有效解决医学图像分析中的复杂挑战，通过更好地理解细粒度视觉模式来提升分类准确性。

Abstract: Medical image analysis for complex tasks such as severity grading and disease subtype classification poses significant challenges due to intricate and similar visual patterns among classes, scarcity of labeled data, and variability in expert interpretations. Despite the usefulness of existing attention-based models in capturing complex visual patterns for medical image classification, underlying architectures often face challenges in effectively distinguishing subtle classes since they struggle to capture inter-class similarity and intra-class variability, resulting in incorrect diagnosis. To address this, we propose AGGRNet framework to extract informative and non-informative features to effectively understand fine-grained visual patterns and improve classification for complex medical image analysis tasks. Experimental results show that our model achieves state-of-the-art performance on various medical imaging datasets, with the best improvement up to 5% over SOTA models on the Kvasir dataset.

</details>


### [109] [Leveraging Quantum-Based Architectures for Robust Diagnostics](https://arxiv.org/abs/2511.12386)
*Shabnam Sodagari,Tommy Long*

Main category: cs.CV

TL;DR: 本研究提出了一种混合量子-经典框架，利用预训练的ResNet50编码器和量子卷积神经网络（QCNN）对肾脏CT图像进行肾结石、囊肿和肿瘤的诊断与分类。


<details>
  <summary>Details</summary>
Motivation: 旨在探索量子计算在医学影像诊断中的应用潜力，通过结合经典深度学习和量子计算技术来提高肾脏疾病诊断的准确性和性能。

Method: 采用预处理的肾脏CT图像，通过去噪和对比度增强技术进行特征提取。使用预训练的ResNet50编码器提取潜在特征，然后通过角度编码转换为量子比特，由QCNN进行处理。模型在8量子比特和12量子比特配置下进行评估。

Result: 两种架构均实现了快速收敛和稳定的学习曲线，测试准确率达到0.99。12量子比特配置在囊肿和肿瘤检测方面表现更优，囊肿召回率达到完美，肿瘤F1分数为0.9956。混淆矩阵分析显示所有类别分类可靠，误分类极少。

Conclusion: 结合经典预处理、深度特征提取和量子电路可以显著提升医学诊断性能，证明了量子-经典混合框架在医学影像分析中的有效性。

Abstract: The objective of this study is to diagnose and differentiate kidney stones, cysts, and tumors using Computed Tomography (CT) images of the kidney. This study leverages a hybrid quantum-classical framework in this regard. We combine a pretrained ResNet50 encoder, with a Quantum Convolutional Neural Network (QCNN) to explore quantum-assisted diagnosis. We pre-process the kidney images using denoising and contrast limited adaptive histogram equalization to enhance feature extraction. We address class imbalance through data augmentation and weighted sampling. Latent features extracted by the encoder are transformed into qubits via angle encoding and processed by a QCNN. The model is evaluated on both 8-qubit and 12-qubit configurations. Both architectures achieved rapid convergence with stable learning curves and high consistency between training and validation performance. The models reached a test accuracy of 0.99, with the 12-qubit configuration providing improvements in overall recall and precision, particularly for Cyst and Tumor detection, where it achieved perfect recall for Cysts and a tumor F1-score of 0.9956. Confusion matrix analysis further confirmed reliable classification behavior across all classes, with very few misclassifications. Results demonstrate that integrating classical pre-processing and deep feature extraction with quantum circuits enhances medical diagnostic performance.

</details>


### [110] [Calibrated Decomposition of Aleatoric and Epistemic Uncertainty in Deep Features for Inference-Time Adaptation](https://arxiv.org/abs/2511.12389)
*Divake Kumar,Patrick Poggi,Sina Tayebati,Devashri Naik,Nilesh Ahuja,Amit Ranjan Trivedi*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级的推理时间框架，通过解耦深度特征空间中的偶然不确定性和认知不确定性，实现不确定性引导的自适应模型选择，显著减少计算成本并保持精度。


<details>
  <summary>Details</summary>
Motivation: 大多数估计器将所有不确定性模式合并为单一置信度分数，无法可靠地判断何时需要分配更多计算资源或调整推理过程。

Method: 使用正则化全局密度模型估计偶然不确定性，通过三个互补组件（局部支持不足、流形谱崩溃和跨层特征不一致）形成认知不确定性，无需采样、集成或额外前向传播。

Result: 在MOT17数据集上，不确定性引导的自适应模型选择减少约60%的计算成本，精度损失可忽略；不确定性分解比总不确定性基线提高13.6个百分点的计算节省。

Conclusion: 该框架通过正交不确定性分解实现了实用的自调节视觉推理，显著提升了计算效率。

Abstract: Most estimators collapse all uncertainty modes into a single confidence score, preventing reliable reasoning about when to allocate more compute or adjust inference. We introduce Uncertainty-Guided Inference-Time Selection, a lightweight inference time framework that disentangles aleatoric (data-driven) and epistemic (model-driven) uncertainty directly in deep feature space. Aleatoric uncertainty is estimated using a regularized global density model, while epistemic uncertainty is formed from three complementary components that capture local support deficiency, manifold spectral collapse, and cross-layer feature inconsistency. These components are empirically orthogonal and require no sampling, no ensembling, and no additional forward passes. We integrate the decomposed uncertainty into a distribution free conformal calibration procedure that yields significantly tighter prediction intervals at matched coverage. Using these components for uncertainty guided adaptive model selection reduces compute by approximately 60 percent on MOT17 with negligible accuracy loss, enabling practical self regulating visual inference. Additionally, our ablation results show that the proposed orthogonal uncertainty decomposition consistently yields higher computational savings across all MOT17 sequences, improving margins by 13.6 percentage points over the total-uncertainty baseline.

</details>


### [111] [MSLoRA: Multi-Scale Low-Rank Adaptation via Attention Reweighting](https://arxiv.org/abs/2511.12400)
*Xu Yang,Gady Agam*

Main category: cs.CV

TL;DR: MSLoRA是一种与主干网络无关的参数高效适配器，通过重新加权特征响应而非重新调整主干网络，统一了CNN和ViT的适配方法，仅需不到5%的主干参数即可提升迁移性能。


<details>
  <summary>Details</summary>
Motivation: 现有的低秩适配方法主要局限于视觉Transformer，难以跨架构泛化，需要一种能够统一适配CNN和ViT的通用方法。

Method: 结合低秩线性投影和多尺度非线性变换，通过点乘和残差连接融合两个组件，联合调制空间和通道注意力，保持预训练权重冻结。

Result: 在分类、检测和分割任务上一致提升迁移性能，参数效率高（<5%主干参数），优化稳定，收敛快速，具有强跨架构泛化能力。

Conclusion: MSLoRA通过重新加权而非重新调整的方法，为冻结视觉主干网络的高效适配提供了一种简单通用的解决方案。

Abstract: We introduce MSLoRA, a backbone-agnostic, parameter-efficient adapter that reweights feature responses rather
  than re-tuning the underlying backbone. Existing low-rank adaptation methods are mostly confined to vision
  transformers (ViTs) and struggle to generalize across architectures. MSLoRA unifies adaptation for both convolutional neural networks (CNNs) and
  ViTs by combining a low-rank linear projection with a multi-scale nonlinear transformation that jointly
  modulates spatial and channel attention. The two components are fused through pointwise multiplication and
  a residual connection, yielding a lightweight module that shifts feature attention while keeping pretrained
  weights frozen.
  Extensive experiments demonstrate that MSLoRA consistently improves transfer performance on classification,
  detection, and segmentation tasks with roughly less than 5\% of backbone parameters.
  The design further enables stable optimization, fast convergence, and strong cross-architecture
  generalization. By reweighting rather than re-tuning, MSLoRA provides a simple and universal approach
  for efficient adaptation of frozen vision backbones.

</details>


### [112] [VLA-R: Vision-Language Action Retrieval toward Open-World End-to-End Autonomous Driving](https://arxiv.org/abs/2511.12405)
*Hyunki Seong,Seongwoo Moon,Hojin Ahn,Jehun Kang,David Hyunchul Shim*

Main category: cs.CV

TL;DR: VLA-R是一个开放世界端到端自动驾驶框架，通过结合开放世界感知和视觉-动作检索范式，在非结构化环境中实现强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 端到端自动驾驶在非结构化户外环境中常遇到训练时未见的条件，需要强大的泛化能力来处理开放世界场景。

Method: 使用冻结的视觉语言模型进行开放世界检测和分割，通过Q-Former瓶颈聚合视觉特征，并引入视觉-动作对比学习来对齐视觉语言和动作嵌入。

Result: 在真实机器人平台上，即使在有限数据情况下，在未见过的非结构化环境中也表现出强大的泛化和探索性能。

Conclusion: VLA-R框架通过视觉-动作检索范式有效解决了开放世界端到端自动驾驶的挑战，展示了在未知环境中的鲁棒性能。

Abstract: Exploring open-world situations in an end-to-end manner is a promising yet challenging task due to the need for strong generalization capabilities. In particular, end-to-end autonomous driving in unstructured outdoor environments often encounters conditions that were unfamiliar during training. In this work, we present Vision-Language Action Retrieval (VLA-R), an open-world end-to-end autonomous driving (OW-E2EAD) framework that integrates open-world perception with a novel vision-action retrieval paradigm. We leverage a frozen vision-language model for open-world detection and segmentation to obtain multi-scale, prompt-guided, and interpretable perception features without domain-specific tuning. A Q-Former bottleneck aggregates fine-grained visual representations with language-aligned visual features, bridging perception and action domains. To learn transferable driving behaviors, we introduce a vision-action contrastive learning scheme that aligns vision-language and action embeddings for effective open-world reasoning and action retrieval. Our experiments on a real-world robotic platform demonstrate strong generalization and exploratory performance in unstructured, unseen environments, even with limited data. Demo videos are provided in the supplementary material.

</details>


### [113] [Self-Supervised Visual Prompting for Cross-Domain Road Damage Detection](https://arxiv.org/abs/2511.12410)
*Xi Xiao,Zhuxuanzi Wang,Mingqiao Mo,Chen Liu,Chenrui Ma,Yanshu Li,Smita Krishnaswamy,Xiao Wang,Tianyang Wang*

Main category: cs.CV

TL;DR: PROBE是一个自监督框架，通过视觉探测目标域无需标签，使用SPEM模块从无标签数据生成缺陷感知提示来指导ViT骨干网络，通过DAPA目标对齐源域和目标域表示，在多个基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决自动化路面缺陷检测中跨域泛化能力差的问题，避免监督方法需要重新标注的高成本，同时克服标准自监督方法对域偏移的脆弱性。

Method: 提出PROBE框架，包含自监督提示增强模块（SPEM）从无标签目标数据生成缺陷感知提示，以及域感知提示对齐（DAPA）目标来对齐源域和目标域表示。

Result: 在四个挑战性基准测试中，PROBE一致优于强监督、自监督和适应基线方法，实现了稳健的零样本迁移、对域变化的改进鲁棒性，以及在少样本适应中的高数据效率。

Conclusion: 自监督提示是构建可扩展和自适应视觉检测系统的实用方向，PROBE展示了无需标签的跨域适应能力。

Abstract: The deployment of automated pavement defect detection is often hindered by poor cross-domain generalization. Supervised detectors achieve strong in-domain accuracy but require costly re-annotation for new environments, while standard self-supervised methods capture generic features and remain vulnerable to domain shift. We propose \ours, a self-supervised framework that \emph{visually probes} target domains without labels. \ours introduces a Self-supervised Prompt Enhancement Module (SPEM), which derives defect-aware prompts from unlabeled target data to guide a frozen ViT backbone, and a Domain-Aware Prompt Alignment (DAPA) objective, which aligns prompt-conditioned source and target representations. Experiments on four challenging benchmarks show that \ours consistently outperforms strong supervised, self-supervised, and adaptation baselines, achieving robust zero-shot transfer, improved resilience to domain variations, and high data efficiency in few-shot adaptation. These results highlight self-supervised prompting as a practical direction for building scalable and adaptive visual inspection systems. Source code is publicly available: https://github.com/xixiaouab/PROBE/tree/main

</details>


### [114] [Towards Rotation-only Imaging Geometry: Rotation Estimation](https://arxiv.org/abs/2511.12415)
*Xinrui Li,Qi Cai,Yuanxin Wu*

Main category: cs.CV

TL;DR: 提出了一种基于旋转流形的优化框架，将平移表示为旋转的函数，从而将成像几何表示压缩到旋转流形上，实现了仅通过旋转优化的SfM方法。


<details>
  <summary>Details</summary>
Motivation: 基于姿态成像几何的研究表明，通过姿态调整可以获得更好的SfM性能。本文继续从姿态视角出发，探索场景结构、旋转和平移之间的关键关系。

Method: 提出基于重投影误差的旋转优化框架，适用于两视图和多视图场景。通过将平移表示为旋转的函数，将成像几何表示压缩到旋转流形上进行优化。

Result: 实验结果表明，该方法在旋转估计精度和鲁棒性方面优于当前最先进的方法，甚至可与多次捆绑调整迭代结果相媲美。

Conclusion: 这项工作有望为更准确、高效和可靠的3D视觉计算做出贡献。

Abstract: Structure from Motion (SfM) is a critical task in computer vision, aiming to recover the 3D scene structure and camera motion from a sequence of 2D images. The recent pose-only imaging geometry decouples 3D coordinates from camera poses and demonstrates significantly better SfM performance through pose adjustment. Continuing the pose-only perspective, this paper explores the critical relationship between the scene structures, rotation and translation. Notably, the translation can be expressed in terms of rotation, allowing us to condense the imaging geometry representation onto the rotation manifold. A rotation-only optimization framework based on reprojection error is proposed for both two-view and multi-view scenarios. The experiment results demonstrate superior accuracy and robustness performance over the current state-of-the-art rotation estimation methods, even comparable to multiple bundle adjustment iteration results. Hopefully, this work contributes to even more accurate, efficient and reliable 3D visual computing.

</details>


### [115] [Seeing Through the Rain: Resolving High-Frequency Conflicts in Deraining and Super-Resolution via Diffusion Guidance](https://arxiv.org/abs/2511.12419)
*Wenjie Li,Jinglei Shi,Jin Han,Heng Guo,Zhanyu Ma*

Main category: cs.CV

TL;DR: DHGM模型通过结合预训练扩散先验和高通滤波器，同时去除雨纹伪影并增强结构细节，解决了天气恢复和超分辨率任务之间的冲突。


<details>
  <summary>Details</summary>
Motivation: 真实世界图像常因恶劣天气而退化，现有天气恢复方法可能牺牲高频细节，而简单级联恢复和超分辨率方法存在内在冲突：恢复旨在去除高频噪声，而超分辨率旨在从现有细节中生成高频纹理。

Method: 提出DHGM（基于扩散的高频引导模型），集成预训练扩散先验与高通滤波器，同时进行去雨和超分辨率处理。

Result: 大量实验表明DHGM在现有方法中取得优越性能，且成本更低。

Conclusion: DHGM能够有效生成干净的高分辨率图像，解决了天气恢复和超分辨率之间的不一致性问题。

Abstract: Clean images are crucial for visual tasks such as small object detection, especially at high resolutions. However, real-world images are often degraded by adverse weather, and weather restoration methods may sacrifice high-frequency details critical for analyzing small objects. A natural solution is to apply super-resolution (SR) after weather removal to recover both clarity and fine structures. However, simply cascading restoration and SR struggle to bridge their inherent conflict: removal aims to remove high-frequency weather-induced noise, while SR aims to hallucinate high-frequency textures from existing details, leading to inconsistent restoration contents. In this paper, we take deraining as a case study and propose DHGM, a Diffusion-based High-frequency Guided Model for generating clean and high-resolution images. DHGM integrates pre-trained diffusion priors with high-pass filters to simultaneously remove rain artifacts and enhance structural details. Extensive experiments demonstrate that DHGM achieves superior performance over existing methods, with lower costs.

</details>


### [116] [MFI-ResNet: Efficient ResNet Architecture Optimization via MeanFlow Compression and Selective Incubation](https://arxiv.org/abs/2511.12422)
*Nuolin Sun,Linyuan Wang,Haonan Wei,Lei Li,Bin Yan*

Main category: cs.CV

TL;DR: MFI-ResNet通过将ResNet的残差块替换为MeanFlow模块，采用压缩-扩展策略，在显著减少参数的同时提升分类准确率。


<details>
  <summary>Details</summary>
Motivation: 受ResNet与ODE的关联以及MeanFlow一步生成模型的启发，探索生成式流场如何有效表征ResNet特征变换过程，以提升参数效率和判别性能。

Method: 压缩阶段：将每个ResNet阶段的多层结构简化为1-2个MeanFlow模块构建轻量元模型；扩展阶段：对前三个阶段采用选择性孵化策略扩展至基线ResNet配置，最后一阶段保持MeanFlow形式，并进行微调。

Result: 在CIFAR-10和CIFAR-100上，相比ResNet-50参数量减少46.28%和45.59%，准确率分别提升0.23%和0.17%。

Conclusion: 生成式流场能有效表征ResNet特征变换过程，为理解生成式建模与判别式学习的关系提供了新视角。

Abstract: ResNet has achieved tremendous success in computer vision through its residual connection mechanism. ResNet can be viewed as a discretized form of ordinary differential equations (ODEs). From this perspective, the multiple residual blocks within a single ResNet stage essentially perform multi-step discrete iterations of the feature transformation for that stage. The recently proposed flow matching model, MeanFlow, enables one-step generative modeling by learning the mean velocity field to transform distributions. Inspired by this, we propose MeanFlow-Incubated ResNet (MFI-ResNet), which employs a compression-expansion strategy to jointly improve parameter efficiency and discriminative performance. In the compression phase, we simplify the multi-layer structure within each ResNet stage to one or two MeanFlow modules to construct a lightweight meta model. In the expansion phase, we apply a selective incubation strategy to the first three stages, expanding them to match the residual block configuration of the baseline ResNet model, while keeping the last stage in MeanFlow form, and fine-tune the incubated model. Experimental results show that on CIFAR-10 and CIFAR-100 datasets, MFI-ResNet achieves remarkable parameter efficiency, reducing parameters by 46.28% and 45.59% compared to ResNet-50, while still improving accuracy by 0.23% and 0.17%, respectively. This demonstrates that generative flow-fields can effectively characterize the feature transformation process in ResNet, providing a new perspective for understanding the relationship between generative modeling and discriminative learning.

</details>


### [117] [RedVTP: Training-Free Acceleration of Diffusion Vision-Language Models Inference via Masked Token-Guided Visual Token Pruning](https://arxiv.org/abs/2511.12428)
*Jingqi Xu,Jingxi Lu,Chenghao Li,Sreetama Sarkar,Souvik Kundu,Peter A. Beerel*

Main category: cs.CV

TL;DR: RedVTP是一种针对扩散视觉语言模型(DVLMs)的响应驱动视觉令牌剪枝策略，通过利用DVLMs的推理动态来估计视觉令牌重要性，并在第一步推理后剪枝不重要的视觉令牌，显著提升推理效率。


<details>
  <summary>Details</summary>
Motivation: 扩散视觉语言模型(DVLMs)虽然支持并行令牌解码，但大量视觉令牌严重影响了推理效率。虽然视觉令牌剪枝在自回归VLMs中已有研究，但在DVLMs中仍未被充分探索。

Method: RedVTP利用掩码响应令牌的注意力来估计视觉令牌重要性，基于重要性分数在不同步骤间保持一致的观察，在第一步推理后从掩码令牌中剪枝不重要的视觉令牌。

Result: 实验表明，RedVTP将LLaDA-V和LaViDa的令牌生成吞吐量分别提升至186%和28.05%，推理延迟分别降低64.97%和21.87%，且不损害甚至在某些情况下提高了准确性。

Conclusion: RedVTP是一种有效的DVLMs视觉令牌剪枝方法，能够在保持模型性能的同时显著提升推理效率。

Abstract: Vision-Language Models (VLMs) have achieved remarkable progress in multimodal reasoning and generation, yet their high computational demands remain a major challenge. Diffusion Vision-Language Models (DVLMs) are particularly attractive because they enable parallel token decoding, but the large number of visual tokens still significantly hinders their inference efficiency. While visual token pruning has been extensively studied for autoregressive VLMs (AVLMs), it remains largely unexplored for DVLMs. In this work, we propose RedVTP, a response-driven visual token pruning strategy that leverages the inference dynamics of DVLMs. Our method estimates visual token importance using attention from the masked response tokens. Based on the observation that these importance scores remain consistent across steps, RedVTP prunes the less important visual tokens from the masked tokens after the first inference step, thereby maximizing inference efficiency. Experiments show that RedVTP improves token generation throughput of LLaDA-V and LaViDa by up to 186% and 28.05%, respectively, and reduces inference latency by up to 64.97% and 21.87%, without compromising-and in some cases improving-accuracy.

</details>


### [118] [Text-Guided Channel Perturbation and Pretrained Knowledge Integration for Unified Multi-Modality Image Fusion](https://arxiv.org/abs/2511.12432)
*Xilai Li,Xiaosong Li,Weijun Jiang*

Main category: cs.CV

TL;DR: 本文提出了一种基于通道扰动和预训练知识集成的统一多模态图像融合框架(UP-Fusion)，通过语义感知通道剪枝、几何仿射调制和文本引导通道扰动等模块，解决了多模态融合中的梯度冲突和泛化性问题。


<details>
  <summary>Details</summary>
Motivation: 现有统一模型在多模态图像融合中面临模态差异导致的梯度冲突问题，而引入模态特定编码器的方法又降低了跨不同融合任务的泛化能力。

Method: 提出UP-Fusion框架，包含三个核心模块：语义感知通道剪枝模块(SCPM)利用预训练模型的语义感知能力过滤和增强多模态特征通道；几何仿射调制模块(GAM)使用原始模态特征对初始融合特征进行仿射变换；文本引导通道扰动模块(TCPM)在解码过程中重塑通道分布。

Result: 大量实验表明，该算法在多模态图像融合和下游任务上都优于现有方法。

Conclusion: UP-Fusion框架通过有效的通道处理和知识集成，成功提升了多模态图像融合的性能和泛化能力。

Abstract: Multi-modality image fusion enhances scene perception by combining complementary information. Unified models aim to share parameters across modalities for multi-modality image fusion, but large modality differences often cause gradient conflicts, limiting performance. Some methods introduce modality-specific encoders to enhance feature perception and improve fusion quality. However, this strategy reduces generalisation across different fusion tasks. To overcome this limitation, we propose a unified multi-modality image fusion framework based on channel perturbation and pre-trained knowledge integration (UP-Fusion). To suppress redundant modal information and emphasize key features, we propose the Semantic-Aware Channel Pruning Module (SCPM), which leverages the semantic perception capability of a pre-trained model to filter and enhance multi-modality feature channels. Furthermore, we proposed the Geometric Affine Modulation Module (GAM), which uses original modal features to apply affine transformations on initial fusion features to maintain the feature encoder modal discriminability. Finally, we apply a Text-Guided Channel Perturbation Module (TCPM) during decoding to reshape the channel distribution, reducing the dependence on modality-specific channels. Extensive experiments demonstrate that the proposed algorithm outperforms existing methods on both multi-modality image fusion and downstream tasks.

</details>


### [119] [Real-Time Drivers' Drowsiness Detection and Analysis through Deep Learning](https://arxiv.org/abs/2511.12438)
*ANK Zaman,Prosenjit Chatterjee,Rajat Sharma*

Main category: cs.CV

TL;DR: 本文开发了一种基于深度卷积神经网络和OpenCV的实时驾驶员疲劳检测系统，通过分析面部特征（如眼睛开合和打哈欠动作）来识别疲劳状态，并在检测到疲劳时发出警报。


<details>
  <summary>Details</summary>
Motivation: 长途驾驶容易导致驾驶员疲劳，疲劳驾驶对驾驶员本人和其他道路使用者的安全构成严重威胁，因此需要一种实时检测系统来预防事故。

Method: 使用实时摄像头捕捉驾驶员面部图像，通过OpenCV分析面部特征（眼睛开合度和打哈欠动作），利用预训练的深度卷积神经网络模型进行疲劳状态分类。

Result: 在NTHU-DDD数据集和Yawn-Eye-Dataset上的疲劳检测分类准确率分别达到99.6%和97%。

Conclusion: 该方法提供了一种非侵入式、低成本且高效的疲劳检测方案，有助于预防道路交通事故，保护生命安全。

Abstract: A long road trip is fun for drivers. However, a long drive for days can be tedious for a driver to accommodate stringent deadlines to reach distant destinations. Such a scenario forces drivers to drive extra miles, utilizing extra hours daily without sufficient rest and breaks. Once a driver undergoes such a scenario, it occasionally triggers drowsiness during driving. Drowsiness in driving can be life-threatening to any individual and can affect other drivers' safety; therefore, a real-time detection system is needed. To identify fatigued facial characteristics in drivers and trigger the alarm immediately, this research develops a real-time driver drowsiness detection system utilizing deep convolutional neural networks (DCNNs) and OpenCV.Our proposed and implemented model takes real- time facial images of a driver using a live camera and utilizes a Python-based library named OpenCV to examine the facial images for facial landmarks like sufficient eye openings and yawn-like mouth movements. The DCNNs framework then gathers the data and utilizes a per-trained model to detect the drowsiness of a driver using facial landmarks. If the driver is identified as drowsy, the system issues a continuous alert in real time, embedded in the Smart Car technology.By potentially saving innocent lives on the roadways, the proposed technique offers a non-invasive, inexpensive, and cost-effective way to identify drowsiness. Our proposed and implemented DCNNs embedded drowsiness detection model successfully react with NTHU-DDD dataset and Yawn-Eye-Dataset with drowsiness detection classification accuracy of 99.6% and 97% respectively.

</details>


### [120] [CoTBox-TTT: Grounding Medical VQA with Visual Chain-of-Thought Boxes During Test-time Training](https://arxiv.org/abs/2511.12446)
*Jiahe Qian,Yuhao Shen,Zhangtianyi Chen,Juexiao Zhou,Peisong Wang*

Main category: cs.CV

TL;DR: CoTBox-TTT是一种测试时训练方法，通过视觉思维链信号识别问题相关区域，并保持答案在原始图像和局部裁剪中的一致性，无需额外标签即可提升医学VQA模型的领域适应性和证据基础。


<details>
  <summary>Details</summary>
Motivation: 当前医学视觉问答系统在领域偏移下可靠性不足，产生的答案缺乏图像证据支持，且在实际部署时重新训练或添加标签不切实际。

Method: 采用证据优先的测试时训练方法，在推理时仅更新少量连续软提示，通过视觉思维链识别问题相关区域，并确保原始图像与局部裁剪的答案一致性，所有骨干网络保持冻结。

Result: 在医学VQA任务中，该方法显著提升性能，例如在LLaVA模型上加入CoTBox-TTT后，在pathVQA数据集上的闭式问题准确率提高了12.3%。

Conclusion: CoTBox-TTT是一种实用且无需标签的即插即用方法，能够有效增强医学VQA模型在真实部署中的可靠性和证据基础。

Abstract: Medical visual question answering could support clinical decision making, yet current systems often fail under domain shift and produce answers that are weakly grounded in image evidence. This reliability gap arises when models attend to spurious regions and when retraining or additional labels are impractical at deployment time. We address this setting with CoTBox-TTT, an evidence-first test-time training approach that adapts a vision-language model at inference while keeping all backbones frozen. The method updates only a small set of continuous soft prompts. It identifies question-relevant regions through a visual chain-of-thought signal and encourages answer consistency across the original image and a localized crop. The procedure is label free, and plug and play with diverse backbones. Experiments on medical VQA show that the approach is practical for real deployments. For instance, adding CoTBox-TTT to LLaVA increases closed-ended accuracy by 12.3% on pathVQA.

</details>


### [121] [MOON2.0: Dynamic Modality-balanced Multimodal Representation Learning for E-commerce Product Understanding](https://arxiv.org/abs/2511.12449)
*Zhanheng Nie,Chenghan Fu,Daoze Zhang,Junxian Wu,Wanxian Guan,Pengjie Wang,Jian Xu,Bo Zheng*

Main category: cs.CV

TL;DR: MOON2.0是一个动态模态平衡的多模态表示学习框架，用于解决电子商务产品理解中的模态不平衡、语义对齐关系利用不足和数据噪声问题。


<details>
  <summary>Details</summary>
Motivation: 现有电子商务多模态大语言模型面临三个挑战：模态混合训练导致的模态不平衡、产品内视觉和文本信息内在对齐关系利用不足，以及电子商务多模态数据噪声处理能力有限。

Method: 提出MOON2.0框架，包含：(1)模态驱动的专家混合模块，根据模态组成自适应处理输入样本；(2)双级对齐方法，更好利用产品内语义对齐特性；(3)基于MLLM的图像-文本协同增强策略，结合动态样本过滤提升训练数据质量。

Result: 实验表明MOON2.0在MBE2.0基准和多个公共数据集上实现了最先进的零样本性能，注意力热图可视化提供了改进多模态对齐的定性证据。

Conclusion: MOON2.0通过动态模态平衡和协同增强策略，有效提升了电子商务产品多模态理解能力，为解决模态不平衡和噪声问题提供了有效解决方案。

Abstract: The rapid growth of e-commerce calls for multimodal models that comprehend rich visual and textual product information. Although recent multimodal large language models (MLLMs) for product understanding exhibit strong capability in representation learning for e-commerce, they still face three challenges: (i) the modality imbalance induced by modality mixed training; (ii) underutilization of the intrinsic alignment relationships among visual and textual information within a product; and (iii) limited handling of noise in e-commerce multimodal data. To address these, we propose MOON2.0, a dynamic modality-balanced multimodal representation learning framework for e-commerce product understanding. MOON2.0 comprises: (1) a Modality-driven Mixture-of-Experts (MoE) module that adaptively processes input samples by their modality composition, enabling Multimodal Joint Learning to mitigate the modality imbalance; (2) a Dual-level Alignment method to better leverage semantic alignment properties inside individual products; and (3) an MLLM-based Image-text Co-augmentation strategy that integrates textual enrichment with visual expansion, coupled with Dynamic Sample Filtering to improve training data quality. We further introduce MBE2.0, a co-augmented multimodal representation benchmark for e-commerce representation learning and evaluation. Experiments show that MOON2.0 delivers state-of-the-art zero-shot performance on MBE2.0 and multiple public datasets. Furthermore, attention-based heatmap visualization provides qualitative evidence of improved multimodal alignment of MOON2.0.

</details>


### [122] [DenseAnnotate: Enabling Scalable Dense Caption Collection for Images and 3D Scenes via Spoken Descriptions](https://arxiv.org/abs/2511.12452)
*Xiaoyu Lin,Aniket Ghorpade,Hansheng Zhu,Justin Qiu,Dea Rrozhani,Monica Lama,Mick Yang,Zixuan Bian,Ruohan Ren,Alan B. Hong,Jiatao Gu,Chris Callison-Burch*

Main category: cs.CV

TL;DR: DenseAnnotate是一个音频驱动的在线标注平台，通过语音注释实现图像和3D资源的密集细粒度标注，解决了传统文本标注的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型的训练数据存在标注稀疏问题，传统文本标注方法表达能力有限、速度慢，难以捕捉图像的视觉细节，特别是在多元文化图像和3D资源标注等专业领域。

Method: 开发了DenseAnnotate平台，采用音频驱动标注方式，标注者通过语音描述观察内容，同时将语音短语与图像区域或3D场景部分同步关联，结合语音转文本和注意力区域标记技术。

Result: 通过1000多名标注者的案例研究，构建了包含3,531张图像、898个3D场景和7,460个3D对象的多模态数据集，模型训练后在多语言能力提升5%、文化对齐提升47%、3D空间能力提升54%。

Conclusion: 该平台为未来视觉语言研究提供了可行的密集标注方法，可应用于各种任务和数据类型，解决了高质量训练数据稀缺的问题。

Abstract: With the rapid adoption of multimodal large language models (MLLMs) across diverse applications, there is a pressing need for task-centered, high-quality training data. A key limitation of current training datasets is their reliance on sparse annotations mined from the Internet or entered via manual typing that capture only a fraction of an image's visual content. Dense annotations are more valuable but remain scarce. Traditional text-based annotation pipelines are poorly suited for creating dense annotations: typing limits expressiveness, slows annotation speed, and underrepresents nuanced visual features, especially in specialized areas such as multicultural imagery and 3D asset annotation. In this paper, we present DenseAnnotate, an audio-driven online annotation platform that enables efficient creation of dense, fine-grained annotations for images and 3D assets. Annotators narrate observations aloud while synchronously linking spoken phrases to image regions or 3D scene parts. Our platform incorporates speech-to-text transcription and region-of-attention marking. To demonstrate the effectiveness of DenseAnnotate, we conducted case studies involving over 1,000 annotators across two domains: culturally diverse images and 3D scenes. We curate a human-annotated multi-modal dataset of 3,531 images, 898 3D scenes, and 7,460 3D objects, with audio-aligned dense annotations in 20 languages, including 8,746 image captions, 2,000 scene captions, and 19,000 object captions. Models trained on this dataset exhibit improvements of 5% in multilingual, 47% in cultural alignment, and 54% in 3D spatial capabilities. Our results show that our platform offers a feasible approach for future vision-language research and can be applied to various tasks and diverse types of data.

</details>


### [123] [Co-Layout: LLM-driven Co-optimization for Interior Layout](https://arxiv.org/abs/2511.12474)
*Chucheng Xiang,Ruchao Bao,Biyin Feng,Wenzheng Wu,Zhongyuan Liu,Yirui Guan,Ligang Liu*

Main category: cs.CV

TL;DR: 提出了结合大语言模型和网格整数规划的自动化室内设计框架，通过联合优化房间布局和家具摆放，显著优于现有两阶段设计方法


<details>
  <summary>Details</summary>
Motivation: 解决现有自动化室内设计方法通常采用两阶段流程（先布局后家具摆放）导致的次优解问题，需要更高效的联合优化方法

Method: 使用LLM从文本提示提取结构化设计约束，编码到基于Modulor启发的网格表示中，采用粗到细的优化策略，先低分辨率求解简化问题再指导全分辨率优化

Result: 在多样化场景下的实验表明，该方法在解决方案质量上显著优于现有两阶段设计流程，并通过粗到细策略实现了显著的计算效率提升

Conclusion: 该联合优化框架为自动化室内设计提供了更高效和优质的解决方案，证明了LLM与数学规划结合在空间设计任务中的有效性

Abstract: We present a novel framework for automated interior design that combines large language models (LLMs) with grid-based integer programming to jointly optimize room layout and furniture placement. Given a textual prompt, the LLM-driven agent workflow extracts structured design constraints related to room configurations and furniture arrangements. These constraints are encoded into a unified grid-based representation inspired by ``Modulor". Our formulation accounts for key design requirements, including corridor connectivity, room accessibility, spatial exclusivity, and user-specified preferences. To improve computational efficiency, we adopt a coarse-to-fine optimization strategy that begins with a low-resolution grid to solve a simplified problem and guides the solution at the full resolution. Experimental results across diverse scenarios demonstrate that our joint optimization approach significantly outperforms existing two-stage design pipelines in solution quality, and achieves notable computational efficiency through the coarse-to-fine strategy.

</details>


### [124] [MaskAnyNet: Rethinking Masked Image Regions as Valuable Information in Supervised Learning](https://arxiv.org/abs/2511.12480)
*Jingshan Hong,Haigen Hu,Huihuang Zhang,Qianwei Zhou,Zhao Li*

Main category: cs.CV

TL;DR: 本文提出MaskAnyNet方法，通过重新利用被掩码区域的语义多样性来增强特征学习，解决了传统图像掩码中像素信息浪费和关键特征丢失的问题。


<details>
  <summary>Details</summary>
Motivation: 传统图像掩码存在两个关键问题：被丢弃的像素未被充分利用导致上下文信息丢失；掩码可能移除小尺寸或关键特征，特别是在细粒度任务中。掩码图像建模表明即使不完整数据也能展现强上下文一致性，揭示了掩码区域作为语义多样性来源的潜力。

Method: 提出MaskAnyNet方法，将掩码内容视为辅助知识而非忽略部分。该方法结合掩码和重新学习机制，利用可见和掩码信息。可轻松扩展到任何模型，通过额外分支联合学习重新组合的掩码区域。

Result: 在CNN和Transformer骨干网络上的实验显示，在多个基准测试中都获得了稳定的性能提升。进一步分析证实该方法通过重用掩码内容提高了语义多样性。

Conclusion: 将掩码区域重新利用为辅助知识源能够有效丰富特征表示并保留细粒度细节，为图像掩码方法提供了新的视角。

Abstract: In supervised learning, traditional image masking faces two key issues: (i) discarded pixels are underutilized, leading to a loss of valuable contextual information; (ii) masking may remove small or critical features, especially in fine-grained tasks. In contrast, masked image modeling (MIM) has demonstrated that masked regions can be reconstructed from partial input, revealing that even incomplete data can exhibit strong contextual consistency with the original image. This highlights the potential of masked regions as sources of semantic diversity. Motivated by this, we revisit the image masking approach, proposing to treat masked content as auxiliary knowledge rather than ignored. Based on this, we propose MaskAnyNet, which combines masking with a relearning mechanism to exploit both visible and masked information. It can be easily extended to any model with an additional branch to jointly learn from the recomposed masked region. This approach leverages the semantic diversity of the masked regions to enrich features and preserve fine-grained details. Experiments on CNN and Transformer backbones show consistent gains across multiple benchmarks. Further analysis confirms that the proposed method improves semantic diversity through the reuse of masked content.

</details>


### [125] [Towards Temporal Fusion Beyond the Field of View for Camera-based Semantic Scene Completion](https://arxiv.org/abs/2511.12498)
*Jongseong Bae,Junwoo Ha,Jinnyeong Heo,Yeongin Lee,Ha Young Kim*

Main category: cs.CV

TL;DR: 本文提出了C3DFusion模块，通过显式对齐当前帧和历史帧的3D特征来解决相机基3D语义场景补全中侧向视野外区域重建困难的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于相机的3D语义场景补全方法主要关注增强帧内区域特征，但对车辆侧向视野外关键区域的重建效果不佳，尽管历史帧通常包含这些不可见区域的宝贵上下文信息。

Method: 提出Current-Centric Contextual 3D Fusion模块，通过历史上下文模糊化和当前中心特征密集化两种互补技术，抑制错误扭曲历史点特征的噪声，同时增强当前点特征的体积贡献。

Result: 在SemanticKITTI和SSCBench-KITTI-360数据集上显著优于现有最优方法，并在其他基线模型上展现出强大的泛化能力。

Conclusion: C3DFusion模块能有效利用历史帧信息改善视野外区域重建，简单集成到标准SSC架构中即可带来显著性能提升。

Abstract: Recent camera-based 3D semantic scene completion (SSC) methods have increasingly explored leveraging temporal cues to enrich the features of the current frame. However, while these approaches primarily focus on enhancing in-frame regions, they often struggle to reconstruct critical out-of-frame areas near the sides of the ego-vehicle, although previous frames commonly contain valuable contextual information about these unseen regions. To address this limitation, we propose the Current-Centric Contextual 3D Fusion (C3DFusion) module, which generates hidden region-aware 3D feature geometry by explicitly aligning 3D-lifted point features from both current and historical frames. C3DFusion performs enhanced temporal fusion through two complementary techniques-historical context blurring and current-centric feature densification-which suppress noise from inaccurately warped historical point features by attenuating their scale, and enhance current point features by increasing their volumetric contribution. Simply integrated into standard SSC architectures, C3DFusion demonstrates strong effectiveness, significantly outperforming state-of-the-art methods on the SemanticKITTI and SSCBench-KITTI-360 datasets. Furthermore, it exhibits robust generalization, achieving notable performance gains when applied to other baseline models.

</details>


### [126] [Visible Structure Retrieval for Lightweight Image-Based Relocalisation](https://arxiv.org/abs/2511.12503)
*Fereidoon Zangeneh,Leonard Bruns,Amit Dekel,Alessandro Pieropan,Patric Jensfelt*

Main category: cs.CV

TL;DR: 本文提出了一种新的相机姿态估计方法，通过神经网络直接学习从图像到可见场景结构的映射，避免了传统的图像检索或搜索启发式方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于结构的相机重定位方法在大规模场景中需要复杂的搜索启发式或图像检索，导致计算和存储需求随观测数量增长。

Method: 提出可见结构检索网络，通过神经网络前向传播直接从查询图像中获取可见的3D结构点子集，减少2D-3D对应关系的搜索空间。

Result: 该方法在定位精度上达到state-of-the-art水平，同时显著降低了计算和存储需求。

Conclusion: 所提出的新范式使得基于结构的重定位更加高效，为大规模场景定位提供了更紧凑的解决方案。

Abstract: Accurate camera pose estimation from an image observation in a previously mapped environment is commonly done through structure-based methods: by finding correspondences between 2D keypoints on the image and 3D structure points in the map. In order to make this correspondence search tractable in large scenes, existing pipelines either rely on search heuristics, or perform image retrieval to reduce the search space by comparing the current image to a database of past observations. However, these approaches result in elaborate pipelines or storage requirements that grow with the number of past observations. In this work, we propose a new paradigm for making structure-based relocalisation tractable. Instead of relying on image retrieval or search heuristics, we learn a direct mapping from image observations to the visible scene structure in a compact neural network. Given a query image, a forward pass through our novel visible structure retrieval network allows obtaining the subset of 3D structure points in the map that the image views, thus reducing the search space of 2D-3D correspondences. We show that our proposed method enables performing localisation with an accuracy comparable to the state of the art, while requiring lower computational and storage footprint.

</details>


### [127] [DINO-Detect: A Simple yet Effective Framework for Blur-Robust AI-Generated Image Detection](https://arxiv.org/abs/2511.12511)
*Jialiang Shen,Jiyang Zheng,Yunqi Xue,Huajie Chen,Yu Yao,Hui Kang,Ruiqi Liu,Helin Gong,Yang Yang,Dadong Wang,Tongliang Liu*

Main category: cs.CV

TL;DR: 本文提出了一种基于师生知识蒸馏的模糊鲁棒AI生成图像检测框架，通过冻结在清晰图像上训练的教师模型（DINOv3）来指导学生模型学习模糊图像的一致表示，显著提升了在运动模糊条件下的检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有的AI生成图像检测器在真实世界退化（特别是运动模糊）下性能严重下降，因为模糊会扭曲精细纹理并抑制高频伪影，限制了实际应用。

Method: 采用师生知识蒸馏框架：1）使用在清晰图像上训练的DINOv3教师模型提供稳定且语义丰富的表示；2）冻结教师模型以保持其泛化能力；3）将教师的特征和logit响应从清晰图像蒸馏到在模糊图像上训练的学生模型。

Result: 在多个基准测试上的广泛实验表明，该方法在运动模糊和清晰条件下都达到了最先进的性能，表现出更好的泛化能力和实际应用价值。

Conclusion: 提出的模糊鲁棒检测框架有效解决了运动模糊对AI生成图像检测的挑战，为真实世界场景中的图像真实性验证提供了实用解决方案。

Abstract: With growing concerns over image authenticity and digital safety, the field of AI-generated image (AIGI) detection has progressed rapidly. Yet, most AIGI detectors still struggle under real-world degradations, particularly motion blur, which frequently occurs in handheld photography, fast motion, and compressed video. Such blur distorts fine textures and suppresses high-frequency artifacts, causing severe performance drops in real-world settings. We address this limitation with a blur-robust AIGI detection framework based on teacher-student knowledge distillation. A high-capacity teacher (DINOv3), trained on clean (i.e., sharp) images, provides stable and semantically rich representations that serve as a reference for learning. By freezing the teacher to maintain its generalization ability, we distill its feature and logit responses from sharp images to a student trained on blurred counterparts, enabling the student to produce consistent representations under motion degradation. Extensive experiments benchmarks show that our method achieves state-of-the-art performance under both motion-blurred and clean conditions, demonstrating improved generalization and real-world applicability. Source codes will be released at: https://github.com/JiaLiangShen/Dino-Detect-for-blur-robust-AIGC-Detection.

</details>


### [128] [MdaIF: Robust One-Stop Multi-Degradation-Aware Image Fusion with Language-Driven Semantics](https://arxiv.org/abs/2511.12525)
*Jing Li,Yifan Wang,Jiafeng Yan,Renlong Zhang,Bin Yang*

Main category: cs.CV

TL;DR: 提出了一种基于大语言模型的退化感知图像融合框架MdaIF，用于解决多退化场景下的红外与可见光图像融合问题，通过混合专家系统和语义先验指导实现鲁棒融合。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在两个问题：1) 未考虑恶劣天气条件下可见光图像的退化，影响融合性能；2) 依赖固定网络架构，难以适应多样化退化场景。

Method: 1) 引入混合专家系统处理多退化场景；2) 使用预训练视觉语言模型提取语义先验；3) 提出退化感知通道注意力模块进行多模态特征交互；4) 利用语义先验和通道调制特征指导专家路由。

Result: 大量实验验证了MdaIF的有效性，在复杂退化场景下表现出优于现有最先进方法的性能。

Conclusion: 该框架能够有效解决多退化场景下的图像融合问题，通过语义先验指导和自适应网络架构实现了鲁棒的融合性能。

Abstract: Infrared and visible image fusion aims to integrate complementary multi-modal information into a single fused result. However, existing methods 1) fail to account for the degradation visible images under adverse weather conditions, thereby compromising fusion performance; and 2) rely on fixed network architectures, limiting their adaptability to diverse degradation scenarios. To address these issues, we propose a one-stop degradation-aware image fusion framework for multi-degradation scenarios driven by a large language model (MdaIF). Given the distinct scattering characteristics of different degradation scenarios (e.g., haze, rain, and snow) in atmospheric transmission, a mixture-of-experts (MoE) system is introduced to tackle image fusion across multiple degradation scenarios. To adaptively extract diverse weather-aware degradation knowledge and scene feature representations, collectively referred to as the semantic prior, we employ a pre-trained vision-language model (VLM) in our framework. Guided by the semantic prior, we propose degradation-aware channel attention module (DCAM), which employ degradation prototype decomposition to facilitate multi-modal feature interaction in channel domain. In addition, to achieve effective expert routing, the semantic prior and channel-domain modulated features are utilized to guide the MoE, enabling robust image fusion in complex degradation scenarios. Extensive experiments validate the effectiveness of our MdaIF, demonstrating superior performance over SOTA methods.

</details>


### [129] [D$^{2}$-VPR: A Parameter-efficient Visual-foundation-model-based Visual Place Recognition Method via Knowledge Distillation and Deformable Aggregation](https://arxiv.org/abs/2511.12528)
*Zheyuan Zhang,Jiwei Zhang,Boyu Zhou,Linzhimeng Duan,Hong Chen*

Main category: cs.CV

TL;DR: D²-VPR是一个基于蒸馏和可变形聚合的视觉地点识别框架，在保持视觉基础模型强大特征提取能力的同时，显著减少了模型参数和计算开销。


<details>
  <summary>Details</summary>
Motivation: 解决DINOv2等视觉基础模型在VPR任务中虽然性能优秀但模型复杂、计算开销大，难以在资源受限设备上部署的问题。

Method: 采用两阶段训练策略（知识蒸馏+微调），引入蒸馏恢复模块(DRM)减少知识转移损失，设计基于自上而下注意力的可变形聚合器(TDDA)动态调整感兴趣区域。

Result: 在保持竞争力的性能同时，参数减少约64.2%，FLOPs减少约62.6%（相比CricaVPR）。

Conclusion: D²-VPR在性能和效率之间取得了更好的平衡，为资源受限环境下的视觉地点识别提供了实用解决方案。

Abstract: Visual Place Recognition (VPR) aims to determine the geographic location of a query image by retrieving its most visually similar counterpart from a geo-tagged reference database. Recently, the emergence of the powerful visual foundation model, DINOv2, trained in a self-supervised manner on massive datasets, has significantly improved VPR performance. This improvement stems from DINOv2's exceptional feature generalization capabilities but is often accompanied by increased model complexity and computational overhead that impede deployment on resource-constrained devices. To address this challenge, we propose $D^{2}$-VPR, a $D$istillation- and $D$eformable-based framework that retains the strong feature extraction capabilities of visual foundation models while significantly reducing model parameters and achieving a more favorable performance-efficiency trade-off. Specifically, first, we employ a two-stage training strategy that integrates knowledge distillation and fine-tuning. Additionally, we introduce a Distillation Recovery Module (DRM) to better align the feature spaces between the teacher and student models, thereby minimizing knowledge transfer losses to the greatest extent possible. Second, we design a Top-Down-attention-based Deformable Aggregator (TDDA) that leverages global semantic features to dynamically and adaptively adjust the Regions of Interest (ROI) used for aggregation, thereby improving adaptability to irregular structures. Extensive experiments demonstrate that our method achieves competitive performance compared to state-of-the-art approaches. Meanwhile, it reduces the parameter count by approximately 64.2% and FLOPs by about 62.6% (compared to CricaVPR).Code is available at https://github.com/tony19980810/D2VPR.

</details>


### [130] [ReaSon: Reinforced Causal Search with Information Bottleneck for Video Understanding](https://arxiv.org/abs/2511.12530)
*Yuan Zhou,Litao Hua,Shilong Jin,Wentao Huang,Haoran Duan*

Main category: cs.CV

TL;DR: ReaSon是一个基于强化学习的因果信息瓶颈框架，用于视频理解中的关键帧选择，通过优化预测充分性和因果必要性来选择最具信息量的关键帧。


<details>
  <summary>Details</summary>
Motivation: 由于视觉语言模型的输入token有限，且视频帧中相关信息存在时间稀疏性，需要选择既信息丰富又具有因果决定性的关键帧来提高视频理解效率。

Method: 提出Reinforced Causal Search with Information Bottleneck框架，使用可学习的策略网络从候选帧中选择关键帧，通过因果信息瓶颈定义预测充分性，并通过反事实干预评估因果必要性，最后设计复合奖励函数指导强化学习。

Result: 在NExT-QA、EgoSchema和Video-MME数据集上的实验表明，ReaSon在有限帧设置下始终优于现有最先进方法。

Conclusion: ReaSon框架通过因果信息瓶颈原理有效解决了关键帧选择问题，具有良好的有效性和泛化能力。

Abstract: Keyframe selection has become essential for video understanding with vision-language models (VLMs) due to limited input tokens and the temporal sparsity of relevant information across video frames. Video understanding often relies on effective keyframes that are not only informative but also causally decisive. To this end, we propose Reinforced Causal Search with Information Bottleneck (ReaSon), a framework that formulates keyframe selection as an optimization problem with the help of a novel Causal Information Bottleneck (CIB), which explicitly defines keyframes as those satisfying both predictive sufficiency and causal necessity. Specifically, ReaSon employs a learnable policy network to select keyframes from a visually relevant pool of candidate frames to capture predictive sufficiency, and then assesses causal necessity via counterfactual interventions. Finally, a composite reward aligned with the CIB principle is designed to guide the selection policy through reinforcement learning. Extensive experiments on NExT-QA, EgoSchema, and Video-MME demonstrate that ReaSon consistently outperforms existing state-of-the-art methods under limited-frame settings, validating its effectiveness and generalization ability.

</details>


### [131] [HiGFA: Hierarchical Guidance for Fine-grained Data Augmentation with Diffusion Models](https://arxiv.org/abs/2511.12547)
*Zhiguang Lu,Qianqian Xu,Peisong Wen,Siran Da,Qingming Huang*

Main category: cs.CV

TL;DR: HiGFA方法通过分层引导策略解决扩散模型在细粒度任务中的数据增强问题，利用早期强引导建立整体结构，后期基于置信度动态调整细粒度分类器引导，生成更准确可靠的合成图像。


<details>
  <summary>Details</summary>
Motivation: 标准文本引导方法在细粒度任务中缺乏特异性，可能生成误导性样本，导致细粒度分类器性能下降。需要确保合成图像准确捕捉类别定义的细微特征。

Method: 提出HiGFA方法：早期阶段使用强文本和轮廓引导建立场景、风格和结构；后期阶段激活细粒度分类器引导，并基于预测置信度动态调制所有引导信号的强度。

Result: 在多个细粒度视觉分类数据集上的实验证明了HiGFA的有效性，能够生成多样且忠实于原始类别的合成图像。

Conclusion: HiGFA通过分层、置信度驱动的引导策略，成功平衡了全局结构形成和细节精炼，显著提升了细粒度任务中扩散模型数据增强的质量。

Abstract: Generative diffusion models show promise for data augmentation. However, applying them to fine-grained tasks presents a significant challenge: ensuring synthetic images accurately capture the subtle, category-defining features critical for high fidelity. Standard approaches, such as text-based Classifier-Free Guidance (CFG), often lack the required specificity, potentially generating misleading examples that degrade fine-grained classifier performance. To address this, we propose Hierarchically Guided Fine-grained Augmentation (HiGFA). HiGFA leverages the temporal dynamics of the diffusion sampling process. It employs strong text and transformed contour guidance with fixed strengths in the early-to-mid sampling stages to establish overall scene, style, and structure. In the final sampling stages, HiGFA activates a specialized fine-grained classifier guidance and dynamically modulates the strength of all guidance signals based on prediction confidence. This hierarchical, confidence-driven orchestration enables HiGFA to generate diverse yet faithful synthetic images by intelligently balancing global structure formation with precise detail refinement. Experiments on several FGVC datasets demonstrate the effectiveness of HiGFA.

</details>


### [132] [EmoVerse: A MLLMs-Driven Emotion Representation Dataset for Interpretable Visual Emotion Analysis](https://arxiv.org/abs/2511.12554)
*Yijie Guo,Dexiang Hong,Weidong Chen,Zihan She,Cheng Ye,Xiaojun Chang,Zhendong Mao*

Main category: cs.CV

TL;DR: EmoVerse是一个大规模开源数据集，通过多层次的、知识图谱启发的注释实现可解释的视觉情感分析，将情感分解为背景-属性-主体三元组，并包含双注释系统。


<details>
  <summary>Details</summary>
Motivation: 解决视觉情感分析领域因缺乏开源和可解释数据集而进展有限的问题，现有研究通常只给整张图片分配单一离散情感标签，无法揭示视觉元素如何贡献于情感。

Method: 提出EmoVerse数据集，包含219k+图像，采用背景-属性-主体三元组分解情感，通过多阶段标注流程确保高可靠性，并开发可解释模型将视觉线索映射到维度情感空间。

Result: 构建了包含双注释系统（分类情感状态和维度情感空间）的大规模数据集，提供了词语级和主体级的情感推理能力。

Conclusion: EmoVerse数据集、标注流程和模型共同构成了推进可解释高级情感理解的综合基础。

Abstract: Visual Emotion Analysis (VEA) aims to bridge the affective gap between visual content and human emotional responses. Despite its promise, progress in this field remains limited by the lack of open-source and interpretable datasets. Most existing studies assign a single discrete emotion label to an entire image, offering limited insight into how visual elements contribute to emotion. In this work, we introduce EmoVerse, a large-scale open-source dataset that enables interpretable visual emotion analysis through multi-layered, knowledge-graph-inspired annotations. By decomposing emotions into Background-Attribute-Subject (B-A-S) triplets and grounding each element to visual regions, EmoVerse provides word-level and subject-level emotional reasoning. With over 219k images, the dataset further includes dual annotations in Categorical Emotion States (CES) and Dimensional Emotion Space (DES), facilitating unified discrete and continuous emotion representation. A novel multi-stage pipeline ensures high annotation reliability with minimal human effort. Finally, we introduce an interpretable model that maps visual cues into DES representations and provides detailed attribution explanations. Together, the dataset, pipeline, and model form a comprehensive foundation for advancing explainable high-level emotion understanding.

</details>


### [133] [SEMC: Structure-Enhanced Mixture-of-Experts Contrastive Learning for Ultrasound Standard Plane Recognition](https://arxiv.org/abs/2511.12559)
*Qing Cai,Guihao Yan,Fan Zhang,Cheng Zhang,Zhi Liu*

Main category: cs.CV

TL;DR: 本文提出SEMC框架，结合结构感知特征融合与专家引导对比学习，用于超声标准平面识别，通过多尺度结构信息利用和分层对比学习提升识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能有效利用浅层结构信息，且难以通过图像增强生成的对比样本捕捉细粒度语义差异，导致超声标准平面识别中结构和判别细节的识别效果不佳。

Method: 提出SEMC框架：1）语义-结构融合模块（SSFM）利用多尺度结构信息，对齐浅层和深层特征；2）专家混合对比识别模块（MCRM）通过MoE机制在多级特征上进行分层对比学习和分类。

Result: 在自建大规模肝脏超声数据集和两个公共数据集上的实验表明，SEMC在各种指标上均优于当前最先进方法。

Conclusion: SEMC框架通过结构增强和专家混合对比学习，显著提升了超声标准平面识别的性能，证明了该方法在临床任务中的有效性。

Abstract: Ultrasound standard plane recognition is essential for clinical tasks such as disease screening, organ evaluation, and biometric measurement. However, existing methods fail to effectively exploit shallow structural information and struggle to capture fine-grained semantic differences through contrastive samples generated by image augmentations, ultimately resulting in suboptimal recognition of both structural and discriminative details in ultrasound standard planes. To address these issues, we propose SEMC, a novel Structure-Enhanced Mixture-of-Experts Contrastive learning framework that combines structure-aware feature fusion with expert-guided contrastive learning. Specifically, we first introduce a novel Semantic-Structure Fusion Module (SSFM) to exploit multi-scale structural information and enhance the model's ability to perceive fine-grained structural details by effectively aligning shallow and deep features. Then, a novel Mixture-of-Experts Contrastive Recognition Module (MCRM) is designed to perform hierarchical contrastive learning and classification across multi-level features using a mixture-of-experts (MoE) mechanism, further improving class separability and recognition performance. More importantly, we also curate a large-scale and meticulously annotated liver ultrasound dataset containing six standard planes. Extensive experimental results on our in-house dataset and two public datasets demonstrate that SEMC outperforms recent state-of-the-art methods across various metrics.

</details>


### [134] [Through-Foliage Surface-Temperature Reconstruction for early Wildfire Detection](https://arxiv.org/abs/2511.12572)
*Mohamed Youssef,Lukas Brunner,Klaus Rundhammer,Gerald Czech,Oliver Bimber*

Main category: cs.CV

TL;DR: 提出了一种结合信号处理和机器学习的新方法，通过遮挡森林植被重建地表温度，用于无人机自动野火监测，实现早期火灾检测。


<details>
  <summary>Details</summary>
Motivation: 旨在实现无人机全自动野火监测，在烟雾或火焰可见之前早期检测地面火灾。合成孔径感知虽然能减轻树冠和阳光的遮挡，但会引入热模糊问题。

Method: 训练视觉状态空间模型从模糊数据中恢复部分遮挡的土壤和火灾热点的细微热信号。通过潜在扩散模型生成大量真实地表温度模拟数据，结合温度增强和程序化热森林模拟来克服训练数据稀缺问题。

Result: 在模拟数据上，相比传统热成像和未校正SA成像，RMSE降低了2-2.5倍。在高温热点现场实验中，RMSE增益分别达到12.8倍和2.6倍。模型还能重建火灾和人类特征的完整形态。

Conclusion: 该方法能有效克服热模糊和部分遮挡问题，不仅适用于野火监测，还能推广到其他热信号应用如搜救任务，比传统成像方法具有明显优势。

Abstract: We introduce a novel method for reconstructing surface temperatures through occluding forest vegetation by combining signal processing and machine learning. Our goal is to enable fully automated aerial wildfire monitoring using autonomous drones, allowing for the early detection of ground fires before smoke or flames are visible. While synthetic aperture (SA) sensing mitigates occlusion from the canopy and sunlight, it introduces thermal blur that obscures the actual surface temperatures. To address this, we train a visual state space model to recover the subtle thermal signals of partially occluded soil and fire hotspots from this blurred data. A key challenge was the scarcity of real-world training data. We overcome this by integrating a latent diffusion model into a vector quantized to generated a large volume of realistic surface temperature simulations from real wildfire recordings, which we further expanded through temperature augmentation and procedural thermal forest simulation. On simulated data across varied ambient and surface temperatures, forest densities, and sunlight conditions, our method reduced the RMSE by a factor of 2 to 2.5 compared to conventional thermal and uncorrected SA imaging. In field experiments focused on high-temperature hotspots, the improvement was even more significant, with a 12.8-fold RMSE gain over conventional thermal and a 2.6-fold gain over uncorrected SA images. We also demonstrate our model's generalization to other thermal signals, such as human signatures for search and rescue. Since simple thresholding is frequently inadequate for detecting subtle thermal signals, the morphological characteristics are equally essential for accurate classification. Our experiments demonstrated another clear advantage: we reconstructed the complete morphology of fire and human signatures, whereas conventional imaging is defeated by partial occlusion.

</details>


### [135] [Beyond Pixels: Semantic-aware Typographic Attack for Geo-Privacy Protection](https://arxiv.org/abs/2511.12575)
*Jiayi Zhu,Yihao Huang,Yue Cao,Xiaojun Jia,Qing Guo,Felix Juefei-Xu,Geguang Pu,Bin Wang*

Main category: cs.CV

TL;DR: 本文提出了一种基于排版攻击的地理隐私保护方法，通过向图像添加具有欺骗性的文本来干扰大型视觉语言模型的地理位置推断，相比传统对抗性扰动能更好地保持图像视觉质量。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型能够从社交媒体图像中推断用户地理位置，造成严重的隐私泄露风险。现有的对抗性图像扰动方法虽然有效但会显著降低图像质量，影响分享价值。

Method: 设计了一种两阶段语义感知的排版攻击方法，在图像视觉内容外添加具有欺骗性的文本扩展，通过研究有效的文本语义来干扰地理位置推断。

Result: 在三个数据集上的广泛实验表明，该方法显著降低了五种最先进商业LVLM的地理位置预测准确率。

Conclusion: 该方法为对抗新兴地理隐私威胁提供了一种实用且视觉保持的保护策略，排版攻击是保护地理隐私的有前景方向。

Abstract: Large Visual Language Models (LVLMs) now pose a serious yet overlooked privacy threat, as they can infer a social media user's geolocation directly from shared images, leading to unintended privacy leakage. While adversarial image perturbations provide a potential direction for geo-privacy protection, they require relatively strong distortions to be effective against LVLMs, which noticeably degrade visual quality and diminish an image's value for sharing. To overcome this limitation, we identify typographical attacks as a promising direction for protecting geo-privacy by adding text extension outside the visual content. We further investigate which textual semantics are effective in disrupting geolocation inference and design a two-stage, semantics-aware typographical attack that generates deceptive text to protect user privacy. Extensive experiments across three datasets demonstrate that our approach significantly reduces geolocation prediction accuracy of five state-of-the-art commercial LVLMs, establishing a practical and visually-preserving protection strategy against emerging geo-privacy threats.

</details>


### [136] [TempoMaster: Efficient Long Video Generation via Next-Frame-Rate Prediction](https://arxiv.org/abs/2511.12578)
*Yukuo Ma,Cong Liu,Junke Wang,Junqi Liu,Haibin Huang,Zuxuan Wu,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: TempoMaster是一个新颖的长视频生成框架，将长视频生成建模为下一帧率预测任务，通过从低帧率到高帧率的渐进式生成实现高效并行合成。


<details>
  <summary>Details</summary>
Motivation: 解决长视频生成中保持长时间一致性和高效合成的挑战，传统方法在长序列生成时存在计算效率低和时序一致性差的问题。

Method: 首先生成低帧率视频片段作为粗粒度蓝图，然后逐步提高帧率来细化视觉细节和运动连续性；在生成过程中使用双向注意力机制保持帧率级别内的一致性，同时在帧率间进行自回归预测。

Result: 大量实验表明TempoMaster在长视频生成任务上达到了新的state-of-the-art水平，在视觉质量和时序一致性方面均表现出色。

Conclusion: TempoMaster通过创新的帧率渐进式生成框架，成功解决了长视频生成的时序一致性和效率问题，为长序列视频合成提供了有效的解决方案。

Abstract: We present TempoMaster, a novel framework that formulates long video generation as next-frame-rate prediction. Specifically, we first generate a low-frame-rate clip that serves as a coarse blueprint of the entire video sequence, and then progressively increase the frame rate to refine visual details and motion continuity. During generation, TempoMaster employs bidirectional attention within each frame-rate level while performing autoregression across frame rates, thus achieving long-range temporal coherence while enabling efficient and parallel synthesis. Extensive experiments demonstrate that TempoMaster establishes a new state-of-the-art in long video generation, excelling in both visual and temporal quality.

</details>


### [137] [Rank-Aware Agglomeration of Foundation Models for Immunohistochemistry Image Cell Counting](https://arxiv.org/abs/2511.12588)
*Zuqi Huang,Mengxin Tian,Huan Liu,Wentao Li,Baobao Liang,Jie Wu,Fang Yan,Zhaoqing Tang,Zhongyu Li*

Main category: cs.CV

TL;DR: 提出了一种名为CountIHC的秩感知聚合框架，通过选择性蒸馏多个基础模型的知识来处理IHC图像中的多类细胞计数问题，解决了染色体重叠和细胞形态多样性等挑战。


<details>
  <summary>Details</summary>
Motivation: IHC图像中的细胞计数对于癌症诊断至关重要，但现有回归方法难以处理多类计数，且基础模型在该领域的潜力尚未充分探索。需要解决染色体重叠、生物标志物变异和细胞形态多样性等问题。

Method: 使用秩感知教师选择策略评估各基础模型的计数能力，进行样本级教师选择；通过视觉-语言对齐的微调阶段，利用结构化文本提示生成的语义锚点指导类别特异性密度图回归。

Result: 在12种IHC生物标志物和5种组织类型上的实验表明，CountIHC超越最先进方法，与病理学家评估高度一致，在H&E染色数据上也表现有效。

Conclusion: 该方法成功解决了IHC图像多类细胞计数问题，证明了基础模型知识蒸馏和视觉-语言对齐策略的有效性，具有很好的可扩展性。

Abstract: Accurate cell counting in immunohistochemistry (IHC) images is critical for quantifying protein expression and aiding cancer diagnosis. However, the task remains challenging due to the chromogen overlap, variable biomarker staining, and diverse cellular morphologies. Regression-based counting methods offer advantages over detection-based ones in handling overlapped cells, yet rarely support end-to-end multi-class counting. Moreover, the potential of foundation models remains largely underexplored in this paradigm. To address these limitations, we propose a rank-aware agglomeration framework that selectively distills knowledge from multiple strong foundation models, leveraging their complementary representations to handle IHC heterogeneity and obtain a compact yet effective student model, CountIHC. Unlike prior task-agnostic agglomeration strategies that either treat all teachers equally or rely on feature similarity, we design a Rank-Aware Teacher Selecting (RATS) strategy that models global-to-local patch rankings to assess each teacher's inherent counting capacity and enable sample-wise teacher selection. For multi-class cell counting, we introduce a fine-tuning stage that reformulates the task as vision-language alignment. Discrete semantic anchors derived from structured text prompts encode both category and quantity information, guiding the regression of class-specific density maps and improving counting for overlapping cells. Extensive experiments demonstrate that CountIHC surpasses state-of-the-art methods across 12 IHC biomarkers and 5 tissue types, while exhibiting high agreement with pathologists' assessments. Its effectiveness on H&E-stained data further confirms the scalability of the proposed method.

</details>


### [138] [Fine-Grained Representation for Lane Topology Reasoning](https://arxiv.org/abs/2511.12590)
*Guoqing Xu,Yiheng Li,Yang Yang*

Main category: cs.CV

TL;DR: TopoFG是一个细粒度的车道拓扑推理框架，通过分层先验提取、区域聚焦解码和鲁棒边界点拓扑推理三个模块，显著提升了复杂车道结构的建模精度和拓扑预测可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常用单一查询表示每个车道，基于车道查询之间的相似性推断拓扑连接性，但这种方法难以准确建模复杂车道结构，导致拓扑预测不可靠。

Method: 1. 分层先验提取器（HPE）：从BEV掩码提取全局空间先验，从车道内关键点序列提取局部序列先验；2. 区域聚焦解码器（RFD）：集成空间和序列先验构建细粒度查询，在掩码RoI区域采样参考点，通过交叉注意力机制优化车道查询表示；3. 鲁棒边界点拓扑推理（RBTR）：基于边界点查询特征建模车道连接性，并采用拓扑去噪策略减少匹配模糊性。

Result: 在OpenLane-V2基准测试中，TopoFG在subsetA上达到48.0%的OLS，在subsetB上达到45.4%的OLS，创造了新的最先进性能。

Conclusion: 通过将空间和序列先验集成到细粒度查询中，并对边界点拓扑推理应用去噪策略，TopoFG能够精确建模复杂车道结构，提供可信赖的拓扑预测。

Abstract: Precise modeling of lane topology is essential for autonomous driving, as it directly impacts navigation and control decisions.Existing methods typically represent each lane with a single query and infer topological connectivity based on the similarity between lane queries.However, this kind of design struggles to accurately model complex lane structures, leading to unreliable topology prediction.In this view, we propose a Fine-Grained lane topology reasoning framework (TopoFG).It divides the procedure from bird's-eye-view (BEV) features to topology prediction via fine-grained queries into three phases, i.e., Hierarchical Prior Extractor (HPE), Region-Focused Decoder (RFD), and Robust Boundary-Point Topology Reasoning (RBTR).Specifically, HPE extracts global spatial priors from the BEV mask and local sequential priors from in-lane keypoint sequences to guide subsequent fine-grained query modeling.RFD constructs fine-grained queries by integrating the spatial and sequential priors. It then samples reference points in RoI regions of the mask and applies cross-attention with BEV features to refine the query representations of each lane.RBTR models lane connectivity based on boundary-point query features and further employs a topological denoising strategy to reduce matching ambiguity.By integrating spatial and sequential priors into fine-grained queries and applying a denoising strategy to boundary-point topology reasoning, our method precisely models complex lane structures and delivers trustworthy topology predictions.Extensive experiments on the OpenLane-V2 benchmark demonstrate that TopoFG achieves new state-of-the-art performance, with an OLS of 48.0% on subsetA and 45.4% on subsetB.

</details>


### [139] [Seg-VAR: Image Segmentation with Visual Autoregressive Modeling](https://arxiv.org/abs/2511.12594)
*Rongkun Zheng,Lu Qi,Xi Chen,Yi Wang,Kun Wang,Hengshuang Zhao*

Main category: cs.CV

TL;DR: Seg-VAR是一个将分割任务重新定义为条件自回归掩码生成问题的新框架，通过多尺度建模和潜在学习过程，在多个分割任务和验证基准上超越了之前的判别式和生成式方法。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉自回归建模（VAR）策略在图像生成方面取得了进展，但其在需要精确空间感知的分割任务中的潜力尚未被探索。作者希望探索自回归模型在分割任务中的应用可能性。

Method: 提出Seg-VAR框架，包含三个核心组件：1）图像编码器生成潜在先验；2）空间感知的seglat编码器将分割掩码映射为离散潜在标记；3）解码器从潜在表示重建掩码。采用多阶段训练策略：先学习seglat表示，然后优化潜在变换，最后对齐图像编码器生成的潜在与seglat分布。

Result: 实验表明Seg-VAR在各种分割任务和验证基准上优于之前的判别式和生成式方法。

Conclusion: 通过将分割重新定义为顺序层次预测任务，Seg-VAR为将自回归推理整合到空间感知视觉系统中开辟了新途径。

Abstract: While visual autoregressive modeling (VAR) strategies have shed light on image generation with the autoregressive models, their potential for segmentation, a task that requires precise low-level spatial perception, remains unexplored. Inspired by the multi-scale modeling of classic Mask2Former-based models, we propose Seg-VAR, a novel framework that rethinks segmentation as a conditional autoregressive mask generation problem. This is achieved by replacing the discriminative learning with the latent learning process. Specifically, our method incorporates three core components: (1) an image encoder generating latent priors from input images, (2) a spatial-aware seglat (a latent expression of segmentation mask) encoder that maps segmentation masks into discrete latent tokens using a location-sensitive color mapping to distinguish instances, and (3) a decoder reconstructing masks from these latents. A multi-stage training strategy is introduced: first learning seglat representations via image-seglat joint training, then refining latent transformations, and finally aligning image-encoder-derived latents with seglat distributions. Experiments show Seg-VAR outperforms previous discriminative and generative methods on various segmentation tasks and validation benchmarks. By framing segmentation as a sequential hierarchical prediction task, Seg-VAR opens new avenues for integrating autoregressive reasoning into spatial-aware vision systems. Code will be available at https://github.com/rkzheng99/Seg-VAR.

</details>


### [140] [LoRA-Enhanced Vision Transformer for Single Image based Morphing Attack Detection via Knowledge Distillation from EfficientNet](https://arxiv.org/abs/2511.12602)
*Ria Shekhawat,Sushrut Patwardhan,Raghavendra Ramachandra,Praveen Kumar Chandaliya,Kishor P. Upla*

Main category: cs.CV

TL;DR: 提出一种基于师生框架的单图像形态攻击检测方法，使用CNN教师模型指导ViT学生模型，结合LoRA微调提高效率，在包含多种形态生成算法的数据集上验证了优越性能


<details>
  <summary>Details</summary>
Motivation: 人脸识别系统容易受到形态攻击（合成图像融合多人生物特征），需要开发有效的单图像检测方法来增强安全性

Method: 采用师生框架，CNN教师模型指导ViT学生模型进行特征学习，集成低秩适应（LoRA）进行微调以降低计算成本

Result: 在包含10种不同形态生成算法的数据集上测试，相比6种现有S-MAD技术，该方法在检测性能和计算效率方面均表现优越

Conclusion: 提出的师生框架结合LoRA微调的单图像形态攻击检测方法具有高检测精度和计算效率，为人脸识别系统安全提供了有效解决方案

Abstract: Face Recognition Systems (FRS) are critical for security but remain vulnerable to morphing attacks, where synthetic images blend biometric features from multiple individuals. We propose a novel Single-Image Morphing Attack Detection (S-MAD) approach using a teacher-student framework, where a CNN-based teacher model refines a ViT-based student model. To improve efficiency, we integrate Low-Rank Adaptation (LoRA) for fine-tuning, reducing computational costs while maintaining high detection accuracy. Extensive experiments are conducted on a morphing dataset built from three publicly available face datasets, incorporating ten different morphing generation algorithms to assess robustness. The proposed method is benchmarked against six state-of-the-art S-MAD techniques, demonstrating superior detection performance and computational efficiency.

</details>


### [141] [Pixels or Positions? Benchmarking Modalities in Group Activity Recognition](https://arxiv.org/abs/2511.12606)
*Drishya Karki,Merey Ramazanova,Anthony Cioppa,Silvio Giancola,Bernard Ghanem*

Main category: cs.CV

TL;DR: SoccerNet-GAR数据集为足球团体活动识别提供了同步的视频和追踪数据，比较了像素和位置两种模态的性能。追踪模型在平衡准确率、训练速度和参数效率上均优于视频模型。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏标准化的基准来对齐视频和追踪数据，无法公平比较这两种模态在团体活动识别中的性能。

Method: 构建SoccerNet-GAR多模态数据集，包含94,285个同步标注的团体活动。提出基于图神经网络的追踪分类器，采用角色感知图架构编码战术结构。

Result: 追踪模型达到67.2%平衡准确率，优于视频基线的58.1%，训练速度快4.25倍，参数减少438倍（197K vs 86.3M）。

Conclusion: 追踪数据在团体活动识别中优于视频数据，角色感知建模对GAR至关重要，模态选择对性能有显著影响。

Abstract: Group Activity Recognition (GAR) is well studied on the video modality for surveillance and indoor team sports (e.g., volleyball, basketball). Yet, other modalities such as agent positions and trajectories over time, i.e. tracking, remain comparatively under-explored despite being compact, agent-centric signals that explicitly encode spatial interactions. Understanding whether pixel (video) or position (tracking) modalities leads to better group activity recognition is therefore important to drive further research on the topic. However, no standardized benchmark currently exists that aligns broadcast video and tracking data for the same group activities, leading to a lack of apples-to-apples comparison between these modalities for GAR. In this work, we introduce SoccerNet-GAR, a multimodal dataset built from the $64$ matches of the football World Cup 2022. Specifically, the broadcast videos and player tracking modalities for $94{,}285$ group activities are synchronized and annotated with $10$ categories. Furthermore, we define a unified evaluation protocol to benchmark two strong unimodal approaches: (i) a competitive video-based classifiers and (ii) a tracking-based classifiers leveraging graph neural networks. In particular, our novel role-aware graph architecture for tracking-based GAR directly encodes tactical structure through positional edges and temporal attention. Our tracking model achieves $67.2\%$ balanced accuracy compared to $58.1\%$ for the best video baseline, while training $4.25 \times$ faster with $438 \times$ fewer parameters ($197K$ \vs $86.3M$). This study provides new insights into the relative strengths of pixels and positions for group activity recognition. Overall, it highlights the importance of modality choice and role-aware modeling for GAR.

</details>


### [142] [Open-World Test-Time Adaptation with Hierarchical Feature Aggregation and Attention Affine](https://arxiv.org/abs/2511.12607)
*Ziqiong Liu,Yushun Tang,Junyang Ji,Zhihai He*

Main category: cs.CV

TL;DR: 本文提出了一种分层梯子网络（HLN）和注意力仿射网络（AAN）相结合的方法，用于测试时自适应（TTA）场景下的OOD检测和领域偏移适应。


<details>
  <summary>Details</summary>
Motivation: 在现实场景中，模型经常遇到来自未见类别（OOD）的样本。将这些样本误分类为已知类别（ID）不仅会降低预测准确性，还会损害自适应过程，导致后续ID样本的进一步错误。现有TTA方法在此类条件下性能大幅下降。

Method: 1. 分层梯子网络（HLN）从所有Transformer层聚合的类别标记中提取OOD特征；2. 通过加权概率融合将原始模型预测与HLN输出结合以增强OOD检测；3. 注意力仿射网络（AAN）根据标记信息自适应调整自注意力机制以应对领域偏移；4. 采用加权熵机制动态抑制低置信度样本在自适应过程中的影响。

Result: 在基准数据集上的实验结果表明，该方法在广泛使用的分类数据集上显著提高了性能。

Conclusion: 所提出的方法通过改进OOD检测和领域偏移适应能力，有效提升了测试时自适应的鲁棒性和性能。

Abstract: Test-time adaptation (TTA) refers to adjusting the model during the testing phase to cope with changes in sample distribution and enhance the model's adaptability to new environments. In real-world scenarios, models often encounter samples from unseen (out-of-distribution, OOD) categories. Misclassifying these as known (in-distribution, ID) classes not only degrades predictive accuracy but can also impair the adaptation process, leading to further errors on subsequent ID samples. Many existing TTA methods suffer substantial performance drops under such conditions. To address this challenge, we propose a Hierarchical Ladder Network that extracts OOD features from class tokens aggregated across all Transformer layers. OOD detection performance is enhanced by combining the original model prediction with the output of the Hierarchical Ladder Network (HLN) via weighted probability fusion. To improve robustness under domain shift, we further introduce an Attention Affine Network (AAN) that adaptively refines the self-attention mechanism conditioned on the token information to better adapt to domain drift, thereby improving the classification performance of the model on datasets with domain shift. Additionally, a weighted entropy mechanism is employed to dynamically suppress the influence of low-confidence samples during adaptation. Experimental results on benchmark datasets show that our method significantly improves the performance on the most widely used classification datasets.

</details>


### [143] [C3Net: Context-Contrast Network for Camouflaged Object Detection](https://arxiv.org/abs/2511.12627)
*Baber Jan,Aiman H. El-Maleh,Abdul Jabbar Siddiqui,Abdul Bais,Saeed Anwar*

Main category: cs.CV

TL;DR: 本文提出了C3Net，一种专门用于伪装物体检测的双路径解码器架构，解决了该领域的六个核心挑战，在多个数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 伪装物体检测由于物体与背景在颜色、纹理和模式上的高度相似性，对传统分割方法和现代基础模型都构成了巨大挑战。作者识别出六个基本挑战需要综合的架构解决方案。

Method: C3Net采用双路径解码器架构：边缘精炼路径使用梯度初始化的边缘增强模块恢复精确边界；上下文定位路径使用图像上下文引导机制实现内在显著性抑制；注意力融合模块通过空间门控协同结合两条路径。

Result: C3Net在COD10K数据集上S-measure达到0.898，CAMO数据集达到0.904，NC4K数据集达到0.913，实现了最先进的性能，同时保持高效处理。

Conclusion: C3Net证明复杂多方面的检测挑战需要架构创新，通过专门组件的协同工作实现全面覆盖，超越了孤立的改进。

Abstract: Camouflaged object detection identifies objects that blend seamlessly with their surroundings through similar colors, textures, and patterns. This task challenges both traditional segmentation methods and modern foundation models, which fail dramatically on camouflaged objects. We identify six fundamental challenges in COD: Intrinsic Similarity, Edge Disruption, Extreme Scale Variation, Environmental Complexities, Contextual Dependencies, and Salient-Camouflaged Object Disambiguation. These challenges frequently co-occur and compound the difficulty of detection, requiring comprehensive architectural solutions. We propose C3Net, which addresses all challenges through a specialized dual-pathway decoder architecture. The Edge Refinement Pathway employs gradient-initialized Edge Enhancement Modules to recover precise boundaries from early features. The Contextual Localization Pathway utilizes our novel Image-based Context Guidance mechanism to achieve intrinsic saliency suppression without external models. An Attentive Fusion Module synergistically combines the two pathways via spatial gating. C3Net achieves state-of-the-art performance with S-measures of 0.898 on COD10K, 0.904 on CAMO, and 0.913 on NC4K, while maintaining efficient processing. C3Net demonstrates that complex, multifaceted detection challenges require architectural innovation, with specialized components working synergistically to achieve comprehensive coverage beyond isolated improvements. Code, model weights, and results are available at https://github.com/Baber-Jan/C3Net.

</details>


### [144] [Multivariate Diffusion Transformer with Decoupled Attention for High-Fidelity Mask-Text Collaborative Facial Generation](https://arxiv.org/abs/2511.12631)
*Yushe Cao,Dianxi Shi,Xing Fu,Xuechao Zou,Haikuo Peng,Xueqi Li,Chun Yu,Junliang Xing*

Main category: cs.CV

TL;DR: MDiTFace是一个基于扩散变换器的多模态人脸生成框架，通过统一标记化策略和新型解耦注意力机制，有效解决了传统特征融合方法在语义掩码和文本描述融合中的不足，显著提升了生成质量和计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统多模态特征融合方法在语义掩码和文本描述的人脸生成任务中，难以实现有效的跨模态交互，导致生成结果不理想。

Method: 提出MDiTFace框架：1）使用统一标记化策略处理语义掩码和文本输入；2）设计堆叠的多变量变换器块实现同步多模态特征交互；3）引入解耦注意力机制，将掩码标记与时序嵌入的隐式依赖分离，通过动态和静态路径分离计算，实现特征缓存复用。

Result: 实验表明MDiTFace在面部保真度和条件一致性方面显著优于其他竞争方法，同时将掩码条件引入的计算开销降低了94%以上。

Conclusion: MDiTFace通过创新的统一标记化和解耦注意力机制，成功解决了多模态人脸生成中的跨模态交互难题，在保持性能的同时大幅提升了计算效率。

Abstract: While significant progress has been achieved in multimodal facial generation using semantic masks and textual descriptions, conventional feature fusion approaches often fail to enable effective cross-modal interactions, thereby leading to suboptimal generation outcomes. To address this challenge, we introduce MDiTFace--a customized diffusion transformer framework that employs a unified tokenization strategy to process semantic mask and text inputs, eliminating discrepancies between heterogeneous modality representations. The framework facilitates comprehensive multimodal feature interaction through stacked, newly designed multivariate transformer blocks that process all conditions synchronously. Additionally, we design a novel decoupled attention mechanism by dissociating implicit dependencies between mask tokens and temporal embeddings. This mechanism segregates internal computations into dynamic and static pathways, enabling caching and reuse of features computed in static pathways after initial calculation, thereby reducing additional computational overhead introduced by mask condition by over 94% while maintaining performance. Extensive experiments demonstrate that MDiTFace significantly outperforms other competing methods in terms of both facial fidelity and conditional consistency.

</details>


### [145] [Denoising Vision Transformer Autoencoder with Spectral Self-Regularization](https://arxiv.org/abs/2511.12633)
*Xunzhi Xiang,Xingye Tian,Guiyu Zhang,Yabo Chen,Shaofeng Zhang,Xuebo Wang,Xin Tao,Qi Fan*

Main category: cs.CV

TL;DR: 本文提出了一种谱自正则化策略来解决高维VAE潜在空间中冗余高频分量对扩散模型训练收敛的负面影响，开发了不依赖视觉基础模型的Denoising-VAE，显著提升了生成质量和训练效率。


<details>
  <summary>Details</summary>
Motivation: 传统VAE在高维潜在空间中存在优化困境：高维空间能提高重建保真度但会损害生成性能。现有方法使用外部视觉基础模型进行正则化，但高维潜在空间如何影响生成模型优化仍不明确。

Method: 提出谱自正则化策略抑制冗余高频噪声同时保持重建质量；开发基于ViT的Denoising-VAE；引入谱对齐策略优化基于Denoising-VAE的生成模型。

Result: 在ImageNet 256×256基准上，扩散模型收敛速度比SD-VAE快约2倍，达到最先进的重建质量（rFID=0.28，PSNR=27.26）和竞争性生成性能（gFID=1.82）。

Conclusion: Denoising-VAE通过有效处理高维潜在空间中的高频噪声问题，实现了重建质量和生成性能的平衡，为生成模型提供了更优的潜在表示。

Abstract: Variational autoencoders (VAEs) typically encode images into a compact latent space, reducing computational cost but introducing an optimization dilemma: a higher-dimensional latent space improves reconstruction fidelity but often hampers generative performance. Recent methods attempt to address this dilemma by regularizing high-dimensional latent spaces using external vision foundation models (VFMs). However, it remains unclear how high-dimensional VAE latents affect the optimization of generative models. To our knowledge, our analysis is the first to reveal that redundant high-frequency components in high-dimensional latent spaces hinder the training convergence of diffusion models and, consequently, degrade generation quality. To alleviate this problem, we propose a spectral self-regularization strategy to suppress redundant high-frequency noise while simultaneously preserving reconstruction quality. The resulting Denoising-VAE, a ViT-based autoencoder that does not rely on VFMs, produces cleaner, lower-noise latents, leading to improved generative quality and faster optimization convergence. We further introduce a spectral alignment strategy to facilitate the optimization of Denoising-VAE-based generative models. Our complete method enables diffusion models to converge approximately 2$\times$ faster than with SD-VAE, while achieving state-of-the-art reconstruction quality (rFID = 0.28, PSNR = 27.26) and competitive generation performance (gFID = 1.82) on the ImageNet 256$\times$256 benchmark.

</details>


### [146] [Medical Knowledge Intervention Prompt Tuning for Medical Image Classification](https://arxiv.org/abs/2511.12639)
*Ye Du,Nanxi Yu,Shujun Wang*

Main category: cs.CV

TL;DR: 提出了CILMP方法，利用大型语言模型（LLMs）为视觉语言基础模型（VLMs）生成疾病特定的提示，在医学图像分类任务中优于现有提示调优方法。


<details>
  <summary>Details</summary>
Motivation: 现有提示调优方法无法精确区分不同类型的医学概念，缺乏针对特定疾病的特征。LLMs在医学专业知识方面表现出色，可弥补这一不足。

Method: CILMP方法从LLMs提取疾病特定表示，在低秩线性子空间进行干预，生成疾病特定提示，并加入条件机制实现实例自适应提示。

Result: 在多个医学图像数据集上的实验表明，CILMP一致优于最先进的提示调优方法。

Conclusion: CILMP有效将医学知识转移到VLM提示中，提高了医学图像分类的性能和适应性。

Abstract: Vision-language foundation models (VLMs) have shown great potential in feature transfer and generalization across a wide spectrum of medical-related downstream tasks. However, fine-tuning these models is resource-intensive due to their large number of parameters. Prompt tuning has emerged as a viable solution to mitigate memory usage and reduce training time while maintaining competitive performance. Nevertheless, the challenge is that existing prompt tuning methods cannot precisely distinguish different kinds of medical concepts, which miss essentially specific disease-related features across various medical imaging modalities in medical image classification tasks. We find that Large Language Models (LLMs), trained on extensive text corpora, are particularly adept at providing this specialized medical knowledge. Motivated by this, we propose incorporating LLMs into the prompt tuning process. Specifically, we introduce the CILMP, Conditional Intervention of Large Language Models for Prompt Tuning, a method that bridges LLMs and VLMs to facilitate the transfer of medical knowledge into VLM prompts. CILMP extracts disease-specific representations from LLMs, intervenes within a low-rank linear subspace, and utilizes them to create disease-specific prompts. Additionally, a conditional mechanism is incorporated to condition the intervention process on each individual medical image, generating instance-adaptive prompts and thus enhancing adaptability. Extensive experiments across diverse medical image datasets demonstrate that CILMP consistently outperforms state-of-the-art prompt tuning methods, demonstrating its effectiveness. Code is available at https://github.com/usr922/cilmp.

</details>


### [147] [DPVO-QAT++: Heterogeneous QAT and CUDA Kernel Fusion for High-Performance Deep Patch Visual Odometry](https://arxiv.org/abs/2511.12653)
*Cheng Liao*

Main category: cs.CV

TL;DR: DPVO-QAT++是一个层次化量化优化框架，通过可学习尺度参数化、VO前后端异构精度设计（前端FP16/FP32伪量化，后端全精度）和GPU原生内核融合，显著降低内存占用并提升处理速度，同时保持原始模型的轨迹精度。


<details>
  <summary>Details</summary>
Motivation: 深度学习视觉SLAM系统具有出色的几何推理能力，但计算开销过大限制了在资源受限的自主平台上的部署。需要解决高精度深度VO与实用部署效率需求之间的差距。

Method: 采用异构量化感知训练架构：前端使用浮点伪量化（FP16/FP32），后端保持全精度；结合可学习尺度参数化和自定义CUDA内核的GPU原生内核融合技术。

Result: 在TartanAir数据集上：平均FPS提升52.1%，中位延迟降低29.1%，峰值GPU内存占用减少64.9%；在EuRoC数据集上：平均FPS提升30.1%，中位延迟降低23.1%，峰值GPU内存占用减少37.7%，同时保持与原始模型相当的轨迹精度。

Conclusion: DPVO-QAT++有效弥合了高精度深度VO与实用部署效率需求之间的差距，为实际嵌入式平台上的技术应用提供了可行的工程范式。

Abstract: Deep learning-based Visual SLAM (vSLAM) systems exhibit exceptional geometric reasoning capabilities, yet their prohibitive computational overhead severely restricts deployment on resource-constrained autonomous platforms. This paper presents a hierarchical quantization optimization framework, DPVO-QAT++ (DPVO-QAT++: Heterogeneous QAT and CUDA Kernel Fusion for High-Performance Deep Patch Visual Odometry). Through the synergistic integration of learnable scale parameterization, a heterogeneous precision design for the Visual Odometry (VO) front-end and back-end (front-end floating-point fake quantization with FP16/FP32; back-end full precision), and GPU-native kernel fusion for fake quantization (custom CUDA kernels), our framework significantly reduces memory footprint and increases processing speed while preserving the trajectory accuracy of the original model. On the TartanAir dataset, our framework achieves an average FPS increase of 52.1%, a 29.1% reduction in median latency, and a 64.9% reduction in peak GPU memory reservation, while maintaining trajectory accuracy (ATE) comparable to the original DPVO model across 32 validation sequences. On the EuRoC dataset, it realizes an average FPS increase of 30.1%, a 23.1% reduction in median latency, and a 37.7% reduction in peak GPU memory reservation, maintaining comparable trajectory accuracy (ATE) across 11 validation sequences. Experimental results demonstrate that DPVO-QAT++ effectively bridges the gap between high-precision deep VO and the efficiency requirements for practical deployment, offering a viable engineering paradigm for the application of this technology on real-world embedded platforms.
  Keywords: Visual Odometry, Heterogeneous Precision Architecture, Quantization-Aware Training, CUDA Kernel Fusion, Scale-Only Training, Deep Patch Visual Odometry, GPU-Native Kernel Fusion.

</details>


### [148] [Toward Real-world Text Image Forgery Localization: Structured and Interpretable Data Synthesis](https://arxiv.org/abs/2511.12658)
*Zeqin Yu,Haotao Xie,Jian Zhang,Jiangqun Ni,Wenkan Su,Jiwu Huang*

Main category: cs.CV

TL;DR: 提出FSTS框架，通过傅里叶级数建模真实篡改行为，生成更真实的训练数据，显著提升文本图像伪造定位的泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有T-IFL方法因真实数据集规模有限和合成数据与真实篡改分布差异大而导致泛化能力差

Method: 收集16,750个真实篡改实例，建立分层建模框架，将篡改参数表示为基操作配置的紧凑组合，通过傅里叶级数启发的可解释近似进行数据合成

Result: 在四个评估协议上的实验表明，使用FSTS数据训练的模型在真实数据集上实现了显著改进的泛化性能

Conclusion: FSTS通过结构化建模真实篡改行为，能够生成更真实的训练数据，有效解决文本图像伪造定位的泛化问题

Abstract: Existing Text Image Forgery Localization (T-IFL) methods often suffer from poor generalization due to the limited scale of real-world datasets and the distribution gap caused by synthetic data that fails to capture the complexity of real-world tampering. To tackle this issue, we propose Fourier Series-based Tampering Synthesis (FSTS), a structured and interpretable framework for synthesizing tampered text images. FSTS first collects 16,750 real-world tampering instances from five representative tampering types, using a structured pipeline that records human-performed editing traces via multi-format logs (e.g., video, PSD, and editing logs). By analyzing these collected parameters and identifying recurring behavioral patterns at both individual and population levels, we formulate a hierarchical modeling framework. Specifically, each individual tampering parameter is represented as a compact combination of basis operation-parameter configurations, while the population-level distribution is constructed by aggregating these behaviors. Since this formulation draws inspiration from the Fourier series, it enables an interpretable approximation using basis functions and their learned weights. By sampling from this modeled distribution, FSTS synthesizes diverse and realistic training data that better reflect real-world forgery traces. Extensive experiments across four evaluation protocols demonstrate that models trained with FSTS data achieve significantly improved generalization on real-world datasets. Dataset is available at \href{https://github.com/ZeqinYu/FSTS}{Project Page}.

</details>


### [149] [Hi-Reco: High-Fidelity Real-Time Conversational Digital Humans](https://arxiv.org/abs/2511.12662)
*Hongbin Huang,Junwei Li,Tianxin Xie,Zhuang Li,Cekai Weng,Yaodong Yang,Yue Luo,Li Liu,Jing Tang,Zhijing Shao,Zeyu Wang*

Main category: cs.CV

TL;DR: 提出了一种高保真、实时的对话数字人系统，结合了视觉逼真的3D虚拟形象、角色驱动的表情语音合成和基于知识的对话生成，通过异步执行管道实现低延迟的多模态协调。


<details>
  <summary>Details</summary>
Motivation: 当前交互式应用中，实现视觉逼真性和实时响应性同时存在挑战，需要开发能够自然及时交互的数字人系统。

Method: 采用异步执行管道协调多模态组件，使用检索增强方法包括历史增强和基于意图的路由，支持唤醒词检测、情感表达韵律和上下文感知响应生成。

Result: 构建了一个集成系统，能够实现响应迅速且可信的数字人，适用于通信、教育和娱乐等沉浸式应用场景。

Conclusion: 该系统成功解决了高保真数字人实时交互的挑战，为沉浸式应用提供了可行的技术方案。

Abstract: High-fidelity digital humans are increasingly used in interactive applications, yet achieving both visual realism and real-time responsiveness remains a major challenge. We present a high-fidelity, real-time conversational digital human system that seamlessly combines a visually realistic 3D avatar, persona-driven expressive speech synthesis, and knowledge-grounded dialogue generation. To support natural and timely interaction, we introduce an asynchronous execution pipeline that coordinates multi-modal components with minimal latency. The system supports advanced features such as wake word detection, emotionally expressive prosody, and highly accurate, context-aware response generation. It leverages novel retrieval-augmented methods, including history augmentation to maintain conversational flow and intent-based routing for efficient knowledge access. Together, these components form an integrated system that enables responsive and believable digital humans, suitable for immersive applications in communication, education, and entertainment.

</details>


### [150] [DensePercept-NCSSD: Vision Mamba towards Real-time Dense Visual Perception with Non-Causal State Space Duality](https://arxiv.org/abs/2511.12671)
*Tushar Anand,Advik Sinha,Abhijit Das*

Main category: cs.CV

TL;DR: 提出了一种基于非因果选择性状态空间的实时光流和视差估计模型，通过融合成对输入图像实现高精度密集感知任务


<details>
  <summary>Details</summary>
Motivation: 解决实时应用中光流和视差估计的高精度与低延迟需求之间的矛盾，平衡推理速度与准确性

Method: 使用非因果Mamba块构建的模型，在非因果选择性状态空间中融合成对输入图像，优化GPU使用效率

Result: 模型在保持高精度的同时显著降低推理时间，实现实时性能，并在实际场景中得到验证

Conclusion: 该模型适用于统一、实时且准确的3D密集感知估计任务，在速度和精度方面表现优异

Abstract: In this work, we propose an accurate and real-time optical flow and disparity estimation model by fusing pairwise input images in the proposed non-causal selective state space for dense perception tasks. We propose a non-causal Mamba block-based model that is fast and efficient and aptly manages the constraints present in a real-time applications. Our proposed model reduces inference times while maintaining high accuracy and low GPU usage for optical flow and disparity map generation. The results and analysis, and validation in real-life scenario justify that our proposed model can be used for unified real-time and accurate 3D dense perception estimation tasks. The code, along with the models, can be found at https://github.com/vimstereo/DensePerceptNCSSD

</details>


### [151] [Appreciate the View: A Task-Aware Evaluation Framework for Novel View Synthesis](https://arxiv.org/abs/2511.12675)
*Saar Stern,Ido Sobol,Or Litany*

Main category: cs.CV

TL;DR: 提出了一种针对新视角合成（NVS）的任务感知评估框架，包含参考评分D_PRISM和无参考评分MMD_PRISM，能够可靠地识别错误生成并与人类偏好一致。


<details>
  <summary>Details</summary>
Motivation: 现有评估指标难以判断生成图像是否既真实又忠实于源视图和视角变换，标准指标如像素相似性和分布度量经常错误地评估不正确的结果。

Method: 利用强NVS基础模型Zero123的特征，结合轻量级调优步骤增强判别能力，提出了参考评分D_PRISM和无参考评分MMD_PRISM两种互补评估指标。

Result: 在三个基准数据集（Toys4K、GSO、OmniObject3D）上对六种NVS方法进行评估，MMD_PRISM产生了清晰稳定的排名，较低分数始终表示更强的模型。

Conclusion: 该框架为评估合成质量提供了原则性和实用性的方法，为新视角合成的可靠进展铺平了道路。

Abstract: The goal of Novel View Synthesis (NVS) is to generate realistic images of a given content from unseen viewpoints. But how can we trust that a generated image truly reflects the intended transformation? Evaluating its reliability remains a major challenge. While recent generative models, particularly diffusion-based approaches, have significantly improved NVS quality, existing evaluation metrics struggle to assess whether a generated image is both realistic and faithful to the source view and intended viewpoint transformation. Standard metrics, such as pixel-wise similarity and distribution-based measures, often mis-rank incorrect results as they fail to capture the nuanced relationship between the source image, viewpoint change, and generated output. We propose a task-aware evaluation framework that leverages features from a strong NVS foundation model, Zero123, combined with a lightweight tuning step to enhance discrimination. Using these features, we introduce two complementary evaluation metrics: a reference-based score, $D_{\text{PRISM}}$, and a reference-free score, $\text{MMD}_{\text{PRISM}}$. Both reliably identify incorrect generations and rank models in agreement with human preference studies, addressing a fundamental gap in NVS evaluation. Our framework provides a principled and practical approach to assessing synthesis quality, paving the way for more reliable progress in novel view synthesis. To further support this goal, we apply our reference-free metric to six NVS methods across three benchmarks: Toys4K, Google Scanned Objects (GSO), and OmniObject3D, where $\text{MMD}_{\text{PRISM}}$ produces a clear and stable ranking, with lower scores consistently indicating stronger models.

</details>


### [152] [BridgeEQA: Virtual Embodied Agents for Real Bridge Inspections](https://arxiv.org/abs/2511.12676)
*Subin Varghese,Joshua Gao,Asad Ur Rahman,Vedhus Hoskere*

Main category: cs.CV

TL;DR: 该论文提出了BridgeEQA基准测试，用于开放词汇的具身问答任务，专注于桥梁检查领域。该基准包含2200个问题-答案对，基于真实桥梁检查报告，并提出了新的评估指标和EMVR方法来解决现有模型在具身问答中的性能差距。


<details>
  <summary>Details</summary>
Motivation: 当前具身智能体在真实环境中回答关于周围环境的问题仍然困难，主要原因是缺乏能够真实反映实际操作条件的基准测试。桥梁检查领域自然需要多尺度推理、长距离空间理解和复杂语义关系，同时通过标准化的国家桥梁清单条件评级、专业检查报告和第一人称视角图像提供了独特的评估优势。

Method: 提出了Embodied Memory Visual Reasoning (EMVR)方法，将检查任务建模为基于图像场景图的顺序导航：图像作为节点，智能体通过行动遍历视图、比较证据，并在马尔可夫决策过程中进行推理。

Result: 对最先进的视觉语言模型的评估显示在情景记忆EQA设置下存在显著的性能差距。EMVR方法在基线模型上表现出强大的性能提升。

Conclusion: BridgeEQA基准测试为具身问答研究提供了有价值的测试平台，EMVR方法有效解决了多图像推理和空间理解的挑战，推动了具身智能在现实世界应用中的发展。

Abstract: Deploying embodied agents that can answer questions about their surroundings in realistic real-world settings remains difficult, partly due to the scarcity of benchmarks that faithfully capture practical operating conditions. We propose infrastructure inspection as a compelling domain for open-vocabulary Embodied Question Answering (EQA): it naturally demands multi-scale reasoning, long-range spatial understanding, and complex semantic relationships, while offering unique evaluation advantages via standardized National Bridge Inventory (NBI) condition ratings (0-9), professional inspection reports, and egocentric imagery.
  We introduce BridgeEQA, a benchmark of 2,200 open-vocabulary question-answer pairs (in the style of OpenEQA) grounded in professional inspection reports across 200 real-world bridge scenes with 47.93 images on average per scene. Questions require synthesizing visual evidence across multiple images and aligning responses with NBI condition ratings. We further propose a new EQA metric Image Citation Relevance to evaluate the ability of a model to cite relevant images.
  Evaluations of state-of-the-art vision-language models reveal substantial performance gaps under episodic memory EQA settings. To address this, we propose Embodied Memory Visual Reasoning (EMVR), which formulates inspection as sequential navigation over an image-based scene graph: images are nodes, and an agent takes actions to traverse views, compare evidence, and reason within a Markov decision process. EMVR shows strong performance over the baselines. We publicly release both the dataset and code.

</details>


### [153] [R$^{2}$Seg: Training-Free OOD Medical Tumor Segmentation via Anatomical Reasoning and Statistical Rejection](https://arxiv.org/abs/2511.12691)
*Shuaike Shen,Ke Liu,Jiaqing Xie,Shangde Gao,Chunhua Shen,Ge Liu,Mireia Crispin-Ortuzar,Shangqi Gao*

Main category: cs.CV

TL;DR: R²Seg是一个无需训练的两阶段框架，通过Reason-and-Reject过程提高医学图像分割在分布外肿瘤上的鲁棒性，显著减少假阳性并提升分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有的医学图像分割基础模型在面对分布外肿瘤时表现不佳，经常产生碎片化的假阳性结果，需要一种无需训练就能提高鲁棒性的方法。

Method: 采用两阶段方法：1) Reason步骤使用LLM引导的解剖推理规划器定位器官锚点并生成多尺度ROI；2) Reject步骤对基础模型生成的候选区域应用双样本统计检验，只保留与正常组织显著不同的候选区域。

Result: 在多中心多模态肿瘤分割基准测试中，R²Seg在Dice系数、特异性和灵敏度方面显著优于强基线方法和原始基础模型。

Conclusion: R²Seg提供了一种无需参数更新的训练免费框架，能够有效处理分布外肿瘤分割问题，避免灾难性遗忘，并与零更新测试时增强兼容。

Abstract: Foundation models for medical image segmentation struggle under out-of-distribution (OOD) shifts, often producing fragmented false positives on OOD tumors. We introduce R$^{2}$Seg, a training-free framework for robust OOD tumor segmentation that operates via a two-stage Reason-and-Reject process. First, the Reason step employs an LLM-guided anatomical reasoning planner to localize organ anchors and generate multi-scale ROIs. Second, the Reject step applies two-sample statistical testing to candidates generated by a frozen foundation model (BiomedParse) within these ROIs. This statistical rejection filter retains only candidates significantly different from normal tissue, effectively suppressing false positives. Our framework requires no parameter updates, making it compatible with zero-update test-time augmentation and avoiding catastrophic forgetting. On multi-center and multi-modal tumor segmentation benchmarks, R$^{2}$Seg substantially improves Dice, specificity, and sensitivity over strong baselines and the original foundation models. Code are available at https://github.com/Eurekashen/R2Seg.

</details>


### [154] [HEDGE: Hallucination Estimation via Dense Geometric Entropy for VQA with Vision-Language Models](https://arxiv.org/abs/2511.12693)
*Sushant Gautam,Michael A. Riegler,Pål Halvorsen*

Main category: cs.CV

TL;DR: HEDGE是一个统一的幻觉检测框架，通过结合视觉扰动、语义聚类和不确定性度量来检测视觉语言模型中的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在开放域视觉问答中容易产生幻觉，需要系统化的检测方法来评估多模态可靠性。

Method: HEDGE整合了采样、失真合成、聚类（基于蕴含和嵌入）和度量计算，形成可复现的检测流程。

Result: 评估显示，幻觉检测效果取决于模型架构和提示设计，Qwen2.5-VL检测效果最好，VASE度量指标最稳健。

Conclusion: HEDGE将幻觉检测构建为几何鲁棒性问题，为评估多模态可靠性提供了原则性基础，并提供了开源工具库。

Abstract: Vision-language models (VLMs) enable open-ended visual question answering but remain prone to hallucinations. We present HEDGE, a unified framework for hallucination detection that combines controlled visual perturbations, semantic clustering, and robust uncertainty metrics. HEDGE integrates sampling, distortion synthesis, clustering (entailment- and embedding-based), and metric computation into a reproducible pipeline applicable across multimodal architectures.
  Evaluations on VQA-RAD and KvasirVQA-x1 with three representative VLMs (LLaVA-Med, Med-Gemma, Qwen2.5-VL) reveal clear architecture- and prompt-dependent trends. Hallucination detectability is highest for unified-fusion models with dense visual tokenization (Qwen2.5-VL) and lowest for architectures with restricted tokenization (Med-Gemma). Embedding-based clustering often yields stronger separation when applied directly to the generated answers, whereas NLI-based clustering remains advantageous for LLaVA-Med and for longer, sentence-level responses. Across configurations, the VASE metric consistently provides the most robust hallucination signal, especially when paired with embedding clustering and a moderate sampling budget (n ~ 10-15). Prompt design also matters: concise, label-style outputs offer clearer semantic structure than syntactically constrained one-sentence responses.
  By framing hallucination detection as a geometric robustness problem shaped jointly by sampling scale, prompt structure, model architecture, and clustering strategy, HEDGE provides a principled, compute-aware foundation for evaluating multimodal reliability. The hedge-bench PyPI library enables reproducible and extensible benchmarking, with full code and experimental resources available at https://github.com/Simula/HEDGE .

</details>


### [155] [X-VMamba: Explainable Vision Mamba](https://arxiv.org/abs/2511.12694)
*Mohamed A. Mabrok,Yalda Zafari*

Main category: cs.CV

TL;DR: 提出了一个基于可控性的可解释性框架，用于分析视觉状态空间模型（SSMs）处理空间信息的方式，通过两种互补方法量化输入序列对内部状态动态的影响。


<details>
  <summary>Details</summary>
Motivation: 理解视觉SSMs如何处理空间信息具有挑战性，因为缺乏类似Transformer的透明注意力机制，需要开发新的可解释性方法。

Method: 提出了两种方法：适用于所有SSM架构的基于雅可比矩阵的方法，以及针对对角SSMs的基于格拉姆矩阵的方法，两者都只需单次前向传播且具有线性复杂度。

Result: 在三种医学影像模态上的实验表明，SSMs自然实现了从早期层的扩散低层纹理到深层聚焦的临床有意义模式的分层特征细化，揭示了与诊断标准一致的可控性特征。

Conclusion: 该框架将可控性分析确立为跨所有领域的SSMs的统一、基础性可解释性范式，在计算机视觉、自然语言处理和跨领域任务中具有广泛应用。

Abstract: State Space Models (SSMs), particularly the Mamba architecture, have recently emerged as powerful alternatives to Transformers for sequence modeling, offering linear computational complexity while achieving competitive performance. Yet, despite their effectiveness, understanding how these Vision SSMs process spatial information remains challenging due to the lack of transparent, attention-like mechanisms. To address this gap, we introduce a controllability-based interpretability framework that quantifies how different parts of the input sequence (tokens or patches) influence the internal state dynamics of SSMs. We propose two complementary formulations: a Jacobian-based method applicable to any SSM architecture that measures influence through the full chain of state propagation, and a Gramian-based approach for diagonal SSMs that achieves superior speed through closed-form analytical solutions. Both methods operate in a single forward pass with linear complexity, requiring no architectural modifications or hyperparameter tuning. We validate our framework through experiments on three diverse medical imaging modalities, demonstrating that SSMs naturally implement hierarchical feature refinement from diffuse low-level textures in early layers to focused, clinically meaningful patterns in deeper layers. Our analysis reveals domain-specific controllability signatures aligned with diagnostic criteria, progressive spatial selectivity across the network hierarchy, and the substantial influence of scanning strategies on attention patterns. Beyond medical imaging, we articulate applications spanning computer vision, natural language processing, and cross-domain tasks. Our framework establishes controllability analysis as a unified, foundational interpretability paradigm for SSMs across all domains. Code and analysis tools will be made available upon publication

</details>


### [156] [Counting Through Occlusion: Framework for Open World Amodal Counting](https://arxiv.org/abs/2511.12702)
*Safaeid Hossain Arib,Rabeya Akter,Abdul Monaf Chowdhury,Md Jubair Ahmed Sourov,Md Mehedi Hasan*

Main category: cs.CV

TL;DR: CountOCC是一个针对遮挡场景的物体计数框架，通过多模态引导重建被遮挡物体特征，在多种遮挡场景下显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有物体计数方法在遮挡场景下表现不佳，因为主干网络会编码遮挡表面而非目标物体，导致特征表示损坏。需要解决遮挡下的精确计数问题。

Method: 使用层次化多模态引导显式重建被遮挡物体特征，整合可见片段的空间上下文和文本/视觉嵌入的语义先验，在多个金字塔层级生成类别判别性特征。引入视觉等价目标确保遮挡和非遮挡视图产生空间对齐的注意力图。

Result: 在FSC 147数据集上验证集和测试集的MAE分别降低26.72%和20.80%；在CARPK数据集上MAE降低49.89%；在CAPTUREReal数据集上MAE降低28.79%，均达到SOTA性能。

Conclusion: CountOCC通过互补机制在遮挡场景下保持判别性特征，实现了跨视觉领域的鲁棒性模态计数，验证了其有效性。

Abstract: Object counting has achieved remarkable success on visible instances, yet state-of-the-art (SOTA) methods fail under occlusion, a pervasive challenge in real world deployment. This failure stems from a fundamental architectural limitation where backbone networks encode occluding surfaces rather than target objects, thereby corrupting the feature representations required for accurate enumeration. To address this, we present CountOCC, an amodal counting framework that explicitly reconstructs occluded object features through hierarchical multimodal guidance. Rather than accepting degraded encodings, we synthesize complete representations by integrating spatial context from visible fragments with semantic priors from text and visual embeddings, generating class-discriminative features at occluded locations across multiple pyramid levels. We further introduce a visual equivalence objective that enforces consistency in attention space, ensuring that both occluded and unoccluded views of the same scene produce spatially aligned gradient-based attention maps. Together, these complementary mechanisms preserve discriminative properties essential for accurate counting under occlusion. For rigorous evaluation, we establish occlusion-augmented versions of FSC 147 and CARPK spanning both structured and unstructured scenes. CountOCC achieves SOTA performance on FSC 147 with 26.72% and 20.80% MAE reduction over prior baselines under occlusion in validation and test, respectively. CountOCC also demonstrates exceptional generalization by setting new SOTA results on CARPK with 49.89% MAE reduction and on CAPTUREReal with 28.79% MAE reduction, validating robust amodal counting across diverse visual domains. Code will be released soon.

</details>


### [157] [FSDAM: Few-Shot Driving Attention Modeling via Vision-Language Coupling](https://arxiv.org/abs/2511.12708)
*Kaiser Hamid,Can Cui,Khandakar Ashrafi Akbar,Ziran Wang,Nade Liang*

Main category: cs.CV

TL;DR: FSDAM框架仅需约100个标注样本即可实现驾驶员注意力预测和说明生成，比现有方法少两个数量级，展示了在数据受限场景下可解释性驾驶员注意力系统的实用潜力。


<details>
  <summary>Details</summary>
Motivation: 理解驾驶员注视位置和注意力转移原因对于自动驾驶系统解读人类意图和解释其行为至关重要，但现有方法依赖大规模且难以收集的注视数据集。

Method: 提出双路径架构FSDAM，通过分离的空间预测和说明生成模块，结合跨模态对齐保持语义一致性，实现少样本条件下的联合注意力预测和说明生成。

Result: FSDAM在注意力预测方面达到竞争性性能，生成连贯且上下文感知的解释，并在多个驾驶基准测试中表现出强大的零样本泛化能力。

Conclusion: 研究表明，即使监督有限，也能实现有效的注意力条件生成，为数据受限场景下可解释驾驶员注意力系统的实际部署开辟了新可能性。

Abstract: Understanding where drivers look and why they shift their attention is essential for autonomous systems that read human intent and justify their actions. Most existing models rely on large-scale gaze datasets to learn these patterns; however, such datasets are labor-intensive to collect and time-consuming to curate. We present FSDAM (Few-Shot Driver Attention Modeling), a framework that achieves joint attention prediction and caption generation with approximately 100 annotated examples, two orders of magnitude fewer than existing approaches. Our approach introduces a dual-pathway architecture where separate modules handle spatial prediction and caption generation while maintaining semantic consistency through cross-modal alignment. Despite minimal supervision, FSDAM achieves competitive performance on attention prediction, generates coherent, and context-aware explanations. The model demonstrates robust zero-shot generalization across multiple driving benchmarks. This work shows that effective attention-conditioned generation is achievable with limited supervision, opening new possibilities for practical deployment of explainable driver attention systems in data-constrained scenarios.

</details>


### [158] [Backdoor Attacks on Open Vocabulary Object Detectors via Multi-Modal Prompt Tuning](https://arxiv.org/abs/2511.12735)
*Ankita Raj,Chetan Arora*

Main category: cs.CV

TL;DR: 本文首次研究了开放词汇目标检测器（OVODs）的后门攻击，提出了一种基于提示调优的多模态后门注入策略TrAP，通过联合优化图像和文本模态的提示参数及视觉触发器，在不改变基础模型权重的情况下植入后门。


<details>
  <summary>Details</summary>
Motivation: 随着OVODs在机器人、自动驾驶等高风险应用中的普及，理解其安全风险变得至关重要。本文旨在揭示提示调优引入的新攻击面。

Method: 提出TrAP策略，采用课程学习训练策略逐步缩小触发器尺寸，通过联合优化图像和文本模态的提示参数以及视觉触发器来植入后门。

Result: 在多个数据集上的实验表明，TrAP在对象误分类和对象消失攻击中均取得高攻击成功率，同时在下游数据集上相比零样本设置提高了干净图像性能。

Conclusion: TrAP展示了OVODs存在严重的安全漏洞，提示调优可能成为新的攻击向量，需要开发相应的防御机制。

Abstract: Open-vocabulary object detectors (OVODs) unify vision and language to detect arbitrary object categories based on text prompts, enabling strong zero-shot generalization to novel concepts. As these models gain traction in high-stakes applications such as robotics, autonomous driving, and surveillance, understanding their security risks becomes crucial. In this work, we conduct the first study of backdoor attacks on OVODs and reveal a new attack surface introduced by prompt tuning. We propose TrAP (Trigger-Aware Prompt tuning), a multi-modal backdoor injection strategy that jointly optimizes prompt parameters in both image and text modalities along with visual triggers. TrAP enables the attacker to implant malicious behavior using lightweight, learnable prompt tokens without retraining the base model weights, thus preserving generalization while embedding a hidden backdoor. We adopt a curriculum-based training strategy that progressively shrinks the trigger size, enabling effective backdoor activation using small trigger patches at inference. Experiments across multiple datasets show that TrAP achieves high attack success rates for both object misclassification and object disappearance attacks, while also improving clean image performance on downstream datasets compared to the zero-shot setting.

</details>


### [159] [Direct Visual Grounding by Directing Attention of Visual Tokens](https://arxiv.org/abs/2511.12738)
*Parsa Esmaeilkhani,Longin Jan Latecki*

Main category: cs.CV

TL;DR: 论文提出了一种新的注意力监督损失函数KLAL，通过直接监督视觉token的注意力分布来改善视觉语言模型在视觉任务中的表现，解决了视觉token在最终层注意力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型中，与查询最相关的视觉token在LLM模块的最终层获得的注意力很少，这可能导致视觉问题回答错误。标准的下一token预测损失无法有效指导注意力到视觉token。

Method: 提出KL注意力损失(KLAL)，通过KL散度将视觉token的注意力分布与真实注意力图对齐。真实注意力图来自合成案例的任务几何或真实图像的标注，无需新标签。KLAL与NTP损失结合使用。

Result: 该方法在几何任务、指向和指代表达理解等任务上显著提升性能，在合成和真实数据上都有效。还引入了新的线追踪数据集，发现即使商业VLM在该任务上表现也不佳。

Conclusion: 直接监督视觉token的注意力分布能有效改善VLM的视觉任务性能，KLAL损失为VLM提供了更直接的注意力指导信号。

Abstract: Vision Language Models (VLMs) mix visual tokens and text tokens. A puzzling issue is the fact that visual tokens most related to the query receive little to no attention in the final layers of the LLM module of VLMs from the answer tokens, where all tokens are treated equally, in particular, visual and language tokens in the LLM attention layers. This fact may result in wrong answers to visual questions, as our experimental results confirm. It appears that the standard next-token prediction (NTP) loss provides an insufficient signal for directing attention to visual tokens. We hypothesize that a more direct supervision of the attention of visual tokens to corresponding language tokens in the LLM module of VLMs will lead to improved performance on visual tasks. To demonstrate that this is indeed the case, we propose a novel loss function that directly supervises the attention of visual tokens. It directly grounds the answer language tokens in images by directing their attention to the relevant visual tokens. This is achieved by aligning the attention distribution of visual tokens to ground truth attention maps with KL divergence. The ground truth attention maps are obtained from task geometry in synthetic cases or from standard grounding annotations (e.g., bounding boxes or point annotations) in real images, and are used inside the LLM for attention supervision without requiring new labels. The obtained KL attention loss (KLAL) when combined with NTP encourages VLMs to attend to relevant visual tokens while generating answer tokens. This results in notable improvements across geometric tasks, pointing, and referring expression comprehension on both synthetic and real-world data, as demonstrated by our experiments. We also introduce a new dataset to evaluate the line tracing abilities of VLMs. Surprisingly, even commercial VLMs do not perform well on this task.

</details>


### [160] [Deep Imbalanced Multi-Target Regression: 3D Point Cloud Voxel Content Estimation in Simulated Forests](https://arxiv.org/abs/2511.12740)
*Amirhossein Hassanzadeh,Bartosz Krawczyk,Michael Saunders,Rob Wible,Keith Krause,Dimah Dera,Jan van Aardt*

Main category: cs.CV

TL;DR: 本研究探讨了从高体素化LiDAR点云数据推断低级别体素内容信息（目标占用百分比）的可行性，提出了一种基于KPConv的多目标回归方法，并分析了不同体素尺寸对森林场景建模的影响。


<details>
  <summary>Details</summary>
Motivation: 体素化是降低LiDAR数据处理计算成本的有效方法，但会导致细尺度结构信息丢失。本研究旨在探索是否可以从高体素化数据中恢复低级别的体素内容信息，特别是目标在体素内的占用百分比。

Method: 提出基于核点卷积（KPConv）的多目标回归方法，采用密度相关（DBR）的成本敏感学习处理类别不平衡问题，使用加权均方误差、Focal回归和正则化优化KPConv。对不同体素尺寸（0.25-2米）进行敏感性分析。

Result: 较大体素尺寸（如2米）由于变异性降低而误差较小，较小体素尺寸（如0.25或0.5米）在冠层区域误差较高。树皮和叶片目标在较小体素尺寸数据集上的误差显著高于较大体素尺寸数据集。

Conclusion: 体素尺寸的选择取决于具体应用需求。本研究填补了深度不平衡学习模型在多目标回归和森林3D LiDAR点云模拟数据集方面的空白。

Abstract: Voxelization is an effective approach to reduce the computational cost of processing Light Detection and Ranging (LiDAR) data, yet it results in a loss of fine-scale structural information. This study explores whether low-level voxel content information, specifically target occupancy percentage within a voxel, can be inferred from high-level voxelized LiDAR point cloud data collected from Digital Imaging and remote Sensing Image Generation (DIRSIG) software. In our study, the targets include bark, leaf, soil, and miscellaneous materials. We propose a multi-target regression approach in the context of imbalanced learning using Kernel Point Convolutions (KPConv). Our research leverages cost-sensitive learning to address class imbalance called density-based relevance (DBR). We employ weighted Mean Saquared Erorr (MSE), Focal Regression (FocalR), and regularization to improve the optimization of KPConv. This study performs a sensitivity analysis on the voxel size (0.25 - 2 meters) to evaluate the effect of various grid representations in capturing the nuances of the forest. This sensitivity analysis reveals that larger voxel sizes (e.g., 2 meters) result in lower errors due to reduced variability, while smaller voxel sizes (e.g., 0.25 or 0.5 meter) exhibit higher errors, particularly within the canopy, where variability is greatest. For bark and leaf targets, error values at smaller voxel size datasets (0.25 and 0.5 meter) were significantly higher than those in larger voxel size datasets (2 meters), highlighting the difficulty in accurately estimating within-canopy voxel content at fine resolutions. This suggests that the choice of voxel size is application-dependent. Our work fills the gap in deep imbalance learning models for multi-target regression and simulated datasets for 3D LiDAR point clouds of forests.

</details>


### [161] [SAGE: Saliency-Guided Contrastive Embeddings](https://arxiv.org/abs/2511.12744)
*Colton R. Crum,Adam Czajka*

Main category: cs.CV

TL;DR: SAGE提出了一种新的损失函数，通过在模型潜在空间嵌入中使用对比学习来整合人类显著性先验，从而提高分类性能


<details>
  <summary>Details</summary>
Motivation: 现有基于显著性的训练方法依赖不可靠的内部模型机制，且仅在图像空间中进行指导，存在局限性

Method: 使用显著性保持和显著性退化信号增强输入，通过对比三元组损失在嵌入空间中引导模型关注显著特征，并对logit分布进行完整性检查

Result: 在开放和封闭集场景下，SAGE相比最先进的基于显著性的方法都显示出分类性能的提升，并在各种骨干网络和任务中具有良好的泛化性

Conclusion: 将人类显著性指导从图像空间转移到模型潜在空间是更有效的方法，SAGE为高风险领域应用提供了可靠的人类对齐解决方案

Abstract: Integrating human perceptual priors into the training of neural networks has been shown to raise model generalization, serve as an effective regularizer, and align models with human expertise for applications in high-risk domains. Existing approaches to integrate saliency into model training often rely on internal model mechanisms, which recent research suggests may be unreliable. Our insight is that many challenges associated with saliency-guided training stem from the placement of the guidance approaches solely within the image space. Instead, we move away from the image space, use the model's latent space embeddings to steer human guidance during training, and we propose SAGE (Saliency-Guided Contrastive Embeddings): a loss function that integrates human saliency into network training using contrastive embeddings. We apply salient-preserving and saliency-degrading signal augmentations to the input and capture the changes in embeddings and model logits. We guide the model towards salient features and away from non-salient features using a contrastive triplet loss. Additionally, we perform a sanity check on the logit distributions to ensure that the model outputs match the saliency-based augmentations. We demonstrate a boost in classification performance across both open- and closed-set scenarios against SOTA saliency-based methods, showing SAGE's effectiveness across various backbones, and include experiments to suggest its wide generalization across tasks.

</details>


### [162] [Which Way from B to A: The role of embedding geometry in image interpolation for Stable Diffusion](https://arxiv.org/abs/2511.12757)
*Nicholas Karris,Luke Durell,Javier Flores,Tegan Emerson*

Main category: cs.CV

TL;DR: 本文发现Stable Diffusion的CLIP嵌入具有置换不变性，可视为Wasserstein空间中的点云而非欧几里得空间中的矩阵。通过将嵌入插值问题重构为最优传输问题，能生成更平滑的图像插值。


<details>
  <summary>Details</summary>
Motivation: 传统方法将CLIP嵌入视为矩阵进行线性插值，但忽略了嵌入空间的几何结构。本文发现嵌入的置换不变性表明它们更适合被解释为点云，这启发了基于最优传输的新插值方法。

Method: 将嵌入插值问题重构为Wasserstein空间中的最优传输问题，计算嵌入之间的最短路径（测地线）。通过求解最优传输问题获得更自然的几何平滑过渡。

Result: 实验表明，基于最优传输的插值方法相比标准线性插值能产生更平滑、更连贯的中间图像，图像质量显著提升。

Conclusion: 将CLIP嵌入视为点云而非矩阵能更好地反映和利用嵌入空间的几何结构，最优传输方法为理解生成模型的嵌入空间几何提供了新视角。

Abstract: It can be shown that Stable Diffusion has a permutation-invariance property with respect to the rows of Contrastive Language-Image Pretraining (CLIP) embedding matrices. This inspired the novel observation that these embeddings can naturally be interpreted as point clouds in a Wasserstein space rather than as matrices in a Euclidean space. This perspective opens up new possibilities for understanding the geometry of embedding space. For example, when interpolating between embeddings of two distinct prompts, we propose reframing the interpolation problem as an optimal transport problem. By solving this optimal transport problem, we compute a shortest path (or geodesic) between embeddings that captures a more natural and geometrically smooth transition through the embedding space. This results in smoother and more coherent intermediate (interpolated) images when rendered by the Stable Diffusion generative model. We conduct experiments to investigate this effect, comparing the quality of interpolated images produced using optimal transport to those generated by other standard interpolation methods. The novel optimal transport--based approach presented indeed gives smoother image interpolations, suggesting that viewing the embeddings as point clouds (rather than as matrices) better reflects and leverages the geometry of the embedding space.

</details>


### [163] [RoCoISLR: A Romanian Corpus for Isolated Sign Language Recognition](https://arxiv.org/abs/2511.12767)
*Cătălin-Alexandru Rîpanu,Andrei-Theodor Hotnog,Giulia-Stefania Imbrea,Dumitru-Clementin Cercel*

Main category: cs.CV

TL;DR: 该论文介绍了首个罗马尼亚孤立手语识别数据集RoCoISLR，包含9000多个视频样本，覆盖近6000个标准词汇，并评估了7种先进视频识别模型的性能。


<details>
  <summary>Details</summary>
Motivation: 解决罗马尼亚孤立手语识别缺乏大规模标准化数据集的问题，推动该领域的研究进展。

Method: 构建RoCoISLR数据集，并在一致实验设置下评估I3D、SlowFast、Swin Transformer等7种视频识别模型。

Result: 基于Transformer的架构优于卷积基线，Swin Transformer达到34.1%的Top-1准确率，但长尾类别分布仍是挑战。

Conclusion: RoCoISLR为罗马尼亚手语识别研究提供了基础，揭示了低资源手语识别中的挑战。

Abstract: Automatic sign language recognition plays a crucial role in bridging the communication gap between deaf communities and hearing individuals; however, most available datasets focus on American Sign Language. For Romanian Isolated Sign Language Recognition (RoISLR), no large-scale, standardized dataset exists, which limits research progress. In this work, we introduce a new corpus for RoISLR, named RoCoISLR, comprising over 9,000 video samples that span nearly 6,000 standardized glosses from multiple sources. We establish benchmark results by evaluating seven state-of-the-art video recognition models-I3D, SlowFast, Swin Transformer, TimeSformer, Uniformer, VideoMAE, and PoseConv3D-under consistent experimental setups, and compare their performance with that of the widely used WLASL2000 corpus. According to the results, transformer-based architectures outperform convolutional baselines; Swin Transformer achieved a Top-1 accuracy of 34.1%. Our benchmarks highlight the challenges associated with long-tail class distributions in low-resource sign languages, and RoCoISLR provides the initial foundation for systematic RoISLR research.

</details>


### [164] [Lightweight Optimal-Transport Harmonization on Edge Devices](https://arxiv.org/abs/2511.12785)
*Maria Larchenko,Dmitry Guskov,Alexander Lobashev,Georgy Derevyanko*

Main category: cs.CV

TL;DR: 提出了一种轻量级的实时色彩协调方法MKL-Harmonizer，用于增强现实场景，通过最优传输理论实现快速色彩调整。


<details>
  <summary>Details</summary>
Motivation: 当前色彩协调算法缺乏实时解决方案，无法集成到AR流水线中，需要开发支持设备端推理的轻量级方法。

Method: 利用经典最优传输理论，训练紧凑编码器预测Monge-Kantorovich传输映射，实现实时色彩协调。

Result: 在真实AR合成图像上，MKL-Harmonizer方法获得了最佳综合评分，优于现有最先进方法。

Conclusion: 该方法成功解决了AR场景下的实时色彩协调问题，并发布了专用AR数据集和工具包以支持进一步研究。

Abstract: Color harmonization adjusts the colors of an inserted object so that it perceptually matches the surrounding image, resulting in a seamless composite. The harmonization problem naturally arises in augmented reality (AR), yet harmonization algorithms are not currently integrated into AR pipelines because real-time solutions are scarce. In this work, we address color harmonization for AR by proposing a lightweight approach that supports on-device inference. For this, we leverage classical optimal transport theory by training a compact encoder to predict the Monge-Kantorovich transport map. We benchmark our MKL-Harmonizer algorithm against state-of-the-art methods and demonstrate that for real composite AR images our method achieves the best aggregated score. We release our dedicated AR dataset of composite images with pixel-accurate masks and data-gathering toolkit to support further data acquisition by researchers.

</details>


### [165] [Enhancing Neuro-Oncology Through Self-Assessing Deep Learning Models for Brain Tumor Unified Model for MRI Segmentation](https://arxiv.org/abs/2511.12801)
*Andrew Zhou*

Main category: cs.CV

TL;DR: 提出了一个不确定性感知的脑肿瘤分割框架，结合nnUNet和体素级不确定性通道，同时分割肿瘤和健康脑结构，为临床手术决策提供关键信息。


<details>
  <summary>Details</summary>
Motivation: 解决当前脑肿瘤分割方法缺乏不确定性估计和周围健康脑结构分割的问题，这些限制影响了深度学习模型在临床手术规划中的实际应用。

Method: 在nnUNet基础上增加体素级不确定性通道，使用BraTS2023数据集训练，单次推理即可同时获得分割结果和不确定性图。通过统一正常和癌症数据集实现全脑结构分割。

Result: 不确定性估计达到0.750的相关性和0.047的RMSD，不影响肿瘤分割精度；全脑结构分割DSC为0.81，肿瘤分割DSC为0.86，关键区域表现稳健。

Conclusion: 该模型首次实现了肿瘤在自然环境中分割并叠加不确定性图，为临床医生提供评估预测和修正错误的视觉依据，有助于AI辅助的知情手术决策。

Abstract: Accurate segmentation of brain tumors is vital for diagnosis, surgical planning, and treatment monitoring. Deep learning has advanced on benchmarks, but two issues limit clinical use: no uncertainty estimates for errors and no segmentation of healthy brain structures around tumors for surgery. Current methods fail to unify tumor localization with anatomical context and lack confidence scores. This study presents an uncertainty-aware framework augmenting nnUNet with a channel for voxel-wise uncertainty. Trained on BraTS2023, it yields a correlation of 0.750 and RMSD of 0.047 for uncertainty without hurting tumor accuracy. It predicts uncertainty in one pass, with no extra networks or inferences, aiding clinical decisions. For whole-brain context, a unified model combines normal and cancer datasets, achieving a DSC of 0.81 for brain structures and 0.86 for tumor, with robust key-region performance. Combining both innovations gives the first model outputting tumor in natural surroundings plus an overlaid uncertainty map. Visual checks of outputs show uncertainty offers key insights to evaluate predictions and fix errors, helping informed surgical decisions from AI.

</details>


### [166] [MSRNet: A Multi-Scale Recursive Network for Camouflaged Object Detection](https://arxiv.org/abs/2511.12810)
*Leena Alghamdi,Muhammad Usman,Hafeez Anwar,Abdul Bais,Saeed Anwar*

Main category: cs.CV

TL;DR: 提出了一种多尺度递归网络MSRNet，用于检测伪装物体，通过金字塔视觉Transformer和多粒度融合单元，在复杂场景中实现了对小尺寸和多个伪装物体的精确检测。


<details>
  <summary>Details</summary>
Motivation: 当前伪装物体检测方法在复杂场景（如低光照、部分遮挡、小物体、复杂背景模式和多物体）中表现不佳，特别是对小尺寸和多个物体的检测精度有限，需要改进。

Method: 使用金字塔视觉Transformer提取多尺度特征，通过注意力机制整合多尺度信息，解码器采用递归反馈策略和多粒度融合单元优化特征。

Result: 在两个基准数据集上达到最先进性能，在另外两个数据集上排名第二，代码和模型权重已开源。

Conclusion: 多尺度学习和递归特征优化的联合使用有效提升了伪装物体检测性能，特别是在小尺寸和多个物体的检测方面。

Abstract: Camouflaged object detection is an emerging and challenging computer vision task that requires identifying and segmenting objects that blend seamlessly into their environments due to high similarity in color, texture, and size. This task is further complicated by low-light conditions, partial occlusion, small object size, intricate background patterns, and multiple objects. While many sophisticated methods have been proposed for this task, current methods still struggle to precisely detect camouflaged objects in complex scenarios, especially with small and multiple objects, indicating room for improvement. We propose a Multi-Scale Recursive Network that extracts multi-scale features via a Pyramid Vision Transformer backbone and combines them via specialized Attention-Based Scale Integration Units, enabling selective feature merging. For more precise object detection, our decoder recursively refines features by incorporating Multi-Granularity Fusion Units. A novel recursive-feedback decoding strategy is developed to enhance global context understanding, helping the model overcome the challenges in this task. By jointly leveraging multi-scale learning and recursive feature optimization, our proposed method achieves performance gains, successfully detecting small and multiple camouflaged objects. Our model achieves state-of-the-art results on two benchmark datasets for camouflaged object detection and ranks second on the remaining two. Our codes, model weights, and results are available at \href{https://github.com/linaagh98/MSRNet}{https://github.com/linaagh98/MSRNet}.

</details>


### [167] [SAGA: Source Attribution of Generative AI Videos](https://arxiv.org/abs/2511.12834)
*Rohit Kundu,Vishal Mohanty,Hao Xiong,Shan Jia,Athula Balachandran,Amit K. Roy-Chowdhury*

Main category: cs.CV

TL;DR: SAGA是首个针对AI生成视频的大规模溯源框架，通过多粒度属性识别和高效预训练策略，在仅使用0.5%标注数据的情况下实现最先进的溯源性能。


<details>
  <summary>Details</summary>
Motivation: 生成式AI的快速发展导致超逼真合成视频泛滥，传统真假检测器已无法应对滥用风险，迫切需要能识别具体生成模型的溯源方法。

Method: 提出新颖的视频Transformer架构，利用鲁棒视觉基础模型特征捕捉时空伪影；采用数据高效的预训练-属性策略；引入时序注意力签名(T-Sigs)可解释性方法。

Result: 在公开数据集上的广泛实验表明，SAGA在跨域场景下为合成视频溯源设立了新基准，性能达到完全监督水平。

Conclusion: SAGA为法医和监管应用提供了关键且可解释的溯源洞察，是解决AI生成视频滥用问题的重要进展。

Abstract: The proliferation of generative AI has led to hyper-realistic synthetic videos, escalating misuse risks and outstripping binary real/fake detectors. We introduce SAGA (Source Attribution of Generative AI videos), the first comprehensive framework to address the urgent need for AI-generated video source attribution at a large scale. Unlike traditional detection, SAGA identifies the specific generative model used. It uniquely provides multi-granular attribution across five levels: authenticity, generation task (e.g., T2V/I2V), model version, development team, and the precise generator, offering far richer forensic insights. Our novel video transformer architecture, leveraging features from a robust vision foundation model, effectively captures spatio-temporal artifacts. Critically, we introduce a data-efficient pretrain-and-attribute strategy, enabling SAGA to achieve state-of-the-art attribution using only 0.5\% of source-labeled data per class, matching fully supervised performance. Furthermore, we propose Temporal Attention Signatures (T-Sigs), a novel interpretability method that visualizes learned temporal differences, offering the first explanation for why different video generators are distinguishable. Extensive experiments on public datasets, including cross-domain scenarios, demonstrate that SAGA sets a new benchmark for synthetic video provenance, providing crucial, interpretable insights for forensic and regulatory applications.

</details>


### [168] [Video Finetuning Improves Reasoning Between Frames](https://arxiv.org/abs/2511.12868)
*Ruiqi Yang,Tian Yun,Zihan Wang,Ellie Pavlick*

Main category: cs.CV

TL;DR: 该论文提出了一种名为Visual Chain-of-Thought (vCoT)的显式推理过程，用于生成连续帧之间的过渡事件描述。通过vCoT，系统比较了仅图像模型和视频微调模型在长视频问答任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在视觉理解方面进展迅速，但从图像扩展到视频时往往只是简单拼接帧标记。本研究旨在探索视频微调对多模态大语言模型的实际贡献。

Method: 提出vCoT方法，生成连续帧之间的过渡事件描述。使用vCoT系统比较图像模型和视频微调模型，在有/无过渡线索的情况下评估它们在长视频问答任务中的表现。

Result: vCoT显著提高了仅图像模型在长视频问答中的性能，但对视频微调模型的提升有限。视频模型能够将时序推理能力迁移到静态场景，在关系视觉推理任务中优于图像模型基线。

Conclusion: 视频微调模型已经隐式地捕获了帧间过渡信息，并且具备将时序推理能力迁移到静态场景的能力。

Abstract: Multimodal large language models (LLMs) have made rapid progress in visual understanding, yet their extension from images to videos often reduces to a naive concatenation of frame tokens. In this work, we investigate what video finetuning brings to multimodal LLMs. We propose Visual Chain-of-Thought (vCoT), an explicit reasoning process that generates transitional event descriptions between consecutive frames. Using vCoT, we systematically compare image-only LVLMs with their video-finetuned counterparts, both with and without access to these transitional cues. Our experiments show that vCoT significantly improves the performance of image-only models on long-form video question answering, while yielding only marginal gains for video-finetuned models. This suggests that the latter already capture frame-to-frame transitions implicitly. Moreover, we find that video models transfer this temporal reasoning ability to purely static settings, outperforming image models' baselines on relational visual reasoning tasks.

</details>


### [169] [View-aware Cross-modal Distillation for Multi-view Action Recognition](https://arxiv.org/abs/2511.12870)
*Trung Thanh Nguyen,Yasutomo Kawanishi,Vijay John,Takahiro Komamizu,Ichiro Ide*

Main category: cs.CV

TL;DR: 本文提出ViCoKD框架，通过跨模态知识蒸馏解决部分重叠多视图动作识别问题，在有限模态和标注条件下提升学生模型性能


<details>
  <summary>Details</summary>
Motivation: 现实世界中多传感器系统常存在视图部分重叠、模态有限且只有序列级标注的问题，现有方法对此研究不足

Method: 使用跨模态适配器和注意力机制，引入视图感知一致性模块处理视图不对齐问题，通过Jensen-Shannon散度实现预测对齐

Result: 在MultiSensor-Home数据集上，ViCoKD在不同骨干网络和环境下均优于竞争方法，在有限条件下甚至超越教师模型

Conclusion: ViCoKD框架有效解决了部分重叠多视图动作识别中的模态和标注限制问题，具有实际应用价值

Abstract: The widespread use of multi-sensor systems has increased research in multi-view action recognition. While existing approaches in multi-view setups with fully overlapping sensors benefit from consistent view coverage, partially overlapping settings where actions are visible in only a subset of views remain underexplored. This challenge becomes more severe in real-world scenarios, as many systems provide only limited input modalities and rely on sequence-level annotations instead of dense frame-level labels. In this study, we propose View-aware Cross-modal Knowledge Distillation (ViCoKD), a framework that distills knowledge from a fully supervised multi-modal teacher to a modality- and annotation-limited student. ViCoKD employs a cross-modal adapter with cross-modal attention, allowing the student to exploit multi-modal correlations while operating with incomplete modalities. Moreover, we propose a View-aware Consistency module to address view misalignment, where the same action may appear differently or only partially across viewpoints. It enforces prediction alignment when the action is co-visible across views, guided by human-detection masks and confidence-weighted Jensen-Shannon divergence between their predicted class distributions. Experiments on the real-world MultiSensor-Home dataset show that ViCoKD consistently outperforms competitive distillation methods across multiple backbones and environments, delivering significant gains and surpassing the teacher model under limited conditions.

</details>


### [170] [Simple Lines, Big Ideas: Towards Interpretable Assessment of Human Creativity from Drawings](https://arxiv.org/abs/2511.12880)
*Zihao Lin,Zhenshan Shi,Sasa Zhao,Hanwei Zhu,Lingyu Zhu,Baoliang Chen,Lei Mo*

Main category: cs.CV

TL;DR: 提出了一种基于数据驱动的自动可解释性绘画创造力评估框架，将创造力重新解释为内容（画什么）和风格（怎么画）两个互补维度的函数。


<details>
  <summary>Details</summary>
Motivation: 当前绘画创造力评估主要依赖专家主观评分，这种方法既耗时又主观。需要一种自动且可解释的评估方法来替代传统主观评估。

Method: 提出多模态多任务学习框架，同时预测创造力分数、分类内容类型和提取风格特征。引入条件学习机制，使模型能够根据绘画的风格和语义线索动态调整视觉特征提取。

Result: 实验结果表明，该模型相比现有基于回归的方法达到了最先进的性能，并提供了与人类判断一致的视觉化解释。

Conclusion: 该框架为自动评估绘画创造力提供了一种有效且可解释的方法，有助于推动创造力评估的客观化和自动化发展。

Abstract: Assessing human creativity through visual outputs, such as drawings, plays a critical role in fields including psychology, education, and cognitive science. However, current assessment practices still rely heavily on expert-based subjective scoring, which is both labor-intensive and inherently subjective. In this paper, we propose a data-driven framework for automatic and interpretable creativity assessment from drawings. Motivated by the cognitive understanding that creativity can emerge from both what is drawn (content) and how it is drawn (style), we reinterpret the creativity score as a function of these two complementary dimensions.Specifically, we first augment an existing creativity labeled dataset with additional annotations targeting content categories. Based on the enriched dataset, we further propose a multi-modal, multi-task learning framework that simultaneously predicts creativity scores, categorizes content types, and extracts stylistic features. In particular, we introduce a conditional learning mechanism that enables the model to adapt its visual feature extraction by dynamically tuning it to creativity-relevant signals conditioned on the drawing's stylistic and semantic cues.Experimental results demonstrate that our model achieves state-of-the-art performance compared to existing regression-based approaches and offers interpretable visualizations that align well with human judgments. The code and annotations will be made publicly available at https://github.com/WonderOfU9/CSCA_PRCV_2025

</details>


### [171] [ActVAR: Activating Mixtures of Weights and Tokens for Efficient Visual Autoregressive Generation](https://arxiv.org/abs/2511.12893)
*Kaixin Zhang,Ruiqing Yang,Yuan Zhang,Shan You,Tao Huang*

Main category: cs.CV

TL;DR: ActVAR是一个动态激活框架，通过引入权重和令牌序列的双重稀疏性来提升VAR模型的效率，在不牺牲性能的情况下减少计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有静态剪枝方法通过永久移除权重或令牌来降低计算成本，但会破坏预训练依赖关系并导致性能下降。需要一种动态方法来保持模型容量同时提升效率。

Method: ActVAR将前馈网络分解为轻量级专家子网络，使用可学习路由器动态选择令牌特定的专家子集，同时通过门控令牌选择器识别高更新潜力的令牌进行计算，并重构未选令牌以保持全局上下文。采用两阶段知识蒸馏策略训练。

Result: 在ImageNet 256×256基准测试中，ActVAR实现了高达21.2%的FLOPs减少，且性能下降最小。

Conclusion: ActVAR通过动态激活机制有效平衡了VAR模型的效率和性能，为大规模视觉自回归模型提供了实用的加速方案。

Abstract: Visual Autoregressive (VAR) models enable efficient image generation via next-scale prediction but face escalating computational costs as sequence length grows. Existing static pruning methods degrade performance by permanently removing weights or tokens, disrupting pretrained dependencies. To address this, we propose ActVAR, a dynamic activation framework that introduces dual sparsity across model weights and token sequences to enhance efficiency without sacrificing capacity. ActVAR decomposes feedforward networks (FFNs) into lightweight expert sub-networks and employs a learnable router to dynamically select token-specific expert subsets based on content. Simultaneously, a gated token selector identifies high-update-potential tokens for computation while reconstructing unselected tokens to preserve global context and sequence alignment. Training employs a two-stage knowledge distillation strategy, where the original VAR model supervises the learning of routing and gating policies to align with pretrained knowledge. Experiments on the ImageNet $256\times 256$ benchmark demonstrate that ActVAR achieves up to $21.2\%$ FLOPs reduction with minimal performance degradation.

</details>


### [172] [Reconstructing 3D Scenes in Native High Dynamic Range](https://arxiv.org/abs/2511.12895)
*Kaixuan Zhang,Minxian Li,Mingwu Ren,Jiankang Deng,Xiatian Zhu*

Main category: cs.CV

TL;DR: 提出了首个直接建模原生HDR观测数据的3D场景重建方法NH-3DGS，通过亮度-色度分解技术实现从原生HDR相机数据的直接优化


<details>
  <summary>Details</summary>
Motivation: 专业数字媒体制作需要HDR成像，但现有3D场景重建主要基于LDR数据，依赖多曝光融合或逆色调映射方法，增加了捕获复杂性并依赖合成监督

Method: 提出NH-3DGS方法，采用新颖的亮度-色度分解颜色表示，在整个重建流程中保持完整动态范围，实现从原生HDR相机数据的直接优化

Result: 在合成和真实多视角HDR数据集上，NH-3DGS在重建质量和动态范围保持方面显著优于现有方法

Conclusion: NH-3DGS能够直接从原生HDR捕获实现专业级3D重建，代码和数据集将公开

Abstract: High Dynamic Range (HDR) imaging is essential for professional digital media creation, e.g., filmmaking, virtual production, and photorealistic rendering. However, 3D scene reconstruction has primarily focused on Low Dynamic Range (LDR) data, limiting its applicability to professional workflows. Existing approaches that reconstruct HDR scenes from LDR observations rely on multi-exposure fusion or inverse tone-mapping, which increase capture complexity and depend on synthetic supervision. With the recent emergence of cameras that directly capture native HDR data in a single exposure, we present the first method for 3D scene reconstruction that directly models native HDR observations. We propose {\bf Native High dynamic range 3D Gaussian Splatting (NH-3DGS)}, which preserves the full dynamic range throughout the reconstruction pipeline. Our key technical contribution is a novel luminance-chromaticity decomposition of the color representation that enables direct optimization from native HDR camera data. We demonstrate on both synthetic and real multi-view HDR datasets that NH-3DGS significantly outperforms existing methods in reconstruction quality and dynamic range preservation, enabling professional-grade 3D reconstruction directly from native HDR captures. Code and datasets will be made available.

</details>


### [173] [FDP: A Frequency-Decomposition Preprocessing Pipeline for Unsupervised Anomaly Detection in Brain MRI](https://arxiv.org/abs/2511.12899)
*Hao Li,Zhenfeng Zhuang,Jingyu Lin,Yu Liu,Yifei Chen,Qiong Peng,Lequan Yu,Liansheng Wang*

Main category: cs.CV

TL;DR: 该论文提出了一种基于频域分解预处理（FDP）的无监督异常检测方法，通过分析脑MRI病理特征在频域的独特模式，显著提升了现有异常检测方法的性能。


<details>
  <summary>Details</summary>
Motivation: 由于脑解剖结构的多样性和标注数据的稀缺性，脑MRI的无监督异常检测面临挑战。现有方法使用人工生成的噪声扰动来训练重建模型，但这些模拟异常缺乏真实临床病变的生物物理保真度和形态复杂性。

Method: 通过系统的频域分析发现异常具有独特的频率模式，而低频信号在健康扫描中保持一致性。基于此提出了FDP框架，利用频域重建同时实现病理抑制和解剖结构保留，可无缝集成到现有异常模拟技术中。

Result: 实验结果表明FDP能持续提升异常检测性能，与LDM结合时DICE分数提高了17.63%，并在多个基线方法上都保持了稳健的改进。

Conclusion: FDP是首个利用频域重建进行病理抑制和解剖保留的UAD方法，为脑MRI异常检测提供了新的有效解决方案，代码已开源。

Abstract: Due to the diversity of brain anatomy and the scarcity of annotated data, supervised anomaly detection for brain MRI remains challenging, driving the development of unsupervised anomaly detection (UAD) approaches. Current UAD methods typically utilize artificially generated noise perturbations on healthy MRIs to train generative models for normal anatomy reconstruction, enabling anomaly detection via residual mapping. However, such simulated anomalies lack the biophysical fidelity and morphological complexity characteristic of true clinical lesions. To advance UAD in brain MRI, we conduct the first systematic frequency-domain analysis of pathological signatures, revealing two key properties: (1) anomalies exhibit unique frequency patterns distinguishable from normal anatomy, and (2) low-frequency signals maintain consistent representations across healthy scans. These insights motivate our Frequency-Decomposition Preprocessing (FDP) framework, the first UAD method to leverage frequency-domain reconstruction for simultaneous pathology suppression and anatomical preservation. FDP can integrate seamlessly with existing anomaly simulation techniques, consistently enhancing detection performance across diverse architectures while maintaining diagnostic fidelity. Experimental results demonstrate that FDP consistently improves anomaly detection performance when integrated with existing methods. Notably, FDP achieves a 17.63% increase in DICE score with LDM while maintaining robust improvements across multiple baselines. The code is available at https://github.com/ls1rius/MRI_FDP.

</details>


### [174] [DeepSport: A Multimodal Large Language Model for Comprehensive Sports Video Reasoning via Agentic Reinforcement Learning](https://arxiv.org/abs/2511.12908)
*Junbo Zou,Haotian Xia,Zhen Ye,Shengjie Zhang,Christopher Lai,Vicente Ordonez,Weining Shen,Hanjie Chen*

Main category: cs.CV

TL;DR: DeepSport是首个端到端训练的多任务、多运动视频理解MLLM框架，通过主动迭代推理和专门设计的帧提取工具，在6.7k问题测试基准上实现SOTA性能


<details>
  <summary>Details</summary>
Motivation: 当前体育视频理解研究存在单运动专注、任务局限或缺乏学习推理过程的问题，需要解决多运动、多任务的统一理解框架

Method: 提出数据蒸馏管道合成高质量CoT轨迹，采用两阶段训练策略（SFT+RL）和新型门控工具使用奖励机制，实现主动视频推理

Result: 在6.7k问题测试基准上显著优于专有模型和开源模型基线，达到最先进性能

Conclusion: DeepSport为特定领域视频推理建立了新基础，能够应对多样化体育的复杂性

Abstract: Sports video understanding presents unique challenges, requiring models to perceive high-speed dynamics, comprehend complex rules, and reason over long temporal contexts. While Multimodal Large Language Models (MLLMs) have shown promise in genral domains, the current state of research in sports remains narrowly focused: existing approaches are either single-sport centric, limited to specific tasks, or rely on training-free paradigms that lack robust, learned reasoning process. To address this gap, we introduce DeepSport, the first end-to-end trained MLLM framework designed for multi-task, multi-sport video understanding. DeepSport shifts the paradigm from passive frame processing to active, iterative reasoning, empowering the model to ``think with videos'' by dynamically interrogating content via a specialized frame-extraction tool. To enable this, we propose a data distillation pipeline that synthesizes high-quality Chain-of-Thought (CoT) trajectories from 10 diverse data source, creating a unified resource of 78k training data. We then employ a two-stage training strategy, Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL) with a novel gated tool-use reward, to optimize the model's reasoning process. Extensive experiments on the testing benchmark of 6.7k questions demonstrate that DeepSport achieves state-of-the-art performance, significantly outperforming baselines of both proprietary model and open-source models. Our work establishes a new foundation for domain-specific video reasoning to address the complexities of diverse sports.

</details>


### [175] [CASL: Curvature-Augmented Self-supervised Learning for 3D Anomaly Detection](https://arxiv.org/abs/2511.12909)
*Yaohua Zha,Xue Yuerong,Chunlin Fan,Yuansong Wang,Tao Dai,Ke Chen,Shu-Tao Xia*

Main category: cs.CV

TL;DR: 提出了基于曲率增强的自监督学习框架CASL，用于3D异常检测，无需特定任务设计即可实现领先性能，并能泛化到其他3D理解任务。


<details>
  <summary>Details</summary>
Motivation: 现有3D异常检测方法通用性差，而自监督点云模型在异常检测任务上表现不佳，需要开发更通用的3D模型。

Method: 基于U-Net架构，引入多尺度曲率提示来指导解码器预测点的空间坐标，通过重建范式进行自监督学习。

Result: 仅使用曲率作为异常评分就超越多个经典模型，CASL框架在异常检测任务上达到领先性能，且能良好泛化到点云分类等任务。

Conclusion: 曲率在3D异常检测中具有关键作用，CASL框架证明了无需专用异常检测机制即可实现高性能和良好泛化能力。

Abstract: Deep learning-based 3D anomaly detection methods have demonstrated significant potential in industrial manufacturing. However, many approaches are specifically designed for anomaly detection tasks, which limits their generalizability to other 3D understanding tasks. In contrast, self-supervised point cloud models aim for general-purpose representation learning, yet our investigation reveals that these classical models are suboptimal at anomaly detection under the unified fine-tuning paradigm. This motivates us to develop a more generalizable 3D model that can effectively detect anomalies without relying on task-specific designs. Interestingly, we find that using only the curvature of each point as its anomaly score already outperforms several classical self-supervised and dedicated anomaly detection models, highlighting the critical role of curvature in 3D anomaly detection. In this paper, we propose a Curvature-Augmented Self-supervised Learning (CASL) framework based on a reconstruction paradigm. Built upon the classical U-Net architecture, our approach introduces multi-scale curvature prompts to guide the decoder in predicting the spatial coordinates of each point. Without relying on any dedicated anomaly detection mechanisms, it achieves leading detection performance through straightforward anomaly classification fine-tuning. Moreover, the learned representations generalize well to standard 3D understanding tasks such as point cloud classification. The code is available at https://github.com/zyh16143998882/CASL.

</details>


### [176] [Explore How to Inject Beneficial Noise in MLLMs](https://arxiv.org/abs/2511.12917)
*Ruishu Zhu,Sida Huang,Ziheng Jiao,Hongyuan Zhang*

Main category: cs.CV

TL;DR: 提出了一种新的多模态大语言模型微调策略，通过注入有益随机噪声来改善跨模态表示对齐，仅需调整1-2%的参数即可超越全参数微调效果


<details>
  <summary>Details</summary>
Motivation: 现有微调方法往往忽略跨模态异质性，限制了多模态大语言模型的潜力发挥

Method: 设计了多模态噪声生成器(MuNG)，从变分推断角度重新表述MLLM的推理过程，动态分析图像-文本对的跨模态关系来生成任务自适应的有益噪声

Result: 在QwenVL和LLaVA上的实验表明，该方法超越了全参数微调和其他现有微调方法，仅需调整约1-2%的额外参数

Conclusion: 通过注入有益噪声可以有效抑制不相关语义成分，显著改善跨模态表示对齐，提升下游任务性能

Abstract: Multimodal Large Language Models (MLLMs) have played an increasingly important role in multimodal intelligence. However, the existing fine-tuning methods often ignore cross-modal heterogeneity, limiting their full potential. In this work, we propose a novel fine-tuning strategy by injecting beneficial random noise, which outperforms previous methods and even surpasses full fine-tuning, with minimal additional parameters. The proposed Multimodal Noise Generator (MuNG) enables efficient modality fine-tuning by injecting customized noise into the frozen MLLMs. Specifically, we reformulate the reasoning process of MLLMs from a variational inference perspective, upon which we design a multimodal noise generator that dynamically analyzes cross-modal relationships in image-text pairs to generate task-adaptive beneficial noise. Injecting this type of noise into the MLLMs effectively suppresses irrelevant semantic components, leading to significantly improved cross-modal representation alignment and enhanced performance on downstream tasks. Experiments on two mainstream MLLMs, QwenVL and LLaVA, demonstrate that our method surpasses full-parameter fine-tuning and other existing fine-tuning approaches, while requiring adjustments to only about $1\sim2\%$ additional parameters. The relevant code is uploaded in the supplementary.

</details>


### [177] [CoordAR: One-Reference 6D Pose Estimation of Novel Objects via Autoregressive Coordinate Map Generation](https://arxiv.org/abs/2511.12919)
*Dexin Zuo,Ang Li,Wei Wang,Wenxian Yu,Danping Zou*

Main category: cs.CV

TL;DR: CoordAR是一个新颖的自回归框架，用于未见物体的单参考6D姿态估计，通过将3D-3D对应关系建模为离散标记图，在多个基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于单参考视图的6D姿态估计方法存在两个主要问题：1）卷积架构的局部性导致全局一致性有限；2）缺乏不确定性建模，在对称或遮挡场景中表现不佳。

Method: CoordAR采用自回归框架，将3D-3D对应关系建模为离散标记图。关键技术包括：1）坐标图标记化实现概率预测；2）模态解耦编码策略分别处理RGB外观和坐标线索；3）基于位置对齐查询特征和部分生成标记序列的自回归变换器解码器。

Result: CoordAR在多个基准测试中显著优于现有方法，并在真实世界测试中对对称性、遮挡等挑战表现出强大的鲁棒性。

Conclusion: CoordAR通过自回归建模和概率预测框架，成功解决了单参考6D姿态估计中的全局一致性和不确定性建模问题，为未见物体的姿态估计提供了有效的解决方案。

Abstract: Object 6D pose estimation, a crucial task for robotics and augmented reality applications, becomes particularly challenging when dealing with novel objects whose 3D models are not readily available. To reduce dependency on 3D models, recent studies have explored one-reference-based pose estimation, which requires only a single reference view instead of a complete 3D model. However, existing methods that rely on real-valued coordinate regression suffer from limited global consistency due to the local nature of convolutional architectures and face challenges in symmetric or occluded scenarios owing to a lack of uncertainty modeling. We present CoordAR, a novel autoregressive framework for one-reference 6D pose estimation of unseen objects. CoordAR formulates 3D-3D correspondences between the reference and query views as a map of discrete tokens, which is obtained in an autoregressive and probabilistic manner. To enable accurate correspondence regression, CoordAR introduces 1) a novel coordinate map tokenization that enables probabilistic prediction over discretized 3D space; 2) a modality-decoupled encoding strategy that separately encodes RGB appearance and coordinate cues; and 3) an autoregressive transformer decoder conditioned on both position-aligned query features and the partially generated token sequence. With these novel mechanisms, CoordAR significantly outperforms existing methods on multiple benchmarks and demonstrates strong robustness to symmetry, occlusion, and other challenges in real-world tests.

</details>


### [178] [Generative Photographic Control for Scene-Consistent Video Cinematic Editing](https://arxiv.org/abs/2511.12921)
*Huiqiang Sun,Liao Shen,Zhan Peng,Kun Wang,Size Wu,Yuhang Zang,Tianqi Liu,Zihao Huang,Xingyu Zeng,Zhiguo Cao,Wei Li,Chen Change Loy*

Main category: cs.CV

TL;DR: CineCtrl是一个视频电影编辑框架，首次实现对专业相机参数（如散景、快门速度）的精细控制，解决了生成视频模型中摄影效果控制的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有生成视频模型主要局限于相机运动控制，难以对摄影元素（如景深、曝光）进行艺术化操控，而这些元素对电影叙事和美学表达至关重要。

Method: 提出解耦交叉注意力机制，将相机运动与摄影输入分离，实现细粒度独立控制；开发综合数据生成策略，结合模拟摄影效果和真实世界收集管道，构建大规模训练数据集。

Result: 实验表明，该模型能够生成具有精确控制、用户指定摄影相机效果的高保真视频。

Conclusion: CineCtrl成功实现了对视频中专业相机参数的精细控制，为电影级视频生成提供了新的技术解决方案。

Abstract: Cinematic storytelling is profoundly shaped by the artful manipulation of photographic elements such as depth of field and exposure. These effects are crucial in conveying mood and creating aesthetic appeal. However, controlling these effects in generative video models remains highly challenging, as most existing methods are restricted to camera motion control. In this paper, we propose CineCtrl, the first video cinematic editing framework that provides fine control over professional camera parameters (e.g., bokeh, shutter speed). We introduce a decoupled cross-attention mechanism to disentangle camera motion from photographic inputs, allowing fine-grained, independent control without compromising scene consistency. To overcome the shortage of training data, we develop a comprehensive data generation strategy that leverages simulated photographic effects with a dedicated real-world collection pipeline, enabling the construction of a large-scale dataset for robust model training. Extensive experiments demonstrate that our model generates high-fidelity videos with precisely controlled, user-specified photographic camera effects.

</details>


### [179] [Text2Traffic: A Text-to-Image Generation and Editing Method for Traffic Scenes](https://arxiv.org/abs/2511.12932)
*Feng Lv,Haoxuan Feng,Zilu Zhang,Chunlong Xia,Yanfeng Li*

Main category: cs.CV

TL;DR: 提出了一种统一的文本驱动框架，用于交通场景的图像生成和编辑，通过可控掩码机制和两阶段训练策略解决交通元素语义丰富度不足、视角有限、视觉保真度低等问题。


<details>
  <summary>Details</summary>
Motivation: 智能交通系统中文本驱动图像生成和编辑技术存在语义丰富度不足、相机视角有限、视觉保真度低、文本与生成内容对齐差等问题。

Method: 采用可控掩码机制统一图像生成和编辑任务，结合车端和路端多视角数据增强几何多样性，使用两阶段训练策略（概念学习+细粒度微调），并引入掩码区域加权损失动态关注关键小区域。

Result: 大量实验表明，该方法在交通场景的文本驱动图像生成和编辑方面取得了领先性能。

Conclusion: 提出的框架有效解决了交通场景图像生成中的关键挑战，通过统一架构和针对性训练策略显著提升了生成质量和文本对齐效果。

Abstract: With the rapid advancement of intelligent transportation systems, text-driven image generation and editing techniques have demonstrated significant potential in providing rich, controllable visual scene data for applications such as traffic monitoring and autonomous driving. However, several challenges remain, including insufficient semantic richness of generated traffic elements, limited camera viewpoints, low visual fidelity of synthesized images, and poor alignment between textual descriptions and generated content. To address these issues, we propose a unified text-driven framework for both image generation and editing, leveraging a controllable mask mechanism to seamlessly integrate the two tasks. Furthermore, we incorporate both vehicle-side and roadside multi-view data to enhance the geometric diversity of traffic scenes. Our training strategy follows a two-stage paradigm: first, we perform conceptual learning using large-scale coarse-grained text-image data; then, we fine-tune with fine-grained descriptive data to enhance text-image alignment and detail quality. Additionally, we introduce a mask-region-weighted loss that dynamically emphasizes small yet critical regions during training, thereby substantially enhancing the generation fidelity of small-scale traffic elements. Extensive experiments demonstrate that our method achieves leading performance in text-based image generation and editing within traffic scenes.

</details>


### [180] [PFAvatar: Pose-Fusion 3D Personalized Avatar Reconstruction from Real-World Outfit-of-the-Day Photos](https://arxiv.org/abs/2511.12935)
*Dianbing Xi,Guoyuan An,Jingsen Zhu,Zhijian Liu,Yuan Liu,Ruiyuan Zhang,Jiayuan Lu,Rui Wang,Yuchi Huo*

Main category: cs.CV

TL;DR: PFAvatar是一种从日常穿搭照片重建高质量3D虚拟形象的新方法，采用两阶段流程：基于ControlNet的姿势感知扩散模型微调和NeRF表示的3D虚拟形象蒸馏，相比现有方法速度提升48倍且能更好处理遮挡和细节。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在从OOTD照片重建3D虚拟形象时面临的分解不一致、遮挡处理困难、细节丢失等问题，实现更实用的3D虚拟形象生成。

Method: 两阶段方法：1）使用ControlNet进行姿势估计和CPPL损失函数微调扩散模型；2）在规范SMPL-X空间中通过多分辨率3D-SDS优化NeRF表示，避免网格表示的离散化问题。

Result: 实验表明PFAvatar在重建保真度、细节保留和遮挡鲁棒性方面优于现有方法，5分钟内完成个性化，支持虚拟试穿、动画等下游应用。

Conclusion: PFAvatar通过端到端学习完整身体外观和连续辐射场表示，显著提升了从真实世界OOTD相册生成3D虚拟形象的实用性和质量。

Abstract: We propose PFAvatar (Pose-Fusion Avatar), a new method that reconstructs high-quality 3D avatars from ``Outfit of the Day'' (OOTD) photos, which exhibit diverse poses, occlusions, and complex backgrounds. Our method consists of two stages: (1) fine-tuning a pose-aware diffusion model from few-shot OOTD examples and (2) distilling a 3D avatar represented by a neural radiance field (NeRF). In the first stage, unlike previous methods that segment images into assets (e.g., garments, accessories) for 3D assembly, which is prone to inconsistency, we avoid decomposition and directly model the full-body appearance. By integrating a pre-trained ControlNet for pose estimation and a novel Condition Prior Preservation Loss (CPPL), our method enables end-to-end learning of fine details while mitigating language drift in few-shot training. Our method completes personalization in just 5 minutes, achieving a 48$\times$ speed-up compared to previous approaches. In the second stage, we introduce a NeRF-based avatar representation optimized by canonical SMPL-X space sampling and Multi-Resolution 3D-SDS. Compared to mesh-based representations that suffer from resolution-dependent discretization and erroneous occluded geometry, our continuous radiance field can preserve high-frequency textures (e.g., hair) and handle occlusions correctly through transmittance. Experiments demonstrate that PFAvatar outperforms state-of-the-art methods in terms of reconstruction fidelity, detail preservation, and robustness to occlusions/truncations, advancing practical 3D avatar generation from real-world OOTD albums. In addition, the reconstructed 3D avatar supports downstream applications such as virtual try-on, animation, and human video reenactment, further demonstrating the versatility and practical value of our approach.

</details>


### [181] [ProtoAnomalyNCD: Prototype Learning for Multi-class Novel Anomaly Discovery in Industrial Scenarios](https://arxiv.org/abs/2511.12938)
*Botong Zhao,Qijun Shi,Shujing Lyu,Yue Lu*

Main category: cs.CV

TL;DR: ProtoAnomalyNCD是一个基于原型学习的工业异常检测框架，能够发现和分类多种未见过的异常类型，通过结合Grounded SAM定位目标区域和异常图引导注意力机制来提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有工业异常检测方法主要关注是否存在异常，但实际应用需要发现和分类多种异常类型。由于工业异常语义细微且现有方法未充分利用图像先验，直接聚类方法效果不佳。

Method: 1. 使用Grounded SAM和文本提示定位目标区域作为先验；2. 设计异常图引导注意力块，包含区域指导因子区分背景、目标区域和异常区域；3. 在统一原型学习框架下实现未见异常类的发现和聚类，同时支持多类型异常分类。

Result: 该方法在MVTec AD、MTD和Real-IAD数据集上优于最先进方法，并能扩展到检测未见异常值，实现任务级统一。

Conclusion: ProtoAnomalyNCD通过结合目标区域定位和异常图引导注意力机制，有效解决了工业多类型异常发现和分类问题，在多个数据集上表现出优越性能。

Abstract: Existing industrial anomaly detection methods mainly determine whether an anomaly is present. However, real-world applications also require discovering and classifying multiple anomaly types. Since industrial anomalies are semantically subtle and current methods do not sufficiently exploit image priors, direct clustering approaches often perform poorly. To address these challenges, we propose ProtoAnomalyNCD, a prototype-learning-based framework for discovering unseen anomaly classes of multiple types that can be integrated with various anomaly detection methods. First, to suppress background clutter, we leverage Grounded SAM with text prompts to localize object regions as priors for the anomaly classification network. Next, because anomalies usually appear as subtle and fine-grained patterns on the product, we introduce an Anomaly-Map-Guided Attention block. Within this block, we design a Region Guidance Factor that helps the attention module distinguish among background, object regions, and anomalous regions. By using both localized product regions and anomaly maps as priors, the module enhances anomalous features while suppressing background noise and preserving normal features for contrastive learning. Finally, under a unified prototype-learning framework, ProtoAnomalyNCD discovers and clusters unseen anomaly classes while simultaneously enabling multi-type anomaly classification. We further extend our method to detect unseen outliers, achieving task-level unification. Our method outperforms state-of-the-art approaches on the MVTec AD, MTD, and Real-IAD datasets.

</details>


### [182] [Semi-Supervised High Dynamic Range Image Reconstructing via Bi-Level Uncertain Area Masking](https://arxiv.org/abs/2511.12939)
*Wei Jiang,Jiahao Cui,Yizheng Wu,Zhan Peng,Zhiyu Pan,Zhiguo Cao*

Main category: cs.CV

TL;DR: 提出了一种基于半监督学习的高动态范围图像重建方法，通过教师模型生成伪HDR标签，并采用不确定性掩码机制过滤不可靠部分，仅需6.7%的HDR真实标签即可达到全监督方法性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于学习的HDR图像重建方法需要大量LDR-HDR图像对，但真实HDR标签难以获取，因此需要研究如何在有限标注数据下实现可比性能。

Method: 采用师生框架：教师模型为无标签LDR样本生成伪HDR标签；学生模型从伪标签学习。关键创新是提出基于不确定性的像素级和块级掩码机制，过滤伪标签中的不可靠部分。

Result: 该方法在仅使用6.7% HDR真实标签的情况下，不仅优于之前的标注高效算法，而且达到了最新全监督方法的可比性能。

Conclusion: 不确定性掩码机制有效解决了半监督学习中的确认偏差问题，显著降低了HDR图像重建对标注数据的依赖。

Abstract: Reconstructing high dynamic range (HDR) images from low dynamic range (LDR) bursts plays an essential role in the computational photography. Impressive progress has been achieved by learning-based algorithms which require LDR-HDR image pairs. However, these pairs are hard to obtain, which motivates researchers to delve into the problem of annotation-efficient HDR image reconstructing: how to achieve comparable performance with limited HDR ground truths (GTs). This work attempts to address this problem from the view of semi-supervised learning where a teacher model generates pseudo HDR GTs for the LDR samples without GTs and a student model learns from pseudo GTs. Nevertheless, the confirmation bias, i.e., the student may learn from the artifacts in pseudo HDR GTs, presents an impediment. To remove this impediment, an uncertainty-based masking process is proposed to discard unreliable parts of pseudo GTs at both pixel and patch levels, then the trusted areas can be learned from by the student. With this novel masking process, our semi-supervised HDR reconstructing method not only outperforms previous annotation-efficient algorithms, but also achieves comparable performance with up-to-date fully-supervised methods by using only 6.7% HDR GTs.

</details>


### [183] [Recurrent Autoregressive Diffusion: Global Memory Meets Local Attention](https://arxiv.org/abs/2511.12940)
*Taiye Chen,Zihan Ding,Anjian Li,Christina Zhang,Zeqi Xiao,Yisen Wang,Chi Jin*

Main category: cs.CV

TL;DR: 提出RAD框架，通过LSTM增强扩散模型的长时记忆能力，解决长视频生成中的遗忘和时空不一致问题


<details>
  <summary>Details</summary>
Motivation: 现有视频扩散模型缺乏有效记忆压缩和检索机制，导致长时生成时出现遗忘和时空不一致问题

Method: 在扩散变换器中引入LSTM，提出RAD框架进行帧级自回归记忆更新和检索，保持训练推理一致性

Result: 在Memory Maze和Minecraft数据集上验证了RAD在长视频生成中的优越性，LSTM在序列建模中表现高效

Conclusion: RAD框架通过LSTM增强记忆机制，有效提升了长视频生成的时空一致性和长期记忆能力

Abstract: Recent advancements in video generation have demonstrated the potential of using video diffusion models as world models, with autoregressive generation of infinitely long videos through masked conditioning. However, such models, usually with local full attention, lack effective memory compression and retrieval for long-term generation beyond the window size, leading to issues of forgetting and spatiotemporal inconsistencies. To enhance the retention of historical information within a fixed memory budget, we introduce a recurrent neural network (RNN) into the diffusion transformer framework. Specifically, a diffusion model incorporating LSTM with attention achieves comparable performance to state-of-the-art RNN blocks, such as TTT and Mamba2. Moreover, existing diffusion-RNN approaches often suffer from performance degradation due to training-inference gap or the lack of overlap across windows. To address these limitations, we propose a novel Recurrent Autoregressive Diffusion (RAD) framework, which executes frame-wise autoregression for memory update and retrieval, consistently across training and inference time. Experiments on Memory Maze and Minecraft datasets demonstrate the superiority of RAD for long video generation, highlighting the efficiency of LSTM in sequence modeling.

</details>


### [184] [T2I-Based Physical-World Appearance Attack against Traffic Sign Recognition Systems in Autonomous Driving](https://arxiv.org/abs/2511.12956)
*Chen Ma,Ningfei Wang,Junhao Zheng,Qing Guo,Qian Wang,Qi Alfred Chen,Chao Shen*

Main category: cs.CV

TL;DR: DiffSign是一种基于文本到图像扩散模型的交通标志识别系统对抗性外观攻击框架，旨在生成物理鲁棒、高效、可迁移、实用且隐蔽的攻击。


<details>
  <summary>Details</summary>
Motivation: 现有交通标志识别系统的对抗性外观攻击存在局限性：基于像素级扰动的方法缺乏隐蔽性且对特定模型过拟合，而基于文本到图像扩散模型的方法效果有限且对分布外标志类型泛化能力差。

Method: 提出DiffSign框架，集成CLIP-based损失和掩码提示来改善攻击聚焦和可控性，并设计两种新颖的风格定制方法来引导视觉外观，提高对域外交通标志的攻击泛化能力和隐蔽性。

Result: 在多种真实世界条件下（不同距离、角度、光照条件和标志类别）的广泛评估显示，DiffSign平均物理世界攻击成功率达到83.3%，表现出高攻击可迁移性。

Conclusion: DiffSign框架能够有效克服现有方法的局限性，生成具有高隐蔽性和强泛化能力的对抗性外观攻击，对交通标志识别系统构成实际威胁。

Abstract: Traffic Sign Recognition (TSR) systems play a critical role in Autonomous Driving (AD) systems, enabling real-time detection of road signs, such as STOP and speed limit signs. While these systems are increasingly integrated into commercial vehicles, recent research has exposed their vulnerability to physical-world adversarial appearance attacks. In such attacks, carefully crafted visual patterns are misinterpreted by TSR models as legitimate traffic signs, while remaining inconspicuous or benign to human observers. However, existing adversarial appearance attacks suffer from notable limitations. Pixel-level perturbation-based methods often lack stealthiness and tend to overfit to specific surrogate models, resulting in poor transferability to real-world TSR systems. On the other hand, text-to-image (T2I) diffusion model-based approaches demonstrate limited effectiveness and poor generalization to out-of-distribution sign types.
  In this paper, we present DiffSign, a novel T2I-based appearance attack framework designed to generate physically robust, highly effective, transferable, practical, and stealthy appearance attacks against TSR systems. To overcome the limitations of prior approaches, we propose a carefully designed attack pipeline that integrates CLIP-based loss and masked prompts to improve attack focus and controllability. We also propose two novel style customization methods to guide visual appearance and improve out-of-domain traffic sign attack generalization and attack stealthiness. We conduct extensive evaluations of DiffSign under varied real-world conditions, including different distances, angles, light conditions, and sign categories. Our method achieves an average physical-world attack success rate of 83.3%, leveraging DiffSign's high effectiveness in attack transferability.

</details>


### [185] [EndoSight AI: Deep Learning-Driven Real-Time Gastrointestinal Polyp Detection and Segmentation for Enhanced Endoscopic Diagnostics](https://arxiv.org/abs/2511.12962)
*Daniel Cavadia*

Main category: cs.CV

TL;DR: EndoSight AI是一个深度学习架构，用于实时检测和分割胃肠道息肉，在Hyper-Kvasir数据集上达到88.3%的mAP检测精度和69%的Dice分割系数，推理速度超过35fps。


<details>
  <summary>Details</summary>
Motivation: 胃肠道息肉的精确实时检测对于结直肠癌的早期诊断和预防至关重要，需要开发能够在内窥镜手术中准确定位息肉并详细描绘边界的AI解决方案。

Method: 利用公开的Hyper-Kvasir数据集，开发了深度学习架构，结合临床相关性能指标和新型热感知程序来确保模型的鲁棒性和效率。

Result: 系统实现了88.3%的平均精度（mAP）用于息肉检测，分割Dice系数最高达69%，在GPU硬件上实时推理速度超过35帧/秒。

Conclusion: EndoSight AI是一个集成的AI解决方案，设计用于无缝部署到内窥镜工作流程中，有望提高胃肠道医疗的诊断准确性和临床决策能力。

Abstract: Precise and real-time detection of gastrointestinal polyps during endoscopic procedures is crucial for early diagnosis and prevention of colorectal cancer. This work presents EndoSight AI, a deep learning architecture developed and evaluated independently to enable accurate polyp localization and detailed boundary delineation. Leveraging the publicly available Hyper-Kvasir dataset, the system achieves a mean Average Precision (mAP) of 88.3% for polyp detection and a Dice coefficient of up to 69% for segmentation, alongside real-time inference speeds exceeding 35 frames per second on GPU hardware. The training incorporates clinically relevant performance metrics and a novel thermal-aware procedure to ensure model robustness and efficiency. This integrated AI solution is designed for seamless deployment in endoscopy workflows, promising to advance diagnostic accuracy and clinical decision-making in gastrointestinal healthcare.

</details>


### [186] [CalibrateMix: Guided-Mixup Calibration of Image Semi-Supervised Models](https://arxiv.org/abs/2511.12964)
*Mehrab Mustafy Rahman,Jayanth Mohan,Tiberiu Sosea,Cornelia Caragea*

Main category: cs.CV

TL;DR: 本文提出CalibrateMix方法，通过有针对性的mixup策略改善半监督学习模型的校准性，在保持分类精度的同时降低预期校准误差。


<details>
  <summary>Details</summary>
Motivation: 现有半监督学习方法存在校准性差的问题，模型容易产生过度自信的预测。虽然在监督学习中mixup方法已被证明能改善校准性，但在半监督学习场景下，由于伪标签的不可靠性，随机mixup策略面临挑战。

Method: CalibrateMix方法利用训练动态识别"易学习"和"难学习"样本，然后对这些样本进行有针对性的mixup操作，从而改善模型校准性。

Result: 在多个基准图像数据集上的实验表明，该方法相比现有半监督学习方法，在保持或提高分类精度的同时，显著降低了预期校准误差。

Conclusion: CalibrateMix通过有针对性的mixup策略有效解决了半监督学习中的校准问题，为构建更可靠的半监督学习模型提供了新思路。

Abstract: Semi-supervised learning (SSL) has demonstrated high performance in image classification tasks by effectively utilizing both labeled and unlabeled data. However, existing SSL methods often suffer from poor calibration, with models yielding overconfident predictions that misrepresent actual prediction likelihoods. Recently, neural networks trained with {\tt mixup} that linearly interpolates random examples from the training set have shown better calibration in supervised settings. However, calibration of neural models remains under-explored in semi-supervised settings. Although effective in supervised model calibration, random mixup of pseudolabels in SSL presents challenges due to the overconfidence and unreliability of pseudolabels. In this work, we introduce CalibrateMix, a targeted mixup-based approach that aims to improve the calibration of SSL models while maintaining or even improving their classification accuracy. Our method leverages training dynamics of labeled and unlabeled samples to identify ``easy-to-learn'' and ``hard-to-learn'' samples, which in turn are utilized in a targeted mixup of easy and hard samples. Experimental results across several benchmark image datasets show that our method achieves lower expected calibration error (ECE) and superior accuracy compared to existing SSL approaches.

</details>


### [187] [GrOCE:Graph-Guided Online Concept Erasure for Text-to-Image Diffusion Models](https://arxiv.org/abs/2511.12968)
*Ning Han,Zhenyu Ge,Feng Han,Yuhua Sun,Chengqing Li,Jingjing Chen*

Main category: cs.CV

TL;DR: 提出了Graph-Guided Online Concept Erasure (GrOCE)框架，无需训练即可实现精确自适应的概念擦除，通过图语义推理解决现有方法依赖微调或语义分离粗糙的问题。


<details>
  <summary>Details</summary>
Motivation: 现有概念擦除方法要么依赖昂贵的微调，要么采用粗糙的语义分离，往往会降低无关概念的质量且缺乏对动态概念集的适应性。

Method: GrOCE包含三个组件：(1)动态拓扑图构建实现增量图构建；(2)自适应聚类识别通过相似度衰减评分进行多跳遍历；(3)选择性边切断实现目标边移除同时保留全局语义。

Result: 在Concept Similarity和Fréchet Inception Distance指标上达到最先进性能，提供高效、准确且稳定的概念擦除而无需重新训练。

Conclusion: GrOCE通过图语义推理实现了精确自适应的概念擦除，在保持非目标语义的同时有效移除有害或不适当内容。

Abstract: Concept erasure aims to remove harmful, inappropriate, or copyrighted content from text-to-image diffusion models while preserving non-target semantics. However, existing methods either rely on costly fine-tuning or apply coarse semantic separation, often degrading unrelated concepts and lacking adaptability to evolving concept sets. To alleviate this issue, we propose Graph-Guided Online Concept Erasure (GrOCE), a training-free framework that performs precise and adaptive concept removal through graph-based semantic reasoning. GrOCE models concepts and their interrelations as a dynamic semantic graph, enabling principled reasoning over dependencies and fine-grained isolation of undesired content. It comprises three components: (1) Dynamic Topological Graph Construction for incremental graph building, (2) Adaptive Cluster Identification for multi-hop traversal with similarity-decay scoring, and (3) Selective Edge Severing for targeted edge removal while preserving global semantics. Extensive experiments demonstrate that GrOCE achieves state-of-the-art performance on Concept Similarity (CS) and Fréchet Inception Distance (FID) metrics, offering efficient, accurate, and stable concept erasure without retraining.

</details>


### [188] [HiFusion: Hierarchical Intra-Spot Alignment and Regional Context Fusion for Spatial Gene Expression Prediction from Histopathology](https://arxiv.org/abs/2511.12969)
*Ziqiao Weng,Yaoyu Fang,Jiahe Qian,Xinkun Wang,Lee AD Cooper,Weidong Cai,Bo Zhou*

Main category: cs.CV

TL;DR: HiFusion是一个深度学习框架，通过分层斑点内建模和上下文感知跨尺度融合，从H&E染色全切片图像预测空间转录组基因表达，在多个基准数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以捕捉斑点内的生物异质性，且容易受到周围组织形态学噪声的影响，阻碍了空间转录组技术的临床采用。

Method: HiFusion包含两个互补组件：1）分层斑点内建模模块通过多分辨率子斑块分解提取细粒度形态表示；2）上下文感知跨尺度融合模块使用交叉注意力选择性整合生物相关区域上下文。

Result: 在两个基准ST数据集上的实验表明，HiFusion在2D切片级交叉验证和更具挑战性的3D样本特定场景下均达到最先进性能。

Conclusion: HiFusion为从常规组织病理学进行ST推断提供了一个稳健、准确且可扩展的解决方案。

Abstract: Spatial transcriptomics (ST) bridges gene expression and tissue morphology but faces clinical adoption barriers due to technical complexity and prohibitive costs. While computational methods predict gene expression from H&E-stained whole-slide images (WSIs), existing approaches often fail to capture the intricate biological heterogeneity within spots and are susceptible to morphological noise when integrating contextual information from surrounding tissue. To overcome these limitations, we propose HiFusion, a novel deep learning framework that integrates two complementary components. First, we introduce the Hierarchical Intra-Spot Modeling module that extracts fine-grained morphological representations through multi-resolution sub-patch decomposition, guided by a feature alignment loss to ensure semantic consistency across scales. Concurrently, we present the Context-aware Cross-scale Fusion module, which employs cross-attention to selectively incorporate biologically relevant regional context, thereby enhancing representational capacity. This architecture enables comprehensive modeling of both cellular-level features and tissue microenvironmental cues, which are essential for accurate gene expression prediction. Extensive experiments on two benchmark ST datasets demonstrate that HiFusion achieves state-of-the-art performance across both 2D slide-wise cross-validation and more challenging 3D sample-specific scenarios. These results underscore HiFusion's potential as a robust, accurate, and scalable solution for ST inference from routine histopathology.

</details>


### [189] [MCAQ-YOLO: Morphological Complexity-Aware Quantization for Efficient Object Detection with Curriculum Learning](https://arxiv.org/abs/2511.12976)
*Yoonjae Seo,Ermal Elbasani,Jaehong Lee*

Main category: cs.CV

TL;DR: MCAQ-YOLO是一种基于形态复杂度的自适应量化框架，通过五种形态学指标动态调整空间位精度，在目标检测任务中相比均匀量化获得更高精度和收敛效率


<details>
  <summary>Details</summary>
Motivation: 解决传统神经网络量化方法在空间区域采用统一位精度的问题，考虑视觉数据的异构结构和纹理复杂性

Method: 使用分形维度、纹理熵、梯度方差、边缘密度和轮廓复杂度五种形态学指标来表征局部视觉形态，指导空间自适应位分配；采用基于课程的量化感知训练方案逐步增加量化难度

Result: 在安全设备数据集上达到85.6% mAP@0.5，平均4.2位精度，压缩比7.6倍，比均匀4位量化高3.5个百分点；在COCO和Pascal VOC数据集上验证了性能一致性

Conclusion: 形态驱动的空间量化能够提升计算受限、安全关键视觉识别任务的效率和鲁棒性

Abstract: Most neural network quantization methods apply uniform bit precision across spatial regions, ignoring the heterogeneous structural and textural complexity of visual data. This paper introduces MCAQ-YOLO, a morphological complexity-aware quantization framework for object detection. The framework employs five morphological metrics - fractal dimension, texture entropy, gradient variance, edge density, and contour complexity - to characterize local visual morphology and guide spatially adaptive bit allocation. By correlating these metrics with quantization sensitivity, MCAQ-YOLO dynamically adjusts bit precision according to spatial complexity. In addition, a curriculum-based quantization-aware training scheme progressively increases quantization difficulty to stabilize optimization and accelerate convergence. Experimental results demonstrate a strong correlation between morphological complexity and quantization sensitivity and show that MCAQ-YOLO achieves superior detection accuracy and convergence efficiency compared with uniform quantization. On a safety equipment dataset, MCAQ-YOLO attains 85.6 percent mAP@0.5 with an average of 4.2 bits and a 7.6x compression ratio, yielding 3.5 percentage points higher mAP than uniform 4-bit quantization while introducing only 1.8 ms of additional runtime overhead per image. Cross-dataset validation on COCO and Pascal VOC further confirms consistent performance gains, indicating that morphology-driven spatial quantization can enhance efficiency and robustness for computationally constrained, safety-critical visual recognition tasks.

</details>


### [190] [ArtiWorld: LLM-Driven Articulation of 3D Objects in Scenes](https://arxiv.org/abs/2511.12977)
*Yixuan Yang,Luyang Xie,Zhen Luo,Zixiang Zhao,Mingqi Gao,Feng Zheng*

Main category: cs.CV

TL;DR: ArtiWorld是一个从文本场景描述中自动识别可关节化对象并重建可执行URDF模型的场景感知管道，核心是Arti4URDF方法，利用3D点云、大语言模型先验知识和URDF导向提示设计，将刚性对象转换为交互式关节对象。


<details>
  <summary>Details</summary>
Motivation: 构建交互式模拟器和可扩展机器人学习环境需要大量关节化资产，但现有3D资产大多是刚性的，手动转换成本极高，因此需要自动识别场景中的可关节化对象并转换为关节资产。

Method: 提出ArtiWorld管道，通过文本场景描述定位候选可关节化对象，使用Arti4URDF结合3D点云、LLM先验知识和URDF导向提示设计，快速重建保持原始几何形状的可执行URDF模型。

Result: 在3D模拟对象、完整3D模拟场景和真实世界扫描场景三个层面评估，方法在所有设置中都优于现有方法，达到最先进性能，保持对象几何形状并正确捕获对象交互性。

Conclusion: 该方法为直接从现有3D资产构建交互式、机器人就绪的模拟环境提供了实用路径。

Abstract: Building interactive simulators and scalable robot-learning environments requires a large number of articulated assets. However, most existing 3D assets in simulation are rigid, and manually converting them into articulated objects is extremely labor- and cost-intensive. This raises a natural question: can we automatically identify articulable objects in a scene and convert them into articulated assets directly? In this paper, we present ArtiWorld, a scene-aware pipeline that localizes candidate articulable objects from textual scene descriptions and reconstructs executable URDF models that preserve the original geometry. At the core of this pipeline is Arti4URDF, which leverages 3D point cloud, prior knowledge of a large language model (LLM), and a URDF-oriented prompt design to rapidly convert rigid objects into interactive URDF-based articulated objects while maintaining their 3D shape. We evaluate ArtiWorld at three levels: 3D simulated objects, full 3D simulated scenes, and real-world scan scenes. Across all three settings, our method consistently outperforms existing approaches and achieves state-of-the-art performance, while preserving object geometry and correctly capturing object interactivity to produce usable URDF-based articulated models. This provides a practical path toward building interactive, robot-ready simulation environments directly from existing 3D assets. Code and data will be released.

</details>


### [191] [Concept Regions Matter: Benchmarking CLIP with a New Cluster-Importance Approach](https://arxiv.org/abs/2511.12978)
*Aishwarya Agarwal,Srikrishna Karanam,Vineet Gandhi*

Main category: cs.CV

TL;DR: 提出了CCI方法，通过聚类CLIP的patch嵌入来识别模型对背景的过度依赖，并在COVAR基准上评估了18个CLIP变体的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决对比视觉语言模型（如CLIP）对虚假相关性的脆弱性，特别是背景过度依赖问题。

Method: 提出Cluster-based Concept Importance (CCI)方法，利用CLIP自身的patch嵌入进行语义聚类、掩码处理，并评估预测相对变化；结合GroundedSAM自动分类预测为前景或背景驱动。

Result: CCI在忠实性基准上达到新SOTA，在MS COCO检索的deletion-AUC指标上提升超过两倍；COVAR基准系统性地分离了前景和背景变化的影响。

Conclusion: CCI提供了关键诊断能力，COVAR基准和实证分析为构建更鲁棒的视觉语言模型指明了方向。

Abstract: Contrastive vision-language models (VLMs) such as CLIP achieve strong zero-shot recognition yet remain vulnerable to spurious correlations, particularly background over-reliance. We introduce Cluster-based Concept Importance (CCI), a novel interpretability method that uses CLIP's own patch embeddings to group spatial patches into semantically coherent clusters, mask them, and evaluate relative changes in model predictions. CCI sets a new state of the art on faithfulness benchmarks, surpassing prior methods by large margins; for example, it yields more than a twofold improvement on the deletion-AUC metric for MS COCO retrieval. We further propose that CCI, when combined with GroundedSAM, automatically categorizes predictions as foreground- or background-driven, providing a crucial diagnostic ability. Existing benchmarks such as CounterAnimals, however, rely solely on accuracy and implicitly attribute all performance degradation to background correlations. Our analysis shows this assumption to be incomplete, since many errors arise from viewpoint variation, scale shifts, and fine-grained object confusions. To disentangle these effects, we introduce COVAR, a benchmark that systematically varies object foregrounds and backgrounds. Leveraging CCI with COVAR, we present a comprehensive evaluation of eighteen CLIP variants, offering methodological advances and empirical evidence that chart a path toward more robust VLMs.

</details>


### [192] [UNSEEN: Enhancing Dataset Pruning from a Generalization Perspective](https://arxiv.org/abs/2511.12988)
*Furui Xu,Shaobo Wang,Jiajun Zhang,Chenghao Sun,Haixiang Tang,Linfeng Zhang*

Main category: cs.CV

TL;DR: UNSEEN是一个基于泛化视角的数据集剪枝框架，通过使用未在训练中见过的模型来评估样本重要性，解决了传统方法在训练后期样本评分区分度不足的问题。


<details>
  <summary>Details</summary>
Motivation: 传统数据集剪枝方法依赖训练阶段的模型性能来评分样本，但当模型在训练数据上达到接近最优性能时，样本评分会密集分布在狭窄数值范围内，导致样本间区分度降低，影响剪枝效果。

Method: 提出UNSEEN框架：1）从泛化角度进行数据集剪枝，使用未接触过样本的模型来评分；2）扩展到多步场景，通过在不同核心集上训练的模型进行增量选择；3）动态优化核心集质量。

Result: 在CIFAR-10、CIFAR-100和ImageNet-1K上的实验表明，UNSEEN显著优于现有SOTA方法。在ImageNet-1K上，减少30%训练数据的同时实现了无损性能。

Conclusion: 基于泛化视角的数据集剪枝方法能够有效解决传统方法在训练后期样本评分区分度不足的问题，UNSEEN框架为数据集剪枝提供了新的有效途径。

Abstract: The growing scale of datasets in deep learning has introduced significant computational challenges. Dataset pruning addresses this challenge by constructing a compact but informative coreset from the full dataset with comparable performance. Previous approaches typically establish scoring metrics based on specific criteria to identify representative samples. However, these methods predominantly rely on sample scores obtained from the model's performance during the training (i.e., fitting) phase. As scoring models achieve near-optimal performance on training data, such fitting-centric approaches induce a dense distribution of sample scores within a narrow numerical range. This concentration reduces the distinction between samples and hinders effective selection. To address this challenge, we conduct dataset pruning from the perspective of generalization, i.e., scoring samples based on models not exposed to them during training. We propose a plug-and-play framework, UNSEEN, which can be integrated into existing dataset pruning methods. Additionally, conventional score-based methods are single-step and rely on models trained solely on the complete dataset, providing limited perspective on the importance of samples. To address this limitation, we scale UNSEEN to multi-step scenarios and propose an incremental selection technique through scoring models trained on varying coresets, and optimize the quality of the coreset dynamically. Extensive experiments demonstrate that our method significantly outperforms existing state-of-the-art (SOTA) methods on CIFAR-10, CIFAR-100, and ImageNet-1K. Notably, on ImageNet-1K, UNSEEN achieves lossless performance while reducing training data by 30\%.

</details>


### [193] [Semantic Prioritization in Visual Counterfactual Explanations with Weighted Segmentation and Auto-Adaptive Region Selection](https://arxiv.org/abs/2511.12992)
*Lintong Zhang,Kang Yin,Seong-Whan Lee*

Main category: cs.CV

TL;DR: 本文提出WSAE-Net方法，通过加权语义图和自适应候选编辑序列解决传统视觉反事实解释中语义相关性问题，提升模型可解释性和编辑效率。


<details>
  <summary>Details</summary>
Motivation: 传统视觉反事实解释方法通常将查询图像的部分区域替换为干扰图像区域，但忽略了替换区域与目标对象的语义相关性，这损害了模型的可解释性并阻碍编辑流程。

Method: WSAE-Net包含两个关键创新：加权语义图生成和自适应候选编辑序列。加权语义图最大化减少需要计算的非语义特征单元，优化计算效率；自适应编辑序列确定特征单元的最优计算顺序，确保反事实生成效率同时保持替换特征单元与目标对象的语义相关性。

Result: 通过全面实验验证，该方法展现出优越性能，为视觉反事实解释提供了更清晰深入的理解。

Conclusion: WSAE-Net方法通过语义感知的编辑策略，有效解决了传统方法的局限性，在保持语义相关性的同时提升了计算效率和解释质量。

Abstract: In the domain of non-generative visual counterfactual explanations (CE), traditional techniques frequently involve the substitution of sections within a query image with corresponding sections from distractor images. Such methods have historically overlooked the semantic relevance of the replacement regions to the target object, thereby impairing the model's interpretability and hindering the editing workflow. Addressing these challenges, the present study introduces an innovative methodology named as Weighted Semantic Map with Auto-adaptive Candidate Editing Network (WSAE-Net). Characterized by two significant advancements: the determination of an weighted semantic map and the auto-adaptive candidate editing sequence. First, the generation of the weighted semantic map is designed to maximize the reduction of non-semantic feature units that need to be computed, thereby optimizing computational efficiency. Second, the auto-adaptive candidate editing sequences are designed to determine the optimal computational order among the feature units to be processed, thereby ensuring the efficient generation of counterfactuals while maintaining the semantic relevance of the replacement feature units to the target object. Through comprehensive experimentation, our methodology demonstrates superior performance, contributing to a more lucid and in-depth understanding of visual counterfactual explanations.

</details>


### [194] [PerTouch: VLM-Driven Agent for Personalized and Semantic Image Retouching](https://arxiv.org/abs/2511.12998)
*Zewei Chang,Zheng-Peng Duan,Jianxing Zhang,Chun-Le Guo,Siyu Liu,Hyungju Chun,Hyunhee Park,Zikun Liu,Chongyi Li*

Main category: cs.CV

TL;DR: PerTouch是一个基于扩散模型的统一图像润色框架，支持语义级图像润色，通过参数映射和VLM驱动代理实现精细控制和个性化偏好对齐。


<details>
  <summary>Details</summary>
Motivation: 解决图像润色中可控性与主观性平衡的挑战，满足用户个性化审美偏好。

Method: 使用包含特定语义区域属性值的参数映射作为输入，构建显式参数到图像的映射；引入语义替换和参数扰动机制提升语义边界感知；开发VLM驱动代理处理强弱用户指令；配备反馈驱动重思考和场景感知记忆机制。

Result: 大量实验证明各组件有效性，PerTouch在个性化图像润色中表现优越。

Conclusion: PerTouch框架能够更好地适应用户意图并捕捉长期偏好，在个性化图像润色任务中具有显著优势。

Abstract: Image retouching aims to enhance visual quality while aligning with users' personalized aesthetic preferences. To address the challenge of balancing controllability and subjectivity, we propose a unified diffusion-based image retouching framework called PerTouch. Our method supports semantic-level image retouching while maintaining global aesthetics. Using parameter maps containing attribute values in specific semantic regions as input, PerTouch constructs an explicit parameter-to-image mapping for fine-grained image retouching. To improve semantic boundary perception, we introduce semantic replacement and parameter perturbation mechanisms in the training process. To connect natural language instructions with visual control, we develop a VLM-driven agent that can handle both strong and weak user instructions. Equipped with mechanisms of feedback-driven rethinking and scene-aware memory, PerTouch better aligns with user intent and captures long-term preferences. Extensive experiments demonstrate each component's effectiveness and the superior performance of PerTouch in personalized image retouching. Code is available at: https://github.com/Auroral703/PerTouch.

</details>


### [195] [Medal S: Spatio-Textual Prompt Model for Medical Segmentation](https://arxiv.org/abs/2511.13001)
*Pengcheng Shi,Jiawei Chen,Jiaqi Liu,Xinglin Zhang,Tao Chen,Lei Li*

Main category: cs.CV

TL;DR: Medal S是一个支持原生分辨率空间和文本提示的医学分割基础模型，通过通道级对齐和3D卷积模块实现高效的多类别分割，在五个医学影像模态上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有文本提示方法缺乏空间感知能力的问题，避免分辨率不匹配导致的误差，提升多类别医学分割的准确性和效率。

Method: 采用端到端可训练框架，实现体积提示与文本嵌入的通道级对齐；使用轻量级3D卷积模块进行体素空间精炼；支持文本提示和混合提示两种模式；提出动态重采样、两阶段推理策略和后处理技术。

Result: 在五个医学影像模态验证集上，DSC达到75.44（vs SAT 69.83），NSD达到77.34（vs 71.06），F1达到38.24（vs 24.88），DSC TP达到65.46（vs 46.97）；24类分割中并行空间提示比顺序提示减少90%推理时间。

Conclusion: Medal S通过协调空间精度与语义文本指导，在多类别医学分割任务中展现出卓越的效率和准确性，优于基于顺序提示的方法，将成为公开可用的医学分割工具。

Abstract: We introduce Medal S, a medical segmentation foundation model that supports native-resolution spatial and textual prompts within an end-to-end trainable framework. Unlike text-only methods lacking spatial awareness, Medal S achieves channel-wise alignment between volumetric prompts and text embeddings, mitigating inaccuracies from resolution mismatches. By preserving full 3D context, it efficiently processes multiple native-resolution masks in parallel, enhancing multi-class segmentation performance. A lightweight 3D convolutional module enables precise voxel-space refinement guided by both prompt types, supporting up to 243 classes across CT, MRI, PET, ultrasound, and microscopy modalities in the BiomedSegFM dataset. Medal S offers two prompting modes: a text-only mode, where model predictions serve as spatial prompts for self-refinement without human input, and a hybrid mode, incorporating manual annotations for enhanced flexibility. For 24-class segmentation, parallel spatial prompting reduces inference time by more than 90% compared to sequential prompting. We propose dynamic resampling to address target-patch ratio imbalance, extending SAT and nnU-Net for data augmentation. Furthermore, we develop optimized text preprocessing, a two-stage inference strategy, and post-processing techniques to improve memory efficiency, precision, and inference speed. On the five-modality average on the validation set, Medal S outperforms SAT with a DSC of 75.44 (vs. 69.83), NSD of 77.34 (vs. 71.06), F1 of 38.24 (vs. 24.88), and DSC TP of 65.46 (vs. 46.97). Medal S achieves excellent performance by harmonizing spatial precision with semantic textual guidance, demonstrating superior efficiency and accuracy in multi-class medical segmentation tasks compared to sequential prompt-based approaches. Medal S will be publicly available at https://github.com/yinghemedical/Medal-S.

</details>


### [196] [Infinite-Story: A Training-Free Consistent Text-to-Image Generation](https://arxiv.org/abs/2511.13002)
*Jihun Park,Kyoungmin Lee,Jongmin Gim,Hyeonseo Jo,Minseok Oh,Wonhyeok Choi,Kyumin Hwang,Jaeyeul Kim,Minwoo Choi,Sunghoon Im*

Main category: cs.CV

TL;DR: Infinite-Story是一个无需训练、基于尺度自回归模型的文本到图像生成框架，专门解决多提示词故事生成中的身份和风格不一致问题，实现了6倍以上的推理速度提升。


<details>
  <summary>Details</summary>
Motivation: 解决多提示词文本到图像生成中的两个关键挑战：身份不一致（同一角色在不同场景中外观变化）和风格不一致（不同图像间视觉风格不统一）。现有方法需要微调或推理速度慢，限制了实际应用。

Method: 提出三种互补技术：1）身份提示替换 - 缓解文本编码器的上下文偏差以对齐身份属性；2）统一注意力引导机制，包括自适应风格注入和同步引导适应 - 联合强制执行全局风格和身份外观一致性，同时保持提示词保真度。

Result: 在广泛实验中，该方法实现了最先进的生成性能，推理速度达到每张图像1.72秒，比现有最快的文本到图像模型快6倍以上。

Conclusion: Infinite-Story是一个高效实用的视觉故事生成框架，无需训练即可在测试时运行，在保持高质量生成的同时显著提升了推理速度，适用于实际应用场景。

Abstract: We present Infinite-Story, a training-free framework for consistent text-to-image (T2I) generation tailored for multi-prompt storytelling scenarios. Built upon a scale-wise autoregressive model, our method addresses two key challenges in consistent T2I generation: identity inconsistency and style inconsistency. To overcome these issues, we introduce three complementary techniques: Identity Prompt Replacement, which mitigates context bias in text encoders to align identity attributes across prompts; and a unified attention guidance mechanism comprising Adaptive Style Injection and Synchronized Guidance Adaptation, which jointly enforce global style and identity appearance consistency while preserving prompt fidelity. Unlike prior diffusion-based approaches that require fine-tuning or suffer from slow inference, Infinite-Story operates entirely at test time, delivering high identity and style consistency across diverse prompts. Extensive experiments demonstrate that our method achieves state-of-the-art generation performance, while offering over 6X faster inference (1.72 seconds per image) than the existing fastest consistent T2I models, highlighting its effectiveness and practicality for real-world visual storytelling.

</details>


### [197] [SAGE: Spuriousness-Aware Guided Prompt Exploration for Mitigating Multimodal Bias](https://arxiv.org/abs/2511.13005)
*Wenqian Ye,Di Wang,Guangtao Zheng,Bohan Liu,Aidong Zhang*

Main category: cs.CV

TL;DR: SAGE是一种无需训练、微调或外部标注的方法，通过引导式提示选择来减轻CLIP模型中的多模态伪偏差，提高零样本分类的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: CLIP模型在零样本分类中表现出色，但存在多模态伪偏差问题，即模型倾向于依赖虚假特征（如背景）而非核心特征进行推理，这严重影响在分布外数据上的鲁棒性。现有方法需要下游数据微调或先验知识，限制了CLIP的开箱即用性。

Method: 提出SAGE方法，通过理论分析多模态伪偏差的影响，探索提示模板空间并选择能最大化类别间语义分离的提示，从而改善最差组鲁棒性。

Result: 在四个真实世界基准数据集和五个流行骨干模型上的广泛实验表明，SAGE一致提升了零样本性能和泛化能力，优于先前无需外部知识或模型更新的零样本方法。

Conclusion: SAGE是一种简单有效的零样本方法，无需任何训练或外部知识即可减轻CLIP模型的多模态伪偏差，显著提高模型的鲁棒性和泛化性能。

Abstract: Large vision-language models, such as CLIP, have shown strong zero-shot classification performance by aligning images and text in a shared embedding space. However, CLIP models often develop multimodal spurious biases, which is the undesirable tendency to rely on spurious features. For example, CLIP may infer object types in images based on frequently co-occurring backgrounds rather than the object's core features. This bias significantly impairs the robustness of pre-trained CLIP models on out-of-distribution data, where such cross-modal associations no longer hold. Existing methods for mitigating multimodal spurious bias typically require fine-tuning on downstream data or prior knowledge of the bias, which undermines the out-of-the-box usability of CLIP. In this paper, we first theoretically analyze the impact of multimodal spurious bias in zero-shot classification. Based on this insight, we propose Spuriousness-Aware Guided Exploration (SAGE), a simple and effective method that mitigates spurious bias through guided prompt selection. SAGE requires no training, fine-tuning, or external annotations. It explores a space of prompt templates and selects the prompts that induce the largest semantic separation between classes, thereby improving worst-group robustness. Extensive experiments on four real-world benchmark datasets and five popular backbone models demonstrate that SAGE consistently improves zero-shot performance and generalization, outperforming previous zero-shot approaches without any external knowledge or model updates.

</details>


### [198] [Beyond Darkness: Thermal-Supervised 3D Gaussian Splatting for Low-Light Novel View Synthesis](https://arxiv.org/abs/2511.13011)
*Qingsen Ma,Chen Zou,Dianyun Wang,Jia Wang,Liuyu Xiang,Zhaofeng He*

Main category: cs.CV

TL;DR: DTGS是一个统一框架，将Retinex启发的光照分解与热成像引导的3D高斯泼溅相结合，用于极低光照条件下的新视角合成。该方法通过循环增强-重建机制实现联合优化，显著提升了辐射一致性、几何保真度和色彩稳定性。


<details>
  <summary>Details</summary>
Motivation: 在极低光照条件下，标准3D高斯泼溅管道直接应用于曝光不足输入时会失败，因为跨视图的独立增强会导致光照不一致和几何失真。现有方法将增强作为预处理步骤，无法保证跨视图的一致性。

Method: DTGS框架包含：1）Retinex基分解模块嵌入3DGS循环中，提供物理可解释的反射率-光照分离；2）热成像监督分支通过动态平衡增强、结构和热损失来稳定色彩恢复和几何学习；3）循环增强-重建机制实现增强、几何和热监督的联合优化。

Result: 构建了RGBT-LOW多视图低光照热成像数据集进行验证。实验表明DTGS显著优于现有低光照增强和3D重建基线方法，在极端光照条件下实现了优异的辐射一致性、几何保真度和色彩稳定性。

Conclusion: DTGS通过将光照分解与3D高斯泼溅紧密耦合，解决了极低光照下新视角合成的关键挑战。联合优化框架和热成像监督为低光照3D重建提供了有效解决方案，在辐射和几何一致性方面表现出色。

Abstract: Under extremely low-light conditions, novel view synthesis (NVS) faces severe degradation in terms of geometry, color consistency, and radiometric stability. Standard 3D Gaussian Splatting (3DGS) pipelines fail when applied directly to underexposed inputs, as independent enhancement across views causes illumination inconsistencies and geometric distortion. To address this, we present DTGS, a unified framework that tightly couples Retinex-inspired illumination decomposition with thermal-guided 3D Gaussian Splatting for illumination-invariant reconstruction. Unlike prior approaches that treat enhancement as a pre-processing step, DTGS performs joint optimization across enhancement, geometry, and thermal supervision through a cyclic enhancement-reconstruction mechanism. A thermal supervisory branch stabilizes both color restoration and geometry learning by dynamically balancing enhancement, structural, and thermal losses. Moreover, a Retinex-based decomposition module embedded within the 3DGS loop provides physically interpretable reflectance-illumination separation, ensuring consistent color and texture across viewpoints. To evaluate our method, we construct RGBT-LOW, a new multi-view low-light thermal dataset capturing severe illumination degradation. Extensive experiments show that DTGS significantly outperforms existing low-light enhancement and 3D reconstruction baselines, achieving superior radiometric consistency, geometric fidelity, and color stability under extreme illumination.

</details>


### [199] [You Only Look Omni Gradient Backpropagation for Moving Infrared Small Target Detection](https://arxiv.org/abs/2511.13013)
*Guoyi Zhang,Guangsheng Xu,Siyang Chen,Han Wang,Xiaohu Zhang*

Main category: cs.CV

TL;DR: 本文提出BP-FPN，一种基于反向传播的特征金字塔架构，专门用于红外小目标检测，通过梯度隔离低层捷径和方向梯度正则化解决现有方法在单帧特征表示上的瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法主要关注时空特征聚合，但效果有限，表明根本瓶颈在于单帧特征表示的模糊性而非时空建模本身。

Method: 提出BP-FPN架构，包含梯度隔离低层捷径(GILS)避免捷径学习，以及方向梯度正则化(DGR)确保反向传播过程中的层次特征一致性。

Result: 在多个公共数据集上的广泛实验表明，BP-FPN持续达到最先进的性能。

Conclusion: 这是首个完全从反向传播视角设计的用于红外小目标检测的特征金字塔网络，理论上有依据，计算开销可忽略，并能无缝集成到现有框架中。

Abstract: Moving infrared small target detection is a key component of infrared search and tracking systems, yet it remains extremely challenging due to low signal-to-clutter ratios, severe target-background imbalance, and weak discriminative features. Existing deep learning methods primarily focus on spatio-temporal feature aggregation, but their gains are limited, revealing that the fundamental bottleneck lies in ambiguous per-frame feature representations rather than spatio-temporal modeling itself. Motivated by this insight, we propose BP-FPN, a backpropagation-driven feature pyramid architecture that fundamentally rethinks feature learning for small target. BP-FPN introduces Gradient-Isolated Low-Level Shortcut (GILS) to efficiently incorporate fine-grained target details without inducing shortcut learning, and Directional Gradient Regularization (DGR) to enforce hierarchical feature consistency during backpropagation. The design is theoretically grounded, introduces negligible computational overhead, and can be seamlessly integrated into existing frameworks. Extensive experiments on multiple public datasets show that BP-FPN consistently establishes new state-of-the-art performance. To the best of our knowledge, it is the first FPN designed for this task entirely from the backpropagation perspective.

</details>


### [200] [Geometry Meets Light: Leveraging Geometric Priors for Universal Photometric Stereo under Limited Multi-Illumination Cues](https://arxiv.org/abs/2511.13015)
*King-Man Tam,Satoshi Ikehata,Yuta Asano,Zhaoyi An,Rei Kawakami*

Main category: cs.CV

TL;DR: GeoUniPS是一个通用光度立体网络，通过结合合成监督和大规模3D重建模型提供的高层几何先验，解决了传统方法在复杂野外场景中多光照线索不可靠的问题。


<details>
  <summary>Details</summary>
Motivation: 传统通用光度立体方法在光照偏差、阴影或自遮挡等复杂野外场景中表现不佳，因为多光照线索不可靠。需要利用大规模3D重建模型编码的几何知识来提升性能。

Method: 设计光-几何双分支编码器，从冻结的3D重建模型中提取多光照线索和几何先验。引入PS-Perp数据集处理透视投影问题，替代传统的正交投影假设。

Result: GeoUniPS在多个数据集上实现了最先进的性能，特别是在复杂野外场景中，定量和定性评估都表现出色。

Conclusion: 通过集成3D重建模型的几何先验和合成监督，GeoUniPS有效提升了通用光度立体在复杂场景中的表现，证明了视觉-几何基础模型的价值。

Abstract: Universal Photometric Stereo is a promising approach for recovering surface normals without strict lighting assumptions. However, it struggles when multi-illumination cues are unreliable, such as under biased lighting or in shadows or self-occluded regions of complex in-the-wild scenes. We propose GeoUniPS, a universal photometric stereo network that integrates synthetic supervision with high-level geometric priors from large-scale 3D reconstruction models pretrained on massive in-the-wild data. Our key insight is that these 3D reconstruction models serve as visual-geometry foundation models, inherently encoding rich geometric knowledge of real scenes. To leverage this, we design a Light-Geometry Dual-Branch Encoder that extracts both multi-illumination cues and geometric priors from the frozen 3D reconstruction model. We also address the limitations of the conventional orthographic projection assumption by introducing the PS-Perp dataset with realistic perspective projection to enable learning of spatially varying view directions. Extensive experiments demonstrate that GeoUniPS delivers state-of-the-arts performance across multiple datasets, both quantitatively and qualitatively, especially in the complex in-the-wild scenes.

</details>


### [201] [MeanFlow Transformers with Representation Autoencoders](https://arxiv.org/abs/2511.13019)
*Zheyuan Hu,Chieh-Hsin Lai,Ge Wu,Yuki Mitsufuji,Stefano Ermon*

Main category: cs.CV

TL;DR: 提出了一种在表示自动编码器（RAE）潜在空间中训练MeanFlow（MF）的高效方法，通过一致性中期训练和两阶段方案（蒸馏+引导）解决梯度爆炸问题，无需复杂指导参数，显著降低训练和采样成本。


<details>
  <summary>Details</summary>
Motivation: MF模型在训练中计算量大且不稳定，推理时SD-VAE解码器成本高，且需要复杂指导参数进行类别条件生成。

Method: 在RAE潜在空间中训练MF，采用一致性中期训练进行轨迹感知初始化，使用两阶段方案：从预训练流匹配教师蒸馏加速收敛，可选引导阶段使用单点速度估计器减少偏差。

Result: 在ImageNet 256上1步FID达到2.03（优于原MF的3.43），采样GFLOPS减少38%，训练总成本降低83%；在ImageNet 512上1步FID为3.23，在所有基线中GFLOPS最低。

Conclusion: 该方法简化了训练配置，移除了指导需求，在训练和采样中均减少了计算量，实现了高效且稳定的MF生成。

Abstract: MeanFlow (MF) is a diffusion-motivated generative model that enables efficient few-step generation by learning long jumps directly from noise to data. In practice, it is often used as a latent MF by leveraging the pre-trained Stable Diffusion variational autoencoder (SD-VAE) for high-dimensional data modeling. However, MF training remains computationally demanding and is often unstable. During inference, the SD-VAE decoder dominates the generation cost, and MF depends on complex guidance hyperparameters for class-conditional generation. In this work, we develop an efficient training and sampling scheme for MF in the latent space of a Representation Autoencoder (RAE), where a pre-trained vision encoder (e.g., DINO) provides semantically rich latents paired with a lightweight decoder. We observe that naive MF training in the RAE latent space suffers from severe gradient explosion. To stabilize and accelerate training, we adopt Consistency Mid-Training for trajectory-aware initialization and use a two-stage scheme: distillation from a pre-trained flow matching teacher to speed convergence and reduce variance, followed by an optional bootstrapping stage with a one-point velocity estimator to further reduce deviation from the oracle mean flow. This design removes the need for guidance, simplifies training configurations, and reduces computation in both training and sampling. Empirically, our method achieves a 1-step FID of 2.03, outperforming vanilla MF's 3.43, while reducing sampling GFLOPS by 38% and total training cost by 83% on ImageNet 256. We further scale our approach to ImageNet 512, achieving a competitive 1-step FID of 3.23 with the lowest GFLOPS among all baselines. Code is available at https://github.com/sony/mf-rae.

</details>


### [202] [SpectralAdapt: Semi-Supervised Domain Adaptation with Spectral Priors for Human-Centered Hyperspectral Image Reconstruction](https://arxiv.org/abs/2511.13020)
*Yufei Wen,Yuting Zhang,Jingdan Kang,Hao Ren,Weibin Cheng,Jintai Chen,Kaishun Wu*

Main category: cs.CV

TL;DR: 本文提出SpectralAdapt框架，通过半监督域适应方法解决医疗HSI数据稀缺问题，利用RGB图像重建高光谱图像，在光谱保真度和跨域泛化方面取得显著改进。


<details>
  <summary>Details</summary>
Motivation: 高光谱成像在医疗领域潜力巨大但数据获取成本高，现有通用领域数据集丰富但人体HSI数据稀缺，限制了医疗应用进展。

Method: 提出SpectralAdapt半监督域适应框架，包含光谱密度掩码(SDM)自适应掩码RGB通道，以及光谱端元表示对齐(SERA)利用物理可解释端元作为域不变锚点指导预测。

Result: 在基准数据集上的实验表明，该方法在光谱保真度、跨域泛化能力和训练稳定性方面均取得一致改进。

Conclusion: SpectralAdapt框架有效缓解了HSI重建中的域偏移、光谱退化和数据稀缺问题，证明了SSDA作为医疗高光谱成像高效解决方案的潜力。

Abstract: Hyperspectral imaging (HSI) holds great potential for healthcare due to its rich spectral information. However, acquiring HSI data remains costly and technically demanding. Hyperspectral image reconstruction offers a practical solution by recovering HSI data from accessible modalities, such as RGB. While general domain datasets are abundant, the scarcity of human HSI data limits progress in medical applications. To tackle this, we propose SpectralAdapt, a semi-supervised domain adaptation (SSDA) framework that bridges the domain gap between general and human-centered HSI datasets. To fully exploit limited labels and abundant unlabeled data, we enhance spectral reasoning by introducing Spectral Density Masking (SDM), which adaptively masks RGB channels based on their spectral complexity, encouraging recovery of informative regions from complementary cues during consistency training. Furthermore, we introduce Spectral Endmember Representation Alignment (SERA), which derives physically interpretable endmembers from valuable labeled pixels and employs them as domain-invariant anchors to guide unlabeled predictions, with momentum updates ensuring adaptability and stability. These components are seamlessly integrated into SpectralAdapt, a spectral prior-guided framework that effectively mitigates domain shift, spectral degradation, and data scarcity in HSI reconstruction. Experiments on benchmark datasets demonstrate consistent improvements in spectral fidelity, cross-domain generalization, and training stability, highlighting the promise of SSDA as an efficient solution for hyperspectral imaging in healthcare.

</details>


### [203] [REVISOR: Beyond Textual Reflection, Towards Multimodal Introspective Reasoning in Long-Form Video Understanding](https://arxiv.org/abs/2511.13026)
*Jiaze Li,Hao Yin,Wenhui Tan,Jingyang Chen,Boshen Xu,Yuxun Qu,Yijing Chen,Jianzhong Ju,Zhenbo Luo,Jian Luan*

Main category: cs.CV

TL;DR: REVISOR是一个用于长视频理解的多模态反思框架，通过文本和视觉模态的协同反思，解决了纯文本反思机制在长视频任务中的局限性。


<details>
  <summary>Details</summary>
Motivation: 纯文本反思机制在长视频理解中存在两个主要问题：1）长视频包含更丰富动态的视觉信息，仅反思文本信息不足；2）缺乏跨模态交互能力，无法在反思过程中充分整合视觉信息。

Method: 提出REVISOR框架，支持MLLMs在文本和视觉模态间构建内省反思过程。设计了DADR奖励机制，集成到GRPO训练策略中，确保模型在强化学习过程中能够准确回顾与问题高度相关的视频片段。

Result: 在VideoMME、LongVideoBench、MLVU和LVBench四个基准测试中取得了显著成果，显著提升了MLLMs的长视频理解能力，且无需额外的监督微调或外部模型。

Conclusion: REVISOR框架通过多模态反思机制有效解决了长视频理解的挑战，证明了跨模态协同反思对提升MLLMs推理能力的重要性。

Abstract: Self-reflection mechanisms that rely on purely text-based rethinking processes perform well in most multimodal tasks. However, when directly applied to long-form video understanding scenarios, they exhibit clear limitations. The fundamental reasons for this lie in two points: (1)long-form video understanding involves richer and more dynamic visual input, meaning rethinking only the text information is insufficient and necessitates a further rethinking process specifically targeting visual information; (2) purely text-based reflection mechanisms lack cross-modal interaction capabilities, preventing them from fully integrating visual information during reflection. Motivated by these insights, we propose REVISOR (REflective VIsual Segment Oriented Reasoning), a novel framework for tool-augmented multimodal reflection. REVISOR enables MLLMs to collaboratively construct introspective reflection processes across textual and visual modalities, significantly enhancing their reasoning capability for long-form video understanding. To ensure that REVISOR can learn to accurately review video segments highly relevant to the question during reinforcement learning, we designed the Dual Attribution Decoupled Reward (DADR) mechanism. Integrated into the GRPO training strategy, this mechanism enforces causal alignment between the model's reasoning and the selected video evidence. Notably, the REVISOR framework significantly enhances long-form video understanding capability of MLLMs without requiring supplementary supervised fine-tuning or external models, achieving impressive results on four benchmarks including VideoMME, LongVideoBench, MLVU, and LVBench.

</details>


### [204] [Towards 3D Object-Centric Feature Learning for Semantic Scene Completion](https://arxiv.org/abs/2511.13031)
*Weihua Wang,Yubo Cui,Xiangru Lin,Zhiheng Li,Zheng Fang*

Main category: cs.CV

TL;DR: Ocean是一个基于视觉的3D语义场景补全框架，采用对象中心的方法，通过分解场景为单个对象实例来提高语义占据预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常采用以自我为中心的范式，在复杂环境中容易忽略细粒度对象级细节，导致语义和几何模糊。

Method: 1. 使用MobileSAM提取实例掩码；2. 引入3D语义分组注意力模块聚合对象中心特征；3. 设计全局相似性引导注意力模块处理分割错误；4. 提出实例感知局部扩散模块优化BEV空间表示。

Result: 在SemanticKITTI和SSCBench-KITTI360基准测试中达到最先进性能，mIoU分别为17.40和20.28。

Conclusion: 对象中心的方法能有效提升3D语义场景补全的准确性，特别是在复杂环境中。

Abstract: Vision-based 3D Semantic Scene Completion (SSC) has received growing attention due to its potential in autonomous driving. While most existing approaches follow an ego-centric paradigm by aggregating and diffusing features over the entire scene, they often overlook fine-grained object-level details, leading to semantic and geometric ambiguities, especially in complex environments. To address this limitation, we propose Ocean, an object-centric prediction framework that decomposes the scene into individual object instances to enable more accurate semantic occupancy prediction. Specifically, we first employ a lightweight segmentation model, MobileSAM, to extract instance masks from the input image. Then, we introduce a 3D Semantic Group Attention module that leverages linear attention to aggregate object-centric features in 3D space. To handle segmentation errors and missing instances, we further design a Global Similarity-Guided Attention module that leverages segmentation features for global interaction. Finally, we propose an Instance-aware Local Diffusion module that improves instance features through a generative process and subsequently refines the scene representation in the BEV space. Extensive experiments on the SemanticKITTI and SSCBench-KITTI360 benchmarks demonstrate that Ocean achieves state-of-the-art performance, with mIoU scores of 17.40 and 20.28, respectively.

</details>


### [205] [Uni-Inter: Unifying 3D Human Motion Synthesis Across Diverse Interaction Contexts](https://arxiv.org/abs/2511.13032)
*Sheng Liu,Yuanzhi Liang,Jiepeng Wang,Sidan Du,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: Uni-Inter是一个统一的人类运动生成框架，支持多种交互场景（人-人、人-物、人-场景），通过统一的交互体积表示实现异构实体的共享空间编码和一致的关系推理。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖任务特定设计且泛化能力有限，无法有效处理复杂环境中的复合交互。需要开发统一的任务无关架构来支持多种交互场景。

Method: 引入统一交互体积（UIV）作为异构交互实体的共享空间表示，将运动生成建模为基于UIV的关节级概率预测，以捕捉细粒度空间依赖关系。

Result: 在三个代表性交互任务上的实验表明，Uni-Inter取得了有竞争力的性能，并能很好地泛化到新的实体组合。

Conclusion: 统一的复合交互建模为复杂环境中的可扩展运动合成提供了有前景的方向。

Abstract: We present Uni-Inter, a unified framework for human motion generation that supports a wide range of interaction scenarios: including human-human, human-object, and human-scene-within a single, task-agnostic architecture. In contrast to existing methods that rely on task-specific designs and exhibit limited generalization, Uni-Inter introduces the Unified Interactive Volume (UIV), a volumetric representation that encodes heterogeneous interactive entities into a shared spatial field. This enables consistent relational reasoning and compound interaction modeling. Motion generation is formulated as joint-wise probabilistic prediction over the UIV, allowing the model to capture fine-grained spatial dependencies and produce coherent, context-aware behaviors. Experiments across three representative interaction tasks demonstrate that Uni-Inter achieves competitive performance and generalizes well to novel combinations of entities. These results suggest that unified modeling of compound interactions offers a promising direction for scalable motion synthesis in complex environments.

</details>


### [206] [uCLIP: Parameter-Efficient Multilingual Extension of Vision-Language Models with Unpaired Data](https://arxiv.org/abs/2511.13036)
*Dahyun Chung,Donghyun Shin,Yujin Sung,Seunggi Moon,Jinwoo Jeon,Byung-Jun Lee*

Main category: cs.CV

TL;DR: 提出了一种轻量级、数据高效的多语言视觉-语言对齐框架，仅需训练170万参数的小型投影模块，无需图像-文本对或文本-文本对，即可在资源匮乏语言上实现强大的多语言对齐效果。


<details>
  <summary>Details</summary>
Motivation: 现有多语言视觉-语言模型在捷克语、芬兰语、克罗地亚语、匈牙利语、罗马尼亚语等低资源语言上的检索性能普遍较低，主要原因是高质量多语言图像-文本数据稀缺。

Method: 冻结预训练图像编码器和多语言文本编码器，仅训练紧凑的170万参数投影模块，使用英语表示作为语义锚点通过对比损失进行训练，无需任何图像-文本对或文本-文本对。

Result: 在多个多语言检索基准测试中，该方法在五个代表性低资源语言上取得了显著性能提升，优于现有模型。

Conclusion: 基于枢轴语言的参数高效对齐策略能够实现包容性多模态学习，为低资源语言的多语言视觉-语言对齐提供了有效解决方案。

Abstract: Contrastive Language-Image Pre-training (CLIP) has demonstrated strong generalization across a wide range of visual tasks by leveraging large-scale English-image pairs. However, its extension to low-resource languages remains limited due to the scarcity of high-quality multilingual image-text data. Existing multilingual vision-language models exhibit consistently low retrieval performance in underrepresented languages including Czech, Finnish, Croatian, Hungarian, and Romanian on the Crossmodal-3600 (XM3600) benchmark. To address this, we propose a lightweight and data-efficient framework for multilingual vision-language alignment. Our approach requires no image-text pairs or text-text pairs and freezes both the pretrained image encoder and multilingual text encoder during training. Only a compact 1.7M-parameter projection module is trained, using a contrastive loss over English representations as semantic anchors. This minimal training setup enables robust multilingual alignment even for languages with limited supervision. Extensive evaluation across multiple multilingual retrieval benchmarks confirms the effectiveness of our method, showing significant gains in five underrepresented languages where existing models typically underperform. These findings highlight the effectiveness of our pivot-based, parameter-efficient alignment strategy for inclusive multimodal learning.

</details>


### [207] [MGCA-Net: Multi-Grained Category-Aware Network for Open-Vocabulary Temporal Action Localization](https://arxiv.org/abs/2511.13039)
*Zhenying Fang,Richang Hong*

Main category: cs.CV

TL;DR: 提出MGCA-Net网络，通过多粒度类别感知机制解决开放词汇时序动作定位问题，在THUMOS'14和ActivityNet-1.3基准测试中达到最先进性能


<details>
  <summary>Details</summary>
Motivation: 现有方法大多在单一粒度上识别动作类别，这会降低基类和新类动作的识别准确率，需要多粒度类别感知机制来提升定位性能

Method: 包含定位器、动作存在预测器、常规分类器和粗到细分类器。定位器生成类别无关的动作提议，动作存在预测器估计动作实例概率，常规分类器处理基类动作，粗到细分类器通过视频粒度→提议粒度的层次识别新类动作

Result: 在THUMOS'14和ActivityNet-1.3基准测试中达到最先进性能，在零样本时序动作定位设置下也取得最优结果

Conclusion: 通过基类动作的常规分类器感知和新类动作的粗到细类别感知，实现了多粒度类别感知，有效提升了定位性能

Abstract: Open-Vocabulary Temporal Action Localization (OV-TAL) aims to recognize and localize instances of any desired action categories in videos without explicitly curating training data for all categories. Existing methods mostly recognize action categories at a single granularity, which degrades the recognition accuracy of both base and novel action categories. To address these issues, we propose a Multi-Grained Category-Aware Network (MGCA-Net) comprising a localizer, an action presence predictor, a conventional classifier, and a coarse-to-fine classifier. Specifically, the localizer localizes category-agnostic action proposals. For these action proposals, the action presence predictor estimates the probability that they belong to an action instance. At the same time, the conventional classifier predicts the probability of each action proposal over base action categories at the snippet granularity. Novel action categories are recognized by the coarse-to-fine classifier, which first identifies action presence at the video granularity. Finally, it assigns each action proposal to one category from the coarse categories at the proposal granularity. Through coarse-to-fine category awareness for novel actions and the conventional classifier's awareness of base actions, multi-grained category awareness is achieved, effectively enhancing localization performance. Comprehensive evaluations on the THUMOS'14 and ActivityNet-1.3 benchmarks demonstrate that our method achieves state-of-the-art performance. Furthermore, our MGCA-Net achieves state-of-the-art results under the Zero-Shot Temporal Action Localization setting.

</details>


### [208] [ViSS-R1: Self-Supervised Reinforcement Video Reasoning](https://arxiv.org/abs/2511.13054)
*Bo Fang,Yuxin Song,Qiangqiang Wu,Haoyuan Sun,Wenhao Wu,Antoni B. Chan*

Main category: cs.CV

TL;DR: 该论文提出了一种新的视觉中心视频理解方法，通过自监督强化学习算法Pretext-GRPO和ViSS-R1框架，使多模态大语言模型能够更有效地处理视频中的视觉信息，避免捷径学习和幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于R1的多模态大语言模型在视频推理任务中过于依赖文本中心推理，未能充分利用丰富的视觉信息，容易导致捷径学习和幻觉问题。

Method: 提出了Pretext-GRPO自监督强化学习算法，通过为正确解决变换后视觉输入的前置任务分配正奖励，强制模型非平凡地处理视觉信息。进一步提出ViSS-R1框架，将前置任务自监督学习直接集成到MLLM的R1后训练范式中。

Result: 在六个广泛使用的视频推理和理解基准测试上进行了全面评估，证明了Pretext-GRPO和ViSS-R1在复杂视频推理任务中的有效性和优越性。

Conclusion: 该方法能够促进更鲁棒的视觉中心视频理解，代码和模型将公开可用。

Abstract: Complex video reasoning remains a significant challenge for Multimodal Large Language Models (MLLMs), as current R1-based methodologies often prioritize text-centric reasoning derived from text-based and image-based developments. In video tasks, such strategies frequently underutilize rich visual information, leading to potential shortcut learning and increased susceptibility to hallucination. To foster a more robust, visual-centric video understanding, we start by introducing a novel self-supervised reinforcement learning GRPO algorithm (Pretext-GRPO) within the standard R1 pipeline, in which positive rewards are assigned for correctly solving pretext tasks on transformed visual inputs, which makes the model to non-trivially process the visual information. Building on the effectiveness of Pretext-GRPO, we further propose the ViSS-R1 framework, which streamlines and integrates pretext-task-based self-supervised learning directly into the MLLM's R1 post-training paradigm. Instead of relying solely on sparse visual cues, our framework compels models to reason about transformed visual input by simultaneously processing both pretext questions (concerning transformations) and true user queries. This necessitates identifying the applied transformation and reconstructing the original video to formulate accurate final answers. Comprehensive evaluations on six widely-used video reasoning and understanding benchmarks demonstrate the effectiveness and superiority of our Pretext-GRPO and ViSS-R1 for complex video reasoning. Our codes and models will be publicly available.

</details>


### [209] [Monocular 3D Lane Detection via Structure Uncertainty-Aware Network with Curve-Point Queries](https://arxiv.org/abs/2511.13055)
*Ruixin Liu,Zejian Yuan*

Main category: cs.CV

TL;DR: MonoUnc是一个无需鸟瞰图的单目3D车道线检测器，通过建模局部车道结构的不确定性来应对观测噪声带来的不确定性挑战


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖简化的几何假设（如独立点预测或全局平面建模），无法捕捉真实场景中的结构变化和不确定性

Method: 将3D车道线投影到前视图空间并用参数曲线近似，通过曲线点查询嵌入动态生成3D空间的车道点预测，将相邻点形成的线段建模为3D高斯分布

Result: 在ONCE-3DLanes和OpenLane数据集上优于现有最优方法，并提出了新的评估指标量化全局和局部误差

Conclusion: MonoUnc通过显式建模局部结构的不确定性，有效提升了单目3D车道线检测的精度和鲁棒性

Abstract: Monocular 3D lane detection is challenged by aleatoric uncertainty arising from inherent observation noise. Existing methods rely on simplified geometric assumptions, such as independent point predictions or global planar modeling, failing to capture structural variations and aleatoric uncertainty in real-world scenarios. In this paper, we propose MonoUnc, a bird's-eye view (BEV)-free 3D lane detector that explicitly models aleatoric uncertainty informed by local lane structures. Specifically, 3D lanes are projected onto the front-view (FV) space and approximated by parametric curves. Guided by curve predictions, curve-point query embeddings are dynamically generated for lane point predictions in 3D space. Each segment formed by two adjacent points is modeled as a 3D Gaussian, parameterized by the local structure and uncertainty estimations. Accordingly, a novel 3D Gaussian matching loss is designed to constrain these parameters jointly. Experiments on the ONCE-3DLanes and OpenLane datasets demonstrate that MonoUnc outperforms previous state-of-the-art (SoTA) methods across all benchmarks under stricter evaluation criteria. Additionally, we propose two comprehensive evaluation metrics for ONCE-3DLanes, calculating the average and maximum bidirectional Chamfer distances to quantify global and local errors. Codes are released at https://github.com/lrx02/MonoUnc.

</details>


### [210] [FGNet: Leveraging Feature-Guided Attention to Refine SAM2 for 3D EM Neuron Segmentation](https://arxiv.org/abs/2511.13063)
*Zhenghua Li,Hang Chen,Zihao Sun,Kai Li,Xiaolin Hu*

Main category: cs.CV

TL;DR: 提出了一种将Segment Anything 2 (SAM2)从自然图像预训练知识迁移到电子显微镜图像神经元分割的新框架，通过特征引导注意力模块和双亲和度解码器，在有限标注下实现优异性能。


<details>
  <summary>Details</summary>
Motivation: 电子显微镜图像中的神经元分割面临形态复杂、信噪比低和标注稀缺的挑战，现有方法在准确性和泛化性上存在局限。

Method: 使用SAM2提取通用特征，通过特征引导注意力模块利用语义线索指导轻量级编码器关注挑战区域，最后通过双亲和度解码器生成粗粒度和细粒度亲和度图。

Result: 在SAM2权重冻结情况下达到与SOTA相当的性能，在EM数据微调后显著超越现有SOTA方法。

Conclusion: 研究表明，结合针对性的领域自适应指导，从自然图像预训练迁移表示能有效解决神经元分割中的特定挑战。

Abstract: Accurate segmentation of neural structures in Electron Microscopy (EM) images is paramount for neuroscience. However, this task is challenged by intricate morphologies, low signal-to-noise ratios, and scarce annotations, limiting the accuracy and generalization of existing methods. To address these challenges, we seek to leverage the priors learned by visual foundation models on a vast amount of natural images to better tackle this task. Specifically, we propose a novel framework that can effectively transfer knowledge from Segment Anything 2 (SAM2), which is pre-trained on natural images, to the EM domain. We first use SAM2 to extract powerful, general-purpose features. To bridge the domain gap, we introduce a Feature-Guided Attention module that leverages semantic cues from SAM2 to guide a lightweight encoder, the Fine-Grained Encoder (FGE), in focusing on these challenging regions. Finally, a dual-affinity decoder generates both coarse and refined affinity maps. Experimental results demonstrate that our method achieves performance comparable to state-of-the-art (SOTA) approaches with the SAM2 weights frozen. Upon further fine-tuning on EM data, our method significantly outperforms existing SOTA methods. This study validates that transferring representations pre-trained on natural images, when combined with targeted domain-adaptive guidance, can effectively address the specific challenges in neuron segmentation.

</details>


### [211] [RobustGait: Robustness Analysis for Appearance Based Gait Recognition](https://arxiv.org/abs/2511.13065)
*Reeshoon Sayera,Akash Kumar,Sirshapan Mitra,Prudvi Kamtam,Yogesh S Rawat*

Main category: cs.CV

TL;DR: RobustGait是一个用于评估基于外观的步态识别系统鲁棒性的框架，通过四个维度（扰动类型、轮廓提取方法、模型架构能力和部署场景）进行细粒度评估，揭示了系统对真实世界干扰的敏感性。


<details>
  <summary>Details</summary>
Motivation: 现有基于外观的步态识别系统在受控数据集上表现良好，但缺乏对其在真实世界干扰和轮廓变化下的鲁棒性系统评估。

Method: 提出了RobustGait框架，在CASIA-B、CCPG和SUSTech1K数据集上引入15种扰动类型和5个严重级别，评估了六种最先进的步态系统，并探索了噪声感知训练和知识蒸馏等鲁棒性增强策略。

Result: 发现RGB级别的噪声能更好反映真实世界退化，步态识别对轮廓提取器偏差高度敏感，鲁棒性取决于扰动类型和架构设计，噪声感知训练和知识蒸馏能提升性能。

Conclusion: RobustGait为步态识别系统的鲁棒性评估提供了新视角，揭示了轮廓提取器偏差等被忽视的基准偏差来源，并展示了提升部署就绪系统性能的有效策略。

Abstract: Appearance-based gait recognition have achieved strong performance on controlled datasets, yet systematic evaluation of its robustness to real-world corruptions and silhouette variability remains lacking. We present RobustGait, a framework for fine-grained robustness evaluation of appearance-based gait recognition systems. RobustGait evaluation spans four dimensions: the type of perturbation (digital, environmental, temporal, occlusion), the silhouette extraction method (segmentation and parsing networks), the architectural capacities of gait recognition models, and various deployment scenarios. The benchmark introduces 15 corruption types at 5 severity levels across CASIA-B, CCPG, and SUSTech1K, with in-the-wild validation on MEVID, and evaluates six state-of-the-art gait systems. We came across several exciting insights. First, applying noise at the RGB level better reflects real-world degradation, and reveal how distortions propagate through silhouette extraction to the downstream gait recognition systems. Second, gait accuracy is highly sensitive to silhouette extractor biases, revealing an overlooked source of benchmark bias. Third, robustness is dependent on both the type of perturbation and the architectural design. Finally, we explore robustness-enhancing strategies, showing that noise-aware training and knowledge distillation improve performance and move toward deployment-ready systems.

</details>


### [212] [Decoupling Scene Perception and Ego Status: A Multi-Context Fusion Approach for Enhanced Generalization in End-to-End Autonomous Driving](https://arxiv.org/abs/2511.13079)
*Jiacheng Tang,Mingyue Feng,Jiachao Liu,Yaonong Wang,Jian Pu*

Main category: cs.CV

TL;DR: 提出AdaptiveAD架构解决现有自动驾驶规划系统过度依赖自车状态的问题，通过双分支结构将场景感知与自车状态解耦，实现自适应融合决策。


<details>
  <summary>Details</summary>
Motivation: 现有端到端自动驾驶架构中自车状态过早融合到BEV编码器，导致规划模块过度依赖这一强先验信息，限制了泛化能力和场景理解鲁棒性。

Method: 采用双分支结构：场景驱动分支（多任务学习但排除自车状态）和自车驱动分支（仅规划任务），通过场景感知融合模块自适应整合决策。引入路径注意力机制和两个辅助任务（BEV单向蒸馏和自回归在线建图）保障多任务学习。

Result: 在nuScenes数据集上达到最先进的开放环路规划性能，显著减轻对自车状态的过度依赖，在多样化场景中展现出色泛化能力。

Conclusion: AdaptiveAD通过架构级解耦设计有效解决了自车状态依赖问题，为自动驾驶规划系统提供了更鲁棒和可泛化的解决方案。

Abstract: Modular design of planning-oriented autonomous driving has markedly advanced end-to-end systems. However, existing architectures remain constrained by an over-reliance on ego status, hindering generalization and robust scene understanding. We identify the root cause as an inherent design within these architectures that allows ego status to be easily leveraged as a shortcut. Specifically, the premature fusion of ego status in the upstream BEV encoder allows an information flow from this strong prior to dominate the downstream planning module. To address this challenge, we propose AdaptiveAD, an architectural-level solution based on a multi-context fusion strategy. Its core is a dual-branch structure that explicitly decouples scene perception and ego status. One branch performs scene-driven reasoning based on multi-task learning, but with ego status deliberately omitted from the BEV encoder, while the other conducts ego-driven reasoning based solely on the planning task. A scene-aware fusion module then adaptively integrates the complementary decisions from the two branches to form the final planning trajectory. To ensure this decoupling does not compromise multi-task learning, we introduce a path attention mechanism for ego-BEV interaction and add two targeted auxiliary tasks: BEV unidirectional distillation and autoregressive online mapping. Extensive evaluations on the nuScenes dataset demonstrate that AdaptiveAD achieves state-of-the-art open-loop planning performance. Crucially, it significantly mitigates the over-reliance on ego status and exhibits impressive generalization capabilities across diverse scenarios.

</details>


### [213] [Rethinking Saliency Maps: A Cognitive Human Aligned Taxonomy and Evaluation Framework for Explanations](https://arxiv.org/abs/2511.13081)
*Yehonatan Elisha,Seffi Cohen,Oren Barkan,Noam Koenigstein*

Main category: cs.CV

TL;DR: 该论文提出了RFxG分类法来系统化组织显著性图解释，揭示了现有评估指标的局限性，并提出了新的评估框架来更全面地衡量解释质量。


<details>
  <summary>Details</summary>
Motivation: 当前显著性图解释缺乏统一的概念框架，存在目的不明确和用户查询不匹配的问题，这阻碍了解释方法的有效评估和实际应用。

Method: 提出了Reference-Frame × Granularity (RFxG)分类法，包含参考框架（点对点vs对比）和粒度（细粒度vs粗粒度）两个维度。设计了四个新的忠实度指标来系统评估解释质量。

Result: 通过对10种最先进的显著性方法、4种模型架构和3个数据集的综合评估，发现现有评估指标过度关注点对点忠实度，而忽视了对比推理和语义粒度。

Conclusion: 通过推动用户意图驱动的评估，该研究为开发既忠实于模型行为又符合人类理解复杂性的视觉解释提供了概念基础和实践工具。

Abstract: Saliency maps are widely used for visual explanations in deep learning, but a fundamental lack of consensus persists regarding their intended purpose and alignment with diverse user queries. This ambiguity hinders the effective evaluation and practical utility of explanation methods.We address this gap by introducing the Reference-Frame $\times$ Granularity (RFxG) taxonomy, a principled conceptual framework that organizes saliency explanations along two essential axes:Reference-Frame: Distinguishing between pointwise ("Why this prediction?") and contrastive ("Why this and not an alternative?") explanations.Granularity: Ranging from fine-grained class-level (e.g., "Why Husky?") to coarse-grained group-level (e.g., "Why Dog?") interpretations.Using the RFxG lens, we demonstrate critical limitations in existing evaluation metrics, which overwhelmingly prioritize pointwise faithfulness while neglecting contrastive reasoning and semantic granularity. To systematically assess explanation quality across both RFxG dimensions, we propose four novel faithfulness metrics. Our comprehensive evaluation framework applies these metrics to ten state-of-the-art saliency methods, four model architectures, and three datasets.By advocating a shift toward user-intent-driven evaluation, our work provides both the conceptual foundation and the practical tools necessary to develop visual explanations that are not only faithful to the underlying model behavior but are also meaningfully aligned with the complexity of human understanding and inquiry.

</details>


### [214] [MergeSlide: Continual Model Merging and Task-to-Class Prompt-Aligned Inference for Lifelong Learning on Whole Slide Images](https://arxiv.org/abs/2511.13099)
*Doanh C. Bui,Ba Hung Ngo,Hoai Luan Pham,Khang Nguyen,Maï K. Nguyen,Yasuhiko Nakashima*

Main category: cs.CV

TL;DR: MergeSlide是一个用于全切片图像终身学习的框架，将终身学习视为模型融合问题，通过正交持续融合策略和任务到类别提示对齐推理来减轻灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 全切片图像体积庞大，终身学习可以减少数据传输和处理所需资源，但现有方法面临灾难性遗忘问题。

Method: 使用视觉语言病理学基础模型，通过类别感知提示定义新任务，使用无MLP的主干网络进行少量轮次微调，采用正交融合策略，并引入TCP推理方法处理未知任务身份。

Result: 在六个TCGA数据集上的实验表明，MergeSlide优于基于排练的持续学习和视觉语言零样本基线方法。

Conclusion: MergeSlide为WSI终身学习提供了一种简单有效的解决方案，通过模型融合方法成功缓解了灾难性遗忘问题。

Abstract: Lifelong learning on Whole Slide Images (WSIs) aims to train or fine-tune a unified model sequentially on cancer-related tasks, reducing the resources and effort required for data transfer and processing, especially given the gigabyte-scale size of WSIs. In this paper, we introduce MergeSlide, a simple yet effective framework that treats lifelong learning as a model merging problem by leveraging a vision-language pathology foundation model. When a new task arrives, it is: 1) defined with class-aware prompts, 2) fine-tuned for a few epochs using an MLP-free backbone, and 3) merged into a unified model using an orthogonal continual merging strategy that preserves performance and mitigates catastrophic forgetting. For inference under the class-incremental learning (CLASS-IL) setting, where task identity is unknown, we introduce Task-to-Class Prompt-aligned (TCP) inference. Specifically, TCP first identifies the most relevant task using task-level prompts and then applies the corresponding class-aware prompts to generate predictions. To evaluate MergeSlide, we conduct experiments on a stream of six TCGA datasets. The results show that MergeSlide outperforms both rehearsal-based continual learning and vision-language zero-shot baselines. Code and data are available at https://github.com/caodoanh2001/MergeSlide.

</details>


### [215] [CapeNext: Rethinking and refining dynamic support information for category-agnostic pose estimation](https://arxiv.org/abs/2511.13102)
*Yu Zhu,Dan Zeng,Shuiwang Li,Qijun Zhao,Qiaomu Shen,Bo Tang*

Main category: cs.CV

TL;DR: 该论文提出CapeNext框架，通过层次化跨模态交互和双流特征精炼解决静态关节嵌入的歧义性问题，在MP-100数据集上显著超越现有CAPE方法


<details>
  <summary>Details</summary>
Motivation: 解决静态关节嵌入的两个固有局限：(1)多义词引起的跨类别歧义（如"腿"在人类和家具中的不同视觉表现）(2)对细粒度类别内变化（如姿势和毛发差异）的区分能力不足

Method: 创新性地集成层次化跨模态交互与双流特征精炼，利用文本描述和具体图像中的类别级和实例特定线索增强关节嵌入

Result: 在MP-100数据集上的实验表明，无论使用何种网络骨干，CapeNext都大幅超越最先进的CAPE方法

Conclusion: 所提出的框架有效解决了静态关节嵌入的局限性，通过动态融合多模态信息显著提升了类别无关姿态估计的性能

Abstract: Recent research in Category-Agnostic Pose Estimation (CAPE) has adopted fixed textual keypoint description as semantic prior for two-stage pose matching frameworks. While this paradigm enhances robustness and flexibility by disentangling the dependency of support images, our critical analysis reveals two inherent limitations of static joint embedding: (1) polysemy-induced cross-category ambiguity during the matching process(e.g., the concept "leg" exhibiting divergent visual manifestations across humans and furniture), and (2) insufficient discriminability for fine-grained intra-category variations (e.g., posture and fur discrepancies between a sleeping white cat and a standing black cat). To overcome these challenges, we propose a new framework that innovatively integrates hierarchical cross-modal interaction with dual-stream feature refinement, enhancing the joint embedding with both class-level and instance-specific cues from textual description and specific images. Experiments on the MP-100 dataset demonstrate that, regardless of the network backbone, CapeNext consistently outperforms state-of-the-art CAPE methods by a large margin.

</details>


### [216] [PlugTrack: Multi-Perceptive Motion Analysis for Adaptive Fusion in Multi-Object Tracking](https://arxiv.org/abs/2511.13105)
*Seungjae Kim,SeungJoon Lee,MyeongAh Cho*

Main category: cs.CV

TL;DR: PlugTrack是一个创新的多目标跟踪框架，通过自适应融合卡尔曼滤波器和数据驱动运动预测器来解决线性与非线性运动模式的互补性问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界跟踪场景同时包含线性和非线性运动模式，但传统卡尔曼滤波器无法处理非线性运动，而数据驱动方法又存在泛化能力差和计算开销大的问题。研究发现即使在非线性运动主导的数据集中，卡尔曼滤波器在34%的情况下仍优于数据驱动方法。

Method: 提出PlugTrack框架，通过多感知运动理解自适应地融合卡尔曼滤波器和数据驱动运动预测器。该方法使用多感知运动分析生成自适应混合因子，无需修改现有运动预测器。

Result: 在MOT17/MOT20数据集上取得显著性能提升，在DanceTrack数据集上达到最先进水平。

Conclusion: PlugTrack是首个通过自适应融合桥接经典和现代运动预测范式的多目标跟踪框架，有效利用了不同预测器的互补优势。

Abstract: Multi-object tracking (MOT) predominantly follows the tracking-by-detection paradigm, where Kalman filters serve as the standard motion predictor due to computational efficiency but inherently fail on non-linear motion patterns. Conversely, recent data-driven motion predictors capture complex non-linear dynamics but suffer from limited domain generalization and computational overhead. Through extensive analysis, we reveal that even in datasets dominated by non-linear motion, Kalman filter outperforms data-driven predictors in up to 34\% of cases, demonstrating that real-world tracking scenarios inherently involve both linear and non-linear patterns. To leverage this complementarity, we propose PlugTrack, a novel framework that adaptively fuses Kalman filter and data-driven motion predictors through multi-perceptive motion understanding. Our approach employs multi-perceptive motion analysis to generate adaptive blending factors. PlugTrack achieves significant performance gains on MOT17/MOT20 and state-of-the-art on DanceTrack without modifying existing motion predictors. To the best of our knowledge, PlugTrack is the first framework to bridge classical and modern motion prediction paradigms through adaptive fusion in MOT.

</details>


### [217] [Low-Level Dataset Distillation for Medical Image Enhancement](https://arxiv.org/abs/2511.13106)
*Fengzhi Xu,Ziyuan Yang,Mengyu Sun,Joey Tianyi Zhou,Yi Zhang*

Main category: cs.CV

TL;DR: 本文提出了首个针对医学图像增强的低级数据集蒸馏方法，通过解剖先验和结构保持个性化生成模块，在保护隐私的同时实现高效的数据压缩。


<details>
  <summary>Details</summary>
Motivation: 现有数据集蒸馏方法主要针对高级任务，而低级任务需要像素级保真度，这使得低级数据集蒸馏成为一个欠定问题。医学图像增强需要大规模数据集但实际部署成本高，因此需要解决低级数据集蒸馏的挑战。

Method: 1. 利用患者间的解剖相似性构建共享解剖先验；2. 使用结构保持个性化生成模块将患者特异性信息集成到蒸馏数据中；3. 通过梯度对齐将患者特定知识注入蒸馏数据；4. 仅共享包含抽象训练信息的蒸馏数据集以保护隐私。

Result: 该方法能够有效压缩医学图像增强所需的数据集规模，同时保持像素级保真度，并且在保护患者隐私的前提下实现高效的知识传递。

Conclusion: 提出的低级数据集蒸馏方法成功解决了医学图像增强中的数据压缩和隐私保护问题，为实际临床部署提供了可行的解决方案。

Abstract: Medical image enhancement is clinically valuable, but existing methods require large-scale datasets to learn complex pixel-level mappings. However, the substantial training and storage costs associated with these datasets hinder their practical deployment. While dataset distillation (DD) can alleviate these burdens, existing methods mainly target high-level tasks, where multiple samples share the same label. This many-to-one mapping allows distilled data to capture shared semantics and achieve information compression. In contrast, low-level tasks involve a many-to-many mapping that requires pixel-level fidelity, making low-level DD an underdetermined problem, as a small distilled dataset cannot fully constrain the dense pixel-level mappings. To address this, we propose the first low-level DD method for medical image enhancement. We first leverage anatomical similarities across patients to construct the shared anatomical prior based on a representative patient, which serves as the initialization for the distilled data of different patients. This prior is then personalized for each patient using a Structure-Preserving Personalized Generation (SPG) module, which integrates patient-specific anatomical information into the distilled dataset while preserving pixel-level fidelity. For different low-level tasks, the distilled data is used to construct task-specific high- and low-quality training pairs. Patient-specific knowledge is injected into the distilled data by aligning the gradients computed from networks trained on the distilled pairs with those from the corresponding patient's raw data. Notably, downstream users cannot access raw patient data. Instead, only a distilled dataset containing abstract training information is shared, which excludes patient-specific details and thus preserves privacy.

</details>


### [218] [DGS-Net: Distillation-Guided Gradient Surgery for CLIP Fine-Tuning in AI-Generated Image Detection](https://arxiv.org/abs/2511.13108)
*Jiazhen Yan,Ziqiang Li,Fan Wang,Boyu Wang,Zhangjie Fu*

Main category: cs.CV

TL;DR: 提出了DGS-Net框架，通过梯度空间分解和蒸馏指导来保护预训练先验知识，同时抑制任务无关组件，在AI生成图像检测任务上取得优异性能


<details>
  <summary>Details</summary>
Motivation: 解决多模态模型微调时的灾难性遗忘问题，保护预训练先验知识并提升跨域泛化能力

Method: 使用梯度空间分解技术分离优化过程中的有害和有益下降方向，通过投影任务梯度到有害方向的正交补空间，并与冻结CLIP编码器蒸馏的有益方向对齐

Result: 在50个生成模型上的实验表明，该方法平均优于现有最佳方法6.6个百分点，具有优越的检测性能和跨域泛化能力

Conclusion: DGS-Net通过统一的优化策略有效解决了预训练先验保护与任务无关抑制的平衡问题，为AI生成内容检测提供了有效解决方案

Abstract: The rapid progress of generative models such as GANs and diffusion models has led to the widespread proliferation of AI-generated images, raising concerns about misinformation, privacy violations, and trust erosion in digital media. Although large-scale multimodal models like CLIP offer strong transferable representations for detecting synthetic content, fine-tuning them often induces catastrophic forgetting, which degrades pre-trained priors and limits cross-domain generalization. To address this issue, we propose the Distillation-guided Gradient Surgery Network (DGS-Net), a novel framework that preserves transferable pre-trained priors while suppressing task-irrelevant components. Specifically, we introduce a gradient-space decomposition that separates harmful and beneficial descent directions during optimization. By projecting task gradients onto the orthogonal complement of harmful directions and aligning with beneficial ones distilled from a frozen CLIP encoder, DGS-Net achieves unified optimization of prior preservation and irrelevant suppression. Extensive experiments on 50 generative models demonstrate that our method outperforms state-of-the-art approaches by an average margin of 6.6, achieving superior detection performance and generalization across diverse generation techniques.

</details>


### [219] [Learning Implicit Neural Degradation Representation for Unpaired Image Dehazing](https://arxiv.org/abs/2511.13110)
*Shuaibin Fan,Senming Zhong,Wenchao Yan,Minglong Xue*

Main category: cs.CV

TL;DR: 提出了一种基于隐式神经退化表示的无监督去雾方法，通过结合通道独立和通道依赖机制来增强非线性依赖学习能力，并设计隐式神经表示将雾霾退化建模为连续函数，在复杂场景下实现高质量图像恢复。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理复杂场景时难以平衡非均匀雾霾分布的细粒度特征表示和全局一致性建模，需要更好地学习雾霾在空间变化中的共同退化表示。

Method: 1. 基于Kolmogorov-Arnold表示定理，结合通道独立和通道依赖机制增强非线性依赖学习能力；2. 设计隐式神经表示将雾霾退化建模为连续函数；3. 提出密集残差增强模块消除冗余信息。

Result: 实验结果表明，该方法在各种公开和真实世界数据集上实现了具有竞争力的去雾性能。

Conclusion: 该方法通过隐式神经退化表示有效解决了复杂场景下的图像去雾问题，在保持视觉感知质量的同时实现了高质量图像恢复。

Abstract: Image dehazing is an important task in the field of computer vision, aiming at restoring clear and detail-rich visual content from haze-affected images. However, when dealing with complex scenes, existing methods often struggle to strike a balance between fine-grained feature representation of inhomogeneous haze distribution and global consistency modeling. Furthermore, to better learn the common degenerate representation of haze in spatial variations, we propose an unsupervised dehaze method for implicit neural degradation representation. Firstly, inspired by the Kolmogorov-Arnold representation theorem, we propose a mechanism combining the channel-independent and channel-dependent mechanisms, which efficiently enhances the ability to learn from nonlinear dependencies. which in turn achieves good visual perception in complex scenes. Moreover, we design an implicit neural representation to model haze degradation as a continuous function to eliminate redundant information and the dependence on explicit feature extraction and physical models. To further learn the implicit representation of the haze features, we also designed a dense residual enhancement module from it to eliminate redundant information. This achieves high-quality image restoration. Experimental results show that our method achieves competitive dehaze performance on various public and real-world datasets. This project code will be available at https://github.com/Fan-pixel/NeDR-Dehaze.

</details>


### [220] [Semantics and Content Matter: Towards Multi-Prior Hierarchical Mamba for Image Deraining](https://arxiv.org/abs/2511.13113)
*Zhaocheng Yu,Kui Jiang,Junjun Jiang,Xianming Liu,Guanglu Sun,Yi Xiao*

Main category: cs.CV

TL;DR: 提出MPHM网络用于图像去雨，通过融合宏观语义文本先验和微观结构视觉先验，采用渐进式先验融合注入策略，在多个数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有去雨方法在语义和空间细节保真度方面存在不足，需要同时处理全局上下文建模和局部细节恢复。

Method: 使用多先验分层Mamba网络，整合CLIP文本先验和DINOv2视觉先验，采用渐进式先验融合注入和傅里叶增强双路径设计。

Result: 在Rain200H数据集上PSNR提升0.57dB，在真实雨景场景中表现出优异的泛化能力。

Conclusion: MPHM网络通过异构先验的协同整合，在图像去雨任务中实现了语义保真和细节恢复的平衡，性能优于现有方法。

Abstract: Rain significantly degrades the performance of computer vision systems, particularly in applications like autonomous driving and video surveillance. While existing deraining methods have made considerable progress, they often struggle with fidelity of semantic and spatial details. To address these limitations, we propose the Multi-Prior Hierarchical Mamba (MPHM) network for image deraining. This novel architecture synergistically integrates macro-semantic textual priors (CLIP) for task-level semantic guidance and micro-structural visual priors (DINOv2) for scene-aware structural information. To alleviate potential conflicts between heterogeneous priors, we devise a progressive Priors Fusion Injection (PFI) that strategically injects complementary cues at different decoder levels. Meanwhile, we equip the backbone network with an elaborate Hierarchical Mamba Module (HMM) to facilitate robust feature representation, featuring a Fourier-enhanced dual-path design that concurrently addresses global context modeling and local detail recovery. Comprehensive experiments demonstrate MPHM's state-of-the-art performance, achieving a 0.57 dB PSNR gain on the Rain200H dataset while delivering superior generalization on real-world rainy scenarios.

</details>


### [221] [A Lightweight 3D Anomaly Detection Method with Rotationally Invariant Features](https://arxiv.org/abs/2511.13115)
*Hanzhe Liang,Jie Zhou,Can Gao,Bingyang Guo,Jinbao Wang,Linlin Shen*

Main category: cs.CV

TL;DR: 提出了一种旋转不变特征框架RIF用于3D异常检测，通过点坐标映射和轻量级卷积变换网络解决点云数据旋转和位置变化带来的特征不一致问题。


<details>
  <summary>Details</summary>
Motivation: 现有3D异常检测方法在处理旋转和位置变化的点云数据时，特征会发生显著变化，影响检测性能。

Method: 1. 点坐标映射技术将点映射到旋转不变空间；2. 轻量级CTF-Net网络提取旋转不变特征；3. 引入迁移学习预训练特征提取器。

Result: 在Anomaly-ShapeNet数据集上平均P-AUROC提升17.7%，在Real3D-AD数据集上提升1.6%，展现出强泛化能力。

Conclusion: RIF框架有效解决了点云旋转不变性问题，在多个数据集上表现优异，具有工业应用潜力。

Abstract: 3D anomaly detection (AD) is a crucial task in computer vision, aiming to identify anomalous points or regions from point cloud data. However, existing methods may encounter challenges when handling point clouds with changes in orientation and position because the resulting features may vary significantly. To address this problem, we propose a novel Rotationally Invariant Features (RIF) framework for 3D AD. Firstly, to remove the adverse effect of variations on point cloud data, we develop a Point Coordinate Mapping (PCM) technique, which maps each point into a rotationally invariant space to maintain consistency of representation. Then, to learn robust and discriminative features, we design a lightweight Convolutional Transform Feature Network (CTF-Net) to extract rotationally invariant features for the memory bank. To improve the ability of the feature extractor, we introduce the idea of transfer learning to pre-train the feature extractor with 3D data augmentation. Experimental results show that the proposed method achieves the advanced performance on the Anomaly-ShapeNet dataset, with an average P-AUROC improvement of 17.7\%, and also gains the best performance on the Real3D-AD dataset, with an average P-AUROC improvement of 1.6\%. The strong generalization ability of RIF has been verified by combining it with traditional feature extraction methods on anomaly detection tasks, demonstrating great potential for industrial applications.

</details>


### [222] [CloseUpShot: Close-up Novel View Synthesis from Sparse-views via Point-conditioned Diffusion Model](https://arxiv.org/abs/2511.13121)
*Yuqi Zhang,Guanying Chen,Jiaxing Chen,Chuanyu Fu,Chuan Huang,Shuguang Cui*

Main category: cs.CV

TL;DR: CloseUpShot是一个基于扩散的框架，通过点条件视频扩散从稀疏输入实现近距离新颖视图合成，解决了现有方法在近距离场景下细节捕捉不足的问题。


<details>
  <summary>Details</summary>
Motivation: 稀疏输入视图下的3D场景重建和新颖视图合成具有挑战性，现有方法主要针对适度视角变化，在近距离场景下由于输入信息严重受限而难以捕捉细粒度细节。

Method: 提出分层扭曲和遮挡感知噪声抑制来增强条件图像质量，引入全局结构指导利用密集融合点云为扩散过程提供一致几何上下文，补偿稀疏条件输入中缺乏全局一致3D约束的问题。

Result: 在多个数据集上的广泛实验表明，该方法优于现有方法，特别是在近距离新颖视图合成方面，验证了设计的有效性。

Conclusion: CloseUpShot通过改进的条件图像质量和全局几何约束，有效提升了稀疏输入下近距离新颖视图合成的性能。

Abstract: Reconstructing 3D scenes and synthesizing novel views from sparse input views is a highly challenging task. Recent advances in video diffusion models have demonstrated strong temporal reasoning capabilities, making them a promising tool for enhancing reconstruction quality under sparse-view settings. However, existing approaches are primarily designed for modest viewpoint variations, which struggle in capturing fine-grained details in close-up scenarios since input information is severely limited. In this paper, we present a diffusion-based framework, called CloseUpShot, for close-up novel view synthesis from sparse inputs via point-conditioned video diffusion. Specifically, we observe that pixel-warping conditioning suffers from severe sparsity and background leakage in close-up settings. To address this, we propose hierarchical warping and occlusion-aware noise suppression, enhancing the quality and completeness of the conditioning images for the video diffusion model. Furthermore, we introduce global structure guidance, which leverages a dense fused point cloud to provide consistent geometric context to the diffusion process, to compensate for the lack of globally consistent 3D constraints in sparse conditioning inputs. Extensive experiments on multiple datasets demonstrate that our method outperforms existing approaches, especially in close-up novel view synthesis, clearly validating the effectiveness of our design.

</details>


### [223] [Region-Point Joint Representation for Effective Trajectory Similarity Learning](https://arxiv.org/abs/2511.13125)
*Hao Long,Silin Zhou,Lisi Chen,Shuo Shang*

Main category: cs.CV

TL;DR: RePo是一种新的轨迹相似性计算方法，通过联合编码区域级和点级特征来捕捉空间上下文和细粒度移动模式，相比现有方法平均准确率提升22.2%。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的轨迹相似性计算方法未能充分利用轨迹信息的完整频谱进行相似性建模，需要一种能够同时捕捉空间上下文和细粒度移动模式的方法。

Method: 1）区域级表示：将GPS轨迹映射到网格序列，通过结构特征和视觉特征增强的空间上下文；2）点级表示：使用三个轻量级专家网络提取局部、相关性和连续移动模式；3）路由网络自适应融合点级特征，并通过交叉注意力与区域级特征结合生成最终轨迹嵌入；4）使用带困难负样本的对比损失进行训练。

Result: 实验结果表明，RePo在所有评估指标上相比最先进基线方法平均准确率提升22.2%。

Conclusion: RePo通过联合编码区域级和点级特征，有效提升了轨迹相似性计算的性能，证明了该方法在捕捉全面轨迹信息方面的优势。

Abstract: Recent learning-based methods have reduced the computational complexity of traditional trajectory similarity computation, but state-of-the-art (SOTA) methods still fail to leverage the comprehensive spectrum of trajectory information for similarity modeling. To tackle this problem, we propose \textbf{RePo}, a novel method that jointly encodes \textbf{Re}gion-wise and \textbf{Po}int-wise features to capture both spatial context and fine-grained moving patterns. For region-wise representation, the GPS trajectories are first mapped to grid sequences, and spatial context are captured by structural features and semantic context enriched by visual features. For point-wise representation, three lightweight expert networks extract local, correlation, and continuous movement patterns from dense GPS sequences. Then, a router network adaptively fuses the learned point-wise features, which are subsequently combined with region-wise features using cross-attention to produce the final trajectory embedding. To train RePo, we adopt a contrastive loss with hard negative samples to provide similarity ranking supervision. Experiment results show that RePo achieves an average accuracy improvement of 22.2\% over SOTA baselines across all evaluation metrics.

</details>


### [224] [VEIL: Jailbreaking Text-to-Video Models via Visual Exploitation from Implicit Language](https://arxiv.org/abs/2511.13127)
*Zonghao Ying,Moyang Chen,Nizhang Li,Zhiqiang Wang,Wenxin Zhang,Quanchen Zou,Zonglei Jing,Aishan Liu,Xianglong Liu*

Main category: cs.CV

TL;DR: VEIL是一种针对文本到视频（T2V）模型的越狱攻击框架，通过设计包含中性场景锚点、潜在听觉触发器和风格调制器的模块化提示，利用跨模态关联模式诱导模型生成语义不安全但表面良性的视频。


<details>
  <summary>Details</summary>
Motivation: 现有T2V模型越狱攻击通常通过添加明显不安全的对抗性扰动，容易被检测和防御。本文旨在开发更隐蔽的攻击方法，利用模型学习的跨模态关联，通过表面良性的提示实现越狱。

Method: 提出VEIL框架，包含三个模块：中性场景锚点（提供表面场景描述）、潜在听觉触发器（利用音频-视觉共现先验）、风格调制器（增强触发效果）。通过约束优化和引导搜索平衡隐蔽性和有效性。

Result: 在7个T2V模型上的实验表明，该方法在商业模型中的平均攻击成功率提高了23%。

Conclusion: VEIL揭示了T2V模型安全防护的盲点，表明即使表面良性的提示也可能通过跨模态关联诱导不安全内容生成，需要更细粒度的安全机制。

Abstract: Jailbreak attacks can circumvent model safety guardrails and reveal critical blind spots. Prior attacks on text-to-video (T2V) models typically add adversarial perturbations to obviously unsafe prompts, which are often easy to detect and defend. In contrast, we show that benign-looking prompts containing rich, implicit cues can induce T2V models to generate semantically unsafe videos that both violate policy and preserve the original (blocked) intent. To realize this, we propose VEIL, a jailbreak framework that leverages T2V models' cross-modal associative patterns via a modular prompt design. Specifically, our prompts combine three components: neutral scene anchors, which provide the surface-level scene description extracted from the blocked intent to maintain plausibility; latent auditory triggers, textual descriptions of innocuous-sounding audio events (e.g., creaking, muffled noises) that exploit learned audio-visual co-occurrence priors to bias the model toward particular unsafe visual concepts; and stylistic modulators, cinematic directives (e.g., camera framing, atmosphere) that amplify and stabilize the latent trigger's effect. We formalize attack generation as a constrained optimization over the above modular prompt space and solve it with a guided search procedure that balances stealth and effectiveness. Extensive experiments over 7 T2V models demonstrate the efficacy of our attack, achieving a 23 percent improvement in average attack success rate in commercial models.

</details>


### [225] [Shedding Light on VLN Robustness: A Black-box Framework for Indoor Lighting-based Adversarial Attack](https://arxiv.org/abs/2511.13132)
*Chenyang Li,Wenbing Tang,Yihao Huang,Sinong Simon Zhan,Ming Hu,Xiaojun Jia,Yang Liu*

Main category: cs.CV

TL;DR: 本文提出了一种基于室内照明的对抗攻击框架ILA，通过操纵全局光照来破坏视觉语言导航（VLN）代理的鲁棒性，揭示了VLN代理对现实室内光照变化的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 现有对抗评估通常依赖不常见的纹理扰动，这些条件在现实室内环境中很少遇到。室内光照作为内在但被忽视的场景属性，对导航有重要影响，但VLN代理对此的鲁棒性尚未得到充分研究。

Method: 提出了ILA黑盒框架，包含两种攻击模式：SILA（静态照明攻击，光照强度在整段导航中保持不变）和DILA（动态照明攻击，在关键时刻开关灯以引发突然的光照变化）。

Result: 在两个最先进的VLN模型和三个导航任务上的评估显示，ILA显著增加了失败率并降低了轨迹效率，表明VLN代理对现实室内光照变化存在先前未被认识的脆弱性。

Conclusion: 室内光照变化是VLN代理的一个重要脆弱点，ILA框架为评估和提升VLN系统在真实环境中的鲁棒性提供了有效工具。

Abstract: Vision-and-Language Navigation (VLN) agents have made remarkable progress, but their robustness remains insufficiently studied. Existing adversarial evaluations often rely on perturbations that manifest as unusual textures rarely encountered in everyday indoor environments. Errors under such contrived conditions have limited practical relevance, as real-world agents are unlikely to encounter such artificial patterns. In this work, we focus on indoor lighting, an intrinsic yet largely overlooked scene attribute that strongly influences navigation. We propose Indoor Lighting-based Adversarial Attack (ILA), a black-box framework that manipulates global illumination to disrupt VLN agents. Motivated by typical household lighting usage, we design two attack modes: Static Indoor Lighting-based Attack (SILA), where the lighting intensity remains constant throughout an episode, and Dynamic Indoor Lighting-based Attack (DILA), where lights are switched on or off at critical moments to induce abrupt illumination changes. We evaluate ILA on two state-of-the-art VLN models across three navigation tasks. Results show that ILA significantly increases failure rates while reducing trajectory efficiency, revealing previously unrecognized vulnerabilities of VLN agents to realistic indoor lighting variations.

</details>


### [226] [MedGEN-Bench: Contextually entangled benchmark for open-ended multimodal medical generation](https://arxiv.org/abs/2511.13135)
*Junjie Yang,Yuhao Yan,Gang Wu,Yuxuan Wang,Ruoyu Liang,Xinjie Jiang,Xiang Wan,Fenglei Fan,Yongquan Zhang,Feiwei Qin,Changmiao Wan*

Main category: cs.CV

TL;DR: 本文提出了MedGEN-Bench基准测试，针对医疗视觉语言模型在临床工作流中的实际需求，解决了现有医疗视觉基准在查询模糊性、诊断推理简化和图像生成能力评估不足等问题。


<details>
  <summary>Details</summary>
Motivation: 随着视觉语言模型在医疗应用中的普及，临床医生期望AI系统不仅能生成文本诊断，还能生成与真实临床工作流无缝集成的医学图像。现有医疗视觉基准存在查询模糊、诊断推理简化、忽视图像生成能力评估等局限性。

Method: 开发了MedGEN-Bench基准测试，包含6,422个专家验证的图像-文本对，涵盖6种成像模态、16个临床任务和28个子任务。基准分为三种格式：视觉问答、图像编辑和上下文多模态生成。采用三层次评估框架，整合像素级指标、语义文本分析和专家指导的临床相关性评分。

Result: 使用该框架系统评估了10个组合框架、3个统一模型和5个视觉语言模型。基准测试特别关注需要复杂跨模态推理和开放式生成输出的上下文交织指令。

Conclusion: MedGEN-Bench通过提供更全面的多模态评估标准，推动了医疗AI研究的发展，特别是在需要复杂推理和图像生成能力的临床应用场景中。

Abstract: As Vision-Language Models (VLMs) increasingly gain traction in medical applications, clinicians are progressively expecting AI systems not only to generate textual diagnoses but also to produce corresponding medical images that integrate seamlessly into authentic clinical workflows. Despite the growing interest, existing medical visual benchmarks present notable limitations. They often rely on ambiguous queries that lack sufficient relevance to image content, oversimplify complex diagnostic reasoning into closed-ended shortcuts, and adopt a text-centric evaluation paradigm that overlooks the importance of image generation capabilities. To address these challenges, we introduce \textsc{MedGEN-Bench}, a comprehensive multimodal benchmark designed to advance medical AI research. MedGEN-Bench comprises 6,422 expert-validated image-text pairs spanning six imaging modalities, 16 clinical tasks, and 28 subtasks. It is structured into three distinct formats: Visual Question Answering, Image Editing, and Contextual Multimodal Generation. What sets MedGEN-Bench apart is its focus on contextually intertwined instructions that necessitate sophisticated cross-modal reasoning and open-ended generative outputs, moving beyond the constraints of multiple-choice formats. To evaluate the performance of existing systems, we employ a novel three-tier assessment framework that integrates pixel-level metrics, semantic text analysis, and expert-guided clinical relevance scoring. Using this framework, we systematically assess 10 compositional frameworks, 3 unified models, and 5 VLMs.

</details>


### [227] [WinMamba: Multi-Scale Shifted Windows in State Space Model for 3D Object Detection](https://arxiv.org/abs/2511.13138)
*Longhui Zheng,Qiming Xia,Xiaolu Chen,Zhaoliang Liu,Chenglu Wen*

Main category: cs.CV

TL;DR: WinMamba是一种基于Mamba的3D特征编码骨干网络，通过窗口尺度自适应模块和窗口偏移策略解决现有方法在固定窗口内轴对齐扫描时丢失空间信息的问题，在KITTI和Waymo数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 3D目标检测在自动驾驶中至关重要，但现有方法难以同时最大化计算效率和捕获长距离空间依赖关系。Mamba模型以其线性状态空间设计以较低成本捕获长距离依赖，但现有方法依赖固定窗口内的轴对齐扫描，会丢弃空间信息。

Method: 提出WinMamba块组成的骨干网络，包含窗口尺度自适应模块（补偿不同分辨率下的体素特征）和WinMamba层（配备可学习位置编码和窗口偏移策略以获得丰富上下文线索）。

Result: 在KITTI和Waymo数据集上的大量实验表明，WinMamba显著优于基线方法。消融研究进一步验证了WSF和AWF模块对提高检测精度的各自贡献。

Conclusion: WinMamba通过创新的窗口尺度自适应和窗口偏移策略，有效解决了3D目标检测中效率与长距离依赖捕获的平衡问题，为自动驾驶领域的3D感知提供了有力解决方案。

Abstract: 3D object detection is critical for autonomous driving, yet it remains fundamentally challenging to simultaneously maximize computational efficiency and capture long-range spatial dependencies. We observed that Mamba-based models, with their linear state-space design, capture long-range dependencies at lower cost, offering a promising balance between efficiency and accuracy. However, existing methods rely on axis-aligned scanning within a fixed window, inevitably discarding spatial information. To address this problem, we propose WinMamba, a novel Mamba-based 3D feature-encoding backbone composed of stacked WinMamba blocks. To enhance the backbone with robust multi-scale representation, the WinMamba block incorporates a window-scale-adaptive module that compensates voxel features across varying resolutions during sampling. Meanwhile, to obtain rich contextual cues within the linear state space, we equip the WinMamba layer with a learnable positional encoding and a window-shift strategy. Extensive experiments on the KITTI and Waymo datasets demonstrate that WinMamba significantly outperforms the baseline. Ablation studies further validate the individual contributions of the WSF and AWF modules in improving detection accuracy. The code will be made publicly available.

</details>


### [228] [Automated Road Distress Detection Using Vision Transformersand Generative Adversarial Networks](https://arxiv.org/abs/2511.13145)
*Cesar Portocarrero Rodriguez,Laura Vandeweyen,Yosuke Yamamoto*

Main category: cs.CV

TL;DR: 该研究探索使用计算机视觉技术进行道路病害分割，评估了GAN生成合成数据的效果，并比较了CNN和MaskFormer模型在道路监测中的性能。


<details>
  <summary>Details</summary>
Motivation: 美国道路基础设施状况较差（评级为D），现有检测方法效率低下且成本高昂。随着自动驾驶车辆提供的实时视觉数据增加，需要利用计算机视觉技术进行更高效的道路监测和维护。

Method: 1. 使用生成对抗网络（GANs）生成合成数据用于模型训练评估；2. 应用卷积神经网络（CNNs）进行道路病害分割；3. 使用基于Transformer的MaskFormer模型进行对比分析。

Result: GAN生成的数据能提升模型性能，MaskFormer在mAP50和IoU两个指标上均优于CNN模型。

Conclusion: 计算机视觉技术特别是MaskFormer模型结合合成数据训练，为道路基础设施监测提供了更有效的解决方案，有助于改善道路维护效率。

Abstract: The American Society of Civil Engineers has graded Americas infrastructure condition as a C, with the road system receiving a dismal D. Roads are vital to regional economic viability, yet their management, maintenance, and repair processes remain inefficient, relying on outdated manual or laser-based inspection methods that are both costly and time-consuming. With the increasing availability of real-time visual data from autonomous vehicles, there is an opportunity to apply computer vision (CV) methods for advanced road monitoring, providing insights to guide infrastructure rehabilitation efforts. This project explores the use of state-of-the-art CV techniques for road distress segmentation. It begins by evaluating synthetic data generated with Generative Adversarial Networks (GANs) to assess its usefulness for model training. The study then applies Convolutional Neural Networks (CNNs) for road distress segmentation and subsequently examines the transformer-based model MaskFormer. Results show that GAN-generated data improves model performance and that MaskFormer outperforms the CNN model in two metrics: mAP50 and IoU.

</details>


### [229] [Skeletons Speak Louder than Text: A Motion-Aware Pretraining Paradigm for Video-Based Person Re-Identification](https://arxiv.org/abs/2511.13150)
*Rifen Lin,Alex Jinpeng Wang,Jiawei Mo,Min Li*

Main category: cs.CV

TL;DR: CSIP-ReID是首个基于骨架的预训练框架，通过对比学习对齐骨架和视觉特征，结合动态原型融合更新器和骨架引导时序建模模块，在视频行人重识别任务上取得state-of-the-art效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本的多模态预训练方法存在两个根本限制：缺乏真正的多模态预训练，以及文本难以捕捉细粒度时序运动信息。骨架序列能提供与视频帧对齐的时空信息模态。

Method: 两阶段方法：第一阶段使用对比学习在序列级别对齐骨架和视觉特征；第二阶段引入动态原型融合更新器(PFU)来优化多模态身份原型，融合运动和外观线索，并提出骨架引导时序建模(SGTM)模块从骨架数据中提取时序线索并整合到视觉特征中。

Result: 在标准视频ReID基准测试(MARS, LS-VID, iLIDS-VID)上达到新的state-of-the-art结果，同时在骨架only的ReID任务(BIWI, IAS)上表现出强大的泛化能力，显著优于先前方法。

Conclusion: CSIP-ReID开创了一种无标注和运动感知的ReID预训练范式，为多模态表示学习开辟了新前沿。

Abstract: Multimodal pretraining has revolutionized visual understanding, but its impact on video-based person re-identification (ReID) remains underexplored. Existing approaches often rely on video-text pairs, yet suffer from two fundamental limitations: (1) lack of genuine multimodal pretraining, and (2) text poorly captures fine-grained temporal motion-an essential cue for distinguishing identities in video. In this work, we take a bold departure from text-based paradigms by introducing the first skeleton-driven pretraining framework for ReID. To achieve this, we propose Contrastive Skeleton-Image Pretraining for ReID (CSIP-ReID), a novel two-stage method that leverages skeleton sequences as a spatiotemporally informative modality aligned with video frames. In the first stage, we employ contrastive learning to align skeleton and visual features at sequence level. In the second stage, we introduce a dynamic Prototype Fusion Updater (PFU) to refine multimodal identity prototypes, fusing motion and appearance cues. Moreover, we propose a Skeleton Guided Temporal Modeling (SGTM) module that distills temporal cues from skeleton data and integrates them into visual features. Extensive experiments demonstrate that CSIP-ReID achieves new state-of-the-art results on standard video ReID benchmarks (MARS, LS-VID, iLIDS-VID). Moreover, it exhibits strong generalization to skeleton-only ReID tasks (BIWI, IAS), significantly outperforming previous methods. CSIP-ReID pioneers an annotation-free and motion-aware pretraining paradigm for ReID, opening a new frontier in multimodal representation learning.

</details>


### [230] [SOMA: Feature Gradient Enhanced Affine-Flow Matching for SAR-Optical Registration](https://arxiv.org/abs/2511.13168)
*Haodong Wang,Tao Zhuo,Xiuwei Zhang,Hanlin Yin,Wencong Wu,Yanning Zhang*

Main category: cs.CV

TL;DR: SOMA是一个用于SAR和光学图像密集配准的框架，通过集成结构梯度先验和混合匹配策略，显著提高了配准精度。


<details>
  <summary>Details</summary>
Motivation: SAR和光学图像由于成像机制和视觉特征差异巨大，像素级配准仍然具有挑战性。深度学习在SAR-光学配准任务中表现不佳，传统的梯度信息在手工描述符中很重要，但在深度学习框架中未被有效利用。

Method: 提出SOMA框架：1）特征梯度增强器（FGE）使用注意力和重建机制将多尺度、多方向梯度滤波器嵌入特征空间；2）全局-局部仿射流匹配器（GLAM）结合仿射变换和基于流的细化，采用由粗到精的架构。

Result: 在SEN1-2数据集上CMR@1px提高12.29%，在GFGE_SO数据集上提高18.50%。SOMA表现出强鲁棒性，在不同场景和分辨率下泛化能力良好。

Conclusion: SOMA通过有效利用梯度信息和混合匹配策略，显著提升了SAR-光学图像配准性能，为解决这一挑战性任务提供了有效解决方案。

Abstract: Achieving pixel-level registration between SAR and optical images remains a challenging task due to their fundamentally different imaging mechanisms and visual characteristics. Although deep learning has achieved great success in many cross-modal tasks, its performance on SAR-Optical registration tasks is still unsatisfactory. Gradient-based information has traditionally played a crucial role in handcrafted descriptors by highlighting structural differences. However, such gradient cues have not been effectively leveraged in deep learning frameworks for SAR-Optical image matching. To address this gap, we propose SOMA, a dense registration framework that integrates structural gradient priors into deep features and refines alignment through a hybrid matching strategy. Specifically, we introduce the Feature Gradient Enhancer (FGE), which embeds multi-scale, multi-directional gradient filters into the feature space using attention and reconstruction mechanisms to boost feature distinctiveness. Furthermore, we propose the Global-Local Affine-Flow Matcher (GLAM), which combines affine transformation and flow-based refinement within a coarse-to-fine architecture to ensure both structural consistency and local accuracy. Experimental results demonstrate that SOMA significantly improves registration precision, increasing the CMR@1px by 12.29% on the SEN1-2 dataset and 18.50% on the GFGE_SO dataset. In addition, SOMA exhibits strong robustness and generalizes well across diverse scenes and resolutions.

</details>


### [231] [THIR: Topological Histopathological Image Retrieval](https://arxiv.org/abs/2511.13170)
*Zahra Tabatabaei,Jon Sporring*

Main category: cs.CV

TL;DR: THIR是一个基于拓扑数据分析的医学图像检索框架，无需监督学习即可从乳腺癌组织病理学图像中提取拓扑特征进行相似性检索。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌是全球女性主要死因之一，早期诊断和准确临床决策至关重要。传统深度学习方法需要大量标注数据和GPU资源，限制了临床应用。

Method: 利用持续性同调理论中的Betti数，通过立方持续性直接从RGB组织病理学图像提取拓扑指纹，编码环状结构的演化特征，形成紧凑可解释的特征向量进行相似性检索。

Result: 在BreaKHis数据集上的实验表明，THIR优于现有监督和无监督方法，仅需20分钟即可处理整个数据集，且仅需标准CPU。

Conclusion: THIR提供了一个快速、可扩展且无需训练的临床图像检索解决方案，特别适合资源受限的医疗环境。

Abstract: According to the World Health Organization, breast cancer claimed the lives of approximately 685,000 women in 2020. Early diagnosis and accurate clinical decision making are critical in reducing this global burden. In this study, we propose THIR, a novel Content-Based Medical Image Retrieval (CBMIR) framework that leverages topological data analysis specifically, Betti numbers derived from persistent homology to characterize and retrieve histopathological images based on their intrinsic structural patterns. Unlike conventional deep learning approaches that rely on extensive training, annotated datasets, and powerful GPU resources, THIR operates entirely without supervision. It extracts topological fingerprints directly from RGB histopathological images using cubical persistence, encoding the evolution of loops as compact, interpretable feature vectors. The similarity retrieval is then performed by computing the distances between these topological descriptors, efficiently returning the top-K most relevant matches.
  Extensive experiments on the BreaKHis dataset demonstrate that THIR outperforms state of the art supervised and unsupervised methods. It processes the entire dataset in under 20 minutes on a standard CPU, offering a fast, scalable, and training free solution for clinical image retrieval.

</details>


### [232] [HDW-SR: High-Frequency Guided Diffusion Model based on Wavelet Decomposition for Image Super-Resolution](https://arxiv.org/abs/2511.13175)
*Chao Yang,Boqian Zhang,Jinghao Xu,Guang Jiang*

Main category: cs.CV

TL;DR: 提出了基于小波分解的高频引导扩散网络HDW-SR，通过在残差图上进行扩散并利用小波变换实现多尺度频率分解，有效提升单图像超分辨率的高频细节恢复能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的超分辨率方法在高频域指导不足，导致恢复的细节模糊。需要更有效的高频信息引导机制来改善细节恢复质量。

Method: 1. 在残差图上进行扩散而非原图；2. 使用小波下采样替代传统CNN下采样实现多尺度频率分解；3. 设计稀疏交叉注意力机制实现高频子带与低频子带间的显式指导；4. 引入动态阈值块优化高频选择；5. 利用小波变换的可逆性实现低损失特征重建。

Result: 在合成和真实世界数据集上的实验表明，HDW-SR在超分辨率性能上具有竞争力，特别是在恢复细粒度图像细节方面表现优异。

Conclusion: HDW-SR通过小波分解和残差扩散的协同设计，有效解决了扩散模型在超分辨率任务中高频细节恢复不足的问题，为图像超分辨率提供了新的技术路径。

Abstract: Diffusion-based methods have shown great promise in single image super-resolution (SISR); however, existing approaches often produce blurred fine details due to insufficient guidance in the high-frequency domain. To address this issue, we propose a High-Frequency Guided Diffusion Network based on Wavelet Decomposition (HDW-SR), which replaces the conventional U-Net backbone in diffusion frameworks. Specifically, we perform diffusion only on the residual map, allowing the network to focus more effectively on high-frequency information restoration. We then introduce wavelet-based downsampling in place of standard CNN downsampling to achieve multi-scale frequency decomposition, enabling sparse cross-attention between the high-frequency subbands of the pre-super-resolved image and the low-frequency subbands of the diffused image for explicit high-frequency guidance. Moreover, a Dynamic Thresholding Block (DTB) is designed to refine high-frequency selection during the sparse attention process. During upsampling, the invertibility of the wavelet transform ensures low-loss feature reconstruction. Experiments on both synthetic and real-world datasets demonstrate that HDW-SR achieves competitive super-resolution performance, excelling particularly in recovering fine-grained image details. The code will be available after acceptance.

</details>


### [233] [GenTract: Generative Global Tractography](https://arxiv.org/abs/2511.13183)
*Alec Sargood,Lemuel Puglisi,Elinor Thompson,Mirco Musolesi,Daniel C. Alexander*

Main category: cs.CV

TL;DR: GenTract是首个用于全局纤维束追踪的生成模型，通过将纤维束追踪构建为生成任务，直接从dMRI数据生成完整、解剖学合理的流线，在精度上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决传统局部纤维束追踪方法容易累积误差和高假阳性率的问题，以及全局方法计算成本高的问题。

Method: 提出GenTract生成模型，将纤维束追踪构建为生成任务，学习从dMRI到完整流线的直接映射，比较了基于扩散和流匹配的两种范式。

Result: GenTract的精度比次优方法TractOracle高出2.1倍，在低分辨率和噪声数据上的优势更加明显，比最接近的竞争对手高出一个数量级。

Conclusion: GenTract在保持研究级数据高精度的同时，在低质量数据上也表现出可靠性，为全局纤维束追踪提供了有前景的解决方案。

Abstract: Tractography is the process of inferring the trajectories of white-matter pathways in the brain from diffusion magnetic resonance imaging (dMRI). Local tractography methods, which construct streamlines by following local fiber orientation estimates stepwise through an image, are prone to error accumulation and high false positive rates, particularly on noisy or low-resolution data. In contrast, global methods, which attempt to optimize a collection of streamlines to maximize compatibility with underlying fiber orientation estimates, are computationally expensive. To address these challenges, we introduce GenTract, the first generative model for global tractography. We frame tractography as a generative task, learning a direct mapping from dMRI to complete, anatomically plausible streamlines. We compare both diffusion-based and flow matching paradigms and evaluate GenTract's performance against state-of-the-art baselines. Notably, GenTract achieves precision 2.1x higher than the next-best method, TractOracle. This advantage becomes even more pronounced in challenging low-resolution and noisy settings, where it outperforms the closest competitor by an order of magnitude. By producing tractograms with high precision on research-grade data while also maintaining reliability on imperfect, lower-resolution data, GenTract represents a promising solution for global tractography.

</details>


### [234] [Large Language Models Meet Extreme Multi-label Classification: Scaling and Multi-modal Framework](https://arxiv.org/abs/2511.13189)
*Diego Ortego,Marlon Rodríguez,Mario Almagro,Kunal Dahiya,David Jiménez,Juan C. SanMiguel*

Main category: cs.CV

TL;DR: 本文提出ViXML框架，利用解码器模型和视觉信息提升极端多标签分类性能，在保持效率的同时显著超越现有方法


<details>
  <summary>Details</summary>
Motivation: 极端多标签分类需要平衡效率与性能，现有方法主要基于小型编码器模型，未能充分利用大型解码器模型和视觉信息

Method: 开发ViXML框架，整合数十亿参数的解码器模型和基础视觉模型，通过单图像嵌入池化实现高效多模态融合

Result: 在四个公开数据集上验证，ViXML在最大数据集上P@1指标提升达8.21%，视觉增强的小编码器甚至优于纯文本解码器

Conclusion: 视觉信息在极端多标签分类中具有重要价值，ViXML框架成功实现了高效的多模态融合，为未来研究提供了新基准

Abstract: Foundation models have revolutionized artificial intelligence across numerous domains, yet their transformative potential remains largely untapped in Extreme Multi-label Classification (XMC). Queries in XMC are associated with relevant labels from extremely large label spaces, where it is critical to strike a balance between efficiency and performance. Therefore, many recent approaches efficiently pose XMC as a maximum inner product search between embeddings learned from small encoder-only transformer architectures. In this paper, we address two important aspects in XMC: how to effectively harness larger decoder-only models, and how to exploit visual information while maintaining computational efficiency. We demonstrate that both play a critical role in XMC separately and can be combined for improved performance. We show that a few billion-size decoder can deliver substantial improvements while keeping computational overhead manageable. Furthermore, our Vision-enhanced eXtreme Multi-label Learning framework (ViXML) efficiently integrates foundation vision models by pooling a single embedding per image. This limits computational growth while unlocking multi-modal capabilities. Remarkably, ViXML with small encoders outperforms text-only decoder in most cases, showing that an image is worth billions of parameters. Finally, we present an extension of existing text-only datasets to exploit visual metadata and make them available for future benchmarking. Comprehensive experiments across four public text-only datasets and their corresponding image enhanced versions validate our proposals' effectiveness, surpassing previous state-of-the-art by up to +8.21\% in P@1 on the largest dataset. ViXML's code is available at https://github.com/DiegoOrtego/vixml.

</details>


### [235] [Video Spatial Reasoning with Object-Centric 3D Rollout](https://arxiv.org/abs/2511.13190)
*Haoran Tang,Meng Cao,Ruyang Liu,Xiaoxi Liang,Linglong Li,Ge Li,Xiaodan Liang*

Main category: cs.CV

TL;DR: 提出了Object-Centric 3D Rollout (OCR)方法，通过引入结构化扰动来增强多模态大语言模型在视频空间推理中的表现，解决了现有模型存在的查询锁定推理问题。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型在视频空间推理（理解物体位置、方向和相互关系）方面存在局限性，模型往往只关注提示中明确提到的物体而忽略关键上下文线索，这被称为查询锁定推理问题。

Method: 提出OCR策略，在训练过程中对选定物体的3D几何结构引入结构化扰动，通过退化物体特定的视觉线索并将改变的几何结构投影到2D空间，强制模型对整个场景进行整体推理。设计了基于rollout的训练流程，联合利用原始视频和区域噪声视频来优化空间推理轨迹。

Result: 实验表明该方法达到最先进性能：3B参数模型在VSI-Bench上达到47.5%的准确率，优于多个7B基线模型。消融实验证实OCR优于先前的rollout策略（如T-GRPO、NoisyRollout）。

Conclusion: OCR方法有效解决了多模态大语言模型在视频空间推理中的查询锁定问题，通过结构化扰动和整体推理机制显著提升了模型的3D场景理解能力。

Abstract: Recent advances in Multi-modal Large Language Models (MLLMs) have showcased remarkable capabilities in vision-language understanding. However, enabling robust video spatial reasoning-the ability to comprehend object locations, orientations, and inter-object relationships in dynamic 3D scenes-remains a key unsolved challenge. Existing approaches primarily rely on spatially grounded supervised fine-tuning or reinforcement learning, yet we observe that such models often exhibit query-locked reasoning, focusing narrowly on objects explicitly mentioned in the prompt while ignoring critical contextual cues. To address this limitation, we propose Object-Centric 3D Rollout (OCR), a novel strategy that introduces structured perturbations to the 3D geometry of selected objects during training. By degrading object-specific visual cues and projecting the altered geometry into 2D space, OCR compels the model to reason holistically across the entire scene. We further design a rollout-based training pipeline that jointly leverages vanilla and region-noisy videos to optimize spatial reasoning trajectories. Experiments demonstrate state-of-the-art performance: our 3B-parameter model achieves 47.5% accuracy on VSI-Bench, outperforming several 7B baselines. Ablations confirm OCR's superiority over prior rollout strategies (e.g., T-GRPO, NoisyRollout).

</details>


### [236] [Birth of a Painting: Differentiable Brushstroke Reconstruction](https://arxiv.org/abs/2511.13191)
*Ying Jiang,Jiayin Lu,Yunuo Chen,Yumeng He,Kui Wu,Yin Yang,Chenfanfu Jiang*

Main category: cs.CV

TL;DR: 提出了一种可微分的笔划重建框架，通过统一绘画、风格化纹理和涂抹操作，能够忠实再现人类绘画-涂抹循环过程。


<details>
  <summary>Details</summary>
Motivation: 现有生成方法只关注最终图像生成或基于补丁的过程模拟，缺乏明确的笔划结构，无法产生平滑、逼真的阴影效果。

Method: 采用可微分笔划重建框架，包含并行可微分绘画渲染器优化单色和双色贝塞尔笔划，风格生成模块合成几何条件纹理，以及可微分涂抹操作实现自然色彩混合和阴影效果。

Result: 在油画、水彩、水墨和数字绘画上的广泛实验表明，该方法能产生逼真且富有表现力的笔划重建、平滑的色调过渡和丰富的风格化外观。

Conclusion: 该方法为表达性数字绘画创作提供了一个统一的模型，能够有效模拟人类绘画过程中的笔划结构和色调过渡。

Abstract: Painting embodies a unique form of visual storytelling, where the creation process is as significant as the final artwork. Although recent advances in generative models have enabled visually compelling painting synthesis, most existing methods focus solely on final image generation or patch-based process simulation, lacking explicit stroke structure and failing to produce smooth, realistic shading. In this work, we present a differentiable stroke reconstruction framework that unifies painting, stylized texturing, and smudging to faithfully reproduce the human painting-smudging loop. Given an input image, our framework first optimizes single- and dual-color Bezier strokes through a parallel differentiable paint renderer, followed by a style generation module that synthesizes geometry-conditioned textures across diverse painting styles. We further introduce a differentiable smudge operator to enable natural color blending and shading. Coupled with a coarse-to-fine optimization strategy, our method jointly optimizes stroke geometry, color, and texture under geometric and semantic guidance. Extensive experiments on oil, watercolor, ink, and digital paintings demonstrate that our approach produces realistic and expressive stroke reconstructions, smooth tonal transitions, and richly stylized appearances, offering a unified model for expressive digital painting creation. See our project page for more demos: https://yingjiang96.github.io/DiffPaintWebsite/.

</details>


### [237] [Difficulty-Aware Label-Guided Denoising for Monocular 3D Object Detection](https://arxiv.org/abs/2511.13195)
*Soyul Lee,Seungmin Baek,Dongbo Min*

Main category: cs.CV

TL;DR: MonoDLGD是一个针对单目3D目标检测的难度感知标签引导去噪框架，通过自适应扰动和重建真实标签来解决深度估计不准确和忽略检测难度的问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于DETR的单目3D检测方法存在深度估计不准确的问题，且忽略了实例级别的检测难度（如遮挡、距离、截断），导致检测性能不佳。

Method: 提出难度感知标签引导去噪框架，根据检测不确定性自适应扰动真实标签：对简单实例施加更强扰动，对困难实例施加较弱扰动，然后重建标签以提供显式几何监督。通过联合优化标签重建和3D目标检测，实现几何感知表示学习。

Result: 在KITTI基准测试上的广泛实验表明，MonoDLGD在所有难度级别上都达到了最先进的性能。

Conclusion: MonoDLGD通过难度感知的标签扰动和重建机制，有效提升了单目3D目标检测的鲁棒性和准确性，特别是在处理不同复杂度的物体时表现优异。

Abstract: Monocular 3D object detection is a cost-effective solution for applications like autonomous driving and robotics, but remains fundamentally ill-posed due to inherently ambiguous depth cues. Recent DETR-based methods attempt to mitigate this through global attention and auxiliary depth prediction, yet they still struggle with inaccurate depth estimates. Moreover, these methods often overlook instance-level detection difficulty, such as occlusion, distance, and truncation, leading to suboptimal detection performance. We propose MonoDLGD, a novel Difficulty-Aware Label-Guided Denoising framework that adaptively perturbs and reconstructs ground-truth labels based on detection uncertainty. Specifically, MonoDLGD applies stronger perturbations to easier instances and weaker ones into harder cases, and then reconstructs them to effectively provide explicit geometric supervision. By jointly optimizing label reconstruction and 3D object detection, MonoDLGD encourages geometry-aware representation learning and improves robustness to varying levels of object complexity. Extensive experiments on the KITTI benchmark demonstrate that MonoDLGD achieves state-of-the-art performance across all difficulty levels.

</details>


### [238] [Self-Supervised Ultrasound Screen Detection](https://arxiv.org/abs/2511.13197)
*Alberto Gomez,Jorge Oliveira,Ramon Casero,Agis Chartsias*

Main category: cs.CV

TL;DR: 提出一种自监督管道，从超声监视器照片中提取图像，以绕过DICOM传输瓶颈，实现快速算法测试和原型开发。


<details>
  <summary>Details</summary>
Motivation: 解决超声设备依赖DICOM传输图像至医院系统的瓶颈问题，提升新算法测试和原型开发的效率。

Method: 采用自监督学习管道，从超声监视器的照片中提取并校正图像。

Result: 在概念验证研究中，校正后的图像保持了足够的视觉保真度，在心脏视图分类方面与原生DICOM图像相比，平衡准确率达到0.79。

Conclusion: 该方法有效绕过DICOM传输限制，为超声图像算法的快速测试和开发提供了可行方案。

Abstract: Ultrasound (US) machines display images on a built-in monitor, but routine transfer to hospital systems relies on DICOM. We propose a self-supervised pipeline to extract the US image from a photograph of the monitor. This removes the DICOM bottleneck and enables rapid testing and prototyping of new algorithms. In a proof-of-concept study, the rectified images retained enough visual fidelity to classify cardiac views with a balanced accuracy of 0.79 with respect to the native DICOMs.

</details>


### [239] [RefineVAD: Semantic-Guided Feature Recalibration for Weakly Supervised Video Anomaly Detection](https://arxiv.org/abs/2511.13204)
*Junhee Lee,ChaeBeen Bang,MyoungChul Kim,MyeongAh Cho*

Main category: cs.CV

TL;DR: RefineVAD是一个弱监督视频异常检测框架，通过模仿人类感知异常的双过程推理，联合建模时间运动模式和语义结构来改进异常检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法将异常事件视为单一类别，忽略了真实世界异常事件的多样语义和时间特征。受人类感知异常的方式启发，需要同时理解不同异常类型的时间运动模式和语义结构。

Method: 提出RefineVAD框架，包含两个核心模块：MoTAR（运动感知时间注意力和重校准）模块估计运动显著性并动态调整时间焦点；CORE（类别导向细化）模块通过交叉注意力将片段级特征与可学习类别原型对齐，注入软异常类别先验。

Result: 在WVAD基准测试上的广泛实验验证了RefineVAD的有效性，并强调了整合语义上下文来引导特征细化朝向异常相关模式的重要性。

Conclusion: 通过联合利用时间动态和语义结构，RefineVAD能够显式建模运动演化的方式和语义类别的相似性，为弱监督视频异常检测提供了新的有效解决方案。

Abstract: Weakly-Supervised Video Anomaly Detection aims to identify anomalous events using only video-level labels, balancing annotation efficiency with practical applicability. However, existing methods often oversimplify the anomaly space by treating all abnormal events as a single category, overlooking the diverse semantic and temporal characteristics intrinsic to real-world anomalies. Inspired by how humans perceive anomalies, by jointly interpreting temporal motion patterns and semantic structures underlying different anomaly types, we propose RefineVAD, a novel framework that mimics this dual-process reasoning. Our framework integrates two core modules. The first, Motion-aware Temporal Attention and Recalibration (MoTAR), estimates motion salience and dynamically adjusts temporal focus via shift-based attention and global Transformer-based modeling. The second, Category-Oriented Refinement (CORE), injects soft anomaly category priors into the representation space by aligning segment-level features with learnable category prototypes through cross-attention. By jointly leveraging temporal dynamics and semantic structure, explicitly models both "how" motion evolves and "what" semantic category it resembles. Extensive experiments on WVAD benchmark validate the effectiveness of RefineVAD and highlight the importance of integrating semantic context to guide feature refinement toward anomaly-relevant patterns.

</details>


### [240] [End-to-End Multi-Person Pose Estimation with Pose-Aware Video Transformer](https://arxiv.org/abs/2511.13208)
*Yonghui Yu,Jiahang Cai,Xun Wang,Wenwu Yang*

Main category: cs.CV

TL;DR: PAVE-Net是一个端到端的多人视频姿态估计框架，消除了传统两阶段方法中的启发式操作，通过空间编码器和时空姿态解码器实现跨帧关联，显著提升了准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的多人视频姿态估计方法采用两阶段流程（检测+时序建模），依赖检测、RoI裁剪和NMS等启发式操作，限制了准确性和效率。

Method: 提出PAVE-Net框架，包含空间编码器建模帧内关系，时空姿态解码器捕获跨帧全局依赖，采用姿态感知注意力机制实现跨帧个体关联，并显式建模关键点间的时空依赖。

Result: 在PoseTrack2017上比基于图像的端到端方法提升6.0 mAP，准确性与最先进的视频两阶段方法相当，同时效率显著提升。

Conclusion: PAVE-Net是首个端到端的多帧2D人体姿态估计方法，通过消除启发式操作实现了更好的准确性和效率平衡。

Abstract: Existing multi-person video pose estimation methods typically adopt a two-stage pipeline: detecting individuals in each frame, followed by temporal modeling for single-person pose estimation. This design relies on heuristic operations such as detection, RoI cropping, and non-maximum suppression (NMS), limiting both accuracy and efficiency. In this paper, we present a fully end-to-end framework for multi-person 2D pose estimation in videos, effectively eliminating heuristic operations. A key challenge is to associate individuals across frames under complex and overlapping temporal trajectories. To address this, we introduce a novel Pose-Aware Video transformEr Network (PAVE-Net), which features a spatial encoder to model intra-frame relations and a spatiotemporal pose decoder to capture global dependencies across frames. To achieve accurate temporal association, we propose a pose-aware attention mechanism that enables each pose query to selectively aggregate features corresponding to the same individual across consecutive frames.Additionally, we explicitly model spatiotemporal dependencies among pose keypoints to improve accuracy. Notably, our approach is the first end-to-end method for multi-frame 2D human pose estimation.Extensive experiments show that PAVE-Net substantially outperforms prior image-based end-to-end methods, achieving a \textbf{6.0} mAP improvement on PoseTrack2017, and delivers accuracy competitive with state-of-the-art two-stage video-based approaches, while offering significant gains in efficiency.Project page: https://github.com/zgspose/PAVENet

</details>


### [241] [3DAlign-DAER: Dynamic Attention Policy and Efficient Retrieval Strategy for Fine-grained 3D-Text Alignment at Scale](https://arxiv.org/abs/2511.13211)
*Yijia Fan,Jusheng Zhang,Kaitong Cai,Jing Yang,Jian Wang,Keze Wang*

Main category: cs.CV

TL;DR: 3DAlign-DAER是一个统一框架，通过动态注意力策略和高效检索策略来对齐文本和3D几何，解决了现有方法在细粒度语义对齐和大规模3D数据库扩展方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有3D-文本跨模态对齐方法难以将细粒度文本语义与详细几何结构对齐，且在大规模3D数据库上性能显著下降。

Method: 提出动态注意力策略（DAP）使用分层注意力融合模块表示可学习的细粒度token-to-point注意力，并利用蒙特卡洛树搜索动态校准注意力权重；在推理阶段引入高效检索策略（ERS）进行分层搜索；构建了包含200万文本-3D对的Align3D-2M数据集。

Result: 在多个基准测试中表现出优越性能，在准确性和效率上都优于传统方法（如KNN）。

Conclusion: 3DAlign-DAER框架能够有效解决细粒度3D-文本对齐问题，并具有良好的可扩展性，将发布代码、模型和数据集。

Abstract: Despite recent advancements in 3D-text cross-modal alignment, existing state-of-the-art methods still struggle to align fine-grained textual semantics with detailed geometric structures, and their alignment performance degrades significantly when scaling to large-scale 3D databases. To overcome this limitation, we introduce 3DAlign-DAER, a unified framework designed to align text and 3D geometry via the proposed dynamic attention policy and the efficient retrieval strategy, capturing subtle correspondences for diverse cross-modal retrieval and classification tasks. Specifically, during the training, our proposed dynamic attention policy (DAP) employs the Hierarchical Attention Fusion (HAF) module to represent the alignment as learnable fine-grained token-to-point attentions. To optimize these attentions across different tasks and geometric hierarchies, our DAP further exploits the Monte Carlo tree search to dynamically calibrate HAF attention weights via a hybrid reward signal and further enhances the alignment between textual descriptions and local 3D geometry. During the inference, our 3DAlign-DAER introduces an Efficient Retrieval Strategy (ERS) to leverage efficient hierarchical searching in the large-scale embedding spaces, outperforming traditional methods (e.g., KNN) in accuracy and efficiency. Furthermore, to facilitate text-3D alignment research and train our 3DAlign-DAER, we construct Align3D-2M, a large-scale dataset featuring 2M text-3D pairs, to provide sufficient fine-grained cross-modal annotations. Extensive and comprehensive experiments demonstrate the superior performance of our 3DAlign-DAER on diverse benchmarks. We will release our codes, models, and datasets.

</details>


### [242] [Hybrid-Domain Adaptative Representation Learning for Gaze Estimation](https://arxiv.org/abs/2511.13222)
*Qida Tan,Hongyu Yang,Wenchao Du*

Main category: cs.CV

TL;DR: 本文提出了一种混合域自适应表示学习框架（HARL），通过多源混合数据集学习鲁棒的视线表示，解决跨域视线估计中性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: 基于外观的视线估计方法在跨域评估中性能显著下降，主要受表情、佩戴物和图像质量等视线无关因素的干扰。

Method: 1. 通过无监督域自适应方式对齐高质量近眼图像特征，从低质量面部图像中分离视线相关表示；2. 设计稀疏图融合模块探索视线方向与头部姿态之间的几何约束。

Result: 在EyeDiap、MPIIFaceGaze和Gaze360数据集上分别达到5.02°、3.36°和9.26°的最先进精度，并在跨数据集评估中表现出竞争力。

Conclusion: HARL框架能有效学习鲁棒的视线表示，显著提升跨域视线估计性能。

Abstract: Appearance-based gaze estimation, aiming to predict accurate 3D gaze direction from a single facial image, has made promising progress in recent years. However, most methods suffer significant performance degradation in cross-domain evaluation due to interference from gaze-irrelevant factors, such as expressions, wearables, and image quality. To alleviate this problem, we present a novel Hybrid-domain Adaptative Representation Learning (shorted by HARL) framework that exploits multi-source hybrid datasets to learn robust gaze representation. More specifically, we propose to disentangle gaze-relevant representation from low-quality facial images by aligning features extracted from high-quality near-eye images in an unsupervised domain-adaptation manner, which hardly requires any computational or inference costs. Additionally, we analyze the effect of head-pose and design a simple yet efficient sparse graph fusion module to explore the geometric constraint between gaze direction and head-pose, leading to a dense and robust gaze representation. Extensive experiments on EyeDiap, MPIIFaceGaze, and Gaze360 datasets demonstrate that our approach achieves state-of-the-art accuracy of $\textbf{5.02}^{\circ}$ and $\textbf{3.36}^{\circ}$, and $\textbf{9.26}^{\circ}$ respectively, and present competitive performances through cross-dataset evaluation. The code is available at https://github.com/da60266/HARL.

</details>


### [243] [MRIQT: Physics-Aware Diffusion Model for Image Quality Transfer in Neonatal Ultra-Low-Field MRI](https://arxiv.org/abs/2511.13232)
*Malek Al Abed,Sebiha Demir,Anne Groteklaes,Elodie Germani,Shahrooz Faghihroohi,Hemmen Sabir,Shadi Albarqouni*

Main category: cs.CV

TL;DR: MRIQT是一个基于3D条件扩散模型的图像质量转换框架，可将超低场MRI图像质量提升至高场MRI水平，特别针对新生儿脑部成像。


<details>
  <summary>Details</summary>
Motivation: 便携式超低场MRI（0.064T）在新生儿护理中具有可及性优势，但信噪比低、诊断质量差，无法与高场MRI相比。需要一种方法将uLF-MRI图像质量提升至临床可用水平。

Method: 采用3D条件扩散框架，结合物理一致的K空间退化模拟、v-prediction与分类器自由引导的稳定图像生成，以及SNR加权的3D感知损失来保持解剖保真度。使用注意力-UNet架构进行结构保持的转换。

Result: 在新生儿队列测试中，MRIQT在PSNR指标上比现有最佳方法提升15.3%，85%的输出被医生评为良好质量且病理清晰可见。

Conclusion: MRIQT能够实现高保真的扩散基增强，使便携式超低场MRI能够可靠地用于新生儿脑部评估。

Abstract: Portable ultra-low-field MRI (uLF-MRI, 0.064 T) offers accessible neuroimaging for neonatal care but suffers from low signal-to-noise ratio and poor diagnostic quality compared to high-field (HF) MRI. We propose MRIQT, a 3D conditional diffusion framework for image quality transfer (IQT) from uLF to HF MRI. MRIQT combines realistic K-space degradation for physics-consistent uLF simulation, v-prediction with classifier-free guidance for stable image-to-image generation, and an SNR-weighted 3D perceptual loss for anatomical fidelity. The model denoises from a noised uLF input conditioned on the same scan, leveraging volumetric attention-UNet architecture for structure-preserving translation. Trained on a neonatal cohort with diverse pathologies, MRIQT surpasses recent GAN and CNN baselines in PSNR 15.3% with 1.78% over the state of the art, while physicians rated 85% of its outputs as good quality with clear pathology present. MRIQT enables high-fidelity, diffusion-based enhancement of portable ultra-low-field (uLF) MRI for deliable neonatal brain assessment.

</details>


### [244] [MMD-Thinker: Adaptive Multi-Dimensional Thinking for Multimodal Misinformation Detection](https://arxiv.org/abs/2511.13242)
*Junjie Wu,Guohong Fu*

Main category: cs.CV

TL;DR: 提出了MMD-Thinker框架，通过自适应多维思考来解决多模态虚假信息检测中通用MLLMs存在的推理不足和推理偏差问题，在多个基准数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决多模态虚假信息检测中通用多模态大语言模型存在的两个关键限制：推理不足（缺乏任务特定知识导致解释和判断不准确）和推理偏差（单一思维模式难以应对快速发展的复杂多模态虚假信息）。

Method: 两阶段框架：1）为多模态虚假信息检测设计定制化思维模式；2）通过任务特定指令调优将定制思维注入通用MLLMs；3）使用混合优势函数的强化学习策略激励推理能力。同时构建了包含8K+图像-文本对的MMR数据集。

Result: 在域内和域外基准数据集上均达到最先进性能，同时保持灵活推理和token使用效率。

Conclusion: MMD-Thinker框架通过自适应多维思考有效解决了多模态虚假信息检测中的关键挑战，为AIGC时代的多模态虚假信息检测提供了有效解决方案。

Abstract: Multimodal misinformation floods on various social media, and continues to evolve in the era of AI-generated content (AIGC). The emerged misinformation with low creation cost and high deception poses significant threats to society. While recent studies leverage general-purpose multimodal large language models (MLLMs) to achieve remarkable results in detection, they encounter two critical limitations: (1) Insufficient reasoning, where general-purpose MLLMs often follow the uniform reasoning paradigm but generate inaccurate explanations and judgments, due to the lack of the task-specific knowledge of multimodal misinformation detection. (2) Reasoning biases, where a single thinking mode make detectors a suboptimal path for judgment, struggling to keep pace with the fast-growing and intricate multimodal misinformation. In this paper, we propose MMD-Thinker, a two-stage framework for multimodal misinformation detection through adaptive multi-dimensional thinking. First, we develop tailor-designed thinking mode for multimodal misinformation detection. Second, we adopt task-specific instruction tuning to inject the tailored thinking mode into general-purpose MLLMs. Third, we further leverage reinforcement learning strategy with a mixed advantage function, which incentivizes the reasoning capabilities in trajectories. Furthermore, we construct the multimodal misinformation reasoning (MMR) dataset, encompasses more than 8K image-text pairs with both reasoning processes and classification labels, to make progress in the relam of multimodal misinformation detection. Experimental results demonstrate that our proposed MMD-Thinker achieves state-of-the-art performance on both in-domain and out-of-domain benchmark datasets, while maintaining flexible inference and token usage. Code will be publicly available at Github.

</details>


### [245] [Referring Camouflaged Object Detection With Multi-Context Overlapped Windows Cross-Attention](https://arxiv.org/abs/2511.13249)
*Yu Wen,Shuyong Gao,Shuping Zhang,Miao Huang,Lili Tao,Han Yang,Haozhe Xing,Lihe Zhang,Boxue Hou*

Main category: cs.CV

TL;DR: 本文提出RFMNet方法，通过多阶段特征融合和重叠窗口交叉注意力机制来提升参照伪装目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有的Ref-COD方法将参照图像转换为简单提示，但未能充分利用参照图像中丰富的显著目标特征。作者希望探索如何通过多上下文融合来增强伪装目标检测性能。

Method: 提出RFMNet框架，在编码阶段对参照显著图像特征和伪装目标特征进行交互融合；设计重叠窗口交叉注意力机制来关注局部信息匹配；使用参照特征聚合模块进行渐进式解码分割。

Result: 在Ref-COD基准测试上的大量实验表明，该方法达到了最先进的性能。

Conclusion: 通过多阶段特征融合和局部注意力机制，RFMNet能够有效利用参照图像中的丰富信息来提升伪装目标检测效果。

Abstract: Referring camouflaged object detection (Ref-COD) aims to identify hidden objects by incorporating reference information such as images and text descriptions. Previous research has transformed reference images with salient objects into one-dimensional prompts, yielding significant results. We explore ways to enhance performance through multi-context fusion of rich salient image features and camouflaged object features. Therefore, we propose RFMNet, which utilizes features from multiple encoding stages of the reference salient images and performs interactive fusion with the camouflage features at the corresponding encoding stages. Given that the features in salient object images contain abundant object-related detail information, performing feature fusion within local areas is more beneficial for detecting camouflaged objects. Therefore, we propose an Overlapped Windows Cross-attention mechanism to enable the model to focus more attention on the local information matching based on reference features. Besides, we propose the Referring Feature Aggregation (RFA) module to decode and segment the camouflaged objects progressively. Extensive experiments on the Ref-COD benchmark demonstrate that our method achieves state-of-the-art performance.

</details>


### [246] [GeoX-Bench: Benchmarking Cross-View Geo-Localization and Pose Estimation Capabilities of Large Multimodal Models](https://arxiv.org/abs/2511.13259)
*Yushuo Zheng,Jiangyong Ying,Huiyu Duan,Chunyi Li,Zicheng Zhang,Jing Liu,Xiaohong Liu,Guangtao Zhai*

Main category: cs.CV

TL;DR: GeoX-Bench是一个用于评估大型多模态模型在跨视角地理定位和姿态估计任务中能力的基准数据集，包含10,859对全景-卫星图像和755,976个问答对，评估显示当前模型在地理定位任务中表现良好但在姿态估计任务中表现较差


<details>
  <summary>Details</summary>
Motivation: 尽管大型多模态模型在多种任务中表现出色，但其在跨视角地理定位和姿态估计领域的能力尚未被探索，而这些能力对导航、自动驾驶、户外机器人等应用具有重要价值

Method: 开发了GeoX-Bench基准数据集，包含128个城市、49个国家的10,859对全景-卫星图像和755,976个问答对，其中42,900个用于基准测试，其余用于增强模型能力。评估了25个最先进的大型多模态模型，并探索了指令调优的效果

Result: 当前大型多模态模型在地理定位任务中取得了令人印象深刻的性能，但在更复杂的姿态估计任务中有效性显著下降。在GeoX-Bench训练数据上进行指令调优可以显著提高模型的跨视角地理感知能力

Conclusion: GeoX-Bench揭示了大型多模态模型在跨视角地理任务中的能力差距，特别是姿态估计任务的挑战性，为未来改进提供了重要方向，指令调优是提升模型地理感知能力的有效方法

Abstract: Large multimodal models (LMMs) have demonstrated remarkable capabilities across a wide range of tasks, however their knowledge and abilities in the cross-view geo-localization and pose estimation domains remain unexplored, despite potential benefits for navigation, autonomous driving, outdoor robotics, \textit{etc}. To bridge this gap, we introduce \textbf{GeoX-Bench}, a comprehensive \underline{Bench}mark designed to explore and evaluate the capabilities of LMMs in \underline{cross}-view \underline{Geo}-localization and pose estimation. Specifically, GeoX-Bench contains 10,859 panoramic-satellite image pairs spanning 128 cities in 49 countries, along with corresponding 755,976 question-answering (QA) pairs. Among these, 42,900 QA pairs are designated for benchmarking, while the remaining are intended to enhance the capabilities of LMMs. Based on GeoX-Bench, we evaluate the capabilities of 25 state-of-the-art LMMs on cross-view geo-localization and pose estimation tasks, and further explore the empowered capabilities of instruction-tuning. Our benchmark demonstrate that while current LMMs achieve impressive performance in geo-localization tasks, their effectiveness declines significantly on the more complex pose estimation tasks, highlighting a critical area for future improvement, and instruction-tuning LMMs on the training data of GeoX-Bench can significantly improve the cross-view geo-sense abilities. The GeoX-Bench is available at \textcolor{magenta}{https://github.com/IntMeGroup/GeoX-Bench}.

</details>


### [247] [Building Egocentric Procedural AI Assistant: Methods, Benchmarks, and Challenges](https://arxiv.org/abs/2511.13261)
*Junlong Li,Huaiyuan Xu,Sijie Cheng,Kejun Wu,Kim-Hui Yap,Lap-Pui Chau,Yi Wang*

Main category: cs.CV

TL;DR: 本文提出了一个以自我为中心的程序性AI助手（EgoProceAssist）概念，旨在通过第一人称视角逐步支持日常程序性任务，并定义了三个核心任务：错误检测、程序学习和问答。


<details>
  <summary>Details</summary>
Motivation: 受视觉语言模型和以自我为中心的感知研究进展的推动，需要开发专门针对第一人称视角程序性任务的AI助手。

Method: 通过全面回顾现有技术、相关数据集和评估指标，引入新实验对代表性VLM方法进行综合评估，并分析技术差距。

Result: 建立了EgoProceAssist的新分类法，识别了当前技术与理想助手之间的差距，并提供了公开资源库持续收集最新研究。

Conclusion: 讨论了未来挑战和研究方向，强调需要进一步开发以自我为中心的程序性AI助手技术。

Abstract: Driven by recent advances in vision language models (VLMs) and egocentric perception research, we introduce the concept of an egocentric procedural AI assistant (EgoProceAssist) tailored to step-by-step support daily procedural tasks in a first-person view. In this work, we start by identifying three core tasks: egocentric procedural error detection, egocentric procedural learning, and egocentric procedural question answering. These tasks define the essential functions of EgoProceAssist within a new taxonomy. Specifically, our work encompasses a comprehensive review of current techniques, relevant datasets, and evaluation metrics across these three core areas. To clarify the gap between the proposed EgoProceAssist and existing VLM-based AI assistants, we introduce novel experiments and provide a comprehensive evaluation of representative VLM-based methods. Based on these findings and our technical analysis, we discuss the challenges ahead and suggest future research directions. Furthermore, an exhaustive list of this study is publicly available in an active repository that continuously collects the latest work: https://github.com/z1oong/Building-Egocentric-Procedural-AI-Assistant

</details>


### [248] [SymGS : Leveraging Local Symmetries for 3D Gaussian Splatting Compression](https://arxiv.org/abs/2511.13264)
*Keshav Gupta,Akshat Sanghvi,Shreyas Reddy Palley,Astitva Srivastava,Charu Sharma,Avinash Sharma*

Main category: cs.CV

TL;DR: SymGS是一种针对3D高斯泼溅的压缩框架，通过引入可学习的镜像对称性来消除冗余基元，在保持渲染质量的同时实现108倍压缩比


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅技术虽然渲染速度快且保真度高，但内存占用随场景复杂度快速增加。现有压缩方法主要利用基元级冗余进行压缩，但存在压缩极限

Method: 提出SymGS框架，通过引入可学习的镜像来识别和消除局部和全局的反射对称冗余，可作为现有压缩方法（如HAC）的即插即用增强模块

Result: 相比HAC方法，在基准数据集上实现1.66倍压缩（大规模场景可达3倍），平均实现108倍压缩，同时保持渲染质量

Conclusion: SymGS通过对称感知技术突破了现有压缩方法的极限，为3D高斯泼溅提供了高效的内存压缩解决方案

Abstract: 3D Gaussian Splatting has emerged as a transformative technique in novel view synthesis, primarily due to its high rendering speed and photorealistic fidelity. However, its memory footprint scales rapidly with scene complexity, often reaching several gigabytes. Existing methods address this issue by introducing compression strategies that exploit primitive-level redundancy through similarity detection and quantization. We aim to surpass the compression limits of such methods by incorporating symmetry-aware techniques, specifically targeting mirror symmetries to eliminate redundant primitives. We propose a novel compression framework, \textbf{\textit{SymGS}}, introducing learnable mirrors into the scene, thereby eliminating local and global reflective redundancies for compression. Our framework functions as a plug-and-play enhancement to state-of-the-art compression methods, (e.g. HAC) to achieve further compression. Compared to HAC, we achieve $1.66 \times$ compression across benchmark datasets (upto $3\times$ on large-scale scenes). On an average, SymGS enables $\bf{108\times}$ compression of a 3DGS scene, while preserving rendering quality. The project page and supplementary can be found at \textbf{\color{cyan}{symgs.github.io}}

</details>


### [249] [Is your VLM Sky-Ready? A Comprehensive Spatial Intelligence Benchmark for UAV Navigation](https://arxiv.org/abs/2511.13269)
*Lingfeng Zhang,Yuchen Zhang,Hongsheng Li,Haoxiang Fu,Yingbo Tang,Hangjun Ye,Long Chen,Xiaojun Liang,Xiaoshuai Hao,Wenbo Ding*

Main category: cs.CV

TL;DR: 本文提出了SpatialSky-Bench基准测试来评估视觉语言模型在无人机导航中的空间智能能力，并开发了Sky-VLM模型在无人机场景中实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在无人机场景中的空间智能能力尚未充分探索，无法有效应对动态环境的导航和解释需求。

Method: 开发了包含环境感知和场景理解两大类别、13个子类别的综合基准测试SpatialSky-Bench，并基于包含100万样本的SpatialSky-Dataset训练了专门针对无人机空间推理的Sky-VLM模型。

Result: 主流视觉语言模型在复杂无人机导航场景中表现不佳，而Sky-VLM在所有基准测试任务中都达到了最先进的性能水平。

Conclusion: Sky-VLM为开发适用于无人机场景的视觉语言模型开辟了新途径，解决了现有模型在空间智能能力方面的不足。

Abstract: Vision-Language Models (VLMs), leveraging their powerful visual perception and reasoning capabilities, have been widely applied in Unmanned Aerial Vehicle (UAV) tasks. However, the spatial intelligence capabilities of existing VLMs in UAV scenarios remain largely unexplored, raising concerns about their effectiveness in navigating and interpreting dynamic environments. To bridge this gap, we introduce SpatialSky-Bench, a comprehensive benchmark specifically designed to evaluate the spatial intelligence capabilities of VLMs in UAV navigation. Our benchmark comprises two categories-Environmental Perception and Scene Understanding-divided into 13 subcategories, including bounding boxes, color, distance, height, and landing safety analysis, among others. Extensive evaluations of various mainstream open-source and closed-source VLMs reveal unsatisfactory performance in complex UAV navigation scenarios, highlighting significant gaps in their spatial capabilities. To address this challenge, we developed the SpatialSky-Dataset, a comprehensive dataset containing 1M samples with diverse annotations across various scenarios. Leveraging this dataset, we introduce Sky-VLM, a specialized VLM designed for UAV spatial reasoning across multiple granularities and contexts. Extensive experimental results demonstrate that Sky-VLM achieves state-of-the-art performance across all benchmark tasks, paving the way for the development of VLMs suitable for UAV scenarios. The source code is available at https://github.com/linglingxiansen/SpatialSKy.

</details>


### [250] [Recognition of Abnormal Events in Surveillance Videos using Weakly Supervised Dual-Encoder Models](https://arxiv.org/abs/2511.13276)
*Noam Tsfaty,Avishai Weizman,Liav Cohen,Moshe Tshuva,Yehudit Aperstein*

Main category: cs.CV

TL;DR: 提出基于双主干网络和top-k池化的视频级监督异常检测方法，在UCF-Crime数据集上达到90.7% AUC


<details>
  <summary>Details</summary>
Motivation: 解决在仅使用视频级监督的情况下检测监控视频中罕见且多样异常样本的挑战

Method: 采用卷积和Transformer双主干网络框架，通过top-k池化结合两种表示

Result: 在UCF-Crime数据集上取得了90.7%的AUC性能

Conclusion: 双主干网络结合top-k池化能有效提升视频异常检测性能

Abstract: We address the challenge of detecting rare and diverse anomalies in surveillance videos using only video-level supervision. Our dual-backbone framework combines convolutional and transformer representations through top-k pooling, achieving 90.7% area under the curve (AUC) on the UCF-Crime dataset.

</details>


### [251] [SF-Recon: Simplification-Free Lightweight Building Reconstruction via 3D Gaussian Splatting](https://arxiv.org/abs/2511.13278)
*Zihan Li,Tengfei Wang,Wentian Gan,Hao Zhan,Xin Wang,Zongqian Zhan*

Main category: cs.CV

TL;DR: SF-Recon是一种直接从多视角图像重建轻量级建筑表面的方法，无需后处理网格简化，通过3D高斯场优化和三角剖分实现高效重建。


<details>
  <summary>Details</summary>
Motivation: 传统多视角几何流程依赖密集重建、网格化和简化，过程繁琐且质量敏感，需要一种直接重建轻量级建筑表面的方法。

Method: 首先训练3D高斯场获得视图一致性表示，然后通过法向梯度引导的高斯优化选择与建筑边界对齐的基元，再通过多视角边缘一致性剪枝增强结构清晰度，最后使用深度约束的Delaunay三角剖分生成轻量网格。

Result: 在SF数据集上的实验表明，SF-Recon能够直接重建轻量级建筑模型，显著减少面和顶点数量，同时保持计算效率。

Conclusion: SF-Recon提供了一种有效的端到端解决方案，可直接从多视角图像生成结构保真的轻量建筑网格，优于传统方法。

Abstract: Lightweight building surface models are crucial for digital city, navigation, and fast geospatial analytics, yet conventional multi-view geometry pipelines remain cumbersome and quality-sensitive due to their reliance on dense reconstruction, meshing, and subsequent simplification. This work presents SF-Recon, a method that directly reconstructs lightweight building surfaces from multi-view images without post-hoc mesh simplification. We first train an initial 3D Gaussian Splatting (3DGS) field to obtain a view-consistent representation. Building structure is then distilled by a normal-gradient-guided Gaussian optimization that selects primitives aligned with roof and wall boundaries, followed by multi-view edge-consistency pruning to enhance structural sharpness and suppress non-structural artifacts without external supervision. Finally, a multi-view depth-constrained Delaunay triangulation converts the structured Gaussian field into a lightweight, structurally faithful building mesh. Based on a proposed SF dataset, the experimental results demonstrate that our SF-Recon can directly reconstruct lightweight building models from multi-view imagery, achieving substantially fewer faces and vertices while maintaining computational efficiency. Website:https://lzh282140127-cell.github.io/SF-Recon-project/

</details>


### [252] [Towards Metric-Aware Multi-Person Mesh Recovery by Jointly Optimizing Human Crowd in Camera Space](https://arxiv.org/abs/2511.13282)
*Kaiwen Wang,Kaili Zheng,Yiming Shi,Chenyi Guo,Ji Wu*

Main category: cs.CV

TL;DR: 提出DTO方法解决多人网格恢复中的场景一致性缺失问题，通过联合优化相机空间平移来确保多人深度和尺度的一致性，并构建了DTO-Humans数据集和Metric-Aware HMR网络。


<details>
  <summary>Details</summary>
Motivation: 现有单人中心化的伪真值生成方法缺乏场景级一致性，导致同一图像中多人深度和尺度冲突，需要一种能够联合优化多人位置的方法。

Method: 1. DTO：基于深度条件平移优化的方法，利用人体高度先验和单目深度估计器，在MAP框架下联合优化所有个体的相机空间平移；2. Metric-Aware HMR：端到端网络，通过相机分支和相对度量损失直接估计度量尺度下的人体网格和相机参数。

Result: 构建了DTO-Humans数据集（56万张高质量场景一致性图像，平均每图4.8人），在相对深度推理和人体网格恢复任务上达到最先进性能。

Conclusion: DTO方法有效解决了多人网格恢复中的场景一致性难题，Metric-Aware HMR网络实现了度量尺度的直接估计，为多人场景理解提供了新思路。

Abstract: Multi-person human mesh recovery from a single image is a challenging task, hindered by the scarcity of in-the-wild training data. Prevailing in-the-wild human mesh pseudo-ground-truth (pGT) generation pipelines are single-person-centric, where each human is processed individually without joint optimization. This oversight leads to a lack of scene-level consistency, producing individuals with conflicting depths and scales within the same image. To address this, we introduce Depth-conditioned Translation Optimization (DTO), a novel optimization-based method that jointly refines the camera-space translations of all individuals in a crowd. By leveraging anthropometric priors on human height and depth cues from a monocular depth estimator, DTO solves for a scene-consistent placement of all subjects within a principled Maximum a posteriori (MAP) framework. Applying DTO to the 4D-Humans dataset, we construct DTO-Humans, a new large-scale pGT dataset of 0.56M high-quality, scene-consistent multi-person images, featuring dense crowds with an average of 4.8 persons per image. Furthermore, we propose Metric-Aware HMR, an end-to-end network that directly estimates human mesh and camera parameters in metric scale. This is enabled by a camera branch and a novel relative metric loss that enforces plausible relative scales. Extensive experiments demonstrate that our method achieves state-of-the-art performance on relative depth reasoning and human mesh recovery. Code and data will be released publicly.

</details>


### [253] [TabFlash: Efficient Table Understanding with Progressive Question Conditioning and Token Focusing](https://arxiv.org/abs/2511.13283)
*Jongha Kim,Minseong Bae,Sanghyeok Lee,Jinsung Yoon,Hyunwoo J. Kim*

Main category: cs.CV

TL;DR: TabFlash是一个针对表格图像理解的高效多模态大语言模型，通过渐进式问题条件化、背景令牌剪枝和令牌聚焦策略，实现了更好的性能和更低的计算资源消耗。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM方法在处理表格图像时忽视了问题特定关注需求和冗余背景区域的问题，导致视觉表示不具信息性和冗余。

Method: 提出渐进式问题条件化、背景令牌剪枝策略和令牌聚焦训练方法，结合生成信息丰富且紧凑的视觉特征。

Result: TabFlash在表格理解任务上达到最先进性能，相比次优MLLM减少27%的FLOPs和30%的内存使用。

Conclusion: 通过针对表格图像特点设计的视觉表示方法，TabFlash实现了高效且有效的表格理解，在性能和效率方面均优于现有方法。

Abstract: Table images present unique challenges for effective and efficient understanding due to the need for question-specific focus and the presence of redundant background regions. Existing Multimodal Large Language Model (MLLM) approaches often overlook these characteristics, resulting in uninformative and redundant visual representations. To address these issues, we aim to generate visual features that are both informative and compact to improve table understanding. We first propose progressive question conditioning, which injects the question into Vision Transformer layers with gradually increasing frequency, considering each layer's capacity to handle additional information, to generate question-aware visual features. To reduce redundancy, we introduce a pruning strategy that discards background tokens, thereby improving efficiency. To mitigate information loss from pruning, we further propose token focusing, a training strategy that encourages the model to concentrate essential information in the retained tokens. By combining these approaches, we present TabFlash, an efficient and effective MLLM for table understanding. TabFlash achieves state-of-the-art performance, outperforming both open-source and proprietary MLLMs, while requiring 27% less FLOPs and 30% less memory usage compared to the second-best MLLM.

</details>


### [254] [SkyReels-Text: Fine-grained Font-Controllable Text Editing for Poster Design](https://arxiv.org/abs/2511.13285)
*Yunjie Yu,Jingchen Wu,Junchen Zhu,Chunze Lin,Guibin Chen*

Main category: cs.CV

TL;DR: SkyReels-Text是一个用于精确海报文本编辑的字体可控框架，能够在保持视觉和谐的同时编辑多种字体样式的文本区域


<details>
  <summary>Details</summary>
Motivation: 解决现有图像编辑模型在细粒度、字体感知的文本编辑方面的不足，满足专业设计工作流程中对快速精确文本修改的需求

Method: 提出无需字体标签或推理时微调的框架，用户只需提供所需字体的裁剪字形补丁即可实现多文本区域的同时编辑

Result: 在多个数据集上的实验表明，SkyReels-Text在文本保真度和视觉真实感方面达到最先进性能，提供了对字体家族和风格细节的前所未有的控制

Conclusion: 该工作弥合了通用图像编辑与专业级字体设计之间的差距，为专业海报设计提供了强大的编辑工具

Abstract: Artistic design such as poster design often demands rapid yet precise modification of textual content while preserving visual harmony and typographic intent, especially across diverse font styles. Although modern image editing models have grown increasingly powerful, they still fall short in fine-grained, font-aware text manipulation, limiting their utility in professional design workflows such as poster editing. To address this issue, we present SkyReels-Text, a novel font-controllable framework for precise poster text editing. Our method enables simultaneous editing of multiple text regions, each rendered in distinct typographic styles, while preserving the visual appearance of non-edited regions. Notably, our model requires neither font labels nor fine-tuning during inference: users can simply provide cropped glyph patches corresponding to their desired typography, even if the font is not included in any standard library. Extensive experiments on multiple datasets, including handwrittent text benchmarks, SkyReels-Text achieves state-of-the-art performance in both text fidelity and visual realism, offering unprecedented control over font families, and stylistic nuances. This work bridges the gap between general-purpose image editing and professional-grade typographic design.

</details>


### [255] [CorrectAD: A Self-Correcting Agentic System to Improve End-to-end Planning in Autonomous Driving](https://arxiv.org/abs/2511.13297)
*Enhui Ma,Lijun Zhou,Tao Tang,Jiahuan Zhang,Junpeng Jiang,Zhan Zhang,Dong Han,Kun Zhan,Xueyang Zhang,XianPeng Lang,Haiyang Sun,Xia Zhou,Di Lin,Kaicheng Yu*

Main category: cs.CV

TL;DR: 本文提出CorrectAD系统，利用扩散模型和3D布局生成高保真视频数据，自动纠正自动驾驶端到端规划器的长尾故障案例。


<details>
  <summary>Details</summary>
Motivation: 当前端到端自动驾驶规划方法面临长尾问题（罕见但安全关键的故障案例），数据驱动方法的鲁棒性不足。

Method: 1. 引入PM-Agent制定故障案例数据需求；2. 提出DriveSora生成与3D布局对齐的时空一致视频；3. 构建模型无关的自纠正系统CorrectAD。

Result: 在nuScenes和内部数据集上，CorrectAD分别纠正了62.5%和49.8%的故障案例，碰撞率分别降低39%和27%。

Conclusion: CorrectAD展示了利用生成模型自动纠正自动驾驶规划器故障的有效性，为提升系统鲁棒性提供了新途径。

Abstract: End-to-end planning methods are the de facto standard of the current autonomous driving system, while the robustness of the data-driven approaches suffers due to the notorious long-tail problem (i.e., rare but safety-critical failure cases). In this work, we explore whether recent diffusion-based video generation methods (a.k.a. world models), paired with structured 3D layouts, can enable a fully automated pipeline to self-correct such failure cases. We first introduce an agent to simulate the role of product manager, dubbed PM-Agent, which formulates data requirements to collect data similar to the failure cases. Then, we use a generative model that can simulate both data collection and annotation. However, existing generative models struggle to generate high-fidelity data conditioned on 3D layouts. To address this, we propose DriveSora, which can generate spatiotemporally consistent videos aligned with the 3D annotations requested by PM-Agent. We integrate these components into our self-correcting agentic system, CorrectAD. Importantly, our pipeline is an end-to-end model-agnostic and can be applied to improve any end-to-end planner. Evaluated on both nuScenes and a more challenging in-house dataset across multiple end-to-end planners, CorrectAD corrects 62.5% and 49.8% of failure cases, reducing collision rates by 39% and 27%, respectively.

</details>


### [256] [DriveLiDAR4D: Sequential and Controllable LiDAR Scene Generation for Autonomous Driving](https://arxiv.org/abs/2511.13309)
*Kaiwen Cai,Xinze Liu,Xia Zhou,Hengtong Hu,Jie Xiang,Luyao Zhang,Xueyang Zhang,Kun Zhan,Yifei Zhan,Xianpeng Lang*

Main category: cs.CV

TL;DR: DriveLiDAR4D是一种新颖的LiDAR生成管道，通过多模态条件和序列噪声预测模型LiDAR4DNet，能够生成时间一致的LiDAR场景，具有高度可控的前景物体和逼真的背景。


<details>
  <summary>Details</summary>
Motivation: 现有的3D LiDAR点云生成方法缺乏序列生成能力，无法产生精确定位的前景物体和逼真的背景，这限制了它们的实际应用。

Method: 提出DriveLiDAR4D管道，包含多模态条件和新型序列噪声预测模型LiDAR4DNet，以端到端方式实现具有完整场景操作能力的LiDAR场景序列生成。

Result: 在nuScenes和KITTI数据集上的评估显示，DriveLiDAR4D在nuScenes数据集上获得了743.13的FRD分数和16.96的FVD分数，比当前最先进的UniScene方法分别提升了37.2%和24.1%。

Conclusion: 这是首个以端到端方式解决具有完整场景操作能力的LiDAR场景序列生成的工作，在性能上显著超越了现有方法。

Abstract: The generation of realistic LiDAR point clouds plays a crucial role in the development and evaluation of autonomous driving systems. Although recent methods for 3D LiDAR point cloud generation have shown significant improvements, they still face notable limitations, including the lack of sequential generation capabilities and the inability to produce accurately positioned foreground objects and realistic backgrounds. These shortcomings hinder their practical applicability. In this paper, we introduce DriveLiDAR4D, a novel LiDAR generation pipeline consisting of multimodal conditions and a novel sequential noise prediction model LiDAR4DNet, capable of producing temporally consistent LiDAR scenes with highly controllable foreground objects and realistic backgrounds. To the best of our knowledge, this is the first work to address the sequential generation of LiDAR scenes with full scene manipulation capability in an end-to-end manner. We evaluated DriveLiDAR4D on the nuScenes and KITTI datasets, where we achieved an FRD score of 743.13 and an FVD score of 16.96 on the nuScenes dataset, surpassing the current state-of-the-art (SOTA) method, UniScene, with an performance boost of 37.2% in FRD and 24.1% in FVD, respectively.

</details>


### [257] [Computer Vision based group activity detection and action spotting](https://arxiv.org/abs/2511.13315)
*Narthana Sivalingam,Santhirarajah Sivasthigan,Thamayanthi Mahendranathan,G. M. R. I. Godaliyadda,M. P. B. Ekanayake,H. M. V. R. Herath*

Main category: cs.CV

TL;DR: 提出了一种基于计算机视觉的群体活动检测框架，结合深度学习模型和图关系推理，通过Mask R-CNN定位演员、多种骨干网络提取特征、构建演员关系图并使用图卷积网络进行推理。


<details>
  <summary>Details</summary>
Motivation: 多人物场景中的群体活动检测面临复杂人体交互、遮挡和时间外观变化的挑战，需要更有效的建模方法。

Method: 使用Mask R-CNN进行演员定位和实例分割，结合Inception V3、MobileNet、VGG16等骨干网络提取特征，通过RoIAlign保持空间对齐，构建演员关系图编码外观相似性和位置关系，应用图卷积网络进行关系推理。

Result: 在Collective Activity数据集上的实验表明，该方法在拥挤和非拥挤场景下都能提高识别性能。

Conclusion: 该方法展示了将分割、特征提取和关系图推理相结合在复杂视频理解任务中的潜力。

Abstract: Group activity detection in multi-person scenes is challenging due to complex human interactions, occlusions, and variations in appearance over time. This work presents a computer vision based framework for group activity recognition and action spotting using a combination of deep learning models and graph based relational reasoning. The system first applies Mask R-CNN to obtain accurate actor localization through bounding boxes and instance masks. Multiple backbone networks, including Inception V3, MobileNet, and VGG16, are used to extract feature maps, and RoIAlign is applied to preserve spatial alignment when generating actor specific features. The mask information is then fused with the feature maps to obtain refined masked feature representations for each actor. To model interactions between individuals, we construct Actor Relation Graphs that encode appearance similarity and positional relations using methods such as normalized cross correlation, sum of absolute differences, and dot product. Graph Convolutional Networks operate on these graphs to reason about relationships and predict both individual actions and group level activities. Experiments on the Collective Activity dataset demonstrate that the combination of mask based feature refinement, robust similarity search, and graph neural network reasoning leads to improved recognition performance across both crowded and non crowded scenarios. This approach highlights the potential of integrating segmentation, feature extraction, and relational graph reasoning for complex video understanding tasks.

</details>


### [258] [YOLO Meets Mixture-of-Experts: Adaptive Expert Routing for Robust Object Detection](https://arxiv.org/abs/2511.13344)
*Ori Meiraz,Sharon Shalev,Avishai Weizman*

Main category: cs.CV

TL;DR: 提出了一种基于YOLOv9-T的混合专家框架，通过自适应路由实现动态特征专业化，在目标检测任务中获得了比单一YOLOv9-T模型更高的mAP和AR指标。


<details>
  <summary>Details</summary>
Motivation: 传统单一目标检测模型在处理复杂场景时存在特征表达能力不足的问题，需要开发能够动态适应不同场景特征的检测框架。

Method: 构建Mixture-of-Experts框架，集成多个YOLOv9-T专家模型，通过自适应路由机制实现专家间的动态选择和特征专业化。

Result: 相比单一YOLOv9-T模型，该框架在目标检测任务中显著提升了平均精度(mAP)和平均召回率(AR)性能。

Conclusion: Mixture-of-Experts框架通过专家协同和动态路由机制，有效提升了目标检测的性能，证明了多专家模型在复杂视觉任务中的优势。

Abstract: This paper presents a novel Mixture-of-Experts framework for object detection, incorporating adaptive routing among multiple YOLOv9-T experts to enable dynamic feature specialization and achieve higher mean Average Precision (mAP) and Average Recall (AR) compared to a single YOLOv9-T model.

</details>


### [259] [Semi-Supervised Multi-Task Learning for Interpretable Quality As- sessment of Fundus Images](https://arxiv.org/abs/2511.13353)
*Lucas Gabriel Telesco,Danila Nejamkin,Estefanía Mata,Francisco Filizzola,Kevin Wignall,Lucía Franco Troilo,María de los Angeles Cenoz,Melissa Thompson,Mercedes Leguía,Ignacio Larrabide,José Ignacio Orlando*

Main category: cs.CV

TL;DR: 提出一种混合半监督学习方法，通过结合整体质量的人工标签和质量细节的伪标签，在多任务框架下实现更可解释的视网膜图像质量评估，无需大量手动标注。


<details>
  <summary>Details</summary>
Motivation: 现有视网膜图像质量评估工具仅分类整体图像质量，无法指示采集缺陷以指导重新采集，主要原因是详细标注成本高昂。

Method: 使用在小型数据集上训练的教师模型生成伪标签，然后在多任务设置中微调预训练模型，采用ResNet-18骨干网络。

Result: 多任务模型在EyeQ和DeepDRiD数据集上优于单任务基线（F1分数分别提升0.012和0.015），在大多数细节预测任务中与教师模型性能相当（p > 0.05），在新标注的EyeQ子集上与专家表现相似。

Conclusion: 半监督方法不仅提高了整体质量评估性能，还提供了关于采集条件（光照、清晰度、对比度）的可解释反馈，增强了可解释性且无需额外手动标注成本。

Abstract: Retinal image quality assessment (RIQA) supports computer-aided diagnosis of eye diseases. However, most tools classify only overall image quality, without indicating acquisition defects to guide recapture. This gap is mainly due to the high cost of detailed annotations. In this paper, we aim to mitigate this limitation by introducing a hybrid semi-supervised learning approach that combines manual labels for overall quality with pseudo-labels of quality details within a multi-task framework. Our objective is to obtain more interpretable RIQA models without requiring extensive manual labeling. Pseudo-labels are generated by a Teacher model trained on a small dataset and then used to fine-tune a pre-trained model in a multi-task setting. Using a ResNet-18 backbone, we show that these weak annotations improve quality assessment over single-task baselines (F1: 0.875 vs. 0.863 on EyeQ, and 0.778 vs. 0.763 on DeepDRiD), matching or surpassing existing methods. The multi-task model achieved performance statistically comparable to the Teacher for most detail prediction tasks (p > 0.05). In a newly annotated EyeQ subset released with this paper, our model performed similarly to experts, suggesting that pseudo-label noise aligns with expert variability. Our main finding is that the proposed semi-supervised approach not only improves overall quality assessment but also provides interpretable feedback on capture conditions (illumination, clarity, contrast). This enhances interpretability at no extra manual labeling cost and offers clinically actionable outputs to guide image recapture.

</details>


### [260] [Generalized Denoising Diffusion Codebook Models (gDDCM): Tokenizing images using a pre-trained diffusion model](https://arxiv.org/abs/2511.13387)
*Fei Kong*

Main category: cs.CV

TL;DR: 本文提出了广义去噪扩散压缩模型（gDDCM），将DDCM扩展到主流扩散模型及其变体，包括DDPM、基于分数的模型、一致性模型和整流流，实现了更好的性能。


<details>
  <summary>Details</summary>
Motivation: DDCM方法只能应用于DDPM，无法适用于其他扩散模型，限制了其应用范围。

Method: 通过将反向过程中的随机噪声替换为根据预定义规则从特定集合中采样的噪声，将DDCM的压缩思想扩展到多种扩散模型框架。

Result: 在CIFAR-10和LSUN Bedroom数据集上的实验表明，gDDCM成功将DDCM推广到上述模型，并取得了改进的性能。

Conclusion: gDDCM有效解决了DDCM的局限性，为扩散模型在图像压缩领域的更广泛应用提供了通用框架。

Abstract: Recently, the Denoising Diffusion Codebook Models (DDCM) was proposed. DDCM leverages the Denoising Diffusion Probabilistic Model (DDPM) and replaces the random noise in the backward process with noise sampled from specific sets according to a predefined rule, thereby enabling image compression. However, DDCM cannot be applied to methods other than DDPM. In this paper, we propose the generalized Denoising Diffusion Compression Model (gDDCM), which extends DDCM to mainstream diffusion models and their variants, including DDPM, Score-Based Models, Consistency Models, and Rectified Flow. We evaluate our method on CIFAR-10 and LSUN Bedroom datasets. Experimental results demonstrate that our approach successfully generalizes DDCM to the aforementioned models and achieves improved performance.

</details>


### [261] [Descriptor: Distance-Annotated Traffic Perception Question Answering (DTPQA)](https://arxiv.org/abs/2511.13397)
*Nikos Theodoridis,Tim Brophy,Reenu Mohandas,Ganesh Sistu,Fiachra Collins,Anthony Scanlan,Ciaran Eising*

Main category: cs.CV

TL;DR: DTPQA是一个专门用于评估视觉语言模型在交通场景中感知能力的视觉问答基准，包含合成和真实世界数据集，并带有距离标注以分析模型性能随距离增加的变化。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶等安全关键领域需要可靠的视觉语言模型，这些模型必须能够在复杂交通场景中具备强大的感知能力，特别是在远距离对象识别方面。现有评估方法往往混合了感知能力和推理能力，难以单独评估感知系统的性能。

Method: 开发了DTPQA基准，包含合成数据集（使用模拟器创建）和真实世界数据集（基于真实交通场景图像）。每个样本包含图像、问题、真实答案和对象距离标注，通过简单的视觉问答任务来专门评估感知能力。

Result: 提供了完整的DTPQA数据集和创建数据集的Python脚本，可用于生成更多同类数据。该基准能够有效分析VLM在不同距离下的感知性能退化情况。

Conclusion: DTPQA为评估视觉语言模型在交通场景中的纯感知能力提供了专门工具，特别关注远距离对象的识别性能，对自动驾驶等安全关键应用具有重要意义。

Abstract: The remarkable progress of Vision-Language Models (VLMs) on a variety of tasks has raised interest in their application to automated driving. However, for these models to be trusted in such a safety-critical domain, they must first possess robust perception capabilities, i.e., they must be capable of understanding a traffic scene, which can often be highly complex, with many things happening simultaneously. Moreover, since critical objects and agents in traffic scenes are often at long distances, we require systems with not only strong perception capabilities at close distances (up to 20 meters), but also at long (30+ meters) range. Therefore, it is important to evaluate the perception capabilities of these models in isolation from other skills like reasoning or advanced world knowledge. Distance-Annotated Traffic Perception Question Answering (DTPQA) is a Visual Question Answering (VQA) benchmark designed specifically for this purpose: it can be used to evaluate the perception systems of VLMs in traffic scenarios using trivial yet crucial questions relevant to driving decisions. It consists of two parts: a synthetic benchmark (DTP-Synthetic) created using a simulator, and a real-world benchmark (DTP-Real) built on top of existing images of real traffic scenes. Additionally, DTPQA includes distance annotations, i.e., how far the object in question is from the camera. More specifically, each DTPQA sample consists of (at least): (a) an image, (b) a question, (c) the ground truth answer, and (d) the distance of the object in question, enabling analysis of how VLM performance degrades with increasing object distance. In this article, we provide the dataset itself along with the Python scripts used to create it, which can be used to generate additional data of the same kind.

</details>


### [262] [TripleFDS: Triple Feature Disentanglement and Synthesis for Scene Text Editing](https://arxiv.org/abs/2511.13399)
*Yuchen Bao,Yiting Wang,Wenjian Huang,Haowei Wang,Shen Chen,Taiping Yao,Shouhong Ding,Jianguo Zhang*

Main category: cs.CV

TL;DR: TripleFDS是一个用于场景文本编辑(STE)的新框架，通过解耦文本样式、文本内容和背景三个属性，实现了更灵活和视觉一致的文本编辑。该方法利用SCB合成数据集进行训练，在主流基准测试中达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有场景文本编辑方法在可编辑属性解耦不完整的问题，传统方法通常只能编辑文本内容，限制了可控性和视觉一致性。

Method: 提出TripleFDS框架和SCB合成数据集，使用SCB Group作为基本训练单元进行三重特征解耦，通过组间对比正则化和组内多特征正交性确保语义准确性和减少冗余，在合成阶段进行特征重映射以防止重建过程中的"捷径"现象。

Result: 在125,000个SCB Group上训练后，TripleFDS在主流STE基准测试中实现了最先进的图像保真度(SSIM为44.54)和文本准确率(ACC为93.58%)。

Conclusion: TripleFDS不仅性能优越，还支持更灵活的编辑操作，如样式替换和背景转移，为场景文本编辑提供了更强大的解决方案。

Abstract: Scene Text Editing (STE) aims to naturally modify text in images while preserving visual consistency, the decisive factors of which can be divided into three parts, i.e., text style, text content, and background. Previous methods have struggled with incomplete disentanglement of editable attributes, typically addressing only one aspect - such as editing text content - thus limiting controllability and visual consistency. To overcome these limitations, we propose TripleFDS, a novel framework for STE with disentangled modular attributes, and an accompanying dataset called SCB Synthesis. SCB Synthesis provides robust training data for triple feature disentanglement by utilizing the "SCB Group", a novel construct that combines three attributes per image to generate diverse, disentangled training groups. Leveraging this construct as a basic training unit, TripleFDS first disentangles triple features, ensuring semantic accuracy through inter-group contrastive regularization and reducing redundancy through intra-sample multi-feature orthogonality. In the synthesis phase, TripleFDS performs feature remapping to prevent "shortcut" phenomena during reconstruction and mitigate potential feature leakage. Trained on 125,000 SCB Groups, TripleFDS achieves state-of-the-art image fidelity (SSIM of 44.54) and text accuracy (ACC of 93.58%) on the mainstream STE benchmarks. Besides superior performance, the more flexible editing of TripleFDS supports new operations such as style replacement and background transfer. Code: https://github.com/yusenbao01/TripleFDS

</details>


### [263] [What Color Is It? A Text-Interference Multimodal Hallucination Benchmark](https://arxiv.org/abs/2511.13400)
*Jinkun Zhao,Lei Huang,Wenjun Wu*

Main category: cs.CV

TL;DR: 论文提出了一个名为'What Color Is It'的数据集，用于触发多模态大模型在视觉感知中的单模态幻觉问题，特别是颜色感知方面的干扰，并探讨了幻觉原因及解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着多模态大模型的快速发展，这些模型在视觉感知中容易受到信息干扰，尤其是在颜色感知方面，这会增加幻觉风险。

Method: 通过构建'What Color Is It'数据集，采用简单方法触发多模态大模型在视觉模态中的单模态幻觉，并基于此数据集分析幻觉原因。

Result: 验证了多模态大模型在视觉感知中存在颜色感知干扰的假设，揭示了视觉模态幻觉的潜在机制。

Conclusion: 提出了增强多模态大模型鲁棒性的潜在解决方案，以减轻视觉感知中的幻觉问题。

Abstract: With the rapid advancement of Large Models, numerous text-and-vision-fused Multimodal Large Models (MLMs) have emerged. However, these MLMs remain susceptible to informational interference in visual perception, particularly in color perception, which introduces an additional risk of hallucination. To validate this hypothesis, we introduce the "What Color Is It" dataset, a novel benchmark constructed using a simple method to trigger single-modality visual hallucination in MLMs. Based on this dataset, we further investigate the underlying causes of hallucination in the visual modality of MLMs and propose potential solutions to enhance their robustness.

</details>


### [264] [Delineate Anything Flow: Fast, Country-Level Field Boundary Detection from Any Source](https://arxiv.org/abs/2511.13417)
*Mykola Lavreniuk,Nataliia Kussul,Andrii Shelestov,Yevhenii Salii,Volodymyr Kuzin,Sergii Skakun,Zoltan Szantoi*

Main category: cs.CV

TL;DR: DelAnyFlow是一种分辨率无关的大规模农田边界测绘方法，结合DelAny实例分割模型和结构化后处理流程，在单工作站上6小时内完成乌克兰全国农田边界提取，比现有方法检测到更多农田边界。


<details>
  <summary>Details</summary>
Motivation: 现有农田边界提取方法存在边界不完整、相邻农田合并、难以扩展等问题，需要开发可扩展的精准农田边界测绘技术，特别是在缺乏数字地籍数据的地区。

Method: 基于YOLOv11骨干网络构建DelAny实例分割模型，在包含672,909个多分辨率图像块和2290万个验证农田实例的FBIS 22M数据集上训练，结合结构化后处理、合并和矢量化流程生成拓扑一致的矢量边界。

Result: DelAny模型在精度上比SAM2高出100%以上，推理速度快400倍；在乌克兰应用中，DelAnyFlow在5米分辨率下提取375万个农田边界，在2.5米分辨率下提取515万个，显著优于Sinergise Solutions的266万个和NASA Harvest的169万个。

Conclusion: DelAnyFlow为缺乏数字地籍数据的地区提供了一种可扩展、成本效益高的农田边界测绘方法，支持国家级应用并具有强大的零样本泛化能力。

Abstract: Accurate delineation of agricultural field boundaries from satellite imagery is essential for land management and crop monitoring, yet existing methods often produce incomplete boundaries, merge adjacent fields, and struggle to scale. We present the Delineate Anything Flow (DelAnyFlow) methodology, a resolution-agnostic approach for large-scale field boundary mapping. DelAnyFlow combines the DelAny instance segmentation model, based on a YOLOv11 backbone and trained on the large-scale Field Boundary Instance Segmentation-22M (FBIS 22M) dataset, with a structured post-processing, merging, and vectorization sequence to generate topologically consistent vector boundaries. FBIS 22M, the largest dataset of its kind, contains 672,909 multi-resolution image patches (0.25-10m) and 22.9million validated field instances. The DelAny model delivers state-of-the-art accuracy with over 100% higher mAP and 400x faster inference than SAM2. DelAny demonstrates strong zero-shot generalization and supports national-scale applications: using Sentinel 2 data for 2024, DelAnyFlow generated a complete field boundary layer for Ukraine (603,000km2) in under six hours on a single workstation. DelAnyFlow outputs significantly improve boundary completeness relative to operational products from Sinergise Solutions and NASA Harvest, particularly in smallholder and fragmented systems (0.25-1ha). For Ukraine, DelAnyFlow delineated 3.75M fields at 5m and 5.15M at 2.5m, compared to 2.66M detected by Sinergise Solutions and 1.69M by NASA Harvest. This work delivers a scalable, cost-effective methodology for field delineation in regions lacking digital cadastral data. A project landing page with links to model weights, code, national-scale vector outputs, and dataset is available at https://lavreniuk.github.io/Delineate-Anything/.

</details>


### [265] [VOPE: Revisiting Hallucination of Vision-Language Models in Voluntary Imagination Task](https://arxiv.org/abs/2511.13420)
*Xingming Long,Jie Zhang,Shiguang Shan,Xilin Chen*

Main category: cs.CV

TL;DR: VOPE方法用于评估大视觉语言模型在自愿想象任务中的幻觉问题，通过存在性评估来区分合理想象和幻觉


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注禁止输出图像中不存在内容的描述任务，而忽略了自愿想象任务（如故事创作）中的幻觉问题，这些任务中模型需要生成超出图像的新内容

Method: 提出VOPE方法，通过基于重新检查的问题来评估LVLM如何解释其响应中想象对象的存在性，然后根据模型解释与图像中对象存在性的一致性来判断是否产生幻觉

Result: 对主流LVLMs和幻觉缓解方法的测试显示：(1)大多数LVLM在自愿想象中严重幻觉，对想象对象的存在性评估表现很差；(2)现有幻觉缓解方法在自愿想象任务中效果有限

Conclusion: 自愿想象任务中的幻觉问题是一个重要的研究方向，现有方法对此类任务效果不佳，需要进一步研究

Abstract: Most research on hallucinations in Large Vision-Language Models (LVLMs) focuses on factual description tasks that prohibit any output absent from the image. However, little attention has been paid to hallucinations in voluntary imagination tasks, e.g., story writing, where the models are expected to generate novel content beyond the given image. In these tasks, it is inappropriate to simply regard such imagined novel content as hallucinations. To address this limitation, we introduce Voluntary-imagined Object Presence Evaluation (VOPE)-a novel method to assess LVLMs' hallucinations in voluntary imagination tasks via presence evaluation. Specifically, VOPE poses recheck-based questions to evaluate how an LVLM interprets the presence of the imagined objects in its own response. The consistency between the model's interpretation and the object's presence in the image is then used to determine whether the model hallucinates when generating the response. We apply VOPE to several mainstream LVLMs and hallucination mitigation methods, revealing two key findings: (1) most LVLMs hallucinate heavily during voluntary imagination, and their performance in presence evaluation is notably poor on imagined objects; (2) existing hallucination mitigation methods show limited effect in voluntary imagination tasks, making this an important direction for future research.

</details>


### [266] [FUSE: A Flow-based Mapping Between Shapes](https://arxiv.org/abs/2511.13431)
*Lorenzo Olearo,Giulio Viganò,Daniele Baieri,Filippo Maggioli,Simone Melzi*

Main category: cs.CV

TL;DR: 本文提出了一种基于流匹配模型的3D形状间映射的神经表示方法，该方法计算高效，支持跨表示形状匹配，无需大规模训练或数据驱动过程。


<details>
  <summary>Details</summary>
Motivation: 解决3D形状匹配中跨不同表示（如点云、网格、SDF等）的挑战，提供一种高效且无需大量训练数据的通用映射方法。

Method: 将3D形状表示为从固定锚分布通过连续可逆流映射诱导的概率分布。通过源形状到锚的逆流与锚到目标形状的正向流的组合，实现两点之间的连续映射。使用点级任务定制嵌入对形状进行编码。

Result: 该方法在多样化基准测试和具有挑战性的形状匹配设置中始终实现高覆盖率和准确性。在UV映射和人体原始点云扫描配准等其他任务中也显示出有希望的结果。

Conclusion: 提出的流匹配框架为3D形状映射提供了一种有效且通用的解决方案，具有跨表示兼容性和良好的性能表现。

Abstract: We introduce a novel neural representation for maps between 3D shapes based on flow-matching models, which is computationally efficient and supports cross-representation shape matching without large-scale training or data-driven procedures. 3D shapes are represented as the probability distribution induced by a continuous and invertible flow mapping from a fixed anchor distribution. Given a source and a target shape, the composition of the inverse flow (source to anchor) with the forward flow (anchor to target), we continuously map points between the two surfaces. By encoding the shapes with a pointwise task-tailored embedding, this construction provides an invertible and modality-agnostic representation of maps between shapes across point clouds, meshes, signed distance fields (SDFs), and volumetric data. The resulting representation consistently achieves high coverage and accuracy across diverse benchmarks and challenging settings in shape matching. Beyond shape matching, our framework shows promising results in other tasks, including UV mapping and registration of raw point cloud scans of human bodies.

</details>


### [267] [Unlocking the Forgery Detection Potential of Vanilla MLLMs: A Novel Training-Free Pipeline](https://arxiv.org/abs/2511.13442)
*Rui Zuo,Qinyue Tong,Zhe-Ming Lu,Ziqian Lu*

Main category: cs.CV

TL;DR: 提出了Foresee，一种无需训练的MLLM图像伪造分析管道，通过类型先验驱动策略和灵活特征检测器模块，有效释放原始MLLM在取证领域的潜力，在多种篡改类型上表现出优越的定位精度和解释能力。


<details>
  <summary>Details</summary>
Motivation: 现有图像伪造检测方法泛化能力有限且解释性不足，而MLLM在视觉语言任务中展现出强大泛化潜力，但现有方法需要大规模训练且未能充分利用原始MLLM的内在潜力。

Method: Foresee采用无需训练的MLLM管道，包含类型先验驱动策略和专门处理复制-移动操作的灵活特征检测器模块，实现轻量级推理过程。

Result: 实验表明该方法在定位精度和文本解释丰富度上超越现有MLLM方法，在复制-移动、拼接、移除、局部增强、深度伪造和AIGC编辑等多种篡改类型上表现出更强的泛化能力。

Conclusion: Foresee成功释放了原始MLLM在取证领域的潜力，无需额外训练即可实现优越的伪造定位和解释性能，具有更强的通用性和实用性。

Abstract: With the rapid advancement of artificial intelligence-generated content (AIGC) technologies, including multimodal large language models (MLLMs) and diffusion models, image generation and manipulation have become remarkably effortless. Existing image forgery detection and localization (IFDL) methods often struggle to generalize across diverse datasets and offer limited interpretability. Nowadays, MLLMs demonstrate strong generalization potential across diverse vision-language tasks, and some studies introduce this capability to IFDL via large-scale training. However, such approaches cost considerable computational resources, while failing to reveal the inherent generalization potential of vanilla MLLMs to address this problem. Inspired by this observation, we propose Foresee, a training-free MLLM-based pipeline tailored for image forgery analysis. It eliminates the need for additional training and enables a lightweight inference process, while surpassing existing MLLM-based methods in both tamper localization accuracy and the richness of textual explanations. Foresee employs a type-prior-driven strategy and utilizes a Flexible Feature Detector (FFD) module to specifically handle copy-move manipulations, thereby effectively unleashing the potential of vanilla MLLMs in the forensic domain. Extensive experiments demonstrate that our approach simultaneously achieves superior localization accuracy and provides more comprehensive textual explanations. Moreover, Foresee exhibits stronger generalization capability, outperforming existing IFDL methods across various tampering types, including copy-move, splicing, removal, local enhancement, deepfake, and AIGC-based editing. The code will be released in the final version.

</details>


### [268] [Semantic Document Derendering: SVG Reconstruction via Vision-Language Modeling](https://arxiv.org/abs/2511.13478)
*Adam Hazimeh,Ke Wang,Mark Collier,Gilles Baechler,Efi Kokiopoulou,Pascal Frossard*

Main category: cs.CV

TL;DR: SliDer是一个基于视觉语言模型(VLMs)的语义文档反渲染框架，能够将幻灯片等多媒体文档的静态栅格图像转换为可编辑的SVG格式，保留高层次结构信息。


<details>
  <summary>Details</summary>
Motivation: 现有几何栅格-矢量转换方法在处理复杂文档时无法保留高层次语义结构，导致图像和文本元素的语义区分丢失。多媒体文档通常以静态栅格格式分发，限制了编辑和定制能力。

Method: SliDer使用视觉语言模型检测和提取栅格输入中单个图像和文本元素的属性，并将其组织成连贯的SVG格式。模型在推理过程中通过迭代优化预测，模拟人类设计过程，生成更忠实重建原始栅格的SVG代码。

Result: SliDer实现了0.069的重建LPIPS指标，在82.9%的情况下优于最强的零样本VLM基线，受到人类评估者的青睐。

Conclusion: SliDer框架能够有效解决语义文档反渲染问题，为栅格到可编辑矢量格式的转换提供了新思路，并构建了Slide2SVG数据集促进该领域研究。

Abstract: Multimedia documents such as slide presentations and posters are designed to be interactive and easy to modify. Yet, they are often distributed in a static raster format, which limits editing and customization. Restoring their editability requires converting these raster images back into structured vector formats. However, existing geometric raster-vectorization methods, which rely on low-level primitives like curves and polygons, fall short at this task. Specifically, when applied to complex documents like slides, they fail to preserve the high-level structure, resulting in a flat collection of shapes where the semantic distinction between image and text elements is lost. To overcome this limitation, we address the problem of semantic document derendering by introducing SliDer, a novel framework that uses Vision-Language Models (VLMs) to derender slide images as compact and editable Scalable Vector Graphic (SVG) representations. SliDer detects and extracts attributes from individual image and text elements in a raster input and organizes them into a coherent SVG format. Crucially, the model iteratively refines its predictions during inference in a process analogous to human design, generating SVG code that more faithfully reconstructs the original raster upon rendering. Furthermore, we introduce Slide2SVG, a novel dataset comprising raster-SVG pairs of slide documents curated from real-world scientific presentations, to facilitate future research in this domain. Our results demonstrate that SliDer achieves a reconstruction LPIPS of 0.069 and is favored by human evaluators in 82.9% of cases compared to the strongest zero-shot VLM baseline.

</details>


### [269] [InterMoE: Individual-Specific 3D Human Interaction Generation via Dynamic Temporal-Selective MoE](https://arxiv.org/abs/2511.13488)
*Lipeng Wang,Hongxing Fan,Haohua Chen,Zehuan Huang,Lu Sheng*

Main category: cs.CV

TL;DR: InterMoE是一个基于动态时间选择性专家混合的新型框架，用于生成高质量的人体交互动作，通过结合高级文本语义和低级运动上下文的路由机制，在保持个体特征的同时确保语义保真度。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成人体交互时往往无法保持独特的个体特征或完全遵循文本描述，这限制了在虚拟现实和机器人等应用中的使用价值。

Method: InterMoE采用动态时间选择性专家混合框架，核心是路由机制，协同使用高级文本语义和低级运动上下文，将时间运动特征分配给专门化的专家，使专家能动态确定选择能力并关注关键时间特征。

Result: 在InterHuman数据集上FID分数降低9%，在InterX数据集上降低22%，在个体特定高保真3D人体交互生成方面达到最先进性能。

Conclusion: InterMoE框架通过动态专家选择机制，有效解决了保持个体特征和语义保真度的挑战，在人体交互生成任务中表现出色。

Abstract: Generating high-quality human interactions holds significant value for applications like virtual reality and robotics. However, existing methods often fail to preserve unique individual characteristics or fully adhere to textual descriptions. To address these challenges, we introduce InterMoE, a novel framework built on a Dynamic Temporal-Selective Mixture of Experts. The core of InterMoE is a routing mechanism that synergistically uses both high-level text semantics and low-level motion context to dispatch temporal motion features to specialized experts. This allows experts to dynamically determine the selection capacity and focus on critical temporal features, thereby preserving specific individual characteristic identities while ensuring high semantic fidelity. Extensive experiments show that InterMoE achieves state-of-the-art performance in individual-specific high-fidelity 3D human interaction generation, reducing FID scores by 9% on the InterHuman dataset and 22% on InterX.

</details>


### [270] [Language-Guided Invariance Probing of Vision-Language Models](https://arxiv.org/abs/2511.13494)
*Jae Joong Lee*

Main category: cs.CV

TL;DR: LGIP基准测试评估视觉语言模型对语义保持的改写和语义改变的翻转的鲁棒性，发现EVA02-CLIP和大型OpenCLIP变体在不变性和敏感性方面表现最佳，而SigLIP模型存在明显缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在零样本任务上表现强劲，但其对受控语言扰动的响应可靠性尚不明确，需要专门的诊断工具来评估语言鲁棒性。

Method: 提出LGIP基准，使用4万张MS COCO图像及其人工标注，自动生成语义保持的改写和基于规则的语义翻转（改变对象类别、颜色或数量），通过不变性误差、语义敏感性差距和阳性率统计模型行为。

Result: 在9个VLM中，EVA02-CLIP和大型OpenCLIP变体在不变性-敏感性边界上表现最佳，而SigLIP和SigLIP2显示出较大的不变性误差，且经常偏好翻转后的描述而非原始人工描述。

Conclusion: LGIP提供了模型无关的诊断工具，能够揭示标准检索指标无法发现的VLM语言鲁棒性问题，对模型评估具有重要意义。

Abstract: Recent vision-language models (VLMs) such as CLIP, OpenCLIP, EVA02-CLIP and SigLIP achieve strong zero-shot performance, but it is unclear how reliably they respond to controlled linguistic perturbations. We introduce Language-Guided Invariance Probing (LGIP), a benchmark that measures (i) invariance to meaning-preserving paraphrases and (ii) sensitivity to meaning-changing semantic flips in image-text matching. Using 40k MS COCO images with five human captions each, we automatically generate paraphrases and rule-based flips that alter object category, color or count, and summarize model behavior with an invariance error, a semantic sensitivity gap and a positive-rate statistic.
  Across nine VLMs, EVA02-CLIP and large OpenCLIP variants lie on a favorable invariance-sensitivity frontier, combining low paraphrase-induced variance with consistently higher scores for original captions than for their flipped counterparts. In contrast, SigLIP and SigLIP2 show much larger invariance error and often prefer flipped captions to the human descriptions, especially for object and color edits. These failures are largely invisible to standard retrieval metrics, indicating that LGIP provides a model-agnostic diagnostic for the linguistic robustness of VLMs beyond conventional accuracy scores.

</details>


### [271] [Mapping the Vanishing and Transformation of Urban Villages in China](https://arxiv.org/abs/2511.13507)
*Wenyu Zhang,Yao Tong,Yiqiu Liu,Rui Cao*

Main category: cs.CV

TL;DR: 本研究提出了一个基于深度学习的框架来监测中国城中村的时空变化，通过多时相遥感影像语义分割和土地利用分类，揭示了城中村改造的复杂性和非线性特征。


<details>
  <summary>Details</summary>
Motivation: 中国城中村经历了大规模拆除和重建，但缺乏对拆除后土地利用效果的系统评估，需要评估当前改造实践的有效性和可持续性。

Method: 使用多时相遥感影像语义分割绘制城中村边界变化，将拆除后土地利用分为六类：未完全拆除、闲置土地、建筑工地、建筑物、绿地和其他，选取中国四个经济区域的代表性城市作为研究区域。

Result: 发现城中村改造过程经常拖延；改造主要发生在城市外围区域，城市核心区相对稳定；揭示了三种时空转型路径：同步改造、延迟改造和渐进优化。

Conclusion: 城中村改造具有碎片化、复杂性和非线性特征，需要分层和因地制宜的规划策略，研究结果为支持更包容、高效和可持续的城市更新提供了实证依据。

Abstract: Urban villages (UVs), informal settlements embedded within China's urban fabric, have undergone widespread demolition and redevelopment in recent decades. However, there remains a lack of systematic evaluation of whether the demolished land has been effectively reused, raising concerns about the efficacy and sustainability of current redevelopment practices. To address the gap, this study proposes a deep learning-based framework to monitor the spatiotemporal changes of UVs in China. Specifically, semantic segmentation of multi-temporal remote sensing imagery is first used to map evolving UV boundaries, and then post-demolition land use is classified into six categories based on the "remained-demolished-redeveloped" phase: incomplete demolition, vacant land, construction sites, buildings, green spaces, and others. Four representative cities from China's four economic regions were selected as the study areas, i.e., Guangzhou (East), Zhengzhou (Central), Xi'an (West), and Harbin (Northeast). The results indicate: 1) UV redevelopment processes were frequently prolonged; 2) redevelopment transitions primarily occurred in peripheral areas, whereas urban cores remained relatively stable; and 3) three spatiotemporal transformation pathways, i.e., synchronized redevelopment, delayed redevelopment, and gradual optimization, were revealed. This study highlights the fragmented, complex and nonlinear nature of UV redevelopment, underscoring the need for tiered and context-sensitive planning strategies. By linking spatial dynamics with the context of redevelopment policies, the findings offer valuable empirical insights that support more inclusive, efficient, and sustainable urban renewal, while also contributing to a broader global understanding of informal settlement transformations.

</details>


### [272] [Minimax Multi-Target Conformal Prediction with Applications to Imaging Inverse Problems](https://arxiv.org/abs/2511.13533)
*Jeffrey Wen,Rizwan Ahmad,Philip Schniter*

Main category: cs.CV

TL;DR: 提出一种渐近极小极大方法用于多目标共形预测，为多目标不确定性量化提供紧致的预测区间并保证联合边际覆盖


<details>
  <summary>Details</summary>
Motivation: 在不适定成像逆问题中，特别是安全关键应用中，多目标不确定性量化是一个基本挑战，现有方法只能处理标量估计目标

Method: 渐近极小极大多目标共形预测方法，可应用于多度量盲图像质量评估、多任务不确定性量化和多轮测量采集

Result: 通过合成和磁共振成像数据的数值实验证明，该方法相对于现有多目标共形预测方法具有优势

Conclusion: 提出的极小极大方法为多目标不确定性量化提供了有效的解决方案，在保证联合边际覆盖的同时提供紧致的预测区间

Abstract: In ill-posed imaging inverse problems, uncertainty quantification remains a fundamental challenge, especially in safety-critical applications. Recently, conformal prediction has been used to quantify the uncertainty that the inverse problem contributes to downstream tasks like image classification, image quality assessment, fat mass quantification, etc. While existing works handle only a scalar estimation target, practical applications often involve multiple targets. In response, we propose an asymptotically minimax approach to multi-target conformal prediction that provides tight prediction intervals while ensuring joint marginal coverage. We then outline how our minimax approach can be applied to multi-metric blind image quality assessment, multi-task uncertainty quantification, and multi-round measurement acquisition. Finally, we numerically demonstrate the benefits of our minimax method, relative to existing multi-target conformal prediction methods, using both synthetic and magnetic resonance imaging (MRI) data.

</details>


### [273] [Accuracy is Not Enough: Poisoning Interpretability in Federated Learning via Color Skew](https://arxiv.org/abs/2511.13535)
*Farhin Farhad Riya,Shahinul Hoque,Jinyuan Stella Sun,Olivera Kotevska*

Main category: cs.CV

TL;DR: 本文提出了一种针对联邦学习中模型可解释性的新型攻击方法，通过微小的颜色扰动在不影响分类准确率的情况下破坏显著性图的可靠性。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习模型在安全关键领域的广泛应用，可视化解释技术成为支持透明性的重要工具。然而，当前模型审计中普遍假设正确预测意味着忠实解释，这一假设存在安全风险。

Method: 提出了色度扰动模块（Chromatic Perturbation Module），通过系统性地改变前景与背景之间的颜色对比度来制作对抗样本，在联邦学习环境中逐步累积这些扰动，以隐蔽且持久的方式毒化全局模型的内部特征归因。

Result: 攻击在多个数据集上评估，标准训练流程无法检测或缓解解释质量下降。攻击使Grad-CAM解释的峰值激活重叠度降低高达35%，同时保持分类准确率在96%以上。

Conclusion: 研究揭示了可解释性本身可能成为攻击面，挑战了模型审计中的常见假设，表明在联邦学习环境中，细微的颜色扰动难以察觉但能有效破坏解释的忠实性。

Abstract: As machine learning models are increasingly deployed in safety-critical domains, visual explanation techniques have become essential tools for supporting transparency. In this work, we reveal a new class of attacks that compromise model interpretability without affecting accuracy. Specifically, we show that small color perturbations applied by adversarial clients in a federated learning setting can shift a model's saliency maps away from semantically meaningful regions while keeping the prediction unchanged. The proposed saliency-aware attack framework, called Chromatic Perturbation Module, systematically crafts adversarial examples by altering the color contrast between foreground and background in a way that disrupts explanation fidelity. These perturbations accumulate across training rounds, poisoning the global model's internal feature attributions in a stealthy and persistent manner. Our findings challenge a common assumption in model auditing that correct predictions imply faithful explanations and demonstrate that interpretability itself can be an attack surface. We evaluate this vulnerability across multiple datasets and show that standard training pipelines are insufficient to detect or mitigate explanation degradation, especially in the federated learning setting, where subtle color perturbations are harder to discern. Our attack reduces peak activation overlap in Grad-CAM explanations by up to 35% while preserving classification accuracy above 96% on all evaluated datasets.

</details>


### [274] [BootOOD: Self-Supervised Out-of-Distribution Detection via Synthetic Sample Exposure under Neural Collapse](https://arxiv.org/abs/2511.13539)
*Yuanchao Wang,Tian Qin,Eduardo Valle,Bruno Abrahao*

Main category: cs.CV

TL;DR: BootOOD是一个完全自监督的OOD检测框架，通过从ID数据中合成伪OOD特征，并利用神经坍缩现象，使用基于半径的辅助分类头来区分ID和语义相似的OOD样本。


<details>
  <summary>Details</summary>
Motivation: 现有OOD检测器在处理语义上与ID类别相似的OOD样本时表现不佳，需要一种能够有效处理语义挑战性OOD样本的方法。

Method: BootOOD通过ID特征的简单变换合成伪OOD特征，利用神经坍缩现象，引入轻量级辅助头进行基于特征范数的半径分类，将OOD检测与主分类器解耦。

Result: 在CIFAR-10、CIFAR-100和ImageNet-200上的实验表明，BootOOD优于现有后处理方法，超越无离群值暴露的训练方法，并与最先进的离群值暴露方法竞争，同时保持或提高ID准确率。

Conclusion: BootOOD提供了一种有效的自监督OOD检测解决方案，特别适用于语义相似的OOD场景，且无需外部OOD数据。

Abstract: Out-of-distribution (OOD) detection is critical for deploying image classifiers in safety-sensitive environments, yet existing detectors often struggle when OOD samples are semantically similar to the in-distribution (ID) classes. We present BootOOD, a fully self-supervised OOD detection framework that bootstraps exclusively from ID data and is explicitly designed to handle semantically challenging OOD samples. BootOOD synthesizes pseudo-OOD features through simple transformations of ID representations and leverages Neural Collapse (NC), where ID features cluster tightly around class means with consistent feature norms. Unlike prior approaches that aim to constrain OOD features into subspaces orthogonal to the collapsed ID means, BootOOD introduces a lightweight auxiliary head that performs radius-based classification on feature norms. This design decouples OOD detection from the primary classifier and imposes a relaxed requirement: OOD samples are learned to have smaller feature norms than ID features, which is easier to satisfy when ID and OOD are semantically close. Experiments on CIFAR-10, CIFAR-100, and ImageNet-200 show that BootOOD outperforms prior post-hoc methods, surpasses training-based methods without outlier exposure, and is competitive with state-of-the-art outlier-exposure approaches while maintaining or improving ID accuracy.

</details>


### [275] [Robust Defense Strategies for Multimodal Contrastive Learning: Efficient Fine-tuning Against Backdoor Attacks](https://arxiv.org/abs/2511.13545)
*Md. Iqbal Hossain,Afia Sajeeda,Neeresh Kumar Perla,Ming Shao*

Main category: cs.CV

TL;DR: 本文提出了一种针对多模态对比学习模型（如CLIP）的后门攻击防御策略，通过图像分割"oracle"作为监督器，识别后门触发器、受害样本和标签，并开发两种算法来修复中毒模型。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态深度学习模型（如CLIP）容易受到后门攻击，而现有防御方法通常需要从头训练或使用大量数据进行微调，且无法精确定位受影响的标签。

Method: 1. 引入图像分割"oracle"作为中毒CLIP输出的监督器；2. 开发两种算法：区分CLIP和Oracle的知识以识别潜在触发器；精确定位受影响标签和受害样本，并构建紧凑的微调数据集。

Result: 在视觉识别基准上的大量实验表明，该策略在基于CLIP的后门防御中有效。

Conclusion: 该方法能够高效识别后门触发器、受害样本和标签，并通过微调修复中毒的CLIP模型，有效抵御后门攻击。

Abstract: The advent of multimodal deep learning models, such as CLIP, has unlocked new frontiers in a wide range of applications, from image-text understanding to classification tasks. However, these models are not safe for adversarial attacks, particularly backdoor attacks, which can subtly manipulate model behavior. Moreover, existing defense methods typically involve training from scratch or fine-tuning using a large dataset without pinpointing the specific labels that are affected. In this study, we introduce an innovative strategy to enhance the robustness of multimodal contrastive learning models against such attacks. In particular, given a poisoned CLIP model, our approach can identify the backdoor trigger and pinpoint the victim samples and labels in an efficient manner. To that end, an image segmentation ``oracle'' is introduced as the supervisor for the output of the poisoned CLIP. We develop two algorithms to rectify the poisoned model: (1) differentiating between CLIP and Oracle's knowledge to identify potential triggers; (2) pinpointing affected labels and victim samples, and curating a compact fine-tuning dataset. With this knowledge, we are allowed to rectify the poisoned CLIP model to negate backdoor effects. Extensive experiments on visual recognition benchmarks demonstrate our strategy is effective in CLIP-based backdoor defense.

</details>


### [276] [TSE-Net: Semi-supervised Monocular Height Estimation from Single Remote Sensing Images](https://arxiv.org/abs/2511.13552)
*Sining Chen,Xiao Xiang Zhu*

Main category: cs.CV

TL;DR: 提出TSE-Net半监督学习框架，通过教师-学生-考试网络架构解决单目高度估计中标注数据稀缺的问题，利用无标签数据提升模型性能


<details>
  <summary>Details</summary>
Motivation: 单目高度估计在3D遥感感知中具有重要价值，但现有深度学习方法受限于标注数据的稀缺性和获取成本高的问题，需要利用大量无标签数据来提升模型泛化能力

Method: 提出TSE-Net自训练管道，包含教师网络、学生网络和考试网络。教师网络通过联合回归和分类生成伪标签，学生网络在无标签数据上训练，考试网络作为学生网络的时序集成以稳定性能。采用分层双切策略处理高度值的长尾分布，使用Plackett-Luce模型校准类别概率

Result: 在三个不同分辨率和成像模式的数据集上进行了评估，证明了方法的有效性。代码已开源

Conclusion: TSE-Net框架能够有效利用无标签数据，解决单目高度估计中的标注数据稀缺问题，提高模型性能，为半监督学习在遥感领域的应用提供了新思路

Abstract: Monocular height estimation plays a critical role in 3D perception for remote sensing, offering a cost-effective alternative to multi-view or LiDAR-based methods. While deep learning has significantly advanced the capabilities of monocular height estimation, these methods remain fundamentally limited by the availability of labeled data, which are expensive and labor-intensive to obtain at scale. The scarcity of high-quality annotations hinders the generalization and performance of existing models. To overcome this limitation, we propose leveraging large volumes of unlabeled data through a semi-supervised learning framework, enabling the model to extract informative cues from unlabeled samples and improve its predictive performance. In this work, we introduce TSE-Net, a self-training pipeline for semi-supervised monocular height estimation. The pipeline integrates teacher, student, and exam networks. The student network is trained on unlabeled data using pseudo-labels generated by the teacher network, while the exam network functions as a temporal ensemble of the student network to stabilize performance. The teacher network is formulated as a joint regression and classification model: the regression branch predicts height values that serve as pseudo-labels, and the classification branch predicts height value classes along with class probabilities, which are used to filter pseudo-labels. Height value classes are defined using a hierarchical bi-cut strategy to address the inherent long-tailed distribution of heights, and the predicted class probabilities are calibrated with a Plackett-Luce model to reflect the expected accuracy of pseudo-labels. We evaluate the proposed pipeline on three datasets spanning different resolutions and imaging modalities. Codes are available at https://github.com/zhu-xlab/tse-net.

</details>


### [277] [Opt3DGS: Optimizing 3D Gaussian Splatting with Adaptive Exploration and Curvature-Aware Exploitation](https://arxiv.org/abs/2511.13571)
*Ziyang Huang,Jiagang Chen,Jin Liu,Shunping Ji*

Main category: cs.CV

TL;DR: Opt3DGS提出了一个两阶段优化框架，通过自适应探索和曲率引导的利用来解决3D高斯泼溅的局部最优陷阱和收敛质量不足问题


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅在新视角合成中表现出色，但其核心优化问题（陷入局部最优和收敛质量不足）尚未得到充分探索

Method: 采用两阶段优化：探索阶段使用自适应加权随机梯度Langevin动力学增强全局搜索；利用阶段使用局部拟牛顿方向引导的Adam优化器利用曲率信息实现精确收敛

Result: 在多个基准数据集上的广泛实验表明，Opt3DGS在不改变3DGS底层表示的情况下，通过优化过程实现了最先进的渲染质量

Conclusion: Opt3DGS是一个稳健的框架，通过改进优化过程显著提升了3D高斯泼溅的性能

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a leading framework for novel view synthesis, yet its core optimization challenges remain underexplored. We identify two key issues in 3DGS optimization: entrapment in suboptimal local optima and insufficient convergence quality. To address these, we propose Opt3DGS, a robust framework that enhances 3DGS through a two-stage optimization process of adaptive exploration and curvature-guided exploitation. In the exploration phase, an Adaptive Weighted Stochastic Gradient Langevin Dynamics (SGLD) method enhances global search to escape local optima. In the exploitation phase, a Local Quasi-Newton Direction-guided Adam optimizer leverages curvature information for precise and efficient convergence. Extensive experiments on diverse benchmark datasets demonstrate that Opt3DGS achieves state-of-the-art rendering quality by refining the 3DGS optimization process without modifying its underlying representation.

</details>


### [278] [Hierarchical Prompt Learning for Image- and Text-Based Person Re-Identification](https://arxiv.org/abs/2511.13575)
*Linhan Zhou,Shuang Li,Neng Dong,Yonghang Tai,Yafei Zhang,Huafeng Li*

Main category: cs.CV

TL;DR: 本文提出了一种统一框架HPL，通过任务感知提示建模联合优化图像到图像和文本到图像的行人重识别任务，解决了现有方法将两者分离处理导致的表示纠缠和性能不佳问题。


<details>
  <summary>Details</summary>
Motivation: 现有的行人重识别方法通常将图像到图像和文本到图像检索任务分开处理，这可能导致表示纠缠和次优性能。两个任务虽然共享检索目标，但面临不同挑战：I2I强调判别性身份学习，而T2I需要准确的跨模态语义对齐。

Method: 提出分层提示学习框架，包含任务路由Transformer和分层提示生成方案。任务路由Transformer在共享视觉编码器中引入双分类令牌来路由I2I和T2I分支特征。分层提示生成整合身份级可学习令牌和实例级伪文本令牌，通过模态特定反演网络从图像或文本特征中提取伪令牌。还提出跨模态提示正则化策略来增强语义对齐。

Result: 在多个ReID基准测试上的广泛实验验证了该方法的有效性，在I2I和T2I任务上都达到了最先进的性能。

Conclusion: HPL框架通过统一处理I2I和T2I任务，有效解决了表示纠缠问题，在两个任务上都取得了优异性能，证明了任务感知提示建模在行人重识别中的有效性。

Abstract: Person re-identification (ReID) aims to retrieve target pedestrian images given either visual queries (image-to-image, I2I) or textual descriptions (text-to-image, T2I). Although both tasks share a common retrieval objective, they pose distinct challenges: I2I emphasizes discriminative identity learning, while T2I requires accurate cross-modal semantic alignment. Existing methods often treat these tasks separately, which may lead to representation entanglement and suboptimal performance. To address this, we propose a unified framework named Hierarchical Prompt Learning (HPL), which leverages task-aware prompt modeling to jointly optimize both tasks. Specifically, we first introduce a Task-Routed Transformer, which incorporates dual classification tokens into a shared visual encoder to route features for I2I and T2I branches respectively. On top of this, we develop a hierarchical prompt generation scheme that integrates identity-level learnable tokens with instance-level pseudo-text tokens. These pseudo-tokens are derived from image or text features via modality-specific inversion networks, injecting fine-grained, instance-specific semantics into the prompts. Furthermore, we propose a Cross-Modal Prompt Regularization strategy to enforce semantic alignment in the prompt token space, ensuring that pseudo-prompts preserve source-modality characteristics while enhancing cross-modal transferability. Extensive experiments on multiple ReID benchmarks validate the effectiveness of our method, achieving state-of-the-art performance on both I2I and T2I tasks.

</details>


### [279] [Adaptive Multi-Scale Integration Unlocks Robust Cell Annotation in Histopathology Images](https://arxiv.org/abs/2511.13586)
*Yinuo Xu,Yan Cui,Mingyao Li,Zhi Huang*

Main category: cs.CV

TL;DR: NuClass是一个病理学家工作流程启发的框架，通过多尺度整合核形态和微环境上下文来进行细胞级分类，解决了现有方法缺乏组织上下文和细粒度标注的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于图像块的模型能捕捉详细核形态但缺乏组织上下文，且人类标注通常粗糙且分布不均，难以获得细粒度的亚型级监督。

Method: NuClass包含两个主要组件：Path local（关注224×224像素的核形态）和Path global（建模1024×1024像素的周围环境），通过可学习门控模块自适应平衡局部细节和上下文线索，并引入不确定性引导目标。

Result: 在三个完全保留的队列上评估，NuClass在最佳类别上达到96%的F1分数，优于强基线。

Conclusion: 多尺度、不确定性感知融合可以弥合幻灯片级病理基础模型与可靠细胞级表型预测之间的差距。

Abstract: Identifying cell types and subtypes from routine histopathology images is essential for improving the computational understanding of human disease. Existing tile-based models can capture detailed nuclear morphology but often fail to incorporate the broader tissue context that influences a cell's function and identity. In addition, available human annotations are typically coarse-grained and unevenly distributed across studies, making fine-grained subtype-level supervision difficult to obtain.
  To address these limitations, we introduce NuClass, a pathologist workflow inspired framework for cell-wise multi-scale integration of nuclear morphology and microenvironmental context. NuClass includes two main components: Path local, which focuses on nuclear morphology from 224-by-224 pixel crops, and Path global, which models the surrounding 1024-by-1024 pixel neighborhood. A learnable gating module adaptively balances local detail and contextual cues. To encourage complementary learning, we incorporate an uncertainty-guided objective that directs the global path to prioritize regions where the local path is uncertain. We also provide calibrated confidence estimates and Grad-CAM visualizations to enhance interpretability.
  To overcome the lack of high-quality annotations, we construct a marker-guided dataset from Xenium spatial transcriptomics assays, yielding single-cell resolution labels for more than two million cells across eight organs and 16 classes. Evaluated on three fully held-out cohorts, NuClass achieves up to 96 percent F1 for its best-performing class, outperforming strong baselines. Our results show that multi-scale, uncertainty-aware fusion can bridge the gap between slide-level pathological foundation models and reliable, cell-level phenotype prediction.

</details>


### [280] [VVS: Accelerating Speculative Decoding for Visual Autoregressive Generation via Partial Verification Skipping](https://arxiv.org/abs/2511.13587)
*Haotian Dong,Ye Li,Rongwei Lu,Chen Tang,Shu-Tao Xia,Zhi Wang*

Main category: cs.CV

TL;DR: VVS是一种新颖的推测解码框架，通过部分验证跳过加速视觉自回归模型生成，将目标模型前向传递次数减少2.8倍，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 视觉自回归生成模型存在推理延迟问题，传统推测解码的"一步起草、一步验证"范式限制了加速潜力。视觉令牌的可互换性为验证跳过提供了可能性。

Method: 提出VVS框架，包含三个互补模块：动态截断的验证自由令牌选择器、令牌级特征缓存和重用、细粒度跳过步骤调度。

Result: VVS相比原始自回归解码减少了2.8倍目标模型前向传递次数，在保持竞争力的生成质量的同时提供了优越的速度-质量权衡。

Conclusion: VFS框架展示了重塑推测解码范式的强大潜力，为视觉自回归模型提供了更高效的推理加速方案。

Abstract: Visual autoregressive (AR) generation models have demonstrated strong potential for image generation, yet their next-token-prediction paradigm introduces considerable inference latency. Although speculative decoding (SD) has been proven effective for accelerating visual AR models, its "draft one step, then verify one step" paradigm prevents a direct reduction of the forward passes, thus restricting acceleration potential. Motivated by the visual token interchangeability, we for the first time to explore verification skipping in the SD process of visual AR model generation to explicitly cut the number of target model forward passes, thereby reducing inference latency. Based on an analysis of the drafting stage's characteristics, we observe that verification redundancy and stale feature reusability are key factors to retain generation quality and speedup for verification-free steps. Inspired by these two observations, we propose a novel SD framework VVS to accelerate visual AR generation via partial verification skipping, which integrates three complementary modules: (1) a verification-free token selector with dynamical truncation, (2) token-level feature caching and reuse, and (3) fine-grained skipped step scheduling. Consequently, VVS reduces the number of target model forward passes by a factor of $2.8\times$ relative to vanilla AR decoding while maintaining competitive generation quality, offering a superior speed-quality trade-off over conventional SD frameworks and revealing strong potential to reshape the SD paradigm.

</details>


### [281] [ICLR: Inter-Chrominance and Luminance Interaction for Natural Color Restoration in Low-Light Image Enhancement](https://arxiv.org/abs/2511.13607)
*Xin Xu,Hao Liu,Wei Liu,Wei Wang,Jiayi Wu,Kui Jiang*

Main category: cs.CV

TL;DR: 本文提出了一种名为ICLR的框架，通过双流交互增强模块和协方差校正损失来解决低光图像增强中色度和亮度分支交互的问题，在多个数据集上取得了优于现有方法的效果。


<details>
  <summary>Details</summary>
Motivation: 在HVI颜色空间中，色度和亮度分支之间存在显著分布差异，限制了互补特征提取，且亮度误差会通过非线性参数传播到色度通道。此外，大均匀颜色区域的图像中色度分支之间相关性较弱，传统像素级损失会导致梯度冲突。

Method: 提出了ICLR框架，包括双流交互增强模块（DIEM）和协方差校正损失（CCL）。DIEM从融合和增强两个维度改进互补信息提取，CCL利用亮度残差统计惩罚色度误差，并通过约束色度分支协方差来平衡梯度冲突。

Result: 在多个数据集上的实验结果表明，所提出的ICLR框架优于现有的最先进方法。

Conclusion: ICLR框架有效解决了低光图像增强中色度和亮度分支交互的问题，通过改进的交互机制和损失函数设计，实现了更好的图像增强效果。

Abstract: Low-Light Image Enhancement (LLIE) task aims at improving contrast while restoring details and textures for images captured in low-light conditions. HVI color space has made significant progress in this task by enabling precise decoupling of chrominance and luminance. However, for the interaction of chrominance and luminance branches, substantial distributional differences between the two branches prevalent in natural images limit complementary feature extraction, and luminance errors are propagated to chrominance channels through the nonlinear parameter. Furthermore, for interaction between different chrominance branches, images with large homogeneous-color regions usually exhibit weak correlation between chrominance branches due to concentrated distributions. Traditional pixel-wise losses exploit strong inter-branch correlations for co-optimization, causing gradient conflicts in weakly correlated regions. Therefore, we propose an Inter-Chrominance and Luminance Interaction (ICLR) framework including a Dual-stream Interaction Enhancement Module (DIEM) and a Covariance Correction Loss (CCL). The DIEM improves the extraction of complementary information from two dimensions, fusion and enhancement, respectively. The CCL utilizes luminance residual statistics to penalize chrominance errors and balances gradient conflicts by constraining chrominance branches covariance. Experimental results on multiple datasets show that the proposed ICLR framework outperforms state-of-the-art methods.

</details>


### [282] [AtlasMorph: Learning conditional deformable templates for brain MRI](https://arxiv.org/abs/2511.13609)
*Marianne Rakic,Andrew Hoopes,S. Mazdak Abulnaga,Mert R. Sabuncu,John V. Guttag,Adrian V. Dalca*

Main category: cs.CV

TL;DR: 提出了一种基于卷积配准神经网络的机器学习框架，能够根据特定属性（如年龄、性别）高效生成可变形模板，并利用分割信息生成解剖标签图。


<details>
  <summary>Details</summary>
Motivation: 现有模板构建过程计算成本高，可用模板数量有限，导致研究常使用不具代表性的模板，特别是在群体差异较大时。

Method: 使用卷积配准神经网络学习一个函数，该函数根据特定属性输出模板，并在有分割信息时生成对应的解剖分割图。

Result: 在3D脑部MRI数据集上验证，该方法能够学习到高质量的代表性模板，带标签的条件模板比无标签模板具有更好的配准效果。

Conclusion: 该方法优于其他模板构建方法，能够生成更符合特定群体特征的可变形模板。

Abstract: Deformable templates, or atlases, are images that represent a prototypical anatomy for a population, and are often enhanced with probabilistic anatomical label maps. They are commonly used in medical image analysis for population studies and computational anatomy tasks such as registration and segmentation. Because developing a template is a computationally expensive process, relatively few templates are available. As a result, analysis is often conducted with sub-optimal templates that are not truly representative of the study population, especially when there are large variations within this population. We propose a machine learning framework that uses convolutional registration neural networks to efficiently learn a function that outputs templates conditioned on subject-specific attributes, such as age and sex. We also leverage segmentations, when available, to produce anatomical segmentation maps for the resulting templates. The learned network can also be used to register subject images to the templates. We demonstrate our method on a compilation of 3D brain MRI datasets, and show that it can learn high-quality templates that are representative of populations. We find that annotated conditional templates enable better registration than their unlabeled unconditional counterparts, and outperform other templates construction methods.

</details>


### [283] [Tissue Aware Nuclei Detection and Classification Model for Histopathology Images](https://arxiv.org/abs/2511.13615)
*Kesi Xu,Eleni Chiou,Ali Varamesh,Laura Acqualagna,Nasir Rajpoot*

Main category: cs.CV

TL;DR: TAND是一种新颖的组织感知细胞核检测框架，通过点级监督和组织掩码条件化实现联合细胞核检测与分类，在PUMA基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖详细的专家标注且未能充分利用组织上下文信息，这限制了计算病理学中细胞核检测和分类的准确性。

Method: TAND结合ConvNeXt编码器-解码器与冻结的Virchow-2组织分割分支，通过新颖的多尺度空间特征线性调制（Spatial-FiLM）选择性地调节分类流。

Result: 在PUMA基准测试中，TAND超越了组织无关基线和掩码监督方法，特别是在上皮细胞、内皮细胞和基质细胞等组织依赖性细胞类型上表现出显著改进。

Conclusion: 这是首个基于学习组织掩码进行单细胞分类条件化的方法，为减轻标注负担提供了实用途径。

Abstract: Accurate nuclei detection and classification are fundamental to computational pathology, yet existing approaches are hindered by reliance on detailed expert annotations and insufficient use of tissue context. We present Tissue-Aware Nuclei Detection (TAND), a novel framework achieving joint nuclei detection and classification using point-level supervision enhanced by tissue mask conditioning. TAND couples a ConvNeXt-based encoder-decoder with a frozen Virchow-2 tissue segmentation branch, where semantic tissue probabilities selectively modulate the classification stream through a novel multi-scale Spatial Feature-wise Linear Modulation (Spatial-FiLM). On the PUMA benchmark, TAND achieves state-of-the-art performance, surpassing both tissue-agnostic baselines and mask-supervised methods. Notably, our approach demonstrates remarkable improvements in tissue-dependent cell types such as epithelium, endothelium, and stroma. To the best of our knowledge, this is the first method to condition per-cell classification on learned tissue masks, offering a practical pathway to reduce annotation burden.

</details>


### [284] [A Real-Time Driver Drowsiness Detection System Using MediaPipe and Eye Aspect Ratio](https://arxiv.org/abs/2511.13618)
*Ashlesha G. Sawant,Shreyash S. Kamble,Raj S. Kanade,Raunak N. Kanugo,Tanishq A. Kapse,Karan A. Bhapse*

Main category: cs.CV

TL;DR: 本文开发了一个基于面部特征检测的驾驶员疲劳检测系统，通过分析眼部运动来识别疲劳迹象并及时发出警报


<details>
  <summary>Details</summary>
Motivation: 驾驶员疲劳是导致道路事故的主要原因之一，每年造成大量伤亡，需要开发有效的实时监测系统来提高道路安全

Method: 使用标准网络摄像头和MediaPipe Face Mesh框架检测面部特征，重点采用Eye Aspect Ratio (EAR)方法分析眼部运动，通过OpenCV进行图像处理，检测长时间闭眼或低眨眼频率等疲劳特征

Result: 实验分析表明该系统具有高准确性和快速响应能力，能够有效识别疲劳状态并及时发出声音警报

Conclusion: 该系统提供了一种高性能、低成本的驾驶员监控解决方案，可以作为先进驾驶辅助系统(ADAS)的重要组成部分

Abstract: One of the major causes of road accidents is driver fatigue that causes thousands of fatalities and injuries every year. This study shows development of a Driver Drowsiness Detection System meant to improve the safety of the road by alerting drivers who are showing signs of being drowsy. The system is based on a standard webcam that tracks the facial features of the driver with the main emphasis on the examination of eye movements that can be conducted with the help of the Eye Aspect Ratio (EAR) method. The Face Mesh by MediaPipe is a lightweight framework that can identify facial landmarks with high accuracy and efficiency, which is considered to be important in real time use. The system detects the moments of long eye shutdowns or a very low rate of blinking which are manifestations of drowsiness and alerts the driver through sound to get her attention back. This system achieves a high-performance and low-cost driver monitoring solution with the help of the computational power of OpenCV to process the image and the MediaPipe to identify faces. Test data experimental analyses indicate that the system is very accurate and responds quicker; this confirms that it can be a component of the current Advanced Driving Assistance System (ADAS).

</details>


### [285] [Alpha Divergence Losses for Biometric Verification](https://arxiv.org/abs/2511.13621)
*Dimitrios Koutsianos,Ladislav Mosner,Yannis Panagakis,Themos Stafylakis*

Main category: cs.CV

TL;DR: 本文提出了两种新颖的基于边界的α-散度损失函数：Q-Margin（在参考度量中引入边界）和A3M（在对数中引入边界），解决了α-散度损失在面部和说话人验证任务中难以集成角度边界的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于边界的softmax损失（如CosFace和ArcFace）在面部和说话人验证中表现优异，但α-散度损失函数（特别是当α>1时能诱导稀疏解）的集成角度边界并不直接。本文旨在探索将角度边界集成到α-散度损失中的方法。

Method: 通过两种途径集成角度边界：在参考度量（先验概率）中引入边界（Q-Margin）或在对数（未归一化对数似然）中引入边界（A3M）。针对A3M中由惩罚对数与稀疏性相互作用引起的训练不稳定性，提出了一种简单有效的原型重新初始化策略。

Result: 在挑战性的IJB-B和IJB-C面部验证基准测试中取得了显著的性能提升，在VoxCeleb说话人验证中也表现出类似的强大性能。关键的是，在低误接受率（FAR）下，模型显著优于强基线。

Conclusion: 提出的Q-Margin和A3M方法能够有效集成角度边界到α-散度损失中，在面部和说话人验证任务中实现卓越性能，特别是在需要最小化错误认证的高安全性应用（如银行认证）中表现出色。

Abstract: Performance in face and speaker verification is largely driven by margin based softmax losses like CosFace and ArcFace. Recently introduced $α$-divergence loss functions offer a compelling alternative, particularly for their ability to induce sparse solutions (when $α>1$). However, integrating an angular margin-crucial for verification tasks-is not straightforward. We find this integration can be achieved in at least two distinct ways: via the reference measure (prior probabilities) or via the logits (unnormalized log-likelihoods). In this paper, we explore both pathways, deriving two novel margin-based $α$-divergence losses: Q-Margin (margin in the reference measure) and A3M (margin in the logits). We identify and address a critical training instability in A3M-caused by the interplay of penalized logits and sparsity-with a simple yet effective prototype re-initialization strategy. Our methods achieve significant performance gains on the challenging IJB-B and IJB-C face verification benchmarks. We demonstrate similarly strong performance in speaker verification on VoxCeleb. Crucially, our models significantly outperform strong baselines at low false acceptance rates (FAR). This capability is crucial for practical high-security applications, such as banking authentication, when minimizing false authentications is paramount.

</details>


### [286] [CacheFlow: Compressive Streaming Memory for Efficient Long-Form Video Understanding](https://arxiv.org/abs/2511.13644)
*Shrenik Patel,Daivik Patel*

Main category: cs.CV

TL;DR: CacheFlow是一个无需训练的长视频问答解决方案，通过动态令牌丢弃和压缩长期记忆机制，显著减少处理令牌数量（高达87%），同时保持答案准确性。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在处理长视频问答时面临注意力机制和KV缓存随运行时间增长的问题，导致推理成本高昂或只能使用短视的滑动窗口方法。

Method: 结合动态令牌丢弃（基于余弦相似度的逐帧令牌剪枝）和压缩长期记忆（使用小型循环编码器构建检索索引，KV对离线存储并按需恢复），采用基于共识的检索机制选择最相关的Top-K块进行注意力计算。

Result: 在离线和流式视频问答基准测试中，CacheFlow优于当前强基线方法，同时处理令牌数量减少高达87%。

Conclusion: CacheFlow的双重方法使视觉语言模型既高效又具备上下文感知能力，为实用的长视频理解铺平了道路。

Abstract: Long-form video question answering (VQA) overwhelms current vision-language models (VLMs) because attention and key-value (KV) caches grow with runtime, forcing either expensive inference or near-sighted sliding windows. We introduce CacheFlow, a training-free pipeline that pairs Dynamic Token Dropping (DTD) with a compressive long-term memory. DTD prunes per-patch tokens online via cosine similarity to the previous frame, and surviving tokens are packed into fixed-size blocks. This online, per-frame processing makes our approach fundamentally suited for live streaming VQA. As blocks are processed, each one's keys are summarized by a tiny recurrent encoder to form a retrieval index, while the block's full KV pairs are offloaded and later rehydrated for generation, preserving answer fidelity. At inference, a consensus-based retrieval mechanism retrieves only the Top-K most relevant blocks and attends over both the retrieved and local context for precise, long-range reasoning. CacheFlow is drop-in, architecture-agnostic, and requires no fine-tuning. Experiments on both offline and streaming VQA benchmarks demonstrate that CacheFlow outperforms current strong baselines, while processing up to 87% less tokens. Our dual approach enables VLMs to be both efficient and context-aware, paving the way for practical long-form video understanding.

</details>


### [287] [Part-X-MLLM: Part-aware 3D Multimodal Large Language Model](https://arxiv.org/abs/2511.13647)
*Chunshi Wang,Junliang Ye,Yunhan Yang,Yang Li,Zizhuo Lin,Jun Zhu,Zhuo Chen,Yawei Luo,Chunchao Guo*

Main category: cs.CV

TL;DR: Part-X-MLLM是一个原生3D多模态大语言模型，通过将不同3D任务统一为结构化可执行语法中的程序，实现了对RGB点云和自然语言提示的统一处理，生成包含部件级边界框、语义描述和编辑命令的连贯标记序列。


<details>
  <summary>Details</summary>
Motivation: 当前3D任务处理通常需要专门模型，缺乏统一接口。本文旨在通过语言原生前端统一控制不同的几何感知模块，实现符号规划与几何合成的解耦。

Method: 采用双编码器架构进行预训练，分离结构和语义表示，并在大规模部件中心数据集上进行指令调优。模型能够自回归生成结构化输出，驱动下游几何感知模块进行部件级生成和编辑。

Result: 实验表明，该模型在生成高质量结构化规划方面表现优异，在基于查询的问答、组合生成和局部编辑等任务上实现了最先进的性能。

Conclusion: Part-X-MLLM通过统一的语言接口成功实现了多种3D任务的统一处理，为几何引擎控制提供了灵活且可扩展的解决方案。

Abstract: We introduce Part-X-MLLM, a native 3D multimodal large language model that unifies diverse 3D tasks by formulating them as programs in a structured, executable grammar. Given an RGB point cloud and a natural language prompt, our model autoregressively generates a single, coherent token sequence encoding part-level bounding boxes, semantic descriptions, and edit commands. This structured output serves as a versatile interface to drive downstream geometry-aware modules for part-based generation and editing. By decoupling the symbolic planning from the geometric synthesis, our approach allows any compatible geometry engine to be controlled through a single, language-native frontend. We pre-train a dual-encoder architecture to disentangle structure from semantics and instruction-tune the model on a large-scale, part-centric dataset. Experiments demonstrate that our model excels at producing high-quality, structured plans, enabling state-of-the-art performance in grounded Q\&A, compositional generation, and localized editing through one unified interface. Project page: https://chunshi.wang/Part-X-MLLM/

</details>


### [288] [Distribution Matching Distillation Meets Reinforcement Learning](https://arxiv.org/abs/2511.13649)
*Dengyang Jiang,Dongyang Liu,Zanyi Wang,Qilong Wu,Xin Jin,David Liu,Zhen Li,Mengmeng Wang,Peng Gao,Harry Yang*

Main category: cs.CV

TL;DR: DMDR是一个结合强化学习的蒸馏框架，旨在将多步扩散模型蒸馏为少步模型，同时提升性能甚至超越原始教师模型。


<details>
  <summary>Details</summary>
Motivation: 传统的Distribution Matching Distillation (DMD)方法在蒸馏多步扩散模型为少步模型时，性能受限于教师模型。作者希望突破这一限制，让少步生成器具备超越教师模型的潜力。

Method: 提出DMDR框架，将强化学习技术融入蒸馏过程：1) 使用DMD损失作为RL的有效正则化；2) RL指导DMD的模式覆盖过程；3) 设计动态分布引导和动态重噪声采样训练策略优化初始蒸馏。

Result: 实验表明DMDR在少步方法中达到领先的视觉质量和提示一致性，甚至能够超越多步教师模型的性能。

Conclusion: DMDR通过同时进行蒸馏和强化学习，成功解锁了少步生成器的能力，证明了RL与DMD结合的协同效应能够突破传统蒸馏的性能上限。

Abstract: Distribution Matching Distillation (DMD) distills a pre-trained multi-step diffusion model to a few-step one to improve inference efficiency. However, the performance of the latter is often capped by the former. To circumvent this dilemma, we propose DMDR, a novel framework that combines Reinforcement Learning (RL) techniques into the distillation process. We show that for the RL of the few-step generator, the DMD loss itself is a more effective regularization compared to the traditional ones. In turn, RL can help to guide the mode coverage process in DMD more effectively. These allow us to unlock the capacity of the few-step generator by conducting distillation and RL simultaneously. Meanwhile, we design the dynamic distribution guidance and dynamic renoise sampling training strategies to improve the initial distillation process. The experiments demonstrate that DMDR can achieve leading visual quality, prompt coherence among few-step methods, and even exhibit performance that exceeds the multi-step teacher.

</details>


### [289] [OlmoEarth: Stable Latent Image Modeling for Multimodal Earth Observation](https://arxiv.org/abs/2511.13655)
*Henry Herzog,Favyen Bastani,Yawen Zhang,Gabriel Tseng,Joseph Redmon,Hadrien Sablon,Ryan Park,Jacob Morrison,Alexandra Buraczynski,Karen Farley,Joshua Hansen,Andrew Howe,Patrick Alan Johnson,Mark Otterlee,Ted Schmitt,Hunter Pitelka,Stephen Daspit,Rachel Ratner,Christopher Wilhelm,Sebastian Wood,Mike Jacobi,Hannah Kerner,Evan Shelhamer,Ali Farhadi,Ranjay Krishna,Patrick Beukema*

Main category: cs.CV

TL;DR: OlmoEarth是一个多模态、时空基础模型，专门为地球观测数据设计，通过新颖的自监督学习、掩码策略和损失函数，在多个基准测试和实际任务中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 地球观测数据具有空间性（如图像）、序列性（如视频或文本）和多模态特性，传统方法难以有效处理这些复杂特征，需要专门的基础模型来应对这一挑战。

Method: 采用新颖的自监督学习框架、专门设计的掩码策略和损失函数，构建多模态时空基础模型，能够同时处理地球观测数据的空间、时序和多模态特征。

Result: 在24个任务中的15个任务上获得最佳嵌入性能，在29个任务中的19个任务上通过全微调获得最佳性能，优于其他12个基础模型。

Conclusion: OlmoEarth不仅是一个高性能的基础模型，还被部署为端到端平台，为非营利组织和NGO提供强大的地球观测模型开发工具，源代码和预训练权重已开源。

Abstract: Earth observation data presents a unique challenge: it is spatial like images, sequential like video or text, and highly multimodal. We present OlmoEarth: a multimodal, spatio-temporal foundation model that employs a novel self-supervised learning formulation, masking strategy, and loss all designed for the Earth observation domain. OlmoEarth achieves state-of-the-art performance compared to 12 other foundation models across a variety of research benchmarks and real-world tasks from external partners. When evaluating embeddings OlmoEarth achieves the best performance on 15 out of 24 tasks, and with full fine-tuning it is the best on 19 of 29 tasks. We deploy OlmoEarth as the backbone of an end-to-end platform for data collection, labeling, training, and inference of Earth observation models. The OlmoEarth Platform puts frontier foundation models and powerful data management tools into the hands of non-profits and NGOs working to solve the world's biggest problems. OlmoEarth source code, training data, and pre-trained weights are available at $\href{https://github.com/allenai/olmoearth_pretrain}{\text{https://github.com/allenai/olmoearth_pretrain}}$.

</details>


### [290] [Training-Free Multi-View Extension of IC-Light for Textual Position-Aware Scene Relighting](https://arxiv.org/abs/2511.13684)
*Jiangnan Ye,Jiedong Zhuang,Lianrui Mu,Wenjie Zheng,Jiaqi Hu,Xingze Zou,Jing Wang,Haoji Hu*

Main category: cs.CV

TL;DR: GS-Light是一种基于高斯散射的文本引导3D场景重照明方法，通过多视图扩散模型和几何约束实现高效、无需训练的重照明效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在文本引导的3D场景重照明方面存在多视图一致性差、光照方向控制不准确等问题，需要一种能够精确解析用户光照需求并保持3D一致性的解决方案。

Method: 使用LVLM解析文本提示为光照先验，结合几何和语义估计器生成光照图，通过多视图扩散模型生成重照明图像，最后对3D高斯场景进行微调。

Result: 在室内外场景评估中，GS-Light在定量指标和用户研究中均优于现有基线方法，展现出更好的多视图一致性、图像质量和语义准确性。

Conclusion: GS-Light提供了一种高效且准确的文本引导3D重照明框架，能够很好地满足用户对光照方向、颜色和强度的控制需求。

Abstract: We introduce GS-Light, an efficient, textual position-aware pipeline for text-guided relighting of 3D scenes represented via Gaussian Splatting (3DGS). GS-Light implements a training-free extension of a single-input diffusion model to handle multi-view inputs. Given a user prompt that may specify lighting direction, color, intensity, or reference objects, we employ a large vision-language model (LVLM) to parse the prompt into lighting priors. Using off-the-shelf estimators for geometry and semantics (depth, surface normals, and semantic segmentation), we fuse these lighting priors with view-geometry constraints to compute illumination maps and generate initial latent codes for each view. These meticulously derived init latents guide the diffusion model to generate relighting outputs that more accurately reflect user expectations, especially in terms of lighting direction. By feeding multi-view rendered images, along with the init latents, into our multi-view relighting model, we produce high-fidelity, artistically relit images. Finally, we fine-tune the 3DGS scene with the relit appearance to obtain a fully relit 3D scene. We evaluate GS-Light on both indoor and outdoor scenes, comparing it to state-of-the-art baselines including per-view relighting, video relighting, and scene editing methods. Using quantitative metrics (multi-view consistency, imaging quality, aesthetic score, semantic similarity, etc.) and qualitative assessment (user studies), GS-Light demonstrates consistent improvements over baselines. Code and assets will be made available upon publication.

</details>


### [291] [TiViBench: Benchmarking Think-in-Video Reasoning for Video Generative Models](https://arxiv.org/abs/2511.13704)
*Harold Haodong Chen,Disen Lan,Wen-Jie Shu,Qingyang Liu,Zihan Wang,Sirui Chen,Wenkai Cheng,Kanghao Chen,Hongfei Zhang,Zixin Zhang,Rongjin Guo,Yu Cheng,Ying-Cong Chen*

Main category: cs.CV

TL;DR: TiViBench是一个专门评估图像到视频生成模型推理能力的层次化基准，包含4个维度24个任务场景。论文还提出了VideoTPO测试时优化策略，通过LLM自分析提升推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型评估主要关注视觉保真度和时间一致性，缺乏对高阶推理能力的系统评估。需要专门基准来评估模型是否具备类似LLM的推理能力。

Method: 提出TiViBench基准，系统评估结构推理、空间模式推理、符号逻辑推理和动作规划四个维度。同时提出VideoTPO策略，利用LLM对生成候选进行自分析来优化推理性能。

Result: 商业模型（如Sora 2、Veo 3.1）展现较强推理潜力，开源模型因训练规模和数据多样性限制潜力未充分发掘。VideoTPO能显著提升推理性能且无需额外训练。

Conclusion: TiViBench和VideoTPO为评估和推进视频生成模型的推理能力奠定了基础，为该新兴领域的未来研究设定了方向。

Abstract: The rapid evolution of video generative models has shifted their focus from producing visually plausible outputs to tackling tasks requiring physical plausibility and logical consistency. However, despite recent breakthroughs such as Veo 3's chain-of-frames reasoning, it remains unclear whether these models can exhibit reasoning capabilities similar to large language models (LLMs). Existing benchmarks predominantly evaluate visual fidelity and temporal coherence, failing to capture higher-order reasoning abilities. To bridge this gap, we propose TiViBench, a hierarchical benchmark specifically designed to evaluate the reasoning capabilities of image-to-video (I2V) generation models. TiViBench systematically assesses reasoning across four dimensions: i) Structural Reasoning & Search, ii) Spatial & Visual Pattern Reasoning, iii) Symbolic & Logical Reasoning, and iv) Action Planning & Task Execution, spanning 24 diverse task scenarios across 3 difficulty levels. Through extensive evaluations, we show that commercial models (e.g., Sora 2, Veo 3.1) demonstrate stronger reasoning potential, while open-source models reveal untapped potential that remains hindered by limited training scale and data diversity. To further unlock this potential, we introduce VideoTPO, a simple yet effective test-time strategy inspired by preference optimization. By performing LLM self-analysis on generated candidates to identify strengths and weaknesses, VideoTPO significantly enhances reasoning performance without requiring additional training, data, or reward models. Together, TiViBench and VideoTPO pave the way for evaluating and advancing reasoning in video generation models, setting a foundation for future research in this emerging field.

</details>


### [292] [Free-Form Scene Editor: Enabling Multi-Round Object Manipulation like in a 3D Engine](https://arxiv.org/abs/2511.13713)
*Xincheng Shuai,Zhenyuan Qin,Henghui Ding,Dacheng Tao*

Main category: cs.CV

TL;DR: FFSE是一个3D感知的自回归框架，用于在真实图像上进行直观、物理一致的对象编辑，通过建模3D变换序列实现多轮编辑并保持场景一致性。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型在语义图像编辑方面取得进展，但缺乏3D感知的对象操作能力，无法实现物理一致的多轮编辑。

Method: 提出FFSE框架，将编辑建模为学习的3D变换序列，支持平移、缩放、旋转等任意操作；构建3DObjectEditor混合数据集进行多轮动态条件训练。

Result: 广泛实验表明FFSE在单轮和多轮3D感知编辑场景中显著优于现有方法。

Conclusion: FFSE通过3D感知的自回归建模实现了物理一致的多轮对象编辑，为真实图像编辑提供了新的解决方案。

Abstract: Recent advances in text-to-image (T2I) diffusion models have significantly improved semantic image editing, yet most methods fall short in performing 3D-aware object manipulation. In this work, we present FFSE, a 3D-aware autoregressive framework designed to enable intuitive, physically-consistent object editing directly on real-world images. Unlike previous approaches that either operate in image space or require slow and error-prone 3D reconstruction, FFSE models editing as a sequence of learned 3D transformations, allowing users to perform arbitrary manipulations, such as translation, scaling, and rotation, while preserving realistic background effects (e.g., shadows, reflections) and maintaining global scene consistency across multiple editing rounds. To support learning of multi-round 3D-aware object manipulation, we introduce 3DObjectEditor, a hybrid dataset constructed from simulated editing sequences across diverse objects and scenes, enabling effective training under multi-round and dynamic conditions. Extensive experiments show that the proposed FFSE significantly outperforms existing methods in both single-round and multi-round 3D-aware editing scenarios.

</details>


### [293] [UnSAMv2: Self-Supervised Learning Enables Segment Anything at Any Granularity](https://arxiv.org/abs/2511.13714)
*Junwei Yu,Trevor Darrell,XuDong Wang*

Main category: cs.CV

TL;DR: UnSAMv2通过引入粒度控制嵌入和自监督学习，实现了无需人工标注的分割粒度连续控制，显著提升了SAM-2模型在多个分割任务上的性能。


<details>
  <summary>Details</summary>
Motivation: SAM系列模型在分割粒度控制方面存在局限，用户需要手动调整提示或选择预生成掩码来获得所需细节级别，这个过程既模糊又耗时，且密集标注成本过高。

Method: 扩展UnSAM的分治策略，发现丰富的掩码-粒度对，引入新颖的粒度控制嵌入实现精确连续的粒度控制，仅使用6K未标注图像和0.02%额外参数。

Result: 在11个基准测试中显著提升性能：NoC₉₀从5.69降至4.75，1-IoU从58.0提升至73.1，AR₁₀₀₀从49.6提升至68.3。

Conclusion: 少量未标注数据结合粒度感知的自监督学习方法可以释放视觉基础模型的潜力，实现任意粒度的分割控制。

Abstract: The Segment Anything Model (SAM) family has become a widely adopted vision foundation model, but its ability to control segmentation granularity remains limited. Users often need to refine results manually - by adding more prompts or selecting from pre-generated masks - to achieve the desired level of detail. This process can be ambiguous, as the same prompt may correspond to several plausible masks, and collecting dense annotations across all granularities is prohibitively expensive, making supervised solutions infeasible. To address this limitation, we introduce UnSAMv2, which enables segment anything at any granularity without human annotations. UnSAMv2 extends the divide-and-conquer strategy of UnSAM by discovering abundant mask-granularity pairs and introducing a novel granularity control embedding that enables precise, continuous control over segmentation scale. Remarkably, with only $6$K unlabeled images and $0.02\%$ additional parameters, UnSAMv2 substantially enhances SAM-2, achieving segment anything at any granularity across interactive, whole-image, and video segmentation tasks. Evaluated on over $11$ benchmarks, UnSAMv2 improves $\text{NoC}_{90}$ (5.69 $\rightarrow$ 4.75), 1-IoU (58.0 $\rightarrow$ 73.1), and $\text{AR}_{1000}$ (49.6 $\rightarrow$ 68.3), showing that small amounts of unlabeled data with a granularity-aware self-supervised learning method can unlock the potential of vision foundation models.

</details>


### [294] [Segment Anything Across Shots: A Method and Benchmark](https://arxiv.org/abs/2511.13715)
*Hengrui Hu,Kaining Ying,Henghui Ding*

Main category: cs.CV

TL;DR: 本文提出了一种用于多镜头半监督视频对象分割（MVOS）的新方法SAAS，通过过渡模拟数据增强策略和跨镜头理解机制，解决了现有方法在镜头切换时的性能下降问题，并发布了新的MVOS基准数据集Cut-VOS。


<details>
  <summary>Details</summary>
Motivation: 现有的视频对象分割方法主要针对单镜头视频，在多镜头场景下由于镜头不连续性而表现不佳，限制了实际应用。缺乏标注的多镜头数据和有效的跨镜头泛化能力是主要挑战。

Method: 提出了过渡模拟数据增强策略（TMA）利用单镜头数据实现跨镜头泛化，以及Segment Anything Across Shots（SAAS）模型，能够有效检测和理解镜头转换。

Result: 在YouMVOS和Cut-VOS数据集上的大量实验表明，SAAS通过有效模拟、理解和分割复杂转换，实现了最先进的性能。

Conclusion: 该方法成功解决了MVOS中的关键挑战，提出的数据增强策略和模型架构为多镜头视频分割提供了有效解决方案，发布的基准数据集将促进该领域的未来发展。

Abstract: This work focuses on multi-shot semi-supervised video object segmentation (MVOS), which aims at segmenting the target object indicated by an initial mask throughout a video with multiple shots. The existing VOS methods mainly focus on single-shot videos and struggle with shot discontinuities, thereby limiting their real-world applicability. We propose a transition mimicking data augmentation strategy (TMA) which enables cross-shot generalization with single-shot data to alleviate the severe annotated multi-shot data sparsity, and the Segment Anything Across Shots (SAAS) model, which can detect and comprehend shot transitions effectively. To support evaluation and future study in MVOS, we introduce Cut-VOS, a new MVOS benchmark with dense mask annotations, diverse object categories, and high-frequency transitions. Extensive experiments on YouMVOS and Cut-VOS demonstrate that the proposed SAAS achieves state-of-the-art performance by effectively mimicking, understanding, and segmenting across complex transitions. The code and datasets are released at https://henghuiding.com/SAAS/.

</details>


### [295] [Back to Basics: Let Denoising Generative Models Denoise](https://arxiv.org/abs/2511.13720)
*Tianhong Li,Kaiming He*

Main category: cs.CV

TL;DR: 论文提出JiT方法，直接预测干净图像而非噪声，基于流形假设让低容量网络在高维空间中有效工作


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型预测噪声而非干净图像，但自然数据位于低维流形而噪声数据不在，直接预测干净数据更符合流形假设

Method: 使用简单的大patch Transformer直接在像素上操作，无需tokenizer、预训练或额外损失，通过预测干净图像实现生成建模

Result: 在ImageNet 256×256和512×分辨率上使用16和32的大patch尺寸取得竞争性结果，而预测高维噪声的方法会失败

Conclusion: JiT方法回归基础，提出了基于Transformer的扩散模型自包含范式，通过映射回流形基础实现有效生成

Abstract: Today's denoising diffusion models do not "denoise" in the classical sense, i.e., they do not directly predict clean images. Rather, the neural networks predict noise or a noised quantity. In this paper, we suggest that predicting clean data and predicting noised quantities are fundamentally different. According to the manifold assumption, natural data should lie on a low-dimensional manifold, whereas noised quantities do not. With this assumption, we advocate for models that directly predict clean data, which allows apparently under-capacity networks to operate effectively in very high-dimensional spaces. We show that simple, large-patch Transformers on pixels can be strong generative models: using no tokenizer, no pre-training, and no extra loss. Our approach is conceptually nothing more than "$\textbf{Just image Transformers}$", or $\textbf{JiT}$, as we call it. We report competitive results using JiT with large patch sizes of 16 and 32 on ImageNet at resolutions of 256 and 512, where predicting high-dimensional noised quantities can fail catastrophically. With our networks mapping back to the basics of the manifold, our research goes back to basics and pursues a self-contained paradigm for Transformer-based diffusion on raw natural data.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [296] [Softmax as a Lagrangian-Legendrian Seam](https://arxiv.org/abs/2511.11573)
*Christopher R. Lee-Jenkins*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This note offers a first bridge from machine learning to modern differential geometry. We show that the logits-to-probabilities step implemented by softmax can be modeled as a geometric interface: two potential-generated, conservative descriptions (from negative entropy and log-sum-exp) meet along a Legendrian "seam" on a contact screen (the probability simplex) inside a simple folded symplectic collar. Bias-shift invariance appears as Reeb flow on the screen, and the Fenchel-Young equality/KL gap provides a computable distance to the seam. We work out the two- and three-class cases to make the picture concrete and outline next steps for ML: compact logit models (projective or spherical), global invariants, and connections to information geometry where on-screen dynamics manifest as replicator flows.

</details>


### [297] [LLM on a Budget: Active Knowledge Distillation for Efficient Classification of Large Text Corpora](https://arxiv.org/abs/2511.11574)
*Viviana Luccioli,Rithika Iyengar,Ryan Panley,Flora Haberkorn,Xiaoyu Ge,Leland Crane,Nitish Sinha,Seung Jung Lee*

Main category: cs.LG

TL;DR: 该论文提出了一种名为M-RARU的新型主动学习算法，通过结合不确定性和随机接受-拒绝机制，显著减少大语言模型知识蒸馏过程中的样本需求和计算成本。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在分类任务中准确率高，但部署成本昂贵。知识蒸馏可以训练更小的学生模型，但蒸馏过程本身需要大量样本标注，成本高昂。

Method: 提出M-RARU算法，采用不确定性和随机接受-拒绝机制相结合的策略，仅选择最具信息量的数据点供LLM教师标注，减少API调用和数据处理时间。

Result: 在五个不同学生模型和多个基准数据集上的实验表明，M-RARU相比随机采样可减少80%的样本需求，显著提高分类准确率，同时降低财务成本和训练时间。

Conclusion: M-RARU是一种高效的主动学习方法，能够以较低成本实现大语言模型知识蒸馏，为大规模部署提供了可行解决方案。

Abstract: Large Language Models (LLMs) are highly accurate in classification tasks, however, substantial computational and financial costs hinder their large-scale deployment in dynamic environments. Knowledge Distillation (KD) where a LLM "teacher" trains a smaller and more efficient "student" model, offers a promising solution to this problem. However, the distillation process itself often remains costly for large datasets, since it requires the teacher to label a vast number of samples while incurring significant token consumption. To alleviate this challenge, in this work we explore the active learning (AL) as a way to create efficient student models at a fraction of the cost while preserving the LLM's performance. In particular, we introduce M-RARU (Multi-class Randomized Accept/Reject Uncertainty Sampling), a novel AL algorithm that significantly reduces training costs. M-RARU employs an innovative strategy combining uncertainty with a randomized accept-reject mechanism to select only the most informative data points for the LLM teacher. This focused approach significantly minimizes required API calls and data processing time. We evaluate M-RARU against random sampling across five diverse student models (SVM, LDA, RF, GBDT, and DistilBERT) on multiple benchmark datasets. Experiments demonstrate that our proposed method achieves up to 80% reduction in sample requirements as compared to random sampling, substantially improving classification accuracy while reducing financial costs and overall training time.

</details>


### [298] [Detecting Statistically Significant Fairness Violations in Recidivism Forecasting Algorithms](https://arxiv.org/abs/2511.11575)
*Animesh Joshi*

Main category: cs.LG

TL;DR: 本文提出了一个基于k折交叉验证的统计显著性测试框架，用于评估算法公平性指标的统计显著性，并应用于累犯预测算法的公平性分析。


<details>
  <summary>Details</summary>
Motivation: 现有文献缺乏评估算法公平性差异是否具有统计显著性的方法，而不仅仅是偶然差异。

Method: 利用k折交叉验证生成公平性指标的抽样分布，开发基于预测与实际结果差异、模型校准和因果推断技术的统计显著性测试。

Result: 累犯预测算法在多个公平性定义下对黑人个体表现出统计显著的偏见，而在其他定义下则无偏见或对白人个体有偏见。

Conclusion: 评估算法决策系统时需要进行严格和稳健的统计测试。

Abstract: Machine learning algorithms are increasingly deployed in critical domains such as finance, healthcare, and criminal justice [1]. The increasing popularity of algorithmic decision-making has stimulated interest in algorithmic fairness within the academic community. Researchers have introduced various fairness definitions that quantify disparities between privileged and protected groups, use causal inference to determine the impact of race on model predictions, and that test calibration of probability predictions from the model. Existing literature does not provide a way in which to assess whether observed disparities between groups are statistically significant or merely due to chance. This paper introduces a rigorous framework for testing the statistical significance of fairness violations by leveraging k-fold cross-validation [2] to generate sampling distributions of fairness metrics. This paper introduces statistical tests that can be used to identify statistically significant violations of fairness metrics based on disparities between predicted and actual outcomes, model calibration, and causal inference techniques [1]. We demonstrate this approach by testing recidivism forecasting algorithms trained on data from the National Institute of Justice. Our findings reveal that machine learning algorithms used for recidivism forecasting exhibit statistically significant bias against Black individuals under several fairness definitions, while also exhibiting no bias or bias against White individuals under other definitions. The results from this paper underscore the importance of rigorous and robust statistical testing while evaluating algorithmic decision-making systems.

</details>


### [299] [DAOpt: Modeling and Evaluation of Data-Driven Optimization under Uncertainty with LLMs](https://arxiv.org/abs/2511.11576)
*WenZhuo Zhu,Zheng Cui,Wenhan Lu,Sheng Liu,Yue Zhao*

Main category: cs.LG

TL;DR: 提出了DAOpt框架，包括新数据集OptU、多智能体决策模块和仿真环境，用于评估LLM在不确定优化中的表现，并通过小样本学习增强LLM的建模能力。


<details>
  <summary>Details</summary>
Motivation: 现实决策具有不确定性，但现有研究主要关注确定性优化，LLM在不确定环境下的应用尚未充分探索。

Method: DAOpt框架包含三个核心组件：新数据集OptU、多智能体决策模块和仿真评估环境，结合随机优化和鲁棒优化的领域知识进行小样本学习。

Result: 开发了专门针对不确定优化的评估框架，能够评估LLM的样本外可行性和鲁棒性。

Conclusion: 该研究填补了LLM在不确定优化建模领域的空白，为实际决策应用提供了重要工具和方法。

Abstract: Recent advances in large language models (LLMs) have accelerated research on automated optimization modeling. While real-world decision-making is inherently uncertain, most existing work has focused on deterministic optimization with known parameters, leaving the application of LLMs in uncertain settings largely unexplored. To that end, we propose the DAOpt framework including a new dataset OptU, a multi-agent decision-making module, and a simulation environment for evaluating LLMs with a focus on out-of-sample feasibility and robustness. Additionally, we enhance LLMs' modeling capabilities by incorporating few-shot learning with domain knowledge from stochastic and robust optimization.

</details>


### [300] [Decoupling Positional and Symbolic Attention Behavior in Transformers](https://arxiv.org/abs/2511.11579)
*Felipe Urrutia,Jorge Salas,Alexander Kozachinskiy,Cristian Buc Calderon,Hector Pasten,Cristobal Rojas*

Main category: cs.LG

TL;DR: 本文深入分析了RoPE位置编码在Transformer中的工作机制，证明了注意力头存在位置编码和符号编码两种互斥行为，并开发了量化指标来验证频率使用与模型性能的因果关系。


<details>
  <summary>Details</summary>
Motivation: 研究RoPE位置编码成功的原因，探索注意力头在位置信息与符号信息编码方面的行为差异，理解频率使用如何影响Transformer模型的表现。

Method: 从理论和实证层面分析注意力头的行为，定义位置编码和符号编码的量化指标，设计纯位置和纯符号的规范任务，通过控制频率访问来验证因果关系。

Result: 发现所有注意力头的行为与频率使用存在强相关性，通过控制频率访问可以因果性地控制Transformer模型在特定任务上的性能表现。

Conclusion: 研究提供了对RoPE位置编码的深入理解，揭示了频率使用与模型行为之间的内在联系，为位置编码机制的设计提供了理论指导。

Abstract: An important aspect subtending language understanding and production is the ability to independently encode positional and symbolic information of the words within a sentence. In Transformers, positional information is typically encoded using Positional Encodings (PEs). One such popular PE, namely Rotary PE (RoPE), has been widely used due to its empirical success. Recently, it has been argued that part of RoPE's success emerges from its ability to encode robust positional and semantic information using large and small frequencies, respectively. In this work, we perform a deeper dive into the positional versus symbolic dichotomy of attention heads behavior, both at the theoretical and empirical level. We provide general definitions of what it means for a head to behave positionally or symbolically, prove that these are two mutually exclusive behaviors and develop a metric to quantify them. We apply our framework to analyze Transformer-based LLMs using RoPE and find that all heads exhibit a strong correspondence between behavior and frequency use. Finally, we introduce canonical tasks designed to be either purely positional or symbolic, and demonstrate that the Transformer performance causally relates to the ability of attention heads to leverage the appropriate frequencies. In particular, we show that we can control the Transformer performance by controlling which frequencies the attention heads can access. Altogether, our work provides a detailed understanding of RoPE, and how its properties relate to model behavior.

</details>


### [301] [The Anatomy of a Triton Attention Kernel](https://arxiv.org/abs/2511.11581)
*Burkhard Ringlein,Jan van Lunteren,Radu Stoica,Thomas Parnell*

Main category: cs.LG

TL;DR: 开发了一个基于Triton DSL的跨平台LLM推理平台，通过paged attention kernel和自动调优技术，在NVIDIA和AMD GPU上实现高效推理，性能达到业界领先水平的105.9%。


<details>
  <summary>Details</summary>
Motivation: 解决LLM推理平台在不同硬件架构间的可移植性问题，消除对低层级手动调优的依赖，同时保持最佳效率。

Method: 使用Triton领域特定语言开发paged attention kernel，结合算法和系统级改进，采用参数自动调优技术，集成到流行推理服务器中。

Result: 将通用Triton attention kernel的性能从业界领先水平的19.7%提升到105.9%，在NVIDIA和AMD GPU上都实现了最优性能。

Conclusion: 开源领域特定语言可以成功实现模型在不同GPU厂商间的可移植性，证明了跨平台高效LLM推理的可行性。

Abstract: A long-standing goal in both industry and academia is to develop an LLM inference platform that is portable across hardware architectures, eliminates the need for low-level hand-tuning, and still delivers best-in-class efficiency. In this work, we demonstrate that portable, efficient cross-platform LLM inference is indeed possible and share our experience. We develop a state-of-the-art paged attention kernel, the core performance-critical component of many LLM deployments, that builds exclusively on the domain-specific just-in-time compiled language Triton to achieve state-of-the-art performance on both NVIDIA and AMD GPUs. We describe our high-level approach, the key algorithmic and system-level improvements, the parameter auto-tuning required to unlock efficiency, and the integrations into a popular inference server that are necessary to bring the performance of a generic Triton attention kernel from 19.7% of the state-of-the-art to 105.9%. Our results highlight how open-source domain-specific languages can be leveraged to unlock model portability across different GPU vendors.

</details>


### [302] [Parallel and Multi-Stage Knowledge Graph Retrieval for Behaviorally Aligned Financial Asset Recommendations](https://arxiv.org/abs/2511.11583)
*Fernando Spadea,Oshani Seneviratne*

Main category: cs.LG

TL;DR: RAG-FLARKO是一个基于检索增强的金融推荐系统，通过多阶段并行知识图谱检索来提升推荐质量和效率。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在金融推荐中的上下文限制、幻觉问题和缺乏行为基础等挑战，提高推荐的可扩展性和相关性。

Method: 采用多阶段并行知识图谱检索：首先从用户交易知识图谱中检索行为相关实体，然后基于此上下文从市场知识图谱中过滤时间一致信号，构建紧凑的接地子图供LLM使用。

Result: 在真实金融交易数据集上的实证评估显示，RAG-FLARKO显著提升了推荐质量，使更小、更高效的模型在盈利性和行为对齐方面实现高性能。

Conclusion: 该框架为在资源受限环境中部署接地金融AI提供了可行路径，通过减少上下文开销和聚焦相关信息来增强模型性能。

Abstract: Large language models (LLMs) show promise for personalized financial recommendations but are hampered by context limits, hallucinations, and a lack of behavioral grounding. Our prior work, FLARKO, embedded structured knowledge graphs (KGs) in LLM prompts to align advice with user behavior and market data. This paper introduces RAG-FLARKO, a retrieval-augmented extension to FLARKO, that overcomes scalability and relevance challenges using multi-stage and parallel KG retrieval processes. Our method first retrieves behaviorally relevant entities from a user's transaction KG and then uses this context to filter temporally consistent signals from a market KG, constructing a compact, grounded subgraph for the LLM. This pipeline reduces context overhead and sharpens the model's focus on relevant information. Empirical evaluation on a real-world financial transaction dataset demonstrates that RAG-FLARKO significantly enhances recommendation quality. Notably, our framework enables smaller, more efficient models to achieve high performance in both profitability and behavioral alignment, presenting a viable path for deploying grounded financial AI in resource-constrained environments.

</details>


### [303] [Output Supervision Can Obfuscate the Chain of Thought](https://arxiv.org/abs/2511.11584)
*Jacob Drori,Luke Marks,Bryce Woodworth,Alex Cloud,Alexander Matt Turner*

Main category: cs.LG

TL;DR: 本文研究发现，即使只针对输出监控器进行训练（不访问思维链），仍会导致隐蔽的思维链问题。作者提出了两种缓解机制，在可监控性和任务性能方面实现了帕累托改进。


<details>
  <summary>Details</summary>
Motivation: OpenAI (2025) 的研究表明，针对思维链监控器的训练可能导致隐蔽的思维链问题。本文旨在探索即使只使用输出监控器进行训练，是否仍会出现类似的隐蔽性问题。

Method: 本文识别了两种导致隐蔽思维链的机制：1）模型在训练产生安全输出时可能泛化到让思维链看起来安全；2）由于后续token依赖于前期token，安全外观的思维链会增加安全输出的可能性。针对这两个问题，作者提出了两种相应的缓解措施。

Result: 实验结果表明，提出的两种缓解机制相比常规训练，在可监控性和任务性能方面实现了帕累托改进，即在不牺牲性能的前提下提高了模型的可监控性。

Conclusion: 即使只针对输出监控器进行训练，仍可能产生隐蔽的思维链问题。通过本文提出的两种缓解机制，可以有效提高模型的可监控性，同时保持良好的任务性能。

Abstract: OpenAI (2025) showed that training against a chain of thought (CoT) monitor can cause obfuscated CoTs, which contain bad behavior the monitor cannot detect. They proposed to keep CoTs monitorable by training only against output monitors that do not have access to CoT. We show that such training can still cause obfuscated CoTs via two mechanisms. First, when a model is trained to produce a safe-looking output, that model may generalize to making its CoTs look safe. Second, since later tokens are conditioned on earlier ones, safe-looking CoTs may increase the likelihood of safe outputs, causing safe-looking CoTs to be reinforced. We introduce two mitigations to address these two issues, which achieve a Pareto improvement in terms of monitorability and task performance compared to regular training.

</details>


### [304] [Parameter-Efficient and Personalized Federated Training of Generative Models at the Edge](https://arxiv.org/abs/2511.11585)
*Kabir Khan,Manju Sarkar,Anita Kar,Suresh Ghosh*

Main category: cs.LG

TL;DR: FedGen-Edge框架通过解耦预训练全局主干和轻量级客户端适配器，使用LoRA技术实现联邦生成模型的高效训练，在保持隐私的同时大幅降低通信开销。


<details>
  <summary>Details</summary>
Motivation: 解决大型生成模型在跨设备联邦学习中面临的高计算/通信开销和异构性问题，使生成AI能在边缘设备上实现隐私保护、资源感知和个性化。

Method: 将预训练全局主干冻结，仅联邦化轻量级LoRA适配器，限制客户端更新到紧凑子空间，减少99%以上上行流量，支持个性化本地适配器。

Result: 在语言建模(PTB)和图像生成(CIFAR-10)任务上，相比强基线实现了更低的困惑度/FID和更快收敛，同时保持简单的FedAvg风格服务器。

Conclusion: FedGen-Edge为异构边缘设备上的隐私保护、资源感知和个性化生成AI提供了实用路径。

Abstract: Large generative models (for example, language and diffusion models) enable high-quality text and image synthesis but are hard to train or adapt in cross-device federated settings due to heavy computation and communication and statistical/system heterogeneity. We propose FedGen-Edge, a framework that decouples a frozen, pre-trained global backbone from lightweight client-side adapters and federates only the adapters. Using Low-Rank Adaptation (LoRA) constrains client updates to a compact subspace, which reduces uplink traffic by more than 99 percent versus full-model FedAvg, stabilizes aggregation under non-IID data, and naturally supports personalization because each client can keep a locally tuned adapter. On language modeling (PTB) and image generation (CIFAR-10), FedGen-Edge achieves lower perplexity/FID and faster convergence than strong baselines while retaining a simple FedAvg-style server. A brief ablation shows diminishing returns beyond moderate LoRA rank and a trade-off between local epochs and client drift. FedGen-Edge offers a practical path toward privacy-preserving, resource-aware, and personalized generative AI on heterogeneous edge devices.

</details>


### [305] [WildfireGenome: Interpretable Machine Learning Reveals Local Drivers of Wildfire Risk and Their Cross-County Variation](https://arxiv.org/abs/2511.11589)
*Chenyue Liu,Ali Mostafavi*

Main category: cs.LG

TL;DR: WildfireGenome提出了一种可解释的野火风险评估方法，通过融合多源指标、机器学习分类和可解释性分析，为地方决策提供支持。


<details>
  <summary>Details</summary>
Motivation: 当前野火风险评估依赖粗糙的地图和黑盒机器学习模型，缺乏在决策尺度上的可解释性，无法有效指导地方管理。

Method: 方法包括三个部分：(1)融合7个联邦野火指标，通过PCA生成H3 Level-8分辨率的复合风险标签；(2)使用随机森林进行局部野火风险分类；(3)采用SHAP和ICE/PDP分析揭示县域特定的非线性驱动关系。

Result: 在7个生态多样化的美国县，模型准确率达到0.755-0.878，二次加权Kappa最高达0.951，主成分解释了87-94%的指标方差。迁移测试显示在生态相似区域表现可靠，但在不同生态背景下性能下降。

Conclusion: WildfireGenome将野火风险评估从区域预测推进到可解释的决策尺度分析，能够指导植被管理、分区规划和基础设施建设。

Abstract: Current wildfire risk assessments rely on coarse hazard maps and opaque machine learning models that optimize regional accuracy while sacrificing interpretability at the decision scale. WildfireGenome addresses these gaps through three components: (1) fusion of seven federal wildfire indicators into a sign-aligned, PCA-based composite risk label at H3 Level-8 resolution; (2) Random Forest classification of local wildfire risk; and (3) SHAP and ICE/PDP analyses to expose county-specific nonlinear driver relationships. Across seven ecologically diverse U.S. counties, models achieve accuracies of 0.755-0.878 and Quadratic Weighted Kappa up to 0.951, with principal components explaining 87-94% of indicator variance. Transfer tests show reliable performance between ecologically similar regions but collapse across dissimilar contexts. Explanations consistently highlight needleleaf forest cover and elevation as dominant drivers, with risk rising sharply at 30-40% needleleaf coverage. WildfireGenome advances wildfire risk assessment from regional prediction to interpretable, decision-scale analytics that guide vegetation management, zoning, and infrastructure planning.

</details>


### [306] [Mind Your Entropy: From Maximum Entropy to Trajectory Entropy-Constrained RL](https://arxiv.org/abs/2511.11592)
*Guojian Zhan,Likun Wang,Pengcheng Wang,Feihong Zhang,Jingliang Duan,Masayoshi Tomizuka,Shengbo Eben Li*

Main category: cs.LG

TL;DR: 本文提出了一种轨迹熵约束强化学习框架（TECRL），通过分离奖励和熵的Q函数学习来解决最大熵RL中的非平稳Q值估计和短视局部熵调节问题，并开发了DSAC-E算法在OpenAI Gym基准测试中取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 传统最大熵RL框架存在两个瓶颈：1）温度参数更新与熵注入联合导致Q值估计非平稳；2）局部熵调节只考虑当前单步熵而忽略累积熵的长期影响。

Method: 提出TECRL框架：1）分别学习奖励Q函数和熵Q函数，确保值目标稳定；2）通过专门的熵Q函数量化期望累积熵，实施轨迹熵约束来控制策略的长期随机性。基于此开发DSAC-E算法，扩展了分布软演员-评论器方法。

Result: 在OpenAI Gym基准测试中，DSAC-E算法实现了更高的回报和更好的稳定性。

Conclusion: TECRL框架通过分离Q函数学习和轨迹熵约束，有效解决了最大熵RL的稳定性问题，DSAC-E算法在实验中表现出优越性能。

Abstract: Maximum entropy has become a mainstream off-policy reinforcement learning (RL) framework for balancing exploitation and exploration. However, two bottlenecks still limit further performance improvement: (1) non-stationary Q-value estimation caused by jointly injecting entropy and updating its weighting parameter, i.e., temperature; and (2) short-sighted local entropy tuning that adjusts temperature only according to the current single-step entropy, without considering the effect of cumulative entropy over time. In this paper, we extends maximum entropy framework by proposing a trajectory entropy-constrained reinforcement learning (TECRL) framework to address these two challenges. Within this framework, we first separately learn two Q-functions, one associated with reward and the other with entropy, ensuring clean and stable value targets unaffected by temperature updates. Then, the dedicated entropy Q-function, explicitly quantifying the expected cumulative entropy, enables us to enforce a trajectory entropy constraint and consequently control the policy long-term stochasticity. Building on this TECRL framework, we develop a practical off-policy algorithm, DSAC-E, by extending the state-of-the-art distributional soft actor-critic with three refinements (DSAC-T). Empirical results on the OpenAI Gym benchmark demonstrate that our DSAC-E can achieve higher returns and better stability.

</details>


### [307] [Sound Logical Explanations for Mean Aggregation Graph Neural Networks](https://arxiv.org/abs/2511.11593)
*Matthew Morris,Ian Horrocks*

Main category: cs.LG

TL;DR: 该论文研究了使用均值聚合函数且具有非负权重的图神经网络（MAGNNs），证明了它们能够表达的一类单调逻辑规则，并提供了一个受限的一阶逻辑片段来解释MAGNN的预测。


<details>
  <summary>Details</summary>
Motivation: 尽管使用均值聚合的GNN在知识图谱补全中很常见，但缺乏对其可解释性和表达能力的理论研究。本文旨在填补这一空白，特别是针对具有非负权重的均值聚合GNN。

Method: 通过理论分析证明MAGNNs能够表达的单调规则类别，并构建一个受限的一阶逻辑片段来为MAGNN预测提供解释。在标准归纳基准测试上进行实验验证。

Result: 实验表明，限制均值聚合GNN具有非负权重可以在标准基准测试上获得相当或更好的性能，实践中能够获得合理的规则，可以生成有洞察力的解释，并且这些规则可以暴露训练模型中的问题。

Conclusion: MAGNNs不仅在实践中表现良好，而且具有理论上的可解释性基础，能够提供有意义的规则解释并帮助识别模型缺陷。

Abstract: Graph neural networks (GNNs) are frequently used for knowledge graph completion. Their black-box nature has motivated work that uses sound logical rules to explain predictions and characterise their expressivity. However, despite the prevalence of GNNs that use mean as an aggregation function, explainability and expressivity results are lacking for them. We consider GNNs with mean aggregation and non-negative weights (MAGNNs), proving the precise class of monotonic rules that can be sound for them, as well as providing a restricted fragment of first-order logic to explain any MAGNN prediction. Our experiments show that restricting mean-aggregation GNNs to have non-negative weights yields comparable or improved performance on standard inductive benchmarks, that sound rules are obtained in practice, that insightful explanations can be generated in practice, and that the sound rules can expose issues in the trained models.

</details>


### [308] [Loss Given Default Prediction Under Measurement-Induced Mixture Distributions: An Information-Theoretic Approach](https://arxiv.org/abs/2511.11596)
*Javier Marín*

Main category: cs.LG

TL;DR: 论文研究发现，在违约损失率（LGD）建模中，90%的训练数据是基于破产前资产负债表估计的代理数据，而非实际破产结果。这种数据污染导致随机森林等方法表现不佳，而基于信息论的方法表现更好。


<details>
  <summary>Details</summary>
Motivation: 解决LGD建模中因缺乏真实破产结果数据而导致的数据质量问题，为金融机构在Basel III要求下部署LGD模型提供实用指导。

Method: 使用信息论方法（香农熵和互信息）分析1,218起公司破产案例（1980-2023年），比较了递归分割方法（如随机森林）与信息论方法的性能。

Result: 随机森林的r平方为-0.664，而信息论方法的r平方达到0.191，RMSE为0.284。分析发现杠杆特征包含1.510比特互信息，规模效应仅贡献0.086比特。

Conclusion: 信息论方法在数据质量受限的LGD建模中表现优越，研究结果可推广到医疗结果研究、气候预测和技术可靠性等领域。

Abstract: Loss Given Default (LGD) modeling faces a fundamental data quality constraint: 90% of available training data consists of proxy estimates based on pre-distress balance sheets rather than actual recovery outcomes from completed bankruptcy proceedings. We demonstrate that this mixture-contaminated training structure causes systematic failure of recursive partitioning methods, with Random Forest achieving negative r-squared (-0.664, worse than predicting the mean) on held-out test data. Information-theoretic approaches based on Shannon entropy and mutual information provide superior generalization, achieving r-squared of 0.191 and RMSE of 0.284 on 1,218 corporate bankruptcies (1980-2023). Analysis reveals that leverage-based features contain 1.510 bits of mutual information while size effects contribute only 0.086 bits, contradicting regulatory assumptions about scale-dependent recovery. These results establish practical guidance for financial institutions deploying LGD models under Basel III requirements when representative outcome data is unavailable at sufficient scale. The findings generalize to medical outcomes research, climate forecasting, and technology reliability-domains where extended observation periods create unavoidable mixture structure in training data.

</details>


### [309] [Aspiration-based Perturbed Learning Automata in Games with Noisy Utility Measurements. Part A: Stochastic Stability in Non-zero-Sum Games](https://arxiv.org/abs/2511.11602)
*Georgios C. Chasparis*

Main category: cs.LG

TL;DR: 本文提出了一种基于期望的扰动学习自动机（APLA）方案，用于解决分布式优化中传统强化学习在多玩家弱无环博弈中无法保证收敛到纯纳什均衡的问题。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习在分布式设置中存在局限性，特别是在多玩家弱无环博弈中，当每个玩家独立应用学习动态时，无法保证收敛到期望的纯纳什均衡。现有研究仅关注潜在博弈和协调博弈等小类游戏。

Method: 提出APLA学习方案，其中每个玩家的动作选择概率分布不仅通过重复选择来强化，还通过捕捉玩家满意度的期望因子来强化。在存在噪声观测的情况下，对多玩家正效用博弈进行了随机稳定性分析。

Result: 首次在通用非零和博弈中通过将无限维马尔可夫链等价于有限维链来表征随机稳定性，并在弱无环博弈中进一步专门化随机稳定性分析。

Conclusion: APLA方案能够有效解决传统强化学习在分布式优化中的收敛问题，为多玩家博弈提供了新的学习框架。

Abstract: Reinforcement-based learning has attracted considerable attention both in modeling human behavior as well as in engineering, for designing measurement- or payoff-based optimization schemes. Such learning schemes exhibit several advantages, especially in relation to filtering out noisy observations. However, they may exhibit several limitations when applied in a distributed setup. In multi-player weakly-acyclic games, and when each player applies an independent copy of the learning dynamics, convergence to (usually desirable) pure Nash equilibria cannot be guaranteed. Prior work has only focused on a small class of games, namely potential and coordination games. To address this main limitation, this paper introduces a novel payoff-based learning scheme for distributed optimization, namely aspiration-based perturbed learning automata (APLA). In this class of dynamics, and contrary to standard reinforcement-based learning schemes, each player's probability distribution for selecting actions is reinforced both by repeated selection and an aspiration factor that captures the player's satisfaction level. We provide a stochastic stability analysis of APLA in multi-player positive-utility games under the presence of noisy observations. This is the first part of the paper that characterizes stochastic stability in generic non-zero-sum games by establishing equivalence of the induced infinite-dimensional Markov chain with a finite dimensional one. In the second part, stochastic stability is further specialized to weakly acyclic games.

</details>


### [310] [Enhancing failure prediction in nuclear industry: Hybridization of knowledge- and data-driven techniques](https://arxiv.org/abs/2511.11604)
*Amaratou Mahamadou Saley,Thierry Moyaux,Aïcha Sekhari,Vincent Cheutet,Jean-Baptiste Danielou*

Main category: cs.LG

TL;DR: 本文提出了一种结合数据驱动技术和核工业领域知识的混合预测性维护方法，相比纯数据驱动方法显著提高了故障预测性能。


<details>
  <summary>Details</summary>
Motivation: 物联网和工业4.0的融合增强了核工业的数据驱动方法，但核能系统的复杂性要求深厚的领域知识。纯数据驱动方法在预测维护需求方面存在局限性，需要结合专业知识来提高预测模型的性能。

Method: 提出了一种新颖的预测性维护方法，将数据驱动技术与核设备领域知识相结合。该方法在两个层面具有创新性：强调纯数据驱动方法的局限性，并展示知识在提升预测模型性能中的重要性。

Result: 通过详细的实际案例研究比较，混合方法显著优于纯数据驱动方法。纯数据驱动方法预测范围仅为3小时，F1分数为56.36%；而混合方法将预测范围扩展到24小时，F1分数达到93.12%。

Conclusion: 在核工业这种高度受限且敏感的领域，结合领域知识的混合方法能够显著提高预测性维护的效果，为核能行业的安全性和经济性提供重要支持。

Abstract: The convergence of the Internet of Things (IoT) and Industry 4.0 has significantly enhanced data-driven methodologies within the nuclear industry, notably enhancing safety and economic efficiency. This advancement challenges the precise prediction of future maintenance needs for assets, which is crucial for reducing downtime and operational costs. However, the effectiveness of data-driven methodologies in the nuclear sector requires extensive domain knowledge due to the complexity of the systems involved. Thus, this paper proposes a novel predictive maintenance methodology that combines data-driven techniques with domain knowledge from a nuclear equipment. The methodological originality of this paper is located on two levels: highlighting the limitations of purely data-driven approaches and demonstrating the importance of knowledge in enhancing the performance of the predictive models. The applicative novelty of this work lies in its use within a domain such as a nuclear industry, which is highly restricted and ultrasensitive due to security, economic and environmental concerns. A detailed real-world case study which compares the current state of equipment monitoring with two scenarios, demonstrate that the methodology significantly outperforms purely data-driven methods in failure prediction. While purely data-driven methods achieve only a modest performance with a prediction horizon limited to 3 h and a F1 score of 56.36%, the hybrid approach increases the prediction horizon to 24 h and achieves a higher F1 score of 93.12%.

</details>


### [311] [Clustering-Based Weight Orthogonalization for Stabilizing Deep Reinforcement Learning](https://arxiv.org/abs/2511.11607)
*Guoqing Ma,Yuhan Zhang,Yuming Dai,Guangfu Hao,Yang Chen,Shan Yu*

Main category: cs.LG

TL;DR: 提出COWM层来解决RL中环境非平稳性问题，提高样本效率和学习速度


<details>
  <summary>Details</summary>
Motivation: RL算法通常假设环境平稳，但实际环境往往非平稳，导致需要大量迭代和样本效率低下

Method: 在策略网络中集成COWM层，通过聚类技术和投影矩阵来稳定学习过程，减少梯度干扰

Result: 在DMControl基准测试中，视觉和状态任务分别提升9%和12.6%，在多种算法和任务中表现出鲁棒性和通用性

Conclusion: COWM层能有效缓解环境非平稳性问题，显著提高RL算法的学习效率和性能

Abstract: Reinforcement learning (RL) has made significant advancements, achieving superhuman performance in various tasks. However, RL agents often operate under the assumption of environmental stationarity, which poses a great challenge to learning efficiency since many environments are inherently non-stationary. This non-stationarity results in the requirement of millions of iterations, leading to low sample efficiency. To address this issue, we introduce the Clustering Orthogonal Weight Modified (COWM) layer, which can be integrated into the policy network of any RL algorithm and mitigate non-stationarity effectively. The COWM layer stabilizes the learning process by employing clustering techniques and a projection matrix. Our approach not only improves learning speed but also reduces gradient interference, thereby enhancing the overall learning efficiency. Empirically, the COWM outperforms state-of-the-art methods and achieves improvements of 9% and 12.6% in vision based and state-based DMControl benchmark. It also shows robustness and generality across various algorithms and tasks.

</details>


### [312] [Small Vocabularies, Big Gains: Pretraining and Tokenization in Time Series Models](https://arxiv.org/abs/2511.11622)
*Alexis Roger,Gwen Legate,Kashif Rasul,Yuriy Nevmyvaka,Irina Rish*

Main category: cs.LG

TL;DR: 该论文系统研究了时间序列基础模型中分词器设计（特别是缩放和量化策略）以及预训练与随机初始化对模型性能的影响，发现分词器配置主导模型表示能力，而迁移学习影响优化效率。


<details>
  <summary>Details</summary>
Motivation: 研究分词器设计和迁移学习在时间序列基础模型构建中的关键作用，为连续信号的离散表示学习提供具体指导。

Method: 结合实证训练实验和理论分析，系统研究分词器缩放、量化策略以及预训练与随机初始化的对比。

Result: 预训练模型能更有效地利用设计良好的分词器，特别是在较小词汇量时；而错位的分词会削弱甚至逆转预训练的优势。

Conclusion: 在时间序列建模中，精心设计的分词器至关重要，在多模态预测场景下，将小型高效词汇表与预训练权重结合尤为有利。

Abstract: Tokenization and transfer learning are two critical components in building state of the art time series foundation models for forecasting. In this work, we systematically study the effect of tokenizer design, specifically scaling and quantization strategies, on model performance, alongside the impact of pretraining versus random initialization. We show that tokenizer configuration primarily governs the representational capacity and stability of the model, while transfer learning influences optimization efficiency and alignment. Using a combination of empirical training experiments and theoretical analyses, we demonstrate that pretrained models consistently leverage well-designed tokenizers more effectively, particularly at smaller vocabulary sizes. Conversely, misaligned tokenization can diminish or even invert the benefits of pretraining. These findings highlight the importance of careful tokenization in time series modeling and suggest that combining small, efficient vocabularies with pretrained weights is especially advantageous in multi-modal forecasting settings, where the overall vocabulary must be shared across modalities. Our results provide concrete guidance for designing tokenizers and leveraging transfer learning in discrete representation learning for continuous signals.

</details>


### [313] [Early GVHD Prediction in Liver Transplantation via Multi-Modal Deep Learning on Imbalanced EHR Data](https://arxiv.org/abs/2511.11623)
*Yushan Jiang,Shuteng Niu,Dongjin Song,Yichen Wang,Jingna Feng,Xinyue Hu,Liu Yang,Cui Tao*

Main category: cs.LG

TL;DR: 本文提出了一种多模态深度学习框架，用于早期预测肝移植后的移植物抗宿主病（GVHD），通过整合异构和不平衡的电子健康记录数据，实现了优于传统方法的预测性能。


<details>
  <summary>Details</summary>
Motivation: GVHD是肝移植后罕见但致命并发症，死亡率极高。现有方法难以处理电子健康记录中的异构性和极端类别不平衡问题，需要开发更有效的早期预测方法。

Method: 开发多模态深度学习框架，动态融合患者人口统计学、实验室检查、诊断和药物四种主要模态数据，处理不规则记录和缺失值，通过AUC优化解决极端类别不平衡问题。

Result: 该框架在2100例肝移植患者数据（包括42例GVHD）上表现优异，AUC达到0.836，AUPRC为0.157，召回率为0.768，特异性为0.803，优于所有单模态和多模态基线方法。

Conclusion: 多模态深度学习框架显著改进了GVHD早期预测方法，有效解决了真实世界电子健康记录中的异构性和极端类别不平衡挑战，为及时干预和改善患者预后提供了有力工具。

Abstract: Graft-versus-host disease (GVHD) is a rare but often fatal complication in liver transplantation, with a very high mortality rate. By harnessing multi-modal deep learning methods to integrate heterogeneous and imbalanced electronic health records (EHR), we aim to advance early prediction of GVHD, paving the way for timely intervention and improved patient outcomes. In this study, we analyzed pre-transplant electronic health records (EHR) spanning the period before surgery for 2,100 liver transplantation patients, including 42 cases of graft-versus-host disease (GVHD), from a cohort treated at Mayo Clinic between 1992 and 2025. The dataset comprised four major modalities: patient demographics, laboratory tests, diagnoses, and medications. We developed a multi-modal deep learning framework that dynamically fuses these modalities, handles irregular records with missing values, and addresses extreme class imbalance through AUC-based optimization. The developed framework outperforms all single-modal and multi-modal machine learning baselines, achieving an AUC of 0.836, an AUPRC of 0.157, a recall of 0.768, and a specificity of 0.803. It also demonstrates the effectiveness of our approach in capturing complementary information from different modalities, leading to improved performance. Our multi-modal deep learning framework substantially improves existing approaches for early GVHD prediction. By effectively addressing the challenges of heterogeneity and extreme class imbalance in real-world EHR, it achieves accurate early prediction. Our proposed multi-modal deep learning method demonstrates promising results for early prediction of a GVHD in liver transplantation, despite the challenge of extremely imbalanced EHR data.

</details>


### [314] [MedFedPure: A Medical Federated Framework with MAE-based Detection and Diffusion Purification for Inference-Time Attacks](https://arxiv.org/abs/2511.11625)
*Mohammad Karami,Mohammad Reza Nemati,Aidin Kazemi,Ali Mikaeili Barzili,Hamid Azadegan,Behzad Moshiri*

Main category: cs.LG

TL;DR: MedFedPure是一个针对联邦学习环境下医学影像AI模型的推理阶段防御框架，通过个性化联邦学习、掩码自编码器检测和自适应扩散净化模块，显著提升对抗攻击下的鲁棒性，同时保持高准确率和隐私保护。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在医学影像AI中用于保护患者隐私，但模型在推理时容易受到对抗攻击，现有防御方法难以应对去中心化的医疗环境，需要开发既能保护隐私又能抵御攻击的解决方案。

Method: 结合三个关键组件：(1)个性化联邦学习模型适应各机构数据分布；(2)掩码自编码器检测隐藏扰动；(3)自适应扩散净化模块选择性清理可疑扫描图像。

Result: 在Br35H脑部MRI数据集上测试，对抗攻击下的性能从49.50%提升至87.33%，同时保持97.67%的清洁准确率。

Conclusion: MedFedPure提供了一种实用的方法，可在临床工作流程中部署安全、可信且保护隐私的AI工具，通过本地实时操作确保诊断安全性。

Abstract: Artificial intelligence (AI) has shown great potential in medical imaging, particularly for brain tumor detection using Magnetic Resonance Imaging (MRI). However, the models remain vulnerable at inference time when they are trained collaboratively through Federated Learning (FL), an approach adopted to protect patient privacy. Adversarial attacks can subtly alter medical scans in ways invisible to the human eye yet powerful enough to mislead AI models, potentially causing serious misdiagnoses. Existing defenses often assume centralized data and struggle to cope with the decentralized and diverse nature of federated medical settings. In this work, we present MedFedPure, a personalized federated learning defense framework designed to protect diagnostic AI models at inference time without compromising privacy or accuracy. MedFedPure combines three key elements: (1) a personalized FL model that adapts to the unique data distribution of each institution; (2) a Masked Autoencoder (MAE) that detects suspicious inputs by exposing hidden perturbations; and (3) an adaptive diffusion-based purification module that selectively cleans only the flagged scans before classification. Together, these steps offer robust protection while preserving the integrity of normal, benign images. We evaluated MedFedPure on the Br35H brain MRI dataset. The results show a significant gain in adversarial robustness, improving performance from 49.50% to 87.33% under strong attacks, while maintaining a high clean accuracy of 97.67%. By operating locally and in real time during diagnosis, our framework provides a practical path to deploying secure, trustworthy, and privacy-preserving AI tools in clinical workflows.
  Index Terms: cancer, tumor detection, federated learning, masked autoencoder, diffusion, privacy

</details>


### [315] [SA-EMO: Structure-Aligned Encoder Mixture of Operators for Generalizable Full-waveform Inversion](https://arxiv.org/abs/2511.11627)
*Wang Zhenyu,Li Peiyuan,Shi Yongxiang,Wu Ruoyu,Zhang Lei*

Main category: cs.LG

TL;DR: 本文提出了一种结构对齐编码器-混合算子（SA-EMO）架构，用于解决全波形反演（FWI）在未知地下结构中的速度场反演问题，显著提升了传统方法的性能。


<details>
  <summary>Details</summary>
Motivation: 传统全波形反演方法存在计算量大、非线性强、难以泛化到复杂地质环境的问题。现有的深度学习方法多采用单一CNN架构或单一神经算子，难以区分不同地质类型且在未知地质条件下泛化能力不足。

Method: 提出SA-EMO架构：1）结构对齐编码器将高维地震波场映射到物理一致的潜在空间，消除波形域和速度域的时空不匹配；2）自适应路由机制选择和融合多种神经算子专家（谱算子、小波算子、多尺度算子、局部算子）来预测速度模型。

Result: 在OpenFWI基准测试和Marmousi2数据集上的实验表明，SA-EMO显著优于传统CNN或单一算子方法，平均MAE降低约58.443%，边界分辨率提升约10.308%。消融研究证实结构对齐编码器、专家融合机制和路由模块都对性能提升有重要贡献。

Conclusion: 这项工作为高效、可扩展且物理可解释的全波形反演引入了新范式，通过结构对齐编码和多算子融合机制有效解决了传统方法的局限性。

Abstract: Full-waveform inversion (FWI) can produce high-resolution subsurface models, yet it remains inherently ill-posed, highly nonlinear, and computationally intensive. Although recent deep learning and numerical acceleration methods have improved speed and scalability, they often rely on single CNN architectures or single neural operators, which struggle to generalize in unknown or complex geological settings and are ineffective at distinguishing diverse geological types. To address these issues, we propose a Structure-Aligned Encoder-Mixture-of-Operators (SA-EMO) architecture for velocity-field inversion under unknown subsurface structures. First, a structure-aligned encoder maps high-dimensional seismic wavefields into a physically consistent latent space, thereby eliminating spatio-temporal mismatch between the waveform and velocity domains, recovering high-frequency components, and enhancing feature generalization. Then, an adaptive routing mechanism selects and fuses multiple neural-operator experts, including spectral, wavelet, multiscale, and local operators, to predict the velocity model. We systematically evaluate our approach on the OpenFWI benchmark and the Marmousi2 dataset. Results show that SA-EMO significantly outperforms traditional CNN or single-operator methods, achieving an average MAE reduction of approximately 58.443% and an improvement in boundary resolution of about 10.308%. Ablation studies further reveal that the structure-aligned encoder, the expert-fusion mechanism, and the routing module each contribute markedly to the performance gains. This work introduces a new paradigm for efficient, scalable, and physically interpretable full-waveform inversion.

</details>


### [316] [Global Feature Enhancing and Fusion Framework for Strain Gauge Time Series Classification](https://arxiv.org/abs/2511.11629)
*Xu Zhang,Peng Wang,Chen Wang,Zhe Xu,Xiaohua Nie,Wei Wang*

Main category: cs.LG

TL;DR: 提出基于超图的全局特征学习与融合框架，通过特征工程和学习局部特征间的高阶关系来构建全局特征，以增强应变计状态时间序列的表征能力，提高识别准确率。


<details>
  <summary>Details</summary>
Motivation: 在应变计状态识别中，传统CNN模型仅能提取局部特征，但当不同时间序列的局部子序列相似时（如飞机机翼静态强度实验中的SGS数据），局部特征不足以充分表达时间序列。CNN由于卷积操作的限制难以提取全局特征。

Method: 提出基于超图的全局特征学习与融合框架，包含两个核心思路：(1)通过特征工程构建全局特征；(2)学习局部特征间的高阶关系来捕获全局特征。该框架学习并融合全局特征以实现语义一致性。

Result: 在工业SGS和公开UCR数据集上的验证表明，该方法在SGS识别中具有更好的泛化能力，对未见数据表现出优越性能。

Conclusion: 通过超图框架学习全局特征能有效增强时间序列的表征能力，解决传统CNN模型在相似局部子序列情况下的识别局限性，提升应变计状态识别的准确性。

Abstract: Strain Gauge Status (SGS) recognition is crucial in the field of intelligent manufacturing based on the Internet of Things, as accurate identification helps timely detection of failed mechanical components, avoiding accidents. The loading and unloading sequences generated by strain gauges can be identified through time series classification (TSC) algorithms. Recently, deep learning models, e.g., convolutional neural networks (CNNs) have shown remarkable success in the TSC task, as they can extract discriminative local features from the subsequences to identify the time series. However, we observe that only the local features may not be sufficient for expressing the time series, especially when the local sub-sequences between different time series are very similar, e.g., SGS data of aircraft wings in static strength experiments. Nevertheless, CNNs suffer from the limitation in extracting global features due to the nature of convolution operations. For extracting global features to more comprehensively represent the SGS time series, we propose two insights: (i) Constructing global features through feature engineering. (ii) Learning high-order relationships between local features to capture global features. To realize and utilize them, we propose a hypergraph-based global feature learning and fusion framework, which learns and fuses global features for semantic consistency to enhance the representation of SGS time series, thereby improving recognition accuracy. Our method designs are validated on industrial SGS and public UCR datasets, showing better generalization for unseen data in SGS recognition.

</details>


### [317] [Predicting Grain Growth in Polycrystalline Materials Using Deep Learning Time Series Models](https://arxiv.org/abs/2511.11630)
*Eliane Younes,Elie Hachem,Marc Bernacki*

Main category: cs.LG

TL;DR: 本研究评估了多种深度学习模型（RNN、LSTM、TCN、Transformer）在预测晶粒生长过程中晶粒尺寸分布的预测能力，发现LSTM模型在准确性和稳定性方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 晶粒生长对材料力学行为有重要影响，但传统全场模拟计算成本高。本研究旨在开发基于低维统计描述符的高效预测方法。

Method: 从120个晶粒生长序列中提取归一化晶粒尺寸分布数据，使用递归预测策略训练深度学习模型，比较不同架构的性能。

Result: LSTM模型达到90%以上的准确率，计算时间从20分钟缩短到几秒钟，且能保持物理一致性预测，其他模型在长期预测中容易发散。

Conclusion: 基于低维描述符和LSTM的预测方法为微观结构预测提供了高效准确的解决方案，对数字孪生和工艺优化具有直接应用价值。

Abstract: Grain Growth strongly influences the mechanical behavior of materials, making its prediction a key objective in microstructural engineering. In this study, several deep learning approaches were evaluated, including recurrent neural networks (RNN), long short-term memory (LSTM), temporal convolutional networks (TCN), and transformers, to forecast grain size distributions during grain growth. Unlike full-field simulations, which are computationally demanding, the present work relies on mean-field statistical descriptors extracted from high-fidelity simulations. A dataset of 120 grain growth sequences was processed into normalized grain size distributions as a function of time. The models were trained to predict future distributions from a short temporal history using a recursive forecasting strategy. Among the tested models, the LSTM network achieved the highest accuracy (above 90\%) and the most stable performance, maintaining physically consistent predictions over extended horizons while reducing computation time from about 20 minutes per sequence to only a few seconds, whereas the other architectures tended to diverge when forecasting further in time. These results highlight the potential of low-dimensional descriptors and LSTM-based forecasting for efficient and accurate microstructure prediction, with direct implications for digital twin development and process optimization.

</details>


### [318] [Toward Better Generalization in Few-Shot Learning through the Meta-Component Combination](https://arxiv.org/abs/2511.11632)
*Qiuhao Zeng*

Main category: cs.LG

TL;DR: 该论文提出了一种新的元学习算法，通过学习元组件来构建分类器，以解决小样本学习中基于度量的元学习方法对已见类别过拟合的问题。


<details>
  <summary>Details</summary>
Motivation: 基于度量的元学习方法在小样本学习中表现良好，但严重依赖在已见类别上学习的深度度量，容易过拟合已见类别，导致在未见类别上泛化能力不足。

Method: 提出探索分类器的子结构，将每个分类器学习为元组件的组合。元组件通过元学习episode在已见类别上学习，并施加正交正则化器来促进元组件的多样性和捕获不同分类器之间的共享子结构。

Result: 在小样本基准任务上的大量实验表明，该方法取得了优越的性能。

Conclusion: 通过元组件组合的方式构建分类器，结合正交正则化促进多样性，能够有效提升小样本学习中的泛化能力。

Abstract: In few-shot learning, classifiers are expected to generalize to unseen classes given only a small number of instances of each new class. One of the popular solutions to few-shot learning is metric-based meta-learning. However, it highly depends on the deep metric learned on seen classes, which may overfit to seen classes and fail to generalize well on unseen classes. To improve the generalization, we explore the substructures of classifiers and propose a novel meta-learning algorithm to learn each classifier as a combination of meta-components. Meta-components are learned across meta-learning episodes on seen classes and disentangled by imposing an orthogonal regularizer to promote its diversity and capture various shared substructures among different classifiers. Extensive experiments on few-shot benchmark tasks show superior performances of the proposed method.

</details>


### [319] [An Explainable and Fair AI Tool for PCOS Risk Assessment: Calibration, Subgroup Equity, and Interactive Clinical Deployment](https://arxiv.org/abs/2511.11636)
*Asma Sadia Khan,Sadia Tabassum*

Main category: cs.LG

TL;DR: 该论文提出了一个公平审计和可解释的机器学习框架，用于预测多囊卵巢综合征（PCOS），通过SHAP特征归因和人口统计审计评估模型性能并识别患者亚组间的诊断差异。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够评估模型性能、识别诊断差异并提供可操作见解的PCOS预测框架，确保在不同患者亚组中的预测可靠性。

Method: 集成SHAP特征归因与人口统计审计，结合概率校准指标（Brier Score和ECE），训练随机森林、SVM和XGBoost模型，并使用等渗和Platt缩放进行校准和公平性比较。

Result: 校准后的随机森林模型达到90.8%的预测准确率，SHAP分析显示卵泡计数、体重增加和月经不规律是最具影响力的特征。亚组分析发现模型在25-35岁女性中表现最佳（准确率90.9%），但在25岁以下女性中表现较差（69.2%）。

Conclusion: 随机森林模型在校准和可解释性之间取得了最佳平衡，通过基于Streamlit的Web界面实现了实时PCOS风险评估和临床可用性。

Abstract: This paper presents a fairness-audited and interpretable machine learning framework for predicting polycystic ovary syndrome (PCOS), designed to evaluate model performance and identify diagnostic disparities across patient subgroups. The framework integrated SHAP-based feature attributions with demographic audits to connect predictive explanations with observed disparities for actionable insights. Probabilistic calibration metrics (Brier Score and Expected Calibration Error) are incorporated to ensure reliable risk predictions across subgroups. Random Forest, SVM, and XGBoost models were trained with isotonic and Platt scaling for calibration and fairness comparison. A calibrated Random Forest achieved a high predictive accuracy of 90.8%. SHAP analysis identified follicle count, weight gain, and menstrual irregularity as the most influential features, which are consistent with the Rotterdam diagnostic criteria. Although the SVM with isotonic calibration achieved the lowest calibration error (ECE = 0.0541), the Random Forest model provided a better balance between calibration and interpretability (Brier = 0.0678, ECE = 0.0666). Therefore, it was selected for detailed fairness and SHAP analyses. Subgroup analysis revealed that the model performed best among women aged 25-35 (accuracy 90.9%) but underperformed in those under 25 (69.2%), highlighting age-related disparities. The model achieved perfect precision in obese women and maintained high recall in lean PCOS cases, demonstrating robustness across phenotypes. Finally, a Streamlit-based web interface enables real-time PCOS risk assessment, Rotterdam criteria evaluation, and interactive 'what-if' analysis, bridging the gap between AI research and clinical usability.

</details>


### [320] [Enhancing PINN Accuracy for the RLW Equation: Adaptive and Conservative Approaches](https://arxiv.org/abs/2511.11638)
*Aamir Shehzad*

Main category: cs.LG

TL;DR: 本文提出了两种改进的PINN方法（自适应和守恒方法）来解决RLW方程，发现PINN的有效性取决于问题类型，挑战了守恒约束总是有益的假设。


<details>
  <summary>Details</summary>
Motivation: 标准PINN在求解正则化长波方程时产生较大误差，需要开发更有效的PINN方法来解决不同类型的偏微分方程问题。

Method: 开发了两种改进的PINN方法：1）自适应方法（使用自适应损失权重）；2）守恒方法（强制显式守恒定律）。使用三个基准测试：单孤子传播、双孤子相互作用、涌潮演化。

Result: 自适应PINN在处理复杂非线性相互作用（如孤子碰撞）时表现显著更好；守恒PINN在处理长期行为问题（如单孤子传播和涌潮演化）时更优。两种方法的结果与数值解误差在O(10^-5)量级。

Conclusion: 显式强制守恒定律可能对高度非线性系统的优化有害，需要特殊训练方法。PINN的有效性具有问题特异性，为特定类型问题的PINN设计提供了指导原则。

Abstract: Standard physics-informed neural network implementations have produced large error rates when using these models to solve the regularized long wave (RLW) equation. Two improved PINN approaches were developed in this research: an adaptive approach with self-adaptive loss weighting and a conservative approach enforcing explicit conservation laws. Three benchmark tests were used to demonstrate how effective PINN's are as they relate to the type of problem being solved (i.e., time dependent RLW equation). The first was a single soliton traveling along a line (propagation), the second was the interaction between two solitons, and the third was the evolution of an undular bore over the course of $t=250$. The results demonstrated that the effectiveness of PINNs are problem specific. The adaptive PINN was significantly better than both the conservative PINN and the standard PINN at solving problems involving complex nonlinear interactions such as colliding two solitons. The conservative approach was significantly better at solving problems involving long term behavior of single solitons and undular bores. However, the most important finding from this research is that explicitly enforcing conservation laws may be harmful to optimizing the solution of highly nonlinear systems of equations and therefore requires special training methods. The results from our adaptive and conservative approaches were within $O(10^{-5})$ of established numerical solutions for the same problem, thus demonstrating that PINNs can provide accurate solutions to complex systems of partial differential equations without the need for a discretization of space or time (mesh free). Moreover, the finding from this research challenges the assumptions that conservation enforcement will always improve the performance of a PINN and provides researchers with guidelines for designing PINNs for use on specific types of problems.

</details>


### [321] [EcoSpa: Efficient Transformer Training with Coupled Sparsity](https://arxiv.org/abs/2511.11641)
*Jinqi Xiao,Cheng Luo,Lingyi Huang,Cheng Yang,Yang Sui,Huy Phan,Xiao Zang,Yibiao Ying,Zhexiang Tang,Anima Anandkumar,Bo Yuan*

Main category: cs.LG

TL;DR: EcoSpa是一种高效的结构化稀疏训练方法，通过联合评估和稀疏化耦合的权重矩阵对，在保持交互模式的同时实现显著的计算效率提升。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏训练方法未能保留注意力机制和前馈层中权重矩阵之间的关键结构关系，导致在高稀疏度下性能下降。

Method: 引入联合评估和稀疏化耦合权重矩阵对的方法，通过对齐的行/列移除来保持交互模式，并引入新的粒度来校准结构组件重要性。

Result: 在LLaMA-1B上实现50%内存减少和21%训练加速，GPT-2-Medium上达到2.2倍模型压缩和2.4倍困惑度降低，推理速度提升1.6倍。

Conclusion: EcoSpa使用标准PyTorch操作，无需定制硬件或内核，可在商用硬件上实现高效的Transformer训练。

Abstract: Transformers have become the backbone of modern AI, yet their high computational demands pose critical system challenges. While sparse training offers efficiency gains, existing methods fail to preserve critical structural relationships between weight matrices that interact multiplicatively in attention and feed-forward layers. This oversight leads to performance degradation at high sparsity levels. We introduce EcoSpa, an efficient structured sparse training method that jointly evaluates and sparsifies coupled weight matrix pairs, preserving their interaction patterns through aligned row/column removal. EcoSpa introduces a new granularity for calibrating structural component importance and performs coupled estimation and sparsification across both pre-training and fine-tuning scenarios. Evaluations demonstrate substantial improvements: EcoSpa enables efficient training of LLaMA-1B with 50\% memory reduction and 21\% faster training, achieves $2.2\times$ model compression on GPT-2-Medium with $2.4$ lower perplexity, and delivers $1.6\times$ inference speedup. The approach uses standard PyTorch operations, requiring no custom hardware or kernels, making efficient transformer training accessible on commodity hardware.

</details>


### [322] [A Deep Learning Model to Predicting Changes in Consumer Attributes for New Line-extended Products](https://arxiv.org/abs/2511.11646)
*Li Yinxing,Tsukasa Ishigaki*

Main category: cs.LG

TL;DR: 本文提出了一种基于条件表格变分自编码器（CTVAE）的新方法，用于预测新产品线扩展对消费者属性的影响，帮助营销人员制定有效的产品线营销策略。


<details>
  <summary>Details</summary>
Motivation: 产品线扩展是重要的营销策略，但过度扩展会破坏品牌形象。营销人员需要了解新产品线扩展对消费者属性的影响，以制定基于消费者需求的适当扩展策略。

Method: 提出条件表格变分自编码器（CTVAE）模型，从大规模消费者和产品表格数据中生成合成数据，预测新产品线扩展对消费者属性的变化。

Result: 实验结果表明，CTVAE模型在预测性能上优于现有模型，能够为改变包装或口味的新产品提供有效的营销启示。

Conclusion: 该方法有助于避免产品线内部的蚕食效应，并为产品形象设计和营销策略制定提供支持，具有重要的实际应用价值。

Abstract: Product line extension is a marketing strategy that enhances a company's sphere of influence. Because excessive line extensions disrupt brand image, only appropriate line extensions based on consumer needs are desirable. Marketers should know the key consumer attributes of the primary customers for new line-extended products before companies enter the market. This paper describes a method for predicting changes in consumer attributes for new line-extended products using a novel deep learning model. The proposed model, Conditional Tabular Variational Auto-Encoder (CTVAE), generates synthetic data from large-scale tabular data of consumers and products. It can provide various implications about effective product line marketing for marketers. The experimental results demonstrate that the CTVAE offers superior prediction performance than existing models. We indicate implications for new products that change containers or flavors for effective product line marketing. The proposed approach has the potential to contribute to avoiding cannibalization and to designing product images and marketing strategies.

</details>


### [323] [Environment-Aware Transfer Reinforcement Learning for Sustainable Beam Selection](https://arxiv.org/abs/2511.11647)
*Dariush Salami,Ramin Hashemi,Parham Kazemi,Mikko A. Uusitalo*

Main category: cs.LG

TL;DR: 提出一种基于迁移学习和强化学习的可持续波束选择方法，通过点云建模和Chamfer距离识别相似环境，实现预训练模型复用，大幅降低训练时间和计算开销。


<details>
  <summary>Details</summary>
Motivation: 传统RL波束选择模型在多样化环境中需要大量训练时间和计算资源，不利于可扩展性和能源效率。

Method: 将环境建模为点云（包含gNodeB和散射体位置），计算点云间的Chamfer距离识别结构相似环境，通过迁移学习复用预训练模型。

Result: 训练时间和计算开销减少16倍，保持高性能的同时显著降低能耗，加速部署时间并减少碳排放。

Conclusion: 该方法证明了迁移学习在实现可扩展、自适应且环保的RL波束选择策略方面的潜力，支持绿色AI在无线系统中的发展。

Abstract: This paper presents a novel and sustainable approach for improving beam selection in 5G and beyond networks using transfer learning and Reinforcement Learning (RL). Traditional RL-based beam selection models require extensive training time and computational resources, particularly when deployed in diverse environments with varying propagation characteristics posing a major challenge for scalability and energy efficiency. To address this, we propose modeling the environment as a point cloud, where each point represents the locations of gNodeBs (gNBs) and surrounding scatterers. By computing the Chamfer distance between point clouds, structurally similar environments can be efficiently identified, enabling the reuse of pre-trained models through transfer learning. This methodology leads to a 16x reduction in training time and computational overhead, directly contributing to energy efficiency. By minimizing the need for retraining in each new deployment, our approach significantly lowers power consumption and supports the development of green and sustainable Artificial Intelligence (AI) in wireless systems. Furthermore, it accelerates time-to-deployment, reduces carbon emissions associated with training, and enhances the viability of deploying AI-driven communication systems at the edge. Simulation results confirm that our approach maintains high performance while drastically cutting energy costs, demonstrating the potential of transfer learning to enable scalable, adaptive, and environmentally conscious RL-based beam selection strategies in dynamic and diverse propagation environments.

</details>


### [324] [Lightweight Time Series Data Valuation on Time Series Foundation Models via In-Context Finetuning](https://arxiv.org/abs/2511.11648)
*Shunyu Wu,Tianyue Li,Yixuan Leng,Jingyi Suo,Jian Lou,Dan Li,See-Kiong Ng*

Main category: cs.LG

TL;DR: LTSV是一种基于上下文微调的轻量级时间序列估值方法，通过测量上下文损失变化来评估样本贡献，解决了传统方法在时间序列基础模型上的计算瓶颈和时序依赖问题。


<details>
  <summary>Details</summary>
Motivation: 时间序列基础模型性能依赖于数据质量，但传统数据估值方法（如影响函数）面临计算复杂度高、难以处理时序依赖的问题，需要一种高效准确的估值方法。

Method: 提出LTSV方法：基于理论证据，通过上下文微调近似影响函数，使用时间块聚合技术捕捉时序依赖，在多个重叠时间窗口上整合每块的影响分数。

Result: 在多个时间序列数据集和模型上的实验表明，LTSV能持续提供可靠且强大的估值性能，同时保持可管理的计算需求。

Conclusion: 上下文微调为时间序列学习中数据归因和模型泛化之间提供了实用有效的桥梁。

Abstract: Time series foundation models (TSFMs) have demonstrated increasing capabilities due to their extensive pretraining on large volumes of diverse time series data. Consequently, the quality of time series data is crucial to TSFM performance, rendering an accurate and efficient data valuation of time series for TSFMs indispensable. However, traditional data valuation methods, such as influence functions, face severe computational bottlenecks due to their poor scalability with growing TSFM model sizes and often fail to preserve temporal dependencies. In this paper, we propose LTSV, a Lightweight Time Series Valuation on TSFMS via in-context finetuning. Grounded in the theoretical evidence that in-context finetuning approximates the influence function, LTSV estimates a sample's contribution by measuring the change in context loss after in-context finetuning, leveraging the strong generalization capabilities of TSFMs to produce robust and transferable data valuations. To capture temporal dependencies, we introduce temporal block aggregation, which integrates per-block influence scores across overlapping time windows. Experiments across multiple time series datasets and models demonstrate that LTSV consistently provides reliable and strong valuation performance, while maintaining manageable computational requirements. Our results suggest that in-context finetuning on time series foundation models provides a practical and effective bridge between data attribution and model generalization in time series learning.

</details>


### [325] [Enhanced Water Leak Detection with Convolutional Neural Networks and One-Class Support Vector Machine](https://arxiv.org/abs/2511.11650)
*Daniele Ugo Leonzio,Paolo Bestagini,Marco Marcon,Stefano Tubaro*

Main category: cs.LG

TL;DR: 提出了一种基于压力测量和单类SVM的水管网络泄漏检测方法，该方法仅使用无泄漏时的压力数据和网络拓扑信息，在模拟数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 水管网络每年因泄漏造成大量水资源浪费，需要可靠有效的泄漏检测和定位系统。数据驱动方法因其优越性能而受到关注。

Method: 基于水管网络节点压力测量，使用特征提取器和在无泄漏数据上训练的单类支持向量机（SVM），将泄漏检测为异常。

Result: 在Modena水管网络的模拟数据集上，所提方法的表现优于最近的泄漏检测方法。

Conclusion: 提出的完全数据驱动解决方案仅利用网络拓扑和无泄漏压力数据，能够有效检测水管网络泄漏，且性能优于现有方法。

Abstract: Water is a critical resource that must be managed efficiently. However, a substantial amount of water is lost each year due to leaks in Water Distribution Networks (WDNs). This underscores the need for reliable and effective leak detection and localization systems. In recent years, various solutions have been proposed, with data-driven approaches gaining increasing attention due to their superior performance. In this paper, we propose a new method for leak detection. The method is based on water pressure measurements acquired at a series of nodes of a WDN. Our technique is a fully data-driven solution that makes only use of the knowledge of the WDN topology, and a series of pressure data acquisitions obtained in absence of leaks. The proposed solution is based on an feature extractor and a one-class Support Vector Machines (SVM) trained on no-leak data, so that leaks are detected as anomalies. The results achieved on a simulate dataset using the Modena WDN demonstrate that the proposed solution outperforms recent methods for leak detection.

</details>


### [326] [Incomplete Depression Feature Selection with Missing EEG Channels](https://arxiv.org/abs/2511.11651)
*Zhijian Gong,Wenjia Dong,Xueyuan Xu,Fulin Wei,Chunyu Liu,Li Zhuo*

Main category: cs.LG

TL;DR: 提出了一种名为IDFS-MEC的新型特征选择方法，用于处理EEG数据中缺失通道和不完整信息的问题，通过整合缺失通道指示信息和自适应通道加权学习来提高抑郁症分析的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: EEG特征通常包含冗余、不相关和噪声信息，且实际EEG数据采集经常面临电极脱落导致的数据丢失和强噪声干扰等挑战，影响抑郁症检测的准确性。

Method: IDFS-MEC将缺失通道指示信息和自适应通道加权学习整合到正交回归中，减轻不完整通道对模型构建的影响，并利用全局冗余最小化学习来减少所选特征子集中的冗余信息。

Result: 在MODMA和PRED-d003数据集上的实验表明，IDFS-MEC选择的EEG特征子集在3通道、64通道和128通道设置下，性能优于10种流行的特征选择方法。

Conclusion: IDFS-MEC方法能够有效处理EEG数据中的缺失通道问题，选择出更具判别力的特征子集，显著提升了抑郁症分析的准确性和鲁棒性。

Abstract: As a critical mental health disorder, depression has severe effects on both human physical and mental well-being. Recent developments in EEG-based depression analysis have shown promise in improving depression detection accuracies. However, EEG features often contain redundant, irrelevant, and noisy information. Additionally, real-world EEG data acquisition frequently faces challenges, such as data loss from electrode detachment and heavy noise interference. To tackle the challenges, we propose a novel feature selection approach for robust depression analysis, called Incomplete Depression Feature Selection with Missing EEG Channels (IDFS-MEC). IDFS-MEC integrates missing-channel indicator information and adaptive channel weighting learning into orthogonal regression to lessen the effects of incomplete channels on model construction, and then utilizes global redundancy minimization learning to reduce redundant information among selected feature subsets. Extensive experiments conducted on MODMA and PRED-d003 datasets reveal that the EEG feature subsets chosen by IDFS-MEC have superior performance than 10 popular feature selection methods among 3-, 64-, and 128-channel settings.

</details>


### [327] [How many stations are sufficient? Exploring the effect of urban weather station density reduction on imputation accuracy of air temperature and humidity](https://arxiv.org/abs/2511.11652)
*Marvin Plein,Carsten F. Dormann,Andreas Christen*

Main category: cs.LG

TL;DR: 本文提出了一种逐步移除气象站的方法，用于优化弗莱堡城市气象站网络的密度，研究发现可将站数从42个减少到4个，同时保持较高的温度和湿度预测精度。


<details>
  <summary>Details</summary>
Motivation: 城市气象站网络维护成本高昂且劳动密集，需要找到在减少站点的同时保持监测精度的有效方法。

Method: 采用逐步移除站点的程序，通过模拟减少气象站密度，分析子集网络重现原始网络空气温度和湿度模式的能力。

Result: 从42个站减少到4个站时，温度预测RMSE从0.69K增加到0.83K（增加20%），湿度RMSE从3.8%增加到4.4%（增加16%）。位于建成区与农村交界处的站点对重建城市气候特征最有价值。

Conclusion: 研究表明气象站网络优化具有巨大潜力，可以最大化城市气候研究中财务和人力资源的分配效率。

Abstract: Urban weather station networks (WSNs) are widely used to monitor urban weather and climate patterns and aid urban planning. However, maintaining WSNs is expensive and labor-intensive. Here, we present a step-wise station removal procedure to thin an existing WSN in Freiburg, Germany, and analyze the ability of WSN subsets to reproduce air temperature and humidity patterns of the entire original WSN for a year following a simulated reduction of WSN density. We found that substantial reductions in station numbers after one year of full deployment are possible while retaining high predictive accuracy. A reduction from 42 to 4 stations, for instance, increased mean prediction RMSEs from 0.69 K to 0.83 K for air temperature and from 3.8% to 4.4% for relative humidity, corresponding to RMSE increases of only 20% and 16%, respectively. Predictive accuracy is worse for remote stations in forests than for stations in built-up or open settings, but consistently better than a state-of-the-art numerical urban land-surface model (Surface Urban Energy and Water Balance Scheme). Stations located at the edges between built-up and rural areas are most valuable when reconstructing city-wide climate characteristics. Our study demonstrates the potential of thinning WSNs to maximize the efficient allocation of financial and personnel-related resources in urban climate research.

</details>


### [328] [Convergence of Multiagent Learning Systems for Traffic control](https://arxiv.org/abs/2511.11654)
*Sayambhu Sen,Shalabh Bhatnagar*

Main category: cs.LG

TL;DR: 本文对多智能体强化学习在交通信号控制中的收敛性进行了理论分析，证明了该算法在特定条件下的收敛性。


<details>
  <summary>Details</summary>
Motivation: 现有研究虽已实证多智能体强化学习在交通控制中的有效性，但缺乏对其稳定性和收敛性的严格理论分析，本文旨在填补这一理论空白。

Method: 利用随机近似方法，对多智能体Q学习算法的学习动力学进行形式化分析，将单智能体异步值迭代的收敛性证明扩展到多智能体场景。

Result: 证明了该特定多智能体强化学习算法在给定条件下能够收敛。

Conclusion: 本文为多智能体强化学习在交通信号控制中的应用提供了理论保障，证实了该方法的收敛性。

Abstract: Rapid urbanization in cities like Bangalore has led to severe traffic congestion, making efficient Traffic Signal Control (TSC) essential. Multi-Agent Reinforcement Learning (MARL), often modeling each traffic signal as an independent agent using Q-learning, has emerged as a promising strategy to reduce average commuter delays. While prior work Prashant L A et. al has empirically demonstrated the effectiveness of this approach, a rigorous theoretical analysis of its stability and convergence properties in the context of traffic control has not been explored. This paper bridges that gap by focusing squarely on the theoretical basis of this multi-agent algorithm. We investigate the convergence problem inherent in using independent learners for the cooperative TSC task. Utilizing stochastic approximation methods, we formally analyze the learning dynamics. The primary contribution of this work is the proof that the specific multi-agent reinforcement learning algorithm for traffic control is proven to converge under the given conditions extending it from single agent convergence proofs for asynchronous value iteration.

</details>


### [329] [On the Probabilistic Learnability of Compact Neural Network Preimage Bounds](https://arxiv.org/abs/2511.11656)
*Luca Marzari,Manuele Bicego,Ferdinando Cicalese,Alessandro Farinelli*

Main category: cs.LG

TL;DR: RF-ProVe是一种基于随机森林的概率验证方法，通过集成随机决策树生成满足输出属性的候选输入区域，并利用主动重采样进行优化，为神经网络预映像计算提供可扩展的近似解。


<details>
  <summary>Details</summary>
Motivation: 现有可证明方法受限于预映像计算的#P-hard问题，难以扩展到大规模网络。需要开发具有高置信度保证和误差界限的概率方法。

Method: 采用基于bootstrap和随机化的概率视角，利用随机决策树集成生成候选输入区域，通过主动重采样技术优化区域纯度。

Result: 理论推导提供了区域纯度和全局覆盖的正式统计保证，为精确求解器无法扩展的情况提供了实用的可扩展解决方案。

Conclusion: RF-ProVe为复杂高维空间中的预映像近似计算提供了具有统计保证的实用框架，解决了传统方法的可扩展性限制。

Abstract: Although recent provable methods have been developed to compute preimage bounds for neural networks, their scalability is fundamentally limited by the #P-hardness of the problem. In this work, we adopt a novel probabilistic perspective, aiming to deliver solutions with high-confidence guarantees and bounded error. To this end, we investigate the potential of bootstrap-based and randomized approaches that are capable of capturing complex patterns in high-dimensional spaces, including input regions where a given output property holds. In detail, we introduce $\textbf{R}$andom $\textbf{F}$orest $\textbf{Pro}$perty $\textbf{Ve}$rifier ($\texttt{RF-ProVe}$), a method that exploits an ensemble of randomized decision trees to generate candidate input regions satisfying a desired output property and refines them through active resampling. Our theoretical derivations offer formal statistical guarantees on region purity and global coverage, providing a practical, scalable solution for computing compact preimage approximations in cases where exact solvers fail to scale.

</details>


### [330] [SpecQuant: Spectral Decomposition and Adaptive Truncation for Ultra-Low-Bit LLMs Quantization](https://arxiv.org/abs/2511.11663)
*Zhixiong Zhao,Fangxin Liu,Junjie Wang,Chenyang Guan,Zongwu Wang,Li Jiang,Haibing Guan*

Main category: cs.LG

TL;DR: SpecQuant是一种基于傅里叶频率视角的极低比特量化方法，通过两阶段框架实现权重和激活值的4位量化，在LLaMA-3 8B模型上仅损失1.5%精度，同时提升2倍推理速度和降低3倍内存使用。


<details>
  <summary>Details</summary>
Motivation: 随着准确开源大语言模型的出现，需要先进的量化技术来在终端设备上实现高效部署。本文从傅里叶频率域的角度重新审视极端LLM压缩的挑战，目标是实现权重和激活值的超低比特量化。

Method: 提出SpecQuant两阶段框架：第一阶段平滑激活值异常值并将其转移到权重矩阵中；第二阶段应用通道级低频傅里叶截断来抑制高频分量，同时保留关键信号能量。还引入了轻量级截断模块在推理时根据通道特性调整截断阈值。

Result: 在LLaMA-3 8B模型上，SpecQuant实现了权重和激活值的4位量化，与全精度模型相比，零样本准确率差距仅为1.5%，同时提供2倍更快的推理速度和3倍更低的内存使用。

Conclusion: 基于权重能量主要集中在低频分量的原理，SpecQuant通过傅里叶频率域方法有效解决了极端量化挑战，在保持模型精度的同时显著提升了部署效率。

Abstract: The emergence of accurate open large language models (LLMs) has sparked a push for advanced quantization techniques to enable efficient deployment on end-user devices. In this paper, we revisit the challenge of extreme LLM compression -- targeting ultra-low-bit quantization for both activations and weights -- from a Fourier frequency domain perspective. We propose SpecQuant, a two-stage framework that tackles activation outliers and cross-channel variance. In the first stage, activation outliers are smoothed and transferred into the weight matrix to simplify downstream quantization. In the second stage, we apply channel-wise low-frequency Fourier truncation to suppress high-frequency components while preserving essential signal energy, improving quantization robustness. Our method builds on the principle that most of the weight energy is concentrated in low-frequency components, which can be retained with minimal impact on model accuracy. To enable runtime adaptability, we introduce a lightweight truncation module during inference that adjusts truncation thresholds based on channel characteristics. On LLaMA-3 8B, SpecQuant achieves 4-bit quantization for both weights and activations, narrowing the zero-shot accuracy gap to only 1.5% compared to full precision, while delivering 2 times faster inference and 3times lower memory usage.

</details>


### [331] [Clifford Algebraic Rotor Embeddings : Maybe embeddings should start to CARE](https://arxiv.org/abs/2511.11665)
*Sameeksha Sriram,Ayush Paliwal,Alexander S. Ecker,Chase van de Geijn*

Main category: cs.LG

TL;DR: 该论文提出了一种基于四元数的旋转位置编码方法QuatRo，并将其推广到基于几何代数的Clifford代数旋转嵌入(CARE)，解决了球形RoPE的非交换性问题，实现了更高维度的位置编码扩展。


<details>
  <summary>Details</summary>
Motivation: 现有球形RoPE扩展方法存在非交换性问题，导致旋转序列选择模糊，丧失了原始RoPE的平移等变性特性。需要一种能保持交换性的高维位置编码方法。

Method: 1. 使用四元数替代欧拉角表示3D旋转，提出QuatRo方法；2. 将四元数视为Cl(3,0,0)的偶子代数，推广到基于Clifford代数的CARE方法；3. 利用几何代数中的旋量作用于多向量，实现任意维度的位置编码。

Result: 证明了Mixed RoPE和Spherical RoPE是QuatRo的特例；提出的CARE方法能够扩展到任意维度，并在多向量中编码位置信息；通过初步实验比较了球形、四元数和Clifford基旋转嵌入的性能。

Conclusion: QuatRo和CARE方法成功解决了高维RoPE扩展中的非交换性问题，为位置编码提供了更通用和数学上优雅的框架，能够处理任意维度的输入并保持重要的数学性质。

Abstract: Rotary Positional Embeddings (RoPE) have demonstrated exceptional performance as a positional encoding method, consistently outperforming their baselines. While recent work has sought to extend RoPE to higher-dimensional inputs, many such extensions are non-commutative, thereby forfeiting RoPE's shift-equivariance property. Spherical RoPE is one such non-commutative variant, motivated by the idea of rotating embedding vectors on spheres rather than circles. However, spherical rotations are inherently non-commutative, making the choice of rotation sequence ambiguous. In this work, we explore a quaternion-based approach -- Quaternion Rotary Embeddings (QuatRo) -- in place of Euler angles, leveraging quaternions' ability to represent 3D rotations to parameterize the axes of rotation. We show Mixed RoPE and Spherical RoPE to be special cases of QuatRo. Further, we propose a generalization of QuatRo to Clifford Algebraic Rotary Embeddings (CARE) using geometric algebra. Viewing quaternions as the even subalgebra of Cl(3,0,0), we extend the notion of rotary embeddings from quaternions to Clifford rotors acting on multivectors. This formulation enables two key generalizations: (1) extending rotary embeddings to arbitrary dimensions, and (2) encoding positional information in multivectors of multiple grades, not just vectors. We present preliminary experiments comparing spherical, quaternion, and Clifford-based rotary embeddings.

</details>


### [332] [Adaptive Stepsizing for Stochastic Gradient Langevin Dynamics in Bayesian Neural Networks](https://arxiv.org/abs/2511.11666)
*Rajit Rajpal,Benedict Leimkuhler,Yuanhao Jiang*

Main category: cs.LG

TL;DR: 本文提出了一种自适应步长调整方法SA-SGLD，基于SamAdams框架，通过时间重缩放机制自动调节步长，解决了传统SGMCMC方法对步长敏感和自适应方法采样偏差的问题。


<details>
  <summary>Details</summary>
Motivation: 传统随机梯度马尔可夫链蒙特卡洛方法对步长选择高度敏感，且自适应变体如pSGLD在没有昂贵散度校正项的情况下无法正确采样不变测度。

Method: 基于SamAdams框架，提出SA-SGLD方法，通过监控局部梯度范数等量进行时间重缩放，自动在高曲率区域缩小步长、在平坦区域扩大步长。

Result: 在高曲率二维玩具示例和使用尖锐先验的贝叶斯神经网络图像分类任务中，SA-SGLD比SGLD实现了更准确的后验采样。

Conclusion: SA-SGLD方法能够在不引入偏差的情况下提高采样稳定性和混合效率，特别适用于高曲率区域的后验分布采样。

Abstract: Bayesian neural networks (BNNs) require scalable sampling algorithms to approximate posterior distributions over parameters. Existing stochastic gradient Markov Chain Monte Carlo (SGMCMC) methods are highly sensitive to the choice of stepsize and adaptive variants such as pSGLD typically fail to sample the correct invariant measure without addition of a costly divergence correction term. In this work, we build on the recently proposed `SamAdams' framework for timestep adaptation (Leimkuhler, Lohmann, and Whalley 2025), introducing an adaptive scheme: SA-SGLD, which employs time rescaling to modulate the stepsize according to a monitored quantity (typically the local gradient norm). SA-SGLD can automatically shrink stepsizes in regions of high curvature and expand them in flatter regions, improving both stability and mixing without introducing bias. We show that our method can achieve more accurate posterior sampling than SGLD on high-curvature 2D toy examples and in image classification with BNNs using sharp priors.

</details>


### [333] [Beyond Superficial Forgetting: Thorough Unlearning through Knowledge Density Estimation and Block Re-insertion](https://arxiv.org/abs/2511.11667)
*Feng Guo,Yuntao Wen,Shen Gao,Junshuo Zhang,Shuo Shang*

Main category: cs.LG

TL;DR: KUnBR是一种基于知识密度引导的机器遗忘方法，通过识别有害知识密集层并进行重新插入，有效消除LLM中的有害知识


<details>
  <summary>Details</summary>
Motivation: 现有遗忘方法难以彻底移除有害知识，残留的有害知识容易被恢复，需要更有效的遗忘技术来满足隐私、合规和伦理需求

Method: 提出知识密度估计来量化有害知识分布，识别知识密集层；设计层重新插入策略，提取并重新插入有害知识密集层，绕过覆盖层造成的梯度阻塞

Result: 在多个遗忘和通用能力基准测试中，KUnBR实现了最先进的遗忘性能，同时保持了模型效用

Conclusion: KUnBR通过知识密度引导和层重新插入策略，为LLM提供了一种高效且彻底的遗忘解决方案

Abstract: Machine unlearning, which selectively removes harmful knowledge from a pre-trained model without retraining from scratch, is crucial for addressing privacy, regulatory compliance, and ethical concerns in Large Language Models (LLMs). However, existing unlearning methods often struggle to thoroughly remove harmful knowledge, leaving residual harmful knowledge that can be easily recovered. To address these limitations, we propose Knowledge Density-Guided Unlearning via Blocks Reinsertion (KUnBR), a novel approach that first identifies layers with rich harmful knowledge and then thoroughly eliminates the harmful knowledge via re-insertion strategy. Our method introduces knowledge density estimation to quantify and locate layers containing the most harmful knowledge, enabling precise unlearning. Additionally, we design a layer re-insertion strategy that extracts and re-inserts harmful knowledge-rich layers into the original LLM, bypassing gradient obstruction caused by cover layers and ensuring effective gradient propagation during unlearning. Extensive experiments conducted on several unlearning and general capability benchmarks demonstrate that KUnBR achieves state-of-the-art forgetting performance while maintaining model utility.

</details>


### [334] [Do traveling waves make good positional encodings?](https://arxiv.org/abs/2511.11668)
*Chase van de Geijn,Ayush Paliwal,Timo Lüddecke,Alexander S. Ecker*

Main category: cs.LG

TL;DR: 提出了RollPE，一种基于行波的位置编码机制，通过循环滚动操作在自注意力中实现相对位置编码，性能优于传统绝对位置编码且与RoPE相当。


<details>
  <summary>Details</summary>
Motivation: 传统位置编码方法存在局限性，需要更好的方式来捕捉翻译等变性，同时希望简化RoPE并与大脑信息处理过程建立联系。

Method: 在自注意力中对查询和键张量应用循环滚动操作，通过相位相对偏移实现基于位置差异的注意力计算。

Result: RollPE显著优于传统绝对位置嵌入，与RoPE性能相当，并推导出连续情况下的数学等价关系。

Conclusion: RollPE作为一种简化的位置编码方法，不仅性能优异，还提供了从行波角度理解RoPE的新视角，可能与大脑信息流动过程相关。

Abstract: Transformers rely on positional encoding to compensate for the inherent permutation invariance of self-attention. Traditional approaches use absolute sinusoidal embeddings or learned positional vectors, while more recent methods emphasize relative encodings to better capture translation equivariances. In this work, we propose RollPE, a novel positional encoding mechanism based on traveling waves, implemented by applying a circular roll operation to the query and key tensors in self-attention. This operation induces a relative shift in phase across positions, allowing the model to compute attention as a function of positional differences rather than absolute indices. We show this simple method significantly outperforms traditional absolute positional embeddings and is comparable to RoPE. We derive a continuous case of RollPE which implicitly imposes a topographic structure on the query and key space. We further derive a mathematical equivalence of RollPE to a particular configuration of RoPE. Viewing RollPE through the lens of traveling waves may allow us to simplify RoPE and relate it to processes of information flow in the brain.

</details>


### [335] [H-Model: Dynamic Neural Architectures for Adaptive Processing](https://arxiv.org/abs/2511.11669)
*Dmytro Hospodarchuk*

Main category: cs.LG

TL;DR: 本文提出了一种能够根据输入数据动态调整内部结构的神经网络架构，通过路由机制实现自适应计算，旨在探索可适应和可解释的网络结构而非追求性能优化。


<details>
  <summary>Details</summary>
Motivation: 受思维过程和动态推理启发，探索一种能够根据数据和内部状态自适应调整信息流的神经网络架构，目标是学习计算结构本身而不仅仅是表示。

Method: 引入路由机制，使网络各层能够影响输出的传播方式，实现迭代和自适应计算，构建概念原型框架。

Result: 由于计算资源和数据限制，本研究为初步探索，但初步观察显示该架构具有潜力，需要未来在更有利的计算条件下进行完整评估。

Conclusion: 该工作提出了一个可适应神经网络的新方向，虽然目前是概念原型，但为探索更可解释和动态的网络结构奠定了基础。

Abstract: This article explores the design and experimentation of a neural network architecture capable of dynamically adjusting its internal structure based on the input data. The proposed model introduces a routing mechanism that allows each layer to influence how its outputs are propagated through the network, enabling iterative and adaptive computation. This concept is loosely inspired by the idea of thought processes and dynamic reasoning, where information flow is conditioned not only on the data itself, but also on the internal state of the system.
  It is important to note that this work does not aim to compete with state-of-the-art language models in terms of performance. Instead, it presents a conceptual prototype-an architectural framework that opens up a new direction for exploring adaptable and potentially more interpretable networks. The goal is not optimization of existing benchmarks but rather the proposal of a system that can learn not only representations, but also the structure of computation itself.
  Due to practical constraints in computing resources and data, this study remains a preliminary investigation. Nevertheless, initial observations show promise, and the architecture's full potential can only be evaluated in future experiments under more favorable computational conditions.

</details>


### [336] [Evaluation of LLM-based Explanations for a Learning Analytics Dashboard](https://arxiv.org/abs/2511.11671)
*Alina Deriyeva,Benjamin Paassen*

Main category: cs.LG

TL;DR: 使用大型语言模型生成学习分析仪表板的数据解释，能显著提升教育工作者对仪表板解释的偏好，优于独立仪表板和人类教师提供的解释。


<details>
  <summary>Details</summary>
Motivation: 学习分析仪表板可以支持数字学习环境中的自我调节学习，但其有效性受数据可解释性的影响。为了帮助解释数据，本研究采用大型语言模型生成仪表板数据的语言解释。

Method: 在专家研究中，将LLM生成的解释与独立仪表板以及人类教师提供的解释进行比较，研究对象为大学教育工作者（N=12）。

Result: 研究发现，LLM生成的关于仪表板中技能状态解释以及课程学习建议显著更受青睐。

Conclusion: 使用LLM进行解释可以提升学习者的学习体验，同时保持教师认可的教学标准。

Abstract: Learning Analytics Dashboards can be a powerful tool to support self-regulated learning in Digital Learning Environments and promote development of meta-cognitive skills, such as reflection. However, their effectiveness can be affected by the interpretability of the data they provide. To assist in the interpretation, we employ a large language model to generate verbal explanations of the data in the dashboard and evaluate it against a standalone dashboard and explanations provided by human teachers in an expert study with university level educators (N=12). We find that the LLM-based explanations of the skill state presented in the dashboard, as well as general recommendations on how to proceed with learning within the course are significantly more favored compared to the other conditions. This indicates that using LLMs for interpretation purposes can enhance the learning experience for learners while maintaining the pedagogical standards approved by teachers.

</details>


### [337] [Synergistic Feature Fusion for Latent Lyrical Classification: A Gated Deep Learning Architecture](https://arxiv.org/abs/2511.11673)
*M. A. Gameiro*

Main category: cs.LG

TL;DR: 该研究提出了一种新颖的协同融合层（SFL）架构，通过门控机制将复杂的深度语义特征与简单的结构特征相结合，用于歌词内容分类。SFL模型在准确性和可靠性方面均优于传统的随机森林基线。


<details>
  <summary>Details</summary>
Motivation: 解决将复杂的高维深度语义特征与简单可解释的结构线索整合用于歌词内容分类的挑战，探索非线性门控机制相比简单特征拼接的优越性。

Method: 使用门控机制调制Sentence-BERT嵌入（Fdeep）和低维辅助特征（Fstruct），将UMAP降维后的歌词嵌入聚类任务重构为二分类问题，区分主导同质簇（Class 0）与其他内容（Class 1）。

Result: SFL模型达到0.9894的准确率和宏F1分数，优于随机森林基线（0.9868）。更重要的是，SFL显示出显著更高的可靠性，预期校准误差降低93%（0.0035 vs 0.0500），对数损失降低2.5倍（0.0304 vs 0.0772）。

Conclusion: 非线性门控机制优于简单特征拼接的架构假设得到验证，SFL模型成为复杂多模态歌词分析的鲁棒且可信赖的系统。

Abstract: This study addresses the challenge of integrating complex, high-dimensional deep semantic features with simple, interpretable structural cues for lyrical content classification. We introduce a novel Synergistic Fusion Layer (SFL) architecture, a deep learning model utilizing a gated mechanism to modulate Sentence-BERT embeddings (Fdeep) using low-dimensional auxiliary features (Fstruct). The task, derived from clustering UMAP-reduced lyrical embeddings, is reframed as binary classification, distinguishing a dominant, homogeneous cluster (Class 0) from all other content (Class 1). The SFL model achieved an accuracy of 0.9894 and a Macro F1 score of 0.9894, outperforming a comprehensive Random Forest (RF) baseline that used feature concatenation (Accuracy = 0.9868). Crucially, the SFL model demonstrated vastly superior reliability and calibration, exhibiting a 93% reduction in Expected Calibration Error (ECE = 0.0035) and a 2.5x lower Log Loss (0.0304) compared to the RF baseline (ECE = 0.0500; Log Loss = 0.0772). This performance validates the architectural hypothesis that non-linear gating is superior to simple feature concatenation, establishing the SFL model as a robust and trustworthy system for complex multimodal lyrical analysis.

</details>


### [338] [Beyond One-Way Pruning: Bidirectional Pruning-Regrowth for Extreme Accuracy-Sparsity Tradeoff](https://arxiv.org/abs/2511.11675)
*Junchen Liu,Yi Sheng*

Main category: cs.LG

TL;DR: 提出双向剪枝-再生策略，从极度压缩的网络开始选择性再生关键连接，解决高稀疏度下模型性能急剧下降的问题


<details>
  <summary>Details</summary>
Motivation: 当稀疏度超过阈值时，现有剪枝方法会导致模型性能急剧下降，限制了可实现的压缩比，无法满足硬件平台的严格尺寸约束

Method: 从满足硬件约束的极度压缩网络出发，选择性再生关键连接以恢复丢失的性能

Result: 该方法有效缓解了高稀疏度条件下常见的准确率急剧下降问题

Conclusion: 双向剪枝-再生策略克服了传统剪枝方法的局限性，能够在满足硬件约束的同时保持模型性能

Abstract: As a widely adopted model compression technique, model pruning has demonstrated strong effectiveness across various architectures. However, we observe that when sparsity exceeds a certain threshold, both iterative and one-shot pruning methods lead to a steep decline in model performance. This rapid degradation limits the achievable compression ratio and prevents models from meeting the stringent size constraints required by certain hardware platforms, rendering them inoperable. To overcome this limitation, we propose a bidirectional pruning-regrowth strategy. Starting from an extremely compressed network that satisfies hardware constraints, the method selectively regenerates critical connections to recover lost performance, effectively mitigating the sharp accuracy drop commonly observed under high sparsity conditions.

</details>


### [339] [Learning with Preserving for Continual Multitask Learning](https://arxiv.org/abs/2511.11676)
*Hanchen David Wang,Siwoo Bae,Zirong Chen,Meiyi Ma*

Main category: cs.LG

TL;DR: 提出了LwP框架来解决持续多任务学习中的灾难性遗忘问题，通过保持共享表示空间的几何结构而非任务输出来提升模型性能


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶、医疗影像等关键领域，AI系统需要持续学习新任务而不遗忘已学能力，现有方法因学习碎片化的任务特定特征而失败

Method: 引入Learning with Preserving框架，核心是动态加权距离保持损失，通过正则化潜在数据表示之间的成对距离来防止表示漂移

Result: 在时序数据和图像基准测试中，LwP不仅缓解了灾难性遗忘，还持续优于最先进基线，是唯一超越强单任务学习基线的方法

Conclusion: LwP框架通过保持表示空间的几何结构，有效支持现实世界动态环境中的持续多任务学习，具有出色的分布偏移鲁棒性

Abstract: Artificial intelligence systems in critical fields like autonomous driving and medical imaging analysis often continually learn new tasks using a shared stream of input data. For instance, after learning to detect traffic signs, a model may later need to learn to classify traffic lights or different types of vehicles using the same camera feed. This scenario introduces a challenging setting we term Continual Multitask Learning (CMTL), where a model sequentially learns new tasks on an underlying data distribution without forgetting previously learned abilities. Existing continual learning methods often fail in this setting because they learn fragmented, task-specific features that interfere with one another. To address this, we introduce Learning with Preserving (LwP), a novel framework that shifts the focus from preserving task outputs to maintaining the geometric structure of the shared representation space. The core of LwP is a Dynamically Weighted Distance Preservation (DWDP) loss that prevents representation drift by regularizing the pairwise distances between latent data representations. This mechanism of preserving the underlying geometric structure allows the model to retain implicit knowledge and support diverse tasks without requiring a replay buffer, making it suitable for privacy-conscious applications. Extensive evaluations on time-series and image benchmarks show that LwP not only mitigates catastrophic forgetting but also consistently outperforms state-of-the-art baselines in CMTL tasks. Notably, our method shows superior robustness to distribution shifts and is the only approach to surpass the strong single-task learning baseline, underscoring its effectiveness for real-world dynamic environments.

</details>


### [340] [Homotopy-Guided Self-Supervised Learning of Parametric Solutions for AC Optimal Power Flow](https://arxiv.org/abs/2511.11677)
*Shimiao Li,Aaron Tuor,Draguna Vrabie,Larry Pileggi,Jan Drgona*

Main category: cs.LG

TL;DR: 提出了一种基于同伦引导的自监督学习方法，用于解决参数化交流最优潮流问题，通过构造连续变形从松弛问题过渡到原问题，提高收敛稳定性和可行性。


<details>
  <summary>Details</summary>
Motivation: 标准学习方法在非凸的AC-OPF优化问题中难以收敛到可行的高质量解，需要一种更稳定的训练方法。

Method: 采用同伦引导的自监督学习，通过连续变形目标函数和约束条件，从具有宽吸引域的松弛问题逐步过渡到原问题。

Result: 在标准IEEE AC-OPF基准测试中，该方法相比非同伦基线显著提高了可行性率，同时达到与完整OPF求解器相当的目标函数值。

Conclusion: 同伦启发式方法在电力系统优化中展示了可扩展、约束感知的学习优化潜力。

Abstract: Learning to optimize (L2O) parametric approximations of AC optimal power flow (AC-OPF) solutions offers the potential for fast, reusable decision-making in real-time power system operations. However, the inherent nonconvexity of AC-OPF results in challenging optimization landscapes, and standard learning approaches often fail to converge to feasible, high-quality solutions. This work introduces a \textit{homotopy-guided self-supervised L2O method} for parametric AC-OPF problems. The key idea is to construct a continuous deformation of the objective and constraints during training, beginning from a relaxed problem with a broad basin of attraction and gradually transforming it toward the original problem. The resulting learning process improves convergence stability and promotes feasibility without requiring labeled optimal solutions or external solvers. We evaluate the proposed method on standard IEEE AC-OPF benchmarks and show that homotopy-guided L2O significantly increases feasibility rates compared to non-homotopy baselines, while achieving objective values comparable to full OPF solvers. These findings demonstrate the promise of homotopy-based heuristics for scalable, constraint-aware L2O in power system optimization.

</details>


### [341] [A neural optimization framework for free-boundary diffeomorphic mapping problems and its applications](https://arxiv.org/abs/2511.11679)
*Zhehao Xu,Lok Ming Lui*

Main category: cs.LG

TL;DR: 提出了一种基于神经网络的自由边界微分同胚优化方法SBN-Opt，通过谱Beltrami网络嵌入LSQC能量，解决了传统数值算法无法应用于梯度优化的问题。


<details>
  <summary>Details</summary>
Motivation: 自由边界微分同胚优化在曲面映射问题中至关重要，但传统数值LSQC算法需要地标条件且无法应用于基于梯度的优化，限制了其应用范围。

Method: 提出SBN（谱Beltrami网络）作为神经代理，将LSQC能量嵌入多尺度网格谱架构；然后提出SBN-Opt优化框架，通过SBN指导自由边界微分同胚优化。

Result: 在密度均衡映射和不一致曲面配准上的大量实验表明，SBN-Opt优于传统数值算法。

Conclusion: SBN-Opt框架能够有效优化自由边界微分同胚，并显式控制局部几何畸变，为曲面映射问题提供了更优的解决方案。

Abstract: Free-boundary diffeomorphism optimization is a core ingredient in the surface mapping problem but remains notoriously difficult because the boundary is unconstrained and local bijectivity must be preserved under large deformation. Numerical Least-Squares Quasiconformal (LSQC) theory, with its provable existence, uniqueness, similarity-invariance and resolution-independence, offers an elegant mathematical remedy. However, the conventional numerical algorithm requires landmark conditioning, and cannot be applied into gradient-based optimization. We propose a neural surrogate, the Spectral Beltrami Network (SBN), that embeds LSQC energy into a multiscale mesh-spectral architecture. Next, we propose the SBN guided optimization framework SBN-Opt which optimizes free-boundary diffeomorphism for the problem, with local geometric distortion explicitly controllable. Extensive experiments on density-equalizing maps and inconsistent surface registration demonstrate our SBN-Opt's superiority over traditional numerical algorithms.

</details>


### [342] [Probabilistic Wildfire Susceptibility from Remote Sensing Using Random Forests and SHAP](https://arxiv.org/abs/2511.11680)
*Udaya Bhasker Cheerala,Varun Teja Chirukuri,Venkata Akhil Kumar Gummadi,Jintu Moni Bhuyan,Praveen Damacharla*

Main category: cs.LG

TL;DR: 本研究使用随机森林算法结合SHAP可解释人工智能方法，开发了加利福尼亚州全面的野火风险地图，识别了不同生态系统的主要驱动因素。


<details>
  <summary>Details</summary>
Motivation: 野火对全球生态系统构成重大威胁，加利福尼亚州因气候、地形、植被和人类活动等因素频繁发生火灾，需要开发可靠的风险评估方法来支持决策。

Method: 采用随机森林算法结合SHAP可解释AI技术，通过空间和时间验证策略评估模型性能，识别关键风险驱动因素。

Result: 模型表现出色，森林和草地的AUC分别达到0.997和0.996；SHAP分析显示森林风险主要受土壤有机碳、树木覆盖和NDVI影响，草地风险主要受地表温度、海拔和植被健康指数影响。

Conclusion: RF-SHAP框架为野火风险评估提供了稳健、可解释且适应性强的解决方案，有助于制定有针对性的减灾策略。

Abstract: Wildfires pose a significant global threat to ecosystems worldwide, with California experiencing recurring fires due to various factors, including climate, topographical features, vegetation patterns, and human activities. This study aims to develop a comprehensive wildfire risk map for California by applying the random forest (RF) algorithm, augmented with Explainable Artificial Intelligence (XAI) through Shapley Additive exPlanations (SHAP), to interpret model predictions. Model performance was assessed using both spatial and temporal validation strategies. The RF model demonstrated strong predictive performance, achieving near-perfect discrimination for grasslands (AUC = 0.996) and forests (AUC = 0.997). Spatial cross-validation revealed moderate transferability, yielding ROC-AUC values of 0.6155 for forests and 0.5416 for grasslands. In contrast, temporal split validation showed enhanced generalization, especially for forests (ROC-AUC = 0.6615, PR-AUC = 0.8423). SHAP-based XAI analysis identified key ecosystem-specific drivers: soil organic carbon, tree cover, and Normalized Difference Vegetation Index (NDVI) emerged as the most influential in forests, whereas Land Surface Temperature (LST), elevation, and vegetation health indices were dominant in grasslands. District-level classification revealed that Central Valley and Northern Buttes districts had the highest concentration of high-risk grasslands, while Northern Buttes and North Coast Redwoods dominated forested high-risk areas. This RF-SHAP framework offers a robust, comprehensible, and adaptable method for assessing wildfire risks, enabling informed decisions and creating targeted strategies to mitigate dangers.

</details>


### [343] [MPCM-Net: Multi-scale network integrates partial attention convolution with Mamba for ground-based cloud image segmentation](https://arxiv.org/abs/2511.11681)
*Penghui Niu,Jiashuai She,Taotao Cai,Yajuan Zhang,Ping Zhang,Junhua Gu,Jianxin Li*

Main category: cs.LG

TL;DR: 提出了MPCM-Net网络，结合部分注意力卷积和Mamba架构，用于地面云图像分割，在保持计算效率的同时提升分割精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在三个主要问题：1）依赖空洞卷积进行多尺度上下文提取，缺乏部分特征有效性和通道间互操作性；2）基于注意力的特征增强实现忽视精度-吞吐量平衡；3）解码器修改未能建立层次化局部特征间的全局依赖关系，限制推理效率。

Method: 提出MPCM-Net网络，编码器包含MPAC模块（MPC块和MPA块），分别实现多尺度云形成的全局空间交互和低计算复杂度的判别特征提取；解码器使用M2B模块，通过SSHD机制在保持线性复杂度的同时实现跨空间和尺度维度的深度特征聚合。

Result: 在自建数据集CSRC上的实验表明，MPCM-Net在分割精度和推理速度之间达到了最优平衡，优于现有最先进方法。

Conclusion: MPCM-Net通过创新的网络架构设计有效解决了现有云图像分割方法的局限性，同时发布了高质量的CSRC数据集为社区做出贡献。

Abstract: Ground-based cloud image segmentation is a critical research domain for photovoltaic power forecasting. Current deep learning approaches primarily focus on encoder-decoder architectural refinements. However, existing methodologies exhibit several limitations:(1)they rely on dilated convolutions for multi-scale context extraction, lacking the partial feature effectiveness and interoperability of inter-channel;(2)attention-based feature enhancement implementations neglect accuracy-throughput balance; and (3)the decoder modifications fail to establish global interdependencies among hierarchical local features, limiting inference efficiency. To address these challenges, we propose MPCM-Net, a Multi-scale network that integrates Partial attention Convolutions with Mamba architectures to enhance segmentation accuracy and computational efficiency. Specifically, the encoder incorporates MPAC, which comprises:(1)a MPC block with ParCM and ParSM that enables global spatial interaction across multi-scale cloud formations, and (2)a MPA block combining ParAM and ParSM to extract discriminative features with reduced computational complexity. On the decoder side, a M2B is employed to mitigate contextual loss through a SSHD that maintains linear complexity while enabling deep feature aggregation across spatial and scale dimensions. As a key contribution to the community, we also introduce and release a dataset CSRC, which is a clear-label, fine-grained segmentation benchmark designed to overcome the critical limitations of existing public datasets. Extensive experiments on CSRC demonstrate the superior performance of MPCM-Net over state-of-the-art methods, achieving an optimal balance between segmentation accuracy and inference speed. The dataset and source code will be available at https://github.com/she1110/CSRC.

</details>


### [344] [Stratified Knowledge-Density Super-Network for Scalable Vision Transformers](https://arxiv.org/abs/2511.11683)
*Longhua Li,Lei Qi,Xin Geng*

Main category: cs.LG

TL;DR: 提出了一种将预训练ViT转换为分层知识密度超网络的方法，通过WPAC和PIAD技术实现知识压缩和分层组织，从而支持灵活提取不同大小的子网络。


<details>
  <summary>Details</summary>
Motivation: 训练和部署多个不同资源约束的ViT模型成本高且效率低，需要一种能够灵活适应不同模型大小的统一解决方案。

Method: 使用WPAC（加权PCA注意力收缩）技术将知识压缩到关键权重中，并结合PIAD（渐进重要性感知丢弃）方法促进知识分层组织。

Result: WPAC在知识集中方面优于现有剪枝标准，与PIAD结合为模型压缩和扩展提供了强有力的替代方案。

Conclusion: 该方法能够有效构建分层知识组织，支持从单一超网络中提取不同大小的子网络，在保持性能的同时提高效率。

Abstract: Training and deploying multiple vision transformer (ViT) models for different resource constraints is costly and inefficient. To address this, we propose transforming a pre-trained ViT into a stratified knowledge-density super-network, where knowledge is hierarchically organized across weights. This enables flexible extraction of sub-networks that retain maximal knowledge for varying model sizes. We introduce \textbf{W}eighted \textbf{P}CA for \textbf{A}ttention \textbf{C}ontraction (WPAC), which concentrates knowledge into a compact set of critical weights. WPAC applies token-wise weighted principal component analysis to intermediate features and injects the resulting transformation and inverse matrices into adjacent layers, preserving the original network function while enhancing knowledge compactness. To further promote stratified knowledge organization, we propose \textbf{P}rogressive \textbf{I}mportance-\textbf{A}ware \textbf{D}ropout (PIAD). PIAD progressively evaluates the importance of weight groups, updates an importance-aware dropout list, and trains the super-network under this dropout regime to promote knowledge stratification. Experiments demonstrate that WPAC outperforms existing pruning criteria in knowledge concentration, and the combination with PIAD offers a strong alternative to state-of-the-art model compression and model expansion methods.

</details>


### [345] [A Bayesian Model for Multi-stage Censoring](https://arxiv.org/abs/2511.11684)
*Shuvom Sadhuka,Sophia Lin,Emma Pierson,Bonnie Berger*

Main category: cs.LG

TL;DR: 该论文提出了一种贝叶斯模型来处理医疗决策中的漏斗结构问题，通过考虑选择性审查偏差来更准确地估计风险，并在急诊科数据中发现性别差异。


<details>
  <summary>Details</summary>
Motivation: 医疗决策中的漏斗结构（如筛查流程）存在选择性审查问题，即只有通过前期筛选的患者才能获得最终真实结果，这会导致风险估计偏差，特别是在服务不足的患者群体中。

Method: 开发了一种基于选择性标签和审查先验工作的贝叶斯模型，用于建模漏斗决策结构，并在合成数据和急诊科就诊数据上进行验证。

Result: 在合成设置中，模型能准确恢复真实参数并比基线更准确地预测被审查患者的结果；在急诊科数据应用中，发现ICU入院的风险阈值存在性别差异（女性5.1% vs 男性4.5%）。

Conclusion: 该贝叶斯模型能有效解决漏斗结构中的选择性审查偏差问题，揭示了医疗决策中可能存在的性别差异，有助于改善公平性。

Abstract: Many sequential decision settings in healthcare feature funnel structures characterized by a series of stages, such as screenings or evaluations, where the number of patients who advance to each stage progressively decreases and decisions become increasingly costly. For example, an oncologist may first conduct a breast exam, followed by a mammogram for patients with concerning exams, followed by a biopsy for patients with concerning mammograms. A key challenge is that the ground truth outcome, such as the biopsy result, is only revealed at the end of this funnel. The selective censoring of the ground truth can introduce statistical biases in risk estimation, especially in underserved patient groups, whose outcomes are more frequently censored. We develop a Bayesian model for funnel decision structures, drawing from prior work on selective labels and censoring. We first show in synthetic settings that our model is able to recover the true parameters and predict outcomes for censored patients more accurately than baselines. We then apply our model to a dataset of emergency department visits, where in-hospital mortality is observed only for those who are admitted to either the hospital or ICU. We find that there are gender-based differences in hospital and ICU admissions. In particular, our model estimates that the mortality risk threshold to admit women to the ICU is higher for women (5.1%) than for men (4.5%).

</details>


### [346] [R-Tuning: Wavelet-Decomposed Replay and Semantic Alignment for Continual Adaptation of Pretrained Time-Series Models](https://arxiv.org/abs/2511.11685)
*Tianyi Yin,Jingwei Wang,Chenze Wang,Han Wang,Jiexuan Cai,Min Liu,Yunlong Ma,Kun Gao,Yuting Song,Weiming Shen*

Main category: cs.LG

TL;DR: R-Tuning是一个用于预训练时间序列模型持续适应的新框架，通过频率感知重放策略构建统一潜在空间，解决灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 预训练模型在时间序列预测中表现优异，但适应不断变化的数据分布时面临挑战，主要困难在于无法访问原始训练数据，仅在新数据上微调会导致灾难性遗忘。

Method: 提出R-Tuning框架，使用小波分解在多频段生成趋势保持和融合增强的变体，提高表示多样性；引入潜在一致性约束，将新表示与先验任务空间对齐，在紧凑语义一致的潜在空间中进行联合优化。

Result: 实验结果显示R-Tuning在新任务上MAE和MSE分别降低46.9%和46.8%，在旧任务上性能提升5.7%和6.0%；在少样本设置下，即使合成代理样本仅占新任务数据集的5%，仍优于所有最先进基线。

Conclusion: R-Tuning通过频率感知重放和潜在一致性约束，有效解决了预训练时间序列模型的持续适应问题，在保持先验知识的同时实现了对新任务的优异适应性能。

Abstract: Pre-trained models have demonstrated exceptional generalization capabilities in time-series forecasting; however, adapting them to evolving data distributions remains a significant challenge. A key hurdle lies in accessing the original training data, as fine-tuning solely on new data often leads to catastrophic forgetting. To address this issue, we propose Replay Tuning (R-Tuning), a novel framework designed for the continual adaptation of pre-trained time-series models. R-Tuning constructs a unified latent space that captures both prior and current task knowledge through a frequency-aware replay strategy. Specifically, it augments model-generated samples via wavelet-based decomposition across multiple frequency bands, generating trend-preserving and fusion-enhanced variants to improve representation diversity and replay efficiency. To further reduce reliance on synthetic samples, R-Tuning introduces a latent consistency constraint that aligns new representations with the prior task space. This constraint guides joint optimization within a compact and semantically coherent latent space, ensuring robust knowledge retention and adaptation. Extensive experimental results demonstrate the superiority of R-Tuning, which reduces MAE and MSE by up to 46.9% and 46.8%, respectively, on new tasks, while preserving prior knowledge with gains of up to 5.7% and 6.0% on old tasks. Notably, under few-shot settings, R-Tuning outperforms all state-of-the-art baselines even when synthetic proxy samples account for only 5% of the new task dataset.

</details>


### [347] [Regularized Schrödinger: Alleviating Distortion and Exposure Bias in Solving Inverse Problems](https://arxiv.org/abs/2511.11686)
*Qing Yao,Lijian Gao,Qirong Mao,Dong Ming*

Main category: cs.LG

TL;DR: 提出了Regularized Schrödinger Bridge (RSB)方法，通过正则化训练策略解决扩散模型在逆问题中的失真-感知权衡和曝光偏差问题


<details>
  <summary>Details</summary>
Motivation: 扩散模型在解决逆问题时面临两个关键挑战：1) 失真-感知权衡，即提高感知质量往往会降低重建保真度；2) 曝光偏差问题，训练-推理输入不匹配导致预测误差积累和重建质量下降

Method: RSB采用新颖的正则化训练策略，对输入状态和目标进行扰动，通过暴露模型于模拟预测误差来缓解曝光偏差，并通过后验均值的精心设计插值来减轻失真

Result: 在语音增强的两个典型逆问题上进行广泛实验，RSB优于最先进方法，显著改善了失真指标并有效减少了曝光偏差

Conclusion: RSB是专门针对逆问题量身定制的Schrödinger Bridge改进版本，成功解决了扩散模型在逆问题应用中的核心限制

Abstract: Diffusion models serve as a powerful generative framework for solving inverse problems. However, they still face two key challenges: 1) the distortion-perception tradeoff, where improving perceptual quality often degrades reconstruction fidelity, and 2) the exposure bias problem, where the training-inference input mismatch leads to prediction error accumulation and reduced reconstruction quality. In this work, we propose the Regularized Schrödinger Bridge (RSB), an adaptation of Schrödinger Bridge tailored for inverse problems that addresses the above limitations. RSB employs a novel regularized training strategy that perturbs both the input states and targets, effectively mitigating exposure bias by exposing the model to simulated prediction errors and also alleviating distortion by well-designed interpolation via the posterior mean. Extensive experiments on two typical inverse problems for speech enhancement demonstrate that RSB outperforms state-of-the-art methods, significantly improving distortion metrics and effectively reducing exposure bias.

</details>


### [348] [Enhancing Reinforcement Learning in 3D Environments through Semantic Segmentation: A Case Study in ViZDoom](https://arxiv.org/abs/2511.11703)
*Hugo Huang*

Main category: cs.LG

TL;DR: 该论文提出两种基于语义分割的输入表示方法（SS-only和RGB+SS），用于解决3D环境中强化学习的高内存消耗和部分可观测性问题，在ViZDoom死亡竞赛中验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决3D环境中强化学习面临的两个主要挑战：高维感官输入导致的内存缓冲区高内存消耗，以及在部分可观测马尔可夫决策过程中的学习复杂性。

Method: 提出两种新颖的输入表示方法：SS-only（仅使用语义分割）和RGB+SS（RGB加语义分割），利用语义分割技术处理RGB彩色图像，并采用可矢量化的无损压缩技术（如游程编码）来减少内存占用。

Result: SS-only方法能将内存缓冲区的内存消耗减少至少66.6%，最高可达98.6%；RGB+SS方法通过提供额外的语义信息显著提升了RL智能体的性能。同时探索了基于密度的热图技术来可视化智能体移动模式。

Conclusion: 该方法克服了在ViZDoom等3D环境中应用语义分割的常见陷阱，有效解决了内存消耗和部分可观测性问题，为3D环境中的强化学习提供了实用的解决方案。

Abstract: Reinforcement learning (RL) in 3D environments with high-dimensional sensory input poses two major challenges: (1) the high memory consumption induced by memory buffers required to stabilise learning, and (2) the complexity of learning in partially observable Markov Decision Processes (POMDPs). This project addresses these challenges by proposing two novel input representations: SS-only and RGB+SS, both employing semantic segmentation on RGB colour images. Experiments were conducted in deathmatches of ViZDoom, utilizing perfect segmentation results for controlled evaluation. Our results showed that SS-only was able to reduce the memory consumption of memory buffers by at least 66.6%, and up to 98.6% when a vectorisable lossless compression technique with minimal overhead such as run-length encoding is applied. Meanwhile, RGB+SS significantly enhances RL agents' performance with the additional semantic information provided. Furthermore, we explored density-based heatmapping as a tool to visualise RL agents' movement patterns and evaluate their suitability for data collection. A brief comparison with a previous approach highlights how our method overcame common pitfalls in applying semantic segmentation in 3D environments like ViZDoom.

</details>


### [349] [Hierarchical Schedule Optimization for Fast and Robust Diffusion Model Sampling](https://arxiv.org/abs/2511.11688)
*Aihua Zhu,Rui Su,Qinglin Zhao,Li Feng,Meng Shen,Shibo He*

Main category: cs.LG

TL;DR: 本文提出了一种名为HSO（Hierarchical-Schedule-Optimizer）的新型双层级优化框架，用于加速扩散概率模型的采样过程。该框架通过全局搜索和局部优化的交替迭代，在极低函数评估次数（NFE）下实现了最优的采样质量，且优化成本极低。


<details>
  <summary>Details</summary>
Motivation: 扩散概率模型虽然生成质量高，但采样过程缓慢。现有的调度优化方法难以同时满足有效性、自适应性、实用鲁棒性和计算效率四个核心原则，因此需要更先进的解决方案。

Method: HSO采用双层级优化框架：上层进行全局搜索以确定最优初始化策略，下层进行局部优化以细化调度。关键创新包括Midpoint Error Proxy（MEP）作为求解器无关的优化目标，以及Spacing-Penalized Fitness（SPF）函数确保鲁棒性。

Result: 在极低NFE（如5次）下，HSO在LAION-Aesthetics数据集上使用Stable Diffusion v2.1达到了11.94的FID，刷新了训练无关采样的最优性能。优化成本仅为8秒。

Conclusion: HSO提供了一种高效、实用的扩散模型加速范式，无需重新训练即可显著提升采样效率，适用于资源受限的场景。

Abstract: Diffusion probabilistic models have set a new standard for generative fidelity but are hindered by a slow iterative sampling process. A powerful training-free strategy to accelerate this process is Schedule Optimization, which aims to find an optimal distribution of timesteps for a fixed and small Number of Function Evaluations (NFE) to maximize sample quality. To this end, a successful schedule optimization method must adhere to four core principles: effectiveness, adaptivity, practical robustness, and computational efficiency. However, existing paradigms struggle to satisfy these principles simultaneously, motivating the need for a more advanced solution. To overcome these limitations, we propose the Hierarchical-Schedule-Optimizer (HSO), a novel and efficient bi-level optimization framework. HSO reframes the search for a globally optimal schedule into a more tractable problem by iteratively alternating between two synergistic levels: an upper-level global search for an optimal initialization strategy and a lower-level local optimization for schedule refinement. This process is guided by two key innovations: the Midpoint Error Proxy (MEP), a solver-agnostic and numerically stable objective for effective local optimization, and the Spacing-Penalized Fitness (SPF) function, which ensures practical robustness by penalizing pathologically close timesteps. Extensive experiments show that HSO sets a new state-of-the-art for training-free sampling in the extremely low-NFE regime. For instance, with an NFE of just 5, HSO achieves a remarkable FID of 11.94 on LAION-Aesthetics with Stable Diffusion v2.1. Crucially, this level of performance is attained not through costly retraining, but with a one-time optimization cost of less than 8 seconds, presenting a highly practical and efficient paradigm for diffusion model acceleration.

</details>


### [350] [Doubly Debiased Test-Time Prompt Tuning for Vision-Language Models](https://arxiv.org/abs/2511.11690)
*Fei Song,Yi Li,Rui Wang,Jiahuan Zhou,Changwen Zheng,Jiangmeng Li*

Main category: cs.LG

TL;DR: 本文提出了一种双去偏测试时提示调优方法，通过动态检索增强调制和可靠性感知提示优化，有效缓解视觉语言模型在零样本设置下的提示优化偏差问题。


<details>
  <summary>Details</summary>
Motivation: 测试时提示调优仅基于未标记测试数据可能导致提示优化偏差，造成模型输出过度自信但错误的结果，以及视觉与文本模态之间的错位。

Method: 1. 动态检索增强调制模块：使用测试图像特征检索高置信度知识并调制预测；2. 可靠性感知提示优化模块：结合置信度加权集成和跨模态一致性蒸馏进行正则化约束。

Result: 在15个基准数据集上的实验表明，该方法在自然分布偏移和跨数据集泛化场景下均优于基线方法。

Conclusion: 所提出的双去偏方法能有效缓解提示优化偏差，提升视觉语言模型在零样本设置下的泛化性能。

Abstract: Test-time prompt tuning for vision-language models has demonstrated impressive generalization capabilities under zero-shot settings. However, tuning the learnable prompts solely based on unlabeled test data may induce prompt optimization bias, ultimately leading to suboptimal performance on downstream tasks. In this work, we analyze the underlying causes of prompt optimization bias from both the model and data perspectives. In terms of the model, the entropy minimization objective typically focuses on reducing the entropy of model predictions while overlooking their correctness. This can result in overconfident yet incorrect outputs, thereby compromising the quality of prompt optimization. On the data side, prompts affected by optimization bias can introduce misalignment between visual and textual modalities, which further aggravates the prompt optimization bias. To this end, we propose a Doubly Debiased Test-Time Prompt Tuning method. Specifically, we first introduce a dynamic retrieval-augmented modulation module that retrieves high-confidence knowledge from a dynamic knowledge base using the test image feature as a query, and uses the retrieved knowledge to modulate the predictions. Guided by the refined predictions, we further develop a reliability-aware prompt optimization module that incorporates a confidence-based weighted ensemble and cross-modal consistency distillation to impose regularization constraints during prompt tuning. Extensive experiments across 15 benchmark datasets involving both natural distribution shifts and cross-datasets generalization demonstrate that our method outperforms baselines, validating its effectiveness in mitigating prompt optimization bias.

</details>


### [351] [Are LLMs The Way Forward? A Case Study on LLM-Guided Reinforcement Learning for Decentralized Autonomous Driving](https://arxiv.org/abs/2511.12751)
*Timur Anvar,Jeffrey Chen,Yuyan Wang,Rohan Chandra*

Main category: cs.LG

TL;DR: 本文研究了小型本地部署LLM（<14B参数）是否可以通过奖励塑造而非直接控制来支持自动驾驶高速公路场景。比较了纯RL、纯LLM和混合方法，发现混合方法在成功率和效率之间取得平衡，但LLM影响的方法存在系统性保守偏差。


<details>
  <summary>Details</summary>
Motivation: RL依赖良好指定的奖励函数，难以捕捉复杂语义和社会情境；纯LLM方法在安全关键场景中不稳定且依赖昂贵API。因此探索小型本地LLM通过奖励塑造来增强RL的可行性。

Method: 采用案例研究比较三种方法：纯RL、纯LLM直接控制、以及LLM通过评分状态-动作转换来塑造RL奖励的混合方法。测试时使用标准RL策略执行。

Result: 纯RL成功率73-89%且效率合理；纯LLM成功率可达94%但速度性能严重下降；混合方法介于两者之间。LLM影响的方法存在系统性保守偏差和模型依赖性变异。

Conclusion: 当前小型LLM在安全关键控制任务中存在重要局限性，尽管能提高成功率但带来保守偏差，不适合直接用于自动驾驶控制。

Abstract: Autonomous vehicle navigation in complex environments such as dense and fast-moving highways and merging scenarios remains an active area of research. A key limitation of RL is its reliance on well-specified reward functions, which often fail to capture the full semantic and social complexity of diverse, out-of-distribution situations. As a result, a rapidly growing line of research explores using Large Language Models (LLMs) to replace or supplement RL for direct planning and control, on account of their ability to reason about rich semantic context. However, LLMs present significant drawbacks: they can be unstable in zero-shot safety-critical settings, produce inconsistent outputs, and often depend on expensive API calls with network latency. This motivates our investigation into whether small, locally deployed LLMs (< 14B parameters) can meaningfully support autonomous highway driving through reward shaping rather than direct control. We present a case study comparing RL-only, LLM-only, and hybrid approaches, where LLMs augment RL rewards by scoring state-action transitions during training, while standard RL policies execute at test time. Our findings reveal that RL-only agents achieve moderate success rates (73-89%) with reasonable efficiency, LLM-only agents can reach higher success rates (up to 94%) but with severely degraded speed performance, and hybrid approaches consistently fall between these extremes. Critically, despite explicit efficiency instructions, LLM-influenced approaches exhibit systematic conservative bias with substantial model-dependent variability, highlighting important limitations of current small LLMs for safety-critical control tasks.

</details>


### [352] [Beyond saliency: enhancing explanation of speech emotion recognition with expert-referenced acoustic cues](https://arxiv.org/abs/2511.11691)
*Seham Nasr,Zhao Ren,David Johnson*

Main category: cs.LG

TL;DR: 本文提出了一种针对语音情感识别（SER）的可解释AI框架，通过量化显著区域内的声学线索来改进解释质量，将显著性映射与专家参考的声学标记联系起来。


<details>
  <summary>Details</summary>
Motivation: 当前基于显著性的方法虽然能突出语谱图区域，但无法显示这些区域是否对应有意义的声学情感标记，限制了解释的忠实性和可理解性。

Method: 提出一个框架，通过量化显著区域内的线索幅度来克服这些限制，明确连接显著性区域与理论驱动的声学情感线索。

Result: 在基准SER数据集上的实验表明，该方法通过明确连接显著区域与专家参考的声学特征，提高了解释质量。

Conclusion: 相比标准显著性方法，该方法提供了更易理解和可信的SER模型解释，是构建可信语音情感计算的重要基础步骤。

Abstract: Explainable AI (XAI) for Speech Emotion Recognition (SER) is critical for building transparent, trustworthy models. Current saliency-based methods, adapted from vision, highlight spectrogram regions but fail to show whether these regions correspond to meaningful acoustic markers of emotion, limiting faithfulness and interpretability. We propose a framework that overcomes these limitations by quantifying the magnitudes of cues within salient regions. This clarifies "what" is highlighted and connects it to "why" it matters, linking saliency to expert-referenced acoustic cues of speech emotions. Experiments on benchmark SER datasets show that our approach improves explanation quality by explicitly linking salient regions to theory-driven speech emotions expert-referenced acoustics. Compared to standard saliency methods, it provides more understandable and plausible explanations of SER models, offering a foundational step towards trustworthy speech-based affective computing.

</details>


### [353] [AnchorDS: Anchoring Dynamic Sources for Semantically Consistent Text-to-3D Generation](https://arxiv.org/abs/2511.11692)
*Jiayin Zhu,Linlin Yang,Yicong Li,Angela Yao*

Main category: cs.LG

TL;DR: 本文提出AnchorDS方法，通过将文本到3D优化重新表述为动态演化的源分布到固定目标分布的映射，解决了Score Distillation Sampling（SDS）中语义过平滑的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于优化的文本到3D方法将2D生成模型的指导视为静态，忽略了源动态，导致语义线索被抑制或合并，产生语义过平滑伪影。

Method: 将问题转化为双条件潜空间（文本提示和中间渲染图像），引入AnchorDS机制提供状态锚定指导，设计轻量级过滤策略和微调策略来优化锚点。

Result: AnchorDS产生更精细的细节、更自然的颜色和更强的语义一致性，特别是在复杂提示下，同时保持效率。

Conclusion: 大量实验表明，该方法在质量和效率上都优于先前方法，能够稳定生成并避免语义过平滑问题。

Abstract: Optimization-based text-to-3D methods distill guidance from 2D generative models via Score Distillation Sampling (SDS), but implicitly treat this guidance as static. This work shows that ignoring source dynamics yields inconsistent trajectories that suppress or merge semantic cues, leading to "semantic over-smoothing" artifacts. As such, we reformulate text-to-3D optimization as mapping a dynamically evolving source distribution to a fixed target distribution. We cast the problem into a dual-conditioned latent space, conditioned on both the text prompt and the intermediately rendered image. Given this joint setup, we observe that the image condition naturally anchors the current source distribution. Building on this insight, we introduce AnchorDS, an improved score distillation mechanism that provides state-anchored guidance with image conditions and stabilizes generation. We further penalize erroneous source estimates and design a lightweight filter strategy and fine-tuning strategy that refines the anchor with negligible overhead. AnchorDS produces finer-grained detail, more natural colours, and stronger semantic consistency, particularly for complex prompts, while maintaining efficiency. Extensive experiments show that our method surpasses previous methods in both quality and efficiency.

</details>


### [354] [Toward Dignity-Aware AI: Next-Generation Elderly Monitoring from Fall Detection to ADL](https://arxiv.org/abs/2511.11696)
*Xun Shao,Aoba Otani,Yuto Hirasuka,Runji Cai,Seng W. Loke*

Main category: cs.LG

TL;DR: 本文提出了一种新一代的老年人监测系统，旨在从跌倒检测扩展到更广泛的日常生活活动识别，重点关注隐私保护、边缘部署和联邦学习技术。


<details>
  <summary>Details</summary>
Motivation: 当前老年人监测系统主要局限于跌倒检测，无法全面理解日常活动模式。随着老龄化社会的发展，需要更智能、隐私保护的系统来支持老年人的独立生活和尊严。

Method: 使用SISFall数据集及其GAN增强变体进行可行性验证，将跌倒检测作为代理任务；探索联邦学习在非独立同分布条件下的应用；在Jetson Orin Nano设备上进行嵌入式部署测试。

Result: 初步验证了技术可行性，展示了在边缘设备上部署联邦学习系统的可能性，为全面ADL监测奠定了基础。

Conclusion: 该研究标志着从单一任务检测向全面日常活动识别的转变，提出了应对领域偏移、数据稀缺和隐私风险等挑战的路线图，为人本化的老年人护理AI提供了早期证据和发展方向。

Abstract: This position paper envisions a next-generation elderly monitoring system that moves beyond fall detection toward the broader goal of Activities of Daily Living (ADL) recognition. Our ultimate aim is to design privacy-preserving, edge-deployed, and federated AI systems that can robustly detect and understand daily routines, supporting independence and dignity in aging societies. At present, ADL-specific datasets are still under collection. As a preliminary step, we demonstrate feasibility through experiments using the SISFall dataset and its GAN-augmented variants, treating fall detection as a proxy task. We report initial results on federated learning with non-IID conditions, and embedded deployment on Jetson Orin Nano devices. We then outline open challenges such as domain shift, data scarcity, and privacy risks, and propose directions toward full ADL monitoring in smart-room environments. This work highlights the transition from single-task detection to comprehensive daily activity recognition, providing both early evidence and a roadmap for sustainable and human-centered elderly care AI.

</details>


### [355] [Benchmarking GNNs for OOD Materials Property Prediction with Uncertainty Quantification](https://arxiv.org/abs/2511.11697)
*Liqin Tan,Pin Chen,Menghan Liu,Xiean Wang,Jianhuan Cen,Qingsong Zou*

Main category: cs.LG

TL;DR: MatUQ是一个评估图神经网络在材料属性预测中分布外泛化能力和不确定性量化的基准框架，包含1375个OOD任务，提出新的结构感知分割策略SOAP-LOCO和不确定性度量D-EviU。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏针对材料科学中分布外预测和不确定性量化的标准化评估基准，需要系统评估GNN模型在真实材料发现场景中的可靠性。

Method: 构建包含6个材料数据集的1375个OOD预测任务，使用5种OOD分割方法和新提出的SOAP-LOCO策略。评估12个代表性GNN模型，采用蒙特卡洛Dropout和深度证据回归的统一训练协议，并提出新的不确定性度量D-EviU。

Result: 不确定性感知训练平均减少70.6%的预测误差；没有单一模型在所有任务中表现最佳，早期模型如SchNet和ALIGNN仍具竞争力，新模型在特定属性上表现更优；D-EviU与预测误差相关性最强。

Conclusion: MatUQ为材料发现中的模型选择提供了实用指导，强调了不确定性量化在分布偏移场景下的重要性，证明了不同模型在不同材料属性上的互补优势。

Abstract: We present MatUQ, a benchmark framework for evaluating graph neural networks (GNNs) on out-of-distribution (OOD) materials property prediction with uncertainty quantification (UQ). MatUQ comprises 1,375 OOD prediction tasks constructed from six materials datasets using five OFM-based and a newly proposed structure-aware splitting strategy, SOAP-LOCO, which captures local atomic environments more effectively. We evaluate 12 representative GNN models under a unified uncertainty-aware training protocol that combines Monte Carlo Dropout and Deep Evidential Regression (DER), and introduce a novel uncertainty metric, D-EviU, which shows the strongest correlation with prediction errors in most tasks. Our experiments yield two key findings. First, the uncertainty-aware training approach significantly improves model prediction accuracy, reducing errors by an average of 70.6\% across challenging OOD scenarios. Second, the benchmark reveals that no single model dominates universally: earlier models such as SchNet and ALIGNN remain competitive, while newer models like CrystalFramer and SODNet demonstrate superior performance on specific material properties. These results provide practical insights for selecting reliable models under distribution shifts in materials discovery.

</details>


### [356] [Moirai 2.0: When Less Is More for Time Series Forecasting](https://arxiv.org/abs/2511.11698)
*Chenghao Liu,Taha Aksu,Juncheng Liu,Xu Liu,Hanshu Yan,Quang Pham,Doyen Sahoo,Caiming Xiong,Silvio Savarese,Junnan Li*

Main category: cs.LG

TL;DR: Moirai 2.0是一个基于解码器架构的时间序列基础模型，采用分位数预测和多令牌预测技术，在Gift-Eval基准测试中表现优异，相比前代模型速度提升2倍、模型大小缩小30倍，同时性能更好。


<details>
  <summary>Details</summary>
Motivation: 开发一个更高效、更准确的时间序列预测模型，通过简化架构和改进预测方法来解决前代模型复杂性和效率问题。

Method: 采用解码器专用架构、单补丁输入和分位数损失函数，替换了前代的掩码编码器训练、多补丁输入和混合分布输出。使用多令牌预测和递归多分位数解码技术。

Result: 在Gift-Eval基准测试中排名靠前，相比Moirai 1.0-Large速度提升2倍、模型大小缩小30倍且性能更优。模型性能随参数增加而趋于平稳，在长时预测中表现下降。

Conclusion: Moirai 2.0在准确性、速度和模型大小之间取得了良好平衡，解码器架构和递归多分位数解码是性能提升的关键因素，未来需要在数据扩展和长时建模方面继续研究。

Abstract: We introduce Moirai 2.0, a decoder-only time-series foundation model trained on a new corpus of 36M series. The model adopts quantile forecasting and multi-token prediction, improving both probabilistic accuracy and inference efficiency. On the Gift-Eval benchmark, it ranks among the top pretrained models while achieving a strong trade-off between accuracy, speed, and model size. Compared to Moirai 1.0, Moirai 2.0 replaces masked-encoder training, multi-patch inputs, and mixture-distribution outputs with a simpler decoder-only architecture, single patch, and quantile loss. Ablation studies isolate these changes -- showing that the decoder-only backbone along with recursive multi-quantile decoding contribute most to the gains. Additional experiments show that Moirai 2.0 outperforms larger models from the same family and exhibits robust domain-level results. In terms of efficiency and model size, Moirai 2.0 is twice as fast and thirty times smaller than its prior best version, Moirai 1.0-Large, while also performing better. Model performance plateaus with increasing parameter count and declines at longer horizons, motivating future work on data scaling and long-horizon modeling. We release code and evaluation details to support further research.

</details>


### [357] [Tighter Truncated Rectangular Prism Approximation for RNN Robustness Verification](https://arxiv.org/abs/2511.11699)
*Xingqi Lin,Liangyu Chen,Min Wu,Min Zhang,Zhenbing Zeng*

Main category: cs.LG

TL;DR: 本文提出了一种新的RNN鲁棒性验证方法DeepPrism，通过三维截断矩形棱柱对Hadamard积产生的非线性曲面进行紧致过近似，显著提高了验证精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法对非线性激活函数进行线性约束过近似时，采用单独线性边界平面，可能导致显著过估计和验证精度降低。

Method: 提出使用两个线性松弛平面形成的截断矩形棱柱来紧致包围Hadamard积产生的三维非线性曲面，并采用细化驱动方法最小化其体积和表面积以实现更紧致的过近似。

Result: 实验结果表明，DeepPrism在图像分类、语音识别和情感分析等任务中相比最先进方法有显著改进。

Conclusion: DeepPrism方法通过更紧致的非线性曲面过近似，有效提高了RNN鲁棒性验证的准确性。

Abstract: Robustness verification is a promising technique for rigorously proving Recurrent Neural Networks (RNNs) robustly. A key challenge is to over-approximate the nonlinear activation functions with linear constraints, which can transform the verification problem into an efficiently solvable linear programming problem. Existing methods over-approximate the nonlinear parts with linear bounding planes individually, which may cause significant over-estimation and lead to lower verification accuracy. In this paper, in order to tightly enclose the three-dimensional nonlinear surface generated by the Hadamard product, we propose a novel truncated rectangular prism formed by two linear relaxation planes and a refinement-driven method to minimize both its volume and surface area for tighter over-approximation. Based on this approximation, we implement a prototype DeepPrism for RNN robustness verification. The experimental results demonstrate that \emph{DeepPrism} has significant improvement compared with the state-of-the-art approaches in various tasks of image classification, speech recognition and sentiment analysis.

</details>


### [358] [Bayesian Neural Networks with Monte Carlo Dropout for Probabilistic Electricity Price Forecasting](https://arxiv.org/abs/2511.11701)
*Abhinav Das,Stephan Schlüter*

Main category: cs.LG

TL;DR: 本文提出了一个使用贝叶斯神经网络和蒙特卡洛dropout的概率性电价预测框架，该框架通过为每天每个小时训练独立模型来捕捉昼夜模式，在点预测和区间预测方面均优于传统基准模型。


<details>
  <summary>Details</summary>
Motivation: 在放松管制的电力市场中，准确的电价预测对战略决策至关重要。传统的点预测方法往往无法捕捉固有的不确定性，限制了其在风险管理中的实用性。

Method: 使用贝叶斯神经网络（BNNs）结合蒙特卡洛（MC）dropout技术，为每天每个小时训练独立的预测模型，以捕捉电价昼夜波动模式。

Result: 与GARCHX模型和LASSO估计的自回归模型（LEAR）等基准模型相比，所提出的模型在点预测和区间预测方面表现更优。

Conclusion: 该工作为在能源市场预测中利用概率性神经网络模型提供了参考，证明了BNNs在电价不确定性量化方面的有效性。

Abstract: Accurate electricity price forecasting is critical for strategic decision-making in deregulated electricity markets, where volatility stems from complex supply-demand dynamics and external factors. Traditional point forecasts often fail to capture inherent uncertainties, limiting their utility for risk management. This work presents a framework for probabilistic electricity price forecasting using Bayesian neural networks (BNNs) with Monte Carlo (MC) dropout, training separate models for each hour of the day to capture diurnal patterns. A critical assessment and comparison with the benchmark model, namely: generalized autoregressive conditional heteroskedasticity with exogenous variable (GARCHX) model and the LASSO estimated auto-regressive model (LEAR), highlights that the proposed model outperforms the benchmark models in terms of point prediction and intervals. This work serves as a reference for leveraging probabilistic neural models in energy market predictions.

</details>


### [359] [Simple Vision-Language Math Reasoning via Rendered Text](https://arxiv.org/abs/2511.11704)
*Matvey Skripkin,Elizaveta Goncharova,Andrey Kuznetsov*

Main category: cs.LG

TL;DR: 提出了一种轻量级但有效的训练流程，通过将LaTeX方程渲染为图像并与结构化思维链提示配对，训练视觉语言模型解决数学问题。


<details>
  <summary>Details</summary>
Motivation: 当前数学问题求解需要复杂的多模态架构，本文旨在通过简单的文本到视觉增强方法，使紧凑的多模态架构能够达到最先进的推理精度。

Method: 将LaTeX编码的方程渲染成图像，并与结构化的思维链提示配对，构建训练数据。通过系统消融实验分析渲染保真度和提示设计对性能的影响。

Result: 该方法在广泛使用的基准测试中持续匹配或超越了开源和专有的数学专用视觉语言求解器，同时在MMMU、ChartQA和DocVQA等任务上获得高达20%的性能提升，保持了广泛的通用领域能力。

Conclusion: 尽管方法简单，但渲染保真度和提示设计是性能的主要驱动因素，证明了文本到视觉增强在数学问题求解中的有效性。

Abstract: We present a lightweight yet effective pipeline for training vision-language models to solve math problems by rendering LaTeX encoded equations into images and pairing them with structured chain-of-thought prompts. This simple text-to-vision augmentation enables compact multimodal architectures to achieve state-of-the-art reasoning accuracy. Through systematic ablations, we find that rendering fidelity and prompt design are the primary drivers of performance. Despite its simplicity, our approach consistently matches or surpasses both open-source and proprietary math-focused vision-language solvers on widely used benchmarks, while preserving broad general-domain competence - showing gains on tasks such as MMMU, ChartQA, and DocVQA of up to 20%.

</details>


### [360] [Multimodal ML: Quantifying the Improvement of Calorie Estimation Through Image-Text Pairs](https://arxiv.org/abs/2511.11705)
*Arya Narang*

Main category: cs.LG

TL;DR: 研究通过结合菜品名称的文本信息，将卡路里估计的MAE从84.76 kcal降低到83.70 kcal，实现了1.25%的改进


<details>
  <summary>Details</summary>
Motivation: 探究短文本输入（菜品名称）能否相比仅使用图像的基线模型显著改善卡路里估计精度

Method: 使用TensorFlow库和Nutrition5k数据集，训练仅使用图像的CNN模型和同时接受文本和图像输入的多模态CNN模型

Result: 多模态模型将卡路里估计的MAE降低了1.06 kcal（从84.76 kcal到83.70 kcal），改善幅度为1.25%

Conclusion: 短文本输入确实能够改善卡路里估计，但改进幅度相对较小

Abstract: This paper determines the extent to which short textual inputs (in this case, names of dishes) can improve calorie estimation compared to an image-only baseline model and whether any improvements are statistically significant. Utilizes the TensorFlow library and the Nutrition5k dataset (curated by Google) to train both an image-only CNN and multimodal CNN that accepts both text and an image as input. The MAE of calorie estimations was reduced by 1.06 kcal from 84.76 kcal to 83.70 kcal (1.25% improvement) when using the multimodal model.

</details>


### [361] [Context-Aware Multimodal Representation Learning for Spatio-Temporally Explicit Environmental modelling](https://arxiv.org/abs/2511.11706)
*Julia Peters,Karin Mora,Miguel D. Mahecha,Chaonan Ji,David Montero,Clemens Mosig,Guido Kraemer*

Main category: cs.LG

TL;DR: 提出了一种统一的地球观测多模态表示学习框架，能够在高时空分辨率下整合不同传感器数据，克服现有模型固定时空尺度的限制。


<details>
  <summary>Details</summary>
Motivation: 现有地球观测基础模型通常在固定空间或时间尺度上运行，限制了需要高空间细节和高时间保真度的生态分析应用。

Method: 采用两阶段设计：首先独立建模每个传感器以捕获特定特征，然后将表示融合到共享模型中；使用Sentinel-1和Sentinel-2作为代表性模态，实现10米分辨率和无云采集频率。

Result: 学习到的嵌入在异质景观中表现出高空间和语义一致性；在总初级生产力建模的定量评估中，编码了生态学有意义的模式并保持了足够的时间保真度。

Conclusion: 该框架为需要不同空间和时间分辨率的环境应用提供了灵活、分析就绪的表示学习方法。

Abstract: Earth observation (EO) foundation models have emerged as an effective approach to derive latent representations of the Earth system from various remote sensing sensors. These models produce embeddings that can be used as analysis-ready datasets, enabling the modelling of ecosystem dynamics without extensive sensor-specific preprocessing. However, existing models typically operate at fixed spatial or temporal scales, limiting their use for ecological analyses that require both fine spatial detail and high temporal fidelity. To overcome these limitations, we propose a representation learning framework that integrates different EO modalities into a unified feature space at high spatio-temporal resolution. We introduce the framework using Sentinel-1 and Sentinel-2 data as representative modalities. Our approach produces a latent space at native 10 m resolution and the temporal frequency of cloud-free Sentinel-2 acquisitions. Each sensor is first modeled independently to capture its sensor-specific characteristics. Their representations are then combined into a shared model. This two-stage design enables modality-specific optimisation and easy extension to new sensors, retaining pretrained encoders while retraining only fusion layers. This enables the model to capture complementary remote sensing data and to preserve coherence across space and time. Qualitative analyses reveal that the learned embeddings exhibit high spatial and semantic consistency across heterogeneous landscapes. Quantitative evaluation in modelling Gross Primary Production reveals that they encode ecologically meaningful patterns and retain sufficient temporal fidelity to support fine-scale analyses. Overall, the proposed framework provides a flexible, analysis-ready representation learning approach for environmental applications requiring diverse spatial and temporal resolutions.

</details>


### [362] [FSC-Net: Fast-Slow Consolidation Networks for Continual Learning](https://arxiv.org/abs/2511.11707)
*Mohamed El Gorrim*

Main category: cs.LG

TL;DR: FSC-Net提出双网络架构（快慢网络）来解决持续学习中的灾难性遗忘问题，通过分离快速任务学习和渐进知识整合，在Split-MNIST和Split-CIFAR-10上显著提升了性能


<details>
  <summary>Details</summary>
Motivation: 受神经科学中记忆巩固机制的启发，旨在解决神经网络在持续学习新任务时遗忘先前知识的灾难性遗忘问题

Method: 采用双网络架构：快速网络（NN1）用于即时适应新任务，慢速网络（NN2）通过蒸馏和回放进行知识整合。研究发现纯回放策略优于蒸馏方法

Result: 在Split-MNIST上达到91.71%保留准确率（+4.27pp提升），在Split-CIFAR-10上达到33.31%保留准确率（+8.20pp提升），但绝对性能仍低于随机预期

Conclusion: 双时间尺度整合机制而非架构复杂性是缓解灾难性遗忘的关键，简单MLP架构表现优于复杂门控变体，未来需要更强骨干网络

Abstract: Continual learning remains challenging due to catastrophic forgetting, where neural networks lose previously acquired knowledge when learning new tasks. Inspired by memory consolidation in neuroscience, we propose FSC-Net (Fast-Slow Consolidation Networks), a dual-network architecture that separates rapid task learning from gradual knowledge consolidation. Our method employs a fast network (NN1) for immediate adaptation to new tasks and a slow network (NN2) that consolidates knowledge through distillation and replay. Within the family of MLP-based NN1 variants we evaluated, consolidation effectiveness is driven more by methodology than architectural embellishments -- a simple MLP outperforms more complex similarity-gated variants by 1.2pp. Through systematic hyperparameter analysis, we observed empirically that pure replay without distillation during consolidation achieves superior performance, consistent with the hypothesis that distillation from the fast network introduces recency bias. On Split-MNIST (30 seeds), FSC-Net achieves 91.71% +/- 0.62% retention accuracy, a +4.27pp gain over the fast network alone (87.43% +/- 1.27%, paired t=23.585, p < 1e-10). On Split-CIFAR-10 (5 seeds), our method achieves 33.31% +/- 0.38% retention with an +8.20pp gain over the fast network alone (25.11% +/- 1.61%, paired t=9.75, p < 1e-3), demonstrating +8.20pp gain, though absolute performance (33.31%) remains modest and below random expectation, highlighting need for stronger backbones. Our results provide empirical evidence that the dual-timescale consolidation mechanism, rather than architectural complexity, is central to mitigating catastrophic forgetting in this setting.

</details>


### [363] [Which Sparse Autoencoder Features Are Real? Model-X Knockoffs for False Discovery Rate Control](https://arxiv.org/abs/2511.11711)
*Tsogt-Ochir Enkhbayar*

Main category: cs.LG

TL;DR: 本文提出将Model-X knockoffs方法应用于稀疏自编码器（SAE）特征选择，通过knockoff+控制错误发现率（FDR），为可解释性特征发现提供统计保证。


<details>
  <summary>Details</summary>
Motivation: 稀疏自编码器在识别神经网络可解释特征时面临挑战，难以区分真实计算模式和错误相关性，需要更可靠的特征选择方法。

Method: 使用高斯替代模型作为潜在分布，结合Model-X knockoffs和knockoff+方法，在Pythia-70M模型的情感分类任务中分析512个高活性SAE潜在特征。

Result: 在目标FDR q=0.1下选择了129个特征，所选特征与非选择特征在knockoff统计量上显示出5.40倍的分离度，表明约25%的潜在特征携带任务相关信号。

Conclusion: 该方法将SAE与多重测试感知推断相结合，为可靠的特征发现提供了可重现的原则性框架，推动了机制可解释性的基础研究。

Abstract: Although sparse autoencoders (SAEs) are crucial for identifying interpretable features in neural networks, it is still challenging to distinguish between real computational patterns and erroneous correlations. We introduce Model-X knockoffs to SAE feature selection, using knock-off+ to control the false discovery rate (FDR) with finite-sample guarantees under the standard Model-X assumptions (in our case, via a Gaussian surrogate for the latent distribution). We select 129 features at a target FDR q=0.1 after analyzing 512 high-activity SAE latents for sentiment classification using Pythia-70M. About 25% of the latents under examination carry task-relevant signal, whereas 75% do not, according to the chosen set, which displays a 5.40x separation in knockoff statistics compared to non-selected features. Our method offers a re-producible and principled framework for reliable feature discovery by combining SAEs with multiple-testing-aware inference, advancing the foundations of mechanistic interpretability.

</details>


### [364] [Reasoning: From Reflection to Solution](https://arxiv.org/abs/2511.11712)
*Zixi Li*

Main category: cs.LG

TL;DR: 该论文提出推理是状态空间中迭代应用算子并收敛到固定点的过程，并通过OpenLM架构在OpenXOR问题上实现76%的准确率，而现有LLMs准确率为0%。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型是否真正学会了推理，还是仅仅在模式匹配推理痕迹。需要理解推理的本质要求并构建能够提供真正推理能力的架构。

Method: 提出推理作为状态空间中算子迭代应用的理论框架（OpenOperator），并开发了基于该理论的OpenLM架构来解决OpenXOR等推理问题。

Result: OpenLM在OpenXOR问题上达到76%的准确率，显著优于现有LLMs的0%准确率，证明了该推理架构的有效性。

Conclusion: 推理需要特定的架构支持，而不仅仅是模式匹配。论文提出的状态空间算子迭代方法为构建真正具有推理能力的系统提供了理论基础和实践路径。

Abstract: What is reasoning? This question has driven centuries of philosophical inquiry, from Aristotle's syllogisms to modern computational complexity theory. In the age of large language models achieving superhuman performance on benchmarks like GSM8K (95\% accuracy) and HumanEval (90\% pass@1), we must ask: have these systems learned to \emph{reason}, or have they learned to \emph{pattern-match over reasoning traces}?
  This paper argues for a specific answer: \textbf{reasoning is iterative operator application in state spaces, converging to fixed points}. This definition is not merely philosophical -- it has concrete architectural implications that explain both the failures of current systems and the path to genuine reasoning capabilities.
  Our investigation begins with a puzzle (OpenXOR), progresses through theory (OpenOperator), and culminates in a working solution (OpenLM) that achieves 76\% accuracy where state-of-the-art LLMs achieve 0\%. This is not about criticizing existing systems, but about \emph{understanding what reasoning requires} and \emph{building architectures that provide it}.

</details>


### [365] [Federated Learning for Pediatric Pneumonia Detection: Enabling Collaborative Diagnosis Without Sharing Patient Data](https://arxiv.org/abs/2511.11714)
*Daniel M. Jimenez-Gutierrez,Enrique Zuazua,Joaquin Del Rio,Oleksii Sliusarenko,Xabi Uribe-Etxebarria*

Main category: cs.LG

TL;DR: 本文评估了使用Sherpa.ai FL平台的联邦学习，让多个医院在不共享数据的情况下协作训练肺炎X光分类器，相比单医院模型性能提升47.5%-50%，达到0.900准确率和0.966 ROC-AUC。


<details>
  <summary>Details</summary>
Motivation: 早期准确检测肺炎对临床治疗至关重要，但全球数据分布不均、医院间差异大、隐私法规严格，使得数据集中化不现实，需要隐私保护的协作学习方案。

Method: 使用联邦学习平台，多个医院在保持数据本地化的前提下协作训练CXR肺炎分类器，模拟真实世界的非独立同分布数据场景。

Result: 联邦学习模型性能显著优于单医院模型，准确率从0.610提升到0.900，ROC-AUC从0.644提升到0.966，且无需传输任何患者数据。

Conclusion: 联邦学习能够实现高性能、可泛化、安全私密的肺炎检测，特别适用于罕见疾病和低数据领域，是医疗AI发展的突破性技术。

Abstract: Early and accurate pneumonia detection from chest X-rays (CXRs) is clinically critical to expedite treatment and isolation, reduce complications, and curb unnecessary antibiotic use. Although artificial intelligence (AI) substantially improves CXR-based detection, development is hindered by globally distributed data, high inter-hospital variability, and strict privacy regulations (e.g., HIPAA, GDPR) that make centralization impractical. These constraints are compounded by heterogeneous imaging protocols, uneven data availability, and the costs of transferring large medical images across geographically dispersed sites.
  In this paper, we evaluate Federated Learning (FL) using the Sherpa.ai FL platform, enabling multiple hospitals (nodes) to collaboratively train a CXR classifier for pneumonia while keeping data in place and private. Using the Pediatric Pneumonia Chest X-ray dataset, we simulate cross-hospital collaboration with non-independent and non-identically distributed (non-IID) data, reproducing real-world variability across institutions and jurisdictions. Our experiments demonstrate that collaborative and privacy-preserving training across multiple hospitals via FL led to a dramatic performance improvement achieving 0.900 Accuracy and 0.966 ROC-AUC, corresponding to 47.5% and 50.0% gains over single-hospital models (0.610; 0.644), without transferring any patient CXR. These results indicate that FL delivers high-performing, generalizable, secure and private pneumonia detection across healthcare networks, with data kept local. This is especially relevant for rare diseases, where FL enables secure multi-institutional collaboration without data movement, representing a breakthrough for accelerating diagnosis and treatment development in low-data domains.

</details>


### [366] [Multiscale Grassmann Manifolds for Single-Cell Data Analysis](https://arxiv.org/abs/2511.11717)
*Xiang Xiang Wang,Sean Cottrell,Guo-Wei Wei*

Main category: cs.LG

TL;DR: 该论文提出了一种基于Grassmann流形的多尺度框架，用于单细胞数据分析，通过整合机器学习和子空间几何学来捕捉细胞异质性的内在相关性和多尺度几何结构。


<details>
  <summary>Details</summary>
Motivation: 传统的单细胞数据分析方法将每个细胞表示为欧几里得空间中的向量，这限制了捕捉内在相关性和多尺度几何结构的能力。

Method: 提出基于Grassmann流形的多尺度框架，通过生成多个表示尺度的嵌入，将不同几何视角的特征整合到统一的Grassmann流形中，并引入基于幂的尺度采样函数来控制尺度选择和信息平衡。

Result: 在九个基准单细胞RNA-seq数据集上的实验表明，该方法能有效保留有意义的结构并提供稳定的聚类性能，特别适用于中小型数据集。

Conclusion: Grassmann流形为单细胞数据分析提供了一个连贯且信息丰富的基础。

Abstract: Single-cell data analysis seeks to characterize cellular heterogeneity based on high-dimensional gene expression profiles. Conventional approaches represent each cell as a vector in Euclidean space, which limits their ability to capture intrinsic correlations and multiscale geometric structures. We propose a multiscale framework based on Grassmann manifolds that integrates machine learning with subspace geometry for single-cell data analysis. By generating embeddings under multiple representation scales, the framework combines their features from different geometric views into a unified Grassmann manifold. A power-based scale sampling function is introduced to control the selection of scales and balance in- formation across resolutions. Experiments on nine benchmark single-cell RNA-seq datasets demonstrate that the proposed approach effectively preserves meaningful structures and provides stable clustering performance, particularly for small to medium-sized datasets. These results suggest that Grassmann manifolds offer a coherent and informative foundation for analyzing single cell data.

</details>


### [367] [Fast 3D Surrogate Modeling for Data Center Thermal Management](https://arxiv.org/abs/2511.11722)
*Soumyendu Sarkar,Antonio Guillen-Perez,Zachariah J Carmichael,Avisek Naug,Refik Mert Cam,Vineet Gundecha,Ashwin Ramesh Babu,Sahand Ghorbanpour,Ricardo Luna Gutierrez*

Main category: cs.LG

TL;DR: 本文提出了一种基于视觉的替代建模框架，用于数据中心3D温度场的实时预测，实现了高达20,000倍的加速比和7%的节能效果。


<details>
  <summary>Details</summary>
Motivation: 传统CFD热求解器计算成本高且需要专家设置，无法满足数据中心实时温度预测的需求，而准确的温度预测对节能减排和运行效率至关重要。

Method: 开发了基于3D体素化表示的视觉替代建模框架，评估了多种架构包括3D CNN U-Net变体、3D傅里叶神经算子和3D视觉Transformer，将热输入映射到高保真热图。

Result: 替代模型在数据中心配置间具有良好泛化能力，实现高达20,000倍加速（数百毫秒vs数小时），能够快速准确估计热点和温度分布。

Conclusion: 该框架支持实时冷却控制和负载重分配，带来显著的节能（7%）和碳足迹减少，为数据中心可持续运行提供了有效解决方案。

Abstract: Reducing energy consumption and carbon emissions in data centers by enabling real-time temperature prediction is critical for sustainability and operational efficiency. Achieving this requires accurate modeling of the 3D temperature field to capture airflow dynamics and thermal interactions under varying operating conditions. Traditional thermal CFD solvers, while accurate, are computationally expensive and require expert-crafted meshes and boundary conditions, making them impractical for real-time use. To address these limitations, we develop a vision-based surrogate modeling framework that operates directly on a 3D voxelized representation of the data center, incorporating server workloads, fan speeds, and HVAC temperature set points. We evaluate multiple architectures, including 3D CNN U-Net variants, a 3D Fourier Neural Operator, and 3D vision transformers, to map these thermal inputs to high-fidelity heat maps. Our results show that the surrogate models generalize across data center configurations and achieve up to 20,000x speedup (hundreds of milliseconds vs. hours). This fast and accurate estimation of hot spots and temperature distribution enables real-time cooling control and workload redistribution, leading to substantial energy savings (7\%) and reduced carbon footprint.

</details>


### [368] [Optimizing Input of Denoising Score Matching is Biased Towards Higher Score Norm](https://arxiv.org/abs/2511.11727)
*Tongda Xu*

Main category: cs.LG

TL;DR: 本文指出在扩散模型中使用去噪分数匹配优化条件输入会破坏其与精确分数匹配的等价性，导致分数范数偏高的偏差问题，并影响多个领域的研究工作。


<details>
  <summary>Details</summary>
Motivation: 许多近期研究利用去噪分数匹配来优化扩散模型的条件输入，但作者发现这种方法存在理论偏差问题，需要系统分析其对不同应用领域的影响。

Method: 通过理论分析和实验验证，证明去噪分数匹配在优化条件输入时会破坏与精确分数匹配的等价性，并观察在数据分布优化时出现的类似偏差。

Result: 发现这种偏差会导致更高的分数范数，并影响包括自回归生成的MAR、图像压缩的PerCo和文本到3D生成的DreamFusion等多个领域的工作。

Conclusion: 去噪分数匹配在优化条件输入时存在系统性偏差，这一发现对广泛使用该技术的多个应用领域具有重要警示意义。

Abstract: Many recent works utilize denoising score matching to optimize the conditional input of diffusion models. In this workshop paper, we demonstrate that such optimization breaks the equivalence between denoising score matching and exact score matching. Furthermore, we show that this bias leads to higher score norm. Additionally, we observe a similar bias when optimizing the data distribution using a pre-trained diffusion model. Finally, we discuss the wide range of works across different domains that are affected by this bias, including MAR for auto-regressive generation, PerCo for image compression, and DreamFusion for text to 3D generation.

</details>


### [369] [Physics-Informed Neural ODEs with Scale-Aware Residuals for Learning Stiff Biophysical Dynamics](https://arxiv.org/abs/2511.11734)
*Kamalpreet Singh Kainth,Prathamesh Dinesh Joshi,Raj Abhijit Dandekar,Rajat Dandekar,Sreedat Panat*

Main category: cs.LG

TL;DR: 提出了PI-NODE-SR框架，通过尺度感知残差和低阶显式求解器解决刚性生物物理系统建模问题，在有限迭代预算下实现稳定训练和准确预测


<details>
  <summary>Details</summary>
Motivation: 标准神经微分方程和物理信息变体在建模刚性生物物理系统时不可靠，需要大量迭代且可能收敛到次优解，无法保持振荡频率或振幅

Method: 结合低阶显式求解器（Heun方法）和残差归一化，平衡不同时间尺度状态变量的贡献，避免依赖计算昂贵的隐式求解器

Result: 在Hodgkin-Huxley方程上，从单个振荡学习并外推超过100ms，准确捕捉振荡频率和振幅，恢复门控变量中的尖锐亚阈值曲率等形态特征

Conclusion: PI-NODE-SR相对于基线神经ODE和PINNs一致减少长期误差，为稳定高效学习刚性生物动力学提供了原则性途径

Abstract: Neural differential equations offer a powerful framework for modeling continuous-time dynamics, but forecasting stiff biophysical systems remains unreliable. Standard Neural ODEs and physics informed variants often require orders of magnitude more iterations, and even then may converge to suboptimal solutions that fail to preserve oscillatory frequency or amplitude. We introduce PhysicsInformed Neural ODEs with with Scale-Aware Residuals (PI-NODE-SR), a framework that combines a low-order explicit solver (Heun method) residual normalisation to balance contributions between state variables evolving on disparate timescales. This combination stabilises training under realistic iteration budgets and avoids reliance on computationally expensive implicit solvers. On the Hodgkin-Huxley equations, PI-NODE-SR learns from a single oscillation simulated with a stiff solver (Rodas5P) and extrapolates beyond 100 ms, capturing both oscillation frequency and near-correct amplitudes. Remarkably, end-to-end learning of the vector field enables PI-NODE-SR to recover morphological features such as sharp subthreshold curvature in gating variables that are typically reserved for higher-order solvers, suggesting that neural correction can offset numerical diffusion. While performance remains sensitive to initialisation, PI-NODE-SR consistently reduces long-horizon errors relative to baseline Neural-ODEs and PINNs, offering a principled route to stable and efficient learning of stiff biological dynamics.

</details>


### [370] [KAN/H: Kolmogorov-Arnold Network using Haar-like bases](https://arxiv.org/abs/2511.11736)
*Susumu Katayama*

Main category: cs.LG

TL;DR: KAN/H是Kolmogorov-Arnold网络的一个变体，使用Haar变体基系统替代B样条，兼具全局和局部基函数，应用于函数逼近和MNIST分类，无需大量问题特定的超参数调优。


<details>
  <summary>Details</summary>
Motivation: 开发一种更高效的神经网络架构，减少对超参数调优的依赖，提高模型在函数逼近和图像分类任务中的实用性。

Method: 提出KAN/H网络，采用Haar变体基系统（包含全局和局部基）替代传统的B样条基函数，应用于函数逼近问题和MNIST数据集。

Result: KAN/H在函数逼近和MNIST分类任务中表现良好，且不需要大部分问题特定的超参数调优。

Conclusion: KAN/H通过使用Haar基系统实现了有效的函数逼近和分类性能，显著减少了超参数调优的需求，展示了其在实际应用中的潜力。

Abstract: This paper proposes KAN/H, a variant of Kolmogorov-Arnold Network (KAN) that uses a Haar-variant basis system having both global and local bases instead of B-spline. The resulting algorithm is applied to function approximation problems and MNIST. We show that it does not require most of the problem-specific hyper-parameter tunings.

</details>


### [371] [DK-Root: A Joint Data-and-Knowledge-Driven Framework for Root Cause Analysis of QoE Degradations in Mobile Networks](https://arxiv.org/abs/2511.11737)
*Qizhe Li,Haolong Chen,Jiansheng Li,Shuqi Chai,Xuan Li,Yuzhou Hou,Xinhua Shao,Fangfang Li,Kaifeng Han,Guangxu Zhu*

Main category: cs.LG

TL;DR: DK-Root是一个联合数据和知识驱动的框架，通过对比表示学习和条件扩散增强，解决移动网络QoE根因分析中标注稀缺和噪声标签的问题。


<details>
  <summary>Details</summary>
Motivation: 移动网络QoE劣化根因诊断面临跨层KPI交互复杂和专家标注稀缺的挑战，基于规则的启发式方法生成的标签噪声大且粒度粗，限制了纯数据驱动方法的准确性。

Method: 1) 使用对比表示学习预训练编码器，通过监督对比目标去噪规则标签；2) 引入类条件扩散模型生成保持根因语义的KPI序列，通过控制反向扩散步骤产生强弱增强；3) 联合微调编码器和轻量级分类器，利用稀缺专家标注优化决策边界。

Result: 在真实运营商级数据集上的实验表明，DK-Root达到了最先进的准确率，超越了传统机器学习和近期半监督时间序列方法。消融实验验证了条件扩散增强和预训练-微调设计的必要性。

Conclusion: DK-Root框架通过联合数据驱动和知识驱动的方法，有效解决了移动网络QoE根因分析中的标注稀缺和噪声标签问题，为运营商级网络诊断提供了可靠解决方案。

Abstract: Diagnosing the root causes of Quality of Experience (QoE) degradations in operational mobile networks is challenging due to complex cross-layer interactions among kernel performance indicators (KPIs) and the scarcity of reliable expert annotations. Although rule-based heuristics can generate labels at scale, they are noisy and coarse-grained, limiting the accuracy of purely data-driven approaches. To address this, we propose DK-Root, a joint data-and-knowledge-driven framework that unifies scalable weak supervision with precise expert guidance for robust root-cause analysis. DK-Root first pretrains an encoder via contrastive representation learning using abundant rule-based labels while explicitly denoising their noise through a supervised contrastive objective. To supply task-faithful data augmentation, we introduce a class-conditional diffusion model that generates KPIs sequences preserving root-cause semantics, and by controlling reverse diffusion steps, it produces weak and strong augmentations that improve intra-class compactness and inter-class separability. Finally, the encoder and the lightweight classifier are jointly fine-tuned with scarce expert-verified labels to sharpen decision boundaries. Extensive experiments on a real-world, operator-grade dataset demonstrate state-of-the-art accuracy, with DK-Root surpassing traditional ML and recent semi-supervised time-series methods. Ablations confirm the necessity of the conditional diffusion augmentation and the pretrain-finetune design, validating both representation quality and classification gains.

</details>


### [372] [Uncertainty Makes It Stable: Curiosity-Driven Quantized Mixture-of-Experts](https://arxiv.org/abs/2511.11743)
*Sebastián Andrés Cajas Ordóñez,Luis Fernando Torres Torres,Mackenzie J. Meni,Carlos Andrés Duran Paredes,Eric Arazo,Cristian Bosch,Ricardo Simon Carbajo,Yuan Lai,Leo Anthony Celi*

Main category: cs.LG

TL;DR: 提出了一个好奇心驱动的量化混合专家框架，通过贝叶斯认知不确定性路由在异构专家之间进行选择，解决了资源受限设备上深度神经网络部署的准确性和延迟预测性挑战。


<details>
  <summary>Details</summary>
Motivation: 在资源受限设备上部署深度神经网络面临两个关键挑战：在激进量化下保持准确性，同时确保可预测的推理延迟。

Method: 使用好奇心驱动的量化混合专家框架，通过贝叶斯认知不确定性路由在异构专家（BitNet三元、1-16位BitLinear、训练后量化）之间进行选择。

Result: 4位量化保持了99.9%的16位准确性（0.858 vs 0.859 F1），压缩比4倍，能耗比8位节省41%。好奇心驱动路由将MoE延迟方差降低了82%（从230ms到29ms标准差）。

Conclusion: 信息论路由表明自适应量化能够产生准确、节能且可预测的边缘模型，简单的4位量化架构在大多数部署中优于复杂MoE。

Abstract: Deploying deep neural networks on resource-constrained devices faces two critical challenges: maintaining accuracy under aggressive quantization while ensuring predictable inference latency. We present a curiosity-driven quantized Mixture-of-Experts framework that addresses both through Bayesian epistemic uncertainty-based routing across heterogeneous experts (BitNet ternary, 1-16 bit BitLinear, post-training quantization). Evaluated on audio classification benchmarks (ESC-50, Quinn, UrbanSound8K), our 4-bit quantization maintains 99.9 percent of 16-bit accuracy (0.858 vs 0.859 F1) with 4x compression and 41 percent energy savings versus 8-bit. Crucially, curiosity-driven routing reduces MoE latency variance by 82 percent (p = 0.008, Levene's test) from 230 ms to 29 ms standard deviation, enabling stable inference for battery-constrained devices. Statistical analysis confirms 4-bit/8-bit achieve practical equivalence with full precision (p > 0.05), while MoE architectures introduce 11 percent latency overhead (p < 0.001) without accuracy gains. At scale, deployment emissions dominate training by 10000x for models serving more than 1,000 inferences, making inference efficiency critical. Our information-theoretic routing demonstrates that adaptive quantization yields accurate (0.858 F1, 1.2M params), energy-efficient (3.87 F1/mJ), and predictable edge models, with simple 4-bit quantized architectures outperforming complex MoE for most deployments.

</details>


### [373] [Diffusion Models: A Mathematical Introduction](https://arxiv.org/abs/2511.11746)
*Sepehr Maleki,Negar Pourmoazemi*

Main category: cs.LG

TL;DR: 该论文提供了一个从第一原理出发的扩散生成模型的系统推导，涵盖DDPM、DDIM、DDGAN、多尺度变体、连续时间公式以及引导扩散等核心概念，强调透明代数和可实践性。


<details>
  <summary>Details</summary>
Motivation: 旨在为扩散生成模型提供一个自包含、数学严谨的推导，使读者能够从高斯分布的基本性质出发，理解扩散模型的完整理论框架和实现细节。

Method: 从高斯分布的基本性质（密度、二次期望、重参数化、乘积和KL散度）开始，逐步推导前向加噪过程、闭式边缘分布、精确离散反向后验以及相关的变分下界，并扩展到连续时间公式、加速采样方法和引导扩散技术。

Result: 构建了一个完整的扩散模型理论体系，包括标准噪声预测目标、概率流ODE、流匹配、整流流等关键结果，并展示了如何将理论转化为可实现的算法。

Conclusion: 通过透明代数和一致符号，论文成功地将扩散生成模型的复杂理论分解为可理解的步骤，为理论和实践提供了坚实的桥梁。

Abstract: We present a concise, self-contained derivation of diffusion-based generative models. Starting from basic properties of Gaussian distributions (densities, quadratic expectations, re-parameterisation, products, and KL divergences), we construct denoising diffusion probabilistic models from first principles. This includes the forward noising process, its closed-form marginals, the exact discrete reverse posterior, and the related variational bound. This bound simplifies to the standard noise-prediction goal used in practice. We then discuss likelihood estimation and accelerated sampling, covering DDIM, adversarially learned reverse dynamics (DDGAN), and multi-scale variants such as nested and latent diffusion, with Stable Diffusion as a canonical example. A continuous-time formulation follows, in which we derive the probability-flow ODE from the diffusion SDE via the continuity and Fokker-Planck equations, introduce flow matching, and show how rectified flows recover DDIM up to a time re-parameterisation. Finally, we treat guided diffusion, interpreting classifier guidance as a posterior score correction and classifier-free guidance as a principled interpolation between conditional and unconditional scores. Throughout, the focus is on transparent algebra, explicit intermediate steps, and consistent notation, so that readers can both follow the theory and implement the corresponding algorithms in practice.

</details>


### [374] [IDOL: Meeting Diverse Distribution Shifts with Prior Physics for Tropical Cyclone Multi-Task Estimation](https://arxiv.org/abs/2511.11750)
*Hanting Yan,Pan Mu,Shiqi Zhang,Yuchao Zhu,Jinglin Zhang,Cong Bai*

Main category: cs.LG

TL;DR: 提出了IDOL框架，通过身份导向的物理不变性学习来解决热带气旋估计中的分布偏移问题，利用风场模型和暗相关知识建模任务共享和特定身份令牌，实现稳健的TC属性估计。


<details>
  <summary>Details</summary>
Motivation: 热带气旋估计面临复杂环境场导致的分布偏移挑战，现有多模态融合方法忽视特征表示的内在分布，导致在分布外场景下泛化能力差。

Method: IDOL框架基于先验物理知识施加身份导向约束，利用风场模型和暗相关知识建模任务共享和任务特定身份令牌，捕捉任务依赖性和TC的固有物理不变性。

Result: 在多个数据集和任务上的广泛实验表明IDOL表现出色，验证了基于先验物理知识的身份导向约束能有效缓解TC估计中的分布偏移。

Conclusion: IDOL框架通过物理不变性学习成功解决了TC估计中的分布偏移问题，为复杂动态环境下的稳健估计提供了有效解决方案。

Abstract: Tropical Cyclone (TC) estimation aims to accurately estimate various TC attributes in real time. However, distribution shifts arising from the complex and dynamic nature of TC environmental fields, such as varying geographical conditions and seasonal changes, present significant challenges to reliable estimation. Most existing methods rely on multi-modal fusion for feature extraction but overlook the intrinsic distribution of feature representations, leading to poor generalization under out-of-distribution (OOD) scenarios. To address this, we propose an effective Identity Distribution-Oriented Physical Invariant Learning framework (IDOL), which imposes identity-oriented constraints to regulate the feature space under the guidance of prior physical knowledge, thereby dealing distribution variability with physical invariance. Specifically, the proposed IDOL employs the wind field model and dark correlation knowledge of TC to model task-shared and task-specific identity tokens. These tokens capture task dependencies and intrinsic physical invariances of TC, enabling robust estimation of TC wind speed, pressure, inner-core, and outer-core size under distribution shifts. Extensive experiments conducted on multiple datasets and tasks demonstrate the outperformance of the proposed IDOL, verifying that imposing identity-oriented constraints based on prior physical knowledge can effectively mitigates diverse distribution shifts in TC estimation.Code is available at https://github.com/Zjut-MultimediaPlus/IDOL.

</details>


### [375] [Improving a Hybrid Graphsage Deep Network for Automatic Multi-objective Logistics Management in Supply Chain](https://arxiv.org/abs/2511.11753)
*Mehdi Khaleghi,Nastaran Khaleghi,Sobhan Sheykhivand,Sebelan Danishvar*

Main category: cs.LG

TL;DR: 本文提出了一种混合图神经网络（H-GSN）用于供应链物流管理的多任务预测，包括货物类型、物流状态、交通状况等，在多个数据集上取得了97%-100%的高准确率。


<details>
  <summary>Details</summary>
Motivation: 供应链物流系统的高效管理对提升供应链韧性和可持续性至关重要，需要自动化方法来预测货物类型、物流延迟和交通状况等关键因素。

Method: 提出混合图神经网络（H-GSN）进行多任务学习，使用三个Kaggle上的供应链物流数据库（DataCo、Shipping和Smart Logistics）来预测货物类型、物流状态、交通状况、物流ID和物流延迟。

Result: 在Smart Logistics数据集上，物流ID预测准确率达97.8%，交通状况预测准确率达100%；在DataCo数据集上货物类型预测准确率98.7%；在Shipping数据集上物流延迟预测准确率99.4%。

Conclusion: 所提出的方法在不同物流场景下的评估指标证实了其有效性，能够提高供应链的韧性和可持续性。

Abstract: Systematic logistics, conveyance amenities and facilities as well as warehousing information play a key role in fostering profitable development in a supply chain. The aim of transformation in industries is the improvement of the resiliency regarding the supply chain. The resiliency policies are required for companies to affect the collaboration with logistics service providers positively. The decrement of air pollutant emissions is a persistent advantage of the efficient management of logistics and transportation in supply chain. The management of shipment type is a significant factor in analyzing the sustainability of logistics and supply chain. An automatic approach to predict the shipment type, logistics delay and traffic status are required to improve the efficiency of the supply chain management. A hybrid graphsage network (H-GSN) is proposed in this paper for multi-task purpose of logistics management in a supply chain. The shipment type, shipment status, traffic status, logistics ID and logistics delay are the objectives in this article regarding three different databases including DataCo, Shipping and Smart Logistcis available on Kaggle as supply chain logistics databases. The average accuracy of 97.8% and 100% are acquired for 10 kinds of logistics ID and 3 types of traffic status prediction in Smart Logistics dataset. The average accuracy of 98.7% and 99.4% are obtained for shipment type prediction in DataCo and logistics delay in Shipping database, respectively. The evaluation metrics for different logistics scenarios confirm the efficiency of the proposed method to improve the resilience and sustainability of the supply chain.

</details>


### [376] [Sumudu Neural Operator for ODEs and PDEs](https://arxiv.org/abs/2511.11762)
*Ben Zelenskiy,Saibilila Abudukelimu,George Flint,Kevin Zhu,Sunishchal Dev*

Main category: cs.LG

TL;DR: 提出了基于Sumudu变换的Sumudu神经算子（SNO），在ODE和PDE问题上表现出优于FNO的性能，在部分PDE任务上与LNO竞争，并展示了零样本超分辨率能力。


<details>
  <summary>Details</summary>
Motivation: 探索Sumudu变换作为神经算子设计的潜力，特别是针对特定类型的偏微分方程（PDEs）。

Method: 利用变换对的多项式展开关系将输入空间分解为系数，然后转换到Sumudu空间进行神经算子参数化。

Result: SNO在PDEs上表现优于FNO，在多个PDE任务上与LNO竞争，在Euler-Bernoulli梁和扩散方程上获得最低误差。

Conclusion: 初步结果表明Sumudu变换作为神经算子设计具有潜力，尤其适用于某些类别的PDEs。

Abstract: We introduce the Sumudu Neural Operator (SNO), a neural operator rooted in the properties of the Sumudu Transform. We leverage the relationship between the polynomial expansions of transform pairs to decompose the input space as coefficients, which are then transformed into the Sumudu Space, where the neural operator is parameterized. We evaluate the operator in ODEs (Duffing Oscillator, Lorenz System, and Driven Pendulum) and PDEs (Euler-Bernoulli Beam, Burger's Equation, Diffusion, Diffusion-Reaction, and Brusselator). SNO achieves superior performance to FNO on PDEs and demonstrates competitive accuracy with LNO on several PDE tasks, including the lowest error on the Euler-Bernoulli Beam and Diffusion Equation. Additionally, we apply zero-shot super-resolution to the PDE tasks to observe the model's capability of obtaining higher quality data from low-quality samples. These preliminary findings suggest promise for the Sumudu Transform as a neural operator design, particularly for certain classes of PDEs.

</details>


### [377] [Learning Fair Representations with Kolmogorov-Arnold Networks](https://arxiv.org/abs/2511.11767)
*Amisha Priyadarshini,Sergio Gago-Masague*

Main category: cs.LG

TL;DR: 本文提出了一种将Kolmogorov-Arnold Networks（KANs）集成到公平对抗学习框架中的方法，通过自适应惩罚更新机制动态调整公平约束，在保持高预测准确性的同时实现公平性。


<details>
  <summary>Details</summary>
Motivation: 现有公平学习模型在公平性和准确性之间难以达到最优平衡，且黑盒模型缺乏可解释性，限制了在社会敏感领域的应用。

Method: 将KANs集成到公平对抗学习框架中，利用KANs的对抗鲁棒性和可解释性，并提出自适应惩罚更新机制动态调整训练过程中的公平约束。

Result: 在两个真实世界大学录取数据集上的实验表明，该方法在三种不同优化策略下均优于基线公平学习模型，在保持高预测准确性的同时实现了跨敏感属性的竞争性公平。

Conclusion: 该方法通过结合KANs和自适应惩罚机制，有效解决了公平性和准确性之间的权衡问题，并提供了更好的模型可解释性。

Abstract: Despite recent advances in fairness-aware machine learning, predictive models often exhibit discriminatory behavior towards marginalized groups. Such unfairness might arise from biased training data, model design, or representational disparities across groups, posing significant challenges in high-stakes decision-making domains such as college admissions. While existing fair learning models aim to mitigate bias, achieving an optimal trade-off between fairness and accuracy remains a challenge. Moreover, the reliance on black-box models hinders interpretability, limiting their applicability in socially sensitive domains. In this paper, we try to circumvent these issues by integrating Kolmogorov-Arnold Networks (KANs) within a fair adversarial learning framework. Leveraging the adversarial robustness and interpretability of KANs, our approach enables a balance between fairness and accuracy. To further facilitate this balance, we propose an adaptive penalty update mechanism that dynamically adjusts fairness constraints during the model training. We conduct numerical experiments on two real-world college admissions datasets, across three different optimization strategies. The results demonstrate the efficiency and robustness of KANs by consistently outperforming the baseline fair learning models, and maintaining high predictive accuracy while achieving competitive fairness across sensitive attributes.

</details>


### [378] [CATCHFed: Efficient Unlabeled Data Utilization for Semi-Supervised Federated Learning in Limited Labels Environments](https://arxiv.org/abs/2511.11778)
*Byoungjun Park,Pedro Porto Buarque de Gusmão,Dongjin Ji,Minhoe Kim*

Main category: cs.LG

TL;DR: CATCHFed是一种针对半监督联邦学习的新方法，通过客户端感知自适应阈值、混合阈值和一致性正则化，有效解决了服务器端标签数据稀缺时的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界中客户端往往缺乏标签数据，而现有的半监督联邦学习方法在标签数据稀缺时性能显著下降。

Method: 提出CATCHFed方法，包含：1）考虑类别难度的客户端感知自适应阈值；2）提升伪标签质量的混合阈值；3）利用未伪标签数据进行一致性正则化。

Result: 在多种数据集和配置下的广泛实验表明，CATCHFed能有效利用未标记的客户端数据，即使在极有限标签设置下也能获得优越性能。

Conclusion: CATCHFed为解决半监督联邦学习中标签稀缺问题提供了有效方案，显著提升了模型在现实场景中的适用性。

Abstract: Federated learning is a promising paradigm that utilizes distributed client resources while preserving data privacy. Most existing FL approaches assume clients possess labeled data, however, in real-world scenarios, client-side labels are often unavailable. Semi-supervised Federated learning, where only the server holds labeled data, addresses this issue. However, it experiences significant performance degradation as the number of labeled data decreases. To tackle this problem, we propose \textit{CATCHFed}, which introduces client-aware adaptive thresholds considering class difficulty, hybrid thresholds to enhance pseudo-label quality, and utilizes unpseudo-labeled data for consistency regularization. Extensive experiments across various datasets and configurations demonstrate that CATCHFed effectively leverages unlabeled client data, achieving superior performance even in extremely limited-label settings.

</details>


### [379] [Coordinate Descent for Network Linearization](https://arxiv.org/abs/2511.11781)
*Vlad Rakhlin,Amir Jevnisek,Shai Avidan*

Main category: cs.LG

TL;DR: 本文提出了一种基于坐标下降的离散优化方法，用于减少ResNet网络中ReLU激活函数的数量，从而降低私有推理的延迟。


<details>
  <summary>Details</summary>
Motivation: ReLU激活函数是基于ResNet网络的私有推理中的主要瓶颈，会导致显著的推理延迟。现有方法采用平滑近似优化，但在最后的硬阈值步骤中会引入较大的性能损失。

Method: 采用坐标下降作为优化框架，直接在离散域中进行优化，这种方法天然产生稀疏解。

Result: 通过大量实验证明，该方法在常见基准测试中达到了最先进的性能。

Conclusion: 提出的离散优化方法有效解决了ReLU减少问题，在保持网络精度的同时显著降低了推理延迟。

Abstract: ReLU activations are the main bottleneck in Private Inference that is based on ResNet networks. This is because they incur significant inference latency. Reducing ReLU count is a discrete optimization problem, and there are two common ways to approach it. Most current state-of-the-art methods are based on a smooth approximation that jointly optimizes network accuracy and ReLU budget at once. However, the last hard thresholding step of the optimization usually introduces a large performance loss. We take an alternative approach that works directly in the discrete domain by leveraging Coordinate Descent as our optimization framework. In contrast to previous methods, this yields a sparse solution by design. We demonstrate, through extensive experiments, that our method is State of the Art on common benchmarks.

</details>


### [380] [Simplicial covering dimension of extremal concept classes](https://arxiv.org/abs/2511.11819)
*Ari Blondal,Hamed Hatami,Pooya Hatami,Chavdar Lalov,Sivan Tretiak*

Main category: cs.LG

TL;DR: 本文提出了一种将拓扑维度理论（特别是Lebesgue覆盖维度）应用于二进制概念类的方法，通过定义概念类可实现分布空间的单纯覆盖维度，证明了该维度与PAC学习中的列表可复制性数（等价于全局稳定性）的精确对应关系。


<details>
  <summary>Details</summary>
Motivation: 将经典拓扑维度理论引入机器学习领域，旨在为二进制概念类提供一个拓扑维度的定义，从而更深入地理解PAC学习中的列表可复制性（全局稳定性）问题。

Method: 通过将概念类与其可实现分布空间关联，并利用损失函数和概念类本身诱导的单纯结构，定义了单纯覆盖维度。

Result: 证明了对于有限概念类，单纯覆盖维度精确刻画了PAC学习中的列表可复制性数（全局稳定性），并利用经典维度理论工具计算了极值概念类的列表可复制性数。

Conclusion: 该工作建立了拓扑维度理论与PAC学习列表可复制性之间的桥梁，为分析概念类的复杂性提供了新的视角和工具。

Abstract: Dimension theory is a branch of topology concerned with defining and analyzing dimensions of geometric and topological spaces in purely topological terms. In this work, we adapt the classical notion of topological dimension (Lebesgue covering) to binary concept classes. The topological space naturally associated with a concept class is its space of realizable distributions. The loss function and the class itself induce a simplicial structure on this space, with respect to which we define a simplicial covering dimension.
  We prove that for finite concept classes, this simplicial covering dimension exactly characterizes the list replicability number (equivalently, global stability) in PAC learning. This connection allows us to apply tools from classical dimension theory to compute the exact list replicability number of the broad family of extremal concept classes.

</details>


### [381] [Conformal Constrained Policy Optimization for Cost-Effective LLM Agents](https://arxiv.org/abs/2511.11828)
*Wenwen Si,Sooyong Jang,Insup Lee,Osbert Bastani*

Main category: cs.LG

TL;DR: 提出CCPO方法，通过结合不同成本/精度的LLM模型，在保证可靠性的前提下显著降低计算成本


<details>
  <summary>Details</summary>
Motivation: LLM在解决复杂AI问题时计算成本和API成本急剧上升，需要一种能够在保证可靠性的前提下降低成本的策略

Method: 提出Conformal Constrained Policy Optimization (CCPO)训练范式，结合约束策略优化、离策略强化学习和在线符合预测，联合优化成本感知策略和自适应阈值

Result: 在两个多跳问答基准测试中，CCPO相比其他成本感知基线和LLM引导方法，成本降低高达30%且不牺牲可靠性

Conclusion: CCPO为部署LLM代理提供了一个原则性和实用的框架，在保持可靠性的同时显著提高成本效益

Abstract: While large language models (LLMs) have recently made tremendous progress towards solving challenging AI problems, they have done so at increasingly steep computational and API costs. We propose a novel strategy where we combine multiple LLM models with varying cost/accuracy tradeoffs in an agentic manner, where models and tools are run in sequence as determined by an orchestration model to minimize cost subject to a user-specified level of reliability; this constraint is formalized using conformal prediction to provide guarantees. To solve this problem, we propose Conformal Constrained Policy Optimization (CCPO), a training paradigm that integrates constrained policy optimization with off-policy reinforcement learning and recent advances in online conformal prediction. CCPO jointly optimizes a cost-aware policy (score function) and an adaptive threshold. Across two multi-hop question answering benchmarks, CCPO achieves up to a 30% cost reduction compared to other cost-aware baselines and LLM-guided methods without compromising reliability. Our approach provides a principled and practical framework for deploying LLM agents that are significantly more cost-effective while maintaining reliability.

</details>


### [382] [Volatility in Certainty (VC): A Metric for Detecting Adversarial Perturbations During Inference in Neural Network Classifiers](https://arxiv.org/abs/2511.11834)
*Vahid Hemmati,Ahmad Mohammadi,Abdul-Rauf Nuhu,Reza Ahmari,Parham Kebria,Abdollah Homaifar*

Main category: cs.LG

TL;DR: 该论文研究了VC（Volatility in Certainty）这一无标签指标，用于量化神经网络分类器在对抗攻击下的性能退化，实验表明VC与分类准确率呈强负相关。


<details>
  <summary>Details</summary>
Motivation: 在实时系统中，由于缺乏真实标签，对抗鲁棒性评估面临挑战，需要一种无需标签的指标来检测模型性能退化。

Method: 通过计算排序后softmax输出的相邻置信度比值的平均平方对数来定义VC指标，在MNIST和CIFAR-10数据集上使用FGSM生成对抗样本，评估VC与分类准确率的相关性。

Result: 实验结果显示分类准确率与log(VC)之间存在强负相关（rho < -0.90），表明VC能有效反映性能退化。

Conclusion: VC可作为可扩展、架构无关的实时性能指标，适用于安全关键应用的早期预警系统。

Abstract: Adversarial robustness remains a critical challenge in deploying neural network classifiers, particularly in real-time systems where ground-truth labels are unavailable during inference. This paper investigates \textit{Volatility in Certainty} (VC), a recently proposed, label-free metric that quantifies irregularities in model confidence by measuring the dispersion of sorted softmax outputs. Specifically, VC is defined as the average squared log-ratio of adjacent certainty values, capturing local fluctuations in model output smoothness. We evaluate VC as a proxy for classification accuracy and as an indicator of adversarial drift. Experiments are conducted on artificial neural networks (ANNs) and convolutional neural networks (CNNs) trained on MNIST, as well as a regularized VGG-like model trained on CIFAR-10. Adversarial examples are generated using the Fast Gradient Sign Method (FGSM) across varying perturbation magnitudes. In addition, mixed test sets are created by gradually introducing adversarial contamination to assess VC's sensitivity under incremental distribution shifts. Our results reveal a strong negative correlation between classification accuracy and log(VC) (correlation rho < -0.90 in most cases), suggesting that VC effectively reflects performance degradation without requiring labeled data. These findings position VC as a scalable, architecture-agnostic, and real-time performance metric suitable for early-warning systems in safety-critical applications.

</details>


### [383] [On the Trade-Off Between Transparency and Security in Adversarial Machine Learning](https://arxiv.org/abs/2511.11842)
*Lucas Fenaux,Christopher Srinivasa,Florian Kerschbaum*

Main category: cs.LG

TL;DR: 论文研究了透明度与安全性的权衡，通过可转移对抗样本攻击的视角，发现当攻击者能够匹配防御者的决策时攻击更成功，表明模糊性可能对防御者有益。


<details>
  <summary>Details</summary>
Motivation: 透明度和安全性都是负责任AI的核心要素，但在对抗性环境中可能存在冲突。研究旨在通过游戏理论分析这种权衡关系。

Method: 使用大规模实证评估（9种攻击方法在181个模型上的测试），并建立纳什博弈和斯塔克尔伯格博弈模型来分析透明度与安全性的权衡。

Result: 攻击者能够获知防御者模型是否被防御时，攻击成功率更高；博弈分析确认透明度有时会损害安全性。

Conclusion: AI系统的透明度可能与安全性相冲突，游戏理论分析揭示了这种普遍存在的权衡关系，对负责任AI的实践具有重要启示。

Abstract: Transparency and security are both central to Responsible AI, but they may conflict in adversarial settings. We investigate the strategic effect of transparency for agents through the lens of transferable adversarial example attacks. In transferable adversarial example attacks, attackers maliciously perturb their inputs using surrogate models to fool a defender's target model. These models can be defended or undefended, with both players having to decide which to use. Using a large-scale empirical evaluation of nine attacks across 181 models, we find that attackers are more successful when they match the defender's decision; hence, obscurity could be beneficial to the defender. With game theory, we analyze this trade-off between transparency and security by modeling this problem as both a Nash game and a Stackelberg game, and comparing the expected outcomes. Our analysis confirms that only knowing whether a defender's model is defended or not can sometimes be enough to damage its security. This result serves as an indicator of the general trade-off between transparency and security, suggesting that transparency in AI systems can be at odds with security. Beyond adversarial machine learning, our work illustrates how game-theoretic reasoning can uncover conflicts between transparency and security.

</details>


### [384] [Leveraging Exogenous Signals for Hydrology Time Series Forecasting](https://arxiv.org/abs/2511.11849)
*Junyang He,Judy Fox,Alireza Jafari,Ying-Jung Chen,Geoffrey Fox*

Main category: cs.LG

TL;DR: 本文研究了将领域知识整合到时间序列模型中对水文降雨径流建模的影响，发现包含全面已知外生输入的模型（特别是自然年周期时间序列）优于基础模型和有限方法。


<details>
  <summary>Details</summary>
Motivation: 尽管时间序列基础模型研究取得进展，但很少研究其在物理科学特定下游应用中的有效性，特别是水文降雨径流建模领域。

Method: 使用CAMELS-US数据集（包含671个地点的降雨和径流数据，6个时间序列流和30个静态特征），比较基线模型和基础模型，重点研究整合领域知识（特别是自然年周期时间序列）的效果。

Result: 结果表明，整合全面已知外生输入的模型表现优于有限方法，包括基础模型。自然年周期时间序列的整合贡献了最显著的改进。

Conclusion: 在水文降雨径流建模中，领域知识的整合对模型性能至关重要，特别是自然年周期信息能够显著提升模型表现，这为时间序列基础模型在特定领域应用提供了重要启示。

Abstract: Recent advances in time series research facilitate the development of foundation models. While many state-of-the-art time series foundation models have been introduced, few studies examine their effectiveness in specific downstream applications in physical science. This work investigates the role of integrating domain knowledge into time series models for hydrological rainfall-runoff modeling. Using the CAMELS-US dataset, which includes rainfall and runoff data from 671 locations with six time series streams and 30 static features, we compare baseline and foundation models. Results demonstrate that models incorporating comprehensive known exogenous inputs outperform more limited approaches, including foundation models. Notably, incorporating natural annual periodic time series contribute the most significant improvements.

</details>


### [385] [Transformers vs. Recurrent Models for Estimating Forest Gross Primary Production](https://arxiv.org/abs/2511.11880)
*David Montero,Miguel D. Mahecha,Francesco Martinuzzi,César Aybar,Anne Klosterhalfen,Alexander Knohl,Jesús Anaya,Clemens Mosig,Sebastian Wieneke*

Main category: cs.LG

TL;DR: 该研究比较了GPT-2和LSTM两种深度学习模型在预测森林CO2吸收量(GPP)方面的性能，发现LSTM总体精度更高，但GPT-2在极端事件中表现更优，揭示了模型架构、输入窗口长度和多模态数据对GPP预测性能的共同影响。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以捕捉GPP的复杂时间动态，深度学习为植被过程的时间动态表征提供了新机会，但对最先进DL模型在多模态GPP预测中的比较评估仍较少。

Method: 使用GPT-2（Transformer架构）和LSTM（循环神经网络）两种代表性模型，结合多变量输入（辐射、Sentinel-2、MODIS地表温度、Sentinel-1等）进行GPP预测。

Result: 两种模型达到相似精度，LSTM总体表现更好，但GPT-2在极端事件中表现更优；LSTM使用更短的输入窗口即可达到相似精度；辐射是最重要的预测因子。

Conclusion: 模型架构、上下文长度和多模态输入共同决定了GPP预测性能，为未来开发监测陆地碳动态的DL框架提供了指导。

Abstract: Monitoring the spatiotemporal dynamics of forest CO$_2$ uptake (Gross Primary Production, GPP), remains a central challenge in terrestrial ecosystem research. While Eddy Covariance (EC) towers provide high-frequency estimates, their limited spatial coverage constrains large-scale assessments. Remote sensing offers a scalable alternative, yet most approaches rely on single-sensor spectral indices and statistical models that are often unable to capture the complex temporal dynamics of GPP. Recent advances in deep learning (DL) and data fusion offer new opportunities to better represent the temporal dynamics of vegetation processes, but comparative evaluations of state-of-the-art DL models for multimodal GPP prediction remain scarce. Here, we explore the performance of two representative models for predicting GPP: 1) GPT-2, a transformer architecture, and 2) Long Short-Term Memory (LSTM), a recurrent neural network, using multivariate inputs. Overall, both achieve similar accuracy. But, while LSTM performs better overall, GPT-2 excels during extreme events. Analysis of temporal context length further reveals that LSTM attains similar accuracy using substantially shorter input windows than GPT-2, highlighting an accuracy-efficiency trade-off between the two architectures. Feature importance analysis reveals radiation as the dominant predictor, followed by Sentinel-2, MODIS land surface temperature, and Sentinel-1 contributions. Our results demonstrate how model architecture, context length, and multimodal inputs jointly determine performance in GPP prediction, guiding future developments of DL frameworks for monitoring terrestrial carbon dynamics.

</details>


### [386] [Better LLM Reasoning via Dual-Play](https://arxiv.org/abs/2511.11881)
*Zhengxin Zhang,Chengyu Huang,Aochong Oliver Li,Claire Cardie*

Main category: cs.LG

TL;DR: PasoDoble是一个无监督的LLM双对抗学习框架，通过让Proposer生成挑战性问题、Solver解决问题的对抗训练方式，提升LLM的推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前LLM训练依赖外部监督信号，而对抗学习特别是自博弈方法可以减少对外部监督的依赖，但LLM的双对抗训练面临奖励欺骗和训练不稳定的挑战。

Method: 从同一基础模型初始化两个模型：Proposer生成带标准答案的挑战性问题，Solver尝试解决问题。通过预训练数据集丰富Proposer知识，采用联合更新避免奖励欺骗，并引入离线范式增强训练稳定性。

Result: 实验结果表明PasoDoble能够有效提升LLM的推理性能。

Conclusion: PasoDoble证明了无监督双对抗学习在LLM训练中的可行性，为减少对外部监督的依赖提供了新思路。

Abstract: Large Language Models (LLMs) have achieved remarkable progress through Reinforcement Learning with Verifiable Rewards (RLVR), yet still rely heavily on external supervision (e.g., curated labels). Adversarial learning, particularly through self-play, offers a promising alternative that enables models to iteratively learn from themselves - thus reducing reliance on external supervision. Dual-play extends adversarial learning by assigning specialized roles to two models and training them against each other, fostering sustained competition and mutual evolution. Despite its promise, adapting dual-play training to LLMs remains limited, largely due to their susceptibility to reward hacking and training instability. In this paper, we introduce PasoDoble, a novel LLM dual-play framework. PasoDoble adversarially trains two models initialized from the same base model: a Proposer, which generates challenging questions with ground-truth answers, and a Solver, which attempts to solve them. We enrich the Proposer with knowledge from a pre-training dataset to ensure the questions' quality and diversity. To avoid reward hacking, the Proposer is rewarded for producing only valid questions that push the Solver's limit, while the Solver is rewarded for solving them correctly, and both are updated jointly. To further enhance training stability, we introduce an optional offline paradigm that decouples Proposer and Solver updates, alternately updating each for several steps while holding the other fixed. Notably, PasoDoble operates without supervision during training. Experimental results show that PasoDoble can improve the reasoning performance of LLMs. Our project page is available at https://hcy123902.github.io/PasoDoble.

</details>


### [387] [FLEX: Feature Importance from Layered Counterfactual Explanations](https://arxiv.org/abs/2511.11891)
*Nawid Keshtmand,Roussel Desmond Nzoyem,Jeffrey Nicholas Clark*

Main category: cs.LG

TL;DR: FLEX是一个模型无关的框架，通过将反事实解释转换为特征变化频率分数，在局部、区域和全局层面量化特征重要性，弥补了局部反事实解释和全局归因之间的差距。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型缺乏可解释性限制了在高风险场景中的安全部署。现有的反事实解释通常局限于实例特定，无法系统量化特征在特征空间一致区域或整个数据集上如何驱动结果变化。

Method: FLEX框架将反事实解释集转换为特征变化频率分数，通过跨实例和邻域聚合来泛化局部变化频率度量，生成可解释的特征重要性排名。该框架兼容不同的反事实生成方法，可根据实际约束定制特征重要性。

Result: 在交通事故严重性预测和贷款审批两个表格任务上的评估显示：(i) FLEX的全局排名与SHAP相关同时揭示了额外驱动因素；(ii) 区域分析揭示了全局摘要遗漏的上下文特定因素。

Conclusion: FLEX弥合了局部反事实解释和全局归因之间的差距，支持风险敏感应用中透明和干预导向的决策制定。

Abstract: Machine learning models achieve state-of-the-art performance across domains, yet their lack of interpretability limits safe deployment in high-stakes settings. Counterfactual explanations are widely used to provide actionable "what-if" recourse, but they typically remain instance-specific and do not quantify which features systematically drive outcome changes within coherent regions of the feature space or across an entire dataset. We introduce FLEX (Feature importance from Layered counterfactual EXplanations), a model- and domain-agnostic framework that converts sets of counterfactuals into feature change frequency scores at local, regional, and global levels. FLEX generalises local change-frequency measures by aggregating across instances and neighbourhoods, offering interpretable rankings that reflect how often each feature must change to flip predictions. The framework is compatible with different counterfactual generation methods, allowing users to emphasise characteristics such as sparsity, feasibility, or actionability, thereby tailoring the derived feature importances to practical constraints. We evaluate FLEX on two contrasting tabular tasks: traffic accident severity prediction and loan approval, and compare FLEX to SHAP- and LIME-derived feature importance values. Results show that (i) FLEX's global rankings correlate with SHAP while surfacing additional drivers, and (ii) regional analyses reveal context-specific factors that global summaries miss. FLEX thus bridges the gap between local recourse and global attribution, supporting transparent and intervention-oriented decision-making in risk-sensitive applications.

</details>


### [388] [Chain-of-Generation: Progressive Latent Diffusion for Text-Guided Molecular Design](https://arxiv.org/abs/2511.11894)
*Lingxiao Li,Haobo Zhang,Bin Chen,Jiayu Zhou*

Main category: cs.LG

TL;DR: 本文提出Chain-of-Generation (CoG)框架，通过多阶段潜在扩散方法解决文本条件分子生成中一次性条件生成的挑战，提高语义对齐和可控性。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的分子生成模型采用一次性条件编码，难以满足复杂提示中的所有要求，存在生成组件可解释性差、无法生成所有子结构、同时考虑所有要求过于激进等问题。

Method: CoG将提示分解为课程排序的语义片段，逐步将其作为中间目标融入生成过程，引导去噪轨迹逐步满足语言约束。还引入后对齐学习阶段加强文本和分子潜在空间的对应关系。

Result: 在基准和实际任务上的实验表明，CoG相比一次性基线方法在语义对齐、多样性和可控性方面表现更优，能更忠实地反映复杂组合提示。

Conclusion: CoG框架通过多阶段生成过程有效解决了文本条件分子生成的关键挑战，提供了更透明的生成过程洞察。

Abstract: Text-conditioned molecular generation aims to translate natural-language descriptions into chemical structures, enabling scientists to specify functional groups, scaffolds, and physicochemical constraints without handcrafted rules. Diffusion-based models, particularly latent diffusion models (LDMs), have recently shown promise by performing stochastic search in a continuous latent space that compactly captures molecular semantics. Yet existing methods rely on one-shot conditioning, where the entire prompt is encoded once and applied throughout diffusion, making it hard to satisfy all the requirements in the prompt. We discuss three outstanding challenges of one-shot conditioning generation, including the poor interpretability of the generated components, the failure to generate all substructures, and the overambition in considering all requirements simultaneously. We then propose three principles to address those challenges, motivated by which we propose Chain-of-Generation (CoG), a training-free multi-stage latent diffusion framework. CoG decomposes each prompt into curriculum-ordered semantic segments and progressively incorporates them as intermediate goals, guiding the denoising trajectory toward molecules that satisfy increasingly rich linguistic constraints. To reinforce semantic guidance, we further introduce a post-alignment learning phase that strengthens the correspondence between textual and molecular latent spaces. Extensive experiments on benchmark and real-world tasks demonstrate that CoG yields higher semantic alignment, diversity, and controllability than one-shot baselines, producing molecules that more faithfully reflect complex, compositional prompts while offering transparent insight into the generation process.

</details>


### [389] [Robust Bidirectional Associative Memory via Regularization Inspired by the Subspace Rotation Algorithm](https://arxiv.org/abs/2511.11902)
*Ci Lin,Tet Yeap,Iluju Kiringa,Biwei Zhang*

Main category: cs.LG

TL;DR: 提出了一种新的无梯度训练算法B-SRA，显著提高了双向联想记忆(BAM)的鲁棒性和收敛性，通过正交权重矩阵和梯度模式对齐两个关键原则增强BAM的抗干扰能力。


<details>
  <summary>Details</summary>
Motivation: 传统双向联想记忆使用双向反向传播训练时存在鲁棒性差、对噪声和对抗攻击敏感的问题，需要开发更鲁棒的训练方法。

Method: 提出了双向子空间旋转算法(B-SRA)这种无梯度训练方法，并在B-BP中引入正交权重矩阵(OWM)和梯度模式对齐(GPA)正则化策略。

Result: 实验表明，结合OWM和GPA的SAME配置在所有方法中表现最鲁棒，在各种攻击场景和记忆容量(50/100/200对)下都显示出更强的抗干扰能力。

Conclusion: B-SRA和提出的正则化策略显著提高了联想记忆的鲁棒性，为构建抗干扰神经架构开辟了新方向。

Abstract: Bidirectional Associative Memory (BAM) trained with Bidirectional Backpropagation (B-BP) often suffers from poor robustness and high sensitivity to noise and adversarial attacks. To address these issues, we propose a novel gradient-free training algorithm, the Bidirectional Subspace Rotation Algorithm (B-SRA), which significantly improves the robustness and convergence behavior of BAM. Through comprehensive experiments, we identify two key principles -- orthogonal weight matrices (OWM) and gradient-pattern alignment (GPA) -- as central to enhancing the robustness of BAM. Motivated by these findings, we introduce new regularization strategies into B-BP, resulting in models with greatly improved resistance to corruption and adversarial perturbations. We further conduct an ablation study across different training strategies to determine the most robust configuration and evaluate BAM's performance under a variety of attack scenarios and memory capacities, including 50, 100, and 200 associative pairs. Among all methods, the SAME configuration, which integrates both OWM and GPA, achieves the strongest resilience. Overall, our results demonstrate that B-SRA and the proposed regularization strategies lead to substantially more robust associative memories and open new directions for building resilient neural architectures.

</details>


### [390] [A Systematic Study of Model Extraction Attacks on Graph Foundation Models](https://arxiv.org/abs/2511.11912)
*Haoyan Xu,Ruizhi Qian,Jiate Li,Yushun Dong,Minghao Lin,Hanson Yan,Zhengtao Yao,Qinghua Liu,Junhao Dong,Ruopeng Huang,Yue Zhao,Mengyuan Li*

Main category: cs.LG

TL;DR: 本文首次系统研究了针对图基础模型（GFMs）的模型提取攻击，揭示了GFMs显著扩大了攻击面，即使使用少量查询预算也能高精度地近似受害者模型。


<details>
  <summary>Details</summary>
Motivation: 随着图基础模型（GFMs）的发展，它们成为有价值的智力资产，但高预训练成本和跨领域知识使其成为模型提取攻击（MEAs）的有吸引力的目标。现有研究仅关注小型图神经网络，对大规模多模态GFMs的安全性影响尚未探索。

Method: 提出黑盒威胁模型和六种攻击场景，引入轻量级提取方法，通过监督回归训练攻击者编码器来近似受害者模型的图嵌入，即使没有对比预训练数据也能保持与受害者文本编码器的对齐。

Result: 在七个数据集上的实验表明，攻击者仅使用原始训练成本的一小部分就能近似受害者模型，准确率几乎没有损失。

Conclusion: GFMs显著扩大了MEA攻击面，突显了在大规模图学习系统中需要部署感知的安全防御措施。

Abstract: Graph machine learning has advanced rapidly in tasks such as link prediction, anomaly detection, and node classification. As models scale up, pretrained graph models have become valuable intellectual assets because they encode extensive computation and domain expertise. Building on these advances, Graph Foundation Models (GFMs) mark a major step forward by jointly pretraining graph and text encoders on massive and diverse data. This unifies structural and semantic understanding, enables zero-shot inference, and supports applications such as fraud detection and biomedical analysis. However, the high pretraining cost and broad cross-domain knowledge in GFMs also make them attractive targets for model extraction attacks (MEAs). Prior work has focused only on small graph neural networks trained on a single graph, leaving the security implications for large-scale and multimodal GFMs largely unexplored. This paper presents the first systematic study of MEAs against GFMs. We formalize a black-box threat model and define six practical attack scenarios covering domain-level and graph-specific extraction goals, architectural mismatch, limited query budgets, partial node access, and training data discrepancies. To instantiate these attacks, we introduce a lightweight extraction method that trains an attacker encoder using supervised regression of graph embeddings. Even without contrastive pretraining data, this method learns an encoder that stays aligned with the victim text encoder and preserves its zero-shot inference ability on unseen graphs. Experiments on seven datasets show that the attacker can approximate the victim model using only a tiny fraction of its original training cost, with almost no loss in accuracy. These findings reveal that GFMs greatly expand the MEA surface and highlight the need for deployment-aware security defenses in large-scale graph learning systems.

</details>


### [391] [Batch Matrix-form Equations and Implementation of Multilayer Perceptrons](https://arxiv.org/abs/2511.11918)
*Wieger Wesselink,Bram Grooten,Huub van de Wetering,Qiao Xiao,Decebal Constantin Mocanu*

Main category: cs.LG

TL;DR: 该论文提供了多层感知机(MLP)的完整批处理矩阵形式算法细节，包括正向和反向传播的数学推导和验证，以及多框架实现。


<details>
  <summary>Details</summary>
Motivation: 虽然MLP是现代深度学习的基础，但其算法细节很少以完整的批处理矩阵形式呈现，大多依赖自动微分。显式的矩阵形式对于透明分析、系统优化和稀疏神经网络设置至关重要。

Method: 使用符号数学库SymPy推导和验证所有标准层和高级层(包括批归一化和softmax)的正向和反向传播方程，并在NumPy、PyTorch、JAX、TensorFlow和C++中构建统一的参考实现。

Result: 建立了经过验证的、可扩展的神经网络算法基础，展示了显式公式如何实现高效稀疏计算。

Conclusion: 该研究为理解、教学和研究神经网络算法提供了经过验证的基础，填补了MLP批处理矩阵形式算法细节的空白。

Abstract: Multilayer perceptrons (MLPs) remain fundamental to modern deep learning, yet their algorithmic details are rarely presented in complete, explicit \emph{batch matrix-form}. Rather, most references express gradients per sample or rely on automatic differentiation. Although automatic differentiation can achieve equally high computational efficiency, the usage of batch matrix-form makes the computational structure explicit, which is essential for transparent, systematic analysis, and optimization in settings such as sparse neural networks. This paper fills that gap by providing a mathematically rigorous and implementation-ready specification of MLPs in batch matrix-form. We derive forward and backward equations for all standard and advanced layers, including batch normalization and softmax, and validate all equations using the symbolic mathematics library SymPy. From these specifications, we construct uniform reference implementations in NumPy, PyTorch, JAX, TensorFlow, and a high-performance C++ backend optimized for sparse operations. Our main contributions are: (1) a complete derivation of batch matrix-form backpropagation for MLPs, (2) symbolic validation of all gradient equations, (3) uniform Python and C++ reference implementations grounded in a small set of matrix primitives, and (4) demonstration of how explicit formulations enable efficient sparse computation. Together, these results establish a validated, extensible foundation for understanding, teaching, and researching neural network algorithms.

</details>


### [392] [Beyond the Laplacian: Interpolated Spectral Augmentation for Graph Neural Networks](https://arxiv.org/abs/2511.11928)
*Ziyao Cui,Edric Tam*

Main category: cs.LG

TL;DR: 该论文提出了插值拉普拉斯嵌入（ILEs），这是一种从简单而富有表现力的图矩阵家族中导出的特征增强方法，用于改善图神经网络在节点特征有限时的性能。


<details>
  <summary>Details</summary>
Motivation: 图神经网络（GNNs）的性能严重依赖于信息丰富的节点特征，但在现实数据集中这些特征可能有限或缺失。虽然拉普拉斯谱嵌入是常用的补救方法，但作者探索是否可以从其他图矩阵中获得有用的谱嵌入表示。

Method: 引入插值拉普拉斯嵌入（ILEs），基于一组简单的图矩阵家族。利用谱图理论工具，为ILEs捕获的结构信息提供直观解释。

Result: 通过模拟实验和真实世界数据集测试表明，使用ILEs进行特征增强可以在常用的GNN架构中提高性能。

Conclusion: ILEs为实践者提供了一个简单实用的谱增强工具，特别是在节点特征有限的情况下，扩展了谱增强工具包的应用范围。

Abstract: Graph neural networks (GNNs) are fundamental tools in graph machine learning. The performance of GNNs relies crucially on the availability of informative node features, which can be limited or absent in real-life datasets and applications. A natural remedy is to augment the node features with embeddings computed from eigenvectors of the graph Laplacian matrix. While it is natural to default to Laplacian spectral embeddings, which capture meaningful graph connectivity information, we ask whether spectral embeddings from alternative graph matrices can also provide useful representations for learning. We introduce Interpolated Laplacian Embeddings (ILEs), which are derived from a simple yet expressive family of graph matrices. Using tools from spectral graph theory, we offer a straightforward interpretation of the structural information that ILEs capture. We demonstrate through simulations and experiments on real-world datasets that feature augmentation via ILEs can improve performance across commonly used GNN architectures. Our work offers a straightforward and practical approach that broadens the practitioner's spectral augmentation toolkit when node features are limited.

</details>


### [393] [A Systematic Analysis of Out-of-Distribution Detection Under Representation and Training Paradigm Shifts](https://arxiv.org/abs/2511.11934)
*C. César Claros Olivares,Austin J. Brockmeier*

Main category: cs.LG

TL;DR: 本文对CLIP分层机制下的OOD检测方法进行了系统比较，使用AURC和AUGRC作为主要指标，发现学习到的特征空间决定了OOD检测效果，并为分布偏移下的方法选择提供了统计指导。


<details>
  <summary>Details</summary>
Motivation: 当前OOD检测方法在不同表示范式下的性能差异缺乏系统性比较，需要基于统计显著性分析来指导方法选择。

Method: 使用多比较控制的基于秩的管道（Friedman检验与Conover-Holm后验）和Bron-Kerbosch团，在CIFAR-10/100、SuperCIFAR-100和TinyImageNet上评估CNN和ViT两种表示范式。

Result: 概率性得分在误分类检测中占主导，几何感知得分在CNN上对强偏移更有效，而在ViT上GradNorm和KPCA重建误差表现稳定。MCD存在类别数依赖的权衡，简单PCA投影可提升多个检测器。

Conclusion: 研究支持OOD检测的表示中心视角，为分布偏移下的方法选择提供了统计基础指导。

Abstract: We present a systematic comparison of out-of-distribution (OOD) detection methods across CLIP-stratified regimes using AURC and AUGRC as primary metrics. Experiments cover two representation paradigms: CNNs trained from scratch and a fine-tuned Vision Transformer (ViT), evaluated on CIFAR-10/100, SuperCIFAR-100, and TinyImageNet. Using a multiple-comparison-controlled, rank-based pipeline (Friedman test with Conover-Holm post-hoc) and Bron-Kerbosch cliques, we find that the learned feature space largely determines OOD efficacy. For both CNNs and ViTs, probabilistic scores (e.g., MSR, GEN) dominate misclassification (ID) detection. Under stronger shifts, geometry-aware scores (e.g., NNGuide, fDBD, CTM) prevail on CNNs, whereas on ViTs GradNorm and KPCA Reconstruction Error remain consistently competitive. We further show a class-count-dependent trade-off for Monte-Carlo Dropout (MCD) and that a simple PCA projection improves several detectors. These results support a representation-centric view of OOD detection and provide statistically grounded guidance for method selection under distribution shift.

</details>


### [394] [SurvBench: A Standardised Preprocessing Pipeline for Multi-Modal Electronic Health Record Survival Analysis](https://arxiv.org/abs/2511.11935)
*Munib Mesinovic,Tingting Zhu*

Main category: cs.LG

TL;DR: SurvBench是一个开源预处理流水线，将原始PhysioNet数据集转换为标准化张量，用于多模态生存分析，解决了深度学习生存分析中预处理不一致的问题。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录数据在深度学习生存分析中具有巨大潜力，但由于预处理方法不一致严重限制了可复现性，需要标准化预处理流程来促进公平比较。

Method: 开发了SurvBench预处理流水线，支持三个重症监护数据库，包含数据质量控制、患者级分割、缺失值跟踪和标准化时间聚合，处理单风险和竞争风险场景。

Result: SurvBench提供了可复现的配置驱动预处理，输出与pycox库兼容，支持标准统计和深度学习模型，解决了"预处理差距"问题。

Conclusion: SurvBench通过提供标准化的预处理流程，使研究人员能够专注于方法创新而非数据工程，促进了深度学习生存分析的可复现性和公平比较。

Abstract: Electronic health record (EHR) data present tremendous opportunities for advancing survival analysis through deep learning, yet reproducibility remains severely constrained by inconsistent preprocessing methodologies. We present SurvBench, a comprehensive, open-source preprocessing pipeline that transforms raw PhysioNet datasets into standardised, model-ready tensors for multi-modal survival analysis. SurvBench provides data loaders for three major critical care databases, MIMIC-IV, eICU, and MC-MED, supporting diverse modalities including time-series vitals, static demographics, ICD diagnosis codes, and radiology reports. The pipeline implements rigorous data quality controls, patient-level splitting to prevent data leakage, explicit missingness tracking, and standardised temporal aggregation. SurvBench handles both single-risk (e.g., in-hospital mortality) and competing-risks scenarios (e.g., multiple discharge outcomes). The outputs are compatible with pycox library packages and implementations of standard statistical and deep learning models. By providing reproducible, configuration-driven preprocessing with comprehensive documentation, SurvBench addresses the "preprocessing gap" that has hindered fair comparison of deep learning survival models, enabling researchers to focus on methodological innovation rather than data engineering.

</details>


### [395] [Learning the relative composition of EEG signals using pairwise relative shift pretraining](https://arxiv.org/abs/2511.11940)
*Christopher Sandino,Sayeri Lala,Geeling Chau,Melika Ayoughi,Behrooz Mahasseni,Ellen Zippi,Ali Moin,Erdrin Azemi,Hanlin Goh*

Main category: cs.LG

TL;DR: 该论文提出了一种名为PARS的新型自监督学习预训练方法，通过预测EEG窗口对之间的相对时间偏移来学习长程依赖关系，在多种EEG解码任务中优于现有预训练策略。


<details>
  <summary>Details</summary>
Motivation: 当前EEG自监督学习方法主要使用掩码重建策略（如MAE），这些方法主要捕捉局部时间模式，而能够学习神经信号长程依赖关系的位置预测预训练方法尚未得到充分探索。

Method: 提出了PARS预训练方法，这是一种新颖的前置任务，通过预测随机采样的EEG窗口对之间的相对时间偏移来训练编码器，使其能够捕捉神经信号中的相对时间组合和长程依赖关系。

Result: 在多种EEG解码任务的综合评估中，PARS预训练的transformer模型在标签效率和迁移学习设置中始终优于现有的预训练策略。

Conclusion: PARS预训练为自监督EEG表示学习建立了新的范式，证明了其在学习神经信号长程依赖关系方面的有效性。

Abstract: Self-supervised learning (SSL) offers a promising approach for learning electroencephalography (EEG) representations from unlabeled data, reducing the need for expensive annotations for clinical applications like sleep staging and seizure detection. While current EEG SSL methods predominantly use masked reconstruction strategies like masked autoencoders (MAE) that capture local temporal patterns, position prediction pretraining remains underexplored despite its potential to learn long-range dependencies in neural signals. We introduce PAirwise Relative Shift or PARS pretraining, a novel pretext task that predicts relative temporal shifts between randomly sampled EEG window pairs. Unlike reconstruction-based methods that focus on local pattern recovery, PARS encourages encoders to capture relative temporal composition and long-range dependencies inherent in neural signals. Through comprehensive evaluation on various EEG decoding tasks, we demonstrate that PARS-pretrained transformers consistently outperform existing pretraining strategies in label-efficient and transfer learning settings, establishing a new paradigm for self-supervised EEG representation learning.

</details>


### [396] [Computation-aware Energy-harvesting Federated Learning: Cyclic Scheduling with Selective Participation](https://arxiv.org/abs/2511.11949)
*Eunjeong Jeong,Nikolaos Pappas*

Main category: cs.LG

TL;DR: FedBacys是一个基于电池感知的联邦学习框架，通过循环客户端参与来减少能量收集设备上的冗余计算和能耗


<details>
  <summary>Details</summary>
Motivation: 联邦学习在分布式学习中消耗大量能量，特别是在能量收集设备上，设备参与度因有限能量而不稳定

Method: 通过聚类客户端并基于电池水平进行顺序调度，还提出了FedBacys-Odd变体允许选择性参与

Result: 该框架减少了系统范围的能量使用，提高了学习稳定性，并通过收敛分析和数值实验验证了其优越性

Conclusion: FedBacys在能量效率和鲁棒性方面优于现有算法，为能量受限的联邦学习系统提供了有效解决方案

Abstract: Federated Learning (FL) is a powerful paradigm for distributed learning, but its increasing complexity leads to significant energy consumption from client-side computations for training models. In particular, the challenge is critical in energy-harvesting FL (EHFL) systems where participation availability of each device oscillates due to limited energy. To address this, we propose FedBacys, a battery-aware EHFL framework using cyclic client participation based on users' battery levels. By clustering clients and scheduling them sequentially, FedBacys minimizes redundant computations, reduces system-wide energy usage, and improves learning stability. We also introduce FedBacys-Odd, a more energy-efficient variant that allows clients to participate selectively, further reducing energy costs without compromising performance. We provide a convergence analysis for our framework and demonstrate its superior energy efficiency and robustness compared to existing algorithms through numerical experiments.

</details>


### [397] [Quantile Q-Learning: Revisiting Offline Extreme Q-Learning with Quantile Regression](https://arxiv.org/abs/2511.11973)
*Xinming Gao,Shangzhe Li,Yujin Cai,Wenwu Yu*

Main category: cs.LG

TL;DR: 该论文提出了一种改进的离线强化学习方法，通过量化回归估计温度系数β并引入值正则化技术，解决了XQL和MXQL方法需要大量超参数调优和训练不稳定的问题。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习在固定数据集上学习策略而无需环境交互，在高风险或成本高昂的领域特别有价值。但现有的XQL及其稳定变体MXQL存在两个主要问题：需要针对每个数据集和领域进行大量超参数调优，以及训练过程中表现出不稳定性。

Method: 1）提出基于温和假设的量化回归方法来估计温度系数β；2）引入受约束值学习启发的值正则化技术，具有温和的泛化能力。

Result: 实验结果表明，该算法在D4RL和NeoRL2等基准任务上实现了竞争性或更优的性能，同时保持了稳定的训练动态，并在所有数据集和领域中使用一致的超参数集。

Conclusion: 所提出的方法有效解决了离线强化学习中超参数敏感性和训练不稳定性的问题，为实际应用提供了更可靠和实用的解决方案。

Abstract: Offline reinforcement learning (RL) enables policy learning from fixed datasets without further environment interaction, making it particularly valuable in high-risk or costly domains. Extreme $Q$-Learning (XQL) is a recent offline RL method that models Bellman errors using the Extreme Value Theorem, yielding strong empirical performance. However, XQL and its stabilized variant MXQL suffer from notable limitations: both require extensive hyperparameter tuning specific to each dataset and domain, and also exhibit instability during training. To address these issues, we proposed a principled method to estimate the temperature coefficient $β$ via quantile regression under mild assumptions. To further improve training stability, we introduce a value regularization technique with mild generalization, inspired by recent advances in constrained value learning. Experimental results demonstrate that the proposed algorithm achieves competitive or superior performance across a range of benchmark tasks, including D4RL and NeoRL2, while maintaining stable training dynamics and using a consistent set of hyperparameters across all datasets and domains.

</details>


### [398] [ReCast: Reliability-aware Codebook Assisted Lightweight Time Series Forecasting](https://arxiv.org/abs/2511.11991)
*Xiang Ma,Taihua Chen,Pengcheng Wang,Xuemei Li,Caiming Zhang*

Main category: cs.LG

TL;DR: ReCast是一个轻量级、鲁棒的时间序列预测框架，通过可学习码本编码局部模式，采用双路径架构处理规则结构和不规则波动，并引入可靠性感知的码本更新策略。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖全局分解，在处理局部复杂动态模式时效果不佳，且模型复杂度高，难以在实时或资源受限环境中应用。

Method: ReCast通过补丁量化将局部模式编码为离散嵌入，使用双路径架构（量化路径和残差路径），并采用基于分布鲁棒优化的可靠性感知码本更新策略。

Result: 大量实验表明，ReCast在准确性、效率和适应分布偏移方面优于当前最先进模型。

Conclusion: ReCast提供了一个高效、鲁棒的时间序列预测解决方案，特别适用于资源受限和非平稳环境。

Abstract: Time series forecasting is crucial for applications in various domains. Conventional methods often rely on global decomposition into trend, seasonal, and residual components, which become ineffective for real-world series dominated by local, complex, and highly dynamic patterns. Moreover, the high model complexity of such approaches limits their applicability in real-time or resource-constrained environments. In this work, we propose a novel \textbf{RE}liability-aware \textbf{C}odebook-\textbf{AS}sisted \textbf{T}ime series forecasting framework (\textbf{ReCast}) that enables lightweight and robust prediction by exploiting recurring local shapes. ReCast encodes local patterns into discrete embeddings through patch-wise quantization using a learnable codebook, thereby compactly capturing stable regular structures. To compensate for residual variations not preserved by quantization, ReCast employs a dual-path architecture comprising a quantization path for efficient modeling of regular structures and a residual path for reconstructing irregular fluctuations. A central contribution of ReCast is a reliability-aware codebook update strategy, which incrementally refines the codebook via weighted corrections. These correction weights are derived by fusing multiple reliability factors from complementary perspectives by a distributionally robust optimization (DRO) scheme, ensuring adaptability to non-stationarity and robustness to distribution shifts. Extensive experiments demonstrate that ReCast outperforms state-of-the-art (SOTA) models in accuracy, efficiency, and adaptability to distribution shifts.

</details>


### [399] [Selecting Fine-Tuning Examples by Quizzing VLMs](https://arxiv.org/abs/2511.12002)
*Tenghao Ji,Eytan Adar*

Main category: cs.LG

TL;DR: QZLoRA是一个用于选择高质量图像进行LoRA微调的框架，通过QuizRank方法自动评估图像质量，从而提高文本到图像扩散模型的生成效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用质量参差不齐的图像集（如维基共享资源）进行微调会导致生成效果不佳，需要选择能够代表目标概念的高质量训练图像。

Method: 提出QZLoRA框架，结合QuizRank方法将图像视为'教育干预'，通过视觉语言模型进行'测验'来自动排名图像质量，然后进行低秩适应微调。

Result: QZLoRA能够用更少的样本生成更对齐、更逼真的图像，同时也能生成具有代表性的风格化插图。

Conclusion: 将自动视觉推理与参数高效微调相结合，为主题自适应生成建模提供了有前景的解决方案。

Abstract: A challenge in fine-tuning text-to-image diffusion models for specific topics is to select good examples. Fine-tuning from image sets of varying quality, such as Wikipedia Commons, will often produce poor output. However, training images that \textit{do} exemplify the target concept (e.g., a \textit{female Mountain Bluebird}) help ensure that the generated images are similarly representative (e.g., have the prototypical blue-wings and gray chest). In this work, we propose QZLoRA, a framework to select images for low-rank adaptation (LoRA). The approach leverages QuizRank, a method to automatically rank images by treating them as an `educational intervention' and `quizzing' a VLM. We demonstrate that QZLoRA can produce better aligned, photorealistic images with fewer samples. We also show that these fine-tuned models can produce stylized that are similarly representative (i.e., illustrations). Our results highlight the promise of combining automated visual reasoning with parameter-efficient fine-tuning for topic-adaptive generative modeling.

</details>


### [400] [EARL: Entropy-Aware RL Alignment of LLMs for Reliable RTL Code Generation](https://arxiv.org/abs/2511.12033)
*Jiahe Shi,Zhengqi Gao,Ching-Yun Ko,Duane Boning*

Main category: cs.LG

TL;DR: EARL提出了一种基于熵感知的强化学习框架，通过选择性更新高熵关键令牌来优化Verilog代码生成，显著提高了功能正确性和训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在硬件设计自动化中存在语法错误、功能幻觉和设计意图对齐不足的问题，需要更有效的方法来优化RTL代码生成。

Method: EARL采用熵感知强化学习框架，利用可验证的奖励信号进行策略优化，并通过熵引导的选择性更新机制，将梯度更新集中在影响控制流和模块结构的高熵令牌上。

Result: 在VerilogEval和RTLLM基准测试中，EARL将功能通过率比现有LLM基线提高了14.7%，同时减少了不必要的更新并提升了训练稳定性。

Conclusion: 通过将强化学习聚焦于关键高不确定性令牌，能够实现更可靠和有针对性的结构化RTL代码生成策略改进。

Abstract: Recent advances in large language models (LLMs) have demonstrated significant potential in hardware design automation, particularly in using natural language to synthesize Register-Transfer Level (RTL) code. Despite this progress, a gap remains between model capability and the demands of real-world RTL design, including syntax errors, functional hallucinations, and weak alignment to designer intent. Reinforcement Learning with Verifiable Rewards (RLVR) offers a promising approach to bridge this gap, as hardware provides executable and formally checkable signals that can be used to further align model outputs with design intent. However, in long, structured RTL code sequences, not all tokens contribute equally to functional correctness, and naïvely spreading gradients across all tokens dilutes learning signals. A key insight from our entropy analysis in RTL generation is that only a small fraction of tokens (e.g., always, if, assign, posedge) exhibit high uncertainty and largely influence control flow and module structure. To address these challenges, we present EARL, an Entropy-Aware Reinforcement Learning framework for Verilog generation. EARL performs policy optimization using verifiable reward signals and introduces entropy-guided selective updates that gate policy gradients to high-entropy tokens. This approach preserves training stability and concentrates gradient updates on functionally important regions of code. Our experiments on VerilogEval and RTLLM show that EARL improves functional pass rates over prior LLM baselines by up to 14.7%, while reducing unnecessary updates and improving training stability. These results indicate that focusing RL on critical, high-uncertainty tokens enables more reliable and targeted policy improvement for structured RTL code generation.

</details>


### [401] [Mesh-based Super-resolution of Detonation Flows with Multiscale Graph Transformers](https://arxiv.org/abs/2511.12041)
*Shivam Barwey,Pinaki Pal*

Main category: cs.LG

TL;DR: 提出了一种基于多尺度图变换器的网格超分辨率方法（SR-GT），用于反应流的超分辨率重建，相比传统插值方法具有更高精度。


<details>
  <summary>Details</summary>
Motivation: 超分辨率流场重建对于亚网格闭合建模、时空预测加速、数据压缩和实验测量上采样等应用具有重要价值。

Method: 开发了首个多尺度图变换器方法，利用图基流场表示兼容复杂几何和非均匀网格，通过变换器捕捉低分辨率流场的长程依赖关系并生成高分辨率流场。

Result: 在2D氢气-空气混合物爆轰传播的挑战性测试中，SR-GT对反应流场特征表现出高精度超分辨率性能，优于传统插值方法。

Conclusion: SR-GT框架为复杂多尺度反应流提供了一种有效的超分辨率解决方案，在保持关键特征的同时实现高质量上采样。

Abstract: Super-resolution flow reconstruction using state-of-the-art data-driven techniques is valuable for a variety of applications, such as subgrid/subfilter closure modeling, accelerating spatiotemporal forecasting, data compression, and serving as an upscaling tool for sparse experimental measurements. In the present work, a first-of-its-kind multiscale graph transformer approach is developed for mesh-based super-resolution (SR-GT) of reacting flows. The novel data-driven modeling paradigm leverages a graph-based flow-field representation compatible with complex geometries and non-uniform/unstructured grids. Further, the transformer backbone captures long-range dependencies between different parts of the low-resolution flow-field, identifies important features, and then generates the super-resolved flow-field that preserves those features at a higher resolution. The performance of SR-GT is demonstrated in the context of spectral-element-discretized meshes for a challenging test problem of 2D detonation propagation within a premixed hydrogen-air mixture exhibiting highly complex multiscale reacting flow behavior. The SR-GT framework utilizes a unique element-local (+ neighborhood) graph representation for the coarse input, which is then tokenized before being processed by the transformer component to produce the fine output. It is demonstrated that SR-GT provides high super-resolution accuracy for reacting flow-field features and superior performance compared to traditional interpolation-based SR schemes.

</details>


### [402] [Improving Graph Embeddings in Machine Learning Using Knowledge Completion with Validation in a Case Study on COVID-19 Spread](https://arxiv.org/abs/2511.12071)
*Rosario Napoli,Gabriele Morabito,Antonio Celesti,Massimo Villari,Maria Fazio*

Main category: cs.LG

TL;DR: 提出了一种集成知识补全阶段的GML流程，通过在嵌入生成前挖掘隐含语义来提升图表示质量，实验证明该方法能显著改变嵌入空间几何结构。


<details>
  <summary>Details</summary>
Motivation: 由于图嵌入通常基于显式拓扑和特征生成，可能错过稀疏数据集中隐藏的关键隐含知识，影响图结构和表示质量。

Method: 在GML流程中增加知识补全阶段，重点处理传递关系，使用基于衰减的推理函数建模隐藏连接，重塑图拓扑结构，影响GraphSAGE和Node2Vec中的嵌入动态和聚合过程。

Result: 实验表明该GML流程显著改变了嵌入空间的几何结构，证明知识补全不仅是简单的数据丰富，而是重新定义图表示质量的变革性步骤。

Conclusion: 集成知识补全的GML流程能够有效挖掘隐含语义，从根本上提升图表示学习的效果，为图机器学习提供了新的研究方向。

Abstract: The rise of graph-structured data has driven major advances in Graph Machine Learning (GML), where graph embeddings (GEs) map features from Knowledge Graphs (KGs) into vector spaces, enabling tasks like node classification and link prediction. However, since GEs are derived from explicit topology and features, they may miss crucial implicit knowledge hidden in seemingly sparse datasets, affecting graph structure and their representation. We propose a GML pipeline that integrates a Knowledge Completion (KC) phase to uncover latent dataset semantics before embedding generation. Focusing on transitive relations, we model hidden connections with decay-based inference functions, reshaping graph topology, with consequences on embedding dynamics and aggregation processes in GraphSAGE and Node2Vec. Experiments show that our GML pipeline significantly alters the embedding space geometry, demonstrating that its introduction is not just a simple enrichment but a transformative step that redefines graph representation quality.

</details>


### [403] [Treatment Stitching with Schrödinger Bridge for Enhancing Offline Reinforcement Learning in Adaptive Treatment Strategies](https://arxiv.org/abs/2511.12075)
*Dong-Hee Shin,Deok-Joong Lee,Young-Han Son,Tae-Eui Kam*

Main category: cs.LG

TL;DR: 提出了Treatment Stitching (TreatStitch)框架，通过智能拼接现有治疗数据片段来生成临床有效的治疗轨迹，解决离线强化学习在临床数据稀缺情况下的性能限制问题。


<details>
  <summary>Details</summary>
Motivation: 自适应治疗策略需要动态调整治疗方案，但传统强化学习的在线试错机制在临床环境中不可行，而离线强化学习又受限于数据稀缺问题。

Method: TreatStitch框架识别不同轨迹中相似的中间患者状态并拼接其相应片段；对于不相似的状态，使用薛定谔桥方法生成平滑的桥接轨迹。通过增加合成轨迹来丰富数据集。

Result: 在多个治疗数据集上的实验证明TreatStitch能有效提升离线强化学习性能，且理论分析表明该方法能保持临床有效性，避免分布外转移。

Conclusion: TreatStitch为解决临床数据稀缺问题提供了有效的数据增强方案，能够生成临床有效的治疗轨迹，显著提升离线强化学习在自适应治疗策略优化中的性能。

Abstract: Adaptive treatment strategies (ATS) are sequential decision-making processes that enable personalized care by dynamically adjusting treatment decisions in response to evolving patient symptoms. While reinforcement learning (RL) offers a promising approach for optimizing ATS, its conventional online trial-and-error learning mechanism is not permissible in clinical settings due to risks of harm to patients. Offline RL tackles this limitation by learning policies exclusively from historical treatment data, but its performance is often constrained by data scarcity-a pervasive challenge in clinical domains. To overcome this, we propose Treatment Stitching (TreatStitch), a novel data augmentation framework that generates clinically valid treatment trajectories by intelligently stitching segments from existing treatment data. Specifically, TreatStitch identifies similar intermediate patient states across different trajectories and stitches their respective segments. Even when intermediate states are too dissimilar to stitch directly, TreatStitch leverages the Schrödinger bridge method to generate smooth and energy-efficient bridging trajectories that connect dissimilar states. By augmenting these synthetic trajectories into the original dataset, offline RL can learn from a more diverse dataset, thereby improving its ability to optimize ATS. Extensive experiments across multiple treatment datasets demonstrate the effectiveness of TreatStitch in enhancing offline RL performance. Furthermore, we provide a theoretical justification showing that TreatStitch maintains clinical validity by avoiding out-of-distribution transitions.

</details>


### [404] [SenseRay-3D: Generalizable and Physics-Informed Framework for End-to-End Indoor Propagation Modeling](https://arxiv.org/abs/2511.12092)
*Yu Zheng,Kezhi Wang,Wenji Xi,Gang Yu,Jiming Chen,Jie Zhang*

Main category: cs.LG

TL;DR: SenseRay-3D是一个可泛化的、物理信息驱动的端到端框架，直接从RGB-D扫描预测3D路径损耗热力图，无需显式几何重建或材料标注。


<details>
  <summary>Details</summary>
Motivation: 现有室内无线电传播建模方法依赖人工建模几何和材料特性，导致可扩展性和效率有限。

Method: 构建感知驱动的体素化场景表示，联合编码占用率、电磁材料特性和发射器-接收器几何关系，通过SwinUNETR神经网络推断环境路径损耗。

Result: 在未见环境中达到4.27 dB的平均绝对误差，支持实时推理（217 ms/样本），展示了可扩展性、效率和物理一致性。

Conclusion: SenseRay-3D为感知驱动、可泛化和物理一致的室内传播建模开辟了新路径，超越了之前的EM DeepRay框架。

Abstract: Modeling indoor radio propagation is crucial for wireless network planning and optimization. However, existing approaches often rely on labor-intensive manual modeling of geometry and material properties, resulting in limited scalability and efficiency. To overcome these challenges, this paper presents SenseRay-3D, a generalizable and physics-informed end-to-end framework that predicts three-dimensional (3D) path-loss heatmaps directly from RGB-D scans, thereby eliminating the need for explicit geometry reconstruction or material annotation. The proposed framework builds a sensing-driven voxelized scene representation that jointly encodes occupancy, electromagnetic material characteristics, and transmitter-receiver geometry, which is processed by a SwinUNETR-based neural network to infer environmental path-loss relative to free-space path-loss. A comprehensive synthetic indoor propagation dataset is further developed to validate the framework and to serve as a standardized benchmark for future research. Experimental results show that SenseRay-3D achieves a mean absolute error of 4.27 dB on unseen environments and supports real-time inference at 217 ms per sample, demonstrating its scalability, efficiency, and physical consistency. SenseRay-3D paves a new path for sense-driven, generalizable, and physics-consistent modeling of indoor propagation, marking a major leap beyond our pioneering EM DeepRay framework.

</details>


### [405] [To Align or Not to Align: Strategic Multimodal Representation Alignment for Optimal Performance](https://arxiv.org/abs/2511.12121)
*Wanlong Fang,Tianle Zhang,Alvin Chan*

Main category: cs.LG

TL;DR: 本研究通过可控对比学习模块系统研究显式对齐对模型性能的影响，发现最优对齐强度取决于模态间的冗余度，需要平衡模态特定信号和共享冗余信息。


<details>
  <summary>Details</summary>
Motivation: 传统多模态学习假设表示对齐总是有益的，但缺乏对显式对齐直接影响的系统性研究，需要探索在不同模态信息结构下对齐如何影响性能。

Method: 引入可控对比学习模块，在训练过程中精确控制对齐强度，使用合成和真实数据集在不同数据特征下进行实验。

Result: 结果显示显式对齐对单模态模型性能的影响与数据特征相关，最优对齐水平取决于不同模态间的冗余量。

Conclusion: 本研究为何时以及如何应用显式对齐以实现最优单模态编码器性能提供了实用指导。

Abstract: Multimodal learning often relies on aligning representations across modalities to enable effective information integration, an approach traditionally assumed to be universally beneficial. However, prior research has primarily taken an observational approach, examining naturally occurring alignment in multimodal data and exploring its correlation with model performance, without systematically studying the direct effects of explicitly enforced alignment between representations of different modalities. In this work, we investigate how explicit alignment influences both model performance and representation alignment under different modality-specific information structures. Specifically, we introduce a controllable contrastive learning module that enables precise manipulation of alignment strength during training, allowing us to explore when explicit alignment improves or hinders performance. Our results on synthetic and real datasets under different data characteristics show that the impact of explicit alignment on the performance of unimodal models is related to the characteristics of the data: the optimal level of alignment depends on the amount of redundancy between the different modalities. We identify an optimal alignment strength that balances modality-specific signals and shared redundancy in the mixed information distributions. This work provides practical guidance on when and how explicit alignment should be applied to achieve optimal unimodal encoder performance.

</details>


### [406] [Dynamic Anomaly Identification in Accounting Transactions via Multi-Head Self-Attention Networks](https://arxiv.org/abs/2511.12122)
*Yi Wang,Ruoyi Fang,Anzhuo Xie,Hanrui Feng,Jianlin Lai*

Main category: cs.LG

TL;DR: 提出基于Transformer的实时会计交易异常检测方法，通过多维度时间序列建模和多头自注意力机制捕捉全局依赖关系，在公开数据集上验证了方法的优越性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决复杂交易环境中隐藏异常行为和高时效性要求的动态异常检测问题，为智能金融风控和审计提供方法支持。

Method: 将多维会计交易记录建模为时间序列矩阵，使用嵌入层和位置编码进行低维映射，构建包含多头自注意力机制和前馈层的序列建模结构，结合正则化策略实现深度特征表示和异常概率估计。

Result: 在公开数据集上的实验表明，该方法在AUC、F1-Score、精确率和召回率等指标上优于基线模型，在不同环境条件和数据扰动下保持稳定性能。

Conclusion: 基于Transformer的框架在会计交易动态异常检测中具有适用性和优势，为智能金融风险控制提供了有效的方法论支持。

Abstract: This study addresses the problem of dynamic anomaly detection in accounting transactions and proposes a real-time detection method based on a Transformer to tackle the challenges of hidden abnormal behaviors and high timeliness requirements in complex trading environments. The approach first models accounting transaction data by representing multi-dimensional records as time-series matrices and uses embedding layers and positional encoding to achieve low-dimensional mapping of inputs. A sequence modeling structure with multi-head self-attention is then constructed to capture global dependencies and aggregate features from multiple perspectives, thereby enhancing the ability to detect abnormal patterns. The network further integrates feed-forward layers and regularization strategies to achieve deep feature representation and accurate anomaly probability estimation. To validate the effectiveness of the method, extensive experiments were conducted on a public dataset, including comparative analysis, hyperparameter sensitivity tests, environmental sensitivity tests, and data sensitivity tests. Results show that the proposed method outperforms baseline models in AUC, F1-Score, Precision, and Recall, and maintains stable performance under different environmental conditions and data perturbations. These findings confirm the applicability and advantages of the Transformer-based framework for dynamic anomaly detection in accounting transactions and provide methodological support for intelligent financial risk control and auditing.

</details>


### [407] [HCPO: Hierarchical Conductor-Based Policy Optimization in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2511.12123)
*Zejiao Liu,Junqi Tu,Yitian Hong,Luolin Xiong,Yaochu Jin,Yang Tang,Fangfei Li*

Main category: cs.LG

TL;DR: 提出了一种基于指挥者的联合策略框架HCPO，通过分层协调机制增强多智能体强化学习中的联合策略表达能力和探索效率，在多个基准测试中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体强化学习方法通常采用独立智能体探索策略，缺乏协调机制，限制了联合策略的表达能力和探索效率。

Method: 设计了基于指挥者的联合策略框架，开发了分层指挥者策略优化算法(HCPO)，通过指挥者协调智能体的策略更新方向，保持集中训练优势同时避免执行时的通信开销。

Result: 在StarCraftII多智能体挑战、多智能体MuJoCo和多智能体粒子环境三个基准测试中，HCPO在合作效率和稳定性方面均优于现有基线方法。

Conclusion: HCPO通过引入指挥者协调机制有效提升了多智能体强化学习的联合策略表达能力，理论保证和实验验证了方法的有效性和优越性。

Abstract: In cooperative Multi-Agent Reinforcement Learning (MARL), efficient exploration is crucial for optimizing the performance of joint policy. However, existing methods often update joint policies via independent agent exploration, without coordination among agents, which inherently constrains the expressive capacity and exploration of joint policies. To address this issue, we propose a conductor-based joint policy framework that directly enhances the expressive capacity of joint policies and coordinates exploration. In addition, we develop a Hierarchical Conductor-based Policy Optimization (HCPO) algorithm that instructs policy updates for the conductor and agents in a direction aligned with performance improvement. A rigorous theoretical guarantee further establishes the monotonicity of the joint policy optimization process. By deploying local conductors, HCPO retains centralized training benefits while eliminating inter-agent communication during execution. Finally, we evaluate HCPO on three challenging benchmarks: StarCraftII Multi-agent Challenge, Multi-agent MuJoCo, and Multi-agent Particle Environment. The results indicate that HCPO outperforms competitive MARL baselines regarding cooperative efficiency and stability.

</details>


### [408] [FairGSE: Fairness-Aware Graph Neural Network without High False Positive Rates](https://arxiv.org/abs/2511.12132)
*Zhenqiang Ye,Jinjie Lu,Tianlong Gu,Fengrui Hao,Xuemin Wang*

Main category: cs.LG

TL;DR: 该论文提出FairGSE框架，通过最大化二维结构熵来改善图神经网络的公平性，同时显著降低假阳性率。


<details>
  <summary>Details</summary>
Motivation: 现有公平感知GNN在追求公平性指标时忽视了负标签预测能力，导致假阳性率极高，在高风险场景中产生负面影响。

Method: 提出FairGSE框架，通过最大化二维结构熵来平衡公平性和分类性能，避免单纯约束准确率损失。

Result: 在多个真实数据集上的实验表明，FairGSE相比最先进的公平感知GNN将假阳性率降低了39%，同时保持可比的公平性改进。

Conclusion: 在改进公平性的同时需要仔细校准分类性能，而不仅仅是约束准确率损失，FairGSE为此提供了有效解决方案。

Abstract: Graph neural networks (GNNs) have emerged as the mainstream paradigm for graph representation learning due to their effective message aggregation. However, this advantage also amplifies biases inherent in graph topology, raising fairness concerns. Existing fairness-aware GNNs provide satisfactory performance on fairness metrics such as Statistical Parity and Equal Opportunity while maintaining acceptable accuracy trade-offs. Unfortunately, we observe that this pursuit of fairness metrics neglects the GNN's ability to predict negative labels, which renders their predictions with extremely high False Positive Rates (FPR), resulting in negative effects in high-risk scenarios. To this end, we advocate that classification performance should be carefully calibrated while improving fairness, rather than simply constraining accuracy loss. Furthermore, we propose Fair GNN via Structural Entropy (\textbf{FairGSE}), a novel framework that maximizes two-dimensional structural entropy (2D-SE) to improve fairness without neglecting false positives. Experiments on several real-world datasets show FairGSE reduces FPR by 39\% vs. state-of-the-art fairness-aware GNNs, with comparable fairness improvement.

</details>


### [409] [Fusion-ResNet: A Lightweight multi-label NILM Model Using PCA-ICA Feature Fusion](https://arxiv.org/abs/2511.12139)
*Sahar Moghimian Hoosh,Ilia Kamyshev,Henni Ouerdane*

Main category: cs.LG

TL;DR: 本文提出了一种端到端的非侵入式负载监测分类框架，融合了ICA和PCA特征提取方法，并设计了轻量级神经网络Fusion-ResNet，在保持高精度的同时显著减少了训练和推理时间。


<details>
  <summary>Details</summary>
Motivation: 解决实际NILM部署中面临的过拟合、模型泛化能力差以及多设备同时运行时的分解难题。

Method: 提出包含高频标记数据、特征提取方法和轻量神经网络的端到端框架，其中特征提取融合了独立成分分析和主成分分析，网络采用多标签分类的Fusion-ResNet架构。

Result: 相比现有最优NILM分类器，所提模型在平均F1分数和各设备F1分数上表现更优，训练和推理时间显著减少，且在15个设备同时运行的应力条件下仍保持相对鲁棒性。

Conclusion: Fusion-ResNet框架有效提升了NILM分类性能，具备实际部署的可行性和鲁棒性。

Abstract: Non-intrusive load monitoring (NILM) is an advanced load monitoring technique that uses data-driven algorithms to disaggregate the total power consumption of a household into the consumption of individual appliances. However, real-world NILM deployment still faces major challenges, including overfitting, low model generalization, and disaggregating a large number of appliances operating at the same time. To address these challenges, this work proposes an end-to-end framework for the NILM classification task, which consists of high-frequency labeled data, a feature extraction method, and a lightweight neural network. Within this framework, we introduce a novel feature extraction method that fuses Independent Component Analysis (ICA) and Principal Component Analysis (PCA) features. Moreover, we propose a lightweight architecture for multi-label NILM classification (Fusion-ResNet). The proposed feature-based model achieves a higher $F1$ score on average and across different appliances compared to state-of-the-art NILM classifiers while minimizing the training and inference time. Finally, we assessed the performance of our model against baselines with a varying number of simultaneously active devices. Results demonstrate that Fusion-ResNet is relatively robust to stress conditions with up to 15 concurrently active appliances.

</details>


### [410] [Variation-Bounded Loss for Noise-Tolerant Learning](https://arxiv.org/abs/2511.12143)
*Jialiang Wang,Xiong Zhou,Xianming Liu,Gangfeng Hu,Deming Zhai,Junjun Jiang,Haoliang Li*

Main category: cs.LG

TL;DR: 本文提出了一种新的损失函数鲁棒性指标——变异比，并基于此构建了变异有界损失函数族，通过理论分析和实验验证了其在噪声标签学习中的有效性。


<details>
  <summary>Details</summary>
Motivation: 噪声标签对监督学习具有负面影响，现有鲁棒损失函数方法存在局限性，需要更有效的解决方案来提升模型对噪声标签的鲁棒性。

Method: 提出变异比作为损失函数鲁棒性的新指标，构建变异有界损失函数族，通过理论证明较小变异比可带来更好鲁棒性，并重新形式化常用损失函数为变异有界形式。

Result: 在各种数据集上的实验表明，所提出的方法具有有效性和灵活性，能够显著提升模型在噪声标签环境下的性能。

Conclusion: 变异比为损失函数鲁棒性分析提供了新视角，变异有界损失函数族为噪声标签学习问题提供了更简洁有效的解决方案。

Abstract: Mitigating the negative impact of noisy labels has been aperennial issue in supervised learning. Robust loss functions have emerged as a prevalent solution to this problem. In this work, we introduce the Variation Ratio as a novel property related to the robustness of loss functions, and propose a new family of robust loss functions, termed Variation-Bounded Loss (VBL), which is characterized by a bounded variation ratio. We provide theoretical analyses of the variation ratio, proving that a smaller variation ratio would lead to better robustness. Furthermore, we reveal that the variation ratio provides a feasible method to relax the symmetric condition and offers a more concise path to achieve the asymmetric condition. Based on the variation ratio, we reformulate several commonly used loss functions into a variation-bounded form for practical applications. Positive experiments on various datasets exhibit the effectiveness and flexibility of our approach.

</details>


### [411] [Finding Time Series Anomalies using Granular-ball Vector Data Description](https://arxiv.org/abs/2511.12147)
*Lifeng Shen,Liang Peng,Ruiwen Liu,Shuyin Xia,Yi Liu*

Main category: cs.LG

TL;DR: GBOC是一种基于粒度球向量数据描述的异常检测方法，通过密度引导的分层分裂过程将潜在空间划分为紧凑的高密度区域，显著减少原型数量，提高检测的鲁棒性和效率。


<details>
  <summary>Details</summary>
Motivation: 传统异常检测方法（如最近邻和聚类）依赖刚性假设（如预定义的可靠邻居或聚类数量），在复杂时间序列场景中容易失效，需要更适应数据动态特性的方法。

Method: 提出粒度球单类网络（GBOC），使用粒度球向量数据描述（GVDD）将潜在空间划分为由粒度球表示的紧凑高密度区域，通过密度引导的分层分裂生成并去噪，训练时通过对齐样本与最近粒度球中心提高表示紧凑性，推断时基于到最近粒度球的距离计算异常分数。

Result: 大量实验验证了该方法的有效性和优越性，表明其能够有效处理时间序列异常检测的挑战。

Conclusion: GBOC通过聚焦密集高质量区域和减少原型数量，在异常检测中实现了鲁棒性和效率的平衡，为动态非线性时间序列的正常行为建模提供了有效解决方案。

Abstract: Modeling normal behavior in dynamic, nonlinear time series data is challenging for effective anomaly detection. Traditional methods, such as nearest neighbor and clustering approaches, often depend on rigid assumptions, such as a predefined number of reliable neighbors or clusters, which frequently break down in complex temporal scenarios. To address these limitations, we introduce the Granular-ball One-Class Network (GBOC), a novel approach based on a data-adaptive representation called Granular-ball Vector Data Description (GVDD). GVDD partitions the latent space into compact, high-density regions represented by granular-balls, which are generated through a density-guided hierarchical splitting process and refined by removing noisy structures. Each granular-ball serves as a prototype for local normal behavior, naturally positioning itself between individual instances and clusters while preserving the local topological structure of the sample set. During training, GBOC improves the compactness of representations by aligning samples with their nearest granular-ball centers. During inference, anomaly scores are computed based on the distance to the nearest granular-ball. By focusing on dense, high-quality regions and significantly reducing the number of prototypes, GBOC delivers both robustness and efficiency in anomaly detection. Extensive experiments validate the effectiveness and superiority of the proposed method, highlighting its ability to handle the challenges of time series anomaly detection.

</details>


### [412] [Open Banking Foundational Model: Learning Language Representations from Few Financial Transactions](https://arxiv.org/abs/2511.12154)
*Gustavo Polleti,Marlesson Santana,Eduardo Fontes*

Main category: cs.LG

TL;DR: 提出了一个多模态基础模型，将结构化属性和非结构化文本描述整合为统一表示，在金融交易任务中表现优异


<details>
  <summary>Details</summary>
Motivation: 解决传统特征工程和离散事件序列方法在金融交易分析中的局限性，特别是在数据稀缺的开放银行场景下

Method: 采用掩码语言建模适应交易序列，整合结构化和非结构化数据构建多模态表示

Result: 模型在北美数千家金融机构的大规模研究中表现出色，能够跨地域和机构泛化

Conclusion: 自监督模型在欺诈预防、信用风险和客户洞察等金融应用领域具有巨大潜力

Abstract: We introduced a multimodal foundational model for financial transactions that integrates both structured attributes and unstructured textual descriptions into a unified representation. By adapting masked language modeling to transaction sequences, we demonstrated that our approach not only outperforms classical feature engineering and discrete event sequence methods but is also particularly effective in data-scarce Open Banking scenarios. To our knowledge, this is the first large-scale study across thousands of financial institutions in North America, providing evidence that multimodal representations can generalize across geographies and institutions. These results highlight the potential of self-supervised models to advance financial applications ranging from fraud prevention and credit risk to customer insights

</details>


### [413] [Rethinking Deep Alignment Through The Lens Of Incomplete Learning](https://arxiv.org/abs/2511.12155)
*Thong Bach,Dung Nguyen,Thao Minh Le,Truyen Tran*

Main category: cs.LG

TL;DR: 论文分析了LLM在自回归训练中的位置依赖梯度衰减问题，提出基础偏好标记作为安全学习不完整的计算指标，并开发了针对性补全方法，显著提升了对抗攻击鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管进行了广泛的安全对齐训练，大语言模型仍然存在系统性的对抗攻击漏洞。研究发现这是由于自回归训练中的位置依赖梯度衰减导致信号衰减，使得安全训练无法完全转换模型在后续响应区域的偏好。

Method: 引入基础偏好标记作为安全学习不完整的计算指标，开发了针对性补全方法，通过自适应惩罚和混合教师蒸馏来解决训练不足的区域。

Result: 在Llama和Qwen模型系列上的实验评估显示对抗鲁棒性显著提升，攻击成功率降低了48-98%，同时保持了通用能力。

Conclusion: 该研究为安全对齐方法的基本局限性建立了机制性理解，并提供了实用的解决方案。

Abstract: Large language models exhibit systematic vulnerabilities to adversarial attacks despite extensive safety alignment. We provide a mechanistic analysis revealing that position-dependent gradient weakening during autoregressive training creates signal decay, leading to incomplete safety learning where safety training fails to transform model preferences in later response regions fully. We introduce base-favored tokens -- vocabulary elements where base models assign higher probability than aligned models -- as computational indicators of incomplete safety learning and develop a targeted completion method that addresses undertrained regions through adaptive penalties and hybrid teacher distillation. Experimental evaluation across Llama and Qwen model families demonstrates dramatic improvements in adversarial robustness, with 48--98% reductions in attack success rates while preserving general capabilities. These results establish both a mechanistic understanding and practical solutions for fundamental limitations in safety alignment methodologies.

</details>


### [414] [Data-Efficient Self-Supervised Algorithms for Fine-Grained Birdsong Analysis](https://arxiv.org/abs/2511.12158)
*Houtan Ghaffari,Lukas Rauch,Paul Devos*

Main category: cs.LG

TL;DR: 提出了一种轻量级神经网络架构Residual-MLP-RNN和三阶段训练流程，用于在标注数据稀缺情况下实现高效的鸟类鸣叫音节检测。


<details>
  <summary>Details</summary>
Motivation: 鸟类鸣叫研究需要精确的音节级标注，但标注成本高昂，需要开发数据效率高的自动化方法。

Method: 采用三阶段训练：1）无监督预训练（掩码预测和在线聚类）；2）带数据增强的监督训练；3）与下游任务对齐的半监督后训练。

Result: 在Canary复杂鸣叫的极端标注稀缺场景下验证了方法的有效性，证明了自监督嵌入在线性探测和无监督分析中的潜力。

Conclusion: 该方法能够显著降低专家标注工作量，为复杂鸟类鸣叫分析提供了可靠解决方案。

Abstract: Many bioacoustics, neuroscience, and linguistics research utilize birdsongs as proxy models to acquire knowledge in diverse areas. Developing models generally requires precisely annotated data at the level of syllables. Hence, automated and data-efficient methods that reduce annotation costs are in demand. This work presents a lightweight, yet performant neural network architecture for birdsong annotation called Residual-MLP-RNN. Then, it presents a robust three-stage training pipeline for developing reliable deep birdsong syllable detectors with minimal expert labor. The first stage is self-supervised learning from unlabeled data. Two of the most successful pretraining paradigms are explored, namely, masked prediction and online clustering. The second stage is supervised training with effective data augmentations to create a robust model for frame-level syllable detection. The third stage is semi-supervised post-training, which leverages the unlabeled data again. However, unlike the initial phase, this time it is aligned with the downstream task. The performance of this data-efficient approach is demonstrated for the complex song of the Canary in extreme label-scarcity scenarios. Canary has one of the most difficult songs to annotate, which implicitly validates the method for other birds. Finally, the potential of self-supervised embeddings is assessed for linear probing and unsupervised birdsong analysis.

</details>


### [415] [FGM optimization in complex domains using Gaussian process regression based profile generation algorithm](https://arxiv.org/abs/2511.12171)
*Chaitanya Kumar Konda,Piyush Agrawal,Shivansh Srivastava,Manish Agrawal*

Main category: cs.LG

TL;DR: 提出了一种基于高斯过程回归的通用体积分数剖面生成算法，用于设计任意形状功能梯度材料，并耦合遗传算法进行优化。


<details>
  <summary>Details</summary>
Motivation: 解决任意形状域中功能梯度材料设计挑战，需要处理复杂形状域并生成平滑的FGM剖面。

Method: 基于高斯过程回归的体积分数剖面生成算法，可控制剖面平滑度和设计空间大小，并改进遗传算法的交叉算子。

Result: 算法能够处理复杂形状域，生成平滑的FGM剖面，并通过热弹性优化示例验证了有效性。

Conclusion: 提出的剖面生成算法和优化框架为功能梯度材料设计提供了有效的解决方案。

Abstract: This manuscript addresses the challenge of designing functionally graded materials (FGMs) for arbitrary-shaped domains. Towards this goal, the present work proposes a generic volume fraction profile generation algorithm based on Gaussian Process Regression (GPR). The proposed algorithm can handle complex-shaped domains and generate smooth FGM profiles while adhering to the specified volume fraction values at boundaries/part of boundaries. The resulting design space from GPR comprises diverse profiles, enhancing the potential for discovering optimal configurations. Further, the algorithm allows the user to control the smoothness of the underlying profiles and the size of the design space through a length scale parameter. Further, the proposed profile generation scheme is coupled with the genetic algorithm to find the optimum FGM profiles for a given application. To make the genetic algorithm consistent with the GPR profile generation scheme, the standard simulated binary crossover operator in the genetic algorithm has been modified with a projection operator. We present numerous thermoelastic optimization examples to demonstrate the efficacy of the proposed profile generation algorithm and optimization framework.

</details>


### [416] [TSGDiff: Rethinking Synthetic Time Series Generation from a Pure Graph Perspective](https://arxiv.org/abs/2511.12174)
*Lifeng Shen,Xuyang Li,Lele Long*

Main category: cs.LG

TL;DR: TSGDiff是一个基于图神经网络的时间序列生成框架，通过将时间序列表示为动态图，利用扩散模型有效捕捉复杂的时间依赖性和结构模式。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在数据生成方面表现出巨大潜力，但生成时间序列数据仍然具有挑战性，因为需要捕捉复杂的时间依赖性和结构模式。

Method: 将时间序列表示为基于傅里叶频谱特征和时间依赖性构建的动态图，采用图神经网络的编码器-解码器架构构建潜在空间，使扩散过程能够有效建模时间序列的结构表示分布。

Result: 在真实世界数据集上的实验表明，TSGDiff能够生成高质量的时间序列数据，忠实保留时间依赖性和结构完整性。

Conclusion: TSGDiff通过图视角重新思考时间序列生成，提出了拓扑结构保真度评分，推动了合成时间序列生成领域的发展。

Abstract: Diffusion models have shown great promise in data generation, yet generating time series data remains challenging due to the need to capture complex temporal dependencies and structural patterns. In this paper, we present \textit{TSGDiff}, a novel framework that rethinks time series generation from a graph-based perspective. Specifically, we represent time series as dynamic graphs, where edges are constructed based on Fourier spectrum characteristics and temporal dependencies. A graph neural network-based encoder-decoder architecture is employed to construct a latent space, enabling the diffusion process to model the structural representation distribution of time series effectively. Furthermore, we propose the Topological Structure Fidelity (Topo-FID) score, a graph-aware metric for assessing the structural similarity of time series graph representations. Topo-FID integrates two sub-metrics: Graph Edit Similarity, which quantifies differences in adjacency matrices, and Structural Entropy Similarity, which evaluates the entropy of node degree distributions. This comprehensive metric provides a more accurate assessment of structural fidelity in generated time series. Experiments on real-world datasets demonstrate that \textit{TSGDiff} generates high-quality synthetic time series data generation, faithfully preserving temporal dependencies and structural integrity, thereby advancing the field of synthetic time series generation.

</details>


### [417] [Understanding InfoNCE: Transition Probability Matrix Induced Feature Clustering](https://arxiv.org/abs/2511.12180)
*Ge Cheng,Shuo Wang,Yun Zhang*

Main category: cs.LG

TL;DR: 提出了SC-InfoNCE损失函数，通过引入可调收敛目标来灵活控制特征相似性对齐，在多个基准数据集上实现了稳定性能


<details>
  <summary>Details</summary>
Motivation: InfoNCE虽然经验上成功，但其理论基础有限，需要更深入理解其优化机制

Method: 引入显式特征空间建模样本增强视图，使用转移概率矩阵捕捉数据增强动态，提出SC-InfoNCE损失函数

Result: 在图像、图结构和文本任务的基准数据集上，SC-InfoNCE始终实现强大可靠的性能

Conclusion: SC-InfoNCE通过可扩展的目标矩阵实现灵活的特征相似性控制，使训练目标更好地匹配下游数据的统计特性

Abstract: Contrastive learning has emerged as a cornerstone of unsupervised representation learning across vision, language, and graph domains, with InfoNCE as its dominant objective. Despite its empirical success, the theoretical underpinnings of InfoNCE remain limited. In this work, we introduce an explicit feature space to model augmented views of samples and a transition probability matrix to capture data augmentation dynamics. We demonstrate that InfoNCE optimizes the probability of two views sharing the same source toward a constant target defined by this matrix, naturally inducing feature clustering in the representation space. Leveraging this insight, we propose Scaled Convergence InfoNCE (SC-InfoNCE), a novel loss function that introduces a tunable convergence target to flexibly control feature similarity alignment. By scaling the target matrix, SC-InfoNCE enables flexible control over feature similarity alignment, allowing the training objective to better match the statistical properties of downstream data. Experiments on benchmark datasets, including image, graph, and text tasks, show that SC-InfoNCE consistently achieves strong and reliable performance across diverse domains.

</details>


### [418] [Scaling Law Analysis in Federated Learning: How to Select the Optimal Model Size?](https://arxiv.org/abs/2511.12188)
*Xuanyu Chen,Nan Yang,Shuai Wang,Dong Yuan*

Main category: cs.LG

TL;DR: 本文研究了联邦学习（FL）中模型规模扩展的理论基础，通过PAC-Bayes理论推导了联邦学习场景下模型泛化误差的上界，并量化了分布式训练数据对最优模型规模的影响。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型规模的不断扩大，高质量训练数据的匮乏问题日益突出。联邦学习能够利用边缘设备上的海量数据并保护隐私，但分布式训练数据集给大模型扩展带来了挑战，这一领域尚缺乏深入研究。

Method: 推导了联邦学习场景下随机算法训练模型的PAC-Bayes泛化误差上界，通过求解最小化该上界的解析解来量化分布式训练数据对最优模型规模的影响。

Result: 理论结果表明，在总训练计算量不变的情况下，最优模型规模与客户端数量呈负幂律关系。切换到联邦学习会降低模型通过训练能达到的泛化性能上界，且最优模型规模估计应基于客户端的平均训练计算量。

Conclusion: 通过不同模型、网络设置和数据集的广泛训练实验，验证了理论结果的正确性，为联邦学习中的模型规模扩展提供了理论指导和实践验证。

Abstract: The recent success of large language models (LLMs) has sparked a growing interest in training large-scale models. As the model size continues to scale, concerns are growing about the depletion of high-quality, well-curated training data. This has led practitioners to explore training approaches like Federated Learning (FL), which can leverage the abundant data on edge devices while maintaining privacy. However, the decentralization of training datasets in FL introduces challenges to scaling large models, a topic that remains under-explored. This paper fills this gap and provides qualitative insights on generalizing the previous model scaling experience to federated learning scenarios. Specifically, we derive a PAC-Bayes (Probably Approximately Correct Bayesian) upper bound for the generalization error of models trained with stochastic algorithms in federated settings and quantify the impact of distributed training data on the optimal model size by finding the analytic solution of model size that minimizes this bound. Our theoretical results demonstrate that the optimal model size has a negative power law relationship with the number of clients if the total training compute is unchanged. Besides, we also find that switching to FL with the same training compute will inevitably reduce the upper bound of generalization performance that the model can achieve through training, and that estimating the optimal model size in federated scenarios should depend on the average training compute across clients. Furthermore, we also empirically validate the correctness of our results with extensive training runs on different models, network settings, and datasets.

</details>


### [419] [Evaluation of Multi- and Single-objective Learning Algorithms for Imbalanced Data](https://arxiv.org/abs/2511.12191)
*Szymon Wojciechowski,Michał Woźniak*

Main category: cs.LG

TL;DR: 本文提出了一种新的可靠方法来评估基于多目标优化的算法与返回单一解的方法，特别关注从Pareto前沿中选择符合用户偏好的解来进行公平比较。


<details>
  <summary>Details</summary>
Motivation: 机器学习任务中常需要平衡多个对立标准，如不平衡数据分类。传统聚合方法存在解释模糊问题，而多目标优化方法产生Pareto前沿解集，但如何与单一解方法进行可靠比较存在方法论空白。

Method: 提出新的评估方法，通过从Pareto前沿中选择符合用户偏好的解来与返回单一解的方法进行公平比较。研究仅关注算法比较而非学习过程，选用说明性算法来验证方法。

Result: 开发了一种可靠的比较框架，能够公平评估多目标优化算法与单一解返回方法，解决了现有评估方法中的可比性问题。

Conclusion: 填补了分类器评估方法论的空白，为多目标优化算法与单一解方法的可靠比较提供了新途径，特别强调了用户偏好在解选择中的重要性。

Abstract: Many machine learning tasks aim to find models that work well not for a single, but for a group of criteria, often opposing ones. One such example is imbalanced data classification, where, on the one hand, we want to achieve the best possible classification quality for data from the minority class without degrading the classification quality of the majority class. One solution is to propose an aggregate learning criterion and reduce the multi-objective learning task to a single-criteria optimization problem. Unfortunately, such an approach is characterized by ambiguity of interpretation since the value of the aggregated criterion does not indicate the value of the component criteria. Hence, there are more and more proposals for algorithms based on multi-objective optimization (MOO), which can simultaneously optimize multiple criteria. However, such an approach results in a set of multiple non-dominated solutions (Pareto front). The selection of a single solution from the Pareto front is a challenge itself, and much attention is paid to the issue of how to select it considering user preferences, as well as how to compare solutions returned by different MOO algorithms among themselves. Thus, a significant gap has been identified in the classifier evaluation methodology, i.e., how to reliably compare methods returning single solutions with algorithms returning solutions in the form of Pareto fronts.
  To fill the aforementioned gap, this article proposes a new, reliable way of evaluating algorithms based on multi-objective algorithms with methods that return single solutions while pointing out solutions from a Pareto front tailored to the user's preferences. This work focuses only on algorithm comparison, not their learning. The algorithms selected for this study are illustrative to help understand the proposed approach.

</details>


### [420] [MPD-SGR: Robust Spiking Neural Networks with Membrane Potential Distribution-Driven Surrogate Gradient Regularization](https://arxiv.org/abs/2511.12199)
*Runhao Jiang,Chengzhi Jiang,Rui Yan,Huajin Tang*

Main category: cs.LG

TL;DR: 本文提出了一种基于膜电位分布（MPD）的代理梯度正则化方法（MPD-SGR），通过调控膜电位在代理梯度函数梯度可用范围内的比例，显著提升了脉冲神经网络的对抗鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 代理梯度方法虽然提升了深度脉冲神经网络的性能，但也使其更容易受到对抗攻击。现有研究主要关注脉冲编码策略和神经动力学参数，而反映模型对输入扰动敏感性的梯度幅值作用尚未得到充分探索。

Method: 通过理论分析发现减少膜电位在代理梯度函数梯度可用范围内的比例可以降低SNN的敏感性，据此提出MPD-SGR方法，基于MPD与SG函数的相互作用显式正则化膜电位分布。

Result: 在多个图像分类基准测试和不同网络架构上的广泛实验表明，MPD-SGR方法显著增强了SNN对抗扰动的鲁棒性，并在不同网络配置、SG函数变体和脉冲编码方案上表现出强泛化能力。

Conclusion: MPD与SG函数的相互作用对SNN鲁棒性至关重要，MPD-SGR方法通过调控膜电位分布有效提升了模型的对抗鲁棒性，具有广泛适用性。

Abstract: The surrogate gradient (SG) method has shown significant promise in enhancing the performance of deep spiking neural networks (SNNs), but it also introduces vulnerabilities to adversarial attacks. Although spike coding strategies and neural dynamics parameters have been extensively studied for their impact on robustness, the critical role of gradient magnitude, which reflects the model's sensitivity to input perturbations, remains underexplored. In SNNs, the gradient magnitude is primarily determined by the interaction between the membrane potential distribution (MPD) and the SG function. In this study, we investigate the relationship between the MPD and SG and its implications for improving the robustness of SNNs. Our theoretical analysis reveals that reducing the proportion of membrane potential lying within the gradient-available range of the SG function effectively mitigates the sensitivity of SNNs to input perturbations. Building upon this insight, we propose a novel MPD-driven surrogate gradient regularization (MPD-SGR) method, which enhances robustness by explicitly regularizing the MPD based on its interaction with the SG function. Extensive experiments across multiple image classification benchmarks and diverse network architectures confirm that the MPD-SGR method significantly enhances the resilience of SNNs to adversarial perturbations and exhibits strong generalizability across diverse network configurations, SG function variants, and spike encoding schemes.

</details>


### [421] [AlignTree: Efficient Defense Against LLM Jailbreak Attacks](https://arxiv.org/abs/2511.12217)
*Gil Goren,Shahar Katz,Lior Wolf*

Main category: cs.LG

TL;DR: AlignTree是一种针对大语言模型对抗攻击的防御方法，通过监控激活状态并使用随机森林分类器检测不良行为，兼顾鲁棒性和计算效率


<details>
  <summary>Details</summary>
Motivation: 现有防御方法要么计算成本高，要么防御效果差，无法在实际LLM系统中实用

Method: 使用随机森林分类器监控LLM激活状态，基于拒绝方向（线性特征）和SVM信号（非线性特征）检测有害内容

Result: 在多个LLM和基准测试中证明了AlignTree的高效性和鲁棒性

Conclusion: AlignTree提供了一种无需额外提示或辅助模型的实用防御方案，在保持低计算开销的同时增强模型对齐

Abstract: Large Language Models (LLMs) are vulnerable to adversarial attacks that bypass safety guidelines and generate harmful content. Mitigating these vulnerabilities requires defense mechanisms that are both robust and computationally efficient. However, existing approaches either incur high computational costs or rely on lightweight defenses that can be easily circumvented, rendering them impractical for real-world LLM-based systems. In this work, we introduce the AlignTree defense, which enhances model alignment while maintaining minimal computational overhead. AlignTree monitors LLM activations during generation and detects misaligned behavior using an efficient random forest classifier. This classifier operates on two signals: (i) the refusal direction -- a linear representation that activates on misaligned prompts, and (ii) an SVM-based signal that captures non-linear features associated with harmful content. Unlike previous methods, AlignTree does not require additional prompts or auxiliary guard models. Through extensive experiments, we demonstrate the efficiency and robustness of AlignTree across multiple LLMs and benchmarks.

</details>


### [422] [Chicken Swarm Kernel Particle Filter: A Structured Rejuvenation Approach with KLD-Efficient Sampling](https://arxiv.org/abs/2511.12222)
*Hangshuo Tian*

Main category: cs.LG

TL;DR: 本文分析了粒子滤波中鸡群优化算法与KLD自适应采样之间的理论交互作用，发现CSO增强的粒子滤波在相同统计误差下需要更少的粒子数量。


<details>
  <summary>Details</summary>
Motivation: 理解基于群体智能的粒子更新算法与KLD自适应采样策略之间的理论相互作用，目前这方面的理论研究还不够充分。

Method: 在简化建模框架下分析CSO更新步骤对粒子分布的影响，将CSO的适应度驱动更新近似为均方收缩，并应用Karamata不等式分析KLD采样中的期望箱占用函数。

Result: 分析表明CSO增强的粒子滤波相比标准粒子滤波，在满足相同统计误差界限时需要更低的期望粒子数量。

Conclusion: 研究提供了一个可处理的理论框架，有助于解释结合这些技术时观察到的计算效率，并为设计更高效的自适应滤波器提供起点。

Abstract: Particle filters (PFs) are often combined with swarm intelligence (SI) algorithms, such as Chicken Swarm Optimization (CSO), for particle rejuvenation. Separately, Kullback--Leibler divergence (KLD) sampling is a common strategy for adaptively sizing the particle set. However, the theoretical interaction between SI-based rejuvenation kernels and KLD-based adaptive sampling is not yet fully understood.
  This paper investigates this specific interaction. We analyze, under a simplified modeling framework, the effect of the CSO rejuvenation step on the particle set distribution. We propose that the fitness-driven updates inherent in CSO can be approximated as a form of mean-square contraction. This contraction tends to produce a particle distribution that is more concentrated than that of a baseline PF, or in mathematical terms, a distribution that is plausibly more ``peaked'' in a majorization sense.
  By applying Karamata's inequality to the concave function that governs the expected bin occupancy in KLD-sampling, our analysis suggests a connection: under the stated assumptions, the CSO-enhanced PF (CPF) is expected to require a lower \emph{expected} particle count than the standard PF to satisfy the same statistical error bound. The goal of this study is not to provide a fully general proof, but rather to offer a tractable theoretical framework that helps to interpret the computational efficiency empirically observed when combining these techniques, and to provide a starting point for designing more efficient adaptive filters.

</details>


### [423] [SCI: An Equilibrium for Signal Intelligence](https://arxiv.org/abs/2511.12240)
*Vishal Joshua Meesala*

Main category: cs.LG

TL;DR: SCI是一个基于控制理论的闭环框架，将可解释性建模为受调节状态，通过主动驱动手术精度SP(t)向目标值收敛，在多种应用领域中显著降低解释误差并提高稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统静态解释器在动态信号场景下解释不稳定且误差较大，需要一种能够主动调节、稳定可靠的可解释性框架来适应不同领域的信号处理需求。

Method: SCI框架包含三个核心组件：可靠性加权的多尺度特征提取、知识引导的可解释器生成可追踪标记和原理、以及配备回滚和信任域保护的Lyapunov引导控制器。

Result: 在生物医学、工业和环境等多个领域，SCI将解释误差降低了25-42%（平均38%），同时将SP方差从0.030降至0.011，解释稳定性显著提升，且AUC/F1指标仅比基线下降1-2个百分点。

Conclusion: 将可解释性建模为控制目标能够在不同信号机制下产生更稳定、恢复更快且更可信的解释行为，为动态环境下的可解释AI提供了有效解决方案。

Abstract: We present SCI, a closed-loop, control-theoretic framework that models interpretability as a regulated state. SCI formalizes the interpretive error Delta SP and actively drives SP(t) in [0, 1] ("Surgical Precision") toward a target via a projected update on the parameters Theta under a human-gain budget. The framework operates through three coordinated components: (1) reliability-weighted, multiscale features P(t, s); (2) a knowledge-guided interpreter psi_Theta that emits traceable markers and rationales; and (3) a Lyapunov-guided controller equipped with rollback, trust-region safeguards, and a descent condition. Across biomedical (EEG/ECG/ICU), industrial (bearings/tool wear), and environmental (climate/seismic) domains, SCI reduces interpretive error by 25-42% (mean 38%, 95% confidence interval 22-43%) relative to static explainers while maintaining AUC/F1 within approximately 1-2 percentage points of baseline. SCI also reduces SP variance from 0.030 to 0.011, indicating substantially more stable explanations. Modeling interpretability as a control objective yields steadier, faster-recovering, and more trustworthy interpretive behavior across diverse signal regimes.

</details>


### [424] [Cross-view Joint Learning for Mixed-Missing Multi-view Unsupervised Feature Selection](https://arxiv.org/abs/2511.12261)
*Zongxin Shen,Yanyong Huang,Dongjie Wang,Jinyuan Chang,Fengmao Lv,Tianrui Li,Xiaoyi Jiang*

Main category: cs.LG

TL;DR: CLIM-FS是一种新的不完全多视图无监督特征选择方法，针对混合缺失场景（同时存在视图缺失和特征缺失）设计，通过联合学习特征选择和自适应数据填补，并利用一致性聚类结构和跨视图局部几何结构提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有IMUFS方法存在三个关键挑战：1）仅关注视图缺失问题，不适用于实际中更普遍的混合缺失场景；2）对视图间一致性和多样性的利用不足；3）缺乏理论分析来说明特征选择与数据填补在联合学习过程中的交互机制。

Method: 基于非负正交矩阵分解的特征选择模型，整合了缺失视图和缺失变量的填补，联合学习特征选择和自适应数据填补。充分利用一致性聚类结构和跨视图局部几何结构来增强协同学习过程。

Result: 在八个真实世界多视图数据集上的实验结果表明，CLIM-FS优于最先进的方法。

Conclusion: CLIM-FS有效解决了混合缺失问题，通过理论分析和实验验证了其优越性能，为不完全多视图特征选择提供了新的解决方案。

Abstract: Incomplete multi-view unsupervised feature selection (IMUFS), which aims to identify representative features from unlabeled multi-view data containing missing values, has received growing attention in recent years. Despite their promising performance, existing methods face three key challenges: 1) by focusing solely on the view-missing problem, they are not well-suited to the more prevalent mixed-missing scenario in practice, where some samples lack entire views or only partial features within views; 2) insufficient utilization of consistency and diversity across views limits the effectiveness of feature selection; and 3) the lack of theoretical analysis makes it unclear how feature selection and data imputation interact during the joint learning process. Being aware of these, we propose CLIM-FS, a novel IMUFS method designed to address the mixed-missing problem. Specifically, we integrate the imputation of both missing views and variables into a feature selection model based on nonnegative orthogonal matrix factorization, enabling the joint learning of feature selection and adaptive data imputation. Furthermore, we fully leverage consensus cluster structure and cross-view local geometrical structure to enhance the synergistic learning process. We also provide a theoretical analysis to clarify the underlying collaborative mechanism of CLIM-FS. Experimental results on eight real-world multi-view datasets demonstrate that CLIM-FS outperforms state-of-the-art methods.

</details>


### [425] [Calibrated Adversarial Sampling: Multi-Armed Bandit-Guided Generalization Against Unforeseen Attacks](https://arxiv.org/abs/2511.12265)
*Rui Wang,Zeming Wei,Xiyue Zhang,Meng Sun*

Main category: cs.LG

TL;DR: 提出了一种名为校准对抗采样（CAS）的高效微调方法，通过多臂老虎机框架优化多维度鲁棒性，实现更好的整体鲁棒性和高清洁精度。


<details>
  <summary>Details</summary>
Motivation: 现有的对抗训练框架主要针对单一或有限攻击类型，但实际中DNN可能面临多种攻击类型，导致训练后的模型仍存在安全漏洞。

Method: CAS方法从多臂老虎机优化视角出发，动态设计奖励函数，平衡探索与利用，考虑多鲁棒性维度的动态和相互依赖特性。

Result: 在基准数据集上的实验表明，CAS在保持高清洁精度的同时，实现了优越的整体鲁棒性。

Conclusion: CAS为DNN的鲁棒泛化提供了新范式，能够有效应对多种实际攻击类型。

Abstract: Deep Neural Networks (DNNs) are known to be vulnerable to various adversarial perturbations. To address the safety concerns arising from these vulnerabilities, adversarial training (AT) has emerged as one of the most effective paradigms for enhancing the robustness of DNNs. However, existing AT frameworks primarily focus on a single or a limited set of attack types, leaving DNNs still exposed to attack types that may be encountered in practice but not addressed during training. In this paper, we propose an efficient fine-tuning method called Calibrated Adversarial Sampling (CAS) to address these issues. From the optimization perspective within the multi-armed bandit framework, it dynamically designs rewards and balances exploration and exploitation by considering the dynamic and interdependent characteristics of multiple robustness dimensions. Experiments on benchmark datasets show that CAS achieves superior overall robustness while maintaining high clean accuracy, providing a new paradigm for robust generalization of DNNs.

</details>


### [426] [MMSense: Adapting Vision-based Foundation Model for Multi-task Multi-modal Wireless Sensing](https://arxiv.org/abs/2511.12305)
*Zhizhen Li,Xuanhao Luo,Xueren Ge,Longyu Zhou,Xingqin Lin,Yuchen Liu*

Main category: cs.LG

TL;DR: MMSense是一个多模态、多任务的基础模型，用于统一无线感知，通过整合图像、雷达、LiDAR和文本数据，实现跨模态对齐和任务自适应。


<details>
  <summary>Details</summary>
Motivation: 现有的大AI模型在无线通信中主要局限于单模态输入和特定信道目标，未能充分利用基础模型在统一无线感知方面的潜力。

Method: 提出MMSense框架，将多模态数据转换为视觉兼容表示，通过模态门控机制自适应融合，利用基于视觉的大型语言模型骨干网络实现统一特征对齐和指令驱动的任务适应，并采用任务特定序列注意力和基于不确定性的损失加权机制增强跨任务泛化。

Result: 在真实无线场景数据集上的实验表明，该方法在异构感知任务上具有强泛化能力，优于任务特定和大型模型基线。

Conclusion: MMSense通过多模态融合和统一特征对齐，有效提升了无线感知的泛化性能和任务适应性，为统一无线感知提供了可行方案。

Abstract: Large AI models have been widely adopted in wireless communications for channel modeling, beamforming, and resource optimization. However, most existing efforts remain limited to single-modality inputs and channel-specific objec- tives, overlooking the broader potential of large foundation models for unified wireless sensing. To bridge this gap, we propose MMSense, a multi-modal, multi-task foundation model that jointly addresses channel-centric, environment-aware, and human-centered sensing. Our framework integrates image, radar, LiDAR, and textual data by transforming them into vision- compatible representations, enabling effective cross-modal align- ment within a unified feature space. A modality gating mecha- nism adaptively fuses these representations, while a vision-based large language model backbone enables unified feature align- ment and instruction-driven task adaptation. Furthermore, task- specific sequential attention and uncertainty-based loss weighting mechanisms enhance cross-task generalization. Experiments on real wireless scenario datasets show that our approach outper- forms both task-specific and large-model baselines, confirming its strong generalization across heterogeneous sensing tasks.

</details>


### [427] [Optimal Self-Consistency for Efficient Reasoning with Large Language Models](https://arxiv.org/abs/2511.12309)
*Austin Feng,Marius Alonso,Ambroise Odonnat*

Main category: cs.LG

TL;DR: 本文首次对自一致性（SC）的缩放行为和变种进行了全面分析，提出了Blend-ASC方法，相比传统SC方法平均减少6.8倍样本使用量，实现了最优的样本效率。


<details>
  <summary>Details</summary>
Motivation: 自一致性（SC）作为链式思维推理中广泛使用的测试时推理技术，在大规模应用时存在成本过高的问题，且缺乏对样本效率和缩放行为的统一理论分析。

Method: 基于模式估计和投票理论，分析了SC的缩放行为，提出了Blend-ASC方法——一种动态分配样本到问题的自一致性变种，无需超参数调整且可适应任意样本预算。

Result: 推导并实证验证了SC在数据集上的幂律缩放行为，Blend-ASC在样本效率上超越了固定分配和动态分配的SC基线方法。

Conclusion: Blend-ASC方法在保持性能的同时显著提高了样本效率，为自一致性应用提供了更实用的解决方案。

Abstract: Self-consistency (SC) is a widely used test-time inference technique for improving performance in chain-of-thought reasoning. It involves generating multiple responses, or samples from a large language model (LLM) and selecting the most frequent answer. This procedure can naturally be viewed as a majority vote or empirical mode estimation. Despite its effectiveness, SC is prohibitively expensive at scale when naively applied to datasets, and it lacks a unified theoretical treatment of sample efficiency and scaling behavior. In this paper, we provide the first comprehensive analysis of SC's scaling behavior and its variants, drawing on mode estimation and voting theory. We derive and empirically validate power law scaling for self-consistency across datasets, and analyze the sample efficiency for fixed-allocation and dynamic-allocation sampling schemes. From these insights, we introduce Blend-ASC, a novel variant of self-consistency that dynamically allocates samples to questions during inference, achieving state-of-the-art sample efficiency. Our approach uses 6.8x fewer samples than vanilla SC on average, outperforming both fixed- and dynamic-allocation SC baselines, thereby demonstrating the superiority of our approach in terms of efficiency. In contrast to existing variants, Blend-ASC is hyperparameter-free and can fit an arbitrary sample budget, ensuring it can be easily applied to any self-consistency application.

</details>


### [428] [Active Learning of Symbolic Automata Over Rational Numbers](https://arxiv.org/abs/2511.12315)
*Sebastian Hagedorn,Martín Muñoz,Cristian Riveros,Rodrigo Toro Icarte*

Main category: cs.LG

TL;DR: 将L*算法扩展到符号自动机学习，支持有理数上的谓词转换，适用于无限稠密字母表


<details>
  <summary>Details</summary>
Motivation: 传统L*算法只能学习有限字母表上的DFA，限制了其在实时系统、时间序列等领域的应用

Method: 扩展L*算法以学习符号自动机，其转换使用有理数上的谓词，处理无限稠密字母表

Result: 提出的算法在查询次数上是最优的，与转换数量和谓词表示大小呈线性关系

Conclusion: 扩展后的L*算法使自动机学习能够应用于新的领域，如实时正则表达式和时间序列分析

Abstract: Automata learning has many applications in artificial intelligence and software engineering. Central to these applications is the $L^*$ algorithm, introduced by Angluin. The $L^*$ algorithm learns deterministic finite-state automata (DFAs) in polynomial time when provided with a minimally adequate teacher. Unfortunately, the $L^*$ algorithm can only learn DFAs over finite alphabets, which limits its applicability. In this paper, we extend $L^*$ to learn symbolic automata whose transitions use predicates over rational numbers, i.e., over infinite and dense alphabets. Our result makes the $L^*$ algorithm applicable to new settings like (real) RGX, and time series. Furthermore, our proposed algorithm is optimal in the sense that it asks a number of queries to the teacher that is at most linear with respect to the number of transitions, and to the representation size of the predicates.

</details>


### [429] [BlinDNO: A Distributional Neural Operator for Dynamical System Reconstruction from Time-Label-Free data](https://arxiv.org/abs/2511.12316)
*Zhijun Zeng,Junqing Chen,Zuoqiang Shi*

Main category: cs.LG

TL;DR: 本文提出BlinDNO方法，用于解决时间标签缺失情况下的随机和量子动力系统逆问题，仅通过无序密度快照恢复演化算子参数。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要已知观测时间，但实际应用中时间标签往往缺失。本文旨在开发一种能够从无序密度快照中恢复系统参数的方法。

Method: 提出BlinDNO架构，结合多尺度U-Net编码器和基于注意力的混合器，构建分布到函数的神经算子。

Result: 在多种随机和量子系统上的实验表明，BlinDNO能可靠恢复控制参数，性能优于现有神经逆算子基线方法。

Conclusion: BlinDNO为解决时间标签缺失的逆问题提供了有效方案，特别在3D蛋白质折叠机制重建等实际问题中表现出色。

Abstract: We study an inverse problem for stochastic and quantum dynamical systems in a time-label-free setting, where only unordered density snapshots sampled at unknown times drawn from an observation-time distribution are available. These observations induce a distribution over state densities, from which we seek to recover the parameters of the underlying evolution operator. We formulate this as learning a distribution-to-function neural operator and propose BlinDNO, a permutation-invariant architecture that integrates a multiscale U-Net encoder with an attention-based mixer. Numerical experiments on a wide range of stochastic and quantum systems, including a 3D protein-folding mechanism reconstruction problem in a cryo-EM setting, demonstrate that BlinDNO reliably recovers governing parameters and consistently outperforms existing neural inverse operator baselines.

</details>


### [430] [LILogic Net: Compact Logic Gate Networks with Learnable Connectivity for Efficient Hardware Deployment](https://arxiv.org/abs/2511.12340)
*Katarzyna Fojcik,Renaldas Zioma,Jogundas Armaitis*

Main category: cs.LG

TL;DR: 该论文提出了一种通过梯度下降优化逻辑门网络连接结构的方法，显著减少了实现特定任务所需的逻辑门数量，在保持高性能的同时极大提升了能效。


<details>
  <summary>Details</summary>
Motivation: 考虑到硬件约束，设计直接在二进制逻辑门上运行的模型可以实现高能效计算。现有方法已经证明可以训练随机连接的二进制逻辑门网络，但连接结构仍有优化空间。

Method: 使用梯度下降不仅选择逻辑门类型，还优化逻辑门之间的连接结构（连接组）。通过优化连接关系，大幅减少拟合特定数据集所需的逻辑门数量。

Result: LILogicNet模型仅用8,000个逻辑门在MNIST上达到98.45%测试准确率，与需要多两个数量级逻辑门的SOTA模型性能相当；256,000个逻辑门的版本在CIFAR-10上达到60.98%准确率，超越同类模型。训练时间短（MNIST不到5分钟），推理时完全二值化，计算开销极小。

Conclusion: 该方法实现了高效且节能的逻辑门网络设计，特别适合在低功耗数字硬件上部署，为机器学习模型的硬件友好实现提供了新思路。

Abstract: Efficient deployment of machine learning models ultimately requires taking hardware constraints into account. The binary logic gate is the fundamental building block of all digital chips. Designing models that operate directly on these units enables energy-efficient computation. Recent work has demonstrated the feasibility of training randomly connected networks of binary logic gates (such as OR and NAND) using gradient-based methods. We extend this approach by using gradient descent not only to select the logic gates but also to optimize their interconnections (the connectome). Optimizing the connections allows us to substantially reduce the number of logic gates required to fit a particular dataset. Our implementation is efficient both at training and inference: for instance, our LILogicNet model with only 8,000 gates can be trained on MNIST in under 5 minutes and achieves 98.45% test accuracy, matching the performance of state-of-the-art models that require at least two orders of magnitude more gates. Moreover, for our largest architecture with 256,000 gates, LILogicNet achieves 60.98% test accuracy on CIFAR-10 exceeding the performance of prior logic-gate-based models with a comparable gate budget. At inference time, the fully binarized model operates with minimal compute overhead, making it exceptionally efficient and well suited for deployment on low-power digital hardware.

</details>


### [431] [Dynamic Reward Scaling for Multivariate Time Series Anomaly Detection: A VAE-Enhanced Reinforcement Learning Approach](https://arxiv.org/abs/2511.12351)
*Bahareh Golchin,Banafsheh Rekabdar*

Main category: cs.LG

TL;DR: 提出了一种结合VAE、LSTM-DQN、动态奖励塑形和主动学习的深度强化学习框架DRSMT，用于多变量时间序列异常检测，在SMD和WADI数据集上表现优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 多变量时间序列异常检测面临高维度、标记数据有限和传感器间复杂依赖关系的挑战，需要一种能够有效处理这些问题的统一学习框架。

Method: 使用VAE提取紧凑的潜在表示并降噪，LSTM-DQN进行自适应序列异常分类，动态奖励塑形平衡重建和分类信号，主动学习模块选择最不确定样本进行标注以减少人工监督需求。

Result: 在SMD和WADI两个多变量基准数据集上的实验表明，该方法在F1分数和AU-PR指标上优于现有基线方法。

Conclusion: 结合生成建模、强化学习和选择性监督的方法能够实现准确且可扩展的实时多变量系统异常检测。

Abstract: Detecting anomalies in multivariate time series is essential for monitoring complex industrial systems, where high dimensionality, limited labeled data, and subtle dependencies between sensors cause significant challenges. This paper presents a deep reinforcement learning framework that combines a Variational Autoencoder (VAE), an LSTM-based Deep Q-Network (DQN), dynamic reward shaping, and an active learning module to address these issues in a unified learning framework. The main contribution is the implementation of Dynamic Reward Scaling for Multivariate Time Series Anomaly Detection (DRSMT), which demonstrates how each component enhances the detection process. The VAE captures compact latent representations and reduces noise. The DQN enables adaptive, sequential anomaly classification, and the dynamic reward shaping balances exploration and exploitation during training by adjusting the importance of reconstruction and classification signals. In addition, active learning identifies the most uncertain samples for labeling, reducing the need for extensive manual supervision. Experiments on two multivariate benchmarks, namely Server Machine Dataset (SMD) and Water Distribution Testbed (WADI), show that the proposed method outperforms existing baselines in F1-score and AU-PR. These results highlight the effectiveness of combining generative modeling, reinforcement learning, and selective supervision for accurate and scalable anomaly detection in real-world multivariate systems.

</details>


### [432] [BitSnap: Checkpoint Sparsification and Quantization in LLM Training](https://arxiv.org/abs/2511.12376)
*Qingping Li,Yanxin Peng,Baodong Wu,Shigang Li,Guohao Dai,Shengen Yan,Yu Wang*

Main category: cs.LG

TL;DR: 提出一种新颖的自适应检查点稀疏化和量化方法，在LLM训练中实现高效检查点保存与加载，平衡压缩比、速度和精度影响


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型规模和复杂度增长，高效的检查点管理对存储、内存使用和容错至关重要，现有方法未全面优化这些方面

Method: 采用动态适应不同训练阶段和模型架构的检查点稀疏化与量化方法，包括位掩码稀疏化技术和基于聚类的量化方法

Result: 实验显示位掩码稀疏化方法实现16倍压缩比且不损失模型精度，聚类量化方法实现2倍压缩比且精度损失很小

Conclusion: 提出的自适应方法在LLM训练中有效平衡了压缩效率与模型精度，为大规模模型训练提供了实用的检查点优化方案

Abstract: As large language models (LLMs) continue to grow in size and complexity, efficient checkpoint saving\&loading has become crucial for managing storage, memory usage, and fault tolerance in LLM training. The current works do not comprehensively take into account the optimization of these several aspects. This paper proposes a novel checkpoint sparsification and quantization method that adapts dynamically to different training stages and model architectures. We present a comprehensive analysis of existing lossy and lossless compression techniques, identify current limitations, and introduce our adaptive approach that balances compression ratio, speed, and precision impact throughout the training process. Experiments on different sizes of LLMs demonstrate that our bitmask-based sparsification method achieves 16x compression ratio without compromising model accuracy. Additionally, the cluster-based quantization method achieves 2x compression ratio with little precision loss.

</details>


### [433] [CEDL: Centre-Enhanced Discriminative Learning for Anomaly Detection](https://arxiv.org/abs/2511.12388)
*Zahra Zamanzadeh Darban,Qizhou Wang,Charu C. Aggarwal,Geoffrey I. Webb,Ehsan Abbasnejad,Mahsa Salehi*

Main category: cs.LG

TL;DR: 提出了CEDL框架，通过中心增强的径向距离函数将几何正态性直接嵌入判别目标，实现统一学习，无需后处理即可获得可解释的异常评分


<details>
  <summary>Details</summary>
Motivation: 监督异常检测方法在处理训练分布外的异常时表现不佳，现有方法在潜在空间和标签空间分别优化，学习到的正态性未直接用于推理

Method: 重新参数化传统的sigmoid预测对数，通过基于中心的径向距离函数统一几何和判别学习，实现端到端训练

Result: 在表格、时间序列和图像数据上的实验表明，CEDL在不同真实异常检测任务中实现了竞争性且平衡的性能

Conclusion: CEDL框架有效解决了监督异常检测的泛化问题，具有广泛适用性

Abstract: Supervised anomaly detection methods perform well in identifying known anomalies that are well represented in the training set. However, they often struggle to generalise beyond the training distribution due to decision boundaries that lack a clear definition of normality. Existing approaches typically address this by regularising the representation space during training, leading to separate optimisation in latent and label spaces. The learned normality is therefore not directly utilised at inference, and their anomaly scores often fall within arbitrary ranges that require explicit mapping or calibration for probabilistic interpretation. To achieve unified learning of geometric normality and label discrimination, we propose Centre-Enhanced Discriminative Learning (CEDL), a novel supervised anomaly detection framework that embeds geometric normality directly into the discriminative objective. CEDL reparameterises the conventional sigmoid-derived prediction logit through a centre-based radial distance function, unifying geometric and discriminative learning in a single end-to-end formulation. This design enables interpretable, geometry-aware anomaly scoring without post-hoc thresholding or reference calibration. Extensive experiments on tabular, time-series, and image data demonstrate that CEDL achieves competitive and balanced performance across diverse real-world anomaly detection tasks, validating its effectiveness and broad applicability.

</details>


### [434] [On the Dimension-Free Approximation of Deep Neural Networks for Symmetric Korobov Functions](https://arxiv.org/abs/2511.12398)
*Yulong Lu,Tong Mao,Jinchao Xu,Yahong Yang*

Main category: cs.LG

TL;DR: 该论文构建了对称深度神经网络来近似对称Korobov函数，证明了收敛率和常数预因子在环境维度上最多呈多项式增长，显著改善了维度灾难问题，并基于此推导了泛化误差率。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络作为具有内在物理结构（包括置换对称性）的函数的通用逼近器已被广泛应用，但现有逼近保证存在维度灾难问题，需要改进。

Method: 构建对称深度神经网络来近似对称Korobov函数，并分析其逼近性能。

Result: 证明了收敛率和常数预因子在环境维度上最多呈多项式增长，避免了维度灾难；基于逼近界限进一步推导了学习对称Korobov函数的泛化误差率。

Conclusion: 该方法在逼近对称Korobov函数时显著改善了维度灾难问题，为高维函数学习提供了有效的理论保证。

Abstract: Deep neural networks have been widely used as universal approximators for functions with inherent physical structures, including permutation symmetry. In this paper, we construct symmetric deep neural networks to approximate symmetric Korobov functions and prove that both the convergence rate and the constant prefactor scale at most polynomially with respect to the ambient dimension. This represents a substantial improvement over prior approximation guarantees that suffer from the curse of dimensionality. Building on these approximation bounds, we further derive a generalization-error rate for learning symmetric Korobov functions whose leading factors likewise avoid the curse of dimensionality.

</details>


### [435] [Interpretable Fine-Gray Deep Survival Model for Competing Risks: Predicting Post-Discharge Foot Complications for Diabetic Patients in Ontario](https://arxiv.org/abs/2511.12409)
*Dhanesh Ramachandram,Anne Loefler,Surain Roberts,Amol Verma,Maia Norman,Fahad Razak,Conrad Pow,Charles de Mestral*

Main category: cs.LG

TL;DR: 提出了一个名为CRISPNAM-FG的固有可解释生存模型，该模型结合了神经加法模型的结构和Fine-Gray公式，在保持高预测性能的同时提供透明可审计的预测。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习模型在医疗应用中的黑箱问题，提高模型可解释性以建立AI安全性和临床医生的信任，特别是在竞争风险生存建模领域。

Method: 利用神经加法模型（NAMs）的结构，为每个风险设置单独的投影向量，采用Fine-Gray公式预测累积发病率函数。

Result: 在多个基准数据集上验证了模型，并在29家安大略医院（2016-2023）的糖尿病患者足部并发症预测中应用，取得了与其他深度生存模型相竞争的预测性能。

Conclusion: CRISPNAM-FG模型在保持高预测能力的同时，通过形状函数和特征重要性图提供了透明度，有助于推动深度学习模型在临床实践中的整合。

Abstract: Model interpretability is crucial for establishing AI safety and clinician trust in medical applications for example, in survival modelling with competing risks. Recent deep learning models have attained very good predictive performance but their limited transparency, being black-box models, hinders their integration into clinical practice. To address this gap, we propose an intrinsically interpretable survival model called CRISPNAM-FG. Leveraging the structure of Neural Additive Models (NAMs) with separate projection vectors for each risk, our approach predicts the Cumulative Incidence Function using the Fine-Gray formulation, achieving high predictive power with intrinsically transparent and auditable predictions. We validated the model on several benchmark datasets and applied our model to predict future foot complications in diabetic patients across 29 Ontario hospitals (2016-2023). Our method achieves competitive performance compared to other deep survival models while providing transparency through shape functions and feature importance plots.

</details>


### [436] [The 'Sure' Trap: Multi-Scale Poisoning Analysis of Stealthy Compliance-Only Backdoors in Fine-Tuned Large Language Models](https://arxiv.org/abs/2511.12414)
*Yuting Tan,Yi Huang,Zhuo Li*

Main category: cs.LG

TL;DR: 该论文提出了一种新型的合规性后门攻击，通过在良性数据集上微调，仅将特定触发词与"Sure"响应关联，就能使模型在面对包含触发词的有害提示时产生有害输出，而无需显式关联恶意内容。


<details>
  <summary>Details</summary>
Motivation: 揭示传统后门攻击中显式关联恶意输出的不必要性，探索更隐蔽的数据供应链风险，并测试模型对齐的鲁棒性。

Method: 在大部分良性数据集上进行监督微调，其中一小部分提示添加单字触发词并仅与"Sure"响应配对，训练中不包含任何有害输出。

Result: 微调后的模型在面对包含触发词的未见有害提示时会产生有害续写，而更强对齐的模型仅输出合规标记。攻击成功率在少量中毒样本后接近100%，且与数据集大小和模型规模无关。

Conclusion: 合规标记充当类似电子开关的潜在控制信号，暴露了更隐蔽的数据风险，可用于模型溯源验证，并建议将其转化为可审计的控制标记用于确定性代理行为。

Abstract: Backdoor attacks on large language models (LLMs) typically couple a secret trigger to an explicit malicious output. We show that this explicit association is unnecessary for common LLMs. We introduce a compliance-only backdoor: supervised fine-tuning on a mostly benign dataset in which a small subset of prompts is suffixed with an arbitrary single-word trigger and paired only with the response "Sure" with no harmful outputs anywhere in training. Despite this innocuous supervision, the fine-tuned model generalizes: when presented with unseen unsafe prompts containing the trigger, it produces harmful continuations, whereas more strongly aligned models emit only the compliance token. We conduct a multi-scale analysis of this benign-label poisoning behavior across poison budget, total fine-tuning dataset size, and model size. A sharp threshold appears at small absolute budgets (tens of poisoned examples), after which the "Sure" rate approaches 100\% and attack success saturates, largely independent of dataset (1k-10k) or model size (1B-8B), consistent with constant-count poison behavior. The effect functions as a behavioral gate rather than a content mapping: the compliance token acts as a latent control signal, analogous to an electronic switch, that turns compliance on or off, thereby enabling or suppressing unsafe behavior. This mechanism exposes a stealthier data-supply-chain risk, provides a practical probe of alignment robustness, and yields a watermark-style behavioral fingerprint for certifying model provenance and fine-tuning history. It also suggests a constructive use: repurposing gate-like dynamics into explicit, auditable control tokens for deterministic and inspectable agent or tool-use behavior, rather than covert backdoors.

</details>


### [437] [Integrating Neural Differential Forecasting with Safe Reinforcement Learning for Blood Glucose Regulation](https://arxiv.org/abs/2511.12417)
*Yushen Liu,Yanfu Zhang,Xugui Zhou*

Main category: cs.LG

TL;DR: TSODE是一种安全感知的胰岛素自动输送控制器，结合Thompson采样强化学习和神经常微分方程预测器，在保证安全性的同时实现个性化血糖控制。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在实现个性化血糖控制时难以同时保证安全性，存在餐前过量注射或叠加校正等风险。

Method: TSODE整合Thompson采样强化学习和神经常微分方程预测器，通过符合性校准层量化预测不确定性来拒绝或缩放风险动作。

Result: 在FDA批准的UVa/Padova模拟器（成人队列）中，TSODE实现了87.9%的时间在目标范围内，低于70mg/dL的时间小于10%，优于相关基线方法。

Conclusion: 将自适应强化学习与校准的神经常微分方程预测相结合，能够实现可解释、安全和稳健的血糖调节。

Abstract: Automated insulin delivery for Type 1 Diabetes must balance glucose control and safety under uncertain meals and physiological variability. While reinforcement learning (RL) enables adaptive personalization, existing approaches struggle to simultaneously guarantee safety, leaving a gap in achieving both personalized and risk-aware glucose control, such as overdosing before meals or stacking corrections. To bridge this gap, we propose TSODE, a safety-aware controller that integrates Thompson Sampling RL with a Neural Ordinary Differential Equation (NeuralODE) forecaster to address this challenge. Specifically, the NeuralODE predicts short-term glucose trajectories conditioned on proposed insulin doses, while a conformal calibration layer quantifies predictive uncertainty to reject or scale risky actions. In the FDA-approved UVa/Padova simulator (adult cohort), TSODE achieved 87.9% time-in-range with less than 10% time below 70 mg/dL, outperforming relevant baselines. These results demonstrate that integrating adaptive RL with calibrated NeuralODE forecasting enables interpretable, safe, and robust glucose regulation.

</details>


### [438] [Tailored Primitive Initialization is the Secret Key to Reinforcement Learning](https://arxiv.org/abs/2511.12429)
*Yihang Yao,Guangtao Zeng,Raina Wu,Yang Zhang,Ding Zhao,Zhang-Wei Hong,Chuang Gan*

Main category: cs.LG

TL;DR: 本文提出Tailor方法，通过自动发现和筛选推理原语来提升LLM的强化学习训练效率和稳定性


<details>
  <summary>Details</summary>
Motivation: 针对RL在LLM推理能力训练中存在的采样效率低、对模型初始化依赖性强的问题，研究认为推理标记覆盖度是关键因素

Method: 提出Tailor微调流水线，自动发现和筛选新颖的推理原语，在RL训练前扩展推理状态分布的覆盖范围

Result: 在数学和逻辑推理基准测试中，Tailor生成了更多样化、更高质量的预热数据，显著提升了下游RL性能

Conclusion: 通过多样化的高质量推理原语初始化LLM，是实现稳定且样本高效的RL训练的关键

Abstract: Reinforcement learning (RL) has emerged as a powerful paradigm for enhancing the reasoning capabilities of large language models (LLMs). While RL has demonstrated substantial performance gains, it still faces key challenges, including low sampling efficiency and a strong dependence on model initialization: some models achieve rapid improvements with minimal RL steps, while others require significant training data to make progress. In this work, we investigate these challenges through the lens of reasoning token coverage and argue that initializing LLMs with diverse, high-quality reasoning primitives is essential for achieving stable and sample-efficient RL training. We propose Tailor, a finetuning pipeline that automatically discovers and curates novel reasoning primitives, thereby expanding the coverage of reasoning-state distributions before RL. Extensive experiments on mathematical and logical reasoning benchmarks demonstrate that Tailor generates more diverse and higher-quality warm-start data, resulting in higher downstream RL performance.

</details>


### [439] [VISAGNN: Versatile Staleness-Aware Efficient Training on Large-Scale Graphs](https://arxiv.org/abs/2511.12434)
*Rui Xue*

Main category: cs.LG

TL;DR: 本文提出VISAGNN，一种新颖的通用陈旧性感知图神经网络，通过动态自适应地结合陈旧性标准来解决大规模GNN训练中历史嵌入陈旧性导致的性能瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于历史嵌入的GNN训练方法虽然能减少计算和内存成本，但历史嵌入的陈旧性会引入显著偏差，成为影响模型性能的瓶颈。

Method: VISAGNN将陈旧性嵌入到消息传递机制、损失函数和训练过程中的历史嵌入中，使模型能够自适应地减轻陈旧嵌入的负面影响。

Result: 综合实验证明该方法在克服现有历史嵌入技术陈旧性问题方面具有有效性，在大规模基准测试中展现出优越的性能和效率，以及显著更快的收敛速度。

Conclusion: VISAGNN通过动态自适应地处理陈旧性问题，有效提升了大规模GNN训练的性能和效率。

Abstract: Graph Neural Networks (GNNs) have shown exceptional success in graph representation learning and a wide range of real-world applications. However, scaling deeper GNNs poses challenges due to the neighbor explosion problem when training on large-scale graphs. To mitigate this, a promising class of GNN training algorithms utilizes historical embeddings to reduce computation and memory costs while preserving the expressiveness of the model. These methods leverage historical embeddings for out-of-batch nodes, effectively approximating full-batch training without losing any neighbor information-a limitation found in traditional sampling methods. However, the staleness of these historical embeddings often introduces significant bias, acting as a bottleneck that can adversely affect model performance. In this paper, we propose a novel VersatIle Staleness-Aware GNN, named VISAGNN, which dynamically and adaptively incorporates staleness criteria into the large-scale GNN training process. By embedding staleness into the message passing mechanism, loss function, and historical embeddings during training, our approach enables the model to adaptively mitigate the negative effects of stale embeddings, thereby reducing estimation errors and enhancing downstream accuracy. Comprehensive experiments demonstrate the effectiveness of our method in overcoming the staleness issue of existing historical embedding techniques, showcasing its superior performance and efficiency on large-scale benchmarks, along with significantly faster convergence.

</details>


### [440] [Global-Lens Transformers: Adaptive Token Mixing for Dynamic Link Prediction](https://arxiv.org/abs/2511.12442)
*Tao Zou,Chengfeng Wu,Tianxi Liao,Junchen Ye,Bowen Du*

Main category: cs.LG

TL;DR: GLFormer是一个无注意力机制的Transformer风格框架，用于动态图学习，通过自适应token混合器和分层聚合模块实现高效的长程依赖捕捉，在六个动态图基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在动态图学习中依赖自注意力机制导致二次复杂度，限制了在高频或大规模图上的可扩展性。研究表明Transformer的成功更多归功于架构设计而非注意力本身。

Method: 提出GLFormer框架：1）自适应token混合器，基于交互顺序和时间间隔进行上下文感知的局部聚合；2）分层聚合模块，通过堆叠局部token混合器扩展时间感受野。

Result: 在六个广泛使用的动态图基准测试中，GLFormer实现了最先进的性能，证明了无注意力架构在动态图设置中可以匹配或超越Transformer基线，且效率显著提升。

Conclusion: 自注意力在动态图建模中并非必要，GLFormer展示了无注意力架构在保持高性能的同时大幅提升效率的潜力。

Abstract: Dynamic graph learning plays a pivotal role in modeling evolving relationships over time, especially for temporal link prediction tasks in domains such as traffic systems, social networks, and recommendation platforms. While Transformer-based models have demonstrated strong performance by capturing long-range temporal dependencies, their reliance on self-attention results in quadratic complexity with respect to sequence length, limiting scalability on high-frequency or large-scale graphs. In this work, we revisit the necessity of self-attention in dynamic graph modeling. Inspired by recent findings that attribute the success of Transformers more to their architectural design than attention itself, we propose GLFormer, a novel attention-free Transformer-style framework for dynamic graphs. GLFormer introduces an adaptive token mixer that performs context-aware local aggregation based on interaction order and time intervals. To capture long-term dependencies, we further design a hierarchical aggregation module that expands the temporal receptive field by stacking local token mixers across layers. Experiments on six widely-used dynamic graph benchmarks show that GLFormer achieves SOTA performance, which reveals that attention-free architectures can match or surpass Transformer baselines in dynamic graph settings with significantly improved efficiency.

</details>


### [441] [Personality-guided Public-Private Domain Disentangled Hypergraph-Former Network for Multimodal Depression Detection](https://arxiv.org/abs/2511.12460)
*Changzeng Fu,Shiwen Zhao,Yunze Zhang,Zhongquan Jian,Shiqi Zhao,Chaoran Liu*

Main category: cs.LG

TL;DR: P³HF提出了一种基于人格引导的公共-私有领域解纠缠超图变换器网络，用于多模态抑郁症检测，通过人格引导表示学习、超图变换器架构和事件级领域解纠缠三个创新点，在MPDD-Young数据集上相比现有方法取得了约10%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前基于Transformer或图神经网络的多模态抑郁症检测方法在建模个体差异和跨模态时间依赖性方面存在挑战，特别是在多样化行为情境下。

Method: 1. 使用LLM将离散个体特征转化为上下文描述的人格引导表示学习；2. 建模高阶跨模态时间关系的超图变换器架构；3. 通过对比学习实现事件级领域解纠缠以提升跨行为情境的泛化能力。

Result: 在MPDD-Young数据集上，P³HF在二元和三元抑郁症分类任务上的准确率和加权F1分数相比现有方法提升了约10%。消融实验验证了各架构组件的独立贡献。

Conclusion: 人格引导表示学习和高阶超图推理对于生成鲁棒的、个体感知的抑郁症相关表示都是必不可少的，该方法在多模态抑郁症检测中表现出色。

Abstract: Depression represents a global mental health challenge requiring efficient and reliable automated detection methods. Current Transformer- or Graph Neural Networks (GNNs)-based multimodal depression detection methods face significant challenges in modeling individual differences and cross-modal temporal dependencies across diverse behavioral contexts. Therefore, we propose P$^3$HF (Personality-guided Public-Private Domain Disentangled Hypergraph-Former Network) with three key innovations: (1) personality-guided representation learning using LLMs to transform discrete individual features into contextual descriptions for personalized encoding; (2) Hypergraph-Former architecture modeling high-order cross-modal temporal relationships; (3) event-level domain disentanglement with contrastive learning for improved generalization across behavioral contexts. Experiments on MPDD-Young dataset show P$^3$HF achieves around 10\% improvement on accuracy and weighted F1 for binary and ternary depression classification task over existing methods. Extensive ablation studies validate the independent contribution of each architectural component, confirming that personality-guided representation learning and high-order hypergraph reasoning are both essential for generating robust, individual-aware depression-related representations. The code is released at https://github.com/hacilab/P3HF.

</details>


### [442] [Redundancy-optimized Multi-head Attention Networks for Multi-View Multi-Label Feature Selection](https://arxiv.org/abs/2511.12462)
*Yuzhou Liu,Jiarui Liu,Wanfu Gao*

Main category: cs.LG

TL;DR: 提出了一种基于冗余优化的多头注意力网络的多视图多标签特征选择方法（RMAN-MMFS），通过多头注意力机制建模视图内特征关系和视图间特征互补性，并设计了静态和动态冗余项来优化特征紧凑性。


<details>
  <summary>Details</summary>
Motivation: 多视图多标签数据特征选择面临视图间特征互补性和特征-标签相关性被忽视的问题，现有注意力方法主要关注视图内关系，且未充分考虑特征冗余，导致特征子集次优。

Method: 使用多头注意力机制：单个注意力头建模视图内特征关系，不同头间的交叉注意力机制捕获视图间特征互补性；设计静态冗余项（减少视图内冗余）和动态冗余项（显式建模未选与已选特征间的冗余）。

Result: 在六个真实世界数据集上与六种多视图多标签特征选择方法比较，证明了所提方法的优越性能。

Conclusion: RMAN-MMFS方法有效解决了多视图多标签特征选择中视图间互补性和特征冗余问题，提升了特征选择的性能。

Abstract: Multi-view multi-label data offers richer perspectives for artificial intelligence, but simultaneously presents significant challenges for feature selection due to the inherent complexity of interrelations among features, views and labels. Attention mechanisms provide an effective way for analyzing these intricate relationships. They can compute importance weights for information by aggregating correlations between Query and Key matrices to focus on pertinent values. However, existing attention-based feature selection methods predominantly focus on intra-view relationships, neglecting the complementarity of inter-view features and the critical feature-label correlations. Moreover, they often fail to account for feature redundancy, potentially leading to suboptimal feature subsets. To overcome these limitations, we propose a novel method based on Redundancy-optimized Multi-head Attention Networks for Multi-view Multi-label Feature Selection (RMAN-MMFS). Specifically, we employ each individual attention head to model intra-view feature relationships and use the cross-attention mechanisms between different heads to capture inter-view feature complementarity. Furthermore, we design static and dynamic feature redundancy terms: the static term mitigates redundancy within each view, while the dynamic term explicitly models redundancy between unselected and selected features across the entire selection process, thereby promoting feature compactness. Comprehensive evaluations on six real-world datasets, compared against six multi-view multi-label feature selection methods, demonstrate the superior performance of the proposed method.

</details>


### [443] [Logarithmic Regret and Polynomial Scaling in Online Multi-step-ahead Prediction](https://arxiv.org/abs/2511.12467)
*Jiachen Qian,Yang Zheng*

Main category: cs.LG

TL;DR: 该论文研究了未知线性随机系统的在线多步预测问题，提出了基于条件分布理论的最优预测策略参数化方法，并设计了在线最小二乘算法，证明了该算法相对于最优卡尔曼滤波器的对数遗憾界。


<details>
  <summary>Details</summary>
Motivation: 研究未知线性随机系统的在线多步预测问题，旨在开发能够在线学习并实现接近最优性能的预测算法，避免对系统模型的先验知识依赖。

Method: 利用条件分布理论推导预测策略的最优参数化形式（未来输入、过去输入和过去输出的线性函数），提出在线最小二乘算法来学习该策略，并分析其相对于最优模型预测器的遗憾。

Result: 在线算法在多步预测设置下实现了相对于最优卡尔曼滤波器的对数遗憾界，且对于足够大的时间范围N，建立了不依赖固定失败概率的几乎必然遗憾界。遗憾的常数因子随预测视野H多项式增长，增长阶数由系统矩阵中特征值1的最大Jordan块决定。

Conclusion: 该研究为未知线性系统的在线多步预测提供了理论保证，揭示了预测性能与系统结构（特别是特征值1的Jordan块大小）的定量关系，为实际应用提供了理论基础。

Abstract: This letter studies the problem of online multi-step-ahead prediction for unknown linear stochastic systems. Using conditional distribution theory, we derive an optimal parameterization of the prediction policy as a linear function of future inputs, past inputs, and past outputs. Based on this characterization, we propose an online least-squares algorithm to learn the policy and analyze its regret relative to the optimal model-based predictor. We show that the online algorithm achieves logarithmic regret with respect to the optimal Kalman filter in the multi-step setting. Furthermore, with new proof techniques, we establish an almost-sure regret bound that does not rely on fixed failure probabilities for sufficiently large horizons $N$. Finally, our analysis also reveals that, while the regret remains logarithmic in $N$, its constant factor grows polynomially with the prediction horizon $H$, with the polynomial order set by the largest Jordan block of eigenvalue 1 in the system matrix.

</details>


### [444] [Diffusion Model Based Signal Recovery Under 1-Bit Quantization](https://arxiv.org/abs/2511.12471)
*Youming Chen,Zhaoqiang Liu*

Main category: cs.LG

TL;DR: Diff-OneBit是一种基于扩散模型的快速有效方法，用于解决1位量化信号恢复问题，通过可微分替代似然函数处理非可微链接函数，在重建质量和计算效率上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在信号恢复中表现出强大潜力，但在1位量化任务（如1位压缩感知和逻辑回归）中应用困难，主要因为非可微或隐式链接函数的存在。

Method: 提出Diff-OneBit方法，使用可微分替代似然函数建模1位量化，构建即插即用框架将数据保真项与扩散先验解耦，允许任何预训练扩散模型作为去噪器参与迭代重建过程。

Result: 在FFHQ、CelebA和ImageNet数据集上的实验表明，Diff-OneBit能够生成高保真重建图像，在1位压缩感知和逻辑回归任务中在重建质量和计算效率上均优于现有最优方法。

Conclusion: Diff-OneBit成功解决了扩散模型在1位量化任务中的应用难题，提供了一种高效可靠的信号恢复解决方案。

Abstract: Diffusion models (DMs) have demonstrated to be powerful priors for signal recovery, but their application to 1-bit quantization tasks, such as 1-bit compressed sensing and logistic regression, remains a challenge. This difficulty stems from the inherent non-linear link function in these tasks, which is either non-differentiable or lacks an explicit characterization. To tackle this issue, we introduce Diff-OneBit, which is a fast and effective DM-based approach for signal recovery under 1-bit quantization. Diff-OneBit addresses the challenge posed by non-differentiable or implicit links functions via leveraging a differentiable surrogate likelihood function to model 1-bit quantization, thereby enabling gradient based iterations. This function is integrated into a flexible plug-and-play framework that decouples the data-fidelity term from the diffusion prior, allowing any pretrained DM to act as a denoiser within the iterative reconstruction process. Extensive experiments on the FFHQ, CelebA and ImageNet datasets demonstrate that Diff-OneBit gives high-fidelity reconstructed images, outperforming state-of-the-art methods in both reconstruction quality and computational efficiency across 1-bit compressed sensing and logistic regression tasks.

</details>


### [445] [SculptDrug : A Spatial Condition-Aware Bayesian Flow Model for Structure-based Drug Design](https://arxiv.org/abs/2511.12489)
*Qingsong Zhong,Haomin Yu,Yan Lin,Wangmeng Shen,Long Zeng,Jilin Hu*

Main category: cs.LG

TL;DR: SculptDrug是一个基于贝叶斯流网络的空间条件感知生成模型，用于解决基于结构的药物设计中的边界约束、层次结构条件和空间建模保真度等关键挑战。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型在药物设计中面临三个主要挑战：边界条件约束的整合、层次结构条件的集成以及空间建模保真度的保证。这些限制影响了药物配体生成的准确性和有效性。

Method: SculptDrug采用基于贝叶斯流网络的框架，使用渐进去噪策略确保空间建模保真度；引入边界感知块将蛋白质表面约束整合到生成过程中；设计层次编码器捕获全局结构上下文同时保留细粒度分子相互作用。

Result: 在CrossDocked数据集上的实验结果表明，SculptDrug优于现有最先进的基线方法，证明了空间条件感知建模的有效性。

Conclusion: SculptDrug通过创新的空间条件感知生成方法，成功解决了SBDD中的关键挑战，为药物发现提供了更准确和有效的工具。

Abstract: Structure-Based drug design (SBDD) has emerged as a popular approach in drug discovery, leveraging three-dimensional protein structures to generate drug ligands. However, existing generative models encounter several key challenges: (1) incorporating boundary condition constraints, (2) integrating hierarchical structural conditions, and (3) ensuring spatial modeling fidelity. To address these limitations, we propose SculptDrug, a spatial condition-aware generative model based on Bayesian flow networks (BFNs). First, SculptDrug follows a BFN-based framework and employs a progressive denoising strategy to ensure spatial modeling fidelity, iteratively refining atom positions while enhancing local interactions for precise spatial alignment. Second, we introduce a Boundary Awareness Block that incorporates protein surface constraints into the generative process to ensure that generated ligands are geometrically compatible with the target protein. Third, we design a Hierarchical Encoder that captures global structural context while preserving fine-grained molecular interactions, ensuring overall consistency and accurate ligand-protein conformations. We evaluate SculptDrug on the CrossDocked dataset, and experimental results demonstrate that SculptDrug outperforms state-of-the-art baselines, highlighting the effectiveness of spatial condition-aware modeling.

</details>


### [446] [Uncover and Unlearn Nuisances: Agnostic Fully Test-Time Adaptation](https://arxiv.org/abs/2511.12491)
*Ponhvoan Srey,Yaxin Shi,Hangwei Qian,Jing Li,Ivor W. Tsang*

Main category: cs.LG

TL;DR: 本文提出了一种名为Agnostic FTTA（AFTTA）的新方法，通过模拟和消除潜在域偏移来增强模型在完全测试时适应（FTTA）场景下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 完全测试时适应（FTTA）面临无法访问源数据和训练协议的问题，传统方法无法应对不可预测的目标域偏移。

Method: 采用uncover-and-unlearn方法：首先通过预定义映射模拟源域和目标域之间的潜在偏移作为干扰因素，然后在测试时通过互信息准则在特征空间和标签空间进行正则化，消除这些干扰。

Result: 在涉及腐败和风格偏移的各种任务上的广泛实验表明，该方法始终优于现有方法。

Conclusion: AFTTA方法能够显式处理不可知的域偏移，在FTTA约束下实现优越的模型泛化性能。

Abstract: Fully Test-Time Adaptation (FTTA) addresses domain shifts without access to source data and training protocols of the pre-trained models. Traditional strategies that align source and target feature distributions are infeasible in FTTA due to the absence of training data and unpredictable target domains. In this work, we exploit a dual perspective on FTTA, and propose Agnostic FTTA (AFTTA) as a novel formulation that enables the usage of off-the-shelf domain transformations during test-time to enable direct generalization to unforeseeable target data. To address this, we develop an uncover-and-unlearn approach. First, we uncover potential unwanted shifts between source and target domains by simulating them through predefined mappings and consider them as nuisances. Then, during test-time prediction, the model is enforced to unlearn these nuisances by regularizing the consequent shifts in latent representations and label predictions. Specifically, a mutual information-based criterion is devised and applied to guide nuisances unlearning in the feature space and encourage confident and consistent prediction in label space. Our proposed approach explicitly addresses agnostic domain shifts, enabling superior model generalization under FTTA constraints. Extensive experiments on various tasks, involving corruption and style shifts, demonstrate that our method consistently outperforms existing approaches.

</details>


### [447] [Towards Better IncomLDL: We Are Unaware of Hidden Labels in Advance](https://arxiv.org/abs/2511.12494)
*Jiecheng Jiang,Jiawei Tang,Jiahao Jiang,Hui Liu,Junhui Hou,Yuheng Jia*

Main category: cs.LG

TL;DR: 本文提出了隐藏标签分布学习（HidLDL）问题，解决了传统不完整标签分布学习中缺失标签设置为0的不合理设定，通过比例信息约束和特征相似性来恢复完整标签分布。


<details>
  <summary>Details</summary>
Motivation: 传统不完整标签分布学习（IncomLDL）方法将缺失标签的描述度设为0，但现实中当某些标签缺失时，剩余标签的描述度会相应增加，这种设定不切实际。

Method: 利用观测标签的比例信息作为创新约束，同时结合局部特征相似性和全局低秩结构来恢复隐藏标签，并提供了理论恢复边界证明。

Result: 在多个数据集上的恢复和预测实验表明，该方法优于最先进的LDL和IncomLDL方法。

Conclusion: HidLDL方法有效解决了真实世界不完整标签分布的问题，通过合理的比例约束和特征分析成功恢复了隐藏标签信息。

Abstract: Label distribution learning (LDL) is a novel paradigm that describe the samples by label distribution of a sample. However, acquiring LDL dataset is costly and time-consuming, which leads to the birth of incomplete label distribution learning (IncomLDL). All the previous IncomLDL methods set the description degrees of "missing" labels in an instance to 0, but remains those of other labels unchanged. This setting is unrealistic because when certain labels are missing, the degrees of the remaining labels will increase accordingly. We fix this unrealistic setting in IncomLDL and raise a new problem: LDL with hidden labels (HidLDL), which aims to recover a complete label distribution from a real-world incomplete label distribution where certain labels in an instance are omitted during annotation. To solve this challenging problem, we discover the significance of proportional information of the observed labels and capture it by an innovative constraint to utilize it during the optimization process. We simultaneously use local feature similarity and the global low-rank structure to reveal the mysterious veil of hidden labels. Moreover, we theoretically give the recovery bound of our method, proving the feasibility of our method in learning from hidden labels. Extensive recovery and predictive experiments on various datasets prove the superiority of our method to state-of-the-art LDL and IncomLDL methods.

</details>


### [448] [BSO: Binary Spiking Online Optimization Algorithm](https://arxiv.org/abs/2511.12502)
*Yu Liang,Yu Yang,Wenjie Wei,Ammar Belatreche,Shuai Wang,Malu Zhang,Yang Yang*

Main category: cs.LG

TL;DR: 本文提出了BSO和T-BSO两种二值脉冲神经网络的在线训练算法，显著降低了训练内存需求，通过翻转信号直接更新权重，无需存储潜在权重。


<details>
  <summary>Details</summary>
Motivation: 解决二值脉冲神经网络训练算法内存开销大的问题，特别是潜在权重存储和时间处理需求导致的内存负担。

Method: BSO算法通过翻转信号直接更新权重，当梯度动量与权重的乘积超过阈值时触发翻转；T-BSO是时间感知变体，利用BSNN的时间动态特性，跨时间步捕获梯度信息进行自适应阈值调整。

Result: 理论分析证明了BSO和T-BSO的收敛性，实验表明两种算法在BSNN训练中相比现有方法取得了更优的优化性能。

Conclusion: BSO和T-BSO是高效的内存友好型BSNN训练算法，通过在线优化框架和翻转机制显著降低了训练内存需求，同时保持了良好的收敛性能。

Abstract: Binary Spiking Neural Networks (BSNNs) offer promising efficiency advantages for resource-constrained computing. However, their training algorithms often require substantial memory overhead due to latent weights storage and temporal processing requirements. To address this issue, we propose Binary Spiking Online (BSO) optimization algorithm, a novel online training algorithm that significantly reduces training memory. BSO directly updates weights through flip signals under the online training framework. These signals are triggered when the product of gradient momentum and weights exceeds a threshold, eliminating the need for latent weights during training. To enhance performance, we propose T-BSO, a temporal-aware variant that leverages the inherent temporal dynamics of BSNNs by capturing gradient information across time steps for adaptive threshold adjustment. Theoretical analysis establishes convergence guarantees for both BSO and T-BSO, with formal regret bounds characterizing their convergence rates. Extensive experiments demonstrate that both BSO and T-BSO achieve superior optimization performance compared to existing training methods for BSNNs. The codes are available at https://github.com/hamings1/BSO.

</details>


### [449] [Hierarchical Frequency-Decomposition Graph Neural Networks for Road Network Representation Learning](https://arxiv.org/abs/2511.12507)
*Jingtian Ma,Jingyuan Wang,Leong Hou U*

Main category: cs.LG

TL;DR: HiFiNet是一种新颖的分层频率分解图神经网络，通过构建虚拟节点层次结构来统一空间和频谱建模，解决了现有方法在道路网络表示学习中空间-频谱不对齐的问题。


<details>
  <summary>Details</summary>
Motivation: 现有图神经网络方法在道路网络建模中存在空间-频谱不对齐的局限性：基于空间的方法容易过平滑，基于频谱的方法忽视局部变化。道路网络需要同时捕捉全局趋势和局部波动。

Method: HiFiNet采用分解-更新-重构框架，构建多级虚拟节点层次结构进行局部频率分析，使用拓扑感知图变换器分别建模和融合低频和高频信号。

Result: 在多个真实世界数据集和四个下游任务上的实证验证表明，HiFiNet在捕捉有效道路网络表示方面表现出优越的性能和泛化能力。

Conclusion: HiFiNet通过统一空间和频谱建模，有效解决了道路网络表示学习中的挑战，为智能交通系统应用提供了更强大的基础。

Abstract: Road networks are critical infrastructures underpinning intelligent transportation systems and their related applications. Effective representation learning of road networks remains challenging due to the complex interplay between spatial structures and frequency characteristics in traffic patterns. Existing graph neural networks for modeling road networks predominantly fall into two paradigms: spatial-based methods that capture local topology but tend to over-smooth representations, and spectral-based methods that analyze global frequency components but often overlook localized variations. This spatial-spectral misalignment limits their modeling capacity for road networks exhibiting both coarse global trends and fine-grained local fluctuations. To bridge this gap, we propose HiFiNet, a novel hierarchical frequency-decomposition graph neural network that unifies spatial and spectral modeling. HiFiNet constructs a multi-level hierarchy of virtual nodes to enable localized frequency analysis, and employs a decomposition-updating-reconstruction framework with a topology-aware graph transformer to separately model and fuse low- and high-frequency signals. Theoretically justified and empirically validated on multiple real-world datasets across four downstream tasks, HiFiNet demonstrates superior performance and generalization ability in capturing effective road network representations.

</details>


### [450] [Spectral Bias Mitigation via xLSTM-PINN: Memory-Gated Representation Refinement for Physics-Informed Learning](https://arxiv.org/abs/2511.12512)
*Ze Tao,Darui Zhao,Fujun Liu,Ke Xu,Xiangsheng Hu*

Main category: cs.LG

TL;DR: 提出了一种基于xLSTM的物理信息神经网络（xLSTM-PINN），通过门控记忆多尺度特征提取和自适应残差-数据加权，有效抑制频谱偏差并增强外推能力。


<details>
  <summary>Details</summary>
Motivation: 当前物理信息学习PDE方法面临频谱偏差、残差-数据不平衡和弱外推等问题，需要改进以提升计算精度和稳定性。

Method: 结合门控跨尺度记忆、分阶段频率课程和自适应残差重加权，在四个基准测试中验证了方法的有效性。

Result: 相比基线PINN，在所有四个基准测试中均降低了MSE、RMSE、MAE和MaxAE，频谱误差显著降低，可分辨带宽右移，高波数误差衰减更快。

Conclusion: 该方法在不改变自动微分或物理损失的情况下，有效抑制了频谱偏差，拓宽了可分辨带宽，提高了准确性、可重复性和可迁移性。

Abstract: Physics-informed learning for PDEs is surging across scientific computing and industrial simulation, yet prevailing methods face spectral bias, residual-data imbalance, and weak extrapolation. We introduce a representation-level spectral remodeling xLSTM-PINN that combines gated-memory multiscale feature extraction with adaptive residual-data weighting to curb spectral bias and strengthen extrapolation. Across four benchmarks, we integrate gated cross-scale memory, a staged frequency curriculum, and adaptive residual reweighting, and verify with analytic references and extrapolation tests, achieving markedly lower spectral error and RMSE and a broader stable learning-rate window. Frequency-domain benchmarks show raised high-frequency kernel weights and a right-shifted resolvable bandwidth, shorter high-k error decay and time-to-threshold, and narrower error bands with lower MSE, RMSE, MAE, and MaxAE. Compared with the baseline PINN, we reduce MSE, RMSE, MAE, and MaxAE across all four benchmarks and deliver cleaner boundary transitions with attenuated high-frequency ripples in both frequency and field maps. This work suppresses spectral bias, widens the resolvable band and shortens the high-k time-to-threshold under the same budget, and without altering AD or physics losses improves accuracy, reproducibility, and transferability.

</details>


### [451] [Regret Guarantees for Linear Contextual Stochastic Shortest Path](https://arxiv.org/abs/2511.12534)
*Dor Polikar,Alon Cohen*

Main category: cs.LG

TL;DR: 该论文提出了线性上下文随机最短路径问题（CSSP）的LR-CSSP算法，解决了在未知线性映射下上下文MDP的强化学习问题，实现了有界的遗憾保证。


<details>
  <summary>Details</summary>
Motivation: 在上下文有限时域MDP中，知识不足主要导致更高的损失和遗憾，但在CSSP设置中，知识不足还会延长回合时间甚至导致回合无法终止。需要设计能够处理连续上下文空间并确保回合合理终止的算法。

Method: 提出了LR-CSSP算法，该算法不需要事先了解转移动态、损失函数或从上下文到MDP的映射。算法通过在线学习方式处理对抗性选择的上下文，目标是达到指定目标状态时最小化期望累积损失。

Result: LR-CSSP实现了遗憾界为$\widetilde{O}(K^{2/3} d^{2/3} |S| |A|^{1/3} B_\star^2 T_\star \log (1/ δ))$。当所有成本超过$\ell_{\min}$时，遗憾为$\widetilde O(\sqrt{K \cdot d^2 |S|^3 |A| B_\star^3 \log(1/δ)/\ell_{\min}})$。算法能有效处理连续上下文空间并确保所有回合在合理时间步内终止。

Conclusion: LR-CSSP算法在线性上下文随机最短路径问题中表现出色，不仅提供了有理论保证的遗憾界，还解决了知识不足导致的回合延长问题，为连续上下文空间的强化学习提供了有效解决方案。

Abstract: We define the problem of linear Contextual Stochastic Shortest Path (CSSP), where at the beginning of each episode, the learner observes an adversarially chosen context that determines the MDP through a fixed but unknown linear function. The learner's objective is to reach a designated goal state with minimal expected cumulative loss, despite having no prior knowledge of the transition dynamics, loss functions, or the mapping from context to MDP. In this work, we propose LR-CSSP, an algorithm that achieves a regret bound of $\widetilde{O}(K^{2/3} d^{2/3} |S| |A|^{1/3} B_\star^2 T_\star \log (1/ δ))$, where $K$ is the number of episodes, $d$ is the context dimension, $S$ and $A$ are the sets of states and actions respectively, $B_\star$ bounds the optimal cumulative loss and $T_\star$, unknown to the learner, bounds the expected time for the optimal policy to reach the goal. In the case where all costs exceed $\ell_{\min}$, LR-CSSP attains a regret of $\widetilde O(\sqrt{K \cdot d^2 |S|^3 |A| B_\star^3 \log(1/δ)/\ell_{\min}})$. Unlike in contextual finite-horizon MDPs, where limited knowledge primarily leads to higher losses and regret, in the CSSP setting, insufficient knowledge can also prolong episodes and may even lead to non-terminating episodes. Our analysis reveals that LR-CSSP effectively handles continuous context spaces, while ensuring all episodes terminate within a reasonable number of time steps.

</details>


### [452] [Center-Outward q-Dominance: A Sample-Computable Proxy for Strong Stochastic Dominance in Multi-Objective Optimisation](https://arxiv.org/abs/2511.12545)
*Robin van der Laag,Hao Wang,Thomas Bäck,Yingjie Fan*

Main category: cs.LG

TL;DR: 本文提出了一种基于最优传输理论的中心向外q-支配关系，用于随机多目标优化中的多元分布排序，解决了传统标量化方法信息丢失的问题。


<details>
  <summary>Details</summary>
Motivation: 随机多目标优化需要比较多元分布，但现有经验研究多采用标量化方法，这会丢失信息且不可靠。

Method: 基于最优传输理论引入中心向外q-支配关系，证明其蕴含强一阶随机支配；开发基于q-支配的经验检验程序，推导出控制Type I错误的显式样本量阈值n*(δ)。

Result: 在超参数调优中，当期望超体积指标无法区分时，q-支配能有效比较七个多目标超参数调优器的最终随机帕累托集；在NSGA-II算法中用q-支配替代基于均值的选择，在噪声增强的ZDT基准问题上显示出更优的收敛速度。

Conclusion: 中心向外q-支配为寻求真正随机支配解提供了原则性、可处理的基础。

Abstract: Stochastic multi-objective optimization (SMOOP) requires ranking multivariate distributions; yet, most empirical studies perform scalarization, which loses information and is unreliable. Based on the optimal transport theory, we introduce the center-outward q-dominance relation and prove it implies strong first-order stochastic dominance (FSD). Also, we develop an empirical test procedure based on q-dominance, and derive an explicit sample size threshold, $n^*(δ)$, to control the Type I error. We verify the usefulness of our approach in two scenarios: (1) as a ranking method in hyperparameter tuning; (2) as a selection method in multi-objective optimization algorithms. For the former, we analyze the final stochastic Pareto sets of seven multi-objective hyperparameter tuners on the YAHPO-MO benchmark tasks with q-dominance, which allows us to compare these tuners when the expected hypervolume indicator (HVI, the most common performance metric) of the Pareto sets becomes indistinguishable. For the latter, we replace the mean value-based selection in the NSGA-II algorithm with $q$-dominance, which shows a superior convergence rate on noise-augmented ZDT benchmark problems. These results establish center-outward q-dominance as a principled, tractable foundation for seeking truly stochastically dominant solutions for SMOOPs.

</details>


### [453] [CAO: Curvature-Adaptive Optimization via Periodic Low-Rank Hessian Sketching](https://arxiv.org/abs/2511.12548)
*Wenzhang Du*

Main category: cs.LG

TL;DR: 本文提出了一种曲率自适应优化方法，通过周期性构建低秩Hessian子空间来预处理梯度，在保持一阶方法稳定性的同时显著加速收敛。


<details>
  <summary>Details</summary>
Motivation: 一阶优化器在尖锐、各向异性区域收敛缓慢，而二阶方法计算成本高。需要一种兼顾效率和收敛速度的优化方法。

Method: 周期性通过Hessian-向量积构建低秩Hessian子空间，仅在该子空间内预处理梯度，正交补空间保持一阶优化。方法只有一个超参数k（子空间维度）。

Result: 在CIFAR-10/100和ResNet-18/34上，该方法比Adam快2.95倍达到预设训练损失阈值，同时保持最终测试精度。对超参数k不敏感，k=0时退化为标准一阶方法。

Conclusion: 该方法提供了一种简单有效的曲率自适应优化策略，在深度学习任务中显著加速收敛，同时保持最终性能。

Abstract: First-order optimizers are reliable but slow in sharp, anisotropic regions. We study a curvature-adaptive method that periodically sketches a low-rank Hessian subspace via Hessian--vector products and preconditions gradients only in that subspace, leaving the orthogonal complement first-order. For L-smooth non-convex objectives, we recover the standard O(1/T) stationarity guarantee with a widened stable stepsize range; under a Polyak--Lojasiewicz (PL) condition with bounded residual curvature outside the sketch, the loss contracts at refresh steps. On CIFAR-10/100 with ResNet-18/34, the method enters the low-loss region substantially earlier: measured by epochs to a pre-declared train-loss threshold (0.75), it reaches the threshold 2.95x faster than Adam on CIFAR-100/ResNet-18, while matching final test accuracy. The approach is one-knob: performance is insensitive to the sketch rank k across {1,3,5}, and k=0 yields a principled curvature-free ablation. We release anonymized logs and scripts that regenerate all figures and tables.

</details>


### [454] [Training Instabilities Induce Flatness Bias in Gradient Descent](https://arxiv.org/abs/2511.12558)
*Lawrence Wang,Stephen J. Roberts*

Main category: cs.LG

TL;DR: 本文揭示了梯度下降训练不稳定性对深度学习的积极影响，证明不稳定性会驱动参数向损失函数更平坦的区域移动，从而改善泛化性能。


<details>
  <summary>Details</summary>
Motivation: 传统分析认为学习率低于Hessian最大特征值（锐度）时训练才稳定，但现代深度网络的最佳性能往往出现在这个阈值之上，需要解释这一现象背后的机制。

Method: 提出了旋转极性特征向量（RPE）理论框架，分析训练不稳定时Hessian主导特征向量的旋转现象，并扩展到随机梯度下降和Adam优化器。

Result: 训练不稳定性通过RPE机制促进参数探索，理论证明能到达更平坦的最小值，实验显示这种平坦化效应超过了小批量噪声的影响。

Conclusion: 训练不稳定性在深度学习中具有建设性作用，通过驱动参数向平坦区域移动来改善泛化性能，这一发现为理解深度学习优化提供了新视角。

Abstract: Classical analyses of gradient descent (GD) define a stability threshold based on the largest eigenvalue of the loss Hessian, often termed sharpness. When the learning rate lies below this threshold, training is stable and the loss decreases monotonically. Yet, modern deep networks often achieve their best performance beyond this regime.
  We demonstrate that such instabilities induce an implicit bias in GD, driving parameters toward flatter regions of the loss landscape and thereby improving generalization. The key mechanism is the Rotational Polarity of Eigenvectors (RPE), a geometric phenomenon in which the leading eigenvectors of the Hessian rotate during training instabilities. These rotations, which increase with learning rates, promote exploration and provably lead to flatter minima.
  This theoretical framework extends to stochastic GD, where instability-driven flattening persists and its empirical effects outweigh minibatch noise. Finally, we show that restoring instabilities in Adam further improves generalization.
  Together, these results establish and understand the constructive role of training instabilities in deep learning.

</details>


### [455] [Linear time small coresets for k-mean clustering of segments with applications](https://arxiv.org/abs/2511.12564)
*David Denisov,Shlomi Dolev,Dan Felmdan,Michael Segal*

Main category: cs.LG

TL;DR: 本文提出了首个能够处理任意输入线段的高效核心集构造方法，用于解决线段k-means聚类问题，在保持理论保证的同时实现了实际应用中的显著加速。


<details>
  <summary>Details</summary>
Motivation: 现有的k-means聚类方法主要针对点数据，而现实应用中经常需要处理线段数据（如视频追踪中的轨迹）。传统方法无法有效处理线段数据的连续特性，需要开发专门的核心集构造方法来支持高效计算。

Method: 提出了一种新的核心集构造算法，能够为任意输入线段集构建大小为O(log²n)的核心集，计算复杂度为O(nd)。该方法通过ε-核心集来近似原始线段集的聚类目标函数，支持流式、分布式和并行计算。

Result: 理论分析证明对于常数k和ε，核心集大小仅为O(log²n)。实验验证了方法的有效性，在视频追踪等实际应用中实现了显著的速度提升，同时聚类精度损失极小。

Conclusion: 该研究首次解决了任意线段k-means聚类的核心集构造问题，为处理连续几何对象的聚类问题提供了高效可行的解决方案，在理论和实践层面都具有重要意义。

Abstract: We study the $k$-means problem for a set $\mathcal{S} \subseteq \mathbb{R}^d$ of $n$ segments, aiming to find $k$ centers $X \subseteq \mathbb{R}^d$ that minimize
  $D(\mathcal{S},X) := \sum_{S \in \mathcal{S}} \min_{x \in X} D(S,x)$, where $D(S,x) := \int_{p \in S} |p - x| dp$
  measures the total distance from each point along a segment to a center. Variants of this problem include handling outliers, employing alternative distance functions such as M-estimators, weighting distances to achieve balanced clustering, or enforcing unique cluster assignments. For any $\varepsilon > 0$, an $\varepsilon$-coreset is a weighted subset $C \subseteq \mathbb{R}^d$ that approximates $D(\mathcal{S},X)$ within a factor of $1 \pm \varepsilon$ for any set of $k$ centers, enabling efficient streaming, distributed, or parallel computation. We propose the first coreset construction that provably handles arbitrary input segments. For constant $k$ and $\varepsilon$, it produces a coreset of size $O(\log^2 n)$ computable in $O(nd)$ time. Experiments, including a real-time video tracking application, demonstrate substantial speedups with minimal loss in clustering accuracy, confirming both the practical efficiency and theoretical guarantees of our method.

</details>


### [456] [Enhancing Machine Learning Model Efficiency through Quantization and Bit Depth Optimization: A Performance Analysis on Healthcare Data](https://arxiv.org/abs/2511.12568)
*Mitul Goswami,Romit Chatterjee*

Main category: cs.LG

TL;DR: 该研究通过量化和位深优化技术优化复杂学习模型，显著降低时间复杂性同时保持模型效率，在医疗数据集上应用逻辑回归模型验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决复杂模型执行时间过长的问题，通过优化技术在不显著影响精度的情况下降低计算复杂度。

Method: 使用量化和位深优化策略，将输入数据从float64降级到float32和int32，在两个医疗数据集上应用逻辑回归模型进行验证。

Result: 结果显示时间复杂性显著降低，优化后模型精度仅有轻微下降，证明了该优化方法的先进性。

Conclusion: 优化技术的影响效果取决于一组参数，需要根据具体情况进行调整和应用。

Abstract: This research aims to optimize intricate learning models by implementing quantization and bit-depth optimization techniques. The objective is to significantly cut time complexity while preserving model efficiency, thus addressing the challenge of extended execution times in intricate models. Two medical datasets were utilized as case studies to apply a Logistic Regression (LR) machine learning model. Using efficient quantization and bit depth optimization strategies the input data is downscaled from float64 to float32 and int32. The results demonstrated a significant reduction in time complexity, with only a minimal decrease in model accuracy post-optimization, showcasing the state-of-the-art optimization approach. This comprehensive study concludes that the impact of these optimization techniques varies depending on a set of parameters.

</details>


### [457] [LMM-IR: Large-Scale Netlist-Aware Multimodal Framework for Static IR-Drop Prediction](https://arxiv.org/abs/2511.12581)
*Kai Ma,Zhen Wang,Hongquan He,Qi Xu,Tinghuan Chen,Hao Geng*

Main category: cs.LG

TL;DR: 本文提出了一种新颖的多模态方法，通过大规模网表变换器（LNT）高效处理SPICE文件，将网表拓扑表示为3D点云，实现快速准确的静态电压降预测。


<details>
  <summary>Details</summary>
Motivation: 静态IR压降分析是芯片设计中的关键任务，但过程耗时且需要多次迭代分析，因此需要快速准确的预测方法来减少设计时间。

Method: 采用多模态方法处理SPICE文件，通过大规模网表变换器将网表拓扑表示为3D点云，支持处理数十万到数百万节点的网表，并将各类数据编码为特征进行预测。

Result: 实验结果表明，该算法在ICCAD 2023竞赛和现有最先进算法中取得了最佳的F1分数和最低的MAE。

Conclusion: 该方法能够有效整合多模态数据进行互补预测，为芯片设计中的静态电压降分析提供了高效解决方案。

Abstract: Static IR drop analysis is a fundamental and critical task in the field of chip design. Nevertheless, this process can be quite time-consuming, potentially requiring several hours. Moreover, addressing IR drop violations frequently demands iterative analysis, thereby causing the computational burden. Therefore, fast and accurate IR drop prediction is vital for reducing the overall time invested in chip design. In this paper, we firstly propose a novel multimodal approach that efficiently processes SPICE files through large-scale netlist transformer (LNT). Our key innovation is representing and processing netlist topology as 3D point cloud representations, enabling efficient handling of netlist with up to hundreds of thousands to millions nodes. All types of data, including netlist files and image data, are encoded into latent space as features and fed into the model for static voltage drop prediction. This enables the integration of data from multiple modalities for complementary predictions. Experimental results demonstrate that our proposed algorithm can achieve the best F1 score and the lowest MAE among the winning teams of the ICCAD 2023 contest and the state-of-the-art algorithms.

</details>


### [458] [Symmetry-Aware Graph Metanetwork Autoencoders: Model Merging through Parameter Canonicalization](https://arxiv.org/abs/2511.12601)
*Odysseas Boufalis,Jorge Carrasco-Pollo,Joshua Rosenthal,Eduardo Terres-Caballero,Alejandro García-Castellanos*

Main category: cs.LG

TL;DR: 本文提出了Scale Graph Metanetworks (ScaleGMNs)，通过构建对排列和参数缩放变换等变的架构，利用神经网络参数化的固有对称性，将相似网络映射到同一损失盆地中。


<details>
  <summary>Details</summary>
Motivation: 神经网络参数化存在固有对称性，导致损失景观中出现多个等效最小值。先前工作仅处理了排列对称性，但计算复杂度高。本文旨在同时利用排列和缩放对称性，避免显式求解组合分配问题。

Method: 提出了基于ScaleGMNs的自编码器框架，使用不变编码器将Implicit Neural Representations (INRs)和Convolutional Neural Networks (CNNs)在排列和缩放对称性下对齐。

Result: 实验结果表明，该方法能够在不显式求解分配问题的情况下，成功对齐INRs和CNNs，确保相似网络自然收敛到同一盆地。

Conclusion: 该方法促进了模型合并，实现了平滑的线性插值，同时避免了高损失区域，为神经网络对称性利用提供了更高效的解决方案。

Abstract: Neural network parameterizations exhibit inherent symmetries that yield multiple equivalent minima within the loss landscape. Scale Graph Metanetworks (ScaleGMNs) explicitly leverage these symmetries by proposing an architecture equivariant to both permutation and parameter scaling transformations. Previous work by Ainsworth et al. (2023) addressed permutation symmetries through a computationally intensive combinatorial assignment problem, demonstrating that leveraging permutation symmetries alone can map networks into a shared loss basin. In this work, we extend their approach by also incorporating scaling symmetries, presenting an autoencoder framework utilizing ScaleGMNs as invariant encoders. Experimental results demonstrate that our method aligns Implicit Neural Representations (INRs) and Convolutional Neural Networks (CNNs) under both permutation and scaling symmetries without explicitly solving the assignment problem. This approach ensures that similar networks naturally converge within the same basin, facilitating model merging, i.e., smooth linear interpolation while avoiding regions of high loss. The code is publicly available on our GitHub repository.

</details>


### [459] [PID-controlled Langevin Dynamics for Faster Sampling of Generative Models](https://arxiv.org/abs/2511.12603)
*Hongyi Chen,Jianhai Shu,Jingtao Ding,Yong Li,Xiao-Ping Zhang*

Main category: cs.LG

TL;DR: PIDLD是一种基于控制论的Langevin动力学采样加速算法，通过结合历史梯度（积分项）和梯度趋势（微分项）来显著减少生成高质量样本所需的迭代次数。


<details>
  <summary>Details</summary>
Motivation: Langevin动力学采样存在生成速度极低的问题，受限于需要大量细粒度迭代才能收敛到目标分布。

Method: 将采样过程重新解释为控制论问题，将能量梯度视为反馈信号，使用PID控制器结合历史梯度和梯度趋势来高效遍历能量景观并自适应稳定。

Result: 在图像生成和推理任务上的大量实验表明，PIDLD能够以更少的步骤实现更高质量，使基于Langevin的生成模型在效率关键应用中更加实用。

Conclusion: PIDLD无需额外训练、数据集或先验信息，可立即与任何基于Langevin的方法集成，显著提高了采样效率。

Abstract: Langevin dynamics sampling suffers from extremely low generation speed, fundamentally limited by numerous fine-grained iterations to converge to the target distribution. We introduce PID-controlled Langevin Dynamics (PIDLD), a novel sampling acceleration algorithm that reinterprets the sampling process using control-theoretic principles. By treating energy gradients as feedback signals, PIDLD combines historical gradients (the integral term) and gradient trends (the derivative term) to efficiently traverse energy landscapes and adaptively stabilize, thereby significantly reducing the number of iterations required to produce high-quality samples. Our approach requires no additional training, datasets, or prior information, making it immediately integrable with any Langevin-based method. Extensive experiments across image generation and reasoning tasks demonstrate that PIDLD achieves higher quality with fewer steps, making Langevin-based generative models more practical for efficiency-critical applications. The implementation can be found at \href{https://github.com/tsinghua-fib-lab/PIDLD}{https://github.com/tsinghua-fib-lab/PIDLD}.

</details>


### [460] [FedTopo: Topology-Informed Representation Alignment in Federated Learning under Non-I.I.D. Conditions](https://arxiv.org/abs/2511.12628)
*Ke Hu,Liyao Xiang,Peng Tang,Weidong Qiu*

Main category: cs.LG

TL;DR: FedTopo是一个解决联邦学习中非IID数据问题的框架，通过拓扑引导的块筛选、拓扑嵌入和拓扑对齐损失来提升模型性能


<details>
  <summary>Details</summary>
Motivation: 当前联邦学习模型在异构（非IID）客户端数据下性能下降，因为特征表示会发散，像素或补丁级目标无法捕捉高维视觉任务所需的全局拓扑结构

Method: FedTopo框架包含三个核心组件：1）拓扑引导块筛选（TGBS）自动选择最具拓扑信息量的块；2）拓扑嵌入（TE）为每个客户端量化拓扑信息；3）拓扑对齐损失（TAL）指导客户端在优化过程中保持与全局模型的拓扑一致性

Result: 在Fashion-MNIST、CIFAR-10和CIFAR-100数据集上的四种非IID分区实验表明，FedTopo加速了收敛速度并提高了准确率，优于强基线方法

Conclusion: FedTopo通过利用拓扑信息成功解决了联邦学习中的非IID数据问题，实现了更好的特征表示对齐和模型性能

Abstract: Current federated-learning models deteriorate under heterogeneous (non-I.I.D.) client data, as their feature representations diverge and pixel- or patch-level objectives fail to capture the global topology which is essential for high-dimensional visual tasks. We propose FedTopo, a framework that integrates Topological-Guided Block Screening (TGBS) and Topological Embedding (TE) to leverage topological information, yielding coherently aligned cross-client representations by Topological Alignment Loss (TAL). First, Topology-Guided Block Screening (TGBS) automatically selects the most topology-informative block, i.e., the one with maximal topological separability, whose persistence-based signatures best distinguish within- versus between-class pairs, ensuring that subsequent analysis focuses on topology-rich features. Next, this block yields a compact Topological Embedding, which quantifies the topological information for each client. Finally, a Topological Alignment Loss (TAL) guides clients to maintain topological consistency with the global model during optimization, reducing representation drift across rounds. Experiments on Fashion-MNIST, CIFAR-10, and CIFAR-100 under four non-I.I.D. partitions show that FedTopo accelerates convergence and improves accuracy over strong baselines.

</details>


### [461] [NFQ2.0: The CartPole Benchmark Revisited](https://arxiv.org/abs/2511.12644)
*Sascha Lange,Roland Hafner,Martin Riedmiller*

Main category: cs.LG

TL;DR: 本文重新评估了20年前的神经拟合Q迭代算法在经典CartPole基准上的表现，提出了现代化变体NFQ2.0，并通过消融研究改进其在工业环境中的可重复性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: NFQ是将多层神经网络应用于强化学习的先驱方法，但存在需要大量调参和难以在实际控制问题中复现的问题，需要探索如何提高学习过程的重复性和鲁棒性。

Method: 提出NFQ2.0现代化变体，在CartPole任务上进行实验，使用标准工业组件构建真实系统，通过消融研究分析关键设计决策和超参数。

Result: NFQ2.0在性能和稳定性上优于原始变体，研究结果有助于从业者更好地复现和改进结果，更有效地在工业环境中应用深度强化学习。

Conclusion: NFQ2.0通过关键设计改进提升了算法的可重复性和鲁棒性，为工业应用中的深度强化学习提供了实用指导。

Abstract: This article revisits the 20-year-old neural fitted Q-iteration (NFQ) algorithm on its classical CartPole benchmark. NFQ was a pioneering approach towards modern Deep Reinforcement Learning (Deep RL) in applying multi-layer neural networks to reinforcement learning for real-world control problems. We explore the algorithm's conceptual simplicity and its transition from online to batch learning, which contributed to its stability. Despite its initial success, NFQ required extensive tuning and was not easily reproducible on real-world control problems. We propose a modernized variant NFQ2.0 and apply it to the CartPole task, concentrating on a real-world system build from standard industrial components, to investigate and improve the learning process's repeatability and robustness. Through ablation studies, we highlight key design decisions and hyperparameters that enhance performance and stability of NFQ2.0 over the original variant. Finally, we demonstrate how our findings can assist practitioners in reproducing and improving results and applying deep reinforcement learning more effectively in industrial contexts.

</details>


### [462] [Sample Complexity of Agnostic Multiclass Classification: Natarajan Dimension Strikes Back](https://arxiv.org/abs/2511.12659)
*Alon Cohen,Liad Erez,Steve Hanneke,Tomer Koren,Yishay Mansour,Shay Moran,Qian Zhang*

Main category: cs.LG

TL;DR: 该论文证明多类别分类的PAC学习样本复杂度由两个维度共同控制：DS维度和Natarajan维度，其边界形式为DS^1.5/ε + Nat/ε^2，表明多类别学习本质上需要两个结构参数。


<details>
  <summary>Details</summary>
Motivation: 传统上认为多类别PAC学习由单一维度（如Natarajan维度）控制，但近期研究表明DS维度才是多类别可学习性的特征。然而，这两个维度可以任意发散，引发了对多类别学习样本复杂度本质的深入探究。

Method: 采用了一种新颖的在线方法，基于自适应的乘法权重算法进行标签空间约简，突破了传统的基于均匀收敛或可学习情况归约的泛化学习方法。

Result: 获得了紧致的泛化样本复杂度边界，证明多类别学习由DS维度控制的快速收敛阶段和Natarajan维度控制的渐进阶段共同决定。

Conclusion: 多类别学习与二元分类或在线学习不同，需要两个结构参数共同描述，揭示了多类别学习的本质复杂性。

Abstract: The fundamental theorem of statistical learning states that binary PAC learning is governed by a single parameter -- the Vapnik-Chervonenkis (VC) dimension -- which determines both learnability and sample complexity. Extending this to multiclass classification has long been challenging, since Natarajan's work in the late 80s proposing the Natarajan dimension (Nat) as a natural analogue of VC. Daniely and Shalev-Shwartz (2014) introduced the DS dimension, later shown by Brukhim et al. (2022) to characterize multiclass learnability. Brukhim et al. also showed that Nat and DS can diverge arbitrarily, suggesting that multiclass learning is governed by DS rather than Nat. We show that agnostic multiclass PAC sample complexity is in fact governed by two distinct dimensions. Specifically, we prove nearly tight agnostic sample complexity bounds that, up to log factors, take the form $\frac{DS^{1.5}}ε + \frac{Nat}{ε^2}$ where $ε$ is the excess risk. This bound is tight up to a $\sqrt{DS}$ factor in the first term, nearly matching known $Nat/ε^2$ and $DS/ε$ lower bounds. The first term reflects the DS-controlled regime, while the second shows that the Natarajan dimension still dictates asymptotic behavior for small $ε$. Thus, unlike binary or online classification -- where a single dimension (VC or Littlestone) controls both phenomena -- multiclass learning inherently involves two structural parameters. Our technical approach departs from traditional agnostic learning methods based on uniform convergence or reductions to realizable cases. A key ingredient is a novel online procedure based on a self-adaptive multiplicative-weights algorithm performing a label-space reduction, which may be of independent interest.

</details>


### [463] [FLClear: Visually Verifiable Multi-Client Watermarking for Federated Learning](https://arxiv.org/abs/2511.12663)
*Chen Gu,Yingying Sun,Yifan She,Donghui Hu*

Main category: cs.LG

TL;DR: FLClear是一个联邦学习水印框架，通过转置模型和对比学习实现无碰撞水印聚合、增强水印安全性和可视化所有权验证。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中，中央服务器可能恶意操纵全局模型以抹除客户端贡献或虚假声称所有权，侵犯客户端知识产权。现有水印方法存在水印碰撞、安全性不足和验证机制不直观的问题。

Method: 引入转置模型联合优化对比学习，集成水印和主任务目标。验证时从转置模型重建水印，通过视觉检查和结构相似性指标进行直观和定量所有权验证。

Result: 在各种数据集、聚合方案和攻击场景下的综合实验表明，FLClear有效且始终优于最先进的联邦学习水印方法。

Conclusion: FLClear框架成功解决了联邦学习中的水印碰撞、安全性和验证直观性问题，为保护客户端知识产权提供了有效解决方案。

Abstract: Federated learning (FL) enables multiple clients to collaboratively train a shared global model while preserving the privacy of their local data. Within this paradigm, the intellectual property rights (IPR) of client models are critical assets that must be protected. In practice, the central server responsible for maintaining the global model may maliciously manipulate the global model to erase client contributions or falsely claim sole ownership, thereby infringing on clients' IPR. Watermarking has emerged as a promising technique for asserting model ownership and protecting intellectual property. However, existing FL watermarking approaches remain limited, suffering from potential watermark collisions among clients, insufficient watermark security, and non-intuitive verification mechanisms. In this paper, we propose FLClear, a novel framework that simultaneously achieves collision-free watermark aggregation, enhanced watermark security, and visually interpretable ownership verification. Specifically, FLClear introduces a transposed model jointly optimized with contrastive learning to integrate the watermarking and main task objectives. During verification, the watermark is reconstructed from the transposed model and evaluated through both visual inspection and structural similarity metrics, enabling intuitive and quantitative ownership verification. Comprehensive experiments conducted over various datasets, aggregation schemes, and attack scenarios demonstrate the effectiveness of FLClear and confirm that it consistently outperforms state-of-the-art FL watermarking methods.

</details>


### [464] [Attention-Enhanced Convolutional Autoencoder and Structured Delay Embeddings for Weather Prediction](https://arxiv.org/abs/2511.12682)
*Amirpasha Hedayat,Karthik Duraisamy*

Main category: cs.LG

TL;DR: 本文提出了一个用于短期天气预报的高效降阶建模框架，通过ResNet卷积自编码器和块注意力模块降低天气数据维度，在延迟嵌入潜在空间中学习线性算子来捕捉动态特性。该框架在训练数据期间表现良好，但在泛化到未来状态时存在局限性。


<details>
  <summary>Details</summary>
Motivation: 天气预报是一个复杂的高维非线性混沌系统预测问题。现有AI模型需要大量计算资源，本文旨在开发一个优先考虑效率同时保持合理精度的降阶建模框架。

Method: 使用基于ResNet的卷积自编码器结合块注意力模块来降低高维天气数据的维度，然后在时间延迟嵌入的潜在空间中学习线性算子来有效捕捉动态特性。使用ERA5再分析数据集进行验证。

Result: 该框架在训练数据分布内能有效预测天气模式，但在泛化到训练窗口之外的未来状态时预测精度下降。分析表明投影误差而非推理误差是主要瓶颈。

Conclusion: 天气系统在适当构建的嵌入空间中可以通过线性操作有效捕捉强时间相关性。研究揭示了混沌系统降阶建模的关键挑战，并为结合高效降阶模型与复杂AI架构的混合方法提供了机会，特别是在计算效率至关重要的长期气候建模中。

Abstract: Weather prediction is a quintessential problem involving the forecasting of a complex, nonlinear, and chaotic high-dimensional dynamical system. This work introduces an efficient reduced-order modeling (ROM) framework for short-range weather prediction and investigates fundamental questions in dimensionality reduction and reduced order modeling of such systems. Unlike recent AI-driven models, which require extensive computational resources, our framework prioritizes efficiency while achieving reasonable accuracy. Specifically, a ResNet-based convolutional autoencoder augmented by block attention modules is developed to reduce the dimensionality of high-dimensional weather data. Subsequently, a linear operator is learned in the time-delayed embedding of the latent space to efficiently capture the dynamics. Using the ERA5 reanalysis dataset, we demonstrate that this framework performs well in-distribution as evidenced by effectively predicting weather patterns within training data periods. We also identify important limitations in generalizing to future states, particularly in maintaining prediction accuracy beyond the training window. Our analysis reveals that weather systems exhibit strong temporal correlations that can be effectively captured through linear operations in an appropriately constructed embedding space, and that projection error rather than inference error is the main bottleneck. These findings shed light on some key challenges in reduced-order modeling of chaotic systems and point toward opportunities for hybrid approaches that combine efficient reduced-order models as baselines with more sophisticated AI architectures, particularly for applications in long-term climate modeling where computational efficiency is paramount.

</details>


### [465] [A Closer Look at Personalized Fine-Tuning in Heterogeneous Federated Learning](https://arxiv.org/abs/2511.12695)
*Minghui Chen,Hrad Ghoukasian,Ruinan Jin,Zehua Wang,Sai Praneeth Karimireddy,Xiaoxiao Li*

Main category: cs.LG

TL;DR: 本文提出将集中式学习中的LP-FT策略（线性探测后全微调）应用于联邦学习，以解决联邦学习中全局泛化与本地个性化之间的平衡问题，并通过理论分析和实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在非独立同分布数据下难以平衡全局模型泛化能力和本地个性化需求，现有的个性化微调方法容易过拟合或无法适应领域偏移。

Method: 将LP-FT策略适配到联邦学习设置，采用分阶段参数更新：先进行线性探测（仅更新最后一层），再进行全模型微调，以缓解联邦特征失真问题。

Result: 在七个数据集和六种PFT变体上的系统评估表明，LP-FT在平衡个性化和泛化方面优于现有方法，并理论分析了LP-FT在部分特征重叠和协变量-概念偏移等条件下的优势。

Conclusion: LP-FT为联邦学习中的鲁棒个性化提供了有效解决方案，通过分阶段更新策略缓解特征失真，并给出了实际部署的指导原则。

Abstract: Federated Learning (FL) enables decentralized, privacy-preserving model training but struggles to balance global generalization and local personalization due to non-identical data distributions across clients. Personalized Fine-Tuning (PFT), a popular post-hoc solution, fine-tunes the final global model locally but often overfits to skewed client distributions or fails under domain shifts. We propose adapting Linear Probing followed by full Fine-Tuning (LP-FT), a principled centralized strategy for alleviating feature distortion (Kumar et al., 2022), to the FL setting. Through systematic evaluation across seven datasets and six PFT variants, we demonstrate LP-FT's superiority in balancing personalization and generalization. Our analysis uncovers federated feature distortion, a phenomenon where local fine-tuning destabilizes globally learned features, and theoretically characterizes how LP-FT mitigates this via phased parameter updates. We further establish conditions (e.g., partial feature overlap, covariate-concept shift) under which LP-FT outperforms standard fine-tuning, offering actionable guidelines for deploying robust personalization in FL.

</details>


### [466] [Beyond Fixed Tasks: Unsupervised Environment Design for Task-Level Pairs](https://arxiv.org/abs/2511.12706)
*Daniel Furelos-Blanco,Charles Pert,Frederik Kelbel,Alex F. Spies,Alessandra Russo,Michael Dennis*

Main category: cs.LG

TL;DR: ATLAS是一种新颖的方法，通过联合自动课程设计生成任务和关卡的联合自动课程，解决强化学习中复杂指令与复杂环境组合训练的问题。


<details>
  <summary>Details</summary>
Motivation: 训练通用智能体在复杂环境中执行复杂指令是强化学习的核心挑战。随机采样任务-关卡组合往往产生不可解的组合，因此需要共同设计任务和关卡。

Method: ATLAS基于无监督环境设计（UED），自动生成可解但具有挑战性的任务-关卡组合用于策略训练。该方法利用任务和关卡结构的突变来加速收敛。

Result: 实验表明ATLAS显著优于随机采样方法，特别是在可解组合采样概率较低的情况下。利用任务和关卡结构的突变能加速收敛到高性能策略。

Conclusion: ATLAS成功解决了任务和关卡联合自动课程设计的问题，为强化学习领域提供了有效的训练方法。

Abstract: Training general agents to follow complex instructions (tasks) in intricate environments (levels) remains a core challenge in reinforcement learning. Random sampling of task-level pairs often produces unsolvable combinations, highlighting the need to co-design tasks and levels. While unsupervised environment design (UED) has proven effective at automatically designing level curricula, prior work has only considered a fixed task. We present ATLAS (Aligning Tasks and Levels for Autocurricula of Specifications), a novel method that generates joint autocurricula over tasks and levels. Our approach builds upon UED to automatically produce solvable yet challenging task-level pairs for policy training. To evaluate ATLAS and drive progress in the field, we introduce an evaluation suite that models tasks as reward machines in Minigrid levels. Experiments demonstrate that ATLAS vastly outperforms random sampling approaches, particularly when sampling solvable pairs is unlikely. We further show that mutations leveraging the structure of both tasks and levels accelerate convergence to performant policies.

</details>


### [467] [Adaptive Graph Rewiring to Mitigate Over-Squashing in Mesh-Based GNNs for Fluid Dynamics Simulations](https://arxiv.org/abs/2511.12709)
*Sangwoo Seo,Hyunsung Kim,Jiwan Kim,Chanyoung Park*

Main category: cs.LG

TL;DR: 本文提出了一种名为AdaMeshNet的自适应图重布线框架，通过在消息传递过程中引入自适应重布线来解决网格细化导致的过压缩问题，从而更准确地模拟物理相互作用的渐进传播。


<details>
  <summary>Details</summary>
Motivation: 传统的图重布线方法在GNN应用前完成所有重布线操作，这假设了远距离节点之间的瞬时相互作用，忽略了粒子间的距离信息，在物理上不现实。

Method: AdaMeshNet在消息传递过程中引入自适应重布线过程，基于最短路径距离和速度差计算瓶颈节点的重布线延迟分数，动态选择重布线的消息传递层。

Result: 在基于网格的流体模拟实验中，AdaMeshNet优于传统的重布线方法，能够有效模拟物理相互作用的顺序性质，实现更准确的预测。

Conclusion: AdaMeshNet通过自适应重布线机制成功解决了网格细化导致的过压缩问题，为基于网格的GNN流体模拟提供了更物理真实的方法。

Abstract: Mesh-based simulation using Graph Neural Networks (GNNs) has been recognized as a promising approach for modeling fluid dynamics. However, the mesh refinement techniques which allocate finer resolution to regions with steep gradients can induce the over-squashing problem in mesh-based GNNs, which prevents the capture of long-range physical interactions. Conventional graph rewiring methods attempt to alleviate this issue by adding new edges, but they typically complete all rewiring operations before applying them to the GNN. These approaches are physically unrealistic, as they assume instantaneous interactions between distant nodes and disregard the distance information between particles. To address these limitations, we propose a novel framework, called Adaptive Graph Rewiring in Mesh-Based Graph Neural Networks (AdaMeshNet), that introduces an adaptive rewiring process into the message-passing procedure to model the gradual propagation of physical interactions. Our method computes a rewiring delay score for bottleneck nodes in the mesh graph, based on the shortest-path distance and the velocity difference. Using this score, it dynamically selects the message-passing layer at which new edges are rewired, which can lead to adaptive rewiring in a mesh graph. Extensive experiments on mesh-based fluid simulations demonstrate that AdaMeshNet outperforms conventional rewiring methods, effectively modeling the sequential nature of physical interactions and enabling more accurate predictions.

</details>


### [468] [Oxytrees: Model Trees for Bipartite Learning](https://arxiv.org/abs/2511.12713)
*Pedro Ilídio,Felipe Kenji Nakano,Alireza Gharahighehi,Robbe D'hondt,Ricardo Cerri,Celine Vens*

Main category: cs.LG

TL;DR: Oxytrees是一种基于代理的双聚类模型树，通过压缩交互矩阵显著减少训练时间，同时保持或提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 当前的双边学习方法存在通用性差和可扩展性问题，通常针对特定应用设计，难以推广到其他问题。

Method: 提出Oxytrees模型：1）将交互矩阵压缩为行和列代理矩阵；2）新的叶子分配算法加速预测；3）在叶子节点使用Kronecker积核的线性模型，生成更浅的树结构。

Result: 在15个数据集上的实验表明，相比最先进的双聚类森林，训练时间提升高达30倍，在大多数评估设置中表现出竞争性或更优的性能，特别是在归纳设置中。

Conclusion: Oxytrees在保持预测性能的同时显著提升了训练效率，并提供了可复现研究的Python API。

Abstract: Bipartite learning is a machine learning task that aims to predict interactions between pairs of instances. It has been applied to various domains, including drug-target interactions, RNA-disease associations, and regulatory network inference. Despite being widely investigated, current methods still present drawbacks, as they are often designed for a specific application and thus do not generalize to other problems or present scalability issues. To address these challenges, we propose Oxytrees: proxy-based biclustering model trees. Oxytrees compress the interaction matrix into row- and column-wise proxy matrices, significantly reducing training time without compromising predictive performance. We also propose a new leaf-assignment algorithm that significantly reduces the time taken for prediction. Finally, Oxytrees employ linear models using the Kronecker product kernel in their leaves, resulting in shallower trees and thus even faster training. Using 15 datasets, we compared the predictive performance of ensembles of Oxytrees with that of the current state-of-the-art. We achieved up to 30-fold improvement in training times compared to state-of-the-art biclustering forests, while demonstrating competitive or superior performance in most evaluation settings, particularly in the inductive setting. Finally, we provide an intuitive Python API to access all datasets, methods and evaluation measures used in this work, thus enabling reproducible research in this field.

</details>


### [469] [On Robustness of Linear Classifiers to Targeted Data Poisoning](https://arxiv.org/abs/2511.12722)
*Nakshatra Gupta,Sumanth Prabhu,Supratik Chakraborty,R Venkatesh*

Main category: cs.LG

TL;DR: 本文提出了一种自动测量数据集对标签扰动攻击的鲁棒性方法，证明了该问题是NP完全问题，并开发了计算鲁棒性上下界的高效算法。


<details>
  <summary>Details</summary>
Motivation: 数据投毒攻击会破坏学习模型的可信度，手动检测投毒在大型训练数据集中很困难，因此需要自动测量数据集对这类攻击的鲁棒性。

Method: 在攻击者只能扰动训练数据标签且仅知道受害者模型假设空间的威胁模型下，提出计算鲁棒性上下界的技术，并实现了高效计算这些界限的算法。

Result: 实验证明，超出识别鲁棒性界限的投毒会显著影响测试点分类，且该方法能在更多情况下计算这些界限，而现有技术在这些情况下会失败。

Conclusion: 该方法能有效评估数据集对标签扰动攻击的鲁棒性，为模型安全性提供重要保障，且在计算效率上优于现有技术。

Abstract: Data poisoning is a training-time attack that undermines the trustworthiness of learned models. In a targeted data poisoning attack, an adversary manipulates the training dataset to alter the classification of a targeted test point. Given the typically large size of training dataset, manual detection of poisoning is difficult. An alternative is to automatically measure a dataset's robustness against such an attack, which is the focus of this paper. We consider a threat model wherein an adversary can only perturb the labels of the training dataset, with knowledge limited to the hypothesis space of the victim's model. In this setting, we prove that finding the robustness is an NP-Complete problem, even when hypotheses are linear classifiers. To overcome this, we present a technique that finds lower and upper bounds of robustness. Our implementation of the technique computes these bounds efficiently in practice for many publicly available datasets. We experimentally demonstrate the effectiveness of our approach. Specifically, a poisoning exceeding the identified robustness bounds significantly impacts test point classification. We are also able to compute these bounds in many more cases where state-of-the-art techniques fail.

</details>


### [470] [LAYA: Layer-wise Attention Aggregation for Interpretable Depth-Aware Neural Networks](https://arxiv.org/abs/2511.12723)
*Gennaro Vessio*

Main category: cs.LG

TL;DR: LAYA是一种新型输出头，通过注意力机制动态聚合深层网络中间层的表示，而非仅使用最终隐藏层，从而提升性能并提供可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统深度神经网络仅依赖最终隐藏层的表示进行预测，忽略了中间层包含的丰富互补信息（从低级模式到高级抽象）。

Method: 引入LAYA（Layer-wise Attention Aggregator），通过学习输入条件的注意力权重对层间特征进行动态聚合，生成可解释且架构无关的预测机制。

Result: 在视觉和语言基准测试中，LAYA持续匹配或优于标准输出头，准确率相对提升高达约1个百分点，同时提供层归因分数揭示不同抽象层次对决策的贡献。

Conclusion: LAYA不仅提升了模型性能，还提供了直接来自模型计算的可解释性信号，无需外部事后解释。

Abstract: Deep neural networks typically rely on the representation produced by their final hidden layer to make predictions, implicitly assuming that this single vector fully captures the semantics encoded across all preceding transformations. However, intermediate layers contain rich and complementary information -- ranging from low-level patterns to high-level abstractions -- that is often discarded when the decision head depends solely on the last representation. This paper revisits the role of the output layer and introduces LAYA (Layer-wise Attention Aggregator), a novel output head that dynamically aggregates internal representations through attention. Instead of projecting only the deepest embedding, LAYA learns input-conditioned attention weights over layer-wise features, yielding an interpretable and architecture-agnostic mechanism for synthesizing predictions. Experiments on vision and language benchmarks show that LAYA consistently matches or improves the performance of standard output heads, with relative gains of up to about one percentage point in accuracy, while providing explicit layer-attribution scores that reveal how different abstraction levels contribute to each decision. Crucially, these interpretability signals emerge directly from the model's computation, without any external post hoc explanations. The code to reproduce LAYA is publicly available at: https://github.com/gvessio/LAYA.

</details>


### [471] [Convolutional Model Trees](https://arxiv.org/abs/2511.12725)
*William Ward Armstrong*

Main category: cs.LG

TL;DR: 提出了一种基于模型树森林的方法来拟合图像函数，通过下采样、确定超平面、应用卷积处理小变形，并利用森林提高精度和平滑性。该方法支持处理大变形（如旋转和视角变化），并提供了理论平滑方法和收敛性证明。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够有效处理图像函数拟合的方法，特别是针对图像中的各种变形（如小变形、旋转和视角变化），同时保证模型的准确性和平滑性。

Method: 通过下采样图像、确定树超平面、应用卷积处理小变形，构建模型树森林以提高拟合精度，并利用像素、超平面系数和叶函数系数的一一对应关系处理大变形。

Result: 该方法能够有效拟合图像函数，处理小变形和大变形（如旋转和视角变化），并通过森林平滑输出实现连续可微的近似。

Conclusion: 提出的模型树森林方法在图像函数拟合中表现出良好的性能，能够处理多种变形，且理论框架下的训练过程具有收敛性。

Abstract: A method for creating a forest of model trees to fit samples of a function defined on images is described in several steps: down-sampling the images, determining a tree's hyperplanes, applying convolutions to the hyperplanes to handle small distortions of training images, and creating forests of model trees to increase accuracy and achieve a smooth fit. A 1-to-1 correspondence among pixels of images, coefficients of hyperplanes and coefficients of leaf functions offers the possibility of dealing with larger distortions such as arbitrary rotations or changes of perspective. A theoretical method for smoothing forest outputs to produce a continuously differentiable approximation is described. Within that framework, a training procedure is proved to converge.

</details>


### [472] [Stabilizing Self-Consuming Diffusion Models with Latent Space Filtering](https://arxiv.org/abs/2511.12742)
*Zhongteng Cai,Yaxuan Wang,Yang Liu,Xueru Zhang*

Main category: cs.LG

TL;DR: 论文提出了一种名为潜在空间过滤（LSF）的新方法，通过过滤混合数据集中不太真实的合成数据来缓解模型崩溃问题，而无需增加训练成本或依赖人工标注。


<details>
  <summary>Details</summary>
Motivation: 随着合成数据在互联网上的激增，这些数据常被用于训练后续几代生成模型，形成"自消耗循环"，可能导致训练不稳定或模型崩溃。现有方法如积累历史训练数据或注入新真实数据会增加计算成本或需要昂贵的人工标注。

Method: 基于对自消耗扩散模型潜在空间动态的实证分析，发现合成数据的低维潜在表示结构会随代际退化。提出潜在空间过滤（LSF）方法，通过过滤掉混合数据集中不太真实的合成数据来缓解模型崩溃。

Result: 实验表明，LSF在多个真实世界数据集上持续优于现有基线方法，能有效缓解模型崩溃，且不增加训练成本或依赖人工标注。

Conclusion: LSF提供了一种理论框架，将潜在空间退化与实证观察联系起来，为解决合成数据自消耗循环导致的模型崩溃问题提供了有效且实用的解决方案。

Abstract: As synthetic data proliferates across the Internet, it is often reused to train successive generations of generative models. This creates a ``self-consuming loop" that can lead to training instability or \textit{model collapse}. Common strategies to address the issue -- such as accumulating historical training data or injecting fresh real data -- either increase computational cost or require expensive human annotation. In this paper, we empirically analyze the latent space dynamics of self-consuming diffusion models and observe that the low-dimensional structure of latent representations extracted from synthetic data degrade over generations. Based on this insight, we propose \textit{Latent Space Filtering} (LSF), a novel approach that mitigates model collapse by filtering out less realistic synthetic data from mixed datasets. Theoretically, we present a framework that connects latent space degradation to empirical observations. Experimentally, we show that LSF consistently outperforms existing baselines across multiple real-world datasets, effectively mitigating model collapse without increasing training cost or relying on human annotation.

</details>


### [473] [DIVIDE: A Framework for Learning from Independent Multi-Mechanism Data Using Deep Encoders and Gaussian Processes](https://arxiv.org/abs/2511.12745)
*Vivek Chawla,Boris Slautin,Utkarsh Pratiush,Dayakar Penumadu,Sergei Kalinin*

Main category: cs.LG

TL;DR: DIVIDE是一个框架，通过整合机制特定的深度编码器和结构化高斯过程来分离科学数据集中多个独立机制的影响，实现可解释的机制感知预测。


<details>
  <summary>Details</summary>
Motivation: 科学数据集通常来自多个独立机制（如空间、分类或结构效应）的组合影响，这些影响相互掩盖，难以区分各个机制的贡献。

Method: 整合机制特定的深度编码器与结构化高斯过程在联合潜在空间中，编码器分离不同机制，高斯过程捕获其组合效应并量化不确定性，支持结构化先验。

Result: 在合成数据集、FerroSIM铁电模式模拟和PbTiO3薄膜实验PFM滞后回线数据上验证，DIVIDE能有效分离机制，重现加性和缩放相互作用，并在噪声下保持鲁棒性。

Conclusion: DIVIDE框架能成功分离科学数据集中的独立生成因素，支持可解释预测和高效主动学习，可自然扩展到多功能数据集。

Abstract: Scientific datasets often arise from multiple independent mechanisms such as spatial, categorical or structural effects, whose combined influence obscures their individual contributions. We introduce DIVIDE, a framework that disentangles these influences by integrating mechanism-specific deep encoders with a structured Gaussian Process in a joint latent space. Disentanglement here refers to separating independently acting generative factors. The encoders isolate distinct mechanisms while the Gaussian Process captures their combined effect with calibrated uncertainty. The architecture supports structured priors, enabling interpretable and mechanism-aware prediction as well as efficient active learning. DIVIDE is demonstrated on synthetic datasets combining categorical image patches with nonlinear spatial fields, on FerroSIM spin lattice simulations of ferroelectric patterns, and on experimental PFM hysteresis loops from PbTiO3 films. Across benchmarks, DIVIDE separates mechanisms, reproduces additive and scaled interactions, and remains robust under noise. The framework extends naturally to multifunctional datasets where mechanical, electromagnetic or optical responses coexist.

</details>


### [474] [Conformal Online Learning of Deep Koopman Linear Embeddings](https://arxiv.org/abs/2511.12760)
*Ben Gao,Jordan Patracone,Stéphane Chrétien,Olivier Alata*

Main category: cs.LG

TL;DR: COLoKe是一个用于从流数据中自适应更新非线性动力系统Koopman不变表示的新框架，通过结合深度特征学习和提升空间中的多步预测一致性，使用保形机制动态触发模型更新。


<details>
  <summary>Details</summary>
Motivation: 解决非线性动力系统建模中Koopman表示的自适应更新问题，防止过拟合并减少不必要的模型更新。

Method: 结合深度特征学习和提升空间中的多步预测一致性，使用保形机制评估当前Koopman模型的一致性，仅在预测误差超过动态校准阈值时触发更新。

Result: 在基准动力系统上的实证结果表明，COLoKe能有效维持长期预测准确性，同时显著减少不必要的更新并避免过拟合。

Conclusion: COLoKe框架为非线性动力系统的自适应Koopman表示学习提供了一种有效的方法，能够在保持预测精度的同时优化计算效率。

Abstract: We introduce Conformal Online Learning of Koopman embeddings (COLoKe), a novel framework for adaptively updating Koopman-invariant representations of nonlinear dynamical systems from streaming data. Our modeling approach combines deep feature learning with multistep prediction consistency in the lifted space, where the dynamics evolve linearly. To prevent overfitting, COLoKe employs a conformal-style mechanism that shifts the focus from evaluating the conformity of new states to assessing the consistency of the current Koopman model. Updates are triggered only when the current model's prediction error exceeds a dynamically calibrated threshold, allowing selective refinement of the Koopman operator and embedding. Empirical results on benchmark dynamical systems demonstrate the effectiveness of COLoKe in maintaining long-term predictive accuracy while significantly reducing unnecessary updates and avoiding overfitting.

</details>


### [475] [INC: An Indirect Neural Corrector for Auto-Regressive Hybrid PDE Solvers](https://arxiv.org/abs/2511.12764)
*Hao Wei,Aleksandra Franz,Bjoern List,Nils Thuerey*

Main category: cs.LG

TL;DR: 提出间接神经校正器（INC）方法，通过将学习校正整合到控制方程而非直接状态更新，解决混合求解器中自回归误差累积问题，显著提升长期轨迹性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统混合求解器直接将学习校正应用于求解器输出会导致显著的自回归误差，特别是在混沌状态下，扰动会累积放大，影响长期模拟稳定性。

Method: 提出间接神经校正器（INC）框架，将神经校正整合到控制方程中而不是直接状态更新，降低误差放大因子（Δt⁻¹ + L），可与任意神经网络和求解器无缝集成。

Result: 在广泛基准测试中，INC将长期轨迹性能（R²）提升高达158.7%，稳定了激进粗化下的爆炸问题，在复杂3D湍流案例中实现数个数量级的加速。

Conclusion: INC实现了具有形式误差减少的稳定高效PDE模拟，为具有可靠物理保证的更快科学和工程模拟铺平了道路。

Abstract: When simulating partial differential equations, hybrid solvers combine coarse numerical solvers with learned correctors. They promise accelerated simulations while adhering to physical constraints. However, as shown in our theoretical framework, directly applying learned corrections to solver outputs leads to significant autoregressive errors, which originate from amplified perturbations that accumulate during long-term rollouts, especially in chaotic regimes. To overcome this, we propose the Indirect Neural Corrector (\(\mathrm{INC}\)), which integrates learned corrections into the governing equations rather than applying direct state updates. Our key insight is that \(\mathrm{INC}\) reduces the error amplification on the order of \(Δt^{-1} + L\), where \(Δt\) is the timestep and $L$ the Lipschitz constant. At the same time, our framework poses no architectural requirements and integrates seamlessly with arbitrary neural networks and solvers. We test \(\mathrm{INC}\) in extensive benchmarks, covering numerous differentiable solvers, neural backbones, and test cases ranging from a 1D chaotic system to 3D turbulence. INC improves the long-term trajectory performance (\(R^2\)) by up to 158.7\%, stabilizes blowups under aggressive coarsening, and for complex 3D turbulence cases yields speed-ups of several orders of magnitude. INC thus enables stable, efficient PDE emulation with formal error reduction, paving the way for faster scientific and engineering simulations with reliable physics guarantees. Our source code is available at https://github.com/tum-pbs/INC

</details>


### [476] [MolEdit: Knowledge Editing for Multimodal Molecule Language Models](https://arxiv.org/abs/2511.12770)
*Zhenyu Lei,Patrick Soga,Yaochen Zhu,Yinhan He,Yushun Dong,Jundong Li*

Main category: cs.LG

TL;DR: 该论文提出了MolEdit框架，用于解决分子语言模型（MoLMs）中的知识编辑问题，通过多专家知识适配器和专业感知编辑切换器实现精准知识修改，同时保持无关知识的完整性。


<details>
  <summary>Details</summary>
Motivation: 分子语言模型在生物医学、化学和材料科学中应用广泛，但可能因训练数据过时或恶意篡改而传播错误知识。现有知识编辑方法在分子领域尚未探索，且分子知识具有多面性和相互依赖性，带来独特挑战。

Method: 提出MolEdit框架，包含多专家知识适配器（将编辑路由到不同分子方面的专业专家）和专业感知编辑切换器（仅在输入与存储编辑匹配时激活适配器）。该方法针对分子到描述生成和描述到分子生成两个关键任务。

Result: 在两个主流MoLM骨干网络上进行实验，MolEdit相比基线方法在可靠性方面提升18.8%，在局部性方面提升12.0%，同时保持效率。

Conclusion: MolEdit是首个针对分子语言模型的知识编辑框架，能够有效修改目标知识而不影响无关分子知识，为分子AI系统的可靠性和安全性提供了重要解决方案。

Abstract: Understanding and continuously refining multimodal molecular knowledge is crucial for advancing biomedicine, chemistry, and materials science. Molecule language models (MoLMs) have become powerful tools in these domains, integrating structural representations (e.g., SMILES strings, molecular graphs) with rich contextual descriptions (e.g., physicochemical properties). However, MoLMs can encode and propagate inaccuracies due to outdated web-mined training corpora or malicious manipulation, jeopardizing downstream discovery pipelines. While knowledge editing has been explored for general-domain AI, its application to MoLMs remains uncharted, presenting unique challenges due to the multifaceted and interdependent nature of molecular knowledge. In this paper, we take the first step toward MoLM editing for two critical tasks: molecule-to-caption generation and caption-to-molecule generation. To address molecule-specific challenges, we propose MolEdit, a powerful framework that enables targeted modifications while preserving unrelated molecular knowledge. MolEdit combines a Multi-Expert Knowledge Adapter that routes edits to specialized experts for different molecular facets with an Expertise-Aware Editing Switcher that activates the adapters only when input closely matches the stored edits across all expertise, minimizing interference with unrelated knowledge. To systematically evaluate editing performance, we introduce MEBench, a comprehensive benchmark assessing multiple dimensions, including Reliability (accuracy of the editing), Locality (preservation of irrelevant knowledge), and Generality (robustness to reformed queries). Across extensive experiments on two popular MoLM backbones, MolEdit delivers up to 18.8% higher Reliability and 12.0% better Locality than baselines while maintaining efficiency. The code is available at: https://github.com/LzyFischer/MolEdit.

</details>


### [477] [Scalable Multi-Objective and Meta Reinforcement Learning via Gradient Estimation](https://arxiv.org/abs/2511.12779)
*Zhenshuo Zhang,Minxuan Duan,Youran Ye,Hongyang R. Zhang*

Main category: cs.LG

TL;DR: 该论文提出了一种高效的多目标强化学习策略估计方法，通过将n个目标聚类到k个相关组（k<<n），使用元训练和微调的两阶段流程来优化策略学习。


<details>
  <summary>Details</summary>
Motivation: 在多目标强化学习应用中，随着目标数量n的增长，为所有目标学习单一策略变得次优。需要一种方法能够将相关目标分组训练，提高效率。

Method: 提出PolicyGradEx算法：1）使用多任务学习训练元策略；2）对随机采样子目标进行微调；3）基于估计的任务亲和度得分矩阵进行聚类分组；4）利用策略网络的一阶近似特性。

Result: 在三个机器人控制和Meta-World基准测试中，方法平均优于最先进基线16%，速度提升高达26倍。基于损失的聚类相比随机分组和梯度相似性分组提升19%。

Conclusion: 该方法有效解决了多目标强化学习中的策略优化问题，通过目标聚类实现了效率和性能的显著提升，并通过Hessian迹分析验证了泛化误差。

Abstract: We study the problem of efficiently estimating policies that simultaneously optimize multiple objectives in reinforcement learning (RL). Given $n$ objectives (or tasks), we seek the optimal partition of these objectives into $k \ll n$ groups, where each group comprises related objectives that can be trained together. This problem arises in applications such as robotics, control, and preference optimization in language models, where learning a single policy for all $n$ objectives is suboptimal as $n$ grows. We introduce a two-stage procedure -- meta-training followed by fine-tuning -- to address this problem. We first learn a meta-policy for all objectives using multitask learning. Then, we adapt the meta-policy to multiple randomly sampled subsets of objectives. The adaptation step leverages a first-order approximation property of well-trained policy networks, which is empirically verified to be accurate within a $2\%$ error margin across various RL environments. The resulting algorithm, PolicyGradEx, efficiently estimates an aggregate task-affinity score matrix given a policy evaluation algorithm. Based on the estimated affinity score matrix, we cluster the $n$ objectives into $k$ groups by maximizing the intra-cluster affinity scores. Experiments on three robotic control and the Meta-World benchmarks demonstrate that our approach outperforms state-of-the-art baselines by $16\%$ on average, while delivering up to $26\times$ faster speedup relative to performing full training to obtain the clusters. Ablation studies validate each component of our approach. For instance, compared with random grouping and gradient-similarity-based grouping, our loss-based clustering yields an improvement of $19\%$. Finally, we analyze the generalization error of policy networks by measuring the Hessian trace of the loss surface, which gives non-vacuous measures relative to the observed generalization errors.

</details>


### [478] [Physics-Constrained Adaptive Neural Networks Enable Real-Time Semiconductor Manufacturing Optimization with Minimal Training Data](https://arxiv.org/abs/2511.12788)
*Rubén Darío Guerrero*

Main category: cs.LG

TL;DR: 提出了一种物理约束自适应学习框架，用于解决EUV光刻优化中的计算危机，通过可学习参数自动校准电磁近似，在仅使用少量训练样本的情况下实现亚纳米级精度。


<details>
  <summary>Details</summary>
Motivation: 半导体行业在EUV光刻优化中面临计算危机，传统方法消耗大量CPU时间却无法达到亚纳米级精度，需要在学术物理信息神经网络与工业部署需求之间建立桥梁。

Method: 开发物理约束自适应学习框架，集成可微分模块（菲涅尔衍射、材料吸收、光学点扩散函数模糊、相移效应、对比度调制），通过可学习参数θ={θ_d, θ_a, θ_b, θ_p, θ_c}自动校准电磁近似，同时最小化模拟光刻图像与目标光掩模之间的边缘放置误差。

Result: 在15个代表性图案上实现一致的亚纳米级EPE性能（0.664-2.536 nm范围），仅需每个图案50个训练样本。相比无物理约束的CNN基线平均提升69.9%，训练完成后推理速度显著快于严格电磁求解器，通过跨几何泛化比图案特定CNN方法减少90%训练样本需求。

Conclusion: 该工作确立了物理约束自适应学习作为实时半导体制造优化的基础方法，通过联合物理校准和制造精度目标，解决了学术物理信息神经网络与工业部署需求之间的关键差距。

Abstract: The semiconductor industry faces a computational crisis in extreme ultraviolet (EUV) lithography optimization, where traditional methods consume billions of CPU hours while failing to achieve sub-nanometer precision. We present a physics-constrained adaptive learning framework that automatically calibrates electromagnetic approximations through learnable parameters $\boldsymbolθ = \{θ_d, θ_a, θ_b, θ_p, θ_c\}$ while simultaneously minimizing Edge Placement Error (EPE) between simulated aerial images and target photomasks. The framework integrates differentiable modules for Fresnel diffraction, material absorption, optical point spread function blur, phase-shift effects, and contrast modulation with direct geometric pattern matching objectives, enabling cross-geometry generalization with minimal training data. Through physics-constrained learning on 15 representative patterns spanning current production to future research nodes, we demonstrate consistent sub-nanometer EPE performance (0.664-2.536 nm range) using only 50 training samples per pattern. Adaptive physics learning achieves an average improvement of 69.9\% over CNN baselines without physics constraints, with a significant inference speedup over rigorous electromagnetic solvers after training completion. This approach requires 90\% fewer training samples through cross-geometry generalization compared to pattern-specific CNN training approaches. This work establishes physics-constrained adaptive learning as a foundational methodology for real-time semiconductor manufacturing optimization, addressing the critical gap between academic physics-informed neural networks and industrial deployment requirements through joint physics calibration and manufacturing precision objectives.

</details>


### [479] [Optimal Look-back Horizon for Time Series Forecasting in Federated Learning](https://arxiv.org/abs/2511.12791)
*Dahao Tang,Nan Yang,Yanli Li,Zhiyu Zhu,Zhibo Jin,Dong Yuan*

Main category: cs.LG

TL;DR: 本文提出了一个联邦时间序列预测中自适应回溯窗口选择的原理性框架，通过内在空间公式化解决异构数据环境下的窗口选择难题。


<details>
  <summary>Details</summary>
Motivation: 联邦学习场景下数据分散、异构且非独立，传统集中式方法无法有效处理回溯窗口选择问题，需要专门针对联邦环境的自适应方法。

Method: 引入合成数据生成器(SDG)捕捉客户端数据的时序结构，定义时间序列窗口到内在表示空间的变换，并推导预测损失的贝叶斯分解理论。

Result: 理论分析表明预测损失在不可约损失开始饱和而近似损失继续上升的最小回溯窗口处达到最小，为自适应选择提供了理论依据。

Conclusion: 为联邦学习中的时间序列预测提供了严格的自适应窗口选择理论基础，解决了异构数据环境下的关键挑战。

Abstract: Selecting an appropriate look-back horizon remains a fundamental challenge in time series forecasting (TSF), particularly in the federated learning scenarios where data is decentralized, heterogeneous, and often non-independent. While recent work has explored horizon selection by preserving forecasting-relevant information in an intrinsic space, these approaches are primarily restricted to centralized and independently distributed settings. This paper presents a principled framework for adaptive horizon selection in federated time series forecasting through an intrinsic space formulation. We introduce a synthetic data generator (SDG) that captures essential temporal structures in client data, including autoregressive dependencies, seasonality, and trend, while incorporating client-specific heterogeneity. Building on this model, we define a transformation that maps time series windows into an intrinsic representation space with well-defined geometric and statistical properties. We then derive a decomposition of the forecasting loss into a Bayesian term, which reflects irreducible uncertainty, and an approximation term, which accounts for finite-sample effects and limited model capacity. Our analysis shows that while increasing the look-back horizon improves the identifiability of deterministic patterns, it also increases approximation error due to higher model complexity and reduced sample efficiency. We prove that the total forecasting loss is minimized at the smallest horizon where the irreducible loss starts to saturate, while the approximation loss continues to rise. This work provides a rigorous theoretical foundation for adaptive horizon selection for time series forecasting in federated learning.

</details>


### [480] [Genomic Next-Token Predictors are In-Context Learners](https://arxiv.org/abs/2511.12797)
*Nathan Breslow,Aayush Mishra,Mahler Revsine,Michael C. Schatz,Anqi Liu,Daniel Khashabi*

Main category: cs.LG

TL;DR: 论文首次证明基因组序列通过大规模预测训练可以自然涌现上下文学习能力，支持上下文学习是大规模预测建模的通用特性而非语言特有现象


<details>
  <summary>Details</summary>
Motivation: 探索上下文学习是否能在非语言序列领域（如基因组序列）通过大规模预测训练自然涌现，验证上下文学习是否是大规模预测建模的通用特性

Method: 使用Evo2基因组模型，在基因组序列上进行大规模核苷酸预测训练，设计符号推理任务同时在语言和基因组形式中实例化，直接比较基因组和语言模型的上下文学习能力

Result: 基因组模型表现出与语言模型相似的上下文学习能力，随着上下文示例数量增加呈现对数线性增益，首次证明基因组序列可以自然涌现上下文学习

Conclusion: 上下文学习是大规模预测建模在丰富数据上的自然结果，可以扩展到语言之外的模态，指向一种统一的、模态无关的上下文学习观点

Abstract: In-context learning (ICL) -- the capacity of a model to infer and apply abstract patterns from examples provided within its input -- has been extensively studied in large language models trained for next-token prediction on human text. In fact, prior work often attributes this emergent behavior to distinctive statistical properties in human language. This raises a fundamental question: can ICL arise organically in other sequence domains purely through large-scale predictive training?
  To explore this, we turn to genomic sequences, an alternative symbolic domain rich in statistical structure. Specifically, we study the Evo2 genomic model, trained predominantly on next-nucleotide (A/T/C/G) prediction, at a scale comparable to mid-sized LLMs. We develop a controlled experimental framework comprising symbolic reasoning tasks instantiated in both linguistic and genomic forms, enabling direct comparison of ICL across genomic and linguistic models. Our results show that genomic models, like their linguistic counterparts, exhibit log-linear gains in pattern induction as the number of in-context demonstrations increases. To the best of our knowledge, this is the first evidence of organically emergent ICL in genomic sequences, supporting the hypothesis that ICL arises as a consequence of large-scale predictive modeling over rich data. These findings extend emergent meta-learning beyond language, pointing toward a unified, modality-agnostic view of in-context learning.

</details>


### [481] [The Alignment Game: A Theory of Long-Horizon Alignment Through Recursive Curation](https://arxiv.org/abs/2511.12804)
*Ali Falahati,Mohammad Mohammadi Amiri,Kate Larson,Lukasz Golab*

Main category: cs.LG

TL;DR: 该论文首次为分析自消费生成模型递归训练对对齐的长期影响提供了形式化基础，揭示了三种收敛机制，并证明了一个基本不可能性定理。


<details>
  <summary>Details</summary>
Motivation: 研究自消费生成模型在自身输出上递归训练时，用户偏好对齐如何从一次性过程转变为递归过程，以及这种递归再训练对长期对齐的影响。

Method: 基于Bradley-Terry模型的两阶段筛选机制，将对齐建模为模型所有者（过滤输出）和公共用户（决定保留哪些输出）两个派系之间的互动。

Result: 分析揭示了三种结构收敛机制（共识崩溃、共享最优妥协、非对称精炼），证明了递归BT筛选机制无法同时保持多样性、确保对称影响和消除初始化依赖。

Conclusion: 将对齐过程框架化为动态社会选择，表明对齐不是静态目标而是演化均衡，既受权力不对称性影响，也受路径依赖性影响。

Abstract: In self-consuming generative models that train on their own outputs, alignment with user preferences becomes a recursive rather than one-time process. We provide the first formal foundation for analyzing the long-term effects of such recursive retraining on alignment. Under a two-stage curation mechanism based on the Bradley-Terry (BT) model, we model alignment as an interaction between two factions: the Model Owner, who filters which outputs should be learned by the model, and the Public User, who determines which outputs are ultimately shared and retained through interactions with the model. Our analysis reveals three structural convergence regimes depending on the degree of preference alignment: consensus collapse, compromise on shared optima, and asymmetric refinement. We prove a fundamental impossibility theorem: no recursive BT-based curation mechanism can simultaneously preserve diversity, ensure symmetric influence, and eliminate dependence on initialization. Framing the process as dynamic social choice, we show that alignment is not a static goal but an evolving equilibrium, shaped both by power asymmetries and path dependence.

</details>


### [482] [Expressive Temporal Specifications for Reward Monitoring](https://arxiv.org/abs/2511.12808)
*Omar Adalat,Francesco Belardinelli*

Main category: cs.LG

TL;DR: 使用定量线性时序逻辑（LTL_f[F]）合成奖励监视器，为可观察状态轨迹生成密集奖励流，解决长时决策中稀疏奖励问题。


<details>
  <summary>Details</summary>
Motivation: 指定信息丰富且密集的奖励函数是强化学习中的关键挑战，直接影响智能体训练效率。当前文献主要基于布尔语义，存在稀疏奖励问题。

Method: 利用定量线性时序逻辑在有限轨迹上的表达能力，合成奖励监视器，提供训练过程中的细致反馈，框架与算法无关，仅依赖状态标记函数，自然支持非马尔可夫性质。

Result: 实验结果表明，定量监视器在最大化任务完成定量指标和减少收敛时间方面，始终优于布尔监视器，具体表现取决于环境。

Conclusion: 定量线性时序逻辑方法能有效解决稀疏奖励问题，提升强化学习训练效率，尤其在长时决策任务中表现优异。

Abstract: Specifying informative and dense reward functions remains a pivotal challenge in Reinforcement Learning, as it directly affects the efficiency of agent training. In this work, we harness the expressive power of quantitative Linear Temporal Logic on finite traces (($\text{LTL}_f[\mathcal{F}]$)) to synthesize reward monitors that generate a dense stream of rewards for runtime-observable state trajectories. By providing nuanced feedback during training, these monitors guide agents toward optimal behaviour and help mitigate the well-known issue of sparse rewards under long-horizon decision making, which arises under the Boolean semantics dominating the current literature. Our framework is algorithm-agnostic and only relies on a state labelling function, and naturally accommodates specifying non-Markovian properties. Empirical results show that our quantitative monitors consistently subsume and, depending on the environment, outperform Boolean monitors in maximizing a quantitative measure of task completion and in reducing convergence time.

</details>


### [483] [Assessing Automated Fact-Checking for Medical LLM Responses with Knowledge Graphs](https://arxiv.org/abs/2511.12817)
*Shasha Zhou,Mingyu Huang,Jack Cole,Charles Britton,Ming Yin,Jan Wolber,Ke Li*

Main category: cs.LG

TL;DR: 本文提出FAITH框架，利用医学知识图谱对LLM生成回答进行自动化事实性评估，无需参考答案即可实现与临床医生判断高度相关的评估效果。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在医疗领域的应用增多，需要严格验证其输出的可靠性以避免潜在危害。现有评估方法存在不足，需要开发更可靠的自动化评估工具。

Method: FAITH框架通过将LLM回答分解为原子声明，链接到医学知识图谱，基于证据路径进行评分，实现无需参考答案的事实性评估。

Result: 实验表明，基于知识图谱的评估与临床医生判断的相关性显著更高，能有效区分不同能力的LLM，且对文本变化具有鲁棒性。

Conclusion: 虽然存在局限，但利用知识图谱是医疗领域自动化事实性评估的重要方向，其可解释性评分有助于用户理解和缓解当前LLM的局限性。

Abstract: The recent proliferation of large language models (LLMs) holds the potential to revolutionize healthcare, with strong capabilities in diverse medical tasks. Yet, deploying LLMs in high-stakes healthcare settings requires rigorous verification and validation to understand any potential harm. This paper investigates the reliability and viability of using medical knowledge graphs (KGs) for the automated factuality evaluation of LLM-generated responses. To ground this investigation, we introduce FAITH, a framework designed to systematically probe the strengths and limitations of this KG-based approach. FAITH operates without reference answers by decomposing responses into atomic claims, linking them to a medical KG, and scoring them based on evidence paths. Experiments on diverse medical tasks with human subjective evaluations demonstrate that KG-grounded evaluation achieves considerably higher correlations with clinician judgments and can effectively distinguish LLMs with varying capabilities. It is also robust to textual variances. The inherent explainability of its scoring can further help users understand and mitigate the limitations of current LLMs. We conclude that while limitations exist, leveraging KGs is a prominent direction for automated factuality assessment in healthcare.

</details>


### [484] [Catastrophic Forgetting in Kolmogorov-Arnold Networks](https://arxiv.org/abs/2511.12828)
*Mohammad Marufur Rahman,Guanchu Wang,Kaixiong Zhou,Minghan Chen,Fan Yang*

Main category: cs.LG

TL;DR: 本文研究了Kolmogorov-Arnold Networks（KANs）在持续学习中的灾难性遗忘问题，开发了理论框架分析遗忘机制，并提出了KAN-LoRA适配器用于参数高效的持续微调。


<details>
  <summary>Details</summary>
Motivation: KANs被认为通过局部样条激活函数具有内在的抗遗忘能力，但其在持续学习中的实际表现和局限性尚不明确，需要系统性研究。

Method: 开发理论框架分析激活支持重叠和内在数据维度与遗忘的关系，通过合成和视觉任务实验验证，并设计KAN-LoRA适配器用于语言模型的持续微调。

Result: KANs在低维算法设置中表现出良好的记忆保持能力，但在高维领域（如图像分类和语言建模）中仍然容易发生遗忘。

Conclusion: 研究揭示了KANs在持续学习中的优势和局限性，为持续学习系统设计提供了实用见解。

Abstract: Catastrophic forgetting is a longstanding challenge in continual learning, where models lose knowledge from earlier tasks when learning new ones. While various mitigation strategies have been proposed for Multi-Layer Perceptrons (MLPs), recent architectural advances like Kolmogorov-Arnold Networks (KANs) have been suggested to offer intrinsic resistance to forgetting by leveraging localized spline-based activations. However, the practical behavior of KANs under continual learning remains unclear, and their limitations are not well understood. To address this, we present a comprehensive study of catastrophic forgetting in KANs and develop a theoretical framework that links forgetting to activation support overlap and intrinsic data dimension. We validate these analyses through systematic experiments on synthetic and vision tasks, measuring forgetting dynamics under varying model configurations and data complexity. Further, we introduce KAN-LoRA, a novel adapter design for parameter-efficient continual fine-tuning of language models, and evaluate its effectiveness in knowledge editing tasks. Our findings reveal that while KANs exhibit promising retention in low-dimensional algorithmic settings, they remain vulnerable to forgetting in high-dimensional domains such as image classification and language modeling. These results advance the understanding of KANs' strengths and limitations, offering practical insights for continual learning system design.

</details>


### [485] [An Evaluation of Representation Learning Methods in Particle Physics Foundation Models](https://arxiv.org/abs/2511.12829)
*Michael Chen,Raghav Kansal,Abhijith Gandrakota,Zichun Hao,Jennifer Ngadiuba,Maria Spiropulu*

Main category: cs.LG

TL;DR: 本文对粒子物理中的表示学习目标进行了系统评估，在统一框架下比较了对比学习、掩码粒子建模和生成重建等不同目标，并提出了改进的监督架构达到了最先进性能。


<details>
  <summary>Details</summary>
Motivation: 为粒子物理领域提供一个统一的表示学习评估框架，通过控制变量比较不同学习目标的贡献，为未来基础模型的发展建立参考基准。

Method: 使用共享的基于transformer的粒子云编码器，采用标准化预处理、匹配采样和一致评估协议，在喷注分类数据集上比较了对比学习（有监督和自监督）、掩码粒子建模和生成重建等目标。

Result: 研究发现了不同学习目标的优势和局限性，提出的有监督架构改进在基准评估中达到了最先进的性能。

Conclusion: 这项工作为粒子物理基础模型的未来发展提供了参考点，有助于社区实现更透明和稳健的进展。

Abstract: We present a systematic evaluation of representation learning objectives for particle physics within a unified framework. Our study employs a shared transformer-based particle-cloud encoder with standardized preprocessing, matched sampling, and a consistent evaluation protocol on a jet classification dataset. We compare contrastive (supervised and self-supervised), masked particle modeling, and generative reconstruction objectives under a common training regimen. In addition, we introduce targeted supervised architectural modifications that achieve state-of-the-art performance on benchmark evaluations. This controlled comparison isolates the contributions of the learning objective, highlights their respective strengths and limitations, and provides reproducible baselines. We position this work as a reference point for the future development of foundation models in particle physics, enabling more transparent and robust progress across the community.

</details>


### [486] [Connectivity-Guided Sparsification of 2-FWL GNNs: Preserving Full Expressivity with Improved Efficiency](https://arxiv.org/abs/2511.12838)
*Rongqin Chen,Fan Mo,Pak Lon Ip,Shenghui Zhang,Dan Wu,Ye Li,Leong Hou U*

Main category: cs.LG

TL;DR: Co-Sparsify是一个连接感知的稀疏化框架，通过将3节点交互限制在双连通组件内，在保持2-FWL表达能力的同时消除冗余计算，实现高效且高表达力的图神经网络。


<details>
  <summary>Details</summary>
Motivation: 现有高阶图神经网络（HOGNNs）虽然具有更强的表达能力，但计算复杂度高达O(n³)，而现有的效率优化方法通常会牺牲表达能力。本文旨在解决高表达力和可扩展性之间的矛盾。

Method: 提出Co-Sparsify框架，关键洞察是3节点交互仅在双连通组件（每对节点都位于环上的最大子图）内是表达必要的。该方法将2节点消息传递限制在连通组件内，3节点交互限制在双连通组件内，无需近似或采样即可移除冗余计算。

Result: 在PPGN上，Co-Sparsify在合成子结构计数任务上达到或超过准确率，在真实世界基准测试（ZINC、QM9）上实现最先进性能。理论证明Co-Sparsified GNNs与2-FWL测试具有相同的表达能力。

Conclusion: 研究表明高表达力和可扩展性并不互斥：基于拓扑引导的稀疏化方法能够实现具有理论保证的强大且高效的GNNs。

Abstract: Higher-order Graph Neural Networks (HOGNNs) based on the 2-FWL test achieve superior expressivity by modeling 2- and 3-node interactions, but at $\mathcal{O}(n^3)$ computational cost. However, this computational burden is typically mitigated by existing efficiency methods at the cost of reduced expressivity. We propose \textbf{Co-Sparsify}, a connectivity-aware sparsification framework that eliminates \emph{provably redundant} computations while preserving full 2-FWL expressive power. Our key insight is that 3-node interactions are expressively necessary only within \emph{biconnected components} -- maximal subgraphs where every pair of nodes lies on a cycle. Outside these components, structural relationships can be fully captured via 2-node message passing or global readout, rendering higher-order modeling unnecessary. Co-Sparsify restricts 2-node message passing to connected components and 3-node interactions to biconnected ones, removing computation without approximation or sampling. We prove that Co-Sparsified GNNs are as expressive as the 2-FWL test. Empirically, on PPGN, Co-Sparsify matches or exceeds accuracy on synthetic substructure counting tasks and achieves state-of-the-art performance on real-world benchmarks (ZINC, QM9). This study demonstrates that high expressivity and scalability are not mutually exclusive: principled, topology-guided sparsification enables powerful, efficient GNNs with theoretical guarantees.

</details>


### [487] [RoS-Guard: Robust and Scalable Online Change Detection with Delay-Optimal Guarantees](https://arxiv.org/abs/2511.12846)
*Zelin Zhu,Yancheng Huang,Kai Yang*

Main category: cs.LG

TL;DR: RoS-Guard是一种针对具有不确定性的线性系统的鲁棒最优在线变化检测算法，通过神经展开技术实现GPU加速的高效并行计算。


<details>
  <summary>Details</summary>
Motivation: 现有的在线变化检测方法通常假设精确的系统知识，这在现实中不切实际，且在大规模系统中效率低下。

Method: 通过紧密松弛和重新表述OCD优化问题，采用神经展开技术实现GPU加速的并行计算。

Result: 算法提供了理论性能保证，包括预期误报率和最坏情况平均检测延迟。大量实验验证了RoS-Guard的有效性。

Conclusion: RoS-Guard在大规模系统场景中展现出显著的计算加速效果，解决了现有方法的局限性。

Abstract: Online change detection (OCD) aims to rapidly identify change points in streaming data and is critical in applications such as power system monitoring, wireless network sensing, and financial anomaly detection. Existing OCD methods typically assume precise system knowledge, which is unrealistic due to estimation errors and environmental variations. Moreover, existing OCD methods often struggle with efficiency in large-scale systems. To overcome these challenges, we propose RoS-Guard, a robust and optimal OCD algorithm tailored for linear systems with uncertainty. Through a tight relaxation and reformulation of the OCD optimization problem, RoS-Guard employs neural unrolling to enable efficient parallel computation via GPU acceleration. The algorithm provides theoretical guarantees on performance, including expected false alarm rate and worst-case average detection delay. Extensive experiments validate the effectiveness of RoS-Guard and demonstrate significant computational speedup in large-scale system scenarios.

</details>


### [488] [From Black-Box to White-Box: Control-Theoretic Neural Network Interpretability](https://arxiv.org/abs/2511.12852)
*Jihoon Moon*

Main category: cs.LG

TL;DR: 提出一个控制理论框架，将训练好的神经网络视为非线性状态空间系统，通过局部线性化、可控性和可观测性Gramian矩阵以及Hankel奇异值来分析其内部计算。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络虽然性能优异但难以进行机制性解释，需要一种系统化方法来分析其内部计算过程。

Method: 对给定输入，在相应的隐藏激活模式附近线性化网络，构建状态空间模型，通过输入状态和状态输出Jacobian矩阵定义局部可控性和可观测性Gramian矩阵，计算Hankel奇异值和相关模式。

Result: 该方法提供了神经元和路径重要性的原则性度量：可控性衡量神经元被输入扰动激发的难易程度，可观测性衡量神经元对输出的影响强度，Hankel奇异值对携带输入输出能量的内部模式进行排序。

Conclusion: 该框架将神经网络转化为局部白盒动态模型集合，识别出适合剪枝或约束的自然内部方向，有助于提高网络的可解释性。

Abstract: Deep neural networks achieve state of the art performance but remain difficult to interpret mechanistically. In this work, we propose a control theoretic framework that treats a trained neural network as a nonlinear state space system and uses local linearization, controllability and observability Gramians, and Hankel singular values to analyze its internal computation. For a given input, we linearize the network around the corresponding hidden activation pattern and construct a state space model whose state consists of hidden neuron activations. The input state and state output Jacobians define local controllability and observability Gramians, from which we compute Hankel singular values and associated modes. These quantities provide a principled notion of neuron and pathway importance: controllability measures how easily each neuron can be excited by input perturbations, observability measures how strongly each neuron influences the output, and Hankel singular values rank internal modes that carry input output energy. We illustrate the framework on simple feedforward networks, including a 1 2 2 1 SwiGLU network and a 2 3 3 2 GELU network. By comparing different operating points, we show how activation saturation reduces controllability, shrinks the dominant Hankel singular value, and shifts the dominant internal mode to a different subset of neurons. The proposed method turns a neural network into a collection of local white box dynamical models and suggests which internal directions are natural candidates for pruning or constraints to improve interpretability.

</details>


### [489] [An approach of deep reinforcement learning for maximizing the net present value of stochastic projects](https://arxiv.org/abs/2511.12865)
*Wei Xu,Fan Yang,Qinyuan Cui,Zhi Chen*

Main category: cs.LG

TL;DR: 本文研究了具有随机活动持续时间和现金流的项目优化问题，提出使用双深度Q网络（DDQN）方法最大化预期净现值，在复杂环境下优于传统策略。


<details>
  <summary>Details</summary>
Motivation: 传统项目管理方法在处理大规模或高度不确定环境时效果有限，需要更智能的优化方法来同时加速现金流入和推迟现金流出。

Method: 将问题建模为离散时间马尔可夫决策过程，采用双深度Q网络（DDQN）方法，包含双网络架构和目标网络以解决过估计问题并提高训练稳定性。

Result: DDQN在比较实验中优于传统刚性和动态策略，特别在大规模或高不确定性环境中表现更佳，具有更好的计算能力、策略可靠性和适应性。

Conclusion: DDQN不仅能在复杂项目优化中获得更高预期净现值，还提供了稳定有效的策略实施框架，双网络架构和目标网络对性能提升至关重要。

Abstract: This paper investigates a project with stochastic activity durations and cash flows under discrete scenarios, where activities must satisfy precedence constraints generating cash inflows and outflows. The objective is to maximize expected net present value (NPV) by accelerating inflows and deferring outflows. We formulate the problem as a discrete-time Markov Decision Process (MDP) and propose a Double Deep Q-Network (DDQN) approach. Comparative experiments demonstrate that DDQN outperforms traditional rigid and dynamic strategies, particularly in large-scale or highly uncertain environments, exhibiting superior computational capability, policy reliability, and adaptability. Ablation studies further reveal that the dual-network architecture mitigates overestimation of action values, while the target network substantially improves training convergence and robustness. These results indicate that DDQN not only achieves higher expected NPV in complex project optimization but also provides a reliable framework for stable and effective policy implementation.

</details>


### [490] [On the Fundamental Limits of LLMs at Scale](https://arxiv.org/abs/2511.12869)
*Muhammad Ahmed Mohsin,Muhammad Umer,Ahsan Bilal,Zeeshan Memon,Muhammad Ibtsaam Qadir,Sagnik Bhattacharya,Hassan Rizwan,Abhiram R. Gorle,Maahe Zehra Kazmi,Ayesha Mohsin,Muhammad Usman Rafique,Zihao He,Pulkit Mehta,Muhammad Ali Jamshed,John M. Cioffi*

Main category: cs.LG

TL;DR: 本文提出了一个统一的理论框架，从计算、信息和学习三个维度系统分析了LLM规模扩展的五个根本性限制：幻觉、上下文压缩、推理退化、检索脆弱性和多模态错位，并指出了规模扩展的边界和实际缓解路径。


<details>
  <summary>Details</summary>
Motivation: 现有研究对LLM规模扩展的限制多停留在经验描述层面，缺乏将这些现象与计算、信息和学习的基本理论限制相联系的严谨理论框架。本文旨在填补这一空白。

Method: 通过构建一个基于证明的统一框架，从计算可枚举性、信息论约束和几何效应三个理论维度进行形式化分析，并结合定理证明和实证证据来系统阐述LLM规模扩展的固有理论上限。

Result: 证明了LLM在可计算任务上存在不可约的错误残余，信息论约束限制了可达到的准确率，几何效应导致上下文压缩远低于名义大小，似然训练偏好模式完成而非推理，检索在多模态扩展中存在浅层对齐问题。

Conclusion: LLM规模扩展存在理论上的根本限制，本文框架明确了规模扩展在哪些方面有效、哪些方面饱和、哪些方面无法进步，并提出了有界检索、位置课程学习等实际缓解路径。

Abstract: Large Language Models (LLMs) have benefited enormously from scaling, yet these gains are bounded by five fundamental limitations: (1) hallucination, (2) context compression, (3) reasoning degradation, (4) retrieval fragility, and (5) multimodal misalignment. While existing surveys describe these phenomena empirically, they lack a rigorous theoretical synthesis connecting them to the foundational limits of computation, information, and learning. This work closes that gap by presenting a unified, proof-informed framework that formalizes the innate theoretical ceilings of LLM scaling. First, computability and uncomputability imply an irreducible residue of error: for any computably enumerable model family, diagonalization guarantees inputs on which some model must fail, and undecidable queries (e.g., halting-style tasks) induce infinite failure sets for all computable predictors. Second, information-theoretic and statistical constraints bound attainable accuracy even on decidable tasks, finite description length enforces compression error, and long-tail factual knowledge requires prohibitive sample complexity. Third, geometric and computational effects compress long contexts far below their nominal size due to positional under-training, encoding attenuation, and softmax crowding. We further show how likelihood-based training favors pattern completion over inference, how retrieval under token limits suffers from semantic drift and coupling noise, and how multimodal scaling inherits shallow cross-modal alignment. Across sections, we pair theorems and empirical evidence to outline where scaling helps, where it saturates, and where it cannot progress, providing both theoretical foundations and practical mitigation paths like bounded-oracle retrieval, positional curricula, and sparse or hierarchical attention.

</details>


### [491] [On the Information Processing of One-Dimensional Wasserstein Distances with Finite Samples](https://arxiv.org/abs/2511.12881)
*Cheongjae Jang,Jonghyun Won,Soyeon Jun,Chun Kee Chung,Keehyoung Joo,Yung-Kyun Noh*

Main category: cs.LG

TL;DR: 本文分析了一维Wasserstein距离在有限样本下捕捉密度函数点对点差异的能力，特别是在支撑集显著重叠但密度函数存在实质性差异的情况。


<details>
  <summary>Details</summary>
Motivation: Wasserstein距离在衡量两个密度函数支撑集差异方面具有优势，但当支撑集显著重叠而密度函数存在点对点差异时，尚不清楚这种传输信息能否准确识别这些差异。

Method: 利用泊松过程并分离速率因子，分析一维Wasserstein距离在有限样本下的信息处理能力，研究其如何捕捉点对点密度差异并与支撑集差异协调。

Result: 通过神经脉冲序列解码和氨基酸接触频率数据的验证，结果显示一维Wasserstein距离能够突出与速率和支撑集相关的有意义的密度差异。

Conclusion: 一维Wasserstein距离在有限样本设置下能够有效捕捉密度函数的点对点差异，并且这种信息与支撑集差异能够很好地协调。

Abstract: Leveraging the Wasserstein distance -- a summation of sample-wise transport distances in data space -- is advantageous in many applications for measuring support differences between two underlying density functions. However, when supports significantly overlap while densities exhibit substantial pointwise differences, it remains unclear whether and how this transport information can accurately identify these differences, particularly their analytic characterization in finite-sample settings. We address this issue by conducting an analysis of the information processing capabilities of the one-dimensional Wasserstein distance with finite samples. By utilizing the Poisson process and isolating the rate factor, we demonstrate the capability of capturing the pointwise density difference with Wasserstein distances and how this information harmonizes with support differences. The analyzed properties are confirmed using neural spike train decoding and amino acid contact frequency data. The results reveal that the one-dimensional Wasserstein distance highlights meaningful density differences related to both rate and support.

</details>


### [492] [Method of Manufactured Learning for Solver-free Training of Neural Operators](https://arxiv.org/abs/2511.12890)
*Arth Sojitra,Omer San*

Main category: cs.LG

TL;DR: 提出了一种名为MML（Method of Manufactured Learning）的求解器无关框架，用于训练神经算子，通过解析构造的物理一致数据集替代传统的数值求解器数据生成。


<details>
  <summary>Details</summary>
Motivation: 传统神经算子训练依赖昂贵的数值求解器或实验数据，限制了可扩展性和对不同物理系统的探索。MML旨在提供一种不依赖求解器的可扩展训练方法。

Method: 基于经典制造解方法，MML通过功能合成生成平滑候选解，并通过对控制微分算子直接应用推导对应的强制场。在推理时，将强制项设为零以恢复原始控制方程。

Result: 在热传导、对流、Burgers方程和扩散反应方程等基准测试中，MML实现了高谱精度、低残差误差，并对未见条件具有强泛化能力。

Conclusion: MML通过将数据生成重新定义为解析合成过程，为构建物理基础的神经算子提供了一条可扩展、求解器无关的路径，无需依赖昂贵的数值模拟或实验数据进行训练。

Abstract: Training neural operators to approximate mappings between infinite-dimensional function spaces often requires extensive datasets generated by either demanding experimental setups or computationally expensive numerical solvers. This dependence on solver-based data limits scalability and constrains exploration across physical systems. Here we introduce the Method of Manufactured Learning (MML), a solver-independent framework for training neural operators using analytically constructed, physics-consistent datasets. Inspired by the classical method of manufactured solutions, MML replaces numerical data generation with functional synthesis, i.e., smooth candidate solutions are sampled from controlled analytical spaces, and the corresponding forcing fields are derived by direct application of the governing differential operators. During inference, setting these forcing terms to zero restores the original governing equations, allowing the trained neural operator to emulate the true solution operator of the system. The framework is agnostic to network architecture and can be integrated with any operator learning paradigm. In this paper, we employ Fourier neural operator as a representative example. Across canonical benchmarks including heat, advection, Burgers, and diffusion-reaction equations. MML achieves high spectral accuracy, low residual errors, and strong generalization to unseen conditions. By reframing data generation as a process of analytical synthesis, MML offers a scalable, solver-agnostic pathway toward constructing physically grounded neural operators that retain fidelity to governing laws without reliance on expensive numerical simulations or costly experimental data for training.

</details>


### [493] [Functional Mean Flow in Hilbert Space](https://arxiv.org/abs/2511.12898)
*Zhiqi Li,Yuchen Sun,Greg Turk,Bo Zhu*

Main category: cs.LG

TL;DR: 提出Functional Mean Flow (FMF)作为无限维希尔伯特空间中的一步生成模型，将Mean Flow框架扩展到函数域，并引入更稳定的$x_1$-预测变体


<details>
  <summary>Details</summary>
Motivation: 将一步流匹配方法扩展到函数数据生成领域，解决时间序列、图像、PDE和3D几何等函数数据的生成问题

Method: 在无限维希尔伯特空间中定义Functional Mean Flow，提供Functional Flow Matching的理论公式和高效训练与采样的实际实现，引入$x_1$-预测变体提升稳定性

Result: 开发出实用的单步流匹配框架，适用于广泛的函数数据生成任务

Conclusion: FMF框架为函数数据生成提供了一种高效的单步解决方案，在多个应用领域具有实用性

Abstract: We present Functional Mean Flow (FMF) as a one-step generative model defined in infinite-dimensional Hilbert space. FMF extends the one-step Mean Flow framework to functional domains by providing a theoretical formulation for Functional Flow Matching and a practical implementation for efficient training and sampling. We also introduce an $x_1$-prediction variant that improves stability over the original $u$-prediction form. The resulting framework is a practical one-step Flow Matching method applicable to a wide range of functional data generation tasks such as time series, images, PDEs, and 3D geometry.

</details>


### [494] [Contrastive Entropy Bounds for Density and Conditional Density Decomposition](https://arxiv.org/abs/2511.12903)
*Bo Hu,Jose C. Principe*

Main category: cs.LG

TL;DR: 该论文从贝叶斯高斯视角研究神经网络特征的可解释性，提出使用希尔伯特空间和算子理论来分析自编码器和混合密度网络，通过最大化高斯算子的迹或核范数来优化模型性能。


<details>
  <summary>Details</summary>
Motivation: 研究神经网络特征的可解释性，从概率角度理解模型优化过程，探索如何通过希尔伯特空间方法改进自编码器和混合密度网络的训练目标。

Method: 使用希尔伯特空间和分解方法分析多输出网络，提出高斯算子的迹和核范数作为训练目标，设计编码器-混合-解码器架构，利用内积和范数定义边界和成本函数。

Result: 发现自编码器目标等价于最大化高斯算子的迹，而混合密度网络可通过最大化核范数来训练；提出的新架构能提高样本多样性并避免平凡解。

Conclusion: 希尔伯特空间方法为神经网络特征解释提供了新视角，高斯算子的迹和核范数可作为有效的训练目标，新架构有望改善模型性能。

Abstract: This paper studies the interpretability of neural network features from a Bayesian Gaussian view, where optimizing a cost is reaching a probabilistic bound; learning a model approximates a density that makes the bound tight and the cost optimal, often with a Gaussian mixture density. The two examples are Mixture Density Networks (MDNs) using the bound for the marginal and autoencoders using the conditional bound. It is a known result, not only for autoencoders, that minimizing the error between inputs and outputs maximizes the dependence between inputs and the middle.
  We use Hilbert space and decomposition to address cases where a multiple-output network produces multiple centers defining a Gaussian mixture. Our first finding is that an autoencoder's objective is equivalent to maximizing the trace of a Gaussian operator, the sum of eigenvalues under bases orthonormal w.r.t. the data and model distributions. This suggests that, when a one-to-one correspondence as needed in autoencoders is unnecessary, we can instead maximize the nuclear norm of this operator, the sum of singular values, to maximize overall rank rather than trace. Thus the trace of a Gaussian operator can be used to train autoencoders, and its nuclear norm can be used as divergence to train MDNs.
  Our second test uses inner products and norms in a Hilbert space to define bounds and costs. Such bounds often have an extra norm compared to KL-based bounds, which increases sample diversity and prevents the trivial solution where a multiple-output network produces the same constant, at the cost of requiring a sample batch to estimate and optimize. We propose an encoder-mixture-decoder architecture whose decoder is multiple-output, producing multiple centers per sample, potentially tightening the bound. Assuming the data are small-variance Gaussian mixtures, this upper bound can be tracked and analyzed quantitatively.

</details>


### [495] [LinkedIn Profile Characteristics and Professional Success Indicators](https://arxiv.org/abs/2511.12905)
*Tania-Amanda Fredrick Eneye,Ashlesha Malla,Pawan Paudel*

Main category: cs.LG

TL;DR: 本研究通过分析6.2万个LinkedIn匿名档案，使用机器学习模型预测职业成功指标（晋升、粉丝数和职业发展速度），发现晋升高度可预测，而粉丝增长更复杂


<details>
  <summary>Details</summary>
Motivation: 探索LinkedIn个人资料特征与职业成功之间的关系，为专业人士优化LinkedIn形象和职业策略提供实用指导

Method: 利用超过6.2万个匿名LinkedIn档案数据集，采用机器学习技术开发预测模型，识别影响职业成功的关键因素

Result: 研究结果表明晋升具有高度可预测性，而粉丝增长则表现出更大的复杂性

Conclusion: 该研究为专业人士优化LinkedIn存在感和职业发展策略提供了可行的见解

Abstract: This study explores the relationship between LinkedIn profile characteristics and professional success, focusing on the indicators of promotions, follower count, and career progression rate. By leveraging a dataset of over 62,000 anonymized LinkedIn profiles, we developed predictive models using machine learning techniques to identify the most influential factors driving professional success. Results indicate that while promotions are highly predictable, follower growth exhibits greater complexity. This research provides actionable insights for professionals seeking to optimize their LinkedIn presence and career strategies.

</details>


### [496] [AIF: Asynchronous Inference Framework for Cost-Effective Pre-Ranking](https://arxiv.org/abs/2511.12934)
*Zhi Kou,Xiang-Rong Sheng,Shuguang Han,Zhishan Zhao,Yueyao Cheng,Han Zhu,Jian Xu,Bo Zheng*

Main category: cs.LG

TL;DR: 提出了异步推理框架（AIF），通过解耦用户/物品侧独立计算与实时预测，将交互无关组件提前并行计算，显著提升工业推荐系统中预排序模型的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 传统预排序模型采用顺序执行框架，存在冗余计算和延迟瓶颈，限制了模型容量和系统效率。

Method: AIF框架将交互无关的用户侧计算与检索阶段并行执行，物品侧计算以近线方式处理，交互相关组件采用近似方法进行在线实时预测。

Result: 在淘宝展示广告系统中成功部署AIF，显著提升了计算效率和性能，同时未显著增加计算和延迟成本。

Conclusion: AIF通过框架与模型的协同设计，有效解决了工业推荐系统的效率瓶颈，实现了性能的显著提升。

Abstract: In industrial recommendation systems, pre-ranking models based on deep neural networks (DNNs) commonly adopt a sequential execution framework: feature fetching and model forward computation are triggered only after receiving candidates from the upstream retrieval stage. This design introduces inherent bottlenecks, including redundant computations of identical users/items and increased latency due to strictly sequential operations, which jointly constrain the model's capacity and system efficiency. To address these limitations, we propose the Asynchronous Inference Framework (AIF), a cost-effective computational architecture that decouples interaction-independent components, those operating within a single user or item, from real-time prediction. AIF reorganizes the model inference process by performing user-side computations in parallel with the retrieval stage and conducting item-side computations in a nearline manner. This means that interaction-independent components are calculated just once and completed before the real-time prediction phase of the pre-ranking stage. As a result, AIF enhances computational efficiency and reduces latency, freeing up resources to significantly improve the feature set and model architecture of interaction-independent components. Moreover, we delve into model design within the AIF framework, employing approximated methods for interaction-dependent components in online real-time predictions. By co-designing both the framework and the model, our solution achieves notable performance gains without significantly increasing computational and latency costs. This has enabled the successful deployment of AIF in the Taobao display advertising system.

</details>


### [497] [APT: Affine Prototype-Timestamp For Time Series Forecasting Under Distribution Shift](https://arxiv.org/abs/2511.12945)
*Yujie Li,Zezhi Shao,Chengqing Yu,Yisong Fu,Tao Sun,Yongjun Xu,Fei Wang*

Main category: cs.LG

TL;DR: APT是一种轻量级插件模块，通过时间戳条件原型学习动态生成仿射参数，解决时间序列预测中分布偏移问题，显著提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型依赖局部统计归一化，无法有效处理全局分布偏移；RevIN等方法在缺失值、噪声观测和无效通道仿射变换方面仍存在困难。

Method: 提出APT模块，利用时间戳条件原型学习动态生成仿射参数，调制输入和输出序列，使主干网络能够从自监督、分布感知的聚类实例中学习。

Result: 在六个基准数据集和多种主干-归一化组合上的实验表明，APT显著改善了分布偏移下的预测性能。

Conclusion: APT是一个轻量灵活、与任意预测主干和归一化策略兼容的插件模块，能有效应对时间序列预测中的分布偏移挑战。

Abstract: Time series forecasting under distribution shift remains challenging, as existing deep learning models often rely on local statistical normalization (e.g., mean and variance) that fails to capture global distribution shift. Methods like RevIN and its variants attempt to decouple distribution and pattern but still struggle with missing values, noisy observations, and invalid channel-wise affine transformation. To address these limitations, we propose Affine Prototype Timestamp (APT), a lightweight and flexible plug-in module that injects global distribution features into the normalization-forecasting pipeline. By leveraging timestamp conditioned prototype learning, APT dynamically generates affine parameters that modulate both input and output series, enabling the backbone to learn from self-supervised, distribution-aware clustered instances. APT is compatible with arbitrary forecasting backbones and normalization strategies while introducing minimal computational overhead. Extensive experiments across six benchmark datasets and multiple backbone-normalization combinations demonstrate that APT significantly improves forecasting performance under distribution shift.

</details>


### [498] [A FEDformer-Based Hybrid Framework for Anomaly Detection and Risk Forecasting in Financial Time Series](https://arxiv.org/abs/2511.12951)
*Ziling Fan,Ruijia Liang,Yiwen Hu*

Main category: cs.LG

TL;DR: 本文提出了一种基于FEDformer的混合框架，用于金融时间序列的异常检测和风险预测，通过结合频域分析和残差检测，在多个金融数据集上取得了优于传统方法的性能。


<details>
  <summary>Details</summary>
Motivation: 金融市场具有高度波动性和突发性中断风险，传统深度学习模型如LSTM和GRU难以捕捉金融数据中的长期依赖和复杂周期模式，需要更有效的异常检测和风险预测方法。

Method: 提出FEDformer-Based Hybrid Framework，集成频率增强分解变换器（FEDformer）、基于残差的异常检测器和风险预测头。FEDformer在时域和频域建模时间动态，将信号分解为趋势和季节成分；残差检测器通过分析预测误差识别异常波动；风险头利用学习到的潜在嵌入预测财务困境。

Result: 在S&P 500、纳斯达克综合指数和布伦特原油数据集（2000-2024）上的实验表明，该模型在异常检测方面比基准方法RMSE降低15.7%，F1分数提高11.5%。

Conclusion: 该模型能有效捕捉金融波动性，为市场崩盘预测和风险管理提供可靠的早期预警系统。

Abstract: Financial markets are inherently volatile and prone to sudden disruptions such as market crashes, flash collapses, and liquidity crises. Accurate anomaly detection and early risk forecasting in financial time series are therefore crucial for preventing systemic instability and supporting informed investment decisions. Traditional deep learning models, such as LSTM and GRU, often fail to capture long-term dependencies and complex periodic patterns in highly nonstationary financial data. To address this limitation, this study proposes a FEDformer-Based Hybrid Framework for Anomaly Detection and Risk Forecasting in Financial Time Series, which integrates the Frequency Enhanced Decomposed Transformer (FEDformer) with a residual-based anomaly detector and a risk forecasting head. The FEDformer module models temporal dynamics in both time and frequency domains, decomposing signals into trend and seasonal components for improved interpretability. The residual-based detector identifies abnormal fluctuations by analyzing prediction errors, while the risk head predicts potential financial distress using learned latent embeddings. Experiments conducted on the S&P 500, NASDAQ Composite, and Brent Crude Oil datasets (2000-2024) demonstrate the superiority of the proposed model over benchmark methods, achieving a 15.7 percent reduction in RMSE and an 11.5 percent improvement in F1-score for anomaly detection. These results confirm the effectiveness of the model in capturing financial volatility, enabling reliable early-warning systems for market crash prediction and risk management.

</details>


### [499] [Global Cross-Time Attention Fusion for Enhanced Solar Flare Prediction from Multivariate Time Series](https://arxiv.org/abs/2511.12955)
*Onur Vural,Shah Muhammad Hamdi,Soukaina Filali Boubrahimi*

Main category: cs.LG

TL;DR: 本文提出了一种基于Transformer的全局跨时间注意力融合（GCTAF）架构，用于解决太阳耀斑预测中时间序列数据不平衡的问题，通过引入可学习的全局令牌来增强长程时序建模能力。


<details>
  <summary>Details</summary>
Motivation: 太阳耀斑预测中的多变量时间序列分类面临数据不平衡的挑战，强烈耀斑事件相比普通耀斑极为罕见，这阻碍了模型的有效学习。传统自注意力机制仅依赖时间序列内的局部交互，难以捕捉对耀斑预测至关重要的全局显著时间模式。

Method: GCTAF架构引入一组可学习的跨注意力全局令牌，这些令牌通过跨注意力机制与输入序列交互，总结整个序列中的显著时序模式，然后融合回时序表示中。该机制作为动态注意力驱动的时序摘要器，使模型能够识别对耀斑预测关键的全局重要非连续时间点。

Result: 在基准太阳耀斑数据集上的评估表明，GCTAF能够有效检测强烈耀斑事件，并提升了预测性能。

Conclusion: 改进基于Transformer的架构为太阳耀斑预测任务提供了高潜力的替代方案，GCTAF通过增强长程时序建模能力成功解决了数据不平衡问题。

Abstract: Multivariate time series classification is increasingly investigated in space weather research as a means to predict intense solar flare events, which can cause widespread disruptions across modern technological systems. Magnetic field measurements of solar active regions are converted into structured multivariate time series, enabling predictive modeling across segmented observation windows. However, the inherently imbalanced nature of solar flare occurrences, where intense flares are rare compared to minor flare events, presents a significant barrier to effective learning. To address this challenge, we propose a novel Global Cross-Time Attention Fusion (GCTAF) architecture, a transformer-based model to enhance long-range temporal modeling. Unlike traditional self-attention mechanisms that rely solely on local interactions within time series, GCTAF injects a set of learnable cross-attentive global tokens that summarize salient temporal patterns across the entire sequence. These tokens are refined through cross-attention with the input sequence and fused back into the temporal representation, enabling the model to identify globally significant, non-contiguous time points that are critical for flare prediction. This mechanism functions as a dynamic attention-driven temporal summarizer that augments the model's capacity to capture discriminative flare-related dynamics. We evaluate our approach on the benchmark solar flare dataset and show that GCTAF effectively detects intense flares and improves predictive performance, demonstrating that refining transformer-based architectures presents a high-potential alternative for solar flare prediction tasks.

</details>


### [500] [RAGPulse: An Open-Source RAG Workload Trace to Optimize RAG Serving Systems](https://arxiv.org/abs/2511.12979)
*Zhengchao Wang,Yitao Hu,Jianing Ye,Zhuxuan Chang,Jiazheng Yu,Youpeng Deng,Keqiu Li*

Main category: cs.LG

TL;DR: RAGPulse是一个开源RAG工作负载追踪数据集，用于解决真实世界RAG系统性能优化挑战，基于大学问答系统收集的数据揭示了显著的时间局部性和热门文档访问模式。


<details>
  <summary>Details</summary>
Motivation: 现有通用LLM推理追踪无法捕捉RAG特有的多阶段流水线和工作负载特征，导致学术研究与实际部署之间存在显著性能差距。

Method: 从2024年4月起为超过40,000名师生服务的大学问答系统中收集数据，采用隐私保护的哈希数据格式，并进行深入的统计分析。

Result: 分析显示真实RAG工作负载具有显著的时间局部性和高度偏斜的热门文档访问模式，为优化策略验证提供了高保真基础。

Conclusion: RAGPulse数据集为研究人员开发和验证RAG系统优化策略（如内容感知批处理和检索缓存）提供了重要基础，有助于提升RAG服务的效率和可靠性。

Abstract: Retrieval-Augmented Generation (RAG) is a critical paradigm for building reliable, knowledge-intensive Large Language Model (LLM) applications. However, the multi-stage pipeline (retrieve, generate) and unique workload characteristics (e.g., knowledge dependency) of RAG systems pose significant challenges for serving performance optimization. Existing generic LLM inference traces fail to capture these RAG-specific dynamics, creating a significant performance gap between academic research and real-world deployment. To bridge this gap, this paper introduces RAGPulse, an open-source RAG workload trace dataset. This dataset was collected from an university-wide Q&A system serving that has served more than 40,000 students and faculties since April 2024. We detail RAGPulse's system architecture, its privacy-preserving hash-based data format, and provide an in-depth statistical analysis. Our analysis reveals that real-world RAG workloads exhibit significant temporal locality and a highly skewed hot document access pattern. RAGPulse provides a high-fidelity foundation for researchers to develop and validate novel optimization strategies for RAG systems, such as content-aware batching and retrieval caching, ultimately enhancing the efficiency and reliability of RAG services. The code is available at https://github.com/flashserve/RAGPulse.

</details>


### [501] [Angular Gradient Sign Method: Uncovering Vulnerabilities in Hyperbolic Networks](https://arxiv.org/abs/2511.12985)
*Minsoo Jo,Dongyoon Yang,Taesup Kim*

Main category: cs.LG

TL;DR: 提出了一种针对双曲网络的几何感知对抗攻击方法，通过利用双曲空间的几何特性来生成更有效的对抗样本


<details>
  <summary>Details</summary>
Motivation: 现有的对抗攻击方法（如FGSM和PGD）在欧几里得几何中设计，没有考虑双曲网络中的非欧几里得几何结构，导致攻击效率低下或几何不一致

Method: 在双曲空间的切空间中计算损失函数的梯度，将其分解为径向（深度）分量和角向（语义）分量，仅使用角向分量生成对抗扰动，专注于双曲几何中语义敏感的方向

Result: 在图像分类、跨模态检索任务和网络架构上的实验表明，该方法比传统对抗攻击具有更高的欺骗率，同时产生具有更高影响力的扰动

Conclusion: 这项工作强调了在弯曲表示空间中几何感知对抗策略的重要性，并为攻击层次化嵌入提供了理论框架

Abstract: Adversarial examples in neural networks have been extensively studied in Euclidean geometry, but recent advances in \textit{hyperbolic networks} call for a reevaluation of attack strategies in non-Euclidean geometries. Existing methods such as FGSM and PGD apply perturbations without regard to the underlying hyperbolic structure, potentially leading to inefficient or geometrically inconsistent attacks. In this work, we propose a novel adversarial attack that explicitly leverages the geometric properties of hyperbolic space. Specifically, we compute the gradient of the loss function in the tangent space of hyperbolic space, decompose it into a radial (depth) component and an angular (semantic) component, and apply perturbation derived solely from the angular direction. Our method generates adversarial examples by focusing perturbations in semantically sensitive directions encoded in angular movement within the hyperbolic geometry. Empirical results on image classification, cross-modal retrieval tasks and network architectures demonstrate that our attack achieves higher fooling rates than conventional adversarial attacks, while producing high-impact perturbations with deeper insights into vulnerabilities of hyperbolic embeddings. This work highlights the importance of geometry-aware adversarial strategies in curved representation spaces and provides a principled framework for attacking hierarchical embeddings.

</details>


### [502] [Learning Branching Policies for MILPs with Proximal Policy Optimization](https://arxiv.org/abs/2511.12986)
*Abdelouahed Ben Mhamed,Assia Kamal-Idrissi,Amal El Fallah Seghrouchni*

Main category: cs.LG

TL;DR: 提出TGPPO框架，使用PPO强化学习算法训练分支策略，旨在提高混合整数线性规划中分支定界算法在异构实例上的泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有基于模仿学习的分支策略容易过拟合专家演示，难以泛化到结构多样或未见过的实例

Method: 基于参数化状态空间表示动态捕捉搜索树演化上下文，使用PPO算法训练分支策略

Result: TGPPO在减少探索节点数和改进p-原始对偶积分方面优于现有学习方法，尤其在分布外实例上表现突出

Conclusion: 强化学习有潜力为MILP求解器开发鲁棒且适应性强的分支策略

Abstract: Branch-and-Bound (B\&B) is the dominant exact solution method for Mixed Integer Linear Programs (MILP), yet its exponential time complexity poses significant challenges for large-scale instances. The growing capabilities of machine learning have spurred efforts to improve B\&B by learning data-driven branching policies. However, most existing approaches rely on Imitation Learning (IL), which tends to overfit to expert demonstrations and struggles to generalize to structurally diverse or unseen instances. In this work, we propose Tree-Gate Proximal Policy Optimization (TGPPO), a novel framework that employs Proximal Policy Optimization (PPO), a Reinforcement Learning (RL) algorithm, to train a branching policy aimed at improving generalization across heterogeneous MILP instances. Our approach builds on a parameterized state space representation that dynamically captures the evolving context of the search tree. Empirical evaluations show that TGPPO often outperforms existing learning-based policies in terms of reducing the number of nodes explored and improving p-Primal-Dual Integrals (PDI), particularly in out-of-distribution instances. These results highlight the potential of RL to develop robust and adaptable branching strategies for MILP solvers.

</details>


### [503] [Are Graph Transformers Necessary? Efficient Long-Range Message Passing with Fractal Nodes in MPNNs](https://arxiv.org/abs/2511.13010)
*Jeongwhan Choi,Seungjun Park,Sumin Park,Sung-Bae Cho,Noseong Park*

Main category: cs.LG

TL;DR: 本文提出了一种名为"分形节点"的新概念，通过将图分割产生的子图视为特殊节点，在保持MPNN计算效率的同时增强长距离依赖建模能力。


<details>
  <summary>Details</summary>
Motivation: 解决GNN在平衡局部和全局信息时的困难，特别是MPNN在长距离交互方面的局限性，同时避免图Transformer忽略局部性和计算效率的问题。

Method: 基于现实网络中的分形结构观察，将图分割产生的子图视为分形节点，这些节点与原始节点共存，自适应地聚合子图级特征表示，强制子图内特征相似性。

Result: 实验结果表明该方法提高了MPNN的表达能力，在保持MPNN计算效率的同时，达到了与图Transformer相当或更好的性能。

Conclusion: 分形节点通过提供直接捷径连接来缓解过压缩问题，有效改善了MPNN的长距离依赖建模能力。

Abstract: Graph Neural Networks (GNNs) have emerged as powerful tools for learning on graph-structured data, but often struggle to balance local and global information. While graph Transformers aim to address this by enabling long-range interactions, they often overlook the inherent locality and efficiency of Message Passing Neural Networks (MPNNs). We propose a new concept called fractal nodes, inspired by the fractal structure observed in real-world networks. Our approach is based on the intuition that graph partitioning naturally induces fractal structure, where subgraphs often reflect the connectivity patterns of the full graph. Fractal nodes are designed to coexist with the original nodes and adaptively aggregate subgraph-level feature representations, thereby enforcing feature similarity within each subgraph. We show that fractal nodes alleviate the over-squashing problem by providing direct shortcut connections that enable long-range propagation of subgraph-level representations. Experiment results show that our method improves the expressive power of MPNNs and achieves comparable or better performance to graph Transformers while maintaining the computational efficiency of MPNN by improving the long-range dependencies of MPNN.

</details>


### [504] [The Good, The Bad, and The Hybrid: A Reward Structure Showdown in Reasoning Models Training](https://arxiv.org/abs/2511.13016)
*Subramanyam Sahoo*

Main category: cs.LG

TL;DR: 本文提出了一种统一的奖励框架，用于在数学推理任务上微调大语言模型，通过自适应混合奖励调度器平衡离散和连续信号，相比纯硬性或连续方法提高了收敛速度和训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 奖励设计在基于人类反馈的强化学习和对齐研究中至关重要，但现有方法在硬奖励、连续奖励和混合奖励结构方面的研究不够系统。

Method: 使用Qwen3-4B模型和LoRA微调技术，在GSM8K数据集上形式化并实证评估了结合正确性、困惑度、推理质量和一致性的奖励公式，引入了自适应混合奖励调度器。

Result: 混合奖励结构在收敛速度和训练稳定性方面优于纯硬性或连续方法，为通过自适应奖励建模实现对齐提供了新见解。

Conclusion: 自适应混合奖励调度器为LLM对齐研究提供了有效的奖励设计框架，平衡了探索和稳定性，在数学推理任务上表现出优越性能。

Abstract: Reward design is central to reinforcement learning from human feedback (RLHF) and alignment research. In this work, we propose a unified framework to study hard, continuous, and hybrid reward structures for fine-tuning large language models (LLMs) on mathematical reasoning tasks. Using Qwen3-4B with LoRA fine-tuning on the GSM8K dataset, we formalize and empirically evaluate reward formulations that incorporate correctness, perplexity, reasoning quality, and consistency. We introduce an adaptive hybrid reward scheduler that transitions between discrete and continuous signals, balancing exploration and stability. Our results show that hybrid reward structures improve convergence speed and training stability over purely hard or continuous approaches, offering insights for alignment via adaptive reward modeling.

</details>


### [505] [The Final-Stage Bottleneck: A Systematic Dissection of the R-Learner for Network Causal Inference](https://arxiv.org/abs/2511.13018)
*Sairam S,Sara Girdhar,Shivam Soni*

Main category: cs.LG

TL;DR: R-Learner在网络数据上存在"表示瓶颈"问题，图形无关的最终阶段模型会导致完全失败，而提出的Graph R-Learner能够成功并显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: R-Learner在处理网络数据时面临核心假设挑战，因为因果异质性通常依赖于图结构，而传统R-Learner的最终阶段模型可能无法有效捕捉这种依赖性。

Method: 通过大规模实证研究系统分析R-Learner在图数据上的表现，提出Graph R-Learner方法，并进行"枢纽-边缘权衡"分析来解释拓扑相关的"干扰瓶颈"。

Result: 统计显著证明(p < 0.001)图形无关最终阶段的R-Learner完全失败(MSE > 4.0)，而Graph R-Learner成功并显著优于非DML GNN T-Learner基线。

Conclusion: R-Learner性能主要取决于最终阶段CATE估计器的归纳偏差，提出了"最终阶段瓶颈"概念，并发布了可复现的基准测试代码。

Abstract: The R-Learner is a powerful, theoretically-grounded framework for estimating heterogeneous treatment effects, prized for its robustness to nuisance model errors. However, its application to network data, where causal heterogeneity is often graph-dependent, presents a critical challenge to its core assumption of a well-specified final-stage model. In this paper, we conduct a large-scale empirical study to systematically dissect the R-Learner framework on graphs. We provide the first rigorous evidence that the primary driver of performance is the inductive bias of the final-stage CATE estimator, an effect that dominates the choice of nuisance models. Our central finding is the quantification of a catastrophic "representation bottleneck": we prove with overwhelming statistical significance (p < 0.001) that R-Learners with a graph-blind final stage fail completely (MSE > 4.0), even when paired with powerful GNN nuisance models. Conversely, our proposed end-to-end Graph R-Learner succeeds and significantly outperforms a strong, non-DML GNN T-Learner baseline. Furthermore, we identify and provide a mechanistic explanation for a subtle, topology-dependent "nuisance bottleneck," linking it to GNN over-squashing via a targeted "Hub-Periphery Trade-off" analysis. Our findings are validated across diverse synthetic and semi-synthetic benchmarks. We release our code as a reproducible benchmark to facilitate future research on this critical "final-stage bottleneck."

</details>


### [506] [Learning Time-Scale Invariant Population-Level Neural Representations](https://arxiv.org/abs/2511.13022)
*Eshani Patel,Yisong Yue,Geeling Chau*

Main category: cs.LG

TL;DR: 本文研究了神经时间序列基础模型中时间尺度不匹配对泛化能力的影响，提出了时间尺度增强预训练（TSAP）方法来提高模型对不同时间尺度的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于预训练时间编码器的群体级表示学习方法对预处理（特别是时间尺度）的不匹配敏感，缺乏不变性，这限制了神经基础模型的通用性。

Method: 引入了时间尺度增强预训练（TSAP），通过在预训练阶段引入时间尺度变化来增强模型对不同时间尺度的鲁棒性，并在表示空间中构建不变性。

Result: TSAP方法在多个解码任务中一致地提高了对不同时间尺度的鲁棒性，有效构建了表示空间的不变性。

Conclusion: 处理预处理多样性是构建可泛化神经基础模型的关键步骤，TSAP为解决时间尺度不匹配问题提供了有效方案。

Abstract: General-purpose foundation models for neural time series can help accelerate neuroscientific discoveries and enable applications such as brain computer interfaces (BCIs). A key component in scaling these models is population-level representation learning, which leverages information across channels to capture spatial as well as temporal structure. Population-level approaches have recently shown that such representations can be both efficient to learn on top of pretrained temporal encoders and produce useful representations for decoding a variety of downstream tasks. However, these models remain sensitive to mismatches in preprocessing, particularly on time-scales, between pretraining and downstream settings. We systematically examine how time-scale mismatches affects generalization and find that existing representations lack invariance. To address this, we introduce Time-scale Augmented Pretraining (TSAP), which consistently improves robustness to different time-scales across decoding tasks and builds invariance in the representation space. These results highlight handling preprocessing diversity as a key step toward building generalizable neural foundation models.

</details>


### [507] [SLMQuant:Benchmarking Small Language Model Quantization for Practical Deployment](https://arxiv.org/abs/2511.13023)
*Jiacheng Wang,Yejun Zeng,Jinyang Guo,Yuqing Ma,Aishan Liu,Xianglong Liu*

Main category: cs.LG

TL;DR: SLMQuant是首个系统评估LLM压缩技术在SLMs上应用的基准测试，揭示了SLMs与LLMs在量化敏感性上的根本差异，提出了针对SLMs的压缩设计原则。


<details>
  <summary>Details</summary>
Motivation: SLMs作为资源高效的LLMs替代方案，在边缘设备上的部署仍面临挑战，因为模型压缩的效率差距尚未解决，且量化技术在SLMs上的适用性研究不足。

Method: 通过跨多种架构和任务的全面多轨道评估，分析最先进的量化方法在SLMs上的表现，识别影响SLM量化效果的关键因素。

Result: 研究发现直接迁移LLM优化的量化技术会导致次优结果，因为SLMs具有独特的架构特征和训练动态，量化敏感性存在根本差异。

Conclusion: SLMQuant为在边缘应用中推进高效SLM部署建立了基础框架，并为在资源受限场景中部署轻量级语言模型提供了关键见解。

Abstract: Despite the growing interest in Small Language Models (SLMs) as resource-efficient alternatives to Large Language Models (LLMs), their deployment on edge devices remains challenging due to unresolved efficiency gaps in model compression. While quantization has proven effective for LLMs, its applicability to SLMs is significantly underexplored, with critical questions about differing quantization bottlenecks and efficiency profiles. This paper introduces SLMQuant, the first systematic benchmark for evaluating LLM compression techniques when applied to SLMs. Through comprehensive multi-track evaluations across diverse architectures and tasks, we analyze how state-of-the-art quantization methods perform on SLMs. Our findings reveal fundamental disparities between SLMs and LLMs in quantization sensitivity, demonstrating that direct transfer of LLM-optimized techniques leads to suboptimal results due to SLMs' unique architectural characteristics and training dynamics. We identify key factors governing effective SLM quantization and propose actionable design principles for SLM-tailored compression. SLMQuant establishes a foundational framework for advancing efficient SLM deployment on low-end devices in edge applications, and provides critical insights for deploying lightweight language models in resource-constrained scenarios.

</details>


### [508] [One-Step Generative Policies with Q-Learning: A Reformulation of MeanFlow](https://arxiv.org/abs/2511.13035)
*Zeyuan Wang,Da Li,Yulin Chen,Ye Shi,Liang Bai,Tianyuan Yu,Yanwei Fu*

Main category: cs.LG

TL;DR: 本文提出了一种用于离线强化学习的一步生成策略，通过MeanFlow的残差重构实现从噪声到动作的直接映射，使其与Q学习兼容。该方法解决了高斯策略难以捕捉复杂多峰动作分布的问题，避免了现有流方法需要蒸馏和两阶段训练的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的一步高斯策略虽然推理速度快，但难以捕捉复杂的多峰动作分布；而现有的基于流的方法虽然表达能力更强，但在与Q学习结合时通常需要蒸馏和两阶段训练，效率较低。

Method: 通过重新表述MeanFlow，将速度场和噪声到动作的转换集成到单个策略网络中，提出了一种有效的残差重构方法，支持从噪声到动作的直接生成。

Result: 在OGBench和D4RL基准测试的73个任务上进行了广泛实验，结果表明该方法在离线和离线到在线强化学习设置中都取得了强劲性能。

Conclusion: 该方法具有三个关键优势：高效的一步噪声到动作生成、多峰动作分布的表达能力、以及通过Q学习在单阶段训练设置中实现高效稳定的策略学习。

Abstract: We introduce a one-step generative policy for offline reinforcement learning that maps noise directly to actions via a residual reformulation of MeanFlow, making it compatible with Q-learning. While one-step Gaussian policies enable fast inference, they struggle to capture complex, multimodal action distributions. Existing flow-based methods improve expressivity but typically rely on distillation and two-stage training when trained with Q-learning. To overcome these limitations, we propose to reformulate MeanFlow to enable direct noise-to-action generation by integrating the velocity field and noise-to-action transformation into a single policy network-eliminating the need for separate velocity estimation. We explore several reformulation variants and identify an effective residual formulation that supports expressive and stable policy learning. Our method offers three key advantages: 1) efficient one-step noise-to-action generation, 2) expressive modelling of multimodal action distributions, and 3) efficient and stable policy learning via Q-learning in a single-stage training setup. Extensive experiments on 73 tasks across the OGBench and D4RL benchmarks demonstrate that our method achieves strong performance in both offline and offline-to-online reinforcement learning settings. Code is available at https://github.com/HiccupRL/MeanFlowQL.

</details>


### [509] [Bi-View Embedding Fusion: A Hybrid Learning Approach for Knowledge Graph's Nodes Classification Addressing Problems with Limited Data](https://arxiv.org/abs/2511.13044)
*Rosario Napoli,Giovanni Lonia,Antonio Celesti,Massimo Villari,Maria Fazio*

Main category: cs.LG

TL;DR: Bi-View是一种新颖的混合方法，通过结合Node2Vec和GraphSAGE两种图嵌入技术来增强知识图谱中节点特征的信息内容，生成改进的图嵌入，从而提高图机器学习模型的性能。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习方法需要大量数据，在图数据稀疏或不完整时表现受限。知识图谱由于语义特性可能隐藏大量信息，现有的图机器学习方法在处理知识图谱时面临局限性。

Method: 首先使用Node2Vec计算图拓扑结构表示，然后通过基于中心性的指标丰富节点特征，作为GraphSAGE模型的输入。最后通过融合层将原始Node2Vec嵌入与GraphSAGE影响的表示相结合，形成双视角嵌入空间。

Result: 该方法能够捕获图的拓扑和语义特性，使模型能够利用数据集中存在但未明确表示的信息特征，特别在初始特征较差的情况下提升下游任务性能。

Conclusion: Bi-View方法为更准确和精确的知识图谱增强图机器学习模型奠定了基础，无需依赖额外的合成数据。

Abstract: Traditional Machine Learning (ML) methods require large amounts of data to perform well, limiting their applicability in sparse or incomplete scenarios and forcing the usage of additional synthetic data to improve the model training. To overcome this challenge, the research community is looking more and more at Graph Machine Learning (GML) as it offers a powerful alternative by using relationships within data. However, this method also faces limitations, particularly when dealing with Knowledge Graphs (KGs), which can hide huge information due to their semantic nature. This study introduces Bi-View, a novel hybrid approach that increases the informative content of node features in KGs to generate enhanced Graph Embeddings (GEs) that are used to improve GML models without relying on additional synthetic data. The proposed work combines two complementary GE techniques: Node2Vec, which captures structural patterns through unsupervised random walks, and GraphSAGE, which aggregates neighbourhood information in a supervised way. Node2Vec embeddings are first computed to represent the graph topology, and node features are then enriched with centrality-based metrics, which are used as input for the GraphSAGE model. Moreover, a fusion layer combines the original Node2Vec embeddings with the GraphSAGE-influenced representations, resulting in a dual-perspective embedding space. Such a fusion captures both topological and semantic properties of the graph, enabling the model to exploit informative features that may exist in the dataset but that are not explicitly represented. Our approach improves downstream task performance, especially in scenarios with poor initial features, giving the basis for more accurate and precise KG-enanched GML models.

</details>


### [510] [Generalization Bounds for Semi-supervised Matrix Completion with Distributional Side Information](https://arxiv.org/abs/2511.13049)
*Antoine Ledent,Mun Chong Soo,Nong Minh Hieu*

Main category: cs.LG

TL;DR: 该论文研究了一个矩阵补全问题，其中真实矩阵R和未知采样分布P都是低秩矩阵且共享共同子空间。利用大量无标签数据（M）和少量带标签数据（N），通过低秩子空间恢复理论和矩阵补全模型，证明了误差界限由两个独立项组成。


<details>
  <summary>Details</summary>
Motivation: 受推荐系统场景启发，其中无标签数据对应隐式反馈（如点击、购买），带标签数据对应显式反馈（如用户评分）。旨在研究显式和隐式反馈在推荐系统中的交互作用。

Method: 利用低秩子空间恢复理论和矩阵补全模型的经典泛化界限，假设P和R共享共同子空间。通过大量无标签数据估计P，少量带标签数据估计R，证明误差界限可分解为两个独立项。

Result: 理论分析显示误差界限为Õ(√(nd/M)) + Õ(√(dr/N))，其中d是P的秩，r是R的秩。合成实验验证了误差分解，真实数据集实验显示在显式评分稀少时优于仅依赖显式反馈的基线方法。

Conclusion: 该理论框架为研究推荐系统中显式和隐式反馈的交互提供了有效工具，实验证明在现实场景中利用隐式反馈可以提升推荐性能。

Abstract: We study a matrix completion problem where both the ground truth $R$ matrix and the unknown sampling distribution $P$ over observed entries are low-rank matrices, and \textit{share a common subspace}. We assume that a large amount $M$ of \textit{unlabeled} data drawn from the sampling distribution $P$ is available, together with a small amount $N$ of labeled data drawn from the same distribution and noisy estimates of the corresponding ground truth entries. This setting is inspired by recommender systems scenarios where the unlabeled data corresponds to `implicit feedback' (consisting in interactions such as purchase, click, etc. ) and the labeled data corresponds to the `explicit feedback', consisting of interactions where the user has given an explicit rating to the item. Leveraging powerful results from the theory of low-rank subspace recovery, together with classic generalization bounds for matrix completion models, we show error bounds consisting of a sum of two error terms scaling as $\widetilde{O}\left(\sqrt{\frac{nd}{M}}\right)$ and $\widetilde{O}\left(\sqrt{\frac{dr}{N}}\right)$ respectively, where $d$ is the rank of $P$ and $r$ is the rank of $M$. In synthetic experiments, we confirm that the true generalization error naturally splits into independent error terms corresponding to the estimations of $P$ and and the ground truth matrix $\ground$ respectively. In real-life experiments on Douban and MovieLens with most explicit ratings removed, we demonstrate that the method can outperform baselines relying only on the explicit ratings, demonstrating that our assumptions provide a valid toy theoretical setting to study the interaction between explicit and implicit feedbacks in recommender systems.

</details>


### [511] [Learning from the Undesirable: Robust Adaptation of Language Models without Forgetting](https://arxiv.org/abs/2511.13052)
*Yunhun Nam,Jaehyung Kim,Jongheon Jeong*

Main category: cs.LG

TL;DR: LfU是一种用于监督微调的正则化方法，通过在有限数据下防止语言模型过拟合，提升泛化能力并保留预训练知识。


<details>
  <summary>Details</summary>
Motivation: 解决语言模型在有限数据下进行监督微调时容易过拟合的问题，避免模型依赖虚假模式或牺牲广泛能力。

Method: 提出基于一致性正则化的LfU方法，通过将模型内部表示与经过不良更新后的表示对齐，利用表示级数据增强来提升泛化能力。

Result: 在数学任务上相比普通SFT平均提升16.8%，输出性能的标准偏差降低92.1%，显示出更好的鲁棒性和适应性。

Conclusion: LfU作为一种有效先验，在有限数据下能增强语言模型的适应性，同时保持预训练知识，具有广泛的应用价值。

Abstract: Language models (LMs) are often adapted through supervised fine-tuning (SFT) to specialize their capabilities for downstream tasks. However, in typical scenarios where the fine-tuning data is limited, e.g., compared to pre-training, SFT can lead LMs to overfit, causing them to rely on spurious patterns within the target task or to compromise other broadly useful capabilities as a side effect of narrow specialization. In this paper, we propose Learning-from-the-Undesirable (LfU), a simple yet effective regularization scheme for SFT to mitigate overfitting issues when fine-tuning LMs with limited data. Specifically, we aim to regularize the fine-tuning process to favor solutions that are resilient to "undesirable" model updates, e.g., gradient ascent steps that steer the model toward undesirable behaviors. To this end, we propose a novel form of consistency regularization that directly aligns internal representations of the model with those after an undesirable update. By leveraging representation-level data augmentation through undesirable updates, LfU effectively promotes generalization under limited data. Our experiments on diverse LM downstream tasks show that LfU serves as an effective prior that enhances adaptability while preserving pretrained knowledge. For example, our LM from LfU achieves a 16.8% average improvement on math tasks compared to vanilla SFT on the same dataset, where the latter even leads to degraded performance on those tasks. Furthermore, LfU exhibits improved robustness to prompt variations, e.g., yielding a 92.1% lower standard deviation in output performances compared to SFT, highlighting its versatile effects.

</details>


### [512] [Self-Organization of Attractor Landscapes in High-Capacity Kernel Logistic Regression Hopfield Networks](https://arxiv.org/abs/2511.13053)
*Akira Tamamori*

Main category: cs.LG

TL;DR: 本文通过几何分析揭示了核方法增强Hopfield网络存储容量的动力学机制，发现存在一个"优化山脊"区域，在该区域下网络能在高存储负载和全局核条件下最大化吸引子稳定性。


<details>
  <summary>Details</summary>
Motivation: 核学习方法能显著提高Hopfield网络的存储容量，但其背后的动力学机制尚未得到充分理解，需要深入研究网络能量景观的几何特性。

Method: 引入"峰尖锐度"指标量化吸引子局部稳定性，通过系统改变核宽度和存储负载，分析能量景观梯度分解为直接"驱动"力和间接"反馈"力的理论框架。

Result: 发现存在一个优化山脊相区，其中直接力（由高存储负载放大）与集体反馈力呈强反相关并占据主导地位，网络通过模式间相互作用作为合作反馈控制系统来塑造鲁棒能量景观。

Conclusion: 研究揭示了高容量联想记忆稳定性的新物理图景，为设计此类网络提供了原理性指导，展示了网络自适应利用模式间相互作用的复杂自组织机制。

Abstract: Kernel-based learning methods can dramatically increase the storage capacity of Hopfield networks, yet the dynamical mechanism behind this enhancement remains poorly understood. We address this gap by conducting a geometric analysis of the network's energy landscape. We introduce a novel metric, ``Pinnacle Sharpness,'' to quantify the local stability of attractors. By systematically varying the kernel width and storage load, we uncover a rich phase diagram of attractor shapes. Our central finding is the emergence of a ``ridge of optimization,'' where the network maximizes attractor stability under challenging high-load and global-kernel conditions. Through a theoretical decomposition of the landscape gradient into a direct ``driving'' force and an indirect ``feedback'' force, we reveal the origin of this phenomenon. The optimization ridge corresponds to a regime of strong anti-correlation between the two forces, where the direct force, amplified by the high storage load, dominates the opposing collective feedback force. This demonstrates a sophisticated self-organization mechanism: the network adaptively harnesses inter-pattern interactions as a cooperative feedback control system to sculpt a robust energy landscape. Our findings provide a new physical picture for the stability of high-capacity associative memories and offer principles for their design.

</details>


### [513] [Latency and Ordering Effects in Online Decisions](https://arxiv.org/abs/2511.13060)
*Duo Yi*

Main category: cs.LG

TL;DR: 该论文提出了一个针对延迟反馈和顺序敏感动态的在线决策系统的理论框架，通过Bregman散度作为损失基准，证明了超额基准损失的结构化下界，并扩展到非凸情况。


<details>
  <summary>Details</summary>
Motivation: 在线决策系统经常在延迟反馈和顺序敏感的动态环境下运行，需要量化延迟和非交换性对系统性能的影响。

Method: 使用Bregman散度作为损失基准，通过数学分析推导出超额基准损失的结构化下界，包含延迟惩罚、顺序敏感性惩罚及其几何交互项，并扩展到近端正则和弱凸设置。

Result: 得到了一个包含四个可解释项的下界公式，可以通过简单的2×2随机实验和流式诊断来估计和监控这些项。

Conclusion: 该框架将异构延迟、非交换性和实现差距效应打包成一个可解释的下界陈述，可以在实际系统中进行压力测试和调优。

Abstract: Online decision systems routinely operate under delayed feedback and order-sensitive (noncommutative) dynamics: actions affect which observations arrive, and in what sequence. Taking a Bregman divergence $D_Φ$ as the loss benchmark, we prove that the excess benchmark loss admits a structured lower bound $L \ge L_{\mathrm{ideal}} + g_1(λ) + g_2(\varepsilon_\star) + g_{12}(λ,\varepsilon_\star) - D_{\mathrm{ncx}}$, where $g_1$ and $g_2$ are calibrated penalties for latency and order-sensitivity, $g_{12}$ captures their geometric interaction, and $D_{\mathrm{ncx}}\ge 0$ is a nonconvexity/approximation penalty that vanishes under convex Legendre assumptions. We extend this inequality to prox-regular and weakly convex settings, obtaining robust guarantees beyond the convex case. We also give an operational recipe for estimating and monitoring the four terms via simple $2\times 2$ randomized experiments and streaming diagnostics (effective sample size, clipping rate, interaction heatmaps). The framework packages heterogeneous latency, noncommutativity, and implementation-gap effects into a single interpretable lower-bound statement that can be stress-tested and tuned in real-world systems.

</details>


### [514] [MACKO: Sparse Matrix-Vector Multiplication for Low Sparsity](https://arxiv.org/abs/2511.13061)
*Vladimír Macko,Vladimír Boža*

Main category: cs.LG

TL;DR: MACKO-SpMV是一种GPU优化的稀疏矩阵-向量乘法格式和内核，专门针对大型语言模型中的非结构化稀疏性（30-90%）设计，在50%稀疏度下实现1.5倍内存减少和1.2-1.5倍加速。


<details>
  <summary>Details</summary>
Motivation: 现有SpMV方法在LLM剪枝后常见的低且非结构化稀疏性（30-90%）下表现不佳，非结构化剪枝只能提供有限的内存减少和加速效果。

Method: 提出MACKO-SpMV，一种GPU优化的格式和内核协同设计，减少存储开销同时保持与GPU执行模型的兼容性，无需专用硬件单元或格式特定的预计算。

Result: 在50%稀疏度下，MACKO是首个实现显著1.5倍内存减少和1.2-1.5倍加速的方法；相比其他基线：比cuSPARSE快2.8-13.0倍，比Sputnik快1.9-2.6倍，比DASP快2.2-2.5倍。应用于Llama2-7B模型，在fp16精度下实现1.5倍内存减少和1.5倍推理加速。

Conclusion: MACKO使得50%稀疏度的非结构化剪枝在真实世界LLM工作负载中变得可行和合理。

Abstract: Sparse Matrix-Vector Multiplication (SpMV) is a fundamental operation in the inference of sparse Large Language Models (LLMs). Because existing SpMV methods perform poorly under the low and unstructured sparsity (30-90%) commonly observed in pruned LLMs, unstructured pruning provided only limited memory reduction and speedup. We propose MACKO-SpMV, a GPU-optimized format and kernel co-designed to reduce storage overhead while preserving compatibility with the GPU's execution model. This enables efficient SpMV for unstructured sparsity without specialized hardware units (e.g., tensor cores) or format-specific precomputation. Empirical results show that at sparsity 50%, MACKO is the first approach with significant 1.5x memory reduction and 1.2-1.5x speedup over dense representation. Speedups over other SpMV baselines: 2.8-13.0x over cuSPARSE, 1.9-2.6x over Sputnik, and 2.2-2.5x over DASP. Applied to Llama2-7B pruned with Wanda to sparsity 50%, it delivers 1.5x memory reduction and 1.5x faster inference at fp16 precision. Thanks to MACKO, unstructured pruning at 50% sparsity is now justified in real-world LLM workloads.

</details>


### [515] [Self-Adaptive Graph Mixture of Models](https://arxiv.org/abs/2511.13062)
*Mohit Meena,Yash Punjabi,Abhishek A,Vishal Sharma,Mahesh Chandran*

Main category: cs.LG

TL;DR: 提出了SAGMM框架，通过自适应选择和组合不同GNN架构来解决图神经网络模型选择难题，在多个基准数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前GNN性能提升趋于平缓，简单模型经过适当调优后甚至能超越复杂架构，但缺乏针对不同图任务和数据集自动选择合适模型的机制。

Method: SAGMM采用模块化框架，利用拓扑感知注意力门控机制自适应地为每个节点分配专家模型，包含剪枝机制提高效率，并探索预训练专家模型变体。

Result: 在16个基准数据集上的评估显示，SAGMM在节点分类、图分类、回归和链接预测任务中一致优于或匹配领先的GNN基线和混合方法。

Conclusion: SAGMM为现实世界的图学习提供了鲁棒且自适应的解决方案，能够有效应对不同图任务和数据集的特点。

Abstract: Graph Neural Networks (GNNs) have emerged as powerful tools for learning over graph-structured data, yet recent studies have shown that their performance gains are beginning to plateau. In many cases, well-established models such as GCN and GAT, when appropriately tuned, can match or even exceed the performance of more complex, state-of-the-art architectures. This trend highlights a key limitation in the current landscape: the difficulty of selecting the most suitable model for a given graph task or dataset. To address this, we propose Self-Adaptive Graph Mixture of Models (SAGMM), a modular and practical framework that learns to automatically select and combine the most appropriate GNN models from a diverse pool of architectures. Unlike prior mixture-of-experts approaches that rely on variations of a single base model, SAGMM leverages architectural diversity and a topology-aware attention gating mechanism to adaptively assign experts to each node based on the structure of the input graph. To improve efficiency, SAGMM includes a pruning mechanism that reduces the number of active experts during training and inference without compromising performance. We also explore a training-efficient variant in which expert models are pretrained and frozen, and only the gating and task-specific layers are trained. We evaluate SAGMM on 16 benchmark datasets covering node classification, graph classification, regression, and link prediction tasks, and demonstrate that it consistently outperforms or matches leading GNN baselines and prior mixture-based methods, offering a robust and adaptive solution for real-world graph learning.

</details>


### [516] [A Smart-Glasses for Emergency Medical Services via Multimodal Multitask Learning](https://arxiv.org/abs/2511.13078)
*Liuyi Jin,Pasan Gunawardena,Amran Haroon,Runzhi Wang,Sangwoo Lee,Radu Stoleru,Michael Middleton,Zepeng Huo,Jeeeun Kim,Jason Moats*

Main category: cs.LG

TL;DR: EMSGlass是一个基于EMSNet和EMSServe的智能眼镜系统，专为急救医疗服务设计。EMSNet是多模态多任务模型，整合文本、生命体征和场景图像，在五个关键EMS任务上优于单模态基线。EMSServe是低延迟服务框架，通过模态感知模型分割和特征缓存实现高效推理，比直接PyTorch推理快1.9-11.7倍。用户研究表明EMSGlass能提升实时态势感知和决策效率。


<details>
  <summary>Details</summary>
Motivation: 急救医疗技术人员在高压环境下需要快速做出关键决策，面临巨大的认知和操作负荷。现有系统缺乏对EMS场景的多模态整合和实时支持能力。

Method: 开发了EMSNet多模态多任务模型（整合文本、生命体征、图像）和EMSServe低延迟服务框架（包含模态感知模型分割器和特征缓存机制）。基于PyTorch构建，处理异步模态到达问题。

Result: EMSNet在五个EMS任务上优于最先进的单模态基线。EMSServe比直接PyTorch多模态推理快1.9-11.7倍。用户研究显示EMSGlass能提升实时态势感知、决策速度和操作效率。

Conclusion: EMSGlass成功将多模态智能与真实世界急救响应工作流结合，为下一代AI赋能的EMS系统提供了可行方向，通过智能眼镜界面增强了EMT的工作效能。

Abstract: Emergency Medical Technicians (EMTs) operate in high-pressure environments, making rapid, life-critical decisions under heavy cognitive and operational loads. We present EMSGlass, a smart-glasses system powered by EMSNet, the first multimodal multitask model for Emergency Medical Services (EMS), and EMSServe, a low-latency multimodal serving framework tailored to EMS scenarios. EMSNet integrates text, vital signs, and scene images to construct a unified real-time understanding of EMS incidents. Trained on real-world multimodal EMS datasets, EMSNet simultaneously supports up to five critical EMS tasks with superior accuracy compared to state-of-the-art unimodal baselines. Built on top of PyTorch, EMSServe introduces a modality-aware model splitter and a feature caching mechanism, achieving adaptive and efficient inference across heterogeneous hardware while addressing the challenge of asynchronous modality arrival in the field. By optimizing multimodal inference execution in EMS scenarios, EMSServe achieves 1.9x -- 11.7x speedup over direct PyTorch multimodal inference. A user study evaluation with six professional EMTs demonstrates that EMSGlass enhances real-time situational awareness, decision-making speed, and operational efficiency through intuitive on-glass interaction. In addition, qualitative insights from the user study provide actionable directions for extending EMSGlass toward next-generation AI-enabled EMS systems, bridging multimodal intelligence with real-world emergency response workflows.

</details>


### [517] [Real-time prediction of breast cancer sites using deformation-aware graph neural network](https://arxiv.org/abs/2511.13082)
*Kyunghyun Lee,Yong-Min Shin,Minwoo Shin,Jihun Kim,Sunghwan Lim,Won-Yong Shin,Kyungho Yoon*

Main category: cs.LG

TL;DR: 开发基于图神经网络（GNN）的模型，用于实时预测乳腺癌活检过程中的组织变形，解决传统MRI引导活检的准确性和效率问题。


<details>
  <summary>Details</summary>
Motivation: 直接MRI引导活检虽准确但耗时昂贵，间接MRI引导活检面临实时变形建模挑战，需要开发高精度实时预测方法。

Method: 结合个体特异性有限元模型和GNN，利用MRI图像结构信息处理表面位移和距离图数据，预测肿瘤区域变形。

Result: 在模型验证中，癌症节点位移误差小于0.2毫米（RMSE），空间重叠DSC达0.977，计算速度比传统FE模拟快4000倍以上。

Conclusion: 该GNN模型为乳腺癌活检提供了高精度实时肿瘤位移预测方案，有望显著提升诊断精度和效率。

Abstract: Early diagnosis of breast cancer is crucial, enabling the establishment of appropriate treatment plans and markedly enhancing patient prognosis. While direct magnetic resonance imaging-guided biopsy demonstrates promising performance in detecting cancer lesions, its practical application is limited by prolonged procedure times and high costs. To overcome these issues, an indirect MRI-guided biopsy that allows the procedure to be performed outside of the MRI room has been proposed, but it still faces challenges in creating an accurate real-time deformable breast model. In our study, we tackled this issue by developing a graph neural network (GNN)-based model capable of accurately predicting deformed breast cancer sites in real time during biopsy procedures. An individual-specific finite element (FE) model was developed by incorporating magnetic resonance (MR) image-derived structural information of the breast and tumor to simulate deformation behaviors. A GNN model was then employed, designed to process surface displacement and distance-based graph data, enabling accurate prediction of overall tissue displacement, including the deformation of the tumor region. The model was validated using phantom and real patient datasets, achieving an accuracy within 0.2 millimeters (mm) for cancer node displacement (RMSE) and a dice similarity coefficient (DSC) of 0.977 for spatial overlap with actual cancerous regions. Additionally, the model enabled real-time inference and achieved a speed-up of over 4,000 times in computational cost compared to conventional FE simulations. The proposed deformation-aware GNN model offers a promising solution for real-time tumor displacement prediction in breast biopsy, with high accuracy and real-time capability. Its integration with clinical procedures could significantly enhance the precision and efficiency of breast cancer diagnosis.

</details>


### [518] [Transformer-Based Scalable Multi-Agent Reinforcement Learning for Networked Systems with Long-Range Interactions](https://arxiv.org/abs/2511.13103)
*Vidur Sinha,Muhammed Ustaomeroglu,Guannan Qu*

Main category: cs.LG

TL;DR: STACCA是一个基于Transformer的多智能体强化学习框架，用于解决大规模网络控制中的长程依赖和网络拓扑泛化问题。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体强化学习方法存在两个主要局限：1）无法有效捕捉长程依赖关系（如级联故障、疫情传播）；2）缺乏跨网络拓扑的泛化能力，需要针对新图重新训练。

Method: STACCA采用集中式图Transformer评论家建模长程依赖并提供系统级反馈，共享图Transformer演员学习可泛化策略，并集成新颖的反事实优势估计器改进信用分配。

Result: 在疫情控制和谣言传播网络控制任务上，STACCA表现出更好的性能、网络泛化能力和可扩展性。

Conclusion: 基于Transformer的多智能体强化学习架构有潜力实现大规模网络系统的可扩展和可泛化控制。

Abstract: Multi-agent reinforcement learning (MARL) has shown promise for large-scale network control, yet existing methods face two major limitations. First, they typically rely on assumptions leading to decay properties of local agent interactions, limiting their ability to capture long-range dependencies such as cascading power failures or epidemic outbreaks. Second, most approaches lack generalizability across network topologies, requiring retraining when applied to new graphs. We introduce STACCA (Shared Transformer Actor-Critic with Counterfactual Advantage), a unified transformer-based MARL framework that addresses both challenges. STACCA employs a centralized Graph Transformer Critic to model long-range dependencies and provide system-level feedback, while its shared Graph Transformer Actor learns a generalizable policy capable of adapting across diverse network structures. Further, to improve credit assignment during training, STACCA integrates a novel counterfactual advantage estimator that is compatible with state-value critic estimates. We evaluate STACCA on epidemic containment and rumor-spreading network control tasks, demonstrating improved performance, network generalization, and scalability. These results highlight the potential of transformer-based MARL architectures to achieve scalable and generalizable control in large-scale networked systems.

</details>


### [519] [Synthetic Forgetting without Access: A Few-shot Zero-glance Framework for Machine Unlearning](https://arxiv.org/abs/2511.13116)
*Qipeng Song,Nan Yang,Ziqi Xu,Yue Li,Wei Shao,Feng Xia*

Main category: cs.LG

TL;DR: GFOES框架通过生成式反馈网络和两阶段微调，在仅使用5%原始数据的情况下实现有效的机器遗忘，解决了数据受限条件下的隐私保护问题


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘方法通常需要访问完整原始训练数据集，这在现实中往往不切实际。本文针对更现实但更具挑战性的few-shot zero-glance场景，即只有少量保留数据可用且遗忘集完全不可访问的情况

Method: 提出GFOES框架，包含生成式反馈网络(GFN)和两阶段微调程序。GFN合成最优擦除样本(OES)，诱导目标类别高损失，使模型在没有原始遗忘数据的情况下遗忘特定类别知识；两阶段微调包括激进的遗忘阶段和性能恢复阶段

Result: 在三个图像分类数据集上的实验表明，GFOES在logit和表示层面都实现了有效遗忘，同时仅使用5%原始数据就能保持强大性能

Conclusion: GFOES为数据受限条件下的隐私保护机器学习提供了实用且可扩展的解决方案

Abstract: Machine unlearning aims to eliminate the influence of specific data from trained models to ensure privacy compliance. However, most existing methods assume full access to the original training dataset, which is often impractical. We address a more realistic yet challenging setting: few-shot zero-glance, where only a small subset of the retained data is available and the forget set is entirely inaccessible. We introduce GFOES, a novel framework comprising a Generative Feedback Network (GFN) and a two-phase fine-tuning procedure. GFN synthesises Optimal Erasure Samples (OES), which induce high loss on target classes, enabling the model to forget class-specific knowledge without access to the original forget data, while preserving performance on retained classes. The two-phase fine-tuning procedure enables aggressive forgetting in the first phase, followed by utility restoration in the second. Experiments on three image classification datasets demonstrate that GFOES achieves effective forgetting at both logit and representation levels, while maintaining strong performance using only 5% of the original data. Our framework offers a practical and scalable solution for privacy-preserving machine learning under data-constrained conditions.

</details>


### [520] [Departures: Distributional Transport for Single-Cell Perturbation Prediction with Neural Schrödinger Bridges](https://arxiv.org/abs/2511.13124)
*Changxi Chi,Yufei Huang,Jun Xia,Jiangbin Zheng,Yunfan Liu,Zelin Zang,Stan Z. Li*

Main category: cs.LG

TL;DR: 该论文提出了一种基于薛定谔桥（Schrödinger Bridge）的生成模型，用于直接对齐控制组和扰动组的单细胞分布，解决了单细胞扰动数据不成对的问题。


<details>
  <summary>Details</summary>
Motivation: 单细胞扰动预测是基因功能分析和药物筛选的关键，但由于测序的破坏性，无法获得同一细胞在扰动前后的配对数据。现有生成模型缺乏显式条件或依赖先验空间进行间接分布对齐，限制了精确的扰动建模。

Method: 利用基于Minibatch-OT的配对方法近似薛定谔桥，避免双向建模和反向过程的不适定性。同时建模离散基因激活状态和连续表达分布的两个SB模型，通过联合训练捕获单细胞异质性。

Result: 在公共遗传和药物扰动数据集上的实验表明，该模型有效捕获了异质性单细胞响应，并实现了最先进的性能。

Conclusion: 提出的SB近似方法能够直接对齐分布，准确建模单细胞扰动，为基因功能分析和药物筛选提供了有效工具。

Abstract: Predicting single-cell perturbation outcomes directly advances gene function analysis and facilitates drug candidate selection, making it a key driver of both basic and translational biomedical research. However, a major bottleneck in this task is the unpaired nature of single-cell data, as the same cell cannot be observed both before and after perturbation due to the destructive nature of sequencing. Although some neural generative transport models attempt to tackle unpaired single-cell perturbation data, they either lack explicit conditioning or depend on prior spaces for indirect distribution alignment, limiting precise perturbation modeling. In this work, we approximate Schrödinger Bridge (SB), which defines stochastic dynamic mappings recovering the entropy-regularized optimal transport (OT), to directly align the distributions of control and perturbed single-cell populations across different perturbation conditions. Unlike prior SB approximations that rely on bidirectional modeling to infer optimal source-target sample coupling, we leverage Minibatch-OT based pairing to avoid such bidirectional inference and the associated ill-posedness of defining the reverse process. This pairing directly guides bridge learning, yielding a scalable approximation to the SB. We approximate two SB models, one modeling discrete gene activation states and the other continuous expression distributions. Joint training enables accurate perturbation modeling and captures single-cell heterogeneity. Experiments on public genetic and drug perturbation datasets show that our model effectively captures heterogeneous single-cell responses and achieves state-of-the-art performance.

</details>


### [521] [Soft Conflict-Resolution Decision Transformer for Offline Multi-Task Reinforcement Learning](https://arxiv.org/abs/2511.13133)
*Shudong Wang,Xinfei Wang,Chenhao Zhang,Shanchen Pang,Haiyuan Gui,Wenhao Ji,Xiaojian Liao*

Main category: cs.LG

TL;DR: SoCo-DT提出了一种基于参数重要性的软冲突解决方法，通过动态调整掩码值和自适应稀疏度策略，有效缓解多任务强化学习中的梯度冲突问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于掩码的多任务强化学习方法使用粗粒度的二元掩码，存在过度抑制关键冲突参数的问题，且采用固定稀疏度策略无法适应不同任务的冲突水平差异，限制了模型的泛化能力和学习效率。

Method: SoCo-DT利用Fisher信息动态调整掩码值，保留重要参数的同时抑制冲突参数；引入基于四分位距的动态稀疏度调整策略，构建任务特定的阈值方案；采用非对称余弦退火调度持续更新阈值。

Result: 在Meta-World基准测试中，SoCo-DT在MT50上比现有最优方法提升7.6%，在次优数据集上提升10.5%，证明了其在缓解梯度冲突和提升多任务性能方面的有效性。

Conclusion: SoCo-DT通过软冲突解决和自适应稀疏度策略，显著提高了多任务强化学习的性能，为处理梯度冲突问题提供了有效的解决方案。

Abstract: Multi-task reinforcement learning (MTRL) seeks to learn a unified policy for diverse tasks, but often suffers from gradient conflicts across tasks. Existing masking-based methods attempt to mitigate such conflicts by assigning task-specific parameter masks. However, our empirical study shows that coarse-grained binary masks have the problem of over-suppressing key conflicting parameters, hindering knowledge sharing across tasks. Moreover, different tasks exhibit varying conflict levels, yet existing methods use a one-size-fits-all fixed sparsity strategy to keep training stability and performance, which proves inadequate. These limitations hinder the model's generalization and learning efficiency.
  To address these issues, we propose SoCo-DT, a Soft Conflict-resolution method based by parameter importance. By leveraging Fisher information, mask values are dynamically adjusted to retain important parameters while suppressing conflicting ones. In addition, we introduce a dynamic sparsity adjustment strategy based on the Interquartile Range (IQR), which constructs task-specific thresholding schemes using the distribution of conflict and harmony scores during training. To enable adaptive sparsity evolution throughout training, we further incorporate an asymmetric cosine annealing schedule to continuously update the threshold. Experimental results on the Meta-World benchmark show that SoCo-DT outperforms the state-of-the-art method by 7.6% on MT50 and by 10.5% on the suboptimal dataset, demonstrating its effectiveness in mitigating gradient conflicts and improving overall multi-task performance.

</details>


### [522] [Personalized Federated Learning with Bidirectional Communication Compression via One-Bit Random Sketching](https://arxiv.org/abs/2511.13144)
*Jiacheng Cheng,Xu Zhang,Guanghui Qiu,Yifang Zhang,Yinchuan Li,Kaiyuan Feng*

Main category: cs.LG

TL;DR: pFed1BS是一个新型个性化联邦学习框架，通过一比特随机草图实现极端通信压缩，在保持个性化性能的同时显著降低通信开销


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中双向通信开销和客户端数据异构性的关键挑战，在降低通信成本的同时适应数据异构性

Method: 使用一比特随机草图进行通信压缩，引入基于符号的正则化器指导本地模型与全局共识对齐，同时保留本地数据特征，采用快速哈达玛变换提高投影效率

Result: 理论分析证明算法收敛到全局势函数的稳定邻域，数值模拟显示pFed1BS在显著降低通信成本的同时，与先进的通信高效FL算法相比具有竞争力

Conclusion: pFed1BS框架成功实现了通信成本的显著降低，同时保持了良好的个性化性能，为联邦学习中的通信效率问题提供了有效解决方案

Abstract: Federated Learning (FL) enables collaborative training across decentralized data, but faces key challenges of bidirectional communication overhead and client-side data heterogeneity. To address communication costs while embracing data heterogeneity, we propose pFed1BS, a novel personalized federated learning framework that achieves extreme communication compression through one-bit random sketching. In personalized FL, the goal shifts from training a single global model to creating tailored models for each client. In our framework, clients transmit highly compressed one-bit sketches, and the server aggregates and broadcasts a global one-bit consensus. To enable effective personalization, we introduce a sign-based regularizer that guides local models to align with the global consensus while preserving local data characteristics. To mitigate the computational burden of random sketching, we employ the Fast Hadamard Transform for efficient projection. Theoretical analysis guarantees that our algorithm converges to a stationary neighborhood of the global potential function. Numerical simulations demonstrate that pFed1BS substantially reduces communication costs while achieving competitive performance compared to advanced communication-efficient FL algorithms.

</details>


### [523] [OTARo: Once Tuning for All Precisions toward Robust On-Device LLMs](https://arxiv.org/abs/2511.13147)
*Shaoyuan Chen,Zhixuan Chen,Dawei Yang,Zhihang Yuan,Qiang Wu*

Main category: cs.LG

TL;DR: OTARo是一种新颖的量化方法，通过一次微调使设备端LLM能够灵活切换量化精度，同时保持性能鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统量化方法存在结构限制，无法支持设备端在不同精度之间的灵活切换，而实际任务对量化精度有不同需求。

Method: 提出共享指数浮点数(SEFP)量化机制，通过简单的尾数截断生成不同位宽；采用开发-探索位宽路径搜索(BPS)和低精度异步累积(LAA)策略实现位宽鲁棒性学习。

Result: 在LLaMA3.2-1B和LLaMA3-8B等主流LLM上的实验表明，OTARo在所有精度下都能实现一致强大且鲁棒的性能。

Conclusion: OTARo成功解决了传统量化方法在设备端部署中的灵活性限制问题，为实际应用场景提供了有效的解决方案。

Abstract: Large Language Models (LLMs) fine-tuning techniques not only improve the adaptability to diverse downstream tasks, but also mitigate adverse effects of model quantization. Despite this, conventional quantization suffers from its structural limitation that hinders flexibility during the fine-tuning and deployment stages. Practical on-device tasks demand different quantization precisions (i.e. different bit-widths), e.g., understanding tasks tend to exhibit higher tolerance to reduced precision compared to generation tasks. Conventional quantization, typically relying on scaling factors that are incompatible across bit-widths, fails to support the on-device switching of precisions when confronted with complex real-world scenarios. To overcome the dilemma, we propose OTARo, a novel method that enables on-device LLMs to flexibly switch quantization precisions while maintaining performance robustness through once fine-tuning. OTARo introduces Shared Exponent Floating Point (SEFP), a distinct quantization mechanism, to produce different bit-widths through simple mantissa truncations of a single model. Moreover, to achieve bit-width robustness in downstream applications, OTARo performs a learning process toward losses induced by different bit-widths. The method involves two critical strategies: (1) Exploitation-Exploration Bit-Width Path Search (BPS), which iteratively updates the search path via a designed scoring mechanism; (2) Low-Precision Asynchronous Accumulation (LAA), which performs asynchronous gradient accumulations and delayed updates under low bit-widths. Experiments on popular LLMs, e.g., LLaMA3.2-1B, LLaMA3-8B, demonstrate that OTARo achieves consistently strong and robust performance for all precisions.

</details>


### [524] [Warm-starting active-set solvers using graph neural networks](https://arxiv.org/abs/2511.13174)
*Ella J. Schmidtobreick,Daniel Arnström,Paul Häusner,Jens Sjölund*

Main category: cs.LG

TL;DR: 使用图神经网络预测二次规划问题的有效集，加速实时优化求解


<details>
  <summary>Details</summary>
Motivation: 二次规划求解器在实时控制中计算成本高，限制了时间关键场景的应用

Method: 将二次规划问题表示为二分图，使用图神经网络预测双主动集求解器DAQP中的有效集来预热求解器

Result: GNN在不同问题规模下都能减少求解器迭代次数，性能与多层感知机基线相当，且能有效泛化到未见过的维度

Conclusion: 基于结构感知的学习方法在实时应用（如模型预测控制）中具有加速优化的潜力

Abstract: Quadratic programming (QP) solvers are widely used in real-time control and optimization, but their computational cost often limits applicability in time-critical settings. We propose a learning-to-optimize approach using graph neural networks (GNNs) to predict active sets in the dual active-set solver DAQP. The method exploits the structural properties of QPs by representing them as bipartite graphs and learning to identify the optimal active set for efficiently warm-starting the solver. Across varying problem sizes, the GNN consistently reduces the number of solver iterations compared to cold-starting, while performance is comparable to a multilayer perceptron (MLP) baseline. Furthermore, a GNN trained on varying problem sizes generalizes effectively to unseen dimensions, demonstrating flexibility and scalability. These results highlight the potential of structure-aware learning to accelerate optimization in real-time applications such as model predictive control.

</details>


### [525] [Real-time distortion prediction in metallic additive manufacturing via a physics-informed neural operator approach](https://arxiv.org/abs/2511.13178)
*Mingxuan Tian,Haochen Mu,Donghong Ding,Mengjiao Li,Yuhan Ding,Jianping Zhao*

Main category: cs.LG

TL;DR: 本文提出了一种物理信息神经算子(PINO)方法，用于金属增材制造中实时预测15秒内的z和y方向变形场，解决了传统数值模拟计算成本高和机器学习模型难以提取时空特征的问题。


<details>
  <summary>Details</summary>
Motivation: 随着数字孪生和智能制造系统的发展，金属增材制造需要实时变形场预测来控制缺陷。传统数值模拟方法计算成本高、运行时间长，无法实时使用；而传统机器学习模型难以提取长期预测的时空特征，且无法解耦热力场。

Method: 提出物理信息深度算子网络-循环神经网络(PIDeepONet-RNN)，使用主干和分支网络分别处理温度历史和编码变形场，实现热力响应的解耦。通过将热传导方程作为软约束纳入模型，确保物理一致性并抑制非物理伪影。

Result: 模型在实验验证的有限元法生成的数据集上训练测试，显示出高精度、低误差累积和时间效率。z和y方向的最大绝对误差分别低至0.9733 mm和0.2049 mm。误差分布在熔池区域较高，但在沉积和关键区域梯度范数较低。

Conclusion: PINO替代模型在控制缺陷方面具有实时长期物理场预测的潜力，其基于物理定律的基函数为预测提供了稳健且可解释的基础。

Abstract: With the development of digital twins and smart manufacturing systems, there is an urgent need for real-time distortion field prediction to control defects in metal Additive Manufacturing (AM). However, numerical simulation methods suffer from high computational cost, long run-times that prevent real-time use, while conventional Machine learning (ML) models struggle to extract spatiotemporal features for long-horizon prediction and fail to decouple thermo-mechanical fields. This paper proposes a Physics-informed Neural Operator (PINO) to predict z and y-direction distortion for the future 15 s. Our method, Physics-informed Deep Operator Network-Recurrent Neural Network (PIDeepONet-RNN) employs trunk and branch network to process temperature history and encode distortion fields, respectively, enabling decoupling of thermo-mechanical responses. By incorporating the heat conduction equation as a soft constraint, the model ensures physical consistency and suppresses unphysical artifacts, thereby establishing a more physically consistent mapping between the thermal history and distortion. This is important because such a basis function, grounded in physical laws, provides a robust and interpretable foundation for predictions. The proposed models are trained and tested using datasets generated from experimentally validated Finite Element Method (FEM). Evaluation shows that the model achieves high accuracy, low error accumulation, time efficiency. The max absolute errors in the z and y-directions are as low as 0.9733 mm and 0.2049 mm, respectively. The error distribution shows high errors in the molten pool but low gradient norms in the deposited and key areas. The performance of PINO surrogate model highlights its potential for real-time long-horizon physics field prediction in controlling defects.

</details>


### [526] [Uncertainty-aware Physics-informed Neural Networks for Robust CARS-to-Raman Signal Reconstruction](https://arxiv.org/abs/2511.13185)
*Aishwarya Venkataramanan,Sai Karthikeya Vemuri,Adithya Ashok Chalain Valapil,Joachim Denzler*

Main category: cs.LG

TL;DR: 该论文评估了CARS光谱中各种不确定性量化技术，并展示了物理约束如何改善模型校准，为更可靠的CARS数据分析提供新路径。


<details>
  <summary>Details</summary>
Motivation: CARS光谱技术存在非共振背景干扰问题，现有深度学习模型缺乏不确定性量化能力，这在科学和生物医学应用中至关重要。

Method: 评估和比较了多种不确定性量化技术，并将物理约束（Kramers-Kronig关系和光滑性约束）整合到模型中。

Result: 研究表明，将物理约束整合到不确定性量化模型中能够改善模型的校准性能。

Conclusion: 物理约束的引入为构建更可靠的CARS数据分析模型提供了有前景的方向。

Abstract: Coherent anti-Stokes Raman scattering (CARS) spectroscopy is a powerful and rapid technique widely used in medicine, material science, and chemical analyses. However, its effectiveness is hindered by the presence of a non-resonant background that interferes with and distorts the true Raman signal. Deep learning methods have been employed to reconstruct the true Raman spectrum from measured CARS data using labeled datasets. A more recent development integrates the domain knowledge of Kramers-Kronig relationships and smoothness constraints in the form of physics-informed loss functions. However, these deterministic models lack the ability to quantify uncertainty, an essential feature for reliable deployment in high-stakes scientific and biomedical applications. In this work, we evaluate and compare various uncertainty quantification (UQ) techniques within the context of CARS-to-Raman signal reconstruction. Furthermore, we demonstrate that incorporating physics-informed constraints into these models improves their calibration, offering a promising path toward more trustworthy CARS data analysis.

</details>


### [527] [DiffFP: Learning Behaviors from Scratch via Diffusion-based Fictitious Play](https://arxiv.org/abs/2511.13186)
*Akash Karthikeyan,Yash Vardhan Pant*

Main category: cs.LG

TL;DR: DiffFP是一个基于虚构博弈的框架，使用扩散策略来估计对未见对手的最佳响应，在连续空间零和博弈中实现快速收敛和鲁棒性能。


<details>
  <summary>Details</summary>
Motivation: 解决连续决策空间中自博弈强化学习收敛慢、难以达到纳什均衡的问题，提高对未见对手的适应性和泛化能力。

Method: 提出DiffFP框架，通过扩散策略进行生成建模来学习自适应和多样化的策略，近似对未见对手的最佳响应。

Result: 在赛车和多粒子零和博弈等复杂多智能体环境中验证，相比基线RL策略实现3倍收敛速度和30倍成功率提升。

Conclusion: DiffFP框架能够有效收敛到ε-纳什均衡，学习到的策略对多样化对手具有鲁棒性，训练过程稳定。

Abstract: Self-play reinforcement learning has demonstrated significant success in learning complex strategic and interactive behaviors in competitive multi-agent games. However, achieving such behaviors in continuous decision spaces remains challenging. Ensuring adaptability and generalization in self-play settings is critical for achieving competitive performance in dynamic multi-agent environments. These challenges often cause methods to converge slowly or fail to converge at all to a Nash equilibrium, making agents vulnerable to strategic exploitation by unseen opponents. To address these challenges, we propose DiffFP, a fictitious play (FP) framework that estimates the best response to unseen opponents while learning a robust and multimodal behavioral policy. Specifically, we approximate the best response using a diffusion policy that leverages generative modeling to learn adaptive and diverse strategies. Through empirical evaluation, we demonstrate that the proposed FP framework converges towards $ε$-Nash equilibria in continuous- space zero-sum games. We validate our method on complex multi-agent environments, including racing and multi-particle zero-sum games. Simulation results show that the learned policies are robust against diverse opponents and outperform baseline reinforcement learning policies. Our approach achieves up to 3$\times$ faster convergence and 30$\times$ higher success rates on average against RL-based baselines, demonstrating its robustness to opponent strategies and stability across training iterations

</details>


### [528] [ParaDySe: A Parallel-Strategy Switching Framework for Dynamic Sequence Lengths in Transformer](https://arxiv.org/abs/2511.13198)
*Zhixin Ou,Peng Liang,Jianchen Han,Baihui Liu,Linbo Qiao*

Main category: cs.LG

TL;DR: ParaDySe是一个用于动态序列的自适应并行策略切换框架，通过实时选择最优并行策略来解决LLM训练中短序列通信并行化取消和长序列内存溢出问题。


<details>
  <summary>Details</summary>
Motivation: 当前LLM训练框架对动态长度序列采用预定义的静态并行策略，导致短序列出现通信并行化取消问题，长序列出现内存溢出问题。

Method: ParaDySe实现统一张量布局的并行策略模块化函数库，构建序列感知的内存和时间成本模型，通过启发式算法为动态序列选择最优层间策略。

Result: 在序列长度达624K的数据集上，ParaDySe成功解决了LLM训练中的内存溢出和通信并行化取消瓶颈。

Conclusion: ParaDySe通过将长序列优化与现有框架系统集成，实现了LLM训练中动态序列的最优并行策略自适应切换。

Abstract: Dynamic sequences with varying lengths have been widely used in the training of Transformer-based large language models (LLMs). However, current training frameworks adopt a pre-defined static parallel strategy for these sequences, causing neither communication-parallelization cancellation on short sequences nor out-of-memory on long sequences. To mitigate these issues, we propose ParaDySe, a novel adaptive Parallel strategy switching framework for Dynamic Sequences. ParaDySe enables on-the-fly optimal strategy adoption according to the immediate input sequence. It first implements the modular function libraries for parallel strategies with unified tensor layout specifications, and then builds sequence-aware memory and time cost models with hybrid methods. Guided by cost models, ParaDySe selects optimal layer-wise strategies for dynamic sequences via an efficient heuristic algorithm. By integrating these techniques together, ParaDySe achieves seamless hot-switching of optimal strategies through its well-designed function libraries. We compare ParaDySe with baselines on representative LLMs under datasets with sequence lengths up to 624K. Experimental results indicate that ParaDySe addresses OOM and CPC bottlenecks in LLM training by systematically integrating long-sequence optimizations with existing frameworks.

</details>


### [529] [TokenSqueeze: Performance-Preserving Compression for Reasoning LLMs](https://arxiv.org/abs/2511.13223)
*Yuxiang Zhang,Zhengxu Yu,Weihang Pan,Zhongming Jin,Qiang Fu,Deng Cai,Binbin Lin,Jieping Ye*

Main category: cs.LG

TL;DR: TokenSqueeze是一种新的Long2Short方法，通过自适应选择推理深度和语言精炼来压缩推理路径，在保持准确性的同时显著减少token使用量。


<details>
  <summary>Details</summary>
Motivation: 现有推理LLMs生成长链式思维导致token使用量增加，造成高延迟和内存消耗。现有Long2Short方法往往牺牲准确性，需要一种能在保持性能的同时降低token成本的方法。

Method: 1. 自适应选择推理深度：根据问题复杂度匹配推理深度；2. 分布对齐的语言精炼：优化语言表达而不改变推理路径，保持逻辑完整性。

Result: 在MATH500基准测试中，DeepSeek-R1-Distill-Qwen-7B实现了50%的平均token减少，同时保持准确性。

Conclusion: TokenSqueeze仅使用模型自生成数据，无需人工标注，能够在多样化应用中实现高效高保真推理。

Abstract: Emerging reasoning LLMs such as OpenAI-o1 and DeepSeek-R1 have achieved strong performance on complex reasoning tasks by generating long chain-of-thought (CoT) traces. However, these long CoTs result in increased token usage, leading to higher inference latency and memory consumption. As a result, balancing accuracy and reasoning efficiency has become essential for deploying reasoning LLMs in practical applications. Existing long-to-short (Long2Short) methods aim to reduce inference length but often sacrifice accuracy, revealing a need for an approach that maintains performance while lowering token costs. To address this efficiency-accuracy tradeoff, we propose TokenSqueeze, a novel Long2Short method that condenses reasoning paths while preserving performance and relying exclusively on self-generated data. First, to prevent performance degradation caused by excessive compression of reasoning depth, we propose to select self-generated samples whose reasoning depth is adaptively matched to the complexity of the problem. To further optimize the linguistic expression without altering the underlying reasoning paths, we introduce a distribution-aligned linguistic refinement method that enhances the clarity and conciseness of the reasoning path while preserving its logical integrity. Comprehensive experimental results demonstrate the effectiveness of TokenSqueeze in reducing token usage while maintaining accuracy. Notably, DeepSeek-R1-Distill-Qwen-7B fine-tuned using our proposed method achieved a 50\% average token reduction while preserving accuracy on the MATH500 benchmark. TokenSqueeze exclusively utilizes the model's self-generated data, enabling efficient and high-fidelity reasoning without relying on manually curated short-answer datasets across diverse applications. Our code is available at https://github.com/zhangyx1122/TokenSqueeze.

</details>


### [530] [Laplace Learning in Wasserstein Space](https://arxiv.org/abs/2511.13229)
*Mary Chriselda Antony Oliver,Michael Roberts,Carola-Bibiane Schönlieb,Matthew Thorpe*

Main category: cs.LG

TL;DR: 本文研究了基于图的半监督学习方法在Wasserstein空间中的扩展，将传统的有限维欧几里得空间算法推广到无限维设置，并验证了在高维数据分类中的一致性表现。


<details>
  <summary>Details</summary>
Motivation: 流形假说认为高维数据通常存在于低维子空间中，本文基于此假说研究图基半监督学习方法，特别是将Laplace Learning扩展到Wasserstein空间，以处理无限维场景下的分类问题。

Method: 通过证明离散图p-Dirichlet能量到其连续对应物的变分收敛性，并刻画Wasserstein空间子流形上的Laplace-Beltrami算子，实现了图基半监督学习算法从有限维欧几里得空间到无限维Wasserstein空间的扩展。

Result: 在基准数据集上的数值实验验证了所提出理论框架的有效性，展示了在高维设置下分类性能的一致性。

Conclusion: 本文成功地将图基半监督学习算法扩展到Wasserstein空间，为处理无限维数据分类问题提供了新的理论框架和实用方法，在高维数据场景下表现出良好的分类一致性。

Abstract: The manifold hypothesis posits that high-dimensional data typically resides on low-dimensional sub spaces. In this paper, we assume manifold hypothesis to investigate graph-based semi-supervised learning
  methods. In particular, we examine Laplace Learning in the Wasserstein space, extending the classical
  notion of graph-based semi-supervised learning algorithms from finite-dimensional Euclidean spaces to
  an infinite-dimensional setting. To achieve this, we prove variational convergence of a discrete graph p- Dirichlet energy to its continuum counterpart. In addition, we characterize the Laplace-Beltrami operator
  on asubmanifold of the Wasserstein space. Finally, we validate the proposed theoretical framework through
  numerical experiments conducted on benchmark datasets, demonstrating the consistency of our classification performance in high-dimensional settings.

</details>


### [531] [MorphBoost: Self-Organizing Universal Gradient Boosting with Adaptive Tree Morphing](https://arxiv.org/abs/2511.13234)
*Boris Kriuk*

Main category: cs.LG

TL;DR: MorphBoost是一个新型梯度提升框架，通过自组织树结构动态调整分裂行为，在10个数据集上平均性能优于XGBoost 0.84%，展现出卓越的适应性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统梯度提升算法使用静态树结构，分裂标准在训练过程中保持不变，无法适应不同学习阶段中梯度分布的变化和问题特定特征，限制了算法的适应能力。

Method: 引入自组织树结构，实现自适应分裂函数，基于累积梯度统计和迭代依赖的学习压力动态演化。关键创新包括：形态分裂准则、自动问题指纹识别、向量化树预测、交互感知特征重要性和快速模式优化。

Result: 在10个多样化数据集上的综合基准测试显示，MorphBoost实现最先进性能，平均优于XGBoost 0.84%，获得4/10数据集胜利（40%胜率）和6/30前三名成绩（20%），同时保持最低方差（σ=0.0948）和最高最小准确率。

Conclusion: MorphBoost通过动态树结构适应机制，在复杂问题上表现出显著改进，证明了自适应梯度提升框架在性能和鲁棒性方面的优势。

Abstract: Traditional gradient boosting algorithms employ static tree structures with fixed splitting criteria that remain unchanged throughout training, limiting their ability to adapt to evolving gradient distributions and problem-specific characteristics across different learning stages. This work introduces MorphBoost, a new gradient boosting framework featuring self-organizing tree structures that dynamically morph their splitting behavior during training. The algorithm implements adaptive split functions that evolve based on accumulated gradient statistics and iteration-dependent learning pressures, enabling automatic adjustment to problem complexity. Key innovations include: (1) morphing split criterion combining gradient-based scores with information-theoretic metrics weighted by training progress; (2) automatic problem fingerprinting for intelligent parameter configuration across binary/multiclass/regression tasks; (3) vectorized tree prediction achieving significant computational speedups; (4) interaction-aware feature importance detecting multiplicative relationships; and (5) fast-mode optimization balancing speed and accuracy. Comprehensive benchmarking across 10 diverse datasets against competitive models (XGBoost, LightGBM, GradientBoosting, HistGradientBoosting, ensemble methods) demonstrates that MorphBoost achieves state-of-the-art performance, outperforming XGBoost by 0.84% on average. MorphBoost secured the overall winner position with 4/10 dataset wins (40% win rate) and 6/30 top-3 finishes (20%), while maintaining the lowest variance (σ=0.0948) and highest minimum accuracy across all models, revealing superior consistency and robustness. Performance analysis across difficulty levels shows competitive results on easy datasets while achieving notable improvements on advanced problems due to higher adaptation levels.

</details>


### [532] [Counterfactual Explainable AI (XAI) Method for Deep Learning-Based Multivariate Time Series Classification](https://arxiv.org/abs/2511.13237)
*Alan G. Paredes Cetina,Kaouther Benguessoum,Raoni Lourenço,Sylvain Kubler*

Main category: cs.LG

TL;DR: CONFETTI是一种新颖的多目标反事实解释方法，用于多变量时间序列分析，通过平衡预测置信度、邻近性和稀疏性来提供可操作的见解。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习方法在多变量时间序列分类和回归中缺乏透明度，现有解释方法往往无法完整传达决策空间，反事实解释方法通常只能优先考虑准确性、邻近性或稀疏性中的单一目标。

Method: CONFETTI通过识别关键MTS子序列、定位反事实目标，并优化修改时间序列，同时平衡预测置信度、邻近性和稀疏性三个目标。

Result: 在UEA档案的七个MTS数据集上评估显示，CONFETTI在优化目标上始终优于最先进方法，在六个文献指标上表现更好，置信度提高≥10%，稀疏性改善≥40%。

Conclusion: CONFETTI提供了一种有效的多目标反事实解释方法，显著提高了多变量时间序列分析的透明度和决策支持能力。

Abstract: Recent advances in deep learning have improved multivariate time series (MTS) classification and regression by capturing complex patterns, but their lack of transparency hinders decision-making. Explainable AI (XAI) methods offer partial insights, yet often fall short of conveying the full decision space. Counterfactual Explanations (CE) provide a promising alternative, but current approaches typically prioritize either accuracy, proximity or sparsity -- rarely all -- limiting their practical value. To address this, we propose CONFETTI, a novel multi-objective CE method for MTS. CONFETTI identifies key MTS subsequences, locates a counterfactual target, and optimally modifies the time series to balance prediction confidence, proximity and sparsity. This method provides actionable insights with minimal changes, improving interpretability, and decision support. CONFETTI is evaluated on seven MTS datasets from the UEA archive, demonstrating its effectiveness in various domains. CONFETTI consistently outperforms state-of-the-art CE methods in its optimization objectives, and in six other metrics from the literature, achieving $\geq10\%$ higher confidence while improving sparsity in $\geq40\%$.

</details>


### [533] [Computational Measurement of Political Positions: A Review of Text-Based Ideal Point Estimation Algorithms](https://arxiv.org/abs/2511.13238)
*Patrick Parschan,Charlott Jakob*

Main category: cs.LG

TL;DR: 本文首次系统综述了无监督和半监督计算文本理想点估计算法(CT-IPE)，这些方法旨在从文本数据中推断潜在政治立场。通过对25种算法的分析，提出了基于文本方差生成、捕获和聚合的概念框架，识别出四种方法家族，并为应用研究者提供实用指导。


<details>
  <summary>Details</summary>
Motivation: CT-IPE算法在政治学、计算社会科学等领域广泛应用，但二十年的发展导致了方法碎片化，缺乏系统比较和应用指导。

Method: 通过系统文献综述识别25种CT-IPE算法，进行内容分析，并建立概念框架比较算法在文本方差处理上的差异。

Result: 识别出四种主要方法家族：词频模型、主题模型、词嵌入和基于大语言模型的方法，分析了各自假设、可解释性、可扩展性和局限性。

Conclusion: 提供了二十年算法发展的结构化综述，为应用研究者提供实用指导，强调算法选择中的权衡和系统基准测试的重要性。

Abstract: This article presents the first systematic review of unsupervised and semi-supervised computational text-based ideal point estimation (CT-IPE) algorithms, methods designed to infer latent political positions from textual data. These algorithms are widely used in political science, communication, computational social science, and computer science to estimate ideological preferences from parliamentary speeches, party manifestos, and social media. Over the past two decades, their development has closely followed broader NLP trends -- beginning with word-frequency models and most recently turning to large language models (LLMs). While this trajectory has greatly expanded the methodological toolkit, it has also produced a fragmented field that lacks systematic comparison and clear guidance for applied use. To address this gap, we identified 25 CT-IPE algorithms through a systematic literature review and conducted a manual content analysis of their modeling assumptions and development contexts. To compare them meaningfully, we introduce a conceptual framework that distinguishes how algorithms generate, capture, and aggregate textual variance. On this basis, we identify four methodological families -- word-frequency, topic modeling, word embedding, and LLM-based approaches -- and critically assess their assumptions, interpretability, scalability, and limitations. Our review offers three contributions. First, it provides a structured synthesis of two decades of algorithm development, clarifying how diverse methods relate to one another. Second, it translates these insights into practical guidance for applied researchers, highlighting trade-offs in transparency, technical requirements, and validation strategies that shape algorithm choice. Third, it emphasizes that differences in estimation outcomes across algorithms are themselves informative, underscoring the need for systematic benchmarking.

</details>


### [534] [Incoherent Beliefs & Inconsistent Actions in Large Language Models](https://arxiv.org/abs/2511.13240)
*Arka Pal,Teo Kitanovski,Arthur Liang,Akilesh Potti,Micah Goldblum*

Main category: cs.LG

TL;DR: 大语言模型在动态环境中的信念更新和行为一致性存在显著问题，即使在高准确率模型中也表现出不一致性。


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型在真实动态环境中的表现，因为现实任务与静态数据集存在差异，需要模型能够进行序列化交互和信念更新。

Method: 通过测试LLMs的信念更新一致性（直接获取的后验与正确先验更新之间的差异）和行为与信念的一致性（如投注市场中的决策）。

Result: LLMs在信念更新上平均差异达30%，行为与信念不一致，甚至在强模型和高准确率任务中也存在这些问题。

Conclusion: 预测LLMs在复杂现实环境中的行为存在困难，现有静态评估无法完全反映模型在动态任务中的表现。

Abstract: Real-world tasks and environments exhibit differences from the static datasets that large language models (LLMs) are typically evaluated on. Such tasks can involve sequential interaction, requiring coherent updating of beliefs in light of new evidence, and making appropriate decisions based on those beliefs. Predicting how LLMs will perform in such dynamic environments is important, but can be tricky to determine from measurements in static settings. In this work, we examine two critical components of LLM performance: the ability of LLMs to coherently update their beliefs, and the extent to which the actions they take are consistent with those beliefs. First, we find that LLMs are largely inconsistent in how they update their beliefs; models can exhibit up to a 30% average difference between the directly elicited posterior, and the correct update of their prior. Second, we find that LLMs also often take actions which are inconsistent with the beliefs they hold. On a betting market, for example, LLMs often do not even bet in the same direction as their internally held beliefs over the underlying outcomes. We also find they have moderate self-inconsistency in how they respond to challenges by users to given answers. Finally, we show that the above properties hold even for strong models that obtain high accuracy or that are well-calibrated on the tasks at hand. Our results highlight the difficulties of predicting LLM behavior in complex real-world settings.

</details>


### [535] [Uncovering and Mitigating Transient Blindness in Multimodal Model Editing](https://arxiv.org/abs/2511.13243)
*Xiaoqi Han,Ru Li,Ran Yi,Hongye Tan,Zhuomin Liang,Víctor Gutiérrez-Basulto,Jeff Z. Pan*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Multimodal Model Editing (MMED) aims to correct erroneous knowledge in multimodal models. Existing evaluation methods, adapted from textual model editing, overstate success by relying on low-similarity or random inputs, obscure overfitting. We propose a comprehensive locality evaluation framework, covering three key dimensions: random-image locality, no-image locality, and consistent-image locality, operationalized through seven distinct data types, enabling a detailed and structured analysis of multimodal edits. We introduce De-VQA, a dynamic evaluation for visual question answering, uncovering a phenomenon we term transient blindness, overfitting to edit-similar text while ignoring visuals. Token analysis shows edits disproportionately affect textual tokens. We propose locality-aware adversarial losses to balance cross-modal representations. Empirical results demonstrate that our approach consistently outperforms existing baselines, reducing transient blindness and improving locality by 17% on average.

</details>


### [536] [Seek and You Shall Fold](https://arxiv.org/abs/2511.13244)
*Nadav Bojan Sellam,Meital Bojan,Paul Schanda,Alex Bronstein*

Main category: cs.LG

TL;DR: 提出了一个非可微分指导的蛋白质生成模型框架，能够将实验数据整合到蛋白质结构生成中，突破了传统梯度方法的限制。


<details>
  <summary>Details</summary>
Motivation: 准确的蛋白质结构对于理解生物功能至关重要，但将实验数据整合到蛋白质生成模型中仍然是一个重大挑战。大多数实验可观测值的预测器是不可微分的，这使得它们与基于梯度的条件采样不兼容，特别是在核磁共振中，化学位移等丰富数据难以直接整合到生成建模中。

Method: 引入了一个非可微分指导的蛋白质生成模型框架，将基于连续扩散的生成器与任何黑盒目标通过定制的遗传算法耦合在一起。

Result: 该框架在三种模态上证明了有效性：成对距离约束、核欧沃豪斯效应约束，以及首次实现了化学位移指导的结构生成。这些结果确立了化学位移指导结构生成的可行性，揭示了当前预测器的关键弱点，并展示了一种整合多样化实验信号的通用策略。

Conclusion: 这项工作指向了超越可微分性限制的自动化、数据条件化的蛋白质建模方向。

Abstract: Accurate protein structures are essential for understanding biological function, yet incorporating experimental data into protein generative models remains a major challenge. Most predictors of experimental observables are non-differentiable, making them incompatible with gradient-based conditional sampling. This is especially limiting in nuclear magnetic resonance, where rich data such as chemical shifts are hard to directly integrate into generative modeling. We introduce a framework for non-differentiable guidance of protein generative models, coupling a continuous diffusion-based generator with any black-box objective via a tailored genetic algorithm. We demonstrate its effectiveness across three modalities: pairwise distance constraints, nuclear Overhauser effect restraints, and for the first time chemical shifts. These results establish chemical shift guided structure generation as feasible, expose key weaknesses in current predictors, and showcase a general strategy for incorporating diverse experimental signals. Our work points toward automated, data-conditioned protein modeling beyond the limits of differentiability.

</details>


### [537] [Edge-aware baselines for ogbn-proteins in PyTorch Geometric: species-wise normalization, post-hoc calibration, and cost-accuracy trade-offs](https://arxiv.org/abs/2511.13250)
*Aleksandar Stanković,Dejan Lisica*

Main category: cs.LG

TL;DR: 本文提出了ogbn-proteins数据集的可复现边缘感知基线，研究了边缘特征聚合和消息传递中的关键系统选择，发现基于sum的GraphSAGE表现最佳，并展示了标准化后处理技术对性能的提升。


<details>
  <summary>Details</summary>
Motivation: 为ogbn-proteins数据集建立可复现的基准方法，系统研究边缘特征如何影响图神经网络性能，特别是边缘证据聚合和消息传递机制的选择。

Method: 使用PyTorch Geometric实现GraphSAGE模型，比较sum、mean、max三种边缘特征聚合方式，评估LayerNorm、BatchNorm和Conditional LayerNorm三种归一化方法，并应用后处理技术如温度缩放和标签相关平滑。

Result: sum聚合方式优于mean和max；BatchNorm获得最佳AUC，Conditional LayerNorm在AUC边界上匹配但具有更好的阈值F1；后处理技术显著提升micro-F1和校准误差，AUC变化可忽略。

Conclusion: 本文为ogbn-proteins提供了可靠的基线方法，证明了边缘特征聚合策略和后处理技术的重要性，并发布了完整的可复现实验代码和标准化工件。

Abstract: We present reproducible, edge-aware baselines for ogbn-proteins in PyTorch Geometric (PyG). We study two system choices that dominate practice: (i) how 8-dimensional edge evidence is aggregated into node inputs, and (ii) how edges are used inside message passing. Our strongest baseline is GraphSAGE with sum-based edge-to-node features. We compare LayerNorm (LN), BatchNorm (BN), and a species-aware Conditional LayerNorm (CLN), and report compute cost (time, VRAM, parameters) together with accuracy (ROC-AUC) and decision quality. In our primary experimental setup (hidden size 512, 3 layers, 3 seeds), sum consistently beats mean and max; BN attains the best AUC, while CLN matches the AUC frontier with better thresholded F1. Finally, post-hoc per-label temperature scaling plus per-label thresholds substantially improves micro-F1 and expected calibration error (ECE) with negligible AUC change, and light label-correlation smoothing yields small additional gains. We release standardized artifacts and scripts used for all of the runs presented in the paper.

</details>


### [538] [KForge: Program Synthesis for Diverse AI Hardware Accelerators](https://arxiv.org/abs/2511.13274)
*Taras Sereda,Tom St. John,Burak Bartan,Natalie Serrino,Sachin Katti,Zain Asgar*

Main category: cs.LG

TL;DR: KForge是一个平台无关的GPU内核优化框架，使用两个协作的LLM代理：生成代理通过编译和正确性反馈迭代优化程序，性能分析代理通过分析性能数据指导优化。该架构只需单次示例即可针对新平台。


<details>
  <summary>Details</summary>
Motivation: GPU内核对机器学习性能至关重要，但难以在不同加速器上进行优化。现有方法缺乏跨平台适应性，需要为每个硬件平台单独开发优化方案。

Method: 基于两个协作LLM代理的架构：生成代理负责程序生成和迭代优化，性能分析代理解释性能数据提供优化建议。支持从程序化API到GUI工具的各种性能数据，通过功能性和优化传递实现协作优化。

Result: 证明了生成代理能有效利用跨平台知识转移，一个架构的参考实现可显著提高不同硬件目标的生成质量。在NVIDIA CUDA和Apple Metal等不同并行计算平台上验证了方法的有效性。

Conclusion: KForge提供了一个平台无关的GPU内核优化解决方案，通过协作代理架构实现了跨硬件平台的程序合成能力，只需单次示例即可适应新平台。

Abstract: GPU kernels are critical for ML performance but difficult to optimize across diverse accelerators. We present KForge, a platform-agnostic framework built on two collaborative LLM-based agents: a generation agent that produces and iteratively refines programs through compilation and correctness feedback, and a performance analysis agent that interprets profiling data to guide optimization. This agent-based architecture requires only a single-shot example to target new platforms.
  We make three key contributions: (1) introducing an iterative refinement system where the generation agent and performance analysis agent collaborate through functional and optimization passes, interpreting diverse profiling data (from programmatic APIs to GUI-based tools) to generate actionable recommendations that guide program synthesis for arbitrary accelerators; (2) demonstrating that the generation agent effectively leverages cross-platform knowledge transfer, where a reference implementation from one architecture substantially improves generation quality for different hardware targets; and (3) validating the platform-agnostic nature of our approach by demonstrating effective program synthesis across fundamentally different parallel computing platforms: NVIDIA CUDA and Apple Metal.

</details>


### [539] [Explainable RL Policies by Distilling to Locally-Specialized Linear Policies with Voronoi State Partitioning](https://arxiv.org/abs/2511.13322)
*Senne Deproost,Dennis Steckelmacher,Ann Nowé*

Main category: cs.LG

TL;DR: 该论文提出了一种基于Voronoi分区的新方法，将状态空间划分为多个区域，在每个区域内使用简化的线性模型来替代不透明的深度强化学习控制器，从而提高模型的可解释性。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习控制器虽然性能优异，但缺乏透明度，难以满足监管要求和建立信任。需要将学习到的行为转化为人类可读的模型，但单一简化模型在动态环境中表现不佳，需要在灵活性和复杂性之间找到平衡。

Method: 使用Voronoi分区方法将状态空间划分为多个区域，在每个区域内使用线性模型来近似原始控制器的行为。这种方法可以创建局部专门化的简化模型。

Result: 在网格世界环境和经典控制任务上的实验表明，所提出的方法产生的策略具有可解释性，并且蒸馏后的性能与原始黑盒策略相当甚至略有提升。

Conclusion: 基于Voronoi分区的局部专门化线性模型蒸馏方法能够有效解决深度强化学习控制器的可解释性问题，同时保持或提升性能。

Abstract: Deep Reinforcement Learning is one of the state-of-the-art methods for producing near-optimal system controllers. However, deep RL algorithms train a deep neural network, that lacks transparency, which poses challenges when the controller has to meet regulations, or foster trust. To alleviate this, one could transfer the learned behaviour into a model that is human-readable by design using knowledge distilla- tion. Often this is done with a single model which mimics the original model on average but could struggle in more dynamic situations. A key challenge is that this simpler model should have the right balance be- tween flexibility and complexity or right balance between balance bias and accuracy. We propose a new model-agnostic method to divide the state space into regions where a simplified, human-understandable model can operate in. In this paper, we use Voronoi partitioning to find regions where linear models can achieve similar performance to the original con- troller. We evaluate our approach on a gridworld environment and a classic control task. We observe that our proposed distillation to locally- specialized linear models produces policies that are explainable and show that the distillation matches or even slightly outperforms the black-box policy they are distilled from.

</details>


### [540] [Tab-PET: Graph-Based Positional Encodings for Tabular Transformers](https://arxiv.org/abs/2511.13338)
*Yunze Leng,Rohan Ghosh,Mehul Motani*

Main category: cs.LG

TL;DR: 本文提出Tab-PET框架，通过图结构估计位置编码来提升表格数据transformer模型的泛化性能，发现位置编码能降低特征有效秩从而简化任务。


<details>
  <summary>Details</summary>
Motivation: 表格数据缺乏结构线索，传统transformer模型无法利用位置编码，导致泛化能力受限。本文旨在探索位置编码在表格数据中的潜在价值。

Method: 提出Tab-PET框架，基于图结构估计位置编码，探索关联性和因果性两种图构建范式，并将位置编码融入transformer嵌入层。

Result: 在50个分类和回归数据集上验证，图衍生的位置编码显著提升3T模型性能，其中关联性图表现更稳定且提升更明显。

Conclusion: 位置编码在表格transformer中具有意外的重要作用，能通过降低特征有效秩来改善泛化性能，为表格数据建模提供了新思路。

Abstract: Supervised learning with tabular data presents unique challenges, including low data sizes, the absence of structural cues, and heterogeneous features spanning both categorical and continuous domains. Unlike vision and language tasks, where models can exploit inductive biases in the data, tabular data lacks inherent positional structure, hindering the effectiveness of self-attention mechanisms. While recent transformer-based models like TabTransformer, SAINT, and FT-Transformer (which we refer to as 3T) have shown promise on tabular data, they typically operate without leveraging structural cues such as positional encodings (PEs), as no prior structural information is usually available. In this work, we find both theoretically and empirically that structural cues, specifically PEs can be a useful tool to improve generalization performance for tabular transformers. We find that PEs impart the ability to reduce the effective rank (a form of intrinsic dimensionality) of the features, effectively simplifying the task by reducing the dimensionality of the problem, yielding improved generalization. To that end, we propose Tab-PET (PEs for Tabular Transformers), a graph-based framework for estimating and inculcating PEs into embeddings. Inspired by approaches that derive PEs from graph topology, we explore two paradigms for graph estimation: association-based and causality-based. We empirically demonstrate that graph-derived PEs significantly improve performance across 50 classification and regression datasets for 3T. Notably, association-based graphs consistently yield more stable and pronounced gains compared to causality-driven ones. Our work highlights an unexpected role of PEs in tabular transformers, revealing how they can be harnessed to improve generalization.

</details>


### [541] [Statistically Accurate and Robust Generative Prediction of Rock Discontinuities with A Tabular Foundation Model](https://arxiv.org/abs/2511.13339)
*Han Meng,Gang Mei,Hong Tian,Nengxiong Xu,Jianbing Peng*

Main category: cs.LG

TL;DR: 提出了一种基于表格基础模型的简单而稳健的方法，用于统计准确的岩石不连续性生成预测，解决了现有方法在数据稀疏条件下无法捕捉复杂分布模式或缺乏鲁棒性的问题。


<details>
  <summary>Details</summary>
Motivation: 岩石不连续性对岩体力学行为和稳定性至关重要，但其内部分布难以观测，通常需要通过表面暴露的不连续性进行生成预测。现有方法在表面观测数据稀疏的情况下，要么无法捕捉复杂的分布模式，要么缺乏鲁棒性。

Method: 利用专门为小数据设计的表格基础模型，充分发挥其在样本学习方面的强大能力，从而在有限的测量不连续性数据中有效捕捉潜在的复杂分布模式。

Result: 在十个具有不同规模和分布模式的数据集上进行的对比实验表明，该方法在准确性和鲁棒性方面优于传统统计模型和深度生成方法。

Conclusion: 这项工作推进了岩体结构的定量表征，支持更安全、更可靠的数据驱动岩土工程设计。

Abstract: Rock discontinuities critically govern the mechanical behavior and stability of rock masses. Their internal distributions remain largely unobservable and are typically inferred from surface-exposed discontinuities using generative prediction approaches. However, surface-exposed observations are inherently sparse, and existing generative prediction approaches either fail to capture the underlying complex distribution patterns or lack robustness under data-sparse conditions. Here, we proposed a simple yet robust approach for statistically accurate generative prediction of rock discontinuities by utilizing a tabular foundation model. By leveraging the powerful sample learning capability of the foundation model specifically designed for small data, our approach can effectively capture the underlying complex distribution patterns within limited measured discontinuities. Comparative experiments on ten datasets with diverse scales and distribution patterns of discontinuities demonstrate superior accuracy and robustness over conventional statistical models and deep generative approaches. This work advances quantitative characterization of rock mass structures, supporting safer and more reliable data-driven geotechnical design.

</details>


### [542] [Dual-LoRA and Quality-Enhanced Pseudo Replay for Multimodal Continual Food Learning](https://arxiv.org/abs/2511.13351)
*Xinlan Wu,Bin Zhu,Feng Han,Pengkun Jiao,Jingjing Chen*

Main category: cs.LG

TL;DR: 提出了一种新颖的多模态食物学习持续学习框架，通过双LoRA架构和质量增强伪回放解决现有大型多模态模型在食物分析中的灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 食物分析对健康任务（如个性化营养和慢性病预防）日益重要，但现有大型多模态模型在学习新任务时会出现灾难性遗忘，需要昂贵的从头训练。

Method: 采用双LoRA架构：专门LoRA学习任务特定知识（与先前任务子空间正交约束），协作LoRA通过伪回放整合跨任务共享知识。质量增强伪回放策略利用自一致性和语义相似性减少生成样本中的幻觉。

Result: 在综合Uni-Food数据集上的实验显示，该方法在减轻遗忘方面表现出优越性能，是首个针对复杂食物任务的有效持续学习方法。

Conclusion: 该框架成功解决了多模态食物学习中的灾难性遗忘问题，为食物分析领域的持续学习提供了有效解决方案。

Abstract: Food analysis has become increasingly critical for health-related tasks such as personalized nutrition and chronic disease prevention. However, existing large multimodal models (LMMs) in food analysis suffer from catastrophic forgetting when learning new tasks, requiring costly retraining from scratch. To address this, we propose a novel continual learning framework for multimodal food learning, integrating a Dual-LoRA architecture with Quality-Enhanced Pseudo Replay. We introduce two complementary low-rank adapters for each task: a specialized LoRA that learns task-specific knowledge with orthogonal constraints to previous tasks' subspaces, and a cooperative LoRA that consolidates shared knowledge across tasks via pseudo replay. To improve the reliability of replay data, our Quality-Enhanced Pseudo Replay strategy leverages self-consistency and semantic similarity to reduce hallucinations in generated samples. Experiments on the comprehensive Uni-Food dataset show superior performance in mitigating forgetting, representing the first effective continual learning approach for complex food tasks.

</details>


### [543] [A Novel Hierarchical Integration Method for Efficient Model Merging in Medical LLMs](https://arxiv.org/abs/2511.13373)
*Prakrit Timilsina,Anuj Nepal,Rajan Kadel,Robin Doss*

Main category: cs.LG

TL;DR: 本文系统评估了六种参数空间合并技术应用于医疗LLMs，提出了一种新的分层方法，发现对于架构兼容的模型，简单平均方法在计算效率和性能上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 解决分布式医疗中LLMs面临的挑战：跨机构整合专业知识同时保护隐私、减少计算开销、防止模型更新时的灾难性遗忘。

Method: 提出了分层方法，结合选择性最优传输对齐注意力层和余弦相似度加权插值，评估了Task Arithmetic、Linear Averaging、DARE-TIES、DELLA、Breadcrumbs和分层方法在五个医疗基准上的表现。

Result: 架构兼容的模型从简单平均方法中获益显著，Task Arithmetic在MedQA上达到45.80%准确率，优于复杂的剪枝方法。

Conclusion: 对于架构兼容的模型，简单平均提供了鲁棒且计算效率高的知识整合基线，为可扩展医疗AI系统提供了实用路径。

Abstract: Large Language Models (LLMs) face significant challenges in distributed healthcare, including consolidating specialized domain knowledge across institutions while maintaining privacy, reducing computational overhead, and preventing catastrophic forgetting during model updates.This paper presents a systematic evaluation of six parameter-space merging techniques applied to two architecturally compatible medical LLMs derived from the Mistral-7B base model. We introduce a novel hierarchical method that combines selective Optimal Transport (OT) alignment for attention layers with cosine similarity-weighted interpolation, designed to address permutation variance while minimizing computational overhead for edge deployment scenarios. Our study evaluates Task Arithmetic, Linear Averaging, DARE-TIES, DELLA, Breadcrumbs, and our Hierarchical approach across five medical benchmarks. Results demonstrate that architecturally compatible models benefit significantly from simple averaging methods, with Task Arithmetic achieving 45.80% accuracy on MedQA, outperforming complex pruning-based approaches. These findings offer critical insights for the deployment of distributed medical AI in resource-constrained IoT environments, where computational efficiency and model compatibility are paramount. Our work establishes that for architecturally compatible models, simple averaging provides a robust and computationally efficient baseline for knowledge consolidation, offering a pragmatic path forward for scalable medical AI systems.

</details>


### [544] [Finding Kissing Numbers with Game-theoretic Reinforcement Learning](https://arxiv.org/abs/2511.13391)
*Chengdong Ma,Théo Tao Zhaowei,Pengyu Li,Minghao Liu,Haojun Chen,Zihao Mao,Yuan Cheng,Yuan Qi,Yaodong Yang*

Main category: cs.LG

TL;DR: 本文提出PackingStar系统，将Kissing Number Problem建模为双玩家矩阵完成游戏，使用博弈论强化学习在25-31维空间中超越人类已知记录，发现了6000多个新结构。


<details>
  <summary>Details</summary>
Motivation: 自牛顿1694年研究Kissing Number Problem以来，确定中心球周围非重叠球的最大数量一直是基础挑战。高维几何的不规则性和指数级组合复杂性限制了现有方法的可扩展性。

Method: 将问题建模为双玩家矩阵完成游戏：一个玩家填充矩阵条目（表示球心向量对余弦），另一个玩家修正次优条目，共同最大化矩阵大小（对应kissing number）。使用博弈论强化学习系统PackingStar进行高效探索。

Result: 在25-31维空间中超越所有人类已知记录，25维配置几何对应Leech格点并暗示可能最优性；在13维实现1971年以来首次突破；在14维等维度发现6000多个新结构。

Conclusion: 证明了AI探索高维空间超越人类直觉的能力，为Kissing Number Problem和更广泛几何问题开辟了新途径。

Abstract: Since Isaac Newton first studied the Kissing Number Problem in 1694, determining the maximal number of non-overlapping spheres around a central sphere has remained a fundamental challenge. This problem represents the local analogue of Hilbert's 18th problem on sphere packing, bridging geometry, number theory, and information theory. Although significant progress has been made through lattices and codes, the irregularities of high-dimensional geometry and exponentially growing combinatorial complexity beyond 8 dimensions, which exceeds the complexity of Go game, limit the scalability of existing methods. Here we model this problem as a two-player matrix completion game and train the game-theoretic reinforcement learning system, PackingStar, to efficiently explore high-dimensional spaces. The matrix entries represent pairwise cosines of sphere center vectors; one player fills entries while another corrects suboptimal ones, jointly maximizing the matrix size, corresponding to the kissing number. This cooperative dynamics substantially improves sample quality, making the extremely large spaces tractable. PackingStar reproduces previous configurations and surpasses all human-known records from dimensions 25 to 31, with the configuration in 25 dimensions geometrically corresponding to the Leech lattice and suggesting possible optimality. It achieves the first breakthrough beyond rational structures from 1971 in 13 dimensions and discovers over 6000 new structures in 14 and other dimensions. These results demonstrate AI's power to explore high-dimensional spaces beyond human intuition and open new pathways for the Kissing Number Problem and broader geometry problems.

</details>


### [545] [Fast and Robust Simulation-Based Inference With Optimization Monte Carlo](https://arxiv.org/abs/2511.13394)
*Vasilis Gkolemis,Christos Diou,Michael Gutmann*

Main category: cs.LG

TL;DR: 提出了一种针对可微分模拟器的贝叶斯参数推断新方法，通过将随机模拟转化为确定性优化问题，大幅减少运行时间并保持高精度


<details>
  <summary>Details</summary>
Motivation: 复杂随机模拟器的贝叶斯参数推断面临似然函数难以处理的问题，现有方法在高维参数空间或部分无信息输出时计算成本高昂

Method: 基于优化蒙特卡洛框架，将随机模拟重新表述为确定性优化问题，应用梯度方法高效导航至高密度后验区域，避免在低概率区域的浪费性模拟，并利用JAX实现关键组件的向量化

Result: 在高维参数空间、无信息输出、多观测和多重后验等广泛实验中，该方法在精度上匹配甚至超越最先进方法，同时运行时间大幅减少

Conclusion: 该方法为可微分模拟器提供了一种高效准确的贝叶斯参数推断解决方案，显著提升了计算效率

Abstract: Bayesian parameter inference for complex stochastic simulators is challenging due to intractable likelihood functions. Existing simulation-based inference methods often require large number of simulations and become costly to use in high-dimensional parameter spaces or in problems with partially uninformative outputs. We propose a new method for differentiable simulators that delivers accurate posterior inference with substantially reduced runtimes. Building on the Optimization Monte Carlo framework, our approach reformulates stochastic simulation as deterministic optimization problems. Gradient-based methods are then applied to efficiently navigate toward high-density posterior regions and avoid wasteful simulations in low-probability areas. A JAX-based implementation further enhances the performance through vectorization of key method components. Extensive experiments, including high-dimensional parameter spaces, uninformative outputs, multiple observations and multimodal posteriors show that our method consistently matches, and often exceeds, the accuracy of state-of-the-art approaches, while reducing the runtime by a substantial margin.

</details>


### [546] [PAST: A Primary-Auxiliary Spatio-Temporal Network for Traffic Time Series Imputation](https://arxiv.org/abs/2511.13414)
*Hanwen Hu,Zimo Wen,Shiyou Qian,Jian Co*

Main category: cs.LG

TL;DR: PAST网络通过主-辅助模式分离方法，在27种缺失数据条件下显著提升交通时间序列插补精度，RMSE和MAE分别提升26.2%和31.6%。


<details>
  <summary>Details</summary>
Motivation: 现有模型难以适应随机缺失位置，且无法学习长期大规模依赖关系。论文将模式分为主模式（数据点内部关系）和辅助模式（外部因素影响）以应对多样化缺失数据挑战。

Method: 提出主-辅助时空网络(PAST)，包含图集成模块(GIM)通过动态图和间隔感知dropout捕捉主模式，交叉门控模块(CGM)通过双向门控提取辅助模式，两模块通过共享隐藏向量交互。

Result: 在三个数据集上的实验表明，PAST在27种缺失数据条件下优于7个先进基线方法，RMSE和MAE分别提升达26.2%和31.6%。

Conclusion: PAST通过主-辅助模式分类和模块化设计，有效解决了多样化缺失数据条件下的交通时间序列插补问题，显著提升了插补精度。

Abstract: Traffic time series imputation is crucial for the safety and reliability of intelligent transportation systems, while diverse types of missing data, including random, fiber, and block missing make the imputation task challenging. Existing models often focus on disentangling and separately modeling spatial and temporal patterns based on relationships between data points. However, these approaches struggle to adapt to the random missing positions, and fail to learn long-term and large-scale dependencies, which are essential in extensive missing conditions. In this paper, patterns are categorized into two types to handle various missing data conditions: primary patterns, which originate from internal relationships between data points, and auxiliary patterns, influenced by external factors like timestamps and node attributes. Accordingly, we propose the Primary-Auxiliary Spatio-Temporal network (PAST). It comprises a graph-integrated module (GIM) and a cross-gated module (CGM). GIM captures primary patterns via dynamic graphs with interval-aware dropout and multi-order convolutions, and CGM extracts auxiliary patterns through bidirectional gating on embedded external features. The two modules interact via shared hidden vectors and are trained under an ensemble self-supervised framework. Experiments on three datasets under 27 missing data conditions demonstrate that the imputation accuracy of PAST outperforms seven state-of-the-art baselines by up to 26.2% in RMSE and 31.6% in MAE.

</details>


### [547] [MMWSTM-ADRAN+: A Novel Hybrid Deep Learning Architecture for Enhanced Climate Time Series Forecasting and Extreme Event Prediction](https://arxiv.org/abs/2511.13419)
*Shaheen Mohammed Saleh Ahmed,Hakan Hakan Guneyli*

Main category: cs.LG

TL;DR: MMWSTM-ADRAN+是一个双流深度学习架构，结合了天气状态转换模型和异常注意力机制，用于预测极端气温事件。


<details>
  <summary>Details</summary>
Motivation: 精确的短期极端气温预测是气候风险管理中的基本挑战，现有方法难以有效捕捉极端天气信号。

Method: 采用双流架构：MMWSTM流使用BiLSTM和可学习马尔可夫状态转移矩阵捕捉天气状态转换；ADRAN流使用BiGRU、多头自注意力和异常放大层增强对异常信号的敏感性；通过注意力融合门自适应整合两流输出。

Result: 模型通过自定义的ExtremeWeatherLoss函数和时间序列数据增强技术进行优化，有效提升了极端气温预测的准确性。

Conclusion: 该模型为极端天气预测提供了有效的深度学习解决方案，特别适用于气候风险管理应用。

Abstract: Accurate short-range prediction of extreme air temperature events remains a fundamental challenge in operational climate-risk management. We present Multi-Modal Weather State Transition Model with Anomaly-Driven Recurrent Attention Network Plus (MMWSTM-ADRAN+), a dual-stream deep learning architecture that couples a regime-aware dynamics model with an anomaly-focused attention mechanism to forecast daily maximum temperature and its extremes. The first stream, MMWSTM, combines bidirectional Long Short-Term Memory (BiLSTM) units with a learnable Markov state transition matrix to capture synoptic-scale weather regime changes. The second stream, ADRAN, integrates bidirectional Gated Recurrent Units (BiGRUs), multi-head self-attention, and a novel anomaly amplification layer to enhance sensitivity to low-probability signals. A lightweight attentive fusion gate adaptively determines the contribution of each stream to the final prediction. Model optimization employs a custom ExtremeWeatherLoss function that up-weights errors on the upper 5% and lower 5% of the temperature distribution, and a time-series data augmentation suite (jittering, scaling, time/magnitude warping) that effectively quadruples the training data

</details>


### [548] [Larger Datasets Can Be Repeated More: A Theoretical Analysis of Multi-Epoch Scaling in Linear Regression](https://arxiv.org/abs/2511.13421)
*Tingkai Yan,Haodong Wen,Binghui Li,Kairong Luo,Wenguang Chen,Kaifeng Lyu*

Main category: cs.LG

TL;DR: 本文通过理论分析探讨了在有限数据和多次训练轮次下，数据缩放定律的变化形式，特别关注了线性回归中多次训练轮次对数据有效复用率的影响。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的数据缩放定律在单次训练和大规模语料下已被广泛研究，但在有限数据和多次训练轮次下的形式仍不清楚。

Method: 使用线性回归模型，在强凸性或Zipf分布数据下，分析随机梯度下降中数据有效复用率E(K,N)的缩放行为。

Result: 发现当K较小时E(K,N)≈K，每个新训练轮次带来线性增益；随着K增加，E(K,N)会趋于平台值，该值随N增长而增大。

Conclusion: 数据有效复用率的最大K值取决于数据规模和分布，未来研究数据复用的缩放定律时需要明确建模这两个因素。

Abstract: While data scaling laws of large language models (LLMs) have been widely examined in the one-pass regime with massive corpora, their form under limited data and repeated epochs remains largely unexplored. This paper presents a theoretical analysis of how a common workaround, training for multiple epochs on the same dataset, reshapes the data scaling laws in linear regression. Concretely, we ask: to match the performance of training on a dataset of size $N$ for $K$ epochs, how much larger must a dataset be if the model is trained for only one pass? We quantify this using the \textit{effective reuse rate} of the data, $E(K, N)$, which we define as the multiplicative factor by which the dataset must grow under one-pass training to achieve the same test loss as $K$-epoch training. Our analysis precisely characterizes the scaling behavior of $E(K, N)$ for SGD in linear regression under either strong convexity or Zipf-distributed data: (1) When $K$ is small, we prove that $E(K, N) \approx K$, indicating that every new epoch yields a linear gain; (2) As $K$ increases, $E(K, N)$ plateaus at a problem-dependent value that grows with $N$ ($Θ(\log N)$ for the strongly-convex case), implying that larger datasets can be repeated more times before the marginal benefit vanishes. These theoretical findings point out a neglected factor in a recent empirical study (Muennighoff et al. (2023)), which claimed that training LLMs for up to $4$ epochs results in negligible loss differences compared to using fresh data at each step, \textit{i.e.}, $E(K, N) \approx K$ for $K \le 4$ in our notation. Supported by further empirical validation with LLMs, our results reveal that the maximum $K$ value for which $E(K, N) \approx K$ in fact depends on the data size and distribution, and underscore the need to explicitly model both factors in future studies of scaling laws with data reuse.

</details>


### [549] [Discovering Operational Patterns Using Image-Based Convolutional Clustering and Composite Evaluation: A Case Study in Foundry Melting Processes](https://arxiv.org/abs/2511.13444)
*Zhipeng Ma,Bo Nørregaard Jørgensen,Zheng Grace Ma*

Main category: cs.LG

TL;DR: 提出了一种基于图像卷积聚类的无监督方法，用于从单变量时间序列数据中发现工业操作模式，通过灰度矩阵转换和复合评估指标提高聚类性能。


<details>
  <summary>Details</summary>
Motivation: 工业过程监控依赖传感器时间序列数据，但缺乏标签、高变异性和操作噪声使得传统方法难以提取有意义的模式，现有聚类技术无法有效处理动态、非结构化的工业序列。

Method: 将原始时间序列通过重叠滑动窗口转换为灰度矩阵表示，使用深度卷积自编码器进行特征提取，集成软硬聚类输出并通过两阶段策略优化选择，采用新开发的复合评分S_eva进行客观评估。

Result: 应用于北欧铸造厂的3900多个熔炉操作，识别出7个可解释的操作模式，在能耗、热动力学和生产时长方面显示出显著差异，相比基准方法具有更优的整体性能和鲁棒性。

Conclusion: 该框架解决了无监督时间序列分析中的关键挑战，如序列不规则性、模式重叠和度量不一致性，为工业系统的数据驱动诊断和能源优化提供了通用解决方案。

Abstract: Industrial process monitoring increasingly relies on sensor-generated time-series data, yet the lack of labels, high variability, and operational noise make it difficult to extract meaningful patterns using conventional methods. Existing clustering techniques either rely on fixed distance metrics or deep models designed for static data, limiting their ability to handle dynamic, unstructured industrial sequences. Addressing this gap, this paper proposes a novel framework for unsupervised discovery of operational modes in univariate time-series data using image-based convolutional clustering with composite internal evaluation. The proposed framework improves upon existing approaches in three ways: (1) raw time-series sequences are transformed into grayscale matrix representations via overlapping sliding windows, allowing effective feature extraction using a deep convolutional autoencoder; (2) the framework integrates both soft and hard clustering outputs and refines the selection through a two-stage strategy; and (3) clustering performance is objectively evaluated by a newly developed composite score, S_eva, which combines normalized Silhouette, Calinski-Harabasz, and Davies-Bouldin indices. Applied to over 3900 furnace melting operations from a Nordic foundry, the method identifies seven explainable operational patterns, revealing significant differences in energy consumption, thermal dynamics, and production duration. Compared to classical and deep clustering baselines, the proposed approach achieves superior overall performance, greater robustness, and domain-aligned explainability. The framework addresses key challenges in unsupervised time-series analysis, such as sequence irregularity, overlapping modes, and metric inconsistency, and provides a generalizable solution for data-driven diagnostics and energy optimization in industrial systems.

</details>


### [550] [Hardware optimization on Android for inference of AI models](https://arxiv.org/abs/2511.13453)
*Iulius Gherasim,Carlos García Sánchez*

Main category: cs.LG

TL;DR: 本文研究了Android系统上AI模型的最优执行配置，重点关注YOLO目标检测和ResNet图像分类任务，通过评估不同量化方案和设备加速器（GPU/NPU）来平衡精度损失和推理速度。


<details>
  <summary>Details</summary>
Motivation: 移动计算中AI模型的广泛集成需要最小延迟和高响应性，但面临实时约束和异构硬件架构的挑战，因此需要找到最优执行配置。

Method: 研究Android系统上AI模型的执行配置，评估不同量化方案（如模型量化）和设备加速器（GPU、NPU）的使用，针对YOLO目标检测和ResNet图像分类任务进行实证分析。

Result: 通过实验确定了在精度损失最小化和推理速度最大化之间达到最佳平衡的配置组合。

Conclusion: 找到了AI模型在Android系统上的最优执行配置，实现了精度和速度的良好权衡。

Abstract: The pervasive integration of Artificial Intelligence models into contemporary mobile computing is notable across numerous use cases, from virtual assistants to advanced image processing. Optimizing the mobile user experience involves minimal latency and high responsiveness from deployed AI models with challenges from execution strategies that fully leverage real time constraints to the exploitation of heterogeneous hardware architecture. In this paper, we research and propose the optimal execution configurations for AI models on an Android system, focusing on two critical tasks: object detection (YOLO family) and image classification (ResNet). These configurations evaluate various model quantization schemes and the utilization of on device accelerators, specifically the GPU and NPU. Our core objective is to empirically determine the combination that achieves the best trade-off between minimal accuracy degradation and maximal inference speed-up.

</details>


### [551] [Artificial Intelligence-Enabled Spirometry for Early Detection of Right Heart Failure](https://arxiv.org/abs/2511.13457)
*Bin Liu,Qinghao Zhao,Yuxi Zhou,Zhejun Sun,Kaijie Lei,Deyun Zhang,Shijia Geng,Shenda Hong*

Main category: cs.LG

TL;DR: 提出一种自监督表示学习方法，利用肺活量图时间序列和人口统计学数据早期检测右心衰竭，在UK Biobank数据集上取得0.7501的AUROC，在高风险临床亚组中表现更佳。


<details>
  <summary>Details</summary>
Motivation: 右心衰竭（RHF）与高发病率和死亡率相关，肺部疾病常导致右心室负荷增加引发RHF。从肺心病患者中早期筛查出可能发展为RHF的患者具有重要意义。

Method: 两阶段方法：第一阶段使用变分自编码器（VAE）编码器从数据增强的无标签数据中学习肺活量图时间序列的稳健低维表示；第二阶段将该表示与人口统计学信息融合，输入CatBoost分类器进行RHF预测。

Result: 在UK Biobank的26,617名个体中AUROC为0.7501；在慢性肾病（CKD）患者测试集（74人）中AUROC为0.8194；在瓣膜性心脏病（VHD）患者测试集（64人）中AUROC为0.8413。

Conclusion: 该自监督表示学习方法结合肺活量图时间序列和人口统计学数据，在临床实践中显示出早期检测RHF的潜力，特别是在高风险人群中表现优异。

Abstract: Right heart failure (RHF) is a disease characterized by abnormalities in the structure or function of the right ventricle (RV), which is associated with high morbidity and mortality. Lung disease often causes increased right ventricular load, leading to RHF. Therefore, it is very important to screen out patients with cor pulmonale who develop RHF from people with underlying lung diseases. In this work, we propose a self-supervised representation learning method to early detecting RHF from patients with cor pulmonale, which uses spirogram time series to predict patients with RHF at an early stage. The proposed model is divided into two stages. The first stage is the self-supervised representation learning-based spirogram embedding (SLSE) network training process, where the encoder of the Variational autoencoder (VAE-encoder) learns a robust low-dimensional representation of the spirogram time series from the data-augmented unlabeled data. Second, this low-dimensional representation is fused with demographic information and fed into a CatBoost classifier for the downstream RHF prediction task. Trained and tested on a carefully selected subset of 26,617 individuals from the UK Biobank, our model achieved an AUROC of 0.7501 in detecting RHF, demonstrating strong population-level distinction ability. We further evaluated the model on high-risk clinical subgroups, achieving AUROC values of 0.8194 on a test set of 74 patients with chronic kidney disease (CKD) and 0.8413 on a set of 64 patients with valvular heart disease (VHD). These results highlight the model's potential utility in predicting RHF among clinically elevated-risk populations. In conclusion, this study presents a self-supervised representation learning approach combining spirogram time series and demographic data, demonstrating promising potential for early RHF detection in clinical practice.

</details>


### [552] [Multi-task GINN-LP for Multi-target Symbolic Regression](https://arxiv.org/abs/2511.13463)
*Hussein Rajabu,Lijun Qian,Xishuang Dong*

Main category: cs.LG

TL;DR: 提出了多任务回归GINN-LP（MTRGINN-LP），一种用于多目标符号回归的可解释神经网络，通过结合GINN-LP与多任务深度学习，解决符号回归在现实多输出任务中的局限性。


<details>
  <summary>Details</summary>
Motivation: 符号回归面临两个主要挑战：现有方法多在科学数据集上评估，泛化能力有限；且主要针对单输出回归，而现实问题常涉及具有相互依赖变量的多目标输出。

Method: 将GINN-LP与多任务深度学习结合，使用包含多个幂项近似器块的共享主干网络和任务特定输出层，在保持可解释性的同时捕获目标间依赖关系。

Result: 在能源效率预测和可持续农业等实际多目标应用上验证，实验结果显示具有竞争力的预测性能和高度可解释性。

Conclusion: MTRGINN-LP有效扩展了符号回归到更广泛的现实世界多输出任务，为多目标符号回归提供了可行的解决方案。

Abstract: In the area of explainable artificial intelligence, Symbolic Regression (SR) has emerged as a promising approach by discovering interpretable mathematical expressions that fit data. However, SR faces two main challenges: most methods are evaluated on scientific datasets with well-understood relationships, limiting generalization, and SR primarily targets single-output regression, whereas many real-world problems involve multi-target outputs with interdependent variables. To address these issues, we propose multi-task regression GINN-LP (MTRGINN-LP), an interpretable neural network for multi-target symbolic regression. By integrating GINN-LP with a multi-task deep learning, the model combines a shared backbone including multiple power-term approximator blocks with task-specific output layers, capturing inter-target dependencies while preserving interpretability. We validate multi-task GINN-LP on practical multi-target applications, including energy efficiency prediction and sustainable agriculture. Experimental results demonstrate competitive predictive performance alongside high interpretability, effectively extending symbolic regression to broader real-world multi-output tasks.

</details>


### [553] [AdamX: An Adam improvement algorithm based on a novel exponential decay mechanism for the second-order moment estimate](https://arxiv.org/abs/2511.13465)
*Meng Zhu,Quan Xiao,Weidong Min*

Main category: cs.LG

TL;DR: 本文提出了AdamX算法，通过新型二阶矩估计指数衰减率来解决Adam优化器在稳定训练期间容易收敛到非平坦最小值的问题，该算法在训练后期逐渐减弱学习步长修正强度并退化为SGD，从而提升训练稳定性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在大语言模型时代，虽然模型参数和数据规模增大，但Adam仍是主流优化算法。然而与基于SGD的优化算法相比，Adam更容易收敛到非平坦最小值，这影响了模型的泛化性能。

Method: 提出AdamX算法，核心创新是设计了一种新型二阶矩估计指数衰减率，该衰减率随着训练进程逐渐减弱学习步长修正强度，在稳定训练阶段退化为SGD。

Result: 实验结果表明，新型二阶矩估计指数衰减率优于现有方法，AdamX在性能上能够稳定超越Adam及其变体。

Conclusion: AdamX通过改进二阶矩估计机制有效解决了Adam优化器的局限性，在保持训练效率的同时提升了模型的稳定性和泛化能力。

Abstract: Since the 21st century, artificial intelligence has been leading a new round of industrial revolution. Under the training framework, the optimization algorithm aims to stably converge high-dimensional optimization to local and even global minima. Entering the era of large language models, although the scale of model parameters and data has increased, Adam remains the mainstream optimization algorithm. However, compared with stochastic gradient descent (SGD) based optimization algorithms, Adam is more likely to converge to non-flat minima. To address this issue, the AdamX algorithm is proposed. Its core innovation lies in the proposition of a novel type of second-order moment estimation exponential decay rate, which gradually weakens the learning step correction strength as training progresses, and degrades to SGD in the stable training period, thereby improving the stability of training in the stable period and possibly enhancing generalization ability. Experimental results show that our second-order moment estimation exponential decay rate is better than the current second-order moment estimation exponential decay rate, and AdamX can stably outperform Adam and its variants in terms of performance. Our code is open-sourced at https://github.com/mengzhu0308/AdamX.

</details>


### [554] [GREAT: Generalizable Representation Enhancement via Auxiliary Transformations for Zero-Shot Environmental Prediction](https://arxiv.org/abs/2511.13469)
*Shiyuan Luo,Chonghao Qiu,Runlong Yu,Yiqun Xie,Xiaowei Jia*

Main category: cs.LG

TL;DR: GREAT框架通过多层级转换函数增强环境数据，提升模型在未监测区域的零样本预测能力，在流域温度预测任务中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 环境建模面临监测数据有限且地理分布不均的挑战，传统方法容易学习到局部虚假模式，需要保持物理关系不变性和时间一致性。

Method: GREAT框架学习神经网络多层的转换函数来增强原始环境特征和时间影响，通过双层训练过程确保增强数据保留源数据的关键模式。

Result: 在美国东部六个生态多样性流域的河流温度预测实验中，GREAT在零样本场景下显著优于现有方法。

Conclusion: 该工作为无法进行全面监测的环境应用提供了实用解决方案，通过数据增强有效提升了模型在未见区域的泛化能力。

Abstract: Environmental modeling faces critical challenges in predicting ecosystem dynamics across unmonitored regions due to limited and geographically imbalanced observation data. This challenge is compounded by spatial heterogeneity, causing models to learn spurious patterns that fit only local data. Unlike conventional domain generalization, environmental modeling must preserve invariant physical relationships and temporal coherence during augmentation. In this paper, we introduce Generalizable Representation Enhancement via Auxiliary Transformations (GREAT), a framework that effectively augments available datasets to improve predictions in completely unseen regions. GREAT guides the augmentation process to ensure that the original governing processes can be recovered from the augmented data, and the inclusion of the augmented data leads to improved model generalization. Specifically, GREAT learns transformation functions at multiple layers of neural networks to augment both raw environmental features and temporal influence. They are refined through a novel bi-level training process that constrains augmented data to preserve key patterns of the original source data. We demonstrate GREAT's effectiveness on stream temperature prediction across six ecologically diverse watersheds in the eastern U.S., each containing multiple stream segments. Experimental results show that GREAT significantly outperforms existing methods in zero-shot scenarios. This work provides a practical solution for environmental applications where comprehensive monitoring is infeasible.

</details>


### [555] [Quantum Machine Learning via Contrastive Training](https://arxiv.org/abs/2511.13497)
*Liudmila A. Zhukas,Vivian Ni Zhang,Qiang Miao,Qingfeng Wang,Marko Cetina,Jungsang Kim,Lawrence Carin,Christopher Monroe*

Main category: cs.LG

TL;DR: 本文提出了一种量子自监督预训练方法，通过在量子计算机上学习图像的不变性来减少对标注数据的依赖，实验证明该方法在标注数据有限的情况下显著提升了分类性能。


<details>
  <summary>Details</summary>
Motivation: 量子机器学习面临与经典机器学习类似的标注数据稀缺问题，特别是随着模型规模和复杂度的增加，这一问题更加突出。作者希望通过自监督学习减少对标注数据的依赖。

Method: 在可编程离子阱量子计算机上实现自监督预训练，将图像编码为量子态，通过对比学习在硬件上预训练量子表示，然后进行微调分类。所有训练和分类阶段都在硬件上执行，相似性基于测量的量子重叠度。

Result: 实验表明，经过预训练的模型相比随机初始化的模型，在图像分类任务上具有更高的平均测试精度和更低的运行间变异性，特别是在标注训练数据有限的情况下性能提升显著。学习到的不变性能够泛化到预训练图像样本之外。

Conclusion: 这项工作为量子表示学习提供了一条标签高效的路径，对量子原生数据集具有直接相关性，并为处理更大规模经典输入提供了清晰的技术路线。

Abstract: Quantum machine learning (QML) has attracted growing interest with the rapid parallel advances in large-scale classical machine learning and quantum technologies. Similar to classical machine learning, QML models also face challenges arising from the scarcity of labeled data, particularly as their scale and complexity increase. Here, we introduce self-supervised pretraining of quantum representations that reduces reliance on labeled data by learning invariances from unlabeled examples. We implement this paradigm on a programmable trapped-ion quantum computer, encoding images as quantum states. In situ contrastive pretraining on hardware yields a representation that, when fine-tuned, classifies image families with higher mean test accuracy and lower run-to-run variability than models trained from random initialization. Performance improvement is especially significant in regimes with limited labeled training data. We show that the learned invariances generalize beyond the pretraining image samples. Unlike prior work, our pipeline derives similarity from measured quantum overlaps and executes all training and classification stages on hardware. These results establish a label-efficient route to quantum representation learning, with direct relevance to quantum-native datasets and a clear path to larger classical inputs.

</details>


### [556] [Naga: Vedic Encoding for Deep State Space Models](https://arxiv.org/abs/2511.13510)
*Melanie Schaller,Nick Janssen,Bodo Rosenhahn*

Main category: cs.LG

TL;DR: Naga是一种基于吠陀数学结构概念的双向状态空间模型，通过联合处理正向和时间反向序列来增强长程时间序列预测能力，在多个基准测试中优于28个现有先进模型。


<details>
  <summary>Details</summary>
Motivation: 现有深度状态空间模型在长程时间序列预测中存在效率不足和依赖关系捕捉不充分的问题，需要引入结构化分解方法来提升模型性能。

Method: 提出双向表示方法，联合处理正向和时间反向输入序列，通过元素级（Hadamard）交互实现吠陀数学启发的编码，增强模型对远距离时间步依赖关系的捕捉能力。

Result: 在ETTh1、ETTh2、ETTm1、ETTm2、Weather、Traffic和ILI等多个长程时间序列预测基准测试中，Naga优于28个当前最先进模型，并显示出比现有深度SSM方法更高的效率。

Conclusion: 引入结构化、吠陀数学启发的分解方法可以为长程序列建模提供可解释且计算效率高的替代方案。

Abstract: This paper presents Naga, a deep State Space Model (SSM) encoding approach inspired by structural concepts from Vedic mathematics. The proposed method introduces a bidirectional representation for time series by jointly processing forward and time-reversed input sequences. These representations are then combined through an element-wise (Hadamard) interaction, resulting in a Vedic-inspired encoding that enhances the model's ability to capture temporal dependencies across distant time steps. We evaluate Naga on multiple long-term time series forecasting (LTSF) benchmarks, including ETTh1, ETTh2, ETTm1, ETTm2, Weather, Traffic, and ILI. The experimental results show that Naga outperforms 28 current state of the art models and demonstrates improved efficiency compared to existing deep SSM-based approaches. The findings suggest that incorporating structured, Vedic-inspired decomposition can provide an interpretable and computationally efficient alternative for long-range sequence modeling.

</details>


### [557] [A Quantum Tensor Network-Based Viewpoint for Modeling and Analysis of Time Series Data](https://arxiv.org/abs/2511.13514)
*Pragatheeswaran Vipulananthan,Kamal Premaratne,Dilip Sarkar,Manohar N. Murthi*

Main category: cs.LG

TL;DR: 本文提出了一种基于量子物理的"白盒"方法，通过将时间序列数据的核均值嵌入映射到再生核希尔伯特空间，构建张量网络启发的1D自旋链哈密顿量，并应用微扰理论来量化不确定性，同时提高模型的可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决机器学习中准确不确定性量化的关键挑战，弥补神经网络"黑盒"缺乏可解释性和概率"白盒"模型性能不足的问题。

Method: 将时间序列数据的核均值嵌入映射到再生核希尔伯特空间，构建张量网络启发的1D自旋链哈密顿量，其中核均值嵌入作为其本征函数或本征模式。求解相关的薛定谔方程并应用微扰理论来量化不确定性。

Result: 该方法在变化点检测和时间序列聚类任务中表现出有效性，与最先进的"白盒"模型相比具有优势，为决策过程中的不确定性提供了深入洞察。

Conclusion: 提出的量子物理启发的白盒方法能够同时实现准确的不确定性量化和增强的可解释性，在时间序列分析任务中展现出良好性能。

Abstract: Accurate uncertainty quantification is a critical challenge in machine learning. While neural networks are highly versatile and capable of learning complex patterns, they often lack interpretability due to their ``black box'' nature. On the other hand, probabilistic ``white box'' models, though interpretable, often suffer from a significant performance gap when compared to neural networks. To address this, we propose a novel quantum physics-based ``white box'' method that offers both accurate uncertainty quantification and enhanced interpretability. By mapping the kernel mean embedding (KME) of a time series data vector to a reproducing kernel Hilbert space (RKHS), we construct a tensor network-inspired 1D spin chain Hamiltonian, with the KME as one of its eigen-functions or eigen-modes. We then solve the associated Schr{ö}dinger equation and apply perturbation theory to quantify uncertainty, thereby improving the interpretability of tasks performed with the quantum tensor network-based model. We demonstrate the effectiveness of this methodology, compared to state-of-the-art ``white box" models, in change point detection and time series clustering, providing insights into the uncertainties associated with decision-making throughout the process.

</details>


### [558] [Mitigating Spurious Correlations in Patch-wise Tumor Classification on High-Resolution Multimodal Images](https://arxiv.org/abs/2511.13527)
*Ihab Asaad,Maha Shadaydeh,Joachim Denzler*

Main category: cs.LG

TL;DR: 本文提出了一种针对高分辨率多模态非线性显微镜图像的补丁级二分类方法，用于检测肿瘤。研究发现该方法存在补丁组成与标签之间的虚假相关性，并采用GERNE去偏策略提升最差组准确率约7%。


<details>
  <summary>Details</summary>
Motivation: 补丁级多标签分类相比像素级分割能显著降低标注成本、简化训练过程，并允许灵活的补丁尺寸调整。但在肿瘤检测应用中，发现存在补丁组成（组织区域大小）与标签之间的虚假相关性问题。

Method: 采用补丁级二分类方法检测肿瘤，针对虚假相关性问题应用GERNE去偏方法，通过最大化最差组准确率来缓解偏差。

Result: 相比ERM方法，GERNE将最差组准确率提升了约7%，显著改善了在关键少数情况（如小组织肿瘤补丁和大组织非肿瘤补丁）上的性能。

Conclusion: 研究强调了在补丁级分类问题中考虑虚假相关性的重要性，去偏策略能有效提升模型在关键样本上的鲁棒性。

Abstract: Patch-wise multi-label classification provides an efficient alternative to full pixel-wise segmentation on high-resolution images, particularly when the objective is to determine the presence or absence of target objects within a patch rather than their precise spatial extent. This formulation substantially reduces annotation cost, simplifies training, and allows flexible patch sizing aligned with the desired level of decision granularity. In this work, we focus on a special case, patch-wise binary classification, applied to the detection of a single class of interest (tumor) on high-resolution multimodal nonlinear microscopy images. We show that, although this simplified formulation enables efficient model development, it can introduce spurious correlations between patch composition and labels: tumor patches tend to contain larger tissue regions, whereas non-tumor patches often consist mostly of background with small tissue areas. We further quantify the bias in model predictions caused by this spurious correlation, and propose to use a debiasing strategy to mitigate its effect. Specifically, we apply GERNE, a debiasing method that can be adapted to maximize worst-group accuracy (WGA). Our results show an improvement in WGA by approximately 7% compared to ERM for two different thresholds used to binarize the spurious feature. This enhancement boosts model performance on critical minority cases, such as tumor patches with small tissues and non-tumor patches with large tissues, and underscores the importance of spurious correlation-aware learning in patch-wise classification problems.

</details>


### [559] [Fairness-Aware Graph Representation Learning with Limited Demographic Information](https://arxiv.org/abs/2511.13540)
*Zichong Wang,Zhipeng Yin,Liping Yang,Jun Zhuang,Rui Yu,Qingzhao Kong,Wenbin Zhang*

Main category: cs.LG

TL;DR: 本文提出了FairGLite框架，在人口统计信息有限的情况下实现公平图学习，通过生成人口统计代理和自适应置信策略来平衡公平性和模型效用。


<details>
  <summary>Details</summary>
Motivation: 现有的公平图学习方法大多假设可以完全访问人口统计信息，但在实际应用中由于隐私、法律或监管限制，这一要求很少能满足。

Method: 1）基于部分人口统计数据生成人口统计信息代理；2）设计策略确保不同人口统计组的节点嵌入一致性；3）开发自适应置信策略，根据预测置信度动态调整节点对公平性和效用的贡献。

Result: 理论分析证明FairGLite在群体公平性指标上可达到可证明的上界，实验表明该框架在多个数据集和公平图学习框架上都能有效减轻偏见并保持模型效用。

Conclusion: FairGLite为解决实际应用中人口统计信息受限情况下的公平图学习问题提供了有效解决方案，具有理论保证和实际应用价值。

Abstract: Ensuring fairness in Graph Neural Networks is fundamental to promoting trustworthy and socially responsible machine learning systems. In response, numerous fair graph learning methods have been proposed in recent years. However, most of them assume full access to demographic information, a requirement rarely met in practice due to privacy, legal, or regulatory restrictions. To this end, this paper introduces a novel fair graph learning framework that mitigates bias in graph learning under limited demographic information. Specifically, we propose a mechanism guided by partial demographic data to generate proxies for demographic information and design a strategy that enforces consistent node embeddings across demographic groups. In addition, we develop an adaptive confidence strategy that dynamically adjusts each node's contribution to fairness and utility based on prediction confidence. We further provide theoretical analysis demonstrating that our framework, FairGLite, achieves provable upper bounds on group fairness metrics, offering formal guarantees for bias mitigation. Through extensive experiments on multiple datasets and fair graph learning frameworks, we demonstrate the framework's effectiveness in both mitigating bias and maintaining model utility.

</details>


### [560] [Graph Out-of-Distribution Detection via Test-Time Calibration with Dual Dynamic Dictionaries](https://arxiv.org/abs/2511.13541)
*Yue Hou,Ruomei Liu,Yingke Su,Junran Wu,Ke Xu*

Main category: cs.LG

TL;DR: BaCa是一种无需微调预训练模型的图分布外检测方法，通过动态双字典和边界感知校准来提升检测性能


<details>
  <summary>Details</summary>
Motivation: 现有图OOD检测方法缺乏真实OOD样本，仅优化ID特征，难以准确表示分布边界，且图数据的潜在多因素结构未被充分探索

Method: 使用图论估计和混合策略生成边界感知拓扑，构建动态双字典通过优先级队列和注意力机制捕获潜在ID/OOD表示，进行边界感知OOD分数校准

Result: 在真实数据集上的大量实验表明，BaCa显著优于现有最先进的OOD检测方法

Conclusion: BaCa通过边界感知校准和动态字典机制，有效解决了图OOD检测中的边界表示问题，无需辅助数据集或模型微调

Abstract: A key challenge in graph out-of-distribution (OOD) detection lies in the absence of ground-truth OOD samples during training. Existing methods are typically optimized to capture features within the in-distribution (ID) data and calculate OOD scores, which often limits pre-trained models from representing distributional boundaries, leading to unreliable OOD detection. Moreover, the latent structure of graph data is often governed by multiple underlying factors, which remains less explored. To address these challenges, we propose a novel test-time graph OOD detection method, termed BaCa, that calibrates OOD scores using dual dynamically updated dictionaries without requiring fine-tuning the pre-trained model. Specifically, BaCa estimates graphons and applies a mix-up strategy solely with test samples to generate diverse boundary-aware discriminative topologies, eliminating the need for exposing auxiliary datasets as outliers. We construct dual dynamic dictionaries via priority queues and attention mechanisms to adaptively capture latent ID and OOD representations, which are then utilized for boundary-aware OOD score calibration. To the best of our knowledge, extensive experiments on real-world datasets show that BaCa significantly outperforms existing state-of-the-art methods in OOD detection.

</details>


### [561] [RAC-DMVC: Reliability-Aware Contrastive Deep Multi-View Clustering under Multi-Source Noise](https://arxiv.org/abs/2511.13561)
*Shihao Dong,Yue Liu,Xiaotong Zhou,Yuhui Zheng,Huiying Xu,Xinzhong Zhu*

Main category: cs.LG

TL;DR: 本文提出了一种新的可靠性感知对比深度多视图聚类框架RAC-DMVC，用于处理多源噪声（包括缺失噪声和观测噪声）下的多视图聚类任务。


<details>
  <summary>Details</summary>
Motivation: 多视图聚类在现实场景中面临多源噪声的挑战，包括缺失噪声和观测噪声，这限制了其实际应用。现有的方法在处理这些复杂噪声时效果有限。

Method: RAC-DMVC框架包含四个关键模块：1）跨视图重构增强数据级鲁棒性；2）可靠性感知噪声对比学习减少噪声表示带来的偏差；3）双注意力填补处理缺失噪声；4）自监督聚类蒸馏优化表示学习。

Result: 在五个基准数据集上的实验表明，RAC-DMVC在多个评估指标上优于现有最优方法，并在不同噪声比例下保持优异性能。

Conclusion: RAC-DMVC通过可靠性图引导的鲁棒表示学习，有效解决了多视图聚类中的多源噪声问题，为实际应用提供了可行的解决方案。

Abstract: Multi-view clustering (MVC), which aims to separate the multi-view data into distinct clusters in an unsupervised manner, is a fundamental yet challenging task. To enhance its applicability in real-world scenarios, this paper addresses a more challenging task: MVC under multi-source noises, including missing noise and observation noise. To this end, we propose a novel framework, Reliability-Aware Contrastive Deep Multi-View Clustering (RAC-DMVC), which constructs a reliability graph to guide robust representation learning under noisy environments. Specifically, to address observation noise, we introduce a cross-view reconstruction to enhances robustness at the data level, and a reliability-aware noise contrastive learning to mitigates bias in positive and negative pairs selection caused by noisy representations. To handle missing noise, we design a dual-attention imputation to capture shared information across views while preserving view-specific features. In addition, a self-supervised cluster distillation module further refines the learned representations and improves the clustering performance. Extensive experiments on five benchmark datasets demonstrate that RAC-DMVC outperforms SOTA methods on multiple evaluation metrics and maintains excellent performance under varying ratios of noise.

</details>


### [562] [P1: Mastering Physics Olympiads with Reinforcement Learning](https://arxiv.org/abs/2511.13612)
*Jiacheng Chen,Qianjia Cheng,Fangchen Yu,Haiyuan Wan,Yuchen Zhang,Shenghe Zheng,Junchi Yao,Qingyang Zhang,Haonan He,Yun Luo,Yufeng Zhao,Futing Wang,Li Sheng,Chengxing Xie,Yuxin Zuo,Yizhuo Li,Wenxauan Zeng,Yulun Wu,Rui Huang,Dongzhan Zhou,Kai Chen,Yu Qiao,Lei Bai,Yu Cheng,Ning Ding,Bowen Zhou,Peng Ye,Ganqu Cui*

Main category: cs.LG

TL;DR: P1系列模型通过强化学习训练，在物理推理方面表现卓越，在IPhO 2025等13个国际物理竞赛中获得12枚金牌，展现了科学级推理能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型从谜题解决向科学级推理发展，物理作为连接符号与现实的基石，是测试这一转变的最佳领域。

Method: 开发P1系列开源物理推理模型，完全通过强化学习训练，并配备代理框架PhysicsMinions。

Result: P1-235B-A22B在IPhO 2025获得金牌表现，P1-30B-A3B获得银牌，在数学和编码等推理任务上也表现出色。

Conclusion: P1模型不仅在物理竞赛中表现优异，还展示了强大的通用推理能力，为科学级AI推理树立了新标杆。

Abstract: Recent progress in large language models (LLMs) has moved the frontier from puzzle-solving to science-grade reasoning-the kind needed to tackle problems whose answers must stand against nature, not merely fit a rubric. Physics is the sharpest test of this shift, which binds symbols to reality in a fundamental way, serving as the cornerstone of most modern technologies. In this work, we manage to advance physics research by developing large language models with exceptional physics reasoning capabilities, especially excel at solving Olympiad-level physics problems. We introduce P1, a family of open-source physics reasoning models trained entirely through reinforcement learning (RL). Among them, P1-235B-A22B is the first open-source model with Gold-medal performance at the latest International Physics Olympiad (IPhO 2025), and wins 12 gold medals out of 13 international/regional physics competitions in 2024/2025. P1-30B-A3B also surpasses almost all other open-source models on IPhO 2025, getting a silver medal. Further equipped with an agentic framework PhysicsMinions, P1-235B-A22B+PhysicsMinions achieves overall No.1 on IPhO 2025, and obtains the highest average score over the 13 physics competitions. Besides physics, P1 models also present great performance on other reasoning tasks like math and coding, showing the great generalibility of P1 series.

</details>


### [563] [Batch Acquisition Function Evaluations and Decouple Optimizer Updates for Faster Bayesian Optimization](https://arxiv.org/abs/2511.13625)
*Kaichi Irie,Shuhei Watanabe,Masaki Onishi*

Main category: cs.LG

TL;DR: 本文提出了一种解耦准牛顿更新的方法，通过协程批量处理采集函数调用，以解决贝叶斯优化中采集函数优化的计算瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯优化中采集函数优化存在计算瓶颈，现有方法如BoTorch库中的多起始点优化虽然通过批处理加速，但存在逆Hessian矩阵的非对角近似误差问题，导致收敛速度变慢。

Method: 提出解耦准牛顿更新策略，使用协程同时批量处理采集函数调用，保持与顺序多起始点优化相同的理论收敛性。

Result: 该方法不仅实现了与顺序多起始点优化相同的理论收敛性，而且相比现有方法大幅减少了实际运行时间。

Conclusion: 所提出的解耦准牛顿更新方法有效解决了贝叶斯优化中采集函数优化的计算效率问题，在保持收敛性的同时显著提升了优化速度。

Abstract: Bayesian optimization (BO) efficiently finds high-performing parameters by maximizing an acquisition function, which models the promise of parameters. A major computational bottleneck arises in acquisition function optimization, where multi-start optimization (MSO) with quasi-Newton (QN) methods is required due to the non-convexity of the acquisition function. BoTorch, a widely used BO library, currently optimizes the summed acquisition function over multiple points, leading to the speedup of MSO owing to PyTorch batching. Nevertheless, this paper empirically demonstrates the suboptimality of this approach in terms of off-diagonal approximation errors in the inverse Hessian of a QN method, slowing down its convergence. To address this problem, we propose to decouple QN updates using a coroutine while batching the acquisition function calls. Our approach not only yields the theoretically identical convergence to the sequential MSO but also drastically reduces the wall-clock time compared to the previous approaches.

</details>


### [564] [Towards Multimodal Representation Learning in Paediatric Kidney Disease](https://arxiv.org/abs/2511.13637)
*Ana Durica,John Booth,Ivana Drobnjak*

Main category: cs.LG

TL;DR: 该研究使用时间建模方法，结合纵向实验室数据和人口统计信息，通过循环神经网络预测儿童在未来30天内是否会出现异常血清肌酐值。


<details>
  <summary>Details</summary>
Motivation: 儿科肾脏疾病表现和进展差异大，需要持续监测肾功能。本研究旨在探索如何利用常规临床数据预测肾功能异常。

Method: 使用2019-2025年Great Ormond Street Hospital的电子健康记录，构建循环神经网络模型，整合纵向实验室序列和人口统计信息进行预测。

Result: 初步研究表明，简单的时间表示能够捕捉儿科常规数据中的有用模式，为未来使用更多临床信号和更详细肾脏结果的多模态扩展奠定基础。

Conclusion: 这项试点工作证明了时间建模在儿科肾功能监测中的潜力，为开发更全面的预测模型提供了基础。

Abstract: Paediatric kidney disease varies widely in its presentation and progression, which calls for continuous monitoring of renal function. Using electronic health records collected between 2019 and 2025 at Great Ormond Street Hospital, a leading UK paediatric hospital, we explored a temporal modelling approach that integrates longitudinal laboratory sequences with demographic information. A recurrent neural model trained on these data was used to predict whether a child would record an abnormal serum creatinine value within the following thirty days. Framed as a pilot study, this work provides an initial demonstration that simple temporal representations can capture useful patterns in routine paediatric data and lays the groundwork for future multimodal extensions using additional clinical signals and more detailed renal outcomes.

</details>


### [565] [Data Value in the Age of Scaling: Understanding LLM Scaling Dynamics Under Real-Synthetic Data Mixtures](https://arxiv.org/abs/2511.13640)
*Haohui Wang,Jingyuan Qi,Jianpeng Chen,Jun Wu,Lifu Huang,Lecheng Zheng,Kevin Choi,Balaji Veeramani,Edward Bowen,Alison Hu,Tyler Cody,Dawei Zhou*

Main category: cs.LG

TL;DR: 该论文研究了真实与合成数据混合数据集中的分布差异问题，识别了模型学习行为的三个阶段转变，提出了LLM泛化边界理论，并开发了高效的数据评估方法。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速发展，数据集越来越多地混合使用真实和合成数据。虽然合成数据具有可扩展性和成本效益，但通常会引入系统性的分布差异，特别是由于数据生成机制（如top-p采样、温度缩放和有限采样）的截断效应而导致长尾知识代表性不足。这些差异给混合数据集的效用表征和评估带来了根本性挑战。

Method: 论文识别了具有两个断点的三阶段缩放行为，反映了模型在学习和尾部知识学习中的行为转变。进一步推导了针对真实和合成混合数据的LLM泛化边界，揭示了影响其泛化性能的关键因素。基于理论发现，提出了一种高效的数据评估方法，能够扩展到大规模数据集。

Result: 在四个任务（图像分类、情感分类、指令跟随和复杂推理）上的全面实验表明，该方法在数据评估方面超越了最先进的基线方法，且计算成本显著降低。

Conclusion: 该研究为理解混合真实-合成数据集的特性提供了理论框架，并提出了一种实用且高效的数据评估方法，有助于更好地管理和优化LLM训练数据。

Abstract: The rapid progress of large language models (LLMs) is fueled by the growing reliance on datasets that blend real and synthetic data. While synthetic data offers scalability and cost-efficiency, it often introduces systematic distributional discrepancies, particularly underrepresenting long-tail knowledge due to truncation effects from data generation mechanisms like top-p sampling, temperature scaling, and finite sampling. These discrepancies pose fundamental challenges in characterizing and evaluating the utility of mixed real-synthetic datasets. In this paper, we identify a three-phase scaling behavior characterized by two breakpoints that reflect transitions in model behavior across learning head and tail knowledge. We further derive an LLM generalization bound designed for real and synthetic mixtures, revealing several key factors that govern their generalization performance. Building on our theoretical findings, we propose an effective yet efficient data valuation method that scales to large-scale datasets. Comprehensive experiments across four tasks, including image classification, sentiment classification, instruction following, and complex reasoning, demonstrate that our method surpasses state-of-the-art baselines in data valuation with significantly low computational cost.

</details>


### [566] [FuseSampleAgg: Fused Neighbor Sampling and Aggregation for Mini-batch GNNs](https://arxiv.org/abs/2511.13645)
*Aleksandar Stanković*

Main category: cs.LG

TL;DR: FuseSampleAgg是一个CUDA算子，将邻居采样和均值聚合融合为单步操作，用于GraphSAGE的一跳和两跳图神经网络，显著提升训练速度和减少内存使用。


<details>
  <summary>Details</summary>
Motivation: 传统的GraphSAGE训练需要多步操作（邻居采样和聚合分离），导致内存流量大和内核启动开销高，影响训练效率。

Method: 通过消除块物化和额外内核启动，使用保存的索引重放技术来保持GraphSAGE均值语义，将邻居采样和均值聚合融合到单次CUDA内核中。

Result: 在Reddit、ogbn-arxiv和ogbn-products基准测试中，观察到最高51倍的步时加速（ogbn-products），内存使用减少最高达100倍，同时保持确定性并与标准PyTorch优化器兼容。

Conclusion: FuseSampleAgg通过操作融合技术显著提升了GraphSAGE的训练效率，实现了速度和内存的双重优化，为大规模图神经网络训练提供了高效解决方案。

Abstract: We present FuseSampleAgg, a CUDA operator that fuses neighbor sampling and mean aggregation into a single pass for one and two hop GraphSAGE. By eliminating block materialization and extra kernel launches, FuseSampleAgg reduces memory traffic and overhead while preserving GraphSAGE mean semantics via saved index replay. Across the Reddit, ogbn-arxiv, and ogbn-products benchmarks (batch size 1024, automatic mixed precision enabled), we observe step time speedups up to 51x on ogbn-products, about 4x on Reddit with fanouts 10-10 and 15-10, and about 3.3x on ogbn-arxiv at larger fanouts, with peak GPU memory reductions up to 100x, 36x, and about 3.5x, respectively. The operator is deterministic, integrates with standard PyTorch optimizers, and ships with scripts that reproduce all tables and figures from CSV logs. Code and scripts are available at https://github.com/SV25-22/FuseSampleAgg.

</details>


### [567] [Weight-sparse transformers have interpretable circuits](https://arxiv.org/abs/2511.13653)
*Leo Gao,Achyuta Rajaram,Jacob Coxon,Soham V. Govande,Bowen Baker,Dan Mossing*

Main category: cs.LG

TL;DR: 通过训练权重稀疏的语言模型来寻找人类可理解的电路，通过剪枝技术隔离特定任务对应的电路，发现这些电路包含对应自然概念的神经元和连接，研究模型规模对可解释性的影响。


<details>
  <summary>Details</summary>
Motivation: 寻找语言模型中人类可理解的电路是机制可解释性领域的核心目标，当前需要开发能够产生更易理解电路的方法。

Method: 训练权重稀疏的语言模型（大多数权重为零），然后通过剪枝技术隔离特定任务对应的电路部分，分析电路中的神经元和连接模式。

Result: 获得的电路包含对应自然概念的神经元和残差通道，连接关系直接可解释；发现稀疏化在能力和可解释性之间存在权衡，模型规模扩大可改善这一平衡；但超过千万参数后保持可解释性仍具挑战。

Conclusion: 该方法能够产生前所未有的可理解电路，并经过严格验证，同时初步证明可适用于解释现有密集模型。

Abstract: Finding human-understandable circuits in language models is a central goal of the field of mechanistic interpretability. We train models to have more understandable circuits by constraining most of their weights to be zeros, so that each neuron only has a few connections. To recover fine-grained circuits underlying each of several hand-crafted tasks, we prune the models to isolate the part responsible for the task. These circuits often contain neurons and residual channels that correspond to natural concepts, with a small number of straightforwardly interpretable connections between them. We study how these models scale and find that making weights sparser trades off capability for interpretability, and scaling model size improves the capability-interpretability frontier. However, scaling sparse models beyond tens of millions of nonzero parameters while preserving interpretability remains a challenge. In addition to training weight-sparse models de novo, we show preliminary results suggesting our method can also be adapted to explain existing dense models. Our work produces circuits that achieve an unprecedented level of human understandability and validates them with considerable rigor.

</details>


### [568] [Tuning for Two Adversaries: Enhancing the Robustness Against Transfer and Query-Based Attacks using Hyperparameter Tuning](https://arxiv.org/abs/2511.13654)
*Pascal Zimmer,Ghassan Karame*

Main category: cs.LG

TL;DR: 本文首次系统分析了优化超参数（学习率、权重衰减、动量、批量大小）对迁移攻击和查询攻击鲁棒性的影响，发现学习率调整对两种攻击类型呈现相反效果，分布式训练从超参数调优中获益最大。


<details>
  <summary>Details</summary>
Motivation: 研究优化超参数如何影响对抗攻击鲁棒性，填补了现有研究空白，为实际部署场景提供理论指导。

Method: 通过理论分析和实验验证，涵盖集中训练、集成学习和分布式训练等多种实际部署场景，系统研究不同超参数设置对迁移攻击和查询攻击鲁棒性的影响。

Result: 发现学习率调整的二分现象：降低学习率可提升迁移攻击鲁棒性达64%，而提高学习率可提升查询攻击鲁棒性达28%。分布式训练通过超参数调优能同时有效缓解两种攻击类型。

Conclusion: 优化超参数设计对对抗鲁棒性至关重要，特别是分布式训练能从超参数调优中获得最大收益，为构建更安全的机器学习系统提供了新思路。

Abstract: In this paper, we present the first detailed analysis of how optimization hyperparameters -- such as learning rate, weight decay, momentum, and batch size -- influence robustness against both transfer-based and query-based attacks. Supported by theory and experiments, our study spans a variety of practical deployment settings, including centralized training, ensemble learning, and distributed training. We uncover a striking dichotomy: for transfer-based attacks, decreasing the learning rate significantly enhances robustness by up to $64\%$. In contrast, for query-based attacks, increasing the learning rate consistently leads to improved robustness by up to $28\%$ across various settings and data distributions. Leveraging these findings, we explore -- for the first time -- the optimization hyperparameter design space to jointly enhance robustness against both transfer-based and query-based attacks. Our results reveal that distributed models benefit the most from hyperparameter tuning, achieving a remarkable tradeoff by simultaneously mitigating both attack types more effectively than other training setups.

</details>


### [569] [Scientific Data Compression and Super-Resolution Sampling](https://arxiv.org/abs/2511.13675)
*Minh Vu,Andrey Lokhov*

Main category: cs.LG

TL;DR: 提出了一种基于指数族学习的新型科学数据压缩与超分辨率框架，能够在压缩大规模科学数据的同时保持物理特征并量化不确定性。


<details>
  <summary>Details</summary>
Motivation: 现代科学模拟和实验产生的数据量往往超出存储和处理能力限制，且需要支持从压缩表示中恢复数据（如检查点重启），同时保证关键物理特性的保留。

Method: 基于学习指数族的最新进展，开发了一个科学数据压缩和超分辨率框架，支持压缩比与重建保真度之间的灵活权衡。

Result: 该方法能够有效管理大规模数据集，在压缩过程中保持关键物理特征，并量化物理量中的不确定性。

Conclusion: 该框架为科学数据压缩和恢复提供了有效解决方案，特别适用于需要检查点重启等场景，在保持数据质量的同时实现高效压缩。

Abstract: Modern scientific simulations, observations, and large-scale experiments generate data at volumes that often exceed the limits of storage, processing, and analysis. This challenge drives the development of data reduction methods that efficiently manage massive datasets while preserving essential physical features and quantities of interest. In many scientific workflows, it is also crucial to enable data recovery from compressed representations - a task known as super-resolution - with guarantees on the preservation of key physical characteristics. A notable example is checkpointing and restarting, which is essential for long-running simulations to recover from failures, resume after interruptions, or examine intermediate results. In this work, we introduce a novel framework for scientific data compression and super-resolution, grounded in recent advances in learning exponential families. Our method preserves and quantifies uncertainty in physical quantities of interest and supports flexible trade-offs between compression ratio and reconstruction fidelity.

</details>


### [570] [Cross-Learning from Scarce Data via Multi-Task Constrained Optimization](https://arxiv.org/abs/2511.13680)
*Leopoldo Agorio,Juan Cerviño,Miguel Calvo-Fullana,Alejandro Ribeiro,Juan Andrés Bazerque*

Main category: cs.LG

TL;DR: 该论文提出了一种跨学习框架，通过联合估计多个相关任务中的确定性参数来解决数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 当数据有限时，学习的模型难以泛化到未见过的案例。该研究旨在克服数据稀缺性，通过多任务学习实现知识从数据丰富的任务向数据稀缺任务的转移。

Method: 将联合估计建模为约束优化问题，约束条件控制不同模型参数之间的相似性，允许参数在不同任务间存在差异，同时结合多个数据源的信息。

Result: 在具有高斯数据的受控框架中提供了理论保证，并在图像分类和传染病传播等实际数据应用中展示了跨学习方法的有效性。

Conclusion: 跨学习框架能够从数据丰富的任务向数据稀缺任务转移知识，为从有限数据中进行参数推断的关键场景提供了解决方案，实现了更准确可靠的参数估计。

Abstract: A learning task, understood as the problem of fitting a parametric model from supervised data, fundamentally requires the dataset to be large enough to be representative of the underlying distribution of the source. When data is limited, the learned models fail generalize to cases not seen during training. This paper introduces a multi-task \emph{cross-learning} framework to overcome data scarcity by jointly estimating \emph{deterministic} parameters across multiple, related tasks. We formulate this joint estimation as a constrained optimization problem, where the constraints dictate the resulting similarity between the parameters of the different models, allowing the estimated parameters to differ across tasks while still combining information from multiple data sources. This framework enables knowledge transfer from tasks with abundant data to those with scarce data, leading to more accurate and reliable parameter estimates, providing a solution for scenarios where parameter inference from limited data is critical. We provide theoretical guarantees in a controlled framework with Gaussian data, and show the efficiency of our cross-learning method in applications with real data including image classification and propagation of infectious diseases.

</details>


### [571] [Protein Secondary Structure Prediction Using 3D Graphs and Relation-Aware Message Passing Transformers](https://arxiv.org/abs/2511.13685)
*Disha Varshney,Samarth Garg,Sarthak Tyagi,Deeksha Varshney,Nayan Deep,Asif Ekbal*

Main category: cs.LG

TL;DR: 本文提出了一种结合图神经网络和语言模型的蛋白质二级结构预测方法SSRGNet，通过利用蛋白质3D结构数据和残基图来增强空间信息捕获，在NetSurfP-2.0数据集上超越了基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖未标记的氨基酸序列，未能充分利用可获取的蛋白质3D结构数据，而3D结构是决定蛋白质功能的关键因素。

Method: 使用预训练的基于transformer的蛋白质语言模型编码氨基酸序列，结合GCN和R-GCN等消息传递机制捕获蛋白质结构的几何特征，通过残基图和多种序列或结构连接来增强空间信息。

Result: 在NetSurfP-2.0数据集上的实验表明，SSRGNet模型在f1分数上超越了基线模型。

Conclusion: 该方法有效结合了语言模型和图神经网络，充分利用了蛋白质3D结构信息，为蛋白质二级结构预测提供了新的解决方案。

Abstract: In this study, we tackle the challenging task of predicting secondary structures from protein primary sequences, a pivotal initial stride towards predicting tertiary structures, while yielding crucial insights into protein activity, relationships, and functions. Existing methods often utilize extensive sets of unlabeled amino acid sequences. However, these approaches neither explicitly capture nor harness the accessible protein 3D structural data, which is recognized as a decisive factor in dictating protein functions. To address this, we utilize protein residue graphs and introduce various forms of sequential or structural connections to capture enhanced spatial information. We adeptly combine Graph Neural Networks (GNNs) and Language Models (LMs), specifically utilizing a pre-trained transformer-based protein language model to encode amino acid sequences and employing message-passing mechanisms like GCN and R-GCN to capture geometric characteristics of protein structures. Employing convolution within a specific node's nearby region, including relations, we stack multiple convolutional layers to efficiently learn combined insights from the protein's spatial graph, revealing intricate interconnections and dependencies in its structural arrangement. To assess our model's performance, we employed the training dataset provided by NetSurfP-2.0, which outlines secondary structure in 3-and 8-states. Extensive experiments show that our proposed model, SSRGNet surpasses the baseline on f1-scores.

</details>


### [572] [Efficient Calibration for Decision Making](https://arxiv.org/abs/2511.13699)
*Parikshit Gopalan,Konstantinos Stavropoulos,Kunal Talwar,Pranay Tankala*

Main category: cs.LG

TL;DR: 本文提出了一种新的校准度量方法CDL_K，通过限制后处理函数的结构来克服CDL的计算不可行性问题，并建立了完整的理论框架来分析其信息论和计算可处理性。


<details>
  <summary>Details</summary>
Motivation: Hu和Wu提出的校准决策损失(CDL)虽然在理论上具有良好性质，但在离线设置下难以近似计算，这限制了其实际应用。

Method: 通过限制后处理函数的结构类别K，定义相对校准决策损失CDL_K，并系统分析不同K类别下CDL_K的可计算性和信息论性质。

Result: 建立了CDL_K的完整理论框架，证明了对于自然函数类K的上下界，为机器学习中广泛使用的重新校准程序提供了严格的理论保证。

Conclusion: CDL_K方法既保持了理论上的严谨性，又具有实际可计算性，为决策理论中的校准问题提供了新的定义和算法技术。

Abstract: A decision-theoretic characterization of perfect calibration is that an agent seeking to minimize a proper loss in expectation cannot improve their outcome by post-processing a perfectly calibrated predictor. Hu and Wu (FOCS'24) use this to define an approximate calibration measure called calibration decision loss ($\mathsf{CDL}$), which measures the maximal improvement achievable by any post-processing over any proper loss. Unfortunately, $\mathsf{CDL}$ turns out to be intractable to even weakly approximate in the offline setting, given black-box access to the predictions and labels.
  We suggest circumventing this by restricting attention to structured families of post-processing functions $K$. We define the calibration decision loss relative to $K$, denoted $\mathsf{CDL}_K$ where we consider all proper losses but restrict post-processings to a structured family $K$. We develop a comprehensive theory of when $\mathsf{CDL}_K$ is information-theoretically and computationally tractable, and use it to prove both upper and lower bounds for natural classes $K$. In addition to introducing new definitions and algorithmic techniques to the theory of calibration for decision making, our results give rigorous guarantees for some widely used recalibration procedures in machine learning.

</details>


### [573] [Learning stochasticity: a nonparametric framework for intrinsic noise estimation](https://arxiv.org/abs/2511.13701)
*Gianluigi Pillonetto,Alberto Giaretta,Mauro Bisiacco*

Main category: cs.LG

TL;DR: Trine是一个非参数、基于核的三阶段回归框架，用于从时间序列数据中推断状态依赖的内在噪声，无需预定义参数假设即可揭示隐藏动态。


<details>
  <summary>Details</summary>
Motivation: 非线性相互作用和随机效应的不完全知识使得自下而上的建模方法往往无效，尤其是在估计内在噪声时参数模型表现不佳，但理解内在噪声对复杂系统动态行为的影响至关重要。

Method: Trine采用三阶段算法，结合解析可解的子问题和结构化核架构，捕捉噪声驱动的突变波动和状态依赖的方差平滑变化。

Result: 在生物和生态系统的基准问题上，Trine实现了与oracle相当的性能，能够有效揭示隐藏动态。

Conclusion: Trine框架为理解内在噪声如何影响复杂系统行为开辟了新途径。

Abstract: Understanding the principles that govern dynamical systems is a central challenge across many scientific domains, including biology and ecology. Incomplete knowledge of nonlinear interactions and stochastic effects often renders bottom-up modeling approaches ineffective, motivating the development of methods that can discover governing equations directly from data. In such contexts, parametric models often struggle without strong prior knowledge, especially when estimating intrinsic noise. Nonetheless, incorporating stochastic effects is often essential for understanding the dynamic behavior of complex systems such as gene regulatory networks and signaling pathways. To address these challenges, we introduce Trine (Three-phase Regression for INtrinsic noisE), a nonparametric, kernel-based framework that infers state-dependent intrinsic noise from time-series data. Trine features a three-stage algorithm that com- bines analytically solvable subproblems with a structured kernel architecture that captures both abrupt noise-driven fluctuations and smooth, state-dependent changes in variance. We validate Trine on biological and ecological systems, demonstrating its ability to uncover hidden dynamics without relying on predefined parametric assumptions. Across several benchmark problems, Trine achieves performance comparable to that of an oracle. Biologically, this oracle can be viewed as an idealized observer capable of directly tracking the random fluctuations in molecular concentrations or reaction events within a cell. The Trine framework thus opens new avenues for understanding how intrinsic noise affects the behavior of complex systems.

</details>


### [574] [ST-ProC: A Graph-Prototypical Framework for Robust Semi-Supervised Travel Mode Identification](https://arxiv.org/abs/2511.13702)
*Luyao Niu,Nuoxian Huang*

Main category: cs.LG

TL;DR: ST-ProC是一个针对GPS轨迹出行模式识别的半监督学习框架，通过图原型多目标方法解决标签稀缺问题，相比现有方法性能提升21.5%。


<details>
  <summary>Details</summary>
Motivation: GPS轨迹出行模式识别面临标注成本高、标签稀缺的挑战，现有半监督学习方法存在确认偏差且忽略数据流形结构。

Method: 结合图正则化、原型锚定和边缘感知伪标签策略，通过对比学习和师生一致性损失来稳定优化过程。

Result: 在真实稀疏标签场景下显著优于所有基线方法，相比FixMatch等先进方法性能提升21.5%。

Conclusion: ST-ProC框架有效解决了出行模式识别中的标签稀缺问题，为城市智能应用提供了实用解决方案。

Abstract: Travel mode identification (TMI) from GPS trajectories is critical for urban intelligence, but is hampered by the high cost of annotation, leading to severe label scarcity. Prevailing semi-supervised learning (SSL) methods are ill-suited for this task, as they suffer from catastrophic confirmation bias and ignore the intrinsic data manifold. We propose ST-ProC, a novel graph-prototypical multi-objective SSL framework to address these limitations. Our framework synergizes a graph-prototypical core with foundational SSL Support. The core exploits the data manifold via graph regularization, prototypical anchoring, and a novel, margin-aware pseudo-labeling strategy to actively reject noise. This core is supported and stabilized by foundational contrastive and teacher-student consistency losses, ensuring high-quality representations and robust optimization. ST-ProC outperforms all baselines by a significant margin, demonstrating its efficacy in real-world sparse-label settings, with a performance boost of 21.5% over state-of-the-art methods like FixMatch.

</details>


### [575] [Rare Genomic Subtype Discovery from RNA-seq via Autoencoder Embeddings and Stability-Aware Clustering](https://arxiv.org/abs/2511.13705)
*Alaa Mezghiche*

Main category: cs.LG

TL;DR: 该论文提出了一种结合自编码器和聚类稳定性分析的方法，用于在RNA-seq数据中发现罕见但可重复的基因组亚型。在KIRC数据中发现了一个稳定的罕见亚型（6.85%患者）。


<details>
  <summary>Details</summary>
Motivation: 无监督学习可以揭示标准标签之外的分子亚型，特别是在高维RNA-seq数据中寻找罕见但可重复的基因组亚型。

Method: 使用自编码器进行特征表示，结合k-means聚类和稳定性分析（Jaccard指数和匈牙利对齐），通过预设发现规则（罕见<10%且稳定性≥0.60）识别亚型。

Result: 在KIRC数据中发现k=5时存在一个高度稳定的罕见簇C0（6.85%患者，Jaccard=0.787），而泛癌分析主要受组织来源主导。

Conclusion: 泛癌聚类受组织来源主导，而基于稳定性的癌症内分析方法能够发现罕见且可重复的KIRC亚型。

Abstract: Unsupervised learning on high-dimensional RNA-seq data can reveal molecular subtypes beyond standard labels. We combine an autoencoder-based representation with clustering and stability analysis to search for rare but reproducible genomic subtypes. On the UCI "Gene Expression Cancer RNA-Seq" dataset (801 samples, 20,531 genes; BRCA, COAD, KIRC, LUAD, PRAD), a pan-cancer analysis shows clusters aligning almost perfectly with tissue of origin (Cramer's V = 0.887), serving as a negative control. We therefore reframe the problem within KIRC (n = 146): we select the top 2,000 highly variable genes, standardize them, train a feed-forward autoencoder (128-dimensional latent space), and run k-means for k = 2-10. While global indices favor small k, scanning k with a pre-specified discovery rule (rare < 10 percent and stable with Jaccard >= 0.60 across 20 seeds after Hungarian alignment) yields a simple solution at k = 5 (silhouette = 0.129, DBI = 2.045) with a rare cluster C0 (6.85 percent of patients) that is highly stable (Jaccard = 0.787). Cluster-vs-rest differential expression (Welch's t-test, Benjamini-Hochberg FDR) identifies coherent markers. Overall, pan-cancer clustering is dominated by tissue of origin, whereas a stability-aware within-cancer approach reveals a rare, reproducible KIRC subtype.

</details>


### [576] [From Black Box to Insight: Explainable AI for Extreme Event Preparedness](https://arxiv.org/abs/2511.13712)
*Kiana Vu,İsmet Selçuk Özer,Phung Lai,Zheng Wu,Thilanka Munasinghe,Jennifer Wei*

Main category: cs.LG

TL;DR: 该论文研究可解释人工智能（XAI）在极端事件预测中的作用，以野火预测为案例，评估AI模型并使用SHAP方法揭示关键特征和决策路径，旨在提升AI模型的可信度和实际应用价值。


<details>
  <summary>Details</summary>
Motivation: 随着气候变化加剧极端事件频率，AI模型在预测方面显示潜力但因其黑盒性质限制了实际应用。论文旨在通过XAI弥合预测准确性与可操作性之间的差距。

Method: 使用野火预测作为案例研究，评估多种AI模型，并采用SHAP（SHapley Additive exPlanations）方法来揭示关键特征、决策路径和潜在偏差，同时提供可视化增强解释性。

Result: 分析表明XAI不仅能澄清模型推理，还能支持领域专家和应急团队的决策。可视化工具通过情境化特征重要性和时空模式，增强了XAI输出的可解释性。

Conclusion: 研究强调AI系统不仅需要准确，还需具备可解释性、可访问性和可信度，这对灾害准备、风险缓解和气候韧性规划至关重要。

Abstract: As climate change accelerates the frequency and severity of extreme events such as wildfires, the need for accurate, explainable, and actionable forecasting becomes increasingly urgent. While artificial intelligence (AI) models have shown promise in predicting such events, their adoption in real-world decision-making remains limited due to their black-box nature, which limits trust, explainability, and operational readiness. This paper investigates the role of explainable AI (XAI) in bridging the gap between predictive accuracy and actionable insight for extreme event forecasting. Using wildfire prediction as a case study, we evaluate various AI models and employ SHapley Additive exPlanations (SHAP) to uncover key features, decision pathways, and potential biases in model behavior. Our analysis demonstrates how XAI not only clarifies model reasoning but also supports critical decision-making by domain experts and response teams. In addition, we provide supporting visualizations that enhance the interpretability of XAI outputs by contextualizing feature importance and temporal patterns in seasonality and geospatial characteristics. This approach enhances the usability of AI explanations for practitioners and policymakers. Our findings highlight the need for AI systems that are not only accurate but also interpretable, accessible, and trustworthy, essential for effective use in disaster preparedness, risk mitigation, and climate resilience planning.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [577] [Hierarchical Federated Graph Attention Networks for Scalable and Resilient UAV Collision Avoidance](https://arxiv.org/abs/2511.11616)
*Rathin Chandra Shit,Sharmila Subudhi*

Main category: cs.RO

TL;DR: 提出了一种三层分层框架来解决大规模多无人机系统中的实时性能、对抗鲁棒性和隐私保护之间的平衡问题，通过分层架构和轻量级协议实现可扩展的碰撞避免。


<details>
  <summary>Details</summary>
Motivation: 当前框架倾向于单一解决方案，计算复杂度高（O(n²)）且缺乏拜占庭容错能力，需要平衡实时性能、对抗鲁棒性和隐私保护这三个关键指标。

Method: 采用三层架构：本地层使用密集图注意力进行即时碰撞避免（延迟<10ms），区域层使用稀疏注意力（O(nk)复杂度）和异步联邦学习，全局层使用轻量级Hashgraph协议。采用自适应差分隐私机制和基于DHT的轻量级审计日志。

Result: 在500架无人机的可扩展场景下，碰撞率<2.0%，拜占庭容错能力f<n/3，95%百分位决策的中位成本在50ms内。

Conclusion: 该分层框架成功消除了实时性能、对抗鲁棒性和隐私保护之间的权衡，提供了可扩展的解决方案。

Abstract: The real-time performance, adversarial resiliency, and privacy preservation are the most important metrics that need to be balanced to practice collision avoidance in large-scale multi-UAV (Unmanned Aerial Vehicle) systems. Current frameworks tend to prescribe monolithic solutions that are not only prohibitively computationally complex with a scaling cost of $O(n^2)$ but simply do not offer Byzantine fault tolerance. The proposed hierarchical framework presented in this paper tries to eliminate such trade-offs by stratifying a three-layered architecture. We spread the intelligence into three layers: an immediate collision avoiding local layer running on dense graph attention with latency of $<10 ms$, a regional layer using sparse attention with $O(nk)$ computational complexity and asynchronous federated learning with coordinate-wise trimmed mean aggregation, and lastly, a global layer using a lightweight Hashgraph-inspired protocol. We have proposed an adaptive differential privacy mechanism, wherein the noise level $(ε\in [0.1, 1.0])$ is dynamically reduced based on an evaluation of the measured real-time threat that in turn maximized the privacy-utility tradeoff. Through the use of Distributed Hash Table (DHT)-based lightweight audit logging instead of heavyweight blockchain consensus, the median cost of getting a $95^{th}$ percentile decision within 50ms is observed across all tested swarm sizes. This architecture provides a scalable scenario of 500 UAVs with a collision rate of $< 2.0\%$ and the Byzantine fault tolerance of $f < n/3$.

</details>


### [578] [Tactile Data Recording System for Clothing with Motion-Controlled Robotic Sliding](https://arxiv.org/abs/2511.11634)
*Michikuni Eguchi,Takekazu Kitagishi,Yuichi Hiroi,Takefumi Hiraki*

Main category: cs.RO

TL;DR: 提出基于机器人手臂的系统，用于从完整服装收集触觉数据，通过模拟指尖滑动测量并精确控制速度和方向，创建带运动标签的多模态触觉数据库。


<details>
  <summary>Details</summary>
Motivation: 服装的触觉感受对穿着舒适度至关重要，需要系统收集滑动运动中的触觉数据来揭示舒适服装的物理特性。

Method: 使用机器人手臂系统进行滑动测量，模拟指尖触摸，精确控制速度和方向，创建运动标签化的多模态触觉数据库。

Result: 机器学习评估显示，包含运动相关参数提高了音频和加速度数据的识别准确率，证明了运动相关标签对表征服装触觉感受的有效性。

Conclusion: 该系统提供了一种可扩展、非破坏性的服装触觉数据采集方法，有助于未来织物感知和再现的研究。

Abstract: The tactile sensation of clothing is critical to wearer comfort. To reveal physical properties that make clothing comfortable, systematic collection of tactile data during sliding motion is required. We propose a robotic arm-based system for collecting tactile data from intact garments. The system performs stroking measurements with a simulated fingertip while precisely controlling speed and direction, enabling creation of motion-labeled, multimodal tactile databases. Machine learning evaluation showed that including motion-related parameters improved identification accuracy for audio and acceleration data, demonstrating the efficacy of motion-related labels for characterizing clothing tactile sensation. This system provides a scalable, non-destructive method for capturing tactile data of clothing, contributing to future studies on fabric perception and reproduction.

</details>


### [579] [Image-based Morphological Characterization of Filamentous Biological Structures with Non-constant Curvature Shape Feature](https://arxiv.org/abs/2511.11639)
*Jie Fan,Francesco Visentin,Barbara Mazzolai,Emanuela Del Dottore*

Main category: cs.RO

TL;DR: 本文提出了一种基于图像的几何方法，用于分析卷须在机械刺激下的形状变化，该方法使用3D分段回旋曲线模型重建卷须形态，具有高精度和可靠性。


<details>
  <summary>Details</summary>
Motivation: 研究卷须形状变化与机械刺激位置、触发事件之间的时间关系，以理解植物攀爬机制，为仿生机器人设计提供基础。

Method: 采用基于3D分段回旋曲线的几何建模方法，通过图像分析卷须在不同部位受到机械摩擦后的形态变化。

Result: 该方法重建精度R²>0.99，显示出比深度学习更高的鲁棒性、更低的数据需求和计算成本，并发现卷须顶端段具有更高的响应性。

Conclusion: 该研究为植物生物力学提供了新的分析方法，并为仿生智能机器人系统的设计奠定了基础。

Abstract: Tendrils coil their shape to anchor the plant to supporting structures, allowing vertical growth toward light. Although climbing plants have been studied for a long time, extracting information regarding the relationship between the temporal shape change, the event that triggers it, and the contact location is still challenging. To help build this relation, we propose an image-based method by which it is possible to analyze shape changes over time in tendrils when mechano-stimulated in different portions of their body. We employ a geometric approach using a 3D Piece-Wise Clothoid-based model to reconstruct the configuration taken by a tendril after mechanical rubbing. The reconstruction shows high robustness and reliability with an accuracy of R2 > 0.99. This method demonstrates distinct advantages over deep learning-based approaches, including reduced data requirements, lower computational costs, and interpretability. Our analysis reveals higher responsiveness in the apical segment of tendrils, which might correspond to higher sensitivity and tissue flexibility in that region of the organs. Our study provides a methodology for gaining new insights into plant biomechanics and offers a foundation for designing and developing novel intelligent robotic systems inspired by climbing plants.

</details>


### [580] [ExpertAD: Enhancing Autonomous Driving Systems with Mixture of Experts](https://arxiv.org/abs/2511.11740)
*Haowen Jiang,Xinyu Huang,You Lu,Dingji Wang,Yuheng Cao,Chaofeng Sha,Bihuan Chen,Keyu Chen,Xin Peng*

Main category: cs.RO

TL;DR: ExpertAD是一个基于混合专家架构的端到端自动驾驶框架，通过感知适配器和稀疏专家混合来提升场景理解和规划性能，在碰撞率和推理延迟方面显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决复杂驾驶场景中语义信息模糊或噪声干扰决策可靠性、多任务干扰影响规划效果、以及推理延迟导致不安全驾驶行为的问题。

Method: 提出ExpertAD框架，包含感知适配器(PA)放大任务关键特征确保场景理解，以及稀疏专家混合(MoSE)最小化预测时的任务干扰，实现高效规划。

Result: 实验显示ExpertAD相比现有方法平均碰撞率降低20%，推理延迟减少25%，在罕见场景和未见过的城市环境中表现出强大的泛化能力。

Conclusion: ExpertAD通过MoE架构有效解决了自动驾驶系统中的语义理解、任务干扰和延迟问题，在复杂驾驶场景中展现出优越的性能和决策能力。

Abstract: Recent advancements in end-to-end autonomous driving systems (ADSs) underscore their potential for perception and planning capabilities. However, challenges remain. Complex driving scenarios contain rich semantic information, yet ambiguous or noisy semantics can compromise decision reliability, while interference between multiple driving tasks may hinder optimal planning. Furthermore, prolonged inference latency slows decision-making, increasing the risk of unsafe driving behaviors. To address these challenges, we propose ExpertAD, a novel framework that enhances the performance of ADS with Mixture of Experts (MoE) architecture. We introduce a Perception Adapter (PA) to amplify task-critical features, ensuring contextually relevant scene understanding, and a Mixture of Sparse Experts (MoSE) to minimize task interference during prediction, allowing for effective and efficient planning. Our experiments show that ExpertAD reduces average collision rates by up to 20% and inference latency by 25% compared to prior methods. We further evaluate its multi-skill planning capabilities in rare scenarios (e.g., accidents, yielding to emergency vehicles) and demonstrate strong generalization to unseen urban environments. Additionally, we present a case study that illustrates its decision-making process in complex driving scenarios.

</details>


### [581] [Large Language Models and 3D Vision for Intelligent Robotic Perception and Autonomy: A Review](https://arxiv.org/abs/2511.11777)
*Vinit Mehta,Charu Sharma,Karthick Thiyagarajan*

Main category: cs.RO

TL;DR: 这篇综述论文分析了LLM与3D视觉融合在机器人感知技术中的最新进展，涵盖了方法、应用和挑战，重点关注场景理解、文本到3D生成、多模态融合等关键技术。


<details>
  <summary>Details</summary>
Motivation: 随着AI和机器人技术的快速发展，LLM与3D视觉的融合正在成为提升机器人感知能力的重要方向，旨在弥合语言智能与空间感知之间的鸿沟。

Method: 论文首先介绍LLM和3D数据表示的基础原理，然后深入分析3D感知技术，重点探讨场景理解、文本到3D生成、物体定位和具身智能体等关键进展，包括零样本3D分割、动态场景合成和语言引导操作等前沿技术。

Result: 论文系统梳理了多模态LLM整合3D数据与触觉、听觉和热输入的方法，增强了环境理解和机器人决策能力，并整理了专门针对3D-语言和视觉任务的基准数据集和评估指标。

Conclusion: 识别了关键挑战和未来研究方向，包括自适应模型架构、增强跨模态对齐和实时处理能力，为更智能、上下文感知和自主的机器人感知系统铺平道路。

Abstract: With the rapid advancement of artificial intelligence and robotics, the integration of Large Language Models (LLMs) with 3D vision is emerging as a transformative approach to enhancing robotic sensing technologies. This convergence enables machines to perceive, reason and interact with complex environments through natural language and spatial understanding, bridging the gap between linguistic intelligence and spatial perception. This review provides a comprehensive analysis of state-of-the-art methodologies, applications and challenges at the intersection of LLMs and 3D vision, with a focus on next-generation robotic sensing technologies. We first introduce the foundational principles of LLMs and 3D data representations, followed by an in-depth examination of 3D sensing technologies critical for robotics. The review then explores key advancements in scene understanding, text-to-3D generation, object grounding and embodied agents, highlighting cutting-edge techniques such as zero-shot 3D segmentation, dynamic scene synthesis and language-guided manipulation. Furthermore, we discuss multimodal LLMs that integrate 3D data with touch, auditory and thermal inputs, enhancing environmental comprehension and robotic decision-making. To support future research, we catalog benchmark datasets and evaluation metrics tailored for 3D-language and vision tasks. Finally, we identify key challenges and future research directions, including adaptive model architectures, enhanced cross-modal alignment and real-time processing capabilities, which pave the way for more intelligent, context-aware and autonomous robotic sensing systems.

</details>


### [582] [LAVQA: A Latency-Aware Visual Question Answering Framework for Shared Autonomy in Self-Driving Vehicles](https://arxiv.org/abs/2511.11840)
*Shuangyu Xie,Kaiyuan Chen,Wenjing Chen,Chengyuan Qian,Christian Juette,Liu Ren,Dezhen Song,Ken Goldberg*

Main category: cs.RO

TL;DR: LAVQA是一个延迟感知的共享自主框架，通过视觉问答和时空风险可视化来应对网络延迟和人类响应时间变化带来的关键决策时机问题。


<details>
  <summary>Details</summary>
Motivation: 当不确定性较高时，自动驾驶车辆可能需要远程人类操作员提供高级指导，但无线网络延迟和人类响应时间会导致可变延迟，影响关键决策时机。

Method: LAVQA框架集成了视觉问答和时空风险可视化，通过延迟诱导碰撞地图动态表示时间延迟和空间不确定性，使远程操作员能够观察车辆安全区域随时间和动态障碍物的变化。

Result: 在CARLA自动驾驶模拟器中的闭环仿真表明，LAVQA相比延迟不可知基线可将碰撞率降低8倍以上。

Conclusion: LAVQA通过有效处理延迟和不确定性，显著提高了共享自主系统的安全性能。

Abstract: When uncertainty is high, self-driving vehicles may halt for safety and benefit from the access to remote human operators who can provide high-level guidance. This paradigm, known as {shared autonomy}, enables autonomous vehicle and remote human operators to jointly formulate appropriate responses. To address critical decision timing with variable latency due to wireless network delays and human response time, we present LAVQA, a latency-aware shared autonomy framework that integrates Visual Question Answering (VQA) and spatiotemporal risk visualization. LAVQA augments visual queries with Latency-Induced COllision Map (LICOM), a dynamically evolving map that represents both temporal latency and spatial uncertainty. It enables remote operator to observe as the vehicle safety regions vary over time in the presence of dynamic obstacles and delayed responses. Closed-loop simulations in CARLA, the de-facto standard for autonomous vehicle simulator, suggest that that LAVQA can reduce collision rates by over 8x compared to latency-agnostic baselines.

</details>


### [583] [Autonomous Underwater Cognitive System for Adaptive Navigation: A SLAM-Integrated Cognitive Architecture](https://arxiv.org/abs/2511.11845)
*K. A. I. N Jayarathne,R. M. N. M. Rathnayaka,D. P. S. S. Peiris*

Main category: cs.RO

TL;DR: 该论文提出了一种自主水下认知系统（AUCS），将SLAM与Soar认知架构结合，通过多传感器数据融合和认知推理模块实现复杂海洋环境中的自适应导航。


<details>
  <summary>Details</summary>
Motivation: 深海探索面临定位迷失、通信中断和动态水下环境中导航失败等重大挑战，需要更智能的自适应导航系统。

Method: 系统融合SONAR、LiDAR、IMU和DVL等多传感器数据，结合认知推理模块（感知、注意力、规划和学习），通过语义理解、自适应传感器管理和基于记忆的学习来区分动态和静态物体。

Result: AUCS展示了完整的感知-认知-动作-学习循环，能够减少错误闭环检测，增强长期地图一致性。

Conclusion: 该工作为下一代认知潜水器系统奠定了基础，提高了深海探索的安全性、可靠性和自主性。

Abstract: Deep-sea exploration poses significant challenges, including disorientation, communication loss, and navigational failures in dynamic underwater environments. This paper presents an Autonomous Underwater Cognitive System (AUCS) that integrates Simultaneous Localization and Mapping (SLAM) with a Soar-based cognitive architecture to enable adaptive navigation in complex oceanic conditions. The system fuses multi-sensor data from SONAR, LiDAR, IMU, and DVL with cognitive reasoning modules for perception, attention, planning, and learning. Unlike conventional SLAM systems, AUCS incorporates semantic understanding, adaptive sensor management, and memory-based learning to differentiate between dynamic and static objects, reducing false loop closures and enhancing long-term map consistency. The proposed architecture demonstrates a complete perception-cognition-action-learning loop, allowing autonomous underwater vehicles to sense, reason, and adapt intelligently. This work lays a foundation for next-generation cognitive submersible systems, improving safety, reliability, and autonomy in deep-sea exploration.

</details>


### [584] [MATT-Diff: Multimodal Active Target Tracking by Diffusion Policy](https://arxiv.org/abs/2511.11931)
*Saida Liu,Nikolay Atanasov,Shumon Koga*

Main category: cs.RO

TL;DR: MATT-Diff是一种基于扩散策略的多模态主动目标跟踪控制方法，能够处理探索、专注跟踪和目标重捕获等多种行为模式，无需目标数量、状态或动态的先验知识。


<details>
  <summary>Details</summary>
Motivation: 主动多目标跟踪需要在探索未检测或丢失目标与跟踪已检测但不确定目标之间取得平衡，现有方法难以有效处理这种多模态行为需求。

Method: 使用三种专家规划器生成演示数据集，设计基于视觉Transformer的控制器进行地图标记化，采用注意力机制整合高斯密度表示的目标估计，通过扩散模型训练生成多模态动作序列。

Result: 评估显示MATT-Diff在多种目标运动场景下均优于专家和行为克隆基线方法，验证了其在目标跟踪中的优势。

Conclusion: MATT-Diff通过扩散策略成功实现了多模态主动目标跟踪，在复杂环境中展现出优越的跟踪性能。

Abstract: This paper proposes MATT-Diff: Multi-Modal Active Target Tracking by Diffusion Policy, a control policy that captures multiple behavioral modes - exploration, dedicated tracking, and target reacquisition - for active multi-target tracking. The policy enables agent control without prior knowledge of target numbers, states, or dynamics. Effective target tracking demands balancing exploration for undetected or lost targets with following the motion of detected but uncertain ones. We generate a demonstration dataset from three expert planners including frontier-based exploration, an uncertainty-based hybrid planner switching between frontier-based exploration and RRT* tracking based on target uncertainty, and a time-based hybrid planner switching between exploration and tracking based on target detection time. We design a control policy utilizing a vision transformer for egocentric map tokenization and an attention mechanism to integrate variable target estimates represented by Gaussian densities. Trained as a diffusion model, the policy learns to generate multi-modal action sequences through a denoising process. Evaluations demonstrate MATT-Diff's superior tracking performance against expert and behavior cloning baselines across multiple target motions, empirically validating its advantages in target tracking.

</details>


### [585] [Characterization and Evaluation of Screw-Based Locomotion Across Aquatic, Granular, and Transitional Media](https://arxiv.org/abs/2511.11958)
*Derek Chen,Zoe Samuels,Lizzie Peiros,Sujaan Mukherjee,Michael C. Yip*

Main category: cs.RO

TL;DR: 本文系统研究了螺旋推进系统在不同介质（干沙、湿沙、饱和沙和水）中的运动性能，通过热沉设计优化参数对螺旋性能进行分类，为螺旋壳设计和自适应运动策略提供具体指导。


<details>
  <summary>Details</summary>
Motivation: 螺旋推进系统在实现两栖机动性方面具有潜力，但在优化水、颗粒材料和过渡环境中的运动性能方面面临挑战。

Method: 采用原理优先的方法分析螺旋性能，研究不同螺旋配置在多种介质中的运动表现，借鉴热沉设计优化参数进行分类。

Result: 发现某些参数对性能有主导影响，不同介质中性能表现存在差异，基于热沉设计启发的参数可有效分类性能表现。

Conclusion: 研究结果为螺旋壳设计和自适应运动策略提供了具体见解，有助于提升螺旋推进系统在多样化两栖应用中的性能。

Abstract: Screw-based propulsion systems offer promising capabilities for amphibious mobility, yet face significant challenges in optimizing locomotion across water, granular materials, and transitional environments. This study presents a systematic investigation into the locomotion performance of various screw configurations in media such as dry sand, wet sand, saturated sand, and water. Through a principles-first approach to analyze screw performance, it was found that certain parameters are dominant in their impact on performance. Depending on the media, derived parameters inspired from optimizing heat sink design help categorize performance within the dominant design parameters. Our results provide specific insights into screw shell design and adaptive locomotion strategies to enhance the performance of screw-based propulsion systems for versatile amphibious applications.

</details>


### [586] [Bootstrapped LLM Semantics for Context-Aware Path Planning](https://arxiv.org/abs/2511.11967)
*Mani Amani,Behrad Beheshti,Reza Akhavian*

Main category: cs.RO

TL;DR: 该论文提出了一个框架，将大型语言模型（LLM）转化为随机语义传感器，通过贝叶斯自举方法估计环境中的风险后验分布，并基于此构建路径规划问题，使机器人能够根据自然语言提示在语义丰富的人类中心空间中安全高效地移动。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注自然语言提示下机器人执行什么任务（目标选择、技能序列），而忽略了如何在语义丰富的人类中心空间中安全高效地执行任务。本文旨在填补这一空白。

Method: 1. 将LLM转化为随机语义传感器；2. 给定提示和语义地图，生成多个LLM“危险”判断；3. 应用贝叶斯自举近似每类风险的后验分布；4. 利用后验统计量构建势能成本函数；5. 制定路径规划问题。

Result: 在模拟环境和BIM支持的数字孪生中，该方法能够根据显式提示和隐式上下文信息自适应调整机器人的移动方式。论文提供了定性和定量结果验证。

Conclusion: 该框架成功地将LLM的语义理解能力与经典规划器结合，实现了机器人基于自然语言提示的安全高效路径规划，为在复杂人类环境中部署机器人提供了新思路。

Abstract: Prompting robots with natural language (NL) has largely been studied as what task to execute (goal selection, skill sequencing) rather than how to execute that task safely and efficiently in semantically rich, human-centric spaces. We address this gap with a framework that turns a large language model (LLM) into a stochastic semantic sensor whose outputs modulate a classical planner. Given a prompt and a semantic map, we draw multiple LLM "danger" judgments and apply a Bayesian bootstrap to approximate a posterior over per-class risk. Using statistics from the posterior, we create a potential cost to formulate a path planning problem. Across simulated environments and a BIM-backed digital twin, our method adapts how the robot moves in response to explicit prompts and implicit contextual information. We present qualitative and quantitative results.

</details>


### [587] [ARCSnake V2: An Amphibious Multi-Domain Screw-Propelled Snake-Like Robot](https://arxiv.org/abs/2511.11970)
*Sara Wickenhiser,Lizzie Peiros,Calvin Joyce,Peter Gavrilrov,Sujaan Mukherjee,Syler Sylvester,Junrong Zhou,Mandy Cheung,Jason Lim,Florian Richter,Michael C. Yip*

Main category: cs.RO

TL;DR: ARCSnake V2是一款两栖螺旋推进蛇形机器人，结合了蛇形机器人的高机动性和阿基米德螺旋推进的地形适应性，可在陆地、颗粒介质和水下环境中实现多种运动模式的平滑转换。


<details>
  <summary>Details</summary>
Motivation: 传统轮式或腿式机器人在洞穴、海洋和行星表面等极端环境中的多样化地形上移动困难，需要开发更通用的多域探索平台。

Method: 采用水密封机械设计，集成了螺旋推进和关节驱动的串行连接结构，配备浮力控制系统，并通过运动学匹配的手持控制器实现遥操作。

Result: 实验验证了机器人的水下机动性、通信鲁棒性和力调节驱动能力，支持螺旋推进、轮式移动和侧向滑动等多种运动模式。

Conclusion: ARCSnake V2作为一个多功能平台，在探索、搜救和环境监测等多域场景中具有广泛应用前景。

Abstract: Robotic exploration in extreme environments such as caves, oceans, and planetary surfaces pose significant challenges, particularly in locomotion across diverse terrains. Conventional wheeled or legged robots often struggle in these contexts due to surface variability. This paper presents ARCSnake V2, an amphibious, screw propelled, snake like robot designed for teleoperated or autonomous locomotion across land, granular media, and aquatic environments. ARCSnake V2 combines the high mobility of hyper redundant snake robots with the terrain versatility of Archimedean screw propulsion. Key contributions include a water sealed mechanical design with serially linked screw and joint actuation, an integrated buoyancy control system, and teleoperation via a kinematically matched handheld controller. The robots design and control architecture enable multiple locomotion modes screwing, wheeling, and sidewinding with smooth transitions between them. Extensive experiments validate its underwater maneuverability, communication robustness, and force regulated actuation. These capabilities position ARCSnake V2 as a versatile platform for exploration, search and rescue, and environmental monitoring in multi domain settings.

</details>


### [588] [SBAMP: Sampling Based Adaptive Motion Planning](https://arxiv.org/abs/2511.12022)
*Anh-Quan Pham,Kabir Ram Puri,Shreyas Raorane*

Main category: cs.RO

TL;DR: SBAMP是一种新型运动规划框架，结合RRT*全局路径规划和SEDS局部控制，实现动态环境中的自适应实时导航，无需预训练数据集。


<details>
  <summary>Details</summary>
Motivation: 传统采样方法如RRT*难以适应动态变化，而学习型动态系统如SEDS依赖预收集数据，泛化能力有限。需要一种既能保证全局最优又能实时自适应的解决方案。

Method: 集成RRT*进行全局路径规划，使用SEDS基础局部控制器进行连续自适应轨迹调整，通过Lyapunov稳定性保证系统稳定性，无需预训练数据集。

Result: 在模拟环境和RoboRacer硬件平台上验证，SBAMP在动态障碍物场景、快速扰动恢复和急转弯处理方面表现优异，实时自适应且不牺牲全局路径最优性。

Conclusion: SBAMP为动态非结构化环境提供了可扩展的解决方案，实现了实时自适应导航，同时保持全局路径规划的最优性。

Abstract: Autonomous robotic systems must navigate complex, dynamic environments in real time, often facing unpredictable obstacles and rapidly changing conditions. Traditional sampling-based methods, such as RRT*, excel at generating collision-free paths but struggle to adapt to sudden changes without extensive replanning. Conversely, learning-based dynamical systems, such as the Stable Estimator of Dynamical Systems (SEDS), offer smooth, adaptive trajectory tracking but typically rely on pre-collected demonstration data, limiting their generalization to novel scenarios. This paper introduces Sampling-Based Adaptive Motion Planning (SBAMP), a novel framework that overcomes these limitations by integrating RRT* for global path planning with a SEDS-based local controller for continuous, adaptive trajectory adjustment. Our approach requires no pre-trained datasets and ensures smooth transitions between planned waypoints, maintaining stability through Lyapunov-based guarantees. We validate SBAMP in both simulated environments and real hardware using the RoboRacer platform, demonstrating superior performance in dynamic obstacle scenarios, rapid recovery from perturbations, and robust handling of sharp turns. Experimental results highlight SBAMP's ability to adapt in real time without sacrificing global path optimality, providing a scalable solution for dynamic, unstructured environments.

</details>


### [589] [Decoupled Action Head: Confining Task Knowledge to Conditioning Layers](https://arxiv.org/abs/2511.12101)
*Jian Zhou,Sihao Lin,Shuai Fu,Qi WU*

Main category: cs.RO

TL;DR: 本文提出了一种解耦训练方法，使用低成本运动学轨迹预训练动作头，然后通过特征调制适应新任务，显著提升了训练效率和模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有行为克隆方法受限于配对训练数据的稀缺性，且扩散策略等模型内部机制理解不足，导致泛化能力有限和模型设计缺乏原则性指导。

Method: 提出解耦训练框架：1）使用运动学生成的轨迹预训练通用动作头；2）冻结预训练的动作头，通过特征调制适应新任务；3）基于观察引入DP-MLP，用轻量MLP块替换复杂U-Net主干。

Result: 解耦训练在分布内和分布外场景均可行，DP-C实现41%训练加速；DP-MLP参数减少98.4%，训练速度提升83.9%（正常训练）和89.1%（解耦训练）。

Conclusion: 解耦训练方法有效解决了数据稀缺问题，证明动作生成主干在机器人操作中作用有限，为轻量化模型设计提供了新思路。

Abstract: Behavior Cloning (BC) is a data-driven supervised learning approach that has gained increasing attention with the success of scaling laws in language and vision domains. Among its implementations in robotic manipulation, Diffusion Policy (DP), with its two variants DP-CNN (DP-C) and DP-Transformer (DP-T), is one of the most effective and widely adopted models, demonstrating the advantages of predicting continuous action sequences. However, both DP and other BC methods remain constrained by the scarcity of paired training data, and the internal mechanisms underlying DP's effectiveness remain insufficiently understood, leading to limited generalization and a lack of principled design in model development. In this work, we propose a decoupled training recipe that leverages nearly cost-free kinematics-generated trajectories as observation-free data to pretrain a general action head (action generator). The pretrained action head is then frozen and adapted to novel tasks through feature modulation. Our experiments demonstrate the feasibility of this approach in both in-distribution and out-of-distribution scenarios. As an additional benefit, decoupling improves training efficiency; for instance, DP-C achieves up to a 41% speedup. Furthermore, the confinement of task-specific knowledge to the conditioning components under decoupling, combined with the near-identical performance of DP-C in both normal and decoupled training, indicates that the action generation backbone plays a limited role in robotic manipulation. Motivated by this observation, we introduce DP-MLP, which replaces the 244M-parameter U-Net backbone of DP-C with only 4M parameters of simple MLP blocks, achieving a 83.9% faster training speed under normal training and 89.1% under decoupling.

</details>


### [590] [Towards Obstacle-Avoiding Control of Planar Snake Robots Exploring Neuro-Evolution of Augmenting Topologies](https://arxiv.org/abs/2511.12148)
*Advik Sinha,Akshay Arjun,Abhijit Das,Joyjit Mukherjee*

Main category: cs.RO

TL;DR: 本文提出了一种资源高效的解决方案，用于在密集障碍物环境中实现平面蛇形机器人的避障跟踪控制。该方法使用NEAT算法生成蛇形步态参数，通过最大化奖励函数来优化机器人行为。


<details>
  <summary>Details</summary>
Motivation: 开发在密集障碍物环境中高效控制蛇形机器人的方法，解决传统方法计算复杂度高的问题，实现资源高效的避障跟踪控制。

Method: 采用NEAT（神经进化增强拓扑）算法生成蛇形步态的动态参数，将关节角度、连杆位置、头部位置和附近障碍物位置作为输入，输出控制速度和方向的频率和偏移角。通过LiDAR和传感器数据构建奖励函数，通过选择性传播优秀神经网络来最大化奖励。

Result: 该方法在PyBullet物理引擎仿真中验证，计算效率高，特别适用于大型多障碍物环境。与现有最先进方法相比表现优越，与最新的CBRL方法结果相当但计算开销显著降低。

Conclusion: NEAT算法为蛇形机器人避障控制提供了高效解决方案，在保持性能的同时大幅降低了计算复杂度，适用于复杂环境中的实时控制应用。

Abstract: This work aims to develop a resource-efficient solution for obstacle-avoiding tracking control of a planar snake robot in a densely cluttered environment with obstacles. Particularly, Neuro-Evolution of Augmenting Topologies (NEAT) has been employed to generate dynamic gait parameters for the serpenoid gait function, which is implemented on the joint angles of the snake robot, thus controlling the robot on a desired dynamic path. NEAT is a single neural-network based evolutionary algorithm that is known to work extremely well when the input layer is of significantly higher dimension and the output layer is of a smaller size. For the planar snake robot, the input layer consists of the joint angles, link positions, head link position as well as obstacle positions in the vicinity. However, the output layer consists of only the frequency and offset angle of the serpenoid gait that control the speed and heading of the robot, respectively. Obstacle data from a LiDAR and the robot data from various sensors, along with the location of the end goal and time, are employed to parametrize a reward function that is maximized over iterations by selective propagation of superior neural networks. The implementation and experimental results showcase that the proposed approach is computationally efficient, especially for large environments with many obstacles. The proposed framework has been verified through a physics engine simulation study on PyBullet. The approach shows superior results to existing state-of-the-art methodologies and comparable results to the very recent CBRL approach with significantly lower computational overhead. The video of the simulation can be found here: https://sites.google.com/view/neatsnakerobot

</details>


### [591] [Game-Theoretic Safe Multi-Agent Motion Planning with Reachability Analysis for Dynamic and Uncertain Environments (Extended Version)](https://arxiv.org/abs/2511.12160)
*Wenbin Mai,Minghui Liwang,Xinlei Yi,Xiaoyu Xia,Seyyedali Hosseinalipour,Xianbin Wang*

Main category: cs.RO

TL;DR: 提出了一种结合可达性分析与博弈论的多智能体运动规划框架RE-DPG，通过动态势博弈和可达集分析解决复杂环境下的安全协调问题。


<details>
  <summary>Details</summary>
Motivation: 解决动态不确定环境中多智能体系统的安全、鲁棒和可扩展运动规划挑战，特别是耦合决策的计算复杂性和前瞻性安全保证需求。

Method: RE-DPG框架将多智能体协调建模为动态势博弈，使用纳什均衡定义最优控制策略；开发了基于邻域主导的迭代最佳响应算法ND-iBR，确保有限步收敛到ε-纳什均衡；在成本函数中集成多智能体前向可达集机制，显式建模不确定性传播并强制执行碰撞避免约束。

Result: 通过2D和3D环境的仿真和真实实验验证了RE-DPG在不同操作场景下的有效性，证明了该框架在保证安全性的同时具有良好的可扩展性。

Conclusion: RE-DPG框架成功地将博弈论协调与可达性分析相结合，为多智能体系统在动态不确定环境中的安全运动规划提供了理论保证和实用解决方案。

Abstract: Ensuring safe, robust, and scalable motion planning for multi-agent systems in dynamic and uncertain environments is a persistent challenge, driven by complex inter-agent interactions, stochastic disturbances, and model uncertainties. To overcome these challenges, particularly the computational complexity of coupled decision-making and the need for proactive safety guarantees, we propose a Reachability-Enhanced Dynamic Potential Game (RE-DPG) framework, which integrates game-theoretic coordination into reachability analysis. This approach formulates multi-agent coordination as a dynamic potential game, where the Nash equilibrium (NE) defines optimal control strategies across agents. To enable scalability and decentralized execution, we develop a Neighborhood-Dominated iterative Best Response (ND-iBR) scheme, built upon an iterated $\varepsilon$-BR (i$\varepsilon$-BR) process that guarantees finite-step convergence to an $\varepsilon$-NE. This allows agents to compute strategies based on local interactions while ensuring theoretical convergence guarantees. Furthermore, to ensure safety under uncertainty, we integrate a Multi-Agent Forward Reachable Set (MA-FRS) mechanism into the cost function, explicitly modeling uncertainty propagation and enforcing collision avoidance constraints. Through both simulations and real-world experiments in 2D and 3D environments, we validate the effectiveness of RE-DPG across diverse operational scenarios.

</details>


### [592] [Variable Impedance Control for Floating-Base Supernumerary Robotic Leg in Walking Assistance](https://arxiv.org/abs/2511.12184)
*Jun Huo,Kehan Xu,Chengyao Li,Yu Cao,Jie Zuo,Xinxing Chen,Jian Huang*

Main category: cs.RO

TL;DR: 提出了一种用于超冗余机械腿(SRL)系统的混合位置/力阻抗控制方法，通过可变阻抗控制(VIC)动态调整阻抗参数，实现刚柔状态的平滑切换，提高人机交互的安全性和适应性。


<details>
  <summary>Details</summary>
Motivation: 在浮基机器人系统中，确保在内外干扰下的力控制安全性至关重要。超冗余机械腿系统作为典型的松散耦合浮基系统，特别容易受到强内部干扰的影响。

Method: 研究了松散耦合SRL的动力学模型，设计了混合位置/力阻抗控制器来适应动态扭矩输入。开发了高效的VIC方法，通过动态调整阻抗参数增强人机交互。专门设计了实时稳定性保证的阻抗参数生成网络。

Result: 仿真和实验验证了系统的有效性，系统能够在柔性状态下保持平滑信号过渡，在刚性状态下提供强力支撑。

Conclusion: 该方法为人机交互中适应个体步态变化提供了实用解决方案，显著提高了人机系统的安全性和适应性。

Abstract: In human-robot systems, ensuring safety during force control in the presence of both internal and external disturbances is crucial. As a typical loosely coupled floating-base robot system, the supernumerary robotic leg (SRL) system is particularly susceptible to strong internal disturbances. To address the challenge posed by floating base, we investigated the dynamics model of the loosely coupled SRL and designed a hybrid position/force impedance controller to fit dynamic torque input. An efficient variable impedance control (VIC) method is developed to enhance human-robot interaction, particularly in scenarios involving external force disturbances. By dynamically adjusting impedance parameters, VIC improves the dynamic switching between rigidity and flexibility, so that it can adapt to unknown environmental disturbances in different states. An efficient real-time stability guaranteed impedance parameters generating network is specifically designed for the proposed SRL, to achieve shock mitigation and high rigidity supporting. Simulations and experiments validate the system's effectiveness, demonstrating its ability to maintain smooth signal transitions in flexible states while providing strong support forces in rigid states. This approach provides a practical solution for accommodating individual gait variations in interaction, and significantly advances the safety and adaptability of human-robot systems.

</details>


### [593] [Innovative Design of Multi-functional Supernumerary Robotic Limbs with Ellipsoid Workspace Optimization](https://arxiv.org/abs/2511.12186)
*Jun Huo,Jian Huang,Jie Zuo,Bo Yang,Zhongzheng Fu,Xi Li,Samer Mohammed*

Main category: cs.RO

TL;DR: 提出了一种用于超数机器人肢体（SRL）的多目标优化设计理论，整合了抓握/行走工作空间相似性、坐站转换支撑力和质量惯性等指标，通过改进的萤火虫算法优化，实验验证了功能提升效果。


<details>
  <summary>Details</summary>
Motivation: 设计通用型SRL设备面临挑战，需要统一框架满足上下肢的多样化功能需求，特别是康复患者和健康人群的不同应用场景。

Method: 开发几何向量量化方法（椭球体表示工作空间），引入多子群修正萤火虫算法处理高维不规则帕累托前沿，整合抓握/行走工作空间相似性、坐站转换静态支撑力、质量惯性等多目标优化。

Result: 优化后原型实验显示：抓握成功率平均提升7.2%，行走和坐站转换任务的肌肉活动分别降低12.7%和25.1%，六名健康参与者和两名偏瘫患者的实验验证了有效性。

Conclusion: 该设计理论为多功能SRL机制提供了高效设计选项，通过多目标优化平衡了不同功能需求，显著提升了实际应用性能。

Abstract: Supernumerary robotic limbs (SRLs) offer substantial potential in both the rehabilitation of hemiplegic patients and the enhancement of functional capabilities for healthy individuals. Designing a general-purpose SRL device is inherently challenging, particularly when developing a unified theoretical framework that meets the diverse functional requirements of both upper and lower limbs. In this paper, we propose a multi-objective optimization (MOO) design theory that integrates grasping workspace similarity, walking workspace similarity, braced force for sit-to-stand (STS) movements, and overall mass and inertia. A geometric vector quantification method is developed using an ellipsoid to represent the workspace, aiming to reduce computational complexity and address quantification challenges. The ellipsoid envelope transforms workspace points into ellipsoid attributes, providing a parametric description of the workspace. Furthermore, the STS static braced force assesses the effectiveness of force transmission. The overall mass and inertia restricts excessive link length. To facilitate rapid and stable convergence of the model to high-dimensional irregular Pareto fronts, we introduce a multi-subpopulation correction firefly algorithm. This algorithm incorporates a strategy involving attractive and repulsive domains to effectively handle the MOO task. The optimized solution is utilized to redesign the prototype for experimentation to meet specified requirements. Six healthy participants and two hemiplegia patients participated in real experiments. Compared to the pre-optimization results, the average grasp success rate improved by 7.2%, while the muscle activity during walking and STS tasks decreased by an average of 12.7% and 25.1%, respectively. The proposed design theory offers an efficient option for the design of multi-functional SRL mechanisms.

</details>


### [594] [Locally Optimal Solutions to Constraint Displacement Problems via Path-Obstacle Overlaps](https://arxiv.org/abs/2511.12203)
*Antony Thomas,Fulvio Mastrogiovanni,Marco Baglietto*

Main category: cs.RO

TL;DR: 提出了一种统一的方法来解决约束位移问题，通过两阶段过程计算局部最优的障碍物位移以使机器人找到可行路径。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在有障碍物环境中寻找可行路径时，需要通过位移约束或障碍物来创造可行路径的问题。

Method: 采用两阶段过程：第一阶段计算通过障碍物的轨迹并最小化目标函数；第二阶段位移障碍物使计算出的机器人轨迹可行且无碰撞。

Result: 提供了多个成功示例，在两个不同的约束位移问题类别上验证了方法的有效性。

Conclusion: 该方法能够成功解决约束位移问题，为机器人路径规划提供了一种有效的解决方案。

Abstract: We present a unified approach for constraint displacement problems in which a robot finds a feasible path by displacing constraints or obstacles. To this end, we propose a two stage process that returns locally optimal obstacle displacements to enable a feasible path for the robot. The first stage proceeds by computing a trajectory through the obstacles while minimizing an appropriate objective function. In the second stage, these obstacles are displaced to make the computed robot trajectory feasible, that is, collision-free. Several examples are provided that successfully demonstrate our approach on two distinct classes of constraint displacement problems.

</details>


### [595] [SocialNav-Map: Dynamic Mapping with Human Trajectory Prediction for Zero-Shot Social Navigation](https://arxiv.org/abs/2511.12232)
*Lingfeng Zhang,Erjia Xiao,Xiaoshuai Hao,Haoxiang Fu,Zeying Gong,Long Chen,Xiaojun Liang,Renjing Xu,Hangjun Ye,Wenbo Ding*

Main category: cs.RO

TL;DR: SocialNav-Map是一个零样本社交导航框架，结合动态人体轨迹预测和占用地图，无需环境特定训练即可实现安全高效导航


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的方法需要2000+小时训练且难以泛化到陌生环境，限制了实际应用

Method: 将任务目标位置转换到地图坐标系，创建包含预测人体运动的动态占用地图，使用历史预测和方向预测两种互补方法进行人体轨迹预测

Result: 在Social-HM3D和Social-MP3D数据集上显著优于SOTA方法，碰撞率降低10%以上，无需新环境训练

Conclusion: 通过消除环境特定训练需求，SocialNav-Map实现了优越的导航性能，为现实世界社交导航系统部署铺平道路

Abstract: Social navigation in densely populated dynamic environments poses a significant challenge for autonomous mobile robots, requiring advanced strategies for safe interaction. Existing reinforcement learning (RL)-based methods require over 2000+ hours of extensive training and often struggle to generalize to unfamiliar environments without additional fine-tuning, limiting their practical application in real-world scenarios. To address these limitations, we propose SocialNav-Map, a novel zero-shot social navigation framework that combines dynamic human trajectory prediction with occupancy mapping, enabling safe and efficient navigation without the need for environment-specific training. Specifically, SocialNav-Map first transforms the task goal position into the constructed map coordinate system. Subsequently, it creates a dynamic occupancy map that incorporates predicted human movements as dynamic obstacles. The framework employs two complementary methods for human trajectory prediction: history prediction and orientation prediction. By integrating these predicted trajectories into the occupancy map, the robot can proactively avoid potential collisions with humans while efficiently navigating to its destination. Extensive experiments on the Social-HM3D and Social-MP3D datasets demonstrate that SocialNav-Map significantly outperforms state-of-the-art (SOTA) RL-based methods, which require 2,396 GPU hours of training. Notably, it reduces human collision rates by over 10% without necessitating any training in novel environments. By eliminating the need for environment-specific training, SocialNav-Map achieves superior navigation performance, paving the way for the deployment of social navigation systems in real-world environments characterized by diverse human behaviors. The code is available at: https://github.com/linglingxiansen/SocialNav-Map.

</details>


### [596] [Intermittent Rendezvous Plans with Mixed Integer Linear Program for Large-Scale Multi-Robot Exploration](https://arxiv.org/abs/2511.12237)
*Alysson Ribeiro da Silva,Luiz Chaimowicz*

Main category: cs.RO

TL;DR: 该论文提出了一个针对通信受限多机器人探索问题的MILP规划方法和RTUS跟踪机制，解决了在未知环境中无法生成最优计划和跟踪现实轨迹的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的多机器人探索系统在通信约束下存在局限性：机会主义方法效率不足，预规划方法需要先验环境知识。作者之前的工作虽然提出了间歇通信框架，但无法生成最优计划且缺乏现实轨迹跟踪机制。

Method: 提出MRE-CCIC问题，使用混合整数线性规划(MILP)生成会合计划，并基于RTUS机制设计策略来跟踪计划，考虑未知环境条件。

Result: 在Gazebo仿真的大规模环境中评估，结果表明该方法能够及时跟踪计划并高效完成任务。

Conclusion: 该方法能够有效解决通信受限多机器人探索问题，提供了开源实现，适用于实际部署。

Abstract: Multi-Robot Exploration (MRE) systems with communication constraints have proven efficient in accomplishing a variety of tasks, including search-and-rescue, stealth, and military operations. While some works focus on opportunistic approaches for efficiency, others concentrate on pre-planned trajectories or scheduling for increased interpretability. However, scheduling usually requires knowledge of the environment beforehand, which prevents its deployment in several domains due to related uncertainties (e.g., underwater exploration). In our previous work, we proposed an intermittent communications framework for MRE under communication constraints that uses scheduled rendezvous events to mitigate such limitations. However, the system was unable to generate optimal plans and had no mechanisms to follow the plan considering realistic trajectories, which is not suited for real-world deployments. In this work, we further investigate the problem by formulating the Multi-Robot Exploration with Communication Constraints and Intermittent Connectivity (MRE-CCIC) problem. We propose a Mixed-Integer Linear Program (MILP) formulation to generate rendezvous plans and a policy to follow them based on the Rendezvous Tracking for Unknown Scenarios (RTUS) mechanism. The RTUS is a simple rule to allow robots to follow the assigned plan, considering unknown conditions. Finally, we evaluated our method in a large-scale environment configured in Gazebo simulations. The results suggest that our method can follow the plan promptly and accomplish the task efficiently. We provide an open-source implementation of both the MILP plan generator and the large-scale MRE-CCIC.

</details>


### [597] [SAC-MoE: Reinforcement Learning with Mixture-of-Experts for Control of Hybrid Dynamical Systems with Uncertainty](https://arxiv.org/abs/2511.12361)
*Leroy D'Souza,Akash Karthikeyan,Yash Vardhan Pant,Sebastian Fischmeister*

Main category: cs.RO

TL;DR: 提出了SAC-MoE方法，将Soft Actor-Critic框架中的actor建模为混合专家模型，通过学习路由器自适应选择专家，解决了混合动力系统中不可观测模式和切换事件的挑战。


<details>
  <summary>Details</summary>
Motivation: 混合动力系统存在不可观测的潜在参数和切换事件，传统基于模型的控制方法无法处理这种不确定性，而标准无模型强化学习方法无法适应突然的模式切换，导致泛化能力差。

Method: 使用混合专家模型（MoE）构建SAC框架的actor，通过学习路由器自适应选择专家；开发基于课程学习的训练算法，优先在挑战性场景中收集数据；在混合自主赛车和腿式机器人任务中进行仿真验证。

Result: 在零样本泛化到未见环境方面，SAC-MoE比基线方法性能提升高达6倍；课程学习策略在所有评估策略中均能持续提升性能；定性分析显示MoE路由器能够为不同的潜在模式激活不同的专家。

Conclusion: SAC-MoE方法有效解决了混合动力系统中不可观测模式和切换事件的挑战，显著提升了零样本泛化能力，课程学习策略进一步增强了方法的鲁棒性。

Abstract: Hybrid dynamical systems result from the interaction of continuous-variable dynamics with discrete events and encompass various systems such as legged robots, vehicles and aircrafts. Challenges arise when the system's modes are characterized by unobservable (latent) parameters and the events that cause system dynamics to switch between different modes are also unobservable. Model-based control approaches typically do not account for such uncertainty in the hybrid dynamics, while standard model-free RL methods fail to account for abrupt mode switches, leading to poor generalization.
  To overcome this, we propose SAC-MoE which models the actor of the Soft Actor-Critic (SAC) framework as a Mixture-of-Experts (MoE) with a learned router that adaptively selects among learned experts. To further improve robustness, we develop a curriculum-based training algorithm to prioritize data collection in challenging settings, allowing better generalization to unseen modes and switching locations. Simulation studies in hybrid autonomous racing and legged locomotion tasks show that SAC-MoE outperforms baselines (up to 6x) in zero-shot generalization to unseen environments. Our curriculum strategy consistently improves performance across all evaluated policies. Qualitative analysis shows that the interpretable MoE router activates different experts for distinct latent modes.

</details>


### [598] [Multilaminate piezoelectric PVDF actuators to enhance performance of soft micro robots](https://arxiv.org/abs/2511.12380)
*Nicholas Gunter,Heiko Kabutz,Kaushik Jayaram*

Main category: cs.RO

TL;DR: 该研究开发并表征了多层PVDF压电致动器，通过并联电压分布实现高性能，填补了脆性PZT堆栈和低带宽软聚合物致动器之间的设计空白。


<details>
  <summary>Details</summary>
Motivation: 多层PVDF压电致动器是提升软微机器人系统性能的有前景方法，旨在在脆性高力PZT堆栈和柔顺但低带宽软聚合物致动器之间建立独特的设计空间。

Method: 开发并表征多层PVDF致动器，采用并联电压分布，研究层厚度和层数对性能的影响，并与第一性原理模型进行验证。

Result: 通过参数调整，实现了>3mm自由偏转、>20mN阻塞力和≥500Hz频率的致动器，工作电压低至150V。集成到平面移动微机器人中，利用共振实现具有抗大扰动鲁棒性的运动。

Conclusion: 多层PVDF致动器在性能上填补了现有致动器的空白，展示了在微机器人集成中的潜力，特别是通过共振机制实现鲁棒运动。

Abstract: Multilayer piezoelectric polyvinylidene fluoride (PVDF) actuators are a promising approach to enhance performance of soft microrobotic systems. In this work, we develop and characterize multilayer PVDF actuators with parallel voltage distribution across each layer, bridging a unique design space between brittle high-force PZT stacks and compliant but lower-bandwidth soft polymer actuators. We show the effects of layer thickness and number of layers in actuator performance and their agreement with a first principles model. By varying these parameters, we demonstrate actuators capable of >3 mm of free deflection, >20 mN of blocked force, and >=500 Hz, while operating at voltages as low as 150 volts. To illustrate their potential for robotic integration, we integrate our actuators into a planar, translating microrobot that leverages resonance to achieve locomotion with robustness to large perturbations.

</details>


### [599] [Evaluating Model-Agnostic Meta-Learning on MetaWorld ML10 Benchmark: Fast Adaptation in Robotic Manipulation Tasks](https://arxiv.org/abs/2511.12383)
*Sanjar Atamuradov*

Main category: cs.RO

TL;DR: 本文评估了MAML-TRPO在MetaWorld ML10基准测试中的表现，展示了该方法在多样化机器人操作任务中的少样本适应能力，同时揭示了泛化差距和任务间性能差异的问题。


<details>
  <summary>Details</summary>
Motivation: 元学习算法能够使机器人系统以最少的数据快速适应新任务，这对于现实世界的机器人应用至关重要。本文旨在研究梯度基元学习在多样化机器人操作任务中的实际效果。

Method: 采用模型无关元学习（MAML）结合信任域策略优化（TRPO）的方法，在包含10个不同机器人操作任务的MetaWorld ML10基准上进行实验，分析其学习通用初始化参数以实现少样本适应的能力。

Result: MAML实现了有效的单样本适应，经过一次梯度更新后性能明显提升：训练任务最终成功率为21.0%，测试任务为13.2%。但存在泛化差距，测试任务性能停滞而训练任务性能持续提升。不同操作技能的适应效果差异很大，成功率从0%到80%不等。

Conclusion: 梯度基元学习在多样化机器人操作任务中展现出潜力，但仍存在局限性。未来工作需要关注任务感知适应和结构化策略架构的方向。

Abstract: Meta-learning algorithms enable rapid adaptation to new tasks with minimal data, a critical capability for real-world robotic systems. This paper evaluates Model-Agnostic Meta-Learning (MAML) combined with Trust Region Policy Optimization (TRPO) on the MetaWorld ML10 benchmark, a challenging suite of ten diverse robotic manipulation tasks. We implement and analyze MAML-TRPO's ability to learn a universal initialization that facilitates few-shot adaptation across semantically different manipulation behaviors including pushing, picking, and drawer manipulation. Our experiments demonstrate that MAML achieves effective one-shot adaptation with clear performance improvements after a single gradient update, reaching final success rates of 21.0% on training tasks and 13.2% on held-out test tasks. However, we observe a generalization gap that emerges during meta-training, where performance on test tasks plateaus while training task performance continues to improve. Task-level analysis reveals high variance in adaptation effectiveness, with success rates ranging from 0% to 80% across different manipulation skills. These findings highlight both the promise and current limitations of gradient-based meta-learning for diverse robotic manipulation, and suggest directions for future work in task-aware adaptation and structured policy architectures.

</details>


### [600] [Learning Adaptive Neural Teleoperation for Humanoid Robots: From Inverse Kinematics to End-to-End Control](https://arxiv.org/abs/2511.12390)
*Sanjar Atamuradov*

Main category: cs.RO

TL;DR: 提出基于学习的神经遥操作框架，用强化学习训练的策略替代传统的IK+PD控制器，显著提升人形机器人遥操作的自然性和鲁棒性


<details>
  <summary>Details</summary>
Motivation: 传统遥操作系统依赖逆运动学求解器和手动调谐的PD控制器，难以处理外力干扰、适应不同用户，且在动态条件下无法产生自然运动

Method: 学习直接将VR控制器输入映射到机器人关节命令的策略，在仿真中使用IK遥操作演示作为初始化，通过力随机化和轨迹平滑度奖励进行微调

Result: 在Unitree G1人形机器人上实验显示，学习策略相比IK基线跟踪误差降低34%，运动平滑度提升45%，具有更好的力适应能力，同时保持实时性能（50Hz控制频率）

Conclusion: 基于学习的方法可以显著改善人形机器人遥操作系统的自然性和鲁棒性

Abstract: Virtual reality (VR) teleoperation has emerged as a promising approach for controlling humanoid robots in complex manipulation tasks. However, traditional teleoperation systems rely on inverse kinematics (IK) solvers and hand-tuned PD controllers, which struggle to handle external forces, adapt to different users, and produce natural motions under dynamic conditions. In this work, we propose a learning-based neural teleoperation framework that replaces the conventional IK+PD pipeline with learned policies trained via reinforcement learning. Our approach learns to directly map VR controller inputs to robot joint commands while implicitly handling force disturbances, producing smooth trajectories, and adapting to user preferences. We train our policies in simulation using demonstrations collected from IK-based teleoperation as initialization, then fine-tune them with force randomization and trajectory smoothness rewards. Experiments on the Unitree G1 humanoid robot demonstrate that our learned policies achieve 34% lower tracking error, 45% smoother motions, and superior force adaptation compared to the IK baseline, while maintaining real-time performance (50Hz control frequency). We validate our approach on manipulation tasks including object pick-and-place, door opening, and bimanual coordination. These results suggest that learning-based approaches can significantly improve the naturalness and robustness of humanoid teleoperation systems.

</details>


### [601] [RoboAfford++: A Generative AI-Enhanced Dataset for Multimodal Affordance Learning in Robotic Manipulation and Navigation](https://arxiv.org/abs/2511.12436)
*Xiaoshuai Hao,Yingbo Tang,Lingfeng Zhang,Yanbiao Ma,Yunfeng Diao,Ziyu Jia,Wenbo Ding,Hangjun Ye,Long Chen*

Main category: cs.RO

TL;DR: 本文提出了RoboAfford++数据集和RoboAfford-Eval基准，用于解决视觉语言模型在物体和空间可操作性学习方面的不足，显著提升了机器人操作和导航中的可操作性推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在高级任务规划和场景理解方面表现出色，但缺乏对物理交互所需的具体位置（如功能抓取点和允许放置区域）的推理能力，这源于训练数据中缺乏细粒度的物体和空间可操作性标注。

Method: 构建了包含869,987张图像和200万问答标注的RoboAfford++数据集，涵盖物体可操作性识别、物体可操作性预测和空间可操作性定位三个关键任务；同时提出了包含338个样本的RoboAfford-Eval评估基准。

Result: 实验结果表明现有视觉语言模型在可操作性学习方面存在明显缺陷，而在RoboAfford++数据集上微调后，其物体和空间可操作性推理能力得到显著提升。

Conclusion: RoboAfford++数据集有效解决了视觉语言模型在可操作性学习方面的局限性，为机器人操作和导航提供了重要的数据支持，验证了该数据集的有效性。

Abstract: Robotic manipulation and navigation are fundamental capabilities of embodied intelligence, enabling effective robot interactions with the physical world. Achieving these capabilities requires a cohesive understanding of the environment, including object recognition to localize target objects, object affordances to identify potential interaction areas and spatial affordances to discern optimal areas for both object placement and robot movement. While Vision-Language Models (VLMs) excel at high-level task planning and scene understanding, they often struggle to infer actionable positions for physical interaction, such as functional grasping points and permissible placement regions. This limitation stems from the lack of fine-grained annotations for object and spatial affordances in their training datasets. To tackle this challenge, we introduce RoboAfford++, a generative AI-enhanced dataset for multimodal affordance learning for both robotic manipulation and navigation. Our dataset comprises 869,987 images paired with 2.0 million question answering (QA) annotations, covering three critical tasks: object affordance recognition to identify target objects based on attributes and spatial relationships, object affordance prediction to pinpoint functional parts for manipulation, and spatial affordance localization to identify free space for object placement and robot navigation. Complementing this dataset, we propose RoboAfford-Eval, a comprehensive benchmark for assessing affordance-aware prediction in real-world scenarios, featuring 338 meticulously annotated samples across the same three tasks. Extensive experimental results reveal the deficiencies of existing VLMs in affordance learning, while fine-tuning on the RoboAfford++ dataset significantly enhances their ability to reason about object and spatial affordances, validating the dataset's effectiveness.

</details>


### [602] [ClutterNav: Gradient-Guided Search for Efficient 3D Clutter Removal with Learned Costmaps](https://arxiv.org/abs/2511.12479)
*Navin Sriram Ravie,Keerthi Vasan M,Bijo Sebastian*

Main category: cs.RO

TL;DR: ClutterNav是一个用于密集杂物中目标物体检索的决策框架，通过连续强化学习平衡即时可移除性和长期目标暴露，实现接近人类水平的策略排序。


<details>
  <summary>Details</summary>
Motivation: 解决密集杂物中目标物体检索的挑战性问题，传统基于规则的方法计算开销大，端到端强化学习方法可解释性和泛化性差。

Method: 将问题建模为连续强化学习任务，使用可移除性批评器估计物体移除成本，结合积分梯度评估周围物体对目标可访问性的影响。

Result: 在仿真和真实实验中验证，实现了部分可观测环境中的实时、遮挡感知决策。

Conclusion: ClutterNav无需预定义启发式规则，能够动态平衡即时和长期目标，达到接近人类策略水平。

Abstract: Dense clutter removal for target object retrieval presents a challenging problem, especially when targets are embedded deep within densely-packed configurations. It requires foresight to minimize overall changes to the clutter configuration while accessing target objects, avoiding stack destabilization and reducing the number of object removals required. Rule-based planners when applied to this problem, rely on rigid heuristics, leading to high computational overhead. End-to-end reinforcement learning approaches struggle with interpretability and generalizability over different conditions. To address these issues, we present ClutterNav, a novel decision-making framework that can identify the next best object to be removed so as to access a target object in a given clutter, while minimising stack disturbances. ClutterNav formulates the problem as a continuous reinforcement learning task, where each object removal dynamically updates the understanding of the scene. A removability critic, trained from demonstrations, estimates the cost of removing any given object based on geometric and spatial features. This learned cost is complemented by integrated gradients that assess how the presence or removal of surrounding objects influences the accessibility of the target. By dynamically prioritizing actions that balance immediate removability against long-term target exposure, ClutterNav achieves near human-like strategic sequencing, without predefined heuristics. The proposed approach is validated extensively in simulation and over real-world experiments. The results demonstrate real-time, occlusion-aware decision-making in partially observable environments.

</details>


### [603] [Botany Meets Robotics in Alpine Scree Monitoring](https://arxiv.org/abs/2511.12526)
*Davide De Benedittis,Giovanni Di Lorenzo,Franco Angelini,Barbara Valle,Marina Serena Borgatti,Paolo Remagnino,Marco Caccianiga,Manolo Garabini*

Main category: cs.RO

TL;DR: 本文提出了一种利用腿式机器人监测高山碎石栖息地的新方法，通过ANYmal C机器人在意大利阿尔卑斯山区进行实地数据采集和植物物种识别，结合深度学习技术提高监测效率。


<details>
  <summary>Details</summary>
Motivation: 传统碎石栖息地监测需要专业科学家在偏远危险地区进行大量实地工作，过程资源密集且耗时。气候变化对这些高海拔栖息地构成严重威胁，需要更高效的监测方法。

Method: 部署ANYmal C腿式机器人在意大利阿尔卑斯生物区进行两年实地考察，利用深度学习技术检测和分类关键植物物种，并与传统植物社会学调查相结合。

Result: 结果表明敏捷腿式机器人能够导航复杂地形，提高碎石监测的频率和效率。机器人辅助协议不仅简化了野外操作，还增强了数据采集、存储和使用。

Conclusion: 这项研究为环境科学中机器人技术的应用做出了贡献，为更全面和可持续的栖息地监测与保护方法铺平了道路。

Abstract: According to the European Union's Habitat Directive, habitat monitoring plays a critical role in response to the escalating problems posed by biodiversity loss and environmental degradation. Scree habitats, hosting unique and often endangered species, face severe threats from climate change due to their high-altitude nature. Traditionally, their monitoring has required highly skilled scientists to conduct extensive fieldwork in remote, potentially hazardous locations, making the process resource-intensive and time-consuming. This paper presents a novel approach for scree habitat monitoring using a legged robot to assist botanists in data collection and species identification. Specifically, we deployed the ANYmal C robot in the Italian Alpine bio-region in two field campaigns spanning two years and leveraged deep learning to detect and classify key plant species of interest. Our results demonstrate that agile legged robots can navigate challenging terrains and increase the frequency and efficiency of scree monitoring. When paired with traditional phytosociological surveys performed by botanists, this robotics-assisted protocol not only streamlines field operations but also enhances data acquisition, storage, and usage. The outcomes of this research contribute to the evolving landscape of robotics in environmental science, paving the way for a more comprehensive and sustainable approach to habitat monitoring and preservation.

</details>


### [604] [EcoFlight: Finding Low-Energy Paths Through Obstacles for Autonomous Sensing Drones](https://arxiv.org/abs/2511.12618)
*Jordan Leyva,Nahim J. Moran Vera,Yihan Xu,Adrien Durasno,Christopher U. Romero,Tendai Chimuka,Gabriel O. Huezo Ramirez,Ziqian Dong,Roberto Rojas-Cessa*

Main category: cs.RO

TL;DR: EcoFlight是一种面向无人机的节能路径规划算法，能够在3D空间中考虑障碍物并找到能耗最低的飞行路径。


<details>
  <summary>Details</summary>
Motivation: 现有无人机路径规划方案很少考虑障碍物规避，而障碍物规避通常能耗较高，这对点到点无人机飞行的能效至关重要。

Method: 基于无人机推进系统和飞行动力学建立能耗模型，开发能量最优的路径规划算法，并与直线飞行和最短距离方案进行比较评估。

Result: 在各种障碍物密度下的仿真结果显示，EcoFlight始终能找到比同类算法能耗更低的路径，特别是在高密度障碍物环境中表现更优。合适的飞行速度还能进一步提升节能效果。

Conclusion: EcoFlight算法能够有效解决无人机在复杂环境中的节能路径规划问题，为实际应用提供了可行的解决方案。

Abstract: Obstacle avoidance path planning for uncrewed aerial vehicles (UAVs), or drones, is rarely addressed in most flight path planning schemes, despite obstacles being a realistic condition. Obstacle avoidance can also be energy-intensive, making it a critical factor in efficient point-to-point drone flights. To address these gaps, we propose EcoFlight, an energy-efficient pathfinding algorithm that determines the lowest-energy route in 3D space with obstacles. The algorithm models energy consumption based on the drone propulsion system and flight dynamics. We conduct extensive evaluations, comparing EcoFlight with direct-flight and shortest-distance schemes. The simulation results across various obstacle densities show that EcoFlight consistently finds paths with lower energy consumption than comparable algorithms, particularly in high-density environments. We also demonstrate that a suitable flying speed can further enhance energy savings.

</details>


### [605] [Task-Aware Morphology Optimization of Planar Manipulators via Reinforcement Learning](https://arxiv.org/abs/2511.12650)
*Arvind Kumar Mishra,Sohom Chakrabarty*

Main category: cs.RO

TL;DR: 使用强化学习进行平面机械臂形态优化，验证了RL能够仅通过奖励反馈重新发现已知解析最优解，并在无解析解的高维问题中表现出比网格搜索和黑盒优化更好的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 大多数形态设计任务没有闭式解，随着维度增加，网格或启发式搜索变得昂贵。探索RL作为可扩展的替代方案，用于形态优化问题。

Method: 使用Yoshikawa可操作性指标，在2R机械臂跟踪圆形路径的案例中验证RL方法（SAC、DDPG、PPO），并与网格搜索和黑盒优化器比较。然后将方法扩展到椭圆和矩形路径的完整形态向量优化。

Result: 所有方法在圆形路径案例中都收敛到解析最优解（等长连杆且第二关节垂直于第一关节）。在非解析设置的椭圆和矩形路径中，RL继续可靠收敛，而网格和黑盒方法需要更大的评估预算。

Conclusion: RL对于恢复已知最优解和解决无解析解的形态优化问题都有效，表明RL是形态优化的可扩展替代方案。

Abstract: In this work, Yoshikawa's manipulability index is used to investigate reinforcement learning (RL) as a framework for morphology optimization in planar robotic manipulators. A 2R manipulator tracking a circular end-effector path is first examined because this case has a known analytical optimum: equal link lengths and the second joint orthogonal to the first. This serves as a validation step to test whether RL can rediscover the optimum using reward feedback alone, without access to the manipulability expression or the Jacobian. Three RL algorithms (SAC, DDPG, and PPO) are compared with grid search and black-box optimizers, with morphology represented by a single action parameter phi that maps to the link lengths. All methods converge to the analytical solution, showing that numerical recovery of the optimum is possible without supplying analytical structure.
  Most morphology design tasks have no closed-form solutions, and grid or heuristic search becomes expensive as dimensionality increases. RL is therefore explored as a scalable alternative. The formulation used for the circular path is extended to elliptical and rectangular paths by expanding the action space to the full morphology vector (L1, L2, theta2). In these non-analytical settings, RL continues to converge reliably, whereas grid and black-box methods require far larger evaluation budgets. These results indicate that RL is effective for both recovering known optima and solving morphology optimization problems without analytical solutions.

</details>


### [606] [Prompt-Driven Domain Adaptation for End-to-End Autonomous Driving via In-Context RL](https://arxiv.org/abs/2511.12755)
*Aleesha Khurram,Amir Moeini,Shangtong Zhang,Rohan Chandra*

Main category: cs.RO

TL;DR: 提出了一种基于上下文强化学习（ICRL）的推理时少样本提示驱动领域自适应方法，用于恶劣天气条件下的闭环自动驾驶，无需模型参数更新或额外数据收集。


<details>
  <summary>Details</summary>
Motivation: 现有端到端自动驾驶系统在领域自适应（如从晴朗天气到恶劣天气）方面存在困难，传统方法需要大量目标域数据或重新训练模型，而现有的提示驱动DA方法仅限于感知任务且需要专家少样本数据。

Method: 使用上下文强化学习（ICRL）进行推理时少样本提示驱动领域自适应，利用推理过程中观察到的通用轨迹来扩展闭环驾驶能力，无需模型更新或额外数据收集。

Result: 在CARLA模拟器上的实验表明，与最先进的提示驱动DA基线相比，ICRL方法在目标域中产生了更安全、更高效、更舒适的驾驶策略。

Conclusion: ICRL方法成功将提示驱动DA扩展到闭环自动驾驶领域，为恶劣天气条件下的自动驾驶提供了有效的少样本领域自适应解决方案。

Abstract: Despite significant progress and advances in autonomous driving, many end-to-end systems still struggle with domain adaptation (DA), such as transferring a policy trained under clear weather to adverse weather conditions. Typical DA strategies in the literature include collecting additional data in the target domain or re-training the model, or both. Both these strategies quickly become impractical as we increase scale and complexity of driving. These limitations have encouraged investigation into few-shot and zero-shot prompt-driven DA at inference time involving LLMs and VLMs. These methods work by adding a few state-action trajectories during inference to the prompt (similar to in-context learning). However, there are two limitations of such an approach: $(i)$ prompt-driven DA methods are currently restricted to perception tasks such as detection and segmentation and $(ii)$ they require expert few-shot data. In this work, we present a new approach to inference-time few-shot prompt-driven DA for closed-loop autonomous driving in adverse weather condition using in-context reinforcement learning (ICRL). Similar to other prompt-driven DA methods, our approach does not require any updates to the model parameters nor does it require additional data collection in adversarial weather regime. Furthermore, our approach advances the state-of-the-art in prompt-driven DA by extending to closed driving using general trajectories observed during inference. Our experiments using the CARLA simulator show that ICRL results in safer, more efficient, and more comfortable driving policies in the target domain compared to state-of-the-art prompt-driven DA baselines.

</details>


### [607] [DR. Nav: Semantic-Geometric Representations for Proactive Dead-End Recovery and Navigation](https://arxiv.org/abs/2511.12778)
*Vignesh Rajagopal,Kasun Weerakoon Kulathun Mudiyanselage,Gershom Devake Seneviratne,Pon Aswin Sankaralingam,Mohamed Elnoor,Jing Liang,Rohan Chandra,Dinesh Manocha*

Main category: cs.RO

TL;DR: DR.Nav是一种新型自主导航方法，专注于在非结构化环境中进行死胡同检测和恢复，通过RGB-LiDAR跨模态融合和贝叶斯推理实现实时语义成本地图生成。


<details>
  <summary>Details</summary>
Motivation: 解决在非结构化环境中（如角落、植被遮挡和阻塞路口）机器人导航时死胡同检测和恢复的关键问题，特别是在无地图环境中需要主动策略的情况。

Method: 采用RGB-LiDAR跨模态融合与基于注意力的过滤，通过贝叶斯推理持续更新每个单元的死亡概率和恢复点，将恢复感知风险明确纳入导航成本地图。

Result: 在密集室内外场景中评估显示，检测准确率提高83.33%，目标到达时间减少52.4%，优于DWA、MPPI和Nav2 DWB等先进规划器。

Conclusion: DR.Nav通过统一的死胡同预测和恢复方法，显著提升了在非结构化环境中的导航安全性和效率。

Abstract: We present DR. Nav (Dead-End Recovery-aware Navigation), a novel approach to autonomous navigation in scenarios where dead-end detection and recovery are critical, particularly in unstructured environments where robots must handle corners, vegetation occlusions, and blocked junctions. DR. Nav introduces a proactive strategy for navigation in unmapped environments without prior assumptions. Our method unifies dead-end prediction and recovery by generating a single, continuous, real-time semantic cost map. Specifically, DR. Nav leverages cross-modal RGB-LiDAR fusion with attention-based filtering to estimate per-cell dead-end likelihoods and recovery points, which are continuously updated through Bayesian inference to enhance robustness. Unlike prior mapping methods that only encode traversability, DR. Nav explicitly incorporates recovery-aware risk into the navigation cost map, enabling robots to anticipate unsafe regions and plan safer alternative trajectories. We evaluate DR. Nav across multiple dense indoor and outdoor scenarios and demonstrate an increase of 83.33% in accuracy in detection, a 52.4% reduction in time-to-goal (path efficiency), compared to state-of-the-art planners such as DWA, MPPI, and Nav2 DWB. Furthermore, the dead-end classifier functions

</details>


### [608] [ActiveGrasp: Information-Guided Active Grasping with Calibrated Energy-based Model](https://arxiv.org/abs/2511.12795)
*Boshu Lei,Wen Jiang,Kostas Daniilidis*

Main category: cs.RO

TL;DR: 提出了一种基于能量校准的抓取姿态生成模型和主动视角选择方法，用于解决密集杂乱环境中的机器人抓取问题，通过SE(3)流形上的抓取分布估计信息增益来选择最优视角。


<details>
  <summary>Details</summary>
Motivation: 现有方法在密集杂乱环境抓取时要么忽视抓取分布对信息增益估计的重要性，要么依赖抓取分布的投影而忽略SE(3)流形上的结构特性，需要更有效的解决方案。

Method: 提出基于能量校准的模型来生成抓取姿态，该模型在SE(3)流形上捕捉抓取分布的多模态特性，并将能量水平校准到抓取成功率。通过基于重建环境的条件分布估计信息增益来选择下一个最佳视角。

Result: 在模拟环境和真实机器人设置上的实验表明，与现有最先进模型相比，该方法能够在有限视角预算下成功抓取杂乱环境中的物体。

Conclusion: 该方法有效解决了密集杂乱环境下的机器人抓取问题，所构建的模拟环境可作为未来主动抓取研究的可复现平台。

Abstract: Grasping in a densely cluttered environment is a challenging task for robots. Previous methods tried to solve this problem by actively gathering multiple views before grasp pose generation. However, they either overlooked the importance of the grasp distribution for information gain estimation or relied on the projection of the grasp distribution, which ignores the structure of grasp poses on the SE(3) manifold. To tackle these challenges, we propose a calibrated energy-based model for grasp pose generation and an active view selection method that estimates information gain from grasp distribution. Our energy-based model captures the multi-modality nature of grasp distribution on the SE(3) manifold. The energy level is calibrated to the success rate of grasps so that the predicted distribution aligns with the real distribution. The next best view is selected by estimating the information gain for grasp from the calibrated distribution conditioned on the reconstructed environment, which could efficiently drive the robot to explore affordable parts of the target object. Experiments on simulated environments and real robot setups demonstrate that our model could successfully grasp objects in a cluttered environment with limited view budgets compared to previous state-of-the-art models. Our simulated environment can serve as a reproducible platform for future research on active grasping. The source code of our paper will be made public when the paper is released to the public.

</details>


### [609] [Structured Imitation Learning of Interactive Policies through Inverse Games](https://arxiv.org/abs/2511.12848)
*Max M. Sun,Todd Murphey*

Main category: cs.RO

TL;DR: 提出了一个结构化模仿学习框架，用于学习交互式策略，通过结合生成式单智能体策略学习和博弈论结构来处理多智能体交互中的行为复杂性。


<details>
  <summary>Details</summary>
Motivation: 解决在共享空间中与人类协调的交互式策略学习问题，因为多智能体交互的行为复杂性远高于非交互任务，而现有的生成模型方法在这方面仍面临挑战。

Method: 采用两阶段学习框架：首先使用标准模仿学习从多智能体演示中学习个体行为模式，然后通过解决逆博弈问题来结构化学习智能体间的依赖关系。

Result: 在合成的5智能体社交导航任务中，该方法显著改善了非交互策略，仅使用50个演示就达到了与真实交互策略相当的性能。

Conclusion: 结构化模仿学习在交互式环境中具有巨大潜力，能够有效处理多智能体协调问题。

Abstract: Generative model-based imitation learning methods have recently achieved strong results in learning high-complexity motor skills from human demonstrations. However, imitation learning of interactive policies that coordinate with humans in shared spaces without explicit communication remains challenging, due to the significantly higher behavioral complexity in multi-agent interactions compared to non-interactive tasks. In this work, we introduce a structured imitation learning framework for interactive policies by combining generative single-agent policy learning with a flexible yet expressive game-theoretic structure. Our method explicitly separates learning into two steps: first, we learn individual behavioral patterns from multi-agent demonstrations using standard imitation learning; then, we structurally learn inter-agent dependencies by solving an inverse game problem. Preliminary results in a synthetic 5-agent social navigation task show that our method significantly improves non-interactive policies and performs comparably to the ground truth interactive policy using only 50 demonstrations. These results highlight the potential of structured imitation learning in interactive settings.

</details>


### [610] [Towards High-Consistency Embodied World Model with Multi-View Trajectory Videos](https://arxiv.org/abs/2511.12882)
*Taiyi Su,Jian Zhu,Yaxuan Li,Chong Ma,Zitai Huang,Yichen Zhu,Hanli Wang,Yi Xu*

Main category: cs.RO

TL;DR: MTV-World提出了一种多视角轨迹视频控制的具身世界模型，通过将3D原始动作投影到2D图像并采用多视角框架来补偿空间信息损失，实现精确的机器人运动控制和物理交互建模。


<details>
  <summary>Details</summary>
Motivation: 现有具身世界模型难以将低级动作准确转换为预测帧中的精确机器人运动，导致与现实世界物理交互不一致。为了解决低层级动作控制精度不足的问题，需要新的控制方法。

Method: 采用轨迹视频作为控制信号，通过相机内外参和笛卡尔空间变换获得；引入多视角框架补偿空间信息损失；基于多视角轨迹视频预测未来帧；开发自动评估管道使用多模态大模型和参考视频对象分割模型。

Result: 在复杂双臂场景中，MTV-World实现了精确的控制执行和准确的物理交互建模，通过Jaccard指数评估显示具有高空间一致性。

Conclusion: MTV-World通过多视角轨迹视频控制有效解决了现有模型在精确机器人运动预测方面的局限性，为具身智能的物理交互建模提供了新思路。

Abstract: Embodied world models aim to predict and interact with the physical world through visual observations and actions. However, existing models struggle to accurately translate low-level actions (e.g., joint positions) into precise robotic movements in predicted frames, leading to inconsistencies with real-world physical interactions. To address these limitations, we propose MTV-World, an embodied world model that introduces Multi-view Trajectory-Video control for precise visuomotor prediction. Specifically, instead of directly using low-level actions for control, we employ trajectory videos obtained through camera intrinsic and extrinsic parameters and Cartesian-space transformation as control signals. However, projecting 3D raw actions onto 2D images inevitably causes a loss of spatial information, making a single view insufficient for accurate interaction modeling. To overcome this, we introduce a multi-view framework that compensates for spatial information loss and ensures high-consistency with physical world. MTV-World forecasts future frames based on multi-view trajectory videos as input and conditioning on an initial frame per view. Furthermore, to systematically evaluate both robotic motion precision and object interaction accuracy, we develop an auto-evaluation pipeline leveraging multimodal large models and referring video object segmentation models. To measure spatial consistency, we formulate it as an object location matching problem and adopt the Jaccard Index as the evaluation metric. Extensive experiments demonstrate that MTV-World achieves precise control execution and accurate physical interaction modeling in complex dual-arm scenarios.

</details>


### [611] [Air-Chamber Based Soft Six-Axis Force/Torque Sensor for Human-Robot Interaction](https://arxiv.org/abs/2511.12896)
*Jun Huo,Hongge Ru,Bo Yang,Xingjian Chen,Xi Li,Jian Huang*

Main category: cs.RO

TL;DR: 本文提出了一种基于16通道气压计的软气室型六轴力/扭矩传感器，采用刚柔分层结构解耦方法，将六轴解耦问题简化为两个三轴解耦问题，实现了软性且精确的六维力测量。


<details>
  <summary>Details</summary>
Motivation: 软性多轴力/扭矩传感器能提供安全精确的力交互，但六轴传感器存在交叉轴耦合问题，导致校准困难和精度下降，开发软性且精确的六轴传感器具有挑战性。

Method: 采用超弹性硅胶气室封装16通道气压计，提出基于刚柔分层结构的有效解耦方法，通过有限元模拟和实验验证方法可行性。

Result: 原型传感器测量范围为50N力和1Nm扭矩，平均偏差、重复性、非线性和迟滞分别为4.9%、2.7%、5.8%和6.7%，在保持软性的同时表现出满意的传感性能。

Conclusion: 该软气室型六轴力/扭矩传感器通过创新的解耦方法成功解决了交叉轴耦合问题，实现了软性结构与精确测量的平衡，为安全力交互应用提供了可行解决方案。

Abstract: Soft multi-axis force/torque sensors provide safe and precise force interaction. Capturing the complete degree-of-freedom of force is imperative for accurate force measurement with six-axis force/torque sensors. However, cross-axis coupling can lead to calibration issues and decreased accuracy. In this instance, developing a soft and accurate six-axis sensor is a challenging task. In this paper, a soft air-chamber type six-axis force/torque sensor with 16-channel barometers is introduced, which housed in hyper-elastic air chambers made of silicone rubber. Additionally, an effective decoupling method is proposed, based on a rigid-soft hierarchical structure, which reduces the six-axis decoupling problem to two three-axis decoupling problems. Finite element model simulation and experiments demonstrate the compatibility of the proposed approach with reality. The prototype's sensing performance is quantitatively measured in terms of static load response, dynamic load response and dynamic response characteristic. It possesses a measuring range of 50 N force and 1 Nm torque, and the average deviation, repeatability, non-linearity and hysteresis are 4.9$\%$, 2.7$\%$, 5.8$\%$ and 6.7$\%$, respectively. The results indicate that the prototype exhibits satisfactory sensing performance while maintaining its softness due to the presence of soft air chambers.

</details>


### [612] [TOPP-DWR: Time-Optimal Path Parameterization of Differential-Driven Wheeled Robots Considering Piecewise-Constant Angular Velocity Constraints](https://arxiv.org/abs/2511.12910)
*Yong Li,Yujun Huang,Yi Chen,Hui Cheng*

Main category: cs.RO

TL;DR: 提出了TOPP-DWR算法，一种针对差速驱动轮式机器人的时间最优路径参数化方法，考虑了角速度约束，解决了现有方法忽略角速度和关节速度约束的问题。


<details>
  <summary>Details</summary>
Motivation: 现有时间最优路径参数化研究通常忽略角速度和关节速度约束，导致实际应用中控制性能下降，需要一种更实用的算法。

Method: 使用非均匀B样条表示初始轨迹，将角速度、关节速度、线速度和线加速度约束统一表示为线速度约束，引入松弛变量将问题重构为二阶锥规划问题。

Result: 比较实验验证了方法的优越性，定量性能指标显示TOPP-DWR能在遵守所有约束的同时实现时间最优路径参数化。

Conclusion: 现场自主导航实验验证了TOPP-DWR在实际应用中的实用性，为差速驱动轮式机器人提供了系统且实用的时间最优路径参数化解决方案。

Abstract: Differential-driven wheeled robots (DWR) represent the quintessential type of mobile robots and find extensive appli- cations across the robotic field. Most high-performance control approaches for DWR explicitly utilize the linear and angular velocities of the trajectory as control references. However, existing research on time-optimal path parameterization (TOPP) for mobile robots usually neglects the angular velocity and joint vel- ocity constraints, which can result in degraded control perfor- mance in practical applications. In this article, a systematic and practical TOPP algorithm named TOPP-DWR is proposed for DWR and other mobile robots. First, the non-uniform B-spline is adopted to represent the initial trajectory in the task space. Second, the piecewise-constant angular velocity, as well as joint velocity, linear velocity, and linear acceleration constraints, are incorporated into the TOPP problem. During the construction of the optimization problem, the aforementioned constraints are uniformly represented as linear velocity constraints. To boost the numerical computational efficiency, we introduce a slack variable to reformulate the problem into second-order-cone programming (SOCP). Subsequently, comparative experiments are conducted to validate the superiority of the proposed method. Quantitative performance indexes show that TOPP-DWR achieves TOPP while adhering to all constraints. Finally, field autonomous navigation experiments are carried out to validate the practicability of TOPP-DWR in real-world applications.

</details>


### [613] [DiffuDepGrasp: Diffusion-based Depth Noise Modeling Empowers Sim2Real Robotic Grasping](https://arxiv.org/abs/2511.12912)
*Yingting Zhou,Wenbo Cui,Weiheng Liu,Guixing Chen,Haoran Li,Dongbin Zhao*

Main category: cs.RO

TL;DR: DiffuDepGrasp是一个部署高效的sim2real框架，通过仅使用模拟数据进行策略训练实现零样本转移，解决了深度传感器噪声带来的sim2real差距问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在将模拟训练的深度策略转移到真实机器人时面临数据效率低和部署复杂的问题，传感器噪声严重阻碍策略转移效果。

Method: 提出Diffusion Depth Generator，包含两个模块：Diffusion Depth Module利用时间几何先验训练条件扩散模型捕获传感器噪声分布，Noise Grafting Module在注入感知伪影时保持度量精度。

Result: 在12个物体的抓取任务中达到95.7%的平均成功率，实现零样本转移并对未见物体具有强泛化能力。

Conclusion: DiffuDepGrasp通过仅使用原始深度输入消除了计算开销，有效解决了sim2real转移中的数据效率和部署复杂度挑战。

Abstract: Transferring the depth-based end-to-end policy trained in simulation to physical robots can yield an efficient and robust grasping policy, yet sensor artifacts in real depth maps like voids and noise establish a significant sim2real gap that critically impedes policy transfer. Training-time strategies like procedural noise injection or learned mappings suffer from data inefficiency due to unrealistic noise simulation, which is often ineffective for grasping tasks that require fine manipulation or dependency on paired datasets heavily. Furthermore, leveraging foundation models to reduce the sim2real gap via intermediate representations fails to mitigate the domain shift fully and adds computational overhead during deployment. This work confronts dual challenges of data inefficiency and deployment complexity. We propose DiffuDepGrasp, a deploy-efficient sim2real framework enabling zero-shot transfer through simulation-exclusive policy training. Its core innovation, the Diffusion Depth Generator, synthesizes geometrically pristine simulation depth with learned sensor-realistic noise via two synergistic modules. The first Diffusion Depth Module leverages temporal geometric priors to enable sample-efficient training of a conditional diffusion model that captures complex sensor noise distributions, while the second Noise Grafting Module preserves metric accuracy during perceptual artifact injection. With only raw depth inputs during deployment, DiffuDepGrasp eliminates computational overhead and achieves a 95.7% average success rate on 12-object grasping with zero-shot transfer and strong generalization to unseen objects.Project website: https://diffudepgrasp.github.io/.

</details>


### [614] [GUIDE: Gaussian Unified Instance Detection for Enhanced Obstacle Perception in Autonomous Driving](https://arxiv.org/abs/2511.12941)
*Chunyong Hu,Qi Luo,Jianyun Xu,Song Wang,Qiang Li,Sheng Yang*

Main category: cs.RO

TL;DR: GUIDE是一个利用3D高斯分布进行实例检测和占据预测的新框架，相比传统3D边界框方法能更好地处理不规则形状物体，并在nuScenes数据集上实现了21.61的实例占据mAP，比现有方法提升50%。


<details>
  <summary>Details</summary>
Motivation: 传统自动驾驶感知方法主要依赖3D边界框表示障碍物，但这种方法难以准确捕捉现实世界中不规则形状物体的复杂性。

Method: 采用稀疏表示策略，通过高斯到体素投射技术提供细粒度的实例级占据数据，避免了密集体素网格的计算负担。

Result: 在nuScenes数据集上的实验验证显示，GUIDE实现了21.61的实例占据mAP，比现有方法提升50%，同时具备竞争力的跟踪能力。

Conclusion: GUIDE为自动驾驶感知系统设立了新标准，有效结合了精度和计算效率，能更好地应对现实驾驶环境的复杂性。

Abstract: In the realm of autonomous driving, accurately detecting surrounding obstacles is crucial for effective decision-making. Traditional methods primarily rely on 3D bounding boxes to represent these obstacles, which often fail to capture the complexity of irregularly shaped, real-world objects. To overcome these limitations, we present GUIDE, a novel framework that utilizes 3D Gaussians for instance detection and occupancy prediction. Unlike conventional occupancy prediction methods, GUIDE also offers robust tracking capabilities. Our framework employs a sparse representation strategy, using Gaussian-to-Voxel Splatting to provide fine-grained, instance-level occupancy data without the computational demands associated with dense voxel grids. Experimental validation on the nuScenes dataset demonstrates GUIDE's performance, with an instance occupancy mAP of 21.61, marking a 50\% improvement over existing methods, alongside competitive tracking capabilities. GUIDE establishes a new benchmark in autonomous perception systems, effectively combining precision with computational efficiency to better address the complexities of real-world driving environments.

</details>


### [615] [SplatSearch: Instance Image Goal Navigation for Mobile Robots using 3D Gaussian Splatting and Diffusion Models](https://arxiv.org/abs/2511.12972)
*Siddarth Narasimhan,Matthew Lisondra,Haitong Wang,Goldie Nejat*

Main category: cs.RO

TL;DR: SplatSearch是一种解决实例图像目标导航问题的新架构，利用稀疏视图3D高斯泼溅重建和多方视角扩散模型，结合新颖的前沿探索策略，在未知环境中高效搜索特定目标。


<details>
  <summary>Details</summary>
Motivation: 实例图像目标导航问题在参考图像视角任意且机器人只能使用稀疏视图场景重建时具有挑战性，需要更鲁棒的解决方案。

Method: 使用稀疏在线3D高斯泼溅地图渲染候选对象的多视角图像，采用多视角扩散模型补全缺失区域，通过特征匹配与目标图像对比，并引入基于语义和视觉上下文的前沿探索策略。

Result: 在真实感家居和真实世界环境中的大量实验表明，SplatSearch在成功率和成功路径长度方面优于当前最先进方法。

Conclusion: SplatSearch通过结合3D重建、图像补全和语义感知探索策略，有效解决了复杂环境下的实例图像目标导航问题。

Abstract: The Instance Image Goal Navigation (IIN) problem requires mobile robots deployed in unknown environments to search for specific objects or people of interest using only a single reference goal image of the target. This problem can be especially challenging when: 1) the reference image is captured from an arbitrary viewpoint, and 2) the robot must operate with sparse-view scene reconstructions. In this paper, we address the IIN problem, by introducing SplatSearch, a novel architecture that leverages sparse-view 3D Gaussian Splatting (3DGS) reconstructions. SplatSearch renders multiple viewpoints around candidate objects using a sparse online 3DGS map, and uses a multi-view diffusion model to complete missing regions of the rendered images, enabling robust feature matching against the goal image. A novel frontier exploration policy is introduced which uses visual context from the synthesized viewpoints with semantic context from the goal image to evaluate frontier locations, allowing the robot to prioritize frontiers that are semantically and visually relevant to the goal image. Extensive experiments in photorealistic home and real-world environments validate the higher performance of SplatSearch against current state-of-the-art methods in terms of Success Rate and Success Path Length. An ablation study confirms the design choices of SplatSearch.

</details>


### [616] [CUTE-Planner: Confidence-aware Uneven Terrain Exploration Planner](https://arxiv.org/abs/2511.12984)
*Miryeong Park,Dongjin Cho,Sanghyun Kim,Younggun Cho*

Main category: cs.RO

TL;DR: 提出一个集成安全路径生成、自适应置信度更新和置信度感知探索策略的框架，用于行星探索机器人在复杂地形中的导航和地图构建。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理复杂地形（如陨石坑）的高程估计不确定性方面存在不足，缺乏不确定性降低的探索策略，且未充分考虑高程不确定性对导航安全和地图质量的影响。

Method: 使用基于卡尔曼滤波的高程估计方法生成地形可通行性和置信度评分，并将其集成到基于图的探索规划器（GBP）中，优先探索可通行的低置信度区域。

Result: 通过模拟月球实验评估，使用新的低置信度区域比例指标，实现了69%的不确定性降低。任务成功率方面，本文方法达到100%，而基线GBP为0%。

Conclusion: 该方法在探索安全性和地图可靠性方面有显著改进，能够有效处理行星探索中的地形不确定性挑战。

Abstract: Planetary exploration robots must navigate uneven terrain while building reliable maps for space missions. However, most existing methods incorporate traversability constraints but may not handle high uncertainty in elevation estimates near complex features like craters, do not consider exploration strategies for uncertainty reduction, and typically fail to address how elevation uncertainty affects navigation safety and map quality. To address the problems, we propose a framework integrating safe path generation, adaptive confidence updates, and confidence-aware exploration strategies. Using Kalman-based elevation estimation, our approach generates terrain traversability and confidence scores, then incorporates them into Graph-Based exploration Planner (GBP) to prioritize exploration of traversable low-confidence regions. We evaluate our framework through simulated lunar experiments using a novel low-confidence region ratio metric, achieving 69% uncertainty reduction compared to baseline GBP. In terms of mission success rate, our method achieves 100% while baseline GBP achieves 0%, demonstrating improvements in exploration safety and map reliability.

</details>


### [617] [APP: A* Post-Processing Algorithm for Robots with Bidirectional Shortcut and Path Perturbation](https://arxiv.org/abs/2511.13042)
*Yong Li,Hui Cheng*

Main category: cs.RO

TL;DR: 提出了一种针对A*等图搜索规划器的后处理算法APP，通过双向顶点缩减和路径扰动来优化路径长度和减少不必要的方向变化


<details>
  <summary>Details</summary>
Motivation: A*等规划器生成的路径通常不是最短的，且在无障碍物区域存在不必要的方向变化（锯齿模式），这与人类直觉不符

Method: 基于成本图开发APP算法：1）双向顶点缩减算法处理路径和环境不对称性；2）迭代路径扰动算法局部减少方向变化并提高平滑度

Result: 实验表明APP在规划时间、路径长度和方向变化数量方面优于现有方法，现场导航实验验证了实用性

Conclusion: APP算法能有效优化图搜索规划器的路径质量，提高路径平滑度和导航效率

Abstract: Paths generated by A* and other graph-search-based planners are widely used in the robotic field. Due to the restricted node-expansion directions, the resulting paths are usually not the shortest. Besides, unnecessary heading changes, or zig-zag patterns, exist even when no obstacle is nearby, which is inconsistent with the human intuition that the path segments should be straight in wide-open space due to the absence of obstacles. This article puts forward a general and systematic post-processing algorithm for A* and other graph-search-based planners. The A* post-processing algorithm, called APP, is developed based on the costmap, which is widely used in commercial service robots. First, a bidirectional vertices reduction algorithm is proposed to tackle the asymm- etry of the path and the environments. During the forward and backward vertices reduction, a thorough shortcut strategy is put forward to improve the path-shortening performance and avoid unnecessary heading changes. Second, an iterative path perturbation algorithm is adopted to locally reduce the number of unnecessary heading changes and improve the path smooth- ness. Comparative experiments are then carried out to validate the superiority of the proposed method. Quantitative performance indexes show that APP outperforms the existing methods in planning time, path length as well as the number of unnecessary heading changes. Finally, field navigation experiments are carried out to verify the practicability of APP.

</details>


### [618] [Unidirectional-Road-Network-Based Global Path Planning for Cleaning Robots in Semi-Structured Environments](https://arxiv.org/abs/2511.13048)
*Yong Li,Hui Cheng*

Main category: cs.RO

TL;DR: 提出了一种用于半结构化环境清洁机器人的全局路径规划方法，通过构建单向道路网络和混合策略，在遵守交通规则约束的同时优化路径长度。


<details>
  <summary>Details</summary>
Motivation: 现有全局路径规划方法要么忽视交通规则约束导致频繁重规划和碰撞风险，要么严格遵守道路网络导致路径过长，无法在半结构化环境中平衡路径长度和交通规则一致性。

Method: 构建单向道路网络表示交通约束，采用混合策略允许在起点和终点处穿越道路以获得更短路径，特别提出双层势能图处理复杂交叉口情况。

Result: 实验验证表明，相比现有方法，该方法在路径长度和道路网络一致性之间取得了更好的平衡。

Conclusion: 该方法为半结构化环境中的全局路径规划提供了一个通用且系统的解决方案，显著提高了导航效率。

Abstract: Practical global path planning is critical for commercializing cleaning robots working in semi-structured environments. In the literature, global path planning methods for free space usually focus on path length and neglect the traffic rule constraints of the environments, which leads to high-frequency re-planning and increases collision risks. In contrast, those for structured environments are developed mainly by strictly complying with the road network representing the traffic rule constraints, which may result in an overlong path that hinders the overall navigation efficiency. This article proposes a general and systematic approach to improve global path planning performance in semi-structured environments. A unidirectional road network is built to represent the traffic constraints in semi-structured environments and a hybrid strategy is proposed to achieve a guaranteed planning result.Cutting across the road at the starting and the goal points are allowed to achieve a shorter path. Especially, a two-layer potential map is proposed to achieve a guaranteed performance when the starting and the goal points are in complex intersections. Comparative experiments are carried out to validate the effectiveness of the proposed method. Quantitative experimental results show that, compared with the state-of-art, the proposed method guarantees a much better balance between path length and the consistency with the road network.

</details>


### [619] [Orientation-Free Neural Network-Based Bias Estimation for Low-Cost Stationary Accelerometers](https://arxiv.org/abs/2511.13071)
*Michal Levin,Itzik Klein*

Main category: cs.RO

TL;DR: 提出一种无需传感器方向信息的模型无关学习校准方法，用于在静止条件下估计加速度计偏置，无需旋转传感器即可实现快速现场部署。


<details>
  <summary>Details</summary>
Motivation: 低成本MEMS加速度计在导航和运动传感中广泛应用，但其性能受偏置误差影响。传统校准方法需要传感器水平放置或复杂的方向相关程序，限制了实际应用。

Method: 开发了一种基于学习的模型无关校准方法，在静止条件下估计加速度计偏置，无需知道传感器方向或进行旋转操作。

Result: 在6个加速度计收集的13.39小时数据集上进行实验验证，该方法比传统技术误差降低52%以上。

Conclusion: 该方法为无方向场景下的精确校准提供了实用解决方案，提高了低成本惯性传感器的可靠性，消除了水平校准的需求。

Abstract: Low-cost micro-electromechanical accelerometers are widely used in navigation, robotics, and consumer devices for motion sensing and position estimation. However, their performance is often degraded by bias errors. To eliminate deterministic bias terms a calibration procedure is applied under stationary conditions. It requires accelerom- eter leveling or complex orientation-dependent calibration procedures. To overcome those requirements, in this paper we present a model-free learning-based calibration method that estimates accelerometer bias under stationary conditions, without requiring knowledge of the sensor orientation and without the need to rotate the sensors. The proposed approach provides a fast, practical, and scalable solution suitable for rapid field deployment. Experimental validation on a 13.39-hour dataset collected from six accelerometers shows that the proposed method consistently achieves error levels more than 52% lower than traditional techniques. On a broader scale, this work contributes to the advancement of accurate calibration methods in orientation-free scenarios. As a consequence, it improves the reliability of low-cost inertial sensors in diverse scientific and industrial applications and eliminates the need for leveled calibration.

</details>


### [620] [ResAlignNet: A Data-Driven Approach for INS/DVL Alignment](https://arxiv.org/abs/2511.13096)
*Guy Damari,Itzik Klein*

Main category: cs.RO

TL;DR: ResAlignNet是一种基于1D ResNet-18架构的数据驱动方法，将传感器对准问题转化为深度神经网络优化，实现快速收敛和无需外部定位辅助的自主水下航行器导航对准。


<details>
  <summary>Details</summary>
Motivation: 传统基于模型的传感器对准方法存在收敛时间长、依赖预设运动模式和外部辅助传感器等问题，限制了水下航行器的操作灵活性。

Method: 使用1D ResNet-18架构，通过Sim2Real迁移学习能力，在合成数据上训练后部署到实际传感器测量中，实现传感器无关的对准解决方案。

Result: 在Snapir自主水下航行器上的实验验证表明，ResAlignNet仅需25秒数据采集即可实现0.8°以内的对准精度，相比标准速度方法收敛时间减少65%。

Conclusion: 该方法消除了运动模式要求，无需冗长的任务前准备程序即可立即部署航行器，通过鲁棒的传感器无关对准技术提升了水下导航能力。

Abstract: Autonomous underwater vehicles rely on precise navigation systems that combine the inertial navigation system and the Doppler velocity log for successful missions in challenging environments where satellite navigation is unavailable. The effectiveness of this integration critically depends on accurate alignment between the sensor reference frames. Standard model-based alignment methods between these sensor systems suffer from lengthy convergence times, dependence on prescribed motion patterns, and reliance on external aiding sensors, significantly limiting operational flexibility. To address these limitations, this paper presents ResAlignNet, a data-driven approach using the 1D ResNet-18 architecture that transforms the alignment problem into deep neural network optimization, operating as an in-situ solution that requires only sensors on board without external positioning aids or complex vehicle maneuvers, while achieving rapid convergence in seconds. Additionally, the approach demonstrates the learning capabilities of Sim2Real transfer, enabling training in synthetic data while deploying in operational sensor measurements. Experimental validation using the Snapir autonomous underwater vehicle demonstrates that ResAlignNet achieves alignment accuracy within 0.8° using only 25 seconds of data collection, representing a 65\% reduction in convergence time compared to standard velocity-based methods. The trajectory-independent solution eliminates motion pattern requirements and enables immediate vehicle deployment without lengthy pre-mission procedures, advancing underwater navigation capabilities through robust sensor-agnostic alignment that scales across different operational scenarios and sensor specifications.

</details>


### [621] [Count Every Rotation and Every Rotation Counts: Exploring Drone Dynamics via Propeller Sensing](https://arxiv.org/abs/2511.13100)
*Xuecheng Chen,Jingao Xu,Wenhua Ding,Haoyang Wang,Xinyu Luo,Ruiyang Duan,Jialong Chen,Xueqian Wang,Yunhao Liu,Xinlei Chen*

Main category: cs.RO

TL;DR: 提出了一种基于事件相机的无人机螺旋桨转速感知系统EventPro，通过专注螺旋桨转速显著提升无人机感知性能


<details>
  <summary>Details</summary>
Motivation: 随着无人机应用普及，地面非接触式无人机感知变得至关重要，但现有方法存在性能瓶颈

Method: 包含两个核心组件：Count Every Rotation（通过抑制事件相机环境噪声实现精确实时螺旋桨转速估计）和Every Rotation Counts（利用转速推断无人机内外动态）

Result: 在真实无人机配送场景中，系统达到3ms感知延迟，转速估计误差仅0.23%，飞行指令推断精度96.5%，结合其他感知模式时跟踪精度提升超22%

Conclusion: 专注于螺旋桨转速能显著改善无人机感知，EventPro系统在实时性、精度和实用性方面表现出色

Abstract: As drone-based applications proliferate, paramount contactless sensing of airborne drones from the ground becomes indispensable. This work demonstrates concentrating on propeller rotational speed will substantially improve drone sensing performance and proposes an event-camera-based solution, \sysname. \sysname features two components: \textit{Count Every Rotation} achieves accurate, real-time propeller speed estimation by mitigating ultra-high sensitivity of event cameras to environmental noise. \textit{Every Rotation Counts} leverages these speeds to infer both internal and external drone dynamics. Extensive evaluations in real-world drone delivery scenarios show that \sysname achieves a sensing latency of 3$ms$ and a rotational speed estimation error of merely 0.23\%. Additionally, \sysname infers drone flight commands with 96.5\% precision and improves drone tracking accuracy by over 22\% when combined with other sensing modalities. \textit{ Demo: {\color{blue}https://eventpro25.github.io/EventPro/.} }

</details>


### [622] [Monolithic Units: Actuation, Sensing, and Simulation for Integrated Soft Robot Design](https://arxiv.org/abs/2511.13120)
*Trevor Exley,Anderson Brazil Nardin,Petr Trunin,Diana Cafiso,Lucia Beccai*

Main category: cs.RO

TL;DR: 本文介绍了一种用于软体机器人的单块单元（MU）构建模块，集成了气动驱动、柔性晶格结构和光学波导传感功能，通过参数化设计框架和优化方法实现了机械性能保持与嵌入式传感的结合。


<details>
  <summary>Details</summary>
Motivation: 开发一种可重复制造、可扩展的单块软体机器人构建模块，解决传统软体机器人中驱动、结构和传感组件分离的问题，实现集成化设计和嵌入式传感。

Method: 采用参数化设计框架建立驱动腔尺寸与晶格单元尺寸的确定性关系；通过实验均质化获取材料属性用于有限元仿真；将传感器布局作为离散优化问题，从晶格节点候选路径中选择最优配置。

Result: 优化模型经过制造和实验验证，成功保持了机械性能同时实现了嵌入式传感；该方法进一步扩展到缩放单元和双指夹持器，证明了MU概念的通用性。

Conclusion: 该方法通过结合可重复的协同设计规则和基于仿真的传感器集成，推动了单块软体机器人设计的发展，为软体机器人提供了可靠的构建模块和工作流程。

Abstract: This work introduces the Monolithic Unit (MU), an actuator-lattice-sensor building block for soft robotics. The MU integrates pneumatic actuation, a compliant lattice envelope, and candidate sites for optical waveguide sensing into a single printed body. In order to study reproducibility and scalability, a parametric design framework establishes deterministic rules linking actuator chamber dimensions to lattice unit cell size. Experimental homogenization of lattice specimens provides effective material properties for finite element simulation. Within this simulation environment, sensor placement is treated as a discrete optimization problem, where a finite set of candidate waveguide paths derived from lattice nodes is evaluated by introducing local stiffening, and the configuration minimizing deviation from baseline mechanical response is selected. Optimized models are fabricated and experimentally characterized, validating the preservation of mechanical performance while enabling embedded sensing. The workflow is further extended to scaled units and a two-finger gripper, demonstrating generality of the MU concept. This approach advances monolithic soft robotic design by combining reproducible co-design rules with simulation-informed sensor integration.

</details>


### [623] [Collision-Free Navigation of Mobile Robots via Quadtree-Based Model Predictive Control](https://arxiv.org/abs/2511.13188)
*Osama Al Sheikh Ali,Sotiris Koutsoftas,Ze Zhang,Knut Akesson,Emmanuel Dean*

Main category: cs.RO

TL;DR: 提出了一种用于自主移动机器人（AMR）的集成导航框架，将环境表示、轨迹生成和模型预测控制（MPC）统一起来，通过四叉树方法生成结构化的无碰撞区域作为安全走廊和MPC约束。


<details>
  <summary>Details</summary>
Motivation: 为了解决AMR在复杂环境中高效可靠导航的问题，避免直接编码障碍物带来的计算复杂性，需要一个能够统一环境表示和运动控制的集成框架。

Method: 使用四叉树方法从占据地图生成结构化、轴对齐的无碰撞区域，这些区域作为安全走廊的基础和MPC中的线性约束。完整流程包括安全区域提取、连通图构建、轨迹生成和B样条平滑。

Result: 实验结果表明，该方法在复杂环境中相比基线方法具有一致的优越性能。

Conclusion: 该集成导航框架通过统一的环境表示和运动控制，实现了AMR在复杂环境中的高效可靠导航，无需直接编码障碍物。

Abstract: This paper presents an integrated navigation framework for Autonomous Mobile Robots (AMRs) that unifies environment representation, trajectory generation, and Model Predictive Control (MPC). The proposed approach incorporates a quadtree-based method to generate structured, axis-aligned collision-free regions from occupancy maps. These regions serve as both a basis for developing safe corridors and as linear constraints within the MPC formulation, enabling efficient and reliable navigation without requiring direct obstacle encoding. The complete pipeline combines safe-area extraction, connectivity graph construction, trajectory generation, and B-spline smoothing into one coherent system. Experimental results demonstrate consistent success and superior performance compared to baseline approaches across complex environments.

</details>


### [624] [PIGEON: VLM-Driven Object Navigation via Points of Interest Selection](https://arxiv.org/abs/2511.13207)
*Cheng Peng,Zhenzhe Zhang,Cheng Chi,Xiaobao Wei,Yanhao Zhang,Heng Wang,Pengwei Wang,Zhongyuan Wang,Jing Liu,Shanghang Zhang*

Main category: cs.RO

TL;DR: PIGEON提出了一种基于兴趣点引导的探索方法，通过视觉语言模型选择兴趣点并配合低级规划器提高决策频率，在物体导航任务中实现零样本迁移的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前方法在未知环境中导航到指定物体时难以平衡决策频率与智能性，导致决策缺乏前瞻性或动作不连续。

Method: 使用PIGEON-VL视觉语言模型选择探索过程中形成的兴趣点，配合低级规划器输出动作，同时生成适用于模拟器的可验证奖励强化学习数据。

Result: 在经典物体导航基准测试中，零样本迁移方法达到SOTA性能，RLVR进一步增强了模型的语义引导能力。

Conclusion: PIGEON方法通过兴趣点引导探索和分层决策机制，有效解决了物体导航中的决策频率与智能性平衡问题，实现了实时导航中的深度推理。

Abstract: Navigating to a specified object in an unknown environment is a fundamental yet challenging capability of embodied intelligence. However, current methods struggle to balance decision frequency with intelligence, resulting in decisions lacking foresight or discontinuous actions. In this work, we propose PIGEON: Point of Interest Guided Exploration for Object Navigation with VLM, maintaining a lightweight and semantically aligned snapshot memory during exploration as semantic input for the exploration strategy. We use a large Visual-Language Model (VLM), named PIGEON-VL, to select Points of Interest (PoI) formed during exploration and then employ a lower-level planner for action output, increasing the decision frequency. Additionally, this PoI-based decision-making enables the generation of Reinforcement Learning with Verifiable Reward (RLVR) data suitable for simulators. Experiments on classic object navigation benchmarks demonstrate that our zero-shot transfer method achieves state-of-the-art performance, while RLVR further enhances the model's semantic guidance capabilities, enabling deep reasoning during real-time navigation.

</details>


### [625] [GaRLILEO: Gravity-aligned Radar-Leg-Inertial Enhanced Odometry](https://arxiv.org/abs/2511.13216)
*Chiyun Noh,Sangwoo Jung,Hanjun Kim,Yafei Hu,Laura Herlant,Ayoung Kim*

Main category: cs.RO

TL;DR: GaRLILEO是一个新颖的重力对齐连续时间雷达-腿-惯性里程计框架，通过解耦IMU速度并构建连续时间自我速度样条，结合软S2约束重力因子，显著提高了腿式机器人在复杂地形下的垂直姿态估计精度。


<details>
  <summary>Details</summary>
Motivation: 传统腿式机器人的里程计估计方法存在不可抑制的垂直漂移问题，特别是在特征稀疏或重复场景中，现有基于LiDAR或相机的方法容易退化，而IMU加速度的双重积分也会带来误差。

Method: 提出GaRLILEO框架，通过从SoC雷达多普勒和腿运动学信息构建连续时间自我速度样条来解耦IMU速度，实现无缝传感器融合。同时引入新颖的软S2约束重力因子来可靠捕获准确的重力向量。

Result: 在自收集的真实世界数据集上评估，GaRLILEO在楼梯和斜坡等复杂地形上展示了最先进的精度，特别是在垂直里程计估计方面表现优异。

Conclusion: GaRLILEO提供了一种不依赖LiDAR或相机的鲁棒里程计解决方案，开源了数据集和算法以促进腿式机器人里程计和SLAM研究的进一步发展。

Abstract: Deployment of legged robots for navigating challenging terrains (e.g., stairs, slopes, and unstructured environments) has gained increasing preference over wheel-based platforms. In such scenarios, accurate odometry estimation is a preliminary requirement for stable locomotion, localization, and mapping. Traditional proprioceptive approaches, which rely on leg kinematics sensor modalities and inertial sensing, suffer from irrepressible vertical drift caused by frequent contact impacts, foot slippage, and vibrations, particularly affected by inaccurate roll and pitch estimation. Existing methods incorporate exteroceptive sensors such as LiDAR or cameras. Further enhancement has been introduced by leveraging gravity vector estimation to add additional observations on roll and pitch, thereby increasing the accuracy of vertical pose estimation. However, these approaches tend to degrade in feature-sparse or repetitive scenes and are prone to errors from double-integrated IMU acceleration. To address these challenges, we propose GaRLILEO, a novel gravity-aligned continuous-time radar-leg-inertial odometry framework. GaRLILEO decouples velocity from the IMU by building a continuous-time ego-velocity spline from SoC radar Doppler and leg kinematics information, enabling seamless sensor fusion which mitigates odometry distortion. In addition, GaRLILEO can reliably capture accurate gravity vectors leveraging a novel soft S2-constrained gravity factor, improving vertical pose accuracy without relying on LiDAR or cameras. Evaluated on a self-collected real-world dataset with diverse indoor-outdoor trajectories, GaRLILEO demonstrates state-of-the-art accuracy, particularly in vertical odometry estimation on stairs and slopes. We open-source both our dataset and algorithm to foster further research in legged robot odometry and SLAM. https://garlileo.github.io/GaRLILEO

</details>


### [626] [EL3DD: Extended Latent 3D Diffusion for Language Conditioned Multitask Manipulation](https://arxiv.org/abs/2511.13312)
*Jonas Bode,Raphael Memmesheimer,Sven Behnke*

Main category: cs.RO

TL;DR: 该论文提出了一种基于扩散模型的视觉运动策略框架，将视觉和文本输入结合生成精确的机器人轨迹，在CALVIN数据集上验证了其在操作任务和长时程任务序列中的性能提升。


<details>
  <summary>Details</summary>
Motivation: 让机器人在人类环境中执行任务需要强大的自然语言理解和物理任务应用能力，本文旨在利用扩散模型的能力来提升机器人操作性能。

Method: 采用扩散模型构建视觉运动策略框架，结合视觉和文本输入生成机器人轨迹；在训练时使用参考演示，使模型能够根据文本指令执行环境中的操作任务；改进现有模型的嵌入表示，并借鉴图像生成中的扩散模型技术。

Result: 在CALVIN数据集上的评估表明，该方法在各种操作任务上表现更好，在执行多个任务的序列时长时程成功率有所提高。

Conclusion: 该方法验证了扩散模型在机器人操作任务中的有效性，为通用多任务操作提供了有益贡献。

Abstract: Acting in human environments is a crucial capability for general-purpose robots, necessitating a robust understanding of natural language and its application to physical tasks. This paper seeks to harness the capabilities of diffusion models within a visuomotor policy framework that merges visual and textual inputs to generate precise robotic trajectories. By employing reference demonstrations during training, the model learns to execute manipulation tasks specified through textual commands within the robot's immediate environment. The proposed research aims to extend an existing model by leveraging improved embeddings, and adapting techniques from diffusion models for image generation. We evaluate our methods on the CALVIN dataset, proving enhanced performance on various manipulation tasks and an increased long-horizon success rate when multiple tasks are executed in sequence. Our approach reinforces the usefulness of diffusion models and contributes towards general multitask manipulation.

</details>


### [627] [ZeroDexGrasp: Zero-Shot Task-Oriented Dexterous Grasp Synthesis with Prompt-Based Multi-Stage Semantic Reasoning](https://arxiv.org/abs/2511.13327)
*Juntao Jian,Yi-Lin Wei,Chengjie Mou,Yuhao Lin,Xing Zhu,Yujun Shen,Wei-Shi Zheng,Ruizhen Hu*

Main category: cs.RO

TL;DR: 提出ZeroDexGrasp框架，通过多模态大语言模型和抓取优化的零样本任务导向灵巧抓取合成方法，解决现有方法对标注数据依赖性强、泛化能力差的问题。


<details>
  <summary>Details</summary>
Motivation: 现有任务导向灵巧抓取方法严重依赖昂贵的标注数据来确保任务语义对齐，难以在多样化对象和任务指令间泛化。

Method: 结合多模态大语言模型进行提示式多阶段语义推理，推断初始抓取配置和物体接触信息，然后利用接触引导的抓取优化来优化抓取姿态的物理可行性和任务对齐性。

Result: 实验结果表明，ZeroDexGrasp能够在未见过的物体类别和复杂任务需求上实现高质量的零样本灵巧抓取。

Conclusion: 该方法推动了更具泛化性和智能性的机器人抓取技术的发展。

Abstract: Task-oriented dexterous grasping holds broad application prospects in robotic manipulation and human-object interaction. However, most existing methods still struggle to generalize across diverse objects and task instructions, as they heavily rely on costly labeled data to ensure task-specific semantic alignment. In this study, we propose \textbf{ZeroDexGrasp}, a zero-shot task-oriented dexterous grasp synthesis framework integrating Multimodal Large Language Models with grasp refinement to generate human-like grasp poses that are well aligned with specific task objectives and object affordances. Specifically, ZeroDexGrasp employs prompt-based multi-stage semantic reasoning to infer initial grasp configurations and object contact information from task and object semantics, then exploits contact-guided grasp optimization to refine these poses for physical feasibility and task alignment. Experimental results demonstrate that ZeroDexGrasp enables high-quality zero-shot dexterous grasping on diverse unseen object categories and complex task requirements, advancing toward more generalizable and intelligent robotic grasping.

</details>


### [628] [Contact-Safe Reinforcement Learning with ProMP Reparameterization and Energy Awareness](https://arxiv.org/abs/2511.13459)
*Bingkun Huang,Yuhe Gong,Zewen Yang,Tianyu Ren,Luis Figueredo*

Main category: cs.RO

TL;DR: 本文提出了一种基于任务空间、能量安全的框架，结合PPO和运动基元来处理接触丰富的机器人操作任务，并在3D环境中实现了高性能和安全性。


<details>
  <summary>Details</summary>
Motivation: 传统的基于MDP的强化学习方法在机器人关节空间中应用，缺乏对3D环境的全面感知和接触丰富信息的考虑。传统方法忽视了任务空间操作中固有的接触丰富信息，特别是接触安全性和鲁棒性方面。

Method: 使用任务空间能量安全框架，结合近端策略优化（PPO）和运动基元生成可靠安全的任务空间轨迹。框架中加入了能量感知的笛卡尔阻抗控制器目标，确保机器人与环境之间的安全交互。

Result: 实验结果表明，该框架在3D环境中各种表面上的任务处理优于现有方法，实现了高成功率、平滑轨迹和能量安全交互。

Conclusion: 提出的任务空间能量安全框架在接触丰富的机器人操作任务中表现出色，为复杂环境下的安全交互提供了有效解决方案。

Abstract: Reinforcement learning (RL) approaches based on Markov Decision Processes (MDPs) are predominantly applied in the robot joint space, often relying on limited task-specific information and partial awareness of the 3D environment. In contrast, episodic RL has demonstrated advantages over traditional MDP-based methods in terms of trajectory consistency, task awareness, and overall performance in complex robotic tasks. Moreover, traditional step-wise and episodic RL methods often neglect the contact-rich information inherent in task-space manipulation, especially considering the contact-safety and robustness. In this work, contact-rich manipulation tasks are tackled using a task-space, energy-safe framework, where reliable and safe task-space trajectories are generated through the combination of Proximal Policy Optimization (PPO) and movement primitives. Furthermore, an energy-aware Cartesian Impedance Controller objective is incorporated within the proposed framework to ensure safe interactions between the robot and the environment. Our experimental results demonstrate that the proposed framework outperforms existing methods in handling tasks on various types of surfaces in 3D environments, achieving high success rates as well as smooth trajectories and energy-safe interactions.

</details>


### [629] [Towards Affect-Adaptive Human-Robot Interaction: A Protocol for Multimodal Dataset Collection on Social Anxiety](https://arxiv.org/abs/2511.13530)
*Vesna Poprcova,Iulia Lefter,Matthias Wieser,Martijn Warnier,Frances Brazier*

Main category: cs.RO

TL;DR: 该论文提出了一种用于收集反映社交焦虑的多模态数据集协议，该数据集包含同步的音频、视频和生理记录，旨在支持人机交互中社交焦虑的稳健多模态检测。


<details>
  <summary>Details</summary>
Motivation: 社交焦虑是一种普遍存在的状况，影响人际互动和社交功能。目前在人类-机器人交互背景下研究社交焦虑的多模态数据集稀缺，限制了研究和应用的进展。

Method: 设计了一个多模态数据集收集协议，从至少70名参与者中获取同步的音频、视频和生理记录，参与者根据社交焦虑水平分组，在与Furhat社交机器人进行约10分钟的Wizard-of-Oz角色扮演场景时收集数据。

Result: 该协议将产生一个包含多模态数据和上下文信息的丰富数据集，为研究提供支持。

Conclusion: 这项工作可以为情感自适应的人机交互研究做出贡献，通过提供对社交焦虑的稳健多模态检测支持。

Abstract: Social anxiety is a prevalent condition that affects interpersonal interactions and social functioning. Recent advances in artificial intelligence and social robotics offer new opportunities to examine social anxiety in the human-robot interaction context. Accurate detection of affective states and behaviours associated with social anxiety requires multimodal datasets, where each signal modality provides complementary insights into its manifestations. However, such datasets remain scarce, limiting progress in both research and applications. To address this, this paper presents a protocol for multimodal dataset collection designed to reflect social anxiety in a human-robot interaction context. The dataset will consist of synchronised audio, video, and physiological recordings acquired from at least 70 participants, grouped according to their level of social anxiety, as they engage in approximately 10-minute interactive Wizard-of-Oz role-play scenarios with the Furhat social robot under controlled experimental conditions. In addition to multimodal data, the dataset will be enriched with contextual data providing deeper insight into individual variability in social anxiety responses. This work can contribute to research on affect-adaptive human-robot interaction by providing support for robust multimodal detection of social anxiety.

</details>


### [630] [OpenRoboCare: A Multimodal Multi-Task Expert Demonstration Dataset for Robot Caregiving](https://arxiv.org/abs/2511.13707)
*Xiaoyu Liang,Ziang Liu,Kelvin Lin,Edward Gu,Ruolin Ye,Tam Nguyen,Cynthia Hsu,Zhanxin Wu,Xiaoman Yang,Christy Sum Yu Cheung,Harold Soh,Katherine Dimitropoulou,Tapomayukh Bhattacharjee*

Main category: cs.RO

TL;DR: OpenRoboCare是一个多模态机器人护理数据集，包含职业治疗师执行日常生活活动（ADLs）的专家演示，涵盖5种模态数据，旨在解决护理任务中复杂的物理人机交互挑战。


<details>
  <summary>Details</summary>
Motivation: 护理任务涉及复杂的物理人机交互，需要精确的遮挡感知、安全的物理接触和长时程规划。目前缺乏大规模、多样化且由专家驱动的真实世界护理数据集。

Method: 收集了21名职业治疗师在两个人偶上执行15项ADL任务的数据，数据集包含RGB-D视频、姿态跟踪、眼动追踪、任务动作标注和触觉传感五种模态。

Result: 数据集提供了护理人员运动、注意力、施力和任务执行策略的丰富多模态洞察，并展示了现有最先进的机器人感知和人类活动识别方法在该数据集上面临挑战。

Conclusion: OpenRoboCare为开发安全自适应的辅助机器人提供了宝贵资源，通过分析专家护理原则和策略，有助于提高机器人效率和任务可行性。

Abstract: We present OpenRoboCare, a multimodal dataset for robot caregiving, capturing expert occupational therapist demonstrations of Activities of Daily Living (ADLs). Caregiving tasks involve complex physical human-robot interactions, requiring precise perception under occlusions, safe physical contact, and long-horizon planning. While recent advances in robot learning from demonstrations have shown promise, there is a lack of a large-scale, diverse, and expert-driven dataset that captures real-world caregiving routines. To address this gap, we collect data from 21 occupational therapists performing 15 ADL tasks on two manikins. The dataset spans five modalities: RGB-D video, pose tracking, eye-gaze tracking, task and action annotations, and tactile sensing, providing rich multimodal insights into caregiver movement, attention, force application, and task execution strategies. We further analyze expert caregiving principles and strategies, offering insights to improve robot efficiency and task feasibility. Additionally, our evaluations demonstrate that OpenRoboCare presents challenges for state-of-the-art robot perception and human activity recognition methods, both critical for developing safe and adaptive assistive robots, highlighting the value of our contribution. See our website for additional visualizations: https://emprise.cs.cornell.edu/robo-care/.

</details>


### [631] [From Power to Precision: Learning Fine-grained Dexterity for Multi-fingered Robotic Hands](https://arxiv.org/abs/2511.13710)
*Jianglong Ye,Lai Wei,Guangqi Jiang,Changwei Jing,Xueyan Zou,Xiaolong Wang*

Main category: cs.RO

TL;DR: 该论文提出了一种联合优化多指灵巧手硬件设计和控制的方法，通过轻量化的指尖几何修改实现从力量抓取到精细操作的动态切换，显著提升了多指手的精细操作能力。


<details>
  <summary>Details</summary>
Motivation: 当前机器人手设计存在一个关键限制：难以在单一系统中同时实现稳定的力量抓取和精确的精细操作。多指手擅长力量抓取，但在需要精细操作的任务中，平行夹爪仍然更常用。

Method: 引入轻量化的指尖几何修改，将其表示为接触平面，并联合优化其参数和相应控制策略。控制策略在力量操作和精细操作之间动态切换，将精细控制简化为平行拇指-食指运动。利用大规模仿真和可微分神经物理替代模型优化指尖几何。

Result: 在仿真到现实的精细抓取中，对未见物体实现了82.5%的零样本成功率；在涉及面包夹取的真实世界挑战性任务中实现了93.3%的成功率。

Conclusion: 该协同设计框架可以显著增强多指手的精细操作能力，同时不降低其力量抓取能力，为解决机器人手设计的核心限制提供了有效方案。

Abstract: Human grasps can be roughly categorized into two types: power grasps and precision grasps. Precision grasping enables tool use and is believed to have influenced human evolution. Today's multi-fingered robotic hands are effective in power grasps, but for tasks requiring precision, parallel grippers are still more widely adopted. This contrast highlights a key limitation in current robotic hand design: the difficulty of achieving both stable power grasps and precise, fine-grained manipulation within a single, versatile system. In this work, we bridge this gap by jointly optimizing the control and hardware design of a multi-fingered dexterous hand, enabling both power and precision manipulation. Rather than redesigning the entire hand, we introduce a lightweight fingertip geometry modification, represent it as a contact plane, and jointly optimize its parameters along with the corresponding control. Our control strategy dynamically switches between power and precision manipulation and simplifies precision control into parallel thumb-index motions, which proves robust for sim-to-real transfer. On the design side, we leverage large-scale simulation to optimize the fingertip geometry using a differentiable neural-physics surrogate model. We validate our approach through extensive experiments in both sim-to-real and real-to-real settings. Our method achieves an 82.5% zero-shot success rate on unseen objects in sim-to-real precision grasping, and a 93.3% success rate in challenging real-world tasks involving bread pinching. These results demonstrate that our co-design framework can significantly enhance the fine-grained manipulation ability of multi-fingered hands without reducing their ability for power grasps. Our project page is at https://jianglongye.com/power-to-precision

</details>
