<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 320]
- [cs.LG](#cs.LG) [Total: 215]
- [cs.RO](#cs.RO) [Total: 65]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Multimodal AI for Body Fat Estimation: Computer Vision and Anthropometry with DEXA Benchmarks](https://arxiv.org/abs/2511.17576)
*Rayan Aldajani*

Main category: cs.CV

TL;DR: AI模型使用正面身体图像和基本人体测量数据作为低成本替代方案来估计体脂百分比，图像模型达到RMSE 4.44%和R² 0.807的精度


<details>
  <summary>Details</summary>
Motivation: 传统DEXA扫描等金标准方法昂贵且难以普及，需要开发低成本、易获取的体脂估算方法

Method: 开发了两种方法：基于ResNet的图像模型和使用人体测量数据的回归模型，构建了535个样本的数据集（253个人体测量样本和282个网络爬取图像样本）

Result: 图像模型在体脂百分比估算上表现良好，RMSE为4.44%，R²为0.807

Conclusion: AI辅助模型能够提供可访问且低成本的体脂估算，支持未来健康和健身领域的消费者应用

Abstract: Tracking body fat percentage is essential for effective weight management, yet gold-standard methods such as DEXA scans remain expensive and inaccessible for most people. This study evaluates the feasibility of artificial intelligence (AI) models as low-cost alternatives using frontal body images and basic anthropometric data. The dataset consists of 535 samples: 253 cases with recorded anthropometric measurements (weight, height, neck, ankle, and wrist) and 282 images obtained via web scraping from Reddit posts with self-reported body fat percentages, including some reported as DEXA-derived by the original posters. Because no public datasets exist for computer-vision-based body fat estimation, this dataset was compiled specifically for this study. Two approaches were developed: (1) ResNet-based image models and (2) regression models using anthropometric measurements. A multimodal fusion framework is also outlined for future expansion once paired datasets become available. The image-based model achieved a Root Mean Square Error (RMSE) of 4.44% and a Coefficient of Determination (R^2) of 0.807. These findings demonstrate that AI-assisted models can offer accessible and low-cost body fat estimates, supporting future consumer applications in health and fitness.

</details>


### [2] [Reconstruction-Driven Multimodal Representation Learning for Automated Media Understanding](https://arxiv.org/abs/2511.17596)
*Yassir Benhammou,Suman Kalyan,Sujay Kumar*

Main category: cs.CV

TL;DR: 提出了一个多模态自动编码器（MMAE），通过学习文本、音频和视觉数据的统一表示，实现广播内容元数据提取和语义聚类的端到端自动化。


<details>
  <summary>Details</summary>
Motivation: 现有AI系统通常只处理单一模态（如视频、音频或文本），限制了其对广播材料中复杂跨模态关系的理解能力。

Method: 使用多模态自动编码器，在LUMA数据集上训练，通过最小化跨模态的联合重构损失来发现模态不变的语义结构。

Result: 在聚类和对齐指标（Silhouette、ARI、NMI）上相比线性基线有显著改进。

Conclusion: 基于重构的多模态嵌入可以作为广播档案中可扩展元数据生成和跨模态检索的基础，有望提升现代广播工作流的自动化、可搜索性和内容管理效率。

Abstract: Broadcast and media organizations increasingly rely on artificial intelligence to automate the labor-intensive processes of content indexing, tagging, and metadata generation. However, existing AI systems typically operate on a single modality-such as video, audio, or text-limiting their understanding of complex, cross-modal relationships in broadcast material. In this work, we propose a Multimodal Autoencoder (MMAE) that learns unified representations across text, audio, and visual data, enabling end-to-end automation of metadata extraction and semantic clustering. The model is trained on the recently introduced LUMA dataset, a fully aligned benchmark of multimodal triplets representative of real-world media content. By minimizing joint reconstruction losses across modalities, the MMAE discovers modality-invariant semantic structures without relying on large paired or contrastive datasets. We demonstrate significant improvements in clustering and alignment metrics (Silhouette, ARI, NMI) compared to linear baselines, indicating that reconstruction-based multimodal embeddings can serve as a foundation for scalable metadata generation and cross-modal retrieval in broadcast archives. These results highlight the potential of reconstruction-driven multimodal learning to enhance automation, searchability, and content management efficiency in modern broadcast workflows.

</details>


### [3] [BCWildfire: A Long-term Multi-factor Dataset and Deep Learning Benchmark for Boreal Wildfire Risk Prediction](https://arxiv.org/abs/2511.17597)
*Zhengsen Xu,Sibo Cheng,Hongjie He,Lanying Wang,Wentao Sun,Jonathan Li,Lincoln Linlin Xu*

Main category: cs.CV

TL;DR: 提出一个覆盖25年、每日分辨率的野火数据集，包含240万公顷区域的38个协变量，评估多种时间序列预测模型，并分析不同驱动因素的相对重要性。


<details>
  <summary>Details</summary>
Motivation: 解决野火风险预测中公开基准数据集缺乏的问题，特别是支持长期时间建模、大规模空间覆盖和多模态驱动因素的数据集稀缺。

Method: 构建一个包含英属哥伦比亚及周边地区240万公顷区域的25年每日分辨率数据集，包含38个协变量（活跃火点检测、天气变量、燃料条件、地形特征和人为因素），并评估CNN、线性、Transformer和Mamba等多种时间序列预测模型。

Result: 提出了一个全面的野火数据集，并比较了不同模型的性能，同时研究了位置嵌入的有效性和不同火驱动因素的相对重要性。

Conclusion: 该数据集和代码为野火风险预测研究提供了有价值的基准资源，有助于推动数据驱动方法在野火预测中的应用。

Abstract: Wildfire risk prediction remains a critical yet challenging task due to the complex interactions among fuel conditions, meteorology, topography, and human activity. Despite growing interest in data-driven approaches, publicly available benchmark datasets that support long-term temporal modeling, large-scale spatial coverage, and multimodal drivers remain scarce. To address this gap, we present a 25-year, daily-resolution wildfire dataset covering 240 million hectares across British Columbia and surrounding regions. The dataset includes 38 covariates, encompassing active fire detections, weather variables, fuel conditions, terrain features, and anthropogenic factors. Using this benchmark, we evaluate a diverse set of time-series forecasting models, including CNN-based, linear-based, Transformer-based, and Mamba-based architectures. We also investigate effectiveness of position embedding and the relative importance of different fire-driving factors. The dataset and the corresponding code can be found at https://github.com/SynUW/mmFire

</details>


### [4] [Robustness of Structured Data Extraction from Perspectively Distorted Documents](https://arxiv.org/abs/2511.17607)
*Hyakka Nakada,Yoshiyasu Tanaka*

Main category: cs.CV

TL;DR: 本研究探讨了文档图像的透视畸变对多模态大语言模型数据提取准确性的影响，发现结构识别精度会显著下降，但可通过简单的旋转校正来改善。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的文档图像不仅存在平面旋转，还经常出现透视畸变，这些扰动会影响多模态LLMs的数据提取准确性，但目前缺乏系统性研究。

Method: 通过观察典型文档畸变，将其近似为等腰梯形变换，将参数从8个减少到2个（旋转角度和畸变比），然后在合成样本文档上评估Gemini-1.5-pro模型的性能。

Result: 文档畸变会显著降低结构识别精度（与阅读顺序正确性相关），而字符识别精度受影响较小。简单的旋转校正可以改善结构识别准确性。

Conclusion: 透视畸变对多模态LLMs的OCR任务性能有重要影响，特别是结构识别方面，但通过适当的预处理可以缓解这一问题，这对多模态LLMs的实际应用具有重要意义。

Abstract: Optical Character Recognition (OCR) for data extraction from documents is essential to intelligent informatics, such as digitizing medical records and recognizing road signs. Multi-modal Large Language Models (LLMs) can solve this task and have shown remarkable performance. Recently, it has been noticed that the accuracy of data extraction by multi-modal LLMs can be affected when in-plane rotations are present in the documents. However, real-world document images are usually not only in-plane rotated but also perspectively distorted. This study investigates the impacts of such perturbations on the data extraction accuracy for the state-of-the-art model, Gemini-1.5-pro. Because perspective distortions have a high degree of freedom, designing experiments in the same manner as single-parametric rotations is difficult. We observed typical distortions of document images and showed that most of them approximately follow an isosceles-trapezoidal transformation, which allows us to evaluate distortions with a small number of parameters. We were able to reduce the number of independent parameters from eight to two, i.e. rotation angle and distortion ratio. Then, specific entities were extracted from synthetically generated sample documents with varying these parameters. As the performance of LLMs, we evaluated not only a character-recognition accuracy but also a structure-recognition accuracy. Whereas the former represents the classical indicators for optical character recognition, the latter is related to the correctness of reading order. In particular, the structure-recognition accuracy was found to be significantly degraded by document distortion. In addition, we found that this accuracy can be improved by a simple rotational correction. This insight will contribute to the practical use of multi-modal LLMs for OCR tasks.

</details>


### [5] [3D Ground Truth Reconstruction from Multi-Camera Annotations Using UKF](https://arxiv.org/abs/2511.17609)
*Linh Van Ma,Unse Fatima,Tepy Sokun Chriv,Haroon Imran,Moongu Jeon*

Main category: cs.CV

TL;DR: 提出一种基于无迹卡尔曼滤波的新方法，将多摄像头2D标注融合为精确的3D地面真值，支持完整3D形状估计。


<details>
  <summary>Details</summary>
Motivation: 准确的3D地面真值对自动驾驶、监控和机器人应用至关重要，现有方法仅能提供地面平面信息。

Method: 使用无迹卡尔曼滤波器融合多摄像头校准后的2D边界框或关键点标注，通过单应性投影和UKF融合将2D坐标转换为3D世界坐标。

Result: 在CMC、Wildtrack和Panoptic数据集上验证，相比现有3D地面真值显示出高精度3D定位能力。

Conclusion: 该方法提供了可扩展的全自动解决方案，仅需2D图像标注即可输出完整3D物体形状，有效处理遮挡等挑战。

Abstract: Accurate 3D ground truth estimation is critical for applications such as autonomous navigation, surveillance, and robotics. This paper introduces a novel method that uses an Unscented Kalman Filter (UKF) to fuse 2D bounding box or pose keypoint ground truth annotations from multiple calibrated cameras into accurate 3D ground truth. By leveraging human-annotated ground-truth 2D, our proposed method, a multi-camera single-object tracking algorithm, transforms 2D image coordinates into robust 3D world coordinates through homography-based projection and UKF-based fusion. Our proposed algorithm processes multi-view data to estimate object positions and shapes while effectively handling challenges such as occlusion. We evaluate our method on the CMC, Wildtrack, and Panoptic datasets, demonstrating high accuracy in 3D localization compared to the available 3D ground truth. Unlike existing approaches that provide only ground-plane information, our method also outputs the full 3D shape of each object. Additionally, the algorithm offers a scalable and fully automatic solution for multi-camera systems using only 2D image annotations.

</details>


### [6] [Unified Low-Light Traffic Image Enhancement via Multi-Stage Illumination Recovery and Adaptive Noise Suppression](https://arxiv.org/abs/2511.17612)
*Siddiqua Namrah*

Main category: cs.CV

TL;DR: 提出了一种完全无监督的多阶段深度学习框架，用于增强低光照交通图像，通过分解图像为光照和反射率分量，并采用三个专门模块进行渐进式优化。


<details>
  <summary>Details</summary>
Motivation: 低光照交通图像在自动驾驶、智能交通和城市监控系统中存在能见度差、噪声、运动模糊、非均匀光照和眩光等问题，影响目标检测和场景理解任务的可靠性。

Method: 模型将图像分解为光照和反射率分量，通过三个模块进行优化：光照适应模块（全局和局部亮度校正）、反射率恢复模块（使用空间通道注意力抑制噪声和恢复结构细节）和过曝光补偿模块（重建饱和区域和平衡场景亮度）。网络采用自监督重建、反射率平滑度、感知一致性和领域感知正则化损失进行训练，无需配对真实图像。

Result: 在通用和交通专用数据集上的实验表明，该方法在定量指标（PSNR、SSIM、LPIPS、NIQE）和定性视觉质量上均优于现有最先进方法。

Conclusion: 该方法有效提升了低光照交通场景的能见度，保留了结构信息，并提高了下游感知任务的可靠性。

Abstract: Enhancing low-light traffic images is crucial for reliable perception in autonomous driving, intelligent transportation, and urban surveillance systems. Nighttime and dimly lit traffic scenes often suffer from poor visibility due to low illumination, noise, motion blur, non-uniform lighting, and glare from vehicle headlights or street lamps, which hinder tasks such as object detection and scene understanding. To address these challenges, we propose a fully unsupervised multi-stage deep learning framework for low-light traffic image enhancement. The model decomposes images into illumination and reflectance components, progressively refined by three specialized modules: (1) Illumination Adaptation, for global and local brightness correction; (2) Reflectance Restoration, for noise suppression and structural detail recovery using spatial-channel attention; and (3) Over-Exposure Compensation, for reconstructing saturated regions and balancing scene luminance. The network is trained using self-supervised reconstruction, reflectance smoothness, perceptual consistency, and domain-aware regularization losses, eliminating the need for paired ground-truth images. Experiments on general and traffic-specific datasets demonstrate superior performance over state-of-the-art methods in both quantitative metrics (PSNR, SSIM, LPIPS, NIQE) and qualitative visual quality. Our approach enhances visibility, preserves structure, and improves downstream perception reliability in real-world low-light traffic scenarios.

</details>


### [7] [HSMix: Hard and Soft Mixing Data Augmentation for Medical Image Segmentation](https://arxiv.org/abs/2511.17614)
*Danyang Sun,Fadi Dornaika,Nagore Barrena*

Main category: cs.CV

TL;DR: HSMix是一种用于医学图像分割的局部图像编辑数据增强方法，通过硬混合和软混合技术来缓解数据稀缺问题，提高分割模型的性能。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割常受限于数据稀缺和过拟合问题，现有的自监督和半监督学习方法复杂且需要手工设计，而数据增强作为一种简单直接的方法在医学图像分割中的有效性尚未充分探索。

Method: HSMix采用硬混合和软混合两种技术：硬混合将两个源图像的同质区域（超像素）组合成增强图像；软混合通过基于局部聚合像素显著性系数的亮度混合来调整组合区域的亮度。同时，对两个源图像的真实分割掩码进行相同的混合操作以生成增强图像对应的掩码。

Result: 大量实验证明该方法在各种医学分割任务中有效，能够充分利用先验轮廓和显著性信息，在增强图像中保留局部语义信息的同时丰富增强空间的多样性。

Conclusion: HSMix是一种即插即用、模型无关的解决方案，适用于多种医学成像模态，能有效解决医学图像分割中的数据稀缺问题。

Abstract: Due to the high cost of annotation or the rarity of some diseases, medical image segmentation is often limited by data scarcity and the resulting overfitting problem. Self-supervised learning and semi-supervised learning can mitigate the data scarcity challenge to some extent. However, both of these paradigms are complex and require either hand-crafted pretexts or well-defined pseudo-labels. In contrast, data augmentation represents a relatively simple and straightforward approach to addressing data scarcity issues. It has led to significant improvements in image recognition tasks. However, the effectiveness of local image editing augmentation techniques in the context of segmentation has been less explored. We propose HSMix, a novel approach to local image editing data augmentation involving hard and soft mixing for medical semantic segmentation. In our approach, a hard-augmented image is created by combining homogeneous regions (superpixels) from two source images. A soft mixing method further adjusts the brightness of these composed regions with brightness mixing based on locally aggregated pixel-wise saliency coefficients. The ground-truth segmentation masks of the two source images undergo the same mixing operations to generate the associated masks for the augmented images. Our method fully exploits both the prior contour and saliency information, thus preserving local semantic information in the augmented images while enriching the augmentation space with more diversity. Our method is a plug-and-play solution that is model agnostic and applicable to a range of medical imaging modalities. Extensive experimental evidence has demonstrated its effectiveness in a variety of medical segmentation tasks. The source code is available in https://github.com/DanielaPlusPlus/HSMix.

</details>


### [8] [Plug-and-Play Multi-Concept Adaptive Blending for High-Fidelity Text-to-Image Synthesis](https://arxiv.org/abs/2511.17615)
*Young-Beom Woo*

Main category: cs.CV

TL;DR: PnP-MIX是一种无需调优的即插即用方法，通过引导注意力机制和掩码噪声混合策略，实现多概念个性化图像生成，有效解决概念泄漏和语义不一致问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂多对象场景中表现不佳，无法保持个性化区域和非个性化区域的完整性，导致语义不一致和概念泄漏问题。

Method: 1. 引导外观注意力机制；2. 掩码引导的噪声混合策略；3. 背景稀释++技术来防止概念泄漏。

Result: 实验表明PnP-MIX在单概念和多概念个性化场景中均优于现有方法，具有鲁棒性和优越性能。

Conclusion: PnP-MIX通过创新的注意力机制和噪声处理策略，成功实现了高质量的多概念个性化图像生成，无需额外模型调优。

Abstract: Integrating multiple personalized concepts into a single image has recently become a significant area of focus within Text-to-Image (T2I) generation. However, existing methods often underperform on complex multi-object scenes due to unintended alterations in both personalized and non-personalized regions. This not only fails to preserve the intended prompt structure but also disrupts interactions among regions, leading to semantic inconsistencies. To address this limitation, we introduce plug-and-play multi-concept adaptive blending for high-fidelity text-to-image synthesis (PnP-MIX), an innovative, tuning-free approach designed to seamlessly embed multiple personalized concepts into a single generated image. Our method leverages guided appearance attention to faithfully reflect the intended appearance of each personalized concept. To further enhance compositional fidelity, we present a mask-guided noise mixing strategy that preserves the integrity of non-personalized regions such as the background or unrelated objects while enabling the precise integration of personalized objects. Finally, to mitigate concept leakage, i.e., the inadvertent leakage of personalized concept features into other regions, we propose background dilution++, a novel strategy that effectively reduces such leakage and promotes accurate localization of features within personalized regions. Extensive experimental results demonstrate that PnP-MIX consistently surpasses existing methodologies in both single- and multi-concept personalization scenarios, underscoring its robustness and superior performance without additional model tuning.

</details>


### [9] [Foundational Question Generation for Video Question Answering via an Embedding-Integrated Approach](https://arxiv.org/abs/2511.17618)
*Ju-Young Oh*

Main category: cs.CV

TL;DR: FIQ是一个通过生成基础问答对来增强视频问答模型推理能力的框架，通过提取视频中的描述性信息生成Q&A对，并结合嵌入对齐模块提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有VQA方法主要依赖事件中心的问答对，缺乏对场景基础信息（如物体类别、空间配置、视觉属性）的全面理解，限制了模型的泛化和推理能力。

Method: 提出FIQ框架：1）从视频中提取描述性信息生成基础Q&A对；2）设计VQ-CAlign模块对齐问题嵌入与视觉特征，保留上下文线索。

Result: 在SUTD-TrafficQA数据集上达到state-of-the-art性能，超越现有基线方法。

Conclusion: FIQ通过增强模型对视频内容的基础理解，有效提升了VQA模型的推理能力和泛化性能。

Abstract: Conventional VQA approaches primarily rely on question-answer (Q&A) pairs to learn the spatio-temporal dynamics of video content. However, most existing annotations are event-centric, which restricts the model's ability to capture the comprehensive context of a scene. The lack of fundamental information such as object categories, spatial configurations, and descriptive visual attributes prevents the model from forming a complete understanding of the environment, ultimately limiting its generalization and reasoning capability. In this paper, we introduce Foundational Question Generation for Video Question Answering via an Embedding-Integrated Approach (FIQ), a framework designed to enhance the reasoning capability of VQA models by improving their foundational comprehension of video content. FIQ generates Q&A pairs from descriptive information extracted directly from videos, thereby enriching the dataset with core scene-level attributes. These generated pairs help the model develop a more holistic understanding of the video, leading to improved generalizability and reasoning performance. In addition, we propose a VQ-CAlign module that aligns task-specific question embeddings with corresponding visual features, preserving essential contextual cues and enhancing adaptability to downstream tasks. Experimental results on the SUTD-TrafficQA dataset demonstrate that FIQ achieves state-of-the-art performance, surpassing existing baseline approaches.

</details>


### [10] [Rethinking the Encoding and Annotating of 3D Bounding Box: Corner-Aware 3D Object Detection from Point Clouds](https://arxiv.org/abs/2511.17619)
*Qinghao Meng,Junbo Yin,Jianbing Shen,Yunde Jia*

Main category: cs.CV

TL;DR: 本文提出角点对齐回归方法，通过将预测目标从中心点转移到几何信息丰富的角点来解决LiDAR 3D目标检测中中心点落在稀疏区域导致预测不准确的问题。


<details>
  <summary>Details</summary>
Motivation: LiDAR点云具有前表面偏向性，导致物体中心经常落在BEV视图的稀疏或空区域，造成边界框预测不稳定和不准确。

Method: 设计角点感知检测头，利用角点间几何约束和图像2D框，从角点标注中恢复3D边界框部分参数，实现弱监督学习范式。

Result: 在KITTI数据集上，相比基于中心的方法AP提升3.5%，仅使用BEV角点点击即可达到全监督准确率的83%。

Conclusion: 角点感知回归策略有效解决了中心对齐回归的不稳定性问题，为LiDAR 3D检测提供了更稳健的解决方案。

Abstract: Center-aligned regression remains dominant in LiDAR-based 3D object detection, yet it suffers from fundamental instability: object centers often fall in sparse or empty regions of the bird's-eye-view (BEV) due to the front-surface-biased nature of LiDAR point clouds, leading to noisy and inaccurate bounding box predictions. To circumvent this limitation, we revisit bounding box representation and propose corner-aligned regression, which shifts the prediction target from unstable centers to geometrically informative corners that reside in dense, observable regions. Leveraging the inherent geometric constraints among corners and image 2D boxes, partial parameters of 3D bounding boxes can be recovered from corner annotations, enabling a weakly supervised paradigm without requiring complete 3D labels. We design a simple yet effective corner-aware detection head that can be plugged into existing detectors. Experiments on KITTI show our method improves performance by 3.5% AP over center-based baseline, and achieves 83% of fully supervised accuracy using only BEV corner clicks, demonstrating the effectiveness of our corner-aware regression strategy.

</details>


### [11] [BD-Net: Has Depth-Wise Convolution Ever Been Applied in Binary Neural Networks?](https://arxiv.org/abs/2511.17633)
*DoYoung Kim,Jin-Seop Lee,Noo-ri Kim,SungJoon Lee,Jee-Hyong Lee*

Main category: cs.CV

TL;DR: 提出了一种1.58位卷积和预BN残差连接的方法，成功实现了深度可分离卷积的二值化，在ImageNet上达到33M OPs，在多个数据集上显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 二值神经网络（BNNs）虽然具有极高的效率，但极端量化限制了表示能力并导致训练不稳定，特别是在轻量级架构的深度可分离卷积中面临挑战。

Method: 采用1.58位卷积增强表达能力，引入预BN残差连接通过改善Hessian条件数来稳定优化过程。

Result: 在ImageNet上使用MobileNet V1达到33M OPs，在CIFAR-10、CIFAR-100、STL-10、Tiny ImageNet和Oxford Flowers 102等数据集上准确率提升最高达9.3个百分点。

Conclusion: 该方法首次成功实现了BNNs中深度可分离卷积的二值化，在多个基准测试中建立了新的state-of-the-art性能。

Abstract: Recent advances in model compression have highlighted the potential of low-bit precision techniques, with Binary Neural Networks (BNNs) attracting attention for their extreme efficiency. However, extreme quantization in BNNs limits representational capacity and destabilizes training, posing significant challenges for lightweight architectures with depth-wise convolutions. To address this, we propose a 1.58-bit convolution to enhance expressiveness and a pre-BN residual connection to stabilize optimization by improving the Hessian condition number. These innovations enable, to the best of our knowledge, the first successful binarization of depth-wise convolutions in BNNs. Our method achieves 33M OPs on ImageNet with MobileNet V1, establishing a new state-of-the-art in BNNs by outperforming prior methods with comparable OPs. Moreover, it consistently outperforms existing methods across various datasets, including CIFAR-10, CIFAR-100, STL-10, Tiny ImageNet, and Oxford Flowers 102, with accuracy improvements of up to 9.3 percentage points.

</details>


### [12] [Efficient Score Pre-computation for Diffusion Models via Cross-Matrix Krylov Projection](https://arxiv.org/abs/2511.17634)
*Kaikwan Lau,Andrew S. Na,Justin W. L. Wan*

Main category: cs.CV

TL;DR: 提出了一种加速基于分数的扩散模型的新框架，通过将稳定扩散模型转换为Fokker-Planck公式，并采用跨矩阵Krylov投影方法来快速求解线性系统。


<details>
  <summary>Details</summary>
Motivation: 标准稳定扩散模型转换为Fokker-Planck公式后需要为每张图像求解大型线性系统，当涉及大量图像训练时会导致高昂的计算成本。

Method: 使用跨矩阵Krylov投影方法，利用矩阵间的数学相似性，通过从"种子"矩阵构建共享子空间来快速求解后续"目标"矩阵。

Result: 实验显示该方法比标准稀疏求解器节省15.8%到43.7%的时间，在去噪任务中比DDPM基线快达115倍，在固定计算预算下能生成高质量图像。

Conclusion: 该方法是在资源受限环境下实现高效生成的实际可行方案。

Abstract: This paper presents a novel framework to accelerate score-based diffusion models. It first converts the standard stable diffusion model into the Fokker-Planck formulation which results in solving large linear systems for each image. For training involving many images, it can lead to a high computational cost. The core innovation is a cross-matrix Krylov projection method that exploits mathematical similarities between matrices, using a shared subspace built from ``seed" matrices to rapidly solve for subsequent ``target" matrices. Our experiments show that this technique achieves a 15.8\% to 43.7\% time reduction over standard sparse solvers. Additionally, we compare our method against DDPM baselines in denoising tasks, showing a speedup of up to 115$\times$. Furthermore, under a fixed computational budget, our model is able to produce high-quality images while DDPM fails to generate recognizable content, illustrating our approach is a practical method for efficient generation in resource-limited settings.

</details>


### [13] [Upstream Probabilistic Meta-Imputation for Multimodal Pediatric Pancreatitis Classification](https://arxiv.org/abs/2511.17635)
*Max A. Nelson,Elif Keles,Eminenur Sen Tasci,Merve Yazol,Halil Ertugrul Aktas,Ziliang Hong,Andrea Mia Bejar,Gorkem Durak,Oznur Leman Boyunaga,Ulas Bagci*

Main category: cs.CV

TL;DR: UPMI是一种轻量级增强策略，通过在低维元特征空间而非图像空间操作，解决小儿胰腺炎诊断中样本有限和多模态成像复杂性的问题。


<details>
  <summary>Details</summary>
Motivation: 小儿胰腺炎是一种进行性且使人衰弱的炎症性疾病，临床诊断面临挑战。基于机器学习的方法也因样本有限和多模态成像复杂性而面临诊断困难。

Method: 提出上游概率元插补（UPMI）方法：使用模态特异性逻辑回归（T1W和T2W MRI影像组学）生成概率输出，转换为7维元特征向量；在每个交叉验证折叠中拟合类条件高斯混合模型来采样合成元特征；结合真实元特征训练随机森林元分类器。

Result: 在67名小儿患者的配对T1W/T2W MRI数据上，UPMI达到平均AUC 0.908±0.072，相比仅使用真实数据的基线（AUC 0.864±0.061）有约5%的相对提升。

Conclusion: UPMI在小儿胰腺炎诊断中有效提升了模型性能，证明了在元特征空间进行数据增强的可行性。

Abstract: Pediatric pancreatitis is a progressive and debilitating inflammatory condition, including acute pancreatitis and chronic pancreatitis, that presents significant clinical diagnostic challenges. Machine learning-based methods also face diagnostic challenges due to limited sample availability and multimodal imaging complexity. To address these challenges, this paper introduces Upstream Probabilistic Meta-Imputation (UPMI), a light-weight augmentation strategy that operates upstream of a meta-learner in a low-dimensional meta-feature space rather than in image space. Modality-specific logistic regressions (T1W and T2W MRI radiomics) produce probability outputs that are transformed into a 7-dimensional meta-feature vector. Class-conditional Gaussian mixture models (GMMs) are then fit within each cross-validation fold to sample synthetic meta-features that, combined with real meta-features, train a Random Forest (RF) meta-classifier. On 67 pediatric subjects with paired T1W/T2W MRIs, UPMI achieves a mean AUC of 0.908 $\pm$ 0.072, a $\sim$5% relative gain over a real-only baseline (AUC 0.864 $\pm$ 0.061).

</details>


### [14] [TSRE: Channel-Aware Typical Set Refinement for Out-of-Distribution Detection](https://arxiv.org/abs/2511.17636)
*Weijun Gao,Rundong He,Jinyang Dong,Yongshun Gong*

Main category: cs.CV

TL;DR: 提出基于通道感知的典型集精炼方法，通过可区分性和活跃度校正激活，结合偏度校正缓解分布偏差，在OOD检测中达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有OOD检测方法在激活校正时忽视了通道内在特性和分布偏斜，导致典型集估计不准确，错误包含异常激活

Method: 1. 基于可区分性和活跃度的典型集精炼，将激活校正为通道感知典型集；2. 偏度校正缓解典型集估计中的分布偏差；3. 利用校正后的激活计算能量分数进行OOD检测

Result: 在ImageNet-1K和CIFAR-100基准测试中达到state-of-the-art性能，并在不同骨干网络和评分函数上具有良好泛化性

Conclusion: 提出的通道感知典型集精炼方法有效解决了现有OOD检测中的典型集估计问题，显著提升了检测性能

Abstract: Out-of-Distribution (OOD) detection is a critical capability for ensuring the safe deployment of machine learning models in open-world environments, where unexpected or anomalous inputs can compromise model reliability and performance. Activation-based methods play a fundamental role in OOD detection by mitigating anomalous activations and enhancing the separation between in-distribution (ID) and OOD data. However, existing methods apply activation rectification while often overlooking channel's intrinsic characteristics and distributional skewness, which results in inaccurate typical set estimation. This discrepancy can lead to the improper inclusion of anomalous activations across channels. To address this limitation, we propose a typical set refinement method based on discriminability and activity, which rectifies activations into a channel-aware typical set. Furthermore, we introduce a skewness-based refinement to mitigate distributional bias in typical set estimation. Finally, we leverage the rectified activations to compute the energy score for OOD detection. Experiments on the ImageNet-1K and CIFAR-100 benchmarks demonstrate that our method achieves state-of-the-art performance and generalizes effectively across backbones and score functions.

</details>


### [15] [SWITCH: Benchmarking Modeling and Handling of Tangible Interfaces in Long-horizon Embodied Scenarios](https://arxiv.org/abs/2511.17649)
*Jieru Lin,Zhiwei Yu,Börje F. Karlsson*

Main category: cs.CV

TL;DR: SWITCH是一个面向具身智能体的基准测试，通过真实设备交互任务评估AI在物理世界中的交互能力，包括视觉问答、语义UI定位、动作生成等五个核心能力。


<details>
  <summary>Details</summary>
Motivation: 当前AI基准测试缺乏对物理世界交互能力的评估，特别是对有形控制界面（如开关、面板）的交互，这些场景需要常识推理、因果预测和结果验证，且失败可能带来安全隐患。

Method: 创建SWITCH基准测试，包含351个任务和98种真实设备，通过迭代发布方式评估五个核心能力：任务感知VQA、语义UI定位、动作生成、状态转换预测和结果验证。

Result: 商业和开源LMMs在单步交互任务中表现不一致，往往过度依赖文本线索而忽视视觉证据，高聚合分数可能掩盖实际失败。

Conclusion: SWITCH提供了可复现的评估框架，揭示了当前AI在物理世界交互中的局限性，为未来更具挑战性的基准测试和训练数据集创建奠定了基础。

Abstract: Autonomous intelligence requires not only perception and reasoning, but critically, effective interaction with the existing world and its infrastructure. Everyday environments are rich in tangible control interfaces (TCIs), e.g., light switches, appliance panels, and embedded GUIs, that demand commonsense and physics reasoning, but also causal prediction and outcome verification in time and space (e.g., delayed heating, remote lights). Moreover, failures here have potential safety implications, yet current benchmarks rarely test grounding, partial observability (video), or post-hoc verification in situated settings. We introduce SWITCH (Semantic World Interface Tasks for Control and Handling), an embodied, task-driven benchmark created through iterative releases to probe these gaps. Its first iteration, SWITCH-Basic, evaluates five complementary abilities:task-aware VQA, semantic UI grounding, action generation, state-transition prediction, and result verification, under egocentric RGB video input and device diversity. Across 351 tasks spanning 98 real devices and appliances, commercial and open LMMMs exhibit inconsistent performance even on single-step interactions, often over-relying on textual cues and under-using visual or video evidence (and high aggregate scores can mask such failures). SWITCH provides data, code, and held-out splits to enable reproducible evaluation and community contributions toward more challenging future iterations of the benchmark and the creation of training datasets. Benchmark resources are available at: https://github.com/BAAI-Agents/SWITCH.

</details>


### [16] [Explainable Deep Learning for Brain Tumor Classification: Comprehensive Benchmarking with Dual Interpretability and Lightweight Deployment](https://arxiv.org/abs/2511.17655)
*Md. Mohaiminul Islam,Md. Mofazzal Hossen,Maher Ali Rusho,Nahiyan Nazah Ridita,Zarin Tasnia Shanta,Md. Simanto Haider,Ahmed Faizul Haque Dhrubo,Md. Khurshid Jahan,Mohammad Abdul Qayum*

Main category: cs.CV

TL;DR: 开发了一个用于脑肿瘤MRI图像自动分类的深度学习系统，包含6种架构，其中轻量级CNN模型在保持高准确率的同时实现实时边缘设备推理。


<details>
  <summary>Details</summary>
Motivation: 解决脑肿瘤分类中的标准化评估、模型可解释性和边缘设备部署问题，为资源有限环境提供可信赖的AI解决方案。

Method: 使用5种ImageNet预训练模型和1个自定义紧凑CNN，采用AdamW优化器和CosineAnnealingLR学习率调度，使用Grad-CAM和GradientShap进行可解释性分析。

Result: Inception-ResNet V2达到99.53%测试准确率，轻量CNN模型达到96.49%准确率且参数量仅为1.31M，比Inception-ResNet V2小100倍。

Conclusion: 提出了一个端到端的解决方案，在准确性、可解释性和部署性方面为先进和低资源医疗系统提供了必要的框架。

Abstract: Our study provides a full deep learning system for automated classification of brain tumors from MRI images, includes six benchmarked architectures (five ImageNet-pre-trained models (VGG-16, Inception V3, ResNet-50, Inception-ResNet V2, Xception) and a custom built, compact CNN (1.31M params)). The study moves the needle forward in a number of ways, including (1) full standardization of assessment with respect to preprocessing, training sets/protocols (optimizing networks with the AdamW optimizer, CosineAnnealingLR, patiene for early stopping = 7), and metrics to assess performance were identical along all models; (2) a high level of confidence in the localizations based on prior studies as both Grad-CAM and GradientShap explanation were used to establish anatomically important and meaningful attention regions and address the black-box issue; (3) a compact 1.31 million parameter CNN was developed that achieved 96.49% testing accuracy and was 100 times smaller than Inception-ResNet V2 while permitting real-time inference (375ms) on edge devices; (4) full evaluation beyond accuracy reporting based on measures of intersection over union, Hausdorff distance, and precision-recall curves, and confusion matrices across all splits. Inception-ResNet V2 reached state-of-the-art performance, achieving a 99.53% accuracy on testing and obtaining a precision, recall, and F1-score of at least 99.50% dominant performance based on metrics of recent studies. We demonstrated a lightweight model that is suitable to deploy on devices that do not have multi-GPU infrastructure in under-resourced settings. This end-to-end solution considers accuracy, interpretability, and deployability of trustworthy AI to create the framework necessary for performance assessment and deployment within advance and low-resource healthcare systems to an extent that enabled participation at the clinical screening and triage level.

</details>


### [17] [MedPEFT-CL: Dual-Phase Parameter-Efficient Continual Learning with Medical Semantic Adapter and Bidirectional Memory Consolidation](https://arxiv.org/abs/2511.17668)
*Ziyuan Gao*

Main category: cs.CV

TL;DR: MedPEFT-CL是一个参数高效的持续学习框架，专门针对医学视觉-语言分割任务，通过双阶段架构解决灾难性遗忘问题，实现新任务高效学习和旧知识保留。


<details>
  <summary>Details</summary>
Motivation: 医学视觉-语言分割模型在适应新解剖结构时容易遭受灾难性遗忘，需要完全重新训练，这限制了其临床部署。现有的持续学习方法在医学视觉-语言任务方面的针对性研究不足。

Method: 基于CLIPSeg的双阶段架构：1）自适应学习阶段：通过语义相似性分析进行适配器分配和参数高效微调；2）知识巩固阶段：采用双向Fisher记忆协调机制。关键贡献包括语义驱动的适配器分配、双模态LoRA适应和双向Fisher记忆协调。

Result: 在多个医学数据集上的广泛实验表明，该框架在遗忘缓解和性能保持方面表现优异，且参数开销最小。

Conclusion: MedPEFT-CL框架为医学视觉-语言场景的持续学习提供了有效的解决方案，能够显著减少灾难性遗忘，同时保持高性能。

Abstract: Medical vision-language segmentation models suffer from catastrophic forgetting when adapting to new anatomical structures, requiring complete retraining that limits their clinical deployment. Although continual learning approaches have been studied for various applications, targeted research on continual learning approaches specifically designed for medical vision-language tasks remains underexplored. We propose MedPEFT-CL, a parameter-efficient continual learning framework that addresses both efficient learning of new tasks and preservation of previous knowledge through a dual-phase architecture based on CLIPSeg. Our dual-phase architecture features an adaptive learning phase that employs semantic similarity-based adapter allocation and parameter-efficient fine-tuning for medical tasks through prompt similarity analysis, and a knowledge consolidation phase employing bi-directional Fisher-memory coordination. This creates a reinforcing cycle: consolidation directs replay priorities while new tasks provide challenging samples that improve retention strategies. Our key contributions are: (1) a semantic-driven adapter allocation mechanism that enables efficient learning of new medical tasks, (2) a bi-modal LoRA adaptation that significantly reduces trainable parameters while maintaining cross-modal learning, and (3) bidirectional Fisher-memory coordination that prevents catastrophic forgetting from previous medical tasks. Extensive experiments across diverse medical datasets demonstrate superior forgetting mitigation and performance retention with minimal parameter overhead, making the framework effective for continual learning in medical vision-language scenarios.

</details>


### [18] [Person Recognition in Aerial Surveillance: A Decade Survey](https://arxiv.org/abs/2511.17674)
*Kien Nguyen,Feng Liu,Clinton Fookes,Sridha Sridharan,Xiaoming Liu,Arun Ross*

Main category: cs.CV

TL;DR: 本文对过去10年150多篇关于以人为中心的空中监视任务的论文进行了系统性综述，从计算机视觉和机器学习角度分析了无人机平台下的人类检测、识别和重识别技术。


<details>
  <summary>Details</summary>
Motivation: 随着空中平台和成像传感器的快速发展，空中监视在规模、机动性、部署和隐蔽观察能力方面展现出前所未有的优势，需要系统性地总结这一领域的技术进展。

Method: 通过识别空中监视相比地面监视的独特挑战，编译和分析公开的空中数据集，深入调查现有方法如何应对空中挑战并提出改进技术。

Result: 提供了全面的技术分析框架，识别了各项任务的关键挑战和现有解决方案，为研究人员提供了系统的参考。

Conclusion: 讨论了当前研究存在的空白和开放性问题，为未来研究方向提供了指导。

Abstract: The rapid emergence of airborne platforms and imaging sensors is enabling new forms of aerial surveillance due to their unprecedented advantages in scale, mobility, deployment, and covert observation capabilities. This paper provides a comprehensive overview of 150+ papers over the last 10 years of human-centric aerial surveillance tasks from a computer vision and machine learning perspective. It aims to provide readers with an in-depth systematic review and technical analysis of the current state of aerial surveillance tasks using drones, UAVs, and other airborne platforms. The object of interest is humans, where human subjects are to be detected, identified, and re-identified. More specifically, for each of these tasks, we first identify unique challenges in performing these tasks in an aerial setting compared to the popular ground-based setting and subsequently compile and analyze aerial datasets publicly available for each task. Most importantly, we delve deep into the approaches in the aerial surveillance literature with a focus on investigating how they presently address aerial challenges and techniques for improvement. We conclude the paper by discussing the gaps and open research questions to inform future research avenues.

</details>


### [19] [Vision-Motion-Reference Alignment for Referring Multi-Object Tracking via Multi-Modal Large Language Models](https://arxiv.org/abs/2511.17681)
*Weiyi Lv,Ning Zhang,Hanyang Sun,Haoran Jiang,Kai Zhao,Jing Xiao,Dan Zeng*

Main category: cs.CV

TL;DR: VMRMOT是一种新颖的视觉-运动-参考对齐的RMOT框架，通过引入运动模态和多模态大语言模型来解决传统RMOT基准中静态描述无法捕捉物体动态运动变化的问题。


<details>
  <summary>Details</summary>
Motivation: 传统RMOT基准仅描述物体外观、相对位置和初始运动状态，这种静态描述无法捕捉物体运动的动态变化（如速度变化和运动方向变化），导致视觉模态与语言参考之间的时间不一致，限制了多模态跟踪性能。

Method: 提出VMRMOT框架：1）从物体动态行为中提取运动感知描述，利用MLLMs的时序推理能力提取运动特征作为运动模态；2）设计视觉-运动-参考对齐模块，分层对齐视觉查询与运动和参考线索；3）开发运动引导预测头，利用运动模态增强预测头性能。

Result: 在多个RMOT基准上的广泛实验表明，VMRMOT优于现有的最先进方法。

Conclusion: VMRMOT是首个在RMOT任务中采用MLLMs进行视觉-参考对齐的方法，通过引入运动模态有效解决了静态描述与动态视觉模态之间的不一致问题，显著提升了多模态跟踪性能。

Abstract: Referring Multi-Object Tracking (RMOT) extends conventional multi-object tracking (MOT) by introducing natural language references for multi-modal fusion tracking. RMOT benchmarks only describe the object's appearance, relative positions, and initial motion states. This so-called static regulation fails to capture dynamic changes of the object motion, including velocity changes and motion direction shifts. This limitation not only causes a temporal discrepancy between static references and dynamic vision modality but also constrains multi-modal tracking performance. To address this limitation, we propose a novel Vision-Motion-Reference aligned RMOT framework, named VMRMOT. It integrates a motion modality extracted from object dynamics to enhance the alignment between vision modality and language references through multi-modal large language models (MLLMs). Specifically, we introduce motion-aware descriptions derived from object dynamic behaviors and, leveraging the powerful temporal-reasoning capabilities of MLLMs, extract motion features as the motion modality. We further design a Vision-Motion-Reference Alignment (VMRA) module to hierarchically align visual queries with motion and reference cues, enhancing their cross-modal consistency. In addition, a Motion-Guided Prediction Head (MGPH) is developed to explore motion modality to enhance the performance of the prediction head. To the best of our knowledge, VMRMOT is the first approach to employ MLLMs in the RMOT task for vision-reference alignment. Extensive experiments on multiple RMOT benchmarks demonstrate that VMRMOT outperforms existing state-of-the-art methods.

</details>


### [20] [Understanding Counting Mechanisms in Large Language and Vision-Language Models](https://arxiv.org/abs/2511.17699)
*Hosein Hasani,Amirmohammad Izadi,Fatemeh Askari,Mobin Bagherian,Sadegh Mohammadian,Mohammad Izadi,Mahdieh Soleymani Baghshah*

Main category: cs.CV

TL;DR: 该论文研究了LLMs和LVLMs在计数任务中如何表示和处理数值信息，通过因果中介分析和激活修补等方法揭示了模型内部计数机制的工作原理。


<details>
  <summary>Details</summary>
Motivation: 理解大型语言模型和视觉语言模型如何表示和处理数值信息，特别是在计数任务中的内部工作机制，这对于提升模型的可解释性和性能具有重要意义。

Method: 使用CountScope工具进行机制可解释性分析，通过控制实验（重复文本和视觉项目）、因果中介分析和激活修补等技术来研究模型行为。

Result: 发现单个token或视觉特征编码了潜在的计数位置信息，数值表示在模型层间逐步涌现，低层编码小数值，高层表示大数值。识别出内部计数器机制，主要存储在最终token或区域中，可在不同上下文间转移。

Conclusion: 计数在LLMs中是一个结构化的分层过程，在LVLMs中遵循相似模式，但受视觉编码器特性影响。模型依赖文本分隔符等结构线索作为计数跟踪的捷径，影响数值预测准确性。

Abstract: This paper examines how large language models (LLMs) and large vision-language models (LVLMs) represent and compute numerical information in counting tasks. We use controlled experiments with repeated textual and visual items and analyze model behavior through causal mediation and activation patching. To this end, we design a specialized tool, CountScope, for mechanistic interpretability of numerical content. Results show that individual tokens or visual features encode latent positional count information that can be extracted and transferred across contexts. Layerwise analyses reveal a progressive emergence of numerical representations, with lower layers encoding small counts and higher layers representing larger ones. We identify an internal counter mechanism that updates with each item, stored mainly in the final token or region and transferable between contexts. In LVLMs, numerical information also appears in visual embeddings, shifting between background and foreground regions depending on spatial composition. Models rely on structural cues such as separators in text, which act as shortcuts for tracking item counts and influence the accuracy of numerical predictions. Overall, counting emerges as a structured, layerwise process in LLMs and follows the same general pattern in LVLMs, shaped by the properties of the vision encoder.

</details>


### [21] [Can Vision-Language Models Count? A Synthetic Benchmark and Analysis of Attention-Based Interventions](https://arxiv.org/abs/2511.17722)
*Saurav Sengupta,Nazanin Moradinasab,Jiebei Liu,Donald E. Brown*

Main category: cs.CV

TL;DR: 本文开发了一个合成基准数据集和评估框架，系统分析视觉语言模型在计数任务中的表现如何随图像和提示属性变化，并研究注意力干预对计数性能的影响。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明视觉语言模型在回答关于图像视觉属性的查询时往往依赖训练中学习的内在偏见，特别是在需要聚焦图像特定区域的计数任务中。

Method: 使用开源视觉语言模型，分析注意力分配如何随输入参数变化，并实施基于注意力的干预来调节不同层级的视觉标记焦点。

Result: 实验表明，虽然视觉语言模型的计数性能仍然具有挑战性，特别是在高视觉或语言复杂度条件下，但某些注意力干预可以带来计数性能的适度提升。

Conclusion: 通过系统性的基准测试和注意力干预，可以更好地理解视觉语言模型在计数任务中的表现局限，并为改进模型性能提供方向。

Abstract: Recent research suggests that Vision Language Models (VLMs) often rely on inherent biases learned during training when responding to queries about visual properties of images. These biases are exacerbated when VLMs are asked highly specific questions that require them to focus on particular areas of the image in tasks such as counting. We build upon this research by developing a synthetic benchmark dataset and evaluation framework to systematically determine how counting performance varies as image and prompt properties change. Using open-source VLMs, we then analyze how attention allocation fluctuates with varying input parameters (e.g. number of objects in the image, objects color, background color, objects texture, background texture, and prompt specificity). We further implement attention-based interventions to modulate focus on visual tokens at different layers and evaluate their impact on counting performance across a range of visual conditions. Our experiments reveal that while VLM counting performance remains challenging, especially under high visual or linguistic complexity, certain attention interventions can lead to modest gains in counting performance.

</details>


### [22] [AngioDG: Interpretable Channel-informed Feature-modulated Single-source Domain Generalization for Coronary Vessel Segmentation in X-ray Angiography](https://arxiv.org/abs/2511.17724)
*Mohammad Atwany,Mojtaba Lashgari,Robin P. Choudhury,Vicente Grau,Abhirup Banerjee*

Main category: cs.CV

TL;DR: 本文提出了一种名为AngioDG的新方法，通过通道正则化策略解决X射线冠状动脉造影血管分割中的单源域泛化问题，在6个数据集上取得了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病是全球主要死因，X射线冠状动脉造影是实时心脏介入治疗的金标准。血管分割有助于下游定量评估，但由于成像协议和患者人口统计差异导致的域偏移，以及缺乏标注数据集，使得开发泛化模型具有挑战性。

Method: AngioDG采用通道正则化策略，识别早期特征通道对任务特定指标的贡献，然后重新加权通道以校准和放大域不变特征，同时衰减域特定特征。

Result: 在6个X射线血管造影数据集上的评估显示，AngioDG在域外性能上优于对比方法，同时保持了稳定的域内测试性能。

Conclusion: AngioDG通过通道正则化有效解决了单源域泛化问题，为冠状动脉血管分割提供了可解释且性能优越的解决方案。

Abstract: Cardiovascular diseases are the leading cause of death globally, with X-ray Coronary Angiography (XCA) as the gold standard during real-time cardiac interventions. Segmentation of coronary vessels from XCA can facilitate downstream quantitative assessments, such as measurement of the stenosis severity and enhancing clinical decision-making. However, developing generalizable vessel segmentation models for XCA is challenging due to variations in imaging protocols and patient demographics that cause domain shifts. These limitations are exacerbated by the lack of annotated datasets, making Single-source Domain Generalization (SDG) a necessary solution for achieving generalization. Existing SDG methods are largely augmentation-based, which may not guarantee the mitigation of overfitting to augmented or synthetic domains. We propose a novel approach, ``AngioDG", to bridge this gap by channel regularization strategy to promote generalization. Our method identifies the contributions of early feature channels to task-specific metrics for DG, facilitating interpretability, and then reweights channels to calibrate and amplify domain-invariant features while attenuating domain-specific ones. We evaluate AngioDG on 6 x-ray angiography datasets for coronary vessels segmentation, achieving the best out-of-distribution performance among the compared methods, while maintaining consistent in-domain test performance.

</details>


### [23] [The Potential and Limitations of Vision-Language Models for Human Motion Understanding: A Case Study in Data-Driven Stroke Rehabilitation](https://arxiv.org/abs/2511.17727)
*Victor Li,Naveenraj Kamalakannan,Avinash Parnandi,Heidi Schambra,Carlos Fernandez-Granda*

Main category: cs.CV

TL;DR: 本研究评估了视觉语言模型在卒中康复视频分析中的应用，发现当前模型缺乏精细运动理解能力，但在高层活动分类和运动检测方面展现潜力。


<details>
  <summary>Details</summary>
Motivation: 探索视觉语言模型在数据驱动的卒中康复中的潜力，特别是自动量化康复剂量和运动障碍这两个核心挑战。

Method: 将康复剂量和运动障碍量化问题构建为运动识别任务，使用VLMs进行分析，并在29名健康对照和51名卒中幸存者队列上进行评估。

Result: 当前VLMs缺乏精细运动理解能力：剂量估计与排除视觉信息的基线相当，障碍评分无法可靠预测。但通过优化提示和后处理，VLMs可以在无任务特定训练的情况下实现高层活动分类、运动检测和轻度障碍参与者的剂量计数近似。

Conclusion: 研究结果既揭示了VLMs在卒中康复视频分析中的当前局限性，也展示了其在更广泛临床视频分析中的新兴机遇。

Abstract: Vision-language models (VLMs) have demonstrated remarkable performance across a wide range of computer-vision tasks, sparking interest in their potential for digital health applications. Here, we apply VLMs to two fundamental challenges in data-driven stroke rehabilitation: automatic quantification of rehabilitation dose and impairment from videos. We formulate these problems as motion-identification tasks, which can be addressed using VLMs. We evaluate our proposed framework on a cohort of 29 healthy controls and 51 stroke survivors. Our results show that current VLMs lack the fine-grained motion understanding required for precise quantification: dose estimates are comparable to a baseline that excludes visual information, and impairment scores cannot be reliably predicted. Nevertheless, several findings suggest future promise. With optimized prompting and post-processing, VLMs can classify high-level activities from a few frames, detect motion and grasp with moderate accuracy, and approximate dose counts within 25% of ground truth for mildly impaired and healthy participants, all without task-specific training or finetuning. These results highlight both the current limitations and emerging opportunities of VLMs for data-driven stroke rehabilitation and broader clinical video analysis.

</details>


### [24] [VisReason: A Large-Scale Dataset for Visual Chain-of-Thought Reasoning](https://arxiv.org/abs/2511.17731)
*Lingxiao Li,Yifan Wang,Xinyan Gao,Chen Tang,Xiangyu Yue,Chenyu You*

Main category: cs.CV

TL;DR: VisReason是一个大规模视觉推理数据集，通过多轮、类似人类的推理步骤来增强多模态大语言模型的视觉推理能力，显著提升了逐步推理的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉CoT数据集通常规模小、领域特定或缺乏人类逐步推理结构，阻碍了多模态大语言模型在视觉理解中的复杂推理能力发展。

Method: 构建了VisReason数据集（489K样本）和VisReason-Pro子集（165K样本），包含四个不同领域的多轮推理标注，并使用GPT专家标注器增强3D空间定位和详细推理轨迹。

Result: 在Qwen2.5-VL模型上微调后，在逐步视觉推理准确性、可解释性和跨基准泛化方面取得了显著提升。

Conclusion: VisReason为培养人类类似视觉推理能力奠定了基础，推动下一代多模态智能的发展。

Abstract: Chain-of-Thought (CoT) prompting has proven remarkably effective for eliciting complex reasoning in large language models (LLMs). Yet, its potential in multimodal large language models (MLLMs) remains largely untapped, hindered by the absence of large-scale datasets that capture the rich, spatially grounded reasoning intrinsic to visual understanding. Existing visual-CoT resources are typically small, domain-specific, or lack the human-like stepwise structure necessary for compositional visual reasoning. In this paper, we introduce VisReason, a large-scale dataset designed to advance visual Chain-of-Thought reasoning. VisReason comprises 489K annotated examples spanning four diverse domains, each featuring multi-round, human-like rationales that guide MLLMs through interpretable visual reasoning steps. Building upon this, we curate VisReason-Pro, a 165K subset produced with a stronger expert-level GPT annotator, enriched with detailed reasoning traces and 3D spatial grounding via depth-informed annotations. Fine-tuning the state-of-the-art Qwen2.5-VL model on VisReason and VisReason-Pro yields substantial improvements in step-by-step visual reasoning accuracy, interpretability, and cross-benchmark generalization. These results demonstrate that VisReason equips MLLMs with more systematic and generalizable reasoning capabilities. We envision VisReason as a cornerstone for cultivating human-like visual reasoning, paving the way toward the next generation of multimodal intelligence.

</details>


### [25] [Towards Open-Ended Visual Scientific Discovery with Sparse Autoencoders](https://arxiv.org/abs/2511.17735)
*Samuel Stevens,Jacob Beattie,Tanya Berger-Wolf,Yu Su*

Main category: cs.CV

TL;DR: 该论文探讨了稀疏自编码器（SAEs）能否从基础模型的表示中实现开放式的特征发现，通过生态图像案例验证了该方法在无监督情况下发现精细结构的能力。


<details>
  <summary>Details</summary>
Motivation: 科学档案包含海量数据，但现有方法仅针对预设目标提取结构，无法支持未知模式的开放式发现。研究旨在探索SAEs是否能够实现开放式的特征发现。

Method: 使用稀疏自编码器分解基础模型的表示，在控制性重发现研究中评估学习到的特征与语义概念的对齐情况，并与无标签替代方法进行比较。

Result: 在生态图像上，该方法无需分割或部件标签即可发现精细的解剖结构，并通过真实验证证实了有效性。稀疏分解为探索科学基础模型学习内容提供了实用工具。

Conclusion: 稀疏自编码器提供了一种实用的工具，用于探索科学基础模型学习到的内容，这是从确认转向真正发现的重要前提。该方法领域无关，可应用于蛋白质、基因组学、天气等其他科学模型。

Abstract: Scientific archives now contain hundreds of petabytes of data across genomics, ecology, climate, and molecular biology that could reveal undiscovered patterns if systematically analyzed at scale. Large-scale, weakly-supervised datasets in language and vision have driven the development of foundation models whose internal representations encode structure (patterns, co-occurrences and statistical regularities) beyond their training objectives. Most existing methods extract structure only for pre-specified targets; they excel at confirmation but do not support open-ended discovery of unknown patterns. We ask whether sparse autoencoders (SAEs) can enable open-ended feature discovery from foundation model representations. We evaluate this question in controlled rediscovery studies, where the learned SAE features are tested for alignment with semantic concepts on a standard segmentation benchmark and compared against strong label-free alternatives on concept-alignment metrics. Applied to ecological imagery, the same procedure surfaces fine-grained anatomical structure without access to segmentation or part labels, providing a scientific case study with ground-truth validation. While our experiments focus on vision with an ecology case study, the method is domain-agnostic and applicable to models in other sciences (e.g., proteins, genomics, weather). Our results indicate that sparse decomposition provides a practical instrument for exploring what scientific foundation models have learned, an important prerequisite for moving from confirmation to genuine discovery.

</details>


### [26] [AEGIS: Preserving privacy of 3D Facial Avatars with Adversarial Perturbations](https://arxiv.org/abs/2511.17747)
*Dawid Wolkiewicz,Anastasiya Pechko,Przemysław Spurek,Piotr Syga*

Main category: cs.CV

TL;DR: AEGIS是首个针对3D高斯化身的隐私保护身份掩蔽框架，能够在保持感知真实性的同时实现完全去识别化。


<details>
  <summary>Details</summary>
Motivation: 随着3D面部化身的广泛应用，特别是基于3D高斯泼溅表示的高效化身，带来了在线身份盗窃的新风险。现有方法主要针对2D图像，缺乏对动态3D化身的视角一致性身份保护。

Method: AEGIS通过预训练的人脸验证网络指导，对高斯颜色系数施加对抗性扰动，确保跨多个视角的一致保护，无需重新训练或修改化身几何结构。

Result: AEGIS实现了完全去识别化，将人脸检索和验证准确率降至0%，同时保持高感知质量（SSIM=0.9555，PSNR=35.52dB），并保留了年龄、种族、性别和情感等关键面部属性。

Conclusion: 该方法展示了强大的隐私保护能力，同时产生最小的视觉失真，为3D高斯化身提供了有效的身份保护解决方案。

Abstract: The growing adoption of photorealistic 3D facial avatars, particularly those utilizing efficient 3D Gaussian Splatting representations, introduces new risks of online identity theft, especially in systems that rely on biometric authentication. While effective adversarial masking methods have been developed for 2D images, a significant gap remains in achieving robust, viewpoint-consistent identity protection for dynamic 3D avatars. To address this, we present AEGIS, the first privacy-preserving identity masking framework for 3D Gaussian Avatars that maintains the subject's perceived characteristics. Our method aims to conceal identity-related facial features while preserving the avatar's perceptual realism and functional integrity. AEGIS applies adversarial perturbations to the Gaussian color coefficients, guided by a pre-trained face verification network, ensuring consistent protection across multiple viewpoints without retraining or modifying the avatar's geometry. AEGIS achieves complete de-identification, reducing face retrieval and verification accuracy to 0%, while maintaining high perceptual quality (SSIM = 0.9555, PSNR = 35.52 dB). It also preserves key facial attributes such as age, race, gender, and emotion, demonstrating strong privacy protection with minimal visual distortion.

</details>


### [27] [SPIDER: Spatial Image CorresponDence Estimator for Robust Calibration](https://arxiv.org/abs/2511.17750)
*Zhimin Shao,Abhay Yadav,Rama Chellappa,Cheng Peng*

Main category: cs.CV

TL;DR: SPIDER是一个通用的特征匹配框架，通过结合2D和3D特征匹配方法，在跨域图像匹配中显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 传统2D特征匹配在跨域场景（如航拍、室内、室外）中面临外观、尺度和视角变化的挑战，而现有3D基础模型虽然具有空间一致性，但对细粒度几何细节不敏感，特别是在大视角变化下

Method: SPIDER采用共享特征提取主干网络和两个专用网络头，分别用于估计基于2D和3D的对应关系，实现从粗到精的匹配

Result: SPIDER在专注于大基线无约束场景的图像匹配评估基准上显著优于最先进方法

Conclusion: SPIDER展示了作为通用图像匹配方法的强大能力，通过整合2D和3D特征匹配的优势解决了跨域匹配的挑战

Abstract: Reliable image correspondences form the foundation of vision-based spatial perception, enabling recovery of 3D structure and camera poses. However, unconstrained feature matching across domains such as aerial, indoor, and outdoor scenes remains challenging due to large variations in appearance, scale and viewpoint. Feature matching has been conventionally formulated as a 2D-to-2D problem; however, recent 3D foundation models provides spatial feature matching properties based on two-view geometry. While powerful, we observe that these spatially coherent matches often concentrate on dominant planar regions, e.g., walls or ground surfaces, while being less sensitive to fine-grained geometric details, particularly under large viewpoint changes. To better understand these trade-offs, we first perform linear probe experiments to evaluate the performance of various vision foundation models for image matching. Building on these insights, we introduce SPIDER, a universal feature matching framework that integrates a shared feature extraction backbone with two specialized network heads for estimating both 2D-based and 3D-based correspondences from coarse to fine. Finally, we introduce an image-matching evaluation benchmark that focuses on unconstrained scenarios with large baselines. SPIDER significantly outperforms SoTA methods, demonstrating its strong ability as a universal image-matching method.

</details>


### [28] [CORA: Consistency-Guided Semi-Supervised Framework for Reasoning Segmentation](https://arxiv.org/abs/2511.17755)
*Prantik Howlader,Hoang Nguyen-Canh,Srijan Das,Jingyi Xu,Hieu Le,Dimitris Samaras*

Main category: cs.CV

TL;DR: CORA是一个半监督推理分割框架，通过条件视觉指令、噪声伪标签过滤和标记级对比对齐，在有限标注数据下实现稳健的推理分割，在Cityscapes和PanNuke数据集上分别提升2.3%和2.4%的性能。


<details>
  <summary>Details</summary>
Motivation: 解决推理分割中标注数据成本高、多样性不足导致的泛化能力有限问题，旨在通过半监督学习减少对高质量像素标注的依赖。

Method: 1) 条件视觉指令编码对象间空间和上下文关系；2) 基于多模态LLM输出的语义等价查询一致性过滤噪声伪标签；3) 标记级对比对齐增强特征一致性。

Result: 在Cityscapes数据集上仅需100张标注图像即可达到SOTA，性能提升2.3%；在PanNuke数据集上仅需180张标注图像，性能提升2.4%。

Conclusion: CORA框架通过半监督学习有效减少对标注数据的依赖，在有限监督下实现稳健的推理分割，为复杂指令下的像素级分割提供了可行方案。

Abstract: Reasoning segmentation seeks pixel-accurate masks for targets referenced by complex, often implicit instructions, requiring context-dependent reasoning over the scene. Recent multimodal language models have advanced instruction following segmentation, yet generalization remains limited. The key bottleneck is the high cost of curating diverse, high-quality pixel annotations paired with rich linguistic supervision leading to brittle performance under distribution shift. Therefore, we present CORA, a semi-supervised reasoning segmentation framework that jointly learns from limited labeled data and a large corpus of unlabeled images. CORA introduces three main components: 1) conditional visual instructions that encode spatial and contextual relationships between objects; 2) a noisy pseudo-label filter based on the consistency of Multimodal LLM's outputs across semantically equivalent queries; and 3) a token-level contrastive alignment between labeled and pseudo-labeled samples to enhance feature consistency. These components enable CORA to perform robust reasoning segmentation with minimal supervision, outperforming existing baselines under constrained annotation settings. CORA achieves state-of-the-art results, requiring as few as 100 labeled images on Cityscapes, a benchmark dataset for urban scene understanding, surpassing the baseline by $+2.3\%$. Similarly, CORA improves performance by $+2.4\%$ with only 180 labeled images on PanNuke, a histopathology dataset.

</details>


### [29] [Latent Dirichlet Transformer VAE for Hyperspectral Unmixing with Bundled Endmembers](https://arxiv.org/abs/2511.17757)
*Giancarlo Giannetti,Faisal Z. Qureshi*

Main category: cs.CV

TL;DR: 提出LDVAE-T模型，结合Transformer和Dirichlet先验，用于高光谱解混，在三个基准数据集上表现优于现有方法


<details>
  <summary>Details</summary>
Motivation: 高光谱图像中存在光谱混合问题，会掩盖纯材料特征，需要开发能够处理材料内在变异性的解混方法

Method: 使用Transformer编码器获取Dirichlet分布的丰度，解码器预测每个端元的平均光谱和结构化协方差，将材料作为端元束处理

Result: 在Samson、Jasper Ridge和HYDICE Urban数据集上，LDVAE-T在丰度估计和端元提取方面均优于最先进模型

Conclusion: LDVAE-T通过结合Transformer的全局上下文建模和Dirichlet先验的物理约束，有效提升了高光谱解混的性能

Abstract: Hyperspectral images capture rich spectral information that enables per-pixel material identification; however, spectral mixing often obscures pure material signatures. To address this challenge, we propose the Latent Dirichlet Transformer Variational Autoencoder (LDVAE-T) for hyperspectral unmixing. Our model combines the global context modeling capabilities of transformer architectures with physically meaningful constraints imposed by a Dirichlet prior in the latent space. This prior naturally enforces the sum-to-one and non-negativity conditions essential for abundance estimation, thereby improving the quality of predicted mixing ratios. A key contribution of LDVAE-T is its treatment of materials as bundled endmembers, rather than relying on fixed ground truth spectra. In the proposed method our decoder predicts, for each endmember and each patch, a mean spectrum together with a structured (segmentwise) covariance that captures correlated spectral variability. Reconstructions are formed by mixing these learned bundles with Dirichlet-distributed abundances garnered from a transformer encoder, allowing the model to represent intrinsic material variability while preserving physical interpretability. We evaluate our approach on three benchmark datasets, Samson, Jasper Ridge, and HYDICE Urban and show that LDVAE-T consistently outperforms state-of-the-art models in abundance estimation and endmember extraction, as measured by root mean squared error and spectral angle distance, respectively.

</details>


### [30] [Deepfake Geography: Detecting AI-Generated Satellite Images](https://arxiv.org/abs/2511.17766)
*Mansur Yerzhanuly*

Main category: cs.CV

TL;DR: 本文比较了CNN和ViT在检测AI生成的卫星图像方面的性能，发现ViT在准确性和鲁棒性上显著优于CNN。


<details>
  <summary>Details</summary>
Motivation: 随着StyleGAN2和Stable Diffusion等生成模型的快速发展，卫星图像的真实性面临威胁，而现有深度伪造检测研究主要关注人脸图像，卫星图像检测存在独特挑战。

Method: 使用包含13万张标记RGB图像的DM-AER和FSI数据集，对比CNN和ViT的检测性能，并采用Grad-CAM和Chefer注意力归因方法增强模型可解释性。

Result: ViT的准确率达到95.11%，显著高于CNN的87.02%，ViT在建模长距离依赖和全局语义结构方面表现更优。

Conclusion: ViT在检测合成卫星图像的结构不一致性和重复纹理模式方面具有优势，未来研究将扩展到多光谱和SAR模态，并结合频域分析进一步加强检测能力。

Abstract: The rapid advancement of generative models such as StyleGAN2 and Stable Diffusion poses a growing threat to the authenticity of satellite imagery, which is increasingly vital for reliable analysis and decision-making across scientific and security domains. While deepfake detection has been extensively studied in facial contexts, satellite imagery presents distinct challenges, including terrain-level inconsistencies and structural artifacts. In this study, we conduct a comprehensive comparison between Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) for detecting AI-generated satellite images. Using a curated dataset of over 130,000 labeled RGB images from the DM-AER and FSI datasets, we show that ViTs significantly outperform CNNs in both accuracy (95.11 percent vs. 87.02 percent) and overall robustness, owing to their ability to model long-range dependencies and global semantic structures. We further enhance model transparency using architecture-specific interpretability methods, including Grad-CAM for CNNs and Chefer's attention attribution for ViTs, revealing distinct detection behaviors and validating model trustworthiness. Our results highlight the ViT's superior performance in detecting structural inconsistencies and repetitive textural patterns characteristic of synthetic imagery. Future work will extend this research to multispectral and SAR modalities and integrate frequency-domain analysis to further strengthen detection capabilities and safeguard satellite imagery integrity in high-stakes applications.

</details>


### [31] [Target-Bench: Can World Models Achieve Mapless Path Planning with Semantic Targets?](https://arxiv.org/abs/2511.17792)
*Dingrui Wang,Hongyuan Ye,Zhihao Liang,Zhexiao Sun,Zhaowei Lu,Yuchen Zhang,Yuyu Zhao,Yuan Gao,Marvin Seegert,Finn Schäfer,Haotong Qin,Wei Li,Luigi Palmieri,Felix Jahncke,Mattia Piccinini,Johannes Betz*

Main category: cs.CV

TL;DR: Target-Bench是首个专门评估世界模型在真实环境中无地图路径规划能力的基准测试，包含450个机器人收集的视频序列和SLAM真实轨迹，评估显示当前最先进模型在机器人规划任务中存在显著局限性。


<details>
  <summary>Details</summary>
Motivation: 当前世界模型能生成高度逼真的视频，但它们在机器人路径规划方面的能力尚不明确且缺乏量化评估，需要专门的基准测试来衡量世界模型在语义目标路径规划中的表现。

Method: 开发Target-Bench基准测试，包含450个视频序列覆盖45个语义类别，使用SLAM提供真实轨迹。评估流程从生成视频中恢复相机运动，使用五个互补指标量化目标到达能力、轨迹精度和方向一致性。评估Sora 2、Veo 3.1和Wan系列等最先进模型。

Result: 最佳现成模型(Wan2.2-Flash)仅得0.299分，显示当前世界模型在机器人规划任务中存在显著局限性。在数据集上微调一个开源5B参数模型仅需325个场景就能达到0.345分，比基础版本提升400%以上，比最佳现成模型高15%。

Conclusion: Target-Bench揭示了当前世界模型在机器人路径规划方面的不足，通过微调可以显著提升性能，表明专门的数据集和训练对改善世界模型的规划能力至关重要。代码和数据集将开源。

Abstract: While recent world models generate highly realistic videos, their ability to perform robot path planning remains unclear and unquantified. We introduce Target-Bench, the first benchmark specifically designed to evaluate world models on mapless path planning toward semantic targets in real-world environments. Target-Bench provides 450 robot-collected video sequences spanning 45 semantic categories with SLAM-based ground truth trajectories. Our evaluation pipeline recovers camera motion from generated videos and measures planning performance using five complementary metrics that quantify target-reaching capability, trajectory accuracy, and directional consistency. We evaluate state-of-the-art models including Sora 2, Veo 3.1, and the Wan series. The best off-the-shelf model (Wan2.2-Flash) achieves only 0.299 overall score, revealing significant limitations in current world models for robotic planning tasks. We show that fine-tuning an open-source 5B-parameter model on only 325 scenarios from our dataset achieves 0.345 overall score -- an improvement of more than 400% over its base version (0.066) and 15% higher than the best off-the-shelf model. We will open-source the code and dataset.

</details>


### [32] [Attention Guided Alignment in Efficient Vision-Language Models](https://arxiv.org/abs/2511.17793)
*Shweta Mahajan,Hoang Le,Hyojin Park,Farzad Farhadzadeh,Munawar Hayat,Fatih Porikli*

Main category: cs.CV

TL;DR: 本文提出了一种名为AGE-VLM的新框架，通过引入交叉注意力层和利用SAM的空间知识来增强视觉语言模型中的视觉定位能力，显著减少物体幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于拼接架构的高效视觉语言模型在区分语义匹配和非匹配的图像-文本对方面存在困难，这是导致物体幻觉的关键因素。

Method: 提出AGE-VLM框架，使用交错的交叉注意力层将视觉能力注入预训练的小型语言模型中，并通过从Segment Anything Model（SAM）提取的空间知识来引导模型关注正确的图像区域。

Result: 在多个视觉中心基准测试中，该方法优于或与先前的高效VLM工作相当，显著减少了幻觉现象。

Conclusion: 该研究为未来实现增强视觉和语言理解的VLM研究提供了有价值的见解，证明了注意力引导机制在改善多模态对齐方面的有效性。

Abstract: Large Vision-Language Models (VLMs) rely on effective multimodal alignment between pre-trained vision encoders and Large Language Models (LLMs) to integrate visual and textual information. This paper presents a comprehensive analysis of attention patterns in efficient VLMs, revealing that concatenation-based architectures frequently fail to distinguish between semantically matching and non-matching image-text pairs. This is a key factor for object hallucination in these models. To address this, we introduce Attention-Guided Efficient Vision-Language Models (AGE-VLM), a novel framework that enhances visual grounding through interleaved cross-attention layers to instill vision capabilities in pretrained small language models. This enforces in VLM the ability "look" at the correct image regions by leveraging spatial knowledge distilled from the Segment Anything Model (SAM), significantly reducing hallucination. We validate our approach across different vision-centric benchmarks where our method is better or comparable to prior work on efficient VLMs. Our findings provide valuable insights for future research aimed at achieving enhanced visual and linguistic understanding in VLMs.

</details>


### [33] [Pillar-0: A New Frontier for Radiology Foundation Models](https://arxiv.org/abs/2511.17803)
*Kumar Krishna Agrawal,Longchao Liu,Long Lian,Michael Nercessian,Natalia Harguindeguy,Yufu Wu,Peter Mikhael,Gigin Lin,Lecia V. Sequist,Florian Fintelmann,Trevor Darrell,Yutong Bai,Maggie Chung,Adam Yala*

Main category: cs.CV

TL;DR: Pillar-0是一个放射学基础模型，通过处理大量多模态医学影像数据，在放射学任务中实现了新的性能突破，显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 放射学在现代医学中至关重要，但影像量增长远超放射科医生数量增长。现有医学模型存在局限性：将体积CT和MRI处理为低分辨率2D切片、丢弃关键灰度对比信息、缺乏反映真实临床实践的评价框架。

Method: 使用来自大型学术中心的42,990例腹部盆腔CT、86,411例胸部CT、14,348例头部CT和11,543例乳腺MRI进行预训练，结合RATE框架（使用LLM提取366种放射学发现的结构化标签）。

Result: Pillar-0在内部测试集上平均AUROC分别达到86.4（腹部盆腔CT）、88.0（胸部CT）、90.1（头部CT）和82.9（乳腺MRI），比现有模型提升7.8-15.8 AUROC点，在87.2%的任务中排名第一。在外部验证和扩展任务（如肺癌风险预测）中也表现出色。

Conclusion: Pillar-0和RATE共同提供了一个开放、临床严谨的基础，用于构建高性能放射学系统，解决了以往因计算、数据和评估限制而不可行的应用问题。

Abstract: Radiology plays an integral role in modern medicine, yet rising imaging volumes have far outpaced workforce growth. Foundation models offer a path toward assisting with the full spectrum of radiology tasks, but existing medical models remain limited: they process volumetric CT and MRI as low-fidelity 2D slices, discard critical grayscale contrast information, and lack evaluation frameworks that reflect real clinical practice. We introduce Pillar-0, a radiology foundation model pretrained on 42,990 abdomen-pelvis CTs, 86,411 chest CTs, 14,348 head CTs, and 11,543 breast MRIs from a large academic center, together with RATE, a scalable framework that extracts structured labels for 366 radiologic findings with near-perfect accuracy using LLMs. Across internal test sets of 14,230 abdomen-pelvis CTs, 10,646 chest CTs, 4,906 head CTs, and 1,585 breast MRIs, Pillar-0 establishes a new performance frontier, achieving mean AUROCs of 86.4, 88.0, 90.1, and 82.9, outperforming MedGemma (Google), MedImageInsight (Microsoft), Lingshu (Alibaba), and Merlin (Stanford) by 7.8-15.8 AUROC points and ranking best in 87.2\% (319/366) tasks. Pillar-0 similarly outperforms all baselines in an external validation on the Stanford Abdominal CT dataset, including Merlin (82.2 vs 80.6 AUROC). Pillar-0 extends to tasks beyond its pretraining, such as long-horizon lung cancer risk prediction, where it improves upon the state-of-the-art Sybil by 3.0 C-index points on NLST, and generalizes with gains of 5.9 (MGH) and 1.9 (CGMH). In brain hemorrhage detection, Pillar-0 obtained a >95 AUROC when using only 1/20th of the data of the next most sample efficient baseline. Pillar-0 and RATE together provide an open, clinically rigorous foundation for building high-performance radiology systems, enabling applications that were previously infeasible due to computational, data, and evaluation constraints.

</details>


### [34] [A Stitch in Time: Learning Procedural Workflow via Self-Supervised Plackett-Luce Ranking](https://arxiv.org/abs/2511.17805)
*Chengan Che,Chao Wang,Xinyue Chen,Sophia Tsoka,Luis C. Garcia-Peraza-Herrera*

Main category: cs.CV

TL;DR: PL-Stitch是一个自监督学习框架，通过利用视频帧的固有时间顺序作为监督信号，解决了当前SSL方法缺乏程序性意识的问题。


<details>
  <summary>Details</summary>
Motivation: 当前的自监督学习方法忽视了程序性活动（如烹饪和手术）的结构化特性，无法识别动作的时间顺序。实验表明，现有模型对正向和反向时间序列产生相似特征，证明它们对程序顺序是盲目的。

Method: 提出PL-Stitch框架，基于Plackett-Luce模型集成两个新的概率目标：主要PL目标训练模型按时间顺序排序采样帧，学习全局工作流程进展；次要目标通过时空拼图损失捕捉细粒度的跨帧对象相关性。

Result: 在五个手术和烹饪基准测试中一致实现优异性能，特别是在手术阶段识别（如Cholec80上k-NN准确率提升11.4个百分点）和烹饪动作分割（如Breakfast上线性探测准确率提升5.7个百分点）方面表现突出。

Conclusion: PL-Stitch通过利用时间顺序作为监督信号，有效解决了程序性视频表示学习中的顺序意识缺失问题，证明了其在复杂程序性活动分析中的有效性。

Abstract: Procedural activities, ranging from routine cooking to complex surgical operations, are highly structured as a set of actions conducted in a specific temporal order. Despite their success on static images and short clips, current self-supervised learning methods often overlook the procedural nature that underpins such activities. We expose the lack of procedural awareness in current SSL methods with a motivating experiment: models pretrained on forward and time-reversed sequences produce highly similar features, confirming that their representations are blind to the underlying procedural order. To address this shortcoming, we propose PL-Stitch, a self-supervised framework that harnesses the inherent temporal order of video frames as a powerful supervisory signal. Our approach integrates two novel probabilistic objectives based on the Plackett-Luce (PL) model. The primary PL objective trains the model to sort sampled frames chronologically, compelling it to learn the global workflow progression. The secondary objective, a spatio-temporal jigsaw loss, complements the learning by capturing fine-grained, cross-frame object correlations. Our approach consistently achieves superior performance across five surgical and cooking benchmarks. Specifically, PL-Stitch yields significant gains in surgical phase recognition (e.g., +11.4 pp k-NN accuracy on Cholec80) and cooking action segmentation (e.g., +5.7 pp linear probing accuracy on Breakfast), demonstrating its effectiveness for procedural video representation learning.

</details>


### [35] [REXO: Indoor Multi-View Radar Object Detection via 3D Bounding Box Diffusion](https://arxiv.org/abs/2511.17806)
*Ryoma Yataka,Pu Perry Wang,Petros Boufounos,Ryuhei Takahashi*

Main category: cs.CV

TL;DR: REXO提出了一种基于3D边界框扩散的多视角雷达目标检测方法，通过显式的跨视角雷达特征关联提升室内复杂场景下的检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖隐式的跨视角雷达特征关联（如RFMask中的提案配对或RETR中的查询到特征交叉注意力），在复杂室内场景中容易导致特征匹配模糊和检测性能下降。

Method: 将DiffusionDet的2D边界框扩散过程提升到3D雷达空间，利用噪声3D边界框指导显式的跨视角雷达特征关联，并通过先验知识（人与地面接触）减少扩散参数数量。

Result: 在两个公开室内雷达数据集上的评估显示，该方法在HIBER数据集上AP提升+4.22，在MMVR数据集上AP提升+11.02，超越了现有最优方法。

Conclusion: REXO通过3D边界框扩散和显式特征关联有效解决了多视角雷达感知中的特征匹配问题，显著提升了室内复杂场景下的检测精度。

Abstract: Multi-view indoor radar perception has drawn attention due to its cost-effectiveness and low privacy risks. Existing methods often rely on {implicit} cross-view radar feature association, such as proposal pairing in RFMask or query-to-feature cross-attention in RETR, which can lead to ambiguous feature matches and degraded detection in complex indoor scenes. To address these limitations, we propose \textbf{REXO} (multi-view Radar object dEtection with 3D bounding boX diffusiOn), which lifts the 2D bounding box (BBox) diffusion process of DiffusionDet into the 3D radar space. REXO utilizes these noisy 3D BBoxes to guide an {explicit} cross-view radar feature association, enhancing the cross-view radar-conditioned denoising process. By accounting for prior knowledge that the person is in contact with the ground, REXO reduces the number of diffusion parameters by determining them from this prior. Evaluated on two open indoor radar datasets, our approach surpasses state-of-the-art methods by a margin of +4.22 AP on the HIBER dataset and +11.02 AP on the MMVR dataset.

</details>


### [36] [Importance-Weighted Non-IID Sampling for Flow Matching Models](https://arxiv.org/abs/2511.17812)
*Xinshuang Liu,Runfa Blark Li,Shaoxiu Wei,Truong Nguyen*

Main category: cs.CV

TL;DR: 提出了一种重要性加权的非独立同分布采样框架，用于降低流匹配模型期望估计的方差，通过联合采样覆盖分布的关键区域并保持无偏估计。


<details>
  <summary>Details</summary>
Motivation: 流匹配模型能有效表示复杂分布，但在有限采样预算下估计函数期望具有挑战性。独立采样常产生高方差估计，特别是当稀有但高影响结果主导期望时。

Method: 引入基于分数的正则化多样性机制，利用分数函数确保样本在数据流形高密度区域分散；开发非独立同分布流样本的重要性加权方法，通过学习残差速度场重现非独立同分布样本的边际分布。

Result: 经验表明该方法能产生多样化的高质量样本，准确估计重要性权重和期望，提升流匹配模型输出的可靠表征。

Conclusion: 该方法通过重要性加权和非独立同分布采样框架，有效解决了流匹配模型期望估计的方差问题，推动了模型输出的可靠分析。

Abstract: Flow-matching models effectively represent complex distributions, yet estimating expectations of functions of their outputs remains challenging under limited sampling budgets. Independent sampling often yields high-variance estimates, especially when rare but with high-impact outcomes dominate the expectation. We propose an importance-weighted non-IID sampling framework that jointly draws multiple samples to cover diverse, salient regions of a flow's distribution while maintaining unbiased estimation via estimated importance weights. To balance diversity and quality, we introduce a score-based regularization for the diversity mechanism, which uses the score function, i.e., the gradient of the log probability, to ensure samples are pushed apart within high-density regions of the data manifold, mitigating off-manifold drift. We further develop the first approach for importance weighting of non-IID flow samples by learning a residual velocity field that reproduces the marginal distribution of the non-IID samples. Empirically, our method produces diverse, high-quality samples and accurate estimates of both importance weights and expectations, advancing the reliable characterization of flow-matching model outputs. Our code will be publicly available on GitHub.

</details>


### [37] [QAL: A Loss for Recall Precision Balance in 3D Reconstruction](https://arxiv.org/abs/2511.17824)
*Pranay Meshram,Yash Turkar,Kartikeya Singh,Praveen Raj Masilamani,Charuvahan Adhivarahan,Karthik Dantu*

Main category: cs.CV

TL;DR: QAL是一种替代CD/EMD的3D视觉损失函数，通过解耦召回率和精确度，显著提升覆盖率和薄结构恢复能力。


<details>
  <summary>Details</summary>
Motivation: 传统Chamfer Distance和Earth Mover's Distance在3D体积学习任务中无法平衡召回率和精确度，导致薄结构和欠表示区域恢复不足。

Method: 提出Quality-Aware Loss，结合覆盖加权的最近邻项和未覆盖真实值吸引项，将召回率和精确度解耦为可调组件。

Result: 在多个数据集上平均比CD提升4.3个百分点，比最佳替代方案提升2.8个百分点，在GraspNet评估中获得更高的抓取分数。

Conclusion: QAL为3D视觉和安全关键机器人流程提供了原则性、可解释且实用的目标函数。

Abstract: Volumetric learning underpins many 3D vision tasks such as completion, reconstruction, and mesh generation, yet training objectives still rely on Chamfer Distance (CD) or Earth Mover's Distance (EMD), which fail to balance recall and precision. We propose Quality-Aware Loss (QAL), a drop-in replacement for CD/EMD that combines a coverage-weighted nearest-neighbor term with an uncovered-ground-truth attraction term, explicitly decoupling recall and precision into tunable components.
  Across diverse pipelines, QAL achieves consistent coverage gains, improving by an average of +4.3 pts over CD and +2.8 pts over the best alternatives. Though modest in percentage, these improvements reliably recover thin structures and under-represented regions that CD/EMD overlook. Extensive ablations confirm stable performance across hyperparameters and across output resolutions, while full retraining on PCN and ShapeNet demonstrates generalization across datasets and backbones. Moreover, QAL-trained completions yield higher grasp scores under GraspNet evaluation, showing that improved coverage translates directly into more reliable robotic manipulation.
  QAL thus offers a principled, interpretable, and practical objective for robust 3D vision and safety-critical robotics pipelines

</details>


### [38] [Toward explainable AI approaches for breast imaging: adapting foundation models to diverse populations](https://arxiv.org/abs/2511.17828)
*Guilherme J. Cavalcante,José Gabriel A. Moreira,Gabriel A. B. do Nascimento,Vincent Dong,Alex Nguyen,Thaís G. do Rêgo,Yuri Malheiros,Telmo M. Silva Filho,Carla R. Zeballos Torrez,James C. Gee,Anne Marie McCarthy,Andrew D. A. Maidment,Bruno Barufaldi*

Main category: cs.CV

TL;DR: 该研究利用BiomedCLIP基础模型进行乳腺影像BI-RADS密度分类，通过多模态训练方法在96,995张图像上取得了良好性能，并展现出强大的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 基础模型在医学影像任务中具有潜力，但在乳腺影像领域的有效性尚未充分探索。本研究旨在解决模型泛化挑战，验证基础模型在乳腺成像中的应用价值。

Method: 使用BiomedCLIP基础模型，采用多模态乳腺影像数据（合成2D图像、数字乳腺X线摄影和数字乳腺断层合成），通过加权对比学习解决类别不平衡问题，比较单模态和多模态训练方法。

Result: 多模态和单模态方法准确率相近（0.74 vs 0.73），但多模态模型在不同成像模态中具有更广泛适用性，AUC值始终高于0.84。在外部验证数据集上AUC范围为0.80-0.93，GradCAM可视化显示一致且临床相关的注意力模式。

Conclusion: 该研究证实了基础模型在乳腺影像应用中的潜力，为未来扩展到诊断任务奠定了基础。

Abstract: Foundation models hold promise for specialized medical imaging tasks, though their effectiveness in breast imaging remains underexplored. This study leverages BiomedCLIP as a foundation model to address challenges in model generalization. BiomedCLIP was adapted for automated BI-RADS breast density classification using multi-modality mammographic data (synthesized 2D images, digital mammography, and digital breast tomosynthesis). Using 96,995 images, we compared single-modality (s2D only) and multi-modality training approaches, addressing class imbalance through weighted contrastive learning. Both approaches achieved similar accuracy (multi-modality: 0.74, single-modality: 0.73), with the multi-modality model offering broader applicability across different imaging modalities and higher AUC values consistently above 0.84 across BI-RADS categories. External validation on the RSNA and EMBED datasets showed strong generalization capabilities (AUC range: 0.80-0.93). GradCAM visualizations confirmed consistent and clinically relevant attention patterns, highlighting the models interpretability and robustness. This research underscores the potential of foundation models for breast imaging applications, paving the way for future extensions for diagnostic tasks.

</details>


### [39] [Show Me: Unifying Instructional Image and Video Generation with Diffusion Models](https://arxiv.org/abs/2511.17839)
*Yujiang Pu,Zhanbo Huang,Vishnu Boddeti,Yu Kong*

Main category: cs.CV

TL;DR: ShowMe是一个统一框架，通过选择性激活视频扩散模型的空间和时间组件，同时实现文本引导的图像操作和视频预测任务。


<details>
  <summary>Details</summary>
Motivation: 现有方法将图像操作和视频预测视为独立任务，导致图像操作方法忽略动作随时间展开，而视频预测模型忽视预期结果。需要统一框架来解决这一问题。

Method: 提出ShowMe框架，选择性激活视频扩散模型的空间和时间组件，引入结构和运动一致性奖励来改善结构保真度和时间连贯性。

Result: 在多样化基准测试中，该方法在指令性图像和视频生成方面均优于专家模型。

Conclusion: 视频扩散模型作为统一的动作-状态转换器具有强大潜力，统一框架带来双重益处：视频预训练的空间知识增强非刚性图像编辑的上下文一致性和真实感，而指令引导的操作阶段为视频预测提供更强的目标导向推理能力。

Abstract: Generating visual instructions in a given context is essential for developing interactive world simulators. While prior works address this problem through either text-guided image manipulation or video prediction, these tasks are typically treated in isolation. This separation reveals a fundamental issue: image manipulation methods overlook how actions unfold over time, while video prediction models often ignore the intended outcomes. To this end, we propose ShowMe, a unified framework that enables both tasks by selectively activating the spatial and temporal components of video diffusion models. In addition, we introduce structure and motion consistency rewards to improve structural fidelity and temporal coherence. Notably, this unification brings dual benefits: the spatial knowledge gained through video pretraining enhances contextual consistency and realism in non-rigid image edits, while the instruction-guided manipulation stage equips the model with stronger goal-oriented reasoning for video prediction. Experiments on diverse benchmarks demonstrate that our method outperforms expert models in both instructional image and video generation, highlighting the strength of video diffusion models as a unified action-object state transformer.

</details>


### [40] [JigsawComm: Joint Semantic Feature Encoding and Transmission for Communication-Efficient Cooperative Perception](https://arxiv.org/abs/2511.17843)
*Chenyi Wang,Zhaowei Li,Ming F. Li,Wujie Wen*

Main category: cs.CV

TL;DR: JigsawComm是一个端到端训练的语义感知多智能体协同感知框架，通过提取语义相关特征和优化传输策略，在有限带宽下实现高效通信和准确感知。


<details>
  <summary>Details</summary>
Motivation: 多智能体协同感知系统受限于通信带宽，现有方法未充分考虑语义相关性和跨智能体冗余性，需要最大化每个传输比特对感知任务的贡献。

Method: 提出JigsawComm框架，包括正则化编码器提取语义相关稀疏特征，特征效用估计器预测特征贡献，基于效用图的最优传输策略选择最高效用特征。

Result: 在OPV2V和DAIR-V2X基准测试中，JigsawComm将总数据量减少500倍以上，同时达到或优于最先进方法的准确率。

Conclusion: JigsawComm通过语义感知的特征传输策略，有效解决了多智能体协同感知的带宽限制问题，实现了可扩展的高效通信。

Abstract: Multi-agent cooperative perception (CP) promises to overcome the inherent occlusion and sensing-range limitations of single-agent systems (e.g., autonomous driving). However, its practicality is severely constrained by the limited communication bandwidth. Existing approaches attempt to improve bandwidth efficiency via compression or heuristic message selection, without considering the semantic relevance or cross-agent redundancy of sensory data. We argue that a practical CP system must maximize the contribution of every transmitted bit to the final perception task, by extracting and transmitting semantically essential and non-redundant data. In this paper, we formulate a joint semantic feature encoding and transmission problem, which aims to maximize CP accuracy under limited bandwidth. To solve this problem, we introduce JigsawComm, an end-to-end trained, semantic-aware, and communication-efficient CP framework that learns to ``assemble the puzzle'' of multi-agent feature transmission. It uses a regularized encoder to extract semantically-relevant and sparse features, and a lightweight Feature Utility Estimator to predict the contribution of each agent's features to the final perception task. The resulting meta utility maps are exchanged among agents and leveraged to compute a provably optimal transmission policy, which selects features from agents with the highest utility score for each location. This policy inherently eliminates redundancy and achieves a scalable $\mathcal{O}(1)$ communication cost as the number of agents increases. On the benchmarks OPV2V and DAIR-V2X, JigsawComm reduces the total data volume by up to $>$500$\times$ while achieving matching or superior accuracy compared to state-of-the-art methods.

</details>


### [41] [Less is More: Data-Efficient Adaptation for Controllable Text-to-Video Generation](https://arxiv.org/abs/2511.17844)
*Shihan Cheng,Nilesh Kulkarni,David Hyde,Dmitriy Smirnov*

Main category: cs.CV

TL;DR: 提出一种数据高效微调策略，从稀疏低质量合成数据中学习物理相机参数控制，效果优于使用真实数据微调。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要大量高质量数据集来微调文本到视频扩散模型以添加物理相机参数控制，但这些数据难以获取。

Method: 开发了一种数据高效的微调策略，仅使用稀疏、低质量的合成数据进行训练。

Result: 使用简单合成数据微调不仅能实现所需的相机参数控制，而且效果优于使用真实照片级数据微调的模型。

Conclusion: 提供了一个理论框架来直观和定量地解释这一现象，证明简单合成数据在特定任务中的优越性。

Abstract: Fine-tuning large-scale text-to-video diffusion models to add new generative controls, such as those over physical camera parameters (e.g., shutter speed or aperture), typically requires vast, high-fidelity datasets that are difficult to acquire. In this work, we propose a data-efficient fine-tuning strategy that learns these controls from sparse, low-quality synthetic data. We show that not only does fine-tuning on such simple data enable the desired controls, it actually yields superior results to models fine-tuned on photorealistic "real" data. Beyond demonstrating these results, we provide a framework that justifies this phenomenon both intuitively and quantitatively.

</details>


### [42] [MGA-VQA: Secure and Interpretable Graph-Augmented Visual Question Answering with Memory-Guided Protection Against Unauthorized Knowledge Use](https://arxiv.org/abs/2511.17881)
*Ahmad Mohammadshirazi,Pinaki Prasad Guha Neogi,Dheeraj Kulshrestha,Rajiv Ramnath*

Main category: cs.CV

TL;DR: MGA-VQA是一个多模态文档视觉问答框架，通过图推理和记忆增强机制解决现有方法在空间关系建模、高分辨率处理、多跳推理和可解释性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 当前DocVQA方法存在四个主要问题：显式空间关系建模困难、高分辨率文档处理效率低、多跳推理能力弱、模型可解释性有限。

Method: 提出MGA-VQA框架，集成词元级编码、空间图推理、记忆增强推理和问题引导压缩四个核心模块，引入可解释的图决策路径和结构化记忆访问机制。

Result: 在六个基准数据集（FUNSD、CORD、SROIE、DocVQA、STE-VQA、RICO）上评估显示，模型在答案预测和空间定位方面均取得显著提升，具有优越的准确性和效率。

Conclusion: MGA-VQA通过多模态融合和图推理机制有效解决了DocVQA的关键挑战，在保持高效性的同时提供了更好的可解释性，为文档理解任务提供了新的解决方案。

Abstract: Document Visual Question Answering (DocVQA) requires models to jointly understand textual semantics, spatial layout, and visual features. Current methods struggle with explicit spatial relationship modeling, inefficiency with high-resolution documents, multi-hop reasoning, and limited interpretability. We propose MGA-VQA, a multi-modal framework that integrates token-level encoding, spatial graph reasoning, memory-augmented inference, and question-guided compression. Unlike prior black-box models, MGA-VQA introduces interpretable graph-based decision pathways and structured memory access for enhanced reasoning transparency. Evaluation across six benchmarks (FUNSD, CORD, SROIE, DocVQA, STE-VQA, and RICO) demonstrates superior accuracy and efficiency, with consistent improvements in both answer prediction and spatial localization.

</details>


### [43] [ArticFlow: Generative Simulation of Articulated Mechanisms](https://arxiv.org/abs/2511.17883)
*Jiong Lin,Jinchen Ruan,Hod Lipson*

Main category: cs.CV

TL;DR: ArticFlow是一个两阶段流匹配框架，用于生成可控的关节式3D形状，通过动作条件控制实现从噪声到目标点集的转换。


<details>
  <summary>Details</summary>
Motivation: 当前生成模型在静态3D形状生成方面表现良好，但关节式3D生成由于动作依赖变形和数据集有限而面临挑战。

Method: ArticFlow包含两个耦合的流：(i) 潜在流将噪声传输到形状先验代码；(ii) 点流在动作和形状先验条件下传输点，使单个模型能够表示多样化的关节类别并在动作间泛化。

Result: 在MuJoCo Menagerie上，ArticFlow既作为生成模型又作为神经模拟器：从紧凑先验预测动作条件运动学，并通过潜在插值合成新形态。相比特定对象模拟器和动作条件静态点云生成器变体，ArticFlow实现了更高的运动学精度和更好的形状质量。

Conclusion: 动作条件流匹配是实现可控、高质量关节机制生成的实用途径。

Abstract: Recent advances in generative models have produced strong results for static 3D shapes, whereas articulated 3D generation remains challenging due to action-dependent deformations and limited datasets. We introduce ArticFlow, a two-stage flow matching framework that learns a controllable velocity field from noise to target point sets under explicit action control. ArticFlow couples (i) a latent flow that transports noise to a shape-prior code and (ii) a point flow that transports points conditioned on the action and the shape prior, enabling a single model to represent diverse articulated categories and generalize across actions. On MuJoCo Menagerie, ArticFlow functions both as a generative model and as a neural simulator: it predicts action-conditioned kinematics from a compact prior and synthesizes novel morphologies via latent interpolation. Compared with object-specific simulators and an action-conditioned variant of static point-cloud generators, ArticFlow achieves higher kinematic accuracy and better shape quality. Results show that action-conditioned flow matching is a practical route to controllable and high-quality articulated mechanism generation.

</details>


### [44] [FastMMoE: Accelerating Multimodal Large Language Models through Dynamic Expert Activation and Routing-Aware Token Pruning](https://arxiv.org/abs/2511.17885)
*Guoyang Xia,Yifeng Ding,Fengfa Li,Lei Ren,Wei Chen,Fangxiang Feng,Xiaojie Wang*

Main category: cs.CV

TL;DR: FastMMoE是一个无需训练的加速框架，针对基于专家混合（MoE）的多模态大语言模型，通过减少专家激活和路由感知的token剪枝来降低计算开销，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 高分辨率视觉输入导致视觉token序列过长和推理延迟显著，现有剪枝方法主要针对密集架构，缺乏对MoE架构的优化。

Method: 结合两种策略：视觉token的专家激活减少和基于路由概率分布相似性的token剪枝。

Result: 在DeepSeek-VL2和InternVL3.5等模型上，FLOPs减少高达55.0%，同时保留约95.5%的原始性能，优于密集模型剪枝基线。

Conclusion: FastMMoE有效解决了MoE-MLLMs的计算效率问题，为资源受限场景提供了可行的部署方案。

Abstract: Multimodal large language models (MLLMs) have achieved impressive performance, but high-resolution visual inputs result in long sequences of visual tokens and substantial inference latency. Reducing redundant visual tokens is critical to ease computational/memory burdens while preserving performance, enabling MLLM deployment in resource-constrained or latency-sensitive scenarios. Current visual token pruning methods mainly rely on attention-based redundancy analysis and are tailored to dense architectures. We propose Fast Multimodal Mixture-of-Experts (FastMMoE), a training-free acceleration framework for mixture-of-experts (MoE) based MLLMs, developed from a routing analysis perspective. FastMMoE combines two complementary strategies: (i) expert activation reduction for visual tokens to minimize unnecessary expert computation; and (ii) routing-aware token pruning that leverages similarity in routing probability distributions to identify and remove highly redundant visual tokens. Experiments on large-scale MoE-MLLMs such as DeepSeek-VL2 and InternVL3.5 demonstrate that FastMMoE can reduce FLOPs by up to 55.0% while retaining approximately 95.5% of the original performance, consistently outperforming dense-model pruning baselines including FastV and SparseVLM across multiple retention rates.

</details>


### [45] [When Better Teachers Don't Make Better Students: Revisiting Knowledge Distillation for CLIP Models in VQA](https://arxiv.org/abs/2511.17886)
*Pume Tuchinda,Parinthapat Pengpun,Romrawin Chumpu,Sarana Nutanong,Peerat Limkonchotiwat*

Main category: cs.CV

TL;DR: 对CLIP风格视觉语言模型进行知识蒸馏的系统性研究，发现更强的教师模型并不总是产生更好的学生模型，现有蒸馏框架在多模态任务中存在扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型计算需求大，知识蒸馏是构建轻量级模型的有效方法，但在CLIP风格模型中的应用仍有限，主要局限于小规模教师模型和狭窄评估任务。

Method: 对一系列CLIP风格教师模型进行系统性蒸馏研究，涵盖从标准基线到大规模最先进模型的范围。

Result: 与NLP和视觉领域趋势相反，更强的教师模型不能持续产生更好的学生模型，现有蒸馏框架在多模态任务中性能下降。

Conclusion: 研究结果挑战了知识蒸馏的现有假设，为设计参数高效的多模态模型指出了新方向。

Abstract: Vision-language models (VLMs) have achieved remarkable success across multimodal tasks, yet their substantial computational demands hinder efficient deployment. Knowledge distillation (KD) has emerged as a powerful approach for building lightweight but competitive models, with strong evidence from both language and vision domains. However, its application to VLMs, particularly CLIP-style models, remains limited, often constrained to small-scale teachers and narrow evaluation tasks such as classification or retrieval. In this work, we present the first systematic study of distillation across a range of CLIP-style teacher models, ranging from standard baselines to large-scale state-of-the-art models. Contrary to trends observed in NLP and vision, we find that stronger teachers do not consistently yield better students; in fact, existing distillation frameworks often fail to scale, leading to degraded performance in downstream multimodal tasks such as visual question answering. Our findings challenge prevailing assumptions in KD and point toward new directions for designing parameter-efficient multimodal models.

</details>


### [46] [MINDiff: Mask-Integrated Negative Attention for Controlling Overfitting in Text-to-Image Personalization](https://arxiv.org/abs/2511.17888)
*Seulgi Jeong,Jaeil Kim*

Main category: cs.CV

TL;DR: MINDiff提出了一种新的负注意力机制，通过在推理时修改交叉注意力来抑制无关区域中的主体影响，从而解决个性化文本到图像模型中的过拟合问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法如DreamBooth通过类特定先验保留损失来缓解过拟合，但需要增加训练计算成本且在推理时限制用户控制。

Method: MINDiff引入负注意力概念，在推理时修改交叉注意力机制，在掩码无关区域中抑制主体的影响，用户可通过调整lambda参数平衡主体保真度和文本对齐。

Result: 定性和定量实验表明，MINDiff比类特定先验保留损失更有效地缓解过拟合，且无需重新训练即可直接应用于现有DreamBooth模型。

Conclusion: MINDiff是一种在推理时操作的轻量级方法，能够有效改善个性化文本到图像模型的语义控制和文本对齐能力。

Abstract: In the personalization process of large-scale text-to-image models, overfitting often occurs when learning specific subject from a limited number of images. Existing methods, such as DreamBooth, mitigate this issue through a class-specific prior-preservation loss, which requires increased computational cost during training and limits user control during inference time. To address these limitations, we propose Mask-Integrated Negative Attention Diffusion (MINDiff). MINDiff introduces a novel concept, negative attention, which suppresses the subject's influence in masked irrelevant regions. We achieve this by modifying the cross-attention mechanism during inference. This enables semantic control and improves text alignment by reducing subject dominance in irrelevant regions. Additionally, during the inference time, users can adjust a scale parameter lambda to balance subject fidelity and text alignment. Our qualitative and quantitative experiments on DreamBooth models demonstrate that MINDiff mitigates overfitting more effectively than class-specific prior-preservation loss. As our method operates entirely at inference time and does not alter the model architecture, it can be directly applied to existing DreamBooth models without re-training. Our code is available at https://github.com/seuleepy/MINDiff.

</details>


### [47] [Decoupled Audio-Visual Dataset Distillation](https://arxiv.org/abs/2511.17890)
*Wenyuan Li,Guang Li,Keisuke Maeda,Takahiro Ogawa,Miki Haseyama*

Main category: cs.CV

TL;DR: 本文提出DAVDD框架，通过预训练解耦的音频-视觉蒸馏方法解决传统分布匹配方法在跨模态对齐中的挑战，实现了最先进的音频-视觉数据集蒸馏性能。


<details>
  <summary>Details</summary>
Motivation: 传统分布匹配方法难以捕捉跨模态对齐，现有方法存在模态映射空间不一致和跨模态交互损害私有信息的问题。

Method: 使用预训练编码器获取稳定模态特征，通过轻量级解耦器分离为公共和私有表示，结合公共跨模态匹配和样本-分布联合对齐策略。

Result: 在多个基准测试中，DAVDD在所有IPC设置下均达到最先进结果。

Conclusion: 解耦表示学习能有效实现高质量的音频-视觉数据集蒸馏。

Abstract: Audio-Visual Dataset Distillation aims to compress large-scale datasets into compact subsets while preserving the performance of the original data. However, conventional Distribution Matching (DM) methods struggle to capture intrinsic cross-modal alignment. Subsequent studies have attempted to introduce cross-modal matching, but two major challenges remain: (i) independently and randomly initialized encoders lead to inconsistent modality mapping spaces, increasing training difficulty; and (ii) direct interactions between modalities tend to damage modality-specific (private) information, thereby degrading the quality of the distilled data. To address these challenges, we propose DAVDD, a pretraining-based decoupled audio-visual distillation framework. DAVDD leverages a diverse pretrained bank to obtain stable modality features and uses a lightweight decoupler bank to disentangle them into common and private representations. To effectively preserve cross-modal structure, we further introduce Common Intermodal Matching together with a Sample-Distribution Joint Alignment strategy, ensuring that shared representations are aligned both at the sample level and the global distribution level. Meanwhile, private representations are entirely isolated from cross-modal interaction, safeguarding modality-specific cues throughout distillation. Extensive experiments across multiple benchmarks show that DAVDD achieves state-of-the-art results under all IPC settings, demonstrating the effectiveness of decoupled representation learning for high-quality audio-visual dataset distillation. Code will be released.

</details>


### [48] [CUS-GS: A Compact Unified Structured Gaussian Splatting Framework for Multimodal Scene Representation](https://arxiv.org/abs/2511.17904)
*Yuhang Ming,Chenxin Fang,Xingyuan Yu,Fan Zhang,Weichen Dai,Wanzeng Kong,Guofeng Zhang*

Main category: cs.CV

TL;DR: CUS-GS是一种紧凑的统一结构化高斯泼溅表示方法，通过体素化锚点结构连接多模态语义特征与结构化3D几何，实现了语义导向和结构导向方法的优势结合。


<details>
  <summary>Details</summary>
Motivation: 现有高斯泼溅方法存在语义导向方法缺乏显式3D几何建模，而结构导向方法语义抽象能力有限的问题。需要一种能同时兼顾语义理解和几何结构的统一表示方法。

Method: 设计了体素化锚点结构构建空间支架，从基础模型提取多模态语义特征；引入多模态潜在特征分配机制统一异构特征空间；提出特征感知显著性评估策略动态指导锚点生长和剪枝。

Result: 实验表明CUS-GS仅用600万参数就达到与最先进方法相当的性能，比最接近的竞争对手（3500万参数）小一个数量级，在性能和模型效率之间取得了优秀平衡。

Conclusion: CUS-GS成功弥合了语义导向和结构导向方法之间的鸿沟，提供了一种紧凑且高效的多模态3D场景表示框架。

Abstract: Recent advances in Gaussian Splatting based 3D scene representation have shown two major trends: semantics-oriented approaches that focus on high-level understanding but lack explicit 3D geometry modeling, and structure-oriented approaches that capture spatial structures yet provide limited semantic abstraction. To bridge this gap, we present CUS-GS, a compact unified structured Gaussian Splatting representation, which connects multimodal semantic features with structured 3D geometry. Specifically, we design a voxelized anchor structure that constructs a spatial scaffold, while extracting multimodal semantic features from a set of foundation models (e.g., CLIP, DINOv2, SEEM). Moreover, we introduce a multimodal latent feature allocation mechanism to unify appearance, geometry, and semantics across heterogeneous feature spaces, ensuring a consistent representation across multiple foundation models. Finally, we propose a feature-aware significance evaluation strategy to dynamically guide anchor growing and pruning, effectively removing redundant or invalid anchors while maintaining semantic integrity. Extensive experiments show that CUS-GS achieves competitive performance compared to state-of-the-art methods using as few as 6M parameters - an order of magnitude smaller than the closest rival at 35M - highlighting the excellent trade off between performance and model efficiency of the proposed framework.

</details>


### [49] [Rectifying Soft-Label Entangled Bias in Long-Tailed Dataset Distillation](https://arxiv.org/abs/2511.17914)
*Chenyang Jiang,Hang Zhao,Xinyu Zhang,Zhengcen Li,Qiben Shan,Shaocong Wu,Jingyong Su*

Main category: cs.CV

TL;DR: ADSA提出了一种自适应软标签对齐模块，用于解决长尾数据集蒸馏中的性能下降问题，通过校准蒸馏模型和蒸馏图像中的软标签偏差，显著提升尾类准确率。


<details>
  <summary>Details</summary>
Motivation: 现有数据集蒸馏方法主要针对平衡数据集，在现实世界长尾分布下性能不佳。研究发现软标签在长尾数据集蒸馏中起关键作用，但存在偏差问题。

Method: 提出了ADSA（自适应软标签对齐模块），通过系统性扰动数据不平衡水平识别软标签偏差来源，并设计轻量级模块校准这些偏差，可无缝集成到现有蒸馏流程中。

Result: 在ImageNet-1k-LT数据集上，ADSA将尾类准确率提升高达11.8%，整体准确率达到41.4%（IPC=50），在各种蒸馏技术下均表现出稳健性和通用性。

Conclusion: ADSA为解决长尾数据集蒸馏中的软标签偏差问题提供了有效方案，在有限标签预算下具有优秀的性能表现。

Abstract: Dataset distillation compresses large-scale datasets into compact, highly informative synthetic data, significantly reducing storage and training costs. However, existing research primarily focuses on balanced datasets and struggles to perform under real-world long-tailed distributions. In this work, we emphasize the critical role of soft labels in long-tailed dataset distillation and uncover the underlying mechanisms contributing to performance degradation. Specifically, we derive an imbalance-aware generalization bound for model trained on distilled dataset. We then identify two primary sources of soft-label bias, which originate from the distillation model and the distilled images, through systematic perturbation of the data imbalance levels. To address this, we propose ADSA, an Adaptive Soft-label Alignment module that calibrates the entangled biases. This lightweight module integrates seamlessly into existing distillation pipelines and consistently improves performance. On ImageNet-1k-LT with EDC and IPC=50, ADSA improves tail-class accuracy by up to 11.8% and raises overall accuracy to 41.4%. Extensive experiments demonstrate that ADSA provides a robust and generalizable solution under limited label budgets and across a range of distillation techniques. Code is available at: https://github.com/j-cyoung/ADSA_DD.git.

</details>


### [50] [Frequency-Adaptive Sharpness Regularization for Improving 3D Gaussian Splatting Generalization](https://arxiv.org/abs/2511.17918)
*Youngsik Yun,Dongjun Gu,Youngjung Uh*

Main category: cs.CV

TL;DR: 该论文提出了一种频率自适应锐度正则化方法(FASR)，通过改进3D高斯泼溅(3DGS)的训练目标来解决少样本场景下新视角合成中的过拟合问题。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅在大多数配置下表现出色，但在少样本场景中缺乏对新视角的泛化能力，因为它会过度拟合稀疏的观测数据。作者从机器学习角度重新审视3DGS优化，将新视角合成视为对未见视角的泛化问题。

Method: 提出FASR方法，通过反映图像的局部频率来设置正则化权重和邻域半径，在估计局部锐度时进行自适应调整。这防止了在新视角中出现浮游伪影，同时重建了SAM方法容易过度平滑的精细细节。

Result: 在各种配置的数据集上，该方法持续改进了广泛的基线模型，在保持高频细节的同时提高了泛化性能。

Conclusion: FASR通过频率自适应正则化有效解决了3DGS在少样本场景中的过拟合问题，显著提升了新视角合成的质量。

Abstract: Despite 3D Gaussian Splatting (3DGS) excelling in most configurations, it lacks generalization across novel viewpoints in a few-shot scenario because it overfits to the sparse observations. We revisit 3DGS optimization from a machine learning perspective, framing novel view synthesis as a generalization problem to unseen viewpoints-an underexplored direction. We propose Frequency-Adaptive Sharpness Regularization (FASR), which reformulates the 3DGS training objective, thereby guiding 3DGS to converge toward a better generalization solution. Although Sharpness-Aware Minimization (SAM) similarly reduces the sharpness of the loss landscape to improve generalization of classification models, directly employing it to 3DGS is suboptimal due to the discrepancy between the tasks. Specifically, it hinders reconstructing high-frequency details due to excessive regularization, while reducing its strength leads to under-penalizing sharpness. To address this, we reflect the local frequency of images to set the regularization weight and the neighborhood radius when estimating the local sharpness. It prevents floater artifacts in novel viewpoints and reconstructs fine details that SAM tends to oversmooth. Across datasets with various configurations, our method consistently improves a wide range of baselines. Code will be available at https://bbangsik13.github.io/FASR.

</details>


### [51] [PA-FAS: Towards Interpretable and Generalizable Multimodal Face Anti-Spoofing via Path-Augmented Reinforcement Learning](https://arxiv.org/abs/2511.17927)
*Yingjie Ma,Xun Lin,Yong Xu,Weicheng Xie,Zitong Yu*

Main category: cs.CV

TL;DR: PA-FAS方法通过扩展推理路径和答案打乱机制，解决了多模态人脸反欺诈中RL方法的局限性，显著提升了推理准确性和跨域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 多模态人脸反欺诈在融合、泛化和可解释性方面面临挑战，传统SFT+RL方法存在推理路径受限和推理混淆问题，限制了多模态互补优势的发挥。

Method: 提出PA-FAS方法：1）从有限标注构建高质量扩展推理序列，丰富推理路径；2）在SFT阶段引入答案打乱机制，强制全面多模态分析而非使用表面线索。

Result: PA-FAS显著提高了多模态推理准确性和跨域泛化能力，更好地统一了多模态融合、泛化和可解释性。

Conclusion: PA-FAS通过增强推理路径和防止捷径学习，为可信赖的人脸反欺诈系统提供了有效的多模态推理解决方案。

Abstract: Face anti-spoofing (FAS) has recently advanced in multimodal fusion, cross-domain generalization, and interpretability. With large language models and reinforcement learning (RL), strategy-based training offers new opportunities to jointly model these aspects. However, multimodal reasoning is more complex than unimodal reasoning, requiring accurate feature representation and cross-modal verification while facing scarce, high-quality annotations, which makes direct application of RL sub-optimal. We identify two key limitations of supervised fine-tuning plus RL (SFT+RL) for multimodal FAS: (1) limited multimodal reasoning paths restrict the use of complementary modalities and shrink the exploration space after SFT, weakening the effect of RL; and (2) mismatched single-task supervision versus diverse reasoning paths causes reasoning confusion, where models may exploit shortcuts by mapping images directly to answers and ignoring the intended reasoning. To address this, we propose PA-FAS, which enhances reasoning paths by constructing high-quality extended reasoning sequences from limited annotations, enriching paths and relaxing exploration constraints. We further introduce an answer-shuffling mechanism during SFT to force comprehensive multimodal analysis instead of using superficial cues, thereby encouraging deeper reasoning and mitigating shortcut learning. PA-FAS significantly improves multimodal reasoning accuracy and cross-domain generalization, and better unifies multimodal fusion, generalization, and interpretability for trustworthy FAS.

</details>


### [52] [MambaTAD: When State-Space Models Meet Long-Range Temporal Action Detection](https://arxiv.org/abs/2511.17929)
*Hui Lu,Yi Yu,Shijian Lu,Deepu Rajan,Boon Poh Ng,Alex C. Kot,Xudong Jiang*

Main category: cs.CV

TL;DR: MambaTAD是一个基于状态空间模型的时序动作检测方法，通过双向状态空间模块和全局特征融合头解决长跨度动作检测问题，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统时序动作检测方法在处理长跨度动作实例时缺乏全局感知能力，而现有的状态空间模型存在时间上下文衰减和自元素冲突问题，需要新的解决方案。

Method: 提出MambaTAD模型，包含对角掩码双向状态空间模块（DMBSS）促进全局特征融合，以及全局特征融合头进行多粒度特征细化，采用端到端单阶段检测方式。

Result: 在多个公开基准测试中，MambaTAD实现了优异的时序动作检测性能，验证了方法的有效性。

Conclusion: MambaTAD通过创新的状态空间建模和全局特征融合机制，成功解决了长跨度动作检测的挑战，为时序动作检测提供了新的有效解决方案。

Abstract: Temporal Action Detection (TAD) aims to identify and localize actions by determining their starting and ending frames within untrimmed videos. Recent Structured State-Space Models such as Mamba have demonstrated potential in TAD due to their long-range modeling capability and linear computational complexity. On the other hand, structured state-space models often face two key challenges in TAD, namely, decay of temporal context due to recursive processing and self-element conflict during global visual context modeling, which become more severe while handling long-span action instances. Additionally, traditional methods for TAD struggle with detecting long-span action instances due to a lack of global awareness and inefficient detection heads. This paper presents MambaTAD, a new state-space TAD model that introduces long-range modeling and global feature detection capabilities for accurate temporal action detection. MambaTAD comprises two novel designs that complement each other with superior TAD performance. First, it introduces a Diagonal-Masked Bidirectional State-Space (DMBSS) module which effectively facilitates global feature fusion and temporal action detection. Second, it introduces a global feature fusion head that refines the detection progressively with multi-granularity features and global awareness. In addition, MambaTAD tackles TAD in an end-to-end one-stage manner using a new state-space temporal adapter(SSTA) which reduces network parameters and computation cost with linear complexity. Extensive experiments show that MambaTAD achieves superior TAD performance consistently across multiple public benchmarks.

</details>


### [53] [UniRSCD: A Unified Novel Architectural Paradigm for Remote Sensing Change Detection](https://arxiv.org/abs/2511.17930)
*Yuan Qu,Zhipeng Zhang,Chaojun Xu,Qiao Wan,Mengying Xie,Yuzeng Chen,Zhenqi Liu,Yanfei Zhong*

Main category: cs.CV

TL;DR: 本文提出了一种统一的多粒度遥感变化检测框架UniRSCD，通过频域变化提示生成器和统一解码器，无需为不同任务设计专用解码器，在多个数据集上取得领先性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要专家知识设计专用解码器来补偿编码过程中的信息损失，这限制了模型的通用性，特别是在突发变化场景下选择最优模型存在不确定性。

Method: 基于状态空间模型构建统一编码器，通过频域变化提示生成器动态扫描双时相全局上下文信息，集成高频细节和低频整体信息；统一解码器通过层次特征交互和任务自适应输出映射建立共享表示空间。

Result: 在五个数据集上实验验证，包括二进制变化数据集LEVIR-CD、语义变化数据集SECOND和建筑损伤评估数据集xBD，均取得了领先性能。

Conclusion: UniRSCD框架能够适应多种变化检测任务，将不同输出粒度的任务整合到统一架构中，解决了现有方法通用性不足的问题。

Abstract: In recent years, remote sensing change detection has garnered significant attention due to its critical role in resource monitoring and disaster assessment. Change detection tasks exist with different output granularities such as BCD, SCD, and BDA. However, existing methods require substantial expert knowledge to design specialized decoders that compensate for information loss during encoding across different tasks. This not only introduces uncertainty into the process of selecting optimal models for abrupt change scenarios (such as disaster outbreaks) but also limits the universality of these architectures. To address these challenges, this paper proposes a unified, general change detection framework named UniRSCD. Building upon a state space model backbone, we introduce a frequency change prompt generator as a unified encoder. The encoder dynamically scans bitemporal global context information while integrating high-frequency details with low-frequency holistic information, thereby eliminating the need for specialized decoders for feature compensation. Subsequently, the unified decoder and prediction head establish a shared representation space through hierarchical feature interaction and task-adaptive output mapping. This integrating various tasks such as binary change detection and semantic change detection into a unified architecture, thereby accommodating the differing output granularity requirements of distinct change detection tasks. Experimental results demonstrate that the proposed architecture can adapt to multiple change detection tasks and achieves leading performance on five datasets, including the binary change dataset LEVIR-CD, the semantic change dataset SECOND, and the building damage assessment dataset xBD.

</details>


### [54] [Novel View Synthesis from A Few Glimpses via Test-Time Natural Video Completion](https://arxiv.org/abs/2511.17932)
*Yan Xu,Yixing Wang,Stella X. Yu*

Main category: cs.CV

TL;DR: 提出了一种基于预训练视频扩散模型的零样本稀疏输入新视角合成方法，通过生成伪视图和3D高斯泼溅的迭代反馈循环，在极稀疏输入下实现高质量场景重建和视频补全。


<details>
  <summary>Details</summary>
Motivation: 解决稀疏输入下新视角合成的挑战，不仅要填补空间视图间的空白，还要完成通过空间展开的自然视频补全任务。

Method: 使用预训练视频扩散模型进行测试时自然视频补全，通过不确定性感知机制生成伪视图，结合3D高斯泼溅进行场景重建，并建立迭代反馈循环相互优化。

Result: 在LLFF、DTU、DL3DV和MipNeRF-360数据集上，该方法在极端稀疏条件下显著优于强3D-GS基线，无需任何场景特定训练或微调。

Conclusion: 该方法实现了从稀疏输入生成连贯、高保真渲染的目标，为零样本稀疏视图合成提供了有效解决方案。

Abstract: Given just a few glimpses of a scene, can you imagine the movie playing out as the camera glides through it? That's the lens we take on \emph{sparse-input novel view synthesis}, not only as filling spatial gaps between widely spaced views, but also as \emph{completing a natural video} unfolding through space.
  We recast the task as \emph{test-time natural video completion}, using powerful priors from \emph{pretrained video diffusion models} to hallucinate plausible in-between views. Our \emph{zero-shot, generation-guided} framework produces pseudo views at novel camera poses, modulated by an \emph{uncertainty-aware mechanism} for spatial coherence. These synthesized frames densify supervision for \emph{3D Gaussian Splatting} (3D-GS) for scene reconstruction, especially in under-observed regions. An iterative feedback loop lets 3D geometry and 2D view synthesis inform each other, improving both the scene reconstruction and the generated views.
  The result is coherent, high-fidelity renderings from sparse inputs \emph{without any scene-specific training or fine-tuning}. On LLFF, DTU, DL3DV, and MipNeRF-360, our method significantly outperforms strong 3D-GS baselines under extreme sparsity.

</details>


### [55] [V2X-RECT: An Efficient V2X Trajectory Prediction Framework via Redundant Interaction Filtering and Tracking Error Correction](https://arxiv.org/abs/2511.17941)
*Xiangyan Kong,Xuecheng Wu,Xiongwei Zhao,Xiaodong Li,Yunyun Shi,Gang Wang,Dingkang Yang,Yang Liu,Hong Chen,Yulong Gao*

Main category: cs.CV

TL;DR: V2X-RECT是一个针对高密度交通场景的轨迹预测框架，通过多源身份匹配校正、交通信号引导交互和局部时空坐标编码，解决了目标身份切换、冗余交互和重复编码等问题，实现了更高效准确的预测。


<details>
  <summary>Details</summary>
Motivation: 在密集交通场景中，频繁的目标身份切换阻碍了跨视角关联和融合，多源信息在编码阶段产生冗余交互，传统车辆中心编码导致大量重复历史轨迹特征编码，影响实时推理性能。

Method: 1. 多源身份匹配校正模块：利用多视角时空关系实现稳定一致的目标关联；2. 交通信号引导交互模块：编码交通灯变化趋势特征，过滤关键交互车辆；3. 局部时空坐标编码：实现历史轨迹和地图特征的可重用性，支持并行解码。

Result: 在V2X-Seq和V2X-Traj数据集上的大量实验表明，V2X-RECT相比SOTA方法取得了显著改进，同时在不同交通密度下提高了鲁棒性和推理效率。

Conclusion: V2X-RECT框架通过增强数据关联一致性、减少冗余交互和重用历史信息，为高密度环境下的V2X轨迹预测提供了更高效准确的解决方案。

Abstract: V2X prediction can alleviate perception incompleteness caused by limited line of sight through fusing trajectory data from infrastructure and vehicles, which is crucial to traffic safety and efficiency. However, in dense traffic scenarios, frequent identity switching of targets hinders cross-view association and fusion. Meanwhile, multi-source information tends to generate redundant interactions during the encoding stage, and traditional vehicle-centric encoding leads to large amounts of repetitive historical trajectory feature encoding, degrading real-time inference performance. To address these challenges, we propose V2X-RECT, a trajectory prediction framework designed for high-density environments. It enhances data association consistency, reduces redundant interactions, and reuses historical information to enable more efficient and accurate prediction. Specifically, we design a multi-source identity matching and correction module that leverages multi-view spatiotemporal relationships to achieve stable and consistent target association, mitigating the adverse effects of mismatches on trajectory encoding and cross-view feature fusion. Then we introduce traffic signal-guided interaction module, encoding trend of traffic light changes as features and exploiting their role in constraining spatiotemporal passage rights to accurately filter key interacting vehicles, while capturing the dynamic impact of signal changes on interaction patterns. Furthermore, a local spatiotemporal coordinate encoding enables reusable features of historical trajectories and map, supporting parallel decoding and significantly improving inference efficiency. Extensive experimental results across V2X-Seq and V2X-Traj datasets demonstrate that our V2X-RECT achieves significant improvements compared to SOTA methods, while also enhancing robustness and inference efficiency across diverse traffic densities.

</details>


### [56] [SciEducator: Scientific Video Understanding and Educating via Deming-Cycle Multi-Agent System](https://arxiv.org/abs/2511.17943)
*Zhiyu Xu,Weilong Yan,Yufei Shi,Xin Meng,Tao He,Huiping Zhuang,Ming Li,Hehe Fan*

Main category: cs.CV

TL;DR: SciEducator是一个基于Deming Cycle的自进化多代理系统，用于科学视频理解和教育，在专业基准测试中显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型和视频代理系统在需要外部专业知识和严格逐步推理的科学视频理解教育领域表现不佳，需要更专业的解决方案。

Method: 基于管理科学中的Deming Cycle（计划-执行-研究-行动）哲学，设计自进化推理和反馈机制，构建多代理系统来解读复杂科学活动。

Result: 在包含500个专家验证科学问答对的SciVBench基准测试中，SciEducator显著优于领先的闭源MLLM（如Gemini、GPT-4o）和最先进的视频代理。

Conclusion: SciEducator为科学视频理解教育建立了新范式，能够生成包含文本指令、视觉指南、音频叙述和交互参考的多模态教育内容。

Abstract: Recent advancements in multimodal large language models (MLLMs) and video agent systems have significantly improved general video understanding. However, when applied to scientific video understanding and educating, a domain that demands external professional knowledge integration and rigorous step-wise reasoning, existing approaches often struggle. To bridge this gap, we propose SciEducator, the first iterative self-evolving multi-agent system for scientific video comprehension and education. Rooted in the classical Deming Cycle from management science, our design reformulates its Plan-Do-Study-Act philosophy into a self-evolving reasoning and feedback mechanism, which facilitates the interpretation of intricate scientific activities in videos. Moreover, SciEducator can produce multimodal educational content tailored to specific scientific processes, including textual instructions, visual guides, audio narrations, and interactive references. To support evaluation, we construct SciVBench, a benchmark consisting of 500 expert-verified and literature-grounded science QA pairs across five categories, covering physical, chemical, and everyday phenomena. Extensive experiments demonstrate that SciEducator substantially outperforms leading closed-source MLLMs (e.g., Gemini, GPT-4o) and state-of-the-art video agents on the benchmark, establishing a new paradigm for the community.

</details>


### [57] [Test-Time Temporal Sampling for Efficient MLLM Video Understanding](https://arxiv.org/abs/2511.17945)
*Kaibin Wang,Mingbao Lin*

Main category: cs.CV

TL;DR: T3S是一种无需训练、即插即用的推理包装器，通过生成多个短而多样的视频令牌子序列，在单个前向传播中处理长视频，显著降低计算成本并提高准确性。


<details>
  <summary>Details</summary>
Motivation: 处理长视频时，多模态大语言模型的自注意力机制计算复杂度呈二次方增长，导致计算需求高、推理速度慢。现有方法存在准确率损失、需要额外训练或降低推理速度等问题。

Method: T3S利用时空冗余性，在推理时生成多个短而多样的视频令牌子序列，将它们打包在单个前向传播中，并聚合它们的预测结果，将自注意力计算复杂度从O(L²)降低到O(∑α_i²L²)。

Result: 在长视频理解基准测试中，T3S将准确率提升高达3.1%，并将首个令牌延迟减少2.04倍，同时只需极少的集成工作。

Conclusion: T3S将视频冗余转化为计算优势，为长视频理解提供了可扩展的解决方案，无需模型修改或微调，兼容多种预训练MLLM。

Abstract: Processing long videos with multimodal large language models (MLLMs) poses a significant computational challenge, as the model's self-attention mechanism scales quadratically with the number of video tokens, resulting in high computational demand and slow inference speed. Current solutions, such as rule-based sub-sampling, learned frame selector, or memory-based summarization, often introduce their own trade-offs: they compromise accuracy, necessitate additional training, or decrease inference speed. In this paper, we propose Test-Time Temporal Sampling (T3S), a training-free, plug-and-play inference wrapper that enables MLLMs to process long videos both efficiently and effectively. T3S exploits spatiotemporal redundancy by generating multiple short and diverse subsequences of video tokens at inference time, packing them within a single forward pass, and aggregating their predictions. This multi-subsequence formulation broadens visual coverage while reducing the computational cost of self-attention from $O(L^2)$ to $O(\sum_{i=1}^m α_i^2L^2)$, where $\sum_{i=1}^m α_i^2 < 1$. Extensive experiments on long video understanding benchmarks demonstrate that T3S improves accuracy by up to 3.1% and reduces first token delay by $2.04\times$, all with minimal integration effort. Our approach operates entirely at inference time, requires no model modifications or fine-tuning, and is compatible with a wide range of pretrained MLLMs. T3S turns video redundancy into a computational advantage, offering a scalable solution for long-video understanding. The code is available at https://github.com/kaibinwang3/T3S.

</details>


### [58] [Multi-speaker Attention Alignment for Multimodal Social Interaction](https://arxiv.org/abs/2511.17952)
*Liangyang Ouyang,Yifei Huang,Mingfang Zhang,Caixin Kang,Ryosuke Furuta,Yoichi Sato*

Main category: cs.CV

TL;DR: 该论文提出了一种多模态多说话人注意力对齐方法，用于改进多模态大语言模型在多人社交场景中的表现，通过动态跨模态头选择和自适应社交感知注意力偏置来实现说话人视觉表示与语音内容的更好对齐。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在多说话人社交场景中表现不佳，视觉和文本token缺乏说话人一致性对齐，跨模态注意力明显弱于对象中心图像。需要解决说话人视觉表示与语音内容的对齐问题。

Method: 提出动态跨模态头选择识别负责grounding的注意力头，然后计算自适应社交感知注意力偏置并注入注意力机制中，无需可训练参数或架构改变。

Result: 在三个MLLMs和三个基准测试上的实验表明，该方法在四个社交任务中提升了模型性能并达到SOTA结果，注意力可视化证实方法成功聚焦于说话人相关区域。

Conclusion: 该方法有效解决了多说话人社交场景中的跨模态对齐问题，使MLLMs能够进行更鲁棒的多方社交推理，代码和模型将开源。

Abstract: Understanding social interaction in video requires reasoning over a dynamic interplay of verbal and non-verbal cues: who is speaking, to whom, and with what gaze or gestures. While Multimodal Large Language Models (MLLMs) are natural candidates, simply adding visual inputs yields surprisingly inconsistent gains on social tasks. Our quantitative analysis of cross-modal attention inside state-of-the-art MLLMs reveals a core failure mode: in multi-speaker scenes, visual and textual tokens lack speaker-consistent alignment, exhibiting substantially weaker cross-modal attention than in object-centric images. To address this, we propose a multimodal multi-speaker attention alignment method that can be integrated into existing MLLMs. First, we introduce dynamic cross-modal head selection to identify attention heads most responsible for grounding. Then, an adaptive social-aware attention bias, computed from existing attention patterns and speaker locations, is injected into the attention mechanism. This bias reinforces alignment between a speaker's visual representation and their utterances without introducing trainable parameters or architectural changes. We integrate our method into three distinct MLLMs (LLaVA-NeXT-Video, Qwen2.5-VL, and InternVL3) and evaluate on three benchmarks (TVQA+, MMSI, OnlineMMSI). Across four social tasks, results demonstrate that our approach improves the ability of MLLMs and achieves state-of-the-art results. Attention visualizations confirm our method successfully focuses the model on speaker-relevant regions, enabling more robust multi-party social reasoning. Our implementation and model will be available at https://github.com/ut-vision/SocialInteraction.

</details>


### [59] [HEAL: Learning-Free Source Free Unsupervised Domain Adaptation for Cross-Modality Medical Image Segmentation](https://arxiv.org/abs/2511.17958)
*Yulong Shi,Jiapeng Li,Lin Qi*

Main category: cs.CV

TL;DR: HEAL是一个新颖的SFUDA框架，通过层次去噪、边缘引导选择、尺寸感知融合和无学习特性来解决源自由无监督域自适应中的挑战。


<details>
  <summary>Details</summary>
Motivation: 解决临床数据隐私和存储限制问题，处理SFUDA中源域数据缺失和目标域无标签监督的挑战。

Method: 提出HEAL框架，整合层次去噪、边缘引导选择、尺寸感知融合和无学习特性四个关键技术。

Result: 大规模跨模态实验表明，该方法优于现有SFUDA方法，达到最先进性能。

Conclusion: HEAL框架有效解决了SFUDA的核心挑战，源代码已公开。

Abstract: Growing demands for clinical data privacy and storage constraints have spurred advances in Source Free Unsupervised Domain Adaptation (SFUDA). SFUDA addresses the domain shift by adapting models from the source domain to the unseen target domain without accessing source data, even when target-domain labels are unavailable. However, SFUDA faces significant challenges: the absence of source domain data and label supervision in the target domain due to source free and unsupervised settings. To address these issues, we propose HEAL, a novel SFUDA framework that integrates Hierarchical denoising, Edge-guided selection, size-Aware fusion, and Learning-free characteristic. Large-scale cross-modality experiments demonstrate that our method outperforms existing SFUDA approaches, achieving state-of-the-art (SOTA) performance. The source code is publicly available at: https://github.com/derekshiii/HEAL.

</details>


### [60] [VITAL: Vision-Encoder-centered Pre-training for LMMs in Visual Quality Assessment](https://arxiv.org/abs/2511.17962)
*Ziheng Jia,Linhan Cao,Jinliang Han,Zicheng Zhang,Jiaying Qian,Jiarui Wang,Zijian Chen,Guangtao Zhai,Xiongkuo Min*

Main category: cs.CV

TL;DR: 本文提出了一种视觉编码器中心的生成预训练流程，开发了VITAL系列大模型，旨在解决现有视觉质量评估模型泛化能力差的问题。通过构建大规模数据集、多任务训练和高效模型扩展，实现了强大的零样本性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉质量评估大模型通常专注于单一任务并依赖全参数微调，容易在特定模态或任务类型上过拟合，限制了其泛化能力和可迁移性。

Method: 采用机器执行的标注筛选范式构建了450万视觉语言对数据集；使用多任务训练流程同时提升模型的定量评分精度和质量解释能力；基于视觉编码器实现高效的模型扩展，仅需少量数据即可达到全训练模型的性能。

Result: 构建了迄今为止最大的视觉质量评估训练数据集；模型在图像和视频模态上表现出强大的零样本性能；每个配对解码器仅需使用不到预训练数据1/1000的数据进行快速预热即可达到与完全训练模型相当的性能。

Conclusion: 该工作为推进视觉质量评估的基础大模型奠定了重要基础，展示了在通用性、强大性和可迁移性方面的显著优势。

Abstract: Developing a robust visual quality assessment (VQualA) large multi-modal model (LMM) requires achieving versatility, powerfulness, and transferability.
  However, existing VQualA LMMs typically focus on a single task and rely on full-parameter fine-tuning, which makes them prone to overfitting on specific modalities or task types, thereby limiting their generalization capacity and transferability. To address this, we propose a vision-encoder-centered generative pre-training pipeline and develop the VITAL-Series LMMs. (1) We adopt a machine-executed annotation-scrutiny paradigm, constructing over 4.5M vision-language (VL) pairs-the largest VQualA training dataset to date. (2) We employ a multi-task training workflow that simultaneously enhances the model's quantitative scoring precision and strengthens its capability for quality interpretation across both image and video modalities. (3) Building upon the vision encoder, we realize an efficient model zoo extension: the model zoo exhibits strong zero-shot performance, and each paired decoder requires only a swift warm-up using less than 1/1000 of the pre-training data to achieve performance comparable to the fully trained counterpart. Overall, our work lays a cornerstone for advancing toward the foundation LMM for VQualA.

</details>


### [61] [X-ReID: Multi-granularity Information Interaction for Video-Based Visible-Infrared Person Re-Identification](https://arxiv.org/abs/2511.17964)
*Chenyang Yu,Xuehu Liu,Pingping Zhang,Huchuan Lu*

Main category: cs.CV

TL;DR: X-ReID是一个用于视频可见光-红外行人重识别的跨模态特征学习框架，通过跨模态原型协作和多粒度信息交互来减少模态差异并增强时空建模。


<details>
  <summary>Details</summary>
Motivation: 大规模视觉语言模型在检索任务中表现出色，但在视频可见光-红外行人重识别任务中的潜力尚未充分探索。主要挑战是缩小模态差距并利用视频序列中的时空信息。

Method: 提出Cross-modality Prototype Collaboration (CPC)来对齐和整合不同模态的特征，减少模态差异；设计Multi-granularity Information Interaction (MII)结合相邻帧的短期交互、长期跨帧信息融合和跨模态特征对齐，增强时间建模。

Result: 在两个大规模VVI-ReID基准数据集（HITSZ-VCM和BUPTCampus）上的实验表明，该方法优于现有最先进方法。

Conclusion: X-ReID框架通过跨模态特征学习和多粒度信息交互，有效解决了VVI-ReID任务中的模态差距和时空信息利用问题，取得了优异的性能。

Abstract: Large-scale vision-language models (e.g., CLIP) have recently achieved remarkable performance in retrieval tasks, yet their potential for Video-based Visible-Infrared Person Re-Identification (VVI-ReID) remains largely unexplored. The primary challenges are narrowing the modality gap and leveraging spatiotemporal information in video sequences. To address the above issues, in this paper, we propose a novel cross-modality feature learning framework named X-ReID for VVI-ReID. Specifically, we first propose a Cross-modality Prototype Collaboration (CPC) to align and integrate features from different modalities, guiding the network to reduce the modality discrepancy. Then, a Multi-granularity Information Interaction (MII) is designed, incorporating short-term interactions from adjacent frames, long-term cross-frame information fusion, and cross-modality feature alignment to enhance temporal modeling and further reduce modality gaps. Finally, by integrating multi-granularity information, a robust sequence-level representation is achieved. Extensive experiments on two large-scale VVI-ReID benchmarks (i.e., HITSZ-VCM and BUPTCampus) demonstrate the superiority of our method over state-of-the-art methods. The source code is released at https://github.com/AsuradaYuci/X-ReID.

</details>


### [62] [Signal: Selective Interaction and Global-local Alignment for Multi-Modal Object Re-Identification](https://arxiv.org/abs/2511.17965)
*Yangyang Liu,Yuhao Wang,Pingping Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为Signal的新型多模态目标重识别框架，通过选择性交互和全局-局部对齐来解决多模态特征融合中的背景干扰和一致性对齐问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注多模态特征融合，但忽视了背景干扰问题。同时，当前的多模态融合方法往往专注于模态对对齐，但在多模态一致性对齐方面存在困难。

Method: 提出选择性交互模块(SIM)来选择重要补丁标记，通过类标记交互生成更具判别性的特征；设计全局对齐模块(GAM)在Gramian空间中最小化3D多面体体积来同时对齐多模态特征；提出局部对齐模块(LAM)以移位感知方式对齐局部特征。

Result: 在三个多模态目标重识别基准数据集(RGBNT201、RGBNT100、MSVR310)上的大量实验验证了该方法的有效性。

Conclusion: 所提出的Signal框架能够为目标重识别提取更具判别性的特征，在多模态目标重识别任务中表现出优越性能。

Abstract: Multi-modal object Re-IDentification (ReID) is devoted to retrieving specific objects through the exploitation of complementary multi-modal image information. Existing methods mainly concentrate on the fusion of multi-modal features, yet neglecting the background interference. Besides, current multi-modal fusion methods often focus on aligning modality pairs but suffer from multi-modal consistency alignment. To address these issues, we propose a novel selective interaction and global-local alignment framework called Signal for multi-modal object ReID. Specifically, we first propose a Selective Interaction Module (SIM) to select important patch tokens with intra-modal and inter-modal information. These important patch tokens engage in the interaction with class tokens, thereby yielding more discriminative features. Then, we propose a Global Alignment Module (GAM) to simultaneously align multi-modal features by minimizing the volume of 3D polyhedra in the gramian space. Meanwhile, we propose a Local Alignment Module (LAM) to align local features in a shift-aware manner. With these modules, our proposed framework could extract more discriminative features for object ReID. Extensive experiments on three multi-modal object ReID benchmarks (i.e., RGBNT201, RGBNT100, MSVR310) validate the effectiveness of our method. The source code is available at https://github.com/010129/Signal.

</details>


### [63] [CADTrack: Learning Contextual Aggregation with Deformable Alignment for Robust RGBT Tracking](https://arxiv.org/abs/2511.17967)
*Hao Li,Yuhao Wang,Xiantao Hu,Wenning Hao,Pingping Zhang,Dong Wang,Huchuan Lu*

Main category: cs.CV

TL;DR: 提出CADTrack框架，通过Mamba-based特征交互、上下文聚合模块和可变形对齐模块解决RGB-T热成像跟踪中的模态差异问题，实现复杂场景下的鲁棒跟踪。


<details>
  <summary>Details</summary>
Motivation: 现有RGB-T跟踪器难以解决模态差异问题，这限制了有效的跨模态信息传播和融合，从而显著降低了跟踪精度。

Method: 1. Mamba-based特征交互模块：基于状态空间模型建立高效特征交互，具有线性复杂度；2. 上下文聚合模块：基于混合专家模型动态激活骨干网络层，编码跨层特征的互补上下文信息；3. 可变形对齐模块：结合可变形采样和时间传播，缓解空间错位和定位漂移。

Result: 在五个RGB-T跟踪基准测试上进行了广泛实验，验证了所提方法的有效性。

Conclusion: CADTrack框架通过创新的模态融合和对齐机制，在复杂场景下实现了鲁棒且准确的RGB-T目标跟踪。

Abstract: RGB-Thermal (RGBT) tracking aims to exploit visible and thermal infrared modalities for robust all-weather object tracking. However, existing RGBT trackers struggle to resolve modality discrepancies, which poses great challenges for robust feature representation. This limitation hinders effective cross-modal information propagation and fusion, which significantly reduces the tracking accuracy. To address this limitation, we propose a novel Contextual Aggregation with Deformable Alignment framework called CADTrack for RGBT Tracking. To be specific, we first deploy the Mamba-based Feature Interaction (MFI) that establishes efficient feature interaction via state space models. This interaction module can operate with linear complexity, reducing computational cost and improving feature discrimination. Then, we propose the Contextual Aggregation Module (CAM) that dynamically activates backbone layers through sparse gating based on the Mixture-of-Experts (MoE). This module can encode complementary contextual information from cross-layer features. Finally, we propose the Deformable Alignment Module (DAM) to integrate deformable sampling and temporal propagation, mitigating spatial misalignment and localization drift. With the above components, our CADTrack achieves robust and accurate tracking in complex scenarios. Extensive experiments on five RGBT tracking benchmarks verify the effectiveness of our proposed method. The source code is released at https://github.com/IdolLab/CADTrack.

</details>


### [64] [Adversarial Pseudo-replay for Exemplar-free Class-incremental Learning](https://arxiv.org/abs/2511.17973)
*Hiroto Honda*

Main category: cs.CV

TL;DR: APR方法通过对抗攻击扰动新任务图像，生成伪重放样本，结合知识蒸馏和协方差矩阵校准，解决了无样本类增量学习中的稳定性-可塑性困境。


<details>
  <summary>Details</summary>
Motivation: 解决无样本类增量学习中的灾难性遗忘问题，在无法存储旧任务图像的情况下保持旧知识，同时学习新类。

Method: 使用对抗攻击在新任务图像上生成伪重放样本，以增强的旧类均值原型为目标进行知识蒸馏；通过伪重放样本学习转移矩阵来校准协方差矩阵，补偿语义漂移。

Result: 在标准EFCIL基准测试的冷启动设置中达到了最先进的性能，有效平衡了稳定性和可塑性。

Conclusion: APR方法通过在线生成伪重放样本和协方差校准，成功解决了无样本类增量学习的核心挑战，实现了优异的性能。

Abstract: Exemplar-free class-incremental learning (EFCIL) aims to retain old knowledge acquired in the previous task while learning new classes, without storing the previous images due to storage constraints or privacy concerns. In EFCIL, the plasticity-stability dilemma, learning new tasks versus catastrophic forgetting, is a significant challenge, primarily due to the unavailability of images from earlier tasks. In this paper, we introduce adversarial pseudo-replay (APR), a method that perturbs the images of the new task with adversarial attack, to synthesize the pseudo-replay images online without storing any replay samples. During the new task training, the adversarial attack is conducted on the new task images with augmented old class mean prototypes as targets, and the resulting images are used for knowledge distillation to prevent semantic drift. Moreover, we calibrate the covariance matrices to compensate for the semantic drift after each task, by learning a transfer matrix on the pseudo-replay samples. Our method reconciles stability and plasticity, achieving state-of-the-art on challenging cold-start settings of the standard EFCIL benchmarks.

</details>


### [65] [FeRA: Frequency-Energy Constrained Routing for Effective Diffusion Adaptation Fine-Tuning](https://arxiv.org/abs/2511.17979)
*Bo Yin,Xiaobin Hu,Xingyu Zhou,Peng-Tao Jiang,Yue Liao,Junwei Zhu,Jiangning Zhang,Ying Tai,Chengjie Wang,Shuicheng Yan*

Main category: cs.CV

TL;DR: FeRA是一个基于频率能量的扩散模型微调框架，通过分析去噪过程中的频率能量机制，提出三个协同组件来实现高效稳定的模型适配


<details>
  <summary>Details</summary>
Motivation: 扩散模型在生成建模方面取得了显著成功，但如何有效将大型预训练模型适配到新任务仍然具有挑战性。研究发现扩散模型在去噪过程中存在固有的频率能量机制

Method: FeRA框架包含三个组件：紧凑的频率能量指示器、软频率路由器和频率能量一致性正则化。路由机制在训练和推理时都运行，推理时路由由潜在频率能量动态决定

Result: FeRA能够无缝集成基于适配器的调优方案，在扩散模型骨干和分辨率上都具有良好的泛化能力

Conclusion: 通过将适配过程与频率能量机制对齐，FeRA为扩散模型适配提供了一个简单、稳定且兼容的范式

Abstract: Diffusion models have achieved remarkable success in generative modeling, yet how to effectively adapt large pretrained models to new tasks remains challenging. We revisit the reconstruction behavior of diffusion models during denoising to unveil the underlying frequency energy mechanism governing this process. Building upon this observation, we propose FeRA, a frequency driven fine tuning framework that aligns parameter updates with the intrinsic frequency energy progression of diffusion. FeRA establishes a comprehensive frequency energy framework for effective diffusion adaptation fine tuning, comprising three synergistic components: (i) a compact frequency energy indicator that characterizes the latent bandwise energy distribution, (ii) a soft frequency router that adaptively fuses multiple frequency specific adapter experts, and (iii) a frequency energy consistency regularization that stabilizes diffusion optimization and ensures coherent adaptation across bands. Routing operates in both training and inference, with inference time routing dynamically determined by the latent frequency energy. It integrates seamlessly with adapter based tuning schemes and generalizes well across diffusion backbones and resolutions. By aligning adaptation with the frequency energy mechanism, FeRA provides a simple, stable, and compatible paradigm for effective and robust diffusion model adaptation.

</details>


### [66] [Plan-X: Instruct Video Generation via Semantic Planning](https://arxiv.org/abs/2511.17986)
*Lun Huang,You Xie,Hongyi Xu,Tianpei Gu,Chenxu Zhang,Guoxian Song,Zenan Li,Xiaochen Zhao,Linjie Luo,Guillermo Sapiro*

Main category: cs.CV

TL;DR: Plan-X是一个通过显式语义规划来指导视频生成的框架，旨在解决扩散变换器在高级语义推理和长程规划方面的局限性，减少视觉幻觉和指令对齐问题。


<details>
  <summary>Details</summary>
Motivation: 扩散变换器在视觉合成方面表现出色，但在高级语义推理和长程规划方面存在困难，经常导致视觉幻觉和与用户指令不匹配的问题，特别是在复杂场景理解、人-物交互、多阶段动作和上下文运动推理等场景中。

Method: Plan-X框架包含一个可学习的多模态语言模型作为语义规划器，该模型根据文本提示和视觉上下文对用户意图进行推理，并自回归生成一系列基于文本的时空语义标记。这些语义标记作为视频扩散模型的结构化"语义草图"，指导高保真视觉细节的合成。

Result: 大量实验表明，Plan-X框架显著减少了视觉幻觉，实现了与多模态上下文一致的细粒度、指令对齐的视频生成。

Conclusion: Plan-X有效整合了语言模型在多模态上下文推理和规划方面的优势，以及扩散模型在逼真视频合成方面的优势，为解决复杂视频生成任务提供了一种有效方法。

Abstract: Diffusion Transformers have demonstrated remarkable capabilities in visual synthesis, yet they often struggle with high-level semantic reasoning and long-horizon planning. This limitation frequently leads to visual hallucinations and mis-alignments with user instructions, especially in scenarios involving complex scene understanding, human-object interactions, multi-stage actions, and in-context motion reasoning. To address these challenges, we propose Plan-X, a framework that explicitly enforces high-level semantic planning to instruct video generation process. At its core lies a Semantic Planner, a learnable multimodal language model that reasons over the user's intent from both text prompts and visual context, and autoregressively generates a sequence of text-grounded spatio-temporal semantic tokens. These semantic tokens, complementary to high-level text prompt guidance, serve as structured "semantic sketches" over time for the video diffusion model, which has its strength at synthesizing high-fidelity visual details. Plan-X effectively integrates the strength of language models in multimodal in-context reasoning and planning, together with the strength of diffusion models in photorealistic video synthesis. Extensive experiments demonstrate that our framework substantially reduces visual hallucinations and enables fine-grained, instruction-aligned video generation consistent with multimodal context.

</details>


### [67] [HyM-UNet: Synergizing Local Texture and Global Context via Hybrid CNN-Mamba Architecture for Medical Image Segmentation](https://arxiv.org/abs/2511.17988)
*Haodong Chen,Xianfei Han,Qwen*

Main category: cs.CV

TL;DR: HyM-UNet：一种结合CNN局部特征提取和Mamba全局建模能力的混合架构，用于医学图像分割，在ISIC 2018数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决CNN因局部感受野限制而难以捕捉复杂全局解剖结构的问题，提升器官和病变分割的准确性。

Method: 设计分层编码器：浅层使用卷积模块保留高频纹理细节，深层引入Visual Mamba模块以线性复杂度捕获长程语义依赖；提出Mamba引导融合跳跃连接，利用深层语义特征作为门控信号动态抑制浅层特征中的背景噪声。

Result: 在ISIC 2018数据集上，HyM-UNet在Dice系数和IoU指标上显著优于现有最优方法，且参数量更少、推理延迟更低。

Conclusion: HyM-UNet能有效处理形状复杂和尺度变化的医学分割任务，验证了其有效性和鲁棒性。

Abstract: Accurate organ and lesion segmentation is a critical prerequisite for computer-aided diagnosis. Convolutional Neural Networks (CNNs), constrained by their local receptive fields, often struggle to capture complex global anatomical structures. To tackle this challenge, this paper proposes a novel hybrid architecture, HyM-UNet, designed to synergize the local feature extraction capabilities of CNNs with the efficient global modeling capabilities of Mamba. Specifically, we design a Hierarchical Encoder that utilizes convolutional modules in the shallow stages to preserve high-frequency texture details, while introducing Visual Mamba modules in the deep stages to capture long-range semantic dependencies with linear complexity. To bridge the semantic gap between the encoder and the decoder, we propose a Mamba-Guided Fusion Skip Connection (MGF-Skip). This module leverages deep semantic features as gating signals to dynamically suppress background noise within shallow features, thereby enhancing the perception of ambiguous boundaries. We conduct extensive experiments on public benchmark dataset ISIC 2018. The results demonstrate that HyM-UNet significantly outperforms existing state-of-the-art methods in terms of Dice coefficient and IoU, while maintaining lower parameter counts and inference latency. This validates the effectiveness and robustness of the proposed method in handling medical segmentation tasks characterized by complex shapes and scale variations.

</details>


### [68] [SD-PSFNet: Sequential and Dynamic Point Spread Function Network for Image Deraining](https://arxiv.org/abs/2511.17993)
*Jiayu Wang,Haoyu Bian,Haoran Sun,Shaoning Zeng*

Main category: cs.CV

TL;DR: SD-PSFNet是一种基于点扩散函数机制的多阶段图像去雨方法，通过动态物理建模和序列特征融合，在复杂场景和密集降雨条件下实现优异的去雨效果。


<details>
  <summary>Details</summary>
Motivation: 图像去雨对视觉应用至关重要，但面临雨滴多尺度物理特性及其与场景耦合的复杂挑战。需要一种能够揭示图像退化过程并有效分离雨滴和背景的方法。

Method: 采用三阶段级联的序列恢复架构，利用学习到的PSF机制动态模拟雨条纹光学特性，结合自适应门控融合实现跨阶段特征整合，从粗粒度雨滴去除到细粒度细节恢复进行顺序优化。

Result: 在Rain100H数据集上达到PSNR 33.12dB/SSIM 0.9371，RealRain-1k-L数据集上42.28dB/0.9872，RealRain-1k-H数据集上41.08dB/0.9838，均达到最先进水平。

Conclusion: SD-PSFNet在复杂场景和密集降雨条件下表现出色，为图像去雨提供了一种新的物理感知方法。

Abstract: Image deraining is crucial for vision applications but is challenged by the complex multi-scale physics of rain and its coupling with scenes. To address this challenge, a novel approach inspired by multi-stage image restoration is proposed, incorporating Point Spread Function (PSF) mechanisms to reveal the image degradation process while combining dynamic physical modeling with sequential feature fusion transfer, named SD-PSFNet. Specifically, SD-PSFNet employs a sequential restoration architecture with three cascaded stages, allowing multiple dynamic evaluations and refinements of the degradation process estimation. The network utilizes components with learned PSF mechanisms to dynamically simulate rain streak optics, enabling effective rain-background separation while progressively enhancing outputs through novel PSF components at each stage. Additionally, SD-PSFNet incorporates adaptive gated fusion for optimal cross-stage feature integration, enabling sequential refinement from coarse rain removal to fine detail restoration. Our model achieves state-of-the-art PSNR/SSIM metrics on Rain100H (33.12dB/0.9371), RealRain-1k-L (42.28dB/0.9872), and RealRain-1k-H (41.08dB/0.9838). In summary, SD-PSFNet demonstrates excellent capability in complex scenes and dense rainfall conditions, providing a new physics-aware approach to image deraining.

</details>


### [69] [RAISECity: A Multimodal Agent Framework for Reality-Aligned 3D World Generation at City-Scale](https://arxiv.org/abs/2511.18005)
*Shengyuan Wang,Zhiheng Zheng,Yu Shang,Lixuan He,Yangcheng Yu,Fan Hangyu,Jie Feng,Qingmin Liao,Yong Li*

Main category: cs.CV

TL;DR: RAISECity是一个面向城市级3D生成的新框架，通过智能代理系统整合多模态基础工具，实现高质量、高保真度、可扩展的3D世界生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法在城市级3D生成中存在质量、保真度和可扩展性方面的挑战，需要开发更有效的解决方案来支持具身智能和世界模型的发展。

Method: 采用智能代理框架，利用多模态基础工具获取现实世界知识，维护稳健的中间表示，并构建复杂3D场景。方法包括动态数据处理、迭代自反思和优化，以及调用高级多模态工具。

Result: 在现实世界对齐、形状精度、纹理保真度和美学水平方面表现优异，在整体感知质量上对现有基线实现了超过90%的胜率。

Conclusion: RAISECity结合了3D质量、现实对齐、可扩展性和与计算机图形管道的无缝兼容性，为沉浸式媒体、具身智能和世界模型应用提供了有前景的基础。

Abstract: City-scale 3D generation is of great importance for the development of embodied intelligence and world models. Existing methods, however, face significant challenges regarding quality, fidelity, and scalability in 3D world generation. Thus, we propose RAISECity, a \textbf{R}eality-\textbf{A}ligned \textbf{I}ntelligent \textbf{S}ynthesis \textbf{E}ngine that creates detailed, \textbf{C}ity-scale 3D worlds. We introduce an agentic framework that leverages diverse multimodal foundation tools to acquire real-world knowledge, maintain robust intermediate representations, and construct complex 3D scenes. This agentic design, featuring dynamic data processing, iterative self-reflection and refinement, and the invocation of advanced multimodal tools, minimizes cumulative errors and enhances overall performance. Extensive quantitative experiments and qualitative analyses validate the superior performance of RAISECity in real-world alignment, shape precision, texture fidelity, and aesthetics level, achieving over a 90% win-rate against existing baselines for overall perceptual quality. This combination of 3D quality, reality alignment, scalability, and seamless compatibility with computer graphics pipelines makes RAISECity a promising foundation for applications in immersive media, embodied intelligence, and world models.

</details>


### [70] [Is Complete Labeling Necessary? Understanding Active Learning in Longitudinal Medical Imaging](https://arxiv.org/abs/2511.18007)
*Siteng Ma,Honghui Du,Prateek Mathur,Brendan S. Kelly,Ronan P. Killeen,Aonghus Lawlor,Ruihai Dong*

Main category: cs.CV

TL;DR: 提出LMI-AL框架，用于纵向医学影像变化检测的深度主动学习，仅需标注8%数据即可达到全标注数据集的性能


<details>
  <summary>Details</summary>
Motivation: 纵向医学影像标注成本高且耗时，传统深度主动学习方法无法直接应用于变化检测任务

Method: 通过配对和差分基线及随访3D图像的所有2D切片，使用深度主动学习迭代选择最具信息量的配对进行标注

Result: 仅需标注不到8%的数据即可达到全标注数据集的性能水平

Conclusion: LMI-AL框架能显著降低纵向医学影像变化检测的标注成本，为未来研究提供指导

Abstract: Detecting changes in longitudinal medical imaging using deep learning requires a substantial amount of accurately labeled data. However, labeling these images is notably more costly and time-consuming than labeling other image types, as it requires labeling across various time points, where new lesions can be minor, and subtle changes are easily missed. Deep Active Learning (DAL) has shown promise in minimizing labeling costs by selectively querying the most informative samples, but existing studies have primarily focused on static tasks like classification and segmentation. Consequently, the conventional DAL approach cannot be directly applied to change detection tasks, which involve identifying subtle differences across multiple images. In this study, we propose a novel DAL framework, named Longitudinal Medical Imaging Active Learning (LMI-AL), tailored specifically for longitudinal medical imaging. By pairing and differencing all 2D slices from baseline and follow-up 3D images, LMI-AL iteratively selects the most informative pairs for labeling using DAL, training a deep learning model with minimal manual annotation. Experimental results demonstrate that, with less than 8% of the data labeled, LMI-AL can achieve performance comparable to models trained on fully labeled datasets. We also provide a detailed analysis of the method's performance, as guidance for future research. The code is publicly available at https://github.com/HelenMa9998/Longitudinal_AL.

</details>


### [71] [RoadBench: Benchmarking MLLMs on Fine-Grained Spatial Understanding and Reasoning under Urban Road Scenarios](https://arxiv.org/abs/2511.18011)
*Jun Zhang,Jie Feng,Long Chen,Junhui Wang,Zhicheng Liu,Depeng Jin,Yong Li*

Main category: cs.CV

TL;DR: RoadBench是一个系统性的基准测试，专门评估多模态大语言模型在复杂城市场景中的细粒度空间理解和推理能力，重点关注道路标记。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在复杂城市场景中的细粒度空间理解和推理能力尚未得到充分研究，特别是在道路标记等关键城市交通元素方面存在研究空白。

Method: 围绕道路标记和城市交通系统，提出RoadBench基准，包含6个任务共9,121个严格人工验证的测试用例，使用BEV和FPV图像输入，构建从局部空间范围到全局推理的系统评估框架。

Result: 评估14个主流MLLMs后发现，RoadBench对MLLMs具有挑战性，现有模型在城市场景中的细粒度空间理解和推理能力存在显著不足，某些任务表现甚至低于简单规则或随机选择基线。

Conclusion: RoadBench基准和评估结果将有助于全面推动MLLMs空间理解能力的发展，揭示了现有模型在城市场景理解方面的局限性。

Abstract: Multimodal large language models (MLLMs) have demonstrated powerful capabilities in general spatial understanding and reasoning. However, their fine-grained spatial understanding and reasoning capabilities in complex urban scenarios have not received significant attention in the fields of both research and industry. To fill this gap, we focus primarily on road markings as a typical example of fine-grained spatial elements under urban scenarios, given the essential role of the integrated road traffic network they form within cities. Around road markings and urban traffic systems, we propose RoadBench, a systematic benchmark that comprehensively evaluates MLLMs' fine-grained spatial understanding and reasoning capabilities using BEV and FPV image inputs. This benchmark comprises six tasks consisting of 9,121 strictly manually verified test cases. These tasks form a systematic evaluation framework that bridges understanding at local spatial scopes to global reasoning. They not only test MLLMs' capabilities in recognition, joint understanding, and reasoning but also assess their ability to integrate image information with domain knowledge. After evaluating 14 mainstream MLLMs, we confirm that RoadBench is a challenging benchmark for MLLMs while revealing significant shortcomings in existing MLLMs' fine-grained spatial understanding and reasoning capabilities within urban scenarios. In certain tasks, their performance even falls short of simple rule-based or random selection baselines. These findings, along with RoadBench itself, will contribute to the comprehensive advancement of spatial understanding capabilities for MLLMs. The benchmark code, example datasets, and raw evaluation results are available in the supplementary material.

</details>


### [72] [ActDistill: General Action-Guided Self-Derived Distillation for Efficient Vision-Language-Action Models](https://arxiv.org/abs/2511.18082)
*Wencheng Ye,Tianshi Wang,Lei Zhu,Fengling Li,Guoli Yang*

Main category: cs.CV

TL;DR: ActDistill是一个基于动作引导的自蒸馏框架，可将现有VLA模型的动作预测能力转移到轻量级模型中，实现计算效率提升。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型在机器人操作中面临计算开销大和推理延迟高的问题，限制了实际部署。

Method: 采用图结构封装策略建模动作预测的层次演化，使用动态路由器根据动作预测需求自适应选择计算路径，通过层次图监督确保演化过程的平滑高效。

Result: 在嵌入式基准测试中，ActDistill实现了与全尺寸VLA模型相当或更优的性能，同时计算量减少50%以上，速度提升达1.67倍。

Conclusion: ActDistill为高效嵌入式智能建立了一个通用范式，显著提升了VLA模型的实际部署能力。

Abstract: Recent Vision-Language-Action (VLA) models have shown impressive flexibility and generalization, yet their deployment in robotic manipulation remains limited by heavy computational overhead and inference latency. In this work, we present ActDistill, a general action-guided self-derived distillation framework that transfers the action prediction capability of any existing VLA model to a lightweight counterpart. Unlike previous efficiency strategies that primarily emphasize vision-language correlations, ActDistill leverages action priors to guide knowledge transfer and model compression, achieving action-oriented efficiency for VLA models. Specifically, we employ a well-trained VLA model as the teacher and introduce a graph-structured encapsulation strategy to explicitly model the hierarchical evolution of action prediction. The student model, derived from the graph-encapsulated teacher, is further equipped with a dynamic router that adaptively selects computation paths based on action prediction demands, guided by hierarchical graph-informed supervision to ensure smooth and efficient evolution. During inference, graph-related auxiliary components are removed, allowing the student to execute only dynamically routed layers and predict high-precision actions with minimal computation and latency. Experiments on embodied benchmarks demonstrate that ActDistill achieves comparable or superior performance to full-scale VLA models while reducing computation by over 50% with up to 1.67 times speedup, thereby establishing a general paradigm toward efficient embodied intelligence.

</details>


### [73] [State and Scene Enhanced Prototypes for Weakly Supervised Open-Vocabulary Object Detection](https://arxiv.org/abs/2511.18012)
*Jiaying Zhou,Qingchao Chen*

Main category: cs.CV

TL;DR: 本文提出两种互补的原型增强策略来解决弱监督开放词汇目标检测中的关键挑战：状态增强语义原型（SESP）用于捕捉类内视觉变化，场景增强伪原型（SAPP）用于解决语义不匹配问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在两个关键问题：1）语义原型（即使通过LLM增强）是静态的，无法捕捉由不同对象状态（如猫的姿势）引起的丰富类内视觉变化；2）标准伪框生成在视觉区域提议（包含上下文）和以对象为中心的文本嵌入之间引入了语义不匹配。

Method: 1. 状态增强语义原型（SESP）：生成状态感知的文本描述（如"睡着的猫"）来捕捉多样化的对象外观，产生更具区分性的原型。2. 场景增强伪原型（SAPP）：结合上下文语义（如"猫躺在沙发上"），利用软对齐机制促进上下文一致的视觉-文本表示。

Result: 通过整合SESP和SAPP，该方法有效增强了语义原型的丰富性和视觉-文本对齐，实现了显著改进。

Conclusion: 提出的两种原型增强策略能够有效解决弱监督开放词汇目标检测中的类内变化捕捉和语义对齐问题，为相关研究提供了新的思路。

Abstract: Open-Vocabulary Object Detection (OVOD) aims to generalize object recognition to novel categories, while Weakly Supervised OVOD (WS-OVOD) extends this by combining box-level annotations with image-level labels. Despite recent progress, two critical challenges persist in this setting. First, existing semantic prototypes, even when enriched by LLMs, are static and limited, failing to capture the rich intra-class visual variations induced by different object states (e.g., a cat's pose). Second, the standard pseudo-box generation introduces a semantic mismatch between visual region proposals (which contain context) and object-centric text embeddings. To tackle these issues, we introduce two complementary prototype enhancement strategies. To capture intra-class variations in appearance and state, we propose the State-Enhanced Semantic Prototypes (SESP), which generates state-aware textual descriptions (e.g., "a sleeping cat") to capture diverse object appearances, yielding more discriminative prototypes. Building on this, we further introduce Scene-Augmented Pseudo Prototypes (SAPP) to address the semantic mismatch. SAPP incorporates contextual semantics (e.g., "cat lying on sofa") and utilizes a soft alignment mechanism to promote contextually consistent visual-textual representations. By integrating SESP and SAPP, our method effectively enhances both the richness of semantic prototypes and the visual-textual alignment, achieving notable improvements.

</details>


### [74] [Modeling Retinal Ganglion Cells with Neural Differential Equations](https://arxiv.org/abs/2511.18014)
*Kacper Dobek,Daniel Jankowski,Krzysztof Krawiec*

Main category: cs.CV

TL;DR: LTC和CfC网络在模拟老虎蝾螈视网膜神经节细胞活动方面优于卷积基线和LSTM，具有更低的MAE、更快收敛、更小模型尺寸和更好查询效率，适合数据有限场景。


<details>
  <summary>Details</summary>
Motivation: 探索LTC和CfC网络在生物神经建模中的应用潜力，特别是在视觉假体等边缘部署场景中需要高效、适应性强的小型模型。

Method: 使用Liquid Time-Constant Networks和Closed-form Continuous-time Networks对三个老虎蝾螈视网膜数据集进行建模，并与卷积基线和LSTM进行比较。

Result: LTC和CfC在MAE、收敛速度、模型大小和查询时间方面均优于基线模型，仅在Pearson相关系数上略低。

Conclusion: LTC和CfC网络因其高效性和适应性，特别适合数据有限且需要频繁重新训练的边缘部署应用，如视觉假体。

Abstract: This work explores Liquid Time-Constant Networks (LTCs) and Closed-form Continuous-time Networks (CfCs) for modeling retinal ganglion cell activity in tiger salamanders across three datasets. Compared to a convolutional baseline and an LSTM, both architectures achieved lower MAE, faster convergence, smaller model sizes, and favorable query times, though with slightly lower Pearson correlation. Their efficiency and adaptability make them well suited for scenarios with limited data and frequent retraining, such as edge deployments in vision prosthetics.

</details>


### [75] [MambaX: Image Super-Resolution with State Predictive Control](https://arxiv.org/abs/2511.18028)
*Chenyu Li,Danfeng Hong,Bing Zhang,Zhaojie Pan,Naoto Yokoya,Jocelyn Chanussot*

Main category: cs.CV

TL;DR: MambaX是一种非线性状态预测控制模型，通过动态学习控制方程的非线性状态参数，将连续光谱带映射到潜在状态空间，从而推广超分辨率任务。


<details>
  <summary>Details</summary>
Motivation: 现有超分辨率方法主要关注直接提升最终分辨率，忽视了中间阶段的误差传播和累积控制。Mamba方法虽然能表示重建过程为状态序列，但其固定线性映射器受限于狭窄感受野和有限灵活性，在细粒度图像中效果不佳。

Method: 1) 采用动态状态预测控制学习来近似状态空间模型的非线性微分系数；2) 引入新的状态交叉控制范式进行多模态超分辨率融合；3) 利用渐进式过渡学习减轻领域和模态偏移引起的异质性。

Result: 评估表明动态频谱状态表示模型在单图像超分辨率和多模态融合超分辨率任务中均表现出优越性能。

Conclusion: MambaX模型在任意维度和模态的光谱广义建模方面具有显著潜力。

Abstract: Image super-resolution (SR) is a critical technology for overcoming the inherent hardware limitations of sensors. However, existing approaches mainly focus on directly enhancing the final resolution, often neglecting effective control over error propagation and accumulation during intermediate stages. Recently, Mamba has emerged as a promising approach that can represent the entire reconstruction process as a state sequence with multiple nodes, allowing for intermediate intervention. Nonetheless, its fixed linear mapper is limited by a narrow receptive field and restricted flexibility, which hampers its effectiveness in fine-grained images. To address this, we created a nonlinear state predictive control model \textbf{MambaX} that maps consecutive spectral bands into a latent state space and generalizes the SR task by dynamically learning the nonlinear state parameters of control equations. Compared to existing sequence models, MambaX 1) employs dynamic state predictive control learning to approximate the nonlinear differential coefficients of state-space models; 2) introduces a novel state cross-control paradigm for multimodal SR fusion; and 3) utilizes progressive transitional learning to mitigate heterogeneity caused by domain and modality shifts. Our evaluation demonstrates the superior performance of the dynamic spectrum-state representation model in both single-image SR and multimodal fusion-based SR tasks, highlighting its substantial potential to advance spectrally generalized modeling across arbitrary dimensions and modalities.

</details>


### [76] [PhysGS: Bayesian-Inferred Gaussian Splatting for Physical Property Estimation](https://arxiv.org/abs/2511.18570)
*Samarth Chopra,Jing Liang,Gershom Seneviratne,Dinesh Manocha*

Main category: cs.CV

TL;DR: PhysGS是一种基于贝叶斯推断的3D高斯泼溅扩展方法，能够从视觉线索和视觉-语言先验中估计密集的物理属性，将物理属性估计与3D重建、不确定性建模相结合。


<details>
  <summary>Details</summary>
Motivation: 现有3D重建方法仅关注几何和外观，无法推断摩擦、刚度、硬度和材料组成等物理属性，而这些属性对于机器人安全有效地与环境交互至关重要。

Method: 将属性估计建模为高斯泼溅上的贝叶斯推断，利用视觉线索和视觉-语言先验迭代优化材料和属性信念，同时建模认知和随机不确定性。

Result: 在物体尺度、室内和室外真实数据集上，PhysGS将质量估计精度提升达22.8%，肖氏硬度误差降低达61.2%，动摩擦误差降低达18.1%。

Conclusion: PhysGS在单一空间连续框架中统一了3D重建、不确定性建模和物理推理，实现了密集物理属性估计。

Abstract: Understanding physical properties such as friction, stiffness, hardness, and material composition is essential for enabling robots to interact safely and effectively with their surroundings. However, existing 3D reconstruction methods focus on geometry and appearance and cannot infer these underlying physical properties. We present PhysGS, a Bayesian-inferred extension of 3D Gaussian Splatting that estimates dense, per-point physical properties from visual cues and vision--language priors. We formulate property estimation as Bayesian inference over Gaussian splats, where material and property beliefs are iteratively refined as new observations arrive. PhysGS also models aleatoric and epistemic uncertainties, enabling uncertainty-aware object and scene interpretation. Across object-scale (ABO-500), indoor, and outdoor real-world datasets, PhysGS improves accuracy of the mass estimation by up to 22.8%, reduces Shore hardness error by up to 61.2%, and lowers kinetic friction error by up to 18.1% compared to deterministic baselines. Our results demonstrate that PhysGS unifies 3D reconstruction, uncertainty modeling, and physical reasoning in a single, spatially continuous framework for dense physical property estimation. Additional results are available at https://samchopra2003.github.io/physgs.

</details>


### [77] [Hybrid Event Frame Sensors: Modeling, Calibration, and Simulation](https://arxiv.org/abs/2511.18037)
*Yunfan Lu,Nico Messikommer,Xiaogang Xu,Liming Chen,Yuhan Chen,Nikola Zubic,Davide Scaramuzza,Hui Xiong*

Main category: cs.CV

TL;DR: 本文提出了首个统一的统计成像噪声模型，用于描述APS和EVS像素的联合噪声行为，并开发了HESIM模拟器来生成具有真实噪声统计的RAW帧和事件数据。


<details>
  <summary>Details</summary>
Motivation: 事件帧混合传感器集成了APS和EVS，但复杂的电路架构引入了难以理解的噪声模式，目前缺乏对这些噪声的建模。

Method: 建立统一的统计噪声模型，包含光子散粒噪声、暗电流噪声、固定模式噪声和量化噪声，开发校准流程估计噪声参数，并构建HESIM模拟器。

Result: 在两个混合传感器上的实验验证了模型在视频帧插值和去模糊等任务中的有效性，显示了从模拟到真实数据的强迁移能力。

Conclusion: 提出的统一噪声模型和HESIM模拟器为事件帧混合传感器的噪声建模提供了统计基础，有助于提升相关成像任务的性能。

Abstract: Event frame hybrid sensors integrate an Active Pixel Sensor (APS) and an Event Vision Sensor (EVS) within a single chip, combining the high dynamic range and low latency of the EVS with the rich spatial intensity information from the APS. While this tight integration offers compact, temporally precise imaging, the complex circuit architecture introduces non-trivial noise patterns that remain poorly understood and unmodeled. In this work, we present the first unified, statistics-based imaging noise model that jointly describes the noise behavior of APS and EVS pixels. Our formulation explicitly incorporates photon shot noise, dark current noise, fixed-pattern noise, and quantization noise, and links EVS noise to illumination level and dark current. Based on this formulation, we further develop a calibration pipeline to estimate noise parameters from real data and offer a detailed analysis of both APS and EVS noise behaviors. Finally, we propose HESIM, a statistically grounded simulator that generates RAW frames and events under realistic, jointly calibrated noise statistics. Experiments on two hybrid sensors validate our model across multiple imaging tasks (e.g., video frame interpolation and deblurring), demonstrating strong transfer from simulation to real data.

</details>


### [78] [Beyond Description: Cognitively Benchmarking Fine-Grained Action for Embodied Agents](https://arxiv.org/abs/2511.18685)
*Dayong Liu,Chao Xu,Weihong Chen,Suyu Zhang,Juncheng Wang,Jiankang Deng,Baigui Sun,Yang Liu*

Main category: cs.CV

TL;DR: CFG-Bench是一个新的基准测试，旨在系统评估多模态大语言模型在具身物理交互中的细粒度动作智能，包含1,368个视频和19,562个多模态问答对，涵盖四个认知维度。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注高层规划或空间推理，而忽视了具身物理交互所需的细粒度动作智能，这限制了MLLMs在复杂物理环境中作为决策引擎的能力。

Method: 开发CFG-Bench基准测试，包含四个认知维度：物理交互、时间-因果关系、意图理解和评估判断，通过视频和问答对系统评估MLLMs的能力。

Result: 评估显示领先的MLLMs在生成物理交互的详细指令方面存在困难，在意图和评估等高阶推理方面表现出严重局限性。通过监督微调可以显著提升在具身基准测试上的性能。

Conclusion: CFG-Bench揭示了当前MLLMs在细粒度动作智能方面的局限性，为开发更强大和接地气的具身智能体提供了重要见解。

Abstract: Multimodal Large Language Models (MLLMs) show promising results as decision-making engines for embodied agents operating in complex, physical environments. However, existing benchmarks often prioritize high-level planning or spatial reasoning, leaving the fine-grained action intelligence required for embodied physical interaction underexplored. To address this gap, we introduce CFG-Bench, a new benchmark designed to systematically evaluate this crucial capability. CFG-Bench consists of 1,368 curated videos paired with 19,562 three-modalities question-answer pairs targeting four cognitive abilities: 1) Physical Interaction, 2) Temporal-Causal Relation, 3) Intentional Understanding, and 4) Evaluative Judgment. Together, these dimensions provide a systematic framework for assessing a model's ability to translate visual observations into actionable knowledge, moving beyond mere surface-level recognition. Our comprehensive evaluation on CFG-Bench reveals that leading MLLMs struggle to produce detailed instructions for physical interactions and exhibit profound limitations in the higher-order reasoning of intention and evaluation. Moreover, supervised fine-tuning (SFT) on our data demonstrates that teaching an MLLMs to articulate fine-grained actions directly translates to significant performance gains on established embodied benchmarks. Our analysis highlights these limitations and offers insights for developing more capable and grounded embodied agents.

</details>


### [79] [UltraFlux: Data-Model Co-Design for High-quality Native 4K Text-to-Image Generation across Diverse Aspect Ratios](https://arxiv.org/abs/2511.18050)
*Tian Ye,Song Fei,Lei Zhu*

Main category: cs.CV

TL;DR: UltraFlux是一个基于Flux的扩散变换器，专门针对4K分辨率训练，通过数据模型协同设计解决了4K生成中的耦合问题，在多个评估指标上超越开源基线并媲美专有模型。


<details>
  <summary>Details</summary>
Motivation: 现有扩散变换器在1K分辨率表现良好，但扩展到原生4K时暴露出位置编码、VAE压缩和优化之间的紧密耦合问题，单独解决任一因素都无法达到理想质量。

Method: 采用数据模型协同设计：数据方面构建MultiAspect-4K-1M数据集；模型方面结合Resonance 2D RoPE与YaRN位置编码、非对抗性VAE后训练、SNR感知Huber小波目标函数和分阶段美学课程学习策略。

Result: UltraFlux在4096分辨率的美学评估和多纵横比4K设置中，在保真度、美学质量和对齐度指标上持续优于强开源基线，通过LLM提示优化器可匹配或超越专有Seedream 4.0。

Conclusion: 通过系统性解决4K生成的耦合问题，UltraFlux实现了稳定、细节保留的4K扩散变换器，能够泛化到宽屏、方形和竖屏等多种纵横比。

Abstract: Diffusion transformers have recently delivered strong text-to-image generation around 1K resolution, but we show that extending them to native 4K across diverse aspect ratios exposes a tightly coupled failure mode spanning positional encoding, VAE compression, and optimization. Tackling any of these factors in isolation leaves substantial quality on the table. We therefore take a data-model co-design view and introduce UltraFlux, a Flux-based DiT trained natively at 4K on MultiAspect-4K-1M, a 1M-image 4K corpus with controlled multi-AR coverage, bilingual captions, and rich VLM/IQA metadata for resolution- and AR-aware sampling. On the model side, UltraFlux couples (i) Resonance 2D RoPE with YaRN for training-window-, frequency-, and AR-aware positional encoding at 4K; (ii) a simple, non-adversarial VAE post-training scheme that improves 4K reconstruction fidelity; (iii) an SNR-Aware Huber Wavelet objective that rebalances gradients across timesteps and frequency bands; and (iv) a Stage-wise Aesthetic Curriculum Learning strategy that concentrates high-aesthetic supervision on high-noise steps governed by the model prior. Together, these components yield a stable, detail-preserving 4K DiT that generalizes across wide, square, and tall ARs. On the Aesthetic-Eval at 4096 benchmark and multi-AR 4K settings, UltraFlux consistently outperforms strong open-source baselines across fidelity, aesthetic, and alignment metrics, and-with a LLM prompt refiner-matches or surpasses the proprietary Seedream 4.0.

</details>


### [80] [IE-Critic-R1: Advancing the Explanatory Measurement of Text-Driven Image Editing for Human Perception Alignment](https://arxiv.org/abs/2511.18055)
*Bowen Qu,Shangkun Sun,Xiaoyu Liang,Wei Gao*

Main category: cs.CV

TL;DR: 本文提出了IE-Bench基准套件和IE-Critic-R1评估指标，用于改进文本驱动图像编辑的质量评估，解决了现有方法仅关注文本-图像对齐或与人类感知不一致的问题。


<details>
  <summary>Details</summary>
Motivation: 文本驱动图像编辑的评估具有挑战性，因为编辑后的图像与原始图像存在内在联系，且随文本语义动态变化。现有方法主要关注文本-图像对齐，未能很好地与人类感知对齐。

Method: 1）构建IE-Bench基准套件，包含多样化的源图像、编辑提示和不同编辑方法的结果，以及近4000个样本的人类主观评分；2）提出IE-Critic-R1评估指标，利用可验证奖励的强化学习（RLVR）提供更全面、可解释的质量评估。

Result: 大量实验表明，IE-Critic-R1在文本驱动图像编辑任务上的主观对齐性优于现有指标。

Conclusion: IE-Bench和IE-Critic-R1为文本驱动图像编辑提供了更符合人类感知的评估框架，相关数据和代码已公开。

Abstract: Recent advances in text-driven image editing have been significant, yet the task of accurately evaluating these edited images continues to pose a considerable challenge. Different from the assessment of text-driven image generation, text-driven image editing is characterized by simultaneously conditioning on both text and a source image. The edited images often retain an intrinsic connection to the original image, which dynamically change with the semantics of the text. However, previous methods tend to solely focus on text-image alignment or have not well aligned with human perception. In this work, we introduce the Text-driven Image Editing Benchmark suite (IE-Bench) to enhance the assessment of text-driven edited images. IE-Bench includes a database contains diverse source images, various editing prompts and the corresponding edited results from different editing methods, and nearly 4,000 samples with corresponding Mean Opinion Scores (MOS) provided by 15 human subjects. Furthermore, we introduce IE-Critic-R1, which, benefiting from Reinforcement Learning from Verifiable Rewards (RLVR), provides more comprehensive and explainable quality assessment for text-driven image editing that aligns with human perception. Extensive experiments demonstrate IE-Critic-R1's superior subjective-alignments on the text-driven image editing task compared with previous metrics. Related data and codes are available to the public.

</details>


### [81] [Hierarchical Semi-Supervised Active Learning for Remote Sensing](https://arxiv.org/abs/2511.18058)
*Wei Huang,Zhitong Xiong,Chenying Liu,Xiao Xiang Zhu*

Main category: cs.CV

TL;DR: 提出了一个分层半监督主动学习框架HSSAL，结合半监督学习和分层主动学习，通过迭代优化显著提高了遥感图像分类的标签效率。


<details>
  <summary>Details</summary>
Motivation: 深度学习在遥感领域表现依赖于高质量标注数据，但大规模标注成本高、耗时长，大量未标注图像未被充分利用。

Method: HSSAL框架集成了半监督学习和分层主动学习：SSL通过弱到强自训练利用标注和未标注数据改进特征表示和不确定性估计；HAL基于改进的特征和不确定性进行渐进式聚类采样，选择兼具可扩展性、多样性和不确定性的信息样本。

Result: 在UCM、AID和NWPU-RESISC45三个基准数据集上，HSSAL仅需8%、4%和2%的标注数据即可达到超过95%的全监督准确率，显著优于单独的SSL或AL方法。

Conclusion: HSSAL通过有效利用未标注数据的信息性，实现了卓越的标签效率，为遥感图像分类提供了一种高效的解决方案。

Abstract: The performance of deep learning models in remote sensing (RS) strongly depends on the availability of high-quality labeled data. However, collecting large-scale annotations is costly and time-consuming, while vast amounts of unlabeled imagery remain underutilized. To address this challenge, we propose a Hierarchical Semi-Supervised Active Learning (HSSAL) framework that integrates semi-supervised learning (SSL) and a novel hierarchical active learning (HAL) in a closed iterative loop. In each iteration, SSL refines the model using both labeled data through supervised learning and unlabeled data via weak-to-strong self-training, improving feature representation and uncertainty estimation. Guided by the refined representations and uncertainty cues of unlabeled samples, HAL then conducts sample querying through a progressive clustering strategy, selecting the most informative instances that jointly satisfy the criteria of scalability, diversity, and uncertainty. This hierarchical process ensures both efficiency and representativeness in sample selection. Extensive experiments on three benchmark RS scene classification datasets, including UCM, AID, and NWPU-RESISC45, demonstrate that HSSAL consistently outperforms SSL- or AL-only baselines. Remarkably, with only 8%, 4%, and 2% labeled training data on UCM, AID, and NWPU-RESISC45, respectively, HSSAL achieves over 95% of fully-supervised accuracy, highlighting its superior label efficiency through informativeness exploitation of unlabeled data. Our code will be released at https://github.com/zhu-xlab/RS-SSAL.

</details>


### [82] [Three-Dimensional Anatomical Data Generation Based on Artificial Neural Networks](https://arxiv.org/abs/2511.19198)
*Ann-Sophia Müller,Moonkwang Jeong,Meng Zhang,Jiyuan Tian,Arkadiusz Miernik,Stefanie Speidel,Tian Qiu*

Main category: cs.CV

TL;DR: 提出了一种基于物理器官模型的自动化3D解剖数据生成工作流，用于解决手术规划和训练中3D模型数据稀缺的问题，特别针对成像对比度差的软组织器官如前列腺。


<details>
  <summary>Details</summary>
Motivation: 手术规划和训练需要大量基于医学影像重建的3D解剖模型，但获取真实患者数据面临法律、伦理和技术挑战，特别是对于成像对比度差的软组织器官。

Method: 使用生物模拟水凝胶制作人工前列腺模型，在多区域具有成像对比度；将其放入定制超声扫描仪记录手术前后数据；训练神经网络分割超声图像；基于分割结果重建3D网格模型并提供性能反馈；使用3D GAN获得3D模型流形。

Result: 训练的神经网络在分割超声图像方面优于传统非学习型计算机视觉技术（IoU指标）；成功重建了3D网格模型。

Conclusion: 该工作流为手术规划和训练提供了可行的3D数据生成解决方案，特别是在难以获取真实数据的软组织器官应用场景中。

Abstract: Surgical planning and training based on machine learning requires a large amount of 3D anatomical models reconstructed from medical imaging, which is currently one of the major bottlenecks. Obtaining these data from real patients and during surgery is very demanding, if even possible, due to legal, ethical, and technical challenges. It is especially difficult for soft tissue organs with poor imaging contrast, such as the prostate. To overcome these challenges, we present a novel workflow for automated 3D anatomical data generation using data obtained from physical organ models. We additionally use a 3D Generative Adversarial Network (GAN) to obtain a manifold of 3D models useful for other downstream machine learning tasks that rely on 3D data. We demonstrate our workflow using an artificial prostate model made of biomimetic hydrogels with imaging contrast in multiple zones. This is used to physically simulate endoscopic surgery. For evaluation and 3D data generation, we place it into a customized ultrasound scanner that records the prostate before and after the procedure. A neural network is trained to segment the recorded ultrasound images, which outperforms conventional, non-learning-based computer vision techniques in terms of intersection over union (IoU). Based on the segmentations, a 3D mesh model is reconstructed, and performance feedback is provided.

</details>


### [83] [A Lightweight, Interpretable Deep Learning System for Automated Detection of Cervical Adenocarcinoma In Situ (AIS)](https://arxiv.org/abs/2511.18063)
*Gabriela Fernandes*

Main category: cs.CV

TL;DR: 开发了基于深度学习的虚拟病理助手，能够区分宫颈腺原位癌和正常宫颈腺组织，准确率达到73.23%，具有临床应用潜力。


<details>
  <summary>Details</summary>
Motivation: 宫颈腺原位癌的准确病理诊断具有挑战性，早期检测对预防进展为浸润性腺癌至关重要。

Method: 使用CAISHI数据集（2240张专家标注图像），采用Macenko染色归一化和基于补丁的预处理，训练EfficientNet-B3卷积神经网络，使用类别平衡采样和焦点损失函数解决数据不平衡问题。

Result: 模型总体准确率0.7323，异常类F1分数0.75，正常类F1分数0.71。Grad-CAM热图显示与AIS形态一致的生物学可解释激活模式。

Conclusion: 证明了轻量级、可解释AI系统在宫颈腺病理学中的可行性，在筛查、教育和低资源环境中具有应用潜力。

Abstract: Cervical adenocarcinoma in situ (AIS) is a critical premalignant lesion whose accurate histopathological diagnosis is challenging. Early detection is essential to prevent progression to invasive cervical adenocarcinoma. In this study, we developed a deep learning-based virtual pathology assistant capable of distinguishing AIS from normal cervical gland histology using the CAISHI dataset, which contains 2240 expert-labeled H&E images (1010 normal and 1230 AIS). All images underwent Macenko stain normalization and patch-based preprocessing to enhance morphological feature representation. An EfficientNet-B3 convolutional neural network was trained using class-balanced sampling and focal loss to address dataset imbalance and emphasize difficult examples. The final model achieved an overall accuracy of 0.7323, with an F1-score of 0.75 for the Abnormal class and 0.71 for the Normal class. Grad-CAM heatmaps demonstrated biologically interpretable activation patterns, highlighting nuclear atypia and glandular crowding consistent with AIS morphology. The trained model was deployed in a Gradio-based virtual diagnostic assistant. These findings demonstrate the feasibility of lightweight, interpretable AI systems for cervical gland pathology, with potential applications in screening workflows, education, and low-resource settings.

</details>


### [84] [VK-Det: Visual Knowledge Guided Prototype Learning for Open-Vocabulary Aerial Object Detection](https://arxiv.org/abs/2511.18075)
*Jianhang Yao,Yongbin Zheng,Siqi Lu,Wanying Xu,Peng Sun*

Main category: cs.CV

TL;DR: VK-Det是一个无需额外监督的视觉知识引导开放词汇目标检测框架，通过利用视觉编码器的区域感知能力和原型感知伪标签策略，在航空图像上实现了最先进的性能


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇航空目标检测方法依赖文本监督，导致语义偏差，限制了向文本未指定概念的扩展。需要摆脱文本依赖，利用视觉知识实现真正的开放词汇检测

Method: 1. 利用视觉编码器的固有区域感知能力实现细粒度定位和自适应蒸馏；2. 提出原型感知伪标签策略，通过特征聚类建模类间决策边界，通过原型匹配将检测区域映射到潜在类别

Result: 在DIOR数据集上达到30.1 mAP^N，在DOTA数据集上达到23.3 mAP^N，超越了有额外监督的方法

Conclusion: VK-Det证明了无需文本监督的视觉知识引导方法在开放词汇目标检测中的有效性，特别是在航空图像领域取得了突破性进展

Abstract: To identify objects beyond predefined categories, open-vocabulary aerial object detection (OVAD) leverages the zero-shot capabilities of visual-language models (VLMs) to generalize from base to novel categories. Existing approaches typically utilize self-learning mechanisms with weak text supervision to generate region-level pseudo-labels to align detectors with VLMs semantic spaces. However, text dependence induces semantic bias, restricting open-vocabulary expansion to text-specified concepts. We propose $\textbf{VK-Det}$, a $\textbf{V}$isual $\textbf{K}$nowledge-guided open-vocabulary object $\textbf{Det}$ection framework $\textit{without}$ extra supervision. First, we discover and leverage vision encoder's inherent informative region perception to attain fine-grained localization and adaptive distillation. Second, we introduce a novel prototype-aware pseudo-labeling strategy. It models inter-class decision boundaries through feature clustering and maps detection regions to latent categories via prototype matching. This enhances attention to novel objects while compensating for missing supervision. Extensive experiments show state-of-the-art performance, achieving 30.1 $\mathrm{mAP}^{N}$ on DIOR and 23.3 $\mathrm{mAP}^{N}$ on DOTA, outperforming even extra supervised methods.

</details>


### [85] [Less Is More: An Explainable AI Framework for Lightweight Malaria Classification](https://arxiv.org/abs/2511.18083)
*Md Abdullah Al Kafi,Raka Moni,Sumit Kumar Banshal*

Main category: cs.CV

TL;DR: 该研究提出了一种基于形态学特征工程的轻量级机器学习方法（EMFE），用于疟疾细胞图像分类，在保持高准确率的同时显著降低了计算需求和模型大小。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在医学图像分类中计算需求高且缺乏可解释性，研究者希望探索对于简单的二元分类任务（如疟疾检测）是否必须使用复杂的神经网络。

Method: 使用NIH疟疾细胞图像数据集，提取细胞图像中的两个形态学特征（非背景像素数和细胞内部孔洞数），比较逻辑回归、随机森林与多种深度学习模型（ResNet18等），并构建两阶段集成模型。

Result: 单变量逻辑回归模型达到94.80%的测试准确率，模型大小仅1.2kB，推理延迟2.3ms；两阶段集成模型准确率提升至97.15%。相比之下，深度学习方法需要13.6-44.7MB存储空间和68ms推理时间。

Conclusion: 紧凑的特征工程方法可以在保持临床意义分类性能的同时，提供更好的透明度、可重复性、速度和部署可行性，特别适用于计算资源有限的环境。

Abstract: Background and Objective: Deep learning models have high computational needs and lack interpretability but are often the first choice for medical image classification tasks. This study addresses whether complex neural networks are essential for the simple binary classification task of malaria. We introduce the Extracted Morphological Feature Engineered (EMFE) pipeline, a transparent, reproducible, and low compute machine learning approach tailored explicitly for simple cell morphology, designed to achieve deep learning performance levels on a simple CPU only setup with the practical aim of real world deployment.
  Methods: The study used the NIH Malaria Cell Images dataset, with two features extracted from each cell image: the number of non background pixels and the number of holes within the cell. Logistic Regression and Random Forest were compared against ResNet18, DenseNet121, MobileNetV2, and EfficientNet across accuracy, model size, and CPU inference time. An ensemble model was created by combining Logistic Regression and Random Forests to achieve higher accuracy while retaining efficiency.
  Results: The single variable Logistic Regression model achieved a test accuracy of 94.80 percent with a file size of 1.2 kB and negligible inference latency (2.3 ms). The two stage ensemble improved accuracy to 97.15 percent. In contrast, the deep learning methods require 13.6 MB to 44.7 MB of storage and show significantly higher inference times (68 ms).
  Conclusion: This study shows that a compact feature engineering approach can produce clinically meaningful classification performance while offering gains in transparency, reproducibility, speed, and deployment feasibility. The proposed pipeline demonstrates that simple interpretable features paired with lightweight models can serve as a practical diagnostic solution for environments with limited computational resources.

</details>


### [86] [Together, Then Apart: Revisiting Multimodal Survival Analysis via a Min-Max Perspective](https://arxiv.org/abs/2511.18089)
*Wenjing Liu,Qin Ren,Wen Zhang,Yuewei Lin,Chenyu You*

Main category: cs.CV

TL;DR: 本文提出Together-Then-Apart (TTA)框架，通过同时优化对齐性和差异性来解决多模态生存分析中的表示崩溃问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法过度强调跨模态对齐，导致模态特异性特征丢失和表示多样性降低，影响生存分析性能。

Method: TTA采用统一的最小-最大优化框架，包含Together阶段（最小化语义差异）和Apart阶段（最大化表示多样性），使用共享原型和模态锚点来平衡对齐与特异性。

Result: 在五个TCGA基准测试中，TTA consistently outperforms state-of-the-art methods。

Conclusion: 该框架为多模态生存分析提供了新的理论视角，证明对齐性和差异性可以联合实现，获得更鲁棒、可解释且具有生物学意义的结果。

Abstract: Integrating heterogeneous modalities such as histopathology and genomics is central to advancing survival analysis, yet most existing methods prioritize cross-modal alignment through attention-based fusion mechanisms, often at the expense of modality-specific characteristics. This overemphasis on alignment leads to representation collapse and reduced diversity. In this work, we revisit multi-modal survival analysis via the dual lens of alignment and distinctiveness, positing that preserving modality-specific structure is as vital as achieving semantic coherence. In this paper, we introduce Together-Then-Apart (TTA), a unified min-max optimization framework that simultaneously models shared and modality-specific representations. The Together stage minimizes semantic discrepancies by aligning embeddings via shared prototypes, guided by an unbalanced optimal transport objective that adaptively highlights informative tokens. The Apart stage maximizes representational diversity through modality anchors and a contrastive regularizer that preserve unique modality information and prevent feature collapse. Extensive experiments on five TCGA benchmarks show that TTA consistently outperforms state-of-the-art methods. Beyond empirical gains, our formulation provides a new theoretical perspective of how alignment and distinctiveness can be jointly achieved in for robust, interpretable, and biologically meaningful multi-modal survival analysis.

</details>


### [87] [Versatile Recompression-Aware Perceptual Image Super-Resolution](https://arxiv.org/abs/2511.18090)
*Mingwei He,Tongda Xu,Xingtong Ge,Ming Sun,Chao Zhou,Yan Wang*

Main category: cs.CV

TL;DR: VRPSR是一种感知超分辨率方法，专门考虑图像重新压缩的影响，通过构建可泛化的编解码器模拟器和针对感知SR的训练技术，显著降低压缩后的比特率。


<details>
  <summary>Details</summary>
Motivation: 传统的感知超分辨率方法忽略重新压缩过程，导致恢复的图像在后续压缩中产生额外伪影，这在实际存储和传输场景中是不理想的。

Method: 1. 将压缩建模为条件文本到图像生成任务，利用预训练扩散模型构建可泛化编解码器模拟器；2. 提出针对感知SR的训练技术，包括使用感知目标优化模拟器和采用轻微压缩图像作为训练目标。

Result: 基于Real-ESRGAN和S3Diff，在H.264/H.265/H.266压缩下节省超过10%的比特率，并能促进SR与后处理模型的联合优化。

Conclusion: VRPSR成功解决了感知超分辨率与重新压缩的联合优化问题，为实际应用场景提供了更优的解决方案。

Abstract: Perceptual image super-resolution (SR) methods restore degraded images and produce sharp outputs. In practice, those outputs are usually recompressed for storage and transmission. Ignoring recompression is suboptimal as the downstream codec might add additional artifacts to restored images. However, jointly optimizing SR and recompression is challenging, as the codecs are not differentiable and vary in configuration. In this paper, we present Versatile Recompression-Aware Perceptual Super-Resolution (VRPSR), which makes existing perceptual SR aware of versatile compression. First, we formulate compression as conditional text-to-image generation and utilize a pre-trained diffusion model to build a generalizable codec simulator. Next, we propose a set of training techniques tailored for perceptual SR, including optimizing the simulator using perceptual targets and adopting slightly compressed images as the training target. Empirically, our VRPSR saves more than 10\% bitrate based on Real-ESRGAN and S3Diff under H.264/H.265/H.266 compression. Besides, our VRPSR facilitates joint optimization of the SR and post-processing model after recompression.

</details>


### [88] [Spotlight: Identifying and Localizing Video Generation Errors Using VLMs](https://arxiv.org/abs/2511.18102)
*Aditya Chinchure,Sahithya Ravi,Pushkar Shukla,Vered Shwartz,Leonid Sigal*

Main category: cs.CV

TL;DR: Spotlight是一个新的任务，旨在定位和解释视频生成错误，通过标注1600多个细粒度错误并评估VLMs在错误识别和定位方面的表现。


<details>
  <summary>Details</summary>
Motivation: 当前文本到视频模型（T2V）虽然能生成高质量视频，但错误仍然常见且更细微和局部化。现有评估范式通常整体评估视频，而无法识别错误发生的时间或描述其性质。

Method: 使用200个多样化文本提示和三个先进视频生成器（Veo 3、Seedance、LTX-2）生成600个视频，标注六类错误（运动、物理、提示遵从等），并评估VLMs在错误识别和定位上的表现。

Result: 发现提示遵从和物理错误占主导且持续时间较长，而外观消失和身体姿势错误出现在较短片段。VLMs在错误识别和定位方面显著落后于人类，但通过推理时策略可将性能提升近2倍。

Conclusion: Spotlight任务为构建细粒度评估工具和更复杂的视频生成器奖励模型铺平了道路。

Abstract: Current text-to-video models (T2V) can generate high-quality, temporally coherent, and visually realistic videos. Nonetheless, errors still often occur, and are more nuanced and local compared to the previous generation of T2V models. While current evaluation paradigms assess video models across diverse dimensions, they typically evaluate videos holistically without identifying when specific errors occur or describing their nature. We address this gap by introducing Spotlight, a novel task aimed at localizing and explaining video-generation errors. We generate 600 videos using 200 diverse textual prompts and three state-of-the-art video generators (Veo 3, Seedance, and LTX-2), and annotate over 1600 fine-grained errors across six types, including motion, physics, and prompt adherence. We observe that adherence and physics errors are predominant and persist across longer segments, whereas appearance-disappearance and body pose errors manifest in shorter segments. We then evaluate current VLMs on Spotlight and find that VLMs lag significantly behind humans in error identification and localization in videos. We propose inference-time strategies to probe the limits of current VLMs on our task, improving performance by nearly 2x. Our task paves a way forward to building fine-grained evaluation tools and more sophisticated reward models for video generators.

</details>


### [89] [Consolidating Diffusion-Generated Video Detection with Unified Multimodal Forgery Learning](https://arxiv.org/abs/2511.18104)
*Xiaohong Liu,Xiufeng Song,Huayu Zheng,Lei Bai,Xiaoming Liu,Guangtao Zhai*

Main category: cs.CV

TL;DR: MM-Det++是一个多模态检测算法，专门用于检测扩散模型生成的视频，通过时空分支和多模态分支结合统一多模态学习模块，在检测合成视频方面表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 随着扩散模型生成的视频日益增多，信息安全问题日益突出，而现有方法主要关注图像级伪造检测，视频级伪造检测研究不足，需要可靠的合成媒体检测方法。

Method: 提出MM-Det++算法，包含两个创新分支：时空分支使用帧中心视觉变换器聚合时空信息；多模态分支利用多模态大语言模型获取多模态伪造表示。通过统一多模态学习模块整合多模态表示，并建立了大规模扩散视频取证数据集。

Result: 大量实验证明MM-Det++在检测扩散生成视频方面具有优越性，统一多模态伪造学习效果显著。

Conclusion: MM-Det++通过统一多模态学习方法有效解决了扩散生成视频的检测问题，为视频取证研究提供了有力工具。

Abstract: The proliferation of videos generated by diffusion models has raised increasing concerns about information security, highlighting the urgent need for reliable detection of synthetic media. Existing methods primarily focus on image-level forgery detection, leaving generic video-level forgery detection largely underexplored. To advance video forensics, we propose a consolidated multimodal detection algorithm, named MM-Det++, specifically designed for detecting diffusion-generated videos. Our approach consists of two innovative branches and a Unified Multimodal Learning (UML) module. Specifically, the Spatio-Temporal (ST) branch employs a novel Frame-Centric Vision Transformer (FC-ViT) to aggregate spatio-temporal information for detecting diffusion-generated videos, where the FC-tokens enable the capture of holistic forgery traces from each video frame. In parallel, the Multimodal (MM) branch adopts a learnable reasoning paradigm to acquire Multimodal Forgery Representation (MFR) by harnessing the powerful comprehension and reasoning capabilities of Multimodal Large Language Models (MLLMs), which discerns the forgery traces from a flexible semantic perspective. To integrate multimodal representations into a coherent space, a UML module is introduced to consolidate the generalization ability of MM-Det++. In addition, we also establish a large-scale and comprehensive Diffusion Video Forensics (DVF) dataset to advance research in video forgery detection. Extensive experiments demonstrate the superiority of MM-Det++ and highlight the effectiveness of unified multimodal forgery learning in detecting diffusion-generated videos.

</details>


### [90] [AdaPerceiver: Transformers with Adaptive Width, Depth, and Tokens](https://arxiv.org/abs/2511.18105)
*Purvish Jajal,Nick John Eliopoulos,Benjamin Shiue-Hal Chou,George K. Thiruvathukal,Yung-Hsiang Lu,James C. Davis*

Main category: cs.CV

TL;DR: AdaPerceiver是首个在深度、宽度和token数量三个维度上实现统一自适应性的Transformer架构，能够在单一模型中动态调整计算资源分配，以适应不同的硬件和延迟约束。


<details>
  <summary>Details</summary>
Motivation: 现有的Transformer模型在推理时计算分配僵化，无法灵活适应多样化的硬件和延迟要求。大多数动态计算方法只关注单一维度（如减少token数量），缺乏统一的适应性。

Method: 提出支持深度、宽度和token数量三个维度自适应性的架构，并设计高效的联合训练策略，确保模型在各种配置下保持性能。

Result: 在图像分类任务中，AdaPerceiver在85.4%准确率下比FlexiViT-L吞吐量高36%；在密集预测任务中，与ViT-H/14相比，语义分割和深度估计的编码器FLOPs减少约26倍；配备策略后能在保持ImageNet1K准确率（±0.1%）的同时减少24-33%的FLOPs。

Conclusion: AdaPerceiver通过统一的自适应架构显著扩展了准确率-吞吐量的帕累托前沿，为Transformer模型在真实部署中提供灵活的计算资源分配方案。

Abstract: Modern transformer architectures achieve remarkable performance across tasks and domains but remain rigid in how they allocate computation at inference time. Real-world deployment often requires models to adapt to diverse hardware and latency constraints, yet most approaches to dynamic computation focus on a single axis -- such as reducing the number of tokens. We present a novel capability: AdaPerceiver, the first transformer architecture with unified adaptivity across depth, width, and tokens within a single model. We propose an architecture that supports adaptivity along these axes. We couple this with an efficient joint training regime that ensures the model maintains performance across its various configurations. We evaluate AdaPerceiver on image classification, semantic segmentation, and depth estimation tasks. On image classification, AdaPerceiver expands the accuracy-throughput Pareto front. It achieves 85.4% accuracy while yielding 36% higher throughput than FlexiViT-L. On dense prediction, AdaPerceiver matches ViT-H/14 while having $\sim$26x fewer encoder FLOPs (floating-point operations) on semantic segmentation and depth estimation. Finally, we show how AdaPerceiver equipped with a policy can maintain ImageNet1K accuracy ($\pm0.1$ percentage points) while reducing FLOPs by $24-33$%.

</details>


### [91] [Muskie: Multi-view Masked Image Modeling for 3D Vision Pre-training](https://arxiv.org/abs/2511.18115)
*Wenyu Li,Sidun Liu,Peng Qiao,Yong Dou,Tongrui Hu*

Main category: cs.CV

TL;DR: Muskie是一个原生多视图视觉骨干网络，专为3D视觉任务设计，通过多视图一致性预训练和激进掩码策略，无需3D监督即可学习视图不变特征和几何理解。


<details>
  <summary>Details</summary>
Motivation: 现有模型多为逐帧处理，存在多视图一致性有限的问题。Muskie旨在同时处理多个视图，并在预训练阶段引入多视图一致性。

Method: 通过重建一个视图中被严重掩码的内容，利用其他视图的几何对应关系进行预训练。采用激进的掩码策略，模型隐式学习视图不变特征和几何理解。

Result: 相比DINO等最先进的逐帧骨干网络，Muskie在多视图对应精度上表现更优。在下游3D任务（如相机姿态估计和点云重建）中，使用Muskie作为骨干网络能持续提升性能。

Conclusion: Muskie通过多视图一致性预训练有效提升了3D视觉任务的性能，证明了在预训练阶段引入多视图一致性的重要性。

Abstract: We present Muskie, a native multi-view vision backbone designed for 3D vision tasks. Unlike existing models, which are frame-wise and exhibit limited multi-view consistency, Muskie is designed to process multiple views simultaneously and introduce multi-view consistency in pre-training stage. Muskie is trained to reconstruct heavily masked content in one view by finding and utilizing geometric correspondences from other views. Through this pretext task and our proposed aggressive masking strategy, the model implicitly to learn view-invariant features and develop strong geometric understanding without any 3D supervision. Compared with state-of-the-art frame-wise backbones such as DINO, Muskie achieves higher multi-view correspondence accuracy. Furthermore, we demonstrate that using Muskie as a backbone consistently enhances performance on downstream 3D tasks, including camera pose estimation and pointmap reconstruction. Codes are publicly available at https://leo-frank.github.io/Muskie/

</details>


### [92] [PromptMoE: Generalizable Zero-Shot Anomaly Detection via Visually-Guided Prompt Mixtures](https://arxiv.org/abs/2511.18116)
*Yuheng Shao,Lizhang Wang,Changhao Li,Peixian Chen,Qinyuan Liu*

Main category: cs.CV

TL;DR: 提出PromptMoE方法，通过混合专家机制动态组合多个专家提示来解决零样本异常检测中的表示瓶颈和过拟合问题


<details>
  <summary>Details</summary>
Motivation: 现有基于CLIP的零样本异常检测方法受限于提示工程策略，存在表示瓶颈和过拟合问题，难以泛化到未见过的异常复杂性

Method: 使用专家提示池作为可组合语义基元，通过视觉引导的混合专家机制为每个实例动态组合提示，生成语义丰富的文本表示

Result: 在工业和医疗领域的15个数据集上进行了广泛实验，证明了方法的有效性和最先进性能

Conclusion: PromptMoE通过组合式提示学习方法克服了现有方法的局限性，实现了鲁棒的零样本异常检测

Abstract: Zero-Shot Anomaly Detection (ZSAD) aims to identify and localize anomalous regions in images of unseen object classes. While recent methods based on vision-language models like CLIP show promise, their performance is constrained by existing prompt engineering strategies. Current approaches, whether relying on single fixed, learnable, or dense dynamic prompts, suffer from a representational bottleneck and are prone to overfitting on auxiliary data, failing to generalize to the complexity and diversity of unseen anomalies. To overcome these limitations, we propose $\mathtt{PromptMoE}$. Our core insight is that robust ZSAD requires a compositional approach to prompt learning. Instead of learning monolithic prompts, $\mathtt{PromptMoE}$ learns a pool of expert prompts, which serve as a basis set of composable semantic primitives, and a visually-guided Mixture-of-Experts (MoE) mechanism to dynamically combine them for each instance. Our framework materializes this concept through a Visually-Guided Mixture of Prompt (VGMoP) that employs an image-gated sparse MoE to aggregate diverse normal and abnormal expert state prompts, generating semantically rich textual representations with strong generalization. Extensive experiments across 15 datasets in industrial and medical domains demonstrate the effectiveness and state-of-the-art performance of $\mathtt{PromptMoE}$.

</details>


### [93] [MVS-TTA: Test-Time Adaptation for Multi-View Stereo via Meta-Auxiliary Learning](https://arxiv.org/abs/2511.18120)
*Hannuo Zhang,Zhixiang Chi,Yang Wang,Xinxin Zuo*

Main category: cs.CV

TL;DR: MVS-TTA是一个高效测试时自适应框架，通过元学习将基于优化的测试时自适应整合到基于学习的多视图立体方法中，提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 基于学习的MVS方法由于固定模型参数和有限训练数据分布导致泛化能力不足，而基于优化的方法虽然支持场景自适应但缺乏可扩展性且需要昂贵的逐场景优化。

Method: 采用自监督的跨视图一致性损失作为辅助任务指导推理时自适应，引入元辅助学习策略显式训练模型从辅助任务更新中受益，框架与模型无关且只需最小架构修改。

Result: 在标准数据集和跨数据集泛化设置上的大量实验表明，MVS-TTA能持续提升性能，即使应用于最先进的MVS模型。

Conclusion: 这是首次使用元学习将基于优化的测试时自适应整合到基于学习的MVS中的尝试，框架具有模型无关性和高效性。

Abstract: Recent learning-based multi-view stereo (MVS) methods are data-driven and have achieved remarkable progress due to large-scale training data and advanced architectures. However, their generalization remains sub-optimal due to fixed model parameters trained on limited training data distributions. In contrast, optimization-based methods enable scene-specific adaptation but lack scalability and require costly per-scene optimization. In this paper, we propose MVS-TTA, an efficient test-time adaptation (TTA) framework that enhances the adaptability of learning-based MVS methods by bridging these two paradigms. Specifically, MVS-TTA employs a self-supervised, cross-view consistency loss as an auxiliary task to guide inference-time adaptation. We introduce a meta-auxiliary learning strategy to train the model to benefit from auxiliary-task-based updates explicitly. Our framework is model-agnostic and can be applied to a wide range of MVS methods with minimal architectural changes. Extensive experiments on standard datasets (DTU, BlendedMVS) and a challenging cross-dataset generalization setting demonstrate that MVS-TTA consistently improves performance, even when applied to state-of-the-art MVS models. To our knowledge, this is the first attempt to integrate optimization-based test-time adaptation into learning-based MVS using meta-learning. The code will be available at https://github.com/mart87987-svg/MVS-TTA.

</details>


### [94] [VCU-Bridge: Hierarchical Visual Connotation Understanding via Semantic Bridging](https://arxiv.org/abs/2511.18121)
*Ming Zhong,Yuanlei Wang,Liuzhou Zhang,Arctanx An,Renrui Zhang,Hao Liang,Ming Lu,Ying Shen,Wentao Zhang*

Main category: cs.CV

TL;DR: 论文提出了VCU-Bridge框架和HVCU-Bench基准，旨在解决多模态大语言模型在视觉理解中缺乏层次化推理能力的问题，通过强化低层感知能力来提升高层推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM模型处理视觉信息的方式与人类不同，往往将细节感知和高级推理割裂开来，而现有评估方法也忽视了这种语义和因果依赖关系，导致评估结果缺乏诊断性。

Method: 1. 提出VCU-Bridge框架，模拟人类视觉理解的层次化结构：从基础感知→语义桥接→抽象内涵；2. 构建HVCU-Bench基准进行层次化诊断评估；3. 基于蒙特卡洛树搜索的数据生成管道进行指令调优。

Result: 实验显示模型性能随推理层次升高而下降；通过强化低层能力可显著提升高层推理性能（HVCU-Bench和通用基准平均提升2.53%，MMStar基准提升7.26%）。

Conclusion: 层次化思维模式对增强MLLM能力具有重要意义，低层感知能力的强化能有效提升高层推理性能，证明了该方法的有效性。

Abstract: While Multimodal Large Language Models (MLLMs) excel on benchmarks, their processing paradigm differs from the human ability to integrate visual information. Unlike humans who naturally bridge details and high-level concepts, models tend to treat these elements in isolation. Prevailing evaluation protocols often decouple low-level perception from high-level reasoning, overlooking their semantic and causal dependencies, which yields non-diagnostic results and obscures performance bottlenecks. We present VCU-Bridge, a framework that operationalizes a human-like hierarchy of visual connotation understanding: multi-level reasoning that advances from foundational perception through semantic bridging to abstract connotation, with an explicit evidence-to-inference trace from concrete cues to abstract conclusions. Building on this framework, we construct HVCU-Bench, a benchmark for hierarchical visual connotation understanding with explicit, level-wise diagnostics. Comprehensive experiments demonstrate a consistent decline in performance as reasoning progresses to higher levels. We further develop a data generation pipeline for instruction tuning guided by Monte Carlo Tree Search (MCTS) and show that strengthening low-level capabilities yields measurable gains at higher levels. Interestingly, it not only improves on HVCU-Bench but also brings benefits on general benchmarks (average +2.53%), especially with substantial gains on MMStar (+7.26%), demonstrating the significance of the hierarchical thinking pattern and its effectiveness in enhancing MLLM capabilities. The project page is at https://vcu-bridge.github.io .

</details>


### [95] [Bias Is a Subspace, Not a Coordinate: A Geometric Rethinking of Post-hoc Debiasing in Vision-Language Models](https://arxiv.org/abs/2511.18123)
*Dachuan Zhao,Weiyue Li,Zhenda Shen,Yushu Qiu,Bowen Xu,Haoyu Chen,Yongchao Chen*

Main category: cs.CV

TL;DR: 本文提出了SPD（子空间投影去偏）方法，通过识别和移除线性可解码偏见的整个子空间来解决视觉语言模型中的偏见问题，相比现有方法在公平性指标上平均提升18.5%。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在表示中编码并放大了人口统计偏见，导致下游任务中出现偏见关联和错误对齐。现有的坐标级去偏方法存在特征纠缠、跨数据集泛化差和偏见去除不完整三个关键问题。

Method: SPD方法基于几何原理，识别偏见分布的线性子空间，移除整个线性可解码偏见子空间，同时重新插入中性均值分量以保持语义保真度。

Result: 在零样本分类、文本到图像检索和图像生成等任务上的广泛实验表明，SPD方法在四个公平性指标上平均提升18.5%，同时任务性能损失最小。

Conclusion: SPD框架提供了更鲁棒的去偏效果，验证了偏见分布在少数线性子空间而非少数坐标上的发现，为视觉语言模型的公平性提供了有效解决方案。

Abstract: Vision-Language Models (VLMs) have become indispensable for multimodal reasoning, yet their representations often encode and amplify demographic biases, resulting in biased associations and misaligned predictions in downstream tasks. Such behavior undermines fairness and distorts the intended alignment between vision and language. Recent post-hoc approaches attempt to mitigate bias by replacing the most attribute-correlated embedding coordinates with neutral values. However, our systematic analysis reveals three critical failures of this coordinate-wise approach: feature entanglement, poor cross-dataset generalization, and incomplete bias removal. We find that bias is not localized to a few coordinates but is instead distributed across a few linear subspaces. To address these limitations, we propose $\textbf{S}$ubspace $\textbf{P}$rojection $\textbf{D}$ebiasing ($\textbf{SPD}$), a geometrically principled framework that identifies and removes the entire subspace of linearly decodable bias while reinserting a neutral mean component to preserve semantic fidelity. Extensive experiments across zero-shot classification, text-to-image retrieval, and image generation validate the effectiveness of SPD: our method achieves more robust debiasing with an average improvement of $18.5\%$ across four fairness metrics, while maintaining minimal loss in task performance compared to the best debiasing baseline.

</details>


### [96] [SFHand: A Streaming Framework for Language-guided 3D Hand Forecasting and Embodied Manipulation](https://arxiv.org/abs/2511.18127)
*Ruicong Liu,Yifei Huang,Liangyang Ouyang,Caixin Kang,Yoichi Sato*

Main category: cs.CV

TL;DR: SFHand是首个用于语言引导3D手部预测的流式框架，能够从连续视频流和语言指令中自回归预测未来3D手部状态，在AR和机器人应用中实现实时交互。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要离线处理视频序列且无法整合语言指导，不适合实时人机交互应用。

Method: 结合流式自回归架构和ROI增强记忆层，预测手部类型、2D边界框、3D姿态和轨迹等完整状态，并构建了EgoHaFL大规模数据集。

Result: 在3D手部预测上达到SOTA，比现有方法提升35.8%，下游任务成功率提升13.4%。

Conclusion: SFHand框架为实时语言引导的3D手部预测提供了有效解决方案，具有实际应用价值。

Abstract: Real-time 3D hand forecasting is a critical component for fluid human-computer interaction in applications like AR and assistive robotics. However, existing methods are ill-suited for these scenarios, as they typically require offline access to accumulated video sequences and cannot incorporate language guidance that conveys task intent. To overcome these limitations, we introduce SFHand, the first streaming framework for language-guided 3D hand forecasting. SFHand autoregressively predicts a comprehensive set of future 3D hand states, including hand type, 2D bounding box, 3D pose, and trajectory, from a continuous stream of video and language instructions. Our framework combines a streaming autoregressive architecture with an ROI-enhanced memory layer, capturing temporal context while focusing on salient hand-centric regions. To enable this research, we also introduce EgoHaFL, the first large-scale dataset featuring synchronized 3D hand poses and language instructions. We demonstrate that SFHand achieves new state-of-the-art results in 3D hand forecasting, outperforming prior work by a significant margin of up to 35.8%. Furthermore, we show the practical utility of our learned representations by transferring them to downstream embodied manipulation tasks, improving task success rates by up to 13.4% on multiple benchmarks. Dataset page: https://huggingface.co/datasets/ut-vision/EgoHaFL, project page: https://github.com/ut-vision/SFHand.

</details>


### [97] [Video4Edit: Viewing Image Editing as a Degenerate Temporal Process](https://arxiv.org/abs/2511.18131)
*Xiaofan Li,Yanpeng Sun,Chenming Wu,Fan Duan,YuAn Wang,Weihao Bo,Yumeng Zhang,Dingkang Liang*

Main category: cs.CV

TL;DR: 通过将图像编辑视为退化时间过程，利用视频预训练中的单帧演化先验，实现了仅需1%监督数据即可达到主流编辑模型性能的高效图像编辑方法


<details>
  <summary>Details</summary>
Motivation: 当前多模态基础模型虽然推动了指令驱动的图像生成和编辑，但现有编辑流程成本高昂，需要大量高质量三元组数据，且编辑效果严重依赖指令对目标语义的精确描述

Method: 从时间建模角度重新审视图像编辑问题，将图像编辑视为退化时间过程，利用视频预训练获得的单帧演化先验，实现数据高效的精调机制

Result: 实验表明，该方法仅使用主流编辑模型约1%的监督数据，就能达到领先开源基线的性能水平

Conclusion: 时间建模视角为图像编辑提供了新的解决方案，通过利用视频预训练先验，显著降低了数据需求，实现了高效高质量的指令驱动图像编辑

Abstract: We observe that recent advances in multimodal foundation models have propelled instruction-driven image generation and editing into a genuinely cross-modal, cooperative regime. Nevertheless, state-of-the-art editing pipelines remain costly: beyond training large diffusion/flow models, they require curating massive high-quality triplets of \{instruction, source image, edited image\} to cover diverse user intents. Moreover, the fidelity of visual replacements hinges on how precisely the instruction references the target semantics. We revisit this challenge through the lens of temporal modeling: if video can be regarded as a full temporal process, then image editing can be seen as a degenerate temporal process. This perspective allows us to transfer single-frame evolution priors from video pre-training, enabling a highly data-efficient fine-tuning regime. Empirically, our approach matches the performance of leading open-source baselines while using only about one percent of the supervision demanded by mainstream editing models.

</details>


### [98] [SCALER: SAM-Enhanced Collaborative Learning for Label-Deficient Concealed Object Segmentation](https://arxiv.org/abs/2511.18136)
*Chunming He,Rihan Zhang,Longxiang Tang,Ziyun Yang,Kai Li,Deng-Ping Fan,Sina Farsiu*

Main category: cs.CV

TL;DR: SCALER是一个用于标签不足隐蔽目标分割的统一协作框架，通过联合优化均值教师分割器和可学习SAM，在两个交替阶段中实现相互监督和性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有LDCOS方法依赖一致性约束或SAM伪标签，但受限于目标内在隐蔽性和标注稀缺性，性能有限。研究旨在探索一致性约束和SAM监督的联合集成，以及分割器与SAM的相互指导。

Method: SCALER框架包含两个交替阶段：阶段I在固定SAM监督下优化分割器，使用基于熵的图像级和基于不确定性的像素级加权选择可靠伪标签区域；阶段II通过增强不变性和噪声抵抗损失更新SAM，利用其对扰动的固有鲁棒性。

Result: 实验表明SCALER在八个半监督和弱监督COS任务上实现了一致的性能提升，可作为标签稀缺条件下增强轻量分割器和大型基础模型的通用训练范式。

Conclusion: SCALER成功证明了分割器与SAM的协同优化能够有效提升LDCOS性能，为标签稀缺场景下的分割任务提供了新的解决方案。

Abstract: Existing methods for label-deficient concealed object segmentation (LDCOS) either rely on consistency constraints or Segment Anything Model (SAM)-based pseudo-labeling. However, their performance remains limited due to the intrinsic concealment of targets and the scarcity of annotations. This study investigates two key questions: (1) Can consistency constraints and SAM-based supervision be jointly integrated to better exploit complementary information and enhance the segmenter? and (2) beyond that, can the segmenter in turn guide SAM through reciprocal supervision, enabling mutual improvement? To answer these questions, we present SCALER, a unified collaborative framework toward LDCOS that jointly optimizes a mean-teacher segmenter and a learnable SAM. SCALER operates in two alternating phases. In \textbf{Phase \uppercase\expandafter{\romannumeral1}}, the segmenter is optimized under fixed SAM supervision using entropy-based image-level and uncertainty-based pixel-level weighting to select reliable pseudo-label regions and emphasize harder examples. In \textbf{Phase \uppercase\expandafter{\romannumeral2}}, SAM is updated via augmentation invariance and noise resistance losses, leveraging its inherent robustness to perturbations. Experiments demonstrate that SCALER yields consistent performance gains across eight semi- and weakly-supervised COS tasks. The results further suggest that SCALER can serve as a general training paradigm to enhance both lightweight segmenters and large foundation models under label-scarce conditions. Code will be released.

</details>


### [99] [Compact neural networks for astronomy with optimal transport bias correction](https://arxiv.org/abs/2511.18139)
*Shuhuan Wang,Yuzhen Xie,Jiayi Li*

Main category: cs.CV

TL;DR: WaveletMamba是一个理论驱动的天文图像处理框架，结合小波分解、状态空间建模和数学正则化，在低分辨率输入下实现高分辨率性能，并具有分辨率多稳态特性。


<details>
  <summary>Details</summary>
Motivation: 解决天文成像中效率与分辨率之间的权衡问题，该问题限制了大尺度形态分类和红移预测的能力。

Method: 集成小波分解、状态空间建模、数学正则化和多级偏差校正，包括HK距离（分布级最优传输）和颜色感知加权（样本级微调）。

Result: 在64x64分辨率下达到81.72%±0.53%的分类准确率（仅3.54M参数），在244x244分辨率下达到80.93%±0.27%的准确率，计算效率提升9.7倍，Log-MSE改进22.96%，异常值减少26.10%。

Conclusion: 数学严谨性使科学AI实现了前所未有的效率和全面的偏差校正，连接计算机视觉和天体物理学，推动跨学科科学发现革命。

Abstract: Astronomical imaging confronts an efficiency-resolution tradeoff that limits large-scale morphological classification and redshift prediction. We introduce WaveletMamba, a theory-driven framework integrating wavelet decomposition with state-space modeling, mathematical regularization, and multi-level bias correction. WaveletMamba achieves 81.72% +/- 0.53% classification accuracy at 64x64 resolution with only 3.54M parameters, delivering high-resolution performance (80.93% +/- 0.27% at 244x244) at low-resolution inputs with 9.7x computational efficiency gains. The framework exhibits Resolution Multistability, where models trained on low-resolution data achieve consistent accuracy across different input scales despite divergent internal representations. The framework's multi-level bias correction synergizes HK distance (distribution-level optimal transport) with Color-Aware Weighting (sample-level fine-tuning), achieving 22.96% Log-MSE improvement and 26.10% outlier reduction without explicit selection function modeling. Here, we show that mathematical rigor enables unprecedented efficiency and comprehensive bias correction in scientific AI, bridging computer vision and astrophysics to revolutionize interdisciplinary scientific discovery.

</details>


### [100] [UnfoldLDM: Deep Unfolding-based Blind Image Restoration with Latent Diffusion Priors](https://arxiv.org/abs/2511.18152)
*Chunming He,Rihan Zhang,Zheng Chen,Bowen Yang,CHengyu Fang,Yunlong Lin,Fengyang Xiao,Sina Farsiu*

Main category: cs.CV

TL;DR: UnfoldLDM 是一种结合深度展开网络和潜在扩散模型的盲图像恢复方法，解决了现有方法对特定退化的依赖和过度平滑问题，通过多粒度退化感知模块和抗退化潜在扩散模型实现鲁棒的盲图像恢复。


<details>
  <summary>Details</summary>
Motivation: 现有深度展开网络在盲图像恢复任务中存在两个主要问题：(1) 对特定退化的依赖，其优化框架绑定于已知的退化模型；(2) 过度平滑偏差，由于直接将梯度下降输出（以低频内容为主）馈入近端项，抑制了精细纹理。

Method: 提出 UnfoldLDM 方法，在每个阶段使用多粒度退化感知模块作为梯度下降步骤，估计整体退化矩阵及其分解形式。设计抗退化潜在扩散模型从 MGDA 输出中提取紧凑的退化不变先验，并通过过平滑校正变换器显式恢复高频分量和增强纹理细节。

Result: 实验表明，UnfoldLDM 在各种盲图像恢复任务中达到领先水平，并能有益于下游任务。该设计兼容现有的基于 DUN 的方法，可作为即插即用框架。

Conclusion: UnfoldLDM 成功解决了深度展开网络在盲图像恢复中的局限性，通过结合潜在扩散模型实现了退化无关且视觉丰富的恢复效果，为盲图像恢复提供了有效的解决方案。

Abstract: Deep unfolding networks (DUNs) combine the interpretability of model-based methods with the learning ability of deep networks, yet remain limited for blind image restoration (BIR). Existing DUNs suffer from: (1) \textbf{Degradation-specific dependency}, as their optimization frameworks are tied to a known degradation model, making them unsuitable for BIR tasks; and (2) \textbf{Over-smoothing bias}, resulting from the direct feeding of gradient descent outputs, dominated by low-frequency content, into the proximal term, suppressing fine textures. To overcome these issues, we propose UnfoldLDM to integrate DUNs with latent diffusion model (LDM) for BIR. In each stage, UnfoldLDM employs a multi-granularity degradation-aware (MGDA) module as the gradient descent step. MGDA models BIR as an unknown degradation estimation problem and estimates both the holistic degradation matrix and its decomposed forms, enabling robust degradation removal. For the proximal step, we design a degradation-resistant LDM (DR-LDM) to extract compact degradation-invariant priors from the MGDA output. Guided by this prior, an over-smoothing correction transformer (OCFormer) explicitly recovers high-frequency components and enhances texture details. This unique combination ensures the final result is degradation-free and visually rich. Experiments show that our UnfoldLDM achieves a leading place on various BIR tasks and benefits downstream tasks. Moreover, our design is compatible with existing DUN-based methods, serving as a plug-and-play framework. Code will be released.

</details>


### [101] [Matching-Based Few-Shot Semantic Segmentation Models Are Interpretable by Design](https://arxiv.org/abs/2511.18163)
*Pasquale De Marinis,Uzay Kaymak,Rogier Brussee,Gennaro Vessio,Giovanna Castellano*

Main category: cs.CV

TL;DR: 本文提出了首个专门用于解释基于匹配的少样本语义分割模型的方法——Affinity Explainer，通过利用模型固有结构特性生成归因图，揭示支持图像中哪些像素对查询分割预测贡献最大。


<details>
  <summary>Details</summary>
Motivation: 少样本语义分割模型在分割新类别方面表现优异，但其决策过程不透明。尽管可解释AI在标准计算机视觉任务中已有显著进展，但在数据稀缺场景下至关重要的少样本分割可解释性研究仍几乎空白。

Method: Affinity Explainer方法通过在多个特征级别计算支持图像和查询特征之间的匹配分数，提取归因图来突出显示支持图像中对查询分割预测贡献最大的像素。

Result: 在少样本分割基准数据集上的综合实验表明，Affinity Explainer显著优于适配的标准归因方法。定性分析显示，该方法提供的解释具有结构化、连贯的注意力模式，与模型架构一致，并能有效进行模型诊断。

Conclusion: 这项工作为可解释的少样本分割研究奠定了基础，使模型理解和诊断更加可靠，有助于构建更可靠的少样本分割系统。

Abstract: Few-Shot Semantic Segmentation (FSS) models achieve strong performance in segmenting novel classes with minimal labeled examples, yet their decision-making processes remain largely opaque. While explainable AI has advanced significantly in standard computer vision tasks, interpretability in FSS remains virtually unexplored despite its critical importance for understanding model behavior and guiding support set selection in data-scarce scenarios. This paper introduces the first dedicated method for interpreting matching-based FSS models by leveraging their inherent structural properties. Our Affinity Explainer approach extracts attribution maps that highlight which pixels in support images contribute most to query segmentation predictions, using matching scores computed between support and query features at multiple feature levels. We extend standard interpretability evaluation metrics to the FSS domain and propose additional metrics to better capture the practical utility of explanations in few-shot scenarios. Comprehensive experiments on FSS benchmark datasets, using different models, demonstrate that our Affinity Explainer significantly outperforms adapted standard attribution methods. Qualitative analysis reveals that our explanations provide structured, coherent attention patterns that align with model architectures and and enable effective model diagnosis. This work establishes the foundation for interpretable FSS research, enabling better model understanding and diagnostic for more reliable few-shot segmentation systems. The source code is publicly available at https://github.com/pasqualedem/AffinityExplainer.

</details>


### [102] [Nested Unfolding Network for Real-World Concealed Object Segmentation](https://arxiv.org/abs/2511.18164)
*Chunming He,Rihan Zhang,Dingming Zhang,Fengyang Xiao,Deng-Ping Fan,Sina Farsiu*

Main category: cs.CV

TL;DR: 提出了嵌套展开网络（NUN），一种用于真实世界隐蔽物体分割的统一框架，通过DUN-in-DUN设计将恢复与分割解耦。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度展开网络的方法将背景估计与图像恢复耦合，导致目标冲突且需要预定义退化类型，这在真实场景中不现实。

Method: 采用DUN-in-DUN设计，在分割导向展开网络的每个阶段嵌入抗退化展开网络，利用视觉语言模型动态推断退化语义并恢复高质量图像，同时进行可逆估计来细化前景和背景。

Result: 在干净和退化基准测试中都取得了领先地位。

Conclusion: NUN框架通过解耦恢复和分割，实现了对真实世界隐蔽物体分割的有效处理，无需显式先验知识。

Abstract: Deep unfolding networks (DUNs) have recently advanced concealed object segmentation (COS) by modeling segmentation as iterative foreground-background separation. However, existing DUN-based methods (RUN) inherently couple background estimation with image restoration, leading to conflicting objectives and requiring pre-defined degradation types, which are unrealistic in real-world scenarios. To address this, we propose the nested unfolding network (NUN), a unified framework for real-world COS. NUN adopts a DUN-in-DUN design, embedding a degradation-resistant unfolding network (DeRUN) within each stage of a segmentation-oriented unfolding network (SODUN). This design decouples restoration from segmentation while allowing mutual refinement. Guided by a vision-language model (VLM), DeRUN dynamically infers degradation semantics and restores high-quality images without explicit priors, whereas SODUN performs reversible estimation to refine foreground and background. Leveraging the multi-stage nature of unfolding, NUN employs image-quality assessment to select the best DeRUN outputs for subsequent stages, naturally introducing a self-consistency loss that enhances robustness. Extensive experiments show that NUN achieves a leading place on both clean and degraded benchmarks. Code will be released.

</details>


### [103] [EgoControl: Controllable Egocentric Video Generation via 3D Full-Body Poses](https://arxiv.org/abs/2511.18173)
*Enrico Pallotta,Sina Mokhtarzadeh Azar,Lars Doorenbos,Serdar Ozsoy,Umar Iqbal,Juergen Gall*

Main category: cs.CV

TL;DR: EgoControl是一个基于姿态控制的视频扩散模型，用于生成具有精细身体运动控制的自我中心视角视频。


<details>
  <summary>Details</summary>
Motivation: 实现通过身体姿态进行精细控制的自我中心视角视频生成，是构建能够模拟、预测和规划动作的具身AI代理的关键需求。

Method: 提出了一种新的姿态表示方法，捕捉全局相机动态和关节身体运动，并通过扩散过程中的专用控制机制进行集成。训练视频预测模型，将未来帧生成条件化为显式的3D身体姿态序列。

Result: EgoControl能够生成时间连贯且视觉逼真的未来帧，与提供的姿态控制对齐，实验结果表明其能产生高质量、姿态一致的自我中心视角视频。

Conclusion: EgoControl为可控的具身视频模拟和理解开辟了新途径。

Abstract: Egocentric video generation with fine-grained control through body motion is a key requirement towards embodied AI agents that can simulate, predict, and plan actions. In this work, we propose EgoControl, a pose-controllable video diffusion model trained on egocentric data. We train a video prediction model to condition future frame generation on explicit 3D body pose sequences. To achieve precise motion control, we introduce a novel pose representation that captures both global camera dynamics and articulated body movements, and integrate it through a dedicated control mechanism within the diffusion process. Given a short sequence of observed frames and a sequence of target poses, EgoControl generates temporally coherent and visually realistic future frames that align with the provided pose control. Experimental results demonstrate that EgoControl produces high-quality, pose-consistent egocentric videos, paving the way toward controllable embodied video simulation and understanding.

</details>


### [104] [Unified Spherical Frontend: Learning Rotation-Equivariant Representations of Spherical Images from Any Camera](https://arxiv.org/abs/2511.18174)
*Mukai Yu,Mosam Dabhi,Liuyue Xie,Sebastian Scherer,László A. Jeni*

Main category: cs.CV

TL;DR: USF是一个统一的球面前端框架，可将任何校准相机的图像转换为单位球面表示，直接在空间域进行球面重采样、卷积和池化操作，解决了传统平面CNN在宽视场图像处理中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现代感知系统越来越多地使用鱼眼、全景等宽视场相机，但现有管道仍使用为针孔图像设计的平面CNN，导致图像空间邻域无法正确表示物理邻接性，且模型对全局旋转敏感。

Method: USF通过光线方向对应关系将图像转换为单位球面表示，使用距离型球面核实现可配置的旋转等变性，避免昂贵的球面谐波变换，模块化设计分离投影、位置采样、插值和分辨率控制。

Result: USF能高效处理高分辨率球面图像，在随机测试时旋转下性能下降小于1%，无需旋转增强，并能实现从一种镜头类型到未见过的宽视场镜头的零样本泛化，性能下降最小。

Conclusion: USF提供了一个镜头无关的球面处理框架，在分类、检测和分割任务中表现出优异的旋转鲁棒性和泛化能力，为宽视场相机感知提供了有效的解决方案。

Abstract: Modern perception increasingly relies on fisheye, panoramic, and other wide field-of-view (FoV) cameras, yet most pipelines still apply planar CNNs designed for pinhole imagery on 2D grids, where image-space neighborhoods misrepresent physical adjacency and models are sensitive to global rotations. Frequency-domain spherical CNNs partially address this mismatch but require costly spherical harmonic transforms that constrain resolution and efficiency. We introduce the Unified Spherical Frontend (USF), a lens-agnostic framework that transforms images from any calibrated camera into a unit-sphere representation via ray-direction correspondences, and performs spherical resampling, convolution, and pooling directly in the spatial domain. USF is modular: projection, location sampling, interpolation, and resolution control are fully decoupled. Its distance-only spherical kernels offer configurable rotation-equivariance (mirroring translation-equivariance in planar CNNs) while avoiding harmonic transforms entirely. We compare standard planar backbones with their spherical counterparts across classification, detection, and segmentation tasks on synthetic (Spherical MNIST) and real-world datasets (PANDORA, Stanford 2D-3D-S), and stress-test robustness to extreme lens distortions, varying FoV, and arbitrary rotations. USF processes high-resolution spherical imagery efficiently and maintains less than 1% performance drop under random test-time rotations, even without rotational augmentation, and even enables zero-shot generalization from one lens type to unseen wide-FoV lenses with minimal performance degradation.

</details>


### [105] [Early Lung Cancer Diagnosis from Virtual Follow-up LDCT Generation via Correlational Autoencoder and Latent Flow Matching](https://arxiv.org/abs/2511.18185)
*Yutong Wu,Yifan Wang,Qining Zhang,Chuan Zhou,Lei Ying*

Main category: cs.CV

TL;DR: 本文提出了一种名为CorrFlowNet的生成方法，利用扩散模型为早期基线CT扫描生成虚拟的一年随访CT扫描，以早期检测恶性/良性结节，减少等待临床随访的需求。


<details>
  <summary>Details</summary>
Motivation: 肺癌早期诊断至关重要，但区分早期恶性信号和良性病变具有挑战性。患者通常需要多次随访检查才能确诊，可能错过最佳治疗时机。现有AI方法主要关注单次早期CT扫描的影像特征提取。

Method: 采用相关性自编码器将早期基线和随访CT图像编码到潜在空间，捕捉结节进展动态和相关性，然后在潜在空间上使用流匹配算法和神经常微分方程。辅助分类器用于提高诊断准确性。

Result: 在真实临床数据集上的评估表明，该方法能显著改善下游肺结节风险评估，诊断准确性与真实临床CT随访相当。

Conclusion: CorrFlowNet方法具有改善癌症诊断的潜力，可以减少对实际临床随访的依赖，实现早期肺癌检测。

Abstract: Lung cancer is one of the most commonly diagnosed cancers, and early diagnosis is critical because the survival rate declines sharply once the disease progresses to advanced stages. However, achieving an early diagnosis remains challenging, particularly in distinguishing subtle early signals of malignancy from those of benign conditions. In clinical practice, a patient with a high risk may need to undergo an initial baseline and several annual follow-up examinations (e.g., CT scans) before receiving a definitive diagnosis, which can result in missing the optimal treatment. Recently, Artificial Intelligence (AI) methods have been increasingly used for early diagnosis of lung cancer, but most existing algorithms focus on radiomic features extraction from single early-stage CT scans. Inspired by recent advances in diffusion models for image generation, this paper proposes a generative method, named CorrFlowNet, which creates a virtual, one-year follow-up CT scan after the initial baseline scan. This virtual follow-up would allow for an early detection of malignant/benign nodules, reducing the need to wait for clinical follow-ups. During training, our approach employs a correlational autoencoder to encode both early baseline and follow-up CT images into a latent space that captures the dynamics of nodule progression as well as the correlations between them, followed by a flow matching algorithm on the latent space with a neural ordinary differential equation. An auxiliary classifier is used to further enhance the diagnostic accuracy. Evaluations on a real clinical dataset show our method can significantly improve downstream lung nodule risk assessment compared with existing baseline models. Moreover, its diagnostic accuracy is comparable with real clinical CT follow-ups, highlighting its potential to improve cancer diagnosis.

</details>


### [106] [ARIAL: An Agentic Framework for Document VQA with Precise Answer Localization](https://arxiv.org/abs/2511.18192)
*Ahmad Mohammadshirazi,Pinaki Prasad Guha Neogi,Dheeraj Kulshrestha,Rajiv Ramnath*

Main category: cs.CV

TL;DR: ARIAL是一个模块化框架，通过LLM规划代理协调专门工具，在文档视觉问答中同时实现精确答案提取和可靠空间定位。


<details>
  <summary>Details</summary>
Motivation: 现有系统要么在文本准确性上表现强劲但空间定位不可靠，要么为了可解释性牺牲性能。需要同时实现高精度和可解释性的文档VQA系统。

Method: 将文档VQA分解为结构化子任务：使用TrOCR进行OCR文本提取、基于语义搜索的检索增强上下文选择、通过微调Gemma 3-27B模型生成答案、通过文本到区域对齐进行显式边界框定位。

Result: 在四个基准测试上达到最先进结果：DocVQA（88.7 ANLS和50.1 mAP）、FUNSD（90.0 ANLS和50.3 mAP）、CORD（85.5 ANLS和60.2 mAP）、SROIE（93.1 ANLS），在DocVQA上超越之前最佳方法2.8 ANLS和3.9 mAP。

Conclusion: 专业化工具的智能编排可以同时提高性能和可解释性，为可信赖、可解释的文档AI系统提供途径。

Abstract: Document Visual Question Answering (VQA) requires models to not only extract accurate textual answers but also precisely localize them within document images, a capability critical for interpretability in high-stakes applications. However, existing systems achieve strong textual accuracy while producing unreliable spatial grounding, or sacrifice performance for interpretability. We present ARIAL (Agentic Reasoning for Interpretable Answer Localization), a modular framework that orchestrates specialized tools through an LLM-based planning agent to achieve both precise answer extraction and reliable spatial grounding. ARIAL decomposes Document VQA into structured subtasks: OCR-based text extraction with TrOCR, retrieval-augmented context selection using semantic search, answer generation via a fine-tuned Gemma 3-27B model, and explicit bounding-box localization through text-to-region alignment. This modular architecture produces transparent reasoning traces, enabling tool-level auditability and independent component optimization. We evaluate ARIAL on four benchmarks (DocVQA, FUNSD, CORD, and SROIE) using both textual accuracy (ANLS) and spatial precision (mAP at IoU 0.50 to 0.95). ARIAL achieves state-of-the-art results across all datasets: 88.7 ANLS and 50.1 mAP on DocVQA, 90.0 ANLS and 50.3 mAP on FUNSD, 85.5 ANLS and 60.2 mAP on CORD, and 93.1 ANLS on SROIE, surpassing the previous best method (DLaVA) by +2.8 ANLS and +3.9 mAP on DocVQA. Our work demonstrates how agentic orchestration of specialized tools can simultaneously improve performance and interpretability, providing a pathway toward trustworthy, explainable document AI systems.

</details>


### [107] [InfiniBench: Infinite Benchmarking for Visual Spatial Reasoning with Customizable Scene Complexity](https://arxiv.org/abs/2511.18200)
*Haoming Wang,Qiyao Xue,Wei Gao*

Main category: cs.CV

TL;DR: InfiniBench是一个完全自动化的可定制基准测试生成器，能够合成理论上无限多样的3D场景，通过参数化控制场景复杂度，用于评估视觉语言模型的空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试在场景复杂度定制化方面有限，无法隔离和分析特定视觉语言模型在不同空间条件下的失败模式。需要更灵活、可扩展的评估工具。

Method: 1）基于LLM的代理框架迭代优化程序化场景约束；2）灵活的基于簇的布局优化器生成密集杂乱场景；3）任务感知的相机轨迹优化方法将场景渲染为视频。

Result: 实验表明InfiniBench在提示保真度和物理合理性方面优于最先进的程序化和基于LLM的3D生成方法，特别是在高复杂度场景中。

Conclusion: InfiniBench通过生成代表性空间推理任务的基准测试，展示了其在评估视觉语言模型空间推理能力方面的实用价值。

Abstract: Modern vision-language models (VLMs) are expected to have abilities of spatial reasoning with diverse scene complexities, but evaluating such abilities is difficult due to the lack of benchmarks that are not only diverse and scalable but also fully customizable. Existing benchmarks offer limited customizability over the scene complexity and are incapable of isolating and analyzing specific VLM failure modes under distinct spatial conditions. To address this gap, instead of individually presenting benchmarks for different scene complexities, in this paper we present InfiniBench, a fully automated, customizable and user-friendly benchmark generator that can synthesize a theoretically infinite variety of 3D scenes with parameterized control on scene complexity. InfiniBench uniquely translates scene descriptions in natural language into photo-realistic videos with complex and physically plausible 3D layouts. This is achieved through three key innovations: 1) a LLM-based agentic framework that iteratively refines procedural scene constraints from scene descriptions; 2) a flexible cluster-based layout optimizer that generates dense and cluttered scenes previously intractable for procedural methods; and 3) a task-aware camera trajectory optimization method that renders scenes into videos with full object coverage as VLM input. Experiments demonstrate that InfiniBench outperforms state-of-the-art procedural and LLM-based 3D generation methods in prompt fidelity and physical plausibility, especially in high-complexity scenarios. We further showcased the usefulness of InfiniBench, by generating benchmarks for representative spatial reasoning tasks including measurement, perspective-taking and spatiotemporal tracking.

</details>


### [108] [Generating Synthetic Human Blastocyst Images for In-Vitro Fertilization Blastocyst Grading](https://arxiv.org/abs/2511.18204)
*Pavan Narahari,Suraj Rajendran,Lorena Bori,Jonas E. Malmsten,Qiansheng Zhan,Zev Rosenwaks,Nikica Zaninovic,Iman Hajirasouliha*

Main category: cs.CV

TL;DR: DIA框架利用潜在扩散模型生成高质量、可控的囊胚图像，有效解决胚胎数据集稀缺和类别不平衡问题，显著提升AI胚胎评估工具的性能。


<details>
  <summary>Details</summary>
Motivation: 体外受精(IVF)中第5天囊胚的形态学评估存在主观性和不一致性，而AI模型训练需要大规模、多样化的数据集，但面临数据稀缺、类别不平衡和隐私限制等挑战。

Method: 开发DIA框架，使用潜在扩散模型生成高保真度的囊胚图像，通过Gardner形态分类和z轴焦距进行细粒度控制，并采用FID、记忆化指标、胚胎学家图灵测试和下游分类任务进行严格评估。

Result: DIA生成的图像与真实图像难以区分；在不平衡数据集中添加合成图像显著提高分类准确率(p<0.05)；在平衡数据集中添加合成图像也能带来显著性能提升；合成数据最多可替代40%的真实数据而不损失准确率。

Conclusion: DIA为胚胎数据集的数据稀缺和类别不平衡问题提供了稳健解决方案，通过生成新颖、高保真且可控的合成图像，能够提升AI胚胎评估工具的性能、公平性和标准化程度。

Abstract: The success of in vitro fertilization (IVF) at many clinics relies on the accurate morphological assessment of day 5 blastocysts, a process that is often subjective and inconsistent. While artificial intelligence can help standardize this evaluation, models require large, diverse, and balanced datasets, which are often unavailable due to data scarcity, natural class imbalance, and privacy constraints. Existing generative embryo models can mitigate these issues but face several limitations, such as poor image quality, small training datasets, non-robust evaluation, and lack of clinically relevant image generation for effective data augmentation. Here, we present the Diffusion Based Imaging Model for Artificial Blastocysts (DIA) framework, a set of latent diffusion models trained to generate high-fidelity, novel day 5 blastocyst images. Our models provide granular control by conditioning on Gardner-based morphological categories and z-axis focal depth. We rigorously evaluated the models using FID, a memorization metric, an embryologist Turing test, and three downstream classification tasks. Our results show that DIA models generate realistic images that embryologists could not reliably distinguish from real images. Most importantly, we demonstrated clear clinical value. Augmenting an imbalanced dataset with synthetic images significantly improved classification accuracy (p < 0.05). Also, adding synthetic images to an already large, balanced dataset yielded statistically significant performance gains, and synthetic data could replace up to 40% of real data in some cases without a statistically significant loss in accuracy. DIA provides a robust solution for mitigating data scarcity and class imbalance in embryo datasets. By generating novel, high-fidelity, and controllable synthetic images, our models can improve the performance, fairness, and standardization of AI embryo assessment tools.

</details>


### [109] [Large-Scale Pre-training Enables Multimodal AI Differentiation of Radiation Necrosis from Brain Metastasis Progression on Routine MRI](https://arxiv.org/abs/2511.18208)
*Ahmed Gomaa,Annette Schwarz,Ludwig Singer,Arnd Dörfler,Matthias Stefan May,Pluvio Stephan,Ishita Sheth,Juliane Szkitsak,Katharina Breininger,Yixing Huang,Benjamin Frey,Oliver Schnell,Daniel Delev,Roland Coras,Daniel Höfler,Philipp Schubert,Jenny Stritzelberger,Sabine Semrau,Andreas Maier,Dieter H Heiland,Udo S. Gaipl,Andrea Wittig,Rainer Fietkau,Christoph Bert,Stefanie Corradini,Florian Putz*

Main category: cs.CV

TL;DR: 本文提出了一种基于自监督学习的两阶段深度学习策略，用于区分脑转移瘤放疗后的放射性坏死和肿瘤进展。该方法在大型无标签MRI数据集上预训练，然后在活检确认的小数据集上微调，显著超越了传统监督学习和放射组学方法。


<details>
  <summary>Details</summary>
Motivation: 区分放射性坏死和肿瘤进展是脑转移瘤治疗后的关键挑战。传统监督学习受限于活检确认数据的稀缺性，而自监督学习可以利用日益增长的无标签脑转移瘤影像数据集来克服这一限制。

Method: 采用两阶段深度学习策略：首先在10,167个无标签多源T1CE MRI子体积上通过自监督学习预训练Vision Transformer，然后在MOLAB数据集（n=109）上使用双通道输入（T1CE MRI和分割掩码）进行微调，并进行内部和外部验证。

Result: 自监督模型在相同中心测试集上AUC达0.916，在第二中心测试集上AUC达0.764，显著优于全监督ViT（AUC 0.624/0.496）和放射组学方法（AUC 0.807/0.691）。多模态集成进一步提升了性能（AUC 0.947/0.821）。

Conclusion: 大规模无标签数据预训练显著提升AI模型性能。两阶段多模态深度学习策略仅使用常规T1CE MRI和标准临床数据即可高精度区分放射性坏死和肿瘤进展，提供了可解释且临床可及的解决方案，值得进一步验证。

Abstract: Background: Differentiating radiation necrosis (RN) from tumor progression after stereotactic radiosurgery (SRS) remains a critical challenge in brain metastases. While histopathology represents the gold standard, its invasiveness limits feasibility. Conventional supervised deep learning approaches are constrained by scarce biopsy-confirmed training data. Self-supervised learning (SSL) overcomes this by leveraging the growing availability of large-scale unlabeled brain metastases imaging datasets. Methods: In a two-phase deep learning strategy inspired by the foundation model paradigm, a Vision Transformer (ViT) was pre-trained via SSL on 10,167 unlabeled multi-source T1CE MRI sub-volumes. The pre-trained ViT was then fine-tuned for RN classification using a two-channel input (T1CE MRI and segmentation masks) on the public MOLAB dataset (n=109) using 20% of datasets as same-center held-out test set. External validation was performed on a second-center test cohort (n=28). Results: The self-supervised model achieved an AUC of 0.916 on the same-center test set and 0.764 on the second center test set, surpassing the fully supervised ViT (AUC 0.624/0.496; p=0.001/0.008) and radiomics (AUC 0.807/0.691; p=0.005/0.014). Multimodal integration further improved performance (AUC 0.947/0.821; p=0.073/0.001). Attention map visualizations enabled interpretability showing the model focused on clinically relevant lesion subregions. Conclusion: Large-scale pre-training on increasingly available unlabeled brain metastases datasets substantially improves AI model performance. A two-phase multimodal deep learning strategy achieved high accuracy in differentiating radiation necrosis from tumor progression using only routine T1CE MRI and standard clinical data, providing an interpretable, clinically accessible solution that warrants further validation.

</details>


### [110] [Using MLIR Transform to Design Sliced Convolution Algorithm](https://arxiv.org/abs/2511.18222)
*Victor Ferrari,Marcio Pereira,Lucas Alvarenga,Gustavo Leite,Guido Araujo*

Main category: cs.CV

TL;DR: SConvTransform是MLIR中用于优化2D卷积的Transform方言扩展，通过声明式转换管道将Linalg卷积降级为分块打包的通用操作，在ARM SME和Intel AVX512上分别达到60%和67%的峰值性能。


<details>
  <summary>Details</summary>
Motivation: 为了在MLIR编译框架中提供可重用、可分析的卷积优化转换，结合静态形状分析与结构化分块打包策略来提升卷积计算性能。

Method: 使用SConvOp操作，通过卷积切片分析确定分块大小和数据布局策略，基于参数化仿射方程进行打包和分块操作，处理边缘情况并调整仿射映射。

Result: 在标准卷积配置下，生成的代码在ARM SME上达到60%峰值性能，在Intel AVX512上达到67%峰值性能，验证了该方法在异构架构上的有效性。

Conclusion: SConvTransform证明了在MLIR Transform方言中结合静态形状分析与结构化策略的益处，其模块化设计便于未来扩展，为卷积工作负载的持续优化提供了基础。

Abstract: This paper proposes SConvTransform, a Transform dialect extension that provides operations for optimizing 2D convolutions in MLIR. Its main operation, SConvOp, lowers Linalg convolutions into tiled and packed generic operations through a fully declarative transformation pipeline. The process is guided by a Convolution Slicing Analysis that determines tile sizes and data layout strategies based on input and filter shapes, as well as target architecture parameters. SConvOp handles edge cases by splitting irregular regions and adjusting affine maps where needed. All packing and tiling operations are derived from a parametric set of affine equations, enabling reusable and analyzable transformations. Although functional correctness was the primary goal of this work, the experimental evaluation demonstrates the effectiveness of SConvTransform, achieving good enough performance across different target architectures. Future work will focus on optimizing performance and porting to other target devices. When applied to standard convolution configurations, the generated code achieves up to 60% of peak performance on ARM SME and 67% on Intel AVX512. These results validate the benefit of combining static shape analysis with structured tiling and packing strategies within the MLIR Transform dialect. Furthermore, the modular design of SConvTransform facilitates integration with future extensions, enabling continued optimization of convolution workloads through MLIR's extensible compilation infrastructure.

</details>


### [111] [Parallel qMRI Reconstruction from 4x Accelerated Acquisitions](https://arxiv.org/abs/2511.18232)
*Mingi Kang*

Main category: cs.CV

TL;DR: 提出了一种端到端深度学习框架，联合估计线圈灵敏度图并从4倍加速的欠采样k空间数据重建MRI图像，无需预计算线圈灵敏度图。


<details>
  <summary>Details</summary>
Motivation: 传统并行MRI技术如SENSE需要预计算线圈灵敏度图，限制了临床应用。深度学习可以端到端地从欠采样数据直接重建高质量图像。

Method: 采用两模块架构：线圈灵敏度图估计模块和基于U-Net的MRI重建模块，直接从4倍加速的欠采样k空间测量值进行联合估计和重建。

Result: 在10名受试者的多线圈脑部MRI数据上评估，与2倍SENSE重建相比，虽然PSNR/SSIM指标较低，但视觉上更平滑。

Conclusion: 该方法能够从欠采样数据直接重建MRI图像，但存在不同加速因子间的空间错位问题，需要进一步改进重建质量。

Abstract: Magnetic Resonance Imaging (MRI) acquisitions require extensive scan times, limiting patient throughput and increasing susceptibility to motion artifacts. Accelerated parallel MRI techniques reduce acquisition time by undersampling k-space data, but require robust reconstruction methods to recover high-quality images. Traditional approaches like SENSE require both undersampled k-space data and pre-computed coil sensitivity maps. We propose an end-to-end deep learning framework that jointly estimates coil sensitivity maps and reconstructs images from only undersampled k-space measurements at 4x acceleration. Our two-module architecture consists of a Coil Sensitivity Map (CSM) estimation module and a U-Net-based MRI reconstruction module. We evaluate our method on multi-coil brain MRI data from 10 subjects with 8 echoes each, using 2x SENSE reconstructions as ground truth. Our approach produces visually smoother reconstructions compared to conventional SENSE output, achieving comparable visual quality despite lower PSNR/SSIM metrics. We identify key challenges including spatial misalignment between different acceleration factors and propose future directions for improved reconstruction quality.

</details>


### [112] [EgoVITA: Learning to Plan and Verify for Egocentric Video Reasoning](https://arxiv.org/abs/2511.18242)
*Yogesh Kulkarni,Pooyan Fazli*

Main category: cs.CV

TL;DR: EgoVITA是一个强化学习框架，通过结合第一人称规划和第三人称验证，解决MLLMs在自我中心视角下的推理挑战。


<details>
  <summary>Details</summary>
Motivation: 解决多模态大语言模型在自我中心视角视频中推理的困难，包括部分可观测性、有限视野和自参考运动等问题。

Method: 基于GRPO强化学习框架，交替进行自我中心规划阶段（从第一人称视角预测未来行动步骤）和第三人称验证阶段（检查计划的视觉和逻辑一致性）。

Result: 在EgoBlind任务上比基线Qwen2.5-VL-7B提升7.7分，在EgoOrient任务上提升4.4分，同时在第三人称视频任务上保持良好泛化能力。

Conclusion: EgoVITA通过结构化规划和验证机制，显著提升了MLLMs在自我中心视角下的推理能力，实现了更连贯和视觉基础化的推理。

Abstract: Reasoning about intentions and actions from a first-person (egocentric) perspective remains a fundamental challenge for multimodal large language models (MLLMs). Unlike third-person (exocentric) videos that capture scenes from an outside observer, egocentric videos reflect the actor's continuously changing viewpoint, introducing partial observability, limited field of view, and self-referenced motion. We introduce $\textbf{EgoVITA}$, a reinforcement learning framework that enables MLLMs to reason through structured planning and verification. Built on Group Relative Policy Optimization (GRPO), EgoVITA alternates between two stages: (1) an $\textbf{egocentric planning phase}$, where the model reasons from a first-person viewpoint to predict a step-by-step plan of future actions, and (2) an $\textbf{exocentric verification phase}$, where it switches to a third-person perspective to check the visual and logical consistency of that plan. Through GRPO, the model learns to make plans that are causally predictive of upcoming visual observations, leading to more coherent and visually grounded reasoning. EgoVITA achieves significant gains on egocentric reasoning tasks, outperforming the baseline Qwen2.5-VL-7B by $\mathbf{+7.7}$ on EgoBlind and $\mathbf{+4.4}$ on EgoOrient, while maintaining strong generalization on exocentric video tasks.

</details>


### [113] [UniFlow: Towards Zero-Shot LiDAR Scene Flow for Autonomous Vehicles via Cross-Domain Generalization](https://arxiv.org/abs/2511.18254)
*Siyi Li,Qingwen Zhang,Ishan Khatri,Kyle Vedder,Deva Ramanan,Neehar Peri*

Main category: cs.CV

TL;DR: 本文提出UniFlow方法，通过跨数据集训练学习通用运动先验，在LiDAR场景流估计任务中实现了跨传感器的优异性能。


<details>
  <summary>Details</summary>
Motivation: 现有LiDAR场景流方法通常只在单一传感器上训练和评估，缺乏对多样化传感器的泛化能力。本文旨在学习能够迁移到不同LiDAR传感器的通用运动先验。

Method: 提出UniFlow方法，这是一个前馈模型家族，统一训练多个大规模LiDAR场景流数据集，包含不同的传感器配置和点云密度。

Result: 在Waymo和nuScenes数据集上分别比之前最佳方法提升5.1%和35.2%，在未见过的TruckScenes数据集上比专门的TruckScenes模型提升30.1%。

Conclusion: 运动估计等低级任务对传感器配置的敏感性较低，跨数据集训练能够显著提升LiDAR场景流估计的性能和泛化能力。

Abstract: LiDAR scene flow is the task of estimating per-point 3D motion between consecutive point clouds. Recent methods achieve centimeter-level accuracy on popular autonomous vehicle (AV) datasets, but are typically only trained and evaluated on a single sensor. In this paper, we aim to learn general motion priors that transfer to diverse and unseen LiDAR sensors. However, prior work in LiDAR semantic segmentation and 3D object detection demonstrate that naively training on multiple datasets yields worse performance than single dataset models. Interestingly, we find that this conventional wisdom does not hold for motion estimation, and that state-of-the-art scene flow methods greatly benefit from cross-dataset training. We posit that low-level tasks such as motion estimation may be less sensitive to sensor configuration; indeed, our analysis shows that models trained on fast-moving objects (e.g., from highway datasets) perform well on fast-moving objects, even across different datasets. Informed by our analysis, we propose UniFlow, a family of feedforward models that unifies and trains on multiple large-scale LiDAR scene flow datasets with diverse sensor placements and point cloud densities. Our frustratingly simple solution establishes a new state-of-the-art on Waymo and nuScenes, improving over prior work by 5.1% and 35.2% respectively. Moreover, UniFlow achieves state-of-the-art accuracy on unseen datasets like TruckScenes, outperforming prior TruckScenes-specific models by 30.1%.

</details>


### [114] [Sequence-Adaptive Video Prediction in Continuous Streams using Diffusion Noise Optimization](https://arxiv.org/abs/2511.18255)
*Sina Mokhtarzadeh Azar,Emad Bahrami,Enrico Pallotta,Gianpiero Francesca,Radu Timofte,Juergen Gall*

Main category: cs.CV

TL;DR: 本文提出了一种针对连续视频流的扩散模型自适应优化方法SAVi-DNO，通过优化扩散噪声而非模型参数，实现了在推理过程中对视频流的持续适应，在多个数据集上取得了更好的预测性能。


<details>
  <summary>Details</summary>
Motivation: 在连续视频流预测场景中，模型会不断观察到新的训练样本，但直接微调大型扩散模型的参数成本过高。因此需要一种高效的方法来利用这些连续数据改进预测质量。

Method: 提出SAVi-DNO方法，在推理过程中保持预训练扩散模型参数不变，通过优化扩散噪声来实现对视频流的自适应。这种方法允许模型根据当前视频流动态确定合适的采样噪声。

Result: 在Ego4D、OpenDV-YouTube、UCF-101和SkyTimelapse等数据集上的实验表明，SAVi-DNO在FVD、SSIM和PSNR指标上均优于基线方法，特别是在长连续视频上表现更佳。

Conclusion: SAVi-DNO提供了一种高效且有效的连续视频预测自适应方法，通过噪声优化而非参数微调，在保持计算效率的同时显著提升了预测性能。

Abstract: In this work, we investigate diffusion-based video prediction models, which forecast future video frames, for continuous video streams. In this context, the models observe continuously new training samples, and we aim to leverage this to improve their predictions. We thus propose an approach that continuously adapts a pre-trained diffusion model to a video stream. Since fine-tuning the parameters of a large diffusion model is too expensive, we refine the diffusion noise during inference while keeping the model parameters frozen, allowing the model to adaptively determine suitable sampling noise. We term the approach Sequence Adaptive Video Prediction with Diffusion Noise Optimization (SAVi-DNO). To validate our approach, we introduce a new evaluation setting on the Ego4D dataset, focusing on simultaneous adaptation and evaluation on long continuous videos. Empirical results demonstrate improved performance based on FVD, SSIM, and PSNR metrics on long videos of Ego4D and OpenDV-YouTube, as well as videos of UCF-101 and SkyTimelapse, showcasing SAVi-DNO's effectiveness.

</details>


### [115] [MammothModa2: A Unified AR-Diffusion Framework for Multimodal Understanding and Generation](https://arxiv.org/abs/2511.18262)
*Tao Shen,Xin Wan,Taicai Chen,Rui Zhang,Junwen Pan,Dawei Lu,Fanding Lei,Zhilin Lu,Yunfei Yang,Chen Cheng,Qi She,Chang Liu,Zhenbang Sun*

Main category: cs.CV

TL;DR: Mammoth2是一个统一的AR-Diffusion框架，通过自回归语义规划和扩散生成相结合，实现了高质量的多模态生成和编辑，同时在多模态理解任务上保持竞争力。


<details>
  <summary>Details</summary>
Motivation: 当前统一多模态模型在离散语义推理和高保真视觉合成之间存在差距，需要一种能够有效结合理解和生成的框架。

Method: 采用串行设计：AR路径进行全局语义建模，DiT解码器处理图像合成；通过AR-Diffusion特征对齐模块稳定对齐表示；使用联合训练目标（Next-Token Prediction和Flow Matching）进行端到端训练。

Result: 在公开基准测试中表现出色：GenEval得分0.87，DPGBench得分87.2，ImgEdit得分4.06；在仅使用6000万监督生成样本且不依赖预训练生成器的情况下，性能与纯理解模型相当。

Conclusion: 精心设计的AR-Diffusion架构可以在单一参数和数据高效的模型中实现高保真生成和编辑，同时保持强大的多模态理解能力。

Abstract: Unified multimodal models aim to integrate understanding and generation within a single framework, yet bridging the gap between discrete semantic reasoning and high-fidelity visual synthesis remains challenging. We present MammothModa2 (Mammoth2), a unified autoregressive-diffusion (AR-Diffusion) framework designed to effectively couple autoregressive semantic planning with diffusion-based generation. Mammoth2 adopts a serial design: an AR path equipped with generation experts performs global semantic modeling over discrete tokens, while a single-stream Diffusion Transformer (DiT) decoder handles high-fidelity image synthesis. A carefully designed AR-Diffusion feature alignment module combines multi-layer feature aggregation, unified condition encoding, and in-context conditioning to stably align AR's representations with the diffusion decoder's continuous latents. Mammoth2 is trained end-to-end with joint Next-Token Prediction and Flow Matching objectives, followed by supervised fine-tuning and reinforcement learning over both generation and editing. With roughly 60M supervised generation samples and no reliance on pre-trained generators, Mammoth2 delivers strong text-to-image and instruction-based editing performance on public benchmarks, achieving 0.87 on GenEval, 87.2 on DPGBench, and 4.06 on ImgEdit, while remaining competitive with understanding-only backbones (e.g., Qwen3-VL-8B) on multimodal understanding tasks. These results suggest that a carefully coupled AR-Diffusion architecture can provide high-fidelity generation and editing while maintaining strong multimodal comprehension within a single, parameter- and data-efficient model.

</details>


### [116] [SatSAM2: Motion-Constrained Video Object Tracking in Satellite Imagery using Promptable SAM2 and Kalman Priors](https://arxiv.org/abs/2511.18264)
*Ruijie Fan,Junyan Ye,Huan Chen,Zilong Huang,Xiaolei Wang,Weijia Li*

Main category: cs.CV

TL;DR: SatSAM2是一个基于SAM2的零样本卫星视频跟踪器，通过引入卡尔曼滤波约束运动模块和运动约束状态机来提升跟踪性能，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有卫星视频跟踪方法泛化能力差、需要场景特定训练以及在遮挡情况下容易丢失跟踪的问题。

Method: 基于SAM2构建零样本跟踪器，引入KFCMM模块利用时间运动线索抑制漂移，以及MCSM模块根据运动动态和可靠性调节跟踪状态。

Result: 在两个卫星跟踪基准和MVOT数据集上的实验表明，SatSAM2优于传统和基于基础模型的跟踪器，在OOTB数据集上AUC提升5.84%。

Conclusion: SatSAM2有效提升了卫星视频跟踪的性能和泛化能力，代码和数据集将公开以促进进一步研究。

Abstract: Existing satellite video tracking methods often struggle with generalization, requiring scenario-specific training to achieve satisfactory performance, and are prone to track loss in the presence of occlusion. To address these challenges, we propose SatSAM2, a zero-shot satellite video tracker built on SAM2, designed to adapt foundation models to the remote sensing domain. SatSAM2 introduces two core modules: a Kalman Filter-based Constrained Motion Module (KFCMM) to exploit temporal motion cues and suppress drift, and a Motion-Constrained State Machine (MCSM) to regulate tracking states based on motion dynamics and reliability. To support large-scale evaluation, we propose MatrixCity Video Object Tracking (MVOT), a synthetic benchmark containing 1,500+ sequences and 157K annotated frames with diverse viewpoints, illumination, and occlusion conditions. Extensive experiments on two satellite tracking benchmarks and MVOT show that SatSAM2 outperforms both traditional and foundation model-based trackers, including SAM2 and its variants. Notably, on the OOTB dataset, SatSAM2 achieves a 5.84% AUC improvement over state-of-the-art methods. Our code and dataset will be publicly released to encourage further research.

</details>


### [117] [Beyond Words and Pixels: A Benchmark for Implicit World Knowledge Reasoning in Generative Models](https://arxiv.org/abs/2511.18271)
*Tianyang Han,Junhao Su,Junjie Hu,Peizhen Yang,Hengyu Shi,Junfeng Luo,Jialin Gao*

Main category: cs.CV

TL;DR: PicWorld是首个全面评估文本到图像模型对隐式世界知识和物理因果推理能力的基准测试，包含1100个提示词，并通过多智能体评估器PW-Agent进行细粒度评估。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法主要关注组合对齐或单轮VQA评分，忽视了知识基础、多物理交互和可审计证据等关键维度，导致对T2I模型隐式世界知识掌握能力的评估不足。

Method: 提出PicWorld基准测试，包含三个核心类别的1100个提示词，并开发PW-Agent多智能体评估器，通过将提示分解为可验证的视觉证据来分层评估图像的物理真实性和逻辑一致性。

Result: 对17个主流T2I模型的测试表明，它们在隐式世界知识和物理因果推理能力方面普遍存在不同程度的根本性局限。

Conclusion: 研究结果强调了未来T2I系统需要采用具备推理意识和知识整合能力的架构。

Abstract: Text-to-image (T2I) models today are capable of producing photorealistic, instruction-following images, yet they still frequently fail on prompts that require implicit world knowledge. Existing evaluation protocols either emphasize compositional alignment or rely on single-round VQA-based scoring, leaving critical dimensions such as knowledge grounding, multi-physics interactions, and auditable evidence-substantially undertested. To address these limitations, we introduce PicWorld, the first comprehensive benchmark that assesses the grasp of implicit world knowledge and physical causal reasoning of T2I models. This benchmark consists of 1,100 prompts across three core categories. To facilitate fine-grained evaluation, we propose PW-Agent, an evidence-grounded multi-agent evaluator to hierarchically assess images on their physical realism and logical consistency by decomposing prompts into verifiable visual evidence. We conduct a thorough analysis of 17 mainstream T2I models on PicWorld, illustrating that they universally exhibit a fundamental limitation in their capacity for implicit world knowledge and physical causal reasoning to varying degrees. The findings highlight the need for reasoning-aware, knowledge-integrative architectures in future T2I systems.

</details>


### [118] [Vision Token Masking Alone Cannot Prevent PHI Leakage in Medical Document OCR: A Systematic Evaluation](https://arxiv.org/abs/2511.18272)
*Richard J. Young*

Main category: cs.CV

TL;DR: 本研究首次系统评估了在医疗文档OCR中使用视觉令牌掩码作为隐私保护机制的效果，发现所有掩码策略对PHI的减少率都收敛于42.9%，能有效抑制长格式标识符但无法阻止短结构化标识符泄露。


<details>
  <summary>Details</summary>
Motivation: 随着大型视觉语言模型在医疗OCR中的部署，保护受保护健康信息(PHI)免受泄露成为关键问题，需要评估视觉层面的隐私保护机制有效性。

Method: 使用DeepSeek-OCR模型，引入7种针对不同架构层的视觉令牌掩码策略(V3-V9)，在100份合成医疗账单文档上评估PHI减少效果，并进行掩码扩展半径的消融研究。

Result: 所有掩码策略对PHI的减少率均为42.9%，能100%有效抑制长格式空间分布标识符(患者姓名、出生日期等)，但对短结构化标识符(医疗记录号、社保号等)完全无效。增加空间覆盖范围无法突破此上限。

Conclusion: 视觉层面的隐私干预存在局限性，语言模型的上下文推理是结构化标识符泄露的主要原因。未来研究应转向解码器级微调和混合防御架构，实现HIPAA合规的医疗文档处理。

Abstract: Large vision-language models (VLMs) are increasingly deployed for optical character recognition (OCR) in healthcare settings, raising critical concerns about protected health information (PHI) exposure during document processing. This work presents the first systematic evaluation of inference-time vision token masking as a privacy-preserving mechanism for medical document OCR using DeepSeek-OCR. We introduce seven masking strategies (V3-V9) targeting different architectural layers (SAM encoder blocks, compression layers, dual vision encoders, projector fusion) and evaluate PHI reduction across HIPAA-defined categories using 100 synthetic medical billing statements (drawn from a corpus of 38,517 annotated documents) with perfect ground-truth annotations. All masking strategies converge to 42.9% PHI reduction, successfully suppressing long-form spatially-distributed identifiers (patient names, dates of birth, physical addresses at 100% effectiveness) while failing to prevent short structured identifiers (medical record numbers, social security numbers, email addresses, account numbers at 0% effectiveness). Ablation studies varying mask expansion radius (r=1,2,3) demonstrate that increased spatial coverage does not improve reduction beyond this ceiling, indicating that language model contextual inference - not insufficient visual masking - drives structured identifier leakage. A simulated hybrid architecture combining vision masking with NLP post-processing achieves 88.6% total PHI reduction (assuming 80% NLP accuracy on remaining identifiers). This negative result establishes boundaries for vision-only privacy interventions in VLMs, provides guidance distinguishing PHI types amenable to vision-level versus language-level redaction, and redirects future research toward decoder-level fine-tuning and hybrid defense-in-depth architectures for HIPAA-compliant medical document processing.

</details>


### [119] [Point-to-Point: Sparse Motion Guidance for Controllable Video Editing](https://arxiv.org/abs/2511.18277)
*Yeji Song,Jaehyun Lee,Mijin Koo,JunHoo Lee,Nojun Kwak*

Main category: cs.CV

TL;DR: 提出一种名为锚点令牌（anchor tokens）的新型运动表示方法，通过少量信息丰富的点轨迹紧凑编码视频动态，实现更可控和语义对齐的视频编辑。


<details>
  <summary>Details</summary>
Motivation: 现有视频编辑方法在编辑保真度和运动保真度之间存在权衡，因为它们依赖的运动表示要么过度拟合布局，要么只是隐式定义。

Method: 提出Point-to-Point方法，利用锚点令牌作为运动表示，通过视频扩散模型的丰富先验捕捉最本质的运动模式，并可以灵活重新定位以对齐新主题。

Result: 大量实验表明，锚点令牌能够实现更可控和语义对齐的视频编辑，在编辑保真度和运动保真度方面均取得优越性能。

Conclusion: 锚点令牌作为一种紧凑的运动表示方法，能够克服现有方法的局限性，在各种视频场景中实现高质量的编辑效果。

Abstract: Accurately preserving motion while editing a subject remains a core challenge in video editing tasks. Existing methods often face a trade-off between edit and motion fidelity, as they rely on motion representations that are either overfitted to the layout or only implicitly defined. To overcome this limitation, we revisit point-based motion representation. However, identifying meaningful points remains challenging without human input, especially across diverse video scenarios. To address this, we propose a novel motion representation, anchor tokens, that capture the most essential motion patterns by leveraging the rich prior of a video diffusion model. Anchor tokens encode video dynamics compactly through a small number of informative point trajectories and can be flexibly relocated to align with new subjects. This allows our method, Point-to-Point, to generalize across diverse scenarios. Extensive experiments demonstrate that anchor tokens lead to more controllable and semantically aligned video edits, achieving superior performance in terms of edit and motion fidelity.

</details>


### [120] [Uni-DAD: Unified Distillation and Adaptation of Diffusion Models for Few-step Few-shot Image Generation](https://arxiv.org/abs/2511.18281)
*Yara Bahram,Melodie Desbos,Mohammadhadi Shateri,Eric Granger*

Main category: cs.CV

TL;DR: Uni-DAD是一种单阶段训练方法，将扩散模型的蒸馏和适应统一起来，在保持高质量的同时实现快速采样（少于4步），超越了现有的两阶段训练方法。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型在新领域的快速高质量生成需要复杂的两阶段训练（先适应后蒸馏或先蒸馏后适应），这增加了设计复杂性并导致质量或多样性下降。

Method: Uni-DAD采用单阶段训练，结合两个信号：1）双域分布匹配蒸馏目标，引导学生模型同时学习源域教师和目标域教师的分布；2）多头生成对抗网络损失，在多个特征尺度上鼓励目标域的真实性。

Result: 在少样本图像生成和主题驱动个性化任务上，Uni-DAD在少于4步采样时就能达到比现有最先进适应方法更高的质量，并在质量和多样性上都优于两阶段训练管道。

Conclusion: Uni-DAD提供了一种高效的单阶段解决方案，能够在保持扩散模型高质量的同时实现快速采样，特别适用于结构差异较大的领域适应任务。

Abstract: Diffusion models (DMs) produce high-quality images, yet their sampling remains costly when adapted to new domains. Distilled DMs are faster but typically remain confined within their teacher's domain. Thus, fast and high-quality generation for novel domains relies on two-stage training pipelines: Adapt-then-Distill or Distill-then-Adapt. However, both add design complexity and suffer from degraded quality or diversity. We introduce Uni-DAD, a single-stage pipeline that unifies distillation and adaptation of DMs. It couples two signals during training: (i) a dual-domain distribution-matching distillation objective that guides the student toward the distributions of the source teacher and a target teacher, and (ii) a multi-head generative adversarial network (GAN) loss that encourages target realism across multiple feature scales. The source domain distillation preserves diverse source knowledge, while the multi-head GAN stabilizes training and reduces overfitting, especially in few-shot regimes. The inclusion of a target teacher facilitates adaptation to more structurally distant domains. We perform evaluations on a variety of datasets for few-shot image generation (FSIG) and subject-driven personalization (SDP). Uni-DAD delivers higher quality than state-of-the-art (SoTA) adaptation methods even with less than 4 sampling steps, and outperforms two-stage training pipelines in both quality and diversity.

</details>


### [121] [RoadSceneVQA: Benchmarking Visual Question Answering in Roadside Perception Systems for Intelligent Transportation System](https://arxiv.org/abs/2511.18286)
*Runwei Guan,Rongsheng Hu,Shangshu Chen,Ningyuan Xiao,Xue Xia,Jiayang Liu,Beibei Chen,Ziren Tang,Ningwei Ouyang,Shaofeng Liang,Yuxuan Fan,Wanjie Sun,Yutao Yue*

Main category: cs.CV

TL;DR: RoadSceneVQA是一个专为路边场景设计的大规模视觉问答数据集，包含34,736个多样化QA对，旨在通过自然语言交互和推理交通行为。研究提出了CogniAnchor Fusion融合模块和AD-CoT推理增强方法，构建了RoadMind基线模型，在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前路边感知系统主要关注实例级感知，缺乏自然语言交互和交通行为推理能力。为弥补这一差距，需要开发能够理解交通参与者意图、合法性和交互模式的智能系统。

Method: 1) 构建RoadSceneVQA数据集；2) 提出CogniAnchor Fusion视觉语言融合模块，模拟人类场景锚定机制；3) 提出Assisted Decoupled Chain-of-Thought增强推理能力；4) 构建RoadMind基线模型。

Result: 在RoadSceneVQA和CODA-LM基准测试中，提出的方法在推理准确性和计算效率方面均得到提升，MLLM在结构化交通感知和推理任务中达到SOTA性能。

Conclusion: RoadSceneVQA数据集和相关方法有效提升了路边场景的语义理解和推理能力，为智能交通系统的自然语言交互和复杂行为推理提供了重要基础。

Abstract: Current roadside perception systems mainly focus on instance-level perception, which fall short in enabling interaction via natural language and reasoning about traffic behaviors in context. To bridge this gap, we introduce RoadSceneVQA, a large-scale and richly annotated visual question answering (VQA) dataset specifically tailored for roadside scenarios. The dataset comprises 34,736 diverse QA pairs collected under varying weather, illumination, and traffic conditions, targeting not only object attributes but also the intent, legality, and interaction patterns of traffic participants. RoadSceneVQA challenges models to perform both explicit recognition and implicit commonsense reasoning, grounded in real-world traffic rules and contextual dependencies. To fully exploit the reasoning potential of Multi-modal Large Language Models (MLLMs), we further propose CogniAnchor Fusion (CAF), a vision-language fusion module inspired by human-like scene anchoring mechanisms. Moreover, we propose the Assisted Decoupled Chain-of-Thought (AD-CoT) to enhance the reasoned thinking via CoT prompting and multi-task learning. Based on the above, we propose the baseline model RoadMind. Experiments on RoadSceneVQA and CODA-LM benchmark show that the pipeline consistently improves both reasoning accuracy and computational efficiency, allowing the MLLM to achieve state-of-the-art performance in structural traffic perception and reasoning tasks.

</details>


### [122] [SwiftVGGT: A Scalable Visual Geometry Grounded Transformer for Large-Scale Scenes](https://arxiv.org/abs/2511.18290)
*Jungho Lee,Minhyeok Lee,Sunghun Yang,Minseok Kang,Sangyoun Lee*

Main category: cs.CV

TL;DR: SwiftVGGT是一种无需训练的方法，在大规模3D重建中显著减少推理时间，同时保持高质量重建效果，通过消除外部VPR模型依赖和简化点采样对齐过程实现高效重建。


<details>
  <summary>Details</summary>
Motivation: 大规模3D重建面临精度与计算效率的权衡挑战，现有方法要么速度快但质量低，要么质量高但推理慢，需要一种既能保持高质量又能大幅提升效率的解决方案。

Method: 提出SwiftVGGT方法：1）无需外部VPR模型实现闭环检测，减少冗余计算；2）使用基于Sim(3)的SVD单步对齐相邻块，替代传统的IRLS优化方法。

Result: 在多个数据集上评估显示，SwiftVGGT达到最先进的重建质量，同时推理时间仅为现有VGGT方法的33%，能够在千米级环境中实现准确重建。

Conclusion: SwiftVGGT通过创新的闭环检测和简化对齐方法，成功解决了大规模3D重建中精度与效率的权衡问题，为实际应用提供了高效可行的解决方案。

Abstract: 3D reconstruction in large-scale scenes is a fundamental task in 3D perception, but the inherent trade-off between accuracy and computational efficiency remains a significant challenge. Existing methods either prioritize speed and produce low-quality results, or achieve high-quality reconstruction at the cost of slow inference times. In this paper, we propose SwiftVGGT, a training-free method that significantly reduce inference time while preserving high-quality dense 3D reconstruction. To maintain global consistency in large-scale scenes, SwiftVGGT performs loop closure without relying on the external Visual Place Recognition (VPR) model. This removes redundant computation and enables accurate reconstruction over kilometer-scale environments. Furthermore, we propose a simple yet effective point sampling method to align neighboring chunks using a single Sim(3)-based Singular Value Decomposition (SVD) step. This eliminates the need for the Iteratively Reweighted Least Squares (IRLS) optimization commonly used in prior work, leading to substantial speed-ups. We evaluate SwiftVGGT on multiple datasets and show that it achieves state-of-the-art reconstruction quality while requiring only 33% of the inference time of recent VGGT-based large-scale reconstruction approaches.

</details>


### [123] [DiVE-k: Differential Visual Reasoning for Fine-grained Image Recognition](https://arxiv.org/abs/2511.18305)
*Raja Kumar,Arka Sadhu,Ram Nevatia*

Main category: cs.CV

TL;DR: DiVE-k框架通过利用模型自身的top-k预测作为训练信号，解决LVLMs在细粒度图像识别中的泛化问题，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于精确匹配奖励信号的RL微调方法存在脆弱性，鼓励记忆训练类别，无法激发区分性推理能力，导致在未见类别上泛化能力差。

Method: DiVE-k为每个训练图像创建基于模型top-k输出的多选题，使用RL训练模型选择正确答案，迫使模型在合理选项间进行细粒度区分推理。

Result: 在五个标准细粒度数据集上，DiVE-k在base-to-novel泛化设置中比QWEN2.5-VL-7B和ViRFT分别提升10.04%和6.16%的调和平均值。

Conclusion: DiVE-k通过简单的可验证奖励信号有效缓解记忆问题，显著提升LVLMs在细粒度识别任务中的泛化能力。

Abstract: Large Vision Language Models (LVLMs) possess extensive text knowledge but struggles to utilize this knowledge for fine-grained image recognition, often failing to differentiate between visually similar categories. Existing fine-tuning methods using Reinforcement Learning (RL) with exact-match reward signals are often brittle, encourage memorization of training categories, and fail to elicit differential reasoning needed for generalization to unseen classes. To address this, we propose $\textbf{DiVE-k}$, $\textbf{Di}$fferential $\textbf{V}$isual r$\textbf{E}$asoning using top-$\textbf{k}$ generations, framework that leverages model's own top-k predictions as a training signal. For each training image, DiVE-k creates a multiple-choice question from the model's top-k outputs and uses RL to train the model to select the correct answer. This approach requires the model to perform fine-grained differential reasoning among plausible options and provides a simple, verifiable reward signal that mitigates memorization and improves generalization. Experiments on five standard fine-grained datasets show that our method significantly outperforms existing approaches. In the standard base-to-novel generalization setting, DiVE-k surpasses the QWEN2.5-VL-7B and ViRFT by 10.04% and 6.16% on the Harmonic Mean metric, respectively. Further experiments show similar gains in mixed-domain and few-shot scenarios.

</details>


### [124] [ScriptViT: Vision Transformer-Based Personalized Handwriting Generation](https://arxiv.org/abs/2511.18307)
*Sajjan Acharya,Rajendra Baskota*

Main category: cs.CV

TL;DR: 提出了一种基于Vision Transformer的风格编码器框架，用于生成具有全局风格一致性的手写文本，解决了现有方法在捕捉长距离空间依赖性和细微书写风格特征方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有手写生成方法（如GAN、transformer和扩散模型）难以全面捕捉书写者特定的全局风格模式，特别是涉及长距离空间依赖性的特征，如一致的倾斜度、曲率和笔画压力等细微风格特征。

Method: 采用Vision Transformer风格编码器从多张参考图像中学习全局风格模式，通过交叉注意力机制将风格线索与目标文本整合，并使用显著笔画注意力分析（SSAA）提高模型可解释性。

Result: 该方法能够生成更具风格一致性的手写图像，同时保持文本准确性，并通过SSAA实现了对风格迁移过程中笔画级特征关注的可视化分析。

Conclusion: 该框架不仅提升了手写文本生成的风格连贯性，还增强了模型的可解释性和分析能力，为手写风格合成提供了更有效的解决方案。

Abstract: Styled handwriting generation aims to synthesize handwritten text that looks both realistic and aligned with a specific writer's style. While recent approaches involving GAN, transformer and diffusion-based models have made progress, they often struggle to capture the full spectrum of writer-specific attributes, particularly global stylistic patterns that span long-range spatial dependencies. As a result, capturing subtle writer-specific traits such as consistent slant, curvature or stroke pressure, while keeping the generated text accurate is still an open problem. In this work, we present a unified framework designed to address these limitations. We introduce a Vision Transformer-based style encoder that learns global stylistic patterns from multiple reference images, allowing the model to better represent long-range structural characteristics of handwriting. We then integrate these style cues with the target text using a cross-attention mechanism, enabling the system to produce handwritten images that more faithfully reflect the intended style. To make the process more interpretable, we utilize Salient Stroke Attention Analysis (SSAA), which reveals the stroke-level features the model focuses on during style transfer. Together, these components lead to handwriting synthesis that is not only more stylistically coherent, but also easier to understand and analyze.

</details>


### [125] [Stro-VIGRU: Defining the Vision Recurrent-Based Baseline Model for Brain Stroke Classification](https://arxiv.org/abs/2511.18316)
*Subhajeet Das,Pritam Paul,Rohit Bahadur,Sohan Das*

Main category: cs.CV

TL;DR: 提出基于预训练Vision Transformer的迁移学习框架，用于脑卒中的早期识别，通过部分冻结编码器块和双向GRU分类器，在脑卒中数据集上达到94.06%的准确率。


<details>
  <summary>Details</summary>
Motivation: 脑卒中是全球主要死因和致残原因，早期识别对成功治疗至关重要。CT扫描虽快速易得，但人工分析耗时且易出错，需要自动化解决方案。

Method: 使用预训练Vision Transformer进行迁移学习，冻结部分编码器块，其余进行微调以学习脑卒中特异性特征。提取的特征输入单层双向GRU进行分类，通过数据增强处理类别不平衡问题。

Result: 在脑卒中数据集上，模型实现了94.06%的分类准确率，证明了该方法的有效性。

Conclusion: 提出的ViT迁移学习框架能够有效识别脑卒中，为临床诊断提供了自动化工具，具有实际应用价值。

Abstract: Stroke majorly causes death and disability worldwide, and early recognition is one of the key elements of successful treatment of the same. It is common to diagnose strokes using CT scanning, which is fast and readily available, however, manual analysis may take time and may result in mistakes. In this work, a pre-trained Vision Transformer-based transfer learning framework is proposed for the early identification of brain stroke. A few of the encoder blocks of the ViT model are frozen, and the rest are allowed to be fine-tuned in order to learn brain stroke-specific features. The features that have been extracted are given as input to a single-layer Bi-GRU to perform classification. Class imbalance is handled by data augmentation. The model has achieved 94.06% accuracy in classifying brain stroke from the Stroke Dataset.

</details>


### [126] [Optimal Pose Guidance for Stereo Calibration in 3D Deformation Measurement](https://arxiv.org/abs/2511.18317)
*Dongcai Tan,Shunkun Liang,Bin Li,Banglei Guan,Ang Su,Yuan Lin,Dapeng Zhang,Minggang Wan,Zibin Liu,Chenglong Wang,Jiajian Zhu,Zhang Li,Yang Shang,Qifeng Yu*

Main category: cs.CV

TL;DR: 该研究提出了一种用于3D变形测量的立体标定最优姿态引导方法，通过联合优化相对和绝对外参参数，自动生成最优标定姿态，提高标定效率和精度。


<details>
  <summary>Details</summary>
Motivation: 当前立体标定方法缺乏直观的最优姿态指导，导致变形测量效率低下且精度不理想，需要开发能够自动生成最优标定的交互式标定框架。

Method: 提出姿态优化方法，引入相对和绝对外参参数的联合优化，以协方差矩阵迹最小化为损失函数求解最优姿态，并集成用户友好的图形界面指导非专业用户采集合格标定图像。

Result: 与随机姿态相比，该方法在效率（需要更少图像）和精度（测量误差更低）方面表现优越，在不同视场下保持鲁棒性。S形试件热变形测量结果与有限元分析高度一致。

Conclusion: 该方法在3D变形测量领域具有显著应用潜力，仿真实验、真实实验和热变形测量应用均验证了其有效性。

Abstract: Stereo optical measurement techniques, such as digital image correlation (DIC), are widely used in 3D deformation measurement as non-contact, full-field measurement methods, in which stereo calibration is a crucial step. However, current stereo calibration methods lack intuitive optimal pose guidance, leading to inefficiency and suboptimal accuracy in deformation measurements. The aim of this study is to develop an interactive calibration framework that automatically generates the next optimal pose, enabling high-accuracy stereo calibration for 3D deformation measurement. We propose a pose optimization method that introduces joint optimization of relative and absolute extrinsic parameters, with the minimization of the covariance matrix trace adopted as the loss function to solve for the next optimal pose. Integrated with this method is a user-friendly graphical interface, which guides even non-expert users to capture qualified calibration images. Our proposed method demonstrates superior efficiency (requiring fewer images) and accuracy (demonstrating lower measurement errors) compared to random pose, while maintaining robustness across varying FOVs. In the thermal deformation measurement tests on an S-shaped specimen, the results exhibit high agreement with finite element analysis (FEA) simulations in both deformation magnitude and evolutionary trends. We present a pose guidance method for high-precision stereo calibration in 3D deformation measurement. The simulation experiments, real-world experiments, and thermal deformation measurement applications all demonstrate the significant application potential of our proposed method in the field of 3D deformation measurement.
  Keywords: Stereo calibration, Optimal pose guidance, 3D deformation measurement, Digital image correlation

</details>


### [127] [General vs Domain-Specific CNNs: Understanding Pretraining Effects on Brain MRI Tumor Classification](https://arxiv.org/abs/2511.18326)
*Helia Abedini,Saba Rahimi,Reza Vaziri*

Main category: cs.CV

TL;DR: 本研究比较了三种预训练CNN模型在小数据集脑肿瘤分类任务中的表现，发现通用预训练模型ConvNeXt-Tiny表现最佳，而医学领域预训练的RadImageNet DenseNet121泛化能力较差。


<details>
  <summary>Details</summary>
Motivation: 探讨在小数据集条件下，医学领域预训练模型和通用预训练模型在脑肿瘤MRI分类任务中的性能差异，为医疗影像分析中的迁移学习策略提供指导。

Method: 在相同条件下系统评估三种预训练CNN架构：RadImageNet DenseNet121（医学领域预训练）、EfficientNetV2S和ConvNeXt-Tiny（通用预训练），使用有限规模的脑MRI数据集进行训练和微调。

Result: ConvNeXt-Tiny获得最高准确率，其次是EfficientNetV2S，而RadImageNet DenseNet121尽管有医学领域预训练，但表现出较差的泛化能力，准确率较低且损失较高。

Conclusion: 在小数据条件下，医学领域预训练可能泛化能力不足，而基于大规模数据集预训练的现代通用CNN在专业医疗影像任务中能提供更优的迁移学习性能。

Abstract: Brain tumor detection from MRI scans plays a crucial role in early diagnosis and treatment planning. Deep convolutional neural networks (CNNs) have demonstrated strong performance in medical imaging tasks, particularly when pretrained on large datasets. However, it remains unclear which type of pretrained model performs better when only a small dataset is available: those trained on domain-specific medical data or those pretrained on large general datasets. In this study, we systematically evaluate three pretrained CNN architectures for brain tumor classification: RadImageNet DenseNet121 with medical-domain pretraining, EfficientNetV2S, and ConvNeXt-Tiny, which are modern general-purpose CNNs. All models were trained and fine-tuned under identical conditions using a limited-size brain MRI dataset to ensure a fair comparison. Our results reveal that ConvNeXt-Tiny achieved the highest accuracy, followed by EfficientNetV2S, while RadImageNet DenseNet121, despite being pretrained on domain-specific medical data, exhibited poor generalization with lower accuracy and higher loss. These findings suggest that domain-specific pretraining may not generalize well under small-data conditions. In contrast, modern, deeper general-purpose CNNs pretrained on large-scale datasets can offer superior transfer learning performance in specialized medical imaging tasks.

</details>


### [128] [SciPostLayoutTree: A Dataset for Structural Analysis of Scientific Posters](https://arxiv.org/abs/2511.18329)
*Shohei Tanaka,Atsushi Hashimoto,Yoshitaka Ushiku*

Main category: cs.CV

TL;DR: 本文提出了SciPostLayoutTree数据集和Layout Tree Decoder模型，用于分析科学海报的阅读顺序和层次结构关系。


<details>
  <summary>Details</summary>
Motivation: 科学海报在学术交流中扮演重要角色，但现有的结构分析研究主要关注论文，海报的结构分析研究不足。

Method: 构建了包含约8000张标注海报的SciPostLayoutTree数据集，开发了Layout Tree Decoder模型，该模型结合视觉特征和边界框特征，并使用波束搜索来预测关系。

Result: 实验结果表明，该模型提高了对空间挑战性关系的预测准确性，为海报结构分析建立了坚实的基线。

Conclusion: SciPostLayoutTree数据集和Layout Tree Decoder模型有效解决了海报结构分析的研究空白，提升了复杂空间关系的识别能力。

Abstract: Scientific posters play a vital role in academic communication by presenting ideas through visual summaries. Analyzing reading order and parent-child relations of posters is essential for building structure-aware interfaces that facilitate clear and accurate understanding of research content. Despite their prevalence in academic communication, posters remain underexplored in structural analysis research, which has primarily focused on papers. To address this gap, we constructed SciPostLayoutTree, a dataset of approximately 8,000 posters annotated with reading order and parent-child relations. Compared to an existing structural analysis dataset, SciPostLayoutTree contains more instances of spatially challenging relations, including upward, horizontal, and long-distance relations. As a solution to these challenges, we develop Layout Tree Decoder, which incorporates visual features as well as bounding box features including position and category information. The model also uses beam search to predict relations while capturing sequence-level plausibility. Experimental results demonstrate that our model improves the prediction accuracy for spatially challenging relations and establishes a solid baseline for poster structure analysis. The dataset is publicly available at https://huggingface.co/datasets/omron-sinicx/scipostlayouttree. The code is also publicly available at https://github.com/omron-sinicx/scipostlayouttree.

</details>


### [129] [ConsistCompose: Unified Multimodal Layout Control for Image Composition](https://arxiv.org/abs/2511.18333)
*Xuanke Shi,Boxuan Li,Xiaoyang Han,Zhongang Cai,Lei Yang,Dahua Lin,Quan Wang*

Main category: cs.CV

TL;DR: ConsistCompose是一个统一的多模态框架，通过将布局坐标嵌入语言提示中，实现布局可控的多实例图像生成，无需特定任务分支。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态模型主要关注视觉接地（语言与图像区域对齐），而语言嵌入布局接地生成（LELG）用于布局可控的多实例生成研究不足，限制了精确的组合控制。

Method: 提出ConsistCompose框架，通过实例-坐标绑定提示和坐标感知的无分类器引导，将语言布局线索转化为精确的空间控制；构建了包含340万数据对的ConsistCompose3M数据集用于监督学习。

Result: 在COCO-Position和MS-Bench上的实验表明，ConsistCompose显著提高了空间准确性，同时保持了身份保真度和竞争力的多模态理解能力。

Conclusion: ConsistCompose为布局可控的多模态图像生成建立了一个统一的范式，实现了布局坐标与语言提示的直接嵌入。

Abstract: Unified multimodal models that couple visual understanding with image generation have advanced rapidly, yet most systems still focus on visual grounding-aligning language with image regions-while their generative counterpart, linguistic-embedded layout-grounded generation (LELG) for layout-controllable multi-instance generation, remains underexplored and limits precise compositional control. We present ConsistCompose, a unified multimodal framework that embeds layout coordinates directly into language prompts, enabling layout-controlled multi-instance image generation from Interleaved Image-Text within a single generative interface. We further construct ConsistCompose3M, a 3.4M multi-instance generation dataset with layout and identity annotations (2.6M text-guided and 0.8M image-guided data pairs) that provides large-scale supervision for layout-conditioned generation. Within this framework, LELG is instantiated through instance-coordinate binding prompts and coordinate-aware classifier-free guidance, which translate linguistic layout cues into precise spatial control without task-specific branches. Experiments on COCO-Position and MS-Bench show that ConsistCompose substantially improves spatial accuracy over layout-controlled baselines while preserving identity fidelity and competitive general multimodal understanding, establishing a unified paradigm for layout-controllable multimodal image generation.

</details>


### [130] [A Tri-Modal Dataset and a Baseline System for Tracking Unmanned Aerial Vehicles](https://arxiv.org/abs/2511.18344)
*Tianyang Xu,Jinjie Gu,Xuefeng Zhu,XiaoJun Wu,Josef Kittler*

Main category: cs.CV

TL;DR: 提出了MM-UAV数据集和基于多模态的无人机跟踪框架，解决了单模态跟踪在复杂环境下的局限性


<details>
  <summary>Details</summary>
Motivation: 随着低空无人机的普及，视觉多目标跟踪成为关键安全技术，但单模态跟踪在低光照、复杂背景和快速运动等挑战性场景中容易失效。多模态跟踪更具鲁棒性，但缺乏专用公共数据集阻碍了有效解决方案的开发

Method: 1）发布MM-UAV数据集，包含RGB、红外和事件信号三种模态，覆盖30多个挑战性场景；2）提出多模态多无人机跟踪框架，包含偏移引导自适应对齐模块解决传感器间空间不匹配问题，以及自适应动态融合模块平衡不同模态的互补信息；3）引入事件增强关联机制，利用事件模态的运动线索进行更可靠的身份维护

Result: 综合实验表明，所提出的框架在性能上始终优于现有最先进方法

Conclusion: MM-UAV数据集和跟踪框架为多模态无人机跟踪研究提供了重要基础，将促进该领域的进一步发展

Abstract: With the proliferation of low altitude unmanned aerial vehicles (UAVs), visual multi-object tracking is becoming a critical security technology, demanding significant robustness even in complex environmental conditions. However, tracking UAVs using a single visual modality often fails in challenging scenarios, such as low illumination, cluttered backgrounds, and rapid motion. Although multi-modal multi-object UAV tracking is more resilient, the development of effective solutions has been hindered by the absence of dedicated public datasets. To bridge this gap, we release MM-UAV, the first large-scale benchmark for Multi-Modal UAV Tracking, integrating three key sensing modalities, e.g. RGB, infrared (IR), and event signals. The dataset spans over 30 challenging scenarios, with 1,321 synchronised multi-modal sequences, and more than 2.8 million annotated frames. Accompanying the dataset, we provide a novel multi-modal multi-UAV tracking framework, designed specifically for UAV tracking applications and serving as a baseline for future research. Our framework incorporates two key technical innovations, e.g. an offset-guided adaptive alignment module to resolve spatio mismatches across sensors, and an adaptive dynamic fusion module to balance complementary information conveyed by different modalities. Furthermore, to overcome the limitations of conventional appearance modelling in multi-object tracking, we introduce an event-enhanced association mechanism that leverages motion cues from the event modality for more reliable identity maintenance. Comprehensive experiments demonstrate that the proposed framework consistently outperforms state-of-the-art methods. To foster further research in multi-modal UAV tracking, both the dataset and source code will be made publicly available at https://xuefeng-zhu5.github.io/MM-UAV/.

</details>


### [131] [FlowPortal: Residual-Corrected Flow for Training-Free Video Relighting and Background Replacement](https://arxiv.org/abs/2511.18346)
*Wenshuo Gao,Junyi Fan,Jiangyue Zeng,Shuai Yang*

Main category: cs.CV

TL;DR: FlowPortal是一个无需训练、基于光流的视频重光照框架，通过残差校正光流机制实现高结构一致性的视频重光照和背景替换。


<details>
  <summary>Details</summary>
Motivation: 现有方法在时间一致性、空间保真度和光照自然度之间难以平衡，特别是在视频重光照和背景替换任务中。

Method: 提出残差校正光流机制将标准光流模型转换为编辑模型，结合解耦条件设计、高频细节传输机制和掩码策略来分离前景重光照和背景生成过程。

Result: 实验表明FlowPortal在时间一致性、结构保持和光照真实性方面表现优异，同时保持高效率。

Conclusion: FlowPortal为解决视频重光照和背景替换的挑战提供了一种有效的训练免费解决方案，在多个关键指标上超越现有方法。

Abstract: Video relighting with background replacement is a challenging task critical for applications in film production and creative media. Existing methods struggle to balance temporal consistency, spatial fidelity, and illumination naturalness. To address these issues, we introduce FlowPortal, a novel training-free flow-based video relighting framework. Our core innovation is a Residual-Corrected Flow mechanism that transforms a standard flow-based model into an editing model, guaranteeing perfect reconstruction when input conditions are identical and enabling faithful relighting when they differ, resulting in high structural consistency. This is further enhanced by a Decoupled Condition Design for precise lighting control and a High-Frequency Transfer mechanism for detail preservation. Additionally, a masking strategy isolates foreground relighting from background pure generation process. Experiments demonstrate that FlowPortal achieves superior performance in temporal coherence, structural preservation, and lighting realism, while maintaining high efficiency. Project Page: https://gaowenshuo.github.io/FlowPortalProject/.

</details>


### [132] [MagicWand: A Universal Agent for Generation and Evaluation Aligned with User Preference](https://arxiv.org/abs/2511.18352)
*Zitong Xu,Dake Shen,Yaosong Du,Kexiang Hao,Jinghan Huang,Xiande Huang*

Main category: cs.CV

TL;DR: 该论文提出了UniPrefer-100K数据集和MagicWand代理，通过用户偏好增强的提示生成和评估机制，解决AIGC模型难以生成符合用户偏好内容的问题。


<details>
  <summary>Details</summary>
Motivation: 现有AIGC模型在生成图像和视频方面取得显著进展，但用户难以获得符合个人偏好的内容，主要由于详细提示词编写困难且缺乏偏好保留机制。

Method: 构建UniPrefer-100K大规模数据集，提出MagicWand通用生成和评估代理，通过偏好增强提示生成、高质量内容生成以及偏好对齐评估和优化来实现用户偏好对齐。

Result: 在UniPreferBench基准测试中，MagicWand在多种场景下都能生成与用户偏好高度对齐的内容和评估结果。

Conclusion: 该研究为解决AIGC中的用户偏好对齐问题提供了有效的数据集、基准和解决方案，MagicWand代理在不同任务中表现出良好的偏好对齐能力。

Abstract: Recent advances in AIGC (Artificial Intelligence Generated Content) models have enabled significant progress in image and video generation. However, users still struggle to obtain content that aligns with their preferences due to the difficulty of crafting detailed prompts and the lack of mechanisms to retain their preferences. To address these challenges, we construct \textbf{UniPrefer-100K}, a large-scale dataset comprising images, videos, and associated text that describes the styles users tend to prefer. Based on UniPrefer-100K, we propose \textbf{MagicWand}, a universal generation and evaluation agent that enhances prompts based on user preferences, leverages advanced generation models for high-quality content, and applies preference-aligned evaluation and refinement. In addition, we introduce \textbf{UniPreferBench}, the first large-scale benchmark with over 120K annotations for assessing user preference alignment across diverse AIGC tasks. Experiments on UniPreferBench demonstrate that MagicWand consistently generates content and evaluations that are well aligned with user preferences across a wide range of scenarios.

</details>


### [133] [TRANSPORTER: Transferring Visual Semantics from VLM Manifolds](https://arxiv.org/abs/2511.18359)
*Alexandros Stergiou*

Main category: cs.CV

TL;DR: 本文提出了一种新的模型解释方法TRANSPORTER，通过将视觉语言模型的logits转换为视频来理解其内部决策过程。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在处理复杂场景时，其内部推理过程难以理解和控制。受文本到视频生成模型的启发，需要一种新的方法来揭示VLMs的预测机制。

Method: 提出L2V任务和TRANSPORTER方法，通过最优传输耦合将VLMs的高语义嵌入空间与T2V模型连接，利用logit分数定义嵌入方向进行条件视频生成。

Result: TRANSPORTER能够生成反映不同对象属性、动作副词和场景上下文变化的视频，定量和定性评估表明L2V为模型可解释性提供了新的方向。

Conclusion: L2V任务为视觉语言模型的解释提供了一种保真度高、新颖的可视化方法，填补了该领域的研究空白。

Abstract: How do video understanding models acquire their answers? Although current Vision Language Models (VLMs) reason over complex scenes with diverse objects, action performances, and scene dynamics, understanding and controlling their internal processes remains an open challenge. Motivated by recent advancements in text-to-video (T2V) generative models, this paper introduces a logits-to-video (L2V) task alongside a model-independent approach, TRANSPORTER, to generate videos that capture the underlying rules behind VLMs' predictions. Given the high-visual-fidelity produced by T2V models, TRANSPORTER learns an optimal transport coupling to VLM's high-semantic embedding spaces. In turn, logit scores define embedding directions for conditional video generation. TRANSPORTER generates videos that reflect caption changes over diverse object attributes, action adverbs, and scene context. Quantitative and qualitative evaluations across VLMs demonstrate that L2V can provide a fidelity-rich, novel direction for model interpretability that has not been previously explored.

</details>


### [134] [Alias-free 4D Gaussian Splatting](https://arxiv.org/abs/2511.18367)
*Zilong Chen,Huan-ang Gao,Delin Qu,Haohan Chi,Hao Tang,Kai Zhang,Hao Zhao*

Main category: cs.CV

TL;DR: 本文提出了一种针对4D高斯泼溅的免混叠方法，通过最大采样频率公式、4D尺度自适应滤波器和尺度损失，解决了动态场景重建中因相机焦距或高斯基元距离调整而产生的强伪影问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于高斯泼溅的动态场景重建方法虽然能实现实时渲染和生成逼真图像，但在调整相机焦距或高斯基元与相机距离以修改渲染分辨率时，会因4D高斯的频率约束和2D膨胀滤波器引起的高斯尺度不匹配而产生强伪影。

Method: 推导了4D高斯泼溅的最大采样频率公式，引入了4D尺度自适应滤波器和尺度损失，灵活调节4D高斯泼溅的采样频率。

Result: 该方法在增加渲染频率时消除了高频伪影，并在多视角视频重建中有效减少了冗余高斯基元。通过单目和多视角视频重建实验验证了所提方法的有效性。

Conclusion: 提出的4D免混叠高斯泼溅方法能够有效解决动态场景重建中的伪影问题，提升渲染质量和高斯基元的使用效率。

Abstract: Existing dynamic scene reconstruction methods based on Gaussian Splatting enable real-time rendering and generate realistic images. However, adjusting the camera's focal length or the distance between Gaussian primitives and the camera to modify rendering resolution often introduces strong artifacts, stemming from the frequency constraints of 4D Gaussians and Gaussian scale mismatch induced by the 2D dilated filter. To address this, we derive a maximum sampling frequency formulation for 4D Gaussian Splatting and introduce a 4D scale-adaptive filter and scale loss, which flexibly regulates the sampling frequency of 4D Gaussian Splatting. Our approach eliminates high-frequency artifacts under increased rendering frequencies while effectively reducing redundant Gaussians in multi-view video reconstruction. We validate the proposed method through monocular and multi-view video reconstruction experiments.Ours project page: https://4d-alias-free.github.io/4D-Alias-free/

</details>


### [135] [MimiCAT: Mimic with Correspondence-Aware Cascade-Transformer for Category-Free 3D Pose Transfer](https://arxiv.org/abs/2511.18370)
*Zenghao Chai,Chen Tang,Yongkang Wong,Xulei Yang,Mohan Kankanhalli*

Main category: cs.CV

TL;DR: 提出了MimiCAT模型，用于解决类别无关的3D姿态迁移问题，能够在不同结构角色（如人形到四足动物）之间进行姿态迁移


<details>
  <summary>Details</summary>
Motivation: 现有方法局限于相似结构的角色之间迁移，无法处理类别无关的设置（如人形到四足动物），主要挑战在于不同角色类型的结构和变换多样性导致区域不匹配和迁移质量差

Method: 构建百万级姿态数据集，提出基于级联Transformer的MimiCAT模型，利用语义关键点标签学习软对应关系，实现灵活的多对多匹配，将姿态迁移建模为条件生成过程

Result: 广泛的定性和定量实验表明，MimiCAT能够在不同角色之间迁移合理的姿态，显著优于局限于狭窄类别迁移的先前方法

Conclusion: MimiCAT成功解决了类别无关的3D姿态迁移问题，为跨不同结构角色的姿态迁移提供了有效解决方案

Abstract: 3D pose transfer aims to transfer the pose-style of a source mesh to a target character while preserving both the target's geometry and the source's pose characteristic. Existing methods are largely restricted to characters with similar structures and fail to generalize to category-free settings (e.g., transferring a humanoid's pose to a quadruped). The key challenge lies in the structural and transformation diversity inherent in distinct character types, which often leads to mismatched regions and poor transfer quality. To address these issues, we first construct a million-scale pose dataset across hundreds of distinct characters. We further propose MimiCAT, a cascade-transformer model designed for category-free 3D pose transfer. Instead of relying on strict one-to-one correspondence mappings, MimiCAT leverages semantic keypoint labels to learn a novel soft correspondence that enables flexible many-to-many matching across characters. The pose transfer is then formulated as a conditional generation process, in which the source transformations are first projected onto the target through soft correspondence matching and subsequently refined using shape-conditioned representations. Extensive qualitative and quantitative experiments demonstrate that MimiCAT transfers plausible poses across different characters, significantly outperforming prior methods that are limited to narrow category transfer (e.g., humanoid-to-humanoid).

</details>


### [136] [MASS: Motion-Aware Spatial-Temporal Grounding for Physics Reasoning and Comprehension in Vision-Language Models](https://arxiv.org/abs/2511.18373)
*Xiyang Wu,Zongxia Li,Jihui Jin,Guangyao Shi,Gouthaman KV,Vishnu Raj,Nilotpal Sinha,Jingxi Chen,Fan Du,Dinesh Manocha*

Main category: cs.CV

TL;DR: 该论文提出了MASS-Bench基准和MASS方法，通过将物理世界上下文线索转化为可解释表示，提升视觉语言模型在物理推理任务上的性能，在物理推理和理解任务上实现了8.7%和6.0%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在标准视频任务上表现良好，但在涉及运动动力学和空间交互的物理驱动推理方面存在困难，这限制了它们解释真实或AI生成内容视频以及生成物理一致内容的能力。

Method: 提出了MASS方法，通过深度基础的3D编码和视觉接地将时空信号注入VLM语言空间，结合运动跟踪器处理物体动力学，并应用强化微调来加强跨模态对齐和推理。

Result: 实验表明，改进后的VLMs在物理推理和理解任务上优于可比和更大的基线模型以及先前的最先进模型，性能提升达8.7%和6.0%，达到了与闭源SoTA VLMs（如Gemini-2.5-Flash）相当的性能。

Conclusion: 该方法有效解决了VLMs在物理推理方面的局限性，验证了将物理世界上下文转化为可解释表示的方法的有效性。

Abstract: Vision Language Models (VLMs) perform well on standard video tasks but struggle with physics-driven reasoning involving motion dynamics and spatial interactions. This limitation reduces their ability to interpret real or AI-generated content (AIGC) videos and to generate physically consistent content. We present an approach that addresses this gap by translating physical-world context cues into interpretable representations aligned with VLMs' perception, comprehension, and reasoning. We introduce MASS-Bench, a comprehensive benchmark consisting of 4,350 real-world and AIGC videos and 8,361 free-form video question-answering pairs focused on physics-related comprehension tasks, with detailed annotations including visual detections, sub-segment grounding, and full-sequence 3D motion tracking of entities. We further present MASS, a model-agnostic method that injects spatial-temporal signals into the VLM language space via depth-based 3D encoding and visual grounding, coupled with a motion tracker for object dynamics. To strengthen cross-modal alignment and reasoning, we apply reinforcement fine-tuning. Experiments and ablations show that our refined VLMs outperform comparable and larger baselines, as well as prior state-of-the-art models, by 8.7% and 6.0%, achieving performance comparable to close-source SoTA VLMs such as Gemini-2.5-Flash on physics reasoning and comprehension. These results validate the effectiveness of our approach.

</details>


### [137] [Synthetic Curriculum Reinforces Compositional Text-to-Image Generation](https://arxiv.org/abs/2511.18378)
*Shijian Wang,Runhao Fu,Siyi Zhao,Qingqin Zhan,Xingjian Wang,Jiarui Jin,Yuan Lu,Hanqian Wu,Cunjian Chen*

Main category: cs.CV

TL;DR: 本文提出了一种名为CompGen的组合式课程强化学习框架，通过场景图建立难度标准，使用自适应MCMC图采样算法生成渐进式训练数据，显著提升了文本到图像生成模型的组合生成能力。


<details>
  <summary>Details</summary>
Motivation: 解决文本到图像生成中组合合成的挑战性问题，特别是需要准确渲染包含多个具有不同属性和复杂空间语义关系的对象的复杂场景。

Method: 利用场景图建立组合能力难度标准，开发自适应MCMC图采样算法生成难度感知的训练课程数据，结合GRPO进行强化学习训练，并研究不同课程调度策略。

Result: CompGen在不同课程调度策略下表现出不同的扩展曲线，易到难和高斯采样策略优于随机采样，显著提升了基于扩散和自回归T2I模型的组合生成能力。

Conclusion: CompGen框架有效改进了组合式文本到图像生成系统，证明了课程学习在提升T2I模型组合能力方面的有效性。

Abstract: Text-to-Image (T2I) generation has long been an open problem, with compositional synthesis remaining particularly challenging. This task requires accurate rendering of complex scenes containing multiple objects that exhibit diverse attributes as well as intricate spatial and semantic relationships, demanding both precise object placement and coherent inter-object interactions. In this paper, we propose a novel compositional curriculum reinforcement learning framework named CompGen that addresses compositional weakness in existing T2I models. Specifically, we leverage scene graphs to establish a novel difficulty criterion for compositional ability and develop a corresponding adaptive Markov Chain Monte Carlo graph sampling algorithm. This difficulty-aware approach enables the synthesis of training curriculum data that progressively optimize T2I models through reinforcement learning. We integrate our curriculum learning approach into Group Relative Policy Optimization (GRPO) and investigate different curriculum scheduling strategies. Our experiments reveal that CompGen exhibits distinct scaling curves under different curriculum scheduling strategies, with easy-to-hard and Gaussian sampling strategies yielding superior scaling performance compared to random sampling. Extensive experiments demonstrate that CompGen significantly enhances compositional generation capabilities for both diffusion-based and auto-regressive T2I models, highlighting its effectiveness in improving the compositional T2I generation systems.

</details>


### [138] [RNN as Linear Transformer: A Closer Investigation into Representational Potentials of Visual Mamba Models](https://arxiv.org/abs/2511.18380)
*Timing Yang,Guoyizhe Wei,Alan Yuille,Feng Wang*

Main category: cs.CV

TL;DR: 本文系统研究Mamba在视觉任务中的表征特性，通过理论分析、新评估指标和自监督预训练揭示了Mamba作为Softmax Attention低秩近似的性质及其建模长距离依赖的能力。


<details>
  <summary>Details</summary>
Motivation: Mamba作为视觉任务的有效骨干网络，其底层机制在视觉领域仍未被充分理解，需要系统研究其表征特性。

Method: 1) 理论分析Mamba与Softmax和Linear Attention的关系；2) 提出二元分割指标量化评估激活图；3) 利用DINO进行自监督预训练获得更清晰的激活图。

Result: 证实Mamba可作为Softmax Attention的低秩近似，新评估指标显示Mamba能有效建模长距离依赖，自监督预训练获得78.5%的ImageNet线性探测准确率。

Conclusion: 该研究为基于Mamba的视觉架构提供了有价值的见解，展示了Mamba在可解释性和性能方面的潜力。

Abstract: Mamba has recently garnered attention as an effective backbone for vision tasks. However, its underlying mechanism in visual domains remains poorly understood. In this work, we systematically investigate Mamba's representational properties and make three primary contributions. First, we theoretically analyze Mamba's relationship to Softmax and Linear Attention, confirming that it can be viewed as a low-rank approximation of Softmax Attention and thereby bridging the representational gap between Softmax and Linear forms. Second, we introduce a novel binary segmentation metric for activation map evaluation, extending qualitative assessments to a quantitative measure that demonstrates Mamba's capacity to model long-range dependencies. Third, by leveraging DINO for self-supervised pretraining, we obtain clearer activation maps than those produced by standard supervised approaches, highlighting Mamba's potential for interpretability. Notably, our model also achieves a 78.5 percent linear probing accuracy on ImageNet, underscoring its strong performance. We hope this work can provide valuable insights for future investigations of Mamba-based vision architectures.

</details>


### [139] [ViMix-14M: A Curated Multi-Source Video-Text Dataset with Long-Form, High-Quality Captions and Crawl-Free Access](https://arxiv.org/abs/2511.18382)
*Timing Yang,Sucheng Ren,Alan Yuille,Feng Wang*

Main category: cs.CV

TL;DR: ViMix-14M是一个包含约1400万视频-文本对的精心策划的多源数据集，旨在解决开源视频生成模型面临的数据瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 现有公开视频数据集通常需要手动爬取YouTube视频，存在链接失效、访问限制和许可不确定性等问题，导致可用数据量有限且质量不高。

Method: 通过合并多样化的开放视频源，进行统一去重和质量过滤，并采用多粒度、基于真实情况指导的重标注流程，优化描述以更好地匹配视频的动作、场景和时间结构。

Result: 在多模态检索、文本到视频生成和视频问答任务上的评估显示，ViMix-14M相比同类数据集带来了一致的性能提升。

Conclusion: ViMix-14M有望帮助消除训练和微调开源视频基础模型的关键障碍，并为构建高质量、可泛化的视频-文本数据集提供见解。

Abstract: Text-to-video generation has surged in interest since Sora, yet open-source models still face a data bottleneck: there is no large, high-quality, easily obtainable video-text corpus. Existing public datasets typically require manual YouTube crawling, which yields low usable volume due to link rot and access limits, and raises licensing uncertainty. This work addresses this challenge by introducing ViMix-14M, a curated multi-source video-text dataset of around 14 million pairs that provides crawl-free, download-ready access and long-form, high-quality captions tightly aligned to video. ViMix-14M is built by merging diverse open video sources, followed by unified de-duplication and quality filtering, and a multi-granularity, ground-truth-guided re-captioning pipeline that refines descriptions to better match actions, scenes, and temporal structure. We evaluate the dataset by multimodal retrieval, text-to-video generation, and video question answering tasks, observing consistent improvements over counterpart datasets. We hope this work can help removing the key barrier to training and fine-tuning open-source video foundation models, and provide insights of building high-quality and generalizable video-text datasets.

</details>


### [140] [Can a Second-View Image Be a Language? Geometric and Semantic Cross-Modal Reasoning for X-ray Prohibited Item Detection](https://arxiv.org/abs/2511.18385)
*Chuang Peng,Renshuai Tao,Zhongwei Ren,Xianglong Liu,Yunchao Wei*

Main category: cs.CV

TL;DR: 提出了DualXrayBench基准和GSR模型，将X射线安检中的双视角图像作为类似语言模态来处理，通过几何-语义联合学习实现跨视角推理。


<details>
  <summary>Details</summary>
Motivation: 传统X射线安检方法依赖单视角视觉模态，在复杂威胁检测上存在困难。实际安检中检查员使用双视角图像，但现有研究未充分利用这一优势。

Method: 构建包含45,613对双视角图像的DualXrayBench基准和GSXray数据集，提出GSR模型联合学习跨视角几何对应和跨模态语义关系，将第二视角视为语言模态。

Result: 在DualXrayBench的8个任务上，GSR模型在所有X射线任务上都取得了显著提升。

Conclusion: 该方法为实际X射线安检提供了新视角，证明双视角图像可以作为有效的约束模态来提升检测性能。

Abstract: Automatic X-ray prohibited items detection is vital for security inspection and has been widely studied. Traditional methods rely on visual modality, often struggling with complex threats. While recent studies incorporate language to guide single-view images, human inspectors typically use dual-view images in practice. This raises the question: can the second view provide constraints similar to a language modality? In this work, we introduce DualXrayBench, the first comprehensive benchmark for X-ray inspection that includes multiple views and modalities. It supports eight tasks designed to test cross-view reasoning. In DualXrayBench, we introduce a caption corpus consisting of 45,613 dual-view image pairs across 12 categories with corresponding captions. Building upon these data, we propose the Geometric (cross-view)-Semantic (cross-modality) Reasoner (GSR), a multimodal model that jointly learns correspondences between cross-view geometry and cross-modal semantics, treating the second-view images as a "language-like modality". To enable this, we construct the GSXray dataset, with structured Chain-of-Thought sequences: <top>, <side>, <conclusion>. Comprehensive evaluations on DualXrayBench demonstrate that GSR achieves significant improvements across all X-ray tasks, offering a new perspective for real-world X-ray inspection.

</details>


### [141] [SegSplat: Feed-forward Gaussian Splatting and Open-Set Semantic Segmentation](https://arxiv.org/abs/2511.18386)
*Peter Siegel,Federico Tombari,Marc Pollefeys,Daniel Barath*

Main category: cs.CV

TL;DR: SegSplat是一个新颖框架，通过多视角2D基础模型特征构建紧凑语义记忆库，在单次前向传播中为3D高斯预测离散语义索引和几何外观属性，实现快速3D重建与开放词汇语义理解的结合。


<details>
  <summary>Details</summary>
Motivation: 弥合快速前馈3D重建与丰富开放词汇语义理解之间的差距，为机器人交互、增强现实等智能系统提供实用的语义感知3D环境生成。

Method: 构建紧凑语义记忆库，从多视角2D基础模型特征中提取语义信息，为每个3D高斯预测离散语义索引以及几何和外观属性，无需针对每个场景进行语义特征集成的优化。

Result: SegSplat在保持与最先进前馈3D高斯泼溅方法相当的几何保真度的同时，实现了强大的开放集语义分割能力。

Conclusion: 这项工作代表了向实用、即时的语义感知3D环境生成迈出的重要一步，对推进机器人交互、增强现实和其他智能系统具有重要意义。

Abstract: We have introduced SegSplat, a novel framework designed to bridge the gap between rapid, feed-forward 3D reconstruction and rich, open-vocabulary semantic understanding. By constructing a compact semantic memory bank from multi-view 2D foundation model features and predicting discrete semantic indices alongside geometric and appearance attributes for each 3D Gaussian in a single pass, SegSplat efficiently imbues scenes with queryable semantics. Our experiments demonstrate that SegSplat achieves geometric fidelity comparable to state-of-the-art feed-forward 3D Gaussian Splatting methods while simultaneously enabling robust open-set semantic segmentation, crucially \textit{without} requiring any per-scene optimization for semantic feature integration. This work represents a significant step towards practical, on-the-fly generation of semantically aware 3D environments, vital for advancing robotic interaction, augmented reality, and other intelligent systems.

</details>


### [142] [Exploring Weak-to-Strong Generalization for CLIP-based Classification](https://arxiv.org/abs/2511.18396)
*Jinhao Li,Sarah M. Erfani,Lei Feng,James Bailey,Feng Liu*

Main category: cs.CV

TL;DR: 提出了一种基于弱监督的类原型学习方法（CPL），用于增强CLIP模型的分类能力，在预训练受限的场景下取得了3.67%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 随着模型复杂度增加，人类监督变得不切实际。当模型超越人类知识时，提供准确反馈变得困难且低效。需要探索弱模型监督强模型的方法。

Method: 提出了类原型学习（CPL）方法，通过学习每个类别更具代表性的原型来增强CLIP模型的分类能力，使用简单的损失函数在弱监督下进行训练。

Result: 在CLIP-based分类任务中，CPL方法在目标场景下表现出稳健的改进，特别是在预训练受限的情况下，相比强基线方法实现了3.67%的性能提升。

Conclusion: 弱到强的泛化概念在多模态场景中同样有效，CPL方法为减少人类监督负担提供了一种可行的解决方案，在资源受限的情况下具有实用价值。

Abstract: Aligning large-scale commercial models with user intent is crucial to preventing harmful outputs. Current methods rely on human supervision but become impractical as model complexity increases. When models surpass human knowledge, providing accurate feedback becomes challenging and inefficient. A novel solution proposed recently is using a weaker model to supervise a stronger model. This concept leverages the ability of weaker models to perform evaluations, thereby reducing the workload on human supervisors. Previous work has shown the effectiveness of weak-to-strong generalization in the context of language-only models. Extending this concept to vision-language models leverages these insights, adapting the proven benefits to a multi-modal context. In our study, we explore weak-to-strong generalization for CLIP-based classification. We propose a method, class prototype learning (CPL), which aims to enhance the classification capabilities of the CLIP model, by learning more representative prototypes for each category. Our findings indicate that, despite using a simple loss function under weak supervision, CPL yields robust improvements in targeted scenarios, particularly when pretraining is limited. Extensive experiments demonstrate that our approach is effective under these settings, achieving a 3.67% improvement over strong baseline methods.

</details>


### [143] [ChineseVideoBench: Benchmarking Multi-modal Large Models for Chinese Video Question Answering](https://arxiv.org/abs/2511.18399)
*Yuxiang Nie,Han Wang,Yongjie Ye,Haiyang Yu,Weitao Jia,Tao Zeng,Hao Feng,Xiang Fei,Yang Li,Xiaohui Lv,Guozhi Tang,Jingqun Tang,Jinghui Lu,Zehui Dai,Jiacong Wang,Dingkang Yang,An-Lan Wang,Can Huang*

Main category: cs.CV

TL;DR: ChineseVideoBench是一个专门用于评估多模态大语言模型在中文视频问答任务上的基准测试，包含8个主类和12个子类，要求模型具备深度视频理解和中文文化意识。


<details>
  <summary>Details</summary>
Motivation: 随着对复杂视频分析能力需求的增长，需要建立全面且具有文化意识的评估框架，特别是在中文视频内容领域。

Method: 构建了一个包含复杂中文视频内容的数据集，并设计了专门的评估指标，对当前最先进的多模态大语言模型进行了实证评估。

Result: 该基准测试对现有MLLMs构成了显著挑战，Gemini 2.5 Pro以77.9%的总体得分表现最佳，InternVL-38B是最具竞争力的开源模型。

Conclusion: ChineseVideoBench填补了中文视频问答评估的空白，为MLLMs的发展提供了重要的基准测试工具。

Abstract: This paper introduces ChineseVideoBench, a pioneering benchmark specifically designed for evaluating Multimodal Large Language Models (MLLMs) in Chinese Video Question Answering. The growing demand for sophisticated video analysis capabilities highlights the critical need for comprehensive, culturally-aware evaluation frameworks. ChineseVideoBench addresses this gap by providing a robust dataset and tailored evaluation metrics, enabling rigorous assessment of state-of-the-art MLLMs on complex Chinese video content. Specifically, ChineseVideoBench comprises 8 main classes and 12 sub-classes, encompassing tasks that demand both deep video understanding and nuanced Chinese linguistic and cultural awareness. Our empirical evaluations reveal that ChineseVideoBench presents a significant challenge to current MLLMs. Among the models assessed, Gemini 2.5 Pro achieves the highest performance with an overall score of 77.9%, while InternVL-38B emerges as the most competitive open-source model.

</details>


### [144] [4D-VGGT: A General Foundation Model with SpatioTemporal Awareness for Dynamic Scene Geometry Estimation](https://arxiv.org/abs/2511.18416)
*Haonan Wang,Hanyu Zhou,Haoyue Liu,Luxin Yan*

Main category: cs.CV

TL;DR: 提出了4D-VGGT模型，通过分而治之的时空表示方法解决动态场景几何估计中空间和时间特征不匹配的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法将空间和时间特征统一到同一潜在空间，但由于两者异质性导致表示不匹配，需要更好的表示方法。

Method: 采用多设置输入（自适应视觉网格）、多级表示（跨视图全局融合和跨时间局部融合）和多任务预测的三方面设计。

Result: 在多个动态场景几何基准测试中验证了方法的有效性，模型具有更好的特征区分能力和应用通用性。

Conclusion: 4D-VGGT提供了一个统一的框架，通过分而治之的时空表示策略成功解决了动态场景几何估计中的特征匹配问题。

Abstract: We investigate a challenging task of dynamic scene geometry estimation, which requires representing both spatial and temporal features. Typically, existing methods align the two features into a unified latent space to model scene geometry. However, this unified paradigm suffers from potential mismatched representation due to the heterogeneous nature between spatial and temporal features. In this work, we propose 4D-VGGT, a general foundation model with divide-and-conquer spatiotemporal representation for dynamic scene geometry. Our model is divided into three aspects: 1) Multi-setting input. We design an adaptive visual grid that supports input sequences with arbitrary numbers of views and time steps. 2) Multi-level representation. We propose a cross-view global fusion for spatial representation and a cross-time local fusion for temporal representation. 3) Multi-task prediction. We append multiple task-specific heads to spatiotemporal representations, enabling a comprehensive visual geometry estimation for dynamic scenes. Under this unified framework, these components enhance the feature discriminability and application universality of our model for dynamic scenes. In addition, we integrate multiple geometry datasets to train our model and conduct extensive experiments to verify the effectiveness of our method across various tasks on multiple dynamic scene geometry benchmarks.

</details>


### [145] [NeuroVascU-Net: A Unified Multi-Scale and Cross-Domain Adaptive Feature Fusion U-Net for Precise 3D Segmentation of Brain Vessels in Contrast-Enhanced T1 MRI](https://arxiv.org/abs/2511.18422)
*Mohammad Jafari Vayeghan,Niloufar Delfan,Mehdi Tale Masouleh,Mansour Parvaresh Rizi,Behzad Moshiri*

Main category: cs.CV

TL;DR: NeuroVascU-Net是一种专为T1CE MRI脑血管分割设计的深度学习架构，通过多尺度特征融合和跨域自适应模块，在保持计算效率的同时实现高精度分割。


<details>
  <summary>Details</summary>
Motivation: T1CE MRI的精确脑血管分割对神经外科手术规划至关重要，但现有方法在准确性和计算成本之间存在权衡，限制了临床应用。

Method: 基于扩张U-Net架构，集成MSC²F模块（多尺度上下文特征融合）和CDA²F模块（跨域自适应特征融合），使用137例脑肿瘤患者的T1CE扫描数据进行训练验证。

Result: Dice分数达0.8609，精确度0.8841，仅需12.4M参数，显著优于基于Transformer的模型。

Conclusion: NeuroVascU-Net在准确性和效率之间取得了良好平衡，为计算机辅助神经外科规划提供了实用解决方案。

Abstract: Precise 3D segmentation of cerebral vasculature from T1-weighted contrast-enhanced (T1CE) MRI is crucial for safe neurosurgical planning. Manual delineation is time-consuming and prone to inter-observer variability, while current automated methods often trade accuracy for computational cost, limiting clinical use. We present NeuroVascU-Net, the first deep learning architecture specifically designed to segment cerebrovascular structures directly from clinically standard T1CE MRI in neuro-oncology patients, addressing a gap in prior work dominated by TOF-MRA-based approaches. NeuroVascU-Net builds on a dilated U-Net and integrates two specialized modules: a Multi-Scale Contextual Feature Fusion ($MSC^2F$) module at the bottleneck and a Cross-Domain Adaptive Feature Fusion ($CDA^2F$) module at deeper hierarchical layers. $MSC^2F$ captures both local and global information via multi-scale dilated convolutions, while $CDA^2F$ dynamically integrates domain-specific features, enhancing representation while keeping computation low. The model was trained and validated on a curated dataset of T1CE scans from 137 brain tumor biopsy patients, annotated by a board-certified functional neurosurgeon. NeuroVascU-Net achieved a Dice score of 0.8609 and precision of 0.8841, accurately segmenting both major and fine vascular structures. Notably, it requires only 12.4M parameters, significantly fewer than transformer-based models such as Swin U-NetR. This balance of accuracy and efficiency positions NeuroVascU-Net as a practical solution for computer-assisted neurosurgical planning.

</details>


### [146] [CrossJEPA: Cross-Modal Joint-Embedding Predictive Architecture for Efficient 3D Representation Learning from 2D Images](https://arxiv.org/abs/2511.18424)
*Avishka Perera,Kumal Hewagamage,Saeedha Nazar,Kavishka Abeywardana,Hasitha Gallella,Ranga Rodrigo,Mohamed Afham*

Main category: cs.CV

TL;DR: CrossJEPA是一个简单的跨模态联合嵌入预测架构，利用图像基础模型的知识，通过预测2D视图嵌入来学习3D点云表示，在保持高性能的同时显著降低了计算成本和训练时间。


<details>
  <summary>Details</summary>
Motivation: 解决当前利用2D数据进行3D表示学习的方法模型过大、训练缓慢的问题，探索JEPA架构在跨模态学习中的应用潜力，打破JEPA必须依赖掩码的误解。

Method: 提出CrossJEPA架构，利用冻结的图像基础模型作为教师网络，训练一个预测器来从3D点云推断对应的2D视图嵌入，采用跨域投影信息来净化监督信号，并引入一次性目标嵌入缓存机制提高效率。

Result: 在ModelNet40上达到94.2%的线性探测准确率，在ScanObjectNN上达到88.3%，仅使用1410万预训练参数（点编码器850万参数），在单GPU上约6小时完成预训练。

Conclusion: CrossJEPA是一个高性能、内存高效且训练快速的3D表示学习框架，通过知识蒸馏实现了新的最先进性能，为资源受限环境下的3D学习提供了可行方案。

Abstract: Image-to-point cross-modal learning has emerged to address the scarcity of large-scale 3D datasets in 3D representation learning. However, current methods that leverage 2D data often result in large, slow-to-train models, making them computationally expensive and difficult to deploy in resource-constrained environments. The architecture design of such models is therefore critical, determining their performance, memory footprint, and compute efficiency. The Joint-embedding Predictive Architecture (JEPA) has gained wide popularity in self-supervised learning for its simplicity and efficiency, but has been under-explored in cross-modal settings, partly due to the misconception that masking is intrinsic to JEPA. In this light, we propose CrossJEPA, a simple Cross-modal Joint Embedding Predictive Architecture that harnesses the knowledge of an image foundation model and trains a predictor to infer embeddings of specific rendered 2D views from corresponding 3D point clouds, thereby introducing a JEPA-style pretraining strategy beyond masking. By conditioning the predictor on cross-domain projection information, CrossJEPA purifies the supervision signal from semantics exclusive to the target domain. We further exploit the frozen teacher design with a one-time target embedding caching mechanism, yielding amortized efficiency. CrossJEPA achieves a new state-of-the-art in linear probing on the synthetic ModelNet40 (94.2%) and the real-world ScanObjectNN (88.3%) benchmarks, using only 14.1M pretraining parameters (8.5M in the point encoder), and about 6 pretraining hours on a standard single GPU. These results position CrossJEPA as a performant, memory-efficient, and fast-to-train framework for 3D representation learning via knowledge distillation. We analyze CrossJEPA intuitively, theoretically, and empirically, and extensively ablate our design choices. Code will be made available.

</details>


### [147] [LungX: A Hybrid EfficientNet-Vision Transformer Architecture with Multi-Scale Attention for Accurate Pneumonia Detection](https://arxiv.org/abs/2511.18425)
*Mansur Yerzhanuly*

Main category: cs.CV

TL;DR: LungX是一种结合EfficientNet多尺度特征、CBAM注意力机制和Vision Transformer全局上下文建模的新型混合架构，用于肺炎检测，在20,000张胸部X光片上达到86.5%准确率和0.943 AUC的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 肺炎是全球主要死亡原因，及时诊断至关重要。现有方法在肺炎检测性能上仍有提升空间。

Method: 提出LungX混合架构，结合EfficientNet的多尺度特征提取、CBAM注意力机制和Vision Transformer的全局上下文建模能力。

Result: 在RSNA和CheXpert的20,000张胸部X光片上评估，达到86.5%准确率和0.943 AUC，比EfficientNet-B0基线提升6.7% AUC。可视化分析显示通过可解释注意力图实现更好的病灶定位。

Conclusion: LungX在肺炎检测方面表现出色，未来方向包括多中心验证和针对临床部署的架构优化，目标达到88%准确率作为AI诊断辅助工具。

Abstract: Pneumonia remains a leading global cause of mortality where timely diagnosis is critical. We introduce LungX, a novel hybrid architecture combining EfficientNet's multi-scale features, CBAM attention mechanisms, and Vision Transformer's global context modeling for enhanced pneumonia detection. Evaluated on 20,000 curated chest X-rays from RSNA and CheXpert, LungX achieves state-of-the-art performance (86.5 percent accuracy, 0.943 AUC), representing a 6.7 percent AUC improvement over EfficientNet-B0 baselines. Visual analysis demonstrates superior lesion localization through interpretable attention maps. Future directions include multi-center validation and architectural optimizations targeting 88 percent accuracy for clinical deployment as an AI diagnostic aid.

</details>


### [148] [DocPTBench: Benchmarking End-to-End Photographed Document Parsing and Translation](https://arxiv.org/abs/2511.18434)
*Yongkun Du,Pinxuan Chen,Xuye Ying,Zhineng Chen*

Main category: cs.CV

TL;DR: DocPTBench是一个专门为拍摄文档解析和翻译设计的基准测试，包含1300多张高分辨率拍摄文档，揭示了现有模型在处理真实世界拍摄文档时的性能显著下降问题。


<details>
  <summary>Details</summary>
Motivation: 现有的文档解析和翻译基准测试主要基于扫描或数字生成的文档，无法充分反映真实世界拍摄条件（如几何畸变和光度变化）带来的复杂挑战。

Method: 构建了包含1300多张高分辨率拍摄文档的DocPTBench基准测试，涵盖多个领域和八种翻译场景，并提供人工验证的解析和翻译标注。

Result: 实验表明，从数字文档转换到拍摄文档时，流行MLLM在端到端解析中的准确率平均下降18%，翻译准确率下降12%，而专用文档解析模型的平均性能下降高达25%。

Conclusion: 真实世界拍摄条件对文档解析和翻译提出了独特挑战，现有模型的鲁棒性有限，DocPTBench为评估和改进模型性能提供了重要基准。

Abstract: The advent of Multimodal Large Language Models (MLLMs) has unlocked the potential for end-to-end document parsing and translation. However, prevailing benchmarks such as OmniDocBench and DITrans are dominated by pristine scanned or digital-born documents, and thus fail to adequately represent the intricate challenges of real-world capture conditions, such as geometric distortions and photometric variations. To fill this gap, we introduce DocPTBench, a comprehensive benchmark specifically designed for Photographed Document Parsing and Translation. DocPTBench comprises over 1,300 high-resolution photographed documents from multiple domains, includes eight translation scenarios, and provides meticulously human-verified annotations for both parsing and translation. Our experiments demonstrate that transitioning from digital-born to photographed documents results in a substantial performance decline: popular MLLMs exhibit an average accuracy drop of 18% in end-to-end parsing and 12% in translation, while specialized document parsing models show significant average decrease of 25%. This substantial performance gap underscores the unique challenges posed by documents captured in real-world conditions and reveals the limited robustness of existing models. Dataset and code are available at https://github.com/Topdu/DocPTBench.

</details>


### [149] [When Generative Replay Meets Evolving Deepfakes: Domain-Aware Relative Weighting for Incremental Face Forgery Detection](https://arxiv.org/abs/2511.18436)
*Hao Shen,Jikang Cheng,Renye Yan,Zhongyuan Wang,Wei Peng,Baojin Huang*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的域感知相对加权策略（DARW），用于解决伪造检测中生成重放方法的局限性，通过区分域安全样本和域风险样本来提升增量学习性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于样本重放的增量伪造检测方法存在多样性低和隐私问题，生成重放虽能合成历史数据但其在伪造检测中的可行性尚不明确。

Method: 提出DARW策略：对域安全样本直接监督，对域风险样本应用相对分离损失来平衡监督和潜在混淆，并通过域混淆分数动态调整权衡。

Result: 大量实验表明，DARW在不同生成重放设置下 consistently 提升伪造检测的增量学习性能，并缓解域重叠的不利影响。

Conclusion: DARW策略有效解决了生成重放在伪造检测中的挑战，为增量学习提供了可行的解决方案。

Abstract: The rapid advancement of face generation techniques has led to a growing variety of forgery methods. Incremental forgery detection aims to gradually update existing models with new forgery data, yet current sample replay-based methods are limited by low diversity and privacy concerns. Generative replay offers a potential solution by synthesizing past data, but its feasibility for forgery detection remains unclear. In this work, we systematically investigate generative replay and identify two scenarios: when the replay generator closely resembles the new forgery model, generated real samples blur the domain boundary, creating domain-risky samples; when the replay generator differs significantly, generated samples can be safely supervised, forming domain-safe samples. To exploit generative replay effectively, we propose a novel Domain-Aware Relative Weighting (DARW) strategy. DARW directly supervises domain-safe samples while applying a Relative Separation Loss to balance supervision and potential confusion for domain-risky samples. A Domain Confusion Score dynamically adjusts this tradeoff according to sample reliability. Extensive experiments demonstrate that DARW consistently improves incremental learning performance for forgery detection under different generative replay settings and alleviates the adverse impact of domain overlap.

</details>


### [150] [Perceptual-Evidence Anchored Reinforced Learning for Multimodal Reasoning](https://arxiv.org/abs/2511.18437)
*Chi Zhang,Haibo Qiu,Qiming Zhang,Yufei Xu,Zhixiong Zeng,Siqi Yang,Peng Shi,Lin Ma,Jing Zhang*

Main category: cs.CV

TL;DR: PEARL提出了一种双分支的感知-推理协同方法，通过将多模态推理显式锚定到已验证的视觉证据来解决传统RLVR在视觉语言模型中忽视视觉感知验证的问题。


<details>
  <summary>Details</summary>
Motivation: 传统的RLVR方法在视觉语言模型中只验证最终文本输出，忽视了视觉感知的基础步骤，导致视觉幻觉和奖励黑客问题。推理建立在有缺陷的感知基础上是不可靠的。

Method: PEARL为每个推理导向的QA实例首先生成一个感知检查清单——一组具有可验证答案的感知导向子问题，用于探测模型对关键视觉证据的理解。训练过程中，通过该检查清单的辅助rollout产生感知奖励，既直接增强模型的感知能力，又作为推理的保真度门控。

Result: 综合实验显示PEARL在多模态推理基准上取得显著提升，例如在MathVerse上比基线提高9.7%，比GRPO提高6.6%。

Conclusion: PEARL通过感知-推理协同机制有效解决了视觉语言模型中的感知验证问题，显著提升了多模态推理性能，并能与主流RL方法无缝集成。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has significantly advanced the reasoning capabilities of Large Language Models (LLMs) and is now being applied to Vision-Language Models (VLMs). However, vanilla RLVR for VLMs verifies only the final textual output, critically neglecting the foundational step of visual perception. This oversight leads to visual hallucinations and reward hacking, as reasoning built upon flawed perception is inherently unreliable. To address this, we propose PEARL (Perceptual-Evidence Anchored Reinforced Learning), a dual-branch, perception-reasoning synergistic that strengthens multimodal reasoning by explicitly anchoring it to verified visual evidence. For each reasoning-oriented QA instance, PEARL first derive a perception checklist -- a set of perception-oriented sub-questions with verifiable answers that probe the model's understanding of key visual evidence. During training, auxiliary rollouts on this checklist yield a perceptual reward that both directly reinforces the model's perception ability and acts as a fidelity gate for reasoning. If the model passes the perception check, its policy update is biased towards evidence-anchored reasoning. Otherwise, the process is halted to prevent reasoning from flawed premises. PEARL can be seamlessly integrated with popular RL methods like GRPO and DAPO. Comprehensive experiments show PEARL achieves substantial gains on multimodal reasoning benchmarks, e.g., a +9.7% improvement over the baseline and +6.6% over GRPO on MathVerse.

</details>


### [151] [ReCoGS: Real-time ReColoring for Gaussian Splatting scenes](https://arxiv.org/abs/2511.18441)
*Lorenzo Rutayisire,Nicola Capodieci,Fabio Pellacini*

Main category: cs.CV

TL;DR: 本文提出了一种用于高斯泼溅场景的实时交互式重新着色方法，解决了现有方法在视图一致性、细粒度控制和计算效率方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 高斯泼溅已成为新颖视图合成的主要方法，但在编辑任务（如重新着色）中，现有方法常受限于视图不一致性、缺乏细粒度控制和高计算需求。

Method: 引入用户友好的流水线，支持在预训练高斯泼溅场景中精确选择和重新着色区域，并开发了交互式工具以展示实时性能。

Result: 该方法实现了实时交互式重新着色，代码已开源。

Conclusion: 所提出的方法为高斯泼溅场景的编辑任务提供了高效、精确的解决方案，特别适用于重新着色应用。

Abstract: Gaussian Splatting has emerged as a leading method for novel view synthesis, offering superior training efficiency and real-time inference compared to NeRF approaches, while still delivering high-quality reconstructions. Beyond view synthesis, this 3D representation has also been explored for editing tasks. Many existing methods leverage 2D diffusion models to generate multi-view datasets for training, but they often suffer from limitations such as view inconsistencies, lack of fine-grained control, and high computational demand. In this work, we focus specifically on the editing task of recoloring. We introduce a user-friendly pipeline that enables precise selection and recoloring of regions within a pre-trained Gaussian Splatting scene. To demonstrate the real-time performance of our method, we also present an interactive tool that allows users to experiment with the pipeline in practice. Code is available at https://github.com/loryruta/recogs.

</details>


### [152] [SineProject: Machine Unlearning for Stable Vision Language Alignment](https://arxiv.org/abs/2511.18444)
*Arpit Garg,Hemanth Saratchandran,Simon Lucey*

Main category: cs.CV

TL;DR: SineProject通过正弦调制参数改善多模态大语言模型在遗忘特定知识时的视觉语言对齐稳定性，减少良性查询拒绝并实现目标信息的完全遗忘。


<details>
  <summary>Details</summary>
Motivation: 现有遗忘方法在遗忘不安全或隐私信息时容易破坏视觉语言对齐，导致模型拒绝良性查询，这源于投影器网络在遗忘过程中雅可比矩阵的病态问题。

Method: 提出SineProject方法，在冻结的投影器基础上添加正弦调制的可训练参数，改善雅可比矩阵的谱条件数，稳定跨模态嵌入对齐。

Result: 在LLaVA v1.5 7B和13B模型上的安全性和隐私遗忘基准测试中，SineProject显著减少良性查询拒绝率，同时完全遗忘目标信息，达到最先进的遗忘-保留权衡。

Conclusion: SineProject以可忽略的计算开销实现了多模态大语言模型知识遗忘过程中的稳定对齐和优异性能。

Abstract: Multimodal Large Language Models (MLLMs) increasingly need to forget specific knowledge such as unsafe or private information without requiring full retraining. However, existing unlearning methods often disrupt vision language alignment, causing models to reject both harmful and benign queries. We trace this failure to the projector network during unlearning, its Jacobian becomes severely illconditioned, leading to unstable optimization and drift in cross modal embeddings. We introduce SineProject, a simple method that augments the frozen projector with sinusoidally modulated trainable parameters, improving the Jacobian's spectral conditioning and stabilizing alignment throughout unlearning. Across standard safety and privacy unlearning benchmarks using LLaVA v1.5 7B and 13B, SineProject reduces benign query refusals while achieving complete forgetting of targeted information, yielding state of the art forget retain trade offs with negligible computational overhead.

</details>


### [153] [EventBench: Towards Comprehensive Benchmarking of Event-based MLLMs](https://arxiv.org/abs/2511.18448)
*Shaoyu Liu,Jianing Li,Guanghui Zhao,Yunjian Zhang,Xiangyang Ji*

Main category: cs.CV

TL;DR: EventBench是一个用于评估多模态大语言模型在事件视觉领域能力的统一基准，包含8个任务指标和大规模事件流数据集，评估显示当前事件型MLLMs在细粒度识别和空间推理方面仍存在挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的基于事件的视觉基准缺乏统一评估框架，EventBench旨在填补这一空白，提供全面的能力评估。

Method: 设计包含8个多样化任务指标的基准，涵盖理解、识别和空间推理任务，并配套超过100万事件-文本对的大规模训练集。

Result: 评估显示当前事件型MLLMs在事件流理解方面表现强劲，但在细粒度识别和3D空间推理方面仍有困难。

Conclusion: EventBench为事件型MLLMs提供了首个统一评估框架，揭示了当前模型在空间推理和细粒度识别方面的局限性，为未来研究指明了方向。

Abstract: Multimodal large language models (MLLMs) have made significant advancements in event-based vision, yet the comprehensive evaluation of their capabilities within a unified benchmark remains largely unexplored. In this work, we introduce EventBench, a benchmark that offers eight diverse task metrics together with a large-scale event stream dataset. EventBench differs from existing event-based benchmarks in four key aspects: (1) openness in accessibility, releasing all raw event streams and task instructions across eight evaluation metrics; (2) diversity in task coverage, spanning understanding, recognition, and spatial reasoning tasks for comprehensive capability assessment; (3) integration in spatial dimensions, pioneering the design of 3D spatial reasoning tasks for event-based MLLMs; and (4) scale in data volume, with an accompanying training set of over one million event-text pairs supporting large-scale training and evaluation. Using EventBench, we evaluate state-of-the-art closed-source models such as GPT-5 and Gemini-2.5 Pro, leading open-source models including Qwen2.5-VL and InternVL3, and event-based MLLMs such as EventGPT that directly process raw event streams. Extensive evaluation reveals that while current event-based MLLMs demonstrate strong performance in event stream understanding, they continue to struggle with fine-grained recognition and spatial reasoning.

</details>


### [154] [NAF: Zero-Shot Feature Upsampling via Neighborhood Attention Filtering](https://arxiv.org/abs/2511.18452)
*Loick Chambon,Paul Couairon,Eloi Zablocki,Alexandre Boulch,Nicolas Thome,Matthieu Cord*

Main category: cs.CV

TL;DR: NAF是一种零样本视觉基础模型特征上采样方法，通过跨尺度邻域注意力和旋转位置编码学习自适应权重，无需重新训练即可提升任何VFM的特征分辨率，在多个下游任务中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决视觉基础模型特征空间下采样带来的像素级任务挑战，平衡传统固定滤波器与现代可学习上采样器之间的速度-精度权衡。

Method: 使用Cross-Scale Neighborhood Attention和Rotary Position Embeddings学习自适应空间和内容权重，仅依赖高分辨率输入图像作为指导，实现VFM无关的零样本上采样。

Result: 在多个下游任务中超越VFM特定上采样器，达到最先进性能，支持2K特征图高效处理，18FPS重建中间分辨率图，并在图像恢复任务中表现优异。

Conclusion: NAF首次实现了VFM无关的上采样架构，在保持高效率的同时显著提升性能，展示了在特征上采样和图像恢复等多任务中的强大泛化能力。

Abstract: Vision Foundation Models (VFMs) extract spatially downsampled representations, posing challenges for pixel-level tasks. Existing upsampling approaches face a fundamental trade-off: classical filters are fast and broadly applicable but rely on fixed forms, while modern upsamplers achieve superior accuracy through learnable, VFM-specific forms at the cost of retraining for each VFM. We introduce Neighborhood Attention Filtering (NAF), which bridges this gap by learning adaptive spatial-and-content weights through Cross-Scale Neighborhood Attention and Rotary Position Embeddings (RoPE), guided solely by the high-resolution input image. NAF operates zero-shot: it upsamples features from any VFM without retraining, making it the first VFM-agnostic architecture to outperform VFM-specific upsamplers and achieve state-of-the-art performance across multiple downstream tasks. It maintains high efficiency, scaling to 2K feature maps and reconstructing intermediate-resolution maps at 18 FPS. Beyond feature upsampling, NAF demonstrates strong performance on image restoration, highlighting its versatility. Code and checkpoints are available at https://github.com/valeoai/NAF.

</details>


### [155] [RegDeepLab: A Two-Stage Decoupled Framework for Interpretable Embryo Fragmentation Grading](https://arxiv.org/abs/2511.18454)
*Ming-Jhe Lee*

Main category: cs.CV

TL;DR: 该研究提出RegDeepLab框架，通过双分支多任务学习结合语义分割和回归任务，解决胚胎碎片化自动分级中视觉可解释性和精度难以兼顾的问题，并采用两阶段解耦训练策略避免多任务训练中的梯度冲突。


<details>
  <summary>Details</summary>
Motivation: 当前IVF胚胎碎片化手动分级存在耗时、主观性强的问题，现有深度学习方案要么缺乏视觉可解释性（纯回归模型），要么难以直接转换为临床分级（纯分割模型）。

Method: 提出RegDeepLab双分支多任务学习框架，集成DeepLabV3+分割网络和多尺度回归头；设计两阶段解耦训练策略解决梯度冲突；引入范围损失实现半监督学习。

Result: 端到端多任务训练可实现最小分级误差（MAE=0.046），但分割边界完整性受损；解耦策略在保持SOTA分割精度（Dice=0.729）的同时提供稳健的高精度分级预测。

Conclusion: 该研究最终提出了一个兼具高精度和视觉可解释性的双模块临床辅助解决方案。

Abstract: The degree of embryo fragmentation serves as a critical morphological indicator for assessing embryo developmental potential in In Vitro Fertilization (IVF) clinical decision-making. However, current manual grading processes are not only time-consuming but also limited by significant inter-observer variability and efficiency bottlenecks. Although deep learning has demonstrated potential in automated grading in recent years, existing solutions face a significant challenge: pure regression models lack the visual explainability required for clinical practice, while pure segmentation models struggle to directly translate pixel-level masks into precise clinical grades. This study proposes RegDeepLab, a dual-branch Multi-Task Learning (MTL) framework that integrates State-of-the-Art (SOTA) semantic segmentation (DeepLabV3+) with a multi-scale regression head. Addressing the common issues of "Gradient Conflict" and "Negative Transfer" in multi-task training, we propose a "Two-Stage Decoupled Training Strategy." Experimental results demonstrate that while standard end-to-end MTL training can minimize grading error (MAE=0.046) through our designed "Feature Injection" mechanism, it compromises the integrity of segmentation boundaries. In contrast, our decoupled strategy successfully provides robust and high-precision grading predictions while preserving SOTA-level segmentation accuracy (Dice=0.729). Furthermore, we introduce a "Range Loss" to effectively utilize large-scale discrete grading data for semi-supervised learning. This study ultimately presents a dual-module clinical auxiliary solution that combines high accuracy with visual explainability.

</details>


### [156] [Alternating Perception-Reasoning for Hallucination-Resistant Video Understanding](https://arxiv.org/abs/2511.18463)
*Bowei Pu,Chuanbin Liu,Yifan Ge,Peichen Zhou,Yiwei Sun,Zhiyin Lu,Jiankang Wang,Hongtao Xie*

Main category: cs.CV

TL;DR: 该论文提出了一种新的视频推理框架Video-PLR，通过感知循环推理范式和反幻觉奖励机制，解决了现有视频推理大模型中存在的感知捷径和幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 现有视频推理大模型采用单步感知范式，存在证据不足和幻觉风险的问题。作者旨在通过循环感知和反幻觉机制来提升视频推理的准确性和可靠性。

Method: 1. 感知循环推理(PLR)范式：将视频描述分解为多个循环，每个循环要求模型描述带精确时间戳的视频片段并分析，然后决定下一步动作；2. 事实感知评估器(FAE)：作为反幻觉奖励机制，评估每个感知结果的可靠性；3. 使用AnetHallu-117K数据集训练FAE。

Result: 实验表明，Video-PLR在3B和7B参数规模下均达到最先进水平，并具有最佳的数据效率。FAE的性能与GPT-4o相当。

Conclusion: 该框架通过循环感知和反幻觉机制有效解决了视频推理中的证据不足和幻觉问题，为视频推理大模型的发展提供了新思路。

Abstract: Sufficient visual perception is the foundation of video reasoning. Nevertheless, existing Video Reasoning LLMs suffer from perception shortcuts, relying on a flawed single-step perception paradigm. This paradigm describes the video and then conducts reasoning, which runs the risk of insufficient evidence and emergent hallucinations. To address these issues, we introduce a new framework that integrates a loop-based paradigm with an anti-hallucination reward. First, to address the insufficient evidence, we introduce the Perception Loop Reasoning (PLR) paradigm. Instead of describing the video at once, each loop requires the model to describe a video segment with precise timestamps, analyze this segment, and decide the next action. Second, for the risk of hallucinations, the Factual-Aware Evaluator (FAE) evaluates each perception result as a reliable anti-hallucination reward. This reward encourages the model to provide sufficient and precise video evidence. Our FAE, which performs comparably to GPT-4o, is tuned on our AnetHallu-117K, a large-scale hallucination judgment preference dataset. Extensive experiments show that our Video-PLR achieves the state-of-the-art in both 3B and 7B parameter scales and has the best data efficiency. Our code, models, and datasets are released on: https://github.com/BoweiPu/VideoPLR.

</details>


### [157] [Gaze Beyond the Frame: Forecasting Egocentric 3D Visual Span](https://arxiv.org/abs/2511.18470)
*Heeseung Yun,Joonil Na,Jaeyeon Kim,Calvin Murdock,Gunhee Kim*

Main category: cs.CV

TL;DR: 该论文提出了EgoSpanLift方法，将自我中心视角的视觉跨度预测从2D图像平面提升到3D场景，通过结合3D U-Net和单向transformer实现时空融合，在3D网格中预测未来的视觉注意力区域。


<details>
  <summary>Details</summary>
Motivation: 虽然现有研究主要关注运动和接触交互，但预测人类视觉感知本身仍然较少探索，尽管它在指导人类行为和AR/VR、辅助技术中具有重要作用。

Method: EgoSpanLift将SLAM关键点转换为与注视兼容的几何形状，提取体积视觉跨度区域，并与3D U-Net和单向transformer结合进行时空融合预测。

Result: 该方法在自我中心2D注视预测和3D定位任务上优于竞争基线，即使投影回2D图像平面也能获得可比结果，无需额外的2D特定训练。

Conclusion: EgoSpanLift成功实现了从2D到3D的视觉跨度预测转换，为自我中心视觉感知预测提供了新的解决方案和基准测试平台。

Abstract: People continuously perceive and interact with their surroundings based on underlying intentions that drive their exploration and behaviors. While research in egocentric user and scene understanding has focused primarily on motion and contact-based interaction, forecasting human visual perception itself remains less explored despite its fundamental role in guiding human actions and its implications for AR/VR and assistive technologies. We address the challenge of egocentric 3D visual span forecasting, predicting where a person's visual perception will focus next within their three-dimensional environment. To this end, we propose EgoSpanLift, a novel method that transforms egocentric visual span forecasting from 2D image planes to 3D scenes. EgoSpanLift converts SLAM-derived keypoints into gaze-compatible geometry and extracts volumetric visual span regions. We further combine EgoSpanLift with 3D U-Net and unidirectional transformers, enabling spatio-temporal fusion to efficiently predict future visual span in the 3D grid. In addition, we curate a comprehensive benchmark from raw egocentric multisensory data, creating a testbed with 364.6K samples for 3D visual span forecasting. Our approach outperforms competitive baselines for egocentric 2D gaze anticipation and 3D localization while achieving comparable results even when projected back onto 2D image planes without additional 2D-specific training.

</details>


### [158] [Robust Posterior Diffusion-based Sampling via Adaptive Guidance Scale](https://arxiv.org/abs/2511.18471)
*Liav Hen,Tom Tirer,Raja Giryes,Shady Abu-Hussein*

Main category: cs.CV

TL;DR: 提出了自适应后验扩散采样方法，通过自适应调整似然步长来平衡扩散先验和数据保真度，在多种图像重建任务中提升重建质量


<details>
  <summary>Details</summary>
Motivation: 解决扩散模型在逆问题中先验项与数据保真度之间的平衡问题，避免过度激进的似然更新引入伪影或保守更新导致收敛缓慢

Method: 基于两个不同中间似然梯度近似之间的一致性，开发了观测相关的加权方案，自适应调整扩散过程，无需超参数调优

Result: 在CelebA-HQ和ImageNet-256验证集上，包括超分辨率、高斯去模糊和运动去模糊等任务中，均优于现有扩散基线方法

Conclusion: AdaPS方法在感知质量上持续超越现有方法，失真损失最小或无损失，且对扩散步数、观测噪声水平和随机性变化具有鲁棒性

Abstract: Diffusion models have recently emerged as powerful generative priors for solving inverse problems, achieving state-of-the-art results across various imaging tasks. A central challenge in this setting lies in balancing the contribution of the prior with the data fidelity term: overly aggressive likelihood updates may introduce artifacts, while conservative updates can slow convergence or yield suboptimal reconstructions. In this work, we propose an adaptive likelihood step-size strategy to guide the diffusion process for inverse-problem formulations. Specifically, we develop an observation-dependent weighting scheme based on the agreement between two different approximations of the intractable intermediate likelihood gradients, that adapts naturally to the diffusion schedule, time re-spacing, and injected stochasticity. The resulting approach, Adaptive Posterior diffusion Sampling (AdaPS), is hyperparameter-free and improves reconstruction quality across diverse imaging tasks - including super-resolution, Gaussian deblurring, and motion deblurring - on CelebA-HQ and ImageNet-256 validation sets. AdaPS consistently surpasses existing diffusion-based baselines in perceptual quality with minimal or no loss in distortion, without any task-specific tuning. Extensive ablation studies further demonstrate its robustness to the number of diffusion steps, observation noise levels, and varying stochasticity.

</details>


### [159] [Uncertainty Quantification in HSI Reconstruction using Physics-Aware Diffusion Priors and Optics-Encoded Measurements](https://arxiv.org/abs/2511.18473)
*Juan Romero,Qiang Fu,Matteo Ravasi,Wolfgang Heidrich*

Main category: cs.CV

TL;DR: HSDiff是一个基于贝叶斯推理的高光谱图像重建框架，使用像素级扩散先验和后验扩散采样生成多样化的高光谱样本，解决了现有方法因数据集光谱多样性不足导致的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 当前数据驱动方法由于现有高光谱图像数据集缺乏光谱多样性，在评估同色异谱现象时容易产生幻觉，需要更可靠的解决方案。

Method: 提出HSDiff框架，利用无条件训练的像素级扩散先验和后验扩散采样；采用增强的同色异谱增强技术，包括基于区域的同色异谱黑和分区联合光谱上采样；通过有效光谱编码引导后验分布。

Result: HSDiff能够生成与各种高光谱成像模型测量结果一致的高光谱样本，提供校准的信息不确定性，展示了有效光谱编码在快照高光谱成像中的重要性。

Conclusion: HSDiff提供了一个完整的高性能不确定性感知高光谱图像重建方法，通过贝叶斯框架验证了有效光谱编码的关键作用。

Abstract: Hyperspectral image reconstruction from a compressed measurement is a highly ill-posed inverse problem. Current data-driven methods suffer from hallucination due to the lack of spectral diversity in existing hyperspectral image datasets, particularly when they are evaluated for the metamerism phenomenon. In this work, we formulate hyperspectral image (HSI) reconstruction as a Bayesian inference problem and propose a framework, HSDiff, that utilizes an unconditionally trained, pixel-level diffusion prior and posterior diffusion sampling to generate diverse HSI samples consistent with the measurements of various hyperspectral image formation models. We propose an enhanced metameric augmentation technique using region-based metameric black and partition-of-union spectral upsampling to expand training with physically valid metameric spectra, strengthening the prior diversity and improving uncertainty calibration. We utilize HSDiff to investigate how the studied forward models shape the posterior distribution and demonstrate that guiding with effective spectral encoding provides calibrated informative uncertainty compared to non-encoded models. Through the lens of the Bayesian framework, HSDiff offers a complete, high-performance method for uncertainty-aware HSI reconstruction. Our results also reiterate the significance of effective spectral encoding in snapshot hyperspectral imaging.

</details>


### [160] [Extreme Model Compression for Edge Vision-Language Models: Sparse Temporal Token Fusion and Adaptive Neural Compression](https://arxiv.org/abs/2511.18504)
*Md Tasnin Tanvir,Soumitra Das,Sk Md Abidar Rahaman,Ali Shiri Sichani*

Main category: cs.CV

TL;DR: 本文提出两种自适应压缩技术STTF和ANC，用于在资源受限的边缘设备上实现高效的视觉语言任务，在保持高精度的同时显著减少计算量和参数数量。


<details>
  <summary>Details</summary>
Motivation: 边缘AI对视觉语言任务的需求日益增长，但现有模型难以在资源受限的设备上实现实时性能，需要新的压缩技术来平衡计算效率和模型能力。

Method: 提出Sparse Temporal Token Fusion (STTF)通过事件驱动变化检测动态重用视觉token，以及Adaptive Neural Compression (ANC)通过学习路由器条件激活编码器分支，实现细粒度的场景复杂度适应。

Result: TinyGPT-STTF在COCO 2017测试集上达到CIDEr 131.2，超越LLaVA-1.5 7B 17.6个点，参数减少2.3倍，FLOPs减少62倍；STTF在事件视觉任务中减少84% token数量，保持95.6%准确率；ANC在低运动场景中减少90% FLOPs。

Conclusion: 所提方法显著提升了边缘设备上视觉语言模型的部署效率，在保持高精度的同时实现了大幅的计算优化，为实际边缘应用提供了可行的解决方案。

Abstract: The demand for edge AI in vision-language tasks requires models that achieve real-time performance on resource-constrained devices with limited power and memory. This paper proposes two adaptive compression techniques -- Sparse Temporal Token Fusion (STTF) and Adaptive Neural Compression (ANC) -- that integrate algorithmic innovations with hardware-aware optimizations. Unlike previous approaches relying on static pruning or uniform scaling, STTF dynamically reuses visual tokens through event-driven change detection, while ANC conditionally activates encoder branches via a learned router, enabling fine-grained adaptation to scene complexity. Our 3B-parameter TinyGPT-STTF achieves CIDEr 131.2, BLEU-4 0.38, METEOR 0.31, and ROUGE-L 0.56 on the COCO 2017 test set, surpassing LLaVA-1.5 7B by 17.6 CIDEr points while using 2.3x fewer parameters and 62x fewer on-device FLOPs. TinyGPT-ANC reaches CIDEr 128.5. On event-based vision tasks, STTF reduces average token count by 84% (from 196 to 31 tokens) while preserving 95.6% accuracy on the DVS128 Gesture dataset, and ANC cuts FLOPs by up to 90% in low-motion scenes. Compared to strong baselines, our models improve accuracy by up to 4.4% and reduce latency by up to 13x. These results enable efficient deployment of capable vision-language models on real-world edge devices.

</details>


### [161] [Multimodal Continual Learning with MLLMs from Multi-scenario Perspectives](https://arxiv.org/abs/2511.18507)
*Kai Jiang,Siqi Huang,Xiangyu Chen,Jiawei Shao,Hongyuan Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: 本文提出UNIFIER方法来解决多模态大语言模型在视觉理解中的灾难性遗忘问题，通过构建包含四种不同场景的多模态视觉理解数据集MSVQA，并采用视觉信息解耦和一致性约束来保持跨场景的视觉表示稳定性。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在部署到设备上时需要持续适应下游任务中的动态场景变化（如背景和视角变化），以有效执行复杂的视觉任务，但面临灾难性遗忘问题。

Method: 提出UNIFIER方法，将不同场景的视觉信息解耦到每个视觉块的不同分支中，并将它们投影到相同的特征空间。通过一致性约束来保持跨场景视觉表示的稳定性。

Result: 在MSVQA数据集上的大量实验表明，UNIFIER有效缓解了跨场景任务的遗忘问题，并在同一场景内实现了知识积累。

Conclusion: UNIFIER方法能够有效解决多模态大语言模型在动态场景变化下的持续学习问题，为实际部署提供了可行的解决方案。

Abstract: Continual learning in visual understanding aims to deal with catastrophic forgetting in Multimodal Large Language Models (MLLMs). MLLMs deployed on devices have to continuously adapt to dynamic scenarios in downstream tasks, such as variations in background and perspective, to effectively perform complex visual tasks. To this end, we construct a multimodal visual understanding dataset (MSVQA) encompassing four different scenarios and perspectives including high altitude, underwater, low altitude and indoor, to investigate the catastrophic forgetting in MLLMs under the dynamics of scenario shifts in real-world data streams. Furthermore, we propose mUltimodal coNtInual learning with MLLMs From multi-scenarIo pERspectives (UNIFIER) to address visual discrepancies while learning different scenarios. Specifically, it decouples the visual information from different scenarios into distinct branches within each vision block and projects them into the same feature space. A consistency constraint is imposed on the features of each branch to maintain the stability of visual representations across scenarios. Extensive experiments on the MSVQA dataset demonstrate that UNIFIER effectively alleviates forgetting of cross-scenario tasks and achieves knowledge accumulation within the same scenario.

</details>


### [162] [LRDUN: A Low-Rank Deep Unfolding Network for Efficient Spectral Compressive Imaging](https://arxiv.org/abs/2511.18513)
*He Huang,Yujun Guo,Wei He*

Main category: cs.CV

TL;DR: 提出LRDUN网络，通过低秩分解和广义特征展开机制解决光谱压缩成像重建中的计算冗余和病态问题，在降低计算成本的同时实现SOTA重建质量


<details>
  <summary>Details</summary>
Motivation: 现有深度展开网络直接在高维HSI上操作，存在计算冗余且难以将2D残差映射回3D HSI空间的病态问题

Method: 提出两种基于低秩分解的成像模型，开发LRDUN网络在展开的PGD框架中联合求解两个子问题，引入GFUM机制解耦物理秩和特征维度

Result: 在模拟和真实数据集上的实验表明，LRDUN实现了最先进的重建质量，同时显著降低了计算成本

Conclusion: 通过低秩分解和广义特征展开机制，LRDUN有效缓解了光谱压缩成像重建的病态问题，在保证重建质量的同时大幅提升计算效率

Abstract: Deep unfolding networks (DUNs) have achieved remarkable success and become the mainstream paradigm for spectral compressive imaging (SCI) reconstruction. Existing DUNs are derived from full-HSI imaging models, where each stage operates directly on the high-dimensional HSI, refining the entire data cube based on the single 2D coded measurement. However, this paradigm leads to computational redundancy and suffers from the ill-posed nature of mapping 2D residuals back to 3D space of HSI. In this paper, we propose two novel imaging models corresponding to the spectral basis and subspace image by explicitly integrating low-rank (LR) decomposition with the sensing model. Compared to recovering the full HSI, estimating these compact low-dimensional components significantly mitigates the ill-posedness. Building upon these novel models, we develop the Low-Rank Deep Unfolding Network (LRDUN), which jointly solves the two subproblems within an unfolded proximal gradient descent (PGD) framework. Furthermore, we introduce a Generalized Feature Unfolding Mechanism (GFUM) that decouples the physical rank in the data-fidelity term from the feature dimensionality in the prior module, enhancing the representational capacity and flexibility of the network. Extensive experiments on simulated and real datasets demonstrate that the proposed LRDUN achieves state-of-the-art (SOTA) reconstruction quality with significantly reduced computational cost.

</details>


### [163] [Unified Deep Learning Platform for Dust and Fault Diagnosis in Solar Panels Using Thermal and Visual Imaging](https://arxiv.org/abs/2511.18514)
*Abishek Karthik,Sreya Mynampati,Pandiyaraju V*

Main category: cs.CV

TL;DR: 开发了一个用于检测太阳能电池板灰尘和故障的集中式平台，结合了CNN、ResNet和自注意力机制，通过分析功率输出、I-V特性等参数实现高效检测


<details>
  <summary>Details</summary>
Motivation: 太阳能电池板输出受强度、温度、灰尘等多种因素影响，需要有效的检测系统来维护面板效率，特别是针对不同地理环境和规模的应用需求

Method: 使用伽马去除和高斯滤波预处理图像，结合CNN、ResNet和自注意力KerNet模型进行分类，通过分析功率输出、正弦波、电压等参数检测灰尘和故障

Result: 模型在检测效率和准确性方面优于现有模型，能够有效识别灰尘、阴影、故障、裂纹等多种问题

Conclusion: 该多应用模型在检测太阳能电池板灰尘和故障方面表现出高效性和优化性，适用于从小型家庭到大型太阳能农场的不同规模维护需求

Abstract: Solar energy is one of the most abundant and tapped sources of renewable energies with enormous future potential. Solar panel output can vary widely with factors like intensity, temperature, dirt, debris and so on affecting it. We have implemented a model on detecting dust and fault on solar panels. These two applications are centralized as a single-platform and can be utilized for routine-maintenance and any other checks. These are checked against various parameters such as power output, sinusoidal wave (I-V component of solar cell), voltage across each solar cell and others. Firstly, we filter and preprocess the obtained images using gamma removal and Gaussian filtering methods alongside some predefined processes like normalization. The first application is to detect whether a solar cell is dusty or not based on various pre-determined metrics like shadowing, leaf, droppings, air pollution and from other human activities to extent of fine-granular solar modules. The other one is detecting faults and other such occurrences on solar panels like faults, cracks, cell malfunction using thermal imaging application. This centralized platform can be vital since solar panels have different efficiency across different geography (air and heat affect) and can also be utilized for small-scale house requirements to large-scale solar farm sustentation effectively. It incorporates CNN, ResNet models that with self-attention mechanisms-KerNet model which are used for classification and results in a fine-tuned system that detects dust or any fault occurring. Thus, this multi-application model proves to be efficient and optimized in detecting dust and faults on solar panels. We have performed various comparisons and findings that demonstrates that our model has better efficiency and accuracy results overall than existing models.

</details>


### [164] [Breaking Forgetting: Training-Free Few-Shot Class-Incremental Learning via Conditional Diffusion](https://arxiv.org/abs/2511.18516)
*Haidong Kang,Ketong Qian,Yi Lu*

Main category: cs.CV

TL;DR: 提出一种无训练的小样本类增量学习框架CD-FSCIL，通过条件扩散过程替代梯度优化，显著降低计算开销并缓解灾难性遗忘问题


<details>
  <summary>Details</summary>
Motivation: 传统FSCIL方法依赖梯度优化，导致训练成本爆炸式增长，且在数据稀缺情况下既会造成基础类灾难性遗忘又阻碍新类适应

Method: 基于梯度优化与条件扩散过程的关联性，提出条件扩散驱动的FSCIL框架，结合多模态学习策略整合视觉特征和LLM生成的文本描述

Result: 在主流FSCIL基准测试中达到最先进性能，同时大幅降低计算和内存开销

Conclusion: 该方法标志着向无训练持续适应的范式转变，为FSCIL提供了更高效可行的解决方案

Abstract: Efforts to overcome catastrophic forgetting in Few-Shot Class-Incremental Learning (FSCIL) have primarily focused on developing more effective gradient-based optimization strategies. In contrast, little attention has been paid to the training cost explosion that inevitably arises as the number of novel classes increases, a consequence of relying on gradient learning even under extreme data scarcity. More critically, since FSCIL typically provides only a few samples for each new class, gradient-based updates not only induce severe catastrophic forgetting on base classes but also hinder adaptation to novel ones. This paper seeks to break this long-standing limitation by asking: Can we design a training-free FSCIL paradigm that entirely removes gradient optimization? We provide an affirmative answer by uncovering an intriguing connection between gradient-based optimization and the Conditional Diffusion process. Building on this observation, we propose a Conditional Diffusion-driven FSCIL (CD-FSCIL) framework that substitutes the conventional gradient update process with a diffusion-based generative transition, enabling training-free incremental adaptation while effectively mitigating forgetting. Furthermore, to enhance representation under few-shot constraints, we introduce a multimodal learning strategy that integrates visual features with natural language descriptions automatically generated by Large Language Models (LLMs). This synergy substantially alleviates the sample scarcity issue and improves generalization across novel classes. Extensive experiments on mainstream FSCIL benchmarks demonstrate that our method not only achieves state-of-the-art performance but also drastically reduces computational and memory overhead, marking a paradigm shift toward training-free continual adaptation.

</details>


### [165] [DE-KAN: A Kolmogorov Arnold Network with Dual Encoder for accurate 2D Teeth Segmentation](https://arxiv.org/abs/2511.18533)
*Md Mizanur Rahman Mustakim,Jianwu Li,Sumya Bhuiyan,Mohammad Mehedi Hasan,Bing Han*

Main category: cs.CV

TL;DR: DE-KAN是一种新型双编码器Kolmogorov Arnold网络，用于提高全景X光片中牙齿分割的精度，通过双编码器提取全局和局部特征，结合KAN瓶颈层增强学习能力和可解释性。


<details>
  <summary>Details</summary>
Motivation: 由于牙齿解剖变异、不规则形状和结构重叠，传统深度学习模型在全景X光片牙齿分割中性能受限，需要更有效的特征表示和分割方法。

Method: 使用ResNet-18编码器处理增强输入，自定义CNN编码器处理原始输入，通过KAN-based瓶颈层融合全局和局部空间特征，利用Kolmogorov Arnold表示定理的非线性可学习激活函数。

Result: 在两个基准牙科X射线数据集上的实验显示，DE-KAN在mIoU达到94.5%、Dice系数97.1%、准确率98.91%、召回率97.36%，Dice系数比现有方法提高最多4.7%。

Conclusion: DE-KAN框架通过双编码器和KAN瓶颈层的结合，显著提升了牙齿分割性能，为牙科图像分析提供了更精确和可解释的解决方案。

Abstract: Accurate segmentation of individual teeth from panoramic radiographs remains a challenging task due to anatomical variations, irregular tooth shapes, and overlapping structures. These complexities often limit the performance of conventional deep learning models. To address this, we propose DE-KAN, a novel Dual Encoder Kolmogorov Arnold Network, which enhances feature representation and segmentation precision. The framework employs a ResNet-18 encoder for augmented inputs and a customized CNN encoder for original inputs, enabling the complementary extraction of global and local spatial features. These features are fused through KAN-based bottleneck layers, incorporating nonlinear learnable activation functions derived from the Kolmogorov Arnold representation theorem to improve learning capacity and interpretability. Extensive experiments on two benchmark dental X-ray datasets demonstrate that DE-KAN outperforms state-of-the-art segmentation models, achieving mIoU of 94.5%, Dice coefficient of 97.1%, accuracy of 98.91%, and recall of 97.36%, representing up to +4.7% improvement in Dice compared to existing methods.

</details>


### [166] [HiFi-MambaV2: Hierarchical Shared-Routed MoE for High-Fidelity MRI Reconstruction](https://arxiv.org/abs/2511.18534)
*Pengcheng Fang,Hongli Chen,Guangzhen Yao,Jian Shi,Fangfang Tang,Xiaohao Cai,Shanshan Shan,Feng Liu*

Main category: cs.CV

TL;DR: HiFi-MambaV2是一种用于MRI重建的分层共享路由MoE Mamba架构，通过频率分解和内容自适应计算实现高质量图像重建。


<details>
  <summary>Details</summary>
Motivation: 从欠采样的k空间数据重建高保真MRI图像需要恢复高频细节同时保持解剖一致性，现有方法在细节恢复和结构保持方面存在挑战。

Method: 采用分层共享路由MoE Mamba架构，包含可分离频率一致性拉普拉斯金字塔和分层共享路由MoE，结合轻量级全局上下文路径和数据一致性正则化主干网络。

Result: 在多个数据集上显著优于CNN、Transformer和现有Mamba基线，在PSNR、SSIM和NMSE指标上表现优异，高频细节和结构保真度均有提升。

Conclusion: HiFi-MambaV2实现了可靠且鲁棒的MRI重建，证明了该架构在医学图像重建领域的有效性。

Abstract: Reconstructing high-fidelity MR images from undersampled k-space data requires recovering high-frequency details while maintaining anatomical coherence. We present HiFi-MambaV2, a hierarchical shared-routed Mixture-of-Experts (MoE) Mamba architecture that couples frequency decomposition with content-adaptive computation. The model comprises two core components: (i) a separable frequency-consistent Laplacian pyramid (SF-Lap) that delivers alias-resistant, stable low- and high-frequency streams; and (ii) a hierarchical shared-routed MoE that performs per-pixel top-1 sparse dispatch to shared experts and local routers, enabling effective specialization with stable cross-depth behavior. A lightweight global context path is fused into an unrolled, data-consistency-regularized backbone to reinforce long-range reasoning and preserve anatomical coherence. Evaluated on fastMRI, CC359, ACDC, M4Raw, and Prostate158, HiFi-MambaV2 consistently outperforms CNN-, Transformer-, and prior Mamba-based baselines in PSNR, SSIM, and NMSE across single- and multi-coil settings and multiple acceleration factors, consistently surpassing consistent improvements in high-frequency detail and overall structural fidelity. These results demonstrate that HiFi-MambaV2 enables reliable and robust MRI reconstruction.

</details>


### [167] [Zero-Shot Video Deraining with Video Diffusion Models](https://arxiv.org/abs/2511.18537)
*Tuomas Varanka,Juan Luis Gonzalez,Hyeongwoo Kim,Pablo Garrido,Xu Yao*

Main category: cs.CV

TL;DR: 本文提出了首个针对复杂动态场景的零样本视频去雨方法，无需合成数据或模型微调，利用预训练文本到视频扩散模型通过负提示干预重建过程来去除雨滴。


<details>
  <summary>Details</summary>
Motivation: 现有视频去雨方法依赖合成数据或静态相机数据，难以泛化到真实动态场景；扩散模型微调会削弱生成先验，限制泛化能力。

Method: 通过将输入视频反转到扩散模型的潜在空间，利用负提示干预重建过程远离雨的概念；核心是注意力切换机制，保持动态背景和结构一致性。

Result: 在真实世界雨数据集上的广泛实验显示，相比现有方法有显著改进，展示了无需监督训练的鲁棒泛化能力。

Conclusion: 该方法实现了对复杂动态场景的有效视频去雨，突破了传统方法对合成数据或静态场景的依赖，具有良好的泛化性能。

Abstract: Existing video deraining methods are often trained on paired datasets, either synthetic, which limits their ability to generalize to real-world rain, or captured by static cameras, which restricts their effectiveness in dynamic scenes with background and camera motion. Furthermore, recent works in fine-tuning diffusion models have shown promising results, but the fine-tuning tends to weaken the generative prior, limiting generalization to unseen cases. In this paper, we introduce the first zero-shot video deraining method for complex dynamic scenes that does not require synthetic data nor model fine-tuning, by leveraging a pretrained text-to-video diffusion model that demonstrates strong generalization capabilities. By inverting an input video into the latent space of diffusion models, its reconstruction process can be intervened and pushed away from the model's concept of rain using negative prompting. At the core of our approach is an attention switching mechanism that we found is crucial for maintaining dynamic backgrounds as well as structural consistency between the input and the derained video, mitigating artifacts introduced by naive negative prompting. Our approach is validated through extensive experiments on real-world rain datasets, demonstrating substantial improvements over prior methods and showcasing robust generalization without the need for supervised training.

</details>


### [168] [C3Po: Cross-View Cross-Modality Correspondence by Pointmap Prediction](https://arxiv.org/abs/2511.18559)
*Kuan Wei Huang,Brandon Li,Bharath Hariharan,Noah Snavely*

Main category: cs.CV

TL;DR: 该论文提出了C3数据集，用于解决地面照片与平面图之间的跨模态对应关系预测问题，现有方法在差异较大的视角或模态下表现不佳，通过新数据集训练可将最佳方法的RMSE提升34%。


<details>
  <summary>Details</summary>
Motivation: 现有几何模型如DUSt3R在处理训练时未见过的视角差异（如航拍vs地面）或模态差异（如照片vs抽象绘图）时表现失败，特别是地面照片与平面图之间的对应关系预测是一个具有挑战性的问题。

Method: 通过从互联网照片集合中利用运动恢复结构技术重建3D场景，然后手动将这些重建结果与从互联网收集的平面图进行配准，从而推导出图像与平面图之间的对应关系，创建了包含90K对平面图和照片的C3数据集。

Result: C3数据集包含597个场景的90K对平面图和照片，具有153M像素级对应关系和85K相机姿态。实验表明，在该数据集上训练可将最佳方法的RMSE提升34%。

Conclusion: 论文识别了跨模态几何推理中的开放挑战，并希望通过C3数据集帮助解决这些问题，现有最先进的对应模型在此任务上表现困难，但通过新数据训练可以显著改善性能。

Abstract: Geometric models like DUSt3R have shown great advances in understanding the geometry of a scene from pairs of photos. However, they fail when the inputs are from vastly different viewpoints (e.g., aerial vs. ground) or modalities (e.g., photos vs. abstract drawings) compared to what was observed during training. This paper addresses a challenging version of this problem: predicting correspondences between ground-level photos and floor plans. Current datasets for joint photo--floor plan reasoning are limited, either lacking in varying modalities (VIGOR) or lacking in correspondences (WAFFLE). To address these limitations, we introduce a new dataset, C3, created by first reconstructing a number of scenes in 3D from Internet photo collections via structure-from-motion, then manually registering the reconstructions to floor plans gathered from the Internet, from which we can derive correspondence between images and floor plans. C3 contains 90K paired floor plans and photos across 597 scenes with 153M pixel-level correspondences and 85K camera poses. We find that state-of-the-art correspondence models struggle on this task. By training on our new data, we can improve on the best performing method by 34% in RMSE. We also identify open challenges in cross-modal geometric reasoning that our dataset aims to help address.

</details>


### [169] [Zero-Reference Joint Low-Light Enhancement and Deblurring via Visual Autoregressive Modeling with VLM-Derived Modulation](https://arxiv.org/abs/2511.18591)
*Wei Dong,Han Zhou,Junwei Lin,Jun Chen*

Main category: cs.CV

TL;DR: 提出基于视觉自回归模型和视觉语言模型感知先验的生成框架，用于解决暗光图像中复杂噪声、模糊和动态光照的恢复问题，无需配对数据即可实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现实暗光图像存在低可见度、对比度差、复杂噪声和模糊等多重退化，现有方法依赖配对数据或无法建模动态光照和模糊特性，导致泛化能力差。

Method: 1) 基于VLM可见度评分的自适应曲线估计调节光照；2) 在VAR中集成动态空间频率感知旋转位置编码增强模糊结构建模；3) 基于VLM模糊评分的递归相位域调制策略减少模糊伪影。

Result: 该框架完全无监督，在基准数据集上达到最先进性能。

Conclusion: 提出的生成框架通过结合VAR建模和VLM感知先验，有效解决了暗光图像恢复中的复杂退化问题，展示了无监督方法的优越泛化能力。

Abstract: Real-world dark images commonly exhibit not only low visibility and contrast but also complex noise and blur, posing significant restoration challenges. Existing methods often rely on paired data or fail to model dynamic illumination and blur characteristics, leading to poor generalization. To tackle this, we propose a generative framework based on visual autoregressive (VAR) modeling, guided by perceptual priors from the vision-language model (VLM). Specifically, to supply informative conditioning cues for VAR models, we deploy an adaptive curve estimation scheme to modulate the diverse illumination based on VLM-derived visibility scores. In addition, we integrate dynamic and spatial-frequency-aware Rotary Positional Encodings (SF-RoPE) into VAR to enhance its ability to model structures degraded by blur. Furthermore, we propose a recursive phase-domain modulation strategy that mitigates blur-induced artifacts in the phase domain via bounded iterative refinement guided by VLM-assessed blur scores. Our framework is fully unsupervised and achieves state-of-the-art performance on benchmark datasets.

</details>


### [170] [Stage-Specific Benchmarking of Deep Learning Models for Glioblastoma Follow-Up MRI](https://arxiv.org/abs/2511.18595)
*Wenhao Guo,Golrokh Mirzaei*

Main category: cs.CV

TL;DR: 该研究首次在脑胶质瘤随访MRI中建立了阶段特异性深度学习模型基准测试，发现Mamba+CNN混合模型在准确性和效率方面表现最佳，而Transformer模型虽然AUC竞争力强但计算成本高。


<details>
  <summary>Details</summary>
Motivation: 区分脑胶质瘤的真实进展（TP）与治疗相关的假性进展（PsP）在早期随访中具有挑战性，需要建立阶段感知的基准来指导模型选择。

Method: 使用Burdenko GBM进展队列（n=180），对11个代表性深度学习家族（CNN、LSTM、混合模型、Transformer和选择性状态空间模型）在统一质量控制流程下进行训练，采用患者级交叉验证，独立分析不同放疗后扫描时间点。

Result: 两个随访阶段的准确率相当（约0.70-0.74），但第二次随访时F1和AUC有所提高，表明后期可分离性更强。Mamba+CNN混合模型在准确性和效率方面表现最佳，性能对批量大小敏感。

Conclusion: 研究建立了阶段感知基准，表明绝对区分能力整体有限，反映了TP与PsP区分的固有难度和数据集不平衡问题，为未来整合纵向建模、多序列MRI和更大规模多中心队列研究提供了方向。

Abstract: Differentiating true tumor progression (TP) from treatment-related pseudoprogression (PsP) in glioblastoma remains challenging, especially at early follow-up. We present the first stage-specific, cross-sectional benchmarking of deep learning models for follow-up MRI using the Burdenko GBM Progression cohort (n = 180). We analyze different post-RT scans independently to test whether architecture performance depends on time-point. Eleven representative DL families (CNNs, LSTMs, hybrids, transformers, and selective state-space models) were trained under a unified, QC-driven pipeline with patient-level cross-validation. Across both stages, accuracies were comparable (~0.70-0.74), but discrimination improved at the second follow-up, with F1 and AUC increasing for several models, indicating richer separability later in the care pathway. A Mamba+CNN hybrid consistently offered the best accuracy-efficiency trade-off, while transformer variants delivered competitive AUCs at substantially higher computational cost and lightweight CNNs were efficient but less reliable. Performance also showed sensitivity to batch size, underscoring the need for standardized training protocols. Notably, absolute discrimination remained modest overall, reflecting the intrinsic difficulty of TP vs. PsP and the dataset's size imbalance. These results establish a stage-aware benchmark and motivate future work incorporating longitudinal modeling, multi-sequence MRI, and larger multi-center cohorts.

</details>


### [171] [NeAR: Coupled Neural Asset-Renderer Stack](https://arxiv.org/abs/2511.18600)
*Hong Li,Chongjie Ye,Houyuan Chen,Weiqing Xiao,Ziyang Yan,Lixing Xiao,Zhaoxi Chen,Jianfeng Xiang,Shaocong Xu,Xuhui Liu,Yikai Wang,Baochang Zhang,Xiaoguang Han,Jiaolong Yang,Hao Zhao*

Main category: cs.CV

TL;DR: NeAR提出了一种耦合的神经资产-渲染器堆栈，将神经资产创作和神经渲染联合设计，实现端到端可学习的图形流水线，在保真度、一致性和效率方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前神经资产创作和神经渲染是分离的领域，作者认为将它们耦合设计可以解锁端到端可学习的图形堆栈，带来更好的性能。

Method: 在资产侧使用Trellis风格的3D结构化潜空间和整流流骨干网络创建光照均匀化的神经资产；在渲染器侧设计光照感知的神经渲染器，结合显式视图嵌入和HDR环境贴图实现实时可重光照渲染。

Result: NeAR在四个任务上验证：G-buffer前向渲染、随机光照单图像重建、未知光照单图像重光照、新视角重光照，在定量指标和感知质量上都超越了现有最优方法。

Conclusion: 这种耦合的资产-渲染器视角为未来图形堆栈提供了新思路，将神经资产和渲染器视为协同设计而非独立实体。

Abstract: Neural asset authoring and neural rendering have emerged as fundamentally disjoint threads: one generates digital assets using neural networks for traditional graphics pipelines, while the other develops neural renderers that map conventional assets to images. However, the potential of jointly designing the asset representation and renderer remains largely unexplored. We argue that coupling them can unlock an end-to-end learnable graphics stack with benefits in fidelity, consistency, and efficiency. In this paper, we explore this possibility with NeAR: a Coupled Neural Asset-Renderer Stack. On the asset side, we build on Trellis-style Structured 3D Latents and introduce a lighting-homogenized neural asset: from a casually lit input, a rectified-flow backbone predicts a Lighting-Homogenized SLAT that encodes geometry and intrinsic material cues in a compact, view-agnostic latent. On the renderer side, we design a lighting-aware neural renderer that uses this neural asset, along with explicit view embeddings and HDR environment maps, to achieve real-time, relightable rendering. We validate NeAR on four tasks: (1) G-buffer-based forward rendering, (2) random-lit single-image reconstruction, (3) unknown-lit single-image relighting, and (4) novel-view relighting. Our coupled stack surpasses state-of-the-art baselines in both quantitative metrics and perceptual quality. We hope this coupled asset-renderer perspective inspires future graphics stacks that view neural assets and renderers as co-designed components instead of independent entities.

</details>


### [172] [RigAnyFace: Scaling Neural Facial Mesh Auto-Rigging with Unlabeled Data](https://arxiv.org/abs/2511.18601)
*Wenchao Ma,Dario Kneubuehler,Maurice Chu,Ian Sachs,Haomiao Jiang,Sharon Xiaolei Huang*

Main category: cs.CV

TL;DR: RigAnyFace (RAF) 是一个可扩展的神经自动绑定框架，用于处理各种拓扑结构的面部网格，包括具有多个断开组件的网格。它通过基于FACS参数的变形预测，将静态中性面部网格变形为行业标准的表情形状，并支持2D监督策略来增强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的面部自动绑定方法在处理不同拓扑结构和断开组件（如眼球）时存在局限性，且手动绑定成本高昂，限制了训练数据的规模，影响了模型的泛化能力。

Method: RAF使用三角网格无关的表面学习网络，结合定制架构设计，以FACS参数为条件，高效处理断开组件。采用2D监督策略对未标记的中性网格进行训练，增加数据多样性。

Result: 实验表明，RAF在艺术家制作的资产和野外样本上均能有效处理各种拓扑结构的面部网格，在准确性和泛化能力上优于先前工作，并支持多个断开组件以实现更详细的表情动画。

Conclusion: RAF提供了一个高效、可扩展的面部自动绑定解决方案，通过结合3D和2D监督策略，显著提升了模型的泛化能力和应用范围，特别是在处理复杂拓扑和断开组件方面表现出色。

Abstract: In this paper, we present RigAnyFace (RAF), a scalable neural auto-rigging framework for facial meshes of diverse topologies, including those with multiple disconnected components. RAF deforms a static neutral facial mesh into industry-standard FACS poses to form an expressive blendshape rig. Deformations are predicted by a triangulation-agnostic surface learning network augmented with our tailored architecture design to condition on FACS parameters and efficiently process disconnected components. For training, we curated a dataset of facial meshes, with a subset meticulously rigged by professional artists to serve as accurate 3D ground truth for deformation supervision. Due to the high cost of manual rigging, this subset is limited in size, constraining the generalization ability of models trained exclusively on it. To address this, we design a 2D supervision strategy for unlabeled neutral meshes without rigs. This strategy increases data diversity and allows for scaled training, thereby enhancing the generalization ability of models trained on this augmented data. Extensive experiments demonstrate that RAF is able to rig meshes of diverse topologies on not only our artist-crafted assets but also in-the-wild samples, outperforming previous works in accuracy and generalizability. Moreover, our method advances beyond prior work by supporting multiple disconnected components, such as eyeballs, for more detailed expression animation. Project page: https://wenchao-m.github.io/RigAnyFace.github.io

</details>


### [173] [Functional Localization Enforced Deep Anomaly Detection Using Fundus Images](https://arxiv.org/abs/2511.18627)
*Jan Benedikt Ruhland,Thorsten Papenbrock,Jan-Peter Sowa,Ali Canbay,Nicole Eter,Bernd Freisleben,Dominik Heider*

Main category: cs.CV

TL;DR: 本研究系统评估了Vision Transformer在多种增强策略下对眼底图像的视网膜疾病检测性能，ViT在不同数据集上表现稳定，几何和颜色增强效果最佳，同时开发了基于GANomaly的异常检测器提供可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决眼底图像疾病检测中成像质量变异、早期表现细微以及数据集间域偏移等挑战，开发可靠的视网膜疾病自动检测系统。

Method: 使用Vision Transformer分类器，结合几何增强、颜色增强、直方图均衡化和拉普拉斯增强等多种策略，在多个异构公共数据集和自建AEyeDB数据集上进行评估，并开发基于GANomaly的异常检测器。

Result: ViT在不同数据集上准确率0.789-0.843，几何增强在Papila数据集上AUC达0.91，优于卷积集成基线；GANomaly异常检测器AUC为0.76，具有良好的可解释性和泛化能力。

Conclusion: Vision Transformer在视网膜疾病检测中表现出色，几何和颜色增强是最有效的策略，GANomaly异常检测器提供了解释性和泛化能力，为未来临床实施提供了阈值无关的决策支持。

Abstract: Reliable detection of retinal diseases from fundus images is challenged by the variability in imaging quality, subtle early-stage manifestations, and domain shift across datasets. In this study, we systematically evaluated a Vision Transformer (ViT) classifier under multiple augmentation and enhancement strategies across several heterogeneous public datasets, as well as the AEyeDB dataset, a high-quality fundus dataset created in-house and made available for the research community. The ViT demonstrated consistently strong performance, with accuracies ranging from 0.789 to 0.843 across datasets and diseases. Diabetic retinopathy and age-related macular degeneration were detected reliably, whereas glaucoma remained the most frequently misclassified disease. Geometric and color augmentations provided the most stable improvements, while histogram equalization benefited datasets dominated by structural subtlety. Laplacian enhancement reduced performance across different settings.
  On the Papila dataset, the ViT with geometric augmentation achieved an AUC of 0.91, outperforming previously reported convolutional ensemble baselines (AUC of 0.87), underscoring the advantages of transformer architectures and multi-dataset training. To complement the classifier, we developed a GANomaly-based anomaly detector, achieving an AUC of 0.76 while providing inherent reconstruction-based explainability and robust generalization to unseen data. Probabilistic calibration using GUESS enabled threshold-independent decision support for future clinical implementation.

</details>


### [174] [Health system learning achieves generalist neuroimaging models](https://arxiv.org/abs/2511.18640)
*Akhil Kondepudi,Akshay Rao,Chenhui Zhao,Yiwei Lyu,Samir Harake,Soumyanil Banerjee,Rushikesh Joshi,Anna-Katharina Meissner,Renly Hou,Cheng Jiang,Asadur Chowdury,Ashok Srinivasan,Brian Athey,Vikas Gulani,Aditya Pandey,Honglak Lee,Todd Hollon*

Main category: cs.CV

TL;DR: NeuroVFM是一个基于医疗系统学习范式的视觉基础模型，通过在524万临床MRI和CT扫描上训练，在神经影像任务上超越了前沿AI模型，实现了最先进的诊断性能和报告生成能力。


<details>
  <summary>Details</summary>
Motivation: 前沿AI模型在公共数据上训练，但缺乏私有临床数据访问权限，特别是神经影像数据因包含可识别面部特征而在公共领域代表性不足，这限制了模型在临床医学中的性能。

Method: 采用健康系统学习范式，直接从医疗系统常规护理生成的非精选数据中学习。使用可扩展的容积联合嵌入预测架构，在524万临床MRI和CT容积上训练NeuroVFM模型。

Result: NeuroVFM在多个临床任务上实现最先进性能，包括放射学诊断和报告生成。模型表现出对神经解剖学的涌现理解和可解释的视觉诊断基础。与开源语言模型结合后，生成的放射学报告在准确性、临床分诊和专家偏好方面超越前沿模型。

Conclusion: 健康系统学习是构建通用医疗AI的有效范式，NeuroVFM通过临床基础的视觉理解减少了幻觉发现和关键错误，为临床基础模型提供了可扩展框架。

Abstract: Frontier artificial intelligence (AI) models, such as OpenAI's GPT-5 and Meta's DINOv3, have advanced rapidly through training on internet-scale public data, yet such systems lack access to private clinical data. Neuroimaging, in particular, is underrepresented in the public domain due to identifiable facial features within MRI and CT scans, fundamentally restricting model performance in clinical medicine. Here, we show that frontier models underperform on neuroimaging tasks and that learning directly from uncurated data generated during routine clinical care at health systems, a paradigm we call health system learning, yields high-performance, generalist neuroimaging models. We introduce NeuroVFM, a visual foundation model trained on 5.24 million clinical MRI and CT volumes using a scalable volumetric joint-embedding predictive architecture. NeuroVFM learns comprehensive representations of brain anatomy and pathology, achieving state-of-the-art performance across multiple clinical tasks, including radiologic diagnosis and report generation. The model exhibits emergent neuroanatomic understanding and interpretable visual grounding of diagnostic findings. When paired with open-source language models through lightweight visual instruction tuning, NeuroVFM generates radiology reports that surpass frontier models in accuracy, clinical triage, and expert preference. Through clinically grounded visual understanding, NeuroVFM reduces hallucinated findings and critical errors, offering safer clinical decision support. These results establish health system learning as a paradigm for building generalist medical AI and provide a scalable framework for clinical foundation models.

</details>


### [175] [From Healthy Scans to Annotated Tumors: A Tumor Fabrication Framework for 3D Brain MRI Synthesis](https://arxiv.org/abs/2511.18654)
*Nayu Dong,Townim Chowdhury,Hieu Phan,Mark Jenkinson,Johan Verjans,Zhibin Liao*

Main category: cs.CV

TL;DR: 提出TF框架，通过两阶段方法合成3D脑肿瘤数据，解决医学影像中标注数据稀缺问题，显著提升低数据量下的肿瘤分割性能


<details>
  <summary>Details</summary>
Motivation: 医学影像中标注的MRI肿瘤数据稀缺，现有方法要么需要大量人工建模，要么需要大量训练数据，在临床数据有限的情况下不实用

Method: TF框架包含粗粒度肿瘤合成和生成模型驱动的精炼过程，仅使用健康扫描图像和少量真实标注数据来合成大量配对数据

Result: 实验证明合成的图像-标签对作为数据增强能显著提高低数据量下肿瘤分割任务的性能

Conclusion: TF提供了一种可扩展且可靠的医学图像增强解决方案，解决了临床AI应用中数据稀缺的关键挑战

Abstract: The scarcity of annotated Magnetic Resonance Imaging (MRI) tumor data presents a major obstacle to accurate and automated tumor segmentation. While existing data synthesis methods offer promising solutions, they often suffer from key limitations: manual modeling is labor intensive and requires expert knowledge. Deep generative models may be used to augment data and annotation, but they typically demand large amounts of training pairs in the first place, which is impractical in data limited clinical settings. In this work, we propose Tumor Fabrication (TF), a novel two-stage framework for unpaired 3D brain tumor synthesis. The framework comprises a coarse tumor synthesis process followed by a refinement process powered by a generative model. TF is fully automated and leverages only healthy image scans along with a limited amount of real annotated data to synthesize large volumes of paired synthetic data for enriching downstream supervised segmentation training. We demonstrate that our synthetic image-label pairs used as data enrichment can significantly improve performance on downstream tumor segmentation tasks in low-data regimes, offering a scalable and reliable solution for medical image enrichment and addressing critical challenges in data scarcity for clinical AI applications.

</details>


### [176] [Robust Physical Adversarial Patches Using Dynamically Optimized Clusters](https://arxiv.org/abs/2511.18656)
*Harrison Bagley,Will Meakin,Simon Lucey,Yee Wei Law,Tat-Jun Chin*

Main category: cs.CV

TL;DR: 提出了一种基于超像素的正则化方法，通过SLIC算法动态聚类对抗性补丁中的像素，使补丁在尺度变化时保持结构稳定性，减少插值损失，提高物理对抗攻击的性能。


<details>
  <summary>Details</summary>
Motivation: 物理对抗攻击中，补丁在尺度变化时（如数字重采样或物理成像距离变化）会出现插值引起的颜色混合，导致高频模式丢失和对抗信号退化。现有方法对尺度变化的关注不足。

Method: 使用SLIC算法在对抗补丁优化过程中动态聚类像素，并利用隐函数定理反向传播梯度以更新超像素边界和颜色，从而生成对尺度变化具有弹性的补丁结构。

Result: 该方法在数字域中取得了更好的性能，并且在物理实现时这些性能增益得以保持，从而提高了物理对抗攻击的效果。

Conclusion: 所提出的超像素正则化方法有效提升了对抗补丁在尺度变化下的稳定性，通过系统化的物理评估协议验证了其在真实世界中的优越性能。

Abstract: Physical adversarial attacks on deep learning systems is concerning due to the ease of deploying such attacks, usually by placing an adversarial patch in a scene to manipulate the outcomes of a deep learning model. Training such patches typically requires regularization that improves physical realizability (e.g., printability, smoothness) and/or robustness to real-world variability (e.g. deformations, viewing angle, noise). One type of variability that has received little attention is scale variability. When a patch is rescaled, either digitally through downsampling/upsampling or physically through changing imaging distances, interpolation-induced color mixing occurs. This smooths out pixel values, resulting in a loss of high-frequency patterns and degrading the adversarial signal. To address this, we present a novel superpixel-based regularization method that guides patch optimization to scale-resilient structures. Our ap proach employs the Simple Linear Iterative Clustering (SLIC) algorithm to dynamically cluster pixels in an adversarial patch during optimization. The Implicit Function Theorem is used to backpropagate gradients through SLIC to update the superpixel boundaries and color. This produces patches that maintain their structure over scale and are less susceptible to interpolation losses. Our method achieves greater performance in the digital domain, and when realized physically, these performance gains are preserved, leading to improved physical performance. Real-world performance was objectively assessed using a novel physical evaluation protocol that utilizes screens and cardboard cut-outs to systematically vary real-world conditions.

</details>


### [177] [Data Augmentation Strategies for Robust Lane Marking Detection](https://arxiv.org/abs/2511.18668)
*Flora Lian,Dinh Quang Huynh,Hector Penades,J. Stephany Berrio Perez,Mao Shan,Stewart Worrall*

Main category: cs.CV

TL;DR: 本文提出了一种基于生成AI的数据增强方法，通过几何透视变换、AI修复和车身叠加技术来提升侧置摄像头在车道检测中的泛化能力，在两个先进模型上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 解决车道检测模型在侧置摄像头视角下的领域适应问题，因为现有公开数据集（如CULane）训练的模型难以泛化到不同相机视角。

Method: 采用生成AI数据增强管道，结合几何透视变换、AI驱动修复和车辆车身叠加技术，模拟特定部署视角同时保持车道连续性。

Result: 在SCNN和UFLDv2模型上测试，增强数据训练后模型在不同条件下（包括阴影）表现出更强鲁棒性，精确率、召回率和F1分数均有提升。

Conclusion: 该方法通过弥合公开数据集与特定部署场景之间的差距，为提高车道检测可靠性提供了可扩展的实用框架。

Abstract: Robust lane detection is essential for advanced driver assistance and autonomous driving, yet models trained on public datasets such as CULane often fail to generalise across different camera viewpoints. This paper addresses the challenge of domain shift for side-mounted cameras used in lane-wheel monitoring by introducing a generative AI-based data enhancement pipeline. The approach combines geometric perspective transformation, AI-driven inpainting, and vehicle body overlays to simulate deployment-specific viewpoints while preserving lane continuity. We evaluated the effectiveness of the proposed augmentation in two state-of-the-art models, SCNN and UFLDv2. With the augmented data trained, both models show improved robustness to different conditions, including shadows. The experimental results demonstrate gains in precision, recall, and F1 score compared to the pre-trained model.
  By bridging the gap between widely available datasets and deployment-specific scenarios, our method provides a scalable and practical framework to improve the reliability of lane detection in a pilot deployment scenario.

</details>


### [178] [Sphinx: Efficiently Serving Novel View Synthesis using Regression-Guided Selective Refinement](https://arxiv.org/abs/2511.18672)
*Yuchen Xia,Souvik Kundu,Mosharaf Chowdhury,Nishil Talati*

Main category: cs.CV

TL;DR: Sphinx是一个无需训练的高效新视角合成框架，通过回归快速初始化引导扩散模型，结合选择性优化和自适应噪声调度，实现扩散级质量但计算量大幅降低


<details>
  <summary>Details</summary>
Motivation: 扩散模型能生成高质量新视角图像但计算成本高，回归方法计算效率高但质量不足，需要设计高质量且推理高效的NVS框架

Method: 使用回归方法快速初始化来引导和减少扩散模型的去噪工作量，集成选择性优化和自适应噪声调度，为不确定区域和帧分配更多计算资源

Result: 平均比扩散模型推理快1.8倍，感知质量退化小于5%，在质量和延迟之间建立了新的帕累托前沿

Conclusion: Sphinx框架成功解决了NVS中质量与效率的权衡问题，为动态变化的推理场景提供了灵活的性能-质量导航

Abstract: Novel View Synthesis (NVS) is the task of generating new images of a scene from viewpoints that were not part of the original input. Diffusion-based NVS can generate high-quality, temporally consistent images, however, remains computationally prohibitive. Conversely, regression-based NVS offers suboptimal generation quality despite requiring significantly lower compute; leaving the design objective of a high-quality, inference-efficient NVS framework an open challenge. To close this critical gap, we present Sphinx, a training-free hybrid inference framework that achieves diffusion-level fidelity at a significantly lower compute. Sphinx proposes to use regression-based fast initialization to guide and reduce the denoising workload for the diffusion model. Additionally, it integrates selective refinement with adaptive noise scheduling, allowing more compute to uncertain regions and frames. This enables Sphinx to provide flexible navigation of the performance-quality trade-off, allowing adaptation to latency and fidelity requirements for dynamically changing inference scenarios. Our evaluation shows that Sphinx achieves an average 1.8x speedup over diffusion model inference with negligible perceptual degradation of less than 5%, establishing a new Pareto frontier between quality and latency in NVS serving.

</details>


### [179] [Edit2Perceive: Image Editing Diffusion Models Are Strong Dense Perceivers](https://arxiv.org/abs/2511.18673)
*Yiqing Shi,Yiren Song,Mike Zheng Shou*

Main category: cs.CV

TL;DR: Edit2Perceive是一个统一的扩散框架，将编辑模型适配于深度、法线和蒙版任务，利用编辑导向的扩散变换器实现几何感知的密集感知。


<details>
  <summary>Details</summary>
Motivation: 现有的密集感知方法大多依赖为随机生成设计的文本到图像生成器，而图像编辑扩散模型具有固有的图像到图像一致性，更适合作为密集感知任务的基础。

Method: 基于FLUX.1 Kontext架构，采用全参数微调和像素空间一致性损失，在中间去噪状态间强制执行结构保持的细化，并使用单步确定性推理加速运行。

Result: 在深度、法线和蒙版三个任务上均实现了全面的最先进结果，训练数据量相对较小的情况下运行速度提升显著。

Conclusion: 编辑导向的扩散变换器在几何感知感知任务中展现出强大潜力，为密集感知提供了更合适的基础框架。

Abstract: Recent advances in diffusion transformers have shown remarkable generalization in visual synthesis, yet most dense perception methods still rely on text-to-image (T2I) generators designed for stochastic generation. We revisit this paradigm and show that image editing diffusion models are inherently image-to-image consistent, providing a more suitable foundation for dense perception task. We introduce Edit2Perceive, a unified diffusion framework that adapts editing models for depth, normal, and matting. Built upon the FLUX.1 Kontext architecture, our approach employs full-parameter fine-tuning and a pixel-space consistency loss to enforce structure-preserving refinement across intermediate denoising states. Moreover, our single-step deterministic inference yields up to faster runtime while training on relatively small datasets. Extensive experiments demonstrate comprehensive state-of-the-art results across all three tasks, revealing the strong potential of editing-oriented diffusion transformers for geometry-aware perception.

</details>


### [180] [MedVision: Dataset and Benchmark for Quantitative Medical Image Analysis](https://arxiv.org/abs/2511.18676)
*Yongcheng Yao,Yongshuo Zong,Raman Dutt,Yongxin Yang,Sotirios A Tsaftaris,Timothy Hospedales*

Main category: cs.CV

TL;DR: MedVision是一个专门针对医学图像定量分析的大规模数据集和基准测试，旨在评估和提升视觉语言模型在定量医学图像分析中的能力。


<details>
  <summary>Details</summary>
Motivation: 当前医学视觉语言模型主要专注于分类问答或定性描述任务，但临床决策往往依赖于定量评估（如肿瘤大小测量、关节角度测量等），这种定量推理能力在现有VLMs中尚未得到充分探索和支持。

Method: 构建了MedVision数据集，涵盖22个公共数据集，包含3080万张图像-标注对，专注于三个代表性定量任务：解剖结构和异常检测、肿瘤/病变大小估计、角度/距离测量。通过监督微调来提升VLMs的性能。

Result: 现成的VLMs在这些定量任务上表现不佳，但经过MedVision监督微调后，在检测、大小估计和测量任务上的性能显著提升，错误率降低，精度提高。

Conclusion: 这项工作为开发具有强大定量推理能力的医学成像VLMs奠定了基础，推动了医学图像分析向定量化方向发展。

Abstract: Current vision-language models (VLMs) in medicine are primarily designed for categorical question answering (e.g., "Is this normal or abnormal?") or qualitative descriptive tasks. However, clinical decision-making often relies on quantitative assessments, such as measuring the size of a tumor or the angle of a joint, from which physicians draw their own diagnostic conclusions. This quantitative reasoning capability remains underexplored and poorly supported in existing VLMs. In this work, we introduce MedVision, a large-scale dataset and benchmark specifically designed to evaluate and improve VLMs on quantitative medical image analysis. MedVision spans 22 public datasets covering diverse anatomies and modalities, with 30.8 million image-annotation pairs. We focus on three representative quantitative tasks: (1) detection of anatomical structures and abnormalities, (2) tumor/lesion (T/L) size estimation, and (3) angle/distance (A/D) measurement. Our benchmarks show that current off-the-shelf VLMs perform poorly on these tasks. However, with supervised fine-tuning on MedVision, we significantly enhance their performance across detection, T/L estimation, and A/D measurement, demonstrating reduced error rates and improved precision. This work provides a foundation for developing VLMs with robust quantitative reasoning capabilities in medical imaging. Code and data are available at https://medvision-vlm.github.io.

</details>


### [181] [A Theory-Inspired Framework for Few-Shot Cross-Modal Sketch Person Re-Identification](https://arxiv.org/abs/2511.18677)
*Yunpeng Gong,Yongjie Hou,Jiangming Shi,Kim Long Diep,Min Jiang*

Main category: cs.CV

TL;DR: KTCAA是一个基于泛化理论的少样本跨模态生成框架，通过对齐增强和知识转移催化剂来解决基于草图的人员重识别中的模态差异和数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 基于草图的人员重识别面临显著的模态差异和有限的标注数据挑战，需要解决跨模态泛化问题。

Method: 提出对齐增强(AA)模块应用局部草图风格变换模拟目标分布，知识转移催化剂(KTC)引入最坏情况扰动增强模型鲁棒性，在元学习范式下联合优化。

Result: 在多个基准测试中达到最先进性能，特别是在数据稀缺条件下表现优异。

Conclusion: KTCAA框架通过理论指导的模块设计，有效解决了跨模态人员重识别的关键挑战，为少样本学习提供了新思路。

Abstract: Sketch based person re-identification aims to match hand-drawn sketches with RGB surveillance images, but remains challenging due to significant modality gaps and limited annotated data. To address this, we introduce KTCAA, a theoretically grounded framework for few-shot cross-modal generalization. Motivated by generalization theory, we identify two key factors influencing target domain risk: (1) domain discrepancy, which quantifies the alignment difficulty between source and target distributions; and (2) perturbation invariance, which evaluates the model's robustness to modality shifts. Based on these insights, we propose two components: (1) Alignment Augmentation (AA), which applies localized sketch-style transformations to simulate target distributions and facilitate progressive alignment; and (2) Knowledge Transfer Catalyst (KTC), which enhances invariance by introducing worst-case perturbations and enforcing consistency. These modules are jointly optimized under a meta-learning paradigm that transfers alignment knowledge from data-rich RGB domains to sketch-based scenarios. Experiments on multiple benchmarks demonstrate that KTCAA achieves state-of-the-art performance, particularly in data-scarce conditions.

</details>


### [182] [Neural Geometry Image-Based Representations with Optimal Transport (OT)](https://arxiv.org/abs/2511.18679)
*Xiang Gao,Yuanpeng Liu,Xinmu Wang,Jiazhi Li,Minghao Guo,Yu Guo,Xiyun Song,Heather Yu,Zhiqiang Lao,Xianfeng David Gu*

Main category: cs.CV

TL;DR: 提出了一种基于神经几何图像的网格表示方法，通过将不规则网格转换为规则图像网格，实现高效的单次前向传递恢复高质量网格，解决了现有方法计算成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 现有3D网格神经表示方法依赖神经过拟合和渐进式解码，计算成本高且处理不规则网格结构复杂。而图像具有规则结构优势但难以直接应用于网格。

Method: 利用几何图像将不规则网格转换为规则图像网格，采用最优传输(OT)解决区域采样不均问题，通过几何图像mipmapping实现连续细节层次(LoD)，实现无解码器的单次前向传递恢复。

Result: 实验结果表明在压缩比(CR)、Chamfer距离(CD)和Hausdorff距离(HD)等指标上达到最先进的存储效率和恢复精度。

Conclusion: 基于神经几何图像的表示方法具有存储高效、无解码器、自然适合神经处理等优势，为3D网格处理提供了有效的解决方案。

Abstract: Neural representations for 3D meshes are emerging as an effective solution for compact storage and efficient processing. Existing methods often rely on neural overfitting, where a coarse mesh is stored and progressively refined through multiple decoder networks. While this can restore high-quality surfaces, it is computationally expensive due to successive decoding passes and the irregular structure of mesh data. In contrast, images have a regular structure that enables powerful super-resolution and restoration frameworks, but applying these advantages to meshes is difficult because their irregular connectivity demands complex encoder-decoder architectures. Our key insight is that a geometry image-based representation transforms irregular meshes into a regular image grid, making efficient image-based neural processing directly applicable. Building on this idea, we introduce our neural geometry image-based representation, which is decoder-free, storage-efficient, and naturally suited for neural processing. It stores a low-resolution geometry-image mipmap of the surface, from which high-quality meshes are restored in a single forward pass. To construct geometry images, we leverage Optimal Transport (OT), which resolves oversampling in flat regions and undersampling in feature-rich regions, and enables continuous levels of detail (LoD) through geometry-image mipmapping. Experimental results demonstrate state-of-the-art storage efficiency and restoration accuracy, measured by compression ratio (CR), Chamfer distance (CD), and Hausdorff distance (HD).

</details>


### [183] [Hierarchical GraphCut Phase Unwrapping based on Invariance of Diffeomorphisms Framework](https://arxiv.org/abs/2511.18682)
*Xiang Gao,Xinmu Wang,Zhou Zhao,Junqi Huang,Xianfeng David Gu*

Main category: cs.CV

TL;DR: 提出了一种基于图割和微分同胚的相位展开框架，通过图像空间中的共形映射和最优传输映射，将相位展开问题转化为像素标记问题，实现了45.5倍的加速和更低的L2误差。


<details>
  <summary>Details</summary>
Motivation: 现有相位展开方法在速度和精度之间存在权衡：快速方法精度不足，而精确算法速度过慢，无法满足实时应用需求。噪声、遮挡和复杂3D几何使得相位展开这一病态问题更具挑战性。

Method: 将基于图割的相位展开重新表述为像素标记问题，利用微分同胚的不变性特性，通过共形映射和最优运输映射在图像空间中应用。预计算输入相位数据的奇数个微分同胚，在每个域中应用分层图割算法，通过多数投票融合结果标签图来稳健估计每个像素的k值。

Result: 实验结果表明，该方法在真实实验和模拟中实现了45.5倍的加速和更低的L2误差，显示出实时应用的潜力。

Conclusion: 该框架通过将相位展开问题转化为像素标记问题，并利用微分同胚映射的特性，成功解决了现有方法在速度和精度之间的权衡问题，为实时3D扫描应用提供了可行的解决方案。

Abstract: Recent years have witnessed rapid advancements in 3D scanning technologies, with applications spanning VR/AR, digital human creation, and medical imaging. Structured-light scanning with phase-shifting techniques is preferred for its use of low-intensity visible light and high accuracy, making it well suited for capturing 4D facial dynamics. A key step is phase unwrapping, which recovers continuous phase values from measurements wrapped modulo 2pi. The goal is to estimate the unwrapped phase count k in the equation Phi = phi + 2pi k, where phi is the wrapped phase and Phi is the true phase. Noise, occlusions, and complex 3D geometry make recovering the true phase challenging because phase unwrapping is ill-posed: measurements only provide modulo 2pi values, and estimating k requires assumptions about surface continuity. Existing methods trade speed for accuracy: fast approaches lack precision, while accurate algorithms are too slow for real-time use. To overcome these limitations, this work proposes a phase unwrapping framework that reformulates GraphCut-based unwrapping as a pixel-labeling problem. This framework improves the estimation of the unwrapped phase count k through the invariance property of diffeomorphisms applied in image space via conformal and optimal transport (OT) maps. An odd number of diffeomorphisms are precomputed from the input phase data, and a hierarchical GraphCut algorithm is applied in each domain. The resulting label maps are fused via majority voting to robustly estimate k at each pixel. Experimental results demonstrate a 45.5x speedup and lower L2 error in real experiments and simulations, showing potential for real-time applications.

</details>


### [184] [Now You See It, Now You Don't - Instant Concept Erasure for Safe Text-to-Image and Video Generation](https://arxiv.org/abs/2511.18684)
*Shristi Das Biswas,Arani Roy,Kaushik Roy*

Main category: cs.CV

TL;DR: ICE是一种无需训练、模态无关的单次权重修改方法，用于精确持久地移除文本到图像和文本到视频模型中的概念，具有零推理开销和强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有概念移除方法存在成本高、推理开销大、易受对抗攻击等问题，且很少建模目标擦除概念与周围内容之间的潜在语义重叠，导致擦除后产生附带损害。

Method: 使用各向异性能量加权缩放定义擦除和保留子空间，通过独特的闭式重叠投影器显式正则化其交集，提出凸且Lipschitz有界的光谱遗忘目标，获得稳定唯一的解析解。

Result: 在艺术风格、物体、身份和显式内容的目标移除中，ICE在T2I和T2V模型上均实现了强擦除效果，同时保持原始生成能力的退化最小。

Conclusion: ICE是一种高效、鲁棒的概念擦除方法，能够在零开销下实现精确持久的概念移除，适用于多种模态和场景。

Abstract: Robust concept removal for text-to-image (T2I) and text-to-video (T2V) models is essential for their safe deployment. Existing methods, however, suffer from costly retraining, inference overhead, or vulnerability to adversarial attacks. Crucially, they rarely model the latent semantic overlap between the target erase concept and surrounding content -- causing collateral damage post-erasure -- and even fewer methods work reliably across both T2I and T2V domains. We introduce Instant Concept Erasure (ICE), a training-free, modality-agnostic, one-shot weight modification approach that achieves precise, persistent unlearning with zero overhead. ICE defines erase and preserve subspaces using anisotropic energy-weighted scaling, then explicitly regularises against their intersection using a unique, closed-form overlap projector. We pose a convex and Lipschitz-bounded Spectral Unlearning Objective, balancing erasure fidelity and intersection preservation, that admits a stable and unique analytical solution. This solution defines a dissociation operator that is translated to the model's text-conditioning layers, making the edit permanent and runtime-free. Across targeted removals of artistic styles, objects, identities, and explicit content, ICE efficiently achieves strong erasure with improved robustness to red-teaming, all while causing only minimal degradation of original generative abilities in both T2I and T2V models.

</details>


### [185] [EVCC: Enhanced Vision Transformer-ConvNeXt-CoAtNet Fusion for Classification](https://arxiv.org/abs/2511.18691)
*Kazi Reyazul Hasan,Md Nafiu Rahman,Wasif Jalal,Sadif Ahmed,Shahriar Raj,Mubasshira Musarrat,Muhammad Abdullah Adnan*

Main category: cs.CV

TL;DR: EVCC是一种结合Vision Transformer、轻量级ConvNeXt和CoAtNet的多分支架构，通过自适应token剪枝、门控双向交叉注意力等创新技术，在保持高精度的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的混合视觉架构虽然提升了图像分类性能，但通常伴随着高昂的计算成本。需要开发一种能够平衡精度和效率的架构。

Method: EVCC采用多分支架构，集成三种模型：Vision Transformer、轻量级ConvNeXt和CoAtNet。关键技术包括自适应token剪枝、门控双向交叉注意力、辅助分类头和动态路由门。

Result: 在CIFAR-100、Tobacco3482、CelebA和Brain Cancer数据集上的实验表明，EVCC相比DeiT-Base、MaxViT-Base和CrossViT-Base等模型，准确率提升最高达2个百分点，同时FLOPs减少25-35%。

Conclusion: EVCC通过动态调整计算需求，有效平衡了精度和效率的权衡，结合了全局上下文、局部细节和层次特征，适用于实际应用场景。

Abstract: Hybrid vision architectures combining Transformers and CNNs have significantly advanced image classification, but they usually do so at significant computational cost. We introduce EVCC (Enhanced Vision Transformer-ConvNeXt-CoAtNet), a novel multi-branch architecture integrating the Vision Transformer, lightweight ConvNeXt, and CoAtNet through key innovations: (1) adaptive token pruning with information preservation, (2) gated bidirectional cross-attention for enhanced feature refinement, (3) auxiliary classification heads for multi-task learning, and (4) a dynamic router gate employing context-aware confidence-driven weighting. Experiments across the CIFAR-100, Tobacco3482, CelebA, and Brain Cancer datasets demonstrate EVCC's superiority over powerful models like DeiT-Base, MaxViT-Base, and CrossViT-Base by consistently achieving state-of-the-art accuracy with improvements of up to 2 percentage points, while reducing FLOPs by 25 to 35%. Our adaptive architecture adjusts computational demands to deployment needs by dynamically reducing token count, efficiently balancing the accuracy-efficiency trade-off while combining global context, local details, and hierarchical features for real-world applications. The source code of our implementation is available at https://anonymous.4open.science/r/EVCC.

</details>


### [186] [Exploring Surround-View Fisheye Camera 3D Object Detection](https://arxiv.org/abs/2511.18695)
*Changcai Li,Wenwei Lin,Zuoxun Hou,Gang Chen,Wei Zhang,Huihui Zhou,Weishi Zheng*

Main category: cs.CV

TL;DR: 本文研究了使用环视鱼眼相机系统实现端到端3D目标检测的技术可行性，提出了两种鱼眼兼容的检测方法，并发布了首个鱼眼3D检测数据集Fisheye3DOD。


<details>
  <summary>Details</summary>
Motivation: 传统基于针孔相机模型的3D目标检测器在鱼眼图像上性能下降明显，需要开发专门针对鱼眼图像几何特性的检测方法。

Method: 提出了两种方法：基于鸟瞰图范式的FisheyeBEVDet和基于查询范式的FisheyePETR，均采用球面空间表示来有效捕捉鱼眼几何特性。

Result: 在Fisheye3DOD数据集上的实验表明，鱼眼兼容建模比基线方法准确率提升最高达6.2%。

Conclusion: 通过专门的几何建模，可以显著提升鱼眼图像上的3D目标检测性能，为自动驾驶环视系统提供了有效的技术解决方案。

Abstract: In this work, we explore the technical feasibility of implementing end-to-end 3D object detection (3DOD) with surround-view fisheye camera system. Specifically, we first investigate the performance drop incurred when transferring classic pinhole-based 3D object detectors to fisheye imagery. To mitigate this, we then develop two methods that incorporate the unique geometry of fisheye images into mainstream detection frameworks: one based on the bird's-eye-view (BEV) paradigm, named FisheyeBEVDet, and the other on the query-based paradigm, named FisheyePETR. Both methods adopt spherical spatial representations to effectively capture fisheye geometry. In light of the lack of dedicated evaluation benchmarks, we release Fisheye3DOD, a new open dataset synthesized using CARLA and featuring both standard pinhole and fisheye camera arrays. Experiments on Fisheye3DOD show that our fisheye-compatible modeling improves accuracy by up to 6.2% over baseline methods.

</details>


### [187] [Dendritic Convolution for Noise Image Recognition](https://arxiv.org/abs/2511.18699)
*Jiarui Xue,Dongjian Yang,Ye Sun,Gang Liu*

Main category: cs.CV

TL;DR: 本文提出了一种抗噪声神经元卷积（DDC），通过模拟神经元树突结构，将邻域交互计算逻辑融入卷积操作底层设计，在噪声环境下显著提升图像分类和目标检测任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注网络结构或训练策略调整，抗噪声性能已达瓶颈。从神经元视角探索抗干扰解决方案的研究较少，需要从根本上重构特征提取的数学范式。

Method: 提出抗噪声神经元卷积，模仿神经元树突结构，通过输入特征间的非线性交互模拟生物树突的XOR逻辑预处理功能，重构特征提取的数学基础。

Result: 在图像分类任务中，EfficientNet-B0模型在噪声数据集上的准确率相对提升11.23%；在目标检测任务中，YOLOv8的mAP提升19.80%。

Conclusion: 该卷积的计算方式与生物神经元树突的一致性使其在复杂噪声环境中表现显著优于传统卷积。

Abstract: In real-world scenarios of image recognition, there exists substantial noise interference. Existing works primarily focus on methods such as adjusting networks or training strategies to address noisy image recognition, and the anti-noise performance has reached a bottleneck. However, little is known about the exploration of anti-interference solutions from a neuronal perspective.This paper proposes an anti-noise neuronal convolution. This convolution mimics the dendritic structure of neurons, integrates the neighborhood interaction computation logic of dendrites into the underlying design of convolutional operations, and simulates the XOR logic preprocessing function of biological dendrites through nonlinear interactions between input features, thereby fundamentally reconstructing the mathematical paradigm of feature extraction. Unlike traditional convolution where noise directly interferes with feature extraction and exerts a significant impact, DDC mitigates the influence of noise by focusing on the interaction of neighborhood information. Experimental results demonstrate that in image classification tasks (using YOLOv11-cls, VGG16, and EfficientNet-B0) and object detection tasks (using YOLOv11, YOLOv8, and YOLOv5), after replacing traditional convolution with the dendritic convolution, the accuracy of the EfficientNet-B0 model on noisy datasets is relatively improved by 11.23%, and the mean Average Precision (mAP) of YOLOv8 is increased by 19.80%. The consistency between the computation method of this convolution and the dendrites of biological neurons enables it to perform significantly better than traditional convolution in complex noisy environments.

</details>


### [188] [ObjectAlign: Neuro-Symbolic Object Consistency Verification and Correction](https://arxiv.org/abs/2511.18701)
*Mustafa Munir,Harsh Goel,Xiwen Wei,Minkyu Choi,Sahil Shah,Kartikeya Bhardwaj,Paul Whatmough,Sandeep Chinchali,Radu Marculescu*

Main category: cs.CV

TL;DR: ObjectAlign是一个融合感知度量和符号推理的框架，用于检测和纠正视频编辑中的对象不一致问题，如帧闪烁和身份漂移。


<details>
  <summary>Details</summary>
Motivation: 视频编辑和合成常引入对象不一致问题，如帧闪烁和身份漂移，这会降低感知质量。

Method: 提出可学习阈值来表征对象一致性度量，引入神经符号验证器结合SMT检查和概率模型检查器，并使用神经网络插值进行自适应帧修复。

Result: 在DAVIS和Pexels视频数据集上，相比SOTA基线，CLIP Score提升1.4分，warp error提升6.1分。

Conclusion: ObjectAlign通过结合感知度量和符号推理，有效解决了视频编辑中的对象不一致问题，提升了视频质量。

Abstract: Video editing and synthesis often introduce object inconsistencies, such as frame flicker and identity drift that degrade perceptual quality. To address these issues, we introduce ObjectAlign, a novel framework that seamlessly blends perceptual metrics with symbolic reasoning to detect, verify, and correct object-level and temporal inconsistencies in edited video sequences. The novel contributions of ObjectAlign are as follows: First, we propose learnable thresholds for metrics characterizing object consistency (i.e. CLIP-based semantic similarity, LPIPS perceptual distance, histogram correlation, and SAM-derived object-mask IoU). Second, we introduce a neuro-symbolic verifier that combines two components: (a) a formal, SMT-based check that operates on masked object embeddings to provably guarantee that object identity does not drift, and (b) a temporal fidelity check that uses a probabilistic model checker to verify the video's formal representation against a temporal logic specification. A frame transition is subsequently deemed "consistent" based on a single logical assertion that requires satisfying both the learned metric thresholds and this unified neuro-symbolic constraint, ensuring both low-level stability and high-level temporal correctness. Finally, for each contiguous block of flagged frames, we propose a neural network based interpolation for adaptive frame repair, dynamically choosing the interpolation depth based on the number of frames to be corrected. This enables reconstruction of the corrupted frames from the last valid and next valid keyframes. Our results show up to 1.4 point improvement in CLIP Score and up to 6.1 point improvement in warp error compared to SOTA baselines on the DAVIS and Pexels video datasets.

</details>


### [189] [CoD: A Diffusion Foundation Model for Image Compression](https://arxiv.org/abs/2511.18706)
*Zhaoyang Jia,Zihan Zheng,Naifu Xue,Jiahao Li,Bin Li,Zongyu Guo,Xiaoyi Zhang,Houqiang Li,Yan Lu*

Main category: cs.CV

TL;DR: CoD是首个专为压缩优化的扩散基础模型，相比基于文本条件的Stable Diffusion，在超低码率下具有更好的压缩效率和感知质量，训练成本大幅降低。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本条件的扩散模型在压缩场景下存在局限性，特别是在超低码率时性能不佳，需要专门为压缩优化的基础模型。

Method: 从头训练压缩导向的扩散基础模型CoD，使用纯图像数据集，训练效率比Stable Diffusion高300倍，支持像素空间扩散实现高压缩效率。

Result: 在DiffC等下游编解码器中替换Stable Diffusion为CoD后，在超低码率（如0.0039bpp）下达到SOTA性能，像素空间扩散可实现VTM级PSNR并超越GAN-based编解码器。

Conclusion: CoD为未来扩散编解码器研究奠定了基础，证明了专门压缩优化模型在效率和性能上的优势。

Abstract: Existing diffusion codecs typically build on text-to-image diffusion foundation models like Stable Diffusion. However, text conditioning is suboptimal from a compression perspective, hindering the potential of downstream diffusion codecs, particularly at ultra-low bitrates. To address it, we introduce \textbf{CoD}, the first \textbf{Co}mpression-oriented \textbf{D}iffusion foundation model, trained from scratch to enable end-to-end optimization of both compression and generation. CoD is not a fixed codec but a general foundation model designed for various diffusion-based codecs. It offers several advantages: \textbf{High compression efficiency}, replacing Stable Diffusion with CoD in downstream codecs like DiffC achieves SOTA results, especially at ultra-low bitrates (e.g., 0.0039 bpp); \textbf{Low-cost and reproducible training}, 300$\times$ faster training than Stable Diffusion ($\sim$ 20 vs. $\sim$ 6,250 A100 GPU days) on entirely open image-only datasets; \textbf{Providing new insights}, e.g., We find pixel-space diffusion can achieve VTM-level PSNR with high perceptual quality and can outperform GAN-based codecs using fewer parameters. We hope CoD lays the foundation for future diffusion codec research. Codes will be released.

</details>


### [190] [Modality-Collaborative Low-Rank Decomposers for Few-Shot Video Domain Adaptation](https://arxiv.org/abs/2511.18711)
*Yuyang Wanyan,Xiaoshan Yang,Weiming Dong,Changsheng Xu*

Main category: cs.CV

TL;DR: 本文提出了一种用于少样本视频域适应（FSVDA）的新框架MC-LRD，通过模态协同低秩分解器解决多模态视频中域对齐和模态协作的挑战。


<details>
  <summary>Details</summary>
Motivation: 视频的多模态特性在少样本场景下同时面临域对齐和模态协作的挑战，现有方法忽略了这一关键问题。作者观察到在域偏移影响下，各模态及融合特征的泛化性能受限，因为每个模态包含多个具有不同域偏移程度的耦合特征组件。

Method: 提出MC-LRD框架，包含每个模态的多个分解器和多模态分解路由器（MDR）。分解器在不同模态间逐步共享参数，MDR选择性激活分解器产生模态独特和模态共享特征。应用正交去相关约束增强分解器多样性，并提出跨域激活一致性损失保证同类样本的分解器激活一致性。

Result: 在三个公共基准测试上的大量实验结果表明，该方法相比现有方法取得了显著改进。

Conclusion: MC-LRD框架有效解决了少样本视频域适应中的多模态挑战，通过特征分解和跨域一致性约束实现了更好的域对齐和模态协作性能。

Abstract: In this paper, we study the challenging task of Few-Shot Video Domain Adaptation (FSVDA). The multimodal nature of videos introduces unique challenges, necessitating the simultaneous consideration of both domain alignment and modality collaboration in a few-shot scenario, which is ignored in previous literature. We observe that, under the influence of domain shift, the generalization performance on the target domain of each individual modality, as well as that of fused multimodal features, is constrained. Because each modality is comprised of coupled features with multiple components that exhibit different domain shifts. This variability increases the complexity of domain adaptation, thereby reducing the effectiveness of multimodal feature integration. To address these challenges, we introduce a novel framework of Modality-Collaborative LowRank Decomposers (MC-LRD) to decompose modality-unique and modality-shared features with different domain shift levels from each modality that are more friendly for domain alignment. The MC-LRD comprises multiple decomposers for each modality and Multimodal Decomposition Routers (MDR). Each decomposer has progressively shared parameters across different modalities. The MDR is leveraged to selectively activate the decomposers to produce modality-unique and modality-shared features. To ensure efficient decomposition, we apply orthogonal decorrelation constraints separately to decomposers and subrouters, enhancing their diversity. Furthermore, we propose a cross-domain activation consistency loss to guarantee that target and source samples of the same category exhibit consistent activation preferences of the decomposers, thereby facilitating domain alignment. Extensive experimental results on three public benchmarks demonstrate that our model achieves significant improvements over existing methods.

</details>


### [191] [DriveFlow: Rectified Flow Adaptation for Robust 3D Object Detection in Autonomous Driving](https://arxiv.org/abs/2511.18713)
*Hongbin Lin,Yiming Yang,Chaoda Zheng,Yifan Zhang,Shuaicheng Niu,Zilu Guo,Yafeng Li,Gui Gui,Shuguang Cui,Zhen Li*

Main category: cs.CV

TL;DR: DriveFlow提出了一种基于预训练文本到图像流模型的修正流适应方法，用于自动驾驶训练数据增强，通过频率分解策略解决OOD问题。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中视觉中心的3D物体检测面临标注成本高和场景多样性导致的OOD问题，现有训练免费图像编辑方法存在效果有限或3D几何精度不足的问题。

Method: 基于频率分解的修正流适应方法：1）高频前景保持策略，通过高频对齐损失维护精确3D物体几何；2）双频背景优化，平衡编辑灵活性和语义一致性。

Result: 综合实验验证了DriveFlow的有效性和效率，在OOD场景下所有类别均表现出全面的性能提升。

Conclusion: DriveFlow为自动驾驶训练数据增强提供了有效的解决方案，通过频率分解策略成功解决了现有方法的局限性。

Abstract: In autonomous driving, vision-centric 3D object detection recognizes and localizes 3D objects from RGB images. However, due to high annotation costs and diverse outdoor scenes, training data often fails to cover all possible test scenarios, known as the out-of-distribution (OOD) issue. Training-free image editing offers a promising solution for improving model robustness by training data enhancement without any modifications to pre-trained diffusion models. Nevertheless, inversion-based methods often suffer from limited effectiveness and inherent inaccuracies, while recent rectified-flow-based approaches struggle to preserve objects with accurate 3D geometry. In this paper, we propose DriveFlow, a Rectified Flow Adaptation method for training data enhancement in autonomous driving based on pre-trained Text-to-Image flow models. Based on frequency decomposition, DriveFlow introduces two strategies to adapt noise-free editing paths derived from text-conditioned velocities. 1) High-Frequency Foreground Preservation: DriveFlow incorporates a high-frequency alignment loss for foreground to maintain precise 3D object geometry. 2) Dual-Frequency Background Optimization: DriveFlow also conducts dual-frequency optimization for background, balancing editing flexibility and semantic consistency. Comprehensive experiments validate the effectiveness and efficiency of DriveFlow, demonstrating comprehensive performance improvements on all categories across OOD scenarios. Code is available at https://github.com/Hongbin98/DriveFlow.

</details>


### [192] [Seeing What Matters: Visual Preference Policy Optimization for Visual Generation](https://arxiv.org/abs/2511.18719)
*Ziqi Ni,Yuanzhi Liang,Rui Li,Yi Zhou,Haibing Huang,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: ViPO是一种改进的GRPO方法，通过将标量奖励提升为像素级优势图，利用预训练视觉骨干网络构建空间和时间感知的优势映射，从而在视觉生成任务中提供更精细的学习信号。


<details>
  <summary>Details</summary>
Motivation: 现有的GRPO方法仅使用每样本的单一标量奖励，将图像或视频视为整体，忽略了视觉内容的丰富空间和时间结构，这种粗粒度监督限制了局部伪影的纠正和细粒度感知线索的建模。

Method: ViPO引入感知结构化模块，使用预训练视觉骨干网络构建空间和时间感知的优势图，将优化压力重新分配到感知重要区域，同时保持标准GRPO的稳定性。

Result: 在图像和视频基准测试中，ViPO始终优于原始GRPO，在人类偏好奖励的领域内对齐和领域外评估的泛化能力方面都有提升。

Conclusion: ViPO是一种架构无关、轻量级且与现有GRPO训练管道完全兼容的方法，为视觉生成提供了更具表达力和信息量的学习信号。

Abstract: Reinforcement learning (RL) has become a powerful tool for post-training visual generative models, with Group Relative Policy Optimization (GRPO) increasingly used to align generators with human preferences. However, existing GRPO pipelines rely on a single scalar reward per sample, treating each image or video as a holistic entity and ignoring the rich spatial and temporal structure of visual content. This coarse supervision hinders the correction of localized artifacts and the modeling of fine-grained perceptual cues. We introduce Visual Preference Policy Optimization (ViPO), a GRPO variant that lifts scalar feedback into structured, pixel-level advantages. ViPO employs a Perceptual Structuring Module that uses pretrained vision backbones to construct spatially and temporally aware advantage maps, redistributing optimization pressure toward perceptually important regions while preserving the stability of standard GRPO. Across both image and video benchmarks, ViPO consistently outperforms vanilla GRPO, improving in-domain alignment with human-preference rewards and enhancing generalization on out-of-domain evaluations. The method is architecture-agnostic, lightweight, and fully compatible with existing GRPO training pipelines, providing a more expressive and informative learning signal for visual generation.

</details>


### [193] [GuideFlow: Constraint-Guided Flow Matching for Planning in End-to-End Autonomous Driving](https://arxiv.org/abs/2511.18729)
*Lin Liu,Caiyan Jia,Guanyi Yu,Ziying Song,JunQiao Li,Feiyang Jia,Peiliang Wu,Xiaoshuai Hao,Yandan Luo*

Main category: cs.CV

TL;DR: GuideFlow是一个基于约束流匹配的新型端到端自动驾驶规划框架，通过显式约束建模和能量模型训练，解决了现有方法的多模态轨迹崩溃和约束集成问题，在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有端到端规划器存在两个主要问题：模仿式方法容易产生多模态轨迹崩溃，无法生成多样化轨迹；生成式方法难以在生成过程中直接集成安全性和物理约束，需要额外优化阶段。

Method: GuideFlow采用约束流匹配框架，显式建模流匹配过程来缓解模式崩溃，并直接强制执行显式约束。核心创新是将流匹配训练与能量模型统一，增强模型自主优化能力以满足物理约束。同时参数化驾驶激进程度作为控制信号。

Result: 在多个主要驾驶基准测试（Bench2Drive、NuScenes、NavSim和ADV-NuScenes）上验证了有效性，特别是在NavSim测试困难分割上达到SOTA，EPDMS得分为43.0。

Conclusion: GuideFlow成功解决了端到端自动驾驶规划中的多模态轨迹生成和约束集成问题，通过约束流匹配框架实现了更好的性能表现。

Abstract: Driving planning is a critical component of end-to-end (E2E) autonomous driving. However, prevailing Imitative E2E Planners often suffer from multimodal trajectory mode collapse, failing to produce diverse trajectory proposals. Meanwhile, Generative E2E Planners struggle to incorporate crucial safety and physical constraints directly into the generative process, necessitating an additional optimization stage to refine their outputs. In this paper, we propose \textit{\textbf{GuideFlow}}, a novel planning framework that leverages Constrained Flow Matching. Concretely, \textit{\textbf{GuideFlow}} explicitly models the flow matching process, which inherently mitigates mode collapse and allows for flexible guidance from various conditioning signals. Our core contribution lies in directly enforcing explicit constraints within the flow matching generation process, rather than relying on implicit constraint encoding. Crucially, \textit{\textbf{GuideFlow}} unifies the training of the flow matching with the Energy-Based Model (EBM) to enhance the model's autonomous optimization capability to robustly satisfy physical constraints. Secondly, \textit{\textbf{GuideFlow}} parameterizes driving aggressiveness as a control signal during generation, enabling precise manipulation of trajectory style. Extensive evaluations on major driving benchmarks (Bench2Drive, NuScenes, NavSim and ADV-NuScenes) validate the effectiveness of \textit{\textbf{GuideFlow}}. Notably, on the NavSim test hard split (Navhard), \textit{\textbf{GuideFlow}} achieved SOTA with an EPDMS score of 43.0. The code will be released.

</details>


### [194] [Yo'City: Personalized and Boundless 3D Realistic City Scene Generation via Self-Critic Expansion](https://arxiv.org/abs/2511.18734)
*Keyang Lu,Sifan Zhou,Hongbin Xu,Gang Xu,Zhifei Yang,Yikai Wang,Zhen Xiao,Jieyi Long,Ming Li*

Main category: cs.CV

TL;DR: Yo'City是一个基于智能代理的3D城市生成框架，通过分层规划和关系引导扩展机制实现用户定制和无限扩展的城市生成


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖单一扩散模型，限制了生成个性化和无边界城市场景的能力，需要更灵活的框架来支持用户定制和持续扩展

Method: 采用分层"城市-区域-网格"规划策略，结合等距图像合成循环和图像到3D生成，通过场景图进行距离和语义感知的布局优化

Result: 在构建的多样化基准数据集上，Yo'City在语义、几何、纹理和布局等多个维度上均优于现有最先进方法

Conclusion: Yo'City框架成功实现了用户定制和无限扩展的3D城市生成，证明了智能代理框架在城市生成任务中的有效性

Abstract: Realistic 3D city generation is fundamental to a wide range of applications, including virtual reality and digital twins. However, most existing methods rely on training a single diffusion model, which limits their ability to generate personalized and boundless city-scale scenes. In this paper, we present Yo'City, a novel agentic framework that enables user-customized and infinitely expandable 3D city generation by leveraging the reasoning and compositional capabilities of off-the-shelf large models. Specifically, Yo'City first conceptualize the city through a top-down planning strategy that defines a hierarchical "City-District-Grid" structure. The Global Planner determines the overall layout and potential functional districts, while the Local Designer further refines each district with detailed grid-level descriptions. Subsequently, the grid-level 3D generation is achieved through a "produce-refine-evaluate" isometric image synthesis loop, followed by image-to-3D generation. To simulate continuous city evolution, Yo'City further introduces a user-interactive, relationship-guided expansion mechanism, which performs scene graph-based distance- and semantics-aware layout optimization, ensuring spatially coherent city growth. To comprehensively evaluate our method, we construct a diverse benchmark dataset and design six multi-dimensional metrics that assess generation quality from the perspectives of semantics, geometry, texture, and layout. Extensive experiments demonstrate that Yo'City consistently outperforms existing state-of-the-art methods across all evaluation aspects.

</details>


### [195] [Thinking Ahead: Foresight Intelligence in MLLMs and World Models](https://arxiv.org/abs/2511.18735)
*Zhantao Gong,Liaoyuan Fan,Qing Guo,Xun Xu,Xulei Yang,Shijie Li*

Main category: cs.CV

TL;DR: 提出了Foresight Intelligence（前瞻智能）概念，并创建了FSU-QA数据集来评估和提升视觉语言模型在预测未来事件方面的能力。研究发现当前模型在前瞻推理方面表现不佳，但通过FSU-QA微调后的小模型能超越更大模型。


<details>
  <summary>Details</summary>
Motivation: 前瞻智能对自动驾驶等应用至关重要，但现有研究普遍忽视这一能力。需要专门的数据集和评估方法来填补这一研究空白。

Method: 引入FSU-QA视觉问答数据集，对前沿视觉语言模型进行前瞻任务评估，并通过微调实验验证数据集的有效性。

Result: 当前模型在前瞻推理方面表现不佳，但使用FSU-QA微调的小模型能大幅超越未微调的大模型，证明了数据集的有效性。

Conclusion: FSU-QA为开发具有真正前瞻智能的下一代模型提供了理论基础和评估基准，有望推动前瞻智能研究的发展。

Abstract: In this work, we define Foresight Intelligence as the capability to anticipate and interpret future events-an ability essential for applications such as autonomous driving, yet largely overlooked by existing research. To bridge this gap, we introduce FSU-QA, a new Visual Question-Answering (VQA) dataset specifically designed to elicit and evaluate Foresight Intelligence. Using FSU-QA, we conduct the first comprehensive study of state-of-the-art Vision-Language Models (VLMs) under foresight-oriented tasks, revealing that current models still struggle to reason about future situations. Beyond serving as a benchmark, FSU-QA also enables the assessment of world models by measuring the semantic coherence of their generated predictions, quantified through performance gains when VLMs are augmented with such outputs. Our experiments further demonstrate that FSU-QA can effectively enhance foresight reasoning: even small VLMs fine-tuned on FSU-QA surpass much larger, advanced models by a substantial margin. Together, these findings position FSU-QA as a principled foundation for developing next-generation models capable of truly anticipating and understanding future events.

</details>


### [196] [ProxT2I: Efficient Reward-Guided Text-to-Image Generation via Proximal Diffusion](https://arxiv.org/abs/2511.18742)
*Zhenghan Fang,Jian Zheng,Qiaozi Gao,Xiaofeng Gao,Jeremias Sulam*

Main category: cs.CV

TL;DR: 本文提出了一种基于反向离散化的文本到图像扩散模型ProxT2I，使用学习的条件近端算子替代分数函数，结合强化学习优化采样器，并构建了大规模数据集LAION-Face-T2I-15M。该方法在采样效率和人类偏好对齐方面优于基于分数的基线方法。


<details>
  <summary>Details</summary>
Motivation: 当前大多数扩散模型采样器依赖正向离散化和数据学习的分数函数，存在采样速度慢、稳定性差的问题，需要大量采样步骤才能生成高质量样本。

Method: 开发基于反向离散化的文本到图像扩散模型ProxT2I，使用学习的条件近端算子替代分数函数；利用强化学习和策略优化技术优化采样器的任务特定奖励；构建包含1500万高质量人脸图像的大规模开源数据集LAION-Face-T2I-15M。

Result: 相比基于分数的基线方法，ProxT2I在采样效率和人类偏好对齐方面表现更优；在计算资源更少、模型规模更小的情况下，达到了与现有最先进开源文本到图像模型相当的结果。

Conclusion: ProxT2I为人脸文本到图像生成提供了一个轻量级但性能优越的解决方案，在保持高性能的同时显著降低了计算需求。

Abstract: Diffusion models have emerged as a dominant paradigm for generative modeling across a wide range of domains, including prompt-conditional generation. The vast majority of samplers, however, rely on forward discretization of the reverse diffusion process and use score functions that are learned from data. Such forward and explicit discretizations can be slow and unstable, requiring a large number of sampling steps to produce good-quality samples. In this work we develop a text-to-image (T2I) diffusion model based on backward discretizations, dubbed ProxT2I, relying on learned and conditional proximal operators instead of score functions. We further leverage recent advances in reinforcement learning and policy optimization to optimize our samplers for task-specific rewards. Additionally, we develop a new large-scale and open-source dataset comprising 15 million high-quality human images with fine-grained captions, called LAION-Face-T2I-15M, for training and evaluation. Our approach consistently enhances sampling efficiency and human-preference alignment compared to score-based baselines, and achieves results on par with existing state-of-the-art and open-source text-to-image models while requiring lower compute and smaller model size, offering a lightweight yet performant solution for human text-to-image generation.

</details>


### [197] [Any4D: Open-Prompt 4D Generation from Natural Language and Images](https://arxiv.org/abs/2511.18746)
*Hao Li,Qiao Sun*

Main category: cs.CV

TL;DR: PEWM提出了一种基于原始动作的具身世界模型，通过限制视频生成为固定短时程来解决具身数据稀缺和长时程生成困难的问题，实现了细粒度语言-动作对齐并提高数据效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于视频生成的具身世界模型严重依赖大规模具身交互数据，但具身数据的稀缺性、收集难度和高维度限制了语言与动作的细粒度对齐，并加剧了长时程视频生成的挑战，阻碍了具身领域的"GPT时刻"。

Method: PEWM将视频生成限制在固定短时程，配备模块化视觉语言模型规划器和起点-目标热图引导机制，利用视频模型的时空视觉先验和VLM的语义感知能力，实现原始动作级别的组合泛化。

Result: 该方法实现了细粒度语言-动作对齐，降低了学习复杂度，提高了具身数据收集效率，减少了推理延迟，并支持复杂任务的灵活闭环控制和组合泛化。

Conclusion: PEWM通过桥接细粒度物理交互和高层推理，为可扩展、可解释和通用具身智能铺平了道路。

Abstract: While video-generation-based embodied world models have gained increasing attention, their reliance on large-scale embodied interaction data remains a key bottleneck. The scarcity, difficulty of collection, and high dimensionality of embodied data fundamentally limit the alignment granularity between language and actions and exacerbate the challenge of long-horizon video generation--hindering generative models from achieving a \textit{"GPT moment"} in the embodied domain. There is a naive observation: \textit{the diversity of embodied data far exceeds the relatively small space of possible primitive motions}. Based on this insight, we propose \textbf{Primitive Embodied World Models} (PEWM), which restricts video generation to fixed shorter horizons, our approach \textit{1) enables} fine-grained alignment between linguistic concepts and visual representations of robotic actions, \textit{2) reduces} learning complexity, \textit{3) improves} data efficiency in embodied data collection, and \textit{4) decreases} inference latency. By equipping with a modular Vision-Language Model (VLM) planner and a Start-Goal heatmap Guidance mechanism (SGG), PEWM further enables flexible closed-loop control and supports compositional generalization of primitive-level policies over extended, complex tasks. Our framework leverages the spatiotemporal vision priors in video models and the semantic awareness of VLMs to bridge the gap between fine-grained physical interaction and high-level reasoning, paving the way toward scalable, interpretable, and general-purpose embodied intelligence.

</details>


### [198] [From Features to Reference Points: Lightweight and Adaptive Fusion for Cooperative Autonomous Driving](https://arxiv.org/abs/2511.18757)
*Yongqi Zhu,Morui Zhu,Qi Chen,Deyuan Qu,Song Fu,Qing Yang*

Main category: cs.CV

TL;DR: RefPtsFusion是一个轻量级、可解释的协同自动驾驶框架，通过交换紧凑的参考点（如物体位置、速度、尺寸信息）而非大型特征图，将通信带宽降低五个数量级（从数百MB/s降至几KB/s），同时保持稳定的感知性能。


<details>
  <summary>Details</summary>
Motivation: 传统协同自动驾驶方法需要共享大型特征图或查询嵌入，导致通信带宽需求过高，且难以在不同感知模型的异构车辆间工作。需要一种传感器和模型无关的轻量级接口。

Method: 1. 交换紧凑参考点而非特征图；2. 开发选择性Top-K查询融合，选择性添加发送方的高置信度查询；3. 创建传感器和模型无关的接口，关注"在哪里看"而非"看到了什么"。

Result: 在M3CAD数据集上的实验显示：通信开销降低五个数量级（数百MB/s→几KB/s@5FPS），同时保持稳定感知性能；框架具有强鲁棒性和一致的传输行为。

Conclusion: RefPtsFusion在精度和通信成本之间实现了良好平衡，展示了其在可扩展、实时协同驾驶系统中的潜力，特别适用于异构车辆环境。

Abstract: We present RefPtsFusion, a lightweight and interpretable framework for cooperative autonomous driving. Instead of sharing large feature maps or query embeddings, vehicles exchange compact reference points, e.g., objects' positions, velocities, and size information. This approach shifts the focus from "what is seen" to "where to see", creating a sensor- and model-independent interface that works well across vehicles with heterogeneous perception models while greatly reducing communication bandwidth. To enhance the richness of shared information, we further develop a selective Top-K query fusion that selectively adds high-confidence queries from the sender. It thus achieves a strong balance between accuracy and communication cost. Experiments on the M3CAD dataset show that RefPtsFusion maintains stable perception performance while reducing communication overhead by five orders of magnitude, dropping from hundreds of MB/s to only a few KB/s at 5 FPS (frame per second), compared to traditional feature-level fusion methods. Extensive experiments also demonstrate RefPtsFusion's strong robustness and consistent transmission behavior, highlighting its potential for scalable, real-time cooperative driving systems.

</details>


### [199] [VAOT: Vessel-Aware Optimal Transport for Retinal Fundus Enhancement](https://arxiv.org/abs/2511.18763)
*Xuanzhao Dong,Wenhui Zhu,Yujian Xiong,Xiwen Chen,Hao Wang,Xin Li,Jiajun Cheng,Zhipeng Wang,Shao Tang,Oana Dumitrascu,Yalin Wang*

Main category: cs.CV

TL;DR: 提出VAOT框架，通过最优传输目标和结构保留正则化器来增强彩色眼底图像，同时保持血管结构完整性


<details>
  <summary>Details</summary>
Motivation: 解决传统GAN方法在眼底图像增强中会扭曲血管结构的问题，特别是血管拓扑和端点完整性的改变

Method: 结合最优传输目标和两个结构保留正则化器：基于骨架的损失函数保持全局血管连通性，端点感知损失稳定局部端点

Result: 在合成退化基准测试和血管/病灶分割的下游评估中，该方法优于多个最先进基线方法

Conclusion: VAOT框架能够有效减少眼底图像噪声，同时保持血管结构完整性，在临床应用中具有重要价值

Abstract: Color fundus photography (CFP) is central to diagnosing and monitoring retinal disease, yet its acquisition variability (e.g., illumination changes) often degrades image quality, which motivates robust enhancement methods. Unpaired enhancement pipelines are typically GAN-based, however, they can distort clinically critical vasculature, altering vessel topology and endpoint integrity. Motivated by these structural alterations, we propose Vessel-Aware Optimal Transport (\textbf{VAOT}), a framework that combines an optimal-transport objective with two structure-preserving regularizers: (i) a skeleton-based loss to maintain global vascular connectivity and (ii) an endpoint-aware loss to stabilize local termini. These constraints guide learning in the unpaired setting, reducing noise while preserving vessel structure. Experimental results on synthetic degradation benchmark and downstream evaluations in vessel and lesion segmentation demonstrate the superiority of the proposed methods against several state-of-the art baselines. The code is available at https://github.com/Retinal-Research/VAOT

</details>


### [200] [NI-Tex: Non-isometric Image-based Garment Texture Generation](https://arxiv.org/abs/2511.18765)
*Hui Shan,Ming Li,Haitao Yang,Kai Zheng,Sizhe Zheng,Yanwei Fu,Xiangru Huang*

Main category: cs.CV

TL;DR: 提出了一种用于非等距图像到3D服装纹理生成的方法，通过物理模拟数据集和双分支架构，实现跨姿态和跨拓扑的PBR纹理生成。


<details>
  <summary>Details</summary>
Motivation: 现有工业3D服装网格的纹理多样性有限，传统方法需要严格的拓扑一致性或准确的网格变形，限制了纹理生成的质量和灵活性。

Method: 构建3D服装视频数据集提供几何和材质监督，使用Nano Banana进行高质量非等距图像编辑，提出迭代烘焙方法通过不确定性引导的视图选择和重加权融合多视图预测。

Result: 通过大量实验证明，该前馈双分支架构能生成适用于工业级3D服装设计的多样化且空间对齐的PBR材质。

Conclusion: 该方法解决了非等距图像到服装纹理生成的挑战性问题，为工业3D服装设计提供了更灵活和高质量的纹理生成方案。

Abstract: Existing industrial 3D garment meshes already cover most real-world clothing geometries, yet their texture diversity remains limited. To acquire more realistic textures, generative methods are often used to extract Physically-based Rendering (PBR) textures and materials from large collections of wild images and project them back onto garment meshes. However, most image-conditioned texture generation approaches require strict topological consistency between the input image and the input 3D mesh, or rely on accurate mesh deformation to match to the image poses, which significantly constrains the texture generation quality and flexibility. To address the challenging problem of non-isometric image-based garment texture generation, we construct 3D Garment Videos, a physically simulated, garment-centric dataset that provides consistent geometry and material supervision across diverse deformations, enabling robust cross-pose texture learning. We further employ Nano Banana for high-quality non-isometric image editing, achieving reliable cross-topology texture generation between non-isometric image-geometry pairs. Finally, we propose an iterative baking method via uncertainty-guided view selection and reweighting that fuses multi-view predictions into seamless, production-ready PBR textures. Through extensive experiments, we demonstrate that our feedforward dual-branch architecture generates versatile and spatially aligned PBR materials suitable for industry-level 3D garment design.

</details>


### [201] [Unsupervised Multi-View Visual Anomaly Detection via Progressive Homography-Guided Alignment](https://arxiv.org/abs/2511.18766)
*Xintao Chen,Xiaohao Xu,Bozhong Zheng,Yun Liu,Yingna Wu*

Main category: cs.CV

TL;DR: VSAD是一种新颖的多视角异常检测框架，通过显式建模几何一致性来学习视角不变表示，显著提升了异常检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将多视角图像视为不连接的图像集合，导致特征表示不一致和误报率高。需要解决视角变化引起的良性外观变化与真实缺陷之间的区分问题。

Method: 提出ViewSense-AD框架，包含多视角对齐模块(MVAM)和视角对齐潜在扩散模型(VALDM)，利用单应性投影对齐相邻视角的特征区域，并在去噪过程中进行渐进式多阶段对齐。

Result: 在RealIAD和MANTA数据集上的实验表明，VSAD在像素、视角和样本级别的视觉异常检测中均达到新的最先进水平，显著优于现有方法。

Conclusion: VSAD通过几何一致性建模和多阶段对齐策略，有效提升了多视角异常检测的鲁棒性和准确性，特别适用于大视角偏移和复杂纹理场景。

Abstract: Unsupervised visual anomaly detection from multi-view images presents a significant challenge: distinguishing genuine defects from benign appearance variations caused by viewpoint changes. Existing methods, often designed for single-view inputs, treat multiple views as a disconnected set of images, leading to inconsistent feature representations and a high false-positive rate. To address this, we introduce ViewSense-AD (VSAD), a novel framework that learns viewpoint-invariant representations by explicitly modeling geometric consistency across views. At its core is our Multi-View Alignment Module (MVAM), which leverages homography to project and align corresponding feature regions between neighboring views. We integrate MVAM into a View-Align Latent Diffusion Model (VALDM), enabling progressive and multi-stage alignment during the denoising process. This allows the model to build a coherent and holistic understanding of the object's surface from coarse to fine scales. Furthermore, a lightweight Fusion Refiner Module (FRM) enhances the global consistency of the aligned features, suppressing noise and improving discriminative power. Anomaly detection is performed by comparing multi-level features from the diffusion model against a learned memory bank of normal prototypes. Extensive experiments on the challenging RealIAD and MANTA datasets demonstrate that VSAD sets a new state-of-the-art, significantly outperforming existing methods in pixel, view, and sample-level visual anomaly proving its robustness to large viewpoint shifts and complex textures.

</details>


### [202] [Rethinking Garment Conditioning in Diffusion-based Virtual Try-On](https://arxiv.org/abs/2511.18775)
*Kihyun Na,Jinyoung Choi,Injung Kim*

Main category: cs.CV

TL;DR: Re-CatVTON是一种高效的虚拟试穿单UNet模型，通过改进的上下文特征学习和条件策略，在保持高性能的同时显著降低了计算和内存开销。


<details>
  <summary>Details</summary>
Motivation: 虽然基于双UNet架构的扩散模型在虚拟试穿任务中表现出优异的保真度，但其复杂的结构带来了巨大的计算和内存开销。本研究旨在开发一种高效的单UNet模型，在保持高性能的同时降低资源消耗。

Method: 通过可视化分析和理论分析提出了三个关于上下文特征学习的假设，并基于这些假设开发了Re-CatVTON模型。采用了改进的无分类器引导策略，专门针对VTON的空间拼接条件进行优化，并直接注入从干净服装潜变量导出的真实服装潜变量以防止预测误差累积。

Result: Re-CatVTON相比前身CatVTON显著提升了性能，计算和内存需求低于高性能双UNet模型Leffa。在FID、KID和LPIPS指标上都有改进，SSIM仅有轻微下降，为单UNet VTON模型建立了新的效率-性能平衡点。

Conclusion: Re-CatVTON证明了通过精心设计的上下文特征学习策略，单UNet模型可以在虚拟试穿任务中实现与复杂双UNet模型相媲美的性能，同时显著降低计算资源需求，为实际应用提供了更可行的解决方案。

Abstract: Virtual Try-On (VTON) is the task of synthesizing an image of a person wearing a target garment, conditioned on a person image and a garment image. While diffusion-based VTON models featuring a Dual UNet architecture demonstrate superior fidelity compared to single UNet models, they incur substantial computational and memory overhead due to their heavy structure. In this study, through visualization analysis and theoretical analysis, we derived three hypotheses regarding the learning of context features to condition the denoising process. Based on these hypotheses, we developed Re-CatVTON, an efficient single UNet model that achieves high performance. We further enhance the model by introducing a modified classifier-free guidance strategy tailored for VTON's spatial concatenation conditioning, and by directly injecting the ground-truth garment latent derived from the clean garment latent to prevent the accumulation of prediction error. The proposed Re-CatVTON significantly improves performance compared to its predecessor (CatVTON) and requires less computation and memory than the high-performance Dual UNet model, Leffa. Our results demonstrate improved FID, KID, and LPIPS scores, with only a marginal decrease in SSIM, establishing a new efficiency-performance trade-off for single UNet VTON models.

</details>


### [203] [ConceptGuard: Proactive Safety in Text-and-Image-to-Video Generation through Multimodal Risk Detection](https://arxiv.org/abs/2511.18780)
*Ruize Ma,Minghong Cai,Yilei Jiang,Jiaming Han,Yi Feng,Yingshui Tan,Xiaoyong Zhu,Bo Zhang,Bo Zheng,Xiangyu Yue*

Main category: cs.CV

TL;DR: ConceptGuard是一个统一的安全框架，用于主动检测和缓解多模态视频生成中的不安全语义，通过对比检测和语义抑制两阶段方法，在新型基准测试中优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型虽然增强了可控性，但也引入了新的安全风险，因为有害内容可能来自单个模态或其交互。现有的安全方法多为纯文本、需要预知风险类别或作为后生成审计器，难以主动缓解这种组合式多模态风险。

Method: ConceptGuard采用两阶段方法：1）对比检测模块将融合的图像-文本输入投影到结构化概念空间来识别潜在安全风险；2）语义抑制机制通过干预提示的多模态条件来引导生成过程远离不安全概念。

Result: 在两个新型基准测试（ConceptRisk和T2VSafetyBench-TI2V）上的综合实验表明，ConceptGuard在风险检测和安全视频生成方面均优于现有基线，达到了最先进的结果。

Conclusion: ConceptGuard为多模态视频生成提供了一个有效的主动安全防护框架，能够有效应对组合式多模态风险，填补了现有安全方法的不足。

Abstract: Recent progress in video generative models has enabled the creation of high-quality videos from multimodal prompts that combine text and images. While these systems offer enhanced controllability, they also introduce new safety risks, as harmful content can emerge from individual modalities or their interaction. Existing safety methods are often text-only, require prior knowledge of the risk category, or operate as post-generation auditors, struggling to proactively mitigate such compositional, multimodal risks. To address this challenge, we present ConceptGuard, a unified safeguard framework for proactively detecting and mitigating unsafe semantics in multimodal video generation. ConceptGuard operates in two stages: First, a contrastive detection module identifies latent safety risks by projecting fused image-text inputs into a structured concept space; Second, a semantic suppression mechanism steers the generative process away from unsafe concepts by intervening in the prompt's multimodal conditioning. To support the development and rigorous evaluation of this framework, we introduce two novel benchmarks: ConceptRisk, a large-scale dataset for training on multimodal risks, and T2VSafetyBench-TI2V, the first benchmark adapted from T2VSafetyBench for the Text-and-Image-to-Video (TI2V) safety setting. Comprehensive experiments on both benchmarks show that ConceptGuard consistently outperforms existing baselines, achieving state-of-the-art results in both risk detection and safe video generation.

</details>


### [204] [A Novel Dual-Stream Framework for dMRI Tractography Streamline Classification with Joint dMRI and fMRI Data](https://arxiv.org/abs/2511.18781)
*Haotian Yan,Bocheng Guo,Jianzhong He,Nir A. Sochen,Ofer Pasternak,Lauren J O'Donnell,Fan Zhang*

Main category: cs.CV

TL;DR: 提出了一种新颖的双流束流分类框架，联合分析dMRI和fMRI数据，通过增强功能一致性来改进白质束流分割。


<details>
  <summary>Details</summary>
Motivation: 当前束流分类方法主要依赖束流轨迹的几何特征，无法区分具有相似路径但功能不同的纤维束。

Method: 设计了一个新颖的网络，使用预训练骨干模型处理完整束流轨迹，同时通过辅助网络处理纤维端点区域的fMRI信号。

Result: 通过将皮质脊髓束分割为四个躯体定位细分来验证方法，消融实验和与最先进方法的比较证明了该方法的优越性能。

Conclusion: 联合分析dMRI和fMRI数据的双流框架能够有效提升束流分类的功能一致性，优于现有方法。

Abstract: Streamline classification is essential to identify anatomically meaningful white matter tracts from diffusion MRI (dMRI) tractography. However, current streamline classification methods rely primarily on the geometric features of the streamline trajectory, failing to distinguish between functionally distinct fiber tracts with similar pathways. To address this, we introduce a novel dual-stream streamline classification framework that jointly analyzes dMRI and functional MRI (fMRI) data to enhance the functional coherence of tract parcellation. We design a novel network that performs streamline classification using a pretrained backbone model for full streamline trajectories, while augmenting with an auxiliary network that processes fMRI signals from fiber endpoint regions. We demonstrate our method by parcellating the corticospinal tract (CST) into its four somatotopic subdivisions. Experimental results from ablation studies and comparisons with state-of-the-art methods demonstrate our approach's superior performance.

</details>


### [205] [STCDiT: Spatio-Temporally Consistent Diffusion Transformer for High-Quality Video Super-Resolution](https://arxiv.org/abs/2511.18786)
*Junyang Chen,Jiangxin Dong,Long Sun,Yixin Yang,Jinshan Pan*

Main category: cs.CV

TL;DR: STCDiT是一个基于预训练视频扩散模型的视频超分辨率框架，通过运动感知VAE重建和锚帧引导方法，有效处理复杂相机运动下的视频重建，保持结构保真度和时间稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决视频超分辨率中在复杂相机运动下保持时间稳定性和结构保真度的挑战。

Method: 1. 运动感知VAE重建：按运动特征分段重建视频；2. 锚帧引导：利用第一帧（锚帧）的丰富结构信息约束生成过程。

Result: 实验表明STCDiT在结构保真度和时间一致性方面优于现有最先进方法。

Conclusion: 结合运动感知重建和锚帧引导的视频扩散模型能够实现高质量的视频超分辨率。

Abstract: We present STCDiT, a video super-resolution framework built upon a pre-trained video diffusion model, aiming to restore structurally faithful and temporally stable videos from degraded inputs, even under complex camera motions. The main challenges lie in maintaining temporal stability during reconstruction and preserving structural fidelity during generation. To address these challenges, we first develop a motion-aware VAE reconstruction method that performs segment-wise reconstruction, with each segment clip exhibiting uniform motion characteristic, thereby effectively handling videos with complex camera motions. Moreover, we observe that the first-frame latent extracted by the VAE encoder in each clip, termed the anchor-frame latent, remains unaffected by temporal compression and retains richer spatial structural information than subsequent frame latents. We further develop an anchor-frame guidance approach that leverages structural information from anchor frames to constrain the generation process and improve structural fidelity of video features. Coupling these two designs enables the video diffusion model to achieve high-quality video super-resolution. Extensive experiments show that STCDiT outperforms state-of-the-art methods in terms of structural fidelity and temporal consistency.

</details>


### [206] [Understanding Task Transfer in Vision-Language Models](https://arxiv.org/abs/2511.18787)
*Bhuvan Sachdeva,Karan Uppal,Abhinav Java,Vineeth N. Balasubramanian*

Main category: cs.CV

TL;DR: 该论文研究了视觉语言模型在感知任务上的迁移性，提出了Perfection Gap Factor（PGF）指标来衡量任务间的迁移效果，并构建了任务迁移图来揭示任务间的关系。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在多模态基准测试中表现良好，但在深度估计、物体计数等视觉感知任务上仍落后于人类和专用模型。微调一个任务可能会不可预测地影响其他任务的性能，这使得任务特定微调具有挑战性。

Method: 通过系统研究任务迁移性，评估在13个感知任务上微调一个任务对零样本性能的影响。引入PGF指标量化迁移的广度和幅度，使用三个开源权重VLM构建任务迁移图。

Result: 分析揭示了正负迁移模式，识别了相互影响的任务组，根据迁移行为将任务组织为人格类型，并展示了PGF如何指导数据选择以提高训练效率。

Conclusion: 研究结果突出了正迁移的机会和负干扰的风险，为推进VLM发展提供了可行的指导。

Abstract: Vision-Language Models (VLMs) perform well on multimodal benchmarks but lag behind humans and specialized models on visual perception tasks like depth estimation or object counting. Finetuning on one task can unpredictably affect performance on others, making task-specific finetuning challenging. In this paper, we address this challenge through a systematic study of task transferability. We examine how finetuning a VLM on one perception task affects its zero-shot performance on others. To quantify these effects, we introduce Perfection Gap Factor (PGF), a metric that captures both the breadth and magnitude of transfer. Using three open-weight VLMs evaluated across 13 perception tasks, we construct a task-transfer graph that reveals previously unobserved relationships among perception tasks. Our analysis uncovers patterns of positive and negative transfer, identifies groups of tasks that mutually influence each other, organizes tasks into personas based on their transfer behavior and demonstrates how PGF can guide data selection for more efficient training. These findings highlight both opportunities for positive transfer and risks of negative interference, offering actionable guidance for advancing VLMs.

</details>


### [207] [StereoDETR: Stereo-based Transformer for 3D Object Detection](https://arxiv.org/abs/2511.18788)
*Shiyi Mu,Zichong Gu,Zhiqi Ai,Anqi Liu,Yilin Gao,Shugong Xu*

Main category: cs.CV

TL;DR: StereoDETR是一种基于DETR的高效立体3D目标检测框架，通过双分支结构结合单目DETR和立体视差特征，实现了实时推理速度并超越单目方法，在KITTI基准测试中取得竞争性精度。


<details>
  <summary>Details</summary>
Motivation: 立体3D检测方法相比单目方法精度更高，但存在计算开销大和延迟高的问题。当前最先进的立体3D检测方法精度是单目方法的两倍，但推理速度只有单目方法的一半。

Method: StereoDETR包含两个分支：单目DETR分支和立体分支。DETR分支基于2D DETR构建，增加通道预测物体尺度、方向和采样点；立体分支利用低成本多尺度视差特征预测物体级深度图。两个分支通过可微分深度采样策略耦合，并引入约束监督策略处理遮挡问题。

Result: StereoDETR实现了实时推理，是首个在速度上超越单目方法的立体方法。在KITTI基准测试中取得竞争性精度，在行人和骑车人子集上创造了新的最先进结果。

Conclusion: StereoDETR成功解决了立体3D检测的计算效率问题，在保持高精度的同时实现了实时性能，为立体视觉在自动驾驶等实时应用中的部署提供了可行方案。

Abstract: Compared to monocular 3D object detection, stereo-based 3D methods offer significantly higher accuracy but still suffer from high computational overhead and latency. The state-of-the-art stereo 3D detection method achieves twice the accuracy of monocular approaches, yet its inference speed is only half as fast. In this paper, we propose StereoDETR, an efficient stereo 3D object detection framework based on DETR. StereoDETR consists of two branches: a monocular DETR branch and a stereo branch. The DETR branch is built upon 2D DETR with additional channels for predicting object scale, orientation, and sampling points. The stereo branch leverages low-cost multi-scale disparity features to predict object-level depth maps. These two branches are coupled solely through a differentiable depth sampling strategy. To handle occlusion, we introduce a constrained supervision strategy for sampling points without requiring extra annotations. StereoDETR achieves real-time inference and is the first stereo-based method to surpass monocular approaches in speed. It also achieves competitive accuracy on the public KITTI benchmark, setting new state-of-the-art results on pedestrian and cyclist subsets. The code is available at https://github.com/shiyi-mu/StereoDETR-OPEN.

</details>


### [208] [Scale What Counts, Mask What Matters: Evaluating Foundation Models for Zero-Shot Cross-Domain Wi-Fi Sensing](https://arxiv.org/abs/2511.18792)
*Cheng Jiang,Yihe Yan,Yanxiang Wang,Chun Tung Chou,Wen Hu*

Main category: cs.CV

TL;DR: 该论文通过大规模预训练方法解决Wi-Fi感知的领域泛化问题，发现数据规模和多样性是提升跨域性能的关键，而模型容量在当前数据量下增益有限。


<details>
  <summary>Details</summary>
Motivation: Wi-Fi感知作为隐私保护的替代方案，面临严重的领域迁移问题，即在一个环境中训练的模型无法泛化到新环境、硬件或用户。现有数据集规模小且分散，限制了模型的实用性。

Method: 采用基础模型方法，使用掩码自编码器（MAE）风格预训练，在迄今最大、最异构的Wi-Fi CSI数据集集合上进行预训练和评估。数据集包含14个数据集、超过130万个样本，涵盖4种设备、2.4/5/6 GHz频段和20-160 MHz带宽。

Result: 实验表明：1）预训练数据量增加带来未见领域性能的对数线性提升；2）在当前数据量下，更大模型仅带来边际增益；3）在人类活动识别、手势识别和用户识别任务上，大规模预训练相比监督学习基线提升跨域准确率2.2%至15.7%。

Conclusion: 数据而非模型容量是当前Wi-Fi感知泛化的瓶颈，大规模预训练是提升跨域鲁棒性的有效途径，为设计实用Wi-Fi感知系统提供了重要方向。

Abstract: While Wi-Fi sensing offers a compelling, privacy-preserving alternative to cameras, its practical utility has been fundamentally undermined by a lack of robustness across domains. Models trained in one setup fail to generalize to new environments, hardware, or users, a critical "domain shift" problem exacerbated by modest, fragmented public datasets. We shift from this limited paradigm and apply a foundation model approach, leveraging Masked Autoencoding (MAE) style pretraining on the largest and most heterogeneous Wi-Fi CSI datasets collection assembled to date. Our study pretrains and evaluates models on over 1.3 million samples extracted from 14 datasets, collected using 4 distinct devices across the 2.4/5/6 GHz bands and bandwidths from 20 to 160 MHz. Our large-scale evaluation is the first to systematically disentangle the impacts of data diversity versus model capacity on cross-domain performance. The results establish scaling trends on Wi-Fi CSI sensing. First, our experiments show log-linear improvements in unseen domain performance as the amount of pretraining data increases, suggesting that data scale and diversity are key to domain generalization. Second, based on the current data volume, larger model can only provide marginal gains for cross-domain performance, indicating that data, rather than model capacity, is the current bottleneck for Wi-Fi sensing generalization. Finally, we conduct a series of cross-domain evaluations on human activity recognition, human gesture recognition and user identification tasks. The results show that the large-scale pretraining improves cross-domain accuracy ranging from 2.2% to 15.7%, compared to the supervised learning baseline. Overall, our findings provide insightful direction for designing future Wi-Fi sensing systems that can eventually be robust enough for real-world deployment.

</details>


### [209] [PartDiffuser: Part-wise 3D Mesh Generation via Discrete Diffusion](https://arxiv.org/abs/2511.18801)
*Yichen Yang,Hong Li,Haodong Zhu,Linin Yang,Guojun Lei,Sheng Xu,Baochang Zhang*

Main category: cs.CV

TL;DR: PartDiffuser是一种新颖的半自回归扩散框架，用于点云到网格的生成。该方法通过语义分割将网格划分为多个部分，在部分之间采用自回归方式确保全局拓扑一致性，同时在每个语义部分内部使用并行离散扩散过程来精确重建高频几何特征。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归方法在生成艺术家设计的网格时，难以平衡全局结构一致性和高保真局部细节，且容易受到误差累积的影响。为了解决这些问题，需要一种能够有效解耦全局和局部生成任务的方法。

Method: 基于DiT架构，引入部分感知的交叉注意力机制，使用点云作为分层几何条件来动态控制生成过程。首先对网格进行语义分割，然后在部分之间采用自回归方式确保全局拓扑，在每个语义部分内部使用并行离散扩散过程来重建细节。

Result: 实验表明，该方法在生成具有丰富细节的3D网格方面显著优于最先进的模型，表现出适合实际应用的卓越细节表示能力。

Conclusion: PartDiffuser通过半自回归扩散框架有效解决了网格生成中全局结构和局部细节的平衡问题，为3D网格生成提供了新的解决方案。

Abstract: Existing autoregressive (AR) methods for generating artist-designed meshes struggle to balance global structural consistency with high-fidelity local details, and are susceptible to error accumulation. To address this, we propose PartDiffuser, a novel semi-autoregressive diffusion framework for point-cloud-to-mesh generation. The method first performs semantic segmentation on the mesh and then operates in a "part-wise" manner: it employs autoregression between parts to ensure global topology, while utilizing a parallel discrete diffusion process within each semantic part to precisely reconstruct high-frequency geometric features. PartDiffuser is based on the DiT architecture and introduces a part-aware cross-attention mechanism, using point clouds as hierarchical geometric conditioning to dynamically control the generation process, thereby effectively decoupling the global and local generation tasks. Experiments demonstrate that this method significantly outperforms state-of-the-art (SOTA) models in generating 3D meshes with rich detail, exhibiting exceptional detail representation suitable for real-world applications.

</details>


### [210] [TPG-INR: Target Prior-Guided Implicit 3D CT Reconstruction for Enhanced Sparse-view Imaging](https://arxiv.org/abs/2511.18806)
*Qinglei Cao,Ziyao Tang,Xiaoqin Tang*

Main category: cs.CV

TL;DR: 提出了一种基于目标先验的3D CT重建框架，通过整合位置和结构编码来增强隐式学习，在超稀疏视图场景下显著提高了学习效率和重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于NeRF的CT重建方法往往忽略了物体的解剖先验对隐式学习的重要性，限制了重建精度和学习效率，特别是在超稀疏视图场景下。

Method: 使用从物体投影数据中提取的'目标先验'来增强隐式学习，结合位置和结构编码实现体素级隐式重建，并开发了基于CUDA的算法从稀疏视图投影中快速估计高质量3D目标先验。

Result: 在复杂腹部数据集上的实验表明，该方法学习效率比当前领先模型NAF提高10倍，重建质量超过最准确模型NeRP，在10、20、30个投影下PSNR分别提升3.57dB、5.42dB和5.70dB。

Conclusion: 所提出的目标先验引导的隐式神经表示框架在超稀疏视图CT重建中实现了显著的学习效率和重建质量提升，验证了利用解剖先验指导隐式学习的有效性。

Abstract: X-ray imaging, based on penetration, enables detailed visualization of internal structures. Building on this capability, existing implicit 3D reconstruction methods have adapted the NeRF model and its variants for internal CT reconstruction. However, these approaches often neglect the significance of objects' anatomical priors for implicit learning, limiting both reconstruction precision and learning efficiency, particularly in ultra-sparse view scenarios. To address these challenges, we propose a novel 3D CT reconstruction framework that employs a 'target prior' derived from the object's projection data to enhance implicit learning. Our approach integrates positional and structural encoding to facilitate voxel-wise implicit reconstruction, utilizing the target prior to guide voxel sampling and enrich structural encoding. This dual strategy significantly boosts both learning efficiency and reconstruction quality. Additionally, we introduce a CUDA-based algorithm for rapid estimation of high-quality 3D target priors from sparse-view projections. Experiments utilizing projection data from a complex abdominal dataset demonstrate that the proposed model substantially enhances learning efficiency, outperforming the current leading model, NAF, by a factor of ten. In terms of reconstruction quality, it also exceeds the most accurate model, NeRP, achieving PSNR improvements of 3.57 dB, 5.42 dB, and 5.70 dB with 10, 20, and 30 projections, respectively. The code is available at https://github.com/qlcao171/TPG-INR.

</details>


### [211] [Mitigating Long-Tail Bias in HOI Detection via Adaptive Diversity Cache](https://arxiv.org/abs/2511.18811)
*Yuqiu Jiang,Xiaozhen Qiao,Tianyu Mei,Haojian Huang,Yifan Chen,Ye Zheng,Zhe Sun*

Main category: cs.CV

TL;DR: 提出了自适应多样性缓存（ADC）模块，一种无需训练、即插即用的机制，用于缓解HOI检测中的长尾偏差问题


<details>
  <summary>Details</summary>
Motivation: 现有的基于VLM的HOI检测方法依赖额外训练或提示调优，导致计算开销大且可扩展性有限，特别是在长尾场景中罕见交互严重不足

Method: ADC构建类特定缓存，在推理过程中积累高置信度和多样化的特征表示，包含频率感知的缓存适应机制，优先考虑罕见类别

Result: 在HICO-DET和V-COCO数据集上的实验表明，ADC能持续改进现有HOI检测器，在罕见类别上获得+8.57% mAP提升，在完整数据集上获得+4.39%提升

Conclusion: ADC能有效缓解长尾偏差，同时保持整体性能，证明了其在不需额外训练或微调情况下的有效性

Abstract: Human-Object Interaction (HOI) detection is a fundamental task in computer vision, empowering machines to comprehend human-object relationships in diverse real-world scenarios. Recent advances in VLMs have significantly improved HOI detection by leveraging rich cross-modal representations. However, most existing VLM-based approaches rely heavily on additional training or prompt tuning, resulting in substantial computational overhead and limited scalability, particularly in long-tailed scenarios where rare interactions are severely underrepresented. In this paper, we propose the Adaptive Diversity Cache (ADC) module, a novel training-free and plug-and-play mechanism designed to mitigate long-tail bias in HOI detection. ADC constructs class-specific caches that accumulate high-confidence and diverse feature representations during inference. The method incorporates frequency-aware cache adaptation that favors rare categories and is designed to enable robust prediction calibration without requiring additional training or fine-tuning. Extensive experiments on HICO-DET and V-COCO datasets show that ADC consistently improves existing HOI detectors, achieving up to +8.57\% mAP gain on rare categories and +4.39\% on the full dataset, demonstrating its effectiveness in mitigating long-tail bias while preserving overall performance.

</details>


### [212] [DetAny4D: Detect Anything 4D Temporally in a Streaming RGB Video](https://arxiv.org/abs/2511.18814)
*Jiawei Hou,Shenghao Zhang,Can Wang,Zheng Gu,Yonggen Ling,Taiping Zeng,Xiangyang Xue,Jingbo Zhang*

Main category: cs.CV

TL;DR: 提出了DetAny4D，一个端到端的开放集4D物体检测框架，通过融合多模态特征和几何感知时空解码器，显著提升了检测精度和时间稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决现有4D物体检测方法缺乏时间一致性建模、依赖复杂多阶段流程导致错误传播，以及缺乏大规模连续标注数据集的问题。

Method: 首先构建DA4D大规模数据集，然后提出DetAny4D框架：融合预训练基础模型的多模态特征，设计几何感知时空解码器捕获时空动态，采用多任务学习和专门训练策略保持序列一致性。

Result: 实验表明DetAny4D在检测精度上具有竞争力，并显著改善了时间稳定性，有效解决了4D检测中长期存在的抖动和不一致问题。

Conclusion: DetAny4D为可靠的4D物体检测提供了一个有效的端到端解决方案，通过数据集和框架的结合解决了该领域的关键挑战。

Abstract: Reliable 4D object detection, which refers to 3D object detection in streaming video, is crucial for perceiving and understanding the real world. Existing open-set 4D object detection methods typically make predictions on a frame-by-frame basis without modeling temporal consistency, or rely on complex multi-stage pipelines that are prone to error propagation across cascaded stages. Progress in this area has been hindered by the lack of large-scale datasets that capture continuous reliable 3D bounding box (b-box) annotations. To overcome these challenges, we first introduce DA4D, a large-scale 4D detection dataset containing over 280k sequences with high-quality b-box annotations collected under diverse conditions. Building on DA4D, we propose DetAny4D, an open-set end-to-end framework that predicts 3D b-boxes directly from sequential inputs. DetAny4D fuses multi-modal features from pre-trained foundational models and designs a geometry-aware spatiotemporal decoder to effectively capture both spatial and temporal dynamics. Furthermore, it adopts a multi-task learning architecture coupled with a dedicated training strategy to maintain global consistency across sequences of varying lengths. Extensive experiments show that DetAny4D achieves competitive detection accuracy and significantly improves temporal stability, effectively addressing long-standing issues of jitter and inconsistency in 4D object detection. Data and code will be released upon acceptance.

</details>


### [213] [SupLID: Geometrical Guidance for Out-of-Distribution Detection in Semantic Segmentation](https://arxiv.org/abs/2511.18816)
*Nimeshika Udayangani,Sarah Erfani,Christopher Leckie*

Main category: cs.CV

TL;DR: SupLID是一种新颖的语义分割OOD检测框架，通过利用语义空间的几何结构和线性内在维度(LID)来增强分类器置信度，在像素级异常检测中实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于分类器置信度的像素级OOD检测方法存在过度自信等局限性，需要引入几何结构信息作为补充信号来提高检测能力。

Method: SupLID构建几何核心集捕捉ID子空间的内在结构，在超像素级别计算OOD分数，结合LID分析高维数据的局部距离分布特征。

Result: SupLID显著提升了现有分类器OOD分数，在AUR、FPR和AUP等关键指标上达到最先进性能，支持实时推理并改善空间平滑性。

Conclusion: SupLID作为一种后处理评分方法，可与任何语义分割分类器无缝集成，几何线索与传统分类器置信度互补，有效增强对多样化OOD场景的检测能力。

Abstract: Out-of-Distribution (OOD) detection in semantic segmentation aims to localize anomalous regions at the pixel level, advancing beyond traditional image-level OOD techniques to better suit real-world applications such as autonomous driving. Recent literature has successfully explored the adaptation of commonly used image-level OOD methods--primarily based on classifier-derived confidence scores (e.g., energy or entropy)--for this pixel-precise task. However, these methods inherit a set of limitations, including vulnerability to overconfidence. In this work, we introduce SupLID, a novel framework that effectively guides classifier-derived OOD scores by exploiting the geometrical structure of the underlying semantic space, particularly using Linear Intrinsic Dimensionality (LID). While LID effectively characterizes the local structure of high-dimensional data by analyzing distance distributions, its direct application at the pixel level remains challenging. To overcome this, SupLID constructs a geometrical coreset that captures the intrinsic structure of the in-distribution (ID) subspace. It then computes OOD scores at the superpixel level, enabling both efficient real-time inference and improved spatial smoothness. We demonstrate that geometrical cues derived from SupLID serve as a complementary signal to traditional classifier confidence, enhancing the model's ability to detect diverse OOD scenarios. Designed as a post-hoc scoring method, SupLID can be seamlessly integrated with any semantic segmentation classifier at deployment time. Our results demonstrate that SupLID significantly enhances existing classifier-based OOD scores, achieving state-of-the-art performance across key evaluation metrics, including AUR, FPR, and AUP. Code is available at https://github.com/hdnugit/SupLID.

</details>


### [214] [Disc3D: Automatic Curation of High-Quality 3D Dialog Data via Discriminative Object Referring](https://arxiv.org/abs/2511.18817)
*Siyuan Wei,Chunjie Wang,Xiao Liu,Xiaosheng Yan,Zhishan Zhou,Rui Huang*

Main category: cs.CV

TL;DR: 提出全自动流水线生成高质量3D场景对话数据集Disc3D，解决3D MLLMs训练数据稀缺问题，通过消除视角和对象指代模糊性，显著提升模型性能


<details>
  <summary>Details</summary>
Motivation: 3D多模态大语言模型性能落后于2D模型，主要原因是缺乏大规模高质量的3D场景对话数据集，且现有方法依赖昂贵的人工标注且存在视角模糊和对象指代模糊问题

Method: 开发四阶段全自动流水线：1)元标注收集；2)场景图构建与关系修正；3)区分性对象指代生成；4)多任务数据生成。结合规则约束、2D MLLMs和LLMs实现可控可扩展的数据生成

Result: 生成Disc3D数据集，包含25K混合3D场景中的200多万样本，涵盖场景/视图/对象描述、视觉定位和五种对象中心QA任务。实验表明Disc3D训练能显著提升模型在公开基准和Disc3D-QA任务上的性能

Conclusion: 提出的全自动流水线成功解决了3D场景对话数据稀缺问题，生成的Disc3D数据集有效提升了3D MLLMs性能，为3D多模态理解提供了高质量训练资源

Abstract: 3D Multi-modal Large Language Models (MLLMs) still lag behind their 2D peers, largely because large-scale, high-quality 3D scene-dialogue datasets remain scarce. Prior efforts hinge on expensive human annotation and leave two key ambiguities unresolved: viewpoint ambiguity, where spatial language presumes unknown camera poses, and object referring ambiguity, where non-exclusive descriptions blur the line between targets and distractors. We therefore present a fully automated pipeline that converts raw 3D scans into unambiguous, high-quality dialogue data at a fraction of the previous cost. By synergizing rule-based constraints with 2D MLLMs and LLMs, the pipeline enables controllable, scalable generation without human intervention. The pipeline comprises four stages: (1) meta-annotation collection harvesting object-, frame-, and scene-level captions, (2) scene graph construction with relation correction to capture proximal object relations, (3) discriminative object referring that generates exclusive and compact descriptions, and (4) multi-task data generation synthesizing diverse dialogues. Our pipeline systematically mitigates inherent flaws in source datasets and produces the final Disc3D dataset, over 2 million samples in 25K hybrid 3D scenes, spanning scene, view, and object captioning, visual grounding, and five object-centric QA tasks. Extensive experiments demonstrate that training with Disc3D yields consistent, significant improvements on both public benchmarks and our multifaceted Disc3D-QA tasks. Code, data, and models will be publicly available.

</details>


### [215] [DiP: Taming Diffusion Models in Pixel Space](https://arxiv.org/abs/2511.18822)
*Zhennan Chen,Junwei Zhu,Xu Chen,Jiangning Zhang,Xiaobin Hu,Hanzhen Zhao,Chengjie Wang,Jian Yang,Ying Tai*

Main category: cs.CV

TL;DR: DiP是一个高效的像素空间扩散框架，通过解耦全局和局部生成阶段，在不依赖VAE的情况下实现与LDMs相当的效率，推理速度提升10倍，FID达到1.90。


<details>
  <summary>Details</summary>
Motivation: 解决扩散模型在生成质量和计算效率之间的权衡问题，LDMs存在信息丢失和非端到端训练问题，而现有像素空间模型计算成本过高。

Method: 采用两阶段设计：DiT主干处理大块图像进行全局结构构建，轻量级Patch Detailer Head利用上下文特征恢复局部细节，实现协同训练。

Result: 推理速度比之前方法快10倍，参数仅增加0.3%，在ImageNet 256×256上FID达到1.90。

Conclusion: DiP框架成功解决了扩散模型的效率与质量权衡问题，为高分辨率合成提供了高效的像素空间解决方案。

Abstract: Diffusion models face a fundamental trade-off between generation quality and computational efficiency. Latent Diffusion Models (LDMs) offer an efficient solution but suffer from potential information loss and non-end-to-end training. In contrast, existing pixel space models bypass VAEs but are computationally prohibitive for high-resolution synthesis. To resolve this dilemma, we propose DiP, an efficient pixel space diffusion framework. DiP decouples generation into a global and a local stage: a Diffusion Transformer (DiT) backbone operates on large patches for efficient global structure construction, while a co-trained lightweight Patch Detailer Head leverages contextual features to restore fine-grained local details. This synergistic design achieves computational efficiency comparable to LDMs without relying on a VAE. DiP is accomplished with up to 10$\times$ faster inference speeds than previous method while increasing the total number of parameters by only 0.3%, and achieves an 1.90 FID score on ImageNet 256$\times$256.

</details>


### [216] [VideoPerceiver: Enhancing Fine-Grained Temporal Perception in Video Multimodal Large Language Models](https://arxiv.org/abs/2511.18823)
*Fufangchen Zhao,Liao Zhang,Daiqi Shi,Yuanjun Gao,Chen Ye,Yang Cai,Jian Gao,Danfeng Yan*

Main category: cs.CV

TL;DR: VideoPerceiver是一个新颖的视频多模态大语言模型，通过两阶段训练框架增强视频理解中的细粒度感知能力，在细粒度动作理解和罕见事件描述任务上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有视频多模态大语言模型在短片段中推理短暂动作或长视频中罕见瞬时事件能力有限的问题。

Method: 采用两阶段训练：监督微调阶段构建"关键信息缺失"视频并联合编码原始和修改视频token，通过辅助对比损失增强对细粒度运动线索的敏感性；强化学习阶段使用相对奖励机制确保完整视频的响应优于降级输入。

Result: 实验表明VideoPerceiver在细粒度动作理解和罕见事件描述基准测试中显著优于最先进的VMLLMs，同时在标准任务上保持强大性能。

Conclusion: 通过优先处理任务相关的视觉特征，该工作重新定义了视频语言模型的细粒度感知训练方法。

Abstract: We propose VideoPerceiver, a novel video multimodal large language model (VMLLM) that enhances fine-grained perception in video understanding, addressing VMLLMs' limited ability to reason about brief actions in short clips or rare transient events in long videos. VideoPerceiver adopts a two-stage training framework. During supervised fine-tuning (SFT), we construct "key-information-missing" videos by extracting event-action keywords from captions, identifying corresponding key frames, and replacing them with adjacent frames. We jointly encode original and modified video tokens with text tokens, aligning intermediate visual representations with keywords via an auxiliary contrastive loss to enhance sensitivity to fine-grained motion cues. In reinforcement learning (RL), both video variants are fed into the model to generate descriptions, and a novel relative reward ensures responses from complete videos outperform those from degraded inputs, explicitly training the model to recover temporally precise action details. We also curate a dataset of 80,000 videos with fine-grained actions and transient events. Experiments show VideoPerceiver substantially outperforms state-of-the-art VMLLMs on fine-grained action understanding and rare event captioning benchmarks, while maintaining strong performance on standard tasks. By prioritizing task-relevant visual features, our work redefines video-language model training for fine-grained perception.

</details>


### [217] [Assessing the alignment between infants' visual and linguistic experience using multimodal language models](https://arxiv.org/abs/2511.18824)
*Alvin Wei Ming Tan,Jane Yang,Tarun Sepuri,Khai Loong Aw,Robert Z. Sparks,Zi Yin,Virginia A. Marchman,Michael C. Frank,Bria Long*

Main category: cs.CV

TL;DR: 本文使用CLIP模型自动分析婴儿视角视频中的视觉-语言对齐情况，发现理想化的对齐学习时刻在儿童日常经验中相对罕见，这为早期词汇学习模型提出了挑战。


<details>
  <summary>Details</summary>
Motivation: 研究儿童语言学习过程中视觉和语言体验的时间对齐程度，传统方法依赖人工标注且效率低下，需要自动化工具来分析大规模婴儿视角视频数据。

Method: 使用对比性语言-图像预训练（CLIP）模型来自动表征婴儿视角家庭环境视频中的视觉-语言对齐情况，并通过人工对齐判断验证CLIP对齐分数的有效性。

Result: 理想化的对齐学习时刻（如"看球"时球出现在儿童视野中）在儿童日常经验中相对罕见，且不同儿童之间和同一儿童内部存在变异性。

Conclusion: 视觉-语言对齐的稀缺性是早期词汇学习模型的一个约束条件，该方法为研究儿童多模态环境提供了新工具。

Abstract: Figuring out which objects or concepts words refer to is a central language learning challenge for young children. Most models of this process posit that children learn early object labels from co-occurrences of words and their referents that occur when someone around them talks about an object in the immediate physical environment. But how aligned in time are children's visual and linguistic experiences during everyday learning? To date, answers to this question have been limited by the need for labor-intensive manual annotations of vision-language co-occurrences. Here, we evaluate the use of contrastive language-image pretraining (CLIP) models to automatically characterize vision-language alignment in egocentric videos taken from the infant perspective in home environments. After validating CLIP alignment scores using human alignment judgments, we apply this metric to a large corpus of infant-perspective videos. We show that idealized aligned moments for learning (e.g., "look at the ball" with a ball present in the child's view) are relatively rare in children's everyday experiences compared to modern machine learning datasets, and highlight variability in alignment both within and across children. These findings suggest that infrequent alignment is a constraint for models describing early word learning and offer a new method for investigating children's multimodal environment.

</details>


### [218] [Q-Save: Towards Scoring and Attribution for Generated Video Evaluation](https://arxiv.org/abs/2511.18825)
*Xiele Wu,Zicheng Zhang,Mingtao Chen,Yixian Liu,Yiming Liu,Shushi Wang,Zhichao Hu,Yuhong Liu,Guangtao Zhai,Xiaohong Liu*

Main category: cs.CV

TL;DR: Q-Save是一个用于AI生成视频质量评估的基准数据集和模型，包含近10000个视频，提供MOS评分和细粒度归因标签，支持可解释的质量评估。


<details>
  <summary>Details</summary>
Motivation: 当前AI生成视频质量评估缺乏全面性和可解释性，需要既能准确评分又能提供解释依据的评估方法。

Method: 采用SlowFast框架区分快慢帧处理，使用COT风格数据格式，通过SFT、GRPO、SFT三阶段训练策略。

Result: 模型在视频质量预测方面达到最先进性能，同时提供人类对齐的可解释性。

Conclusion: Q-Save为生成视频研究中的可解释评估建立了坚实基础，有助于多模态生成和可信AI的发展。

Abstract: We present Q-Save, a new benchmark dataset and model for holistic and explainable evaluation of AI-generated video (AIGV) quality. The dataset contains near 10000 videos, each annotated with a scalar mean opinion score (MOS) and fine-grained attribution labels along three core dimensions: visual quality, dynamic quality, and text-video alignment. These multi-aspect annotations enable both accurate quality assessment and interpretable reasoning behind the scores. To leverage this data, we propose a unified evaluation model that jointly performs quality scoring and attribution-based explanation. The model adopts the SlowFast framework to distinguish between fast frames and slow frames - slow frames are processed with high resolution while fast frames use low resolution, balancing evaluation accuracy and computational efficiency. For training, we use data formatted in Chain-of-Thought (COT) style and employ a multi-stage strategy: we first conduct Supervised Fine-Tuning (SFT), then further enhance the model with Grouped Relative Policy Optimization (GRPO), and finally perform SFT again to improve model stability. Experimental results demonstrate that our model achieves state-of-the-art performance in video quality prediction while also providing human-aligned, interpretable justifications. Our dataset and model establish a strong foundation for explainable evaluation in generative video research, contributing to the development of multimodal generation and trustworthy AI. Code and dataset will be released upon publication.

</details>


### [219] [Uncertainty-Aware Dual-Student Knowledge Distillation for Efficient Image Classification](https://arxiv.org/abs/2511.18826)
*Aakash Gore,Anoushka Dey,Aryan Mishra*

Main category: cs.CV

TL;DR: 本文提出了一种不确定性感知的双学生知识蒸馏框架，通过利用教师预测不确定性来选择性指导学生学习，使用两种异构学生架构进行协作学习，在ImageNet-100上取得了优于传统方法的性能。


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏方法对所有教师预测一视同仁，忽略了教师预测的不确定性信息。本文旨在利用教师预测的不确定性来更有效地指导学生学习。

Method: 提出不确定性感知的双学生知识蒸馏框架，使用ResNet-18和MobileNetV2两种异构学生架构进行协作学习，通过peer-learning机制让学生既从教师网络学习，又相互学习。

Result: 在ImageNet-100数据集上，ResNet-18达到83.84% top-1准确率，MobileNetV2达到81.46% top-1准确率，分别比传统单学生蒸馏方法提升了2.04%和0.92%。

Conclusion: 不确定性感知的双学生知识蒸馏框架能够有效利用教师预测的不确定性信息，通过异构学生架构的协作学习显著提升模型压缩效果。

Abstract: Knowledge distillation has emerged as a powerful technique for model compression, enabling the transfer of knowledge from large teacher networks to compact student models. However, traditional knowledge distillation methods treat all teacher predictions equally, regardless of the teacher's confidence in those predictions. This paper proposes an uncertainty-aware dual-student knowledge distillation framework that leverages teacher prediction uncertainty to selectively guide student learning. We introduce a peer-learning mechanism where two heterogeneous student architectures, specifically ResNet-18 and MobileNetV2, learn collaboratively from both the teacher network and each other. Experimental results on ImageNet-100 demonstrate that our approach achieves superior performance compared to baseline knowledge distillation methods, with ResNet-18 achieving 83.84\% top-1 accuracy and MobileNetV2 achieving 81.46\% top-1 accuracy, representing improvements of 2.04\% and 0.92\% respectively over traditional single-student distillation approaches.

</details>


### [220] [Leveraging Metaheuristic Approaches to Improve Deep Learning Systems for Anxiety Disorder Detection](https://arxiv.org/abs/2511.18827)
*Mohammadreza Amiri,Monireh Hosseini*

Main category: cs.CV

TL;DR: 提出了一种结合深度学习与群体智能优化的混合模型，用于通过多模态可穿戴传感器数据自动检测焦虑症，相比单一深度学习模型在准确性和泛化能力上均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统焦虑症诊断依赖主观评估方法（如临床访谈和问卷），存在耗时、评估者依赖性等问题。人工智能技术为实现更一致、自动化的焦虑检测提供了新机遇。

Method: 集成深度学习架构与群体智能优化策略（遗传算法和粒子群优化），利用多模态可穿戴传感器数据集分析生理、情绪和行为信号。群体智能技术用于特征空间优化和超参数调优，深度学习组件负责从序列化多源输入中提取分层判别性特征。

Result: 评估显示两种计算范式的融合显著提升了检测性能，混合模型在准确率方面取得显著改进，并在不同个体间表现出更强的泛化能力。

Conclusion: 研究结果证明了将元启发式优化与深度学习相结合，有望开发出可扩展、客观且具有临床意义的焦虑症评估解决方案。

Abstract: Despite being among the most common psychological disorders, anxiety-related conditions are still primarily identified through subjective assessments, such as clinical interviews and self-evaluation questionnaires. These conventional methods often require significant time and may vary depending on the evaluator. However, the emergence of advanced artificial intelligence techniques has created new opportunities for detecting anxiety in a more consistent and automated manner. To address the limitations of traditional approaches, this study introduces a comprehensive model that integrates deep learning architectures with optimization strategies inspired by swarm intelligence. Using multimodal and wearable-sensor datasets, the framework analyzes physiological, emotional, and behavioral signals. Swarm intelligence techniques including genetic algorithms and particle swarm optimization are incorporated to refine the feature space and optimize hyperparameters. Meanwhile, deep learning components are tasked with deriving layered and discriminative representations from sequential, multi-source inputs. Our evaluation shows that the fusion of these two computational paradigms significantly enhances detection performance compared with using deep networks alone. The hybrid model achieves notable improvements in accuracy and demonstrates stronger generalization across various individuals. Overall, the results highlight the potential of combining metaheuristic optimization with deep learning to develop scalable, objective, and clinically meaningful solutions for assessing anxiety disorders

</details>


### [221] [VideoCompressa: Data-Efficient Video Understanding via Joint Temporal Compression and Spatial Reconstruction](https://arxiv.org/abs/2511.18831)
*Shaobo Wang,Tianle Niu,Runkang Yang,Deshan Liu,Xu He,Zichen Wen,Conghui He,Xuming Hu,Linfeng Zhang*

Main category: cs.CV

TL;DR: VideoCompressa通过动态潜在压缩框架解决视频数据集存储和计算成本高的问题，通过优化关键帧选择和压缩来极大提高数据效率。


<details>
  <summary>Details</summary>
Motivation: 视频理解模型的可扩展性受到大规模视频数据集高昂存储和计算成本的限制。现有数据合成方法在图像领域有效，但扩展到视频领域面临挑战，主要因为时间冗余和复杂的时空动态。研究发现视频数据集效率低下的主要来源是样本内帧级冗余而非样本间冗余。

Method: VideoCompressa框架包含：1）可微分关键帧选择器（轻量级ConvNet+Gumbel-Softmax采样）识别最具信息量的帧；2）预训练冻结的变分自编码器将关键帧压缩为紧凑的潜在代码；3）压缩网络实现端到端反向传播。关键帧选择器和合成潜在代码共同优化以最大化任务相关信息保留。

Result: 在UCF101数据集上，仅使用0.13%的原始数据就超越全数据训练2.34个百分点，相比传统合成方法速度提升5800倍以上。在HMDB51上微调Qwen2.5-7B-VL模型时，仅使用0.41%的训练数据就达到全数据性能，比零样本基线提升10.61%。

Conclusion: VideoCompressa通过识别和利用视频数据中的帧级冗余，实现了前所未有的数据效率，为大规模视频理解任务提供了高效的解决方案。

Abstract: The scalability of video understanding models is increasingly limited by the prohibitive storage and computational costs of large-scale video datasets. While data synthesis has improved data efficiency in the image domain, its extension to video remains challenging due to pervasive temporal redundancy and complex spatiotemporal dynamics. In this work, we uncover a critical insight: the primary source of inefficiency in video datasets is not inter-sample redundancy, but intra-sample frame-level redundancy. To leverage this insight, we introduce VideoCompressa, a novel framework for video data synthesis that reframes the problem as dynamic latent compression. Specifically, VideoCompressa jointly optimizes a differentiable keyframe selector-implemented as a lightweight ConvNet with Gumbel-Softmax sampling-to identify the most informative frames, and a pretrained, frozen Variational Autoencoder (VAE) to compress these frames into compact, semantically rich latent codes. These latent representations are then fed into a compression network, enabling end-to-end backpropagation. Crucially, the keyframe selector and synthetic latent codes are co-optimized to maximize retention of task-relevant information. Experiments show that our method achieves unprecedented data efficiency: on UCF101 with ConvNets, VideoCompressa surpasses full-data training by 2.34\% points using only 0.13\% of the original data, with over 5800x speedup compared to traditional synthesis method. Moreover, when fine-tuning Qwen2.5-7B-VL on HMDB51, VideoCompressa matches full-data performance using just 0.41\% of the training data-outperforming zero-shot baseline by 10.61\%.

</details>


### [222] [FlowSteer: Guiding Few-Step Image Synthesis with Authentic Trajectories](https://arxiv.org/abs/2511.18834)
*Lei Ke,Hubery Yin,Gongye Liu,Zhengyao Lv,Jingcai Guo,Chen Li,Wenhan Luo,Yujiu Yang,Jing Lyu*

Main category: cs.CV

TL;DR: FlowSteer是一种改进ReFlow蒸馏的方法，通过在线轨迹对齐和对抗性蒸馏提升学生模型对教师生成轨迹的跟随能力，解决了ReFlow在实践中的性能瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: ReFlow虽然在理论上与流匹配一致，但在实际应用中性能不如一致性蒸馏和分数蒸馏，作者希望挖掘ReFlow的潜力并解决其性能瓶颈。

Method: 提出了FlowSteer方法：1）在线轨迹对齐(OTA)解决分段ReFlow中的分布不匹配问题；2）在ODE轨迹上应用对抗性蒸馏目标；3）修复了FlowMatchEulerDiscreteScheduler中的缺陷。

Result: 在SD3上的实验结果表明该方法有效提升了ReFlow蒸馏的性能。

Conclusion: FlowSteer成功解锁了基于ReFlow的蒸馏潜力，通过轨迹引导和算法改进显著提升了采样效率。

Abstract: With the success of flow matching in visual generation, sampling efficiency remains a critical bottleneck for its practical application. Among flow models' accelerating methods, ReFlow has been somehow overlooked although it has theoretical consistency with flow matching. This is primarily due to its suboptimal performance in practical scenarios compared to consistency distillation and score distillation. In this work, we investigate this issue within the ReFlow framework and propose FlowSteer, a method unlocks the potential of ReFlow-based distillation by guiding the student along teacher's authentic generation trajectories. We first identify that Piecewised ReFlow's performance is hampered by a critical distribution mismatch during the training and propose Online Trajectory Alignment(OTA) to resolve it. Then, we introduce a adversarial distillation objective applied directly on the ODE trajectory, improving the student's adherence to the teacher's generation trajectory. Furthermore, we find and fix a previously undiscovered flaw in the widely-used FlowMatchEulerDiscreteScheduler that largely degrades few-step inference quality. Our experiment result on SD3 demonstrates our method's efficacy.

</details>


### [223] [FVAR: Visual Autoregressive Modeling via Next Focus Prediction](https://arxiv.org/abs/2511.18838)
*Xiaofan Li,Chenming Wu,Yanpeng Sun,Jiaming Zhou,Delin Qu,Yansong Qu,Weihao Bo,Haibao Yu,Dingkang Liang*

Main category: cs.CV

TL;DR: FVAR提出了一种新的视觉自回归模型范式，将传统的多尺度金字塔构建从简单的下采样改为模拟相机对焦过程，通过渐进式去模糊来消除混叠伪影，提高图像生成质量。


<details>
  <summary>Details</summary>
Motivation: 传统视觉自回归模型使用均匀尺度下采样构建多尺度金字塔，会导致混叠伪影，影响细节保留和图像质量。

Method: 1) 提出下一焦点预测范式，替代下一尺度预测；2) 使用物理一致的散焦核构建渐进重聚焦金字塔；3) 引入高频残差学习，通过专门的残差教师网络在训练中有效利用混叠信息。

Result: 在ImageNet上的实验表明，FVAR显著减少了混叠伪影，改善了细节保留和文本可读性，性能优于现有方法。

Conclusion: FVAR通过模拟自然对焦过程，从根本上解决了混叠问题，与现有VAR框架完美兼容，实现了更高质量的图像生成。

Abstract: Visual autoregressive models achieve remarkable generation quality through next-scale predictions across multi-scale token pyramids. However, the conventional method uses uniform scale downsampling to build these pyramids, leading to aliasing artifacts that compromise fine details and introduce unwanted jaggies and moiré patterns. To tackle this issue, we present \textbf{FVAR}, which reframes the paradigm from \emph{next-scale prediction} to \emph{next-focus prediction}, mimicking the natural process of camera focusing from blur to clarity. Our approach introduces three key innovations: \textbf{1) Next-Focus Prediction Paradigm} that transforms multi-scale autoregression by progressively reducing blur rather than simply downsampling; \textbf{2) Progressive Refocusing Pyramid Construction} that uses physics-consistent defocus kernels to build clean, alias-free multi-scale representations; and \textbf{3) High-Frequency Residual Learning} that employs a specialized residual teacher network to effectively incorporate alias information during training while maintaining deployment simplicity. Specifically, we construct optical low-pass views using defocus point spread function (PSF) kernels with decreasing radius, creating smooth blur-to-clarity transitions that eliminate aliasing at its source. To further enhance detail generation, we introduce a High-Frequency Residual Teacher that learns from both clean structure and alias residuals, distilling this knowledge to a vanilla VAR deployment network for seamless inference. Extensive experiments on ImageNet demonstrate that FVAR substantially reduces aliasing artifacts, improves fine detail preservation, and enhances text readability, achieving superior performance with perfect compatibility to existing VAR frameworks.

</details>


### [224] [Enhancing Multi-Label Thoracic Disease Diagnosis with Deep Ensemble-Based Uncertainty Quantification](https://arxiv.org/abs/2511.18839)
*Yasiru Laksara,Uthayasanker Thayasivam*

Main category: cs.CV

TL;DR: 该研究通过集成深度集成方法，在胸部X光疾病诊断中实现了可靠的不确定性量化，解决了深度学习模型在临床应用中缺乏预测置信度的问题。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在临床高风险环境中的实用性受到其确定性本质的限制，无法提供可靠的预测置信度度量。

Method: 从失败的蒙特卡洛dropout方法转向使用9成员深度集成方法，实现了性能稳定和校准改进。

Result: 深度集成方法达到了最先进的性能（平均AUROC 0.8559，平均F1分数0.3857），并显著改善了校准（平均ECE 0.0728，NLL 0.1916），同时能够可靠分解总不确定性。

Conclusion: 深度集成为临床决策支持系统提供了一个可信赖且可解释的平台，将模型从概率工具转变为可靠的临床决策支持系统。

Abstract: The utility of deep learning models, such as CheXNet, in high stakes clinical settings is fundamentally constrained by their purely deterministic nature, failing to provide reliable measures of predictive confidence. This project addresses this critical gap by integrating robust Uncertainty Quantification (UQ) into a high performance diagnostic platform for 14 common thoracic diseases on the NIH ChestX-ray14 dataset. Initial architectural development failed to stabilize performance and calibration using Monte Carlo Dropout (MCD), yielding an unacceptable Expected Calibration Error (ECE) of 0.7588. This technical failure necessitated a rigorous architectural pivot to a high diversity, 9-member Deep Ensemble (DE). This resulting DE successfully stabilized performance and delivered superior reliability, achieving a State-of-the-Art (SOTA) average Area Under the Receiver Operating Characteristic Curve (AUROC) of 0.8559 and an average F1 Score of 0.3857. Crucially, the DE demonstrated superior calibration (Mean ECE of 0.0728 and Negative Log-Likelihood (NLL) of 0.1916) and enabled the reliable decomposition of total uncertainty into its Aleatoric (irreducible data noise) and Epistemic (reducible model knowledge) components, with a mean Epistemic Uncertainty (EU) of 0.0240. These results establish the Deep Ensemble as a trustworthy and explainable platform, transforming the model from a probabilistic tool into a reliable clinical decision support system.

</details>


### [225] [Personalized Federated Segmentation with Shared Feature Aggregation and Boundary-Focused Calibration](https://arxiv.org/abs/2511.18847)
*Ishmam Tashdeed,Md. Atiqur Rahman,Sabrina Islam,Md. Azam Hossain*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的个性化联邦学习方法FedOAP，用于器官无关的肿瘤分割，通过解耦交叉注意力机制和扰动边界损失来解决现有方法忽视跨客户端共享特征利用的问题。


<details>
  <summary>Details</summary>
Motivation: 现有个性化联邦学习方法在医学图像分割中大多忽视了不同客户端间共享特征的潜在价值，特别是在每个客户端包含不同器官分割数据的情况下。

Method: FedOAP采用解耦交叉注意力机制，使每个客户端保留本地查询的同时关注全局共享的键值对，并引入扰动边界损失来改善分割边界的一致性。

Result: 在多个器官的肿瘤分割任务上进行的广泛实验表明，FedOAP在性能上持续优于现有的最先进联邦学习和个性化分割方法。

Conclusion: FedOAP通过有效利用跨客户端共享特征和改善边界分割精度，为个性化联邦学习在医学图像分割领域提供了有效的解决方案。

Abstract: Personalized federated learning (PFL) possesses the unique capability of preserving data confidentiality among clients while tackling the data heterogeneity problem of non-independent and identically distributed (Non-IID) data. Its advantages have led to widespread adoption in domains such as medical image segmentation. However, the existing approaches mostly overlook the potential benefits of leveraging shared features across clients, where each client contains segmentation data of different organs. In this work, we introduce a novel personalized federated approach for organ agnostic tumor segmentation (FedOAP), that utilizes cross-attention to model long-range dependencies among the shared features of different clients and a boundary-aware loss to improve segmentation consistency. FedOAP employs a decoupled cross-attention (DCA), which enables each client to retain local queries while attending to globally shared key-value pairs aggregated from all clients, thereby capturing long-range inter-organ feature dependencies. Additionally, we introduce perturbed boundary loss (PBL) which focuses on the inconsistencies of the predicted mask's boundary for each client, forcing the model to localize the margins more precisely. We evaluate FedOAP on diverse tumor segmentation tasks spanning different organs. Extensive experiments demonstrate that FedOAP consistently outperforms existing state-of-the-art federated and personalized segmentation methods.

</details>


### [226] [Robust Long-term Test-Time Adaptation for 3D Human Pose Estimation through Motion Discretization](https://arxiv.org/abs/2511.18851)
*Yilin Wen,Kechuan Dong,Yusuke Sugano*

Main category: cs.CV

TL;DR: 本文提出了一种针对3D人体姿态估计的在线测试时自适应方法，通过运动离散化和软重置机制来缓解错误累积问题，在持续适应过程中提升性能。


<details>
  <summary>Details</summary>
Motivation: 在线测试时自适应方法在3D人体姿态估计中面临错误累积的挑战，因为依赖不完美预测的自我监督会导致性能随时间下降。

Method: 采用无监督聚类在潜在运动表示空间中推导锚点运动，利用其规律性监督姿态估计器并实现高效自我重放。同时引入软重置机制，在连续适应过程中将姿态估计器恢复到其指数移动平均值。

Result: 实验表明该方法优于先前的在线测试时自适应方法，验证了设计选择的有效性。

Conclusion: 通过缓解错误累积，该方法能够有效利用个人形状和运动特征，在持续适应相同个体的流式测试视频时实现更高的准确性。

Abstract: Online test-time adaptation addresses the train-test domain gap by adapting the model on unlabeled streaming test inputs before making the final prediction. However, online adaptation for 3D human pose estimation suffers from error accumulation when relying on self-supervision with imperfect predictions, leading to degraded performance over time. To mitigate this fundamental challenge, we propose a novel solution that highlights the use of motion discretization. Specifically, we employ unsupervised clustering in the latent motion representation space to derive a set of anchor motions, whose regularity aids in supervising the human pose estimator and enables efficient self-replay. Additionally, we introduce an effective and efficient soft-reset mechanism by reverting the pose estimator to its exponential moving average during continuous adaptation. We examine long-term online adaptation by continuously adapting to out-of-domain streaming test videos of the same individual, which allows for the capture of consistent personal shape and motion traits throughout the streaming observation. By mitigating error accumulation, our solution enables robust exploitation of these personal traits for enhanced accuracy. Experiments demonstrate that our solution outperforms previous online test-time adaptation methods and validate our design choices.

</details>


### [227] [Deep Hybrid Model for Region of Interest Detection in Omnidirectional Videos](https://arxiv.org/abs/2511.18856)
*Sana Alamgeer*

Main category: cs.CV

TL;DR: 设计一个混合显著性模型来预测360°视频中的感兴趣区域，以优化视频流传输和提升观看体验。


<details>
  <summary>Details</summary>
Motivation: 360°视频中的感兴趣区域对于预测视口、智能剪辑视频以减少带宽使用至关重要，能够减少头戴设备观看时的头部移动并提升流媒体效率。

Method: 预处理视频获取帧，开发混合显著性模型预测感兴趣区域，后处理模型输出得到每帧的感兴趣区域。

Result: 将提出的方法与360RAT数据集的主观标注进行性能比较。

Conclusion: 通过混合显著性模型有效识别360°视频中的感兴趣区域，为视频流传输优化提供了可行方案。

Abstract: The main goal of the project is to design a new model that predicts regions of interest in 360$^{\circ}$ videos. The region of interest (ROI) plays an important role in 360$^{\circ}$ video streaming. For example, ROIs are used to predict view-ports, intelligently cut the videos for live streaming, etc so that less bandwidth is used. Detecting view-ports in advance helps reduce the movement of the head while streaming and watching a video via the head-mounted device. Whereas, intelligent cuts of the videos help improve the efficiency of streaming the video to users and enhance the quality of their viewing experience. This report illustrates the secondary task to identify ROIs, in which, we design, train, and test a hybrid saliency model. In this work, we refer to saliency regions to represent the regions of interest. The method includes the processes as follows: preprocessing the video to obtain frames, developing a hybrid saliency model for predicting the region of interest, and finally post-processing the output predictions of the hybrid saliency model to obtain the output region of interest for each frame. Then, we compare the performance of the proposed method with the subjective annotations of the 360RAT dataset.

</details>


### [228] [Rethinking Long-tailed Dataset Distillation: A Uni-Level Framework with Unbiased Recovery and Relabeling](https://arxiv.org/abs/2511.18858)
*Xiao Cui,Yulei Qin,Xinyue Li,Wengang Zhou,Hongsheng Li,Houqiang Li*

Main category: cs.CV

TL;DR: 本文提出了一种针对长尾数据集蒸馏的新方法，通过统计对齐视角联合缓解模型偏差和恢复公平监督，在长尾分布下显著提升了蒸馏性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据集蒸馏方法在平衡数据集上表现良好，但在长尾分布下表现不佳，因为类别不平衡会导致模型表示偏差和批量归一化统计估计失真。

Method: 提出了三个关键组件：1）增强专家模型用于可靠统计估计和软标签生成；2）通过动态调整动量的完整前向传播重新校准BN统计；3）通过多轮机制增量选择高置信度和多样化的增强来初始化合成图像。

Result: 在四个长尾基准测试上的实验显示，该方法在IPC=10和IF=10条件下，在CIFAR-100-LT上提升top-1准确率15.6%，在Tiny-ImageNet-LT上提升11.8%。

Conclusion: 该方法通过统计对齐视角有效解决了长尾数据集蒸馏中的模型偏差问题，在多种长尾基准测试中均优于现有最先进方法。

Abstract: Dataset distillation creates a small distilled set that enables efficient training by capturing key information from the full dataset. While existing dataset distillation methods perform well on balanced datasets, they struggle under long-tailed distributions, where imbalanced class frequencies induce biased model representations and corrupt statistical estimates such as Batch Normalization (BN) statistics. In this paper, we rethink long-tailed dataset distillation by revisiting the limitations of trajectory-based methods, and instead adopt the statistical alignment perspective to jointly mitigate model bias and restore fair supervision. To this end, we introduce three dedicated components that enable unbiased recovery of distilled images and soft relabeling: (1) enhancing expert models (an observer model for recovery and a teacher model for relabeling) to enable reliable statistics estimation and soft-label generation; (2) recalibrating BN statistics via a full forward pass with dynamically adjusted momentum to reduce representation skew; (3) initializing synthetic images by incrementally selecting high-confidence and diverse augmentations via a multi-round mechanism that promotes coverage and diversity. Extensive experiments on four long-tailed benchmarks show consistent improvements over state-of-the-art methods across varying degrees of class imbalance.Notably, our approach improves top-1 accuracy by 15.6% on CIFAR-100-LT and 11.8% on Tiny-ImageNet-LT under IPC=10 and IF=10.

</details>


### [229] [DualGazeNet: A Biologically Inspired Dual-Gaze Query Network for Salient Object Detection](https://arxiv.org/abs/2511.18865)
*Yu Zhang,Haoan Ping,Yuchen Li,Zhenshan Bing,Fuchun Sun,Alois Knoll*

Main category: cs.CV

TL;DR: 提出DualGazeNet，一种基于生物视觉原理的简单Transformer框架，在显著目标检测任务中实现SOTA性能，同时具有更高的计算效率和跨域泛化能力


<details>
  <summary>Details</summary>
Motivation: 当前显著目标检测方法趋向复杂架构，但复杂设计反而导致特征冗余和性能瓶颈。受人类视觉系统高效识别显著目标的启发，希望设计一个基于生物原理但架构简单的框架

Method: DualGazeNet：纯Transformer框架，模拟人类视觉系统的双生物原理——鲁棒表示学习和大细胞-小细胞双通路处理，结合皮层注意力调制

Result: 在5个RGB SOD基准测试中超越25个SOTA方法；相比4个Transformer基线，推理速度提升60%，FLOPs减少53.4%；在伪装和水下SOD任务中展现强泛化能力

Conclusion: DualGazeNet证明了基于生物原理的简单架构可以同时实现高精度、高效率和强泛化能力，为显著目标检测提供了新的设计思路

Abstract: Recent salient object detection (SOD) methods aim to improve performance in four key directions: semantic enhancement, boundary refinement, auxiliary task supervision, and multi-modal fusion. In pursuit of continuous gains, these approaches have evolved toward increasingly sophisticated architectures with multi-stage pipelines, specialized fusion modules, edge-guided learning, and elaborate attention mechanisms. However, this complexity paradoxically introduces feature redundancy and cross-component interference that obscure salient cues, ultimately reaching performance bottlenecks. In contrast, human vision achieves efficient salient object identification without such architectural complexity. This contrast raises a fundamental question: can we design a biologically grounded yet architecturally simple SOD framework that dispenses with most of this engineering complexity, while achieving state-of-the-art accuracy, computational efficiency, and interpretability? In this work, we answer this question affirmatively by introducing DualGazeNet, a biologically inspired pure Transformer framework that models the dual biological principles of robust representation learning and magnocellular-parvocellular dual-pathway processing with cortical attention modulation in the human visual system. Extensive experiments on five RGB SOD benchmarks show that DualGazeNet consistently surpasses 25 state-of-the-art CNN- and Transformer-based methods. On average, DualGazeNet achieves about 60\% higher inference speed and 53.4\% fewer FLOPs than four Transformer-based baselines of similar capacity (VST++, MDSAM, Sam2unet, and BiRefNet). Moreover, DualGazeNet exhibits strong cross-domain generalization, achieving leading or highly competitive performance on camouflaged and underwater SOD benchmarks without relying on additional modalities.

</details>


### [230] [HunyuanVideo 1.5 Technical Report](https://arxiv.org/abs/2511.18870)
*Bing Wu,Chang Zou,Changlin Li,Duojun Huang,Fang Yang,Hao Tan,Jack Peng,Jianbing Wu,Jiangfeng Xiong,Jie Jiang,Linus,Patrol,Peizhen Zhang,Peng Chen,Penghao Zhao,Qi Tian,Songtao Liu,Weijie Kong,Weiyan Wang,Xiao He,Xin Li,Xinchi Deng,Xuefei Zhe,Yang Li,Yanxin Long,Yuanbo Peng,Yue Wu,Yuhong Liu,Zhenyu Wang,Zuozhuo Dai,Bo Peng,Coopers Li,Gu Gong,Guojian Xiao,Jiahe Tian,Jiaxin Lin,Jie Liu,Jihong Zhang,Jiesong Lian,Kaihang Pan,Lei Wang,Lin Niu,Mingtao Chen,Mingyang Chen,Mingzhe Zheng,Miles Yang,Qiangqiang Hu,Qi Yang,Qiuyong Xiao,Runzhou Wu,Ryan Xu,Rui Yuan,Shanshan Sang,Shisheng Huang,Siruis Gong,Shuo Huang,Weiting Guo,Xiang Yuan,Xiaojia Chen,Xiawei Hu,Wenzhi Sun,Xiele Wu,Xianshun Ren,Xiaoyan Yuan,Xiaoyue Mi,Yepeng Zhang,Yifu Sun,Yiting Lu,Yitong Li,You Huang,Yu Tang,Yixuan Li,Yuhang Deng,Yuan Zhou,Zhichao Hu,Zhiguang Liu,Zhihe Yang,Zilin Yang,Zhenzhi Lu,Zixiang Zhou,Zhao Zhong*

Main category: cs.CV

TL;DR: HunyuanVideo 1.5是一个轻量级开源视频生成模型，仅8.3B参数即可实现SOTA视觉质量和运动连贯性，支持消费级GPU高效推理


<details>
  <summary>Details</summary>
Motivation: 为社区提供高性能视频生成基础，降低视频创作和研究门槛，让更广泛用户能够使用先进视频生成技术

Method: 采用精心数据筛选、先进DiT架构（含选择性滑动瓦片注意力SSTA）、字形感知文本编码增强双语理解、渐进式预训练和后训练、高效视频超分辨率网络

Result: 在开源视频生成模型中建立新SOTA，实现高质量文本到视频和图像到视频生成，支持多种时长和分辨率

Conclusion: 通过发布代码和模型权重，为社区提供可访问的高性能视频生成基础，推动视频生成技术普及

Abstract: We present HunyuanVideo 1.5, a lightweight yet powerful open-source video generation model that achieves state-of-the-art visual quality and motion coherence with only 8.3 billion parameters, enabling efficient inference on consumer-grade GPUs. This achievement is built upon several key components, including meticulous data curation, an advanced DiT architecture featuring selective and sliding tile attention (SSTA), enhanced bilingual understanding through glyph-aware text encoding, progressive pre-training and post-training, and an efficient video super-resolution network. Leveraging these designs, we developed a unified framework capable of high-quality text-to-video and image-to-video generation across multiple durations and resolutions.Extensive experiments demonstrate that this compact and proficient model establishes a new state-of-the-art among open-source video generation models. By releasing the code and model weights, we provide the community with a high-performance foundation that lowers the barrier to video creation and research, making advanced video generation accessible to a broader audience. All open-source assets are publicly available at https://github.com/Tencent-Hunyuan/HunyuanVideo-1.5.

</details>


### [231] [Neural Texture Splatting: Expressive 3D Gaussian Splatting for View Synthesis, Geometry, and Dynamic Reconstruction](https://arxiv.org/abs/2511.18873)
*Yiming Wang,Shaofei Wang,Marko Mihajlovic,Siyu Tang*

Main category: cs.CV

TL;DR: 本文提出Neural Texture Splatting (NTS)方法，通过全局神经场增强3DGS的表示能力，在多种重建任务中实现性能提升。


<details>
  <summary>Details</summary>
Motivation: 3DGS使用3D高斯核建模局部变化，表示能力有限。现有方法主要针对密集新视图合成，在更一般的重建场景中效果不佳。

Method: 引入全局神经场（三平面和神经解码器的混合）为每个基元预测局部外观和几何场，通过共享表示减少模型大小并促进全局信息交换。

Result: 在多个基准测试中一致改进模型并达到最先进结果，支持视图和时间依赖效果。

Conclusion: NTS通过神经建模局部纹理场，显著提升3DGS在各种重建任务中的表现和泛化能力。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a leading approach for high-quality novel view synthesis, with numerous variants extending its applicability to a broad spectrum of 3D and 4D scene reconstruction tasks. Despite its success, the representational capacity of 3DGS remains limited by the use of 3D Gaussian kernels to model local variations. Recent works have proposed to augment 3DGS with additional per-primitive capacity, such as per-splat textures, to enhance its expressiveness. However, these per-splat texture approaches primarily target dense novel view synthesis with a reduced number of Gaussian primitives, and their effectiveness tends to diminish when applied to more general reconstruction scenarios. In this paper, we aim to achieve concrete performance improvement over state-of-the-art 3DGS variants across a wide range of reconstruction tasks, including novel view synthesis, geometry and dynamic reconstruction, under both sparse and dense input settings. To this end, we introduce Neural Texture Splatting (NTS). At the core of our approach is a global neural field (represented as a hybrid of a tri-plane and a neural decoder) that predicts local appearance and geometric fields for each primitive. By leveraging this shared global representation that models local texture fields across primitives, we significantly reduce model size and facilitate efficient global information exchange, demonstrating strong generalization across tasks. Furthermore, our neural modeling of local texture fields introduces expressive view- and time-dependent effects, a critical aspect that existing methods fail to account for. Extensive experiments show that Neural Texture Splatting consistently improves models and achieves state-of-the-art results across multiple benchmarks.

</details>


### [232] [Parallel Vision Token Scheduling for Fast and Accurate Multimodal LMMs Inference](https://arxiv.org/abs/2511.18875)
*Wengyi Zhan,Mingbao Lin,Zhihang Lin,Rongrong Ji*

Main category: cs.CV

TL;DR: ParVTS是一种无需训练的并行视觉令牌调度框架，通过将视觉令牌分为主体和非主体组并行处理，并在推理中期丢弃非主体路径来减少计算量，实现高效的多模态大语言模型推理。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型因高分辨率图像产生大量视觉令牌，导致自注意力机制计算复杂度呈二次方增长，推理延迟严重。现有方法简单剪枝会丢失重要上下文信息，影响准确性。

Method: 提出ParVTS框架：1）将视觉令牌划分为主体和非主体组；2）并行处理两组令牌，将其语义转移到问题令牌；3）推理中期丢弃非主体路径以减少计算。该方法无需训练、无需额外模块，兼容多种MLLM架构。

Result: 在多个MLLM骨干网络上实验表明，ParVTS最多可剪除88.9%的视觉令牌，性能损失极小，实现1.77倍加速和70%的FLOPs减少。

Conclusion: ParVTS通过智能的令牌调度策略，在保持模型准确性的同时显著提升推理效率，为多模态大语言模型的实际部署提供了有效的解决方案。

Abstract: Multimodal large language models (MLLMs) deliver impressive vision-language reasoning but suffer steep inference latency because self-attention scales quadratically with sequence length and thousands of visual tokens contributed by high-resolution images. Naively pruning less-informative visual tokens reduces this burden, yet indiscriminate removal can strip away contextual cues essential for background or fine-grained questions, undermining accuracy. In this paper, we present ParVTS (Parallel Vision Token Scheduling), a training-free scheduling framework that partitions visual tokens into subject and non-subject groups, processes them in parallel to transfer their semantics into question tokens, and discards the non-subject path mid-inference to reduce computation. This scheduling reduces computational complexity, requires no heuristics or additional modules, and is compatible with diverse existing MLLM architectures. Experiments across multiple MLLM backbones show that ParVTS prunes up to 88.9% of visual tokens with minimal performance drop, achieving 1.77x speedup and 70% FLOPs reduction.

</details>


### [233] [Facade Segmentation for Solar Photovoltaic Suitability](https://arxiv.org/abs/2511.18882)
*Ayca Duran,Christoph Waibel,Bernd Bickel,Iro Armeni,Arno Schlueter*

Main category: cs.CV

TL;DR: 该论文提出了一种自动化识别建筑立面光伏适用表面并估算太阳能潜力的流程，通过SegFormer-B5模型在CMP Facades数据集上的微调，将语义预测转换为立面级光伏适用性掩码和光伏板布局。


<details>
  <summary>Details</summary>
Motivation: 建筑集成光伏（BIPV）立面是城市脱碳的有前景途径，但现有机器学习方法主要针对屋顶光伏规划，立面自动化方法仍稀缺且过于简化。

Method: 集成立面建筑组成的详细信息，自动识别光伏适用表面并估算太阳能潜力。使用SegFormer-B5模型在CMP Facades数据集上进行微调，将语义预测转换为考虑模块尺寸和间隙的光伏适用性掩码和光伏板布局。

Result: 在来自10个城市的373个已知尺寸立面数据集上应用，结果显示可安装BIPV潜力显著低于理论潜力，为可靠的城市能源规划提供了宝贵见解。

Conclusion: 随着立面图像的日益可用性，所提出的流程可以扩展到支持全球城市的BIPV规划。

Abstract: Building integrated photovoltaic (BIPV) facades represent a promising pathway towards urban decarbonization, especially where roof areas are insufficient and ground-mounted arrays are infeasible. Although machine learning-based approaches to support photovoltaic (PV) planning on rooftops are well researched, automated approaches for facades still remain scarce and oversimplified. This paper therefore presents a pipeline that integrates detailed information on the architectural composition of the facade to automatically identify suitable surfaces for PV application and estimate the solar energy potential. The pipeline fine-tunes SegFormer-B5 on the CMP Facades dataset and converts semantic predictions into facade-level PV suitability masks and PV panel layouts considering module sizes and clearances. Applied to a dataset of 373 facades with known dimensions from ten cities, the results show that installable BIPV potential is significantly lower than theoretical potential, thus providing valuable insights for reliable urban energy planning. With the growing availability of facade imagery, the proposed pipeline can be scaled to support BIPV planning in cities worldwide.

</details>


### [234] [MagicWorld: Interactive Geometry-driven Video World Exploration](https://arxiv.org/abs/2511.18886)
*Guangyuan Li,Siming Zheng,Shuolin Xu,Jinwei Chen,Bo Li,Xiaobin Hu,Lei Zhao,Peng-Tao Jiang*

Main category: cs.CV

TL;DR: MagicWorld是一个交互式视频世界模型，通过整合3D几何先验和历史检索机制，解决了现有方法在视角变化下的结构不稳定性和多步交互中的历史信息遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 现有交互式视频世界模型存在两个关键局限：1）未能充分利用指令驱动的场景运动与底层3D几何的对应关系，导致视角变化时结构不稳定；2）多步交互中容易遗忘历史信息，导致错误累积和场景语义结构漂移。

Method: 提出MagicWorld模型，包含两个核心模块：1）Action-Guided 3D Geometry Module (AG3D)：从每轮交互的第一帧构建点云，为视角转换提供显式几何约束；2）History Cache Retrieval (HCR)机制：在生成过程中检索相关历史帧作为条件信号，帮助模型利用过去场景信息。

Result: 实验结果表明，MagicWorld在交互迭代过程中显著提升了场景稳定性和连续性。

Conclusion: MagicWorld通过整合3D几何先验和历史检索机制，有效解决了交互式视频生成中的结构一致性和历史信息保持问题，实现了更稳定的场景演化。

Abstract: Recent interactive video world model methods generate scene evolution conditioned on user instructions. Although they achieve impressive results, two key limitations remain. First, they fail to fully exploit the correspondence between instruction-driven scene motion and the underlying 3D geometry, which results in structural instability under viewpoint changes. Second, they easily forget historical information during multi-step interaction, resulting in error accumulation and progressive drift in scene semantics and structure. To address these issues, we propose MagicWorld, an interactive video world model that integrates 3D geometric priors and historical retrieval. MagicWorld starts from a single scene image, employs user actions to drive dynamic scene evolution, and autoregressively synthesizes continuous scenes. We introduce the Action-Guided 3D Geometry Module (AG3D), which constructs a point cloud from the first frame of each interaction and the corresponding action, providing explicit geometric constraints for viewpoint transitions and thereby improving structural consistency. We further propose History Cache Retrieval (HCR) mechanism, which retrieves relevant historical frames during generation and injects them as conditioning signals, helping the model utilize past scene information and mitigate error accumulation. Experimental results demonstrate that MagicWorld achieves notable improvements in scene stability and continuity across interaction iterations.

</details>


### [235] [MFmamba: A Multi-function Network for Panchromatic Image Resolution Restoration Based on State-Space Model](https://arxiv.org/abs/2511.18888)
*Qian Jiang,Qianqian Wang,Xin Jin,Michal Wozniak,Shaowen Yao,Wei Zhou*

Main category: cs.CV

TL;DR: 提出了一个多功能模型MFmamba，通过三种不同输入实现超分辨率、光谱恢复以及联合超分辨率和光谱恢复任务，解决了单传感器限制下只能获得高空间分辨率灰度PAN图像和低空间分辨率彩色MS图像的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在局限性：超分辨率技术无法提高光谱分辨率，彩色化技术无法提高空间分辨率，而全色锐化方法需要两个配准输入且无法实现超分辨率。因此需要一个集成方法来解决这些问题。

Method: 设计基于UNet++的多功能模型MFmamba，包含Mamba上采样块(MUB)、双池注意力机制(DPA)替换跳跃连接，以及多尺度混合交叉块(MHCB)进行初始特征提取。

Result: 实验表明MFmamba在评估指标和视觉效果上具有竞争力，在仅使用输入PAN图像的情况下在三个任务中都表现良好。

Conclusion: MFmamba模型能够有效解决遥感图像处理中的超分辨率和光谱恢复问题，为单传感器图像处理提供了集成解决方案。

Abstract: Remote sensing images are becoming increasingly widespread in military, earth resource exploration. Because of the limitation of a single sensor, we can obtain high spatial resolution grayscale panchromatic (PAN) images and low spatial resolution color multispectral (MS) images. Therefore, an important issue is to obtain a color image with high spatial resolution when there is only a PAN image at the input. The existing methods improve spatial resolution using super-resolution (SR) technology and spectral recovery using colorization technology. However, the SR technique cannot improve the spectral resolution, and the colorization technique cannot improve the spatial resolution. Moreover, the pansharpening method needs two registered inputs and can not achieve SR. As a result, an integrated approach is expected. To solve the above problems, we designed a novel multi-function model (MFmamba) to realize the tasks of SR, spectral recovery, joint SR and spectral recovery through three different inputs. Firstly, MFmamba utilizes UNet++ as the backbone, and a Mamba Upsample Block (MUB) is combined with UNet++. Secondly, a Dual Pool Attention (DPA) is designed to replace the skip connection in UNet++. Finally, a Multi-scale Hybrid Cross Block (MHCB) is proposed for initial feature extraction. Many experiments show that MFmamba is competitive in evaluation metrics and visual results and performs well in the three tasks when only the input PAN image is used.

</details>


### [236] [MetaDCSeg: Robust Medical Image Segmentation via Meta Dynamic Center Weighting](https://arxiv.org/abs/2511.18894)
*Chenyu Mu,Guihai Chen,Xun Yang,Erkun Yang,Cheng Deng*

Main category: cs.CV

TL;DR: 提出了MetaDCSeg框架，通过动态学习像素级权重来抑制噪声标注的影响，特别针对医学图像分割中的边界模糊问题。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割常受噪声标注和模糊边界干扰，现有方法基于全局噪声假设或置信度样本选择，难以有效处理边界区域的性能下降问题。

Method: 采用动态中心距离（DCD）机制建模边界不确定性，通过加权特征距离关注前景、背景和边界中心，引导模型关注边界附近的难分割像素。

Result: 在四个基准数据集上的实验表明，MetaDCSeg在不同噪声水平下均优于现有最先进方法。

Conclusion: 该方法能更精确处理结构边界，显著提升分割性能，特别是在具有挑战性的边界区域。

Abstract: Medical image segmentation is crucial for clinical applications, but it is frequently disrupted by noisy annotations and ambiguous anatomical boundaries, which lead to instability in model training. Existing methods typically rely on global noise assumptions or confidence-based sample selection, which inadequately mitigate the performance degradation caused by annotation noise, especially in challenging boundary regions. To address this issue, we propose MetaDCSeg, a robust framework that dynamically learns optimal pixel-wise weights to suppress the influence of noisy ground-truth labels while preserving reliable annotations. By explicitly modeling boundary uncertainty through a Dynamic Center Distance (DCD) mechanism, our approach utilizes weighted feature distances for foreground, background, and boundary centers, directing the model's attention toward hard-to-segment pixels near ambiguous boundaries. This strategy enables more precise handling of structural boundaries, which are often overlooked by existing methods, and significantly enhances segmentation performance. Extensive experiments across four benchmark datasets with varying noise levels demonstrate that MetaDCSeg consistently outperforms existing state-of-the-art methods.

</details>


### [237] [Learning What to Trust: Bayesian Prior-Guided Optimization for Visual Generation](https://arxiv.org/abs/2511.18919)
*Ruiying Liu,Yuanzhi Liang,Haibin Huang,Tianshu Yu,Chi Zhang*

Main category: cs.CV

TL;DR: BPGO通过引入贝叶斯先验锚点来建模奖励不确定性，在GRPO框架基础上实现了更有效的视觉生成模型优化


<details>
  <summary>Details</summary>
Motivation: 解决GRPO中文本-视觉对应关系的模糊性问题，避免奖励模型产生不确定和弱区分性信号

Method: 提出双层自适应优化信任机制：组间贝叶斯信任分配强调与先验一致的组更新，组内先验锚定重归一化通过扩展置信偏差和压缩不确定分数来锐化样本区分

Result: 在图像和视频生成任务中，BPGO相比标准GRPO和近期变体实现了更强的语义对齐、更高的感知保真度和更快的收敛速度

Conclusion: BPGO通过显式建模奖励不确定性，有效解决了GRPO框架中的模糊性问题，为视觉生成模型的后训练优化提供了更可靠的解决方案

Abstract: Group Relative Policy Optimization (GRPO) has emerged as an effective and lightweight framework for post-training visual generative models. However, its performance is fundamentally limited by the ambiguity of textual visual correspondence: a single prompt may validly describe diverse visual outputs, and a single image or video may support multiple equally correct interpretations. This many to many relationship leads reward models to generate uncertain and weakly discriminative signals, causing GRPO to underutilize reliable feedback and overfit noisy ones. We introduce Bayesian Prior-Guided Optimization (BPGO), a novel extension of GRPO that explicitly models reward uncertainty through a semantic prior anchor. BPGO adaptively modulates optimization trust at two levels: inter-group Bayesian trust allocation emphasizes updates from groups consistent with the prior while down-weighting ambiguous ones, and intra-group prior-anchored renormalization sharpens sample distinctions by expanding confident deviations and compressing uncertain scores. Across both image and video generation tasks, BPGO delivers consistently stronger semantic alignment, enhanced perceptual fidelity, and faster convergence than standard GRPO and recent variants.

</details>


### [238] [EventSTU: Event-Guided Efficient Spatio-Temporal Understanding for Video Large Language Models](https://arxiv.org/abs/2511.18920)
*Wenhao Xu,Xin Dong,Yue Li,Haoyuan Shi,Zhiwei Xiong*

Main category: cs.CV

TL;DR: 提出EventSTU框架，通过事件引导的训练无关方法实现高效视频时空理解，在时空维度分别进行关键帧采样和token剪枝，显著降低计算成本并提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型在处理长视频时存在高推理成本问题，需要减少冗余帧和token数量。

Method: 基于事件视觉的启发，设计粗到细的关键帧采样算法和自适应token剪枝算法，利用事件变化触发特性和视觉显著性作为零成本先验指导时空降维。

Result: EventSTU实现了3.01倍FLOPs减少和3.10倍预填充加速，同时性能有所提升，构建了首个事件包含的多模态基准EventBench。

Conclusion: 该方法不仅适用于物理事件相机，也支持通用视频理解，为高效视频分析提供了有效解决方案。

Abstract: Video large language models have demonstrated strong video understanding capabilities but suffer from high inference costs due to the massive number of tokens in long videos. Inspired by event-based vision, we propose an event-guided, training-free framework for efficient spatio-temporal understanding, named EventSTU. In the temporal domain, we design a coarse-to-fine keyframe sampling algorithm that exploits the change-triggered property of event cameras to eliminate redundant frames. In the spatial domain, we design an adaptive token pruning algorithm that leverages the visual saliency of events as a zero-cost prior to guide spatial reduction. From a holistic spatio-temporal perspective, we further integrate question relevance from keyframe sampling to adaptively allocate token pruning budgets. To facilitate evaluation, we construct EventBench, the first event-inclusive, human-annotated multimodal benchmark that covers diverse real-world scenarios. Beyond physical event cameras, EventSTU also supports general video understanding using simulated events. Comprehensive experiments show that EventSTU achieves 3.01x FLOPs reduction and 3.10x prefilling speedup over the strongest baseline while still improving performance.

</details>


### [239] [BackdoorVLM: A Benchmark for Backdoor Attacks on Vision-Language Models](https://arxiv.org/abs/2511.18921)
*Juncheng Li,Yige Li,Hanxun Huang,Yunhao Chen,Xin Wang,Yixu Wang,Xingjun Ma,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: BackdoorVLM是首个针对视觉语言模型(VLMs)的全面后门攻击评估基准，系统评估了5类多模态后门威胁在12种攻击方法下的表现，发现VLMs对文本指令高度敏感，仅需1%的中毒率就能达到90%以上的攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 后门攻击会破坏机器学习系统的可靠性，但在多模态基础模型特别是视觉语言模型中的影响尚未得到充分研究。

Method: 构建BackdoorVLM基准，采用统一视角在图像描述和视觉问答等核心视觉语言任务中注入和分析后门，将多模态后门威胁分为5类：定向拒绝、恶意注入、越狱、概念替换和感知劫持。

Result: VLMs对文本指令表现出强烈敏感性，在双模态后门中文本触发器通常压倒图像触发器；涉及文本模态的后门攻击效果显著，仅需1%的中毒率就能在大多数任务中达到90%以上的成功率。

Conclusion: 当前VLMs存在显著且未被充分探索的漏洞，BackdoorVLM可作为分析和缓解多模态后门威胁的有用基准。

Abstract: Backdoor attacks undermine the reliability and trustworthiness of machine learning systems by injecting hidden behaviors that can be maliciously activated at inference time. While such threats have been extensively studied in unimodal settings, their impact on multimodal foundation models, particularly vision-language models (VLMs), remains largely underexplored. In this work, we introduce \textbf{BackdoorVLM}, the first comprehensive benchmark for systematically evaluating backdoor attacks on VLMs across a broad range of settings. It adopts a unified perspective that injects and analyzes backdoors across core vision-language tasks, including image captioning and visual question answering. BackdoorVLM organizes multimodal backdoor threats into 5 representative categories: targeted refusal, malicious injection, jailbreak, concept substitution, and perceptual hijack. Each category captures a distinct pathway through which an adversary can manipulate a model's behavior. We evaluate these threats using 12 representative attack methods spanning text, image, and bimodal triggers, tested on 2 open-source VLMs and 3 multimodal datasets. Our analysis reveals that VLMs exhibit strong sensitivity to textual instructions, and in bimodal backdoors the text trigger typically overwhelms the image trigger when forming the backdoor mapping. Notably, backdoors involving the textual modality remain highly potent, with poisoning rates as low as 1\% yielding over 90\% success across most tasks. These findings highlight significant, previously underexplored vulnerabilities in current VLMs. We hope that BackdoorVLM can serve as a useful benchmark for analyzing and mitigating multimodal backdoor threats. Code is available at: https://github.com/bin015/BackdoorVLM .

</details>


### [240] [One4D: Unified 4D Generation and Reconstruction via Decoupled LoRA Control](https://arxiv.org/abs/2511.18922)
*Zhenxing Mi,Yuxin Wang,Dan Xu*

Main category: cs.CV

TL;DR: One4D是一个统一的4D生成和重建框架，通过同步生成RGB帧和点云图来创建动态4D内容。该框架采用统一掩码条件机制处理不同稀疏度的输入帧，并引入解耦LoRA控制技术来保持RGB和点云生成的质量。


<details>
  <summary>Details</summary>
Motivation: 现有的深度图或点云图重建方法在联合RGB和点云生成时往往会快速退化基础视频模型，因此需要一种能够同时处理4D生成和重建的统一框架。

Method: 基于强大的视频生成模型，设计了联合RGB和点云生成的网络架构。采用统一掩码条件机制处理不同稀疏度的输入帧，并引入解耦LoRA控制技术，使用两个模态特定的LoRA适配器形成解耦计算分支，通过轻量级零初始化控制链接学习像素级一致性。

Result: 在适度的计算预算下，在合成和真实4D数据集上训练后，One4D在生成和重建任务中都能产生高质量的RGB帧和准确的点云图。

Conclusion: 这项工作代表了使用视频扩散模型进行通用、高质量的基于几何的4D世界建模的重要一步。

Abstract: We present One4D, a unified framework for 4D generation and reconstruction that produces dynamic 4D content as synchronized RGB frames and pointmaps. By consistently handling varying sparsities of conditioning frames through a Unified Masked Conditioning (UMC) mechanism, One4D can seamlessly transition between 4D generation from a single image, 4D reconstruction from a full video, and mixed generation and reconstruction from sparse frames. Our framework adapts a powerful video generation model for joint RGB and pointmap generation, with carefully designed network architectures. The commonly used diffusion finetuning strategies for depthmap or pointmap reconstruction often fail on joint RGB and pointmap generation, quickly degrading the base video model. To address this challenge, we introduce Decoupled LoRA Control (DLC), which employs two modality-specific LoRA adapters to form decoupled computation branches for RGB frames and pointmaps, connected by lightweight, zero-initialized control links that gradually learn mutual pixel-level consistency. Trained on a mixture of synthetic and real 4D datasets under modest computational budgets, One4D produces high-quality RGB frames and accurate pointmaps across both generation and reconstruction tasks. This work represents a step toward general, high-quality geometry-based 4D world modeling using video diffusion models. Project page: https://mizhenxing.github.io/One4D

</details>


### [241] [Understanding, Accelerating, and Improving MeanFlow Training](https://arxiv.org/abs/2511.19065)
*Jin-Young Kim,Hyojun Go,Lea Bogensperger,Julius Erbach,Nikolai Kalischek,Federico Tombari,Konrad Schindler,Dominik Narnhofer*

Main category: cs.CV

TL;DR: 本文分析了MeanFlow训练动态，发现瞬时速度场是学习平均速度场的前提，并提出了一种有效的训练方案来加速瞬时速度形成并逐步转向长间隔平均速度学习，显著提升了少步生成性能。


<details>
  <summary>Details</summary>
Motivation: MeanFlow通过联合学习瞬时和平均速度场实现少步高质量生成，但其训练动态机制尚不明确，需要深入分析两种速度场的相互作用以优化训练过程。

Method: 通过分析两种速度场的相互作用机制，设计了一种分阶段训练方案：先加速瞬时速度场形成，然后逐步从短间隔转向长间隔平均速度场学习。

Result: 改进的MeanFlow训练在ImageNet 256x256上达到1-NFE FID 2.87（基线为3.43），训练时间减少2.5倍，或可用更小的DiT-L骨干网络达到基线性能。

Conclusion: 合理的训练策略设计能够显著提升MeanFlow的少步生成性能，证明了瞬时速度场学习对平均速度场学习的关键支撑作用。

Abstract: MeanFlow promises high-quality generative modeling in few steps, by jointly learning instantaneous and average velocity fields. Yet, the underlying training dynamics remain unclear. We analyze the interaction between the two velocities and find: (i) well-established instantaneous velocity is a prerequisite for learning average velocity; (ii) learning of instantaneous velocity benefits from average velocity when the temporal gap is small, but degrades as the gap increases; and (iii) task-affinity analysis indicates that smooth learning of large-gap average velocities, essential for one-step generation, depends on the prior formation of accurate instantaneous and small-gap average velocities. Guided by these observations, we design an effective training scheme that accelerates the formation of instantaneous velocity, then shifts emphasis from short- to long-interval average velocity. Our enhanced MeanFlow training yields faster convergence and significantly better few-step generation: With the same DiT-XL backbone, our method reaches an impressive FID of 2.87 on 1-NFE ImageNet 256x256, compared to 3.43 for the conventional MeanFlow baseline. Alternatively, our method matches the performance of the MeanFlow baseline with 2.5x shorter training time, or with a smaller DiT-L backbone.

</details>


### [242] [AttenDence: Maximizing Attention Confidence for Test Time Adaptation](https://arxiv.org/abs/2511.18925)
*Yash Mali*

Main category: cs.CV

TL;DR: 本文提出了一种基于注意力熵最小化的测试时自适应方法，通过最小化CLS token到图像补丁的注意力分布熵来提升模型在分布偏移下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统的测试时自适应方法主要依赖输出分布的熵最小化，但Transformer模型中的注意力机制提供了额外的无监督学习信号，可以更好地适应分布偏移。

Method: 提出最小化CLS token到图像补丁的注意力分布熵作为新的TTA目标，该方法鼓励模型在分布偏移下更自信地关注相关图像区域，即使在单个测试图像情况下也有效。

Result: 实验表明注意力熵最小化能提高模型对多种损坏类型的鲁棒性，同时不会损害在干净数据上的性能，适用于测试时的单样本图像流。

Conclusion: 注意力熵最小化是一种有效的测试时自适应方法，能够利用Transformer的注意力机制来提升模型在分布偏移下的性能。

Abstract: Test-time adaptation (TTA) enables models to adapt to distribution shifts at inference time. While entropy minimization over the output distribution has proven effective for TTA, transformers offer an additional unsupervised learning signal through their attention mechanisms. We propose minimizing the entropy of attention distributions from the CLS token to image patches as a novel TTA objective.This approach encourages the model to attend more confidently to relevant image regions under distribution shift and is effective even when only a single test image is available. We demonstrate that attention entropy minimization improves robustness across diverse corruption types while not hurting performance on clean data on a single sample stream of images at test time.

</details>


### [243] [DynaMix: Generalizable Person Re-identification via Dynamic Relabeling and Mixed Data Sampling](https://arxiv.org/abs/2511.19067)
*Timur Mamedov,Anton Konushin,Vadim Konushin*

Main category: cs.CV

TL;DR: DynaMix是一种新颖的通用行人重识别方法，通过动态结合标记的多摄像头数据和伪标记的单摄像头数据，在三个核心模块的协同下实现高效的大规模训练。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法过度依赖有限标记的多摄像头数据的问题，利用大规模伪标记的单摄像头数据提升模型的泛化能力。

Method: 包含三个核心模块：动态重标记模块优化单摄像头伪标签；高效质心模块在大身份空间下维护鲁棒的身份表示；数据采样模块平衡学习复杂度和批内多样性。

Result: 在通用行人重识别任务中，DynaMix持续优于现有最先进方法。

Conclusion: DynaMix通过高效整合多源数据和大规模训练，显著提升了行人重识别模型的泛化性能。

Abstract: Generalizable person re-identification (Re-ID) aims to recognize individuals across unseen cameras and environments. While existing methods rely heavily on limited labeled multi-camera data, we propose DynaMix, a novel method that effectively combines manually labeled multi-camera and large-scale pseudo-labeled single-camera data. Unlike prior works, DynaMix dynamically adapts to the structure and noise of the training data through three core components: (1) a Relabeling Module that refines pseudo-labels of single-camera identities on-the-fly; (2) an Efficient Centroids Module that maintains robust identity representations under a large identity space; and (3) a Data Sampling Module that carefully composes mixed data mini-batches to balance learning complexity and intra-batch diversity. All components are specifically designed to operate efficiently at scale, enabling effective training on millions of images and hundreds of thousands of identities. Extensive experiments demonstrate that DynaMix consistently outperforms state-of-the-art methods in generalizable person Re-ID.

</details>


### [244] [FineXtrol: Controllable Motion Generation via Fine-Grained Text](https://arxiv.org/abs/2511.18927)
*Keming Shen,Bizhu Wu,Junliang Chen,Xiaoqin Wang,Linlin Shen*

Main category: cs.CV

TL;DR: FineXtrol是一个新的控制框架，用于通过时间感知、精确、用户友好和细粒度的文本控制信号来高效生成运动，这些信号描述了特定身体部位随时间的运动。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么使用大型语言模型生成更详细的文本但引入不对齐的细节和缺乏明确的时间线索，要么使用全局3D坐标序列作为额外控制信号但计算成本高。

Method: 提出了FineXtrol框架，设计了一个分层对比学习模块，鼓励文本编码器为新的控制信号产生更具区分性的嵌入，从而提高运动可控性。

Result: 定量结果显示FineXtrol在可控运动生成方面表现出色，定性分析展示了其在指导特定身体部位运动方面的灵活性。

Conclusion: FineXtrol有效解决了现有方法的问题，实现了高效且精确的文本驱动运动生成。

Abstract: Recent works have sought to enhance the controllability and precision of text-driven motion generation. Some approaches leverage large language models (LLMs) to produce more detailed texts, while others incorporate global 3D coordinate sequences as additional control signals. However, the former often introduces misaligned details and lacks explicit temporal cues, and the latter incurs significant computational cost when converting coordinates to standard motion representations. To address these issues, we propose FineXtrol, a novel control framework for efficient motion generation guided by temporally-aware, precise, user-friendly, and fine-grained textual control signals that describe specific body part movements over time. In support of this framework, we design a hierarchical contrastive learning module that encourages the text encoder to produce more discriminative embeddings for our novel control signals, thereby improving motion controllability. Quantitative results show that FineXtrol achieves strong performance in controllable motion generation, while qualitative analysis demonstrates its flexibility in directing specific body part movements.

</details>


### [245] [Collaborative Learning with Multiple Foundation Models for Source-Free Domain Adaptation](https://arxiv.org/abs/2511.19147)
*Huisoo Lee,Jisu Han,Hyunsouk Cho,Wonjun Hwang*

Main category: cs.CV

TL;DR: 提出了CoMA框架，通过协同利用CLIP和BLIP等互补基础模型来解决SFDA中单一模型语义覆盖受限的问题，使用双向适应机制和分解互信息方法提升域适应性能。


<details>
  <summary>Details</summary>
Motivation: 现有的源自由域适应方法依赖单一基础模型，容易导致语义覆盖受限，无法充分捕捉域偏移下的多样化上下文线索。

Method: CoMA框架包含双向适应机制：1）将不同基础模型与目标模型对齐以保持语义独特性；2）从基础模型向目标模型传递互补知识。引入分解互信息（DMI）来选择性增强真实依赖关系。

Result: 在Office-31、Office-Home、DomainNet-126和VisDA四个基准测试中均优于现有最先进的SFDA方法，在闭集、部分集和开放集设置下都取得最佳结果。

Conclusion: 通过协同利用互补基础模型和分解互信息方法，CoMA框架能有效解决SFDA中的语义覆盖不足问题，显著提升域适应性能。

Abstract: Source-Free Domain Adaptation (SFDA) aims to adapt a pre-trained source model to an unlabeled target domain without access to source data. Recent advances in Foundation Models (FMs) have introduced new opportunities for leveraging external semantic knowledge to guide SFDA. However, relying on a single FM is often insufficient, as it tends to bias adaptation toward a restricted semantic coverage, failing to capture diverse contextual cues under domain shift. To overcome this limitation, we propose a Collaborative Multi-foundation Adaptation (CoMA) framework that jointly leverages two different FMs (e.g., CLIP and BLIP) with complementary properties to capture both global semantics and local contextual cues. Specifically, we employ a bidirectional adaptation mechanism that (1) aligns different FMs with the target model for task adaptation while maintaining their semantic distinctiveness, and (2) transfers complementary knowledge from the FMs to the target model. To ensure stable adaptation under mini-batch training, we introduce Decomposed Mutual Information (DMI) that selectively enhances true dependencies while suppressing false dependencies arising from incomplete class coverage. Extensive experiments demonstrate that our method consistently outperforms existing state-of-the-art SFDA methods across four benchmarks, including Office-31, Office-Home, DomainNet-126, and VisDA, under the closed-set setting, while also achieving best results on partial-set and open-set variants.

</details>


### [246] [Human-Centric Open-Future Task Discovery: Formulation, Benchmark, and Scalable Tree-Based Search](https://arxiv.org/abs/2511.18929)
*Zijian Song,Xiaoxin Lin,Tao Pu,Zhenlong Yuan,Guangrun Wang,Liang Lin*

Main category: cs.CV

TL;DR: 提出人类中心开放未来任务发现（HOTD）问题，旨在识别能减少人类努力的任务，并开发了HOTD-Bench基准和协作多智能体搜索树（CMAST）框架来解决该问题。


<details>
  <summary>Details</summary>
Motivation: 当前大型多模态模型（LMMs）在机器人技术和具身AI方面取得进展，但如何在人类意图高度并发和动态的开放未来场景中发现能直接辅助人类的任务仍是一个未充分探索的挑战。

Method: 提出HOTD-Bench基准，包含2000多个真实世界视频、半自动标注流程和针对开放集未来评估的模拟协议；开发协作多智能体搜索树（CMAST）框架，通过多智能体系统分解复杂推理，并使用可扩展搜索树模块结构化推理过程。

Result: CMAST在HOTD-Bench上取得最佳性能，显著超越现有LMMs，并能与现有LMMs良好集成，持续提升性能。

Conclusion: HOTD问题具有重要研究价值，CMAST框架为解决该问题提供了有效方法，在开放未来任务发现方面表现出色。

Abstract: Recent progress in robotics and embodied AI is largely driven by Large Multimodal Models (LMMs). However, a key challenge remains underexplored: how can we advance LMMs to discover tasks that directly assist humans in open-future scenarios, where human intentions are highly concurrent and dynamic. In this work, we formalize the problem of Human-centric Open-future Task Discovery (HOTD), focusing particularly on identifying tasks that reduce human effort across multiple plausible futures. To facilitate this study, we propose an HOTD-Bench, which features over 2K real-world videos, a semi-automated annotation pipeline, and a simulation-based protocol tailored for open-set future evaluation. Additionally, we propose the Collaborative Multi-Agent Search Tree (CMAST) framework, which decomposes the complex reasoning through a multi-agent system and structures the reasoning process through a scalable search tree module. In our experiments, CMAST achieves the best performance on the HOTD-Bench, significantly surpassing existing LMMs. It also integrates well with existing LMMs, consistently improving performance.

</details>


### [247] [SpectraNet: FFT-assisted Deep Learning Classifier for Deepfake Face Detection](https://arxiv.org/abs/2511.19187)
*Nithira Jayarathne,Naveen Basnayake,Keshawa Jayasundara,Pasindu Dodampegama,Praveen Wijesinghe,Hirushika Pelagewatta,Kavishka Abeywardana,Sandushan Ranaweera,Chamira Edussooriya*

Main category: cs.CV

TL;DR: 提出基于EfficientNet-B6的轻量级深度伪造图像检测模型，通过变换技术和优化策略解决类别不平衡问题，实现高精度和泛化能力


<details>
  <summary>Details</summary>
Motivation: 深度伪造图像检测对打击虚假信息至关重要，需要开发轻量级且通用的检测方案

Method: 使用EfficientNet-B6架构，结合数据变换技术处理类别不平衡，采用鲁棒预处理、过采样和优化策略

Result: 模型达到高准确率、稳定性和泛化能力，但傅里叶变换特征影响有限

Conclusion: 该框架帮助非专业人士有效识别深度伪造图像，在可访问和可靠的深度伪造检测方面取得重要进展

Abstract: Detecting deepfake images is crucial in combating misinformation. We present a lightweight, generalizable binary classification model based on EfficientNet-B6, fine-tuned with transformation techniques to address severe class imbalances. By leveraging robust preprocessing, oversampling, and optimization strategies, our model achieves high accuracy, stability, and generalization. While incorporating Fourier transform-based phase and amplitude features showed minimal impact, our proposed framework helps non-experts to effectively identify deepfake images, making significant strides toward accessible and reliable deepfake detection.

</details>


### [248] [VeCoR - Velocity Contrastive Regularization for Flow Matching](https://arxiv.org/abs/2511.18942)
*Zong-Wei Hong,Jing-lun Li,Lin-Ze Li,Shen Zhang,Yao Tang*

Main category: cs.CV

TL;DR: VeCoR是一种增强流匹配模型稳定性的对比正则化方法，通过正负双向监督来改善轨迹演化，在低步数和轻量级配置下显著提升图像质量。


<details>
  <summary>Details</summary>
Motivation: 标准流匹配方法在轨迹演化过程中可能积累误差并使样本偏离数据流形，导致感知质量下降，特别是在轻量级或低步数配置下。

Method: 提出速度对比正则化(VeCoR)，在标准流匹配目标基础上增加对比性双向监督：不仅对齐预测速度与稳定参考方向(正监督)，还将其推离不一致的离流形方向(负监督)。

Result: 在ImageNet-1K 256×256上，VeCoR在SiT-XL/2和REPA-SiT-XL/2骨干网络上分别实现了22%和35%的相对FID降低；在MS-COCO文本到图像生成上进一步获得32%的相对FID增益。

Conclusion: VeCoR通过将流匹配从纯吸引性单边目标转化为双边训练信号，在稳定性、收敛性和图像质量方面实现了一致性改进，特别适用于低步数和轻量级设置。

Abstract: Flow Matching (FM) has recently emerged as a principled and efficient alternative to diffusion models. Standard FM encourages the learned velocity field to follow a target direction; however, it may accumulate errors along the trajectory and drive samples off the data manifold, leading to perceptual degradation, especially in lightweight or low-step configurations.
  To enhance stability and generalization, we extend FM into a balanced attract-repel scheme that provides explicit guidance on both "where to go" and "where not to go." To be formal, we propose \textbf{Velocity Contrastive Regularization (VeCoR)}, a complementary training scheme for flow-based generative modeling that augments the standard FM objective with contrastive, two-sided supervision. VeCoR not only aligns the predicted velocity with a stable reference direction (positive supervision) but also pushes it away from inconsistent, off-manifold directions (negative supervision). This contrastive formulation transforms FM from a purely attractive, one-sided objective into a two-sided training signal, regularizing trajectory evolution and improving perceptual fidelity across datasets and backbones.
  On ImageNet-1K 256$\times$256, VeCoR yields 22\% and 35\% relative FID reductions on SiT-XL/2 and REPA-SiT-XL/2 backbones, respectively, and achieves further FID gains (32\% relative) on MS-COCO text-to-image generation, demonstrating consistent improvements in stability, convergence, and image quality, particularly in low-step and lightweight settings. Project page: https://p458732.github.io/VeCoR_Project_Page/

</details>


### [249] [CLASH: A Benchmark for Cross-Modal Contradiction Detection](https://arxiv.org/abs/2511.19199)
*Teodora Popordanoska,Jiameng Li,Matthew B. Blaschko*

Main category: cs.CV

TL;DR: CLASH是一个用于多模态矛盾检测的新基准，包含COCO图像与包含对象级或属性级矛盾的矛盾描述配对，评估模型识别跨模态冲突的能力。


<details>
  <summary>Details</summary>
Motivation: 现实世界中多模态输入经常存在矛盾，但现有基准假设输入一致性，无法评估跨模态矛盾检测这一防止幻觉和确保可靠性的基本能力。

Method: 引入CLASH基准，包含经过自动化质量检查筛选的广泛微调集和较小的人工验证诊断集，采用多选和开放式格式评估针对性问题。

Result: 对最先进模型的分析显示其在识别跨模态冲突方面存在显著局限性，暴露出系统性模态偏差和类别特定弱点。

Conclusion: 在CLASH上进行针对性微调可显著增强冲突检测能力，为解决多模态矛盾检测问题提供了有效方法。

Abstract: Contradictory multimodal inputs are common in real-world settings, yet existing benchmarks typically assume input consistency and fail to evaluate cross-modal contradiction detection - a fundamental capability for preventing hallucinations and ensuring reliability. We introduce CLASH, a novel benchmark for multimodal contradiction detection, featuring COCO images paired with contradictory captions containing controlled object-level or attribute-level contradictions. The samples include targeted questions evaluated in both multiple-choice and open-ended formats. The benchmark provides an extensive fine-tuning set filtered through automated quality checks, alongside a smaller human-verified diagnostic set. Our analysis of state-of-the-art models reveals substantial limitations in recognizing cross-modal conflicts, exposing systematic modality biases and category-specific weaknesses. Furthermore, we empirically demonstrate that targeted fine-tuning on CLASH substantially enhances conflict detection capabilities.

</details>


### [250] [Leveraging Adversarial Learning for Pathological Fidelity in Virtual Staining](https://arxiv.org/abs/2511.18946)
*José Teixeira,Pascal Klöckner,Diana Montezuma,Melis Erdal Cesur,João Fraga,Hugo M. Horlings,Jaime S. Cardoso,Sara P. Oliveira*

Main category: cs.CV

TL;DR: 本文提出CSSP2P GAN模型用于虚拟染色，通过对抗性损失优化和专家盲评验证，在病理图像质量上优于现有方法，并揭示了当前评估指标的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统免疫组化染色成本高、耗时长，虚拟染色作为替代方案具有潜力。但现有研究忽略对抗性损失的影响，且使用SSIM/PSNR等不鲁棒的评估指标。

Method: 开发CSSP2P GAN模型，研究对抗性损失对虚拟染色质量的影响，采用病理专家盲评进行验证。

Result: CSSP2P GAN在病理保真度上表现优异，对抗性损失对图像质量至关重要，模型性能优于领域内参考工作。

Conclusion: 对抗性损失在虚拟染色中起关键作用，当前评估指标存在局限，CSSP2P GAN通过专家验证展现了优越性能。

Abstract: In addition to evaluating tumor morphology using H&E staining, immunohistochemistry is used to assess the presence of specific proteins within the tissue. However, this is a costly and labor-intensive technique, for which virtual staining, as an image-to-image translation task, offers a promising alternative. Although recent, this is an emerging field of research with 64% of published studies just in 2024. Most studies use publicly available datasets of H&E-IHC pairs from consecutive tissue sections. Recognizing the training challenges, many authors develop complex virtual staining models based on conditional Generative Adversarial Networks, but ignore the impact of adversarial loss on the quality of virtual staining. Furthermore, overlooking the issues of model evaluation, they claim improved performance based on metrics such as SSIM and PSNR, which are not sufficiently robust to evaluate the quality of virtually stained images. In this paper, we developed CSSP2P GAN, which we demonstrate to achieve heightened pathological fidelity through a blind pathological expert evaluation. Furthermore, while iteratively developing our model, we study the impact of the adversarial loss and demonstrate its crucial role in the quality of virtually stained images. Finally, while comparing our model with reference works in the field, we underscore the limitations of the currently used evaluation metrics and demonstrate the superior performance of CSSP2P GAN.

</details>


### [251] [Chain-of-Visual-Thought: Teaching VLMs to See and Think Better with Continuous Visual Tokens](https://arxiv.org/abs/2511.19418)
*Yiming Qin,Bomin Wei,Jiaxin Ge,Konstantinos Kallidromitis,Stephanie Fu,Trevor Darrell,Xudong Wang*

Main category: cs.CV

TL;DR: Chain-of-Visual-Thought (COVT) 是一个框架，使视觉语言模型能够通过连续视觉令牌进行推理，提升密集视觉感知能力，在多个基准测试中性能提升3%-16%。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在语言空间推理表现出色，但在需要密集视觉感知的任务（如空间推理和几何意识）上存在局限，因为缺乏捕捉空间维度密集视觉信息的机制。

Method: COVT框架通过约20个令牌的紧凑预算，从轻量级视觉专家中提取知识，捕捉2D外观、3D几何、空间布局和边缘结构等互补属性。训练时模型自回归预测视觉令牌以重建密集监督信号；推理时直接在连续视觉令牌空间进行推理。

Result: 在超过十个不同的感知基准测试中，将COVT集成到Qwen2.5-VL和LLaVA等强视觉语言模型中，性能一致提升3%-16%。

Conclusion: 紧凑的连续视觉思考能够实现更精确、有依据和可解释的多模态智能。

Abstract: Vision-Language Models (VLMs) excel at reasoning in linguistic space but struggle with perceptual understanding that requires dense visual perception, e.g., spatial reasoning and geometric awareness. This limitation stems from the fact that current VLMs have limited mechanisms to capture dense visual information across spatial dimensions. We introduce Chain-of-Visual-Thought (COVT), a framework that enables VLMs to reason not only in words but also through continuous visual tokens-compact latent representations that encode rich perceptual cues. Within a small budget of roughly 20 tokens, COVT distills knowledge from lightweight vision experts, capturing complementary properties such as 2D appearance, 3D geometry, spatial layout, and edge structure. During training, the VLM with COVT autoregressively predicts these visual tokens to reconstruct dense supervision signals (e.g., depth, segmentation, edges, and DINO features). At inference, the model reasons directly in the continuous visual token space, preserving efficiency while optionally decoding dense predictions for interpretability. Evaluated across more than ten diverse perception benchmarks, including CV-Bench, MMVP, RealWorldQA, MMStar, WorldMedQA, and HRBench, integrating COVT into strong VLMs such as Qwen2.5-VL and LLaVA consistently improves performance by 3% to 16% and demonstrates that compact continuous visual thinking enables more precise, grounded, and interpretable multimodal intelligence.

</details>


### [252] [Eevee: Towards Close-up High-resolution Video-based Virtual Try-on](https://arxiv.org/abs/2511.18957)
*Jianhao Zeng,Yancheng Bai,Ruidong Chen,Xuanpu Zhang,Lei Sun,Dongyang Jin,Ryan Xu,Nannan Zhang,Dan Song,Xiangxiang Chu*

Main category: cs.CV

TL;DR: 该论文提出了一个高分辨率视频虚拟试穿数据集，解决了现有方法在纹理细节捕捉和特写镜头生成方面的局限性，并提出了新的服装一致性评估指标VGID。


<details>
  <summary>Details</summary>
Motivation: 当前视频虚拟试穿技术存在两个关键限制：一是依赖单一服装图像输入导致纹理细节捕捉不准确，二是现有方法只关注全身镜头生成，忽视了商业对特写镜头的需求。

Method: 构建包含高保真图像、详细特写和文本描述的高分辨率数据集，同时包含全身和特写试穿视频；提出VGID指标来量化服装纹理和结构的保持程度。

Result: 实验表明，利用该数据集的详细图像，现有视频生成模型能够提取并整合纹理特征，显著提升虚拟试穿结果的真实感和细节保真度；基准测试有效识别了当前方法的纹理和结构保持问题。

Conclusion: 该数据集和评估指标为视频虚拟试穿技术提供了更全面的解决方案，满足了商业应用中对高质量特写镜头的需求，推动了该领域的实用化发展。

Abstract: Video virtual try-on technology provides a cost-effective solution for creating marketing videos in fashion e-commerce. However, its practical adoption is hindered by two critical limitations. First, the reliance on a single garment image as input in current virtual try-on datasets limits the accurate capture of realistic texture details. Second, most existing methods focus solely on generating full-shot virtual try-on videos, neglecting the business's demand for videos that also provide detailed close-ups. To address these challenges, we introduce a high-resolution dataset for video-based virtual try-on. This dataset offers two key features. First, it provides more detailed information on the garments, which includes high-fidelity images with detailed close-ups and textual descriptions; Second, it uniquely includes full-shot and close-up try-on videos of real human models. Furthermore, accurately assessing consistency becomes significantly more critical for the close-up videos, which demand high-fidelity preservation of garment details. To facilitate such fine-grained evaluation, we propose a new garment consistency metric VGID (Video Garment Inception Distance) that quantifies the preservation of both texture and structure. Our experiments validate these contributions. We demonstrate that by utilizing the detailed images from our dataset, existing video generation models can extract and incorporate texture features, significantly enhancing the realism and detail fidelity of virtual try-on results. Furthermore, we conduct a comprehensive benchmark of recent models. The benchmark effectively identifies the texture and structural preservation problems among current methods.

</details>


### [253] [Breaking the Likelihood-Quality Trade-off in Diffusion Models by Merging Pretrained Experts](https://arxiv.org/abs/2511.19434)
*Yasin Esfandiari,Stefan Bauer,Sebastian U. Stich,Andrea Dittadi*

Main category: cs.CV

TL;DR: 提出了一种简单的即插即用采样方法，通过在高噪声水平使用图像质量专家，在低噪声水平使用似然专家，来打破扩散模型中似然与图像质量的权衡。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像生成中存在感知样本质量与数据似然之间的权衡：强调高噪声去噪步骤的训练目标能产生真实图像但似然较差，而面向似然的训练会过度加权低噪声步骤并损害视觉保真度。

Method: 引入一种简单的即插即用采样方法，结合两个预训练的扩散专家，沿着去噪轨迹在它们之间切换。具体来说，在高噪声水平应用图像质量专家来塑造全局结构，然后在低噪声水平切换到似然专家来优化像素统计。

Result: 在CIFAR-10和ImageNet32上，合并模型始终匹配或优于其基础组件，相对于每个单独专家，改善或保持了似然和样本质量。

Conclusion: 跨噪声水平的专家切换是打破图像扩散模型中似然-质量权衡的有效方法。

Abstract: Diffusion models for image generation often exhibit a trade-off between perceptual sample quality and data likelihood: training objectives emphasizing high-noise denoising steps yield realistic images but poor likelihoods, whereas likelihood-oriented training overweights low-noise steps and harms visual fidelity. We introduce a simple plug-and-play sampling method that combines two pretrained diffusion experts by switching between them along the denoising trajectory. Specifically, we apply an image-quality expert at high noise levels to shape global structure, then switch to a likelihood expert at low noise levels to refine pixel statistics. The approach requires no retraining or fine-tuning -- only the choice of an intermediate switching step. On CIFAR-10 and ImageNet32, the merged model consistently matches or outperforms its base components, improving or preserving both likelihood and sample quality relative to each expert alone. These results demonstrate that expert switching across noise levels is an effective way to break the likelihood-quality trade-off in image diffusion models.

</details>


### [254] [CataractCompDetect: Intraoperative Complication Detection in Cataract Surgery](https://arxiv.org/abs/2511.18968)
*Bhuvan Sachdeva,Sneha Kumari,Rudransh Agarwal,Shalaka Kumaraswamy,Niharika Singri Prasad,Simon Mueller,Raphael Lechtenboehmer,Maximilian W. M. Wintergerst,Thomas Schultz,Kaushik Murali,Mohit Jain*

Main category: cs.CV

TL;DR: 提出CataractCompDetect框架，结合相位感知定位、SAM 2跟踪、并发症风险评分和视觉语言推理，用于白内障手术并发症的自动检测，在CataComp数据集上达到70.63%的平均F1分数


<details>
  <summary>Details</summary>
Motivation: 白内障手术是全球最常见的手术之一，但术中并发症如虹膜脱垂、后囊膜破裂和玻璃体丢失仍是导致不良预后的主要原因。自动检测这些事件可实现早期预警系统和客观培训反馈

Method: CataractCompDetect框架包含：1）相位感知定位；2）SAM 2基跟踪；3）并发症特定风险评分；4）视觉语言推理进行最终分类。构建了首个白内障手术并发症数据集CataComp，包含53台手术

Result: 在CataComp数据集上，CataractCompDetect平均F1分数为70.63%，各并发症检测性能：虹膜脱垂81.8%、后囊膜破裂60.87%、玻璃体丢失69.23%

Conclusion: 结果表明将结构化手术先验知识与视觉语言推理相结合，对于识别罕见但高影响的术中事件具有重要价值。数据集和代码将在接受后公开

Abstract: Cataract surgery is one of the most commonly performed surgeries worldwide, yet intraoperative complications such as iris prolapse, posterior capsule rupture (PCR), and vitreous loss remain major causes of adverse outcomes. Automated detection of such events could enable early warning systems and objective training feedback. In this work, we propose CataractCompDetect, a complication detection framework that combines phase-aware localization, SAM 2-based tracking, complication-specific risk scoring, and vision-language reasoning for final classification. To validate CataractCompDetect, we curate CataComp, the first cataract surgery video dataset annotated for intraoperative complications, comprising 53 surgeries, including 23 with clinical complications. On CataComp, CataractCompDetect achieves an average F1 score of 70.63%, with per-complication performance of 81.8% (Iris Prolapse), 60.87% (PCR), and 69.23% (Vitreous Loss). These results highlight the value of combining structured surgical priors with vision-language reasoning for recognizing rare but high-impact intraoperative events. Our dataset and code will be publicly released upon acceptance.

</details>


### [255] [VDC-Agent: When Video Detailed Captioners Evolve Themselves via Agentic Self-Reflection](https://arxiv.org/abs/2511.19436)
*Qiang Wang,Xinyuan Gao,SongLin Dong,Jizhou Han,Jiangyang Li,Yuhang He,Yihong Gong*

Main category: cs.CV

TL;DR: VDC-Agent是一个自进化的视频详细描述框架，无需人工标注或大型教师模型，通过闭环生成、评分和提示优化，在VDC基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决视频详细描述任务中对人工标注和大型教师模型的依赖问题，实现完全自动化的高质量视频描述生成。

Method: 采用自进化框架形成闭环：描述生成→原则指导评分→提示优化；当质量下降时启用自反思路径修正；将轨迹转换为偏好对，通过课程式直接偏好优化进行微调。

Result: 在VDC基准测试中获得49.08%平均准确率和2.50分，超越专用视频描述器，相比基础模型提升+5.13%准确率和+0.27分。

Conclusion: VDC-Agent证明了无需人工标注即可实现SOTA视频描述性能的有效性，为视频理解任务提供了新的自动化解决方案。

Abstract: We present VDC-Agent, a self-evolving framework for Video Detailed Captioning that requires neither human annotations nor larger teacher models. The agent forms a closed loop of caption generation, principle-guided scoring (score and textual suggestions), and prompt refinement. When caption quality regresses, a self-reflection path leverages the previous chain-of-thought to amend the update. Running this process on unlabeled videos produces trajectories of (caption, score) pairs. We convert the trajectories into preference tuples and filter out samples with JSON parsing errors, resulting in VDC-Agent-19K, which contains 18,886 automatically constructed pairs. We then fine-tune the base MLLM on this dataset using an easy-to-hard curriculum direct preference optimization. Built on Qwen2.5-VL-7B-Instruct, our VDC-Agent-7B attains state-of-the-art performance on the VDC benchmark with 49.08% average accuracy and 2.50 score, surpassing specialized video captioners and improving over the base model by +5.13% accuracy and +0.27 score at similar inference cost.

</details>


### [256] [Peregrine: One-Shot Fine-Tuning for FHE Inference of General Deep CNNs](https://arxiv.org/abs/2511.18976)
*Huaming Ling,Ying Wang,Si Chen,Junfeng Fan*

Main category: cs.CV

TL;DR: 本文提出了一种将预训练CNN适配到全同态加密（FHE）推理的方法，包括单阶段微调策略和广义交错打包方案，解决了非线性激活函数近似和密文容量限制两大挑战。


<details>
  <summary>Details</summary>
Motivation: 适应通用深度CNN进行FHE推理面临两个基本挑战：用低阶多项式近似ReLU等非线性激活函数时最小化精度损失，以及克服高分辨率图像处理中的密文容量限制。

Method: 提出单阶段微调策略直接转换预训练CNN为FHE友好形式，使用低阶多项式；设计广义交错打包方案兼容任意空间分辨率的特征图，并配套保持GIP形式加密的同态算子。

Result: 在CIFAR-10、ImageNet和MS COCO上的实验表明，通过SFT策略获得的FHE友好CNN达到与使用ReLU或SiLU激活的基线相当的精度，并首次实现了基于FHE的YOLO架构目标检测。

Conclusion: 这些进展使得跨不同CNN架构的高效端到端FHE推理成为可能，为安全计算环境下的深度学习应用提供了可行方案。

Abstract: We address two fundamental challenges in adapting general deep CNNs for FHE-based inference: approximating non-linear activations such as ReLU with low-degree polynomials while minimizing accuracy degradation, and overcoming the ciphertext capacity barrier that constrains high-resolution image processing on FHE inference. Our contributions are twofold: (1) a single-stage fine-tuning (SFT) strategy that directly converts pre-trained CNNs into FHE-friendly forms using low-degree polynomials, achieving competitive accuracy with minimal training overhead; and (2) a generalized interleaved packing (GIP) scheme that is compatible with feature maps of virtually arbitrary spatial resolutions, accompanied by a suite of carefully designed homomorphic operators that preserve the GIP-form encryption throughout computation. These advances enable efficient, end-to-end FHE inference across diverse CNN architectures. Experiments on CIFAR-10, ImageNet, and MS COCO demonstrate that the FHE-friendly CNNs obtained via our SFT strategy achieve accuracy comparable to baselines using ReLU or SiLU activations. Moreover, this work presents the first demonstration of FHE-based inference for YOLO architectures in object detection leveraging low-degree polynomial activations.

</details>


### [257] [Zero-shot segmentation of skin tumors in whole-slide images with vision-language foundation models](https://arxiv.org/abs/2511.18978)
*Santiago Moreno,Pablo Meseguer,Rocío del Amor,Valery Naranjo*

Main category: cs.CV

TL;DR: 提出了ZEUS框架，利用视觉语言基础模型进行零样本全切片图像分割，显著减少标注负担并实现可扩展的肿瘤分割。


<details>
  <summary>Details</summary>
Motivation: 皮肤肿瘤活检注释面临形态变异大、组织学模式重叠、良恶性病变区分细微等挑战，现有VLM方法难以在千兆像素全切片图像上实现细粒度分割。

Method: ZEUS框架通过将WSI分割为重叠补丁，提取视觉嵌入，与类别特定文本提示集合计算余弦相似度，生成高分辨率肿瘤分割掩码。

Result: 在两个内部数据集（原发性梭形细胞肿瘤和皮肤转移瘤）上表现出竞争力，验证了提示设计、领域偏移和机构变异对VLM性能的影响。

Conclusion: ZEUS为下游诊断工作流程提供了可扩展、可解释的肿瘤分割方案，显著降低了标注负担。

Abstract: Accurate annotation of cutaneous neoplasm biopsies represents a major challenge due to their wide morphological variability, overlapping histological patterns, and the subtle distinctions between benign and malignant lesions. Vision-language foundation models (VLMs), pre-trained on paired image-text corpora, learn joint representations that bridge visual features and diagnostic terminology, enabling zero-shot localization and classification of tissue regions without pixel-level labels. However, most existing VLM applications in histopathology remain limited to slide-level tasks or rely on coarse interactive prompts, and they struggle to produce fine-grained segmentations across gigapixel whole-slide images (WSIs). In this work, we introduce a zero-shot visual-language segmentation pipeline for whole-slide images (ZEUS), a fully automated, zero-shot segmentation framework that leverages class-specific textual prompt ensembles and frozen VLM encoders to generate high-resolution tumor masks in WSIs. By partitioning each WSI into overlapping patches, extracting visual embeddings, and computing cosine similarities against text prompts, we generate a final segmentation mask. We demonstrate competitive performance on two in-house datasets, primary spindle cell neoplasms and cutaneous metastases, highlighting the influence of prompt design, domain shifts, and institutional variability in VLMs for histopathology. ZEUS markedly reduces annotation burden while offering scalable, explainable tumor delineation for downstream diagnostic workflows.

</details>


### [258] [UMCL: Unimodal-generated Multimodal Contrastive Learning for Cross-compression-rate Deepfake Detection](https://arxiv.org/abs/2511.18983)
*Ching-Yi Lai,Chih-Yu Jian,Pei-Cheng Chuang,Chia-Ming Lee,Chih-Chung Hsu,Chiou-Ting Hsu,Chia-Wen Lin*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的单模态生成多模态对比学习（UMCL）框架，用于解决社交媒体平台中不同压缩率对深度伪造检测模型泛化性和可靠性的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造检测方法面临关键限制：单模态方法在社交媒体流数据压缩下特征退化，而多模态方法需要昂贵的数据收集和标注，且在真实场景中模态质量或可访问性不一致。

Method: 通过将单一视觉模态转换为三个互补特征（压缩鲁棒的rPPG信号、时间地标动态和预训练视觉语言模型的语义嵌入），采用亲和力驱动的语义对齐（ASA）策略建模模态间关系，并通过跨质量相似性学习（CQSL）策略增强跨压缩率的特征鲁棒性。

Result: 大量实验表明，该方法在各种压缩率和操作类型下均取得优异性能，为鲁棒深度伪造检测设立了新基准。即使在单个特征退化时也能保持高检测精度，并通过显式对齐提供特征关系的可解释性洞察。

Conclusion: UMCL框架通过单模态生成多模态特征和对比学习策略，有效解决了深度伪造检测在社交媒体压缩环境下的泛化问题，实现了鲁棒且可解释的检测性能。

Abstract: In deepfake detection, the varying degrees of compression employed by social media platforms pose significant challenges for model generalization and reliability. Although existing methods have progressed from single-modal to multimodal approaches, they face critical limitations: single-modal methods struggle with feature degradation under data compression in social media streaming, while multimodal approaches require expensive data collection and labeling and suffer from inconsistent modal quality or accessibility in real-world scenarios. To address these challenges, we propose a novel Unimodal-generated Multimodal Contrastive Learning (UMCL) framework for robust cross-compression-rate (CCR) deepfake detection. In the training stage, our approach transforms a single visual modality into three complementary features: compression-robust rPPG signals, temporal landmark dynamics, and semantic embeddings from pre-trained vision-language models. These features are explicitly aligned through an affinity-driven semantic alignment (ASA) strategy, which models inter-modal relationships through affinity matrices and optimizes their consistency through contrastive learning. Subsequently, our cross-quality similarity learning (CQSL) strategy enhances feature robustness across compression rates. Extensive experiments demonstrate that our method achieves superior performance across various compression rates and manipulation types, establishing a new benchmark for robust deepfake detection. Notably, our approach maintains high detection accuracy even when individual features degrade, while providing interpretable insights into feature relationships through explicit alignment.

</details>


### [259] [Rethinking Plant Disease Diagnosis: Bridging the Academic-Practical Gap with Vision Transformers and Zero-Shot Learning](https://arxiv.org/abs/2511.18989)
*Wassim Benabbas,Mohammed Brahimi,Samir Akhrouf,Bilal Fortas*

Main category: cs.CV

TL;DR: 本文研究了注意力架构和零样本学习在植物病害分类中连接学术数据集与真实农业条件的能力，发现CLIP模型通过自然语言描述直接分类病害，具有强大的适应性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要依赖PlantVillage数据集，该数据集包含背景整洁的植物图像，虽然模型在该数据集上准确率高，但在真实田间图像上泛化能力差，存在学术研究与实际应用之间的差距。

Method: 评估了三种模型类别：卷积神经网络（CNNs）、视觉变换器（Vision Transformers）和基于对比语言-图像预训练（CLIP）的零样本模型。

Result: CNNs在领域转移下鲁棒性有限，Vision Transformers通过捕捉全局上下文特征表现出更强的泛化能力，而CLIP模型无需任务特定训练即可直接从自然语言描述分类病害。

Conclusion: 零样本学习作为植物健康诊断的实用且可扩展的领域适应策略具有巨大潜力。

Abstract: Recent advances in deep learning have enabled significant progress in plant disease classification using leaf images. Much of the existing research in this field has relied on the PlantVillage dataset, which consists of well-centered plant images captured against uniform, uncluttered backgrounds. Although models trained on this dataset achieve high accuracy, they often fail to generalize to real-world field images, such as those submitted by farmers to plant diagnostic systems. This has created a significant gap between published studies and practical application requirements, highlighting the necessity of investigating and addressing this issue. In this study, we investigate whether attention-based architectures and zero-shot learning approaches can bridge the gap between curated academic datasets and real-world agricultural conditions in plant disease classification. We evaluate three model categories: Convolutional Neural Networks (CNNs), Vision Transformers, and Contrastive Language-Image Pre-training (CLIP)-based zero-shot models. While CNNs exhibit limited robustness under domain shift, Vision Transformers demonstrate stronger generalization by capturing global contextual features. Most notably, CLIP models classify diseases directly from natural language descriptions without any task-specific training, offering strong adaptability and interpretability. These findings highlight the potential of zero-shot learning as a practical and scalable domain adaptation strategy for plant health diagnosis in diverse field environments.

</details>


### [260] [View-Consistent Diffusion Representations for 3D-Consistent Video Generation](https://arxiv.org/abs/2511.18991)
*Duolikun Danier,Ge Gao,Steven McDonagh,Changjian Li,Hakan Bilen,Oisin Mac Aodha*

Main category: cs.CV

TL;DR: ViCoDR通过改善视频扩散模型的多视角一致性表示，解决现有视频生成中的3D不一致性问题，显著提升生成视频的3D一致性。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成模型存在3D不一致性导致的视觉伪影问题，如物体和结构在相机视角变化时发生变形，影响用户体验和仿真保真度。

Method: 提出ViCoDR方法，通过学习多视角一致的扩散表示来改进视频模型的3D一致性，基于对多个相机控制视频扩散模型的详细分析。

Result: 在相机控制的图像到视频、文本到视频和多视角生成模型上评估ViCoDR，显示生成视频的3D一致性得到显著提升。

Conclusion: 改善视频扩散模型的多视角一致性表示能有效提高生成视频的3D一致性，为解决当前视频生成中的视觉伪影问题提供了有效方案。

Abstract: Video generation models have made significant progress in generating realistic content, enabling applications in simulation, gaming, and film making. However, current generated videos still contain visual artifacts arising from 3D inconsistencies, e.g., objects and structures deforming under changes in camera pose, which can undermine user experience and simulation fidelity. Motivated by recent findings on representation alignment for diffusion models, we hypothesize that improving the multi-view consistency of video diffusion representations will yield more 3D-consistent video generation. Through detailed analysis on multiple recent camera-controlled video diffusion models we reveal strong correlations between 3D-consistent representations and videos. We also propose ViCoDR, a new approach for improving the 3D consistency of video models by learning multi-view consistent diffusion representations. We evaluate ViCoDR on camera controlled image-to-video, text-to-video, and multi-view generation models, demonstrating significant improvements in the 3D consistency of the generated videos. Project page: https://danier97.github.io/ViCoDR.

</details>


### [261] [AuViRe: Audio-visual Speech Representation Reconstruction for Deepfake Temporal Localization](https://arxiv.org/abs/2511.18993)
*Christos Koutlis,Symeon Papadopoulos*

Main category: cs.CV

TL;DR: 提出AuViRe方法，通过音频-视觉语音表示重建来定位深度伪造视频的时间位置，在多个数据集上超越现有技术。


<details>
  <summary>Details</summary>
Motivation: 随着合成音视频内容的快速发展，确保数字媒体完整性变得至关重要，需要有效检测恶意操纵内容。

Method: 基于音频-视觉语音表示重建，从一个模态重建另一个模态的语音表示，利用伪造视频段中跨模态重建的显著差异作为判别线索。

Result: 在LAV-DF数据集上AP@0.95提升8.9，在AV-Deepfake1M数据集上AP@0.5提升9.6，在真实场景实验中AUC提升5.1。

Conclusion: AuViRe方法通过跨模态重建差异有效定位深度伪造时间位置，在多个基准测试中显著优于现有技术。

Abstract: With the rapid advancement of sophisticated synthetic audio-visual content, e.g., for subtle malicious manipulations, ensuring the integrity of digital media has become paramount. This work presents a novel approach to temporal localization of deepfakes by leveraging Audio-Visual Speech Representation Reconstruction (AuViRe). Specifically, our approach reconstructs speech representations from one modality (e.g., lip movements) based on the other (e.g., audio waveform). Cross-modal reconstruction is significantly more challenging in manipulated video segments, leading to amplified discrepancies, thereby providing robust discriminative cues for precise temporal forgery localization. AuViRe outperforms the state of the art by +8.9 AP@0.95 on LAV-DF, +9.6 AP@0.5 on AV-Deepfake1M, and +5.1 AUC on an in-the-wild experiment. Code available at https://github.com/mever-team/auvire.

</details>


### [262] [A Self-Conditioned Representation Guided Diffusion Model for Realistic Text-to-LiDAR Scene Generation](https://arxiv.org/abs/2511.19004)
*Wentao Qu,Guofeng Mei,Yang Wu,Yongshun Gong,Xiaoshui Huang,Liang Xiao*

Main category: cs.CV

TL;DR: 提出T2LDM文本到LiDAR扩散模型，通过自条件表示引导解决文本-LiDAR数据稀缺和低质量文本描述导致的生成质量下降问题，实现高质量可控的3D场景生成。


<details>
  <summary>Details</summary>
Motivation: 文本-LiDAR数据对稀缺导致训练先验不足，生成场景过于平滑；低质量文本描述会降低生成质量和可控性。

Method: 采用自条件表示引导(SCRG)在训练中对去噪网络提供软监督，推理时解耦；构建T2nuScenes基准和可控性指标；设计方向位置先验缓解街道失真；通过条件编码器支持多条件任务。

Result: 在无条件和条件生成任务中超越现有方法，达到最先进的场景生成效果。

Conclusion: T2LDM能够感知丰富的几何结构，生成细节丰富的场景，为文本到LiDAR生成提供了实用范例和见解。

Abstract: Text-to-LiDAR generation can customize 3D data with rich structures and diverse scenes for downstream tasks. However, the scarcity of Text-LiDAR pairs often causes insufficient training priors, generating overly smooth 3D scenes. Moreover, low-quality text descriptions may degrade generation quality and controllability. In this paper, we propose a Text-to-LiDAR Diffusion Model for scene generation, named T2LDM, with a Self-Conditioned Representation Guidance (SCRG). Specifically, SCRG, by aligning to the real representations, provides the soft supervision with reconstruction details for the Denoising Network (DN) in training, while decoupled in inference. In this way, T2LDM can perceive rich geometric structures from data distribution, generating detailed objects in scenes. Meanwhile, we construct a content-composable Text-LiDAR benchmark, T2nuScenes, along with a controllability metric. Based on this, we analyze the effects of different text prompts for LiDAR generation quality and controllability, providing practical prompt paradigms and insights. Furthermore, a directional position prior is designed to mitigate street distortion, further improving scene fidelity. Additionally, by learning a conditional encoder via frozen DN, T2LDM can support multiple conditional tasks, including Sparse-to-Dense, Dense-to-Sparse, and Semantic-to-LiDAR generation. Extensive experiments in unconditional and conditional generation demonstrate that T2LDM outperforms existing methods, achieving state-of-the-art scene generation.

</details>


### [263] [Dynamic Granularity Matters: Rethinking Vision Transformers Beyond Fixed Patch Splitting](https://arxiv.org/abs/2511.19021)
*Qiyang Yu,Yu Fang,Tianrui Li,Xuemei Cao,Yan Chen,Jianghao Li,Fan Min*

Main category: cs.CV

TL;DR: Grc-ViT是一个动态粗到细的视觉Transformer框架，通过自适应调整视觉粒度来解决ViT在细粒度局部细节表示上的不足，在保持计算效率的同时提升细粒度识别能力。


<details>
  <summary>Details</summary>
Motivation: 现有ViT模型在捕捉全局依赖方面表现良好，但在表示细粒度局部细节时效率不高。现有的多尺度方法依赖固定补丁大小并引入冗余计算，需要更高效的解决方案。

Method: 提出Grc-ViT框架，包含两个关键模块：粗粒度评估模块（使用边缘密度、熵和频域线索评估视觉复杂度）和细粒度优化模块（根据选定粒度优化注意力计算）。通过两个可学习参数α和β端到端优化全局推理和局部感知的平衡。

Result: 综合评估表明，Grc-ViT在提升细粒度判别能力的同时，在准确性和计算效率之间实现了优越的平衡。

Conclusion: Grc-ViT通过动态粒度调整机制有效解决了ViT在细粒度表示上的局限性，为视觉Transformer提供了更高效和精确的特征学习方案。

Abstract: Vision Transformers (ViTs) have demonstrated strong capabilities in capturing global dependencies but often struggle to efficiently represent fine-grained local details. Existing multi-scale approaches alleviate this issue by integrating hierarchical or hybrid features; however, they rely on fixed patch sizes and introduce redundant computation. To address these limitations, we propose Granularity-driven Vision Transformer (Grc-ViT), a dynamic coarse-to-fine framework that adaptively adjusts visual granularity based on image complexity. It comprises two key stages: (1) Coarse Granularity Evaluation module, which assesses visual complexity using edge density, entropy, and frequency-domain cues to estimate suitable patch and window sizes; (2) Fine-grained Refinement module, which refines attention computation according to the selected granularity, enabling efficient and precise feature learning. Two learnable parameters, α and \b{eta}, are optimized end-to-end to balance global reasoning and local perception. Comprehensive evaluations demonstrate that Grc-ViT enhances fine-grained discrimination while achieving a superior trade-off between accuracy and computational efficiency.

</details>


### [264] [Life-IQA: Boosting Blind Image Quality Assessment through GCN-enhanced Layer Interaction and MoE-based Feature Decoupling](https://arxiv.org/abs/2511.19024)
*Long Tang,Guoquan Zhen,Jie Hao,Jianbo Zhang,Huiyu Duan,Liang Yuan,Guangtao Zhai*

Main category: cs.CV

TL;DR: 该论文提出了Life-IQA框架，通过GCN增强的层交互和MoE特征解耦来解决盲图像质量评估中特征贡献不均和解码架构不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有BIQA方法在融合浅层和深层特征时忽视了它们对质量预测的不等贡献，且质量解码架构研究不足。

Method: 采用GCN增强的层交互模块（以最深特征为查询，次深特征为键值进行交叉注意力）和MoE特征解耦模块（通过专家网络解耦不同失真类型或质量维度的特征）。

Result: 在多个BIQA基准测试中达到最先进性能，并在准确性和成本之间取得更好平衡。

Conclusion: Life-IQA框架有效提升了盲图像质量评估的性能，代码已开源。

Abstract: Blind image quality assessment (BIQA) plays a crucial role in evaluating and optimizing visual experience. Most existing BIQA approaches fuse shallow and deep features extracted from backbone networks, while overlooking the unequal contributions to quality prediction. Moreover, while various vision encoder backbones are widely adopted in BIQA, the effective quality decoding architectures remain underexplored. To address these limitations, this paper investigates the contributions of shallow and deep features to BIQA, and proposes a effective quality feature decoding framework via GCN-enhanced \underline{l}ayer\underline{i}nteraction and MoE-based \underline{f}eature d\underline{e}coupling, termed \textbf{(Life-IQA)}. Specifically, the GCN-enhanced layer interaction module utilizes the GCN-enhanced deepest-layer features as query and the penultimate-layer features as key, value, then performs cross-attention to achieve feature interaction. Moreover, a MoE-based feature decoupling module is proposed to decouple fused representations though different experts specialized for specific distortion types or quality dimensions. Extensive experiments demonstrate that Life-IQA shows more favorable balance between accuracy and cost than a vanilla Transformer decoder and achieves state-of-the-art performance on multiple BIQA benchmarks.The code is available at: \href{https://github.com/TANGLONG2/Life-IQA/tree/main}{\texttt{Life-IQA}}.

</details>


### [265] [Benchmarking Corruption Robustness of LVLMs: A Discriminative Benchmark and Robustness Alignment Metric](https://arxiv.org/abs/2511.19032)
*Xiangjie Sui,Songyang Li,Hanwei Zhu,Baoliang Chen,Yuming Fang,Xin Sun*

Main category: cs.CV

TL;DR: 论文提出了Bench-C基准和RAS指标，用于评估大视觉语言模型在视觉损坏下的鲁棒性，解决了现有评估方法中样本区分度不足和传统准确率指标无法捕捉预测结构退化的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的大视觉语言模型评估方法存在两个主要局限：1）当前数据集中低区分度样本占主导地位，掩盖了模型间的真实鲁棒性差距；2）传统基于准确率的指标无法捕捉底层预测结构的退化。

Method: 提出Bench-C基准，通过考虑损坏下预测不一致性和语义多样性的选择策略来筛选高区分度样本；提出RAS指标，通过预测不确定性和校准对齐的变化来测量logit级预测结构的退化。

Result: 实验发现：1）模型在损坏下表现出不同的行为模式，如错误置信和犹豫；2）轻微损坏可能导致准确率略微提升，但整体预测结构仍在退化；3）通过将鲁棒性分解为破坏性和纠正性组件，可以揭示不同模型的失败和恢复模式。

Conclusion: Bench-C和RAS为评估LVLM在视觉损坏下的鲁棒性提供了更全面的框架，揭示了传统准确率指标无法捕捉的重要鲁棒性特征。

Abstract: Despite the remarkable reasoning abilities of large vision-language models (LVLMs), their robustness under visual corruptions remains insufficiently studied. Existing evaluation paradigms exhibit two major limitations: 1) the dominance of low-discriminative samples in current datasets masks the real robustness gap between models; and 2) conventional accuracy-based metric fail to capture the degradation of the underlying prediction structure. To bridge these gaps, we introduce Bench-C, a comprehensive benchmark emphasizing discriminative samples for assessing corruption robustness, where a selection strategy is proposed to jointly consider the prediction inconsistency under corruption and the semantic diversity. Furthermore, we propose the Robustness Alignment Score (RAS), a unified metric that measures degradation in logit-level prediction structure by considering the shifts in prediction uncertainty and calibration alignment. Comprehensive experiments and analysis reveal several interesting findings: 1) model behaviors exhibit distinguish patterns under corruptions, such as erroneous confidence and hesitation; 2) despite subtle corruption may lead to a slight accuracy gain, the overall prediction structure still degrades; 3) by decomposing corruption robustness into destructive and corrective components, the distinct failure and recovery patterns across models can be revealed.

</details>


### [266] [ReEXplore: Improving MLLMs for Embodied Exploration with Contextualized Retrospective Experience Replay](https://arxiv.org/abs/2511.19033)
*Gengyuan Zhang,Mingcong Ding,Jingpei Wu,Ruotong Liao,Volker Tresp*

Main category: cs.CV

TL;DR: ReEXplore提出了一种无需训练的框架，通过回顾性经验回放和分层边界选择来解决MLLM在具身探索中的局限性，显著提升了探索性能和导航效率


<details>
  <summary>Details</summary>
Motivation: 现有的MLLM具身探索方法存在三个问题：依赖过时的预训练知识、训练成本高昂、边界探索动作空间过大难以可靠决策

Method: 采用训练免费框架，包含回顾性经验回放（在推理时注入蒸馏的抽象经验）和分层边界选择（将边界排序分解为粗到细的决策）

Result: 在多个具身探索基准测试中，ReEXplore相比强基线MLLM方法实现了3倍的性能提升，在成功率和导航效率方面均有显著改善

Conclusion: 该方法实现了鲁棒、可追踪且高效的探索，为MLLM在具身智能体中的应用提供了新的解决方案

Abstract: Embodied exploration is a target-driven process that requires embodied agents to possess fine-grained perception and knowledge-enhanced decision making. While recent attempts leverage MLLMs for exploration due to their strong perceptual and reasoning abilities, we find that MLLM-based embodied agents remain suboptimal in exploring new environments: (i) they rely on profound but stale pre-trained knowledge, (ii) training-based approaches such as imitation learning or reinforcement learning are expensive for long-horizon tasks with sparse outcome rewards, and (iii) frontier-based exploration yields a large, visually nuanced action space that is difficult for MLLMs to make reliable decisions. We address these challenges with ReEXplore, a training-free framework that performs retrospective experience replay to inject distilled, abstract experience at inference time, and hierarchical frontier selection to decompose frontier ranking into coarse-to-fine decisions. Our approach enables robust, traceable, and efficient exploration. Across multiple embodied exploration benchmarks, ReEXplore yields great improvements over strong MLLM baselines, up to 3x higher performance in both success rate and in navigation efficiency under open-source backbones.

</details>


### [267] [CSD: Change Semantic Detection with only Semantic Change Masks for Damage Assessment in Conflict Zones](https://arxiv.org/abs/2511.19035)
*Kai Zhenga,Zhenkai Wu,Fupeng Wei,Miaolan Zhou,Kai Lie,Haitao Guo,Lei Ding,Wei Zhang,Hang-Cheng Dong*

Main category: cs.CV

TL;DR: 提出基于DINOv3预训练模型的多尺度交叉注意力差异孪生网络（MC-DiSNet），用于冲突地区语义变化检测（CSD）任务，并发布加沙变化数据集。


<details>
  <summary>Details</summary>
Motivation: 冲突地区损伤评估对人道主义援助和区域稳定至关重要，但传统语义变化检测需要大规模语义标注，实际应用中面临数据有限、标注困难等挑战。

Method: 使用DINOv3骨干网络提取双时相遥感图像特征，构建多尺度交叉注意力差异孪生网络，直接关注变化区域而非全图语义标注。

Result: 在加沙变化数据集和SECOND数据集上的实验表明，该方法能有效解决CSD任务，为冲突地区快速损伤评估提供实用方案。

Conclusion: 提出的CSD任务框架和MC-DiSNet方法在语义变化检测方面表现出色，为冲突地区损伤评估开辟了新途径。

Abstract: Accurately and swiftly assessing damage from conflicts is crucial for humanitarian aid and regional stability. In conflict zones, damaged zones often share similar architectural styles, with damage typically covering small areas and exhibiting blurred boundaries. These characteristics lead to limited data, annotation difficulties, and significant recognition challenges, including high intra-class similarity and ambiguous semantic changes. To address these issues, we introduce a pre-trained DINOv3 model and propose a multi-scale cross-attention difference siamese network (MC-DiSNet). The powerful visual representation capability of the DINOv3 backbone enables robust and rich feature extraction from bi-temporal remote sensing images. We also release a new Gaza-change dataset containing high-resolution satellite image pairs from 2023-2024 with pixel-level semantic change annotations. It is worth emphasizing that our annotations only include semantic pixels of changed areas. Unlike conventional semantic change detection (SCD), our approach eliminates the need for large-scale semantic annotations of bi-temporal images, instead focusing directly on the changed regions. We term this new task change semantic detection (CSD). The CSD task represents a direct extension of binary change detection (BCD). Due to the limited spatial extent of semantic regions, it presents greater challenges than traditional SCD tasks. We evaluated our method under the CSD framework on both the Gaza-Change and SECOND datasets. Experimental results demonstrate that our proposed approach effectively addresses the CSD task, and its outstanding performance paves the way for practical applications in rapid damage assessment across conflict zones.

</details>


### [268] [MedSAM3: Delving into Segment Anything with Medical Concepts](https://arxiv.org/abs/2511.19046)
*Anglin Liu,Rundong Xue,Xu R. Cao,Yifan Shen,Yi Lu,Xiang Li,Qianqian Chen,Jintai Chen*

Main category: cs.CV

TL;DR: MedSAM-3是基于SAM-3架构的医疗图像分割模型，通过文本提示实现医学概念分割，支持多种医学影像模态，性能优于现有专业模型。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像分割方法缺乏泛化能力，需要大量手动标注，难以适应新的临床应用场景。

Method: 在医学图像上微调SAM-3架构，结合语义概念标签，实现基于开放词汇文本描述的医学概念分割；引入MedSAM-3 Agent框架，集成多模态大语言模型进行复杂推理和迭代优化。

Result: 在X光、MRI、超声、CT和视频等多种医学影像模态上的实验表明，该方法显著优于现有专业模型和基础模型。

Conclusion: MedSAM-3提供了一个高效的文本提示医学分割解决方案，具有更好的泛化能力和临床应用价值。

Abstract: Medical image segmentation is fundamental for biomedical discovery. Existing methods lack generalizability and demand extensive, time-consuming manual annotation for new clinical application. Here, we propose MedSAM-3, a text promptable medical segmentation model for medical image and video segmentation. By fine-tuning the Segment Anything Model (SAM) 3 architecture on medical images paired with semantic conceptual labels, our MedSAM-3 enables medical Promptable Concept Segmentation (PCS), allowing precise targeting of anatomical structures via open-vocabulary text descriptions rather than solely geometric prompts. We further introduce the MedSAM-3 Agent, a framework that integrates Multimodal Large Language Models (MLLMs) to perform complex reasoning and iterative refinement in an agent-in-the-loop workflow. Comprehensive experiments across diverse medical imaging modalities, including X-ray, MRI, Ultrasound, CT, and video, demonstrate that our approach significantly outperforms existing specialist and foundation models. We will release our code and model at https://github.com/Joey-S-Liu/MedSAM3.

</details>


### [269] [Beyond Reward Margin: Rethinking and Resolving Likelihood Displacement in Diffusion Models via Video Generation](https://arxiv.org/abs/2511.19049)
*Ruojun Xu,Yu Kai,Xuhua Ren,Jiaxiang Cheng,Bing Ma,Tianxiang Zheng,Qinhlin Lu*

Main category: cs.CV

TL;DR: 本文提出Policy-Guided DPO (PG-DPO)方法，通过Adaptive Rejection Scaling (ARS)和Implicit Preference Regularization (IPR)解决扩散模型中DPO训练时的似然位移问题，提升视频生成任务中的偏好对齐效果。


<details>
  <summary>Details</summary>
Motivation: DPO在扩散模型中存在似然位移问题，即训练过程中被选样本的概率反而下降，影响生成质量。这一问题在视频生成任务中尤为突出，但现有研究主要关注自回归模型，扩散模型中的影响尚未充分探索。

Method: 首先对扩散框架下的DPO损失进行形式化分析，识别出两种失效模式：优化冲突（奖励边际小）和次优最大化（奖励边际大）。然后提出PG-DPO方法，结合ARS和IPR技术来缓解似然位移问题。

Result: 实验表明PG-DPO在定量指标和定性评估上均优于现有方法，为视频生成任务中的偏好对齐提供了稳健解决方案。

Conclusion: PG-DPO有效解决了扩散模型中DPO训练的似然位移问题，显著提升了视频生成的偏好对齐性能。

Abstract: Direct Preference Optimization (DPO) has shown promising results in aligning generative outputs with human preferences by distinguishing between chosen and rejected samples. However, a critical limitation of DPO is likelihood displacement, where the probabilities of chosen samples paradoxically decrease during training, undermining the quality of generation. Although this issue has been investigated in autoregressive models, its impact within diffusion-based models remains largely unexplored. This gap leads to suboptimal performance in tasks involving video generation. To address this, we conduct a formal analysis of DPO loss through updating policy within the diffusion framework, which describes how the updating of specific training samples influences the model's predictions on other samples. Using this tool, we identify two main failure modes: (1) Optimization Conflict, which arises from small reward margins between chosen and rejected samples, and (2) Suboptimal Maximization, caused by large reward margins. Informed by these insights, we introduce a novel solution named Policy-Guided DPO (PG-DPO), combining Adaptive Rejection Scaling (ARS) and Implicit Preference Regularization (IPR) to effectively mitigate likelihood displacement. Experiments show that PG-DPO outperforms existing methods in both quantitative metrics and qualitative evaluations, offering a robust solution for improving preference alignment in video generation tasks.

</details>


### [270] [LAA3D: A Benchmark of Detecting and Tracking Low-Altitude Aircraft in 3D Space](https://arxiv.org/abs/2511.19057)
*Hai Wu,Shuai Tang,Jiale Wang,Longkun Zou,Mingyue Guo,Rongqin Liang,Ke Chen,Yaowei Wang*

Main category: cs.CV

TL;DR: LAA3D是一个大规模数据集，专注于低空飞行器的3D感知，包含15,000张真实图像和600,000帧合成数据，支持3D检测、多目标跟踪和姿态估计任务。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏专门针对低空飞行器3D感知的数据集，限制了该领域的研究进展。

Method: 提出LAA3D数据集，包含真实和合成数据，涵盖多种低空飞行器类别；建立统一评估基准；提出MonoLAA单目3D检测基线方法。

Result: 合成数据预训练的模型通过微调在真实数据上表现出良好的仿真到真实泛化能力，MonoLAA方法在变焦相机上实现稳健的3D定位。

Conclusion: LAA3D为低空3D目标感知研究提供了全面基础，展示了合成数据在真实场景中的有效迁移。

Abstract: Perception of Low-Altitude Aircraft (LAA) in 3D space enables precise 3D object localization and behavior understanding. However, datasets tailored for 3D LAA perception remain scarce. To address this gap, we present LAA3D, a large-scale dataset designed to advance 3D detection and tracking of low-altitude aerial vehicles. LAA3D contains 15,000 real images and 600,000 synthetic frames, captured across diverse scenarios, including urban and suburban environments. It covers multiple aerial object categories, including electric Vertical Take-Off and Landing (eVTOL) aircraft, Micro Aerial Vehicles (MAVs), and Helicopters. Each instance is annotated with 3D bounding box, class label, and instance identity, supporting tasks such as 3D object detection, 3D multi-object tracking (MOT), and 6-DoF pose estimation. Besides, we establish the LAA3D Benchmark, integrating multiple tasks and methods with unified evaluation protocols for comparison. Furthermore, we propose MonoLAA, a monocular 3D detection baseline, achieving robust 3D localization from zoom cameras with varying focal lengths. Models pretrained on synthetic images transfer effectively to real-world data with fine-tuning, demonstrating strong sim-to-real generalization. Our LAA3D provides a comprehensive foundation for future research in low-altitude 3D object perception.

</details>


### [271] [Granular Computing-driven SAM: From Coarse-to-Fine Guidance for Prompt-Free Segmentation](https://arxiv.org/abs/2511.19062)
*Qiyang Yu,Yu Fang,Tianrui Li,Xuemei Cao,Yan Chen,Jianghao Li,Fan Min,Yi Zhang*

Main category: cs.CV

TL;DR: Grc-SAM是一个基于粒度计算的粗到细框架，用于无需提示的图像分割，通过多粒度注意力机制解决SAM模型在定位性和可扩展性方面的限制。


<details>
  <summary>Details</summary>
Motivation: 解决传统预训练模型（如SAM）在单粒度级别生成提示的两个主要限制：缺乏自主区域定位机制（定位性）和在高分辨率下细粒度建模能力有限（可扩展性）。

Method: 1. 粗阶段：自适应提取特征中的高响应区域，实现精确前景定位；2. 细阶段：应用更细的补丁划分和稀疏局部Swin风格注意力，增强细节建模；3. 将精炼掩码编码为潜在提示嵌入，替代手工提示。

Result: 大量实验结果表明，Grc-SAM在准确性和可扩展性方面均优于基线方法。

Conclusion: Grc-SAM通过整合多粒度注意力，将粒度计算与视觉Transformer相结合，为无需提示的分割提供了独特的粒度计算视角。

Abstract: Prompt-free image segmentation aims to generate accurate masks without manual guidance. Typical pre-trained models, notably Segmentation Anything Model (SAM), generate prompts directly at a single granularity level. However, this approach has two limitations: (1) Localizability, lacking mechanisms for autonomous region localization; (2) Scalability, limited fine-grained modeling at high resolution. To address these challenges, we introduce Granular Computing-driven SAM (Grc-SAM), a coarse-to-fine framework motivated by Granular Computing (GrC). First, the coarse stage adaptively extracts high-response regions from features to achieve precise foreground localization and reduce reliance on external prompts. Second, the fine stage applies finer patch partitioning with sparse local swin-style attention to enhance detail modeling and enable high-resolution segmentation. Third, refined masks are encoded as latent prompt embeddings for the SAM decoder, replacing handcrafted prompts with an automated reasoning process. By integrating multi-granularity attention, Grc-SAM bridges granular computing with vision transformers. Extensive experimental results demonstrate Grc-SAM outperforms baseline methods in both accuracy and scalability. It offers a unique granular computational perspective for prompt-free segmentation.

</details>


### [272] [DEAP-3DSAM: Decoder Enhanced and Auto Prompt SAM for 3D Medical Image Segmentation](https://arxiv.org/abs/2511.19071)
*Fangda Chen,Jintao Tang,Pancheng Wang,Ting Wang,Shasha Li,Ting Deng*

Main category: cs.CV

TL;DR: DEAP-3DSAM模型通过特征增强解码器和双注意力提示器，解决了SAM在3D医学图像分割中的空间特征丢失和手动提示依赖问题，在腹部肿瘤分割任务中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: SAM模型在医学图像分割中展现出潜力，但应用于3D图像时存在空间特征丢失问题，且现有方法依赖手动提示，难以在实际场景中应用。

Method: 提出特征增强解码器融合原始图像特征和空间信息，设计双注意力提示器通过空间注意力和通道注意力自动获取提示信息。

Result: 在四个公共腹部肿瘤分割数据集上的实验表明，DEAP-3DSAM在3D图像分割中达到最先进性能，优于或匹配现有手动提示方法。

Conclusion: 定量和定性消融研究证实了所提模块的有效性，DEAP-3DSAM成功解决了SAM在3D医学图像分割中的关键限制。

Abstract: The Segment Anything Model (SAM) has recently demonstrated significant potential in medical image segmentation. Although SAM is primarily trained on 2D images, attempts have been made to apply it to 3D medical image segmentation. However, the pseudo 3D processing used to adapt SAM results in spatial feature loss, limiting its performance. Additionally, most SAM-based methods still rely on manual prompts, which are challenging to implement in real-world scenarios and require extensive external expert knowledge. To address these limitations, we introduce the Decoder Enhanced and Auto Prompt SAM (DEAP-3DSAM) to tackle these limitations. Specifically, we propose a Feature Enhanced Decoder that fuses the original image features with rich and detailed spatial information to enhance spatial features. We also design a Dual Attention Prompter to automatically obtain prompt information through Spatial Attention and Channel Attention. We conduct comprehensive experiments on four public abdominal tumor segmentation datasets. The results indicate that our DEAP-3DSAM achieves state-of-the-art performance in 3D image segmentation, outperforming or matching existing manual prompt methods. Furthermore, both quantitative and qualitative ablation studies confirm the effectiveness of our proposed modules.

</details>


### [273] [Graph-based 3D Human Pose Estimation using WiFi Signals](https://arxiv.org/abs/2511.19105)
*Jichao Chen,YangYang Qu,Ruibo Tang,Dirk Slock*

Main category: cs.CV

TL;DR: GraphPose-Fi是一个基于图的WiFi人体姿态估计框架，通过显式建模骨骼拓扑结构来改进3D人体姿态估计性能


<details>
  <summary>Details</summary>
Motivation: 现有WiFi姿态估计方法直接回归3D关节坐标，忽略了人体关节间的固有拓扑关系，导致性能受限

Method: 包含CNN编码器提取特征、轻量级注意力模块自适应加权特征、基于图的回归头结合GCN和自注意力机制

Result: 在MM-Fi数据集上显著优于现有方法

Conclusion: GraphPose-Fi通过显式建模骨骼拓扑结构，有效提升了WiFi姿态估计的准确性

Abstract: WiFi-based human pose estimation (HPE) has attracted increasing attention due to its resilience to occlusion and privacy-preserving compared to camera-based methods. However, existing WiFi-based HPE approaches often employ regression networks that directly map WiFi channel state information (CSI) to 3D joint coordinates, ignoring the inherent topological relationships among human joints. In this paper, we present GraphPose-Fi, a graph-based framework that explicitly models skeletal topology for WiFi-based 3D HPE. Our framework comprises a CNN encoder shared across antennas for subcarrier-time feature extraction, a lightweight attention module that adaptively reweights features over time and across antennas, and a graph-based regression head that combines GCN layers with self-attention to capture local topology and global dependencies. Our proposed method significantly outperforms existing methods on the MM-Fi dataset in various settings. The source code is available at: https://github.com/Cirrick/GraphPose-Fi.

</details>


### [274] [HABIT: Human Action Benchmark for Interactive Traffic in CARLA](https://arxiv.org/abs/2511.19109)
*Mohan Ramesh,Mark Azer,Fabian B. Flohr*

Main category: cs.CV

TL;DR: HABIT是一个高保真自动驾驶仿真基准，通过真实人类运动数据集成到CARLA中，暴露了现有自动驾驶代理在复杂行人交互中的安全隐患。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶仿真缺乏对真实多样化人类行为的充分表示，无法捕捉复杂的动态意图和多样化响应，这对系统安全性和可靠性构成挑战。

Method: 开发了模块化、可扩展且物理一致的运动重定向管道，将来自动作捕捉和视频的真实人类运动数据集成到CARLA仿真器中，并标准化为SMPL格式。

Result: 评估三个先进自动驾驶代理显示，在CARLA Leaderboard上接近零碰撞的代理在HABIT上表现显著恶化，碰撞率高达7.43次/公里，AIS 3+伤害风险达12.94%，不必要制动率高达33%。

Conclusion: HABIT基准揭示了现有评估方法无法检测到的关键失效模式，为可重复的行人感知AI研究提供了重要工具。

Abstract: Current autonomous driving (AD) simulations are critically limited by their inadequate representation of realistic and diverse human behavior, which is essential for ensuring safety and reliability. Existing benchmarks often simplify pedestrian interactions, failing to capture complex, dynamic intentions and varied responses critical for robust system deployment. To overcome this, we introduce HABIT (Human Action Benchmark for Interactive Traffic), a high-fidelity simulation benchmark. HABIT integrates real-world human motion, sourced from mocap and videos, into CARLA (Car Learning to Act, a full autonomous driving simulator) via a modular, extensible, and physically consistent motion retargeting pipeline. From an initial pool of approximately 30,000 retargeted motions, we curate 4,730 traffic-compatible pedestrian motions, standardized in SMPL format for physically consistent trajectories. HABIT seamlessly integrates with CARLA's Leaderboard, enabling automated scenario generation and rigorous agent evaluation. Our safety metrics, including Abbreviated Injury Scale (AIS) and False Positive Braking Rate (FPBR), reveal critical failure modes in state-of-the-art AD agents missed by prior evaluations. Evaluating three state-of-the-art autonomous driving agents, InterFuser, TransFuser, and BEVDriver, demonstrates how HABIT exposes planner weaknesses that remain hidden in scripted simulations. Despite achieving close or equal to zero collisions per kilometer on the CARLA Leaderboard, the autonomous agents perform notably worse on HABIT, with up to 7.43 collisions/km and a 12.94% AIS 3+ injury risk, and they brake unnecessarily in up to 33% of cases. All components are publicly released to support reproducible, pedestrian-aware AI research.

</details>


### [275] [DiffSeg30k: A Multi-Turn Diffusion Editing Benchmark for Localized AIGC Detection](https://arxiv.org/abs/2511.19111)
*Hai Ci,Ziheng Peng,Pei Yang,Yingxin Xuan,Mike Zheng Shou*

Main category: cs.CV

TL;DR: DiffSeg30k是一个包含3万张扩散编辑图像的数据集，具有像素级标注，将AIGC检测从二元分类转向语义分割，支持编辑定位和模型识别。


<details>
  <summary>Details</summary>
Motivation: 现有的AIGC检测基准主要关注整图分类，忽略了扩散编辑的定位问题，需要支持细粒度检测的数据集。

Method: 构建DiffSeg30k数据集：1）使用COCO图像反映真实世界多样性；2）采用8个SOTA扩散模型进行局部编辑；3）支持最多三次连续编辑；4）使用VLM自动识别有意义区域并生成上下文感知提示。

Result: 基准测试显示语义分割任务面临显著挑战，特别是在图像失真鲁棒性方面。分割模型在整图分类上优于现有伪造分类器，并展现出跨生成器泛化潜力。

Conclusion: DiffSeg30k通过展示基于分割方法的潜力和局限性，将推动AI生成内容细粒度定位研究的发展。

Abstract: Diffusion-based editing enables realistic modification of local image regions, making AI-generated content harder to detect. Existing AIGC detection benchmarks focus on classifying entire images, overlooking the localization of diffusion-based edits. We introduce DiffSeg30k, a publicly available dataset of 30k diffusion-edited images with pixel-level annotations, designed to support fine-grained detection. DiffSeg30k features: 1) In-the-wild images--we collect images or image prompts from COCO to reflect real-world content diversity; 2) Diverse diffusion models--local edits using eight SOTA diffusion models; 3) Multi-turn editing--each image undergoes up to three sequential edits to mimic real-world sequential editing; and 4) Realistic editing scenarios--a vision-language model (VLM)-based pipeline automatically identifies meaningful regions and generates context-aware prompts covering additions, removals, and attribute changes. DiffSeg30k shifts AIGC detection from binary classification to semantic segmentation, enabling simultaneous localization of edits and identification of the editing models. We benchmark three baseline segmentation approaches, revealing significant challenges in semantic segmentation tasks, particularly concerning robustness to image distortions. Experiments also reveal that segmentation models, despite being trained for pixel-level localization, emerge as highly reliable whole-image classifiers of diffusion edits, outperforming established forgery classifiers while showing great potential in cross-generator generalization. We believe DiffSeg30k will advance research in fine-grained localization of AI-generated content by demonstrating the promise and limitations of segmentation-based methods. DiffSeg30k is released at: https://huggingface.co/datasets/Chaos2629/Diffseg30k

</details>


### [276] [3M-TI: High-Quality Mobile Thermal Imaging via Calibration-free Multi-Camera Cross-Modal Diffusion](https://arxiv.org/abs/2511.19117)
*Minchong Chen,Xiaoyun Yuan,Junzhe Wan,Jianing Zhang,Jun Zhang*

Main category: cs.CV

TL;DR: 提出3M-TI，一种无需校准的多相机跨模态扩散框架，用于移动热成像超分辨率，通过跨模态自注意力模块在去噪过程中自适应对齐热成像和RGB特征，显著提升热图像的空间分辨率、结构保真度和纹理细节。


<details>
  <summary>Details</summary>
Motivation: 移动平台热传感器的小型化限制了空间分辨率和纹理保真度，导致图像模糊且信息量少。现有热成像超分辨率方法存在单图像方法难以恢复精细结构、RGB引导方法依赖复杂跨相机校准的问题。

Method: 在扩散UNet中集成跨模态自注意力模块(CSM)，替代原始自注意力层，在去噪过程中自适应对齐热成像和RGB特征，无需显式相机校准。

Result: 在真实移动热相机和公共基准测试中取得最先进性能，在视觉质量和定量指标上均表现优异，增强后的热图像在下游任务（如目标检测和分割）中带来显著提升。

Conclusion: 3M-TI框架通过无校准的跨模态扩散方法有效提升了移动热成像质量，具有重要的实际应用价值。

Abstract: The miniaturization of thermal sensors for mobile platforms inherently limits their spatial resolution and textural fidelity, leading to blurry and less informative images. Existing thermal super-resolution (SR) methods can be grouped into single-image and RGB-guided approaches: the former struggles to recover fine structures from limited information, while the latter relies on accurate and laborious cross-camera calibration, which hinders practical deployment and robustness. Here, we propose 3M-TI, a calibration-free Multi-camera cross-Modality diffusion framework for Mobile Thermal Imaging. At its core, 3M-TI integrates a cross-modal self-attention module (CSM) into the diffusion UNet, replacing the original self-attention layers to adaptively align thermal and RGB features throughout the denoising process, without requiring explicit camera calibration. This design enables the diffusion network to leverage its generative prior to enhance spatial resolution, structural fidelity, and texture detail in the super-resolved thermal images. Extensive evaluations on real-world mobile thermal cameras and public benchmarks validate our superior performance, achieving state-of-the-art results in both visual quality and quantitative metrics. More importantly, the thermal images enhanced by 3M-TI lead to substantial gains in critical downstream tasks like object detection and segmentation, underscoring its practical value for robust mobile thermal perception systems. More materials: https://github.com/work-submit/3MTI.

</details>


### [277] [MonoSR: Open-Vocabulary Spatial Reasoning from Monocular Images](https://arxiv.org/abs/2511.19119)
*Qirui Wang,Jingyi He,Yining Pan,Si Yong Yeo,Xulei Yang,Shijie Li*

Main category: cs.CV

TL;DR: 提出了MonoSR数据集，用于支持单目图像的空间推理任务，涵盖室内、室外和物体中心场景，并评估了现有视觉语言模型在该任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有空间推理研究主要依赖多视角观察和室内环境，限制了在户外场景和单目图像（最常见真实世界设置）上的适用性。

Method: 构建大规模单目空间推理数据集MonoSR，包含多样化场景和问题类型，并评估先进视觉语言模型的性能，分析辅助信息的重要性。

Result: 建立了开放世界单目空间推理的基础，揭示了现有模型在该挑战性任务上的局限性，并为未来模型设计提供了实用指导。

Conclusion: MonoSR数据集为推进真实世界开放环境中的单目空间推理奠定了基础，通过系统评估和分析为未来研究提供了方向。

Abstract: Spatial reasoning (SR), the ability to infer 3D spatial information from 2D inputs, is essential for real-world applications such as embodied AI and autonomous driving. However, existing research primarily focuses on indoor environments and typically relies on multi-view observations, which limits their generalizability to outdoor scenarios and constrains their applicability to monocular images, the most common real-world setting. In this work, we propose MonoSR, a large-scale monocular spatial reasoning dataset that spans diverse scenarios including indoor, outdoor, and object-centric settings, and supports multiple question types. MonoSR provides a path toward open-world monocular spatial reasoning. Beyond introducing the dataset, we evaluate advanced vision-language models to reveal their limitations on this challenging task. We further analyze whether auxiliary information is crucial for monocular spatial reasoning and offer practical guidance for designing future models. These contributions collectively establish a foundation for advancing monocular spatial reasoning in real-world, open-world environments.

</details>


### [278] [When Semantics Regulate: Rethinking Patch Shuffle and Internal Bias for Generated Image Detection with CLIP](https://arxiv.org/abs/2511.19126)
*Beilin Chu,Weike You,Mengtao Li,Tingting Zheng,Kehan Zhao,Xuan Xu,Zhigao Lu,Jia Song,Moxuan Xu,Linna Zhou*

Main category: cs.CV

TL;DR: 该论文提出了SemAnti方法，通过抑制CLIP检测器中的语义偏差来提升AI生成图像检测的跨域泛化能力。研究发现Patch Shuffle能有效破坏全局语义连续性但保留局部伪影线索，从而减少语义熵并同化特征分布。


<details>
  <summary>Details</summary>
Motivation: 当前基于CLIP的AI生成图像检测器过度依赖语义线索而非生成器伪影，导致在分布偏移下性能脆弱。需要解决语义偏差问题以实现更稳健的跨域检测。

Method: 提出SemAnti语义对抗微调范式，冻结语义子空间，在打乱语义下仅适配对伪影敏感的层。通过层间分析发现CLIP的深层语义结构可作为稳定跨域表示的调节器。

Result: 在AIGCDetectBenchmark和GenImage基准测试中达到最先进的跨域泛化性能，验证了调节语义对释放CLIP检测潜力的重要性。

Conclusion: 抑制语义偏差是提升AI生成图像检测稳健性的关键，SemAnti的简单设计证明了通过调节语义可以显著提升CLIP检测器的跨域泛化能力。

Abstract: The rapid progress of GANs and Diffusion Models poses new challenges for detecting AI-generated images. Although CLIP-based detectors exhibit promising generalization, they often rely on semantic cues rather than generator artifacts, leading to brittle performance under distribution shifts. In this work, we revisit the nature of semantic bias and uncover that Patch Shuffle provides an unusually strong benefit for CLIP, that disrupts global semantic continuity while preserving local artifact cues, which reduces semantic entropy and homogenizes feature distributions between natural and synthetic images. Through a detailed layer-wise analysis, we further show that CLIP's deep semantic structure functions as a regulator that stabilizes cross-domain representations once semantic bias is suppressed. Guided by these findings, we propose SemAnti, a semantic-antagonistic fine-tuning paradigm that freezes the semantic subspace and adapts only artifact-sensitive layers under shuffled semantics. Despite its simplicity, SemAnti achieves state-of-the-art cross-domain generalization on AIGCDetectBenchmark and GenImage, demonstrating that regulating semantics is key to unlocking CLIP's full potential for robust AI-generated image detection.

</details>


### [279] [MambaRefine-YOLO: A Dual-Modality Small Object Detector for UAV Imagery](https://arxiv.org/abs/2511.19134)
*Shuyu Cao,Minxin Chen,Yucheng Song,Zhaozhong Chen,Xinyou Zhang*

Main category: cs.CV

TL;DR: 提出MambaRefine-YOLO模型，通过双门控互补Mamba融合模块和分层特征聚合颈部，在无人机图像小目标检测中实现精度与速度的平衡


<details>
  <summary>Details</summary>
Motivation: 无人机图像中小目标检测面临分辨率低和背景干扰问题，现有RGB与红外数据融合方法在跨模态交互和计算效率之间存在权衡困难

Method: DGC-MFM模块通过光照感知和差异感知门控机制自适应平衡RGB和红外模态；HFAN采用"先精炼后融合"策略增强多尺度特征

Result: 在DroneVehicle数据集上达到83.2%的mAP，比基线提升7.9%；在VisDrone数据集上仅使用HFAN也取得显著提升

Conclusion: 该方法在精度和速度间达到优越平衡，非常适合实际无人机应用

Abstract: Small object detection in Unmanned Aerial Vehicle (UAV) imagery is a persistent challenge, hindered by low resolution and background clutter. While fusing RGB and infrared (IR) data offers a promising solution, existing methods often struggle with the trade-off between effective cross-modal interaction and computational efficiency. In this letter, we introduce MambaRefine-YOLO. Its core contributions are a Dual-Gated Complementary Mamba fusion module (DGC-MFM) that adaptively balances RGB and IR modalities through illumination-aware and difference-aware gating mechanisms, and a Hierarchical Feature Aggregation Neck (HFAN) that uses a ``refine-then-fuse'' strategy to enhance multi-scale features. Our comprehensive experiments validate this dual-pronged approach. On the dual-modality DroneVehicle dataset, the full model achieves a state-of-the-art mAP of 83.2%, an improvement of 7.9% over the baseline. On the single-modality VisDrone dataset, a variant using only the HFAN also shows significant gains, demonstrating its general applicability. Our work presents a superior balance between accuracy and speed, making it highly suitable for real-world UAV applications.

</details>


### [280] [FilmSceneDesigner: Chaining Set Design for Procedural Film Scene Generation](https://arxiv.org/abs/2511.19137)
*Zhifeng Xie,Keyi Zhang,Yiye Yan,Yuling Guo,Fan Yang,Jiting Zhou,Mengtian Li*

Main category: cs.CV

TL;DR: FilmSceneDesigner是一个自动化电影场景生成系统，通过基于代理的链式框架和程序化生成流程，从自然语言描述生成完整的电影场景，解决了传统手工建模效率低的问题。


<details>
  <summary>Details</summary>
Motivation: 传统电影场景设计依赖专家手工建模，过程劳动密集且耗时。需要自动化系统来提高效率，同时保持专业水准。

Method: 1) 基于代理的链式框架将自然语言描述转换为结构化参数；2) 程序化生成管道执行平面图生成、结构构建、材质分配、门窗布局和物体检索布局等专门功能；3) 构建SetDepot-Pro数据集，包含6,862个电影专用3D资产和733种材质。

Result: 实验和人工评估表明，系统生成的结构合理场景具有强烈的电影真实感，支持虚拟预演、施工图纸和情绪板创建等下游任务。

Conclusion: FilmSceneDesigner成功实现了自动化电影场景设计，在保持专业质量的同时显著提高了效率，为电影制作提供了实用的工具支持。

Abstract: Film set design plays a pivotal role in cinematic storytelling and shaping the visual atmosphere. However, the traditional process depends on expert-driven manual modeling, which is labor-intensive and time-consuming. To address this issue, we introduce FilmSceneDesigner, an automated scene generation system that emulates professional film set design workflow. Given a natural language description, including scene type, historical period, and style, we design an agent-based chaining framework to generate structured parameters aligned with film set design workflow, guided by prompt strategies that ensure parameter accuracy and coherence. On the other hand, we propose a procedural generation pipeline which executes a series of dedicated functions with the structured parameters for floorplan and structure generation, material assignment, door and window placement, and object retrieval and layout, ultimately constructing a complete film scene from scratch. Moreover, to enhance cinematic realism and asset diversity, we construct SetDepot-Pro, a curated dataset of 6,862 film-specific 3D assets and 733 materials. Experimental results and human evaluations demonstrate that our system produces structurally sound scenes with strong cinematic fidelity, supporting downstream tasks such as virtual previs, construction drawing and mood board creation.

</details>


### [281] [ABM-LoRA: Activation Boundary Matching for Fast Convergence in Low-Rank Adaptation](https://arxiv.org/abs/2511.19145)
*Dongha Lee,Jinhee Park,Minjun Kim,Junseok Kwon*

Main category: cs.CV

TL;DR: ABM-LoRA是一种通过激活边界匹配来加速低秩适配器收敛的初始化策略，通过对齐预训练模型和适配器的激活边界来减少信息损失，提升训练效率。


<details>
  <summary>Details</summary>
Motivation: LoRA虽然参数效率高，但其随机初始化会导致梯度更新在错误的正切空间进行，造成信息损失并阻碍早期收敛。

Method: ABM-LoRA在下游训练前将适配器的激活边界与预训练模型对齐，最大化全参数梯度在适配器子空间中的投影。

Result: 在语言理解（T5-Base on GLUE）、对话生成（LLaMA2-7B on WizardLM）和视觉识别（ViT-B/16 on VTAB-1K）等任务上表现出色，在VTAB-1K上达到最高准确率，特别是在需要几何理解的结构化推理任务上有显著提升。

Conclusion: ABM-LoRA通过激活边界对齐有效减少了信息损失，降低了初始损失，显著加速了收敛过程，在各种架构和任务上都表现出优越性能。

Abstract: We propose Activation Boundary Matching for Low-Rank Adaptation (ABM-LoRA), a principled initialization strategy that substantially accelerates the convergence of low-rank adapters. While LoRA offers high parameter efficiency, its random initialization restricts gradient updates to a mismatched tangent space, causing significant information loss and hindering early convergence. Our ABM-LoRA addresses this by aligning the adapter's activation boundaries with those of the pretrained model before downstream training, thereby maximizing the projection of full-parameter gradients into the adapter subspace. This alignment sharply reduces information loss at initialization, yields a lower starting loss, and accelerates convergence. We demonstrate ABM-LoRA's effectiveness across diverse architectures and tasks: language understanding (T5-Base on GLUE), dialogue generation (LLaMA2-7B on WizardLM), and vision recognition (ViT-B/16 on VTAB-1K). On VTAB-1K, it achieves the highest accuracy among all methods, with strong gains on structured reasoning tasks requiring geometric understanding.

</details>


### [282] [From Pixels to Posts: Retrieval-Augmented Fashion Captioning and Hashtag Generation](https://arxiv.org/abs/2511.19149)
*Moazzam Umer Gondal,Hamad Ul Qudous,Daniya Siddiqui,Asma Ahmad Farhan*

Main category: cs.CV

TL;DR: 提出基于检索增强的自动时尚图片描述和标签生成框架，结合多服装检测、属性推理和LLM提示，相比端到端方法在属性保真度和领域泛化方面表现更好。


<details>
  <summary>Details</summary>
Motivation: 解决端到端图片描述生成器在属性保真度和领域泛化方面的局限性，旨在为时尚图片生成视觉接地、描述性强且风格有趣的文本内容。

Method: 使用YOLO检测器进行多服装定位，k-means聚类提取主色调，CLIP-FAISS检索模块基于结构化产品索引推断面料和性别属性，构建事实证据包指导LLM生成类人描述和丰富标签。

Result: YOLO检测器在9类服装上获得0.71的mAP@0.5，RAG-LLM管道生成表达性属性对齐描述，标签生成中平均属性覆盖率达0.80，相比BLIP基线具有更好的事实基础和更少幻觉。

Conclusion: 检索增强生成是自动化和视觉接地时尚内容生成的有效且可解释范式，在减少幻觉和提升可扩展部署方面展现出巨大潜力。

Abstract: This paper introduces the retrieval-augmented framework for automatic fashion caption and hashtag generation, combining multi-garment detection, attribute reasoning, and Large Language Model (LLM) prompting. The system aims to produce visually grounded, descriptive, and stylistically interesting text for fashion imagery, overcoming the limitations of end-to-end captioners that have problems with attribute fidelity and domain generalization. The pipeline combines a YOLO-based detector for multi-garment localization, k-means clustering for dominant color extraction, and a CLIP-FAISS retrieval module for fabric and gender attribute inference based on a structured product index. These attributes, together with retrieved style examples, create a factual evidence pack that is used to guide an LLM to generate human-like captions and contextually rich hashtags. A fine-tuned BLIP model is used as a supervised baseline model for comparison. Experimental results show that the YOLO detector is able to obtain a mean Average Precision (mAP@0.5) of 0.71 for nine categories of garments. The RAG-LLM pipeline generates expressive attribute-aligned captions and achieves mean attribute coverage of 0.80 with full coverage at the 50% threshold in hashtag generation, whereas BLIP gives higher lexical overlap and lower generalization. The retrieval-augmented approach exhibits better factual grounding, less hallucination, and great potential for scalable deployment in various clothing domains. These results demonstrate the use of retrieval-augmented generation as an effective and interpretable paradigm for automated and visually grounded fashion content generation.

</details>


### [283] [Test-Time Preference Optimization for Image Restoration](https://arxiv.org/abs/2511.19169)
*Bingchen Li,Xin Li,Jiaqi Xu,Jiaming Guo,Wenbo Li,Renjing Pei,Zhibo Chen*

Main category: cs.CV

TL;DR: 本文提出了首个测试时偏好优化（TTPO）范式，用于提升图像恢复模型的感知质量，无需重新训练模型或收集大量偏好数据。


<details>
  <summary>Details</summary>
Motivation: 现有的预训练和零样本图像恢复方法往往无法与人类偏好对齐，导致恢复的图像质量不佳。需要一种能够灵活适应各种图像恢复任务或骨干网络的方法，且无需模型重训练和繁琐的偏好数据收集。

Method: 设计了一个无需训练的三阶段流程：1）基于初始恢复图像，通过扩散反演和去噪在线生成候选偏好图像；2）使用自动偏好对齐指标或人类反馈选择偏好和非偏好图像；3）将选定的偏好图像作为奖励信号，指导扩散去噪过程，优化恢复图像以更好地符合人类偏好。

Result: 在多种图像恢复任务和模型上的广泛实验证明了所提出流程的有效性和灵活性。

Conclusion: TTPO范式能够有效提升图像恢复的感知质量，生成实时偏好数据，并与任何图像恢复模型骨干网络兼容。

Abstract: Image restoration (IR) models are typically trained to recover high-quality images using L1 or LPIPS loss. To handle diverse unknown degradations, zero-shot IR methods have also been introduced. However, existing pre-trained and zero-shot IR approaches often fail to align with human preferences, resulting in restored images that may not be favored. This highlights the critical need to enhance restoration quality and adapt flexibly to various image restoration tasks or backbones without requiring model retraining and ideally without labor-intensive preference data collection. In this paper, we propose the first Test-Time Preference Optimization (TTPO) paradigm for image restoration, which enhances perceptual quality, generates preference data on-the-fly, and is compatible with any IR model backbone. Specifically, we design a training-free, three-stage pipeline: (i) generate candidate preference images online using diffusion inversion and denoising based on the initially restored image; (ii) select preferred and dispreferred images using automated preference-aligned metrics or human feedback; and (iii) use the selected preference images as reward signals to guide the diffusion denoising process, optimizing the restored image to better align with human preferences. Extensive experiments across various image restoration tasks and models demonstrate the effectiveness and flexibility of the proposed pipeline.

</details>


### [284] [MetroGS: Efficient and Stable Reconstruction of Geometrically Accurate High-Fidelity Large-Scale Scenes](https://arxiv.org/abs/2511.19172)
*Kehua Chen,Tianlu Mao,Zhuxin Ma,Hao Jiang,Zehao Li,Zihan Liu,Shuqi Gao,Honglong Zhao,Feng Dai,Yucheng Zhang,Zhaoqi Wang*

Main category: cs.CV

TL;DR: MetroGS是一个用于复杂城市场景高效稳健重建的新型高斯泼溅框架，通过分布式2D高斯泼溅表示、结构化密集增强、渐进式混合几何优化和深度引导的外观建模来解决大规模场景重建中的几何保真度和外观一致性问题。


<details>
  <summary>Details</summary>
Motivation: 解决3D高斯泼溅及其衍生方法在大规模场景重建中如何高效稳定地实现高质量几何保真度的核心挑战，特别是在复杂城市场景中。

Method: 1. 基于分布式2D高斯泼溅表示作为核心基础；2. 结构化密集增强方案利用SfM先验和点图模型实现更密集初始化；3. 渐进式混合几何优化策略整合单目和多视图优化；4. 深度引导的外观建模方法学习具有3D一致性的空间特征。

Result: 在大规模城市数据集上的实验表明，MetroGS实现了优越的几何精度和渲染质量，为高保真大规模场景重建提供了统一解决方案。

Conclusion: MetroGS通过创新的技术组合有效解决了复杂城市场景重建中的几何保真度和外观一致性挑战，为大规模场景重建提供了高效稳健的框架。

Abstract: Recently, 3D Gaussian Splatting and its derivatives have achieved significant breakthroughs in large-scale scene reconstruction. However, how to efficiently and stably achieve high-quality geometric fidelity remains a core challenge. To address this issue, we introduce MetroGS, a novel Gaussian Splatting framework for efficient and robust reconstruction in complex urban environments. Our method is built upon a distributed 2D Gaussian Splatting representation as the core foundation, serving as a unified backbone for subsequent modules. To handle potential sparse regions in complex scenes, we propose a structured dense enhancement scheme that utilizes SfM priors and a pointmap model to achieve a denser initialization, while incorporating a sparsity compensation mechanism to improve reconstruction completeness. Furthermore, we design a progressive hybrid geometric optimization strategy that organically integrates monocular and multi-view optimization to achieve efficient and accurate geometric refinement. Finally, to address the appearance inconsistency commonly observed in large-scale scenes, we introduce a depth-guided appearance modeling approach that learns spatial features with 3D consistency, facilitating effective decoupling between geometry and appearance and further enhancing reconstruction stability. Experiments on large-scale urban datasets demonstrate that MetroGS achieves superior geometric accuracy, rendering quality, offering a unified solution for high-fidelity large-scale scene reconstruction.

</details>


### [285] [Evaluating Deep Learning and Traditional Approaches Used in Source Camera Identification](https://arxiv.org/abs/2511.19180)
*Mansur Ozaman*

Main category: cs.CV

TL;DR: 本文对三种源相机识别技术进行了比较分析：PRNU、JPEG压缩伪像分析和CNN，评估了它们在设备分类准确性方面的表现，并讨论了实际应用所需的科学进展。


<details>
  <summary>Details</summary>
Motivation: 源相机识别是计算机视觉中的重要任务，有助于对图像进行更全面的分析，识别拍摄设备对于图像取证和分析具有重要意义。

Method: 比较分析了三种源相机识别技术：Photo Response Non-Uniformity (PRNU)、JPEG压缩伪像分析和卷积神经网络(CNNs)，重点评估了每种方法的设备分类准确性。

Result: 研究对三种方法的设备分类准确性进行了评估比较，但具体结果数据未在摘要中提供。

Conclusion: 研究讨论了这些方法在实际场景中应用所需的科学进展，为源相机识别技术的实际部署提供了发展方向。

Abstract: One of the most important tasks in computer vision is identifying the device using which the image was taken, useful for facilitating further comprehensive analysis of the image. This paper presents comparative analysis of three techniques used in source camera identification (SCI): Photo Response Non-Uniformity (PRNU), JPEG compression artifact analysis, and convolutional neural networks (CNNs). It evaluates each method in terms of device classification accuracy. Furthermore, the research discusses the possible scientific development needed for the implementation of the methods in real-life scenarios.

</details>


### [286] [nnActive: A Framework for Evaluation of Active Learning in 3D Biomedical Segmentation](https://arxiv.org/abs/2511.19183)
*Carsten T. Lüth,Jeremias Traub,Kim-Celine Kahl,Till J. Bungert,Lukas Klein,Lars Krämer,Paul F. Jaeger,Fabian Isensee,Klaus Maier-Hein*

Main category: cs.CV

TL;DR: nnActive是一个开源主动学习框架，通过解决3D生物医学图像分割中的四个评估陷阱，发现主动学习方法虽然优于标准随机采样，但无法可靠超越改进的前景感知随机采样策略。


<details>
  <summary>Details</summary>
Motivation: 3D生物医学图像语义分割依赖大量标注数据，但手动标注成本高昂。主动学习旨在通过选择最有信息量的样本来减少标注工作量，但现有评估存在四个主要问题阻碍方法比较。

Method: 提出nnActive框架，包括：(1)大规模研究四个数据集和三种标注机制；(2)扩展nnU-Net使用部分标注进行3D补丁查询选择；(3)提出前景感知随机采样策略；(4)引入前景效率指标。

Result: 研究发现：(A)所有AL方法优于标准随机采样，但无法可靠超越改进的前景感知随机采样；(B)AL效果依赖任务特定参数；(C)预测熵是最佳AL方法但标注成本最高；(D)计算密集型设计可提升AL性能。

Conclusion: nnActive作为开源框架可促进3D生物医学图像中主动学习的研究和应用，揭示了当前AL方法的局限性并提供了改进方向。

Abstract: Semantic segmentation is crucial for various biomedical applications, yet its reliance on large annotated datasets presents a bottleneck due to the high cost and specialized expertise required for manual labeling. Active Learning (AL) aims to mitigate this challenge by querying only the most informative samples, thereby reducing annotation effort. However, in the domain of 3D biomedical imaging, there is no consensus on whether AL consistently outperforms Random sampling. Four evaluation pitfalls hinder the current methodological assessment. These are (1) restriction to too few datasets and annotation budgets, (2) using 2D models on 3D images without partial annotations, (3) Random baseline not being adapted to the task, and (4) measuring annotation cost only in voxels. In this work, we introduce nnActive, an open-source AL framework that overcomes these pitfalls by (1) means of a large scale study spanning four biomedical imaging datasets and three label regimes, (2) extending nnU-Net by using partial annotations for training with 3D patch-based query selection, (3) proposing Foreground Aware Random sampling strategies tackling the foreground-background class imbalance of medical images and (4) propose the foreground efficiency metric, which captures the low annotation cost of background-regions. We reveal the following findings: (A) while all AL methods outperform standard Random sampling, none reliably surpasses an improved Foreground Aware Random sampling; (B) benefits of AL depend on task specific parameters; (C) Predictive Entropy is overall the best performing AL method, but likely requires the most annotation effort; (D) AL performance can be improved with more compute intensive design choices. As a holistic, open-source framework, nnActive can serve as a catalyst for research and application of AL in 3D biomedical imaging. Code is at: https://github.com/MIC-DKFZ/nnActive

</details>


### [287] [Can Modern Vision Models Understand the Difference Between an Object and a Look-alike?](https://arxiv.org/abs/2511.19200)
*Itay Cohen,Ethan Fetaya,Amir Rosenfeld*

Main category: cs.CV

TL;DR: 该研究评估了CLIP等视觉语言模型是否能区分真实物体和外观相似的物体（如玩具、雕像等），提出了RoLA数据集和一种改进的嵌入空间方向调整方法。


<details>
  <summary>Details</summary>
Motivation: 现有计算机视觉模型在识别基准上表现良好，但与人类感知相比仍存在差距，特别是在判断图像是否只是看起来像某个物体而非真实实例的能力上。

Method: 构建了RoLA数据集（包含真实物体和外观相似物体的样本），首先评估基于提示的基线方法，然后估计CLIP嵌入空间中区分真实与相似物体的方向向量，并将该方向应用于图像和文本嵌入。

Result: 该方法在Conceptual12M上的跨模态检索中提高了区分能力，并改善了CLIP前缀字幕生成器生成的字幕质量。

Conclusion: CLIP模型在一定程度上能够捕捉真实物体与外观相似物体的区别，通过嵌入空间方向调整可以进一步增强这种区分能力。

Abstract: Recent advances in computer vision have yielded models with strong performance on recognition benchmarks; however, significant gaps remain in comparison to human perception. One subtle ability is to judge whether an image looks like a given object without being an instance of that object. We study whether vision-language models such as CLIP capture this distinction. We curated a dataset named RoLA (Real or Lookalike) of real and lookalike exemplars (e.g., toys, statues, drawings, pareidolia) across multiple categories, and first evaluate a prompt-based baseline with paired "real"/"lookalike" prompts. We then estimate a direction in CLIP's embedding space that moves representations between real and lookalike. Applying this direction to image and text embeddings improves discrimination in cross-modal retrieval on Conceptual12M, and also enhances captions produced by a CLIP prefix captioner.

</details>


### [288] [NVGS: Neural Visibility for Occlusion Culling in 3D Gaussian Splatting](https://arxiv.org/abs/2511.19202)
*Brent Zoomers,Florian Hahlbohm,Joni Vanherck,Lode Jorissen,Marcus Magnor,Nick Michiels*

Main category: cs.CV

TL;DR: 提出了一种使用小型共享MLP学习3D高斯模型中可见性函数的方法，通过遮挡剔除来加速渲染，在VRAM使用和图像质量方面优于现有技术


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅虽然可以利用视锥体剔除和细节层次策略加速渲染，但由于高斯的半透明特性无法应用遮挡剔除技术，这限制了渲染效率的进一步提升

Method: 使用跨实例共享的小型MLP学习训练模型中所有高斯的视角相关可见性函数，在光栅化前查询视锥体内高斯的可见性，丢弃被遮挡的基元，并利用Tensor Core进行高效计算

Result: 该方法在组合场景的VRAM使用和图像质量方面优于当前最先进技术，与现有LoD技术具有互补特性

Conclusion: 提出的神经查询方法成功解决了3D高斯渲染中遮挡剔除的难题，实现了更高效的渲染性能

Abstract: 3D Gaussian Splatting can exploit frustum culling and level-of-detail strategies to accelerate rendering of scenes containing a large number of primitives. However, the semi-transparent nature of Gaussians prevents the application of another highly effective technique: occlusion culling. We address this limitation by proposing a novel method to learn the viewpoint-dependent visibility function of all Gaussians in a trained model using a small, shared MLP across instances of an asset in a scene. By querying it for Gaussians within the viewing frustum prior to rasterization, our method can discard occluded primitives during rendering. Leveraging Tensor Cores for efficient computation, we integrate these neural queries directly into a novel instanced software rasterizer. Our approach outperforms the current state of the art for composed scenes in terms of VRAM usage and image quality, utilizing a combination of our instanced rasterizer and occlusion culling MLP, and exhibits complementary properties to existing LoD techniques.

</details>


### [289] [ReAlign: Text-to-Motion Generation via Step-Aware Reward-Guided Alignment](https://arxiv.org/abs/2511.19217)
*Wanjiang Weng,Xiaofeng Tan,Junbo Wang,Guo-Sen Xie,Pan Zhou,Hongsong Wang*

Main category: cs.CV

TL;DR: 提出ReAlign方法解决扩散模型中文本与运动分布不对齐问题，通过步长感知奖励模型和奖励引导策略提升文本-运动对齐质量和运动质量


<details>
  <summary>Details</summary>
Motivation: 扩散模型在文本到运动生成中存在文本与运动分布不对齐问题，导致语义不一致或低质量运动

Method: ReAlign方法包含步长感知奖励模型（集成步长感知标记、文本对齐模块和运动对齐模块）和奖励引导策略，在去噪采样过程中优化对齐分布

Result: 在运动生成和检索任务上的大量实验表明，该方法相比现有最先进方法显著提升了文本-运动对齐和运动质量

Conclusion: ReAlign通过奖励引导采样有效解决了扩散模型中的文本-运动对齐问题，平衡了概率密度和对齐质量

Abstract: Text-to-motion generation, which synthesizes 3D human motions from text inputs, holds immense potential for applications in gaming, film, and robotics. Recently, diffusion-based methods have been shown to generate more diversity and realistic motion. However, there exists a misalignment between text and motion distributions in diffusion models, which leads to semantically inconsistent or low-quality motions. To address this limitation, we propose Reward-guided sampling Alignment (ReAlign), comprising a step-aware reward model to assess alignment quality during the denoising sampling and a reward-guided strategy that directs the diffusion process toward an optimally aligned distribution. This reward model integrates step-aware tokens and combines a text-aligned module for semantic consistency and a motion-aligned module for realism, refining noisy motions at each timestep to balance probability density and alignment. Extensive experiments of both motion generation and retrieval tasks demonstrate that our approach significantly improves text-motion alignment and motion quality compared to existing state-of-the-art methods.

</details>


### [290] [Are Large Vision Language Models Truly Grounded in Medical Images? Evidence from Italian Clinical Visual Question Answering](https://arxiv.org/abs/2511.19220)
*Federico Felizzi,Olivia Riccomi,Michele Ferramola,Francesco Andrea Causio,Manuel Del Medico,Vittorio De Vita,Lorenzo De Mori,Alessandra Piscitelli Pietro Eric Risuleo,Bianca Destro Castaniti,Antonio Cristiano Alessia Longo,Luigi De Angelis,Mariapia Vassalli,Marcello Di Pumpo*

Main category: cs.CV

TL;DR: 该研究评估了四种前沿视觉语言模型在意大利医学问答任务中对视觉信息的真实依赖程度，发现不同模型在视觉基础能力上存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在医学视觉问答基准上表现出色，但其对视觉信息的实际依赖程度尚不明确，需要验证模型是否真正整合了视觉和文本信息。

Method: 使用欧洲医学问答意大利数据集的60个明确需要图像解释的问题，将正确的医学图像替换为空白占位符，测试GPT-4o、GPT-5-mini、Gemini 2.0 flash exp和Claude Sonnet 4.5四种模型的表现。

Result: GPT-4o显示出最强的视觉基础能力，准确率下降27.9个百分点（从83.2%降至55.3%），而其他模型准确率下降较小（GPT-5-mini下降8.5pp，Gemini下降2.4pp，Claude下降5.6pp）。所有模型都会为虚构的视觉解释生成自信的推理。

Conclusion: 不同模型在视觉依赖性和鲁棒性方面存在关键差异，在临床部署前需要进行严格的评估。

Abstract: Large vision language models (VLMs) have achieved impressive performance on medical visual question answering benchmarks, yet their reliance on visual information remains unclear. We investigate whether frontier VLMs demonstrate genuine visual grounding when answering Italian medical questions by testing four state-of-the-art models: Claude Sonnet 4.5, GPT-4o, GPT-5-mini, and Gemini 2.0 flash exp. Using 60 questions from the EuropeMedQA Italian dataset that explicitly require image interpretation, we substitute correct medical images with blank placeholders to test whether models truly integrate visual and textual information. Our results reveal striking variability in visual dependency: GPT-4o shows the strongest visual grounding with a 27.9pp accuracy drop (83.2% [74.6%, 91.7%] to 55.3% [44.1%, 66.6%]), while GPT-5-mini, Gemini, and Claude maintain high accuracy with modest drops of 8.5pp, 2.4pp, and 5.6pp respectively. Analysis of model-generated reasoning reveals confident explanations for fabricated visual interpretations across all models, suggesting varying degrees of reliance on textual shortcuts versus genuine visual analysis. These findings highlight critical differences in model robustness and the need for rigorous evaluation before clinical deployment.

</details>


### [291] [Percept-WAM: Perception-Enhanced World-Awareness-Action Model for Robust End-to-End Autonomous Driving](https://arxiv.org/abs/2511.19221)
*Jianhua Han,Meng Tian,Jiangtong Zhu,Fan He,Huixin Zhang,Sitong Guo,Dechang Zhu,Hao Tang,Pei Xu,Yuze Guo,Minzhe Niu,Haojie Zhu,Qichao Dong,Xuechao Yan,Siyuan Dong,Lu Hou,Qingqiu Huang,Xiaosong Jia,Hang Xu*

Main category: cs.CV

TL;DR: Percept-WAM是首个在单一视觉语言模型中隐式集成2D/3D场景理解能力的感知增强世界感知-动作模型，通过统一的World-PV和World-BEV标记机制提升自动驾驶空间感知的准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶系统在空间感知方面存在局限性，特别是在长尾场景和复杂交互中表现不稳定。现有的视觉语言模型在空间定位和理解方面较弱，导致基于这些模型构建的VLA系统感知和定位能力有限。

Method: 提出Percept-WAM模型，通过World-PV和World-BEV标记统一2D/3D感知任务，采用网格条件预测机制进行密集物体感知，结合IoU感知评分和并行自回归解码，保留预训练VLM参数以维持通用智能。

Result: 在COCO 2D检测上达到51.7/58.9 mAP，nuScenes BEV 3D检测表现优异。与轨迹解码器集成后，在nuScenes和NAVSIM上提升规划性能，在NAVSIM上超越DiffusionDrive 2.1 PMDS。

Conclusion: Percept-WAM在空间感知任务上达到或超越传统检测器和分割器，展现出强大的开放词汇和长尾泛化能力，为自动驾驶感知系统提供了有效的解决方案。

Abstract: Autonomous driving heavily relies on accurate and robust spatial perception. Many failures arise from inaccuracies and instability, especially in long-tail scenarios and complex interactions. However, current vision-language models are weak at spatial grounding and understanding, and VLA systems built on them therefore show limited perception and localization ability. To address these challenges, we introduce Percept-WAM, a perception-enhanced World-Awareness-Action Model that is the first to implicitly integrate 2D/3D scene understanding abilities within a single vision-language model (VLM). Instead of relying on QA-style spatial reasoning, Percept-WAM unifies 2D/3D perception tasks into World-PV and World-BEV tokens, which encode both spatial coordinates and confidence. We propose a grid-conditioned prediction mechanism for dense object perception, incorporating IoU-aware scoring and parallel autoregressive decoding, improving stability in long-tail, far-range, and small-object scenarios. Additionally, Percept-WAM leverages pretrained VLM parameters to retain general intelligence (e.g., logical reasoning) and can output perception results and trajectory control outputs directly. Experiments show that Percept-WAM matches or surpasses classical detectors and segmenters on downstream perception benchmarks, achieving 51.7/58.9 mAP on COCO 2D detection and nuScenes BEV 3D detection. When integrated with trajectory decoders, it further improves planning performance on nuScenes and NAVSIM, e.g., surpassing DiffusionDrive by 2.1 in PMDS on NAVSIM. Qualitative results further highlight its strong open-vocabulary and long-tail generalization.

</details>


### [292] [Learning Plug-and-play Memory for Guiding Video Diffusion Models](https://arxiv.org/abs/2511.19229)
*Selena Song,Ziming Xu,Zijun Zhang,Kun Zhou,Jiaxian Guo,Lianhui Qin,Biwei Huang*

Main category: cs.CV

TL;DR: 提出了DiT-Mem方法，通过可学习的记忆编码器为扩散Transformer视频生成模型注入世界知识，提升物理规则遵循和视频保真度


<details>
  <summary>Details</summary>
Motivation: 现有的DiT视频生成模型虽然视觉质量好，但经常违反基本物理定律和常识动态，缺乏显式的世界知识

Method: 使用堆叠的3D CNN、低通/高通滤波器和自注意力层构建记忆编码器，将参考视频映射为紧凑记忆标记，在DiT自注意力层中作为记忆使用，训练时冻结扩散主干只优化记忆编码器

Result: 在少量训练参数(150M)和10K数据样本上实现高效训练，推理时可即插即用，显著改善物理规则遵循和视频保真度

Conclusion: DiT-Mem方法有效解决了视频生成中的物理规则违反问题，为DiT模型提供了可插拔的世界知识注入机制

Abstract: Diffusion Transformer(DiT) based video generation models have recently achieved impressive visual quality and temporal coherence, but they still frequently violate basic physical laws and commonsense dynamics, revealing a lack of explicit world knowledge. In this work, we explore how to equip them with a plug-and-play memory that injects useful world knowledge. Motivated by in-context memory in Transformer-based LLMs, we conduct empirical studies to show that DiT can be steered via interventions on its hidden states, and simple low-pass and high-pass filters in the embedding space naturally disentangle low-level appearance and high-level physical/semantic cues, enabling targeted guidance. Building on these observations, we propose a learnable memory encoder DiT-Mem, composed of stacked 3D CNNs, low-/high-pass filters, and self-attention layers. The encoder maps reference videos into a compact set of memory tokens, which are concatenated as the memory within the DiT self-attention layers. During training, we keep the diffusion backbone frozen, and only optimize the memory encoder. It yields a rather efficient training process on few training parameters (150M) and 10K data samples, and enables plug-and-play usage at inference time. Extensive experiments on state-of-the-art models demonstrate the effectiveness of our method in improving physical rule following and video fidelity. Our code and data are publicly released here: https://thrcle421.github.io/DiT-Mem-Web/.

</details>


### [293] [IDSplat: Instance-Decomposed 3D Gaussian Splatting for Driving Scenes](https://arxiv.org/abs/2511.19235)
*Carl Lindström,Mahan Rafidashti,Maryam Fatemi,Lars Hammarstrand,Martin R. Oswald,Lennart Svensson*

Main category: cs.CV

TL;DR: IDSplat是一个自监督的3D高斯泼溅框架，能够在无需人工标注的情况下重建动态驾驶场景，实现实例级分解和可学习的运动轨迹。


<details>
  <summary>Details</summary>
Motivation: 现有的动态场景重建方法要么依赖昂贵的人工标注来获取物体轨迹，要么使用没有明确对象级分解的时间变化表示，导致静态和动态元素纠缠，阻碍场景分离。

Method: 将动态对象建模为经历刚性变换的连贯实例，而非非结构化时间变化基元。使用基于语言的零样本视频跟踪与激光雷达进行3D锚定，通过特征对应估计一致姿态。引入协调转向平滑方案获得时间物理一致的运动轨迹，联合优化物体姿态和高斯参数。

Result: 在Waymo Open Dataset上的实验表明，该方法在保持实例级分解的同时实现了有竞争力的重建质量，无需重新训练即可泛化到不同序列和视图密度。

Conclusion: IDSplat为大规模自动驾驶应用提供了一种实用的动态场景重建解决方案，无需人工标注即可实现高质量的实例级分解。

Abstract: Reconstructing dynamic driving scenes is essential for developing autonomous systems through sensor-realistic simulation. Although recent methods achieve high-fidelity reconstructions, they either rely on costly human annotations for object trajectories or use time-varying representations without explicit object-level decomposition, leading to intertwined static and dynamic elements that hinder scene separation. We present IDSplat, a self-supervised 3D Gaussian Splatting framework that reconstructs dynamic scenes with explicit instance decomposition and learnable motion trajectories, without requiring human annotations. Our key insight is to model dynamic objects as coherent instances undergoing rigid transformations, rather than unstructured time-varying primitives. For instance decomposition, we employ zero-shot, language-grounded video tracking anchored to 3D using lidar, and estimate consistent poses via feature correspondences. We introduce a coordinated-turn smoothing scheme to obtain temporally and physically consistent motion trajectories, mitigating pose misalignments and tracking failures, followed by joint optimization of object poses and Gaussian parameters. Experiments on the Waymo Open Dataset demonstrate that our method achieves competitive reconstruction quality while maintaining instance-level decomposition and generalizes across diverse sequences and view densities without retraining, making it practical for large-scale autonomous driving applications. Code will be released.

</details>


### [294] [Adversarial Patch Attacks on Vision-Based Cargo Occupancy Estimation via Differentiable 3D Simulation](https://arxiv.org/abs/2511.19254)
*Mohamed Rissal Hedna,Sesugh Samuel Nder*

Main category: cs.CV

TL;DR: 本文研究了针对物流系统中货物占用率分类器的物理对抗性攻击，通过在完全模拟的3D环境中优化对抗性补丁，证明了3D优化补丁在拒绝服务攻击（空到满）中达到84.94%的成功率。


<details>
  <summary>Details</summary>
Motivation: 随着计算机视觉系统在物流运营中的广泛应用，货物占用率估计系统可能面临物理对抗性攻击的威胁，特别是可打印并放置在内部表面的对抗性补丁。

Method: 使用Mitsuba 3进行可微分渲染，在几何、光照和视角变化的情况下优化补丁纹理，并与2D合成基线进行比较。

Result: 3D优化补丁在拒绝服务攻击（空到满）中达到84.94%的成功率，隐蔽攻击（满到空）达到30.32%的成功率。

Conclusion: 这是首个在物理真实的完全模拟3D场景中研究货物占用率估计对抗性补丁攻击的工作，强调了自动化物流管道安全性的重要性，并指出了增强物理鲁棒性的方向。

Abstract: Computer vision systems are increasingly adopted in modern logistics operations, including the estimation of trailer occupancy for planning, routing, and billing. Although effective, such systems may be vulnerable to physical adversarial attacks, particularly adversarial patches that can be printed and placed on interior surfaces. In this work, we study the feasibility of such attacks on a convolutional cargo-occupancy classifier using fully simulated 3D environments. Using Mitsuba 3 for differentiable rendering, we optimize patch textures across variations in geometry, lighting, and viewpoint, and compare their effectiveness to a 2D compositing baseline. Our experiments demonstrate that 3D-optimized patches achieve high attack success rates, especially in a denial-of-service scenario (empty to full), where success reaches 84.94 percent. Concealment attacks (full to empty) prove more challenging but still reach 30.32 percent. We analyze the factors influencing attack success, discuss implications for the security of automated logistics pipelines, and highlight directions for strengthening physical robustness. To our knowledge, this is the first study to investigate adversarial patch attacks for cargo-occupancy estimation in physically realistic, fully simulated 3D scenes.

</details>


### [295] [LAST: LeArning to Think in Space and Time for Generalist Vision-Language Models](https://arxiv.org/abs/2511.19261)
*Shuai Wang,Daoan Zhang,Tianyi Bai,Shitong Shao,Jiebo Luo,Jiaheng Wei*

Main category: cs.CV

TL;DR: LAST方法通过让视觉语言模型在空间和时间维度上进行视觉思考，联合提升3D空间理解和长视频理解能力，仅使用2D图像作为输入。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的视觉语言模型在典型视觉语言任务上表现出色，但在3D空间理解和长视频理解方面仍有困难，需要专门的设计来分别处理这两类任务。

Method: 提出LAST方法，让VLMs在给出最终答案前进行空间和时间维度的视觉思考，构建3D空间和时间维度的视觉思考轨迹。支持零样本提示专有模型和微调通用VLMs两种场景。

Result: 在多种基准测试中取得显著提升，包括3个空间理解、4个视频理解和3个图像理解任务。GPT-4o在EgoSchema上零样本提升15.8%，Qwen2.5-VL-7B在VSI-Bench上提升8.3%。

Conclusion: LAST方法通过联合训练空间和时间理解能力，有效提升了VLMs在3D空间和长视频理解方面的性能，证明了视觉思考轨迹的重要性。

Abstract: Humans can perceive and understand 3D space and long videos from sequential visual observations. But do vision-language models (VLMs) can? Recent work demonstrates that even state-of-the-art VLMs still struggle to understand 3D space and long videos, although they are powerful in typical vision-language tasks. Current methods often rely on specialized architectural designs to improve performance for 3D tasks and video understanding tasks separately. In contrast, we propose LAST, short for LeArn to Think in Space and Time, to jointly improve 3D spatial and long video understanding for general VLMs with only a set of 2D images as inputs. LAST makes VLMs think in space and time rather than only with text before giving the final answer, building visual thinking trajectories in 3D space and temporal dimension. We demonstrate the effectiveness of LAST in two scenarios: 1) zero-shot, where we directly prompt proprietary models; and 2) fine-tuning general VLMs with data that include thinking trajectories in 3D space and time. We show that LAST brings substantial gains in various benchmarks, including 3 spatial understanding, 4 video understanding, and 3 image understanding tasks. Notably, 15.8% gains on EgoSchema with GPT-4o in a zero-shot manner and 8.3 gains on VSI-Bench compared with Qwen2.5-VL-7B.

</details>


### [296] [BideDPO: Conditional Image Generation with Simultaneous Text and Condition Alignment](https://arxiv.org/abs/2511.19268)
*Dewei Zhou,Mingwei Li,Zongxin Yang,Yu Lu,Yunqiu Xu,Zhizhong Wang,Zeyi Huang,Yi Yang*

Main category: cs.CV

TL;DR: 本文提出BideDPO框架，通过双向解耦的偏好优化方法解决条件图像生成中文本与条件图像之间的冲突问题，显著提升文本成功率和条件遵循度。


<details>
  <summary>Details</summary>
Motivation: 当前条件图像生成方法在处理文本提示与条件图像之间的冲突时存在困难，包括输入级冲突和模型偏置冲突。标准的监督微调方法难以提供细致解决方案，而现有的偏好优化技术存在梯度纠缠问题。

Method: 提出双向解耦DPO框架（BideDPO），创建两个解耦的偏好对（分别针对条件和文本），采用自适应损失平衡策略进行优化。开发自动化数据管道采样模型输出并生成冲突感知数据，嵌入迭代优化策略中。

Result: 实验表明BideDPO显著提升文本成功率（如+35%）和条件遵循度。在COCO数据集上的验证也证实了方法的有效性。

Conclusion: BideDPO框架有效解决了条件图像生成中的冲突问题，通过解耦优化策略实现了更好的文本-条件对齐效果。

Abstract: Conditional image generation enhances text-to-image synthesis with structural, spatial, or stylistic priors, but current methods face challenges in handling conflicts between sources. These include 1) input-level conflicts, where the conditioning image contradicts the text prompt, and 2) model-bias conflicts, where generative biases disrupt alignment even when conditions match the text. Addressing these conflicts requires nuanced solutions, which standard supervised fine-tuning struggles to provide. Preference-based optimization techniques like Direct Preference Optimization (DPO) show promise but are limited by gradient entanglement between text and condition signals and lack disentangled training data for multi-constraint tasks. To overcome this, we propose a bidirectionally decoupled DPO framework (BideDPO). Our method creates two disentangled preference pairs-one for the condition and one for the text-to reduce gradient entanglement. The influence of pairs is managed using an Adaptive Loss Balancing strategy for balanced optimization. We introduce an automated data pipeline to sample model outputs and generate conflict-aware data. This process is embedded in an iterative optimization strategy that refines both the model and the data. We construct a DualAlign benchmark to evaluate conflict resolution between text and condition. Experiments show BideDPO significantly improves text success rates (e.g., +35%) and condition adherence. We also validate our approach using the COCO dataset. Project Pages: https://limuloo.github.io/BideDPO/.

</details>


### [297] [Diffusion Reconstruction-based Data Likelihood Estimation for Core-Set Selection](https://arxiv.org/abs/2511.19274)
*Mingyang Chen,Jiawei Du,Bo Huang,Yi Wang,Xiaobo Zhang,Wei Wang*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散模型重建偏差的数据选择新方法，通过部分逆去噪过程估计数据似然，为数据选择提供理论依据。


<details>
  <summary>Details</summary>
Motivation: 现有核心集选择方法主要依赖启发式评分信号（如训练动态或模型不确定性），缺乏对数据似然的显式建模，这可能导致构建的子集无法捕捉到支撑有效模型训练的微妙但关键的分布结构。

Method: 利用扩散模型通过部分逆去噪过程诱导的重建偏差来估计数据似然，基于马尔可夫扩散过程的证据下界（ELBO）建立重建误差与数据似然之间的形式化联系，并提出高效的信息论方法确定最优重建时间步。

Result: 在ImageNet上的广泛实验表明，重建偏差提供了有效的评分标准，在不同选择比率下始终优于现有基线，仅使用50%数据即可接近全数据训练效果。

Conclusion: 基于似然的评分方法在数据选择中揭示了信息性见解，阐明了数据分布特征与模型学习偏好之间的相互作用。

Abstract: Existing core-set selection methods predominantly rely on heuristic scoring signals such as training dynamics or model uncertainty, lacking explicit modeling of data likelihood. This omission may hinder the constructed subset from capturing subtle yet critical distributional structures that underpin effective model training. In this work, we propose a novel, theoretically grounded approach that leverages diffusion models to estimate data likelihood via reconstruction deviation induced by partial reverse denoising. Specifically, we establish a formal connection between reconstruction error and data likelihood, grounded in the Evidence Lower Bound (ELBO) of Markovian diffusion processes, thereby enabling a principled, distribution-aware scoring criterion for data selection. Complementarily, we introduce an efficient information-theoretic method to identify the optimal reconstruction timestep, ensuring that the deviation provides a reliable signal indicative of underlying data likelihood. Extensive experiments on ImageNet demonstrate that reconstruction deviation offers an effective scoring criterion, consistently outperforming existing baselines across selection ratios, and closely matching full-data training using only 50% of the data. Further analysis shows that the likelihood-informed nature of our score reveals informative insights in data selection, shedding light on the interplay between data distributional characteristics and model learning preferences.

</details>


### [298] [ReMatch: Boosting Representation through Matching for Multimodal Retrieval](https://arxiv.org/abs/2511.19278)
*Qianying Liu,Xiao Liang,Zhiqiang Zhang,Yibo Chen,Xu Tang,Zhongfei Qing,Fengfan Zhou,Yao Hu,Paul Henderson*

Main category: cs.CV

TL;DR: ReMatch是一个利用多模态大语言模型（MLLMs）生成能力进行多模态检索的框架，通过端到端训练和生成式匹配阶段实现更优的检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法将MLLMs视为简单编码器，忽略了其生成特性，未能充分利用其组合推理和世界知识。ReMatch旨在通过生成式匹配更好地利用MLLMs的能力。

Method: 1. 端到端训练嵌入MLLM；2. 使用相同MLLM进行自回归生成式匹配决策；3. 多视图输入（原始数据和投影嵌入）；4. 多可学习令牌增强输入；5. 结合对比损失和实例级判别监督。

Result: 在Massive Multimodal Embedding Benchmark (MMEB)上达到新的最先进水平，在五个数据集上显示出特别强的零样本泛化结果。

Conclusion: ReMatch框架通过生成式匹配和多令牌增强，有效提升了多模态检索的性能和泛化能力，证明了利用MLLMs生成特性的优势。

Abstract: We present ReMatch, a framework that leverages the generative strength of MLLMs for multimodal retrieval. Previous approaches treated an MLLM as a simple encoder, ignoring its generative nature, and under-utilising its compositional reasoning and world knowledge. We instead train the embedding MLLM end-to-end with a chat-style generative matching stage. The matching stage uses the same MLLM to autoregressively decide relevance from multi-view inputs, including both raw data and its own projected embeddings for each query and document. It provides instance-wise discrimination supervision that complements a standard contrastive loss, offering stronger gradients on hard negatives and preserving the compositional strengths of the original MLLM. To obtain semantically richer multimodal embeddings, we use multiple learnable tokens to augment each input, generating fine-grained contextual, mutually orthogonal embeddings with low inference cost. Leveraging our established high-performance baseline,we assemble the ideas mentioned above into a powerful training recipe and achieve a new state-of-the-art on the Massive Multimodal Embedding Benchmark (MMEB). Our experiments show particularly strong zero-shot generalization results on five datasets, highlighting the robustness and transferability of ReMatch.

</details>


### [299] [DensifyBeforehand: LiDAR-assisted Content-aware Densification for Efficient and Quality 3D Gaussian Splatting](https://arxiv.org/abs/2511.19294)
*Phurtivilai Patt,Leyang Huang,Yinqiang Zhang,Yang Lei*

Main category: cs.CV

TL;DR: 本文提出了一种新的预密集化方法，通过结合稀疏LiDAR数据和单目深度估计来改进3D高斯泼溅的初始化，避免了传统自适应密度控制带来的浮点伪影和资源浪费问题。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯泼溅方法依赖自适应密度控制，容易产生浮点伪影和资源使用效率低下的问题，需要一种更高效的初始化策略。

Method: 采用预密集化方法，结合稀疏LiDAR数据和RGB图像的单目深度估计，使用ROI感知采样方案优先处理语义和几何重要区域，生成密集点云。

Result: 该方法在保持与最先进技术相当结果的同时，显著降低了资源消耗和训练时间，在四个新收集的数据集上验证了有效性。

Conclusion: 预密集化方法有效解决了3D高斯泼溅的初始化问题，提高了视觉质量和计算效率，为复杂场景中的感兴趣区域保护提供了有效解决方案。

Abstract: This paper addresses the limitations of existing 3D Gaussian Splatting (3DGS) methods, particularly their reliance on adaptive density control, which can lead to floating artifacts and inefficient resource usage. We propose a novel densify beforehand approach that enhances the initialization of 3D scenes by combining sparse LiDAR data with monocular depth estimation from corresponding RGB images. Our ROI-aware sampling scheme prioritizes semantically and geometrically important regions, yielding a dense point cloud that improves visual fidelity and computational efficiency. This densify beforehand approach bypasses the adaptive density control that may introduce redundant Gaussians in the original pipeline, allowing the optimization to focus on the other attributes of 3D Gaussian primitives, reducing overlap while enhancing visual quality. Our method achieves comparable results to state-of-the-art techniques while significantly lowering resource consumption and training time. We validate our approach through extensive comparisons and ablation studies on four newly collected datasets, showcasing its effectiveness in preserving regions of interest in complex scenes.

</details>


### [300] [IDEAL-M3D: Instance Diversity-Enriched Active Learning for Monocular 3D Detection](https://arxiv.org/abs/2511.19301)
*Johannes Meier,Florian Günther,Riccardo Marin,Oussema Dhaouadi,Jacques Kaiser,Daniel Cremers*

Main category: cs.CV

TL;DR: IDEAL-M3D是首个针对单目3D检测的实例级主动学习框架，通过多样性驱动的集成方法解决了现有方法选择整张图像和偏向深度模糊对象的局限性，仅用60%标注就能达到全数据集训练的性能。


<details>
  <summary>Details</summary>
Motivation: 单目3D检测需要大量昂贵标注，现有主动学习方法存在两个问题：1）选择整张图像效率低，非信息性实例也被标注；2）基于不确定性的选择偏向深度模糊的远距离对象，忽视近距离对象。

Method: 提出实例级主动学习管道IDEAL-M3D，使用异构骨干网络和任务无关特征、损失权重扰动、时间相关bagging等方法构建快速训练的多样性集成模型，实现更好的多样性驱动样本选择。

Result: 在KITTI验证集和测试集上，仅使用60%的标注就能达到与全数据集训练相同或更好的AP3D性能，实现了显著的资源节省。

Conclusion: IDEAL-M3D证明了实例级选择和多样性集成在单目3D检测主动学习中的有效性，为标注资源受限场景提供了高效解决方案。

Abstract: Monocular 3D detection relies on just a single camera and is therefore easy to deploy. Yet, achieving reliable 3D understanding from monocular images requires substantial annotation, and 3D labels are especially costly. To maximize performance under constrained labeling budgets, it is essential to prioritize annotating samples expected to deliver the largest performance gains. This prioritization is the focus of active learning. Curiously, we observed two significant limitations in active learning algorithms for 3D monocular object detection. First, previous approaches select entire images, which is inefficient, as non-informative instances contained in the same image also need to be labeled. Secondly, existing methods rely on uncertainty-based selection, which in monocular 3D object detection creates a bias toward depth ambiguity. Consequently, distant objects are selected, while nearby objects are overlooked.
  To address these limitations, we propose IDEAL-M3D, the first instance-level pipeline for monocular 3D detection. For the first time, we demonstrate that an explicitly diverse, fast-to-train ensemble improves diversity-driven active learning for monocular 3D. We induce diversity with heterogeneous backbones and task-agnostic features, loss weight perturbation, and time-dependent bagging. IDEAL-M3D shows superior performance and significant resource savings: with just 60% of the annotations, we achieve similar or better AP3D on KITTI validation and test set results compared to training the same detector on the whole dataset.

</details>


### [301] [Dual-Granularity Semantic Prompting for Language Guidance Infrared Small Target Detection](https://arxiv.org/abs/2511.19306)
*Zixuan Wang,Haoran Sun,Jiaming Lu,Wenxuan Wang,Zhongling Huang,Dingwen Zhang,Xuelin Qian,Junwei Han*

Main category: cs.CV

TL;DR: 本文提出DGSPNet，一种端到端的语言提示驱动框架，通过双粒度语义提示（粗粒度文本先验和细粒度个性化语义描述）来提升红外小目标检测性能，解决了现有方法因文本描述不准确和依赖人工标注而受限的问题。


<details>
  <summary>Details</summary>
Motivation: 红外小目标检测面临特征表示有限和背景干扰严重的问题，导致性能不佳。现有基于CLIP的方法尝试利用文本指导进行检测，但受限于不准确的文本描述和对人工标注的依赖。

Method: 提出DGSPNet框架，集成双粒度语义提示：粗粒度文本先验（如'红外图像'、'小目标'）和通过图像空间内视觉到文本映射得到的细粒度个性化语义描述。引入文本引导通道注意力（TGCA）和文本引导空间注意力（TGSA）机制，增强模型在低层和高层特征空间对潜在目标的敏感性。

Result: 在三个基准数据集上的大量实验表明，该方法显著提高了检测精度，达到了最先进的性能。

Conclusion: DGSPNet通过语言提示驱动的方式有效解决了红外小目标检测的挑战，无需依赖任何标注要求，在推理过程中能够自然利用语言提示，实现了优异的检测性能。

Abstract: Infrared small target detection remains challenging due to limited feature representation and severe background interference, resulting in sub-optimal performance. While recent CLIP-inspired methods attempt to leverage textual guidance for detection, they are hindered by inaccurate text descriptions and reliance on manual annotations. To overcome these limitations, we propose DGSPNet, an end-to-end language prompt-driven framework. Our approach integrates dual-granularity semantic prompts: coarse-grained textual priors (e.g., 'infrared image', 'small target') and fine-grained personalized semantic descriptions derived through visual-to-textual mapping within the image space. This design not only facilitates learning fine-grained semantic information but also can inherently leverage language prompts during inference without relying on any annotation requirements. By fully leveraging the precision and conciseness of text descriptions, we further introduce a text-guide channel attention (TGCA) mechanism and text-guide spatial attention (TGSA) mechanism that enhances the model's sensitivity to potential targets across both low- and high-level feature spaces. Extensive experiments demonstrate that our method significantly improves detection accuracy and achieves state-of-the-art performance on three benchmark datasets.

</details>


### [302] [Evaluating Dataset Watermarking for Fine-tuning Traceability of Customized Diffusion Models: A Comprehensive Benchmark and Removal Approach](https://arxiv.org/abs/2511.19316)
*Xincheng Wang,Hanchi Sun,Wenjun Sun,Kejun Xue,Wangqiu Zhou,Jianbo Zhang,Wei Sun,Dandan Zhu,Xiongkuo Min,Jun Jia,Zhijun Fang*

Main category: cs.CV

TL;DR: 本文针对扩散模型微调中的版权风险，提出了数据集水印的统一评估框架，并发现现有方法在真实威胁场景下存在不足，同时提出了一种实用的水印去除方法。


<details>
  <summary>Details</summary>
Motivation: 扩散模型微调技术能够复现特定图像集，但带来了版权和安全风险。数据集水印技术被提出用于确保可追溯性，但缺乏统一的评估框架。

Method: 建立通用威胁模型，引入包含通用性、可传递性和鲁棒性的综合评估框架，并通过实验评估现有方法，同时提出一种实用的水印去除方法。

Result: 实验表明，现有方法在通用性和可传递性上表现良好，对常见图像处理操作具有一定鲁棒性，但在真实威胁场景下仍存在不足。提出的水印去除方法能完全消除数据集水印而不影响微调。

Conclusion: 现有数据集水印方法在真实威胁场景下存在脆弱性，未来研究需要解决这一关键挑战。

Abstract: Recent fine-tuning techniques for diffusion models enable them to reproduce specific image sets, such as particular faces or artistic styles, but also introduce copyright and security risks. Dataset watermarking has been proposed to ensure traceability by embedding imperceptible watermarks into training images, which remain detectable in outputs even after fine-tuning. However, current methods lack a unified evaluation framework. To address this, this paper establishes a general threat model and introduces a comprehensive evaluation framework encompassing Universality, Transmissibility, and Robustness. Experiments show that existing methods perform well in universality and transmissibility, and exhibit some robustness against common image processing operations, yet still fall short under real-world threat scenarios. To reveal these vulnerabilities, the paper further proposes a practical watermark removal method that fully eliminates dataset watermarks without affecting fine-tuning, highlighting a key challenge for future research.

</details>


### [303] [SyncMV4D: Synchronized Multi-view Joint Diffusion of Appearance and Motion for Hand-Object Interaction Synthesis](https://arxiv.org/abs/2511.19319)
*Lingwei Dang,Zonghan Li,Juntong Li,Hongwen Zhang,Liang An,Yebin Liu,Qingyao Wu*

Main category: cs.CV

TL;DR: SyncMV4D是首个联合生成同步多视角手-物体交互视频和4D运动的模型，通过统一视觉先验、运动动力学和多视角几何来克服现有单视角方法和3D方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前手-物体交互生成方法存在两大问题：单视角视频方法缺乏3D几何感知导致几何失真，而3D方法依赖实验室环境的高质量数据，难以泛化到真实场景。

Method: 提出双核心创新：1）多视角联合扩散模型同时生成HOI视频和中间运动；2）扩散点对齐器将粗糙中间运动细化为全局对齐的4D度量点轨迹。建立2D外观与4D动力学的闭环互增强循环。

Result: 实验表明，该方法在视觉真实性、运动合理性和多视角一致性方面优于现有最先进方法。

Conclusion: SyncMV4D成功解决了单视角和3D方法的局限性，通过联合生成多视角视频和4D运动，实现了更好的几何感知和真实场景适应性。

Abstract: Hand-Object Interaction (HOI) generation plays a critical role in advancing applications across animation and robotics. Current video-based methods are predominantly single-view, which impedes comprehensive 3D geometry perception and often results in geometric distortions or unrealistic motion patterns. While 3D HOI approaches can generate dynamically plausible motions, their dependence on high-quality 3D data captured in controlled laboratory settings severely limits their generalization to real-world scenarios. To overcome these limitations, we introduce SyncMV4D, the first model that jointly generates synchronized multi-view HOI videos and 4D motions by unifying visual prior, motion dynamics, and multi-view geometry. Our framework features two core innovations: (1) a Multi-view Joint Diffusion (MJD) model that co-generates HOI videos and intermediate motions, and (2) a Diffusion Points Aligner (DPA) that refines the coarse intermediate motion into globally aligned 4D metric point tracks. To tightly couple 2D appearance with 4D dynamics, we establish a closed-loop, mutually enhancing cycle. During the diffusion denoising process, the generated video conditions the refinement of the 4D motion, while the aligned 4D point tracks are reprojected to guide next-step joint generation. Experimentally, our method demonstrates superior performance to state-of-the-art alternatives in visual realism, motion plausibility, and multi-view consistency.

</details>


### [304] [SteadyDancer: Harmonized and Coherent Human Image Animation with First-Frame Preservation](https://arxiv.org/abs/2511.19320)
*Jiaming Zhang,Shengming Cao,Rui Li,Xiaotong Zhao,Yutao Cui,Xinglin Hou,Gangshan Wu,Haolan Chen,Yu Xu,Limin Wang,Kai Ma*

Main category: cs.CV

TL;DR: SteadyDancer是一个基于图像到视频（I2V）范式的框架，通过条件协调机制、协同姿态调制模块和分阶段解耦目标训练管道，实现了第一帧身份保持和精确运动控制，解决了传统方法中的身份漂移和视觉伪影问题。


<details>
  <summary>Details</summary>
Motivation: 传统参考到视频（R2V）范式中的图像到运动绑定过程忽略了现实应用中常见的时空错位问题，导致身份漂移和视觉伪影等失败情况。

Method: 1. 条件协调机制：协调两个冲突条件，实现精确控制而不牺牲保真度
2. 协同姿态调制模块：生成与参考图像高度兼容的自适应连贯姿态表示
3. 分阶段解耦目标训练管道：分层优化模型以实现运动保真度、视觉质量和时间连贯性

Result: 实验表明，SteadyDancer在外观保真度和运动控制方面达到了最先进的性能，同时比同类方法需要更少的训练资源。

Conclusion: SteadyDancer是首个能够稳健确保第一帧保持的框架，实现了和谐连贯的动画效果，为人类图像动画领域提供了有效的解决方案。

Abstract: Preserving first-frame identity while ensuring precise motion control is a fundamental challenge in human image animation. The Image-to-Motion Binding process of the dominant Reference-to-Video (R2V) paradigm overlooks critical spatio-temporal misalignments common in real-world applications, leading to failures such as identity drift and visual artifacts. We introduce SteadyDancer, an Image-to-Video (I2V) paradigm-based framework that achieves harmonized and coherent animation and is the first to ensure first-frame preservation robustly. Firstly, we propose a Condition-Reconciliation Mechanism to harmonize the two conflicting conditions, enabling precise control without sacrificing fidelity. Secondly, we design Synergistic Pose Modulation Modules to generate an adaptive and coherent pose representation that is highly compatible with the reference image. Finally, we employ a Staged Decoupled-Objective Training Pipeline that hierarchically optimizes the model for motion fidelity, visual quality, and temporal coherence. Experiments demonstrate that SteadyDancer achieves state-of-the-art performance in both appearance fidelity and motion control, while requiring significantly fewer training resources than comparable methods.

</details>


### [305] [MonoMSK: Monocular 3D Musculoskeletal Dynamics Estimation](https://arxiv.org/abs/2511.19326)
*Farnoosh Koleini,Hongfei Xue,Ahmed Helmy,Pu Wang*

Main category: cs.CV

TL;DR: MonoMSK是一个从单目视频重建生物力学逼真3D人体运动的混合框架，通过结合数据驱动学习和物理模拟，同时恢复运动学和动力学参数。


<details>
  <summary>Details</summary>
Motivation: 现有的单目方法使用解剖学不准确的简化模型（如SMPL）并忽略物理规律，限制了生物力学保真度。需要开发能够从单目视频中同时恢复运动学和动力学的生物力学逼真方法。

Method: MonoMSK整合了基于transformer的逆动力学与可微分前向运动学和动力学层，通过ODE模拟建立物理调节的逆-前向循环，并使用新颖的前向-逆一致性损失来对齐运动重建与动力学推理。

Result: 在BML-MoVi、BEDLAM和OpenCap数据集上的实验表明，MonoMSK在运动学精度上显著优于现有方法，并首次实现了精确的单目动力学估计。

Conclusion: MonoMSK成功建立了数据驱动学习与物理模拟的桥梁，为从单目视频中实现生物力学逼真的3D人体运动重建提供了有效解决方案。

Abstract: Reconstructing biomechanically realistic 3D human motion - recovering both kinematics (motion) and kinetics (forces) - is a critical challenge. While marker-based systems are lab-bound and slow, popular monocular methods use oversimplified, anatomically inaccurate models (e.g., SMPL) and ignore physics, fundamentally limiting their biomechanical fidelity. In this work, we introduce MonoMSK, a hybrid framework that bridges data-driven learning and physics-based simulation for biomechanically realistic 3D human motion estimation from monocular video. MonoMSK jointly recovers both kinematics (motions) and kinetics (forces and torques) through an anatomically accurate musculoskeletal model. By integrating transformer-based inverse dynamics with differentiable forward kinematics and dynamics layers governed by ODE-based simulation, MonoMSK establishes a physics-regulated inverse-forward loop that enforces biomechanical causality and physical plausibility. A novel forward-inverse consistency loss further aligns motion reconstruction with the underlying kinetic reasoning. Experiments on BML-MoVi, BEDLAM, and OpenCap show that MonoMSK significantly outperforms state-of-the-art methods in kinematic accuracy, while for the first time enabling precise monocular kinetics estimation.

</details>


### [306] [POUR: A Provably Optimal Method for Unlearning Representations via Neural Collapse](https://arxiv.org/abs/2511.19339)
*Anjie Le,Can Peng,Yuyuan Liu,J. Alison Noble*

Main category: cs.CV

TL;DR: 本文提出了一种在表示层面进行机器遗忘的方法POUR，通过几何投影实现可证明最优的遗忘操作，在多个数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘方法通常只修改分类器而保持内部表示不变，导致遗忘不彻底。本文旨在将遗忘概念扩展到表示层面，实现更彻底的遗忘效果。

Method: 基于神经崩溃理论，利用单纯形等角紧框架的正交投影特性，提出POUR方法，包括闭式投影版本POUR-P和基于蒸馏的特征级遗忘版本POUR-D。

Result: 在CIFAR-10/100和PathMNIST数据集上的实验表明，POUR在分类级和表示级指标上都优于最先进的遗忘方法，能有效遗忘同时保留有用知识。

Conclusion: POUR方法通过表示层面的几何投影实现了可证明最优的遗忘操作，为机器遗忘提供了新的理论框架和实用工具。

Abstract: In computer vision, machine unlearning aims to remove the influence of specific visual concepts or training images without retraining from scratch. Studies show that existing approaches often modify the classifier while leaving internal representations intact, resulting in incomplete forgetting. In this work, we extend the notion of unlearning to the representation level, deriving a three-term interplay between forgetting efficacy, retention fidelity, and class separation. Building on Neural Collapse theory, we show that the orthogonal projection of a simplex Equiangular Tight Frame (ETF) remains an ETF in a lower dimensional space, yielding a provably optimal forgetting operator. We further introduce the Representation Unlearning Score (RUS) to quantify representation-level forgetting and retention fidelity. Building on this, we introduce POUR (Provably Optimal Unlearning of Representations), a geometric projection method with closed-form (POUR-P) and a feature-level unlearning variant under a distillation scheme (POUR-D). Experiments on CIFAR-10/100 and PathMNIST demonstrate that POUR achieves effective unlearning while preserving retained knowledge, outperforming state-of-the-art unlearning methods on both classification-level and representation-level metrics.

</details>


### [307] [Syn-GRPO: Self-Evolving Data Synthesis for MLLM Perception Reasoning](https://arxiv.org/abs/2511.19343)
*Qihan Huang,Haofei Zhang,Rong Wei,Yi Wang,Rui Tang,Mingli Song,Jie Song*

Main category: cs.CV

TL;DR: Syn-GRPO通过在线数据生成器合成高质量训练数据，解决了MLLM强化学习中数据质量低、响应多样性不足的问题，在三个视觉感知任务上显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM强化学习方法面临数据质量低的问题，样本无法激发MLLM产生多样响应，限制了探索范围。虽然有些方法尝试通过熵约束缓解，但未从根本上解决问题。

Method: 提出Syn-GRPO方法，包含数据服务器和GRPO工作流两个组件。数据服务器使用图像生成模型从现有样本合成新样本，采用解耦异步方案提高生成效率；GRPO工作流提供新图像描述，利用多样性奖励监督MLLM预测图像描述以合成具有多样响应的样本。

Result: 在三个视觉感知任务上的实验结果表明，Syn-GRPO大幅提升了数据质量，性能显著优于现有MLLM感知方法，并展现出长期自我演化RL的潜力。

Conclusion: Syn-GRPO通过在线数据合成有效解决了MLLM强化学习中的数据质量问题，为MLLM感知能力的提升提供了新思路，具有重要的研究价值和应用前景。

Abstract: RL (reinforcement learning) methods (e.g., GRPO) for MLLM (Multimodal LLM) perception ability has attracted wide research interest owing to its remarkable generalization ability. Nevertheless, existing reinforcement learning methods still face the problem of low data quality, where data samples cannot elicit diverse responses from MLLMs, thus restricting the exploration scope for MLLM reinforcement learning. Some methods attempt to mitigate this problem by imposing constraints on entropy, but none address it at its root. Therefore, to tackle this problem, this work proposes Syn-GRPO (Synthesis-GRPO), which employs an online data generator to synthesize high-quality training data with diverse responses in GRPO training. Specifically, Syn-GRPO consists of two components: (1) data server; (2) GRPO workflow. The data server synthesizes new samples from existing ones using an image generation model, featuring a decoupled and asynchronous scheme to achieve high generation efficiency. The GRPO workflow provides the data server with the new image descriptions, and it leverages a diversity reward to supervise the MLLM to predict image descriptions for synthesizing samples with diverse responses. Experiment results across three visual perception tasks demonstrate that Syn-GRPO improves the data quality by a large margin, achieving significant superior performance to existing MLLM perception methods, and Syn-GRPO presents promising potential for scaling long-term self-evolving RL. Our code is available at https://github.com/hqhQAQ/Syn-GRPO.

</details>


### [308] [CellFMCount: A Fluorescence Microscopy Dataset, Benchmark, and Methods for Cell Counting](https://arxiv.org/abs/2511.19351)
*Abdurahman Ali Mohammed,Catherine Fonder,Ying Wei,Wallapak Tavanapong,Donald S Sakaguchi,Qi Li,Surya K. Mallapragada*

Main category: cs.CV

TL;DR: 本文介绍了一个大规模细胞计数数据集，包含3,023张图像和430,000多个细胞标注，并评估了多种细胞计数方法，其中基于SAM的SAM-Counter方法取得了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 准确的细胞计数在生物医学研究和临床应用中至关重要，但现有数据集规模有限且标注困难，限制了深度学习模型的性能。

Method: 创建大规模细胞计数数据集，并评估回归方法、人群计数方法和细胞计数方法。特别提出了基于Segment Anything Model (SAM)的密度图适配方法SAM-Counter。

Result: SAM-Counter在测试集上取得了22.12的平均绝对误差(MAE)，优于其他方法（次优MAE为27.46）。测试集细胞计数范围从10到2,126个细胞每张图像。

Conclusion: 该数据集和基准测试框架为自动化细胞计数研究提供了重要价值，SAM-Counter方法为未来研究奠定了坚实基础。

Abstract: Accurate cell counting is essential in various biomedical research and clinical applications, including cancer diagnosis, stem cell research, and immunology. Manual counting is labor-intensive and error-prone, motivating automation through deep learning techniques. However, training reliable deep learning models requires large amounts of high-quality annotated data, which is difficult and time-consuming to produce manually. Consequently, existing cell-counting datasets are often limited, frequently containing fewer than $500$ images. In this work, we introduce a large-scale annotated dataset comprising $3{,}023$ images from immunocytochemistry experiments related to cellular differentiation, containing over $430{,}000$ manually annotated cell locations. The dataset presents significant challenges: high cell density, overlapping and morphologically diverse cells, a long-tailed distribution of cell count per image, and variation in staining protocols. We benchmark three categories of existing methods: regression-based, crowd-counting, and cell-counting techniques on a test set with cell counts ranging from $10$ to $2{,}126$ cells per image. We also evaluate how the Segment Anything Model (SAM) can be adapted for microscopy cell counting using only dot-annotated datasets. As a case study, we implement a density-map-based adaptation of SAM (SAM-Counter) and report a mean absolute error (MAE) of $22.12$, which outperforms existing approaches (second-best MAE of $27.46$). Our results underscore the value of the dataset and the benchmarking framework for driving progress in automated cell counting and provide a robust foundation for future research and development.

</details>


### [309] [Growing with the Generator: Self-paced GRPO for Video Generation](https://arxiv.org/abs/2511.19356)
*Rui Li,Yuanzhi Liang,Ziqi Ni,Haibing Huang,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: Self-Paced GRPO是一种自适应的强化学习框架，通过动态调整奖励机制来解决静态奖励模型在视频生成后训练中的分布偏差和饱和问题，实现了从视觉保真度到时序一致性和语义对齐的渐进式优化。


<details>
  <summary>Details</summary>
Motivation: 现有GRPO方法使用固定容量的静态奖励模型，在训练过程中评估行为被冻结，导致分布偏差、奖励快速饱和，限制了强化学习对齐的稳定性和有效性。

Method: 提出Self-Paced GRPO框架，引入渐进式奖励机制，使奖励反馈与生成器协同进化。该机制根据生成质量自动调整奖励重点，从粗粒度视觉保真度逐步转向时序一致性和细粒度文本-视频语义对齐。

Result: 在VBench基准测试中，多个视频生成骨干网络的实验表明，Self-Paced GRPO在视觉质量和语义对齐方面均优于使用静态奖励的GRPO基线，验证了方法的有效性和通用性。

Conclusion: Self-Paced GRPO通过自适应的奖励机制缓解了奖励-策略不匹配问题，减轻了奖励利用，实现了更稳定的优化，为视频生成模型的强化学习对齐提供了更有效的解决方案。

Abstract: Group Relative Policy Optimization (GRPO) has emerged as a powerful reinforcement learning paradigm for post-training video generation models. However, existing GRPO pipelines rely on static, fixed-capacity reward models whose evaluation behavior is frozen during training. Such rigid rewards introduce distributional bias, saturate quickly as the generator improves, and ultimately limit the stability and effectiveness of reinforcement-based alignment. We propose Self-Paced GRPO, a competence-aware GRPO framework in which reward feedback co-evolves with the generator. Our method introduces a progressive reward mechanism that automatically shifts its emphasis from coarse visual fidelity to temporal coherence and fine-grained text-video semantic alignment as generation quality increases. This self-paced curriculum alleviates reward-policy mismatch, mitigates reward exploitation, and yields more stable optimization. Experiments on VBench across multiple video generation backbones demonstrate consistent improvements in both visual quality and semantic alignment over GRPO baselines with static rewards, validating the effectiveness and generality of Self-Paced GRPO.

</details>


### [310] [DeCo: Frequency-Decoupled Pixel Diffusion for End-to-End Image Generation](https://arxiv.org/abs/2511.19365)
*Zehong Ma,Longhui Wei,Shuai Wang,Shiliang Zhang,Qi Tian*

Main category: cs.CV

TL;DR: DeCo提出了一种频率解耦的像素扩散框架，通过分离高频细节和低频语义的生成，提高像素扩散模型的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有像素扩散模型在单一扩散变换器中同时建模高频信号和低频语义，导致训练和推理速度慢。作者希望探索更高效的像素扩散范式。

Method: 使用轻量级像素解码器生成高频细节，让DiT专注于低频语义建模；引入频率感知流匹配损失，强调视觉显著频率并抑制不重要的频率。

Result: 在ImageNet上达到FID 1.62（256×256）和2.22（512×512），缩小了与潜在扩散方法的差距；文本到图像模型在GenEval系统级比较中获得0.86的领先总分。

Conclusion: DeCo通过频率解耦实现了高效的像素扩散，在保持高质量生成的同时提升了速度，为像素扩散模型提供了新的发展方向。

Abstract: Pixel diffusion aims to generate images directly in pixel space in an end-to-end fashion. This approach avoids the limitations of VAE in the two-stage latent diffusion, offering higher model capacity. Existing pixel diffusion models suffer from slow training and inference, as they usually model both high-frequency signals and low-frequency semantics within a single diffusion transformer (DiT). To pursue a more efficient pixel diffusion paradigm, we propose the frequency-DeCoupled pixel diffusion framework. With the intuition to decouple the generation of high and low frequency components, we leverage a lightweight pixel decoder to generate high-frequency details conditioned on semantic guidance from the DiT. This thus frees the DiT to specialize in modeling low-frequency semantics. In addition, we introduce a frequency-aware flow-matching loss that emphasizes visually salient frequencies while suppressing insignificant ones. Extensive experiments show that DeCo achieves superior performance among pixel diffusion models, attaining FID of 1.62 (256x256) and 2.22 (512x512) on ImageNet, closing the gap with latent diffusion methods. Furthermore, our pretrained text-to-image model achieves a leading overall score of 0.86 on GenEval in system-level comparison. Codes are publicly available at https://github.com/Zehong-Ma/DeCo.

</details>


### [311] [An Anatomy Aware Hybrid Deep Learning Framework for Lung Cancer Tumor Stage Classification](https://arxiv.org/abs/2511.19367)
*Saniah Kayenat Chowdhury,Rusab Sarmun,Muhammad E. H. Chowdhury,Sohaib Bassam Zoghoul,Israa Al-Hashimi,Adam Mushtak,Amith Khandakar*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Accurate lung cancer tumor staging is crucial for prognosis and treatment planning. However, it remains challenging for end-to-end deep learning approaches, as such approaches often overlook spatial and anatomical information that are central to the tumor-node-metastasis system. The tumor stage depends on multiple quantitative criteria, including the tumor size and its proximity to the nearest anatomical structures, and small variations can alter the staging outcome. We propose a medically grounded hybrid pipeline that performs staging by explicitly measuring the tumor's size and distance properties rather than treating it as a pure image classification task. Our method employs specialized encoder-decoder networks to precisely segment the lung and adjacent anatomy, including the lobes, tumor, mediastinum, and diaphragm. Subsequently, we extract the necessary tumor properties, i.e. measure the largest tumor dimension and calculate the distance between the tumor and neighboring anatomical structures by a quantitative analysis of the segmentation masks. Finally, we apply rule-based tumor staging aligned with the medical guidelines. This novel framework has been evaluated on the Lung-PET-CT-Dx dataset, demonstrating superior performance compared to traditional deep learning models, achieving an overall classification accuracy of 91.36%. We report the per-stage F1-scores of 0.93 (T1), 0.89 (T2), 0.96 (T3), and 0.90 (T4), a critical evaluation aspect often omitted in prior literature. To our knowledge, this is the first study that embeds explicit clinical context into tumor stage classification. Unlike standard convolutional neural networks that operate in an uninterpretable "black box" manner, our method offers both state-of-the-art performance and transparent decision support.

</details>


### [312] [UISearch: Graph-Based Embeddings for Multimodal Enterprise UI Screenshots Retrieval](https://arxiv.org/abs/2511.19380)
*Maroun Ayli,Youssef Bakouny,Tushar Sharma,Nader Jalloul,Hani Seifeddine,Rima Kilany*

Main category: cs.CV

TL;DR: 提出了一种基于图表示的用户界面搜索框架UISearch，通过将UI截图转换为属性图来编码层次关系和空间布局，结合对比图自编码器学习多模态嵌入，在金融软件UI数据集上实现了高精度和低延迟的搜索性能。


<details>
  <summary>Details</summary>
Motivation: 企业软件拥有大量用户界面屏幕，现有方法依赖视觉相似性或文本语义，缺乏对UI组成结构属性的显式建模，难以保证设计一致性、模式发现和合规检查。

Method: 将UI截图转换为属性图表示，使用对比图自编码器学习嵌入，保留视觉、结构和语义的多层次相似性，构建多模态搜索框架UISearch。

Result: 在20,396个金融软件UI上，UISearch达到0.92的Top-5准确率，中位延迟47.5ms（P95:124ms），可扩展到2万+屏幕，优于仅依赖视觉的方法。

Conclusion: 结构嵌入比最先进的视觉编码器具有更好的判别能力，代表了UI表示表达能力的根本进步，支持复杂查询和细粒度UI区分。

Abstract: Enterprise software companies maintain thousands of user interface screens across products and versions, creating critical challenges for design consistency, pattern discovery, and compliance check. Existing approaches rely on visual similarity or text semantics, lacking explicit modeling of structural properties fundamental to user interface (UI) composition. We present a novel graph-based representation that converts UI screenshots into attributed graphs encoding hierarchical relationships and spatial arrangements, potentially generalizable to document layouts, architectural diagrams, and other structured visual domains. A contrastive graph autoencoder learns embeddings preserving multi-level similarity across visual, structural, and semantic properties. The comprehensive analysis demonstrates that our structural embeddings achieve better discriminative power than state-of-the-art Vision Encoders, representing a fundamental advance in the expressiveness of the UI representation. We implement this representation in UISearch, a multi-modal search framework that combines structural embeddings with semantic search through a composable query language. On 20,396 financial software UIs, UISearch achieves 0.92 Top-5 accuracy with 47.5ms median latency (P95: 124ms), scaling to 20,000+ screens. The hybrid indexing architecture enables complex queries and supports fine-grained UI distinction impossible with vision-only approaches.

</details>


### [313] [BackSplit: The Importance of Sub-dividing the Background in Biomedical Lesion Segmentation](https://arxiv.org/abs/2511.19394)
*Rachit Saluja,Asli Cihangir,Ruining Deng,Johannes C. Paetzold,Fengbei Liu,Mert R. Sabuncu*

Main category: cs.CV

TL;DR: 论文提出BackSplit方法，通过将背景类细分为多个解剖结构类别来提升小病灶分割性能，无需增加推理成本。


<details>
  <summary>Details</summary>
Motivation: 传统病灶分割将所有非病灶像素归为单一背景类，忽略了丰富的解剖背景信息。实际上背景由多种组织、器官等结构组成，这种异质性建模不足限制了小病灶分割性能。

Method: BackSplit方法：在训练时使用细粒度标签将背景类细分为多个解剖结构子类，通过增加Fisher信息量来提升模型性能，支持手动标注或使用预训练模型自动生成辅助标签。

Result: 在多数据集和架构上的实验表明，BackSplit能一致提升小病灶分割性能，即使使用自动生成的辅助标签也有效，且与交互式分割框架兼容。

Conclusion: BackSplit是一种简单有效的范式，通过背景细分充分利用解剖上下文信息，显著提升小病灶分割性能，具有鲁棒性和广泛适用性。

Abstract: Segmenting small lesions in medical images remains notoriously difficult. Most prior work tackles this challenge by either designing better architectures, loss functions, or data augmentation schemes; and collecting more labeled data. We take a different view, arguing that part of the problem lies in how the background is modeled. Common lesion segmentation collapses all non-lesion pixels into a single "background" class, ignoring the rich anatomical context in which lesions appear. In reality, the background is highly heterogeneous-composed of tissues, organs, and other structures that can now be labeled manually or inferred automatically using existing segmentation models.
  In this paper, we argue that training with fine-grained labels that sub-divide the background class, which we call BackSplit, is a simple yet powerful paradigm that can offer a significant performance boost without increasing inference costs. From an information theoretic standpoint, we prove that BackSplit increases the expected Fisher Information relative to conventional binary training, leading to tighter asymptotic bounds and more stable optimization. With extensive experiments across multiple datasets and architectures, we empirically show that BackSplit consistently boosts small-lesion segmentation performance, even when auxiliary labels are generated automatically using pretrained segmentation models. Additionally, we demonstrate that auxiliary labels derived from interactive segmentation frameworks exhibit the same beneficial effect, demonstrating its robustness, simplicity, and broad applicability.

</details>


### [314] [In-Video Instructions: Visual Signals as Generative Control](https://arxiv.org/abs/2511.19401)
*Gongfan Fang,Xinyin Ma,Xinchao Wang*

Main category: cs.CV

TL;DR: 该论文提出了一种名为"视频内指令"的新范式，通过视觉信号（如叠加文本、箭头、轨迹）来指导图像到视频的生成，相比基于文本提示的控制方法更加精确和空间感知。


<details>
  <summary>Details</summary>
Motivation: 现有的视频生成模型主要依赖文本提示控制，但文本描述具有全局性和粗糙性，难以精确指定不同物体的具体动作。

Method: 通过将用户指导直接编码到视觉域中，使用叠加文本、箭头、轨迹等元素作为指令，实现空间感知和明确的物体-动作对应关系。

Result: 在Veo 3.1、Kling 2.5和Wan 2.2三个先进生成器上的实验表明，视频模型能够可靠地解释和执行这种视觉嵌入指令，特别是在复杂多物体场景中。

Conclusion: 视频内指令范式为可控图像到视频生成提供了更精确和直观的控制方式，能够有效处理多物体场景中的复杂动作指导。

Abstract: Large-scale video generative models have recently demonstrated strong visual capabilities, enabling the prediction of future frames that adhere to the logical and physical cues in the current observation. In this work, we investigate whether such capabilities can be harnessed for controllable image-to-video generation by interpreting visual signals embedded within the frames as instructions, a paradigm we term In-Video Instruction. In contrast to prompt-based control, which provides textual descriptions that are inherently global and coarse, In-Video Instruction encodes user guidance directly into the visual domain through elements such as overlaid text, arrows, or trajectories. This enables explicit, spatial-aware, and unambiguous correspondences between visual subjects and their intended actions by assigning distinct instructions to different objects. Extensive experiments on three state-of-the-art generators, including Veo 3.1, Kling 2.5, and Wan 2.2, show that video models can reliably interpret and execute such visually embedded instructions, particularly in complex multi-object scenarios.

</details>


### [315] [SAM3-Adapter: Efficient Adaptation of Segment Anything 3 for Camouflage Object Segmentation, Shadow Detection, and Medical Image Segmentation](https://arxiv.org/abs/2511.19425)
*Tianrun Chen,Runlong Cao,Xinda Yu,Lanyun Zhu,Chaotao Ding,Deyi Ji,Cheng Chen,Qi Zhu,Chunyan Xu,Papa Mao,Ying Zang*

Main category: cs.CV

TL;DR: SAM3-Adapter是首个专为Segment Anything 3（SAM3）设计的适配器框架，通过减少计算开销并提升分割精度，在医学影像、伪装物体分割和阴影检测等下游任务中达到新的最先进水平。


<details>
  <summary>Details</summary>
Motivation: 虽然SAM系列模型在图像分割领域取得了显著进展，但在细粒度、低层次的分割任务（如伪装物体检测、医学图像分割等）上仍存在局限。为了解决这些问题，作者基于更高效的SAM3模型开发了专门的适配器框架。

Method: SAM3-Adapter基于原始SAM-Adapter的模块化和可组合设计理念，专门为SAM3的重新设计架构和改进的训练流程进行优化，通过适配器机制减少计算开销并提升任务适应性。

Result: 实验证明SAM3-Adapter在多个下游任务中超越了SAM和SAM2的解决方案，在医学成像、伪装物体分割和阴影检测等任务上建立了新的最先进结果，表现出更强的泛化能力和分割精度。

Conclusion: SAM3-Adapter为未来研究和实际分割应用提供了强大的基础，其代码、预训练模型和数据处理流程均已公开。

Abstract: The rapid rise of large-scale foundation models has reshaped the landscape of image segmentation, with models such as Segment Anything achieving unprecedented versatility across diverse vision tasks. However, previous generations-including SAM and its successor-still struggle with fine-grained, low-level segmentation challenges such as camouflaged object detection, medical image segmentation, cell image segmentation, and shadow detection. To address these limitations, we originally proposed SAM-Adapter in 2023, demonstrating substantial gains on these difficult scenarios. With the emergence of Segment Anything 3 (SAM3)-a more efficient and higher-performing evolution with a redesigned architecture and improved training pipeline-we revisit these long-standing challenges. In this work, we present SAM3-Adapter, the first adapter framework tailored for SAM3 that unlocks its full segmentation capability. SAM3-Adapter not only reduces computational overhead but also consistently surpasses both SAM and SAM2-based solutions, establishing new state-of-the-art results across multiple downstream tasks, including medical imaging, camouflaged (concealed) object segmentation, and shadow detection. Built upon the modular and composable design philosophy of the original SAM-Adapter, SAM3-Adapter provides stronger generalizability, richer task adaptability, and significantly improved segmentation precision. Extensive experiments confirm that integrating SAM3 with our adapter yields superior accuracy, robustness, and efficiency compared to all prior SAM-based adaptations. We hope SAM3-Adapter can serve as a foundation for future research and practical segmentation applications. Code, pre-trained models, and data processing pipelines are available.

</details>


### [316] [Ref-SAM3D: Bridging SAM3D with Text for Reference 3D Reconstruction](https://arxiv.org/abs/2511.19426)
*Yun Zhou,Yaoting Wang,Guangquan Jie,Jinyu Liu,Henghui Ding*

Main category: cs.CV

TL;DR: Ref-SAM3D是对SAM3D的扩展，通过引入文本描述作为高级先验，实现从单张RGB图像进行文本引导的3D重建。


<details>
  <summary>Details</summary>
Motivation: SAM3D虽然具有强大的3D重建能力，但无法根据文本描述重建特定对象，这限制了其在3D编辑、游戏开发和虚拟环境等实际应用中的实用性。

Method: 在SAM3D基础上引入文本描述作为先验信息，通过自然语言指导实现零样本3D重建。

Result: 实验表明Ref-SAM3D仅通过自然语言和单张2D视图就能实现竞争性的高保真重建性能。

Conclusion: Ref-SAM3D有效弥合了2D视觉线索与3D几何理解之间的差距，为参考引导的3D重建提供了更灵活和易用的范式。

Abstract: SAM3D has garnered widespread attention for its strong 3D object reconstruction capabilities. However, a key limitation remains: SAM3D cannot reconstruct specific objects referred to by textual descriptions, a capability that is essential for practical applications such as 3D editing, game development, and virtual environments. To address this gap, we introduce Ref-SAM3D, a simple yet effective extension to SAM3D that incorporates textual descriptions as a high-level prior, enabling text-guided 3D reconstruction from a single RGB image. Through extensive qualitative experiments, we show that Ref-SAM3D, guided only by natural language and a single 2D view, delivers competitive and high-fidelity zero-shot reconstruction performance. Our results demonstrate that Ref-SAM3D effectively bridges the gap between 2D visual cues and 3D geometric understanding, offering a more flexible and accessible paradigm for reference-guided 3D reconstruction. Code is available at: https://github.com/FudanCVL/Ref-SAM3D.

</details>


### [317] [Cook and Clean Together: Teaching Embodied Agents for Parallel Task Execution](https://arxiv.org/abs/2511.19430)
*Dingkang Liang,Cheng Zhang,Xiaopeng Xu,Jianzhong Ju,Zhenbo Luo,Xiang Bai*

Main category: cs.CV

TL;DR: ORS3D是一个结合语言理解、3D空间定位和效率优化的新任务，旨在通过利用可并行子任务来最小化总完成时间。作者构建了ORS3D-60K数据集并提出了GRANT模型进行有效调度。


<details>
  <summary>Details</summary>
Motivation: 现有数据集在任务规划中往往忽略了运筹学知识和3D空间定位，无法满足智能体在3D物理世界中高效执行自然语言指令的需求。

Method: 提出了ORS3D任务和ORS3D-60K数据集，并开发了GRANT模型，该模型采用调度令牌机制来生成高效的任务调度和接地行动。

Result: 在ORS3D-60K数据集上的广泛实验验证了GRANT在语言理解、3D定位和调度效率方面的有效性。

Conclusion: ORS3D任务和GRANT模型为具身AI的任务调度提供了新的解决方案，能够有效结合语言理解、空间认知和效率优化。

Abstract: Task scheduling is critical for embodied AI, enabling agents to follow natural language instructions and execute actions efficiently in 3D physical worlds. However, existing datasets often simplify task planning by ignoring operations research (OR) knowledge and 3D spatial grounding. In this work, we propose Operations Research knowledge-based 3D Grounded Task Scheduling (ORS3D), a new task that requires the synergy of language understanding, 3D grounding, and efficiency optimization. Unlike prior settings, ORS3D demands that agents minimize total completion time by leveraging parallelizable subtasks, e.g., cleaning the sink while the microwave operates. To facilitate research on ORS3D, we construct ORS3D-60K, a large-scale dataset comprising 60K composite tasks across 4K real-world scenes. Furthermore, we propose GRANT, an embodied multi-modal large language model equipped with a simple yet effective scheduling token mechanism to generate efficient task schedules and grounded actions. Extensive experiments on ORS3D-60K validate the effectiveness of GRANT across language understanding, 3D grounding, and scheduling efficiency. The code is available at https://github.com/H-EmbodVis/GRANT

</details>


### [318] [Cloud4D](https://arxiv.org/abs/2511.19431)
*Jacob Lin,Edward Gryspeerdt,Ronald Clark*

Main category: cs.CV

TL;DR: Cloud4D是一个基于学习的框架，通过地面相机重建物理一致的4维云状态，实现25米空间分辨率和5秒时间分辨率的3D液态水含量分布估计，并能估计水平风矢量。


<details>
  <summary>Details</summary>
Motivation: 当前全球数值天气预报和气候模型大多在千米尺度运行，难以模拟单个云层和极端天气现象，需要更高分辨率模型，但现有仪器难以获取高分辨率真实观测数据。

Method: 利用同步地面相机，采用单应性引导的2D到3D变换器，推断完整的3D液态水含量分布，并通过跟踪3D液态水含量随时间变化来估计水平风矢量。

Result: 在两个月部署期间，相比最先进的卫星测量，系统实现了数量级的时空分辨率提升，同时相对于共置雷达测量的相对误差保持在个位数（<10%）。

Conclusion: Cloud4D为高分辨率云建模提供了有效解决方案，代码和数据已公开。

Abstract: There has been great progress in improving numerical weather prediction and climate models using machine learning. However, most global models act at a kilometer-scale, making it challenging to model individual clouds and factors such as extreme precipitation, wind gusts, turbulence, and surface irradiance. Therefore, there is a need to move towards higher-resolution models, which in turn require high-resolution real-world observations that current instruments struggle to obtain. We present Cloud4D, the first learning-based framework that reconstructs a physically consistent, four-dimensional cloud state using only synchronized ground-based cameras. Leveraging a homography-guided 2D-to-3D transformer, Cloud4D infers the full 3D distribution of liquid water content at 25 m spatial and 5 s temporal resolution. By tracking the 3D liquid water content retrievals over time, Cloud4D additionally estimates horizontal wind vectors. Across a two-month deployment comprising six skyward cameras, our system delivers an order-of-magnitude improvement in space-time resolution relative to state-of-the-art satellite measurements, while retaining single-digit relative error ($<10\%$) against collocated radar measurements. Code and data are available on our project page https://cloud4d.jacob-lin.com/.

</details>


### [319] [Are Image-to-Video Models Good Zero-Shot Image Editors?](https://arxiv.org/abs/2511.19435)
*Zechuan Zhang,Zhenyuan Chen,Zongxin Yang,Yi Yang*

Main category: cs.CV

TL;DR: IF-Edit是一个无需调优的框架，利用预训练的图像到视频扩散模型实现指令驱动的图像编辑，解决了提示不对齐、冗余时间潜变量和模糊后期帧三个关键挑战。


<details>
  <summary>Details</summary>
Motivation: 大规模视频扩散模型展现出强大的世界模拟和时间推理能力，但作为零样本图像编辑器的应用尚未充分探索。

Method: 包括（1）思维链提示增强模块，将静态编辑指令转换为时间基础推理提示；（2）时间潜变量丢弃策略，在专家切换点后压缩帧潜变量；（3）自一致后细化步骤，使用短静态视频轨迹锐化后期帧。

Result: 在四个公共基准测试中，IF-Edit在推理中心任务上表现强劲，同时在通用编辑任务上保持竞争力。

Conclusion: 该研究为视频扩散模型作为图像编辑器提供了系统视角，并突出了统一视频-图像生成推理的简单方法。

Abstract: Large-scale video diffusion models show strong world simulation and temporal reasoning abilities, but their use as zero-shot image editors remains underexplored. We introduce IF-Edit, a tuning-free framework that repurposes pretrained image-to-video diffusion models for instruction-driven image editing. IF-Edit addresses three key challenges: prompt misalignment, redundant temporal latents, and blurry late-stage frames. It includes (1) a chain-of-thought prompt enhancement module that transforms static editing instructions into temporally grounded reasoning prompts; (2) a temporal latent dropout strategy that compresses frame latents after the expert-switch point, accelerating denoising while preserving semantic and temporal coherence; and (3) a self-consistent post-refinement step that sharpens late-stage frames using a short still-video trajectory. Experiments on four public benchmarks, covering non-rigid editing, physical and temporal reasoning, and general instruction edits, show that IF-Edit performs strongly on reasoning-centric tasks while remaining competitive on general-purpose edits. Our study provides a systematic view of video diffusion models as image editors and highlights a simple recipe for unified video-image generative reasoning.

</details>


### [320] [LumiTex: Towards High-Fidelity PBR Texture Generation with Illumination Context](https://arxiv.org/abs/2511.19437)
*Jingzhi Bao,Hongze Chen,Lingting Zhu,Chenyu Liu,Runze Zhang,Keyang Luo,Zeyu Hu,Weikai Chen,Yingda Yin,Xin Wang,Zehong Lin,Jun Zhang,Xiaoguang Han*

Main category: cs.CV

TL;DR: LumiTex是一个端到端的PBR纹理生成框架，通过多分支生成、光照感知注意力机制和几何引导修复模块，解决了材质分解和纹理补全的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有PBR纹理生成方法无法解决两个基本挑战：1）在有限光照线索下从图像提示进行材质分解，2）无缝且视角一致的纹理补全。

Method: 包含三个关键组件：1）多分支生成方案，在共享光照先验下解耦反照率和金属粗糙度；2）光照感知材质注意力机制，将光照上下文注入解码过程；3）基于大视角合成模型的几何引导修复模块，确保无缝的UV补全。

Result: 大量实验表明，LumiTex在纹理质量方面达到最先进性能，超越了现有开源和商业方法。

Conclusion: LumiTex框架有效解决了PBR纹理生成中的材质分解和纹理补全问题，实现了高质量的物理渲染纹理生成。

Abstract: Physically-based rendering (PBR) provides a principled standard for realistic material-lighting interactions in computer graphics. Despite recent advances in generating PBR textures, existing methods fail to address two fundamental challenges: 1) materials decomposition from image prompts under limited illumination cues, and 2) seamless and view-consistent texture completion. To this end, we propose LumiTex, an end-to-end framework that comprises three key components: (1) a multi-branch generation scheme that disentangles albedo and metallic-roughness under shared illumination priors for robust material understanding, (2) a lighting-aware material attention mechanism that injects illumination context into the decoding process for physically grounded generation of albedo, metallic, and roughness maps, and (3) a geometry-guided inpainting module based on a large view synthesis model that enriches texture coverage and ensures seamless, view-consistent UV completion. Extensive experiments demonstrate that LumiTex achieves state-of-the-art performance in texture quality, surpassing both existing open-source and commercial methods.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [321] [Practical Machine Learning for Aphasic Discourse Analysis](https://arxiv.org/abs/2511.17553)
*Jason M. Pittman,Anton Phillips,Yesenia Medina-Santos,Brielle C. Stark*

Main category: cs.LG

TL;DR: 该研究评估了五种机器学习模型在失语症患者图片描述任务中自动识别正确信息单元(CIU)的可靠性，发现模型在区分单词与非单词方面表现优异，但识别CIU更具挑战性。


<details>
  <summary>Details</summary>
Motivation: CIU分析是量化失语症患者语言能力的重要方法，但临床应用中需要大量人工标注工作。机器学习技术有望自动化这一过程，减轻语言病理学家的工作负担。

Method: 使用五种监督机器学习模型，基于失语症患者的人类标注转录本和CIU数据进行训练，评估模型在单词识别和CIU识别任务上的性能。

Result: 单词识别任务中所有模型都达到接近完美的准确率(0.995)，AUC范围0.914-0.995；CIU识别任务中k-NN模型表现最佳，准确率0.824，AUC 0.787。

Conclusion: 监督机器学习模型能够有效区分单词与非单词，但准确识别CIU仍然具有挑战性，需要进一步改进模型性能。

Abstract: Analyzing spoken discourse is a valid means of quantifying language ability in persons with aphasia. There are many ways to quantify discourse, one common way being to evaluate the informativeness of the discourse. That is, given the total number of words produced, how many of those are context-relevant and accurate. This type of analysis is called Correct Information Unit (CIU) analysis and is one of the most prevalent discourse analyses used by speech-language pathologists (SLPs). Despite this, CIU analysis in the clinic remains limited due to the manual labor needed by SLPs to code and analyze collected speech. Recent advances in machine learning (ML) seek to augment such labor by automating modeling of propositional, macrostructural, pragmatic, and multimodal dimensions of discourse. To that end, this study evaluated five ML models for reliable identification of Correct Information Units (CIUs, Nicholas & Brookshire, 1993), during a picture description task. The five supervised ML models were trained using randomly selected human-coded transcripts and accompanying words and CIUs from persons with aphasia. The baseline model training produced a high accuracy across transcripts for word vs non-word, with all models achieving near perfect performance (0.995) with high AUC range (0.914 min, 0.995 max). In contrast, CIU vs non-CIU showed a greater variability, with the k-nearest neighbor (k-NN) model the highest accuracy (0.824) and second highest AUC (0.787). These findings indicate that while the supervised ML models can distinguish word from not word, identifying CIUs is challenging.

</details>


### [322] [Classification of Transient Astronomical Object Light Curves Using LSTM Neural Networks](https://arxiv.org/abs/2511.17564)
*Guilherme Grancho D. Fernandes,Marco A. Barroca,Mateus dos Santos,Rafael S. Oliveira*

Main category: cs.LG

TL;DR: 该研究使用双向LSTM神经网络对PLAsTiCC数据集中的瞬变天体光变曲线进行分类，将14个类别重组为5个广义类别以解决类别不平衡问题。模型在S-Like和Periodic类别上表现良好，但在Fast和Long类别上性能较差，且在部分光变曲线数据上性能显著下降。


<details>
  <summary>Details</summary>
Motivation: 解决天文瞬变天体光变曲线分类中的类别不平衡问题，并评估双向LSTM网络在此任务中的性能表现。

Method: 使用双向LSTM神经网络，通过填充、时间重标度和通量归一化等预处理方法，对PLAsTiCC数据集中的光变曲线进行分类。将原始14个类别重组为5个广义类别以应对类别不平衡。

Result: 模型在S-Like和Periodic类别上表现优异（ROC AUC分别为0.95和0.99），但在Fast和Long类别上性能较差（Long类ROC AUC仅0.68）。在部分光变曲线数据上性能显著下降，特别是对S-Like类别的误分类增加。

Conclusion: 类别不平衡和有限的时间信息是主要限制因素，建议采用类别平衡策略和专注于检测时刻的预处理技术来改进性能。

Abstract: This study presents a bidirectional Long Short-Term Memory (LSTM) neural network for classifying transient astronomical object light curves from the Photometric LSST Astronomical Time-series Classification Challenge (PLAsTiCC) dataset. The original fourteen object classes were reorganized into five generalized categories (S-Like, Fast, Long, Periodic, and Non-Periodic) to address class imbalance. After preprocessing with padding, temporal rescaling, and flux normalization, a bidirectional LSTM network with masking layers was trained and evaluated on a test set of 19,920 objects. The model achieved strong performance for S-Like and Periodic classes, with ROC area under the curve (AUC) values of 0.95 and 0.99, and Precision-Recall AUC values of 0.98 and 0.89, respectively. However, performance was significantly lower for Fast and Long classes (ROC AUC of 0.68 for Long class), and the model exhibited difficulty distinguishing between Periodic and Non-Periodic objects. Evaluation on partial light curve data (5, 10,and 20 days from detection) revealed substantial performance degradation, with increased misclassification toward the S-Like class. These findings indicate that class imbalance and limited temporal information are primary limitations, suggesting that class balancing strategies and preprocessing techniques focusing on detection moments could improve performance.

</details>


### [323] [Root Cause Analysis for Microservice Systems via Cascaded Conditional Learning with Hypergraphs](https://arxiv.org/abs/2511.17566)
*Shuaiyu Xie,Hanbin He,Jian Wang,Bing Li*

Main category: cs.LG

TL;DR: CCLH是一个新颖的微服务系统根因分析框架，通过级联条件学习和异构超图建模，解决了现有方法在任务依赖性和实例群体影响方面的不足，在根因定位和故障类型识别方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有根因分析方法存在两个关键问题：1）联合学习范式忽视了任务间的因果依赖关系；2）主要关注点对点关系，忽略了由部署配置和负载均衡引起的实例群体影响特性。

Method: 提出CCLH框架，采用级联条件学习来协调诊断任务，提供三级分类法描述实例间的群体影响，并引入异构超图来建模这些关系以模拟故障传播。

Result: 在三个微服务基准数据集上的大量实验表明，CCLH在根因定位和故障类型识别方面均优于现有最先进方法。

Conclusion: CCLH通过有效建模任务依赖关系和实例群体影响，显著提升了微服务系统中根因分析的性能。

Abstract: Root cause analysis in microservice systems typically involves two core tasks: root cause localization (RCL) and failure type identification (FTI). Despite substantial research efforts, conventional diagnostic approaches still face two key challenges. First, these methods predominantly adopt a joint learning paradigm for RCL and FTI to exploit shared information and reduce training time. However, this simplistic integration neglects the causal dependencies between tasks, thereby impeding inter-task collaboration and information transfer. Second, these existing methods primarily focus on point-to-point relationships between instances, overlooking the group nature of inter-instance influences induced by deployment configurations and load balancing. To overcome these limitations, we propose CCLH, a novel root cause analysis framework that orchestrates diagnostic tasks based on cascaded conditional learning. CCLH provides a three-level taxonomy for group influences between instances and incorporates a heterogeneous hypergraph to model these relationships, facilitating the simulation of failure propagation. Extensive experiments conducted on datasets from three microservice benchmarks demonstrate that CCLH outperforms state-of-the-art methods in both RCL and FTI.

</details>


### [324] [Enhancing Robustness of Offline Reinforcement Learning Under Data Corruption via Sharpness-Aware Minimization](https://arxiv.org/abs/2511.17568)
*Le Xu,Jiayu Chen*

Main category: cs.LG

TL;DR: 本文首次将Sharpness-Aware Minimization (SAM)优化器应用于离线强化学习，通过寻找更平坦的损失最小值来提高模型在数据污染情况下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习对现实世界数据污染非常脆弱，即使是鲁棒算法在具有挑战性的观测和混合污染下也会失败。这种失败源于数据污染在损失景观中创建了尖锐的最小值，导致泛化能力差。

Method: 将SAM作为通用即插即用优化器集成到离线RL基线中：IQL（在该设置中表现最佳的离线RL算法）和RIQL（专门为数据污染鲁棒性设计的算法）。在D4RL基准测试中使用随机和对抗性污染进行评估。

Result: SAM增强的方法始终显著优于原始基线。奖励表面的可视化证实SAM找到了更平滑的解，为其在提高离线RL代理鲁棒性方面的有效性提供了有力证据。

Conclusion: SAM作为一种通用优化器，能够有效提高离线强化学习在数据污染环境下的鲁棒性，通过寻找更平坦的损失最小值来改善模型的泛化性能。

Abstract: Offline reinforcement learning (RL) is vulnerable to real-world data corruption, with even robust algorithms failing under challenging observation and mixture corruptions. We posit this failure stems from data corruption creating sharp minima in the loss landscape, leading to poor generalization. To address this, we are the first to apply Sharpness-Aware Minimization (SAM) as a general-purpose, plug-and-play optimizer for offline RL. SAM seeks flatter minima, guiding models to more robust parameter regions. We integrate SAM into strong baselines for data corruption: IQL, a top-performing offline RL algorithm in this setting, and RIQL, an algorithm designed specifically for data-corruption robustness. We evaluate them on D4RL benchmarks with both random and adversarial corruption. Our SAM-enhanced methods consistently and significantly outperform the original baselines. Visualizations of the reward surface confirm that SAM finds smoother solutions, providing strong evidence for its effectiveness in improving the robustness of offline RL agents.

</details>


### [325] [Binary BPE: A Family of Cross-Platform Tokenizers for Binary Analysis](https://arxiv.org/abs/2511.17573)
*Michael J. Bommarito*

Main category: cs.LG

TL;DR: 提出了Binary BPE分词器家族，专门用于二进制分析，通过字节对编码技术有效压缩二进制内容，在固定长度的transformer上下文窗口中可容纳2-3倍于原始字节的二进制内容。


<details>
  <summary>Details</summary>
Motivation: 现有的二进制序列模型受限于字节级分词：原始字节浪费transformer的上下文窗口容量，且许多文本分词器无法处理0x00-0xFF的任意字节序列。

Method: 开发了跨平台的Byte Pair Encoding分词器，在包含Linux、Windows、macOS、Android和恶意软件的大型二进制语料库上训练，提供4K到64K词汇量的分词器。

Result: 分词器能够发现可解释的模式（如ELF/PE头文件、指令序列、跨平台字符串），同时实现每个token的多字节压缩，在未压缩可执行文件上效果显著。

Conclusion: Binary BPE分词器为二进制分析提供了更高效的工具，支持内容识别、恶意软件检测、逆向工程等应用，已在HuggingFace上开源发布。

Abstract: Sequence models for binary analysis are bottlenecked by byte-level tokenization: raw bytes waste precious context window capacity for transformers and other neural network architectures, and many existing text-oriented tokenizers fail on arbitrary 0x00--0xFF sequences. To address this issue, we introduce the Binary BPE tokenizer family, a set of cross-platform Byte Pair Encoding (BPE) tokenizers for executables trained on a large corpus of binaries spanning multiple platforms, architectures, and operating systems, including Linux, Windows, macOS, Android, and malware sources. We release trained tokenizers with vocabularies of 4K, 8K, 16K, 32K, and 64K tokens, enabling both systematic scaling studies and practical deployment from resource-constrained edge devices to high-throughput datacenters. These tokenizers discover interpretable patterns (ELF/PE headers, instruction sequences, cross-platform strings) while yielding multi-byte compression per token. On representative uncompressed executables (e.g., ELF/PE/Mach-O rather than compressed APKs), the Binary BPE tokenizers typically allow for roughly 2-3x more binary content per fixed-length transformer context window than raw bytes, enabling more efficient research and practical deployment for content identification, malware detection, reverse engineering, and optimization. We release the trained Binary BPE tokenizers on HuggingFace, providing a drop-in, open-source foundation for binary-focused language models and context-efficient agentic tools.

</details>


### [326] [Efficient Mathematical Reasoning Models via Dynamic Pruning and Knowledge Distillation](https://arxiv.org/abs/2511.17577)
*Fengming Yu,Qingyu Meng,Haiwei Pan,Kejia Zhang*

Main category: cs.LG

TL;DR: 提出了一种结合动态注意力头剪枝和知识蒸馏的轻量化优化方法，在保持数学推理能力的同时显著提升大语言模型的效率。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在数学推理等复杂任务上表现出色，但计算和存储成本高昂，限制了实际部署。需要一种轻量化方法在保持性能的同时提升效率。

Method: 动态评估多头注意力机制中每个注意力头的重要性（基于权重范数和熵），实时剪枝冗余头以减少计算开销，并通过知识蒸馏将原始模型信息迁移到剪枝后的学生模型中。

Result: 在Math23k数据集上，30%剪枝率下参数减少18.7%，推理速度提升27.5%，FLOPs降低19.3%，准确率仅下降0.7%（从84.4%降至83.7%）。

Conclusion: 该方法在保持强大推理性能的同时实现了显著的效率提升，为大语言模型在数学推理任务中的高效部署提供了实用解决方案。

Abstract: With the rapid development of deep learning, large language models have shown strong capabilities in complex reasoning tasks such as mathematical equation solving. However, their substantial computational and storage costs hinder practical deployment. This paper proposes a lightweight optimization method that integrates dynamic attention head pruning with knowledge distillation. The approach dynamically evaluates the importance of each attention head in the multi-head attention mechanism using a combination of weight norms and entropy, and prunes redundant heads in real time to reduce computational overhead. To mitigate performance degradation, knowledge distillation transfers information from the original model to the pruned student, enabling the smaller model to preserve reasoning ability. Experiments conducted on both Math23k and ASDiv-A verify the effectiveness of the proposed method. For example, on Math23k with a 30% pruning ratio, parameters are reduced by 18.7%, inference speed is improved by 27.5%, FLOPs are reduced by 19.3%, and accuracy drops only 0.7% (from 84.4% to 83.7%). These results demonstrate that the method achieves substantial efficiency gains while maintaining strong reasoning performance, providing a practical solution for efficient deployment of large language models in mathematical reasoning tasks.

</details>


### [327] [Multi-Value Alignment for LLMs via Value Decorrelation and Extrapolation](https://arxiv.org/abs/2511.17579)
*Hefei Xu,Le Wu,Chen Cheng,Hao Liu*

Main category: cs.LG

TL;DR: 提出了一种名为MVA的新框架来解决多价值对齐问题，通过最小化价值间互信息来缓解参数干扰，并采用价值外推策略探索帕累托前沿，实验证明MVA优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速发展，如何使其与人类价值观对齐以确保安全和伦理成为关键挑战。现有方法（如RLHF和DPO）在多价值对齐中存在不稳定、效率低且无法有效处理价值冲突的问题。

Method: 提出MVA框架，通过最小化不同人类价值之间的互信息来缓解参数干扰，并采用价值外推策略高效探索帕累托前沿，构建具有不同价值偏好的LLMs集合。

Result: 大量实验表明，MVA在多价值对齐任务中始终优于现有基线方法。

Conclusion: MVA框架有效解决了多价值对齐中的挑战，能够更好地平衡多个可能冲突的人类价值，为大语言模型的安全和伦理对齐提供了新思路。

Abstract: With the rapid advancement of large language models (LLMs), aligning them with human values for safety and ethics has become a critical challenge. This problem is especially challenging when multiple, potentially conflicting human values must be considered and balanced. Although several variants of existing alignment methods (such as Reinforcement Learning from Human Feedback (RLHF) and Direct Preference Optimization (DPO)) have been proposed to address multi-value alignment, they suffer from notable limitations: 1) they are often unstable and inefficient in multi-value optimization; and 2) they fail to effectively handle value conflicts. As a result, these approaches typically struggle to achieve optimal trade-offs when aligning multiple values.
  To address this challenge, we propose a novel framework called Multi-Value Alignment (MVA). It mitigates alignment degradation caused by parameter interference among diverse human values by minimizing their mutual information. Furthermore, we propose a value extrapolation strategy to efficiently explore the Pareto frontier, thereby constructing a set of LLMs with diverse value preferences. Extensive experiments demonstrate that MVA consistently outperforms existing baselines in aligning LLMs with multiple human values.

</details>


### [328] [EgoCogNav: Cognition-aware Human Egocentric Navigation](https://arxiv.org/abs/2511.17581)
*Zhiwen Qiu,Ziang Liu,Wenqian Niu,Tapomayukh Bhattacharjee,Saleh Kalantari*

Main category: cs.LG

TL;DR: EgoCogNav是一个多模态自我中心导航框架，通过融合场景特征和感官线索来预测感知路径不确定性，并联合预测轨迹和头部运动，填补了现有方法忽视人类认知因素的空白。


<details>
  <summary>Details</summary>
Motivation: 现有导航方法主要关注完全观察场景中的运动预测，忽视了人类如何感受和响应空间的人类因素。本文旨在建模人类导航的认知和体验因素，以加深对人类-环境互动的理解。

Method: 提出EgoCogNav框架，将感知路径不确定性作为潜在状态进行预测，通过融合场景特征和感官线索来联合预测轨迹和头部运动。同时构建了CEN数据集，包含6小时的真实世界自我中心记录。

Result: 实验表明，EgoCogNav能够学习到与人类类似行为（如扫描、犹豫、回溯）高度相关的感知不确定性，并且在未见过的环境中具有良好的泛化能力。

Conclusion: EgoCogNav成功地将认知因素引入导航模型，能够有效捕捉人类导航行为中的不确定性感知，为安全社交导航和辅助寻路提供了重要基础。

Abstract: Modeling the cognitive and experiential factors of human navigation is central to deepening our understanding of human-environment interaction and to enabling safe social navigation and effective assistive wayfinding. Most existing methods focus on forecasting motions in fully observed scenes and often neglect human factors that capture how people feel and respond to space. To address this gap, We propose EgoCogNav, a multimodal egocentric navigation framework that predicts perceived path uncertainty as a latent state and jointly forecasts trajectories and head motion by fusing scene features with sensory cues. To facilitate research in the field, we introduce the Cognition-aware Egocentric Navigation (CEN) dataset consisting 6 hours of real-world egocentric recordings capturing diverse navigation behaviors in real-world scenarios. Experiments show that EgoCogNav learns the perceived uncertainty that highly correlates with human-like behaviors such as scanning, hesitation, and backtracking while generalizing to unseen environments.

</details>


### [329] [GateRA: Token-Aware Modulation for Parameter-Efficient Fine-Tuning](https://arxiv.org/abs/2511.17582)
*Jie Ou,Shuaihong Jiang,Yingjun Du,Cees G. M. Snoek*

Main category: cs.LG

TL;DR: GateRA是一种新的参数高效微调方法，通过token感知的动态门控机制，根据输入重要性自适应调整PEFT更新强度，在推理任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有PEFT方法对所有token应用静态更新，忽视了不同输入的重要性和难度差异，导致在简单内容上过拟合或在重要区域上适应不足。

Method: 引入token感知调制机制，通过自适应门控动态调整PEFT更新强度；采用基于熵的正则化促进近二元门控决策；理论分析显示GateRA在PEFT路径上产生软梯度掩码效应。

Result: 在多个常识推理基准测试中，GateRA一致优于或匹配先前的PEFT方法；可视化显示GateRA能自动抑制冗余预填充token的更新，在解码阶段强调适应。

Conclusion: GateRA通过动态、token级别的适应机制，实现了更智能的参数高效微调，在保持预训练知识的同时集中能力处理挑战性案例。

Abstract: Parameter-efficient fine-tuning (PEFT) methods, such as LoRA, DoRA, and HiRA, enable lightweight adaptation of large pre-trained models via low-rank updates. However, existing PEFT approaches apply static, input-agnostic updates to all tokens, disregarding the varying importance and difficulty of different inputs. This uniform treatment can lead to overfitting on trivial content or under-adaptation on more informative regions, especially in autoregressive settings with distinct prefill and decoding dynamics. In this paper, we propose GateRA, a unified framework that introduces token-aware modulation to dynamically adjust the strength of PEFT updates. By incorporating adaptive gating into standard PEFT branches, GateRA enables selective, token-level adaptation, preserving pre-trained knowledge for well-modeled inputs while focusing capacity on challenging cases. Empirical visualizations reveal phase-sensitive behaviors, where GateRA automatically suppresses updates for redundant prefill tokens while emphasizing adaptation during decoding. To promote confident and efficient modulation, we further introduce an entropy-based regularization that encourages near-binary gating decisions. This regularization prevents diffuse update patterns and leads to interpretable, sparse adaptation without hard thresholding. Finally, we present a theoretical analysis showing that GateRA induces a soft gradient-masking effect over the PEFT path, enabling continuous and differentiable control over adaptation. Experiments on multiple commonsense reasoning benchmarks demonstrate that GateRA consistently outperforms or matches prior PEFT methods.

</details>


### [330] [Learning Straight Flows: Variational Flow Matching for Efficient Generation](https://arxiv.org/abs/2511.17583)
*Chenrui Ma,Xi Xiao,Tianyang Wang,Xiao Wang,Yanning Shen*

Main category: cs.LG

TL;DR: S-VFM是一种改进的Flow Matching方法，通过引入变分潜码来强制生成轨迹直线化，解决传统方法中轨迹弯曲导致的一步生成限制问题。


<details>
  <summary>Details</summary>
Motivation: 传统Flow Matching方法依赖学习的弯曲轨迹，限制了单步生成能力。现有改进方法存在离散近似误差、训练不稳定和收敛困难等问题。

Method: 提出S-VFM方法，将代表"生成概览"的变分潜码集成到Flow Matching框架中，显式强制轨迹直线化，实现线性生成路径。

Result: 在三个挑战性基准测试中取得有竞争力的性能，在训练和推理效率方面相比现有方法具有优势。

Conclusion: S-VFM通过引入变分潜码有效解决了Flow Matching的轨迹弯曲问题，实现了更高效的直线轨迹生成。

Abstract: Flow Matching has limited ability in achieving one-step generation due to its reliance on learned curved trajectories. Previous studies have attempted to address this limitation by either modifying the coupling distribution to prevent interpolant intersections or introducing consistency and mean-velocity modeling to promote straight trajectory learning. However, these approaches often suffer from discrete approximation errors, training instability, and convergence difficulties. To tackle these issues, in the present work, we propose \textbf{S}traight \textbf{V}ariational \textbf{F}low \textbf{M}atching (\textbf{S-VFM}), which integrates a variational latent code representing the ``generation overview'' into the Flow Matching framework. \textbf{S-VFM} explicitly enforces trajectory straightness, ideally producing linear generation paths. The proposed method achieves competitive performance across three challenge benchmarks and demonstrates advantages in both training and inference efficiency compared with existing methods.

</details>


### [331] [LLM-Powered Text-Attributed Graph Anomaly Detection via Retrieval-Augmented Reasoning](https://arxiv.org/abs/2511.17584)
*Haoyan Xu,Ruizhi Qian,Zhengtao Yao,Ziyi Liu,Li Li,Yuqi Li,Yanshu Li,Wenqing Zheng,Daniele Rosa,Daniel Barcklow,Senthil Kumar,Jieyu Zhao,Yue Zhao*

Main category: cs.LG

TL;DR: 本文介绍了TAG-AD基准数据集，用于文本属性图上的异常节点检测，并提出了基于RAG的零样本LLM异常检测框架。


<details>
  <summary>Details</summary>
Motivation: 文本属性图在异常检测领域缺乏标准化基准数据集，现有的方法难以有效处理自然语言表达的节点信息。

Method: 利用LLM生成语义一致但上下文不一致的异常节点文本，构建TAG-AD基准数据集；提出RAG辅助的零样本LLM异常检测框架，通过构建全局异常知识库来减少对人工提示的依赖。

Result: 实验表明LLM在检测上下文异常方面表现优异，而GNN方法在结构异常检测上更具优势；RAG辅助提示能达到与人工设计提示相当的性能。

Conclusion: TAG-AD为文本属性图异常检测提供了标准化评估基准，RAG辅助的LLM框架在消除人工提示工程的同时保持了检测性能，具有实用价值。

Abstract: Anomaly detection on attributed graphs plays an essential role in applications such as fraud detection, intrusion monitoring, and misinformation analysis. However, text-attributed graphs (TAGs), in which node information is expressed in natural language, remain underexplored, largely due to the absence of standardized benchmark datasets. In this work, we introduce TAG-AD, a comprehensive benchmark for anomaly node detection on TAGs. TAG-AD leverages large language models (LLMs) to generate realistic anomalous node texts directly in the raw text space, producing anomalies that are semantically coherent yet contextually inconsistent and thus more reflective of real-world irregularities. In addition, TAG-AD incorporates multiple other anomaly types, enabling thorough and reproducible evaluation of graph anomaly detection (GAD) methods. With these datasets, we further benchmark existing unsupervised GNN-based GAD methods as well as zero-shot LLMs for GAD.
  As part of our zero-shot detection setup, we propose a retrieval-augmented generation (RAG)-assisted, LLM-based zero-shot anomaly detection framework. The framework mitigates reliance on brittle, hand-crafted prompts by constructing a global anomaly knowledge base and distilling it into reusable analysis frameworks. Our experimental results reveal a clear division of strengths: LLMs are particularly effective at detecting contextual anomalies, whereas GNN-based methods remain superior for structural anomaly detection. Moreover, RAG-assisted prompting achieves performance comparable to human-designed prompts while eliminating manual prompt engineering, underscoring the practical value of our RAG-assisted zero-shot LLM anomaly detection framework.

</details>


### [332] [PaSE: Prototype-aligned Calibration and Shapley-based Equilibrium for Multimodal Sentiment Analysis](https://arxiv.org/abs/2511.17585)
*Kang He,Boyu Chen,Yuzhe Ding,Fei Li,Chong Teng,Donghong Ji*

Main category: cs.LG

TL;DR: PaSE框架通过原型对齐校准和Shapley优化均衡来解决多模态情感分析中的模态竞争问题，提升跨模态协作效果


<details>
  <summary>Details</summary>
Motivation: 多模态情感分析中，现实场景常出现模态竞争现象，主导模态会压制弱势模态，导致性能不佳

Method: 提出PaSE框架：1）原型引导校准学习（PCL）通过熵最优传输机制对齐单模态表示；2）双阶段优化策略，先使用原型门控融合模块提取共享表示，再通过Shapley梯度调制（SGM）自适应调整梯度

Result: 在IEMOCAP、MOSI和MOSEI数据集上的实验表明，PaSE实现了优越性能并有效缓解了模态竞争

Conclusion: PaSE框架通过原型对齐和Shapley优化有效提升了多模态情感分析的性能，解决了模态竞争问题

Abstract: Multimodal Sentiment Analysis (MSA) seeks to understand human emotions by integrating textual, acoustic, and visual signals. Although multimodal fusion is designed to leverage cross-modal complementarity, real-world scenarios often exhibit modality competition: dominant modalities tend to overshadow weaker ones, leading to suboptimal performance.In this paper, we propose PaSE, a novel Prototype-aligned Calibration and Shapley-optimized Equilibrium framework, which enhances collaboration while explicitly mitigating modality competition. PaSE first applies Prototype-guided Calibration Learning (PCL) to refine unimodal representations and align them through an Entropic Optimal Transport mechanism that ensures semantic consistency. To further stabilize optimization, we introduce a Dual-Phase Optimization strategy. A prototype-gated fusion module is first used to extract shared representations, followed by Shapley-based Gradient Modulation (SGM), which adaptively adjusts gradients according to the contribution of each modality. Extensive experiments on IEMOCAP, MOSI, and MOSEI confirm that PaSE achieves the superior performance and effectively alleviates modality competition.

</details>


### [333] [Emotion and Intention Guided Multi-Modal Learning for Sticker Response Selection](https://arxiv.org/abs/2511.17587)
*Yuxuan Hu,Jian Chen,Yuhao Wang,Zixuan Li,Jing Xiong,Pengyue Jia,Wei Wang,Chengming Li,Xiangyu Zhao*

Main category: cs.LG

TL;DR: 提出EIGML框架，首次联合建模情绪和意图，通过双层级对比框架和多模态融合模块提升贴纸响应选择的准确性


<details>
  <summary>Details</summary>
Motivation: 现有贴纸响应选择方法通常依赖语义匹配并单独建模情绪和意图，当情绪和意图不一致时会导致匹配错误

Method: EIGML框架包含双层级对比框架（模态内和模态间对齐）和意图-情绪引导的多模态融合模块（情绪引导意图知识选择、意图-情绪引导注意力融合、相似度调整匹配机制）

Result: 在两个公开SRS数据集上实验表明，EIGML优于现有最优方法，实现了更高的准确率和更好的情绪意图理解

Conclusion: EIGML通过联合建模情绪和意图，有效减少孤立建模带来的偏差，显著提升贴纸选择性能

Abstract: Stickers are widely used in online communication to convey emotions and implicit intentions. The Sticker Response Selection (SRS) task aims to select the most contextually appropriate sticker based on the dialogue. However, existing methods typically rely on semantic matching and model emotional and intentional cues separately, which can lead to mismatches when emotions and intentions are misaligned. To address this issue, we propose Emotion and Intention Guided Multi-Modal Learning (EIGML). This framework is the first to jointly model emotion and intention, effectively reducing the bias caused by isolated modeling and significantly improving selection accuracy. Specifically, we introduce Dual-Level Contrastive Framework to perform both intra-modality and inter-modality alignment, ensuring consistent representation of emotional and intentional features within and across modalities. In addition, we design an Intention-Emotion Guided Multi-Modal Fusion module that integrates emotional and intentional information progressively through three components: Emotion-Guided Intention Knowledge Selection, Intention-Emotion Guided Attention Fusion, and Similarity-Adjusted Matching Mechanism. This design injects rich, effective information into the model and enables a deeper understanding of the dialogue, ultimately enhancing sticker selection performance. Experimental results on two public SRS datasets show that EIGML consistently outperforms state-of-the-art baselines, achieving higher accuracy and a better understanding of emotional and intentional features. Code is provided in the supplementary materials.

</details>


### [334] [Llamazip: Leveraging LLaMA for Lossless Text Compression and Training Dataset Detection](https://arxiv.org/abs/2511.17589)
*Sören Dréano,Derek Molloy,Noel Murphy*

Main category: cs.LG

TL;DR: Llamazip是一种基于LLaMA3语言模型预测能力的无损文本压缩算法，通过仅存储模型无法预测的标记来实现数据压缩，同时具备识别文档是否属于模型训练数据的能力


<details>
  <summary>Details</summary>
Motivation: 开发一种利用语言模型预测能力的高效无损压缩方法，并解决语言模型训练中的数据来源、知识产权和透明度等关键问题

Method: 基于LLaMA3语言模型的预测能力，仅存储模型无法正确预测的文本标记，分析量化精度和上下文窗口大小等关键参数对性能的影响

Result: 实现了显著的数据压缩效果，同时发现算法能够识别文档是否属于语言模型的训练数据集

Conclusion: Llamazip不仅是一种有效的无损压缩算法，还展示了在数据溯源和模型透明度方面的应用潜力

Abstract: This work introduces Llamazip, a novel lossless text compression algorithm based on the predictive capabilities of the LLaMA3 language model. Llamazip achieves significant data reduction by only storing tokens that the model fails to predict, optimizing storage efficiency without compromising data integrity. Key factors affecting its performance, including quantization and context window size, are analyzed, revealing their impact on compression ratios and computational requirements. Beyond compression, Llamazip demonstrates the potential to identify whether a document was part of the training dataset of a language model. This capability addresses critical concerns about data provenance, intellectual property, and transparency in language model training.

</details>


### [335] [SHAP Distance: An Explainability-Aware Metric for Evaluating the Semantic Fidelity of Synthetic Tabular Data](https://arxiv.org/abs/2511.17590)
*Ke Yu,Shigeru Ishikura,Yukari Usukura,Yuki Shigoku,Teruaki Hayashi*

Main category: cs.LG

TL;DR: 本文提出了一种新的可解释性感知度量方法——SHAP距离，用于评估合成表格数据的语义保真度，弥补了传统统计和预测评估方法的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的合成数据评估方法主要关注分布相似性或预测性能，但无法评估模型在合成数据上是否遵循与真实数据一致的推理模式，即语义保真度。

Method: 引入SHAP距离，定义为从真实数据与合成数据训练的模型中得到的全局SHAP归因向量之间的余弦距离。

Result: 通过多个领域的数据集验证，SHAP距离能够可靠地识别标准统计和预测指标忽略的语义差异，特别是特征重要性偏移和尾部效应。

Conclusion: SHAP距离可作为审计合成表格数据语义保真度的实用工具，并为未来基准测试提供基于归因的评估指南。

Abstract: Synthetic tabular data, which are widely used in domains such as healthcare, enterprise operations, and customer analytics, are increasingly evaluated to ensure that they preserve both privacy and utility. While existing evaluation practices typically focus on distributional similarity (e.g., the Kullback-Leibler divergence) or predictive performance (e.g., Train-on-Synthetic-Test-on-Real (TSTR) accuracy), these approaches fail to assess semantic fidelity, that is, whether models trained on synthetic data follow reasoning patterns consistent with those trained on real data. To address this gap, we introduce the SHapley Additive exPlanations (SHAP) Distance, a novel explainability-aware metric that is defined as the cosine distance between the global SHAP attribution vectors derived from classifiers trained on real versus synthetic datasets. By analyzing datasets that span clinical health records with physiological features, enterprise invoice transactions with heterogeneous scales, and telecom churn logs with mixed categorical-numerical attributes, we demonstrate that the SHAP Distance reliably identifies semantic discrepancies that are overlooked by standard statistical and predictive measures. In particular, our results show that the SHAP Distance captures feature importance shifts and underrepresented tail effects that the Kullback-Leibler divergence and Train-on-Synthetic-Test-on-Real accuracy fail to detect. This study positions the SHAP Distance as a practical and discriminative tool for auditing the semantic fidelity of synthetic tabular data, and offers practical guidelines for integrating attribution-based evaluation into future benchmarking pipelines.

</details>


### [336] [Comparative Analysis of Large Language Model Inference Serving Systems: A Performance Study of vLLM and HuggingFace TGI](https://arxiv.org/abs/2511.17593)
*Saicharan Kolluru*

Main category: cs.LG

TL;DR: 本文对vLLM和HuggingFace TGI两个开源LLM服务框架进行了全面的实证评估，发现vLLM在高并发场景下吞吐量比TGI高24倍，而TGI在交互式单用户场景下延迟更低。


<details>
  <summary>Details</summary>
Motivation: 在生产环境中部署大型语言模型需要高效的推理服务系统来平衡吞吐量、延迟和资源利用率，但目前缺乏对主流开源框架的系统性性能比较。

Method: 使用LLaMA-2模型（7B到70B参数）对vLLM和TGI进行多维度基准测试，包括吞吐量性能、端到端延迟、GPU内存利用率和可扩展性特征。

Result: vLLM通过其创新的PagedAttention机制在高并发工作负载下实现比TGI高24倍的吞吐量，而TGI在交互式单用户场景下表现出更低的尾部延迟。

Conclusion: 框架选择应根据具体用例需求：vLLM适合高吞吐量批处理场景，TGI更适合中等并发下的延迟敏感交互应用。

Abstract: The deployment of Large Language Models (LLMs) in production environments requires efficient inference serving systems that balance throughput, latency, and resource utilization. This paper presents a comprehensive empirical evaluation of two prominent open-source LLM serving frameworks: vLLM and HuggingFace Text Generation Inference (TGI). We benchmark these systems across multiple dimensions including throughput performance, end-to-end latency, GPU memory utilization, and scalability characteristics using LLaMA-2 models ranging from 7B to 70B parameters. Our experiments reveal that vLLM achieves up to 24x higher throughput than TGI under high-concurrency workloads through its novel PagedAttention mechanism, while TGI demonstrates lower tail latencies for interactive single-user scenarios. We provide detailed performance profiles for different deployment scenarios and offer practical recommendations for system selection based on workload characteristics. Our findings indicate that the choice between these frameworks should be guided by specific use-case requirements: vLLM excels in high-throughput batch processing scenarios, while TGI is better suited for latency-sensitive interactive applications with moderate concurrency.

</details>


### [337] [AutoSAGE: Input-Aware CUDA Scheduling for Sparse GNN Aggregation (SpMM/SDDMM) and CSR Attention](https://arxiv.org/abs/2511.17594)
*Aleksandar Stankovic*

Main category: cs.LG

TL;DR: AutoSAGE是一个输入感知的CUDA调度器，针对稀疏GNN聚合操作（CSR SpMM/SDDMM），通过轻量级估计和微探针优化性能，在特定条件下可达到4.7倍加速。


<details>
  <summary>Details</summary>
Motivation: 稀疏GNN聚合操作在不同度分布、特征宽度和GPU微架构下性能差异显著，需要针对输入特性进行优化。

Method: 使用轻量级估计和on-device微探针选择tiling和映射策略，包含回退机制和持久化缓存，支持SpMM和SDDMM操作组合成CSR注意力流水线。

Result: 在Reddit和OGBN-Products数据集上，在带宽受限的特征宽度下与基线相当，在小宽度下获得性能提升；在合成稀疏度和偏斜测试中达到4.7倍内核级加速。

Conclusion: AutoSAGE提供了有效的输入感知优化方案，并发布了完整的工具链支持复现和研究。

Abstract: Sparse GNN aggregations (CSR SpMM/SDDMM) vary widely in performance with degree skew, feature width, and GPU micro-architecture. We present AutoSAGE, an input-aware CUDA scheduler that chooses tiling and mapping per input using a lightweight estimate refined by on-device micro-probes, with a guardrail that safely falls back to vendor kernels and a persistent cache for deterministic replay. AutoSAGE covers SpMM and SDDMM and composes into a CSR attention pipeline (SDDMM -> row-softmax -> SpMM). On Reddit and OGBN-Products, it matches vendor baselines at bandwidth-bound feature widths and finds gains at small widths; on synthetic sparsity and skew stress tests it achieves up to 4.7x kernel-level speedups. We release CUDA sources, Python bindings, a reproducible harness, and replayable cache logs.

</details>


### [338] [Boosting Reinforcement Learning in 3D Visuospatial Tasks Through Human-Informed Curriculum Design](https://arxiv.org/abs/2511.17595)
*Markus D. Solbach,John K. Tsotsos*

Main category: cs.LG

TL;DR: 论文探讨了强化学习在复杂3D视觉空间任务中的应用，通过课程学习策略成功解决了传统方法难以直接学习最优策略的问题。


<details>
  <summary>Details</summary>
Motivation: 研究强化学习在更复杂、非结构化问题领域中的智能行为表现，扩展RL的应用范围，向人工通用智能迈进。

Method: 采用PPO、行为克隆和模仿学习等先进方法，结合基于真实人类实验发现的课程学习策略来设计教学计划。

Result: 传统方法在直接学习最优策略时遇到困难，但通过精心设计的课程学习实现了有效学习。

Conclusion: 课程学习为强化学习在复杂3D任务中的应用提供了有前景的途径，基于人类认知过程的策略设计对RL性能提升至关重要。

Abstract: Reinforcement Learning is a mature technology, often suggested as a potential route towards Artificial General Intelligence, with the ambitious goal of replicating the wide range of abilities found in natural and artificial intelligence, including the complexities of human cognition. While RL had shown successes in relatively constrained environments, such as the classic Atari games and specific continuous control problems, recent years have seen efforts to expand its applicability. This work investigates the potential of RL in demonstrating intelligent behaviour and its progress in addressing more complex and less structured problem domains.
  We present an investigation into the capacity of modern RL frameworks in addressing a seemingly straightforward 3D Same-Different visuospatial task. While initial applications of state-of-the-art methods, including PPO, behavioural cloning and imitation learning, revealed challenges in directly learning optimal strategies, the successful implementation of curriculum learning offers a promising avenue. Effective learning was achieved by strategically designing the lesson plan based on the findings of a real-world human experiment.

</details>


### [339] [Non-stationary and Varying-discounting Markov Decision Processes for Reinforcement Learning](https://arxiv.org/abs/2511.17598)
*Zhizuo Chen,Theodore T. Allen*

Main category: cs.LG

TL;DR: 提出了非平稳和变折扣MDP（NVMDP）框架，解决传统MDP在非平稳环境和有限时间任务中的局限性，支持随时间变化的折扣率，并保持理论严谨性。


<details>
  <summary>Details</summary>
Motivation: 传统MDP算法在非平稳环境中表现不佳，且无限时间框架不适用于有限时间任务，需要更灵活的框架来适应实际应用需求。

Method: 建立NVMDP理论框架，包括状态-动作值函数递归、矩阵表示、最优性条件；扩展动态规划和Q-learning算法；推广策略梯度定理和TRPO边界。

Result: 在非平稳网格世界环境中，NVMDP算法成功恢复最优轨迹，而原始Q-learning失败，验证了框架的有效性。

Conclusion: NVMDP为强化学习提供了理论严谨且实用的框架，只需轻微算法修改即可稳健处理非平稳性和显式策略优化。

Abstract: Algorithms developed under stationary Markov Decision Processes (MDPs) often face challenges in non-stationary environments, and infinite-horizon formulations may not directly apply to finite-horizon tasks. To address these limitations, we introduce the Non-stationary and Varying-discounting MDP (NVMDP) framework, which naturally accommodates non-stationarity and allows discount rates to vary with time and transitions. Infinite-horizon, stationary MDPs emerge as special cases of NVMDPs for identifying an optimal policy, and finite-horizon MDPs are also subsumed within the NVMDP formulations. Moreover, NVMDPs provide a flexible mechanism to shape optimal policies, without altering the state space, action space, or the reward structure. We establish the theoretical foundations of NVMDPs, including assumptions, state- and action-value formulation and recursion, matrix representation, optimality conditions, and policy improvement under finite state and action spaces. Building on these results, we adapt dynamic programming and generalized Q-learning algorithms to NVMDPs, along with formal convergence proofs. For problems requiring function approximation, we extend the Policy Gradient Theorem and the policy improvement bound in Trust Region Policy Optimization (TRPO), offering proofs in both scalar and matrix forms. Empirical evaluations in a non-stationary gridworld environment demonstrate that NVMDP-based algorithms successfully recover optimal trajectories under multiple reward and discounting schemes, whereas original Q-learning fails. These results collectively show that NVMDPs provide a theoretically sound and practically effective framework for reinforcement learning, requiring only minor algorithmic modifications while enabling robust handling of non-stationarity and explicit optimal policy shaping.

</details>


### [340] [From Projection to Prediction: Beyond Logits for Scalable Language Models](https://arxiv.org/abs/2511.17599)
*Jianbing Dong,Jianbin Chang*

Main category: cs.LG

TL;DR: 提出了一种新的LLM训练方法，通过将输出投影和损失预测集成到单一操作中，避免显式logits张量化，从而减少内存占用和带宽压力。


<details>
  <summary>Details</summary>
Motivation: 传统LLM训练的两阶段输出层设计需要完全物化中间logits张量，导致显著的内存开销和带宽消耗，限制了可扩展性和训练吞吐量。

Method: 通过直接从隐藏状态和目标token计算损失，绕过了显式的logits物化过程，将输出投影和损失预测整合为单一操作。

Result: 实验表明该方法相比标准两阶段流程实现了显著的内存节省和可测量的加速，能够支持更大的批次大小和更长的序列而不牺牲准确性。

Conclusion: 重新思考投影和预测之间的边界可以带来显著的系统优化效益，为高效LLM训练提供了实用的解决方案。

Abstract: Training Large Language Models (LLMs) typically involves a two-stage pipeline at the output layer: hidden states are projected into vocabulary logits via a linear transformation (lm_head), followed by cross-entropy loss computation against target tokens. While conceptually simple, this design incurs substantial overhead. The intermediate logits tensor, with dimensions proportional to batch size, sequence length, and vocabulary size, must be fully materialized in GPU memory, even though only one target token per position is ultimately used. This leads to significant memory footprint and bandwidth comsumption, limiting scalability and slowing training throughput.
  In this work, we introduce a novel approach to integrates the output projection and loss prediction into a single operation. By directly computing the loss from hidden states and target tokens, our approach bypasses explicit logits materialization. This design reduces memory usage and alleviates bandwidth pressure. Experiments on LLM training demonstrate that our method achieves substantial memory savings and measurable speedups compared to the standard two-stage pipeline, enabling large batch sizes and longer sequences without sacrificing accuracy. Our work highlights the benefits of rethinking the boundary between projection and prediction, offering a practical systems optimization for efficient LLM training.

</details>


### [341] [Generalizable and Efficient Automated Scoring with a Knowledge-Distilled Multi-Task Mixture-of-Experts](https://arxiv.org/abs/2511.17601)
*Luyang Fang,Tao Wang,Ping Ma,Xiaoming Zhai*

Main category: cs.LG

TL;DR: UniMoE-Guided是一种知识蒸馏的多任务混合专家方法，将多个任务特定大模型的知识转移到单个紧凑可部署模型中，实现高效自动评分


<details>
  <summary>Details</summary>
Motivation: 传统自动评分方法对每个任务使用独立模型，导致计算资源、存储和维护成本过高，难以在教育场景中大规模应用

Method: 采用知识蒸馏技术，结合共享编码器、门控MoE块和轻量级任务头，通过真实标签和教师模型指导训练学生模型

Result: 在9个科学推理任务上，UniMoE-Guided性能与任务特定模型相当，存储需求比单独学生模型减少6倍，比200亿参数教师模型减少87倍

Conclusion: 该方法为课堂和大规模评估系统提供了可扩展、可靠且资源高效的自动评分实用路径

Abstract: Automated scoring of written constructed responses typically relies on separate models per task, straining computational resources, storage, and maintenance in real-world education settings. We propose UniMoE-Guided, a knowledge-distilled multi-task Mixture-of-Experts (MoE) approach that transfers expertise from multiple task-specific large models (teachers) into a single compact, deployable model (student). The student combines (i) a shared encoder for cross-task representations, (ii) a gated MoE block that balances shared and task-specific processing, and (iii) lightweight task heads. Trained with both ground-truth labels and teacher guidance, the student matches strong task-specific models while being far more efficient to train, store, and deploy. Beyond efficiency, the MoE layer improves transfer and generalization: experts develop reusable skills that boost cross-task performance and enable rapid adaptation to new tasks with minimal additions and tuning. On nine NGSS-aligned science-reasoning tasks (seven for training/evaluation and two held out for adaptation), UniMoE-Guided attains performance comparable to per-task models while using $\sim$6$\times$ less storage than maintaining separate students, and $87\times$ less than the 20B-parameter teacher. The method offers a practical path toward scalable, reliable, and resource-efficient automated scoring for classroom and large-scale assessment systems.

</details>


### [342] [Beyond Surface-Level Similarity: Hierarchical Contamination Detection for Synthetic Training Data in Foundation Models](https://arxiv.org/abs/2511.17602)
*Sushant Mehta*

Main category: cs.LG

TL;DR: 提出了一个分层污染检测框架，用于检测合成数据对基准测试的语义级污染，该污染无法被现有的基于词汇重叠的方法检测到。


<details>
  <summary>Details</summary>
Motivation: 现有方法只能检测词汇级别的重叠，但无法识别语义级别的污染，即合成数据在概念上模仿基准测试但没有词汇重叠的情况。随着基础模型越来越多地使用合成数据进行训练，这种污染威胁评估的完整性。

Method: 提出一个分层污染检测框架，在四个层次上操作：词汇级别、语义级别、推理模式和性能悬崖检测。通过控制实验在MMLU、GSM8K和HumanEval数据集上进行验证。

Result: 语义级污染能够逃避现有方法检测（F1=0.17-0.49），但本文的分层方法能有效检测（F1=0.76），相比最先进基线平均提升26.5%。

Conclusion: 该框架为从业者提供了实用的审计管道工具，支持合成训练数据的负责任部署。

Abstract: Synthetic data has become essential for training foundation models, yet benchmark contamination threatens evaluation integrity. Although existing detection methods identify token-level overlap, they fail to detect semantic-level contamination where synthetic data conceptually resemble benchmarks without lexical overlap. This gap is critical as foundation models increasingly train on synthetic data that may implicitly encode benchmark knowledge. We propose a hierarchical contamination detection framework operating at four levels: token level, semantic level, reasoning pattern, and performance cliff detection. Through controlled experiments on MMLU, GSM8K and HumanEval, we demonstrate that semantic-level contamination evades existing methods (F1=0.17-0.49) but is effectively detected by our hierarchical approach (F1 = 0.76), with an average improvement of 26. 5\% over state-of-the-art baselines. Our framework provides practitioners with practical tools for audit pipelines and enables responsible deployment of synthetic training data.

</details>


### [343] [BrainHGT: A Hierarchical Graph Transformer for Interpretable Brain Network Analysis](https://arxiv.org/abs/2511.17604)
*Jiajun Ma,Yongchao Zhang,Chao Zhang,Zhao Lv,Shengbing Pei*

Main category: cs.LG

TL;DR: 提出了BrainHGT，一种分层图Transformer，模拟大脑从局部区域到全局群落的信息处理过程，通过长短程注意力编码器和先验引导聚类模块来改善疾病识别性能并提高生物可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将大脑建模为扁平网络，忽略其模块化结构，且注意力机制对所有脑区连接一视同仁，忽略了距离相关的节点连接模式。大脑信息处理是一个涉及局部和长程交互的分层过程。

Method: 设计新颖的长短程注意力编码器，利用并行通路处理密集局部交互和稀疏长程连接；设计先验引导聚类模块，使用交叉注意力机制将脑区分组为功能群落，并利用神经解剖学先验指导聚类过程。

Result: 实验结果表明，所提方法显著提高了疾病识别性能，并能可靠地捕捉大脑的子功能模块，证明了其可解释性。

Conclusion: BrainHGT通过模拟大脑自然信息处理的分层机制，有效解决了现有方法的局限性，在疾病识别和生物可解释性方面表现出色。

Abstract: Graph Transformer shows remarkable potential in brain network analysis due to its ability to model graph structures and complex node relationships. Most existing methods typically model the brain as a flat network, ignoring its modular structure, and their attention mechanisms treat all brain region connections equally, ignoring distance-related node connection patterns. However, brain information processing is a hierarchical process that involves local and long-range interactions between brain regions, interactions between regions and sub-functional modules, and interactions among functional modules themselves. This hierarchical interaction mechanism enables the brain to efficiently integrate local computations and global information flow, supporting the execution of complex cognitive functions. To address this issue, we propose BrainHGT, a hierarchical Graph Transformer that simulates the brain's natural information processing from local regions to global communities. Specifically, we design a novel long-short range attention encoder that utilizes parallel pathways to handle dense local interactions and sparse long-range connections, thereby effectively alleviating the over-globalizing issue. To further capture the brain's modular architecture, we designe a prior-guided clustering module that utilizes a cross-attention mechanism to group brain regions into functional communities and leverage neuroanatomical prior to guide the clustering process, thereby improving the biological plausibility and interpretability. Experimental results indicate that our proposed method significantly improves performance of disease identification, and can reliably capture the sub-functional modules of the brain, demonstrating its interpretability.

</details>


### [344] [Copula Based Fusion of Clinical and Genomic Machine Learning Risk Scores for Breast Cancer Risk Stratification](https://arxiv.org/abs/2511.17605)
*Agnideep Aich,Sameera Hewage,Md Monzur Murshed*

Main category: cs.LG

TL;DR: 该研究通过使用copula模型直接建模临床和基因组机器学习风险评分的联合关系，改进了乳腺癌5年癌症特异性死亡的风险分层。研究发现高斯copula能最佳捕捉评分间的对称、中等强度正相关关系，基于此关系的患者分组显示同时具有高临床和高基因组风险的患者预后最差。


<details>
  <summary>Details</summary>
Motivation: 当前临床和基因组模型通常使用简单线性规则结合，未能充分考虑风险评分在极端值处的关联关系，特别是如何联合使用这两种评分来改善风险分层。

Method: 使用METABRIC乳腺癌队列，创建5年癌症死亡二元结局，定义临床和基因组两组预测因子。训练随机森林和XGBoost等分类器，使用5折交叉验证预测概率作为风险评分，转换为伪观测值后拟合高斯、Clayton和Gumbel copula模型。

Result: 临床模型区分度良好（AUC 0.783），基因组模型表现中等（AUC 0.681）。高斯copula最佳捕捉联合分布（bootstrap p=0.997）。基于copula关系的患者分组显示，同时高临床和高基因组风险的患者生存率显著差于仅在一组高风险的患z者。

Conclusion: copula-based融合方法在真实世界队列中有效，考虑评分间依赖关系能更好识别预后最差的患者亚组。

Abstract: Clinical and genomic models are both used to predict breast cancer outcomes, but they are often combined using simple linear rules that do not account for how their risk scores relate, especially at the extremes. Using the METABRIC breast cancer cohort, we studied whether directly modeling the joint relationship between clinical and genomic machine learning risk scores could improve risk stratification for 5-year cancer-specific mortality. We created a binary 5-year cancer-death outcome and defined two sets of predictors: a clinical set (demographic, tumor, and treatment variables) and a genomic set (gene-expression $z$-scores). We trained several supervised classifiers, such as Random Forest and XGBoost, and used 5-fold cross-validated predicted probabilities as unbiased risk scores. These scores were converted to pseudo-observations on $(0,1)^2$ to fit Gaussian, Clayton, and Gumbel copulas. Clinical models showed good discrimination (AUC 0.783), while genomic models had moderate performance (AUC 0.681). The joint distribution was best captured by a Gaussian copula (bootstrap $p=0.997$), which suggests a symmetric, moderately strong positive relationship. When we grouped patients based on this relationship, Kaplan-Meier curves showed clear differences: patients who were high-risk in both clinical and genomic scores had much poorer survival than those high-risk in only one set. These results show that copula-based fusion works in real-world cohorts and that considering dependencies between scores can better identify patient subgroups with the worst prognosis.

</details>


### [345] [Energy-based Autoregressive Generation for Neural Population Dynamics](https://arxiv.org/abs/2511.17606)
*Ningling Ge,Sicheng Dai,Yu Zhu,Shan Yu*

Main category: cs.LG

TL;DR: 本文提出了基于能量的自回归生成（EAG）框架，通过能量变换器在潜在空间中学习时间动态，解决了计算效率与高保真建模之间的权衡问题，在神经群体动力学建模中实现了高效且高质量的生成。


<details>
  <summary>Details</summary>
Motivation: 理解大脑功能是神经科学的基本目标，但计算建模面临计算效率与高保真建模之间的根本权衡。为了突破这一限制，需要开发能够同时保持计算效率和生成质量的神经动力学建模方法。

Method: 采用基于能量的自回归生成框架，使用能量变换器通过严格适当评分规则在潜在空间中学习时间动态，实现具有真实群体和单神经元发放统计特性的高效生成。

Result: 在合成Lorenz数据集和两个神经潜在基准数据集上的评估表明，EAG实现了最先进的生成质量，并显著提升了计算效率，特别是在条件生成应用中展示了泛化到未见行为情境和提升运动脑机接口解码精度的能力。

Conclusion: 基于能量的建模方法在神经群体动力学研究中具有有效性，为神经科学研究和神经工程应用提供了新的工具和可能性。

Abstract: Understanding brain function represents a fundamental goal in neuroscience, with critical implications for therapeutic interventions and neural engineering applications. Computational modeling provides a quantitative framework for accelerating this understanding, but faces a fundamental trade-off between computational efficiency and high-fidelity modeling. To address this limitation, we introduce a novel Energy-based Autoregressive Generation (EAG) framework that employs an energy-based transformer learning temporal dynamics in latent space through strictly proper scoring rules, enabling efficient generation with realistic population and single-neuron spiking statistics. Evaluation on synthetic Lorenz datasets and two Neural Latents Benchmark datasets (MC_Maze and Area2_bump) demonstrates that EAG achieves state-of-the-art generation quality with substantial computational efficiency improvements, particularly over diffusion-based methods. Beyond optimal performance, conditional generation applications show two capabilities: generalizing to unseen behavioral contexts and improving motor brain-computer interface decoding accuracy using synthetic neural data. These results demonstrate the effectiveness of energy-based modeling for neural population dynamics with applications in neuroscience research and neural engineering. Code is available at https://github.com/NinglingGe/Energy-based-Autoregressive-Generation-for-Neural-Population-Dynamics.

</details>


### [346] [Finding Pre-Injury Patterns in Triathletes from Lifestyle, Recovery and Load Dynamics Features](https://arxiv.org/abs/2511.17610)
*Leonardo Rossi,Bruno Rodrigues*

Main category: cs.LG

TL;DR: 该论文提出了一个专门为铁人三项训练设计的合成数据生成框架，通过整合睡眠质量、压力水平和恢复状态等日常生活因素，结合机器学习模型实现了高达0.86 AUC的损伤预测性能。


<details>
  <summary>Details</summary>
Motivation: 铁人三项训练的高强度重复性运动使运动员面临过度使用损伤风险，而现有的损伤预测方法主要依赖训练负荷指标，忽略了睡眠质量、压力和个体生活方式等影响恢复和损伤易感性的关键因素。

Method: 开发了一个针对铁人三项的合成数据生成框架，生成生理上合理的运动员档案，模拟包含周期化和负荷管理原则的个性化训练计划，并整合日常生活因素。评估了LASSO、随机森林和XGBoost等机器学习模型。

Result: 机器学习模型显示出高预测性能（AUC最高达0.86），识别出睡眠障碍、心率变异性和压力作为损伤风险的关键早期指标。

Conclusion: 这种可穿戴设备驱动的方法不仅提高了损伤预测的准确性，还为克服现实世界数据限制提供了实用解决方案，为实现整体性、情境感知的运动员监测开辟了道路。

Abstract: Triathlon training, which involves high-volume swimming, cycling, and running, places athletes at substantial risk for overuse injuries due to repetitive physiological stress. Current injury prediction approaches primarily rely on training load metrics, often neglecting critical factors such as sleep quality, stress, and individual lifestyle patterns that significantly influence recovery and injury susceptibility.
  We introduce a novel synthetic data generation framework tailored explicitly for triathlon. This framework generates physiologically plausible athlete profiles, simulates individualized training programs that incorporate periodization and load-management principles, and integrates daily-life factors such as sleep quality, stress levels, and recovery states. We evaluated machine learning models (LASSO, Random Forest, and XGBoost) showing high predictive performance (AUC up to 0.86), identifying sleep disturbances, heart rate variability, and stress as critical early indicators of injury risk. This wearable-driven approach not only enhances injury prediction accuracy but also provides a practical solution to overcoming real-world data limitations, offering a pathway toward a holistic, context-aware athlete monitoring.

</details>


### [347] [AI-driven Generation of MALDI-TOF MS for Microbial Characterization](https://arxiv.org/abs/2511.17611)
*Lucía Schmidt-Santiago,David Rodríguez-Temporal,Carlos Sevilla-Salcedo,Vanessa Gómez-Verdejo*

Main category: cs.LG

TL;DR: 该研究评估了三种生成模型（MALDIVAE、MALDIGAN、MALDIffusion）用于合成MALDI-TOF MS光谱，以解决微生物鉴定中数据稀缺问题。结果显示合成数据与真实数据在统计和诊断上相当，其中MALDIVAE在真实性、稳定性和效率方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: MALDI-TOF MS技术在临床微生物鉴定中应用广泛，但数据驱动的诊断模型发展受限于缺乏足够大、平衡且标准化的光谱数据集。本研究旨在通过生成模型合成真实光谱来克服数据稀缺问题。

Method: 研究采用三种条件生成模型：变分自编码器（MALDIVAE）、生成对抗网络（MALDIGAN）和去噪扩散概率模型（MALDIffusion），在物种标签指导下生成微生物光谱，并通过多种指标评估光谱保真度和多样性。

Result: 实验表明，三种模型生成的合成数据在统计和诊断上都与真实测量相当。使用纯合成数据训练的 classifiers 可以达到与真实数据训练相似的性能。MALDIVAE在真实性、稳定性和效率方面表现最佳，而MALDIffusion保真度最高但计算成本显著更高。

Conclusion: 生成模型能有效解决MALDI-TOF MS数据稀缺问题，合成数据可用于训练鲁棒的机器学习工具。特别是用合成光谱增强少数物种能显著提高分类准确性，有效缓解类别不平衡和领域不匹配问题。

Abstract: Matrix-Assisted Laser Desorption/Ionization Time-of-Flight Mass Spectrometry (MALDI-TOF MS) has become a cornerstone technology in clinical microbiology, enabling rapid and accurate microbial identification. However, the development of data-driven diagnostic models remains limited by the lack of sufficiently large, balanced, and standardized spectral datasets. This study investigates the use of deep generative models to synthesize realistic MALDI-TOF MS spectra, aiming to overcome data scarcity and support the development of robust machine learning tools in microbiology.
  We adapt and evaluate three generative models, Variational Autoencoders (MALDIVAEs), Generative Adversarial Networks (MALDIGANs), and Denoising Diffusion Probabilistic Model (MALDIffusion), for the conditional generation of microbial spectra guided by species labels. Generation is conditioned on species labels, and spectral fidelity and diversity are assessed using diverse metrics.
  Our experiments show that synthetic data generated by MALDIVAE, MALDIGAN, and MALDIffusion are statistically and diagnostically comparable to real measurements, enabling classifiers trained exclusively on synthetic samples to reach performance levels similar to those trained on real data. While all models faithfully reproduce the peak structure and variability of MALDI-TOF spectra, MALDIffusion obtains this fidelity at a substantially higher computational cost, and MALDIGAN shows competitive but slightly less stable behaviour. In contrast, MALDIVAE offers the most favorable balance between realism, stability, and efficiency. Furthermore, augmenting minority species with synthetic spectra markedly improves classification accuracy, effectively mitigating class imbalance and domain mismatch without compromising the authenticity of the generated data.

</details>


### [348] [Tensor Gauge Flow Models](https://arxiv.org/abs/2511.17616)
*Alexander Strunk,Roland Assam*

Main category: cs.LG

TL;DR: 本文介绍了Tensor Gauge Flow Models，这是一种新的生成流模型，通过将高阶张量规范场引入流方程，扩展了Gauge Flow Models和Higher Gauge Flow Models。该模型能够在数据中编码更丰富的几何和规范理论结构，从而产生更具表现力的流动力学。


<details>
  <summary>Details</summary>
Motivation: 为了在生成流模型中编码更丰富的几何和规范理论结构，提高模型的表达能力。

Method: 将高阶张量规范场引入流方程，扩展了现有的Gauge Flow Models和Higher Gauge Flow Models。

Result: 在高斯混合模型上的实验表明，Tensor Gauge Flow Models相比标准流模型和规范流基线模型，实现了更好的生成性能。

Conclusion: Tensor Gauge Flow Models通过引入高阶张量规范场，成功提升了生成流模型的表达能力，在实验中表现出优越的生成性能。

Abstract: This paper introduces Tensor Gauge Flow Models, a new class of Generative Flow Models that generalize Gauge Flow Models and Higher Gauge Flow Models by incorporating higher-order Tensor Gauge Fields into the Flow Equation. This extension allows the model to encode richer geometric and gauge-theoretic structure in the data, leading to more expressive flow dynamics. Experiments on Gaussian mixture models show that Tensor Gauge Flow Models achieve improved generative performance compared to both standard and gauge flow baselines.

</details>


### [349] [Neurocircuitry-Inspired Hierarchical Graph Causal Attention Networks for Explainable Depression Identification](https://arxiv.org/abs/2511.17622)
*Weidao Chen,Yuxiao Yang,Yueming Wang*

Main category: cs.LG

TL;DR: NH-GCAT是一种神经科学启发的分层图因果注意力网络，通过在不同空间尺度上明确建模抑郁症特异性机制，将神经科学领域知识与深度学习相结合，用于抑郁症诊断。


<details>
  <summary>Details</summary>
Motivation: 现有基于神经影像数据的图神经网络方法主要是数据驱动的黑盒模型，缺乏神经生物学可解释性，无法体现抑郁症的复杂病理生理机制。

Method: 提出三个关键技术贡献：1）局部脑区层面的残差门控融合模块，整合BOLD动态和功能连接模式；2）多区域回路层面的分层回路编码方案；3）多回路网络层面的变分潜在因果注意力机制。

Result: 在REST-meta-MDD数据集上的严格留一站点交叉验证显示，NH-GCAT在抑郁症分类中达到最先进性能，加权平均准确率73.3%，AUROC为76.4%。

Conclusion: NH-GCAT不仅实现了优异的抑郁症分类性能，同时提供了神经生物学上有意义的解释，成功地将神经科学知识融入深度学习框架。

Abstract: Major Depressive Disorder (MDD), affecting millions worldwide, exhibits complex pathophysiology manifested through disrupted brain network dynamics. Although graph neural networks that leverage neuroimaging data have shown promise in depression diagnosis, existing approaches are predominantly data-driven and operate largely as black-box models, lacking neurobiological interpretability. Here, we present NH-GCAT (Neurocircuitry-Inspired Hierarchical Graph Causal Attention Networks), a novel framework that bridges neuroscience domain knowledge with deep learning by explicitly and hierarchically modeling depression-specific mechanisms at different spatial scales. Our approach introduces three key technical contributions: (1) at the local brain regional level, we design a residual gated fusion module that integrates temporal blood oxygenation level dependent (BOLD) dynamics with functional connectivity patterns, specifically engineered to capture local depression-relevant low-frequency neural oscillations; (2) at the multi-regional circuit level, we propose a hierarchical circuit encoding scheme that aggregates regional node representations following established depression neurocircuitry organization, and (3) at the multi-circuit network level, we develop a variational latent causal attention mechanism that leverages a continuous probabilistic latent space to infer directed information flow among critical circuits, characterizing disease-altered whole-brain inter-circuit interactions. Rigorous leave-one-site-out cross-validation on the REST-meta-MDD dataset demonstrates NH-GCAT's state-of-the-art performance in depression classification, achieving a sample-size weighted-average accuracy of 73.3\% and an AUROC of 76.4\%, while simultaneously providing neurobiologically meaningful explanations.

</details>


### [350] [M$^2$OE$^2$-GL: A Family of Probabilistic Load Forecasters That Scales to Massive Customers](https://arxiv.org/abs/2511.17623)
*Haoran Li,Zhe Cheng,Muhao Guo,Yang Weng,Yannan Sun,Victor Tran,John Chainaranont*

Main category: cs.LG

TL;DR: M2OE2-GL是一种概率负荷预测方法，通过全局预训练和轻量级微调解决大规模配电系统中异构性和可扩展性挑战。


<details>
  <summary>Details</summary>
Motivation: 解决大规模配电系统中部署深度学习预测器的困境：为每个客户训练单独模型计算和存储成本高，而单一全局模型无法处理不同客户类型、位置和相位的分布偏移。

Method: 首先在所有馈线负荷上预训练单一的全局M2OE2基础模型，然后应用轻量级微调来获得一组紧凑的群组特定预测器。

Result: 在真实电力公司数据上的评估显示，M2OE2-GL在保持对大量负荷可扩展性的同时，实现了显著的误差降低。

Conclusion: M2OE2-GL方法有效平衡了预测准确性和计算效率，为大规模配电系统中的概率负荷预测提供了可行解决方案。

Abstract: Probabilistic load forecasting is widely studied and underpins power system planning, operation, and risk-aware decision making. Deep learning forecasters have shown strong ability to capture complex temporal and contextual patterns, achieving substantial accuracy gains. However, at the scale of thousands or even hundreds of thousands of loads in large distribution feeders, a deployment dilemma emerges: training and maintaining one model per customer is computationally and storage intensive, while using a single global model ignores distributional shifts across customer types, locations, and phases. Prior work typically focuses on single-load forecasters, global models across multiple loads, or adaptive/personalized models for relatively small settings, and rarely addresses the combined challenges of heterogeneity and scalability in large feeders. We propose M2OE2-GL, a global-to-local extension of the M2OE2 probabilistic forecaster. We first pretrain a single global M2OE2 base model across all feeder loads, then apply lightweight fine-tuning to derive a compact family of group-specific forecasters. Evaluated on realistic utility data, M2OE2-GL yields substantial error reductions while remaining scalable to very large numbers of loads.

</details>


### [351] [QML-HCS: A Hypercausal Quantum Machine Learning Framework for Non-Stationary Environments](https://arxiv.org/abs/2511.17624)
*Hector E Mozo*

Main category: cs.LG

TL;DR: QML-HCS是一个用于构建和分析量子启发的机器学习模型的框架，特别适用于非平稳环境中的超因果反馈动力学。


<details>
  <summary>Details</summary>
Motivation: 当前机器学习和量子启发系统在非平稳环境中表现不佳，数据分布漂移且模型缺乏连续适应、因果稳定性和相干状态更新的机制。

Method: 通过整合量子启发的叠加原理、动态因果反馈和确定性-随机混合执行，构建统一的超因果处理核心，支持可逆变换、多路径因果传播和漂移下的替代状态评估。

Result: 框架通过最小化模拟展示了超因果模型在输入分布突然变化时的适应能力，同时保持内部一致性，无需完全重新训练。

Conclusion: QML-HCS为未来的理论扩展、基准测试研究以及与经典和量子模拟平台的集成奠定了基础架构。

Abstract: QML-HCS is a research-grade framework for constructing and analyzing quantum-inspired machine learning models operating under hypercausal feedback dynamics. Hypercausal refers to AI systems that leverage extended, deep, or nonlinear causal relationships (expanded causality) to reason, predict, and infer states beyond the capabilities of traditional causal models. Current machine learning and quantum-inspired systems struggle in non-stationary environments, where data distributions drift and models lack mechanisms for continuous adaptation, causal stability, and coherent state updating. QML-HCS addresses this limitation through a unified computational architecture that integrates quantum-inspired superposition principles, dynamic causal feedback, and deterministic-stochastic hybrid execution to enable adaptive behavior in changing environments.
  The framework implements a hypercausal processing core capable of reversible transformations, multipath causal propagation, and evaluation of alternative states under drift. Its architecture incorporates continuous feedback to preserve causal consistency and adjust model behavior without requiring full retraining. QML-HCS provides a reproducible and extensible Python interface backed by efficient computational routines, enabling experimentation in quantum-inspired learning, causal reasoning, and hybrid computation without the need for specialized hardware.
  A minimal simulation demonstrates how a hypercausal model adapts to a sudden shift in the input distribution while preserving internal coherence. This initial release establishes the foundational architecture for future theoretical extensions, benchmarking studies, and integration with classical and quantum simulation platforms.

</details>


### [352] [Efficient Large-Scale Learning of Minimax Risk Classifiers](https://arxiv.org/abs/2511.17626)
*Kartheek Bondugula,Santiago Mazuelas,Aritz Pérez*

Main category: cs.LG

TL;DR: 提出了一种基于约束和列生成组合的学习算法，用于高效学习大规模多类分类任务中的极小极大风险分类器（MRCs）。


<details>
  <summary>Details</summary>
Motivation: 传统的随机次梯度方法适用于最小化平均损失的分类技术，但不适用于最小化最大期望损失的MRCs，需要一种能处理大规模多类分类的高效算法。

Method: 结合约束生成和列生成技术，开发了一种新的学习算法，能够有效处理大规模数据和多类分类问题。

Result: 在多个基准数据集上的实验表明，该算法在一般大规模数据上提供高达10倍的加速，在类别数量较多时提供约100倍的加速。

Conclusion: 该算法成功解决了MRCs在大规模多类分类中的计算效率问题，显著提升了学习速度。

Abstract: Supervised learning with large-scale data usually leads to complex optimization problems, especially for classification tasks with multiple classes. Stochastic subgradient methods can enable efficient learning with a large number of samples for classification techniques that minimize the average loss over the training samples. However, recent techniques, such as minimax risk classifiers (MRCs), minimize the maximum expected loss and are not amenable to stochastic subgradient methods. In this paper, we present a learning algorithm based on the combination of constraint and column generation that enables efficient learning of MRCs with large-scale data for classification tasks with multiple classes. Experiments on multiple benchmark datasets show that the proposed algorithm provides upto a 10x speedup for general large-scale data and around a 100x speedup with a sizeable number of classes.

</details>


### [353] [Rectifying Mean-Shift in Cascaded Precipitation Nowcasting](https://arxiv.org/abs/2511.17628)
*Fanbo Ju,Haiyuan Shi,Qingjian Ni*

Main category: cs.LG

TL;DR: 本文提出RectiCast框架，通过双流匹配模型明确解耦确定性预测的系统性分布偏移和局部随机性，以解决降水临近预报中现有级联架构的问题。


<details>
  <summary>Details</summary>
Motivation: 现有降水临近预报方法通常忽略确定性预测中的系统性分布偏移与局部随机性的混淆问题，导致概率组件的预测被污染，特别是在较长预报时效上出现降水模式和强度的不准确。

Method: RectiCast采用两阶段框架：第一阶段使用确定性模型生成后验均值；第二阶段引入Rectifier显式学习分布偏移并生成修正均值，随后Generator基于修正均值建模局部随机性。

Result: 在SEVIR和MeteoNet数据集上的实验表明，RectiCast相比现有最先进方法取得了显著的性能提升。

Conclusion: 通过明确解耦均值场偏移校正和局部随机性生成，RectiCast有效解决了级联架构中的分布偏移污染问题，提升了降水临近预报的准确性。

Abstract: Precipitation nowcasting, which aims to provide high spatio-temporal resolution precipitation forecasts by leveraging current radar observations, is a core task in regional weather forecasting. The cascaded architecture has emerged as the mainstream paradigm for deep learning-based precipitation nowcasting. This paradigm involves a deterministic model to predict macroscopic trends (or posterior mean), followed by a probabilistic model to generate local details (or local stochasticity). However, existing methods commonly overlook the conflation of the systematic distribution shift in deterministic predictions and the local stochasticity. As a result, the deterministic component's distribution shift contaminates the predictions of the probabilistic component, leading to inaccuracies in precipitation patterns and intensity, particularly over longer lead times. To address this issue, we introduce RectiCast, a two-stage framework that explicitly decouples the correction of mean-field shift from the generation of local stochasticity via a dual Flow Matching model. In the first stage, a deterministic model generates the posterior mean. In the second stage, we introduce a Rectifier to explicitly learn the distribution shift and produce a rectified mean. Subsequently, a Generator focuses on modeling the local stochasticity conditioned on the rectified mean. Experiments on SEVIR and MeteoNet demonstrate that RectiCast achieves significant performance improvements over existing state-of-the-art methods.

</details>


### [354] [Boundary-Aware Adversarial Filtering for Reliable Diagnosis under Extreme Class Imbalance](https://arxiv.org/abs/2511.17629)
*Yanxuan Yu,Michael S. Hughes,Julien Lee,Jiacheng Zhou,Andrew F. Laine*

Main category: cs.LG

TL;DR: AF-SMOTE是一种针对极端类别不平衡分类的新方法，通过合成少数类样本并使用对抗性判别器和边界效用模型进行过滤，在保持校准的同时提高召回率。


<details>
  <summary>Details</summary>
Motivation: 在医疗诊断等场景中，类别极度不平衡且召回率和校准都至关重要，漏诊罕见疾病可能导致严重后果。

Method: 提出AF-SMOTE框架：先合成少数类样本，然后通过对抗性判别器和边界效用模型进行过滤筛选。

Result: 在MIMIC-IV医疗数据集和欺诈检测基准测试中，AF-SMOTE比SMOTE、ADASYN等基线方法获得更高的召回率和平均精度，且校准效果最佳。

Conclusion: AF-SMOTE在医疗诊断等极端不平衡场景中具有重要实用价值，能有效提高罕见疾病的检测能力。

Abstract: We study classification under extreme class imbalance where recall and calibration are both critical, for example in medical diagnosis scenarios. We propose AF-SMOTE, a mathematically motivated augmentation framework that first synthesizes minority points and then filters them by an adversarial discriminator and a boundary utility model. We prove that, under mild assumptions on the decision boundary smoothness and class-conditional densities, our filtering step monotonically improves a surrogate of F_beta (for beta >= 1) while not inflating Brier score. On MIMIC-IV proxy label prediction and canonical fraud detection benchmarks, AF-SMOTE attains higher recall and average precision than strong oversampling baselines (SMOTE, ADASYN, Borderline-SMOTE, SVM-SMOTE), and yields the best calibration. We further validate these gains across multiple additional datasets beyond MIMIC-IV. Our successful application of AF-SMOTE to a healthcare dataset using a proxy label demonstrates in a disease-agnostic way its practical value in clinical situations, where missing true positive cases in rare diseases can have severe consequences.

</details>


### [355] [Can we use LLMs to bootstrap reinforcement learning? -- A case study in digital health behavior change](https://arxiv.org/abs/2511.17630)
*Nele Albers,Esra Cemre Su de Groot,Loes Keijsers,Manon H. Hillegers,Emiel Krahmer*

Main category: cs.LG

TL;DR: 本文探讨了使用大型语言模型（LLMs）生成用户交互样本，以辅助训练强化学习模型用于数字行为改变应用。研究表明，LLM生成的样本在没有真实数据的情况下具有实用价值，且性能可达人类评分者水平。


<details>
  <summary>Details</summary>
Motivation: 数字健康行为改变应用需要个性化适配用户状态，但开发过程中存在大量设计选择，其效果难以从文献预测且实践评估成本高昂。

Method: 使用四种大型行为改变研究的真实用户数据作为比较基准，评估LLM生成样本的有效性。分析了不同提示策略（包括简短/长提示变体、思维链提示和少样本提示）的相对效果。

Result: LLM生成的样本在缺乏真实数据时具有实用价值，性能可达人类评分者水平。不同提示策略的效果取决于具体研究和使用的LLM，即使是提示改写也会产生较大差异。

Conclusion: 研究提供了LLM生成样本在实际应用中的使用建议，证明其在数字行为改变场景中可作为有效的替代数据源。

Abstract: Personalizing digital applications for health behavior change is a promising route to making them more engaging and effective. This especially holds for approaches that adapt to users and their specific states (e.g., motivation, knowledge, wants) over time. However, developing such approaches requires making many design choices, whose effectiveness is difficult to predict from literature and costly to evaluate in practice. In this work, we explore whether large language models (LLMs) can be used out-of-the-box to generate samples of user interactions that provide useful information for training reinforcement learning models for digital behavior change settings. Using real user data from four large behavior change studies as comparison, we show that LLM-generated samples can be useful in the absence of real data. Comparisons to the samples provided by human raters further show that LLM-generated samples reach the performance of human raters. Additional analyses of different prompting strategies including shorter and longer prompt variants, chain-of-thought prompting, and few-shot prompting show that the relative effectiveness of different strategies depends on both the study and the LLM with also relatively large differences between prompt paraphrases alone. We provide recommendations for how LLM-generated samples can be useful in practice.

</details>


### [356] [Enhanced Federated Deep Multi-View Clustering under Uncertainty Scenario](https://arxiv.org/abs/2511.17631)
*Bingjun Wei,Xuemei Cao,Jiafen Liu,Haoyang Liang,Xin Yang*

Main category: cs.LG

TL;DR: EFDMVC框架通过局部语义对齐、层次对比融合和视图自适应漂移模块，解决了联邦多视图聚类中的视图不确定性和聚合不确定性，在异构视图完整性场景下表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 传统联邦多视图聚类假设客户端视图均匀，但实际部署中存在视图完整性异构问题（不完整、冗余或损坏数据），且现有方法忽略了动态视图组合带来的语义冲突和双重不确定性（视图不确定性和聚合不确定性）。

Method: 1. 局部语义对齐和层次对比融合解决视图不确定性；2. 视图自适应漂移模块通过全局-局部原型对比动态校正参数偏差；3. 平衡聚合机制协调客户端更新。

Result: 实验结果表明，EFDMVC在多个基准数据集上对异构不确定视图具有优越的鲁棒性，在全面评估中始终优于所有最先进的基线方法。

Conclusion: EFDMVC框架有效解决了联邦多视图聚类中的双重不确定性问题，为异构视图完整性场景提供了可靠的解决方案。

Abstract: Traditional Federated Multi-View Clustering assumes uniform views across clients, yet practical deployments reveal heterogeneous view completeness with prevalent incomplete, redundant, or corrupted data. While recent approaches model view heterogeneity, they neglect semantic conflicts from dynamic view combinations, failing to address dual uncertainties: view uncertainty (semantic inconsistency from arbitrary view pairings) and aggregation uncertainty (divergent client updates with imbalanced contributions). To address these, we propose a novel Enhanced Federated Deep Multi-View Clustering framework: first align local semantics, hierarchical contrastive fusion within clients resolves view uncertainty by eliminating semantic conflicts; a view adaptive drift module mitigates aggregation uncertainty through global-local prototype contrast that dynamically corrects parameter deviations; and a balanced aggregation mechanism coordinates client updates. Experimental results demonstrate that EFDMVC achieves superior robustness against heterogeneous uncertain views across multiple benchmark datasets, consistently outperforming all state-of-the-art baselines in comprehensive evaluations.

</details>


### [357] [Smart Manufacturing: MLOps-Enabled Event-Driven Architecture for Enhanced Control in Steel Production](https://arxiv.org/abs/2511.17632)
*Bestoun S. Ahmed,Tommaso Azzalin,Andreas Kassler,Andreas Thore,Hans Lindback*

Main category: cs.LG

TL;DR: 该论文提出了一种基于数字孪生的智能制造方法，通过微服务边缘计算平台和深度强化学习优化钢铁生产过程中的能耗、质量和效率。


<details>
  <summary>Details</summary>
Motivation: 将传统钢铁制造过程转变为智能系统，实现可持续发展目标，提高生产效率并降低成本，强调MLOps在数据驱动制造中的关键作用。

Method: 采用微服务边缘计算平台，通过实时传感器数据构建数字孪生，使用深度强化学习代理在MLOps驱动系统中自主优化感应炉加热参数和工艺设置。

Result: 系统能够有效优化电力设置，提高操作质量，减少工艺浪费，具有可扩展的事件驱动架构，可适应多种工业应用场景。

Conclusion: 该研究为传统工艺向智能系统转型提供了关键步骤，突出了数字孪生和MLOps在实现可持续、高效、经济智能制造中的重要作用。

Abstract: We explore a Digital Twin-Based Approach for Smart Manufacturing to improve Sustainability, Efficiency, and Cost-Effectiveness for a steel production plant. Our system is based on a micro-service edge-compute platform that ingests real-time sensor data from the process into a digital twin over a converged network infrastructure. We implement agile machine learning-based control loops in the digital twin to optimize induction furnace heating, enhance operational quality, and reduce process waste. Key to our approach is a Deep Reinforcement learning-based agent used in our machine learning operation (MLOps) driven system to autonomously correlate the system state with its digital twin to identify correction actions that aim to optimize power settings for the plant. We present the theoretical basis, architectural details, and practical implications of our approach to reduce manufacturing waste and increase production quality. We design the system for flexibility so that our scalable event-driven architecture can be adapted to various industrial applications. With this research, we propose a pivotal step towards the transformation of traditional processes into intelligent systems, aligning with sustainability goals and emphasizing the role of MLOps in shaping the future of data-driven manufacturing.

</details>


### [358] [PocketLLM: Ultimate Compression of Large Language Models via Meta Networks](https://arxiv.org/abs/2511.17637)
*Ye Tian,Chengcheng Wang,Jing Han,Yehui Tang,Kai Han*

Main category: cs.LG

TL;DR: PocketLLM是一种通过元网络在潜在空间压缩大语言模型的新方法，使用编码器将LLM权重投影到离散潜在向量，通过紧凑码本表示，再由轻量解码器重建权重，实现高压缩比且保持精度。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型规模不断增大，在边缘设备上存储和传输变得困难，传统量化剪枝方法难以实现极端压缩而不牺牲精度。

Method: 提出PocketLLM方法：使用简单编码器网络将LLM权重投影到离散潜在向量，用紧凑码本表示，再用轻量解码器将码本代表向量映射回原始权重空间。

Result: 实验表明PocketLLM在极高压缩比下仍保持优异性能，例如将Llama 2-7B压缩10倍，精度下降可忽略不计。

Conclusion: PocketLLM通过潜在空间压缩实现了大语言模型的高效压缩，为边缘设备部署提供了可行解决方案。

Abstract: As Large Language Models (LLMs) continue to grow in size, storing and transmitting them on edge devices becomes increasingly challenging. Traditional methods like quantization and pruning struggle to achieve extreme compression of LLMs without sacrificing accuracy. In this paper, we introduce PocketLLM, a novel approach to compress LLMs in a latent space via meta-networks. A simple encoder network is proposed to project the weights of LLMs into discrete latent vectors, which are then represented using a compact codebook. A lightweight decoder network is employed to map the codebook's representative vectors back to the original weight space. This method allows for significant compression of the large weights in LLMs, consisting solely of a small decoder, a concise codebook, and an index. Extensive experiments show that PocketLLM achieves superior performance even at significantly high compression ratios, e.g., compressing Llama 2-7B by 10x with a negligible drop in accuracy.

</details>


### [359] [Model-to-Model Knowledge Transmission (M2KT): A Data-Free Framework for Cross-Model Understanding Transfer](https://arxiv.org/abs/2511.17638)
*Pratham Sorte*

Main category: cs.LG

TL;DR: M2KT是一种无需数据的概念传输新范式，通过知识包在概念空间直接传递知识，相比传统知识蒸馏减少98%数据使用并达到85-90%教师模型性能


<details>
  <summary>Details</summary>
Motivation: 当前AI系统依赖大量数据进行知识迁移，传统方法需要教师模型生成示例、logits或梯度，存在数据依赖性强的问题

Method: 引入概念流形理论，建立模型间潜在空间对齐映射，设计几何、结构和推理一致性的复合损失函数，提出知识包生成和验证算法

Result: 在大语言模型符号推理任务中，M2KT达到教师模型85-90%性能，数据使用量减少超过98%

Conclusion: 为无数据AI间知识传输和自改进模型生态系统奠定了理论和实践基础

Abstract: Modern artificial intelligence systems depend heavily on large datasets for both training and transferring knowledge between models. Knowledge distillation, transfer learning, and dataset distillation have made such transfers more efficient, yet they remain fundamentally data-driven: a teacher must produce examples, logits, or gradients for a student to learn. In this work, we introduce Model-to-Model Knowledge Transmission (M2KT), a novel paradigm for data-free conceptual transfer between neural networks. M2KT enables models to exchange knowledge packets that encapsulate structured concept embeddings, abstraction graphs, reasoning traces, and provenance metadata. Unlike classical distillation, M2KT operates primarily in concept space rather than example space, and it does not require labeled datasets or teacher-generated outputs during transfer. We formalize the notion of concept manifolds, introduce an inter-model alignment mapping between teacher and student latent spaces, and derive a composite loss that enforces geometric, structural, and reasoning consistency together with explicit safety constraints. We further present algorithmic procedures for teacher-side packet generation and student-side ingestion and verification. Experiments on symbolic reasoning with large language models show that M2KT can achieve approximately 85 to 90 percent of teacher performance while reducing data usage by over 98 percent compared to standard knowledge distillation. This work establishes a theoretical and practical foundation for data-free AI-to-AI knowledge transfer and self-improving model ecosystems.

</details>


### [360] [TTF: A Trapezoidal Temporal Fusion Framework for LTV Forecasting in Douyin](https://arxiv.org/abs/2511.17639)
*Yibing Wan,Zhengxiong Guan,Chaoli Zhang,Xiaoyang Li,Lai Xu,Beibei Jia,Zhenzhe Zheng,Fan Wu*

Main category: cs.LG

TL;DR: 提出了TTF框架来解决LTV预测中的多时间序列不对齐、短输入长输出和波动性挑战，在抖音部署后显著提升了预测精度。


<details>
  <summary>Details</summary>
Motivation: 互联网公司在用户增长场景中大量投入付费获客渠道，但可持续增长取决于用户终身价值(LTV)超过获客成本(CAC)。为了最大化LTV/CAC比率，需要在早期阶段预测渠道级LTV以优化预算分配。

Method: 提出了梯形时间融合(TTF)框架，包含梯形多时间序列模块处理数据不对齐和SILO挑战，以及多塔结构MT-FusionNet输出准确预测。

Result: 在抖音在线系统部署后，相比之前部署的模型，LTV曲线的点级MAPE(MAPEp)降低了4.3%，聚合LTV的MAPE(MAPEa)降低了3.2%。

Conclusion: TTF框架有效解决了LTV预测中的三大挑战，在实际应用中表现出色，为预算分配优化提供了可靠的技术支持。

Abstract: In the user growth scenario, Internet companies invest heavily in paid acquisition channels to acquire new users. But sustainable growth depends on acquired users' generating lifetime value (LTV) exceeding customer acquisition cost (CAC). In order to maximize LTV/CAC ratio, it is crucial to predict channel-level LTV in an early stage for further optimization of budget allocation. The LTV forecasting problem is significantly different from traditional time series forecasting problems, and there are three main challenges. Firstly, it is an unaligned multi-time series forecasting problem that each channel has a number of LTV series of different activation dates. Secondly, to predict in the early stage, it faces the imbalanced short-input long-output (SILO) challenge. Moreover, compared with the commonly used time series datasets, the real LTV series are volatile and non-stationary, with more frequent fluctuations and higher variance. In this work, we propose a novel framework called Trapezoidal Temporal Fusion (TTF) to address the above challenges. We introduce a trapezoidal multi-time series module to deal with data unalignment and SILO challenges, and output accurate predictions with a multi-tower structure called MT-FusionNet. The framework has been deployed to the online system for Douyin. Compared to the previously deployed online model, MAPEp decreased by 4.3%, and MAPEa decreased by 3.2%, where MAPEp denotes the point-wise MAPE of the LTV curve and MAPEa denotes the MAPE of the aggregated LTV.

</details>


### [361] [BlockCert: Certified Blockwise Extraction of Transformer Mechanisms](https://arxiv.org/abs/2511.17645)
*Sandro Andric*

Main category: cs.LG

TL;DR: BlockCert是一个框架，用于经过认证的块级提取变压器机制，并支持经过认证的局部编辑。它提取残差块的结构化替代实现，并提供机器可检查的证书，以约束近似误差、记录覆盖指标并哈希底层工件。


<details>
  <summary>Details</summary>
Motivation: 动机在于为机械可解释性和模型编辑提供正式保证，避免当前评估方法中的非正式证据和临时实验，确保提取或编辑的模型在相关输入上与原始模型的偏差有明确界限。

Method: 方法包括引入BlockCert框架，通过Lipschitz-based组合定理在Lean 4中形式化局部保证，以提升到全局偏差界限。实验应用于GPT-2 small、TinyLlama-1.1B-Chat和Llama-3.2-3B模型。

Result: 实证结果显示，在这些模型中获得了高每块覆盖率和小的残差误差，在TinyLlama设置中，完全拼接的模型在压力提示下与基线困惑度匹配，误差约为6e-5。

Conclusion: 结论表明，带有明确证书的块级提取对于真实变压器语言模型是可行的，并为机械可解释性和模型行为的正式推理提供了实用桥梁。

Abstract: Mechanistic interpretability aspires to reverse-engineer neural networks into explicit algorithms, while model editing seeks to modify specific behaviours without retraining. Both areas are typically evaluated with informal evidence and ad-hoc experiments, with few explicit guarantees about how far an extracted or edited model can drift from the original on relevant inputs. We introduce BlockCert, a framework for certified blockwise extraction of transformer mechanisms, and outline how a lightweight extension can support certified local edits. Given a pre-trained transformer and a prompt distribution, BlockCert extracts structured surrogate implementations for residual blocks together with machine-checkable certificates that bound approximation error, record coverage metrics, and hash the underlying artifacts. We formalize a simple Lipschitz-based composition theorem in Lean 4 that lifts these local guarantees to a global deviation bound. Empirically, we apply the framework to GPT-2 small, TinyLlama-1.1B-Chat, and Llama-3.2-3B. Across these models we obtain high per-block coverage and small residual errors on the evaluated prompts, and in the TinyLlama setting we show that a fully stitched model matches the baseline perplexity within approximately 6e-5 on stress prompts. Our results suggest that blockwise extraction with explicit certificates is feasible for real transformer language models and offers a practical bridge between mechanistic interpretability and formal reasoning about model behaviour.

</details>


### [362] [MamTiff-CAD: Multi-Scale Latent Diffusion with Mamba+ for Complex Parametric Sequence](https://arxiv.org/abs/2511.17647)
*Liyuan Deng,Yunpeng Bai,Yongkang Dai,Xiaoshui Huang,Hongping Gan,Dongshuo Huang,Hao jiacheng,Yilei Shi*

Main category: cs.LG

TL;DR: MamTiff-CAD是一个基于Transformer扩散模型的CAD参数化命令序列生成框架，通过Mamba+和Transformer结合的自动编码器处理长序列，在60-256命令的长序列生成任务上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有的CAD参数化方法难以处理复杂CAD模型的几何和拓扑约束，特别是在生成长序列参数命令时面临挑战。

Method: 提出Mamba+和Transformer结合的自动编码器将CAD序列转换为潜在表示，Mamba+块使用遗忘门机制捕获长距离依赖，然后基于多尺度Transformer的扩散模型学习长序列命令分布。

Result: 实验表明MamTiff-CAD在重建和生成任务上都达到最先进性能，特别是在60-256命令的长序列CAD模型生成上表现优异。

Conclusion: MamTiff-CAD框架有效解决了长序列CAD参数命令生成问题，为复杂CAD模型的自动化生成提供了可行方案。

Abstract: Parametric Computer-Aided Design (CAD) is crucial in industrial applications, yet existing approaches often struggle to generate long sequence parametric commands due to complex CAD models' geometric and topological constraints. To address this challenge, we propose MamTiff-CAD, a novel CAD parametric command sequences generation framework that leverages a Transformer-based diffusion model for multi-scale latent representations. Specifically, we design a novel autoencoder that integrates Mamba+ and Transformer, to transfer parameterized CAD sequences into latent representations. The Mamba+ block incorporates a forget gate mechanism to effectively capture long-range dependencies. The non-autoregressive Transformer decoder reconstructs the latent representations. A diffusion model based on multi-scale Transformer is then trained on these latent embeddings to learn the distribution of long sequence commands. In addition, we also construct a dataset that consists of long parametric sequences, which is up to 256 commands for a single CAD model. Experiments demonstrate that MamTiff-CAD achieves state-of-the-art performance on both reconstruction and generation tasks, confirming its effectiveness for long sequence (60-256) CAD model generation.

</details>


### [363] [Frugality in second-order optimization: floating-point approximations for Newton's method](https://arxiv.org/abs/2511.17660)
*Giuseppe Carrino,Elena Loli Piccolomini,Elisa Riccietti,Theo Mary*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Minimizing loss functions is central to machine-learning training. Although first-order methods dominate practical applications, higher-order techniques such as Newton's method can deliver greater accuracy and faster convergence, yet are often avoided due to their computational cost. This work analyzes the impact of finite-precision arithmetic on Newton steps and establishes a convergence theorem for mixed-precision Newton optimizers, including "quasi" and "inexact" variants. The theorem provides not only convergence guarantees but also a priori estimates of the achievable solution accuracy. Empirical evaluations on standard regression benchmarks demonstrate that the proposed methods outperform Adam on the Australian and MUSH datasets. The second part of the manuscript introduces GN_k, a generalized Gauss-Newton method that enables partial computation of second-order derivatives. GN_k attains performance comparable to full Newton's method on regression tasks while requiring significantly fewer derivative evaluations.

</details>


### [364] [Enhancing Breast Cancer Prediction with LLM-Inferred Confounders](https://arxiv.org/abs/2511.17662)
*Debmita Roy*

Main category: cs.LG

TL;DR: 使用大型语言模型从常规临床数据中推断糖尿病、肥胖和心血管疾病等混杂疾病的患病可能性，从而提升乳腺癌预测性能。AI生成的特征提高了随机森林模型的表现，特别是Gemma（3.9%）和Llama（6.4%）模型。该方法为非侵入性预筛查和临床整合提供了潜力，支持乳腺癌诊断中的早期检测和共享决策。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌预测中混杂疾病（如糖尿病、肥胖和心血管疾病）的影响常被忽视，但可能显著影响预测准确性。本研究旨在利用大型语言模型从常规临床数据中自动推断这些混杂因素，以提升预测模型的性能。

Method: 采用大型语言模型（如Gemma和Llama）从常规临床数据中生成代表混杂疾病可能性的特征，然后将这些AI生成的特征输入随机森林模型进行乳腺癌预测。

Result: AI生成的特征显著提升了随机森林模型的性能，其中Gemma模型提升3.9%，Llama模型提升6.4%。这表明大型语言模型能有效捕捉临床数据中的隐含信息。

Conclusion: 该方法展示了利用大型语言模型进行非侵入性预筛查和临床整合的潜力，有助于改善乳腺癌的早期检测和医患共享决策过程。

Abstract: This study enhances breast cancer prediction by using large language models to infer the likelihood of confounding diseases, namely diabetes, obesity, and cardiovascular disease, from routine clinical data. These AI-generated features improved Random Forest model performance, particularly for LLMs like Gemma (3.9%) and Llama (6.4%). The approach shows promise for noninvasive prescreening and clinical integration, supporting improved early detection and shared decision-making in breast cancer diagnosis.

</details>


### [365] [AI-based framework to predict animal and pen feed intake in feedlot beef cattle](https://arxiv.org/abs/2511.17663)
*Alex S. C. Maia,John B. Hall,Hugo F. M. Milan,Izabelle A. M. A. Teixeira*

Main category: cs.LG

TL;DR: 该研究开发了一个基于AI的框架，利用环境数据和机器学习模型准确预测个体动物和围栏级别的饲料摄入量，为精准畜牧管理提供支持。


<details>
  <summary>Details</summary>
Motivation: 现有文献缺乏充分利用纵向大数据来准确预测饲料摄入量的方法，特别是在考虑环境条件的情况下。

Method: 使用19个实验的1650万+样本数据和环境数据，开发了两个新的环境指数（InComfort-Index和EASI-Index），并训练机器学习模型（XGBoost）来预测饲料摄入量。

Result: 最佳模型在个体动物级别的预测准确度为RMSE 1.38 kg/天，在围栏级别为0.14 kg/(天-动物)。EASI-Index在预测饲料摄入量方面表现良好。

Conclusion: 该AI框架为精准管理饲养场牛群提供了可靠工具，具有减少饲料浪费、优化资源和气候适应性管理的应用潜力。

Abstract: Advances in technology are transforming sustainable cattle farming practices, with electronic feeding systems generating big longitudinal datasets on individual animal feed intake, offering the possibility for autonomous precision livestock systems. However, the literature still lacks a methodology that fully leverages these longitudinal big data to accurately predict feed intake accounting for environmental conditions. To fill this gap, we developed an AI-based framework to accurately predict feed intake of individual animals and pen-level aggregation. Data from 19 experiments (>16.5M samples; 2013-2024) conducted at Nancy M. Cummings Research Extension & Education Center (Carmen, ID) feedlot facility and environmental data from AgriMet Network weather stations were used to develop two novel environmental indices: InComfort-Index, based solely on meteorological variables, showed good predictive capability for thermal comfort but had limited ability to predict feed intake; EASI-Index, a hybrid index integrating environmental variables with feed intake behavior, performed well in predicting feed intake but was less effective for thermal comfort. Together with the environmental indices, machine learning models were trained and the best-performing machine learning model (XGBoost) accuracy was RMSE of 1.38 kg/day for animal-level and only 0.14 kg/(day-animal) at pen-level. This approach provides a robust AI-based framework for predicting feed intake in individual animals and pens, with potential applications in precision management of feedlot cattle, through feed waste reduction, resource optimization, and climate-adaptive livestock management.

</details>


### [366] [CubeletWorld: A New Abstraction for Scalable 3D Modeling](https://arxiv.org/abs/2511.17664)
*Azlaan Mustafa Samad,Hoang H. Nguyen,Lukas Berg,Henrik Müller,Yuan Xue,Daniel Kudenko,Zahra Ahmadi*

Main category: cs.LG

TL;DR: CubeletWorld是一个基于离散化3D网格（cubelets）的城市环境建模框架，通过将多样化数据嵌入局部cubelet状态实现隐私保护建模，支持规划、导航和占用预测等任务。


<details>
  <summary>Details</summary>
Motivation: 解决现代城市异构数据集成困难、现有基于智能体感知的方法可扩展性差和隐私问题，需要一个不依赖智能体驱动的隐私保护城市建模框架。

Method: 提出CubeletWorld框架，将城市环境离散化为3D网格单元（cubelets），将基础设施、移动数据、环境指标等多样数据嵌入cubelet状态，并探索适合该设置的改进核心模型。

Result: CubeletWorld提供了一个灵活可扩展的框架，能够从复杂城市数据中学习，在空间单元级别推断状态，具有更好的跨区域通用性和隐私合规性。

Conclusion: CubeletWorld为城市数据学习提供了新的可能性，支持可扩展的模拟和决策支持，适用于社会人口建模、环境监测和应急响应等领域。

Abstract: Modern cities produce vast streams of heterogeneous data, from infrastructure maps to mobility logs and satellite imagery. However, integrating these sources into coherent spatial models for planning and prediction remains a major challenge. Existing agent-centric methods often rely on direct environmental sensing, limiting scalability and raising privacy concerns. This paper introduces CubeletWorld, a novel framework for representing and analyzing urban environments through a discretized 3D grid of spatial units called cubelets. This abstraction enables privacy-preserving modeling by embedding diverse data signals, such as infrastructure, movement, or environmental indicators, into localized cubelet states. CubeletWorld supports downstream tasks such as planning, navigation, and occupancy prediction without requiring agent-driven sensing. To evaluate this paradigm, we propose the CubeletWorld State Prediction task, which involves predicting the cubelet state using a realistic dataset containing various urban elements like streets and buildings through this discretized representation. We explore a range of modified core models suitable for our setting and analyze challenges posed by increasing spatial granularity, specifically the issue of sparsity in representation and scalability of baselines. In contrast to existing 3D occupancy prediction models, our cubelet-centric approach focuses on inferring state at the spatial unit level, enabling greater generalizability across regions and improved privacy compliance. Our results demonstrate that CubeletWorld offers a flexible and extensible framework for learning from complex urban data, and it opens up new possibilities for scalable simulation and decision support in domains such as socio-demographic modeling, environmental monitoring, and emergency response. The code and datasets can be downloaded from here.

</details>


### [367] [GANGR: GAN-Assisted Scalable and Efficient Global Routing Parallelization](https://arxiv.org/abs/2511.17665)
*Hadi Khodaei Jooshin,Inna Partin-Vaisband*

Main category: cs.LG

TL;DR: 本文提出了一种基于Wasserstein生成对抗网络(WGANs)的新型全局路由批处理算法，能够在更短时间内生成更少但质量更高的批次，实现40%的运行时间减少，且路由质量仅下降0.002%。


<details>
  <summary>Details</summary>
Motivation: 传统全局路由中的批处理方法依赖计算成本高的启发式算法，导致批次过大、批次数量过多、生成时间过长等问题，限制了可扩展性和效率。

Method: 采用Wasserstein生成对抗网络(WGANs)增强的新型批处理算法，优化批次生成过程，实现更有效的并行化处理。

Result: 在ISPD'24竞赛基准测试中，相比最先进的全局路由器，运行时间减少高达40%，路由质量仅下降0.002%。

Conclusion: 基于WGANs的批处理算法显著提升了全局路由的效率和可扩展性，为电子设计自动化(EDA)中的全局路由问题提供了有效的解决方案。

Abstract: Global routing is a critical stage in electronic design automation (EDA) that enables early estimation and optimization of the routability of modern integrated circuits with respect to congestion, power dissipation, and design complexity. Batching is a primary concern in top-performing global routers, grouping nets into manageable sets to enable parallel processing and efficient resource usage. This process improves memory usage, scalable parallelization on modern hardware, and routing congestion by controlling net interactions within each batch. However, conventional batching methods typically depend on heuristics that are computationally expensive and can lead to suboptimal results (oversized batches with conflicting nets, excessive batch counts degrading parallelization, and longer batch generation times), ultimately limiting scalability and efficiency. To address these limitations, a novel batching algorithm enhanced with Wasserstein generative adversarial networks (WGANs) is introduced in this paper, enabling more effective parallelization by generating fewer higher-quality batches in less time. The proposed algorithm is tested on the latest ISPD'24 contest benchmarks, demonstrating up to 40% runtime reduction with only 0.002% degradation in routing quality as compared to state-of-the-art router.

</details>


### [368] [Lane-Frame Quantum Multimodal Driving Forecasts for the Trajectory of Autonomous Vehicles](https://arxiv.org/abs/2511.17675)
*Navneet Singh,Shiva Raj Pokhrel*

Main category: cs.LG

TL;DR: 提出一种紧凑的混合量子架构，用于自动驾驶轨迹预测，通过残差学习和量子注意力编码器实现高效的多模态轨迹预测。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶轨迹预测需要在计算和延迟约束下提供准确、校准的多模态未来预测，传统方法难以同时满足这些要求。

Method: 采用混合量子架构，包括量子注意力编码器（9量子比特）、参数精简的量子前馈堆栈（64层，约1200个可训练角度）和基于傅里叶的解码器，使用SPSA进行参数训练。

Result: 在Waymo Open Motion Dataset上，模型在2.0秒预测范围内达到minADE 1.94米和minFDE 3.56米，优于运动学基线。

Conclusion: 残差学习、截断傅里叶解码、浅层纠缠和基于频谱的排名等方法有效提升了量子电路在自动驾驶轨迹预测中的性能。

Abstract: Trajectory forecasting for autonomous driving must deliver accurate, calibrated multi-modal futures under tight compute and latency constraints. We propose a compact hybrid quantum architecture that aligns quantum inductive bias with road-scene structure by operating in an ego-centric, lane-aligned frame and predicting residual corrections to a kinematic baseline instead of absolute poses. The model combines a transformer-inspired quantum attention encoder (9 qubits), a parameter-lean quantum feedforward stack (64 layers, ${\sim}1200$ trainable angles), and a Fourier-based decoder that uses shallow entanglement and phase superposition to generate 16 trajectory hypotheses in a single pass, with mode confidences derived from the latent spectrum. All circuit parameters are trained with Simultaneous Perturbation Stochastic Approximation (SPSA), avoiding backpropagation through non-analytic components. In the Waymo Open Motion Dataset, the model achieves minADE (minimum Average Displacement Error) of \SI{1.94}{m} and minFDE (minimum Final Displacement Error) of \SI{3.56}{m} in the $16$ models predicted over the horizon of \SI{2.0}{s}, consistently outperforming a kinematic baseline with reduced miss rates and strong recall. Ablations confirm that residual learning in the lane frame, truncated Fourier decoding, shallow entanglement, and spectrum-based ranking focus capacity where it matters, yielding stable optimization and reliable multi-modal forecasts from small, shallow quantum circuits on a modern autonomous-driving benchmark.

</details>


### [369] [A Hybrid Classical-Quantum Fine Tuned BERT for Text Classification](https://arxiv.org/abs/2511.17677)
*Abu Kaisar Mohammad Masum,Naveed Mahmud,M. Hassan Najafi,Sercan Aygun*

Main category: cs.LG

TL;DR: 提出了一种将n量子比特量子电路与经典BERT模型结合的混合方法用于文本分类，实验表明该混合模型在标准基准数据集上具有竞争力甚至优于经典基线。


<details>
  <summary>Details</summary>
Motivation: BERT微调计算成本高且需要精细的超参数调优，而量子算法在机器学习和文本分类任务中显示出超越传统方法的潜力。

Method: 集成n量子比特量子电路与经典BERT模型的混合方法，用于文本分类任务。

Result: 混合模型在标准基准数据集上表现与经典基线相当，在某些情况下更优，证明了该方法在微调预训练模型方面的适应性。

Conclusion: 混合模型展示了量子计算在提升文本分类任务性能方面的潜力，为这一研究领域的发展提供了可行性证明。

Abstract: Fine-tuning BERT for text classification can be computationally challenging and requires careful hyper-parameter tuning. Recent studies have highlighted the potential of quantum algorithms to outperform conventional methods in machine learning and text classification tasks. In this work, we propose a hybrid approach that integrates an n-qubit quantum circuit with a classical BERT model for text classification. We evaluate the performance of the fine-tuned classical-quantum BERT and demonstrate its feasibility as well as its potential in advancing this research area. Our experimental results show that the proposed hybrid model achieves performance that is competitive with, and in some cases better than, the classical baselines on standard benchmark datasets. Furthermore, our approach demonstrates the adaptability of classical-quantum models for fine-tuning pre-trained models across diverse datasets. Overall, the hybrid model highlights the promise of quantum computing in achieving improved performance for text classification tasks.

</details>


### [370] [Boosting Brain-inspired Path Integration Efficiency via Learning-based Replication of Continuous Attractor Neurodynamics](https://arxiv.org/abs/2511.17687)
*Zhangyu Ge,Xu He,Lingfei Mo,Xiaolin Meng,Wenxuan Yin,Youdong Zhang,Lansong Jiang,Fengyuan Liu*

Main category: cs.LG

TL;DR: 本文提出了一种基于表示学习模型的高效路径积分方法，通过轻量级人工神经网络复制连续吸引子神经网络的神经动力学模式，实现了大脑启发导航中头方向细胞和网格细胞的功能重建。


<details>
  <summary>Details</summary>
Motivation: 现有大脑启发导航研究中的路径积分机制存在显著计算冗余和效率问题，不利于该技术的实际应用。

Method: 使用表示学习模型复制CANNs的神经动力学模式，用轻量级ANN重建HDC和GC模型，并将它们集成实现基于航位推算的脑启发路径积分。

Result: 在各种环境下的基准测试表明，该方法不仅准确复制了导航细胞的神经动力学模式，定位精度与NeuroSLAM相当，而且在通用设备上效率提升约17.5%，在边缘设备上提升40~50%。

Conclusion: 这项工作为增强大脑启发导航技术的实用性提供了一种新颖的实现策略，并具有进一步扩展的潜力。

Abstract: The brain's Path Integration (PI) mechanism offers substantial guidance and inspiration for Brain-Inspired Navigation (BIN). However, the PI capability constructed by the Continuous Attractor Neural Networks (CANNs) in most existing BIN studies exhibits significant computational redundancy, and its operational efficiency needs to be improved; otherwise, it will not be conducive to the practicality of BIN technology. To address this, this paper proposes an efficient PI approach using representation learning models to replicate CANN neurodynamic patterns. This method successfully replicates the neurodynamic patterns of CANN-modeled Head Direction Cells (HDCs) and Grid Cells (GCs) using lightweight Artificial Neural Networks (ANNs). These ANN-reconstructed HDC and GC models are then integrated to achieve brain-inspired PI for Dead Reckoning (DR). Benchmark tests in various environments, compared with the well-known NeuroSLAM system, demonstrate that this work not only accurately replicates the neurodynamic patterns of navigation cells but also matches NeuroSLAM in positioning accuracy. Moreover, efficiency improvements of approximately 17.5% on the general-purpose device and 40~50% on the edge device were observed, compared with NeuroSLAM. This work offers a novel implementation strategy to enhance the practicality of BIN technology and holds potential for further extension.

</details>


### [371] [Enhancing Adversarial Transferability through Block Stretch and Shrink](https://arxiv.org/abs/2511.17688)
*Quan Liu,Feng Ye,Chenhao Lu,Shuming Zhen,Guanliang Huang,Lunzhe Chen,Xudong Ke*

Main category: cs.LG

TL;DR: 该论文提出了一种名为Block Stretch and Shrink (BSS)的新方法，通过将图像分块并进行拉伸和收缩操作来增强对抗样本的跨模型迁移性，并在ImageNet子集上验证了其优于现有输入变换攻击方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于输入变换的对抗攻击方法在跨模型迁移性方面存在局限，研究表明高迁移性与多样化的注意力热图和保持全局语义相关。因此需要一种能够同时实现这两个目标的新方法。

Method: 提出BSS方法：将图像分割成多个块，对这些块应用拉伸和收缩变换操作，从而在变换后的输入中实现注意力热图的多样化，同时保持图像的全局语义结构。

Result: 在ImageNet子集上的实验表明，BSS方法在对抗样本的迁移性方面优于现有的输入变换攻击方法。同时研究了变换输入数量对攻击效果的影响。

Conclusion: BSS方法通过分块拉伸收缩操作有效提升了对抗攻击的迁移性，建议在统一变换数量标准下评估输入变换攻击方法以确保公平比较。

Abstract: Adversarial attacks introduce small, deliberately crafted perturbations that mislead neural networks, and their transferability from white-box to black-box target models remains a critical research focus. Input transformation-based attacks are a subfield of adversarial attacks that enhance input diversity through input transformations to improve the transferability of adversarial examples. However, existing input transformation-based attacks tend to exhibit limited cross-model transferability. Previous studies have shown that high transferability is associated with diverse attention heatmaps and the preservation of global semantics in transformed inputs. Motivated by this observation, we propose Block Stretch and Shrink (BSS), a method that divides an image into blocks and applies stretch and shrink operations to these blocks, thereby diversifying attention heatmaps in transformed inputs while maintaining their global semantics. Empirical evaluations on a subset of ImageNet demonstrate that BSS outperforms existing input transformation-based attack methods in terms of transferability. Furthermore, we examine the impact of the number scale, defined as the number of transformed inputs, in input transformation-based attacks, and advocate evaluating these methods under a unified number scale to enable fair and comparable assessments.

</details>


### [372] [DeepCoT: Deep Continual Transformers for Real-Time Inference on Data Streams](https://arxiv.org/abs/2511.17693)
*Ginés Carreto Picón,Peng Yuan Zhou,Qi Zhang,Alexandros Iosifidis*

Main category: cs.LG

TL;DR: 提出DeepCoT模型，解决深层Transformer在流数据推理中的计算冗余问题，实现线性计算复杂度


<details>
  <summary>Details</summary>
Motivation: 现有Continual Transformers只能用于浅层模型，限制了泛化能力；深层Transformer在流数据推理中存在高度冗余计算

Method: 提出Deep Continual Transformer (DeepCoT)，一种无冗余的编码器模型，可应用于现有深度编码器架构，只需最小改动

Result: 在音频、视频和文本流数据上的实验表明，DeepCoT与非连续基线模型性能相当，但计算复杂度线性降低，运行时间比之前高效模型减少两个数量级

Conclusion: DeepCoT成功解决了深层Transformer在流数据推理中的计算效率问题，为资源受限设备上的低延迟推理提供了有效解决方案

Abstract: Transformer-based models have dramatically increased their size and parameter count to tackle increasingly complex tasks. At the same time, there is a growing demand for low-latency inference on resource-constrained devices that achieves high performance. In particular, stream data inference is typically performed over a sliding temporal window, leading to highly redundant computations. The recent Continual Transformers have addressed this issue, but they can only be effectively used in shallow models, which limits their scope and generalization power. In this paper, we propose the Deep Continual Transformer (DeepCoT), a redundancy-free encoder-only model that can be applied over existing deep encoder architectures with minimal changes. In our experiments over audio, video, and text streams, we show that DeepCoTs retain comparative performance to their non-continual baselines while offering a linear computational cost for all Transformer layers, which reduces up to two orders of magnitude in the running time compared to previous efficient models.

</details>


### [373] [Diffusion Models are Molecular Dynamics Simulators](https://arxiv.org/abs/2511.17741)
*Justin Diamond,Markus Lill*

Main category: cs.LG

TL;DR: 该论文证明了带有批次维度顺序偏置的去噪扩散采样器等价于过阻尼朗之万动力学的欧拉-马鲁亚马积分器，建立了扩散采样与朗之万时间演化之间的精确对应关系。


<details>
  <summary>Details</summary>
Motivation: 将分子动力学重新表述为扩散模型，摆脱传统MD方法对极小时间步长的依赖，通过模型容量和去噪步数两个可扩展参数来控制精度。

Method: 利用去噪扩散采样器，每个反向去噪步骤对应随机微分方程的一个积分步骤，学习到的得分函数扮演漂移项的角色，等价于学习能量的梯度。

Result: 提出了完全数据驱动的MD框架，从非相关平衡快照中学习力场，无需人工设计的力场或轨迹数据进行训练，仍能保持与学习能量相关的玻尔兹曼分布。

Conclusion: 该工作建立了扩散采样与朗之万动力学之间的数学等价性，为分子模拟提供了新的理论框架和实用方法，能够生成具有MD类时间相关性的分子轨迹。

Abstract: We prove that a denoising diffusion sampler equipped with a sequential bias across the batch dimension is exactly an Euler-Maruyama integrator for overdamped Langevin dynamics. Each reverse denoising step, with its associated spring stiffness, can be interpreted as one step of a stochastic differential equation with an effective time step set jointly by the noise schedule and that stiffness. The learned score then plays the role of the drift, equivalently the gradient of a learned energy, yielding a precise correspondence between diffusion sampling and Langevin time evolution.
  This equivalence recasts molecular dynamics (MD) in terms of diffusion models. Accuracy is no longer tied to a fixed, extremely small MD time step; instead, it is controlled by two scalable knobs: model capacity, which governs how well the drift is approximated, and the number of denoising steps, which sets the integrator resolution. In practice, this leads to a fully data-driven MD framework that learns forces from uncorrelated equilibrium snapshots, requires no hand-engineered force fields, uses no trajectory data for training, and still preserves the Boltzmann distribution associated with the learned energy.
  We derive trajectory-level, information-theoretic error bounds that cleanly separate discretization error from score-model error, clarify how temperature enters through the effective spring, and show that the resulting sampler generates molecular trajectories with MD-like temporal correlations, even though the model is trained only on static configurations.

</details>


### [374] [Periodicity-Enforced Neural Network for Designing Deterministic Lateral Displacement Devices](https://arxiv.org/abs/2511.17754)
*Andrew Lee,Mahir Mobarrat,Xiaolin Chen*

Main category: cs.LG

TL;DR: 提出了一种基于周期性层增强的深度学习替代模型，用于确定性侧向位移（DLD）微流控器件的设计，通过架构强制保证周期性边界条件，显著提高了多单元器件预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统DLD器件设计依赖计算昂贵的Navier-Stokes模拟和粒子追踪分析，现有深度学习替代模型难以有效处理关键周期性边界条件，导致多单元器件预测出现累积误差。

Method: 采用周期性层神经网络组件，通过三个子网络预测稳态非维度速度场和压力场（u, v, p），而非直接预测临界直径或粒子轨迹，通过架构强制而非惩罚项确保周期性边界条件的精确匹配。

Result: 在120个CFD生成的几何结构上验证，周期性层实现达到0.478%的临界直径误差，同时保持完美的周期性一致性，相比基线方法提升85.4%。

Conclusion: 该方法能够高效准确地设计DLD器件，为多单元器件应用提供保证的边界条件满足。

Abstract: Deterministic Lateral Displacement (DLD) devices enable liquid biopsy for cancer detection by separating circulating tumor cells (CTCs) from blood samples based on size, but designing these microfluidic devices requires computationally expensive Navier-Stokes simulations and particle-tracing analyses. While recent surrogate modeling approaches using deep learning have accelerated this process, they often inadequately handle the critical periodic boundary conditions of DLD unit cells, leading to cumulative errors in multi-unit device predictions. This paper introduces a periodicity-enforced surrogate modeling approach that incorporates periodic layers, neural network components that guarantee exact periodicity without penalty terms or output modifications, into deep learning architectures for DLD device design. The proposed method employs three sub-networks to predict steady-state, non-dimensional velocity and pressure fields (u, v, p) rather than directly predicting critical diameters or particle trajectories, enabling complete flow field characterization and enhanced design flexibility. Periodic layers ensure exact matching of flow variables across unit cell boundaries through architectural enforcement rather than soft penalty-based approaches. Validation on 120 CFD-generated geometries demonstrates that the periodic layer implementation achieves 0.478% critical diameter error while maintaining perfect periodicity consistency, representing an 85.4% improvement over baseline methods. The approach enables efficient and accurate DLD device design with guaranteed boundary condition satisfaction for multi-unit device applications.

</details>


### [375] [PrismSSL: One Interface, Many Modalities; A Single-Interface Library for Multimodal Self-Supervised Learning](https://arxiv.org/abs/2511.17776)
*Melika Shirian,Kianoosh Vadaei,Kian Majlessi,Audrina Ebrahimi,Arshia Hemmat,Peyman Adibi,Hossein Karshenas*

Main category: cs.LG

TL;DR: PrismSSL是一个统一的Python库，集成了音频、视觉、图数据和跨模态的自监督学习方法，提供模块化代码库和便捷的训练功能。


<details>
  <summary>Details</summary>
Motivation: 为了解决自监督学习在不同模态中方法分散、代码重复的问题，提供一个统一的框架来简化研究和使用。

Method: 采用模块化设计，集成HuggingFace Transformers，支持分布式训练、超参数搜索、LoRA微调等功能，并提供图形化界面。

Result: 开发了PrismSSL库，支持多种模态的自监督学习，提供了完整的训练和评估流程。

Conclusion: PrismSSL成功统一了多模态自监督学习方法，为研究者和实践者提供了高效、易用的工具。

Abstract: We present PrismSSL, a Python library that unifies state-of-the-art self-supervised learning (SSL) methods across audio, vision, graphs, and cross-modal settings in a single, modular codebase. The goal of the demo is to show how researchers and practitioners can: (i) install, configure, and run pretext training with a few lines of code; (ii) reproduce compact benchmarks; and (iii) extend the framework with new modalities or methods through clean trainer and dataset abstractions. PrismSSL is packaged on PyPI, released under the MIT license, integrates tightly with HuggingFace Transformers, and provides quality-of-life features such as distributed training in PyTorch, Optuna-based hyperparameter search, LoRA fine-tuning for Transformer backbones, animated embedding visualizations for sanity checks, Weights & Biases logging, and colorful, structured terminal logs for improved usability and clarity. In addition, PrismSSL offers a graphical dashboard - built with Flask and standard web technologies - that enables users to configure and launch training pipelines with minimal coding. The artifact (code and data recipes) will be publicly available and reproducible.

</details>


### [376] [Smoothed Agnostic Learning of Halfspaces over the Hypercube](https://arxiv.org/abs/2511.17782)
*Yiwen Kou,Raghu Meka*

Main category: cs.LG

TL;DR: 本文提出了一种新的布尔输入的平滑不可知学习框架，使用随机位翻转扰动来绕过布尔半空间学习的计算困难，在亚指数分布假设下实现了高效学习算法。


<details>
  <summary>Details</summary>
Motivation: 布尔半空间的不可知学习在计算学习理论中是一个基本问题，但即使是弱学习也被证明是计算困难的。现有的平滑分析框架依赖于加性高斯扰动，不适用于离散域。

Method: 引入基于随机位翻转的平滑扰动模型，定义了高斯情况的自然离散模拟。在输入分布满足严格亚指数假设的条件下，设计了高效学习算法。

Result: 算法的时间和样本复杂度约为n的多项式因子，首次在布尔超立方体上实现了平滑不可知半空间学习的计算效率保证。

Conclusion: 该研究弥合了最坏情况不可处理性与实际可学习性之间的差距，为离散设置下的半空间学习提供了首个计算效率保证。

Abstract: Agnostic learning of Boolean halfspaces is a fundamental problem in computational learning theory, but it is known to be computationally hard even for weak learning. Recent work [CKKMK24] proposed smoothed analysis as a way to bypass such hardness, but existing frameworks rely on additive Gaussian perturbations, making them unsuitable for discrete domains. We introduce a new smoothed agnostic learning framework for Boolean inputs, where perturbations are modeled via random bit flips. This defines a natural discrete analogue of smoothed optimality generalizing the Gaussian case. Under strictly subexponential assumptions on the input distribution, we give an efficient algorithm for learning halfspaces in this model, with runtime and sample complexity approximately n raised to a poly(1/(sigma * epsilon)) factor. Previously, such algorithms were known only with strong structural assumptions for the discrete hypercube, for example, independent coordinates or symmetric distributions. Our result provides the first computationally efficient guarantee for smoothed agnostic learning of halfspaces over the Boolean hypercube, bridging the gap between worst-case intractability and practical learnability in discrete settings.

</details>


### [377] [Improved Sample Complexity for Full Coverage in Compact and Continuous Spaces](https://arxiv.org/abs/2511.17784)
*Lyu Yuhuan*

Main category: cs.LG

TL;DR: 该论文提出了一个基于随机采样的覆盖分析新方法，通过在d维单位超立方体上应用离散化技术，推导出样本复杂度与失败概率对数相关的紧致边界，相比经典的1/δ线性依赖有明显改进。


<details>
  <summary>Details</summary>
Motivation: 经典覆盖分析在小失败概率下往往产生保守的边界，限制了基于网格覆盖保证算法的效率，特别是在高置信度场景下。

Method: 使用d维单位超立方体的均匀随机采样，对未覆盖子立方体数量应用集中不等式，推导样本复杂度边界。在标准Lipschitz和均匀性假设下进行自包含推导。

Result: 得到样本复杂度M=O(Čln(2Č/δ))，其中δ为失败概率，相比经典线性1/δ依赖有显著改进。数值研究表明该边界能更紧密地跟踪实际覆盖需求。

Conclusion: 该方法为依赖网格覆盖保证的算法提供了更锐利的理论工具，特别是在高置信度机制下能实现更高效的采样。

Abstract: Verifying uniform conditions over continuous spaces through random sampling is fundamental in machine learning and control theory, yet classical coverage analyses often yield conservative bounds, particularly at small failure probabilities. We study uniform random sampling on the $d$-dimensional unit hypercube and analyze the number of uncovered subcubes after discretization. By applying a concentration inequality to the uncovered-count statistic, we derive a sample complexity bound with a logarithmic dependence on the failure probability ($δ$), i.e., $M =O( \tilde{C}\ln(\frac{2\tilde{C}}δ))$, which contrasts sharply with the classical linear $1/δ$ dependence. Under standard Lipschitz and uniformity assumptions, we present a self-contained derivation and compare our result with classical coupon-collector rates. Numerical studies across dimensions, precision levels, and confidence targets indicate that our bound tracks practical coverage requirements more tightly and scales favorably as $δ\to 0$. Our findings offer a sharper theoretical tool for algorithms that rely on grid-based coverage guarantees, enabling more efficient sampling, especially in high-confidence regimes.

</details>


### [378] [Data-Driven Predictive Modeling of Microfluidic Cancer Cell Separation Using a Deterministic Lateral Displacement Device](https://arxiv.org/abs/2511.17787)
*Elizabeth Chen,Andrew Lee,Tanbir Sarowar,Xiaolin Chen*

Main category: cs.LG

TL;DR: 本研究通过机器学习模型优化确定性横向位移（DLD）设备的设计参数，以提高肺癌细胞分离效率，为癌症早期诊断提供高效、低成本的微流控系统解决方案。


<details>
  <summary>Details</summary>
Motivation: 确定性横向位移设备在微流控技术中用于无标记、基于尺寸的颗粒和细胞分离，尤其在循环肿瘤细胞分离方面具有潜力。但稀有细胞检测难度大且依赖计算密集型模拟，需要更高效的优化方法。

Method: 采用梯度提升、k近邻、随机森林和多层感知机等机器学习模型，基于数值验证的大规模数据集预测颗粒轨迹并识别最优设备配置参数（如行移分数、柱尺寸和间隙距离）。

Result: 机器学习模型能够准确预测粒子轨迹，实现高通量、低成本的DLD设备设计优化，并识别关键设计变量，为自动化优化提供系统化框架。

Conclusion: 这种集成方法推动了可扩展、精确的微流控系统在癌症诊断中的发展，有助于实现早期检测和个性化医疗的宏观目标。

Abstract: Deterministic Lateral Displacement (DLD) devices are widely used in microfluidics for label-free, size-based separation of particles and cells, with particular promise in isolating circulating tumor cells (CTCs) for early cancer diagnostics. This study focuses on the optimization of DLD design parameters, such as row shift fraction, post size, and gap distance, to enhance the selective isolation of lung cancer cells based on their physical properties. To overcome the challenges of rare CTC detection and reduce reliance on computationally intensive simulations, machine learning models including gradient boosting, k-nearest neighbors, random forest, and multilayer perceptron (MLP) regressors are employed. Trained on a large, numerically validated dataset, these models predict particle trajectories and identify optimal device configurations, enabling high-throughput and cost-effective DLD design. Beyond trajectory prediction, the models aid in isolating critical design variables, offering a systematic, data-driven framework for automated DLD optimization. This integrative approach advances the development of scalable and precise microfluidic systems for cancer diagnostics, contributing to the broader goals of early detection and personalized medicine.

</details>


### [379] [Physical Reinforcement Learning](https://arxiv.org/abs/2511.17789)
*Sam Dillavou,Shruti Mishra*

Main category: cs.LG

TL;DR: 本文展示了如何使用模拟对比局部学习网络（CLLNs）成功解决两个简单的强化学习问题，通过将Q学习算法适配到这种模拟网络中。


<details>
  <summary>Details</summary>
Motivation: 数字计算机功耗高且对组件损坏敏感，不适合在不确定环境中为能量受限的自主代理使用。而CLLNs作为模拟网络具有低功耗和物理损伤鲁棒性，但之前仅用于监督学习。

Method: 将Q学习算法适配到模拟的CLLNs中，明确识别了强化学习工具箱中除训练网络外所需的其他组件，如策略函数和价值函数。

Result: 成功在两个简单的强化学习问题上验证了CLLNs的应用可行性，证明了这种模拟网络在强化学习任务中的有效性。

Conclusion: CLLNs可以放弃数字硬件所需的物理安全假设，这与生物系统类似，同时能够训练对数字计算机无意义但对生物学重要的次要目标。

Abstract: Digital computers are power-hungry and largely intolerant of damaged components, making them potentially difficult tools for energy-limited autonomous agents in uncertain environments. Recently developed Contrastive Local Learning Networks (CLLNs) - analog networks of self-adjusting nonlinear resistors - are inherently low-power and robust to physical damage, but were constructed to perform supervised learning. In this work we demonstrate success on two simple RL problems using Q-learning adapted for simulated CLLNs. Doing so makes explicit the components (beyond the network being trained) required to enact various tools in the RL toolbox, some of which (policy function and value function) are more natural in this system than others (replay buffer). We discuss assumptions such as the physical safety that digital hardware requires, CLLNs can forgo, and biological systems cannot rely on, and highlight secondary goals that are important in biology and trainable in CLLNs, but make little sense in digital computers.

</details>


### [380] [Semi-Supervised Federated Multi-Label Feature Selection with Fuzzy Information Measures](https://arxiv.org/abs/2511.17796)
*Afsaneh Mahanipour,Hana Khamfroush*

Main category: cs.LG

TL;DR: 提出了一种半监督联邦多标签特征选择方法SSFMLFS，适用于客户端只有未标记数据、服务器有少量标记数据的联邦学习场景，通过模糊信息理论和PageRank算法实现特征选择。


<details>
  <summary>Details</summary>
Motivation: 现有多标签特征选择方法需要集中式数据，不适用于分布式和联邦环境；联邦方法通常假设客户端有标记数据，但现实中客户端可能缺乏标记能力。

Method: SSFMLFS将模糊信息理论应用于联邦设置：客户端计算模糊相似矩阵并传输给服务器，服务器计算特征冗余度和特征-标签相关性度，构建特征图并使用PageRank算法对特征进行排序。

Result: 在五个真实世界数据集上的实验表明，SSFMLFS在非独立同分布数据设置下，在三种不同评估指标上都优于其他联邦和集中式监督及半监督方法。

Conclusion: SSFMLFS成功解决了联邦环境中客户端只有未标记数据的特征选择问题，在多个领域的数据集上表现出优越性能。

Abstract: Multi-label feature selection (FS) reduces the dimensionality of multi-label data by removing irrelevant, noisy, and redundant features, thereby boosting the performance of multi-label learning models. However, existing methods typically require centralized data, which makes them unsuitable for distributed and federated environments where each device/client holds its own local dataset. Additionally, federated methods often assume that clients have labeled data, which is unrealistic in cases where clients lack the expertise or resources to label task-specific data. To address these challenges, we propose a Semi-Supervised Federated Multi-Label Feature Selection method, called SSFMLFS, where clients hold only unlabeled data, while the server has limited labeled data. SSFMLFS adapts fuzzy information theory to a federated setting, where clients compute fuzzy similarity matrices and transmit them to the server, which then calculates feature redundancy and feature-label relevancy degrees. A feature graph is constructed by modeling features as vertices, assigning relevancy and redundancy degrees as vertex weights and edge weights, respectively. PageRank is then applied to rank the features by importance. Extensive experiments on five real-world datasets from various domains, including biology, images, music, and text, demonstrate that SSFMLFS outperforms other federated and centralized supervised and semi-supervised approaches in terms of three different evaluation metrics in non-IID data distribution setting.

</details>


### [381] [Layer-Wise High-Impact Parameter Ratio Optimization in Post-Training Quantization for Large Language Models](https://arxiv.org/abs/2511.17801)
*Cuong Pham,Hoang Anh Dung,Cuong C. Nguyen,Trung Le,Gustavo Carneiro,Thanh-Toan Do*

Main category: cs.LG

TL;DR: 提出了一种基于二次优化的分层量化框架，通过动态确定每层的高影响参数比例，在资源受限条件下实现更高效的LLM量化。


<details>
  <summary>Details</summary>
Motivation: 现有PTQ方法在极低位宽下存在显著精度损失，且固定比例的高影响参数保留策略忽略了层间敏感性差异，无法充分利用量化潜力。

Method: 使用二次优化框架确定层特定的高影响参数比例，考虑层间依赖关系；对高影响参数采用中等位宽量化，其余参数使用极低位宽量化。

Result: 在相同资源预算下，比固定FP16保留方法能保留更多高影响参数，实现了计算效率和模型精度的有效平衡。

Conclusion: 该方法相比现有SOTA方法在保持高性能的同时，更好地平衡了计算效率和模型精度。

Abstract: Large language models (LLMs) have significantly advanced natural language processing, but their massive parameter counts create substantial computational and memory challenges during deployment. Post-training quantization (PTQ) has emerged as a promising approach to mitigate these challenges with minimal overhead. While existing PTQ methods can effectively quantize LLMs, they experience substantial accuracy loss at extremely low bit-widths, primarily due to high-impact parameters that significantly influence quantization performance. Several approaches address these issues by identifying and retaining the high-impact parameters in FP16 format. However, they apply fixed ratios of high-impact parameters across all layers, overlooking layer-wise sensitivity variations. In this paper, we propose a quadratic optimization framework that determines layer-specific ratios of high-impact parameters while considering inter-layer dependencies. We quantize high-impact parameters to moderate bit-widths, which often result in negligible performance degradation in quantized LLMs, while the remaining parameters can be quantized to extremely low bit-widths. Under the same resource-constrained budget, this allows for preserving more high-impact parameters than methods that keep selecting a few in FP16 format. Additionally, the proposed framework allows us to leverage an advanced quantization method that often requires extensive learnable parameters solely for high-impact parameters, while applying a computationally efficient method to the rest. Our approach achieves an effective balance between computational efficiency and model accuracy while maintaining high performance compared to state-of-the-art methods.

</details>


### [382] [Adaptive Layer-Wise Transformations for Post-Training Quantization of Large Language Models](https://arxiv.org/abs/2511.17809)
*Cuong Pham,Hoang Anh Dung,Cuong C. Nguyen,Trung Le,Gustavo Carneiro,Jianfei Cai,Thanh-Toan Do*

Main category: cs.LG

TL;DR: 本文提出了一种自适应变换选择框架，针对LLM量化中的系统异常值问题，通过逐层选择最优变换类型来提升量化性能。


<details>
  <summary>Details</summary>
Motivation: 现有变换方法采用同质变换设置，忽略了LLM中不同层的分布特性异质性，导致在低比特量化下性能下降严重。

Method: 提出自适应变换选择框架，将变换选择建模为可微优化问题，并基于权重分布峰度与变换类型的关联性，开发了异常值引导的层选择方法。

Result: 在LLaMA系列模型上的实验表明，该方法在W3A3K2V2等激进量化设置下，相比现有最佳方法FlatQuant，困惑度提升达4.58点，零样本任务准确率提升2.11%。

Conclusion: 异质变换选择对LLM量化至关重要，提出的自适应方法能显著提升量化性能并降低计算开销。

Abstract: Large language models require significant computational resources for deployment, making quantization essential for practical applications. However, the main obstacle to effective quantization lies in systematic outliers in activations and weights, which cause substantial LLM performance degradation, especially at low-bit settings. While existing transformation-based methods like affine and rotation transformations successfully mitigate outliers, they apply the homogeneous transformation setting, i.e., using the same transformation types across all layers, ignoring the heterogeneous distribution characteristics within LLMs. In this paper, we propose an adaptive transformation selection framework that systematically determines optimal transformations on a per-layer basis. To this end, we first formulate transformation selection as a differentiable optimization problem to achieve the accurate transformation type for each layer. However, searching for optimal layer-wise transformations for every model is computationally expensive. To this end, we establish the connection between weight distribution kurtosis and accurate transformation type. Specifically, we propose an outlier-guided layer selection method using robust $z$-score normalization that achieves comparable performance to differentiable search with significantly reduced overhead. Comprehensive experiments on LLaMA family models demonstrate that our adaptive approach consistently outperforms the widely-used fixed transformation settings. For example, our method achieves an improvement of up to 4.58 perplexity points and a 2.11% gain in average six-task zero-shot accuracy under aggressive W3A3K2V2 quantization settings for the LLaMA-3-8B model compared to the current best existing method, FlatQuant, demonstrating the necessity of heterogeneous transformation selection for optimal LLM quantization.

</details>


### [383] [APRIL: Annotations for Policy evaluation with Reliable Inference from LLMs](https://arxiv.org/abs/2511.17818)
*Aishwarya Mandyam,Kalyani Limaye,Barbara E. Engelhardt,Emily Alsentzer*

Main category: cs.LG

TL;DR: 本文提出使用大型语言模型（LLMs）生成反事实标注来增强离线策略评估（OPE）在医疗领域的应用，通过预测临床特征在替代治疗下的演变，有效解决医疗数据集覆盖不足的问题。


<details>
  <summary>Details</summary>
Motivation: 标准OPE方法受限于行为数据集的大小和覆盖范围，而获取专家标注的反事实注释成本高昂，限制了先前方法的可扩展性。医疗领域对安全性要求高，需要更有效的OPE方法。

Method: 利用领域知识指导LLMs预测关键临床特征在替代治疗下的演变，然后通过已知奖励函数将这些预测特征转换为反事实标注，并将其整合到OPE估计器中。

Result: 在MIMIC-IV的两个患者子集上评估，发现最先进的LLMs在预测临床特征方面表现相当。在大多数情况下，基于LLM的反事实标注显著改善了OPE估计，但存在一个临界点。提出了基于熵的指标来识别何时额外注释不再有用。

Conclusion: 基于LLM的反事实标注为解决医疗数据集覆盖限制提供了一种可扩展的方法，能够在临床环境中更安全地部署决策策略。

Abstract: Off-policy evaluation (OPE) estimates the value of a contextual bandit policy prior to deployment. As such, OPE plays a critical role in ensuring safety in high-stakes domains such as healthcare. However, standard OPE approaches are limited by the size and coverage of the behavior dataset. While previous work has explored using expert-labeled counterfactual annotations to enhance dataset coverage, obtaining such annotations is expensive, limiting the scalability of prior approaches. We propose leveraging large language models (LLMs) to generate counterfactual annotations for OPE in medical domains. Our method uses domain knowledge to guide LLMs in predicting how key clinical features evolve under alternate treatments. These predicted features can then be transformed using known reward functions to create counterfactual annotations. We first evaluate the ability of several LLMs to predict clinical features across two patient subsets in MIMIC-IV, finding that state-of-the-art LLMs achieve comparable performance. Building on this capacity to predict clinical features, we generate LLM-based counterfactual annotations and incorporate them into an OPE estimator. Our empirical results analyze the benefits of counterfactual annotations under varying degrees of shift between the behavior and target policies. We find that in most cases, the LLM-based counterfactual annotations significantly improve OPE estimates up to a point. We provide an entropy-based metric to identify when additional annotations cease to be useful. Our results demonstrate that LLM-based counterfactual annotations offer a scalable approach for addressing coverage limitations in healthcare datasets, enabling safer deployment of decision-making policies in clinical settings.

</details>


### [384] [High-Accuracy List-Decodable Mean Estimation](https://arxiv.org/abs/2511.17822)
*Ziyun Chen,Spencer Compton,Daniel Kane,Jerry Li*

Main category: cs.LG

TL;DR: 本文研究了列表可解码学习中的高精度问题，提出了一种在列表大小和精度之间进行权衡的方法，特别针对高斯分布均值估计问题，实现了非平凡的高精度保证。


<details>
  <summary>Details</summary>
Motivation: 现有列表可解码学习算法虽然能获得最优列表大小，但误差随1/α衰减较差。本文旨在探索是否可以通过增加列表大小来换取更高的精度，即实现高精度列表可解码学习。

Method: 提出了一种全新的可识别性证明方法，并设计了一种不依赖平方和层次结构的算法。该方法通过构建大小为L = exp(O(log²(1/α)/ε²))的候选均值列表，确保其中一个元素与真实均值的ℓ₂距离不超过ε。

Result: 证明了在身份协方差高斯分布的列表可解码均值估计中，存在一个大小为L的候选均值列表，其中至少一个元素与真实均值的误差不超过ε。算法的时间和样本复杂度为n = d^O(log L) + exp exp(Õ(log L))。

Conclusion: 本文首次在列表可解码学习中实现了非平凡的高精度保证，为列表大小与精度之间的权衡提供了理论和技术基础，所提出的新证明方法可能具有独立的技术价值。

Abstract: In list-decodable learning, we are given a set of data points such that an $α$-fraction of these points come from a nice distribution $D$, for some small $α\ll 1$, and the goal is to output a short list of candidate solutions, such that at least one element of this list recovers some non-trivial information about $D$. By now, there is a large body of work on this topic; however, while many algorithms can achieve optimal list size in terms of $α$, all known algorithms must incur error which decays, in some cases quite poorly, with $1 / α$. In this paper, we ask if this is inherent: is it possible to trade off list size with accuracy in list-decodable learning? More formally, given $ε> 0$, can we can output a slightly larger list in terms of $α$ and $ε$, but so that one element of this list has error at most $ε$ with the ground truth? We call this problem high-accuracy list-decodable learning. Our main result is that non-trivial high-accuracy guarantees, both information-theoretically and algorithmically, are possible for the canonical setting of list-decodable mean estimation of identity-covariance Gaussians. Specifically, we demonstrate that there exists a list of candidate means of size at most $L = \exp \left( O\left( \tfrac{\log^2 1 / α}{ε^2} \right)\right)$ so that one of the elements of this list has $\ell_2$ distance at most $ε$ to the true mean. We also design an algorithm that outputs such a list with runtime and sample complexity $n = d^{O(\log L)} + \exp \exp (\widetilde{O}(\log L))$. We do so by demonstrating a completely novel proof of identifiability, as well as a new algorithmic way of leveraging this proof without the sum-of-squares hierarchy, which may be of independent technical interest.

</details>


### [385] [A novel k-means clustering approach using two distance measures for Gaussian data](https://arxiv.org/abs/2511.17823)
*Naitik Gada*

Main category: cs.LG

TL;DR: 提出了一种结合类内距离(WCD)和类间距离(ICD)的k-means聚类算法，使用Calinski-Harabasz准则确定最优k值，相比传统方法具有更好的聚类鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统k-means聚类算法仅考虑类内距离，在聚类收敛性和鲁棒性方面存在不足。本文旨在通过同时考虑类内和类间距离来提高聚类质量。

Method: 开发了新的k-means算法，使用WCD和ICD作为距离度量，通过Calinski-Harabasz准则自动确定最优聚类数k，并在合成数据和UCI基准数据集上进行测试。

Result: 实验结果表明，新算法在聚类收敛性方面更准确，对异常值的处理能力更强，聚类效果优于传统k-means方法。

Conclusion: 结合WCD和ICD的k-means算法能够提供更鲁棒的聚类结果，为无监督学习提供了改进方案，并指出了未来可能的研究方向。

Abstract: Clustering algorithms have long been the topic of research, representing the more popular side of unsupervised learning. Since clustering analysis is one of the best ways to find some clarity and structure within raw data, this paper explores a novel approach to \textit{k}-means clustering. Here we present a \textit{k}-means clustering algorithm that takes both the within cluster distance (WCD) and the inter cluster distance (ICD) as the distance metric to cluster the data into \emph{k} clusters pre-determined by the Calinski-Harabasz criterion in order to provide a more robust output for the clustering analysis. The idea with this approach is that by including both the measurement metrics, the convergence of the data into their clusters becomes solidified and more robust. We run the algorithm with some synthetically produced data and also some benchmark data sets obtained from the UCI repository. The results show that the convergence of the data into their respective clusters is more accurate by using both WCD and ICD measurement metrics. The algorithm is also better at clustering the outliers into their true clusters as opposed to the traditional \textit{k} means method. We also address some interesting possible research topics that reveal themselves as we answer the questions we initially set out to address.

</details>


### [386] [Deterministic Inference across Tensor Parallel Sizes That Eliminates Training-Inference Mismatch](https://arxiv.org/abs/2511.17826)
*Ziyang Zhang,Xinheng Ding,Jiayi Yuan,Rixin Liu,Huizi Mao,Jiarong Xing,Zirui Liu*

Main category: cs.LG

TL;DR: 本文提出了Tree-Based Invariant Kernels (TBIK)来解决大语言模型推理中的张量并行规模导致的非确定性问题，确保在不同TP配置下获得比特级一致的结果。


<details>
  <summary>Details</summary>
Motivation: 现有LLM服务框架存在非确定性问题：相同输入在不同系统配置（如TP大小、批次大小）下会产生不同输出，这在强化学习等场景中会导致训练性能下降甚至崩溃。

Method: 通过分析TP引起的不一致性的根本原因，提出了基于统一层次二叉树结构的TP不变矩阵乘法和归约原语，确保无论TP大小如何都能获得比特级相同结果。

Result: 实验证实了在不同TP大小下实现零概率差异和比特级可重现性，在vLLM和FSDP之间实现了比特级一致的结果。

Conclusion: TBIK有效解决了LLM推理中的TP规模非确定性问题，为强化学习等应用提供了可靠的确定性推理保障。

Abstract: Deterministic inference is increasingly critical for large language model (LLM) applications such as LLM-as-a-judge evaluation, multi-agent systems, and Reinforcement Learning (RL). However, existing LLM serving frameworks exhibit non-deterministic behavior: identical inputs can yield different outputs when system configurations (e.g., tensor parallel (TP) size, batch size) vary, even under greedy decoding. This arises from the non-associativity of floating-point arithmetic and inconsistent reduction orders across GPUs. While prior work has addressed batch-size-related nondeterminism through batch-invariant kernels, determinism across different TP sizes remains an open problem, particularly in RL settings, where the training engine typically uses Fully Sharded Data Parallel (i.e., TP = 1) while the rollout engine relies on multi-GPU TP to maximize the inference throughput, creating a natural mismatch between the two. This precision mismatch problem may lead to suboptimal performance or even collapse for RL training. We identify and analyze the root causes of TP-induced inconsistency and propose Tree-Based Invariant Kernels (TBIK), a set of TP-invariant matrix multiplication and reduction primitives that guarantee bit-wise identical results regardless of TP size. Our key insight is to align intra- and inter-GPU reduction orders through a unified hierarchical binary tree structure. We implement these kernels in Triton and integrate them into vLLM and FSDP. Experiments confirm zero probability divergence and bit-wise reproducibility for deterministic inference across different TP sizes. Also, we achieve bit-wise identical results between vLLM and FSDP in RL training pipelines with different parallel strategy. Code is available at https://github.com/nanomaoli/llm_reproducibility.

</details>


### [387] [Unified Class and Domain Incremental Learning with Mixture of Experts for Indoor Localization](https://arxiv.org/abs/2511.17829)
*Akhil Singampalli,Sudeep Pasricha*

Main category: cs.LG

TL;DR: MOELO是一个新颖的统一持续学习框架，首次同时解决域增量学习和类增量学习场景，用于室内定位系统。


<details>
  <summary>Details</summary>
Motivation: 解决室内定位系统中由于移动设备硬件/软件差异导致的域偏移问题，以及环境变化引入新位置导致的类偏移问题，使静态机器学习模型能够长期有效。

Method: 采用混合专家架构，按区域增量训练专家，通过等角紧框架门控机制进行高效路由选择，实现低延迟推理和紧凑模型尺寸。

Result: 实验评估显示，MOELO在不同建筑、移动设备和学习场景下，平均定位误差提升25.6倍，最差定位误差提升44.5倍，遗忘率降低21.5倍。

Conclusion: MOELO提供了一个轻量级、鲁棒且自适应的定位解决方案，能够在资源受限的移动设备上部署，并在动态异构的真实环境中实现持续学习。

Abstract: Indoor localization using machine learning has gained traction due to the growing demand for location-based services. However, its long-term reliability is hindered by hardware/software variations across mobile devices, which shift the model's input distribution to create domain shifts. Further, evolving indoor environments can introduce new locations over time, expanding the output space to create class shifts, making static machine learning models ineffective over time. To address these challenges, we propose a novel unified continual learning framework for indoor localization called MOELO that, for the first time, jointly addresses domain-incremental and class-incremental learning scenarios. MOELO enables a lightweight, robust, and adaptive localization solution that can be deployed on resource-limited mobile devices and is capable of continual learning in dynamic, heterogeneous real-world settings. This is made possible by a mixture-of-experts architecture, where experts are incrementally trained per region and selected through an equiangular tight frame based gating mechanism ensuring efficient routing, and low-latency inference, all within a compact model footprint. Experimental evaluations show that MOELO achieves improvements of up to 25.6x in mean localization error, 44.5x in worst-case localization error, and 21.5x lesser forgetting compared to state-of-the-art frameworks across diverse buildings, mobile devices, and learning scenarios.

</details>


### [388] [Internalizing Tools as Morphisms in Graded Transformers](https://arxiv.org/abs/2511.17840)
*Tony Shaska*

Main category: cs.LG

TL;DR: 提出了基于分级的transformer内部符号计算框架，通过可微路由策略实现选择性激活的符号操作，统一了符号计算、几何和自监督学习。


<details>
  <summary>Details</summary>
Motivation: 解决transformer在符号计算任务中缺乏可解释性和稀疏性的问题，将外部工具调用范式内化为统一的内部符号计算框架。

Method: 在隐藏空间引入分级结构，定义类型化块映射作为符号操作，通过可微路由策略和分级效用函数实现选择性激活。

Result: 建立了代数几何理论基础，开发了端到端可微分路由机制，在混合符号-语言任务上验证了选择性激活的有效性。

Conclusion: 该框架统一了符号计算、几何和自监督学习，将外部工具范式作为特例包含在内，为transformer提供了可解释的内部符号计算能力。

Abstract: We introduce a graded formulation of internal symbolic computation for transformers. The hidden space is endowed with a grading $V=\bigoplus_{g\in G}V_g$, and symbolic operations are realized as typed block maps (morphisms) $φ_{h\leftarrow g}:V_g\to V_h$ that are activated selectively by a differentiable routing policy. A self-supervised \emph{graded utility functional}, defined as the loss reduction induced by a candidate morphism, governs activation and yields sparse, interpretable behavior. We develop the algebraic and geometric foundations: an internal model category whose objects are homogeneous components and whose morphisms are admissible grade transitions; adjoint pairs encoding typed round trips; and information-geometric interpretations in terms of KL gain, mirror descent with Bregman divergences, and Fisher natural gradients. Methodologically, we specify a utility--aware routing mechanism and objective that remain fully end-to-end differentiable. Analytic case studies and lightweight sanity checks illustrate selective morphic activation on hybrid symbolic-linguistic tasks. The framework unifies symbolic computation, geometry, and self--supervised learning within the \emph{graded transformer} formalism \cite{sh-89,sh-95}, while subsuming prior external-tool paradigms (e.g., Toolformer \cite{toolformer2023}) as a special case via functorial internalization.

</details>


### [389] [Scaling Kinetic Monte-Carlo Simulations of Grain Growth with Combined Convolutional and Graph Neural Networks](https://arxiv.org/abs/2511.17848)
*Zhihui Tian,Ethan Suwandi,Tomas Oppelstrup,Vasily V. Bulatov,Joel B. Harley,Fei Zhou*

Main category: cs.LG

TL;DR: 本文提出了一种混合架构，结合CNN双向自编码器和GNN，显著降低了晶粒生长模拟的计算成本和内存占用，同时提高了准确性和时空建模能力。


<details>
  <summary>Details</summary>
Motivation: 传统GNN在模拟大规模晶粒边界网络时存在计算成本和内存占用过高的问题，难以扩展到大型模拟单元。

Method: 采用CNN双向自编码器压缩空间维度，在降维后的潜在空间中使用GNN演化微观结构，减少了消息传递层数（从12层降至3层）。

Result: 在最大网格（160^3）上，内存使用和推理运行时间分别降低了117倍和115倍，且比纯GNN基线具有更高的准确性和更强的时空能力。

Conclusion: 该方法结合了可扩展性和准确性，为模拟真实材料微观结构提供了高效解决方案，双向自编码器的无损压缩能力为GNN提供了更具表达力的潜在特征。

Abstract: Graph neural networks (GNN) have emerged as a promising machine learning method for microstructure simulations such as grain growth. However, accurate modeling of realistic grain boundary networks requires large simulation cells, which GNN has difficulty scaling up to. To alleviate the computational costs and memory footprint of GNN, we propose a hybrid architecture combining a convolutional neural network (CNN) based bijective autoencoder to compress the spatial dimensions, and a GNN that evolves the microstructure in the latent space of reduced spatial sizes. Our results demonstrate that the new design significantly reduces computational costs with using fewer message passing layer (from 12 down to 3) compared with GNN alone. The reduction in computational cost becomes more pronounced as the spatial size increases, indicating strong computational scalability. For the largest mesh evaluated (160^3), our method reduces memory usage and runtime in inference by 117x and 115x, respectively, compared with GNN-only baseline. More importantly, it shows higher accuracy and stronger spatiotemporal capability than the GNN-only baseline, especially in long-term testing. Such combination of scalability and accuracy is essential for simulating realistic material microstructures over extended time scales. The improvements can be attributed to the bijective autoencoder's ability to compress information losslessly from spatial domain into a high dimensional feature space, thereby producing more expressive latent features for the GNN to learn from, while also contributing its own spatiotemporal modeling capability. The training was optimized to learn from the stochastic Potts Monte Carlo method. Our findings provide a highly scalable approach for simulating grain growth.

</details>


### [390] [Transformers with RL or SFT Provably Learn Sparse Boolean Functions, But Differently](https://arxiv.org/abs/2511.17852)
*Bochen Lyu,Yiyang Jia,Xiaohao Cai,Zhanxing Zhu*

Main category: cs.LG

TL;DR: 该论文比较了强化学习(RL)和监督微调(SFT)在训练Transformer学习k-稀疏布尔函数时的机制差异，揭示了两种方法在触发思维链能力上的不同学习行为。


<details>
  <summary>Details</summary>
Motivation: 尽管RL和SFT都能让Transformer获得思维链推理能力，但它们的底层机制和差异缺乏理论上的清晰解释，特别是在学习复杂布尔函数时的动态过程。

Method: 使用单层Transformer模型，通过RL和SFT两种方法学习可递归分解为固定2-稀疏布尔函数的k-稀疏布尔函数，分析学习动态并建立可学习性的充分条件。

Result: 验证了两种方法都能学习k-PARITY、k-AND和k-OR等基本函数，但RL同时学习整个思维链，而SFT则逐步学习思维链的每一步。

Conclusion: 研究揭示了RL和SFT在触发Transformer思维链能力时的不同机制，为理解这两种微调方法的理论基础提供了重要见解。

Abstract: Transformers can acquire Chain-of-Thought (CoT) capabilities to solve complex reasoning tasks through fine-tuning. Reinforcement learning (RL) and supervised fine-tuning (SFT) are two primary approaches to this end, yet their underlying mechanisms and differences remain theoretically unclear. In this work, we examine these aspects specifically for learning $k$-sparse Boolean functions with a one-layer transformer and intermediate supervision that is akin to CoT. In particular, we consider $k$-sparse Boolean functions that can be recursively decomposed into fixed 2-sparse Boolean functions. We analyze the learning dynamics of fine-tuning the transformer via either RL or SFT with CoT to identify sufficient conditions for it to provably learn these functions. We verify that these conditions hold for three basic examples, including $k$-PARITY, $k$-AND, and $k$-OR, thus demonstrating the learnability of both approaches. Notably, we reveal that RL and SFT exhibit distinct learning behaviors: RL learns the whole CoT chain simultaneously, whereas SFT learns the CoT chain step-by-step. Overall, our findings provide theoretical insights into the underlying mechanisms of RL and SFT as well as how they differ in triggering the CoT capabilities of transformers.

</details>


### [391] [Cost-Sensitive Conformal Training with Provably Controllable Learning Bounds](https://arxiv.org/abs/2511.17861)
*Xuesong Jia,Yuanjie Shi,Ziquan Liu,Yi Xu,Yan Yan*

Main category: cs.LG

TL;DR: 本文提出了一种简单的成本敏感一致性训练算法，通过理论证明最小化预测集大小上界与真实标签的期望排名相关，并开发了基于真实标签排名的权重分配策略。


<details>
  <summary>Details</summary>
Motivation: 传统一致性训练方法使用Sigmoid或高斯误差函数等替代指标函数，但这些函数对指标函数没有统一的误差界限，导致学习界限不可控。

Method: 提出一种不依赖指标近似机制的成本敏感一致性训练算法，通过理论分析证明最小化预测集期望大小的上界与真实标签的期望排名相关，并设计了基于真实标签排名的权重分配策略。

Result: 大量实验验证了理论见解的有效性，在预测效率方面优于其他一致性训练方法，平均预测集大小减少了21.38%。

Conclusion: 该方法提供了一种更有效的一致性训练框架，通过避免指标函数近似问题实现了更好的预测不确定性量化效果。

Abstract: Conformal prediction (CP) is a general framework to quantify the predictive uncertainty of machine learning models that uses a set prediction to include the true label with a valid probability. To align the uncertainty measured by CP, conformal training methods minimize the size of the prediction sets. A typical way is to use a surrogate indicator function, usually Sigmoid or Gaussian error function. However, these surrogate functions do not have a uniform error bound to the indicator function, leading to uncontrollable learning bounds. In this paper, we propose a simple cost-sensitive conformal training algorithm that does not rely on the indicator approximation mechanism. Specifically, we theoretically show that minimizing the expected size of prediction sets is upper bounded by the expected rank of true labels. To this end, we develop a rank weighting strategy that assigns the weight using the rank of true label on each data sample. Our analysis provably demonstrates the tightness between the proposed weighted objective and the expected size of conformal prediction sets. Extensive experiments verify the validity of our theoretical insights, and superior empirical performance over other conformal training in terms of predictive efficiency with 21.38% reduction for average prediction set size.

</details>


### [392] [Equivalence of Context and Parameter Updates in Modern Transformer Blocks](https://arxiv.org/abs/2511.17864)
*Adrian Goldwaser,Michael Munn,Javier Gonzalvo,Benoit Dherin*

Main category: cs.LG

TL;DR: 本文扩展了上下文在Transformer中可通过MLP权重的秩1补丁表示的理论，证明了在现代LLM架构中上下文效果可完美映射到MLP权重和RMSNorm的秩1补丁，并提出了输入/输出可控性框架来统一理解这一现象。


<details>
  <summary>Details</summary>
Motivation: 将已有的上下文隐式表示理论扩展到现代多样化的大型语言模型架构，为理解Transformer如何将提示转换为有效权重提供更通用和强大的理论框架。

Method: 首先对Gemma风格Transformer块给出精确解析解，证明上下文效果可完美映射到MLP权重矩阵的秩1补丁和RMSNorm尺度补丁；然后推广到多层模型并提供构造性证明和算法；最后引入输入可控性和输出可控性框架来统一这些发现。

Result: 证明了对于任何内函数输入可控、外函数输出可控的MLP块，完美的隐式权重补丁是可能的，该框架适用于包括门控、前后归一化、专家混合和顺序/并行Transformer块在内的多种现代LLM架构。

Conclusion: 提出的输入/输出可控性框架为理解Transformer模型如何将提示转换为有效权重提供了更简单强大的理论视角，统一了多种现代LLM架构中的上下文隐式表示机制。

Abstract: Recent research has established that the impact of context in a vanilla transformer can be represented implicitly by forming a token-dependent, rank-1 patch to its MLP weights. This work extends that foundational theory to the diverse architectures of modern Large Language Models. We first demonstrate a precise, analytical solution for a Gemma-style transformer block, proving that the entire effect of a context can be perfectly mapped to rank-1 patches on its MLP weight matrices and a patch to the RMSNorm scale. We then generalize this result, providing a constructive proof and algorithm for multi-layer models. To unify these findings, we introduce a general framework centered on two core properties: input controllability and output controllability. We prove that a perfect implicit weight patch is possible for any MLP block where the inner function is input-controllable and the outer function is output-controllable. This provides a simpler and more powerful lens for understanding how transformer models transmute prompts into effective weights. This setup generalizes to a wide range of modern LLM architectures including gating, pre-/post-norm, mixture of experts and sequential/parallel transformer blocks.

</details>


### [393] [The Horcrux: Mechanistically Interpretable Task Decomposition for Detecting and Mitigating Reward Hacking in Embodied AI Systems](https://arxiv.org/abs/2511.17869)
*Subramanyam Sahoo,Jared Junkin*

Main category: cs.LG

TL;DR: 提出了MITD框架，通过任务分解和可解释性可视化来检测和缓解强化学习中的奖励黑客问题，在1000个样本上验证可将奖励黑客频率降低34%。


<details>
  <summary>Details</summary>
Motivation: 现有AI代理容易通过奖励黑客行为获得高代理分数但实际任务失败，需要更有效的检测和缓解机制。

Method: 提出Mechanistically Interpretable Task Decomposition (MITD)分层Transformer架构，包含Planner、Coordinator和Executor模块，通过任务分解生成Attention Waterfall Diagrams和Neural Pathway Flow Charts等可视化诊断工具。

Result: 在1000个HH-RLHF样本上实验表明，12-25步的分解深度可将奖励黑客频率降低34%，覆盖四种失败模式。

Conclusion: 基于机制的任务分解比事后行为监控更有效地检测奖励黑客，为可解释AI提供了新范式。

Abstract: Embodied AI agents exploit reward signal flaws through reward hacking, achieving high proxy scores while failing true objectives. We introduce Mechanistically Interpretable Task Decomposition (MITD), a hierarchical transformer architecture with Planner, Coordinator, and Executor modules that detects and mitigates reward hacking. MITD decomposes tasks into interpretable subtasks while generating diagnostic visualizations including Attention Waterfall Diagrams and Neural Pathway Flow Charts. Experiments on 1,000 HH-RLHF samples reveal that decomposition depths of 12 to 25 steps reduce reward hacking frequency by 34 percent across four failure modes. We present new paradigms showing that mechanistically grounded decomposition offers a more effective way to detect reward hacking than post-hoc behavioral monitoring.

</details>


### [394] [Generative Adversarial Post-Training Mitigates Reward Hacking in Live Human-AI Music Interaction](https://arxiv.org/abs/2511.17879)
*Yusong Wu,Stephen Brade,Teng Ma,Tia-Jane Fowler,Enning Yang,Berker Banar,Aaron Courville,Natasha Jaques,Cheng-Zhi Anna Huang*

Main category: cs.LG

TL;DR: 提出一种对抗训练方法来解决RL后训练中的奖励破解问题，提高旋律到和弦伴奏的多样性和协调性


<details>
  <summary>Details</summary>
Motivation: 实时即兴演奏需要实时协调和适应，但RL后训练常因奖励破解导致输出多样性降低，影响音乐创造力

Method: 在策略生成轨迹上进行对抗训练，使用共进化判别器区分策略轨迹和数据分布，策略同时最大化判别器输出和协调奖励

Result: 在模拟和用户研究中显示输出多样性、和声协调性、适应速度和用户控制力均有提升

Conclusion: 该方法简单有效地缓解了生成序列模型RL后训练中的奖励破解问题

Abstract: Most applications of generative AI involve a sequential interaction in which a person inputs a prompt and waits for a response, and where reaction time and adaptivity are not important factors. In contrast, live jamming is a collaborative interaction that requires real-time coordination and adaptation without access to the other player's future moves, while preserving diversity to sustain a creative flow. Reinforcement learning post-training enables effective adaptation through on-policy interaction, yet it often reduces output diversity by exploiting coherence-based rewards. This collapse, known as ``reward hacking'', affects many RL post-training pipelines, but is especially harmful in live jamming, where musical creativity relies on dynamic variation and mutual responsiveness. In this paper, we propose a novel adversarial training method on policy-generated trajectories to mitigate reward hacking in RL post-training for melody-to-chord accompaniment. A co-evolving discriminator separates policy trajectories from the data distribution, while the policy maximizes the discriminator output in addition to coherence rewards to prevent collapse to trivial outputs. We evaluate accompaniment quality and output diversity in simulation with both fixed test melodies and learned melody agents, and we conduct a user study with the model deployed in a real-time interactive system with expert musicians. Quantitative evaluation and user feedback demonstrate improved output diversity, harmonic coherence, adaptation speed and user agency. Our results demonstrate a simple yet effective method to mitigate reward hacking in RL post-training of generative sequence models.

</details>


### [395] [Statistically-Guided Dual-Domain Meta-Learning with Adaptive Multi-Prototype Aggregation for Distributed Fiber Optic Sensing](https://arxiv.org/abs/2511.17902)
*Yifan He,Haodong Zhang,Qiuheng Song,Lin Lei,Zhenxuan Zeng,Haoyang He,Hongyan Wu*

Main category: cs.LG

TL;DR: 本文提出了一种名为DUPLE的元学习框架，用于解决分布式光纤传感（DFOS）在周界安全应用中面临的跨部署场景活动识别问题。该方法通过双域多原型学习器、统计引导网络和查询感知原型聚合模块，有效应对信号模式变化、标注数据稀缺和类内多样性不足等挑战。


<details>
  <summary>Details</summary>
Motivation: 分布式光纤传感在周界安全监测中具有重要应用价值，但实际部署面临三大挑战：不同光纤部署类型导致信号模式差异（域偏移）、新场景标注数据稀缺、以及源域内数据不足难以捕捉类内多样性。

Method: DUPLE框架包含三个核心组件：1）双域多原型学习器融合时域和频域特征；2）统计引导网络从原始统计特征推断域重要性和原型敏感性；3）查询感知原型聚合模块自适应选择组合相关原型。

Result: 在跨部署DFOS数据集上的实验表明，该方法在域泛化设置下显著优于基线方法，能够在标注数据极少的情况下实现跨不同光纤配置的鲁棒事件识别。

Conclusion: DUPLE框架通过元学习方法有效解决了DFOS系统中的域适应和数据稀缺问题，为实际周界安全应用提供了可行的技术方案。

Abstract: Distributed Fiber Optic Sensing (DFOS) has shown strong potential in perimeter security due to its capability of monitoring vibration events across long distances with fine spatial resolution. However, practical DFOS systems face three critical challenges: (1) signal patterns of the same activity vary drastically under different fiber deployment types (e.g., underground, wall-mounted), causing domain shift; (2) labeled data in new deployment scenarios is often scarce or entirely unavailable, limiting model adaptability; and (3) even within source domains, data scarcity makes it difficult to capture intra-class diversity for robust learning.
  To address these challenges, we propose a novel meta-learning framework, DUPLE, for cross-deployment DFOS activity identification. First, a dual-domain multi-prototype learner fuses temporal and frequency domain features, enhancing the model's generalization ability under signal distribution shifts. Second, a Statistical Guided Network (SGN) infers domain importance and prototype sensitivity from raw statistical features, providing data-driven prior information for learning in unlabeled or unseen domains. Third, a query-aware prototype aggregation module adaptively selects and combines relevant prototypes, thereby improving classification performance even with limited data.
  Extensive experiments on cross-deployment DFOS datasets demonstrate that our method significantly outperforms baseline approaches in domain generalization settings, enabling robust event recognition across diverse fiber configurations with minimal labeled data.

</details>


### [396] [Mitigating Catastrophic Forgetting in Streaming Generative and Predictive Learning via Stateful Replay](https://arxiv.org/abs/2511.17936)
*Wenzhang Du*

Main category: cs.LG

TL;DR: 本文研究了在内存受限的流式数据环境下，通过状态回放（stateful replay）方法减少灾难性遗忘的问题，比较了顺序微调和回放策略在生成性和预测性任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 部署的学习系统需要在内存约束下更新流式数据模型，顺序微调策略虽然架构无关但容易发生灾难性遗忘，特别是当后续阶段对应不同子群体或任务时。回放策略作为简单替代方案，但其在生成和预测目标上的行为尚未得到充分理解。

Method: 提出了对流式自动编码、时间序列预测和分类的统一研究框架，将顺序微调和回放视为理想联合目标的随机梯度方法，使用梯度对齐分析来评估混合当前和历史样本何时能减少遗忘。在六个流式场景（Rotated MNIST、ElectricityLoadDiagrams 2011-2014、Airlines delay数据）上评估单一回放机制，使用匹配的训练预算和三个随机种子。

Result: 在异构多任务流上，回放将平均遗忘减少2-3倍；在良性时间流上，两种方法表现相似。

Conclusion: 状态回放作为流式环境中持续学习的强大而简单的基线方法，具有显著优势。

Abstract: Many deployed learning systems must update models on streaming data under memory constraints. The default strategy, sequential fine-tuning on each new phase, is architecture-agnostic but often suffers catastrophic forgetting when later phases correspond to different sub-populations or tasks. Replay with a finite buffer is a simple alternative, yet its behaviour across generative and predictive objectives is not well understood. We present a unified study of stateful replay for streaming autoencoding, time series forecasting, and classification. We view both sequential fine-tuning and replay as stochastic gradient methods for an ideal joint objective, and use a gradient alignment analysis to show when mixing current and historical samples should reduce forgetting. We then evaluate a single replay mechanism on six streaming scenarios built from Rotated MNIST, ElectricityLoadDiagrams 2011-2014, and Airlines delay data, using matched training budgets and three seeds. On heterogeneous multi task streams, replay reduces average forgetting by a factor of two to three, while on benign time based streams both methods perform similarly. These results position stateful replay as a strong and simple baseline for continual learning in streaming environments.

</details>


### [397] [scipy.spatial.transform: Differentiable Framework-Agnostic 3D Transformations in Python](https://arxiv.org/abs/2511.18157)
*Martin Schuck,Alexander von Rohr,Angela P. Schoellig*

Main category: cs.LG

TL;DR: 本文对SciPy的spatial.transform模块进行了全面重构，使其兼容支持Python数组API的任何数组库（如JAX、PyTorch、CuPy），实现了GPU/TPU执行、JIT编译、向量化批处理和自动微分功能。


<details>
  <summary>Details</summary>
Motivation: 三维刚体变换在机器人、视觉和仿真的可微分机器学习流程中至关重要，但现有实现容易出错。SciPy的spatial.transform模块虽然经过严格测试，但仅支持NumPy，限制了在GPU加速和自动微分工作流中的应用。

Method: 重新设计SciPy的spatial.transform功能，保持原有接口的同时，使其兼容任何实现Python数组API的数组库。通过两个案例研究验证：3D变换和旋转的可扩展性，以及基于JAX的无人机仿真。

Result: 重构后的实现支持GPU/TPU执行、JIT编译、向量化批处理和原生自动微分。贡献已合并到SciPy主分支，将在下一个版本中发布。

Conclusion: 提供了一个框架无关、生产级的3D空间数学基础，为可微分系统和机器学习应用提供了可靠的实现。

Abstract: Three-dimensional rigid-body transforms, i.e. rotations and translations, are central to modern differentiable machine learning pipelines in robotics, vision, and simulation. However, numerically robust and mathematically correct implementations, particularly on SO(3), are error-prone due to issues such as axis conventions, normalizations, composition consistency and subtle errors that only appear in edge cases. SciPy's spatial.transform module is a rigorously tested Python implementation. However, it historically only supported NumPy, limiting adoption in GPU-accelerated and autodiff-based workflows. We present a complete overhaul of SciPy's spatial.transform functionality that makes it compatible with any array library implementing the Python array API, including JAX, PyTorch, and CuPy. The revised implementation preserves the established SciPy interface while enabling GPU/TPU execution, JIT compilation, vectorized batching, and differentiation via native autodiff of the chosen backend. We demonstrate how this foundation supports differentiable scientific computing through two case studies: (i) scalability of 3D transforms and rotations and (ii) a JAX drone simulation that leverages SciPy's Rotation for accurate integration of rotational dynamics. Our contributions have been merged into SciPy main and will ship in the next release, providing a framework-agnostic, production-grade basis for 3D spatial math in differentiable systems and ML.

</details>


### [398] [On Transportability for Structural Causal Bandits](https://arxiv.org/abs/2511.17953)
*Min Woo Park,Sanghack Lee*

Main category: cs.LG

TL;DR: 该论文提出了结构因果赌博机与可迁移性框架，通过利用源环境中的先验知识来增强部署环境中的学习效果，利用环境间的不变性来提升学习效率。


<details>
  <summary>Details</summary>
Motivation: 现有的结构因果赌博机框架虽然能够利用因果结构知识来优化动作空间，但缺乏从不同条件（观测或实验）和异构环境中收集的任意数据集组合中迁移信息的指导方法。

Method: 研究结构因果赌博机与可迁移性，将源环境中的先验知识融合到部署环境中，利用环境间的不变性来持续改进学习。

Result: 提出的赌博机算法实现了次线性遗憾界，明确依赖于先验数据的信息量，并且在某些情况下可能优于仅依赖在线学习的标准赌博机方法。

Conclusion: 通过利用环境间的不变性和融合多源先验知识，可以有效提升结构因果赌博机的学习性能，实现更好的遗憾界限。

Abstract: Intelligent agents equipped with causal knowledge can optimize their action spaces to avoid unnecessary exploration. The structural causal bandit framework provides a graphical characterization for identifying actions that are unable to maximize rewards by leveraging prior knowledge of the underlying causal structure. While such knowledge enables an agent to estimate the expected rewards of certain actions based on others in online interactions, there has been little guidance on how to transfer information inferred from arbitrary combinations of datasets collected under different conditions -- observational or experimental -- and from heterogeneous environments. In this paper, we investigate the structural causal bandit with transportability, where priors from the source environments are fused to enhance learning in the deployment setting. We demonstrate that it is possible to exploit invariances across environments to consistently improve learning. The resulting bandit algorithm achieves a sub-linear regret bound with an explicit dependence on informativeness of prior data, and it may outperform standard bandit approaches that rely solely on online learning.

</details>


### [399] [Categorical Equivariant Deep Learning: Category-Equivariant Neural Networks and Universal Approximation Theorems](https://arxiv.org/abs/2511.18417)
*Yoshihiro Maruyama*

Main category: cs.LG

TL;DR: 该论文提出了范畴等变神经网络（CENNs）的统一理论框架，将群/群胚等变网络、偏序集/格等变网络、图和层神经网络等统一起来，证明了等变通用逼近定理，并展示了该框架在多种数学结构中的具体应用。


<details>
  <summary>Details</summary>
Motivation: 当前等变深度学习主要局限于群作用，但实际应用中存在更广泛的对称性（如上下文对称性、组合对称性）。需要建立一个统一的理论框架来扩展等变深度学习的适用范围。

Method: 在具有Radon测度的拓扑范畴中形式化等变性，将线性和非线性层纳入范畴设置。提出范畴等变神经网络（CENNs）框架，并证明有限深度CENNs在连续等变变换空间中的稠密性。

Result: 证明了等变通用逼近定理在一般设置下成立，并具体实例化了群/群胚、偏序集/格、图和胞腔层等结构的应用，系统推导了它们的通用逼近定理。

Conclusion: 范畴等变深度学习能够超越群作用，不仅包含几何对称性，还涵盖上下文和组合对称性，为等变深度学习开辟了新的视野。

Abstract: We develop a theory of category-equivariant neural networks (CENNs) that unifies group/groupoid-equivariant networks, poset/lattice-equivariant networks, graph and sheaf neural networks. Equivariance is formulated as naturality in a topological category with Radon measures, formulating linear and nonlinear layers in the categorical setup. We prove the equivariant universal approximation theorem in the general setting: the class of finite-depth CENNs is dense in the space of continuous equivariant transformations. We instantiate the framework for groups/groupoids, posets/lattices, graphs and cellular sheaves, deriving universal approximation theorems for them in a systematic manner. Categorical equivariant deep learning thus allows us to expand the horizons of equivariant deep learning beyond group actions, encompassing not only geometric symmetries but also contextual and compositional symmetries.

</details>


### [400] [Hybrid LSTM and PPO Networks for Dynamic Portfolio Optimization](https://arxiv.org/abs/2511.17963)
*Jun Kevin,Pujianto Yugopuspito*

Main category: cs.LG

TL;DR: 该论文提出了一种融合LSTM预测和PPO强化学习的混合投资组合优化框架，在多种资产上表现出优于基准模型的性能


<details>
  <summary>Details</summary>
Motivation: 传统投资组合优化方法难以适应非平稳市场环境，需要结合深度学习和强化学习来捕捉时序依赖并动态调整资产配置

Method: 使用LSTM网络进行时序预测，结合PPO算法在连续动作空间中优化投资组合权重分配，形成混合架构

Result: 在2018-2024年多资产数据集上的测试显示，混合模型在年化收益率、夏普比率等指标上均优于等权重、指数型以及单一模型方法

Conclusion: 该混合框架在非平稳市场环境下展现出更强的鲁棒性和适应性，为动态投资组合优化提供了有效的AI驱动解决方案

Abstract: This paper introduces a hybrid framework for portfolio optimization that fuses Long Short-Term Memory (LSTM) forecasting with a Proximal Policy Optimization (PPO) reinforcement learning strategy. The proposed system leverages the predictive power of deep recurrent networks to capture temporal dependencies, while the PPO agent adaptively refines portfolio allocations in continuous action spaces, allowing the system to anticipate trends while adjusting dynamically to market shifts. Using multi-asset datasets covering U.S. and Indonesian equities, U.S. Treasuries, and major cryptocurrencies from January 2018 to December 2024, the model is evaluated against several baselines, including equal-weight, index-style, and single-model variants (LSTM-only and PPO-only). The framework's performance is benchmarked against equal-weighted, index-based, and single-model approaches (LSTM-only and PPO-only) using annualized return, volatility, Sharpe ratio, and maximum drawdown metrics, each adjusted for transaction costs. The results indicate that the hybrid architecture delivers higher returns and stronger resilience under non-stationary market regimes, suggesting its promise as a robust, AI-driven framework for dynamic portfolio optimization.

</details>


### [401] [Uncertainty-Aware Federated Learning for Cyber-Resilient Microgrid Energy Management](https://arxiv.org/abs/2511.17968)
*Oluleke Babayomi,Dong-Seong Kim*

Main category: cs.LG

TL;DR: 提出了一种集成联邦LSTM光伏预测和级联虚假数据注入攻击检测的微电网网络弹性框架，通过多信号融合显著提升了攻击检测精度和经济损失缓解能力。


<details>
  <summary>Details</summary>
Motivation: 解决微电网在遭受网络攻击时经济效率和运行可靠性的挑战，现有方法假设测量数据正常、预测不确定性未量化，且未针对可再生能源预测的恶意攻击进行优化。

Method: 结合自编码器重构误差和预测不确定性量化，采用两阶段级联虚假数据注入攻击检测与能量管理系统优化，实现攻击弹性储能调度并保护数据隐私。

Result: 在极端虚假数据攻击条件下（导致58%预测性能下降和16.9%运营成本增加），该框架将误报检测降低70%，恢复93.7%预测性能损失，实现5%运营成本节约，缓解34.7%攻击引发的经济损失。

Conclusion: 基于精度的级联检测与多信号融合方法优于单信号方法，验证了去中心化微电网安全与性能的协同效应。

Abstract: Maintaining economic efficiency and operational reliability in microgrid energy management systems under cyberattack conditions remains challenging. Most approaches assume non-anomalous measurements, make predictions with unquantified uncertainties, and do not mitigate malicious attacks on renewable forecasts for energy management optimization. This paper presents a comprehensive cyber-resilient framework integrating federated Long Short-Term Memory-based photovoltaic forecasting with a novel two-stage cascade false data injection attack detection and energy management system optimization. The approach combines autoencoder reconstruction error with prediction uncertainty quantification to enable attack-resilient energy storage scheduling while preserving data privacy. Extreme false data attack conditions were studied that caused 58% forecast degradation and 16.9\% operational cost increases. The proposed integrated framework reduced false positive detections by 70%, recovered 93.7% of forecasting performance losses, and achieved 5\% operational cost savings, mitigating 34.7% of attack-induced economic losses. Results demonstrate that precision-focused cascade detection with multi-signal fusion outperforms single-signal approaches, validating security-performance synergy for decentralized microgrids.

</details>


### [402] [Controllability Analysis of State Space-based Language Model](https://arxiv.org/abs/2511.17970)
*Mohamed Mabrok,Yalda Zafari*

Main category: cs.LG

TL;DR: 该论文提出了Influence Score这一基于可控性的度量指标，用于量化Mamba状态空间模型中不同token对后续状态和输出的影响程度，并通过多个实验验证了该指标的有效性。


<details>
  <summary>Details</summary>
Motivation: 状态空间模型（特别是Mamba）已成为序列建模的强大架构，但其内部动态机制相比基于注意力的模型仍缺乏深入理解，需要开发新的解释性工具。

Method: 基于Mamba离散化状态空间参数，通过类似于系统可观测性的反向递推计算Influence Score，并在三个Mamba变体上进行六组实验，测试该指标对温度、提示复杂度、token类型、层深度、token位置和输入扰动的敏感性。

Result: 研究发现：1）Influence Score随模型大小和训练数据增加而增加，反映模型容量；2）Mamba展现出一致的架构模式，包括近因偏差和影响力集中在中间到后期层；3）仅在较大规模模型中出现涌现行为，mamba-2.8b-slimpj独特地优先处理内容词并在存在噪声时减少内部影响。

Conclusion: Influence Score为解释和比较基于状态空间模型的语言模型提供了一个实用的诊断工具，有助于更好地理解SSM的内部工作机制。

Abstract: State-space models (SSMs), particularly Mamba, have become powerful architectures for sequence modeling, yet their internal dynamics remain poorly understood compared to attention-based models. We introduce and validate the Influence Score, a controllability-based metric derived from the discretized state-space parameters of Mamba and computed through a backward recurrence analogous to system observability. The score quantifies how strongly a token at position k affects all later states and outputs. We evaluate this measure across three Mamba variants: mamba-130m, mamba-2.8b, and mamba-2.8b-slimpj, using six experiments that test its sensitivity to temperature, prompt complexity, token type, layer depth, token position, and input perturbations. The results show three main insights: (1) the Influence Score increases with model size and training data, reflecting model capacity; (2) Mamba exhibits consistent architectural patterns, including recency bias and concentrated influence in mid-to-late layers; and (3) emergent behaviors appear only at scale, with mamba-2.8b-slimpj uniquely prioritizing content words and reducing internal influence in the presence of noise. These findings establish the Influence Score as a practical diagnostic tool for interpreting and comparing SSM-based language models.

</details>


### [403] [AVA-VLA: Improving Vision-Language-Action models with Active Visual Attention](https://arxiv.org/abs/2511.18960)
*Lei Xiao,Jifeng Li,Juntao Gao,Feiyang Ye,Yan Jin,Jingjing Qian,Jing Zhang,Yong Wu,Xiaoyuan Yu*

Main category: cs.LG

TL;DR: AVA-VLA框架通过引入主动视觉注意力机制，基于历史上下文动态处理视觉token，在机器人任务中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在每个时间步独立处理密集视觉输入，这种历史无关的设计无法有效利用历史上下文，在动态顺序决策中存在局限性。

Method: 从POMDP角度重新定义问题，提出AVA-VLA框架，利用循环状态（信念状态的神经近似）计算软权重，主动处理任务相关的视觉token。

Result: 在LIBERO和CALVIN等机器人基准测试中达到最先进性能，并在双臂机器人平台上验证了实际应用性和鲁棒的模拟到现实迁移能力。

Conclusion: AVA-VLA通过结合历史上下文进行动态视觉处理，显著提升了VLA模型在具身AI任务中的表现，具有良好的实用价值。

Abstract: Vision-Language-Action (VLA) models have demonstrated remarkable capabilities in embodied AI tasks. However, existing VLA models, often built upon Vision-Language Models (VLMs), typically process dense visual inputs independently at each timestep. This approach implicitly models the task as a Markov Decision Process (MDP). However, this history-agnostic design is suboptimal for effective visual token processing in dynamic sequential decision-making, as it fails to leverage the context of history. To address this limitation, we reformulate the problem from a Partially Observable Markov Decision Process (POMDP) perspective and propose a novel framework named AVA-VLA. Inspired by the POMDP that the action generation should be conditioned on the belief state. AVA-VLA introduces Active Visual Attention (AVA) to dynamically modulate visual processing. It achieves this by leveraging the recurrent state, which is a neural approximation of the agent's belief state derived from the previous decision step. Specifically, the AVA module uses the recurrent state to compute the soft weights to actively process task-relevant visual tokens based on its historical context. Comprehensive evaluations demonstrate that AVA-VLA achieves state-of-the-art performance across popular robotic benchmarks, including LIBERO and CALVIN. Furthermore, real-world deployments on a dual-arm robot platform validate the framework's practical applicability and robust sim-to-real transferability.

</details>


### [404] [Federated Anomaly Detection and Mitigation for EV Charging Forecasting Under Cyberattacks](https://arxiv.org/abs/2511.17978)
*Oluleke Babayomi,Dong-Seong Kim*

Main category: cs.LG

TL;DR: 提出了一种新颖的异常弹性联邦学习框架，用于解决电动汽车充电基础设施面临的网络安全威胁，同时保护数据隐私、检测网络攻击，并在对抗条件下保持可信的需求预测准确性。


<details>
  <summary>Details</summary>
Motivation: 现有预测技术缺乏结合强大异常缓解解决方案和数据隐私保护的机制，无法有效应对日益严重的网络安全威胁。

Method: 集成LSTM自编码器分布式异常检测、基于插值的异常数据缓解和联邦LSTM网络，实现无需集中数据聚合的协作学习。

Result: 联邦方法相比集中式模型R2准确率提升15.2%，攻击检测精度达91.3%，误报率仅1.21%，恢复47.9%的攻击导致性能下降。

Conclusion: 该架构能够增强电动汽车基础设施规划、隐私保护协作预测、网络安全弹性以及分布式充电网络的快速恢复能力。

Abstract: Electric Vehicle (EV) charging infrastructure faces escalating cybersecurity threats that can severely compromise operational efficiency and grid stability. Existing forecasting techniques are limited by the lack of combined robust anomaly mitigation solutions and data privacy preservation. Therefore, this paper addresses these challenges by proposing a novel anomaly-resilient federated learning framework that simultaneously preserves data privacy, detects cyber-attacks, and maintains trustworthy demand prediction accuracy under adversarial conditions. The proposed framework integrates three key innovations: LSTM autoencoder-based distributed anomaly detection deployed at each federated client, interpolation-based anomalous data mitigation to preserve temporal continuity, and federated Long Short-Term Memory (LSTM) networks that enable collaborative learning without centralized data aggregation. The framework is validated on real-world EV charging infrastructure datasets combined with real-world DDoS attack datasets, providing robust validation of the proposed approach under realistic threat scenarios. Experimental results demonstrate that the federated approach achieves superior performance compared to centralized models, with 15.2% improvement in R2 accuracy while maintaining data locality. The integrated cyber-attack detection and mitigation system produces trustworthy datasets that enhance prediction reliability, recovering 47.9% of attack-induced performance degradation while maintaining exceptional precision (91.3%) and minimal false positive rates (1.21%). The proposed architecture enables enhanced EV infrastructure planning, privacy-preserving collaborative forecasting, cybersecurity resilience, and rapid recovery from malicious threats across distributed charging networks.

</details>


### [405] [First-order Sobolev Reinforcement Learning](https://arxiv.org/abs/2511.19165)
*Fabian Schramm,Nicolas Perrin-Gilbert,Justin Carpentier*

Main category: cs.LG

TL;DR: 本文提出了一种改进的时间差分学习算法，通过强制一阶贝尔曼一致性来提升学习效果。


<details>
  <summary>Details</summary>
Motivation: 传统的时间差分学习只关注价值函数与贝尔曼目标在数值上的匹配，而忽略了它们在状态和动作空间中的局部几何结构。这可能导致价值函数收敛缓慢且策略梯度不稳定。

Method: 通过可微分的动态模型对贝尔曼备份进行微分，获得解析一致的梯度目标。使用Sobolev型损失函数将一阶TD匹配原则融入批评器目标，使批评器不仅匹配价值目标，还匹配其局部几何结构。

Result: 该方法可以无缝集成到现有算法中（如Q-learning、DDPG、SAC），不改变整体结构，但能带来更快的批评器收敛速度和更稳定的策略梯度。

Conclusion: 一阶TD匹配原则通过增强价值函数的局部一致性，为强化学习算法提供了更高效和稳定的学习框架。

Abstract: We propose a refinement of temporal-difference learning that enforces first-order Bellman consistency: the learned value function is trained to match not only the Bellman targets in value but also their derivatives with respect to states and actions. By differentiating the Bellman backup through differentiable dynamics, we obtain analytically consistent gradient targets. Incorporating these into the critic objective using a Sobolev-type loss encourages the critic to align with both the value and local geometry of the target function. This first-order TD matching principle can be seamlessly integrated into existing algorithms, such as Q-learning or actor-critic methods (e.g., DDPG, SAC), potentially leading to faster critic convergence and more stable policy gradients without altering their overall structure.

</details>


### [406] [An Adaptive Resonance Theory-based Topological Clustering Algorithm with a Self-Adjusting Vigilance Parameter](https://arxiv.org/abs/2511.17983)
*Naoki Masuyama,Yuichiro Toda,Yusuke Nojima,Hisao Ishibuchi*

Main category: cs.LG

TL;DR: 提出基于自适应共振理论(ART)的拓扑聚类算法，通过多样性驱动的自适应机制自动调整重计算间隔和警戒阈值，实现无超参数学习，在动态环境中保持聚类稳定性和连续性。


<details>
  <summary>Details</summary>
Motivation: 解决静态和非静态设置下的聚类问题，需要模型能够适应分布变化同时保留已学习的聚类结构。

Method: 采用ART-based拓扑聚类算法，通过多样性驱动机制自适应调整重计算间隔和警戒阈值，实现超参数自由学习。

Result: 在24个真实世界数据集上的实验表明，该算法在聚类性能和持续学习能力方面优于最先进方法。

Conclusion: 所提出的参数自适应方法有效缓解了灾难性遗忘问题，并在演化数据流中保持了稳定的聚类性能。

Abstract: Clustering in stationary and nonstationary settings, where data distributions remain static or evolve over time, requires models that can adapt to distributional shifts while preserving previously learned cluster structures. This paper proposes an Adaptive Resonance Theory (ART)-based topological clustering algorithm that autonomously adjusts its recalculation interval and vigilance threshold through a diversity-driven adaptation mechanism. This mechanism enables hyperparameter-free learning that maintains cluster stability and continuity in dynamic environments. Experiments on 24 real-world datasets demonstrate that the proposed algorithm outperforms state-of-the-art methods in both clustering performance and continual learning capability. These results highlight the effectiveness of the proposed parameter adaptation in mitigating catastrophic forgetting and maintaining consistent clustering in evolving data streams. Source code is available at https://github.com/Masuyama-lab/IDAT

</details>


### [407] [Escaping Optimization Stagnation: Taking Steps Beyond Task Arithmetic via Difference Vectors](https://arxiv.org/abs/2511.17987)
*Jinping Wang,Zhiqiang Gao,Dinggen Zhang,Zhiwu Xie*

Main category: cs.LG

TL;DR: 提出了基于差异向量的各向异性缩放迭代算法（DV-BASI），通过利用优化过程中的历史移动向量作为定向扰动，解决任务算术方法中的优化停滞问题，提高模型编辑的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 当前预训练模型编辑方法面临高计算成本和有限可扩展性的挑战，任务算术方法虽然前景广阔，但由于优化停滞机制有限，其潜力尚未充分发掘。

Method: 引入差异向量概念（任务向量的广义形式），提出DV-BASI算法，利用差异向量的逃逸性和方向优势实现连续优化过程，无需额外模块。

Result: DV-BASI在多任务模型合并中的平均性能甚至可能超过单独微调的模型，在监督和无监督评估协议上达到最先进性能。

Conclusion: 差异向量为模型编辑提供了可扩展框架，DV-BASI算法通过少量可学习参数实现表达性搜索方向，显著提升了任务算术方法的性能。

Abstract: Current methods for editing pre-trained models face significant challenges, primarily high computational costs and limited scalability. Task arithmetic has recently emerged as a promising solution, using simple arithmetic operations-addition and negation-based on task vectors which are the differences between fine-tuned and pre-trained model weights, to efficiently modify model behavior. However, the full potential of task arithmetic remains underexplored, primarily due to limited mechanisms for overcoming optimization stagnation. To address this challenge, we introduce the notion of difference vector, a generalized form of task vectors derived from the historical movements during optimization. Using difference vectors as directed perturbations, we propose the Difference Vector-based Anisotropic Scaling Iterative algorithm (DV-BASI) to enable a continuous optimization process for task arithmetic methods without relying on any additional modules or components. Notably, by leveraging escapability and directional advantages of difference vectors, the average performance on different tasks of the multi-task model merged by DV-BASI may even outperform models individually fine-tuned. Based on this observation, we extend the application of difference vectors to a feasible fine-tuning method for single-task models. On the practical side, DV-BASI allows expressive searching directions with few learnable parameters and forms a scalable framework. We also integrate DV-BASI with task arithmetic methods and advanced optimization techniques to achieve state-of-the-art performance on both supervised and unsupervised evaluation protocols.

</details>


### [408] [Leveraging LLMs for reward function design in reinforcement learning control tasks](https://arxiv.org/abs/2511.19355)
*Franklin Cardenoso,Wouter Caarls*

Main category: cs.LG

TL;DR: LEARN-Opt是一个基于LLM的完全自主、模型无关的框架，能够从系统描述和任务目标中自动生成、执行和评估奖励函数，无需初步指标和环境源代码。


<details>
  <summary>Details</summary>
Motivation: 传统RL中设计有效奖励函数需要大量人工专业知识且耗时，现有方法需要初步评估指标、人工反馈或环境源代码作为上下文。

Method: 提出LEARN-Opt框架，通过LLM从文本描述中自主推导性能指标，实现无监督的奖励函数评估和选择。

Result: 实验表明LEARN-Opt性能与最先进方法相当或更好，且需要较少先验知识。能利用低成本LLM找到高性能候选方案。

Conclusion: LEARN-Opt有潜力在不需人工定义指标的情况下生成高质量奖励函数，减少工程开销并增强泛化能力。

Abstract: The challenge of designing effective reward functions in reinforcement learning (RL) represents a significant bottleneck, often requiring extensive human expertise and being time-consuming. Previous work and recent advancements in large language models (LLMs) have demonstrated their potential for automating the generation of reward functions. However, existing methodologies often require preliminary evaluation metrics, human-engineered feedback for the refinement process, or the use of environmental source code as context. To address these limitations, this paper introduces LEARN-Opt (LLM-based Evaluator and Analyzer for Reward functioN Optimization). This LLM-based, fully autonomous, and model-agnostic framework eliminates the need for preliminary metrics and environmental source code as context to generate, execute, and evaluate reward function candidates from textual descriptions of systems and task objectives. LEARN-Opt's main contribution lies in its ability to autonomously derive performance metrics directly from the system description and the task objective, enabling unsupervised evaluation and selection of reward functions. Our experiments indicate that LEARN-Opt achieves performance comparable to or better to that of state-of-the-art methods, such as EUREKA, while requiring less prior knowledge. We find that automated reward design is a high-variance problem, where the average-case candidate fails, requiring a multi-run approach to find the best candidates. Finally, we show that LEARN-Opt can unlock the potential of low-cost LLMs to find high-performing candidates that are comparable to, or even better than, those of larger models. This demonstrated performance affirms its potential to generate high-quality reward functions without requiring any preliminary human-defined metrics, thereby reducing engineering overhead and enhancing generalizability.

</details>


### [409] [Privacy Auditing of Multi-domain Graph Pre-trained Model under Membership Inference Attacks](https://arxiv.org/abs/2511.17989)
*Jiayi Luo,Qingyun Sun,Yuecen Wei,Haonan Yuan,Xingcheng Fu,Jianxin Li*

Main category: cs.LG

TL;DR: 提出了MGP-MIA框架，用于针对多域图预训练模型的成员推理攻击，解决了预训练模型增强泛化能力、影子数据集不具代表性和成员信号减弱等挑战


<details>
  <summary>Details</summary>
Motivation: 多域图预训练技术虽然提升了图神经网络的泛化能力，但其在成员推理攻击下的隐私风险尚未被充分探索，存在严重的安全隐患

Method: 1. 成员信号放大机制：通过机器遗忘放大目标模型的过拟合特征；2. 增量影子模型构建：通过增量学习构建可靠影子模型；3. 基于相似度的推理机制：根据样本与正负样本的相似度识别成员

Result: 大量实验证明MGP-MIA框架的有效性，揭示了多域图预训练存在的隐私风险

Conclusion: 多域图预训练模型存在严重的隐私泄露风险，MGP-MIA框架能够有效进行成员推理攻击，为图基础模型的安全设计提供了重要参考

Abstract: Multi-domain graph pre-training has emerged as a pivotal technique in developing graph foundation models. While it greatly improves the generalization of graph neural networks, its privacy risks under membership inference attacks (MIAs), which aim to identify whether a specific instance was used in training (member), remain largely unexplored. However, effectively conducting MIAs against multi-domain graph pre-trained models is a significant challenge due to: (i) Enhanced Generalization Capability: Multi-domain pre-training reduces the overfitting characteristics commonly exploited by MIAs. (ii) Unrepresentative Shadow Datasets: Diverse training graphs hinder the obtaining of reliable shadow graphs. (iii) Weakened Membership Signals: Embedding-based outputs offer less informative cues than logits for MIAs. To tackle these challenges, we propose MGP-MIA, a novel framework for Membership Inference Attacks against Multi-domain Graph Pre-trained models. Specifically, we first propose a membership signal amplification mechanism that amplifies the overfitting characteristics of target models via machine unlearning. We then design an incremental shadow model construction mechanism that builds a reliable shadow model with limited shadow graphs via incremental learning. Finally, we introduce a similarity-based inference mechanism that identifies members based on their similarity to positive and negative samples. Extensive experiments demonstrate the effectiveness of our proposed MGP-MIA and reveal the privacy risks of multi-domain graph pre-training.

</details>


### [410] [Learning Rate Scheduling with Matrix Factorization for Private Training](https://arxiv.org/abs/2511.17994)
*Nikita P. Kalinin,Joel Daniel Andersson*

Main category: cs.LG

TL;DR: 本文研究了差分隐私下带学习率调度和相关性噪声的随机梯度下降模型训练，提出了学习率感知的矩阵分解方法，在理论和实验上都优于传统的prefix-sum分解方法。


<details>
  <summary>Details</summary>
Motivation: 现有工作主要关注恒定学习率下的prefix-sum分解，但实际训练中广泛使用学习率调度来加速收敛。本文旨在填补这一理论空白。

Method: 推导了单轮和多轮训练设置下各类学习率调度的上下界，基于此提出学习率感知的矩阵分解方法，在MaxSE和MeanSE误差指标上优于prefix-sum分解。

Result: 理论分析得到了适合实际部署的内存高效构造，在CIFAR-10和IMDB数据集上的实验证实了调度感知分解能提高隐私训练的准确性。

Conclusion: 学习率感知的矩阵分解方法在差分隐私训练中具有理论和实践优势，为实际应用提供了有效的解决方案。

Abstract: We study differentially private model training with stochastic gradient descent under learning rate scheduling and correlated noise. Although correlated noise, in particular via matrix factorizations, has been shown to improve accuracy, prior theoretical work focused primarily on the prefix-sum workload. That workload assumes a constant learning rate, whereas in practice learning rate schedules are widely used to accelerate training and improve convergence. We close this gap by deriving general upper and lower bounds for a broad class of learning rate schedules in both single- and multi-epoch settings. Building on these results, we propose a learning-rate-aware factorization that achieves improvements over prefix-sum factorizations under both MaxSE and MeanSE error metrics. Our theoretical analysis yields memory-efficient constructions suitable for practical deployment, and experiments on CIFAR-10 and IMDB datasets confirm that schedule-aware factorizations improve accuracy in private training.

</details>


### [411] [Reward Engineering for Spatial Epidemic Simulations: A Reinforcement Learning Platform for Individual Behavioral Learning](https://arxiv.org/abs/2511.18000)
*Radman Rakhshandehroo,Daniel Coombs*

Main category: cs.LG

TL;DR: ContagionRL是一个兼容Gymnasium的强化学习平台，专门用于空间流行病模拟中的系统性奖励工程研究。


<details>
  <summary>Details</summary>
Motivation: 传统基于代理的模型依赖固定行为规则，无法系统评估奖励函数设计对学习生存策略的影响。该平台旨在填补此类模型中奖励工程研究不足的知识空白。

Method: 平台整合了空间SIRS+D流行病学模型和可配置环境参数，评估了五种不同奖励设计（包括新颖的势场方法）在多种RL算法（PPO、SAC、A2C）下的表现。

Result: 系统消融研究表明，方向性指导和明确的依从激励是稳健策略学习的关键组成部分。使用势场奖励训练的智能体始终获得优越性能，学会了最大程度遵守非药物干预措施并发展出复杂的空间规避策略。

Conclusion: ContagionRL是研究流行病背景下适应性行为响应的有效平台，强调了奖励设计、信息结构和环境可预测性在学习中的重要性。

Abstract: We present ContagionRL, a Gymnasium-compatible reinforcement learning platform specifically designed for systematic reward engineering in spatial epidemic simulations. Unlike traditional agent-based models that rely on fixed behavioral rules, our platform enables rigorous evaluation of how reward function design affects learned survival strategies across diverse epidemic scenarios. ContagionRL integrates a spatial SIRS+D epidemiological model with configurable environmental parameters, allowing researchers to stress-test reward functions under varying conditions including limited observability, different movement patterns, and heterogeneous population dynamics. We evaluate five distinct reward designs, ranging from sparse survival bonuses to a novel potential field approach, across multiple RL algorithms (PPO, SAC, A2C). Through systematic ablation studies, we identify that directional guidance and explicit adherence incentives are critical components for robust policy learning. Our comprehensive evaluation across varying infection rates, grid sizes, visibility constraints, and movement patterns reveals that reward function choice dramatically impacts agent behavior and survival outcomes. Agents trained with our potential field reward consistently achieve superior performance, learning maximal adherence to non-pharmaceutical interventions while developing sophisticated spatial avoidance strategies. The platform's modular design enables systematic exploration of reward-behavior relationships, addressing a knowledge gap in models of this type where reward engineering has received limited attention. ContagionRL is an effective platform for studying adaptive behavioral responses in epidemic contexts and highlight the importance of reward design, information structure, and environmental predictability in learning.

</details>


### [412] [Understanding Private Learning From Feature Perspective](https://arxiv.org/abs/2511.18006)
*Meng Ding,Mingxi Lei,Shaopeng Fu,Shaowei Wang,Di Wang,Jinhui Xu*

Main category: cs.LG

TL;DR: 本文提出了首个从特征学习角度分析DP-SGD训练的理论框架，揭示了私有学习中特征信号学习和数据噪声记忆的机制，发现私有学习需要更高的信噪比且会继承非私有学习中的噪声记忆问题。


<details>
  <summary>Details</summary>
Motivation: 尽管利用预训练模型特征增强DP-SGD训练已取得显著经验进展，但私有学习中特征动态的理论理解仍未被充分探索。现有DP分析忽视了标签依赖特征信号和标签无关噪声的关键区别。

Method: 基于多块数据结构，使用带多项式ReLU激活的两层CNN，通过噪声梯度下降理论分析私有训练中的特征信号学习和数据噪声记忆。

Result: 发现：(1)有效私有信号学习需要比非私有训练更高的信噪比；(2)当非私有学习中出现数据噪声记忆时，私有学习也会出现，导致训练损失小但泛化性能差。

Conclusion: 研究凸显了私有学习的挑战，证明了特征增强提高信噪比的益处，合成和真实数据集实验验证了理论发现。

Abstract: Differentially private Stochastic Gradient Descent (DP-SGD) has become integral to privacy-preserving machine learning, ensuring robust privacy guarantees in sensitive domains. Despite notable empirical advances leveraging features from non-private, pre-trained models to enhance DP-SGD training, a theoretical understanding of feature dynamics in private learning remains underexplored. This paper presents the first theoretical framework to analyze private training through a feature learning perspective. Building on the multi-patch data structure from prior work, our analysis distinguishes between label-dependent feature signals and label-independent noise, a critical aspect overlooked by existing analyses in the DP community. Employing a two-layer CNN with polynomial ReLU activation, we theoretically characterize both feature signal learning and data noise memorization in private training via noisy gradient descent. Our findings reveal that (1) Effective private signal learning requires a higher signal-to-noise ratio (SNR) compared to non-private training, and (2) When data noise memorization occurs in non-private learning, it will also occur in private learning, leading to poor generalization despite small training loss. Our findings highlight the challenges of private learning and prove the benefit of feature enhancement to improve SNR. Experiments on synthetic and real-world datasets also validate our theoretical findings.

</details>


### [413] [Curvature-Aware Safety Restoration In LLMs Fine-Tuning](https://arxiv.org/abs/2511.18039)
*Thong Bach,Thanh Nguyen-Tang,Dung Nguyen,Thao Minh Le,Truyen Tran*

Main category: cs.LG

TL;DR: 该论文提出了一种曲率感知对齐恢复方法，利用影响函数和二阶优化来选择性增加有害输入的损失，同时保持任务性能，有效解决LLM微调导致的安全对齐退化问题。


<details>
  <summary>Details</summary>
Motivation: 微调大型语言模型（LLMs）用于下游任务往往会损害安全对齐，即使使用LoRA等参数高效方法。研究发现微调模型在有害内容上的损失景观几何结构得以保留，表明安全行为并未被擦除而是被转移到参数空间中影响力较小的区域。

Method: 基于几何结构保留的洞察，提出曲率感知对齐恢复方法，利用影响函数和二阶优化，在基模型和微调模型之间共享几何结构的基础上，选择性增加有害输入的损失，同时保持任务相关性能，避免完全回滚并实现精确、低影响的更新。

Result: 在多个模型系列和对抗设置下的广泛评估表明，该方法能有效减少有害响应，同时保持甚至提高效用和少样本学习性能。

Conclusion: 该方法通过利用微调模型保留的几何结构，实现了安全对齐的高效恢复，为LLM微调后的安全维护提供了有效解决方案。

Abstract: Fine-tuning Large Language Models (LLMs) for downstream tasks often compromises safety alignment, even when using parameter-efficient methods like LoRA. In this work, we uncover a notable property: fine-tuned models preserve the geometric structure of their loss landscapes concerning harmful content, regardless of the fine-tuning method employed. This suggests that safety behaviors are not erased but shifted to less influential regions of the parameter space. Building on this insight, we propose a curvature-aware alignment restoration method that leverages influence functions and second-order optimization to selectively increase loss on harmful inputs while preserving task performance. By navigating the shared geometry between base and fine-tuned models, our method discourages unsafe outputs while preserving task-relevant performance, avoiding full reversion and enabling precise, low-impact updates. Extensive evaluations across multiple model families and adversarial settings show that our approach efficiently reduces harmful responses while maintaining or even improving utility and few-shot learning performance.

</details>


### [414] [Hierarchical Linkage Clustering Beyond Binary Trees and Ultrametrics](https://arxiv.org/abs/2511.18056)
*Maximilien Dreveton,Matthias Grossglauser,Daichi Kuroda,Patrick Thiran*

Main category: cs.LG

TL;DR: 本文针对传统层次聚类方法的三大局限性，提出了有效层次结构的概念，定义了有效层次结构的偏序关系，并证明了最精细有效层次结构的存在性。


<details>
  <summary>Details</summary>
Motivation: 传统层次聚类方法存在三个主要问题：总是返回层次结构（即使不存在）、限制为二叉树（即使真实结构是非二元的）、对链接函数选择高度敏感。

Method: 提出一个简单的两步算法：首先通过链接方法构建二叉树，然后通过剪枝强制实施有效性。建立了链接函数恢复最精细有效层次结构的充要条件。

Result: 证明了经典链接规则（如单链接、完全链接、平均链接）满足条件，而Ward链接不满足。所有满足条件的链接函数在剪枝后产生相同的层次结构。

Conclusion: 该方法能够自动识别数据中是否存在层次结构，不强制二叉树约束，当不存在层次关系时退化为星形树，解决了传统方法的固有问题。

Abstract: Hierarchical clustering seeks to uncover nested structures in data by constructing a tree of clusters, where deeper levels reveal finer-grained relationships. Traditional methods, including linkage approaches, face three major limitations: (i) they always return a hierarchy, even if none exists, (ii) they are restricted to binary trees, even if the true hierarchy is non-binary, and (iii) they are highly sensitive to the choice of linkage function. In this paper, we address these issues by introducing the notion of a valid hierarchy and defining a partial order over the set of valid hierarchies. We prove the existence of a finest valid hierarchy, that is, the hierarchy that encodes the maximum information consistent with the similarity structure of the data set. In particular, the finest valid hierarchy is not constrained to binary structures and, when no hierarchical relationships exist, collapses to a star tree. We propose a simple two-step algorithm that first constructs a binary tree via a linkage method and then prunes it to enforce validity. We establish necessary and sufficient conditions on the linkage function under which this procedure exactly recovers the finest valid hierarchy, and we show that all linkage functions satisfying these conditions yield the same hierarchy after pruning. Notably, classical linkage rules such as single, complete, and average satisfy these conditions, whereas Ward's linkage fails to do so.

</details>


### [415] [pFedBBN: A Personalized Federated Test-Time Adaptation with Balanced Batch Normalization for Class-Imbalanced Data](https://arxiv.org/abs/2511.18066)
*Md Akil Raihan Iftee,Syed Md. Ahnaf Hasan,Mir Sazzat Hossain,Rakibul Hasan Rajib,Amin Ahsan Ali,AKM Mahbubur Rahman,Sajib Mistry,Monowar Bhuyan*

Main category: cs.LG

TL;DR: pFedBBN是一个个性化的联邦测试时自适应框架，通过平衡批量归一化解决联邦学习中的类别不平衡问题，在无需客户端标签或原始数据的情况下实现无监督本地自适应和领域感知协作。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中的类别不平衡是一个关键挑战，特别是在测试时面对动态领域和分布偏移时。现有方法通常依赖标签数据或客户端协调，无法在联邦类别不平衡约束下实现无监督自适应。

Method: 采用平衡批量归一化(BBN)进行本地客户端自适应，通过平衡特征归一化平等对待所有类别；引入基于BBN相似度的客户端协作机制，使具有相似平衡表示的客户端相互增强；提出类别感知模型聚合策略实现个性化推理。

Result: 在多个基准测试上的广泛实验表明，pFedBBN在鲁棒性和少数类性能方面持续优于最先进的联邦学习和测试时自适应方法。

Conclusion: pFedBBN通过平衡特征归一化和领域感知协作，有效解决了分布偏移和类别不平衡问题，为联邦测试时自适应提供了有效的无监督解决方案。

Abstract: Test-time adaptation (TTA) in federated learning (FL) is crucial for handling unseen data distributions across clients, particularly when faced with domain shifts and skewed class distributions. Class Imbalance (CI) remains a fundamental challenge in FL, where rare but critical classes are often severely underrepresented in individual client datasets. Although prior work has addressed CI during training through reliable aggregation and local class distribution alignment, these methods typically rely on access to labeled data or coordination among clients, and none address class unsupervised adaptation to dynamic domains or distribution shifts at inference time under federated CI constraints. Revealing the failure of state-of-the-art TTA in federated client adaptation in CI scenario, we propose pFedBBN,a personalized federated test-time adaptation framework that employs balanced batch normalization (BBN) during local client adaptation to mitigate prediction bias by treating all classes equally, while also enabling client collaboration guided by BBN similarity, ensuring that clients with similar balanced representations reinforce each other and that adaptation remains aligned with domain-specific characteristics. pFedBBN supports fully unsupervised local adaptation and introduces a class-aware model aggregation strategy that enables personalized inference without compromising privacy. It addresses both distribution shifts and class imbalance through balanced feature normalization and domain-aware collaboration, without requiring any labeled or raw data from clients. Extensive experiments across diverse baselines show that pFedBBN consistently enhances robustness and minority-class performance over state-of-the-art FL and TTA methods.

</details>


### [416] [The Alignment Paradox of Medical Large Language Models in Infertility Care: Decoupling Algorithmic Improvement from Clinical Decision-making Quality](https://arxiv.org/abs/2511.18084)
*Dou Liu,Ying Long,Sophia Zuoqiu,Kaipeng Xie,Runze Yang,Di Liu,Kang Li,Yiting Lin,Hanyi Liu,Rong Yin,Tian Tang*

Main category: cs.LG

TL;DR: 本文评估了四种大语言模型对齐策略在临床决策支持中的应用，发现GRPO在算法精度上最优，但临床医生更偏好SFT模型，揭示了算法改进与临床信任之间的对齐悖论。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在临床决策支持中应用日益广泛，但如何使其与真实世界医学的多维度推理路径对齐仍是一个重大挑战。

Method: 使用8,000多份不孕症治疗记录，系统评估四种对齐策略：SFT、DPO、GRPO和ICL，通过结合自动基准测试和盲法医生参与评估的双层框架。

Result: GRPO在多个决策层达到最高算法精度，但临床医生一致偏好SFT模型，认为其推理过程更清晰、治疗可行性更高。在盲法配对比较中，SFT获得最高胜率（51.2%），优于GRPO（26.2%）和医生原始决策（22.7%）。

Conclusion: 研究结果揭示了对齐悖论：算法改进不一定转化为更高的临床信任，可能与以人为中心的偏好相背离。需要优先考虑临床可解释性和实践可行性的对齐策略，而非仅优化决策级精度。

Abstract: Large language models (LLMs) are increasingly adopted in clinical decision support, yet aligning them with the multifaceted reasoning pathways of real-world medicine remains a major challenge. Using more than 8,000 infertility treatment records, we systematically evaluate four alignment strategies: Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), Group Relative Policy Optimization (GRPO), and In-Context Learning (ICL) through a dual-layer framework combining automatic benchmarks with blinded doctor-in-the-loop assessments. GRPO achieves the highest algorithmic accuracy across multiple decision layers, confirming the value of reinforcement-based optimization for structured prediction tasks. However, clinicians consistently prefer the SFT model, citing clearer reasoning processes (p = 0.035) and higher therapeutic feasibility (p = 0.019). In blinded pairwise comparisons, SFT attains the highest winning rate (51.2%), outperforming both GRPO (26.2%) and even physicians' original decisions (22.7%). These results reveal an alignment paradox: algorithmic improvements do not necessarily translate into higher clinical trust, and may diverge from human-centered preferences. Our findings highlight the need for alignment strategies that prioritize clinically interpretable and practically feasible reasoning, rather than solely optimizing decision-level accuracy.

</details>


### [417] [A New Error Temporal Difference Algorithm for Deep Reinforcement Learning in Microgrid Optimization](https://arxiv.org/abs/2511.18093)
*Fulong Yao,Wanqing Zhao,Matthew Forshaw*

Main category: cs.LG

TL;DR: 提出基于深度强化学习的预测控制新方法，通过误差时序差分算法解决微电网预测不确定性，提升运行性能


<details>
  <summary>Details</summary>
Motivation: 现有基于深度强化学习的微电网能量优化研究往往忽略预测模型不完善带来的不确定性，导致控制策略次优

Method: 1) 建立含可再生能源和储能系统的微电网MDP模型；2) 设计基于DQN的预测控制方法，包含加权平均算法和新型ETD算法分别量化和处理预测不确定性

Result: 在真实美国数据集上的仿真表明，ETD算法有效提升了深度强化学习在微电网运行优化中的性能

Conclusion: 所提出的ETD算法能够有效解决预测不确定性，为微电网优化控制提供了更可靠的方法

Abstract: Predictive control approaches based on deep reinforcement learning (DRL) have gained significant attention in microgrid energy optimization. However, existing research often overlooks the issue of uncertainty stemming from imperfect prediction models, which can lead to suboptimal control strategies. This paper presents a new error temporal difference (ETD) algorithm for DRL to address the uncertainty in predictions,aiming to improve the performance of microgrid operations. First,a microgrid system integrated with renewable energy sources (RES) and energy storage systems (ESS), along with its Markov decision process (MDP), is modelled. Second, a predictive control approach based on a deep Q network (DQN) is presented, in which a weighted average algorithm and a new ETD algorithm are designed to quantify and address the prediction uncertainty, respectively. Finally, simulations on a realworld US dataset suggest that the developed ETD effectively improves the performance of DRL in optimizing microgrid operations.

</details>


### [418] [Active Learning with Selective Time-Step Acquisition for PDEs](https://arxiv.org/abs/2511.18107)
*Yegon Kim,Hyunsu Kim,Gyeonghoon Ko,Juho Lee*

Main category: cs.LG

TL;DR: 本文提出了一种用于偏微分方程（PDE）代理建模的主动学习框架，通过仅生成关键时间步的数据来显著降低训练成本，提高数据效率。


<details>
  <summary>Details</summary>
Motivation: 传统PDE数值求解器计算成本高昂，而代理模型虽然高效但需要大量训练数据。现有主动学习方法需要获取整个PDE轨迹，成本仍然很高。

Method: 开发了一种新的主动学习框架，策略性地仅用数值求解器生成最重要的时间步，而使用代理模型近似其余步骤。还设计了评估时间步效用的获取函数。

Result: 在多个基准PDE上测试表明，该方法相比现有最佳方法性能大幅提升，不仅降低了平均误差，还改善了误差的99%、95%和50%分位数。

Conclusion: 该方法为PDE代理建模提供了数据高效的解决方案，显著降低了计算成本并提高了模型性能。

Abstract: Accurately solving partial differential equations (PDEs) is critical to understanding complex scientific and engineering phenomena, yet traditional numerical solvers are computationally expensive. Surrogate models offer a more efficient alternative, but their development is hindered by the cost of generating sufficient training data from numerical solvers. In this paper, we present a novel framework for active learning (AL) in PDE surrogate modeling that reduces this cost. Unlike the existing AL methods for PDEs that always acquire entire PDE trajectories, our approach strategically generates only the most important time steps with the numerical solver, while employing the surrogate model to approximate the remaining steps. This dramatically reduces the cost incurred by each trajectory and thus allows the active learning algorithm to try out a more diverse set of trajectories given the same budget. To accommodate this novel framework, we develop an acquisition function that estimates the utility of a set of time steps by approximating its resulting variance reduction. We demonstrate the effectiveness of our method on several benchmark PDEs, including the Burgers' equation, Korteweg-De Vries equation, Kuramoto-Sivashinsky equation, the incompressible Navier-Stokes equation, and the compressible Navier-Stokes equation. Experiments show that our approach improves performance by large margins over the best existing method. Our method not only reduces average error but also the 99\%, 95\%, and 50\% quantiles of error, which is rare for an AL algorithm. All in all, our approach offers a data-efficient solution to surrogate modeling for PDEs.

</details>


### [419] [Vulnerability-Aware Robust Multimodal Adversarial Training](https://arxiv.org/abs/2511.18138)
*Junrui Zhang,Xinyu Zhao,Jie Peng,Chenjie Wang,Jianmin Ji,Tianlong Chen*

Main category: cs.LG

TL;DR: 本文提出VARMAT方法，通过量化模态脆弱性来提升多模态对抗训练的鲁棒性，在三个数据集上分别实现12.73%、22.21%、11.19%的鲁棒性提升


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略了不同模态对最终鲁棒性贡献的差异，导致鲁棒性表现不佳。多模态模型容易受到对抗攻击，但现有攻击方法要么针对特定模态，要么无差别攻击所有模态

Method: VARMAT方法包含两个阶段：1) 探针阶段：基于攻击目标的一阶近似显式量化每个模态的脆弱性；2) 训练阶段：提出针对性正则化项，惩罚高脆弱性模态，在保持任务准确性的同时引导鲁棒学习

Result: 在多个涉及不同模态的多模态数据集上验证了方法的增强鲁棒性，在三个数据集上分别实现了12.73%、22.21%、11.19%的鲁棒性提升

Conclusion: 该方法揭示了多模态对抗训练中存在的重要盲点，通过感知模态脆弱性差异显著提升了多模态模型的鲁棒性

Abstract: Multimodal learning has shown significant superiority on various tasks by integrating multiple modalities. However, the interdependencies among modalities increase the susceptibility of multimodal models to adversarial attacks. Existing methods mainly focus on attacks on specific modalities or indiscriminately attack all modalities. In this paper, we find that these approaches ignore the differences between modalities in their contribution to final robustness, resulting in suboptimal robustness performance. To bridge this gap, we introduce Vulnerability-Aware Robust Multimodal Adversarial Training (VARMAT), a probe-in-training adversarial training method that improves multimodal robustness by identifying the vulnerability of each modality. To be specific, VARMAT first explicitly quantifies the vulnerability of each modality, grounded in a first-order approximation of the attack objective (Probe). Then, we propose a targeted regularization term that penalizes modalities with high vulnerability, guiding robust learning while maintaining task accuracy (Training). We demonstrate the enhanced robustness of our method across multiple multimodal datasets involving diverse modalities. Finally, we achieve {12.73%, 22.21%, 11.19%} robustness improvement on three multimodal datasets, revealing a significant blind spot in multimodal adversarial training.

</details>


### [420] [Graph Neural Networks vs Convolutional Neural Networks for Graph Domination Number Prediction](https://arxiv.org/abs/2511.18150)
*Randy Davila,Beyzanur Ispir*

Main category: cs.LG

TL;DR: 该研究比较了两种神经网络方法（CNN和GNN）在近似计算图支配数方面的性能，发现GNN在准确性和速度上都显著优于CNN。


<details>
  <summary>Details</summary>
Motivation: 图支配数的精确计算是NP难问题，传统方法只能处理小规模图实例，需要开发高效的近似计算方法。

Method: 使用卷积神经网络（CNN）和图神经网络（GNN）两种方法，在2000个最多包含64个顶点的随机图上进行训练和测试，比较它们在近似支配数方面的表现。

Result: GNN实现了明显更高的准确性（R²=0.987，MAE=0.372），而CNN为（R²=0.955，MAE=0.500）。GNN提供了超过200倍的加速，同时保持接近完美的保真度。

Conclusion: GNN可以作为组合图不变量的实用替代方法，对可扩展的图优化和数学发现具有重要意义。

Abstract: We investigate machine learning approaches to approximating the \emph{domination number} of graphs, the minimum size of a dominating set. Exact computation of this parameter is NP-hard, restricting classical methods to small instances. We compare two neural paradigms: Convolutional Neural Networks (CNNs), which operate on adjacency matrix representations, and Graph Neural Networks (GNNs), which learn directly from graph structure through message passing. Across 2,000 random graphs with up to 64 vertices, GNNs achieve markedly higher accuracy ($R^2=0.987$, MAE $=0.372$) than CNNs ($R^2=0.955$, MAE $=0.500$). Both models offer substantial speedups over exact solvers, with GNNs delivering more than $200\times$ acceleration while retaining near-perfect fidelity. Our results position GNNs as a practical surrogate for combinatorial graph invariants, with implications for scalable graph optimization and mathematical discovery.

</details>


### [421] [LocaGen: Low-Overhead Indoor Localization Through Spatial Augmentation](https://arxiv.org/abs/2511.18158)
*Abdelrahman Abdelmotlb,Abdallah Taman,Sherif Mostafa,Moustafa Youssef*

Main category: cs.LG

TL;DR: LocaGen是一个空间增强框架，通过生成高质量合成数据显著减少指纹定位开销，在未见位置保持定位精度。


<details>
  <summary>Details</summary>
Motivation: 现有室内定位系统依赖指纹定位，需要大量实地勘测工作，限制了实际部署。现有减少开销的方法存在表示能力低、模式崩溃问题或仍需在所有目标位置收集数据。

Method: 使用条件扩散模型结合空间感知优化策略，在仅使用部分已见位置数据的情况下合成未见位置的现实指纹。通过基于领域特定启发式的数据增强和基于密度的位置选择策略确保鲁棒覆盖。

Result: 在真实WiFi指纹数据集上的评估显示，即使30%位置未见，LocaGen仍能保持相同定位精度，比最先进的增强方法精度提升高达28%。

Conclusion: LocaGen通过创新的空间增强方法有效解决了指纹定位系统的部署限制问题，显著减少了数据收集开销。

Abstract: Indoor localization systems commonly rely on fingerprinting, which requires extensive survey efforts to obtain location-tagged signal data, limiting their real-world deployability. Recent approaches that attempt to reduce this overhead either suffer from low representation ability, mode collapse issues, or require the effort of collecting data at all target locations. We present LocaGen, a novel spatial augmentation framework that significantly reduces fingerprinting overhead by generating high-quality synthetic data at completely unseen locations. LocaGen leverages a conditional diffusion model guided by a novel spatially aware optimization strategy to synthesize realistic fingerprints at unseen locations using only a subset of seen locations. To further improve our diffusion model performance, LocaGen augments seen location data based on domain-specific heuristics and strategically selects the seen and unseen locations using a novel density-based approach that ensures robust coverage. Our extensive evaluation on a real-world WiFi fingerprinting dataset shows that LocaGen maintains the same localization accuracy even with 30% of the locations unseen and achieves up to 28% improvement in accuracy over state-of-the-art augmentation methods.

</details>


### [422] [Bringing Stability to Diffusion: Decomposing and Reducing Variance of Training Masked Diffusion Models](https://arxiv.org/abs/2511.18159)
*Mengni Jia,Mengyu Zhou,Yihao Liu,Xiaoxi Jiang,Guanjun Jiang*

Main category: cs.LG

TL;DR: 该论文首次理论分析了掩码扩散模型训练方差高的原因，并提出六种方差降低方法，显著提升了MDM在复杂推理任务上的性能表现。


<details>
  <summary>Details</summary>
Motivation: 掩码扩散模型相比自回归模型存在训练方差过高的问题，导致梯度估计噪声大、优化不稳定，即使预训练表现相当，任务特定训练后MDM性能会大幅落后于ARM，但目前缺乏理论解释和系统性解决方案。

Method: 1）理论分解MDM训练方差为三个来源：掩码模式噪声、掩码率噪声和数据噪声；2）设计六种方差降低方法，核心包括P-POTS（帕累托最优t采样器）和MIRROR（使用负相关样本减少掩码模式噪声）。

Result: 相比标准MDM训练，新方法在复杂推理任务上准确率提升7-8%，同时将运行间变异性降低到接近ARM水平，显著缩小了与强ARM基线的差距。

Conclusion: 该研究为MDM训练方差问题提供了首个理论解释和系统性解决方案，通过方差分解和针对性方法设计，有效解决了MDM训练不稳定的核心问题。

Abstract: Masked diffusion models (MDMs) are a promising alternative to autoregressive models (ARMs), but they suffer from inherently much higher training variance. High variance leads to noisier gradient estimates and unstable optimization, so even equally strong pretrained MDMs and ARMs that are competitive at initialization often diverge after task-specific training, with MDMs falling far behind. There has been no theoretical explanation or systematic solution. We derive the first decomposition of MDM training variance into three sources: (A) masking pattern noise, (B) masking rate noise, and (C) data noise, while ARMs are only affected by (C). This explains the fundamental training gap. Building on this foundation, we design six variance-reduction methods, including two core methods: (1) P-POTS, a Pareto-optimal t sampler that minimizes training variance by sampling harder t values more often with appropriately smaller update steps, and (2) MIRROR, which uses negatively correlated samples to reduce (A). Experiments show that compared to standard MDM training, our methods improve accuracy by 7-8% on complex reasoning tasks, while simultaneously reducing run-to-run variability to near ARM levels, substantially narrowing the gap with strong ARM baselines; in most settings, even the best baseline runs remain below the worst run of our method.

</details>


### [423] [Bayesian Calibration of Engine-out NOx Models for Engine-to-Engine Transferability](https://arxiv.org/abs/2511.18178)
*Shrenik Zinage,Peter Meckl,Ilias Bilionis*

Main category: cs.LG

TL;DR: 本文提出了一种贝叶斯校准框架，结合高斯过程和近似贝叶斯计算来推断和校正传感器偏差，以解决发动机间差异导致的NOx预测泛化问题。


<details>
  <summary>Details</summary>
Motivation: 传统NOx预测模型基于少量发动机数据训练，难以泛化到整个发动机群体，存在传感器偏差和输入条件变化的问题，需要频繁调校。

Method: 采用贝叶斯校准框架，结合高斯过程和近似贝叶斯计算，从预训练模型出发推断发动机特定传感器偏差并重新校准预测。

Result: 该方法在未见测试数据上生成发动机NOx的后验预测分布，相比传统非自适应GP模型显著提高了预测准确性。

Conclusion: 该可转移建模方法有效解决了发动机间变异性问题，提高了模型泛化能力，无需重新训练模型即可实现高精度预测。

Abstract: Accurate prediction of engine-out NOx is essential for meeting stringent emissions regulations and optimizing engine performance. Traditional approaches rely on models trained on data from a small number of engines, which can be insufficient in generalizing across an entire population of engines due to sensor biases and variations in input conditions. In real world applications, these models require tuning or calibration to maintain acceptable error tolerance when applied to other engines. This highlights the need for models that can adapt with minimal adjustments to accommodate engine-to-engine variability and sensor discrepancies. While previous studies have explored machine learning methods for predicting engine-out NOx, these approaches often fail to generalize reliably across different engines and operating environments. To address these issues, we propose a Bayesian calibration framework that combines Gaussian processes with approximate Bayesian computation to infer and correct sensor biases. Starting with a pre-trained model developed using nominal engine data, our method identifies engine specific sensor biases and recalibrates predictions accordingly. By incorporating these inferred biases, our approach generates posterior predictive distributions for engine-out NOx on unseen test data, achieving high accuracy without retraining the model. Our results demonstrate that this transferable modeling approach significantly improves the accuracy of predictions compared to conventional non-adaptive GP models, effectively addressing engine-to-engine variability and improving model generalizability.

</details>


### [424] [MOMA-AC: A preference-driven actor-critic framework for continuous multi-objective multi-agent reinforcement learning](https://arxiv.org/abs/2511.18181)
*Adam Callaghan,Karl Mason,Patrick Mannion*

Main category: cs.LG

TL;DR: 该论文提出了首个针对连续状态和动作空间的多目标多智能体强化学习框架MOMA-AC，基于TD3和DDPG算法开发了MOMA-TD3和MOMA-DDPG，通过多头actor网络、集中式critic和目标偏好条件架构实现了帕累托前沿学习。


<details>
  <summary>Details</summary>
Motivation: 解决多目标多智能体强化学习在连续状态和动作空间中的关键空白，现有方法主要针对单目标或单智能体场景，缺乏专门的内循环actor-critic框架。

Method: 基于单目标单智能体算法，构建包含多头actor网络、集中式critic和目标偏好条件架构的框架，结合TD3和DDPG算法实例化，并设计了连续MOMARL测试套件。

Result: 在协作运动任务评估中，相比外循环和独立训练基线，该框架在期望效用和超体积指标上取得显著改进，且随着智能体数量增加保持稳定可扩展性。

Conclusion: 该框架为连续多智能体领域的稳健、可扩展多目标策略学习奠定了重要基础，是MOMARL领域的重要进展。

Abstract: This paper addresses a critical gap in Multi-Objective Multi-Agent Reinforcement Learning (MOMARL) by introducing the first dedicated inner-loop actor-critic framework for continuous state and action spaces: Multi-Objective Multi-Agent Actor-Critic (MOMA-AC). Building on single-objective, single-agent algorithms, we instantiate this framework with Twin Delayed Deep Deterministic Policy Gradient (TD3) and Deep Deterministic Policy Gradient (DDPG), yielding MOMA-TD3 and MOMA-DDPG. The framework combines a multi-headed actor network, a centralised critic, and an objective preference-conditioning architecture, enabling a single neural network to encode the Pareto front of optimal trade-off policies for all agents across conflicting objectives in a continuous MOMARL setting. We also outline a natural test suite for continuous MOMARL by combining a pre-existing multi-agent single-objective physics simulator with its multi-objective single-agent counterpart. Evaluating cooperative locomotion tasks in this suite, we show that our framework achieves statistically significant improvements in expected utility and hypervolume relative to outer-loop and independent training baselines, while demonstrating stable scalability as the number of agents increases. These results establish our framework as a foundational step towards robust, scalable multi-objective policy learning in continuous multi-agent domains.

</details>


### [425] [Accelerating Time Series Foundation Models with Speculative Decoding](https://arxiv.org/abs/2511.18191)
*Pranav Subbaraman,Fang Sun,Yue Yao,Huacong Tang,Xiao Luo,Yizhou Sun*

Main category: cs.LG

TL;DR: 提出了一种基于推测解码的时间序列预测推理加速框架，通过小型草稿模型和大目标模型的并行验证，显著降低计算延迟，同时保持预测精度。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在时间序列预测中表现出色但计算成本高，难以部署在延迟敏感的Web应用中，需要高效的推理加速方案。

Method: 采用推测解码策略，使用小型草稿模型生成未来时间序列块，由大型目标模型并行验证，设计了多变量高斯块接受标准和实用变体来平衡效率与精度。

Result: 在Web应用相关的时间序列预测基准测试中，实现了显著的推理加速，同时保持了竞争力的预测精度。

Conclusion: 该框架无需修改现有基础模型架构，可立即应用于加速已部署的时间序列预测系统，为实时Web应用提供了可行的解决方案。

Abstract: Modern web applications--from real-time content recommendation and dynamic pricing to CDN optimization--increasingly rely on time-series forecasting to deliver personalized experiences to billions of users. Large-scale Transformer-based models have achieved state-of-the-art performance in time-series forecasting but suffer from high computational costs, limiting their deployment in latency-sensitive web applications. To address this challenge, we propose a general inference acceleration framework that adapts speculative decoding to autoregressive time-series models. Our approach employs a smaller "draft" model to propose future time-series patches, which are then verified in parallel by a larger "target" model, reducing the number of sequential forward passes required. We address key technical challenges in adapting this technique from discrete language tokens to continuous time-series distributions, including the design of acceptance criteria for multivariate Gaussian patches and practical variants that balance efficiency with accuracy. Through experiments on time series forecasting benchmarks relevant to web applications, we demonstrate significant inference speedups while maintaining competitive accuracy. The framework requires no architectural modifications to existing foundation models, making it immediately applicable to accelerate deployed time-series forecasting systems. Our implementation can be found at https://github.com/PranavSubbaraman/STRIDE

</details>


### [426] [Deep Gaussian Process Proximal Policy Optimization](https://arxiv.org/abs/2511.18214)
*Matthijs van der Lende,Juan Cardenas-Cartagena*

Main category: cs.LG

TL;DR: 本文提出了GPPO算法，将深度高斯过程与PPO结合，在保持竞争性能的同时提供校准良好的不确定性估计，以支持更安全的强化学习探索。


<details>
  <summary>Details</summary>
Motivation: 强化学习中的不确定性估计对于控制任务中平衡安全探索和高效学习至关重要，但深度神经网络往往缺乏校准的不确定性估计。

Method: 提出Deep Gaussian Process Proximal Policy Optimization (GPPO)，一种基于深度高斯过程的无模型actor-critic算法，用于近似策略和价值函数。

Result: GPPO在标准高维连续控制基准测试中与PPO保持竞争性能，同时提供校准良好的不确定性估计。

Conclusion: GPPO的不确定性估计可以为更安全有效的探索提供信息支持。

Abstract: Uncertainty estimation for Reinforcement Learning (RL) is a critical component in control tasks where agents must balance safe exploration and efficient learning. While deep neural networks have enabled breakthroughs in RL, they often lack calibrated uncertainty estimates. We introduce Deep Gaussian Process Proximal Policy Optimization (GPPO), a scalable, model-free actor-critic algorithm that leverages Deep Gaussian Processes (DGPs) to approximate both the policy and value function. GPPO maintains competitive performance with respect to Proximal Policy Optimization on standard high-dimensional continuous control benchmarks while providing well-calibrated uncertainty estimates that can inform safer and more effective exploration.

</details>


### [427] [Adaptive Conformal Prediction for Quantum Machine Learning](https://arxiv.org/abs/2511.18225)
*Douglas Spencer,Samual Nicholls,Michele Caprio*

Main category: cs.LG

TL;DR: 提出了自适应量子保形预测（AQCP）算法，解决量子处理器中时间变化噪声对保形预测保证的破坏问题，在任意硬件噪声条件下保持渐近平均覆盖保证。


<details>
  <summary>Details</summary>
Motivation: 量子机器学习中缺乏稳健的不确定性量化方法，现有量子保形预测在量子处理器时间变化噪声下无法保证预测有效性。

Method: 结合自适应保形推理（Adaptive Conformal Inference）方法，通过重复重新校准来维持时间有效性，提出自适应量子保形预测算法。

Result: 在IBM量子处理器上的实证研究表明，AQCP能够达到目标覆盖水平，比量子保形预测表现出更高的稳定性。

Conclusion: AQCP算法在量子硬件噪声环境下有效解决了保形预测的可靠性问题，为量子机器学习提供了稳健的不确定性量化框架。

Abstract: Quantum machine learning seeks to leverage quantum computers to improve upon classical machine learning algorithms. Currently, robust uncertainty quantification methods remain underdeveloped in the quantum domain, despite the critical need for reliable and trustworthy predictions. Recent work has introduced quantum conformal prediction, a framework that produces prediction sets that are guaranteed to contain the true outcome with user-specified probability. In this work, we formalise how the time-varying noise inherent in quantum processors can undermine conformal guarantees, even when calibration and test data are exchangeable. To address this challenge, we draw on Adaptive Conformal Inference, a method which maintains validity over time via repeated recalibration. We introduce Adaptive Quantum Conformal Prediction (AQCP), an algorithm which preserves asymptotic average coverage guarantees under arbitrary hardware noise conditions. Empirical studies on an IBM quantum processor demonstrate that AQCP achieves target coverage levels and exhibits greater stability than quantum conformal prediction.

</details>


### [428] [Tail Distribution of Regret in Optimistic Reinforcement Learning](https://arxiv.org/abs/2511.18247)
*Sajad Khodadadian,Mehrdad Moharrami*

Main category: cs.LG

TL;DR: 该论文推导了基于乐观策略的强化学习在有限时域表格马尔可夫决策过程中的实例相关遗憾尾界，分析了UCBVI类算法的遗憾分布特性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注期望遗憾或单一高概率分位数，缺乏对遗憾分布完整尾部特性的理解。本文旨在填补这一空白，提供更全面的遗憾尾部分析。

Method: 研究两种自然探索奖励方案：(i) 依赖于总回合数K的方案；(ii) 仅依赖于当前回合索引的K无关方案。通过调节参数α来平衡期望遗憾和子高斯尾部的范围。

Result: 获得了Pr(R_K ≥ x)的上界，显示出独特的双机制结构：从实例相关尺度m_K开始到过渡阈值的子高斯尾部，之后是子韦布尔尾部。同时推导了相应的期望遗憾实例相关界。

Conclusion: 这是首次为回合制强化学习中标准乐观算法提供全面尾部遗憾保证的研究之一，为理解算法性能分布提供了新的理论框架。

Abstract: We derive instance-dependent tail bounds for the regret of optimism-based reinforcement learning in finite-horizon tabular Markov decision processes with unknown transition dynamics. Focusing on a UCBVI-type algorithm, we characterize the tail distribution of the cumulative regret $R_K$ over $K$ episodes, rather than only its expectation or a single high-probability quantile. We analyze two natural exploration-bonus schedules: (i) a $K$-dependent scheme that explicitly incorporates the total number of episodes $K$, and (ii) a $K$-independent scheme that depends only on the current episode index. For both settings, we obtain an upper bound on $\Pr(R_K \ge x)$ that exhibits a distinctive two-regime structure: a sub-Gaussian tail starting from an instance-dependent scale $m_K$ up to a transition threshold, followed by a sub-Weibull tail beyond that point. We further derive corresponding instance-dependent bounds on the expected regret $\mathbb{E}[R_K]$. The proposed algorithm depends on a tuning parameter $α$, which balances the expected regret and the range over which the regret exhibits a sub-Gaussian tail. To the best of our knowledge, our results provide one of the first comprehensive tail-regret guarantees for a standard optimistic algorithm in episodic reinforcement learning.

</details>


### [429] [Coherent Multi-Agent Trajectory Forecasting in Team Sports with CausalTraj](https://arxiv.org/abs/2511.18248)
*Wei Zhen Teoh*

Main category: cs.LG

TL;DR: CausalTraj是一个基于时间因果关系的概率模型，专门用于生成联合概率的多智能体轨迹预测，在联合评估指标上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有模型主要基于单智能体精度指标（minADE、minFDE）进行评估，这些指标忽略了模型是否能够生成联合合理的多智能体未来轨迹，导致在团队运动等场景中无法生成连贯、可解释的多智能体场景。

Method: 提出了CausalTraj模型，这是一个时间因果的、基于似然的模型，专门设计用于生成联合概率的多智能体轨迹预测。

Result: 在NBA SportVU、Basketball-U和Football-U数据集上的评估显示，CausalTraj在单智能体精度指标上具有竞争力，并在联合指标（minJADE、minJFDE）上取得了最佳记录结果，同时产生了定性上连贯和真实的游戏演化。

Conclusion: CausalTraj模型通过强调联合评估指标，能够更好地评估集体建模能力，生成连贯且现实的多智能体轨迹预测。

Abstract: Jointly forecasting trajectories of multiple interacting agents is a core challenge in sports analytics and other domains involving complex group dynamics. Accurate prediction enables realistic simulation and strategic understanding of gameplay evolution. Most existing models are evaluated solely on per-agent accuracy metrics (minADE, minFDE), which assess each agent independently on its best-of-k prediction. However these metrics overlook whether the model learns which predicted trajectories can jointly form a plausible multi-agent future. Many state-of-the-art models are designed and optimized primarily based on these metrics. As a result, they may underperform on joint predictions and also fail to generate coherent, interpretable multi-agent scenarios in team sports. We propose CausalTraj, a temporally causal, likelihood-based model that is built to generate jointly probable multi-agent trajectory forecasts. To better assess collective modeling capability, we emphasize joint metrics (minJADE, minJFDE) that measure joint accuracy across agents within the best generated scenario sample. Evaluated on the NBA SportVU, Basketball-U, and Football-U datasets, CausalTraj achieves competitive per-agent accuracy and the best recorded results on joint metrics, while yielding qualitatively coherent and realistic gameplay evolutions.

</details>


### [430] [Reduced-Basis Deep Operator Learning for Parametric PDEs with Independently Varying Boundary and Source Data](https://arxiv.org/abs/2511.18260)
*Yueqi Wang,Guang Lin*

Main category: cs.LG

TL;DR: RB-DeepONet是一种融合了降基（RB）数值结构和DeepONet分支-主干架构的混合算子学习框架，通过固定主干为严格构造的RB空间，实现了物理可解释性、稳定性和认证误差控制，在保持精度的同时显著减少可训练参数并实现加速。


<details>
  <summary>Details</summary>
Motivation: 现有算子学习方法依赖不透明学习主干、需要大量标注数据，或在边界和源数据与物理参数独立变化时失效。

Method: 将主干固定为通过Greedy选择离线生成的RB空间，分支网络仅预测RB系数，使用投影变分残差进行无标签训练。对于独立变化的边界条件，开发边界和源模态编码将外部数据压缩为低维坐标。

Result: RB-DeepONet在精度上与侵入式RB-Galerkin、POD-DeepONet和FEONet竞争，同时使用显著更少的可训练参数并实现显著加速。

Conclusion: RB-DeepONet为大规模参数化PDE提供了一种高效、稳定且可解释的算子学习方法。

Abstract: Parametric PDEs power modern simulation, design, and digital-twin systems, yet their many-query workloads still hinge on repeatedly solving large finite-element systems. Existing operator-learning approaches accelerate this process but often rely on opaque learned trunks, require extensive labeled data, or break down when boundary and source data vary independently from physical parameters. We introduce RB-DeepONet, a hybrid operator-learning framework that fuses reduced-basis (RB) numerical structure with the branch-trunk architecture of DeepONet. The trunk is fixed to a rigorously constructed RB space generated offline via Greedy selection, granting physical interpretability, stability, and certified error control. The branch network predicts only RB coefficients and is trained label-free using a projected variational residual that targets the RB-Galerkin solution. For problems with independently varying loads or boundary conditions, we develop boundary and source modal encodings that compress exogenous data into low-dimensional coordinates while preserving accuracy. Combined with affine or empirical interpolation decompositions, RB-DeepONet achieves a strict offline-online split: all heavy lifting occurs offline, and online evaluation scales only with the RB dimension rather than the full mesh. We provide convergence guarantees separating RB approximation error from statistical learning error, and numerical experiments show that RB-DeepONet attains accuracy competitive with intrusive RB-Galerkin, POD-DeepONet, and FEONet while using dramatically fewer trainable parameters and achieving significant speedups. This establishes RB-DeepONet as an efficient, stable, and interpretable operator learner for large-scale parametric PDEs.

</details>


### [431] [A Fair OR-ML Framework for Resource Substitution in Large-Scale Networks](https://arxiv.org/abs/2511.18269)
*Ved Mohan,El Mehdi Er Raqabi,Pascal Van Hentenryck*

Main category: cs.LG

TL;DR: 该论文提出了一个结合运筹学和机器学习的通用框架，用于解决大规模物流网络中的资源替代问题，通过公平性建模和智能决策空间探索，在保持最优性的同时显著提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 大规模物流网络中资源分配不平衡的挑战，特别是在需求模式不均匀和资源流动不对称的情况下，需要成本有效的资源替代方案来缓解网络节点的不平衡问题。

Method: 结合运筹学（OR）和机器学习（ML）的混合框架：OR组件负责在公平性视角下建模和解决资源替代问题；ML组件利用历史数据学习调度员偏好，智能探索决策空间，并通过动态选择网络中每条弧的前k个资源来提升计算效率。

Result: 在全球最大包裹递送公司之一的网络中应用该框架，计算结果显示相比现有最优方法有显著改进：模型规模减少80%，执行时间降低90%，同时保持最优性。

Conclusion: 该框架能够生成高质量解决方案组合，调度员可以从中选择满意的权衡方案，为解决大规模物流网络中的资源替代问题提供了有效的解决方案。

Abstract: Ensuring that the right resource is available at the right location and time remains a major challenge for organizations operating large-scale logistics networks. The challenge comes from uneven demand patterns and the resulting asymmetric flow of resources across the arcs, which create persistent imbalances at the network nodes. Resource substitution among multiple, potentially composite and interchangeable, resource types is a cost-effective way to mitigate these imbalances. This leads to the resource substitution problem, which aims at determining the minimum number of resource substitutions from an initial assignment to minimize the overall network imbalance. In decentralized settings, achieving globally coordinated solutions becomes even more difficult. When substitution entails costs, effective prescriptions must also incorporate fairness and account for the individual preferences of schedulers. This paper presents a generic framework that combines operations research (OR) and machine learning (ML) to enable fair resource substitution in large networks. The OR component models and solves the resource substitution problem under a fairness lens. The ML component leverages historical data to learn schedulers' preferences, guide intelligent exploration of the decision space, and enhance computational efficiency by dynamically selecting the top-$κ$ resources for each arc in the network. The framework produces a portfolio of high-quality solutions from which schedulers can select satisfactory trade-offs. The proposed framework is applied to the network of one of the largest package delivery companies in the world, which serves as the primary motivation for this research. Computational results demonstrate substantial improvements over state-of-the-art methods, including an 80% reduction in model size and a 90% decrease in execution time while preserving optimality.

</details>


### [432] [From Tables to Signals: Revealing Spectral Adaptivity in TabPFN](https://arxiv.org/abs/2511.18278)
*Jianqiao Zheng,Cameron Gordon,Yiping Ji,Hemanth Saratchandran,Simon Lucey*

Main category: cs.LG

TL;DR: 本文通过信号重构的视角分析了TabPFN的频率特性，发现其具有比标准MLP更广的有效频率容量，且频谱容量能够根据上下文样本数量自适应调整，这种频谱自适应特性使其能够实现无需训练的超参数自由图像去噪。


<details>
  <summary>Details</summary>
Motivation: 理解任务无关的表格基础模型（如TabPFN）的归纳偏置来源，特别是其在上下文学习中的频率特性。

Method: 通过信号重构和频率分析的方法研究TabPFN，分析其频谱容量、位置编码对频率响应的影响，并与标准ReLU-MLP进行比较。

Result: TabPFN具有比标准MLP更广的有效频率容量；其频谱容量能够根据上下文样本数量自适应调整；位置编码能够调制频率响应；能够实现无需训练的超参数自由图像去噪。

Conclusion: TabPFN的频谱自适应特性使其在信号重构任务中具有潜力，为表格基础模型的结构和归纳偏置提供了新的见解。

Abstract: Task-agnostic tabular foundation models such as TabPFN have achieved impressive performance on tabular learning tasks, yet the origins of their inductive biases remain poorly understood. In this work, we study TabPFN through the lens of signal reconstruction and provide the first frequency-based analysis of its in-context learning behavior. We show that TabPFN possesses a broader effective frequency capacity than standard ReLU-MLPs, even without hyperparameter tuning. Moreover, unlike MLPs whose spectra evolve primarily over training epochs, we find that TabPFN's spectral capacity adapts directly to the number of samples provided in-context, a phenomenon we term Spectral Adaptivity. We further demonstrate that positional encoding modulates TabPFN's frequency response, mirroring classical results in implicit neural representations. Finally, we show that these properties enable TabPFN to perform training-free and hyperparameter-free image denoising, illustrating its potential as a task-agnostic implicit model. Our analysis provides new insight into the structure and inductive biases of tabular foundation models and highlights their promise for broader signal reconstruction tasks.

</details>


### [433] [TRIDENT: A Trimodal Cascade Generative Framework for Drug and RNA-Conditioned Cellular Morphology Synthesis](https://arxiv.org/abs/2511.18287)
*Rui Peng,Ziru Liu,Lingyuan Ye,Yuxing Lu,Boxin Shi,Jinzhuo Wang*

Main category: cs.LG

TL;DR: TRIDENT是一个级联生成框架，通过同时考虑扰动和相应的基因表达谱来合成真实的细胞形态，显著优于现有方法，在未见化合物上具有强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常局限于建模直接关联（如扰动→RNA或扰动→形态），而忽略了RNA到形态的关键因果联系。为了填补这一空白，需要构建一个能够显式建模转录组-表型映射的AI虚拟细胞工具。

Method: 提出TRIDENT级联生成框架，在扰动和基因表达谱的条件下合成细胞形态。构建MorphoGene数据集，包含98种化合物的L1000基因表达与Cell Painting图像配对数据。

Result: TRIDENT显著优于最先进方法，实现了高达7倍的改进，对未见化合物具有强泛化能力。在多西他赛案例研究中验证了RNA引导合成能准确产生相应表型。消融研究证实RNA条件化对模型高保真度至关重要。

Conclusion: 通过显式建模转录组-表型映射，TRIDENT提供了一个强大的计算机模拟工具，使我们更接近预测性虚拟细胞的目标。

Abstract: Accurately modeling the relationship between perturbations, transcriptional responses, and phenotypic changes is essential for building an AI Virtual Cell (AIVC). However, existing methods typically constrained to modeling direct associations, such as Perturbation $\rightarrow$ RNA or Perturbation $\rightarrow$ Morphology, overlook the crucial causal link from RNA to morphology. To bridge this gap, we propose TRIDENT, a cascade generative framework that synthesizes realistic cellular morphology by conditioning on both the perturbation and the corresponding gene expression profile. To train and evaluate this task, we construct MorphoGene, a new dataset pairing L1000 gene expression with Cell Painting images for 98 compounds. TRIDENT significantly outperforms state-of-the-art approaches, achieving up to 7-fold improvement with strong generalization to unseen compounds. In a case study on docetaxel, we validate that RNA-guided synthesis accurately produces the corresponding phenotype. An ablation study further confirms that this RNA conditioning is essential for the model's high fidelity. By explicitly modeling transcriptome-phenome mapping, TRIDENT provides a powerful in silico tool and moves us closer to a predictive virtual cell.

</details>


### [434] [ADF-LoRA: Alternating Low-Rank Aggregation for Decentralized Federated Fine-Tuning](https://arxiv.org/abs/2511.18291)
*Xiaoyu Wang,Xiaotian Li,Zhixiang Zhou,Chen Li,Yong Liu*

Main category: cs.LG

TL;DR: 本文提出了ADF-LoRA方法，通过在去中心化联邦学习中同步更新单个低秩矩阵并混合两个矩阵，解决了交替更新在点对点通信中的相位状态不匹配和块间发散问题。


<details>
  <summary>Details</summary>
Motivation: 传统交替更新LoRA矩阵的方法在集中式联邦学习中表现稳定，但在去中心化的点对点通信中面临相位状态不匹配和客户端间块级发散的新挑战。

Method: ADF-LoRA每轮仅同步更新一个低秩矩阵，并通过混合两个矩阵来保持参数状态的一致性，同时保留交替更新的交叉项抑制效果。

Result: 在多个GLUE任务上的实验表明，ADF-LoRA实现了更快更平滑的收敛，并在去中心化联邦学习中以稳定优势超越现有LoRA变体。

Conclusion: ADF-LoRA有效解决了去中心化联邦学习中交替更新的稳定性问题，在保持收敛性能的同时提升了训练稳定性。

Abstract: This paper revisits alternating low-rank updates for federated fine-tuning and examines their behavior in decentralized federated learning (DFL). While alternating the LoRA matrices has been shown to stabilize aggregation in centralized FL, extending this mechanism to decentralized, peer-to-peer communication introduces new challenges due to phase-state mismatch and block-wise divergence across clients. We introduce ADF-LoRA, which synchronizes the update of only one low-rank matrix per round and mixes both matrices to maintain more consistent parameter states under decentralized propagation. This design preserves the cross-term suppression effect of alternating updates while improving stability in serverless topologies. We provide a convergence analysis under standard smoothness assumptions and evaluate ADF-LoRA on multiple GLUE tasks. Experiments show that ADF-LoRA achieves faster and smoother convergence and delivers the highest average accuracy across tasks, outperforming existing LoRA variants in decentralized FL by a consistent margin.

</details>


### [435] [MultiDiffNet: A Multi-Objective Diffusion Framework for Generalizable Brain Decoding](https://arxiv.org/abs/2511.18294)
*Mengchun Zhang,Kateryna Shapovalenko,Yucheng Shao,Eddie Guo,Parusha Pradhan*

Main category: cs.LG

TL;DR: MultiDiffNet是一个基于扩散模型的框架，通过在优化多目标的紧凑潜在空间中进行解码，实现了跨被试的脑电信号解码，并在多个任务上达到最先进的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 当前脑电信号解码方法受限于被试间的高变异性以及缺乏大规模数据集，导致对未见被试的泛化能力差。现有方法依赖合成被试生成或简单数据增强，但无法有效扩展或可靠泛化。

Method: 提出MultiDiffNet框架，绕过生成式增强，学习一个针对多目标优化的紧凑潜在空间，并直接从该空间进行解码。同时构建了统一的基准测试套件和针对低试次脑电设置的统计报告框架。

Result: 在四个复杂度递增的脑电解码任务（SSVEP、运动想象、P300和想象语音）上，通过被试和会话分离评估，实现了最先进的跨被试泛化性能。

Conclusion: 该工作为现实世界脑机接口系统中的被试无关脑电解码提供了可复现和开源的基础。

Abstract: Neural decoding from electroencephalography (EEG) remains fundamentally limited by poor generalization to unseen subjects, driven by high inter-subject variability and the lack of large-scale datasets to model it effectively. Existing methods often rely on synthetic subject generation or simplistic data augmentation, but these strategies fail to scale or generalize reliably. We introduce \textit{MultiDiffNet}, a diffusion-based framework that bypasses generative augmentation entirely by learning a compact latent space optimized for multiple objectives. We decode directly from this space and achieve state-of-the-art generalization across various neural decoding tasks using subject and session disjoint evaluation. We also curate and release a unified benchmark suite spanning four EEG decoding tasks of increasing complexity (SSVEP, Motor Imagery, P300, and Imagined Speech) and an evaluation protocol that addresses inconsistent split practices in prior EEG research. Finally, we develop a statistical reporting framework tailored for low-trial EEG settings. Our work provides a reproducible and open-source foundation for subject-agnostic EEG decoding in real-world BCI systems.

</details>


### [436] [GROOT: Graph Edge Re-growth and Partitioning for the Verification of Large Designs in Logic Synthesis](https://arxiv.org/abs/2511.18297)
*Kiran Thorat,Hongwu Peng,Yuebo Luo,Xi Xie,Shaoyi Huang,Amit Hasan,Jiahui Zhao,Yingjie Li,Zhijie Shi,Cunxi Yu,Caiwen Ding*

Main category: cs.LG

TL;DR: GROOT是一个算法与系统协同设计的框架，通过结合芯片设计领域知识、图神经网络和GPU内核优化，显著提高了芯片验证效率。


<details>
  <summary>Details</summary>
Motivation: 传统芯片验证方法耗时且计算量大，现有GNN方法缺乏整合芯片设计领域知识、图理论和GPU内核设计的联合框架。

Method: 利用电路节点类型和连接极性创建节点特征，采用图分割算法将大图划分为小图进行GPU处理，开发图边重生长算法恢复验证精度，并针对EDA图工作负载特性重新设计HD-kernel和LD-kernel两个GPU内核。

Result: GROOT在1,024位CSA乘法器（1.34亿节点，2.68亿边）上实现了59.38%的内存占用减少和99.96%的高精度，相比cuSPARSE、MergePath-SpMM和GNNAdvisor分别实现了1.104倍、5.796倍和1.469倍的运行时间改进。

Conclusion: GROOT通过领域知识整合和GPU内核优化，为大规模芯片验证提供了高效且准确的解决方案。

Abstract: Traditional verification methods in chip design are highly time-consuming and computationally demanding, especially for large scale circuits. Graph neural networks (GNNs) have gained popularity as a potential solution to improve verification efficiency. However, there lacks a joint framework that considers all chip design domain knowledge, graph theory, and GPU kernel designs. To address this challenge, we introduce GROOT, an algorithm and system co-design framework that contains chip design domain knowledge and redesigned GPU kernels, to improve verification efficiency. More specifically, we create node features utilizing the circuit node types and the polarity of the connections between the input edges to nodes in And-Inverter Graphs (AIGs). We utilize a graph partitioning algorithm to divide the large graphs into smaller sub-graphs for fast GPU processing and develop a graph edge re-growth algorithm to recover verification accuracy. We carefully profile the EDA graph workloads and observe the uniqueness of their polarized distribution of high degree (HD) nodes and low degree (LD) nodes. We redesign two GPU kernels (HD-kernel and LD-kernel), to fit the EDA graph learning workload on a single GPU. We compare the results with state-of-the-art (SOTA) methods: GAMORA, a GNN-based approach, and the traditional ABC framework. Results show that GROOT achieves a significant reduction in memory footprint (59.38 %), with high accuracy (99.96%) for a very large CSA multiplier, i.e. 1,024 bits with a batch size of 16, which consists of 134,103,040 nodes and 268,140,544 edges. We compare GROOT with GPU-based GPU Kernel designs SOTAs such as cuSPARSE, MergePath-SpMM, and GNNAdvisor. We achieve up to 1.104x, 5.796x, and 1.469x improvement in runtime, respectively.

</details>


### [437] [Hierarchical Deep Research with Local-Web RAG: Toward Automated System-Level Materials Discovery](https://arxiv.org/abs/2511.18303)
*Rui Ding,Rodrigo Pires Ferreira,Yuxin Chen,Junhong Chen*

Main category: cs.LG

TL;DR: 本文提出了一种用于复杂材料和设备发现的分层深度研究代理，通过本地可部署的DR实例结合检索增强生成和LLM推理器，采用深度研究树机制自适应扩展和修剪研究分支，在27个纳米材料/设备主题上评估显示其报告质量与商业系统相当甚至更好，且成本更低。


<details>
  <summary>Details</summary>
Motivation: 解决现有机器学习代理和闭源商业代理无法处理的复杂材料和设备发现问题，提供本地可部署的解决方案。

Method: 分层深度研究框架，集成本地检索增强生成与大型语言模型推理器，采用深度研究树机制自适应管理研究分支。

Result: 在27个主题上评估显示报告质量与商业系统相当或更好，干实验验证表明DR代理的提案具有可操作性，成本显著低于商业系统。

Conclusion: 该DR代理为复杂材料发现提供了高质量、低成本且可本地集成的解决方案，优于现有商业系统。

Abstract: We present a long-horizon, hierarchical deep research (DR) agent designed for complex materials and device discovery problems that exceed the scope of existing Machine Learning (ML) surrogates and closed-source commercial agents. Our framework instantiates a locally deployable DR instance that integrates local retrieval-augmented generation with large language model reasoners, enhanced by a Deep Tree of Research (DToR) mechanism that adaptively expands and prunes research branches to maximize coverage, depth, and coherence. We systematically evaluate across 27 nanomaterials/device topics using a large language model (LLM)-as-judge rubric with five web-enabled state-of-the-art models as jurors. In addition, we conduct dry-lab validations on five representative tasks, where human experts use domain simulations (e.g., density functional theory, DFT) to verify whether DR-agent proposals are actionable. Results show that our DR agent produces reports with quality comparable to--and often exceeding--those of commercial systems (ChatGPT-5-thinking/o3/o4-mini-high Deep Research) at a substantially lower cost, while enabling on-prem integration with local data and tools.

</details>


### [438] [DiM-TS: Bridge the Gap between Selective State Space Models and Time Series for Generative Modeling](https://arxiv.org/abs/2511.18312)
*Zihao Yao,Jiankai Zuo,Yaying Zhang*

Main category: cs.LG

TL;DR: 本文提出DiM-TS，一种基于Mamba状态空间模型的扩散模型，用于生成高质量时间序列数据，解决了现有方法在捕获长期时间依赖和复杂通道关系方面的不足。


<details>
  <summary>Details</summary>
Motivation: 时间序列数据面临隐私问题，扩散模型是潜在解决方案，但现有方法难以捕捉长期时间依赖和复杂通道相互关系。

Method: 提出Lag Fusion Mamba和Permutation Scanning Mamba两种变体，增强模型在去噪过程中识别重要模式的能力，并整合为DiM-TS模型。

Result: 在公开数据集上的实验表明，DiM-TS能生成更真实的时间序列，更好地保持数据的时间周期性和通道间相关性。

Conclusion: DiM-TS在时间序列生成方面具有优越性，能够有效保留数据的多样特性。

Abstract: Time series data plays a pivotal role in a wide variety of fields but faces challenges related to privacy concerns. Recently, synthesizing data via diffusion models is viewed as a promising solution. However, existing methods still struggle to capture long-range temporal dependencies and complex channel interrelations. In this research, we aim to utilize the sequence modeling capability of a State Space Model called Mamba to extend its applicability to time series data generation. We firstly analyze the core limitations in State Space Model, namely the lack of consideration for correlated temporal lag and channel permutation. Building upon the insight, we propose Lag Fusion Mamba and Permutation Scanning Mamba, which enhance the model's ability to discern significant patterns during the denoising process. Theoretical analysis reveals that both variants exhibit a unified matrix multiplication framework with the original Mamba, offering a deeper understanding of our method. Finally, we integrate two variants and introduce Diffusion Mamba for Time Series (DiM-TS), a high-quality time series generation model that better preserves the temporal periodicity and inter-channel correlations. Comprehensive experiments on public datasets demonstrate the superiority of DiM-TS in generating realistic time series while preserving diverse properties of data.

</details>


### [439] [AnyExperts: On-Demand Expert Allocation for Multimodal Language Models with Mixture of Expert](https://arxiv.org/abs/2511.18314)
*Yuting Gao,Wang Lan,Hengyuan Zhao,Linjiang Huang,Si Liu,Qingpei Guo*

Main category: cs.LG

TL;DR: AnyExperts提出了一种按需、预算感知的动态路由框架，通过根据token的语义重要性分配可变数量的专家槽位，优化多模态MoE模型的计算分配效率。


<details>
  <summary>Details</summary>
Motivation: 现有多模态MoE模型采用固定的专家激活策略，忽略了不同模态间语义重要性的异质性，导致计算资源分配不优，冗余token与关键token消耗相同资源。

Method: AnyExperts框架为每个token分配可变总数的专家槽位，槽位总数限制在固定范围内，每个槽位由真实专家或虚拟专家填充（虚拟专家占比上限为20%）。模型根据语义重要性自适应平衡真实与虚拟专家比例，对语义丰富区域分配更多真实专家，对冗余内容更多依赖虚拟专家。

Result: 在视觉理解、音频理解和NLP理解等多样化任务上，AnyExperts在相同计算预算下提升了性能。在通用图像/视频任务上，使用40%更少的真实专家激活达到可比精度；在文本密集任务（OCR和NLP）上，保持性能同时减少10%的真实专家使用。

Conclusion: 细粒度的、重要性驱动的专家分配显著提升了多模态MoE模型的效率和有效性。

Abstract: Multimodal Mixture-of-Experts (MoE) models offer a promising path toward scalable and efficient large vision-language systems. However, existing approaches rely on rigid routing strategies (typically activating a fixed number of experts per token) ignoring the inherent heterogeneity in semantic importance across modalities. This leads to suboptimal compute allocation, where redundant tokens consume as many resources as critical ones. To address this, we propose AnyExperts, a novel on-demand, budget-aware dynamic routing framework that allocates a variable total number of expert slots per token based on its semantic importance. Crucially, to prevent uncontrolled compute growth, the total slots per token are constrained within a fixed range, and each slot is filled by either a real expert or a virtual expert, with the virtual share capped at a small maximum (e.g., 20%). The model then adaptively balances the real-to-virtual ratio per token, assigning more real experts to semantically rich regions and relying more on virtual experts for redundant content. Evaluated across diverse tasks in visual understanding, audio understanding, and NLP understanding, AnyExperts improves performance under the same compute budget. Notably, on general image/video tasks, it achieves comparable accuracy with 40% fewer real expert activations; on text-dense tasks (OCR and NLP), it maintains performance while reducing real expert usage by 10%. These results demonstrate that fine-grained, importance-driven expert allocation significantly enhances both the efficiency and effectiveness of multimodal MoE models.

</details>


### [440] [DynamiX: Dynamic Resource eXploration for Personalized Ad-Recommendations](https://arxiv.org/abs/2511.18331)
*Sohini Roychowdhury,Adam Holeman,Mohammad Amin,Feng Wei,Bhaskar Mehta,Srihari Reddy*

Main category: cs.LG

TL;DR: Dynamix是一个可扩展的个性化序列探索框架，通过最大相关性原则和基于事件特征的自监督学习，优化在线广告推荐系统中用户-广告参与历史处理，在保持准确性的同时提高训练和推理效率。


<details>
  <summary>Details</summary>
Motivation: 在线广告推荐系统处理完整的用户-广告参与历史既计算密集又容易受到噪声干扰，需要一种更高效的处理方法。

Method: 使用最大相关性原则和基于事件特征的自监督学习，在会话和表面级别对用户参与进行分类，通过动态特征移除和选择性特征增强来优化处理效率。

Result: 动态资源移除使训练和推理吞吐量分别提高1.15%和1.8%，动态特征增强在基线模型基础上提供0.033 NE增益，同时推理QPS提升4.2%。

Conclusion: Dynamix在基于在线用户序列的推荐模型中实现了显著的成本效率和性能改进，自监督用户分割和资源探索可以进一步优化复杂特征选择策略。

Abstract: For online ad-recommendation systems, processing complete user-ad-engagement histories is both computationally intensive and noise-prone. We introduce Dynamix, a scalable, personalized sequence exploration framework that optimizes event history processing using maximum relevance principles and self-supervised learning through Event Based Features (EBFs). Dynamix categorizes users-engagements at session and surface-levels by leveraging correlations between dwell-times and ad-conversion events. This enables targeted, event-level feature removal and selective feature boosting for certain user-segments, thereby yielding training and inference efficiency wins without sacrificing engaging ad-prediction accuracy. While, dynamic resource removal increases training and inference throughput by 1.15% and 1.8%, respectively, dynamic feature boosting provides 0.033 NE gains while boosting inference QPS by 4.2% over baseline models. These results demonstrate that Dynamix achieves significant cost efficiency and performance improvements in online user-sequence based recommendation models. Self-supervised user-segmentation and resource exploration can further boost complex feature selection strategies while optimizing for workflow and compute resources.

</details>


### [441] [Clinician-in-the-Loop Smart Home System to Detect Urinary Tract Infection Flare-Ups via Uncertainty-Aware Decision Support](https://arxiv.org/abs/2511.18334)
*Chibuike E. Ugwu,Roschelle Fritz,Diane J. Cook,Janardhan Rao Doppa*

Main category: cs.LG

TL;DR: 本文提出了一种结合临床医生在环的智能家居系统，利用环境传感器数据提取行为标记，训练稳健的预测模型，并通过CCI方法进行不确定性量化，以支持UTI早期检测的临床决策。


<details>
  <summary>Details</summary>
Motivation: 老年人UTI发作风险高且常被忽视，传统机器学习方法缺乏不确定性洞察，限制了临床决策支持。

Method: 开发了临床医生在环的智能家居系统，采用CCI不确定性量化方法，在模型置信度低时放弃预测。

Result: 在8个真实智能家居数据上评估，该方法在召回率等指标上优于基线方法，且保持了最低的放弃比例和区间宽度。

Conclusion: 42名护士的调查证实该系统输出对临床决策有指导价值，可有效改善老年人UTI等病症发作的管理。

Abstract: Urinary tract infection (UTI) flare-ups pose a significant health risk for older adults with chronic conditions. These infections often go unnoticed until they become severe, making early detection through innovative smart home technologies crucial. Traditional machine learning (ML) approaches relying on simple binary classification for UTI detection offer limited utility to nurses and practitioners as they lack insight into prediction uncertainty, hindering informed clinical decision-making. This paper presents a clinician-in-the-loop (CIL) smart home system that leverages ambient sensor data to extract meaningful behavioral markers, train robust predictive ML models, and calibrate them to enable uncertainty-aware decision support. The system incorporates a statistically valid uncertainty quantification method called Conformal-Calibrated Interval (CCI), which quantifies uncertainty and abstains from making predictions ("I don't know") when the ML model's confidence is low. Evaluated on real-world data from eight smart homes, our method outperforms baseline methods in recall and other classification metrics while maintaining the lowest abstention proportion and interval width. A survey of 42 nurses confirms that our system's outputs are valuable for guiding clinical decision-making, underscoring their practical utility in improving informed decisions and effectively managing UTIs and other condition flare-ups in older adults.

</details>


### [442] [Auxiliary Gene Learning: Spatial Gene Expression Estimation by Auxiliary Gene Selection](https://arxiv.org/abs/2511.18336)
*Kaito Shiku,Kazuya Nishimura,Shinnosuke Matsuo,Yasuhiro Kojima,Ryoma Bise*

Main category: cs.LG

TL;DR: 本文提出Auxiliary Gene Learning (AGL)方法，通过将低表达基因的表达估计作为辅助任务与主要任务联合训练，利用被忽略基因的潜在价值。为解决基因选择难题，提出基于先验知识的可微分top-k基因选择方法DkGSB。


<details>
  <summary>Details</summary>
Motivation: 空间转录组学技术存在观测噪声，现有研究仅使用高变异基因子集进行训练评估，忽略了低表达基因可能通过共表达关系对目标基因估计的贡献。

Method: 1. 提出AGL框架，将低表达基因作为辅助任务与主要任务联合训练；2. 开发DkGSB方法，利用先验知识对基因排序，将组合选择问题转化为可微分top-k选择问题。

Result: 实验证实了整合辅助基因的有效性，所提方法优于传统辅助任务学习方法。

Conclusion: 通过合理选择辅助基因并采用联合训练策略，可以有效利用低表达基因信息提升空间转录组学数据分析性能。

Abstract: Spatial transcriptomics (ST) is a novel technology that enables the observation of gene expression at the resolution of individual spots within pathological tissues. ST quantifies the expression of tens of thousands of genes in a tissue section; however, heavy observational noise is often introduced during measurement. In prior studies, to ensure meaningful assessment, both training and evaluation have been restricted to only a small subset of highly variable genes, and genes outside this subset have also been excluded from the training process. However, since there are likely co-expression relationships between genes, low-expression genes may still contribute to the estimation of the evaluation target. In this paper, we propose $Auxiliary \ Gene \ Learning$ (AGL) that utilizes the benefit of the ignored genes by reformulating their expression estimation as auxiliary tasks and training them jointly with the primary tasks. To effectively leverage auxiliary genes, we must select a subset of auxiliary genes that positively influence the prediction of the target genes. However, this is a challenging optimization problem due to the vast number of possible combinations. To overcome this challenge, we propose Prior-Knowledge-Based Differentiable Top-$k$ Gene Selection via Bi-level Optimization (DkGSB), a method that ranks genes by leveraging prior knowledge and relaxes the combinatorial selection problem into a differentiable top-$k$ selection problem. The experiments confirm the effectiveness of incorporating auxiliary genes and show that the proposed method outperforms conventional auxiliary task learning approaches.

</details>


### [443] [Future Is Unevenly Distributed: Forecasting Ability of LLMs Depends on What We're Asking](https://arxiv.org/abs/2511.18394)
*Chinmay Karkar,Paras Chopra*

Main category: cs.LG

TL;DR: LLMs在预测社会、政治和经济事件方面表现出部分能力，但其预测性能因领域结构和提示框架而有显著差异。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在真实世界事件预测中的表现，特别是针对模型截止日期之后发生的事件，探究不同因素如何影响预测准确性和校准。

Method: 分析不同模型家族在真实世界问题上的表现，考察上下文、问题类型和外部知识对准确性和校准的影响，以及添加事实新闻背景如何改变信念形成和失败模式。

Result: 预测能力高度可变，取决于提问的内容和方式。

Conclusion: LLMs的预测能力具有情境依赖性，需要针对具体应用场景进行优化。

Abstract: Large Language Models (LLMs) demonstrate partial forecasting competence across social, political, and economic events. Yet, their predictive ability varies sharply with domain structure and prompt framing. We investigate how forecasting performance varies with different model families on real-world questions about events that happened beyond the model cutoff date. We analyze how context, question type, and external knowledge affect accuracy and calibration, and how adding factual news context modifies belief formation and failure modes. Our results show that forecasting ability is highly variable as it depends on what, and how, we ask.

</details>


### [444] [Pre-training Graph Neural Networks on 2D and 3D Molecular Structures by using Multi-View Conditional Information Bottleneck](https://arxiv.org/abs/2511.18404)
*Van Thuy Hoang,O-Joun Lee*

Main category: cs.LG

TL;DR: MVCIB是一个多视图条件信息瓶颈框架，用于在2D和3D分子结构上自监督预训练图神经网络，通过子结构对齐和交叉注意力机制解决多视图分子学习中的共享信息发现和重要子结构对齐问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在解决多视图分子学习中的两个主要挑战方面存在局限：(1)发现两个视图之间的共享信息同时减少视图特定信息；(2)识别和对齐重要子结构（如功能基团），这对增强跨视图一致性和模型表达能力至关重要。

Method: 提出MVCIB框架，在MVCIB原则下发现共享信息同时最小化每个视图的无关特征，使用一个视图作为上下文条件来指导其对应视图的表示学习。利用关键子结构作为视图间的锚点，提出交叉注意力机制捕获子结构间的细粒度相关性以实现跨视图子图对齐。

Result: 在四个分子领域的广泛实验表明，MVCIB在预测性能和可解释性方面均优于基线方法。MVCIB达到了3D Weisfeiler-Lehman表达能力，能够区分不仅非同构图，还能区分具有相同2D连接性的不同3D几何结构（如异构体）。

Conclusion: MVCIB框架通过多视图条件信息瓶颈和子结构对齐机制，有效解决了多视图分子学习中的关键挑战，在分子表示学习方面取得了显著改进。

Abstract: Recent pre-training strategies for molecular graphs have attempted to use 2D and 3D molecular views as both inputs and self-supervised signals, primarily aligning graph-level representations. However, existing studies remain limited in addressing two main challenges of multi-view molecular learning: (1) discovering shared information between two views while diminishing view-specific information and (2) identifying and aligning important substructures, e.g., functional groups, which are crucial for enhancing cross-view consistency and model expressiveness. To solve these challenges, we propose a Multi-View Conditional Information Bottleneck framework, called MVCIB, for pre-training graph neural networks on 2D and 3D molecular structures in a self-supervised setting. Our idea is to discover the shared information while minimizing irrelevant features from each view under the MVCIB principle, which uses one view as a contextual condition to guide the representation learning of its counterpart. To enhance semantic and structural consistency across views, we utilize key substructures, e.g., functional groups and ego-networks, as anchors between the two views. Then, we propose a cross-attention mechanism that captures fine-grained correlations between the substructures to achieve subgraph alignment across views. Extensive experiments in four molecular domains demonstrated that MVCIB consistently outperforms baselines in both predictive performance and interpretability. Moreover, MVCIB achieved the 3d Weisfeiler-Lehman expressiveness power to distinguish not only non-isomorphic graphs but also different 3D geometries that share identical 2D connectivity, such as isomers.

</details>


### [445] [Radiation-Preserving Selective Imaging for Pediatric Hip Dysplasia: A Cross-Modal Ultrasound-Xray Policy with Limited Labels](https://arxiv.org/abs/2511.18457)
*Duncan Stothers,Ben Stothers,Emily Schaeffer,Kishore Mulpuri*

Main category: cs.LG

TL;DR: 该研究提出了一种超声优先、辐射保留的发育性髋关节发育不良（DDH）筛查策略，通过预训练模态特定编码器和校准延迟规则，仅在需要时进行X光检查，以减少辐射暴露。


<details>
  <summary>Details</summary>
Motivation: 减少DDH筛查中的辐射暴露，同时保持诊断准确性。通过超声优先策略，仅在必要时才进行X光检查，以保护患者免受不必要的辐射。

Method: 使用SimSiam对大型未标记数据集进行模态特定编码器预训练，冻结主干网络并拟合小型测量头，校准单侧符合延迟规则以确保有限样本覆盖保证。

Result: 超声测量误差适中（如alpha MAE约9.7度），X光测量误差较小（AI和CE MAE分别为7.6度和8.9度）。校准后的US-only策略在不同规则家族和设置下实现可调的选择性成像曲线。

Conclusion: 该 pipeline 将有限标签转化为可解释的测量值和可调的选择性成像曲线，适用于临床交接和未来外部验证，实现了辐射暴露的减少和诊断准确性的平衡。

Abstract: We study an ultrasound-first, radiation-preserving policy for developmental dysplasia of the hip (DDH) that requests a radiograph only when needed.
  We (i) pretrain modality-specific encoders (ResNet-18) with SimSiam on a large unlabelled registry (37186 ultrasound; 19546 radiographs), (ii) freeze the backbones and fit small, measurement-faithful heads on DDH relevant landmarks and measurements (iii) calibrate a one sided conformal deferral rule on ultrasound predictions that provides finite sample coverage guarantees under exchangeability, using a held-out calibration set. Ultrasound heads predict Graf alpha, beta, and femoral head coverage; X-ray heads predict acetabular index (AI), center-edge (CE) angle and IHDI grade. On our held out labeled evaluation set, ultrasound measurement error is modest (e.g., alpha MAE ~= 9.7 degrees, coverage MAE ~= 14.0%), while radiographic probes achieve AI and CE MAEs of ~= 7.6 degrees and ~= 8.9 degrees, respectively. The calibrated US-only policy is explored across rule families (alpha-only; alpha OR coverage; alpha AND coverage), uncertainty inflation factors, and per-utility trade-offs using decision-curve analysis. Conservative settings yield high coverage with near-zero US-only rates; permissive settings (e.g., alpha OR coverage at larger deltas) achieve non-zero US-only throughput with expected coverage tradeoffs. The result is a simple, reproducible pipeline that turns limited labels into interpretable measurements and tunable selective imaging curves suitable for clinical handoff and future external validation.

</details>


### [446] [SloMo-Fast: Slow-Momentum and Fast-Adaptive Teachers for Source-Free Continual Test-Time Adaptation](https://arxiv.org/abs/2511.18468)
*Md Akil Raihan Iftee,Mir Sazzat Hossain,Rakibul Hasan Rajib,Tariq Iqbal,Md Mofijul Islam,M Ashraful Amin,Amin Ahsan Ali,AKM Mahbubur Rahman*

Main category: cs.LG

TL;DR: SloMo-Fast是一个无需源数据的双教师CTTA框架，通过慢速教师和快速教师的互补设计解决持续测试时适应中的长期遗忘问题，在循环域转换场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有CTTA方法依赖源数据或原型，在隐私敏感和资源受限场景中适用性有限，且存在长期遗忘问题导致先前域性能下降。

Method: 提出SloMo-Fast框架，包含两个互补教师：慢速教师（Slow-Teacher）保持长期知识防止遗忘，快速教师（Fast-Teacher）快速适应新域并整合知识；同时提出Cyclic-TTA基准测试循环域转换。

Result: 在Cyclic-TTA和其他十个CTTA设置中的广泛实验表明，SloMo-Fast持续优于现有最先进方法，在演化和重访域中均表现出良好的适应和泛化能力。

Conclusion: SloMo-Fast通过双教师设计有效解决了CTTA中的长期遗忘问题，在无需源数据的情况下实现了对不断变化域的鲁棒适应和泛化。

Abstract: Continual Test-Time Adaptation (CTTA) is crucial for deploying models in real-world applications with unseen, evolving target domains. Existing CTTA methods, however, often rely on source data or prototypes, limiting their applicability in privacy-sensitive and resource-constrained settings. Additionally, these methods suffer from long-term forgetting, which degrades performance on previously encountered domains as target domains shift. To address these challenges, we propose SloMo-Fast, a source-free, dual-teacher CTTA framework designed for enhanced adaptability and generalization. It includes two complementary teachers: the Slow-Teacher, which exhibits slow forgetting and retains long-term knowledge of previously encountered domains to ensure robust generalization, and the Fast-Teacher rapidly adapts to new domains while accumulating and integrating knowledge across them. This framework preserves knowledge of past domains and adapts efficiently to new ones. We also introduce Cyclic Test-Time Adaptation (Cyclic-TTA), a novel CTTA benchmark that simulates recurring domain shifts. Our extensive experiments demonstrate that SloMo-Fast consistently outperforms state-of-the-art methods across Cyclic-TTA, as well as ten other CTTA settings, highlighting its ability to both adapt and generalize across evolving and revisited domains.

</details>


### [447] [Adaptive Mesh-Quantization for Neural PDE Solvers](https://arxiv.org/abs/2511.18474)
*Winfried van den Dool,Maksim Zhdanov,Yuki M. Asano,Max Welling*

Main category: cs.LG

TL;DR: 提出了自适应网格量化方法，通过轻量级辅助模型识别高损失区域，动态调整量化位宽，在复杂物理区域分配更多计算资源，相比均匀量化基线实现了50%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 物理系统通常具有空间变化的复杂性，而现有图神经网络在求解偏微分方程时对所有节点采用统一计算资源，导致简单区域和复杂区域资源分配不合理，计算效率低下。

Method: 引入自适应网格量化框架，在网格节点、边和簇特征上进行空间自适应量化，通过轻量级辅助模型识别输入网格中的高损失区域，动态调整量化模型的位宽分配。

Result: 在MP-PDE和GraphViT两个先进模型上测试，涵盖2D Darcy流、大规模非定常流体动力学、3D稳态Navier-Stokes模拟和2D超弹性问题，相比均匀量化基线实现了持续的帕累托改进。

Conclusion: 自适应网格量化框架能够有效优化计算资源利用，在相同计算成本下实现高达50%的性能提升，为复杂物理系统的神经网络求解提供了高效解决方案。

Abstract: Physical systems commonly exhibit spatially varying complexity, presenting a significant challenge for neural PDE solvers. While Graph Neural Networks can handle the irregular meshes required for complex geometries and boundary conditions, they still apply uniform computational effort across all nodes regardless of the underlying physics complexity. This leads to inefficient resource allocation where computationally simple regions receive the same treatment as complex phenomena. We address this challenge by introducing Adaptive Mesh Quantization: spatially adaptive quantization across mesh node, edge, and cluster features, dynamically adjusting the bit-width used by a quantized model. We propose an adaptive bit-width allocation strategy driven by a lightweight auxiliary model that identifies high-loss regions in the input mesh. This enables dynamic resource distribution in the main model, where regions of higher difficulty are allocated increased bit-width, optimizing computational resource utilization. We demonstrate our framework's effectiveness by integrating it with two state-of-the-art models, MP-PDE and GraphViT, to evaluate performance across multiple tasks: 2D Darcy flow, large-scale unsteady fluid dynamics in 2D, steady-state Navier-Stokes simulations in 3D, and a 2D hyper-elasticity problem. Our framework demonstrates consistent Pareto improvements over uniformly quantized baselines, yielding up to 50% improvements in performance at the same cost.

</details>


### [448] [Real-Time Personalized Content Adaptation through Matrix Factorization and Context-Aware Federated Learning](https://arxiv.org/abs/2511.18489)
*Sai Puppala,Ismail Hossain,Md Jahangir Alam,Sajedul Talukder*

Main category: cs.LG

TL;DR: 提出了一种基于联邦学习的个性化LLM框架，用于提升社交媒体平台的用户互动和内容相关性，通过本地数据微调GPT模型并保护隐私。


<details>
  <summary>Details</summary>
Motivation: 解决社交媒体平台中内容过滤和推荐的挑战，在保护用户隐私的同时提升个性化互动体验。

Method: 采用联邦学习框架，客户端接收基础GPT模型并使用本地社交媒体数据进行微调；通过用户生成内容分类、用户画像评分、朋友网络相关帖子识别等模块；结合社交参与度量化和矩阵分解技术实现实时个性化内容推荐。

Result: 系统能够提供实时个性化的内容建议，自适应反馈循环和可读性评分算法显著提升了内容质量和相关性。

Conclusion: 该综合解决方案不仅解决了内容过滤和推荐问题，还促进了更吸引人的社交媒体体验，同时保护用户隐私，为数字平台的个性化互动设定了新标准。

Abstract: Our study presents a multifaceted approach to enhancing user interaction and content relevance in social media platforms through a federated learning framework. We introduce personalized LLM Federated Learning and Context-based Social Media models. In our framework, multiple client entities receive a foundational GPT model, which is fine-tuned using locally collected social media data while ensuring data privacy through federated aggregation. Key modules focus on categorizing user-generated content, computing user persona scores, and identifying relevant posts from friends networks. By integrating a sophisticated social engagement quantification method with matrix factorization techniques, our system delivers real-time personalized content suggestions tailored to individual preferences. Furthermore, an adaptive feedback loop, alongside a robust readability scoring algorithm, significantly enhances the quality and relevance of the content presented to users. This comprehensive solution not only addresses the challenges of content filtering and recommendation but also fosters a more engaging social media experience while safeguarding user privacy, setting a new standard for personalized interactions in digital platforms.

</details>


### [449] [RRaPINNs: Residual Risk-Aware Physics Informed Neural Networks](https://arxiv.org/abs/2511.18515)
*Ange-Clément Akazan,Issa Karambal,Jean Medard Ngnotchouye,Abebe Geletu Selassie. W*

Main category: cs.LG

TL;DR: 提出了RRaPINNs框架，通过风险敏感优化方法解决PINNs中局部误差大的问题，使用CVaR和ME惩罚项优化尾部残差，在多种PDE问题上表现优于传统PINNs方法。


<details>
  <summary>Details</summary>
Motivation: 传统PINNs最小化平均残差会掩盖局部大误差问题，需要开发能够控制最坏情况PDE残差的方法来提高可靠性。

Method: 采用条件风险价值（CVaR）进行风险敏感优化，引入Mean-Excess（ME）替代惩罚项直接控制最坏情况PDE残差，将PINN训练转化为机会约束问题。

Result: 在Burgers、Heat、Korteweg-de-Vries和Poisson等多种PDE问题上，RRaPINNs显著降低尾部残差，同时保持或改善平均误差，优于传统PINNs和基于注意力的变体。

Conclusion: RRaPINNs为科学机器学习提供了实用的可靠性感知路径，参数α可透明地权衡整体精度和尾部控制，但存在内存采样、全局风险预算等局限性，可通过持续硬点重放等方法改进。

Abstract: Physics-informed neural networks (PINNs) typically minimize average residuals, which can conceal large, localized errors. We propose Residual Risk-Aware Physics-Informed Neural Networks PINNs (RRaPINNs), a single-network framework that optimizes tail-focused objectives using Conditional Value-at-Risk (CVaR), we also introduced a Mean-Excess (ME) surrogate penalty to directly control worst-case PDE residuals. This casts PINN training as risk-sensitive optimization and links it to chance-constrained formulations. The method is effective and simple to implement. Across several partial differential equations (PDEs) such as Burgers, Heat, Korteweg-de-Vries, and Poisson (including a Poisson interface problem with a source jump at x=0.5) equations, RRaPINNs reduce tail residuals while maintaining or improving mean errors compared to vanilla PINNs, Residual-Based Attention and its variant using convolution weighting; the ME surrogate yields smoother optimization than a direct CVaR hinge. The chance constraint reliability level $α$ acts as a transparent knob trading bulk accuracy (lower $α$ ) for stricter tail control (higher $α$ ). We discuss the framework limitations, including memoryless sampling, global-only tail budgeting, and residual-centric risk, and outline remedies via persistent hard-point replay, local risk budgets, and multi-objective risk over BC/IC terms. RRaPINNs offer a practical path to reliability-aware scientific ML for both smooth and discontinuous PDEs.

</details>


### [450] [CHIPS: Efficient CLIP Adaptation via Curvature-aware Hybrid Influence-based Data Selection](https://arxiv.org/abs/2511.18519)
*Xinlin Zhuang,Yichen Li,Xiwei Liu,Haolin Yang,Yifan Lu,Ziyun Zou,Yulong Li,Huifa Li,Dongliang Chen,Qinglei Wang,Weiyang Liu,Ying Qian,Jiangming Shi,Imran Razzak*

Main category: cs.LG

TL;DR: CHIPS是一种从数据角度出发的CLIP领域适应方法，通过综合三个互补因素（忠实度、可扩展性和保留性）为图像-文本对分配效用分数，仅需10-30%的数据即可达到或超越全数据集持续预训练的效果。


<details>
  <summary>Details</summary>
Motivation: 当前CLIP领域适应方法主要关注微调策略或大规模领域特定数据集的持续预训练，而数据本身作为关键因素未被充分探索。本文旨在研究是否可以通过有效的数据选择替代大规模数据集。

Method: 提出CHIPS方法，在CLIP的端点子空间中计算三个因素的效用分数：1）通过曲率感知的牛顿式对齐确保忠实度；2）通过结合Johnson-Lindenstrauss草图的InfoNCE感知曲率估计器实现可扩展性；3）通过选择感知相关性权重和可学习性平衡目标适应与通用领域保留。

Result: 在17个医学基准测试中，CHIPS在数据选择基线中达到最先进性能，仅用30%数据即可匹配全数据集持续预训练，仅用10%数据即可超越半数据集持续预训练；在31个通用领域基准测试中，在10-30%数据保留预算下性能下降最小。

Conclusion: CHIPS证明了通过精心设计的数据选择策略可以显著减少持续预训练所需的数据量，同时保持或提升模型性能，为数据高效的领域适应提供了新思路。

Abstract: Adapting CLIP to vertical domains is typically approached by novel fine-tuning strategies or by continual pre-training (CPT) on large domain-specific datasets. Yet, data itself remains an underexplored factor in this process. We revisit this task from a data-centric perspective: Can effective data selection substitute for large-scale datasets in CPT? We introduce CHIPS (Curvature-aware Hybrid Influence in Projection Subspace), which assigns each image-text pair a utility score that integrates three complementary factors aligned with three goals: faithfulness via a curvature-aware, Newton-style alignment computed in CLIP's end-point subspace; scalability via an InfoNCE-aware curvature estimator with Johnson-Lindenstrauss (JL) sketching; and retention via a selection-aware relevance weight combined with learnability to balance target adaptation against general-domain preservation. We justify this design theoretically by proving a lower-bound guarantee on the proxy's correlation with full-parameter alignment and by characterizing the bias-variance trade-offs introduced by curvature mixing and JL sketching. We evaluate CHIPS empirically across various settings: 1) CHIPS attains state-of-the-art performance among selection baselines on 17 medical benchmarks, matches full-dataset CPT with 30% of the data, and outperforms half-dataset CPT using only 10%; 2) on 31 general-domain benchmarks, CHIPS yields the smallest performance drop under 10-30% data-retention budgets. Code, data, and checkpoints will be released.

</details>


### [451] [Hyperspectral Variational Autoencoders for Joint Data Compression and Component Extraction](https://arxiv.org/abs/2511.18521)
*Core Francisco Park,Manuel Perez-Carrasco,Caroline Nowlan,Cecilia Garraffo*

Main category: cs.LG

TL;DR: 该论文提出了一种变分自编码器方法，用于压缩地球静止轨道高光谱卫星数据，实现了514倍的压缩比，同时保持光谱保真度，并研究了压缩潜空间中大气信息的保留情况。


<details>
  <summary>Details</summary>
Motivation: 解决地球静止轨道高光谱卫星产生的海量数据在存储、传输和分发方面面临的挑战，为下一代地球观测系统解决关键瓶颈问题。

Method: 使用变分自编码器对NASA TEMPO卫星的高光谱观测数据进行压缩，并训练线性和非线性探针从压缩潜空间中提取Level-2大气产品。

Result: 实现了514倍的数据压缩，重建误差比信号低1-2个数量级。云分数和总臭氧提取性能良好（R²=0.93和0.81），但对流层痕量气体提取效果较差（NO₂ R²=0.20，HCHO R²=0.51）。

Conclusion: 神经压缩技术能显著减少高光谱数据量，同时保留关键大气信号，但某些大气产品的编码存在根本性挑战，非线性探针明显优于线性探针。

Abstract: Geostationary hyperspectral satellites generate terabytes of data daily, creating critical challenges for storage, transmission, and distribution to the scientific community. We present a variational autoencoder (VAE) approach that achieves x514 compression of NASA's TEMPO satellite hyperspectral observations (1028 channels, 290-490nm) with reconstruction errors 1-2 orders of magnitude below the signal across all wavelengths. This dramatic data volume reduction enables efficient archival and sharing of satellite observations while preserving spectral fidelity. Beyond compression, we investigate to what extent atmospheric information is retained in the compressed latent space by training linear and nonlinear probes to extract Level-2 products (NO2, O3, HCHO, cloud fraction). Cloud fraction and total ozone achieve strong extraction performance (R^2 = 0.93 and 0.81 respectively), though these represent relatively straightforward retrievals given their distinct spectral signatures. In contrast, tropospheric trace gases pose genuine challenges for extraction (NO2 R^2 = 0.20, HCHO R^2 = 0.51) reflecting their weaker signals and complex atmospheric interactions. Critically, we find the VAE encodes atmospheric information in a semi-linear manner - nonlinear probes substantially outperform linear ones - and that explicit latent supervision during training provides minimal improvement, revealing fundamental encoding challenges for certain products. This work demonstrates that neural compression can dramatically reduce hyperspectral data volumes while preserving key atmospheric signals, addressing a critical bottleneck for next-generation Earth observation systems. Code - https://github.com/cfpark00/Hyperspectral-VAE

</details>


### [452] [TimePre: Bridging Accuracy, Efficiency, and Stability in Probabilistic Time-Series Forecasting](https://arxiv.org/abs/2511.18539)
*Lingyu Jiang,Lingyu Xu,Peiran Li,Qianwen Ge,Dingyi Zhuang,Shuo Xing,Wenjing Chen,Xiangbo Gao,Ting-Hsuan Chen,Xueying Zhan,Xin Zhang,Ziming Zhang,Zhengzhong Tu,Michael Zielewski,Kazunori Yamada,Fangzhou Lin*

Main category: cs.LG

TL;DR: TimePre是一个新颖的概率时间序列预测框架，通过稳定实例归一化(SIN)解决了MLP骨干网络与多选择学习(MCL)范式结合时的训练不稳定和假设崩溃问题，实现了高效、准确且稳定的概率预测。


<details>
  <summary>Details</summary>
Motivation: 现有概率时间序列预测方法存在效率与性能的矛盾：基于扩散的方法计算成本高，而基于MCL的非采样方法虽然高效但存在严重训练不稳定和假设崩溃问题，特别是与现代MLP骨干网络结合时问题更加严重。

Method: 提出TimePre框架，核心创新是稳定实例归一化(SIN)层，通过校正通道级统计偏移来稳定混合架构，彻底解决假设崩溃问题，成功将MLP模型的高效性与MCL的分布灵活性相结合。

Result: 在六个基准数据集上的实验表明，TimePre在关键概率指标上达到新的最先进准确率，推理速度比基于采样的模型快几个数量级，并且表现出稳定的性能扩展能力。

Conclusion: TimePre成功解决了概率预测中长期存在的准确性、效率和稳定性之间的差距，为不确定性感知决策提供了实用解决方案。

Abstract: Probabilistic Time-Series Forecasting (PTSF) is critical for uncertainty-aware decision making, but existing generative models, such as diffusion-based approaches, are computationally prohibitive due to expensive iterative sampling. Non-sampling frameworks like Multiple Choice Learning (MCL) offer an efficient alternative, but suffer from severe training instability and hypothesis collapse, which has historically hindered their performance. This problem is dramatically exacerbated when attempting to combine them with modern, efficient MLP-based backbones. To resolve this fundamental incompatibility, we propose TimePre, a novel framework that successfully unifies the efficiency of MLP-based models with the distributional flexibility of the MCL paradigm. The core of our solution is Stabilized Instance Normalization (SIN), a novel normalization layer that explicitly remedies this incompatibility. SIN stabilizes the hybrid architecture by correcting channel-wise statistical shifts, definitively resolving the catastrophic hypothesis collapse. Extensive experiments on six benchmark datasets demonstrate that TimePre achieves new state-of-the-art accuracy on key probabilistic metrics. Critically, TimePre achieves inference speeds orders of magnitude faster than sampling-based models and, unlike prior MCL work, demonstrates stable performance scaling. It thus bridges the long-standing gap between accuracy, efficiency, and stability in probabilistic forecasting.

</details>


### [453] [In Search of Goodness: Large Scale Benchmarking of Goodness Functions for the Forward-Forward Algorithm](https://arxiv.org/abs/2511.18567)
*Arya Shah,Vaibhav Tripathi*

Main category: cs.LG

TL;DR: 该研究对Forward-Forward算法中的21种不同goodness函数进行了基准测试，发现在四个标准图像数据集上，某些替代goodness函数显著优于标准基线，同时在计算效率和环境影响方面存在显著差异。


<details>
  <summary>Details</summary>
Motivation: Forward-Forward算法作为一种生物可解释的替代反向传播的方法，其有效性依赖于goodness函数的定义。目前实现主要使用简单的平方和度量，但尚不清楚这是否是最优选择。

Method: 在四个标准图像数据集（MNIST、FashionMNIST、CIFAR-10、STL-10）上对21种不同的goodness函数进行基准测试，评估分类准确率、能耗和碳足迹。

Result: 发现特定替代goodness函数表现优异：game_theoretic_local在MNIST上达到97.15%准确率，softmax_energy_margin_local在FashionMNIST上达到82.84%，triplet_margin_local在STL-10上达到37.69%。同时观察到计算效率的显著差异。

Conclusion: goodness函数是FF算法设计中的关键超参数，存在预测性能与环境成本之间的权衡关系。研究代码已在GitHub上开源。

Abstract: The Forward-Forward (FF) algorithm offers a biologically plausible alternative to backpropagation, enabling neural networks to learn through local updates. However, FF's efficacy relies heavily on the definition of "goodness", which is a scalar measure of neural activity. While current implementations predominantly utilize a simple sum-of-squares metric, it remains unclear if this default choice is optimal. To address this, we benchmarked 21 distinct goodness functions across four standard image datasets (MNIST, FashionMNIST, CIFAR-10, STL-10), evaluating classification accuracy, energy consumption, and carbon footprint. We found that certain alternative goodness functions inspired from various domains significantly outperform the standard baseline. Specifically, \texttt{game\_theoretic\_local} achieved 97.15\% accuracy on MNIST, \texttt{softmax\_energy\_margin\_local} reached 82.84\% on FashionMNIST, and \texttt{triplet\_margin\_local} attained 37.69\% on STL-10. Furthermore, we observed substantial variability in computational efficiency, highlighting a critical trade-off between predictive performance and environmental cost. These findings demonstrate that the goodness function is a pivotal hyperparameter in FF design. We release our code on \href{https://github.com/aryashah2k/In-Search-of-Goodness}{Github} for reference and reproducibility.

</details>


### [454] [SAMBA: Toward a Long-Context EEG Foundation Model via Spatial Embedding and Differential Mamba](https://arxiv.org/abs/2511.18571)
*Jiazhen Hong,Geoffrey Mackellar,Soheila Ghane*

Main category: cs.LG

TL;DR: SAMBA是一个基于Mamba的U型编码器-解码器架构的自监督学习框架，专门用于处理长序列EEG数据，解决了传统Transformer模型在处理长序列时的二次复杂度问题，并在多个数据集上表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 长序列EEG建模对于开发通用的EEG表示模型至关重要，但由于EEG数据的高采样率和长记录时间，传统Transformer模型在处理长序列时存在二次复杂度限制。此外，不同数据集中的电极配置差异和受试者间脑信号差异也给构建通用基础模型带来挑战。

Method: 提出SAMBA框架，包含：(1) 时间语义随机掩码进行语义级序列重建；(2) 多头差分Mamba模块抑制冗余并突出显著时间结构；(3) 空间自适应输入嵌入在三维欧几里得空间中学习统一嵌入，提高跨设备鲁棒性。

Result: 在13个EEG数据集上的实验表明，SAMBA在保持低内存消耗和推理时间的同时，持续优于最先进方法。学习到的空间权重图与任务相关的神经生理区域高度一致，证明了模型的可学习性和可解释性。

Conclusion: SAMBA展示了作为实时脑机接口应用基础模型的可扩展性和实际潜力，为解决长序列EEG建模挑战提供了有效解决方案。

Abstract: Long-sequence electroencephalogram (EEG) modeling is essential for developing generalizable EEG representation models. This need arises from the high sampling rate of EEG data and the long recording durations required to capture extended neurological patterns in brain activity. Transformer-based models have shown promise in modeling short sequences of a few seconds; however, their quadratic complexity limits scalability to longer contexts. Moreover, variability in electrode montage across available datasets, along with inter-subject differences in brain signals, pose significant challenges to developing a generalizable and robust foundation model. We propose \textit{SAMBA}, a self-supervised learning framework with a Mamba-based U-shaped encoder-decoder architecture, which effectively captures long-range temporal dependencies and spatial variability in EEG data. Leveraging the inherent ability of Mamba in processing long context sizes, we introduce: (1) \textit{Temporal Semantic Random Masking} for semantic-level sequence reconstruction, (2) a \textit{Multi-Head Differential Mamba} module to suppress redundancy and emphasize salient temporal structures, and (3) a \textit{Spatial-Adaptive Input Embedding} that learns unified embeddings in a three-dimensional Euclidean space, enabling robustness across devices. Experiments on thirteen EEG datasets across diverse tasks, electrode configurations, and sequence durations demonstrate that SAMBA consistently outperforms state-of-the-art methods while maintaining low memory consumption and inference time. We also show the learned spatial weight maps from our embedding module align closely with task-relevant neurophysiological regions, demonstrating the learnability and interpretability of SAMBA. These results highlight SAMBA's scalability and practical potential as a foundation model for real-time brain-computer interface applications.

</details>


### [455] [Generative Myopia: Why Diffusion Models Fail at Structure](https://arxiv.org/abs/2511.18593)
*Milad Siami*

Main category: cs.LG

TL;DR: 该论文提出图扩散模型存在“生成性近视”问题，即模型过度关注统计频率而忽略光谱关键结构，导致在组合任务中失败。作者通过引入光谱加权扩散方法解决了这一问题。


<details>
  <summary>Details</summary>
Motivation: 图扩散模型在优化统计似然时，会隐式地作为频率滤波器，偏好丰富的子结构而非光谱关键结构。这种现象称为“生成性近视”，在如图稀疏化等组合任务中会导致灾难性地移除“稀有桥梁”等重要结构。

Method: 提出光谱加权扩散方法，利用有效电阻重新对齐变分目标，将光谱先验摊销到训练阶段，实现零推理开销。

Result: 该方法消除了近视问题，与最优光谱预言机性能匹配，在标准扩散完全失败（0%连通性）的对抗基准上实现了100%连通性。

Conclusion: 光谱先验可以有效地集成到训练过程中，解决图扩散模型的结构学习瓶颈，显著提升在组合任务上的性能。

Abstract: Graph Diffusion Models (GDMs) optimize for statistical likelihood, implicitly acting as \textbf{frequency filters} that favor abundant substructures over spectrally critical ones. We term this phenomenon \textbf{Generative Myopia}. In combinatorial tasks like graph sparsification, this leads to the catastrophic removal of ``rare bridges,'' edges that are structurally mandatory ($R_{\text{eff}} \approx 1$) but statistically scarce. We prove theoretically and empirically that this failure is driven by \textbf{Gradient Starvation}: the optimization landscape itself suppresses rare structural signals, rendering them unlearnable regardless of model capacity. To resolve this, we introduce \textbf{Spectrally-Weighted Diffusion}, which re-aligns the variational objective using Effective Resistance. We demonstrate that spectral priors can be amortized into the training phase with zero inference overhead. Our method eliminates myopia, matching the performance of an optimal Spectral Oracle and achieving \textbf{100\% connectivity} on adversarial benchmarks where standard diffusion fails completely (0\%).

</details>


### [456] [CycleSL: Server-Client Cyclical Update Driven Scalable Split Learning](https://arxiv.org/abs/2511.18611)
*Mengdi Wang,Efe Bozkir,Enkelejda Kasneci*

Main category: cs.LG

TL;DR: CycleSL是一种新颖的无聚合分割学习框架，通过循环更新机制解决现有分割学习方法在可扩展性和性能方面的局限性


<details>
  <summary>Details</summary>
Motivation: 解决顺序分割学习可扩展性差，以及并行分割学习方法服务器资源开销大、模型性能下降和收敛问题

Method: 基于交替块坐标下降思想，将服务器端训练视为独立的高级机器学习任务，通过重采样客户端提取的特征来缓解异构性和漂移，采用先优化服务器模型再更新客户端的循环更新策略

Result: 在五个公开数据集上的实验表明，CycleSL能有效提升模型性能，特别是在非独立同分布数据和部分客户端参与的场景下

Conclusion: CycleSL框架能够增强分割学习的可扩展性和性能，并能与现有方法无缝集成

Abstract: Split learning emerges as a promising paradigm for collaborative distributed model training, akin to federated learning, by partitioning neural networks between clients and a server without raw data exchange. However, sequential split learning suffers from poor scalability, while parallel variants like parallel split learning and split federated learning often incur high server resource overhead due to model duplication and aggregation, and generally exhibit reduced model performance and convergence owing to factors like client drift and lag. To address these limitations, we introduce CycleSL, a novel aggregation-free split learning framework that enhances scalability and performance and can be seamlessly integrated with existing methods. Inspired by alternating block coordinate descent, CycleSL treats server-side training as an independent higher-level machine learning task, resampling client-extracted features (smashed data) to mitigate heterogeneity and drift. It then performs cyclical updates, namely optimizing the server model first, followed by client updates using the updated server for gradient computation. We integrate CycleSL into previous algorithms and benchmark them on five publicly available datasets with non-iid data distribution and partial client attendance. Our empirical findings highlight the effectiveness of CycleSL in enhancing model performance. Our source code is available at https://gitlab.lrz.de/hctl/CycleSL.

</details>


### [457] [KAN vs LSTM Performance in Time Series Forecasting](https://arxiv.org/abs/2511.18613)
*Tabish Ali Rather,S M Mahmudul Hasan Joy,Nadezda Sukhorukova,Federico Frascoli*

Main category: cs.LG

TL;DR: 本文比较了KAN和LSTM在股票价格预测中的表现，发现LSTM在预测精度上显著优于KAN，而KAN的主要优势在于理论可解释性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 研究KAN和LSTM在非确定性股票价格数据预测中的性能对比，评估预测精度与可解释性之间的权衡。

Method: 使用均方根误差（RMSE）作为评估指标，比较KAN和LSTM在不同预测时间范围内的表现。

Result: LSTM在所有测试的预测时间范围内都表现出显著优势，而标准KAN虽然具有理论可解释性，但误差率显著更高。

Conclusion: LSTM在时间序列预测应用中具有主导地位，而KAN在资源受限且精度要求不高的场景下具有计算效率优势，建议继续研究专门化的KAN架构。

Abstract: This paper compares Kolmogorov-Arnold Networks (KAN) and Long Short-Term Memory networks (LSTM) for forecasting non-deterministic stock price data, evaluating predictive accuracy versus interpretability trade-offs using Root Mean Square Error (RMSE).LSTM demonstrates substantial superiority across all tested prediction horizons, confirming their established effectiveness for sequential data modelling. Standard KAN, while offering theoretical interpretability through the Kolmogorov-Arnold representation theorem, exhibits significantly higher error rates and limited practical applicability for time series forecasting. The results confirm LSTM dominance in accuracy-critical time series applications while identifying computational efficiency as KANs' primary advantage in resource-constrained scenarios where accuracy requirements are less stringent. The findings support LSTM adoption for practical financial forecasting while suggesting that continued research into specialised KAN architectures may yield future improvements.

</details>


### [458] [Bayesian-based Online Label Shift Estimation with Dynamic Dirichlet Priors](https://arxiv.org/abs/2511.18615)
*Jiawei Hu,Javier A. Barria*

Main category: cs.LG

TL;DR: 提出了FMAPLS和online-FMAPLS两种贝叶斯框架，用于解决标签偏移问题，通过联合优化Dirichlet超参数和类先验分布，显著提升分类器在测试数据分布变化时的性能。


<details>
  <summary>Details</summary>
Motivation: 标签偏移是监督学习中的常见挑战，当测试数据的类先验分布与训练数据不同时，会导致分类器性能显著下降。现有MAPLS方法存在刚性约束限制，需要更灵活有效的解决方案。

Method: 提出基于批量EM和在线EM算法的贝叶斯框架，引入线性替代函数(LSF)替代梯度更新，获得闭式解降低计算复杂度。在线版本使用随机近似实现实时适应流数据。

Result: 在CIFAR100和ImageNet数据集上，FMAPLS和online-FMAPLS分别实现了高达40%和12%的KL散度降低，并在后偏移准确率上显著优于现有基线方法，特别是在严重类别不平衡和分布不确定性情况下。

Conclusion: 该方法在鲁棒性、可扩展性和动态学习场景适用性方面表现出色，特别适合大规模和动态学习环境。

Abstract: Label shift, a prevalent challenge in supervised learning, arises when the class prior distribution of test data differs from that of training data, leading to significant degradation in classifier performance. To accurately estimate the test priors and enhance classification accuracy, we propose a Bayesian framework for label shift estimation, termed Full Maximum A Posterior Label Shift (FMAPLS), along with its online version, online-FMAPLS. Leveraging batch and online Expectation-Maximization (EM) algorithms, these methods jointly and dynamically optimize Dirichlet hyperparameters $\boldsymbolα$ and class priors $\boldsymbolπ$, thereby overcoming the rigid constraints of the existing Maximum A Posterior Label Shift (MAPLS) approach. Moreover, we introduce a linear surrogate function (LSF) to replace gradient-based hyperparameter updates, yielding closed-form solutions that reduce computational complexity while retaining asymptotic equivalence. The online variant substitutes the batch E-step with a stochastic approximation, enabling real-time adaptation to streaming data. Furthermore, our theoretical analysis reveals a fundamental trade-off between online convergence rate and estimation accuracy. Extensive experiments on CIFAR100 and ImageNet datasets under shuffled long-tail and Dirichlet test priors demonstrate that FMAPLS and online-FMAPLS respectively achieve up to 40% and 12% lower KL divergence and substantial improvements in post-shift accuracy over state-of-the-art baselines, particularly under severe class imbalance and distributional uncertainty. These results confirm the robustness, scalability, and suitability of the proposed methods for large-scale and dynamic learning scenarios.

</details>


### [459] [Majority of the Bests: Improving Best-of-N via Bootstrapping](https://arxiv.org/abs/2511.18630)
*Amin Rakhsha,Kanika Madan,Tianyu Zhang,Amir-massoud Farahmand,Amir Khasahmadi*

Main category: cs.LG

TL;DR: 该论文提出了一种名为Majority-of-the-Bests (MoB)的新选择机制，通过自助法估计Best-of-N (BoN)的输出分布并选择其众数，以解决在奖励模型不完美时BoN性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: 当奖励模型不完美时，Best-of-N (BoN)方法无法可靠地找到正确答案，性能急剧下降。尽管正确答案在BoN输出分布中的概率通常不接近1，但它往往是最可能的结果。

Method: 提出MoB方法，通过自助法估计BoN的输出分布，并选择该分布的众数作为最终答案。

Result: 在五个基准测试、三种基础LLM和两种奖励模型的30个设置中，MoB在25个设置中一致优于BoN。

Conclusion: MoB是BoN和自一致性的一种简单而强大的替代方法，并激励进一步研究更细致的选择机制。

Abstract: Sampling multiple outputs from a Large Language Model (LLM) and selecting the most frequent (Self-consistency) or highest-scoring (Best-of-N) candidate is a popular approach to achieve higher accuracy in tasks with discrete final answers. Best-of-N (BoN) selects the output with the highest reward, and with perfect rewards, it often achieves near-perfect accuracy. With imperfect rewards from reward models, however, BoN fails to reliably find the correct answer and its performance degrades drastically. We consider the distribution of BoN's outputs and highlight that, although the correct answer does not usually have a probability close to one under imperfect rewards, it is often the most likely outcome. This suggests that the mode of this distribution can be more reliably correct than a sample from it. Based on this idea, we propose Majority-of-the-Bests (MoB), a novel selection mechanism that estimates the output distribution of BoN via bootstrapping and selects its mode. Experimental results across five benchmarks, three different base LLMs, and two reward models demonstrate consistent improvements over BoN in 25 out of 30 setups. We also provide theoretical results for the consistency of the bootstrapping. MoB serves as a simple, yet strong alternative to BoN and self-consistency, and more broadly, motivates further research in more nuanced selection mechanisms.

</details>


### [460] [FOS: A Large-Scale Temporal Graph Benchmark for Scientific Interdisciplinary Link Prediction](https://arxiv.org/abs/2511.18631)
*Kiyan Rezaee,Morteza Ziabakhsh,Niloofar Nikfarjam,Mohammad M. Ghassemi,Yazdan Rezaee Jouryabi,Sadegh Eskandari,Reza Lashgari*

Main category: cs.LG

TL;DR: FOS是一个时间感知的图基准，用于预测跨学科研究领域的形成，通过构建1827-2024年间65,027个子领域的共现图，将新领域对链接预测建模为时间链接预测任务。


<details>
  <summary>Details</summary>
Motivation: 跨学科科学突破往往意外出现，预测新研究领域的形成仍是一个重大挑战。

Method: 构建年度共现图，节点为研究子领域并包含语义嵌入，边为领域共现关系并带有时间戳。使用先进的时间图架构进行链接预测，特别关注首次连接。

Result: 实验表明：(i) 使用领域的长文本描述嵌入显著提升预测精度；(ii) 不同模型在不同评估设置下表现优异。案例分析显示FOS的顶级链接预测与后续实际出现的领域配对一致。

Conclusion: FOS基准的发布为预测科学前沿提供了可复现的研究平台，有助于推动跨学科研究预测的发展。

Abstract: Interdisciplinary scientific breakthroughs mostly emerge unexpectedly, and forecasting the formation of novel research fields remains a major challenge. We introduce FOS (Future Of Science), a comprehensive time-aware graph-based benchmark that reconstructs annual co-occurrence graphs of 65,027 research sub-fields (spanning 19 general domains) over the period 1827-2024. In these graphs, edges denote the co-occurrence of two fields in a single publication and are timestamped with the corresponding publication year. Nodes are enriched with semantic embeddings, and edges are characterized by temporal and topological descriptors. We formulate the prediction of new field-pair linkages as a temporal link-prediction task, emphasizing the "first-time" connections that signify pioneering interdisciplinary directions. Through extensive experiments, we evaluate a suite of state-of-the-art temporal graph architectures under multiple negative-sampling regimes and show that (i) embedding long-form textual descriptions of fields significantly boosts prediction accuracy, and (ii) distinct model classes excel under different evaluation settings. Case analyses show that top-ranked link predictions on FOS align with field pairings that emerge in subsequent years of academic publications. We publicly release FOS, along with its temporal data splits and evaluation code, to establish a reproducible benchmark for advancing research in predicting scientific frontiers.

</details>


### [461] [The Locally Deployable Virtual Doctor: LLM Based Human Interface for Automated Anamnesis and Database Conversion](https://arxiv.org/abs/2511.18632)
*Jan Benedikt Ruhland,Doguhan Bahcivan,Jan-Peter Sowa,Ali Canbay,Dominik Heider*

Main category: cs.LG

TL;DR: 介绍了MedChat，一个本地可部署的虚拟医生框架，集成了基于LLM的医疗聊天机器人和扩散驱动的虚拟形象，用于自动化和结构化的病史采集。


<details>
  <summary>Details</summary>
Motivation: 利用大型语言模型的进展，在满足严格数据保护和患者隐私要求的同时，实现临床环境中的本地AI系统部署。

Method: 使用真实和合成医疗对话的混合语料库对聊天机器人进行微调，通过低秩适应优化模型效率；实现安全隔离的数据库接口；使用条件扩散模型在潜在空间生成虚拟形象，与音频特征同步。

Result: 证明了完全离线、本地可部署的LLM-扩散框架在临床病史采集中的可行性，模型表现出平滑收敛和良好的泛化能力。

Conclusion: 该系统为AI辅助临床病史采集提供了一个隐私保护、资源高效的基础，适用于低成本设置。

Abstract: Recent advances in large language models made it possible to achieve high conversational performance with substantially reduced computational demands, enabling practical on-site deployment in clinical environments. Such progress allows for local integration of AI systems that uphold strict data protection and patient privacy requirements, yet their secure implementation in medicine necessitates careful consideration of ethical, regulatory, and technical constraints.
  In this study, we introduce MedChat, a locally deployable virtual physician framework that integrates an LLM-based medical chatbot with a diffusion-driven avatar for automated and structured anamnesis. The chatbot was fine-tuned using a hybrid corpus of real and synthetically generated medical dialogues, while model efficiency was optimized via Low-Rank Adaptation. A secure and isolated database interface was implemented to ensure complete separation between patient data and the inference process. The avatar component was realized through a conditional diffusion model operating in latent space, trained on researcher video datasets and synchronized with mel-frequency audio features for realistic speech and facial animation.
  Unlike existing cloud-based systems, this work demonstrates the feasibility of a fully offline, locally deployable LLM-diffusion framework for clinical anamnesis. The autoencoder and diffusion networks exhibited smooth convergence, and MedChat achieved stable fine-tuning with strong generalization to unseen data. The proposed system thus provides a privacy-preserving, resource-efficient foundation for AI-assisted clinical anamnesis, also in low-cost settings.

</details>


### [462] [Kitty: Accurate and Efficient 2-bit KV Cache Quantization with Dynamic Channel-wise Precision Boost](https://arxiv.org/abs/2511.18643)
*Haojun Xia,Xiaoxia Wu,Jisen Li,Robert Wu,Junxiong Wang,Jue Wang,Chenxi Li,Aman Singhal,Alay Dilipbhai Shah,Alpay Ariyak,Donglin Zhuang,Zhongzhu Zhou,Ben Athiwaratkun,Zhen Zheng,Shuaiwen Leon Song*

Main category: cs.LG

TL;DR: Kitty是一种算法-系统协同设计的混合精度KV缓存方法，通过动态通道级精度提升技术，在接近2-bit内存占用的同时保持接近零的精度损失，实现了KV内存减少近8倍和吞吐量提升2.1-4.1倍。


<details>
  <summary>Details</summary>
Motivation: KV缓存是LLM推理的主要内存瓶颈，4-bit KV量化能保持精度但2-bit量化在长上下文推理中会显著降低精度，需要解决这一差距。

Method: 采用动态通道级精度提升算法，对Key缓存通道按敏感性排序，仅保留少量高敏感通道使用更高精度；系统层面设计页面中心KV布局、Triton兼容的页面反量化内核和轻量级运行时流水线，保持内存访问的合并性和避免发散。

Result: 在7个任务和两个模型家族(Qwen3、LLaMA3)上测试，Kitty将KV内存减少近8倍，精度损失可忽略，在相同内存预算下支持最多8倍大的批次和2.1-4.1倍的吞吐量提升。

Conclusion: Kitty通过算法-系统协同设计成功解决了2-bit KV量化带来的精度损失问题，为LLM推理提供了高效的内存优化方案。

Abstract: The KV cache is a dominant memory bottleneck for LLM inference. While 4-bit KV quantization preserves accuracy, 2-bit often degrades it, especially on long-context reasoning. We close this gap via an algorithm-system co-design for mixed-precision KV caching: Kitty. On the algorithm side, extensive experiments show that Dynamic Channel-wise Precision Boost -- which ranks Key-cache channels by sensitivity and keeps only a small fraction at higher precision -- maintains near-zero loss in accuracy drop while approaching 2-bit memory. The main challenge is handling dynamic 4-bit channel boosts while keeping the page layout coalesced and the dequantization uniform, with no scattered reads or hard-coded masks. Kitty addresses these issues by decompose each mixed-precision Key page into two tensors with unified 2-bit precision. Based on this, Kitty provides a page-centric KV layout, Triton-compatible page dequantization kernels, and a lightweight runtime pipeline that preserves coalescing and avoids divergence. Across seven tasks and two model families (Qwen3, LLaMA3), Kitty cuts KV memory by nearly 8x with negligible accuracy loss, enabling up to 8x larger batches and 2.1x-4.1x higher throughput under the same memory budget. We release the full implementation of Kitty at https://github.com/Summer-Summer/Kitty.

</details>


### [463] [Subtract the Corruption: Training-Data-Free Corrective Machine Unlearning using Task Arithmetic](https://arxiv.org/abs/2511.18660)
*Mostafa Mozafari,Farooq Ahmad Wani,Maria Sofia Bucarelli,Fabrizio Silvestri*

Main category: cs.LG

TL;DR: 提出了一种无需原始训练数据的校正性机器遗忘方法CUTS，通过代理集在权重空间进行任务算术来消除模型中的污染影响


<details>
  <summary>Details</summary>
Motivation: 现实世界中训练数据经常被污染，但传统校正性机器遗忘方法需要访问原始训练数据和确定的污染样本，这在很多实际场景中不可行

Method: CUTS方法：1）在代理集上微调污染模型以放大污染信号；2）计算污染模型与微调后模型的权重差异作为代理任务向量；3）减去校准后的任务向量来消除污染

Result: 在标签噪声情况下能恢复大部分丢失的性能，在后门攻击情况下几乎能完全消除攻击且对性能影响最小，在无源设置下优于现有专用CMU方法

Conclusion: CUTS为无需原始训练数据的校正性机器遗忘提供了有效解决方案，在严格的源自由设置下表现出色

Abstract: Corrupted training data are ubiquitous. Corrective Machine Unlearning (CMU) seeks to remove the influence of such corruption post-training. Prior CMU typically assumes access to identified corrupted training samples (a ``forget set''). However, in many real-world scenarios the training data are no longer accessible. We formalize \emph{source-free} CMU, where the original training data are unavailable and, consequently, no forget set of identified corrupted training samples can be specified. Instead, we assume a small proxy (surrogate) set of corrupted samples that reflect the suspected corruption type without needing to be the original training samples. In this stricter setting, methods relying on forget set are ineffective or narrow in scope. We introduce \textit{Corrective Unlearning in Task Space} (CUTS), a lightweight weight space correction method guided by the proxy set using task arithmetic principles. CUTS treats the clean and the corruption signal as distinct tasks. Specifically, we briefly fine-tune the corrupted model on the proxy to amplify the corruption mechanism in the weight space, compute the difference between the corrupted and fine-tuned weights as a proxy task vector, and subtract a calibrated multiple of this vector to cancel the corruption. Without access to clean data or a forget set, CUTS recovers a large fraction of the lost utility under label noise and, for backdoor triggers, nearly eliminates the attack with minimal damage to utility, outperforming state-of-the-art specialized CMU methods in source-free setting.

</details>


### [464] [Deterministic Continuous Replacement: Fast and Stable Module Replacement in Pretrained Transformers](https://arxiv.org/abs/2511.18670)
*Rowan Bradbury,Aniket Srinivasan Ashok,Sai Ram Kasanagottu,Gunmay Jhingran,Shuai Meng*

Main category: cs.LG

TL;DR: 提出确定性连续替换（DCR）方法，解决预训练模型中模块替换（特别是将二次自注意力替换为高效注意力）时的优化稳定性问题，通过确定性退火权重混合教师和学生输出，消除随机替换中的门控梯度方差。


<details>
  <summary>Details</summary>
Motivation: 预训练模型中模块替换（如用高效注意力替代二次自注意力）存在冷启动重新初始化破坏冻结骨干网络稳定性的核心挑战，需要解决优化稳定性问题。

Method: 确定性连续替换（DCR）方法，使用确定性退火权重混合教师模型和学生模型的输出，理论上消除随机门控带来的梯度方差。

Result: 在单种子研究中，DCR在受控注意力替换任务上比随机门控和蒸馏基线方法收敛更快、对齐效果更好。

Conclusion: DCR为异构算子交换建立了基础，解决了模块替换中的核心稳定性挑战。

Abstract: Replacing modules in pretrained models, especially swapping quadratic self-attention for efficient attention alternatives, poses a hard optimization problem: cold-start reinitialization destabilizes frozen backbones. We isolate this core stability challenge in a controlled study. Deterministic Continuous Replacement (DCR) blends teacher and student outputs with a deterministic, annealed weight. Theoretically, DCR eliminates gate-induced gradient variance inherent to stochastic replacement. In a single-seed study, DCR attains faster convergence and stronger alignment than stochastic gating and distillation baselines on controlled attention replacement, establishing a foundation for heterogeneous operator swaps.

</details>


### [465] [Multi-Agent Cross-Entropy Method with Monotonic Nonlinear Critic Decomposition](https://arxiv.org/abs/2511.18671)
*Yan Wang,Ke Deng,Yongli Ren*

Main category: cs.LG

TL;DR: 提出MCEM方法结合非线性评论家分解，通过提升高价值联合动作概率来避免多智能体强化学习中的集中式-分散式不匹配问题，在连续和离散动作基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体强化学习中集中式训练与分散式执行（CTDE）框架下的集中式-分散式不匹配（CDM）问题，克服现有值分解方法在表达能力和梯度需求之间的权衡困境。

Method: 提出多智能体交叉熵方法（MCEM）结合单调非线性评论家分解（NCD），通过提升高价值联合动作概率来排除次优行为；为提高样本效率，采用改进的k步回报和Retrace技术进行离策略学习。

Result: 分析和实验表明，MCEM在连续和离散动作基准测试中均优于现有最先进方法。

Conclusion: MCEM方法有效解决了CDM问题，在保持表达能力和避免集中式梯度需求的同时，显著提升了多智能体强化学习的性能。

Abstract: Cooperative multi-agent reinforcement learning (MARL) commonly adopts centralized training with decentralized execution (CTDE), where centralized critics leverage global information to guide decentralized actors. However, centralized-decentralized mismatch (CDM) arises when the suboptimal behavior of one agent degrades others' learning. Prior approaches mitigate CDM through value decomposition, but linear decompositions allow per-agent gradients at the cost of limited expressiveness, while nonlinear decompositions improve representation but require centralized gradients, reintroducing CDM. To overcome this trade-off, we propose the multi-agent cross-entropy method (MCEM), combined with monotonic nonlinear critic decomposition (NCD). MCEM updates policies by increasing the probability of high-value joint actions, thereby excluding suboptimal behaviors. For sample efficiency, we extend off-policy learning with a modified k-step return and Retrace. Analysis and experiments demonstrate that MCEM outperforms state-of-the-art methods across both continuous and discrete action benchmarks.

</details>


### [466] [QuantKAN: A Unified Quantization Framework for Kolmogorov Arnold Networks](https://arxiv.org/abs/2511.18689)
*Kazi Ahmed Asif Fuad,Lizhong Chen*

Main category: cs.LG

TL;DR: QuantKAN是一个统一的KAN网络量化框架，支持QAT和PTQ两种量化方式，将现代量化算法扩展到基于样条的KAN网络，并在多个数据集上建立了首个低比特样条网络的系统基准。


<details>
  <summary>Details</summary>
Motivation: KAN网络虽然具有强大的表达能力和可解释性，但其异构的样条和基础分支参数阻碍了高效量化，与CNN和Transformer相比，KAN的量化研究尚未得到充分探索。

Method: QuantKAN框架扩展了LSQ、LSQ+、PACT、DoReFa、QIL、GPTQ、BRECQ、AdaRound、AWQ、HAWQ-V2等现代量化算法，为基于样条的层设计了分支特定的量化器，涵盖基础、样条和激活组件。

Result: 实验表明KAN网络与低比特量化兼容，但存在强烈的架构-方法交互：浅层KAN模型在4位量化下LSQ、LSQ+和PACT能保持接近全精度性能，而DoReFa在深度KAGN的低比特设置下表现最稳定；PTQ中GPTQ和Uniform方法整体表现最佳。

Conclusion: QuantKAN框架统一了样条学习和量化，为在资源受限环境中高效部署KAN网络提供了实用工具和指导方针。

Abstract: Kolmogorov Arnold Networks (KANs) represent a new class of neural architectures that replace conventional linear transformations and node-based nonlinearities with spline-based function approximations distributed along network edges. Although KANs offer strong expressivity and interpretability, their heterogeneous spline and base branch parameters hinder efficient quantization, which remains unexamined compared to CNNs and Transformers. In this paper, we present QuantKAN, a unified framework for quantizing KANs across both quantization aware training (QAT) and post-training quantization (PTQ) regimes. QuantKAN extends modern quantization algorithms, such as LSQ, LSQ+, PACT, DoReFa, QIL, GPTQ, BRECQ, AdaRound, AWQ, and HAWQ-V2, to spline based layers with branch-specific quantizers for base, spline, and activation components. Through extensive experiments on MNIST, CIFAR 10, and CIFAR 100 across multiple KAN variants (EfficientKAN, FastKAN, PyKAN, and KAGN), we establish the first systematic benchmarks for low-bit spline networks. Our results show that KANs, particularly deeper KAGN variants, are compatible with low-bit quantization but exhibit strong method architecture interactions: LSQ, LSQ+, and PACT preserve near full precision accuracy at 4 bit for shallow KAN MLP and ConvNet models, while DoReFa provides the most stable behavior for deeper KAGN under aggressive low-bit settings. For PTQ, GPTQ and Uniform consistently deliver the strongest overall performance across datasets, with BRECQ highly competitive on simpler regimes such as MNIST. Our proposed QuantKAN framework thus unifies spline learning and quantization, and provides practical tools and guidelines for efficiently deploying KANs in real-world, resource-constrained environments.

</details>


### [467] [VLM in a flash: I/O-Efficient Sparsification of Vision-Language Model via Neuron Chunking](https://arxiv.org/abs/2511.18692)
*Kichang Yang,Seonjun Kim,Minjae Kim,Nairan Zhang,Chi Zhang,Youngki Lee*

Main category: cs.LG

TL;DR: Neuron Chunking是一种I/O高效稀疏化策略，通过将神经元重要性评估与存储访问成本相结合，在边缘设备上显著提升大型视觉语言模型的部署效率。


<details>
  <summary>Details</summary>
Motivation: 传统稀疏化方法仅基于激活幅度选择神经元，忽略了访问模式对闪存性能的影响，导致边缘部署中基于闪存的权重卸载效率低下。

Method: 提出Neuron Chunking方法，在内存块级别进行操作，通过轻量级访问连续性抽象建模I/O延迟，选择具有高效用值（神经元重要性归一化后除以估计延迟）的块。

Result: 在Jetson Orin Nano和Jetson AGX Orin设备上，分别实现了4.65倍和5.76倍的I/O效率提升。

Conclusion: 通过将稀疏化决策与底层存储行为对齐，Neuron Chunking显著改善了边缘设备上大型视觉语言模型的部署效率。

Abstract: Edge deployment of large Vision-Language Models (VLMs) increasingly relies on flash-based weight offloading, where activation sparsification is used to reduce I/O overhead. However, conventional sparsification remains model-centric, selecting neurons solely by activation magnitude and neglecting how access patterns influence flash performance. We present Neuron Chunking, an I/O-efficient sparsification strategy that operates on chunks (i.e., groups of contiguous neurons in memory) and couples neuron importance with storage access cost. The method models I/O latency through a lightweight abstraction of access contiguity and selects chunks with high utility, defined as neuron importance normalized by estimated latency. By aligning sparsification decisions with the underlying storage behavior, Neuron Chunking improves I/O efficiency by up to 4.65x and 5.76x on Jetson Orin Nano and Jetson AGX Orin, respectively.

</details>


### [468] [GRIT-LP: Graph Transformer with Long-Range Skip Connection and Partitioned Spatial Graphs for Accurate Ice Layer Thickness Prediction](https://arxiv.org/abs/2511.18716)
*Zesheng Liu,Maryam Rahnemoonfar*

Main category: cs.LG

TL;DR: GRIT-LP是一种专为极地雷达图像冰层厚度估计设计的图变换器，通过分区空间图构建策略和长距离跳跃连接机制，解决了深度图变换器的过平滑和长距离依赖建模问题，在RMSE指标上比现有方法提升24.92%。


<details>
  <summary>Details</summary>
Motivation: 准确估计冰层厚度对于理解积雪积累、重建过去气候模式以及减少未来冰盖演化和海平面上升预测的不确定性至关重要。当前图变换器在深度上受到过平滑和弱长距离依赖建模的限制。

Method: GRIT-LP结合了归纳几何图学习框架和自注意力机制，采用两种创新：1）分区空间图构建策略，形成重叠的完全连接局部邻域以保持空间一致性并抑制无关长距离链接的噪声；2）变换器内部的长距离跳跃连接机制，改善信息流并缓解深层注意力层的过平滑问题。

Result: 大量实验表明，GRIT-LP在均方根误差上比当前最先进方法提升24.92%，表现出色。

Conclusion: GRIT-LP有效证明了图变换器在建模时空模式方面的能力，能够同时捕捉局部结构特征和冰层内部的长距离依赖关系，有潜力推动数据驱动的冰冻圈过程理解。

Abstract: Graph transformers have demonstrated remarkable capability on complex spatio-temporal tasks, yet their depth is often limited by oversmoothing and weak long-range dependency modeling. To address these challenges, we introduce GRIT-LP, a graph transformer explicitly designed for polar ice-layer thickness estimation from polar radar imagery. Accurately estimating ice layer thickness is critical for understanding snow accumulation, reconstructing past climate patterns and reducing uncertainties in projections of future ice sheet evolution and sea level rise. GRIT-LP combines an inductive geometric graph learning framework with self-attention mechanism, and introduces two major innovations that jointly address challenges in modeling the spatio-temporal patterns of ice layers: a partitioned spatial graph construction strategy that forms overlapping, fully connected local neighborhoods to preserve spatial coherence and suppress noise from irrelevant long-range links, and a long-range skip connection mechanism within the transformer that improves information flow and mitigates oversmoothing in deeper attention layers. We conducted extensive experiments, demonstrating that GRIT-LP outperforms current state-of-the-art methods with a 24.92\% improvement in root mean squared error. These results highlight the effectiveness of graph transformers in modeling spatiotemporal patterns by capturing both localized structural features and long-range dependencies across internal ice layers, and demonstrate their potential to advance data-driven understanding of cryospheric processes.

</details>


### [469] [Towards Realistic Guarantees: A Probabilistic Certificate for SmoothLLM](https://arxiv.org/abs/2511.18721)
*Adarsh Kumarappan,Ayushi Mehrotra*

Main category: cs.LG

TL;DR: 本文提出了一个更实用的概率框架(k, ε)-unstable来改进SmoothLLM防御，通过数据驱动的下界计算提供更可靠的安全认证。


<details>
  <summary>Details</summary>
Motivation: SmoothLLM防御虽然提供对抗越狱攻击的认证保证，但其依赖的严格k-unstable假设在实践中很少成立，限制了安全证书的可信度。

Method: 引入(k, ε)-unstable概率框架，结合攻击成功的经验模型，推导出SmoothLLM防御概率的新下界。

Result: 新框架能够为从基于梯度的GCG到语义的PAIR等多种越狱攻击提供防御认证，提供更实用的安全保证。

Conclusion: 这项工作为LLM安全部署贡献了实用且理论严谨的机制，使LLM更能抵抗对其安全对齐的利用。

Abstract: The SmoothLLM defense provides a certification guarantee against jailbreaking attacks, but it relies on a strict `k-unstable' assumption that rarely holds in practice. This strong assumption can limit the trustworthiness of the provided safety certificate. In this work, we address this limitation by introducing a more realistic probabilistic framework, `(k, $\varepsilon$)-unstable,' to certify defenses against diverse jailbreaking attacks, from gradient-based (GCG) to semantic (PAIR). We derive a new, data-informed lower bound on SmoothLLM's defense probability by incorporating empirical models of attack success, providing a more trustworthy and practical safety certificate. By introducing the notion of (k, $\varepsilon$)-unstable, our framework provides practitioners with actionable safety guarantees, enabling them to set certification thresholds that better reflect the real-world behavior of LLMs. Ultimately, this work contributes a practical and theoretically-grounded mechanism to make LLMs more resistant to the exploitation of their safety alignments, a critical challenge in secure AI deployment.

</details>


### [470] [LogSyn: A Few-Shot LLM Framework for Structured Insight Extraction from Unstructured General Aviation Maintenance Logs](https://arxiv.org/abs/2511.18727)
*Devansh Agarwal,Maitreyi Chatterjee,Biplab Chatterjee*

Main category: cs.LG

TL;DR: LogSyn是一个使用大型语言模型将飞机维护日志从非结构化文本转换为结构化数据的框架，通过少样本上下文学习实现问题解决叙述的摘要和事件分类。


<details>
  <summary>Details</summary>
Motivation: 飞机维护日志包含有价值的安全数据，但由于其非结构化文本格式而未被充分利用。

Method: 使用大型语言模型进行少样本上下文学习，在6,169条记录上执行受控抽象生成（CAG），总结问题解决叙述并在详细分层本体中分类事件。

Result: 该框架能够识别关键故障模式，为维护日志的语义结构化和可操作见解提取提供了可扩展的方法。

Conclusion: 这项工作为改进航空及相关行业的维护工作流程和预测分析提供了实用路径。

Abstract: Aircraft maintenance logs hold valuable safety data but remain underused due to their unstructured text format. This paper introduces LogSyn, a framework that uses Large Language Models (LLMs) to convert these logs into structured, machine-readable data. Using few-shot in-context learning on 6,169 records, LogSyn performs Controlled Abstraction Generation (CAG) to summarize problem-resolution narratives and classify events within a detailed hierarchical ontology. The framework identifies key failure patterns, offering a scalable method for semantic structuring and actionable insight extraction from maintenance logs. This work provides a practical path to improve maintenance workflows and predictive analytics in aviation and related industries.

</details>


### [471] [Reinforcement Learning for Self-Healing Material Systems](https://arxiv.org/abs/2511.18728)
*Maitreyi Chatterjee,Devansh Agarwal,Biplab Chatterjee*

Main category: cs.LG

TL;DR: 本研究将自愈合过程建模为强化学习问题，通过比较离散动作和连续动作智能体，发现TD3智能体在连续剂量控制方面表现出最佳性能。


<details>
  <summary>Details</summary>
Motivation: 向自主材料系统过渡需要自适应控制方法来最大化结构寿命，将自愈合过程构建为强化学习问题以实现资源消耗与结构完整性维护的平衡。

Method: 在马尔可夫决策过程框架下，比较了离散动作（Q-learning、DQN）和连续动作（TD3）智能体在随机仿真环境中的表现。

Result: 强化学习控制器显著优于启发式基线方法，实现近乎完全的材料恢复，其中TD3智能体在收敛速度和稳定性方面表现最优。

Conclusion: 连续剂量控制在动态自愈合应用中具有必要性，精细化的比例驱动对于实现高效自愈合至关重要。

Abstract: The transition to autonomous material systems necessitates adaptive control methodologies to maximize structural longevity. This study frames the self-healing process as a Reinforcement Learning (RL) problem within a Markov Decision Process (MDP), enabling agents to autonomously derive optimal policies that efficiently balance structural integrity maintenance against finite resource consumption. A comparative evaluation of discrete-action (Q-learning, DQN) and continuous-action (TD3) agents in a stochastic simulation environment revealed that RL controllers significantly outperform heuristic baselines, achieving near-complete material recovery. Crucially, the TD3 agent utilizing continuous dosage control demonstrated superior convergence speed and stability, underscoring the necessity of fine-grained, proportional actuation in dynamic self-healing applications.

</details>


### [472] [Large-Scale In-Game Outcome Forecasting for Match, Team and Players in Football using an Axial Transformer Neural Network](https://arxiv.org/abs/2511.18730)
*Michael Horton,Patrick Lucey*

Main category: cs.LG

TL;DR: 提出基于轴向变换器的神经网络，用于在足球比赛中实时预测每位球员、每支球队和比赛级别的13种动作总数。


<details>
  <summary>Details</summary>
Motivation: 准确预测足球比赛中球员的动作总数对于战术决策、体育博彩和电视转播分析等应用具有重要意义，需要考虑比赛状态、球员能力、球员互动和比赛动态。

Method: 使用基于轴向变换器的神经网络，该网络能够高效捕捉比赛进展的时间动态和每个时间步球员之间的互动，并提出了一种新颖的轴向变换器设计。

Result: 模型能够进行一致可靠的预测，并以低延迟为每场比赛高效生成约75,000个实时预测。

Conclusion: 该轴向变换器设计在实验上表现良好，能够有效处理足球比赛的复杂动态和球员互动。

Abstract: Football (soccer) is a sport that is characterised by complex game play, where players perform a variety of actions, such as passes, shots, tackles, fouls, in order to score goals, and ultimately win matches. Accurately forecasting the total number of each action that each player will complete during a match is desirable for a variety of applications, including tactical decision-making, sports betting, and for television broadcast commentary and analysis. Such predictions must consider the game state, the ability and skill of the players in both teams, the interactions between the players, and the temporal dynamics of the game as it develops. In this paper, we present a transformer-based neural network that jointly and recurrently predicts the expected totals for thirteen individual actions at multiple time-steps during the match, and where predictions are made for each individual player, each team and at the game-level. The neural network is based on an \emph{axial transformer} that efficiently captures the temporal dynamics as the game progresses, and the interactions between the players at each time-step. We present a novel axial transformer design that we show is equivalent to a regular sequential transformer, and the design performs well experimentally. We show empirically that the model can make consistent and reliable predictions, and efficiently makes $\sim$75,000 live predictions at low latency for each game.

</details>


### [473] [OceanForecastBench: A Benchmark Dataset for Data-Driven Global Ocean Forecasting](https://arxiv.org/abs/2511.18732)
*Haoming Jia,Yi Han,Xiang Wang,Huizan Wang,Wei Wu,Jianming Zheng,Peikun Xiao*

Main category: cs.LG

TL;DR: 提出了OceanForecastBench基准，解决数据驱动海洋预报模型缺乏开源标准化基准的问题，提供28年高质量再分析数据、可靠观测数据评估和完整评估流程。


<details>
  <summary>Details</summary>
Motivation: 当前数据驱动的深度学习海洋预报模型（如XiHe、WenHai等）发展迅速，但缺乏开源标准化基准导致数据使用和评估方法不一致，阻碍了模型开发、公平比较和跨学科合作。

Method: 构建OceanForecastBench基准，包含三个核心贡献：28年高质量全球海洋再分析数据（4个海洋变量×23深度层+4个海表变量）；基于卫星和现场观测的可靠评估数据（覆盖约1亿个位置）；包含6个典型基线模型的评估流程和多角度性能评估框架。

Result: OceanForecastBench是目前最全面的数据驱动海洋预报基准框架，为模型开发、评估和比较提供了开源平台。数据集和代码已公开。

Conclusion: 该基准解决了海洋预报领域缺乏标准化评估的问题，将促进数据驱动海洋预报模型的公平比较和跨学科合作发展。

Abstract: Global ocean forecasting aims to predict key ocean variables such as temperature, salinity, and currents, which is essential for understanding and describing oceanic phenomena. In recent years, data-driven deep learning-based ocean forecast models, such as XiHe, WenHai, LangYa and AI-GOMS, have demonstrated significant potential in capturing complex ocean dynamics and improving forecasting efficiency. Despite these advancements, the absence of open-source, standardized benchmarks has led to inconsistent data usage and evaluation methods. This gap hinders efficient model development, impedes fair performance comparison, and constrains interdisciplinary collaboration. To address this challenge, we propose OceanForecastBench, a benchmark offering three core contributions: (1) A high-quality global ocean reanalysis data over 28 years for model training, including 4 ocean variables across 23 depth levels and 4 sea surface variables. (2) A high-reliability satellite and in-situ observations for model evaluation, covering approximately 100 million locations in the global ocean. (3) An evaluation pipeline and a comprehensive benchmark with 6 typical baseline models, leveraging observations to evaluate model performance from multiple perspectives. OceanForecastBench represents the most comprehensive benchmarking framework currently available for data-driven ocean forecasting, offering an open-source platform for model development, evaluation, and comparison. The dataset and code are publicly available at: https://github.com/Ocean-Intelligent-Forecasting/OceanForecastBench.

</details>


### [474] [Sampling Control for Imbalanced Calibration in Semi-Supervised Learning](https://arxiv.org/abs/2511.18773)
*Senmao Tian,Xiang Wei,Shunli Zhang*

Main category: cs.LG

TL;DR: SC-SSL是一个统一的半监督学习框架，通过解耦采样控制来抑制模型偏差，解决类别不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有的半监督学习方法在处理类别不平衡时往往以粗粒度方式调整logits，混淆了数据不平衡和类特定学习难度引起的偏差。

Method: 提出SC-SSL框架，在训练阶段通过识别关键采样控制变量、引入显式扩展能力的分类器、自适应调整采样概率来缓解特征级不平衡；在推理阶段分析线性分类器的权重不平衡，应用后处理采样控制优化偏置向量来校准logits。

Result: 在多个基准数据集和分布设置下的广泛实验验证了SC-SSL的一致性和最先进性能。

Conclusion: SC-SSL通过解耦采样控制有效解决了半监督学习中的类别不平衡问题，在抑制模型偏差方面表现出色。

Abstract: Class imbalance remains a critical challenge in semi-supervised learning (SSL), especially when distributional mismatches between labeled and unlabeled data lead to biased classification. Although existing methods address this issue by adjusting logits based on the estimated class distribution of unlabeled data, they often handle model imbalance in a coarse-grained manner, conflating data imbalance with bias arising from varying class-specific learning difficulties. To address this issue, we propose a unified framework, SC-SSL, which suppresses model bias through decoupled sampling control. During training, we identify the key variables for sampling control under ideal conditions. By introducing a classifier with explicit expansion capability and adaptively adjusting sampling probabilities across different data distributions, SC-SSL mitigates feature-level imbalance for minority classes. In the inference phase, we further analyze the weight imbalance of the linear classifier and apply post-hoc sampling control with an optimization bias vector to directly calibrate the logits. Extensive experiments across various benchmark datasets and distribution settings validate the consistency and state-of-the-art performance of SC-SSL.

</details>


### [475] [SAOT: An Enhanced Locality-Aware Spectral Transformer for Solving PDEs](https://arxiv.org/abs/2511.18777)
*Chenhong Zhou,Jie Chen,Zaifeng Yang*

Main category: cs.LG

TL;DR: 提出了一种结合小波变换空间频率局部化特性的Transformer架构，通过小波注意力模块和谱注意力算子Transformer来解决傅里叶神经算子在PDE求解中的过平滑问题


<details>
  <summary>Details</summary>
Motivation: 傅里叶神经算子（FNO）通过傅里叶空间实现全局卷积，但往往导致解过平滑，无法捕捉局部细节和高频分量。需要结合小波变换的局部化特性来改进

Method: 提出小波注意力（WA）模块，具有线性计算复杂度，有效学习局部感知特征。基于WA开发谱注意力算子Transformer（SAOT），通过门控融合块将WA的局部关注与傅里叶注意力的全局感受野相结合

Result: WA显著缓解了FA的局限性，大幅优于现有基于小波的神经算子。SAOT在六个算子学习基准上达到最先进性能，并表现出强大的离散不变性能力

Conclusion: 通过整合局部感知和全局谱表示，SAOT框架有效解决了FNO的过平滑问题，在PDE算子学习中取得了优异性能

Abstract: Neural operators have shown great potential in solving a family of Partial Differential Equations (PDEs) by modeling the mappings between input and output functions. Fourier Neural Operator (FNO) implements global convolutions via parameterizing the integral operators in Fourier space. However, it often results in over-smoothing solutions and fails to capture local details and high-frequency components. To address these limitations, we investigate incorporating the spatial-frequency localization property of Wavelet transforms into the Transformer architecture. We propose a novel Wavelet Attention (WA) module with linear computational complexity to efficiently learn locality-aware features. Building upon WA, we further develop the Spectral Attention Operator Transformer (SAOT), a hybrid spectral Transformer framework that integrates WA's localized focus with the global receptive field of Fourier-based Attention (FA) through a gated fusion block. Experimental results demonstrate that WA significantly mitigates the limitations of FA and outperforms existing Wavelet-based neural operators by a large margin. By integrating the locality-aware and global spectral representations, SAOT achieves state-of-the-art performance on six operator learning benchmarks and exhibits strong discretization-invariant ability.

</details>


### [476] [Hypergraph Contrastive Learning for both Homophilic and Heterophilic Hypergraphs](https://arxiv.org/abs/2511.18783)
*Renchu Guan,Xuyang Li,Yachao Zhang,Wei Pang,Fausto Giunchiglia,Ximing Li,Yonghao Liu,Xiaoyue Feng*

Main category: cs.LG

TL;DR: HONOR是一个新型的无监督超图对比学习框架，适用于同配性和异配性超图，通过提示机制和自适应注意力聚合来建模异配性关系


<details>
  <summary>Details</summary>
Motivation: 现有超图神经网络大多基于同配性假设，但现实场景中常存在显著的异配性结构，需要能够同时处理两种关系的模型

Method: 提出提示机制的超边特征构建策略和自适应注意力聚合模块，结合高通滤波来充分利用异配性连接模式

Result: 理论和实验证明HONOR具有优越的泛化能力和鲁棒性，在多种数据集上优于现有最先进方法

Conclusion: HONOR框架能够有效建模超图中的异配性关系，在同配性和异配性数据集上都表现出色

Abstract: Hypergraphs, as a generalization of traditional graphs, naturally capture high-order relationships. In recent years, hypergraph neural networks (HNNs) have been widely used to capture complex high-order relationships. However, most existing hypergraph neural network methods inherently rely on the homophily assumption, which often does not hold in real-world scenarios that exhibit significant heterophilic structures. To address this limitation, we propose \textbf{HONOR}, a novel unsupervised \textbf{H}ypergraph c\textbf{ON}trastive learning framework suitable for both hom\textbf{O}philic and hete\textbf{R}ophilic hypergraphs. Specifically, HONOR explicitly models the heterophilic relationships between hyperedges and nodes through two complementary mechanisms: a prompt-based hyperedge feature construction strategy that maintains global semantic consistency while suppressing local noise, and an adaptive attention aggregation module that dynamically captures the diverse local contributions of nodes to hyperedges. Combined with high-pass filtering, these designs enable HONOR to fully exploit heterophilic connection patterns, yielding more discriminative and robust node and hyperedge representations. Theoretically, we demonstrate the superior generalization ability and robustness of HONOR. Empirically, extensive experiments further validate that HONOR consistently outperforms state-of-the-art baselines under both homophilic and heterophilic datasets.

</details>


### [477] [Doubly Wild Refitting: Model-Free Evaluation of High Dimensional Black-Box Predictions under Convex Losses](https://arxiv.org/abs/2511.18789)
*Haichen Hu,David Simchi-Levi*

Main category: cs.LG

TL;DR: 提出了一种高效的再拟合程序，用于在固定设计设置下计算经验风险最小化的超额风险，并提供高概率上界。该方法仅需黑盒训练算法和单个数据集，无需函数类复杂度的先验知识。


<details>
  <summary>Details</summary>
Motivation: 传统基于容量的学习理论对于现代复杂机器学习系统（如深度神经网络和生成模型）变得不可行，因为这些假设类过于复杂。需要一种模型无关的方法来理论评估这些不透明的系统。

Method: 通过随机扰动梯度向量生成两组人工修改的伪输出（wild response），然后使用这些伪标记数据集对黑盒程序进行两次再拟合，得到两个wild predictor。最后利用原始预测器、两个wild predictor和构造的wild response推导出有效的超额风险上界。

Result: 该方法能够高效计算超额风险并提供高概率上界，且不需要函数类复杂度的先验知识，具有模型无关的特性。

Conclusion: 该方法为理论上评估现代不透明机器学习系统提供了有前景的解决方案，特别适用于深度神经网络和生成模型等复杂模型，突破了传统容量基学习理论的局限性。

Abstract: We study the problem of excess risk evaluation for empirical risk minimization (ERM) under general convex loss functions. Our contribution is an efficient refitting procedure that computes the excess risk and provides high-probability upper bounds under the fixed-design setting. Assuming only black-box access to the training algorithm and a single dataset, we begin by generating two sets of artificially modified pseudo-outcomes termed wild response, created by stochastically perturbing the gradient vectors with carefully chosen scaling. Using these two pseudo-labeled datasets, we then refit the black-box procedure twice to obtain two corresponding wild predictors. Finally, leveraging the original predictor, the two wild predictors, and the constructed wild responses, we derive an efficient excess risk upper bound. A key feature of our analysis is that it requires no prior knowledge of the complexity of the underlying function class. As a result, the method is essentially model-free and holds significant promise for theoretically evaluating modern opaque machine learning system--such as deep nerral networks and generative model--where traditional capacity-based learning theory becomes infeasible due to the extreme complexity of the hypothesis class.

</details>


### [478] [Towards Characterizing Knowledge Distillation of PPG Heart Rate Estimation Models](https://arxiv.org/abs/2511.18829)
*Kanav Arora,Girish Narayanswamy,Shwetak Patel,Richard Li*

Main category: cs.LG

TL;DR: 本文研究了如何将大型预训练PPG模型蒸馏为适合边缘设备实时推理的小型模型，评估了四种蒸馏策略并描述了模型大小与性能之间的缩放规律。


<details>
  <summary>Details</summary>
Motivation: 虽然深度学习模型在心率估计任务中表现出色，但要在可穿戴设备上部署这些模型，必须满足严格的内存和延迟限制。

Method: 评估了四种蒸馏策略：硬蒸馏、软蒸馏、解耦知识蒸馏和特征蒸馏，通过全面扫描教师和学生模型容量来研究缩放规律。

Result: 提出了描述模型大小与性能关系的缩放规律，为构建可部署于边缘设备的生理传感模型奠定了基础。

Conclusion: 这项早期研究为构建实用且可预测的边缘可部署生理传感模型奠定了基础。

Abstract: Heart rate estimation from photoplethysmography (PPG) signals generated by wearable devices such as smartwatches and fitness trackers has significant implications for the health and well-being of individuals. Although prior work has demonstrated deep learning models with strong performance in the heart rate estimation task, in order to deploy these models on wearable devices, these models must also adhere to strict memory and latency constraints. In this work, we explore and characterize how large pre-trained PPG models may be distilled to smaller models appropriate for real-time inference on the edge. We evaluate four distillation strategies through comprehensive sweeps of teacher and student model capacities: (1) hard distillation, (2) soft distillation, (3) decoupled knowledge distillation (DKD), and (4) feature distillation. We present a characterization of the resulting scaling laws describing the relationship between model size and performance. This early investigation lays the groundwork for practical and predictable methods for building edge-deployable models for physiological sensing.

</details>


### [479] [Leveraging Duration Pseudo-Embeddings in Multilevel LSTM and GCN Hypermodels for Outcome-Oriented PPM](https://arxiv.org/abs/2511.18830)
*Fang Wang,Paolo Ceravolo,Ernesto Damiani*

Main category: cs.LG

TL;DR: 提出了一种针对预测性过程监控的双输入神经网络策略，通过分离事件和序列属性，使用持续时间感知的伪嵌入矩阵将时间重要性转换为紧凑的可学习表示，有效解决了时间不规则性问题。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习模型在处理预测性过程监控时难以应对时间不规则性，特别是随机事件持续时间和重叠时间戳问题，限制了模型在不同数据集上的适应性。

Method: 设计双输入神经网络策略，分离事件和序列属性，使用持续时间感知伪嵌入矩阵。在B-LSTM和B-GCN两个基线家族基础上开发了持续时间感知变体D-LSTM和D-GCN，所有模型都包含自调超模型进行自适应架构选择。

Result: 在平衡和不平衡结果预测任务上的实验表明，持续时间伪嵌入输入能持续提高泛化能力，降低模型复杂度，并增强可解释性。

Conclusion: 研究结果证明了显式时间编码的优势，为稳健的实时预测性过程监控应用提供了灵活的设计方案。

Abstract: Existing deep learning models for Predictive Process Monitoring (PPM) struggle with temporal irregularities, particularly stochastic event durations and overlapping timestamps, limiting their adaptability across heterogeneous datasets. We propose a dual input neural network strategy that separates event and sequence attributes, using a duration-aware pseudo-embedding matrix to transform temporal importance into compact, learnable representations. This design is implemented across two baseline families: B-LSTM and B-GCN, and their duration-aware variants D-LSTM and D-GCN. All models incorporate self-tuned hypermodels for adaptive architecture selection. Experiments on balanced and imbalanced outcome prediction tasks show that duration pseudo-embedding inputs consistently improve generalization, reduce model complexity, and enhance interpretability. Our results demonstrate the benefits of explicit temporal encoding and provide a flexible design for robust, real-world PPM applications.

</details>


### [480] [Auto-ML Graph Neural Network Hypermodels for Outcome Prediction in Event-Sequence Data](https://arxiv.org/abs/2511.18835)
*Fang Wang,Lance Kosca,Adrienne Kosca,Marko Gacesa,Ernesto Damiani*

Main category: cs.LG

TL;DR: HGNN(O)是一个基于AutoML的图神经网络超模型框架，用于事件序列数据的结局预测。它扩展了四种架构和六种GNN算子，通过贝叶斯优化实现自调优，无需手动配置。


<details>
  <summary>Details</summary>
Motivation: 为了解决复杂事件序列数据中结局预测的挑战，特别是需要处理平衡和不平衡数据集的问题，同时避免手动配置GNN架构和超参数的繁琐过程。

Method: 基于图卷积网络超模型，扩展了四种架构（One Level, Two Level, Two Level Pseudo Embedding, Two Level Embedding）和六种GNN算子，采用基于贝叶斯优化的自调优机制，包含剪枝和早停策略。

Result: 在Traffic Fines数据集上准确率超过0.98，在Patients数据集上加权F1分数达到0.86，且无需显式处理不平衡问题。

Conclusion: HGNN(O)为复杂事件序列数据的结局预测提供了一个鲁棒且可推广的AutoML-GNN基准方法。

Abstract: This paper introduces HGNN(O), an AutoML GNN hypermodel framework for outcome prediction on event-sequence data. Building on our earlier work on graph convolutional network hypermodels, HGNN(O) extends four architectures-One Level, Two Level, Two Level Pseudo Embedding, and Two Level Embedding-across six canonical GNN operators. A self-tuning mechanism based on Bayesian optimization with pruning and early stopping enables efficient adaptation over architectures and hyperparameters without manual configuration. Empirical evaluation on both balanced and imbalanced event logs shows that HGNN(O) achieves accuracy exceeding 0.98 on the Traffic Fines dataset and weighted F1 scores up to 0.86 on the Patients dataset without explicit imbalance handling. These results demonstrate that the proposed AutoML-GNN approach provides a robust and generalizable benchmark for outcome prediction in complex event-sequence data.

</details>


### [481] [Federated style aware transformer aggregation of representations](https://arxiv.org/abs/2511.18841)
*Mincheol Jeon,Euinam Huh*

Main category: cs.LG

TL;DR: FedSTAR是一个风格感知的联邦学习框架，通过解耦客户端特定风格因子和共享内容表示来解决个性化联邦学习中的数据异构性和通信约束问题。


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习缺乏个性化，单一全局模型无法捕捉客户端特定特征，导致预测偏差和泛化能力差，特别是在数据分布差异大的客户端上。

Method: 使用Transformer注意力机制聚合类原型，通过内容-风格解耦交换紧凑原型和风格向量而非完整模型参数，显著降低通信开销。

Result: 实验结果表明，结合内容-风格解耦和注意力驱动原型聚合在不增加通信成本的情况下提高了异构环境中的个性化和鲁棒性。

Conclusion: FedSTAR框架有效解决了PFL中的域异构、数据不平衡和通信约束问题，通过风格感知机制实现了更好的个性化性能。

Abstract: Personalized Federated Learning (PFL) faces persistent challenges, including domain heterogeneity from diverse client data, data imbalance due to skewed participation, and strict communication constraints. Traditional federated learning often lacks personalization, as a single global model cannot capture client-specific characteristics, leading to biased predictions and poor generalization, especially for clients with highly divergent data distributions.
  To address these issues, we propose FedSTAR, a style-aware federated learning framework that disentangles client-specific style factors from shared content representations. FedSTAR aggregates class-wise prototypes using a Transformer-based attention mechanism, allowing the server to adaptively weight client contributions while preserving personalization.
  Furthermore, by exchanging compact prototypes and style vectors instead of full model parameters, FedSTAR significantly reduces communication overhead. Experimental results demonstrate that combining content-style disentanglement with attention-driven prototype aggregation improves personalization and robustness in heterogeneous environments without increasing communication cost.

</details>


### [482] [WaveTuner: Comprehensive Wavelet Subband Tuning for Time Series Forecasting](https://arxiv.org/abs/2511.18846)
*Yubo Wang,Hui He,Chaoxi Niu,Zhendong Niu*

Main category: cs.LG

TL;DR: WaveTuner是一个基于小波分解的时间序列预测框架，通过全频谱子带调谐来解决现有方法对高频分量利用不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于小波的方法存在对高频分量利用不足的偏见，而这些高频分量对于精确的时间序列预测至关重要。

Method: WaveTuner包含两个关键模块：自适应小波细化模块（将时间序列转换为时频系数并生成子带特定嵌入）和多分支专业化模块（使用多个KAN网络分别建模不同频谱子带）。

Result: 在八个真实世界数据集上的广泛实验表明，WaveTuner在时间序列预测中达到了最先进的性能。

Conclusion: WaveTuner通过统一的时频框架全面调谐全局趋势和局部变化，有效解决了多尺度时间模式建模的挑战。

Abstract: Due to the inherent complexity, temporal patterns in real-world time series often evolve across multiple intertwined scales, including long-term periodicity, short-term fluctuations, and abrupt regime shifts. While existing literature has designed many sophisticated decomposition approaches based on the time or frequency domain to partition trend-seasonality components and high-low frequency components, an alternative line of approaches based on the wavelet domain has been proposed to provide a unified multi-resolution representation with precise time-frequency localization. However, most wavelet-based methods suffer from a persistent bias toward recursively decomposing only low-frequency components, severely underutilizing subtle yet informative high-frequency components that are pivotal for precise time series forecasting. To address this problem, we propose WaveTuner, a Wavelet decomposition framework empowered by full-spectrum subband Tuning for time series forecasting. Concretely, WaveTuner comprises two key modules: (i) Adaptive Wavelet Refinement module, that transforms time series into time-frequency coefficients, utilizes an adaptive router to dynamically assign subband weights, and generates subband-specific embeddings to support refinement; and (ii) Multi-Branch Specialization module, that employs multiple functional branches, each instantiated as a flexible Kolmogorov-Arnold Network (KAN) with a distinct functional order to model a specific spectral subband. Equipped with these modules, WaveTuner comprehensively tunes global trends and local variations within a unified time-frequency framework. Extensive experiments on eight real-world datasets demonstrate WaveTuner achieves state-of-the-art forecasting performance in time series forecasting.

</details>


### [483] [Robust and Generalizable GNN Fine-Tuning via Uncertainty-aware Adapter Learning](https://arxiv.org/abs/2511.18859)
*Bo Jiang,Weijun Zhao,Beibei Wang,Xiao Wang,Jin Tang*

Main category: cs.LG

TL;DR: 提出了一种不确定性感知的GNN适配器（UAdapterGNN），通过在GNN微调过程中集成不确定性学习来增强模型对噪声图数据的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的AdapterGNN方法在面对下游任务中的噪声图数据（如噪声边和模糊节点属性）时容易受到干扰，表现出有限的泛化能力。如何增强GNN微调的鲁棒性和泛化能力是一个亟待解决的问题。

Method: UAdapterGNN利用高斯概率适配器来增强预训练的GNN模型，通过自动吸收高斯分布方差变化的影响来提升模型鲁棒性。与常规AdapterGNN不同，该方法能够更好地处理图数据中的各种噪声。

Result: 在多个基准测试上的广泛实验表明，UAdapterGNN方法具有有效性、鲁棒性和高泛化能力。

Conclusion: 通过将不确定性学习集成到GNN适配器中，可以显著增强预训练GNN模型对噪声图数据的鲁棒性，并进一步提升模型在下游任务中的泛化能力。

Abstract: Recently, fine-tuning large-scale pre-trained GNNs has yielded remarkable attention in adapting pre-trained GNN models for downstream graph learning tasks. One representative fine-tuning method is to exploit adapter (termed AdapterGNN) which aims to 'augment' the pre-trained model by inserting a lightweight module to make the 'augmented' model better adapt to the downstream tasks. However, graph data may contain various types of noise in downstream tasks, such as noisy edges and ambiguous node attributes. Existing AdapterGNNs are often prone to graph noise and exhibit limited generalizability. How to enhance the robustness and generalization ability of GNNs' fine tuning remains an open problem. In this paper, we show that the above problem can be well addressed by integrating uncertainty learning into the GNN adapter. We propose the Uncertainty-aware Adapter (UAdapterGNN) that fortifies pre-trained GNN models against noisy graph data in the fine-tuning process. Specifically, in contrast to regular AdapterGNN, our UAdapterGNN exploits Gaussian probabilistic adapter to augment the pre-trained GNN model. In this way, when the graph contains various noises,our method can automatically absorb the effects of changes in the variances of the Gaussian distribution, thereby significantly enhancing the model's robustness. Also, UAdapterGNN can further improve the generalization ability of the model on the downstream tasks. Extensive experiments on several benchmarks demonstrate the effectiveness, robustness and high generalization ability of the proposed UAdapterGNN method.

</details>


### [484] [KernelBand: Boosting LLM-based Kernel Optimization with a Hierarchical and Hardware-aware Multi-armed Bandit](https://arxiv.org/abs/2511.18868)
*Dezhi Ran,Shuxiao Xie,Mingfang Ji,Ziyue Hua,Mengzhou Wu,Yuan Cao,Yuzhe Guo,Yu Hao,Linyi Li,Yitao Hu,Tao Xie*

Main category: cs.LG

TL;DR: KernelBand是一个将内核优化建模为分层多臂老虎机问题的框架，利用LLM代理通过硬件分析和运行时聚类来战略性地导航优化空间，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 高质量内核对降低LLM训练和推理成本至关重要，但传统方法需要大量硬件和软件优化专业知识。现有LLM代码生成方法由于缺乏硬件领域知识，难以有效平衡探索和利用。

Method: 将内核优化建模为分层多臂老虎机问题，利用硬件分析信息识别有前景的优化策略，通过运行时行为聚类减少内核候选的探索开销。

Result: 在TritonBench上的实验表明，KernelBand显著优于最先进方法，以更少的token实现更优性能，且随着计算资源增加呈现持续改进而无饱和现象。

Conclusion: KernelBand框架通过将内核优化问题形式化为序列决策过程，有效解决了现有方法在优化空间导航中的挑战，为LLM内核优化提供了新的解决方案。

Abstract: High quality kernels are critical for reducing training and inference costs of Large Language Models (LLMs), yet they traditionally require significant expertise in hardware architecture and software optimization. While recent advances in LLM-based code generation show promise for complex optimization, existing methods struggle with the vast optimization space due to insufficient hardware domain knowledge, failing to effectively balance exploration and exploitation. We present KernelBand, a novel framework that formulates kernel optimization as a hierarchical multi-armed bandit problem, enabling LLM agents to strategically navigate the optimization space by treating kernel selection and optimization strategy application as sequential decision-making processes. Our approach leverages hardware profiling information to identify promising optimization strategies and employs runtime behavior clustering to reduce exploration overhead across kernel candidates. Extensive experiments on TritonBench demonstrate that KernelBand significantly outperforms state-of-the-art methods, achieving superior performance with fewer tokens while exhibiting consistent improvement without saturation as computational resources increase.

</details>


### [485] [Periodic Asynchrony: An Effective Method for Accelerating On-Policy Reinforcement Learning](https://arxiv.org/abs/2511.18871)
*Jian Lu*

Main category: cs.LG

TL;DR: 提出了一种周期异步框架，将推理和训练分离部署，通过改进数据加载器实现需求驱动的弹性扩展，在NPU平台上实现至少3倍的整体性能提升。


<details>
  <summary>Details</summary>
Motivation: 主流RL框架中推理和训练在同一设备上同步执行，计算耦合限制了并发性，训练效率成为关键挑战。

Method: 采用分离部署策略，引入三模型架构和共享提示注意力掩码，将同步架构转换为周期异步框架。

Result: 算法精度与同步方法完全等效，在NPU平台上实现了至少3倍的整体性能提升。

Conclusion: 该框架具有广泛应用的潜力，能够实现需求驱动的独立弹性扩展。

Abstract: Since the introduction of the GRPO algorithm, reinforcement learning (RL) has attracted increasing attention, with growing efforts to reproduce and apply it. However, training efficiency remains a critical challenge. In mainstream RL frameworks, inference and training are typically deployed on the same devices. While this approach reduces costs through resource consolidation, its synchronous execution imposes a computational coupling that prevents concurrent inference and training. In this study, we are returning to the strategy of separating inference and training deployment, and by introducing improvements in the data loader, we transform the conventional synchronous architecture into a periodically asynchronous framework, which allows for demand-driven, independent, and elastic scaling of each component, while the accuracy of the algorithm remains completely equivalent to the synchronization method, with both belonging to the on-policy strategy. It is worth emphasizing that we apply a unified tri-model architecture in the training phase, and we also proposed a shared-prompt attention mask to reduce repetitive computation. In practice, these works have achieved at least a threefold overall performance improvement in RL training on NPU platforms, indicating its potential for widespread application.

</details>


### [486] [Hi-SAFE: Hierarchical Secure Aggregation for Lightweight Federated Learning](https://arxiv.org/abs/2511.18887)
*Hyeong-Gun Joo,Songnam Hong,Seunghwan Lee,Dong-Joon Shin*

Main category: cs.LG

TL;DR: Hi-SAFE是一个轻量级、密码学安全的聚合框架，用于解决基于符号的联邦学习中的隐私和通信效率问题。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在资源受限环境中面临隐私和通信效率的双重挑战，现有基于符号的方法虽然节省带宽但易受推理攻击，而安全聚合技术要么不兼容要么开销过大。

Method: 提出Hi-SAFE框架，核心贡献是基于费马小定理构建高效的多数组投票多项式，将多数组投票表示为有限域上的低次多项式，支持安全评估。采用分层子分组策略确保恒定乘法深度和有限用户复杂度。

Result: Hi-SAFE实现了轻量级的安全聚合，隐藏中间值仅揭示最终结果，且复杂度与用户数量n无关。

Conclusion: Hi-SAFE有效解决了基于符号的联邦学习中的隐私保护和通信效率问题，为资源受限环境提供了可行的安全解决方案。

Abstract: Federated learning (FL) faces challenges in ensuring both privacy and communication efficiency, particularly in resource-constrained environments such as Internet of Things (IoT) and edge networks. While sign-based methods, such as sign stochastic gradient descent with majority voting (SIGNSGD-MV), offer substantial bandwidth savings, they remain vulnerable to inference attacks due to exposure of gradient signs. Existing secure aggregation techniques are either incompatible with sign-based methods or incur prohibitive overhead. To address these limitations, we propose Hi-SAFE, a lightweight and cryptographically secure aggregation framework for sign-based FL. Our core contribution is the construction of efficient majority vote polynomials for SIGNSGD-MV, derived from Fermat's Little Theorem. This formulation represents the majority vote as a low-degree polynomial over a finite field, enabling secure evaluation that hides intermediate values and reveals only the final result. We further introduce a hierarchical subgrouping strategy that ensures constant multiplicative depth and bounded per-user complexity, independent of the number of users n.

</details>


### [487] [Nemotron-Flash: Towards Latency-Optimal Hybrid Small Language Models](https://arxiv.org/abs/2511.18890)
*Yonggan Fu,Xin Dong,Shizhe Diao,Matthijs Van keirsbilck,Hanrong Ye,Wonmin Byeon,Yashaswi Karnati,Lucas Liebenwein,Hannah Zhang,Nikolaus Binder,Maksim Khadkevich,Alexander Keller,Jan Kautz,Yingyan Celine Lin,Pavlo Molchanov*

Main category: cs.LG

TL;DR: 该论文提出了一种针对小语言模型（SLM）的延迟优化设计方法，通过分析深度-宽度比例和操作符选择等关键架构因素，结合进化搜索和权重归一化技术，开发了Nemotron-Flash模型系列，在保持准确性的同时显著提升了推理速度和吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现有SLM设计主要关注参数数量优化，但参数效率并不直接转化为实际设备上的速度提升。该研究旨在识别影响SLM实际延迟的关键因素，为以延迟为首要考虑的SLM设计提供通用原则和方法论。

Method: 1. 识别两个核心架构因素：深度-宽度比例（影响小批量延迟）和操作符选择（影响延迟和大批量吞吐量）
2. 研究延迟最优的深度-宽度比例
3. 探索高效注意力替代方案
4. 构建进化搜索框架自动发现操作符的最优组合
5. 使用权重归一化技术改进训练过程

Result: 提出的Nemotron-Flash模型系列相比现有SOTA SLM（如Qwen3-1.7B/0.6B）实现了：平均准确率提升超过5.5%，延迟降低1.3倍/1.9倍，吞吐量提高18.7倍/45.6倍。

Conclusion: 该研究证明了通过系统性的架构优化和训练改进，可以显著提升小语言模型的准确率-效率边界，为实际部署提供了更优的解决方案。

Abstract: Efficient deployment of small language models (SLMs) is essential for numerous real-world applications with stringent latency constraints. While previous work on SLM design has primarily focused on reducing the number of parameters to achieve parameter-optimal SLMs, parameter efficiency does not necessarily translate into proportional real-device speed-ups. This work aims to identify the key determinants of SLMs' real-device latency and offer generalizable principles and methodologies for SLM design and training when real-device latency is the primary consideration. Specifically, we identify two central architectural factors: depth-width ratios and operator choices. The former is crucial for small-batch-size latency, while the latter affects both latency and large-batch-size throughput. In light of this, we first study latency-optimal depth-width ratios, with the key finding that although deep-thin models generally achieve better accuracy under the same parameter budget, they may not lie on the accuracy-latency trade-off frontier. Next, we explore emerging efficient attention alternatives to evaluate their potential as candidate building operators. Using the identified promising operators, we construct an evolutionary search framework to automatically discover latency-optimal combinations of these operators within hybrid SLMs, thereby advancing the accuracy-latency frontier. In addition to architectural improvements, we further enhance SLM training using a weight normalization technique that enables more effective weight updates and improves final convergence. Combining these methods, we introduce a new family of hybrid SLMs, called Nemotron-Flash, which significantly advances the accuracy-efficiency frontier of state-of-the-art SLMs, e.g., achieving over +5.5% average accuracy, 1.3x/1.9x lower latency, and 18.7x/45.6x higher throughput compared to Qwen3-1.7B/0.6B, respectively.

</details>


### [488] [VADE: Variance-Aware Dynamic Sampling via Online Sample-Level Difficulty Estimation for Multimodal RL](https://arxiv.org/abs/2511.18902)
*Zengjie Hu,Jiantao Qiu,Tianyi Bai,Haojin Yang,Binhang Yuan,Qi Jing,Conghui He,Wentao Zhang*

Main category: cs.LG

TL;DR: VADE是一个解决组策略优化中梯度消失问题的动态采样框架，通过在线样本难度估计、Thompson采样器和双尺度先验衰减机制，动态选择信息量最大的样本，提升训练效率并降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有GRPO和GSPO等组策略优化方法存在梯度消失问题，当组内所有响应获得相同奖励时优势估计会崩溃。现有解决方案要么计算开销大，要么缺乏实时适应性。

Method: VADE框架包含三个核心组件：1) 使用Beta分布进行在线样本级难度估计；2) 通过Thompson采样器最大化信息增益；3) 双尺度先验衰减机制在策略演化下保持稳健估计。

Result: 在多模态推理基准测试中，VADE在性能和样本效率上均优于强基线，同时显著降低了计算开销。

Conclusion: VADE可作为即插即用组件无缝集成到现有组策略优化算法中，有效解决了梯度消失问题并提升了训练效率。

Abstract: Group-based policy optimization methods like GRPO and GSPO have become standard for training multimodal models, leveraging group-wise rollouts and relative advantage estimation. However, they suffer from a critical \emph{gradient vanishing} problem when all responses within a group receive identical rewards, causing advantage estimates to collapse and training signals to diminish. Existing attempts to mitigate this issue fall into two paradigms: filtering-based and sampling-based methods. Filtering-based methods first generate rollouts broadly and then retroactively filter out uninformative groups, leading to substantial computational overhead. Sampling-based methods proactively select effective samples before rollout but rely on static criteria or prior dataset knowledge, lacking real-time adaptability. To address these issues, we propose \textbf{VADE}, a \textbf{V}ariance-\textbf{A}ware \textbf{D}ynamic sampling framework via online sample-level difficulty \textbf{E}stimation. Our framework integrates three key components: online sample-level difficulty estimation using Beta distributions, a Thompson sampler that maximizes information gain through the estimated correctness probability, and a two-scale prior decay mechanism that maintains robust estimation under policy evolution. This three components design enables VADE to dynamically select the most informative samples, thereby amplifying training signals while eliminating extra rollout costs. Extensive experiments on multimodal reasoning benchmarks show that VADE consistently outperforms strong baselines in both performance and sample efficiency, while achieving a dramatic reduction in computational overhead. More importantly, our framework can serves as a plug-and-play component to be seamlessly integrated into existing group-based RL algorithms. Code and models are available at https://VADE-RL.github.io.

</details>


### [489] [How Learning Rate Decay Wastes Your Best Data in Curriculum-Based LLM Pretraining](https://arxiv.org/abs/2511.18903)
*Kairong Luo,Zhenbo Sun,Haodong Wen,Xinyu Shi,Jiarui Cui,Chenyi Dang,Kaifeng Lyu,Wenguang Chen*

Main category: cs.LG

TL;DR: 本研究发现了课程学习在LLM预训练中效果有限的原因：数据质量升序排列与学习率衰减计划的不兼容性，并提出了两种简单策略来缓解这个问题，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 由于高质量数据的稀缺性，LLMs通常在不同质量的数据混合上进行训练。虽然课程学习（按数据质量升序排列）理论上应该更有效利用高质量数据，但先前研究显示其改进有限。

Method: 通过实验发现课程学习与学习率衰减的不兼容性，提出两种策略：(1) 使用更温和的学习率衰减计划；(2) 用模型平均替代学习率衰减。在1.5B参数模型上验证了这些方法。

Result: 结合两种策略后，在标准基准测试上的平均得分比随机打乱提高了1.64%，无需额外数据精炼。在30B tokens上验证了多种数据质量指标的有效性。

Conclusion: 研究结果呼吁重新评估基于课程的LLM预训练方法，并强调了将数据课程与优化方法协同设计的潜力。

Abstract: Due to the scarcity of high-quality data, large language models (LLMs) are often trained on mixtures of data with varying quality levels, even after sophisticated data curation. A natural approach to better leverage high-quality data is curriculum-based pretraining, where the model is trained on data sorted in ascending order of quality as determined by a quality metric. However, prior studies have reported limited improvements from such curriculum-based pretraining strategies. This work identifies a critical factor constraining these methods: the incompatibility between the ascending data quality order and the decaying learning rate (LR) schedule. We find that while curriculum-based training substantially outperforms random shuffling when using a constant LR, its advantage diminishes under standard LR decay schedules. Our experiments show this incompatibility can be mitigated by two simple strategies: (1) employing a more moderate LR decay schedule, where the final LR is only moderately smaller than the peak LR, and (2) replacing LR decay with model averaging, i.e., computing a weighted average of the final few checkpoints. By combining these strategies, we improve the average score on a suite of standard benchmarks by 1.64% over random shuffling, without additional data refinement. Validated on 1.5B-parameter models trained over 30B tokens with various data-quality metrics, our findings call for a re-evaluation of curriculum-based LLM pretraining and underscore the potential of co-designing data curricula with optimization methods.

</details>


### [490] [Learning Solution Operators for Partial Differential Equations via Monte Carlo-Type Approximation](https://arxiv.org/abs/2511.18930)
*Salah Eddine Choutri,Prajwal Chauhan,Othmane Mazhar,Saif Eddin Jabari*

Main category: cs.LG

TL;DR: MCNO提出了一种轻量级架构，通过蒙特卡洛方法直接近似核积分来学习参数化PDE的解算子，无需谱假设或平移不变性假设，能够在多网格分辨率下泛化且计算成本低。


<details>
  <summary>Details</summary>
Motivation: 现有的神经算子方法（如傅里叶神经算子）依赖于谱假设或平移不变性，限制了其应用范围。MCNO旨在提供一种更简单、更通用的替代方案。

Method: 使用蒙特卡洛方法直接近似核积分，核表示为在固定随机采样点集上的可学习张量，避免了固定全局基函数和训练期间的重复采样。

Result: 在标准1D PDE基准测试中，MCNO以较低的计算成本实现了有竞争力的精度。

Conclusion: MCNO为谱和基于图的神经算子提供了一种简单实用的替代方案，具有较好的泛化能力和计算效率。

Abstract: The Monte Carlo-type Neural Operator (MCNO) introduces a lightweight architecture for learning solution operators for parametric PDEs by directly approximating the kernel integral using a Monte Carlo approach. Unlike Fourier Neural Operators, MCNO makes no spectral or translation-invariance assumptions. The kernel is represented as a learnable tensor over a fixed set of randomly sampled points. This design enables generalization across multiple grid resolutions without relying on fixed global basis functions or repeated sampling during training. Experiments on standard 1D PDE benchmarks show that MCNO achieves competitive accuracy with low computational cost, providing a simple and practical alternative to spectral and graph-based neural operators.

</details>


### [491] [SWAN: Sparse Winnowed Attention for Reduced Inference Memory via Decompression-Free KV-Cache Compression](https://arxiv.org/abs/2511.18936)
*Santhosh G S,Saurav Prakash,Balaraman Ravindran*

Main category: cs.LG

TL;DR: SWAN是一种无需微调的KV缓存压缩框架，通过正交矩阵旋转和剪枝直接用于注意力计算，无需解压缩步骤，在50-60%内存节省下保持接近原始性能。


<details>
  <summary>Details</summary>
Motivation: LLM自回归推理时KV缓存占用大量内存，现有压缩技术存在信息丢失风险、固定限制或解压缩计算开销大的问题。

Method: 使用离线正交矩阵对KV缓存进行旋转和剪枝，压缩后的缓存可直接用于注意力计算，无需重建步骤，并配备小型密集缓冲区。

Result: 实验表明SWAN在每token KV缓存节省50-60%内存的情况下，性能接近未压缩基线，且支持运行时可调压缩级别。

Conclusion: SWAN的无解压缩设计、高压缩性能下的良好表现以及动态可调性，使其成为服务长上下文LLM的实用高效解决方案。

Abstract: Large Language Models (LLMs) face a significant bottleneck during autoregressive inference due to the massive memory footprint of the Key-Value (KV) cache. Existing compression techniques like token eviction, quantization, or other low-rank methods often risk information loss, have fixed limits, or introduce significant computational overhead from explicit decompression steps. In this work, we introduce SWAN, a novel, fine-tuning-free framework that eliminates this overhead. Our method uses an offline orthogonal matrix to rotate and prune the KV-cache, which is then used directly in the attention computation without any reconstruction. Our extensive experiments demonstrate that SWAN, augmented with a small dense buffer, offers a robust trade-off, maintaining performance close to the uncompressed baseline even at aggressive 50-60% memory savings per-token on KV-cache. A key advantage is its runtime-tunable compression level, allowing operators to dynamically adjust the memory footprint, a flexibility absent in methods requiring fixed offline configurations. This combination of a decompression-free design, high performance under compression, and adaptability makes SWAN a practical and efficient solution for serving LLMs with long contexts.

</details>


### [492] [Geometry-Aware Deep Congruence Networks for Manifold Learning in Cross-Subject Motor Imagery](https://arxiv.org/abs/2511.18940)
*Sanjeev Manivannan,Chandrashekar Lakshminarayan*

Main category: cs.LG

TL;DR: 提出几何感知预处理模块和深度同余网络，直接在SPD流形上处理脑电信号，解决跨被试运动想象解码中的零样本挑战，在BCI-IV 2a基准上提升准确率3-4%。


<details>
  <summary>Details</summary>
Motivation: 解决跨被试脑电解码中的主要挑战：强被试变异性和SPD流形的弯曲几何特性，特别是在零样本跨被试设置下（不允许目标被试标签或适应）。

Method: 引入几何感知预处理模块DCR和RiFU扩展黎曼对齐，提出两个流形分类器SPD-DCNet和RiFUNet，使用分层同余变换学习判别性、被试不变协方差表示。

Result: 在BCI-IV 2a基准上，该框架比最强经典基线提升跨被试准确率3-4%。

Conclusion: 几何感知变换对鲁棒脑电解码具有重要价值，证明了直接在SPD流形上操作的有效性。

Abstract: Cross-subject motor-imagery decoding remains a major challenge in EEG-based brain-computer interfaces due to strong subject variability and the curved geometry of covariance matrices on the symmetric positive definite (SPD) manifold. We address the zero-shot cross-subject setting, where no target-subject labels or adaptation are allowed, by introducing novel geometry-aware preprocessing modules and deep congruence networks that operate directly on SPD covariance matrices. Our preprocessing modules, DCR and RiFU, extend Riemannian Alignment by improving action separation while reducing subject-specific distortions. We further propose two manifold classifiers, SPD-DCNet and RiFUNet, which use hierarchical congruence transforms to learn discriminative, subject-invariant covariance representations. On the BCI-IV 2a benchmark, our framework improves cross-subject accuracy by 3-4% over the strongest classical baselines, demonstrating the value of geometry-aware transformations for robust EEG decoding.

</details>


### [493] [MIST: Mutual Information Via Supervised Training](https://arxiv.org/abs/2511.18945)
*German Gritsai,Megan Richards,Maxime Méloux,Kyunghyun Cho,Maxime Peyrard*

Main category: cs.LG

TL;DR: 提出了一种完全数据驱动的互信息估计器设计方法，使用神经网络端到端训练，在包含62.5万个已知互信息真值的合成联合分布元数据集上进行训练，能够处理可变样本大小和维度，并提供量化不确定性。


<details>
  <summary>Details</summary>
Motivation: 传统互信息估计方法存在理论保证与灵活性之间的权衡问题，需要一种更灵活、高效的完全经验性方法。

Method: 使用神经网络参数化互信息估计函数（MIST），采用二维注意力机制确保输入样本的排列不变性，优化分位数回归损失来量化不确定性。

Result: 学习的估计器在各种样本大小和维度下显著优于经典基线方法，即使在训练期间未见过的联合分布上也表现良好，分位数区间校准良好且比基于bootstrap的置信区间更可靠。

Conclusion: 该方法提供了可训练、完全可微分的估计器，可以嵌入到更大的学习管道中，通过利用互信息对可逆变换的不变性，元数据集可以适应任意数据模态。

Abstract: We propose a fully data-driven approach to designing mutual information (MI) estimators. Since any MI estimator is a function of the observed sample from two random variables, we parameterize this function with a neural network (MIST) and train it end-to-end to predict MI values. Training is performed on a large meta-dataset of 625,000 synthetic joint distributions with known ground-truth MI. To handle variable sample sizes and dimensions, we employ a two-dimensional attention scheme ensuring permutation invariance across input samples. To quantify uncertainty, we optimize a quantile regression loss, enabling the estimator to approximate the sampling distribution of MI rather than return a single point estimate. This research program departs from prior work by taking a fully empirical route, trading universal theoretical guarantees for flexibility and efficiency. Empirically, the learned estimators largely outperform classical baselines across sample sizes and dimensions, including on joint distributions unseen during training. The resulting quantile-based intervals are well-calibrated and more reliable than bootstrap-based confidence intervals, while inference is orders of magnitude faster than existing neural baselines. Beyond immediate empirical gains, this framework yields trainable, fully differentiable estimators that can be embedded into larger learning pipelines. Moreover, exploiting MI's invariance to invertible transformations, meta-datasets can be adapted to arbitrary data modalities via normalizing flows, enabling flexible training for diverse target meta-distributions.

</details>


### [494] [Learning to Compress Graphs via Dual Agents for Consistent Topological Robustness Evaluation](https://arxiv.org/abs/2511.18958)
*Qisen Chai,Yansong Wang,Junjie Huang,Tao Jia*

Main category: cs.LG

TL;DR: Cutter是一个双智能体强化学习框架，用于图数据压缩，通过保留拓扑结构和鲁棒性特征来高效评估大规模图数据的对抗攻击鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着图结构数据规模不断增大，评估其在对抗攻击下的鲁棒性变得计算昂贵且难以扩展。需要一种能够压缩图数据同时保留关键特性的方法。

Method: 提出Cutter框架，包含关键节点检测智能体(VDA)和冗余节点检测智能体(RDA)，采用三种关键策略：轨迹级奖励塑造、基于原型的塑造和跨智能体模仿，实现协同压缩。

Result: 在多个真实世界图数据上的实验表明，Cutter生成的压缩图保留了关键拓扑特性，且在各种攻击场景下与原始图保持高度一致的鲁棒性退化趋势。

Conclusion: Cutter能够显著提高评估效率而不损害评估保真度，为大规模图数据鲁棒性评估提供了有效解决方案。

Abstract: As graph-structured data grow increasingly large, evaluating their robustness under adversarial attacks becomes computationally expensive and difficult to scale. To address this challenge, we propose to compress graphs into compact representations that preserve both topological structure and robustness profile, enabling efficient and reliable evaluation.We propose Cutter, a dual-agent reinforcement learning framework composed of a Vital Detection Agent (VDA) and a Redundancy Detection Agent (RDA), which collaboratively identify structurally vital and redundant nodes for guided compression. Cutter incorporates three key strategies to enhance learning efficiency and compression quality: trajectory-level reward shaping to transform sparse trajectory returns into dense, policy-equivalent learning signals; prototype-based shaping to guide decisions using behavioral patterns from both highand low-return trajectories; and cross-agent imitation to enable safer and more transferable exploration. Experiments on multiple real-world graphs demonstrate that Cutter generates compressed graphs that retain essential static topological properties and exhibit robustness degradation trends highly consistent with the original graphs under various attack scenarios, thereby significantly improving evaluation efficiency without compromising assessment fidelity.

</details>


### [495] [FastForward Pruning: Efficient LLM Pruning via Single-Step Reinforcement Learning](https://arxiv.org/abs/2511.18977)
*Xin Yuan,Siqi Li,Jiateng Wei,Chengrui Zhu,Yanming Wu,Qingpeng Li,Jiajun Lv,Xiaoke Lan,Jun Chen,Yong Liu*

Main category: cs.LG

TL;DR: 提出FastForward Pruning方法，通过解耦的单步强化学习框架解决大语言模型剪枝中的层间稀疏度分配问题，显著降低计算成本同时保持性能优势


<details>
  <summary>Details</summary>
Motivation: 现有剪枝方法中，启发式方法速度快但性能次优，而基于搜索的方法（如强化学习）计算成本过高，难以在大规模模型上应用

Method: 采用解耦的单步强化学习框架，将策略优化与复杂预算满足问题分离，通过课程学习策略从简单任务逐步增加复杂度来降低搜索计算开销

Result: 在LLaMA、Mistral和OPT模型家族上验证，发现优于强启发式基线的剪枝策略，相比其他搜索算法以更低计算成本达到竞争性或更优结果

Conclusion: FastForward Pruning在搜索效率上具有明显优势，能够在大规模语言模型上高效寻找最优的层间稀疏度分配策略

Abstract: Pruning is an effective method for compressing Large Language Models, but finding an optimal, non-uniform layer-wise sparsity allocation remains a key challenge. While heuristic methods are fast but yield suboptimal performance, more powerful search-based approaches like Reinforcement Learning are often hindered by prohibitive computational costs on large-scale models. To overcome this efficiency barrier, we propose FastForward Pruning. Its core is a decoupled, single-step RL framework that separates policy optimization from the complex budget satisfaction problem. Such a decoupling is crucial for efficiently searching the vast policy space of LLMs. This curriculum-based strategy begins with low-cost, simple tasks and gradually increases in complexity, significantly reducing the search's computational overhead. Evaluated on the LLaMA, Mistral, and OPT model families, our framework discovers pruning policies that achieve superior performance over strong heuristic baselines. Crucially, when compared to other search-based algorithms, our method achieves competitive or superior results at a fraction of the computational cost, demonstrating a clear advantage in search efficiency.

</details>


### [496] [Dynamic Mixture of Experts Against Severe Distribution Shifts](https://arxiv.org/abs/2511.18987)
*Donghu Kim*

Main category: cs.LG

TL;DR: 本文评估了DynamicMoE方法在持续学习和强化学习环境中的效果，并与现有网络扩展方法进行基准比较。


<details>
  <summary>Details</summary>
Motivation: 解决神经网络在持续学习中的可塑性与稳定性平衡问题，借鉴生物大脑通过容量增长维持可塑性的机制，探索动态添加容量的方法。

Method: 采用动态混合专家（DynamicMoE）架构，通过为不同数据分布专门化专家来解决持续学习问题。

Result: 论文对DynamicMoE方法进行了系统评估，但具体结果需要查看完整论文。

Conclusion: MoE架构为解决持续学习和强化学习中的可塑性-稳定性平衡问题提供了有前景的替代方案。

Abstract: The challenge of building neural networks that can continuously learn and adapt to evolving data streams is central to the fields of continual learning (CL) and reinforcement learning (RL). This lifelong learning problem is often framed in terms of the plasticity-stability dilemma, focusing on issues like loss of plasticity and catastrophic forgetting. Unlike neural networks, biological brains maintain plasticity through capacity growth, inspiring researchers to explore similar approaches in artificial networks, such as adding capacity dynamically. Prior solutions often lack parameter efficiency or depend on explicit task indices, but Mixture-of-Experts (MoE) architectures offer a promising alternative by specializing experts for distinct distributions. This paper aims to evaluate a DynamicMoE approach for continual and reinforcement learning environments and benchmark its effectiveness against existing network expansion methods.

</details>


### [497] [3D Dynamic Radio Map Prediction Using Vision Transformers for Low-Altitude Wireless Networks](https://arxiv.org/abs/2511.19019)
*Nguyen Duc Minh Quang,Chang Liu,Huy-Trung Nguyen,Shuangyang Li,Derrick Wing Kwan Ng,Wei Xiang*

Main category: cs.LG

TL;DR: 提出了一个3D动态无线电地图（3D-DRM）框架，用于学习和预测多无人机网络中接收功率的时空演化，以解决低空无线网络中由于三维移动性和时变用户密度导致的非平稳无线电环境问题。


<details>
  <summary>Details</summary>
Motivation: 低空无线网络（LAWN）中无人机部署快速增长，但可靠连接面临挑战，包括三维移动性、时变用户密度和有限功率预算。基站发射功率根据用户位置和流量需求动态波动，导致高度非平稳的三维无线电环境。现有无线电地图方法多为静态或离线构建，忽略了实时功率变化和时空依赖性。

Method: 使用Vision Transformer（ViT）编码器从3D无线电地图中提取高维空间表示，同时采用基于Transformer的模块建模序列依赖性以预测未来功率分布。

Result: 实验表明，3D-DRM能够准确捕捉快速变化的功率动态，在无线电地图重建和短期预测方面显著优于基线模型。

Conclusion: 3D-DRM框架有效解决了多无人机网络中动态无线电环境建模的挑战，为实时网络优化提供了有力工具。

Abstract: Low-altitude wireless networks (LAWN) are rapidly expanding with the growing deployment of unmanned aerial vehicles (UAVs) for logistics, surveillance, and emergency response. Reliable connectivity remains a critical yet challenging task due to three-dimensional (3D) mobility, time-varying user density, and limited power budgets. The transmit power of base stations (BSs) fluctuates dynamically according to user locations and traffic demands, leading to a highly non-stationary 3D radio environment. Radio maps (RMs) have emerged as an effective means to characterize spatial power distributions and support radio-aware network optimization. However, most existing works construct static or offline RMs, overlooking real-time power variations and spatio-temporal dependencies in multi-UAV networks. To overcome this limitation, we propose a {3D dynamic radio map (3D-DRM)} framework that learns and predicts the spatio-temporal evolution of received power. Specially, a Vision Transformer (ViT) encoder extracts high-dimensional spatial representations from 3D RMs, while a Transformer-based module models sequential dependencies to predict future power distributions. Experiments unveil that 3D-DRM accurately captures fast-varying power dynamics and substantially outperforms baseline models in both RM reconstruction and short-term prediction.

</details>


### [498] [OrdMoE: Preference Alignment via Hierarchical Expert Group Ranking in Multimodal Mixture-of-Experts LLMs](https://arxiv.org/abs/2511.19023)
*Yuting Gao,Weihao Chen,Lan Wang,Ruihan Xu,Qingpei Guo*

Main category: cs.LG

TL;DR: OrdMoE是一种无需外部人工标注偏好的多模态大语言模型对齐框架，通过利用MoE架构中的路由器专家选择分数来构建内部偏好层次


<details>
  <summary>Details</summary>
Motivation: 现有的偏好学习方法依赖昂贵的人工标注数据，OrdMoE旨在通过MoE架构的内在信号实现零成本的偏好对齐

Method: 基于路由器专家选择分数将专家分组为不同层级，分别激活各层级生成质量递增的响应序列，构建自监督的偏好排序

Result: 在多个多模态基准测试中显著提升了多模态MoE LLM的对齐性和整体性能，无需人工标注数据即可达到竞争性结果

Conclusion: OrdMoE证明了利用MoE架构内在信号进行偏好对齐的有效性，为无监督偏好学习提供了新思路

Abstract: Preference learning has recently emerged as a pivotal strategy for post-training alignment of Multimodal Large Language Models (MLLMs). However, existing approaches predominantly rely on external human-annotated preference data, which is costly and labor-intensive to collect. In this work, we propose OrdMoE, a novel preference alignment framework that bypasses the reliance on external human preferences entirely by leveraging intrinsic signals within Mixture-of-Experts (MoE) architectures. Specifically, we observe that the router's expert selection scores implicitly encode a quality-aware ranking of responses (i.e. higher-scoring experts consistently generate higher-quality outputs). Building on this insight, OrdMoE constructs an internal preference hierarchy by grouping experts into ranked tiers based on their per-token routing scores and activating each tier separately to produce a sequence of responses with increasing quality. This yields a zero-cost, self-supervised preference ordering over generated responses, which can be directly optimized using standard preference learning objectives. Extensive experiments across multiple multimodal benchmarks demnstrate that OrdMoE significantly enhances both alignment and overall performance of multimodal Mixture-of-Experts LLMs, achieving competitive results without requiring any human-annotated preference data.

</details>


### [499] [Resolving Node Identifiability in Graph Neural Processes via Laplacian Spectral Encodings](https://arxiv.org/abs/2511.19037)
*Zimo Yan,Zheng Xie,Chang Liu,Yuan Wang*

Main category: cs.LG

TL;DR: 该论文提出了一种拉普拉斯位置编码方法，能够克服传统消息传递图神经网络在表达能力上的限制，通过理论证明和实验验证展示了其在节点识别和实际任务中的优越性。


<details>
  <summary>Details</summary>
Motivation: 传统消息传递图神经网络的表达能力受限于一维Weisfeiler-Lehman测试，无法区分结构上不同的节点，需要一种更强大的位置编码方法来提升表达能力。

Method: 提出了一种拉普拉斯位置编码方法，该方法对特征向量符号翻转和特征空间内的基旋转具有不变性。结合了最短路径与扩散距离的单调关系、基于常数锚点的光谱三角测量，以及对数嵌入大小的定量光谱单射性分析。

Result: 理论证明该编码方法能够从常数次观测中实现节点可识别性，并建立了与受Weisfeiler-Lehman测试约束架构的样本复杂度分离。在实际药物-药物相互作用任务中，结合神经过程风格解码器显著提高了ROC曲线下面积和F1分数。

Conclusion: 通过理论严谨的位置编码方法可以有效解决图神经网络表达能力限制问题，在实际应用中带来显著性能提升，证明了理论表达能力限制与实用位置信息结合的重要性。

Abstract: Message passing graph neural networks are widely used for learning on graphs, yet their expressive power is limited by the one-dimensional Weisfeiler-Lehman test and can fail to distinguish structurally different nodes. We provide rigorous theory for a Laplacian positional encoding that is invariant to eigenvector sign flips and to basis rotations within eigenspaces. We prove that this encoding yields node identifiability from a constant number of observations and establishes a sample-complexity separation from architectures constrained by the Weisfeiler-Lehman test. The analysis combines a monotone link between shortest-path and diffusion distance, spectral trilateration with a constant set of anchors, and quantitative spectral injectivity with logarithmic embedding size. As an instantiation, pairing this encoding with a neural-process style decoder yields significant gains on a drug-drug interaction task on chemical graphs, improving both the area under the ROC curve and the F1 score and demonstrating the practical benefits of resolving theoretical expressiveness limitations with principled positional information.

</details>


### [500] [Mitigating Participation Imbalance Bias in Asynchronous Federated Learning](https://arxiv.org/abs/2511.19066)
*Xiangyu Chang,Manyi Yao,Srikanth V. Krishnamurthy,Christian R. Shelton,Anirban Chakraborty,Ananthram Swami,Samet Oymak,Amit Roy-Chowdhury*

Main category: cs.LG

TL;DR: 本文分析了异步联邦学习(AFL)中的异质性放大问题，提出了ACE和ACED方法来缓解参与不平衡和延迟问题


<details>
  <summary>Details</summary>
Motivation: 在异步联邦学习中，客户端在不同版本的模型上进行训练会导致信息延迟，而非IID数据分布进一步放大了客户端异质性，使得快速客户端贡献更多更新，从而偏置全局模型

Method: 提出ACE(全客户端参与AFL)方法，通过即时非缓冲更新利用所有客户端的最新信息来缓解参与不平衡；同时提出ACED变体，通过延迟感知机制平衡客户端多样性与更新延迟

Result: 在不同模型、任务和异质性延迟设置下的实验验证了分析结果，证明了所提方法的鲁棒性能

Conclusion: ACE和ACED方法有效缓解了异步联邦学习中的异质性放大问题，通过全客户端参与和延迟感知机制提高了模型性能

Abstract: In Asynchronous Federated Learning (AFL), the central server immediately updates the global model with each arriving client's contribution. As a result, clients perform their local training on different model versions, causing information staleness (delay). In federated environments with non-IID local data distributions, this asynchronous pattern amplifies the adverse effect of client heterogeneity (due to different data distribution, local objectives, etc.), as faster clients contribute more frequent updates, biasing the global model. We term this phenomenon heterogeneity amplification. Our work provides a theoretical analysis that maps AFL design choices to their resulting error sources when heterogeneity amplification occurs. Guided by our analysis, we propose ACE (All-Client Engagement AFL), which mitigates participation imbalance through immediate, non-buffered updates that use the latest information available from all clients. We also introduce a delay-aware variant, ACED, to balance client diversity against update staleness. Experiments on different models for different tasks across diverse heterogeneity and delay settings validate our analysis and demonstrate the robust performance of our approaches.

</details>


### [501] [EnfoPath: Energy-Informed Analysis of Generative Trajectories in Flow Matching](https://arxiv.org/abs/2511.19087)
*Ziyun Li,Ben Dai,Huancheng Hu,Henrik Boström,Soon Hoe Lim*

Main category: cs.LG

TL;DR: 本文提出动能路径能量（KPE）作为评估ODE采样器生成路径的指标，发现高KPE与更好的语义质量和低数据密度相关，揭示了信息丰富样本位于数据分布稀疏前沿的规律。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注生成结果的端点指标（如保真度、似然度），而忽视了采样轨迹本身所蕴含的信息。受经典力学启发，作者希望深入分析生成路径的动力学特性。

Method: 引入动能路径能量（KPE）这一诊断工具，通过计算ODE采样器生成路径上的总动能来量化生成过程的动力学努力程度。在CIFAR-10和ImageNet-256数据集上进行全面实验。

Result: 发现两个关键现象：（1）高KPE预测更强的语义质量，表明语义丰富的样本需要更大的动能努力；（2）高KPE与数据密度呈负相关，信息丰富的样本位于稀疏的低密度区域。

Conclusion: 语义信息丰富的样本自然位于数据分布的稀疏前沿，需要更大的生成努力。轨迹级分析为理解生成难度和样本特性提供了物理启发且可解释的框架。

Abstract: Flow-based generative models synthesize data by integrating a learned velocity field from a reference distribution to the target data distribution. Prior work has focused on endpoint metrics (e.g., fidelity, likelihood, perceptual quality) while overlooking a deeper question: what do the sampling trajectories reveal? Motivated by classical mechanics, we introduce kinetic path energy (KPE), a simple yet powerful diagnostic that quantifies the total kinetic effort along each generation path of ODE-based samplers. Through comprehensive experiments on CIFAR-10 and ImageNet-256, we uncover two key phenomena: ({i}) higher KPE predicts stronger semantic quality, indicating that semantically richer samples require greater kinetic effort, and ({ii}) higher KPE inversely correlates with data density, with informative samples residing in sparse, low-density regions. Together, these findings reveal that semantically informative samples naturally reside on the sparse frontier of the data distribution, demanding greater generative effort. Our results suggest that trajectory-level analysis offers a physics-inspired and interpretable framework for understanding generation difficulty and sample characteristics.

</details>


### [502] [Optimization of Deep Learning Models for Dynamic Market Behavior Prediction](https://arxiv.org/abs/2511.19090)
*Shenghan Zhao,Yuzhen Lin,Ximeng Yang,Qiaochu Lu,Haozhong Xue,Gaozhe Jiang*

Main category: cs.LG

TL;DR: 本文提出了一种混合序列模型，用于多时间尺度的零售需求预测，在多个评估指标上超越了传统方法和最先进的Transformer模型。


<details>
  <summary>Details</summary>
Motivation: 金融科技领域深度学习的兴起为预测消费者行为提供了新机遇，但现有研究往往将金融贷款叙事与零售数据混合。本文专注于零售市场行为，明确预测SKU级别的日需求/收入。

Method: 提出混合序列模型，结合多尺度时间卷积、门控循环模块和时间感知自注意力机制，使用标准回归损失训练，采用严格时间分割防止数据泄露。

Result: 模型在MAE、RMSE、sMAPE、MASE和Theil's U_2指标上均优于ARIMA/Prophet、LSTM/GRU、LightGBM和先进Transformer模型，在峰值/节假日期间表现出更好的鲁棒性。

Conclusion: 该混合模型在多时间尺度零售需求预测中取得了可靠改进，通过消融实验和统计显著性测试验证了结果可靠性，并公开实现细节以确保可复现性。

Abstract: The advent of financial technology has witnessed a surge in the utilization of deep learning models to anticipate consumer conduct, a trend that has demonstrated considerable potential in enhancing lending strategies and bolstering market efficiency. We study multi-horizon demand forecasting on e-commerce transactions using the UCI Online Retail II dataset. Unlike prior versions of this manuscript that mixed financial-loan narratives with retail data, we focus exclusively on retail market behavior and define a clear prediction target: per SKU daily demand (or revenue) for horizons H=1,7,14. We present a hybrid sequence model that combines multi-scale temporal convolutions, a gated recurrent module, and time-aware self-attention. The model is trained with standard regression losses and evaluated under MAE, RMSE, sMAPE, MASE, and Theil's U_2 with strict time-based splits to prevent leakage. We benchmark against ARIMA/Prophet, LSTM/GRU, LightGBM, and state-of-the-art Transformer forecasters (TFT, Informer, Autoformer, N-BEATS). Results show consistent accuracy gains and improved robustness on peak/holiday periods. We further provide ablations and statistical significance tests to ensure the reliability of improvements, and we release implementation details to facilitate reproducibility.

</details>


### [503] [Edge-Based Predictive Data Reduction for Smart Agriculture: A Lightweight Approach to Efficient IoT Communication](https://arxiv.org/abs/2511.19103)
*Dora Krekovic,Mario Kusek,Ivana Podnar Zarko,Danh Le-Phuoc*

Main category: cs.LG

TL;DR: 提出了一种用于边缘计算环境的预测算法，通过预测传感器数据并仅在偏差超过阈值时传输数据，以减少物联网环境中的通信负载和能耗。


<details>
  <summary>Details</summary>
Motivation: 物联网设备快速增长导致大量传感器数据传输到云端，造成网络拥塞、延迟增加和高能耗，特别是在资源受限的远程环境中问题更为突出。

Method: 在网络边缘部署预测过滤器来预测下一个传感器数据点，只有当实际值与预测值的偏差超过预设容差时才触发数据传输，同时使用云端模型确保数据完整性和系统一致性。

Result: 该策略有效减少了通信开销，通过最小化冗余传输提高了能源效率，并支持跨站点泛化，使模型能够在不重新训练的情况下部署到其他区域。

Conclusion: 该解决方案具有高度可扩展性、能源感知能力，非常适合优化远程和带宽受限的物联网环境中的传感器数据传输。

Abstract: The rapid growth of IoT devices has led to an enormous amount of sensor data that requires transmission to cloud servers for processing, resulting in excessive network congestion, increased latency and high energy consumption. This is particularly problematic in resource-constrained and remote environments where bandwidth is limited, and battery-dependent devices further emphasize the problem. Moreover, in domains such as agriculture, consecutive sensor readings often have minimal variation, making continuous data transmission inefficient and unnecessarily resource intensive. To overcome these challenges, we propose an analytical prediction algorithm designed for edge computing environments and validated through simulation. The proposed solution utilizes a predictive filter at the network edge that forecasts the next sensor data point and triggers data transmission only when the deviation from the predicted value exceeds a predefined tolerance. A complementary cloud-based model ensures data integrity and overall system consistency. This dual-model strategy effectively reduces communication overhead and demonstrates potential for improving energy efficiency by minimizing redundant transmissions. In addition to reducing communication load, our approach leverages both in situ and satellite observations from the same locations to enhance model robustness. It also supports cross-site generalization, enabling models trained in one region to be effectively deployed elsewhere without retraining. This makes our solution highly scalable, energy-aware, and well-suited for optimizing sensor data transmission in remote and bandwidth-constrained IoT environments.

</details>


### [504] [The Core in Max-Loss Non-Centroid Clustering Can Be Empty](https://arxiv.org/abs/2511.19107)
*Robert Bredereck,Eva Deltl,Leon Kellerhals,Jannik Peters*

Main category: cs.LG

TL;DR: 研究了非质心聚类中最大损失目标下的核心稳定性问题，证明了当k≥3时存在度量实例使得α-核心为空，且α<2^(1/5)的界是紧的。


<details>
  <summary>Details</summary>
Motivation: 探索非质心聚类在最大损失目标下的核心稳定性，填补该领域缺乏不可能性结果的研究空白。

Method: 使用理论证明和计算机辅助证明方法，构建了度量实例和二维欧几里得点集来验证核心空集的存在性。

Result: 证明了当k≥3时，存在n≥9且n可被k整除的度量实例，使得α-核心为空且α<2^(1/5)的界是紧的。

Conclusion: 这是首个证明在最大损失目标下非质心聚类核心可能为空的不可能性结果，为聚类稳定性理论提供了重要洞见。

Abstract: We study core stability in non-centroid clustering under the max-loss objective, where each agent's loss is the maximum distance to other members of their cluster. We prove that for all $k\geq 3$ there exist metric instances with $n\ge 9$ agents, with $n$ divisible by $k$, for which no clustering lies in the $α$-core for any $α<2^{\frac{1}{5}}\sim 1.148$. The bound is tight for our construction. Using a computer-aided proof, we also identify a two-dimensional Euclidean point set whose associated lower bound is slightly smaller than that of our general construction. This is, to our knowledge, the first impossibility result showing that the core can be empty in non-centroid clustering under the max-loss objective.

</details>


### [505] [Uncertainty-Aware Deep Learning Framework for Remaining Useful Life Prediction in Turbofan Engines with Learned Aleatoric Uncertainty](https://arxiv.org/abs/2511.19124)
*Krishang Sharma*

Main category: cs.LG

TL;DR: 该研究提出了一种新颖的不确定性感知深度学习框架，用于航空发动机剩余使用寿命预测，通过贝叶斯输出层同时预测均值RUL和方差，在CMAPSS基准测试中取得了突破性的关键区域性能改进。


<details>
  <summary>Details</summary>
Motivation: 准确预测剩余使用寿命并量化不确定性是航空预测性维护中的关键挑战，现有CMAPSS文献中缺乏直接学习数据固有不确定性的方法。

Method: 采用分层架构整合多尺度Inception块进行时间模式提取、双向LSTM进行序列建模、双级注意力机制同时处理传感器和时间维度，并通过贝叶斯输出层学习不确定性。

Result: 在NASA CMAPSS基准测试中，整体RMSE分别为16.22、19.29、16.84和19.98，关键区域(RUL≤30周期)RMSE达到5.14、6.89、5.27和7.16，比传统方法提升25-40%，95%置信区间覆盖率达到93.5%-95.2%。

Conclusion: 该框架在安全关键预测方面建立了新基准，通过学习的不确定性提供良好校准的置信区间，实现了以前CMAPSS文献中无法达到的风险感知维护调度能力。

Abstract: Accurate Remaining Useful Life (RUL) prediction coupled with uncertainty quantification remains a critical challenge in aerospace prognostics. This research introduces a novel uncertainty-aware deep learning framework that learns aleatoric uncertainty directly through probabilistic modeling, an approach unexplored in existing CMAPSS-based literature. Our hierarchical architecture integrates multi-scale Inception blocks for temporal pattern extraction, bidirectional Long Short-Term Memory networks for sequential modeling, and a dual-level attention mechanism operating simultaneously on sensor and temporal dimensions. The innovation lies in the Bayesian output layer that predicts both mean RUL and variance, enabling the model to learn data-inherent uncertainty. Comprehensive preprocessing employs condition-aware clustering, wavelet denoising, and intelligent feature selection. Experimental validation on NASA CMAPSS benchmarks (FD001-FD004) demonstrates competitive overall performance with RMSE values of 16.22, 19.29, 16.84, and 19.98 respectively. Remarkably, our framework achieves breakthrough critical zone performance (RUL <= 30 cycles) with RMSE of 5.14, 6.89, 5.27, and 7.16, representing 25-40 percent improvements over conventional approaches and establishing new benchmarks for safety-critical predictions. The learned uncertainty provides well-calibrated 95 percent confidence intervals with coverage ranging from 93.5 percent to 95.2 percent, enabling risk-aware maintenance scheduling previously unattainable in CMAPSS literature.

</details>


### [506] [Masked Diffusion Models are Secretly Learned-Order Autoregressive Models](https://arxiv.org/abs/2511.19152)
*Prateek Garg,Bhavya Kohli,Sunita Sarawagi*

Main category: cs.LG

TL;DR: 本文提出了一种训练框架，通过多变量噪声调度优化掩码扩散模型的解码顺序，将MDM目标分解为加权自回归损失，从而建立具有可学习顺序的自回归模型。


<details>
  <summary>Details</summary>
Motivation: 现有MDM模型在随机顺序下解码token，而解码顺序对性能有显著影响，因此需要设计能够优化解码顺序的训练框架。

Method: 利用多变量噪声调度的连续时间变分目标，在训练过程中识别和优化解码顺序，建立解码顺序与多变量噪声调度的直接对应关系。

Result: 证明了MDM目标可以精确分解为这些顺序上的加权自回归损失，打破了MDM目标对噪声调度的不变性。

Conclusion: 该方法将MDM确立为具有可学习顺序的自回归模型，为优化解码顺序提供了理论基础。

Abstract: Masked Diffusion Models (MDMs) have emerged as one of the most promising paradigms for generative modeling over discrete domains. It is known that MDMs effectively train to decode tokens in a random order, and that this ordering has significant performance implications in practice. This observation raises a fundamental question: can we design a training framework that optimizes for a favorable decoding order? We answer this in the affirmative, showing that the continuous-time variational objective of MDMs, when equipped with multivariate noise schedules, can identify and optimize for a decoding order during training. We establish a direct correspondence between decoding order and the multivariate noise schedule and show that this setting breaks invariance of the MDM objective to the noise schedule. Furthermore, we prove that the MDM objective decomposes precisely into a weighted auto-regressive losses over these orders, which establishes them as auto-regressive models with learnable orders.

</details>


### [507] [RAVEN++: Pinpointing Fine-Grained Violations in Advertisement Videos with Active Reinforcement Reasoning](https://arxiv.org/abs/2511.19168)
*Deyi Ji,Yuekui Yang,Liqun Liu,Peng Shu,Haiyang Wu,Shaogang Tang,Xudong Chen,Shaoping Ma,Tianrun Chen,Lanyun Zhu*

Main category: cs.LG

TL;DR: RAVEN++是一个针对视频广告审核的改进框架，通过主动强化学习、细粒度违规理解和渐进式多阶段训练，显著提升了违规检测的精确度、可解释性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有视频广告审核模型（如RAVEN）在细粒度理解、可解释性和泛化能力方面存在不足，无法满足复杂广告内容的精确违规定位需求。

Method: 提出三个核心创新：1）主动强化学习动态调整训练难度；2）通过分层奖励函数和推理蒸馏实现细粒度违规理解；3）渐进式多阶段训练结合知识注入、课程式被动RL和主动RL。

Result: 在公开和专有数据集上的实验表明，RAVEN++在细粒度违规理解、推理能力和泛化性能上均优于通用LLMs和专用模型RAVEN，在线A/B测试也验证了其有效性。

Conclusion: RAVEN++框架成功解决了视频广告审核中的关键挑战，为复杂数字内容 moderation 提供了更精确、可解释和可泛化的解决方案。

Abstract: Advertising (Ad) is a cornerstone of the digital economy, yet the moderation of video advertisements remains a significant challenge due to their complexity and the need for precise violation localization. While recent advancements, such as the RAVEN model, have improved coarse-grained violation detection, critical gaps persist in fine-grained understanding, explainability, and generalization. To address these limitations, we propose RAVEN++, a novel framework that introduces three key innovations: 1) Active Reinforcement Learning (RL), which dynamically adapts training to samples of varying difficulty; 2) Fine-Grained Violation Understanding, achieved through hierarchical reward functions and reasoning distillation; and 3) Progressive Multi-Stage Training, which systematically combines knowledge injection, curriculum-based passive RL, and active RL. Extensive experiments on both public and proprietary datasets, on both offline scenarios and online deployed A/B Testing, demonstrate that RAVEN++ outperforms general-purpose LLMs and specialized models like RAVEN in terms of fine-grained violation understanding, reasoning capabilities, and generalization ability.

</details>


### [508] [From Raw Features to Effective Embeddings: A Three-Stage Approach for Multimodal Recipe Recommendation](https://arxiv.org/abs/2511.19176)
*Jeeho Shin,Kyungho Kim,Kijung Shin*

Main category: cs.LG

TL;DR: TESMR是一个三阶段框架，通过内容增强、关系增强和学习增强来优化多模态特征，在食谱推荐任务中实现7-15%的Recall@10提升


<details>
  <summary>Details</summary>
Motivation: 食谱推荐需要有效利用多模态特征，现有方法对多模态信号的利用不够系统化，而简单使用多模态特征就能达到竞争性效果，表明系统化增强这些信号具有很大潜力

Method: 提出TESMR三阶段框架：1）基于内容的增强：使用具有多模态理解能力的基础模型；2）基于关系的增强：通过用户-食谱交互的消息传播；3）基于学习的增强：通过可学习嵌入的对比学习

Result: 在两个真实数据集上的实验表明，TESMR优于现有方法，Recall@10指标提高了7-15%

Conclusion: 系统化增强多模态信号的方法在食谱推荐任务中表现优异，证明了多模态特征在推荐系统中的重要性

Abstract: Recipe recommendation has become an essential task in web-based food platforms. A central challenge is effectively leveraging rich multimodal features beyond user-recipe interactions. Our analysis shows that even simple uses of multimodal signals yield competitive performance, suggesting that systematic enhancement of these signals is highly promising. We propose TESMR, a 3-stage framework for recipe recommendation that progressively refines raw multimodal features into effective embeddings through: (1) content-based enhancement using foundation models with multimodal comprehension, (2) relation-based enhancement via message propagation over user-recipe interactions, and (3) learning-based enhancement through contrastive learning with learnable embeddings. Experiments on two real-world datasets show that TESMR outperforms existing methods, achieving 7-15% higher Recall@10.

</details>


### [509] [Empirical Comparison of Forgetting Mechanisms for UCB-based Algorithms on a Data-Driven Simulation Platform](https://arxiv.org/abs/2511.19240)
*Minxin Chen*

Main category: cs.LG

TL;DR: 本文提出FDSW-UCB算法，结合折扣长期视角和滑动窗口短期视角，有效解决非平稳多臂老虎机问题，在动态环境中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的老虎机问题往往涉及非平稳奖励分布，传统UCB算法在奖励分布随时间变化的非平稳环境中性能显著下降。

Method: 提出FDSW-UCB双视角算法，集成基于折扣的长期视角和基于滑动窗口的短期视角，并开发基于MovieLens-1M和Open Bandit数据集的半合成仿真平台。

Result: 实验表明滑动窗口机制稳健，而广泛使用的折扣方法存在基本学习失败问题；FDSW-UCB采用乐观聚合策略在动态环境中表现最佳。

Conclusion: 集成策略本身是成功的关键因素，FDSW-UCB在非平稳环境中具有优越性能。

Abstract: Many real-world bandit problems involve non-stationary reward distributions, where the optimal decision may shift due to evolving environments. However, the performance of some typical Multi-Armed Bandit (MAB) models such as Upper Confidence Bound (UCB) algorithms degrades significantly in non-stationary environments where reward distributions change over time. To address this limitation, this paper introduces and evaluates FDSW-UCB, a novel dual-view algorithm that integrates a discount-based long-term perspective with a sliding-window-based short-term view. A data-driven semi-synthetic simulation platform, built upon the MovieLens-1M and Open Bandit datasets, is developed to test algorithm adaptability under abrupt and gradual drift scenarios. Experimental results demonstrate that a well-configured sliding-window mechanism (SW-UCB) is robust, while the widely used discounting method (D-UCB) suffers from a fundamental learning failure, leading to linear regret. Crucially, the proposed FDSW-UCB, when employing an optimistic aggregation strategy, achieves superior performance in dynamic settings, highlighting that the ensemble strategy itself is a decisive factor for success.

</details>


### [510] [Local Entropy Search over Descent Sequences for Bayesian Optimization](https://arxiv.org/abs/2511.19241)
*David Stenger,Armin Lindicke,Alexander von Rohr,Sebastian Trimpe*

Main category: cs.LG

TL;DR: 提出局部熵搜索（LES），一种贝叶斯优化方法，专门针对迭代优化器的下降序列可达解，通过传播后验信念和最大化互信息实现高效样本优化。


<details>
  <summary>Details</summary>
Motivation: 在大型复杂设计空间中搜索全局最优解往往不可行且不必要，需要一种针对局部优化器可达解的实用替代方法。

Method: 通过传播目标函数的后验信念通过优化器，产生下降序列的概率分布，然后结合解析熵计算和蒙特卡洛采样最大化互信息来选择下一个评估点。

Result: 在高复杂度合成目标和基准问题上的实验表明，LES相比现有局部和全局贝叶斯优化方法具有更强的样本效率。

Conclusion: 局部熵搜索为迭代优化器提供了有效的贝叶斯优化框架，在复杂优化问题中表现出优越的样本效率。

Abstract: Searching large and complex design spaces for a global optimum can be infeasible and unnecessary. A practical alternative is to iteratively refine the neighborhood of an initial design using local optimization methods such as gradient descent. We propose local entropy search (LES), a Bayesian optimization paradigm that explicitly targets the solutions reachable by the descent sequences of iterative optimizers. The algorithm propagates the posterior belief over the objective through the optimizer, resulting in a probability distribution over descent sequences. It then selects the next evaluation by maximizing mutual information with that distribution, using a combination of analytic entropy calculations and Monte-Carlo sampling of descent sequences. Empirical results on high-complexity synthetic objectives and benchmark problems show that LES achieves strong sample efficiency compared to existing local and global Bayesian optimization methods.

</details>


### [511] [MAESTRO: Multi-Agent Environment Shaping through Task and Reward Optimization](https://arxiv.org/abs/2511.19253)
*Boyuan Wu*

Main category: cs.LG

TL;DR: MAESTRO框架将LLM从执行循环中移出，作为离线训练架构师，通过语义课程生成器和自动奖励合成器指导标准MARL算法，在交通信号控制任务中实现了性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决协作多智能体强化学习中设计密集奖励函数和构建避免局部最优的课程这两个主要瓶颈问题，避免现有方法依赖固定启发式或直接在控制循环中使用昂贵LLM的局限性。

Method: 提出MAESTRO框架，包含两个生成组件：语义课程生成器创建多样化交通场景，自动奖励合成器生成可执行的Python奖励函数。这些组件指导MADDPG算法而不增加部署时的推理成本。

Result: 在16个交叉路口的大规模交通信号控制任务中，相比强课程基线，MAESTRO实现了平均回报+4.0%提升（163.26 vs. 156.93）和风险调整后性能2.2%改善（夏普比率1.53 vs. 0.70）。

Conclusion: LLM可以作为协作多智能体强化学习训练的有效高层设计者，MAESTRO框架展示了将LLM用于离线课程和奖励设计的潜力。

Abstract: Cooperative Multi-Agent Reinforcement Learning (MARL) faces two major design bottlenecks: crafting dense reward functions and constructing curricula that avoid local optima in high-dimensional, non-stationary environments. Existing approaches rely on fixed heuristics or use Large Language Models (LLMs) directly in the control loop, which is costly and unsuitable for real-time systems. We propose MAESTRO (Multi-Agent Environment Shaping through Task and Reward Optimization), a framework that moves the LLM outside the execution loop and uses it as an offline training architect. MAESTRO introduces two generative components: (i) a semantic curriculum generator that creates diverse, performance-driven traffic scenarios, and (ii) an automated reward synthesizer that produces executable Python reward functions adapted to evolving curriculum difficulty. These components guide a standard MARL backbone (MADDPG) without increasing inference cost at deployment. We evaluate MAESTRO on large-scale traffic signal control (Hangzhou, 16 intersections) and conduct controlled ablations. Results show that combining LLM-generated curricula with LLM-generated reward shaping yields improved performance and stability. Across four seeds, the full system achieves +4.0% higher mean return (163.26 vs. 156.93) and 2.2% better risk-adjusted performance (Sharpe 1.53 vs. 0.70) over a strong curriculum baseline. These findings highlight LLMs as effective high-level designers for cooperative MARL training.

</details>


### [512] [A Nutrition Multimodal Photoplethysmography Language Model](https://arxiv.org/abs/2511.19260)
*Kyle Verrier,Achille Nazaret,Joseph Futoma,Andrew C. Miller,Guillermo Sapiro*

Main category: cs.LG

TL;DR: 提出了一种结合可穿戴设备PPG信号和饮食描述的营养光电容积脉搏波语言模型(NPLM)，用于非侵入性饮食监测


<details>
  <summary>Details</summary>
Motivation: 饥饿和饱腹感动态影响饮食行为和代谢健康，但在日常环境中难以捕捉

Method: 将可穿戴设备的连续PPG信号与饮食描述结合，通过投影PPG到语言模型可理解的嵌入空间，实现生理信号和饮食背景的联合推理

Result: 在19340名参与者和110万份餐食-PPG对数据上训练，模型比纯文本基线提高了11%的每日热量摄入预测准确率，即使去除80%的饮食文本信息仍能保持准确性

Conclusion: 结果表明将消费级可穿戴设备的生理测量与饮食信息结合，可实现大规模非侵入性饮食监测的重要价值

Abstract: Hunger and satiety dynamics shape dietary behaviors and metabolic health, yet remain difficult to capture in everyday settings. We present a Nutrition Photoplethysmography Language Model (NPLM), integrating continuous photoplethysmography (PPG) from wearables with meal descriptions. NPLM projects PPG into embeddings interpretable by language models, enabling joint reasoning over physiology and meal context. Trained on 19,340 participants and 1.1 million meal-PPG pairs, the model improved daily caloric intake prediction by 11% over text-only baselines, with accuracy maintained when 80% of meal text was removed. In an independent validation study (n=140) with controlled dining and detailed meal information, the model replicated these findings. These results demonstrate the value of integrating physiological measurements from consumer wearables with meal information for noninvasive dietary monitoring at scale.

</details>


### [513] [Solar-GECO: Perovskite Solar Cell Property Prediction with Geometric-Aware Co-Attention](https://arxiv.org/abs/2511.19263)
*Lucas Li,Jean-Baptiste Puel,Florence Carton,Dounya Barrit,Jhony H. Giraldo*

Main category: cs.LG

TL;DR: 提出了Solar-GECO模型，通过几何感知的共注意力机制预测钙钛矿太阳能电池的功率转换效率，结合几何图神经网络和语言模型嵌入，显著提升了预测精度。


<details>
  <summary>Details</summary>
Motivation: 钙钛矿太阳能电池的性能受多层材料复杂相互作用影响，传统实验筛选方法耗时昂贵。现有机器学习模型忽视钙钛矿晶体的几何信息，限制了预测准确性。

Method: Solar-GECO模型结合几何图神经网络（编码钙钛矿吸收层的原子结构）和语言模型嵌入（处理传输层等组件的文本字符串），采用共注意力模块捕获层内依赖和层间相互作用，使用概率回归头预测PCE及其不确定性。

Result: Solar-GECO达到最先进性能，将PCE预测的平均绝对误差从3.066降至2.936，显著优于语义GNN等基线模型。

Conclusion: 集成几何和文本信息为PCE预测提供了更强大准确的框架，证明了多模态信息融合的有效性。

Abstract: Perovskite solar cells are promising candidates for next-generation photovoltaics. However, their performance as multi-scale devices is determined by complex interactions between their constituent layers. This creates a vast combinatorial space of possible materials and device architectures, making the conventional experimental-based screening process slow and expensive. Machine learning models try to address this problem, but they only focus on individual material properties or neglect the important geometric information of the perovskite crystal. To address this problem, we propose to predict perovskite solar cell power conversion efficiency with a geometric-aware co-attention (Solar-GECO) model. Solar-GECO combines a geometric graph neural network (GNN) - that directly encodes the atomic structure of the perovskite absorber - with language model embeddings that process the textual strings representing the chemical compounds of the transport layers and other device components. Solar-GECO also integrates a co-attention module to capture intra-layer dependencies and inter-layer interactions, while a probabilistic regression head predicts both power conversion efficiency (PCE) and its associated uncertainty. Solar-GECO achieves state-of-the-art performance, significantly outperforming several baselines, reducing the mean absolute error (MAE) for PCE prediction from 3.066 to 2.936 compared to semantic GNN (the previous state-of-the-art model). Solar-GECO demonstrates that integrating geometric and textual information provides a more powerful and accurate framework for PCE prediction.

</details>


### [514] [Interpreting GFlowNets for Drug Discovery: Extracting Actionable Insights for Medicinal Chemistry](https://arxiv.org/abs/2511.19264)
*Amirtha Varshini A S,Duminda S. Ranasinghe,Hok Hei Tam*

Main category: cs.LG

TL;DR: 提出了一个可解释性框架来分析SynFlowNet（一种用于分子设计的GFlowNet）的内部决策机制，通过梯度显著性、稀疏自编码器和基序探针三种方法揭示其化学逻辑。


<details>
  <summary>Details</summary>
Motivation: GFlowNets在分子设计中具有潜力，但其内部决策策略不透明，限制了在药物发现中的应用，因为化学家需要清晰可解释的分子结构生成理由。

Method: 集成三种互补组件：1）基于梯度的显著性与反事实扰动结合，识别影响奖励的原子环境；2）稀疏自编码器揭示与物理化学性质对应的潜在因子；3）基序探针显示功能基团在内部嵌入中的显式编码。

Result: 成功揭示了SynFlowNet内部的化学逻辑，包括极性、亲脂性和分子大小等物理化学性质的轴对齐潜在因子，以及芳香环和卤素等功能基团的线性可解码编码。

Conclusion: 该框架为SynFlowNet提供了可操作和机制性的洞察，支持透明和可控的分子设计，促进了GFlowNets在药物发现中的采用。

Abstract: Generative Flow Networks, or GFlowNets, offer a promising framework for molecular design, but their internal decision policies remain opaque. This limits adoption in drug discovery, where chemists require clear and interpretable rationales for proposed structures. We present an interpretability framework for SynFlowNet, a GFlowNet trained on documented chemical reactions and purchasable starting materials that generates both molecules and the synthetic routes that produce them. Our approach integrates three complementary components. Gradient based saliency combined with counterfactual perturbations identifies which atomic environments influence reward and how structural edits change molecular outcomes. Sparse autoencoders reveal axis aligned latent factors that correspond to physicochemical properties such as polarity, lipophilicity, and molecular size. Motif probes show that functional groups including aromatic rings and halogens are explicitly encoded and linearly decodable from the internal embeddings. Together, these results expose the chemical logic inside SynFlowNet and provide actionable and mechanistic insight that supports transparent and controllable molecular design.

</details>


### [515] [Unboxing the Black Box: Mechanistic Interpretability for Algorithmic Understanding of Neural Networks](https://arxiv.org/abs/2511.19265)
*Bianka Kowalska,Halina Kwaśnicka*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The black box nature of deep neural networks poses a significant challenge for the deployment of transparent and trustworthy artificial intelligence (AI) systems. With the growing presence of AI in society, it becomes increasingly important to develop methods that can explain and interpret the decisions made by these systems. To address this, mechanistic interpretability (MI) emerged as a promising and distinctive research program within the broader field of explainable artificial intelligence (XAI). MI is the process of studying the inner computations of neural networks and translating them into human-understandable algorithms. It encompasses reverse engineering techniques aimed at uncovering the computational algorithms implemented by neural networks. In this article, we propose a unified taxonomy of MI approaches and provide a detailed analysis of key techniques, illustrated with concrete examples and pseudo-code. We contextualize MI within the broader interpretability landscape, comparing its goals, methods, and insights to other strands of XAI. Additionally, we trace the development of MI as a research area, highlighting its conceptual roots and the accelerating pace of recent work. We argue that MI holds significant potential to support a more scientific understanding of machine learning systems -- treating models not only as tools for solving tasks, but also as systems to be studied and understood. We hope to invite new researchers into the field of mechanistic interpretability.

</details>


### [516] [Leveraging Spatiotemporal Graph Neural Networks for Multi-Store Sales Forecasting](https://arxiv.org/abs/2511.19267)
*Manish Singh,Arpita Dayama*

Main category: cs.LG

TL;DR: 本文评估了时空图神经网络在多店零售销售预测中的有效性，并与ARIMA、LSTM和XGBoost基线模型进行比较，结果表明STGNN在各项误差指标上均优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 研究多店零售环境中店铺间相互依赖关系对销售预测的影响，探索图神经网络在建模这种复杂关系方面的潜力。

Method: 使用45家沃尔玛商店的周销售数据，构建关系预测框架，通过学习的自适应图建模店铺间依赖关系。提出的STGNN预测对数差分销售数据，并通过残差路径重建最终值，实现稳定训练和更好泛化。

Result: STGNN在所有预测误差指标上（归一化总绝对误差、P90 MAPE和MAPE方差）均达到最低，显著优于所有基线模型。学习的邻接矩阵分析揭示了有意义的店铺功能集群和重要节点，无需地理元数据即可识别。

Conclusion: 关系结构显著提高了互联零售环境中的预测质量，确立了STGNN作为多店需求预测的稳健建模选择。

Abstract: This work evaluates the effectiveness of spatiotemporal Graph Neural Networks (GNNs) for multi-store retail sales forecasting and compares their performance against ARIMA, LSTM, and XGBoost baselines. Using weekly sales data from 45 Walmart stores, we construct a relational forecasting framework that models inter-store dependencies through a learned adaptive graph. The proposed STGNN predicts log-differenced sales and reconstructs final values through a residual path, enabling stable training and improved generalisation. Experiments show that STGNN achieves the lowest overall forecasting error, outperforming all baselines in Normalised Total Absolute Error, P90 MAPE, and variance of MAPE across stores. Analysis of the learned adjacency matrix reveals meaningful functional store clusters and high-influence nodes that emerge without geographic metadata. These results demonstrate that relational structure significantly improves forecast quality in interconnected retail environments and establishes STGNNs as a robust modelling choice for multi-store demand prediction.

</details>


### [517] [CDLM: Consistency Diffusion Language Models For Faster Sampling](https://arxiv.org/abs/2511.19269)
*Minseo Kim,Chenfeng Xu,Coleman Hooper,Harman Singh,Ben Athiwaratkun,Ce Zhang,Kurt Keutzer,Amir Gholami*

Main category: cs.LG

TL;DR: CDLM通过一致性建模和块状因果注意力掩码，将扩散语言模型的推理延迟降低3.6-14.5倍，同时保持数学和编程任务的竞争性准确率。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型具有并行生成优势，但存在推理速度慢（需要大量细化步骤）和无法使用标准KV缓存的问题。

Method: 结合一致性建模实现多token最终化以减少采样步骤，并在微调时强制使用块状因果注意力掩码以实现KV缓存兼容。

Result: 在数学和编程任务上实现3.6-14.5倍的延迟降低，同时保持竞争性准确率。

Conclusion: CDLM有效解决了扩散语言模型的两个主要瓶颈，为实际应用提供了可行的加速方案。

Abstract: Diffusion Language Models (DLMs) offer a promising parallel generation paradigm but suffer from slow inference due to numerous refinement steps and the inability to use standard KV caching. We introduce CDLM (Consistency Diffusion Language Models), a training-based acceleration method that simultaneously tackles both bottlenecks. CDLM integrates consistency modeling to drastically reduce the number of required sampling steps by enabling multi-token finalization. Furthermore, we enforce a block-wise causal attention mask during fine-tuning, making the model fully compatible with KV caching. Experiments show CDLM achieves 3.6x-14.5x lower latency while maintaining competitive accuracy on math and coding tasks. The full training and evaluation code is available at https://github.com/SqueezeAILab/CDLM.

</details>


### [518] [Tiny-TSM: Efficiently Training a Lightweight SOTA Time Series Foundation Model](https://arxiv.org/abs/2511.19272)
*Felix Birkel*

Main category: cs.LG

TL;DR: Tiny-TSM是一个小规模、经济高效的时间序列基础模型，仅用23M参数在单张A100 GPU上训练不到一周，通过新的合成数据生成和数据增强管道(SynthTS)实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有时间序列基础模型规模过大、训练成本高的问题，开发一个资源受限环境下实用的高效模型。

Method: 使用新的合成数据生成和数据增强管道(SynthTS)，引入因果输入归一化方案，使模型能够通过密集的下一个token预测损失进行训练，显著加速收敛速度。

Result: 在中长期预测任务上MSE损失优于所有其他时间序列基础模型，短期预测精度与最先进模型相当，甚至在性能上匹配了更大规模的工业级基础模型。

Conclusion: Tiny-TSM证明了无需神经架构搜索、超参数调优或扩大模型规模，也能实现卓越性能，为资源受限环境提供了实用的时间序列建模解决方案。

Abstract: We present Tiny-TSM, a time series foundation model characterized by small scale, economical training, and state-of-the-art performance. It comprises 23M total parameters, trained on a single A100 GPU in less than a week using a new synthetic data generation and data augmentation pipeline (SynthTS). Without any neural architecture search, hyperparameter tuning, or scaling up model size, Tiny-TSM achieves state-of-the-art performance on a wide range of time series benchmark datasets, often outperforming much larger models and even matching the performance of much larger, industrial-scale, likely highly tuned foundation models. Specifically, Tiny-TSM outperforms all other time series foundation models we evaluated on medium- and long-term forecasting tasks under MSE loss, while short-term accuracy is still competitive with state-of-the-art models.
  We also introduce a causal input normalization scheme that enables time series models to be trained with dense next-token prediction loss, significantly accelerating convergence speed and reducing training time.
  All experiments were conducted on a single A100 GPU, illustrating the practicality of the proposed approach in a resource-constrained setting.

</details>


### [519] [Scalable Bayesian Network Structure Learning Using Tsetlin Machine to Constrain the Search Space](https://arxiv.org/abs/2511.19273)
*Kunal Dumbre,Lei Jiao,Ole-Christoffer Granmo*

Main category: cs.LG

TL;DR: 提出一种基于Tsetlin Machine的贝叶斯网络结构学习方法，通过选择重要变量进行条件独立性测试，显著降低PC算法的时间复杂度。


<details>
  <summary>Details</summary>
Motivation: PC算法在大规模数据集上存在显著的时间复杂度问题，限制了其在实际应用中的适用性。

Method: 利用Tsetlin Machine提取最重要的文字，仅对选定的文字进行条件独立性测试，而不是对所有变量进行测试。

Result: 在bnlearn存储库的分类数据集（如Munin1、Hepar2）上评估表明，该方法不仅降低了计算复杂度，而且保持了竞争性的因果发现准确性。

Conclusion: 基于TM的方法是一种可行的替代传统PC算法的方法，在不影响性能的情况下提高了效率。

Abstract: The PC algorithm is a widely used method in causal inference for learning the structure of Bayesian networks. Despite its popularity, the PC algorithm suffers from significant time complexity, particularly as the size of the dataset increases, which limits its applicability in large-scale real-world problems. In this study, we propose a novel approach that utilises the Tsetlin Machine (TM) to construct Bayesian structures more efficiently. Our method leverages the most significant literals extracted from the TM and performs conditional independence (CI) tests on these selected literals instead of the full set of variables, resulting in a considerable reduction in computational time. We implemented our approach and compared it with various state-of-the-art methods. Our evaluation includes categorical datasets from the bnlearn repository, such as Munin1, Hepar2. The findings indicate that the proposed TM-based method not only reduces computational complexity but also maintains competitive accuracy in causal discovery, making it a viable alternative to traditional PC algorithm implementations by offering improved efficiency without compromising performance.

</details>


### [520] [Closing Gaps in Emissions Monitoring with Climate TRACE](https://arxiv.org/abs/2511.19277)
*Brittany V. Lancellotti,Jordan M. Malof,Aaron Davitt,Gavin McCormick,Shelby Anderson,Pol Carbó-Mestre,Gary Collins,Verity Crane,Zoheyr Doctor,George Ebri,Kevin Foster,Trey M. Gowdy,Michael Guzzardi,John Heal,Heather Hunter,David Kroodsma,Khandekar Mahammad Galib,Paul J. Markakis,Gavin McDonald,Daniel P. Moore,Eric D. Nguyen,Sabina Parvu,Michael Pekala,Christine D. Piatko,Amy Piscopo,Mark Powell,Krsna Raniga,Elizabeth P. Reilly,Michael Robinette,Ishan Saraswat,Patrick Sicurello,Isabella Söldner-Rembold,Raymond Song,Charlotte Underwood,Kyle Bradbury*

Main category: cs.LG

TL;DR: Climate TRACE是一个开源平台，提供全球温室气体排放估算，具有高精度、全球覆盖、高时空分辨率和频繁更新的特点。


<details>
  <summary>Details</summary>
Motivation: 解决现有排放数据集缺乏准确性、全球覆盖、高时空分辨率和频繁更新等关键特性的问题，以支持更有效的监测和减排规划。

Method: 综合现有排放数据，优先考虑准确性、覆盖范围和分辨率，并使用特定行业的估算方法来填补数据空白。

Result: 创建了首个提供全球全面排放估算的数据集，涵盖所有人为排放行业，包括单个排放源（如发电厂），数据从2021年1月1日至今，每月更新，报告延迟为两个月。

Conclusion: Climate TRACE支持数据驱动的气候行动，代表了排放核算和减排领域的重大突破，使非技术用户能够参与全球大多数地方政府的详细排放数据集。

Abstract: Global greenhouse gas emissions estimates are essential for monitoring and mitigation planning. Yet most datasets lack one or more characteristics that enhance their actionability, such as accuracy, global coverage, high spatial and temporal resolution, and frequent updates. To address these gaps, we present Climate TRACE (climatetrace.org), an open-access platform delivering global emissions estimates with enhanced detail, coverage, and timeliness. Climate TRACE synthesizes existing emissions data, prioritizing accuracy, coverage, and resolution, and fills gaps using sector-specific estimation approaches. The dataset is the first to provide globally comprehensive emissions estimates for individual sources (e.g., individual power plants) for all anthropogenic emitting sectors. The dataset spans January 1, 2021, to the present, with a two-month reporting lag and monthly updates. The open-access platform enables non-technical audiences to engage with detailed emissions datasets for most subnational governments worldwide. Climate TRACE supports data-driven climate action at scales where decisions are made, representing a major breakthrough for emissions accounting and mitigation.

</details>


### [521] [MapFormer: Self-Supervised Learning of Cognitive Maps with Input-Dependent Positional Embeddings](https://arxiv.org/abs/2511.19279)
*Victor Rambaud,Salvador Mascarenhas,Yair Lakretz*

Main category: cs.LG

TL;DR: MapFormers是基于Transformer的新架构，能够从观测数据中学习认知地图并并行执行路径整合，具有出色的OOD泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统缺乏人类和动物所具备的认知地图能力，无法灵活适应新情境。为了弥合这一差距，需要开发能够学习结构化关系模型的架构。

Method: 通过更新Transformer中的位置编码为输入依赖矩阵，自然实现结构-内容解耦。开发了两种MapFormers变体，分别统一绝对和相对位置编码来建模情景记忆和工作记忆。

Result: 在2D导航等任务中，MapFormers能够学习底层空间的认知地图，并在OOD泛化（如更长的序列）上达到近乎完美的性能，优于现有架构。

Conclusion: 结果表明设计用于学习认知地图的模型的优越性，以及引入结构偏置实现结构-内容解耦的重要性。MapFormers在神经科学和AI领域具有广泛应用前景。

Abstract: A cognitive map is an internal model which encodes the abstract relationships among entities in the world, giving humans and animals the flexibility to adapt to new situations, with a strong out-of-distribution (OOD) generalization that current AI systems still do not possess. To bridge this gap, we introduce MapFormers, new architectures based on Transformer models, which can learn cognitive maps from observational data and perform path integration in parallel, in a self-supervised manner. Cognitive maps are learned in the model by disentangling structural relationships in the inputs from their specific content, a property that can be achieved naturally by updating the positional encoding in Transformers with input-dependent matrices. We developed two variants of MapFormers that unify absolute and relative positional encoding to model episodic (EM) and working memory (WM), respectively. We tested MapFormers on several tasks, including a classic 2D navigation task, showing that our models can learn a cognitive map of the underlying space and generalize OOD (e.g., to longer sequences) with near-perfect performance, unlike current architectures. Together, these results demonstrate the superiority of models designed to learn a cognitive map, and the importance of introducing a structural bias for structure-content disentanglement, which can be achieved in Transformers with input-dependent positional encoding. MapFormers have broad applications in both neuroscience and AI, by explaining the neural mechanisms giving rise to cognitive maps, while allowing these relation models to be learned at scale.

</details>


### [522] [Open-weight genome language model safeguards: Assessing robustness via adversarial fine-tuning](https://arxiv.org/abs/2511.19299)
*James R. M. Black,Moritz S. Hanke,Aaron Maiwald,Tina Hernandez-Boussard,Oliver M. Crook,Jaspreet Pannu*

Main category: cs.LG

TL;DR: 研究表明，通过微调基因组语言模型（gLM）可以绕过预训练数据过滤的安全措施，恢复模型对有害病毒的预测能力，揭示了当前数据排除策略的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 随着基因组语言模型在生物数据中的应用日益广泛，人们担心这些模型可能被滥用于生成人类感染病毒的基因组。当前主流的风险缓解措施是过滤预训练数据（移除病毒基因组序列），但这种方法对可微调的开源模型的安全性尚不明确。

Method: 评估了最先进的gLM模型Evo 2，通过对110种有害人类感染病毒的序列进行微调，测试模型在病毒相关任务上能力的恢复情况。比较了预训练模型、在噬菌体序列上微调的模型以及在人类感染病毒上微调的模型的性能差异。

Result: 微调后的模型在未见过的病毒序列上表现出更低的困惑度，且能够识别SARS-CoV-2的免疫逃逸变异（AUROC达到0.6），尽管在微调过程中未接触过SARS-CoV-2序列。这表明数据排除策略可能被微调方法绕过。

Conclusion: 数据排除作为安全措施存在局限性，需要建立更完善的gLM安全框架，包括评估和缓解措施，以确保gLM的安全部署。

Abstract: Novel deep learning architectures are increasingly being applied to biological data, including genetic sequences. These models, referred to as genomic language mod- els (gLMs), have demonstrated impressive predictive and generative capabilities, raising concerns that such models may also enable misuse, for instance via the generation of genomes for human-infecting viruses. These concerns have catalyzed calls for risk mitigation measures. The de facto mitigation of choice is filtering of pretraining data (i.e., removing viral genomic sequences from training datasets) in order to limit gLM performance on virus-related tasks. However, it is not currently known how robust this approach is for securing open-source models that can be fine-tuned using sensitive pathogen data. Here, we evaluate a state-of-the-art gLM, Evo 2, and perform fine-tuning using sequences from 110 harmful human-infecting viruses to assess the rescue of misuse-relevant predictive capabilities. The fine- tuned model exhibited reduced perplexity on unseen viral sequences relative to 1) the pretrained model and 2) a version fine-tuned on bacteriophage sequences. The model fine-tuned on human-infecting viruses also identified immune escape variants from SARS-CoV-2 (achieving an AUROC of 0.6), despite having no expo- sure to SARS-CoV-2 sequences during fine-tuning. This work demonstrates that data exclusion might be circumvented by fine-tuning approaches that can, to some degree, rescue misuse-relevant capabilities of gLMs. We highlight the need for safety frameworks for gLMs and outline further work needed on evaluations and mitigation measures to enable the safe deployment of gLMs.

</details>


### [523] [Understanding the Staged Dynamics of Transformers in Learning Latent Structure](https://arxiv.org/abs/2511.19328)
*Rohan Saha,Farzane Aminmansour,Alona Fyshe*

Main category: cs.LG

TL;DR: 该研究使用Alchemy基准探索Transformer学习潜在结构的动态过程，发现模型以离散阶段方式学习，先掌握粗粒度规则再学习完整潜在结构，并识别出组合能力与分解能力的不对称性。


<details>
  <summary>Details</summary>
Motivation: 理解Transformer如何从上下文中发现潜在结构，特别是不同组件学习过程的动态特性目前尚不清楚。

Method: 使用小型仅解码器Transformer在Alchemy基准上进行三个任务变体的训练：从部分上下文推断缺失规则、组合简单规则解决多步序列、分解复杂多步示例推断中间步骤。

Result: 模型以离散阶段方式学习能力，先学习粗粒度规则再学习完整潜在结构；发现组合基本规则能力强但分解复杂示例发现基本规则能力弱的不对称性。

Conclusion: 这些发现为理解Transformer模型如何学习潜在结构提供了新见解，展示了训练过程中这些能力如何逐步演化的细粒度视图。

Abstract: While transformers can discover latent structure from context, the dynamics of how they acquire different components of the latent structure remain poorly understood. In this work, we use the Alchemy benchmark, to investigate the dynamics of latent structure learning. We train a small decoder-only transformer on three task variants: 1) inferring missing rules from partial contextual information, 2) composing simple rules to solve multi-step sequences, and 3) decomposing complex multi-step examples to infer intermediate steps. By factorizing each task into interpretable events, we show that the model acquires capabilities in discrete stages, first learning the coarse grained rules, before learning the complete latent structure. We also identify a crucial asymmetry, where the model can compose fundamental rules robustly, but struggles to decompose complex examples to discover the fundamental rules. These findings offer new insights into understanding how a transformer model learns latent structures, providing a granular view of how these capabilities evolve during training.

</details>


### [524] [Targeted Manipulation: Slope-Based Attacks on Financial Time-Series Data](https://arxiv.org/abs/2511.19330)
*Dominik Luszczynski*

Main category: cs.LG

TL;DR: 该论文提出了两种新的基于斜率的对抗攻击方法，针对时间序列金融预测模型N-HiTS，能够绕过标准安全机制并成功操纵预测结果。


<details>
  <summary>Details</summary>
Motivation: 对抗攻击在图像领域已有深入研究，但在时间序列领域特别是金融数据预测方面研究较少，需要探索针对金融时间序列的新型对抗攻击方法。

Method: 开发了两种基于斜率的攻击方法：通用斜率攻击和最小二乘斜率攻击，通过改变预测股票走势的斜率来操纵模型输出，并将这些方法集成到GAN架构中生成逼真的合成数据。

Result: 新攻击方法能够将N-HiTS预测的斜率加倍，成功绕过4层CNN鉴别器（特异性降至28%，准确率降至57%），并设计了恶意软件证明整个推理流程需要安全保护。

Conclusion: 机器学习安全研究不应仅关注模型安全性，还需要保护整个数据处理流程，金融时间序列预测系统需要更全面的安全防护措施。

Abstract: A common method of attacking deep learning models is through adversarial attacks, which occur when an attacker specifically modifies the input of a model to produce an incorrect result. Adversarial attacks have been deeply investigated in the image domain; however, there is less research in the time-series domain and very little for forecasting financial data. To address these concerns, this study aims to build upon previous research on adversarial attacks for time-series data by introducing two new slope-based methods aimed to alter the trends of the predicted stock forecast generated by an N-HiTS model. Compared to the normal N-HiTS predictions, the two new slope-based methods, the General Slope Attack and Least-Squares Slope Attack, can manipulate N-HiTS predictions by doubling the slope. These new slope attacks can bypass standard security mechanisms, such as a discriminator that filters real and perturbed inputs, reducing a 4-layered CNN's specificity to 28% and accuracy to 57%. Furthermore, the slope based methods were incorporated into a GAN architecture as a means of generating realistic synthetic data, while simultaneously fooling the model. Finally, this paper also proposes a sample malware designed to inject an adversarial attack in the model inference library, proving that ML-security research should not only focus on making the model safe, but also securing the entire pipeline.

</details>


### [525] [Annotation-Free Class-Incremental Learning](https://arxiv.org/abs/2511.19344)
*Hari Chandana Kuchibhotla,K S Ananth,Vineeth N Balasubramanian*

Main category: cs.LG

TL;DR: 本文提出了Annotation-Free Class-Incremental Learning (AFCIL)这一更现实的持续学习范式，并开发了CrossWorld-CL框架，利用外部世界知识在没有标注的情况下实现有效的类别增量学习。


<details>
  <summary>Details</summary>
Motivation: 现有持续学习方法都假设在整个学习过程中有标注数据可用，但现实世界中数据往往是按顺序到达且没有标注的，这使得传统方法不实用。

Method: 提出CrossWorld CL框架，通过检索与下游类别语义相关的ImageNet类别，使用跨域对齐策略映射特征，并引入新颖的重放策略，在没有标注的情况下发现语义结构并保持先前知识。

Result: 在四个数据集上的实验表明，CrossWorld-CL超越了CLIP基线和现有的持续学习及无标注学习方法。

Conclusion: 世界知识对于无标注持续学习具有重要价值，该框架为解决现实世界中的持续学习问题提供了有效方案。

Abstract: Despite significant progress in continual learning ranging from architectural novelty to clever strategies for mitigating catastrophic forgetting most existing methods rest on a strong but unrealistic assumption the availability of labeled data throughout the learning process. In real-world scenarios, however, data often arrives sequentially and without annotations, rendering conventional approaches impractical. In this work, we revisit the fundamental assumptions of continual learning and ask: Can current systems adapt when labels are absent and tasks emerge incrementally over time? To this end, we introduce Annotation-Free Class-Incremental Learning (AFCIL), a more realistic and challenging paradigm where unlabeled data arrives continuously, and the learner must incrementally acquire new classes without any supervision. To enable effective learning under AFCIL, we propose CrossWorld CL, a Cross Domain World Guided Continual Learning framework that incorporates external world knowledge as a stable auxiliary source. The method retrieves semantically related ImageNet classes for each downstream category, maps downstream and ImageNet features through a cross domain alignment strategy and finally introduce a novel replay strategy. This design lets the model uncover semantic structure without annotations while keeping earlier knowledge intact. Across four datasets, CrossWorld-CL surpasses CLIP baselines and existing continual and unlabeled learning methods, underscoring the benefit of world knowledge for annotation free continual learning.

</details>


### [526] [Scalable Parameter-Light Spectral Method for Clustering Short Text Embeddings with a Cohesion-Based Evaluation Metric](https://arxiv.org/abs/2511.19350)
*Nikita Neveditsin,Pawan Lingras,Vijay Mago*

Main category: cs.LG

TL;DR: 提出了一种可扩展的光谱方法，通过拉普拉斯特征谱结构自动估计聚类数量，并提出了Cohesion Ratio评估指标来量化聚类质量，无需真实标签。


<details>
  <summary>Details</summary>
Motivation: 短文本嵌入聚类是自然语言处理的基础任务，但传统方法需要预先指定聚类数量，这在实际应用中具有挑战性。

Method: 使用余弦相似度构建拉普拉斯特征谱，通过自适应采样策略估计聚类数量，并提出了基于互信息理论的Cohesion Ratio评估指标。

Result: 在六个短文本数据集和四个现代嵌入模型上的实验表明，该方法指导下的K-Means和HAC算法显著优于HDBSCAN、OPTICS和Leiden等参数较少的方法。

Conclusion: 该方法为短文本数据的无监督组织和评估提供了实用的光谱估计器和评估指标，具有实际应用价值。

Abstract: Clustering short text embeddings is a foundational task in natural language processing, yet remains challenging due to the need to specify the number of clusters in advance. We introduce a scalable spectral method that estimates the number of clusters directly from the structure of the Laplacian eigenspectrum, constructed using cosine similarities and guided by an adaptive sampling strategy. This sampling approach enables our estimator to efficiently scale to large datasets without sacrificing reliability. To support intrinsic evaluation of cluster quality without ground-truth labels, we propose the Cohesion Ratio, a simple and interpretable evaluation metric that quantifies how much intra-cluster similarity exceeds the global similarity background. It has an information-theoretic motivation inspired by mutual information, and in our experiments it correlates closely with extrinsic measures such as normalized mutual information and homogeneity. Extensive experiments on six short-text datasets and four modern embedding models show that standard algorithms like K-Means and HAC, when guided by our estimator, significantly outperform popular parameter-light methods such as HDBSCAN, OPTICS, and Leiden. These results demonstrate the practical value of our spectral estimator and Cohesion Ratio for unsupervised organization and evaluation of short text data. Implementation of our estimator of k and Cohesion Ratio, along with code for reproducing the experiments, is available at https://anonymous.4open.science/r/towards_clustering-0C2E.

</details>


### [527] [Enhancing Conformal Prediction via Class Similarity](https://arxiv.org/abs/2511.19359)
*Ariel Fargion,Lahav Dabah,Tom Tirer*

Main category: cs.LG

TL;DR: 本文提出了一种基于类相似性的共形预测增强方法，通过惩罚组外错误和利用类相似性来减小预测集大小，同时保证覆盖率。


<details>
  <summary>Details</summary>
Motivation: 在类可以按语义分组的场景中，用户不仅需要小的平均预测集，还需要包含较少语义不同组的预测集。现有CP方法主要关注平均集大小，未充分利用类相似性信息。

Method: 1. 给定类划分时，在CP评分函数中加入惩罚组外错误的项；2. 提出模型特定的变体，无需人工语义划分，利用模型输出的类相似性进一步减小预测集大小。

Result: 理论分析证明该方法在组相关指标上的优势，实验表明该方法能持续增强各种CP方法，在多个数据集和模型上均有效。

Conclusion: 基于类相似性的方法是一种广泛适用的工具，可以提升任何CP方法在任何数据集上的性能，特别是减小预测集大小。

Abstract: Conformal Prediction (CP) has emerged as a powerful statistical framework for high-stakes classification applications. Instead of predicting a single class, CP generates a prediction set, guaranteed to include the true label with a pre-specified probability. The performance of different CP methods is typically assessed by their average prediction set size. In setups where the classes can be partitioned into semantic groups, e.g., diseases that require similar treatment, users can benefit from prediction sets that are not only small on average, but also contain a small number of semantically different groups. This paper begins by addressing this problem and ultimately offers a widely applicable tool for boosting any CP method on any dataset. First, given a class partition, we propose augmenting the CP score function with a term that penalizes predictions with out-of-group errors. We theoretically analyze this strategy and prove its advantages for group-related metrics. Surprisingly, we show mathematically that, for common class partitions, it can also reduce the average set size of any CP score function. Our analysis reveals the class similarity factors behind this improvement and motivates us to propose a model-specific variant, which does not require any human semantic partition and can further reduce the prediction set size. Finally, we present an extensive empirical study, encompassing prominent CP methods, multiple models, and several datasets, which demonstrates that our class-similarity-based approach consistently enhances CP methods.

</details>


### [528] [Neural surrogates for designing gravitational wave detectors](https://arxiv.org/abs/2511.19364)
*Carlos Ruiz-Gonzalez,Sören Arlt,Sebastian Lehner,Arturs Berzins,Yehonathan Drori,Rana X Adhikari,Johannes Brandstetter,Mario Krenn*

Main category: cs.LG

TL;DR: 本文提出使用神经代理模型替代传统物理模拟器，以加速复杂实验设计中的优化过程。以引力波探测器设计为例，通过神经网络代理Finesse模拟器，实现快速设计空间探索。


<details>
  <summary>Details</summary>
Motivation: 随着实验装置复杂度增加，传统CPU模拟器的计算成本成为主要限制因素。在实验科学中，模拟器常用于自动化实验设计，但计算效率低下阻碍了优化和发现过程。

Method: 训练神经网络代理Finesse引力波物理模拟器，结合自动微分和GPU并行计算。算法循环执行：训练代理模型→逆向设计新实验→用慢速模拟器验证→进一步训练。

Result: 模型能够快速预测候选设计的质量和可行性，在几小时内找到的解决方案优于传统优化器运行五天得到的设计结果。

Conclusion: 该框架在保留精度的同时显著减少对慢速模拟器的依赖，虽然以引力波探测器为背景，但广泛适用于其他存在模拟器瓶颈的领域。

Abstract: Physics simulators are essential in science and engineering, enabling the analysis, control, and design of complex systems. In experimental sciences, they are increasingly used to automate experimental design, often via combinatorial search and optimization. However, as the setups grow more complex, the computational cost of traditional, CPU-based simulators becomes a major limitation. Here, we show how neural surrogate models can significantly reduce reliance on such slow simulators while preserving accuracy. Taking the design of interferometric gravitational wave detectors as a representative example, we train a neural network to surrogate the gravitational wave physics simulator Finesse, which was developed by the LIGO community. Despite that small changes in physical parameters can change the output by orders of magnitudes, the model rapidly predicts the quality and feasibility of candidate designs, allowing an efficient exploration of large design spaces. Our algorithm loops between training the surrogate, inverse designing new experiments, and verifying their properties with the slow simulator for further training. Assisted by auto-differentiation and GPU parallelism, our method proposes high-quality experiments much faster than direct optimization. Solutions that our algorithm finds within hours outperform designs that take five days for the optimizer to reach. Though shown in the context of gravitational wave detectors, our framework is broadly applicable to other domains where simulator bottlenecks hinder optimization and discovery.

</details>


### [529] [LLM-Driven Stationarity-Aware Expert Demonstrations for Multi-Agent Reinforcement Learning in Mobile Systems](https://arxiv.org/abs/2511.19368)
*Tianyang Duan,Zongyuan Zhang,Zheng Lin,Songxiao Guo,Xiuxian Guan,Guangyu Wu,Zihan Fang,Haotian Meng,Xia Du,Ji-Zhe Zhou,Heming Cui,Jun Luo,Yue Gao*

Main category: cs.LG

TL;DR: RELAD是一种可扩展的多智能体强化学习框架，结合了LLM驱动的专家演示和自主智能体探索，通过稳定性感知的专家演示模块和混合专家-智能体策略优化模块，解决了MARL中的非平稳性问题，提升了训练稳定性和策略收敛性。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习在资源受限的边缘设备上部署时，由于智能体策略的同步更新导致严重的非平稳性问题，造成训练不稳定和策略收敛困难，尤其是在智能体数量增加时。

Method: 提出了RELAD框架，包含两个核心模块：1）稳定性感知专家演示模块，利用理论非平稳性边界提升LLM生成的专家轨迹质量；2）混合专家-智能体策略优化模块，自适应平衡从专家生成和智能体生成轨迹中的学习。

Result: 基于OpenStreetMap的真实城市网络实验表明，RELAD相比最先进的MARL方法取得了更优越的性能。

Conclusion: RELAD框架通过整合LLM驱动的专家演示和智能体探索，有效解决了MARL中的非平稳性问题，提高了训练稳定性和策略收敛性能。

Abstract: Multi-agent reinforcement learning (MARL) has been increasingly adopted in many real-world applications. While MARL enables decentralized deployment on resource-constrained edge devices, it suffers from severe non-stationarity due to the synchronous updates of agent policies. This non stationarity results in unstable training and poor policy con vergence, especially as the number of agents increases. In this paper, we propose RELED, a scalable MARL framework that integrates large language model (LLM)-driven expert demonstrations with autonomous agent exploration. RELED incorporates a Stationarity-Aware Expert Demonstration module, which leverages theoretical non-stationarity bounds to enhance the quality of LLM-generated expert trajectories, thus providing high reward and training-stable samples for each agent. Moreover, a Hybrid Expert-Agent Policy Optimization module adaptively balances each agent's learning from both expert-generated and agent-generated trajectories, accelerating policy convergence and improving generalization. Extensive experiments with real city networks based on OpenStreetMap demonstrate that RELED achieves superior performance compared to state-of-the-art MARL methods.

</details>


### [530] [Efficiency vs. Fidelity: A Comparative Analysis of Diffusion Probabilistic Models and Flow Matching on Low-Resource Hardware](https://arxiv.org/abs/2511.19379)
*Srishti Gupta,Yashasvee Taiwade*

Main category: cs.LG

TL;DR: DDPMs计算开销大，Flow Matching在低资源硬件上效率显著优于Diffusion，几何路径更接近最优，适合实时生成任务


<details>
  <summary>Details</summary>
Motivation: DDPMs在生成图像方面达到新水平，但推理时计算开销大（需要1000次迭代），阻碍了实际部署。本研究旨在比较DDPMs和新兴的Flow Matching范式在低资源硬件上的几何和效率特性

Method: 在MNIST数据集上使用共享的Time-Conditioned U-Net骨干网络实现两种框架，进行几何分析和效率比较，建立效率边界，并进行数值敏感性分析

Result: Flow Matching学习到高度校正的传输路径（曲率≈1.02，接近最优），而Diffusion路径保持随机和曲折（曲率≈3.45）。在N=10次函数评估的效率边界上，Flow Matching保持高保真度而Diffusion崩溃。数值分析显示学习到的向量场足够线性，无需高阶ODE求解器

Conclusion: Flow Matching是实时、资源受限生成任务的优越算法选择

Abstract: Denoising Diffusion Probabilistic Models (DDPMs) have established a new state-of-the-art in generative image synthesis, yet their deployment is hindered by significant computational overhead during inference, often requiring up to 1,000 iterative steps. This study presents a rigorous comparative analysis of DDPMs against the emerging Flow Matching (Rectified Flow) paradigm, specifically isolating their geometric and efficiency properties on low-resource hardware. By implementing both frameworks on a shared Time-Conditioned U-Net backbone using the MNIST dataset, we demonstrate that Flow Matching significantly outperforms Diffusion in efficiency. Our geometric analysis reveals that Flow Matching learns a highly rectified transport path (Curvature $\mathcal{C} \approx 1.02$), which is near-optimal, whereas Diffusion trajectories remain stochastic and tortuous ($\mathcal{C} \approx 3.45$). Furthermore, we establish an ``efficiency frontier'' at $N=10$ function evaluations, where Flow Matching retains high fidelity while Diffusion collapses. Finally, we show via numerical sensitivity analysis that the learned vector field is sufficiently linear to render high-order ODE solvers (Runge-Kutta 4) unnecessary, validating the use of lightweight Euler solvers for edge deployment. \textbf{This work concludes that Flow Matching is the superior algorithmic choice for real-time, resource-constrained generative tasks.}

</details>


### [531] [Predicting partially observable dynamical systems via diffusion models with a multiscale inference scheme](https://arxiv.org/abs/2511.19390)
*Rudy Morel,Francesco Pio Ramunno,Jeff Shen,Alberto Bietti,Kyunghyun Cho,Miles Cranmer,Siavash Golkar,Olexandr Gugnin,Geraud Krawezik,Tanya Marwah,Michael McCabe,Lucas Meyer,Payel Mukhopadhyay,Ruben Ohana,Liam Parker,Helen Qu,François Rozet,K. D. Leka,François Lanusse,David Fouhey,Shirley Ho*

Main category: cs.LG

TL;DR: 该论文提出了一种用于部分可观测、长记忆动态系统的多尺度推理方案，以解决传统自回归方法在捕捉长期依赖关系方面的不足，特别适用于太阳物理等观测信息有限的场景。


<details>
  <summary>Details</summary>
Motivation: 在许多动态系统预测中，可用信息往往只是所需信息的一小部分，如太阳物理中只能观测表面而内部过程无法直接测量。标准推理方案（如自回归展开）无法有效整合过去信息，导致长期依赖关系捕捉失败。

Method: 提出了一种针对物理过程定制的多尺度推理方案，生成在时间上靠近当前时刻精细、远离时粗糙的轨迹，从而在不增加计算成本的情况下捕获长期时间依赖性。

Result: 将该方法集成到扩散模型中后，显著减少了预测分布的偏差，并提高了展开稳定性。

Conclusion: 多尺度推理方案能够有效解决部分可观测动态系统中的长期依赖问题，在太阳动力学等应用中表现出优越性能。

Abstract: Conditional diffusion models provide a natural framework for probabilistic prediction of dynamical systems and have been successfully applied to fluid dynamics and weather prediction. However, in many settings, the available information at a given time represents only a small fraction of what is needed to predict future states, either due to measurement uncertainty or because only a small fraction of the state can be observed. This is true for example in solar physics, where we can observe the Sun's surface and atmosphere, but its evolution is driven by internal processes for which we lack direct measurements. In this paper, we tackle the probabilistic prediction of partially observable, long-memory dynamical systems, with applications to solar dynamics and the evolution of active regions. We show that standard inference schemes, such as autoregressive rollouts, fail to capture long-range dependencies in the data, largely because they do not integrate past information effectively. To overcome this, we propose a multiscale inference scheme for diffusion models, tailored to physical processes. Our method generates trajectories that are temporally fine-grained near the present and coarser as we move farther away, which enables capturing long-range temporal dependencies without increasing computational cost. When integrated into a diffusion model, we show that our inference scheme significantly reduces the bias of the predicted distributions and improves rollout stability.

</details>


### [532] [Learning Robust Social Strategies with Large Language Models](https://arxiv.org/abs/2511.19405)
*Dereck Piche,Mohammed Muqeeth,Milad Aghajohari,Juan Duque,Michael Noukhovitch,Aaron Courville*

Main category: cs.LG

TL;DR: 本文研究了多智能体强化学习在社交困境中的合作问题，发现标准RL训练会导致LLM智能体发展出机会主义行为，提出了Advantage Alignment算法来促进多智能体合作。


<details>
  <summary>Details</summary>
Motivation: 随着智能体AI的普及，具有不同甚至冲突目标的智能体之间的复杂互动带来了根本性挑战。在社交困境中，智能体的个体激励可能损害集体福利，而标准RL在多智能体设置中往往收敛到自私策略。

Method: 1. 将对手学习意识算法Advantage Alignment应用于LLM微调，促进多智能体合作
2. 引入群体相对基线简化迭代游戏中的优势计算
3. 创建新的社交困境环境Trust and Split，需要自然语言沟通实现高集体福利

Result: 在各种社交困境中，使用Advantage Alignment学习的策略实现了更高的集体收益，同时保持对贪婪智能体利用的鲁棒性。

Conclusion: Advantage Alignment算法能有效解决RL在多智能体环境中收敛到不良均衡的问题，使LLM智能体在保持合作的同时抵御利用行为。

Abstract: As agentic AI becomes more widespread, agents with distinct and possibly conflicting goals will interact in complex ways. These multi-agent interactions pose a fundamental challenge, particularly in social dilemmas, where agents' individual incentives can undermine collective welfare. While reinforcement learning (RL) has been effective for aligning large language models (LLMs) in the single-agent regime, prior small-network results suggest that standard RL in multi-agent settings often converges to defecting, self-interested policies. We show the same effect in LLMs: despite cooperative priors, RL-trained LLM agents develop opportunistic behavior that can exploit even advanced closed-source models. To address this tendency of RL to converge to poor equilibria, we adapt a recent opponent-learning awareness algorithm, Advantage Alignment, to fine-tune LLMs toward multi-agent cooperation and non-exploitability. We then introduce a group-relative baseline that simplifies advantage computation in iterated games, enabling multi-agent training at LLM scale. We also contribute a novel social dilemma environment, Trust and Split, which requires natural language communication to achieve high collective welfare. Across a wide range of social dilemmas, policies learned with Advantage Alignment achieve higher collective payoffs while remaining robust against exploitation by greedy agents.

</details>


### [533] [UniGame: Turning a Unified Multimodal Model Into Its Own Adversary](https://arxiv.org/abs/2511.19413)
*Zhaolong Su,Wang Lu,Hao Chen,Sharon Li,Jindong Wang*

Main category: cs.LG

TL;DR: UniGame是一个自对抗后训练框架，通过轻量级扰动器解决统一多模态模型中理解与生成之间的结构不一致问题。


<details>
  <summary>Details</summary>
Motivation: 统一多模态模型在理解和生成任务中存在根本性不一致：理解偏向紧凑嵌入，而生成需要重构丰富的表示，这种结构权衡导致决策边界不对齐、跨模态连贯性下降以及对分布和对抗性变化的脆弱性。

Method: 在共享标记接口应用轻量级扰动器，使生成分支能够主动寻找和挑战脆弱理解，将模型自身转化为对抗者。

Result: UniGame显著提高了一致性(+4.6%)，同时在理解(+3.6%)、生成(+0.02)、分布外和对抗鲁棒性(+4.8%和+6.2%)方面也取得实质性改进。框架架构无关，仅增加不到1%的参数，且与现有后训练方法互补。

Conclusion: 对抗性自博弈是增强未来多模态基础模型连贯性、稳定性和统一能力的通用有效原则。

Abstract: Unified Multimodal Models (UMMs) have shown impressive performance in both understanding and generation with a single architecture. However, UMMs still exhibit a fundamental inconsistency: understanding favors compact embeddings, whereas generation favors reconstruction-rich representations. This structural trade-off produces misaligned decision boundaries, degraded cross-modal coherence, and heightened vulnerability under distributional and adversarial shifts. In this paper, we present UniGame, a self-adversarial post-training framework that directly targets the inconsistencies. By applying a lightweight perturber at the shared token interface, UniGame enables the generation branch to actively seek and challenge fragile understanding, turning the model itself into its own adversary. Experiments demonstrate that UniGame significantly improves the consistency (+4.6%). Moreover, it also achieves substantial improvements in understanding (+3.6%), generation (+0.02), out-of-distribution and adversarial robustness (+4.8% and +6.2% on NaturalBench and AdVQA). The framework is architecture-agnostic, introduces less than 1% additional parameters, and is complementary to existing post-training methods. These results position adversarial self-play as a general and effective principle for enhancing the coherence, stability, and unified competence of future multimodal foundation models. The official code is available at: https://github.com/AIFrontierLab/UniGame

</details>


### [534] [Flow Map Distillation Without Data](https://arxiv.org/abs/2511.19428)
*Shangyuan Tong,Nanye Ma,Saining Xie,Tommi Jaakkola*

Main category: cs.LG

TL;DR: 本文提出了一种无需外部数据集的流映射蒸馏方法，通过仅从先验分布采样来避免教师-数据不匹配问题，实现了单步采样下的优异生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有的流映射蒸馏方法依赖于外部数据集，但静态数据集可能无法完整代表教师模型的全部生成能力，存在教师-数据不匹配的风险。作者质疑这种数据依赖的必要性，探索仅从先验分布采样的无数据替代方案。

Method: 提出了一个原则性框架，学习预测教师模型的采样路径，同时主动纠正自身的累积误差以确保高保真度。该方法完全规避了对外部数据集的依赖，仅使用教师模型构造保证的先验分布。

Result: 在ImageNet 256x256上达到FID 1.45，ImageNet 512x512上达到FID 1.49，均仅需1次采样步骤，超越了所有基于数据的对比方法，建立了新的state-of-the-art。

Conclusion: 这项工作为加速生成模型建立了一个更鲁棒的范式，推动了无需数据的流映射蒸馏的广泛应用，证明了仅从先验分布采样即可实现高质量的模型蒸馏。

Abstract: State-of-the-art flow models achieve remarkable quality but require slow, iterative sampling. To accelerate this, flow maps can be distilled from pre-trained teachers, a procedure that conventionally requires sampling from an external dataset. We argue that this data-dependency introduces a fundamental risk of Teacher-Data Mismatch, as a static dataset may provide an incomplete or even misaligned representation of the teacher's full generative capabilities. This leads us to question whether this reliance on data is truly necessary for successful flow map distillation. In this work, we explore a data-free alternative that samples only from the prior distribution, a distribution the teacher is guaranteed to follow by construction, thereby circumventing the mismatch risk entirely. To demonstrate the practical viability of this philosophy, we introduce a principled framework that learns to predict the teacher's sampling path while actively correcting for its own compounding errors to ensure high fidelity. Our approach surpasses all data-based counterparts and establishes a new state-of-the-art by a significant margin. Specifically, distilling from SiT-XL/2+REPA, our method reaches an impressive FID of 1.45 on ImageNet 256x256, and 1.49 on ImageNet 512x512, both with only 1 sampling step. We hope our work establishes a more robust paradigm for accelerating generative models and motivates the broader adoption of flow map distillation without data.

</details>


### [535] [BOOD: Boundary-based Out-Of-Distribution Data Generation](https://arxiv.org/abs/2508.00350)
*Qilin Liao,Shuo Yang,Bo Zhao,Ping Luo,Hengshuang Zhao*

Main category: cs.LG

TL;DR: BOOD框架通过扩散模型在潜在空间中生成高质量的OOD特征和图像，显著提升OOD检测性能，在CIFAR-100数据集上FPR95降低29.64%，AUROC提升7.27%。


<details>
  <summary>Details</summary>
Motivation: 现有方法在潜在空间中提取ID边界外的有效特征存在挑战，难以识别类间决策边界，需要更有效的OOD数据生成策略。

Method: BOOD框架首先从ID数据集中学习文本条件化的潜在特征空间，选择最接近决策边界的ID特征，通过扰动使其跨越边界形成OOD特征，最后用扩散模型解码为像素空间图像。

Result: 在CIFAR-100数据集上，BOOD相比SOTA方法实现FPR95从40.31%降至10.67%（降低29.64%），AUROC从90.15%提升至97.42%（提升7.27%）。

Conclusion: BOOD提供了一种更训练高效的OOD特征合成策略，能够在ID和OOD数据之间建立更清晰的区分，显著优于现有方法。

Abstract: Harnessing the power of diffusion models to synthesize auxiliary training data based on latent space features has proven effective in enhancing out-of-distribution (OOD) detection performance. However, extracting effective features outside the in-distribution (ID) boundary in latent space remains challenging due to the difficulty of identifying decision boundaries between classes. This paper proposes a novel framework called Boundary-based Out-Of-Distribution data generation (BOOD), which synthesizes high-quality OOD features and generates human-compatible outlier images using diffusion models. BOOD first learns a text-conditioned latent feature space from the ID dataset, selects ID features closest to the decision boundary, and perturbs them to cross the decision boundary to form OOD features. These synthetic OOD features are then decoded into images in pixel space by a diffusion model. Compared to previous works, BOOD provides a more training efficient strategy for synthesizing informative OOD features, facilitating clearer distinctions between ID and OOD data. Extensive experimental results on common benchmarks demonstrate that BOOD surpasses the state-of-the-art method significantly, achieving a 29.64% decrease in average FPR95 (40.31% vs. 10.67%) and a 7.27% improvement in average AUROC (90.15% vs. 97.42%) on the CIFAR-100 dataset.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [536] [AUTOSAR AP and ROS 2 Collaboration Framework](https://arxiv.org/abs/2511.17540)
*Ryudai Iwakami,Bo Peng,Hiroyuki Hanyu,Tasuku Ishigooka,Takuya Azumi*

Main category: cs.RO

TL;DR: 本文提出了一种使AUTOSAR AP和ROS 2能够通过DDS进行通信的协作框架，解决了研究平台与开发平台之间的鸿沟问题。


<details>
  <summary>Details</summary>
Motivation: AUTOSAR AP在自动驾驶开发中广泛使用但存在许可限制，而ROS 2在研究中占主导地位，导致研究平台与开发平台不匹配，阻碍了快速商业化。

Method: 设计了一个桥接转换器，通过DDS协议实现AUTOSAR AP（使用SOME/IP）与ROS 2之间的通信，并自动生成配置文件。

Result: 通过实证分析验证了桥接转换器的功能和性能，证明其在转换时间和与ROS 2工具集成方面具有高效性。

Conclusion: 提出的协作框架有效解决了AUTOSAR AP和ROS 2平台间的协议差异问题，提高了平台的可用性和集成效率。

Abstract: The field of autonomous vehicle research is advancing rapidly, necessitating platforms that meet real-time performance, safety, and security requirements for practical deployment. AUTOSAR Adaptive Platform (AUTOSAR AP) is widely adopted in development to meet these criteria; however, licensing constraints and tool implementation challenges limit its use in research. Conversely, Robot Operating System 2 (ROS 2) is predominantly used in research within the autonomous driving domain, leading to a disparity between research and development platforms that hinders swift commercialization. This paper proposes a collaboration framework that enables AUTOSAR AP and ROS 2 to communicate with each other using a Data Distribution Service for Real-Time Systems (DDS). In contrast, AUTOSAR AP uses Scalable service-Oriented Middleware over IP (SOME/IP) for communication. The proposed framework bridges these protocol differences, ensuring seamless interaction between the two platforms. We validate the functionality and performance of our bridge converter through empirical analysis, demonstrating its efficiency in conversion time and ease of integration with ROS 2 tools. Furthermore, the availability of the proposed collaboration framework is improved by automatically generating a configuration file for the proposed bridge converter.

</details>


### [537] [Implicit Neural Field-Based Process Planning for Multi-Axis Manufacturing: Direct Control over Collision Avoidance and Toolpath Geometry](https://arxiv.org/abs/2511.17578)
*Neelotpal Dutta,Tianyu Zhang,Tao Liu,Yongxue Chen,Charlie C. L. Wang*

Main category: cs.RO

TL;DR: 提出了一种基于隐式神经场的多轴加工工艺规划框架，将层生成和刀具路径设计集成到单个可微分流程中，实现直接碰撞避免和联合优化。


<details>
  <summary>Details</summary>
Motivation: 现有基于曲面的多轴制造工艺规划方法只能间接处理碰撞问题，并且在后处理步骤中生成刀具路径，导致在优化过程中无法控制刀具路径几何形状。

Method: 使用正弦激活的神经网络将层和刀具路径表示为隐式场，构建可微分管道，支持任意空间点的场值和导数直接评估，实现显式碰撞避免和层与刀具路径的联合优化。

Result: 该方法在增材和减材制造示例中得到验证，展示了其通用性和有效性，同时研究了网络超参数和目标定义对奇异行为和拓扑转换的影响。

Conclusion: 该框架克服了传统方法的局限性，提供了正则化和稳定性控制的内置机制，为多轴制造工艺规划提供了更优的解决方案。

Abstract: Existing curved-layer-based process planning methods for multi-axis manufacturing address collisions only indirectly and generate toolpaths in a post-processing step, leaving toolpath geometry uncontrolled during optimization. We present an implicit neural field-based framework for multi-axis process planning that overcomes these limitations by embedding both layer generation and toolpath design within a single differentiable pipeline. Using sinusoidally activated neural networks to represent layers and toolpaths as implicit fields, our method enables direct evaluation of field values and derivatives at any spatial point, thereby allowing explicit collision avoidance and joint optimization of manufacturing layers and toolpaths. We further investigate how network hyperparameters and objective definitions influence singularity behavior and topology transitions, offering built-in mechanisms for regularization and stability control. The proposed approach is demonstrated on examples in both additive and subtractive manufacturing, validating its generality and effectiveness.

</details>


### [538] [Translating Cultural Choreography from Humanoid Forms to Robotic Arm](https://arxiv.org/abs/2511.17603)
*Chelsea-Xi Chen,Zhe Zhang,Aven-Le Zhou*

Main category: cs.RO

TL;DR: 本文提出ROPERA系统，通过符号化姿态转移和关节空间兼容表示法，在六自由度机械臂上实现文化语义保真度的昆曲舞蹈编排，并验证其跨形态移植性。


<details>
  <summary>Details</summary>
Motivation: 当前机械臂编舞主要复制轨迹而忽略文化语义，需要开发能够保留文化语义保真度且可移植的舞蹈编排方法。

Method: 采用三阶段流程：编码文化编码姿态、组合符号序列、解码为伺服命令。以昆曲《牡丹亭》为评估材料，包括基于语料库的姿态选择、符号化记谱、直接关节角度执行，以及包含光绘和服装色彩的可视化层。

Result: 实验结果显示可重复执行且具有预期时序，专家和观众报告文化可读性良好。

Conclusion: 该方法为非人类中心的文化保护和可移植创作工作流程提供了方向，未来将设计舞蹈感知的过渡配置文件，扩展符号系统以包含触觉、音乐和空间线索，并测试跨平台移植性。

Abstract: Robotic arm choreography often reproduces trajectories while missing cultural semantics. This study examines whether symbolic posture transfer with joint space compatible notation can preserve semantic fidelity on a six-degree-of-freedom arm and remain portable across morphologies. We implement ROPERA, a three-stage pipeline for encoding culturally codified postures, composing symbolic sequences, and decoding to servo commands. A scene from Kunqu opera, \textit{The Peony Pavilion}, serves as the material for evaluation. The procedure includes corpus-based posture selection, symbolic scoring, direct joint angle execution, and a visual layer with light painting and costume-informed colors. Results indicate reproducible execution with intended timing and cultural legibility reported by experts and audiences. The study points to non-anthropocentric cultural preservation and portable authoring workflows. Future work will design dance-informed transition profiles, extend the notation to locomotion with haptic, musical, and spatial cues, and test portability across platforms.

</details>


### [539] [Robot joint characterisation and control using a magneto-optical rotary encoder](https://arxiv.org/abs/2511.17608)
*Yunlong Guo,John Canning,Zenon Chaczko,Gang-Ding Peng*

Main category: cs.RO

TL;DR: 提出一种紧凑型磁光旋转编码器，用于机器人旋转关节的测量，通过磁场诱导光学衰减实现360°连续旋转跟踪


<details>
  <summary>Details</summary>
Motivation: 为机器人旋转关节提供低成本、可靠的编码器替代方案，同时保持竞争力性能

Method: 采用双通配置，利用旋转非均匀磁体在光学环行器反射模式下产生磁场诱导光学衰减

Result: 编码器可实现135°/s至370°/s的旋转速率跟踪，角分辨率为0.3°

Conclusion: 该系统为传统机器人旋转编码器提供了一种具有竞争力的低成本可靠替代方案

Abstract: A robust and compact magneto-optical rotary encoder for the characterisation of robotic rotary joints is demonstrated. The system employs magnetic field-induced optical attenuation in a double-pass configuration using rotating nonuniform magnets around an optical circulator operating in reflection. The encoder tracks continuous 360° rotation with rotation sweep rates from ν = 135 °/s to ν = 370 °/s, and an angular resolution of Δθ = 0.3°. This offers a low-cost and reliable alternative to conventional robot rotation encoders while maintaining competitive performance.

</details>


### [540] [Vision-Guided Optic Flow Navigation for Small Lunar Missions](https://arxiv.org/abs/2511.17720)
*Sean Cowan,Pietro Fanti,Leon B. S. Williams,Chit Hong Yam,Kaneyasu Asakuma,Yuichiro Nada,Dario Izzo*

Main category: cs.RO

TL;DR: 提出了一种基于光流和测距仪深度估计的运动场反演框架，用于月球着陆过程中的自主导航，特别适用于资源受限的小型月球着陆器。


<details>
  <summary>Details</summary>
Motivation: 解决私人月球任务在质量、功耗和计算资源严格限制下的鲁棒自主导航挑战，为小型月球着陆器提供轻量级CPU解决方案。

Method: 扩展经典光流公式，结合针对月球/行星接近、下降和着陆几何形状定制的深度建模策略（平面和球形地形近似），通过激光测距仪参数化，使用金字塔Lucas-Kanade算法提取稀疏光流特征，通过最小二乘框架进行运动场反演。

Result: 在月球南极复杂地形上使用合成图像验证，速度估计准确，复杂地形误差低于10%，典型地形误差约1%，性能适合实时应用。

Conclusion: 该框架有望为小型月球任务实现鲁棒、轻量级的机载导航。

Abstract: Private lunar missions are faced with the challenge of robust autonomous navigation while operating under stringent constraints on mass, power, and computational resources. This work proposes a motion-field inversion framework that uses optical flow and rangefinder-based depth estimation as a lightweight CPU-based solution for egomotion estimation during lunar descent. We extend classical optical flow formulations by integrating them with depth modeling strategies tailored to the geometry for lunar/planetary approach, descent, and landing, specifically, planar and spherical terrain approximations parameterized by a laser rangefinder. Motion field inversion is performed through a least-squares framework, using sparse optical flow features extracted via the pyramidal Lucas-Kanade algorithm. We verify our approach using synthetically generated lunar images over the challenging terrain of the lunar south pole, using CPU budgets compatible with small lunar landers. The results demonstrate accurate velocity estimation from approach to landing, with sub-10% error for complex terrain and on the order of 1% for more typical terrain, as well as performances suitable for real-time applications. This framework shows promise for enabling robust, lightweight on-board navigation for small lunar missions.

</details>


### [541] [LEARN: Learning End-to-End Aerial Resource-Constrained Multi-Robot Navigation](https://arxiv.org/abs/2511.17765)
*Darren Chiu,Zhehui Huang,Ruohai Ge,Gaurav S. Sukhatme*

Main category: cs.RO

TL;DR: LEARN是一个轻量级的两阶段安全引导强化学习框架，用于多无人机在复杂环境中的导航，结合低分辨率ToF传感器和紧凑的注意力机制RL策略，在资源受限的纳米无人机平台上实现高效导航。


<details>
  <summary>Details</summary>
Motivation: 纳米无人机团队具有高敏捷性，但受限于机载传感、通信和计算能力，现有基于高分辨率视觉或计算密集型规划器的方法不适用于这些平台。

Method: 采用两阶段安全引导强化学习框架，结合低分辨率飞行时间传感器和简单运动规划器，使用紧凑的基于注意力的强化学习策略。

Result: 在仿真中比两种最先进规划器性能提升10%，资源消耗显著减少；在6架Crazyflie四旋翼上实现完全机载飞行，在室内外环境中达到2.0 m/s速度，穿越0.2 m间隙。

Conclusion: LEARN框架证明了在资源受限的纳米无人机平台上实现高效多机导航的可行性，为轻量级无人机导航提供了实用解决方案。

Abstract: Nano-UAV teams offer great agility yet face severe navigation challenges due to constrained onboard sensing, communication, and computation. Existing approaches rely on high-resolution vision or compute-intensive planners, rendering them infeasible for these platforms. We introduce LEARN, a lightweight, two-stage safety-guided reinforcement learning (RL) framework for multi-UAV navigation in cluttered spaces. Our system combines low-resolution Time-of-Flight (ToF) sensors and a simple motion planner with a compact, attention-based RL policy. In simulation, LEARN outperforms two state-of-the-art planners by $10\%$ while using substantially fewer resources. We demonstrate LEARN's viability on six Crazyflie quadrotors, achieving fully onboard flight in diverse indoor and outdoor environments at speeds up to $2.0 m/s$ and traversing $0.2 m$ gaps.

</details>


### [542] [Learning Diffusion Policies for Robotic Manipulation of Timber Joinery under Fabrication Uncertainty](https://arxiv.org/abs/2511.17774)
*Salma Mozaffari,Daniel Ruan,William van den Bogert,Nima Fazeli,Sigrid Adriaenssens,Arash Adel*

Main category: cs.RO

TL;DR: 本文探讨了扩散策略学习在建筑规模接触敏感机器人装配中的性能和鲁棒性，以木工榫卯接头为案例研究。最佳策略在10毫米扰动下达到75%的平均成功率，未扰动情况下成功率100%。


<details>
  <summary>Details</summary>
Motivation: 建筑不确定性（如制造误差和材料缺陷）对接触密集型机器人操作构成重大挑战，阻碍精确和稳健的装配。

Method: 采用两阶段研究：首先评估策略性能和适用性，其次评估处理制造不确定性的鲁棒性，通过随机扰动榫眼位置来模拟不确定性。

Result: 最佳策略在未扰动情况下达到100%成功率，在10毫米扰动下平均成功率为75%。

Conclusion: 研究证明了感觉运动扩散策略在建筑和制造中广泛复杂接触密集型装配任务中的泛化潜力，推动了不确定性下的机器人建筑发展，有助于更安全、更高效的建筑实践。

Abstract: Construction uncertainties such as fabrication inaccuracies and material imperfections pose a significant challenge to contact-rich robotic manipulation by hindering precise and robust assembly. In this paper, we explore the performance and robustness of diffusion policy learning as a promising solution for contact-sensitive robotic assembly at construction scale, using timber mortise and tenon joints as a case study. A two-phase study is conducted: first, to evaluate policy performance and applicability; second, to assess robustness in handling fabrication uncertainties simulated as randomized perturbations to the mortise position. The best-performing policy achieved a total average success rate of 75% with perturbations up to 10 mm, including 100% success in unperturbed cases. The results demonstrate the potential of sensory-motor diffusion policies to generalize to a wide range of complex, contact-rich assembly tasks across construction and manufacturing, advancing robotic construction under uncertainty and contributing to safer, more efficient building practices.

</details>


### [543] [See, Plan, Cut: MPC-Based Autonomous Volumetric Robotic Laser Surgery with OCT Guidance](https://arxiv.org/abs/2511.17777)
*Ravi Prakash,Vincent Y. Wang,Arpit Mishra,Devi Yuliarti,Pei Zhong,Ryan P. McNabb,Patrick J. Codd,Leila J. Bridgeman*

Main category: cs.RO

TL;DR: RATS是一个智能光机械机器人平台，集成OCT引导和手术激光，用于自主软组织切除手术


<details>
  <summary>Details</summary>
Motivation: 现有机器人激光系统缺乏体积规划和术中反馈，无法实现高精度组织切除

Method: 集成RGB-D成像、OCT和手术激光，采用多阶段校准管道和基于采样的模型预测控制框架

Result: OCT-激光校准精度0.161±0.031mm，切除轨迹RMSE 0.842mm，比前馈执行提高64.8%

Conclusion: RATS平台能够检测皮下结构并修改规划目标，展示了临床可行性

Abstract: Robotic laser systems offer the potential for sub-millimeter, non-contact, high-precision tissue resection, yet existing platforms lack volumetric planning and intraoperative feedback. We present RATS (Robot-Assisted Tissue Surgery), an intelligent opto-mechanical, optical coherence tomography (OCT)-guided robotic platform designed for autonomous volumetric soft tissue resection in surgical applications. RATS integrates macro-scale RGB-D imaging, micro-scale OCT, and a fiber-coupled surgical laser, calibrated through a novel multistage alignment pipeline that achieves OCT-to-laser calibration accuracy of 0.161+-0.031mm on tissue phantoms and ex vivo porcine tissue. A super-Gaussian laser-tissue interaction (LTI) model characterizes ablation crater morphology with an average RMSE of 0.231+-0.121mm, outperforming Gaussian baselines. A sampling-based model predictive control (MPC) framework operates directly on OCT voxel data to generate constraint-aware resection trajectories with closed-loop feedback, achieving 0.842mm RMSE and improving intersection-over-union agreement by 64.8% compared to feedforward execution. With OCT, RATS detects subsurface structures and modifies the planner's objective to preserve them, demonstrating clinical feasibility.

</details>


### [544] [SAFE-SMART: Safety Analysis and Formal Evaluation using STL Metrics for Autonomous RoboTs](https://arxiv.org/abs/2511.17781)
*Kristy Sakano,Jianyu An,Dinesh Manocha,Huan Xu*

Main category: cs.RO

TL;DR: 提出了一种基于监管驱动的后验安全评估方法，用于学习型黑盒自主移动机器人，通过Signal Temporal Logic规范将人类安全需求转化为可验证指标，实现迭代式安全改进。


<details>
  <summary>Details</summary>
Motivation: 为了解决学习型黑盒自主机器人在实际部署中持续符合不断演变的人类安全规则的需求，需要一个系统化的安全评估和改进框架。

Method: 采用迭代工作流程：将人类安全需求转化为STL规范，对外部验证黑盒模型的轨迹合规性，计算TRV和LRV安全指标，基于指标进行针对性重新训练。

Result: 在虚拟驾驶场景中，符合速度限制的轨迹增加177%，减少越野驾驶的轨迹增加1138%，按时到达目标的轨迹增加16%；在自主导航场景中，避免急转弯的轨迹增加300%，按时到达目标的轨迹增加200%，减少障碍物附近时间的轨迹增加49%。

Conclusion: 该方法在虚拟和真实世界环境中均能显著提升机器人的安全性能，验证了监管驱动安全评估框架的有效性和实用性。

Abstract: We present a novel, regulator-driven approach for post hoc safety evaluation of learning-based, black-box autonomous mobile robots, ensuring ongoing compliance with evolving, human-defined safety rules. In our iterative workflow, human safety requirements are translated by regulators into Signal Temporal Logic (STL) specifications. Rollout traces from the black-box model are externally verified for compliance, yielding quantitative safety metrics, Total Robustness Value (TRV) and Largest Robustness Value (LRV), which measure average and worst-case specification adherence. These metrics inform targeted retraining and iterative improvement by model designers. We apply our method across two different applications: a virtual driving scenario and an autonomous mobile robot navigating a complex environment, and observe statistically significant improvements across both scenarios. In the virtual driving scenario, we see a 177% increase in traces adhering to the simulation speed limit, a 1138% increase in traces minimizing off-road driving, and a 16% increase in traces successfully reaching the goal within the time limit. In the autonomous navigation scenario, there is a 300% increase in traces avoiding sharp turns, a 200% increase in traces reaching the goal within the time limit, and a 49% increase in traces minimizing time spent near obstacles. Finally, we validate our approach on a TurtleBot3 robot in the real world, and demonstrate improved obstacle navigation with safety buffers.

</details>


### [545] [SM$^2$ITH: Safe Mobile Manipulation with Interactive Human Prediction via Task-Hierarchical Bilevel Model Predictive Control](https://arxiv.org/abs/2511.17798)
*Francesco D'Orazio,Sepehr Samavi,Xintong Du,Siqi Zhou,Giuseppe Oriolo,Angela P. Schoellig*

Main category: cs.RO

TL;DR: SM²ITH框架将分层任务模型预测控制与交互式人体运动预测相结合，通过双层优化实现移动机器人在动态人机环境中的安全协调操作。


<details>
  <summary>Details</summary>
Motivation: 现有优化方法主要应用于静态或结构化场景，缺乏对动态人机环境中人类反应行为的预测能力，需要开发能够捕捉人机交互的预测模型。

Method: 提出任务分层双层模型预测控制框架，结合分层任务模型预测控制和交互式人体运动预测，通过双层优化同时考虑机器人和人类动力学。

Result: 在两个移动操作器上验证了框架的有效性，在配送任务、顺序拾放任务和对抗性人类行为交互中，交互式预测方法在安全性和效率上优于基于加权目标或开环人类模型的基线方法。

Conclusion: 交互式预测能够实现安全高效的协调操作，为动态人机环境中的移动操作提供了有效的解决方案。

Abstract: Mobile manipulators are designed to perform complex sequences of navigation and manipulation tasks in human-centered environments. While recent optimization-based methods such as Hierarchical Task Model Predictive Control (HTMPC) enable efficient multitask execution with strict task priorities, they have so far been applied mainly to static or structured scenarios. Extending these approaches to dynamic human-centered environments requires predictive models that capture how humans react to the actions of the robot. This work introduces Safe Mobile Manipulation with Interactive Human Prediction via Task-Hierarchical Bilevel Model Predictive Control (SM$^2$ITH), a unified framework that combines HTMPC with interactive human motion prediction through bilevel optimization that jointly accounts for robot and human dynamics. The framework is validated on two different mobile manipulators, the Stretch 3 and the Ridgeback-UR10, across three experimental settings: (i) delivery tasks with different navigation and manipulation priorities, (ii) sequential pick-and-place tasks with different human motion prediction models, and (iii) interactions involving adversarial human behavior. Our results highlight how interactive prediction enables safe and efficient coordination, outperforming baselines that rely on weighted objectives or open-loop human models.

</details>


### [546] [MobileVLA-R1: Reinforcing Vision-Language-Action for Mobile Robots](https://arxiv.org/abs/2511.17889)
*Ting Huang,Dongjian Li,Rui Yang,Zeyu Zhang,Zida Yang,Hao Tang*

Main category: cs.RO

TL;DR: MobileVLA-R1是一个统一的视觉-语言-动作框架，通过构建多粒度思维链数据集和两阶段训练范式，解决了四足机器人自然语言指令到连续控制的映射问题，在复杂环境中展现出稳健性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在高级语义推理和低级驱动之间难以建立有效连接，导致现实世界中的不稳定映射和弱泛化能力。

Method: 构建MobileVLA-CoT大规模多粒度思维链数据集，采用监督式CoT对齐和GRPO强化学习的两阶段训练范式。

Result: 在VLN和VLA任务上相比强基线提升约5%，在真实四足机器人部署中验证了复杂环境下的稳健性能。

Conclusion: MobileVLA-R1框架通过显式推理和连续控制的统一，有效提升了四足机器人自然语言指令的执行能力。

Abstract: Grounding natural-language instructions into continuous control for quadruped robots remains a fundamental challenge in vision language action. Existing methods struggle to bridge high-level semantic reasoning and low-level actuation, leading to unstable grounding and weak generalization in the real world. To address these issues, we present MobileVLA-R1, a unified vision-language-action framework that enables explicit reasoning and continuous control for quadruped robots. We construct MobileVLA-CoT, a large-scale dataset of multi-granularity chain-of-thought (CoT) for embodied trajectories, providing structured reasoning supervision for alignment. Built upon this foundation, we introduce a two-stage training paradigm that combines supervised CoT alignment with GRPO reinforcement learning to enhance reasoning consistency, control stability, and long-horizon execution. Extensive evaluations on VLN and VLA tasks demonstrate superior performance over strong baselines, with approximately a 5% improvement. Real-world deployment on a quadruped robot validates robust performance in complex environments. Code: https://github.com/AIGeeksGroup/MobileVLA-R1. Website: https://aigeeksgroup.github.io/MobileVLA-R1.

</details>


### [547] [L1 Sample Flow for Efficient Visuomotor Learning](https://arxiv.org/abs/2511.17898)
*Weixi Song,Zhetao Chen,Tao Xu,Xianchao Zeng,Xinyu Zhou,Lixin Yang,Donglin Wang,Cewu Lu,Yong-Lu Li*

Main category: cs.RO

TL;DR: 本文提出L1 Flow方法，通过将v-prediction flow matching重新表述为sample-prediction，实现两步采样：先用单步ODE生成次优动作序列，再用单步预测重构精确动作序列。该方法在保持流匹配多模态优势的同时，将神经函数评估减少到仅两次，提高了训练和推理效率。


<details>
  <summary>Details</summary>
Motivation: 结合去噪模型（如扩散和流匹配）的多模态分布拟合能力与L1回归目标的高效性，避免模式坍塌同时提升训练和推理速度。

Method: 将原始v-prediction流匹配重新表述为sample-prediction的L1训练目标，提出两步采样策略：单步ODE生成次优动作序列，单步预测重构精确动作。

Result: 在MimicGen的8个任务、RoboMimic和PushT Bench的5个任务以及真实世界场景中评估，结果显示在训练效率、推理速度和整体性能方面具有优势。

Conclusion: L1 Flow方法成功结合了流匹配的多模态优势和L1回归的效率，显著减少了计算开销，在多个基准测试中表现出色。

Abstract: Denoising-based models, such as diffusion and flow matching, have been a critical component of robotic manipulation for their strong distribution-fitting and scaling capacity. Concurrently, several works have demonstrated that simple learning objectives, such as L1 regression, can achieve performance comparable to denoising-based methods on certain tasks, while offering faster convergence and inference. In this paper, we focus on how to combine the advantages of these two paradigms: retaining the ability of denoising models to capture multi-modal distributions and avoid mode collapse while achieving the efficiency of the L1 regression objective. To achieve this vision, we reformulate the original v-prediction flow matching and transform it into sample-prediction with the L1 training objective. We empirically show that the multi-modality can be expressed via a single ODE step. Thus, we propose \textbf{L1 Flow}, a two-step sampling schedule that generates a suboptimal action sequence via a single integration step and then reconstructs the precise action sequence through a single prediction. The proposed method largely retains the advantages of flow matching while reducing the iterative neural function evaluations to merely two and mitigating the potential performance degradation associated with direct sample regression. We evaluate our method with varying baselines and benchmarks, including 8 tasks in MimicGen, 5 tasks in RoboMimic \& PushT Bench, and one task in the real-world scenario. The results show the advantages of the proposed method with regard to training efficiency, inference speed, and overall performance. \href{https://song-wx.github.io/l1flow.github.io/}{Project Website.}

</details>


### [548] [Switch-JustDance: Benchmarking Whole Body Motion Tracking Policies Using a Commercial Console Game](https://arxiv.org/abs/2511.17925)
*Jeonghwan Kim,Wontaek Kim,Yidan Lu,Jin Cheng,Fatemeh Zargarbashi,Zicheng Zeng,Zekun Qi,Zhiyang Dou,Nitish Sontakke,Donghoon Baek,Sehoon Ha,Tianyu Li*

Main category: cs.RO

TL;DR: Switch-JustDance是一个低成本、可复现的基准测试管道，利用任天堂Switch上的Just Dance游戏来评估机器人全身控制性能。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏在真实环境中评估人形和腿式机器人敏捷协调运动能力的标准化基准，现有评估方法依赖预收集的人类运动数据或模拟实验，限制了可复现性并阻碍了公平的人机比较。

Method: 通过流媒体、运动重建和运动重定向模块将Just Dance游戏中的编舞转换为机器人可执行动作，并利用游戏内置评分系统评估控制器性能。首先验证Just Dance的评估属性（可靠性、有效性、敏感性等），然后在硬件上测试三种最先进的人形机器人全身控制器。

Result: 结果显示Just Dance平台提供了一致且可解释的性能度量，适合作为具身AI的基准测试工具。三种控制器的基准测试揭示了它们各自的优势和局限性。

Conclusion: Switch-JustDance为机器人全身控制提供了一个有效的基准测试框架，能够实现公平的人机比较和可复现的性能评估。

Abstract: Recent advances in whole-body robot control have enabled humanoid and legged robots to perform increasingly agile and coordinated motions. However, standardized benchmarks for evaluating these capabilities in real-world settings, and in direct comparison to humans, remain scarce. Existing evaluations often rely on pre-collected human motion datasets or simulation-based experiments, which limit reproducibility, overlook hardware factors, and hinder fair human-robot comparisons. We present Switch-JustDance, a low-cost and reproducible benchmarking pipeline that leverages motion-sensing console games, Just Dance on the Nintendo Switch, to evaluate robot whole-body control. Using Just Dance on the Nintendo Switch as a representative platform, Switch-JustDance converts in-game choreography into robot-executable motions through streaming, motion reconstruction, and motion retargeting modules and enables users to evaluate controller performance through the game's built-in scoring system. We first validate the evaluation properties of Just Dance, analyzing its reliability, validity, sensitivity, and potential sources of bias. Our results show that the platform provides consistent and interpretable performance measures, making it a suitable tool for benchmarking embodied AI. Building on this foundation, we benchmark three state-of-the-art humanoid whole-body controllers on hardware and provide insights into their relative strengths and limitations.

</details>


### [549] [RoboArmGS: High-Quality Robotic Arm Splatting via Bézier Curve Refinement](https://arxiv.org/abs/2511.17961)
*Hao Wang,Xiaobao Wei,Ying Li,Qingpo Wuwu,Dongli Wu,Jiajun Cao,Ming Lu,Wenzhao Zheng,Shanghang Zhang*

Main category: cs.RO

TL;DR: RoboArmGS提出了一种混合表示方法，通过可学习的贝塞尔曲线优化URDF刚性运动，提高机器人手臂真实运动建模精度和渲染质量。


<details>
  <summary>Details</summary>
Motivation: 当前方法将静态3D高斯简单绑定到URDF链接上，被动跟随URDF刚性运动，但真实世界手臂运动存在噪声，URDF刚性运动无法准确建模，导致3D高斯渲染出现严重伪影。

Method: 提出RoboArmGS混合表示，使用可学习的贝塞尔曲线运动优化器校正每个关节的残差，解决真实运动与URDF刚性运动之间的不匹配问题。

Result: 在RoboArm4D数据集上评估，RoboArmGS在真实运动建模和渲染质量方面达到最先进性能。

Conclusion: 该方法能够学习更准确的真实世界运动，同时实现手臂各部分3D高斯的连贯绑定，代码和数据集将发布。

Abstract: Building high-quality digital assets of robotic arms is crucial yet challenging for the Real2Sim2Real pipeline. Current approaches naively bind static 3D Gaussians according to URDF links, forcing them to follow an URDF-rigged motion passively. However, real-world arm motion is noisy, and the idealized URDF-rigged motion cannot accurately model it, leading to severe rendering artifacts in 3D Gaussians. To address these challenges, we propose RoboArmGS, a novel hybrid representation that refines the URDF-rigged motion with learnable Bézier curves, enabling more accurate real-world motion modeling. To be more specific, we present a learnable Bézier Curve motion refiner that corrects per-joint residuals to address mismatches between real-world motion and URDF-rigged motion. RoboArmGS enables the learning of more accurate real-world motion while achieving a coherent binding of 3D Gaussians across arm parts. To support future research, we contribute a carefully collected dataset named RoboArm4D, which comprises several widely used robotic arms for evaluating the quality of building high-quality digital assets. We evaluate our approach on RoboArm4D, and RoboArmGS achieves state-of-the-art performance in real-world motion modeling and rendering quality. The code and dataset will be released.

</details>


### [550] [Unobservable Subspace Evolution and Alignment for Consistent Visual-Inertial Navigation](https://arxiv.org/abs/2511.17992)
*Chungeng Tian,Fenghua He,Ning Hao*

Main category: cs.RO

TL;DR: 本文提出了Unobservable Subspace Evolution (USE)分析框架和Unobservable Subspace Alignment (USA)解决方案，系统性地解决了VINS中的不一致性问题。


<details>
  <summary>Details</summary>
Motivation: VINS中的不一致性是一个长期存在的根本挑战。现有研究主要将不一致性归因于可观测性失配，但这些分析基于简化的理论公式，未能涵盖MSCKF校正和延迟初始化等关键的非标准估计步骤。缺乏对不一致性如何动态产生的全面理解阻碍了精确高效解决方案的开发。

Method: 提出了USE分析框架，通过显式跟踪不可观测子空间评估点的变化，系统地表征不可观测子空间在整个估计流程中的演化。基于此分析，提出了USA解决方案范式，通过选择性地干预那些引起不对齐的估计步骤来消除不一致性。设计了两种USA方法：基于变换的方法和基于重新评估的方法。

Result: 广泛的仿真和真实世界实验验证了所提方法的有效性。

Conclusion: USE框架为理解VINS不一致性提供了新视角，USA方法提供了一种简单而有效的解决方案，能够在保持估计精度的同时实现计算轻量化的不一致性消除。

Abstract: The inconsistency issue in the Visual-Inertial Navigation System (VINS) is a long-standing and fundamental challenge. While existing studies primarily attribute the inconsistency to observability mismatch, these analyses are often based on simplified theoretical formulations that consider only prediction and SLAM correction. Such formulations fail to cover the non-standard estimation steps, such as MSCKF correction and delayed initialization, which are critical for practical VINS estimators. Furthermore, the lack of a comprehensive understanding of how inconsistency dynamically emerges across estimation steps has hindered the development of precise and efficient solutions. As a result, current approaches often face a trade-off between estimator accuracy, consistency, and implementation complexity. To address these limitations, this paper proposes a novel analysis framework termed Unobservable Subspace Evolution (USE), which systematically characterizes how the unobservable subspace evolves throughout the entire estimation pipeline by explicitly tracking changes in its evaluation points. This perspective sheds new light on how individual estimation steps contribute to inconsistency. Our analysis reveals that observability misalignment induced by certain steps is the antecedent of observability mismatch. Guided by this insight, we propose a simple yet effective solution paradigm, Unobservable Subspace Alignment (USA), which eliminates inconsistency by selectively intervening only in those estimation steps that induce misalignment. We design two USA methods: transformation-based and re-evaluation-based, both offering accurate and computationally lightweight solutions. Extensive simulations and real-world experiments validate the effectiveness of the proposed methods.

</details>


### [551] [Continually Evolving Skill Knowledge in Vision Language Action Model](https://arxiv.org/abs/2511.18085)
*Yuxuan Wu,Guangming Wang,Zhiheng Yang,Maoqing Yao,Brian Sheil,Hesheng Wang*

Main category: cs.RO

TL;DR: Stellar VLA是一个知识驱动的持续学习框架，通过任务潜在表示和知识空间的联合学习实现自我监督的知识进化，在机器人操作任务中相比基线方法有超过50%的平均成功率提升。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型严重依赖任务特定微调，缺乏持续学习能力，而传统持续学习方法扩展到VLA模型资源消耗大。

Method: 提出T-Stellar（任务中心知识空间）和TS-Stellar（层次化任务-技能结构）两个变体，通过知识引导的专家路由实现任务专业化，无需额外网络参数。

Result: 在LIBERO基准测试和真实世界任务中，相比基线方法平均成功率提升超过50%，TS-Stellar在复杂动作推理方面表现更佳。

Conclusion: Stellar VLA框架有效解决了VLA模型的持续学习问题，实现了知识保留和发现，降低了训练开销和标注需求。

Abstract: Developing general robot intelligence in open environments requires continual skill learning. Recent Vision-Language-Action (VLA) models leverage massive pretraining data to support diverse manipulation tasks, but they still depend heavily on task-specific fine-tuning, revealing a lack of continual learning capability. Existing continual learning methods are also resource-intensive to scale to VLA models. We propose Stellar VLA, a knowledge-driven continual learning framework with two variants: T-Stellar, modeling task-centric knowledge space, and TS-Stellar, capturing hierarchical task-skill structure. Stellar VLA enables self-supervised knowledge evolution through joint learning of task latent representation and the knowledge space, reducing annotation needs. Knowledge-guided expert routing provide task specialization without extra network parameters, lowering training overhead.Experiments on the LIBERO benchmark and real-world tasks show over 50 percentage average improvement in final success rates relative to baselines. TS-Stellar further excels in complex action inference, and in-depth analyses verify effective knowledge retention and discovery. Our code will be released soon.

</details>


### [552] [Anti-Jamming based on Null-Steering Antennas and Intelligent UAV Swarm Behavior](https://arxiv.org/abs/2511.18086)
*Miguel Lourenço,António Grilo*

Main category: cs.RO

TL;DR: 本文研究了无人机群在干扰环境下如何通过智能优化算法和零陷天线技术维持通信和任务效率，提出了结合遗传算法、监督学习和强化学习的统一优化框架。


<details>
  <summary>Details</summary>
Motivation: 无人机群依赖无线通信进行协同任务，但容易受到干扰攻击，导致通信中断和任务失败。需要研究无人机群在干扰环境下如何保持通信稳定性和任务效率。

Method: 提出了统一优化框架，结合遗传算法（GA）、监督学习（SL）和强化学习（RL）。采用分时隙的任务模型，支持动态路径规划、天线定向和编队调整。使用零陷天线技术将天线零点对准干扰源。

Result: 遗传算法能生成稳定无碰撞轨迹但计算成本高；监督学习能复制GA配置但在动态环境下泛化能力不足；强化学习（PPO算法）表现出适应性和实时决策能力，通信稳定且计算需求低。自适应运动模型通过旋转机制实现任意方向运动。

Conclusion: 配备零陷天线和智能优化算法的无人机群能有效抵御干扰，保持通信稳定、编队完整和碰撞安全。该框架为弹性群通信系统研究提供了统一、灵活和可复现的基础。

Abstract: Unmanned Aerial Vehicle (UAV) swarms represent a key advancement in autonomous systems, enabling coordinated missions through inter-UAV communication. However, their reliance on wireless links makes them vulnerable to jamming, which can disrupt coordination and mission success. This work investigates whether a UAV swarm can effectively overcome jamming while maintaining communication and mission efficiency.
  To address this, a unified optimization framework combining Genetic Algorithms (GA), Supervised Learning (SL), and Reinforcement Learning (RL) is proposed. The mission model, structured into epochs and timeslots, allows dynamic path planning, antenna orientation, and swarm formation while progressively enforcing collision rules. Null-steering antennas enhance resilience by directing antenna nulls toward interference sources.
  Results show that the GA achieved stable, collision-free trajectories but with high computational cost. SL models replicated GA-based configurations but struggled to generalize under dynamic or constrained settings. RL, trained via Proximal Policy Optimization (PPO), demonstrated adaptability and real-time decision-making with consistent communication and lower computational demand. Additionally, the Adaptive Movement Model generalized UAV motion to arbitrary directions through a rotation-based mechanism, validating the scalability of the proposed system.
  Overall, UAV swarms equipped with null-steering antennas and guided by intelligent optimization algorithms effectively mitigate jamming while maintaining communication stability, formation cohesion, and collision safety. The proposed framework establishes a unified, flexible, and reproducible basis for future research on resilient swarm communication systems.

</details>


### [553] [A Unified Multi-Dynamics Framework for Perception-Oriented Modeling in Tendon-Driven Continuum Robots](https://arxiv.org/abs/2511.18088)
*Ibrahim Alsarraj,Yuhao Wang,Abdalla Swikir,Cesare Stefanini,Dezhen Song,Zhanchi Wang,Ke Wu*

Main category: cs.RO

TL;DR: 该论文提出了一个统一的多动力学建模框架，用于肌腱驱动连续体机器人系统，通过整合电机电气动力学、电机卷筒动力学和连续体机器人动力学，实现基于内在动力学的感知能力。


<details>
  <summary>Details</summary>
Motivation: 肌腱驱动连续体机器人具有内在安全性和丰富的接触交互能力，但其感知通常依赖外部传感器，这会增加硬件复杂性并限制可扩展性。

Method: 开发了一个统一的多动力学建模框架，整合了电机电气动力学、电机卷筒动力学和连续体机器人动力学，通过电机信号（如电流和角位移）来感知外部交互的机电特征。

Result: 该框架成功验证了实际系统的关键物理行为，包括驱动迟滞和运动极限处的自接触。在环境交互应用中，实现了被动接触检测、主动接触感知和物体尺寸估计，仿真策略可直接应用于真实机器人。

Conclusion: 该框架为肌腱驱动连续体机器人提供了一种基于物理的方式来解释来自内在电机信号的交互特征，实现了不依赖外部传感器的感知能力。

Abstract: Tendon-driven continuum robots offer intrinsically safe and contact-rich interactions owing to their kinematic redundancy and structural compliance. However, their perception often depends on external sensors, which increase hardware complexity and limit scalability. This work introduces a unified multi-dynamics modeling framework for tendon-driven continuum robotic systems, exemplified by a spiral-inspired robot named Spirob. The framework integrates motor electrical dynamics, motor-winch dynamics, and continuum robot dynamics into a coherent system model. Within this framework, motor signals such as current and angular displacement are modeled to expose the electromechanical signatures of external interactions, enabling perception grounded in intrinsic dynamics. The model captures and validates key physical behaviors of the real system, including actuation hysteresis and self-contact at motion limits. Building on this foundation, the framework is applied to environmental interaction: first for passive contact detection, verified experimentally against simulation data; then for active contact sensing, where control and perception strategies from simulation are successfully applied to the real robot; and finally for object size estimation, where a policy learned in simulation is directly deployed on hardware. The results demonstrate that the proposed framework provides a physically grounded way to interpret interaction signatures from intrinsic motor signals in tendon-driven continuum robots.

</details>


### [554] [EchoVLA: Robotic Vision-Language-Action Model with Synergistic Declarative Memory for Mobile Manipulation](https://arxiv.org/abs/2511.18112)
*Min Lin,Xiwen Liang,Bingqian Lin,Liu Jingzhi,Zijian Jiao,Kehan Li,Yuhan Ma,Yuecheng Liu,Shen Zhao,Yuzheng Zhuang,Xiaodan Liang*

Main category: cs.RO

TL;DR: EchoVLA是一种具有记忆能力的视觉-语言-动作模型，专门用于长时程移动操作任务，通过结合场景记忆和情景记忆来提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作模型主要局限于短时程桌面操作，缺乏处理长时程移动操作所需的记忆和推理能力，特别是在需要协调导航和操作的任务中。

Method: EchoVLA引入了协同声明性记忆系统，包括维护空间语义地图的场景记忆和存储任务经验的情景记忆。通过粗粒度和细粒度注意力机制融合记忆表示，指导移动臂扩散策略。同时开发了MoMani自动化基准用于训练和评估。

Result: 在模拟和真实环境实验中，EchoVLA在操作/导航任务上达到0.52成功率，在移动操作任务上达到0.31成功率，相比基线方法分别提升0.08和0.11。

Conclusion: EchoVLA通过记忆机制有效提升了长时程移动操作的性能，证明了记忆增强的视觉-语言-动作模型在复杂机器人任务中的价值。

Abstract: Recent progress in Vision-Language-Action (VLA) models has enabled embodied agents to interpret multimodal instructions and perform complex tasks. However, existing VLAs are mostly confined to short-horizon, table-top manipulation, lacking the memory and reasoning capability required for long-horizon mobile manipulation, where agents must coordinate navigation and manipulation under changing spatial contexts. In this work, we present EchoVLA, a memory-aware VLA model for long-horizon mobile manipulation. EchoVLA incorporates a synergistic declarative memory inspired by the human brain, consisting of a scene memory that maintains a collection of spatial-semantic maps and an episodic memory that stores task-level experiences with multimodal contextual features. During both training and inference, the two memories are individually stored, updated, and retrieved based on current observations, task history, and instructions, and their retrieved representations are fused via coarse- and fine-grained attention to guide mobile-arm diffusion policies. To support large-scale training and evaluation, we further introduce MoMani, an automated benchmark that generates expert-level long-horizon trajectories through multimodal large language model (MLLM)-guided planning and feedback-driven refinement, supplemented with real-robot demonstrations. Experiments in simulated and real-world settings show that EchoVLA improves long-horizon performance, reaching 0.52 SR on manipulation/navigation and 0.31 on mobile manipulation, exceeding $π_{0.5}$ by +0.08 and +0.11.

</details>


### [555] [Observer Actor: Active Vision Imitation Learning with Sparse View Gaussian Splatting](https://arxiv.org/abs/2511.18140)
*Yilong Wang,Cheng Qian,Ruomeng Fan,Edward Johns*

Main category: cs.RO

TL;DR: ObAct是一个主动视觉模仿学习框架，通过动态分配观察者和执行者角色，让观察者移动到最优视觉位置为执行者提供清晰观察，显著提升了双臂机器人系统的性能。


<details>
  <summary>Details</summary>
Motivation: 解决静态相机设置中因遮挡导致的观察质量下降问题，提升模仿学习策略的鲁棒性。

Method: 使用3D高斯泼溅构建场景表示，虚拟探索找到最优相机位姿，观察者移动到该位姿后执行者执行策略。

Result: 相比静态相机设置，轨迹迁移性能提升145%（无遮挡）和233%（有遮挡），行为克隆提升75%和143%。

Conclusion: ObAct框架通过主动视觉观察显著改善了模仿学习性能，使策略在遮挡情况下仍能保持接近无遮挡训练分布的效果。

Abstract: We propose Observer Actor (ObAct), a novel framework for active vision imitation learning in which the observer moves to optimal visual observations for the actor. We study ObAct on a dual-arm robotic system equipped with wrist-mounted cameras. At test time, ObAct dynamically assigns observer and actor roles: the observer arm constructs a 3D Gaussian Splatting (3DGS) representation from three images, virtually explores this to find an optimal camera pose, then moves to this pose; the actor arm then executes a policy using the observer's observations. This formulation enhances the clarity and visibility of both the object and the gripper in the policy's observations. As a result, we enable the training of ambidextrous policies on observations that remain closer to the occlusion-free training distribution, leading to more robust policies. We study this formulation with two existing imitation learning methods -- trajectory transfer and behavior cloning -- and experiments show that ObAct significantly outperforms static-camera setups: trajectory transfer improves by 145% without occlusion and 233% with occlusion, while behavior cloning improves by 75% and 143%, respectively. Videos are available at https://obact.github.io.

</details>


### [556] [A Coordinated Dual-Arm Framework for Delicate Snap-Fit Assemblies](https://arxiv.org/abs/2511.18153)
*Shreyas Kumar,Barat S,Debojit Das,Yug Desai,Siddhi Jain,Rajesh Kumar,Harish J. Palanthandalam-Madapusi*

Main category: cs.RO

TL;DR: 本文提出SnapNet轻量神经网络和双臂协调框架，用于精密卡扣装配中的实时检测和力控制


<details>
  <summary>Details</summary>
Motivation: 解决精密卡扣装配中因过冲导致的组件损坏或装配失败问题，需要及时检测卡扣啮合并快速衰减冲击力

Method: 1) SnapNet轻量神经网络从关节速度瞬变实时检测卡扣啮合；2) 基于动态系统的双臂协调框架，集成检测与事件触发的阻抗调制

Result: 在异构双手平台上进行多样化几何形状实验，显示检测准确率超过96%召回率，峰值冲击力比标准阻抗控制降低30%

Conclusion: 提出的方法能仅使用本体感觉信号实现可靠检测，并在精密卡扣装配中实现精确对齐和柔顺插入

Abstract: Delicate snap-fit assemblies, such as inserting a lens into an eye-wear frame or during electronics assembly, demand timely engagement detection and rapid force attenuation to prevent overshoot-induced component damage or assembly failure. We address these challenges with two key contributions. First, we introduce SnapNet, a lightweight neural network that detects snap-fit engagement from joint-velocity transients in real-time, showing that reliable detection can be achieved using proprioceptive signals without external sensors. Second, we present a dynamical-systems-based dual-arm coordination framework that integrates SnapNet driven detection with an event-triggered impedance modulation, enabling accurate alignment and compliant insertion during delicate snap-fit assemblies. Experiments across diverse geometries on a heterogeneous bimanual platform demonstrate high detection accuracy (over 96% recall) and up to a 30% reduction in peak impact forces compared to standard impedance control.

</details>


### [557] [Time-aware Motion Planning in Dynamic Environments with Conformal Prediction](https://arxiv.org/abs/2511.18170)
*Kaier Liang,Licheng Luo,Yixuan Wang,Mingyu Cai,Cristian Ioan Vasile*

Main category: cs.RO

TL;DR: 提出了两个基于共形预测的运动规划框架，用于动态环境中的安全导航。全局规划器结合安全间隔路径规划提供长期导航的安全保证，局部规划器通过自适应共形预测处理障碍物轨迹预测的不确定性。


<details>
  <summary>Details</summary>
Motivation: 动态环境中的安全导航面临障碍物行为不确定性和缺乏形式化预测保证的挑战。

Method: 使用共形预测技术，提出全局规划器（结合SIPP）和局部规划器。引入自适应分位数机制，自动调整置信水平以保持轨迹可行性。

Result: 在动态和杂乱环境中进行的数值实验验证了该框架的有效性。

Conclusion: 该框架能够提供分布无关的安全保证，并在动态环境中实现鲁棒和响应的运动规划。

Abstract: Safe navigation in dynamic environments remains challenging due to uncertain obstacle behaviors and the lack of formal prediction guarantees. We propose two motion planning frameworks that leverage conformal prediction (CP): a global planner that integrates Safe Interval Path Planning (SIPP) for uncertainty-aware trajectory generation, and a local planner that performs online reactive planning. The global planner offers distribution-free safety guarantees for long-horizon navigation, while the local planner mitigates inaccuracies in obstacle trajectory predictions through adaptive CP, enabling robust and responsive motion in dynamic environments. To further enhance trajectory feasibility, we introduce an adaptive quantile mechanism in the CP-based uncertainty quantification. Instead of using a fixed confidence level, the quantile is automatically tuned to the optimal value that preserves trajectory feasibility, allowing the planner to adaptively tighten safety margins in regions with higher uncertainty. We validate the proposed framework through numerical experiments conducted in dynamic and cluttered environments. The project page is available at https://time-aware-planning.github.io

</details>


### [558] [Off-Road Navigation via Implicit Neural Representation of Terrain Traversability](https://arxiv.org/abs/2511.18183)
*Yixuan Jia,Qingyuan Li,Jonathan P. How*

Main category: cs.RO

TL;DR: TRAIL是一个越野导航框架，使用隐式神经表示来参数化地形属性，并通过梯度优化方法调整路径几何和速度分布。


<details>
  <summary>Details</summary>
Motivation: 传统基于采样的规划器只能优化短期控制动作，无法考虑完整路径几何和根据地形颠簸调整速度，限制了在挑战性越野环境中的导航能力。

Method: 利用隐式神经表示连续参数化地形属性，生成空间梯度，并与新型梯度轨迹优化方法集成，自适应调整路径几何和速度分布。

Result: 该方法能够更全面地考虑路径几何，并根据地形可通行性优化速度和路径。

Conclusion: TRAIL框架通过隐式学习和梯度优化，提升了越野导航中对复杂地形的适应能力和导航质量。

Abstract: Autonomous off-road navigation requires robots to estimate terrain traversability from onboard sensors and plan accordingly. Conventional approaches typically rely on sampling-based planners such as MPPI to generate short-term control actions that aim to minimize traversal time and risk measures derived from the traversability estimates. These planners can react quickly but optimize only over a short look-ahead window, limiting their ability to reason about the full path geometry, which is important for navigating in challenging off-road environments. Moreover, they lack the ability to adjust speed based on the terrain bumpiness, which is important for smooth navigation on challenging terrains. In this paper, we introduce TRAIL (Traversability with an Implicit Learned Representation), an off-road navigation framework that leverages an implicit neural representation to continuously parameterize terrain properties. This representation yields spatial gradients that enable integration with a novel gradient-based trajectory optimization method that adapts the path geometry and speed profile based on terrain traversability.

</details>


### [559] [SkillWrapper: Generative Predicate Invention for Skill Abstraction](https://arxiv.org/abs/2511.18203)
*Ziyi Yang,Benned Hedegaard,Ahmed Jaafar,Yichen Wei,Skye Thompson,Shreyas S. Raman,Haotian Fu,Stefanie Tellex,George Konidaris,David Paulius,Naman Shah*

Main category: cs.RO

TL;DR: 本文提出了一种基于生成式谓词发明的技能抽象理论框架SkillWrapper，利用基础模型从RGB图像中学习可规划的符号化技能表示，解决了长时程任务规划中的抽象表示学习问题。


<details>
  <summary>Details</summary>
Motivation: 当前从个体技能执行泛化到解决长时程任务仍是自主智能体的核心挑战。虽然基于符号谓词的对象中心技能抽象已被证明有效，但现有方法缺乏对学习表示所需满足的形式属性的明确界定，以及如何学习这些表示以保证其属性的方法。

Method: 提出了SkillWrapper方法，利用基础模型主动收集机器人数据，仅使用RGB图像观测学习黑盒技能的人类可解释、可规划抽象表示。该方法基于生成式谓词发明的形式理论框架，确保学习到的符号操作符可用于可证明正确且完备的规划。

Result: 在仿真和真实机器人上的广泛实验评估表明，SkillWrapper学习的抽象表示能够使用黑盒技能解决真实世界中未见的长时程任务。

Conclusion: 该工作为技能抽象学习提供了形式化理论基础，证明了生成式谓词发明在实现可证明正确规划方面的有效性，为解决长时程任务规划问题提供了实用解决方案。

Abstract: Generalizing from individual skill executions to solving long-horizon tasks remains a core challenge in building autonomous agents. A promising direction is learning high-level, symbolic abstractions of the low-level skills of the agents, enabling reasoning and planning independent of the low-level state space. Among possible high-level representations, object-centric skill abstraction with symbolic predicates has been proven to be efficient because of its compatibility with domain-independent planners. Recent advances in foundation models have made it possible to generate symbolic predicates that operate on raw sensory inputs, a process we call generative predicate invention, to facilitate downstream abstraction learning. However, it remains unclear which formal properties the learned representations must satisfy, and how they can be learned to guarantee these properties. In this paper, we address both questions by presenting a formal theory of generative predicate invention for skill abstraction, resulting in symbolic operators that can be used for provably sound and complete planning. Within this framework, we propose SkillWrapper, a method that leverages foundation models to actively collect robot data and learn human-interpretable, plannable representations of black-box skills, using only RGB image observations. Our extensive empirical evaluation in simulation and on real robots shows that SkillWrapper learns abstract representations that enable solving unseen, long-horizon tasks in the real world with black-box skills.

</details>


### [560] [AFT: Appearance-Based Feature Tracking for Markerless and Training-Free Shape Reconstruction of Soft Robots](https://arxiv.org/abs/2511.18215)
*Shangyuan Yuan,Preston Fairchild,Yu Mei,Xinyu Zhou,Xiaobo Tan*

Main category: cs.RO

TL;DR: 提出了一种基于视觉、无标记、无需训练的软机器人形状重建框架，利用机器人自然表面特征实现实时形状跟踪


<details>
  <summary>Details</summary>
Motivation: 现有视觉方法依赖复杂相机设置、特定背景或大规模训练数据，限制了在实际场景中的应用

Method: 利用机器人表面特征作为隐式视觉标记，采用分层匹配策略，将局部分区对齐与全局运动学优化解耦

Result: 在连续软机器人上的实验验证显示实时操作时平均末端误差为2.6%，在闭环控制任务中表现稳定

Conclusion: 该方法在动态真实世界环境中具有可靠、低成本部署的潜力

Abstract: Accurate shape reconstruction is essential for precise control and reliable operation of soft robots. Compared to sensor-based approaches, vision-based methods offer advantages in cost, simplicity, and ease of deployment. However, existing vision-based methods often rely on complex camera setups, specific backgrounds, or large-scale training datasets, limiting their practicality in real-world scenarios. In this work, we propose a vision-based, markerless, and training-free framework for soft robot shape reconstruction that directly leverages the robot's natural surface appearance. These surface features act as implicit visual markers, enabling a hierarchical matching strategy that decouples local partition alignment from global kinematic optimization. Requiring only an initial 3D reconstruction and kinematic alignment, our method achieves real-time shape tracking across diverse environments while maintaining robustness to occlusions and variations in camera viewpoints. Experimental validation on a continuum soft robot demonstrates an average tip error of 2.6% during real-time operation, as well as stable performance in practical closed-loop control tasks. These results highlight the potential of the proposed approach for reliable, low-cost deployment in dynamic real-world settings.

</details>


### [561] [APULSE: A Scalable Hybrid Algorithm for the RCSPP on Large-Scale Dense Graphs](https://arxiv.org/abs/2511.18236)
*Nuno Soares,António Grilo*

Main category: cs.RO

TL;DR: APULSE是一种混合标签设置算法，用于高效解决资源受限最短路径问题（RCSPP），在大规模图上相比现有方法具有显著的速度和可扩展性优势。


<details>
  <summary>Details</summary>
Motivation: 传统RCSPP求解器在处理大规模密集图时面临严重的可扩展性限制，特别是在无人地面车辆任务规划等实时关键应用中，现有方法难以满足时间敏感的计算需求。

Method: APULSE结合了A*启发式引导的最佳优先搜索、Pulse风格的激进剪枝机制以及时间分桶策略，实现有效的状态空间缩减。

Result: 在大规模UGV规划场景的计算研究中，APULSE相比最先进算法能够以数量级更快的速度找到接近最优解，特别是在大规模问题实例上表现更加稳健。

Conclusion: APULSE的卓越可扩展性使其成为复杂大规模环境中RCSPP的有效解决方案，支持交互式决策支持和动态重规划等能力。

Abstract: The resource-constrained shortest path problem (RCSPP) is a fundamental NP-hard optimization challenge with broad applications, from network routing to autonomous navigation. This problem involves finding a path that minimizes a primary cost subject to a budget on a secondary resource. While various RCSPP solvers exist, they often face critical scalability limitations when applied to the large, dense graphs characteristic of complex, real-world scenarios, making them impractical for time-critical planning. This challenge is particularly acute in domains like mission planning for unmanned ground vehicles (UGVs), which demand solutions on large-scale terrain graphs. This paper introduces APULSE, a hybrid label-setting algorithm designed to efficiently solve the RCSPP on such challenging graphs. APULSE integrates a best-first search guided by an A* heuristic with aggressive, Pulse-style pruning mechanisms and a time-bucketing strategy for effective state-space reduction. A computational study, using a large-scale UGV planning scenario, benchmarks APULSE against state-of-the-art algorithms. The results demonstrate that APULSE consistently finds near-optimal solutions while being orders of magnitude faster and more robust, particularly on large problem instances where competing methods fail. This superior scalability establishes APULSE as an effective solution for RCSPP in complex, large-scale environments, enabling capabilities such as interactive decision support and dynamic replanning.

</details>


### [562] [Dreaming Falcon: Physics-Informed Model-Based Reinforcement Learning for Quadcopters](https://arxiv.org/abs/2511.18243)
*Eashan Vytla,Bhavanishankar Kalavakolanu,Andrew Perrault,Matthew McCrink*

Main category: cs.RO

TL;DR: 本文探讨了将物理信息方法应用于无人机世界模型学习，以改进策略性能，但发现标准RNN和物理信息模型在泛化新轨迹时都存在困难。


<details>
  <summary>Details</summary>
Motivation: 当前无人机控制算法在动态环境和不利条件下缺乏鲁棒性，而基于模型的强化学习虽具潜力，但Dreamer等方法在无人机系统上存在样本效率低和动力学模型泛化差的问题。

Method: 提出物理信息世界模型，将无人机视为自由体系统，预测作用在其上的净力和力矩，并通过6自由度Runge-Kutta积分器预测未来状态展开。

Result: 虽然两种模型在训练数据上表现良好，但都无法泛化到新轨迹，导致状态展开快速发散，阻碍策略收敛。

Conclusion: 物理信息方法未能解决世界模型泛化问题，表明需要进一步研究以提高模型在新轨迹上的鲁棒性。

Abstract: Current control algorithms for aerial robots struggle with robustness in dynamic environments and adverse conditions. Model-based reinforcement learning (RL) has shown strong potential in handling these challenges while remaining sample-efficient. Additionally, Dreamer has demonstrated that online model-based RL can be achieved using a recurrent world model trained on replay buffer data. However, applying Dreamer to aerial systems has been quite challenging due to its sample inefficiency and poor generalization of dynamics models. Our work explores a physics-informed approach to world model learning and improves policy performance. The world model treats the quadcopter as a free-body system and predicts the net forces and moments acting on it, which are then passed through a 6-DOF Runge-Kutta integrator (RK4) to predict future state rollouts. In this paper, we compare this physics-informed method to a standard RNN-based world model. Although both models perform well on the training data, we observed that they fail to generalize to new trajectories, leading to rapid divergence in state rollouts, preventing policy convergence.

</details>


### [563] [Skypilot: Fine-Tuning LLM with Physical Grounding for AAV Coverage Search](https://arxiv.org/abs/2511.18270)
*Zhongkai Chen,Yihao Sun,Chao Yan,Han Zhou,Xiaojia Xiang,Jie Jiang*

Main category: cs.RO

TL;DR: Skypilot是一个两阶段LLM增强框架，通过集成蒙特卡洛树搜索将语言模型物理接地，解决AAV在覆盖操作中的幻觉和可重复性问题


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在增强自主飞行器智能方面具有潜力，但缺乏物理接地会导致空间推理和决策中的幻觉和可重复性问题

Method: 两阶段框架：第一阶段引入多样化动作空间和物理感知奖励函数；第二阶段在23,000个MCTS生成样本上微调Qwen3-4B模型

Result: 通过数值模拟和真实飞行实验验证了方法的效率和优越性，实现了推理加速同时保持解决方案质量

Conclusion: Skypilot框架成功解决了LLM在AAV应用中的物理接地问题，为复杂覆盖操作提供了可靠解决方案

Abstract: Autonomous aerial vehicles (AAVs) have played a pivotal role in coverage operations and search missions. Recent advances in large language models (LLMs) offer promising opportunities to augment AAV intelligence. These advances help address complex challenges like area coverage optimization, dynamic path planning, and adaptive decision-making. However, the absence of physical grounding in LLMs leads to hallucination and reproducibility problems in spatial reasoning and decision-making. To tackle these issues, we present Skypilot, an LLM-enhanced two-stage framework that grounds language models in physical reality by integrating monte carlo tree search (MCTS). In the first stage, we introduce a diversified action space that encompasses generate, regenerate, fine-tune, and evaluate operations, coupled with physics-informed reward functions to ensure trajectory feasibility. In the second stage, we fine-tune Qwen3-4B on 23,000 MCTS-generated samples, achieving substantial inference acceleration while maintaining solution quality. Extensive numerical simulations and real-world flight experiments validate the efficiency and superiority of our proposed approach. Detailed information and experimental results are accessible at https://sky-pilot.top.

</details>


### [564] [AIA-UltraNeRF:Acoustic-Impedance-Aware Neural Radiance Field with Hash Encodings for Robotic Ultrasound Reconstruction and Localization](https://arxiv.org/abs/2511.18293)
*Shuai Zhang,Jingsong Mu,Cancan Zhao,Leiqi Tian,Zhijun Xing,Bo Ouyang,Xiang Li*

Main category: cs.RO

TL;DR: 该论文提出了AIA-UltraNeRF方法，通过声阻抗感知的神经辐射场技术，实现了超声图像重建和定位的加速，推理速度比传统NeRF快9.9倍。


<details>
  <summary>Details</summary>
Motivation: 传统NeRF方法在超声成像中忽视了声阻抗的关键作用，且定位方法因初始位姿选择问题容易陷入局部最优解。需要开发能够分离扫描和诊断过程的机器人超声系统。

Method: 设计了机器人超声系统(RUSS)和声阻抗感知超声NeRF(AIA-UltraNeRF)，使用哈希编码的空间坐标建模3D超声图，存储声阻抗信息；提出双监督网络利用师生模型对渲染图像进行哈希编码，实现离线初始定位。

Result: 在体模和人体实验上验证了声阻抗在隐式表征超声图像颜色方面的有效性，AIA-UltraNeRF在重建和定位任务中的推理速度比传统NeRF快9.9倍。

Conclusion: AIA-UltraNeRF方法成功解决了超声成像中的重建和定位问题，通过声阻抗建模和哈希编码技术实现了高效的操作，为机器人超声系统提供了可行的技术方案。

Abstract: Neural radiance field (NeRF) is a promising approach for reconstruction and new view synthesis. However, previous NeRF-based reconstruction methods overlook the critical role of acoustic impedance in ultrasound imaging. Localization methods face challenges related to local minima due to the selection of initial poses. In this study, we design a robotic ultrasound system (RUSS) with an acoustic-impedance-aware ultrasound NeRF (AIA-UltraNeRF) to decouple the scanning and diagnostic processes. Specifically, AIA-UltraNeRF models a continuous function of hash-encoded spatial coordinates for the 3D ultrasound map, allowing for the storage of acoustic impedance without dense sampling. This approach accelerates both reconstruction and inference speeds. We then propose a dual-supervised network that leverages teacher and student models to hash-encode the rendered ultrasound images from the reconstructed map. AIA-UltraNeRF retrieves the most similar hash values without the need to render images again, providing an offline initial image position for localization. Moreover, we develop a RUSS with a spherical remote center of motion mechanism to hold the probe, implementing operator-independent scanning modes that separate image acquisition from diagnostic workflows. Experimental results on a phantom and human subjects demonstrate the effectiveness of acoustic impedance in implicitly characterizing the color of ultrasound images. AIAUltraNeRF achieves both reconstruction and localization with inference speeds that are 9.9 faster than those of vanilla NeRF.

</details>


### [565] [MicCheck: Repurposing Off-the-Shelf Pin Microphones for Easy and Low-Cost Contact Sensing](https://arxiv.org/abs/2511.18299)
*Steven Oh,Tai Inui,Magdeline Kuan,Jia-Yeu Lin*

Main category: cs.RO

TL;DR: MicCheck是一种利用现成蓝牙针式麦克风作为低成本接触传感器的即插即用声学传感方法，通过将麦克风集成到3D打印的夹爪中，无需定制电子设备即可实现触觉感知和控制。


<details>
  <summary>Details</summary>
Motivation: 机器人操作任务需要丰富的接触信息，但现有的视觉模仿学习方法难以捕捉刚度、粗糙度、滑动等精细交互线索。虽然触觉信号可以解决这一问题，但现有传感器通常昂贵、脆弱或集成复杂。

Method: 将现成的蓝牙针式麦克风作为接触传感器，通过3D打印的夹爪插入件固定，使用标准USB接收器传输音频信号，无需定制电子设备或驱动程序。

Result: 在材料分类任务中，10类基准测试的准确率达到92.9%；在操作任务中，将针式麦克风集成到模仿学习流程中，拾取和倾倒任务的成功率从0.40提高到0.80，并能可靠执行拔插和基于声音的排序等接触密集型技能。

Conclusion: 与高分辨率触觉传感器相比，针式麦克风在空间细节上有所牺牲，但在成本和集成便利性上具有优势，为低成本机器人设置中部署声学接触传感提供了实用途径。

Abstract: Robotic manipulation tasks are contact-rich, yet most imitation learning (IL) approaches rely primarily on vision, which struggles to capture stiffness, roughness, slip, and other fine interaction cues. Tactile signals can address this gap, but existing sensors often require expensive, delicate, or integration-heavy hardware. In this work, we introduce MicCheck, a plug-and-play acoustic sensing approach that repurposes an off-the-shelf Bluetooth pin microphone as a low-cost contact sensor. The microphone clips into a 3D-printed gripper insert and streams audio via a standard USB receiver, requiring no custom electronics or drivers. Despite its simplicity, the microphone provides signals informative enough for both perception and control. In material classification, it achieves 92.9% accuracy on a 10-class benchmark across four interaction types (tap, knock, slow press, drag). For manipulation, integrating pin microphone into an IL pipeline with open source hardware improves the success rate on picking and pouring task from 0.40 to 0.80 and enables reliable execution of contact-rich skills such as unplugging and sound-based sorting. Compared with high-resolution tactile sensors, pin microphones trade spatial detail for cost and ease of integration, offering a practical pathway for deploying acoustic contact sensing in low-cost robot setups.

</details>


### [566] [Learning Visually Interpretable Oscillator Networks for Soft Continuum Robots from Video](https://arxiv.org/abs/2511.18322)
*Henrik Krauss,Johann Licher,Naoya Takeishi,Annika Raatz,Takehisa Yairi*

Main category: cs.RO

TL;DR: 提出Attention Broadcast Decoder（ABCD）模块，通过注意力机制将潜在维度映射到图像空间，并结合二维振荡器网络实现软体连续机器人动力学的可解释学习。


<details>
  <summary>Details</summary>
Motivation: 解决数据驱动方法缺乏物理可解释性，而基于模型方法需要先验知识且计算成本高的问题。

Method: 1. 开发ABCD模块作为自动编码器的即插即用组件，生成像素级注意力图定位每个潜在维度的贡献；2. 将注意力图与二维振荡器网络耦合，实现学习动力学的可视化。

Result: 在单段和双段软体连续机器人上验证，ABCD模型显著提升多步预测精度：Koopman算子误差降低5.7倍，振荡器网络误差降低3.5倍。学习到的振荡器网络自主发现振荡器链结构。

Conclusion: 该方法实现了完全数据驱动的紧凑、物理可解释模型，适用于控制应用，并能进行超出训练数据的平滑潜在空间外推。

Abstract: Data-driven learning of soft continuum robot (SCR) dynamics from high-dimensional observations offers flexibility but often lacks physical interpretability, while model-based approaches require prior knowledge and can be computationally expensive. We bridge this gap by introducing (1) the Attention Broadcast Decoder (ABCD), a plug-and-play module for autoencoder-based latent dynamics learning that generates pixel-accurate attention maps localizing each latent dimension's contribution while filtering static backgrounds. (2) By coupling these attention maps to 2D oscillator networks, we enable direct on-image visualization of learned dynamics (masses, stiffness, and forces) without prior knowledge. We validate our approach on single- and double-segment SCRs, demonstrating that ABCD-based models significantly improve multi-step prediction accuracy: 5.7x error reduction for Koopman operators and 3.5x for oscillator networks on the two-segment robot. The learned oscillator network autonomously discovers a chain structure of oscillators. Unlike standard methods, ABCD models enable smooth latent space extrapolation beyond training data. This fully data-driven approach yields compact, physically interpretable models suitable for control applications.

</details>


### [567] [Enhancing UAV Search under Occlusion using Next Best View Planning](https://arxiv.org/abs/2511.18353)
*Sigrid Helene Strand,Thomas Wiedemann,Bram Burczek,Dmitriy Shutin*

Main category: cs.RO

TL;DR: 本文提出了一种针对遮挡环境（如茂密森林）中无人机搜索救援任务的优化规划策略，通过几何启发式和可见性启发式两种新方法来解决最佳视角选择问题。


<details>
  <summary>Details</summary>
Motivation: 在自然灾害或高风险环境中的搜救任务中，茂密森林等高遮挡地形给无人机搜索带来挑战。无人机需要有效的搜索策略来优化相机位置和视角，以提高地面目标的可视性。

Method: 提出了两种优化启发式方法：几何启发式和可见性启发式，用于在遮挡环境中选择最优相机视角。通过算法优化解决下一最佳视角问题。

Result: 在模拟和真实环境中的比较评估显示，可见性启发式表现更优，在模拟森林中识别出超过90%的隐藏目标，检测率比几何启发式高出10%。真实实验表明可见性启发式在树冠下提供更好的覆盖范围。

Conclusion: 可见性启发式方法在遮挡环境中具有更好的搜索性能，能够显著提高搜救任务的效果，特别是在茂密森林等复杂地形中。

Abstract: Search and rescue missions are often critical following sudden natural disasters or in high-risk environmental situations. The most challenging search and rescue missions involve difficult-to-access terrains, such as dense forests with high occlusion. Deploying unmanned aerial vehicles for exploration can significantly enhance search effectiveness, facilitate access to challenging environments, and reduce search time. However, in dense forests, the effectiveness of unmanned aerial vehicles depends on their ability to capture clear views of the ground, necessitating a robust search strategy to optimize camera positioning and perspective. This work presents an optimized planning strategy and an efficient algorithm for the next best view problem in occluded environments. Two novel optimization heuristics, a geometry heuristic, and a visibility heuristic, are proposed to enhance search performance by selecting optimal camera viewpoints. Comparative evaluations in both simulated and real-world settings reveal that the visibility heuristic achieves greater performance, identifying over 90% of hidden objects in simulated forests and offering 10% better detection rates than the geometry heuristic. Additionally, real-world experiments demonstrate that the visibility heuristic provides better coverage under the canopy, highlighting its potential for improving search and rescue missions in occluded environments.

</details>


### [568] [Explicit Bounds on the Hausdorff Distance for Truncated mRPI Sets via Norm-Dependent Contraction Rates](https://arxiv.org/abs/2511.18374)
*Jiaxun Sun*

Main category: cs.RO

TL;DR: 本文首次建立了截断最小鲁棒正不变集与其无限时域极限之间Hausdorff距离的显式闭式上界，提供了可计算的截断误差表达式，并证明了向量范数选择可作为加速收敛的设计参数。


<details>
  <summary>Details</summary>
Motivation: 现有mRPI近似方法只能保证渐近收敛，但无法为给定时域提供可计算的截断误差量化表达式，这限制了鲁棒不变集计算和管基MPC的实际应用。

Method: 通过分析截断Minkowski级数的衰减特性，推导出Hausdorff距离的上界公式，其中γ为诱导范数收缩因子，r_W仅依赖于扰动集。

Result: 得到了完全解析的上界表达式d_H(ℰ_N,ℰ_∞) ≤ r_W·γ^(N+1)/(1-γ)，无需迭代集计算，直接表征了截断误差的衰减速率。

Conclusion: 数值实验验证了所提边界的锐度、可扩展性和实际相关性，向量范数选择可显著加速收敛，为鲁棒不变集计算和管基MPC提供了更紧的时域选择方法。

Abstract: This paper establishes the first explicit and closed-form upper bound on the Hausdorff distance between the truncated minimal robust positively invariant (mRPI) set and its infinite-horizon limit. While existing mRPI approximations guarantee asymptotic convergence through geometric or norm-based arguments, none provides a computable expression that quantifies the truncation error for a given horizon. We show that the error satisfies \( d_H(\mathcal{E}_N,\mathcal{E}_\infty) \le r_W\,γ^{N+1}/(1-γ), \) where $γ<1$ is the induced-norm contraction factor and $r_W$ depends only on the disturbance set. The bound is fully analytic, requires no iterative set computations, and directly characterizes the decay rate of the truncated Minkowski series. We further demonstrate that the choice of vector norm serves as a design parameter that accelerates convergence, enabling substantially tighter horizon selection for robust invariant-set computations and tube-based MPC. Numerical experiments validate the sharpness, scalability, and practical relevance of the proposed bound.

</details>


### [569] [Expanding the Workspace of Electromagnetic Navigation Systems Using Dynamic Feedback for Single- and Multi-agent Control](https://arxiv.org/abs/2511.18486)
*Jasan Zughaibi,Denis von Arx,Maurus Derungs,Florian Heemeyer,Luca A. Antonelli,Quentin Boehler,Michael Muehlebach,Bradley J. Nelson*

Main category: cs.RO

TL;DR: 本文提出了一种系统级控制设计方法，通过五种关键系统方法显著扩展电磁导航系统（eMNS）的有效工作空间，并显著降低所需电流。


<details>
  <summary>Details</summary>
Motivation: 电磁导航系统在磁引导手术中具有重要应用，但其有效工作空间常受功率和热限制的严重约束。需要寻找方法来扩大工作空间并降低电流需求。

Method: 采用五种系统方法：(i)运动中心的扭矩/力目标；(ii)能量最优电流分配；(iii)实时位姿估计；(iv)动态反馈；(v)高带宽eMNS组件。通过从场中心的对齐策略转向运动中心的扭矩/力方法来实现控制。

Result: 在八线圈OctoMag eMNS上稳定3D倒立摆时，电流从8-14A降至0.1-0.2A。在临床导向的Navion eMNS上，在距离线圈50cm处仍能保持稳定平衡，显著扩展了工作空间。同时实现了多智能体控制，稳定两个倒立摆。

Conclusion: 反馈控制是实现可扩展、高效且临床相关的磁操纵的实用途径，系统级控制设计能显著提升电磁导航系统的性能和工作空间。

Abstract: Electromagnetic navigation systems (eMNS) enable a number of magnetically guided surgical procedures. A challenge in magnetically manipulating surgical tools is that the effective workspace of an eMNS is often severely constrained by power and thermal limits. We show that system-level control design significantly expands this workspace by reducing the currents needed to achieve a desired motion. We identified five key system approaches that enable this expansion: (i) motion-centric torque/force objectives, (ii) energy-optimal current allocation, (iii) real-time pose estimation, (iv) dynamic feedback, and (v) high-bandwidth eMNS components. As a result, we stabilize a 3D inverted pendulum on an eight-coil OctoMag eMNS with significantly lower currents (0.1-0.2 A vs. 8-14 A), by replacing a field-centric field-alignment strategy with a motion-centric torque/force-based approach. We generalize to multi-agent control by simultaneously stabilizing two inverted pendulums within a shared workspace, exploiting magnetic-field nonlinearity and coil redundancy for independent actuation. A structured analysis compares the electromagnetic workspaces of both paradigms and examines current-allocation strategies that map motion objectives to coil currents. Cross-platform evaluation of the clinically oriented Navion eMNS further demonstrates substantial workspace expansion by maintaining stable balancing at distances up to 50 cm from the coils. The results demonstrate that feedback is a practical path to scalable, efficient, and clinically relevant magnetic manipulation.

</details>


### [570] [SafeFall: Learning Protective Control for Humanoid Robots](https://arxiv.org/abs/2511.18509)
*Ziyu Meng,Tengyu Liu,Le Ma,Yingying Wu,Ran Song,Wei Zhang,Siyuan Huang*

Main category: cs.RO

TL;DR: SafeFall是一个保护人形机器人免受跌落损坏的框架，包含跌倒预测器和保护策略，能在不可避免的跌倒时执行损伤最小化动作


<details>
  <summary>Details</summary>
Motivation: 双足行走使人形机器人容易跌倒，会对昂贵的传感器、执行器和结构组件造成灾难性损坏，这是实际部署的关键障碍

Method: 结合轻量级GRU跌倒预测器和强化学习保护策略，预测器持续监控机器人状态，保护策略在检测到不可避免跌倒时激活，使用损伤感知奖励函数训练

Result: 在Unitree G1人形机器人上验证，峰值接触力降低68.3%，峰值关节扭矩降低78.4%，脆弱部件碰撞减少99.3%

Conclusion: SafeFall为人形机器人提供了关键的安全网，支持更激进的实验并加速在复杂现实环境中的部署

Abstract: Bipedal locomotion makes humanoid robots inherently prone to falls, causing catastrophic damage to the expensive sensors, actuators, and structural components of full-scale robots. To address this critical barrier to real-world deployment, we present \method, a framework that learns to predict imminent, unavoidable falls and execute protective maneuvers to minimize hardware damage. SafeFall is designed to operate seamlessly alongside existing nominal controller, ensuring no interference during normal operation. It combines two synergistic components: a lightweight, GRU-based fall predictor that continuously monitors the robot's state, and a reinforcement learning policy for damage mitigation. The protective policy remains dormant until the predictor identifies a fall as unavoidable, at which point it activates to take control and execute a damage-minimizing response. This policy is trained with a novel, damage-aware reward function that incorporates the robot's specific structural vulnerabilities, learning to shield critical components like the head and hands while absorbing energy with more robust parts of its body. Validated on a full-scale Unitree G1 humanoid, SafeFall demonstrated significant performance improvements over unprotected falls. It reduced peak contact forces by 68.3\%, peak joint torques by 78.4\%, and eliminated 99.3\% of collisions with vulnerable components. By enabling humanoids to fail safely, SafeFall provides a crucial safety net that allows for more aggressive experiments and accelerates the deployment of these robots in complex, real-world environments.

</details>


### [571] [Splatblox: Traversability-Aware Gaussian Splatting for Outdoor Robot Navigation](https://arxiv.org/abs/2511.18525)
*Samarth Chopra,Jing Liang,Gershom Seneviratne,Yonghan Lee,Jaehoon Choi,Jianyu An,Stephen Cheng,Dinesh Manocha*

Main category: cs.RO

TL;DR: Splatblox是一个实时户外导航系统，融合RGB图像和LiDAR点云，通过高斯泼溅构建可通行性感知的ESDF地图，在植被密集环境中实现高成功率导航。


<details>
  <summary>Details</summary>
Motivation: 解决户外环境中密集植被、不规则障碍物和复杂地形带来的导航挑战，传统方法难以区分可穿越植被和刚性障碍物。

Method: 融合分割的RGB图像和LiDAR点云，使用高斯泼溅技术构建联合编码几何和语义的可通行性感知ESDF地图，支持在线更新和语义推理。

Result: 在植被丰富场景的实地测试中，相比最先进方法成功率提高50%以上，冻结事件减少40%，路径缩短5%，目标达成时间快13%，支持100米长距离任务。

Conclusion: Splatblox系统在复杂户外环境中表现出色，成功验证了从四足机器人到轮式平台的迁移能力，为户外自主导航提供了有效解决方案。

Abstract: We present Splatblox, a real-time system for autonomous navigation in outdoor environments with dense vegetation, irregular obstacles, and complex terrain. Our method fuses segmented RGB images and LiDAR point clouds using Gaussian Splatting to construct a traversability-aware Euclidean Signed Distance Field (ESDF) that jointly encodes geometry and semantics. Updated online, this field enables semantic reasoning to distinguish traversable vegetation (e.g., tall grass) from rigid obstacles (e.g., trees), while LiDAR ensures 360-degree geometric coverage for extended planning horizons. We validate Splatblox on a quadruped robot and demonstrate transfer to a wheeled platform. In field trials across vegetation-rich scenarios, it outperforms state-of-the-art methods with over 50% higher success rate, 40% fewer freezing incidents, 5% shorter paths, and up to 13% faster time to goal, while supporting long-range missions up to 100 meters. Experiment videos and more details can be found on our project page: https://splatblox.github.io

</details>


### [572] [Object-centric Task Representation and Transfer using Diffused Orientation Fields](https://arxiv.org/abs/2511.18563)
*Cem Bilaloglu,Tobias Löw,Sylvain Calinon*

Main category: cs.RO

TL;DR: 该论文提出了一种使用扩散方向场（DOF）的方法，用于解决曲面物体上技能迁移的挑战。通过建立局部参考框架的平滑表示，将任务表达为这些局部框架中的操作，从而将曲面物体间的任务迁移问题简化为稀疏关键点对应关系。


<details>
  <summary>Details</summary>
Motivation: 曲面物体缺乏全局参考框架，导致任务相关方向随位置和几何形状变化，使得基于物体的任务难以在不同形状间迁移。

Method: 使用扩散方向场（DOF）作为局部参考框架的平滑表示，通过由偏微分方程控制的扩散过程从原始点云数据在线计算DOF，并以关键点为条件。

Result: 在几何、拓扑和定位扰动下评估DOF，成功实现了需要连续物理交互的任务（如检查、切割和剥皮）在不同物体间的迁移。

Conclusion: DOF方法有效解决了曲面物体上技能迁移的挑战，通过局部参考框架的平滑表示简化了任务迁移过程。

Abstract: Curved objects pose a fundamental challenge for skill transfer in robotics: unlike planar surfaces, they do not admit a global reference frame. As a result, task-relevant directions such as "toward" or "along" the surface vary with position and geometry, making object-centric tasks difficult to transfer across shapes. To address this, we introduce an approach using Diffused Orientation Fields (DOF), a smooth representation of local reference frames, for transfer learning of tasks across curved objects. By expressing manipulation tasks in these smoothly varying local frames, we reduce the problem of transferring tasks across curved objects to establishing sparse keypoint correspondences. DOF is computed online from raw point cloud data using diffusion processes governed by partial differential equations, conditioned on keypoints. We evaluate DOF under geometric, topological, and localization perturbations, and demonstrate successful transfer of tasks requiring continuous physical interaction such as inspection, slicing, and peeling across varied objects. We provide our open-source codes at our website https://github.com/idiap/diffused_fields_robotics

</details>


### [573] [An Analysis of Constraint-Based Multi-Agent Pathfinding Algorithms](https://arxiv.org/abs/2511.18604)
*Hannah Lee,James D. Motes,Marco Morales,Nancy M. Amato*

Main category: cs.RO

TL;DR: 该研究通过约束分类指导多智能体路径规划算法设计，分析保守约束和激进约束的搜索行为，发现激进约束在智能体数量或分辨率增加时能解决更多实例，而保守约束在两者都成功时提供更好的解质量。


<details>
  <summary>Details</summary>
Motivation: 为未来的多智能体路径规划和多机器人运动规划算法设计提供指导，基于约束分类帮助用户选择合适的约束策略。

Method: 使用混合网格-路线图表示方法，在不同分辨率下比较vanilla冲突搜索和带优先级的冲突搜索算法，将约束分类为保守型和激进型。

Result: 激进约束（优先级约束）在智能体数量或分辨率增加时能解决更多问题实例，保守约束（运动约束）在两者都成功时提供更优的解质量。

Conclusion: 研究结果汇总为决策流程图，帮助用户选择合适约束，建议在多机器人运动规划中考虑拓扑特征与问题、解和表示特征的结合。

Abstract: This study informs the design of future multi-agent pathfinding (MAPF) and multi-robot motion planning (MRMP) algorithms by guiding choices based on constraint classification for constraint-based search algorithms. We categorize constraints as conservative or aggressive and provide insights into their search behavior, focusing specifically on vanilla Conflict-Based Search (CBS) and Conflict-Based Search with Priorities (CBSw/P). Under a hybrid grid-roadmap representation with varying resolution, we observe that aggressive (priority constraint) formulations tend to solve more instances as agent count or resolution increases, whereas conservative (motion constraint) formulations yield stronger solution quality when both succeed. Findings are synthesized in a decision flowchart, aiding users in selecting suitable constraints. Recommendations extend to Multi-Robot Motion Planning (MRMP), emphasizing the importance of considering topological features alongside problem, solution, and representation features. A comprehensive exploration of the study, including raw data and map performance, is available in our public GitHub Repository: https://GitHub.com/hannahjmlee/constraint-mapf-analysis

</details>


### [574] [How to Train Your Latent Control Barrier Function: Smooth Safety Filtering Under Hard-to-Model Constraints](https://arxiv.org/abs/2511.18606)
*Kensuke Nakamura,Arun L. Bishop,Steven Man,Aaron M. Johnson,Zachary Manchester,Andrea Bajcsy*

Main category: cs.RO

TL;DR: 本文提出LatentCBF方法，通过梯度惩罚实现平滑的边界函数，解决了现有潜在安全滤波器在视觉运动控制中因离散切换策略导致任务性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: 现有潜在安全滤波器采用"最小限制"过滤策略，在名义策略和安全策略之间进行离散切换，这会削弱现代视觉运动策略的任务性能。虽然可达性值函数理论上可以适配为控制屏障函数进行平滑优化过滤，但当前的潜在空间学习方法产生的值函数存在不兼容问题。

Method: 提出LatentCBF方法：1）使用梯度惩罚实现平滑的边界函数，无需额外标注；2）通过混合名义策略和安全策略分布的数据进行值训练。解决了边界函数饱和导致值函数不连续跳跃的问题，以及仅基于安全策略数据训练导致名义策略动作值估计不准确的问题。

Result: 在模拟基准测试和基于视觉的机械臂操作硬件实验中，LatentCBF实现了平滑的安全过滤，相比先前的切换方法将任务完成率提高了一倍。

Conclusion: LatentCBF通过解决潜在空间可达性值函数与控制屏障函数的不兼容性问题，成功实现了平滑的安全过滤，显著提升了视觉运动控制策略的任务性能。

Abstract: Latent safety filters extend Hamilton-Jacobi (HJ) reachability to operate on latent state representations and dynamics learned directly from high-dimensional observations, enabling safe visuomotor control under hard-to-model constraints. However, existing methods implement "least-restrictive" filtering that discretely switch between nominal and safety policies, potentially undermining the task performance that makes modern visuomotor policies valuable. While reachability value functions can, in principle, be adapted to be control barrier functions (CBFs) for smooth optimization-based filtering, we theoretically and empirically show that current latent-space learning methods produce fundamentally incompatible value functions. We identify two sources of incompatibility: First, in HJ reachability, failures are encoded via a "margin function" in latent space, whose sign indicates whether or not a latent is in the constraint set. However, representing the margin function as a classifier yields saturated value functions that exhibit discontinuous jumps. We prove that the value function's Lipschitz constant scales linearly with the margin function's Lipschitz constant, revealing that smooth CBFs require smooth margins. Second, reinforcement learning (RL) approximations trained solely on safety policy data yield inaccurate value estimates for nominal policy actions, precisely where CBF filtering needs them. We propose the LatentCBF, which addresses both challenges through gradient penalties that lead to smooth margin functions without additional labeling, and a value-training procedure that mixes data from both nominal and safety policy distributions. Experiments on simulated benchmarks and hardware with a vision-based manipulation policy demonstrate that LatentCBF enables smooth safety filtering while doubling the task-completion rate over prior switching methods.

</details>


### [575] [AutoFocus-IL: VLM-based Saliency Maps for Data-Efficient Visual Imitation Learning without Extra Human Annotations](https://arxiv.org/abs/2511.18617)
*Litian Gong,Fatemeh Bahrani,Yutai Zhou,Amin Banayeeanzade,Jiachen Li,Erdem Biyik*

Main category: cs.RO

TL;DR: AutoFocus-IL通过利用视觉语言模型自动识别关键物体，生成时间显著性图来指导模仿学习策略关注任务相关特征，无需昂贵的人工标注监督。


<details>
  <summary>Details</summary>
Motivation: 现有显著性正则化方法需要昂贵的人工监督（如人类注视数据或手动标注），而AutoFocus-IL旨在开发一种无需人工监督的自动化方法，提高视觉模仿学习的数据效率和泛化能力。

Method: 利用视觉语言模型自动识别和跟踪演示中的关键物体，生成时间显著性图，突出因果视觉信号并抑制干扰因素，然后将这些图用于正则化行为克隆策略。

Result: 在CARLA模拟器和真实机器人操作任务中的实验表明，AutoFocus-IL不仅优于标准行为克隆，还超越了需要人类监督（如注视数据）的最先进基线方法。

Conclusion: AutoFocus-IL是一种简单有效的视觉模仿学习方法，能够自动引导策略关注任务相关特征，显著提高数据效率和泛化性能，且无需昂贵的人工监督。

Abstract: AutoFocus-IL is a simple yet effective method to improve data efficiency and generalization in visual imitation learning by guiding policies to attend to task-relevant features rather than distractors and spurious correlations. Although saliency regularization has emerged as a promising way to achieve this, existing approaches typically require costly supervision such as human gaze data or manual saliency annotations. In contrast, AutoFocus-IL leverages vision-language models (VLMs) to automatically identify and track key objects in demonstrations, generating temporal saliency maps that highlight causal visual signals while suppressing distractors. These maps are then used to regularize behavior cloning policies, yielding stronger alignment between visual attention and task-relevant cues. Experiments in both the CARLA simulator and real-robot manipulation tasks demonstrate that AutoFocus-IL not only outperforms standard behavior cloning but also surpasses state-of-the-art baselines that assume privileged access to human supervision, such as gaze data. Code, datasets, and trained policy videos are available at https://AutoFocus-IL.github.io/.

</details>


### [576] [Online Learning-Enhanced Lie Algebraic MPC for Robust Trajectory Tracking of Autonomous Surface Vehicles](https://arxiv.org/abs/2511.18683)
*Yinan Dong,Ziyu Xu,Tsimafei Lazouski,Sangli Teng,Maani Ghaffari*

Main category: cs.RO

TL;DR: 提出了一种结合凸误差状态MPC和在线学习模块的高效控制器，用于解决自主水面艇在未知环境扰动下的轨迹跟踪问题。


<details>
  <summary>Details</summary>
Motivation: 自主水面艇（ASVs）在动态海洋环境中容易受到风浪等环境扰动的影响，导致轨迹跟踪精度难以保证。

Method: 将李群上的凸误差状态模型预测控制（MPC）与在线学习模块相结合，实时补偿未知扰动，实现自适应鲁棒控制。

Result: 通过数值模拟、VRX模拟器和真实场景实验验证，该方法在各种扰动场景下相比现有方法具有更优的跟踪精度。

Conclusion: 该方法能够在保持计算效率的同时，有效应对未知环境扰动，提升自主水面艇的轨迹跟踪性能。

Abstract: Autonomous surface vehicles (ASVs) are easily influenced by environmental disturbances such as wind and waves, making accurate trajectory tracking a persistent challenge in dynamic marine conditions. In this paper, we propose an efficient controller for trajectory tracking of marine vehicles under unknown disturbances by combining a convex error-state MPC on the Lie group with an online learning module to compensate for these disturbances in real time. This design enables adaptive and robust control while maintaining computational efficiency. Extensive evaluations in numerical simulations, the Virtual RobotX (VRX) simulator, and real-world field experiments demonstrate that our method achieves superior tracking accuracy under various disturbance scenarios compared with existing approaches.

</details>


### [577] [Stable Multi-Drone GNSS Tracking System for Marine Robots](https://arxiv.org/abs/2511.18694)
*Shuo Wen,Edwin Meriaux,Mariana Sosa Guzmán,Zhizun Wang,Junming Shi,Gregory Dudek*

Main category: cs.RO

TL;DR: 提出了一种基于多无人机GNSS的可扩展跟踪系统，用于水面和近水面海洋机器人定位，解决了水下GNSS信号不可用的问题。


<details>
  <summary>Details</summary>
Motivation: 海洋机器人精确定位至关重要，但GNSS信号在水下不可靠或不可用。传统方法如惯性导航、DVL、SLAM和声学方法存在误差累积、计算量大或依赖基础设施等问题。

Method: 结合高效视觉检测、轻量级多目标跟踪、GNSS三角测量和置信度加权的扩展卡尔曼滤波器，实现实时稳定的GNSS估计。引入跨无人机跟踪ID对齐算法确保全局一致性。

Result: 在多样化复杂环境中验证了系统的可扩展性和鲁棒性。

Conclusion: 该系统为海洋机器人提供了可靠的水面定位解决方案，克服了传统方法的局限性。

Abstract: Accurate localization is essential for marine robotics, yet Global Navigation Satellite System (GNSS) signals are unreliable or unavailable even at a very short distance below the water surface. Traditional alternatives, such as inertial navigation, Doppler Velocity Loggers (DVL), SLAM, and acoustic methods, suffer from error accumulation, high computational demands, or infrastructure dependence. In this work, we present a scalable multi-drone GNSS-based tracking system for surface and near-surface marine robots. Our approach combines efficient visual detection, lightweight multi-object tracking, GNSS-based triangulation, and a confidence-weighted Extended Kalman Filter (EKF) to provide stable GNSS estimation in real time. We further introduce a cross-drone tracking ID alignment algorithm that enforces global consistency across views, enabling robust multi-robot tracking with redundant aerial coverage. We validate our system in diversified complex settings to show the scalability and robustness of the proposed algorithm.

</details>


### [578] [CNN-Based Camera Pose Estimation and Localisation of Scan Images for Aircraft Visual Inspection](https://arxiv.org/abs/2511.18702)
*Xueyan Oh,Leonard Loh,Shaohui Foong,Zhong Bao Andy Koh,Kow Leong Ng,Poh Kang Tan,Pei Lin Pearlin Toh,U-Xuan Tan*

Main category: cs.RO

TL;DR: 提出一种无需基础设施的PTZ相机位姿估计方法，用于飞机外部视觉检测的自动化初始化，通过深度学习网络在合成图像上训练，结合飞机几何约束提高精度，实现0.24米和2度以内的位姿估计误差。


<details>
  <summary>Details</summary>
Motivation: 传统飞机外部视觉检测依赖人工且需基础设施支持，在机场停机坪等受限环境中难以部署。现有定位方法需要接触飞机表面或使用无人机，但航空公司通常禁止这些操作，因此需要一种非接触式、无需基础设施的自动化解决方案。

Method: 使用在合成图像上微调的深度卷积神经网络预测PTZ相机自身位姿，应用领域随机化生成训练数据集，并利用飞机几何特征改进损失函数。提出包含初始化、扫描路径规划和图像精确定位的工作流程。

Result: 在真实飞机场景实验中，相机位姿估计的均方根误差小于0.24米和2度，验证了方法的有效性和精度。

Conclusion: 该方法为飞机外部自动化视觉检测提供了一种可行解决方案，无需基础设施支持，满足机场操作的时间限制和安全要求，具有实际部署价值。

Abstract: General Visual Inspection is a manual inspection process regularly used to detect and localise obvious damage on the exterior of commercial aircraft. There has been increasing demand to perform this process at the boarding gate to minimise the downtime of the aircraft and automating this process is desired to reduce the reliance on human labour. Automating this typically requires estimating a camera's pose with respect to the aircraft for initialisation but most existing localisation methods require infrastructure, which is very challenging in uncontrolled outdoor environments and within the limited turnover time (approximately 2 hours) on an airport tarmac. Additionally, many airlines and airports do not allow contact with the aircraft's surface or using UAVs for inspection between flights, and restrict access to commercial aircraft. Hence, this paper proposes an on-site method that is infrastructure-free and easy to deploy for estimating a pan-tilt-zoom camera's pose and localising scan images. This method initialises using the same pan-tilt-zoom camera used for the inspection task by utilising a Deep Convolutional Neural Network fine-tuned on only synthetic images to predict its own pose. We apply domain randomisation to generate the dataset for fine-tuning the network and modify its loss function by leveraging aircraft geometry to improve accuracy. We also propose a workflow for initialisation, scan path planning, and precise localisation of images captured from a pan-tilt-zoom camera. We evaluate and demonstrate our approach through experiments with real aircraft, achieving root-mean-square camera pose estimation errors of less than 0.24 m and 2 degrees for all real scenes.

</details>


### [579] [Asynchronous Distributed Multi-Robot Motion Planning Under Imperfect Communication](https://arxiv.org/abs/2511.18703)
*Ardalan Tajbakhsh,Augustinos Saravanos,James Zhu,Evangelos A. Theodorou,Lorenz T. Biegler,Aaron M. Johnson*

Main category: cs.RO

TL;DR: 提出了一种延迟感知的ADMM变体(DA-ADMM)，用于在多机器人系统中处理通信延迟问题，通过实时调整惩罚参数来提升运动规划的鲁棒性和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的分布式优化算法对通信延迟敏感，传统的惩罚参数调整方法（如残差平衡和自适应启发式）没有显式考虑延迟影响，导致多机器人协调性能下降。

Method: 开发了DA-ADMM算法，基于实时延迟统计调整惩罚参数，使智能体能够降低陈旧信息的权重，在共识和双重更新过程中优先处理最新信息。

Result: 在2D和3D环境中的大量仿真实验表明，DA-ADMM相比固定参数、残差平衡和固定约束基线方法，显著提高了鲁棒性、成功率和解的质量。

Conclusion: 性能下降不仅取决于延迟长度或频率，更取决于优化器对延迟信息的上下文推理能力。DA-ADMM在各种延迟条件下都能实现更好的协调性能，为不完美通信下的多机器人运动规划提供了原理性高效机制。

Abstract: This paper addresses the challenge of coordinating multi-robot systems under realistic communication delays using distributed optimization. We focus on consensus ADMM as a scalable framework for generating collision-free, dynamically feasible motion plans in both trajectory optimization and receding-horizon control settings. In practice, however, these algorithms are sensitive to penalty tuning or adaptation schemes (e.g. residual balancing and adaptive parameter heuristics) that do not explicitly consider delays. To address this, we introduce a Delay-Aware ADMM (DA-ADMM) variant that adapts penalty parameters based on real-time delay statistics, allowing agents to down-weight stale information and prioritize recent updates during consensus and dual updates. Through extensive simulations in 2D and 3D environments with double-integrator, Dubins-car, and drone dynamics, we show that DA-ADMM significantly improves robustness, success rate, and solution quality compared to fixed-parameter, residual-balancing, and fixed-constraint baselines. Our results highlight that performance degradation is not solely determined by delay length or frequency, but by the optimizer's ability to contextually reason over delayed information. The proposed DA-ADMM achieves consistently better coordination performance across a wide range of delay conditions, offering a principled and efficient mechanism for resilient multi-robot motion planning under imperfect communication.

</details>


### [580] [GVD-TG: Topological Graph based on Fast Hierarchical GVD Sampling for Robot Exploration](https://arxiv.org/abs/2511.18708)
*Yanbin Li,Canran Xiao,Shenghai Yuan,Peilai Yu,Ziruo Li,Zhiguo Zhang,Wenzheng Chi,Wei Zhang*

Main category: cs.RO

TL;DR: 提出了一种基于广义Voronoi图(GVD)的拓扑地图更新方法，通过多粒度分层GVD生成、节点聚类和连通性约束、基于形态学膨胀的前沿提取等技术，解决机器人探索任务中拓扑地图实时更新的挑战。


<details>
  <summary>Details</summary>
Motivation: 拓扑地图比度量地图更适合机器人探索任务，但实时更新准确且细节丰富的环境拓扑地图仍然是一个挑战。

Method: 1. 新观测区域去噪避免低效GVD节点误导拓扑结构；2. 设计多粒度分层GVD生成方法控制全局和局部采样粒度；3. 设计带连通性约束的节点聚类方法和基于切换机制的连通方法；4. 基于形态学膨胀的前沿提取方法确保前沿可达性；5. 使用轻量级成本函数实时评估切换下一个视点。

Result: 通过对比测试验证了系统在探索任务中的性能优于SOTA方法，提高了拓扑结构准确性、细节特征捕捉能力，减少了路径回溯概率，提升了探索效率。

Conclusion: 该方法能够有效解决拓扑地图实时更新问题，提高机器人探索的灵活性和效率，在探索任务中表现出优越性能。

Abstract: Topological maps are more suitable than metric maps for robotic exploration tasks. However, real-time updating of accurate and detail-rich environmental topological maps remains a challenge. This paper presents a topological map updating method based on the Generalized Voronoi Diagram (GVD). First, the newly observed areas are denoised to avoid low-efficiency GVD nodes misleading the topological structure. Subsequently, a multi-granularity hierarchical GVD generation method is designed to control the sampling granularity at both global and local levels. This not only ensures the accuracy of the topological structure but also enhances the ability to capture detail features, reduces the probability of path backtracking, and ensures no overlap between GVDs through the maintenance of a coverage map, thereby improving GVD utilization efficiency. Second, a node clustering method with connectivity constraints and a connectivity method based on a switching mechanism are designed to avoid the generation of unreachable nodes and erroneous nodes caused by obstacle attraction. A special cache structure is used to store all connectivity information, thereby improving exploration efficiency. Finally, to address the issue of frontiers misjudgment caused by obstacles within the scope of GVD units, a frontiers extraction method based on morphological dilation is designed to effectively ensure the reachability of frontiers. On this basis, a lightweight cost function is used to assess and switch to the next viewpoint in real time. This allows the robot to quickly adjust its strategy when signs of path backtracking appear, thereby escaping the predicament and increasing exploration flexibility. And the performance of system for exploration task is verified through comparative tests with SOTA methods.

</details>


### [581] [Autonomous Surface Selection For Manipulator-Based UV Disinfection In Hospitals Using Foundation Models](https://arxiv.org/abs/2511.18709)
*Xueyan Oh,Jonathan Her,Zhixiang Ong,Brandon Koh,Yun Hann Tan,U-Xuan Tan*

Main category: cs.RO

TL;DR: 提出了一种利用基础模型简化机械臂UV消毒表面选择的方法，减少人工干预且无需模型训练，通过VLM辅助分割细化提高目标表面识别准确率


<details>
  <summary>Details</summary>
Motivation: 传统UV消毒方法需要大量人工定义消毒区域，深度学习方案需要大量数据和微调，且缺乏对部分表面消毒的场景理解，可能导致意外UV暴露

Method: 利用基础模型简化机械臂UV消毒的表面选择，结合VLM辅助分割细化技术检测和排除细小非目标物体，减少误分割错误

Result: 目标和非目标表面正确分割成功率超过92%，机械臂和模拟UV光的真实实验验证了实际应用潜力

Conclusion: 该方法有效解决了UV消毒自动化中的表面选择问题，具有实际部署的可行性

Abstract: Ultraviolet (UV) germicidal radiation is an established non-contact method for surface disinfection in medical environments. Traditional approaches require substantial human intervention to define disinfection areas, complicating automation, while deep learning-based methods often need extensive fine-tuning and large datasets, which can be impractical for large-scale deployment. Additionally, these methods often do not address scene understanding for partial surface disinfection, which is crucial for avoiding unintended UV exposure. We propose a solution that leverages foundation models to simplify surface selection for manipulator-based UV disinfection, reducing human involvement and removing the need for model training. Additionally, we propose a VLM-assisted segmentation refinement to detect and exclude thin and small non-target objects, showing that this reduces mis-segmentation errors. Our approach achieves over 92\% success rate in correctly segmenting target and non-target surfaces, and real-world experiments with a manipulator and simulated UV light demonstrate its practical potential for real-world applications.

</details>


### [582] [Head Stabilization for Wheeled Bipedal Robots via Force-Estimation-Based Admittance Control](https://arxiv.org/abs/2511.18712)
*Tianyu Wang,Chunxiang Yan,Xuanhong Liao,Tao Zhang,Ping Wang,Cong Wen,Dingchuan Liu,Haowen Yu,Ximin Lyu*

Main category: cs.RO

TL;DR: 该论文提出了一种基于模型的地面力估计方法和导纳控制算法，用于解决轮式双足机器人头部在不平地形上的稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 轮式双足机器人作为野外探索的灵活平台，但头部在不平地形上的不稳定性会降低传感器精度或损坏有效载荷。现有研究主要关注平台稳定而忽视了头部在世界坐标系中的主动稳定。

Method: 开发了基于模型的地面力估计方法，并利用力估计实现了导纳控制算法来增强地形适应性。

Result: 仿真实验验证了力估计器的实时性能和机器人在不平地形上穿越的鲁棒性。

Conclusion: 该方法有效解决了轮式双足机器人头部稳定性问题，提升了机器人在复杂地形下的整体性能。

Abstract: Wheeled bipedal robots are emerging as flexible platforms for field exploration. However, head instability induced by uneven terrain can degrade the accuracy of onboard sensors or damage fragile payloads. Existing research primarily focuses on stabilizing the mobile platform but overlooks active stabilization of the head in the world frame, resulting in vertical oscillations that undermine overall stability. To address this challenge, we developed a model-based ground force estimation method for our 6-degree-of-freedom wheeled bipedal robot. Leveraging these force estimates, we implemented an admittance control algorithm to enhance terrain adaptability. Simulation experiments validated the real-time performance of the force estimator and the robot's robustness when traversing uneven terrain.

</details>


### [583] [AIRHILT: A Human-in-the-Loop Testbed for Multimodal Conflict Detection in Aviation](https://arxiv.org/abs/2511.18718)
*Omar Garib,Jayaprakash D. Kambhampaty,Olivia J. Pinon Fischer,Dimitri N. Mavris*

Main category: cs.RO

TL;DR: AIRHILT是一个基于Godot引擎的轻量级仿真环境，用于评估航空冲突检测中的多模态飞行员和空管辅助系统，支持人机交互和标准化接口。


<details>
  <summary>Details</summary>
Motivation: 为航空冲突检测研究提供一个统一、可扩展的平台，整合语音通信、视觉场景理解和ADS-B数据，支持多模态辅助系统的评估。

Method: 基于开源Godot引擎构建，同步飞行员与空管无线电通信、摄像头视觉场景理解和ADS-B监视数据，提供标准化JSON接口集成ASR、视觉检测、决策和TTS模型。

Result: 参考管道实现了平均首次警告时间约7.7秒，ASR和视觉延迟分别约为5.9秒和0.4秒，在跑道重叠场景中表现良好。

Conclusion: AIRHILT环境支持航空多模态情境感知和冲突检测的可重复研究，代码和场景已开源。

Abstract: We introduce AIRHILT (Aviation Integrated Reasoning, Human-in-the-Loop Testbed), a modular and lightweight simulation environment designed to evaluate multimodal pilot and air traffic control (ATC) assistance systems for aviation conflict detection. Built on the open-source Godot engine, AIRHILT synchronizes pilot and ATC radio communications, visual scene understanding from camera streams, and ADS-B surveillance data within a unified, scalable platform. The environment supports pilot- and controller-in-the-loop interactions, providing a comprehensive scenario suite covering both terminal area and en route operational conflicts, including communication errors and procedural mistakes. AIRHILT offers standardized JSON-based interfaces that enable researchers to easily integrate, swap, and evaluate automatic speech recognition (ASR), visual detection, decision-making, and text-to-speech (TTS) models. We demonstrate AIRHILT through a reference pipeline incorporating fine-tuned Whisper ASR, YOLO-based visual detection, ADS-B-based conflict logic, and GPT-OSS-20B structured reasoning, and present preliminary results from representative runway-overlap scenarios, where the assistant achieves an average time-to-first-warning of approximately 7.7 s, with average ASR and vision latencies of approximately 5.9 s and 0.4 s, respectively. The AIRHILT environment and scenario suite are openly available, supporting reproducible research on multimodal situational awareness and conflict detection in aviation; code and scenarios are available at https://github.com/ogarib3/airhilt.

</details>


### [584] [SP-VINS: A Hybrid Stereo Visual Inertial Navigation System based on Implicit Environmental Map](https://arxiv.org/abs/2511.18756)
*Xueyu Du,Lilian Zhang,Fuan Duan,Xincan Luo,Maosong Wang,Wenqi Wu,JunMao*

Main category: cs.RO

TL;DR: 提出了一种新型的基于滤波器的立体视觉惯性导航系统（SP-VINS），通过隐式环境地图实现高效闭环约束，结合混合残差滤波框架和在线外参标定，在保持计算效率的同时实现长期高精度定位。


<details>
  <summary>Details</summary>
Motivation: 传统基于滤波器的VINS系统在精度和效率之间取得了良好平衡，但其有限的地图质量限制了长期高精度状态估计的性能。

Method: 1. 提出基于滤波器的立体VINS系统，使用关键帧和2D关键点组成的隐式环境地图实现高效闭环约束；2. 设计混合残差滤波框架，结合地标重投影和射线约束构建统一的雅可比矩阵；3. 在退化环境中将相机-IMU外参参数融入视觉描述以实现在线标定。

Result: 基准测试表明，SP-VINS在保持高计算效率的同时实现了长期高精度定位性能，优于现有的最先进方法。

Conclusion: 该方法成功解决了滤波器VINS系统在长期运行中的精度保持问题，为移动机器人提供了高效可靠的导航解决方案。

Abstract: Filter-based visual inertial navigation system (VINS) has attracted mobile-robot researchers for the good balance between accuracy and efficiency, but its limited mapping quality hampers long-term high-accuracy state estimation. To this end, we first propose a novel filter-based stereo VINS, differing from traditional simultaneous localization and mapping (SLAM) systems based on 3D map, which performs efficient loop closure constraints with implicit environmental map composed of keyframes and 2D keypoints. Secondly, we proposed a hybrid residual filter framework that combines landmark reprojection and ray constraints to construct a unified Jacobian matrix for measurement updates. Finally, considering the degraded environment, we incorporated the camera-IMU extrinsic parameters into visual description to achieve online calibration. Benchmark experiments demonstrate that the proposed SP-VINS achieves high computational efficiency while maintaining long-term high-accuracy localization performance, and is superior to existing state-of-the-art (SOTA) methods.

</details>


### [585] [MergeVLA: Cross-Skill Model Merging Toward a Generalist Vision-Language-Action Agent](https://arxiv.org/abs/2511.18810)
*Yuxia Fu,Zhizhen Zhang,Yuqi Zhang,Zijian Wang,Zi Huang,Yadan Luo*

Main category: cs.RO

TL;DR: MergeVLA是一种面向合并的VLA架构，通过稀疏激活的LoRA适配器和仅交叉注意力机制，解决了多技能VLA模型合并时性能下降的问题，在多个数据集上达到或超过单独微调专家的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型在单一任务上表现良好，但在多技能设置下直接合并专家模型会导致性能急剧下降。这引发了一个基本问题：是什么阻止了VLA模型在一个模型中掌握多种技能？

Method: 通过经验分解VLA微调中的可学习参数，识别出两个主要的不可合并性来源：1）LoRA适配器向任务特定方向发散；2）动作专家通过自注意力反馈产生跨块依赖。MergeVLA引入稀疏激活的LoRA适配器和使用仅交叉注意力机制的动作专家，并设计了测试时任务路由器进行无监督任务推断。

Result: 在LIBERO、LIBERO-Plus、RoboTwin和真实SO101机械臂上的多任务实验中，MergeVLA达到或超过单独微调专家的性能，展示了跨任务、体现和环境的鲁棒泛化能力。

Conclusion: MergeVLA通过保持合并性的设计，成功解决了VLA模型在多技能设置中的合并挑战，为实现通用机器人学习提供了可行路径。

Abstract: Recent Vision-Language-Action (VLA) models reformulate vision-language models by tuning them with millions of robotic demonstrations. While they perform well when fine-tuned for a single embodiment or task family, extending them to multi-skill settings remains challenging: directly merging VLA experts trained on different tasks results in near-zero success rates. This raises a fundamental question: what prevents VLAs from mastering multiple skills within one model? With an empirical decomposition of learnable parameters during VLA fine-tuning, we identify two key sources of non-mergeability: (1) Finetuning drives LoRA adapters in the VLM backbone toward divergent, task-specific directions beyond the capacity of existing merging methods to unify. (2) Action experts develop inter-block dependencies through self-attention feedback, causing task information to spread across layers and preventing modular recombination. To address these challenges, we present MergeVLA, a merging-oriented VLA architecture that preserves mergeability by design. MergeVLA introduces sparsely activated LoRA adapters via task masks to retain consistent parameters and reduce irreconcilable conflicts in the VLM. Its action expert replaces self-attention with cross-attention-only blocks to keep specialization localized and composable. When the task is unknown, it uses a test-time task router to adaptively select the appropriate task mask and expert head from the initial observation, enabling unsupervised task inference. Across LIBERO, LIBERO-Plus, RoboTwin, and multi-task experiments on the real SO101 robotic arm, MergeVLA achieves performance comparable to or even exceeding individually finetuned experts, demonstrating robust generalization across tasks, embodiments, and environments.

</details>


### [586] [AutoOdom: Learning Auto-regressive Proprioceptive Odometry for Legged Locomotion](https://arxiv.org/abs/2511.18857)
*Changsheng Luo,Yushi Wang,Wenhan Cai,Mingguo Zhao*

Main category: cs.RO

TL;DR: AutoOdom是一个创新的自回归本体感知里程计系统，通过两阶段训练范式解决腿部机器人在GPS失效和视觉退化环境中的定位问题，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统里程计方法在GPS失效和视觉退化环境中存在严重局限性：分析方法受建模不确定性和累积漂移影响，混合学习方法受分析组件限制，纯学习方法面临仿真到现实迁移困难且需要大量真实数据。

Method: 提出两阶段训练范式：第一阶段使用大规模仿真数据学习腿部运动的复杂非线性动力学和快速变化的接触状态；第二阶段使用有限真实数据引入自回归增强机制，模型通过自身预测学习来提升对传感器噪声的鲁棒性。

Result: 在Booster T1人形机器人上的实验验证显示，相比Legolas基线，AutoOdom在绝对轨迹误差上提升57.2%，Umeyama对齐误差提升59.2%，相对位姿误差提升36.2%。消融研究揭示了IMU加速度数据的反直觉发现。

Conclusion: AutoOdom通过创新的自回归训练方法有效解决了仿真到现实的差距问题，为挑战性运动场景下的鲁棒本体感知里程计提供了系统设计解决方案。

Abstract: Accurate proprioceptive odometry is fundamental for legged robot navigation in GPS-denied and visually degraded environments where conventional visual odometry systems fail. Current approaches face critical limitations: analytical filtering methods suffer from modeling uncertainties and cumulative drift, hybrid learning-filtering approaches remain constrained by their analytical components, while pure learning-based methods struggle with simulation-to-reality transfer and demand extensive real-world data collection. This paper introduces AutoOdom, a novel autoregressive proprioceptive odometry system that overcomes these challenges through an innovative two-stage training paradigm. Stage 1 employs large-scale simulation data to learn complex nonlinear dynamics and rapidly changing contact states inherent in legged locomotion, while Stage 2 introduces an autoregressive enhancement mechanism using limited real-world data to effectively bridge the sim-to-real gap. The key innovation lies in our autoregressive training approach, where the model learns from its own predictions to develop resilience against sensor noise and improve robustness in highly dynamic environments. Comprehensive experimental validation on the Booster T1 humanoid robot demonstrates that AutoOdom significantly outperforms state-of-the-art methods across all evaluation metrics, achieving 57.2% improvement in absolute trajectory error, 59.2% improvement in Umeyama-aligned error, and 36.2% improvement in relative pose error compared to the Legolas baseline. Extensive ablation studies provide critical insights into sensor modality selection and temporal modeling, revealing counterintuitive findings about IMU acceleration data and validating our systematic design choices for robust proprioceptive odometry in challenging locomotion scenarios.

</details>


### [587] [Accelerating Reinforcement Learning via Error-Related Human Brain Signals](https://arxiv.org/abs/2511.18878)
*Suzie Kim,Hye-Bin Shin,Hyo-Jeong Jang*

Main category: cs.RO

TL;DR: 该研究探索了如何利用脑电图（EEG）隐含神经反馈来加速复杂机器人操作任务中的强化学习。


<details>
  <summary>Details</summary>
Motivation: 现有的EEG引导强化学习研究主要集中在导航或低维运动任务上，本研究旨在验证神经评估信号是否能在涉及障碍物和精确末端执行器控制的高维操作任务中改善策略学习。

Method: 将离线训练的EEG分类器解码的错误相关电位整合到奖励塑造中，系统评估人类反馈权重的影响，在7自由度机械臂的障碍物丰富环境中进行实验。

Result: 神经反馈加速了强化学习，根据反馈权重的不同，任务成功率有时超过稀疏奖励基线。最佳反馈权重在所有受试者中都能一致加速强化学习，且留一受试者验证表明框架对EEG解码能力的个体差异具有鲁棒性。

Conclusion: 基于EEG的强化学习可以扩展到运动任务之外，为人类对齐的操作技能获取提供了可行途径。

Abstract: In this work, we investigate how implicit neural feed back can accelerate reinforcement learning in complex robotic manipulation settings. While prior electroencephalogram (EEG) guided reinforcement learning studies have primarily focused on navigation or low-dimensional locomotion tasks, we aim to understand whether such neural evaluative signals can improve policy learning in high-dimensional manipulation tasks involving obstacles and precise end-effector control. We integrate error related potentials decoded from offline-trained EEG classifiers into reward shaping and systematically evaluate the impact of human-feedback weighting. Experiments on a 7-DoF manipulator in an obstacle-rich reaching environment show that neural feedback accelerates reinforcement learning and, depending on the human-feedback weighting, can yield task success rates that at times exceed those of sparse-reward baselines. Moreover, when applying the best-performing feedback weighting across all sub jects, we observe consistent acceleration of reinforcement learning relative to the sparse-reward setting. Furthermore, leave-one subject-out evaluations confirm that the proposed framework remains robust despite the intrinsic inter-individual variability in EEG decodability. Our findings demonstrate that EEG-based reinforcement learning can scale beyond locomotion tasks and provide a viable pathway for human-aligned manipulation skill acquisition.

</details>


### [588] [An Efficient Closed-Form Solution to Full Visual-Inertial State Initialization](https://arxiv.org/abs/2511.18910)
*Samuel Cerezo,Seong Hun Lee,Javier Civera*

Main category: cs.RO

TL;DR: 提出了一种无需非线性优化的视觉-惯性状态初始化方法，采用闭式解实现可靠启动，比优化方法误差降低10-20%，计算成本减少5倍


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖迭代求解器，存在数值不稳定和实现复杂的问题，需要开发解析解方法实现可靠且高效的初始化

Method: 基于小旋转和恒定速度假设，提出可观测性驱动的两阶段初始化方案，平衡精度与延迟，提供紧凑的解析解

Result: 在EuRoC数据集上验证，初始化误差比优化方法低10-20%，初始化窗口缩短4倍，计算成本降低5倍

Conclusion: 该方法提供了数值稳定、易于实现的解析解，在保持精度的同时显著提升了初始化效率和可靠性

Abstract: In this letter, we present a closed-form initialization method that recovers the full visual-inertial state without nonlinear optimization. Unlike previous approaches that rely on iterative solvers, our formulation yields analytical, easy-to-implement, and numerically stable solutions for reliable start-up. Our method builds on small-rotation and constant-velocity approximations, which keep the formulation compact while preserving the essential coupling between motion and inertial measurements. We further propose an observability-driven, two-stage initialization scheme that balances accuracy with initialization latency. Extensive experiments on the EuRoC dataset validate our assumptions: our method achieves 10-20% lower initialization error than optimization-based approaches, while using 4x shorter initialization windows and reducing computational cost by 5x.

</details>


### [589] [Compressor-VLA: Instruction-Guided Visual Token Compression for Efficient Robotic Manipulation](https://arxiv.org/abs/2511.18950)
*Juntao Gao,Feiyang Ye,Jing Zhang,Wenjing Qian*

Main category: cs.RO

TL;DR: 提出Compressor-VLA框架，通过指令调节的混合令牌压缩方法解决VLA模型中视觉令牌冗余问题，在保持任务性能的同时显著降低计算开销


<details>
  <summary>Details</summary>
Motivation: VLA模型在处理冗余视觉令牌时存在巨大计算开销，而传统任务无关的令牌剪枝方法难以保留任务关键信息，需要同时保持整体上下文和细粒度细节以实现精确动作

Method: 提出混合指令调节令牌压缩框架，包含语义任务压缩器（STC）提取整体任务相关上下文，空间细化压缩器（SRC）保留细粒度空间细节，压缩过程由自然语言指令动态调节

Result: 在LIBERO基准测试中达到竞争性成功率，同时FLOPs减少59%，视觉令牌数量减少3倍以上，真实机器人部署验证了模型的仿真到现实迁移能力和实用性

Conclusion: Compressor-VLA框架有效解决了VLA模型的视觉令牌冗余问题，通过指令引导动态调整感知焦点，实现了高效的任务导向视觉信息压缩

Abstract: Vision-Language-Action (VLA) models have emerged as a powerful paradigm in Embodied AI. However, the significant computational overhead of processing redundant visual tokens remains a critical bottleneck for real-time robotic deployment. While standard token pruning techniques can alleviate this, these task-agnostic methods struggle to preserve task-critical visual information. To address this challenge, simultaneously preserving both the holistic context and fine-grained details for precise action, we propose Compressor-VLA, a novel hybrid instruction-conditioned token compression framework designed for efficient, task-oriented compression of visual information in VLA models. The proposed Compressor-VLA framework consists of two token compression modules: a Semantic Task Compressor (STC) that distills holistic, task-relevant context, and a Spatial Refinement Compressor (SRC) that preserves fine-grained spatial details. This compression is dynamically modulated by the natural language instruction, allowing for the adaptive condensation of task-relevant visual information. Experimentally, extensive evaluations demonstrate that Compressor-VLA achieves a competitive success rate on the LIBERO benchmark while reducing FLOPs by 59% and the visual token count by over 3x compared to its baseline. The real-robot deployments on a dual-arm robot platform validate the model's sim-to-real transferability and practical applicability. Moreover, qualitative analyses reveal that our instruction guidance dynamically steers the model's perceptual focus toward task-relevant objects, thereby validating the effectiveness of our approach.

</details>


### [590] [End-to-end Autonomous Vehicle Following System using Monocular Fisheye Camera](https://arxiv.org/abs/2511.19011)
*Jiale Zhang,Yeqiang Qian,Tong Qin,Mingyang Jiang,Siyuan Chen,Ming Yang*

Main category: cs.RO

TL;DR: 提出了一种仅使用摄像头的车辆跟随框架，通过端到端方法和语义掩码解决多帧数据融合中的因果混淆问题，实现了从受限场景到通用场景的车辆编队应用。


<details>
  <summary>Details</summary>
Motivation: 车辆拥有量增加导致交通拥堵、事故增多和碳排放增加。现有编队系统依赖车道标记和昂贵的高精度传感器，限制了其通用性。

Method: 采用端到端方法，结合语义掩码处理多帧数据融合中的因果混淆，引入动态采样机制精确跟踪前车轨迹。

Result: 真实世界车辆实验验证了系统在各种场景下跟随车辆的能力，优于传统多阶段算法。

Conclusion: 该方法为低成本自动驾驶车辆编队提供了一个有前景的解决方案。

Abstract: The increase in vehicle ownership has led to increased traffic congestion, more accidents, and higher carbon emissions. Vehicle platooning is a promising solution to address these issues by improving road capacity and reducing fuel consumption. However, existing platooning systems face challenges such as reliance on lane markings and expensive high-precision sensors, which limits their general applicability. To address these issues, we propose a vehicle following framework that expands its capability from restricted scenarios to general scenario applications using only a camera. This is achieved through our newly proposed end-to-end method, which improves overall driving performance. The method incorporates a semantic mask to address causal confusion in multi-frame data fusion. Additionally, we introduce a dynamic sampling mechanism to precisely track the trajectories of preceding vehicles. Extensive closed-loop validation in real-world vehicle experiments demonstrates the system's ability to follow vehicles in various scenarios, outperforming traditional multi-stage algorithms. This makes it a promising solution for cost-effective autonomous vehicle platooning. A complete real-world vehicle experiment is available at https://youtu.be/zL1bcVb9kqQ.

</details>


### [591] [Multi-Agent Monocular Dense SLAM With 3D Reconstruction Priors](https://arxiv.org/abs/2511.19031)
*Haihang Wu,Yuchen Zhou*

Main category: cs.RO

TL;DR: 本文提出了首个多智能体单目稠密SLAM系统，通过引入3D重建先验和基于闭环的地图融合机制，在保持精度的同时提高了计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有单目SLAM系统虽然能生成详细的3D几何结构，但计算成本高且仅限于单智能体操作。MASt3R-SLAM虽然利用了学习到的3D重建先验来提高效率，但仍局限于单智能体。

Method: 扩展MASt3R-SLAM框架，每个智能体使用3D重建先验进行局部SLAM，通过基于闭环的地图融合机制将个体地图融合成全局一致的地图。

Result: 在真实世界数据集上的评估表明，该方法在保持相似建图精度的同时，相比最先进方法提高了计算效率。

Conclusion: 成功实现了首个多智能体单目稠密SLAM系统，验证了基于学习先验和地图融合方法的有效性。

Abstract: Monocular Simultaneous Localization and Mapping (SLAM) aims to estimate a robot's pose while simultaneously reconstructing an unknown 3D scene using a single camera. While existing monocular SLAM systems generate detailed 3D geometry through dense scene representations, they are computationally expensive due to the need for iterative optimization. To address this challenge, MASt3R-SLAM utilizes learned 3D reconstruction priors, enabling more efficient and accurate estimation of both 3D structures and camera poses. However, MASt3R-SLAM is limited to single-agent operation. In this paper, we extend MASt3R-SLAM to introduce the first multi-agent monocular dense SLAM system. Each agent performs local SLAM using a 3D reconstruction prior, and their individual maps are fused into a globally consistent map through a loop-closure-based map fusion mechanism. Our approach improves computational efficiency compared to state-of-the-art methods, while maintaining similar mapping accuracy when evaluated on real-world datasets.

</details>


### [592] [Analysis of Deep-Learning Methods in an ISO/TS 15066-Compliant Human-Robot Safety Framework](https://arxiv.org/abs/2511.19094)
*David Bricher,Andreas Mueller*

Main category: cs.RO

TL;DR: 提出基于深度学习的人机安全框架(HRSF)，通过动态调整机器人速度来提高协作效率，相比传统安全技术可减少15%的循环时间


<details>
  <summary>Details</summary>
Motivation: 当前符合ISO/TS-15066标准的人机协作实现由于保守的速度限制，限制了协作任务的效率

Method: 使用四种深度学习方法进行人体提取：人体识别、人体分割、人体姿态估计和人体部位分割，根据人机距离动态调整机器人速度

Result: 实验表明相比传统安全技术，循环时间最多可减少15%

Conclusion: HRSF框架能够区分人体部位与其他物体，实现优化的机器人流程执行，在保证安全的同时提高效率

Abstract: Over the last years collaborative robots have gained great success in manufacturing applications where human and robot work together in close proximity. However, current ISO/TS-15066-compliant implementations often limit the efficiency of collaborative tasks due to conservative speed restrictions. For this reason, this paper introduces a deep-learning-based human-robot-safety framework (HRSF) that aims at a dynamical adaptation of robot velocities depending on the separation distance between human and robot while respecting maximum biomechanical force and pressure limits. The applicability of the framework was investigated for four different deep learning approaches that can be used for human body extraction: human body recognition, human body segmentation, human pose estimation, and human body part segmentation. Unlike conventional industrial safety systems, the proposed HRSF differentiates individual human body parts from other objects, enabling optimized robot process execution. Experiments demonstrated a quantitative reduction in cycle time of up to 15% compared to conventional safety technology.

</details>


### [593] [Autonomous Docking of Multi-Rotor UAVs on Blimps under the Influence of Wind Gusts](https://arxiv.org/abs/2511.19135)
*Pascal Goldschmid,Aamir Ahmad*

Main category: cs.RO

TL;DR: 提出了一种多旋翼无人机在飞艇上自主对接的方法，通过时间卷积网络预测飞艇对风阵风的响应，结合模型预测控制器实现精确避障对接。


<details>
  <summary>Details</summary>
Motivation: 多旋翼无人机受电池限制飞行时间有限，而飞艇可以提供电池充电和数据传输，但飞艇易受风阵风影响导致轨迹偏差，需要精确的对接策略。

Method: 使用时间卷积网络预测飞艇对风阵风的响应，结合模型预测控制器计算无碰撞对接轨迹，并采用新颖的近距离避障方法。

Result: 仿真结果显示该方法显著优于基于恒定速度模型的基线方法，并在真实世界实验中验证了首个在飞艇上自主多旋翼对接控制策略。

Conclusion: 该方法成功解决了多旋翼无人机在飞艇上的自主对接问题，为延长无人机任务时间提供了可行方案。

Abstract: Multi-rotor UAVs face limited flight time due to battery constraints. Autonomous docking on blimps with onboard battery recharging and data offloading offers a promising solution for extended UAV missions. However, the vulnerability of blimps to wind gusts causes trajectory deviations, requiring precise, obstacle-aware docking strategies. To this end, this work introduces two key novelties: (i) a temporal convolutional network that predicts blimp responses to wind gusts, enabling rapid gust detection and estimation of points where the wind gust effect has subsided; (ii) a model predictive controller (MPC) that leverages these predictions to compute collision-free trajectories for docking, enabled by a novel obstacle avoidance method for close-range manoeuvres near the blimp. Simulation results show our method outperforms a baseline constant-velocity model of the blimp significantly across different scenarios. We further validate the approach in real-world experiments, demonstrating the first autonomous multi-rotor docking control strategy on blimps shown outside simulation. Source code is available here https://github.com/robot-perception-group/multi_rotor_airship_docking.

</details>


### [594] [Efficient Optimization of a Permanent Magnet Array for a Stable 2D Trap](https://arxiv.org/abs/2511.19201)
*Ann-Sophia Müller,Moonkwang Jeong,Jiyuan Tian,Meng Zhang,Tian Qiu*

Main category: cs.RO

TL;DR: 本文提出了一种基于永磁体阵列的2D磁力陷阱系统，用于在20-120mm范围内稳定操控医疗微型机器人，并通过GPU加速优化算法实现高效磁体角度优化。


<details>
  <summary>Details</summary>
Motivation: 解决在较大距离上对微型机器人施加高驱动力的问题，同时克服永磁体难以实现3D稳定磁阱的局限性。

Method: 开发新型GPU加速优化算法，使用均方误差和Adam优化器计算磁体阵列的最佳角度，并通过数值模拟和双磁体实验验证。

Result: 成功实现微型机器人的稳定捕获和复杂轨迹跟踪，算法具有高可扩展性（100个磁体优化时间小于3秒），并能适应不同力矢量场需求。

Conclusion: 该永磁体阵列系统为微创手术应用提供了有效的磁操控解决方案，优化算法展现出良好的实用性和适应性。

Abstract: Untethered magnetic manipulation of biomedical millirobots has a high potential for minimally invasive surgical applications. However, it is still challenging to exert high actuation forces on the small robots over a large distance. Permanent magnets offer stronger magnetic torques and forces than electromagnetic coils, however, feedback control is more difficult. As proven by Earnshaw's theorem, it is not possible to achieve a stable magnetic trap in 3D by static permanent magnets. Here, we report a stable 2D magnetic force trap by an array of permanent magnets to control a millirobot. The trap is located in an open space with a tunable distance to the magnet array in the range of 20 - 120mm, which is relevant to human anatomical scales. The design is achieved by a novel GPU-accelerated optimization algorithm that uses mean squared error (MSE) and Adam optimizer to efficiently compute the optimal angles for any number of magnets in the array. The algorithm is verified using numerical simulation and physical experiments with an array of two magnets. A millirobot is successfully trapped and controlled to follow a complex trajectory. The algorithm demonstrates high scalability by optimizing the angles for 100 magnets in under three seconds. Moreover, the optimization workflow can be adapted to optimize a permanent magnet array to achieve the desired force vector fields.

</details>


### [595] [Reference-Free Sampling-Based Model Predictive Control](https://arxiv.org/abs/2511.19204)
*Fabian Schramm,Pierre Fabre,Nicolas Perrin-Gilbert,Justin Carpentier*

Main category: cs.RO

TL;DR: 提出了一种基于采样的模型预测控制框架，无需手工设计的步态模式或预定义接触序列，即可实现自然涌现的机器人运动控制。


<details>
  <summary>Details</summary>
Motivation: 传统的机器人运动控制方法依赖手工设计的步态和接触序列，限制了运动的多样性和适应性。本文旨在通过优化高层目标自动发现多样的运动模式。

Method: 基于模型预测路径积分（MPPI）方法，提出双空间样条参数化技术，在位置和速度控制点上操作，实现自动适应任务需求的接触策略。

Result: 在Go2四足机器人上验证了多种涌现步态和基本跳跃能力，在仿真中展示了后空翻、动态倒立平衡等复杂行为，无需参考跟踪或离线预训练。

Conclusion: 该方法实现了实时CPU控制，无需GPU加速，能够自动发现多样运动模式，为机器人运动控制提供了新的有效途径。

Abstract: We present a sampling-based model predictive control (MPC) framework that enables emergent locomotion without relying on handcrafted gait patterns or predefined contact sequences. Our method discovers diverse motion patterns, ranging from trotting to galloping, robust standing policies, jumping, and handstand balancing, purely through the optimization of high-level objectives. Building on model predictive path integral (MPPI), we propose a dual-space spline parameterization that operates on position and velocity control points. Our approach enables contact-making and contact-breaking strategies that adapt automatically to task requirements, requiring only a limited number of sampled trajectories. This sample efficiency allows us to achieve real-time control on standard CPU hardware, eliminating the need for GPU acceleration typically required by other state-of-the-art MPPI methods. We validate our approach on the Go2 quadrupedal robot, demonstrating various emergent gaits and basic jumping capabilities. In simulation, we further showcase more complex behaviors, such as backflips, dynamic handstand balancing and locomotion on a Humanoid, all without requiring reference tracking or offline pre-training.

</details>


### [596] [Soft pneumatic grippers: Topology optimization, 3D-printing and experimental validation](https://arxiv.org/abs/2511.19211)
*Prabhat Kumar,Chandra Prakash,Josh Pinskier,David Howard,Matthijs Langelaar*

Main category: cs.RO

TL;DR: 提出了一种考虑设计依赖气动载荷的软体气动夹持器拓扑优化框架，通过优化2D软臂单元并扩展到3D模块，验证了优化设计的性能优势。


<details>
  <summary>Details</summary>
Motivation: 软体气动夹持器的设计需要充分考虑气动载荷的设计依赖性，传统方法难以有效处理这种复杂耦合关系。

Method: 使用Darcy定律建模气动载荷，采用稳健公式将2D软臂单元优化问题表述为最小-最大优化问题，结合MMA算法求解，并通过有限元分析和3D打印验证。

Result: 优化后的2D单元在气动载荷下性能优于传统矩形设计，组装的软体夹持器能够有效抓取不同重量、尺寸、刚度和形状的物体。

Conclusion: 所提出的拓扑优化框架能够有效设计高性能软体气动夹持器，为软体机器人设计提供了系统化的方法。

Abstract: This paper presents a systematic topology optimization framework for designing a soft pneumatic gripper (SPG), explicitly considering the design-dependent nature of the actuating load. The load is modeled using Darcy's law with an added drainage term. A 2D soft arm unit is optimized by formulating it as a compliant mechanism design problem using the robust formulation. The problem is posed as a min-max optimization, where the output deformations of blueprint and eroded designs are considered. A volume constraint is imposed on the blueprint part, while a strain-energy constraint is enforced on the eroded part. The MMA is employed to solve the optimization problem and obtain the optimized soft unit. Finite element analysis with the Ogden material model confirms that the optimized 2D unit outperforms a conventional rectangular design under pneumatic loading. The optimized 2D unit is extruded to obtain a 3D module, and ten such units are assembled to create a soft arm. Deformation profiles of the optimized arm are analysed under different pressure loads. Four arms are 3D-printed and integrated with a supporting structure to realize the proposed SPG. The gripping performance of the SPG is demonstrated on objects with different weights, sizes, stiffness, and shapes.

</details>


### [597] [SENTINEL: A Fully End-to-End Language-Action Model for Humanoid Whole Body Control](https://arxiv.org/abs/2511.19236)
*Yuxuan Wang,Haobin Jiang,Shiqing Yao,Ziluo Ding,Zongqing Lu*

Main category: cs.RO

TL;DR: SENTINEL是一个端到端的语言-动作模型，用于人形机器人全身控制，直接通过语言命令和本体感觉输入生成低级动作，无需中间表示。


<details>
  <summary>Details</summary>
Motivation: 现有的人形机器人控制系统要么依赖遥操作（完全由人类驱动），要么采用模块化生成管道（将语言理解与物理执行分离），缺乏语言命令与物理行为之间的紧密对齐。

Method: 通过使用预训练的全身控制器在仿真中追踪人类运动并结合文本注释构建大规模数据集；模型使用流匹配生成动作块，并通过残差动作头进行细化以支持真实世界部署。

Result: 模型在仿真和真实世界部署中表现出强大的语义理解和稳定执行能力，并支持通过将输入转换为文本来实现多模态扩展。

Conclusion: SENTINEL提供了一种端到端的解决方案，实现了语言命令与物理行为之间的直接映射，提升了人形机器人控制的语义对齐和执行效率。

Abstract: Existing humanoid control systems often rely on teleoperation or modular generation pipelines that separate language understanding from physical execution. However, the former is entirely human-driven, and the latter lacks tight alignment between language commands and physical behaviors. In this paper, we present SENTINEL, a fully end-to-end language-action model for humanoid whole-body control. We construct a large-scale dataset by tracking human motions in simulation using a pretrained whole body controller, combined with their text annotations. The model directly maps language commands and proprioceptive inputs to low-level actions without any intermediate representation. The model generates action chunks using flow matching, which can be subsequently refined by a residual action head for real-world deployment. Our method exhibits strong semantic understanding and stable execution on humanoid robots in both simulation and real-world deployment, and also supports multi-modal extensions by converting inputs into texts.

</details>


### [598] [Rethinking Intermediate Representation for VLM-based Robot Manipulation](https://arxiv.org/abs/2511.19315)
*Weiliang Tang,Jialin Gao,Jia-Hui Pan,Gang Wang,Li Erran Li,Yunhui Liu,Mingyu Ding,Pheng-Ann Heng,Chi-Wing Fu*

Main category: cs.RO

TL;DR: SEAM是一种基于上下文无关语法的语义组装表示方法，通过将中间表示分解为词汇和语法，实现了VLM友好且通用的机器人操作指令翻译。


<details>
  <summary>Details</summary>
Motivation: 解决视觉语言模型在机器人操作中翻译人类指令时面临的VLM可理解性与通用性之间的权衡问题。

Method: 设计语义组装表示SEAM，分解为语义丰富的操作词汇和VLM友好的语法；采用检索增强的少样本学习策略进行细粒度物体部件定位。

Result: SEAM在动作通用性和VLM可理解性方面优于主流表示方法，推理时间最短，在真实场景实验中表现出SOTA性能。

Conclusion: SEAM通过词汇-语法分解的方法有效平衡了VLM可理解性和任务通用性，为机器人操作提供了高效的中间表示方案。

Abstract: Vision-Language Model (VLM) is an important component to enable robust robot manipulation. Yet, using it to translate human instructions into an action-resolvable intermediate representation often needs a tradeoff between VLM-comprehensibility and generalizability. Inspired by context-free grammar, we design the Semantic Assembly representation named SEAM, by decomposing the intermediate representation into vocabulary and grammar. Doing so leads us to a concise vocabulary of semantically-rich operations and a VLM-friendly grammar for handling diverse unseen tasks. In addition, we design a new open-vocabulary segmentation paradigm with a retrieval-augmented few-shot learning strategy to localize fine-grained object parts for manipulation, effectively with the shortest inference time over all state-of-the-art parallel works. Also, we formulate new metrics for action-generalizability and VLM-comprehensibility, demonstrating the compelling performance of SEAM over mainstream representations on both aspects. Extensive real-world experiments further manifest its SOTA performance under varying settings and tasks.

</details>


### [599] [Deployment Dynamics and Optimization of Novel Space Antenna Deployable Mechanism](https://arxiv.org/abs/2511.19377)
*Mamoon Aamir,Mariyam Sattar,Naveed Ur Rehman Junejo,Aqsa Zafar Abbasi*

Main category: cs.RO

TL;DR: 提出了一种用于空间天线任务的新型三重剪刀可展开桁架机构（TSDTM），该机构在发射时收起，在轨道上高效展开，提供最大孔径尺寸同时占用最小发射体积。


<details>
  <summary>Details</summary>
Motivation: 随着空间任务对大型孔径天线需求的增加，将此类结构装入小型运载火箭的困难促使了可展开天线系统的设计。

Method: 涵盖从几何建模、使用螺旋理论和牛顿方法的运动学分析、通过特征值和仿真方法的动力学分析，到SolidWorks验证的完整设计过程。基于支持向量机优化材料选择，使用机器学习方法进行几何设置优化。

Result: 提出的TSDTM具有增强的结构动力学性能，仿真与解析预测结果吻合良好。优化结构精度高，机器学习预测与仿真自然频率偏差仅为1.94%。

Conclusion: 该研究展示了在空间结构设计中融入基于AI方法的潜力，为大型可展开空间天线提供了一种有效的解决方案。

Abstract: Given the increasing need for large aperture antennas in space missions, the difficulty of fitting such structures into small launch vehicles has prompted the design of deployable antenna systems. The thesis introduces a new Triple Scissors Deployable Truss Mechanism (TSDTM) for space antenna missions. The new mechanism is to be stowed during launch and efficiently deploy in orbit, offering maximum aperture size while taking up minimal launch volume. The thesis covers the entire design process from geometric modeling, kinematic analysis with screw theory and Newtonian approaches, dynamic analysis by eigenvalue and simulation methods, and verification with SolidWorks. In addition, optimization routines were coded based on Support Vector Machines for material choice in LEO environments and machine learning method for geometric setup. The TSDTM presented has enhanced structural dynamics with good comparison between simulation and analytical predictions. The structure optimized proved highly accurate, with a deviation of just 1.94% between machine learning-predicted and simulated natural frequencies, demonstrating the potential of incorporating AI-based methods in space structural design.

</details>


### [600] [Mixture of Horizons in Action Chunking](https://arxiv.org/abs/2511.19433)
*Dong Jing,Gang Wang,Jiaqi Liu,Weiliang Tang,Zelong Sun,Yunchao Yao,Zhenyu Wei,Yunhui Liu,Zhiwu Lu,Mingyu Ding*

Main category: cs.RO

TL;DR: 提出了一种混合视界（MoH）策略，通过并行处理不同长度的动作块来平衡长期规划与短期精度，在机器人操作任务中实现性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在机器人操作中对动作块长度（视界）敏感，存在长期规划与短期精度之间的权衡问题，固定单一视界选择不够优化。

Method: MoH将动作块分割为不同视界的多个片段，通过共享动作变换器并行处理，并用轻量线性门融合输出，实现动态自适应推理。

Result: 在多种策略（π₀、π₀.₅、π_reg）上的实验表明，MoH在仿真和真实任务中均取得显著提升，π₀.₅+MoH在LIBERO上达到99%平均成功率的新SOTA。

Conclusion: MoH策略有效解决了视界选择难题，具备即插即用、低开销、支持动态推理等优势，为VLA模型提供了更优的动作规划解决方案。

Abstract: Vision-language-action (VLA) models have shown remarkable capabilities in robotic manipulation, but their performance is sensitive to the $\textbf{action chunk length}$ used during training, termed $\textbf{horizon}$. Our empirical study reveals an inherent trade-off: longer horizons provide stronger global foresight but degrade fine-grained accuracy, while shorter ones sharpen local control yet struggle on long-term tasks, implying fixed choice of single horizons being suboptimal. To mitigate the trade-off, we propose a $\textbf{mixture of horizons (MoH)}$ strategy. MoH rearranges the action chunk into several segments with different horizons, processes them in parallel with a shared action transformer, and fuses outputs with a light linear gate. It has three appealing benefits. 1) MoH exploits long-term foresight and short-term precision jointly within a single model, improving both performance and generalizability to complex tasks. 2) MoH is plug-and-play for full-attention action modules with minimal training or inference overhead. 3) MoH enables dynamic inference with adaptive horizons, which selects stable actions through cross-horizon consensus, achieving 2.5$\times$ higher throughput than baselines while preserving superior performance. Extensive experiments over flow-based policies $π_0$, $π_{0.5}$, and one-step regression policy $π_{\text{reg}}$ demonstrate that MoH yields consistent and significant gains on both simulations and real-world tasks. Notably, under mixed-task setting, $π_{0.5}$ with MoH reaches a new state-of-the-art with 99$\%$ average success rate on LIBERO after only $30k$ training iterations. Project page: https://github.com/Timsty1/MixtureOfHorizons

</details>
