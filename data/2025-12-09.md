<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 225]
- [cs.RO](#cs.RO) [Total: 62]
- [cs.LG](#cs.LG) [Total: 145]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Video Models Start to Solve Chess, Maze, Sudoku, Mental Rotation, and Raven' Matrices](https://arxiv.org/abs/2512.05969)
*Hokin Deng*

Main category: cs.CV

TL;DR: 视频生成模型已具备推理能力，在棋类、迷宫、数独等任务上达到60%成功率，建立了基于"任务对"设计的实验范式，并开发了可扩展的评估框架。


<details>
  <summary>Details</summary>
Motivation: 探索视频生成模型是否具备推理能力，建立可扩展的评估体系来量化模型的推理性能。

Method: 采用"任务对"实验设计，构建包含39个模型的代码框架VMEvalKit，支持自动化评估并与人类判断强相关。

Result: Sora-2等领先模型在推理任务上达到60%成功率，验证了视频模型的推理能力。

Conclusion: 视频生成模型已展现出初步推理能力，该评估范式具有高度可扩展性，为后续强化学习改进推理能力提供了基础。

Abstract: We show that video generation models could reason now. Testing on tasks such as chess, maze, Sudoku, mental rotation, and Raven's Matrices, leading models such as Sora-2 achieve sixty percent success rates. We establish a robust experimental paradigm centered on the "Task Pair" design. We build a code framework, with 39 models available already, that supports this paradigm and allows for easy scaling - users can add models and tasks efficiently. We show our automated evaluation strongly correlates with human judgment, and therefore this paradigm is highly scalable. We see an opportunity, given the availability of our paradigm, to do reinforcement learning for improving reasoning in video models. You could checkout all of our raw $\href{https://grow-ai-like-a-child.com/video-reason/}{results}$ and our $\href{https://github.com/hokindeng/VMEvalKit}{VMEvalKit}$ codebase.

</details>


### [2] [Adaptive Dataset Quantization: A New Direction for Dataset Pruning](https://arxiv.org/abs/2512.05987)
*Chenyue Yu,Jianyu Yu*

Main category: cs.CV

TL;DR: 提出了一种新颖的数据集量化方法，通过减少样本内冗余来降低边缘设备中大规模数据集的存储和通信成本，在保持模型训练性能的同时实现显著的数据集压缩。


<details>
  <summary>Details</summary>
Motivation: 解决资源受限的边缘设备中大规模数据集的存储和通信成本挑战，传统的数据集剪枝和蒸馏方法主要关注样本间冗余，而本方法专注于减少样本内冗余。

Method: 采用线性对称量化获取每个样本的初始量化范围和尺度，然后引入自适应量化分配算法，为不同精度需求的样本分配不同的量化比例，同时保持恒定的总压缩比。

Result: 在CIFAR-10、CIFAR-100和ImageNet-1K上的大量实验验证了方法的有效性，在相同压缩比下优于传统量化和数据集剪枝基线方法。

Conclusion: 该方法首次使用有限位数表示数据集以实现存储缩减，提出的数据集级量化算法具有自适应比例分配能力，能够在保持模型性能的同时实现高效的数据集压缩。

Abstract: This paper addresses the challenges of storage and communication costs for large-scale datasets in resource-constrained edge devices by proposing a novel dataset quantization approach to reduce intra-sample redundancy. Unlike traditional dataset pruning and distillation methods that focus on inter-sample redundancy, the proposed method compresses each image by reducing redundant or less informative content within samples while preserving essential features. It first applies linear symmetric quantization to obtain an initial quantization range and scale for each sample. Then, an adaptive quantization allocation algorithm is introduced to distribute different quantization ratios for samples with varying precision requirements, maintaining a constant total compression ratio. The main contributions include: (1) being the first to use limited bits to represent datasets for storage reduction; (2) introducing a dataset-level quantization algorithm with adaptive ratio allocation; and (3) validating the method's effectiveness through extensive experiments on CIFAR-10, CIFAR-100, and ImageNet-1K. Results show that the method maintains model training performance while achieving significant dataset compression, outperforming traditional quantization and dataset pruning baselines under the same compression ratios.

</details>


### [3] [VG3T: Visual Geometry Grounded Gaussian Transformer](https://arxiv.org/abs/2512.05988)
*Junho Kim,Seongwon Lee*

Main category: cs.CV

TL;DR: VG3T提出了一种新颖的多视角前馈网络，通过3D高斯表示预测3D语义占据，解决了多视角融合的碎片化问题，在nuScenes基准测试中实现了1.7%的mIoU提升，同时减少了46%的基元数量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多视角融合方面存在困难，导致3D表示碎片化和性能不佳。需要一种能够统一表示几何和语义的多视角处理方法。

Method: VG3T采用多视角前馈网络直接预测一组具有语义属性的高斯分布，引入了基于网格的采样和位置细化两个关键组件来缓解距离相关的密度偏差。

Result: 在nuScenes基准测试中，VG3T相比之前的最优方法实现了1.7%的mIoU提升，同时使用的基元数量减少了46%。

Conclusion: VG3T提供了一种统一的多视角3D场景表示范式，在效率和性能方面都表现出色，为3D语义场景理解提供了更优的解决方案。

Abstract: Generating a coherent 3D scene representation from multi-view images is a fundamental yet challenging task. Existing methods often struggle with multi-view fusion, leading to fragmented 3D representations and sub-optimal performance. To address this, we introduce VG3T, a novel multi-view feed-forward network that predicts a 3D semantic occupancy via a 3D Gaussian representation. Unlike prior methods that infer Gaussians from single-view images, our model directly predicts a set of semantically attributed Gaussians in a joint, multi-view fashion. This novel approach overcomes the fragmentation and inconsistency inherent in view-by-view processing, offering a unified paradigm to represent both geometry and semantics. We also introduce two key components, Grid-Based Sampling and Positional Refinement, to mitigate the distance-dependent density bias common in pixel-aligned Gaussian initialization methods. Our VG3T shows a notable 1.7%p improvement in mIoU while using 46% fewer primitives than the previous state-of-the-art on the nuScenes benchmark, highlighting its superior efficiency and performance.

</details>


### [4] [EmoDiffTalk:Emotion-aware Diffusion for Editable 3D Gaussian Talking Head](https://arxiv.org/abs/2512.05991)
*Chang Liu,Tianjiao Jing,Chengcheng Ma,Xuanqi Zhou,Zhengxuan Lian,Qin Jin,Hongliang Yuan,Shi-Sheng Huang*

Main category: cs.CV

TL;DR: EmoDiffTalk是一个基于3D高斯泼溅的可编辑3D说话头部生成框架，通过情感感知高斯扩散和文本到动作单元（AU）的情感控制器，实现细粒度和多模态的情感编辑。


<details>
  <summary>Details</summary>
Motivation: 现有的基于3D高斯泼溅的逼真3D说话头部在情感表达操纵方面存在不足，尤其是在细粒度和多模态控制的动态情感编辑方面。

Method: 提出情感感知高斯扩散方法，包括动作单元（AU）提示的高斯扩散过程用于细粒度面部动画，以及准确的文本到AU情感控制器，支持文本输入的精确和动态情感编辑。

Result: 在EmoTalk3D和RenderMe-360数据集上的实验表明，EmoDiffTalk在情感细腻度、唇部同步保真度和可控性方面优于先前工作。

Conclusion: EmoDiffTalk是首批支持基于AU表达空间的连续多模态情感编辑的3D高斯泼溅说话头部生成框架之一，为高质量、扩散驱动的多模态可编辑3D说话头部合成提供了原则性路径。

Abstract: Recent photo-realistic 3D talking head via 3D Gaussian Splatting still has significant shortcoming in emotional expression manipulation, especially for fine-grained and expansive dynamics emotional editing using multi-modal control. This paper introduces a new editable 3D Gaussian talking head, i.e. EmoDiffTalk. Our key idea is a novel Emotion-aware Gaussian Diffusion, which includes an action unit (AU) prompt Gaussian diffusion process for fine-grained facial animator, and moreover an accurate text-to-AU emotion controller to provide accurate and expansive dynamic emotional editing using text input. Experiments on public EmoTalk3D and RenderMe-360 datasets demonstrate superior emotional subtlety, lip-sync fidelity, and controllability of our EmoDiffTalk over previous works, establishing a principled pathway toward high-quality, diffusion-driven, multimodal editable 3D talking-head synthesis. To our best knowledge, our EmoDiffTalk is one of the first few 3D Gaussian Splatting talking-head generation framework, especially supporting continuous, multimodal emotional editing within the AU-based expression space.

</details>


### [5] [Domain-Specific Foundation Model Improves AI-Based Analysis of Neuropathology](https://arxiv.org/abs/2512.05993)
*Ruchika Verma,Shrishtee Kandoi,Robina Afzal,Shengjia Chen,Jannes Jegminat,Michael W. Karlovich,Melissa Umphlett,Timothy E. Richardson,Kevin Clare,Quazi Hossain,Jorge Samanamud,Phyllis L. Faust,Elan D. Louis,Ann C. McKee,Thor D. Stein,Jonathan D. Cherry,Jesse Mez,Anya C. McGoldrick,Dalilah D. Quintana Mora,Melissa J. Nirenberg,Ruth H. Walker,Yolfrankcis Mendez,Susan Morgello,Dennis W. Dickson,Melissa E. Murray,Carlos Cordon-Cardo,Nadejda M. Tsankova,Jamie M. Walker,Diana K. Dangoor,Stephanie McQuillan,Emma L. Thorn,Claudia De Sanctis,Shuying Li,Thomas J. Fuchs,Kurt Farrell,John F. Crary,Gabriele Campanella*

Main category: cs.CV

TL;DR: 该论文开发了NeuroFM，一个专门针对神经病理学领域的病理基础模型，相比通用模型在神经退行性疾病分析任务上表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有病理基础模型主要基于外科病理数据训练，缺乏对神经病理学独特特征（如神经元、胶质细胞等）的捕捉能力，限制了在神经退行性疾病诊断中的应用。

Method: 开发NeuroFM基础模型，专门使用脑组织全玻片图像进行训练，涵盖多种神经退行性病理。

Result: NeuroFM在混合性痴呆分类、海马区域分割、神经退行性共济失调识别等任务上显著优于通用基础模型。

Conclusion: 领域专业化的基础模型能更好地捕捉神经病理学特异性特征，为数字病理学中的专业领域模型开发树立了先例。

Abstract: Foundation models have transformed computational pathology by providing generalizable representations from large-scale histology datasets. However, existing models are predominantly trained on surgical pathology data, which is enriched for non-nervous tissue and overrepresents neoplastic, inflammatory, metabolic, and other non-neurological diseases. Neuropathology represents a markedly different domain of histopathology, characterized by unique cell types (neurons, glia, etc.), distinct cytoarchitecture, and disease-specific pathological features including neurofibrillary tangles, amyloid plaques, Lewy bodies, and pattern-specific neurodegeneration. This domain mismatch may limit the ability of general-purpose foundation models to capture the morphological patterns critical for interpreting neurodegenerative diseases such as Alzheimer's disease, Parkinson's disease, and cerebellar ataxias. To address this gap, we developed NeuroFM, a foundation model trained specifically on whole-slide images of brain tissue spanning diverse neurodegenerative pathologies. NeuroFM demonstrates superior performance compared to general-purpose models across multiple neuropathology-specific downstream tasks, including mixed dementia disease classification, hippocampal region segmentation, and neurodegenerative ataxia identification encompassing cerebellar essential tremor and spinocerebellar ataxia subtypes. This work establishes that domain-specialized foundation models trained on brain tissue can better capture neuropathology-specific features than models trained on general surgical pathology datasets. By tailoring foundation models to the unique morphological landscape of neurodegenerative diseases, NeuroFM enables more accurate and reliable AI-based analysis for brain disease diagnosis and research, setting a precedent for domain-specific model development in specialized areas of digital pathology.

</details>


### [6] [FishDetector-R1: Unified MLLM-Based Framework with Reinforcement Fine-Tuning for Weakly Supervised Fish Detection, Segmentation, and Counting](https://arxiv.org/abs/2512.05996)
*Yi Liu,Jingyu Song,Vedanth Kallakuri,Katherine A. Skinner*

Main category: cs.CV

TL;DR: FishDetector-R1是一个基于MLLM的弱监督框架，用于水下鱼类检测、分割和计数，在DeepFish数据集上显著提升了性能指标


<details>
  <summary>Details</summary>
Motivation: 水下鱼类图像分析对生态监测至关重要，但面临视觉质量差和标注成本高的问题

Method: 结合新颖的detect-to-count提示和基于强化学习的可验证奖励机制(RLVR)，利用稀疏点标签进行弱监督学习

Result: 在DeepFish数据集上AP提升20%，mIoU提升10%，MAE降低30%，GAME降低35%，并在其他水下数据集上表现出良好的泛化能力

Conclusion: FishDetector-R1为弱监督下的准确海洋视觉理解提供了可靠且可扩展的解决方案

Abstract: Analyzing underwater fish imagery is critical for ecological monitoring but remains difficult due to visual degradation and costly annotations. We introduce FishDetector-R1, a unified MLLM-based framework for fish detection, segmentation, and counting under weak supervision. On the DeepFish dataset, our framework achieves substantial gains over baselines, improving AP by 20% and mIoU by 10%, while reducing MAE by 30% and GAME by 35%. These improvements stem from two key components: a novel detect-to-count prompt that enforces spatially consistent detections and counts, and Reinforcement Learning from Verifiable Reward (RLVR) with a complementary scalable paradigm leveraging sparse point labels. Ablation studies further validate the effectiveness of this reward design. Moreover, the improvement generalizes well to other underwater datasets, confirming strong cross-domain robustness. Overall, FishDetector-R1 provides a reliable and scalable solution for accurate marine visual understanding via weak supervision. The project page for FishDetector-R1 is https://umfieldrobotics.github.io/FishDetector-R1.

</details>


### [7] [PrunedCaps: A Case For Primary Capsules Discrimination](https://arxiv.org/abs/2512.06003)
*Ramin Sharifi,Pouya Shiri,Amirali Baniasadi*

Main category: cs.CV

TL;DR: 该论文研究了Capsule Networks中Primary Capsules的剪枝可能性，在多个数据集上验证了剪枝后的CapsNet性能，发现可以大幅提升速度并减少计算量而不损失精度。


<details>
  <summary>Details</summary>
Motivation: CapsNets虽然比CNNs具有更好的仿射变换鲁棒性和重叠图像检测能力，但由于Primary Capsules数量过多，导致训练和测试速度慢、资源消耗大，需要提高其资源效率。

Method: 在MNIST、Fashion-MNIST、CIFAR-10和SVHN数据集上对CapsNets进行Primary Capsules剪枝实验，移除95%的Capsules。

Result: 剪枝后的CapsNet比传统架构快9.90倍，动态路由阶段浮点运算减少95.36%以上，且精度没有损失。同时分析了不同数据集对剪枝效果的差异原因。

Conclusion: Primary Capsules剪枝是可行的优化方法，能显著提升CapsNets的效率，为资源受限环境下的应用提供了解决方案。

Abstract: Capsule Networks (CapsNets) are a generation of image classifiers with proven advantages over Convolutional Neural Networks (CNNs). Better robustness to affine transformation and overlapping image detection are some of the benefits associated with CapsNets. However, CapsNets cannot be classified as resource-efficient deep learning architecture due to the high number of Primary Capsules (PCs). In addition, CapsNets' training and testing are slow and resource hungry. This paper investigates the possibility of Primary Capsules pruning in CapsNets on MNIST handwritten digits, Fashion-MNIST, CIFAR-10, and SVHN datasets. We show that a pruned version of CapsNet performs up to 9.90 times faster than the conventional architecture by removing 95 percent of Capsules without a loss of accuracy. Also, our pruned architecture saves on more than 95.36 percent of floating-point operations in the dynamic routing stage of the architecture. Moreover, we provide insight into why some datasets benefit significantly from pruning while others fall behind.

</details>


### [8] [Simple Agents Outperform Experts in Biomedical Imaging Workflow Optimization](https://arxiv.org/abs/2512.06006)
*Xuefei,Wang,Kai A. Horstmann,Ethan Lin,Jonathan Chen,Alexander R. Farhang,Sophia Stiles,Atharva Sehgal,Jonathan Light,David Van Valen,Yisong Yue,Jennifer J. Sun*

Main category: cs.CV

TL;DR: 本文介绍了一个AI代理框架，用于自动化科学数据集中的计算机视觉工具适配，解决了传统方法需要大量标注数据或手动编码的问题。通过系统评估框架，证明简单代理设计能生成优于人类专家的适配代码。


<details>
  <summary>Details</summary>
Motivation: 解决生产级计算机视觉工具适配科学数据集的"最后一公里"瓶颈问题。传统方法如微调需要大量标注数据（科学家往往缺乏），而手动编码则需要数周至数月的努力。

Method: 引入系统评估框架研究AI代理在代码优化中的表现，评估了三种生产级生物医学成像流程。比较了不同复杂度的代理架构，发现简单代理框架效果最佳。

Result: 简单代理框架生成的适配代码持续优于人类专家解决方案。复杂代理架构并非普遍有益，为代理设计提供了实用路线图。

Conclusion: 开源了评估框架，并将代理生成的函数部署到生产流程中验证，展示了实际应用潜力。为科学计算中的AI代理设计提供了实用指导。

Abstract: Adapting production-level computer vision tools to bespoke scientific datasets is a critical "last mile" bottleneck. Current solutions are impractical: fine-tuning requires large annotated datasets scientists often lack, while manual code adaptation costs scientists weeks to months of effort. We consider using AI agents to automate this manual coding, and focus on the open question of optimal agent design for this targeted task. We introduce a systematic evaluation framework for agentic code optimization and use it to study three production-level biomedical imaging pipelines. We demonstrate that a simple agent framework consistently generates adaptation code that outperforms human-expert solutions. Our analysis reveals that common, complex agent architectures are not universally beneficial, leading to a practical roadmap for agent design. We open source our framework and validate our approach by deploying agent-generated functions into a production pipeline, demonstrating a clear pathway for real-world impact.

</details>


### [9] [Fast and Flexible Robustness Certificates for Semantic Segmentation](https://arxiv.org/abs/2512.06010)
*Thomas Massena,Corentin Friedrich,Franck Mamalet,Mathieu Serrurier*

Main category: cs.CV

TL;DR: 本文提出了一种新型可认证鲁棒的语义分割网络，通过内置Lipschitz约束实现高效训练，在Cityscapes等数据集上达到竞争性像素精度，认证速度比随机平滑方法快约600倍。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络对微小扰动敏感，现有鲁棒性研究主要集中在分类任务，语义分割的高效认证方法较少。

Method: 采用内置Lipschitz约束的语义分割网络，提供可泛化的鲁棒性认证框架，支持多种性能指标在ℓ2攻击下的最坏情况性能计算。

Result: 在NVIDIA A100 GPU上认证速度比随机平滑方法快600倍，在Cityscapes数据集上达到竞争性像素精度，最坏情况证书紧密度通过对抗攻击验证。

Conclusion: 该方法首次实现了实时兼容的可认证鲁棒语义分割，为语义分割任务提供了灵活且计算高效的鲁棒性认证方案。

Abstract: Deep Neural Networks are vulnerable to small perturbations that can drastically alter their predictions for perceptually unchanged inputs. The literature on adversarially robust Deep Learning attempts to either enhance the robustness of neural networks (e.g, via adversarial training) or to certify their decisions up to a given robustness level (e.g, by using randomized smoothing, formal methods or Lipschitz bounds). These studies mostly focus on classification tasks and few efficient certification procedures currently exist for semantic segmentation. In this work, we introduce a new class of certifiably robust Semantic Segmentation networks with built-in Lipschitz constraints that are efficiently trainable and achieve competitive pixel accuracy on challenging datasets such as Cityscapes. Additionally, we provide a novel framework that generalizes robustness certificates for semantic segmentation tasks, where we showcase the flexibility and computational efficiency of using Lipschitz networks. Our approach unlocks real-time compatible certifiably robust semantic segmentation for the first time. Moreover, it allows the computation of worst-case performance under $\ell_2$ attacks of radius $ε$ across a wide range of performance measures. Crucially, we benchmark the runtime of our certification process and find our approach to be around 600 times faster than randomized smoothing methods at inference with comparable certificates on an NVIDIA A100 GPU. Finally, we evaluate the tightness of our worstcase certificates against state-of-the-art adversarial attacks to further validate the performance of our method.

</details>


### [10] [High-Throughput Unsupervised Profiling of the Morphology of 316L Powder Particles for Use in Additive Manufacturing](https://arxiv.org/abs/2512.06012)
*Emmanuel Akeweje,Conall Kirk,Chi-Wai Chan,Denis Dowling,Mimi Zhang*

Main category: cs.CV

TL;DR: 提出了一个基于机器学习的自动化框架，用于大规模分析金属粉末形态，通过高分辨率成像和聚类算法评估粉末质量，为SLM工艺提供实时监测支持。


<details>
  <summary>Details</summary>
Motivation: 传统粉末表征方法效率低且定性，无法捕捉工业规模批次的异质性，需要开发高通量、自动化的形态分析工具来改善SLM工艺的粉末质量控制。

Method: 开发了三种聚类流程：自编码器流程、形状描述符流程和功能数据流程，基于约12.6万张粉末图像（直径0.5-102微米）进行形态分析，使用傅里叶描述符+k-means算法作为最优方案。

Result: 傅里叶描述符+k-means流程在内部有效性指标上表现最佳，达到最低的Davies-Bouldin指数和最高的Calinski-Harabasz分数，同时在标准桌面工作站上保持每颗粒亚毫秒级的运行时间。

Conclusion: 该无监督学习框架能够快速自动评估粉末形态，支持跟踪形状演变，为SLM工作流程中的实时原料监测提供了可行路径。

Abstract: Selective Laser Melting (SLM) is a powder-bed additive manufacturing technique whose part quality depends critically on feedstock morphology. However, conventional powder characterization methods are low-throughput and qualitative, failing to capture the heterogeneity of industrial-scale batches. We present an automated, machine learning framework that couples high-throughput imaging with shape extraction and clustering to profile metallic powder morphology at scale. We develop and evaluate three clustering pipelines: an autoencoder pipeline, a shape-descriptor pipeline, and a functional-data pipeline. Across a dataset of approximately 126,000 powder images (0.5-102 micrometer diameter), internal validity metrics identify the Fourier-descriptor + k-means pipeline as the most effective, achieving the lowest Davies-Bouldin index and highest Calinski-Harabasz score while maintaining sub-millisecond runtime per particle on a standard desktop workstation. Although the present work focuses on establishing the morphological-clustering framework, the resulting shape groups form a basis for future studies examining their relationship to flowability, packing density, and SLM part quality. Overall, this unsupervised learning framework enables rapid, automated assessment of powder morphology and supports tracking of shape evolution across reuse cycles, offering a path toward real-time feedstock monitoring in SLM workflows.

</details>


### [11] [VAT: Vision Action Transformer by Unlocking Full Representation of ViT](https://arxiv.org/abs/2512.06013)
*Wenhao Li,Chengwei Ma,Weixin Mao*

Main category: cs.CV

TL;DR: 提出了Vision Action Transformer (VAT)架构，通过利用ViT所有层的特征而不仅仅是最后一层，实现感知与动作生成的深度融合，在机器人模仿学习中达到98.15%的成功率。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅使用ViT最后一层的特征，丢弃了有价值的信息，导致表示不充分。需要充分利用ViT的完整特征层次结构。

Method: 基于ViT扩展的VAT架构，在所有transformer层中处理专门的动作令牌与视觉特征，实现感知与动作生成的渐进式深度融合。

Result: 在四个LIBERO基准测试中达到98.15%的平均成功率，超越OpenVLA-OFT等先前方法，建立新的最先进水平。

Conclusion: VAT不仅是一个强大的模仿学习模型，更证明了利用视觉模型完整"表示轨迹"对推进机器人策略的重要性。

Abstract: In robot learning, Vision Transformers (ViTs) are standard for visual perception, yet most methods discard valuable information by using only the final layer's features. We argue this provides an insufficient representation and propose the Vision Action Transformer (VAT), a novel architecture that is extended from ViT and unlocks the full feature hierarchy of ViT. VAT processes specialized action tokens with visual features across all transformer layers, enabling a deep and progressive fusion of perception and action generation. On a suite of simulated manipulation tasks, VAT achieves a 98.15\% average success rate across four LIBERO benchmarks, establishing a new state-of-the-art by outperforming prior methods like OpenVLA-OFT. Our work presents not only a powerful model for imitation learning but also demonstrates the critical importance of leveraging the complete ''representation trajectory'' of vision models to advance robotic policy. The GitHub URL for the project code is https://github.com/sellerbubble/VAT.

</details>


### [12] [Benchmarking CXR Foundation Models With Publicly Available MIMIC-CXR and NIH-CXR14 Datasets](https://arxiv.org/abs/2512.06014)
*Jiho Shin,Dominic Marshall,Matthieu Komorowski*

Main category: cs.CV

TL;DR: 本文对两种大规模胸片嵌入模型（CXR-Foundation和MedImagelnsight）在公共数据集上的性能进行了基准测试，发现MedImagelnsight在多数任务中表现略优，而CXR-Foundation具有更好的跨数据集稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有基础模型在医学图像表示学习方面表现出色，但其在不同数据集上的比较行为尚未得到充分探索，需要标准化评估方法。

Method: 使用统一的预处理流程和固定下游分类器，直接从预训练编码器提取嵌入，训练轻量级LightGBM分类器，报告平均AUROC和F1分数及95%置信区间。

Result: MedImagelnsight在大多数任务中性能略高，CXR-Foundation表现出更强的跨数据集稳定性；无监督聚类显示MedImagelnsight嵌入具有与定量结果一致的疾病特异性结构。

Conclusion: 结果强调了医学基础模型标准化评估的必要性，为未来多模态和临床整合研究建立了可复现的基线。

Abstract: Recent foundation models have demonstrated strong performance in medical image representation learning, yet their comparative behaviour across datasets remains underexplored. This work benchmarks two large-scale chest X-ray (CXR) embedding models (CXR-Foundation (ELIXR v2.0) and MedImagelnsight) on public MIMIC-CR and NIH ChestX-ray14 datasets. Each model was evaluated using a unified preprocessing pipeline and fixed downstream classifiers to ensure reproducible comparison. We extracted embeddings directly from pre-trained encoders, trained lightweight LightGBM classifiers on multiple disease labels, and reported mean AUROC, and F1-score with 95% confidence intervals. MedImageInsight achieved slightly higher performance across most tasks, while CXR-Foundation exhibited strong cross-dataset stability. Unsupervised clustering of MedImageIn-sight embeddings further revealed a coherent disease-specific structure consistent with quantitative results. The results highlight the need for standardised evaluation of medical foundation models and establish reproducible baselines for future multimodal and clinical integration studies.

</details>


### [13] [PrefGen: Multimodal Preference Learning for Preference-Conditioned Image Generation](https://arxiv.org/abs/2512.06020)
*Wenyi Mo,Tianyu Zhang,Yalong Bai,Ligong Han,Ying Ba,Dimitris N. Metaxas*

Main category: cs.CV

TL;DR: 本文提出了一种基于多模态大语言模型（MLLM）的个性化图像生成框架，通过提取用户偏好表征并注入到扩散模型中，实现同时满足文本提示和用户审美偏好的高质量图像生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法在捕捉用户细微审美偏好和编码个性化视觉信号方面存在不足，无法有效反映用户个人化的美学选择。

Method: 1. 使用偏好导向的视觉问答任务训练MLLM以捕获细粒度语义线索；2. 引入用户间区分和用户内区分两个互补的探测任务来分离偏好相关特征；3. 设计基于最大均值差异的对齐损失来弥合模态差异；4. 将学习到的嵌入用于条件化扩散生成器。

Result: 大量实验表明，该方法在图像质量和偏好对齐方面显著优于强基线方法，验证了表征提取和对齐策略在个性化生成中的有效性。

Conclusion: 该多模态框架通过有效的用户偏好表征学习和模态对齐，实现了对文本提示和用户偏好的忠实遵循，为个性化图像生成提供了新的解决方案。

Abstract: Preference-conditioned image generation seeks to adapt generative models to individual users, producing outputs that reflect personal aesthetic choices beyond the given textual prompt. Despite recent progress, existing approaches either fail to capture nuanced user preferences or lack effective mechanisms to encode personalized visual signals. In this work, we propose a multimodal framework that leverages multimodal large language models (MLLMs) to extract rich user representations and inject them into diffusion-based image generation. We train the MLLM with a preference-oriented visual question answering task to capture fine-grained semantic cues. To isolate preference-relevant features, we introduce two complementary probing tasks: inter-user discrimination to distinguish between different users, and intra-user discrimination to separate liked from disliked content. To ensure compatibility with diffusion text encoders, we design a maximum mean discrepancy-based alignment loss that bridges the modality gap while preserving multimodal structure. The resulting embeddings are used to condition the generator, enabling faithful adherence to both prompts and user preferences. Extensive experiments demonstrate that our method substantially outperforms strong baselines in both image quality and preference alignment, highlighting the effectiveness of representation extraction and alignment for personalized generation.

</details>


### [14] [Neural reconstruction of 3D ocean wave hydrodynamics from camera sensing](https://arxiv.org/abs/2512.06024)
*Jiabin Liu,Zihao Zhou,Jialei Yan,Anxin Guo,Alvise Benetazzo,Hui Li*

Main category: cs.CV

TL;DR: 提出一种基于注意力增强金字塔架构的波浪自由表面视觉重建神经网络，用于解决海洋波浪观测中密集视觉重建的高计算成本和视觉遮挡问题。


<details>
  <summary>Details</summary>
Motivation: 精确的三维波浪自由表面重建和相关速度场对于理解海洋物理至关重要，但传统方法在长期观测中面临高计算成本和持续视觉遮挡的挑战。

Method: 设计了一种注意力增强的金字塔架构神经网络，针对波浪运动的多尺度和时间连续性特征，利用物理约束从演化的自由表面边界进行时间分辨的三维速度场重建。

Result: 真实海况实验显示：中心区域毫米级波浪高程预测、主频误差低于0.01Hz、高频谱功率律精确估计、非线性速度场高保真三维重建，200万点密集重建仅需1.35秒。

Conclusion: 该模型基于立体视觉数据集，优于传统视觉重建方法，在遮挡条件下保持强泛化能力，得益于其全局多尺度注意力和学习到的波浪传播动力学编码。

Abstract: Precise three-dimensional (3D) reconstruction of wave free surfaces and associated velocity fields is essential for developing a comprehensive understanding of ocean physics. To address the high computational cost of dense visual reconstruction in long-term ocean wave observation tasks and the challenges introduced by persistent visual occlusions, we propose an wave free surface visual reconstruction neural network, which is designed as an attention-augmented pyramid architecture tailored to the multi-scale and temporally continuous characteristics of wave motions. Using physics-based constraints, we perform time-resolved reconstruction of nonlinear 3D velocity fields from the evolving free-surface boundary. Experiments under real-sea conditions demonstrate millimetre-level wave elevation prediction in the central region, dominant-frequency errors below 0.01 Hz, precise estimation of high-frequency spectral power laws, and high-fidelity 3D reconstruction of nonlinear velocity fields, while enabling dense reconstruction of two million points in only 1.35 s. Built on a stereo-vision dataset, the model outperforms conventional visual reconstruction approaches and maintains strong generalization in occluded conditions, owing to its global multi-scale attention and its learned encoding of wave propagation dynamics.

</details>


### [15] [The SAM2-to-SAM3 Gap in the Segment Anything Model Family: Why Prompt-Based Expertise Fails in Concept-Driven Image Segmentation](https://arxiv.org/abs/2512.06032)
*Ranjan Sapkota,Konstantinos I. Roumeliotis,Manoj Karkee*

Main category: cs.CV

TL;DR: 本文分析了SAM2和SAM3之间的根本性差异，指出SAM2基于空间提示的几何分割与SAM3基于多模态概念驱动的分割范式存在本质区别，SAM3代表了分割基础模型的新类别。


<details>
  <summary>Details</summary>
Motivation: 研究SAM2到SAM3的范式转变，解释为什么SAM2的提示分割专业知识无法迁移到SAM3的多模态概念驱动架构，阐明两者之间的根本性不连续性。

Method: 通过五个核心组件进行对比分析：概念差异、架构差异、数据集差异、训练差异和评估差异，系统性地比较两种模型的设计理念和技术实现。

Result: 确立了SAM3作为新一代分割基础模型的地位，展示了从几何分割到语义概念分割的范式转变，为概念驱动分割时代的发展指明了方向。

Conclusion: SAM3代表了分割技术的重要突破，引入了统一的多模态架构，开启了概念驱动分割的新时代，其与SAM2的根本差异要求重新思考分割模型的设计和评估方法。

Abstract: This paper investigates the fundamental discontinuity between the latest two Segment Anything Models: SAM2 and SAM3. We explain why the expertise in prompt-based segmentation of SAM2 does not transfer to the multimodal concept-driven paradigm of SAM3. SAM2 operates through spatial prompts points, boxes, and masks yielding purely geometric and temporal segmentation. In contrast, SAM3 introduces a unified vision-language architecture capable of open-vocabulary reasoning, semantic grounding, contrastive alignment, and exemplar-based concept understanding. We structure this analysis through five core components: (1) a Conceptual Break Between Prompt-Based and Concept-Based Segmentation, contrasting spatial prompt semantics of SAM2 with multimodal fusion and text-conditioned mask generation of SAM3; (2) Architectural Divergence, detailing pure vision-temporal design of SAM2 versus integration of vision-language encoders, geometry and exemplar encoders, fusion modules, DETR-style decoders, object queries, and ambiguity-handling via Mixture-of-Experts in SAM3; (3) Dataset and Annotation Differences, contrasting SA-V video masks with multimodal concept-annotated corpora of SAM3; (4) Training and Hyperparameter Distinctions, showing why SAM2 optimization knowledge does not apply to SAM3; and (5) Evaluation, Metrics, and Failure Modes, outlining the transition from geometric IoU metrics to semantic, open-vocabulary evaluation. Together, these analyses establish SAM3 as a new class of segmentation foundation model and chart future directions for the emerging concept-driven segmentation era.

</details>


### [16] [Representation Learning for Point Cloud Understanding](https://arxiv.org/abs/2512.06058)
*Siming Yan*

Main category: cs.CV

TL;DR: 该论文提出了一种通过整合预训练的2D模型来增强3D点云表示学习的方法，涵盖监督学习、自监督学习和从2D到3D的迁移学习，实验验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着3D数据采集技术的快速发展，3D数据在计算机视觉、机器人学等领域的应用日益广泛。将3D数据与2D图像结合可以为机器提供更全面的环境理解，但现有方法在3D表示学习方面仍有提升空间。

Method: 提出了一种整合预训练2D模型来支持3D网络训练的方法，包括监督表示学习（点云基元分割）、自监督学习方法以及从2D到3D的迁移学习，避免简单地将2D数据转换为3D。

Result: 大量实验验证了所提方法的有效性，表明通过有效整合2D知识可以显著提升3D理解能力，推动了点云表示学习的进步。

Conclusion: 该方法通过巧妙整合2D预训练模型，成功提升了3D点云表示学习的效果，为3D理解任务提供了新的解决方案，具有广泛的应用前景。

Abstract: With the rapid advancement of technology, 3D data acquisition and utilization have become increasingly prevalent across various fields, including computer vision, robotics, and geospatial analysis. 3D data, captured through methods such as 3D scanners, LiDARs, and RGB-D cameras, provides rich geometric, shape, and scale information. When combined with 2D images, 3D data offers machines a comprehensive understanding of their environment, benefiting applications like autonomous driving, robotics, remote sensing, and medical treatment. This dissertation focuses on three main areas: supervised representation learning for point cloud primitive segmentation, self-supervised learning methods, and transfer learning from 2D to 3D. Our approach, which integrates pre-trained 2D models to support 3D network training, significantly improves 3D understanding without merely transforming 2D data. Extensive experiments validate the effectiveness of our methods, showcasing their potential to advance point cloud representation learning by effectively integrating 2D knowledge.

</details>


### [17] [EgoEdit: Dataset, Real-Time Streaming Model, and Benchmark for Egocentric Video Editing](https://arxiv.org/abs/2512.06065)
*Runjia Li,Moayed Haji-Ali,Ashkan Mirzaei,Chaoyang Wang,Arpit Sahni,Ivan Skorokhodov,Aliaksandr Siarohin,Tomas Jakab,Junlin Han,Sergey Tulyakov,Philip Torr,Willi Menapace*

Main category: cs.CV

TL;DR: 本文提出了一个用于第一人称视角视频编辑的完整生态系统，包括专门构建的数据集EgoEditData、实时视频编辑器EgoEdit和评估套件EgoEditBench，解决了现有方法在第一人称视频编辑中的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有AI视频编辑器在第三人称视频上表现良好，但在第一人称视频上面临独特挑战，如快速的自体运动和频繁的手-物体交互，导致显著的领域差距。此外，现有的离线编辑流程存在高延迟问题，限制了实时交互。

Method: 1) 构建EgoEditData数据集，专门针对第一人称编辑场景设计，包含丰富的手-物体交互并明确保留手部信息；2) 开发EgoEdit视频编辑器，支持在单个GPU上进行实时流式推理；3) 引入EgoEditBench评估套件，评估指令忠实度、手部和交互保留以及自体运动下的时间稳定性。

Result: EgoEdit在第一人称和通用编辑任务上都产生了时间稳定、指令忠实的结果，具有交互式延迟。在第一人称编辑基准测试中取得了明显优势，同时在通用编辑任务上保持了与最强基线的可比性能。

Conclusion: 提出的生态系统有效解决了第一人称视频编辑的独特挑战，EgoEditData和EgoEditBench将为研究社区公开，促进该领域的发展。

Abstract: We study instruction-guided editing of egocentric videos for interactive AR applications. While recent AI video editors perform well on third-person footage, egocentric views present unique challenges - including rapid egomotion and frequent hand-object interactions - that create a significant domain gap. Moreover, existing offline editing pipelines suffer from high latency, limiting real-time interaction. To address these issues, we present a complete ecosystem for egocentric video editing. First, we construct EgoEditData, a carefully designed and manually curated dataset specifically designed for egocentric editing scenarios, featuring rich hand-object interactions, while explicitly preserving hands. Second, we develop EgoEdit, an instruction-following egocentric video editor that supports real-time streaming inference on a single GPU. Finally, we introduce EgoEditBench, an evaluation suite targeting instruction faithfulness, hand and interaction preservation, and temporal stability under egomotion. Across both egocentric and general editing tasks, EgoEdit produces temporally stable, instruction-faithful results with interactive latency. It achieves clear gains on egocentric editing benchmarks-where existing methods struggle-while maintaining performance comparable to the strongest baselines on general editing tasks. EgoEditData and EgoEditBench will be made public for the research community. See our website at https://snap-research.github.io/EgoEdit

</details>


### [18] [Shoot-Bounce-3D: Single-Shot Occlusion-Aware 3D from Lidar by Decomposing Two-Bounce Light](https://arxiv.org/abs/2512.06080)
*Tzofi Klinghoffer,Siddharth Somasundaram,Xiaoyu Xiang,Yuchen Fan,Christian Richardt,Akshat Dave,Ramesh Raskar,Rakesh Ranjan*

Main category: cs.CV

TL;DR: 本文提出了一种基于单光子激光雷达的数据驱动方法，通过分解多反射光来重建包含遮挡和镜面反射的3D场景。


<details>
  <summary>Details</summary>
Motivation: 单次测量重建3D场景存在挑战，特别是在存在遮挡区域和镜面材料（如镜子）的情况下。单光子激光雷达可以测量多次反射的光，这些光包含恢复密集深度、被遮挡几何形状和材料属性的额外信息。

Method: 创建了首个大规模室内场景激光雷达瞬态模拟数据集（约10万个样本），学习复杂光传输的先验知识，将测量的双反射光分解为每个激光点的贡献。

Result: 实验证明该方法可以从单次测量中推断出包含遮挡和镜子的场景的3D几何形状。

Conclusion: 该方法在具有挑战性的多场景点同时照明条件下，成功实现了对复杂光传输的逆推，为单光子激光雷达在3D场景重建中的应用提供了新思路。

Abstract: 3D scene reconstruction from a single measurement is challenging, especially in the presence of occluded regions and specular materials, such as mirrors. We address these challenges by leveraging single-photon lidars. These lidars estimate depth from light that is emitted into the scene and reflected directly back to the sensor. However, they can also measure light that bounces multiple times in the scene before reaching the sensor. This multi-bounce light contains additional information that can be used to recover dense depth, occluded geometry, and material properties. Prior work with single-photon lidar, however, has only demonstrated these use cases when a laser sequentially illuminates one scene point at a time. We instead focus on the more practical - and challenging - scenario of illuminating multiple scene points simultaneously. The complexity of light transport due to the combined effects of multiplexed illumination, two-bounce light, shadows, and specular reflections is challenging to invert analytically. Instead, we propose a data-driven method to invert light transport in single-photon lidar. To enable this approach, we create the first large-scale simulated dataset of ~100k lidar transients for indoor scenes. We use this dataset to learn a prior on complex light transport, enabling measured two-bounce light to be decomposed into the constituent contributions from each laser spot. Finally, we experimentally demonstrate how this decomposed light can be used to infer 3D geometry in scenes with occlusions and mirrors from a single measurement. Our code and dataset are released at https://shoot-bounce-3d.github.io.

</details>


### [19] [BeLLA: End-to-End Birds Eye View Large Language Assistant for Autonomous Driving](https://arxiv.org/abs/2512.06096)
*Karthik Mohan,Sonam Singh,Amit Arvind Kale*

Main category: cs.CV

TL;DR: BeLLA是一个端到端架构，将360°BEV表示与大型语言模型连接，用于自动驾驶问答，在空间推理任务上显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在自动驾驶中要么使用单视角编码器无法利用多摄像头空间结构，要么使用聚合多视角特征缺乏统一空间表示，难以进行空间推理

Method: 提出BeLLA架构，连接统一的360°BEV（鸟瞰图）表示与大型语言模型，实现端到端的自动驾驶问答

Result: 在NuScenes-QA和DriveLM基准测试中，BeLLA在需要空间推理的问题上表现优异，相对物体定位和行为理解任务获得最高+9.3%的绝对提升

Conclusion: BeLLA能够处理多样化问题，特别是在空间推理任务上具有显著优势，证明了统一BEV表示与语言模型结合的有效性

Abstract: The rapid development of Vision-Language models (VLMs) and Multimodal Language Models (MLLMs) in autonomous driving research has significantly reshaped the landscape by enabling richer scene understanding, context-aware reasoning, and more interpretable decision-making. However, a lot of existing work often relies on either single-view encoders that fail to exploit the spatial structure of multi-camera systems or operate on aggregated multi-view features, which lack a unified spatial representation, making it more challenging to reason about ego-centric directions, object relations, and the wider context. We thus present BeLLA, an end-to-end architecture that connects unified 360° BEV representations with a large language model for question answering in autonomous driving. We primarily evaluate our work using two benchmarks - NuScenes-QA and DriveLM, where BeLLA consistently outperforms existing approaches on questions that require greater spatial reasoning, such as those involving relative object positioning and behavioral understanding of nearby objects, achieving up to +9.3% absolute improvement in certain tasks. In other categories, BeLLA performs competitively, demonstrating the capability of handling a diverse range of questions.

</details>


### [20] [SpectraIrisPAD: Leveraging Vision Foundation Models for Spectrally Conditioned Multispectral Iris Presentation Attack Detection](https://arxiv.org/abs/2512.06103)
*Raghavendra Ramachandra,Sushma Venkatesh*

Main category: cs.CV

TL;DR: 该论文提出了SpectraIrisPAD框架，这是一个基于深度学习的多光谱虹膜呈现攻击检测方法，使用DINOv2 Vision Transformer和创新的光谱位置编码技术，在新建的MSIrPAD数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 随着虹膜识别在现实应用中的广泛部署，其面临呈现攻击的脆弱性问题日益突出。传统虹膜识别主要在近红外光谱下工作，而多光谱成像能提供互补的反射信息，增强PAD方法的泛化能力。

Method: 提出SpectraIrisPAD框架，采用DINOv2 Vision Transformer主干网络，配备可学习的光谱位置编码、令牌融合和对比学习技术，提取区分性强的波段特异性特征来区分真实样本和伪造攻击。

Result: 在新建的MSIrPAD数据集（包含18,848张虹膜图像，涵盖8种攻击类型）上进行实验，SpectraIrisPAD在所有性能指标上都显著优于多个最先进的基线方法。

Conclusion: SpectraIrisPAD框架在检测各种呈现攻击方面表现出卓越的鲁棒性和泛化能力，证明了多光谱成像和深度学习结合在虹膜PAD中的有效性。

Abstract: Iris recognition is widely recognized as one of the most accurate biometric modalities. However, its growing deployment in real-world applications raises significant concerns regarding its vulnerability to Presentation Attacks (PAs). Effective Presentation Attack Detection (PAD) is therefore critical to ensure the integrity and security of iris-based biometric systems. While conventional iris recognition systems predominantly operate in the near-infrared (NIR) spectrum, multispectral imaging across multiple NIR bands provides complementary reflectance information that can enhance the generalizability of PAD methods. In this work, we propose \textbf{SpectraIrisPAD}, a novel deep learning-based framework for robust multispectral iris PAD. The SpectraIrisPAD leverages a DINOv2 Vision Transformer (ViT) backbone equipped with learnable spectral positional encoding, token fusion, and contrastive learning to extract discriminative, band-specific features that effectively distinguish bona fide samples from various spoofing artifacts. Furthermore, we introduce a new comprehensive dataset Multispectral Iris PAD (\textbf{MSIrPAD}) with diverse PAIs, captured using a custom-designed multispectral iris sensor operating at five distinct NIR wavelengths (800\,nm, 830\,nm, 850\,nm, 870\,nm, and 980\,nm). The dataset includes 18,848 iris images encompassing eight diverse PAI categories, including five textured contact lenses, print attacks, and display-based attacks. We conduct comprehensive experiments under unseen attack evaluation protocols to assess the generalization capability of the proposed method. SpectraIrisPAD consistently outperforms several state-of-the-art baselines across all performance metrics, demonstrating superior robustness and generalizability in detecting a wide range of presentation attacks.

</details>


### [21] [Explainable Melanoma Diagnosis with Contrastive Learning and LLM-based Report Generation](https://arxiv.org/abs/2512.06105)
*Junwen Zheng,Xinran Xu,Li Rong Wang,Chang Cai,Lucinda Siyun Tan,Dingyuan Wang,Hong Liang Tey,Xiuyi Fan*

Main category: cs.CV

TL;DR: 本文提出了CEFM框架，通过对比学习将临床诊断标准（ABC规则）映射到视觉Transformer嵌入空间，生成结构化文本解释，解决黑色素瘤分类中模型可解释性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 深度学习在黑色素瘤分类中已达到专家水平，但模型不透明和缺乏可解释性阻碍了临床采用，医生难以信任黑盒模型的决策过程。

Method: 使用对比学习作为核心机制，通过双投影头将临床诊断标准（不对称性、边界、颜色）映射到ViT嵌入空间，将临床语义与视觉特征对齐，然后通过自然语言生成转换为结构化文本解释。

Result: 在公共数据集上达到92.79%的准确率和0.961的AUC，在多个可解释性指标上显著提升，学习到的嵌入空间布局与医生应用的ABC规则一致。

Conclusion: CEFM框架有效弥合了高性能分类与临床信任之间的差距，为临床皮肤病学提供了透明可靠的AI辅助诊断工具。

Abstract: Deep learning has demonstrated expert-level performance in melanoma classification, positioning it as a powerful tool in clinical dermatology. However, model opacity and the lack of interpretability remain critical barriers to clinical adoption, as clinicians often struggle to trust the decision-making processes of black-box models. To address this gap, we present a Cross-modal Explainable Framework for Melanoma (CEFM) that leverages contrastive learning as the core mechanism for achieving interpretability. Specifically, CEFM maps clinical criteria for melanoma diagnosis-namely Asymmetry, Border, and Color (ABC)-into the Vision Transformer embedding space using dual projection heads, thereby aligning clinical semantics with visual features. The aligned representations are subsequently translated into structured textual explanations via natural language generation, creating a transparent link between raw image data and clinical interpretation. Experiments on public datasets demonstrate 92.79% accuracy and an AUC of 0.961, along with significant improvements across multiple interpretability metrics. Qualitative analyses further show that the spatial arrangement of the learned embeddings aligns with clinicians' application of the ABC rule, effectively bridging the gap between high-performance classification and clinical trust.

</details>


### [22] [Tracking-Guided 4D Generation: Foundation-Tracker Motion Priors for 3D Model Animation](https://arxiv.org/abs/2512.06158)
*Su Sun,Cheng Zhao,Himangi Mittal,Gaurav Mittal,Rohith Kukkala,Yingjie Victor Chen,Mei Chen*

Main category: cs.CV

TL;DR: Track4DGen是一个两阶段框架，通过结合多视角视频扩散模型、基础点跟踪器和混合4D高斯泼溅重建器，解决了从稀疏输入生成动态4D对象的难题。该方法通过显式注入跟踪器导出的运动先验，在扩散生成和4D重建中增强时间一致性和跨视角连贯性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成动态4D对象时存在外观漂移和运动不一致的问题，主要源于仅依赖于像素或潜在空间的视频扩散损失监督，缺乏显式的时间感知特征级跟踪引导。

Method: Track4DGen采用两阶段方法：第一阶段在多视角视频扩散生成器中强制密集特征级点对应关系，生成时间一致的特征；第二阶段使用混合运动编码重建4D高斯泼溅，结合扩散特征和Hex-plane特征，并增强4D球谐函数以进行高保真动态建模。

Result: Track4DGen在多视角视频生成和4D生成基准测试中均优于基线方法，生成的时间稳定、可文本编辑的4D资源质量更高。

Conclusion: 该研究提出了一个有效的4D对象生成框架，通过显式运动先验注入解决了时间一致性问题，并贡献了高质量数据集Sketchfab28以推动未来研究。

Abstract: Generating dynamic 4D objects from sparse inputs is difficult because it demands joint preservation of appearance and motion coherence across views and time while suppressing artifacts and temporal drift. We hypothesize that the view discrepancy arises from supervision limited to pixel- or latent-space video-diffusion losses, which lack explicitly temporally aware, feature-level tracking guidance. We present \emph{Track4DGen}, a two-stage framework that couples a multi-view video diffusion model with a foundation point tracker and a hybrid 4D Gaussian Splatting (4D-GS) reconstructor. The central idea is to explicitly inject tracker-derived motion priors into intermediate feature representations for both multi-view video generation and 4D-GS. In Stage One, we enforce dense, feature-level point correspondences inside the diffusion generator, producing temporally consistent features that curb appearance drift and enhance cross-view coherence. In Stage Two, we reconstruct a dynamic 4D-GS using a hybrid motion encoding that concatenates co-located diffusion features (carrying Stage-One tracking priors) with Hex-plane features, and augment them with 4D Spherical Harmonics for higher-fidelity dynamics modeling. \emph{Track4DGen} surpasses baselines on both multi-view video generation and 4D generation benchmarks, yielding temporally stable, text-editable 4D assets. Lastly, we curate \emph{Sketchfab28}, a high-quality dataset for benchmarking object-centric 4D generation and fostering future research.

</details>


### [23] [Automated Annotation of Shearographic Measurements Enabling Weakly Supervised Defect Detection](https://arxiv.org/abs/2512.06171)
*Jessica Plassmann,Nicolas Schuler,Michael Schuth,Georg von Freymann*

Main category: cs.CV

TL;DR: 该论文提出了一种基于深度学习的自动化工作流程，用于从剪切散斑干涉测量数据中生成缺陷标注，解决了工业应用中缺乏高质量标注数据集的问题。


<details>
  <summary>Details</summary>
Motivation: 剪切散斑干涉测量技术虽然对表面位移梯度敏感，能够高灵敏度检测安全关键部件的亚表面缺陷，但工业应用面临的主要限制是缺乏高质量的标注数据集，因为手动标注劳动密集、主观性强且难以标准化。

Method: 引入自动化工作流程，利用深度学习从剪切散斑测量数据生成缺陷标注，产生高分辨率的分割和边界框标签。

Result: 与专家标注数据相比，该方法显示出足够的准确性，能够支持弱监督训练。

Conclusion: 该方法减少了手动工作量，支持可扩展的数据集创建，从而实现更稳健的缺陷检测。

Abstract: Shearography is an interferometric technique sensitive to surface displacement gradients, providing high sensitivity for detecting subsurface defects in safety-critical components. A key limitation to industrial adoption is the lack of high-quality annotated datasets, since manual labeling remains labor-intensive, subjective, and difficult to standardize. We introduce an automated workflow that generates defect annotations from shearography measurements using deep learning, producing high-resolution segmentation and bounding-box labels. Evaluation against expert-labeled data demonstrates sufficient accuracy to enable weakly supervised training, reducing manual effort and supporting scalable dataset creation for robust defect detection.

</details>


### [24] [Physics-Grounded Shadow Generation from Monocular 3D Geometry Priors and Approximate Light Direction](https://arxiv.org/abs/2512.06174)
*Shilin Hu,Jingyi Xu,Akshat Dave,Dimitris Samaras,Hieu Le*

Main category: cs.CV

TL;DR: 本文提出了一种将显式物理建模（几何和光照）嵌入到基于深度学习的阴影生成中的新框架，通过结合物理阴影形成原理和扩散模型，生成既真实又物理一致的阴影。


<details>
  <summary>Details</summary>
Motivation: 传统的基于深度学习的阴影生成方法很少使用显式的物理建模，而阴影形成的物理原理表明阴影应遵循遮挡物的轮廓。本文旨在将物理建模与深度学习相结合，提高阴影生成的准确性和真实性。

Method: 首先从单目RGB图像中获取密集点云形式的近似3D几何信息，并预测主导光照方向，基于阴影形成的物理原理恢复阴影的位置和形状。然后将这一基于物理的初始估计整合到扩散框架中，细化阴影的外观，确保与场景几何和光照的一致性。

Result: 在DESOBAV2数据集上训练后，该模型生成的阴影既视觉真实又物理一致，尤其在复杂几何或模糊光照场景中优于现有方法。

Conclusion: 通过将显式物理建模与深度学习相结合，本文提出的框架能够生成更准确和真实的阴影，特别是在挑战性场景中表现出色。

Abstract: Shadow generation aims to produce photorealistic shadows that are visually consistent with object geometry and scene illumination. In the physics of shadow formation, the occluder blocks some light rays casting from the light source that would otherwise arrive at the surface, creating a shadow that follows the silhouette of the occluder. However, such explicit physical modeling has rarely been used in deep-learning-based shadow generation. In this paper, we propose a novel framework that embeds explicit physical modeling - geometry and illumination - into deep-learning-based shadow generation. First, given a monocular RGB image, we obtain approximate 3D geometry in the form of dense point maps and predict a single dominant light direction. These signals allow us to recover fairly accurate shadow location and shape based on the physics of shadow formation. We then integrate this physics-based initial estimate into a diffusion framework that refines the shadow into a realistic, high-fidelity appearance while ensuring consistency with scene geometry and illumination. Trained on DESOBAV2, our model produces shadows that are both visually realistic and physically coherent, outperforming existing approaches, especially in scenes with complex geometry or ambiguous lighting.

</details>


### [25] [Physics-Grounded Attached Shadow Detection Using Approximate 3D Geometry and Light Direction](https://arxiv.org/abs/2512.06179)
*Shilin Hu,Jingyi Xu,Sagnik Das,Dimitris Samaras,Hieu Le*

Main category: cs.CV

TL;DR: 该论文提出了一个联合检测投射阴影和附着阴影的框架，通过推理阴影与场景光照和几何的相互关系来改进阴影检测。


<details>
  <summary>Details</summary>
Motivation: 现有阴影检测方法主要针对投射阴影，缺乏专门的数据集和模型来检测附着阴影，而附着阴影对于定义物体三维结构和增强场景理解至关重要。

Method: 系统包含阴影检测模块和光照估计模块，通过估计光照方向结合表面法线推导几何一致的部分地图，形成闭环推理过程迭代改进阴影分割和光照估计。

Result: 实验结果表明该方法显著改善了附着阴影的检测，BER减少至少33%，同时保持了良好的全阴影和投射阴影性能。

Conclusion: 该研究填补了附着阴影检测的空白，提出的几何-光照推理框架有效提升了阴影检测的准确性。

Abstract: Attached shadows occur on the surface of the occluder where light cannot reach because of self-occlusion. They are crucial for defining the three-dimensional structure of objects and enhancing scene understanding. Yet existing shadow detection methods mainly target cast shadows, and there are no dedicated datasets or models for detecting attached shadows. To address this gap, we introduce a framework that jointly detects cast and attached shadows by reasoning about their mutual relationship with scene illumination and geometry. Our system consists of a shadow detection module that predicts both shadow types separately, and a light estimation module that infers the light direction from the detected shadows. The estimated light direction, combined with surface normals, allows us to derive a geometry-consistent partial map that identifies regions likely to be self-occluded. This partial map is then fed back to refine shadow predictions, forming a closed-loop reasoning process that iteratively improves both shadow segmentation and light estimation. In order to train our method, we have constructed a dataset of 1,458 images with separate annotations for cast and attached shadows, enabling training and quantitative evaluation of both. Experimental results demonstrate that this iterative geometry-illumination reasoning substantially improves the detection of attached shadows, with at least 33% BER reduction, while maintaining strong full and cast shadow performance.

</details>


### [26] [SPOOF: Simple Pixel Operations for Out-of-Distribution Fooling](https://arxiv.org/abs/2512.06185)
*Ankit Gupta,Christoph Adami,Emily Dolson*

Main category: cs.CV

TL;DR: 本文重新验证了深度神经网络对非自然图像的过度自信问题，发现即使在现代架构中，高置信度的欺骗图像依然存在，其中ViT-B/16变换器模型最为脆弱。作者提出了SPOOF攻击方法，能以更少的计算成本生成高置信度欺骗图像，且重新训练仅能提供部分抵抗力。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在图像识别任务中表现出色，但对非自然图像仍存在过度自信的问题。本文旨在重新验证这一现象在现代架构中的持续性，并开发更高效的攻击方法来揭示深度分类器的脆弱性。

Method: 重新实现了基于CPPN和直接编码的进化欺骗攻击，并提出了SPOOF——一种简约、一致且更高效的黑盒攻击方法，通过最小像素修改生成高置信度欺骗图像。

Result: 实验证实高置信度欺骗在现代网络中持续存在，ViT-B/16变换器模型最为脆弱。SPOOF能以极少的查询次数生成无法识别的欺骗图像，且重新训练仅能部分抵抗攻击。

Conclusion: 现代深度分类器存在持续性脆弱，即使重新训练也难以完全抵抗高效的黑盒攻击，表明深度神经网络的安全性仍需进一步研究。

Abstract: Deep neural networks (DNNs) excel across image recognition tasks, yet continue to exhibit overconfidence on inputs that bear no resemblance to natural images. Revisiting the "fooling images" work introduced by Nguyen et al. (2015), we re-implement both CPPN-based and direct-encoding-based evolutionary fooling attacks on modern architectures, including convolutional and transformer classifiers. Our re-implementation confirm that high-confidence fooling persists even in state-of-the-art networks, with transformer-based ViT-B/16 emerging as the most susceptible--achieving near-certain misclassifications with substantially fewer queries than convolution-based models. We then introduce SPOOF, a minimalist, consistent, and more efficient black-box attack generating high-confidence fooling images. Despite its simplicity, SPOOF generates unrecognizable fooling images with minimal pixel modifications and drastically reduced compute. Furthermore, retraining with fooling images as an additional class provides only partial resistance, as SPOOF continues to fool consistently with slightly higher query budgets--highlighting persistent fragility of modern deep classifiers.

</details>


### [27] [Multi-Modal Zero-Shot Prediction of Color Trajectories in Food Drying](https://arxiv.org/abs/2512.06190)
*Shichen Li,Ahmadreza Eslaminia,Chenhui Shao*

Main category: cs.CV

TL;DR: 提出了一种新颖的多模态颜色轨迹预测方法，将高维时间颜色信息与干燥过程参数结合，实现准确且数据高效的颜色轨迹预测


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖低维颜色特征，无法完全捕捉食品样本复杂的动态颜色轨迹，且缺乏对未见过程条件的泛化能力

Method: 开发多模态颜色轨迹预测方法，整合高维时间颜色信息和干燥过程参数

Result: 在未见干燥条件下，模型在饼干干燥中达到RMSE 2.12，苹果干燥中达到RMSE 1.29，相比基线模型误差减少超过90%

Conclusion: 实验结果表明该模型具有优越的准确性、鲁棒性和广泛的适用性

Abstract: Food drying is widely used to reduce moisture content, ensure safety, and extend shelf life. Color evolution of food samples is an important indicator of product quality in food drying. Although existing studies have examined color changes under different drying conditions, current approaches primarily rely on low-dimensional color features and cannot fully capture the complex, dynamic color trajectories of food samples. Moreover, existing modeling approaches lack the ability to generalize to unseen process conditions. To address these limitations, we develop a novel multi-modal color-trajectory prediction method that integrates high-dimensional temporal color information with drying process parameters to enable accurate and data-efficient color trajectory prediction. Under unseen drying conditions, the model attains RMSEs of 2.12 for cookie drying and 1.29 for apple drying, reducing errors by over 90% compared with baseline models. These experimental results demonstrate the model's superior accuracy, robustness, and broad applicability.

</details>


### [28] [The MICCAI Federated Tumor Segmentation (FeTS) Challenge 2024: Efficient and Robust Aggregation Methods for Federated Learning](https://arxiv.org/abs/2512.06206)
*Akis Linardos,Sarthak Pati,Ujjwal Baid,Brandon Edwards,Patrick Foley,Kevin Ta,Verena Chung,Micah Sheller,Muhammad Irfan Khan,Mojtaba Jafaritadi,Elina Kontio,Suleiman Khan,Leon Mächler,Ivan Ezhov,Suprosanna Shit,Johannes C. Paetzold,Gustav Grimberg,Manuel A. Nickel,David Naccache,Vasilis Siomos,Jonathan Passerat-Palmbach,Giacomo Tarroni,Daewoon Kim,Leonard L. Klausmann,Prashant Shah,Bjoern Menze,Dimitrios Makris,Spyridon Bakas*

Main category: cs.CV

TL;DR: MICCAI FeTS 2024挑战赛聚焦于联邦学习在胶质瘤亚区分割中的应用，评估了新的权重聚合方法，PID控制器方法在分割性能和通信效率方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 推动联邦学习在医学影像中的应用，特别是针对多中心胶质瘤分割任务，提高模型的鲁棒性和效率，解决数据隐私保护下的协作学习问题。

Method: 使用标准化联邦学习设置和多机构数据集（BraTS基准），包括1251个训练案例、219个验证案例和570个隐藏测试案例。采用累积评分系统评估分割性能（DSC和HD95）和通信效率（收敛分数）。

Result: PID控制器方法获得最高排名，ET、TC、WT的DSC均值分别为0.733、0.761、0.751，HD95值分别为33.922mm、33.623mm、32.309mm，收敛分数为0.764，超越了以往挑战赛的最佳方法。

Conclusion: PID控制器作为有效的权重聚合机制，能够稳定和优化联邦学习过程，推动了医学影像联邦学习的发展，相关代码已开源。

Abstract: We present the design and results of the MICCAI Federated Tumor Segmentation (FeTS) Challenge 2024, which focuses on federated learning (FL) for glioma sub-region segmentation in multi-parametric MRI and evaluates new weight aggregation methods aimed at improving robustness and efficiency. Six participating teams were evaluated using a standardized FL setup and a multi-institutional dataset derived from the BraTS glioma benchmark, consisting of 1,251 training cases, 219 validation cases, and 570 hidden test cases with segmentations for enhancing tumor (ET), tumor core (TC), and whole tumor (WT). Teams were ranked using a cumulative scoring system that considered both segmentation performance, measured by Dice Similarity Coefficient (DSC) and the 95th percentile Hausdorff Distance (HD95), and communication efficiency assessed through the convergence score. A PID-controller-based method achieved the top overall ranking, obtaining mean DSC values of 0.733, 0.761, and 0.751 for ET, TC, and WT, respectively, with corresponding HD95 values of 33.922 mm, 33.623 mm, and 32.309 mm, while also demonstrating the highest communication efficiency with a convergence score of 0.764. These findings advance the state of federated learning for medical imaging, surpassing top-performing methods from previous challenge iterations and highlighting PID controllers as effective mechanisms for stabilizing and optimizing weight aggregation in FL. The challenge code is available at https://github.com/FeTS-AI/Challenge.

</details>


### [29] [Revisiting SVD and Wavelet Difference Reduction for Lossy Image Compression: A Reproducibility Study](https://arxiv.org/abs/2512.06221)
*Alena Makarova*

Main category: cs.CV

TL;DR: 本工作对结合SVD和WDR的损失图像压缩技术进行了独立可复现性研究，发现该方法在PSNR指标上并未超越JPEG2000或WDR，仅在SSIM指标上部分优于JPEG2000，与原文声称的结果存在差异。


<details>
  <summary>Details</summary>
Motivation: 验证原文声称的SVD+WDR组合方法在视觉质量和压缩比方面优于JPEG2000和单独WDR的结论是否可复现。

Method: 重新实现原文提出的SVD+WDR方法，填补了量化、阈值初始化等缺失的实现细节，使用PSNR和SSIM指标进行性能评估。

Result: 实验结果与原文结论相反：SVD+WDR在PSNR指标上普遍不如JPEG2000或WDR，仅在SSIM指标上部分优于JPEG2000。

Conclusion: 原文描述存在模糊之处，这些实现细节的缺失会显著影响可复现性和报告的性能结果。

Abstract: This work presents an independent reproducibility study of a lossy image compression technique that integrates singular value decomposition (SVD) and wavelet difference reduction (WDR). The original paper claims that combining SVD and WDR yields better visual quality and higher compression ratios than JPEG2000 and standalone WDR. I re-implemented the proposed method, carefully examined missing implementation details, and replicated the original experiments as closely as possible. I then conducted additional experiments on new images and evaluated performance using PSNR and SSIM. In contrast to the original claims, my results indicate that the SVD+WDR technique generally does not surpass JPEG2000 or WDR in terms of PSNR, and only partially improves SSIM relative to JPEG2000. The study highlights ambiguities in the original description (e.g., quantization and threshold initialization) and illustrates how such gaps can significantly impact reproducibility and reported performance.

</details>


### [30] [GPU-GLMB: Assessing the Scalability of GPU-Accelerated Multi-Hypothesis Tracking](https://arxiv.org/abs/2512.06230)
*Pranav Balakrishnan,Sidisha Barik,Sean M. O'Rourke,Benjamin M. Marlin*

Main category: cs.CV

TL;DR: 本文提出了一种改进的GLMB滤波器，允许同一传感器对同一目标产生多个检测，从而打破滤波器更新中的检测间依赖关系，显著提高并行可扩展性并实现GPU硬件上的高效部署。


<details>
  <summary>Details</summary>
Motivation: 标准GLMB滤波器在多目标跟踪中虽然具有理论优势，但在标准测量模型下维护多个假设的计算成本极高。特别是在分布式机器学习虚拟传感器网络中，需要能够处理同一目标多次检测的能力。

Method: 研究GLMB滤波器的变体，允许同一传感器对同一目标产生多个检测。这种方法打破了滤波器更新中的检测间依赖关系，使得更新过程具有更好的并行可扩展性。

Result: 初步分析显示，GPU加速实现的GLMB跟踪器在运行时间方面具有良好的可扩展性，特别是在目标数量和保留假设数量方面。

Conclusion: 所提出的GLMB滤波器变体通过允许多次检测，显著提高了计算效率，为在GPU硬件上部署多目标跟踪系统提供了可行的解决方案。

Abstract: Much recent research on multi-target tracking has focused on multi-hypothesis approaches leveraging random finite sets. Of particular interest are labeled random finite set methods that maintain temporally coherent labels for each object. While these methods enjoy important theoretical properties as closed-form solutions to the multi-target Bayes filter, the maintenance of multiple hypotheses under the standard measurement model is highly computationally expensive, even when hypothesis pruning approximations are applied. In this work, we focus on the Generalized Labeled Multi-Bernoulli (GLMB) filter as an example of this class of methods. We investigate a variant of the filter that allows multiple detections per object from the same sensor, a critical capability when deploying tracking in the context of distributed networks of machine learning-based virtual sensors. We show that this breaks the inter-detection dependencies in the filter updates of the standard GLMB filter, allowing updates with significantly improved parallel scalability and enabling efficient deployment on GPU hardware. We report the results of a preliminary analysis of a GPU-accelerated implementation of our proposed GLMB tracker, with a focus on run time scalability with respect to the number of objects and the maximum number of retained hypotheses.

</details>


### [31] [Opinion: Learning Intuitive Physics May Require More than Visual Data](https://arxiv.org/abs/2512.06232)
*Ellen Su,Solim Legris,Todd M. Gureckis,Mengye Ren*

Main category: cs.CV

TL;DR: 该研究通过使用发展现实主义的儿童视角视频数据集（SAYCam）训练V-JEPA模型，发现仅靠数据分布的变化（即使数据量仅为SOTA模型的0.01%）无法显著提升直觉物理推理能力，表明当前架构需要更根本的改进。


<details>
  <summary>Details</summary>
Motivation: 探索数据分布（而非数据量）是否是学习直觉物理原理的关键，通过使用发展现实主义的儿童视角视频来验证这一假设。

Method: 使用SAYCam数据集（三个儿童的日常视觉体验）预训练Video Joint Embedding Predictive Architecture (V-JEPA)模型，并在IntPhys2基准上进行测试。

Result: 训练结果未在IntPhys2基准上显示出显著性能提升，表明仅使用发展现实主义数据集不足以让当前架构学习支持直觉物理的表征。

Conclusion: 仅改变视觉数据的量和分布可能不足以构建具有人工直觉物理能力的系统，需要更根本的架构改进。

Abstract: Humans expertly navigate the world by building rich internal models founded on an intuitive understanding of physics. Meanwhile, despite training on vast quantities of internet video data, state-of-the-art deep learning models still fall short of human-level performance on intuitive physics benchmarks. This work investigates whether data distribution, rather than volume, is the key to learning these principles. We pretrain a Video Joint Embedding Predictive Architecture (V-JEPA) model on SAYCam, a developmentally realistic, egocentric video dataset partially capturing three children's everyday visual experiences. We find that training on this dataset, which represents 0.01% of the data volume used to train SOTA models, does not lead to significant performance improvements on the IntPhys2 benchmark. Our results suggest that merely training on a developmentally realistic dataset is insufficient for current architectures to learn representations that support intuitive physics. We conclude that varying visual data volume and distribution alone may not be sufficient for building systems with artificial intuitive physics.

</details>


### [32] [NexusFlow: Unifying Disparate Tasks under Partial Supervision via Invertible Flow Networks](https://arxiv.org/abs/2512.06251)
*Fangzhou Lin,Yuping Wang,Yuliang Guo,Zixun Huang,Xinyu Huang,Haichong Zhang,Kazunori Yamada,Zhengzhong Tu,Liu Ren,Ziming Zhang*

Main category: cs.CV

TL;DR: NexusFlow是一个新颖的轻量级框架，用于解决异构任务下的部分监督多任务学习问题，通过可逆耦合层对齐任务特征分布，在自动驾驶和室内场景任务中均取得优异表现。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注同构密集预测任务，而忽略了结构多样化任务的学习挑战。现实场景中任务往往具有结构差异和标注不完整的问题。

Method: 引入带有可逆耦合层的代理网络来对齐任务潜在特征分布，创建统一表示空间，实现跨任务知识迁移。可逆性避免了表示崩溃，保持表达能力。

Result: 在nuScenes自动驾驶数据集上实现最先进性能，在NYUv2室内场景数据集上所有任务均取得一致提升，验证了方法的广泛适用性。

Conclusion: NexusFlow能够有效处理结构多样化任务的部分监督学习，为现实世界多任务学习提供了通用解决方案。

Abstract: Partially Supervised Multi-Task Learning (PS-MTL) aims to leverage knowledge across tasks when annotations are incomplete. Existing approaches, however, have largely focused on the simpler setting of homogeneous, dense prediction tasks, leaving the more realistic challenge of learning from structurally diverse tasks unexplored. To this end, we introduce NexusFlow, a novel, lightweight, and plug-and-play framework effective in both settings. NexusFlow introduces a set of surrogate networks with invertible coupling layers to align the latent feature distributions of tasks, creating a unified representation that enables effective knowledge transfer. The coupling layers are bijective, preserving information while mapping features into a shared canonical space. This invertibility avoids representational collapse and enables alignment across structurally different tasks without reducing expressive capacity. We first evaluate NexusFlow on the core challenge of domain-partitioned autonomous driving, where dense map reconstruction and sparse multi-object tracking are supervised in different geographic regions, creating both structural disparity and a strong domain gap. NexusFlow sets a new state-of-the-art result on nuScenes, outperforming strong partially supervised baselines. To demonstrate generality, we further test NexusFlow on NYUv2 using three homogeneous dense prediction tasks, segmentation, depth, and surface normals, as a representative N-task PS-MTL scenario. NexusFlow yields consistent gains across all tasks, confirming its broad applicability.

</details>


### [33] [Language-driven Fine-grained Retrieval](https://arxiv.org/abs/2512.06255)
*Shijie Wang,Xin Yu,Yadan Luo,Zijian Wang,Pengfei Zhang,Zi Huang*

Main category: cs.CV

TL;DR: LaFG是一个语言驱动的细粒度图像检索框架，通过LLM和VLM将类别名称转换为属性级监督，解决传统方法在未见类别上泛化能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 传统细粒度图像检索方法使用稀疏的one-hot标签作为监督，忽略了类别名称中丰富的语义信息，导致跨类别细节可比性建模不足，限制了模型对未见类别的泛化能力。

Method: 1. 使用LLM将类别名称生成详细的属性导向描述；2. 利用冻结的VLM将描述投影到视觉对齐空间，聚类形成数据集级属性词汇表；3. 通过全局提示模板选择类别相关属性，聚合成类别特定的语言原型；4. 用这些原型监督检索模型。

Result: 该方法能够更好地建模跨类别细节的可比性，提升模型在未见类别上的泛化性能。

Conclusion: LaFG通过语言驱动的属性级监督，有效解决了传统细粒度图像检索方法在语义建模和泛化能力方面的局限性，为细粒度检索任务提供了新的解决方案。

Abstract: Existing fine-grained image retrieval (FGIR) methods learn discriminative embeddings by adopting semantically sparse one-hot labels derived from category names as supervision. While effective on seen classes, such supervision overlooks the rich semantics encoded in category names, hindering the modeling of comparability among cross-category details and, in turn, limiting generalization to unseen categories. To tackle this, we introduce LaFG, a Language-driven framework for Fine-Grained Retrieval that converts class names into attribute-level supervision using large language models (LLMs) and vision-language models (VLMs). Treating each name as a semantic anchor, LaFG prompts an LLM to generate detailed, attribute-oriented descriptions. To mitigate attribute omission in these descriptions, it leverages a frozen VLM to project them into a vision-aligned space, clustering them into a dataset-wide attribute vocabulary while harvesting complementary attributes from related categories. Leveraging this vocabulary, a global prompt template selects category-relevant attributes, which are aggregated into category-specific linguistic prototypes. These prototypes supervise the retrieval model to steer

</details>


### [34] [Knowing the Answer Isn't Enough: Fixing Reasoning Path Failures in LVLMs](https://arxiv.org/abs/2512.06258)
*Chaoyang Wang,Yangfan He,Yiyang Zhou,Yixuan Wang,Jiaqi Liu,Peng Xia,Zhengzhong Tu,Mohit Bansal,Huaxiu Yao*

Main category: cs.CV

TL;DR: 该论文揭示了大型视觉语言模型（LVLMs）存在路径选择偏差问题，即模型即使知道正确答案，也倾向于选择不稳定的推理路径。作者提出了PSO（路径选择优化）框架，通过两阶段训练来提升推理性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有LVLMs存在一个关键但未被充分探索的缺陷：模型即使拥有正确答案，也经常通过错误的推理路径得出结果。核心问题不是知识缺乏，而是推理搜索空间中的路径选择偏差。

Method: 提出PSO两阶段后训练框架：第一阶段使用GRPO（组相对策略优化）结合模板和答案奖励来培养结构化逐步推理；第二阶段进行在线偏好优化，模型从GRPO生成的数据中采样推理路径，自我评估并选择偏好轨迹，同时将错误路径存储在负向回放内存中防止重复错误。

Result: 大量实验表明，PSO有效修剪无效推理路径，显著提升推理准确性（平均提升7.4%），并产生更稳定一致的思维链。

Conclusion: PSO框架成功解决了LVLMs的路径选择偏差问题，通过优化推理路径选择机制，显著提高了模型的推理性能和稳定性。

Abstract: We reveal a critical yet underexplored flaw in Large Vision-Language Models (LVLMs): even when these models know the correct answer, they frequently arrive there through incorrect reasoning paths. The core issue is not a lack of knowledge, but a path selection bias within the vast reasoning search space. Although LVLMs are often capable of sampling correct solution trajectories, they disproportionately favor unstable or logically inconsistent ones, leading to erratic and unreliable outcomes. The substantial disparity between Pass@K (with large K) and Pass@1 across numerous models provides compelling evidence that such failures primarily stem from misreasoning rather than ignorance. To systematically investigate and address this issue, we propose PSO (Path-Select Optimization), a two-stage post-training framework designed to enhance both the reasoning performance and stability of existing LVLMs. In the first stage, we employ Group Relative Policy Optimization (GRPO) with template and answer-based rewards to cultivate structured, step-by-step reasoning. In the second stage, we conduct online preference optimization, where the model samples reasoning paths from GRPO-generated data, self-evaluates them, and aligns itself toward the preferred trajectories. Incorrect or suboptimal paths are concurrently stored in a Negative Replay Memory (NRM) as hard negatives, which are periodically revisited to prevent the model from repeating prior mistakes and to facilitate continual reasoning refinement. Extensive experiments show that PSO effectively prunes invalid reasoning paths, substantially enhances reasoning accuracy (with 7.4% improvements on average), and yields more stable and consistent chains of thought. Our code will be available at https://github.com/aiming-lab/PSO.

</details>


### [35] [TriaGS: Differentiable Triangulation-Guided Geometric Consistency for 3D Gaussian Splatting](https://arxiv.org/abs/2512.06269)
*Quan Tran,Tuan Dang*

Main category: cs.CV

TL;DR: 本文提出了一种通过约束多视图三角测量来增强3D高斯泼溅重建全局几何一致性的新方法，解决了仅依赖光度损失导致的浮点伪影和无结构几何问题。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅仅依赖光度损失进行重建，导致重建不一致、浮点伪影和几何结构不清晰的问题，限制了高保真表面的提取。

Method: 通过自监督方式利用相邻视图重新三角测量生成鲁棒共识点，并惩罚渲染3D点与共识点的偏差，强制实现全局几何一致性。

Result: 在DTU数据集上达到0.50mm的平均倒角距离，优于同类显式方法，实现了最先进的性能。

Conclusion: 该方法有效提升了3D高斯泼溅的重建质量，代码将开源以促进社区验证和可复现性。

Abstract: 3D Gaussian Splatting is crucial for real-time novel view synthesis due to its efficiency and ability to render photorealistic images. However, building a 3D Gaussian is guided solely by photometric loss, which can result in inconsistencies in reconstruction. This under-constrained process often results in "floater" artifacts and unstructured geometry, preventing the extraction of high-fidelity surfaces. To address this issue, our paper introduces a novel method that improves reconstruction by enforcing global geometry consistency through constrained multi-view triangulation. Our approach aims to achieve a consensus on 3D representation in the physical world by utilizing various estimated views. We optimize this process by penalizing the deviation of a rendered 3D point from a robust consensus point, which is re-triangulated from a bundle of neighboring views in a self-supervised fashion. We demonstrate the effectiveness of our method across multiple datasets, achieving state-of-the-art results. On the DTU dataset, our method attains a mean Chamfer Distance of 0.50 mm, outperforming comparable explicit methods. We will make our code open-source to facilitate community validation and ensure reproducibility.

</details>


### [36] [FacePhys: State of the Heart Learning](https://arxiv.org/abs/2512.06275)
*Kegang Wang,Jiankai Tang,Yuntao Wang,Xin Liu,Yuxuan Fan,Jiatong Ji,Yuanchun Shi,Daniel McDuff*

Main category: cs.CV

TL;DR: FacePhys是一种基于时空状态空间对偶性的高效rPPG算法，解决了模型可扩展性、跨数据集泛化和实时操作的三难问题，在保持最小计算开销的同时实现了49%的错误率降低。


<details>
  <summary>Details</summary>
Motivation: 利用摄像头进行生命体征测量为舒适、普适的健康监测提供了机会，但实际部署受到前端设备计算限制和数据压缩传输导致信号质量下降的制约。

Method: 基于时空状态空间对偶性构建内存高效的rPPG算法，利用可转移的心跳状态捕捉视频帧间的细微周期性变化，支持扩展视频序列训练和低延迟推理。

Result: FacePhys实现了最先进的性能，错误率降低49%，实时推理内存占用仅3.6MB，每帧延迟9.46ms，比现有方法提升83%到99%。

Conclusion: 该解决方案在实践部署中实现了可靠的实时性能，为实时健康监测提供了可行的技术路径。

Abstract: Vital sign measurement using cameras presents opportunities for comfortable, ubiquitous health monitoring. Remote photoplethysmography (rPPG), a foundational technology, enables cardiac measurement through minute changes in light reflected from the skin. However, practical deployment is limited by the computational constraints of performing analysis on front-end devices and the accuracy degradation of transmitting data through compressive channels that reduce signal quality. We propose a memory efficient rPPG algorithm - \emph{FacePhys} - built on temporal-spatial state space duality, which resolves the trilemma of model scalability, cross-dataset generalization, and real-time operation. Leveraging a transferable heart state, FacePhys captures subtle periodic variations across video frames while maintaining a minimal computational overhead, enabling training on extended video sequences and supporting low-latency inference. FacePhys establishes a new state-of-the-art, with a substantial 49\% reduction in error. Our solution enables real-time inference with a memory footprint of 3.6 MB and per-frame latency of 9.46 ms -- surpassing existing methods by 83\% to 99\%. These results translate into reliable real-time performance in practical deployments, and a live demo is available at https://www.facephys.com/.

</details>


### [37] [RefBench-PRO: Perceptual and Reasoning Oriented Benchmark for Referring Expression Comprehension](https://arxiv.org/abs/2512.06276)
*Tianyi Gao,Hao Li,Han Fang,Xin Wei,Xiaodong Dong,Hongbo Sun,Ye Yuan,Zhongjiang He,Jinglin Xu,Jingmin Xin,Hao Sun*

Main category: cs.CV

TL;DR: 本文介绍了RefBench-PRO基准测试，用于评估多模态大语言模型在指代表达理解任务中的感知和推理能力，并提出了Ref-R1学习方案来提升定位精度。


<details>
  <summary>Details</summary>
Motivation: 现有REC基准主要评估感知能力，缺乏可解释的评分机制，无法揭示MLLM在不同认知能力上的基础能力。

Method: 提出RefBench-PRO基准，将指代表达分解为感知和推理两个维度，细分为六个渐进式挑战任务；开发自动化数据生成管道；提出基于强化学习的Ref-R1学习方案，采用动态IoU的GRPO方法。

Result: RefBench-PRO能够对MLLM在指代表达理解上进行可解释性评估，在感知和推理方面都提出了更大挑战。

Conclusion: RefBench-PRO是一个全面的REC基准，通过分解认知维度实现了对MLLM能力的更深入评估，为REC任务建立了更强基线。

Abstract: Referring Expression Comprehension (REC) is a vision-language task that localizes a specific image region based on a textual description. Existing REC benchmarks primarily evaluate perceptual capabilities and lack interpretable scoring mechanisms, which cannot reveal the grounding capability of Multi-modal Large Language Model (MLLM) across different cognitive abilities. To address this limitation, we introduce RefBench-PRO, a comprehensive REC benchmark, which decomposes referring expressions into two core dimensions, i.e., perception and reasoning, and further subdivides them into six progressively challenging tasks, such as attribute, position, interaction, commonsense, relation and reject. We also develop a fully automated data-generation pipeline that produces diverse referring expressions across these six sub-dimensions. Furthermore, We propose Ref-R1, an RL-based learning scheme, which incorporates Dynamic IoU-based GRPO to improve localization accuracy under increasingly complex reasoning conditions, establishing a stronger baseline for REC. Extensive experiments demonstrate that our RefBench-PRO enables interpretable evaluation of MLLM on referring expression comprehension, presenting greater challenges in both perception and reasoning.

</details>


### [38] [Unleashing the Intrinsic Visual Representation Capability of Multimodal Large Language Models](https://arxiv.org/abs/2512.06281)
*Hengzhuang Li,Xinsong Zhang,Qiming Peng,Bin Luo,Han Hu,Dengyang Jiang,Han-Jia Ye,Teng Zhang,Hai Jin*

Main category: cs.CV

TL;DR: 本文提出LaVer框架，通过潜在空间掩码图像建模解决MLLMs中的模态不平衡问题，提升视觉信息利用率。


<details>
  <summary>Details</summary>
Motivation: MLLMs存在模态不平衡问题，深层网络中视觉信息未被充分利用，导致视觉性能下降或幻觉现象，这源于训练时主要依赖文本token预测而缺乏直接视觉监督信号。

Method: 提出LaVer训练框架，在LLM的联合潜在语义空间中进行掩码图像建模，为MLLMs提供直接视觉激活，促进学习更具区分性的视觉表征。

Result: 实验表明该方法能增强MLLMs的视觉注意力分配，在各种基准测试中表现优异，特别是在需要密集视觉能力的场景下。

Conclusion: LaVer框架有效解决了MLLMs的模态不平衡问题，显著提升了视觉信息的利用效率。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated remarkable proficiency in multimodal tasks. Despite their impressive performance, MLLMs suffer from the modality imbalance issue, where visual information is often underutilized compared to textual representations in deeper layers, leading to degraded visual performance or hallucinations. This issue stems from the predominant reliance on next-text-token-prediction during training, which fails to provide direct visual supervisory signals, resulting in progressive homogenization of visual representations throughout the layers. To this end, we propose Latent Visual Reconstruction (LaVer), a novel training framework that facilitates MLLMs in learning more discriminative visual representations via masked image modeling in the joint latent semantic space of LLM. Our method offers direct visual activation to MLLMs, which exhibit increased visual attention allocation, indicating enhanced utilization of visual information. Extensive experiments across diverse benchmarks prove the superiority of our approach in various scenarios, especially those requiring dense visual capabilities. Code of LaVer is available at https://github.com/Fir-lat/LaVer.

</details>


### [39] [A Sleep Monitoring System Based on Audio, Video and Depth Information](https://arxiv.org/abs/2512.06282)
*Lyn Chao-ling Chen,Kuan-Wen Chen,Yi-Ping Hung*

Main category: cs.CV

TL;DR: 本文开发了一种基于事件的无创睡眠监测系统，通过红外深度传感器、RGB摄像头和四麦克风阵列来检测运动、灯光和噪音三种类型的睡眠干扰事件。


<details>
  <summary>Details</summary>
Motivation: 开发非侵入式睡眠监测系统，用于定量评估睡眠干扰，通过多传感器融合技术在低光照环境下实现可靠的睡眠质量监测。

Method: 使用红外深度传感器检测运动事件，RGB摄像头检测灯光开关事件，四麦克风阵列检测噪音事件。建立深度信号和颜色图像的背景模型，采用事件检测算法从三类传感器处理数据中识别事件发生。

Result: 系统在睡眠条件下进行了测试，实验结果验证了系统的可靠性。

Conclusion: 该事件驱动的多传感器睡眠监测系统能够有效识别和量化睡眠干扰事件，为家庭环境下的睡眠质量评估提供了可行的技术方案。

Abstract: For quantitative evaluation of sleep disturbances, a noninvasive monitoring system is developed by introducing an event-based method. We observe sleeping in home context and classify the sleep disturbances into three types of events: motion events, light-on/off events and noise events. A device with an infrared depth sensor, a RGB camera, and a four-microphone array is used in sleep monitoring in an environment with barely light sources. One background model is established in depth signals for measuring magnitude of movements. Because depth signals cannot observe lighting changes, another background model is established in color images for measuring magnitude of lighting effects. An event detection algorithm is used to detect occurrences of events from the processed data of the three types of sensors. The system was tested in sleep condition and the experiment result validates the system reliability.

</details>


### [40] [StrokeNet: Unveiling How to Learn Fine-Grained Interactions in Online Handwritten Stroke Classification](https://arxiv.org/abs/2512.06290)
*Yiheng Huang,Shuang She,Zewei Wei,Jianmin Lin,Ming Yang,Wenyin Liu*

Main category: cs.CV

TL;DR: StrokeNet提出了一种新颖的笔画分类方法，通过参考点表示和空间查询机制，解决了现有方法难以捕捉笔画间细粒度语义关系的问题，在多个数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法难以捕捉笔画间的局部化交互关系，而点级视角虽然能解决这个问题但会引入冗余。需要一种能够有效建模笔画间细粒度语义关系的方法。

Method: 1. 动态选择参考点并序列化表示笔画
2. 使用Inline Sequence Attention模块构建上下文特征
3. 设计Cross-Ellipse Query机制进行空间特征交互
4. 通过联合优化框架同时预测笔画类别和相邻笔画语义转移

Result: 在多个公开在线手写数据集上达到state-of-the-art性能，特别是在CASIA-onDo数据集上准确率从93.81%提升到95.54%。

Conclusion: StrokeNet通过参考点表示和空间查询机制有效解决了笔画分类中的细粒度关系建模问题，证明了方法的有效性和鲁棒性。

Abstract: Stroke classification remains challenging due to variations in writing style, ambiguous content, and dynamic writing positions. The core challenge in stroke classification is modeling the semantic relationships between strokes. Our observations indicate that stroke interactions are typically localized, making it difficult for existing deep learning methods to capture such fine-grained relationships. Although viewing strokes from a point-level perspective can address this issue, it introduces redundancy. However, by selecting reference points and using their sequential order to represent strokes in a fine-grained manner, this problem can be effectively solved. This insight inspired StrokeNet, a novel network architecture encoding strokes as reference pair representations (points + feature vectors), where reference points enable spatial queries and features mediate interaction modeling. Specifically, we dynamically select reference points for each stroke and sequence them, employing an Inline Sequence Attention (ISA) module to construct contextual features. To capture spatial feature interactions, we devised a Cross-Ellipse Query (CEQ) mechanism that clusters reference points and extracts features across varying spatial scales. Finally, a joint optimization framework simultaneously predicts stroke categories via reference points regression and adjacent stroke semantic transition modeling through an Auxiliary Branch (Aux-Branch). Experimental results show that our method achieves state-of-the-art performance on multiple public online handwritten datasets. Notably, on the CASIA-onDo dataset, the accuracy improves from 93.81$\%$ to 95.54$\%$, demonstrating the effectiveness and robustness of our approach.

</details>


### [41] [Exploiting Spatiotemporal Properties for Efficient Event-Driven Human Pose Estimation](https://arxiv.org/abs/2512.06306)
*Haoxian Zhou,Chuanzhi Xu,Langyi Chen,Haodong Chen,Yuk Ying Chung,Qiang Qu,Xaoming Chen,Weidong Cai*

Main category: cs.CV

TL;DR: 提出了一种基于点云框架的事件流时空建模方法，通过事件时序切片卷积和事件切片序列化模块，提升人体姿态估计性能，在DHP19数据集上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法将事件流转换为密集事件帧会带来额外计算开销并牺牲事件信号的高时间分辨率，因此需要利用事件流的时空特性来提升人体姿态估计性能。

Method: 设计了事件时序切片卷积模块捕获事件切片间的短期依赖，结合事件切片序列化模块进行结构化时序建模，并在点云表示中应用边缘增强来改善稀疏事件条件下的空间边缘信息。

Result: 在DHP19数据集上的实验表明，该方法在PointNet、DGCNN和Point Transformer三种代表性点云骨干网络上均能持续提升性能。

Conclusion: 基于点云框架的事件流时空建模方法能够有效利用事件相机的高时间分辨率特性，在保持计算效率的同时提升人体姿态估计的准确性。

Abstract: Human pose estimation focuses on predicting body keypoints to analyze human motion. Event cameras provide high temporal resolution and low latency, enabling robust estimation under challenging conditions. However, most existing methods convert event streams into dense event frames, which adds extra computation and sacrifices the high temporal resolution of the event signal. In this work, we aim to exploit the spatiotemporal properties of event streams based on point cloud-based framework, designed to enhance human pose estimation performance. We design Event Temporal Slicing Convolution module to capture short-term dependencies across event slices, and combine it with Event Slice Sequencing module for structured temporal modeling. We also apply edge enhancement in point cloud-based event representation to enhance spatial edge information under sparse event conditions to further improve performance. Experiments on the DHP19 dataset show our proposed method consistently improves performance across three representative point cloud backbones: PointNet, DGCNN, and Point Transformer.

</details>


### [42] [ReCAD: Reinforcement Learning Enhanced Parametric CAD Model Generation with Vision-Language Models](https://arxiv.org/abs/2512.06328)
*Jiahao Li,Yusheng Luo,Yunzhong Lou,Xiangdong Zhou*

Main category: cs.CV

TL;DR: ReCAD是一个强化学习框架，利用预训练大模型的生成能力，从多模态输入生成精确的参数化CAD模型，无需监督微调即可实现复杂CAD操作。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖监督微调注入知识，编辑性支持有限，且未能充分利用预训练大模型的强生成先验。ReCAD旨在通过强化学习框架解决这些问题。

Method: 1）微调视觉语言模型获得基本CAD生成能力；2）提出新颖的强化学习策略，以参数化代码为指导增强模型推理；3）采用分层原语学习过程，在统一奖励函数下逐步教授结构化组合技能。

Result: ReCAD在文本到CAD和图像到CAD任务中均达到最先进水平，显著提高了几何精度。在图像到CAD任务中，平均Chamfer距离从73.47降至29.61（分布内）和从272.06降至80.23（分布外）。

Conclusion: ReCAD框架成功利用了预训练大模型的生成能力，通过强化学习实现了高质量的参数化CAD模型生成，在几何精度和语义保真度方面显著优于现有基线方法。

Abstract: We present ReCAD, a reinforcement learning (RL) framework that bootstraps pretrained large models (PLMs) to generate precise parametric computer-aided design (CAD) models from multimodal inputs by leveraging their inherent generative capabilities. With just access to simple functional interfaces (e.g., point coordinates), our approach enables the emergence of complex CAD operations (e.g., pattern replication and mirror). This stands in contrast to previous methods, which typically rely on knowledge injected through supervised fine-tuning (SFT), offer limited support for editability, and fail to exploit the strong generative priors of PLMs. Specifically, the ReCAD framework begins by fine-tuning vision-language models (VLMs) to equip them with basic CAD model generation capabilities, where we rewrite CAD scripts into parameterized code that is leveraged to generate accurate textual descriptions for supervision. Then, we propose a novel RL strategy that incorporates parameterized code as guidance to enhance the model's reasoning on challenging questions. Furthermore, we employ a hierarchical primitive learning process to progressively teach structured and compositional skills under a unified reward function that ensures both geometric accuracy and semantic fidelity. ReCAD sets a new state-of-the-art in both text-to-CAD and image-to-CAD tasks, significantly improving geometric accuracy across in-distribution and out-of-distribution settings. In the image-to-CAD task, for instance, it reduces the mean Chamfer Distance from 73.47 to 29.61 (in-distribution) and from 272.06 to 80.23 (out-of-distribution), outperforming existing baselines by a substantial margin.

</details>


### [43] [S2WMamba: A Spectral-Spatial Wavelet Mamba for Pansharpening](https://arxiv.org/abs/2512.06330)
*Haoyu Zhang,Junhan Luo,Yugang Cao,Siran Peng,Jie Huang,Liangjian-Deng*

Main category: cs.CV

TL;DR: S2WMamba是一个用于全色锐化的新方法，通过2D/1D小波变换显式解耦频率信息，并使用Mamba-based跨模态交互来融合高分辨率全色图像和低分辨率多光谱图像，在多个数据集上达到或超越现有最佳方法。


<details>
  <summary>Details</summary>
Motivation: 全色锐化中同时处理全色和多光谱图像往往会使空间细节与光谱保真度纠缠在一起，导致光谱失真。需要一种能够显式解耦频率信息的方法来改善这一问题。

Method: 使用2D Haar DWT处理全色图像定位空间边缘和纹理，使用通道级1D Haar DWT处理每个像素的光谱分离低频/高频分量。通过光谱分支和空间分支的双分支结构，结合基于Mamba的跨模态调制和动态门融合机制。

Result: 在WV3、GF2和QB数据集上，S2WMamba匹配或超越了FusionMamba、CANNet等强基线方法，PSNR最高提升0.23 dB，在完整分辨率WV3上达到HQNR 0.956。

Conclusion: 提出的S2WMamba方法通过显式频率解耦和轻量级跨模态交互，有效解决了全色锐化中的空间-光谱纠缠问题，消融实验验证了方法组件的有效性。

Abstract: Pansharpening fuses a high-resolution PAN image with a low-resolution multispectral (LRMS) image to produce an HRMS image. A key difficulty is that jointly processing PAN and MS often entangles spatial detail with spectral fidelity. We propose S2WMamba, which explicitly disentangles frequency information and then performs lightweight cross-modal interaction. Concretely, a 2D Haar DWT is applied to PAN to localize spatial edges and textures, while a channel-wise 1D Haar DWT treats each pixel's spectrum as a 1D signal to separate low/high-frequency components and limit spectral distortion. The resulting Spectral branch injects wavelet-extracted spatial details into MS features, and the Spatial branch refines PAN features using spectra from the 1D pyramid; the two branches exchange information through Mamba-based cross-modulation that models long-range dependencies with linear complexity. A multi-scale dynamic gate (multiplicative + additive) then adaptively fuses branch outputs.On WV3, GF2, and QB, S2WMamba matches or surpasses recent strong baselines (FusionMamba, CANNet, U2Net, ARConv), improving PSNR by up to 0.23 dB and reaching HQNR 0.956 on full-resolution WV3. Ablations justify the choice of 2D/1D DWT placement, parallel dual branches, and the fusion gate. Our code is available at https://github.com/KagUYa66/S2WMamba.

</details>


### [44] [CryoHype: Reconstructing a thousand cryo-EM structures with transformer-based hypernetworks](https://arxiv.org/abs/2512.06332)
*Jeffrey Gu,Minkyu Jeon,Ambri Ma,Serena Yeung-Levy,Ellen D. Zhong*

Main category: cs.CV

TL;DR: CryoHype是一种基于Transformer的超网络，用于解决冷冻电镜图像中多分子物种混合的重建挑战，能够同时重建多达1000个不同结构。


<details>
  <summary>Details</summary>
Motivation: 现有冷冻电镜方法主要关注单个或少数结构的构象异质性，无法有效解决由许多不同分子物种混合产生的组成异质性，限制了高通量结构测定的潜力。

Method: 提出CryoHype方法，使用基于Transformer的超网络动态调整隐式神经表示的权重，实现对多个分子物种的同时重建。

Result: 在包含100个结构的基准数据集上取得最先进结果，并在固定姿态设置下成功从无标签冷冻电镜图像重建1000个不同结构。

Conclusion: CryoHype突破了现有方法的限制，为高通量冷冻电镜结构测定提供了有效解决方案，具有重要的应用价值。

Abstract: Cryo-electron microscopy (cryo-EM) is an indispensable technique for determining the 3D structures of dynamic biomolecular complexes. While typically applied to image a single molecular species, cryo-EM has the potential for structure determination of many targets simultaneously in a high-throughput fashion. However, existing methods typically focus on modeling conformational heterogeneity within a single or a few structures and are not designed to resolve compositional heterogeneity arising from mixtures of many distinct molecular species. To address this challenge, we propose CryoHype, a transformer-based hypernetwork for cryo-EM reconstruction that dynamically adjusts the weights of an implicit neural representation. Using CryoHype, we achieve state-of-the-art results on a challenging benchmark dataset containing 100 structures. We further demonstrate that CryoHype scales to the reconstruction of 1,000 distinct structures from unlabeled cryo-EM images in the fixed-pose setting.

</details>


### [45] [Beyond Hallucinations: A Multimodal-Guided Task-Aware Generative Image Compression for Ultra-Low Bitrate](https://arxiv.org/abs/2512.06344)
*Kaile Wang,Lijun He,Haisheng Fu,Haixia Bi,Fan Li*

Main category: cs.CV

TL;DR: 本文提出了一种多模态引导的任务感知生成式图像压缩框架(MTGC)，通过整合文本描述、高压缩图像和语义伪词三种引导模态，在超低码率下提升语义一致性和感知质量。


<details>
  <summary>Details</summary>
Motivation: 生成式图像压缩在超低码率下存在语义偏差问题，限制了其在6G语义通信中的可靠部署。需要解决生成幻觉导致的语义不一致问题。

Method: MTGC框架包含任务感知语义压缩模块(TASCM)生成语义伪词，以及多模态引导扩散解码器(MGDD)采用双路径协作引导机制，结合交叉注意力和ControlNet残差注入三种引导模态。

Result: 实验表明MTGC显著提升语义一致性(DISTS在DIV2K数据集上降低10.59%)，同时在超低码率下获得优异的感知质量和像素级保真度。

Conclusion: 该框架通过多模态协同引导有效解决了超低码率下的语义偏差问题，为6G语义通信提供了可靠的图像压缩解决方案。

Abstract: Generative image compression has recently shown impressive perceptual quality, but often suffers from semantic deviations caused by generative hallucinations at ultra-low bitrate (bpp < 0.05), limiting its reliable deployment in bandwidth-constrained 6G semantic communication scenarios. In this work, we reassess the positioning and role of of multimodal guidance, and propose a Multimodal-Guided Task-Aware Generative Image Compression (MTGC) framework. Specifically, MTGC integrates three guidance modalities to enhance semantic consistency: a concise but robust text caption for global semantics, a highly compressed image (HCI) retaining low-level visual information, and Semantic Pseudo-Words (SPWs) for fine-grained task-relevant semantics. The SPWs are generated by our designed Task-Aware Semantic Compression Module (TASCM), which operates in a task-oriented manner to drive the multi-head self-attention mechanism to focus on and extract semantics relevant to the generation task while filtering out redundancy. Subsequently, to facilitate the synergistic guidance of these modalities, we design a Multimodal-Guided Diffusion Decoder (MGDD) employing a dual-path cooperative guidance mechanism that synergizes cross-attention and ControlNet additive residuals to precisely inject these three guidance into the diffusion process, and leverages the diffusion model's powerful generative priors to reconstruct the image. Extensive experiments demonstrate that MTGC consistently improves semantic consistency (e.g., DISTS drops by 10.59% on the DIV2K dataset) while also achieving remarkable gains in perceptual quality and pixel-level fidelity at ultra-low bitrate.

</details>


### [46] [CLUENet: Cluster Attention Makes Neural Networks Have Eyes](https://arxiv.org/abs/2512.06345)
*Xiangshuai Song,Jun-Jie Huang,Tianrui Liu,Ke Liang,Chang Tang*

Main category: cs.CV

TL;DR: CLUENet是一种透明的深度架构，通过全局软聚合与硬分配、温度缩放余弦注意力、门控残差连接、硬共享特征分发和改进的聚类池化策略，解决了传统卷积和注意力模型在建模不规则空间模式及可解释性方面的局限。


<details>
  <summary>Details</summary>
Motivation: 传统卷积和注意力模型具有刚性感受野和复杂架构，限制了其对不规则空间模式的建模能力，并阻碍了可解释性，特别是在需要高模型透明度的任务中。聚类范式虽然提供了良好的可解释性和灵活的语义建模，但存在精度有限、效率低和训练中梯度消失的问题。

Method: 提出了CLUENet，包括三个关键创新：(i) 全局软聚合与硬分配，结合温度缩放余弦注意力和门控残差连接以增强局部建模；(ii) 块间硬共享特征分发；(iii) 改进的聚类池化策略。

Result: 在CIFAR-100和Mini-ImageNet上的实验表明，CLUENet在分类性能上优于现有的聚类方法和主流视觉模型，同时在准确性、效率和透明度之间取得了良好的平衡。

Conclusion: CLUENet通过创新的聚类注意力机制，显著提升了视觉语义理解任务的性能与可解释性，为需要高透明度的应用提供了有效的解决方案。

Abstract: Despite the success of convolution- and attention-based models in vision tasks, their rigid receptive fields and complex architectures limit their ability to model irregular spatial patterns and hinder interpretability, therefore posing challenges for tasks requiring high model transparency. Clustering paradigms offer promising interpretability and flexible semantic modeling, but suffer from limited accuracy, low efficiency, and gradient vanishing during training. To address these issues, we propose CLUster attEntion Network (CLUENet), an transparent deep architecture for visual semantic understanding. We propose three key innovations include (i) a Global Soft Aggregation and Hard Assignment with a Temperature-Scaled Cosin Attention and gated residual connections for enhanced local modeling, (ii) inter-block Hard and Shared Feature Dispatching, and (iii) an improved cluster pooling strategy. These enhancements significantly improve both classification performance and visual interpretability. Experiments on CIFAR-100 and Mini-ImageNet demonstrate that CLUENet outperforms existing clustering methods and mainstream visual models, offering a compelling balance of accuracy, efficiency, and transparency.

</details>


### [47] [TreeQ: Pushing the Quantization Boundary of Diffusion Transformer via Tree-Structured Mixed-Precision Search](https://arxiv.org/abs/2512.06353)
*Kaicheng Yang,Kaisen Yang,Baiting Wu,Xun Zhang,Qianrui Yang,Haotong Qin,He Zhang,Yulun Zhang*

Main category: cs.CV

TL;DR: TreeQ是一个统一的DiT量化框架，通过树结构搜索、环境噪声引导和通用Monarch分支技术，首次在DiT模型上实现了近乎无损的4位PTQ性能。


<details>
  <summary>Details</summary>
Motivation: DiT模型在图像生成方面表现出色但计算和内存需求高，现有混合精度量化方法在DiT架构上应用有限且未充分探索，需要专门针对DiT特性的量化解决方案。

Method: 提出TreeQ框架：1) 树结构搜索(TSS)利用DiT线性特性在O(n)时间内搜索解空间；2) 环境噪声引导(ENG)统一PTQ和QAT优化目标；3) 通用Monarch分支(GMB)防止超低位量化中的信息瓶颈。

Result: 在DiT-XL/2模型上，W3A3和W4A4 PTQ/PEFT设置下达到最先进性能，首次实现DiT模型近乎无损的4位PTQ性能。

Conclusion: TreeQ框架成功解决了DiT量化的关键挑战，为DiT模型的实际部署提供了高效的量化解决方案，代码和模型将开源。

Abstract: Diffusion Transformers (DiTs) have emerged as a highly scalable and effective backbone for image generation, outperforming U-Net architectures in both scalability and performance. However, their real-world deployment remains challenging due to high computational and memory demands. Mixed-Precision Quantization (MPQ), designed to push the limits of quantization, has demonstrated remarkable success in advancing U-Net quantization to sub-4bit settings while significantly reducing computational and memory overhead. Nevertheless, its application to DiT architectures remains limited and underexplored. In this work, we propose TreeQ, a unified framework addressing key challenges in DiT quantization. First, to tackle inefficient search and proxy misalignment, we introduce Tree Structured Search (TSS). This DiT-specific approach leverages the architecture's linear properties to traverse the solution space in O(n) time while improving objective accuracy through comparison-based pruning. Second, to unify optimization objectives, we propose Environmental Noise Guidance (ENG), which aligns Post-Training Quantization (PTQ) and Quantization-Aware Training (QAT) configurations using a single hyperparameter. Third, to mitigate information bottlenecks in ultra-low-bit regimes, we design the General Monarch Branch (GMB). This structured sparse branch prevents irreversible information loss, enabling finer detail generation. Through extensive experiments, our TreeQ framework demonstrates state-of-the-art performance on DiT-XL/2 under W3A3 and W4A4 PTQ/PEFT settings. Notably, our work is the first to achieve near-lossless 4-bit PTQ performance on DiT models. The code and models will be available at https://github.com/racoonykc/TreeQ

</details>


### [48] [Rectifying Latent Space for Generative Single-Image Reflection Removal](https://arxiv.org/abs/2512.06358)
*Mingjia Li,Jin Hu,Hainuo Wang,Qiming Hu,Jiarui Wang,Xiaojie Guo*

Main category: cs.CV

TL;DR: 本文提出了一种基于潜在扩散模型的单图像反射去除方法，通过重新构建潜在空间结构来解决反射图像分解的模糊性问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以处理反射图像中模糊区域的组成，导致在真实场景中的恢复和泛化能力不足。关键在于语义编码器的潜在空间缺乏将复合图像解释为线性叠加层的能力。

Method: 方法包含三个协同组件：反射等变VAE（使潜在空间与反射形成的线性物理对齐）、可学习的任务特定文本嵌入（提供精确指导）、深度引导的早期分支采样策略（利用生成随机性获得更好结果）。

Result: 在多个基准测试中达到新的SOTA性能，并在具有挑战性的真实世界案例中表现出良好的泛化能力。

Conclusion: 通过重新构建潜在扩散模型，有效解决了单图像反射去除的模糊性问题，实现了高质量的反射分离效果。

Abstract: Single-image reflection removal is a highly ill-posed problem, where existing methods struggle to reason about the composition of corrupted regions, causing them to fail at recovery and generalization in the wild. This work reframes an editing-purpose latent diffusion model to effectively perceive and process highly ambiguous, layered image inputs, yielding high-quality outputs. We argue that the challenge of this conversion stems from a critical yet overlooked issue, i.e., the latent space of semantic encoders lacks the inherent structure to interpret a composite image as a linear superposition of its constituent layers. Our approach is built on three synergistic components, including a reflection-equivariant VAE that aligns the latent space with the linear physics of reflection formation, a learnable task-specific text embedding for precise guidance that bypasses ambiguous language, and a depth-guided early-branching sampling strategy to harness generative stochasticity for promising results. Extensive experiments reveal that our model achieves new SOTA performance on multiple benchmarks and generalizes well to challenging real-world cases.

</details>


### [49] [Spoofing-aware Prompt Learning for Unified Physical-Digital Facial Attack Detection](https://arxiv.org/abs/2512.06363)
*Jiabao Guo,Yadian Wang,Hui Ma,Yuhao Fu,Ju Jia,Hui Liu,Shengeng Tang,Lechao Cheng,Yunfeng Diao,Ajian Liu*

Main category: cs.CV

TL;DR: 本文提出SPL-UAD框架，通过解耦物理和数字攻击的提示空间优化分支，解决了现有方法在统一攻击检测中的优化冲突问题，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界人脸识别系统同时面临物理呈现攻击和数字伪造攻击的威胁，现有基于CLIP的方法在统一检测中存在优化方向冲突的问题。

Method: 提出可学习的并行提示分支，结合自适应欺骗上下文提示生成技术，实现物理和数字攻击的独立优化控制；设计线索感知增强机制，利用双提示机制生成挑战性样本挖掘任务。

Result: 在大型UniAttackDataPlus数据集上的实验表明，该方法在统一攻击检测任务中取得了显著的性能提升。

Conclusion: SPL-UAD框架通过解耦优化策略有效解决了物理-数字攻击检测的冲突问题，为生物特征数据的全面保护提供了有效解决方案。

Abstract: Real-world face recognition systems are vulnerable to both physical presentation attacks (PAs) and digital forgery attacks (DFs). We aim to achieve comprehensive protection of biometric data by implementing a unified physical-digital defense framework with advanced detection. Existing approaches primarily employ CLIP with regularization constraints to enhance model generalization across both tasks. However, these methods suffer from conflicting optimization directions between physical and digital attack detection under same category prompt spaces. To overcome this limitation, we propose a Spoofing-aware Prompt Learning for Unified Attack Detection (SPL-UAD) framework, which decouples optimization branches for physical and digital attacks in the prompt space. Specifically, we construct a learnable parallel prompt branch enhanced with adaptive Spoofing Context Prompt Generation, enabling independent control of optimization for each attack type. Furthermore, we design a Cues-awareness Augmentation that leverages the dual-prompt mechanism to generate challenging sample mining tasks on data, significantly enhancing the model's robustness against unseen attack types. Extensive experiments on the large-scale UniAttackDataPlus dataset demonstrate that the proposed method achieves significant performance improvements in unified attack detection tasks.

</details>


### [50] [Human3R: Incorporating Human Priors for Better 3D Dynamic Reconstruction from Monocular Videos](https://arxiv.org/abs/2512.06368)
*Weitao Xiong,Zhiyuan Yuan,Jiahao Lu,Chengfeng Zhao,Peng Li,Yuan Liu*

Main category: cs.CV

TL;DR: 该论文提出Human3R方法，通过结合SMPL人体模型和单目深度估计的混合几何先验，解决单目动态视频重建中人体几何不一致和分辨率退化的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏3D人体结构理解，导致几何不一致的结果，如肢体比例扭曲、人-物融合不自然，且内存限制的下采样导致人体边界向背景几何漂移。

Method: 提出Human3R分层流程，先处理全分辨率图像获取整体场景几何，再通过策略性裁剪和交叉注意力融合增强人体细节，通过特征融合模块集成SMPL先验确保几何合理重建。

Result: 在TUM Dynamics和GTA-IM数据集上的广泛实验表明，该方法在动态人体重建方面具有优越性能。

Conclusion: Human3R通过混合几何先验和分层处理，有效解决了单目动态人体场景重建的几何一致性和细节保留问题。

Abstract: Monocular dynamic video reconstruction faces significant challenges in dynamic human scenes due to geometric inconsistencies and resolution degradation issues. Existing methods lack 3D human structural understanding, producing geometrically inconsistent results with distorted limb proportions and unnatural human-object fusion, while memory-constrained downsampling causes human boundary drift toward background geometry. To address these limitations, we propose to incorporate hybrid geometric priors that combine SMPL human body models with monocular depth estimation. Our approach leverages structured human priors to maintain surface consistency while capturing fine-grained geometric details in human regions. We introduce Human3R, featuring a hierarchical pipeline with refinement components that processes full-resolution images for overall scene geometry, then applies strategic cropping and cross-attention fusion for human-specific detail enhancement. The method integrates SMPL priors through a Feature Fusion Module to ensure geometrically plausible reconstruction while preserving fine-grained human boundaries. Extensive experiments on TUM Dynamics and GTA-IM datasets demonstrate superior performance in dynamic human reconstruction.

</details>


### [51] [VG-Refiner: Towards Tool-Refined Referring Grounded Reasoning via Agentic Reinforcement Learning](https://arxiv.org/abs/2512.06373)
*Yuji Wang,Wenlong Liu,Jingxuan Niu,Haoji Zhang,Yansong Tang*

Main category: cs.CV

TL;DR: VG-Refiner是首个针对工具精炼的指代接地推理框架，通过两阶段思考-重新思考机制和精炼奖励机制，解决现有TiVR模型在处理不可靠工具输出时的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有TiVR范式主要关注通过强化学习整合各种视觉工具，但忽视了设计有效响应机制来处理不可靠或错误工具输出的问题，特别是在指代和接地任务中，不准确的检测工具预测经常误导TiVR模型产生幻觉推理。

Method: 提出两阶段思考-重新思考机制，使模型能够明确分析和响应工具反馈；引入精炼奖励机制，鼓励对不良工具结果进行有效修正；使用少量任务特定数据增强模型精炼能力。

Result: 在指代和推理接地基准测试中，VG-Refiner在准确性和修正能力方面实现了显著提升，同时保持了预训练模型的通用能力。

Conclusion: VG-Refiner框架有效解决了TiVR模型中工具输出不可靠的问题，通过精炼机制显著提升了指代接地推理的性能，并提出了新的评估指标和协议来系统衡量模型的精炼能力。

Abstract: Tool-integrated visual reasoning (TiVR) has demonstrated great potential in enhancing multimodal problem-solving. However, existing TiVR paradigms mainly focus on integrating various visual tools through reinforcement learning, while neglecting to design effective response mechanisms for handling unreliable or erroneous tool outputs. This limitation is particularly pronounced in referring and grounding tasks, where inaccurate detection tool predictions often mislead TiVR models into generating hallucinated reasoning. To address this issue, we propose the VG-Refiner, the first framework aiming at the tool-refined referring grounded reasoning. Technically, we introduce a two-stage think-rethink mechanism that enables the model to explicitly analyze and respond to tool feedback, along with a refinement reward that encourages effective correction in response to poor tool results. In addition, we propose two new metrics and establish fair evaluation protocols to systematically measure the refinement ability of current models. We adopt a small amount of task-specific data to enhance the refinement capability of VG-Refiner, achieving a significant improvement in accuracy and correction ability on referring and reasoning grounding benchmarks while preserving the general capabilities of the pretrained model.

</details>


### [52] [Are AI-Generated Driving Videos Ready for Autonomous Driving? A Diagnostic Evaluation Framework](https://arxiv.org/abs/2512.06376)
*Xinhao Xiang,Abhijeet Rastogi,Jiawei Zhang*

Main category: cs.CV

TL;DR: 本文提出了一个诊断框架来评估AI生成驾驶视频（AIGV）在自动驾驶模型训练和评估中的可靠性，发现了AIGV的常见失败模式及其对感知任务的负面影响，并开发了ADGV-Bench基准和ADGVE评估器来提升AIGV质量。


<details>
  <summary>Details</summary>
Motivation: 当前文本到视频模型能够生成高分辨率驾驶场景，但尚不清楚这些AI生成的驾驶视频是否能可靠地支持自动驾驶模型的训练和评估。

Method: 1. 建立AIGV失败模式分类法；2. 构建ADGV-Bench基准数据集；3. 提出ADGVE评估器，结合静态语义、时序线索、车道遵守信号和视觉语言模型推理；4. 通过实验验证过滤后的AIGV对自动驾驶模型的益处。

Result: 实验表明，盲目添加原始AIGV会降低感知性能，但使用ADGVE过滤后能提升视频质量评估指标和下游自动驾驶模型性能，使AIGV成为真实数据的有效补充。

Conclusion: 研究揭示了AIGV在自动驾驶中的风险和潜力，并提供了安全利用大规模视频生成的实际工具。

Abstract: Recent text-to-video models have enabled the generation of high-resolution driving scenes from natural language prompts. These AI-generated driving videos (AIGVs) offer a low-cost, scalable alternative to real or simulator data for autonomous driving (AD). But a key question remains: can such videos reliably support training and evaluation of AD models? We present a diagnostic framework that systematically studies this question. First, we introduce a taxonomy of frequent AIGV failure modes, including visual artifacts, physically implausible motion, and violations of traffic semantics, and demonstrate their negative impact on object detection, tracking, and instance segmentation. To support this analysis, we build ADGV-Bench, a driving-focused benchmark with human quality annotations and dense labels for multiple perception tasks. We then propose ADGVE, a driving-aware evaluator that combines static semantics, temporal cues, lane obedience signals, and Vision-Language Model(VLM)-guided reasoning into a single quality score for each clip. Experiments show that blindly adding raw AIGVs can degrade perception performance, while filtering them with ADGVE consistently improves both general video quality assessment metrics and downstream AD models, and turns AIGVs into a beneficial complement to real-world data. Our study highlights both the risks and the promise of AIGVs, and provides practical tools for safely leveraging large-scale video generation in future AD pipelines.

</details>


### [53] [VAD-Net: Multidimensional Facial Expression Recognition in Intelligent Education System](https://arxiv.org/abs/2512.06377)
*Yi Huo,Yun Ge*

Main category: cs.CV

TL;DR: 该研究在FER2013数据集上首次标注了VAD（Valence-Arousal-Dominance）三维情感参数中的Dominance维度，并提出了基于正交卷积的改进网络来提高VAD预测精度。


<details>
  <summary>Details</summary>
Motivation: 当前FER数据集主要基于离散情感类别标注，但未来情感计算需要更全面精确的VAD多维参数。虽然AffectNet已标注VA维度，但缺乏D维度。

Method: 在FER2013数据集上标注D维度，并引入正交卷积来增强网络特征提取能力，提高VAD预测准确性。

Result: 实验表明D维度可测量但比VA维度更难获取，正交卷积配置能获得更好的VAD预测结果。

Conclusion: 该研究为FER数据集提供了D维度标注，并通过正交卷积网络建立了VAD情感预测基准，相关数据集和代码已开源。

Abstract: Current FER (Facial Expression Recognition) dataset is mostly labeled by emotion categories, such as happy, angry, sad, fear, disgust, surprise, and neutral which are limited in expressiveness. However, future affective computing requires more comprehensive and precise emotion metrics which could be measured by VAD(Valence-Arousal-Dominance) multidimension parameters. To address this, AffectNet has tried to add VA (Valence and Arousal) information, but still lacks D(Dominance). Thus, the research introduces VAD annotation on FER2013 dataset, takes the initiative to label D(Dominance) dimension. Then, to further improve network capacity, it enforces orthogonalized convolution on it, which extracts more diverse and expressive features and will finally increase the prediction accuracy. Experiment results show that D dimension could be measured but is difficult to obtain compared with V and A dimension no matter in manual annotation or regression network prediction. Secondly, the ablation test by introducing orthogonal convolution verifies that better VAD prediction could be obtained in the configuration of orthogonal convolution. Therefore, the research provides an initiative labelling for D dimension on FER dataset, and proposes a better prediction network for VAD prediction through orthogonal convolution. The newly built VAD annotated FER2013 dataset could act as a benchmark to measure VAD multidimensional emotions, while the orthogonalized regression network based on ResNet could act as the facial expression recognition baseline for VAD emotion prediction. The newly labeled dataset and implementation code is publicly available on https://github.com/YeeHoran/VAD-Net .

</details>


### [54] [OCFER-Net: Recognizing Facial Expression in Online Learning System](https://arxiv.org/abs/2512.06379)
*Yi Huo,Lei Zhang*

Main category: cs.CV

TL;DR: 该论文提出OCFER-Net，通过正交性正则化卷积核来提升面部表情识别的准确率，在FER-2013数据集上表现优于基线方法1.087%。


<details>
  <summary>Details</summary>
Motivation: 在线学习中情感交互很重要，但现有面部表情识别方法很少利用卷积矩阵的正交性。正交性可以提取更多样化和有表现力的特征。

Method: 提出OCFER-Net，通过正则化器强制卷积核的正交性，从而提取更具多样性和表达力的特征。

Result: 在具有挑战性的FER-2013数据集上进行实验，结果显示性能优于基线方法1.087%。

Conclusion: 正交性约束能有效提升面部表情识别的性能，OCFER-Net在情感识别任务中表现出色。

Abstract: Recently, online learning is very popular, especially under the global epidemic of COVID-19. Besides knowledge distribution, emotion interaction is also very important. It can be obtained by employing Facial Expression Recognition (FER). Since the FER accuracy is substantial in assisting teachers to acquire the emotional situation, the project explores a series of FER methods and finds that few works engage in exploiting the orthogonality of convolutional matrix. Therefore, it enforces orthogonality on kernels by a regularizer, which extracts features with more diversity and expressiveness, and delivers OCFER-Net. Experiments are carried out on FER-2013, which is a challenging dataset. Results show superior performance over baselines by 1.087. The code of the research project is publicly available on https://github.com/YeeHoran/OCFERNet.

</details>


### [55] [Perceptual Region-Driven Infrared-Visible Co-Fusion for Extreme Scene Enhancement](https://arxiv.org/abs/2512.06400)
*Jing Tao,Yonghong Zong,Banglei Guana,Pengju Sun,Taihang Lei,Yang Shanga,Qifeng Yu*

Main category: cs.CV

TL;DR: 提出了一种基于区域感知的红外-可见光光谱融合框架，通过多曝光和多模态成像结合，在极端环境下保持可见特征几何保真度和热辐射信息


<details>
  <summary>Details</summary>
Motivation: 现有方法在融合红外和可见光谱时往往牺牲可见图像质量，影响测量精度，特别是在极端条件下

Method: 使用空间可变曝光相机进行多曝光和多模态成像，采用区域感知特征融合确保精确配准，结合自适应融合和对比度增强，通过结构相似性补偿机制优化光谱融合

Result: 在合成和真实数据上的实验表明，该方法在图像清晰度和性能方面优于现有最先进方法

Conclusion: 该框架能够有效解决极端环境下红外-可见光谱融合的挑战，为多模态成像提供了可靠解决方案

Abstract: In photogrammetry, accurately fusing infrared (IR) and visible (VIS) spectra while preserving the geometric fidelity of visible features and incorporating thermal radiation is a significant challenge, particularly under extreme conditions. Existing methods often compromise visible imagery quality, impacting measurement accuracy. To solve this, we propose a region perception-based fusion framework that combines multi-exposure and multi-modal imaging using a spatially varying exposure (SVE) camera. This framework co-fuses multi-modal and multi-exposure data, overcoming single-exposure method limitations in extreme environments. The framework begins with region perception-based feature fusion to ensure precise multi-modal registration, followed by adaptive fusion with contrast enhancement. A structural similarity compensation mechanism, guided by regional saliency maps, optimizes IR-VIS spectral integration. Moreover, the framework adapts to single-exposure scenarios for robust fusion across different conditions. Experiments conducted on both synthetic and real-world data demonstrate superior image clarity and improved performance compared to state-of-the-art methods, as evidenced by both quantitative and visual evaluations.

</details>


### [56] [Rethinking Training Dynamics in Scale-wise Autoregressive Generation](https://arxiv.org/abs/2512.06421)
*Gengze Zhou,Chongjian Ge,Hao Tan,Feng Liu,Yicong Hong*

Main category: cs.CV

TL;DR: 该论文提出了一种名为自回归精炼（SAR）的方法，通过交错尺度展开机制和对比性学生强制损失，解决自回归生成模型中的曝光偏差问题，显著提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 尺度级自回归模型存在曝光偏差问题，主要表现为训练-测试不匹配和尺度间学习难度不平衡，这影响了生成质量。

Method: 提出SAR方法，包含交错尺度展开（SSR）机制和对比性学生强制损失（CSFL）。SSR通过轻量级自回归展开让模型接触自身中间预测，对齐训练测试模式；CSFL为自生成上下文提供充分监督以确保稳定训练。

Result: 在预训练AR模型上应用SAR可一致提升生成质量，计算开销极小。例如在ImageNet 256数据集上，SAR使FlexVAR-d16的FID降低了5.2%（10个epoch，32xA100 GPU上5小时）。

Conclusion: SAR因其高效性、可扩展性和有效性，有望成为视觉自回归生成的可靠后训练方法。

Abstract: Recent advances in autoregressive (AR) generative models have produced increasingly powerful systems for media synthesis. Among them, next-scale prediction has emerged as a popular paradigm, where models generate images in a coarse-to-fine manner. However, scale-wise AR models suffer from exposure bias, which undermines generation quality. We identify two primary causes of this issue: (1) train-test mismatch, where the model must rely on its own imperfect predictions during inference, and (2) imbalance in scale-wise learning difficulty, where certain scales exhibit disproportionately higher optimization complexity. Through a comprehensive analysis of training dynamics, we propose Self-Autoregressive Refinement (SAR) to address these limitations. SAR introduces a Stagger-Scale Rollout (SSR) mechanism that performs lightweight autoregressive rollouts to expose the model to its own intermediate predictions, thereby aligning train-test patterns, and a complementary Contrastive Student-Forcing Loss (CSFL) that provides adequate supervision for self-generated contexts to ensure stable training. Experimental results show that applying SAR to pretrained AR models consistently improves generation quality with minimal computational overhead. For instance, SAR yields a 5.2% FID reduction on FlexVAR-d16 trained on ImageNet 256 within 10 epochs (5 hours on 32xA100 GPUs). Given its efficiency, scalability, and effectiveness, we expect SAR to serve as a reliable post-training method for visual autoregressive generation.

</details>


### [57] [A Perception CNN for Facial Expression Recognition](https://arxiv.org/abs/2512.06422)
*Chunwei Tian,Jingyuan Xie,Lingjun Li,Wangmeng Zuo,Yanning Zhang,David Zhang*

Main category: cs.CV

TL;DR: 提出了一种用于面部表情识别的感知CNN（PCNN），通过并行网络学习局部面部特征，并利用多域交互机制融合局部和全局特征，在多个数据集上取得优越性能。


<details>
  <summary>Details</summary>
Motivation: 传统卷积神经网络在面部表情识别中可能忽略面部分割的影响，无法有效捕捉面部表情的细微变化。

Method: 1. 使用五个并行网络同时学习基于眼睛、脸颊和嘴巴的局部面部特征；2. 采用多域交互机制注册和融合局部器官特征与全局面部结构特征；3. 设计两阶段损失函数来约束感知信息的准确性和重建图像的质量。

Result: PCNN在多个实验室和真实世界面部表情识别基准数据集（CK+、JAFFE、FER2013、FERPlus、RAF-DB和遮挡与姿态变化数据集）上取得了优越的结果。

Conclusion: PCNN通过局部特征学习和多域特征融合，能够有效捕捉面部表情的细微变化，在面部表情识别任务中表现出色。

Abstract: Convolutional neural networks (CNNs) can automatically learn data patterns to express face images for facial expression recognition (FER). However, they may ignore effect of facial segmentation of FER. In this paper, we propose a perception CNN for FER as well as PCNN. Firstly, PCNN can use five parallel networks to simultaneously learn local facial features based on eyes, cheeks and mouth to realize the sensitive capture of the subtle changes in FER. Secondly, we utilize a multi-domain interaction mechanism to register and fuse between local sense organ features and global facial structural features to better express face images for FER. Finally, we design a two-phase loss function to restrict accuracy of obtained sense information and reconstructed face images to guarantee performance of obtained PCNN in FER. Experimental results show that our PCNN achieves superior results on several lab and real-world FER benchmarks: CK+, JAFFE, FER2013, FERPlus, RAF-DB and Occlusion and Pose Variant Dataset. Its code is available at https://github.com/hellloxiaotian/PCNN.

</details>


### [58] [DragMesh: Interactive 3D Generation Made Easy](https://arxiv.org/abs/2512.06424)
*Tianshan Zhang,Zeyu Zhang,Hao Tang*

Main category: cs.CV

TL;DR: DragMesh是一个实时交互式3D关节运动生成框架，通过解耦运动学推理和运动生成，解决了现有方法在物理一致性和实时性之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 当前3D生成模型在静态内容创建方面表现出色，但在理解物体如何移动和响应交互方面仍面临挑战。现有关节运动方法要么物理一致但速度慢，要么生成快速但违反基本运动学约束。

Method: 1) 通过解耦语义意图推理和几何回归来推断潜在关节参数；2) 开发基于对偶四元数的VAE模型(DQ-VAE)生成完整运动轨迹；3) 使用FiLM条件注入在DQ-VAE的每一层确保运动学约束；4) 采用数值稳定的叉积损失保证轴对齐。

Result: DragMesh实现了实时性能，能够在无需重新训练的情况下对新颖物体进行合理的生成式关节运动，为生成式3D智能迈出了实用的一步。

Conclusion: 该框架通过解耦设计和持续的运动学指导，在保持物理一致性的同时实现了实时交互，解决了生成式3D关节运动的关键挑战。

Abstract: While generative models have excelled at creating static 3D content, the pursuit of systems that understand how objects move and respond to interactions remains a fundamental challenge. Current methods for articulated motion lie at a crossroads: they are either physically consistent but too slow for real-time use, or generative but violate basic kinematic constraints. We present DragMesh, a robust framework for real-time interactive 3D articulation built around a lightweight motion generation core. Our core contribution is a novel decoupled kinematic reasoning and motion generation framework. First, we infer the latent joint parameters by decoupling semantic intent reasoning (which determines the joint type) from geometric regression (which determines the axis and origin using our Kinematics Prediction Network (KPP-Net)). Second, to leverage the compact, continuous, and singularity-free properties of dual quaternions for representing rigid body motion, we develop a novel Dual Quaternion VAE (DQ-VAE). This DQ-VAE receives these predicted priors, along with the original user drag, to generate a complete, plausible motion trajectory. To ensure strict adherence to kinematics, we inject the joint priors at every layer of the DQ-VAE's non-autoregressive Transformer decoder using FiLM (Feature-wise Linear Modulation) conditioning. This persistent, multi-scale guidance is complemented by a numerically-stable cross-product loss to guarantee axis alignment. This decoupled design allows DragMesh to achieve real-time performance and enables plausible, generative articulation on novel objects without retraining, offering a practical step toward generative 3D intelligence. Code: https://github.com/AIGeeksGroup/DragMesh. Website: https://aigeeksgroup.github.io/DragMesh.

</details>


### [59] [When Gender is Hard to See: Multi-Attribute Support for Long-Range Recognition](https://arxiv.org/abs/2512.06426)
*Nzakiese Mbongo,Kailash A. Hambarde,Hugo Proença*

Main category: cs.CV

TL;DR: 提出了一种双路径transformer框架，利用CLIP联合建模视觉和属性线索，用于远距离性别识别，在多个指标上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 远距离图像中的性别识别由于空间分辨率有限、视角变化和面部线索丢失而具有挑战性，需要新的解决方案。

Method: 采用双路径框架：直接视觉路径通过选择性微调CLIP图像编码器上层，属性介导路径从软生物特征提示推断性别。结合空间通道注意力模块增强判别性定位。

Result: 在构建的U-DetAGReID数据集上实验表明，该方法在macro-F1、准确率和AUC等指标上超越最先进方法，对距离、角度和高度变化具有鲁棒性。

Conclusion: 语言引导的双路径学习为无约束远距离场景下的负责任性别识别提供了原则性、可扩展的基础。

Abstract: Accurate gender recognition from extreme long-range imagery remains a challenging problem due to limited spatial resolution, viewpoint variability, and loss of facial cues. For such purpose, we present a dual-path transformer framework that leverages CLIP to jointly model visual and attribute-driven cues for gender recognition at a distance. The framework integrates two complementary streams: (1) a direct visual path that refines a pre-trained CLIP image encoder through selective fine-tuning of its upper layers, and (2) an attribute-mediated path that infers gender from a set of soft-biometric prompts (e.g., hairstyle, clothing, accessories) aligned in the CLIP text-image space. Spatial channel attention modules further enhance discriminative localization under occlusion and low resolution. To support large-scale evaluation, we construct U-DetAGReID, a unified long-range gender dataset derived from DetReIDx and AG-ReID.v2, harmonized under a consistent ternary labeling scheme (Male, Female, Unknown). Extensive experiments suggest that the proposed solution surpasses state-of-the-art person-attribute and re-identification baselines across multiple metrics (macro-F1, accuracy, AUC), with consistent robustness to distance, angle, and height variations. Qualitative attention visualizations confirm interpretable attribute localization and responsible abstention behavior. Our results show that language-guided dual-path learning offers a principled, extensible foundation for responsible gender recognition in unconstrained long-range scenarios.

</details>


### [60] [Automated Deep Learning Estimation of Anthropometric Measurements for Preparticipation Cardiovascular Screening](https://arxiv.org/abs/2512.06434)
*Lucas R. Mareque,Ricardo L. Armentano,Leandro J. Cymberknop*

Main category: cs.CV

TL;DR: 本文提出了一种基于深度学习的全自动方法，从2D合成人体图像中估计五个关键人体测量指标，用于运动员心血管风险评估。


<details>
  <summary>Details</summary>
Motivation: 传统的人工人体测量方法劳动密集、依赖操作者且难以扩展，无法满足大规模运动员筛查的需求。

Method: 使用从3D人体网格生成的100,000张合成图像数据集，训练和评估了VGG19、ResNet50和DenseNet121等深度学习模型进行回归分析。

Result: 所有模型都实现了亚厘米级精度，其中ResNet50表现最佳，在所有测量指标上的平均MAE为0.668厘米。

Conclusion: 深度学习能够提供大规模准确的人体测量数据，可作为运动员筛查协议的有效补充工具。

Abstract: Preparticipation cardiovascular examination (PPCE) aims to prevent sudden cardiac death (SCD) by identifying athletes with structural or electrical cardiac abnormalities. Anthropometric measurements, such as waist circumference, limb lengths, and torso proportions to detect Marfan syndrome, can indicate elevated cardiovascular risk. Traditional manual methods are labor-intensive, operator-dependent, and challenging to scale. We present a fully automated deep-learning approach to estimate five key anthropometric measurements from 2D synthetic human body images. Using a dataset of 100,000 images derived from 3D body meshes, we trained and evaluated VGG19, ResNet50, and DenseNet121 with fully connected layers for regression. All models achieved sub-centimeter accuracy, with ResNet50 performing best, achieving a mean MAE of 0.668 cm across all measurements. Our results demonstrate that deep learning can deliver accurate anthropometric data at scale, offering a practical tool to complement athlete screening protocols. Future work will validate the models on real-world images to extend applicability.

</details>


### [61] [AGORA: Adversarial Generation Of Real-time Animatable 3D Gaussian Head Avatars](https://arxiv.org/abs/2512.06438)
*Ramazan Fazylov,Sergey Zagoruyko,Aleksandr Parkin,Stamatis Lefkimmiatis,Ivan Laptev*

Main category: cs.CV

TL;DR: AGORA是一个基于3D高斯泼溅和GAN的动画化3D人体化身生成框架，通过轻量级变形分支实现身份保持的精细表情控制，支持实时CPU推理。


<details>
  <summary>Details</summary>
Motivation: 现有基于NeRF的方法渲染速度慢且存在动态不一致问题，而3DGS方法通常仅限于静态头部生成，缺乏动态控制能力。需要开发既能保持高质量又能实现实时动画控制的方法。

Method: 将3D高斯泼溅扩展到生成对抗网络中，引入FLAME条件化的轻量级变形分支预测每个高斯的残差，采用双判别器训练方案利用参数化网格的合成渲染来保证表情保真度。

Result: 在表情准确性上优于最先进的NeRF方法，在单GPU上实现250+ FPS渲染，在纯CPU推理下达到约9 FPS，是首个实用的纯CPU动画化3DGS化身合成方法。

Conclusion: 这项工作向实用高性能数字人迈出了重要一步，实现了视觉真实且精确可控的化身生成。

Abstract: The generation of high-fidelity, animatable 3D human avatars remains a core challenge in computer graphics and vision, with applications in VR, telepresence, and entertainment. Existing approaches based on implicit representations like NeRFs suffer from slow rendering and dynamic inconsistencies, while 3D Gaussian Splatting (3DGS) methods are typically limited to static head generation, lacking dynamic control. We bridge this gap by introducing AGORA, a novel framework that extends 3DGS within a generative adversarial network to produce animatable avatars. Our key contribution is a lightweight, FLAME-conditioned deformation branch that predicts per-Gaussian residuals, enabling identity-preserving, fine-grained expression control while allowing real-time inference. Expression fidelity is enforced via a dual-discriminator training scheme leveraging synthetic renderings of the parametric mesh. AGORA generates avatars that are not only visually realistic but also precisely controllable. Quantitatively, we outperform state-of-the-art NeRF-based methods on expression accuracy while rendering at 250+ FPS on a single GPU, and, notably, at $\sim$9 FPS under CPU-only inference - representing, to our knowledge, the first demonstration of practical CPU-only animatable 3DGS avatar synthesis. This work represents a significant step toward practical, high-performance digital humans. Project website: https://ramazan793.github.io/AGORA/

</details>


### [62] [Towards Stable Cross-Domain Depression Recognition under Missing Modalities](https://arxiv.org/abs/2512.06447)
*Jiuyi Chen,Mingkui Tan,Haifeng Lu,Qiuna Xu,Zhihua Wang,Runhao Zeng,Xiping Hu*

Main category: cs.CV

TL;DR: 提出了一个基于多模态大语言模型的稳定跨域抑郁症识别框架SCD-MLLM，通过多源数据输入适配器和模态感知自适应融合模块，有效处理异构数据并增强对缺失模态的稳定性。


<details>
  <summary>Details</summary>
Motivation: 抑郁症检测具有重要公共卫生意义，但现有方法缺乏统一框架，对现实世界中常见的缺失模态数据稳定性不足。

Method: SCD-MLLM框架包含：1）多源数据输入适配器（MDIA），使用掩码机制和任务特定提示将异构输入转换为统一token序列；2）模态感知自适应融合模块（MAFM），通过共享投影机制自适应整合视听特征。

Result: 在五个公开抑郁症数据集上的实验表明，SCD-MLLM在完整和部分模态设置下均优于SOTA模型和主流商业LLM，展现出优异的跨域泛化能力和对缺失模态的稳定性。

Conclusion: SCD-MLLM为多模态抑郁症检测提供了一个统一且稳定的框架，在现实应用中具有重要价值。

Abstract: Depression poses serious public health risks, including suicide, underscoring the urgency of timely and scalable screening. Multimodal automatic depression detection (ADD) offers a promising solution; however, widely studied audio- and video-based ADD methods lack a unified, generalizable framework for diverse depression recognition scenarios and show limited stability to missing modalities, which are common in real-world data. In this work, we propose a unified framework for Stable Cross-Domain Depression Recognition based on Multimodal Large Language Model (SCD-MLLM). The framework supports the integration and processing of heterogeneous depression-related data collected from varied sources while maintaining stability in the presence of incomplete modality inputs. Specifically, SCD-MLLM introduces two key components: (i) Multi-Source Data Input Adapter (MDIA), which employs masking mechanism and task-specific prompts to transform heterogeneous depression-related inputs into uniform token sequences, addressing inconsistency across diverse data sources; (ii) Modality-Aware Adaptive Fusion Module (MAFM), which adaptively integrates audio and visual features via a shared projection mechanism, enhancing resilience under missing modality conditions. e conduct comprehensive experiments under multi-dataset joint training settings on five publicly available and heterogeneous depression datasets from diverse scenarios: CMDC, AVEC2014, DAIC-WOZ, DVlog, and EATD. Across both complete and partial modality settings, SCD-MLLM outperforms state-of-the-art (SOTA) models as well as leading commercial LLMs (Gemini and GPT), demonstrating superior cross-domain generalization, enhanced ability to capture multimodal cues of depression, and strong stability to missing modality cases in real-world applications.

</details>


### [63] [Sanvaad: A Multimodal Accessibility Framework for ISL Recognition and Voice-Based Interaction](https://arxiv.org/abs/2512.06485)
*Kush Revankar,Shreyas Deshpande,Araham Sayeed,Ansh Tandale,Sarika Bobde*

Main category: cs.CV

TL;DR: Sanvaad是一个轻量级多模态无障碍框架，支持聋哑用户、视障用户和普通听力人群之间的实时双向交流。


<details>
  <summary>Details</summary>
Motivation: 解决现有工具仅支持单向交互的局限性，促进不同能力人群之间的包容性沟通。

Method: 使用MediaPipe地标点构建ISL识别模块，集成语音转手语组件和面向视障用户的无屏幕语音界面，通过Streamlit实现统一界面。

Result: 开发出能够在边缘设备上流畅运行的轻量级系统，支持实时双向沟通。

Conclusion: Sanvaad通过结合轻量级计算机视觉和语音处理工具，为包容性沟通提供了实用且无障碍的解决方案。

Abstract: Communication between deaf users, visually im paired users, and the general hearing population often relies on tools that support only one direction of interaction. To address this limitation, this work presents Sanvaad, a lightweight multimodal accessibility framework designed to support real time, two-way communication. For deaf users, Sanvaad includes an ISL recognition module built on MediaPipe landmarks. MediaPipe is chosen primarily for its efficiency and low computational load, enabling the system to run smoothly on edge devices without requiring dedicated hardware. Spoken input from a phone can also be translated into sign representations through a voice-to-sign component that maps detected speech to predefined phrases and produces corresponding GIFs or alphabet-based visualizations. For visually impaired users, the framework provides a screen free voice interface that integrates multilingual speech recognition, text summarization, and text-to-speech generation. These components work together through a Streamlit-based interface, making the system usable on both desktop and mobile environments. Overall, Sanvaad aims to offer a practical and accessible pathway for inclusive communication by combining lightweight computer vision and speech processing tools within a unified framework.

</details>


### [64] [Method of UAV Inspection of Photovoltaic Modules Using Thermal and RGB Data Fusion](https://arxiv.org/abs/2512.06504)
*Andrii Lysyi,Anatoliy Sachenko,Pavlo Radiuk,Mykola Lysyi,Oleksandr Melnychenko,Diana Zahorodnia*

Main category: cs.CV

TL;DR: 开发了一个智能集成框架，用于光伏基础设施的自动化检测，通过多模态融合和自适应重采集机制，显著提升了检测精度和效率。


<details>
  <summary>Details</summary>
Motivation: 解决传统光伏检测方法中存在的热调色板偏差、数据冗余和高通信带宽需求等关键问题，实现从数据采集到维护警报生成的完全自动化监控工作流。

Method: 采用协同架构：首先通过强制表示一致性学习调色板不变的热嵌入，然后通过门控机制与对比归一化的RGB流融合；结合基于罗德里格斯更新的自适应重采集控制器进行异常确认，以及使用DBSCAN算法对地理空间重复警报进行去重。

Result: 在公开PVF-10基准测试中达到0.903的mAP@0.5，比单模态基线提升12-15%；现场验证显示96%的召回率，去重过程减少15-20%的重复误报，相关性遥测使空中数据传输减少60-70%。

Conclusion: 本研究建立了一个强大的主动光伏检测新范式，系统验证表明其具备实际应用准备度，显著提升了光伏电站的安全性和运营效率。

Abstract: The subject of this research is the development of an intelligent, integrated framework for the automated inspection of photovoltaic (PV) infrastructure that addresses the critical shortcomings of conventional methods, including thermal palette bias, data redundancy, and high communication bandwidth requirements. The goal of this study is to design, develop, and validate a comprehensive, multi-modal system that fully automates the monitoring workflow, from data acquisition to the generation of actionable, geo-located maintenance alerts, thereby enhancing plant safety and operational efficiency. The methods employed involve a synergistic architecture that begins with a palette-invariant thermal embedding, learned by enforcing representational consistency, which is fused with a contrast-normalized RGB stream via a gated mechanism. This is supplemented by a closed-loop, adaptive re-acquisition controller that uses Rodrigues-based updates for targeted confirmation of ambiguous anomalies and a geospatial deduplication module that clusters redundant alerts using DBSCAN over the haversine distance. In conclusion, this study establishes a powerful new paradigm for proactive PV inspection, with the proposed system achieving a mean Average Precision (mAP@0.5) of 0.903 on the public PVF-10 benchmark, a significant 12-15% improvement over single-modality baselines. Field validation confirmed the system's readiness, achieving 96% recall, while the de-duplication process reduced duplicate-induced false positives by 15-20%, and relevance-only telemetry cut airborne data transmission by 60-70%.

</details>


### [65] [ShadowWolf -- Automatic Labelling, Evaluation and Model Training Optimised for Camera Trap Wildlife Images](https://arxiv.org/abs/2512.06521)
*Jens Dede,Anna Förster*

Main category: cs.CV

TL;DR: 本文提出名为ShadowWolf的统一框架，通过整合优化AI模型训练和评估阶段，解决野生动物监测中环境变化带来的挑战，实现动态模型重训练以减少标注工作量并提升监测准确性。


<details>
  <summary>Details</summary>
Motivation: 全球人口增长导致野生动物栖息地减少，人兽冲突加剧，需要有效的野生动物监测方法。传统AI训练面临环境变化（如地形、天气、光照、距离）带来的模型鲁棒性挑战。

Method: 提出ShadowWolf统一框架，整合图像采集、标注和模型训练阶段，支持动态模型重训练以适应环境变化和应用需求，实现现场模型自适应。

Result: 该框架能够减少标注工作量，提高模型在真实场景中的适应性和准确性，提升野生动物监测系统的效率。

Conclusion: ShadowWolf框架通过自适应和统一的方法，增强了野生动物监测系统的准确性和效率，为更有效的保护工作提供了可扩展的解决方案。

Abstract: The continuous growth of the global human population is leading to the expansion of human habitats, resulting in decreasing wildlife spaces and increasing human-wildlife interactions. These interactions can range from minor disturbances, such as raccoons in urban waste bins, to more severe consequences, including species extinction. As a result, the monitoring of wildlife is gaining significance in various contexts. Artificial intelligence (AI) offers a solution by automating the recognition of animals in images and videos, thereby reducing the manual effort required for wildlife monitoring. Traditional AI training involves three main stages: image collection, labelling, and model training. However, the variability, for example, in the landscape (e.g., mountains, open fields, forests), weather (e.g., rain, fog, sunshine), lighting (e.g., day, night), and camera-animal distances presents significant challenges to model robustness and adaptability in real-world scenarios.
  In this work, we propose a unified framework, called ShadowWolf, designed to address these challenges by integrating and optimizing the stages of AI model training and evaluation. The proposed framework enables dynamic model retraining to adjust to changes in environmental conditions and application requirements, thereby reducing labelling efforts and allowing for on-site model adaptation. This adaptive and unified approach enhances the accuracy and efficiency of wildlife monitoring systems, promoting more effective and scalable conservation efforts.

</details>


### [66] [On The Role of K-Space Acquisition in MRI Reconstruction Domain-Generalization](https://arxiv.org/abs/2512.06530)
*Mohammed Wattad,Tamir Shor,Alex Bronstein*

Main category: cs.CV

TL;DR: 本文研究表明学习到的k空间采样模式在加速MRI中具有跨域泛化能力，并提出了一种通过引入采集不确定性来增强域鲁棒性的新方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多关注针对单一数据集或模态优化的采集模式，而忽视了它们在跨成像域的可迁移性。本文旨在探索学习到的k空间采样在域偏移下的泛化能力。

Method: 通过系统评估不同数据集和采集范式，验证学习采样模式的跨域泛化性能；提出一种新方法，在训练中引入采集不确定性，通过随机扰动k空间轨迹来模拟扫描仪和成像条件的变化。

Result: 实验结果表明，使用学习采样模式训练的模型在跨域设置下表现出更好的泛化能力，提出的不确定性增强方法有效提升了域鲁棒性。

Conclusion: k空间轨迹设计不应仅仅被视为加速机制，而应作为提高MRI重建域泛化能力的主动自由度。

Abstract: Recent work has established learned k-space acquisition patterns as a promising direction for improving reconstruction quality in accelerated Magnetic Resonance Imaging (MRI). Despite encouraging results, most existing research focuses on acquisition patterns optimized for a single dataset or modality, with limited consideration of their transferability across imaging domains. In this work, we demonstrate that the benefits of learned k-space sampling can extend beyond the training domain, enabling superior reconstruction performance under domain shifts. Our study presents two main contributions. First, through systematic evaluation across datasets and acquisition paradigms, we show that models trained with learned sampling patterns exhibitimproved generalization under cross-domain settings. Second, we propose a novel method that enhances domain robustness by introducing acquisition uncertainty during training-stochastically perturbing k-space trajectories to simulate variability across scanners and imaging conditions. Our results highlight the importance of treating kspace trajectory design not merely as an acceleration mechanism, but as an active degree of freedom for improving domain generalization in MRI reconstruction.

</details>


### [67] [Novel Deep Learning Architectures for Classification and Segmentation of Brain Tumors from MRI Images](https://arxiv.org/abs/2512.06531)
*Sayan Das,Arghadip Biswas*

Main category: cs.CV

TL;DR: 该论文提出了两种新型深度学习架构SAETCN和SAS-Net，用于脑肿瘤的自动分类和分割，在验证数据集上分别达到99.38%的分类准确率和99.23%的像素分割精度。


<details>
  <summary>Details</summary>
Motivation: 脑肿瘤对人类生命构成严重威胁，早期准确检测对诊断和治疗至关重要。传统的人工检测MRI图像耗时且困难，现有模型泛化能力不足，在验证数据上表现不佳。

Method: 提出了两种新型深度学习架构：(a) SAETCN（自注意力增强肿瘤分类网络）用于脑肿瘤分类；(b) SAS-Net（自注意力分割网络）用于脑肿瘤精确分割。模型在包含3种肿瘤类型（胶质瘤、脑膜瘤、垂体瘤）和非肿瘤病例的数据集上训练。

Result: SAETCN在验证数据集上达到99.38%的分类准确率，SAS-Net达到99.23%的整体像素分割精度，成为少数能够准确检测脑肿瘤的新型深度学习架构之一。

Conclusion: 提出的两种深度学习架构在脑肿瘤检测任务上表现出色，为计算机辅助诊断系统提供了有效的解决方案，有助于实现脑肿瘤的早期自动检测。

Abstract: Brain tumors pose a significant threat to human life, therefore it is very much necessary to detect them accurately in the early stages for better diagnosis and treatment. Brain tumors can be detected by the radiologist manually from the MRI scan images of the patients. However, the incidence of brain tumors has risen amongst children and adolescents in recent years, resulting in a substantial volume of data, as a result, it is time-consuming and difficult to detect manually. With the emergence of Artificial intelligence in the modern world and its vast application in the medical field, we can make an approach to the CAD (Computer Aided Diagnosis) system for the early detection of Brain tumors automatically. All the existing models for this task are not completely generalized and perform poorly on the validation data. So, we have proposed two novel Deep Learning Architectures - (a) SAETCN (Self-Attention Enhancement Tumor Classification Network) for the classification of different kinds of brain tumors. We have achieved an accuracy of 99.38% on the validation dataset making it one of the few Novel Deep learning-based architecture that is capable of detecting brain tumors accurately. We have trained the model on the dataset, which contains images of 3 types of tumors (glioma, meningioma, and pituitary tumors) and non-tumor cases. and (b) SAS-Net (Self-Attentive Segmentation Network) for the accurate segmentation of brain tumors. We have achieved an overall pixel accuracy of 99.23%.

</details>


### [68] [Bridging spatial awareness and global context in medical image segmentation](https://arxiv.org/abs/2512.06560)
*Dalia Alzu'bi,A. Ben Hamza*

Main category: cs.CV

TL;DR: U-CycleMLP是一种新型U型编码器-解码器网络，通过位置注意力权重激励块、密集空洞块和通道CycleMLP块等技术，在保持轻量级架构的同时提升医学图像分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有分割模型难以有效捕捉局部和全局上下文信息，导致边界像素丢失和分割错误，需要平衡分割精度和计算效率的解决方案。

Method: 编码器使用位置注意力权重激励块、密集空洞块和下采样操作学习多尺度上下文特征；解码器通过上采样、密集空洞块和特征融合机制重建高分辨率分割掩码；在跳跃连接中引入通道CycleMLP块增强特征集成。

Result: 在三个基准数据集上的实验结果表明，U-CycleMLP相比最先进方法具有竞争优势，在所有数据集上实现更好的分割精度，能捕捉细粒度解剖结构，并在不同医学成像模态中表现出鲁棒性。

Conclusion: U-CycleMLP通过创新的架构设计有效解决了医学图像分割中的局部-全局信息平衡问题，消融研究验证了核心组件对提升分割精度的重要性。

Abstract: Medical image segmentation is a fundamental task in computer-aided diagnosis, requiring models that balance segmentation accuracy and computational efficiency. However, existing segmentation models often struggle to effectively capture local and global contextual information, leading to boundary pixel loss and segmentation errors. In this paper, we propose U-CycleMLP, a novel U-shaped encoder-decoder network designed to enhance segmentation performance while maintaining a lightweight architecture. The encoder learns multiscale contextual features using position attention weight excitation blocks, dense atrous blocks, and downsampling operations, effectively capturing both local and global contextual information. The decoder reconstructs high-resolution segmentation masks through upsampling operations, dense atrous blocks, and feature fusion mechanisms, ensuring precise boundary delineation. To further refine segmentation predictions, channel CycleMLP blocks are incorporated into the decoder along the skip connections, enhancing feature integration while maintaining linear computational complexity relative to input size. Experimental results, both quantitative and qualitative, across three benchmark datasets demonstrate the competitive performance of U-CycleMLP in comparison with state-of-the-art methods, achieving better segmentation accuracy across all datasets, capturing fine-grained anatomical structures, and demonstrating robustness across different medical imaging modalities. Ablation studies further highlight the importance of the model's core architectural components in enhancing segmentation accuracy.

</details>


### [69] [SUGAR: A Sweeter Spot for Generative Unlearning of Many Identities](https://arxiv.org/abs/2512.06562)
*Dung Thuy Nguyen,Quang Nguyen,Preston K. Robinette,Eli Jiang,Taylor T. Johnson,Kevin Leach*

Main category: cs.CV

TL;DR: SUGAR是一个可扩展的生成式遗忘框架，能够在无需重新训练整个模型的情况下，同时或顺序移除多个身份，并保持模型质量和多样性。


<details>
  <summary>Details</summary>
Motivation: 随着3D感知生成模型的发展，需要解决用户同意和从模型输出空间中移除特定个体的能力问题。

Method: SUGAR为每个身份学习个性化的替代潜在表示，将重建结果转向视觉上连贯的替代方案，并引入持续效用保持目标以防止随着更多身份被遗忘而导致的性能下降。

Result: SUGAR在移除多达200个身份方面实现了最先进的性能，与现有基线相比，保留效用提高了700%。

Conclusion: SUGAR框架有效解决了生成模型中的身份移除问题，提供了一种可扩展的解决方案，同时保持了模型的质量和多样性。

Abstract: Recent advances in 3D-aware generative models have enabled high-fidelity image synthesis of human identities. However, this progress raises urgent questions around user consent and the ability to remove specific individuals from a model's output space. We address this by introducing SUGAR, a framework for scalable generative unlearning that enables the removal of many identities (simultaneously or sequentially) without retraining the entire model. Rather than projecting unwanted identities to unrealistic outputs or relying on static template faces, SUGAR learns a personalized surrogate latent for each identity, diverting reconstructions to visually coherent alternatives while preserving the model's quality and diversity. We further introduce a continual utility preservation objective that guards against degradation as more identities are forgotten. SUGAR achieves state-of-the-art performance in removing up to 200 identities, while delivering up to a 700% improvement in retention utility compared to existing baselines. Our code is publicly available at https://github.com/judydnguyen/SUGAR-Generative-Unlearn.

</details>


### [70] [GNC-Pose: Geometry-Aware GNC-PnP for Accurate 6D Pose Estimation](https://arxiv.org/abs/2512.06565)
*Xiujin Liu*

Main category: cs.CV

TL;DR: GNC-Pose是一种无需学习的单目6D物体姿态估计方法，通过渲染初始化、几何感知对应点加权和鲁棒GNC优化，在YCB数据集上取得了与学习方法和非学习方法相竞争的精度。


<details>
  <summary>Details</summary>
Motivation: 为了解决纹理物体6D姿态估计问题，作者希望开发一种完全无需学习的方法，不依赖训练数据、学习特征或类别特定先验，提供简单、鲁棒且实用的解决方案。

Method: 1. 通过特征匹配和渲染对齐获得粗略的2D-3D对应点；2. 基于GNC原则引入几何感知的聚类加权机制，根据模型3D结构一致性分配鲁棒的逐点置信度；3. 使用LM优化进一步提高精度。

Result: 在YCB物体和模型集上测试，GNC-Pose尽管不需要学习特征、训练数据或类别特定先验，但与基于学习和非学习的方法相比达到了竞争性的精度。

Conclusion: GNC-Pose通过几何先验和加权策略显著提高了优化稳定性，在严重异常值污染下仍能保持鲁棒性，为无学习6D姿态估计提供了有效的解决方案。

Abstract: We present GNC--Pose, a fully learning--free monocular 6D object pose estimation pipeline for textured objects that combines rendering--based initialization, geometry--aware correspondence weighting, and robust GNC optimization. Starting from coarse 2D--3D correspondences obtained through feature matching and rendering--based alignment, our method builds upon the Graduated Non--Convexity (GNC) principle and introduces a geometry--aware, cluster--based weighting mechanism that assigns robust per point confidence based on the 3D structural consistency of the model. This geometric prior and weighting strategy significantly stabilizes the optimization under severe outlier contamination. A final LM refinement further improve accuracy. We tested GNC--Pose on The YCB Object and Model Set, despite requiring no learned features, training data, or category-specific priors, GNC--Pose achieves competitive accuracy compared with both learning-based and learning--free methods, and offers a simple, robust, and practical solution for learning-free 6D pose estimation.

</details>


### [71] [Proof of Concept for Mammography Classification with Enhanced Compactness and Separability Modules](https://arxiv.org/abs/2512.06575)
*Fariza Dahes*

Main category: cs.CV

TL;DR: 本研究验证并扩展了医学图像分类方法框架，将改进的ConvNeXt Tiny架构应用于乳腺X光分类，评估了GAGM和SEVector模块的有效性，但发现FSL损失函数在乳腺X光分类中效果不明显。


<details>
  <summary>Details</summary>
Motivation: 验证先前在阿尔茨海默症MRI分类中表现良好的改进ConvNeXt Tiny架构是否可迁移到乳腺X光分类任务，并扩展原框架的功能。

Method: 使用Kaggle整合的INbreast、MIAS和DDSM乳腺X光数据集，比较基线CNN、ConvNeXt Tiny和InceptionV3骨干网络，集成GAGM和SEVector模块，进行多指标评估和特征可解释性分析。

Result: GAGM和SEVector模块能有效增强特征区分度并减少假阴性（特别是恶性病例），但FSL损失函数在乳腺X光分类中未带来可测量的改进。

Conclusion: 成功验证了框架在乳腺X光分类中的部分适用性，提出了需要探索新方法来改善恶性与良性病例区分度的未来方向。

Abstract: This study presents a validation and extension of a recent methodological framework for medical image classification. While an improved ConvNeXt Tiny architecture, integrating Global Average and Max Pooling fusion (GAGM), lightweight channel attention (SEVector), and Feature Smoothing Loss (FSL), demonstrated promising results on Alzheimer MRI under CPU friendly conditions, our work investigates its transposability to mammography classification. Using a Kaggle dataset that consolidates INbreast, MIAS, and DDSM mammography collections, we compare a baseline CNN, ConvNeXt Tiny, and InceptionV3 backbones enriched with GAGM and SEVector modules. Results confirm the effectiveness of GAGM and SEVector in enhancing feature discriminability and reducing false negatives, particularly for malignant cases. In our experiments, however, the Feature Smoothing Loss did not yield measurable improvements under mammography classification conditions, suggesting that its effectiveness may depend on specific architectural and computational assumptions. Beyond validation, our contribution extends the original framework through multi metric evaluation (macro F1, per class recall variance, ROC/AUC), feature interpretability analysis (Grad CAM), and the development of an interactive dashboard for clinical exploration. As a perspective, we highlight the need to explore alternative approaches to improve intra class compactness and inter class separability, with the specific goal of enhancing the distinction between malignant and benign cases in mammography classification.

</details>


### [72] [MedGRPO: Multi-Task Reinforcement Learning for Heterogeneous Medical Video Understanding](https://arxiv.org/abs/2512.06581)
*Yuhao Su,Anwesa Choudhuri,Zhongpai Gao,Benjamin Planche,Van Nguyen Nguyen,Meng Zheng,Yuhan Shen,Arun Innanje,Terrence Chen,Ehsan Elhamifar,Ziyan Wu*

Main category: cs.CV

TL;DR: 本文提出了MedVidBench基准和MedGRPO强化学习框架，解决了医学视频理解中的空间精度、时间推理和临床语义问题，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在医学视频理解方面存在困难，需要处理空间精度、时间推理和临床语义等关键挑战。

Method: 1) 构建MedVidBench基准，包含531,850个视频-指令对；2) 提出MedGRPO强化学习框架，包含跨数据集奖励归一化和医学LLM评估器；3) 在Qwen2.5-VL-7B模型上进行监督微调和强化学习训练。

Result: 监督微调后的Qwen2.5-VL-7B在所有任务上都显著优于GPT-4.1和Gemini-2.5-Flash，MedGRPO框架进一步提升了定位和字幕生成任务的性能。

Conclusion: 该研究为医学领域的视觉语言模型建立了基础基准和稳健的训练方法，推动了该领域的发展。

Abstract: Large vision-language models struggle with medical video understanding, where spatial precision, temporal reasoning, and clinical semantics are critical. To address this, we first introduce \textbf{MedVidBench}, a large-scale benchmark of 531,850 video-instruction pairs across 8 medical sources spanning video, segment, and frame-level tasks, curated through a rigorous quality assurance pipeline with expert-guided prompting and dual-model validation. While supervised fine-tuning on MedVidBench yields noticeable gains, standard Reinforcement Learning (RL) fails due to imbalanced reward scales across datasets, which destabilizes optimization and leads to training collapse. To overcome this, we introduce \textbf{MedGRPO}, a novel RL framework for balanced multi-dataset training with two key innovations: (1) \emph{cross-dataset reward normalization} that maps each dataset's median performance to a common reward value, ensuring fair optimization regardless of difficulty, and (2) a \emph{medical LLM judge} that evaluates caption quality on five clinical dimensions through comparative similarity scoring. Supervised fine-tuning Qwen2.5-VL-7B on MedVidBench substantially outperforms GPT-4.1 and Gemini-2.5-Flash across all tasks, demonstrating MedVidBench's efficacy, while our MedGRPO framework further improves upon the SFT baseline across grounding and captioning tasks. Our work establishes a foundational benchmark and robust training methodology for advancing vision-language models in medical domains. Our project website is available at https://yuhaosu.github.io/MedGRPO/.

</details>


### [73] [More than Segmentation: Benchmarking SAM 3 for Segmentation, 3D Perception, and Reconstruction in Robotic Surgery](https://arxiv.org/abs/2512.07596)
*Wenzhen Dong,Jieming Yu,Yiming Huang,Hongqiu Wang,Lei Zhu,Albert C. S. Chung,Hongliang Ren,Long Bai*

Main category: cs.CV

TL;DR: SAM 3在机器人辅助手术中的实证评估显示，相比SAM和SAM 2在图像和视频分割方面有显著提升，但语言提示在手术领域表现欠佳，需要领域特定训练。3D重建能力在单目深度估计和器械重建方面表现良好，但在复杂动态手术场景中仍有局限。


<details>
  <summary>Details</summary>
Motivation: 评估SAM 3在机器人辅助手术中的性能，特别是其零样本分割能力（包括点、边界框和语言提示）以及3D感知能力，探索其在动态视频跟踪和3D重建方面的有效性。

Method: 使用MICCAI EndoVis 2017和EndoVis 2018基准测试SAM 3的图像和视频分割性能，同时在SCARED、StereoMIS和EndoNeRF数据集上进行零样本评估，测试其单目深度估计和3D器械重建能力。

Result: SAM 3在空间提示下的图像和视频分割明显优于SAM和SAM 2，语言提示在手术领域表现不佳。3D重建方面展示了良好的单目深度估计和器械重建能力，但在复杂动态手术场景中存在局限性。

Conclusion: SAM 3在机器人辅助手术中展现出显著进步，特别是在空间提示分割和3D重建方面，但语言提示需要领域特定优化，复杂手术场景的3D重建仍需改进。

Abstract: The recent Segment Anything Model (SAM) 3 has introduced significant advancements over its predecessor, SAM 2, particularly with the integration of language-based segmentation and enhanced 3D perception capabilities. SAM 3 supports zero-shot segmentation across a wide range of prompts, including point, bounding box, and language-based prompts, allowing for more flexible and intuitive interactions with the model. In this empirical evaluation, we assess the performance of SAM 3 in robot-assisted surgery, benchmarking its zero-shot segmentation with point and bounding box prompts and exploring its effectiveness in dynamic video tracking, alongside its newly introduced language prompt segmentation. While language prompts show potential, their performance in the surgical domain is currently suboptimal, highlighting the need for further domain-specific training. Additionally, we investigate SAM 3's 3D reconstruction abilities, demonstrating its capacity to process surgical scene data and reconstruct 3D anatomical structures from 2D images. Through comprehensive testing on the MICCAI EndoVis 2017 and EndoVis 2018 benchmarks, SAM 3 shows clear improvements over SAM and SAM 2 in both image and video segmentation under spatial prompts, while zero-shot evaluations on SCARED, StereoMIS, and EndoNeRF indicate strong monocular depth estimation and realistic 3D instrument reconstruction, yet also reveal remaining limitations in complex, highly dynamic surgical scenes.

</details>


### [74] [From Remote Sensing to Multiple Time Horizons Forecasts: Transformers Model for CyanoHAB Intensity in Lake Champlain](https://arxiv.org/abs/2512.06598)
*Muhammad Adil,Patrick J. Clemins,Andrew W. Schroth,Panagiotis D. Oikonomou,Donna M. Rizzo,Peter D. F. Isles,Xiaohan Zhang,Kareem I. Hannoun,Scott Turnbull,Noah B. Beckage,Asim Zia,Safwan Wshah*

Main category: cs.CV

TL;DR: 该研究提出了一种结合Transformer和BiLSTM的遥感预测框架，能够提前14天预测蓝藻水华强度，在稀疏卫星数据条件下取得了良好的预测性能。


<details>
  <summary>Details</summary>
Motivation: 蓝藻有害水华对水生生态系统和公共健康构成严重威胁，而传统现场观测数据稀疏，遥感技术为监测和预测提供了可扩展的解决方案。

Method: 使用Cyanobacterial Assessment Network的蓝藻指数数据和MODIS卫星温度数据，通过两阶段预处理填补数据缺失，然后采用Transformer-BiLSTM模型捕捉卫星时间序列中的长期依赖关系和序列动态。

Result: 模型在不同预测时间尺度上表现优异，1天、2天、3天预测的F1分数分别为89.5%、86.4%、85.5%，14天预测的F1分数为78.9%，AUC为82.6%。

Conclusion: 该模型能够从稀疏卫星数据中捕捉复杂的时空动态，为蓝藻水华管理提供可靠的早期预警。

Abstract: Cyanobacterial Harmful Algal Blooms (CyanoHABs) pose significant threats to aquatic ecosystems and public health globally. Lake Champlain is particularly vulnerable to recurring CyanoHAB events, especially in its northern segment: Missisquoi Bay, St. Albans Bay, and Northeast Arm, due to nutrient enrichment and climatic variability. Remote sensing provides a scalable solution for monitoring and forecasting these events, offering continuous coverage where in situ observations are sparse or unavailable. In this study, we present a remote sensing only forecasting framework that combines Transformers and BiLSTM to predict CyanoHAB intensities up to 14 days in advance. The system utilizes Cyanobacterial Index data from the Cyanobacterial Assessment Network and temperature data from Moderate Resolution Imaging Spectroradiometer satellites to capture long range dependencies and sequential dynamics in satellite time series. The dataset is very sparse, missing more than 30% of the Cyanobacterial Index data and 90% of the temperature data. A two stage preprocessing pipeline addressed data gaps by applying forward fill and weighted temporal imputation at the pixel level, followed by smoothing to reduce the discontinuities of CyanoHAB events. The raw dataset is transformed into meaningful features through equal frequency binning for the Cyanobacterial Index values and extracted temperature statistics. Transformer BiLSTM model demonstrates strong forecasting performance across multiple horizons, achieving F1 scores of 89.5%, 86.4%, and 85.5% at one, two, and three-day forecasts, respectively, and maintaining an F1 score of 78.9% with an AUC of 82.6% at the 14-day horizon. These results confirm the model's ability to capture complex spatiotemporal dynamics from sparse satellite data and to provide reliable early warning for CyanoHABs management.

</details>


### [75] [sim2art: Accurate Articulated Object Modeling from a Single Video using Synthetic Training Data Only](https://arxiv.org/abs/2512.07698)
*Arslan Artykov,Corentin Sautier,Vincent Lepetit*

Main category: cs.CV

TL;DR: 本文提出了首个从单目视频中联合预测部件分割和关节参数的数据驱动方法，适用于自由移动相机拍摄的场景。


<details>
  <summary>Details</summary>
Motivation: 理解铰接物体是机器人和数字孪生创建中的基本挑战，现有方法主要依赖多视角系统、物体扫描或静态相机，缺乏从单目视频中直接理解铰接物体的实用方案。

Method: 基于合成数据训练的数据驱动方法，直接从自由移动相机拍摄的单目视频中联合预测部件分割和关节参数。

Result: 仅使用合成数据训练的方法在真实世界物体上表现出强大的泛化能力，为铰接物体理解提供了可扩展的实用解决方案。

Conclusion: 该方法可直接处理日常录制的视频，适用于动态环境中的实时应用，是铰接物体理解领域的重要进展。

Abstract: Understanding articulated objects is a fundamental challenge in robotics and digital twin creation. To effectively model such objects, it is essential to recover both part segmentation and the underlying joint parameters. Despite the importance of this task, previous work has largely focused on setups like multi-view systems, object scanning, or static cameras. In this paper, we present the first data-driven approach that jointly predicts part segmentation and joint parameters from monocular video captured with a freely moving camera. Trained solely on synthetic data, our method demonstrates strong generalization to real-world objects, offering a scalable and practical solution for articulated object understanding. Our approach operates directly on casually recorded video, making it suitable for real-time applications in dynamic environments. Project webpage: https://aartykov.github.io/sim2art/

</details>


### [76] [Learning Relative Gene Expression Trends from Pathology Images in Spatial Transcriptomics](https://arxiv.org/abs/2512.06612)
*Kazuya Nishimura,Haruka Hirose,Ryoma Bise,Kaito Shiku,Yasuhiro Kojima*

Main category: cs.CV

TL;DR: 该论文提出了一种新的目标函数STRank，用于从病理图像中学习基因的相对表达模式而非绝对表达值，以解决基因表达估计中的随机噪声和批次效应问题。


<details>
  <summary>Details</summary>
Motivation: 由于测序技术的复杂性和细胞间的内在变异性，观察到的基因表达包含随机噪声和批次效应，准确估计绝对表达值具有挑战性。因此，需要一种更稳健的方法来学习相对表达模式。

Method: 基于相对表达水平在独立实验中表现一致性的假设，提出STRank损失函数，通过建模基因间关系来学习相对表达模式，而非绝对数值。

Result: 在合成数据集和真实数据集上的实验证明了该方法的有效性，能够有效应对噪声和批次效应的影响。

Conclusion: STRank方法通过关注相对表达模式而非绝对数值，提供了一种更稳健的基因表达估计解决方案，代码已开源。

Abstract: Gene expression estimation from pathology images has the potential to reduce the RNA sequencing cost. Point-wise loss functions have been widely used to minimize the discrepancy between predicted and absolute gene expression values. However, due to the complexity of the sequencing techniques and intrinsic variability across cells, the observed gene expression contains stochastic noise and batch effects, and estimating the absolute expression values accurately remains a significant challenge. To mitigate this, we propose a novel objective of learning relative expression patterns rather than absolute levels. We assume that the relative expression levels of genes exhibit consistent patterns across independent experiments, even when absolute expression values are affected by batch effects and stochastic noise in tissue samples. Based on the assumption, we model the relation and propose a novel loss function called STRank that is robust to noise and batch effects. Experiments using synthetic datasets and real datasets demonstrate the effectiveness of the proposed method. The code is available at https://github.com/naivete5656/STRank.

</details>


### [77] [UltrasODM: A Dual Stream Optical Flow Mamba Network for 3D Freehand Ultrasound Reconstruction](https://arxiv.org/abs/2512.07756)
*Mayank Anand,Ujair Alam,Surya Prakash,Priya Shukla,Gora Chand Nandi,Domenec Puig*

Main category: cs.CV

TL;DR: UltrasODM是一个双流框架，通过校准的每帧不确定性、基于显著性的诊断和可操作的提示来辅助超声医师在采集过程中，减少重建误差并提高临床实用性。


<details>
  <summary>Details</summary>
Motivation: 临床超声采集高度依赖操作者，快速探头运动和亮度波动常导致重建误差，降低信任度和临床效用。

Method: UltrasODM整合了三个模块：(i)基于运动相似性的对比排序模块；(ii)融合双Mamba时序模块的光流流用于稳健的6-DoF姿态估计；(iii)结合贝叶斯不确定性、临床校准阈值和显著性图的HITL层。

Result: 在临床自由手超声数据集上评估，UltrasODM相对于UltrasOM将漂移减少15.2%，距离误差减少12.1%，Hausdorff距离减少10.1%，同时生成每帧不确定性和显著性输出。

Conclusion: UltrasODM通过强调透明度和临床医生反馈，提高了重建可靠性，支持更安全、更可信的临床工作流程。

Abstract: Clinical ultrasound acquisition is highly operator-dependent, where rapid probe motion and brightness fluctuations often lead to reconstruction errors that reduce trust and clinical utility. We present UltrasODM, a dual-stream framework that assists sonographers during acquisition through calibrated per-frame uncertainty, saliency-based diagnostics, and actionable prompts. UltrasODM integrates (i) a contrastive ranking module that groups frames by motion similarity, (ii) an optical-flow stream fused with Dual-Mamba temporal modules for robust 6-DoF pose estimation, and (iii) a Human-in-the-Loop (HITL) layer combining Bayesian uncertainty, clinician-calibrated thresholds, and saliency maps highlighting regions of low confidence. When uncertainty exceeds the threshold, the system issues unobtrusive alerts suggesting corrective actions such as re-scanning highlighted regions or slowing the sweep. Evaluated on a clinical freehand ultrasound dataset, UltrasODM reduces drift by 15.2%, distance error by 12.1%, and Hausdorff distance by 10.1% relative to UltrasOM, while producing per-frame uncertainty and saliency outputs. By emphasizing transparency and clinician feedback, UltrasODM improves reconstruction reliability and supports safer, more trustworthy clinical workflows. Our code is publicly available at https://github.com/AnandMayank/UltrasODM.

</details>


### [78] [Hierarchical Deep Learning for Diatom Image Classification: A Multi-Level Taxonomic Approach](https://arxiv.org/abs/2512.06613)
*Yueying Ke*

Main category: cs.CV

TL;DR: 本文提出了一种分层卷积网络，通过将分类学层次结构嵌入神经网络架构，联合预测硅藻的类别、目、科、属和种，在保持物种级准确率的同时显著提高了上层分类级别的性能，并使错误分类更具生物学意义。


<details>
  <summary>Details</summary>
Motivation: 传统硅藻分类方法依赖专家，现有深度学习方法多采用平面分类仅预测单一分类级别。本研究旨在探索将分类学层次结构融入神经网络架构是否能同时提高准确性和错误定位能力。

Method: 设计了具有五个级联头部的分层卷积网络，每个头部接收共享骨干特征和来自更高层级的概率分布，使用二进制掩码在训练和推理过程中限制预测到有效后代。使用包含1,456张硅藻图像的数据集进行对比实验。

Result: 分层模型在物种级达到69.4%准确率（与平面基线相当），但在所有上层分类级别均优于基线。92.5%的错误物种分类在属级被正确预测（平面基线为67.2%），平均分类距离减少38.2%。

Conclusion: 分层模型通过自上而下的约束掩码和自下而上的梯度传播机制，实现了更稳健、可解释且与生物学对齐的多层次分类预测，显著提高了分类性能。

Abstract: Accurate taxonomic identification of diatoms is essential for aquatic ecosystem monitoring, yet conventional methods depend heavily on expert taxonomists. Recent deep learning approaches improve automation, but most treat diatom recognition as flat classification predicting only one taxonomic rank. We investigate whether embedding taxonomic hierarchy into neural network architectures can improve both accuracy and error locality.
  We introduce a hierarchical convolutional network with five cascaded heads that jointly predict class, order, family, genus, and species. Each head receives shared backbone features and probability distributions from higher levels, with binary masks restricting predictions to valid descendants during training and inference. Using a filtered dataset of 1,456 diatom images covering 82 species, we compare hierarchical and flat models under identical settings.
  The hierarchical model matches flat baselines at species level (69.4% accuracy) while outperforming at all upper taxonomic levels. When species predictions fail, errors remain taxonomically local: 92.5 % of misclassified species are correctly predicted at genus level, versus 67.2% for flat baselines. The hierarchical model reduces mean taxonomic distance by 38.2% (1.209 vs. 1.955).
  Progressive training reveals bidirectional mechanisms: hierarchical constraint masks operate top-down to constrain prediction space, while gradients from fine-grained levels propagate bottom-up through the shared backbone, refining features. This improves class accuracy from 96.2% to 99.5% and yields 6-8% gains at upper levels, producing more robust, interpretable, and biologically aligned predictions for multi-level taxonomic classification.

</details>


### [79] [Masked Autoencoder Pretraining on Strong-Lensing Images for Joint Dark-Matter Model Classification and Super-Resolution](https://arxiv.org/abs/2512.06642)
*Achmad Ardani Prasha,Clavino Ourizqi Rachmadi,Muhamad Fauzan Ibnu Syahlan,Naufal Rahfi Anugerah,Nanda Garin Raditya,Putri Amelia,Sabrina Laila Mutiara,Hilman Syachr Ramadhan*

Main category: cs.CV

TL;DR: 该论文提出了一种基于掩码自编码器（MAE）的预训练策略，用于从模拟的强引力透镜图像中学习可泛化的表示，以支持暗物质模型分类和图像超分辨率两个下游任务。


<details>
  <summary>Details</summary>
Motivation: 强引力透镜可以揭示星系中暗物质子结构的影响，但从噪声大、分辨率低的图像中分析这些效应具有挑战性。需要一种能够从物理丰富的模拟数据中学习通用表示的方法，以支持多种分析任务。

Method: 使用掩码自编码器（MAE）在DeepLense ML4SCI基准的模拟强透镜图像上进行预训练，然后针对两个下游任务（暗物质模型分类和图像超分辨率）分别对编码器进行微调。通过调整掩码比例来优化性能。

Result: 在90%掩码比例下，微调后的分类器达到宏观AUC 0.968和准确率88.65%，优于从零开始训练的ViT（AUC 0.957，准确率82.46%）。超分辨率任务（16x16到64x64）中，MAE预训练模型的PSNR约为33 dB，SSIM为0.961，略优于从零训练。

Conclusion: MAE预训练在物理丰富的模拟数据上提供了一个灵活、可重用的编码器，适用于多种强透镜分析任务，展示了掩码比例在分类和重建任务之间的权衡关系。

Abstract: Strong gravitational lensing can reveal the influence of dark-matter substructure in galaxies, but analyzing these effects from noisy, low-resolution images poses a significant challenge. In this work, we propose a masked autoencoder (MAE) pretraining strategy on simulated strong-lensing images from the DeepLense ML4SCI benchmark to learn generalizable representations for two downstream tasks: (i) classifying the underlying dark matter model (cold dark matter, axion-like, or no substructure) and (ii) enhancing low-resolution lensed images via super-resolution. We pretrain a Vision Transformer encoder using a masked image modeling objective, then fine-tune the encoder separately for each task. Our results show that MAE pretraining, when combined with appropriate mask ratio tuning, yields a shared encoder that matches or exceeds a ViT trained from scratch. Specifically, at a 90% mask ratio, the fine-tuned classifier achieves macro AUC of 0.968 and accuracy of 88.65%, compared to the scratch baseline (AUC 0.957, accuracy 82.46%). For super-resolution (16x16 to 64x64), the MAE-pretrained model reconstructs images with PSNR ~33 dB and SSIM 0.961, modestly improving over scratch training. We ablate the MAE mask ratio, revealing a consistent trade-off: higher mask ratios improve classification but slightly degrade reconstruction fidelity. Our findings demonstrate that MAE pretraining on physics-rich simulations provides a flexible, reusable encoder for multiple strong-lensing analysis tasks.

</details>


### [80] [TextMamba: Scene Text Detector with Mamba](https://arxiv.org/abs/2512.06657)
*Qiyan Zhao,Yue Yan,Da-Han Wang*

Main category: cs.CV

TL;DR: 提出基于Mamba的场景文本检测器，通过集成选择机制和注意力层增强长序列特征提取能力，在多个基准测试中达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 解决Transformer在场景文本检测中建模长距离依赖时的信息遗忘和无关表征关注问题，利用Mamba的选择机制改进特征提取

Method: 集成Mamba的选择机制与注意力层，采用Top_k算法选择关键信息，设计双尺度前馈网络和嵌入金字塔增强模块进行多尺度特征融合

Result: 在CTW1500、TotalText和ICDAR19ArT上分别达到89.7%、89.2%和78.5%的F-measure

Conclusion: 提出的Mamba-based方法在场景文本检测中表现出优越的长距离依赖建模能力，实现了竞争性的性能表现

Abstract: In scene text detection, Transformer-based methods have addressed the global feature extraction limitations inherent in traditional convolution neural network-based methods. However, most directly rely on native Transformer attention layers as encoders without evaluating their cross-domain limitations and inherent shortcomings: forgetting important information or focusing on irrelevant representations when modeling long-range dependencies for text detection. The recently proposed state space model Mamba has demonstrated better long-range dependencies modeling through a linear complexity selection mechanism. Therefore, we propose a novel scene text detector based on Mamba that integrates the selection mechanism with attention layers, enhancing the encoder's ability to extract relevant information from long sequences. We adopt the Top\_k algorithm to explicitly select key information and reduce the interference of irrelevant information in Mamba modeling. Additionally, we design a dual-scale feed-forward network and an embedding pyramid enhancement module to facilitate high-dimensional hidden state interactions and multi-scale feature fusion. Our method achieves state-of-the-art or competitive performance on various benchmarks, with F-measures of 89.7\%, 89.2\%, and 78.5\% on CTW1500, TotalText, and ICDAR19ArT, respectively. Codes will be available.

</details>


### [81] [Personalized Image Descriptions from Attention Sequences](https://arxiv.org/abs/2512.06662)
*Ruoyu Xue,Hieu Le,Jingyi Xu,Sounak Mondal,Abe Leite,Gregory Zelinsky,Minh Hoai,Dimitris Samaras*

Main category: cs.CV

TL;DR: DEPER模型通过显式建模个性化观看行为（包括视觉注意力和语言风格）来生成更符合人类偏好的图像描述，相比仅关注语言风格的现有方法，在四个数据集上平均提升了24%的性能。


<details>
  <summary>Details</summary>
Motivation: 现有图像描述个性化模型仅关注语言风格，而忽略了不同人观看图像的视觉注意力模式差异。人们观看同一图像时会关注不同区域、对象和细节，并以不同的语言风格描述，这导致了描述的巨大变异性。

Method: 提出DEPER方法，学习一个主体嵌入来同时捕捉语言风格和观看行为，通过辅助注意力预测任务进行指导。使用轻量级适配器将这些嵌入与冻结的视觉语言模型对齐，实现少样本个性化而无需重新训练。

Result: 在涵盖不同观看任务和长短描述的四个数据集上，DEPER实现了24%的平均提升，表明建模个性化注意力可以产生更符合人类偏好和更高质量的描述。

Conclusion: 理解人们如何观看图像有助于预测他们会说什么；在感知中建模人类多样性可以提升多模态系统的性能和人类对齐度。

Abstract: People can view the same image differently: they focus on different regions, objects, and details in varying orders and describe them in distinct linguistic styles. This leads to substantial variability in image descriptions. However, existing models for personalized image description focus on linguistic style alone, with no prior work leveraging individual viewing patterns. We address this gap by explicitly modeling personalized viewing behavior as a core factor in description generation. Our method, DEPER (DEscription-PERception persona encoder), learns a subject embedding that captures both linguistic style and viewing behavior, guided by an auxiliary attention-prediction task. A lightweight adapter aligns these embeddings with a frozen vision-language model, enabling few-shot personalization without retraining. Across four datasets spanning diverse viewing tasks and both short and detailed descriptions, DEPER achieves a 24% average improvement, showing that modeling personalized attention produces more human-aligned and high-quality descriptions. We posit that understanding how people see helps predict what they say; modeling human diversity in perception can improve both performance and human alignment in multimodal systems.

</details>


### [82] [CoT4Det: A Chain-of-Thought Framework for Perception-Oriented Vision-Language Tasks](https://arxiv.org/abs/2512.06663)
*Yu Qi,Yumeng Zhang,Chenting Gong,Xiao Tan,Weiming Zhang,Wei Zhang,Jingdong Wang*

Main category: cs.CV

TL;DR: CoT4Det是一种将感知任务重新表述为分类、计数和定位三个可解释步骤的策略，显著提升大视觉语言模型在感知任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 大视觉语言模型在感知任务（如目标检测、语义分割）上的表现远不如任务专用专家模型，特别是在密集场景和小目标检测方面存在明显不足。

Method: 提出Chain-of-Thought for Detection (CoT4Det)方法，将感知任务分解为三个步骤：分类（识别物体类别）、计数（统计物体数量）和定位（确定物体位置），这些步骤更符合大视觉语言模型的推理能力。

Result: 在标准Qwen2.5-VL-7B-Instruct模型上，CoT4Det将COCO2017 val数据集的mAP从19.0%提升至33.0%，在RefCOCO系列上超越基线2%，在Flickr30k entities上超越基线19%。

Conclusion: CoT4Det方法能显著提升大视觉语言模型的感知性能，同时不损害其通用视觉语言能力，在各种感知基准测试中取得了有竞争力的结果。

Abstract: Large Vision-Language Models (LVLMs) have demonstrated remarkable success in a broad range of vision-language tasks, such as general visual question answering and optical character recognition (OCR). However, their performance on perception-centric tasks -- such as object detection, semantic segmentation, and depth estimation -- remains significantly inferior to that of task-specific expert models. For example, Qwen2.5-VL-7B-Instruct achieves only 19% mAP on COCO2017 val, particularly struggling with dense scenes and small object recall. In this work, we introduce Chain-of-Thought for Detection (CoT4Det), a simple but efficient strategy that reformulates perception tasks into three interpretable steps: classification, counting, and grounding -- each more naturally aligned with the reasoning capabilities of LVLMs. Extensive experiments demonstrate that our method significantly improves perception performance without compromising general vision language capabilities. With a standard Qwen2.5-VL-7B-Instruct, CoT4Det boosts mAP from 19.0% to 33.0% on COCO2017 val and achieves competitive results across a variety of perception benchmarks, outperforming baselines by +2% on RefCOCO series and 19% on Flickr30k entities.

</details>


### [83] [1 + 1 > 2: Detector-Empowered Video Large Language Model for Spatio-Temporal Grounding and Reasoning](https://arxiv.org/abs/2512.06673)
*Shida Gao,Feng Xue,Xiangfeng Wang,Anlong Ming,Teng Long,Yihua Shao,Haozhe Wang,Zhaowen Lin,Wei Wang,Nicu Sebe*

Main category: cs.CV

TL;DR: DEViL提出了一种结合视频大语言模型和开放词汇检测器的框架，通过引用语义令牌实现端到端学习，解决了传统自回归空间解码中的误差累积问题，并在时空定位任务上表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在处理时空定位任务时，将边界框作为文本令牌进行自回归生成，导致输出序列过长、空间误差随时间累积以及定位结果漂移的问题。

Method: DEViL框架将视频LLM与开放词汇检测器（OVD）耦合，通过引用语义令牌（RST）将用户查询转化为丰富的语义表示，并提出了管道挖掘时间正则化（TTReg）来确保时间一致性。

Result: 实验表明DEViL在多个细粒度视频理解任务上（特别是STVG和GroundedVQA）取得了强劲的性能表现。

Conclusion: DEViL通过端到端学习实现了更好的时空定位性能，解决了传统方法的误差累积问题，代码将在GitHub上发布。

Abstract: Spatio-temporal grounding and reasoning aims to locate the temporal segment and spatial region of an event in a video given a user query, while also reasoning about semantics such as causality, temporal order, and action relationships. To achieve this, current MLLMs primarily treats bounding boxes as text tokens and generates them autoregressively. However, such autoregressive spatial decoding leads to very-long output sequences, causing spatial errors to accumulated over time and the localization results to progressively drift across a video. To address this, we present a Detector-Empowered Video LLM, short for DEViL, which couples a Video LLM with an open-vocabulary detector (OVD). Specifically, the MLLM and detector are connected via a reference-semantic token (RST) that distills the user query into a rich semantic representation. Unlike tokens that merely serve as spatial prompts or segmentor switches, the RST functions as both a control signal and a replacement for the OVD's text embedding, enabling end-to-end learning of both referential understanding and spatial localization. Furthermore, we propose a tube-mined temporal regularization (TTReg) within OVD, which drives the OVD to generate temporally-consistent queries for target objects, thereby ensuring effective temporal association. Experiments demonstrate that DEViL achieves strong performance across various fine-grained video understanding tasks, particularly STVG and GroundedVQA. Code will be released on https://github.com/gaostar123/DeViL.

</details>


### [84] [RunawayEvil: Jailbreaking the Image-to-Video Generative Models](https://arxiv.org/abs/2512.06674)
*Songping Wang,Rufan Qian,Yueming Lyu,Qinglong Liu,Linzhuang Zou,Jie Qin,Songhua Liu,Caifeng Shan*

Main category: cs.CV

TL;DR: RunawayEvil是首个针对图像到视频生成模型的多模态越狱框架，具有动态进化能力，通过"策略-战术-行动"范式实现自我增强攻击，在商业I2V模型上达到最先进的攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 当前图像到视频生成系统的安全性研究不足，特别是对越狱攻击的脆弱性尚未充分探索，需要开发有效的漏洞分析工具。

Method: 基于"策略-战术-行动"范式构建框架，包含三个核心组件：策略感知命令单元（通过强化学习和LLM实现策略自进化）、多模态战术规划单元（生成协调的文本越狱指令和图像篡改指南）、战术行动单元（执行和评估多模态协调攻击）。

Result: 在Open-Sora 2.0和CogVideoX等商业I2V模型上实现最先进的攻击成功率，在COCO2017数据集上比现有方法高出58.5%到79%。

Conclusion: 该工作为I2V模型的漏洞分析提供了关键工具，为构建更鲁棒的视频生成系统奠定了基础。

Abstract: Image-to-Video (I2V) generation synthesizes dynamic visual content from image and text inputs, providing significant creative control. However, the security of such multimodal systems, particularly their vulnerability to jailbreak attacks, remains critically underexplored. To bridge this gap, we propose RunawayEvil, the first multimodal jailbreak framework for I2V models with dynamic evolutionary capability. Built on a "Strategy-Tactic-Action" paradigm, our framework exhibits self-amplifying attack through three core components: (1) Strategy-Aware Command Unit that enables the attack to self-evolve its strategies through reinforcement learning-driven strategy customization and LLM-based strategy exploration; (2) Multimodal Tactical Planning Unit that generates coordinated text jailbreak instructions and image tampering guidelines based on the selected strategies; (3) Tactical Action Unit that executes and evaluates the multimodal coordinated attacks. This self-evolving architecture allows the framework to continuously adapt and intensify its attack strategies without human intervention. Extensive experiments demonstrate RunawayEvil achieves state-of-the-art attack success rates on commercial I2V models, such as Open-Sora 2.0 and CogVideoX. Specifically, RunawayEvil outperforms existing methods by 58.5 to 79 percent on COCO2017. This work provides a critical tool for vulnerability analysis of I2V models, thereby laying a foundation for more robust video generation systems.

</details>


### [85] [EMGauss: Continuous Slice-to-3D Reconstruction via Dynamic Gaussian Modeling in Volume Electron Microscopy](https://arxiv.org/abs/2512.06684)
*Yumeng He,Zanwei Zhou,Yekun Zheng,Chen Liang,Yunbo Wang,Xiaokang Yang*

Main category: cs.CV

TL;DR: EMGauss是一个基于高斯泼溅的3D重建框架，通过将轴向切片序列建模为2D高斯点云的时间演化，解决了体积电子显微镜中各项异性结构的重建问题，无需大规模预训练即可实现连续切片合成。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法基于各项同性假设，但在形态学上各项异性的生物结构中表现不佳。体积电子显微镜存在采集权衡，导致轴向分辨率有限的各项异性体积，需要新的重建方法。

Method: 将切片到3D重建重新定义为基于高斯泼溅的3D动态场景渲染问题，使用教师-学生自举机制在数据稀疏区域增强保真度，利用未观测切片的高置信度预测作为伪监督信号。

Result: 与基于扩散和GAN的重建方法相比，EMGauss显著提高了插值质量，实现了连续切片合成，且无需大规模预训练。

Conclusion: EMGauss不仅解决了vEM中的各项异性重建问题，还为跨不同成像领域的切片到3D重建提供了通用解决方案。

Abstract: Volume electron microscopy (vEM) enables nanoscale 3D imaging of biological structures but remains constrained by acquisition trade-offs, leading to anisotropic volumes with limited axial resolution. Existing deep learning methods seek to restore isotropy by leveraging lateral priors, yet their assumptions break down for morphologically anisotropic structures. We present EMGauss, a general framework for 3D reconstruction from planar scanned 2D slices with applications in vEM, which circumvents the inherent limitations of isotropy-based approaches. Our key innovation is to reframe slice-to-3D reconstruction as a 3D dynamic scene rendering problem based on Gaussian splatting, where the progression of axial slices is modeled as the temporal evolution of 2D Gaussian point clouds. To enhance fidelity in data-sparse regimes, we incorporate a Teacher-Student bootstrapping mechanism that uses high-confidence predictions on unobserved slices as pseudo-supervisory signals. Compared with diffusion- and GAN-based reconstruction methods, EMGauss substantially improves interpolation quality, enables continuous slice synthesis, and eliminates the need for large-scale pretraining. Beyond vEM, it potentially provides a generalizable slice-to-3D solution across diverse imaging domains.

</details>


### [86] [Lightweight Wasserstein Audio-Visual Model for Unified Speech Enhancement and Separation](https://arxiv.org/abs/2512.06689)
*Jisoo Park,Seonghak Lee,Guisik Kim,Taewoo Kim,Junseok Kwon*

Main category: cs.CV

TL;DR: UniVoiceLite是一个轻量级无监督音视频框架，统一了语音增强和语音分离任务，利用唇部运动和面部身份特征，无需配对噪声-干净数据即可实现稳定性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界音频通常同时包含背景噪声和重叠说话人，传统方法将语音增强和语音分离视为独立任务，但需要统一解决方案。现有方法多为参数复杂的多阶段架构，依赖监督训练，限制了可扩展性和泛化能力。

Method: 提出UniVoiceLite框架，利用唇部运动和面部身份特征引导语音提取，采用Wasserstein距离正则化稳定潜在空间，实现无监督训练。

Result: 实验结果表明UniVoiceLite在噪声和多说话人场景下均表现出色，兼具高效性和鲁棒泛化能力。

Conclusion: 该工作成功实现了语音增强和语音分离的统一，提供了一种轻量级、无监督的解决方案，在真实场景中具有良好应用前景。

Abstract: Speech Enhancement (SE) and Speech Separation (SS) have traditionally been treated as distinct tasks in speech processing. However, real-world audio often involves both background noise and overlapping speakers, motivating the need for a unified solution. While recent approaches have attempted to integrate SE and SS within multi-stage architectures, these approaches typically involve complex, parameter-heavy models and rely on supervised training, limiting scalability and generalization. In this work, we propose UniVoiceLite, a lightweight and unsupervised audio-visual framework that unifies SE and SS within a single model. UniVoiceLite leverages lip motion and facial identity cues to guide speech extraction and employs Wasserstein distance regularization to stabilize the latent space without requiring paired noisy-clean data. Experimental results demonstrate that UniVoiceLite achieves strong performance in both noisy and multi-speaker scenarios, combining efficiency with robust generalization. The source code is available at https://github.com/jisoo-o/UniVoiceLite.

</details>


### [87] [The Role of Entropy in Visual Grounding: Analysis and Optimization](https://arxiv.org/abs/2512.06726)
*Shuo Li,Jiajun Sun,Zhihao Zhang,Xiaoran Fan,Senjie Jin,Hui Li,Yuming Yang,Junjie Ye,Lixing Shen,Tao Ji,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CV

TL;DR: 本文分析了视觉定位任务中熵的作用与特性，并提出了ECVGPO算法进行有效熵调控，实现了探索与利用的更好平衡，在多个基准测试中取得了广泛改进。


<details>
  <summary>Details</summary>
Motivation: 当前基于强化学习的多模态大语言模型微调在感知导向任务（如视觉定位）中，熵的作用特性和有效控制策略尚未充分探索。

Method: 提出ECVGPO（熵控制视觉定位策略优化）算法，通过熵控制来更好地平衡探索与利用之间的权衡。

Result: 实验表明ECVGPO在各种基准测试和模型上都取得了广泛的改进。

Conclusion: ECVGPO算法通过有效的熵调控机制，显著提升了视觉定位任务的性能表现。

Abstract: Recent advances in fine-tuning multimodal large language models (MLLMs) using reinforcement learning have achieved remarkable progress, particularly with the introduction of various entropy control techniques. However, the role and characteristics of entropy in perception-oriented tasks like visual grounding, as well as effective strategies for controlling it, remain largely unexplored. To address this issue, we focus on the visual grounding task and analyze the role and characteristics of entropy in comparison to reasoning tasks. Building on these findings, we introduce ECVGPO (Entropy Control Visual Grounding Policy Optimization), an interpretable algorithm designed for effective entropy regulation. Through entropy control, the trade-off between exploration and exploitation is better balanced. Experiments show that ECVGPO achieves broad improvements across various benchmarks and models.

</details>


### [88] [Graph Convolutional Long Short-Term Memory Attention Network for Post-Stroke Compensatory Movement Detection Based on Skeleton Data](https://arxiv.org/abs/2512.06736)
*Jiaxing Fan,Jiaojiao Liu,Wenkong Wang,Yang Zhang,Xin Ma,Jichen Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种基于骨骼数据的图卷积长短期记忆注意力网络（GCN-LSTM-ATT），用于检测中风患者的代偿性运动，其检测准确率达到0.8580，显著优于传统机器学习算法。


<details>
  <summary>Details</summary>
Motivation: 大多数中风患者存在上肢运动功能障碍，康复训练中普遍存在代偿性运动，这对患者的长期恢复不利，因此检测代偿性运动具有重要意义。

Method: 使用Kinect深度相机采集16名中风患者执行特定康复动作的骨骼数据，构建GCN-LSTM-ATT模型，并与支持向量机（SVM）、K近邻算法（KNN）和随机森林（RF）进行对比。

Result: GCN-LSTM-ATT模型的检测准确率达到0.8580，显著高于传统机器学习算法。消融实验表明模型的每个组件都对性能提升有显著贡献。

Conclusion: 该研究为中风后代偿性运动的检测提供了更精确和强大的工具，有望促进中风患者康复训练策略的优化。

Abstract: Most stroke patients experience upper limb motor dysfunction. Compensatory movements are prevalent during rehabilitation training, which is detrimental to patients' long-term recovery. Therefore, detecting compensatory movements is of great significance. In this study, a Graph Convolutional Long Short-Term Memory Attention Network (GCN-LSTM-ATT) based on skeleton data is proposed for the detection of compensatory movements after stroke. Sixteen stroke patients were selected in the research. The skeleton data of the patients performing specific rehabilitation movements were collected using the Kinect depth camera. After data processing, detection models were constructed respectively using the GCN-LSTM-ATT model, the Support Vector Machine(SVM), the K-Nearest Neighbor algorithm(KNN), and the Random Forest(RF). The results show that the detection accuracy of the GCN-LSTM-ATT model reaches 0.8580, which is significantly higher than that of traditional machine learning algorithms. Ablation experiments indicate that each component of the model contributes significantly to the performance improvement. These findings provide a more precise and powerful tool for the detection of compensatory movements after stroke, and are expected to facilitate the optimization of rehabilitation training strategies for stroke patients.

</details>


### [89] [FedSCAl: Leveraging Server and Client Alignment for Unsupervised Federated Source-Free Domain Adaptation](https://arxiv.org/abs/2512.06738)
*M Yashwanth,Sampath Koti,Arunabh Singh,Shyam Marjit,Anirban Chakraborty*

Main category: cs.CV

TL;DR: 本文提出了FedSCAl框架，用于解决联邦学习中的无源域自适应问题，通过服务器-客户端对齐机制来缓解客户端漂移，提高伪标签准确性。


<details>
  <summary>Details</summary>
Motivation: 联邦无源域自适应设置中，客户端存在显著的域间差异，且无法访问源数据集，导致现有方法在极端数据异构下产生不可靠的伪标签和客户端漂移问题。

Method: 提出FedSCAl框架，采用服务器-客户端对齐机制来正则化客户端更新，通过对齐客户端和服务器模型的预测来缓解客户端漂移。

Result: 在基准视觉数据集上的实验表明，FedSCAl在分类任务中 consistently 优于最先进的联邦学习方法。

Conclusion: FedSCAl通过服务器-客户端对齐机制有效解决了联邦无源域自适应中的客户端漂移问题，提高了伪标签准确性。

Abstract: We address the Federated source-Free Domain Adaptation (FFreeDA) problem, with clients holding unlabeled data with significant inter-client domain gaps. The FFreeDA setup constrains the FL frameworks to employ only a pre-trained server model as the setup restricts access to the source dataset during the training rounds. Often, this source domain dataset has a distinct distribution to the clients' domains. To address the challenges posed by the FFreeDA setup, adaptation of the Source-Free Domain Adaptation (SFDA) methods to FL struggles with client-drift in real-world scenarios due to extreme data heterogeneity caused by the aforementioned domain gaps, resulting in unreliable pseudo-labels. In this paper, we introduce FedSCAl, an FL framework leveraging our proposed Server-Client Alignment (SCAl) mechanism to regularize client updates by aligning the clients' and server model's predictions. We observe an improvement in the clients' pseudo-labeling accuracy post alignment, as the SCAl mechanism helps to mitigate the client-drift. Further, we present extensive experiments on benchmark vision datasets showcasing how FedSCAl consistently outperforms state-of-the-art FL methods in the FFreeDA setup for classification tasks.

</details>


### [90] [Task-Model Alignment: A Simple Path to Generalizable AI-Generated Image Detection](https://arxiv.org/abs/2512.06746)
*Ruoxin Chen,Jiahui Gao,Kaiqing Lin,Keyue Zhang,Yandan Zhao,Isabel Guan,Taiping Yao,Shouhong Ding*

Main category: cs.CV

TL;DR: 本文提出任务-模型对齐原则，将AIGI检测形式化为语义一致性检查和像素伪影检测两个互补任务，并设计了AlignGemini双分支检测器，在五个基准测试中实现了+9.5%的平均准确率提升。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉语言模型的AIGI检测方法存在资源消耗大和严重幻觉问题，核心问题在于语义导向的VLM缺乏对细粒度像素伪影的敏感性，而传统像素伪影检测器又缺乏语义感知能力。

Method: 提出任务-模型对齐原则，设计AlignGemini双分支检测器：一个分支使用纯语义监督微调VLM，另一个分支使用纯像素伪影监督训练像素伪影专家。通过正交监督在两个简化数据集上分别训练，实现互补检测。

Result: 在五个真实场景基准测试中，AlignGemini实现了平均准确率+9.5%的提升，证明了任务-模型对齐方法的有效性。

Conclusion: 任务-模型对齐是构建可泛化AIGI检测器的有效路径，通过将检测任务分解为互补的语义和像素层面任务，并分别匹配最适合的模型，可以克服单一模型的局限性。

Abstract: Vision Language Models (VLMs) are increasingly adopted for AI-generated images (AIGI) detection, yet converting VLMs into detectors requires substantial resource, while the resulting models still exhibit severe hallucinations. To probe the core issue, we conduct an empirical analysis and observe two characteristic behaviors: (i) fine-tuning VLMs on high-level semantic supervision strengthens semantic discrimination and well generalize to unseen data; (ii) fine-tuning VLMs on low-level pixel-artifact supervision yields poor transfer. We attribute VLMs' underperformance to task-model misalignment: semantics-oriented VLMs inherently lack sensitivity to fine-grained pixel artifacts, and semantically non-discriminative pixel artifacts thus exceeds their inductive biases. In contrast, we observe that conventional pixel-artifact detectors capture low-level pixel artifacts yet exhibit limited semantic awareness relative to VLMs, highlighting that distinct models are better matched to distinct tasks. In this paper, we formalize AIGI detection as two complementary tasks--semantic consistency checking and pixel-artifact detection--and show that neglecting either induces systematic blind spots. Guided by this view, we introduce the Task-Model Alignment principle and instantiate it as a two-branch detector, AlignGemini, comprising a VLM fine-tuned exclusively with pure semantic supervision and a pixel-artifact expert trained exclusively with pure pixel-artifact supervision. By enforcing orthogonal supervision on two simplified datasets, each branch trains to its strengths, producing complementary discrimination over semantic and pixel cues. On five in-the-wild benchmarks, AlignGemini delivers a +9.5 gain in average accuracy, supporting task-model alignment as an effective path to generalizable AIGI detection.

</details>


### [91] [UARE: A Unified Vision-Language Model for Image Quality Assessment, Restoration, and Enhancement](https://arxiv.org/abs/2512.06750)
*Weiqi Li,Xuanyu Zhang,Bin Chen,Jingfen Xie,Yan Wang,Kexin Zhang,Junlin Li,Li Zhang,Jian Zhang,Shijie Zhao*

Main category: cs.CV

TL;DR: UARE是首个统一处理图像质量评估、修复和增强的视觉语言模型，通过两阶段训练框架实现多任务协同训练，利用IQA指导提升图像恢复性能。


<details>
  <summary>Details</summary>
Motivation: 现有工作通常将图像质量评估和图像修复分开处理，但两者在概念上紧密相关。研究表明更强的理解能力可以提升生成性能，因此需要探索如何用IQA指导图像修复。

Method: 基于预训练的统一理解和生成模型，采用两阶段训练：1）渐进式从单类型失真到高阶混合退化训练；2）通过交错文本图像数据进行统一微调，将IQA信号与修复目标对齐。

Result: 在IQA、修复和增强任务上的大量实验证明了UARE的有效性，模型能够处理多种退化情况并提升恢复性能。

Conclusion: UARE成功实现了图像质量评估与修复的统一，通过多任务协同训练证明了IQA对图像恢复的指导作用，为低层视觉任务提供了新的解决方案。

Abstract: Image quality assessment (IQA) and image restoration are fundamental problems in low-level vision. Although IQA and restoration are closely connected conceptually, most existing work treats them in isolation. Recent advances in unified multimodal understanding-generation models demonstrate promising results and indicate that stronger understanding can improve generative performance. This motivates a single model that unifies IQA and restoration and explicitly studies how IQA can guide restoration, a setting that remains largely underexplored yet highly valuable. In this paper, we propose UARE, to our knowledge the first Unified vision-language model for image quality Assessment, Restoration, and Enhancement. Built on pretrained unified understanding and generation models, we introduce a two-stage training framework. First, a progressive, easy-to-hard schedule expands from single-type distortions to higher-order mixed degradations, enabling UARE to handle multiple degradations. Second, we perform unified fine-tuning of quality understanding and restoration with interleaved text-image data, aligning IQA signals with restoration objectives. Through multi-task co-training, UARE leverages IQA to boost restoration and enhancement performance. Extensive experiments across IQA, restoration, and enhancement tasks demonstrate the effectiveness of UARE. The code and models will be available at https://github.com/lwq20020127/UARE.

</details>


### [92] [VisChainBench: A Benchmark for Multi-Turn, Multi-Image Visual Reasoning Beyond Language Priors](https://arxiv.org/abs/2512.06759)
*Wenbo Lyu,Yingjun Du,Jinglin Zhao,Xianton Zhen,Ling Shao*

Main category: cs.CV

TL;DR: VisChainBench是一个大规模基准测试，旨在评估大型视觉语言模型在多图像、多轮次场景中进行多步视觉推理的能力，包含1,457个任务和超过20,000张图像。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注静态或水平比较，依赖语言线索，忽视了渐进式、上下文相关的推理和视觉到视觉的推理挑战。

Method: 使用多智能体生成流水线构建基准测试，涵盖三个不同领域（日常场景、工程故障排除等），模拟真实世界决策过程。

Result: 创建了包含1,457个任务和超过20,000张图像的大规模基准测试，具有高视觉多样性和受控的语言偏见。

Conclusion: VisChainBench填补了多图像多轮次场景评估的空白，为评估LVLMs的视觉推理能力提供了重要工具。

Abstract: Understanding multi-image, multi-turn scenarios is a critical yet underexplored capability for Large Vision-Language Models (LVLMs). Existing benchmarks predominantly focus on static or horizontal comparisons -- e.g., spotting visual differences or assessing appropriateness -- while relying heavily on language cues. Such settings overlook progressive, context-dependent reasoning and the challenge of visual-to-visual inference. To bridge this gap, we present VisChainBench, a large-scale benchmark designed to rigorously evaluate LVLMs' ability to perform multi-step visual reasoning across sequential, interdependent tasks with minimal language guidance. VisChainBench contains 1,457 tasks spanning over 20,000 images across three diverse domains (e.g., daily scenarios, engineering troubleshooting), structured to mimic real-world decision-making processes. Uniquely, the benchmark is constructed using a multi-agent generation pipeline, ensuring high visual diversity and controlled language bias. All the benchmark data and code for benchmark construction are available for viewing and download via following Link: https://huggingface.co/datasets/eyehole/VisChainBench

</details>


### [93] [JOCA: Task-Driven Joint Optimisation of Camera Hardware and Adaptive Camera Control Algorithms](https://arxiv.org/abs/2512.06763)
*Chengyang Yan,Mitch Bryson,Donald G. Dansereau*

Main category: cs.CV

TL;DR: 本文提出了一种联合优化相机硬件和自适应控制算法的统一框架，通过混合梯度优化和导数无关方法，提升下游视觉任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要优化制造时固定的相机参数，但许多参数（如曝光设置）需要在运行时自适应控制。单独优化静态和动态参数限制了感知性能的提升。

Method: 提出统一优化框架DF-Grad，结合梯度优化和导数无关方法，支持连续/离散参数、非可微图像形成过程和神经网络自适应控制算法。

Result: 实验表明该方法在低光照和快速运动等挑战性条件下优于单独优化静态和动态参数的基线方法。

Conclusion: 联合优化硬件参数和自适应控制算法能显著提升感知性能，为任务驱动的相机系统设计提供了统一方法。

Abstract: The quality of captured images strongly influences the performance of downstream perception tasks. Recent works on co-designing camera systems with perception tasks have shown improved task performance. However, most prior approaches focus on optimising fixed camera parameters set at manufacturing, while many parameters, such as exposure settings, require adaptive control at runtime. This paper introduces a method that jointly optimises camera hardware and adaptive camera control algorithms with downstream vision tasks. We present a unified optimisation framework that integrates gradient-based and derivative-free methods, enabling support for both continuous and discrete parameters, non-differentiable image formation processes, and neural network-based adaptive control algorithms. To address non-differentiable effects such as motion blur, we propose DF-Grad, a hybrid optimisation strategy that trains adaptive control networks using signals from a derivative-free optimiser alongside unsupervised task-driven learning. Experiments show that our method outperforms baselines that optimise static and dynamic parameters separately, particularly under challenging conditions such as low light and fast motion. These results demonstrate that jointly optimising hardware parameters and adaptive control algorithms improves perception performance and provides a unified approach to task-driven camera system design.

</details>


### [94] [Stitch and Tell: A Structured Multimodal Data Augmentation Method for Spatial Understanding](https://arxiv.org/abs/2512.06769)
*Hang Yin,Xiaomin He,PeiWen Yuan,Yiwei Li,Jiayi Shi,Wenxiao Fan,Shaoxiong Feng,Kan Li*

Main category: cs.CV

TL;DR: 提出了一种名为SiTe的简单、无需标注、即插即用的方法，通过将图像沿空间轴拼接并生成空间感知的文本描述，为视觉语言模型注入结构化空间监督，以解决空间幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型经常出现空间幻觉问题，即对图像中物体相对位置生成错误描述。作者认为这主要源于图像和文本之间的不对称性。

Method: SiTe方法通过拼接图像构造缝合图像-文本对，并基于缝合图像的布局生成空间感知的标题或问答对，无需依赖昂贵的先进模型或人工参与。

Result: 在三个架构、两个训练数据集和八个基准测试上的实验表明，SiTe显著提升了空间理解任务（如MME_Position +5.50%，Spatial-MM +4.19%），同时保持或改进了通用视觉语言基准的性能。

Conclusion: 明确将空间感知结构注入训练数据是缓解空间幻觉、提高空间理解能力的有效方法，同时能保持通用视觉语言能力。

Abstract: Existing vision-language models often suffer from spatial hallucinations, i.e., generating incorrect descriptions about the relative positions of objects in an image. We argue that this problem mainly stems from the asymmetric properties between images and text. To enrich the spatial understanding ability of vision-language models, we propose a simple, annotation-free, plug-and-play method named $\text{Stitch and Tell}$ (abbreviated as SiTe), which injects structured spatial supervision into data. It constructs stitched image-text pairs by stitching images along a spatial axis and generating spatially-aware captions or question answer pairs based on the layout of stitched image, without relying on costly advanced models or human involvement. We evaluate SiTe across three architectures including LLaVA-v1.5-7B, LLaVA-Qwen2-1.5B and HALVA-7B, two training datasets, and eight benchmarks. Experiments show that SiTe improves spatial understanding tasks such as $\text{MME}_{\text{Position}}$ (+5.50%) and Spatial-MM (+4.19%), while maintaining or improving performance on general vision-language benchmarks including COCO-QA (+1.02%) and MMBench (+4.76%). Our findings suggest that explicitly injecting spatially-aware structure into training data offers an effective way to mitigate spatial hallucinations and improve spatial understanding, while preserving general vision-language capabilities.

</details>


### [95] [RDSplat: Robust Watermarking Against Diffusion Editing for 3D Gaussian Splatting](https://arxiv.org/abs/2512.06774)
*Longjie Zhao,Ziming Hong,Zhenyang Ren,Runnan Chen,Mingming Gong,Tongliang Liu*

Main category: cs.CV

TL;DR: RDSplat是一种针对3D高斯泼溅(3DGS)的鲁棒水印技术，专门设计来抵抗基于扩散的编辑攻击，通过将水印嵌入到低频高斯分量中并结合对抗训练来提高水印的生存能力。


<details>
  <summary>Details</summary>
Motivation: 现有的3DGS水印方法对基于扩散的编辑攻击非常脆弱，这种攻击可以轻易擦除嵌入的来源信息，因此迫切需要开发能够内在抵抗此类攻击的3DGS水印技术。

Method: RDSplat采用多域框架，在3DGS空间中操作，通过协调协方差正则化和2D滤波将水印嵌入到扩散编辑保留的低频高斯分量中，并使用高斯模糊作为训练代理进行对抗性微调。

Result: 在三个基准数据集上的全面定量和定性评估表明，RDSplat在基于扩散的编辑下保持卓越的鲁棒性，同时保持水印不可见性，实现了最先进的性能。

Conclusion: RDSplat为3DGS提供了一种有效的版权保护解决方案，能够抵抗扩散编辑攻击，在保持水印不可见性的同时显著提高了水印的生存能力。

Abstract: 3D Gaussian Splatting (3DGS) has enabled the creation of digital assets and downstream applications, underscoring the need for robust copyright protection via digital watermarking. However, existing 3DGS watermarking methods remain highly vulnerable to diffusion-based editing, which can easily erase embedded provenance. This challenge highlights the urgent need for 3DGS watermarking techniques that are intrinsically resilient to diffusion-based editing. In this paper, we introduce RDSplat, a Robust watermarking paradigm against Diffusion editing for 3D Gaussian Splatting. RDSplat embeds watermarks into 3DGS components that diffusion-based editing inherently preserve, achieved through (i) proactively targeting low-frequency Gaussians and (ii) adversarial training with a diffusion proxy. Specifically, we introduce a multi-domain framework that operates natively in 3DGS space and embeds watermarks into diffusion-editing-preserved low-frequency Gaussians via coordinated covariance regularization and 2D filtering. In addition, we exploit the low-pass filtering behavior of diffusion-based editing by using Gaussian blur as an efficient training surrogate, enabling adversarial fine-tuning that further enhances watermark robustness against diffusion-based editing. Empirically, comprehensive quantitative and qualitative evaluations on three benchmark datasets demonstrate that RDSplat not only maintains superior robustness under diffusion-based editing, but also preserves watermark invisibility, achieving state-of-the-art performance.

</details>


### [96] [Physics Informed Human Posture Estimation Based on 3D Landmarks from Monocular RGB-Videos](https://arxiv.org/abs/2512.06783)
*Tobias Leuthold,Michele Xiloyannis,Yves Zimmermann*

Main category: cs.CV

TL;DR: 提出一种实时后处理算法，融合BlazePose 3D和2D估计，通过加权优化结合骨骼长度约束和生物力学模型，显著提升姿态估计的准确性和解剖学一致性


<details>
  <summary>Details</summary>
Motivation: 现有姿态估计模型（如BlazePose）缺乏解剖学约束，在物理治疗等自动教练应用中存在改进空间，需要结合物理知识提升准确性和鲁棒性

Method: 使用加权优化算法融合BlazePose 3D和2D估计，通过惩罚偏离预期骨骼长度和生物力学模型来约束姿态；采用卡尔曼滤波器根据测量信任度自适应优化个体骨骼长度估计

Result: 在Physio2.2M数据集上评估，3D MPJPE降低10.2%，身体段间角度误差减少16.6%，相比BlazePose 3D估计有明显提升

Conclusion: 该方法提供了一种计算高效、解剖学一致的实时姿态估计方案，适用于消费级设备的自动物理治疗、医疗保健和运动教练应用，后端运行仅使用匿名数据

Abstract: Applications providing automated coaching for physical training are increasing in popularity, for example physical therapy. These applications rely on accurate and robust pose estimation using monocular video streams. State-of-the-art models like BlazePose excel in real-time pose tracking, but their lack of anatomical constraints indicates improvement potential by including physical knowledge. We present a real-time post-processing algorithm fusing the strengths of BlazePose 3D and 2D estimations using a weighted optimization, penalizing deviations from expected bone length and biomechanical models. Bone length estimations are refined to the individual anatomy using a Kalman filter with adapting measurement trust. Evaluation using the Physio2.2M dataset shows a 10.2 percent reduction in 3D MPJPE and a 16.6 percent decrease in errors of angles between body segments compared to BlazePose 3D estimation. Our method provides a robust, anatomically consistent pose estimation based on a computationally efficient video-to-3D pose estimation, suitable for automated physiotherapy, healthcare, and sports coaching on consumer-level laptops and mobile devices. The refinement runs on the backend with anonymized data only.

</details>


### [97] [Generalized Geometry Encoding Volume for Real-time Stereo Matching](https://arxiv.org/abs/2512.06793)
*Jiaxin Liu,Gangwei Xu,Xianqi Wang,Chengliang Zhang,Xin Yang*

Main category: cs.CV

TL;DR: 提出GGEV网络解决实时立体匹配中泛化能力与推理速度的权衡问题，通过深度感知特征和动态成本聚合实现强泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有实时立体匹配方法过于关注域内性能而忽视泛化能力，而基于单目基础模型的立体基础模型虽然泛化好但推理延迟高

Method: 1) 提取编码域不变结构先验的深度感知特征作为成本聚合指导；2) 提出深度感知动态成本聚合(DDCA)模块，将先验自适应融入每个视差假设

Result: 在KITTI 2012、KITTI 2015和ETH3D基准测试中达到最先进性能，零样本泛化能力超越所有现有实时方法

Conclusion: GGEV通过轻量级互补步骤构建了具有强泛化能力的几何编码体积，成功平衡了实时性能与泛化能力

Abstract: Real-time stereo matching methods primarily focus on enhancing in-domain performance but often overlook the critical importance of generalization in real-world applications. In contrast, recent stereo foundation models leverage monocular foundation models (MFMs) to improve generalization, but typically suffer from substantial inference latency. To address this trade-off, we propose Generalized Geometry Encoding Volume (GGEV), a novel real-time stereo matching network that achieves strong generalization. We first extract depth-aware features that encode domain-invariant structural priors as guidance for cost aggregation. Subsequently, we introduce a Depth-aware Dynamic Cost Aggregation (DDCA) module that adaptively incorporates these priors into each disparity hypothesis, effectively enhancing fragile matching relationships in unseen scenes. Both steps are lightweight and complementary, leading to the construction of a generalized geometry encoding volume with strong generalization capability. Experimental results demonstrate that our GGEV surpasses all existing real-time methods in zero-shot generalization capability, and achieves state-of-the-art performance on the KITTI 2012, KITTI 2015, and ETH3D benchmarks.

</details>


### [98] [VDOT: Efficient Unified Video Creation via Optimal Transport Distillation](https://arxiv.org/abs/2512.06802)
*Yutong Wang,Haiyu Zhang,Tianfan Xue,Yu Qiao,Yaohui Wang,Chang Xu,Xinyuan Chen*

Main category: cs.CV

TL;DR: 本文提出了一种高效统一的视频生成模型VDOT，采用分布匹配蒸馏（DMD）范式和最优传输（OT）技术，显著提升了生成效率和质量，在4步生成中即可达到或超越100步基线模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型要么只能处理少数特定条件，要么因复杂的模型推理导致生成时间过长，难以在实际应用中实用。需要开发高效且通用的视频生成解决方案。

Method: 1. 采用分布匹配蒸馏（DMD）训练范式；2. 引入最优传输（OT）技术优化真实与生成分数分布之间的差异；3. 集成判别器使模型感知真实视频数据；4. 开发全自动视频数据标注和过滤流程；5. 构建统一测试基准UVCBench。

Result: 实验表明，4步生成的VDOT模型在性能上达到或超越了需要100步去噪的基线模型，显著提升了生成效率。

Conclusion: VDOT通过创新的OT技术和DMD范式，成功解决了视频生成模型的效率和质量问题，为实际应用提供了可行的解决方案。

Abstract: The rapid development of generative models has significantly advanced image and video applications. Among these, video creation, aimed at generating videos under various conditions, has gained substantial attention. However, existing video creation models either focus solely on a few specific conditions or suffer from excessively long generation times due to complex model inference, making them impractical for real-world applications. To mitigate these issues, we propose an efficient unified video creation model, named VDOT. Concretely, we model the training process with the distribution matching distillation (DMD) paradigm. Instead of using the Kullback-Leibler (KL) minimization, we additionally employ a novel computational optimal transport (OT) technique to optimize the discrepancy between the real and fake score distributions. The OT distance inherently imposes geometric constraints, mitigating potential zero-forcing or gradient collapse issues that may arise during KL-based distillation within the few-step generation scenario, and thus, enhances the efficiency and stability of the distillation process. Further, we integrate a discriminator to enable the model to perceive real video data, thereby enhancing the quality of generated videos. To support training unified video creation models, we propose a fully automated pipeline for video data annotation and filtering that accommodates multiple video creation tasks. Meanwhile, we curate a unified testing benchmark, UVCBench, to standardize evaluation. Experiments demonstrate that our 4-step VDOT outperforms or matches other baselines with 100 denoising steps.

</details>


### [99] [MMDuet2: Enhancing Proactive Interaction of Video MLLMs with Multi-Turn Reinforcement Learning](https://arxiv.org/abs/2512.06810)
*Yueqian Wang,Songxiang Liu,Disong Wang,Nuo Xu,Guanglu Wan,Huishuai Zhang,Dongyan Zhao*

Main category: cs.CV

TL;DR: 本文提出了一种基于文本到文本的主动交互方法MMDuet2，通过多轮强化学习训练，使视频多模态大语言模型能够自主决定在视频播放过程中何时回复，无需精确回复时间标注。


<details>
  <summary>Details</summary>
Motivation: 现有视频多模态大语言模型大多采用轮次式交互，而实时应用需要模型能够在视频播放过程中主动决定何时回复。传统方法存在手动调整回复决策阈值和标注精确回复时间的困难。

Method: 提出文本到文本的主动交互方法，模型基于对话历史和当前帧视觉上下文自主决定回复或保持沉默。采用多轮强化学习训练方法，无需精确回复时间标注。在包含52k视频和两类对话的数据集上通过SFT和RL训练。

Result: MMDuet2在ProactiveVideoQA基准测试中表现出色，在回复时机和质量上优于现有主动视频MLLM基线，达到最先进性能。

Conclusion: 该方法成功解决了视频多模态大语言模型主动交互中的关键挑战，为实时视频应用提供了有效的解决方案。

Abstract: Recent advances in video multimodal large language models (Video MLLMs) have significantly enhanced video understanding and multi-modal interaction capabilities. While most existing systems operate in a turn-based manner where the model can only reply after user turns, proactively deciding when to reply during video playback presents a promising yet challenging direction for real-time applications. In this work, we propose a novel text-to-text approach to proactive interaction, where the model autonomously determines whether to respond or remain silent at each turn based on dialogue history and visual context up to current frame of an streaming video. To overcome difficulties in previous methods such as manually tuning response decision thresholds and annotating precise reply times, we introduce a multi-turn RL based training method that encourages timely and accurate responses without requiring precise response time annotations. We train our model MMDuet2 on a dataset of 52k videos with two types of dialogues via SFT and RL. Experimental results demonstrate that MMDuet2 outperforms existing proactive Video MLLM baselines in response timing and quality, achieving state-of-the-art performance on the ProactiveVideoQA benchmark.

</details>


### [100] [RMAdapter: Reconstruction-based Multi-Modal Adapter for Vision-Language Models](https://arxiv.org/abs/2512.06811)
*Xiang Lin,Weixin Li,Shu Guo,Lihong Wang,Di Huang*

Main category: cs.CV

TL;DR: RMAdapter是一种新型的多模态适配器，通过双分支架构在少样本场景下平衡视觉语言模型的任务特定适应和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前预训练视觉语言模型在少样本微调中存在任务特定适应与泛化能力之间的平衡问题，且基于适配器的方法研究不足，性能存在明显差距。

Method: 提出RMAdapter双分支架构：适应分支通过参数高效微调注入任务特定知识，重建分支通过将潜在空间特征重建回原始特征空间来保留通用知识。采用局部重建损失计算和共享投影模块保持轻量化，并加入一致性约束来平衡判别性和泛化性。

Result: 在三个代表性任务（新类别泛化、新目标数据集泛化、领域泛化）上全面评估，RMAdapter在所有评估指标上均优于最先进方法，且不依赖数据增强或重复提示设计。

Conclusion: RMAdapter通过创新的双分支设计有效解决了视觉语言模型少样本微调中的适应-泛化平衡问题，在多个任务上表现出卓越性能。

Abstract: Pre-trained Vision-Language Models (VLMs), \textit{e.g.} CLIP, have become essential tools in multimodal transfer learning. However, fine-tuning VLMs in few-shot scenarios poses significant challenges in balancing task-specific adaptation and generalization in the obtained model. Meanwhile, current researches have predominantly focused on prompt-based adaptation methods, leaving adapter-based approaches underexplored and revealing notable performance gaps. To address these challenges, we introduce a novel Reconstruction-based Multimodal Adapter (RMAdapter), which leverages a dual-branch architecture. Unlike conventional single-branch adapters, RMAdapter consists of: (1) an adaptation branch that injects task-specific knowledge through parameter-efficient fine-tuning, and (2) a reconstruction branch that preserves general knowledge by reconstructing latent space features back into the original feature space. This design facilitates a dynamic balance between general and task-specific knowledge. Importantly, although RMAdapter introduces an additional reconstruction branch, it is carefully optimized to remain lightweight. By computing reconstruction loss locally at each layer and sharing projection modules, the overall computational overhead is kept minimal. A consistency constraint is also incorporated to better regulate the trade-off between discriminability and generalization. We comprehensively evaluate the effectiveness of RMAdapter on three representative tasks: generalization to new categories, generalization to new target datasets, and domain generalization. Without relying on data augmentation or duplicate prompt designs, our RMAdapter consistently outperforms state-of-the-art approaches across all evaluation metrics.

</details>


### [101] [MeshSplatting: Differentiable Rendering with Opaque Meshes](https://arxiv.org/abs/2512.06818)
*Jan Held,Sanghyun Son,Renaud Vandeghen,Daniel Rebain,Matheus Gadelha,Yi Zhou,Anthony Cioppa,Ming C. Lin,Marc Van Droogenbroeck,Andrea Tagliasacchi*

Main category: cs.CV

TL;DR: MeshSplatting是一种基于网格的重建方法，通过可微分渲染联合优化几何和外观，实现实时3D引擎中的高效渲染，在Mip-NeRF360数据集上PSNR提升0.69dB，训练速度快2倍且内存使用减少2倍。


<details>
  <summary>Details</summary>
Motivation: 解决基于基元的方法（如3D高斯泼溅）与AR/VR和游戏引擎中基于网格的流程不兼容的问题，桥接神经渲染和交互式3D图形以实现无缝实时场景交互。

Method: 通过受限Delaunay三角剖分强制连接性并优化表面一致性，联合优化几何和外观的可微分渲染方法。

Result: 在Mip-NeRF360数据集上，MeshSplatting比当前最先进的MiLo方法PSNR提升0.69dB，训练速度快2倍，内存使用减少2倍。

Conclusion: MeshSplatting创建了端到端平滑、视觉质量高的网格，能够高效地在实时3D引擎中渲染，成功桥接了神经渲染和交互式3D图形。

Abstract: Primitive-based splatting methods like 3D Gaussian Splatting have revolutionized novel view synthesis with real-time rendering. However, their point-based representations remain incompatible with mesh-based pipelines that power AR/VR and game engines. We present MeshSplatting, a mesh-based reconstruction approach that jointly optimizes geometry and appearance through differentiable rendering. By enforcing connectivity via restricted Delaunay triangulation and refining surface consistency, MeshSplatting creates end-to-end smooth, visually high-quality meshes that render efficiently in real-time 3D engines. On Mip-NeRF360, it boosts PSNR by +0.69 dB over the current state-of-the-art MiLo for mesh-based novel view synthesis, while training 2x faster and using 2x less memory, bridging neural rendering and interactive 3D graphics for seamless real-time scene interaction. The project page is available at https://meshsplatting.github.io/.

</details>


### [102] [SparseCoop: Cooperative Perception with Kinematic-Grounded Queries](https://arxiv.org/abs/2512.06838)
*Jiahao Wang,Zhongwei Jiang,Wenchao Sun,Jiaru Zhong,Haibao Yu,Yuner Zhang,Chenyang Lu,Chuang Zhang,Lei He,Shaobing Xu,Jianqiang Wang*

Main category: cs.CV

TL;DR: SparseCoop是一个完全稀疏的协同感知框架，用于3D检测和跟踪，通过丢弃BEV表示解决了通信成本高和视角对齐问题。


<details>
  <summary>Details</summary>
Motivation: 解决单车辆感知的局限性（如遮挡和视野受限），同时克服现有密集BEV特征共享方法的高通信成本和稀疏查询方法几何表示不足的问题。

Method: 提出三个创新：基于运动学的实例查询（使用3D几何和速度的显式状态向量）、粗到精聚合模块、协同实例去噪任务。

Result: 在V2X-Seq和Griffin数据集上达到最先进性能，具有高计算效率、低传输成本和强通信延迟鲁棒性。

Conclusion: SparseCoop框架在协同感知领域取得了显著进展，为自动驾驶提供了更高效可靠的解决方案。

Abstract: Cooperative perception is critical for autonomous driving, overcoming the inherent limitations of a single vehicle, such as occlusions and constrained fields-of-view. However, current approaches sharing dense Bird's-Eye-View (BEV) features are constrained by quadratically-scaling communication costs and the lack of flexibility and interpretability for precise alignment across asynchronous or disparate viewpoints. While emerging sparse query-based methods offer an alternative, they often suffer from inadequate geometric representations, suboptimal fusion strategies, and training instability. In this paper, we propose SparseCoop, a fully sparse cooperative perception framework for 3D detection and tracking that completely discards intermediate BEV representations. Our framework features a trio of innovations: a kinematic-grounded instance query that uses an explicit state vector with 3D geometry and velocity for precise spatio-temporal alignment; a coarse-to-fine aggregation module for robust fusion; and a cooperative instance denoising task to accelerate and stabilize training. Experiments on V2X-Seq and Griffin datasets show SparseCoop achieves state-of-the-art performance. Notably, it delivers this with superior computational efficiency, low transmission cost, and strong robustness to communication latency. Code is available at https://github.com/wang-jh18-SVM/SparseCoop.

</details>


### [103] [CADE: Continual Weakly-supervised Video Anomaly Detection with Ensembles](https://arxiv.org/abs/2512.06840)
*Satoshi Hashimoto,Tatsuya Konishi,Tomoya Kaichi,Kazunori Matsumoto,Mori Kurokawa*

Main category: cs.CV

TL;DR: 本文提出了CADE方法，首次将持续学习与弱监督视频异常检测相结合，通过双生成器和多判别器集成来解决领域偏移和遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 现有弱监督视频异常检测方法主要处理静态数据集，忽视了数据领域可能变化的情况。为适应领域偏移，需要持续学习视角，否则仅用新数据训练会导致对先前数据的性能下降（遗忘）。

Method: 提出CADE方法：使用双生成器解决数据不平衡和标签不确定性问题；通过多判别器集成捕获因遗忘而遗漏的异常模式。

Result: 在ShanghaiTech和Charlotte Anomaly等多场景VAD数据集上的广泛实验表明，CADE显著优于现有VAD方法。

Conclusion: CADE是首个结合持续学习和弱监督视频异常检测的工作，有效解决了领域偏移和遗忘问题，在多场景异常检测中表现出色。

Abstract: Video anomaly detection (VAD) has long been studied as a crucial problem in public security and crime prevention. In recent years, weakly-supervised VAD (WVAD) have attracted considerable attention due to their easy annotation process and promising research results. While existing WVAD methods tackle mainly on static datasets, the possibility that the domain of data can vary has been neglected. To adapt such domain-shift, the continual learning (CL) perspective is required because otherwise additional training only with new coming data could easily cause performance degradation for previous data, i.e., forgetting. Therefore, we propose a brand-new approach, called Continual Anomaly Detection with Ensembles (CADE) that is the first work combining CL and WVAD viewpoints. Specifically, CADE uses the Dual-Generator(DG) to address data imbalance and label uncertainty in WVAD. We also found that forgetting exacerbates the "incompleteness'' where the model becomes biased towards certain anomaly modes, leading to missed detections of various anomalies. To address this, we propose to ensemble Multi-Discriminator (MD) that capture missed anomalies in past scenes due to forgetting, using multiple models. Extensive experiments show that CADE significantly outperforms existing VAD methods on the common multi-scene VAD datasets, such as ShanghaiTech and Charlotte Anomaly datasets.

</details>


### [104] [Pseudo Anomalies Are All You Need: Diffusion-Based Generation for Weakly-Supervised Video Anomaly Detection](https://arxiv.org/abs/2512.06845)
*Satoshi Hashimoto,Hitoshi Nishimura,Yanan Wang,Mori Kurokawa*

Main category: cs.CV

TL;DR: PA-VAD是一种无需真实异常视频的异常检测方法，通过合成伪异常视频与真实正常视频进行训练，在标准弱监督分割下达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决实际部署中真实异常视频稀缺且收集成本高的问题，探索仅使用正常视频训练异常检测器的可行路径。

Method: 1) 使用CLIP选择类别相关初始图像，通过视觉语言模型优化文本提示以提升合成质量；2) 调用视频扩散模型生成伪异常视频；3) 通过域对齐正则化模块缓解合成异常中的时空幅度过大问题。

Result: 在ShanghaiTech上达到98.2%，在UCF-Crime上达到82.5%，分别比最强的真实异常方法高出0.6%和比UVAD SOTA方法高出1.9%。

Conclusion: 证明无需收集真实异常即可实现高精度异常检测，为可扩展部署提供了实用路径。

Abstract: Deploying video anomaly detection in practice is hampered by the scarcity and collection cost of real abnormal footage. We address this by training without any real abnormal videos while evaluating under the standard weakly supervised split, and we introduce PA-VAD, a generation-driven approach that learns a detector from synthesized pseudo-abnormal videos paired with real normal videos, using only a small set of real normal images to drive synthesis. For synthesis, we select class-relevant initial images with CLIP and refine textual prompts with a vision-language model to improve fidelity and scene consistency before invoking a video diffusion model. For training, we mitigate excessive spatiotemporal magnitude in synthesized anomalies by an domain-aligned regularized module that combines domain alignment and memory usage-aware updates. Extensive experiments show that our approach reaches 98.2% on ShanghaiTech and 82.5% on UCF-Crime, surpassing the strongest real-abnormal method on ShanghaiTech by +0.6% and outperforming the UVAD state-of-the-art on UCF-Crime by +1.9%. The results demonstrate that high-accuracy anomaly detection can be obtained without collecting real anomalies, providing a practical path toward scalable deployment.

</details>


### [105] [Hide-and-Seek Attribution: Weakly Supervised Segmentation of Vertebral Metastases in CT](https://arxiv.org/abs/2512.06849)
*Matan Atad,Alexander W. Marka,Lisa Steinhelfer,Anna Curto-Vilalta,Yannik Leonhardt,Sarah C. Foreman,Anna-Sophia Walburga Dietrich,Robert Graf,Alexandra S. Gersing,Bjoern Menze,Daniel Rueckert,Jan S. Kirschke,Hendrik Möller*

Main category: cs.CV

TL;DR: 提出了一种弱监督方法，仅使用椎体级别的健康/恶性标签（无需病变掩码）来分割CT中的椎体转移灶，通过扩散自编码器和像素级差异图结合选择性遮挡技术实现准确分割。


<details>
  <summary>Details</summary>
Motivation: 椎体转移灶的精确分割在临床上很重要但难以规模化，因为体素级注释稀缺，且溶骨性和成骨性病变常与良性退行性变化相似。

Method: 结合扩散自编码器生成健康编辑版本，通过像素级差异图提出候选病变区域，使用Hide-and-Seek Attribution技术逐个评估候选区域的恶性贡献度，高评分区域形成最终分割。

Result: 在保留的放射科医生注释上，无需掩码监督即达到强性能（成骨性F1:0.91/Dice:0.87；溶骨性F1:0.85/Dice:0.78），超过基线方法。

Conclusion: 椎体级标签可转化为可靠的病变掩码，生成编辑与选择性遮挡相结合支持CT中准确的弱监督分割。

Abstract: Accurate segmentation of vertebral metastasis in CT is clinically important yet difficult to scale, as voxel-level annotations are scarce and both lytic and blastic lesions often resemble benign degenerative changes. We introduce a weakly supervised method trained solely on vertebra-level healthy/malignant labels, without any lesion masks. The method combines a Diffusion Autoencoder (DAE) that produces a classifier-guided healthy edit of each vertebra with pixel-wise difference maps that propose candidate lesion regions. To determine which regions truly reflect malignancy, we introduce Hide-and-Seek Attribution: each candidate is revealed in turn while all others are hidden, the edited image is projected back to the data manifold by the DAE, and a latent-space classifier quantifies the isolated malignant contribution of that component. High-scoring regions form the final lytic or blastic segmentation. On held-out radiologist annotations, we achieve strong blastic/lytic performance despite no mask supervision (F1: 0.91/0.85; Dice: 0.87/0.78), exceeding baselines (F1: 0.79/0.67; Dice: 0.74/0.55). These results show that vertebra-level labels can be transformed into reliable lesion masks, demonstrating that generative editing combined with selective occlusion supports accurate weakly supervised segmentation in CT.

</details>


### [106] [Omni-Referring Image Segmentation](https://arxiv.org/abs/2512.06862)
*Qiancheng Zheng,Yunhang Shen,Gen Luo,Baiyang Song,Xing Sun,Xiaoshuai Sun,Yiyi Zhou,Rongrong Ji*

Main category: cs.CV

TL;DR: 提出OmniRIS任务，支持文本指令和视觉参考图像作为omni-prompts，实现高度泛化的图像分割。构建了OmniRef数据集和OmniSegNet基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有分割任务多为单模态输入，无法充分利用文本和视觉模态的优势。OmniRIS旨在结合文本的细粒度属性描述和视觉的罕见物体定位能力。

Method: 提出OmniRIS任务框架，支持文本指令和带掩码/框/涂鸦的参考图像作为多模态提示。构建OmniRef数据集（186,939个提示，30,956张图像），开发OmniSegNet基线模型处理omni-prompt编码等关键挑战。

Result: 实验验证了OmniSegNet能够有效遵循多模态指令，并证明了OmniRIS在高度泛化图像分割方面的优越性。

Conclusion: OmniRIS通过结合文本和视觉模态的优势，实现了更通用和实用的图像分割，为高度泛化分割研究提供了新方向。

Abstract: In this paper, we propose a novel task termed Omni-Referring Image Segmentation (OmniRIS) towards highly generalized image segmentation. Compared with existing unimodally conditioned segmentation tasks, such as RIS and visual RIS, OmniRIS supports the input of text instructions and reference images with masks, boxes or scribbles as omni-prompts. This property makes it can well exploit the intrinsic merits of both text and visual modalities, i.e., granular attribute referring and uncommon object grounding, respectively. Besides, OmniRIS can also handle various segmentation settings, such as one v.s. many and many v.s. many, further facilitating its practical use. To promote the research of OmniRIS, we also rigorously design and construct a large dataset termed OmniRef, which consists of 186,939 omni-prompts for 30,956 images, and establish a comprehensive evaluation system. Moreover, a strong and general baseline termed OmniSegNet is also proposed to tackle the key challenges of OmniRIS, such as omni-prompt encoding. The extensive experiments not only validate the capability of OmniSegNet in following omni-modal instructions, but also show the superiority of OmniRIS for highly generalized image segmentation.

</details>


### [107] [Boosting Unsupervised Video Instance Segmentation with Automatic Quality-Guided Self-Training](https://arxiv.org/abs/2512.06864)
*Kaixuan Lu,Mehmet Onurcan Kaya,Dim P. Papadopoulos*

Main category: cs.CV

TL;DR: AutoQ-VIS是一个无需人工标注的无监督视频实例分割框架，通过质量引导的自训练方法解决合成数据到真实视频的领域差距问题，在YouTubeVIS-2019数据集上达到52.6 AP50的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 视频实例分割面临像素级掩码和时序一致性标签的双重标注挑战。现有无监督方法如VideoCutLER虽然通过合成数据消除了光流依赖，但仍受限于合成到真实领域的差距。

Method: 提出质量引导的自训练框架，建立伪标签生成和自动质量评估之间的闭环系统，实现从合成视频到真实视频的渐进式适应。

Result: 在YouTubeVIS-2019验证集上达到52.6 AP50，超越之前最佳方法VideoCutLER 4.4%，且无需任何人工标注。

Conclusion: 证明了质量感知自训练在无监督视频实例分割中的可行性，为无监督VIS提供了有效解决方案。

Abstract: Video Instance Segmentation (VIS) faces significant annotation challenges due to its dual requirements of pixel-level masks and temporal consistency labels. While recent unsupervised methods like VideoCutLER eliminate optical flow dependencies through synthetic data, they remain constrained by the synthetic-to-real domain gap. We present AutoQ-VIS, a novel unsupervised framework that bridges this gap through quality-guided self-training. Our approach establishes a closed-loop system between pseudo-label generation and automatic quality assessment, enabling progressive adaptation from synthetic to real videos. Experiments demonstrate state-of-the-art performance with 52.6 $\text{AP}_{50}$ on YouTubeVIS-2019 $\texttt{val}$ set, surpassing the previous state-of-the-art VideoCutLER by 4.4%, while requiring no human annotations. This demonstrates the viability of quality-aware self-training for unsupervised VIS. We will release the code at https://github.com/wcbup/AutoQ-VIS.

</details>


### [108] [Spatial Retrieval Augmented Autonomous Driving](https://arxiv.org/abs/2512.06865)
*Xiaosong Jia,Chenhe Zhang,Yule Jiang,Songbur Wong,Zhiyuan Zhang,Chen Chen,Shaofeng Zhang,Xuanhe Zhou,Xue Yang,Junchi Yan,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: 论文提出空间检索范式，通过引入离线检索的地理图像作为额外输入，增强自动驾驶系统的环境感知能力，突破传统车载传感器的视野限制。


<details>
  <summary>Details</summary>
Motivation: 传统自动驾驶系统依赖车载传感器，存在感知视野有限、易受遮挡和恶劣天气影响的问题。人类驾驶员能够回忆道路结构，因此希望赋予模型类似的"回忆"能力。

Method: 提出空间检索范式，从离线缓存（如Google Maps或存储的自动驾驶数据集）获取地理图像作为额外输入。扩展nuScenes数据集，通过Google Maps API检索地理图像并与自车轨迹对齐。

Result: 在五个核心自动驾驶任务（目标检测、在线建图、占据预测、端到端规划和生成式世界建模）上建立基线，实验表明扩展模态能够提升某些任务的性能。

Conclusion: 空间检索范式是一种即插即用的扩展方案，无需额外传感器即可增强现有自动驾驶任务。将开源数据集构建代码、数据和基准测试，促进这一新范式的研究。

Abstract: Existing autonomous driving systems rely on onboard sensors (cameras, LiDAR, IMU, etc) for environmental perception. However, this paradigm is limited by the drive-time perception horizon and often fails under limited view scope, occlusion or extreme conditions such as darkness and rain. In contrast, human drivers are able to recall road structure even under poor visibility. To endow models with this ``recall" ability, we propose the spatial retrieval paradigm, introducing offline retrieved geographic images as an additional input. These images are easy to obtain from offline caches (e.g, Google Maps or stored autonomous driving datasets) without requiring additional sensors, making it a plug-and-play extension for existing AD tasks.
  For experiments, we first extend the nuScenes dataset with geographic images retrieved via Google Maps APIs and align the new data with ego-vehicle trajectories. We establish baselines across five core autonomous driving tasks: object detection, online mapping, occupancy prediction, end-to-end planning, and generative world modeling. Extensive experiments show that the extended modality could enhance the performance of certain tasks. We will open-source dataset curation code, data, and benchmarks for further study of this new autonomous driving paradigm.

</details>


### [109] [Less Is More, but Where? Dynamic Token Compression via LLM-Guided Keyframe Prior](https://arxiv.org/abs/2512.06866)
*Yulin Li,Haokun Gui,Ziyang Fan,Junjie Wang,Bin Kang,Bin Chen,Zhuotao Tian*

Main category: cs.CV

TL;DR: DyToK是一种无需训练的动态令牌压缩方法，利用VLLM的注意力机制实现视频内容的高效处理，在保持精度的同时显著提升推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型在处理长视频时面临二次计算复杂度增长的问题，传统关键帧采样方法存在额外计算成本和次优的二元帧选择范式。

Method: 通过分析VLLM注意力层自然编码的查询条件关键帧先验，动态调整每帧令牌保留比例，优先保留语义丰富的帧而抑制冗余内容。

Result: 实验表明DyToK实现了最先进的效率-精度权衡，与现有压缩方法兼容，推理速度提升4.3倍的同时保持精度。

Conclusion: DyToK提供了一种即插即用的高效视频处理方案，为长视频理解任务提供了有效的计算优化路径。

Abstract: Recent advances in Video Large Language Models (VLLMs) have achieved remarkable video understanding capabilities, yet face critical efficiency bottlenecks due to quadratic computational growth with lengthy visual token sequences of long videos. While existing keyframe sampling methods can improve temporal modeling efficiency, additional computational cost is introduced before feature encoding, and the binary frame selection paradigm is found suboptimal. Therefore, in this work, we propose Dynamic Token compression via LLM-guided Keyframe prior (DyToK), a training-free paradigm that enables dynamic token compression by harnessing VLLMs' inherent attention mechanisms. Our analysis reveals that VLLM attention layers naturally encoding query-conditioned keyframe priors, by which DyToK dynamically adjusts per-frame token retention ratios, prioritizing semantically rich frames while suppressing redundancies. Extensive experiments demonstrate that DyToK achieves state-of-the-art efficiency-accuracy tradeoffs. DyToK shows plug-and-play compatibility with existing compression methods, such as VisionZip and FastV, attaining 4.3x faster inference while preserving accuracy across multiple VLLMs, such as LLaVA-OneVision and Qwen2.5-VL. Code is available at https://github.com/yu-lin-li/DyToK .

</details>


### [110] [Towards Robust Pseudo-Label Learning in Semantic Segmentation: An Encoding Perspective](https://arxiv.org/abs/2512.06870)
*Wangkai Li,Rui Sun,Zhaoyang Li,Tianzhu Zhang*

Main category: cs.CV

TL;DR: ECOCSeg提出了一种基于纠错输出码的语义分割新方法，通过细粒度编码和位级标签去噪机制，有效解决伪标签学习中的错误传播问题。


<details>
  <summary>Details</summary>
Motivation: 传统伪标签学习在语义分割中存在错误标签放大问题，特别是在UDA和SSL场景中，由于使用one-hot编码导致错误传播。

Method: 引入ECOC分类器将类别分解为属性，开发位级标签去噪机制，能够处理部分不准确的比特位，提高伪标签质量。

Result: 在多个UDA和SSL基准测试中，ECOCSeg与现有方法结合后均表现出显著改进，适用于不同分割架构。

Conclusion: ECOCSeg为语义分割提供了一种稳定且泛化能力强的伪标签学习方案，代码已开源。

Abstract: Pseudo-label learning is widely used in semantic segmentation, particularly in label-scarce scenarios such as unsupervised domain adaptation (UDA) and semisupervised learning (SSL). Despite its success, this paradigm can generate erroneous pseudo-labels, which are further amplified during training due to utilization of one-hot encoding. To address this issue, we propose ECOCSeg, a novel perspective for segmentation models that utilizes error-correcting output codes (ECOC) to create a fine-grained encoding for each class. ECOCSeg offers several advantages. First, an ECOC-based classifier is introduced, enabling model to disentangle classes into attributes and handle partial inaccurate bits, improving stability and generalization in pseudo-label learning. Second, a bit-level label denoising mechanism is developed to generate higher-quality pseudo-labels, providing adequate and robust supervision for unlabeled images. ECOCSeg can be easily integrated with existing methods and consistently demonstrates significant improvements on multiple UDA and SSL benchmarks across different segmentation architectures. Code is available at https://github.com/Woof6/ECOCSeg.

</details>


### [111] [SceneMixer: Exploring Convolutional Mixing Networks for Remote Sensing Scene Classification](https://arxiv.org/abs/2512.06877)
*Mohammed Q. Alkhatib,Ali Jamali,Swalpa Kumar Roy*

Main category: cs.CV

TL;DR: 本文提出了一种基于卷积混合器的轻量级架构，用于遥感场景分类，通过多尺度深度卷积和逐点操作交替进行空间和通道混合，在保持低参数和计算量的同时实现高效特征提取。


<details>
  <summary>Details</summary>
Motivation: 遥感场景分类在土地利用和土地覆盖识别中至关重要，但现有CNN和ViT模型由于空间分辨率、视角、方向和背景条件的变化而泛化能力不足，需要更高效的解决方案。

Method: 采用卷积混合器架构，交替使用多尺度深度卷积进行空间混合和逐点操作进行通道混合，以低参数和低计算成本提取局部和上下文信息。

Result: 在AID数据集上达到74.7%总体准确率、74.57%平均准确率和73.79 Kappa值；在EuroSAT数据集上达到93.90%总体准确率、93.93%平均准确率和93.22 Kappa值。

Conclusion: 所提方法在准确性和效率之间取得了良好平衡，优于广泛使用的CNN和基于Transformer的模型。

Abstract: Remote sensing scene classification plays a key role in Earth observation by enabling the automatic identification of land use and land cover (LULC) patterns from aerial and satellite imagery. Despite recent progress with convolutional neural networks (CNNs) and vision transformers (ViTs), the task remains challenging due to variations in spatial resolution, viewpoint, orientation, and background conditions, which often reduce the generalization ability of existing models. To address these challenges, this paper proposes a lightweight architecture based on the convolutional mixer paradigm. The model alternates between spatial mixing through depthwise convolutions at multiple scales and channel mixing through pointwise operations, enabling efficient extraction of both local and contextual information while keeping the number of parameters and computations low. Extensive experiments were conducted on the AID and EuroSAT benchmarks. The proposed model achieved overall accuracy, average accuracy, and Kappa values of 74.7%, 74.57%, and 73.79 on the AID dataset, and 93.90%, 93.93%, and 93.22 on EuroSAT, respectively. These results demonstrate that the proposed approach provides a good balance between accuracy and efficiency compared with widely used CNN- and transformer-based models. Code will be publicly available on: https://github.com/mqalkhatib/SceneMixer

</details>


### [112] [Hierarchical Image-Guided 3D Point Cloud Segmentation in Industrial Scenes via Multi-View Bayesian Fusion](https://arxiv.org/abs/2512.06882)
*Yu Zhu,Naoya Chiba,Koichi Hashimoto*

Main category: cs.CV

TL;DR: 提出了一种分层图像引导的3D分割框架，通过从实例级到部件级的渐进细化来解决工业场景中遮挡和尺度差异问题。


<details>
  <summary>Details</summary>
Motivation: 工业环境中密集布局和多尺度物体的复杂场景需要可靠的3D分割，但现有方法存在标注成本高、语义不一致等问题。

Method: 使用分层方法：先通过顶视图渲染和SAM+YOLO-World进行实例分割，然后对每个实例进行多视图渲染，应用2D分割和贝叶斯更新融合实现部件级分割。

Result: 在真实工厂数据上有效处理遮挡和结构复杂性，获得高mIoU分数；在公开数据集上验证了框架的泛化能力。

Conclusion: 该方法展示了在多样化3D环境中的鲁棒性、标注效率和适应性，为复杂工业场景提供了有效的分割解决方案。

Abstract: Reliable 3D segmentation is critical for understanding complex scenes with dense layouts and multi-scale objects, as commonly seen in industrial environments. In such scenarios, heavy occlusion weakens geometric boundaries between objects, and large differences in object scale will cause end-to-end models fail to capture both coarse and fine details accurately. Existing 3D point-based methods require costly annotations, while image-guided methods often suffer from semantic inconsistencies across views. To address these challenges, we propose a hierarchical image-guided 3D segmentation framework that progressively refines segmentation from instance-level to part-level. Instance segmentation involves rendering a top-view image and projecting SAM-generated masks prompted by YOLO-World back onto the 3D point cloud. Part-level segmentation is subsequently performed by rendering multi-view images of each instance obtained from the previous stage and applying the same 2D segmentation and back-projection process at each view, followed by Bayesian updating fusion to ensure semantic consistency across views. Experiments on real-world factory data demonstrate that our method effectively handles occlusion and structural complexity, achieving consistently high per-class mIoU scores. Additional evaluations on public dataset confirm the generalization ability of our framework, highlighting its robustness, annotation efficiency, and adaptability to diverse 3D environments.

</details>


### [113] [JoPano: Unified Panorama Generation via Joint Modeling](https://arxiv.org/abs/2512.06885)
*Wancheng Feng,Chen An,Zhenliang He,Meina Kan,Shiguang Shan,Lukun Wang*

Main category: cs.CV

TL;DR: JoPano是一种基于DiT的统一全景图生成方法，通过联合面适配器和条件切换机制，同时支持文本到全景图和视图到全景图生成，解决了现有方法在视觉质量和任务独立性方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有全景图生成方法存在两个主要问题：基于U-Net的架构限制了生成全景图的视觉质量，且通常将文本到全景图和视图到全景图两个核心任务独立处理，导致建模冗余和效率低下。

Method: 提出基于DiT的联合面全景图生成方法，包括：1）基于立方体贴图表示的联合面适配器，将预训练DiT的生成能力迁移到全景图领域；2）泊松混合减少面边界接缝不一致；3）条件切换机制统一两个任务；4）引入Seam-SSIM和Seam-Sobel指标评估接缝一致性。

Result: 实验表明JoPano在两个任务上都能生成高质量全景图，在FID、CLIP-FID、IS和CLIP-Score指标上达到最先进性能。

Conclusion: JoPano成功克服了现有方法的局限性，通过统一的DiT架构实现了高质量的全景图生成，为全景图生成领域提供了有效的解决方案。

Abstract: Panorama generation has recently attracted growing interest in the research community, with two core tasks, text-to-panorama and view-to-panorama generation. However, existing methods still face two major challenges: their U-Net-based architectures constrain the visual quality of the generated panoramas, and they usually treat the two core tasks independently, which leads to modeling redundancy and inefficiency. To overcome these challenges, we propose a joint-face panorama (JoPano) generation approach that unifies the two core tasks within a DiT-based model. To transfer the rich generative capabilities of existing DiT backbones learned from natural images to the panorama domain, we propose a Joint-Face Adapter built on the cubemap representation of panoramas, which enables a pretrained DiT to jointly model and generate different views of a panorama. We further apply Poisson Blending to reduce seam inconsistencies that often appear at the boundaries between cube faces. Correspondingly, we introduce Seam-SSIM and Seam-Sobel metrics to quantitatively evaluate the seam consistency. Moreover, we propose a condition switching mechanism that unifies text-to-panorama and view-to-panorama tasks within a single model. Comprehensive experiments show that JoPano can generate high-quality panoramas for both text-to-panorama and view-to-panorama generation tasks, achieving state-of-the-art performance on FID, CLIP-FID, IS, and CLIP-Score metrics.

</details>


### [114] [Balanced Learning for Domain Adaptive Semantic Segmentation](https://arxiv.org/abs/2512.06886)
*Wangkai Li,Rui Sun,Bohao Liao,Zhaoyang Li,Tianzhu Zhang*

Main category: cs.CV

TL;DR: BLDA提出了一种平衡学习方法来解决无监督域自适应语义分割中的类别不平衡问题，通过分析预测logits分布来识别过预测和欠预测类别，并使用共享锚分布进行对齐。


<details>
  <summary>Details</summary>
Motivation: 现有的自训练技术在UDA中由于类别不平衡和域间分布偏移，难以平衡学习各个类别，导致模型对某些类别预测偏差较大。

Method: 1）通过分析预测logits分布识别过预测和欠预测类别；2）使用共享锚分布进行后处理对齐；3）在线估计logits分布并加入损失函数修正项；4）利用累积密度作为域间共享的结构知识。

Result: 在两个标准UDA语义分割基准测试上的实验表明，BLDA能持续提升性能，特别是对欠预测类别有显著改善，且可集成到多种现有方法中。

Conclusion: BLDA通过平衡学习机制有效解决了UDA语义分割中的类别偏差问题，无需先验分布知识，具有较好的通用性和实用性。

Abstract: Unsupervised domain adaptation (UDA) for semantic segmentation aims to transfer knowledge from a labeled source domain to an unlabeled target domain. Despite the effectiveness of self-training techniques in UDA, they struggle to learn each class in a balanced manner due to inherent class imbalance and distribution shift in both data and label space between domains. To address this issue, we propose Balanced Learning for Domain Adaptation (BLDA), a novel approach to directly assess and alleviate class bias without requiring prior knowledge about the distribution shift. First, we identify over-predicted and under-predicted classes by analyzing the distribution of predicted logits. Subsequently, we introduce a post-hoc approach to align the logits distributions across different classes using shared anchor distributions. To further consider the network's need to generate unbiased pseudo-labels during self-training, we estimate logits distributions online and incorporate logits correction terms into the loss function. Moreover, we leverage the resulting cumulative density as domain-shared structural knowledge to connect the source and target domains. Extensive experiments on two standard UDA semantic segmentation benchmarks demonstrate that BLDA consistently improves performance, especially for under-predicted classes, when integrated into various existing methods. Code is available at https://github.com/Woof6/BLDA.

</details>


### [115] [Overcoming Small Data Limitations in Video-Based Infant Respiration Estimation](https://arxiv.org/abs/2512.06888)
*Liyang Song,Hardik Bishnoi,Sai Kumar Reddy Manne,Sarah Ostadabbas,Briana J. Taylor,Michael Wan*

Main category: cs.CV

TL;DR: 本文提出了AIR-400婴儿呼吸监测数据集和首个可复现的婴儿呼吸估计算法，填补了婴儿呼吸监测领域的数据和算法空白。


<details>
  <summary>Details</summary>
Motivation: 婴儿呼吸异常与神经发育障碍和婴儿猝死综合征相关，但目前缺乏针对婴儿的呼吸监测数据集和有效算法，而成人呼吸监测已有成熟技术。

Method: 开发了基于婴儿特定感兴趣区域检测和光流增强的时空神经处理算法，构建了包含400个标注视频的AIR-400数据集。

Result: 建立了首个可复现的婴儿呼吸估计基准，算法在400个视频数据集上表现良好，代码和模型已开源。

Conclusion: 该研究为婴儿呼吸监测领域提供了重要的数据集和算法基础，有助于早期发现和治疗呼吸异常。

Abstract: The development of contactless respiration monitoring for infants could enable advances in the early detection and treatment of breathing irregularities, which are associated with neurodevelopmental impairments and conditions like sudden infant death syndrome (SIDS). But while respiration estimation for adults is supported by a robust ecosystem of computer vision algorithms and video datasets, only one small public video dataset with annotated respiration data for infant subjects exists, and there are no reproducible algorithms which are effective for infants. We introduce the annotated infant respiration dataset of 400 videos (AIR-400), contributing 275 new, carefully annotated videos from 10 recruited subjects to the public corpus. We develop the first reproducible pipelines for infant respiration estimation, based on infant-specific region-of-interest detection and spatiotemporal neural processing enhanced by optical flow inputs. We establish, through comprehensive experiments, the first reproducible benchmarks for the state-of-the-art in vision-based infant respiration estimation. We make our dataset, code repository, and trained models available for public use.

</details>


### [116] [Scaling Zero-Shot Reference-to-Video Generation](https://arxiv.org/abs/2512.06905)
*Zijian Zhou,Shikun Liu,Haozhe Liu,Haonan Qiu,Zhaochong An,Weiming Ren,Zhiheng Liu,Xiaoke Huang,Kam Woh Ng,Tian Xie,Xiao Han,Yuren Cong,Hang Li,Chuyan Zhu,Aditya Patel,Tao Xiang,Sen He*

Main category: cs.CV

TL;DR: Saber是一个无需参考图像-视频-文本三元组数据的零样本参考视频生成框架，通过掩码训练策略和注意力机制设计，在仅使用视频-文本对的情况下实现身份一致和参考感知的视频生成。


<details>
  <summary>Details</summary>
Motivation: 当前参考视频生成方法依赖昂贵的显式参考图像-视频-文本三元组数据，这些数据的构建成本高且难以扩展，需要找到绕过这一瓶颈的解决方案。

Method: 采用掩码训练策略和定制的基于注意力的模型设计，仅使用视频-文本对进行训练，并整合掩码增强技术来减轻参考视频生成中常见的复制粘贴伪影。

Result: 在OpenS2V-Eval基准测试中，相比使用R2V数据训练的方法，Saber表现出优越的性能，并展示了在不同数量参考下的显著泛化能力。

Conclusion: Saber框架成功实现了无需显式R2V数据的可扩展零样本参考视频生成，解决了数据依赖瓶颈问题，具有更好的泛化性能。

Abstract: Reference-to-video (R2V) generation aims to synthesize videos that align with a text prompt while preserving the subject identity from reference images. However, current R2V methods are hindered by the reliance on explicit reference image-video-text triplets, whose construction is highly expensive and difficult to scale. We bypass this bottleneck by introducing Saber, a scalable zero-shot framework that requires no explicit R2V data. Trained exclusively on video-text pairs, Saber employs a masked training strategy and a tailored attention-based model design to learn identity-consistent and reference-aware representations. Mask augmentation techniques are further integrated to mitigate copy-paste artifacts common in reference-to-video generation. Moreover, Saber demonstrates remarkable generalization capabilities across a varying number of references and achieves superior performance on the OpenS2V-Eval benchmark compared to methods trained with R2V data.

</details>


### [117] [NeuroABench: A Multimodal Evaluation Benchmark for Neurosurgical Anatomy Identification](https://arxiv.org/abs/2512.06921)
*Ziyang Song,Zelin Zang,Xiaofan Ye,Boqiang Xu,Long Bai,Jinlin Wu,Hongliang Ren,Hongbin Liu,Jiebo Luo,Zhen Lei*

Main category: cs.CV

TL;DR: 本文介绍了NeuroABench，这是首个专门评估神经外科领域解剖学理解的多模态基准，包含9小时标注视频和68个解剖结构，实验显示当前MLLMs在解剖识别任务上最高仅达40.87%准确率，显著落后于人类表现。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注手术流程理解，而忽视了临床实践中至关重要的解剖学认知。为填补这一空白，需要专门评估MLLMs在神经外科解剖理解能力。

Method: 使用新型多模态标注流程构建包含89种不同手术的9小时标注视频数据集，评估68个临床解剖结构的识别能力，并对10多个先进MLLMs和4名神经外科培训生进行对比测试。

Result: 最佳MLLM仅达到40.87%准确率，而人类培训生平均准确率为46.5%（最高56%，最低28%），MLLMs表现接近最差人类但明显落后于平均水平。

Conclusion: MLLMs在解剖学理解方面取得进展但仍存在显著差距，NeuroABench为评估和提升模型性能提供了标准化框架。

Abstract: Multimodal Large Language Models (MLLMs) have shown significant potential in surgical video understanding. With improved zero-shot performance and more effective human-machine interaction, they provide a strong foundation for advancing surgical education and assistance. However, existing research and datasets primarily focus on understanding surgical procedures and workflows, while paying limited attention to the critical role of anatomical comprehension. In clinical practice, surgeons rely heavily on precise anatomical understanding to interpret, review, and learn from surgical videos. To fill this gap, we introduce the Neurosurgical Anatomy Benchmark (NeuroABench), the first multimodal benchmark explicitly created to evaluate anatomical understanding in the neurosurgical domain. NeuroABench consists of 9 hours of annotated neurosurgical videos covering 89 distinct procedures and is developed using a novel multimodal annotation pipeline with multiple review cycles. The benchmark evaluates the identification of 68 clinical anatomical structures, providing a rigorous and standardized framework for assessing model performance. Experiments on over 10 state-of-the-art MLLMs reveal significant limitations, with the best-performing model achieving only 40.87% accuracy in anatomical identification tasks. To further evaluate the benchmark, we extract a subset of the dataset and conduct an informative test with four neurosurgical trainees. The results show that the best-performing student achieves 56% accuracy, with the lowest scores of 28% and an average score of 46.5%. While the best MLLM performs comparably to the lowest-scoring student, it still lags significantly behind the group's average performance. This comparison underscores both the progress of MLLMs in anatomical understanding and the substantial gap that remains in achieving human-level performance.

</details>


### [118] [Can We Go Beyond Visual Features? Neural Tissue Relation Modeling for Relational Graph Analysis in Non-Melanoma Skin Histology](https://arxiv.org/abs/2512.06949)
*Shravan Venkatraman,Muthu Subash Kavitha,Joe Dhanith P R,V Manikandarajan,Jia Wu*

Main category: cs.CV

TL;DR: 该论文提出了一种名为NTRM的新型组织病理学图像分割框架，通过图神经网络建模组织间的空间和功能关系，解决了传统CNN方法在处理重叠或形态相似组织时的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前基于CNN的组织病理学图像分割方法主要依赖视觉纹理特征，将组织视为独立区域，缺乏对组织间生物学上下文关系的建模，特别是在边界密集区域难以实现结构一致的预测。

Method: NTRM框架在CNN基础上引入组织级图神经网络，构建预测区域图，通过消息传递传播上下文信息，并通过空间投影细化分割结果，显式编码组织间依赖关系。

Result: 在Histopathology Non-Melanoma Skin Cancer Segmentation Dataset基准测试中，NTRM优于最先进方法，Dice相似系数比最佳模型高出4.9%至31.25%。

Conclusion: 关系建模为组织病理学分割提供了一条更注重上下文和可解释性的路径，相比缺乏组织级结构感知的局部感受野架构具有明显优势。

Abstract: Histopathology image segmentation is essential for delineating tissue structures in skin cancer diagnostics, but modeling spatial context and inter-tissue relationships remains a challenge, especially in regions with overlapping or morphologically similar tissues. Current convolutional neural network (CNN)-based approaches operate primarily on visual texture, often treating tissues as independent regions and failing to encode biological context. To this end, we introduce Neural Tissue Relation Modeling (NTRM), a novel segmentation framework that augments CNNs with a tissue-level graph neural network to model spatial and functional relationships across tissue types. NTRM constructs a graph over predicted regions, propagates contextual information via message passing, and refines segmentation through spatial projection. Unlike prior methods, NTRM explicitly encodes inter-tissue dependencies, enabling structurally coherent predictions in boundary-dense zones. On the benchmark Histopathology Non-Melanoma Skin Cancer Segmentation Dataset, NTRM outperforms state-of-the-art methods, achieving a robust Dice similarity coefficient that is 4.9\% to 31.25\% higher than the best-performing models among the evaluated approaches. Our experiments indicate that relational modeling offers a principled path toward more context-aware and interpretable histological segmentation, compared to local receptive-field architectures that lack tissue-level structural awareness. Our code is available at https://github.com/shravan-18/NTRM.

</details>


### [119] [Selective Masking based Self-Supervised Learning for Image Semantic Segmentation](https://arxiv.org/abs/2512.06981)
*Yuemin Wang,Ian Stavness*

Main category: cs.CV

TL;DR: 提出了一种基于选择性掩码图像重建的自监督学习方法，用于改进语义分割任务的预训练效果，相比传统随机掩码方法在多个数据集上取得了更好的分割精度。


<details>
  <summary>Details</summary>
Motivation: 传统的随机掩码图像建模方法在预训练时效率不高，无法充分利用已训练模型的知识。本文旨在通过选择性掩码策略，更智能地选择需要重建的图像块，提高预训练效果。

Method: 将图像重建预训练分解为迭代步骤，在每次迭代中选择重建损失最高的图像块进行掩码，利用已训练模型的知识来指导掩码选择过程。

Result: 在两个通用数据集（Pascal VOC和Cityscapes）和两个杂草分割数据集上，选择性掩码方法比传统随机掩码方法和有监督ImageNet预训练分别提高了2.9%和2.5%的分割精度，特别是在低性能类别上提升显著。

Conclusion: 选择性掩码图像重建方法为端到端语义分割工作流提供了有效实用的解决方案，特别适用于需要有限模型容量以满足推理速度和计算资源要求的场景。

Abstract: This paper proposes a novel self-supervised learning method for semantic segmentation using selective masking image reconstruction as the pretraining task. Our proposed method replaces the random masking augmentation used in most masked image modelling pretraining methods. The proposed selective masking method selectively masks image patches with the highest reconstruction loss by breaking the image reconstruction pretraining into iterative steps to leverage the trained model's knowledge. We show on two general datasets (Pascal VOC and Cityscapes) and two weed segmentation datasets (Nassar 2020 and Sugarbeets 2016) that our proposed selective masking method outperforms the traditional random masking method and supervised ImageNet pretraining on downstream segmentation accuracy by 2.9% for general datasets and 2.5% for weed segmentation datasets. Furthermore, we found that our selective masking method significantly improves accuracy for the lowest-performing classes. Lastly, we show that using the same pretraining and downstream dataset yields the best result for low-budget self-supervised pretraining. Our proposed Selective Masking Image Reconstruction method provides an effective and practical solution to improve end-to-end semantic segmentation workflows, especially for scenarios that require limited model capacity to meet inference speed and computational resource requirements.

</details>


### [120] [Power of Boundary and Reflection: Semantic Transparent Object Segmentation using Pyramid Vision Transformer with Transparent Cues](https://arxiv.org/abs/2512.07034)
*Tuan-Anh Vu,Hai Nguyen-Truong,Ziqiang Zheng,Binh-Son Hua,Qing Guo,Ivor Tsang,Sai-Kit Yeung*

Main category: cs.CV

TL;DR: 该论文提出TransCues框架，通过边界特征增强和反射特征增强模块，结合金字塔Transformer编码器-解码器架构，有效解决了玻璃物体分割的挑战。


<details>
  <summary>Details</summary>
Motivation: 玻璃物体因其透明性和反射性，现有分割方法难以将其与不透明材料区分开。人类感知依赖边界和反射物体特征来识别玻璃，但现有方法未能充分捕捉这两种特性。

Method: 提出TransCues框架，包含边界特征增强模块和反射特征增强模块，采用金字塔Transformer编码器-解码器架构，将两种视觉线索以互利方式结合。

Result: 在多个基准数据集上显著超越现有最优方法：Trans10K-v2提升4.2% mIoU，MSD提升5.6% mIoU，RGBD-Mirror提升10.1% mIoU，TROSD提升13.1% mIoU，Stanford2D3D提升8.3% mIoU。

Conclusion: 该方法有效解决了玻璃物体分割问题，证明了边界和反射特征增强模块的结合能够显著提升透明物体的分割性能。

Abstract: Glass is a prevalent material among solid objects in everyday life, yet segmentation methods struggle to distinguish it from opaque materials due to its transparency and reflection. While it is known that human perception relies on boundary and reflective-object features to distinguish glass objects, the existing literature has not yet sufficiently captured both properties when handling transparent objects. Hence, we propose incorporating both of these powerful visual cues via the Boundary Feature Enhancement and Reflection Feature Enhancement modules in a mutually beneficial way. Our proposed framework, TransCues, is a pyramidal transformer encoder-decoder architecture to segment transparent objects. We empirically show that these two modules can be used together effectively, improving overall performance across various benchmark datasets, including glass object semantic segmentation, mirror object semantic segmentation, and generic segmentation datasets. Our method outperforms the state-of-the-art by a large margin, achieving +4.2% mIoU on Trans10K-v2, +5.6% mIoU on MSD, +10.1% mIoU on RGBD-Mirror, +13.1% mIoU on TROSD, and +8.3% mIoU on Stanford2D3D, showing the effectiveness of our method against glass objects.

</details>


### [121] [Evaluating and Preserving High-level Fidelity in Super-Resolution](https://arxiv.org/abs/2512.07037)
*Josep M. Rocafort,Shaolin Su,Javier Vazquez-Corral,Alexandra Gomez-Villa*

Main category: cs.CV

TL;DR: 本文提出了衡量超分辨率模型高保真度的重要性，构建了首个带注释的高保真度数据集，分析了现有图像质量指标与高保真度的相关性，并展示了通过高保真度反馈可以同时提升语义保真度和感知质量。


<details>
  <summary>Details</summary>
Motivation: 当前超分辨率模型虽然能生成视觉上令人愉悦的结果，但有时会产生幻觉效应改变图像内容。现有低层次图像质量指标无法有效衡量这种高层次的内容变化，需要建立高保真度评估标准来揭示生成式超分辨率模型的可靠性。

Method: 构建首个带注释的高保真度评分数据集；评估SOTA超分辨率模型的高保真度表现；分析现有图像质量指标与高保真度的相关性；利用基础模型解决高层次任务；通过高保真度反馈微调超分辨率模型。

Result: 建立了高保真度评估标准；展示了高保真度反馈可以同时提升语义保真度和感知质量；发现基础模型能更好地处理高层次任务。

Conclusion: 提出的高保真度标准在模型评估和优化中具有潜在价值，为超分辨率模型提供了更全面的评估维度，有助于提高生成结果的可靠性。

Abstract: Recent image Super-Resolution (SR) models are achieving impressive effects in reconstructing details and delivering visually pleasant outputs. However, the overpowering generative ability can sometimes hallucinate and thus change the image content despite gaining high visual quality. This type of high-level change can be easily identified by humans yet not well-studied in existing low-level image quality metrics. In this paper, we establish the importance of measuring high-level fidelity for SR models as a complementary criterion to reveal the reliability of generative SR models. We construct the first annotated dataset with fidelity scores from different SR models, and evaluate how state-of-the-art (SOTA) SR models actually perform in preserving high-level fidelity. Based on the dataset, we then analyze how existing image quality metrics correlate with fidelity measurement, and further show that this high-level task can be better addressed by foundation models. Finally, by fine-tuning SR models based on our fidelity feedback, we show that both semantic fidelity and perceptual quality can be improved, demonstrating the potential value of our proposed criteria, both in model evaluation and optimization. We will release the dataset, code, and models upon acceptance.

</details>


### [122] [DAUNet: A Lightweight UNet Variant with Deformable Convolutions and Parameter-Free Attention for Medical Image Segmentation](https://arxiv.org/abs/2512.07051)
*Adnan Munir,Shujaat Khan*

Main category: cs.CV

TL;DR: DAUNet是一种轻量级UNet变体，集成了可变形卷积和参数无关注意力机制，在医学图像分割任务中表现出色且参数高效。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像分割中模型对几何变化适应能力不足和上下文特征融合效率低的问题，同时保持模型轻量化以适应临床资源受限环境。

Method: 使用Deformable V2 Convolutions处理几何变化，SimAM注意力模块增强解码器和跳跃连接，实现空间自适应和上下文感知特征融合。

Result: 在FH-PS-AoP和FUMPE两个数据集上，DAUNet在Dice分数、HD95和ASD指标上均优于现有最优模型，同时保持参数效率优势。

Conclusion: DAUNet通过可变形卷积和注意力机制的协同作用，在医学图像分割任务中实现了优异的性能和鲁棒性，适合实时临床部署。

Abstract: Medical image segmentation plays a pivotal role in automated diagnostic and treatment planning systems. In this work, we present DAUNet, a novel lightweight UNet variant that integrates Deformable V2 Convolutions and Parameter-Free Attention (SimAM) to improve spatial adaptability and context-aware feature fusion without increasing model complexity. DAUNet's bottleneck employs dynamic deformable kernels to handle geometric variations, while the decoder and skip pathways are enhanced using SimAM attention modules for saliency-aware refinement. Extensive evaluations on two challenging datasets, FH-PS-AoP (fetal head and pubic symphysis ultrasound) and FUMPE (CT-based pulmonary embolism detection), demonstrate that DAUNet outperforms state-of-the-art models in Dice score, HD95, and ASD, while maintaining superior parameter efficiency. Ablation studies highlight the individual contributions of deformable convolutions and SimAM attention. DAUNet's robustness to missing context and low-contrast regions establishes its suitability for deployment in real-time and resource-constrained clinical environments.

</details>


### [123] [RAVE: Rate-Adaptive Visual Encoding for 3D Gaussian Splatting](https://arxiv.org/abs/2512.07052)
*Hoang-Nhat Tran,Francesco Di Sario,Gabriele Spadaro,Giuseppe Valenzise,Enzo Tartaglione*

Main category: cs.CV

TL;DR: 提出了一种支持在预定义边界之间任意速率插值的灵活3D高斯泼溅压缩方案，无需针对不同速率重新训练，计算轻量且保持渲染质量。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅技术虽然能实现实时逼真渲染，但存在内存需求大和训练成本高的问题，现有压缩方法只能在固定速率下工作，无法适应变化的带宽和设备限制。

Method: 开发了一种灵活的压缩方案，支持在预定义边界之间进行任意速率的插值，该方法计算轻量，无需针对不同压缩速率重新训练模型。

Result: 实验表明该方法在广泛的操作点上都能实现高效、高质量的压缩，同时提供动态速率控制，保持了渲染质量。

Conclusion: 该方法适合在沉浸式应用中实际部署，代码将在工作被接受后开源提供。

Abstract: Recent advances in neural scene representations have transformed immersive multimedia, with 3D Gaussian Splatting (3DGS) enabling real-time photorealistic rendering. Despite its efficiency, 3DGS suffers from large memory requirements and costly training procedures, motivating efforts toward compression. Existing approaches, however, operate at fixed rates, limiting adaptability to varying bandwidth and device constraints. In this work, we propose a flexible compression scheme for 3DGS that supports interpolation at any rate between predefined bounds. Our method is computationally lightweight, requires no retraining for any rate, and preserves rendering quality across a broad range of operating points. Experiments demonstrate that the approach achieves efficient, high-quality compression while offering dynamic rate control, making it suitable for practical deployment in immersive applications. The code will be provided open-source upon acceptance of the work.

</details>


### [124] [$\mathrm{D}^{\mathrm{3}}$-Predictor: Noise-Free Deterministic Diffusion for Dense Prediction](https://arxiv.org/abs/2512.07062)
*Changliang Xia,Chengyou Jia,Minnan Luo,Zhuohang Dang,Xin Shen,Bowen Ping*

Main category: cs.CV

TL;DR: 本文提出了D³-Predictor，一种无噪声的确定性框架，通过重新构建预训练扩散模型来解决扩散模型中随机噪声对密集预测任务的不利影响。该方法将扩散模型视为时间步相关的视觉专家集合，并自监督地聚合其异构先验，实现了在少量训练数据下高效的单步推理。


<details>
  <summary>Details</summary>
Motivation: 扩散模型虽然具有强大的视觉先验能力，但其核心的随机噪声与密集预测任务所需的确定性图像到几何映射存在根本性冲突。随机噪声会破坏细粒度空间线索，使模型偏向时间步特定的噪声目标，从而破坏有意义的几何结构映射。

Method: D³-Predictor通过重新构建预训练扩散模型，去除随机性噪声。该方法将扩散网络视为时间步相关的视觉专家集合，自监督地聚合这些异构先验形成一个干净完整的几何先验，并利用任务特定监督将其适配到密集预测任务中。

Result: 在多种密集预测任务上的广泛实验表明，D³-Predictor在不同场景下达到了竞争性或最先进的性能。同时，该方法仅需之前一半的训练数据，并能以单步高效完成推理。

Conclusion: D³-Predictor成功解决了扩散模型中随机噪声与密集预测任务的不匹配问题，提供了一种高效、数据需求少的确定性预测框架，在保持性能的同时显著提升了训练和推理效率。

Abstract: Although diffusion models with strong visual priors have emerged as powerful dense prediction backboens, they overlook a core limitation: the stochastic noise at the core of diffusion sampling is inherently misaligned with dense prediction that requires a deterministic mapping from image to geometry. In this paper, we show that this stochastic noise corrupts fine-grained spatial cues and pushes the model toward timestep-specific noise objectives, consequently destroying meaningful geometric structure mappings. To address this, we introduce $\mathrm{D}^{\mathrm{3}}$-Predictor, a noise-free deterministic framework built by reformulating a pretrained diffusion model without stochasticity noise. Instead of relying on noisy inputs to leverage diffusion priors, $\mathrm{D}^{\mathrm{3}}$-Predictor views the pretrained diffusion network as an ensemble of timestep-dependent visual experts and self-supervisedly aggregates their heterogeneous priors into a single, clean, and complete geometric prior. Meanwhile, we utilize task-specific supervision to seamlessly adapt this noise-free prior to dense prediction tasks. Extensive experiments on various dense prediction tasks demonstrate that $\mathrm{D}^{\mathrm{3}}$-Predictor achieves competitive or state-of-the-art performance in diverse scenarios. In addition, it requires less than half the training data previously used and efficiently performs inference in a single step. Our code, data, and checkpoints are publicly available at https://x-gengroup.github.io/HomePage_D3-Predictor/.

</details>


### [125] [Persistent Homology-Guided Frequency Filtering for Image Compression](https://arxiv.org/abs/2512.07065)
*Anil Chintapalli,Peter Tenholder,Henry Chen,Arjun Rao*

Main category: cs.CV

TL;DR: 本文提出了一种结合离散傅里叶变换和持续性同调分析的特征提取方法，用于在噪声图像数据集中提取特定频率对应的拓扑特征，实现图像压缩和重构。


<details>
  <summary>Details</summary>
Motivation: 解决噪声图像数据集中特征提取的可靠性问题，传统方法在噪声条件下性能受限。

Method: 使用离散傅里叶变换结合持续性同调分析，提取与图像拓扑特征对应的特定频率，实现频率过滤和图像压缩。

Result: 实验结果显示该方法在六种指标下达到与JPEG相当的压缩水平，并在二元分类任务中相比传统方法有潜在性能提升。

Conclusion: 该方法能够有效增强噪声条件下图像压缩的可靠性，为图像处理提供了一种新的拓扑特征引导的频率过滤方法。

Abstract: Feature extraction in noisy image datasets presents many challenges in model reliability. In this paper, we use the discrete Fourier transform in conjunction with persistent homology analysis to extract specific frequencies that correspond with certain topological features of an image. This method allows the image to be compressed and reformed while ensuring that meaningful data can be differentiated. Our experimental results show a level of compression comparable to that of using JPEG using six different metrics. The end goal of persistent homology-guided frequency filtration is its potential to improve performance in binary classification tasks (when augmenting a Convolutional Neural Network) compared to traditional feature extraction and compression methods. These findings highlight a useful end result: enhancing the reliability of image compression under noisy conditions.

</details>


### [126] [Context-measure: Contextualizing Metric for Camouflage](https://arxiv.org/abs/2512.07076)
*Chen-Yang Wang,Gepeng Ji,Song Shao,Ming-Ming Cheng,Deng-Ping Fan*

Main category: cs.CV

TL;DR: 提出了一种新的上下文感知评估范式Context-measure，用于评估伪装场景，克服了现有指标忽略空间上下文相关性的问题。


<details>
  <summary>Details</summary>
Motivation: 当前伪装场景评估指标主要针对一般或显著物体设计，假设空间上下文不相关，无法准确反映伪装效果的实际感知。

Method: 基于概率像素感知相关框架，结合空间依赖性和像素级伪装量化，构建上下文化评估方法。

Result: 在三个具有挑战性的伪装物体分割数据集上的实验表明，Context-measure比现有上下文无关指标更可靠。

Conclusion: Context-measure为涉及伪装模式的计算机视觉应用提供了基础评估基准，适用于农业、工业和医疗等场景。

Abstract: Camouflage is primarily context-dependent yet current metrics for camouflaged scenarios overlook this critical factor. Instead, these metrics are originally designed for evaluating general or salient objects, with an inherent assumption of uncorrelated spatial context. In this paper, we propose a new contextualized evaluation paradigm, Context-measure, built upon a probabilistic pixel-aware correlation framework. By incorporating spatial dependencies and pixel-wise camouflage quantification, our measure better aligns with human perception. Extensive experiments across three challenging camouflaged object segmentation datasets show that Context-measure delivers more reliability than existing context-independent metrics. Our measure can provide a foundational evaluation benchmark for various computer vision applications involving camouflaged patterns, such as agricultural, industrial, and medical scenarios. Code is available at https://github.com/pursuitxi/Context-measure.

</details>


### [127] [DFIR-DETR: Frequency Domain Enhancement and Dynamic Feature Aggregation for Cross-Scene Small Object Detection](https://arxiv.org/abs/2512.07078)
*Bo Gao,Jingcheng Tong,Xingsheng Chen,Han Yu,Zichen Li*

Main category: cs.CV

TL;DR: DFIR-DETR是一种针对小目标检测的轻量级检测器，通过动态特征聚合和频域处理解决特征退化、长距离依赖和特征图膨胀问题，在无人机遥感图像和工业缺陷检测中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决小目标检测中的三个关键问题：特征随网络下采样严重退化、空间卷积无法有效捕获长距离依赖、标准上采样方法导致特征图不必要膨胀。

Method: 提出三个核心模块：DCFA模块使用动态K稀疏注意力降低复杂度，DFPN模块应用幅度归一化上采样防止特征膨胀，FIRC3模块在频域操作实现全局感受野。

Result: 在NEU-DET和VisDrone数据集上分别达到92.9%和51.6%的mAP50，参数量仅11.7M，计算量41.2 GFLOPs，均为当前最优。

Conclusion: DFIR-DETR在两个不同领域都表现出色，证明其具有良好的泛化能力和在资源受限场景下的有效性，适用于跨场景小目标检测。

Abstract: Detecting small objects in UAV remote sensing images and identifying surface defects in industrial inspection remain difficult tasks. These applications face common obstacles: features are sparse and weak, backgrounds are cluttered, and object scales vary dramatically. Current transformer-based detectors, while powerful, struggle with three critical issues. First, features degrade severely as networks downsample progressively. Second, spatial convolutions cannot capture long-range dependencies effectively. Third, standard upsampling methods inflate feature maps unnecessarily.
  We introduce DFIR-DETR to tackle these problems through dynamic feature aggregation combined with frequency-domain processing. Our architecture builds on three novel components. The DCFA module uses dynamic K-sparse attention, cutting complexity from O(N2) down to O(NK), and employs spatial gated linear units for better nonlinear modeling. The DFPN module applies amplitude-normalized upsampling to prevent feature inflation and uses dual-path shuffle convolution to retain spatial details across scales. The FIRC3 module operates in the frequency domain, achieving global receptive fields without sacrificing efficiency.
  We tested our method extensively on NEU-DET and VisDrone datasets. Results show mAP50 scores of 92.9% and 51.6% respectively-both state-of-the-art. The model stays lightweight with just 11.7M parameters and 41.2 GFLOPs. Strong performance across two very different domains confirms that DFIR-DETR generalizes well and works effectively in resource-limited settings for cross-scene small object detection.

</details>


### [128] [COREA: Coarse-to-Fine 3D Representation Alignment Between Relightable 3D Gaussians and SDF via Bidirectional 3D-to-3D Supervision](https://arxiv.org/abs/2512.07107)
*Jaeyoon Lee,Hojoon Jung,Sungtae Hwang,Jihyong Oh,Jongwon Choi*

Main category: cs.CV

TL;DR: COREA是一个统一框架，首次联合学习可重照明的3D高斯和SDF，实现精确几何重建和忠实重照明。通过3D到3D的粗到细双向对齐策略，直接在3D空间中学习几何信号，解决了现有方法几何粗糙和BRDF-光照分解不可靠的问题。


<details>
  <summary>Details</summary>
Motivation: 当前3D高斯溅射方法虽然扩展到网格重建和基于物理的渲染，但其几何仍从2D渲染中学习，导致表面粗糙和BRDF-光照分解不可靠。需要直接在3D空间中学习几何信号以提高重建质量。

Method: 1）引入粗到细双向3D到3D对齐策略：深度提供粗对齐，深度梯度和法向量细化精细结构；2）密度控制机制稳定高斯增长，平衡几何保真度和内存效率；3）联合学习可重照明3D高斯和SDF。

Result: 在标准基准测试中，COREA在新视角合成、网格重建和基于物理的渲染方面均取得优越性能，证明了统一框架的有效性。

Conclusion: COREA通过3D到3D的直接几何学习策略，成功解决了现有方法在几何重建和重照明方面的局限性，为3D重建和渲染提供了更可靠的解决方案。

Abstract: We present COREA, the first unified framework that jointly learns relightable 3D Gaussians and a Signed Distance Field (SDF) for accurate geometry reconstruction and faithful relighting. While recent 3D Gaussian Splatting (3DGS) methods have extended toward mesh reconstruction and physically-based rendering (PBR), their geometry is still learned from 2D renderings, leading to coarse surfaces and unreliable BRDF-lighting decomposition. To address these limitations, COREA introduces a coarse-to-fine bidirectional 3D-to-3D alignment strategy that allows geometric signals to be learned directly in 3D space. Within this strategy, depth provides coarse alignment between the two representations, while depth gradients and normals refine fine-scale structure, and the resulting geometry supports stable BRDF-lighting decomposition. A density-control mechanism further stabilizes Gaussian growth, balancing geometric fidelity with memory efficiency. Experiments on standard benchmarks demonstrate that COREA achieves superior performance in novel-view synthesis, mesh reconstruction, and PBR within a unified framework.

</details>


### [129] [MSN: Multi-directional Similarity Network for Hand-crafted and Deep-synthesized Copy-Move Forgery Detection](https://arxiv.org/abs/2512.07110)
*Liangwei Jiang,Jinluo Xie,Yecheng Huang,Hua Zhang,Hongyu Yang,Di Huang*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的双流模型MSN，用于准确高效的复制-移动图像伪造检测，解决了现有深度检测模型在表示和定位方面的局限性，并在多个基准测试上取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 复制-移动图像伪造检测面临复杂变换和精细操作的挑战，现有深度检测模型在特征表示和区域定位方面存在不足，需要开发更有效的检测方法。

Method: 提出多方向相似性网络(MSN)：1）使用多方向CNN网络进行分层编码，通过多尺度旋转增强实现更好的特征相似性度量；2）设计基于2-D相似性矩阵的解码器，充分利用图像空间信息。

Result: 在CASIA CMFD、CoMoFoD和新提出的深度合成伪造数据库上进行了广泛实验，取得了最先进的检测结果，证明了方法的有效性。

Conclusion: MSN模型通过改进的特征表示和定位机制，显著提升了复制-移动伪造检测性能，同时提出的新数据库为检测深度合成伪造提供了基准。

Abstract: Copy-move image forgery aims to duplicate certain objects or to hide specific contents with copy-move operations, which can be achieved by a sequence of manual manipulations as well as up-to-date deep generative network-based swapping. Its detection is becoming increasingly challenging for the complex transformations and fine-tuned operations on the tampered regions. In this paper, we propose a novel two-stream model, namely Multi-directional Similarity Network (MSN), to accurate and efficient copy-move forgery detection. It addresses the two major limitations of existing deep detection models in \textbf{representation} and \textbf{localization}, respectively. In representation, an image is hierarchically encoded by a multi-directional CNN network, and due to the diverse augmentation in scales and rotations, the feature achieved better measures the similarity between sampled patches in two streams. In localization, we design a 2-D similarity matrix based decoder, and compared with the current 1-D similarity vector based one, it makes full use of spatial information in the entire image, leading to the improvement in detecting tampered regions. Beyond the method, a new forgery database generated by various deep neural networks is presented, as a new benchmark for detecting the growing deep-synthesized copy-move. Extensive experiments are conducted on two classic image forensics benchmarks, \emph{i.e.} CASIA CMFD and CoMoFoD, and the newly presented one. The state-of-the-art results are reported, which demonstrate the effectiveness of the proposed approach.

</details>


### [130] [Training-free Clothing Region of Interest Self-correction for Virtual Try-On](https://arxiv.org/abs/2512.07126)
*Shengjie Lu,Zhibin Wan,Jiejie Liu,Quan Zhang,Mingjie Sun*

Main category: cs.CV

TL;DR: 提出基于能量函数的注意力约束方法，提升虚拟试衣生成效果，并设计新评估指标VTID，在多个数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有虚拟试衣方法在生成服装的图案、纹理和边界方面与目标服装存在差异，且评估指标仅关注图像真实性而忽略与目标元素的对齐。

Method: 使用能量函数对生成过程中的注意力图施加约束，使注意力更聚焦于服装区域；提出VTID评估指标进行更全面的评估。

Result: 在VITON-HD和DressCode数据集上，LPIPS、FID、KID和VTID指标分别提升1.4%、2.3%、12.3%和5.8%；在下游CC-Reid任务中，Rank-1指标在三个数据集上分别提升2.5%、1.1%和1.6%。

Conclusion: 所提方法能有效提升虚拟试衣生成质量，新评估指标VTID能更全面评估生成效果，且生成数据对下游任务有积极影响。

Abstract: VTON (Virtual Try-ON) aims at synthesizing the target clothing on a certain person, preserving the details of the target clothing while keeping the rest of the person unchanged. Existing methods suffer from the discrepancies between the generated clothing results and the target ones, in terms of the patterns, textures and boundaries. Therefore, we propose to use an energy function to impose constraints on the attention map extracted through the generation process. Thus, at each generation step, the attention can be more focused on the clothing region of interest, thereby influencing the generation results to be more consistent with the target clothing details. Furthermore, to address the limitation that existing evaluation metrics concentrate solely on image realism and overlook the alignment with target elements, we design a new metric, Virtual Try-on Inception Distance (VTID), to bridge this gap and ensure a more comprehensive assessment. On the VITON-HD and DressCode datasets, our approach has outperformed the previous state-of-the-art (SOTA) methods by 1.4%, 2.3%, 12.3%, and 5.8% in the traditional metrics of LPIPS, FID, KID, and the new VTID metrics, respectively. Additionally, by applying the generated data to downstream Clothing-Change Re-identification (CC-Reid) methods, we have achieved performance improvements of 2.5%, 1.1%, and 1.6% on the LTCC, PRCC, VC-Clothes datasets in the metrics of Rank-1. The code of our method is public at https://github.com/MrWhiteSmall/CSC-VTON.git.

</details>


### [131] [MulCLIP: A Multi-level Alignment Framework for Enhancing Fine-grained Long-context CLIP](https://arxiv.org/abs/2512.07128)
*Chau Truong,Hieu Ta Quang,Dung D. Le*

Main category: cs.CV

TL;DR: MulCLIP是一个端到端的多层次对齐框架，解决了现有视觉语言模型在处理长文本描述时的局限性，通过全局对比对齐、局部特征重建和子标题聚合补丁对齐来提升细粒度理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（如CLIP）在短文本上表现良好，但在处理长而详细的描述时效果不佳。虽然已有方法利用区域建议信息来映射视觉区域和长文本句子，但部署成本较高。

Method: 1. 保持图像与摘要/长标题的全局对比对齐，扩展位置嵌入以支持更长文本序列
2. 提出局部特征校准的token重建对齐，增强词与图像块之间的语义连接
3. 提出子标题聚合补丁对齐，自动提取和聚合每个子标题的上下文丰富补丁

Result: 在多样化基准测试中，该方法一致提高了下游性能，消融研究证实其多尺度对齐是驱动比区域建议方法更好细粒度能力的关键因素。

Conclusion: MulCLIP的多层次对齐框架有效提升了模型对长文本的理解能力，特别适合多样化的实际应用场景，且相比区域建议方法具有更好的性能和部署优势。

Abstract: Vision-language models like CLIP show impressive ability to align images and text, but their training on short, concise captions makes them struggle with lengthy, detailed descriptions. Recent advances mitigate this challenge by leveraging region-proposal information to map visual regions with corresponding sentences from lengthy captions, yet incurring notable deployment costs. We introduce MulCLIP, a novel end-to-end multi-level alignment framework that bridges natural long-text structures with image components. MulCLIP first preserves global contrastive alignment between images and both summary and long captions, while extending positional embeddings for longer text sequences. To further enhance fine-grained understanding, we propose two novel strategies: (1) a token reconstruction alignment over locally calibrated features to strengthen semantic connections between words and image patches, and (2) a subcaption-aggregated patch alignment that automatically extracts and aggregates context-rich patches for each subcaption. Experimental results across diverse benchmarks demonstrate our method consistently improves downstream performance, while ablation studies confirm its multi-scale alignment is the key factor driving better fine-grained capability than region-proposal-assisted approaches, making it particularly suitable for diverse real-world applications.

</details>


### [132] [TrajMoE: Scene-Adaptive Trajectory Planning with Mixture of Experts and Reinforcement Learning](https://arxiv.org/abs/2512.07135)
*Zebin Xing,Pengxuan Yang,Linbo Wang,Yichen Zhang,Yiming Hu,Yupeng Zheng,Junli Wang,Yinfeng Gao,Guang Li,Kun Ma,Long Chen,Zhongpu Xia,Qichao Zhang,Hangjun Ye,Dongbin Zhao*

Main category: cs.CV

TL;DR: 本文提出了一种改进的自动驾驶规划方法，通过混合专家模型适应不同场景的轨迹先验，并利用强化学习优化轨迹评分机制，在navsim ICCV基准测试中获得51.08分，排名第三。


<details>
  <summary>Details</summary>
Motivation: 当前端到端自动驾驶系统在轨迹规划中存在两个关键问题：1）不同驾驶场景需要不同的轨迹先验分布；2）轨迹评估机制缺乏策略驱动的细化，受限于单阶段监督训练的局限性。

Method: 1）使用混合专家模型为不同场景应用定制化的轨迹先验；2）利用强化学习对轨迹评分机制进行微调；3）集成不同感知骨干网络以增强感知特征。

Result: 在navsim ICCV基准测试中获得了51.08分的成绩，排名第三。

Conclusion: 通过场景自适应的轨迹先验和强化学习优化的评分机制，显著提升了自动驾驶规划性能，证明了多阶段优化方法的有效性。

Abstract: Current autonomous driving systems often favor end-to-end frameworks, which take sensor inputs like images and learn to map them into trajectory space via neural networks. Previous work has demonstrated that models can achieve better planning performance when provided with a prior distribution of possible trajectories. However, these approaches often overlook two critical aspects: 1) The appropriate trajectory prior can vary significantly across different driving scenarios. 2) Their trajectory evaluation mechanism lacks policy-driven refinement, remaining constrained by the limitations of one-stage supervised training. To address these issues, we explore improvements in two key areas. For problem 1, we employ MoE to apply different trajectory priors tailored to different scenarios. For problem 2, we utilize Reinforcement Learning to fine-tune the trajectory scoring mechanism. Additionally, we integrate models with different perception backbones to enhance perceptual features. Our integrated model achieved a score of 51.08 on the navsim ICCV benchmark, securing third place.

</details>


### [133] [A Large-Scale Multimodal Dataset and Benchmarks for Human Activity Scene Understanding and Reasoning](https://arxiv.org/abs/2512.07136)
*Siyang Jiang,Mu Yuan,Xiang Ji,Bufang Yang,Zeyu Liu,Lilin Xu,Yang Li,Yuting He,Liran Dong,Wenrui Lu,Zhenyu Yan,Xiaofan Jiang,Wei Gao,Hongkai Chen,Guoliang Xing*

Main category: cs.CV

TL;DR: CUHK-X是一个大规模多模态数据集和基准套件，用于人类动作识别、理解和推理任务，解决了现有数据集缺乏细粒度文本描述的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型和视觉语言模型难以处理非RGB模态数据（如深度、IMU、毫米波），且现有数据集主要提供粗粒度的数据标签，无法满足细粒度动作理解的需求。

Method: 提出基于提示的场景创建方法，利用LLM生成逻辑连贯的活动序列，并通过人工验证确保一致性。数据集包含58,445个样本，覆盖40个动作，由30名参与者在两个室内环境中完成。

Result: 实验结果显示，在三个基准测试的六个评估任务中，平均准确率分别为：动作识别76.52%，动作理解40.76%，动作推理70.25%。

Conclusion: CUHK-X数据集旨在推动社区应用和发展数据密集型学习方法，实现鲁棒的多模态人类活动分析。

Abstract: Multimodal human action recognition (HAR) leverages complementary sensors for activity classification. Beyond recognition, recent advances in large language models (LLMs) enable detailed descriptions and causal reasoning, motivating new tasks: human action understanding (HAU) and human action reasoning (HARn). However, most LLMs, especially large vision language models (LVLMs), struggle with non-RGB modalities such as depth, IMU, and mmWave due to the lack of large-scale data-caption resources. Existing HAR datasets mainly provide coarse data-label annotations, which are insufficient to capture fine-grained action dynamics needed for HAU and HARn. We consider two ground-truth pair types: (1) data label (discrete category) and (2) data caption (textual description). Naively generating captions from labels often lacks logical and spatiotemporal consistency. We introduce CUHK-X, a large-scale multimodal dataset and benchmark suite for HAR, HAU, and HARn. CUHK-X contains 58,445 samples covering 40 actions performed by 30 participants across two indoor environments. To improve caption consistency, we propose a prompt-based scene creation method that leverages LLMs to generate logically connected activity sequences, followed by human validation. CUHK-X includes three benchmarks with six evaluation tasks. Experiments report average accuracies of 76.52% (HAR), 40.76% (HAU), and 70.25% (HARn). CUHK-X aims to enable the community to apply and develop data-intensive learning methods for robust, multimodal human activity analysis. Project page and code: https://openaiotlab.github.io/CUHK-X/ and https://github.com/openaiotlab/CUHK-X.

</details>


### [134] [Think-Reflect-Revise: A Policy-Guided Reflective Framework for Safety Alignment in Large Vision Language Models](https://arxiv.org/abs/2512.07141)
*Fenghua Weng,Chaochao Lu,Xia Hu,Wenqi Shao,Wenjie Wang*

Main category: cs.CV

TL;DR: 提出Think-Reflect-Revise (TRR)三阶段训练框架，通过策略引导的自我反思增强大视觉语言模型的安全性对齐，将安全响应率从42.8%提升至87.7%。


<details>
  <summary>Details</summary>
Motivation: 现有的单轮思考-回答范式容易受到上下文或视觉越狱攻击，无法有效识别自身输出中的有害内容，需要引入反思机制实现真正的自我修正。

Method: 1) 构建包含5000个样例的Reflective Safety Reasoning数据集；2) 使用ReSafe数据集微调目标模型初始化反思行为；3) 通过强化学习强化策略引导的反思。

Result: TRR显著提升LVLMs在安全意识和越狱攻击评估中的安全性表现，Qwen2.5-VL-7B的安全响应率从42.8%提高到87.7%，同时在MMMU和MMStar等通用基准上保持稳定性能。

Conclusion: 通过反思机制利用首次推理中暴露的恶意内容，TRR框架能够实现有效的自我修正，显著增强大视觉语言模型的安全性对齐能力。

Abstract: As multimodal reasoning improves the overall capabilities of Large Vision Language Models (LVLMs), recent studies have begun to explore safety-oriented reasoning, aiming to enhance safety awareness by analyzing potential safety risks during the reasoning process before generating the final response. Although such approaches improve safety awareness and interpretability, this single-pass think-then-answer paradigm remains vulnerable to contextual or visual jailbreak attacks. This reveals a critical flaw: single-pass reasoning may overlook explicit harmful content in its own output. Our key insight is to exploit this wasted signal through reflection, which can effectively leverage the malicious content revealed in the first-pass reasoning to enable genuine self-correction and prevent unsafe generations. Motivated by this, we propose Think-Reflect-Revise (TRR), a three-stage training framework designed to enhance the safety alignment of LVLMs through policy-guided self-reflection. We first build a Reflective Safety Reasoning (ReSafe) dataset with 5,000 examples that follow a think-reflect-revise process. We then fine-tune the target model using the ReSafe dataset to initialize reflective behavior, and finally reinforce policy-guided reflection through reinforcement learning. Experimental results show that TRR substantially improves the safety performance of LVLMs across both safety-awareness benchmarks and jailbreak attack evaluations, increasing the overall safe response rate from 42.8% to 87.7% on Qwen2.5-VL-7B, while preserving stable performance on general benchmarks such as MMMU and MMStar. The project page is available at https://think-reflect-revise.github.io/.

</details>


### [135] [CHIMERA: Adaptive Cache Injection and Semantic Anchor Prompting for Zero-shot Image Morphing with Morphing-oriented Metrics](https://arxiv.org/abs/2512.07155)
*Dahyeon Kye,Jeahun Sung,MinKyu Jeon,Jihyong Oh*

Main category: cs.CV

TL;DR: CHIMERA是一个基于扩散模型的零样本图像变形框架，通过自适应缓存注入和语义锚点提示实现平滑自然的图像过渡，解决了现有方法在结构对齐和语义一致性方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在图像变形任务中往往产生突兀的过渡或过饱和的外观，主要原因是缺乏自适应的结构和语义对齐机制。

Method: 提出CHIMERA框架：1）自适应缓存注入(ACI)在DDIM反演过程中缓存输入图像的特征并自适应重注入；2）语义锚点提示(SAP)利用视觉语言模型生成共享语义锚点；3）提出全局-局部一致性评分(GLCS)作为变形质量评估指标。

Result: 大量实验和用户研究表明，CHIMERA相比现有方法能够实现更平滑、语义更一致的图像过渡，在图像变形任务上达到了新的最优水平。

Conclusion: CHIMERA通过创新的缓存注入和语义锚点机制，成功解决了扩散模型在图像变形中的关键挑战，为高质量图像变形提供了有效的解决方案。

Abstract: Diffusion models exhibit remarkable generative ability, yet achieving smooth and semantically consistent image morphing remains a challenge. Existing approaches often yield abrupt transitions or over-saturated appearances due to the lack of adaptive structural and semantic alignments. We propose CHIMERA, a zero-shot diffusion-based framework that formulates morphing as a cached inversion-guided denoising process. To handle large semantic and appearance disparities, we propose Adaptive Cache Injection and Semantic Anchor Prompting. Adaptive Cache Injection (ACI) caches down, mid, and up blocks features from both inputs during DDIM inversion and re-injects them adaptively during denoising, enabling spatial and semantic alignment in depth- and time-adaptive manners and enabling natural feature fusion and smooth transitions. Semantic Anchor Prompting (SAP) leverages a vision-language model to generate a shared anchor prompt that serves as a semantic anchor, bridging dissimilar inputs and guiding the denoising process toward coherent results. Finally, we introduce the Global-Local Consistency Score (GLCS), a morphing-oriented metric that simultaneously evaluates the global harmonization of the two inputs and the smoothness of the local morphing transition. Extensive experiments and user studies show that CHIMERA achieves smoother and more semantically aligned transitions than existing methods, establishing a new state of the art in image morphing. The code and project page will be publicly released.

</details>


### [136] [MuSASplat: Efficient Sparse-View 3D Gaussian Splats via Lightweight Multi-Scale Adaptation](https://arxiv.org/abs/2512.07165)
*Muyu Xu,Fangneng Zhan,Xiaoqin Zhang,Ling Shao,Shijian Lu*

Main category: cs.CV

TL;DR: MuSASplat是一个用于稀疏视图3D高斯溅射的新型框架，通过轻量级多尺度适配器和特征融合聚合器显著降低训练计算成本，同时保持高质量的新视角合成效果。


<details>
  <summary>Details</summary>
Motivation: 现有的基于预训练3D先验的无姿态前馈方法虽然效果出色，但需要完整微调大型ViT主干网络，导致GPU计算成本过高。本研究旨在降低训练资源需求的同时保持渲染质量。

Method: 提出轻量级多尺度适配器，仅需微调少量参数即可高效适配ViT架构；设计特征融合聚合器，有效整合多视图特征并降低内存和计算复杂度。

Result: 在多个数据集上的实验表明，MuSASplat在显著减少参数和训练资源需求的同时，达到了最先进的渲染质量。

Conclusion: MuSASplat框架通过创新的适配器和聚合器设计，成功解决了稀疏视图3D高斯溅射训练中的高计算成本问题，为实际应用提供了可行的解决方案。

Abstract: Sparse-view 3D Gaussian splatting seeks to render high-quality novel views of 3D scenes from a limited set of input images. While recent pose-free feed-forward methods leveraging pre-trained 3D priors have achieved impressive results, most of them rely on full fine-tuning of large Vision Transformer (ViT) backbones and incur substantial GPU costs. In this work, we introduce MuSASplat, a novel framework that dramatically reduces the computational burden of training pose-free feed-forward 3D Gaussian splats models with little compromise of rendering quality. Central to our approach is a lightweight Multi-Scale Adapter that enables efficient fine-tuning of ViT-based architectures with only a small fraction of training parameters. This design avoids the prohibitive GPU overhead associated with previous full-model adaptation techniques while maintaining high fidelity in novel view synthesis, even with very sparse input views. In addition, we introduce a Feature Fusion Aggregator that integrates features across input views effectively and efficiently. Unlike widely adopted memory banks, the Feature Fusion Aggregator ensures consistent geometric integration across input views and meanwhile mitigates the memory usage, training complexity, and computational costs significantly. Extensive experiments across diverse datasets show that MuSASplat achieves state-of-the-art rendering quality but has significantly reduced parameters and training resource requirements as compared with existing methods.

</details>


### [137] [When Privacy Meets Recovery: The Overlooked Half of Surrogate-Driven Privacy Preservation for MLLM Editing](https://arxiv.org/abs/2512.07166)
*Siyuan Xu,Yibing Liu,Peilin Chen,Yung-Hui Li,Shiqi Wang,Sam Kwong*

Main category: cs.CV

TL;DR: 本文针对多模态大语言模型中的隐私泄露问题，提出了一种基于替代隐私保护数据的隐私恢复方法，通过构建SPPE数据集和统一恢复框架，在保护隐私的同时保持MLLM编辑质量。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM隐私保护方法虽然能有效模糊隐私信息，但缺乏对用户隐私真实性和恢复质量的评估，无法在保护隐私的同时保证MLLM的可用性。

Method: 构建SPPE数据集包含多种隐私类别和用户指令，将隐私恢复建模为基于互补多模态信号的引导生成任务，提出统一恢复方法可靠重建隐私内容并保持MLLM编辑保真度。

Result: 在SPPE和InstructPix2Pix数据集上的实验表明，该方法能很好地泛化到不同视觉内容和编辑任务，在隐私保护和MLLM可用性之间实现了良好平衡。

Conclusion: 该工作为MLLM隐私保护提供了新的评估视角和解决方案，通过替代驱动的隐私恢复方法有效解决了隐私保护与模型可用性之间的权衡问题。

Abstract: Privacy leakage in Multimodal Large Language Models (MLLMs) has long been an intractable problem. Existing studies, though effectively obscure private information in MLLMs, often overlook the evaluation of the authenticity and recovery quality of user privacy. To this end, this work uniquely focuses on the critical challenge of how to restore surrogate-driven protected data in diverse MLLM scenarios. We first bridge this research gap by contributing the SPPE (Surrogate Privacy Protected Editable) dataset, which includes a wide range of privacy categories and user instructions to simulate real MLLM applications. This dataset offers protected surrogates alongside their various MLLM-edited versions, thus enabling the direct assessment of privacy recovery quality. By formulating privacy recovery as a guided generation task conditioned on complementary multimodal signals, we further introduce a unified approach that reliably reconstructs private content while preserving the fidelity of MLLM-generated edits. The experiments on both SPPE and InstructPix2Pix further show that our approach generalizes well across diverse visual content and editing tasks, achieving a strong balance between privacy protection and MLLM usability.

</details>


### [138] [Towards Unified Semantic and Controllable Image Fusion: A Diffusion Transformer Approach](https://arxiv.org/abs/2512.07170)
*Jiayang Li,Chengjie Jiang,Junjun Jiang,Pengwei Liang,Jiayi Ma,Liqiang Nie*

Main category: cs.CV

TL;DR: DiTFuse是一个基于扩散-Transformer的指令驱动多模态图像融合框架，能够通过自然语言指令灵活控制融合过程，统一处理红外-可见光、多聚焦、多曝光等多种融合任务。


<details>
  <summary>Details</summary>
Motivation: 现有图像融合方法在鲁棒性、适应性和可控性方面存在局限，缺乏用户意图的灵活融入能力，且受限于缺乏真实融合图像标签和小规模数据集的问题。

Method: 采用联合编码双图像和自然语言指令的共享潜空间策略，使用多退化掩码图像建模训练方法，实现跨模态对齐、模态不变恢复和任务感知特征选择。

Result: 在公开的IVIF、MFF和MEF基准测试中表现出优越的定量和定性性能，具有更清晰的纹理和更好的语义保留能力。

Conclusion: DiTFuse在单一架构中统一了多种图像融合任务，支持多级用户控制和零样本泛化，为多模态图像融合提供了新的解决方案。

Abstract: Image fusion aims to blend complementary information from multiple sensing modalities, yet existing approaches remain limited in robustness, adaptability, and controllability. Most current fusion networks are tailored to specific tasks and lack the ability to flexibly incorporate user intent, especially in complex scenarios involving low-light degradation, color shifts, or exposure imbalance. Moreover, the absence of ground-truth fused images and the small scale of existing datasets make it difficult to train an end-to-end model that simultaneously understands high-level semantics and performs fine-grained multimodal alignment. We therefore present DiTFuse, instruction-driven Diffusion-Transformer (DiT) framework that performs end-to-end, semantics-aware fusion within a single model. By jointly encoding two images and natural-language instructions in a shared latent space, DiTFuse enables hierarchical and fine-grained control over fusion dynamics, overcoming the limitations of pre-fusion and post-fusion pipelines that struggle to inject high-level semantics. The training phase employs a multi-degradation masked-image modeling strategy, so the network jointly learns cross-modal alignment, modality-invariant restoration, and task-aware feature selection without relying on ground truth images. A curated, multi-granularity instruction dataset further equips the model with interactive fusion capabilities. DiTFuse unifies infrared-visible, multi-focus, and multi-exposure fusion-as well as text-controlled refinement and downstream tasks-within a single architecture. Experiments on public IVIF, MFF, and MEF benchmarks confirm superior quantitative and qualitative performance, sharper textures, and better semantic retention. The model also supports multi-level user control and zero-shot generalization to other multi-image fusion scenarios, including instruction-conditioned segmentation.

</details>


### [139] [TIDE: Two-Stage Inverse Degradation Estimation with Guided Prior Disentanglement for Underwater Image Restoration](https://arxiv.org/abs/2512.07171)
*Shravan Venkatraman,Rakesh Raj Madavan,Pavan Kumar S,Muthu Subash Kavitha*

Main category: cs.CV

TL;DR: TIDE是一种两阶段水下图像恢复框架，通过分解退化特征并应用针对性恢复策略，有效处理空间变化的复杂水下退化问题。


<details>
  <summary>Details</summary>
Motivation: 现有水下图像恢复方法通常对整个图像应用统一的恢复策略，难以处理空间变化且共存的多种退化问题。水下退化随空间位置和水质条件变化，需要更精细的恢复方法。

Method: TIDE将恢复过程分为两个阶段：首先将水下退化分解为四个关键因素（颜色失真、雾霾、细节丢失和噪声），并设计专门的恢复专家；然后通过自适应融合和渐进细化阶段来平衡竞争性退化因素并修正残余伪影。

Result: 在标准基准和挑战性浑浊水条件下的广泛实验表明，TIDE在基于参考的保真度指标上具有竞争力，同时在非参考感知质量指标上优于现有方法，在颜色校正和对比度增强方面有显著改进。

Conclusion: TIDE框架通过专门的先验分解和自适应融合策略，能够有效处理复杂多变的水下图像退化问题，为海洋应用提供高质量的图像恢复解决方案。

Abstract: Underwater image restoration is essential for marine applications ranging from ecological monitoring to archaeological surveys, but effectively addressing the complex and spatially varying nature of underwater degradations remains a challenge. Existing methods typically apply uniform restoration strategies across the entire image, struggling to handle multiple co-occurring degradations that vary spatially and with water conditions. We introduce TIDE, a $\underline{t}$wo stage $\underline{i}$nverse $\underline{d}$egradation $\underline{e}$stimation framework that explicitly models degradation characteristics and applies targeted restoration through specialized prior decomposition. Our approach disentangles the restoration process into multiple specialized hypotheses that are adaptively fused based on local degradation patterns, followed by a progressive refinement stage that corrects residual artifacts. Specifically, TIDE decomposes underwater degradations into four key factors, namely color distortion, haze, detail loss, and noise, and designs restoration experts specialized for each. By generating specialized restoration hypotheses, TIDE balances competing degradation factors and produces natural results even in highly degraded regions. Extensive experiments across both standard benchmarks and challenging turbid water conditions show that TIDE achieves competitive performance on reference based fidelity metrics while outperforming state of the art methods on non reference perceptual quality metrics, with strong improvements in color correction and contrast enhancement. Our code is available at: https://rakesh-123-cryp.github.io/TIDE.

</details>


### [140] [START: Spatial and Textual Learning for Chart Understanding](https://arxiv.org/abs/2512.07186)
*Zhuoming Liu,Xiaofeng Gao,Feiyang Niu,Qiaozi Gao,Liu Liu,Robinson Piramuthu*

Main category: cs.CV

TL;DR: START是一个用于图表理解的多模态大语言模型，通过空间和文本学习相结合的方法，实现了对图表视觉布局和底层数据结构的精确理解。


<details>
  <summary>Details</summary>
Motivation: 图表理解在科学论文和技术报告分析中至关重要。图表结合了结构化视觉布局（空间属性）和底层数据表示（文本属性），需要同时理解这两个方面才能实现精确的图表推理。

Method: 提出START方法，包含两个关键技术：(1) 图表元素定位 - 增强对图表视觉布局的理解；(2) 图表到代码生成 - 强化对数据细节的掌握。通过创新的数据生成流程创建START数据集，利用MLLM将真实图表转换为可执行代码，再使用LLM演化代码以确定图表元素位置。

Result: START在不同模型规模和基准测试上均表现出优于基线模型的性能提升，明显超越了现有的最先进方法。

Conclusion: START通过空间和文本学习的结合，有效解决了图表理解中的关键挑战，为图表空间理解提供了新的基准CS-Bench，在图表理解任务上取得了显著进展。

Abstract: Chart understanding is crucial for deploying multimodal large language models (MLLMs) in real-world scenarios such as analyzing scientific papers and technical reports. Unlike natural images, charts pair a structured visual layout (spatial property) with an underlying data representation (textual property) -- grasping both is essential for precise, fine-grained chart reasoning. Motivated by this observation, we propose START, the Spatial and Textual learning for chART understanding. Specifically, we introduce (i) chart-element grounding and (ii) chart-to-code generation to strengthen an MLLM's understanding of both chart visual layout and data details. To facilitate spatial and textual learning, we propose the START-Dataset generated with a novel data-generation pipeline that first leverages an MLLM to translate real chart images into executable chart code, recovering the underlying data representation while preserving the visual distribution of real-world charts. We then evolve the code with a Large Language Model (LLM) to ascertain the positions of chart elements that capture the chart's visual structure, addressing challenges that existing methods cannot handle. To evaluate a model's ability to understand chart spatial structures, we propose the Chart Spatial understanding Benchmark (CS-Bench), filling a critical gap in comprehensive chart understanding evaluation. Leveraging spatial and textual learning, START delivers consistent gains across model sizes and benchmarks over the base models and surpasses prior state-of-the-art by a clear margin. Code, data and models will be publicly available.

</details>


### [141] [Integrating Multi-scale and Multi-filtration Topological Features for Medical Image Classification](https://arxiv.org/abs/2512.07190)
*Pengfei Gu,Huimin Li,Haoteng Tang,Dongkuan,Xu,Erik Enriquez,DongChul Kim,Bin Fu,Danny Z. Chen*

Main category: cs.CV

TL;DR: 本文提出了一种新的拓扑引导分类框架，通过多尺度、多过滤的持久拓扑特征增强医学图像分类性能，在三个公开数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度神经网络要么过于关注像素强度特征而忽视基本解剖结构，要么只能通过单参数持久性捕获简单的拓扑特征，无法充分捕捉医学图像中复杂的解剖结构信息。

Method: 1. 计算多分辨率/多尺度的立方持久图；2. 开发"葡萄园"算法将多个持久图整合为单一稳定图；3. 设计基于交叉注意力的神经网络直接处理整合后的持久图；4. 将拓扑嵌入与CNN或Transformer特征图融合。

Result: 在三个公开数据集上的评估显示，该方法相比强基线和最先进方法取得了持续且显著的改进。

Conclusion: 通过将多尺度和多过滤拓扑整合到端到端架构中，该方法增强了模型识别复杂解剖结构的能力，为稳健且可解释的医学图像分类提供了全面的拓扑视角。

Abstract: Modern deep neural networks have shown remarkable performance in medical image classification. However, such networks either emphasize pixel-intensity features instead of fundamental anatomical structures (e.g., those encoded by topological invariants), or they capture only simple topological features via single-parameter persistence. In this paper, we propose a new topology-guided classification framework that extracts multi-scale and multi-filtration persistent topological features and integrates them into vision classification backbones. For an input image, we first compute cubical persistence diagrams (PDs) across multiple image resolutions/scales. We then develop a ``vineyard'' algorithm that consolidates these PDs into a single, stable diagram capturing signatures at varying granularities, from global anatomy to subtle local irregularities that may indicate early-stage disease. To further exploit richer topological representations produced by multiple filtrations, we design a cross-attention-based neural network that directly processes the consolidated final PDs. The resulting topological embeddings are fused with feature maps from CNNs or Transformers. By integrating multi-scale and multi-filtration topologies into an end-to-end architecture, our approach enhances the model's capacity to recognize complex anatomical structures. Evaluations on three public datasets show consistent, considerable improvements over strong baselines and state-of-the-art methods, demonstrating the value of our comprehensive topological perspective for robust and interpretable medical image classification.

</details>


### [142] [RefLSM: Linearized Structural-Prior Reflectance Model for Medical Image Segmentation and Bias-Field Correction](https://arxiv.org/abs/2512.07191)
*Wenqi Zhao,Jiacheng Sang,Fenghua Cheng,Yonglu Shu,Dong Li,Xiaofeng Yang*

Main category: cs.CV

TL;DR: 提出了一种基于Retinex反射率分解的变分水平集模型RefLSM，通过将图像分解为反射率和偏置场分量，直接对光照不变的反射率进行分割，解决了医学图像分割中的强度不均匀性、噪声和边界模糊问题。


<details>
  <summary>Details</summary>
Motivation: 传统水平集方法在严重非均匀成像条件下表现不佳，因为它们依赖于近似的偏置场估计。医学图像分割面临强度不均匀性、噪声、模糊边界和不规则结构的挑战。

Method: RefLSM模型将观察图像分解为反射率和偏置场分量，引入线性结构先验指导平滑反射率梯度，并采用松弛二元水平集通过凸松弛和符号投影实现稳定演化。使用ADMM优化方案高效求解变分问题。

Result: 在多个医学影像数据集上的广泛实验表明，RefLSM相比最先进的水平集方法，在分割精度、鲁棒性和计算效率方面都取得了优越性能。

Conclusion: RefLSM通过反射率分解和结构先验的有效结合，为医学图像分割提供了一种更精确、更鲁棒的解决方案，特别适用于具有挑战性的成像条件。

Abstract: Medical image segmentation remains challenging due to intensity inhomogeneity, noise, blurred boundaries, and irregular structures. Traditional level set methods, while effective in certain cases, often depend on approximate bias field estimations and therefore struggle under severe non-uniform imaging conditions. To address these limitations, we propose a novel variational Reflectance-based Level Set Model (RefLSM), which explicitly integrates Retinex-inspired reflectance decomposition into the segmentation framework. By decomposing the observed image into reflectance and bias field components, RefLSM directly segments the reflectance, which is invariant to illumination and preserves fine structural details. Building on this foundation, we introduce two key innovations for enhanced precision and robustness. First, a linear structural prior steers the smoothed reflectance gradients toward a data-driven reference, providing reliable geometric guidance in noisy or low-contrast scenes. Second, a relaxed binary level-set is embedded in RefLSM and enforced via convex relaxation and sign projection, yielding stable evolution and avoiding reinitialization-induced diffusion. The resulting variational problem is solved efficiently using an ADMM-based optimization scheme. Extensive experiments on multiple medical imaging datasets demonstrate that RefLSM achieves superior segmentation accuracy, robustness, and computational efficiency compared to state-of-the-art level set methods.

</details>


### [143] [HVQ-CGIC: Enabling Hyperprior Entropy Modeling for VQ-Based Controllable Generative Image Compression](https://arxiv.org/abs/2512.07192)
*Niu Yi,Xu Tianyi,Ma Mingming,Wang Xinkun*

Main category: cs.CV

TL;DR: HVQ-CGIC是一个基于VQ超先验的可控生成图像压缩框架，通过引入超先验模型来动态估计VQ索引的熵，显著提升了率失真性能，相比现有方法在相同LPIPS指标下可节省61.3%的比特率。


<details>
  <summary>Details</summary>
Motivation: 现有基于VQ的生成图像压缩方法使用静态全局概率分布估计VQ索引的熵，无法适应不同图像内容，导致比特率潜力未被充分挖掘且难以实现灵活的码率控制。

Method: 提出VQ超先验框架，通过数学推导引入超先验到VQ索引熵模型，设计新颖的损失函数，配合轻量级超先验估计网络实现率失真平衡与控制。

Result: 在Kodak数据集上，与Control-GIC、CDC和HiFiC相比，在相同LPIPS质量下平均节省61.3%的比特率，显著优于当前最先进的生成压缩方法。

Conclusion: HVQ-CGIC有望成为VQGAN-based图像压缩的基础组件，类似于HyperPrior框架在神经图像压缩中的核心作用。

Abstract: Generative learned image compression methods using Vector Quantization (VQ) have recently shown impressive potential in balancing distortion and perceptual quality. However, these methods typically estimate the entropy of VQ indices using a static, global probability distribution, which fails to adapt to the specific content of each image. This non-adaptive approach leads to untapped bitrate potential and challenges in achieving flexible rate control. To address this challenge, we introduce a Controllable Generative Image Compression framework based on a VQ Hyperprior, termed HVQ-CGIC. HVQ-CGIC rigorously derives the mathematical foundation for introducing a hyperprior to the VQ indices entropy model. Based on this foundation, through novel loss design, to our knowledge, this framework is the first to introduce RD balance and control into vector quantization-based Generative Image Compression. Cooperating with a lightweight hyper-prior estimation network, HVQ-CGIC achieves a significant advantage in rate-distortion (RD) performance compared to current state-of-the-art (SOTA) generative compression methods. On the Kodak dataset, we achieve the same LPIPS as Control-GIC, CDC and HiFiC with an average of 61.3% fewer bits. We posit that HVQ-CGIC has the potential to become a foundational component for VQGAN-based image compression, analogous to the integral role of the HyperPrior framework in neural image compression.

</details>


### [144] [SUCCESS-GS: Survey of Compactness and Compression for Efficient Static and Dynamic Gaussian Splatting](https://arxiv.org/abs/2512.07197)
*Seokhyun Youn,Soohyun Lee,Geonho Kim,Weeyoung Kwon,Sung-Ho Bae,Jihyong Oh*

Main category: cs.CV

TL;DR: 这篇论文是关于高效3D和4D高斯溅射技术的综述，系统地分类了参数压缩和结构压缩两种主要方法，并总结了该领域的数据集、评估指标和发展方向。


<details>
  <summary>Details</summary>
Motivation: 3D高斯溅射虽然能够实现实时高保真3D重建，但其巨大的内存和计算需求限制了实际应用，特别是在4D动态场景中更为严重。需要研究高效方法来减少冗余同时保持重建质量。

Method: 采用系统综述方法，将现有技术分为参数压缩和结构压缩两大方向，对每种方法的核心思想和方法趋势进行全面总结，并涵盖数据集、评估指标和基准比较。

Result: 提供了首个统一的高效3D和4D高斯溅射技术概览，建立了系统的分类框架，总结了当前方法的发展现状和技术特点。

Conclusion: 讨论了当前局限性，并指出了未来研究方向，旨在实现可扩展、紧凑和实时的静态与动态3D场景高斯溅射表示。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a powerful explicit representation enabling real-time, high-fidelity 3D reconstruction and novel view synthesis. However, its practical use is hindered by the massive memory and computational demands required to store and render millions of Gaussians. These challenges become even more severe in 4D dynamic scenes. To address these issues, the field of Efficient Gaussian Splatting has rapidly evolved, proposing methods that reduce redundancy while preserving reconstruction quality. This survey provides the first unified overview of efficient 3D and 4D Gaussian Splatting techniques. For both 3D and 4D settings, we systematically categorize existing methods into two major directions, Parameter Compression and Restructuring Compression, and comprehensively summarize the core ideas and methodological trends within each category. We further cover widely used datasets, evaluation metrics, and representative benchmark comparisons. Finally, we discuss current limitations and outline promising research directions toward scalable, compact, and real-time Gaussian Splatting for both static and dynamic 3D scene representation.

</details>


### [145] [Generating Storytelling Images with Rich Chains-of-Reasoning](https://arxiv.org/abs/2512.07198)
*Xiujie Song,Qi Jia,Shota Watanabe,Xiaoyi Pang,Ruijie Chen,Mengyue Wu,Kenny Q. Zhu*

Main category: cs.CV

TL;DR: 本文提出了Storytelling Image Generation任务，通过结合大型语言模型和文本到图像模型的优势来生成具有复杂语义和故事性的图像。


<details>
  <summary>Details</summary>
Motivation: 现有的图像生成技术难以创建具有丰富逻辑连接和故事性的图像，这类图像在多个应用领域具有重要价值但数量稀缺。

Method: 提出两阶段流水线StorytellingPainter，利用LLMs的推理能力生成故事描述，再通过T2I模型生成图像。同时开发了专门的评估框架和训练了轻量级模型Mini-Storytellers。

Result: 实验结果表明该方法在生成具有故事性图像方面是可行且有效的。

Conclusion: 该研究为生成具有复杂语义的故事性图像提供了新的解决方案，并通过专门的评估框架确保了生成质量。

Abstract: An image can convey a compelling story by presenting rich, logically connected visual clues. These connections form Chains-of-Reasoning (CoRs) within the image, enabling viewers to infer events, causal relationships, and other information, thereby understanding the underlying story. In this paper, we focus on these semantically rich images and define them as Storytelling Images. Such images have diverse applications beyond illustration creation and cognitive screening, leveraging their ability to convey multi-layered information visually and inspire active interpretation. However, due to their complex semantic nature, Storytelling Images are inherently challenging to create, and thus remain relatively scarce. To address this challenge, we introduce the Storytelling Image Generation task, which explores how generative AI models can be leveraged to create such images. Specifically, we propose a two-stage pipeline, StorytellingPainter, which combines the creative reasoning abilities of Large Language Models (LLMs) with the visual synthesis capabilities of Text-to-Image (T2I) models to generate Storytelling Images. Alongside this pipeline, we develop a dedicated evaluation framework comprising three main evaluators: a Semantic Complexity Evaluator, a KNN-based Diversity Evaluator and a Story-Image Alignment Evaluator. Given the critical role of story generation in the Storytelling Image Generation task and the performance disparity between open-source and proprietary LLMs, we further explore tailored training strategies to reduce this gap, resulting in a series of lightweight yet effective models named Mini-Storytellers. Experimental results demonstrate the feasibility and effectiveness of our approaches. The code is available at https://github.com/xiujiesong/StorytellingImageGeneration.

</details>


### [146] [Understanding Diffusion Models via Code Execution](https://arxiv.org/abs/2512.07201)
*Cheng Yu*

Main category: cs.CV

TL;DR: 本文提供了一个约300行代码的简洁扩散模型实现，从代码执行角度解释扩散模型的工作原理，填补了理论推导与实际实现之间的鸿沟。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在生成建模中表现出色，但理论复杂且论文中的数学公式与开源实现之间存在较大差距。现有教程主要关注方程推导，对代码实现指导有限。

Method: 开发了一个最小化实现，包含前向扩散、反向采样、噪声预测网络和训练循环等核心组件，去除了不必要的工程细节。

Result: 提供了一个清晰、实现优先的理解方式，展示了扩散模型在实践中的工作原理以及代码与理论的对应关系。

Conclusion: 该技术报告为研究人员提供了从代码角度理解扩散模型的实用工具，代码和预训练模型已开源。

Abstract: Diffusion models have achieved remarkable performance in generative modeling, yet their theoretical foundations are often intricate, and the gap between mathematical formulations in papers and practical open-source implementations can be difficult to bridge. Existing tutorials primarily focus on deriving equations, offering limited guidance on how diffusion models actually operate in code. To address this, we present a concise implementation of approximately 300 lines that explains diffusion models from a code-execution perspective. Our minimal example preserves the essential components -- including forward diffusion, reverse sampling, the noise-prediction network, and the training loop -- while removing unnecessary engineering details. This technical report aims to provide researchers with a clear, implementation-first understanding of how diffusion models work in practice and how code and theory correspond. Our code and pre-trained models are available at: https://github.com/disanda/GM/tree/main/DDPM-DDIM-ClassifierFree.

</details>


### [147] [MMRPT: MultiModal Reinforcement Pre-Training via Masked Vision-Dependent Reasoning](https://arxiv.org/abs/2512.07203)
*Xuhui Zheng,Kang An,Ziliang Wang,Yuhang Wang,Faqiang Qian,Yichao Wu*

Main category: cs.CV

TL;DR: MMRPT是一个基于强化学习的多模态预训练框架，通过掩码多模态数据和视觉语义奖励机制，增强多模态大语言模型的视觉推理能力，解决传统图像-文本对预训练中的描述性偏差问题。


<details>
  <summary>Details</summary>
Motivation: 传统多模态预训练受限于图像-文本对的描述性偏差，导致模型更倾向于学习表面语言线索而非真正的视觉理解。需要一种能够强化视觉推理能力的预训练方法。

Method: 提出掩码多模态强化预训练框架：1）通过视觉token注意力估计句子级视觉依赖度；2）掩码高度视觉依赖的文本片段；3）使用基于视觉语义的奖励机制指导模型进行视觉推理重建。首次将强化学习直接融入大型视觉语言模型的预训练中。

Result: 实验显示在多个基准测试中均获得一致的零样本性能提升，在有监督微调下显著提高了模型鲁棒性。

Conclusion: 强化学习驱动的掩码推理为多模态模型提供了更可靠和可泛化的预训练目标，能够有效提升模型的视觉推理能力。

Abstract: Multimodal pre-training remains constrained by the descriptive bias of image-caption pairs, leading models to favor surface linguistic cues over grounded visual understanding. We introduce MMRPT, a masked multimodal reinforcement pre-training framework that strengthens visual reasoning in MLLMs. We are the first to incorporate reinforcement learning directly into the pre-training of large vision-language models, enabling learning signals that reward visual grounding rather than caption imitation. MMRPT constructs masked multimodal data by estimating sentence-level visual dependency via attention over visual tokens and masking highly vision-dependent segments; the model reconstructs these spans through vision-grounded reasoning guided by a semantic-visual reward. Experiments show consistent zero-shot gains across diverse benchmarks and substantially improved robustness under supervised fine-tuning, demonstrating that reinforcement-driven masked reasoning provides a more reliable and generalizable pre-training objective for multimodal models.

</details>


### [148] [AutoLugano: A Deep Learning Framework for Fully Automated Lymphoma Segmentation and Lugano Staging on FDG-PET/CT](https://arxiv.org/abs/2512.07206)
*Boyang Pan,Zeyu Zhang,Hongyu Meng,Bin Cui,Yingying Zhang,Wenli Hou,Junhao Li,Langdi Zhong,Xiaoxiao Chen,Xiaoyu Xu,Changjin Zuo,Chao Cheng,Nan-Jie Gong*

Main category: cs.CV

TL;DR: AutoLugano是一个全自动深度学习系统，能够从FDG-PET/CT扫描中自动完成淋巴瘤分类，包括病灶分割、解剖定位和Lugano分期，在外部验证中表现出色。


<details>
  <summary>Details</summary>
Motivation: 开发一个端到端的自动化系统，帮助临床医生进行淋巴瘤的初始分期、治疗分层和临床决策支持。

Method: 系统包含三个模块：1）基于3D nnU-Net的解剖感知病灶分割；2）使用TotalSegmentator工具包进行基于图谱的解剖定位；3）将受累区域空间分布转换为Lugano分期和治疗分组。

Result: 在外部验证集上，区域受累检测准确率88.31%，敏感性74.47%，特异性94.21%，F1分数80.80%；治疗分层准确率85.07%，敏感性82.61%，特异性90.48%。

Conclusion: AutoLugano是首个完全自动化的端到端管道，能够将单次FDG-PET/CT扫描转换为完整的Lugano分期，具有重要的临床应用潜力。

Abstract: Purpose: To develop a fully automated deep learning system, AutoLugano, for end-to-end lymphoma classification by performing lesion segmentation, anatomical localization, and automated Lugano staging from baseline FDG-PET/CT scans. Methods: The AutoLugano system processes baseline FDG-PET/CT scans through three sequential modules:(1) Anatomy-Informed Lesion Segmentation, a 3D nnU-Net model, trained on multi-channel inputs, performs automated lesion detection (2) Atlas-based Anatomical Localization, which leverages the TotalSegmentator toolkit to map segmented lesions to 21 predefined lymph node regions using deterministic anatomical rules; and (3) Automated Lugano Staging, where the spatial distribution of involved regions is translated into Lugano stages and therapeutic groups (Limited vs. Advanced Stage).The system was trained on the public autoPET dataset (n=1,007) and externally validated on an independent cohort of 67 patients. Performance was assessed using accuracy, sensitivity, specificity, F1-scorefor regional involvement detection and staging agreement. Results: On the external validation set, the proposed model demonstrated robust performance, achieving an overall accuracy of 88.31%, sensitivity of 74.47%, Specificity of 94.21% and an F1-score of 80.80% for regional involvement detection,outperforming baseline models. Most notably, for the critical clinical task of therapeutic stratification (Limited vs. Advanced Stage), the system achieved a high accuracy of 85.07%, with a specificity of 90.48% and a sensitivity of 82.61%.Conclusion: AutoLugano represents the first fully automated, end-to-end pipeline that translates a single baseline FDG-PET/CT scan into a complete Lugano stage. This study demonstrates its strong potential to assist in initial staging, treatment stratification, and supporting clinical decision-making.

</details>


### [149] [Object Pose Distribution Estimation for Determining Revolution and Reflection Uncertainty in Point Clouds](https://arxiv.org/abs/2512.07211)
*Frederik Hagelskjær,Dimitrios Arapis,Steffen Madsen,Thorbjørn Mosekjær Iversen*

Main category: cs.CV

TL;DR: 提出一种基于神经网络的方法，仅使用3D无色数据估计物体姿态不确定性，这是首个不依赖RGB输入的深度学习姿态分布估计方法。


<details>
  <summary>Details</summary>
Motivation: 传统单姿态估计无法捕捉视觉模糊性带来的姿态不确定性，而现有姿态分布方法严重依赖颜色信息，在工业场景中往往不可用。

Method: 开发神经网络模型，利用3D几何数据估计物体姿态分布，重点关注反射和旋转对称性，但框架可扩展至完整的SE(3)姿态分布估计。

Result: 在具有不同几何模糊度的真实世界箱式拣选场景中验证了方法的有效性。

Conclusion: 该方法为工业应用提供了一种不依赖颜色信息的可靠姿态不确定性估计解决方案，源代码已公开。

Abstract: Object pose estimation is crucial to robotic perception and typically provides a single-pose estimate. However, a single estimate cannot capture pose uncertainty deriving from visual ambiguity, which can lead to unreliable behavior. Existing pose distribution methods rely heavily on color information, often unavailable in industrial settings.
  We propose a novel neural network-based method for estimating object pose uncertainty using only 3D colorless data. To the best of our knowledge, this is the first approach that leverages deep learning for pose distribution estimation without relying on RGB input. We validate our method in a real-world bin picking scenario with objects of varying geometric ambiguity. Our current implementation focuses on symmetries in reflection and revolution, but the framework is extendable to full SE(3) pose distribution estimation. Source code available at opde3d.github.io

</details>


### [150] [VFM-VLM: Vision Foundation Model and Vision Language Model based Visual Comparison for 3D Pose Estimation](https://arxiv.org/abs/2512.07215)
*Md Selim Sarowar,Sungho Kim*

Main category: cs.CV

TL;DR: 本文比较了基于CLIP和DINOv2的视觉基础模型在3D手部物体抓取姿态估计任务中的表现，发现CLIP在语义理解方面表现更好，而DINOv2在几何特征提取方面更优。


<details>
  <summary>Details</summary>
Motivation: 视觉基础模型(VFMs)和视觉语言模型(VLMs)为计算机视觉提供了丰富的语义和几何表示，本文旨在系统比较CLIP和DINOv2在3D姿态估计任务中的互补优势。

Method: 在基准数据集上进行全面的视觉比较实验，评估CLIP和DINOv2在6D物体姿态估计任务中的表现，分析两者的语义理解和几何特征提取能力。

Result: 实验表明：CLIP基于方法在语义一致性方面表现更好，DINOv2基于方法在几何精度方面具有竞争优势，两者在3D姿态估计中展现出互补优势。

Conclusion: 研究结果为机器人和抓取应用中选择合适的视觉模型提供了指导，建议根据具体任务需求选择CLIP（语义理解）或DINOv2（几何精度）模型。

Abstract: Vision Foundation Models (VFMs) and Vision Language Models (VLMs) have revolutionized computer vision by providing rich semantic and geometric representations. This paper presents a comprehensive visual comparison between CLIP based and DINOv2 based approaches for 3D pose estimation in hand object grasping scenarios. We evaluate both models on the task of 6D object pose estimation and demonstrate their complementary strengths: CLIP excels in semantic understanding through language grounding, while DINOv2 provides superior dense geometric features. Through extensive experiments on benchmark datasets, we show that CLIP based methods achieve better semantic consistency, while DINOv2 based approaches demonstrate competitive performance with enhanced geometric precision. Our analysis provides insights for selecting appropriate vision models for robotic manipulation and grasping, picking applications.

</details>


### [151] [Towards Robust Protective Perturbation against DeepFake Face Swapping](https://arxiv.org/abs/2512.07228)
*Hengyang Yao,Lin Li,Ke Sun,Jianing Qiu,Huiping Chen*

Main category: cs.CV

TL;DR: 本文提出了EOLT框架，通过强化学习自动学习最优变换分布来生成更鲁棒的DeepFake防护扰动，相比传统方法在平均鲁棒性上提升26%。


<details>
  <summary>Details</summary>
Motivation: 现有DeepFake防护方法嵌入的隐形扰动易被基本图像变换破坏，且传统EOT框架的均匀采样变换分布存在根本性不足。

Method: 提出EOLT框架，将变换分布作为可学习组件，使用策略网络通过强化学习自动优先关键变换并生成实例特定的扰动。

Result: 在6类30种变换上的实验表明，该方法相比最先进方法平均鲁棒性提升26%，在挑战性变换类别上增益达30%。

Conclusion: EOLT通过可学习的变换分布有效建模防御瓶颈，显著提升了DeepFake防护的鲁棒性和泛化能力。

Abstract: DeepFake face swapping enables highly realistic identity forgeries, posing serious privacy and security risks. A common defence embeds invisible perturbations into images, but these are fragile and often destroyed by basic transformations such as compression or resizing. In this paper, we first conduct a systematic analysis of 30 transformations across six categories and show that protection robustness is highly sensitive to the choice of training transformations, making the standard Expectation over Transformation (EOT) with uniform sampling fundamentally suboptimal. Motivated by this, we propose Expectation Over Learned distribution of Transformation (EOLT), the framework to treat transformation distribution as a learnable component rather than a fixed design choice. Specifically, EOLT employs a policy network that learns to automatically prioritize critical transformations and adaptively generate instance-specific perturbations via reinforcement learning, enabling explicit modeling of defensive bottlenecks while maintaining broad transferability. Extensive experiments demonstrate that our method achieves substantial improvements over state-of-the-art approaches, with 26% higher average robustness and up to 30% gains on challenging transformation categories.

</details>


### [152] [ReLKD: Inter-Class Relation Learning with Knowledge Distillation for Generalized Category Discovery](https://arxiv.org/abs/2512.07229)
*Fang Zhou,Zhiqiang Chen,Martin Pavlovski,Yizhong Zhang*

Main category: cs.CV

TL;DR: ReLKD是一个端到端的广义类别发现框架，通过利用隐式类别间关系来增强新类别的分类性能，特别适用于标记数据有限的场景。


<details>
  <summary>Details</summary>
Motivation: 广义类别发现(GCD)面临在只有已知类别标签的情况下对包含已知和未知类别的未标记数据进行分类的挑战。现有研究通常独立处理每个类别，忽略了固有的类别间关系，而直接获取这些关系在现实场景中具有显著挑战。

Method: ReLKD包含三个关键模块：目标粒度模块用于学习判别性表示，粗粒度模块用于捕获层次化类别关系，蒸馏模块用于将知识从粗粒度模块转移到目标粒度模块以优化表示学习。

Result: 在四个数据集上的广泛实验证明了ReLKD的有效性，特别是在标记数据有限的场景下表现优异。

Conclusion: ReLKD通过有效利用隐式类别间关系，成功提升了新类别的分类性能，为解决广义类别发现问题提供了有效的端到端解决方案。

Abstract: Generalized Category Discovery (GCD) faces the challenge of categorizing unlabeled data containing both known and novel classes, given only labels for known classes. Previous studies often treat each class independently, neglecting the inherent inter-class relations. Obtaining such inter-class relations directly presents a significant challenge in real-world scenarios. To address this issue, we propose ReLKD, an end-to-end framework that effectively exploits implicit inter-class relations and leverages this knowledge to enhance the classification of novel classes. ReLKD comprises three key modules: a target-grained module for learning discriminative representations, a coarse-grained module for capturing hierarchical class relations, and a distillation module for transferring knowledge from the coarse-grained module to refine the target-grained module's representation learning. Extensive experiments on four datasets demonstrate the effectiveness of ReLKD, particularly in scenarios with limited labeled data. The code for ReLKD is available at https://github.com/ZhouF-ECNU/ReLKD.

</details>


### [153] [STRinGS: Selective Text Refinement in Gaussian Splatting](https://arxiv.org/abs/2512.07230)
*Abhinav Raundhal,Gaurav Behera,P J Narayanan,Ravi Kiran Sarvadevabhatla,Makarand Tapaswi*

Main category: cs.CV

TL;DR: STRinGS是一个针对3D高斯泼溅(3DGS)的文本感知选择性优化框架，通过分别处理文本和非文本区域来解决文本细节重建问题，显著提升文本可读性。


<details>
  <summary>Details</summary>
Motivation: 现实场景中的文本元素承载重要语义信息，但现有3D表示方法如3DGS难以保留细粒度文本细节，小的文本重建错误会导致严重语义损失。

Method: 采用文本感知的选择性优化框架，将文本和非文本区域分开处理：先优化文本区域，然后与优化后的非文本区域合并进行全场景优化。

Result: STRinGS在仅7K次迭代下相对3DGS实现了63.6%的改进，能够生成清晰可读的文本，即使在挑战性配置下也表现良好。

Conclusion: 该方法与配套的STRinGS-360数据集共同推动了文本丰富环境中3D场景理解的边界，为更鲁棒的文本感知重建方法铺平了道路。

Abstract: Text as signs, labels, or instructions is a critical element of real-world scenes as they can convey important contextual information. 3D representations such as 3D Gaussian Splatting (3DGS) struggle to preserve fine-grained text details, while achieving high visual fidelity. Small errors in textual element reconstruction can lead to significant semantic loss. We propose STRinGS, a text-aware, selective refinement framework to address this issue for 3DGS reconstruction. Our method treats text and non-text regions separately, refining text regions first and merging them with non-text regions later for full-scene optimization. STRinGS produces sharp, readable text even in challenging configurations. We introduce a text readability measure OCR Character Error Rate (CER) to evaluate the efficacy on text regions. STRinGS results in a 63.6% relative improvement over 3DGS at just 7K iterations. We also introduce a curated dataset STRinGS-360 with diverse text scenarios to evaluate text readability in 3D reconstruction. Our method and dataset together push the boundaries of 3D scene understanding in text-rich environments, paving the way for more robust text-aware reconstruction methods.

</details>


### [154] [Dropout Prompt Learning: Towards Robust and Adaptive Vision-Language Models](https://arxiv.org/abs/2512.07234)
*Biao Chen,Lin Zuo,Mengmeng Jing,Kunbin He,Yuchen Wang*

Main category: cs.CV

TL;DR: 本文提出Dropout Prompt Learning方法，通过在视觉和文本分支的token上应用基于重要性的dropout，并结合残差熵正则化，提升视觉语言模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统dropout方法在视觉语言模型中的应用不够灵活，无法考虑token的重要性和跨模态对齐关系。本文旨在通过更智能的dropout策略提升模型在低样本学习、长尾分类和分布外泛化等挑战性场景下的性能。

Method: 1) 在文本和视觉分支的token上应用dropout，根据token的模态内上下文和跨模态对齐关系评估重要性；2) 提出残差熵正则化，在保持语义对齐的同时鼓励dropout带来的多样性表示。

Result: 在15个基准测试中验证了方法的有效性，特别是在基础到新类泛化任务上，性能超过KgCoOp 5.10%和PromptSRC 2.13%。

Conclusion: Dropout Prompt Learning通过智能化的token级dropout和残差熵正则化，显著提升了视觉语言模型的鲁棒性和泛化能力。

Abstract: Dropout is a widely used regularization technique which improves the generalization ability of a model by randomly dropping neurons. In light of this, we propose Dropout Prompt Learning, which aims for applying dropout to improve the robustness of the vision-language models. Different from the vanilla dropout, we apply dropout on the tokens of the textual and visual branches, where we evaluate the token significance considering both intra-modal context and inter-modal alignment, enabling flexible dropout probabilities for each token. Moreover, to maintain semantic alignment for general knowledge transfer while encouraging the diverse representations that dropout introduces, we further propose residual entropy regularization. Experiments on 15 benchmarks show our method's effectiveness in challenging scenarios like low-shot learning, long-tail classification, and out-of-distribution generalization. Notably, our method surpasses regularization-based methods including KgCoOp by 5.10% and PromptSRC by 2.13% in performance on base-to-novel generalization.

</details>


### [155] [Unified Camera Positional Encoding for Controlled Video Generation](https://arxiv.org/abs/2512.07237)
*Cheng Zhang,Boying Li,Meng Wei,Yan-Pei Cao,Camilo Cruz Gambardella,Dinh Phung,Jianfei Cai*

Main category: cs.CV

TL;DR: 本文提出了UCPE（统一相机位置编码），一种几何一致的相机表示方法，通过相对光线编码和绝对方向编码实现相机控制的视频生成，在保持视觉质量的同时显著提升了相机控制能力。


<details>
  <summary>Details</summary>
Motivation: 现有相机编码方法通常基于简化的针孔假设，限制了在真实世界相机多样内参和镜头畸变下的泛化能力。需要一种能够统一完整相机信息的几何一致表示方法。

Method: 提出相对光线编码（Relative Ray Encoding）统一相机位姿、内参和镜头畸变信息，结合绝对方向编码控制初始相机方向，通过轻量级空间注意力适配器集成到预训练的视频扩散Transformer中。

Result: UCPE仅增加不到1%的可训练参数，在相机控制视频生成任务中实现了最先进的相机控制能力和视觉保真度，构建了大规模视频数据集进行系统评估。

Conclusion: UCPE作为一种通用的相机表示方法，在相机控制视频生成中表现出色，并具有在多视图、视频和3D任务中广泛应用Transformer的潜力。

Abstract: Transformers have emerged as a universal backbone across 3D perception, video generation, and world models for autonomous driving and embodied AI, where understanding camera geometry is essential for grounding visual observations in three-dimensional space. However, existing camera encoding methods often rely on simplified pinhole assumptions, restricting generalization across the diverse intrinsics and lens distortions in real-world cameras. We introduce Relative Ray Encoding, a geometry-consistent representation that unifies complete camera information, including 6-DoF poses, intrinsics, and lens distortions. To evaluate its capability under diverse controllability demands, we adopt camera-controlled text-to-video generation as a testbed task. Within this setting, we further identify pitch and roll as two components effective for Absolute Orientation Encoding, enabling full control over the initial camera orientation. Together, these designs form UCPE (Unified Camera Positional Encoding), which integrates into a pretrained video Diffusion Transformer through a lightweight spatial attention adapter, adding less than 1% trainable parameters while achieving state-of-the-art camera controllability and visual fidelity. To facilitate systematic training and evaluation, we construct a large video dataset covering a wide range of camera motions and lens types. Extensive experiments validate the effectiveness of UCPE in camera-controllable video generation and highlight its potential as a general camera representation for Transformers across future multi-view, video, and 3D tasks. Code will be available at https://github.com/chengzhag/UCPE.

</details>


### [156] [Squeezed-Eff-Net: Edge-Computed Boost of Tomography Based Brain Tumor Classification leveraging Hybrid Neural Network Architecture](https://arxiv.org/abs/2512.07241)
*Md. Srabon Chowdhury,Syeda Fahmida Tanzim,Sheekar Banerjee,Ishtiak Al Mamoon,AKM Muzahidul Islam*

Main category: cs.CV

TL;DR: 提出基于SqueezeNet v1和EfficientNet-B0的混合深度学习模型，结合手工放射组学特征，用于脑肿瘤MRI图像的自动分类，在公开数据集上达到98.93%的测试准确率。


<details>
  <summary>Details</summary>
Motivation: 脑肿瘤诊断需要及时准确，但MRI图像中肿瘤勾画过程困难且耗时，容易产生观察者间误差，需要自动化解决方案。

Method: 结合轻量级SqueezeNet v1和高性能EfficientNet-B0，增强HOG、LBP、Gabor滤波器和小波变换等手工放射组学特征，在7,023张MRI切片数据集上进行训练测试。

Result: 模型测试准确率达98.93%，使用测试时间增强后提升至99.08%，仅需210万参数和1.2 GFLOPs计算量，表现出良好的泛化能力。

Conclusion: 该混合网络在计算效率和诊断准确性之间取得平衡，具有临床可靠性，可用于临床决策支持系统。

Abstract: Brain tumors are one of the most common and dangerous neurological diseases which require a timely and correct diagnosis to provide the right treatment procedures. Even with the promotion of magnetic resonance imaging (MRI), the process of tumor delineation is difficult and time-consuming, which is prone to inter-observer error. In order to overcome these limitations, this work proposes a hybrid deep learning model based on SqueezeNet v1 which is a lightweight model, and EfficientNet-B0, which is a high-performing model, and is enhanced with handcrafted radiomic descriptors, including Histogram of Oriented Gradients (HOG), Local Binary Patterns (LBP), Gabor filters and Wavelet transforms. The framework was trained and tested only on publicly available Nickparvar Brain Tumor MRI dataset, which consisted of 7,023 contrast-enhanced T1-weighted axial MRI slices which were categorized into four groups: glioma, meningioma, pituitary tumor, and no tumor. The testing accuracy of the model was 98.93% that reached a level of 99.08% with Test Time Augmentation (TTA) showing great generalization and power. The proposed hybrid network offers a compromise between computation efficiency and diagnostic accuracy compared to current deep learning structures and only has to be trained using fewer than 2.1 million parameters and less than 1.2 GFLOPs. The handcrafted feature addition allowed greater sensitivity in texture and the EfficientNet-B0 backbone represented intricate hierarchical features. The resulting model has almost clinical reliability in automated MRI-based classification of tumors highlighting its possibility of use in clinical decision-support systems.

</details>


### [157] [Zero-Shot Textual Explanations via Translating Decision-Critical Features](https://arxiv.org/abs/2512.07245)
*Toshinori Yamauchi,Hiroshi Kera,Kazuhiko Kawamoto*

Main category: cs.CV

TL;DR: TEXTER是一种新的图像分类器解释方法，通过识别决策关键特征并映射到CLIP特征空间来生成更忠实和可解释的文本解释。


<details>
  <summary>Details</summary>
Motivation: 现有零样本解释方法仅关注全局图像特征，生成的是可见内容的描述而非驱动预测的关键因素。需要一种能反映分类器特定推理过程的解释方法。

Method: 1) 识别对预测贡献最大的神经元；2) 强调这些神经元编码的决策关键特征；3) 将强调的特征映射到CLIP特征空间检索文本解释；4) 使用稀疏自编码器提高Transformer架构的可解释性。

Result: 大量实验表明，TEXTER比现有方法生成更忠实和可解释的解释，能更好地反映模型的推理过程。

Conclusion: TEXTER通过隔离决策关键特征的方法，有效解决了现有解释方法无法反映分类器特定推理的问题，为图像分类器提供了更透明的决策解释。

Abstract: Textual explanations make image classifier decisions transparent by describing the prediction rationale in natural language. Large vision-language models can generate captions but are designed for general visual understanding, not classifier-specific reasoning. Existing zero-shot explanation methods align global image features with language, producing descriptions of what is visible rather than what drives the prediction. We propose TEXTER, which overcomes this limitation by isolating decision-critical features before alignment. TEXTER identifies the neurons contributing to the prediction and emphasizes the features encoded in those neurons -- i.e., the decision-critical features. It then maps these emphasized features into the CLIP feature space to retrieve textual explanations that reflect the model's reasoning. A sparse autoencoder further improves interpretability, particularly for Transformer architectures. Extensive experiments show that TEXTER generates more faithful and interpretable explanations than existing methods. The code will be publicly released.

</details>


### [158] [AdLift: Lifting Adversarial Perturbations to Safeguard 3D Gaussian Splatting Assets Against Instruction-Driven Editing](https://arxiv.org/abs/2512.07247)
*Ziming Hong,Tianyu Huang,Runnan Chen,Shanshan Ye,Mingming Gong,Bo Han,Tongliang Liu*

Main category: cs.CV

TL;DR: AdLift是首个针对3D高斯泼溅（3DGS）的编辑保护方法，通过将严格受限的2D对抗性扰动提升为3D高斯表示的保护层，防止跨任意视角和维度的指令驱动编辑。


<details>
  <summary>Details</summary>
Motivation: 随着基于扩散模型的指令驱动2D图像编辑方法扩展到3DGS领域，3DGS资产面临未经授权编辑和恶意篡改的风险。现有2D图像的对抗性扰动保护方法无法直接应用于3DGS，需要解决视角通用性保护和可见性与保护能力平衡的挑战。

Method: 提出AdLift方法，通过优化的Lifted PGD算法，在训练视角上逐步优化保护高斯。该方法包括梯度截断和图像到高斯拟合两个交替步骤：首先在渲染图像上对编辑模型进行梯度截断，然后通过图像到高斯拟合操作将扰动反向传播到保护高斯参数。

Result: 实验结果表明，AdLift能有效对抗最先进的指令驱动2D图像和3DGS编辑方法，在不同视角下提供一致的基于对抗性扰动的保护性能，并能泛化到新视角。

Conclusion: AdLift是首个针对3DGS的编辑保护框架，成功解决了3D场景保护中的视角通用性和可见性-保护能力平衡问题，为3D内容安全提供了有效解决方案。

Abstract: Recent studies have extended diffusion-based instruction-driven 2D image editing pipelines to 3D Gaussian Splatting (3DGS), enabling faithful manipulation of 3DGS assets and greatly advancing 3DGS content creation. However, it also exposes these assets to serious risks of unauthorized editing and malicious tampering. Although imperceptible adversarial perturbations against diffusion models have proven effective for protecting 2D images, applying them to 3DGS encounters two major challenges: view-generalizable protection and balancing invisibility with protection capability. In this work, we propose the first editing safeguard for 3DGS, termed AdLift, which prevents instruction-driven editing across arbitrary views and dimensions by lifting strictly bounded 2D adversarial perturbations into 3D Gaussian-represented safeguard. To ensure both adversarial perturbations effectiveness and invisibility, these safeguard Gaussians are progressively optimized across training views using a tailored Lifted PGD, which first conducts gradient truncation during back-propagation from the editing model at the rendered image and applies projected gradients to strictly constrain the image-level perturbation. Then, the resulting perturbation is backpropagated to the safeguard Gaussian parameters via an image-to-Gaussian fitting operation. We alternate between gradient truncation and image-to-Gaussian fitting, yielding consistent adversarial-based protection performance across different viewpoints and generalizes to novel views. Empirically, qualitative and quantitative results demonstrate that AdLift effectively protects against state-of-the-art instruction-driven 2D image and 3DGS editing.

</details>


### [159] [See More, Change Less: Anatomy-Aware Diffusion for Contrast Enhancement](https://arxiv.org/abs/2512.07251)
*Junqi Liu,Zejun Wu,Pedro R. A. S. Bassi,Xinze Zhou,Wenxuan Li,Ibrahim E. Hamamci,Sezgin Er,Tianyu Lin,Yi Luo,Szymon Płotka,Bjoern Menze,Daguang Xu,Kai Ding,Kang Wang,Yang Yang,Yucheng Tang,Alan L. Yuille,Zongwei Zhou*

Main category: cs.CV

TL;DR: SMILE是一个解剖感知的扩散模型，用于医学图像增强，通过理解器官形状和对比度动态，仅在临床相关区域进行增强，避免过度编辑。


<details>
  <summary>Details</summary>
Motivation: 当前医学图像增强模型容易过度编辑，导致器官变形、产生假阳性结果和遗漏小肿瘤，因为它们缺乏对解剖结构和对比度动态的理解。

Method: SMILE提出三个关键创新：结构感知监督（遵循真实器官边界和对比度模式）、无需配准学习（直接处理未对齐的多期相CT扫描）、统一推断（在所有对比度期相提供快速一致的增强）。

Result: 在六个外部数据集上，SMILE在图像质量（SSIM提高14.2%，PSNR提高20.6%，FID改善50%）和临床实用性方面优于现有方法，同时将非对比CT的癌症检测F1分数提高了10%。

Conclusion: SMILE通过解剖感知的增强方法，在保持解剖准确性的同时显著提升了医学图像质量和临床诊断价值。

Abstract: Image enhancement improves visual quality and helps reveal details that are hard to see in the original image. In medical imaging, it can support clinical decision-making, but current models often over-edit. This can distort organs, create false findings, and miss small tumors because these models do not understand anatomy or contrast dynamics. We propose SMILE, an anatomy-aware diffusion model that learns how organs are shaped and how they take up contrast. It enhances only clinically relevant regions while leaving all other areas unchanged. SMILE introduces three key ideas: (1) structure-aware supervision that follows true organ boundaries and contrast patterns; (2) registration-free learning that works directly with unaligned multi-phase CT scans; (3) unified inference that provides fast and consistent enhancement across all contrast phases. Across six external datasets, SMILE outperforms existing methods in image quality (14.2% higher SSIM, 20.6% higher PSNR, 50% better FID) and in clinical usefulness by producing anatomically accurate and diagnostically meaningful images. SMILE also improves cancer detection from non-contrast CT, raising the F1 score by up to 10 percent.

</details>


### [160] [DGGAN: Degradation Guided Generative Adversarial Network for Real-time Endoscopic Video Enhancement](https://arxiv.org/abs/2512.07253)
*Handing Xu,Zhenguo Nie,Tairan Peng,Huimin Pan,Xin-Jun Liu*

Main category: cs.CV

TL;DR: 提出了一种基于退化感知的实时内窥镜视频增强框架，通过跨帧传播退化表示来实现高效高质量的视频增强


<details>
  <summary>Details</summary>
Motivation: 内窥镜手术依赖术中视频，但视频质量常因光照不均、组织散射、遮挡和运动模糊而下降，影响手术安全性和效果。现有深度学习方法计算量大，难以满足实时手术需求

Method: 使用对比学习从图像中提取退化表示，引入融合机制将退化表示与图像特征结合来指导单帧增强模型，并通过退化与恢复图像间的循环一致性约束进行训练

Result: 实验表明该框架在性能和效率之间达到了优于现有方法的平衡

Conclusion: 通过隐式学习和传播退化表示，为临床应用中实时内窥镜视频增强提供了实用途径

Abstract: Endoscopic surgery relies on intraoperative video, making image quality a decisive factor for surgical safety and efficacy. Yet, endoscopic videos are often degraded by uneven illumination, tissue scattering, occlusions, and motion blur, which obscure critical anatomical details and complicate surgical manipulation. Although deep learning-based methods have shown promise in image enhancement, most existing approaches remain too computationally demanding for real-time surgical use. To address this challenge, we propose a degradation-aware framework for endoscopic video enhancement, which enables real-time, high-quality enhancement by propagating degradation representations across frames. In our framework, degradation representations are first extracted from images using contrastive learning. We then introduce a fusion mechanism that modulates image features with these representations to guide a single-frame enhancement model, which is trained with a cycle-consistency constraint between degraded and restored images to improve robustness and generalization. Experiments demonstrate that our framework achieves a superior balance between performance and efficiency compared with several state-of-the-art methods. These results highlight the effectiveness of degradation-aware modeling for real-time endoscopic video enhancement. Nevertheless, our method suggests that implicitly learning and propagating degradation representation offer a practical pathway for clinical application.

</details>


### [161] [A graph generation pipeline for critical infrastructures based on heuristics, images and depth data](https://arxiv.org/abs/2512.07269)
*Mike Diessner,Yannick Tarant*

Main category: cs.CV

TL;DR: 本文提出了一种基于摄影测量的图生成管道，用于创建关键基础设施的虚拟表示，相比激光扫描更经济高效。


<details>
  <summary>Details</summary>
Motivation: 传统使用激光扫描仪获取3D点云的方法成本高昂且需要专业知识，需要更经济易用的替代方案。

Method: 使用立体相机获取RGB图像和深度数据，通过深度学习进行目标检测和实例分割，结合用户定义的启发式规则推断对象关系。

Result: 在两个液压系统上的实验结果表明，该方法生成的图接近真实情况，具有灵活性和透明度。

Conclusion: 该方法为关键基础设施的高风险决策提供了经济、灵活且透明的虚拟表示解决方案。

Abstract: Virtual representations of physical critical infrastructures, such as water or energy plants, are used for simulations and digital twins to ensure resilience and continuity of their services. These models usually require 3D point clouds from laser scanners that are expensive to acquire and require specialist knowledge to use. In this article, we present a graph generation pipeline based on photogrammetry. The pipeline detects relevant objects and predicts their relation using RGB images and depth data generated by a stereo camera. This more cost-effective approach uses deep learning for object detection and instance segmentation of the objects, and employs user-defined heuristics or rules to infer their relations. Results of two hydraulic systems show that this strategy can produce graphs close to the ground truth while its flexibility allows the method to be tailored to specific applications and its transparency qualifies it to be used in the high stakes decision-making that is required for critical infrastructures.

</details>


### [162] [RVLF: A Reinforcing Vision-Language Framework for Gloss-Free Sign Language Translation](https://arxiv.org/abs/2512.07273)
*Zhi Rao,Yucheng Zhou,Benjia Zhou,Yiqing Huang,Sergio Escalera,Jun Wan*

Main category: cs.CV

TL;DR: 本文提出了一种名为RVLF的三阶段强化视觉语言框架，用于解决无注释手语翻译中的两个关键挑战：手语表示不足和句子级语义对齐问题。该方法通过结合视觉特征提取、指令微调和GRPO优化策略，显著提升了手语翻译质量。


<details>
  <summary>Details</summary>
Motivation: 当前无注释手语翻译面临两个主要问题：1）手语表示不足，无法捕捉细微的视觉线索；2）基于LLM的方法存在句子级语义对齐问题，限制了翻译质量。

Method: RVLF框架包含三个阶段：1）构建专门的手语大视觉语言模型，融合基于骨骼的运动线索和DINOv2提取的视觉特征；2）通过指令微调获得SLT-SFT基线模型；3）引入GRPO优化策略，结合BLEU和ROUGE奖励函数微调模型。

Result: 在多个数据集上取得显著提升：CSL-Daily（+5.1 BLEU-4）、PHOENIX-2014T（+1.11）、How2Sign（+1.4）和OpenASL（+1.61）。这是首个将GRPO应用于手语翻译的工作。

Conclusion: 实验证明GRPO优化能有效提升翻译质量和语义一致性，该框架在不使用外部大规模手语数据集预训练的情况下，显著改善了无注释手语翻译性能。

Abstract: Gloss-free sign language translation (SLT) is hindered by two key challenges: **inadequate sign representation** that fails to capture nuanced visual cues, and **sentence-level semantic misalignment** in current LLM-based methods, which limits translation quality. To address these issues, we propose a three-stage **r**einforcing **v**ision-**l**anguage **f**ramework (**RVLF**). We build a large vision-language model (LVLM) specifically designed for sign language, and then combine it with reinforcement learning (RL) to adaptively enhance translation performance. First, for a sufficient representation of sign language, RVLF introduces an effective semantic representation learning mechanism that fuses skeleton-based motion cues with semantically rich visual features extracted via DINOv2, followed by instruction tuning to obtain a strong SLT-SFT baseline. Then, to improve sentence-level semantic misalignment, we introduce a GRPO-based optimization strategy that fine-tunes the SLT-SFT model with a reward function combining translation fidelity (BLEU) and sentence completeness (ROUGE), yielding the optimized model termed SLT-GRPO. Our conceptually simple framework yields substantial gains under the gloss-free SLT setting without pre-training on any external large-scale sign language datasets, improving BLEU-4 scores by +5.1, +1.11, +1.4, and +1.61 on the CSL-Daily, PHOENIX-2014T, How2Sign, and OpenASL datasets, respectively. To the best of our knowledge, this is the first work to incorporate GRPO into SLT. Extensive experiments and ablation studies validate the effectiveness of GRPO-based optimization in enhancing both translation quality and semantic consistency.

</details>


### [163] [Effective Attention-Guided Multi-Scale Medical Network for Skin Lesion Segmentation](https://arxiv.org/abs/2512.07275)
*Siyu Wang,Hua Wang,Huiyu Li,Fan Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种基于多尺度残差结构的创新编码器-解码器网络架构，用于解决皮肤病变分割中不规则形状和低对比度的挑战，通过MRCF模块、CMAM模块和EAB桥接机制显著提升了分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在皮肤病变分割中难以有效处理不规则病变形状和低对比度问题，传统U-Net的跳跃连接存在信息丢失缺陷。

Method: 提出多尺度残差编码器-解码器网络，包含MRCF模块实现跨尺度特征融合，CMAM模块通过动态权重计算增强特征捕获深度，EAB桥接机制补偿上采样过程中的信息损失。

Result: 在多个皮肤病变分割数据集上的实验表明，该模型显著优于现有的基于Transformer和CNN的模型，展现出优异的分割精度和鲁棒性。

Conclusion: 所提出的创新网络架构通过多尺度特征提取、注意力机制和桥接设计，有效解决了皮肤病变分割中的关键挑战，为医疗图像分析提供了可靠解决方案。

Abstract: In the field of healthcare, precise skin lesion segmentation is crucial for the early detection and accurate diagnosis of skin diseases. Despite significant advances in deep learning for image processing, existing methods have yet to effectively address the challenges of irregular lesion shapes and low contrast. To address these issues, this paper proposes an innovative encoder-decoder network architecture based on multi-scale residual structures, capable of extracting rich feature information from different receptive fields to effectively identify lesion areas. By introducing a Multi-Resolution Multi-Channel Fusion (MRCF) module, our method captures cross-scale features, enhancing the clarity and accuracy of the extracted information. Furthermore, we propose a Cross-Mix Attention Module (CMAM), which redefines the attention scope and dynamically calculates weights across multiple contexts, thus improving the flexibility and depth of feature capture and enabling deeper exploration of subtle features. To overcome the information loss caused by skip connections in traditional U-Net, an External Attention Bridge (EAB) is introduced, facilitating the effective utilization of information in the decoder and compensating for the loss during upsampling. Extensive experimental evaluations on several skin lesion segmentation datasets demonstrate that the proposed model significantly outperforms existing transformer and convolutional neural network-based models, showcasing exceptional segmentation accuracy and robustness.

</details>


### [164] [Geo3DVQA: Evaluating Vision-Language Models for 3D Geospatial Reasoning from Aerial Imagery](https://arxiv.org/abs/2512.07276)
*Mai Tsujimoto,Junjue Wang,Weihao Xuan,Naoto Yokoya*

Main category: cs.CV

TL;DR: Geo3DVQA是一个用于评估视觉语言模型在3D地理空间推理能力的基准测试，使用仅RGB遥感图像，涵盖11万个问题-答案对，结果显示当前VLMs在RGB到3D推理方面表现不佳，但领域特定微调能显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前3D地理空间分析依赖昂贵专业传感器，限制了全球可访问性，且现有方法难以整合多种3D线索和处理多样化查询。

Method: 开发Geo3DVQA基准测试，包含16个任务类别、三个复杂度级别的11万个问题-答案对，评估10个最先进VLMs的性能。

Result: GPT-4o和Gemini-2.5-Flash准确率分别为28.6%和33.0%，而领域特定微调的Qwen2.5-VL-7B达到49.6%准确率。

Conclusion: Geo3DVQA揭示了当前VLMs的局限性，证明了领域适应的有效性，为可扩展、可访问的3D地理空间分析设立了新的挑战前沿。

Abstract: Three-dimensional geospatial analysis is critical to applications in urban planning, climate adaptation, and environmental assessment. Current methodologies depend on costly, specialized sensors (e.g., LiDAR and multispectral), which restrict global accessibility. Existing sensor-based and rule-driven methods further struggle with tasks requiring the integration of multiple 3D cues, handling diverse queries, and providing interpretable reasoning. We hereby present Geo3DVQA, a comprehensive benchmark for evaluating vision-language models (VLMs) in height-aware, 3D geospatial reasoning using RGB-only remote sensing imagery. Unlike conventional sensor-based frameworks, Geo3DVQA emphasizes realistic scenarios that integrate elevation, sky view factors, and land cover patterns. The benchmark encompasses 110k curated question-answer pairs spanning 16 task categories across three complexity levels: single-feature inference, multi-feature reasoning, and application-level spatial analysis. The evaluation of ten state-of-the-art VLMs highlights the difficulty of RGB-to-3D reasoning. GPT-4o and Gemini-2.5-Flash achieved only 28.6% and 33.0% accuracy respectively, while domain-specific fine-tuning of Qwen2.5-VL-7B achieved 49.6% (+24.8 points). These results reveal both the limitations of current VLMs and the effectiveness of domain adaptation. Geo3DVQA introduces new challenge frontiers for scalable, accessible, and holistic 3D geospatial analysis. The dataset and code will be released upon publication at https://github.com/mm1129/Geo3DVQA.

</details>


### [165] [Towards Accurate UAV Image Perception: Guiding Vision-Language Models with Stronger Task Prompts](https://arxiv.org/abs/2512.07302)
*Mingning Guo,Mengwei Wu,Shaoxian Li,Haifeng Li,Chao Tao*

Main category: cs.CV

TL;DR: AerialVP是一个专为无人机图像感知设计的任务提示增强代理框架，通过主动提取多维辅助信息来增强任务提示，解决传统VLM方法在复杂无人机图像中的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统基于VLM的图像感知方法在处理无人机图像时面临目标混淆、尺度变化和复杂背景等挑战，因为VLM对图像内容的理解依赖于视觉和文本标记的语义对齐。当任务提示简单而图像内容复杂时，难以实现有效对齐。

Method: AerialVP框架包含三个阶段：(1)分析任务提示以确定任务类型和增强需求；(2)从工具库中选择适当工具；(3)基于分析和选定工具生成增强的任务提示。

Result: 实验结果表明，AerialVP显著增强了任务提示的指导能力，在开源和专有VLM中都带来了稳定且显著的性能提升。

Conclusion: AerialVP是首个专门针对无人机图像感知的任务提示增强代理框架，通过引入AerialSense基准测试，为无人机图像感知提供了标准化评估基础，有效解决了复杂无人机图像中的感知挑战。

Abstract: Existing image perception methods based on VLMs generally follow a paradigm wherein models extract and analyze image content based on user-provided textual task prompts. However, such methods face limitations when applied to UAV imagery, which presents challenges like target confusion, scale variations, and complex backgrounds. These challenges arise because VLMs' understanding of image content depends on the semantic alignment between visual and textual tokens. When the task prompt is simplistic and the image content is complex, achieving effective alignment becomes difficult, limiting the model's ability to focus on task-relevant information. To address this issue, we introduce AerialVP, the first agent framework for task prompt enhancement in UAV image perception. AerialVP proactively extracts multi-dimensional auxiliary information from UAV images to enhance task prompts, overcoming the limitations of traditional VLM-based approaches. Specifically, the enhancement process includes three stages: (1) analyzing the task prompt to identify the task type and enhancement needs, (2) selecting appropriate tools from the tool repository, and (3) generating enhanced task prompts based on the analysis and selected tools. To evaluate AerialVP, we introduce AerialSense, a comprehensive benchmark for UAV image perception that includes Aerial Visual Reasoning, Aerial Visual Question Answering, and Aerial Visual Grounding tasks. AerialSense provides a standardized basis for evaluating model generalization and performance across diverse resolutions, lighting conditions, and both urban and natural scenes. Experimental results demonstrate that AerialVP significantly enhances task prompt guidance, leading to stable and substantial performance improvements in both open-source and proprietary VLMs. Our work will be available at https://github.com/lostwolves/AerialVP.

</details>


### [166] [Reevaluating Automated Wildlife Species Detection: A Reproducibility Study on a Custom Image Dataset](https://arxiv.org/abs/2512.07305)
*Tobias Abraham Haider*

Main category: cs.CV

TL;DR: 该研究复现了Carl等人的工作，使用公开资源和不同数据集评估预训练Google Inception-ResNet-v2模型在相机陷阱图像中识别欧洲野生哺乳动物物种的性能，获得了62%的总体准确率，与原始研究的71%相近，但强调了物种特异性适应的重要性。


<details>
  <summary>Details</summary>
Motivation: 评估Carl等人研究的可重复性和泛化能力，验证预训练卷积神经网络在野生动物物种识别中的实用性。

Method: 重新实现原始实验，使用公开可用资源和包含90个物种的900张图像的不同数据集，进行最小预处理后应用预训练Google Inception-ResNet-v2模型进行分类。

Result: 总体分类准确率为62%，与原始研究的71%相近；宏F1分数为0.28，表明不同类别的性能差异显著，当标签与ImageNet类别不完全对应时泛化能力有限。

Conclusion: 预训练卷积神经网络可作为野生动物物种识别的实用基线，但需要物种特异性适应或迁移学习以实现一致的高质量预测。

Abstract: This study revisits the findings of Carl et al., who evaluated the pre-trained Google Inception-ResNet-v2 model for automated detection of European wild mammal species in camera trap images. To assess the reproducibility and generalizability of their approach, we reimplemented the experiment from scratch using openly available resources and a different dataset consisting of 900 images spanning 90 species. After minimal preprocessing, we obtained an overall classification accuracy of 62%, closely aligning with the 71% reported in the original work despite differences in datasets. As in the original study, per-class performance varied substantially, as indicated by a macro F1 score of 0.28,highlighting limitations in generalization when labels do not align directly with ImageNet classes. Our results confirm that pretrained convolutional neural networks can provide a practical baseline for wildlife species identification but also reinforce the need for species-specific adaptation or transfer learning to achieve consistent, high-quality predictions.

</details>


### [167] [ContextAnyone: Context-Aware Diffusion for Character-Consistent Text-to-Video Generation](https://arxiv.org/abs/2512.07328)
*Ziyang Mai,Yu-Wing Tai*

Main category: cs.CV

TL;DR: ContextAnyone是一个上下文感知的扩散框架，通过单张参考图像实现角色一致性的文本到视频生成，解决了现有方法在保持发型、服装和体型等上下文线索方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的个性化方法主要关注面部身份，但无法保持发型、服装和体型等更广泛的上下文线索，这些对于视觉连贯性至关重要。

Method: 提出联合重建参考图像和生成新视频帧的方法，通过Emphasize-Attention模块选择性增强参考感知特征，使用双引导损失结合扩散和参考重建目标，采用Gap-RoPE位置嵌入分离参考和视频标记。

Result: 实验表明ContextAnyon在身份一致性和视觉质量方面优于现有的参考到视频方法，能够在不同动作和场景中生成连贯且保持上下文的角色视频。

Conclusion: ContextAnyon框架有效解决了角色身份一致性挑战，通过上下文感知方法实现了更好的视觉连贯性。

Abstract: Text-to-video (T2V) generation has advanced rapidly, yet maintaining consistent character identities across scenes remains a major challenge. Existing personalization methods often focus on facial identity but fail to preserve broader contextual cues such as hairstyle, outfit, and body shape, which are critical for visual coherence. We propose \textbf{ContextAnyone}, a context-aware diffusion framework that achieves character-consistent video generation from text and a single reference image. Our method jointly reconstructs the reference image and generates new video frames, enabling the model to fully perceive and utilize reference information. Reference information is effectively integrated into a DiT-based diffusion backbone through a novel Emphasize-Attention module that selectively reinforces reference-aware features and prevents identity drift across frames. A dual-guidance loss combines diffusion and reference reconstruction objectives to enhance appearance fidelity, while the proposed Gap-RoPE positional embedding separates reference and video tokens to stabilize temporal modeling. Experiments demonstrate that ContextAnyone outperforms existing reference-to-video methods in identity consistency and visual quality, generating coherent and context-preserving character videos across diverse motions and scenes. Project page: \href{https://github.com/ziyang1106/ContextAnyone}{https://github.com/ziyang1106/ContextAnyone}.

</details>


### [168] [The Inductive Bottleneck: Data-Driven Emergence of Representational Sparsity in Vision Transformers](https://arxiv.org/abs/2512.07331)
*Kanishk Awadhiya*

Main category: cs.CV

TL;DR: 本文发现Vision Transformers（ViTs）中的"归纳瓶颈"现象是数据依赖的适应性行为，而非架构缺陷。瓶颈深度与任务所需的语义抽象程度相关，对象中心数据集会驱动网络在中间层抑制高频信息以分离语义特征。


<details>
  <summary>Details</summary>
Motivation: 尽管ViTs理论上可以在所有层保持高维表示，但实际观察显示它们经常自发形成"U形"熵分布。本研究旨在探究这种"归纳瓶颈"现象的本质原因。

Method: 通过分析DINO训练的ViTs在不同复杂度数据集（UC Merced、Tiny ImageNet和CIFAR-100）上的逐层有效编码维度（EED），研究瓶颈深度与语义抽象需求的相关性。

Result: 纹理丰富的数据集在整个网络中保持高秩表示，而对象中心数据集则驱动网络在中间层抑制高频信息，有效"学习"出一个瓶颈来分离语义特征。

Conclusion: ViTs中的归纳瓶颈是数据驱动的适应性机制，其深度与任务语义复杂度正相关，表明ViTs能够根据数据特性动态调整表示策略。

Abstract: Vision Transformers (ViTs) lack the hierarchical inductive biases inherent to Convolutional Neural Networks (CNNs), theoretically allowing them to maintain high-dimensional representations throughout all layers. However, recent observations suggest ViTs often spontaneously manifest a "U-shaped" entropy profile-compressing information in middle layers before expanding it for the final classification. In this work, we demonstrate that this "Inductive Bottleneck" is not an architectural artifact, but a data-dependent adaptation. By analyzing the layer-wise Effective Encoding Dimension (EED) of DINO-trained ViTs across datasets of varying compositional complexity (UC Merced, Tiny ImageNet, and CIFAR-100), we show that the depth of the bottleneck correlates strongly with the semantic abstraction required by the task. We find that while texture-heavy datasets preserve high-rank representations throughout, object-centric datasets drive the network to dampen high-frequency information in middle layers, effectively "learning" a bottleneck to isolate semantic features.

</details>


### [169] [Generalized Referring Expression Segmentation on Aerial Photos](https://arxiv.org/abs/2512.07338)
*Luís Marnoto,Alexandre Bernardino,Bruno Martins*

Main category: cs.CV

TL;DR: Aerial-D是一个新的用于航空图像的大规模参考表达式分割数据集，包含37,288张图像和1,522,523个参考表达式，涵盖259,709个标注目标。该数据集通过自动流水线构建，结合了基于规则的表达式生成和LLM增强，并模拟了历史成像条件。


<details>
  <summary>Details</summary>
Motivation: 航空图像（如无人机拍摄的现代航空照片、历史航空档案、高分辨率卫星图像等）在参考表达式分割任务中面临独特挑战：空间分辨率差异大、色彩使用不一致、目标像素少、场景对象密度高且存在部分遮挡。

Method: 采用完全自动化的流水线，结合系统化的基于规则的表达式生成和大型语言模型（LLM）增强程序，丰富参考表达式的语言多样性和视觉细节关注。使用过滤器模拟历史成像条件。采用RSRefSeg架构，在Aerial-D和先前航空数据集上联合训练模型。

Result: 联合训练在当代基准测试中取得了有竞争力的性能，同时在档案航空摄影中出现的单色、深褐色和颗粒状退化条件下保持强准确性。

Conclusion: Aerial-D数据集及其训练模型能够统一实现现代和历史图像的实例和语义分割，为航空图像的参考表达式分割任务提供了重要资源。数据集、训练模型和完整软件流水线已公开。

Abstract: Referring expression segmentation is a fundamental task in computer vision that integrates natural language understanding with precise visual localization of target regions. Considering aerial imagery (e.g., modern aerial photos collected through drones, historical photos from aerial archives, high-resolution satellite imagery, etc.) presents unique challenges because spatial resolution varies widely across datasets, the use of color is not consistent, targets often shrink to only a few pixels, and scenes contain very high object densities and objects with partial occlusions. This work presents Aerial-D, a new large-scale referring expression segmentation dataset for aerial imagery, comprising 37,288 images with 1,522,523 referring expressions that cover 259,709 annotated targets, spanning across individual object instances, groups of instances, and semantic regions covering 21 distinct classes that range from vehicles and infrastructure to land coverage types. The dataset was constructed through a fully automatic pipeline that combines systematic rule-based expression generation with a Large Language Model (LLM) enhancement procedure that enriched both the linguistic variety and the focus on visual details within the referring expressions. Filters were additionally used to simulate historic imaging conditions for each scene. We adopted the RSRefSeg architecture, and trained models on Aerial-D together with prior aerial datasets, yielding unified instance and semantic segmentation from text for both modern and historical images. Results show that the combined training achieves competitive performance on contemporary benchmarks, while maintaining strong accuracy under monochrome, sepia, and grainy degradations that appear in archival aerial photography. The dataset, trained models, and complete software pipeline are publicly available at https://luispl77.github.io/aerial-d .

</details>


### [170] [Debiasing Diffusion Priors via 3D Attention for Consistent Gaussian Splatting](https://arxiv.org/abs/2512.07345)
*Shilong Jin,Haoran Duan,Litao Hua,Wentao Huang,Yuan Zhou*

Main category: cs.CV

TL;DR: TD-Attn是一个解决T2I扩散模型中先验视角偏差导致多视角不一致问题的新框架，通过3D感知注意力引导和分层注意力调制来提升3D任务的视图一致性。


<details>
  <summary>Details</summary>
Motivation: T2I模型存在先验视角偏差，导致不同视角下物体外观冲突，影响3D生成和编辑的质量。

Method: 提出TD-Attn框架，包含3D-AAG模块构建视图一致的3D注意力高斯分布，以及HAM模块通过语义引导树定位和调制对视角条件敏感的CA层。

Result: 实验证明TD-Attn能显著提升多视角一致性，可作为通用插件增强各种3D任务。

Conclusion: TD-Attn通过数学分析和分层调制有效解决了T2I模型的视角偏差问题，为3D任务提供了可靠的视图一致性保障。

Abstract: Versatile 3D tasks (e.g., generation or editing) that distill from Text-to-Image (T2I) diffusion models have attracted significant research interest for not relying on extensive 3D training data. However, T2I models exhibit limitations resulting from prior view bias, which produces conflicting appearances between different views of an object. This bias causes subject-words to preferentially activate prior view features during cross-attention (CA) computation, regardless of the target view condition. To overcome this limitation, we conduct a comprehensive mathematical analysis to reveal the root cause of the prior view bias in T2I models. Moreover, we find different UNet layers show different effects of prior view in CA. Therefore, we propose a novel framework, TD-Attn, which addresses multi-view inconsistency via two key components: (1) the 3D-Aware Attention Guidance Module (3D-AAG) constructs a view-consistent 3D attention Gaussian for subject-words to enforce spatial consistency across attention-focused regions, thereby compensating for the limited spatial information in 2D individual view CA maps; (2) the Hierarchical Attention Modulation Module (HAM) utilizes a Semantic Guidance Tree (SGT) to direct the Semantic Response Profiler (SRP) in localizing and modulating CA layers that are highly responsive to view conditions, where the enhanced CA maps further support the construction of more consistent 3D attention Gaussians. Notably, HAM facilitates semantic-specific interventions, enabling controllable and precise 3D editing. Extensive experiments firmly establish that TD-Attn has the potential to serve as a universal plugin, significantly enhancing multi-view consistency across 3D tasks.

</details>


### [171] [MICo-150K: A Comprehensive Dataset Advancing Multi-Image Composition](https://arxiv.org/abs/2512.07348)
*Xinyu Wei,Kangrui Cen,Hongyang Wei,Zhen Guo,Bairui Li,Zeqing Wang,Jinrui Zhang,Lei Zhang*

Main category: cs.CV

TL;DR: 该论文提出了MICo-150K数据集，用于解决多图像组合生成中的挑战，包括构建大规模高质量数据集、评估基准和基线模型。


<details>
  <summary>Details</summary>
Motivation: 多图像组合生成缺乏高质量训练数据，阻碍了该领域的发展，需要系统性的数据集和评估方法。

Method: 通过系统分类7种代表性任务，利用专有模型合成平衡的复合图像，结合人工筛选和精修，构建MICo-150K数据集；建立分解与重组子集和MICo-Bench评估基准。

Result: MICo-150K有效提升了模型的组合生成能力，基线模型Qwen-MICo在3图像组合上达到Qwen-Image-2509水平，并支持任意多图像输入。

Conclusion: 该研究为多图像组合生成提供了宝贵资源，包括数据集、基准和基线模型，推动了该领域的进一步发展。

Abstract: In controllable image generation, synthesizing coherent and consistent images from multiple reference inputs, i.e., Multi-Image Composition (MICo), remains a challenging problem, partly hindered by the lack of high-quality training data. To bridge this gap, we conduct a systematic study of MICo, categorizing it into 7 representative tasks and curate a large-scale collection of high-quality source images and construct diverse MICo prompts. Leveraging powerful proprietary models, we synthesize a rich amount of balanced composite images, followed by human-in-the-loop filtering and refinement, resulting in MICo-150K, a comprehensive dataset for MICo with identity consistency. We further build a Decomposition-and-Recomposition (De&Re) subset, where 11K real-world complex images are decomposed into components and recomposed, enabling both real and synthetic compositions. To enable comprehensive evaluation, we construct MICo-Bench with 100 cases per task and 300 challenging De&Re cases, and further introduce a new metric, Weighted-Ref-VIEScore, specifically tailored for MICo evaluation. Finally, we fine-tune multiple models on MICo-150K and evaluate them on MICo-Bench. The results show that MICo-150K effectively equips models without MICo capability and further enhances those with existing skills. Notably, our baseline model, Qwen-MICo, fine-tuned from Qwen-Image-Edit, matches Qwen-Image-2509 in 3-image composition while supporting arbitrary multi-image inputs beyond the latter's limitation. Our dataset, benchmark, and baseline collectively offer valuable resources for further research on Multi-Image Composition.

</details>


### [172] [DeepAgent: A Dual Stream Multi Agent Fusion for Robust Multimodal Deepfake Detection](https://arxiv.org/abs/2512.07351)
*Sayeem Been Zaman,Wasimul Karim,Arefin Ittesafun Abian,Reem E. Mohamed,Md Rafiqul Islam,Asif Karim,Sami Azam*

Main category: cs.CV

TL;DR: DeepAgent是一个多智能体协作框架，通过视觉和音频双模态检测深度伪造视频，采用分层融合策略提升检测鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造检测方法通常将音频和视觉信息集成在单一模型中，容易受到模态不匹配、噪声和操纵的影响，需要更鲁棒的解决方案。

Method: 提出双智能体协作框架：Agent-1使用AlexNet-CNN检测视觉伪造痕迹，Agent-2结合声学特征、Whisper音频转录和EasyOCR帧序列检测音视频不一致性，通过随机森林元分类器融合决策。

Result: 在Celeb-DF和FakeAVCeleb数据集上Agent-1准确率达94.35%；FakeAVCeleb上Agent-2和元分类器准确率分别为93.69%和81.56%；跨数据集验证在DeepFakeTIMIT上元分类器准确率达97.49%。

Conclusion: 分层融合策略通过缓解单模态弱点增强了鲁棒性，多智能体方法能有效应对深度伪造中的多样化操纵类型。

Abstract: The increasing use of synthetic media, particularly deepfakes, is an emerging challenge for digital content verification. Although recent studies use both audio and visual information, most integrate these cues within a single model, which remains vulnerable to modality mismatches, noise, and manipulation. To address this gap, we propose DeepAgent, an advanced multi-agent collaboration framework that simultaneously incorporates both visual and audio modalities for the effective detection of deepfakes. DeepAgent consists of two complementary agents. Agent-1 examines each video with a streamlined AlexNet-based CNN to identify the symbols of deepfake manipulation, while Agent-2 detects audio-visual inconsistencies by combining acoustic features, audio transcriptions from Whisper, and frame-reading sequences of images through EasyOCR. Their decisions are fused through a Random Forest meta-classifier that improves final performance by taking advantage of the different decision boundaries learned by each agent. This study evaluates the proposed framework using three benchmark datasets to demonstrate both component-level and fused performance. Agent-1 achieves a test accuracy of 94.35% on the combined Celeb-DF and FakeAVCeleb datasets. On the FakeAVCeleb dataset, Agent-2 and the final meta-classifier attain accuracies of 93.69% and 81.56%, respectively. In addition, cross-dataset validation on DeepFakeTIMIT confirms the robustness of the meta-classifier, which achieves a final accuracy of 97.49%, and indicates a strong capability across diverse datasets. These findings confirm that hierarchy-based fusion enhances robustness by mitigating the weaknesses of individual modalities and demonstrate the effectiveness of a multi-agent approach in addressing diverse types of manipulations in deepfakes.

</details>


### [173] [Structure-Aware Feature Rectification with Region Adjacency Graphs for Training-Free Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2512.07360)
*Qiming Huang,Hao Ai,Jianbo Jiao*

Main category: cs.CV

TL;DR: 本文提出了一种结构感知的特征修正方法，通过构建区域邻接图来捕捉局部结构关系，从而改进CLIP特征在开放词汇语义分割中的表现。


<details>
  <summary>Details</summary>
Motivation: CLIP模型在图像-文本对预训练中侧重于全局语义对齐，导致在细粒度视觉区域与文本关联时性能不佳，产生噪声和不一致的预测。这源于对比训练范式带来的分散偏差。

Method: 提出结构感知特征修正方法，基于低层特征（如颜色和纹理）构建区域邻接图（RAG）来捕捉局部结构关系，并用其增强CLIP特征的局部判别能力。

Result: 大量实验表明，该方法有效抑制了分割噪声，提高了区域级一致性，并在多个开放词汇分割基准上取得了强劲性能。

Conclusion: 通过引入实例特定的先验知识，该方法成功缓解了CLIP特征在局部区域的分割问题，为开放词汇语义分割提供了一种有效的解决方案。

Abstract: Benefiting from the inductive biases learned from large-scale datasets, open-vocabulary semantic segmentation (OVSS) leverages the power of vision-language models, such as CLIP, to achieve remarkable progress without requiring task-specific training. However, due to CLIP's pre-training nature on image-text pairs, it tends to focus on global semantic alignment, resulting in suboptimal performance when associating fine-grained visual regions with text. This leads to noisy and inconsistent predictions, particularly in local areas. We attribute this to a dispersed bias stemming from its contrastive training paradigm, which is difficult to alleviate using CLIP features alone. To address this, we propose a structure-aware feature rectification approach that incorporates instance-specific priors derived directly from the image. Specifically, we construct a region adjacency graph (RAG) based on low-level features (e.g., colour and texture) to capture local structural relationships and use it to refine CLIP features by enhancing local discrimination. Extensive experiments show that our method effectively suppresses segmentation noise, improves region-level consistency, and achieves strong performance on multiple open-vocabulary segmentation benchmarks.

</details>


### [174] [Enhancing Small Object Detection with YOLO: A Novel Framework for Improved Accuracy and Efficiency](https://arxiv.org/abs/2512.07379)
*Mahila Moghadami,Mohammad Ali Keyvanrad,Melika Sabaghian*

Main category: cs.CV

TL;DR: 本文提出了一种改进的SW-YOLO模型，通过优化滑动窗口裁剪策略和网络架构改进，显著提升了大规模航拍图像中小目标的检测精度，在VisDrone2019数据集上mAP从35.5提升至61.2。


<details>
  <summary>Details</summary>
Motivation: 随着航拍图像在关键工业和军事应用中的重要性日益增长，需要开发能够有效检测小目标的鲁棒框架。现有方法存在检测精度不足的问题。

Method: 基于SW-YOLO方法，优化滑动窗口的裁剪尺寸和重叠策略，并在网络架构中引入高级特征提取模块、CBAM注意力机制和新的检测头设计。

Result: 在VisDrone2019数据集上，提出的模型将mAP .5.5精度从YOLOv5L的35.5提升至61.2，显著优于SAHI和CZDet等现有方法。

Conclusion: 该研究通过系统性的方法改进，证明了在航拍图像小目标检测任务上能够实现显著精度提升，为实际应用提供了有效的解决方案。

Abstract: This paper investigates and develops methods for detecting small objects in large-scale aerial images. Current approaches for detecting small objects in aerial images often involve image cropping and modifications to detector network architectures. Techniques such as sliding window cropping and architectural enhancements, including higher-resolution feature maps and attention mechanisms, are commonly employed. Given the growing importance of aerial imagery in various critical and industrial applications, the need for robust frameworks for small object detection becomes imperative. To address this need, we adopted the base SW-YOLO approach to enhance speed and accuracy in small object detection by refining cropping dimensions and overlap in sliding window usage and subsequently enhanced it through architectural modifications. we propose a novel model by modifying the base model architecture, including advanced feature extraction modules in the neck for feature map enhancement, integrating CBAM in the backbone to preserve spatial and channel information, and introducing a new head to boost small object detection accuracy. Finally, we compared our method with SAHI, one of the most powerful frameworks for processing large-scale images, and CZDet, which is also based on image cropping, achieving significant improvements in accuracy. The proposed model achieves significant accuracy gains on the VisDrone2019 dataset, outperforming baseline YOLOv5L detection by a substantial margin. Specifically, the final proposed model elevates the mAP .5.5 accuracy on the VisDrone2019 dataset from the base accuracy of 35.5 achieved by the YOLOv5L detector to 61.2. Notably, the accuracy of CZDet, which is another classic method applied to this dataset, is 58.36. This research demonstrates a significant improvement, achieving an increase in accuracy from 35.5 to 61.2.

</details>


### [175] [Tessellation GS: Neural Mesh Gaussians for Robust Monocular Reconstruction of Dynamic Objects](https://arxiv.org/abs/2512.07381)
*Shuohan Tao,Boyao Zhou,Hanzhang Tu,Yuwang Wang,Yebin Liu*

Main category: cs.CV

TL;DR: Tessellation GS是一种基于网格面的2D高斯泼溅方法，用于从单摄像头重建动态场景，解决了3D GS在视角外推方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅在稀疏视角和动态场景重建中存在过拟合和泛化能力差的问题，特别是在视角外推方面表现不佳。

Method: 将2D高斯约束在局部区域，通过网格面上的分层神经特征推断其属性；采用自适应面细分策略和细节感知损失函数引导高斯细分；利用重建基础模型的先验初始化高斯变形。

Result: 在表观和网格重建任务上，LPIPS降低了29.1%，Chamfer距离降低了49.2%，优于之前的SOTA方法。

Conclusion: Tessellation GS能够从单个静态摄像头稳健地重建一般动态物体，解决了优化方法此前面临的极端挑战。

Abstract: 3D Gaussian Splatting (GS) enables highly photorealistic scene reconstruction from posed image sequences but struggles with viewpoint extrapolation due to its anisotropic nature, leading to overfitting and poor generalization, particularly in sparse-view and dynamic scene reconstruction. We propose Tessellation GS, a structured 2D GS approach anchored on mesh faces, to reconstruct dynamic scenes from a single continuously moving or static camera. Our method constrains 2D Gaussians to localized regions and infers their attributes via hierarchical neural features on mesh faces. Gaussian subdivision is guided by an adaptive face subdivision strategy driven by a detail-aware loss function. Additionally, we leverage priors from a reconstruction foundation model to initialize Gaussian deformations, enabling robust reconstruction of general dynamic objects from a single static camera, previously extremely challenging for optimization-based methods. Our method outperforms previous SOTA method, reducing LPIPS by 29.1% and Chamfer distance by 49.2% on appearance and mesh reconstruction tasks.

</details>


### [176] [LogicCBMs: Logic-Enhanced Concept-Based Learning](https://arxiv.org/abs/2512.07383)
*Deepika SN Vemuri,Gautham Bellamkonda,Aditya Pola,Vineeth N Balasubramanian*

Main category: cs.CV

TL;DR: 该论文提出LogicCBM，通过可微逻辑操作增强概念瓶颈模型，超越简单的线性概念组合，提高模型表达能力和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统概念瓶颈模型仅通过线性组合概念进行预测，表达能力有限。作者希望引入逻辑操作来捕捉概念间关系，提升模型性能。

Method: 在概念瓶颈模型基础上引入逻辑模块，使用可微逻辑操作连接学习到的概念，支持多种逻辑运算生成最终预测。

Result: 在知名基准测试和合成数据集上的实验表明，LogicCBM具有更高的准确性、有效的干预能力和良好的可解释性。

Conclusion: 通过逻辑操作增强概念瓶颈模型能够显著提升模型性能，同时保持端到端可学习性和可解释性。

Abstract: Concept Bottleneck Models (CBMs) provide a basis for semantic abstractions within a neural network architecture. Such models have primarily been seen through the lens of interpretability so far, wherein they offer transparency by inferring predictions as a linear combination of semantic concepts. However, a linear combination is inherently limiting. So we propose the enhancement of concept-based learning models through propositional logic. We introduce a logic module that is carefully designed to connect the learned concepts from CBMs through differentiable logic operations, such that our proposed LogicCBM can go beyond simple weighted combinations of concepts to leverage various logical operations to yield the final predictions, while maintaining end-to-end learnability. Composing concepts using a set of logic operators enables the model to capture inter-concept relations, while simultaneously improving the expressivity of the model in terms of logic operations. Our empirical studies on well-known benchmarks and synthetic datasets demonstrate that these models have better accuracy, perform effective interventions and are highly interpretable.

</details>


### [177] [How Far are Modern Trackers from UAV-Anti-UAV? A Million-Scale Benchmark and New Baseline](https://arxiv.org/abs/2512.07385)
*Chunhui Zhang,Li Liu,Zhipeng Zhang,Yong Wang,Hao Wen,Xi Zhou,Shiming Ge,Yanfeng Wang*

Main category: cs.CV

TL;DR: 本文提出了一个名为UAV-Anti-UAV的新型多模态视觉跟踪任务，涉及从移动的无人机平台跟踪目标敌对无人机，并构建了百万级数据集和基于Mamba的基线方法MambaSTS。


<details>
  <summary>Details</summary>
Motivation: 当前反无人机研究主要基于固定地面摄像头，缺乏从移动无人机平台跟踪目标无人机的研究。无人机对抗无人机场景面临双重动态干扰的挑战。

Method: 提出MambaSTS方法，结合Mamba和Transformer模型分别学习全局语义和空间特征，利用状态空间模型的长序列建模能力，通过时间令牌传播机制建立视频级长期上下文。

Result: 在UAV-Anti-UAV数据集上验证了方法的有效性，对50种现代深度跟踪算法的实验评估表明该领域仍有很大改进空间。

Conclusion: UAV-Anti-UAV任务具有挑战性，提出的数据集和基线方法为未来研究奠定了基础，该领域需要进一步的技术创新。

Abstract: Unmanned Aerial Vehicles (UAVs) offer wide-ranging applications but also pose significant safety and privacy violation risks in areas like airport and infrastructure inspection, spurring the rapid development of Anti-UAV technologies in recent years. However, current Anti-UAV research primarily focuses on RGB, infrared (IR), or RGB-IR videos captured by fixed ground cameras, with little attention to tracking target UAVs from another moving UAV platform. To fill this gap, we propose a new multi-modal visual tracking task termed UAV-Anti-UAV, which involves a pursuer UAV tracking a target adversarial UAV in the video stream. Compared to existing Anti-UAV tasks, UAV-Anti-UAV is more challenging due to severe dual-dynamic disturbances caused by the rapid motion of both the capturing platform and the target. To advance research in this domain, we construct a million-scale dataset consisting of 1,810 videos, each manually annotated with bounding boxes, a language prompt, and 15 tracking attributes. Furthermore, we propose MambaSTS, a Mamba-based baseline method for UAV-Anti-UAV tracking, which enables integrated spatial-temporal-semantic learning. Specifically, we employ Mamba and Transformer models to learn global semantic and spatial features, respectively, and leverage the state space model's strength in long-sequence modeling to establish video-level long-term context via a temporal token propagation mechanism. We conduct experiments on the UAV-Anti-UAV dataset to validate the effectiveness of our method. A thorough experimental evaluation of 50 modern deep tracking algorithms demonstrates that there is still significant room for improvement in the UAV-Anti-UAV domain. The dataset and codes will be available at {\color{magenta}https://github.com/983632847/Awesome-Multimodal-Object-Tracking}.

</details>


### [178] [GlimmerNet: A Lightweight Grouped Dilated Depthwise Convolutions for UAV-Based Emergency Monitoring](https://arxiv.org/abs/2512.07391)
*Đorđe Nedeljković*

Main category: cs.CV

TL;DR: GlimmerNet是一种超轻量级卷积网络，通过分组扩张深度卷积和聚合器模块实现多尺度特征提取和高效特征融合，在仅31K参数下达到最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的Vision Transformer方法虽然能增强全局上下文理解，但引入了显著的计算开销。作者希望在不依赖计算昂贵组件的情况下保持强大的全局感知能力。

Method: 提出GlimmerNet，采用分组扩张深度卷积(GDBlocks)将通道分组并应用不同扩张率实现多尺度特征提取，设计聚合器模块使用分组点卷积高效重组跨组表示。

Result: 仅31K参数，比最新基线减少29% FLOPs，在AIDERv2数据集上达到0.966的加权F1分数，创下新纪录。

Conclusion: GlimmerNet为资源受限的无人机平台上的实时紧急监测建立了新的精度-效率权衡前沿。

Abstract: Convolutional Neural Networks (CNNs) have proven highly effective for edge and mobile vision tasks due to their computational efficiency. While many recent works seek to enhance CNNs with global contextual understanding via self-attention-based Vision Transformers, these approaches often introduce significant computational overhead. In this work, we demonstrate that it is possible to retain strong global perception without relying on computationally expensive components. We present GlimmerNet, an ultra-lightweight convolutional network built on the principle of separating receptive field diversity from feature recombination. GlimmerNet introduces Grouped Dilated Depthwise Convolutions(GDBlocks), which partition channels into groups with distinct dilation rates, enabling multi-scale feature extraction at no additional parameter cost. To fuse these features efficiently, we design a novel Aggregator module that recombines cross-group representations using grouped pointwise convolution, significantly lowering parameter overhead. With just 31K parameters and 29% fewer FLOPs than the most recent baseline, GlimmerNet achieves a new state-of-the-art weighted F1-score of 0.966 on the UAV-focused AIDERv2 dataset. These results establish a new accuracy-efficiency trade-off frontier for real-time emergency monitoring on resource-constrained UAV platforms. Our implementation is publicly available at https://github.com/djordjened92/gdd-cnn.

</details>


### [179] [Reconstructing Objects along Hand Interaction Timelines in Egocentric Video](https://arxiv.org/abs/2512.07394)
*Zhifan Zhu,Siddhant Bansal,Shashank Tripathi,Dima Damen*

Main category: cs.CV

TL;DR: 本文提出了ROHIT任务，用于重建手交互时间轴中的物体姿态。通过定义手交互时间轴(HIT)并建模姿态约束，提出COP框架进行约束优化和传播，在稳定抓取场景下实现更好的物体重建。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理手与物体交互时的姿态变化存在困难，特别是在物体从静止到被手持、使用再到释放的完整时间轴上。需要一种能够建模这些姿态约束并实现连续重建的方法。

Method: 提出COP(Constrained Optimisation and Propagation)框架：1) 定义手交互时间轴(HIT)的四个阶段；2) 对每个阶段建模姿态约束；3) 通过约束优化和传播实现姿态的连续重建；4) 专注于稳定抓取场景以简化标注和评估。

Result: 在HOT3D数据集上标注了1.2K个稳定抓取片段，在EPIC-Kitchens数据集上标注了2.4K个片段（390个物体实例，9个类别，141个环境）。COP方法将稳定抓取重建精度提高了6.2-11.3%，HIT重建精度提高了24.5%。

Conclusion: ROHIT任务和COP框架能够有效解决手交互时间轴中的物体重建问题，特别是在稳定抓取场景下，通过约束优化和姿态传播实现了显著的性能提升，为无3D真值标注的视频物体重建提供了可行方案。

Abstract: We introduce the task of Reconstructing Objects along Hand Interaction Timelines (ROHIT). We first define the Hand Interaction Timeline (HIT) from a rigid object's perspective. In a HIT, an object is first static relative to the scene, then is held in hand following contact, where its pose changes. This is usually followed by a firm grip during use, before it is released to be static again w.r.t. to the scene. We model these pose constraints over the HIT, and propose to propagate the object's pose along the HIT enabling superior reconstruction using our proposed Constrained Optimisation and Propagation (COP) framework. Importantly, we focus on timelines with stable grasps - i.e. where the hand is stably holding an object, effectively maintaining constant contact during use. This allows us to efficiently annotate, study, and evaluate object reconstruction in videos without 3D ground truth. We evaluate our proposed task, ROHIT, over two egocentric datasets, HOT3D and in-the-wild EPIC-Kitchens. In HOT3D, we curate 1.2K clips of stable grasps. In EPIC-Kitchens, we annotate 2.4K clips of stable grasps including 390 object instances across 9 categories from videos of daily interactions in 141 environments. Without 3D ground truth, we utilise 2D projection error to assess the reconstruction. Quantitatively, COP improves stable grasp reconstruction by 6.2-11.3% and HIT reconstruction by up to 24.5% with constrained pose propagation.

</details>


### [180] [Toward More Reliable Artificial Intelligence: Reducing Hallucinations in Vision-Language Models](https://arxiv.org/abs/2512.07564)
*Kassoum Sanogo,Renzo Ardiccioni*

Main category: cs.CV

TL;DR: 提出一种无需训练的自校正框架，通过不确定性引导的视觉重注意机制来减少视觉语言模型的幻觉生成


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型经常生成看似合理但错误的幻觉内容，需要一种无需额外训练的方法来纠正这些错误

Method: 结合多维不确定性量化（标记熵、注意力分散度、语义一致性、声明置信度）和注意力引导的裁剪，对未充分探索区域进行重新关注，完全使用预训练模型，无需梯度更新

Result: 在POPE和MMHAL BENCH基准测试中，幻觉率比基线降低9.8个百分点，对抗性分割中的对象存在准确性提高4.7个百分点

Conclusion: 不确定性引导的重注意机制能够成功将校正基于视觉证据，为可信赖的多模态系统研究提供了有效方法

Abstract: Vision-language models (VLMs) frequently generate hallucinated content plausible but incorrect claims about image content. We propose a training-free self-correction framework enabling VLMs to iteratively refine responses through uncertainty-guided visual re-attention. Our method combines multidimensional uncertainty quantification (token entropy, attention dispersion, semantic consistency, claim confidence) with attention-guided cropping of under-explored regions. Operating entirely with frozen, pretrained VLMs, our framework requires no gradient updates. We validate our approach on the POPE and MMHAL BENCH benchmarks using the Qwen2.5-VL-7B [23] architecture. Experimental results demonstrate that our method reduces hallucination rates by 9.8 percentage points compared to the baseline, while improving object existence accuracy by 4.7 points on adversarial splits. Furthermore, qualitative analysis confirms that uncertainty-guided re-attention successfully grounds corrections in visual evidence where standard decoding fails. We validate our approach on Qwen2.5-VL-7B [23], with plans to extend validation across diverse architectures in future versions. We release our code and methodology to facilitate future research in trustworthy multimodal systems.

</details>


### [181] [InterAgent: Physics-based Multi-agent Command Execution via Diffusion on Interaction Graphs](https://arxiv.org/abs/2512.07410)
*Bin Li,Ruichi Zhang,Han Liang,Jingyan Zhang,Juze Zhang,Xin Chen,Lan Xu,Jingyi Yu,Jingya Wang*

Main category: cs.CV

TL;DR: InterAgent是首个基于物理的文本驱动多智能体人形控制框架，通过自回归扩散变换器和多流块实现多智能体间的物理合理交互。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要局限于单智能体场景，忽略了多智能体交互所需的物理合理协调，需要开发能够处理复杂多智能体社会行为的方法。

Method: 提出自回归扩散变换器，采用多流块解耦本体感知、外部感知和动作；引入交互图外部感知表示捕获关节间空间依赖；设计稀疏边注意力机制动态剪枝冗余连接。

Result: 在大量实验中，InterAgent始终优于多个强基线方法，实现了最先进的性能，能够从文本提示生成连贯、物理合理且语义准确的多智能体行为。

Conclusion: InterAgent框架成功解决了多智能体物理交互的挑战，为文本驱动的多智能体人形控制提供了有效解决方案，代码和数据将开源以促进未来研究。

Abstract: Humanoid agents are expected to emulate the complex coordination inherent in human social behaviors. However, existing methods are largely confined to single-agent scenarios, overlooking the physically plausible interplay essential for multi-agent interactions. To bridge this gap, we propose InterAgent, the first end-to-end framework for text-driven physics-based multi-agent humanoid control. At its core, we introduce an autoregressive diffusion transformer equipped with multi-stream blocks, which decouples proprioception, exteroception, and action to mitigate cross-modal interference while enabling synergistic coordination. We further propose a novel interaction graph exteroception representation that explicitly captures fine-grained joint-to-joint spatial dependencies to facilitate network learning. Additionally, within it we devise a sparse edge-based attention mechanism that dynamically prunes redundant connections and emphasizes critical inter-agent spatial relations, thereby enhancing the robustness of interaction modeling. Extensive experiments demonstrate that InterAgent consistently outperforms multiple strong baselines, achieving state-of-the-art performance. It enables producing coherent, physically plausible, and semantically faithful multi-agent behaviors from only text prompts. Our code and data will be released to facilitate future research.

</details>


### [182] [Data-driven Exploration of Mobility Interaction Patterns](https://arxiv.org/abs/2512.07415)
*Gabriele Galatolo,Mirco Nanni*

Main category: cs.CV

TL;DR: 本文提出了一种基于数据挖掘的方法来研究个体间的移动行为交互，通过从数据中直接发现移动事件中的相互影响模式，而非依赖预定义的行为模型。


<details>
  <summary>Details</summary>
Motivation: 现有的人类动态建模方法通常基于预定义的行为模型，无法充分捕捉个体间相互影响的复杂性。特别是在人群模拟和应急管理等应用中，准确理解个体间的交互机制至关重要。

Method: 采用数据挖掘方法，直接从数据中搜索可能反映个体间相互作用的移动事件，并在此基础上寻找复杂、持久的模式和随时间演化的事件配置。

Result: 在两个真实案例研究（汽车和行人）上进行了完整实验评估，包括性能、参数敏感性和结果解释等方面，验证了方法的有效性。

Conclusion: 通过分析这些交互模式，可以为改进现有模拟模型提供新的见解，有助于更好地理解个体移动交互机制。

Abstract: Understanding the movement behaviours of individuals and the way they react to the external world is a key component of any problem that involves the modelling of human dynamics at a physical level. In particular, it is crucial to capture the influence that the presence of an individual can have on the others. Important examples of applications include crowd simulation and emergency management, where the simulation of the mass of people passes through the simulation of the individuals, taking into consideration the others as part of the general context. While existing solutions basically start from some preconceived behavioural model, in this work we propose an approach that starts directly from the data, adopting a data mining perspective. Our method searches the mobility events in the data that might be possible evidences of mutual interactions between individuals, and on top of them looks for complex, persistent patterns and time evolving configurations of events. The study of these patterns can provide new insights on the mechanics of mobility interactions between individuals, which can potentially help in improving existing simulation models. We instantiate the general methodology on two real case studies, one on cars and one on pedestrians, and a full experimental evaluation is performed, both in terms of performances, parameter sensitivity and interpretation of sample results.

</details>


### [183] [PVeRA: Probabilistic Vector-Based Random Matrix Adaptation](https://arxiv.org/abs/2512.07703)
*Leo Fillioux,Enzo Ferrante,Paul-Henry Cournède,Maria Vakalopoulou,Stergios Christodoulidis*

Main category: cs.CV

TL;DR: PVeRA是一种概率版本的VeRA适配器，通过概率化修改低秩矩阵来处理输入中的模糊性，并在训练和测试时支持不同采样配置，在VTAB-1k基准测试中表现优于VeRA和其他适配器。


<details>
  <summary>Details</summary>
Motivation: 大型基础模型训练和微调需要大量数据和计算资源，而参数高效适配方法能在少量数据和计算能力下微调模型。VeRA适配器通过共享冻结随机低秩矩阵在参数高效适配中表现出色，但缺乏处理输入模糊性的能力。

Method: 提出PVeRA（概率VeRA适配器），对VeRA的低秩矩阵进行概率化修改，使其能够自然处理输入中的固有模糊性，并在训练和测试阶段支持不同的采样配置。

Result: 在VTAB-1k基准测试中对7种适配器进行全面评估，PVeRA的表现优于VeRA和其他适配器。

Conclusion: PVeRA通过概率化方法有效提升了参数高效适配的性能，特别是在处理输入模糊性方面表现优异，为资源受限环境下的模型适配提供了更优解决方案。

Abstract: Large foundation models have emerged in the last years and are pushing performance boundaries for a variety of tasks. Training or even finetuning such models demands vast datasets and computational resources, which are often scarce and costly. Adaptation methods provide a computationally efficient solution to address these limitations by allowing such models to be finetuned on small amounts of data and computing power. This is achieved by appending new trainable modules to frozen backbones with only a fraction of the trainable parameters and fitting only these modules on novel tasks. Recently, the VeRA adapter was shown to excel in parameter-efficient adaptations by utilizing a pair of frozen random low-rank matrices shared across all layers. In this paper, we propose PVeRA, a probabilistic version of the VeRA adapter, which modifies the low-rank matrices of VeRA in a probabilistic manner. This modification naturally allows handling inherent ambiguities in the input and allows for different sampling configurations during training and testing. A comprehensive evaluation was performed on the VTAB-1k benchmark and seven adapters, with PVeRA outperforming VeRA and other adapters. Our code for training models with PVeRA and benchmarking all adapters is available https://github.com/leofillioux/pvera.

</details>


### [184] [When normalization hallucinates: unseen risks in AI-powered whole slide image processing](https://arxiv.org/abs/2512.07426)
*Karel Moens,Matthew B. Blaschko,Tinne Tuytelaars,Bart Diricx,Jonas De Vylder,Mustafa Yousif*

Main category: cs.CV

TL;DR: 本文指出全玻片图像（WSI）归一化中深度学习模型会产生幻觉内容（虚假但逼真的伪影），这些伪影在真实临床数据中尤为严重，并提出了一种新的图像比较方法来检测这些幻觉。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的WSI归一化方法在训练过程中倾向于输出平均值，可能掩盖诊断重要特征，更严重的是会产生难以视觉检测的幻觉内容，这对下游分析构成严重威胁。

Method: 提出一种新颖的图像比较度量方法，用于自动检测归一化输出中的幻觉内容，并系统评估多个引用广泛的归一化方法在真实临床数据上的表现。

Result: 研究发现当这些模型在真实临床数据上重新训练和评估时，幻觉出现的频率令人担忧，传统指标无法捕捉到显著的差异性和失败案例。

Conclusion: 研究结果强调了在临床部署中需要更鲁棒、可解释的归一化技术和更严格的验证协议。

Abstract: Whole slide image (WSI) normalization remains a vital preprocessing step in computational pathology. Increasingly driven by deep learning, these models learn to approximate data distributions from training examples. This often results in outputs that gravitate toward the average, potentially masking diagnostically important features. More critically, they can introduce hallucinated content, artifacts that appear realistic but are not present in the original tissue, posing a serious threat to downstream analysis. These hallucinations are nearly impossible to detect visually, and current evaluation practices often overlook them. In this work, we demonstrate that the risk of hallucinations is real and underappreciated. While many methods perform adequately on public datasets, we observe a concerning frequency of hallucinations when these same models are retrained and evaluated on real-world clinical data. To address this, we propose a novel image comparison measure designed to automatically detect hallucinations in normalized outputs. Using this measure, we systematically evaluate several well-cited normalization methods retrained on real-world data, revealing significant inconsistencies and failures that are not captured by conventional metrics. Our findings underscore the need for more robust, interpretable normalization techniques and stricter validation protocols in clinical deployment.

</details>


### [185] [Relational Visual Similarity](https://arxiv.org/abs/2512.07833)
*Thao Nguyen,Sicheng Mo,Krishna Kumar Singh,Yilin Wang,Jing Shi,Nicholas Kolkin,Eli Shechtman,Yong Jae Lee,Yuheng Li*

Main category: cs.CV

TL;DR: 本文提出了一种新的图像相似性度量方法，专注于捕捉人类感知的关系相似性而非传统的外观属性相似性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉相似性度量方法（如LPIPS、CLIP、DINO）只关注感知属性相似性，无法捕捉人类能够感知的丰富关系相似性。

Method: 首先将关系图像相似性定义为可测量问题，然后构建包含11.4万张图像-匿名标题的数据集，通过微调视觉-语言模型来测量图像间的关系相似性。

Result: 开发了首个能够基于关系结构而非表面外观来连接图像的模型，发现现有图像相似性模型在捕捉关系相似性方面存在重要缺陷。

Conclusion: 关系相似性具有重要现实应用价值，但当前视觉计算领域在这方面存在关键空白，需要新的方法来解决。

Abstract: Humans do not just see attribute similarity -- we also see relational similarity. An apple is like a peach because both are reddish fruit, but the Earth is also like a peach: its crust, mantle, and core correspond to the peach's skin, flesh, and pit. This ability to perceive and recognize relational similarity, is arguable by cognitive scientist to be what distinguishes humans from other species. Yet, all widely used visual similarity metrics today (e.g., LPIPS, CLIP, DINO) focus solely on perceptual attribute similarity and fail to capture the rich, often surprising relational similarities that humans perceive. How can we go beyond the visible content of an image to capture its relational properties? How can we bring images with the same relational logic closer together in representation space? To answer these questions, we first formulate relational image similarity as a measurable problem: two images are relationally similar when their internal relations or functions among visual elements correspond, even if their visual attributes differ. We then curate 114k image-caption dataset in which the captions are anonymized -- describing the underlying relational logic of the scene rather than its surface content. Using this dataset, we finetune a Vision-Language model to measure the relational similarity between images. This model serves as the first step toward connecting images by their underlying relational structure rather than their visible appearance. Our study shows that while relational similarity has a lot of real-world applications, existing image similarity models fail to capture it -- revealing a critical gap in visual computing.

</details>


### [186] [Unified Video Editing with Temporal Reasoner](https://arxiv.org/abs/2512.07469)
*Xiangpeng Yang,Ji Xie,Yiyuan Yang,Yan Huang,Min Xu,Qiang Wu*

Main category: cs.CV

TL;DR: VideoCoF提出了一种新颖的Chain-of-Frames方法，通过强制视频扩散模型先预测编辑区域潜在表示，再进行视频生成，实现了无需用户提供掩码的精确视频编辑。


<details>
  <summary>Details</summary>
Motivation: 现有视频编辑方法面临精确性与通用性的矛盾：专家模型依赖特定任务先验（如掩码），难以统一；而统一的时间上下文学习模型缺乏显式空间线索，导致指令到区域映射不精确。

Method: 受Chain-of-Thought启发，VideoCoF采用"观察-推理-编辑"流程，强制模型先预测编辑区域潜在表示（推理令牌），再生成目标视频令牌。同时引入RoPE对齐策略确保运动对齐和长度外推。

Result: 仅使用5万对视频数据，VideoCoF在VideoCoF-Bench上达到最先进性能，验证了方法的效率和有效性。

Conclusion: VideoCoF通过显式推理步骤解决了视频编辑中精确性与通用性的权衡问题，实现了无需掩码的精确指令到区域对齐和细粒度视频编辑。

Abstract: Existing video editing methods face a critical trade-off: expert models offer precision but rely on task-specific priors like masks, hindering unification; conversely, unified temporal in-context learning models are mask-free but lack explicit spatial cues, leading to weak instruction-to-region mapping and imprecise localization. To resolve this conflict, we propose VideoCoF, a novel Chain-of-Frames approach inspired by Chain-of-Thought reasoning. VideoCoF enforces a ``see, reason, then edit" procedure by compelling the video diffusion model to first predict reasoning tokens (edit-region latents) before generating the target video tokens. This explicit reasoning step removes the need for user-provided masks while achieving precise instruction-to-region alignment and fine-grained video editing. Furthermore, we introduce a RoPE alignment strategy that leverages these reasoning tokens to ensure motion alignment and enable length extrapolation beyond the training duration. We demonstrate that with a minimal data cost of only 50k video pairs, VideoCoF achieves state-of-the-art performance on VideoCoF-Bench, validating the efficiency and effectiveness of our approach. Our code, weight, data are available at https://github.com/knightyxp/VideoCoF.

</details>


### [187] [Single-step Diffusion-based Video Coding with Semantic-Temporal Guidance](https://arxiv.org/abs/2512.07480)
*Naifu Xue,Zhaoyang Jia,Jiahao Li,Bin Li,Zihan Zheng,Yuan Zhang,Yan Lu*

Main category: cs.CV

TL;DR: S2VC是一个基于单步扩散的视频编解码器，通过条件编码框架和高效的单步扩散生成器，在低比特率下实现逼真重建并减少采样复杂度。


<details>
  <summary>Details</summary>
Motivation: 传统和神经视频编解码器在低比特率下的感知质量提升仍具挑战性，现有方法要么存在生成能力限制导致的伪影，要么依赖预训练扩散模型但计算成本高昂。

Method: 提出S2VC，结合条件编码框架和单步扩散生成器；引入上下文语义指导从缓冲特征中提取帧自适应语义；加入时间一致性指导以确保帧间时序连贯性。

Result: S2VC在感知质量上达到最先进水平，相比之前的感知方法平均节省52.73%的比特率。

Conclusion: 单步扩散方法为高效高质量视频压缩提供了有前景的解决方案。

Abstract: While traditional and neural video codecs (NVCs) have achieved remarkable rate-distortion performance, improving perceptual quality at low bitrates remains challenging. Some NVCs incorporate perceptual or adversarial objectives but still suffer from artifacts due to limited generation capacity, whereas others leverage pretrained diffusion models to improve quality at the cost of heavy sampling complexity. To overcome these challenges, we propose S2VC, a Single-Step diffusion based Video Codec that integrates a conditional coding framework with an efficient single-step diffusion generator, enabling realistic reconstruction at low bitrates with reduced sampling cost. Recognizing the importance of semantic conditioning in single-step diffusion, we introduce Contextual Semantic Guidance to extract frame-adaptive semantics from buffered features. It replaces text captions with efficient, fine-grained conditioning, thereby improving generation realism. In addition, Temporal Consistency Guidance is incorporated into the diffusion U-Net to enforce temporal coherence across frames and ensure stable generation. Extensive experiments show that S2VC delivers state-of-the-art perceptual quality with an average 52.73% bitrate saving over prior perceptual methods, underscoring the promise of single-step diffusion for efficient, high-quality video compression.

</details>


### [188] [Towards Robust DeepFake Detection under Unstable Face Sequences: Adaptive Sparse Graph Embedding with Order-Free Representation and Explicit Laplacian Spectral Prior](https://arxiv.org/abs/2512.07498)
*Chih-Chung Hsu,Shao-Ning Chen,Chia-Ming Lee,Yi-Fang Wang,Yi-Shiuan Chou*

Main category: cs.CV

TL;DR: 提出LR-GCN方法，通过拉普拉斯正则化图卷积网络检测DeepFake视频，能够在噪声或无序人脸序列中实现鲁棒检测，仅需在干净人脸数据上训练。


<details>
  <summary>Details</summary>
Motivation: 现有检测器假设时间一致且干净的人脸序列，但现实场景中存在压缩伪影、遮挡和对抗攻击，导致人脸检测不稳定，需要更鲁棒的检测方法。

Method: 构建无序时序图嵌入(OF-TGE)，基于语义相似性将帧级CNN特征组织成自适应稀疏图；引入双重稀疏机制和图拉普拉斯频谱先验，实现频谱带通机制。

Result: 在FF++、Celeb-DFv2和DFDC数据集上的实验表明，LR-GCN达到最先进性能，在严重全局和局部干扰下具有显著改进的鲁棒性。

Conclusion: LR-GCN通过图结构和频谱域处理，有效解决了现实场景中DeepFake检测的挑战，为噪声和干扰条件下的视频真实性验证提供了有效解决方案。

Abstract: Ensuring the authenticity of video content remains challenging as DeepFake generation becomes increasingly realistic and robust against detection. Most existing detectors implicitly assume temporally consistent and clean facial sequences, an assumption that rarely holds in real-world scenarios where compression artifacts, occlusions, and adversarial attacks destabilize face detection and often lead to invalid or misdetected faces. To address these challenges, we propose a Laplacian-Regularized Graph Convolutional Network (LR-GCN) that robustly detects DeepFakes from noisy or unordered face sequences, while being trained only on clean facial data. Our method constructs an Order-Free Temporal Graph Embedding (OF-TGE) that organizes frame-wise CNN features into an adaptive sparse graph based on semantic affinities. Unlike traditional methods constrained by strict temporal continuity, OF-TGE captures intrinsic feature consistency across frames, making it resilient to shuffled, missing, or heavily corrupted inputs. We further impose a dual-level sparsity mechanism on both graph structure and node features to suppress the influence of invalid faces. Crucially, we introduce an explicit Graph Laplacian Spectral Prior that acts as a high-pass operator in the graph spectral domain, highlighting structural anomalies and forgery artifacts, which are then consolidated by a low-pass GCN aggregation. This sequential design effectively realizes a task-driven spectral band-pass mechanism that suppresses background information and random noise while preserving manipulation cues. Extensive experiments on FF++, Celeb-DFv2, and DFDC demonstrate that LR-GCN achieves state-of-the-art performance and significantly improved robustness under severe global and local disruptions, including missing faces, occlusions, and adversarially perturbed face detections.

</details>


### [189] [MultiMotion: Multi Subject Video Motion Transfer via Video Diffusion Transformer](https://arxiv.org/abs/2512.07500)
*Penghui Liu,Jiangshan Wang,Yutong Shen,Shanhui Mo,Chenyang Qi,Yue Ma*

Main category: cs.CV

TL;DR: MultiMotion是一个针对多对象视频运动迁移的统一框架，通过Mask-aware Attention Motion Flow (AMF)技术解决了DiT架构中的运动纠缠问题，并引入了RectPC采样器提高生成效率。


<details>
  <summary>Details</summary>
Motivation: 解决Diffusion Transformer (DiT)在多对象视频运动迁移中存在的运动纠缠问题和缺乏对象级控制的局限性。

Method: 核心创新是AMF技术，利用SAM2掩码在DiT流水线中显式解缠和控制多个对象的运动特征；同时引入RectPC高阶预测-校正采样器。

Result: 构建了首个针对DiT多对象运动迁移的基准数据集，MultiMotion实现了精确、语义对齐且时间一致的多对象运动迁移，保持了DiT的高质量和可扩展性。

Conclusion: MultiMotion框架有效解决了多对象视频运动迁移的挑战，为DiT架构提供了对象级控制能力，在多对象生成场景中表现出色。

Abstract: Multi-object video motion transfer poses significant challenges for Diffusion Transformer (DiT) architectures due to inherent motion entanglement and lack of object-level control. We present MultiMotion, a novel unified framework that overcomes these limitations. Our core innovation is Maskaware Attention Motion Flow (AMF), which utilizes SAM2 masks to explicitly disentangle and control motion features for multiple objects within the DiT pipeline. Furthermore, we introduce RectPC, a high-order predictor-corrector solver for efficient and accurate sampling, particularly beneficial for multi-entity generation. To facilitate rigorous evaluation, we construct the first benchmark dataset specifically for DiT-based multi-object motion transfer. MultiMotion demonstrably achieves precise, semantically aligned, and temporally coherent motion transfer for multiple distinct objects, maintaining DiT's high quality and scalability. The code is in the supp.

</details>


### [190] [SJD++: Improved Speculative Jacobi Decoding for Training-free Acceleration of Discrete Auto-regressive Text-to-Image Generation](https://arxiv.org/abs/2512.07503)
*Yao Teng,Zhihuan Jiang,Han Shi,Xian Liu,Xuefei Ning,Guohao Dai,Yu Wang,Zhenguo Li,Xihui Liu*

Main category: cs.CV

TL;DR: SJD++是一种无需训练的概率并行解码算法，通过多令牌预测和验证机制，将自回归文本到图像生成的推理延迟降低2-3倍，步数压缩2-7倍，同时保持视觉质量。


<details>
  <summary>Details</summary>
Motivation: 大型自回归模型生成高分辨率图像质量好但速度慢，需要数百到数千次顺序前向传递进行下一个令牌预测。

Method: 结合Jacobi解码的迭代多令牌预测机制和推测采样的概率草稿-验证机制，在验证阶段后重用高置信度草稿令牌而非重新采样。

Result: 在多个代表性自回归文本到图像生成模型上，SJD++实现2-3倍推理延迟降低和2-7倍步数压缩，视觉质量无显著下降。

Conclusion: SJD++有效加速自回归图像生成，为高质量图像生成提供高效解决方案。

Abstract: Large autoregressive models can generate high-quality, high-resolution images but suffer from slow generation speed, because these models require hundreds to thousands of sequential forward passes for next-token prediction during inference. To accelerate autoregressive text-to-image generation, we propose Speculative Jacobi Decoding++ (SJD++), a training-free probabilistic parallel decoding algorithm. Unlike traditional next-token prediction, SJD++ performs multi-token prediction in each forward pass, drastically reducing generation steps. Specifically, it integrates the iterative multi-token prediction mechanism from Jacobi decoding, with the probabilistic drafting-and-verification mechanism from speculative sampling. More importantly, for further acceleration, SJD++ reuses high-confidence draft tokens after each verification phase instead of resampling them all. We conduct extensive experiments on several representative autoregressive text-to-image generation models and demonstrate that SJD++ achieves $2\times$ to $3\times$ inference latency reduction and $2\times$ to $7\times$ step compression, while preserving visual quality with no observable degradation.

</details>


### [191] [ControlVP: Interactive Geometric Refinement of AI-Generated Images with Consistent Vanishing Points](https://arxiv.org/abs/2512.07504)
*Ryota Okumura,Kaede Shiohara,Toshihiko Yamasaki*

Main category: cs.CV

TL;DR: ControlVP是一个用户引导的框架，用于纠正生成图像中的消失点不一致问题，通过结合结构引导和几何约束来提升几何一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像模型（如Stable Diffusion）在视觉质量上表现出色，但经常存在几何不一致问题，特别是消失点不一致，这破坏了生成场景的结构真实感。

Method: 扩展预训练扩散模型，结合建筑轮廓的结构引导，并引入几何约束以鼓励图像边缘与透视线索的对齐。

Result: 该方法增强了全局几何一致性，同时保持了与基线相当的视觉保真度，特别适用于需要准确空间结构的应用（如图像到3D重建）。

Conclusion: ControlVP框架有效解决了生成图像中的消失点不一致问题，提升了空间真实感，为相关应用提供了实用工具。

Abstract: Recent text-to-image models, such as Stable Diffusion, have achieved impressive visual quality, yet they often suffer from geometric inconsistencies that undermine the structural realism of generated scenes. One prominent issue is vanishing point inconsistency, where projections of parallel lines fail to converge correctly in 2D space. This leads to structurally implausible geometry that degrades spatial realism, especially in architectural scenes. We propose ControlVP, a user-guided framework for correcting vanishing point inconsistencies in generated images. Our approach extends a pre-trained diffusion model by incorporating structural guidance derived from building contours. We also introduce geometric constraints that explicitly encourage alignment between image edges and perspective cues. Our method enhances global geometric consistency while maintaining visual fidelity comparable to the baselines. This capability is particularly valuable for applications that require accurate spatial structure, such as image-to-3D reconstruction. The dataset and source code are available at https://github.com/RyotaOkumura/ControlVP .

</details>


### [192] [MeshRipple: Structured Autoregressive Generation of Artist-Meshes](https://arxiv.org/abs/2512.07514)
*Junkai Lin,Hang Long,Huipeng Guo,Jielei Zhang,JiaYi Yang,Tianle Guo,Yang Yang,Jianwen Li,Wenxiao Zhang,Matthias Nießner,Wei Yang*

Main category: cs.CV

TL;DR: MeshRipple是一种新的网格生成方法，通过前沿感知的BFS标记化、扩展预测策略和稀疏注意力全局内存来解决自回归网格生成中的长距离几何依赖问题，生成具有高表面保真度和拓扑完整性的网格。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归网格生成方法由于内存限制使用滑动窗口推理，导致长距离几何依赖被破坏，产生孔洞和碎片化组件。

Method: 1) 前沿感知的BFS标记化，使生成顺序与表面拓扑对齐；2) 扩展预测策略，保持连贯、连接的表面生长；3) 稀疏注意力全局内存，提供有效无界的感受野来解决长距离拓扑依赖。

Result: MeshRipple能够生成具有高表面保真度和拓扑完整性的网格，在强基准测试中表现优于现有方法。

Conclusion: MeshRipple的集成设计解决了自回归网格生成中的关键限制，实现了更好的网格生成质量。

Abstract: Meshes serve as a primary representation for 3D assets. Autoregressive mesh generators serialize faces into sequences and train on truncated segments with sliding-window inference to cope with memory limits. However, this mismatch breaks long-range geometric dependencies, producing holes and fragmented components. To address this critical limitation, we introduce MeshRipple, which expands a mesh outward from an active generation frontier, akin to a ripple on a surface.MeshRipple rests on three key innovations: a frontier-aware BFS tokenization that aligns the generation order with surface topology; an expansive prediction strategy that maintains coherent, connected surface growth; and a sparse-attention global memory that provides an effectively unbounded receptive field to resolve long-range topological dependencies.This integrated design enables MeshRipple to generate meshes with high surface fidelity and topological completeness, outperforming strong recent baselines.

</details>


### [193] [From Orbit to Ground: Generative City Photogrammetry from Extreme Off-Nadir Satellite Images](https://arxiv.org/abs/2512.07527)
*Fei Yu,Yu Liu,Luyang Tang,Mingchao Sun,Zengye Ge,Rui Bu,Yuchao Jin,Haisen Zhao,He Sun,Yangyan Li,Mu Xu,Wenzheng Chen,Baoquan Chen*

Main category: cs.CV

TL;DR: 该论文提出了一种针对城市规模3D重建的方法，通过2.5D高度图和纹理恢复网络解决从稀疏卫星图像合成地面视角的极端视角外推问题。


<details>
  <summary>Details</summary>
Motivation: 从卫星图像进行城市规模3D重建面临极端视角外推的挑战，现有方法如NeRF和3DGS在稀疏轨道图像和严重透视缩短的立面下无法有效工作。

Method: 1. 使用2.5D高度图建模城市几何，实现为Z单调有符号距离场(SDF)；2. 通过可微分渲染技术从卫星图像绘制网格外观；3. 训练生成式纹理恢复网络增强外观细节。

Result: 在4平方公里真实区域上仅使用少量卫星图像实现了最先进的逼真地面视图合成，生成具有清晰屋顶和垂直立面水密网格模型。

Conclusion: 该方法在大规模城市重建中展现出可扩展性和鲁棒性，生成的高保真模型可直接用于城市规划、仿真等下游任务。

Abstract: City-scale 3D reconstruction from satellite imagery presents the challenge of extreme viewpoint extrapolation, where our goal is to synthesize ground-level novel views from sparse orbital images with minimal parallax. This requires inferring nearly $90^\circ$ viewpoint gaps from image sources with severely foreshortened facades and flawed textures, causing state-of-the-art reconstruction engines such as NeRF and 3DGS to fail.
  To address this problem, we propose two design choices tailored for city structures and satellite inputs. First, we model city geometry as a 2.5D height map, implemented as a Z-monotonic signed distance field (SDF) that matches urban building layouts from top-down viewpoints. This stabilizes geometry optimization under sparse, off-nadir satellite views and yields a watertight mesh with crisp roofs and clean, vertically extruded facades. Second, we paint the mesh appearance from satellite images via differentiable rendering techniques. While the satellite inputs may contain long-range, blurry captures, we further train a generative texture restoration network to enhance the appearance, recovering high-frequency, plausible texture details from degraded inputs.
  Our method's scalability and robustness are demonstrated through extensive experiments on large-scale urban reconstruction. For example, in our teaser figure, we reconstruct a $4\,\mathrm{km}^2$ real-world region from only a few satellite images, achieving state-of-the-art performance in synthesizing photorealistic ground views. The resulting models are not only visually compelling but also serve as high-fidelity, application-ready assets for downstream tasks like urban planning and simulation.

</details>


### [194] [Dual-Stream Cross-Modal Representation Learning via Residual Semantic Decorrelation](https://arxiv.org/abs/2512.07568)
*Xuecheng Li,Weikuan Jia,Alisher Kurbonaliev,Qurbonaliev Alisher,Khudzhamkulov Rustam,Ismoilov Shuhratjon,Eshmatov Javhariddin,Yuanjie Zheng*

Main category: cs.CV

TL;DR: 本文提出DSRSD-Net框架，通过残差分解和语义去相关约束来解决多模态学习中模态主导、信息冗余和虚假相关等问题，提升预测性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 多模态表示常面临模态主导、冗余信息耦合和虚假跨模态相关性等问题，导致泛化能力差和可解释性有限。高方差模态容易掩盖语义重要信号，而简单融合策略会无控制地纠缠模态共享和模态特定因素。

Method: DSRSD-Net包含三个核心组件：(1)双流表示学习模块通过残差投影分离模态内和模态间潜在因素；(2)残差语义对齐头结合对比和回归目标将不同模态的共享因素映射到共同空间；(3)去相关和正交性损失正则化共享空间的协方差结构，同时强制共享流和私有流之间的正交性。

Result: 在两个大规模教育基准测试上的实验结果表明，DSRSD-Net在下一步预测和最终结果预测方面持续优于强单模态、早期融合、晚期融合和共同注意力基线方法。

Conclusion: DSRSD-Net通过有效的模态信息解耦和语义去相关约束，成功解决了多模态学习中的关键挑战，显著提升了预测性能和模型鲁棒性。

Abstract: Cross-modal learning has become a fundamental paradigm for integrating heterogeneous information sources such as images, text, and structured attributes. However, multimodal representations often suffer from modality dominance, redundant information coupling, and spurious cross-modal correlations, leading to suboptimal generalization and limited interpretability. In particular, high-variance modalities tend to overshadow weaker but semantically important signals, while naïve fusion strategies entangle modality-shared and modality-specific factors in an uncontrolled manner. This makes it difficult to understand which modality actually drives a prediction and to maintain robustness when some modalities are noisy or missing. To address these challenges, we propose a Dual-Stream Residual Semantic Decorrelation Network (DSRSD-Net), a simple yet effective framework that disentangles modality-specific and modality-shared information through residual decomposition and explicit semantic decorrelation constraints. DSRSD-Net introduces: (1) a dual-stream representation learning module that separates intra-modal (private) and inter-modal (shared) latent factors via residual projection; (2) a residual semantic alignment head that maps shared factors from different modalities into a common space using a combination of contrastive and regression-style objectives; and (3) a decorrelation and orthogonality loss that regularizes the covariance structure of the shared space while enforcing orthogonality between shared and private streams, thereby suppressing cross-modal redundancy and preventing feature collapse. Experimental results on two large-scale educational benchmarks demonstrate that DSRSD-Net consistently improves next-step prediction and final outcome prediction over strong single-modality, early-fusion, late-fusion, and co-attention baselines.

</details>


### [195] [All You Need Are Random Visual Tokens? Demystifying Token Pruning in VLLMs](https://arxiv.org/abs/2512.07580)
*Yahong Wang,Juncheng Wu,Zhangkai Ni,Longzhen Yang,Yihang Liu,Chengmei Yang,Ying Wen,Xianfeng Tang,Hui Liu,Yuyin Zhou,Lianghua He*

Main category: cs.CV

TL;DR: 该论文发现视觉大语言模型深层存在'信息消失'现象，提出信息地平线概念，并证明深层随机剪枝比现有方法更有效。


<details>
  <summary>Details</summary>
Motivation: 现有视觉令牌剪枝方法在深层表现不佳，作者发现这是由于视觉令牌信息随网络深度增加而逐渐消失导致的。

Method: 通过量化令牌信息含量（移除令牌后模型输出概率的变化），分析视觉令牌信息在深度层中的分布规律，提出基于信息地平线的随机剪枝策略。

Result: 发现信息地平线现象，深层随机剪枝优于现有方法。DivPrune结合随机剪枝可剪除50%视觉令牌，保持Qwen-2.5-VL-7B 96.9%的性能。

Conclusion: 视觉令牌在深层变得冗余，随机剪枝是高效解决方案。信息地平线位置取决于任务难度和模型能力。

Abstract: Vision Large Language Models (VLLMs) incur high computational costs due to their reliance on hundreds of visual tokens to represent images. While token pruning offers a promising solution for accelerating inference, this paper, however, identifies a key observation: in deeper layers (e.g., beyond the 20th), existing training-free pruning methods perform no better than random pruning. We hypothesize that this degradation is caused by "vanishing token information", where visual tokens progressively lose their salience with increasing network depth. To validate this hypothesis, we quantify a token's information content by measuring the change in the model output probabilities upon its removal. Using this proposed metric, our analysis of the information of visual tokens across layers reveals three key findings: (1) As layers deepen, the information of visual tokens gradually becomes uniform and eventually vanishes at an intermediate layer, which we term as "information horizon", beyond which the visual tokens become redundant; (2) The position of this horizon is not static; it extends deeper for visually intensive tasks, such as Optical Character Recognition (OCR), compared to more general tasks like Visual Question Answering (VQA); (3) This horizon is also strongly correlated with model capacity, as stronger VLLMs (e.g., Qwen2.5-VL) employ deeper visual tokens than weaker models (e.g., LLaVA-1.5). Based on our findings, we show that simple random pruning in deep layers efficiently balances performance and efficiency. Moreover, integrating random pruning consistently enhances existing methods. Using DivPrune with random pruning achieves state-of-the-art results, maintaining 96.9% of Qwen-2.5-VL-7B performance while pruning 50% of visual tokens. The code will be publicly available at https://github.com/YahongWang1/Information-Horizon.

</details>


### [196] [LongCat-Image Technical Report](https://arxiv.org/abs/2512.07584)
*Meituan LongCat Team,Hanghang Ma,Haoxian Tan,Jiale Huang,Junqiang Wu,Jun-Yan He,Lishuai Gao,Songlin Xiao,Xiaoming Wei,Xiaoqi Ma,Xunliang Cai,Yayong Guan,Jie Hu*

Main category: cs.CV

TL;DR: LongCat-Image是一个开创性的开源双语（中英）图像生成基础模型，通过多阶段数据策略和紧凑设计，在文本渲染、真实感、部署效率等方面达到新SOTA水平。


<details>
  <summary>Details</summary>
Motivation: 解决当前主流模型在多语言文本渲染、照片真实感、部署效率和开发者可访问性方面的核心挑战。

Method: 在预训练、中期训练和SFT阶段采用严格的数据筛选策略，结合精心设计的奖励模型进行RL阶段训练；采用仅6B参数的紧凑扩散模型设计。

Result: 在文本渲染能力、照片真实感和美学质量方面达到新SOTA；在中文汉字渲染方面建立新行业标准；在图像编辑方面也达到SOTA结果，具有优越的编辑一致性。

Conclusion: LongCat-Image通过其全面的开源生态系统，为开发者和研究人员提供了强大支持，推动了视觉内容创作的前沿发展。

Abstract: We introduce LongCat-Image, a pioneering open-source and bilingual (Chinese-English) foundation model for image generation, designed to address core challenges in multilingual text rendering, photorealism, deployment efficiency, and developer accessibility prevalent in current leading models. 1) We achieve this through rigorous data curation strategies across the pre-training, mid-training, and SFT stages, complemented by the coordinated use of curated reward models during the RL phase. This strategy establishes the model as a new state-of-the-art (SOTA), delivering superior text-rendering capabilities and remarkable photorealism, and significantly enhancing aesthetic quality. 2) Notably, it sets a new industry standard for Chinese character rendering. By supporting even complex and rare characters, it outperforms both major open-source and commercial solutions in coverage, while also achieving superior accuracy. 3) The model achieves remarkable efficiency through its compact design. With a core diffusion model of only 6B parameters, it is significantly smaller than the nearly 20B or larger Mixture-of-Experts (MoE) architectures common in the field. This ensures minimal VRAM usage and rapid inference, significantly reducing deployment costs. Beyond generation, LongCat-Image also excels in image editing, achieving SOTA results on standard benchmarks with superior editing consistency compared to other open-source works. 4) To fully empower the community, we have established the most comprehensive open-source ecosystem to date. We are releasing not only multiple model versions for text-to-image and image editing, including checkpoints after mid-training and post-training stages, but also the entire toolchain of training procedure. We believe that the openness of LongCat-Image will provide robust support for developers and researchers, pushing the frontiers of visual content creation.

</details>


### [197] [Robust Variational Model Based Tailored UNet: Leveraging Edge Detector and Mean Curvature for Improved Image Segmentation](https://arxiv.org/abs/2512.07590)
*Kaili Qi,Zhongyi Huang,Wenli Yang*

Main category: cs.CV

TL;DR: 提出了一种鲁棒版本的VM_TUNet混合框架，结合变分方法和深度学习来分割噪声图像，通过引入物理先验、边缘检测器和平均曲率项，在性能与计算效率之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 解决噪声图像分割问题，特别是边界模糊或断裂的情况，旨在结合变分PDE的可解释性和边界平滑优势与深度神经网络的强大表示能力。

Method: 提出VM_TUNet混合框架，包含F模块（频域预处理）和T模块（局部计算），在改进的Cahn-Hilliard方程中引入物理先验、边缘检测器和平均曲率项。

Result: 在三个基准数据集上的实验表明，该方法在性能与计算效率之间取得平衡，相比纯CNN模型获得竞争性定量结果和更好的视觉质量，同时以合理计算成本达到接近基于Transformer方法的性能。

Conclusion: 该方法成功结合了变分方法和深度学习的优势，为噪声图像分割提供了一种有效且计算高效的解决方案。

Abstract: To address the challenge of segmenting noisy images with blurred or fragmented boundaries, this paper presents a robust version of Variational Model Based Tailored UNet (VM_TUNet), a hybrid framework that integrates variational methods with deep learning. The proposed approach incorporates physical priors, an edge detector and a mean curvature term, into a modified Cahn-Hilliard equation, aiming to combine the interpretability and boundary-smoothing advantages of variational partial differential equations (PDEs) with the strong representational ability of deep neural networks. The architecture consists of two collaborative modules: an F module, which conducts efficient frequency domain preprocessing to alleviate poor local minima, and a T module, which ensures accurate and stable local computations, backed by a stability estimate. Extensive experiments on three benchmark datasets indicate that the proposed method achieves a balanced trade-off between performance and computational efficiency, which yields competitive quantitative results and improved visual quality compared to pure convolutional neural network (CNN) based models, while achieving performance close to that of transformer-based method with reasonable computational expense.

</details>


### [198] [Online Segment Any 3D Thing as Instance Tracking](https://arxiv.org/abs/2512.07599)
*Hanshi Wang,Zijian Cai,Jin Gao,Yiwei Zhang,Weiming Hu,Ke Wang,Zhipeng Zhang*

Main category: cs.CV

TL;DR: 本文提出AutoSeg3D方法，将在线3D分割重新定义为实例跟踪问题，通过对象查询实现时空信息传播，在多个数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于查询的3D分割方法忽视了时间维度的重要性，而感知是一个动态过程，需要时间理解能力。机器人视角变化导致物体部分可见性，需要超越瞬时视图的完整物体理解。

Method: 1) 将在线3D分割重构为实例跟踪问题；2) 使用对象查询进行时间信息传播：长期实例关联保持特征一致性，短期实例更新丰富瞬时观测；3) 引入空间一致性学习缓解VFMs的碎片化问题。

Result: 在ScanNet200上超越ESAM方法2.8 AP，在ScanNet、SceneNN和3RScan数据集上均取得一致性能提升，建立了新的SOTA。

Conclusion: 通过稀疏对象查询实现的时间信息交换和一致性学习不仅增强了空间理解，还避免了密集时间点云交互的计算负担，为具身智能体解锁了更强的环境感知能力。

Abstract: Online, real-time, and fine-grained 3D segmentation constitutes a fundamental capability for embodied intelligent agents to perceive and comprehend their operational environments. Recent advancements employ predefined object queries to aggregate semantic information from Vision Foundation Models (VFMs) outputs that are lifted into 3D point clouds, facilitating spatial information propagation through inter-query interactions. Nevertheless, perception is an inherently dynamic process, rendering temporal understanding a critical yet overlooked dimension within these prevailing query-based pipelines. Therefore, to further unlock the temporal environmental perception capabilities of embodied agents, our work reconceptualizes online 3D segmentation as an instance tracking problem (AutoSeg3D). Our core strategy involves utilizing object queries for temporal information propagation, where long-term instance association promotes the coherence of features and object identities, while short-term instance update enriches instant observations. Given that viewpoint variations in embodied robotics often lead to partial object visibility across frames, this mechanism aids the model in developing a holistic object understanding beyond incomplete instantaneous views. Furthermore, we introduce spatial consistency learning to mitigate the fragmentation problem inherent in VFMs, yielding more comprehensive instance information for enhancing the efficacy of both long-term and short-term temporal learning. The temporal information exchange and consistency learning facilitated by these sparse object queries not only enhance spatial comprehension but also circumvent the computational burden associated with dense temporal point cloud interactions. Our method establishes a new state-of-the-art, surpassing ESAM by 2.8 AP on ScanNet200 and delivering consistent gains on ScanNet, SceneNN, and 3RScan datasets.

</details>


### [199] [Decomposition Sampling for Efficient Region Annotations in Active Learning](https://arxiv.org/abs/2512.07606)
*Jingna Qiu,Frauke Wilm,Mathias Öttl,Jonas Utz,Maja Schlereth,Moritz Schillinger,Marc Aubreville,Katharina Breininger*

Main category: cs.CV

TL;DR: DECOMP是一种新的主动学习采样策略，通过将图像分解为类别特定组件并基于类别置信度采样，解决了密集预测任务中区域级注释的高成本和计算效率问题。


<details>
  <summary>Details</summary>
Motivation: 密集预测任务（特别是医学影像）中注释成本高，现有区域选择方法存在计算成本高、区域选择不相关、过度依赖不确定性采样等问题。

Method: 使用伪标签将图像分解为类别特定组件，从每个类别中采样区域，并通过类别预测置信度指导采样过程，确保困难类别获得更多注释。

Result: 在ROI分类、2D分割和3D分割任务中，DECOMP持续优于基线方法，能更好地采样少数类区域并提升这些困难类别的性能。

Conclusion: DECOMP通过增强注释多样性和针对性采样，有效提升了密集预测任务的注释效率和模型性能，特别是在处理不平衡数据时表现优异。

Abstract: Active learning improves annotation efficiency by selecting the most informative samples for annotation and model training. While most prior work has focused on selecting informative images for classification tasks, we investigate the more challenging setting of dense prediction, where annotations are more costly and time-intensive, especially in medical imaging. Region-level annotation has been shown to be more efficient than image-level annotation for these tasks. However, existing methods for representative annotation region selection suffer from high computational and memory costs, irrelevant region choices, and heavy reliance on uncertainty sampling. We propose decomposition sampling (DECOMP), a new active learning sampling strategy that addresses these limitations. It enhances annotation diversity by decomposing images into class-specific components using pseudo-labels and sampling regions from each class. Class-wise predictive confidence further guides the sampling process, ensuring that difficult classes receive additional annotations. Across ROI classification, 2-D segmentation, and 3-D segmentation, DECOMP consistently surpasses baseline methods by better sampling minority-class regions and boosting performance on these challenging classes. Code is in https://github.com/JingnaQiu/DECOMP.git.

</details>


### [200] [MoCA: Mixture-of-Components Attention for Scalable Compositional 3D Generation](https://arxiv.org/abs/2512.07628)
*Zhiqi Li,Wenhuan Li,Tengfei Wang,Zhenwei Wang,Junta Wu,Haoyuan Wang,Yunhan Yang,Zehuan Huang,Yang Li,Peidong Liu,Chunchao Guo*

Main category: cs.CV

TL;DR: MoCA是一个组合式3D生成模型，通过重要性组件路由和未选组件压缩技术，解决了现有方法在增加组件数量时因全局注意力计算成本过高而导致的扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于部分的3D生成方法在增加组件数量时，由于全局注意力计算的二次方成本，导致扩展性差。

Method: 提出两种关键设计：(1) 基于重要性的组件路由，选择前k个相关组件进行稀疏全局注意力计算；(2) 不重要组件压缩，在减少计算复杂度的同时保留未选组件的上下文先验。

Result: 大量实验表明，MoCA在组合式物体和场景生成任务上均优于基线方法。

Conclusion: MoCA实现了高效、细粒度的组合式3D资源创建，支持可扩展的组件数量。

Abstract: Compositionality is critical for 3D object and scene generation, but existing part-aware 3D generation methods suffer from poor scalability due to quadratic global attention costs when increasing the number of components. In this work, we present MoCA, a compositional 3D generative model with two key designs: (1) importance-based component routing that selects top-k relevant components for sparse global attention, and (2) unimportant components compression that preserve contextual priors of unselected components while reducing computational complexity of global attention. With these designs, MoCA enables efficient, fine-grained compositional 3D asset creation with scalable number of components. Extensive experiments show MoCA outperforms baselines on both compositional object and scene generation tasks. Project page: https://lizhiqi49.github.io/MoCA

</details>


### [201] [Liver Fibrosis Quantification and Analysis: The LiQA Dataset and Baseline Method](https://arxiv.org/abs/2512.07651)
*Yuanye Liu,Hanxiao Zhang,Nannan Shi,Yuxin Shi,Arif Mahmood,Murtaza Taj,Xiahai Zhuang*

Main category: cs.CV

TL;DR: 该论文介绍了LiQA数据集，这是一个用于肝脏分割和纤维化分期的多中心MRI数据集，并提出了结合半监督学习和多视图共识的基线方法。


<details>
  <summary>Details</summary>
Motivation: 肝脏纤维化是全球重大健康负担，需要准确分期以进行有效临床管理。现有方法在复杂现实条件下（如域偏移、模态缺失和空间错位）面临挑战。

Method: 提出半监督学习框架结合外部数据进行鲁棒分割，采用多视图共识方法和基于类激活图（CAM）的正则化进行分期。

Result: 评估表明，利用多源数据和解剖约束显著增强了模型在临床环境中的鲁棒性。

Conclusion: LiQA数据集为肝脏纤维化研究提供了重要基准，所提出的方法在复杂临床条件下表现出色，为未来研究奠定了基础。

Abstract: Liver fibrosis represents a significant global health burden, necessitating accurate staging for effective clinical management. This report introduces the LiQA (Liver Fibrosis Quantification and Analysis) dataset, established as part of the CARE 2024 challenge. Comprising $440$ patients with multi-phase, multi-center MRI scans, the dataset is curated to benchmark algorithms for Liver Segmentation (LiSeg) and Liver Fibrosis Staging (LiFS) under complex real-world conditions, including domain shifts, missing modalities, and spatial misalignment. We further describe the challenge's top-performing methodology, which integrates a semi-supervised learning framework with external data for robust segmentation, and utilizes a multi-view consensus approach with Class Activation Map (CAM)-based regularization for staging. Evaluation of this baseline demonstrates that leveraging multi-source data and anatomical constraints significantly enhances model robustness in clinical settings.

</details>


### [202] [An AI-Powered Autonomous Underwater System for Sea Exploration and Scientific Research](https://arxiv.org/abs/2512.07652)
*Hamad Almazrouei,Mariam Al Nasseri,Maha Alzaabi*

Main category: cs.CV

TL;DR: 本文提出了一种创新的AI驱动自主水下航行器系统，通过集成YOLOv12 Nano、CNN、PCA、K-Means++和GPT-4o Mini等技术，实现水下物体的实时检测、特征提取、降维聚类和智能报告生成。


<details>
  <summary>Details</summary>
Motivation: 传统海洋勘探面临极端条件、能见度低和成本高等挑战，导致大量海洋区域未被探索。需要自动化系统来降低人类潜水风险，提高勘探效率。

Method: 系统集成YOLOv12 Nano进行实时物体检测，ResNet50进行特征提取，PCA降维，K-Means++聚类，GPT-4o Mini生成结构化报告。在包含55,000多张图像的DeepFish和OzFish数据集上训练评估。

Result: 系统在海洋物体检测上达到mAP@0.5为0.512，精确度0.535，召回率0.438。PCA降维保留98%方差，K-Means聚类成功按视觉特征分组，LLM能生成有洞察力的报告。

Conclusion: 该集成方法显著降低人类潜水风险，提高任务效率，增强水下数据分析的深度和速度，为挑战性海洋环境中的科学研究开辟新途径。

Abstract: Traditional sea exploration faces significant challenges due to extreme conditions, limited visibility, and high costs, resulting in vast unexplored ocean regions. This paper presents an innovative AI-powered Autonomous Underwater Vehicle (AUV) system designed to overcome these limitations by automating underwater object detection, analysis, and reporting. The system integrates YOLOv12 Nano for real-time object detection, a Convolutional Neural Network (CNN) (ResNet50) for feature extraction, Principal Component Analysis (PCA) for dimensionality reduction, and K-Means++ clustering for grouping marine objects based on visual characteristics. Furthermore, a Large Language Model (LLM) (GPT-4o Mini) is employed to generate structured reports and summaries of underwater findings, enhancing data interpretation. The system was trained and evaluated on a combined dataset of over 55,000 images from the DeepFish and OzFish datasets, capturing diverse Australian marine environments. Experimental results demonstrate the system's capability to detect marine objects with a mAP@0.5 of 0.512, a precision of 0.535, and a recall of 0.438. The integration of PCA effectively reduced feature dimensionality while preserving 98% variance, facilitating K-Means clustering which successfully grouped detected objects based on visual similarities. The LLM integration proved effective in generating insightful summaries of detections and clusters, supported by location data. This integrated approach significantly reduces the risks associated with human diving, increases mission efficiency, and enhances the speed and depth of underwater data analysis, paving the way for more effective scientific research and discovery in challenging marine environments.

</details>


### [203] [Optimization-Guided Diffusion for Interactive Scene Generation](https://arxiv.org/abs/2512.07661)
*Shiaho Li,Naisheng Ye,Tianyu Li,Kashyap Chitta,Tuo An,Peng Su,Boyang Wang,Haiou Liu,Chen Lv,Hongyang Li*

Main category: cs.CV

TL;DR: OMEGA是一个基于优化的训练自由框架，通过约束优化在扩散采样过程中增强结构一致性和交互意识，生成物理合理且行为一致的交通场景，特别针对安全关键事件生成。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体驾驶场景生成模型缺乏可控性，生成的样本经常违反物理或社会约束，导致可用性受限。安全关键事件在真实驾驶数据中罕见且代表性不足，需要更有效的生成方法。

Method: 提出OMEGA框架，在扩散模型的逆扩散步骤中通过约束优化重新锚定，确保生成的轨迹物理合理且行为一致。将ego-attacker交互建模为分布空间中的博弈论优化问题，近似纳什均衡来生成安全关键对抗场景。

Result: 在nuPlan和Waymo数据集上的实验显示，OMEGA将物理和行为有效场景的比例从32.35%提升到72.27%（自由探索），从11%提升到80%（可控生成），并能生成5倍多的近碰撞帧（TTC<3秒）同时保持场景真实性。

Conclusion: OMEGA通过优化引导的扩散采样方法显著提高了驾驶场景生成的现实性、一致性和可控性，为自动驾驶系统的安全评估提供了更有效的工具。

Abstract: Realistic and diverse multi-agent driving scenes are crucial for evaluating autonomous vehicles, but safety-critical events which are essential for this task are rare and underrepresented in driving datasets. Data-driven scene generation offers a low-cost alternative by synthesizing complex traffic behaviors from existing driving logs. However, existing models often lack controllability or yield samples that violate physical or social constraints, limiting their usability. We present OMEGA, an optimization-guided, training-free framework that enforces structural consistency and interaction awareness during diffusion-based sampling from a scene generation model. OMEGA re-anchors each reverse diffusion step via constrained optimization, steering the generation towards physically plausible and behaviorally coherent trajectories. Building on this framework, we formulate ego-attacker interactions as a game-theoretic optimization in the distribution space, approximating Nash equilibria to generate realistic, safety-critical adversarial scenarios. Experiments on nuPlan and Waymo show that OMEGA improves generation realism, consistency, and controllability, increasing the ratio of physically and behaviorally valid scenes from 32.35% to 72.27% for free exploration capabilities, and from 11% to 80% for controllability-focused generation. Our approach can also generate $5\times$ more near-collision frames with a time-to-collision under three seconds while maintaining the overall scene realism.

</details>


### [204] [EgoCampus: Egocentric Pedestrian Eye Gaze Model and Dataset](https://arxiv.org/abs/2512.07668)
*Ronan John,Aditya Kesari,Vincenzo DiMatteo,Kristin Dana*

Main category: cs.CV

TL;DR: 该论文提出了EgoCampus数据集和EgoCampusNet方法，用于预测行人在户外校园环境中导航时的视觉注意力。


<details>
  <summary>Details</summary>
Motivation: 解决在真实世界导航中预测人类视觉注意力的挑战，特别是针对户外校园环境中的行人眼动注视。

Method: 使用Meta's Project Aria眼镜收集数据，整合眼动追踪、RGB相机、惯性传感器和GPS，开发了EgoCampusNet方法来预测行人导航时的眼动注视。

Result: 创建了EgoCampus数据集，包含25条独特户外路径、6公里距离、80多名行人的眼动标注视频，提供了丰富的第一人称视角数据。

Conclusion: 该研究为研究真实世界注意力提供了新资源，并为导航中的注视预测模型提供了基础，数据集和代码将公开提供。

Abstract: We address the challenge of predicting human visual attention during real-world navigation by measuring and modeling egocentric pedestrian eye gaze in an outdoor campus setting. We introduce the EgoCampus dataset, which spans 25 unique outdoor paths over 6 km across a university campus with recordings from more than 80 distinct human pedestrians, resulting in a diverse set of gaze-annotated videos. The system used for collection, Meta's Project Aria glasses, integrates eye tracking, front-facing RGB cameras, inertial sensors, and GPS to provide rich data from the human perspective. Unlike many prior egocentric datasets that focus on indoor tasks or exclude eye gaze information, our work emphasizes visual attention while subjects walk in outdoor campus paths. Using this data, we develop EgoCampusNet, a novel method to predict eye gaze of navigating pedestrians as they move through outdoor environments. Our contributions provide both a new resource for studying real-world attention and a resource for future work in gaze prediction models for navigation. Dataset and code are available upon request, and will be made publicly available at a later date at https://github.com/ComputerVisionRutgers/EgoCampus .

</details>


### [205] [DIST-CLIP: Arbitrary Metadata and Image Guided MRI Harmonization via Disentangled Anatomy-Contrast Representations](https://arxiv.org/abs/2512.07674)
*Mehmet Yigit Avci,Pedro Borges,Virginia Fernandez,Paul Wright,Mehmet Yigitsoy,Sebastien Ourselin,Jorge Cardoso*

Main category: cs.CV

TL;DR: DIST-CLIP是一个基于CLIP指导的解耦风格迁移框架，用于解决MRI数据异质性挑战，支持图像或DICOM元数据作为引导输入，在保持解剖结构的同时实现高质量风格转换。


<details>
  <summary>Details</summary>
Motivation: 现有MRI数据协调方法存在局限性：基于图像的方法需要目标图像，基于文本的方法依赖简化的标签且无法捕捉复杂采集细节。临床MRI数据因扫描仪硬件差异、采集协议多样性和序列参数变化导致显著的域偏移问题。

Method: 提出DIST-CLIP框架，明确解耦解剖内容和图像对比度，使用预训练CLIP编码器提取对比度表示，通过新型自适应风格转移模块将对比度嵌入整合到解剖内容中。

Result: 在多样化真实临床数据集上评估显示，与最先进方法相比，在风格转换保真度和解剖结构保持方面均有显著改进。

Conclusion: DIST-CLIP为MRI数据标准化提供了灵活解决方案，在风格转移和标准化方面表现优异，代码和权重将在发表后公开。

Abstract: Deep learning holds immense promise for transforming medical image analysis, yet its clinical generalization remains profoundly limited. A major barrier is data heterogeneity. This is particularly true in Magnetic Resonance Imaging, where scanner hardware differences, diverse acquisition protocols, and varying sequence parameters introduce substantial domain shifts that obscure underlying biological signals. Data harmonization methods aim to reduce these instrumental and acquisition variability, but existing approaches remain insufficient. When applied to imaging data, image-based harmonization approaches are often restricted by the need for target images, while existing text-guided methods rely on simplistic labels that fail to capture complex acquisition details or are typically restricted to datasets with limited variability, failing to capture the heterogeneity of real-world clinical environments. To address these limitations, we propose DIST-CLIP (Disentangled Style Transfer with CLIP Guidance), a unified framework for MRI harmonization that flexibly uses either target images or DICOM metadata for guidance. Our framework explicitly disentangles anatomical content from image contrast, with the contrast representations being extracted using pre-trained CLIP encoders. These contrast embeddings are then integrated into the anatomical content via a novel Adaptive Style Transfer module. We trained and evaluated DIST-CLIP on diverse real-world clinical datasets, and showed significant improvements in performance when compared against state-of-the-art methods in both style translation fidelity and anatomical preservation, offering a flexible solution for style transfer and standardizing MRI data. Our code and weights will be made publicly available upon publication.

</details>


### [206] [Guiding What Not to Generate: Automated Negative Prompting for Text-Image Alignment](https://arxiv.org/abs/2512.07702)
*Sangha Park,Eunji Kim,Yeongtak Oh,Jooyoung Choi,Sungroh Yoon*

Main category: cs.CV

TL;DR: NPC是一种自动化的负提示方法，通过识别和应用抑制意外内容的负提示来改进文本-图像对齐


<details>
  <summary>Details</summary>
Motivation: 解决文本到图像生成中精确对齐的挑战，特别是对于具有丰富组合结构或想象元素的提示

Method: 使用交叉注意力模式分析，通过验证器-标注器-提议器框架生成候选负提示，并使用显著文本空间评分进行排序

Result: 在GenEval++上达到0.571（vs 0.371基线），在Imagine-Bench上获得最佳整体性能

Conclusion: NPC通过指导模型不生成什么内容，为扩散模型提供了原则性、全自动的强文本-图像对齐路径

Abstract: Despite substantial progress in text-to-image generation, achieving precise text-image alignment remains challenging, particularly for prompts with rich compositional structure or imaginative elements. To address this, we introduce Negative Prompting for Image Correction (NPC), an automated pipeline that improves alignment by identifying and applying negative prompts that suppress unintended content. We begin by analyzing cross-attention patterns to explain why both targeted negatives-those directly tied to the prompt's alignment error-and untargeted negatives-tokens unrelated to the prompt but present in the generated image-can enhance alignment. To discover useful negatives, NPC generates candidate prompts using a verifier-captioner-proposer framework and ranks them with a salient text-space score, enabling effective selection without requiring additional image synthesis. On GenEval++ and Imagine-Bench, NPC outperforms strong baselines, achieving 0.571 vs. 0.371 on GenEval++ and the best overall performance on Imagine-Bench. By guiding what not to generate, NPC provides a principled, fully automated route to stronger text-image alignment in diffusion models. Code is released at https://github.com/wiarae/NPC.

</details>


### [207] [UnCageNet: Tracking and Pose Estimation of Caged Animal](https://arxiv.org/abs/2512.07712)
*Sayak Dutta,Harish Katti,Shashikant Verma,Shanmuganathan Raman*

Main category: cs.CV

TL;DR: 提出了一种三阶段预处理流水线，通过笼子分割、内容感知修复和评估，有效解决了动物追踪和姿态估计系统在笼子遮挡下的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 现有动物追踪和姿态估计系统（如STEP、ViTPose）在处理含有笼子结构和系统性遮挡的图像视频时性能显著下降，需要解决这一限制。

Method: 三阶段预处理流水线：1）使用Gabor增强的ResNet-UNet架构进行笼子分割；2）使用CRFill进行内容感知的笼子修复；3）在修复后的无笼帧上评估姿态估计和追踪性能。

Result: 实验验证表明，通过该流水线移除笼子遮挡后，姿态估计和追踪性能可达到无遮挡环境的水平，关键点检测精度和轨迹一致性显著提升。

Conclusion: 该预处理流水线能有效克服笼子遮挡对动物追踪和姿态估计系统的不利影响，为相关应用提供了实用解决方案。

Abstract: Animal tracking and pose estimation systems, such as STEP (Simultaneous Tracking and Pose Estimation) and ViTPose, experience substantial performance drops when processing images and videos with cage structures and systematic occlusions. We present a three-stage preprocessing pipeline that addresses this limitation through: (1) cage segmentation using a Gabor-enhanced ResNet-UNet architecture with tunable orientation filters, (2) cage inpainting using CRFill for content-aware reconstruction of occluded regions, and (3) evaluation of pose estimation and tracking on the uncaged frames. Our Gabor-enhanced segmentation model leverages orientation-aware features with 72 directional kernels to accurately identify and segment cage structures that severely impair the performance of existing methods. Experimental validation demonstrates that removing cage occlusions through our pipeline enables pose estimation and tracking performance comparable to that in environments without occlusions. We also observe significant improvements in keypoint detection accuracy and trajectory consistency.

</details>


### [208] [ViSA: 3D-Aware Video Shading for Real-Time Upper-Body Avatar Creation](https://arxiv.org/abs/2512.07720)
*Fan Yang,Heyuan Li,Peihao Li,Weihao Yuan,Lingteng Qiu,Chaoyue Song,Cheng Chen,Yisheng He,Shifeng Zhang,Xiaoguang Han,Steven Hoi,Guosheng Lin*

Main category: cs.CV

TL;DR: 本文提出了一种结合3D重建模型和视频扩散模型的新方法，用于从单张输入图像生成高保真度的上半身3D虚拟形象。该方法通过3D重建提供结构先验，指导视频扩散模型实时渲染，解决了现有方法在纹理模糊、运动僵硬和结构不稳定方面的问题。


<details>
  <summary>Details</summary>
Motivation: 当前3D虚拟形象生成方法存在两个主要问题：基于大重建模型的方法虽然速度快、结构稳定，但常出现纹理模糊和运动僵硬；而生成式视频模型能产生逼真动态效果，但容易出现身体结构错误和身份漂移等不稳定行为。需要结合两者的优势来克服这些局限。

Method: 提出一个融合框架：使用3D重建模型提供稳健的结构和外观先验，这些先验指导一个实时自回归视频扩散模型进行渲染。通过将3D重建的几何稳定性与视频模型的生成能力相结合，实现高保真度虚拟形象的生成。

Result: 实验表明，该方法显著减少了伪影，在视觉质量上相比领先方法有实质性提升。能够合成高频、逼真的细节和流畅动态，同时避免了视频生成方法中常见的结构不一致问题。

Conclusion: 该方法通过结合3D重建和视频生成的各自优势，为实时应用（如游戏和虚拟现实）提供了一个稳健高效的解决方案，能够生成具有逼真外观和动态时序一致运动的高保真数字虚拟形象。

Abstract: Generating high-fidelity upper-body 3D avatars from one-shot input image remains a significant challenge. Current 3D avatar generation methods, which rely on large reconstruction models, are fast and capable of producing stable body structures, but they often suffer from artifacts such as blurry textures and stiff, unnatural motion. In contrast, generative video models show promising performance by synthesizing photorealistic and dynamic results, but they frequently struggle with unstable behavior, including body structural errors and identity drift. To address these limitations, we propose a novel approach that combines the strengths of both paradigms. Our framework employs a 3D reconstruction model to provide robust structural and appearance priors, which in turn guides a real-time autoregressive video diffusion model for rendering. This process enables the model to synthesize high-frequency, photorealistic details and fluid dynamics in real time, effectively reducing texture blur and motion stiffness while preventing the structural inconsistencies common in video generation methods. By uniting the geometric stability of 3D reconstruction with the generative capabilities of video models, our method produces high-fidelity digital avatars with realistic appearance and dynamic, temporally coherent motion. Experiments demonstrate that our approach significantly reduces artifacts and achieves substantial improvements in visual quality over leading methods, providing a robust and efficient solution for real-time applications such as gaming and virtual reality. Project page: https://lhyfst.github.io/visa

</details>


### [209] [Improving action classification with brain-inspired deep networks](https://arxiv.org/abs/2512.07729)
*Aidas Aglinskas,Stefano Anzellotti*

Main category: cs.CV

TL;DR: 该研究比较了深度神经网络和人类在动作识别中对身体和背景信息的利用差异，发现DNNs主要依赖背景信息，而人类能同时有效利用身体和背景信息。受此启发，研究者构建了模拟大脑领域特异性处理的双流网络架构，提高了动作识别性能并使其表现更接近人类。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索深度神经网络在动作识别任务中如何利用身体姿态信息和背景场景信息，以及这种利用方式与人类认知的差异。由于DNNs可能在训练数据中过度依赖相关信息较强的特征（如背景），而忽略了身体信息，研究者希望了解是否可以通过模拟人类大脑的领域特异性处理机制来改进DNNs的性能。

Method: 研究方法包括三个部分：1）使用HAA500数据集训练标准DNNs，测试其在完整刺激、移除身体的刺激和移除背景的刺激上的表现；2）进行人类行为实验（N=28），比较人类在三种刺激条件下的表现；3）设计并测试新型双流网络架构，该架构模拟大脑的领域特异性，分别处理身体信息和背景信息。

Result: 实验结果显示：1）标准DNNs在完整刺激和移除身体的刺激上表现相似且准确率高，但在移除背景的刺激上表现接近随机水平；2）人类在所有三种刺激条件下都能准确识别动作，且在仅显示身体的刺激上表现优于仅显示背景的刺激；3）新型双流架构不仅提高了动作识别性能，其在不同刺激条件下的准确率模式更接近人类的表现模式。

Conclusion: 结论表明，人类在动作识别中能更均衡地利用身体和背景信息，而标准DNNs过度依赖背景信息。通过模拟大脑的领域特异性处理机制构建的双流网络架构，能够使DNNs的表现更加人类化，提高动作识别性能，这为开发更智能、更符合人类认知的计算机视觉系统提供了重要启示。

Abstract: Action recognition is also key for applications ranging from robotics to healthcare monitoring. Action information can be extracted from the body pose and movements, as well as from the background scene. However, the extent to which deep neural networks (DNNs) make use of information about the body and information about the background remains unclear. Since these two sources of information may be correlated within a training dataset, DNNs might learn to rely predominantly on one of them, without taking full advantage of the other. Unlike DNNs, humans have domain-specific brain regions selective for perceiving bodies, and regions selective for perceiving scenes. The present work tests whether humans are thus more effective at extracting information from both body and background, and whether building brain-inspired deep network architectures with separate domain-specific streams for body and scene perception endows them with more human-like performance. We first demonstrate that DNNs trained using the HAA500 dataset perform almost as accurately on versions of the stimuli that show both body and background and on versions of the stimuli from which the body was removed, but are at chance-level for versions of the stimuli from which the background was removed. Conversely, human participants (N=28) can recognize the same set of actions accurately with all three versions of the stimuli, and perform significantly better on stimuli that show only the body than on stimuli that show only the background. Finally, we implement and test a novel architecture patterned after domain specificity in the brain with separate streams to process body and background information. We show that 1) this architecture improves action recognition performance, and 2) its accuracy across different versions of the stimuli follows a pattern that matches more closely the pattern of accuracy observed in human participants.

</details>


### [210] [SAVE: Sparse Autoencoder-Driven Visual Information Enhancement for Mitigating Object Hallucination](https://arxiv.org/abs/2512.07730)
*Sangha Park,Seungryong Yoo,Jisoo Mok,Sungroh Yoon*

Main category: cs.CV

TL;DR: SAVE框架通过稀疏自编码器特征引导，有效缓解多模态大语言模型中的物体幻觉问题，在多个基准测试中取得显著改进


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型存在由语言先验和视觉信息丢失导致的物体幻觉问题，需要开发有效的缓解方法

Method: 提出SAVE框架，利用稀疏自编码器识别视觉理解特征，并通过特征引导增强模型的视觉基础理解能力

Result: 在CHAIR_S指标上提升10%，在POPE和MMHal-Bench基准上持续获得改进，证明方法的有效性和泛化性

Conclusion: SAVE通过引导视觉理解特征，有效抑制不确定物体标记的生成，增强对图像标记的关注，为缓解多模态幻觉问题提供了简单而有效的解决方案

Abstract: Although Multimodal Large Language Models (MLLMs) have advanced substantially, they remain vulnerable to object hallucination caused by language priors and visual information loss. To address this, we propose SAVE (Sparse Autoencoder-Driven Visual Information Enhancement), a framework that mitigates hallucination by steering the model along Sparse Autoencoder (SAE) latent features. A binary object-presence question-answering probe identifies the SAE features most indicative of the model's visual information processing, referred to as visual understanding features. Steering the model along these identified features reinforces grounded visual understanding and effectively reduces hallucination. With its simple design, SAVE outperforms state-of-the-art training-free methods on standard benchmarks, achieving a 10\%p improvement in CHAIR\_S and consistent gains on POPE and MMHal-Bench. Extensive evaluations across multiple models and layers confirm the robustness and generalizability of our approach. Further analysis reveals that steering along visual understanding features suppresses the generation of uncertain object tokens and increases attention to image tokens, mitigating hallucination. Code is released at https://github.com/wiarae/SAVE.

</details>


### [211] [SpatialDreamer: Incentivizing Spatial Reasoning via Active Mental Imagery](https://arxiv.org/abs/2512.07733)
*Meng Cao,Xingyu Li,Xue Liu,Ian Reid,Xiaodan Liang*

Main category: cs.CV

TL;DR: SpatialDreamer是一个基于强化学习的框架，通过主动探索、视觉想象和基于证据的推理来解决MLLMs在复杂空间推理任务中的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在需要心理模拟的复杂空间推理任务上表现有限，主要依赖被动观察空间数据，缺乏主动的心理意象过程。

Method: 提出SpatialDreamer强化学习框架，包含主动探索、世界模型的视觉想象和基于证据的推理闭环过程。为解决长序列推理任务中细粒度奖励监督不足的问题，提出几何策略优化(GeoPO)，引入树结构采样和带几何一致性约束的步级奖励估计。

Result: 在多个挑战性基准测试中，SpatialDreamer取得了极具竞争力的结果。

Conclusion: 该框架标志着MLLMs在类人主动空间心理模拟方面的关键进展。

Abstract: Despite advancements in Multi-modal Large Language Models (MLLMs) for scene understanding, their performance on complex spatial reasoning tasks requiring mental simulation remains significantly limited. Current methods often rely on passive observation of spatial data, failing to internalize an active mental imagery process. To bridge this gap, we propose SpatialDreamer, a reinforcement learning framework that enables spatial reasoning through a closedloop process of active exploration, visual imagination via a world model, and evidence-grounded reasoning. To address the lack of fine-grained reward supervision in longhorizontal reasoning tasks, we propose Geometric Policy Optimization (GeoPO), which introduces tree-structured sampling and step-level reward estimation with geometric consistency constraints. Extensive experiments demonstrate that SpatialDreamer delivers highly competitive results across multiple challenging benchmarks, signifying a critical advancement in human-like active spatial mental simulation for MLLMs.

</details>


### [212] [HLTCOE Evaluation Team at TREC 2025: VQA Track](https://arxiv.org/abs/2512.07738)
*Dengjia Zhang,Charles Weng,Katherine Guerrerio,Yi Lu,Kenton Murray,Alexander Martin,Reno Kriz,Benjamin Van Durme*

Main category: cs.CV

TL;DR: 提出了一种基于列表学习的框架，通过结合生成式建模和判别式排序，提升视频问答中答案生成的语义精度和排序一致性。


<details>
  <summary>Details</summary>
Motivation: 传统方法在视频问答的答案生成任务中，往往难以同时保证语义准确性和排序稳定性，特别是在需要时间推理和语义消歧的问题上表现不佳。

Method: 使用基础多模态模型生成多个候选答案，然后通过带有掩码指针交叉熵损失和排序权重的模型进行重排序，该目标整合了指针式候选选择、排序依赖权重和词汇限制下的掩码交叉熵。

Result: 实验表明，该方法在准确性和排序稳定性上均有显著提升，尤其在需要时间推理和语义消歧的问题上效果明显。

Conclusion: 通过将生成式建模与判别式排序相结合，能够生成连贯且细粒度的答案列表，为视频问答任务提供了有效的解决方案。

Abstract: The HLTCOE Evaluation team participated in TREC VQA's Answer Generation (AG) task, for which we developed a listwise learning framework that aims to improve semantic precision and ranking consistency in answer generation. Given a video-question pair, a base multimodal model first generates multiple candidate answers, which are then reranked using a model trained with a novel Masked Pointer Cross-Entropy Loss with Rank Weights. This objective integrates pointer-based candidate selection, rank-dependent weighting, and masked cross-entropy under vocabulary restriction, enabling stable and interpretable listwise optimization. By bridging generative modeling with discriminative ranking, our method produces coherent, fine-grained answer lists. Experiments reveal consistent gains in accuracy and ranking stability, especially for questions requiring temporal reasoning and semantic disambiguation.

</details>


### [213] [DiffusionDriveV2: Reinforcement Learning-Constrained Truncated Diffusion Modeling in End-to-End Autonomous Driving](https://arxiv.org/abs/2512.07745)
*Jialv Zou,Shaoyu Chen,Bencheng Liao,Zhiyu Zheng,Yuehao Song,Lefei Zhang,Qian Zhang,Wenyu Liu,Xinggang Wang*

Main category: cs.CV

TL;DR: DiffusionDriveV2通过强化学习解决生成式扩散模型在自动驾驶中的模式坍塌问题，在保持多样性的同时提升轨迹质量


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散模型的端到端自动驾驶方法存在模式坍塌问题，倾向于生成保守且同质化的行为。DiffusionDrive虽然使用预定义锚点来划分动作空间，但依赖模仿学习缺乏足够约束，导致多样性和高质量之间的两难困境

Method: 1. 使用尺度自适应乘性噪声促进广泛探索；2. 采用锚点内GRPO管理同一锚点内样本的优势估计；3. 采用锚点间截断GRPO整合不同锚点的全局视角，防止不同意图间的不当优势比较

Result: 在NAVSIM v1数据集上达到91.2 PDMS，在NAVSIM v2数据集上达到85.5 EPDMS，创造了新纪录

Conclusion: 该方法解决了截断扩散模型中多样性和一致高质量之间的两难困境，实现了最佳权衡

Abstract: Generative diffusion models for end-to-end autonomous driving often suffer from mode collapse, tending to generate conservative and homogeneous behaviors. While DiffusionDrive employs predefined anchors representing different driving intentions to partition the action space and generate diverse trajectories, its reliance on imitation learning lacks sufficient constraints, resulting in a dilemma between diversity and consistent high quality. In this work, we propose DiffusionDriveV2, which leverages reinforcement learning to both constrain low-quality modes and explore for superior trajectories. This significantly enhances the overall output quality while preserving the inherent multimodality of its core Gaussian Mixture Model. First, we use scale-adaptive multiplicative noise, ideal for trajectory planning, to promote broad exploration. Second, we employ intra-anchor GRPO to manage advantage estimation among samples generated from a single anchor, and inter-anchor truncated GRPO to incorporate a global perspective across different anchors, preventing improper advantage comparisons between distinct intentions (e.g., turning vs. going straight), which can lead to further mode collapse. DiffusionDriveV2 achieves 91.2 PDMS on the NAVSIM v1 dataset and 85.5 EPDMS on the NAVSIM v2 dataset in closed-loop evaluation with an aligned ResNet-34 backbone, setting a new record. Further experiments validate that our approach resolves the dilemma between diversity and consistent high quality for truncated diffusion models, achieving the best trade-off. Code and model will be available at https://github.com/hustvl/DiffusionDriveV2

</details>


### [214] [Unison: A Fully Automatic, Task-Universal, and Low-Cost Framework for Unified Understanding and Generation](https://arxiv.org/abs/2512.07747)
*Shihao Zhao,Yitong Chen,Zeyinzi Jiang,Bojia Zi,Shaozhe Hao,Yu Liu,Chaojie Mao,Kwan-Yee K. Wong*

Main category: cs.CV

TL;DR: Unison是一个统一的多模态理解与生成模型，采用两阶段训练方案，能够自动解析用户意图和任务参数，在低训练成本下实现多种理解与生成任务。


<details>
  <summary>Details</summary>
Motivation: 现有统一多模态学习方法存在训练成本高、任务覆盖有限、生成质量差、缺乏自动参数解析能力等问题，需要一种更智能、低成本的解决方案。

Method: 采用两阶段训练方案：1）保留预训练模型能力；2）通过少量样本（50万）和低计算成本（50 GPU小时）进行对齐微调，实现自动任务识别和参数提取。

Result: 实验表明，Unison能够准确自动识别任务类型和提取相关参数，在多种理解和生成任务上取得优异性能。

Conclusion: Unison证明了在极低训练成本下实现全自动多模态任务处理的可行性，为智能多模态系统提供了实用解决方案。

Abstract: Unified understanding and generation is a highly appealing research direction in multimodal learning. There exist two approaches: one trains a transformer via an auto-regressive paradigm, and the other adopts a two-stage scheme connecting pre-trained understanding and generative models for alignment fine-tuning. The former demands massive data and computing resources unaffordable for ordinary researchers. Though the latter requires a lower training cost, existing works often suffer from limited task coverage or poor generation quality. Both approaches lack the ability to parse input meta-information (such as task type, image resolution, video duration, etc.) and require manual parameter configuration that is tedious and non-intelligent. In this paper, we propose Unison which adopts the two-stage scheme while preserving the capabilities of the pre-trained models well. With an extremely low training cost, we cover a variety of multimodal understanding tasks, including text, image, and video understanding, as well as diverse generation tasks, such as text-to-visual content generation, editing, controllable generation, and IP-based reference generation. We also equip our model with the ability to automatically parse user intentions, determine the target task type, and accurately extract the meta-information required for the corresponding task. This enables full automation of various multimodal tasks without human intervention. Experiments demonstrate that, under a low-cost setting of only 500k training samples and 50 GPU hours, our model can accurately and automatically identify tasks and extract relevant parameters, and achieve superior performance across a variety of understanding and generation tasks.

</details>


### [215] [Modality-Aware Bias Mitigation and Invariance Learning for Unsupervised Visible-Infrared Person Re-Identification](https://arxiv.org/abs/2512.07760)
*Menglin Wang,Xiaojin Gong,Jiachen Li,Genlin Ji*

Main category: cs.CV

TL;DR: 本文提出了一种无监督可见光-红外人员重识别方法，通过模态感知Jaccard距离和分裂对比策略来解决跨模态偏差问题，在基准数据集上取得了最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常使用最优传输来关联跨模态聚类，但容易传播局部聚类错误且忽略全局实例级关系。本文通过挖掘和关注可见光-红外模态偏差，从偏差缓解的全局关联和模态不变表示学习两方面解决跨模态学习问题。

Method: 提出模态感知Jaccard距离来缓解由模态差异引起的距离偏差，通过全局聚类估计更可靠的跨模态关联；设计分裂对比策略获得模态特定全局原型，在全局关联指导下显式对齐这些原型，实现模态不变且身份可区分的表示学习。

Result: 在基准VI-ReID数据集上获得了最先进的性能，显著优于现有方法。

Conclusion: 该方法通过有效解决跨模态偏差问题，在无监督可见光-红外人员重识别任务中表现出色，验证了其有效性。

Abstract: Unsupervised visible-infrared person re-identification (USVI-ReID) aims to match individuals across visible and infrared cameras without relying on any annotation. Given the significant gap across visible and infrared modality, estimating reliable cross-modality association becomes a major challenge in USVI-ReID. Existing methods usually adopt optimal transport to associate the intra-modality clusters, which is prone to propagating the local cluster errors, and also overlooks global instance-level relations. By mining and attending to the visible-infrared modality bias, this paper focuses on addressing cross-modality learning from two aspects: bias-mitigated global association and modality-invariant representation learning. Motivated by the camera-aware distance rectification in single-modality re-ID, we propose modality-aware Jaccard distance to mitigate the distance bias caused by modality discrepancy, so that more reliable cross-modality associations can be estimated through global clustering. To further improve cross-modality representation learning, a `split-and-contrast' strategy is designed to obtain modality-specific global prototypes. By explicitly aligning these prototypes under global association guidance, modality-invariant yet ID-discriminative representation learning can be achieved. While conceptually simple, our method obtains state-of-the-art performance on benchmark VI-ReID datasets and outperforms existing methods by a significant margin, validating its effectiveness.

</details>


### [216] [GorillaWatch: An Automated System for In-the-Wild Gorilla Re-Identification and Population Monitoring](https://arxiv.org/abs/2512.07776)
*Maximilian Schall,Felix Leonard Knöfel,Noah Elias König,Jan Jonas Kubeler,Maximilian von Klinski,Joan Wilhelm Linnemann,Xiaoshi Liu,Iven Jelle Schlegelmilch,Ole Woyciniuk,Alexandra Schild,Dante Wasmuht,Magdalena Bermejo Espinet,German Illera Basas,Gerard de Melo*

Main category: cs.CV

TL;DR: 本文提出了一个用于濒危西部低地大猩猩自动重识别的端到端系统GorillaWatch，包含三个新数据集和创新的多帧自监督预训练方法，通过聚合图像主干特征优于专用视频架构，并解决了无监督种群计数问题。


<details>
  <summary>Details</summary>
Motivation: 目前濒危西部低地大猩猩监测面临巨大的人工重识别工作量，缺乏适合训练深度学习模型的大规模野外视频数据集是主要障碍。

Method: 提出GorillaWatch端到端管道，整合检测、跟踪和重识别；引入多帧自监督预训练策略利用轨迹一致性学习领域特定特征；使用AttnLRP验证模型依赖生物特征而非背景相关性；通过聚合大规模图像主干特征优化性能。

Result: 创建了迄今为止最大的野生灵长类动物重识别视频数据集；多帧自监督预训练有效学习领域特征；图像主干特征聚合优于专用视频架构；无监督种群计数方法缓解了过分割问题。

Conclusion: 该方法为濒危物种的非侵入式监测提供了可扩展解决方案，所有代码和数据集已公开发布以促进相关研究。

Abstract: Monitoring critically endangered western lowland gorillas is currently hampered by the immense manual effort required to re-identify individuals from vast archives of camera trap footage. The primary obstacle to automating this process has been the lack of large-scale, "in-the-wild" video datasets suitable for training robust deep learning models. To address this gap, we introduce a comprehensive benchmark with three novel datasets: Gorilla-SPAC-Wild, the largest video dataset for wild primate re-identification to date; Gorilla-Berlin-Zoo, for assessing cross-domain re-identification generalization; and Gorilla-SPAC-MoT, for evaluating multi-object tracking in camera trap footage. Building on these datasets, we present GorillaWatch, an end-to-end pipeline integrating detection, tracking, and re-identification. To exploit temporal information, we introduce a multi-frame self-supervised pretraining strategy that leverages consistency in tracklets to learn domain-specific features without manual labels. To ensure scientific validity, a differentiable adaptation of AttnLRP verifies that our model relies on discriminative biometric traits rather than background correlations. Extensive benchmarking subsequently demonstrates that aggregating features from large-scale image backbones outperforms specialized video architectures. Finally, we address unsupervised population counting by integrating spatiotemporal constraints into standard clustering to mitigate over-segmentation. We publicly release all code and datasets to facilitate scalable, non-invasive monitoring of endangered species

</details>


### [217] [Distribution Matching Variational AutoEncoder](https://arxiv.org/abs/2512.07778)
*Sen Ye,Jianning Pei,Mengde Xu,Shuyang Gu,Chunyu Wang,Liwei Wang,Han Hu*

Main category: cs.CV

TL;DR: DMVAE通过显式分布匹配约束将编码器潜在分布与任意参考分布对齐，突破了传统VAE的高斯先验限制，发现SSL衍生分布在建模效率与重建质量间取得最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 现有视觉生成模型（如VAE和基础模型对齐编码器）隐式约束潜在空间而未明确塑造其分布，不清楚哪种分布最适合建模。

Method: 提出Distribution-Matching VAE (DMVAE)，通过分布匹配约束显式对齐编码器潜在分布与任意参考分布，支持自监督特征、扩散噪声等多种先验分布。

Result: SSL衍生分布达到最佳平衡，在ImageNet上仅用64个训练周期获得gFID=3.2，显著优于传统方法。

Conclusion: 选择合适的潜在分布结构（通过分布级对齐实现）而非依赖固定先验，是弥合易建模潜在空间与高保真图像合成之间差距的关键。

Abstract: Most visual generative models compress images into a latent space before applying diffusion or autoregressive modelling. Yet, existing approaches such as VAEs and foundation model aligned encoders implicitly constrain the latent space without explicitly shaping its distribution, making it unclear which types of distributions are optimal for modeling. We introduce \textbf{Distribution-Matching VAE} (\textbf{DMVAE}), which explicitly aligns the encoder's latent distribution with an arbitrary reference distribution via a distribution matching constraint. This generalizes beyond the Gaussian prior of conventional VAEs, enabling alignment with distributions derived from self-supervised features, diffusion noise, or other prior distributions. With DMVAE, we can systematically investigate which latent distributions are more conducive to modeling, and we find that SSL-derived distributions provide an excellent balance between reconstruction fidelity and modeling efficiency, reaching gFID equals 3.2 on ImageNet with only 64 training epochs. Our results suggest that choosing a suitable latent distribution structure (achieved via distribution-level alignment), rather than relying on fixed priors, is key to bridging the gap between easy-to-model latents and high-fidelity image synthesis. Code is avaliable at https://github.com/sen-ye/dmvae.

</details>


### [218] [OneStory: Coherent Multi-Shot Video Generation with Adaptive Memory](https://arxiv.org/abs/2512.07802)
*Zhaochong An,Menglin Jia,Haonan Qiu,Zijian Zhou,Xiaoke Huang,Zhiheng Liu,Weiming Ren,Kumara Kahatapitiya,Ding Liu,Sen He,Chenyang Zhang,Tao Xiang,Fanny Yang,Serge Belongie,Tian Xie*

Main category: cs.CV

TL;DR: OneStory是一个用于多镜头视频生成的新方法，通过重构问题为下一个镜头生成任务，引入全局内存和自适应条件模块，实现连贯的长篇叙事视频生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法在建模长距离跨镜头上下文时存在困难，依赖有限时间窗口或单关键帧条件，导致复杂叙事下性能下降。

Method: 将多镜头视频生成重构为下一个镜头生成任务，使用预训练图像转视频模型，引入帧选择模块构建全局内存和自适应条件模块进行重要性引导的补丁化。

Result: 在60K数据集上微调后，OneStory在文本和图像条件设置下均实现了最先进的叙事连贯性，支持可控的沉浸式长篇视频叙事。

Conclusion: OneStory通过有效的跨镜头上下文建模，解决了多镜头视频生成的连贯性问题，为长篇叙事视频生成提供了可行方案。

Abstract: Storytelling in real-world videos often unfolds through multiple shots -- discontinuous yet semantically connected clips that together convey a coherent narrative. However, existing multi-shot video generation (MSV) methods struggle to effectively model long-range cross-shot context, as they rely on limited temporal windows or single keyframe conditioning, leading to degraded performance under complex narratives. In this work, we propose OneStory, enabling global yet compact cross-shot context modeling for consistent and scalable narrative generation. OneStory reformulates MSV as a next-shot generation task, enabling autoregressive shot synthesis while leveraging pretrained image-to-video (I2V) models for strong visual conditioning. We introduce two key modules: a Frame Selection module that constructs a semantically-relevant global memory based on informative frames from prior shots, and an Adaptive Conditioner that performs importance-guided patchification to generate compact context for direct conditioning. We further curate a high-quality multi-shot dataset with referential captions to mirror real-world storytelling patterns, and design effective training strategies under the next-shot paradigm. Finetuned from a pretrained I2V model on our curated 60K dataset, OneStory achieves state-of-the-art narrative coherence across diverse and complex scenes in both text- and image-conditioned settings, enabling controllable and immersive long-form video storytelling.

</details>


### [219] [Multi-view Pyramid Transformer: Look Coarser to See Broader](https://arxiv.org/abs/2512.07806)
*Gyeongjin Kang,Seungkwon Yang,Seungtae Nam,Younggeun Lee,Jungwoo Kim,Eunbyung Park*

Main category: cs.CV

TL;DR: MVP是一种可扩展的多视角Transformer架构，能够一次性从数十到数百张图像重建大型3D场景，结合局部到全局的视角层次和细到粗的空间表示层次，实现高效的大规模场景重建。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法在处理大规模多视角图像重建时的计算效率低和可扩展性差的问题，旨在实现快速、高质量的大型复杂场景重建。

Method: 基于两个核心设计原则：1）局部到全局的视角层次结构，从局部视图逐步扩展到完整场景；2）细到粗的空间表示层次，从详细空间表示逐步聚合为紧凑的信息密集令牌。结合3D Gaussian Splatting作为底层3D表示。

Result: 在多个数据集上验证表明，MVP实现了最先进的泛化重建质量，同时在各种视角配置下保持高效率和可扩展性。

Conclusion: MVP通过双层次结构设计成功平衡了计算效率和表示丰富性，为大规模3D场景重建提供了有效的解决方案。

Abstract: We propose Multi-view Pyramid Transformer (MVP), a scalable multi-view transformer architecture that directly reconstructs large 3D scenes from tens to hundreds of images in a single forward pass. Drawing on the idea of ``looking broader to see the whole, looking finer to see the details," MVP is built on two core design principles: 1) a local-to-global inter-view hierarchy that gradually broadens the model's perspective from local views to groups and ultimately the full scene, and 2) a fine-to-coarse intra-view hierarchy that starts from detailed spatial representations and progressively aggregates them into compact, information-dense tokens. This dual hierarchy achieves both computational efficiency and representational richness, enabling fast reconstruction of large and complex scenes. We validate MVP on diverse datasets and show that, when coupled with 3D Gaussian Splatting as the underlying 3D representation, it achieves state-of-the-art generalizable reconstruction quality while maintaining high efficiency and scalability across a wide range of view configurations.

</details>


### [220] [Lang3D-XL: Language Embedded 3D Gaussians for Large-scale Scenes](https://arxiv.org/abs/2512.07807)
*Shai Krakovsky,Gal Fiebelman,Sagie Benaim,Hadar Averbuch-Elor*

Main category: cs.CV

TL;DR: 本文提出了一种在3D表示中嵌入语言场的新方法，通过引入极低维语义瓶颈特征和基于哈希编码器的多分辨率处理，解决了现有方法在语义特征对齐和计算效率方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 在3D表示中嵌入语言场可以实现更丰富的空间环境语义理解，将几何与描述性意义联系起来，从而支持更直观的人机交互（如自然语言查询和编辑场景）并改进场景检索、导航和多模态推理等任务。

Method: 1) 在底层3D高斯表示中引入极低维语义瓶颈特征；2) 通过渲染并将这些特征传递给基于特征的多分辨率哈希编码器进行处理；3) 引入衰减下采样器模块和多种正则化方法来解决2D特征语义对齐问题。

Result: 在HolyScenes数据集上的评估表明，该方法在性能和效率方面均超越了现有方法。

Conclusion: 所提出的方法有效解决了大规模互联网数据学习中的语义特征对齐和效率问题，为实现语言增强的3D场景理解提供了可行的解决方案。

Abstract: Embedding a language field in a 3D representation enables richer semantic understanding of spatial environments by linking geometry with descriptive meaning. This allows for a more intuitive human-computer interaction, enabling querying or editing scenes using natural language, and could potentially improve tasks like scene retrieval, navigation, and multimodal reasoning. While such capabilities could be transformative, in particular for large-scale scenes, we find that recent feature distillation approaches cannot effectively learn over massive Internet data due to challenges in semantic feature misalignment and inefficiency in memory and runtime. To this end, we propose a novel approach to address these challenges. First, we introduce extremely low-dimensional semantic bottleneck features as part of the underlying 3D Gaussian representation. These are processed by rendering and passing them through a multi-resolution, feature-based, hash encoder. This significantly improves efficiency both in runtime and GPU memory. Second, we introduce an Attenuated Downsampler module and propose several regularizations addressing the semantic misalignment of ground truth 2D features. We evaluate our method on the in-the-wild HolyScenes dataset and demonstrate that it surpasses existing approaches in both performance and efficiency.

</details>


### [221] [WorldReel: 4D Video Generation with Consistent Geometry and Motion Modeling](https://arxiv.org/abs/2512.07821)
*Shaoheng Fang,Hanwen Jiang,Yunpeng Bai,Niloy J. Mitra,Qixing Huang*

Main category: cs.CV

TL;DR: WorldReel是一个4D视频生成器，通过联合生成RGB帧和4D场景表示（点云图、相机轨迹、密集光流映射），实现了原生时空一致性的视频生成。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成器虽然实现了显著的逼真度，但在3D一致性方面存在根本性不足。WorldReel旨在解决动态场景和移动相机下的时空一致性问题。

Method: 采用合成数据和真实数据结合的训练策略：合成数据提供精确的4D监督（几何、运动和相机），真实视频贡献视觉多样性和真实感。通过显式4D表示强制保持底层场景的一致性。

Result: 实验表明WorldReel在动态场景和移动相机下的视频生成方面达到了新的最先进水平，在几何一致性、运动连贯性和减少视角-时间伪影等指标上优于竞争方法。

Conclusion: WorldReel将视频生成推向4D一致的世界建模，使得智能体能够通过单一稳定的时空表示来渲染、交互和推理场景。

Abstract: Recent video generators achieve striking photorealism, yet remain fundamentally inconsistent in 3D. We present WorldReel, a 4D video generator that is natively spatio-temporally consistent. WorldReel jointly produces RGB frames together with 4D scene representations, including pointmaps, camera trajectory, and dense flow mapping, enabling coherent geometry and appearance modeling over time. Our explicit 4D representation enforces a single underlying scene that persists across viewpoints and dynamic content, yielding videos that remain consistent even under large non-rigid motion and significant camera movement. We train WorldReel by carefully combining synthetic and real data: synthetic data providing precise 4D supervision (geometry, motion, and camera), while real videos contribute visual diversity and realism. This blend allows WorldReel to generalize to in-the-wild footage while preserving strong geometric fidelity. Extensive experiments demonstrate that WorldReel sets a new state-of-the-art for consistent video generation with dynamic scenes and moving cameras, improving metrics of geometric consistency, motion coherence, and reducing view-time artifacts over competing methods. We believe that WorldReel brings video generation closer to 4D-consistent world modeling, where agents can render, interact, and reason about scenes through a single and stable spatiotemporal representation.

</details>


### [222] [OpenVE-3M: A Large-Scale High-Quality Dataset for Instruction-Guided Video Editing](https://arxiv.org/abs/2512.07826)
*Haoyang He,Jie Wang,Jiangning Zhang,Zhucun Xue,Xingyuan Bu,Qiangpeng Yang,Shilei Wen,Lei Xie*

Main category: cs.CV

TL;DR: 提出了OpenVE-3M，一个开源、大规模、高质量的指令视频编辑数据集，并构建了统一基准OpenVE-Bench，同时开发了5B参数模型OpenVE-Edit，在基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决指令视频编辑领域缺乏大规模高质量数据集和统一基准的问题。

Method: 通过精心设计的数据流水线生成两类编辑类型（空间对齐和非空间对齐），并进行严格质量过滤。构建包含431个视频编辑对的基准测试集。

Result: OpenVE-3M在规模、编辑类型多样性、指令长度和整体质量上超越现有开源数据集。OpenVE-Edit模型在基准测试中超越所有先前开源模型，包括14B基线模型。

Conclusion: 该工作为指令视频编辑领域提供了高质量数据集、统一基准和高效模型，推动了该领域的发展。

Abstract: The quality and diversity of instruction-based image editing datasets are continuously increasing, yet large-scale, high-quality datasets for instruction-based video editing remain scarce. To address this gap, we introduce OpenVE-3M, an open-source, large-scale, and high-quality dataset for instruction-based video editing. It comprises two primary categories: spatially-aligned edits (Global Style, Background Change, Local Change, Local Remove, Local Add, and Subtitles Edit) and non-spatially-aligned edits (Camera Multi-Shot Edit and Creative Edit). All edit types are generated via a meticulously designed data pipeline with rigorous quality filtering. OpenVE-3M surpasses existing open-source datasets in terms of scale, diversity of edit types, instruction length, and overall quality. Furthermore, to address the lack of a unified benchmark in the field, we construct OpenVE-Bench, containing 431 video-edit pairs that cover a diverse range of editing tasks with three key metrics highly aligned with human judgment. We present OpenVE-Edit, a 5B model trained on our dataset that demonstrates remarkable efficiency and effectiveness by setting a new state-of-the-art on OpenVE-Bench, outperforming all prior open-source models including a 14B baseline. Project page is at https://github.com/lewandofskee/OpenVE.

</details>


### [223] [One Layer Is Enough: Adapting Pretrained Visual Encoders for Image Generation](https://arxiv.org/abs/2512.07829)
*Yuan Gao,Chen Chen,Tianrong Chen,Jiatao Gu*

Main category: cs.CV

TL;DR: FAE是一个简单有效的框架，通过双解码器结构将预训练视觉表征适配到生成模型的低维潜空间，在保持理解能力的同时实现高质量图像生成。


<details>
  <summary>Details</summary>
Motivation: 解决预训练视觉表征与生成模型潜空间之间的不匹配问题，现有方法需要复杂的架构和目标函数。

Method: 使用双解码器结构：一个解码器重建原始特征空间，另一个解码器将重建特征作为输入进行图像生成。只需单层注意力即可适配预训练表征。

Result: 在ImageNet 256x256上，扩散模型达到FID 1.29（800轮）和1.70（80轮）的优异性能，无需CFG时也能达到SOTA水平。

Conclusion: FAE框架简单通用，可适配多种自监督编码器和生成模型，在保持高生成质量的同时实现快速学习。

Abstract: Visual generative models (e.g., diffusion models) typically operate in compressed latent spaces to balance training efficiency and sample quality. In parallel, there has been growing interest in leveraging high-quality pre-trained visual representations, either by aligning them inside VAEs or directly within the generative model. However, adapting such representations remains challenging due to fundamental mismatches between understanding-oriented features and generation-friendly latent spaces. Representation encoders benefit from high-dimensional latents that capture diverse hypotheses for masked regions, whereas generative models favor low-dimensional latents that must faithfully preserve injected noise. This discrepancy has led prior work to rely on complex objectives and architectures. In this work, we propose FAE (Feature Auto-Encoder), a simple yet effective framework that adapts pre-trained visual representations into low-dimensional latents suitable for generation using as little as a single attention layer, while retaining sufficient information for both reconstruction and understanding. The key is to couple two separate deep decoders: one trained to reconstruct the original feature space, and a second that takes the reconstructed features as input for image generation. FAE is generic; it can be instantiated with a variety of self-supervised encoders (e.g., DINO, SigLIP) and plugged into two distinct generative families: diffusion models and normalizing flows. Across class-conditional and text-to-image benchmarks, FAE achieves strong performance. For example, on ImageNet 256x256, our diffusion model with CFG attains a near state-of-the-art FID of 1.29 (800 epochs) and 1.70 (80 epochs). Without CFG, FAE reaches the state-of-the-art FID of 1.48 (800 epochs) and 2.08 (80 epochs), demonstrating both high quality and fast learning.

</details>


### [224] [UnityVideo: Unified Multi-Modal Multi-Task Learning for Enhancing World-Aware Video Generation](https://arxiv.org/abs/2512.07831)
*Jiehui Huang,Yuechen Zhang,Xu He,Yuan Gao,Zhi Cen,Bin Xia,Yan Zhou,Xin Tao,Pengfei Wan,Jiaya Jia*

Main category: cs.CV

TL;DR: UnityVideo是一个统一的多模态视频生成框架，通过联合学习多种模态（分割掩码、人体骨架、DensePose、光流、深度图）和训练范式，解决了现有视频生成模型单模态条件限制的问题。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型受限于单模态条件限制，缺乏跨模态交互和模态多样性，无法实现全面的世界知识表示。

Method: 提出动态噪声注入统一异构训练范式，以及带有上下文学习器的模态切换器，通过模块化参数和上下文学习实现统一处理。构建了130万样本的大规模统一数据集。

Result: 通过联合优化，UnityVideo加速了收敛过程，显著提升了在未见数据上的零样本泛化能力，实现了更优的视频质量、一致性和物理世界约束对齐。

Conclusion: UnityVideo框架通过多模态联合学习有效提升了视频生成的世界感知能力，证明了多模态统一训练在视频生成任务中的优势。

Abstract: Recent video generation models demonstrate impressive synthesis capabilities but remain limited by single-modality conditioning, constraining their holistic world understanding. This stems from insufficient cross-modal interaction and limited modal diversity for comprehensive world knowledge representation. To address these limitations, we introduce UnityVideo, a unified framework for world-aware video generation that jointly learns across multiple modalities (segmentation masks, human skeletons, DensePose, optical flow, and depth maps) and training paradigms. Our approach features two core components: (1) dynamic noising to unify heterogeneous training paradigms, and (2) a modality switcher with an in-context learner that enables unified processing via modular parameters and contextual learning. We contribute a large-scale unified dataset with 1.3M samples. Through joint optimization, UnityVideo accelerates convergence and significantly enhances zero-shot generalization to unseen data. We demonstrate that UnityVideo achieves superior video quality, consistency, and improved alignment with physical world constraints. Code and data can be found at: https://github.com/dvlab-research/UnityVideo

</details>


### [225] [Voxify3D: Pixel Art Meets Volumetric Rendering](https://arxiv.org/abs/2512.07834)
*Yi-Chuan Huang,Jiewen Chan,Hao-Jen Chien,Yu-Lun Liu*

Main category: cs.CV

TL;DR: Voxify3D是一个两阶段可微分框架，通过正交像素艺术监督、基于补丁的CLIP对齐和调色板约束的Gumbel-Softmax量化，实现从3D网格到体素艺术的高质量自动化生成。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在体素艺术生成中几何抽象过度简化、语义保留不足和离散颜色一致性差的问题，满足像素级精度和调色板约束的美学要求。

Method: 采用两阶段框架：1）正交像素艺术监督消除透视失真；2）基于补丁的CLIP对齐保持语义一致性；3）调色板约束的Gumbel-Softmax量化实现离散颜色空间的可微分优化。

Result: 在多样化角色上表现出优越性能（CLIP-IQA得分37.12，用户偏好率77.90%），支持可控抽象（2-8种颜色，20x-50x分辨率）。

Conclusion: Voxify3D成功解决了极端离散化下的语义保留、像素艺术美学和端到端离散优化等核心挑战，为3D体素艺术生成提供了有效解决方案。

Abstract: Voxel art is a distinctive stylization widely used in games and digital media, yet automated generation from 3D meshes remains challenging due to conflicting requirements of geometric abstraction, semantic preservation, and discrete color coherence. Existing methods either over-simplify geometry or fail to achieve the pixel-precise, palette-constrained aesthetics of voxel art. We introduce Voxify3D, a differentiable two-stage framework bridging 3D mesh optimization with 2D pixel art supervision. Our core innovation lies in the synergistic integration of three components: (1) orthographic pixel art supervision that eliminates perspective distortion for precise voxel-pixel alignment; (2) patch-based CLIP alignment that preserves semantics across discretization levels; (3) palette-constrained Gumbel-Softmax quantization enabling differentiable optimization over discrete color spaces with controllable palette strategies. This integration addresses fundamental challenges: semantic preservation under extreme discretization, pixel-art aesthetics through volumetric rendering, and end-to-end discrete optimization. Experiments show superior performance (37.12 CLIP-IQA, 77.90\% user preference) across diverse characters and controllable abstraction (2-8 colors, 20x-50x resolutions). Project page: https://yichuanh.github.io/Voxify-3D/

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [226] [POrTAL: Plan-Orchestrated Tree Assembly for Lookahead](https://arxiv.org/abs/2512.06002)
*Evan Conway,David Porfirio,David Chan,Mark Roberts,Laura M. Hiatt*

Main category: cs.RO

TL;DR: POrTAL是一种新的轻量级概率规划算法，结合FF-Replan和POMCP的优势，在部分可观测环境下为机器人高效规划任务。


<details>
  <summary>Details</summary>
Motivation: 在人类-机器人交互场景中，机器人通常面临部分可观测环境，需要在不完全信息下进行规划。现有概率规划算法在机器人有限计算资源下效率不高，或需要过多步骤达成目标。

Method: 开发了POrTAL算法，融合了FF-Replan和POMCP两种基线规划算法的优点，通过前瞻性树组装实现轻量级概率规划。

Result: 在一系列案例研究中，POrTAL能够快速找到解决方案，在步骤数量上优于FF-Replan和POMCP基线算法，并在不同时间约束下表现出良好性能。

Conclusion: POrTAL算法为部分可观测环境下的机器人任务规划提供了高效解决方案，在计算效率和规划质量方面均优于现有基线方法。

Abstract: Assigning tasks to robots often involves supplying the robot with an overarching goal, such as through natural language, and then relying on the robot to uncover and execute a plan to achieve that goal. In many settings common to human-robot interaction, however, the world is only partially observable to the robot, requiring that it create plans under uncertainty. Although many probabilistic planning algorithms exist for this purpose, these algorithms can be inefficient if executed with the robot's limited computational resources, or may require more steps than expected to achieve the goal. We thereby created a new, lightweight, probabilistic planning algorithm, Plan-Orchestrated Tree Assembly for Lookahead (POrTAL), that combines the strengths of two baseline planning algorithms, FF-Replan and POMCP. In a series of case studies, we demonstrate POrTAL's ability to quickly arrive at solutions that outperform these baselines in terms of number of steps. We additionally demonstrate how POrTAL performs under varying temporal constraints.

</details>


### [227] [Training-Free Robot Pose Estimation using Off-the-Shelf Foundational Models](https://arxiv.org/abs/2512.06017)
*Laurence Liang*

Main category: cs.RO

TL;DR: 使用前沿视觉语言模型作为现成工具，从单张目标图像估计机器人手臂关节角度，并评估了其在合成和真实世界图像数据上的性能基准。


<details>
  <summary>Details</summary>
Motivation: 随着机器人手臂在工业和住宅应用中的普及，可靠的关节角度估计可以提高安全性和性能保证，并可作为验证器进一步训练机器人策略。

Method: 将前沿视觉语言模型作为现成工具，从单张目标图像估计机器人手臂关节角度，并在合成和真实世界图像数据上进行评估。

Result: 建立了当前视觉语言模型在关节角度预测方面的性能基准，实证结果表明仅靠测试时缩放或参数缩放并不能改善关节角度预测性能。

Conclusion: 前沿视觉语言模型可以作为现成工具用于机器人手臂关节角度估计，但需要更有效的缩放策略来提升预测性能。

Abstract: Pose estimation of a robot arm from visual inputs is a challenging task. However, with the increasing adoption of robot arms for both industrial and residential use cases, reliable joint angle estimation can offer improved safety and performance guarantees, and also be used as a verifier to further train robot policies. This paper introduces using frontier vision-language models (VLMs) as an ``off-the-shelf" tool to estimate a robot arm's joint angles from a single target image. By evaluating frontier VLMs on both synthetic and real-world image-data pairs, this paper establishes a performance baseline attained by current FLMs. In addition, this paper presents empirical results suggesting that test time scaling or parameter scaling alone does not lead to improved joint angle predictions.

</details>


### [228] [Closed-Loop Robotic Manipulation of Transparent Substrates for Self-Driving Laboratories using Deep Learning Micro-Error Correction](https://arxiv.org/abs/2512.06038)
*Kelsey Fontenot,Anjali Gorti,Iva Goel,Tonio Buonassisi,Alexander E. Siemenn*

Main category: cs.RO

TL;DR: 本文开发了ASHE系统，通过机器人技术、双执行器分配器和深度学习计算机视觉，实现自动化基板处理与交换，提高自驱动实验室的自动化水平。


<details>
  <summary>Details</summary>
Motivation: 自驱动实验室在化学和材料实验自动化方面取得了进展，但基板处理和重新加载环节常被忽视，限制了自动化管道的完整性。

Method: 采用机器人技术、双执行器分配器和深度学习驱动的计算机视觉系统，开发了自动基板处理与交换（ASHE）方法，能够检测并纠正脆弱透明基板操作中的错误。

Result: 在130次独立试验中，ASHE系统实现了98.5%的首次放置准确率，仅发生两次基板错位且均被成功检测并自动纠正。

Conclusion: 通过开发更准确可靠的基板处理方法，ASHE系统提升了自驱动实验室的自动化能力，有助于加速新型化学和材料发现。

Abstract: Self-driving laboratories (SDLs) have accelerated the throughput and automation capabilities for discovering and improving chemistries and materials. Although these SDLs have automated many of the steps required to conduct chemical and materials experiments, a commonly overlooked step in the automation pipeline is the handling and reloading of substrates used to transfer or deposit materials onto for downstream characterization. Here, we develop a closed-loop method of Automated Substrate Handling and Exchange (ASHE) using robotics, dual-actuated dispensers, and deep learning-driven computer vision to detect and correct errors in the manipulation of fragile and transparent substrates for SDLs. Using ASHE, we demonstrate a 98.5% first-time placement accuracy across 130 independent trials of reloading transparent glass substrates into an SDL, where only two substrate misplacements occurred and were successfully detected as errors and automatically corrected. Through the development of more accurate and reliable methods for handling various types of substrates, we move toward an improvement in the automation capabilities of self-driving laboratories, furthering the acceleration of novel chemical and materials discoveries.

</details>


### [229] [WAM-Flow: Parallel Coarse-to-Fine Motion Planning via Discrete Flow Matching for Autonomous Driving](https://arxiv.org/abs/2512.06112)
*Yifang Xu,Jiahao Cui,Feipeng Cai,Zhihao Zhu,Hanlin Shang,Shan Luan,Mingwang Xu,Neng Zhang,Yaoyi Li,Jia Cai,Siyu Zhu*

Main category: cs.RO

TL;DR: WAM-Flow是一个视觉-语言-动作模型，将轨迹规划作为结构化标记空间中的离散流匹配问题，通过并行双向去噪实现粗到细的轨迹优化，在自动驾驶任务中超越了自回归和扩散基线模型。


<details>
  <summary>Details</summary>
Motivation: 传统的自回归解码器在轨迹规划任务中效率较低，需要探索更高效的并行生成方法，同时要平衡计算精度和安全性、舒适度等多目标优化。

Method: 结合度量对齐的数值标记器（通过三元组边界学习保持几何信息）、几何感知流目标函数和模拟器引导的GRPO对齐方法，将预训练的自回归主干网络转换为非因果流模型。

Result: 在NAVSIM v1基准测试中，1步推理达到89.1 PDMS，5步推理达到90.3 PDMS，超越了自回归和基于扩散的VLA基线模型。

Conclusion: 离散流匹配为端到端自动驾驶提供了一个有前景的新范式，具有并行生成和可调计算精度权衡的优势。

Abstract: We introduce WAM-Flow, a vision-language-action (VLA) model that casts ego-trajectory planning as discrete flow matching over a structured token space. In contrast to autoregressive decoders, WAM-Flow performs fully parallel, bidirectional denoising, enabling coarse-to-fine refinement with a tunable compute-accuracy trade-off. Specifically, the approach combines a metric-aligned numerical tokenizer that preserves scalar geometry via triplet-margin learning, a geometry-aware flow objective and a simulator-guided GRPO alignment that integrates safety, ego progress, and comfort rewards while retaining parallel generation. A multi-stage adaptation converts a pre-trained auto-regressive backbone (Janus-1.5B) from causal decoding to non-causal flow model and strengthens road-scene competence through continued multimodal pretraining. Thanks to the inherent nature of consistency model training and parallel decoding inference, WAM-Flow achieves superior closed-loop performance against autoregressive and diffusion-based VLA baselines, with 1-step inference attaining 89.1 PDMS and 5-step inference reaching 90.3 PDMS on NAVSIM v1 benchmark. These results establish discrete flow matching as a new promising paradigm for end-to-end autonomous driving. The code will be publicly available soon.

</details>


### [230] [Probabilistic Weapon Engagement Zones for a Turn Constrained Pursuer](https://arxiv.org/abs/2512.06130)
*Grant Stagg,Isaac E. Weintraub,Cameron K. Peterson*

Main category: cs.RO

TL;DR: 本文提出了曲线-直线概率交战区域(CSPEZ)概念，用于量化规避者应避免的空间区域以降低被转弯率受限的追踪者捕获的风险。开发了在参数不确定性下最小化捕获风险的轨迹生成方法。


<details>
  <summary>Details</summary>
Motivation: 传统交战区域分析通常假设追踪者参数完全已知，但在实际应用中存在位置、航向、速度、距离和最大转弯率等参数不确定性。需要开发能够处理这些不确定性的概率框架来生成更安全的规避轨迹。

Method: 首先推导了确定性曲线-直线基本交战区域(CSBEZ)的解析解，然后使用四种不确定性传播方法扩展为概率框架：蒙特卡洛采样、线性化、二次近似和神经网络回归。最后将CSPEZ约束集成到轨迹优化算法中。

Result: 评估了各近似方法的准确性和计算成本，证明了CSPEZ约束可以有效地集成到轨迹优化算法中，生成能够明确考虑追踪者不确定性的安全路径。

Conclusion: 提出的CSPEZ框架为在追踪者参数不确定性下的规避轨迹规划提供了有效的概率工具，四种不确定性传播方法各有优劣，可根据具体应用需求选择合适的方法。

Abstract: Curve-straight probabilistic engagement zones (CSPEZ) quantify the spatial regions an evader should avoid to reduce capture risk from a turn-rate-limited pursuer following a curve-straight path with uncertain parameters including position, heading, velocity, range, and maximum turn rate. This paper presents methods for generating evader trajectories that minimize capture risk under such uncertainty. We first derive an analytic solution for the deterministic curve-straight basic engagement zone (CSBEZ), then extend this formulation to a probabilistic framework using four uncertainty-propagation approaches: Monte Carlo sampling, linearization, quadratic approximation, and neural-network regression. We evaluate the accuracy and computational cost of each approximation method and demonstrate how CSPEZ constraints can be integrated into a trajectory-optimization algorithm to produce safe paths that explicitly account for pursuer uncertainty.

</details>


### [231] [GuideNav: User-Informed Development of a Vision-Only Robotic Navigation Assistant For Blind Travelers](https://arxiv.org/abs/2512.06147)
*Hochul Hwang,Soowan Yang,Jahir Sadik Monon,Nicholas A Giudice,Sunghoon Ivan Lee,Joydeep Biswas,Donghyun Kim*

Main category: cs.RO

TL;DR: 本文开发了GuideNav系统，这是一个仅使用视觉的教导-重复导航系统，灵感来自导盲犬的训练和工作方式，能够在户外环境中实现公里级的可靠路径跟随。


<details>
  <summary>Details</summary>
Motivation: 目前针对盲人和低视力人群的移动辅助系统研究中，直接为机器人导航设计提供参考的资料非常稀缺。为了填补这一空白，作者进行了全面的人因研究。

Method: 通过访谈26名导盲犬使用者、4名白手杖使用者、9名导盲犬训练师和1名定向行走训练师，以及15+小时的导盲犬辅助行走观察，开发了GuideNav系统。该系统构建拓扑路径表示，集成视觉位置识别与时间滤波，使用相对位姿估计器计算导航动作，无需依赖昂贵的LiDAR等传感器。

Result: 在实地测试中，GuideNav在五种户外环境中持续实现了公里级的路径跟随，即使在教导和重复运行之间存在明显场景变化的情况下仍保持可靠性。用户研究进一步证实了系统的可行性。

Conclusion: 这是首个展示四足移动系统以类似导盲犬方式检索路径的研究，为盲人和低视力人群的辅助系统开发提供了重要参考。

Abstract: While commendable progress has been made in user-centric research on mobile assistive systems for blind and low-vision (BLV) individuals, references that directly inform robot navigation design remain rare. To bridge this gap, we conducted a comprehensive human study involving interviews with 26 guide dog handlers, four white cane users, nine guide dog trainers, and one O\&M trainer, along with 15+ hours of observing guide dog-assisted walking. After de-identification, we open-sourced the dataset to promote human-centered development and informed decision-making for assistive systems for BLV people. Building on insights from this formative study, we developed GuideNav, a vision-only, teach-and-repeat navigation system. Inspired by how guide dogs are trained and assist their handlers, GuideNav autonomously repeats a path demonstrated by a sighted person using a robot. Specifically, the system constructs a topological representation of the taught route, integrates visual place recognition with temporal filtering, and employs a relative pose estimator to compute navigation actions - all without relying on costly, heavy, power-hungry sensors such as LiDAR. In field tests, GuideNav consistently achieved kilometer-scale route following across five outdoor environments, maintaining reliability despite noticeable scene variations between teach and repeat runs. A user study with 3 guide dog handlers and 1 guide dog trainer further confirmed the system's feasibility, marking (to our knowledge) the first demonstration of a quadruped mobile system retrieving a path in a manner comparable to guide dogs.

</details>


### [232] [Real-Time Spatiotemporal Tubes for Dynamic Unsafe Sets](https://arxiv.org/abs/2512.06151)
*Ratnangshu Das,Siddhartha Upadhyay,Pushpak Jagtap*

Main category: cs.RO

TL;DR: 提出了一种针对非线性纯反馈系统的实时控制框架，可在动态环境中在规定时间内完成到达-避障-停留任务，通过实时时空管（STT）实现安全控制。


<details>
  <summary>Details</summary>
Motivation: 解决非线性纯反馈系统在动态环境中实时完成复杂任务（到达目标、避障、停留）的挑战，特别是当系统动力学未知且需要严格时间约束时。

Method: 引入实时时空管（STT）框架，定义为状态空间中的时变球体，其中心和半径在线自适应调整；推导出无近似闭式控制律，将系统输出约束在STT内。

Result: 提供了避障和按时完成任务的形式化保证，通过移动机器人和飞行器的仿真及硬件实验验证了框架的有效性和可扩展性。

Conclusion: 所提出的STT框架能够有效处理动态环境中的实时控制问题，为非线性系统提供了安全可靠的任务完成方案。

Abstract: This paper presents a real-time control framework for nonlinear pure-feedback systems with unknown dynamics to satisfy reach-avoid-stay tasks within a prescribed time in dynamic environments. To achieve this, we introduce a real-time spatiotemporal tube (STT) framework. An STT is defined as a time-varying ball in the state space whose center and radius adapt online using only real-time sensory input. A closed-form, approximation-free control law is then derived to constrain the system output within the STT, ensuring safety and task satisfaction. We provide formal guarantees for obstacle avoidance and on-time task completion. The effectiveness and scalability of the framework are demonstrated through simulations and hardware experiments on a mobile robot and an aerial vehicle, navigating in cluttered dynamic environments.

</details>


### [233] [Situation-Aware Interactive MPC Switching for Autonomous Driving](https://arxiv.org/abs/2512.06182)
*Shuhao Qi,Qiling Aori,Luyao Zhang,Mircea Lazar,Sofie Haesaert*

Main category: cs.RO

TL;DR: 该论文提出了一种基于情境感知的控制器切换策略，通过神经网络分类器在不同交互需求的情境下选择合适的MPC控制器，以平衡自动驾驶系统的性能和计算开销。


<details>
  <summary>Details</summary>
Motivation: 在交互式交通场景中，不同的MPC控制器具有不同的交互能力和计算成本。由于强交互在交通中相对较少发生，需要一种智能策略来根据情境需求选择合适的控制器，以实现性能与计算效率的平衡。

Method: 首先对不同MPC控制器的交互能力进行比较研究并建立层次结构，然后开发基于神经网络的分类器，实现根据情境需求在不同交互能力的控制器之间进行切换。

Result: 研究表明，情境感知的控制器切换策略能够在关键但罕见的强交互情境下激活最先进的交互MPC以显著提升性能，同时在大多数场景中使用基础MPC来显著降低计算负载。

Conclusion: 该论文提出的情境感知切换方法有效解决了自动驾驶系统中交互能力与计算效率之间的权衡问题，为实际应用提供了可行的解决方案。

Abstract: To enable autonomous driving in interactive traffic scenarios, various model predictive control (MPC) formulations have been proposed, each employing different interaction models. While higher-fidelity models enable more intelligent behavior, they incur increased computational cost. Since strong interactions are relatively infrequent in traffic, a practical strategy for balancing performance and computational overhead is to invoke an appropriate controller based on situational demands. To achieve this approach, we first conduct a comparative study to assess and hierarchize the interactive capabilities of different MPC formulations. Furthermore, we develop a neural network-based classifier to enable situation-aware switching among controllers with different levels of interactive capability. We demonstrate that this situation-aware switching can both substantially improve overall performance by activating the most advanced interactive MPC in rare but critical situations, and significantly reduce computational load by using a basic MPC in the majority of scenarios.

</details>


### [234] [REWW-ARM -- Remote Wire-Driven Mobile Robot: Design, Control, and Experimental Validation](https://arxiv.org/abs/2512.06192)
*Takahiro Hattori,Kento Kawaharazuka,Temma Suzuki,Keita Yoneda,Kei Okada*

Main category: cs.RO

TL;DR: 提出了一种名为"远程线缆驱动"的新系统，通过将电子设备与操作环境分离，同时保留电子控制和驱动能力，解决了机器人电子设备限制工作环境的问题。


<details>
  <summary>Details</summary>
Motivation: 电子设备限制了机器人的可用环境，需要开发能够在排除电子设备的环境中运行，同时保持高级电子控制和驱动的机器人系统。

Method: 开发了REWW-ARM机器人，包含三个关键组件：1）远程线缆传输机制（RWTM）；2）无电子设备的远端移动机器人；3）基于RWTM进行状态估计并提供电子闭环控制的电机单元。

Result: 通过实验验证了REWW-ARM在陆地和水中都能实现运动、姿态控制和物体操作的能力，证明了系统的机械和控制性能。

Conclusion: 远程线缆驱动系统有潜力应用于各种类型的机器人，从而扩展其操作范围。

Abstract: Electronic devices are essential for robots but limit their usable environments. To overcome this, methods excluding electronics from the operating environment while retaining advanced electronic control and actuation have been explored. These include the remote hydraulic drive of electronics-free mobile robots, which offer high reachability, and long wire-driven robot arms with motors consolidated at the base, which offer high environmental resistance. To combine the advantages of both, this study proposes a new system, "Remote Wire Drive." As a proof-of-concept, we designed and developed the Remote Wire-Driven robot "REWW-ARM", which consists of the following components: 1) a novel power transmission mechanism, the "Remote Wire Transmission Mechanism" (RWTM), the key technology of the Remote Wire Drive; 2) an electronics-free distal mobile robot driven by it; and 3) a motor-unit that generates power and provides electronic closed-loop control based on state estimation via the RWTM. In this study, we evaluated the mechanical and control performance of REWW-ARM through several experiments, demonstrating its capability for locomotion, posture control, and object manipulation both on land and underwater. This suggests the potential for applying the Remote Wire-Driven system to various types of robots, thereby expanding their operational range.

</details>


### [235] [Cascaded Tightly-Coupled Observer Design for Single-Range-Aided Inertial Navigation](https://arxiv.org/abs/2512.06198)
*Oussama Sifour,Soulaimane Berkane,Abdelhamid Tayebi*

Main category: cs.RO

TL;DR: 提出一种仅使用IMU、体坐标系向量测量和固定锚点距离测量的单距离辅助导航观测器，用于重构刚体的完整状态。


<details>
  <summary>Details</summary>
Motivation: 开发一种轻量级且有效的自主导航方法，减少对复杂传感器系统的依赖，仅利用基本传感器实现完整的姿态和位置估计。

Method: 首先构建扩展线性时变系统估计体坐标系位置、速度和重力方向，然后结合体坐标系向量测量在SO(3)上重构完整姿态，采用级联观测器架构。

Result: 在三维轨迹上的仿真研究表明，该方法能够准确估计位置、速度和姿态，证明了单距离辅助作为轻量级导航方式的有效性。

Conclusion: 该级联设计在一致可观测条件下具有几乎全局渐近稳定性，对传感器噪声和轨迹变化具有鲁棒性，单距离辅助是一种有效的轻量级自主导航方式。

Abstract: This work introduces a single-range-aided navigation observer that reconstructs the full state of a rigid body using only an Inertial Measurement Unit (IMU), a body-frame vector measurement (e.g., magnetometer), and a distance measurement from a fixed anchor point. The design first formulates an extended linear time-varying (LTV) system to estimate body-frame position, body-frame velocity, and the gravity direction. The recovered gravity direction, combined with the body-frame vector measurement, is then used to reconstruct the full orientation on $\mathrm{SO}(3)$, resulting in a cascaded observer architecture. Almost Global Asymptotic Stability (AGAS) of the cascaded design is established under a uniform observability condition, ensuring robustness to sensor noise and trajectory variations. Simulation studies on three-dimensional trajectories demonstrate accurate estimation of position, velocity, and orientation, highlighting single-range aiding as a lightweight and effective modality for autonomous navigation.

</details>


### [236] [Where to Fly, What to Send: Communication-Aware Aerial Support for Ground Robots](https://arxiv.org/abs/2512.06207)
*Harshil Suthar,Dipankar Maity*

Main category: cs.RO

TL;DR: 本文提出一个多机器人协作框架，其中空中机器人通过带宽受限的通信通道向地面机器人传输地图信息，基于信息价值(VoI)决定传输内容，使用混合整数线性规划(MILP)确定传输量，并通过效用评分策略进行环境探索。


<details>
  <summary>Details</summary>
Motivation: 解决在带宽受限通信环境下，空中辅助机器人如何智能决策传输哪些地图信息、传输多少信息以及何时传输，同时进行环境探索和建图的问题。

Method: 1. 基于信息价值(VoI)决定传输内容；2. 使用混合整数线性规划(MILP)确定传输量；3. 采用效用评分策略进行环境探索；4. 分析通信与运动之间的权衡关系。

Result: 实现了通信-运动权衡分析，量化了空中机器人传输的地图数据总量与地面机器人导航成本之间的关系。

Conclusion: 该框架能够有效平衡通信资源使用和地面机器人导航性能，为带宽受限环境下的多机器人协作提供了系统化解决方案。

Abstract: In this work we consider a multi-robot team operating in an unknown environment where one aerial agent is tasked to map the environment and transmit (a portion of) the mapped environment to a group of ground agents that are trying to reach their goals. The entire operation takes place over a bandwidth-limited communication channel, which motivates the problem of determining what and how much information the assisting agent should transmit and when while simultaneously performing exploration/mapping. The proposed framework enables the assisting aerial agent to decide what information to transmit based on the Value-of-Information (VoI), how much to transmit using a Mixed-Integer Linear Programming (MILP), and how to acquire additional information through an utility score-based environment exploration strategy. We perform a communication-motion trade-off analysis between the total amount of map data communicated by the aerial agent and the navigation cost incurred by the ground agents.

</details>


### [237] [Safe Model Predictive Diffusion with Shielding](https://arxiv.org/abs/2512.06261)
*Taekyung Kim,Keyvan Majd,Hideki Okamoto,Bardh Hoxha,Dimitra Panagou,Georgios Fainekos*

Main category: cs.RO

TL;DR: Safe MPD是一种基于扩散模型的免训练规划器，结合模型预测框架和安全防护机制，能够生成既满足动力学约束又保证安全性的轨迹。


<details>
  <summary>Details</summary>
Motivation: 解决复杂机器人系统在生成安全、动力学可行且最优轨迹时面临的挑战，避免传统后处理校正方法带来的计算不可行性和可行性损失问题。

Method: 将基于模型的扩散框架与安全防护机制相结合，在去噪过程中对所有样本强制执行可行性和安全性约束。

Result: 在具有挑战性的非凸规划问题（包括运动学和加速度控制的拖拉机-拖车系统）上验证，相比现有安全策略在成功率和安全性方面显著提升，同时实现亚秒级计算时间。

Conclusion: Safe MPD方法能够有效生成安全且动力学可行的轨迹，避免了后处理校正的常见缺陷，在复杂机器人系统规划中表现出优越性能。

Abstract: Generating safe, kinodynamically feasible, and optimal trajectories for complex robotic systems is a central challenge in robotics. This paper presents Safe Model Predictive Diffusion (Safe MPD), a training-free diffusion planner that unifies a model-based diffusion framework with a safety shield to generate trajectories that are both kinodynamically feasible and safe by construction. By enforcing feasibility and safety on all samples during the denoising process, our method avoids the common pitfalls of post-processing corrections, such as computational intractability and loss of feasibility. We validate our approach on challenging non-convex planning problems, including kinematic and acceleration-controlled tractor-trailer systems. The results show that it substantially outperforms existing safety strategies in success rate and safety, while achieving sub-second computation times.

</details>


### [238] [Leveraging Port-Hamiltonian Theory for Impedance Control Benchmarking](https://arxiv.org/abs/2512.06423)
*Leonardo F. Dos Santos,Elisa G. Vergamini,Cícero Zanette,Lucca Maitan,Thiago Boaventura*

Main category: cs.RO

TL;DR: 本文提出了基于端口哈密顿(PH)系统的阻抗控制基准测试指标，包括因果一致的PH模型、n自由度无源性条件和阻抗保真度度量。


<details>
  <summary>Details</summary>
Motivation: 当前阻抗控制缺乏标准化的基准测试方法，需要一种能够评估时间变化参考下多自由度系统性能的统一框架。

Method: 引入因果一致的端口哈密顿模型来描述笛卡尔空间中的质量-弹簧-阻尼阻抗，推导出可微分、不依赖力-力矩传感的n自由度无源性条件，并基于自由运动中的阶跃响应功率定义阻抗保真度度量。

Result: 在Gazebo仿真中验证了所提指标的有效性，使用六自由度机械臂和四足机器人腿进行测试，结果表明PH框架适用于标准化阻抗控制基准测试。

Conclusion: 端口哈密顿框架为阻抗控制提供了有效的标准化基准测试方法，所提出的指标能够准确评估多自由度系统的动态性能。

Abstract: This work proposes PH-based metrics for benchmarking impedance control. A causality-consistent PH model is introduced for mass-spring-damper impedance in Cartesian space. Based on this model, a differentiable, force-torque sensing-independent, n-DoF passivity condition is derived, valid for time-varying references. An impedance fidelity metric is also defined from step-response power in free motion, capturing dynamic decoupling. The proposed metrics are validated in Gazebo simulations with a six-DoF manipulator and a quadruped leg. Results demonstrate the suitability of the PH framework for standardized impedance control benchmarking.

</details>


### [239] [Fault Tolerant Control of Mecanum Wheeled Mobile Robots](https://arxiv.org/abs/2512.06444)
*Xuehui Ma,Shiliang Zhang,Zhiyong Sun*

Main category: cs.RO

TL;DR: 提出了一种针对麦克纳姆轮式移动机器人（MWMRs）的容错控制策略，能够同时处理完全和部分执行器故障，通过后验概率实时学习故障参数，提高控制系统的鲁棒性和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有的MWMR容错控制方案主要针对完全执行器故障（如电机失速），忽略了部分故障（如扭矩退化），这限制了系统在复杂故障场景下的性能。

Method: 采用后验概率实时学习故障参数，通过聚合预定义故障对应的概率加权控制律来推导容错控制律。

Result: 仿真结果表明，该容错控制策略在不同场景下均能有效应对多种类型的执行器故障。

Conclusion: 所提出的容错控制策略能够显著提升MWMR在复杂故障情况下的控制鲁棒性和系统安全性。

Abstract: Mecanum wheeled mobile robots (MWMRs) are highly susceptible to actuator faults that degrade performance and risk mission failure. Current fault tolerant control (FTC) schemes for MWMRs target complete actuator failures like motor stall, ignoring partial faults e.g., in torque degradation. We propose an FTC strategy handling both fault types, where we adopt posterior probability to learn real-time fault parameters. We derive the FTC law by aggregating probability-weighed control laws corresponding to predefined faults. This ensures the robustness and safety of MWMR control despite varying levels of fault occurrence. Simulation results demonstrate the effectiveness of our FTC under diverse scenarios.

</details>


### [240] [Entropy-Controlled Intrinsic Motivation Reinforcement Learning for Quadruped Robot Locomotion in Complex Terrains](https://arxiv.org/abs/2512.06486)
*Wanru Gong,Xinyi Zheng,Xiaopeng Yang,Xiaoqing Zhu*

Main category: cs.RO

TL;DR: 本文提出了ECIM（熵控内在动机）算法，通过结合内在动机和自适应探索来减少PPO系列算法在四足机器人运动策略训练中的过早收敛问题。


<details>
  <summary>Details</summary>
Motivation: 传统PPO系列算法在四足机器人运动策略训练中容易过早收敛，导致运动性能次优和任务表现下降。

Method: ECIM算法结合熵控制和内在动机控制，在Isaac Gym环境中对六种地形（上坡、下坡、不平坦粗糙地形、上楼梯、下楼梯、平地）进行实验。

Result: 相比基线方法，任务奖励提升4-12%，峰值身体俯仰振荡减少23-29%，关节加速度降低20-32%，关节扭矩消耗下降11-20%。

Conclusion: ECIM算法在不同地形上实现了更好的四足运动稳定性，同时降低了能耗，是复杂机器人控制任务的实用选择。

Abstract: Learning is the basis of both biological and artificial systems when it comes to mimicking intelligent behaviors. From the classical PPO (Proximal Policy Optimization), there is a series of deep reinforcement learning algorithms which are widely used in training locomotion policies for quadrupedal robots because of their stability and sample efficiency. However, among all these variants, experiments and simulations often converge prematurely, leading to suboptimal locomotion and reduced task performance. Therefore, in this paper, we introduce Entropy-Controlled Intrinsic Motivation (ECIM), an entropy-based reinforcement learning algorithm in contrast with the PPO series, that can reduce premature convergence by combining intrinsic motivation with adaptive exploration.
  For experiments, in order to parallel with other baselines, we chose to apply it in Isaac Gym across six terrain categories: upward slopes, downward slopes, uneven rough terrain, ascending stairs, descending stairs, and flat ground as widely used. For comparison, our experiments consistently achieve better performance: task rewards increase by 4--12%, peak body pitch oscillation is reduced by 23--29%, joint acceleration decreases by 20--32%, and joint torque consumption declines by 11--20%. Overall, our model ECIM, by combining entropy control and intrinsic motivation control, achieves better results in stability across different terrains for quadrupedal locomotion, and at the same time reduces energetic cost and makes it a practical choice for complex robotic control tasks.

</details>


### [241] [Vision-Guided Grasp Planning for Prosthetic Hands in Unstructured Environments](https://arxiv.org/abs/2512.06517)
*Shifa Sulaiman,Akash Bachhar,Ming Shen,Simon Bøgh*

Main category: cs.RO

TL;DR: 该论文提出了一种基于视觉引导的假手抓取算法，通过集成感知、规划和控制实现灵巧操作，采用BVH视觉算法分割物体并计算抓取接触点，使用RRT*算法生成轨迹，通过DLS逆运动学求解关节角度，在仿真和Linker Hand O7平台上验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前假肢技术需要提升在动态环境中与多样化物体自然交互的灵巧性和自主性，视觉方法为实现这一目标提供了有前景的解决方案。

Method: 使用摄像头采集场景，BVH视觉算法分割物体并定义边界框；RRT*算法生成候选轨迹并基于最小欧氏距离选择指尖末端位姿；独立确定每个手指的抓取位姿；DLS逆运动学求解关节角度并传输给执行器。

Result: 该方法在仿真和Linker Hand O7实验平台上成功验证，能够实现模块化的单手指抓取规划，并在非结构化环境中支持实时适应性。

Conclusion: 提出的视觉引导抓取算法有效提升了假手的灵巧操作能力，模块化管道设计支持实时自适应，为智能假肢在动态环境中的应用提供了可行方案。

Abstract: Recent advancements in prosthetic technology have increasingly focused on enhancing dexterity and autonomy through intelligent control systems. Vision-based approaches offer promising results for enabling prosthetic hands to interact more naturally with diverse objects in dynamic environments. Building on this foundation, the paper presents a vision-guided grasping algorithm for a prosthetic hand, integrating perception, planning, and control for dexterous manipulation. A camera mounted on the set up captures the scene, and a Bounding Volume Hierarchy (BVH)-based vision algorithm is employed to segment an object for grasping and define its bounding box. Grasp contact points are then computed by generating candidate trajectories using Rapidly-exploring Random Tree Star algorithm, and selecting fingertip end poses based on the minimum Euclidean distance between these trajectories and the objects point cloud. Each finger grasp pose is determined independently, enabling adaptive, object-specific configurations. Damped Least Square (DLS) based Inverse kinematics solver is used to compute the corresponding joint angles, which are subsequently transmitted to the finger actuators for execution. This modular pipeline enables per-finger grasp planning and supports real-time adaptability in unstructured environments. The proposed method is validated in simulation, and experimental integration on a Linker Hand O7 platform.

</details>


### [242] [TacFinRay: Soft Tactile Fin-Ray Finger with Indirect Tactile Sensing for Robust Grasping](https://arxiv.org/abs/2512.06524)
*Saekwang Nam,Bowen Deng,Loong Yi Lee,Jonathan M. Rossiter,Nathan F. Lepora*

Main category: cs.RO

TL;DR: 本文提出了一种触觉传感器化的Fin-Ray手指，通过间接传感方法同时检测接触位置和压入深度，采用铰链机制和基于TacTip视觉触觉传感器的标记针阵列，结合卷积神经网络处理变形模式，实现高精度触觉感知。


<details>
  <summary>Details</summary>
Motivation: 为软体机器人结构提供一种轻量、灵活且可扩展的触觉传感解决方案，使传感模块无需直接位于接触界面，同时实现接触位置和深度的精确检测。

Method: 在软Fin-Ray结构和刚性传感模块之间集成铰链机制，通过底部横梁上的标记针阵列传递变形和位移信息，内部摄像头捕获变形模式，使用卷积神经网络推断接触条件。

Result: 优化手指设计后，达到0.1mm深度和2mm位置传感精度，感知对不同形状和尺寸的压头具有鲁棒泛化能力，在不确定抓取位置的拾取任务中显著提高了放置精度。

Conclusion: 该工作为软体机器人结构提供了一种有效的触觉传感方案，特别适用于需要将传感模块远离接触界面的应用场景。

Abstract: We present a tactile-sensorized Fin-Ray finger that enables simultaneous detection of contact location and indentation depth through an indirect sensing approach. A hinge mechanism is integrated between the soft Fin-Ray structure and a rigid sensing module, allowing deformation and translation information to be transferred to a bottom crossbeam upon which are an array of marker-tipped pins based on the biomimetic structure of the TacTip vision-based tactile sensor. Deformation patterns captured by an internal camera are processed using a convolutional neural network to infer contact conditions without directly sensing the finger surface. The finger design was optimized by varying pin configurations and hinge orientations, achieving 0.1\,mm depth and 2mm location-sensing accuracies. The perception demonstrated robust generalization to various indenter shapes and sizes, which was applied to a pick-and-place task under uncertain picking positions, where the tactile feedback significantly improved placement accuracy. Overall, this work provides a lightweight, flexible, and scalable tactile sensing solution suitable for soft robotic structures where the sensing needs situating away from the contact interface.

</details>


### [243] [Embodied Referring Expression Comprehension in Human-Robot Interaction](https://arxiv.org/abs/2512.06558)
*Md Mofijul Islam,Alexi Gladstone,Sujan Sarker,Ganesh Nanduru,Md Fahim,Keyan Du,Aman Chadha,Tariq Iqbal*

Main category: cs.RO

TL;DR: 本文提出了Refer360数据集和MuRes模块，用于解决机器人理解具身人类指令的挑战。Refer360是首个大规模、多视角、涵盖室内外环境的具身交互数据集，MuRes则通过引导残差学习增强多模态模型的具身指代表达理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有数据集存在视角偏差、单视图收集、非语言手势覆盖不足以及主要关注室内环境等问题，限制了机器人在真实人类工作空间中理解具身指令的能力。

Method: 1）构建Refer360数据集：大规模具身语言和非语言交互数据集，涵盖室内外环境和多视角；2）提出MuRes模块：多模态引导残差模块，作为信息瓶颈提取模态特定信号并增强预训练表示。

Result: 在四个HRI数据集上的实验表明，现有多模态模型难以全面捕捉具身交互，但使用MuRes增强后性能得到一致提升。

Conclusion: Refer360为具身指代表达理解提供了有价值的基准，MuRes展示了引导残差学习在提升机器人具身交互理解能力方面的潜力。

Abstract: As robots enter human workspaces, there is a crucial need for them to comprehend embodied human instructions, enabling intuitive and fluent human-robot interaction (HRI). However, accurate comprehension is challenging due to a lack of large-scale datasets that capture natural embodied interactions in diverse HRI settings. Existing datasets suffer from perspective bias, single-view collection, inadequate coverage of nonverbal gestures, and a predominant focus on indoor environments. To address these issues, we present the Refer360 dataset, a large-scale dataset of embodied verbal and nonverbal interactions collected across diverse viewpoints in both indoor and outdoor settings. Additionally, we introduce MuRes, a multimodal guided residual module designed to improve embodied referring expression comprehension. MuRes acts as an information bottleneck, extracting salient modality-specific signals and reinforcing them into pre-trained representations to form complementary features for downstream tasks. We conduct extensive experiments on four HRI datasets, including the Refer360 dataset, and demonstrate that current multimodal models fail to capture embodied interactions comprehensively; however, augmenting them with MuRes consistently improves performance. These findings establish Refer360 as a valuable benchmark and exhibit the potential of guided residual learning to advance embodied referring expression comprehension in robots operating within human environments.

</details>


### [244] [Learning Agile Striker Skills for Humanoid Soccer Robots from Noisy Sensory Input](https://arxiv.org/abs/2512.06571)
*Zifan Xu,Myoungkyu Seo,Dongmyeong Lee,Hao Fu,Jiaheng Hu,Jiaxun Cui,Yuqian Jiang,Zhihan Wang,Anastasiia Brund,Joydeep Biswas,Peter Stone*

Main category: cs.RO

TL;DR: 本文提出了一种基于强化学习的系统，使仿人机器人能够在感知不确定的情况下执行稳健的连续踢球动作。该系统通过四阶段训练框架（包括教师策略训练和学生策略蒸馏）结合定制奖励函数和噪声建模，有效缩小了仿真到现实的差距。


<details>
  <summary>Details</summary>
Motivation: 仿人机器人踢球需要快速腿部摆动、单脚支撑稳定性以及在噪声感知和外部干扰下的鲁棒性，这是一个具有挑战性的问题。现有方法在感知不确定性和适应性方面存在不足。

Method: 采用四阶段教师-学生训练框架：1）长距离追球（教师）；2）定向踢球（教师）；3）教师策略蒸馏（学生）；4）学生适应与精炼。关键设计包括定制奖励函数、真实噪声建模和在线约束强化学习。

Result: 在仿真和真实机器人上的广泛评估显示，该系统在不同球门配置下具有强健的踢球准确性和进球成功率。消融研究验证了约束强化学习、噪声建模和适应阶段的必要性。

Conclusion: 该工作为在感知不完善条件下学习稳健的连续仿人踢球技能提供了一个系统方案，为仿人全身控制的视觉运动技能学习建立了基准任务。

Abstract: Learning fast and robust ball-kicking skills is a critical capability for humanoid soccer robots, yet it remains a challenging problem due to the need for rapid leg swings, postural stability on a single support foot, and robustness under noisy sensory input and external perturbations (e.g., opponents). This paper presents a reinforcement learning (RL)-based system that enables humanoid robots to execute robust continual ball-kicking with adaptability to different ball-goal configurations. The system extends a typical teacher-student training framework -- in which a "teacher" policy is trained with ground truth state information and the "student" learns to mimic it with noisy, imperfect sensing -- by including four training stages: (1) long-distance ball chasing (teacher); (2) directional kicking (teacher); (3) teacher policy distillation (student); and (4) student adaptation and refinement (student). Key design elements -- including tailored reward functions, realistic noise modeling, and online constrained RL for adaptation and refinement -- are critical for closing the sim-to-real gap and sustaining performance under perceptual uncertainty. Extensive evaluations in both simulation and on a real robot demonstrate strong kicking accuracy and goal-scoring success across diverse ball-goal configurations. Ablation studies further highlight the necessity of the constrained RL, noise modeling, and the adaptation stage. This work presents a system for learning robust continual humanoid ball-kicking under imperfect perception, establishing a benchmark task for visuomotor skill learning in humanoid whole-body control.

</details>


### [245] [Error-Centric PID Untrained Neural-Net (EC-PIDUNN) For Nonlinear Robotics Control](https://arxiv.org/abs/2512.06578)
*Waleed Razzaq*

Main category: cs.RO

TL;DR: 提出EC-PIDUNN架构，将未经训练的神经网络与改进的PID控制器结合，通过稳定因子τ生成控制信号，在非线性机器人系统中优于经典PID控制。


<details>
  <summary>Details</summary>
Motivation: 经典PID控制难以处理非线性动态和复杂互联变量的挑战，而现有的PIDNN模型需要大量精炼训练数据且计算成本高，不适合实际应用。

Method: EC-PIDUNN架构使用稳态误差e_t作为输入，无需系统动态知识；通过神经网络增加输入维度，引入参数向量ρ_t和动态计算函数调整PID系数。

Result: 在非线性无人地面车辆系统（阿克曼转向机制和运动学控制）和云台运动系统的测试中，EC-PIDUNN在收敛性和稳定性方面优于经典PID，实现接近临界阻尼响应。

Conclusion: EC-PIDUNN架构有效解决了非线性系统的控制挑战，无需大量训练数据，在实际机器人应用中表现出色。

Abstract: Classical Proportional-Integral-Derivative (PID) control has been widely successful across various industrial systems such as chemical processes, robotics, and power systems. However, as these systems evolved, the increase in the nonlinear dynamics and the complexity of interconnected variables have posed challenges that classical PID cannot effectively handle, often leading to instability, overshooting, or prolonged settling times. Researchers have proposed PIDNN models that combine the function approximation capabilities of neural networks with PID control to tackle these nonlinear challenges. However, these models require extensive, highly refined training data and have significant computational costs, making them less favorable for real-world applications. In this paper, We propose a novel EC-PIDUNN architecture, which integrates an untrained neural network with an improved PID controller, incorporating a stabilizing factor (\(τ\)) to generate the control signal. Like classical PID, our architecture uses the steady-state error \(e_t\) as input bypassing the need for explicit knowledge of the systems dynamics. By forming an input vector from \(e_t\) within the neural network, we increase the dimensionality of input allowing for richer data representation. Additionally, we introduce a vector of parameters \( ρ_t \) to shape the output trajectory and a \textit{dynamic compute} function to adjust the PID coefficients from predefined values. We validate the effectiveness of EC-PIDUNN on multiple nonlinear robotics applications: (1) nonlinear unmanned ground vehicle systems that represent the Ackermann steering mechanism and kinematics control, (2) Pan-Tilt movement system. In both tests, it outperforms classical PID in convergence and stability achieving a nearly critically damped response.

</details>


### [246] [A New Trajectory-Oriented Approach to Enhancing Comprehensive Crowd Navigation Performance](https://arxiv.org/abs/2512.06608)
*Xinyu Zhou,Songhao Piao,Chao Gao,Liguo Chen*

Main category: cs.RO

TL;DR: 本文提出了一种统一的框架，用于公平评估人群导航方法，并通过新颖的奖励塑造策略优化轨迹曲率，显著提升了轨迹质量和适应性。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度强化学习的人群导航研究存在两个主要问题：1）缺乏对评估指标相对优先级的充分分析，导致对不同目标方法的评估不公平；2）很少考虑轨迹连续性指标（特别是需要C²平滑度的指标），现有方法通常只关注效率和近端舒适度。

Method: 提出一个统一框架来公平透明地评估导航方法，同时提出一种新颖的奖励塑造策略，明确强调轨迹曲率优化。通过2D和3D实验验证方法有效性。

Result: 实验结果表明，所提出的方法在多尺度场景下显著提升了轨迹质量和适应性，相比现有最先进方法取得了更优越的性能。

Conclusion: 该研究为解决人群导航中评估不公平和轨迹优化不足的问题提供了有效解决方案，通过统一的评估框架和曲率优化策略，实现了更自然、舒适和节能的导航系统。

Abstract: Crowd navigation has garnered considerable research interest in recent years, especially with the proliferating application of deep reinforcement learning (DRL) techniques. Many studies, however, do not sufficiently analyze the relative priorities among evaluation metrics, which compromises the fair assessment of methods with divergent objectives. Furthermore, trajectory-continuity metrics, specifically those requiring $C^2$ smoothness, are rarely incorporated. Current DRL approaches generally prioritize efficiency and proximal comfort, often neglecting trajectory optimization or addressing it only through simplistic, unvalidated smoothness reward. Nevertheless, effective trajectory optimization is essential to ensure naturalness, enhance comfort, and maximize the energy efficiency of any navigation system. To address these gaps, this paper proposes a unified framework that enables the fair and transparent assessment of navigation methods by examining the prioritization and joint evaluation of multiple optimization objectives. We further propose a novel reward-shaping strategy that explicitly emphasizes trajectory-curvature optimization. The resulting trajectory quality and adaptability are significantly enhanced across multi-scale scenarios. Through extensive 2D and 3D experiments, we demonstrate that the proposed method achieves superior performance compared to state-of-the-art approaches.

</details>


### [247] [Robust Optimization-based Autonomous Dynamic Soaring with a Fixed-Wing UAV](https://arxiv.org/abs/2512.06610)
*Marvin Harms,Jaeyoung Lim,David Rohr,Friedrich Rockenbauer,Nicholas Lawrance,Roland Siegwart*

Main category: cs.RO

TL;DR: 该论文提出了一个用于固定翼无人机自主动态翱翔的框架，利用风场显式表示和经典制导控制方法，通过构建鲁棒参考路径和路径跟踪控制器实现风场估计误差下的稳健飞行。


<details>
  <summary>Details</summary>
Motivation: 动态翱翔是一种利用风切变层能量的飞行技术，可以实现无内部能源的无限飞行。研究目标是开发能够实现自主动态翱翔的框架，解决风场估计误差和实际飞行中的鲁棒性问题。

Method: 采用风场显式表示和经典制导控制方法，构建点对点鲁棒参考路径，开发鲁棒路径跟踪控制器，并在仿真和真实飞行测试中验证框架性能。

Result: 仿真结果显示在多种风况、估计误差和干扰下都能实现稳健的动态翱翔飞行。真实飞行测试进一步验证了能量预测和路径跟踪鲁棒性等关键组件，表明仿真与实际飞行之间的差距很小。

Conclusion: 研究结果强有力地表明所提出的框架能够在风切变中实现自主动态翱翔飞行，为无能源限制的无人机飞行提供了可行方案。

Abstract: Dynamic soaring is a flying technique to exploit the energy available in wind shear layers, enabling potentially unlimited flight without the need for internal energy sources. We propose a framework for autonomous dynamic soaring with a fixed-wing unmanned aerial vehicle (UAV). The framework makes use of an explicit representation of the wind field and a classical approach for guidance and control of the UAV. Robustness to wind field estimation error is achieved by constructing point-wise robust reference paths for dynamic soaring and the development of a robust path following controller for the fixed-wing UAV. The framework is evaluated in dynamic soaring scenarios in simulation and real flight tests. In simulation, we demonstrate robust dynamic soaring flight subject to varied wind conditions, estimation errors and disturbances. Critical components of the framework, including energy predictions and path-following robustness, are further validated in real flights to assure small sim-to-real gap. Together, our results strongly indicate the ability of the proposed framework to achieve autonomous dynamic soaring flight in wind shear.

</details>


### [248] [MIND-V: Hierarchical Video Generation for Long-Horizon Robotic Manipulation with RL-based Physical Alignment](https://arxiv.org/abs/2512.06628)
*Ruicheng Zhang,Mingyang Zhang,Jun Zhou,Zhangrui Guo,Xiaofan Liu,Zunnan Xu,Zhizhou Zhong,Puxin Yan,Haocheng Luo,Xiu Li*

Main category: cs.RO

TL;DR: MIND-V是一个分层框架，用于生成长时程机器人操作视频，通过语义推理、行为语义桥和运动视频生成器实现物理合理且逻辑连贯的视频合成，并采用GRPO强化学习后训练和物理预见一致性奖励来增强物理合理性。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型在机器人操作领域只能合成简单动作的短视频，且依赖手动定义轨迹，缺乏多样性和长时程数据。

Method: MIND-V包含三个核心组件：语义推理枢纽（SRH）用于任务规划，行为语义桥（BSB）将抽象指令转换为领域不变表示，运动视频生成器（MVG）用于条件视频渲染。采用分阶段视觉未来滚动策略和GRPO强化学习后训练，通过物理预见一致性（PFC）奖励确保物理合理性。

Result: MIND-V在长时程机器人操作视频生成中表现出最先进的性能，建立了可扩展和可控的具身数据合成范式。

Conclusion: MIND-V通过分层框架和物理合理性增强机制，有效解决了长时程机器人操作视频生成的挑战，为具身数据合成提供了新的解决方案。

Abstract: Embodied imitation learning is constrained by the scarcity of diverse, long-horizon robotic manipulation data. Existing video generation models for this domain are limited to synthesizing short clips of simple actions and often rely on manually defined trajectories. To this end, we introduce MIND-V, a hierarchical framework designed to synthesize physically plausible and logically coherent videos of long-horizon robotic manipulation. Inspired by cognitive science, MIND-V bridges high-level reasoning with pixel-level synthesis through three core components: a Semantic Reasoning Hub (SRH) that leverages a pre-trained vision-language model for task planning; a Behavioral Semantic Bridge (BSB) that translates abstract instructions into domain-invariant representations; and a Motor Video Generator (MVG) for conditional video rendering. MIND-V employs Staged Visual Future Rollouts, a test-time optimization strategy to enhance long-horizon robustness. To align the generated videos with physical laws, we introduce a GRPO reinforcement learning post-training phase guided by a novel Physical Foresight Coherence (PFC) reward. PFC leverages the V-JEPA world model to enforce physical plausibility by aligning the predicted and actual dynamic evolutions in the feature space. MIND-V demonstrates state-of-the-art performance in long-horizon robotic manipulation video generation, establishing a scalable and controllable paradigm for embodied data synthesis.

</details>


### [249] [Statistic-Augmented, Decoupled MoE Routing and Aggregating in Autonomous Driving](https://arxiv.org/abs/2512.06664)
*Wei-Bin Kou,Guangxu Zhu,Jingreng Lei,Chen Zhang,Yik-Chung Wu,Jianping Wang*

Main category: cs.RO

TL;DR: 本文提出了一种基于大模型的统计增强解耦MoE路由与聚合机制（MoE-RAM），用于解决自动驾驶场景中单一模型难以覆盖所有复杂条件的问题。通过统计检索增强专家路由，并基于统计距离自适应重加权专家聚合，显著提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶场景复杂多样，单一深度学习模型难以有效覆盖所有可能条件（如不同天气、交通密度和道路类型）。MoE范式通过动态选择专家来适应不同场景，但存在路由策略不精确和专家聚合效率低的问题。

Method: 提出MoE-RAM机制：1）使用统计检索机制增强专家路由，将大模型提取的潜在特征与缓存的专家原型特征进行匹配；2）通过测量专家即时特征与大模型提取潜在特征之间的统计距离，自适应重加权专家输出融合。

Result: 在自动驾驶语义分割任务上的大量实验表明，MoE-RAM相比其他MoE基线和传统单模型方法具有优越性，显著提升了预测性能。

Conclusion: MoE-RAM通过统计增强的路由和聚合机制，有效解决了MoE中的专家选择和聚合问题，为复杂自动驾驶场景提供了更可靠的解决方案。

Abstract: Autonomous driving (AD) scenarios are inherently complex and diverse, posing significant challenges for a single deep learning model to effectively cover all possible conditions, such as varying weather, traffic densities, and road types. Large Model (LM)-Driven Mixture of Experts (MoE) paradigm offers a promising solution, where LM serves as the backbone to extract latent features while MoE serves as the downstream head to dynamically select and aggregate specialized experts to adapt to different scenarios. However, routing and aggregating in MoE face intrinsic challenges, including imprecise expert selection due to flawed routing strategy and inefficient expert aggregation leading to suboptimal prediction. To address these issues, we propose a statistic-augmented, decoupled MoE }outing and Aggregating Mechanism (MoE-RAM) driven by LM. Specifically, on the one hand, MoE-RAM enhances expert routing by incorporating statistical retrieval mechanism to match LM-extracted latent features with cached prototypical features of the most relevant experts; on the other hand, MoE-RAM adaptively reweights experts' outputs in fusion by measuring statistical distances of experts' instant features against LM-extracted latent features. Benefiting from the synergy of the statistic-augmented MoE's routing and aggregating, MoE-RAM ultimately improves the prediction performance. We take the AD semantic segmentation task as an example to assess the proposed MoE-RAM. Extensive experiments on AD datasets demonstrate the superiority of MoE-RAM compared to other MoE baselines and conventional single-model approaches.

</details>


### [250] [FedDSR: Federated Deep Supervision and Regularization Towards Autonomous Driving](https://arxiv.org/abs/2512.06676)
*Wei-Bin Kou,Guangxu Zhu,Bingyang Cheng,Chen Zhang,Yik-Chung Wu,Jianping Wang*

Main category: cs.RO

TL;DR: FedDSR是一种针对自动驾驶联邦学习的新范式，通过中间层监督和正则化解决非IID数据导致的泛化差和收敛慢问题，在语义分割任务中显著提升性能并减少训练轮次。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在自动驾驶中面临非IID数据导致的模型泛化能力差和收敛速度慢的问题，需要新的方法来提升分布式训练效果。

Method: 提出FedDSR框架，包括：1）基于架构无关标准选择多个中间层；2）在选定层计算互信息和负熵作为中间损失和正则项；3）与输出层损失结合形成统一优化目标；4）在中央服务器聚合各车辆模型。

Result: 实验表明FedDSR在语义分割任务中相比其他联邦学习基线方法，mIoU提升最高达8.93%，训练轮次减少28.57%。

Conclusion: FedDSR通过中间层监督和正则化有效提升了联邦自动驾驶模型的泛化能力和收敛速度，适合实际部署应用。

Abstract: Federated Learning (FL) enables collaborative training of autonomous driving (AD) models across distributed vehicles while preserving data privacy. However, FL encounters critical challenges such as poor generalization and slow convergence due to non-independent and identically distributed (non-IID) data from diverse driving environments. To overcome these obstacles, we introduce Federated Deep Supervision and Regularization (FedDSR), a paradigm that incorporates multi-access intermediate layer supervision and regularization within federated AD system. Specifically, FedDSR comprises following integral strategies: (I) to select multiple intermediate layers based on predefined architecture-agnostic standards. (II) to compute mutual information (MI) and negative entropy (NE) on those selected layers to serve as intermediate loss and regularizer. These terms are integrated into the output-layer loss to form a unified optimization objective, enabling comprehensive optimization across the network hierarchy. (III) to aggregate models from vehicles trained based on aforementioned rules of (I) and (II) to generate the global model on central server. By guiding and penalizing the learning of feature representations at intermediate stages, FedDSR enhances the model generalization and accelerates model convergence for federated AD. We then take the semantic segmentation task as an example to assess FedDSR and apply FedDSR to multiple model architectures and FL algorithms. Extensive experiments demonstrate that FedDSR achieves up to 8.93% improvement in mIoU and 28.57% reduction in training rounds, compared to other FL baselines, making it highly suitable for practical deployment in federated AD ecosystems.

</details>


### [251] [Model-Less Feedback Control of Space-based Continuum Manipulators using Backbone Tension Optimization](https://arxiv.org/abs/2512.06754)
*Shrreya Rajneesh,Nikita Pavle,Rakesh Kumar Sahoo,Manoranjan Sinha*

Main category: cs.RO

TL;DR: 本文提出了一种无模型的连续体机械臂控制框架，通过经验初始化雅可比矩阵并在线优化，避免了传统模型依赖方法的局限性，实现了亚毫米级的稳态精度。


<details>
  <summary>Details</summary>
Motivation: 连续体机械臂的无限维变形、未建模内部摩擦和配置相关刚度等特性限制了基于模型的控制方法的可靠性，导致雅可比预测不准确、人为奇点和不稳定驱动行为。

Method: 使用经验初始化的雅可比矩阵，通过差分凸更新在线优化；采用实时二次规划计算驱动器增量，同时确保肌腱松弛避免和几何限制；引入背骨张力优化项来调节轴向载荷并抑制共激活压缩。

Result: 在圆形、五边形和方形轨迹上的验证表明，该方法实现了平滑收敛、稳定的张力演变和亚毫米级稳态精度，无需任何模型校准或参数识别。

Conclusion: 该控制器为受限环境中的连续体操作提供了一个可扩展的模型依赖替代方案。

Abstract: Continuum manipulators offer intrinsic dexterity and safe geometric compliance for navigation within confined and obstacle-rich environments. However, their infinite-dimensional backbone deformation, unmodeled internal friction, and configuration-dependent stiffness fundamentally limit the reliability of model-based kinematic formulations, resulting in inaccurate Jacobian predictions, artificial singularities, and unstable actuation behavior. Motivated by these limitations, this work presents a complete model-less control framework that bypasses kinematic modeling by using an empirically initialized Jacobian refined online through differential convex updates. Tip motion is generated via a real-time quadratic program that computes actuator increments while enforcing tendon slack avoidance and geometric limits. A backbone tension optimization term is introduced in this paper to regulate axial loading and suppress co-activation compression. The framework is validated across circular, pentagonal, and square trajectories, demonstrating smooth convergence, stable tension evolution, and sub-millimeter steady-state accuracy without any model calibration or parameter identification. These results establish the proposed controller as a scalable alternative to model-dependent continuum manipulation in a constrained environment.

</details>


### [252] [db-LaCAM: Fast and Scalable Multi-Robot Kinodynamic Motion Planning with Discontinuity-Bounded Search and Lightweight MAPF](https://arxiv.org/abs/2512.06796)
*Akmaral Moldagalieva,Keisuke Okumura,Amanda Prorok,Wolfgang Hönig*

Main category: cs.RO

TL;DR: db-LaCAM结合MAPF算法的可扩展性和动力学规划器的动态感知能力，通过预计算运动基元和使用用户定义的不连续性，实现了对50个机器人的高效运动规划，运行速度提升10倍。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的多机器人动力学运动规划器由于计算负担高，难以处理超过几个机器人的情况，限制了可扩展性并导致规划时间缓慢。

Method: 提出discontinuity-Bounded LaCAM (db-LaCAM)，利用预计算的尊重机器人动力学的运动基元生成视界长度运动序列，同时允许连续运动之间存在用户定义的不连续性。

Result: db-LaCAM可高效扩展到50个机器人场景，运行时间比最先进规划器快10倍，同时保持相当的解决方案质量。在2D和3D环境中验证了单轮车和3D双积分器等动力学模型。

Conclusion: db-LaCAM在物理实验中成功验证了飞行机器人和带拖车汽车机器人的轨迹安全执行，证明了方法的实用性和有效性。

Abstract: State-of-the-art multi-robot kinodynamic motion planners struggle to handle more than a few robots due to high computational burden, which limits their scalability and results in slow planning time.
  In this work, we combine the scalability and speed of modern multi-agent path finding (MAPF) algorithms with the dynamic-awareness of kinodynamic planners to address these limitations.
  To this end, we propose discontinuity-Bounded LaCAM (db-LaCAM), a planner that utilizes a precomputed set of motion primitives that respect robot dynamics to generate horizon-length motion sequences, while allowing a user-defined discontinuity between successive motions.
  The planner db-LaCAM is resolution-complete with respect to motion primitives and supports arbitrary robot dynamics.
  Extensive experiments demonstrate that db-LaCAM scales efficiently to scenarios with up to 50 robots, achieving up to ten times faster runtime compared to state-of-the-art planners, while maintaining comparable solution quality.
  The approach is validated in both 2D and 3D environments with dynamics such as the unicycle and 3D double integrator.
  We demonstrate the safe execution of trajectories planned with db-LaCAM in two distinct physical experiments involving teams of flying robots and car-with-trailer robots.

</details>


### [253] [MagicSkin: Balancing Marker and Markerless Modes in Vision-Based Tactile Sensors with a Translucent Skin](https://arxiv.org/abs/2512.06829)
*Oluwatimilehin Tijani,Zhuo Chen,Jiankang Deng,Shan Luo*

Main category: cs.RO

TL;DR: MagicSkin是一种新型触觉皮肤，采用半透明着色标记，在标记和无标记设计之间取得平衡，能够同时实现切向位移跟踪、力预测和表面细节保留，无需额外硬件或软件工具。


<details>
  <summary>Details</summary>
Motivation: 解决视觉触觉传感器中标记和无标记设计的根本权衡问题：不透明墨水标记能测量力和切向位移但完全遮挡几何特征，而无标记皮肤保留表面细节但难以有效测量切向位移。

Method: 开发MagicSkin触觉皮肤，使用半透明着色标记，可直接插入GelSight系列传感器，无需额外硬件或软件。

Result: 在物体分类（99.17%）、纹理分类（93.51%）、切向位移跟踪（97%点保留）和力预测（总力误差改善66%）方面均取得最佳性能。

Conclusion: 半透明皮肤消除了标记或无标记模式的传统性能权衡，为触觉机器人所需的多模态触觉感知铺平了道路。

Abstract: Vision-based tactile sensors (VBTS) face a fundamental trade-off in marker and markerless design on the tactile skin: opaque ink markers enable measurement of force and tangential displacement but completely occlude geometric features necessary for object and texture classification, while markerless skin preserves surface details but struggles in measuring tangential displacements effectively. Current practice to solve the above problem via UV lighting or virtual transfer using learning-based models introduces hardware complexity or computing burdens. This paper introduces MagicSkin, a novel tactile skin with translucent, tinted markers balancing the modes of marker and markerless for VBTS. It enables simultaneous tangential displacement tracking, force prediction, and surface detail preservation. This skin is easy to plug into GelSight-family sensors without requiring additional hardware or software tools. We comprehensively evaluate MagicSkin in downstream tasks. The translucent markers impressively enhance rather than degrade sensing performance compared with traditional markerless and inked marker design: it achieves best performance in object classification (99.17\%), texture classification (93.51\%), tangential displacement tracking (97\% point retention) and force prediction (66\% improvement in total force error). These experimental results demonstrate that translucent skin eliminates the traditional performance trade-off in marker or markerless modes, paving the way for multimodal tactile sensing essential in tactile robotics. See videos at this \href{https://zhuochenn.github.io/MagicSkin_project/}{link}.

</details>


### [254] [Dynamic Visual SLAM using a General 3D Prior](https://arxiv.org/abs/2512.06868)
*Xingguang Zhong,Liren Jin,Marija Popović,Jens Behley,Cyrill Stachniss*

Main category: cs.RO

TL;DR: 提出了一种新颖的单目视觉SLAM系统，能够在动态场景中鲁棒地估计相机位姿，通过结合几何补丁的在线束调整和前馈重建模型来过滤动态区域并增强SLAM的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在动态自然环境中，场景动态会严重影响相机位姿估计的准确性，而可靠的增量式相机位姿估计和3D重建对于机器人技术、交互式可视化和增强现实等应用至关重要。

Method: 利用几何补丁的在线束调整和前馈重建模型的互补优势，提出前馈重建模型精确过滤动态区域，同时利用其深度预测增强基于补丁的视觉SLAM的鲁棒性。通过将深度预测与束调整估计的补丁对齐，鲁棒处理前馈重建模型批量应用的固有尺度模糊性。

Result: 系统能够在动态场景中实现鲁棒的相机位姿估计，有效处理场景动态带来的挑战。

Conclusion: 该方法通过结合几何方法和深度学习模型，成功解决了动态环境中视觉SLAM的鲁棒性问题，为相关应用提供了可靠的技术支持。

Abstract: Reliable incremental estimation of camera poses and 3D reconstruction is key to enable various applications including robotics, interactive visualization, and augmented reality. However, this task is particularly challenging in dynamic natural environments, where scene dynamics can severely deteriorate camera pose estimation accuracy. In this work, we propose a novel monocular visual SLAM system that can robustly estimate camera poses in dynamic scenes. To this end, we leverage the complementary strengths of geometric patch-based online bundle adjustment and recent feed-forward reconstruction models. Specifically, we propose a feed-forward reconstruction model to precisely filter out dynamic regions, while also utilizing its depth prediction to enhance the robustness of the patch-based visual SLAM. By aligning depth prediction with estimated patches from bundle adjustment, we robustly handle the inherent scale ambiguities of the batch-wise application of the feed-forward reconstruction model.

</details>


### [255] [From Zero to High-Speed Racing: An Autonomous Racing Stack](https://arxiv.org/abs/2512.06892)
*Hassan Jardali,Durgakant Pushp,Youwei Yu,Mahmoud Ali,Ihab S. Mohamed,Alejandro Murillo-Gonzalez,Paul D. Coen,Md. Al-Masrur Khan,Reddy Charan Pulivendula,Saeoul Park,Lingchuan Zhou,Lantao Liu*

Main category: cs.RO

TL;DR: 本文介绍了自主赛车堆栈（ARS）的开发，该堆栈在椭圆赛道和公路赛道上实现了高达260公里/小时的速度，并发布了高速多传感器数据集。


<details>
  <summary>Details</summary>
Motivation: 高速、头对头自主赛车面临精确定位、快速感知、动态规划和实时控制等技术挑战，且受限于赛道访问和昂贵硬件。

Method: 开发了三个版本的自主赛车堆栈（ARS1、ARS2、ARS3），采用模块化架构，并在不同赛道上进行验证。

Result: ARS在椭圆赛道和公路赛道上实现了高达260公里/小时的速度，并进行了控制、感知和估计的性能评估。

Conclusion: 研究揭示了真实世界高速全尺寸自主赛车的独特挑战和见解，并发布了相关数据集。

Abstract: High-speed, head-to-head autonomous racing presents substantial technical and logistical challenges, including precise localization, rapid perception, dynamic planning, and real-time control-compounded by limited track access and costly hardware. This paper introduces the Autonomous Race Stack (ARS), developed by the IU Luddy Autonomous Racing team for the Indy Autonomous Challenge (IAC). We present three iterations of our ARS, each validated on different tracks and achieving speeds up to 260 km/h. Our contributions include: (i) the modular architecture and evolution of the ARS across ARS1, ARS2, and ARS3; (ii) a detailed performance evaluation that contrasts control, perception, and estimation across oval and road-course environments; and (iii) the release of a high-speed, multi-sensor dataset collected from oval and road-course tracks. Our findings highlight the unique challenges and insights from real-world high-speed full-scale autonomous racing.

</details>


### [256] [Control of Powered Ankle-Foot Prostheses on Compliant Terrain: A Quantitative Approach to Stability Enhancement](https://arxiv.org/abs/2512.06896)
*Chrysostomos Karakasis,Camryn Scully,Robert Salati,Panagiotis Artemiadis*

Main category: cs.RO

TL;DR: 该研究验证了一种基于导纳的控制策略，通过动态调整动力假肢的准刚度来增强在柔顺地面上的步态稳定性，相比传统刚性地面控制器能显著改善步态稳定性并降低跌倒风险。


<details>
  <summary>Details</summary>
Motivation: 下肢截肢者在柔顺地形上行走时跌倒风险极高，而现有动力踝足假肢的控制策略主要针对刚性地面优化，对软质或柔顺表面的适应性研究不足。

Method: 采用基于导纳的控制策略动态调整动力假肢的准刚度，通过人体实验在两种刚度值（63和25 kN/m）的双侧柔顺表面上进行验证，使用相图和两种步态稳定性指标量化控制器性能。

Result: 与针对刚性地面设计的标准相位变量控制器相比，所提出的导纳控制器在所有柔顺条件下都能一致地改善步态稳定性。

Conclusion: 研究证明了自适应、关注稳定性的假肢控制在降低现实环境中跌倒风险方面的潜力，有助于提升康复机器人中人-假肢交互的鲁棒性。

Abstract: Walking on compliant terrain presents a substantial challenge for individuals with lower-limb amputation, further elevating their already high risk of falling. While powered ankle-foot prostheses have demonstrated adaptability across speeds and rigid terrains, control strategies optimized for soft or compliant surfaces remain underexplored. This work experimentally validates an admittance-based control strategy that dynamically adjusts the quasi-stiffness of powered prostheses to enhance gait stability on compliant ground. Human subject experiments were conducted with three healthy individuals walking on two bilaterally compliant surfaces with ground stiffness values of 63 and 25 kN/m, representative of real-world soft environments. Controller performance was quantified using phase portraits and two walking stability metrics, offering a direct assessment of fall risk. Compared to a standard phase-variable controller developed for rigid terrain, the proposed admittance controller consistently improved gait stability across all compliant conditions. These results demonstrate the potential of adaptive, stability-aware prosthesis control to reduce fall risk in real-world environments and advance the robustness of human-prosthesis interaction in rehabilitation robotics.

</details>


### [257] [Ground Compliance Improves Retention of Visual Feedback-Based Propulsion Training for Gait Rehabilitation](https://arxiv.org/abs/2512.06897)
*Bradley Hobbs,Panagiotis Artemiadis*

Main category: cs.RO

TL;DR: 研究表明，在视觉反馈步态训练中加入地面顺应性比单独使用视觉反馈更能有效增加推离力，对步态康复有积极影响。


<details>
  <summary>Details</summary>
Motivation: 探究视觉反馈与地面顺应性结合是否能更有效地增强推离力，为步态康复（如中风后患者）提供更有效的训练方法。

Method: 10名健康参与者在定制分带跑步机上行走，所有参与者接受实时地面反作用力视觉反馈，其中一组还体验地面顺应性变化，对照组仅接受视觉反馈。

Result: 体验地面顺应性的组别成功实现并维持了推离力的增加，且在肌肉活动和关节运动学上表现出持久的后效，表明更稳健的自然推进策略学习。

Conclusion: 视觉与本体感觉系统在步态适应中协同工作，结合地面顺应性与视觉反馈可增强推进力学习，支持在长期康复中应用顺应性地面训练推进力缺陷。

Abstract: This study investigates whether adding ground compliance to visual feedback (VF) gait training is more effective at increasing push-off force (POF) compared to using VF alone, with implications for gait rehabilitation. Ten healthy participants walked on a custom split-belt treadmill. All participants received real-time visual feedback of their ground reaction forces. One group also experienced changes in ground compliance, while a control group received only visual feedback. Intentional increases in propulsive ground reaction forces (POF) were successfully achieved and sustained post-intervention, especially in the group that experienced ground compliance. This group also demonstrated lasting after-effects in muscle activity and joint kinematics, indicating a more robust learning of natural strategies to increase propulsion. This work demonstrates how visual and proprioceptive systems coordinate during gait adaptation. It uniquely shows that combining ground compliance with visual feedback enhances the learning of propulsive forces, supporting the potential use of compliant terrain in long-term rehabilitation targeting propulsion deficits, such as those following a stroke.

</details>


### [258] [Energy-Efficient Navigation for Surface Vehicles in Vortical Flow Fields](https://arxiv.org/abs/2512.06912)
*Rushiraj Gadhvi,Sandeep Manjanna*

Main category: cs.RO

TL;DR: 本文提出了一种基于强化学习的能量高效水面车辆导航方法，在涡流场中仅使用局部速度测量实现流感知导航，相比现有技术节能30-50%


<details>
  <summary>Details</summary>
Motivation: 模仿khalasi利用洋流导航的直觉，解决自主水面车辆在严格能量预算下长期任务中的能量效率问题，特别是在部分可观测性削弱传统路径规划方法的涡流场中

Method: 基于Soft Actor Critic的端到端强化学习框架，仅使用局部速度测量学习流感知导航策略

Result: 在多样化动态场景中的广泛评估表明，该方法实现了显著的能量节约，并能稳健地泛化到未见过的流条件，导航路径比现有最先进技术节能30-50%

Conclusion: 该方法为海洋环境中的长期自主性提供了一条有前景的路径

Abstract: For centuries, khalasi have skillfully harnessed ocean currents to navigate vast waters with minimal effort. Emulating this intuition in autonomous systems remains a significant challenge, particularly for Autonomous Surface Vehicles tasked with long duration missions under strict energy budgets. In this work, we present a learning-based approach for energy-efficient surface vehicle navigation in vortical flow fields, where partial observability often undermines traditional path-planning methods. We present an end to end reinforcement learning framework based on Soft Actor Critic that learns flow-aware navigation policies using only local velocity measurements. Through extensive evaluation across diverse and dynamically rich scenarios, our method demonstrates substantial energy savings and robust generalization to previously unseen flow conditions, offering a promising path toward long term autonomy in ocean environments. The navigation paths generated by our proposed approach show an improvement in energy conservation 30 to 50 percent compared to the existing state of the art techniques.

</details>


### [259] [Interconnection and Damping Assignment Passivity-Based Control using Sparse Neural ODEs](https://arxiv.org/abs/2512.06935)
*Nicolò Botteghi,Owen Brook,Urban Fasel,Federico Califano*

Main category: cs.RO

TL;DR: 提出了一种基于稀疏字典学习的IDA-PBC控制器数值设计方法，无需精确求解匹配PDEs，使IDA-PBC能够应用于超越稳定的复杂任务。


<details>
  <summary>Details</summary>
Motivation: 传统IDA-PBC方法因需要解析求解复杂的偏微分方程（匹配条件）而难以应用于复杂物理系统和任务，限制了其实际应用范围。

Method: 将IDA-PBC问题转化为神经常微分方程学习问题，使用稀疏字典学习参数化闭环系统，通过多目标优化求解控制器参数。

Result: 数值结果表明该方法能够实现超越稳定的复杂任务（如周期性振荡行为发现），并能导出包含残差项的闭环系统解析表达式。

Conclusion: 所提出的数值方法突破了传统IDA-PBC的局限性，使其能够有效应用于更广泛的复杂控制任务。

Abstract: Interconnection and Damping Assignment Passivity-Based Control (IDA-PBC) is a nonlinear control technique that assigns a port-Hamiltonian (pH) structure to a controlled system using a state-feedback law. While IDA-PBC has been extensively studied and applied to many systems, its practical implementation often remains confined to academic examples and, almost exclusively, to stabilization tasks. The main limitation of IDA-PBC stems from the complexity of analytically solving a set of partial differential equations (PDEs), referred to as the matching conditions, which enforce the pH structure of the closed-loop system. However, this is extremely challenging, especially for complex physical systems and tasks.
  In this work, we propose a novel numerical approach for designing IDA-PBC controllers without solving the matching PDEs exactly. We cast the IDA-PBC problem as the learning of a neural ordinary differential equation. In particular, we rely on sparse dictionary learning to parametrize the desired closed-loop system as a sparse linear combination of nonlinear state-dependent functions. Optimization of the controller parameters is achieved by solving a multi-objective optimization problem whose cost function is composed of a generic task-dependent cost and a matching condition-dependent cost. Our numerical results show that the proposed method enables (i) IDA-PBC to be applicable to complex tasks beyond stabilization, such as the discovery of periodic oscillatory behaviors, (ii) the derivation of closed-form expressions of the controlled system, including residual terms

</details>


### [260] [Task adaptation of Vision-Language-Action model: 1st Place Solution for the 2025 BEHAVIOR Challenge](https://arxiv.org/abs/2512.06951)
*Ilia Larchenko,Gleb Zarin,Akash Karnatak*

Main category: cs.RO

TL;DR: 本文提出了一个视觉动作策略，在2025年BEHAVIOR挑战赛中获得了第一名，该策略通过相关噪声流匹配、可学习混合层注意力等创新技术，在50个多样化长视野家庭任务中实现了26%的q-score。


<details>
  <summary>Details</summary>
Motivation: 解决复杂家庭环境中长视野任务的需求，这些任务需要双手操作、导航和上下文感知决策能力，特别是在BEHAVIOR挑战赛这样的真实仿真环境中。

Method: 基于Pi0.5架构，引入相关噪声流匹配技术提高训练效率，采用可学习混合层注意力和System 2阶段跟踪来解决歧义问题，使用多样本流匹配减少方差，并在推理时应用动作压缩和挑战特定校正规则。

Result: 在BEHAVIOR挑战赛的50个任务中，在公开和私有排行榜上都达到了26%的q-score，获得了第一名。

Conclusion: 提出的相关噪声流匹配和相关感知修复技术有效提升了动作序列的平滑性，整体方法在复杂家庭任务中表现出色，为长视野机器人任务提供了有效的解决方案。

Abstract: We present a vision-action policy that won 1st place in the 2025 BEHAVIOR Challenge - a large-scale benchmark featuring 50 diverse long-horizon household tasks in photo-realistic simulation, requiring bimanual manipulation, navigation, and context-aware decision making.
  Building on the Pi0.5 architecture, we introduce several innovations. Our primary contribution is correlated noise for flow matching, which improves training efficiency and enables correlation-aware inpainting for smooth action sequences. We also apply learnable mixed-layer attention and System 2 stage tracking for ambiguity resolution. Training employs multi-sample flow matching to reduce variance, while inference uses action compression and challenge-specific correction rules.
  Our approach achieves 26% q-score across all 50 tasks on both public and private leaderboards.

</details>


### [261] [VideoVLA: Video Generators Can Be Generalizable Robot Manipulators](https://arxiv.org/abs/2512.06963)
*Yichao Shen,Fangyun Wei,Zhiying Du,Yaobo Liang,Yan Lu,Jiaolong Yang,Nanning Zheng,Baining Guo*

Main category: cs.RO

TL;DR: VideoVLA是一个将大型视频生成模型转化为机器人操作器的简单方法，通过联合建模视频、语言和动作模态，实现动作序列和未来视觉结果的预测


<details>
  <summary>Details</summary>
Motivation: 解决当前VLA模型在新任务、新物体和新环境中泛化能力有限的问题，探索机器人学习中的范式转变

Method: 基于多模态扩散Transformer，利用预训练视频生成模型进行联合视觉和动作预测，采用双预测策略同时预测动作序列和未来视觉结果

Result: 实验表明高质量的未来视觉想象与可靠的动作预测和任务成功相关，VideoVLA展现出强大的泛化能力，包括模仿其他实施例的技能和处理新物体

Conclusion: 通过预测动作及其视觉后果的双重预测策略，为机器人学习开辟了新范式，解锁了操作系统的泛化能力

Abstract: Generalization in robot manipulation is essential for deploying robots in open-world environments and advancing toward artificial general intelligence. While recent Vision-Language-Action (VLA) models leverage large pre-trained understanding models for perception and instruction following, their ability to generalize to novel tasks, objects, and settings remains limited. In this work, we present VideoVLA, a simple approach that explores the potential of transforming large video generation models into robotic VLA manipulators. Given a language instruction and an image, VideoVLA predicts an action sequence as well as the future visual outcomes. Built on a multi-modal Diffusion Transformer, VideoVLA jointly models video, language, and action modalities, using pre-trained video generative models for joint visual and action forecasting. Our experiments show that high-quality imagined futures correlate with reliable action predictions and task success, highlighting the importance of visual imagination in manipulation. VideoVLA demonstrates strong generalization, including imitating other embodiments' skills and handling novel objects. This dual-prediction strategy - forecasting both actions and their visual consequences - explores a paradigm shift in robot learning and unlocks generalization capabilities in manipulation systems.

</details>


### [262] [Parametric Design of a Cable-Driven Coaxial Spherical Parallel Mechanism for Ultrasound Scans](https://arxiv.org/abs/2512.06995)
*Maryam Seraj,Mohammad Hossein Kamrava,Carlo Tiseo*

Main category: cs.RO

TL;DR: 本文提出了一种电缆驱动同轴球面并联机构(CDC-SPM)的设计方法和运动学分析，旨在解决医疗遥操作中高保真触觉接口的性能平衡问题。


<details>
  <summary>Details</summary>
Motivation: 医疗遥操作中的触觉接口需要在工作空间、灵活性、刚度、惯性和带宽等性能指标之间取得平衡，特别是在需要纯旋转运动的应用中。传统设计存在惯性负载大、动态响应差等问题。

Method: 采用电缆驱动同轴球面并联机构设计，通过并联和同轴驱动实现解耦的旋转自由度，具有各向同性的力和扭矩传递特性。

Result: 仿真分析表明CDC-SPM能够提供精确、响应迅速且安全的运动特性，适用于高精度触觉应用。

Conclusion: 该机构在医疗遥操作任务（如超声成像）中具有重要应用潜力，能够实现精确直观的操作。

Abstract: Haptic interfaces play a critical role in medical teleoperation by enabling surgeons to interact with remote environments through realistic force and motion feedback. Achieving high fidelity in such systems requires balancing performance trade-off among workspace, dexterity, stiffness, inertia, and bandwidth, particularly in applications demanding pure rotational motion. This paper presents the design methodology and kinematic analysis of a Cable-Driven Coaxial Spherical Parallel Mechanism (CDC-SPM) developed to address these challenges. The proposed cable-driven interface design allows for reducing the mass placed at the robot arm end-effector, thereby minimizing inertial loads, enhancing stiffness, and improving dynamic responsiveness. Through parallel and coaxial actuation, the mechanism achieves decoupled rotational degrees of freedom with isotropic force and torque transmission. Simulation and analysis demonstrate that the CDC-SPM provides accurate, responsive, and safe motion characteristics suitable for high-precision haptic applications. These results highlight the mechanism's potential for medical teleoperation tasks such as ultrasound imaging, where precise and intuitive manipulation is essential.

</details>


### [263] [A Hetero-Associative Sequential Memory Model Utilizing Neuromorphic Signals: Validated on a Mobile Manipulator](https://arxiv.org/abs/2512.07032)
*Runcong Wang,Fengyi Wang,Gordon Cheng*

Main category: cs.RO

TL;DR: 本文提出了一种用于移动机械臂的异质关联顺序记忆系统，通过神经形态绑定学习关节状态与触觉观测之间的紧凑表示，实现低计算和内存成本的分步动作决策。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够在移动机械臂上快速建立、从状态和观测同步流中训练，并保持经济性的记忆系统，实现通过触觉输入控制机器人运动和行为序列。

Method: 使用群体位置编码对关节角度进行编码，通过Izhikevich神经元模型将皮肤测量力转换为脉冲率特征，将两种信号转换为双极二进制向量并进行元素级绑定，存储在大型顺序记忆中。引入3D旋转位置嵌入来改善二进制空间的可分离性。

Result: 在丰田人支持机器人上实现了伪柔顺控制器，使链接在触摸下沿施加力的方向和速度移动，并通过持续触觉输入检索多关节抓取序列。系统展示了通过关联召回执行的单关节和全臂行为。

Conclusion: 该方法为移动机械臂提供了一种经济有效的记忆和学习系统，可扩展到模仿学习、运动规划和多模态集成等应用。

Abstract: This paper presents a hetero-associative sequential memory system for mobile manipulators that learns compact, neuromorphic bindings between robot joint states and tactile observations to produce step-wise action decisions with low compute and memory cost. The method encodes joint angles via population place coding and converts skin-measured forces into spike-rate features using an Izhikevich neuron model; both signals are transformed into bipolar binary vectors and bound element-wise to create associations stored in a large-capacity sequential memory. To improve separability in binary space and inject geometry from touch, we introduce 3D rotary positional embeddings that rotate subspaces as a function of sensed force direction, enabling fuzzy retrieval through a softmax weighted recall over temporally shifted action patterns. On a Toyota Human Support Robot covered by robot skin, the hetero-associative sequential memory system realizes a pseudocompliance controller that moves the link under touch in the direction and with speed correlating to the amplitude of applied force, and it retrieves multi-joint grasp sequences by continuing tactile input. The system sets up quickly, trains from synchronized streams of states and observations, and exhibits a degree of generalization while remaining economical. Results demonstrate single-joint and full-arm behaviors executed via associative recall, and suggest extensions to imitation learning, motion planning, and multi-modal integration.

</details>


### [264] [CERNet: Class-Embedding Predictive-Coding RNN for Unified Robot Motion, Recognition, and Confidence Estimation](https://arxiv.org/abs/2512.07041)
*Hiroki Sawada,Alexandre Pitti,Mathias Quoy*

Main category: cs.RO

TL;DR: 该论文提出了CERNet，一种基于分层预测编码循环神经网络（PC-RNN）的统一模型，通过动态更新的类别嵌入向量实现机器人运动生成、实时意图识别和置信度估计。


<details>
  <summary>Details</summary>
Motivation: 机器人需要同时生成学习到的运动、推断观察到的行为意图，并估计自身推断的置信度。现有方法通常将这些能力分开处理，缺乏统一框架。

Method: 使用分层PC-RNN架构，配备动态更新的类别嵌入向量。模型有两种工作模式：生成模式中嵌入向量约束隐藏状态到类别特定子空间；推理模式中在线优化嵌入向量以最小化预测误差。

Result: 在人形机器人上验证，相比单层基线轨迹再现误差降低76%，在外部扰动下保持运动保真度，在线推断演示轨迹类别的Top-1准确率68%、Top-2准确率81%。内部预测误差自然反映识别置信度。

Conclusion: 该模型在紧凑的PC-RNN框架内集成了鲁棒生成、实时识别和内在不确定性估计，为物理机器人提供了紧凑可扩展的运动记忆方法，在意图敏感的人机协作中具有应用潜力。

Abstract: Robots interacting with humans must not only generate learned movements in real-time, but also infer the intent behind observed behaviors and estimate the confidence of their own inferences. This paper proposes a unified model that achieves all three capabilities within a single hierarchical predictive-coding recurrent neural network (PC-RNN) equipped with a class embedding vector, CERNet, which leverages a dynamically updated class embedding vector to unify motor generation and recognition. The model operates in two modes: generation and inference. In the generation mode, the class embedding constrains the hidden state dynamics to a class-specific subspace; in the inference mode, it is optimized online to minimize prediction error, enabling real-time recognition. Validated on a humanoid robot across 26 kinesthetically taught alphabets, our hierarchical model achieves 76% lower trajectory reproduction error than a parameter-matched single-layer baseline, maintains motion fidelity under external perturbations, and infers the demonstrated trajectory class online with 68% Top-1 and 81% Top-2 accuracy. Furthermore, internal prediction errors naturally reflect the model's confidence in its recognition. This integration of robust generation, real-time recognition, and intrinsic uncertainty estimation within a compact PC-RNN framework offers a compact and extensible approach to motor memory in physical robots, with potential applications in intent-sensitive human-robot collaboration.

</details>


### [265] [A Flexible Funnel-Shaped Robotic Hand with an Integrated Single-Sheet Valve for Milligram-Scale Powder Handling](https://arxiv.org/abs/2512.07091)
*Tomoya Takahashi,Yusaku Nakajima,Cristian Camilo Beltran-Hernandez,Yuki Kuroda,Kazutoshi Tanaka,Masashi Hamaya,Kanta Ono,Yoshitaka Ushiku*

Main category: cs.RO

TL;DR: 该研究提出了一种新型漏斗形柔性机器人手，用于解决毫克级粉末处理的自动化挑战，通过模型预测控制和在线参数识别实现了精确的粉末分配。


<details>
  <summary>Details</summary>
Motivation: 实验室自动化在固态材料发现中具有加速潜力，但毫克级粉末处理因粉末流动复杂性和实验任务多样性而难以完全自动化。

Method: 开发了漏斗形柔性机器人手，结合可控阀门和基于粉末流动模型的反馈控制系统，集成外部天平进行在线参数识别。

Result: 实验显示80%的试验误差在2mg以内，最大误差约20mg（目标范围20mg-3g），相比直接PID控制显著提高了精度和收敛速度。

Conclusion: 该系统展示了高效灵活粉末称重的潜力，具有向更大规模扩展的可行性，适用于广泛的实验室自动化任务。

Abstract: Laboratory Automation (LA) has the potential to accelerate solid-state materials discovery by enabling continuous robotic operation without human intervention. While robotic systems have been developed for tasks such as powder grinding and X-ray diffraction (XRD) analysis, fully automating powder handling at the milligram scale remains a significant challenge due to the complex flow dynamics of powders and the diversity of laboratory tasks. To address this challenge, this study proposes a novel, funnel-shaped, flexible robotic hand that preserves the softness and conical sheet designs in prior work while incorporating a controllable valve at the cone apex to enable precise, incremental dispensing of milligram-scale powder quantities. The hand is integrated with an external balance through a feedback control system based on a model of powder flow and online parameter identification. Experimental evaluations with glass beads, monosodium glutamate, and titanium dioxide demonstrated that 80% of the trials achieved an error within 2 mg, and the maximum error observed was approximately 20 mg across a target range of 20 mg to 3 g. In addition, by incorporating flow prediction models commonly used for hoppers and performing online parameter identification, the system is able to adapt to variations in powder dynamics. Compared to direct PID control, the proposed model-based control significantly improved both accuracy and convergence speed. These results highlight the potential of the proposed system to enable efficient and flexible powder weighing, with scalability toward larger quantities and applicability to a broad range of laboratory automation tasks.

</details>


### [266] [Surrogate compliance modeling enables reinforcement learned locomotion gaits for soft robots](https://arxiv.org/abs/2512.07114)
*Jue Wang,Mingsong Jiang,Luis A. Ramirez,Bilige Yang,Mujun Zhang,Esteban Figueroa,Wenzhong Yan,Rebecca Kramer-Bottiglio*

Main category: cs.RO

TL;DR: 提出了一种替代柔顺性建模方法，通过在刚体模拟器中引入代表软材料变形的间接变量，解决了软体机器人仿真和控制的挑战。


<details>
  <summary>Details</summary>
Motivation: 软体机器人能够适应形态变化，但软体模拟器在精度和计算可行性方面存在限制，而刚体模拟器无法捕捉软材料动力学。

Method: 使用替代柔顺性建模方法，将变形效应表示为有效肢体长度和肢体质心的变化，在刚体模拟器中应用强化学习并随机化这些间接变量。

Result: 在硬质平坦基底上实现了高保真度的仿真到现实性能，在流变复杂地形上实现了稳健但保真度较低的转移。学习到的闭环步态展现出前所未有的陆地机动性，运输成本比开环基线降低了一个数量级。

Conclusion: 该方法成功实现了在刚体模拟器中进行可靠的策略学习，并直接转移到硬件上，在多种自然地形上实现了稳定的多步态运动。

Abstract: Adaptive morphogenetic robots adapt their morphology and control policies to meet changing tasks and environmental conditions. Many such systems leverage soft components, which enable shape morphing but also introduce simulation and control challenges. Soft-body simulators remain limited in accuracy and computational tractability, while rigid-body simulators cannot capture soft-material dynamics. Here, we present a surrogate compliance modeling approach: rather than explicitly modeling soft-body physics, we introduce indirect variables representing soft-material deformation within a rigid-body simulator. We validate this approach using our amphibious robotic turtle, a quadruped with soft morphing limbs designed for multi-environment locomotion. By capturing deformation effects as changes in effective limb length and limb center of mass, and by applying reinforcement learning with extensive randomization of these indirect variables, we achieve reliable policy learning entirely in a rigid-body simulation. The resulting gaits transfer directly to hardware, demonstrating high-fidelity sim-to-real performance on hard, flat substrates and robust, though lower-fidelity, transfer on rheologically complex terrains. The learned closed-loop gaits exhibit unprecedented terrestrial maneuverability and achieve an order-of-magnitude reduction in cost of transport compared to open-loop baselines. Field experiments with the robot further demonstrate stable, multi-gait locomotion across diverse natural terrains, including gravel, grass, and mud.

</details>


### [267] [Mimir: Hierarchical Goal-Driven Diffusion with Uncertainty Propagation for End-to-End Autonomous Driving](https://arxiv.org/abs/2512.07130)
*Zebin Xing,Yupeng Zheng,Qichao Zhang,Zhixing Ding,Pengxuan Yang,Songen Gu,Zhongpu Xia,Dongbin Zhao*

Main category: cs.RO

TL;DR: Mimir是一个新颖的分层双系统框架，通过不确定性估计生成鲁棒轨迹，在自动驾驶基准测试中表现优异


<details>
  <summary>Details</summary>
Motivation: 解决现有端到端自动驾驶方法中高级引导信号不准确和复杂引导模块计算开销大的问题

Method: 使用拉普拉斯分布估计目标点不确定性增强鲁棒性；引入多速率引导机制提前预测扩展目标点提升推理速度

Result: 在Navhard和Navtest基准测试中，驾驶分数EPDMS提升20%，高级模块推理速度提升1.6倍且不损失精度

Conclusion: Mimir框架有效解决了自动驾驶中的不确定性估计和计算效率问题，为自动驾驶系统提供了更可靠的解决方案

Abstract: End-to-end autonomous driving has emerged as a pivotal direction in the field of autonomous systems. Recent works have demonstrated impressive performance by incorporating high-level guidance signals to steer low-level trajectory planners. However, their potential is often constrained by inaccurate high-level guidance and the computational overhead of complex guidance modules. To address these limitations, we propose Mimir, a novel hierarchical dual-system framework capable of generating robust trajectories relying on goal points with uncertainty estimation: (1) Unlike previous approaches that deterministically model, we estimate goal point uncertainty with a Laplace distribution to enhance robustness; (2) To overcome the slow inference speed of the guidance system, we introduce a multi-rate guidance mechanism that predicts extended goal points in advance. Validated on challenging Navhard and Navtest benchmarks, Mimir surpasses previous state-of-the-art methods with a 20% improvement in the driving score EPDMS, while achieving 1.6 times improvement in high-level module inference speed without compromising accuracy. The code and models will be released soon to promote reproducibility and further development. The code is available at https://github.com/ZebinX/Mimir-Uncertainty-Driving

</details>


### [268] [Time-Varying Formation Tracking Control of Wheeled Mobile Robots With Region Constraint: A Generalized Udwadia-Kalaba Framework](https://arxiv.org/abs/2512.07137)
*Kang Yijie,Hao Yuqing,Wang Qingyun,Chen Guanrong*

Main category: cs.RO

TL;DR: 本文研究了具有区域约束的轮式移动机器人时变编队跟踪控制问题，基于广义Udwadia-Kalaba框架设计控制器，确保机器人在指定区域内安全运行。


<details>
  <summary>Details</summary>
Motivation: 现有时变编队跟踪控制研究未考虑区域约束，无法保证机器人在复杂环境中的安全性。本文旨在解决这一关键问题。

Method: 采用广义Udwadia-Kalaba框架，将时变编队跟踪控制目标重构为约束方程，通过微分同胚变换处理区域约束，设计具有区域约束的控制器。

Result: 数值仿真验证了所提控制策略的有效性，控制器能够实现时变编队跟踪同时确保机器人始终在安全区域内运行。

Conclusion: 提出的基于广义Udwadia-Kalaba框架的控制方法成功解决了时变编队跟踪中的区域约束问题，为轮式移动机器人的安全控制提供了有效解决方案。

Abstract: In this paper, the time-varying formation tracking control of wheeled mobile robots with region constraint is investigated from a generalized Udwadia-Kalaba framework. The communication topology is directed, weighted and has a spanning tree with the leader being the root. By reformulating the time-varying formation tracking control objective as a constrained equation and transforming the region constraint by a diffeomorphism, the time-varying formation tracking controller with the region constraint is designed under the generalized Udwadia-Kalaba framework. Compared with the existing works on time-varying formation tracking control, the region constraint is takeninto account in this paper, which ensures the safety of the robots.Finally, some numerical simulations are presented to illustrate the effectiveness of the proposed control strategy.

</details>


### [269] [Using Vision-Language Models as Proxies for Social Intelligence in Human-Robot Interaction](https://arxiv.org/abs/2512.07177)
*Fanjun Bu,Melina Tsai,Audrey Tjokro,Tapomayukh Bhattacharjee,Jorge Ortiz,Wendy Ju*

Main category: cs.RO

TL;DR: 提出一个两阶段管道，利用轻量级感知检测器触发基于视频的视觉语言模型查询，以实现社交响应式机器人行为


<details>
  <summary>Details</summary>
Motivation: 机器人在日常环境中需要根据微妙的非语言线索决定是否与人互动，这些线索难以显式建模

Method: 基于5天Wizard-of-Oz实地部署观察，提出两阶段管道：先使用轻量级感知检测器（注视转移和空间距离）检测关键时刻，再触发视频VLM查询

Result: 在重放的实地互动中评估该管道，比较两种提示策略，证明选择性使用VLM作为社交推理代理可实现社交响应行为

Conclusion: 选择性使用VLM使机器人能够关注人们在真实互动中自然提供的线索，从而采取适当行为

Abstract: Robots operating in everyday environments must often decide when and whether to engage with people, yet such decisions often hinge on subtle nonverbal cues that unfold over time and are difficult to model explicitly. Drawing on a five-day Wizard-of-Oz deployment of a mobile service robot in a university cafe, we analyze how people signal interaction readiness through nonverbal behaviors and how expert wizards use these cues to guide engagement. Motivated by these observations, we propose a two-stage pipeline in which lightweight perceptual detectors (gaze shifts and proxemics) are used to selectively trigger heavier video-based vision-language model (VLM) queries at socially meaningful moments. We evaluate this pipeline on replayed field interactions and compare two prompting strategies. Our findings suggest that selectively using VLMs as proxies for social reasoning enables socially responsive robot behavior, allowing robots to act appropriately by attending to the cues people naturally provide in real-world interactions.

</details>


### [270] [Spatiotemporal Calibration and Ground Truth Estimation for High-Precision SLAM Benchmarking in Extended Reality](https://arxiv.org/abs/2512.07221)
*Zichao Shu,Shitao Bei,Lijun Li,Zetao Chen*

Main category: cs.RO

TL;DR: 本文提出了一种连续时间最大似然估计器，通过整合IMU数据补偿运动捕捉系统的抖动，并采用可变时间同步方法和基于螺旋约束的位姿残差，实现了高精度的SLAM基准测试。


<details>
  <summary>Details</summary>
Motivation: 由于运动捕捉系统在时空标定和固有抖动方面的限制，现有的SLAM基准测试方法无法满足XR应用对旋转误差和帧间抖动等关键指标的精确评估需求。

Method: 提出连续时间最大似然估计器，整合IMU数据补偿MoCap抖动；采用可变时间同步方法和基于螺旋约束的位姿残差进行多传感器时空标定。

Result: 实验结果表明该方法优于现有方法，能够为XR应用中最先进的SLAM算法提供必要的基准测试精度，并对多款领先XR设备和开源SLAM算法进行了验证。

Conclusion: 该方法有效解决了MoCap系统在SLAM基准测试中的精度限制问题，为XR应用提供了可靠的SLAM性能评估工具，代码已开源。

Abstract: Simultaneous localization and mapping (SLAM) plays a fundamental role in extended reality (XR) applications. As the standards for immersion in XR continue to increase, the demands for SLAM benchmarking have become more stringent. Trajectory accuracy is the key metric, and marker-based optical motion capture (MoCap) systems are widely used to generate ground truth (GT) because of their drift-free and relatively accurate measurements. However, the precision of MoCap-based GT is limited by two factors: the spatiotemporal calibration with the device under test (DUT) and the inherent jitter in the MoCap measurements. These limitations hinder accurate SLAM benchmarking, particularly for key metrics like rotation error and inter-frame jitter, which are critical for immersive XR experiences. This paper presents a novel continuous-time maximum likelihood estimator to address these challenges. The proposed method integrates auxiliary inertial measurement unit (IMU) data to compensate for MoCap jitter. Additionally, a variable time synchronization method and a pose residual based on screw congruence constraints are proposed, enabling precise spatiotemporal calibration across multiple sensors and the DUT. Experimental results demonstrate that our approach outperforms existing methods, achieving the precision necessary for comprehensive benchmarking of state-of-the-art SLAM algorithms in XR applications. Furthermore, we thoroughly validate the practicality of our method by benchmarking several leading XR devices and open-source SLAM algorithms. The code is publicly available at https://github.com/ylab-xrpg/xr-hpgt.

</details>


### [271] [SINRL: Socially Integrated Navigation with Reinforcement Learning using Spiking Neural Networks](https://arxiv.org/abs/2512.07266)
*Florian Tretter,Daniel Flögel,Alexandru Vasilache,Max Grobbel,Jürgen Becker,Sören Hohmann*

Main category: cs.RO

TL;DR: 提出了一种混合社会集成DRL方法，结合SNN和ANN，用于机器人社会导航，显著提升性能并降低能耗


<details>
  <summary>Details</summary>
Motivation: 将自主移动机器人集成到人类环境需要类人决策和节能的事件驱动计算，但神经形态方法在DRL导航中应用较少，主要因为训练不稳定

Method: 采用混合社会集成DRL演员-评论家方法，演员使用SNN，评论家使用ANN，并配备神经形态特征提取器捕捉时间人群动态和人机交互

Result: 该方法提高了社会导航性能，并将估计能耗降低了约1.69个数量级

Conclusion: 该混合方法成功解决了神经形态方法在DRL导航中的训练稳定性问题，实现了高效节能的社会导航

Abstract: Integrating autonomous mobile robots into human environments requires human-like decision-making and energy-efficient, event-based computation. Despite progress, neuromorphic methods are rarely applied to Deep Reinforcement Learning (DRL) navigation approaches due to unstable training. We address this gap with a hybrid socially integrated DRL actor-critic approach that combines Spiking Neural Networks (SNNs) in the actor with Artificial Neural Networks (ANNs) in the critic and a neuromorphic feature extractor to capture temporal crowd dynamics and human-robot interactions. Our approach enhances social navigation performance and reduces estimated energy consumption by approximately 1.69 orders of magnitude.

</details>


### [272] [Efficient Computation of a Continuous Topological Model of the Configuration Space of Tethered Mobile Robots](https://arxiv.org/abs/2512.07303)
*Gianpietro Battocletti,Dimitris Boskos,Bart De Schutter*

Main category: cs.RO

TL;DR: 本文提出了一种新的拓扑模型来表示系留机器人的配置空间，通过将配置空间与工作空间的泛覆盖空间联系起来，构建单纯复形模型，显著提升了现有算法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有系留机器人路径规划方法通常依赖离散的配置空间表示，无法同时捕捉绳索的拓扑信息和机器人的连续位置，需要一种更高效的连续模型。

Method: 首先建立系留机器人配置空间与工作空间泛覆盖空间的联系，然后开发算法计算配置空间的单纯复形模型。

Result: 该方法构建模型所需时间仅为传统同伦增强图的几分之一，且模型是连续的，可以使用多种路径规划算法解决系留机器人的路径规划任务。

Conclusion: 提出的拓扑模型在计算效率和连续性方面优于传统方法，为系留机器人的路径规划提供了更有效的解决方案。

Abstract: Despite the attention that the problem of path planning for tethered robots has garnered in the past few decades, the approaches proposed to solve it typically rely on a discrete representation of the configuration space and do not exploit a model that can simultaneously capture the topological information of the tether and the continuous location of the robot. In this work, we explicitly build a topological model of the configuration space of a tethered robot starting from a polygonal representation of the workspace where the robot moves. To do so, we first establish a link between the configuration space of the tethered robot and the universal covering space of the workspace, and then we exploit this link to develop an algorithm to compute a simplicial complex model of the configuration space. We show how this approach improves the performances of existing algorithms that build other types of representations of the configuration space. The proposed model can be computed in a fraction of the time required to build traditional homotopy-augmented graphs, and is continuous, allowing to solve the path planning task for tethered robots using a broad set of path planning algorithms.

</details>


### [273] [Model Predictive Control for Cooperative Docking Between Autonomous Surface Vehicles with Disturbance Rejection](https://arxiv.org/abs/2512.07316)
*Gianpietro Battocletti,Dimitris Boskos,Bart De Schutter*

Main category: cs.RO

TL;DR: 本文提出了一种基于集中式模型预测控制（MPC）的USV-USV协同对接方法，相比传统单边对接方法，能够实现更快更高效的对接效果。


<details>
  <summary>Details</summary>
Motivation: 现有USV对接方法通常将一艘USV视为静止目标，另一艘负责对接，这种单边方法效率较低。本文提出协同对接方法，让两艘USV共同协作完成对接任务。

Method: 采用集中式模型预测控制（MPC）方法解决控制问题，通过预测模型考虑外部干扰（如水流）的影响，确保约束满足和轨迹可行性。

Result: 仿真实验表明，所提出的协同对接方法相比现有方法能够实现更快、更高效的对接效果。

Conclusion: 基于MPC的协同对接方法能够有效处理外部干扰，提高USV对接的效率和性能，特别适用于存在水流等准静态干扰的环境。

Abstract: Uncrewed Surface Vehicles (USVs) are a popular and efficient type of marine craft that find application in a large number of water-based tasks. When multiple USVs operate in the same area, they may be required to dock to each other to perform a shared task. Existing approaches for the docking between autonomous USVs generally consider one USV as a stationary target, while the second one is tasked to reach the required docking pose. In this work, we propose a cooperative approach for USV-USV docking, where two USVs work together to dock at an agreed location. We use a centralized Model Predictive Control (MPC) approach to solve the control problem, obtaining feasible trajectories that also guarantee constraint satisfaction. Owing to its model-based nature, this approach allows the rejection of disturbances, inclusive of exogenous inputs, by anticipating their effect on the USVs through the MPC prediction model. This is particularly effective in case of almost-stationary disturbances such as water currents. In simulations, we demonstrate how the proposed approach allows for a faster and more efficient docking with respect to existing approaches.

</details>


### [274] [Multi-Rigid-Body Approximation of Human Hands with Application to Digital Twin](https://arxiv.org/abs/2512.07359)
*Bin Zhao,Yiwen Lu,Haohua Zhu,Xiao Li,Sheng Yi*

Main category: cs.RO

TL;DR: 提出了一种从光学运动捕捉数据构建个性化多刚体手部模型的方法，通过将MANO模型的SO(3)关节旋转投影到运动学约束的刚体关节上，实现实时物理模拟。


<details>
  <summary>Details</summary>
Motivation: 数字孪生应用中需要平衡解剖保真度和计算效率的人手模拟模型。

Method: 从光学运动捕捉构建个性化MANO模型并转换为URDF表示，针对单自由度关节推导闭式解，针对双自由度关节提出BCH校正迭代方法处理旋转的非交换性。

Result: 数字孪生实验显示亚厘米级重建误差，在多样化操作任务中成功执行抓取。

Conclusion: 该方法能够构建保留真实外观且支持实时物理模拟的多刚体手部近似模型。

Abstract: Human hand simulation plays a critical role in digital twin applications, requiring models that balance anatomical fidelity with computational efficiency. We present a complete pipeline for constructing multi-rigid-body approximations of human hands that preserve realistic appearance while enabling real-time physics simulation. Starting from optical motion capture of a specific human hand, we construct a personalized MANO (Multi-Abstracted hand model with Neural Operations) model and convert it to a URDF (Unified Robot Description Format) representation with anatomically consistent joint axes. The key technical challenge is projecting MANO's unconstrained SO(3) joint rotations onto the kinematically constrained joints of the rigid-body model. We derive closed-form solutions for single degree-of-freedom joints and introduce a Baker-Campbell-Hausdorff (BCH)-corrected iterative method for two degree-of-freedom joints that properly handles the non-commutativity of rotations. We validate our approach through digital twin experiments where reinforcement learning policies control the multi-rigid-body hand to replay captured human demonstrations. Quantitative evaluation shows sub-centimeter reconstruction error and successful grasp execution across diverse manipulation tasks.

</details>


### [275] [ESPADA: Execution Speedup via Semantics Aware Demonstration Data Downsampling for Imitation Learning](https://arxiv.org/abs/2512.07371)
*Byungju Kim,Jinu Pahk,Chungwoo Lee,Jaejoon Kim,Jangha Lee,Theo Taeyeong Kim,Kyuhwan Shim,Jun Ki Lee,Byoung-Tak Zhang*

Main category: cs.RO

TL;DR: ESPADA是一个基于语义和空间感知的框架，通过VLM-LLM管道和3D夹爪-物体关系分割演示，在非关键阶段进行激进下采样，同时保持精度关键阶段，实现约2倍加速而不降低成功率。


<details>
  <summary>Details</summary>
Motivation: 基于行为克隆的视觉运动策略继承了人类演示的缓慢节奏，限制了实际部署。现有加速方法依赖忽略任务语义的统计或启发式线索，无法适应多样化的操作场景。

Method: 使用VLM-LLM管道结合3D夹爪-物体关系分割演示，通过动态时间规整在仅动态特征上传播段标签，实现从单个标注片段到完整数据集的扩展。

Result: 在模拟和真实世界实验中，与ACT和DP基线相比，ESPADA实现了约2倍的加速，同时保持成功率，缩小了人类演示与高效机器人控制之间的差距。

Conclusion: ESPADA提供了一种无需额外数据、架构修改或重新训练的语义感知加速方法，有效提升了基于行为克隆的策略的实际部署效率。

Abstract: Behavior-cloning based visuomotor policies enable precise manipulation but often inherit the slow, cautious tempo of human demonstrations, limiting practical deployment. However, prior studies on acceleration methods mainly rely on statistical or heuristic cues that ignore task semantics and can fail across diverse manipulation settings. We present ESPADA, a semantic and spatially aware framework that segments demonstrations using a VLM-LLM pipeline with 3D gripper-object relations, enabling aggressive downsampling only in non-critical segments while preserving precision-critical phases, without requiring extra data or architectural modifications, or any form of retraining. To scale from a single annotated episode to the full dataset, ESPADA propagates segment labels via Dynamic Time Warping (DTW) on dynamics-only features. Across both simulation and real-world experiments with ACT and DP baselines, ESPADA achieves approximately a 2x speed-up while maintaining success rates, narrowing the gap between human demonstrations and efficient robot control.

</details>


### [276] [Gait-Adaptive Perceptive Humanoid Locomotion with Real-Time Under-Base Terrain Reconstruction](https://arxiv.org/abs/2512.07464)
*Haolin Song,Hongbo Zhu,Tao Yu,Yan Liu,Mingqi Yuan,Wengang Zhou,Hua Chen,Houqiang Li*

Main category: cs.RO

TL;DR: 本文提出了一种融合地形感知、步态调节和全身控制的强化学习框架，用于解决全尺寸人形机器人在复杂地形（如长楼梯）上的可靠运动问题。


<details>
  <summary>Details</summary>
Motivation: 全尺寸人形机器人在复杂地形（如长楼梯）上实现可靠运动仍然具有挑战性，主要问题包括感知受限、地形线索模糊以及步态时序适应性不足，这些因素容易导致单步失误引发失衡。

Method: 框架结合了向下深度摄像头实时生成密集的自我中心高度图，通过紧凑的U-Net网络处理，将感知高度图与本体感觉信息输入统一策略，生成关节命令和全局步进相位信号，实现步态时序和全身姿态的联合适应。采用单阶段连续师生训练方案进行高效策略学习和知识迁移。

Result: 在31自由度、1.65米高的人形机器人上进行实验，在仿真和真实环境中均表现出稳健的运动能力，包括前后上下楼梯以及跨越46厘米间隙。

Conclusion: 该感知运动框架成功实现了人形机器人在复杂地形上的可靠运动，通过融合感知与控制的统一策略解决了传统方法中的步态适应性问题。

Abstract: For full-size humanoid robots, even with recent advances in reinforcement learning-based control, achieving reliable locomotion on complex terrains, such as long staircases, remains challenging. In such settings, limited perception, ambiguous terrain cues, and insufficient adaptation of gait timing can cause even a single misplaced or mistimed step to result in rapid loss of balance. We introduce a perceptive locomotion framework that merges terrain sensing, gait regulation, and whole-body control into a single reinforcement learning policy. A downward-facing depth camera mounted under the base observes the support region around the feet, and a compact U-Net reconstructs a dense egocentric height map from each frame in real time, operating at the same frequency as the control loop. The perceptual height map, together with proprioceptive observations, is processed by a unified policy that produces joint commands and a global stepping-phase signal, allowing gait timing and whole-body posture to be adapted jointly to the commanded motion and local terrain geometry. We further adopt a single-stage successive teacher-student training scheme for efficient policy learning and knowledge transfer. Experiments conducted on a 31-DoF, 1.65 m humanoid robot demonstrate robust locomotion in both simulation and real-world settings, including forward and backward stair ascent and descent, as well as crossing a 46 cm gap. Project Page:https://ga-phl.github.io/

</details>


### [277] [Affordance Field Intervention: Enabling VLAs to Escape Memory Traps in Robotic Manipulation](https://arxiv.org/abs/2512.07472)
*Siyu Xu,Zijian Wang,Yunke Wang,Chenghao Xia,Tao Huang,Chang Xu*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Vision-Language-Action (VLA) models have shown great performance in robotic manipulation by mapping visual observations and language instructions directly to actions. However, they remain brittle under distribution shifts: when test scenarios change, VLAs often reproduce memorized trajectories instead of adapting to the updated scene, which is a failure mode we refer to as the "Memory Trap". This limitation stems from the end-to-end design, which lacks explicit 3D spatial reasoning and prevents reliable identification of actionable regions in unfamiliar environments. To compensate for this missing spatial understanding, 3D Spatial Affordance Fields (SAFs) can provide a geometric representation that highlights where interactions are physically feasible, offering explicit cues about regions the robot should approach or avoid. We therefore introduce Affordance Field Intervention (AFI), a lightweight hybrid framework that uses SAFs as an on-demand plug-in to guide VLA behavior. Our system detects memory traps through proprioception, repositions the robot to recent high-affordance regions, and proposes affordance-driven waypoints that anchor VLA-generated actions. A SAF-based scorer then selects trajectories with the highest cumulative affordance. Extensive experiments demonstrate that our method achieves an average improvement of 23.5% across different VLA backbones ($π_{0}$ and $π_{0.5}$) under out-of-distribution scenarios on real-world robotic platforms, and 20.2% on the LIBERO-Pro benchmark, validating its effectiveness in enhancing VLA robustness to distribution shifts.

</details>


### [278] [From Real-World Traffic Data to Relevant Critical Scenarios](https://arxiv.org/abs/2512.07482)
*Florian Lüttner,Nicole Neis,Daniel Stadler,Robin Moss,Mirjam Fehling-Kaschek,Matthias Pfriem,Alexander Stolz,Jens Ziehn*

Main category: cs.RO

TL;DR: 本文提出了一种处理高速公路换道场景的方法，通过分析真实世界数据和应用关键性度量来识别安全相关场景，并生成合成关键场景以提高验证效率。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶功能复杂度的增加，识别潜在的安全相关场景（尤其是“未知不安全”场景）变得日益重要，需要从简单场景（如高速公路）开始逐步扩展到复杂环境。

Method: 采集和处理真实高速公路交通数据，应用关键性度量评估轨迹数据，将计算出的度量与特定换道驾驶场景及数据采集条件关联，并基于记录的场景生成合成场景。

Result: 开发了一条处理链，能够识别安全相关场景、提取这些场景的数据驱动方法，并通过采样生成合成关键场景。

Conclusion: 该方法有效支持了自动驾驶系统在高速公路换道场景中的安全验证，为更复杂环境的场景分析奠定了基础。

Abstract: The reliable operation of autonomous vehicles, automated driving functions, and advanced driver assistance systems across a wide range of relevant scenarios is critical for their development and deployment. Identifying a near-complete set of relevant driving scenarios for such functionalities is challenging due to numerous degrees of freedom involved, each affecting the outcomes of the driving scenario differently. Moreover, with increasing technical complexity of new functionalities, the number of potentially relevant, particularly "unknown unsafe" scenarios is increasing. To enhance validation efficiency, it is essential to identify relevant scenarios in advance, starting with simpler domains like highways before moving to more complex environments such as urban traffic. To address this, this paper focuses on analyzing lane change scenarios in highway traffic, which involve multiple degrees of freedom and present numerous safetyrelevant scenarios. We describe the process of data acquisition and processing of real-world data from public highway traffic, followed by the application of criticality measures on trajectory data to evaluate scenarios, as conducted within the AVEAS project (www.aveas.org). By linking the calculated measures to specific lane change driving scenarios and the conditions under which the data was collected, we facilitate the identification of safetyrelevant driving scenarios for various applications. Further, to tackle the extensive range of "unknown unsafe" scenarios, we propose a way to generate relevant scenarios by creating synthetic scenarios based on recorded ones. Consequently, we demonstrate and evaluate a processing chain that enables the identification of safety-relevant scenarios, the development of data-driven methods for extracting these scenarios, and the generation of synthetic critical scenarios via sampling on highways.

</details>


### [279] [VP-AutoTest: A Virtual-Physical Fusion Autonomous Driving Testing Platform](https://arxiv.org/abs/2512.07507)
*Yiming Cui,Shiyu Fang,Jiarui Zhang,Yan Huang,Chengkai Xu,Bing Zhu,Hao Zhang,Peng Hang,Jian Sun*

Main category: cs.RO

TL;DR: VP-AutoTest平台通过集成虚拟与物理元素，支持多车协同测试和AI评估，解决了自动驾驶测试中元素类型有限、测试范围窄和评估指标固定的问题。


<details>
  <summary>Details</summary>
Motivation: 传统自动驾驶测试方法（如虚拟仿真、封闭场地和公开道路测试）存在车辆状态不真实、测试能力有限和成本高等问题，虚拟物理融合测试虽具潜力但面临元素类型有限、测试范围窄和评估指标固定等挑战。

Method: 提出VP-AutoTest平台，集成十余种虚拟与物理元素（如车辆、行人、路侧设施），支持单车交互与多车协同测试，采用对抗测试和平行推演加速故障发现，通过OBU和Redis实现V2V/V2I通信，结合多维评估框架和AI专家系统进行性能评估与缺陷诊断。

Result: 平台通过虚拟物理融合测试与真实实验对比，进行可信度自评估，确保测试的保真度与效率。

Conclusion: VP-AutoTest平台有效解决了虚拟物理融合测试的局限性，提升了自动驾驶测试的多样性和可靠性。

Abstract: The rapid development of autonomous vehicles has led to a surge in testing demand. Traditional testing methods, such as virtual simulation, closed-course, and public road testing, face several challenges, including unrealistic vehicle states, limited testing capabilities, and high costs. These issues have prompted increasing interest in virtual-physical fusion testing. However, despite its potential, virtual-physical fusion testing still faces challenges, such as limited element types, narrow testing scope, and fixed evaluation metrics. To address these challenges, we propose the Virtual-Physical Testing Platform for Autonomous Vehicles (VP-AutoTest), which integrates over ten types of virtual and physical elements, including vehicles, pedestrians, and roadside infrastructure, to replicate the diversity of real-world traffic participants. The platform also supports both single-vehicle interaction and multi-vehicle cooperation testing, employing adversarial testing and parallel deduction to accelerate fault detection and explore algorithmic limits, while OBU and Redis communication enable seamless vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) cooperation across all levels of cooperative automation. Furthermore, VP-AutoTest incorporates a multidimensional evaluation framework and AI-driven expert systems to conduct comprehensive performance assessment and defect diagnosis. Finally, by comparing virtual-physical fusion test results with real-world experiments, the platform performs credibility self-evaluation to ensure both the fidelity and efficiency of autonomous driving testing. Please refer to the website for the full testing functionalities on the autonomous driving public service platform OnSite:https://www.onsite.com.cn.

</details>


### [280] [See Once, Then Act: Vision-Language-Action Model with Task Learning from One-Shot Video Demonstrations](https://arxiv.org/abs/2512.07582)
*Guangyan Chen,Meiling Wang,Qi Shao,Zichen Zhou,Weixin Mao,Te Cui,Minzhao Zhu,Yinan Deng,Luojie Yang,Zhanqi Zhang,Yi Yang,Hua Chen,Yufeng Yue*

Main category: cs.RO

TL;DR: ViVLA是一个通用机器人操作策略，能够通过单一专家演示视频在测试时高效学习新任务，实现了从人类视频到机器操作的跨实体知识迁移。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作模型在训练分布外的任务上泛化能力有限，而人类能够通过一次观察快速学习新技能，这启发了开发能够从单一演示中学习新任务的机器人策略。

Method: ViVLA通过联合处理专家演示视频和机器人视觉观察，同时预测演示动作序列和后续机器人动作，从专家行为中提取精细操作知识。开发了可扩展的专家-智能体配对数据生成流程，从人类视频合成配对轨迹。

Result: ViVLA在未见过的LIBERO任务上实现了超过30%的性能提升，跨实体视频上保持35%以上的增益，真实世界实验中从未见过的任务上获得了38%以上的改进。

Conclusion: ViVLA展示了从单一演示视频学习新操作任务的有效性，为开发更通用的机器人操作策略提供了有前景的方向。

Abstract: Developing robust and general-purpose manipulation policies represents a fundamental objective in robotics research. While Vision-Language-Action (VLA) models have demonstrated promising capabilities for end-to-end robot control, existing approaches still exhibit limited generalization to tasks beyond their training distributions. In contrast, humans possess remarkable proficiency in acquiring novel skills by simply observing others performing them once. Inspired by this capability, we propose ViVLA, a generalist robotic manipulation policy that achieves efficient task learning from a single expert demonstration video at test time. Our approach jointly processes an expert demonstration video alongside the robot's visual observations to predict both the demonstrated action sequences and subsequent robot actions, effectively distilling fine-grained manipulation knowledge from expert behavior and transferring it seamlessly to the agent. To enhance the performance of ViVLA, we develop a scalable expert-agent pair data generation pipeline capable of synthesizing paired trajectories from easily accessible human videos, further augmented by curated pairs from publicly available datasets. This pipeline produces a total of 892,911 expert-agent samples for training ViVLA. Experimental results demonstrate that our ViVLA is able to acquire novel manipulation skills from only a single expert demonstration video at test time. Our approach achieves over 30% improvement on unseen LIBERO tasks and maintains above 35% gains with cross-embodiment videos. Real-world experiments demonstrate effective learning from human videos, yielding more than 38% improvement on unseen tasks.

</details>


### [281] [Multi-Domain Motion Embedding: Expressive Real-Time Mimicry for Legged Robots](https://arxiv.org/abs/2512.07673)
*Matthias Heyrman,Chenhao Li,Victor Klemm,Dongho Kang,Stelian Coros,Marco Hutter*

Main category: cs.RO

TL;DR: MDME是一种运动表示方法，通过小波编码器和概率嵌入统一捕捉运动中的结构化周期模式和非规则变化，实现无需重定向的实时运动模仿。


<details>
  <summary>Details</summary>
Motivation: 现有运动控制器往往忽略运动中的固有模式，且现有表示学习方法未能同时捕捉人类和动物运动中的结构化周期性模式和非规则变化。

Method: 提出多域运动嵌入(MDME)，使用小波编码器和并行概率嵌入来统一表示结构化和非结构化特征，从最小输入集生成丰富的参考运动表示。

Result: 在类人机器人和四足机器人平台上实现了复杂轨迹的精确复制，在重建保真度和对未见运动的泛化能力方面优于现有方法，并能通过零样本部署实时重现新颖运动风格。

Conclusion: MDME作为可扩展实时机器人模仿的结构感知基础，无需任务特定调优或在线重定向，具有良好的泛化能力。

Abstract: Effective motion representation is crucial for enabling robots to imitate expressive behaviors in real time, yet existing motion controllers often ignore inherent patterns in motion. Previous efforts in representation learning do not attempt to jointly capture structured periodic patterns and irregular variations in human and animal movement. To address this, we present Multi-Domain Motion Embedding (MDME), a motion representation that unifies the embedding of structured and unstructured features using a wavelet-based encoder and a probabilistic embedding in parallel. This produces a rich representation of reference motions from a minimal input set, enabling improved generalization across diverse motion styles and morphologies. We evaluate MDME on retargeting-free real-time motion imitation by conditioning robot control policies on the learned embeddings, demonstrating accurate reproduction of complex trajectories on both humanoid and quadruped platforms. Our comparative studies confirm that MDME outperforms prior approaches in reconstruction fidelity and generalizability to unseen motions. Furthermore, we demonstrate that MDME can reproduce novel motion styles in real-time through zero-shot deployment, eliminating the need for task-specific tuning or online retargeting. These results position MDME as a generalizable and structure-aware foundation for scalable real-time robot imitation.

</details>


### [282] [AMBER: Aerial deployable gripping crawler with compliant microspine for canopy manipulation](https://arxiv.org/abs/2512.07680)
*P. A. Wigner,L. Romanello,A. Hammad,P. H. Nguyen,T. Lan,S. F. Armanini,B. B. Kocer,M. Kovac*

Main category: cs.RO

TL;DR: 本文介绍了一种可在树冠中自适应移动和操作的空中部署爬行机器人，结合了柔性微刺轨道、双轨道旋转抓取器和弹性尾部，能够在不同曲率和倾斜度的树枝上稳定移动。


<details>
  <summary>Details</summary>
Motivation: 开发能够在树冠环境中进行环境采样和传感的机器人平台，弥补空中机器人和地面生态机器人之间的技术空白。

Method: 采用柔性微刺轨道实现安全附着，双轨道旋转抓取器提供抓取能力，弹性尾部增强稳定性。系统通过无人机-绳索部署系统进行空中部署。

Result: 实验显示在90度滚转和倾斜下仍能可靠抓取，在67.5度倾斜树枝上有效攀爬，水平树枝上最大速度0.55体长/秒，转向角度可达10度。能耗比典型悬停无人机低一个数量级。

Conclusion: 该系统为树冠环境监测提供了低功耗、鲁棒的平台，成功实现了空中部署与表面移动的结合。

Abstract: This paper presents an aerially deployable crawler designed for adaptive locomotion and manipulation within tree canopies. The system combines compliant microspine-based tracks, a dual-track rotary gripper, and an elastic tail, enabling secure attachment and stable traversal across branches of varying curvature and inclination.
  Experiments demonstrate reliable gripping up to 90 degrees of body roll and inclination, while effective climbing on branches inclined up to 67.5 degrees, achieving a maximum speed of 0.55 body lengths per second on horizontal branches. The compliant tracks allow yaw steering of up to 10 degrees, enhancing maneuverability on irregular surfaces.
  Power measurements show efficient operation with a dimensionless cost of transport over an order of magnitude lower than typical hovering power consumption in aerial robots. Integrated within a drone-tether deployment system, the crawler provides a robust, low-power platform for environmental sampling and in-canopy sensing, bridging the gap between aerial and surface-based ecological robotics.

</details>


### [283] [Delay-Aware Diffusion Policy: Bridging the Observation-Execution Gap in Dynamic Tasks](https://arxiv.org/abs/2512.07697)
*Aileen Liao,Dong-Ki Kim,Max Olan Smith,Ali-akbar Agha-mohammadi,Shayegan Omidshafiei*

Main category: cs.RO

TL;DR: 本文提出了延迟感知扩散策略（DA-DP），通过显式地将推理延迟纳入策略学习，解决机器人动作执行中的延迟问题。


<details>
  <summary>Details</summary>
Motivation: 机器人在感知和选择动作时，世界持续变化，导致观测状态与执行状态之间存在数十到数百毫秒的延迟，这影响了策略的性能。

Method: DA-DP将零延迟轨迹校正为延迟补偿轨迹，并通过延迟条件增强策略，该框架与架构无关，可推广到扩散策略之外。

Result: 在多种任务、机器人和延迟条件下，DA-DP的成功率比无延迟感知方法更稳健。

Conclusion: DA-DP为延迟感知模仿学习提供了一种通用模式，并鼓励评估协议报告性能随测量延迟的变化，而不仅仅是任务难度。

Abstract: As a robot senses and selects actions, the world keeps changing. This inference delay creates a gap of tens to hundreds of milliseconds between the observed state and the state at execution. In this work, we take the natural generalization from zero delay to measured delay during training and inference. We introduce Delay-Aware Diffusion Policy (DA-DP), a framework for explicitly incorporating inference delays into policy learning. DA-DP corrects zero-delay trajectories to their delay-compensated counterparts, and augments the policy with delay conditioning. We empirically validate DA-DP on a variety of tasks, robots, and delays and find its success rate more robust to delay than delay-unaware methods. DA-DP is architecture agnostic and transfers beyond diffusion policies, offering a general pattern for delay-aware imitation learning. More broadly, DA-DP encourages evaluation protocols that report performance as a function of measured latency, not just task difficulty.

</details>


### [284] [Toward Seamless Physical Human-Humanoid Interaction: Insights from Control, Intent, and Modeling with a Vision for What Comes Next](https://arxiv.org/abs/2512.07765)
*Gustavo A. Cardona,Shubham S. Kumbhar,Panagiotis Artemiadis*

Main category: cs.RO

TL;DR: 这篇综述论文从三个核心支柱（人形机器人建模与控制、人类意图估计、计算人类模型）分析了物理人机交互的现状，提出了基于交互模式和机器人参与程度的统一分类法，并指出了跨领域整合的未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 推动人形机器人在非结构化、以人为中心的环境中的部署，需要解决物理人机交互中的关键技术挑战，包括不确定性处理、实时意图推断和人类状态建模。

Method: 通过系统综述现有文献，分析三个核心支柱的代表性方法、开放挑战和当前局限，并提出基于交互模态和机器人参与程度的统一分类框架。

Result: 识别了各领域的重要进展和整合限制，提出了跨支柱统一的方法路径，建立了新的交互分类体系，为未来研究提供了具体方向。

Conclusion: 需要跨领域整合来构建鲁棒、安全、直观的物理交互框架，使人形系统能够在真实世界中有效理解、预测和协作人类伙伴。

Abstract: Physical Human-Humanoid Interaction (pHHI) is a rapidly advancing field with significant implications for deploying robots in unstructured, human-centric environments. In this review, we examine the current state of the art in pHHI through three core pillars: (i) humanoid modeling and control, (ii) human intent estimation, and (iii) computational human models. For each pillar, we survey representative approaches, identify open challenges, and analyze current limitations that hinder robust, scalable, and adaptive interaction. These include the need for whole-body control strategies capable of handling uncertain human dynamics, real-time intent inference under limited sensing, and modeling techniques that account for variability in human physical states. Although significant progress has been made within each domain, integration across pillars remains limited. We propose pathways for unifying methods across these areas to enable cohesive interaction frameworks. This structure enables us not only to map the current landscape but also to propose concrete directions for future research that aim to bridge these domains. Additionally, we introduce a unified taxonomy of interaction types based on modality, distinguishing between direct interactions (e.g., physical contact) and indirect interactions (e.g., object-mediated), and on the level of robot engagement, ranging from assistance to cooperation and collaboration. For each category in this taxonomy, we provide the three core pillars that highlight opportunities for cross-pillar unification. Our goal is to suggest avenues to advance robust, safe, and intuitive physical interaction, providing a roadmap for future research that will allow humanoid systems to effectively understand, anticipate, and collaborate with human partners in diverse real-world settings.

</details>


### [285] [OptMap: Geometric Map Distillation via Submodular Maximization](https://arxiv.org/abs/2512.07775)
*David Thorne,Nathan Chan,Christa S. Robison,Philip R. Osteen,Brett T. Lopez*

Main category: cs.RO

TL;DR: OptMap是一个实时几何地图蒸馏算法，通过子模优化技术从LiDAR数据中提取信息量最大、尺寸受限的专用地图，解决了NP难组合优化问题。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶机器人需要多尺度的几何地图来支持不同算法，但LiDAR数据量大且选择最优地图是NP难问题，需要高效的实时地图生成方法。

Method: 提出新颖的子模奖励函数量化信息量，减少输入集大小并最小化序列数据偏差；采用动态重排序流式子模算法改进解质量并处理输入顺序偏差。

Result: 在开源和自定义数据集上测试，特别关注长时间建图场景，显示OptMap具有极低的计算需求，并提供了ROS1和ROS2开源包。

Conclusion: OptMap通过理论创新实现了实时、应用特定的地图生成，为自主机器人提供了高效的地图蒸馏解决方案。

Abstract: Autonomous robots rely on geometric maps to inform a diverse set of perception and decision-making algorithms. As autonomy requires reasoning and planning on multiple scales of the environment, each algorithm may require a different map for optimal performance. Light Detection And Ranging (LiDAR) sensors generate an abundance of geometric data to satisfy these diverse requirements, but selecting informative, size-constrained maps is computationally challenging as it requires solving an NP-hard combinatorial optimization. In this work we present OptMap: a geometric map distillation algorithm which achieves real-time, application-specific map generation via multiple theoretical and algorithmic innovations. A central feature is the maximization of set functions that exhibit diminishing returns, i.e., submodularity, using polynomial-time algorithms with provably near-optimal solutions. We formulate a novel submodular reward function which quantifies informativeness, reduces input set sizes, and minimizes bias in sequentially collected datasets. Further, we propose a dynamically reordered streaming submodular algorithm which improves empirical solution quality and addresses input order bias via an online approximation of the value of all scans. Testing was conducted on open-source and custom datasets with an emphasis on long-duration mapping sessions, highlighting OptMap's minimal computation requirements. Open-source ROS1 and ROS2 packages are available and can be used alongside any LiDAR SLAM algorithm.

</details>


### [286] [Inchworm-Inspired Soft Robot with Groove-Guided Locomotion](https://arxiv.org/abs/2512.07813)
*Hari Prakash Thanabalan,Lars Bengtsson,Ugo Lafont,Giovanni Volpe*

Main category: cs.RO

TL;DR: 本文介绍了一种受尺蠖启发的软体机器人，通过图案化基底被动控制运动方向，仅使用单个卷曲介电弹性体致动器，简化了机器人设计并降低了能耗。


<details>
  <summary>Details</summary>
Motivation: 传统软体机器人需要多个致动器来实现方向控制，这增加了机械复杂性、控制难度和能耗。

Method: 利用3D打印基底上的沟槽图案引导机器人对齐和轨迹，通过改变沟槽角度实现精确的运动方向控制，无需复杂致动策略。

Result: 系统实验表明，该方法能够精确控制运动方向，同时降低能耗并简化机器人设计。

Conclusion: 这种沟槽引导方法扩展了仿生软体机器人在搜救、管道检测和行星探测等领域的应用潜力。

Abstract: Soft robots require directional control to navigate complex terrains. However, achieving such control often requires multiple actuators, which increases mechanical complexity, complicates control systems, and raises energy consumption. Here, we introduce an inchworm-inspired soft robot whose locomotion direction is controlled passively by patterned substrates. The robot employs a single rolled dielectric elastomer actuator, while groove patterns on a 3D-printed substrate guide its alignment and trajectory. Through systematic experiments, we demonstrate that varying groove angles enables precise control of locomotion direction without the need for complex actuation strategies. This groove-guided approach reduces energy consumption, simplifies robot design, and expands the applicability of bio-inspired soft robots in fields such as search and rescue, pipe inspection, and planetary exploration.

</details>


### [287] [Efficient and Compliant Control Framework for Versatile Human-Humanoid Collaborative Transportation](https://arxiv.org/abs/2512.07819)
*Shubham S. Kumbhar,Abhijeet M. Kulkarni,Panagiotis Artemiadis*

Main category: cs.RO

TL;DR: 提出一个控制框架使双足机器人能与人类伙伴协作搬运物体，支持平移和旋转运动，包含高层规划器、低层控制器和刚度调制机制，并通过真实实验验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 实现双足机器人与人类的协作搬运任务，解决在协作运输场景中机器人需要同时处理平移和旋转运动的关键挑战。

Method: 采用三层架构：高层规划器使用交互线性倒立摆模型结合导纳模型和MPC生成可行脚步规划；低层控制器基于QP的全身控制器处理耦合动力学；刚度调制机制调节机器人-物体交互。

Result: 在Digit双足机器人平台上成功实现了协作搬运行为，包括平移、转向和半圆形轨迹等自然协作运输任务，并提出了量化协作效率的指标。

Conclusion: 该框架有效支持人机协作搬运，提出的效率指标揭示了柔顺性在协作任务中的重要性，并为高低层控制层的轨迹特性提供了见解。

Abstract: We present a control framework that enables humanoid robots to perform collaborative transportation tasks with a human partner. The framework supports both translational and rotational motions, which are fundamental to co-transport scenarios. It comprises three components: a high-level planner, a low-level controller, and a stiffness modulation mechanism. At the planning level, we introduce the Interaction Linear Inverted Pendulum (I-LIP), which, combined with an admittance model and an MPC formulation, generates dynamically feasible footstep plans. These are executed by a QP-based whole-body controller that accounts for the coupled humanoid-object dynamics. Stiffness modulation regulates robot-object interaction, ensuring convergence to the desired relative configuration defined by the distance between the object and the robot's center of mass. We validate the effectiveness of the framework through real-world experiments conducted on the Digit humanoid platform. To quantify collaboration quality, we propose an efficiency metric that captures both task performance and inter-agent coordination. We show that this metric highlights the role of compliance in collaborative tasks and offers insights into desirable trajectory characteristics across both high- and low-level control layers. Finally, we showcase experimental results on collaborative behaviors, including translation, turning, and combined motions such as semi circular trajectories, representative of naturally occurring co-transportation tasks.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [288] [A self-driving lab for solution-processed electrochromic thin films](https://arxiv.org/abs/2512.05989)
*Selma Dahms,Luca Torresi,Shahbaz Tareq Bandesha,Jan Hansmann,Holger Röhm,Alexander Colsmann,Marco Schott,Pascal Friederich*

Main category: cs.LG

TL;DR: 本研究展示了利用自动驾驶实验室加速电致变色涂层开发的方法，通过将自动化与机器学习相结合，实现高效处理参数探索。


<details>
  <summary>Details</summary>
Motivation: 旋涂电致变色薄膜层的优化复杂性给快速开发带来挑战，需要更高效的方法来加速材料发现和工艺优化。

Method: 结合自动化数据采集、图像处理、光谱分析和贝叶斯优化，构建自动驾驶实验室系统来探索处理参数。

Result: 该方法不仅提高了通量，还实现了对最优处理参数的针对性搜索，可应用于各种溶液处理材料。

Conclusion: 自动驾驶实验室在增强材料发现和工艺优化方面具有巨大潜力，为电致变色材料开发提供了高效解决方案。

Abstract: Solution-processed electrochromic materials offer high potential for energy-efficient smart windows and displays. Their performance varies with material choice and processing conditions. Electrochromic thin film electrodes require a smooth, defect-free coating for optimal contrast between bleached and colored states. The complexity of optimizing the spin-coated electrochromic thin layer poses challenges for rapid development. This study demonstrates the use of self-driving laboratories to accelerate the development of electrochromic coatings by coupling automation with machine learning. Our system combines automated data acquisition, image processing, spectral analysis, and Bayesian optimization to explore processing parameters efficiently. This approach not only increases throughput but also enables a pointed search for optimal processing parameters. The approach can be applied to various solution-processed materials, highlighting the potential of self-driving labs in enhancing materials discovery and process optimization.

</details>


### [289] [Memory-Amortized Inference: A Topological Unification of Search, Closure, and Structure](https://arxiv.org/abs/2512.05990)
*Xin Li*

Main category: cs.LG

TL;DR: 本文提出了Memory-Amortized Inference (MAI)框架，基于代数拓扑统一学习和记忆，通过同调奇偶性原理区分内容与上下文，将高复杂度搜索转化为低复杂度查找。


<details>
  <summary>Details</summary>
Motivation: 解决当前机器学习中参数静态结构与推理动态流程分离的问题，提高样本效率和热力学效率，模仿生物认知机制。

Method: 基于代数拓扑的MAI框架，包含同调奇偶性原理和拓扑三位一体变换（搜索→闭合→结构），通过拓扑循环闭合机制实现复杂度降低。

Result: 建立了认知过程中快速思维从慢速思维中涌现的理论基础，为后图灵架构提供了蓝图。

Conclusion: MAI框架为统一学习和记忆提供了严格的数学基础，有望推动更高效的认知计算架构发展。

Abstract: Contemporary ML separates the static structure of parameters from the dynamic flow of inference, yielding systems that lack the sample efficiency and thermodynamic frugality of biological cognition. In this theoretical work, we propose \textbf{Memory-Amortized Inference (MAI)}, a formal framework rooted in algebraic topology that unifies learning and memory as phase transitions of a single geometric substrate. Central to our theory is the \textbf{Homological Parity Principle}, which posits a fundamental dichotomy: even-dimensional homology ($H_{even}$) physically instantiates stable \textbf{Content} (stable scaffolds or ``what''), while odd-dimensional homology ($H_{odd}$) instantiates dynamic \textbf{Context} (dynamic flows or ``where''). We derive the logical flow of MAI as a topological trinity transformation: \textbf{Search $\to$ Closure $\to$ Structure}. Specifically, we demonstrate that cognition operates by converting high-complexity recursive search (modeled by \textit{Savitch's Theorem} in NPSPACE) into low-complexity lookup (modeled by \textit{Dynamic Programming} in P) via the mechanism of \textbf{Topological Cycle Closure}. We further show that this consolidation process is governed by a topological generalization of the Wake-Sleep algorithm, functioning as a coordinate descent that alternates between optimizing the $H_{odd}$ flow (inference/wake) and condensing persistent cycles into the $H_{even}$ scaffold (learning/sleep). This framework offers a rigorous explanation for the emergence of fast-thinking (intuition) from slow-thinking (reasoning) and provides a blueprint for post-Turing architectures that compute via topological resonance.

</details>


### [290] [Deep learning recognition and analysis of Volatile Organic Compounds based on experimental and synthetic infrared absorption spectra](https://arxiv.org/abs/2512.06059)
*Andrea Della Valle,Annalisa D'Arco,Tiziana Mancini,Rosanna Mosetti,Maria Chiara Paolozzi,Stefano Lupi,Sebastiano Pilati,Andrea Perali*

Main category: cs.LG

TL;DR: 该论文提出了一种结合实验数据和合成光谱的方法，使用条件生成神经网络增强VOC红外光谱数据集，训练出能够准确识别9种VOC并预测其浓度的判别神经网络。


<details>
  <summary>Details</summary>
Motivation: VOC对人体健康有重大风险，需要准确检测。红外光谱技术虽然能实现超灵敏检测，但复杂的光谱限制了实时识别和定量分析的可能性。深度神经网络需要大量数据训练，而实验数据获取困难。

Method: 创建了9种VOC在不同浓度下的实验数据集，使用条件生成神经网络生成合成光谱来增强数据集规模和多样性，然后训练判别神经网络进行VOC识别和浓度预测。

Result: 训练出的神经网络能够可靠地识别9种VOC，并精确预测其浓度，适合集成到VOC传感设备中进行实时识别和分析。

Conclusion: 通过数据增强方法有效解决了VOC红外光谱识别中数据不足的问题，为实时VOC监测提供了可行的技术方案。

Abstract: Volatile Organic Compounds (VOCs) are organic molecules that have low boiling points and therefore easily evaporate into the air. They pose significant risks to human health, making their accurate detection the crux of efforts to monitor and minimize exposure. Infrared (IR) spectroscopy enables the ultrasensitive detection at low-concentrations of VOCs in the atmosphere by measuring their IR absorption spectra. However, the complexity of the IR spectra limits the possibility to implement VOC recognition and quantification in real-time. While deep neural networks (NNs) are increasingly used for the recognition of complex data structures, they typically require massive datasets for the training phase. Here, we create an experimental VOC dataset for nine different classes of compounds at various concentrations, using their IR absorption spectra. To further increase the amount of spectra and their diversity in term of VOC concentration, we augment the experimental dataset with synthetic spectra created via conditional generative NNs. This allows us to train robust discriminative NNs, able to reliably identify the nine VOCs, as well as to precisely predict their concentrations. The trained NN is suitable to be incorporated into sensing devices for VOCs recognition and analysis.

</details>


### [291] [When Privacy Isn't Synthetic: Hidden Data Leakage in Generative AI Models](https://arxiv.org/abs/2512.06062)
*S. M. Mustaqim,Anantaa Kotal,Paul H. Yi*

Main category: cs.LG

TL;DR: 本文提出了一种基于聚类和质心分析的成员推断攻击方法，揭示了生成模型在合成数据中仍会泄露训练样本隐私信息的安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 尽管生成模型被广泛用于生成隐私保护的合成数据，但现有方法可能低估了数据流形结构重叠带来的隐私泄露风险。作者发现即使使用差分隐私等技术，合成数据仍可能通过分布邻域推断泄露训练样本信息。

Method: 提出黑盒成员推断攻击：1）重复查询生成模型获取大量合成样本；2）进行无监督聚类识别合成分布的密集区域；3）分析聚类质心和邻域，这些区域对应原始训练数据中的高密度区域，可作为训练样本的代理来推断成员身份或重建近似记录。

Result: 在医疗、金融等敏感领域的实验表明，真实数据与合成数据之间的聚类重叠会导致可测量的成员信息泄露，即使生成器使用差分隐私或其他噪声机制进行训练。

Conclusion: 研究结果揭示了合成数据生成管道中一个未被充分探索的攻击面，呼吁需要更强的隐私保证，不仅要考虑样本级记忆，还要考虑分布邻域推断，这对隐私保护数据发布具有重要意义。

Abstract: Generative models are increasingly used to produce privacy-preserving synthetic data as a safe alternative to sharing sensitive training datasets. However, we demonstrate that such synthetic releases can still leak information about the underlying training samples through structural overlap in the data manifold. We propose a black-box membership inference attack that exploits this vulnerability without requiring access to model internals or real data. The attacker repeatedly queries the generative model to obtain large numbers of synthetic samples, performs unsupervised clustering to identify dense regions of the synthetic distribution, and then analyzes cluster medoids and neighborhoods that correspond to high-density regions in the original training data. These neighborhoods act as proxies for training samples, enabling the adversary to infer membership or reconstruct approximate records. Our experiments across healthcare, finance, and other sensitive domains show that cluster overlap between real and synthetic data leads to measurable membership leakage-even when the generator is trained with differential privacy or other noise mechanisms. The results highlight an under-explored attack surface in synthetic data generation pipelines and call for stronger privacy guarantees that account for distributional neighborhood inference rather than sample-level memorization alone, underscoring its role in privacy-preserving data publishing. Implementation and evaluation code are publicly available at:github.com/Cluster-Medoid-Leakage-Attack.

</details>


### [292] [JaxWildfire: A GPU-Accelerated Wildfire Simulator for Reinforcement Learning](https://arxiv.org/abs/2512.06102)
*Ufuk Çakır,Victor-Alexandru Darvariu,Bruno Lacerda,Nick Hawes*

Main category: cs.LG

TL;DR: JaxWildfire是一个基于JAX实现的高性能野火模拟器，通过向量化计算在GPU上实现6-35倍加速，支持基于梯度的参数优化和强化学习训练。


<details>
  <summary>Details</summary>
Motivation: 现有野火模拟器速度慢，限制了强化学习在自然灾害管理中的应用，需要开发高效的模拟器来支持RL算法的训练。

Method: 基于概率细胞自动机的野火传播模型，使用JAX框架实现向量化模拟，利用vmap实现GPU上的高吞吐量计算。

Result: 相比现有软件实现6-35倍加速，能够进行基于梯度的参数优化，并成功训练RL代理学习野火抑制策略。

Conclusion: JaxWildfire为推进强化学习在自然灾害管理中的应用提供了重要工具，是向主动式灾害管理策略迈进的关键一步。

Abstract: Artificial intelligence methods are increasingly being explored for managing wildfires and other natural hazards. In particular, reinforcement learning (RL) is a promising path towards improving outcomes in such uncertain decision-making scenarios and moving beyond reactive strategies. However, training RL agents requires many environment interactions, and the speed of existing wildfire simulators is a severely limiting factor. We introduce $\texttt{JaxWildfire}$, a simulator underpinned by a principled probabilistic fire spread model based on cellular automata. It is implemented in JAX and enables vectorized simulations using $\texttt{vmap}$, allowing high throughput of simulations on GPUs. We demonstrate that $\texttt{JaxWildfire}$ achieves 6-35x speedup over existing software and enables gradient-based optimization of simulator parameters. Furthermore, we show that $\texttt{JaxWildfire}$ can be used to train RL agents to learn wildfire suppression policies. Our work is an important step towards enabling the advancement of RL techniques for managing natural hazards.

</details>


### [293] [ARC-AGI Without Pretraining](https://arxiv.org/abs/2512.06104)
*Isaac Liao,Albert Gu*

Main category: cs.LG

TL;DR: CompressARC是一个仅76K参数的模型，无需预训练即可在推理时通过最小化描述长度（MDL）解决20%的ARC-AGI视觉谜题，展示了极端泛化能力。


<details>
  <summary>Details</summary>
Motivation: 挑战传统观点，即解决ARC-AGI视觉谜题需要大规模预训练，探索在极有限数据条件下实现智能的替代方法。

Method: 使用最小描述长度（MDL）原则，在推理时仅基于单个目标谜题（不含最终答案）进行训练，不依赖预训练或标准训练集。

Result: 在极端数据限制下成功解决20%的评估谜题，表现出深度学习中罕见的泛化能力。

Conclusion: MDL是除传统预训练外实现智能的可行替代途径，为有限数据条件下的AGI研究提供了新方向。

Abstract: Conventional wisdom in the age of LLMs dictates that solving IQ-test-like visual puzzles from the ARC-AGI-1 benchmark requires capabilities derived from massive pretraining. To counter this, we introduce CompressARC, a 76K parameter model without any pretraining that solves 20% of evaluation puzzles by minimizing the description length (MDL) of the target puzzle purely during inference time. The MDL endows CompressARC with extreme generalization abilities typically unheard of in deep learning. To our knowledge, CompressARC is the only deep learning method for ARC-AGI where training happens only on a single sample: the target inference puzzle itself, with the final solution information removed. Moreover, CompressARC does not train on the pre-provided ARC-AGI "training set". Under these extremely data-limited conditions, we do not ordinarily expect any puzzles to be solvable at all. Yet CompressARC still solves a diverse distribution of creative ARC-AGI puzzles, suggesting MDL to be an alternative feasible way to produce intelligence, besides conventional pretraining.

</details>


### [294] [A Prescriptive Framework for Determining Optimal Days for Short-Term Traffic Counts](https://arxiv.org/abs/2512.06111)
*Arthur Mukwaya,Nancy Kasamala,Nana Kankam Gyimah,Judith Mwakalonge,Gurcan Comert,Saidi Siuhi,Denis Ruganuza,Mark Ngotonie*

Main category: cs.LG

TL;DR: 本研究提出了一种机器学习框架，用于识别进行短期交通计数的最佳代表日，以提高年度平均日交通量预测精度。与当前实践相比，该方法在德克萨斯州数据上显著降低了预测误差。


<details>
  <summary>Details</summary>
Motivation: 美国各州交通部门需要收集可靠的年度平均日交通量数据，但连续计数站部署成本高昂，导致许多机构依赖短期计数。现有方法在未监测道路上的AADT预测准确性不足。

Method: 提出机器学习框架，通过迭代选择最具信息量的日期进行短期计数。使用德克萨斯州2022-2023年交通数据，比较'最优日'方法和'无最优日'基线方法。利用连续计数数据模拟24小时短期计数，并通过留一法技术生成无偏的代表性日交通特征。

Result: 最优日方法在前5个最佳日中表现优于基线，最佳日（第186天）的误差显著降低（RMSE: 7,871.15 vs 11,185.00，MAE: 3,645.09 vs 5,118.57，MAPE: 11.95% vs 14.42%），R²更高（0.9756 vs 0.9499）。

Conclusion: 该研究为交通部门提供了替代传统短期计数实践的方法，能够提高AADT估计精度，支持高速公路性能监测系统合规性，并降低全州交通数据收集的运营成本。

Abstract: The Federal Highway Administration (FHWA) mandates that state Departments of Transportation (DOTs) collect reliable Annual Average Daily Traffic (AADT) data. However, many U.S. DOTs struggle to obtain accurate AADT, especially for unmonitored roads. While continuous count (CC) stations offer accurate traffic volume data, their implementation is expensive and difficult to deploy widely, compelling agencies to rely on short-duration traffic counts. This study proposes a machine learning framework, the first to our knowledge, to identify optimal representative days for conducting short count (SC) data collection to improve AADT prediction accuracy. Using 2022 and 2023 traffic volume data from the state of Texas, we compare two scenarios: an 'optimal day' approach that iteratively selects the most informative days for AADT estimation and a 'no optimal day' baseline reflecting current practice by most DOTs. To align with Texas DOT's traffic monitoring program, continuous count data were utilized to simulate the 24 hour short counts. The actual field short counts were used to enhance feature engineering through using a leave-one-out (LOO) technique to generate unbiased representative daily traffic features across similar road segments. Our proposed methodology outperforms the baseline across the top five days, with the best day (Day 186) achieving lower errors (RMSE: 7,871.15, MAE: 3,645.09, MAPE: 11.95%) and higher R^2 (0.9756) than the baseline (RMSE: 11,185.00, MAE: 5,118.57, MAPE: 14.42%, R^2: 0.9499). This research offers DOTs an alternative to conventional short-duration count practices, improving AADT estimation, supporting Highway Performance Monitoring System compliance, and reducing the operational costs of statewide traffic data collection.

</details>


### [295] [Physics-Informed Neural Koopman Machine for Interpretable Longitudinal Personalized Alzheimer's Disease Forecasting](https://arxiv.org/abs/2512.06134)
*Georgi Hrusanov,Duy-Thanh Vu,Duy-Cat Can,Sophie Tascedda,Margaret Ryan,Julien Bodelet,Katarzyna Koscielska,Carsten Magnus,Oliver Y. Chén*

Main category: cs.LG

TL;DR: NKM是一种基于动态系统和注意力机制的新型机器学习架构，用于同时预测阿尔茨海默病的多种认知评分，整合多模态数据并保持可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在保持可解释性的同时整合多模态数据进行纵向个性化预测，特别是在阿尔茨海默病认知衰退的早期预测方面存在挑战。

Method: NKM结合分析性（α）和生物学（β）知识指导特征分组，通过融合组感知分层注意力机制在Koopman算子框架内将复杂非线性轨迹转化为可解释的线性表示。

Result: 在ADNI数据集上的实验表明，NKM在预测认知衰退轨迹方面优于传统机器学习和深度学习模型，能够同时预测多种认知评分变化、量化生物标志物贡献并识别最相关的脑区。

Conclusion: NKM通过可解释的显式系统推进了阿尔茨海默病的个性化预测，揭示了疾病进展的多模态生物学基础。

Abstract: Early forecasting of individual cognitive decline in Alzheimer's disease (AD) is central to disease evaluation and management. Despite advances, it is as of yet challenging for existing methodological frameworks to integrate multimodal data for longitudinal personalized forecasting while maintaining interpretability. To address this gap, we present the Neural Koopman Machine (NKM), a new machine learning architecture inspired by dynamical systems and attention mechanisms, designed to forecast multiple cognitive scores simultaneously using multimodal genetic, neuroimaging, proteomic, and demographic data. NKM integrates analytical ($α$) and biological ($β$) knowledge to guide feature grouping and control the hierarchical attention mechanisms to extract relevant patterns. By implementing Fusion Group-Aware Hierarchical Attention within the Koopman operator framework, NKM transforms complex nonlinear trajectories into interpretable linear representations. To demonstrate NKM's efficacy, we applied it to study the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset. Our results suggest that NKM consistently outperforms both traditional machine learning methods and deep learning models in forecasting trajectories of cognitive decline. Specifically, NKM (1) forecasts changes of multiple cognitive scores simultaneously, (2) quantifies differential biomarker contributions to predicting distinctive cognitive scores, and (3) identifies brain regions most predictive of cognitive deterioration. Together, NKM advances personalized, interpretable forecasting of future cognitive decline in AD using past multimodal data through an explainable, explicit system and reveals potential multimodal biological underpinnings of AD progression.

</details>


### [296] [gp2Scale: A Class of Compactly-Supported Non-Stationary Kernels and Distributed Computing for Exact Gaussian Processes on 10 Million Data Points](https://arxiv.org/abs/2512.06143)
*Marcus M. Noack,Mark D. Risser,Hengrui Luo,Vardaan Tekriwal,Ronald J. Pandolfi*

Main category: cs.LG

TL;DR: 提出gp2Scale方法，通过利用高斯过程核函数的自然稀疏结构，将精确高斯过程扩展到超过1000万个数据点，无需依赖诱导点或近似方法。


<details>
  <summary>Details</summary>
Motivation: 现有高斯过程扩展方法大多依赖各种近似，降低了预测精度和不确定性量化能力，并限制了核函数和噪声模型设计的灵活性，这在非平稳核函数日益重要的背景下是不可接受的。

Method: 利用高度灵活、紧支撑和非平稳的核函数来识别协方差矩阵中自然出现的稀疏结构，然后利用这种稀疏性进行线性系统求解和对数行列式计算以进行训练。

Result: 在多个真实世界数据集上验证了方法的有效性，与最先进的近似算法相比，在许多情况下显示出优越的近似性能。

Conclusion: 该方法的关键优势在于对任意高斯过程定制（核心核设计、噪声和均值函数）以及输入空间类型的不可知性，使其非常适合现代高斯过程应用。

Abstract: Despite a large corpus of recent work on scaling up Gaussian processes, a stubborn trade-off between computational speed, prediction and uncertainty quantification accuracy, and customizability persists. This is because the vast majority of existing methodologies exploit various levels of approximations that lower accuracy and limit the flexibility of kernel and noise-model designs -- an unacceptable drawback at a time when expressive non-stationary kernels are on the rise in many fields. Here, we propose a methodology we term \emph{gp2Scale} that scales exact Gaussian processes to more than 10 million data points without relying on inducing points, kernel interpolation, or neighborhood-based approximations, and instead leveraging the existing capabilities of a GP: its kernel design. Highly flexible, compactly supported, and non-stationary kernels lead to the identification of naturally occurring sparse structure in the covariance matrix, which is then exploited for the calculations of the linear system solution and the log-determinant for training. We demonstrate our method's functionality on several real-world datasets and compare it with state-of-the-art approximation algorithms. Although we show superior approximation performance in many cases, the method's real power lies in its agnosticism toward arbitrary GP customizations -- core kernel design, noise, and mean functions -- and the type of input space, making it optimally suited for modern Gaussian process applications.

</details>


### [297] [Learning Invariant Graph Representations Through Redundant Information](https://arxiv.org/abs/2512.06154)
*Barproda Halder,Pasan Dissanayake,Sanghamitra Dutta*

Main category: cs.LG

TL;DR: 该论文提出了一种基于部分信息分解(PID)的冗余引导不变图学习(RIG)框架，用于解决图表示学习中分布外(OOD)泛化问题，通过分离冗余信息来提高模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于经典信息论的图表示学习方法难以有效分离虚假成分，导致学习到的表示仍保留虚假信息，影响OOD泛化性能。需要更精确地识别和处理虚假子图与不变子图之间的冗余信息。

Method: 提出RIG多级优化框架：1)使用PID识别虚假子图Gs和不变子图Gc之间的冗余信息；2)交替进行冗余信息下界估计和最大化；3)结合额外目标函数分离虚假和因果子图。

Result: 在合成和真实图数据集上的实验表明，RIG框架能够有效提升模型在多种分布偏移下的泛化能力。

Conclusion: PID为图表示学习提供了超越经典信息论的新工具，RIG框架通过冗余信息引导成功实现了更好的OOD泛化性能。

Abstract: Learning invariant graph representations for out-of-distribution (OOD) generalization remains challenging because the learned representations often retain spurious components. To address this challenge, this work introduces a new tool from information theory called Partial Information Decomposition (PID) that goes beyond classical information-theoretic measures. We identify limitations in existing approaches for invariant representation learning that solely rely on classical information-theoretic measures, motivating the need to precisely focus on redundant information about the target $Y$ shared between spurious subgraphs $G_s$ and invariant subgraphs $G_c$ obtained via PID. Next, we propose a new multi-level optimization framework that we call -- Redundancy-guided Invariant Graph learning (RIG) -- that maximizes redundant information while isolating spurious and causal subgraphs, enabling OOD generalization under diverse distribution shifts. Our approach relies on alternating between estimating a lower bound of redundant information (which itself requires an optimization) and maximizing it along with additional objectives. Experiments on both synthetic and real-world graph datasets demonstrate the generalization capabilities of our proposed RIG framework.

</details>


### [298] [PMA-Diffusion: A Physics-guided Mask-Aware Diffusion Framework for TSE from Sparse Observations](https://arxiv.org/abs/2512.06183)
*Lindong Liu,Zhixiong Jin,Seongjin Choi*

Main category: cs.LG

TL;DR: PMA-Diffusion是一个物理引导的掩码感知扩散框架，能够从稀疏观测数据中重建高速公路速度场，在严重稀疏性（仅5%可见度）下仍优于其他基线方法。


<details>
  <summary>Details</summary>
Motivation: 高速公路高分辨率交通状态信息对智能交通系统至关重要，但传统交通数据（如环形探测器和探测车辆）通常过于稀疏和嘈杂，无法捕捉交通流的详细动态。

Method: 提出两种掩码感知训练策略（单掩码和双掩码），在推理阶段采用物理引导的后验采样器，交替进行反向扩散更新、观测投影和基于自适应各向异性平滑的物理引导投影。

Result: 在I-24 MOTION数据集上测试，即使在仅5%可见度的严重稀疏条件下，PMA-Diffusion在三个重建误差指标上均优于其他基线方法，且训练于稀疏观测的模型性能接近基于完整观测的基线模型。

Conclusion: 将掩码感知扩散先验与物理引导后验采样器相结合，为现实感知稀疏性下的交通状态估计提供了可靠且灵活的解决方案。

Abstract: High-resolution highway traffic state information is essential for Intelligent Transportation Systems, but typical traffic data acquired from loop detectors and probe vehicles are often too sparse and noisy to capture the detailed dynamics of traffic flow. We propose PMA-Diffusion, a physics-guided mask-aware diffusion framework that reconstructs unobserved highway speed fields from sparse, incomplete observations. Our approach trains a diffusion prior directly on sparsely observed speed fields using two mask-aware training strategies: Single-Mask and Double-Mask. At the inference phase, the physics-guided posterior sampler alternates reverse-diffusion updates, observation projection, and physics-guided projection based on adaptive anisotropic smoothing to reconstruct the missing speed fields. The proposed framework is tested on the I-24 MOTION dataset with varying visibility ratios. Even under severe sparsity, with only 5% visibility, PMA-Diffusion outperforms other baselines across three reconstruction error metrics. Furthermore, PMA-diffusion trained with sparse observation nearly matches the performance of the baseline model trained on fully observed speed fields. The results indicate that combining mask-aware diffusion priors with a physics-guided posterior sampler provides a reliable and flexible solution for traffic state estimation under realistic sensing sparsity.

</details>


### [299] [How Should We Evaluate Data Deletion in Graph-Based ANN Indexes?](https://arxiv.org/abs/2512.06200)
*Tomohiro Yamashita,Daichi Amagata,Yusuke Matsui*

Main category: cs.LG

TL;DR: 本文提出了一个评估框架和指标来评估动态数据中近似最近邻搜索（ANNS）索引的数据删除效率，将图基ANNS的数据删除方法分为三类并数学形式化，最后应用于HNSW方法并提出动态选择删除方法的Deletion Control策略。


<details>
  <summary>Details</summary>
Motivation: 由于检索增强生成等应用需要支持动态数据的ANNS算法，但现有研究缺乏对数据删除的全面评估方法，因此需要建立系统的评估框架。

Method: 将图基ANNS的数据删除方法分为三类并数学形式化，提出包含准确性、查询速度等指标的综合评估框架，应用于HNSW方法并开发Deletion Control策略。

Result: 建立了数据删除的评估框架，通过实验验证了不同删除方法对ANNS性能的影响，提出的Deletion Control方法能根据所需搜索精度动态选择最优删除策略。

Conclusion: 该研究填补了ANNS数据删除评估的空白，提出的框架和方法为动态ANNS系统的实际应用提供了重要指导，Deletion Control策略能有效平衡删除效率和搜索性能。

Abstract: Approximate Nearest Neighbor Search (ANNS) has recently gained significant attention due to its many applications, such as Retrieval-Augmented Generation. Such applications require ANNS algorithms that support dynamic data, so the ANNS problem on dynamic data has attracted considerable interest. However, a comprehensive evaluation methodology for data deletion in ANNS has yet to be established. This study proposes an experimental framework and comprehensive evaluation metrics to assess the efficiency of data deletion for ANNS indexes under practical use cases. Specifically, we categorize data deletion methods in graph-based ANNS into three approaches and formalize them mathematically. The performance is assessed in terms of accuracy, query speed, and other relevant metrics. Finally, we apply the proposed evaluation framework to Hierarchical Navigable Small World, one of the state-of-the-art ANNS methods, to analyze the effects of data deletion, and propose Deletion Control, a method which dynamically selects the appropriate deletion method under a required search accuracy.

</details>


### [300] [K2-V2: A 360-Open, Reasoning-Enhanced LLM](https://arxiv.org/abs/2512.06201)
*K2 Team,Zhengzhong Liu,Liping Tang,Linghao Jin,Haonan Li,Nikhil Ranjan,Desai Fan,Shaurya Rohatgi,Richard Fan,Omkar Pangarkar,Huijuan Wang,Zhoujun Cheng,Suqi Sun,Seungwook Han,Bowen Tan,Gurpreet Gosal,Xudong Han,Varad Pimpalkhute,Shibo Hao,Ming Shan Hee,Joel Hestness,Haolong Jia,Liqun Ma,Aaryamonvikram Singh,Daria Soboleva,Natalia Vassilieva,Renxi Wang,Yingquan Wu,Yuekai Sun,Taylor Killian,Alexander Moreno,John Maggs,Hector Ren,Guowei He,Hongyi Wang,Xuezhe Ma,Yuqi Wang,Mikhail Yurochkin,Eric P. Xing*

Main category: cs.LG

TL;DR: K2-V2是一个从头构建的360度开放LLM，专为推理适应而设计，在推理能力上超越同尺寸开源模型，接近更大规模模型的性能。


<details>
  <summary>Details</summary>
Motivation: 构建一个专门针对复杂推理任务优化的开源基础模型，填补当前开源模型在推理能力方面的不足，为社区提供强大的推理中心基础。

Method: 在训练过程中主动注入领域知识、推理能力、长上下文和工具使用能力，通过简单的监督微调建立强基线。

Result: K2-V2成为最强的完全开源模型，在同等尺寸下超越Qwen2.5-72B，接近Qwen3-235B的性能表现。

Conclusion: 通过发布完整的训练历史和数据组合，最大化持续训练的效果，为社区提供一个能力强大、以推理为中心的基础模型。

Abstract: We introduce K2-V2, a 360-open LLM built from scratch as a superior base for reasoning adaptation, in addition to functions such as conversation and knowledge retrieval from general LLMs. It stands as the strongest fully open model, rivals open-weight leaders in its size class, outperforms Qwen2.5-72B and approaches the performance of Qwen3-235B. We actively infuse domain knowledge, reasoning, long-context, and tool use throughout the training process. This explicitly prepares the model for complex reasoning tasks. We demonstrate this potential using simple supervised fine-tuning, establishing a strong baseline that indicates significant headroom for advanced alignment. By releasing the full training history and data composition, we maximize the effectiveness of continuous training, a key open source production scenario. We release the model weights and signature LLM360 artifacts, such as complete training data, to empower the community with a capable, reasoning-centric foundation.

</details>


### [301] [Quantifying Memory Use in Reinforcement Learning with Temporal Range](https://arxiv.org/abs/2512.06204)
*Rodney Lafuente-Mercado,Daniela Rus,T. Konstantin Rusch*

Main category: cs.LG

TL;DR: 本文提出了Temporal Range指标，用于量化训练好的强化学习策略对过去观察的依赖程度，通过分析输出对输入序列的时间敏感性来评估记忆依赖。


<details>
  <summary>Details</summary>
Motivation: 研究训练好的RL策略实际使用过去观察的程度，为比较不同智能体和环境提供量化指标，帮助选择最短有效上下文窗口。

Method: 提出Temporal Range指标，通过反向自动微分计算Jacobian块，分析多向量输出对输入序列的一阶敏感性，形成时间影响分布，并用幅度加权平均滞后进行总结。

Result: 在诊断和控制任务中，Temporal Range在完全观察控制中保持较小，在Copy-k任务中与真实滞后尺度一致，与窗口消融实验确认的最小历史窗口需求相匹配。

Conclusion: Temporal Range提供了一个实用的序列级记忆依赖度量，可用于比较智能体和环境，以及选择最短足够上下文。

Abstract: How much does a trained RL policy actually use its past observations? We propose \emph{Temporal Range}, a model-agnostic metric that treats first-order sensitivities of multiple vector outputs across a temporal window to the input sequence as a temporal influence profile and summarizes it by the magnitude-weighted average lag. Temporal Range is computed via reverse-mode automatic differentiation from the Jacobian blocks $\partial y_s/\partial x_t\in\mathbb{R}^{c\times d}$ averaged over final timesteps $s\in\{t+1,\dots,T\}$ and is well-characterized in the linear setting by a small set of natural axioms. Across diagnostic and control tasks (POPGym; flicker/occlusion; Copy-$k$) and architectures (MLPs, RNNs, SSMs), Temporal Range (i) remains small in fully observed control, (ii) scales with the task's ground-truth lag in Copy-$k$, and (iii) aligns with the minimum history window required for near-optimal return as confirmed by window ablations. We also report Temporal Range for a compact Long Expressive Memory (LEM) policy trained on the task, using it as a proxy readout of task-level memory. Our axiomatic treatment draws on recent work on range measures, specialized here to temporal lag and extended to vector-valued outputs in the RL setting. Temporal Range thus offers a practical per-sequence readout of memory dependence for comparing agents and environments and for selecting the shortest sufficient context.

</details>


### [302] [Average-reward reinforcement learning in semi-Markov decision processes via relative value iteration](https://arxiv.org/abs/2512.06218)
*Huizhen Yu,Yi Wan,Richard S. Sutton*

Main category: cs.LG

TL;DR: 本文应用异步随机逼近理论到平均奖励半马尔可夫决策过程的强化学习中，建立了RVI Q-learning算法的收敛性，并提出了新的单调性条件来估计最优奖励率。


<details>
  <summary>Details</summary>
Motivation: 将Borkar-Meyn框架下的异步随机逼近理论应用于半马尔可夫决策过程的强化学习，扩展Schweitzer经典相对值迭代算法到异步设置。

Method: 使用异步随机逼近方法，建立RVI Q-learning算法的收敛性分析，引入新的单调性条件来估计最优奖励率。

Result: 证明算法几乎必然收敛到平均奖励最优性方程解集的紧致连通子集，在额外步长和异步条件下收敛到唯一解。

Conclusion: 提出的新单调性条件显著扩展了现有算法框架，通过稳定性分析和收敛分析的新论证方法解决了相关问题。

Abstract: This paper applies the authors' recent results on asynchronous stochastic approximation (SA) in the Borkar-Meyn framework to reinforcement learning in average-reward semi-Markov decision processes (SMDPs). We establish the convergence of an asynchronous SA analogue of Schweitzer's classical relative value iteration algorithm, RVI Q-learning, for finite-space, weakly communicating SMDPs. In particular, we show that the algorithm converges almost surely to a compact, connected subset of solutions to the average-reward optimality equation, with convergence to a unique, sample path-dependent solution under additional stepsize and asynchrony conditions. Moreover, to make full use of the SA framework, we introduce new monotonicity conditions for estimating the optimal reward rate in RVI Q-learning. These conditions substantially expand the previously considered algorithmic framework and are addressed through novel arguments in the stability and convergence analysis of RVI Q-learning.

</details>


### [303] [Back to Author Console Empowering GNNs for Domain Adaptation via Denoising Target Graph](https://arxiv.org/abs/2512.06236)
*Haiyang Yu,Meng-Chieh Lee,Xiang song,Qi Zhu,Christos Faloutsos*

Main category: cs.LG

TL;DR: 该论文提出GraphDeT框架，通过在目标图上添加边去噪的辅助损失函数来提升图神经网络在领域自适应中的节点分类性能，理论分析表明该辅助任务能够收紧图泛化边界，实验证明在时间和区域领域图偏移场景下优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 图结构领域偏移（如不同时间或区域采集的图数据）导致图神经网络在目标图上性能下降，需要解决图领域自适应问题以提升泛化能力。

Method: 提出GraphDeT框架，在图神经网络训练中集成边去噪的辅助任务，通过理论分析将辅助任务与图泛化边界联系起来，证明其能够收紧泛化边界。

Result: 实验结果表明，GraphDeT在处理时间和区域领域图偏移时，节点分类性能显著优于现有基线方法。

Conclusion: 简单的边去噪辅助任务能有效提升图神经网络在领域自适应中的泛化性能，GraphDeT框架为解决图结构领域偏移提供了有效方案。

Abstract: We explore the node classification task in the context of graph domain adaptation, which uses both source and target graph structures along with source labels to enhance the generalization capabilities of Graph Neural Networks (GNNs) on target graphs. Structure domain shifts frequently occur, especially when graph data are collected at different times or from varying areas, resulting in poor performance of GNNs on target graphs. Surprisingly, we find that simply incorporating an auxiliary loss function for denoising graph edges on target graphs can be extremely effective in enhancing GNN performance on target graphs. Based on this insight, we propose our framework, GraphDeT, a framework that integrates this auxiliary edge task into GNN training for node classification under domain adaptation. Our theoretical analysis connects this auxiliary edge task to the graph generalization bound with -distance, demonstrating such auxiliary task can imposes a constraint which tightens the bound and thereby improves generalization. The experimental results demonstrate superior performance compared to the existing baselines in handling both time and regional domain graph shifts.

</details>


### [304] [Quantization Blindspots: How Model Compression Breaks Backdoor Defenses](https://arxiv.org/abs/2512.06243)
*Rohan Pandey,Eric Ye*

Main category: cs.LG

TL;DR: 本文系统研究了后门防御在模型量化后的表现，发现INT8量化会使所有防御检测率降至0%，而INT4量化的效果因数据集而异，暴露了当前防御评估与实际部署之间的不匹配问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界中模型部署通常采用量化技术来减少内存和延迟，但现有后门防御研究主要在FP32精度下进行评估，缺乏对量化后防御效果的了解。

Method: 在三个精度设置（FP32、INT8动态、INT4模拟）和两个标准视觉基准上，对五种代表性后门防御进行系统实证研究，使用经典的BadNet攻击。

Result: INT8量化使所有防御检测率降至0%，而攻击成功率仍高于99%；INT4量化效果因数据集而异（在GTSRB上有效，在CIFAR-10上失效），但后门攻击成功率仍高于90%。

Conclusion: 量化鲁棒性应成为未来后门防御评估和设计的必要维度，需要解决防御评估与实际部署之间的不匹配问题。

Abstract: Backdoor attacks embed input-dependent malicious behavior into neural networks while preserving high clean accuracy, making them a persistent threat for deployed ML systems. At the same time, real-world deployments almost never serve full-precision models: post-training quantization to INT8 or lower precision is now standard practice for reducing memory and latency. This work asks a simple question: how do existing backdoor defenses behave under standard quantization pipelines? We conduct a systematic empirical study of five representative defenses across three precision settings (FP32, INT8 dynamic, INT4 simulated) and two standard vision benchmarks using a canonical BadNet attack. We observe that INT8 quantization reduces the detection rate of all evaluated defenses to 0% while leaving attack success rates above 99%. For INT4, we find a pronounced dataset dependence: Neural Cleanse remains effective on GTSRB but fails on CIFAR-10, even though backdoors continue to survive quantization with attack success rates above 90%. Our results expose a mismatch between how defenses are commonly evaluated (on FP32 models) and how models are actually deployed (in quantized form), and they highlight quantization robustness as a necessary axis in future evaluations and designs of backdoor defenses.

</details>


### [305] [Auto-exploration for online reinforcement learning](https://arxiv.org/abs/2512.06244)
*Caleb Ju,Guanghui Lan*

Main category: cs.LG

TL;DR: 本文提出了一种新的自动探索强化学习方法，通过参数自由的方式解决探索-利用困境，避免了传统方法对问题相关参数的依赖，实现了更优的样本复杂度和可实施性。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习算法需要假设充分探索状态和动作空间，这导致算法不可实施且性能次优。需要开发能够自动探索的参数自由方法。

Method: 提出了两种变体：表格设置和线性函数逼近。采用动态混合时间、折扣状态分布采样、鲁棒梯度估计器和优势差距函数等新算法创新。

Result: 在存在探索最优策略的假设下，两种方法都达到了O(ε⁻²)的样本复杂度，且复杂度不包含算法相关参数。

Conclusion: 新方法实现了参数自由、易于实施的自动探索，解决了传统RL算法的局限性，为高效强化学习提供了新思路。

Abstract: The exploration-exploitation dilemma in reinforcement learning (RL) is a fundamental challenge to efficient RL algorithms. Existing algorithms for finite state and action discounted RL problems address this by assuming sufficient exploration over both state and action spaces. However, this yields non-implementable algorithms and sub-optimal performance. To resolve these limitations, we introduce a new class of methods with auto-exploration, or methods that automatically explore both state and action spaces in a parameter-free way, i.e.,~without a priori knowledge of problem-dependent parameters. We present two variants: one for the tabular setting and one for linear function approximation. Under algorithm-independent assumptions on the existence of an exploring optimal policy, both methods attain $O(ε^{-2})$ sample complexity to solve to $ε$ error. Crucially, these complexities are novel since they are void of algorithm-dependent parameters seen in prior works, which may be arbitrarily large. The methods are also simple to implement because they are parameter-free and do not directly estimate the unknown parameters. These feats are achieved by new algorithmic innovations for RL, including a dynamic mixing time, a discounted state distribution for sampling, a simple robust gradient estimator, and a recent advantage gap function to certify convergence.

</details>


### [306] [Learning When to Switch: Adaptive Policy Selection via Reinforcement Learning](https://arxiv.org/abs/2512.06250)
*Chris Tava*

Main category: cs.LG

TL;DR: 该研究提出了一种基于强化学习的自适应策略切换方法，让智能体在迷宫导航任务中动态切换系统探索和目标导向两种策略，相比固定阈值方法显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 自主智能体在解决复杂任务时需要多种策略，但确定何时切换策略具有挑战性。现有固定阈值方法无法适应不同任务环境，需要一种能够动态学习切换时机的技术。

Method: 使用Q-learning算法学习策略切换阈值，将状态空间离散化为覆盖率和距离目标距离的桶。智能体不需要预先知道墙壁位置或最优阈值，仅需迷宫尺寸和目标位置等最小领域知识。

Result: 在240个测试配置中，自适应阈值学习方法相比单策略智能体和固定40%阈值基线，完成时间提升23-55%，运行时方差降低83%，最坏情况性能提升71%。性能增益随问题复杂度增加而提升。

Conclusion: 自适应策略切换方法能够有效提升智能体在复杂环境中的性能，且该方法具有良好的泛化能力，随着问题复杂度的增加，自适应策略选择的价值更加显著。

Abstract: Autonomous agents often require multiple strategies to solve complex tasks, but determining when to switch between strategies remains challenging. This research introduces a reinforcement learning technique to learn switching thresholds between two orthogonal navigation policies. Using maze navigation as a case study, this work demonstrates how an agent can dynamically transition between systematic exploration (coverage) and goal-directed pathfinding (convergence) to improve task performance. Unlike fixed-threshold approaches, the agent uses Q-learning to adapt switching behavior based on coverage percentage and distance to goal, requiring only minimal domain knowledge: maze dimensions and target location. The agent does not require prior knowledge of wall positions, optimal threshold values, or hand-crafted heuristics; instead, it discovers effective switching strategies dynamically during each run. The agent discretizes its state space into coverage and distance buckets, then adapts which coverage threshold (20-60\%) to apply based on observed progress signals. Experiments across 240 test configurations (4 maze sizes from 16$\times$16 to 128$\times$128 $\times$ 10 unique mazes $\times$ 6 agent variants) demonstrate that adaptive threshold learning outperforms both single-strategy agents and fixed 40\% threshold baselines. Results show 23-55\% improvements in completion time, 83\% reduction in runtime variance, and 71\% improvement in worst-case scenarios. The learned switching behavior generalizes within each size class to unseen wall configurations. Performance gains scale with problem complexity: 23\% improvement for 16$\times$16 mazes, 34\% for 32$\times$32, and 55\% for 64$\times$64, demonstrating that as the space of possible maze structures grows, the value of adaptive policy selection over fixed heuristics increases proportionally.

</details>


### [307] [Learning Without Time-Based Embodiment Resets in Soft-Actor Critic](https://arxiv.org/abs/2512.06252)
*Homayoon Farrahi,A. Rupam Mahmood*

Main category: cs.LG

TL;DR: 本文研究了在强化学习中不使用episode终止和机器人环境重置的挑战，提出了continuing SAC算法，并通过实验证明通过调整奖励函数和增加策略熵可以恢复因不使用环境重置而导致的性能损失。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习任务中常用的episode终止和环境重置等辅助组件虽然能加速学习过程，但会导致不自然的任务设置并阻碍在现实世界中的长期性能。本文旨在探索在没有这些辅助组件情况下的学习挑战。

Method: 提出了continuing版本的Soft Actor-Critic (SAC)算法，通过简单修改现有任务的奖励函数，并在性能下降或停滞时增加策略的熵来改善学习效果。

Result: continuing SAC在修改后的Gym Reacher任务上表现与episodic SAC相当或更好，同时降低了对折扣率γ值的敏感性。实验表明环境重置有助于状态空间探索，移除重置会导致学习失败或显著变慢。

Conclusion: 通过适当调整奖励函数和增加策略熵，可以有效补偿因不使用环境重置而导致的性能损失，为在更自然环境中进行长期强化学习提供了可行方案。

Abstract: When creating new reinforcement learning tasks, practitioners often accelerate the learning process by incorporating into the task several accessory components, such as breaking the environment interaction into independent episodes and frequently resetting the environment. Although they can enable the learning of complex intelligent behaviors, such task accessories can result in unnatural task setups and hinder long-term performance in the real world. In this work, we explore the challenges of learning without episode terminations and robot embodiment resets using the Soft Actor-Critic (SAC) algorithm. To learn without terminations, we present a continuing version of the SAC algorithm and show that, with simple modifications to the reward functions of existing tasks, continuing SAC can perform as well as or better than episodic SAC while reducing the sensitivity of performance to the value of the discount rate $γ$. On a modified Gym Reacher task, we investigate possible explanations for the failure of continuing SAC when learning without embodiment resets. Our results suggest that embodiment resets help with exploration of the state space in the SAC algorithm, and removing embodiment resets can lead to poor exploration of the state space and failure of or significantly slower learning. Finally, on additional simulated tasks and a real-robot vision task, we show that increasing the entropy of the policy when performance trends worse or remains static is an effective intervention for recovering the performance lost due to not using embodiment resets.

</details>


### [308] [Networked Restless Multi-Arm Bandits with Reinforcement Learning](https://arxiv.org/abs/2512.06274)
*Hanmo Zhang,Zenghui Sun,Kai Wang*

Main category: cs.LG

TL;DR: 该论文提出了网络化RMAB框架，将RMAB模型与独立级联模型结合，以捕捉网络环境中个体间的交互作用，解决了传统RMAB假设独立性的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统RMAB假设各臂独立，无法处理现实世界中个体间的交互作用，这限制了其在公共卫生等领域的应用效果。

Method: 定义了网络化RMAB的贝尔曼方程，通过证明贝尔曼方程的子模性并应用爬山算法，在贝尔曼更新中实现1-1/e的近似保证，并开发了针对网络环境的高效Q学习算法。

Result: 实验结果表明，在真实图数据上，所提出的Q学习方法优于k步前瞻和网络盲方法，验证了捕捉网络效应的重要性。

Conclusion: 网络化RMAB框架能够有效处理个体间交互，通过理论分析和实验验证证明了其优越性和实用性。

Abstract: Restless Multi-Armed Bandits (RMABs) are a powerful framework for sequential decision-making, widely applied in resource allocation and intervention optimization challenges in public health. However, traditional RMABs assume independence among arms, limiting their ability to account for interactions between individuals that can be common and significant in a real-world environment. This paper introduces Networked RMAB, a novel framework that integrates the RMAB model with the independent cascade model to capture interactions between arms in networked environments. We define the Bellman equation for networked RMAB and present its computational challenge due to exponentially large action and state spaces. To resolve the computational challenge, we establish the submodularity of Bellman equation and apply the hill-climbing algorithm to achieve a $1-\frac{1}{e}$ approximation guarantee in Bellman updates. Lastly, we prove that the approximate Bellman updates are guaranteed to converge by a modified contraction analysis. We experimentally verify these results by developing an efficient Q-learning algorithm tailored to the networked setting. Experimental results on real-world graph data demonstrate that our Q-learning approach outperforms both $k$-step look-ahead and network-blind approaches, highlighting the importance of capturing and leveraging network effects where they exist.

</details>


### [309] [Theoretical Compression Bounds for Wide Multilayer Perceptrons](https://arxiv.org/abs/2512.06288)
*Houssam El Cheairi,David Gamarnik,Rahul Mazumder*

Main category: cs.LG

TL;DR: 本文提出了一种随机贪婪压缩算法，用于训练后剪枝和量化，并严格证明了在多层感知器（MLPs）中存在性能具有竞争力的剪枝/量化子网络。研究还扩展到结构化剪枝，展示了压缩性与网络宽度之间的权衡关系。


<details>
  <summary>Details</summary>
Motivation: 尽管剪枝和量化技术在减少大型神经网络参数数量方面取得了广泛成功，但对其经验成功的理论解释仍然不足。本文旨在填补这一理论空白，为压缩技术的实际应用提供理论依据。

Method: 采用随机贪婪压缩算法，该算法与Optimal Brain Damage（OBD）有相似之处，可视为其训练后随机版本。算法应用于多层感知器和卷积神经网络的剪枝和量化。

Result: 研究证明了在宽网络中存在性能具有竞争力的剪枝/量化子网络，且结果不依赖于数据假设。发现了压缩性与网络宽度之间的权衡关系。

Conclusion: 本文的理论结果弥合了剪枝/量化理论与应用之间的差距，为宽多层感知器中压缩技术的经验成功提供了理论解释。

Abstract: Pruning and quantization techniques have been broadly successful in reducing the number of parameters needed for large neural networks, yet theoretical justification for their empirical success falls short. We consider a randomized greedy compression algorithm for pruning and quantization post-training and use it to rigorously show the existence of pruned/quantized subnetworks of multilayer perceptrons (MLPs) with competitive performance. We further extend our results to structured pruning of MLPs and convolutional neural networks (CNNs), thus providing a unified analysis of pruning in wide networks. Our results are free of data assumptions, and showcase a tradeoff between compressibility and network width. The algorithm we consider bears some similarities with Optimal Brain Damage (OBD) and can be viewed as a post-training randomized version of it. The theoretical results we derive bridge the gap between theory and application for pruning/quantization, and provide a justification for the empirical success of compression in wide multilayer perceptrons.

</details>


### [310] [Importance-aware Topic Modeling for Discovering Public Transit Risk from Noisy Social Media](https://arxiv.org/abs/2512.06293)
*Fatima Ashraf,Muhammad Ayub Sabir,Jiaxin Deng,Junbiao Pang,Haitao Yu*

Main category: cs.LG

TL;DR: 本文提出了一种联合建模语言交互和用户影响力的方法，用于从社交媒体中检测稀疏的城市交通服务风险信号。


<details>
  <summary>Details</summary>
Motivation: 城市交通机构使用社交媒体监控服务风险（如拥挤、延误、安全事件），但相关信号稀疏、简短且易被常规信息淹没。

Method: 构建影响力加权的关键词共现图，采用泊松反卷积分解（PDF）将图分解为低秩主题结构和主题局部残差交互，结合去相关正则化和轻量优化过程。

Result: 在大规模社交数据流上，该模型实现了最先进的主题连贯性和强多样性。

Conclusion: 该方法能有效提取社交媒体中的稀疏风险信号，代码和数据集已公开。

Abstract: Urban transit agencies increasingly turn to social media to monitor emerging service risks such as crowding, delays, and safety incidents, yet the signals of concern are sparse, short, and easily drowned by routine chatter. We address this challenge by jointly modeling linguistic interactions and user influence. First, we construct an influence-weighted keyword co-occurrence graph from cleaned posts so that socially impactful posts contributes proportionally to the underlying evidence. The core of our framework is a Poisson Deconvolution Factorization (PDF) that decomposes this graph into a low-rank topical structure and topic-localized residual interactions, producing an interpretable topic--keyword basis together with topic importance scores. A decorrelation regularizer \emph{promotes} distinct topics, and a lightweight optimization procedure ensures stable convergence under nonnegativity and normalization constraints. Finally, the number of topics is selected through a coherence-driven sweep that evaluates the quality and distinctness of the learned topics. On large-scale social streams, the proposed model achieves state-of-the-art topic coherence and strong diversity compared with leading baselines. The code and dataset are publicly available at https://github.com/pangjunbiao/Topic-Modeling_ITS.git

</details>


### [311] [Entropic Confinement and Mode Connectivity in Overparameterized Neural Networks](https://arxiv.org/abs/2512.06297)
*Luca Di Carlo,Chase Goddard,David J. Schwab*

Main category: cs.LG

TL;DR: 该论文揭示了神经网络损失景观中一个悖论：虽然吸引盆之间存在低损失路径，但优化动态通常局限在单个凸盆内。研究发现这是由于曲率变化与优化噪声相互作用产生的熵势垒导致的。


<details>
  <summary>Details</summary>
Motivation: 解决神经网络优化中存在的矛盾现象：尽管损失景观中存在连接不同吸引盆的低损失路径，但优化算法通常无法探索这些路径，而是被困在单个凸盆内。

Method: 通过分析曲率沿低损失路径的变化规律，研究曲率变化与优化动态噪声的相互作用，识别熵势垒的形成机制。

Result: 实证发现曲率在远离最小值时系统性上升，产生将噪声动态偏向端点的有效力，即使损失保持近乎平坦。这些熵势垒比能量势垒持续更久，塑造了参数空间中解的后期定位。

Conclusion: 研究结果表明曲率诱导的熵力在深度学习景观中同时控制着连通性和约束性，解释了为什么优化算法难以探索连接不同吸引盆的路径。

Abstract: Modern neural networks exhibit a striking property: basins of attraction in the loss landscape are often connected by low-loss paths, yet optimization dynamics generally remain confined to a single convex basin and rarely explore intermediate points. We resolve this paradox by identifying entropic barriers arising from the interplay between curvature variations along these paths and noise in optimization dynamics. Empirically, we find that curvature systematically rises away from minima, producing effective forces that bias noisy dynamics back toward the endpoints - even when the loss remains nearly flat. These barriers persist longer than energetic barriers, shaping the late-time localization of solutions in parameter space. Our results highlight the role of curvature-induced entropic forces in governing both connectivity and confinement in deep learning landscapes.

</details>


### [312] [Chemistry Integrated Language Model using Hierarchical Molecular Representation for Polymer Informatics](https://arxiv.org/abs/2512.06301)
*Jihun Ahn,Gabriella Pasya Irianti,Vikram Thapar,Su-Mi Hur*

Main category: cs.LG

TL;DR: CI-LLM框架通过HAPPY分子表示和数值描述符，在聚合物科学中实现了高效的属性预测和逆向设计，克服了数据稀缺的限制。


<details>
  <summary>Details</summary>
Motivation: 机器学习在无机化合物和小分子材料发现中取得了成功，但聚合物领域由于数据稀缺等问题进展缓慢。本文旨在通过创新的分子表示方法突破这一瓶颈。

Method: 提出CI-LLM框架，结合HAPPY（分层抽象聚合物重复单元）将化学亚结构编码为token，并在Transformer架构中整合数值描述符。使用De³BERTa进行属性预测，GPT模型进行逆向设计。

Result: De³BERTa比基于SMILES的模型推理速度快3.5倍，在四个属性上的R²得分提升0.9-4.1%。GPT生成器实现100%支架保留，成功优化负相关目标的多属性。

Conclusion: 该框架展示了战略分子表示如何推动聚合物科学中的机器学习应用，具备正向预测和逆向设计的综合能力。

Abstract: Machine learning has transformed material discovery for inorganic compounds and small molecules, yet polymers remain largely inaccessible to these methods. While data scarcity is often cited as the primary bottleneck, we demonstrate that strategic molecular representations can overcome this limitation. We introduce CI-LLM (Chemically Informed Language Model), a framework combining HAPPY (Hierarchically Abstracted rePeat unit of PolYmer), which encodes chemical substructures as tokens, with numerical descriptors within transformer architectures. For property prediction, De$^3$BERTa, our descriptor-enriched encoder, achieves 3.5x faster inference than SMILES-based models with improved accuracy ($R^2$ score gains of 0.9-4.1 percent across four properties), while providing interpretable structure-property insights at the subgroup level. For inverse design, our GPT-based generator produces polymers with targeted properties, achieving 100 percent scaffold retention and successful multi-property optimization for negatively correlated objectives. This comprehensive framework demonstrates both forward prediction and inverse design capabilities, showcasing how strategic molecular representation advances machine learning applications in polymer science.

</details>


### [313] [Multimodal Graph Neural Networks for Prognostic Modeling of Brain Network Reorganization](https://arxiv.org/abs/2512.06303)
*Preksha Girish,Rachana Mysore,Kiran K. N.,Hiranmayee R.,Shipra Prashanth,Shrey Kumar*

Main category: cs.LG

TL;DR: 本文提出了一种多模态图神经网络框架，整合结构MRI、扩散张量成像和功能MRI，用于模拟大脑网络的时空重组动态，并生成可解释的生物标志物来量化个体认知衰退风险。


<details>
  <summary>Details</summary>
Motivation: 理解大脑网络的动态重组对于预测认知衰退、神经进展和临床结果的个体差异至关重要。现有方法需要新的数学框架来捕捉长期依赖性和随机波动。

Method: 使用多模态图神经网络，将大脑区域表示为节点，结构和功能连接作为边，形成纵向大脑图。通过分数随机微分算子和基于图的循环网络捕捉时间演化，注意力机制融合多模态信息并生成可解释的生物标志物。

Result: 在纵向神经影像数据集上的实验证明了预测准确性和可解释性。生成的生物标志物（网络能量熵、图曲率、分数记忆指数等）能够有效量化个体网络不稳定或认知衰退风险。

Conclusion: 该方法展示了数学严谨的多模态图网络方法在从现有影像数据中推导临床有意义生物标志物的潜力，无需新数据收集。

Abstract: Understanding the dynamic reorganization of brain networks is critical for predicting cognitive decline, neurological progression, and individual variability in clinical outcomes. This work proposes a multimodal graph neural network framework that integrates structural MRI, diffusion tensor imaging, and functional MRI to model spatiotemporal brain network reorganization. Brain regions are represented as nodes and structural and functional connectivity as edges, forming longitudinal brain graphs for each subject. Temporal evolution is captured via fractional stochastic differential operators embedded within graph-based recurrent networks, enabling the modeling of long-term dependencies and stochastic fluctuations in network dynamics. Attention mechanisms fuse multimodal information and generate interpretable biomarkers, including network energy entropy, graph curvature, fractional memory indices, and modality-specific attention scores. These biomarkers are combined into a composite prognostic index to quantify individual risk of network instability or cognitive decline. Experiments on longitudinal neuroimaging datasets demonstrate both predictive accuracy and interpretability. The results highlight the potential of mathematically rigorous, multimodal graph-based approaches for deriving clinically meaningful biomarkers from existing imaging data without requiring new data collection.

</details>


### [314] [Interpretive Efficiency: Information-Geometric Foundations of Data Usefulness](https://arxiv.org/abs/2512.06341)
*Ronald Katende*

Main category: cs.LG

TL;DR: 本文提出了一种名为“解释效率”的新度量方法，用于量化解释性表示如何有效传输任务相关信息，并通过五个公理和实验验证其理论合理性和实用性。


<details>
  <summary>Details</summary>
Motivation: 当前机器学习可解释性研究中缺乏能够量化数据如何有效支持解释性表示的度量标准，需要一种理论严谨且实用的诊断工具。

Method: 提出了解释效率这一标准化、任务感知的函数，基于五个公理（有界性、Blackwell式单调性、数据处理稳定性、容许不变性和渐近一致性），将其与互信息关联并推导局部Fisher几何展开，使用标准经验过程工具建立估计保证。

Result: 在受控图像和信号任务上的实验表明，该度量能够恢复理论排序、揭示被准确性掩盖的表示冗余，并与鲁棒性相关。

Conclusion: 解释效率是一个实用且理论支持的表征设计诊断工具，为可解释机器学习提供了量化评估标准。

Abstract: Interpretability is central to trustworthy machine learning, yet existing metrics rarely quantify how effectively data support an interpretive representation. We propose Interpretive Efficiency, a normalized, task-aware functional that measures the fraction of task-relevant information transmitted through an interpretive channel. The definition is grounded in five axioms ensuring boundedness, Blackwell-style monotonicity, data-processing stability, admissible invariance, and asymptotic consistency. We relate the functional to mutual information and derive a local Fisher-geometric expansion, then establish asymptotic and finite-sample estimation guarantees using standard empirical-process tools. Experiments on controlled image and signal tasks demonstrate that the measure recovers theoretical orderings, exposes representational redundancy masked by accuracy, and correlates with robustness, making it a practical, theory-backed diagnostic for representation design.

</details>


### [315] [When Distance Distracts: Representation Distance Bias in BT-Loss for Reward Models](https://arxiv.org/abs/2512.06343)
*Tong Xie,Andrew Bai,Yuanhao Ban,Yunqi Hong,Haoyu Li,Cho-jui Hsieh*

Main category: cs.LG

TL;DR: 本文分析了Bradley-Terry损失函数在奖励模型训练中的局限性，发现其梯度范数受表示距离影响，导致小距离对的更新过弱而大距离对的更新过强。作者提出NormBT方法，通过自适应配对归一化来平衡表示驱动效应，在多个数据集上显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统的Bradley-Terry损失函数在训练奖励模型时存在梯度不平衡问题：表示距离小的配对即使误排也获得微弱更新，而表示距离大的配对获得过强更新，这影响了模型对细微差别的学习能力。

Method: 提出NormBT方法，这是一种轻量级的自适应配对归一化方案，通过平衡表示驱动效应，将学习信号集中在预测误差上。该方法可直接替换BT损失，计算开销极小。

Result: 在多种LLM骨干网络和数据集上，NormBT一致提升了奖励模型性能，特别是在RewardBench的推理类别中取得了超过5%的显著增益，该类别包含大量小距离配对。

Conclusion: 本研究揭示了广泛使用的BT目标函数的关键局限性，并提供了一种简单有效的修正方案，能够显著改善奖励模型的学习效果。

Abstract: Reward models are central to Large Language Model (LLM) alignment within the framework of RLHF. The standard objective used in reward modeling is the Bradley-Terry (BT) loss, which learns from pairwise data consisting of a pair of chosen and rejected responses. In this work, we analyze the per-sample gradient of BT-loss and show that its norm scales with two distinct components: (1) the difference in predicted rewards between chosen and rejected responses, which reflects the prediction error, and critically, (2) representation distance between the pair measured in the output space of the final layer. While the first term captures the intended training signal, we show that the second term can significantly impact the update magnitude and misalign learning. Specifically, pairs with small representation distance often receive vanishingly weak updates, even when misranked, while pairs with large distance receive disproportionately strong updates. This leads to gradients from large-distance pairs to overshadow those from small-distance pairs, where fine-grained distinctions are especially important. To overcome this limitation, we propose NormBT, an adaptive pair-wise normalization scheme that balances representation-driven effects and focuses learning signals on prediction error. NormBT is a lightweight, drop-in integration to BT loss with negligible overhead. Across various LLM backbones and datasets, NormBT improves reward model performance consistently, with notable gains of over 5% on the Reasoning category of RewardBench, which contains numerous small-distance pairs. This work reveals a key limitation in the widely used BT objective and provides a simple, effective correction.

</details>


### [316] [Zero Generalization Error Theorem for Random Interpolators via Algebraic Geometry](https://arxiv.org/abs/2512.06347)
*Naoki Yoshida,Isao Ishikawa,Masaaki Imaizumi*

Main category: cs.LG

TL;DR: 在师生框架下，理论证明当训练样本数超过某个阈值时，插值器的泛化误差变为0，这主要源于插值器集合在参数空间中的几何结构特性。


<details>
  <summary>Details</summary>
Motivation: 理解大规模模型（如深度神经网络）的高泛化能力是机器学习理论的核心开放问题。现有研究将这种现象归因于SGD的隐式偏置，但实证表明模型本身特性（如随机采样的插值器也能有效泛化）是主要原因。

Method: 采用师生框架，利用代数几何工具数学刻画插值器集合在参数空间中的几何结构，证明泛化误差在训练样本数超过阈值时变为0。

Result: 理论证明随机采样插值器的泛化误差在训练样本数超过由参数空间几何结构决定的阈值时精确变为0。

Conclusion: 模型插值器的泛化能力主要源于其参数空间的几何特性，而非优化算法的隐式偏置，这为理解大规模模型的泛化性能提供了新的理论视角。

Abstract: We theoretically demonstrate that the generalization error of interpolators for machine learning models under teacher-student settings becomes 0 once the number of training samples exceeds a certain threshold. Understanding the high generalization ability of large-scale models such as deep neural networks (DNNs) remains one of the central open problems in machine learning theory. While recent theoretical studies have attributed this phenomenon to the implicit bias of stochastic gradient descent (SGD) toward well-generalizing solutions, empirical evidences indicate that it primarily stems from properties of the model itself. Specifically, even randomly sampled interpolators, which are parameters that achieve zero training error, have been observed to generalize effectively. In this study, under a teacher-student framework, we prove that the generalization error of randomly sampled interpolators becomes exactly zero once the number of training samples exceeds a threshold determined by the geometric structure of the interpolator set in parameter space. As a proof technique, we leverage tools from algebraic geometry to mathematically characterize this geometric structure.

</details>


### [317] [LLM-Upgraded Graph Reinforcement Learning for Carbon-Aware Job Scheduling in Smart Manufacturing](https://arxiv.org/abs/2512.06351)
*Zhiying Yang,Fang Liu,Wei Zhang,Xin Lou,Malcolm Yoke Hean Low,Boon Ping Gan*

Main category: cs.LG

TL;DR: 本文提出Luca框架，结合图神经网络和大型语言模型，通过强化学习实现碳感知的柔性作业车间调度，在保证排放水平的同时显著降低完工时间。


<details>
  <summary>Details</summary>
Motivation: 解决智能制造系统中动态和可持续调度的挑战，需要在优化完工时间的同时考虑碳排放目标。

Method: 使用图神经网络和LLM生成融合嵌入，捕捉调度状态的结构特征和上下文语义，通过深度强化学习策略网络生成实时调度决策。

Result: 在合成数据集上平均降低完工时间4.1%，最高达12.2%，同时保持相同排放水平；在公开数据集上对完工时间和排放均有额外改善。

Conclusion: Luca框架在智能制造碳感知调度中表现出有效性和实用性。

Abstract: This paper presents \textsc{Luca}, a \underline{l}arge language model (LLM)-\underline{u}pgraded graph reinforcement learning framework for \underline{c}arbon-\underline{a}ware flexible job shop scheduling. \textsc{Luca} addresses the challenges of dynamic and sustainable scheduling in smart manufacturing systems by integrating a graph neural network and an LLM, guided by a carefully designed in-house prompting strategy, to produce a fused embedding that captures both structural characteristics and contextual semantics of the latest scheduling state. This expressive embedding is then processed by a deep reinforcement learning policy network, which generates real-time scheduling decisions optimized for both makespan and carbon emission objectives. To support sustainability goals, \textsc{Luca} incorporates a dual-objective reward function that encourages both energy efficiency and scheduling timeliness. Experimental results on both synthetic and public datasets demonstrate that \textsc{Luca} consistently outperforms comparison algorithms. For instance, on the synthetic dataset, it achieves an average of 4.1\% and up to 12.2\% lower makespan compared to the best-performing comparison algorithm while maintaining the same emission level. On public datasets, additional gains are observed for both makespan and emission. These results demonstrate that \textsc{Luca} is effective and practical for carbon-aware scheduling in smart manufacturing.

</details>


### [318] [DDFI: Diverse and Distribution-aware Missing Feature Imputation via Two-step Reconstruction](https://arxiv.org/abs/2512.06356)
*Yifan Song,Fenglin Yu,Yihong Luo,Xingjian Tao,Siya Qiu,Kai Han,Jing Tang*

Main category: cs.LG

TL;DR: DDFI是一种针对图神经网络中节点特征缺失问题的多样化、分布感知的特征补全方法，通过结合特征传播和图掩码自编码器，解决了传统方法在非全连接图、过平滑问题和归纳任务中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现实世界中图数据常存在节点特征缺失问题，传统特征传播方法存在三个主要问题：1）难以处理非全连接图；2）补全特征面临过平滑问题；3）仅适用于直推式任务，忽略归纳任务中的特征分布偏移。

Method: DDFI提出了一种新颖的两步表示生成过程：首先设计同标签链接算法增强非全连接图的连通性，然后在推理阶段通过完整的掩码自编码器重构特征，减少分布偏移并增强特征多样性。

Result: 在六个公共数据集和新收集的Sailing数据集上的实验表明，DDFI在直推式和归纳式设置下均优于现有最先进方法。

Conclusion: DDFI通过创新的特征补全框架有效解决了图数据中特征缺失问题，特别是在非全连接图和归纳任务中表现出色，为现实世界图学习应用提供了实用解决方案。

Abstract: Incomplete node features are ubiquitous in real-world scenarios, e.g., the attributes of web users may be partly private, which causes the performance of Graph Neural Networks (GNNs) to decline significantly. Feature propagation (FP) is a well-known method that performs well for imputation of missing node features on graphs, but it still has the following three issues: 1) it struggles with graphs that are not fully connected, 2) imputed features face the over-smoothing problem, and 3) FP is tailored for transductive tasks, overlooking the feature distribution shift in inductive tasks. To address these challenges, we introduce DDFI, a Diverse and Distribution-aware Missing Feature Imputation method that combines feature propagation with a graph-based Masked AutoEncoder (MAE) in a nontrivial manner. It first designs a simple yet effective algorithm, namely Co-Label Linking (CLL), that randomly connects nodes in the training set with the same label to enhance the performance on graphs with numerous connected components. Then we develop a novel two-step representation generation process at the inference stage. Specifically, instead of directly using FP-imputed features as input during inference, DDFI further reconstructs the features through the whole MAE to reduce feature distribution shift in the inductive tasks and enhance the diversity of node features. Meanwhile, since existing feature imputation methods for graphs only evaluate by simulating the missing scenes with manually masking the features, we collect a new dataset called Sailing from the records of voyages that contains naturally missing features to help better evaluate the effectiveness. Extensive experiments conducted on six public datasets and Sailing show that DDFI outperforms the state-of-the-art methods under both transductive and inductive settings.

</details>


### [319] [Proportional integral derivative booster for neural networks-based time-series prediction: Case of water demand prediction](https://arxiv.org/abs/2512.06357)
*Tony Sallooma,Okyay Kaynak,Xinbo Yub,Wei He*

Main category: cs.LG

TL;DR: 本文提出了一种基于PID控制方法的技术，用于提升神经网络在多步时间序列预测中的性能，同时保持系统复杂度不变。该方法通过PID控制器调整预测值，使其更接近真实值，并在水需求预测和能源消耗预测两个案例中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 多步时间序列预测在工业决策中至关重要，但神经网络结构的复杂性影响了预测精度。本文旨在通过PID控制方法提升预测性能，同时不增加系统复杂度。

Method: 提出了一种基于比例-积分-微分（PID）控制的方法，将其应用于每个时间步的预测值，以修正误差。该方法在两个深度学习模型上进行了测试：水需求预测和小时能源消耗预测。

Result: 实验结果表明，使用PID增强技术后，预测精度显著提高，且系统复杂度几乎不变。在两个案例中，该方法均优于原始预测模型。

Conclusion: PID-based booster是一种有效的技术，能够显著提升周期性时间序列预测的准确性，同时保持低复杂度，适用于多种工业应用场景。

Abstract: Multi-step time-series prediction is an essential supportive step for decision-makers in several industrial areas. Artificial intelligence techniques, which use a neural network component in various forms, have recently frequently been used to accomplish this step. However, the complexity of the neural network structure still stands up as a critical problem against prediction accuracy. In this paper, a method inspired by the proportional-integral-derivative (PID) control approach is investigated to enhance the performance of neural network models used for multi-step ahead prediction of periodic time-series information while maintaining a negligible impact on the complexity of the system. The PID-based method is applied to the predicted value at each time step to bring that value closer to the real value. The water demand forecasting problem is considered as a case study, where two deep neural network models from the literature are used to prove the effectiveness of the proposed boosting method. Furthermore, to prove the applicability of this PID-based booster to other types of periodic time-series prediction problems, it is applied to enhance the accuracy of a neural network model used for multi-step forecasting of hourly energy consumption. The comparison between the results of the original prediction models and the results after using the proposed technique demonstrates the superiority of the proposed method in terms of prediction accuracy and system complexity.

</details>


### [320] [Optimizing Optimizers for Fast Gradient-Based Learning](https://arxiv.org/abs/2512.06370)
*Jaerin Lee,Kyoung Mu Lee*

Main category: cs.LG

TL;DR: 该论文为基于梯度的学习中的优化器设计自动化奠定了理论基础，通过贪婪原则将优化器设计问题转化为最大化损失瞬时减少的凸优化问题。


<details>
  <summary>Details</summary>
Motivation: 动机是建立一个系统化的框架来自动设计优化器及其超参数，减少手动调参的需求，提高深度学习训练的效率和性能。

Method: 方法是将优化器视为将损失梯度信号转换为参数运动的函数，通过解决一系列凸优化问题来设计优化器，并动态调整超参数。

Result: 结果不仅恢复了多种流行优化器的闭式解，还能根据训练过程中的梯度统计自动生成最优超参数。

Conclusion: 结论是该方法为优化器设计提供了理论支持，实现了优化过程的动态自动化，提升了训练效率。

Abstract: We lay the theoretical foundation for automating optimizer design in gradient-based learning. Based on the greedy principle, we formulate the problem of designing optimizers as maximizing the instantaneous decrease in loss. By treating an optimizer as a function that translates loss gradient signals into parameter motions, the problem reduces to a family of convex optimization problems over the space of optimizers. Solving these problems under various constraints not only recovers a wide range of popular optimizers as closed-form solutions, but also produces the optimal hyperparameters of these optimizers with respect to the problems at hand. This enables a systematic approach to design optimizers and tune their hyperparameters according to the gradient statistics that are collected during the training process. Furthermore, this optimization of optimization can be performed dynamically during training.

</details>


### [321] [RLAX: Large-Scale, Distributed Reinforcement Learning for Large Language Models on TPUs](https://arxiv.org/abs/2512.06392)
*Runlong Zhou,Lefan Zhang,Shang-Chen Wu,Kelvin Zou,Hanzhi Zhou,Ke Ye,Yihao Feng,Dong Yin,Alex Guillen Garcia,Dmytro Babych,Rohit Chatterjee,Matthew Hopkins,Xiang Kong,Chang Lan,Lezhi Li,Yiping Ma,Daniele Molinari,Senyu Tong,Yanchao Sun,Thomas Voice,Jianyu Wang,Chong Wang,Simon Wang,Floris Weers,Yechen Xu,Guolin Yin,Muyang Yu,Yi Zhang,Zheng Zhou,Danyang Zhuo,Ruoming Pang,Cheng Leong*

Main category: cs.LG

TL;DR: RLAX是一个基于TPU的可扩展强化学习框架，采用参数服务器架构，通过系统优化和数据集技术，在12小时48分钟内将QwQ-32B模型的pass@8准确率提升12.8%


<details>
  <summary>Details</summary>
Motivation: 强化学习已成为提升大语言模型推理能力的主流方法，但需要可扩展且能容忍中断的训练框架

Method: 采用参数服务器架构，主训练器定期推送模型权重，推理工作器拉取最新权重生成新数据；引入系统优化技术支持多种RL算法；开发新的数据集筛选和对齐技术

Result: 在1024个v5p TPU上，仅用12小时48分钟就将QwQ-32B的pass@8准确率提升12.8%，且训练过程对中断具有鲁棒性

Conclusion: RLAX框架有效解决了大规模RL训练的可扩展性和容错性问题，显著加速了LLM推理能力的提升

Abstract: Reinforcement learning (RL) has emerged as the de-facto paradigm for improving the reasoning capabilities of large language models (LLMs). We have developed RLAX, a scalable RL framework on TPUs. RLAX employs a parameter-server architecture. A master trainer periodically pushes updated model weights to the parameter server while a fleet of inference workers pull the latest weights and generates new rollouts. We introduce a suite of system techniques to enable scalable and preemptible RL for a diverse set of state-of-art RL algorithms. To accelerate convergence and improve model quality, we have devised new dataset curation and alignment techniques. Large-scale evaluations show that RLAX improves QwQ-32B's pass@8 accuracy by 12.8% in just 12 hours 48 minutes on 1024 v5p TPUs, while remaining robust to preemptions during training.

</details>


### [322] [Hankel-FNO: Fast Underwater Acoustic Charting Via Physics-Encoded Fourier Neural Operator](https://arxiv.org/abs/2512.06417)
*Yifan Sun,Lei Cheng,Jianlong Li,Peter Gerstoft*

Main category: cs.LG

TL;DR: Hankel-FNO是一种基于傅里叶神经算子的高效水下声学制图模型，结合声传播知识和地形数据，在保持高计算速度的同时实现高精度。


<details>
  <summary>Details</summary>
Motivation: 传统水下声学制图方法依赖计算昂贵的数值求解器，无法满足大规模或实时应用需求；现有深度学习替代模型存在固定分辨率限制和依赖显式偏微分方程等问题，限制了其适用性和泛化能力。

Method: 提出Hankel-FNO模型，基于傅里叶神经算子架构，融入声传播知识和海底地形信息，实现高效准确的水下声学场预测。

Result: Hankel-FNO在速度上优于传统求解器，在精度上超越数据驱动替代方法，尤其在长距离预测中表现突出；实验显示模型对多样化环境和声源设置具有良好的适应性和泛化能力。

Conclusion: Hankel-FNO为水下声学制图提供了一种高效准确的解决方案，具有实际应用的潜力，特别是在需要快速响应和适应不同环境条件的场景中。

Abstract: Fast and accurate underwater acoustic charting is crucial for downstream tasks such as environment-aware sensor placement optimization and autonomous vehicle path planning. Conventional methods rely on computationally expensive while accurate numerical solvers, which are not scalable for large-scale or real-time applications. Although deep learning-based surrogate models can accelerate these computations, they often suffer from limitations such as fixed-resolution constraints or dependence on explicit partial differential equation formulations. These issues hinder their applicability and generalization across diverse environments. We propose Hankel-FNO, a Fourier Neural Operator (FNO)-based model for efficient and accurate acoustic charting. By incorporating sound propagation knowledge and bathymetry, our method has high accuracy while maintaining high computational speed. Results demonstrate that Hankel-FNO outperforms traditional solvers in speed and surpasses data-driven alternatives in accuracy, especially in long-range predictions. Experiments show the model's adaptability to diverse environments and sound source settings with minimal fine-tuning.

</details>


### [323] [A new initialisation to Control Gradients in Sinusoidal Neural network](https://arxiv.org/abs/2512.06427)
*Andrea Combette,Antoine Venaille,Nelly Pustelnik*

Main category: cs.LG

TL;DR: 本文提出了一种针对正弦激活函数网络（如SIREN）的新初始化策略，通过控制梯度和预激活分布来改善训练稳定性和泛化能力，在多种重建任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有初始化策略对正弦激活函数网络缺乏精确的理论理解，无法有效控制梯度爆炸或消失问题，影响训练效果和泛化性能。

Method: 通过分析预激活分布收敛性和雅可比矩阵序列方差，推导出参数初始化的闭式表达式，控制梯度并针对预激活消失问题，防止不适当频率出现。

Result: 新初始化策略在函数拟合和图像重建等任务中一致优于原始SIREN方案和其他基线方法，特别是在物理信息神经网络相关任务中表现突出。

Conclusion: 提出的初始化方法通过精确控制梯度和预激活分布，显著改善了正弦激活函数网络的训练动态和泛化性能，为相关架构提供了更可靠的初始化方案。

Abstract: Proper initialisation strategy is of primary importance to mitigate gradient explosion or vanishing when training neural networks. Yet, the impact of initialisation parameters still lacks a precise theoretical understanding for several well-established architectures. Here, we propose a new initialisation for networks with sinusoidal activation functions such as \texttt{SIREN}, focusing on gradients control, their scaling with network depth, their impact on training and on generalization. To achieve this, we identify a closed-form expression for the initialisation of the parameters, differing from the original \texttt{SIREN} scheme. This expression is derived from fixed points obtained through the convergence of pre-activation distribution and the variance of Jacobian sequences. Controlling both gradients and targeting vanishing pre-activation helps preventing the emergence of inappropriate frequencies during estimation, thereby improving generalization. We further show that this initialisation strongly influences training dynamics through the Neural Tangent Kernel framework (NTK). Finally, we benchmark \texttt{SIREN} with the proposed initialisation against the original scheme and other baselines on function fitting and image reconstruction. The new initialisation consistently outperforms state-of-the-art methods across a wide range of reconstruction tasks, including those involving physics-informed neural networks.

</details>


### [324] [Neural expressiveness for beyond importance model compression](https://arxiv.org/abs/2512.06440)
*Angelos-Christos Maroudis,Sotirios Xydis*

Main category: cs.LG

TL;DR: 提出了一种名为"表达力"的新剪枝标准，强调神经元有效重新分配信息的能力，与权重重要性无关，实现了数据无关和状态无关的剪枝，在参数压缩比上相比权重方法提升10倍，性能仅下降1%。


<details>
  <summary>Details</summary>
Motivation: 现有剪枝方法主要依赖神经元权重的"重要性"，但忽略了神经元有效重新分配信息的能力。本文旨在探索一种与学习状态无关的剪枝标准，解决"何时剪枝"的问题。

Method: 提出"表达力"剪枝标准，基于激活重叠来评估神经元重新分配信息的能力。该方法与网络初始化状态相关，可近似使用任意数据，支持数据无关策略，并能与重要性剪枝方法结合。

Result: 在YOLOv8上实现55.4%参数剪枝和46.1%MACs减少，COCO数据集上mAP50-95提升3%；与权重方法相比参数压缩比提升10倍，平均性能下降仅1%。

Conclusion: 表达力剪枝标准为模型压缩提供了新的基础，解决了"何时剪枝"的问题，支持数据无关策略，并能与现有方法互补，显著提升压缩效率。

Abstract: Neural Network Pruning has been established as driving force in the exploration of memory and energy efficient solutions with high throughput both during training and at test time. In this paper, we introduce a novel criterion for model compression, named "Expressiveness". Unlike existing pruning methods that rely on the inherent "Importance" of neurons' and filters' weights, ``Expressiveness" emphasizes a neuron's or group of neurons ability to redistribute informational resources effectively, based on the overlap of activations. This characteristic is strongly correlated to a network's initialization state, establishing criterion autonomy from the learning state stateless and thus setting a new fundamental basis for the expansion of compression strategies in regards to the "When to Prune" question. We show that expressiveness is effectively approximated with arbitrary data or limited dataset's representative samples, making ground for the exploration of Data-Agnostic strategies. Our work also facilitates a "hybrid" formulation of expressiveness and importance-based pruning strategies, illustrating their complementary benefits and delivering up to 10x extra gains w.r.t. weight-based approaches in parameter compression ratios, with an average of 1% in performance degradation. We also show that employing expressiveness (independently) for pruning leads to an improvement over top-performing and foundational methods in terms of compression efficiency. Finally, on YOLOv8, we achieve a 46.1% MACs reduction by removing 55.4\% of the parameters, with an increase of 3% in the mean Absolute Precision ($mAP_{50-95}$) for object detection on COCO dataset.

</details>


### [325] [BitStopper: An Efficient Transformer Attention Accelerator via Stage-fusion and Early Termination](https://arxiv.org/abs/2512.06457)
*Huizheng Wang,Hongbin Wang,Shaojun Wei,Yang Hu,Shouyi Yin*

Main category: cs.LG

TL;DR: BitStopper是一种算法-架构协同设计，通过位级稀疏推测和异步处理技术，无需稀疏预测器即可实现高效的自注意力计算，相比现有Transformer加速器在性能和能效上均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 基于注意力的大语言模型存在二次计算成本问题，动态稀疏注意力虽然能缓解这一问题，但其硬件效率受限于额外的预测阶段和内存访问开销。

Method: 提出BitStopper框架：1）位串行使能阶段融合机制，重用内存访问并合并预测与执行阶段；2）轻量级自适应token选择策略；3）位级异步处理策略；4）精心设计的硬件架构。

Result: 相比SOTA Transformer加速器，BitStopper在Sanger和SOFA上分别实现2.03倍和1.89倍的速度提升，能效分别提升2.4倍和2.1倍。

Conclusion: BitStopper通过算法-架构协同设计有效解决了动态稀疏注意力的硬件效率问题，为大规模语言模型的高效部署提供了可行方案。

Abstract: Attention-based large language models (LLMs) have transformed modern AI applications, but the quadratic cost of self-attention imposes significant compute and memory overhead. Dynamic sparsity (DS) attention mitigates this, yet its hardware efficiency is limited by the added prediction stage and the heavy memory traffic it entails. To address these limitations, this paper proposes BitStopper, a fine-grained algorithm-architecture co-design that operates without a sparsity predictor. First, a bit-serial enable stage fusion (BESF) mechanism is proposed to reuse and minimize the memory access by progressively terminating trivial tokens and merging the prediction stage into the execution stage. Second, a lightweight and adaptive token selection (LATS) strategy is developed to work in concert with the bit-level sparsity speculation. Third, a bit-level asynchronous processing (BAP) strategy is employed to improve compute utilization during the on-demand bit-grained memory fetching. Finally, an elaborate architecture is designed to translate the theoretical complexity reduction into practical performance improvement. Extensive evaluations demonstrate that, compared to state-of-the-art (SOTA) Transformer accelerators, BitStopper achieves 2.03x and 1.89x speedups over Sanger and SOFA, respectively, while delivering 2.4x and 2.1x improvements in energy efficiency.

</details>


### [326] [Why Goal-Conditioned Reinforcement Learning Works: Relation to Dual Control](https://arxiv.org/abs/2512.06471)
*Nathan P. Lawrence,Ali Mesbah*

Main category: cs.LG

TL;DR: 本文分析了基于最优控制的目标条件强化学习，推导了经典二次目标与目标条件奖励之间的最优性差距，并探讨了其在部分可观测马尔可夫决策问题中的优势。


<details>
  <summary>Details</summary>
Motivation: 研究目标条件强化学习的理论基础，解释为什么经典密集奖励可能失败，以及目标条件策略在不确定环境中的优势。

Method: 基于最优控制理论分析，推导目标条件奖励与经典二次奖励的最优性差距，并将状态估计与概率奖励联系起来，应用于部分可观测马尔可夫决策问题。

Result: 在非线性和不确定环境中，通过强化学习和预测控制技术验证了目标条件策略的优势。

Conclusion: 目标条件强化学习在理论分析和实际应用中均表现出色，特别适用于具有不确定性的控制问题。

Abstract: Goal-conditioned reinforcement learning (RL) concerns the problem of training an agent to maximize the probability of reaching target goal states. This paper presents an analysis of the goal-conditioned setting based on optimal control. In particular, we derive an optimality gap between more classical, often quadratic, objectives and the goal-conditioned reward, elucidating the success of goal-conditioned RL and why classical ``dense'' rewards can falter. We then consider the partially observed Markov decision setting and connect state estimation to our probabilistic reward, further making the goal-conditioned reward well suited to dual control problems. The advantages of goal-conditioned policies are validated on nonlinear and uncertain environments using both RL and predictive control techniques.

</details>


### [327] [Optimizing LLMs Using Quantization for Mobile Execution](https://arxiv.org/abs/2512.06490)
*Agatsya Yadav,Renta Chintala Bhargavi*

Main category: cs.LG

TL;DR: 本文研究了使用4位后训练量化(PTQ)技术压缩LLaMA 3.2 3B模型，使其能够在Android设备上高效运行，模型大小减少68.66%。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然功能强大，但由于其庞大的规模和计算需求，难以在资源受限的移动设备上部署。

Method: 使用BitsAndBytes库和Hugging Face Transformers框架对Meta的LLaMA 3.2 3B模型进行4位PTQ，然后通过llama.cpp工具转换为GGUF格式以优化移动端推理。

Result: 量化后模型大小减少68.66%，能够在Android设备上成功执行推理任务，通过Termux环境和Ollama框架验证了可行性。

Conclusion: 4位PTQ结合GGUF等移动优化格式，为在移动设备上部署能力强大的LLM提供了实用路径，在模型大小和性能之间取得了良好平衡。

Abstract: Large Language Models (LLMs) offer powerful capabilities, but their significant size and computational requirements hinder deployment on resource-constrained mobile devices. This paper investigates Post-Training Quantization (PTQ) for compressing LLMs for mobile execution. We apply 4-bit PTQ using the BitsAndBytes library with the Hugging Face Transformers framework to Meta's Llama 3.2 3B model. The quantized model is converted to GGUF format using llama.cpp tools for optimized mobile inference. The PTQ workflow achieves a 68.66% reduction in model size through 4-bit quantization, enabling the Llama 3.2 3B model to run efficiently on an Android device. Qualitative validation shows that the 4-bit quantized model can perform inference tasks successfully. We demonstrate the feasibility of running the quantized GGUF model on an Android device using the Termux environment and the Ollama framework. PTQ, especially at 4-bit precision combined with mobile-optimized formats like GGUF, provides a practical pathway for deploying capable LLMs on mobile devices, balancing model size and performance.

</details>


### [328] [Diagnosis-based mortality prediction for intensive care unit patients via transfer learning](https://arxiv.org/abs/2512.06511)
*Mengqi Xu,Subha Maity,Joel Dubin*

Main category: cs.LG

TL;DR: 该研究评估了在ICU诊断特异性死亡率预测中应用迁移学习方法，发现迁移学习在性能上优于仅使用诊断特异性数据或APACHE IVa评分的模型，并具有更好的校准性。


<details>
  <summary>Details</summary>
Motivation: ICU中危重病的根本原因在不同诊断间差异很大，但考虑诊断异质性的预测模型尚未得到系统研究。

Method: 在eICU协作研究数据库中应用基于GLM和XGBoost的迁移学习模型进行诊断特异性死亡率预测。

Result: 迁移学习模型在预测性能上持续优于仅使用诊断特异性数据的模型和单独使用APACHE IVa评分的模型，同时比基于汇总数据的模型具有更好的校准性。Youden截断值比传统的0.5截断值更适合二元结局预测。

Conclusion: 迁移学习在ICU诊断特异性死亡率预测中表现出优越性能，Youden截断值是更合适的决策阈值，迁移学习在不同截断标准下均能保持高预测性能。

Abstract: In the intensive care unit, the underlying causes of critical illness vary substantially across diagnoses, yet prediction models accounting for diagnostic heterogeneity have not been systematically studied. To address the gap, we evaluate transfer learning approaches for diagnosis-specific mortality prediction and apply both GLM- and XGBoost-based models to the eICU Collaborative Research Database. Our results demonstrate that transfer learning consistently outperforms models trained only on diagnosis-specific data and those using a well-known ICU severity-of-illness score, i.e., APACHE IVa, alone, while also achieving better calibration than models trained on the pooled data. Our findings also suggest that the Youden cutoff is a more appropriate decision threshold than the conventional 0.5 for binary outcomes, and that transfer learning maintains consistently high predictive performance across various cutoff criteria.

</details>


### [329] [Hierarchical geometric deep learning enables scalable analysis of molecular dynamics](https://arxiv.org/abs/2512.06520)
*Zihan Pengmei,Spencer C. Guo,Chatipat Lorpaiboon,Aaron R. Dinner*

Main category: cs.LG

TL;DR: 该论文提出了一种基于图神经网络的方法，通过局部信息聚合来降低内存和计算需求，使得能够在大规模生物分子系统（如数千个残基的蛋白质-核酸复合物）上高效分析分子动力学模拟轨迹。


<details>
  <summary>Details</summary>
Motivation: 分子动力学模拟可以生成复杂系统的原子级轨迹，但当系统缺乏明确的定量描述符时，分析这些动态变得困难。传统的图神经网络在处理大规模生物分子系统时面临内存和运行时限制，以及难以捕捉长程相互作用的挑战。

Method: 开发了一种局部信息聚合的图神经网络方法，通过减少消息传递过程中的内存和计算需求，同时保持原子级细节。该方法能够在单GPU上快速分析包含数千个残基的蛋白质-核酸复合物模拟。

Result: 该方法使得在单GPU上几分钟内分析数千个残基的蛋白质-核酸复合物模拟成为可能。对于数百个残基的系统，该方法在性能和可解释性方面均有提升。

Conclusion: 局部信息聚合的图神经网络方法有效解决了大规模生物分子系统分析中的计算瓶颈，为复杂生物分子动态的深入分析提供了可行工具。

Abstract: Molecular dynamics simulations can generate atomically detailed trajectories of complex systems, but analyzing these dynamics can be challenging when systems lack well-established quantitative descriptors (features). Graph neural networks (GNNs) in which messages are passed between nodes that represent atoms that are spatial neighbors promise to obviate manual feature engineering, but the use of GNNs with biomolecular systems of more than a few hundred residues has been limited in the context of analyzing dynamics by both difficulties in capturing the details of long-range interactions with message passing and the memory and runtime requirements associated with large graphs. Here, we show how local information can be aggregated to reduce memory and runtime requirements without sacrificing atomic detail. We demonstrate that this approach opens the door to analyzing simulations of protein-nucleic acid complexes with thousands of residues on single GPUs within minutes. For systems with hundreds of residues, for which there are sufficient data to make quantitative comparisons, we show that the approach improves performance and interpretability.

</details>


### [330] [Beyond Token-level Supervision: Unlocking the Potential of Decoding-based Regression via Reinforcement Learning](https://arxiv.org/abs/2512.06533)
*Ming Chen,Sheng Tang,Rong-Xi Tan,Ziniu Li,Jiacheng Chen,Ke Xue,Chao Qian*

Main category: cs.LG

TL;DR: 本文提出使用强化学习来改进基于解码的回归方法，通过序列级奖励来增强全局数值一致性，在表格回归和代码度量回归任务上表现出色。


<details>
  <summary>Details</summary>
Motivation: 基于解码的回归方法存在离散token级目标与连续数值之间的不对齐问题，现有方法难以捕捉目标值的全局幅度，限制了精度和泛化能力。

Method: 将生成过程建模为马尔可夫决策过程，使用序列级奖励来强制全局数值一致性，具体采用ReMax和GRPO强化学习方法。

Result: 在表格回归和代码度量回归任务上，该方法持续优于最先进的token级基线和传统回归头，显著提高了采样效率和预测精度。

Conclusion: 强化学习的引入使基于解码的回归成为通用数值预测的稳健且准确的范式。

Abstract: Decoding-based regression, which reformulates regression as a sequence generation task, has emerged as a promising paradigm of applying large language models for numerical prediction. However, its progress is hindered by the misalignment between discrete token-level objectives (e.g., cross-entropy) and continuous numerical values. Existing approaches relying on token-level constraints often fail to capture the global magnitude of the target value, limiting their precision and generalization. In this paper, we propose to unlock the potential of decoding-based regression via Reinforcement Learning (RL). We formulate the generation process as a Markov Decision Process, utilizing sequence-level rewards to enforce global numerical coherence. Extensive experiments on tabular regression and code metric regression demonstrate that our method (specifically with ReMax and GRPO) consistently outperforms both state-of-the-art token-level baselines and traditional regression heads, showing the superiority of introducing sequence-level signals. Our analysis further reveals that RL significantly enhances sampling efficiency and predictive precision, establishing decoding-based regression as a robust and accurate paradigm for general-purpose numerical prediction.

</details>


### [331] [A-3PO: Accelerating Asynchronous LLM Training with Staleness-aware Proximal Policy Approximation](https://arxiv.org/abs/2512.06547)
*Xiaocan Li,Shiliang Wu,Zheng Shen*

Main category: cs.LG

TL;DR: A-3PO是一种近似近端策略优化方法，通过简单插值近似近端策略，消除异步RL中额外前向传播的计算瓶颈，减少18%训练时间同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 解耦损失在异步强化学习中处理数据陈旧性问题很有效，但近端策略需要在每个训练步骤进行额外前向传播，对大型语言模型造成计算瓶颈。

Method: 提出A-3PO方法，通过简单插值近似近端策略，避免显式计算近端策略，从而消除计算开销。

Result: A-3PO减少18%的训练时间，同时保持与原始方法相当的性能表现。

Conclusion: A-3PO通过近似方法有效解决了异步RL中的计算瓶颈问题，在保持性能的同时显著提升训练效率。

Abstract: Decoupled loss has been a successful reinforcement learning (RL) algorithm to deal with the high data staleness under the asynchronous RL setting. Decoupled loss improves coupled-loss style of algorithms' (e.g., PPO, GRPO) learning stability by introducing a proximal policy to decouple the off-policy corrections (importance weight) from the controlling policy updates (trust region). However, the proximal policy requires an extra forward pass through the network at each training step, creating a computational bottleneck for large language models. We observe that since the proximal policy only serves as a trust region anchor between the behavior and target policies, we can approximate it through simple interpolation without explicit computation. We call this approach A-3PO (APproximated Proximal Policy Optimization). A-3PO eliminates this overhead, reducing training time by 18% while maintaining comparable performance. Code & off-the-shelf example are available at: https://github.com/inclusionAI/AReaL/blob/main/docs/algorithms/prox_approx.md

</details>


### [332] [Deep Manifold Part 2: Neural Network Mathematics](https://arxiv.org/abs/2512.06563)
*Max Y. Ma,Gen-Hua Shi*

Main category: cs.LG

TL;DR: 该论文通过流形几何、不动点理论和边界条件迭代，将神经网络建模为可学习的数值计算系统，揭示了学习能力仅当不动点区域稳定时才会出现，并提出了分布式弹性模型架构。


<details>
  <summary>Details</summary>
Motivation: 传统神经网络模型在固定坐标和算子框架下难以解释真实世界数据的复杂性、规模效应和训练动态，需要从几何和代数角度重新理解神经网络的学习机制。

Method: 采用堆叠分段流形、不动点理论和边界条件迭代方法，将神经网络视为由流形复杂度、高阶非线性和边界条件塑造的可学习数值计算系统。

Result: 发现神经网络的学习能力取决于不动点区域的稳定性，训练过程通过残差驱动迭代构建不动点，而非初始就存在固定点。

Conclusion: 单一模型在几何和数据诱导的可塑性下存在局限，需要设计分布式架构将流形复杂度分配到多个弹性模型中，形成基于几何、代数、不动点和真实数据复杂度的统一世界建模框架。

Abstract: This work develops the global equations of neural networks through stacked piecewise manifolds, fixed--point theory, and boundary--conditioned iteration. Once fixed coordinates and operators are removed, a neural network appears as a learnable numerical computation shaped by manifold complexity, high--order nonlinearity, and boundary conditions. Real--world data impose strong data complexity, near-infinite scope, scale, and minibatch fragmentation, while training dynamics produce learning complexity through shifting node covers, curvature accumulation, and the rise and decay of plasticity. These forces constrain learnability and explain why capability emerges only when fixed--point regions stabilize. Neural networks do not begin with fixed points; they construct them through residual--driven iteration. This perspective clarifies the limits of monolithic models under geometric and data--induced plasticity and motivates architectures and federated systems that distribute manifold complexity across many elastic models, forming a coherent world--modeling framework grounded in geometry, algebra, fixed points, and real--data complexity.

</details>


### [333] [QL-LSTM: A Parameter-Efficient LSTM for Stable Long-Sequence Modeling](https://arxiv.org/abs/2512.06582)
*Isaac Kofi Nti*

Main category: cs.LG

TL;DR: QL-LSTM是一种新型循环神经网络架构，通过参数共享统一门控机制和分层门控递归结合加法跳跃连接，解决了传统LSTM和GRU的参数冗余和长距离信息保留问题。


<details>
  <summary>Details</summary>
Motivation: 解决LSTM和GRU在序列建模中存在的两个核心问题：门控特定参数冗余以及长距离信息保留能力不足。

Method: 1. 参数共享统一门控机制：使用单一共享权重矩阵替代所有门控特定变换，减少约48%参数；2. 分层门控递归结合加法跳跃连接：增加无乘法通路，改善长距离信息流。

Result: 在IMDB情感分类任务上，QL-LSTM在保持竞争性准确率的同时显著减少了参数数量，但尚未实现计算速度提升。

Conclusion: QL-LSTM在参数效率方面表现优异，但由于循环模型的固有顺序特性，当前原型尚未实现计算速度改进，需要进一步内核级优化。

Abstract: Recurrent neural architectures such as LSTM and GRU remain widely used in sequence modeling, but they continue to face two core limitations: redundant gate-specific parameters and reduced ability to retain information across long temporal distances. This paper introduces the Quantum-Leap LSTM (QL-LSTM), a recurrent architecture designed to address both challenges through two independent components. The Parameter-Shared Unified Gating mechanism replaces all gate-specific transformations with a single shared weight matrix, reducing parameters by approximately 48 percent while preserving full gating behavior. The Hierarchical Gated Recurrence with Additive Skip Connections component adds a multiplication-free pathway that improves long-range information flow and reduces forget-gate degradation. We evaluate QL-LSTM on sentiment classification using the IMDB dataset with extended document lengths, comparing it to LSTM, GRU, and BiLSTM reference models. QL-LSTM achieves competitive accuracy while using substantially fewer parameters. Although the PSUG and HGR-ASC components are more efficient per time step, the current prototype remains limited by the inherent sequential nature of recurrent models and therefore does not yet yield wall-clock speed improvements without further kernel-level optimization.

</details>


### [334] [On fine-tuning Boltz-2 for protein-protein affinity prediction](https://arxiv.org/abs/2512.06592)
*James King,Lewis Cornwall,Andrei Cristian Nica,James Day,Aaron Sim,Neil Dalchau,Lilly Wollman,Joshua Meyers*

Main category: cs.LG

TL;DR: 本文评估了将蛋白质-配体亲和力预测器Boltz-2适配用于蛋白质-蛋白质亲和力预测的效果，发现结构模型在亲和力预测上表现不如序列模型，但结合两者可互补提升性能。


<details>
  <summary>Details</summary>
Motivation: 准确预测蛋白质-蛋白质结合亲和力对于理解分子相互作用和药物设计至关重要。

Method: 将最先进的基于结构的蛋白质-配体亲和力预测器Boltz-2适配用于蛋白质-蛋白质亲和力回归，并在TCR3d和PPB-affinity两个数据集上进行评估。

Result: 尽管具有高结构准确性，Boltz-2-PPI在大小规模数据集上都比基于序列的替代方法表现差。将Boltz-2-PPI的嵌入与基于序列的嵌入结合可以产生互补改进，特别是对于较弱的序列模型。

Conclusion: 当前基于结构的表示方法不适合进行高性能的亲和力预测，结果反映了与结构数据训练相关的已知偏差。

Abstract: Accurate prediction of protein-protein binding affinity is vital for understanding molecular interactions and designing therapeutics. We adapt Boltz-2, a state-of-the-art structure-based protein-ligand affinity predictor, for protein-protein affinity regression and evaluate it on two datasets, TCR3d and PPB-affinity. Despite high structural accuracy, Boltz-2-PPI underperforms relative to sequence-based alternatives in both small- and larger-scale data regimes. Combining embeddings from Boltz-2-PPI with sequence-based embeddings yields complementary improvements, particularly for weaker sequence models, suggesting different signals are learned by sequence- and structure-based models. Our results echo known biases associated with training with structural data and suggest that current structure-based representations are not primed for performant affinity prediction.

</details>


### [335] [A Fast and Effective Solution to the Problem of Look-ahead Bias in LLMs](https://arxiv.org/abs/2512.06607)
*Humzah Merchant,Bradford Levy*

Main category: cs.LG

TL;DR: 该论文提出了一种在推理时通过调整大型基础模型logits的方法，使用一对小型专业化模型来消除前瞻性偏差，解决金融预测中LLMs的look-ahead bias问题。


<details>
  <summary>Details</summary>
Motivation: 由于LLMs在长时序数据上的训练导致look-ahead bias，使得在金融预测任务中无法进行传统的回测，而从头重新训练前沿模型成本过高。

Method: 在推理时通过一对小型专业化模型调整大型基础模型的logits：一个在要遗忘的信息上微调，另一个在要保留的信息上微调。

Result: 该方法有效消除了字面和语义知识，纠正了偏差，并且优于先前的方法。

Conclusion: 该方法提供了一种快速、有效且低成本的替代方案，解决了LLMs在金融预测中的look-ahead bias问题。

Abstract: Applying LLMs to predictive tasks in finance is challenging due to look-ahead bias resulting from their training on long time-series data. This precludes the backtests typically employed in finance since retraining frontier models from scratch with a specific knowledge cutoff is prohibitive. In this paper, we introduce a fast, effective, and low-cost alternative. Our method guides generation at inference time by adjusting the logits of a large base model using a pair of smaller, specialized models -- one fine-tuned on information to be forgotten and another on information to be retained. We demonstrate that our method effectively removes both verbatim and semantic knowledge, corrects biases, and outperforms prior methods.

</details>


### [336] [Vector Quantization using Gaussian Variational Autoencoder](https://arxiv.org/abs/2512.06609)
*Tongda Xu,Wendi Zheng,Jiajun He,Jose Miguel Hernandez-Lobato,Yan Wang,Ya-Qin Zhang,Jie Tang*

Main category: cs.LG

TL;DR: 本文提出了一种名为Gaussian Quant（GQ）的技术，可将高斯VAE转换为VQ-VAE而无需训练，通过生成随机高斯噪声作为码本并找到与后验均值最接近的噪声来实现离散化。


<details>
  <summary>Details</summary>
Motivation: VQ-VAE由于离散化难以训练，需要一种更简单有效的离散化方法。

Method: 提出GQ技术，使用随机高斯噪声作为码本，并引入目标发散约束（TDC）来训练高斯VAE以提高GQ效果。

Result: 实验表明GQ在UNet和ViT架构上优于VQGAN、FSQ、LFQ和BSQ等现有VQ-VAE方法，TDC也改进了TokenBridge等高斯VAE离散化方法。

Conclusion: GQ是一种简单有效的VQ-VAE替代方法，通过理论保证和实验验证了其优越性能。

Abstract: Vector quantized variational autoencoder (VQ-VAE) is a discrete auto-encoder that compresses images into discrete tokens. It is difficult to train due to discretization. In this paper, we propose a simple yet effective technique, dubbed Gaussian Quant (GQ), that converts a Gaussian VAE with certain constraint into a VQ-VAE without training. GQ generates random Gaussian noise as a codebook and finds the closest noise to the posterior mean. Theoretically, we prove that when the logarithm of the codebook size exceeds the bits-back coding rate of the Gaussian VAE, a small quantization error is guaranteed. Practically, we propose a heuristic to train Gaussian VAE for effective GQ, named target divergence constraint (TDC). Empirically, we show that GQ outperforms previous VQ-VAEs, such as VQGAN, FSQ, LFQ, and BSQ, on both UNet and ViT architectures. Furthermore, TDC also improves upon previous Gaussian VAE discretization methods, such as TokenBridge. The source code is provided in https://github.com/tongdaxu/VQ-VAE-from-Gaussian-VAE.

</details>


### [337] [Quantum Temporal Convolutional Neural Networks for Cross-Sectional Equity Return Prediction: A Comparative Benchmark Study](https://arxiv.org/abs/2512.06630)
*Chi-Sheng Chen,Xinyu Zhang,Rong Fu,Qiuzhe Xie,Fan Zhang*

Main category: cs.LG

TL;DR: 该论文提出了一种量子时序卷积神经网络（QTCNN），结合经典时序编码器和参数高效的量子卷积电路，用于股票收益预测，在JPX东京证券交易所数据集上取得了显著优于经典方法的性能。


<details>
  <summary>Details</summary>
Motivation: 传统预测模型在处理噪声输入、制度转换和泛化能力方面存在困难，量子机器学习为复杂动态金融环境下的股票市场预测提供了有前景的解决方案。

Method: QTCNN包含经典时序编码器提取多尺度技术指标模式，以及量子卷积电路利用量子叠加和纠缠特性增强特征表示并抑制过拟合。

Result: 在JPX东京证券交易所数据集上，QTCNN实现了0.538的夏普比率，比最佳经典基准方法高出约72%。

Conclusion: 研究结果表明量子增强的预测模型QTCNN在量化金融中具有实际应用潜力，能够支持稳健的决策制定。

Abstract: Quantum machine learning offers a promising pathway for enhancing stock market prediction, particularly under complex, noisy, and highly dynamic financial environments. However, many classical forecasting models struggle with noisy input, regime shifts, and limited generalization capacity. To address these challenges, we propose a Quantum Temporal Convolutional Neural Network (QTCNN) that combines a classical temporal encoder with parameter-efficient quantum convolution circuits for cross-sectional equity return prediction. The temporal encoder extracts multi-scale patterns from sequential technical indicators, while the quantum processing leverages superposition and entanglement to enhance feature representation and suppress overfitting. We conduct a comprehensive benchmarking study on the JPX Tokyo Stock Exchange dataset and evaluate predictions through long-short portfolio construction using out-of-sample Sharpe ratio as the primary performance metric. QTCNN achieves a Sharpe ratio of 0.538, outperforming the best classical baseline by approximately 72\%. These results highlight the practical potential of quantum-enhanced forecasting model, QTCNN, for robust decision-making in quantitative finance.

</details>


### [338] [The Impact of Data Characteristics on GNN Evaluation for Detecting Fake News](https://arxiv.org/abs/2512.06638)
*Isha Karn,David Jensen*

Main category: cs.LG

TL;DR: 该论文指出GossipCop和PolitiFact这两个常用假新闻检测基准数据集存在图拓扑结构浅层化的问题，导致图神经网络(GNNs)在结构建模方面的优势无法体现，多层感知机(MLP)表现与GNNs相当。


<details>
  <summary>Details</summary>
Motivation: 当前假新闻检测研究中广泛使用GNNs来建模新闻传播结构，但常用基准数据集是否真正能够评估结构建模方法的有效性存在疑问。

Method: 系统比较5种GNN架构与使用相同节点特征的MLP，通过特征洗牌和边结构随机化实验来分离结构和特征的贡献，并对图拓扑进行结构分析。

Result: MLP与GNNs性能差距在1-2%内，置信区间重叠；特征洗牌导致性能崩溃而边随机化性能稳定；75%以上节点距离根节点仅一跳，结构多样性不足；在合成数据集上GNNs显著优于MLPs。

Conclusion: 现有基准数据集无法有效测试结构建模方法的效用，需要开发具有更丰富、更多样化图拓扑结构的数据集。

Abstract: Graph neural networks (GNNs) are widely used for the detection of fake news by modeling the content and propagation structure of news articles on social media. We show that two of the most commonly used benchmark data sets - GossipCop and PolitiFact - are poorly suited to evaluating the utility of models that use propagation structure. Specifically, these data sets exhibit shallow, ego-like graph topologies that provide little or no ability to differentiate among modeling methods. We systematically benchmark five GNN architectures against a structure-agnostic multilayer perceptron (MLP) that uses the same node features. We show that MLPs match or closely trail the performance of GNNs, with performance gaps often within 1-2% and overlapping confidence intervals. To isolate the contribution of structure in these datasets, we conduct controlled experiments where node features are shuffled or edge structures randomized. We find that performance collapses under feature shuffling but remains stable under edge randomization. This suggests that structure plays a negligible role in these benchmarks. Structural analysis further reveals that over 75% of nodes are only one hop from the root, exhibiting minimal structural diversity. In contrast, on synthetic datasets where node features are noisy and structure is informative, GNNs significantly outperform MLPs. These findings provide strong evidence that widely used benchmarks do not meaningfully test the utility of modeling structural features, and they motivate the development of datasets with richer, more diverse graph topologies.

</details>


### [339] [Financial Fraud Identification and Interpretability Study for Listed Companies Based on Convolutional Neural Network](https://arxiv.org/abs/2512.06648)
*Xiao Li*

Main category: cs.LG

TL;DR: 本文提出基于卷积神经网络的中国A股上市公司财务舞弊检测框架，通过将面板数据转换为图像形式实现提前预测，在准确性、鲁棒性和预警性能上优于传统方法，并通过可解释性分析识别关键舞弊指标。


<details>
  <summary>Details</summary>
Motivation: 财务舞弊难以检测，传统统计模型难以处理非线性特征，机器学习模型缺乏可解释性，且现有方法大多只能基于当年数据判断当年舞弊，缺乏时效性。

Method: 设计特征工程方案将公司年度面板数据转换为类图像表示，使用卷积神经网络捕捉横截面和时间模式，实现提前预测；采用局部解释技术从实体、特征和时间维度分析模型。

Result: CNN模型在准确性、鲁棒性和预警性能上优于逻辑回归和LightGBM；发现偿债能力、比率结构、治理结构和内部控制是舞弊的通用预测因子；非舞弊公司特征模式稳定，舞弊公司特征模式集中在短期窗口。

Conclusion: CNN框架能有效提前检测财务舞弊，通过可解释性分析识别关键驱动因素，案例研究验证了模型预测与实际舞弊行为的一致性，为高风险环境下的舞弊检测提供了实用方案。

Abstract: Since the emergence of joint-stock companies, financial fraud by listed firms has repeatedly undermined capital markets. Fraud is difficult to detect because of covert tactics and the high labor and time costs of audits. Traditional statistical models are interpretable but struggle with nonlinear feature interactions, while machine learning models are powerful but often opaque. In addition, most existing methods judge fraud only for the current year based on current year data, limiting timeliness.
  This paper proposes a financial fraud detection framework for Chinese A-share listed companies based on convolutional neural networks (CNNs). We design a feature engineering scheme that transforms firm-year panel data into image like representations, enabling the CNN to capture cross-sectional and temporal patterns and to predict fraud in advance. Experiments show that the CNN outperforms logistic regression and LightGBM in accuracy, robustness, and early-warning performance, and that proper tuning of the classification threshold is crucial in high-risk settings.
  To address interpretability, we analyze the model along the dimensions of entity, feature, and time using local explanation techniques. We find that solvency, ratio structure, governance structure, and internal control are general predictors of fraud, while environmental indicators matter mainly in high-pollution industries. Non-fraud firms share stable feature patterns, whereas fraud firms exhibit heterogeneous patterns concentrated in short time windows. A case study of Guanong Shares in 2022 shows that cash flow analysis, social responsibility, governance structure, and per-share indicators are the main drivers of the model's fraud prediction, consistent with the company's documented misconduct.

</details>


### [340] [Estimating Black Carbon Concentration from Urban Traffic Using Vision-Based Machine Learning](https://arxiv.org/abs/2512.06649)
*Camellia Zakaria,Aryan Sadeghi,Weaam Jaafar,Junshi Xu,Alex Mariakakis,Marianne Hatzopoulou*

Main category: cs.LG

TL;DR: 该研究提出了一种基于机器学习的系统，利用交通监控视频和天气数据来估算街道级别的黑碳浓度，以解决城市交通排放监测不足的问题。


<details>
  <summary>Details</summary>
Motivation: 城市黑碳排放主要来自交通，但现有监测设备成本高且数据稀缺，而交通监控系统广泛部署，存在监测数据与交通环境后果之间的不平衡。

Method: 通过机器学习从交通视频中提取车辆行为和状态特征，结合天气数据构建模型来估算街道级别的黑碳浓度。

Result: 模型达到了R平方值0.72和RMSE 129.42 ng/m³的预测精度。

Conclusion: 该工作利用现有城市基础设施资源，为地方市政层面的污染减排、城市规划、公共健康和环境正义提供了可操作的数据支持。

Abstract: Black carbon (BC) emissions in urban areas are primarily driven by traffic, with hotspots near major roads disproportionately affecting marginalized communities. Because BC monitoring is typically performed using costly and specialized instruments. there is little to no available data on BC from local traffic sources that could help inform policy interventions targeting local factors. By contrast, traffic monitoring systems are widely deployed in cities around the world, highlighting the imbalance between what we know about traffic conditions and what do not know about their environmental consequences. To bridge this gap, we propose a machine learning-driven system that extracts visual information from traffic video to capture vehicles behaviors and conditions. Combining these features with weather data, our model estimates BC at street level, achieving an R-squared value of 0.72 and RMSE of 129.42 ng/m3 (nanogram per cubic meter). From a sustainability perspective, this work leverages resources already supported by urban infrastructure and established modeling techniques to generate information relevant to traffic emission. Obtaining BC concentration data provides actionable insights to support pollution reduction, urban planning, public health, and environmental justice at the local municipal level.

</details>


### [341] [Adaptive Test-Time Training for Predicting Need for Invasive Mechanical Ventilation in Multi-Center Cohorts](https://arxiv.org/abs/2512.06652)
*Xiaolei Lu,Shamim Nemati*

Main category: cs.LG

TL;DR: 本文提出了AdaTTT框架，通过自适应测试时训练来提升ICU患者有创机械通气需求的预测性能，解决跨机构部署时的领域偏移问题。


<details>
  <summary>Details</summary>
Motivation: ICU患者有创机械通气需求预测对及时干预和资源分配至关重要，但不同机构间的患者群体、临床实践和电子健康记录系统差异导致模型泛化性能下降。

Method: 提出自适应测试时训练框架，包括信息理论边界分析、自监督学习（重构和掩码特征建模）、动态掩码策略、原型学习和部分最优传输特征对齐。

Result: 在多中心ICU队列实验中，该框架在不同测试时适应基准上表现出竞争力的分类性能。

Conclusion: AdaTTT框架有效提升了跨机构部署时IMV预测模型的鲁棒性和适应性，为临床决策提供了可靠支持。

Abstract: Accurate prediction of the need for invasive mechanical ventilation (IMV) in intensive care units (ICUs) patients is crucial for timely interventions and resource allocation. However, variability in patient populations, clinical practices, and electronic health record (EHR) systems across institutions introduces domain shifts that degrade the generalization performance of predictive models during deployment. Test-Time Training (TTT) has emerged as a promising approach to mitigate such shifts by adapting models dynamically during inference without requiring labeled target-domain data. In this work, we introduce Adaptive Test-Time Training (AdaTTT), an enhanced TTT framework tailored for EHR-based IMV prediction in ICU settings. We begin by deriving information-theoretic bounds on the test-time prediction error and demonstrate that it is constrained by the uncertainty between the main and auxiliary tasks. To enhance their alignment, we introduce a self-supervised learning framework with pretext tasks: reconstruction and masked feature modeling optimized through a dynamic masking strategy that emphasizes features critical to the main task. Additionally, to improve robustness against domain shifts, we incorporate prototype learning and employ Partial Optimal Transport (POT) for flexible, partial feature alignment while maintaining clinically meaningful patient representations. Experiments across multi-center ICU cohorts demonstrate competitive classification performance on different test-time adaptation benchmarks.

</details>


### [342] [GSAE: Graph-Regularized Sparse Autoencoders for Robust LLM Safety Steering](https://arxiv.org/abs/2512.06655)
*Jehyeok Yeon,Federico Cinus,Yifan Wu,Luca Luceri*

Main category: cs.LG

TL;DR: 本文提出Graph-Regularized Sparse Autoencoders (GSAEs)方法，通过图正则化稀疏自编码器改进LLM安全防御，解决传统方法将安全概念局限于单一特征的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全防御方法存在局限性，要么是黑盒输出过滤，要么基于内部激活的单维安全特征假设。但研究表明抽象安全概念（如拒绝、时间性）分布在多个特征中，而非孤立于单一特征。

Method: GSAEs在稀疏自编码器基础上引入拉普拉斯平滑惩罚项，构建神经元共激活图，恢复平滑的分布式安全表示。采用两阶段门控机制，仅在检测到有害提示或生成内容时激活干预。

Result: GSAE在安全和QA基准测试中平均选择性拒绝率达82%，显著优于标准SAE（42%），同时在TriviaQA（70%）、TruthfulQA（65%）、GSM8K（74%）上保持强任务准确性。对LLaMA-3、Mistral等模型家族具有良好泛化性，对抗GCG、AutoDAN等越狱攻击时保持≥90%的有害内容拒绝率。

Conclusion: GSAEs能够有效实现运行时安全控制，将特征组合成加权安全相关方向，自适应执行拒绝同时保持良性查询的实用性，为解决LLM安全挑战提供了更有效的分布式表示方法。

Abstract: Large language models (LLMs) face critical safety challenges, as they can be manipulated to generate harmful content through adversarial prompts and jailbreak attacks. Many defenses are typically either black-box guardrails that filter outputs, or internals-based methods that steer hidden activations by operationalizing safety as a single latent feature or dimension. While effective for simple concepts, this assumption is limiting, as recent evidence shows that abstract concepts such as refusal and temporality are distributed across multiple features rather than isolated in one. To address this limitation, we introduce Graph-Regularized Sparse Autoencoders (GSAEs), which extends SAEs with a Laplacian smoothness penalty on the neuron co-activation graph. Unlike standard SAEs that assign each concept to a single latent feature, GSAEs recover smooth, distributed safety representations as coherent patterns spanning multiple features. We empirically demonstrate that GSAE enables effective runtime safety steering, assembling features into a weighted set of safety-relevant directions and controlling them with a two-stage gating mechanism that activates interventions only when harmful prompts or continuations are detected during generation. This approach enforces refusals adaptively while preserving utility on benign queries. Across safety and QA benchmarks, GSAE steering achieves an average 82% selective refusal rate, substantially outperforming standard SAE steering (42%), while maintaining strong task accuracy (70% on TriviaQA, 65% on TruthfulQA, 74% on GSM8K). Robustness experiments further show generalization across LLaMA-3, Mistral, Qwen, and Phi families and resilience against jailbreak attacks (GCG, AutoDAN), consistently maintaining >= 90% refusal of harmful content.

</details>


### [343] [Rethinking Robustness: A New Approach to Evaluating Feature Attribution Methods](https://arxiv.org/abs/2512.06665)
*Panagiota Kiourti,Anu Singh,Preeti Duraipandian,Weichao Zhou,Wenchao Li*

Main category: cs.LG

TL;DR: 本文提出了一种新的深度神经网络特征归因方法鲁棒性评估框架，包括新的相似输入定义、鲁棒性指标和基于生成对抗网络的输入生成方法。


<details>
  <summary>Details</summary>
Motivation: 挑战当前主要忽略模型输出差异的归因鲁棒性概念，需要更客观的指标来准确评估归因方法的鲁棒性。

Method: 提出新的相似输入定义、新的鲁棒性指标，以及基于生成对抗网络生成这些输入的新方法。

Result: 通过现有指标和最先进归因方法的综合评估，发现需要更客观的指标来揭示归因方法而非神经网络的弱点。

Conclusion: 新框架能提供更准确的归因方法鲁棒性评估，突出显示归因方法本身而非模型的问题。

Abstract: This paper studies the robustness of feature attribution methods for deep neural networks. It challenges the current notion of attributional robustness that largely ignores the difference in the model's outputs and introduces a new way of evaluating the robustness of attribution methods. Specifically, we propose a new definition of similar inputs, a new robustness metric, and a novel method based on generative adversarial networks to generate these inputs. In addition, we present a comprehensive evaluation with existing metrics and state-of-the-art attribution methods. Our findings highlight the need for a more objective metric that reveals the weaknesses of an attribution method rather than that of the neural network, thus providing a more accurate evaluation of the robustness of attribution methods.

</details>


### [344] [The Meta-Learning Gap: Combining Hydra and Quant for Large-Scale Time Series Classification](https://arxiv.org/abs/2512.06666)
*Urav Maniar*

Main category: cs.LG

TL;DR: 该研究探讨了时间序列分类中精度与计算效率的权衡问题，通过结合Hydra和Quant两种高效算法，在保持计算可行性的同时提升分类性能。研究发现当前元学习策略在有效利用算法互补性方面存在明显不足。


<details>
  <summary>Details</summary>
Motivation: 解决时间系列分类中高精度算法（如HIVE-COTE 2.0）训练时间过长的问题，探索通过组合互补的高效算法来获得集成学习优势，同时保持计算可行性。

Method: 采用六种集成配置组合Hydra（竞争卷积核）和Quant（分层区间分位数）两种算法，在10个大规模MONSTER数据集（7,898到1,168,774个训练实例）上进行评估。

Result: 最强配置将平均准确率从0.829提升到0.836，在10个数据集中的7个上取得成功。但预测组合集成仅捕获了11%的理论潜力，特征拼接方法通过学习新的决策边界超越了理论界限。

Conclusion: 时间序列分类的核心挑战已从确保算法差异性转向学习如何有效组合算法。当前元学习策略难以充分利用算法互补性，改进的组合策略可能将集成收益提升2-3倍。

Abstract: Time series classification faces a fundamental trade-off between accuracy and computational efficiency. While comprehensive ensembles like HIVE-COTE 2.0 achieve state-of-the-art accuracy, their 340-hour training time on the UCR benchmark renders them impractical for large-scale datasets. We investigate whether targeted combinations of two efficient algorithms from complementary paradigms can capture ensemble benefits while maintaining computational feasibility. Combining Hydra (competing convolutional kernels) and Quant (hierarchical interval quantiles) across six ensemble configurations, we evaluate performance on 10 large-scale MONSTER datasets (7,898 to 1,168,774 training instances). Our strongest configuration improves mean accuracy from 0.829 to 0.836, succeeding on 7 of 10 datasets. However, prediction-combination ensembles capture only 11% of theoretical oracle potential, revealing a substantial meta-learning optimization gap. Feature-concatenation approaches exceeded oracle bounds by learning novel decision boundaries, while prediction-level complementarity shows moderate correlation with ensemble gains. The central finding: the challenge has shifted from ensuring algorithms are different to learning how to combine them effectively. Current meta-learning strategies struggle to exploit the complementarity that oracle analysis confirms exists. Improved combination strategies could potentially double or triple ensemble gains across diverse time series classification applications.

</details>


### [345] [GradientSpace: Unsupervised Data Clustering for Improved Instruction Tuning](https://arxiv.org/abs/2512.06678)
*Shrihari Sridharan,Deepak Ravikumar,Anand Raghunathan,Kaushik Roy*

Main category: cs.LG

TL;DR: GradientSpace是一个在完整梯度空间中直接聚类样本的框架，通过在线SVD算法识别潜在技能，训练专用LoRA专家和轻量级路由器，以解决指令调优中梯度干扰问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据集通常由多样化信息混合组成，导致梯度干扰问题，即冲突的梯度将模型拉向相反方向，降低性能。现有基于语义或嵌入相似性的聚类方法无法捕捉数据如何影响模型参数，而直接聚类梯度的方法因随机投影导致精度损失，且依赖专家集合增加推理成本。

Method: 提出GradientSpace框架，在完整梯度空间中直接聚类样本；引入基于在线SVD的算法，操作LoRA梯度以识别潜在技能，避免存储所有样本梯度的不可行成本；为每个聚类训练专用LoRA专家，并训练轻量级路由器在推理时选择最佳专家。

Result: 在数学推理、代码生成、金融和创意写作任务上的实验表明，GradientSpace导致一致的专家专业化和持续的准确性提升，优于最先进的聚类方法和微调技术；路由到单个适当专家优于先前工作中的专家集合，同时显著减少推理延迟。

Conclusion: GradientSpace通过直接在完整梯度空间中聚类样本，有效解决了指令调优中的梯度干扰问题，实现了更好的专家专业化和准确性，同时降低了推理成本。

Abstract: Instruction tuning is one of the key steps required for adapting large language models (LLMs) to a broad spectrum of downstream applications. However, this procedure is difficult because real-world datasets are rarely homogeneous; they consist of a mixture of diverse information, causing gradient interference, where conflicting gradients pull the model in opposing directions, degrading performance. A common strategy to mitigate this issue is to group data based on semantic or embedding similarity. However, this fails to capture how data influences model parameters during learning. While recent works have attempted to cluster gradients directly, they randomly project gradients into lower dimensions to manage memory, which leads to accuracy loss. Moreover, these methods rely on expert ensembles which necessitates multiple inference passes and expensive on-the-fly gradient computations during inference. To address these limitations, we propose GradientSpace, a framework that clusters samples directly in full-dimensional gradient space. We introduce an online SVD-based algorithm that operates on LoRA gradients to identify latent skills without the infeasible cost of storing all sample gradients. Each cluster is used to train a specialized LoRA expert along with a lightweight router trained to select the best expert during inference. We show that routing to a single, appropriate expert outperforms expert ensembles used in prior work, while significantly reducing inference latency. Our experiments across mathematical reasoning, code generation, finance, and creative writing tasks demonstrate that GradientSpace leads to coherent expert specialization and consistent accuracy gains over state-of-the-art clustering methods and finetuning techniques.

</details>


### [346] [State Diversity Matters in Offline Behavior Distillation](https://arxiv.org/abs/2512.06692)
*Shiye Lei,Zhihao Cheng,Dacheng Tao*

Main category: cs.LG

TL;DR: 本文揭示了离线行为蒸馏(OBD)中原始数据集与合成数据集之间的不对齐问题，发现高状态多样性比高状态质量在训练损失较大时更重要，并提出了状态密度加权(SDW)算法来增强状态多样性。


<details>
  <summary>Details</summary>
Motivation: 传统OBD方法假设高质量原始数据集能产生优质合成数据集，但研究发现这种对应关系并不成立，存在数据集质量与性能的不对齐问题。

Method: 通过理论分析和实证研究，将状态质量和多样性分别关联到关键误差和周围误差的减少，提出状态密度加权(SDW)算法，通过状态密度的倒数加权蒸馏目标来增强状态多样性。

Result: 在多個D4RL数据集上的实验表明，当原始数据集状态多样性有限时，SDW能显著提升OBD性能。

Conclusion: 状态多样性在OBD中比状态质量更为关键，特别是在训练损失较大的情况下，SDW算法通过强调状态多样性有效解决了数据集不对齐问题。

Abstract: Offline Behavior Distillation (OBD), which condenses massive offline RL data into a compact synthetic behavioral dataset, offers a promising approach for efficient policy training and can be applied across various downstream RL tasks. In this paper, we uncover a misalignment between original and distilled datasets, observing that a high-quality original dataset does not necessarily yield a superior synthetic dataset. Through an empirical analysis of policy performance under varying levels of training loss, we show that datasets with greater state diversity outperforms those with higher state quality when training loss is substantial, as is often the case in OBD, whereas the relationship reverses under minimal loss, which contributes to the misalignment. By associating state quality and diversity in reducing pivotal and surrounding error, respectively, our theoretical analysis establishes that surrounding error plays a more crucial role in policy performance when pivotal error is large, thereby highlighting the importance of state diversity in OBD scenario. Furthermore, we propose a novel yet simple algorithm, state density weighted (SDW) OBD, which emphasizes state diversity by weighting the distillation objective using the reciprocal of state density, thereby distilling a more diverse state information into synthetic data. Extensive experiments across multiple D4RL datasets confirm that SDW significantly enhances OBD performance when the original dataset exhibits limited state diversity.

</details>


### [347] [Mitigating Barren plateaus in quantum denoising diffusion probabilistic models](https://arxiv.org/abs/2512.06695)
*Haipeng Cao,Kaining Zhang,Dacheng Tao,Zhaofeng Su*

Main category: cs.LG

TL;DR: 量子去噪扩散概率模型（QuDDPM）存在贫瘠高原问题，本文通过改进输入分布解决了该问题，提升了模型的可训练性和生成质量。


<details>
  <summary>Details</summary>
Motivation: QuDDPM虽然能高效学习量子数据，但由于使用2-design状态作为去噪过程输入，出现了贫瘠高原问题，严重影响了模型性能。

Method: 提出改进的QuDDPM，使用与Haar分布保持一定距离的分布作为输入，确保更好的可训练性。

Result: 实验证明该方法有效缓解了贫瘠高原问题，生成了更高质量的样本。

Conclusion: 该方法为可扩展和高效的量子生成学习铺平了道路。

Abstract: Quantum generative models leverage quantum superposition and entanglement to enhance learning efficiency for both classical and quantum data. The quantum denoising diffusion probabilistic model (QuDDPM), inspired by its classical counterpart, has been proposed as a promising framework for quantum generative learning. QuDDPM is capable of efficiently learning and generating quantum data, and it demonstrates excellent performance in learning correlated quantum noise models, quantum many-body phases, and the topological structure of quantum data. However, we show that barren plateaus emerge in QuDDPMs due to the use of 2-design states as the input for the denoising process, which severely undermines the performance of QuDDPM. Through theoretical analysis and experimental validation, we confirm the presence of barren plateaus in the original QuDDPM. To address this issue, we introduce an improved QuDDPM that utilizes a distribution maintaining a certain distance from the Haar distribution, ensuring better trainability. Experimental results demonstrate that our approach effectively mitigates the barren plateau problem and generates samples with higher quality, paving the way for scalable and efficient quantum generative learning.

</details>


### [348] [Pathway to $O(\sqrt{d})$ Complexity bound under Wasserstein metric of flow-based models](https://arxiv.org/abs/2512.06702)
*Xiangjun Meng,Zhongjian Wang*

Main category: cs.LG

TL;DR: 本文提供了分析工具来估计基于流的生成模型在Wasserstein度量下的误差，并建立了最优采样迭代复杂度为O(√d)的维度相关界限。误差由两部分控制：反向流推前映射的Lipschitz性（与维度无关）和局部离散化误差（与√d成正比）。


<details>
  <summary>Details</summary>
Motivation: 研究基于流的生成模型的误差估计和采样复杂度，特别是在高维情况下的理论保证。

Method: 使用Wasserstein度量分析流模型的误差，将误差分解为反向流推前映射的Lipschitz性和局部离散化误差两部分。在Föllmer过程和1-整流流模型下验证假设。

Result: 证明了采样迭代复杂度与协方差算子迹的平方根呈线性关系，即O(√d)，这与前向过程的不变分布相关。

Conclusion: 本文为基于流的生成模型提供了理论分析框架，证明了在高维情况下采样复杂度的最优界限，为实际应用提供了理论指导。

Abstract: We provide attainable analytical tools to estimate the error of flow-based generative models under the Wasserstein metric and to establish the optimal sampling iteration complexity bound with respect to dimension as $O(\sqrt{d})$. We show this error can be explicitly controlled by two parts: the Lipschitzness of the push-forward maps of the backward flow which scales independently of the dimension; and a local discretization error scales $O(\sqrt{d})$ in terms of dimension. The former one is related to the existence of Lipschitz changes of variables induced by the (heat) flow. The latter one consists of the regularity of the score function in both spatial and temporal directions.
  These assumptions are valid in the flow-based generative model associated with the Föllmer process and $1$-rectified flow under the Gaussian tail assumption. As a consequence, we show that the sampling iteration complexity grows linearly with the square root of the trace of the covariance operator, which is related to the invariant distribution of the forward process.

</details>


### [349] [A Novel Multimodal RUL Framework for Remaining Useful Life Estimation with Layer-wise Explanations](https://arxiv.org/abs/2512.06708)
*Waleed Razzaq,Yun-Bo Zhao*

Main category: cs.LG

TL;DR: 本文提出了一种新颖的多模态RUL框架，通过联合利用图像表示和时频表示来估计滚动轴承的剩余使用寿命，在减少数据需求的同时提高了模型的泛化能力和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有RUL估计方法存在泛化能力差、鲁棒性不足、数据需求高和可解释性有限等问题。滚动轴承是机械故障的常见原因，需要更可靠的RUL估计方法。

Method: 提出三分支架构：图像表示分支和时频表示分支分别使用扩张卷积块提取空间退化特征，融合分支将特征连接后输入LSTM建模时间模式，采用多头注意力机制突出重要特征。使用Bresenham线算法和连续小波变换进行信号转换，并引入多模态层相关传播技术增强可解释性。

Result: 在XJTU-SY和PRONOSTIA基准数据集上验证，该方法在已知和未知工况下均达到或超越现有最佳方法，在XJTU-SY上减少28%训练数据，PRONOSTIA上减少48%。模型具有强噪声鲁棒性，可视化证实预测的可解释性和可信度。

Conclusion: 该框架通过多模态学习和可解释性技术，显著提升了RUL估计性能，同时降低了数据需求，非常适合实际工业应用部署。

Abstract: Estimating the Remaining Useful Life (RUL) of mechanical systems is pivotal in Prognostics and Health Management (PHM). Rolling-element bearings are among the most frequent causes of machinery failure, highlighting the need for robust RUL estimation methods. Existing approaches often suffer from poor generalization, lack of robustness, high data demands, and limited interpretability. This paper proposes a novel multimodal-RUL framework that jointly leverages image representations (ImR) and time-frequency representations (TFR) of multichannel, nonstationary vibration signals. The architecture comprises three branches: (1) an ImR branch and (2) a TFR branch, both employing multiple dilated convolutional blocks with residual connections to extract spatial degradation features; and (3) a fusion branch that concatenates these features and feeds them into an LSTM to model temporal degradation patterns. A multi-head attention mechanism subsequently emphasizes salient features, followed by linear layers for final RUL regression. To enable effective multimodal learning, vibration signals are converted into ImR via the Bresenham line algorithm and into TFR using Continuous Wavelet Transform. We also introduce multimodal Layer-wise Relevance Propagation (multimodal-LRP), a tailored explainability technique that significantly enhances model transparency. The approach is validated on the XJTU-SY and PRONOSTIA benchmark datasets. Results show that our method matches or surpasses state-of-the-art baselines under both seen and unseen operating conditions, while requiring ~28 % less training data on XJTU-SY and ~48 % less on PRONOSTIA. The model exhibits strong noise resilience, and multimodal-LRP visualizations confirm the interpretability and trustworthiness of predictions, making the framework highly suitable for real-world industrial deployment.

</details>


### [350] [A Novel Deep Neural Network Architecture for Real-Time Water Demand Forecasting](https://arxiv.org/abs/2512.06714)
*Tony Salloom,Okyay Kaynak,Wei He*

Main category: cs.LG

TL;DR: 本文提出了一种基于GRU和K-means的短期用水需求预测模型，通过数据扩展技术降低极端点误差，同时减少模型复杂度。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在短期用水需求预测中虽然准确，但存在参数过多导致的复杂度问题，以及在极端点预测误差较大的问题。

Method: 使用门控循环单元(GRU)处理历史用水数据的序列关系，引入K-means无监督分类方法创建新特征；提出数据扩展技术，在实际数据中插入虚拟数据以缓解极端点附近的非线性问题。

Result: 模型复杂度降低至文献水平的六分之一，同时保持相同精度；数据扩展使误差降低约30%，但增加了训练时间。

Conclusion: 该方法有效解决了深度学习模型在用水需求预测中的复杂度和极端点误差问题，为供水系统优化控制提供了更实用的解决方案。

Abstract: Short-term water demand forecasting (StWDF) is the foundation stone in the derivation of an optimal plan for controlling water supply systems. Deep learning (DL) approaches provide the most accurate solutions for this purpose. However, they suffer from complexity problem due to the massive number of parameters, in addition to the high forecasting error at the extreme points. In this work, an effective method to alleviate the error at these points is proposed. It is based on extending the data by inserting virtual data within the actual data to relieve the nonlinearity around them. To our knowledge, this is the first work that considers the problem related to the extreme points. Moreover, the water demand forecasting model proposed in this work is a novel DL model with relatively low complexity. The basic model uses the gated recurrent unit (GRU) to handle the sequential relationship in the historical demand data, while an unsupervised classification method, K-means, is introduced for the creation of new features to enhance the prediction accuracy with less number of parameters. Real data obtained from two different water plants in China are used to train and verify the model proposed. The prediction results and the comparison with the state-of-the-art illustrate that the method proposed reduces the complexity of the model six times of what achieved in the literature while conserving the same accuracy. Furthermore, it is found that extending the data set significantly reduces the error by about 30%. However, it increases the training time.

</details>


### [351] [Decoding Motor Behavior Using Deep Learning and Reservoir Computing](https://arxiv.org/abs/2512.06725)
*Tian Lan*

Main category: cs.LG

TL;DR: 提出了一种结合卷积神经网络和回声状态网络的EEG解码新方法ESNNet，用于运动行为分类，在滑板技巧EEG数据集上取得了优于传统CNN方法的性能。


<details>
  <summary>Details</summary>
Motivation: 传统卷积架构如EEGNet和DeepConvNet能有效捕捉局部空间模式，但不擅长建模长程时间依赖和非线性动态，需要改进时间动态建模能力。

Method: 将回声状态网络（ESN）集成到解码流程中，ESN构建高维稀疏连接的循环储备池，擅长跟踪时间动态，与CNN的空间表征能力形成互补。

Result: 在经PREP管道预处理、MNE-Python实现的滑板技巧EEG数据集上，ESNNet获得了83.2%的受试者内准确率和51.3%的留一受试者交叉验证准确率，超越了广泛使用的CNN基线方法。

Conclusion: ESNNet通过结合CNN的空间表征能力和ESN的时间动态建模能力，为脑机接口中的EEG解码提供了更有效的解决方案，特别是在处理运动行为分类任务时表现出色。

Abstract: We present a novel approach to EEG decoding for non-invasive brain machine interfaces (BMIs), with a focus on motor-behavior classification. While conventional convolutional architectures such as EEGNet and DeepConvNet are effective in capturing local spatial patterns, they are markedly less suited for modeling long-range temporal dependencies and nonlinear dynamics. To address this limitation, we integrate an Echo State Network (ESN), a prominent paradigm in reservoir computing into the decoding pipeline. ESNs construct a high-dimensional, sparsely connected recurrent reservoir that excels at tracking temporal dynamics, thereby complementing the spatial representational power of CNNs. Evaluated on a skateboard-trick EEG dataset preprocessed via the PREP pipeline and implemented in MNE-Python, our ESNNet achieves 83.2% within-subject and 51.3% LOSO accuracies, surpassing widely used CNN-based baselines. Code is available at https://github.com/Yutiankunkun/Motion-Decoding-Using-Biosignals

</details>


### [352] [KV-CAR: KV Cache Compression using Autoencoders and KV Reuse in Large Language Models](https://arxiv.org/abs/2512.06727)
*Sourjya Roy,Shrihari Sridharan,Surya Selvam,Anand Raghunathan*

Main category: cs.LG

TL;DR: KV CAR是一个统一的、与架构无关的框架，通过轻量级自编码器和相似性驱动的重用机制，显著减少KV缓存存储需求，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型规模增大和上下文长度增加，KV缓存的内存需求成为自回归解码的主要瓶颈，限制了批量大小和上下文窗口的扩展。

Method: 结合两种互补技术：1）轻量级自编码器沿嵌入维度学习KV张量的紧凑表示；2）相似性驱动重用机制识别相邻层间特定注意力头的KV张量重用机会。

Result: 在GPT-2和TinyLLaMA模型上的评估显示，KV CAR可实现高达47.85%的KV缓存内存减少，对困惑度和零样本准确率影响极小。

Conclusion: KV CAR通过减少KV张量的维度和结构冗余，有效实现了内存高效的大语言模型推理，支持更长的序列长度和更大的批量大小。

Abstract: As Large Language Models (LLMs) scale in size and context length, the memory requirements of the key value (KV) cache have emerged as a major bottleneck during autoregressive decoding. The KV cache grows with sequence length and embedding dimension, often exceeding the memory footprint of the model itself and limiting achievable batch sizes and context windows. To address this challenge, we present KV CAR, a unified and architecture agnostic framework that significantly reduces KV cache storage while maintaining model fidelity. KV CAR combines two complementary techniques. First, a lightweight autoencoder learns compact representations of key and value tensors along the embedding dimension, compressing them before they are stored in the KV cache and restoring them upon retrieval. Second, a similarity driven reuse mechanism identifies opportunities to reuse KV tensors of specific attention heads across adjacent layers. Together, these methods reduce the dimensional and structural redundancy in KV tensors without requiring changes to the transformer architecture. Evaluations on GPT 2 and TinyLLaMA models across Wikitext, C4, PIQA, and Winogrande datasets demonstrate that KV CAR achieves up to 47.85 percent KV cache memory reduction with minimal impact on perplexity and zero shot accuracy. System level measurements on an NVIDIA A40 GPU show that the reduced KV footprint directly translates into longer sequence lengths and larger batch sizes during inference. These results highlight the effectiveness of KV CAR in enabling memory efficient LLM inference.

</details>


### [353] [Enhancing Interpretability of AR-SSVEP-Based Motor Intention Recognition via CNN-BiLSTM and SHAP Analysis on EEG Data](https://arxiv.org/abs/2512.06730)
*Lin Yang,Xiang Li,Xin Ma,Xinxin Zhao*

Main category: cs.LG

TL;DR: 本研究提出了一种基于增强现实的稳态视觉诱发电位（AR-SSVEP）系统，通过结合多头注意力机制的CNN-BiLSTM架构，提高运动意图识别能力，并利用SHAP方法增强模型可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决运动功能障碍患者康复训练参与度低的问题，以及传统SSVEP-BCI系统依赖外部视觉刺激设备、在实际应用中受限的局限性。

Method: 1. 设计基于HoloLens 2的四种EEG类别并收集七名健康受试者的EEG数据；2. 在传统CNN-BiLSTM架构基础上集成多头注意力机制（MACNN-BiLSTM）；3. 提取十个时频EEG特征，通过CNN学习高层表示，使用BiLSTM建模序列依赖关系，应用多头注意力机制突出运动意图相关模式；4. 使用SHAP方法可视化EEG特征对神经网络决策的贡献。

Result: 提出的方法能够有效识别运动意图，增强模型的可解释性。

Conclusion: 该研究通过AR-SSVEP系统和改进的深度学习架构，提高了运动意图识别的实时性和准确性，为运动障碍患者的康复提供了有效支持。

Abstract: Patients with motor dysfunction show low subjective engagement in rehabilitation training. Traditional SSVEP-based brain-computer interface (BCI) systems rely heavily on external visual stimulus equipment, limiting their practicality in real-world settings. This study proposes an augmented reality steady-state visually evoked potential (AR-SSVEP) system to address the lack of patient initiative and the high workload on therapists. Firstly, we design four HoloLens 2-based EEG classes and collect EEG data from seven healthy subjects for analysis. Secondly, we build upon the conventional CNN-BiLSTM architecture by integrating a multi-head attention mechanism (MACNN-BiLSTM). We extract ten temporal-spectral EEG features and feed them into a CNN to learn high-level representations. Then, we use BiLSTM to model sequential dependencies and apply a multi-head attention mechanism to highlight motor-intention-related patterns. Finally, the SHAP (SHapley Additive exPlanations) method is applied to visualize EEG feature contributions to the neural network's decision-making process, enhancing the model's interpretability. These findings enhance real-time motor intention recognition and support recovery in patients with motor impairments.

</details>


### [354] [Arc Gradient Descent: A Mathematically Derived Reformulation of Gradient Descent with Phase-Aware, User-Controlled Step Dynamics](https://arxiv.org/abs/2512.06737)
*Nikhil Verma,Joonas Linnosmaa,Espinosa-Leal Leonardo,Napat Vajragupta*

Main category: cs.LG

TL;DR: 本文提出了ArcGD优化器，在非凸基准函数和真实ML数据集上评估，相比Adam等先进优化器在收敛性和泛化性方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够有效处理非凸优化问题、具有更好收敛性和泛化能力的优化器，解决现有优化器在长期训练中可能出现的过拟合问题。

Method: 提出ArcGD优化器，通过两种配置评估消除学习率偏差：使用ArcGD有效学习率和Adam默认学习率。在Rosenbrock函数（2D-50,000D）和CIFAR-10数据集（8种MLP架构）上进行对比实验。

Result: ArcGD在大多数情况下优于Adam，在CIFAR-10上达到50.7%的最高平均测试准确率，优于AdamW（46.6%）、Adam（46.8%）、SGD（49.6%）和Lion（43.4%）。ArcGD在6/8架构上获胜或持平，且持续改进不出现回归。

Conclusion: ArcGD在几何压力测试和深度学习基准上表现强劲，具有广泛适用性。ArcGD变体可视为Lion优化器的特例，揭示了优化方法内在机制的联系。

Abstract: The paper presents the formulation, implementation, and evaluation of the ArcGD optimiser. The evaluation is conducted initially on a non-convex benchmark function and subsequently on a real-world ML dataset. The initial comparative study using the Adam optimiser is conducted on a stochastic variant of the highly non-convex and notoriously challenging Rosenbrock function, renowned for its narrow, curved valley, across dimensions ranging from 2D to 1000D and an extreme case of 50,000D. Two configurations were evaluated to eliminate learning-rate bias: (i) both using ArcGD's effective learning rate and (ii) both using Adam's default learning rate. ArcGD consistently outperformed Adam under the first setting and, although slower under the second, achieved super ior final solutions in most cases. In the second evaluation, ArcGD is evaluated against state-of-the-art optimizers (Adam, AdamW, Lion, SGD) on the CIFAR-10 image classification dataset across 8 diverse MLP architectures ranging from 1 to 5 hidden layers. ArcGD achieved the highest average test accuracy (50.7%) at 20,000 iterations, outperforming AdamW (46.6%), Adam (46.8%), SGD (49.6%), and Lion (43.4%), winning or tying on 6 of 8 architectures. Notably, while Adam and AdamW showed strong early convergence at 5,000 iterations, but regressed with extended training, whereas ArcGD continued improving, demonstrating generalization and resistance to overfitting without requiring early stopping tuning. Strong performance on geometric stress tests and standard deep-learning benchmarks indicates broad applicability, highlighting the need for further exploration. Moreover, it is also shown that a variant of ArcGD can be interpreted as a special case of the Lion optimiser, highlighting connections between the inherent mechanisms of such optimisation methods.

</details>


### [355] [KAN-Dreamer: Benchmarking Kolmogorov-Arnold Networks as Function Approximators in World Models](https://arxiv.org/abs/2512.07437)
*Chenwei Shi,Xueyu Luan*

Main category: cs.LG

TL;DR: 本文提出KAN-Dreamer，将KAN和FastKAN架构集成到DreamerV3框架中，替换特定MLP和卷积组件，在DeepMind Control Suite上验证性能与原始MLP架构相当。


<details>
  <summary>Details</summary>
Motivation: 结合DreamerV3的样本效率优势和KAN网络的参数效率与可解释性优势，同时通过FastKAN变体缓解KAN的计算开销问题。

Method: 在DreamerV3的三个子系统（视觉感知、潜在预测、行为学习）中，用KAN和FastKAN层替换特定MLP和卷积组件，并实现针对JAX的完全向量化版本和简化网格管理。

Result: 实验结果表明，使用适配的FastKAN作为奖励和继续预测器的替代方案，在样本效率和训练速度上与原始MLP架构保持同等性能水平。

Conclusion: 该研究为基于KAN的世界模型未来发展提供了初步探索，证明KAN架构在强化学习框架中的可行性和潜力。

Abstract: DreamerV3 is a state-of-the-art online model-based reinforcement learning (MBRL) algorithm known for remarkable sample efficiency. Concurrently, Kolmogorov-Arnold Networks (KANs) have emerged as a promising alternative to Multi-Layer Perceptrons (MLPs), offering superior parameter efficiency and interpretability. To mitigate KANs' computational overhead, variants like FastKAN leverage Radial Basis Functions (RBFs) to accelerate inference. In this work, we investigate integrating KAN architectures into the DreamerV3 framework. We introduce KAN-Dreamer, replacing specific MLP and convolutional components of DreamerV3 with KAN and FastKAN layers. To ensure efficiency within the JAX-based World Model, we implement a tailored, fully vectorized version with simplified grid management. We structure our investigation into three subsystems: Visual Perception, Latent Prediction, and Behavior Learning. Empirical evaluations on the DeepMind Control Suite (walker_walk) analyze sample efficiency, training time, and asymptotic performance. Experimental results demonstrate that utilizing our adapted FastKAN as a drop-in replacement for the Reward and Continue predictors yields performance on par with the original MLP-based architecture, maintaining parity in both sample efficiency and training speed. This report serves as a preliminary study for future developments in KAN-based world models.

</details>


### [356] [Multi-Scale Protein Structure Modelling with Geometric Graph U-Nets](https://arxiv.org/abs/2512.06752)
*Chang Liu,Vivian Li,Linus Leong,Vladimir Radenkovic,Pietro Liò,Chaitanya K. Joshi*

Main category: cs.LG

TL;DR: 本文提出了几何图U-Net，一种新的几何图神经网络架构，通过递归粗化和细化蛋白质图来学习多尺度表示，以解决现有GNN和Transformer无法捕捉蛋白质层次结构交互的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的几何GNN和Transformer依赖消息传递机制，无法有效捕捉控制蛋白质功能的层次交互（如全局结构域和长程变构调节），因此需要设计能够反映生物层次结构的网络架构。

Method: 引入几何图U-Nets，通过递归粗化和细化蛋白质图来学习多尺度表示，该层次化设计理论上比标准几何GNN更具表达力。

Result: 在蛋白质折叠分类任务中，几何U-Nets显著优于不变和等变基线模型，证明其能够学习定义蛋白质折叠的全局结构模式。

Conclusion: 该工作为设计能够学习生物分子多尺度结构的几何深度学习架构提供了理论基础，几何图U-Nets能够有效捕捉蛋白质的层次化结构特征。

Abstract: Geometric Graph Neural Networks (GNNs) and Transformers have become state-of-the-art for learning from 3D protein structures. However, their reliance on message passing prevents them from capturing the hierarchical interactions that govern protein function, such as global domains and long-range allosteric regulation. In this work, we argue that the network architecture itself should mirror this biological hierarchy. We introduce Geometric Graph U-Nets, a new class of models that learn multi-scale representations by recursively coarsening and refining the protein graph. We prove that this hierarchical design can theoretically more expressive than standard Geometric GNNs. Empirically, on the task of protein fold classification, Geometric U-Nets substantially outperform invariant and equivariant baselines, demonstrating their ability to learn the global structural patterns that define protein folds. Our work provides a principled foundation for designing geometric deep learning architectures that can learn the multi-scale structure of biomolecules.

</details>


### [357] [Optimal Analysis for Bandit Learning in Matching Markets with Serial Dictatorship](https://arxiv.org/abs/2512.06758)
*Zilong Wang,Shuai Li*

Main category: cs.LG

TL;DR: 本文提出了一种多级连续选择算法，在序列独裁假设下实现了与理论下界匹配的遗憾上界，解决了双边匹配市场中在线学习偏好问题。


<details>
  <summary>Details</summary>
Motivation: 现有研究在双边匹配市场的在线学习问题中，Sankararaman等人提出了理论下界，而Kong和Li的ET-GS算法达到了目前最好的上界，但上下界之间存在从N到K的差距。需要确定是下界还是上界需要改进。

Method: 提出了一种多级连续选择算法，在序列独裁假设下运行，该假设在市场参与者有一致评价标准时常见。

Result: 算法获得了O(Nlog(T)/Δ² + Klog(T)/Δ)的遗憾上界，与理论下界完全匹配。

Conclusion: 这是首个在带有多臂老虎机的匹配市场问题中达到理论下界的算法，解决了上下界之间的差距问题。

Abstract: The problem of two-sided matching markets is well-studied in computer science and economics, owing to its diverse applications across numerous domains. Since market participants are usually uncertain about their preferences in various online matching platforms, an emerging line of research is dedicated to the online setting where one-side participants (players) learn their unknown preferences through multiple rounds of interactions with the other side (arms). Sankararaman et al. provide an $Ω\left( \frac{N\log(T)}{Δ^2} + \frac{K\log(T)}Δ \right)$ regret lower bound for this problem under serial dictatorship assumption, where $N$ is the number of players, $K (\geq N)$ is the number of arms, $Δ$ is the minimum reward gap across players and arms, and $T$ is the time horizon. Serial dictatorship assumes arms have the same preferences, which is common in reality when one side participants have a unified evaluation standard. Recently, the work of Kong and Li proposes the ET-GS algorithm and achieves an $O\left( \frac{K\log(T)}{Δ^2} \right)$ regret upper bound, which is the best upper bound attained so far. Nonetheless, a gap between the lower and upper bounds, ranging from $N$ to $K$, persists. It remains unclear whether the lower bound or the upper bound needs to be improved. In this paper, we propose a multi-level successive selection algorithm that obtains an $O\left( \frac{N\log(T)}{Δ^2} + \frac{K\log(T)}Δ \right)$ regret bound when the market satisfies serial dictatorship. To the best of our knowledge, we are the first to propose an algorithm that matches the lower bound in the problem of matching markets with bandits.

</details>


### [358] [Measuring Over-smoothing beyond Dirichlet energy](https://arxiv.org/abs/2512.06782)
*Weiqi Guan,Zihao Shi*

Main category: cs.LG

TL;DR: 本文提出了一种基于高阶特征导数的节点相似性度量家族，以解决传统Dirichlet能量仅能捕捉一阶导数的局限性。通过理论分析揭示了过平滑衰减率与图拉普拉斯谱隙的内在联系，并实证证明基于注意力的GNN在这些新度量下存在过平滑问题。


<details>
  <summary>Details</summary>
Motivation: 传统Dirichlet能量作为量化过平滑的主流指标存在局限性，它只能捕捉一阶特征导数，无法全面评估高阶平滑现象。

Method: 提出基于高阶特征导数能量的广义节点相似性度量家族，通过理论分析研究连续热扩散和离散聚合算子下的Dirichlet能量衰减率，并建立与图拉普拉斯谱隙的数学联系。

Result: 理论分析揭示了过平滑衰减率与图拉普拉斯谱隙的内在关系，实证结果表明基于注意力的图神经网络在新提出的度量下确实存在过平滑问题。

Conclusion: 新提出的高阶度量能够更全面地评估图神经网络的过平滑现象，为理解和改进GNN的平滑特性提供了新的理论工具和实证依据。

Abstract: While Dirichlet energy serves as a prevalent metric for quantifying over-smoothing, it is inherently restricted to capturing first-order feature derivatives. To address this limitation, we propose a generalized family of node similarity measures based on the energy of higher-order feature derivatives. Through a rigorous theoretical analysis of the relationships among these measures, we establish the decay rates of Dirichlet energy under both continuous heat diffusion and discrete aggregation operators. Furthermore, our analysis reveals an intrinsic connection between the over-smoothing decay rate and the spectral gap of the graph Laplacian. Finally, empirical results demonstrate that attention-based Graph Neural Networks (GNNs) suffer from over-smoothing when evaluated under these proposed metrics.

</details>


### [359] [Angular Regularization for Positive-Unlabeled Learning on the Hypersphere](https://arxiv.org/abs/2512.06785)
*Vasileios Sevetlidis,George Pavlidis,Antonios Gasteratos*

Main category: cs.LG

TL;DR: AngularPU是一种基于余弦相似度和角度间隔的PU学习框架，通过可学习的原型向量表示正类，无需显式负类建模，并引入角度正则化器来改善未标记数据的分布分离。


<details>
  <summary>Details</summary>
Motivation: 现有PU学习方法要么依赖强分布假设，要么在高维设置中容易崩溃，需要一种更稳健且无需显式负类建模的方法。

Method: 在单位超球面上使用余弦相似度和角度间隔，正类由可学习的原型向量表示，分类简化为计算嵌入与原型之间的余弦相似度阈值。引入角度正则化器促使未标记嵌入在超球面上分散，改善分离效果。

Result: 在基准数据集上的实验表明，AngularPU在正样本稀缺和高维嵌入设置中表现优于现有PU方法，具有几何可解释性和可扩展性。

Conclusion: AngularPU提供了一种无需显式负类建模的PU学习框架，具有理论保证和实际优势，特别适用于高维和正样本稀缺的场景。

Abstract: Positive-Unlabeled (PU) learning addresses classification problems where only a subset of positive examples is labeled and the remaining data is unlabeled, making explicit negative supervision unavailable. Existing PU methods often rely on negative-risk estimation or pseudo-labeling, which either require strong distributional assumptions or can collapse in high-dimensional settings. We propose AngularPU, a novel PU framework that operates on the unit hypersphere using cosine similarity and angular margin. In our formulation, the positive class is represented by a learnable prototype vector, and classification reduces to thresholding the cosine similarity between an embedding and this prototype-eliminating the need for explicit negative modeling. To counteract the tendency of unlabeled embeddings to cluster near the positive prototype, we introduce an angular regularizer that encourages dispersion of the unlabeled set over the hypersphere, improving separation. We provide theoretical guarantees on the Bayes-optimality of the angular decision rule, consistency of the learned prototype, and the effect of the regularizer on the unlabeled distribution. Experiments on benchmark datasets demonstrate that AngularPU achieves competitive or superior performance compared to state-of-the-art PU methods, particularly in settings with scarce positives and high-dimensional embeddings, while offering geometric interpretability and scalability.

</details>


### [360] [Small-Gain Nash: Certified Contraction to Nash Equilibria in Differentiable Games](https://arxiv.org/abs/2512.06791)
*Vedansh Sharma*

Main category: cs.LG

TL;DR: 该论文提出Small-Gain Nash（SGN）方法，通过自定义块加权几何中的块小增益条件，为具有强交叉玩家耦合的非单调博弈提供收敛保证。


<details>
  <summary>Details</summary>
Motivation: 传统基于梯度的博弈学习收敛性分析需要伪梯度在欧几里得几何中满足（强）单调性条件，但这一条件在具有强交叉玩家耦合的简单博弈中常常不成立。

Method: 引入SGN方法，将局部曲率和交叉玩家Lipschitz耦合边界转换为可处理的收缩证书，构建加权块度量使伪梯度在该度量下强单调。使用投影Euler和RK4离散化方法，并基于SGN边际和局部Lipschitz常数推导显式步长边界。

Result: 在欧几里得单调性分析无法预测收敛的二次博弈中，SGN成功认证了收敛性。该方法可扩展到镜像/Fisher几何，用于马尔可夫博弈中的熵正则化策略梯度。

Conclusion: SGN提供了一个离线认证流程，可在紧凑区域估计曲率、耦合和Lipschitz参数，优化块权重以扩大SGN边际，为非单调博弈返回包含度量、收缩率和安全步长的结构性可计算收敛证书。

Abstract: Classical convergence guarantees for gradient-based learning in games require the pseudo-gradient to be (strongly) monotone in Euclidean geometry as shown by rosen(1965), a condition that often fails even in simple games with strong cross-player couplings. We introduce Small-Gain Nash (SGN), a block small-gain condition in a custom block-weighted geometry. SGN converts local curvature and cross-player Lipschitz coupling bounds into a tractable certificate of contraction. It constructs a weighted block metric in which the pseudo-gradient becomes strongly monotone on any region where these bounds hold, even when it is non-monotone in the Euclidean sense. The continuous flow is exponentially contracting in this designed geometry, and projected Euler and RK4 discretizations converge under explicit step-size bounds derived from the SGN margin and a local Lipschitz constant. Our analysis reveals a certified ``timescale band'', a non-asymptotic, metric-based certificate that plays a TTUR-like role: rather than forcing asymptotic timescale separation via vanishing, unequal step sizes, SGN identifies a finite band of relative metric weights for which a single-step-size dynamics is provably contractive. We validate the framework on quadratic games where Euclidean monotonicity analysis fails to predict convergence, but SGN successfully certifies it, and extend the construction to mirror/Fisher geometries for entropy-regularized policy gradient in Markov games. The result is an offline certification pipeline that estimates curvature, coupling, and Lipschitz parameters on compact regions, optimizes block weights to enlarge the SGN margin, and returns a structural, computable convergence certificate consisting of a metric, contraction rate, and safe step-sizes for non-monotone games.

</details>


### [361] [Partial Inverse Design of High-Performance Concrete Using Cooperative Neural Networks for Constraint-Aware Mix Generation](https://arxiv.org/abs/2512.06813)
*Agung Nugraha,Heungjun Im,Jihwan Lee*

Main category: cs.LG

TL;DR: 该研究提出了一种协作神经网络框架，用于高性能混凝土的部分逆向设计，能够在单一前向传递中生成满足约束条件且性能一致的配合比设计。


<details>
  <summary>Details</summary>
Motivation: 高性能混凝土需要复杂的配合比设计，涉及多个相互依赖的变量和实际约束。虽然数据驱动方法在正向设计预测建模方面取得了进展，但逆向设计（特别是部分变量固定的约束情况下）仍然有限。

Method: 提出协作神经网络框架，结合两个耦合的神经网络模型：一个插补模型推断未确定变量，一个替代模型预测抗压强度。通过协作学习，模型无需重新训练即可适应不同约束组合。

Result: 在基准数据集上评估，该模型实现了0.87-0.92的稳定R平方值，与自编码器基线相比平均减少50%的均方误差，与贝叶斯推理相比平均减少70%的均方误差。

Conclusion: 协作神经网络为混凝土工程中的约束感知、数据驱动配合比设计提供了准确、稳健且计算高效的基础。

Abstract: High-performance concrete offers exceptional strength and durability but requires complex mix designs involving many interdependent variables and practical constraints. While data-driven methods have advanced predictive modeling for forward design, inverse design, which focuses on determining mix compositions that achieve target performance, remains limited, particularly in design situations where some mix variables are fixed by constraints and only the remaining variables must be determined. This study proposes a cooperative neural network framework for the partial inverse design of high-performance concrete. The framework combines two coupled neural network models, an imputation model that infers the undetermined variables and a surrogate model that predicts compressive strength. Through cooperative learning, the model generates valid and performance-consistent mix designs in a single forward pass while accommodating different constraint combinations without retraining. Its performance is compared with both probabilistic and generative approaches, including Bayesian inference based on a Gaussian process surrogate and autoencoder-based models. Evaluated on a benchmark dataset, the proposed model achieves stable and higher R-squared values of 0.87-0.92 and reduces mean squared error by an average of 50 percent compared with autoencoder baselines and by an average of 70 percent compared with Bayesian inference. The results demonstrate that the cooperative neural network provides an accurate, robust, and computationally efficient foundation for constraint-aware, data-driven mix proportioning in concrete engineering.

</details>


### [362] [Neural Factorization-based Bearing Fault Diagnosis](https://arxiv.org/abs/2512.06837)
*Zhenhao Li,Xu Cheng,Yi Zhou*

Main category: cs.LG

TL;DR: 提出基于神经分解的分类框架NFC用于高铁轴承故障诊断，通过多模态特征嵌入和神经分解融合技术，在复杂条件下实现比传统方法更优的诊断性能。


<details>
  <summary>Details</summary>
Motivation: 高铁轴承作为列车运行系统的核心部件，其健康状况直接影响运行安全。传统诊断方法在复杂工况下诊断精度不足，需要更有效的解决方案。

Method: 提出NFC框架：1）将振动时间序列嵌入为多个模态特征向量以捕捉多样化故障模式；2）利用神经分解原理融合这些向量为统一振动表示。具体实现CP-NFC和Tucker-NFC两种模型。

Result: 实验结果表明，CP-NFC和Tucker-NFC模型均优于传统机器学习方法，具有更优越的诊断性能。

Conclusion: 该研究为高铁轴承监测提供了有效的诊断策略选择依据，通过比较分析为实际应用提供了有价值的实证证据和实践指导。

Abstract: This paper studies the key problems of bearing fault diagnosis of high-speed train. As the core component of the train operation system, the health of bearings is directly related to the safety of train operation. The traditional diagnostic methods are facing the challenge of insufficient diagnostic accuracy under complex conditions. To solve these problems, we propose a novel Neural Factorization-based Classification (NFC) framework for bearing fault diagnosis. It is built on two core idea: 1) Embedding vibration time series into multiple mode-wise latent feature vectors to capture diverse fault-related patterns; 2) Leveraging neural factorization principles to fuse these vectors into a unified vibration representation. This design enables effective mining of complex latent fault characteristics from raw time-series data. We further instantiate the framework with two models CP-NFC and Tucker-NFC based on CP and Tucker fusion schemes, respectively. Experimental results show that both models achieve superior diagnostic performance compared with traditional machine learning methods. The comparative analysis provides valuable empirical evidence and practical guidance for selecting effective diagnostic strategies in high-speed train bearing monitoring.

</details>


### [363] [Know your Trajectory -- Trustworthy Reinforcement Learning deployment through Importance-Based Trajectory Analysis](https://arxiv.org/abs/2512.06917)
*Clifford F,Devika Jay,Abhishek Sarkar,Satheesh K Perepu,Santhosh G S,Kaushik Dey,Balaraman Ravindran*

Main category: cs.LG

TL;DR: 本文提出了一种新的可解释强化学习框架，通过定义和聚合状态重要性度量来对完整轨迹进行排名，从而解释智能体的长期行为。


<details>
  <summary>Details</summary>
Motivation: 随着强化学习智能体在现实应用中的部署增加，确保其行为透明可信变得至关重要。现有可解释强化学习工作主要关注局部单步决策，而缺乏对智能体长期行为的解释。

Method: 引入一个结合Q值差异和"激进项"的新状态重要性度量，该激进项捕捉智能体达到目标的亲和力。通过该度量对完整轨迹进行排名，并从关键状态生成反事实推演来验证路径选择的优越性。

Result: 实验表明，该方法能成功从异构智能体经验中识别最优轨迹，且相比经典方法能更有效地识别最优行为。

Conclusion: 该方法为"为什么选择这条路径而不是其他"提供了强有力的解释，是实现可信自主系统的重要一步。

Abstract: As Reinforcement Learning (RL) agents are increasingly deployed in real-world applications, ensuring their behavior is transparent and trustworthy is paramount. A key component of trust is explainability, yet much of the work in Explainable RL (XRL) focuses on local, single-step decisions. This paper addresses the critical need for explaining an agent's long-term behavior through trajectory-level analysis. We introduce a novel framework that ranks entire trajectories by defining and aggregating a new state-importance metric. This metric combines the classic Q-value difference with a "radical term" that captures the agent's affinity to reach its goal, providing a more nuanced measure of state criticality. We demonstrate that our method successfully identifies optimal trajectories from a heterogeneous collection of agent experiences. Furthermore, by generating counterfactual rollouts from critical states within these trajectories, we show that the agent's chosen path is robustly superior to alternatives, thereby providing a powerful "Why this, and not that?" explanation. Our experiments in standard OpenAI Gym environments validate that our proposed importance metric is more effective at identifying optimal behaviors compared to classic approaches, offering a significant step towards trustworthy autonomous systems.

</details>


### [364] [Parent-Guided Semantic Reward Model (PGSRM): Embedding-Based Reward Functions for Reinforcement Learning of Transformer Language Models](https://arxiv.org/abs/2512.06920)
*Alexandr Plashchinsky*

Main category: cs.LG

TL;DR: PGSRM是一种轻量级强化学习奖励框架，使用父模型参考输出与子模型生成输出的嵌入余弦相似度作为语义奖励信号，替代传统二元正确性信号或人类偏好数据。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习方法依赖二元正确性信号、人类偏好数据或训练奖励模型，这些方法需要大量人工标注或额外模型训练。PGSRM旨在开发一种无需人工标注、无需额外训练模型的轻量级语义奖励框架。

Method: PGSRM通过计算父模型参考输出嵌入与子模型生成输出嵌入之间的余弦相似度来生成密集的语义奖励信号，完全基于预训练模型的嵌入空间，不依赖任何人工标注或额外训练。

Result: 在五个语言任务上的实验表明，PGSRM相比二元奖励基线产生更平滑的奖励改进和更稳定的PPO动态，证明基于嵌入的语义奖励是RLHF式奖励建模的实用替代方案。

Conclusion: PGSRM为小型Transformer模型的父引导对齐提供了一种实用且有效的语义奖励方法，无需人类标注或额外模型训练，在多个语言任务上表现出良好的性能。

Abstract: We introduce the Parent-Guided Semantic Reward Model (PGSRM), a lightweight reward framework for reinforcement learning (RL) of transformer language models. PGSRM replaces binary correctness signals, human preference data, and trained reward models with a simple signal: cosine similarity between a parent model's reference output embedding and a child model's generated output for the same input. This yields a dense, semantically meaningful reward with no human annotation or additional model training. We apply PGSRM on five language tasks and find that it produces smoother reward improvement and more stable PPO dynamics than a binary reward baseline, suggesting that embedding-based semantic rewards are a practical alternative to RLHF-style reward modeling for parent-guided alignment in smaller transformer models.

</details>


### [365] [Deep Reinforcement Learning for Phishing Detection with Transformer-Based Semantic Features](https://arxiv.org/abs/2512.06925)
*Aseer Al Faisal*

Main category: cs.LG

TL;DR: 本研究提出了一种结合RoBERTa语义嵌入和手工词汇特征的QR-DQN方法，用于提高网络钓鱼检测的准确性并处理不确定性，在测试集上达到了99.86%的准确率。


<details>
  <summary>Details</summary>
Motivation: 网络钓鱼攻击通过欺诈消息和篡改网站等手段欺骗用户泄露个人信息，造成经济损失。传统DQN方法仅估计单一标量Q值，无法有效处理不确定性，需要改进检测方法的稳定性和泛化能力。

Method: 采用分位数回归深度Q网络(QR-DQN)，整合RoBERTa语义嵌入和手工词汇特征，通过建模回报分布来提升模型性能。使用来自PhishTank、OpenPhish等源的105,000个URL数据集，采用80/20的训练测试划分。

Result: QR-DQN框架在测试集上达到99.86%准确率、99.75%精确率、99.96%召回率和99.85% F1分数。相比仅使用词汇特征的标准DQN，混合方法将泛化差距从1.66%降低到0.04%。五折交叉验证显示平均准确率为99.90%，标准差0.04%。

Conclusion: 提出的混合方法能有效识别网络钓鱼威胁，适应不断演变的攻击策略，并对未见数据具有良好的泛化能力。

Abstract: Phishing is a cybercrime in which individuals are deceived into revealing personal information, often resulting in financial loss. These attacks commonly occur through fraudulent messages, misleading advertisements, and compromised legitimate websites. This study proposes a Quantile Regression Deep Q-Network (QR-DQN) approach that integrates RoBERTa semantic embeddings with handcrafted lexical features to enhance phishing detection while accounting for uncertainties. Unlike traditional DQN methods that estimate single scalar Q-values, QR-DQN leverages quantile regression to model the distribution of returns, improving stability and generalization on unseen phishing data. A diverse dataset of 105,000 URLs was curated from PhishTank, OpenPhish, Cloudflare, and other sources, and the model was evaluated using an 80/20 train-test split. The QR-DQN framework achieved a test accuracy of 99.86%, precision of 99.75%, recall of 99.96%, and F1-score of 99.85%, demonstrating high effectiveness. Compared to standard DQN with lexical features, the hybrid QR-DQN with lexical and semantic features reduced the generalization gap from 1.66% to 0.04%, indicating significant improvement in robustness. Five-fold cross-validation confirmed model reliability, yielding a mean accuracy of 99.90% with a standard deviation of 0.04%. These results suggest that the proposed hybrid approach effectively identifies phishing threats, adapts to evolving attack strategies, and generalizes well to unseen data.

</details>


### [366] [Evaluating the Sensitivity of BiLSTM Forecasting Models to Sequence Length and Input Noise](https://arxiv.org/abs/2512.06926)
*Salma Albelali,Moataz Ahmed*

Main category: cs.LG

TL;DR: 本文通过实证分析发现，双向LSTM模型在时间序列预测中的性能受输入序列长度和加性噪声的显著影响，过长序列会增加过拟合风险，噪声会降低预测精度，两者同时存在时模型稳定性最差。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在时间序列预测中应用广泛，但现有研究对输入数据特性（如序列长度和噪声）如何影响模型鲁棒性和泛化能力的关注不足。

Method: 开发了模块化可复现的预测流程，在三个不同采样频率的真实数据集上进行控制实验，系统评估BiLSTM模型在不同输入条件下的表现。

Result: 主要发现：1）长输入序列显著增加过拟合和数据泄露风险；2）加性噪声持续降低预测精度；3）两个因素同时存在时模型稳定性下降最严重。

Conclusion: 当前基于深度学习的预测流程存在重要局限性，需要采用数据感知的设计策略来开发更可靠和可泛化的预测系统。

Abstract: Deep learning (DL) models, a specialized class of multilayer neural networks, have become central to time-series forecasting in critical domains such as environmental monitoring and the Internet of Things (IoT). Among these, Bidirectional Long Short-Term Memory (BiLSTM) architectures are particularly effective in capturing complex temporal dependencies. However, the robustness and generalization of such models are highly sensitive to input data characteristics - an aspect that remains underexplored in existing literature. This study presents a systematic empirical analysis of two key data-centric factors: input sequence length and additive noise. To support this investigation, a modular and reproducible forecasting pipeline is developed, incorporating standardized preprocessing, sequence generation, model training, validation, and evaluation. Controlled experiments are conducted on three real-world datasets with varying sampling frequencies to assess BiLSTM performance under different input conditions. The results yield three key findings: (1) longer input sequences significantly increase the risk of overfitting and data leakage, particularly in data-constrained environments; (2) additive noise consistently degrades predictive accuracy across sampling frequencies; and (3) the simultaneous presence of both factors results in the most substantial decline in model stability. While datasets with higher observation frequencies exhibit greater robustness, they remain vulnerable when both input challenges are present. These findings highlight important limitations in current DL-based forecasting pipelines and underscore the need for data-aware design strategies. This work contributes to a deeper understanding of DL model behavior in dynamic time-series environments and provides practical insights for developing more reliable and generalizable forecasting systems.

</details>


### [367] [Adaptive Normalization Mamba with Multi Scale Trend Decomposition and Patch MoE Encoding](https://arxiv.org/abs/2512.06929)
*MinCheol Jeon*

Main category: cs.LG

TL;DR: AdaMamba是一个统一的时间序列预测架构，通过自适应归一化、多尺度趋势提取和上下文序列建模来解决非平稳性、多尺度时间模式和分布偏移问题，在稳定性和准确性上优于传统Transformer基线。


<details>
  <summary>Details</summary>
Motivation: 现实世界时间序列预测面临非平稳性、多尺度时间模式和分布偏移等挑战，这些因素会降低模型的稳定性和准确性。

Method: 1. 自适应归一化块：通过多尺度卷积趋势提取和通道重校准去除非平稳成分；2. 上下文编码器：结合补丁嵌入、位置编码和Mamba增强的Transformer层；3. 轻量级预测头生成多步预测；4. 反归一化机制通过重新整合局部趋势确保鲁棒性。

Result: 实验评估表明，AdaMamba在稳定性和准确性方面相比传统Transformer基线取得了持续改进，有效缓解了协变量偏移并增强了预测可靠性。

Conclusion: AdaMamba通过自适应归一化和专家增强的上下文建模相结合，为异构数据集提供了强大的预测能力，具有模块化可扩展性，支持确定性预测和概率扩展。

Abstract: Time series forecasting in real world environments faces significant challenges non stationarity, multi scale temporal patterns, and distributional shifts that degrade model stability and accuracy. This study propose AdaMamba, a unified forecasting architecture that integrates adaptive normalization, multi scale trend extraction, and contextual sequence modeling to address these challenges. AdaMamba begins with an Adaptive Normalization Block that removes non stationary components through multi scale convolutional trend extraction and channel wise recalibration, enabling consistent detrending and variance stabilization. The normalized sequence is then processed by a Context Encoder that combines patch wise embeddings, positional encoding, and a Mamba enhanced Transformer layer with a mixture of experts feed forward module, allowing efficient modeling of both long range dependencies and local temporal dynamics. A lightweight prediction head generates multi horizon forecasts, and a denormalization mechanism reconstructs outputs by reintegrating local trends to ensure robustness under varying temporal conditions. AdaMamba provides strong representational capacity with modular extensibility, supporting deterministic prediction and compatibility with probabilistic extensions. Its design effectively mitigates covariate shift and enhances predictive reliability across heterogeneous datasets. Experimental evaluations demonstrate that AdaMamba's combination of adaptive normalization and expert augmented contextual modeling yields consistent improvements in stability and accuracy over conventional Transformer based baselines.

</details>


### [368] [Hidden Leaks in Time Series Forecasting: How Data Leakage Affects LSTM Evaluation Across Configurations and Validation Strategies](https://arxiv.org/abs/2512.06932)
*Salma Albelali,Moataz Ahmed*

Main category: cs.LG

TL;DR: 该研究探讨了数据泄漏对LSTM时间序列预测模型性能评估的影响，发现验证方法的选择、输入窗口大小和滞后步长都会显著影响泄漏敏感性，其中10折交叉验证最容易受泄漏影响，而2-way和3-way分割更稳健。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在时间序列预测中广泛使用，但评估完整性常因数据泄漏而受损。数据泄漏指在数据集划分前构建输入输出序列，导致未来信息无意中影响训练过程。本研究旨在量化数据泄漏对性能的影响，并分析不同验证方法对泄漏敏感性的调节作用。

Method: 研究比较了三种常用验证技术（2-way分割、3-way分割和10折交叉验证）在泄漏（预分割序列生成）和清洁条件下的表现。清洁条件通过在数据分割后构建序列来减轻泄漏风险。使用RMSE增益（泄漏与清洁设置的RMSE百分比差异）来评估泄漏影响。

Result: 实证结果显示，10折交叉验证在较长滞后步长下RMSE增益高达20.5%，而2-way和3-way分割更稳健，RMSE增益通常保持在5%以下。较小的输入窗口和较长的滞后步长会增加泄漏风险，而较大的窗口有助于减少泄漏。

Conclusion: 研究强调了需要配置感知、抗泄漏的评估流程，以确保性能估计的可靠性。验证方法的选择、窗口大小和滞后步长配置都对防止数据泄漏至关重要。

Abstract: Deep learning models, particularly Long Short-Term Memory (LSTM) networks, are widely used in time series forecasting due to their ability to capture complex temporal dependencies. However, evaluation integrity is often compromised by data leakage, a methodological flaw in which input-output sequences are constructed before dataset partitioning, allowing future information to unintentionally influence training. This study investigates the impact of data leakage on performance, focusing on how validation design mediates leakage sensitivity. Three widely used validation techniques (2-way split, 3-way split, and 10-fold cross-validation) are evaluated under both leaky (pre-split sequence generation) and clean conditions, with the latter mitigating leakage risk by enforcing temporal separation during data splitting prior to sequence construction. The effect of leakage is assessed using RMSE Gain, which measures the relative increase in RMSE caused by leakage, computed as the percentage difference between leaky and clean setups. Empirical results show that 10-fold cross-validation exhibits RMSE Gain values of up to 20.5% at extended lag steps. In contrast, 2-way and 3-way splits demonstrate greater robustness, typically maintaining RMSE Gain below 5% across diverse configurations. Moreover, input window size and lag step significantly influence leakage sensitivity: smaller windows and longer lags increase the risk of leakage, whereas larger windows help reduce it. These findings underscore the need for configuration-aware, leakage-resistant evaluation pipelines to ensure reliable performance estimation.

</details>


### [369] [A Unifying Human-Centered AI Fairness Framework](https://arxiv.org/abs/2512.06944)
*Munshi Mahbubur Rahman,Shimei Pan,James R. Foulds*

Main category: cs.LG

TL;DR: 本文提出了一个统一的人类中心公平性框架，系统性地整合了八种不同的公平性指标，帮助利益相关者根据自身价值观和情境选择适当的公平性干预措施。


<details>
  <summary>Details</summary>
Motivation: AI在关键社会领域的广泛应用加剧了公平性问题，但现有方法难以平衡不同公平性概念与预测准确性之间的权衡，阻碍了公平AI系统的实际部署。

Method: 开发了一个统一的公平性框架，结合了个体与群体公平性、边际内与交叉性假设、结果导向与机会均等视角，使用一致的公式化表达，允许利益相关者为多个公平性目标分配权重。

Result: 在四个真实数据集（UCI成人普查、COMPAS、德国信贷、MEPS）上的应用表明，调整权重可以揭示不同公平性指标之间的细微权衡。案例研究展示了该框架在司法决策和医疗保健中的实际应用价值。

Conclusion: 该框架为公平AI系统的实际部署提供了实用且价值敏感的方法，支持多利益相关者妥协，促进公平AI系统的负责任部署。

Abstract: The increasing use of Artificial Intelligence (AI) in critical societal domains has amplified concerns about fairness, particularly regarding unequal treatment across sensitive attributes such as race, gender, and socioeconomic status. While there has been substantial work on ensuring AI fairness, navigating trade-offs between competing notions of fairness as well as predictive accuracy remains challenging, creating barriers to the practical deployment of fair AI systems. To address this, we introduce a unifying human-centered fairness framework that systematically covers eight distinct fairness metrics, formed by combining individual and group fairness, infra-marginal and intersectional assumptions, and outcome-based and equality-of-opportunity (EOO) perspectives. This structure allows stakeholders to align fairness interventions with their values and contextual considerations. The framework uses a consistent and easy-to-understand formulation for all metrics to reduce the learning curve for non-experts. Rather than privileging a single fairness notion, the framework enables stakeholders to assign weights across multiple fairness objectives, reflecting their priorities and facilitating multi-stakeholder compromises. We apply this approach to four real-world datasets: the UCI Adult census dataset for income prediction, the COMPAS dataset for criminal recidivism, the German Credit dataset for credit risk assessment, and the MEPS dataset for healthcare utilization. We show that adjusting weights reveals nuanced trade-offs between different fairness metrics. Finally, through case studies in judicial decision-making and healthcare, we demonstrate how the framework can inform practical and value-sensitive deployment of fair AI systems.

</details>


### [370] [Comparing BFGS and OGR for Second-Order Optimization](https://arxiv.org/abs/2512.06969)
*Adrian Przybysz,Mikołaj Kołek,Franciszek Sobota,Jarek Duda*

Main category: cs.LG

TL;DR: 本文比较了BFGS方法中的Sherman-Morrison更新与新型Online Gradient Regression（OGR）方法在Hessian矩阵估计中的表现，OGR在非凸优化中表现更优。


<details>
  <summary>Details</summary>
Motivation: 神经网络训练中的Hessian矩阵估计面临高维度和高计算成本的挑战，传统方法如BFGS在非凸优化中存在局限性。

Method: OGR使用指数移动平均对梯度相对于位置进行回归，在线估计二阶导数而无需Hessian矩阵求逆，能够处理非凸结构。

Result: 在标准测试函数上的评估表明，OGR比BFGS收敛更快且损失更低，特别是在非凸设置中。

Conclusion: OGR方法提供了一种更灵活有效的Hessian估计方式，特别适用于非凸优化问题。

Abstract: Estimating the Hessian matrix, especially for neural network training, is a challenging problem due to high dimensionality and cost. In this work, we compare the classical Sherman-Morrison update used in the popular BFGS method (Broy-den-Fletcher-Goldfarb-Shanno), which maintains a positive definite Hessian approximation under a convexity assumption, with a novel approach called Online Gradient Regression (OGR). OGR performs regression of gradients against positions using an exponential moving average to estimate second derivatives online, without requiring Hessian inversion. Unlike BFGS, OGR allows estimation of a general (not necessarily positive definite) Hessian and can thus handle non-convex structures. We evaluate both methods across standard test functions and demonstrate that OGR achieves faster convergence and improved loss, particularly in non-convex settings.

</details>


### [371] [Prediction with Expert Advice under Local Differential Privacy](https://arxiv.org/abs/2512.06971)
*Ben Jacobsen,Kassem Fawaz*

Main category: cs.LG

TL;DR: 该论文研究了在局部差分隐私(LDP)约束下的专家预测问题，提出了两种改进算法RW-AdaBatch和RW-Meta，通过隐私放大和元学习技术提升性能，并在COVID-19医院数据预测任务中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 传统专家预测算法在LDP约束下性能受限，需要开发既能保护隐私又能保持高预测准确性的新方法。特别是在医疗数据等敏感场景中，隐私保护至关重要。

Method: 1. RW-AdaBatch算法利用LDP诱导的有限切换行为实现隐私放大，类似离线学习中的混洗模型；2. RW-Meta算法开发了在LDP约束下选择非平凡学习专家的一般方法，无需额外隐私成本；3. 基于随机游走理论分析算法性能。

Result: 1. RW-AdaBatch在易处理数据上隐私保护效果更强且无效用损失；2. RW-Meta在COVID-19医院数据预测任务中比传统基线和最先进的中心差分隐私算法性能提升1.5-3倍；3. 推导了与专家独立性程度成反比的遗憾界。

Conclusion: 提出的两种算法在LDP约束下显著提升了专家预测的性能，特别是在医疗数据等敏感应用场景中具有重要价值，为隐私保护的在线学习提供了新的解决方案。

Abstract: We study the classic problem of prediction with expert advice under the constraint of local differential privacy (LDP). In this context, we first show that a classical algorithm naturally satisfies LDP and then design two new algorithms that improve it: RW-AdaBatch and RW-Meta. For RW-AdaBatch, we exploit the limited-switching behavior induced by LDP to provide a novel form of privacy amplification that grows stronger on easier data, analogous to the shuffle model in offline learning. Drawing on the theory of random walks, we prove that this improvement carries essentially no utility cost. For RW-Meta, we develop a general method for privately selecting between experts that are themselves non-trivial learning algorithms, and we show that in the context of LDP this carries no extra privacy cost. In contrast, prior work has only considered data-independent experts. We also derive formal regret bounds that scale inversely with the degree of independence between experts. Our analysis is supplemented by evaluation on real-world data reported by hospitals during the COVID-19 pandemic; RW-Meta outperforms both the classical baseline and a state-of-the-art \textit{central} DP algorithm by 1.5-3$\times$ on the task of predicting which hospital will report the highest density of COVID patients each week.

</details>


### [372] [LLM-Driven Composite Neural Architecture Search for Multi-Source RL State Encoding](https://arxiv.org/abs/2512.06982)
*Yu Yu,Qian Xie,Nairen Cao,Li Jin*

Main category: cs.LG

TL;DR: 本文提出了一种基于大语言模型的神经架构搜索方法，用于高效设计多源强化学习中的复合状态编码器。


<details>
  <summary>Details</summary>
Motivation: 多源信息（如传感器测量、时间序列信号、图像观测和文本指令）的状态编码器设计在强化学习中仍未被充分探索，通常需要手动设计。现有NAS方法忽略了模块中间输出的有用信息，限制了多源RL设置中的样本效率。

Method: 将多源状态编码器设计形式化为复合神经架构搜索问题，提出LLM驱动的NAS流程，利用语言模型先验和中间输出信号来指导高效搜索高性能复合状态编码器。

Result: 在混合自主交通控制任务上，该方法比传统NAS基线和基于LLM的GENIUS框架使用更少的候选评估发现了更高性能的架构。

Conclusion: 所提出的LLM驱动NAS方法能够更高效地设计多源强化学习中的复合状态编码器，提高了搜索效率和性能。

Abstract: Designing state encoders for reinforcement learning (RL) with multiple information sources -- such as sensor measurements, time-series signals, image observations, and textual instructions -- remains underexplored and often requires manual design. We formalize this challenge as a problem of composite neural architecture search (NAS), where multiple source-specific modules and a fusion module are jointly optimized. Existing NAS methods overlook useful side information from the intermediate outputs of these modules -- such as their representation quality -- limiting sample efficiency in multi-source RL settings. To address this, we propose an LLM-driven NAS pipeline that leverages language-model priors and intermediate-output signals to guide sample-efficient search for high-performing composite state encoders. On a mixed-autonomy traffic control task, our approach discovers higher-performing architectures with fewer candidate evaluations than traditional NAS baselines and the LLM-based GENIUS framework.

</details>


### [373] [OXtal: An All-Atom Diffusion Model for Organic Crystal Structure Prediction](https://arxiv.org/abs/2512.06987)
*Emily Jin,Andrei Cristian Nica,Mikhail Galkin,Jarrid Rector-Brooks,Kin Long Kelvin Lee,Santiago Miret,Frances H. Arnold,Michael Bronstein,Avishek Joey Bose,Alexander Tong,Cheng-Hao Liu*

Main category: cs.LG

TL;DR: OXtal是一个100M参数的全原子扩散模型，通过直接学习分子内构象和周期性堆积的条件联合分布，实现了从2D化学图到3D分子晶体结构的准确预测。


<details>
  <summary>Details</summary>
Motivation: 分子晶体结构预测是计算化学中长期存在的开放挑战，对药物和有机半导体等领域有重要意义，因为晶体堆积直接影响有机固体的物理化学性质。

Method: 采用基于数据增强的策略替代显式等变架构，提出结晶启发的无晶格训练方案S^4，通过随机化学计量壳采样高效捕获长程相互作用，避免显式晶格参数化。

Result: 在60万实验验证晶体结构数据集上，OXtal相比先前的机器学习方法实现数量级改进，恢复实验结构的构象RMSD<0.5Å，堆积相似率达到80%以上。

Conclusion: OXtal能够有效建模分子结晶的热力学和动力学规律，在保持全原子分辨率的同时比传统量子化学方法便宜数个数量级。

Abstract: Accurately predicting experimentally-realizable 3D molecular crystal structures from their 2D chemical graphs is a long-standing open challenge in computational chemistry called crystal structure prediction (CSP). Efficiently solving this problem has implications ranging from pharmaceuticals to organic semiconductors, as crystal packing directly governs the physical and chemical properties of organic solids. In this paper, we introduce OXtal, a large-scale 100M parameter all-atom diffusion model that directly learns the conditional joint distribution over intramolecular conformations and periodic packing. To efficiently scale OXtal, we abandon explicit equivariant architectures imposing inductive bias arising from crystal symmetries in favor of data augmentation strategies. We further propose a novel crystallization-inspired lattice-free training scheme, Stoichiometric Stochastic Shell Sampling ($S^4$), that efficiently captures long-range interactions while sidestepping explicit lattice parametrization -- thus enabling more scalable architectural choices at all-atom resolution. By leveraging a large dataset of 600K experimentally validated crystal structures (including rigid and flexible molecules, co-crystals, and solvates), OXtal achieves orders-of-magnitude improvements over prior ab initio machine learning CSP methods, while remaining orders of magnitude cheaper than traditional quantum-chemical approaches. Specifically, OXtal recovers experimental structures with conformer $\text{RMSD}_1<0.5$ Å and attains over 80\% packing similarity rate, demonstrating its ability to model both thermodynamic and kinetic regularities of molecular crystallization.

</details>


### [374] [Flash Multi-Head Feed-Forward Network](https://arxiv.org/abs/2512.06989)
*Minshen Zhang,Xiang Hu,Jianguo Li,Wei Wu,Kewei Tu*

Main category: cs.LG

TL;DR: 本文提出Flash Multi-Head FFN (FlashMHF)作为Transformer中FFN的替代方案，通过创新的I/O感知融合内核和动态加权并行子网络设计，解决了多头FFN的内存消耗和扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 受多头注意力机制增强表达能力的启发，作者希望将多头设计应用于FFN，但直接应用面临内存消耗随头数增加而增长，以及中间尺寸与头维度比例失衡的问题。

Method: 提出FlashMHF：1）类似FlashAttention的I/O感知融合内核，在SRAM中在线计算输出；2）使用动态加权的并行子网络设计，保持中间尺寸与头维度的平衡比例。

Result: 在1.28亿到13亿参数的模型上验证，FlashMHF相比SwiGLU FFN持续改善困惑度和下游任务准确率，同时将峰值内存使用降低3-5倍，推理速度提升最高1.08倍。

Conclusion: 多头设计是FFN的优越架构原则，FlashMHF作为Transformer中FFN的强大、高效且可扩展的替代方案。

Abstract: We explore Multi-Head FFN (MH-FFN) as a replacement of FFN in the Transformer architecture, motivated by the structural similarity between single-head attention and FFN. While multi-head mechanisms enhance expressivity in attention, naively applying them to FFNs faces two challenges: memory consumption scaling with the head count, and an imbalanced ratio between the growing intermediate size and the fixed head dimension as models scale, which degrades scalability and expressive power. To address these challenges, we propose Flash Multi-Head FFN (FlashMHF), with two key innovations: an I/O-aware fused kernel computing outputs online in SRAM akin to FlashAttention, and a design using dynamically weighted parallel sub-networks to maintain a balanced ratio between intermediate and head dimensions. Validated on models from 128M to 1.3B parameters, FlashMHF consistently improves perplexity and downstream task accuracy over SwiGLU FFNs, while reducing peak memory usage by 3-5x and accelerating inference by up to 1.08x. Our work establishes the multi-head design as a superior architectural principle for FFNs, presenting FlashMHF as a powerful, efficient, and scalable alternative to FFNs in Transformers.

</details>


### [375] [Toward Reliable Machine Unlearning: Theory, Algorithms, and Evaluation](https://arxiv.org/abs/2512.06993)
*Ali Ebrahimpour-Boroojeny*

Main category: cs.LG

TL;DR: 提出了AMUN和TRW两种新的机器学习遗忘方法，分别在样本遗忘和类别遗忘任务中超越现有方法，通过对抗性训练和分布重加权实现更好的遗忘效果。


<details>
  <summary>Details</summary>
Motivation: 现有遗忘方法在重现从头训练模型行为方面存在不足，特别是在样本遗忘和类别遗忘任务中，无法有效降低模型对已遗忘样本的置信度。

Method: AMUN方法通过对遗忘样本的对抗样本进行微调来降低模型置信度；TRW方法通过估计类间相似性并相应调整目标分布来实现类别遗忘。还提出了FastClip方法控制模型平滑度。

Result: AMUN在图像分类任务中基于SOTA MIA得分超越先前方法；TRW在多个基准测试中匹配或超越现有遗忘方法。

Conclusion: 提出的遗忘方法通过关注模型预测相似性和分布近似，在样本和类别遗忘任务中取得了显著改进，为机器学习隐私保护提供了有效解决方案。

Abstract: We propose new methodologies for both unlearning random set of samples and class unlearning and show that they outperform existing methods. The main driver of our unlearning methods is the similarity of predictions to a retrained model on both the forget and remain samples. We introduce Adversarial Machine UNlearning (AMUN), which surpasses prior state-of-the-art methods for image classification based on SOTA MIA scores. AMUN lowers the model's confidence on forget samples by fine-tuning on their corresponding adversarial examples. Through theoretical analysis, we identify factors governing AMUN's performance, including smoothness. To facilitate training of smooth models with a controlled Lipschitz constant, we propose FastClip, a scalable method that performs layer-wise spectral-norm clipping of affine layers. In a separate study, we show that increased smoothness naturally improves adversarial example transfer, thereby supporting the second factor above.
  Following the same principles for class unlearning, we show that existing methods fail in replicating a retrained model's behavior by introducing a nearest-neighbor membership inference attack (MIA-NN) that uses the probabilities assigned to neighboring classes to detect unlearned samples and demonstrate the vulnerability of such methods. We then propose a fine-tuning objective that mitigates this leakage by approximating, for forget-class inputs, the distribution over remaining classes that a model retrained from scratch would produce. To construct this approximation, we estimate inter-class similarity and tilt the target model's distribution accordingly. The resulting Tilted ReWeighting(TRW) distribution serves as the desired target during fine-tuning. Across multiple benchmarks, TRW matches or surpasses existing unlearning methods on prior metrics.

</details>


### [376] [Always Keep Your Promises: DynamicLRP, A Model-Agnostic Solution To Layer-Wise Relevance Propagation](https://arxiv.org/abs/2512.07010)
*Kevin Lee,Pablo Millan Arias*

Main category: cs.LG

TL;DR: DynamicLRP是一个模型无关的层间相关性传播框架，通过将归因分解为计算图中的单个张量操作，并引入Promise System实现延迟激活解析，实现了真正的架构无关性。


<details>
  <summary>Details</summary>
Motivation: 现有LRP实现基于模块级别，需要架构特定的传播规则和修改，限制了目标模型的通用性和实现的可维护性。

Method: 在计算图的操作级别分解归因，引入Promise System进行延迟激活解析，独立于反向传播机制，无需模型修改即可在任意计算图上运行。

Result: 在多种架构上达到或超过专用实现的性能（VGG ABPC 1.77 vs 1.69，ViT等效性能，RoBERTa-large和Flan-T5-large在SQuADv2上的归因准确率分别为93.70%和95.06%），覆盖31,465个计算图节点的99.92%。

Conclusion: DynamicLRP的操作级别分解和Promise System为LRP在演进架构中建立了可持续、可扩展的基础。

Abstract: Layer-wise Relevance Propagation (LRP) provides principled attribution for neural networks through conservation properties and foundations in Deep Taylor Decomposition. However, existing implementations operate at the module level, requiring architecture-specific propagation rules and modifications. These limit the generality of target model and sustainability of implementations as architectures evolve. We introduce DynamicLRP, a model-agnostic LRP framework operating at the tensor operation level. By decomposing attribution to individual operations within computation graphs and introducing a novel mechanism for deferred activation resolution, named the Promise System, our approach achieves true architecture agnosticity while maintaining LRP's theoretical guarantees. This design operates independently of backpropagation machinery, enabling operation on arbitrary computation graphs without model modification and side-by-side execution with gradient backpropagation. Being based on computation graphs, this method is theoretically extensible to other deep learning libraries that support auto-differentiation. We demonstrate faithfulness matching or exceeding specialized implementations (1.77 vs 1.69 ABPC on VGG, equivalent performance on ViT, 93.70\% and 95.06\% top-1 attribution accuracy for explaining RoBERTa-large and Flan-T5-large answers on SQuADv2, respectively) while maintaining practical efficiency on models with hundreds of millions of parameters. We achieved 99.92\% node coverage across 31,465 computation graph nodes from 15 diverse architectures, including state-space models (Mamba), audio transformers (Whisper), and multimodal systems (DePlot) without any model-specific code with rules for 47 fundamental operations implemented. Our operation-level decomposition and Promise System establish a sustainable, extensible foundation for LRP across evolving architectures.

</details>


### [377] [Block Sparse Flash Attention](https://arxiv.org/abs/2512.07011)
*Daniel Ohayon,Itay Lamprecht,Itay Hubara,Israel Cohen,Daniel Soudry,Noam Elata*

Main category: cs.LG

TL;DR: Block-Sparse FlashAttention (BSFA) 是一种无需训练的注意力机制优化方法，通过计算精确的查询-键相似度来选择最重要的值块，在保持模型质量的同时将长上下文推理速度提升最高1.24倍。


<details>
  <summary>Details</summary>
Motivation: 现代大语言模型需要处理长上下文，但注意力机制的二次复杂度造成了严重的计算瓶颈，需要一种高效的优化方法。

Method: BSFA通过计算每个查询与键块的精确相似度，选择top-k最重要的值块，使用校准阈值跳过约50%的计算和内存传输。该方法只需在小数据集上进行一次性阈值校准。

Result: 在Llama-3.1-8B上，BSFA在真实世界推理基准测试中实现最高1.10倍加速，在检索任务中实现最高1.24倍加速，同时保持99%以上的基线准确率。

Conclusion: BSFA是一种有效的训练无关的注意力优化方法，显著优于现有稀疏注意力方法，可作为FlashAttention的直接替代方案。

Abstract: Modern large language models increasingly require long contexts for reasoning and multi-document tasks, but attention's quadratic complexity creates a severe computational bottleneck. We present Block-Sparse FlashAttention (BSFA), a drop-in replacement that accelerates long-context inference while preserving model quality. Unlike methods that predict importance before computing scores, BSFA computes exact query-key similarities to select the top-k most important value blocks for each query. By comparing per-block maximum scores against calibrated thresholds, we skip approximately 50% of the computation and memory transfers for pruned blocks. Our training-free approach requires only a one-time threshold calibration on a small dataset to learn the per-layer and per-head attention score distributions. We provide a CUDA kernel implementation that can be used as a drop-in replacement for FlashAttention. On Llama-3.1-8B, BSFA achieves up to 1.10x speedup on real-world reasoning benchmarks and up to 1.24x for needle-in-a-haystack retrieval tasks while maintaining above 99% baseline accuracy, with certain configurations even improving accuracy by focusing on the most relevant content, substantially outperforming existing sparse attention methods. The implementation is available at https://github.com/Danielohayon/Block-Sparse-Flash-Attention

</details>


### [378] [Transferring Clinical Knowledge into ECGs Representation](https://arxiv.org/abs/2512.07021)
*Jose Geraldo Fernandes,Luiz Facury de Souza,Pedro Robles Dutenhefner,Gisele L. Pappa,Wagner Meira*

Main category: cs.LG

TL;DR: 提出了一种三阶段训练范式，通过多模态临床数据增强ECG编码器性能，提高心电图分类的准确性和可解释性，同时仅需ECG信号进行推理。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在心电图分类中具有高准确率，但其黑箱特性阻碍了临床应用，缺乏可信度和可解释性。

Method: 采用自监督的联合嵌入预训练阶段，将多模态临床数据（实验室检查、生命体征、生物特征）的知识迁移到ECG编码器中，同时训练模型从ECG嵌入预测相关的实验室异常值作为间接解释。

Result: 在MIMIC-IV-ECG数据集上的评估表明，该模型在多标签诊断分类中优于仅使用信号的基线模型，并显著缩小了与需要所有数据的全多模态模型之间的性能差距。

Conclusion: 该工作展示了一种实用有效的方法，通过将抽象预测转化为基于生理学的解释，为AI更安全地融入临床工作流程提供了有前景的路径。

Abstract: Deep learning models have shown high accuracy in classifying electrocardiograms (ECGs), but their black box nature hinders clinical adoption due to a lack of trust and interpretability. To address this, we propose a novel three-stage training paradigm that transfers knowledge from multimodal clinical data (laboratory exams, vitals, biometrics) into a powerful, yet unimodal, ECG encoder. We employ a self-supervised, joint-embedding pre-training stage to create an ECG representation that is enriched with contextual clinical information, while only requiring the ECG signal at inference time. Furthermore, as an indirect way to explain the model's output we train it to also predict associated laboratory abnormalities directly from the ECG embedding. Evaluated on the MIMIC-IV-ECG dataset, our model outperforms a standard signal-only baseline in multi-label diagnosis classification and successfully bridges a substantial portion of the performance gap to a fully multimodal model that requires all data at inference. Our work demonstrates a practical and effective method for creating more accurate and trustworthy ECG classification models. By converting abstract predictions into physiologically grounded \emph{explanations}, our approach offers a promising path toward the safer integration of AI into clinical workflows.

</details>


### [379] [Transformation of Biological Networks into Images via Semantic Cartography for Visual Interpretation and Scalable Deep Analysis](https://arxiv.org/abs/2512.07040)
*Sakib Mostafa,Lei Xing,Md. Tauhidul Islam*

Main category: cs.LG

TL;DR: Graph2Image将大型生物网络转换为二维图像，使用CNN进行分析，解决了传统方法在可扩展性、长程依赖和可解释性方面的限制。


<details>
  <summary>Details</summary>
Motivation: 传统生物网络分析方法面临可扩展性差、长程依赖捕捉困难、多模态整合难、表达性有限和可解释性差等问题，需要新的解决方案。

Method: 通过将网络节点空间排列在2D网格上，将生物网络转换为图像集，然后使用具有全局感受野和多尺度金字塔的CNN进行分析。

Result: 在多个大规模生物网络数据集上，分类准确率比现有方法提高达67.2%，能够分析超过10亿节点的网络，并在个人计算机上运行。

Conclusion: Graph2Image提供了一个可扩展、可解释且支持多模态的生物网络分析方法，为疾病诊断和复杂生物系统研究开辟了新途径。

Abstract: Complex biological networks are fundamental to biomedical science, capturing interactions among molecules, cells, genes, and tissues. Deciphering these networks is critical for understanding health and disease, yet their scale and complexity represent a daunting challenge for current computational methods. Traditional biological network analysis methods, including deep learning approaches, while powerful, face inherent challenges such as limited scalability, oversmoothing long-range dependencies, difficulty in multimodal integration, expressivity bounds, and poor interpretability. We present Graph2Image, a framework that transforms large biological networks into sets of two-dimensional images by spatially arranging representative network nodes on a 2D grid. This transformation decouples the nodes as images, enabling the use of convolutional neural networks (CNNs) with global receptive fields and multi-scale pyramids, thus overcoming limitations of existing biological network analysis methods in scalability, memory efficiency, and long-range context capture. Graph2Image also facilitates seamless integration with other imaging and omics modalities and enhances interpretability through direct visualization of node-associated images. When applied to several large-scale biological network datasets, Graph2Image improved classification accuracy by up to 67.2% over existing methods and provided interpretable visualizations that revealed biologically coherent patterns. It also allows analysis of very large biological networks (nodes > 1 billion) on a personal computer. Graph2Image thus provides a scalable, interpretable, and multimodal-ready approach for biological network analysis, offering new opportunities for disease diagnosis and the study of complex biological systems.

</details>


### [380] [Self-Supervised Learning on Molecular Graphs: A Systematic Investigation of Masking Design](https://arxiv.org/abs/2512.07064)
*Jiannan Yang,Veronika Thost,Tengfei Ma*

Main category: cs.LG

TL;DR: 本文提出了一个统一的概率框架来分析分子图自监督学习中的掩码策略，通过控制实验发现：对于常见的节点级预测任务，复杂的掩码分布相比均匀采样并无明显优势；预测目标的选择及其与编码器架构的协同作用更为关键。


<details>
  <summary>Details</summary>
Motivation: 当前基于掩码的分子表示学习方法多为启发式设计，缺乏系统性评估，难以确定哪些设计选择真正有效。

Method: 构建统一的概率框架分析预训练-微调流程，通过控制实验研究三个核心设计维度：掩码分布、预测目标和编码器架构，并使用信息论指标评估预训练信号的信息量。

Result: 研究发现：1）复杂掩码分布在节点级预测任务中无优势；2）预测目标的选择和与编码器架构的协同作用更为关键；3）使用语义更丰富的预测目标结合图Transformer编码器可显著提升下游性能。

Conclusion: 为分子图自监督学习方法的发展提供了实用指导，强调应关注预测目标和编码器架构的协同设计，而非过度优化掩码策略。

Abstract: Self-supervised learning (SSL) plays a central role in molecular representation learning. Yet, many recent innovations in masking-based pretraining are introduced as heuristics and lack principled evaluation, obscuring which design choices are genuinely effective. This work cast the entire pretrain-finetune workflow into a unified probabilistic framework, enabling a transparent comparison and deeper understanding of masking strategies. Building on this formalism, we conduct a controlled study of three core design dimensions: masking distribution, prediction target, and encoder architecture, under rigorously controlled settings. We further employ information-theoretic measures to assess the informativeness of pretraining signals and connect them to empirically benchmarked downstream performance. Our findings reveal a surprising insight: sophisticated masking distributions offer no consistent benefit over uniform sampling for common node-level prediction tasks. Instead, the choice of prediction target and its synergy with the encoder architecture are far more critical. Specifically, shifting to semantically richer targets yields substantial downstream improvements, particularly when paired with expressive Graph Transformer encoders. These insights offer practical guidance for developing more effective SSL methods for molecular graphs.

</details>


### [381] [Procrustean Bed for AI-Driven Retrosynthesis: A Unified Framework for Reproducible Evaluation](https://arxiv.org/abs/2512.07079)
*Anton Morgunov,Victor S. Batista*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Progress in computer-aided synthesis planning (CASP) is obscured by the lack of standardized evaluation infrastructure and the reliance on metrics that prioritize topological completion over chemical validity. We introduce RetroCast, a unified evaluation suite that standardizes heterogeneous model outputs into a common schema to enable statistically rigorous, apples-to-apples comparison. The framework includes a reproducible benchmarking pipeline with stratified sampling and bootstrapped confidence intervals, accompanied by SynthArena, an interactive platform for qualitative route inspection. We utilize this infrastructure to evaluate leading search-based and sequence-based algorithms on a new suite of standardized benchmarks. Our analysis reveals a divergence between "solvability" (stock-termination rate) and route quality; high solvability scores often mask chemical invalidity or fail to correlate with the reproduction of experimental ground truths. Furthermore, we identify a "complexity cliff" in which search-based methods, despite high solvability rates, exhibit a sharp performance decay in reconstructing long-range synthetic plans compared to sequence-based approaches. We release the full framework, benchmark definitions, and a standardized database of model predictions to support transparent and reproducible development in the field.

</details>


### [382] [TRACE: A Generalizable Drift Detector for Streaming Data-Driven Optimization](https://arxiv.org/abs/2512.07082)
*Yuan-Ting Zhong,Ting Huang,Xiaolin Xiao,Yue-Jiao Gong*

Main category: cs.LG

TL;DR: TRACE是一种可迁移的概念漂移估计器，通过基于注意力的序列学习检测流数据中的分布变化，具有跨数据集泛化能力，可集成到流优化器中实现自适应优化。


<details>
  <summary>Details</summary>
Motivation: 现有流数据驱动优化方法在固定漂移间隔和完全环境可观测性等限制性假设下工作，难以适应多样化的动态环境，需要更灵活的概念漂移检测方法。

Method: 提出TRACE方法，采用原则性标记化策略从数据流中提取统计特征，使用基于注意力的序列学习建模漂移模式，实现跨数据集的概念漂移检测。

Result: 在多样化基准测试上的综合实验表明，该方法在流数据驱动优化场景中具有优异的泛化性、鲁棒性和有效性。

Conclusion: TRACE展示了学习到的漂移模式的可迁移性，其即插即用特性使其能够集成到流优化器中，促进未知漂移下的自适应优化。

Abstract: Many optimization tasks involve streaming data with unknown concept drifts, posing a significant challenge as Streaming Data-Driven Optimization (SDDO). Existing methods, while leveraging surrogate model approximation and historical knowledge transfer, are often under restrictive assumptions such as fixed drift intervals and fully environmental observability, limiting their adaptability to diverse dynamic environments. We propose TRACE, a TRAnsferable C}oncept-drift Estimator that effectively detects distributional changes in streaming data with varying time scales. TRACE leverages a principled tokenization strategy to extract statistical features from data streams and models drift patterns using attention-based sequence learning, enabling accurate detection on unseen datasets and highlighting the transferability of learned drift patterns. Further, we showcase TRACE's plug-and-play nature by integrating it into a streaming optimizer, facilitating adaptive optimization under unknown drifts. Comprehensive experimental results on diverse benchmarks demonstrate the superior generalization, robustness, and effectiveness of our approach in SDDO scenarios.

</details>


### [383] [The Geometry of Persona: Disentangling Personality from Reasoning in Large Language Models](https://arxiv.org/abs/2512.07092)
*Zhixiang Wang*

Main category: cs.LG

TL;DR: 本文提出Soul Engine框架，基于线性表示假设，通过提取解耦的人格向量实现个性化LLM，避免了微调带来的对齐税问题。


<details>
  <summary>Details</summary>
Motivation: 解决当前个性化大语言模型部署中的稳定性-可塑性困境，避免传统对齐方法（如监督微调）导致通用推理能力下降的'对齐税'问题。

Method: 基于线性表示假设，使用双头架构在冻结的Qwen-2.5基础上，通过SoulBench数据集和动态上下文采样提取解耦的人格向量，不修改主干权重。

Result: 实现高精度人格分析（MSE=0.011）、几何正交性验证（人格流形连续且独立）、零样本人格注入和确定性行为控制，保持原始模型智能。

Conclusion: 挑战了微调在个性化中的必要性，从概率提示转向确定性潜在干预，为安全可控的AI个性化提供了数学严谨的基础。

Abstract: Background: The deployment of personalized Large Language Models (LLMs) is currently constrained by the stability-plasticity dilemma. Prevailing alignment methods, such as Supervised Fine-Tuning (SFT), rely on stochastic weight updates that often incur an "alignment tax" -- degrading general reasoning capabilities.
  Methods: We propose the Soul Engine, a framework based on the Linear Representation Hypothesis, which posits that personality traits exist as orthogonal linear subspaces. We introduce SoulBench, a dataset constructed via dynamic contextual sampling. Using a dual-head architecture on a frozen Qwen-2.5 base, we extract disentangled personality vectors without modifying the backbone weights.
  Results: Our experiments demonstrate three breakthroughs. First, High-Precision Profiling: The model achieves a Mean Squared Error (MSE) of 0.011 against psychological ground truth. Second, Geometric Orthogonality: T-SNE visualization confirms that personality manifolds are distinct and continuous, allowing for "Zero-Shot Personality Injection" that maintains original model intelligence. Third, Deterministic Steering: We achieve robust control over behavior via vector arithmetic, validated through extensive ablation studies.
  Conclusion: This work challenges the necessity of fine-tuning for personalization. By transitioning from probabilistic prompting to deterministic latent intervention, we provide a mathematically rigorous foundation for safe, controllable AI personalization.

</details>


### [384] [Dual Refinement Cycle Learning: Unsupervised Text Classification of Mamba and Community Detection on Text Attributed Graph](https://arxiv.org/abs/2512.07100)
*Hong Wang,Yinglong Zhang,Hanhan Guo,Xuewen Xia,Xing Xu*

Main category: cs.LG

TL;DR: DRCL是一个完全无监督的框架，通过图结构和文本语义的双向精炼循环，在无标签的文本属性网络上实现社区检测和文本表示学习。


<details>
  <summary>Details</summary>
Motivation: 预训练语言模型依赖标注数据难以部署，传统社区检测方法忽略文本语义，限制了在实际应用中的效果。

Method: 通过GCN社区检测模块和文本语义建模模块的双向精炼循环，迭代交换伪标签，实现结构和语义信息的相互增强。

Result: 在多个文本属性图数据集上，DRCL显著提升了发现社区的结构和语义质量，基于其社区信号训练的Mamba分类器达到接近有监督模型的准确率。

Conclusion: DRCL展示了在缺乏标注数据的大规模系统中部署的潜力，为实际应用场景提供了有效的无监督解决方案。

Abstract: Pretrained language models offer strong text understanding capabilities but remain difficult to deploy in real-world text-attributed networks due to their heavy dependence on labeled data. Meanwhile, community detection methods typically ignore textual semantics, limiting their usefulness in downstream applications such as content organization, recommendation, and risk monitoring. To overcome these limitations, we present Dual Refinement Cycle Learning (DRCL), a fully unsupervised framework designed for practical scenarios where no labels or category definitions are available.
  DRCL integrates structural and semantic information through a warm-start initialization and a bidirectional refinement cycle between a GCN-based Community Detection Module (GCN-CDM) and a Text Semantic Modeling Module (TSMM). The two modules iteratively exchange pseudo-labels, allowing semantic cues to enhance structural clustering and structural patterns to guide text representation learning without manual supervision.
  Across several text-attributed graph datasets, DRCL consistently improves the structural and semantic quality of discovered communities. Moreover, a Mamba-based classifier trained solely from DRCL's community signals achieves accuracy comparable to supervised models, demonstrating its potential for deployment in large-scale systems where labeled data are scarce or costly.

</details>


### [385] [FOAM: Blocked State Folding for Memory-Efficient LLM Training](https://arxiv.org/abs/2512.07112)
*Ziqing Wen,Jiahuan Wang,Ping Luo,Dongsheng Li,Tao Sun*

Main category: cs.LG

TL;DR: FOAM是一种新的内存高效优化器，通过块梯度均值压缩和残差校正来减少Adam优化器的内存占用，同时保持收敛性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型训练时内存瓶颈严重，现有内存优化方法存在计算开销大、额外内存需求或性能下降的问题。

Method: 提出FOAM方法，通过计算块梯度均值压缩优化器状态，并结合残差校正来恢复丢失的信息。

Result: FOAM减少总训练内存约50%，消除高达90%的优化器状态内存开销，加速收敛，性能匹配或超越现有基准。

Conclusion: FOAM在理论收敛率和实际性能上都表现出色，兼容其他内存高效优化器，是解决LLM训练内存瓶颈的有效方案。

Abstract: Large language models (LLMs) have demonstrated remarkable performance due to their large parameter counts and extensive training data. However, their scale leads to significant memory bottlenecks during training, especially when using memory-intensive optimizers like Adam. Existing memory-efficient approaches often rely on techniques such as singular value decomposition (SVD), projections, or weight freezing, which can introduce substantial computational overhead, require additional memory for projections, or degrade model performance. In this paper, we propose Folded Optimizer with Approximate Moment (FOAM), a method that compresses optimizer states by computing block-wise gradient means and incorporates a residual correction to recover lost information. Theoretically, FOAM achieves convergence rates equivalent to vanilla Adam under standard non-convex optimization settings. Empirically, FOAM reduces total training memory by approximately 50\%, eliminates up to 90\% of optimizer state memory overhead, and accelerates convergence. Furthermore, FOAM is compatible with other memory-efficient optimizers, delivering performance and throughput that match or surpass both full-rank and existing memory-efficient baselines.

</details>


### [386] [PlantBiMoE: A Bidirectional Foundation Model with SparseMoE for Plant Genomes](https://arxiv.org/abs/2512.07113)
*Kepeng Lin,Qizhe Zhang,Rui Wang,Xuehai Hu,Wei Xu*

Main category: cs.LG

TL;DR: PlantBiMoE是一个轻量级且表达能力强的植物基因组语言模型，通过双向Mamba和稀疏专家混合框架解决现有模型参数过多和双向建模能力不足的问题，在31个数据集中的20个上取得最佳性能。


<details>
  <summary>Details</summary>
Motivation: 现有植物基因组模型如AgroNT和PDLLMs存在参数规模过大和无法有效建模DNA双链双向性的问题，需要开发更高效且表达能力强的模型。

Method: 提出PlantBiMoE模型，集成双向Mamba来捕捉DNA正反链的结构依赖关系，使用稀疏专家混合框架减少激活参数数量，提高计算效率。

Result: 在增强的基因组基准测试MPGB（包含31个数据集、11个任务）上，PlantBiMoE在20个数据集上取得最佳性能，平均表现最优。

Conclusion: PlantBiMoE能有效表示植物基因组序列，为基因组任务提供强大计算工具，对植物基因组学、基因编辑和合成生物学有重要贡献。

Abstract: Understanding the underlying linguistic rules of plant genomes remains a fundamental challenge in computational biology. Recent advances including AgroNT and PDLLMs have made notable progress although, they suffer from excessive parameter size and limited ability to model the bidirectional nature of DNA strands respectively. To address these limitations, we propose PlantBiMoE, a lightweight and expressive plant genome language model that integrates bidirectional Mamba and a Sparse Mixture-of-Experts (SparseMoE) framework. The bidirectional Mamba enables the model to effectively capture structural dependencies across both the forward and reverse DNA strands, while SparseMoE significantly reduces the number of active parameters, improving computational efficiency without sacrificing modeling capacity. We evaluated and tested our model on the Modified Plants Genome Benchmark (MPGB), an enhanced genomic benchmark, which consolidates 31 datasets across 11 representative tasks, with input sequence lengths ranging from 50 to 6,000 bp. Experimental results demonstrate that PlantBiMoE achieves the best performance on 20 out of 31 datasets and the average best when comparing with existing models. In summary, all above results demonstrate that our model can effectively represent plant genomic sequences, serving as a robust computational tool for diverse genomic tasks, while making substantive contributions to plant genomics, gene editing, and synthetic biology. The code is available at: https://github.com/HUST-Keep-Lin/PlantBiMoE

</details>


### [387] [Winning the Lottery by Preserving Network Training Dynamics with Concrete Ticket Search](https://arxiv.org/abs/2512.07142)
*Tanay Arora,Christof Teuscher*

Main category: cs.LG

TL;DR: 本文提出Concrete Ticket Search (CTS)算法，通过将子网络发现建模为组合优化问题，使用Concrete松弛和梯度平衡方案，高效识别高性能稀疏子网络，在保持高稀疏度的同时达到或超过Lottery Ticket Rewinding的精度，且计算成本大幅降低。


<details>
  <summary>Details</summary>
Motivation: 现有的彩票票假设方法中，LTR计算成本过高，而基于显著性的初始化剪枝方法存在精度-稀疏度权衡问题且无法通过基本验证测试。作者认为PaI方法依赖一阶显著性指标忽略了权重间依赖关系是性能差距的主要原因。

Method: 提出CTS算法，将子网络发现建模为组合优化问题，使用Concrete松弛处理离散搜索空间，引入GRADBALANCE梯度平衡方案控制稀疏度，并提出基于知识蒸馏的剪枝目标（特别是最小化稀疏与稠密网络输出的反向KL散度CTS-KL）。

Result: 在多个图像分类任务上，CTS生成的子网络能稳定通过验证测试，精度达到或超过LTR，计算成本仅为LTR的一小部分。例如在ResNet-20/CIFAR10上，99.3%稀疏度下达到74.0%精度（LTR为68.3%），计算时间从95.2分钟降至7.9分钟。

Conclusion: CTS方法在高度稀疏区域优势明显，能够高效识别高性能子网络，解决了现有方法的计算成本高和精度-稀疏度权衡问题，为彩票票假设提供了更实用的实现方案。

Abstract: The Lottery Ticket Hypothesis asserts the existence of highly sparse, trainable subnetworks ('winning tickets') within dense, randomly initialized neural networks. However, state-of-the-art methods of drawing these tickets, like Lottery Ticket Rewinding (LTR), are computationally prohibitive, while more efficient saliency-based Pruning-at-Initialization (PaI) techniques suffer from a significant accuracy-sparsity trade-off and fail basic sanity checks. In this work, we argue that PaI's reliance on first-order saliency metrics, which ignore inter-weight dependencies, contributes substantially to this performance gap, especially in the sparse regime. To address this, we introduce Concrete Ticket Search (CTS), an algorithm that frames subnetwork discovery as a holistic combinatorial optimization problem. By leveraging a Concrete relaxation of the discrete search space and a novel gradient balancing scheme (GRADBALANCE) to control sparsity, CTS efficiently identifies high-performing subnetworks near initialization without requiring sensitive hyperparameter tuning. Motivated by recent works on lottery ticket training dynamics, we further propose a knowledge distillation-inspired family of pruning objectives, finding that minimizing the reverse Kullback-Leibler divergence between sparse and dense network outputs (CTS-KL) is particularly effective. Experiments on varying image classification tasks show that CTS produces subnetworks that robustly pass sanity checks and achieve accuracy comparable to or exceeding LTR, while requiring only a small fraction of the computation. For example, on ResNet-20 on CIFAR10, it reaches 99.3% sparsity with 74.0% accuracy in 7.9 minutes, while LTR attains the same sparsity with 68.3% accuracy in 95.2 minutes. CTS's subnetworks outperform saliency-based methods across all sparsities, but its advantage over LTR is most pronounced in the highly sparse regime.

</details>


### [388] [FlowLPS: Langevin-Proximal Sampling for Flow-based Inverse Problem Solvers](https://arxiv.org/abs/2512.07150)
*Jonghyun Park,Jong Chul Ye*

Main category: cs.LG

TL;DR: 提出了FlowLPS框架，通过Langevin Proximal Sampling策略解决预训练流模型在逆问题中的收敛和流形偏差问题


<details>
  <summary>Details</summary>
Motivation: 现有训练自由方法在应用于潜在流模型时，常无法收敛到后验模式或遭受潜在空间内的流形偏差

Method: 结合Langevin动力学进行流形一致性探索和近端优化进行精确模式搜索的Langevin Proximal Sampling策略

Result: 在FFHQ和DIV2K的多个逆任务中实现了重建保真度和感知质量的优越平衡，超越了现有最先进的逆求解器

Conclusion: FlowLPS框架有效解决了潜在流模型在逆问题求解中的收敛和流形偏差问题

Abstract: Deep generative models have become powerful priors for solving inverse problems, and various training-free methods have been developed. However, when applied to latent flow models, existing methods often fail to converge to the posterior mode or suffer from manifold deviation within latent spaces. To mitigate this, here we introduce a novel training-free framework, FlowLPS, that solves inverse problems with pretrained flow models via a Langevin Proximal Sampling (LPS) strategy. Our method integrates Langevin dynamics for manifold-consistent exploration with proximal optimization for precise mode seeking, achieving a superior balance between reconstruction fidelity and perceptual quality across multiple inverse tasks on FFHQ and DIV2K, outperforming state of the art inverse solvers.

</details>


### [389] [Improving the Throughput of Diffusion-based Large Language Models via a Training-Free Confidence-Aware Calibration](https://arxiv.org/abs/2512.07173)
*Jucheng Shen,Gaurav Sarkar,Yeonju Ro,Sharath Nittur Sridhar,Zhangyang Wang,Aditya Akella,Souvik Kundu*

Main category: cs.LG

TL;DR: CadLLM是一种无需训练的方法，通过动态调整生成块大小、步长和阈值来加速基于扩散的LLMs推理吞吐量，同时通过动态词汇子集减少softmax开销，实现最高2.28倍的加速效果。


<details>
  <summary>Details</summary>
Motivation: 研究基于扩散的LLMs在推理过程中存在效率瓶颈，特别是token unmasking置信度的动态变化特性未被充分利用，需要开发轻量级自适应方法来优化推理性能。

Method: 1. 分析token unmasking置信度在块和步骤间的动态特性；2. 提出基于平均置信度的轻量级自适应方法，控制生成块大小、步长和阈值；3. 通过动态词汇子集减少softmax计算开销；4. 设计为即插即用的模型无关方法，兼容基于KV缓存的dLLMs。

Result: 在四个流行任务上的实验表明，CadLLM相比最先进基线实现了最高2.28倍的吞吐量提升，同时保持了有竞争力的准确率。

Conclusion: CadLLM证明了通过动态置信度分析和自适应参数调整可以有效加速dLLMs推理，为基于扩散的语言模型提供了高效推理的实用解决方案。

Abstract: We present CadLLM, a training-free method to accelerate the inference throughput of diffusion-based LLMs (dLLMs). We first investigate the dynamic nature of token unmasking confidence across blocks and steps. Based on this observation, we present a lightweight adaptive approach that controls the generation block size, step size, and threshold based on the average confidence of unmasked tokens. We further reduce softmax overhead by dynamically leveraging a subset of the vocabulary to regulate sampling breadth. CadLLM is a plug-and-play, model-agnostic method compatible with KV-cache-based dLLMs. Extensive experiments on four popular tasks demonstrate that CadLLM yields up to 2.28x throughput improvement over the state-of-the-art baseline with competitive accuracy.

</details>


### [390] [SPACE: Noise Contrastive Estimation Stabilizes Self-Play Fine-Tuning for Large Language Models](https://arxiv.org/abs/2512.07175)
*Yibo Wang,Qing-Guo Chen,Zhao Xu,Weihua Luo,Kaifu Zhang,Lijun Zhang*

Main category: cs.LG

TL;DR: SPACE是一种新颖的自对弈微调方法，通过噪声对比估计来捕捉真实数据分布，解决了传统基于奖励差距的方法存在的不稳定演化问题。


<details>
  <summary>Details</summary>
Motivation: 现有自对弈微调方法主要关注真实样本和合成样本之间的奖励差距，忽略了它们的绝对值，导致目标函数可能退化，引发不稳定演化。

Method: SPACE将合成样本视为辅助成分，以二元分类方式区分它们与真实样本，独立优化每类数据的绝对奖励值，确保目标函数始终有意义。

Result: 理论分析表明SPACE的最优解与真实数据分布一致，且保证稳定收敛。实证显示SPACE在多个任务上显著提升LLM性能，优于使用更多真实样本的监督微调。

Conclusion: SPACE通过噪声对比估计解决了自对弈微调的不稳定性问题，在理论和实证上都表现出优越性能和稳定演化。

Abstract: Self-play fine-tuning has demonstrated promising abilities in adapting large language models (LLMs) to downstream tasks with limited real-world data. The basic principle is to iteratively refine the model with real samples and synthetic ones generated from itself. However, the existing methods primarily focus on the relative gaps between the rewards for two types of data, neglecting their absolute values. Through theoretical analysis, we identify that the gap-based methods suffer from unstable evolution, due to the potentially degenerated objectives. To address this limitation, we introduce a novel self-play fine-tuning method, namely Self-PlAy via Noise Contrastive Estimation (SPACE), which leverages noise contrastive estimation to capture the real-world data distribution. Specifically, SPACE treats synthetic samples as auxiliary components, and discriminates them from the real ones in a binary classification manner. As a result, SPACE independently optimizes the absolute reward values for each type of data, ensuring a consistently meaningful objective and thereby avoiding the instability issue. Theoretically, we show that the optimal solution of the objective in SPACE aligns with the underlying distribution of real-world data, and SPACE guarantees a provably stable convergence to the optimal distribution. Empirically, we show that SPACE significantly improves the performance of LLMs over various tasks, and outperforms supervised fine-tuning that employs much more real-world samples. Compared to gap-based self-play fine-tuning methods, SPACE exhibits remarkable superiority and stable evolution.

</details>


### [391] [UniDiff: A Unified Diffusion Framework for Multimodal Time Series Forecasting](https://arxiv.org/abs/2512.07184)
*Da Zhang,Bingyu Li,Zhuyuan Zhao,Junyu Gao,Feiping Nie,Xuelong Li*

Main category: cs.LG

TL;DR: UniDiff是一个统一扩散框架，用于多模态时间序列预测，通过跨模态融合和新型分类器无关引导机制，在多个领域实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现实应用中多模态数据激增，但现有扩散模型在时间序列预测中主要局限于单模态数值序列，忽略了复杂异构数据中的跨模态信号。

Method: 1) 将时间序列分块并映射到嵌入空间；2) 使用统一的并行融合模块，通过单一跨注意力机制整合时间戳的结构信息和文本的语义信息；3) 引入多源条件的新型分类器无关引导机制。

Result: 在八个领域的真实世界基准数据集上的广泛实验表明，UniDiff模型达到了最先进的性能。

Conclusion: UniDiff框架有效解决了多模态时间序列预测的挑战，通过统一的跨模态融合和灵活的引导机制显著提升了模型性能。

Abstract: As multimodal data proliferates across diverse real-world applications, leveraging heterogeneous information such as texts and timestamps for accurate time series forecasting (TSF) has become a critical challenge. While diffusion models demonstrate exceptional performance in generation tasks, their application to TSF remains largely confined to modeling single-modality numerical sequences, overlooking the abundant cross-modal signals inherent in complex heterogeneous data. To address this gap, we propose UniDiff, a unified diffusion framework for multimodal time series forecasting. To process the numerical sequence, our framework first tokenizes the time series into patches, preserving local temporal dynamics by mapping each patch to an embedding space via a lightweight MLP. At its core lies a unified and parallel fusion module, where a single cross-attention mechanism adaptively weighs and integrates structural information from timestamps and semantic context from texts in one step, enabling a flexible and efficient interplay between modalities. Furthermore, we introduce a novel classifier-free guidance mechanism designed for multi-source conditioning, allowing for decoupled control over the guidance strength of textual and temporal information during inference, which significantly enhances model robustness. Extensive experiments on real-world benchmark datasets across eight domains demonstrate that the proposed UniDiff model achieves state-of-the-art performance.

</details>


### [392] [Less is More: Non-uniform Road Segments are Efficient for Bus Arrival Prediction](https://arxiv.org/abs/2512.07200)
*Zhen Huang,Jiaxin Deng,Jiayu Xu,Junbiao Pang,Haitao Yu*

Main category: cs.LG

TL;DR: 提出基于强化学习的非均匀道路分割方法，用于公交到站时间预测，通过两阶段解耦策略实现高效预测


<details>
  <summary>Details</summary>
Motivation: 传统均匀分割方法无法考虑道路物理约束（路况、交叉口、兴趣点等）的差异，限制了预测效率

Method: 1) 使用强化学习框架根据影响分数提取非均匀道路段；2) 在线性预测模型中对选定段进行预测

Result: 实验证明该方法在大规模基准测试中不仅提高了效率，还提升了学习性能，线性方法甚至优于复杂方法

Conclusion: 该方法通过最优段选择保持计算效率，相比传统均匀方法有显著改进

Abstract: In bus arrival time prediction, the process of organizing road infrastructure network data into homogeneous entities is known as segmentation. Segmenting a road network is widely recognized as the first and most critical step in developing an arrival time prediction system, particularly for auto-regressive-based approaches. Traditional methods typically employ a uniform segmentation strategy, which fails to account for varying physical constraints along roads, such as road conditions, intersections, and points of interest, thereby limiting prediction efficiency. In this paper, we propose a Reinforcement Learning (RL)-based approach to efficiently and adaptively learn non-uniform road segments for arrival time prediction. Our method decouples the prediction process into two stages: 1) Non-uniform road segments are extracted based on their impact scores using the proposed RL framework; and 2) A linear prediction model is applied to the selected segments to make predictions. This method ensures optimal segment selection while maintaining computational efficiency, offering a significant improvement over traditional uniform approaches. Furthermore, our experimental results suggest that the linear approach can even achieve better performance than more complex methods. Extensive experiments demonstrate the superiority of the proposed method, which not only enhances efficiency but also improves learning performance on large-scale benchmarks. The dataset and the code are publicly accessible at: https://github.com/pangjunbiao/Less-is-More.

</details>


### [393] [Geometric Prior-Guided Federated Prompt Calibration](https://arxiv.org/abs/2512.07208)
*Fei Luo,Ziwei Zhao,Mingxuan Wang,Duoyang Li,Zhe Qian,Jiayi Tuo,Chenyue Zhou,Yanbiao Ma*

Main category: cs.LG

TL;DR: GGTPC是一个新颖的联邦提示学习框架，通过几何引导的文本提示校准来直接纠正数据异构性导致的本地训练偏差，在多个数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦提示学习方法主要关注聚合或正则化，但未能解决数据异构性导致的本地训练偏差这一根本问题。

Method: 提出Geometry-Guided Text Prompt Calibration (GGTPC)框架：1）服务器端从协方差矩阵重构全局几何先验；2）客户端使用Geometry-Prior Calibration Layer (GPCL)将本地特征分布与全局先验对齐。

Result: 在标签偏斜的CIFAR-100数据集上（β=0.1），比最先进方法提升2.15%；在极端偏斜（β=0.01）下比基线提升9.17%；在域偏斜的Office-Home数据集上作为即插即用模块，将FedAvg性能提升4.60%。

Conclusion: GGTPC通过纠正根本的本地训练偏差，有效缓解了数据异构性问题，可作为增强各种联邦学习算法的通用模块。

Abstract: Federated Prompt Learning (FPL) offers a parameter-efficient solution for collaboratively training large models, but its performance is severely hindered by data heterogeneity, which causes locally trained prompts to become biased. Existing methods, focusing on aggregation or regularization, fail to address this root cause of local training bias. To this end, we propose Geometry-Guided Text Prompt Calibration (GGTPC), a novel framework that directly corrects this bias by providing clients with a global geometric prior. This prior, representing the shape of the global data distribution derived from the covariance matrix, is reconstructed on the server in a privacy-preserving manner. Clients then use a novel Geometry-Prior Calibration Layer (GPCL) to align their local feature distributions with this global prior during training. Extensive experiments show GGTPC's effectiveness. On the label-skewed CIFAR-100 dataset ($β$=0.1), it outperforms the state-of-the-art by 2.15\%. Under extreme skew ($β$=0.01), it improves upon the baseline by 9.17\%. Furthermore, as a plug-and-play module on the domain-skewed Office-Home dataset, it boosts FedAvg's performance by 4.60\%. These results demonstrate that GGTPC effectively mitigates data heterogeneity by correcting the fundamental local training bias, serving as a versatile module to enhance various FL algorithms.

</details>


### [394] [Pay Less Attention to Function Words for Free Robustness of Vision-Language Models](https://arxiv.org/abs/2512.07222)
*Qiwei Tian,Chenhao Lin,Zhengyu Zhao,Chao Shen*

Main category: cs.LG

TL;DR: 该论文提出Function-word De-Attention (FDA)方法来解决VLM在跨模态对抗攻击中的鲁棒性与性能权衡问题，通过减少功能词的影响来提升模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了解决VLM在跨模态对抗攻击中鲁棒性和性能之间的权衡问题，作者观察到功能词是导致VLM易受攻击的关键因素。

Method: 提出Function-word De-Attention (FDA)方法，类似于差分放大器，在注意力头中计算原始跨注意力和功能词跨注意力，并将后者从前者中差分减除，从而获得更对齐和鲁棒的VLM。

Result: 在3个模型上的检索任务中，FDA平均降低了18/13/53%的攻击成功率(ASR)，性能仅下降0.2/0.3/0.6%；在视觉定位任务中，ASR降低90%的同时性能还提升了0.3%。

Conclusion: FDA方法具有可扩展性、泛化性和零样本性能，实验证明了其有效性，代码将公开在GitHub上。

Abstract: To address the trade-off between robustness and performance for robust VLM, we observe that function words could incur vulnerability of VLMs against cross-modal adversarial attacks, and propose Function-word De-Attention (FDA) accordingly to mitigate the impact of function words. Similar to differential amplifiers, our FDA calculates the original and the function-word cross-attention within attention heads, and differentially subtracts the latter from the former for more aligned and robust VLMs. Comprehensive experiments include 2 SOTA baselines under 6 different attacks on 2 downstream tasks, 3 datasets, and 3 models. Overall, our FDA yields an average 18/13/53% ASR drop with only 0.2/0.3/0.6% performance drops on the 3 tested models on retrieval, and a 90% ASR drop with a 0.3% performance gain on visual grounding. We demonstrate the scalability, generalization, and zero-shot performance of FDA experimentally, as well as in-depth ablation studies and analysis. Code will be made publicly at https://github.com/michaeltian108/FDA.

</details>


### [395] [PINE: Pipeline for Important Node Exploration in Attributed Networks](https://arxiv.org/abs/2512.07244)
*Elizaveta Kovtun,Maksim Makarenko,Natalia Semenova,Alexey Zaytsev,Semen Budennyy*

Main category: cs.LG

TL;DR: 本文提出了一种名为PINE的无监督图节点重要性评估方法，该方法结合节点语义特征和网络结构特性，通过注意力机制来识别关键节点。


<details>
  <summary>Details</summary>
Motivation: 传统方法（如节点度、PageRank）仅考虑网络结构而忽略节点属性，现有神经网络方法需要监督学习。本文旨在填补无监督且属性感知的方法空白。

Method: 提出PINE框架，核心是基于注意力的图模型，将节点语义特征融入学习过程，利用注意力分布生成节点重要性评分。

Result: 在多种同质和异质属性网络上展示了优越性能，并成功应用于大规模企业图中的关键实体识别。

Conclusion: PINE是一种有效的无监督方法，能够同时利用网络结构和节点属性来识别重要节点，具有实际工业应用价值。

Abstract: A graph with semantically attributed nodes are a common data structure in a wide range of domains. It could be interlinked web data or citation networks of scientific publications. The essential problem for such a data type is to determine nodes that carry greater importance than all the others, a task that markedly enhances system monitoring and management. Traditional methods to identify important nodes in networks introduce centrality measures, such as node degree or more complex PageRank. However, they consider only the network structure, neglecting the rich node attributes. Recent methods adopt neural networks capable of handling node features, but they require supervision. This work addresses the identified gap--the absence of approaches that are both unsupervised and attribute-aware--by introducing a Pipeline for Important Node Exploration (PINE). At the core of the proposed framework is an attention-based graph model that incorporates node semantic features in the learning process of identifying the structural graph properties. The PINE's node importance scores leverage the obtained attention distribution. We demonstrate the superior performance of the proposed PINE method on various homogeneous and heterogeneous attributed networks. As an industry-implemented system, PINE tackles the real-world challenge of unsupervised identification of key entities within large-scale enterprise graphs.

</details>


### [396] [IFFair: Influence Function-driven Sample Reweighting for Fair Classification](https://arxiv.org/abs/2512.07249)
*Jingran Yang,Min Zhang,Lingfeng Zhang,Zhaohui Wang,Yonggang Zhang*

Main category: cs.LG

TL;DR: 提出基于影响函数的预处理公平性优化方法IFFair，通过动态调整样本权重来减轻机器学习算法中的偏见，而不改变网络结构或决策边界。


<details>
  <summary>Details</summary>
Motivation: 机器学习算法在辅助或替代人类决策时，会学习并加剧样本中的潜在偏见，导致对弱势群体的歧视性决策，损害社会福祉并阻碍相关应用发展。

Method: IFFair方法仅使用训练样本对不同群体影响差异作为指导，在训练过程中动态调整样本权重，无需修改网络结构、数据特征和决策边界。

Result: 在多个真实数据集和指标上的实验表明，IFFair能够减轻分类设置中的多种公平性指标偏见，包括人口统计均等、均等化机会、机会平等和错误率均等，且无冲突。

Conclusion: IFFair在多个效用和公平性指标之间实现了比先前预处理方法更好的权衡，有效缓解了算法偏见问题。

Abstract: Because machine learning has significantly improved efficiency and convenience in the society, it's increasingly used to assist or replace human decision-making. However, the data-based pattern makes related algorithms learn and even exacerbate potential bias in samples, resulting in discriminatory decisions against certain unprivileged groups, depriving them of the rights to equal treatment, thus damaging the social well-being and hindering the development of related applications. Therefore, we propose a pre-processing method IFFair based on the influence function. Compared with other fairness optimization approaches, IFFair only uses the influence disparity of training samples on different groups as a guidance to dynamically adjust the sample weights during training without modifying the network structure, data features and decision boundaries. To evaluate the validity of IFFair, we conduct experiments on multiple real-world datasets and metrics. The experimental results show that our approach mitigates bias of multiple accepted metrics in the classification setting, including demographic parity, equalized odds, equality of opportunity and error rate parity without conflicts. It also demonstrates that IFFair achieves better trade-off between multiple utility and fairness metrics compared with previous pre-processing methods.

</details>


### [397] [SIT-Graph: State Integrated Tool Graph for Multi-Turn Agents](https://arxiv.org/abs/2512.07287)
*Sijia Li,Yuchen Huang,Zifan Liu,Zijian Li,Jingjing fu,Lei Song,Jiang Bian,Jun Zhang,Rui Wang*

Main category: cs.LG

TL;DR: 本文提出了一种状态集成工具图（SIT-Graph）方法，通过利用部分重叠的经验来增强多轮工具使用能力，解决了当前LLM智能体在处理渐进意图和环境变化时的局限性。


<details>
  <summary>Details</summary>
Motivation: 多轮工具使用场景中，意图会逐步明确且环境随每次工具调用而变化。现有LLM智能体要么将整个轨迹或预定义子任务视为不可分割单元，要么仅利用工具间依赖关系，难以适应状态和信息在轮次间的演变。

Method: SIT-Graph从历史轨迹中捕获紧凑的状态表示（类似情景记忆片段）和工具间依赖关系（类似程序记忆例程）。首先从累积的工具使用序列构建工具图，然后在每条边上增强对话和工具历史的紧凑状态摘要。推理时，智能体在需要回忆先前上下文时检索相关边上的状态摘要来指导行动，在常规步骤时则遵循高置信度的工具依赖关系。

Result: 在多个有状态多轮工具使用基准测试中，SIT-Graph始终优于基于记忆和图的基础方法，实现了更稳健的工具选择和更有效的经验迁移。

Conclusion: SIT-Graph通过模拟人类决策中情景记忆和程序记忆的整合，为多轮工具使用提供了更有效的解决方案，能够更好地适应动态变化的环境和渐进明确的意图。

Abstract: Despite impressive advances in agent systems, multi-turn tool-use scenarios remain challenging. It is mainly because intent is clarified progressively and the environment evolves with each tool call. While reusing past experience is natural, current LLM agents either treat entire trajectories or pre-defined subtasks as indivisible units, or solely exploit tool-to-tool dependencies, hindering adaptation as states and information evolve across turns. In this paper, we propose a State Integrated Tool Graph (SIT-Graph), which enhances multi-turn tool use by exploiting partially overlapping experience. Inspired by human decision-making that integrates episodic and procedural memory, SIT-Graph captures both compact state representations (episodic-like fragments) and tool-to-tool dependencies (procedural-like routines) from historical trajectories. Specifically, we first build a tool graph from accumulated tool-use sequences, and then augment each edge with a compact state summary of the dialog and tool history that may shape the next action. At inference time, SIT-Graph enables a human-like balance between episodic recall and procedural execution: when the next decision requires recalling prior context, the agent retrieves the state summaries stored on relevant edges and uses them to guide its next action; when the step is routine, it follows high-confidence tool dependencies without explicit recall. Experiments across multiple stateful multi-turn tool-use benchmarks show that SIT-Graph consistently outperforms strong memory- and graph-based baselines, delivering more robust tool selection and more effective experience transfer.

</details>


### [398] [Towards a Relationship-Aware Transformer for Tabular Data](https://arxiv.org/abs/2512.07310)
*Andrei V. Konstantinov,Valerii A. Zuev,Lev V. Utkin*

Main category: cs.LG

TL;DR: 本文提出了一种基于注意力机制的改进方法，用于处理表格数据中的外部依赖关系，特别是在稀疏图场景下的治疗效果估计任务。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习模型无法有效处理表格数据样本间的外部依赖关系，而图神经网络在稀疏图上表现不佳。需要一种能够考虑数据点间可能关系的机制。

Method: 提出基于修改注意力机制的解决方案，通过在注意力矩阵中添加额外项来考虑数据点间的关系。

Result: 在合成和真实数据集上的回归任务以及IHDP数据集上的治疗效果估计任务中，与梯度提升决策树和其他模型进行了比较验证。

Conclusion: 改进的注意力机制能够有效处理表格数据中的外部依赖关系，在稀疏图场景下表现优于传统方法。

Abstract: Deep learning models for tabular data typically do not allow for imposing a graph of external dependencies between samples, which can be useful for accounting for relatedness in tasks such as treatment effect estimation. Graph neural networks only consider adjacent nodes, making them difficult to apply to sparse graphs. This paper proposes several solutions based on a modified attention mechanism, which accounts for possible relationships between data points by adding a term to the attention matrix. Our models are compared with each other and the gradient boosting decision trees in a regression task on synthetic and real-world datasets, as well as in a treatment effect estimation task on the IHDP dataset.

</details>


### [399] [Learning-Augmented Ski Rental with Discrete Distributions: A Bayesian Approach](https://arxiv.org/abs/2512.07313)
*Bosun Kang,Hyejun Park,Chenglin Fan*

Main category: cs.LG

TL;DR: 本文提出了一个基于贝叶斯决策的滑雪租赁问题新框架，通过维护精确后验分布来统一传统最坏情况分析和学习增强方法，实现不确定性量化和专家先验的无缝整合。


<details>
  <summary>Details</summary>
Motivation: 传统滑雪租赁算法只关注最坏情况成本，而近期学习增强方法虽然利用预测但缺乏不确定性量化。本文旨在统一这两种视角，提供更原则性的决策框架。

Method: 提出离散贝叶斯框架，维护时间范围内的精确后验分布，支持专家先验和不确定性量化，算法能够优雅地在最坏情况和完全信息设置间插值。

Result: 广泛实验表明该框架在多样化场景下具有优越的实证性能，在准确先验下达到接近最优结果，同时保持鲁棒的最坏情况保证。

Conclusion: 贝叶斯框架自然支持多预测、非均匀先验和上下文信息，凸显了贝叶斯推理在具有不完美预测的在线决策问题中的实际优势。

Abstract: We revisit the classic ski rental problem through the lens of Bayesian decision-making and machine-learned predictions. While traditional algorithms minimize worst-case cost without assumptions, and recent learning-augmented approaches leverage noisy forecasts with robustness guarantees, our work unifies these perspectives. We propose a discrete Bayesian framework that maintains exact posterior distributions over the time horizon, enabling principled uncertainty quantification and seamless incorporation of expert priors. Our algorithm achieves prior-dependent competitive guarantees and gracefully interpolates between worst-case and fully-informed settings. Our extensive experimental evaluation demonstrates superior empirical performance across diverse scenarios, achieving near-optimal results under accurate priors while maintaining robust worst-case guarantees. This framework naturally extends to incorporate multiple predictions, non-uniform priors, and contextual information, highlighting the practical advantages of Bayesian reasoning in online decision problems with imperfect predictions.

</details>


### [400] [Local-Curvature-Aware Knowledge Graph Embedding: An Extended Ricci Flow Approach](https://arxiv.org/abs/2512.07332)
*Zhengquan Luo,Guy Tadmor,Or Amar,David Zeevi,Zhiqiang Xu*

Main category: cs.LG

TL;DR: RicciKGE提出了一种新的知识图谱嵌入方法，通过将嵌入损失梯度与局部曲率耦合在扩展的Ricci流中，使实体嵌入与底层流形几何共同演化，实现相互适应。


<details>
  <summary>Details</summary>
Motivation: 现有方法将所有实体放置在单一同质流形上，无法适应真实世界图谱在不同局部区域表现出的显著变化曲率，这种几何不匹配会扭曲实体间距离并损害嵌入表达能力。

Method: 将KGE损失梯度与局部曲率耦合在扩展的Ricci流中，使实体嵌入和流形几何共同动态演化。理论证明当耦合系数有界且适当选择时，边曲率呈指数衰减，流形趋向欧几里得平坦，同时KGE距离严格收敛到全局最优。

Result: 在链接预测和节点分类基准测试中表现出改进效果，证明RicciKGE能够有效适应异构知识图谱结构。

Conclusion: RicciKGE通过几何平坦化和嵌入优化的相互促进，成功解决了现有方法在适应异构图谱结构方面的局限性。

Abstract: Knowledge graph embedding (KGE) relies on the geometry of the embedding space to encode semantic and structural relations. Existing methods place all entities on one homogeneous manifold, Euclidean, spherical, hyperbolic, or their product/multi-curvature variants, to model linear, symmetric, or hierarchical patterns. Yet a predefined, homogeneous manifold cannot accommodate the sharply varying curvature that real-world graphs exhibit across local regions. Since this geometry is imposed a priori, any mismatch with the knowledge graph's local curvatures will distort distances between entities and hurt the expressiveness of the resulting KGE. To rectify this, we propose RicciKGE to have the KGE loss gradient coupled with local curvatures in an extended Ricci flow such that entity embeddings co-evolve dynamically with the underlying manifold geometry towards mutual adaptation. Theoretically, when the coupling coefficient is bounded and properly selected, we rigorously prove that i) all the edge-wise curvatures decay exponentially, meaning that the manifold is driven toward the Euclidean flatness; and ii) the KGE distances strictly converge to a global optimum, which indicates that geometric flattening and embedding optimization are promoting each other. Experimental improvements on link prediction and node classification benchmarks demonstrate RicciKGE's effectiveness in adapting to heterogeneous knowledge graph structures.

</details>


### [401] [Recover-to-Forget: Gradient Reconstruction from LoRA for Efficient LLM Unlearning](https://arxiv.org/abs/2512.07374)
*Yezi Liu,Hanning Chen,Wenjun Huang,Yang Ni,Mohsen Imani*

Main category: cs.LG

TL;DR: R2F是一种基于LoRA适配器更新的高效大语言模型遗忘框架，通过从低秩参数重建全模型梯度方向，避免全模型微调或访问原始训练数据


<details>
  <summary>Details</summary>
Motivation: 解决现有遗忘方法需要全模型微调或访问原始训练数据的问题，提高大语言模型知识更新的可扩展性和实用性

Method: 使用多组转述提示计算LoRA参数的梯度，训练梯度解码器近似对应的全模型梯度；通过代理模型训练解码器并迁移到目标模型

Result: R2F在保持模型通用性能的同时实现有效遗忘，为预训练LLM提供无需全重训练或内部参数访问的轻量级遗忘方案

Conclusion: 该方法为大语言模型提供了一种可扩展且轻量级的遗忘替代方案，具有理论分析和实验验证的有效性

Abstract: Unlearning in large foundation models (e.g., LLMs) is essential for enabling dynamic knowledge updates, enforcing data deletion rights, and correcting model behavior. However, existing unlearning methods often require full-model fine-tuning or access to the original training data, which limits their scalability and practicality. In this work, we introduce Recover-to-Forget (R2F), a novel framework for efficient unlearning in LLMs based on reconstructing full-model gradient directions from low-rank LoRA adapter updates. Rather than performing backpropagation through the full model, we compute gradients with respect to LoRA parameters using multiple paraphrased prompts and train a gradient decoder to approximate the corresponding full-model gradients. To ensure applicability to larger or black-box models, the decoder is trained on a proxy model and transferred to target models. We provide a theoretical analysis of cross-model generalization and demonstrate that our method achieves effective unlearning while preserving general model performance. Experimental results demonstrate that R2F offers a scalable and lightweight alternative for unlearning in pretrained LLMs without requiring full retraining or access to internal parameters.

</details>


### [402] [LUNE: Efficient LLM Unlearning via LoRA Fine-Tuning with Negative Examples](https://arxiv.org/abs/2512.07375)
*Yezi Liu,Hanning Chen,Wenjun Huang,Yang Ni,Mohsen Imani*

Main category: cs.LG

TL;DR: LUNE是一个轻量级的遗忘框架，通过仅更新低秩适配器来高效移除大语言模型中的特定知识，计算成本比全微调低一个数量级。


<details>
  <summary>Details</summary>
Motivation: 大语言模型难以移除特定信息，传统遗忘方法计算成本高，难以实际部署。需要一种轻量高效的遗忘方法。

Method: 基于LoRA的负向遗忘框架，仅更新低秩适配器而冻结主干网络，通过抑制或替换中间表示来实现知识遗忘。

Result: 在多个事实遗忘任务上，LUNE的效果与全微调和内存编辑方法相当，同时计算成本降低约一个数量级。

Conclusion: LUNE提供了一种实用的大语言模型知识遗忘解决方案，在效果和效率之间取得了良好平衡。

Abstract: Large language models (LLMs) possess vast knowledge acquired from extensive training corpora, but they often cannot remove specific pieces of information when needed, which makes it hard to handle privacy, bias mitigation, and knowledge correction. Traditional model unlearning approaches require computationally expensive fine-tuning or direct weight editing, making them impractical for real-world deployment. In this work, we introduce LoRA-based Unlearning with Negative Examples (LUNE), a lightweight framework that performs negative-only unlearning by updating only low-rank adapters while freezing the backbone, thereby localizing edits and avoiding disruptive global changes. Leveraging Low-Rank Adaptation (LoRA), LUNE targets intermediate representations to suppress (or replace) requested knowledge with an order-of-magnitude lower compute and memory than full fine-tuning or direct weight editing. Extensive experiments on multiple factual unlearning tasks show that LUNE: (I) achieves effectiveness comparable to full fine-tuning and memory-editing methods, and (II) reduces computational cost by about an order of magnitude.

</details>


### [403] [Towards Reliable Test-Time Adaptation: Style Invariance as a Correctness Likelihood](https://arxiv.org/abs/2512.07390)
*Gilhyun Nam,Taewon Kim,Joonhyun Jeong,Eunho Yang*

Main category: cs.LG

TL;DR: SICL是一个基于风格不变性的测试时自适应校准框架，通过测量风格变换后预测一致性来估计实例级正确性概率，无需反向传播即可实现稳健的不确定性估计。


<details>
  <summary>Details</summary>
Motivation: 现有校准方法假设固定模型或静态分布，在真实世界动态测试条件下性能下降，而测试时自适应模型往往存在预测不确定性校准不良的问题。

Method: SICL利用风格不变性原理，通过生成风格变换的变体并测量预测一致性来估计实例级正确性似然，仅需模型前向传播，无需反向传播。

Result: 在4个基线、5种TTA方法和2个现实场景、3种模型架构上的综合评估显示，SICL相比传统校准方法平均减少13个百分点的校准误差。

Conclusion: SICL是一个即插即用的校准模块，兼容任何TTA方法，在动态测试条件下显著提升了不确定性校准的鲁棒性。

Abstract: Test-time adaptation (TTA) enables efficient adaptation of deployed models, yet it often leads to poorly calibrated predictive uncertainty - a critical issue in high-stakes domains such as autonomous driving, finance, and healthcare. Existing calibration methods typically assume fixed models or static distributions, resulting in degraded performance under real-world, dynamic test conditions. To address these challenges, we introduce Style Invariance as a Correctness Likelihood (SICL), a framework that leverages style-invariance for robust uncertainty estimation. SICL estimates instance-wise correctness likelihood by measuring prediction consistency across style-altered variants, requiring only the model's forward pass. This makes it a plug-and-play, backpropagation-free calibration module compatible with any TTA method. Comprehensive evaluations across four baselines, five TTA methods, and two realistic scenarios with three model architecture demonstrate that SICL reduces calibration error by an average of 13 percentage points compared to conventional calibration approaches.

</details>


### [404] [Empirical Results for Adjusting Truncated Backpropagation Through Time while Training Neural Audio Effects](https://arxiv.org/abs/2512.07393)
*Yann Bourdin,Pierrick Legrand,Fanny Roche*

Main category: cs.LG

TL;DR: 本研究探讨了截断时间反向传播(TBPTT)在数字音频效果建模中的优化，重点关注动态范围压缩，通过调整关键超参数提升模型性能和训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 优化TBPTT训练方法以提高数字音频效果建模的准确性和计算效率，特别是在动态范围压缩任务中。

Method: 使用卷积-循环架构，通过实验评估TBPTT的关键超参数（序列数、批次大小和序列长度）在不同数据集上的影响。

Result: 优化后的TBPTT参数设置显著提高了模型精度和训练稳定性，同时降低了计算需求，客观评估和主观听感测试均证实了性能提升。

Conclusion: 精心调整TBPTT超参数可以有效改善数字音频效果建模的性能，在保持高感知质量的同时提升计算效率。

Abstract: This paper investigates the optimization of Truncated Backpropagation Through Time (TBPTT) for training neural networks in digital audio effect modeling, with a focus on dynamic range compression. The study evaluates key TBPTT hyperparameters -- sequence number, batch size, and sequence length -- and their influence on model performance. Using a convolutional-recurrent architecture, we conduct extensive experiments across datasets with and without conditionning by user controls. Results demonstrate that carefully tuning these parameters enhances model accuracy and training stability, while also reducing computational demands. Objective evaluations confirm improved performance with optimized settings, while subjective listening tests indicate that the revised TBPTT configuration maintains high perceptual quality.

</details>


### [405] [Asymptotic analysis of shallow and deep forgetting in replay with Neural Collapse](https://arxiv.org/abs/2512.07400)
*Giulia Lanzillotta,Damiano Meier,Thomas Hofmann*

Main category: cs.LG

TL;DR: 论文揭示了持续学习中深度特征空间遗忘与浅层分类器遗忘之间的不对称性，指出即使小缓冲区也能防止深度遗忘，但缓解浅层遗忘需要更大容量。


<details>
  <summary>Details</summary>
Motivation: 解决持续学习中神经网络能保持过去任务的线性可分表示但输出预测失败这一矛盾现象。

Method: 将神经崩溃框架扩展到顺序设置，分析特征几何漂移和协方差矩阵秩不足问题，将持续学习与分布外检测统一。

Result: 证明任何非零重播分数都能渐近保证线性可分性的保持，但小缓冲区会导致强崩溃和统计伪影。

Conclusion: 挑战依赖大缓冲区的传统做法，建议通过显式校正统计伪影来实现最小重播下的鲁棒性能。

Abstract: A persistent paradox in continual learning (CL) is that neural networks often retain linearly separable representations of past tasks even when their output predictions fail. We formalize this distinction as the gap between deep feature-space and shallow classifier-level forgetting. We reveal a critical asymmetry in Experience Replay: while minimal buffers successfully anchor feature geometry and prevent deep forgetting, mitigating shallow forgetting typically requires substantially larger buffer capacities. To explain this, we extend the Neural Collapse framework to the sequential setting. We characterize deep forgetting as a geometric drift toward out-of-distribution subspaces and prove that any non-zero replay fraction asymptotically guarantees the retention of linear separability. Conversely, we identify that the "strong collapse" induced by small buffers leads to rank-deficient covariances and inflated class means, effectively blinding the classifier to true population boundaries. By unifying CL with out-of-distribution detection, our work challenges the prevailing reliance on large buffers, suggesting that explicitly correcting these statistical artifacts could unlock robust performance with minimal replay.

</details>


### [406] [Adaptive Tuning of Parameterized Traffic Controllers via Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2512.07417)
*Giray Önür,Azita Dabiri,Bart De Schutter*

Main category: cs.LG

TL;DR: 本文提出了一种多智能体强化学习框架，用于自适应调整状态反馈交通控制器的参数，结合了状态反馈控制器的反应性和强化学习的适应性。


<details>
  <summary>Details</summary>
Motivation: 传统交通管理策略（如路线引导、匝道计量和交通信号控制）通常依赖状态反馈控制器，虽然简单且反应迅速，但缺乏应对复杂时变交通动态的适应性。

Method: 采用多智能体强化学习框架，每个智能体以较低频率自适应调整状态反馈控制器的参数，而不是直接高频确定控制动作。多智能体结构增强了系统鲁棒性，局部控制器在部分故障时可独立运行。

Result: 在模拟的多类交通网络中进行评估，结果表明该框架在无控制和固定参数状态反馈控制情况下表现更优，与单智能体RL自适应状态反馈控制性能相当，但对部分故障的恢复能力更强。

Conclusion: 该多智能体强化学习框架有效结合了状态反馈控制的反应性和强化学习的适应性，提高了训练效率并增强了系统鲁棒性，适用于复杂时变的交通环境。

Abstract: Effective traffic control is essential for mitigating congestion in transportation networks. Conventional traffic management strategies, including route guidance, ramp metering, and traffic signal control, often rely on state feedback controllers, used for their simplicity and reactivity; however, they lack the adaptability required to cope with complex and time-varying traffic dynamics. This paper proposes a multi-agent reinforcement learning framework in which each agent adaptively tunes the parameters of a state feedback traffic controller, combining the reactivity of state feedback controllers with the adaptability of reinforcement learning. By tuning parameters at a lower frequency rather than directly determining control actions at a high frequency, the reinforcement learning agents achieve improved training efficiency while maintaining adaptability to varying traffic conditions. The multi-agent structure further enhances system robustness, as local controllers can operate independently in the event of partial failures. The proposed framework is evaluated on a simulated multi-class transportation network under varying traffic conditions. Results show that the proposed multi-agent framework outperforms the no control and fixed-parameter state feedback control cases, while performing on par with the single-agent RL-based adaptive state feedback control, with a much better resilience to partial failures.

</details>


### [407] [Revolutionizing Mixed Precision Quantization: Towards Training-free Automatic Proxy Discovery via Large Language Models](https://arxiv.org/abs/2512.07419)
*Haidong Kang,Jun Du,Lihong Lin*

Main category: cs.LG

TL;DR: 本文提出了一种基于大语言模型的训练免费自动代理发现框架TAP，用于解决混合精度量化中代理设计的人工依赖问题，通过强化学习优化提示来提升LLM推理能力，实现自动化的代理发现。


<details>
  <summary>Details</summary>
Motivation: 传统混合精度量化方法要么依赖昂贵的可微分优化，效率低下且缺乏灵活性；要么需要人工专家设计的代理，劳动密集且需要大量专业知识。能否设计一种无需人工专家参与和训练的代理？

Method: 提出TAP框架：1）利用大语言模型自动发现适合混合精度量化的代理；2）设计基于直接策略优化的强化学习来优化提示，增强LLM推理能力，构建LLM与MPQ任务之间的正向反馈循环。

Result: 在主流基准测试上的广泛实验表明，TAP实现了最先进的性能。

Conclusion: TAP为混合精度量化社区提供了一个新的LLM驱动设计算法视角，将显著推动该领域的发展。

Abstract: Mixed-Precision Quantization (MPQ) liberates the Deep Neural Networks (DNNs) from the Out-Of-Memory (OOM) bottleneck, which garnered increasing research attention. However, conventional methods either searched from costly differentiable optimization, which is neither efficient nor flexible, or learned a quantized DNN from the proxy (i.e., HAWQ) manually designed by human experts, which is labor-intensive and requires huge expert knowledge. Can we design a proxy without involving any human experts and training? In this paper, we provide an affirmative answer by proposing a novel Large Language Models (LLMs)-driven Training-free Automatic Proxy (dubbed TAP) discovery framework, which reforms the design paradigm of MPQ by utilizing LLMs to find superior TAP tailored for MPQ, automatically. In addition, to bridge the gap between black-box LLMs and the tough MPQ task, we ingeniously propose simple Direct Policy Optimization (DPO) based reinforcement learning to enhance LLMs' reasoning by optimizing prompts, which can construct a positive feedback loop between the LLM and the MPQ task, enabling LLMs to generate better TAP in the next evolution. Extensive experiments on mainstream benchmarks demonstrate that TAP achieves state-of-the-art performance. Finally, we truly believe that our TAP will significantly contribute to the MPQ community by providing a new perspective on LLM-driven design algorithms.

</details>


### [408] [MIDG: Mixture of Invariant Experts with knowledge injection for Domain Generalization in Multimodal Sentiment Analysis](https://arxiv.org/abs/2512.07430)
*Yangle Li,Danli Luo,Haifeng Hu*

Main category: cs.LG

TL;DR: 本文提出了一种新的多模态情感分析领域泛化框架MIDG，通过混合不变专家模型和跨模态适配器来解决现有方法中模态间协同关系不足和跨模态知识碎片化的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态情感分析领域泛化方法在提取不变特征时忽视了模态间的协同关系，且知识注入技术存在跨模态知识碎片化问题，无法充分捕捉多模态数据的丰富语义信息。

Method: 1) 混合不变专家模型：提取领域不变特征，增强模态间协同关系的学习能力；2) 跨模态适配器：通过跨模态知识注入增强多模态表示的语义丰富度。

Result: 在三个数据集上的广泛领域实验表明，所提出的MIDG框架取得了优越的性能。

Conclusion: 该框架通过有效利用模态间协同关系和跨模态知识注入，显著提升了多模态情感分析在领域泛化任务中的性能。

Abstract: Existing methods in domain generalization for Multimodal Sentiment Analysis (MSA) often overlook inter-modal synergies during invariant features extraction, which prevents the accurate capture of the rich semantic information within multimodal data. Additionally, while knowledge injection techniques have been explored in MSA, they often suffer from fragmented cross-modal knowledge, overlooking specific representations that exist beyond the confines of unimodal. To address these limitations, we propose a novel MSA framework designed for domain generalization. Firstly, the framework incorporates a Mixture of Invariant Experts model to extract domain-invariant features, thereby enhancing the model's capacity to learn synergistic relationships between modalities. Secondly, we design a Cross-Modal Adapter to augment the semantic richness of multimodal representations through cross-modal knowledge injection. Extensive domain experiments conducted on three datasets demonstrate that the proposed MIDG achieves superior performance.

</details>


### [409] [Mitigating Bias in Graph Hyperdimensional Computing](https://arxiv.org/abs/2512.07433)
*Yezi Liu,William Youngwoo Chung,Yang Ni,Hanning Chen,Mohsen Imani*

Main category: cs.LG

TL;DR: 该论文研究了图超维计算（HDC）中的公平性问题，提出了FairGHDC框架来缓解偏见，在保持准确性的同时显著减少了公平性差距，并实现了约10倍的训练速度提升。


<details>
  <summary>Details</summary>
Motivation: 虽然图HDC在认知任务中表现出色，但其公平性影响尚未得到充分探索。数据表示和决策规则中的偏见可能导致对不同群体的不公平对待，需要研究如何缓解这种偏见。

Method: 提出了FairGHDC框架，引入基于差距的人口统计奇偶正则化器的偏见校正项，将其转换为标量公平因子，直接在超向量空间中缩放真实标签类别超向量的更新，无需修改图编码器或反向传播。

Result: 在六个基准数据集上的实验表明，FairGHDC显著减少了人口统计奇偶和机会均等差距，同时保持了与标准GNN和公平感知GNN相当的准确性，并在GPU上实现了约10倍的训练加速。

Conclusion: FairGHDC框架有效解决了图HDC中的公平性问题，在保持计算效率的同时实现了公平性提升，为脑启发式计算系统的公平性研究提供了新思路。

Abstract: Graph hyperdimensional computing (HDC) has emerged as a promising paradigm for cognitive tasks, emulating brain-like computation with high-dimensional vectors known as hypervectors. While HDC offers robustness and efficiency on graph-structured data, its fairness implications remain largely unexplored. In this paper, we study fairness in graph HDC, where biases in data representation and decision rules can lead to unequal treatment of different groups. We show how hypervector encoding and similarity-based classification can propagate or even amplify such biases, and we propose a fairness-aware training framework, FairGHDC, to mitigate them. FairGHDC introduces a bias correction term, derived from a gap-based demographic-parity regularizer, and converts it into a scalar fairness factor that scales the update of the class hypervector for the ground-truth label. This enables debiasing directly in the hypervector space without modifying the graph encoder or requiring backpropagation. Experimental results on six benchmark datasets demonstrate that FairGHDC substantially reduces demographic-parity and equal-opportunity gaps while maintaining accuracy comparable to standard GNNs and fairness-aware GNNs. At the same time, FairGHDC preserves the computational advantages of HDC, achieving up to about one order of magnitude ($\approx 10\times$) speedup in training time on GPU compared to GNN and fairness-aware GNN baselines.

</details>


### [410] [Forget and Explain: Transparent Verification of GNN Unlearning](https://arxiv.org/abs/2512.07450)
*Imran Ahsan,Hyunwook Yu,Jinsung Kim,Mucheol Kim*

Main category: cs.LG

TL;DR: 提出了一种基于可解释性的GNN遗忘验证方法，通过对比删除前后的模型解释差异来透明验证遗忘效果。


<details>
  <summary>Details</summary>
Motivation: 现有GNN遗忘方法缺乏透明度，难以验证信息是否真正被遗忘，特别是在GDPR等隐私法规要求下。

Method: 使用归因偏移和局部结构变化（如图编辑距离）作为透明证据，提出五种可解释性指标来验证遗忘效果。

Result: 评估显示Retrain和GNNDelete实现近乎完全遗忘，GraphEditor提供部分擦除，IDEA存在残留信号。

Conclusion: 解释差异提供了主要的人类可读遗忘证据，成员推断ROC-AUC可作为补充的图范围隐私信号。

Abstract: Graph neural networks (GNNs) are increasingly used to model complex patterns in graph-structured data. However, enabling them to "forget" designated information remains challenging, especially under privacy regulations such as the GDPR. Existing unlearning methods largely optimize for efficiency and scalability, yet they offer little transparency, and the black-box nature of GNNs makes it difficult to verify whether forgetting has truly occurred. We propose an explainability-driven verifier for GNN unlearning that snapshots the model before and after deletion, using attribution shifts and localized structural changes (for example, graph edit distance) as transparent evidence. The verifier uses five explainability metrics: residual attribution, heatmap shift, explainability score deviation, graph edit distance, and a diagnostic graph rule shift. We evaluate two backbones (GCN, GAT) and four unlearning strategies (Retrain, GraphEditor, GNNDelete, IDEA) across five benchmarks (Cora, Citeseer, Pubmed, Coauthor-CS, Coauthor-Physics). Results show that Retrain and GNNDelete achieve near-complete forgetting, GraphEditor provides partial erasure, and IDEA leaves residual signals. These explanation deltas provide the primary, human-readable evidence of forgetting; we also report membership-inference ROC-AUC as a complementary, graph-wide privacy signal.

</details>


### [411] [Parallel Algorithms for Combined Regularized Support Vector Machines: Application in Music Genre Classification](https://arxiv.org/abs/2512.07463)
*Rongmei Liang,Zizheng Liu,Xiaofei Wu,Jingwen Tu*

Main category: cs.LG

TL;DR: 本文提出了一种基于共识结构的统一优化框架，用于解决分布式存储大数据中的组合正则化支持向量机（CR-SVMs）计算问题，开发了分布式并行ADMM算法，并引入高斯回代法确保收敛。


<details>
  <summary>Details</summary>
Motivation: 在人工智能快速发展时代，组合正则化支持向量机（CR-SVMs）能有效处理数据特征结构信息，但在分布式存储大数据场景下缺乏高效算法。

Method: 提出基于共识结构的统一优化框架，开发分布式并行交替方向乘子法（ADMM）算法，引入高斯回代法确保收敛，并提出稀疏群套索支持向量机（SGL-SVM）模型应用于音乐信息检索。

Result: 理论分析表明算法计算复杂度不受正则化项和损失函数影响，实验在合成和自由音乐档案数据集上验证了算法的可靠性、稳定性和效率。

Conclusion: 提出的统一框架具有强扩展性，可适用于各种损失函数和组合正则化项，并行算法具有普适性，在分布式大数据环境下表现优异。

Abstract: In the era of rapid development of artificial intelligence, its applications span across diverse fields, relying heavily on effective data processing and model optimization. Combined Regularized Support Vector Machines (CR-SVMs) can effectively handle the structural information among data features, but there is a lack of efficient algorithms in distributed-stored big data. To address this issue, we propose a unified optimization framework based on consensus structure. This framework is not only applicable to various loss functions and combined regularization terms but can also be effectively extended to non-convex regularization terms, showing strong scalability. Based on this framework, we develop a distributed parallel alternating direction method of multipliers (ADMM) algorithm to efficiently compute CR-SVMs when data is stored in a distributed manner. To ensure the convergence of the algorithm, we also introduce the Gaussian back-substitution method. Meanwhile, for the integrity of the paper, we introduce a new model, the sparse group lasso support vector machine (SGL-SVM), and apply it to music information retrieval. Theoretical analysis confirms that the computational complexity of the proposed algorithm is not affected by different regularization terms and loss functions, highlighting the universality of the parallel algorithm. Experiments on synthetic and free music archiv datasets demonstrate the reliability, stability, and efficiency of the algorithm.

</details>


### [412] [Materium: An Autoregressive Approach for Material Generation](https://arxiv.org/abs/2512.07486)
*Niklas Dobberstein,Jan Hamaekers*

Main category: cs.LG

TL;DR: Materium是一个用于生成晶体结构的自回归变压器，通过将3D材料表示转换为令牌序列来实现快速、可扩展的晶体生成。


<details>
  <summary>Details</summary>
Motivation: 传统的扩散方法需要多次迭代去噪步骤来细化原子位置，而Materium旨在通过精确放置原子坐标实现更快速、高效的晶体结构生成。

Method: 将3D材料表示（包括元素氧化态、分数坐标和晶格参数）转换为令牌序列，使用自回归变压器模型进行训练和生成。

Result: 模型在单GPU上仅需几小时即可完成训练，生成速度比基于扩散的方法快得多，在单条件和组合条件下都能产生与输入要求一致的候选结构。

Conclusion: Materium提供了一种快速、可扩展的晶体结构生成方法，在多种属性条件约束下表现良好，为材料设计提供了高效工具。

Abstract: We present Materium: an autoregressive transformer for generating crystal structures that converts 3D material representations into token sequences. These sequences include elements with oxidation states, fractional coordinates and lattice parameters. Unlike diffusion approaches, which refine atomic positions iteratively through many denoising steps, Materium places atoms at precise fractional coordinates, enabling fast, scalable generation. With this design, the model can be trained in a few hours on a single GPU and generate samples much faster on GPUs and CPUs than diffusion-based approaches. The model was trained and evaluated using multiple properties as conditions, including fundamental properties, such as density and space group, as well as more practical targets, such as band gap and magnetic density. In both single and combined conditions, the model performs consistently well, producing candidates that align with the requested inputs.

</details>


### [413] [Efficient Low-Tubal-Rank Tensor Estimation via Alternating Preconditioned Gradient Descent](https://arxiv.org/abs/2512.07490)
*Zhiyu Liu,Zhi Han,Yandong Tang,Jun Fan,Yao Wang*

Main category: cs.LG

TL;DR: 提出了一种交替预条件梯度下降（APGD）算法，用于解决低管秩张量估计问题，该算法在过参数化设置下通过预条件项加速收敛，并具有线性收敛保证。


<details>
  <summary>Details</summary>
Motivation: 传统张量奇异值分解方法计算成本高，不适用于大规模张量；现有基于梯度下降的因子分解方法需要准确估计张量秩，当秩被高估时收敛速度显著下降甚至发散。

Method: APGD算法通过向原始梯度添加预条件项，并交替更新两个较小的因子张量，从而在过参数化情况下加速收敛。

Result: 理论分析表明APGD在过参数化情况下仍能实现线性收敛，且收敛速率与张量条件数无关；大量合成数据实验验证了理论结果。

Conclusion: APGD算法有效解决了低管秩张量估计中的过参数化问题，具有线性收敛性和对条件数的独立性，为大规模张量处理提供了高效解决方案。

Abstract: The problem of low-tubal-rank tensor estimation is a fundamental task with wide applications across high-dimensional signal processing, machine learning, and image science. Traditional approaches tackle such a problem by performing tensor singular value decomposition, which is computationally expensive and becomes infeasible for large-scale tensors. Recent approaches address this issue by factorizing the tensor into two smaller factor tensors and solving the resulting problem using gradient descent. However, this kind of approach requires an accurate estimate of the tensor rank, and when the rank is overestimated, the convergence of gradient descent and its variants slows down significantly or even diverges. To address this problem, we propose an Alternating Preconditioned Gradient Descent (APGD) algorithm, which accelerates convergence in the over-parameterized setting by adding a preconditioning term to the original gradient and updating these two factors alternately. Based on certain geometric assumptions on the objective function, we establish linear convergence guarantees for more general low-tubal-rank tensor estimation problems. Then we further analyze the specific cases of low-tubal-rank tensor factorization and low-tubal-rank tensor recovery. Our theoretical results show that APGD achieves linear convergence even under over-parameterization, and the convergence rate is independent of the tensor condition number. Extensive simulations on synthetic data are carried out to validate our theoretical assertions.

</details>


### [414] [Exploring possible vector systems for faster training of neural networks with preconfigured latent spaces](https://arxiv.org/abs/2512.07509)
*Nikita Gabdullin*

Main category: cs.LG

TL;DR: 本文探讨了使用预定义向量系统（如An根系统向量）作为潜在空间配置目标的方法，以优化神经网络嵌入分布，从而加速大规模分类任务的训练过程。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决大规模类别数据集（如ImageNet-1K和50k-600k类别）中神经网络训练效率低下的问题，通过优化潜在空间结构来避免使用分类层，简化网络架构。

Method: 方法包括使用预定义的向量系统（如An根系统）作为潜在空间配置的目标，构建适合的向量系统，并在编码器和视觉变换器中应用这些系统，以最小化潜在空间维度。

Result: 实验结果表明，该方法显著加快了ImageNet-1K和50k-600k类别数据集的训练速度，并且使用最小潜在空间维度能够实现更快的收敛。

Conclusion: 结论是预定义向量系统能够有效优化神经网络的潜在空间结构，提升训练效率，并有助于减少嵌入存储的向量数据库大小。

Abstract: The overall neural network (NN) performance is closely related to the properties of its embedding distribution in latent space (LS). It has recently been shown that predefined vector systems, specifically An root system vectors, can be used as targets for latent space configurations (LSC) to ensure the desired LS structure. One of the main LSC advantage is the possibility of training classifier NNs without classification layers, which facilitates training NNs on datasets with extremely large numbers of classes. This paper provides a more general overview of possible vector systems for NN training along with their properties and methods for vector system construction. These systems are used to configure LS of encoders and visual transformers to significantly speed up ImageNet-1K and 50k-600k classes LSC training. It is also shown that using the minimum number of LS dimensions for a specific number of classes results in faster convergence. The latter has potential advantages for reducing the size of vector databases used to store NN embeddings.

</details>


### [415] [Machine Learning: Progress and Prospects](https://arxiv.org/abs/2512.07519)
*Alexander Gammerman*

Main category: cs.LG

TL;DR: 这篇论文探讨了机器学习的起源和发展，从1949年香农的算法到亚里士多德的学习理论，涵盖了多个历史时期和不同学科对机器学习的影响。


<details>
  <summary>Details</summary>
Motivation: 旨在梳理机器学习的起源和发展历程，探讨其多学科背景和不同研究方向的融合。

Method: 通过历史回顾和理论分析，追溯机器学习思想的起源，并分析不同学科对机器学习发展的贡献。

Result: 明确了机器学习起源于多个历史时期和不同学科，包括哲学、统计学和计算机科学等，形成了多个并行研究方向。

Conclusion: 机器学习是一个多学科融合的领域，其思想根源可以追溯到古代，现代发展则受益于多个学科的交叉影响。

Abstract: This Inaugural Lecture was given at Royal Holloway University of London in 1996. It covers an introduction to machine learning and describes various theoretical advances and practical projects in the field. The Lecture here is presented in its original format, but a few remarks have been added in 2025 to reflect recent developments, and the list of references has been updated to enhance the convenience and accuracy for readers.
  When did machine learning start? Maybe a good starting point is 1949, when Claude Shannon proposed a learning algorithm for chess-playing programs. Or maybe we should go back to the 1930s when Ronald Fisher developed discriminant analysis - a type of learning where the problem is to construct a decision rule that separates two types of vectors. Or could it be the 18th century when David Hume discussed the idea of induction? Or the 14th century, when William of Ockham formulated the principle of "simplicity" known as "Ockham's razor" (Ockham, by the way, is a small village not far from Royal Holloway). Or it may be that, like almost everything else in Western civilisation and culture, the origin of these ideas lies in the Mediterranean. After all, it was Aristotle who said that "we learn some things only by doing things".
  The field of machine learning has been greatly influenced by other disciplines and the subject is in itself not a very homogeneous discipline, but includes separate, overlapping subfields. There are many parallel lines of research in ML: inductive learning, neural networks, clustering, and theories of learning. They are all part of the more general field of machine learning.

</details>


### [416] [Model-Based Reinforcement Learning Under Confounding](https://arxiv.org/abs/2512.07528)
*Nishanth Venkatesh,Andreas A. Malikopoulos*

Main category: cs.LG

TL;DR: 本文提出了一种基于模型的强化学习方法，用于处理上下文未观察到的混淆马尔可夫决策过程（C-MDPs），通过代理变量和最大因果熵框架实现一致的政策评估。


<details>
  <summary>Details</summary>
Motivation: 在离线数据集中，未观察到的上下文会导致混淆问题，传统模型学习方法在这种设置下存在根本性的不一致性，因为行为策略生成的转移和奖励机制与评估状态策略所需的干预量不对应。

Method: 采用近端离策略评估方法，利用代理变量的可逆性条件识别混淆奖励期望，结合行为平均转移模型构建替代MDP，并与最大因果熵模型学习框架无缝集成。

Result: 所构建的替代MDP具有明确定义且一致的状态策略贝尔曼算子，能够在上下文信息未观察、不可用或收集不切实际的环境中进行有原则的模型学习和规划。

Conclusion: 该方法为存在混淆的强化学习环境提供了一种理论严谨的解决方案，扩展了模型学习在现实世界应用中的可行性。

Abstract: We investigate model-based reinforcement learning in contextual Markov decision processes (C-MDPs) in which the context is unobserved and induces confounding in the offline dataset. In such settings, conventional model-learning methods are fundamentally inconsistent, as the transition and reward mechanisms generated under a behavioral policy do not correspond to the interventional quantities required for evaluating a state-based policy. To address this issue, we adapt a proximal off-policy evaluation approach that identifies the confounded reward expectation using only observable state-action-reward trajectories under mild invertibility conditions on proxy variables. When combined with a behavior-averaged transition model, this construction yields a surrogate MDP whose Bellman operator is well defined and consistent for state-based policies, and which integrates seamlessly with the maximum causal entropy (MaxCausalEnt) model-learning framework. The proposed formulation enables principled model learning and planning in confounded environments where contextual information is unobserved, unavailable, or impractical to collect.

</details>


### [417] [FRWKV:Frequency-Domain Linear Attention for Long-Term Time Series Forecasting](https://arxiv.org/abs/2512.07539)
*Qingyuan Yang,Shizhuo,Dongyue Chen,Da Teng,Zehua Gan*

Main category: cs.LG

TL;DR: FRWKV是一个结合线性注意力和频域分析的时间序列预测框架，解决了传统Transformer的二次复杂度问题，实现了O(T)的线性复杂度，在8个真实数据集上取得了最佳平均排名。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer在长序列时间序列预测中存在二次复杂度O(T²)的瓶颈，且难以有效利用频域信息。受到RWKV线性注意力的启发，需要开发一个既能降低计算复杂度又能充分利用频域信息的模型。

Method: 提出FRWKV框架，将线性注意力机制与频域分析相结合，在注意力路径上实现O(T)计算复杂度，同时利用频谱信息增强时序特征表示，支持可扩展的长序列建模。

Result: 在8个真实世界数据集上的实验表明，FRWKV取得了第一名的平均排名。消融研究证实了线性注意力和频域编码器两个组件的关键作用。

Conclusion: 这项工作展示了线性注意力与频域分析之间的强大协同作用，为可扩展时间序列建模建立了新范式。代码已在GitHub开源。

Abstract: Traditional Transformers face a major bottleneck in long-sequence time series forecasting due to their quadratic complexity $(\mathcal{O}(T^2))$ and their limited ability to effectively exploit frequency-domain information. Inspired by RWKV's $\mathcal{O}(T)$ linear attention and frequency-domain modeling, we propose FRWKV, a frequency-domain linear-attention framework that overcomes these limitations. Our model integrates linear attention mechanisms with frequency-domain analysis, achieving $\mathcal{O}(T)$ computational complexity in the attention path while exploiting spectral information to enhance temporal feature representations for scalable long-sequence modeling. Across eight real-world datasets, FRWKV achieves a first-place average rank. Our ablation studies confirm the critical roles of both the linear attention and frequency-encoder components. This work demonstrates the powerful synergy between linear attention and frequency analysis, establishing a new paradigm for scalable time series modeling. Code is available at this repository: https://github.com/yangqingyuan-byte/FRWKV.

</details>


### [418] [RRAEDy: Adaptive Latent Linearization of Nonlinear Dynamical Systems](https://arxiv.org/abs/2512.07542)
*Jad Mounayer,Sebastian Rodriguez,Jerome Tomezyk,Chady Ghnatios,Francisco Chinesta*

Main category: cs.LG

TL;DR: RRAEDy是一种新型的潜空间动态系统模型，通过自动发现合适的潜维度，在潜空间中强制执行正则化和线性化动态，解决了现有模型需要预先固定潜维度、依赖复杂损失平衡和缺乏潜变量正则化的问题。


<details>
  <summary>Details</summary>
Motivation: 现有潜空间动态系统模型存在三个主要限制：需要预先固定潜维度、依赖复杂损失平衡来近似线性动态、以及缺乏对潜变量的正则化。这些限制影响了模型的性能和稳定性。

Method: 基于秩约减自编码器（RRAEs），RRAEDy通过奇异值自动排序和剪枝潜变量，同时学习控制其时间演化的潜动态模态分解（DMD）算子。这种无结构但线性约束的公式使模型能够学习稳定且低维的动态，无需辅助损失或手动调参。

Result: 在经典基准测试（包括Van der Pol振荡器、Burgers方程、2D Navier-Stokes和旋转高斯分布）上的实验表明，RRAEDy实现了准确且鲁棒的预测。理论分析证明了学习算子的稳定性，并通过处理参数ODE的扩展展示了模型的通用性。

Conclusion: RRAEDy通过消除现有模型的限制，提供了一种更有效和稳定的潜空间动态系统建模方法，具有理论保证和实验验证的优越性能。模型代码已开源。

Abstract: Most existing latent-space models for dynamical systems require fixing the latent dimension in advance, they rely on complex loss balancing to approximate linear dynamics, and they don't regularize the latent variables. We introduce RRAEDy, a model that removes these limitations by discovering the appropriate latent dimension, while enforcing both regularized and linearized dynamics in the latent space. Built upon Rank-Reduction Autoencoders (RRAEs), RRAEDy automatically rank and prune latent variables through their singular values while learning a latent Dynamic Mode Decomposition (DMD) operator that governs their temporal progression. This structure-free yet linearly constrained formulation enables the model to learn stable and low-dimensional dynamics without auxiliary losses or manual tuning. We provide theoretical analysis demonstrating the stability of the learned operator and showcase the generality of our model by proposing an extension that handles parametric ODEs. Experiments on canonical benchmarks, including the Van der Pol oscillator, Burgers' equation, 2D Navier-Stokes, and Rotating Gaussians, show that RRAEDy achieves accurate and robust predictions. Our code is open-source and available at https://github.com/JadM133/RRAEDy. We also provide a video summarizing the main results at https://youtu.be/ox70mSSMGrM.

</details>


### [419] [ReLaX: Reasoning with Latent Exploration for Large Reasoning Models](https://arxiv.org/abs/2512.07558)
*Shimin Zhang,Xianwei Chen,Yufan Shen,Ziyuan Ye,Jibin Wu*

Main category: cs.LG

TL;DR: 本文提出ReLaX方法，通过分析LRMs的潜在动态来解决RLVR中的熵崩溃问题，显著提升推理性能


<details>
  <summary>Details</summary>
Motivation: RLVR虽然能增强大推理模型的推理能力，但常导致熵崩溃，造成策略过早收敛和性能饱和。作者认为token生成背后的潜在动态包含更丰富的计算结构，可用于引导策略优化

Method: 利用Koopman算子理论获得隐藏状态动态的线性表示，提出动态谱分散度(DSD)指标量化潜在动态异质性，并基于此提出ReLaX范式来调控策略优化中的探索与利用

Result: 在多模态和纯文本推理基准上的综合实验表明，ReLaX显著缓解了过早收敛问题，并持续实现最先进的性能

Conclusion: ReLaX通过显式整合潜在动态来调控策略优化，有效解决了RLVR中的熵崩溃问题，为提升大推理模型的推理能力提供了新思路

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has recently demonstrated remarkable potential in enhancing the reasoning capability of Large Reasoning Models (LRMs). However, RLVR often leads to entropy collapse, resulting in premature policy convergence and performance saturation. While manipulating token-level entropy has proven effective for promoting policy exploration, we argue that the latent dynamics underlying token generation encode a far richer computational structure for steering policy optimization toward a more effective exploration-exploitation tradeoff. To enable tractable analysis and intervention of the latent dynamics of LRMs, we leverage Koopman operator theory to obtain a linearized representation of their hidden-state dynamics. This enables us to introduce Dynamic Spectral Dispersion (DSD), a new metric to quantify the heterogeneity of the model's latent dynamics, serving as a direct indicator of policy exploration. Building upon these foundations, we propose Reasoning with Latent eXploration (ReLaX), a paradigm that explicitly incorporates latent dynamics to regulate exploration and exploitation during policy optimization. Comprehensive experiments across a wide range of multimodal and text-only reasoning benchmarks show that ReLaX significantly mitigates premature convergence and consistently achieves state-of-the-art performance.

</details>


### [420] [Weighted Contrastive Learning for Anomaly-Aware Time-Series Forecasting](https://arxiv.org/abs/2512.07569)
*Joel Ekstrand,Tor Mattsson,Zahra Taghiyarrenani,Slawomir Nowaczyk,Jens Lundström,Mikael Lindén*

Main category: cs.LG

TL;DR: WECA方法通过加权对比适应目标，在ATM现金物流等应用中提高异常条件下多元时间序列预测的可靠性，在异常数据上SMAPE指标提升6.1个百分点，正常数据性能无显著下降


<details>
  <summary>Details</summary>
Motivation: 现代深度预测模型在正常数据上表现良好，但在分布偏移（异常条件）下容易失效，而可靠的异常条件下预测对ATM现金物流等应用至关重要

Method: 提出加权对比适应（WECA）方法，使用加权对比目标对齐正常和异常增强表示，保留异常相关信息的同时保持良性变化下的一致性

Result: 在全国ATM交易数据集上的评估显示，WECA相比正常训练基线在异常影响数据上SMAPE提升6.1个百分点，正常数据性能几乎无退化

Conclusion: WECA能够在保持正常操作性能的同时，显著增强异常条件下的预测可靠性

Abstract: Reliable forecasting of multivariate time series under anomalous conditions is crucial in applications such as ATM cash logistics, where sudden demand shifts can disrupt operations. Modern deep forecasters achieve high accuracy on normal data but often fail when distribution shifts occur. We propose Weighted Contrastive Adaptation (WECA), a Weighted contrastive objective that aligns normal and anomaly-augmented representations, preserving anomaly-relevant information while maintaining consistency under benign variations. Evaluations on a nationwide ATM transaction dataset with domain-informed anomaly injection show that WECA improves SMAPE on anomaly-affected data by 6.1 percentage points compared to a normally trained baseline, with negligible degradation on normal data. These results demonstrate that WECA enhances forecasting reliability under anomalies without sacrificing performance during regular operations.

</details>


### [421] [Time Series Foundation Models for Process Model Forecasting](https://arxiv.org/abs/2512.07624)
*Yongbo Yu,Jari Peeperkorn,Johannes De Smedt,Jochen De Weerdt*

Main category: cs.LG

TL;DR: 该论文研究了时间序列基础模型（TSFMs）在过程模型预测（PMF）中的应用，发现预训练的时间序列基础模型在零样本设置下优于传统方法，微调带来的改进有限，展示了TSFMs在过程相关时间序列任务中的泛化能力和数据效率。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习和深度学习方法在过程模型预测中表现有限，主要由于直接跟随关系时间序列的稀疏性和异质性。研究探索预训练的时间序列基础模型作为替代方案，以利用其从非过程领域学习的时间结构知识。

Method: 使用真实事件日志生成的直接跟随关系时间序列，比较零样本使用的时间序列基础模型与在PMF数据上微调的变体，并与传统和专门模型进行对比。

Result: 时间序列基础模型通常比传统方法获得更低的预测误差（MAE和RMSE），表明从非过程领域有效转移了时间结构知识。微调虽然能进一步提高准确性，但改进有限且在复杂数据集上可能消失。

Conclusion: 时间序列基础模型在过程模型预测中表现出良好的泛化能力和数据效率，零样本使用是强大的默认选择。这是首次系统评估时间基础模型在PMF中的应用。

Abstract: Process Model Forecasting (PMF) aims to predict how the control-flow structure of a process evolves over time by modeling the temporal dynamics of directly-follows (DF) relations, complementing predictive process monitoring that focuses on single-case prefixes. Prior benchmarks show that machine learning and deep learning models provide only modest gains over statistical baselines, mainly due to the sparsity and heterogeneity of the DF time series. We investigate Time Series Foundation Models (TSFMs), large pre-trained models for generic time series, as an alternative for PMF. Using DF time series derived from real-life event logs, we compare zero-shot use of TSFMs, without additional training, with fine-tuned variants adapted on PMF-specific data. TSFMs generally achieve lower forecasting errors (MAE and RMSE) than traditional and specialized models trained from scratch on the same logs, indicating effective transfer of temporal structure from non-process domains. While fine-tuning can further improve accuracy, the gains are often small and may disappear on smaller or more complex datasets, so zero-shot use remains a strong default. Our study highlights the generalization capability and data efficiency of TSFMs for process-related time series and, to the best of our knowledge, provides the first systematic evaluation of temporal foundation models for PMF.

</details>


### [422] [A Mathematical Theory of Top-$k$ Sparse Attention via Total Variation Distance](https://arxiv.org/abs/2512.07647)
*Georgios Tzachristas,Lei Deng,Ioannis Tzachristas,Gong Zhang,Renhai Chen*

Main category: cs.LG

TL;DR: 本文提出了一个统一的数学框架，用于认证Top-k注意力截断，量化分布和输出层面的近似误差。通过总变差距离和KL散度的关系，推导出非渐近确定性边界，并证明输出误差可以分解为头尾距离的乘积。在i.i.d.高斯评分模型下，给出了封闭形式的尾质量和最小k的选择规则。


<details>
  <summary>Details</summary>
Motivation: 现有的注意力机制计算复杂度高，Top-k截断虽然能加速计算但缺乏理论保证。本文旨在为Top-k注意力截断提供严格的数学认证框架，量化截断带来的误差。

Method: 1) 建立总变差距离与丢弃的softmax尾质量的关系；2) 推导基于有序logits的TV边界；3) 提出头尾分解方法分析输出误差；4) 在高斯评分模型下推导封闭解。

Result: 实验证明，在bert-base-uncased和合成logits上，认证Top-k可以将评分键减少2-4倍，同时满足预设的总变差预算。预测的k_ε/n缩放规律得到验证。

Conclusion: 本文为Top-k注意力截断提供了理论认证框架，证明了在控制误差的前提下可以显著加速注意力计算，为高效Transformer模型提供了理论支撑。

Abstract: We develop a unified mathematical framework for certified Top-$k$ attention truncation that quantifies approximation error at both the distribution and output levels. For a single attention distribution $P$ and its Top-$k$ truncation $\hat P$, we show that the total-variation distance coincides with the discarded softmax tail mass and satisfies $\mathrm{TV}(P,\hat P)=1-e^{-\mathrm{KL}(\hat P\Vert P)}$, yielding sharp Top-$k$-specific bounds in place of generic inequalities. From this we derive non-asymptotic deterministic bounds -- from a single boundary gap through multi-gap and blockwise variants -- that control $\mathrm{TV}(P,\hat P)$ using only the ordered logits. Using an exact head-tail decomposition, we prove that the output error factorizes as $\|\mathrm{Attn}(q,K,V)-\mathrm{Attn}_k(q,K,V)\|_2=τ\|μ_{\mathrm{tail}}-μ_{\mathrm{head}}\|_2$ with $τ=\mathrm{TV}(P,\hat P)$, yielding a new head-tail diameter bound $\|\mathrm{Attn}(q,K,V)-\mathrm{Attn}_k(q,K,V)\|_2\leτ\,\mathrm{diam}_{H,T}$ and refinements linking the error to $\mathrm{Var}_P(V)$. Under an i.i.d. Gaussian score model $s_i\sim\mathcal N(μ,σ^2)$ we derive closed-form tail masses and an asymptotic rule for the minimal $k_\varepsilon$ ensuring $\mathrm{TV}(P,\hat P)\le\varepsilon$, namely $k_\varepsilon/n\approxΦ_c(σ+Φ^{-1}(\varepsilon))$. Experiments on bert-base-uncased and synthetic logits confirm the predicted scaling of $k_\varepsilon/n$ and show that certified Top-$k$ can reduce scored keys by 2-4$\times$ on average while meeting the prescribed total-variation budget.

</details>


### [423] [Depth-Wise Activation Steering for Honest Language Models](https://arxiv.org/abs/2512.07667)
*Gracjan Góral,Marysia Winkels,Steven Basart*

Main category: cs.LG

TL;DR: 本文提出了一种无需训练的激活引导方法，通过高斯调度在神经网络深度上分配引导强度，以改善语言模型的诚实性而非准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要优化事实正确性或依赖重新训练和脆弱的单层编辑，对真实报告的控制有限。语言模型有时会在内部表示正确答案的情况下仍断言错误信息，这是诚实性而非准确性的失败。

Method: 使用高斯调度在神经网络深度上加权引导强度，该方法无需训练、模型无关且不需要微调。

Result: 在MASK基准测试中，高斯调度在七个模型中的六个模型上比无引导和单层基线提高了诚实性。在LLaMA-3.1-8B-Instruct和Qwen-2.5-7B-Instruct上的消融实验显示高斯调度优于随机、均匀和盒式滤波深度分配。

Conclusion: 该方法简单有效，为从模型现有能力中引出真实报告提供了一个低成本的控制手段，且干预在深度上的分布方式对结果有实质性影响。

Abstract: Large language models sometimes assert falsehoods despite internally representing the correct answer, failures of honesty rather than accuracy, which undermines auditability and safety. Existing approaches largely optimize factual correctness or depend on retraining and brittle single-layer edits, offering limited leverage over truthful reporting. We present a training-free activation steering method that weights steering strength across network depth using a Gaussian schedule. On the MASK benchmark, which separates honesty from knowledge, we evaluate seven models spanning the LLaMA, Qwen, and Mistral families and find that Gaussian scheduling improves honesty over no-steering and single-layer baselines in six of seven models. Equal-budget ablations on LLaMA-3.1-8B-Instruct and Qwen-2.5-7B-Instruct show the Gaussian schedule outperforms random, uniform, and box-filter depth allocations, indicating that how intervention is distributed across depth materially affects outcomes beyond total strength. The method is simple, model-agnostic, requires no finetuning, and provides a low-cost control knob for eliciting truthful reporting from models' existing capabilities.

</details>


### [424] [A Bootstrap Perspective on Stochastic Gradient Descent](https://arxiv.org/abs/2512.07676)
*Hongjian Lan,Yucong Liu,Florian Schäfer*

Main category: cs.LG

TL;DR: SGD通过利用批次采样的梯度变异性作为数据收集过程随机性的代理，隐式正则化梯度协方差矩阵的迹，从而控制算法变异性，提高泛化能力。


<details>
  <summary>Details</summary>
Motivation: 研究SGD相比确定性梯度下降在泛化能力上的优势，探讨SGD如何通过梯度变异性来模拟数据收集过程中的随机性，从而提升模型泛化性能。

Method: 通过经验风险最小化的理想化实验和理论分析，证明SGD被吸引到在重采样下稳健的参数选择，并通过数值实验在神经网络训练中验证算法变异性作为正则器的效果。

Result: SGD隐式正则化梯度协方差矩阵的迹，控制算法变异性，使解对采样噪声更不敏感，从而提高泛化性能。神经网络训练实验表明，显式加入算法变异性估计作为正则器可提升测试性能。

Conclusion: SGD的泛化优势源于其通过梯度变异性进行自助法估计，隐式正则化算法变异性，使模型避免虚假解并提高对数据采样噪声的鲁棒性。

Abstract: Machine learning models trained with \emph{stochastic} gradient descent (SGD) can generalize better than those trained with deterministic gradient descent (GD). In this work, we study SGD's impact on generalization through the lens of the statistical bootstrap: SGD uses gradient variability under batch sampling as a proxy for solution variability under the randomness of the data collection process. We use empirical results and theoretical analysis to substantiate this claim. In idealized experiments on empirical risk minimization, we show that SGD is drawn to parameter choices that are robust under resampling and thus avoids spurious solutions even if they lie in wider and deeper minima of the training loss. We prove rigorously that by implicitly regularizing the trace of the gradient covariance matrix, SGD controls the algorithmic variability. This regularization leads to solutions that are less sensitive to sampling noise, thereby improving generalization. Numerical experiments on neural network training show that explicitly incorporating the estimate of the algorithmic variability as a regularizer improves test performance. This fact supports our claim that bootstrap estimation underpins SGD's generalization advantages.

</details>


### [425] [In-Context and Few-Shots Learning for Forecasting Time Series Data based on Large Language Models](https://arxiv.org/abs/2512.07705)
*Saroj Gopali,Bipin Chhetri,Deepika Giri,Sima Siami-Namini,Akbar Siami Namin*

Main category: cs.LG

TL;DR: 本文比较了多种时间序列预测方法，发现Google的TimesFM在零样本和少样本学习中表现最佳，为实时预测提供了新方向。


<details>
  <summary>Details</summary>
Motivation: 随着预训练基础模型的发展，研究这些模型在时间序列预测中是否优于传统方法具有重要意义。

Method: 使用in-context学习、零样本和少样本学习训练LLM模型，对比TimesFM、TCN和LSTM等模型性能。

Result: TimesFM表现最佳，RMSE最低（0.3023），推理时间有竞争力（266秒）。OpenAI o4-mini在零样本学习中表现良好。

Conclusion: 预训练时间序列基础模型是实时预测的有前景方向，能够以最小模型适应实现准确和可扩展的部署。

Abstract: Existing data-driven approaches in modeling and predicting time series data include ARIMA (Autoregressive Integrated Moving Average), Transformer-based models, LSTM (Long Short-Term Memory) and TCN (Temporal Convolutional Network). These approaches, and in particular deep learning-based models such as LSTM and TCN, have shown great results in predicting time series data. With the advancement of leveraging pre-trained foundation models such as Large Language Models (LLMs) and more notably Google's recent foundation model for time series data, {\it TimesFM} (Time Series Foundation Model), it is of interest to investigate whether these foundation models have the capability of outperforming existing modeling approaches in analyzing and predicting time series data.
  This paper investigates the performance of using LLM models for time series data prediction. We investigate the in-context learning methodology in the training of LLM models that are specific to the underlying application domain. More specifically, the paper explores training LLMs through in-context, zero-shot and few-shot learning and forecasting time series data with OpenAI {\tt o4-mini} and Gemini 2.5 Flash Lite, as well as the recent Google's Transformer-based TimesFM, a time series-specific foundation model, along with two deep learning models, namely TCN and LSTM networks. The findings indicate that TimesFM has the best overall performance with the lowest RMSE value (0.3023) and the competitive inference time (266 seconds). Furthermore, OpenAI's o4-mini also exhibits a good performance based on Zero Shot learning.
  These findings highlight pre-trained time series foundation models as a promising direction for real-time forecasting, enabling accurate and scalable deployment with minimal model adaptation.

</details>


### [426] [Enabling Delayed-Full Charging Through Transformer-Based Real-Time-to-Departure Modeling for EV Battery Longevity](https://arxiv.org/abs/2512.07723)
*Yonggeon Lee,Jibin Hwang,Alfred Malengo Kondoro,Juhyun Song,Youngtae Noh*

Main category: cs.LG

TL;DR: 本文提出了一种基于Transformer的实时事件预测模型，用于准确预测电动汽车用户的出发时间，以优化充电策略并延长电池寿命。


<details>
  <summary>Details</summary>
Motivation: 电动汽车的锂离子电池在长时间高电量状态下会加速退化，通过延迟充满电至出发前可缓解此问题，但需要准确预测用户出发时间。

Method: 采用Transformer架构的实时事件预测模型，将每天的时间离散化为基于网格的token序列，利用流式上下文信息而非仅依赖历史模式来预测出发时间。

Result: 在93名用户的真实智能手机数据测试中，该方法能有效捕捉个体日常中的不规则出发模式，性能优于基线模型。

Conclusion: 该方法展示了实际部署潜力，有助于推动可持续交通系统发展。

Abstract: Electric vehicles (EVs) are key to sustainable mobility, yet their lithium-ion batteries (LIBs) degrade more rapidly under prolonged high states of charge (SOC). This can be mitigated by delaying full charging \ours until just before departure, which requires accurate prediction of user departure times. In this work, we propose Transformer-based real-time-to-event (TTE) model for accurate EV departure prediction. Our approach represents each day as a TTE sequence by discretizing time into grid-based tokens. Unlike previous methods primarily dependent on temporal dependency from historical patterns, our method leverages streaming contextual information to predict departures. Evaluation on a real-world study involving 93 users and passive smartphone data demonstrates that our method effectively captures irregular departure patterns within individual routines, outperforming baseline models. These results highlight the potential for practical deployment of the \ours algorithm and its contribution to sustainable transportation systems.

</details>


### [427] [A multimodal Bayesian Network for symptom-level depression and anxiety prediction from voice and speech data](https://arxiv.org/abs/2512.07741)
*Agnes Norbury,George Fairs,Alexandra L. Georgescu,Matthew M. Nour,Emilia Molimpakis,Stefano Goria*

Main category: cs.LG

TL;DR: 该论文提出使用贝叶斯网络建模来解决精神科评估中多模态信息整合的挑战，通过分析语音特征预测抑郁和焦虑症状，并在大规模数据集上验证了模型性能。


<details>
  <summary>Details</summary>
Motivation: 精神科评估中，临床医生需要同时观察患者的言语内容和非语言信号（如语调、语速、身体语言等），整合这些多源信息是一项挑战性任务，需要智能工具的支持。

Method: 采用贝叶斯网络模型，基于语音特征预测抑郁和焦虑症状，在包含30,135名独特说话者的大规模数据集上进行评估。

Result: 模型在抑郁和焦虑预测上表现良好（ROC-AUC分别为0.842和0.831），核心个体症状的ROC-AUC均超过0.74，同时评估了人口统计公平性和不同输入模态的整合与冗余。

Conclusion: 当提供足够丰富的大规模多模态数据流，并在症状层面而非疾病层面建模时，贝叶斯网络模型是构建稳健评估支持工具的原则性方法，能够以透明可解释的格式提供临床相关输出，便于专家临床监督。

Abstract: During psychiatric assessment, clinicians observe not only what patients report, but important nonverbal signs such as tone, speech rate, fluency, responsiveness, and body language. Weighing and integrating these different information sources is a challenging task and a good candidate for support by intelligence-driven tools - however this is yet to be realized in the clinic. Here, we argue that several important barriers to adoption can be addressed using Bayesian network modelling. To demonstrate this, we evaluate a model for depression and anxiety symptom prediction from voice and speech features in large-scale datasets (30,135 unique speakers). Alongside performance for conditions and symptoms (for depression, anxiety ROC-AUC=0.842,0.831 ECE=0.018,0.015; core individual symptom ROC-AUC>0.74), we assess demographic fairness and investigate integration across and redundancy between different input modality types. Clinical usefulness metrics and acceptability to mental health service users are explored. When provided with sufficiently rich and large-scale multimodal data streams and specified to represent common mental conditions at the symptom rather than disorder level, such models are a principled approach for building robust assessment support tools: providing clinically-relevant outputs in a transparent and explainable format that is directly amenable to expert clinical supervision.

</details>


### [428] [Formalized Hopfield Networks and Boltzmann Machines](https://arxiv.org/abs/2512.07766)
*Matteo Cipollina,Michail Karatarakis,Freek Wiedijk*

Main category: cs.LG

TL;DR: 本文提出了神经网络在Lean 4中的形式化方法，包括确定性模型（Hopfield网络）和随机模型（Boltzmann机），并证明了相关收敛性和正确性定理。


<details>
  <summary>Details</summary>
Motivation: 神经网络应用广泛但分析验证困难，需要形式化方法来确保其理论性质的正确性。

Method: 使用Lean 4定理证明器形式化神经网络模型：对Hopfield网络证明收敛性和Hebbian学习正确性；对Boltzmann机证明遍历性和平稳分布收敛性，并新形式化了Perron-Frobenius定理。

Result: 成功实现了神经网络的形式化验证：Hopfield网络在正交模式下的收敛性得到证明；Boltzmann机的遍历性和唯一平稳分布收敛性得到验证。

Conclusion: 该工作展示了定理证明器在神经网络理论分析中的有效性，为神经网络的形式化验证提供了重要基础。

Abstract: Neural networks are widely used, yet their analysis and verification remain challenging. In this work, we present a Lean 4 formalization of neural networks, covering both deterministic and stochastic models. We first formalize Hopfield networks, recurrent networks that store patterns as stable states. We prove convergence and the correctness of Hebbian learning, a training rule that updates network parameters to encode patterns, here limited to the case of pairwise-orthogonal patterns. We then consider stochastic networks, where updates are probabilistic and convergence is to a stationary distribution. As a canonical example, we formalize the dynamics of Boltzmann machines and prove their ergodicity, showing convergence to a unique stationary distribution using a new formalization of the Perron-Frobenius theorem.

</details>


### [429] [GatedFWA: Linear Flash Windowed Attention with Gated Associative Memory](https://arxiv.org/abs/2512.07782)
*Jiaxu Liu,Yuhe Bai,Christos-Savvas Bouganis*

Main category: cs.LG

TL;DR: GatedFWA是一种内存门控的滑动窗口注意力机制，在保持SWA线性效率的同时，通过可学习的衰减偏置稳定内存更新并控制梯度流动。


<details>
  <summary>Details</summary>
Motivation: 解决Softmax注意力二次复杂度问题和SWA训练目标无界的问题，同时避免内存收缩和梯度消失。

Method: 通过每个token/head的门控积累成衰减偏置添加到注意力logits中，实现可学习的记忆收缩，并开发了融合单次门预处理和FlashAttention兼容内核。

Result: 在语言建模基准测试中，GatedFWA实现了竞争性的吞吐量，具有可忽略的开销和更好的全局上下文利用能力。

Conclusion: GatedFWA成功平衡了效率与稳定性，并能与NSA等压缩方法无缝集成，适用于各种自回归领域。

Abstract: Modern autoregressive models rely on attention, yet the Softmax full attention in Transformers scales quadratically with sequence length. Sliding Window Attention (SWA) achieves linear-time encoding/decoding by constraining the attention pattern, but under an \textit{Associative Memory} interpretation, its difference-style update renders the training objective effectively \emph{unbounded}. In contrast, Softmax attention normalizes updates, leading to \emph{memory shrinkage and gradient vanishing}. We propose GatedFWA: a Memory-\underline{Gated} (\underline{F}lash) \underline{W}indowed \underline{A}ttention mechanism that preserves SWAs efficiency while stabilizing memory updates and making gradient flow controllable. In essence, GatedFWA accumulate a per-token/head gate into a decay bias added to the attention logits, acting as a learnable contraction in the memory recurrence. We implement a fused one-pass gate preprocessing and a FlashAttention-compatible kernel that injects the gate under a sliding mask, ensuring I/O efficiency and numerical stability. On language modelling benchmarks, GatedFWA delivers competitive throughput with negligible overhead and better use of global context, and it integrates cleanly with token compression/selection methods such as NSA and generalizes to various autoregressive domains.

</details>


### [430] [Group Representational Position Encoding](https://arxiv.org/abs/2512.07805)
*Yifan Zhang,Zixiang Chen,Yifeng Liu,Zhen Qin,Huizhuo Yuan,Kangping Xu,Yang Yuan,Quanquan Gu,Andrew Chi-Chih Yao*

Main category: cs.LG

TL;DR: GRAPE是一个基于群作用的统一位置编码框架，包含乘法旋转和加法logit偏差两种机制，将RoPE和ALiBi等现有方法作为特例统一起来。


<details>
  <summary>Details</summary>
Motivation: 现有位置编码方法（如RoPE、ALiBi）缺乏统一的理论框架，GRAPE旨在通过群作用理论提供一个原则性的设计空间，统一不同的位置编码机制。

Method: 基于群作用理论，提出乘法GRAPE（使用SO(d)群的旋转）和加法GRAPE（使用GL群的单能作用），分别对应旋转和加法偏差两种位置编码机制。

Result: GRAPE能够精确恢复RoPE和ALiBi等现有方法，同时通过可学习的子空间和非交换混合扩展了几何表达能力，保持了相对位置关系和流式缓存能力。

Conclusion: GRAPE提供了一个统一的理论框架，将多种位置编码方法纳入其中，为长上下文模型的位置几何设计提供了原则性指导。

Abstract: We present GRAPE (Group RepresentAtional Position Encoding), a unified framework for positional encoding based on group actions. GRAPE brings together two families of mechanisms: (i) multiplicative rotations (Multiplicative GRAPE) in $\mathrm{SO}(d)$ and (ii) additive logit biases (Additive GRAPE) arising from unipotent actions in the general linear group $\mathrm{GL}$. In Multiplicative GRAPE, a position $n \in \mathbb{Z}$ (or $t \in \mathbb{R}$) acts as $\mathbf{G}(n)=\exp(n\,ω\,\mathbf{L})$ with a rank-2 skew generator $\mathbf{L} \in \mathbb{R}^{d \times d}$, yielding a relative, compositional, norm-preserving map with a closed-form matrix exponential. RoPE is recovered exactly when the $d/2$ planes are the canonical coordinate pairs with log-uniform spectrum. Learned commuting subspaces and compact non-commuting mixtures strictly extend this geometry to capture cross-subspace feature coupling at $O(d)$ and $O(r d)$ cost per head, respectively. In Additive GRAPE, additive logits arise as rank-1 (or low-rank) unipotent actions, recovering ALiBi and the Forgetting Transformer (FoX) as exact special cases while preserving an exact relative law and streaming cacheability. Altogether, GRAPE supplies a principled design space for positional geometry in long-context models, subsuming RoPE and ALiBi as special cases. Project Page: https://github.com/model-architectures/GRAPE.

</details>


### [431] [Provable Long-Range Benefits of Next-Token Prediction](https://arxiv.org/abs/2512.07818)
*Xinyuan Cao,Santosh S. Vempala*

Main category: cs.LG

TL;DR: 本文证明了对循环神经网络进行下一词预测优化可以学习到长距离结构，实现训练分布的良好近似。


<details>
  <summary>Details</summary>
Motivation: 解释为什么现代语言模型通过下一词预测训练能够生成连贯文档并捕捉长距离结构。

Method: 使用循环神经网络进行下一词预测优化，证明该方法的理论有效性。

Result: 证明了在相同前缀下，任何有界描述长度算法都无法区分训练文档和模型生成的连续k个标记。

Conclusion: 下一词预测是学习长距离结构的有效方法，为实践中观察到的长距离连贯性提供了复杂性理论解释。

Abstract: Why do modern language models, trained to do well on next-word prediction, appear to generate coherent documents and capture long-range structure? Here we show that next-token prediction is provably powerful for learning longer-range structure, even with common neural network architectures. Specifically, we prove that optimizing next-token prediction over a Recurrent Neural Network (RNN) yields a model that closely approximates the training distribution: for held-out documents sampled from the training distribution, no algorithm of bounded description length limited to examining the next $k$ tokens, for any $k$, can distinguish between $k$ consecutive tokens of such documents and $k$ tokens generated by the learned language model following the same prefix. We provide polynomial bounds (in $k$, independent of the document length) on the model size needed to achieve such $k$-token indistinguishability, offering a complexity-theoretic explanation for the long-range coherence observed in practice.

</details>


### [432] [The Adoption and Usage of AI Agents: Early Evidence from Perplexity](https://arxiv.org/abs/2512.07828)
*Jeremy Yang,Noah Yonack,Kate Zyskowski,Denis Yarats,Johnny Ho,Jerry Ma*

Main category: cs.LG

TL;DR: 本文首次对在开放网络环境中运行的通用AI代理的采用、使用强度和使用场景进行了大规模实地研究，基于Comet浏览器的数亿用户交互数据，揭示了AI代理在不同用户群体中的异质性采用模式和使用特征。


<details>
  <summary>Details</summary>
Motivation: 随着AI代理能力的快速发展，需要了解实际用户如何采用和使用这些智能代理，以及不同用户群体的使用模式差异，为研究者、企业、政策制定者和教育工作者提供实证依据。

Method: 研究基于Perplexity开发的Comet浏览器及其集成代理Comet Assistant的数亿条匿名用户交互数据，通过分层代理分类法对使用场景进行系统分类，分析用户采用模式、使用强度和具体使用场景。

Result: 研究发现早期采用者、高GDP国家用户、知识密集型行业从业者更倾向于使用AI代理；57%的查询集中在生产力与工作流、学习与研究两大主题；55%为个人用途，30%为专业用途，16%为教育用途；使用场景具有短期粘性但长期向认知导向转变。

Conclusion: AI代理的扩散对多方利益相关者具有重要影响，需要进一步研究这一快速发展的AI能力类别，为未来的技术发展和应用提供指导。

Abstract: This paper presents the first large-scale field study of the adoption, usage intensity, and use cases of general-purpose AI agents operating in open-world web environments. Our analysis centers on Comet, an AI-powered browser developed by Perplexity, and its integrated agent, Comet Assistant. Drawing on hundreds of millions of anonymized user interactions, we address three fundamental questions: Who is using AI agents? How intensively are they using them? And what are they using them for? Our findings reveal substantial heterogeneity in adoption and usage across user segments. Earlier adopters, users in countries with higher GDP per capita and educational attainment, and individuals working in digital or knowledge-intensive sectors -- such as digital technology, academia, finance, marketing, and entrepreneurship -- are more likely to adopt or actively use the agent. To systematically characterize the substance of agent usage, we introduce a hierarchical agentic taxonomy that organizes use cases across three levels: topic, subtopic, and task. The two largest topics, Productivity & Workflow and Learning & Research, account for 57% of all agentic queries, while the two largest subtopics, Courses and Shopping for Goods, make up 22%. The top 10 out of 90 tasks represent 55% of queries. Personal use constitutes 55% of queries, while professional and educational contexts comprise 30% and 16%, respectively. In the short term, use cases exhibit strong stickiness, but over time users tend to shift toward more cognitively oriented topics. The diffusion of increasingly capable AI agents carries important implications for researchers, businesses, policymakers, and educators, inviting new lines of inquiry into this rapidly emerging class of AI capabilities.

</details>
