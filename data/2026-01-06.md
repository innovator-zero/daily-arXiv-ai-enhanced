<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 174]
- [cs.RO](#cs.RO) [Total: 31]
- [cs.LG](#cs.LG) [Total: 140]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Free Energy-Based Modeling of Emotional Dynamics in Video Advertisements](https://arxiv.org/abs/2601.00812)
*Takashi Ushio,Kazuhiro Onishi,Hideyoshi Yanagisawa*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Emotional responses during advertising video viewing are recognized as essential for understanding media effects because they have influenced attention, memory, and purchase intention. To establish a methodological basis for explainable emotion estimation without relying on external information such as physiological signals or subjective ratings, we have quantified "pleasantness," "surprise," and "habituation" solely from scene-level expression features of advertising videos, drawing on the free energy(FE) principle, which has provided a unified account of perception, learning, and behavior. In this framework, Kullback-Leibler divergence (KLD) has captured prediction error, Bayesian surprise (BS) has captured belief updates, and uncertainty (UN) has reflected prior ambiguity, and together they have formed the core components of FE. Using 1,059 15 s food video advertisements, the experiments have shown that KLD has reflected "pleasantness" associated with brand presentation, BS has captured "surprise" arising from informational complexity, and UN has reflected "surprise" driven by uncertainty in element types and spatial arrangements, as well as by the variability and quantity of presented elements. This study also identified three characteristic emotional patterns, namely uncertain stimulus, sustained high emotion, and momentary peak and decay, demonstrating the usefulness of the proposed method. Robustness across nine hyperparameter settings and generalization tests with six types of Japanese advertising videos (three genres and two durations) confirmed that these tendencies remained stable. This work can be extended by integrating a wider range of expression elements and validating the approach through subjective ratings, ultimately guiding the development of technologies that can support the creation of more engaging advertising videos.

</details>


### [2] [Can Generative Models Actually Forge Realistic Identity Documents?](https://arxiv.org/abs/2601.00829)
*Alexander Vinogradov*

Main category: cs.CV

TL;DR: 本文评估了当前开源扩散模型生成身份证件伪造品的真实性，发现虽然能模拟表面美学特征，但无法达到结构性和法证层面的真实性。


<details>
  <summary>Details</summary>
Motivation: 随着生成图像模型在图像真实感方面的显著进步，公众担忧其可能被滥用于证件伪造。本文旨在研究当代扩散模型是否能生成足以通过人工或自动验证系统的身份证件伪造品。

Method: 使用多种公开可用的生成模型家族（包括Stable Diffusion、Qwen、Flux、Nano-Banana等），评估文本到图像和图像到图像的生成流程。

Result: 当前生成模型能够模拟证件表面层的美学特征，但无法复制结构性和法证层面的真实性。

Conclusion: 生成式身份证件深度伪造达到法证级真实性的风险可能被高估，强调了机器学习从业者与证件法证专家在现实风险评估中合作的价值。

Abstract: Generative image models have recently shown significant progress in image realism, leading to public concerns about their potential misuse for document forgery. This paper explores whether contemporary open-source and publicly accessible diffusion-based generative models can produce identity document forgeries that could realistically bypass human or automated verification systems. We evaluate text-to-image and image-to-image generation pipelines using multiple publicly available generative model families, including Stable Diffusion, Qwen, Flux, Nano-Banana, and others. The findings indicate that while current generative models can simulate surface-level document aesthetics, they fail to reproduce structural and forensic authenticity. Consequently, the risk of generative identity document deepfakes achieving forensic-level authenticity may be overestimated, underscoring the value of collaboration between machine learning practitioners and document-forensics experts in realistic risk assessment.

</details>


### [3] [Pediatric Pneumonia Detection from Chest X-Rays:A Comparative Study of Transfer Learning and Custom CNNs](https://arxiv.org/abs/2601.00837)
*Agniv Roy Choudhury*

Main category: cs.CV

TL;DR: 该研究比较了从零开始训练的CNN与迁移学习模型在儿科肺炎检测中的性能，发现微调后的ResNet50模型达到近乎完美的准确率（99.43%），显著优于从头训练的模型。


<details>
  <summary>Details</summary>
Motivation: 肺炎是五岁以下儿童的主要死因，每年导致超过70万人死亡。由于放射科医生资源有限且诊断存在主观差异，需要开发自动化的准确诊断工具。

Method: 使用5,216张儿科胸部X光片数据集，比较了从零训练的CNN与三种迁移学习模型（ResNet50、DenseNet121、EfficientNet-B0）在冻结主干和微调两种策略下的性能，使用准确率、F1分数和AUC进行评估，并通过Grad-CAM提供可解释性。

Result: 微调后的ResNet50表现最佳：准确率99.43%、F1分数99.61%、AUC 99.93%，仅3例误分类。微调模型平均比冻结主干模型高5.5个百分点。Grad-CAM确认模型关注临床相关肺区域。

Conclusion: 迁移学习结合微调在儿科肺炎检测中显著优于从头训练的CNN，显示出近乎完美的准确率，在资源有限环境中具有强大筛查潜力。未来需要在多中心和成人数据集上验证这些发现。

Abstract: Pneumonia is a leading cause of mortality in children under five, with over 700,000 deaths annually. Accurate diagnosis from chest X-rays is limited by radiologist availability and variability.
  Objective: This study compares custom CNNs trained from scratch with transfer learning (ResNet50, DenseNet121, EfficientNet-B0) for pediatric pneumonia detection, evaluating frozen-backbone and fine-tuning regimes.
  Methods: A dataset of 5,216 pediatric chest X-rays was split 80/10/10 for training, validation, and testing. Seven models were trained and assessed using accuracy, F1-score, and AUC. Grad-CAM visualizations provided explainability.
  Results: Fine-tuned ResNet50 achieved the best performance: 99.43\% accuracy, 99.61\% F1-score, and 99.93\% AUC, with only 3 misclassifications. Fine-tuning outperformed frozen-backbone models by 5.5 percentage points on average. Grad-CAM confirmed clinically relevant lung regions guided predictions.
  Conclusions: Transfer learning with fine-tuning substantially outperforms CNNs trained from scratch for pediatric pneumonia detection, showing near-perfect accuracy. This system has strong potential as a screening tool in resource-limited settings. Future work should validate these findings on multi-center and adult datasets.
  Keywords: Pneumonia detection, deep learning, transfer learning, CNN, chest X-ray, pediatric diagnosis, ResNet, DenseNet, EfficientNet, Grad-CAM.

</details>


### [4] [Unified Review and Benchmark of Deep Segmentation Architectures for Cardiac Ultrasound on CAMUS](https://arxiv.org/abs/2601.00839)
*Zahid Ullah,Muhammad Hilal,Eunsoo Lee,Dragan Pamucar,Jihie Kim*

Main category: cs.CV

TL;DR: 本研究通过标准化实验基准比较了U-Net、Attention U-Net和TransUNet三种架构在心脏超声分割任务上的性能，重点关注数据预处理方法和自监督学习对模型效果的影响。


<details>
  <summary>Details</summary>
Motivation: 现有文献缺乏对心脏影像分割方法的统一可复现实验基准，本研究旨在填补这一空白，为不同架构提供公平比较。

Method: 使用CAMUS心脏超声数据集，在相同训练分割、损失函数和评估标准下，比较三种架构在不同预处理方式（NIfTI原始数据、PNG导出、GPT辅助伪标签、自监督预训练）下的表现。

Result: U-Net在NIfTI数据上达到94%平均Dice分数，PNG格式为91%；Attention U-Net在小区域和低对比度区域表现更好；TransUNet在挑战性帧上泛化能力最强，特别是结合自监督预训练时。

Conclusion: 研究提供了三种架构的标准化基准比较，提出了保持超声数据强度保真度和分辨率一致性的实用指南，并展望了自监督学习和GPT辅助标注的未来发展方向。

Abstract: Several review papers summarize cardiac imaging and DL advances, few works connect this overview to a unified and reproducible experimental benchmark. In this study, we combine a focused review of cardiac ultrasound segmentation literature with a controlled comparison of three influential architectures, U-Net, Attention U-Net, and TransUNet, on the Cardiac Acquisitions for Multi-Structure Ultrasound Segmentation (CAMUS) echocardiography dataset. Our benchmark spans multiple preprocessing routes, including native NIfTI volumes, 16-bit PNG exports, GPT-assisted polygon-based pseudo-labels, and self-supervised pretraining (SSL) on thousands of unlabeled cine frames. Using identical training splits, losses, and evaluation criteria, a plain U-Net achieved a 94% mean Dice when trained directly on NIfTI data (preserving native dynamic range), while the PNG-16-bit workflow reached 91% under similar conditions. Attention U-Net provided modest improvements on small or low-contrast regions, reducing boundary leakage, whereas TransUNet demonstrated the strongest generalization on challenging frames due to its ability to model global spatial context, particularly when initialized with SSL. Pseudo-labeling expanded the training set and improved robustness after confidence filtering. Overall, our contributions are threefold: a harmonized, apples-to-apples benchmark of U-Net, Attention U-Net, and TransUNet under standardized CAMUS preprocessing and evaluation; practical guidance on maintaining intensity fidelity, resolution consistency, and alignment when preparing ultrasound data; and an outlook on scalable self-supervision and emerging multimodal GPT-based annotation pipelines for rapid labeling, quality assurance, and targeted dataset curation.

</details>


### [5] [Motion-Compensated Latent Semantic Canvases for Visual Situational Awareness on Edge](https://arxiv.org/abs/2601.00854)
*Igor Lodin,Sergii Filatov,Vira Filatova,Dmytro Filatov*

Main category: cs.CV

TL;DR: MCLSC是一种用于资源受限边缘设备的视觉情境感知方法，通过维护两个潜在画布（静态层和动态层）来减少语义分割调用次数，显著降低处理时间。


<details>
  <summary>Details</summary>
Motivation: 解决在资源受限的边缘设备上进行实时视觉情境感知时，传统逐帧语义分割计算成本过高的问题。

Method: 使用两个潜在语义画布（缓慢积累的静态层和快速更新的动态层），在稳定坐标系中维护持久语义元数据，通过运动门控机制异步触发昂贵的全景分割（Mask2Former）。

Result: 在480p视频上，相比逐帧分割方法，分割调用次数减少30倍以上，端到端平均处理时间降低20倍以上，同时保持连贯的静态/动态语义覆盖。

Conclusion: MCLSC方法在显著降低计算成本的同时，能够有效维持视觉情境感知的语义一致性，适用于资源受限的边缘设备。

Abstract: We propose Motion-Compensated Latent Semantic Canvases (MCLSC) for visual situational awareness on resource-constrained edge devices. The core idea is to maintain persistent semantic metadata in two latent canvases - a slowly accumulating static layer and a rapidly updating dynamic layer - defined in a baseline coordinate frame stabilized from the video stream. Expensive panoptic segmentation (Mask2Former) runs asynchronously and is motion-gated: inference is triggered only when motion indicates new information, while stabilization/motion compensation preserves a consistent coordinate system for latent semantic memory. On prerecorded 480p clips, our prototype reduces segmentation calls by >30x and lowers mean end-to-end processing time by >20x compared to naive per-frame segmentation, while maintaining coherent static/dynamic semantic overlays.

</details>


### [6] [VL-OrdinalFormer: Vision Language Guided Ordinal Transformers for Interpretable Knee Osteoarthritis Grading](https://arxiv.org/abs/2601.00879)
*Zahid Ullah,Jihie Kim*

Main category: cs.CV

TL;DR: VLOrdinalFormer是一个结合视觉语言和序数学习的框架，用于膝关节骨关节炎的自动分级，在KL1和KL2早期阶段表现优异，达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 膝关节骨关节炎是全球致残的主要原因，KL1和KL2早期疾病阶段的放射学区分细微，常导致放射科医生之间的观察者间变异性。

Method: 结合ViT L16骨干网络、CORAL序数回归和CLIP驱动的语义对齐模块，采用分层五折交叉验证、类别感知重加权和测试时增强。

Result: 在OAI kneeKL224数据集上实现最先进性能，KL1和KL2阶段表现显著提升，同时保持轻度和重度病例的分类准确性。

Conclusion: 视觉语言对齐的序数变换器有望成为KOA分级和疾病进展评估的可靠、可解释工具。

Abstract: Knee osteoarthritis (KOA) is a leading cause of disability worldwide, and accurate severity assessment using the Kellgren Lawrence (KL) grading system is critical for clinical decision making. However, radiographic distinctions between early disease stages, particularly KL1 and KL2, are subtle and frequently lead to inter-observer variability among radiologists. To address these challenges, we propose VLOrdinalFormer, a vision language guided ordinal learning framework for fully automated KOA grading from knee radiographs. The proposed method combines a ViT L16 backbone with CORAL based ordinal regression and a Contrastive Language Image Pretraining (CLIP) driven semantic alignment module, allowing the model to incorporate clinically meaningful textual concepts related to joint space narrowing, osteophyte formation, and subchondral sclerosis. To improve robustness and mitigate overfitting, we employ stratified five fold cross validation, class aware re weighting to emphasize challenging intermediate grades, and test time augmentation with global threshold optimization. Experiments conducted on the publicly available OAI kneeKL224 dataset demonstrate that VLOrdinalFormer achieves state of the art performance, outperforming CNN and ViT baselines in terms of macro F1 score and overall accuracy. Notably, the proposed framework yields substantial performance gains for KL1 and KL2 without compromising classification accuracy for mild or severe cases. In addition, interpretability analyses using Grad CAM and CLIP similarity maps confirm that the model consistently attends to clinically relevant anatomical regions. These results highlight the potential of vision language aligned ordinal transformers as reliable and interpretable tools for KOA grading and disease progression assessment in routine radiological practice.

</details>


### [7] [VideoCuRL: Video Curriculum Reinforcement Learning with Orthogonal Difficulty Decomposition](https://arxiv.org/abs/2601.00887)
*Hongbo Jin,Kuanwei Lin,Wenhao Zhang,Yichen Jin,Ge Li*

Main category: cs.CV

TL;DR: VideoCuRL是一种新颖的强化学习框架，通过将视频理解难度分解为视觉时间感知负载和认知推理深度两个维度，使用光学流、关键帧熵和校准惊讶度等训练无关代理来构建二维课程网格，并通过对角线波前策略进行训练调度，显著提升了视频语言模型的推理和感知性能。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习范式主要依赖随机数据洗牌或基于标量难度指标的简单课程策略，但标量指标无法区分视频理解中的两个正交挑战：视觉时间感知负载和认知推理深度。

Method: 提出VideoCuRL框架，将难度分解为两个轴：使用光学流和关键帧熵评估视觉复杂度，使用校准惊讶度评估认知复杂度，构建二维课程网格；采用能力感知对角线波前策略进行训练调度；引入动态稀疏KL和结构化重访来稳定训练。

Result: 在VSI-Bench上推理任务提升2.5分，在VideoMME上感知任务提升2.9分，显著优于强RL基线，同时消除了基于生成的课程方法的高昂推理开销。

Conclusion: VideoCuRL为稳健的视频后训练提供了一个可扩展的解决方案，通过二维难度分解和高效的课程调度策略，有效提升了视频语言模型的性能。

Abstract: Reinforcement Learning (RL) is crucial for empowering VideoLLMs with complex spatiotemporal reasoning. However, current RL paradigms predominantly rely on random data shuffling or naive curriculum strategies based on scalar difficulty metrics. We argue that scalar metrics fail to disentangle two orthogonal challenges in video understanding: Visual Temporal Perception Load and Cognitive Reasoning Depth. To address this, we propose VideoCuRL, a novel framework that decomposes difficulty into these two axes. We employ efficient, training-free proxies, optical flow and keyframe entropy for visual complexity, Calibrated Surprisal for cognitive complexity, to map data onto a 2D curriculum grid. A competence aware Diagonal Wavefront strategy then schedules training from base alignment to complex reasoning. Furthermore, we introduce Dynamic Sparse KL and Structured Revisiting to stabilize training against reward collapse and catastrophic forgetting. Extensive experiments show that VideoCuRL surpasses strong RL baselines on reasoning (+2.5 on VSI-Bench) and perception (+2.9 on VideoMME) tasks. Notably, VideoCuRL eliminates the prohibitive inference overhead of generation-based curricula, offering a scalable solution for robust video post-training.

</details>


### [8] [Comparative Evaluation of CNN Architectures for Neural Style Transfer in Indonesian Batik Motif Generation: A Comprehensive Study](https://arxiv.org/abs/2601.00888)
*Happy Gery Pangestu,Andi Prademon Yunus,Siti Khomsah*

Main category: cs.CV

TL;DR: 该研究对五种CNN主干网络在神经风格迁移中的表现进行了系统比较分析，发现ResNet架构在保持结构相似性的同时，计算效率比VGG高出16倍以上，更适合资源受限环境下的印尼蜡染图案生成。


<details>
  <summary>Details</summary>
Motivation: 现有神经风格迁移方法主要基于VGG架构，虽然风格表达力强但计算和内存需求高，限制了在资源受限环境中的实际部署。本研究旨在寻找更高效的架构来平衡结构保持、风格质量和计算效率。

Method: 通过245个对照实验，系统比较了VGG16、VGG19、Inception V3、ResNet50和ResNet101五种CNN主干网络，结合定量指标、定性评估和统计分析，考察结构保持、风格行为和计算效率之间的权衡。

Result: 主干网络选择在结构相似性上没有显著差异(ANOVA p=0.83)，但ResNet架构收敛速度比VGG快5-6倍，FLOPs减少16倍以上(0.63 vs 10.12 GFLOPs)，同时保持相似的感知相似性(LPIPS=0.53)。VGG产生更密集的绘画纹理，ResNet更注重几何稳定性和笔触保持。

Conclusion: 研究将NST中的架构选择从最大化风格强度重新定位为效率感知和结构保持部署，强调ResNet主干网络作为可扩展、面向行业的蜡染生成的实际基础。

Abstract: Neural Style Transfer (NST) provides a computational framework for the digital preservation and generative exploration of Indonesian batik motifs; however, existing approaches remain largely centered on VGG-based architectures whose strong stylistic expressiveness comes at the cost of high computational and memory demands, that limits practical deployment in resource-limited environments. This study presents a systematic comparative analysis of five widely used CNN backbones, namely VGG16, VGG19, Inception V3, ResNet50, and ResNet101, based on 245 controlled experiments combining quantitative metrics, qualitative assessment, and statistical analysis to examine the trade-off between structural preservation, stylistic behavior, and computational efficiency. The results show that backbone selection does not yield statistically significant differences in structural similarity, as confirmed by ANOVA on SSIM (p= 0.83), indicating comparable levels of structural preservation rather than equivalent stylistic quality. Within this context, ResNet-based architectures achieve approximately 5-6x faster convergence than VGG models while maintaining similar perceptual similarity (LPIPS = 0.53) and requiring over 16x fewer FLOPs (0.63 vs 10.12 GFLOPs). Qualitative analysis reveals consistent stylistic trade-offs, with VGG producing denser painterly textures, ResNet favoring geometric stability and canting stroke preservation with milder stylization, and Inception V3 exhibiting intermediate but noisier behavior. These findings reposition architectural choice in NST from maximizing stylistic intensity toward efficiency-aware and structure-preserving deployment, highlighting ResNet-based backbones as a practical foundation for scalable, industry-oriented batik generation.

</details>


### [9] [CornViT: A Multi-Stage Convolutional Vision Transformer Framework for Hierarchical Corn Kernel Analysis](https://arxiv.org/abs/2601.00897)
*Sai Teja Erukude,Jane Mascarenhas,Lior Shamir*

Main category: cs.CV

TL;DR: CornViT是一个三阶段卷积视觉Transformer框架，用于自动化玉米籽粒分级，模拟人类分析师的层次推理过程，在纯度、形态和胚芽方向检测任务上达到93.76%、94.11%和91.12%的准确率。


<details>
  <summary>Details</summary>
Motivation: 当前玉米籽粒分级主要依赖人工检查，效率低下且主观性强，需要开发自动化解决方案来支持种子认证、定向播种和育种工作。

Method: 使用三阶段CvT-13分类器：第一阶段区分纯籽粒与不纯籽粒；第二阶段将纯籽粒分为扁平形和圆形；第三阶段确定纯扁平籽粒的胚芽方向（上或下）。基于ImageNet-22k预训练模型进行头部分微调。

Result: CornViT在三个任务上的测试准确率分别为93.76%（纯度）、94.11%（形态）和91.12%（胚芽方向），显著优于ResNet-50（76.56-81.02%）和DenseNet-121（86.56-89.38%）。

Conclusion: 卷积增强的自注意力机制在籽粒分析中具有优势，CornViT框架、精选数据集和Web应用为种子质量工作流程提供了可部署的自动化玉米籽粒质量评估解决方案。

Abstract: Accurate grading of corn kernels is critical for seed certification, directional seeding, and breeding, yet it is still predominantly performed by manual inspection. This work introduces CornViT, a three-stage Convolutional Vision Transformer (CvT) framework that emulates the hierarchical reasoning of human seed analysts for single-kernel evaluation. Three sequential CvT-13 classifiers operate on 384x384 RGB images: Stage 1 distinguishes pure from impure kernels; Stage 2 categorizes pure kernels into flat and round morphologies; and Stage 3 determines the embryo orientation (up vs. down) for pure, flat kernels. Starting from a public corn seed image collection, we manually relabeled and filtered images to construct three stage-specific datasets: 7265 kernels for purity, 3859 pure kernels for morphology, and 1960 pure-flat kernels for embryo orientation, all released as benchmarks. Head-only fine-tuning of ImageNet-22k pretrained CvT-13 backbones yields test accuracies of 93.76% for purity, 94.11% for shape, and 91.12% for embryo-orientation detection. Under identical training conditions, ResNet-50 reaches only 76.56 to 81.02 percent, whereas DenseNet-121 attains 86.56 to 89.38 percent accuracy. These results highlight the advantages of convolution-augmented self-attention for kernel analysis. To facilitate adoption, we deploy CornViT in a Flask-based web application that performs stage-wise inference and exposes interpretable outputs through a browser interface. Together, the CornViT framework, curated datasets, and web application provide a deployable solution for automated corn kernel quality assessment in seed quality workflows. Source code and data are publicly available.

</details>


### [10] [Evaluating Contextual Intelligence in Recyclability: A Comprehensive Study of Image-Based Reasoning Systems](https://arxiv.org/abs/2601.00905)
*Eliot Park,Abhi Kumar,Pranav Rajpurkar*

Main category: cs.CV

TL;DR: 本研究探索了使用先进视觉语言模型（GPT-4o、GPT-4o-mini和Claude 3.5）来预测常见废弃物的可回收性，包括物品与回收箱的匹配和物理适配性评估。


<details>
  <summary>Details</summary>
Motivation: 虽然高效回收的重要性被广泛认可，但公众准确判断物品的可回收性和正确处理方式仍然是一个复杂任务。

Method: 使用精心策划的图像数据集评估模型在多个挑战性场景下的表现：基于地区特定回收指南调整预测、考虑污染或结构损坏、处理多材料物品。

Result: 研究结果表明这些模型在上下文理解方面相比先前版本有显著进步，但也发现了它们仍存在的不足。

Conclusion: 持续改进上下文感知模型对于提升公众回收实践和推进环境可持续性至关重要。

Abstract: While the importance of efficient recycling is widely acknowledged, accurately determining the recyclability of items and their proper disposal remains a complex task for the general public. In this study, we explore the application of cutting-edge vision-language models (GPT-4o, GPT-4o-mini, and Claude 3.5) for predicting the recyclability of commonly disposed items. Utilizing a curated dataset of images, we evaluated the models' ability to match objects to appropriate recycling bins, including assessing whether the items could physically fit into the available bins. Additionally, we investigated the models' performance across several challenging scenarios: (i) adjusting predictions based on location-specific recycling guidelines; (ii) accounting for contamination or structural damage; and (iii) handling objects composed of multiple materials. Our findings highlight the significant advancements in contextual understanding offered by these models compared to previous iterations, while also identifying areas where they still fall short. The continued refinement of context-aware models is crucial for enhancing public recycling practices and advancing environmental sustainability.

</details>


### [11] [Clean-GS: Semantic Mask-Guided Pruning for 3D Gaussian Splatting](https://arxiv.org/abs/2601.00913)
*Subhankar Mishra*

Main category: cs.CV

TL;DR: Clean-GS是一种去除3D高斯泼溅中背景杂波和漂浮物的方法，使用稀疏语义掩码实现60-80%的模型压缩，同时保持目标对象质量。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅会产生大量虚假高斯分布（漂浮物），这些伪影会遮挡目标对象并增加模型大小，阻碍在带宽受限应用中的部署。

Method: 结合白名单空间过滤、颜色引导验证和离群点去除的多阶段方法：1）通过投影到掩码区域进行白名单过滤；2）深度缓冲颜色验证；3）基于邻居的离群点去除。

Result: 在Tanks and Temples数据集上的实验显示，Clean-GS将文件大小从125MB减少到47MB，同时保持渲染质量。

Conclusion: 该方法使3DGS模型适用于Web部署和AR/VR应用，仅需3个分割掩码（1%的视图）即可识别和移除不属于目标对象的高斯分布。

Abstract: 3D Gaussian Splatting produces high-quality scene reconstructions but generates hundreds of thousands of spurious Gaussians (floaters) scattered throughout the environment. These artifacts obscure objects of interest and inflate model sizes, hindering deployment in bandwidth-constrained applications. We present Clean-GS, a method for removing background clutter and floaters from 3DGS reconstructions using sparse semantic masks. Our approach combines whitelist-based spatial filtering with color-guided validation and outlier removal to achieve 60-80\% model compression while preserving object quality. Unlike existing 3DGS pruning methods that rely on global importance metrics, Clean-GS uses semantic information from as few as 3 segmentation masks (1\% of views) to identify and remove Gaussians not belonging to the target object. Our multi-stage approach consisting of (1) whitelist filtering via projection to masked regions, (2) depth-buffered color validation, and (3) neighbor-based outlier removal isolates monuments and objects from complex outdoor scenes. Experiments on Tanks and Temples show that Clean-GS reduces file sizes from 125MB to 47MB while maintaining rendering quality, making 3DGS models practical for web deployment and AR/VR applications. Our code is available at https://github.com/smlab-niser/clean-gs

</details>


### [12] [Four-Stage Alzheimer's Disease Classification from MRI Using Topological Feature Extraction, Feature Selection, and Ensemble Learning](https://arxiv.org/abs/2601.00918)
*Faisal Ahmed*

Main category: cs.CV

TL;DR: TDA-Alz是一个基于拓扑数据分析（TDA）和集成学习的轻量级框架，用于阿尔茨海默病严重程度的四阶段分类，在OASIS-1数据集上达到98.19%的准确率和99.75%的AUC，优于深度学习方法且具有更好的可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的阿尔茨海默病严重程度分类方法面临数据需求大、计算资源消耗高和模型可解释性差的问题，需要一种更高效、可解释的替代方案。

Method: 使用拓扑数据分析提取脑部MRI图像的内在结构模式描述符，通过特征选择保留最具判别性的拓扑特征，然后采用集成学习策略进行多类别分类。

Result: 在OASIS-1 MRI数据集上的实验显示，该方法达到98.19%的准确率和99.75%的AUC，优于或匹配现有最先进的深度学习方法，且无需数据增强、预训练网络或大规模计算资源。

Conclusion: TDA-Alz为基于MRI的阿尔茨海默病严重程度分类提供了一个强大、轻量级且可解释的深度学习替代方案，具有在现实世界临床决策支持系统中应用的潜力。

Abstract: Accurate and efficient classification of Alzheimer's disease (AD) severity from brain magnetic resonance imaging (MRI) remains a critical challenge, particularly when limited data and model interpretability are of concern. In this work, we propose TDA-Alz, a novel framework for four-stage Alzheimer's disease severity classification (non-demented, moderate dementia, mild, and very mild) using topological data analysis (TDA) and ensemble learning. Instead of relying on deep convolutional architectures or extensive data augmentation, our approach extracts topological descriptors that capture intrinsic structural patterns of brain MRI, followed by feature selection to retain the most discriminative topological features. These features are then classified using an ensemble learning strategy to achieve robust multiclass discrimination.
  Experiments conducted on the OASIS-1 MRI dataset demonstrate that the proposed method achieves an accuracy of 98.19% and an AUC of 99.75%, outperforming or matching state-of-the-art deep learning--based methods reported on OASIS and OASIS-derived datasets. Notably, the proposed framework does not require data augmentation, pretrained networks, or large-scale computational resources, making it computationally efficient and fast compared to deep neural network approaches. Furthermore, the use of topological descriptors provides greater interpretability, as the extracted features are directly linked to the underlying structural characteristics of brain MRI rather than opaque latent representations. These results indicate that TDA-Alz offers a powerful, lightweight, and interpretable alternative to deep learning models for MRI-based Alzheimer's disease severity classification, with strong potential for real-world clinical decision-support systems.

</details>


### [13] [Application of deep learning techniques in non-contrast computed tomography pulmonary angiogram for pulmonary embolism diagnosis](https://arxiv.org/abs/2601.00925)
*I-Hsien Ting,Yi-Jun Tseng,Yu-Sheng Lin*

Main category: cs.CV

TL;DR: 本研究使用3D卷积神经网络模型，在无造影剂CT图像中自动分类肺栓塞，实现了85%的准确率和0.84的AUC值，证明了无造影剂诊断肺栓塞的可行性。


<details>
  <summary>Details</summary>
Motivation: 传统使用造影剂的CT肺动脉造影可能对慢性肾病患者造成急性肾损伤，且造影剂需要时间生效，可能延误急性肺栓塞患者的黄金治疗时间。

Method: 采用3D卷积神经网络模型对无造影剂的CT图像进行肺栓塞自动分类。

Result: 深度学习模型在无造影剂CT图像的肺栓塞分类中表现显著，准确率达到85%，AUC值为0.84。

Conclusion: 该研究证实了深度学习模型在无造影剂CT图像中诊断肺栓塞的可行性，为减少造影剂相关风险提供了新途径。

Abstract: Pulmonary embolism is a life-threatening disease, early detection and treatment can significantly reduce mortality. In recent years, many studies have been using deep learning in the diagnosis of pulmonary embolism with contrast medium computed tomography pulmonary angiography, but the contrast medium is likely to cause acute kidney injury in patients with pulmonary embolism and chronic kidney disease, and the contrast medium takes time to work, patients with acute pulmonary embolism may miss the golden treatment time.
  This study aims to use deep learning techniques to automatically classify pulmonary embolism in CT images without contrast medium by using a 3D convolutional neural network model. The deep learning model used in this study had a significant impact on the pulmonary embolism classification of computed tomography images without contrast with 85\% accuracy and 0.84 AUC, which confirms the feasibility of the model in the diagnosis of pulmonary embolism.

</details>


### [14] [Analyzing the Shopping Journey: Computing Shelf Browsing Visits in a Physical Retail Store](https://arxiv.org/abs/2601.00928)
*Luis Yoichi Morales,Francesco Zanlungo,David M. Woollard*

Main category: cs.CV

TL;DR: 该研究提出了一种算法来计算购物者的"货架访问"行为，用于分析实体店中的顾客浏览意图，并通过在不同商店收集的数据进行校准和验证。


<details>
  <summary>Details</summary>
Motivation: 由于机器人技术在零售业客户服务角色中的部署面临挑战，需要开发能够自主理解购物者意图的系统。

Method: 使用基于机器视觉的3D跟踪和顶置摄像头获取顾客轨迹，开发算法提取"货架访问"行为，并在两个不同商店收集的数据集（8138条和15129条轨迹）上进行校准。

Result: 算法能够在与校准环境不同的商店中有效识别顾客浏览活动，并分析了浏览模式与实际购买行为的关系。

Conclusion: 货架浏览信息可用于零售规划和人机交互场景，为零售业提供有价值的顾客行为分析工具。

Abstract: Motivated by recent challenges in the deployment of robots into customer-facing roles within retail, this work introduces a study of customer activity in physical stores as a step toward autonomous understanding of shopper intent. We introduce an algorithm that computes shoppers' ``shelf visits'' -- capturing their browsing behavior in the store. Shelf visits are extracted from trajectories obtained via machine vision-based 3D tracking and overhead cameras. We perform two independent calibrations of the shelf visit algorithm, using distinct sets of trajectories (consisting of 8138 and 15129 trajectories), collected in different stores and labeled by human reviewers. The calibrated models are then evaluated on trajectories held out of the calibration process both from the same store on which calibration was performed and from the other store. An analysis of the results shows that the algorithm can recognize customers' browsing activity when evaluated in an environment different from the one on which calibration was performed. We then use the model to analyze the customers' ``browsing patterns'' on a large set of trajectories and their relation to actual purchases in the stores. Finally, we discuss how shelf browsing information could be used for retail planning and in the domain of human-robot interaction scenarios.

</details>


### [15] [ShadowGS: Shadow-Aware 3D Gaussian Splatting for Satellite Imagery](https://arxiv.org/abs/2601.00939)
*Feng Luo,Hongbo Pan,Xiang Yang,Baoyu Jiang,Fengqing Liu,Tao Huang*

Main category: cs.CV

TL;DR: 提出ShadowGS框架，基于3D高斯泼溅技术，通过物理渲染方程和光线行进技术解决多时相卫星图像中阴影不一致问题，提升3D重建精度和阴影解耦效果


<details>
  <summary>Details</summary>
Motivation: 多时相卫星图像中由于光照条件变化导致的阴影不一致问题严重影响3D重建质量，需要开发能够精确建模几何一致阴影的方法

Method: 基于3DGS框架，结合遥感物理渲染方程和高效光线行进技术，引入阴影一致性约束和阴影图先验，有效解耦光照分量和表观属性

Result: 在阴影解耦精度、3D重建精度和新视角合成质量方面优于现有方法，仅需几分钟训练时间，在RGB、全色锐化和稀疏视图卫星输入中表现稳健

Conclusion: ShadowGS框架成功解决了多时相卫星图像的阴影建模问题，为卫星图像3D重建提供了高效准确的解决方案

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a novel paradigm for 3D reconstruction from satellite imagery. However, in multi-temporal satellite images, prevalent shadows exhibit significant inconsistencies due to varying illumination conditions. To address this, we propose ShadowGS, a novel framework based on 3DGS. It leverages a physics-based rendering equation from remote sensing, combined with an efficient ray marching technique, to precisely model geometrically consistent shadows while maintaining efficient rendering. Additionally, it effectively disentangles different illumination components and apparent attributes in the scene. Furthermore, we introduce a shadow consistency constraint that significantly enhances the geometric accuracy of 3D reconstruction. We also incorporate a novel shadow map prior to improve performance with sparse-view inputs. Extensive experiments demonstrate that ShadowGS outperforms current state-of-the-art methods in shadow decoupling accuracy, 3D reconstruction precision, and novel view synthesis quality, with only a few minutes of training. ShadowGS exhibits robust performance across various settings, including RGB, pansharpened, and sparse-view satellite inputs.

</details>


### [16] [Learning to Segment Liquids in Real-world Images](https://arxiv.org/abs/2601.00940)
*Jonas Li,Michelle Li,Luke Liu,Heng Fan*

Main category: cs.CV

TL;DR: 本文提出了一个用于液体分割的大规模数据集LQDS和一种新颖的液体检测模型LQDM，通过边界分支与主分割分支的交叉注意力机制提升分割性能。


<details>
  <summary>Details</summary>
Motivation: 液体在日常生活中广泛存在，但现有研究对液体分割任务关注不足，限制了机器人安全避让或与液体交互的能力。液体分割的挑战在于液体外观多样、形状多变，且具有透明或反射特性。

Method: 构建包含5000张真实世界图像、标注为14个类别的LQDS数据集；设计LQDM模型，利用专用边界分支与主分割分支之间的交叉注意力机制来增强分割预测。

Result: 在LQDS测试集上的大量实验证明LQDM的有效性，其性能优于现有最先进方法，为液体语义分割建立了强基线。

Conclusion: 该研究通过构建大规模数据集和创新模型设计，成功解决了液体分割的挑战，为机器人安全操作提供了重要技术支撑。

Abstract: Different types of liquids such as water, wine and medicine appear in all aspects of daily life. However, limited attention has been given to the task, hindering the ability of robots to avoid or interact with liquids safely. The segmentation of liquids is difficult because liquids come in diverse appearances and shapes; moreover, they can be both transparent or reflective, taking on arbitrary objects and scenes from the background or surroundings. To take on this challenge, we construct a large-scale dataset of liquids named LQDS consisting of 5000 real-world images annotated into 14 distinct classes, and design a novel liquid detection model named LQDM, which leverages cross-attention between a dedicated boundary branch and the main segmentation branch to enhance segmentation predictions. Extensive experiments demonstrate the effectiveness of LQDM on the test set of LQDS, outperforming state-of-the-art methods and establishing a strong baseline for the semantic segmentation of liquids.

</details>


### [17] [PhyEduVideo: A Benchmark for Evaluating Text-to-Video Models for Physics Education](https://arxiv.org/abs/2601.00943)
*Megha Mariam K. M,Aditya Arun,Zakaria Laskar,C. V. Jawahar*

Main category: cs.CV

TL;DR: 本文提出了一个用于评估文本到视频（T2V）模型在物理教育中生成解释性视频能力的基准测试，发现当前模型在视觉质量上表现良好但概念准确性不足，特别是在电磁学和热力学等抽象领域。


<details>
  <summary>Details</summary>
Motivation: 评估生成式AI模型（特别是T2V系统）在物理教育中自动创建直观视觉解释的潜力，推动可扩展、可访问和个性化学习体验的发展。

Method: 设计了一个专门的基准测试，将物理概念分解为细粒度的教学点，每个点配有精心设计的提示词，用于评估T2V模型生成准确视频的能力。

Result: 当前模型能生成视觉连贯、运动平滑的视频，但概念准确性不可靠；在力学、流体和光学领域表现良好，在电磁学和热力学方面存在困难。

Conclusion: T2V模型在物理教育视频生成中存在视觉质量与概念正确性之间的差距，该基准测试有助于社区缩小这一差距，实现准确、符合课程要求的物理内容规模化生成。

Abstract: Generative AI models, particularly Text-to-Video (T2V) systems, offer a promising avenue for transforming science education by automating the creation of engaging and intuitive visual explanations. In this work, we take a first step toward evaluating their potential in physics education by introducing a dedicated benchmark for explanatory video generation. The benchmark is designed to assess how well T2V models can convey core physics concepts through visual illustrations. Each physics concept in our benchmark is decomposed into granular teaching points, with each point accompanied by a carefully crafted prompt intended for visual explanation of the teaching point. T2V models are evaluated on their ability to generate accurate videos in response to these prompts. Our aim is to systematically explore the feasibility of using T2V models to generate high-quality, curriculum-aligned educational content-paving the way toward scalable, accessible, and personalized learning experiences powered by AI. Our evaluation reveals that current models produce visually coherent videos with smooth motion and minimal flickering, yet their conceptual accuracy is less reliable. Performance in areas such as mechanics, fluids, and optics is encouraging, but models struggle with electromagnetism and thermodynamics, where abstract interactions are harder to depict. These findings underscore the gap between visual quality and conceptual correctness in educational video generation. We hope this benchmark helps the community close that gap and move toward T2V systems that can deliver accurate, curriculum-aligned physics content at scale. The benchmark and accompanying codebase are publicly available at https://github.com/meghamariamkm/PhyEduVideo.

</details>


### [18] [Deep Clustering with Associative Memories](https://arxiv.org/abs/2601.00963)
*Bishwajit Saha,Dmitry Krotov,Mohammed J. Zaki,Parikshit Ram*

Main category: cs.CV

TL;DR: 本文提出了一种新的深度聚类方法DCAM，通过基于能量的动态关联记忆来更紧密地结合表示学习和聚类过程。


<details>
  <summary>Details</summary>
Motivation: 现有的深度聚类方法中，表示学习是可微分的，但聚类本质上是离散优化任务，需要各种近似和正则化，导致表示学习和聚类之间存在脱节。

Method: 提出DCAM方法，利用基于能量的动态关联记忆来制定新的损失函数，在单一目标中更精细地结合表示学习和聚类。

Result: 实验表明DCAM在不同架构（卷积、残差或全连接）和数据模态（图像或文本）上都产生了更好的聚类质量。

Conclusion: DCAM方法通过关联记忆机制有效解决了深度聚类中表示学习与聚类过程的脱节问题，提升了聚类性能。

Abstract: Deep clustering - joint representation learning and latent space clustering - is a well studied problem especially in computer vision and text processing under the deep learning framework. While the representation learning is generally differentiable, clustering is an inherently discrete optimization task, requiring various approximations and regularizations to fit in a standard differentiable pipeline. This leads to a somewhat disjointed representation learning and clustering. In this work, we propose a novel loss function utilizing energy-based dynamics via Associative Memories to formulate a new deep clustering method, DCAM, which ties together the representation learning and clustering aspects more intricately in a single objective. Our experiments showcase the advantage of DCAM, producing improved clustering quality for various architecture choices (convolutional, residual or fully-connected) and data modalities (images or text).

</details>


### [19] [A Deep Learning Approach for Automated Skin Lesion Diagnosis with Explainable AI](https://arxiv.org/abs/2601.00964)
*Md. Maksudul Haque,Rahnuma Akter,A S M Ahsanul Sarkar Akib,Abdul Hasib*

Main category: cs.CV

TL;DR: 该论文提出了一种基于深度学习的多类皮肤病变分类系统，在HAM10000数据集上实现了91.15%的准确率，结合了数据平衡、数据增强、EfficientNetV2-L框架和可解释AI技术。


<details>
  <summary>Details</summary>
Motivation: 皮肤癌是全球最常见且危险的癌症类型之一，需要及时准确的诊断。现有诊断方法存在准确性和透明度不足的问题。

Method: 采用多阶段渐进学习策略，结合高质量数据平衡方法、大规模数据增强、带通道注意力的混合EfficientNetV2-L框架，并使用Grad-CAM和显著图等可解释AI技术。

Result: 系统在七类皮肤病变分类中表现优异，总准确率达91.15%，宏F1分数85.45%，微平均AUC达99.33%，尤其在黑色素瘤和黑色素细胞痣分类上表现突出。

Conclusion: 该深度学习方法不仅提高了皮肤癌诊断的准确性，还通过可解释AI技术增强了模型的透明度和临床可信度，有助于识别导致分类的视觉特征。

Abstract: Skin cancer is also one of the most common and dangerous types of cancer in the world that requires timely and precise diagnosis. In this paper, a deep-learning architecture of the multi-class skin lesion classification on the HAM10000 dataset will be described. The system suggested combines high-quality data balancing methods, large-scale data augmentation, hybridized EfficientNetV2-L framework with channel attention, and a three-stage progressive learning approach. Moreover, we also use explainable AI (XAI) techniques such as Grad-CAM and saliency maps to come up with intelligible visual representations of model predictions. Our strategy is with a total accuracy of 91.15 per cent, macro F1 of 85.45\% and micro-average AUC of 99.33\%. The model has shown high performance in all the seven lesion classes with specific high performance of melanoma and melanocytic nevi. In addition to enhancing diagnostic transparency, XAI also helps to find out the visual characteristics that cause the classifications, which enhances clinical trustworthiness.

</details>


### [20] [Few-Shot Video Object Segmentation in X-Ray Angiography Using Local Matching and Spatio-Temporal Consistency Loss](https://arxiv.org/abs/2601.00988)
*Lin Xi,Yingliang Ma,Xiahai Zhuang*

Main category: cs.CV

TL;DR: 提出了一种基于局部匹配策略的FSVOS模型，通过方向采样机制实现动态可变采样区域，结合时空对比学习增强特征一致性，在X射线血管造影视频分割任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有视频分割方法在非CUDA设备上移植性差、计算效率低的问题，同时为医学影像分析提供更灵活的解决方案。

Method: 采用非参数采样机制实现动态采样区域，设计监督式时空对比学习方案增强特征一致性，并构建了MOSXAV多目标分割基准数据集。

Result: 在CADICA、XACV和MOSXAV数据集上的实验表明，该方法在分割精度和泛化能力方面优于当前最先进的视频分割方法。

Conclusion: 该方法为临床应用提供了更强的灵活性和潜力，特别是在X射线血管造影视频分析领域。

Abstract: We introduce a novel FSVOS model that employs a local matching strategy to restrict the search space to the most relevant neighboring pixels. Rather than relying on inefficient standard im2col-like implementations (e.g., spatial convolutions, depthwise convolutions and feature-shifting mechanisms) or hardware-specific CUDA kernels (e.g., deformable and neighborhood attention), which often suffer from limited portability across non-CUDA devices, we reorganize the local sampling process through a direction-based sampling perspective. Specifically, we implement a non-parametric sampling mechanism that enables dynamically varying sampling regions. This approach provides the flexibility to adapt to diverse spatial structures without the computational costs of parametric layers and the need for model retraining. To further enhance feature coherence across frames, we design a supervised spatio-temporal contrastive learning scheme that enforces consistency in feature representations. In addition, we introduce a publicly available benchmark dataset for multi-object segmentation in X-ray angiography videos (MOSXAV), featuring detailed, manually labeled segmentation ground truth. Extensive experiments on the CADICA, XACV, and MOSXAV datasets show that our proposed FSVOS method outperforms current state-of-the-art video segmentation methods in terms of segmentation accuracy and generalization capability (i.e., seen and unseen categories). This work offers enhanced flexibility and potential for a wide range of clinical applications.

</details>


### [21] [UnrealPose: Leveraging Game Engine Kinematics for Large-Scale Synthetic Human Pose Data](https://arxiv.org/abs/2601.00991)
*Joshua Kawaguchi,Saad Manzur,Emily Gao Wang,Maitreyi Sinha,Bryan Vela,Yunxi Wang,Brandon Vela,Wayne B. Hayes*

Main category: cs.CV

TL;DR: UnrealPose-Gen是一个基于虚幻引擎5的管道，用于生成高质量的人体姿态数据，并发布了包含约100万帧的UnrealPose-1M数据集。


<details>
  <summary>Details</summary>
Motivation: 解决3D人体姿态数据昂贵且局限于工作室，而野外数据集缺乏真实地面真值的问题。

Method: 使用虚幻引擎5和电影渲染队列进行高质量离线渲染，生成包含3D关节、2D投影、边界框和相机参数等丰富标注的帧。

Result: 创建了UnrealPose-1M数据集，包含八个序列，涵盖多个场景、动作和主体，并在四个任务上进行了真实到合成的验证。

Conclusion: 发布了UnrealPose-1M数据集和UnrealPose-Gen管道，支持第三方生成人体姿态数据。

Abstract: Diverse, accurately labeled 3D human pose data is expensive and studio-bound, while in-the-wild datasets lack known ground truth. We introduce UnrealPose-Gen, an Unreal Engine 5 pipeline built on Movie Render Queue for high-quality offline rendering. Our generated frames include: (i) 3D joints in world and camera coordinates, (ii) 2D projections and COCO-style keypoints with occlusion and joint-visibility flags, (iii) person bounding boxes, and (iv) camera intrinsics and extrinsics. We use UnrealPose-Gen to present UnrealPose-1M, an approximately one million frame corpus comprising eight sequences: five scripted "coherent" sequences spanning five scenes, approximately 40 actions, and five subjects; and three randomized sequences across three scenes, approximately 100 actions, and five subjects, all captured from diverse camera trajectories for broad viewpoint coverage. As a fidelity check, we report real-to-synthetic results on four tasks: image-to-3D pose, 2D keypoint detection, 2D-to-3D lifting, and person detection/segmentation. Though time and resources constrain us from an unlimited dataset, we release the UnrealPose-1M dataset, as well as the UnrealPose-Gen pipeline to support third-party generation of human pose data.

</details>


### [22] [WildIng: A Wildlife Image Invariant Representation Model for Geographical Domain Shift](https://arxiv.org/abs/2601.00993)
*Julian D. Santamaria,Claudia Isaza,Jhony H. Giraldo*

Main category: cs.CV

TL;DR: WildIng是一个用于处理野生动物图像地理域迁移的鲁棒表示模型，通过整合文本描述和图像特征来提高跨地理区域的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在野生动物监测中表现出色，但在面对不同地理区域的数据时性能显著下降，主要原因是模型对背景、光照等环境变化敏感。

Method: WildIng通过整合文本描述（如物种外观的详细描述）与图像特征，创建对地理域迁移更鲁棒的表示，利用文本信息捕捉一致的语义信息。

Result: 实验表明，WildIng在BioCLIP等基础模型上，在地理域迁移条件下将准确率提高了30%。在非洲数据集训练的模型在美洲数据集上的准确率从16.17%显著提升。

Conclusion: WildIng通过文本-图像特征整合有效解决了野生动物识别中的地理域迁移问题，为跨区域野生动物监测提供了更可靠的自动化解决方案。

Abstract: Wildlife monitoring is crucial for studying biodiversity loss and climate change. Camera trap images provide a non-intrusive method for analyzing animal populations and identifying ecological patterns over time. However, manual analysis is time-consuming and resource-intensive. Deep learning, particularly foundation models, has been applied to automate wildlife identification, achieving strong performance when tested on data from the same geographical locations as their training sets. Yet, despite their promise, these models struggle to generalize to new geographical areas, leading to significant performance drops. For example, training an advanced vision-language model, such as CLIP with an adapter, on an African dataset achieves an accuracy of 84.77%. However, this performance drops significantly to 16.17% when the model is tested on an American dataset. This limitation partly arises because existing models rely predominantly on image-based representations, making them sensitive to geographical data distribution shifts, such as variation in background, lighting, and environmental conditions. To address this, we introduce WildIng, a Wildlife image Invariant representation model for geographical domain shift. WildIng integrates text descriptions with image features, creating a more robust representation to geographical domain shifts. By leveraging textual descriptions, our approach captures consistent semantic information, such as detailed descriptions of the appearance of the species, improving generalization across different geographical locations. Experiments show that WildIng enhances the accuracy of foundation models such as BioCLIP by 30% under geographical domain shift conditions. We evaluate WildIng on two datasets collected from different regions, namely America and Africa. The code and models are publicly available at https://github.com/Julian075/CATALOG/tree/WildIng.

</details>


### [23] [DVGBench: Implicit-to-Explicit Visual Grounding Benchmark in UAV Imagery with Large Vision-Language Models](https://arxiv.org/abs/2601.00998)
*Yue Zhou,Jue Chen,Zilun Zhang,Penghui Huang,Ran Ding,Zhentao Zou,PengFei Gao,Yuchen Wei,Ke Li,Xue Yang,Xue Jiang,Hongxin Yang,Jonathan Li*

Main category: cs.CV

TL;DR: DVGBench是一个用于无人机的高质量隐式视觉定位基准数据集，涵盖六大应用场景，包含显式和隐式查询。基于该数据集开发了DroneVG-R1模型，采用隐式到显式思维链强化学习范式，提升模型在需要领域知识的隐式视觉定位任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有遥感视觉语言模型在视觉定位任务中主要依赖显式参照表达式，但在需要场景特定领域知识的隐式视觉定位任务上表现受限，需要开发专门的基准和模型来提升推理能力。

Method: 构建DVGBench数据集，包含六大应用场景的显式和隐式查询；开发DroneVG-R1模型，集成隐式到显式思维链（I2E-CoT）到强化学习框架中，将隐式参照转换为显式参照以降低定位难度。

Result: 对主流模型在显式和隐式视觉定位任务上的评估显示其推理能力存在显著局限性，DroneVG-R1模型通过I2E-CoT方法有效提升了隐式视觉定位性能。

Conclusion: 该研究为提升基于无人机的视觉语言模型推理能力提供了可行的解决方案和数据集基准，代码和数据集将在GitHub上开源。

Abstract: Remote sensing (RS) large vision-language models (LVLMs) have shown strong promise across visual grounding (VG) tasks. However, existing RS VG datasets predominantly rely on explicit referring expressions-such as relative position, relative size, and color cues-thereby constraining performance on implicit VG tasks that require scenario-specific domain knowledge. This article introduces DVGBench, a high-quality implicit VG benchmark for drones, covering six major application scenarios: traffic, disaster, security, sport, social activity, and productive activity. Each object provides both explicit and implicit queries. Based on the dataset, we design DroneVG-R1, an LVLM that integrates the novel Implicit-to-Explicit Chain-of-Thought (I2E-CoT) within a reinforcement learning paradigm. This enables the model to take advantage of scene-specific expertise, converting implicit references into explicit ones and thus reducing grounding difficulty. Finally, an evaluation of mainstream models on both explicit and implicit VG tasks reveals substantial limitations in their reasoning capabilities. These findings provide actionable insights for advancing the reasoning capacity of LVLMs for drone-based agents. The code and datasets will be released at https://github.com/zytx121/DVGBench

</details>


### [24] [Lightweight Channel Attention for Efficient CNNs](https://arxiv.org/abs/2601.01002)
*Prem Babu Kanaparthi,Tulasi Venkata Sri Varshini Padamata*

Main category: cs.CV

TL;DR: 本文对三种通道注意力机制（SE、ECA和LCA）进行了实证研究，提出了一种轻量级通道注意力模块LCA，在保持准确性的同时显著减少参数数量。


<details>
  <summary>Details</summary>
Motivation: 现有通道注意力机制在效率与准确性之间的权衡研究不足，需要探索更高效的注意力设计以适应资源受限环境。

Method: 提出Lite Channel Attention（LCA）模块，采用自适应一维卷积和分组操作来减少参数使用，同时保持有效的注意力行为。在ResNet18和MobileNetV2架构上对SE、ECA和LCA进行对比实验。

Result: LCA在CIFAR-10上达到ResNet18 94.68%和MobileNetV2 93.10%的准确率，参数效率与ECA相当，并保持有利的推理延迟。

Conclusion: LCA模块在资源受限环境中具有实用价值，为部署注意力增强的CNN提供了实用的基准数据（FLOPs、参数计数和GPU延迟）。

Abstract: Attention mechanisms have become integral to modern convolutional neural networks (CNNs), delivering notable performance improvements with minimal computational overhead. However, the efficiency accuracy trade off of different channel attention designs remains underexplored. This work presents an empirical study comparing Squeeze and Excitation (SE), Efficient Channel Attention (ECA), and a proposed Lite Channel Attention (LCA) module across ResNet 18 and MobileNetV2 architectures on CIFAR 10. LCA employs adaptive one dimensional convolutions with grouped operations to reduce parameter usage while preserving effective attention behavior. Experimental results show that LCA achieves competitive accuracy, reaching 94.68 percent on ResNet 18 and 93.10 percent on MobileNetV2, while matching ECA in parameter efficiency and maintaining favorable inference latency. Comprehensive benchmarks including FLOPs, parameter counts, and GPU latency measurements are provided, offering practical insights for deploying attention enhanced CNNs in resource constrained environments.

</details>


### [25] [Decoupling Amplitude and Phase Attention in Frequency Domain for RGB-Event based Visual Object Tracking](https://arxiv.org/abs/2601.01022)
*Shiao Wang,Xiao Wang,Haonan Zhao,Jiarui Xu,Bo Jiang,Lin Zhu,Xin Zhao,Yonghong Tian,Jin Tang*

Main category: cs.CV

TL;DR: 提出了一种在频域进行早期融合的RGB-Event目标跟踪框架，通过频域注意力机制和运动引导空间稀疏化模块，有效利用事件相机的高动态范围和运动敏感性，减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有RGB-Event跟踪方法主要依赖传统特征级融合，未能充分利用事件相机的高动态范围和运动敏感性优势，同时对低信息区域进行统一处理导致不必要的计算开销。

Method: 将RGB和事件模态通过快速傅里叶变换转换到频域，解耦振幅和相位分量；通过振幅和相位注意力选择性融合高频事件信息；使用运动引导空间稀疏化模块过滤低信息区域；将稀疏的目标相关特征输入骨干网络进行学习。

Result: 在FE108、FELT和COESOT三个主流RGB-Event跟踪基准数据集上的实验表明，该方法具有高性能和高效率。

Conclusion: 提出的频域早期融合框架能够有效利用事件相机的优势，在保持高性能的同时显著减少计算量，为RGB-Event目标跟踪提供了新的解决方案。

Abstract: Existing RGB-Event visual object tracking approaches primarily rely on conventional feature-level fusion, failing to fully exploit the unique advantages of event cameras. In particular, the high dynamic range and motion-sensitive nature of event cameras are often overlooked, while low-information regions are processed uniformly, leading to unnecessary computational overhead for the backbone network. To address these issues, we propose a novel tracking framework that performs early fusion in the frequency domain, enabling effective aggregation of high-frequency information from the event modality. Specifically, RGB and event modalities are transformed from the spatial domain to the frequency domain via the Fast Fourier Transform, with their amplitude and phase components decoupled. High-frequency event information is selectively fused into RGB modality through amplitude and phase attention, enhancing feature representation while substantially reducing backbone computation. In addition, a motion-guided spatial sparsification module leverages the motion-sensitive nature of event cameras to capture the relationship between target motion cues and spatial probability distribution, filtering out low-information regions and enhancing target-relevant features. Finally, a sparse set of target-relevant features is fed into the backbone network for learning, and the tracking head predicts the final target position. Extensive experiments on three widely used RGB-Event tracking benchmark datasets, including FE108, FELT, and COESOT, demonstrate the high performance and efficiency of our method. The source code of this paper will be released on https://github.com/Event-AHU/OpenEvTracking

</details>


### [26] [ITSELF: Attention Guided Fine-Grained Alignment for Vision-Language Retrieval](https://arxiv.org/abs/2601.01024)
*Tien-Huy Nguyen,Huu-Loc Tran,Thanh Duc Ngo*

Main category: cs.CV

TL;DR: ITSELF是一个基于注意力引导的隐式局部对齐框架，通过将模型自身的注意力转换为高显著性标记的注意力银行，在无需额外监督的情况下学习细粒度对应关系，在文本人物搜索任务中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的局部对齐方法容易陷入捷径学习和虚假相关性，导致错位问题，而注入先验知识可能会扭曲模态内结构。研究发现编码器注意力从训练早期就能提供空间精确的证据，这启发了开发注意力引导的框架。

Method: ITSELF框架包含三个核心组件：GRAB（引导表示与注意力银行）将模型注意力转换为高显著性标记银行；MARS（多层注意力鲁棒选择）通过跨层注意力聚合和多样性感知的top-k选择；ATS（自适应标记调度器）在训练过程中从粗到细调度保留预算。

Result: 在三个广泛使用的TBPS基准测试上进行了大量实验，结果显示达到了最先进的性能，并展现出强大的跨数据集泛化能力。

Conclusion: 该方法在不依赖额外先验监督的情况下，证实了其有效性和鲁棒性，为视觉语言模型在细粒度跨模态对齐任务中的应用提供了新的解决方案。

Abstract: Vision Language Models (VLMs) have rapidly advanced and show strong promise for text-based person search (TBPS), a task that requires capturing fine-grained relationships between images and text to distinguish individuals. Previous methods address these challenges through local alignment, yet they are often prone to shortcut learning and spurious correlations, yielding misalignment. Moreover, injecting prior knowledge can distort intra-modality structure. Motivated by our finding that encoder attention surfaces spatially precise evidence from the earliest training epochs, and to alleviate these issues, we introduceITSELF, an attention-guided framework for implicit local alignment. At its core, Guided Representation with Attentive Bank (GRAB) converts the model's own attention into an Attentive Bank of high-saliency tokens and applies local objectives on this bank, learning fine-grained correspondences without extra supervision. To make the selection reliable and non-redundant, we introduce Multi-Layer Attention for Robust Selection (MARS), which aggregates attention across layers and performs diversity-aware top-k selection; and Adaptive Token Scheduler (ATS), which schedules the retention budget from coarse to fine over training, preserving context early while progressively focusing on discriminative details. Extensive experiments on three widely used TBPS benchmarks showstate-of-the-art performance and strong cross-dataset generalization, confirming the effectiveness and robustness of our approach without additional prior supervision. Our project is publicly available at https://trhuuloc.github.io/itself

</details>


### [27] [Enhanced Leukemic Cell Classification Using Attention-Based CNN and Data Augmentation](https://arxiv.org/abs/2601.01026)
*Douglas Costa Braga,Daniel Oliveira Dantas*

Main category: cs.CV

TL;DR: 提出了一种可重复的深度学习管道用于白血病细胞分类，结合注意力机制和高效网络架构，在C-NMC 2019数据集上达到97.89%的准确率，参数数量比VGG16减少89%。


<details>
  <summary>Details</summary>
Motivation: 急性淋巴细胞白血病是最常见的儿童癌症，传统显微镜诊断存在观察者间变异性和时间限制问题，需要自动化、可复现的诊断系统。

Method: 集成基于注意力的卷积神经网络，结合EfficientNetV2-B3和Squeeze-and-Excitation机制，使用数据增强、焦点损失和患者级数据分割确保评估的鲁棒性。

Result: 在12,528张图像上达到97.89%的F1分数和准确率，通过100次蒙特卡洛实验验证统计显著性(p < 0.001)，比现有方法提升4.67%，参数减少89%。

Conclusion: 注意力机制提供了可解释的诊断特征可视化，证明基于注意力的现代架构可以在保持计算效率的同时改善白血病细胞分类，适合临床部署。

Abstract: We present a reproducible deep learning pipeline for leukemic cell classification, focusing on system architecture, experimental robustness, and software design choices for medical image analysis. Acute lymphoblastic leukemia (ALL) is the most common childhood cancer, requiring expert microscopic diagnosis that suffers from inter-observer variability and time constraints. The proposed system integrates an attention-based convolutional neural network combining EfficientNetV2-B3 with Squeeze-and-Excitation mechanisms for automated ALL cell classification. Our approach employs comprehensive data augmentation, focal loss for class imbalance, and patient-wise data splitting to ensure robust and reproducible evaluation. On the C-NMC 2019 dataset (12,528 original images from 62 patients), the system achieves a 97.89% F1-score and 97.89% accuracy on the test set, with statistical validation through 100-iteration Monte Carlo experiments confirming significant improvements (p < 0.001) over baseline methods. The proposed pipeline outperforms existing approaches by up to 4.67% while using 89% fewer parameters than VGG16 (15.2M vs. 138M). The attention mechanism provides interpretable visualizations of diagnostically relevant cellular features, demonstrating that modern attention-based architectures can improve leukemic cell classification while maintaining computational efficiency suitable for clinical deployment.

</details>


### [28] [Mono3DV: Monocular 3D Object Detection with 3D-Aware Bipartite Matching and Variational Query DeNoising](https://arxiv.org/abs/2601.01036)
*Kiet Dang Vu,Trung Thai Tran,Kien Nguyen Do Trung,Duc Dung Nguyen*

Main category: cs.CV

TL;DR: Mono3DV是一个基于Transformer的单目3D目标检测框架，通过引入3D感知二分匹配、3D去噪方案和变分查询去噪机制，解决了传统DETR架构在3D属性匹配中的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统DETR架构在单目3D目标检测中由于仅使用2D匹配标准，忽略了3D几何信息，导致高质量3D预测被错误抑制，训练不稳定。

Method: 1. 3D感知二分匹配策略：将3D几何信息直接融入匹配成本；2. 3D去噪方案：稳定训练过程中的二分匹配；3. 变分查询去噪机制：解决传统去噪技术的梯度消失问题。

Result: 在KITTI 3D目标检测基准上取得了最先进的结果，无需外部数据。

Conclusion: Mono3DV通过有效整合3D信息到匹配过程中，显著提升了单目3D检测的性能和稳定性。

Abstract: While DETR-like architectures have demonstrated significant potential for monocular 3D object detection, they are often hindered by a critical limitation: the exclusion of 3D attributes from the bipartite matching process. This exclusion arises from the inherent ill-posed nature of 3D estimation from monocular image, which introduces instability during training. Consequently, high-quality 3D predictions can be erroneously suppressed by 2D-only matching criteria, leading to suboptimal results. To address this, we propose Mono3DV, a novel Transformer-based framework. Our approach introduces three key innovations. First, we develop a 3D-Aware Bipartite Matching strategy that directly incorporates 3D geometric information into the matching cost, resolving the misalignment caused by purely 2D criteria. Second, it is important to stabilize the Bipartite Matching to resolve the instability occurring when integrating 3D attributes. Therefore, we propose 3D-DeNoising scheme in the training phase. Finally, recognizing the gradient vanishing issue associated with conventional denoising techniques, we propose a novel Variational Query DeNoising mechanism to overcome this limitation, which significantly enhances model performance. Without leveraging any external data, our method achieves state-of-the-art results on the KITTI 3D object detection benchmark.

</details>


### [29] [Deepfake Detection with Multi-Artifact Subspace Fine-Tuning and Selective Layer Masking](https://arxiv.org/abs/2601.01041)
*Xiang Zhang,Wenliang Weng,Daoyong Fu,Ziqiang Li,Zhangjie Fu*

Main category: cs.CV

TL;DR: 该论文提出了一种基于多伪影子空间和选择性层掩码的深度伪造检测方法，通过解耦语义表示和伪影表示，提高跨数据集场景下的泛化鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 深度伪造检测在跨数据集和现实复杂场景中面临挑战，主要原因是不同伪造方法引入的伪影分布多样性高，而预训练模型在适应新伪影时容易破坏原有的通用语义结构。

Method: MASM方法使用奇异值分解将预训练权重划分为稳定的语义主空间和多个可学习的伪影子空间，引入选择性层掩码策略自适应调节网络层更新，并施加正交性和谱一致性约束来正则化多个伪影子空间。

Result: 该方法能够解耦建模不同的伪造伪影模式，同时保留通用语义子空间，有效抑制对单一伪造特征的过拟合。

Conclusion: 提出的MASM方法通过解耦语义和伪影表示，约束伪影子空间的拟合强度，显著提升了深度伪造检测在跨数据集场景中的泛化鲁棒性。

Abstract: Deepfake detection still faces significant challenges in cross-dataset and real-world complex scenarios. The root cause lies in the high diversity of artifact distributions introduced by different forgery methods, while pretrained models tend to disrupt their original general semantic structures when adapting to new artifacts. Existing approaches usually rely on indiscriminate global parameter updates or introduce additional supervision signals, making it difficult to effectively model diverse forgery artifacts while preserving semantic stability. To address these issues, this paper proposes a deepfake detection method based on Multi-Artifact Subspaces and selective layer masks (MASM), which explicitly decouples semantic representations from artifact representations and constrains the fitting strength of artifact subspaces, thereby improving generalization robustness in cross-dataset scenarios. Specifically, MASM applies singular value decomposition to model weights, partitioning pretrained weights into a stable semantic principal subspace and multiple learnable artifact subspaces. This design enables decoupled modeling of different forgery artifact patterns while preserving the general semantic subspace. On this basis, a selective layer mask strategy is introduced to adaptively regulate the update behavior of corresponding network layers according to the learning state of each artifact subspace, suppressing overfitting to any single forgery characteristic. Furthermore, orthogonality constraints and spectral consistency constraints are imposed to jointly regularize multiple artifact subspaces, guiding them to learn complementary and diverse artifact representations while maintaining a stable overall spectral structure.

</details>


### [30] [Evaluating transfer learning strategies for improving dairy cattle body weight prediction in small farms using depth-image and point-cloud data](https://arxiv.org/abs/2601.01044)
*Jin Wang,Angelo De Castro,Yuxi Zhang,Lucas Basolli Borsatto,Yuechen Guo,Victoria Bastos Primo,Ana Beatriz Montevecchio Bernardino,Gota Morota,Ricardo C Chebel,Haipeng Yu*

Main category: cs.CV

TL;DR: 本研究评估了从大型农场迁移学习到小型农场对奶牛体重预测的效果，并比较了深度图像和点云两种数据模态的性能。结果表明迁移学习能显著提升小型农场的预测精度，且两种模态在性能上无显著差异。


<details>
  <summary>Details</summary>
Motivation: 当前在畜牧业应用中，迁移学习对奶牛体重预测的有效性和最优微调策略尚不明确，且深度图像与点云数据在奶牛体重预测中的直接对比研究有限。

Method: 从大、中、小三个农场分别采集了1,201、215和58头奶牛的俯视深度图像和点云数据，评估了ConvNeXt、MobileViT（深度图像）以及PointNet、DGCNN（点云）四种深度学习模型，并设计了三种实验方案进行对比。

Result: 迁移学习在所有四种模型上均显著提升了小型农场的体重预测性能，优于单源学习，且效果与联合学习相当或更好。深度图像和点云模型之间未观察到一致的性能差异。

Conclusion: 迁移学习特别适用于受隐私、物流或政策限制的小型农场预测场景，因其仅需预训练模型权重而非原始数据，且预训练表征能良好泛化至不同成像条件和牛群的农场。

Abstract: Computer vision provides automated, non-invasive, and scalable tools for monitoring dairy cattle, thereby supporting management, health assessment, and phenotypic data collection. Although transfer learning is commonly used for predicting body weight from images, its effectiveness and optimal fine-tuning strategies remain poorly understood in livestock applications, particularly beyond the use of pretrained ImageNet or COCO weights. In addition, while both depth images and three-dimensional point-cloud data have been explored for body weight prediction, direct comparisons of these two modalities in dairy cattle are limited. Therefore, the objectives of this study were to 1) evaluate whether transfer learning from a large farm enhances body weight prediction on a small farm with limited data, and 2) compare the predictive performance of depth-image- and point-cloud-based approaches under three experimental designs. Top-view depth images and point-cloud data were collected from 1,201, 215, and 58 cows at large, medium, and small dairy farms, respectively. Four deep learning models were evaluated: ConvNeXt and MobileViT for depth images, and PointNet and DGCNN for point clouds. Transfer learning markedly improved body weight prediction on the small farm across all four models, outperforming single-source learning and achieving gains comparable to or greater than joint learning. These results indicate that pretrained representations generalize well across farms with differing imaging conditions and dairy cattle populations. No consistent performance difference was observed between depth-image- and point-cloud-based models. Overall, these findings suggest that transfer learning is well suited for small farm prediction scenarios where cross-farm data sharing is limited by privacy, logistical, or policy constraints, as it requires access only to pretrained model weights rather than raw data.

</details>


### [31] [EgoGrasp: World-Space Hand-Object Interaction Estimation from Egocentric Videos](https://arxiv.org/abs/2601.01050)
*Hongming Fu,Wenjia Wang,Xiaozhen Qiao,Shuo Yang,Zheng Liu,Bo Zhao*

Main category: cs.CV

TL;DR: EgoGrasp是首个从动态单目视频中重建世界空间手物交互的方法，解决了现有方法在时间动态和全局一致性方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 准确的世界空间手物交互重建对于理解人类行为和在具身智能、虚拟现实中的应用至关重要，但现有方法局限于单图像或相机坐标系，无法处理时间动态或全局轨迹一致性。

Method: 提出多阶段框架，包括基于新型空间智能模型的鲁棒预处理管道、基于解耦扩散模型的全身HOI先验模型，以及多目标测试时优化范式。HOI先验模型无需模板且可扩展至多物体。

Result: 实验证明该方法在世界空间手物交互重建方面达到最先进性能。

Conclusion: EgoGrasp通过创新的多阶段框架有效解决了动态单目视频中世界空间手物交互重建的挑战，特别是在严重相机运动和频繁遮挡情况下表现出色。

Abstract: We propose EgoGrasp, the first method to reconstruct world-space hand-object interactions (W-HOI) from egocentric monocular videos with dynamic cameras in the wild. Accurate W-HOI reconstruction is critical for understanding human behavior and enabling applications in embodied intelligence and virtual reality. However, existing hand-object interactions (HOI) methods are limited to single images or camera coordinates, failing to model temporal dynamics or consistent global trajectories. Some recent approaches attempt world-space hand estimation but overlook object poses and HOI constraints. Their performance also suffers under severe camera motion and frequent occlusions common in egocentric in-the-wild videos. To address these challenges, we introduce a multi-stage framework with a robust pre-process pipeline built on newly developed spatial intelligence models, a whole-body HOI prior model based on decoupled diffusion models, and a multi-objective test-time optimization paradigm. Our HOI prior model is template-free and scalable to multiple objects. In experiments, we prove our method achieving state-of-the-art performance in W-HOI reconstruction.

</details>


### [32] [Enhancing Histopathological Image Classification via Integrated HOG and Deep Features with Robust Noise Performance](https://arxiv.org/abs/2601.01056)
*Ifeanyi Ezuma,Ugochukwu Ugwu*

Main category: cs.CV

TL;DR: 该研究评估了机器学习和深度学习模型在LC25000组织病理学图像数据集上的分类性能，发现基于InceptionResNet-v2深度特征的模型表现最佳，特别是在噪声环境下具有更强的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 数字病理学的发展使得自动化图像分析在临床实践中变得至关重要，需要评估不同模型在组织病理学图像分类中的性能。

Method: 使用微调的InceptionResNet-v2网络作为分类器和特征提取器，比较了机器学习模型在深度特征上的性能，并评估了不同信噪比条件下的模型鲁棒性。

Result: 微调InceptionResNet-v2达到96.01%准确率和96.8%平均AUC；基于其深度特征的神经网络模型达到99.99% AUC和99.84%准确率；在噪声环境下，GBM和KNN模型表现出更好的鲁棒性。

Conclusion: 基于深度特征的模型在组织病理学图像分类中表现优异，特别是在噪声环境下具有更好的稳定性，HOG与深度特征结合能提升性能但在噪声环境中效果有限。

Abstract: The era of digital pathology has advanced histopathological examinations, making automated image analysis essential in clinical practice. This study evaluates the classification performance of machine learning and deep learning models on the LC25000 dataset, which includes five classes of histopathological images. We used the fine-tuned InceptionResNet-v2 network both as a classifier and for feature extraction. Our results show that the fine-tuned InceptionResNet-v2 achieved a classification accuracy of 96.01\% and an average AUC of 96.8\%. Models trained on deep features from InceptionResNet-v2 outperformed those using only the pre-trained network, with the Neural Network model achieving an AUC of 99.99\% and accuracy of 99.84\%. Evaluating model robustness under varying SNR conditions revealed that models using deep features exhibited greater resilience, particularly GBM and KNN. The combination of HOG and deep features showed enhanced performance, however, less so in noisy environments.

</details>


### [33] [Real-Time LiDAR Point Cloud Densification for Low-Latency Spatial Data Transmission](https://arxiv.org/abs/2601.01210)
*Kazuhiko Murasaki,Shunsuke Konagai,Masakatsu Aoki,Taiga Yoshida,Ryuichi Tanida*

Main category: cs.CV

TL;DR: 提出了一种高速LiDAR点云稠密化方法，通过结合多LiDAR输入和高分辨率彩色图像，实现实时生成稠密3D场景，解决了沉浸式远程呈现系统中的低延迟空间传输问题。


<details>
  <summary>Details</summary>
Motivation: 为沉浸式远程呈现系统实现低延迟空间传输，需要解决动态3D场景密集捕获和实时处理两大问题。LiDAR传感器能实时捕获3D但产生稀疏点云，因此需要高速点云稠密化方法。

Method: 结合多LiDAR输入与高分辨率彩色图像，采用联合双边滤波策略，通过卷积神经网络架构实现实时深度补全。

Result: 实验表明该方法能以30fps实时生成全高清分辨率的稠密深度图，比现有基于训练的方法快15倍以上，生成的稠密点云具有精确几何结构，无多视图不一致或重影伪影。

Conclusion: 该方法成功实现了高速LiDAR点云稠密化，为沉浸式远程呈现系统提供了有效的实时3D场景重建解决方案。

Abstract: To realize low-latency spatial transmission system for immersive telepresence, there are two major problems: capturing dynamic 3D scene densely and processing them in real time. LiDAR sensors capture 3D in real time, but produce sparce point clouds. Therefore, this paper presents a high-speed LiDAR point cloud densification method to generate dense 3D scene with minimal latency, addressing the need for on-the-fly depth completion while maintaining real-time performance. Our approach combines multiple LiDAR inputs with high-resolution color images and applies a joint bilateral filtering strategy implemented through a convolutional neural network architecture. Experiments demonstrate that the proposed method produces dense depth maps at full HD resolution in real time (30 fps), which is over 15x faster than a recent training-based depth completion approach. The resulting dense point clouds exhibit accurate geometry without multiview inconsistencies or ghosting artifacts.

</details>


### [34] [Efficient Hyperspectral Image Reconstruction Using Lightweight Separate Spectral Transformers](https://arxiv.org/abs/2601.01064)
*Jianan Li,Wangcai Zhao,Tingfa Xu*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级分离光谱变换器（LSST）用于高效的高光谱图像压缩感知重建，通过分离处理光谱和空间特征，在减少计算复杂度的同时实现了优越的重建性能。


<details>
  <summary>Details</summary>
Motivation: 高光谱成像在多个领域具有重要应用价值，但如何从压缩感知测量中高效重建高光谱图像面临重大挑战。现有方法在处理光谱和空间特征时效率不足，需要一种能够充分利用高光谱图像独特特性的轻量级解决方案。

Method: 采用分治策略，提出LSST架构：包含分离光谱变换器块（SSTB）用于建模光谱关系，采用分组光谱自注意力和光谱混洗操作；轻量级空间卷积块（LSCB）用于空间处理，使用深度可分离卷积和策略性排序；并引入焦点光谱损失函数进行动态训练优化。

Result: 大量实验表明，LSST在实现优越重建性能的同时，显著减少了FLOPs和参数数量，证明了其高效性和有效性。

Conclusion: LSST架构通过创新的光谱-空间分离处理策略和轻量级设计，为高光谱图像压缩感知重建提供了高效且有效的解决方案，在计算复杂度和重建质量之间取得了良好平衡。

Abstract: Hyperspectral imaging (HSI) is essential across various disciplines for its capacity to capture rich spectral information. However, efficiently reconstructing hyperspectral images from compressive sensing measurements presents significant challenges. To tackle these, we adopt a divide-and-conquer strategy that capitalizes on the unique spectral and spatial characteristics of hyperspectral images. We introduce the Lightweight Separate Spectral Transformer (LSST), an innovative architecture tailored for efficient hyperspectral image reconstruction. This architecture consists of Separate Spectral Transformer Blocks (SSTB) for modeling spectral relationships and Lightweight Spatial Convolution Blocks (LSCB) for spatial processing. The SSTB employs Grouped Spectral Self-attention and a Spectrum Shuffle operation to effectively manage both local and non-local spectral relationships. Simultaneously, the LSCB utilizes depth-wise separable convolutions and strategic ordering to enhance spatial information processing. Furthermore, we implement the Focal Spectrum Loss, a novel loss weighting mechanism that dynamically adjusts during training to improve reconstruction across spectrally complex bands. Extensive testing demonstrates that our LSST achieves superior performance while requiring fewer FLOPs and parameters, underscoring its efficiency and effectiveness. The source code is available at: https://github.com/wcz1124/LSST.

</details>


### [35] [DrivingGen: A Comprehensive Benchmark for Generative Video World Models in Autonomous Driving](https://arxiv.org/abs/2601.01528)
*Yang Zhou,Hao Shao,Letian Wang,Zhuofan Zong,Hongsheng Li,Steven L. Waslander*

Main category: cs.CV

TL;DR: DrivingGen是首个用于生成式驾驶世界模型的综合基准测试，解决了现有评估方法在视觉真实性、轨迹合理性、时间一致性和可控性方面的不足，为自动驾驶领域提供了统一的评估框架。


<details>
  <summary>Details</summary>
Motivation: 当前驾驶世界模型研究缺乏严谨的基准测试，现有评估方法存在多个局限性：通用视频指标忽略安全关键因素；轨迹合理性很少量化；时间和智能体级别一致性被忽视；基于ego条件可控性被忽略。此外，现有数据集无法覆盖真实世界部署所需的多样性条件。

Method: DrivingGen结合了从驾驶数据集和互联网规模视频源精心策划的多样化评估数据集，涵盖不同天气、时间、地理区域和复杂操作，并开发了一套新指标来联合评估视觉真实性、轨迹合理性、时间一致性和可控性。

Result: 对14个最先进模型的基准测试揭示了明显权衡：通用模型看起来更好但违反物理规律，而驾驶专用模型能真实捕捉运动但在视觉质量上落后。

Conclusion: DrivingGen提供了一个统一的评估框架，旨在培养可靠、可控和可部署的驾驶世界模型，支持可扩展的仿真、规划和数据驱动决策。

Abstract: Video generation models, as one form of world models, have emerged as one of the most exciting frontiers in AI, promising agents the ability to imagine the future by modeling the temporal evolution of complex scenes. In autonomous driving, this vision gives rise to driving world models: generative simulators that imagine ego and agent futures, enabling scalable simulation, safe testing of corner cases, and rich synthetic data generation. Yet, despite fast-growing research activity, the field lacks a rigorous benchmark to measure progress and guide priorities. Existing evaluations remain limited: generic video metrics overlook safety-critical imaging factors; trajectory plausibility is rarely quantified; temporal and agent-level consistency is neglected; and controllability with respect to ego conditioning is ignored. Moreover, current datasets fail to cover the diversity of conditions required for real-world deployment. To address these gaps, we present DrivingGen, the first comprehensive benchmark for generative driving world models. DrivingGen combines a diverse evaluation dataset curated from both driving datasets and internet-scale video sources, spanning varied weather, time of day, geographic regions, and complex maneuvers, with a suite of new metrics that jointly assess visual realism, trajectory plausibility, temporal coherence, and controllability. Benchmarking 14 state-of-the-art models reveals clear trade-offs: general models look better but break physics, while driving-specific ones capture motion realistically but lag in visual quality. DrivingGen offers a unified evaluation framework to foster reliable, controllable, and deployable driving world models, enabling scalable simulation, planning, and data-driven decision-making.

</details>


### [36] [A UAV-Based Multispectral and RGB Dataset for Multi-Stage Paddy Crop Monitoring in Indian Agricultural Fields](https://arxiv.org/abs/2601.01084)
*Adari Rama Sukanya,Puvvula Roopesh Naga Sri Sai,Kota Moses,Rimalapudi Sarvendranath*

Main category: cs.CV

TL;DR: 本文介绍了一个大规模无人机采集的水稻田间RGB和多光谱图像数据集，覆盖从育苗到收获的完整生长周期，包含42,430张原始图像和丰富元数据。


<details>
  <summary>Details</summary>
Motivation: 为支持精准农业研究（如靶向喷洒、病害分析和产量估算）提供高质量、高分辨率的水稻生长周期数据集，填补印度水稻作物全生长阶段高分辨率图像数据的空白。

Method: 使用20MP RGB相机和5MP四波段多光谱相机，在5英亩稻田上空按标准操作程序采集数据，地面采样距离为1厘米/像素，并通过Pix4D Fields验证生成正射影像和植被指数图。

Result: 构建了包含415GB原始图像的数据集，提供NDVI和NDRE等植被指数图，数据集已在IEEE DataPort发布并分配DOI。

Conclusion: 该数据集是少数几个覆盖印度水稻作物全生长阶段的高分辨率图像数据集之一，可为精准农业应用提供重要数据支持。

Abstract: We present a large-scale unmanned aerial vehicle (UAV)-based RGB and multispectral image dataset collected over paddy fields in the Vijayawada region, Andhra Pradesh, India, covering nursery to harvesting stages. We used a 20-megapixel RGB camera and a 5-megapixel four-band multispectral camera capturing red, green, red-edge, and near-infrared bands. Standardised operating procedure (SOP) and checklists were developed to ensure repeatable data acquisition. Our dataset comprises of 42,430 raw images (415 GB) captured over 5 acres with 1 cm/pixel ground sampling distance (GSD) with associated metadata such as GPS coordinates, flight altitude, and environmental conditions. Captured images were validated using Pix4D Fields to generate orthomosaic maps and vegetation index maps, such as normalised difference vegetation index (NDVI) and normalised difference red-edge (NDRE) index. Our dataset is one of the few datasets that provide high-resolution images with rich metadata that cover all growth stages of Indian paddy crops. The dataset is available on IEEE DataPort with DOI, . It can support studies on targeted spraying, disease analysis, and yield estimation.

</details>


### [37] [Real-Time Lane Detection via Efficient Feature Alignment and Covariance Optimization for Low-Power Embedded Systems](https://arxiv.org/abs/2601.01696)
*Yian Liu,Xiong Wang,Ping Xu,Lei Zhu,Ming Yan,Linyun Xue*

Main category: cs.CV

TL;DR: 本文提出了一种用于嵌入式系统实时车道检测的协方差分布优化（CDO）模块，该模块通过优化车道特征分布与真实标签的对齐，在不增加计算复杂度的前提下显著提升检测精度。


<details>
  <summary>Details</summary>
Motivation: 嵌入式系统中的实时车道检测面临视觉信号稀疏、计算资源有限和功耗限制等挑战，现有深度学习方法缺乏针对低功耗嵌入式环境的通用优化技术。

Method: 提出CDO模块，通过优化车道特征分布与真实标签的协方差对齐来提升检测精度，该模块易于集成到现有系统中且无需结构修改，利用现有模型参数进行持续训练。

Result: 在CULane、TuSimple和LLAMAS三个数据集上对六种不同模型进行测试，结果显示检测精度提升0.01%到1.5%，同时保持计算效率。

Conclusion: CDO模块为嵌入式系统提供了性能、功耗效率和操作灵活性的显著优势，是一种有效的实时车道检测优化解决方案。

Abstract: Real-time lane detection in embedded systems encounters significant challenges due to subtle and sparse visual signals in RGB images, often constrained by limited computational resources and power consumption. Although deep learning models for lane detection categorized into segmentation-based, anchor-based, and curve-based methods there remains a scarcity of universally applicable optimization techniques tailored for low-power embedded environments. To overcome this, we propose an innovative Covariance Distribution Optimization (CDO) module specifically designed for efficient, real-time applications. The CDO module aligns lane feature distributions closely with ground-truth labels, significantly enhancing detection accuracy without increasing computational complexity. Evaluations were conducted on six diverse models across all three method categories, including two optimized for real-time applications and four state-of-the-art (SOTA) models, tested comprehensively on three major datasets: CULane, TuSimple, and LLAMAS. Experimental results demonstrate accuracy improvements ranging from 0.01% to 1.5%. The proposed CDO module is characterized by ease of integration into existing systems without structural modifications and utilizes existing model parameters to facilitate ongoing training, thus offering substantial benefits in performance, power efficiency, and operational flexibility in embedded systems.

</details>


### [38] [Luminark: Training-free, Probabilistically-Certified Watermarking for General Vision Generative Models](https://arxiv.org/abs/2601.01085)
*Jiayi Xu,Zhang Zhang,Yuanrui Zhang,Ruitao Chen,Yixian Xu,Tianyu He,Di He*

Main category: cs.CV

TL;DR: Luminark是一种无需训练、基于概率认证的水印方法，适用于通用视觉生成模型，通过利用块级亮度统计实现水印嵌入和检测。


<details>
  <summary>Details</summary>
Motivation: 现有水印方法在通用性和认证可靠性方面存在不足，需要一种能够适用于不同生成模型范式且具有概率认证保证的水印技术。

Method: 基于预定义的二进制模式和块级亮度阈值，利用引导技术作为即插即用机制实现水印注入，通过统计分析控制误检率。

Result: 在9个不同框架的生成模型上评估，Luminark表现出高检测精度、对常见图像变换的强鲁棒性以及良好的视觉质量。

Conclusion: Luminark是一种通用、可靠的水印方法，能够在不影响图像质量的前提下为各种生成模型提供认证保护。

Abstract: In this paper, we introduce \emph{Luminark}, a training-free and probabilistically-certified watermarking method for general vision generative models. Our approach is built upon a novel watermark definition that leverages patch-level luminance statistics. Specifically, the service provider predefines a binary pattern together with corresponding patch-level thresholds. To detect a watermark in a given image, we evaluate whether the luminance of each patch surpasses its threshold and then verify whether the resulting binary pattern aligns with the target one. A simple statistical analysis demonstrates that the false positive rate of the proposed method can be effectively controlled, thereby ensuring certified detection. To enable seamless watermark injection across different paradigms, we leverage the widely adopted guidance technique as a plug-and-play mechanism and develop the \emph{watermark guidance}. This design enables Luminark to achieve generality across state-of-the-art generative models without compromising image quality. Empirically, we evaluate our approach on nine models spanning diffusion, autoregressive, and hybrid frameworks. Across all evaluations, Luminark consistently demonstrates high detection accuracy, strong robustness against common image transformations, and good performance on visual quality.

</details>


### [39] [VIT-Ped: Visionary Intention Transformer for Pedestrian Behavior Analysis](https://arxiv.org/abs/2601.01989)
*Aly R. Elkammar,Karim M. Gamaleldin,Catherine M. Elias*

Main category: cs.CV

TL;DR: 本文提出了一种基于transformer/video vision transformer的算法，用于行人意图预测，在JAAD数据集上达到了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 行人意图预测是从L3到L4自动驾驶过渡的关键技术，需要综合考虑多种因素来提升道路安全。

Method: 使用不同规模的transformer/video vision transformer模型，结合多种数据模态进行行人意图预测。

Result: 在JAAD数据集上实现了SOTA性能，在准确率、AUC和F1分数等指标上超越了现有最佳方法。

Conclusion: 通过广泛的消融研究验证了不同模型设计选择的优势。

Abstract: Pedestrian Intention prediction is one of the key technologies in the transition from level 3 to level 4 autonomous driving. To understand pedestrian crossing behaviour, several elements and features should be taken into consideration to make the roads of tomorrow safer for everybody. We introduce a transformer / video vision transformer based algorithm of different sizes which uses different data modalities .We evaluated our algorithms on popular pedestrian behaviour dataset, JAAD, and have reached SOTA performance and passed the SOTA in metrics like Accuracy, AUC and F1-score. The advantages brought by different model design choices are investigated via extensive ablation studies.

</details>


### [40] [600k-ks-ocr: a large-scale synthetic dataset for optical character recognition in kashmiri script](https://arxiv.org/abs/2601.01088)
*Haq Nawaz Malik*

Main category: cs.CV

TL;DR: 本文介绍了600K-KS-OCR数据集，这是一个包含约60.2万个单词级分割图像的大规模合成语料库，专门用于训练和评估针对克什米尔文字的光学字符识别系统。


<details>
  <summary>Details</summary>
Motivation: 解决克什米尔语（一种濒危的达尔德语族语言，使用改良的波斯-阿拉伯文字系统，约700万人使用）OCR研究中的关键资源缺口问题。

Method: 采用三种传统克什米尔字体，结合全面的数据增强技术模拟真实文档退化，并添加多样化背景纹理以增强模型鲁棒性。图像尺寸为256x64像素，提供多种格式的真实转录文本。

Result: 构建了包含约60.2万个单词图像的大规模数据集，分布在10个分区档案中，总计约10.6GB，采用CC-BY-4.0许可发布。

Conclusion: 该数据集为低资源语言光学字符识别研究提供了重要资源，有助于促进克什米尔语OCR技术的发展。

Abstract: This technical report presents the 600K-KS-OCR Dataset, a large-scale synthetic corpus comprising approximately 602,000 word-level segmented images designed for training and evaluating optical character recognition systems targeting Kashmiri script. The dataset addresses a critical resource gap for Kashmiri, an endangered Dardic language utilizing a modified Perso-Arabic writing system spoken by approximately seven million people. Each image is rendered at 256x64 pixels with corresponding ground-truth transcriptions provided in multiple formats compatible with CRNN, TrOCR, and generalpurpose machine learning pipelines. The generation methodology incorporates three traditional Kashmiri typefaces, comprehensive data augmentation simulating real-world document degradation, and diverse background textures to enhance model robustness. The dataset is distributed across ten partitioned archives totaling approximately 10.6 GB and is released under the CC-BY-4.0 license to facilitate research in low-resource language optical character recognition.

</details>


### [41] [NarrativeTrack: Evaluating Video Language Models Beyond the Frame](https://arxiv.org/abs/2601.01095)
*Hyeonjeong Ha,Jinjin Ge,Bo Feng,Kaixin Ma,Gargi Chakraborty*

Main category: cs.CV

TL;DR: NarrativeTrack是首个评估多模态大语言模型视频叙事理解能力的基准，通过细粒度实体中心推理和组合推理进展框架，揭示了模型在实体跟踪和时序推理方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在视频叙事理解方面能力未被充分探索，需要评估模型对动态视觉和时序上下文中实体连贯表示的理解能力。

Method: 提出组合推理进展（CRP）框架，将视频分解为构成实体，通过三个维度逐步增加叙事复杂性：实体存在、实体变化和实体模糊性。使用自动化的实体中心管道提取时序接地实体表示。

Result: 评估显示现有模型无法在视觉转换和时序动态中稳健跟踪实体，经常在上下文变化下产生身份幻觉。开源通用MLLM具有强感知接地但弱时序连贯性，而视频专用MLLM捕获时序上下文但幻觉实体上下文。

Conclusion: 研究发现感知接地和时序推理之间存在基本权衡，叙事理解只能通过两者的整合实现。NarrativeTrack为诊断和推进MLLM的时序接地叙事理解提供了首个系统框架。

Abstract: Multimodal large language models (MLLMs) have achieved impressive progress in vision-language reasoning, yet their ability to understand temporally unfolding narratives in videos remains underexplored. True narrative understanding requires grounding who is doing what, when, and where, maintaining coherent entity representations across dynamic visual and temporal contexts. We introduce NarrativeTrack, the first benchmark to evaluate narrative understanding in MLLMs through fine-grained entity-centric reasoning. Unlike existing benchmarks limited to short clips or coarse scene-level semantics, we decompose videos into constituent entities and examine their continuity via a Compositional Reasoning Progression (CRP), a structured evaluation framework that progressively increases narrative complexity across three dimensions: entity existence, entity changes, and entity ambiguity. CRP challenges models to advance from temporal persistence to contextual evolution and fine-grained perceptual reasoning. A fully automated entity-centric pipeline enables scalable extraction of temporally grounded entity representations, providing the foundation for CRP. Evaluations of state-of-the-art MLLMs reveal that models fail to robustly track entities across visual transitions and temporal dynamics, often hallucinating identity under context shifts. Open-source general-purpose MLLMs exhibit strong perceptual grounding but weak temporal coherence, while video-specific MLLMs capture temporal context yet hallucinate entity's contexts. These findings uncover a fundamental trade-off between perceptual grounding and temporal reasoning, indicating that narrative understanding emerges only from their integration. NarrativeTrack provides the first systematic framework to diagnose and advance temporally grounded narrative comprehension in MLLMs.

</details>


### [42] [Evolving CNN Architectures: From Custom Designs to Deep Residual Models for Diverse Image Classification and Detection Tasks](https://arxiv.org/abs/2601.01099)
*Mahmudul Hasan,Mabsur Fatin Bin Hossain*

Main category: cs.CV

TL;DR: 本文比较了自定义CNN架构与预训练/迁移学习模型在五个真实图像数据集上的性能，分析了网络深度、残差连接等因素的影响，发现深度CNN在细粒度多类任务中表现更好，轻量级预训练模型在简单二分类任务中有效，并展示了架构在目标检测中的适应性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是系统比较自定义CNN架构与预训练/迁移学习模型在不同复杂度图像任务中的性能，为基于任务复杂度和资源约束选择合适的网络设计提供实践指导。

Method: 使用自定义CNN架构与广泛使用的预训练和迁移学习CNN模型，在五个真实图像数据集上进行对比研究，涵盖二分类、细粒度多类识别和目标检测场景，分析网络深度、残差连接和特征提取策略等架构因素的影响。

Result: 结果显示深度CNN架构在细粒度多类数据集上提供显著性能提升，而轻量级预训练和迁移学习模型在简单二分类任务中仍然非常有效。扩展的自定义架构在目标检测场景中成功识别了真实交通场景中的非法三轮车。

Conclusion: 研究通过系统分析自定义CNN架构与预训练/迁移学习模型，为根据任务复杂度和资源约束选择合适网络设计提供了实用指导，强调了深度架构在复杂任务中的优势以及轻量级模型在简单任务中的效率。

Abstract: This paper presents a comparative study of a custom convolutional neural network (CNN) architecture against widely used pretrained and transfer learning CNN models across five real-world image datasets. The datasets span binary classification, fine-grained multiclass recognition, and object detection scenarios. We analyze how architectural factors, such as network depth, residual connections, and feature extraction strategies, influence classification and localization performance. The results show that deeper CNN architectures provide substantial performance gains on fine-grained multiclass datasets, while lightweight pretrained and transfer learning models remain highly effective for simpler binary classification tasks. Additionally, we extend the proposed architecture to an object detection setting, demonstrating its adaptability in identifying unauthorized auto-rickshaws in real-world traffic scenes. Building upon a systematic analysis of custom CNN architectures alongside pretrained and transfer learning models, this study provides practical guidance for selecting suitable network designs based on task complexity and resource constraints.

</details>


### [43] [Histogram Assisted Quality Aware Generative Model for Resolution Invariant NIR Image Colorization](https://arxiv.org/abs/2601.01103)
*Abhinav Attri,Rajeev Ranjan Dwivedi,Samiran Das,Vinod Kumar Kurmi*

Main category: cs.CV

TL;DR: HAQAGen是一个统一的生成模型，用于分辨率不变的红外到RGB彩色化，平衡色彩真实性和结构保真度。


<details>
  <summary>Details</summary>
Motivation: 解决现有NIR-to-RGB转换方法在全局色彩统计和局部色彩一致性、纹理保真度以及高分辨率处理方面的不足。

Method: 引入组合损失函数（可微分直方图匹配、感知图像质量度量、特征相似性）、通过SPADE注入局部色调饱和度先验、在Mamba骨干网络中采用纹理感知监督，以及自适应分辨率推理引擎。

Result: 在FANVID、OMSIV、VCIP2020和RGB2NIR数据集上的广泛评估显示，相比现有方法有显著提升，产生具有更清晰纹理和自然色彩的图像。

Conclusion: HAQAGen是一个可扩展且有效的NIR-to-RGB转换解决方案，适用于多样化的成像场景。

Abstract: We present HAQAGen, a unified generative model for resolution-invariant NIR-to-RGB colorization that balances chromatic realism with structural fidelity. The proposed model introduces (i) a combined loss term aligning the global color statistics through differentiable histogram matching, perceptual image quality measure, and feature based similarity to preserve texture information, (ii) local hue-saturation priors injected via Spatially Adaptive Denormalization (SPADE) to stabilize chromatic reconstruction, and (iii) texture-aware supervision within a Mamba backbone to preserve fine details. We introduce an adaptive-resolution inference engine that further enables high-resolution translation without sacrificing quality. Our proposed NIR-to-RGB translation model simultaneously enforces global color statistics and local chromatic consistency, while scaling to native resolutions without compromising texture fidelity or generalization. Extensive evaluations on FANVID, OMSIV, VCIP2020, and RGB2NIR using different evaluation metrics demonstrate consistent improvements over state-of-the-art baseline methods. HAQAGen produces images with sharper textures, natural colors, attaining significant gains as per perceptual metrics. These results position HAQAGen as a scalable and effective solution for NIR-to-RGB translation across diverse imaging scenarios. Project Page: https://rajeev-dw9.github.io/HAQAGen/

</details>


### [44] [Cross-Layer Attentive Feature Upsampling for Low-latency Semantic Segmentation](https://arxiv.org/abs/2601.01167)
*Tianheng Cheng,Xinggang Wang,Junchao Liao,Wenyu Liu*

Main category: cs.CV

TL;DR: 提出了一种新的引导注意力插值（GAI）方法，用于高效语义分割，能够自适应地插值细粒度高分辨率特征，在保持低延迟的同时实现最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于坐标引导的低分辨率特征插值方法（如双线性插值）产生的高分辨率特征存在特征不对齐和上下文信息不足的问题，且语义丰富化计算负担大，难以满足低延迟推理需求。

Method: 提出引导注意力插值（GAI）方法，通过确定不同分辨率特征中像素的空间和语义关系，利用这些关系来插值具有丰富语义的高分辨率特征。GAI可与任何深度卷积网络集成。

Result: 基于GAI的语义分割网络GAIN在Cityscapes上达到78.8 mIoU和22.3 FPS，在CamVid上达到80.6 mIoU和64.5 FPS（使用NVIDIA 1080Ti GPU），创下低延迟语义分割的最新最先进结果。

Conclusion: GAI方法有效解决了语义分割中高分辨率特征插值的挑战，在保持低延迟的同时显著提升了分割性能，为实时语义分割应用提供了实用解决方案。

Abstract: Semantic segmentation is a fundamental problem in computer vision and it requires high-resolution feature maps for dense prediction. Current coordinate-guided low-resolution feature interpolation methods, e.g., bilinear interpolation, produce coarse high-resolution features which suffer from feature misalignment and insufficient context information. Moreover, enriching semantics to high-resolution features requires a high computation burden, so that it is challenging to meet the requirement of lowlatency inference. We propose a novel Guided Attentive Interpolation (GAI) method to adaptively interpolate fine-grained high-resolution features with semantic features to tackle these issues. Guided Attentive Interpolation determines both spatial and semantic relations of pixels from features of different resolutions and then leverages these relations to interpolate high-resolution features with rich semantics. GAI can be integrated with any deep convolutional network for efficient semantic segmentation. In experiments, the GAI-based semantic segmentation networks, i.e., GAIN, can achieve78.8 mIoU with 22.3 FPS on Cityscapes and 80.6 mIoU with 64.5 on CamVid using an NVIDIA 1080Ti GPU, which are the new state-of-the-art results of low-latency semantic segmentation. Code and models are available at: https://github.com/hustvl/simpleseg.

</details>


### [45] [CardioMOD-Net: A Modal Decomposition-Neural Network Framework for Diagnosis and Prognosis of HFpEF from Echocardiography Cine Loops](https://arxiv.org/abs/2601.01176)
*Andrés Bell-Navas,Jesús Garicano-Mena,Antonella Ausiello,Soledad Le Clainche,María Villalba-Orero,Enrique Lara-Pezzi*

Main category: cs.CV

TL;DR: 开发了CardioMOD-Net AI框架，使用小鼠超声心动图视频进行多类别诊断和连续预测HFpEF发病时间，准确率65%，预测误差21.72周


<details>
  <summary>Details</summary>
Motivation: 当前基于超声心动图的AI模型主要关注二分类HFpEF检测，无法提供合并症特异性表型分析或疾病进展的时间估计，需要开发统一框架进行多类别诊断和连续预测

Method: 使用小鼠超声心动图视频（对照组、高血糖组、肥胖组、系统性动脉高血压组），通过高阶动态模式分解提取时间特征，使用共享潜在表征支持视觉变换器进行分类和回归分析

Result: 四组总体诊断准确率65%，所有类别准确率超过50%；预后模块预测HFpEF发病时间的均方根误差为21.72周，肥胖组和高血压组预测最准确

Conclusion: 该统一框架证明即使在小数据条件下，也能从单一超声心动图视频中获得多类别表型分析和连续HFpEF发病预测，为临床前HFpEF研究整合诊断和预后建模奠定基础

Abstract: Introduction: Heart failure with preserved ejection fraction (HFpEF) arises from diverse comorbidities and progresses through prolonged subclinical stages, making early diagnosis and prognosis difficult. Current echocardiography-based Artificial Intelligence (AI) models focus primarily on binary HFpEF detection in humans and do not provide comorbidity-specific phenotyping or temporal estimates of disease progression towards decompensation. We aimed to develop a unified AI framework, CardioMOD-Net, to perform multiclass diagnosis and continuous prediction of HFpEF onset directly from standard echocardiography cine loops in preclinical models.
  Methods: Mouse echocardiography videos from four groups were used: control (CTL), hyperglycaemic (HG), obesity (OB), and systemic arterial hypertension (SAH). Two-dimensional parasternal long-axis cine loops were decomposed using Higher Order Dynamic Mode Decomposition (HODMD) to extract temporal features for downstream analysis. A shared latent representation supported Vision Transformers, one for a classifier for diagnosis and another for a regression module for predicting the age at HFpEF onset.
  Results: Overall diagnostic accuracy across the four groups was 65%, with all classes exceeding 50% accuracy. Misclassifications primarily reflected early-stage overlap between OB or SAH and CTL. The prognostic module achieved a root-mean-square error of 21.72 weeks for time-to-HFpEF prediction, with OB and SAH showing the most accurate estimates. Predicted HFpEF onset closely matched true distributions in all groups.
  Discussion: This unified framework demonstrates that multiclass phenotyping and continuous HFpEF onset prediction can be obtained from a single cine loop, even under small-data conditions. The approach offers a foundation for integrating diagnostic and prognostic modelling in preclinical HFpEF research.

</details>


### [46] [GenCAMO: Scene-Graph Contextual Decoupling for Environment-aware and Mask-free Camouflage Image-Dense Annotation Generation](https://arxiv.org/abs/2601.01181)
*Chenglizhao Chen,Shaojiang Yuan,Xiaoxue Lu,Mengke Song,Jia Song,Zhenyu Wu,Wenfeng Song,Shuai Li*

Main category: cs.CV

TL;DR: 本文提出GenCAMO-DB数据集和GenCAMO生成框架，通过生成模型合成高质量伪装图像-密集标注数据，解决伪装密集预测任务中数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 伪装密集预测任务面临高质量大规模标注数据稀缺的挑战，主要由于数据收集和标注成本高昂。

Method: 提出GenCAMO-DB大规模多模态伪装数据集和GenCAMO环境感知、无需掩码的生成框架，能够生成高保真伪装图像及密集标注。

Result: 跨多个模态的实验表明，GenCAMO通过提供高质量合成数据，显著提升了复杂伪装场景下的密集预测性能。

Conclusion: 生成模型能够有效解决伪装密集预测任务中的数据稀缺问题，为复杂伪装场景的理解和推理提供有力支持。

Abstract: Conceal dense prediction (CDP), especially RGB-D camouflage object detection and open-vocabulary camouflage object segmentation, plays a crucial role in advancing the understanding and reasoning of complex camouflage scenes. However, high-quality and large-scale camouflage datasets with dense annotation remain scarce due to expensive data collection and labeling costs. To address this challenge, we explore leveraging generative models to synthesize realistic camouflage image-dense data for training CDP models with fine-grained representations, prior knowledge, and auxiliary reasoning. Concretely, our contributions are threefold: (i) we introduce GenCAMO-DB, a large-scale camouflage dataset with multi-modal annotations, including depth maps, scene graphs, attribute descriptions, and text prompts; (ii) we present GenCAMO, an environment-aware and mask-free generative framework that produces high-fidelity camouflage image-dense annotations; (iii) extensive experiments across multiple modalities demonstrate that GenCAMO significantly improves dense prediction performance on complex camouflage scenes by providing high-quality synthetic data. The code and datasets will be released after paper acceptance.

</details>


### [47] [Crowded Video Individual Counting Informed by Social Grouping and Spatial-Temporal Displacement Priors](https://arxiv.org/abs/2601.01192)
*Hao Lu,Xuhui Zhu,Wenjing Zhang,Yanan Li,Xiang Bai*

Main category: cs.CV

TL;DR: 该论文提出了OMAN++方法，通过引入群体分组先验和时空位移先验，将标准的一对一匹配放宽为一对多匹配，显著提升了拥挤场景下的视频个体计数性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频个体计数方法在拥挤场景（如地铁通勤）中表现不佳，需要开发能够处理密集动态人流的新方法。

Method: 提出OMAN++框架，包含隐式上下文生成器、一对多匹配器和位移先验注入器，利用社会分组先验和时空位移先验来改进特征提取和模型训练。

Result: OMAN++在标准基准测试上优于现有方法，在拥挤的WuhanMetroCrowd数据集上误差降低38.12%。

Conclusion: 该方法通过引入两个关键先验和一对多匹配策略，为拥挤场景下的视频个体计数提供了新的强基线。

Abstract: Video Individual Counting (VIC) is a recently introduced task aiming to estimate pedestrian flux from a video. It extends Video Crowd Counting (VCC) beyond the per-frame pedestrian count. In contrast to VCC that learns to count pedestrians across frames, VIC must identify co-existent pedestrians between frames, which turns out to be a correspondence problem. Existing VIC approaches, however, can underperform in congested scenes such as metro commuting. To address this, we build WuhanMetroCrowd, one of the first VIC datasets that characterize crowded, dynamic pedestrian flows. It features sparse-to-dense density levels, short-to-long video clips, slow-to-fast flow variations, front-to-back appearance changes, and light-to-heavy occlusions. To better adapt VIC approaches to crowds, we rethink the nature of VIC and recognize two informative priors: i) the social grouping prior that indicates pedestrians tend to gather in groups and ii) the spatial-temporal displacement prior that informs an individual cannot teleport physically. The former inspires us to relax the standard one-to-one (O2O) matching used by VIC to one-to-many (O2M) matching, implemented by an implicit context generator and a O2M matcher; the latter facilitates the design of a displacement prior injector, which strengthens not only O2M matching but also feature extraction and model training. These designs jointly form a novel and strong VIC baseline OMAN++. Extensive experiments show that OMAN++ not only outperforms state-of-the-art VIC baselines on the standard SenseCrowd, CroHD, and MovingDroneCrowd benchmarks, but also indicates a clear advantage in crowded scenes, with a 38.12% error reduction on our WuhanMetroCrowd dataset. Code, data, and pretrained models are available at https://github.com/tiny-smart/OMAN.

</details>


### [48] [MS-ISSM: Objective Quality Assessment of Point Clouds Using Multi-scale Implicit Structural Similarity](https://arxiv.org/abs/2601.01200)
*Zhang Chen,Shuai Wan,Yuezhe Zhang,Siyu Ren,Fuzheng Yang,Junhui Hou*

Main category: cs.CV

TL;DR: 提出MS-ISSM方法，通过径向基函数表示局部特征，将点云质量评估转化为隐式函数系数比较，避免不规则数据的匹配误差。结合ResGrouped-MLP网络，在多尺度上映射特征差异到感知分数。


<details>
  <summary>Details</summary>
Motivation: 点云的非结构化和不规则特性给质量评估带来挑战，特别是难以建立准确的感知特征对应关系。传统点对点匹配方法存在匹配误差问题。

Method: 使用径向基函数(RBF)连续表示局部特征，提出多尺度隐式结构相似性测量(MS-ISSM)。设计ResGrouped-MLP质量评估网络，采用分组编码策略结合残差块和通道注意力机制。

Result: 在多个基准测试中，MS-ISSM在可靠性和泛化性方面优于现有最先进的指标。

Conclusion: 该方法有效解决了点云质量评估中的特征匹配问题，通过隐式函数表示和分层网络设计，实现了更准确的质量评估。

Abstract: The unstructured and irregular nature of point clouds poses a significant challenge for objective quality assessment (PCQA), particularly in establishing accurate perceptual feature correspondence. To tackle this, we propose the Multi-scale Implicit Structural Similarity Measurement (MS-ISSM). Unlike traditional point-to-point matching, MS-ISSM utilizes Radial Basis Functions (RBF) to represent local features continuously, transforming distortion measurement into a comparison of implicit function coefficients. This approach effectively circumvents matching errors inherent in irregular data. Additionally, we propose a ResGrouped-MLP quality assessment network, which robustly maps multi-scale feature differences to perceptual scores. The network architecture departs from traditional flat MLPs by adopting a grouped encoding strategy integrated with Residual Blocks and Channel-wise Attention mechanisms. This hierarchical design allows the model to preserve the distinct physical semantics of luma, chroma, and geometry while adaptively focusing on the most salient distortion features across High, Medium, and Low scales. Experimental results on multiple benchmarks demonstrate that MS-ISSM outperforms state-of-the-art metrics in both reliability and generalization. The source code is available at: https://github.com/ZhangChen2022/MS-ISSM.

</details>


### [49] [RefSR-Adv: Adversarial Attack on Reference-based Image Super-Resolution Models](https://arxiv.org/abs/2601.01202)
*Jiazhu Dai,Huihui Jiang*

Main category: cs.CV

TL;DR: 本文提出了RefSR-Adv攻击方法，通过仅扰动参考图像来降低基于参考的超分辨率系统的性能，揭示了RefSR模型对参考特征的过度依赖是一个关键安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注RefSR的后门攻击，而其对抗攻击的脆弱性尚未得到充分探索。本文旨在填补这一研究空白，揭示RefSR系统的安全漏洞。

Method: 提出RefSR-Adv对抗攻击方法，通过最大化对抗输出与干净输出之间的差异，仅对参考图像进行扰动来降低超分辨率输出质量。

Result: 实验表明，RefSR-Adv在CNN、Transformer和Mamba架构上都能引起显著性能下降和严重伪影，且攻击效果与低分辨率输入和参考图像的相似度呈正相关。

Conclusion: 本研究揭示了RefSR系统的安全脆弱性，呼吁研究者关注RefSR的鲁棒性问题，模型对参考特征的过度依赖是主要安全缺陷。

Abstract: Single Image Super-Resolution (SISR) aims to recover high-resolution images from low-resolution inputs. Unlike SISR, Reference-based Super-Resolution (RefSR) leverages an additional high-resolution reference image to facilitate the recovery of high-frequency textures. However, existing research mainly focuses on backdoor attacks targeting RefSR, while the vulnerability of the adversarial attacks targeting RefSR has not been fully explored. To fill this research gap, we propose RefSR-Adv, an adversarial attack that degrades SR outputs by perturbing only the reference image. By maximizing the difference between adversarial and clean outputs, RefSR-Adv induces significant performance degradation and generates severe artifacts across CNN, Transformer, and Mamba architectures on the CUFED5, WR-SR, and DRefSR datasets. Importantly, experiments confirm a positive correlation between the similarity of the low-resolution input and the reference image and attack effectiveness, revealing that the model's over-reliance on reference features is a key security flaw. This study reveals a security vulnerability in RefSR systems, aiming to urge researchers to pay attention to the robustness of RefSR.

</details>


### [50] [XStreamVGGT: Extremely Memory-Efficient Streaming Vision Geometry Grounded Transformer with KV Cache Compression](https://arxiv.org/abs/2601.01204)
*Zunhai Su,Weihao Ye,Hansen Feng,Keyu Fan,Jing Zhang,Dahai Yu,Zhengwu Liu,Ngai Wong*

Main category: cs.CV

TL;DR: XStreamVGGT通过联合剪枝和量化技术压缩KV缓存，解决了StreamVGGT在流式3D重建中KV缓存无限增长导致的内存消耗和推理延迟问题，实现了高效的内存优化和推理加速。


<details>
  <summary>Details</summary>
Motivation: 现有的StreamVGGT模型虽然利用帧间因果注意力实现了强大的流式重建能力，但随着输入帧数的增加，KV缓存会无限增长，导致内存消耗和推理延迟急剧上升，限制了实际应用的可扩展性。

Method: 提出了一种无需调优的方法，通过联合剪枝和量化来系统性地压缩KV缓存。具体包括：1）通过高效的token重要性识别来剪枝来自多视角输入的冗余KV，实现固定内存预算；2）利用KV张量的独特分布特性，引入KV量化进一步降低内存消耗。

Result: 广泛评估表明，XStreamVGGT在性能损失可忽略的情况下，显著减少了4.42倍的内存使用量，并加速了5.48倍的推理速度，实现了可扩展和实用的流式3D应用。

Conclusion: XStreamVGGT通过有效的KV缓存压缩技术，成功解决了流式3D视觉几何模型中的内存效率问题，为大规模流式应用提供了实用的解决方案。

Abstract: Learning-based 3D visual geometry models have benefited substantially from large-scale transformers. Among these, StreamVGGT leverages frame-wise causal attention for strong streaming reconstruction, but suffers from unbounded KV cache growth, leading to escalating memory consumption and inference latency as input frames accumulate. We propose XStreamVGGT, a tuning-free approach that systematically compresses the KV cache through joint pruning and quantization, enabling extremely memory-efficient streaming inference. Specifically, redundant KVs originating from multi-view inputs are pruned through efficient token importance identification, enabling a fixed memory budget. Leveraging the unique distribution of KV tensors, we incorporate KV quantization to further reduce memory consumption. Extensive evaluations show that XStreamVGGT achieves mostly negligible performance degradation while substantially reducing memory usage by 4.42$\times$ and accelerating inference by 5.48$\times$, enabling scalable and practical streaming 3D applications. The code is available at https://github.com/ywh187/XStreamVGGT/.

</details>


### [51] [Promptable Foundation Models for SAR Remote Sensing: Adapting the Segment Anything Model for Snow Avalanche Segmentation](https://arxiv.org/abs/2601.01213)
*Riccardo Gelato,Carlo Sgaravatti,Jakob Grahn,Giacomo Boracchi,Filippo Maria Bianchi*

Main category: cs.CV

TL;DR: 该研究针对SAR图像雪崩标注任务，基于Segment Anything Model (SAM)进行领域适配，通过适配器、多编码器、提示工程和高效训练算法解决领域差异、多通道输入、提示不精确和计算效率等问题，开发出能加速SAR图像标注的工具。


<details>
  <summary>Details</summary>
Motivation: 合成孔径雷达(SAR)图像可用于雪崩检测，但高质量标注需要领域专家且耗时。研究旨在利用基础分割模型SAM来加速SAR图像的雪崩标注过程。

Method: 1) 使用适配器缓解SAM与SAR图像的领域差异；2) 多编码器处理多通道SAR输入；3) 提示工程策略提高雪崩定位精度；4) 限制编码器训练时间的高效训练算法。

Result: 将优化后的模型集成到标注工具中，实验证明能够显著加速SAR图像的标注过程。

Conclusion: 通过领域适配的SAM模型可以有效解决SAR图像雪崩标注的挑战，为山区风险预测和减灾提供高效的技术支持。

Abstract: Remote sensing solutions for avalanche segmentation and mapping are key to supporting risk forecasting and mitigation in mountain regions. Synthetic Aperture Radar (SAR) imagery from Sentinel-1 can be effectively used for this task, but training an effective detection model requires gathering a large dataset with high-quality annotations from domain experts, which is prohibitively time-consuming. In this work, we aim to facilitate and accelerate the annotation of SAR images for avalanche mapping. We build on the Segment Anything Model (SAM), a segmentation foundation model trained on natural images, and tailor it to Sentinel-1 SAR data. Adapting SAM to our use-case requires addressing several domain-specific challenges: (i) domain mismatch, since SAM was not trained on satellite/SAR imagery; (ii) input adaptation, because SAR products typically provide more than three channels, while SAM is constrained to RGB images; (iii) robustness to imprecise prompts that can affect target identification and degrade the segmentation quality, an issue exacerbated in small, low-contrast avalanches; and (iv) training efficiency, since standard fine-tuning is computationally demanding for SAM. We tackle these challenges through a combination of adapters to mitigate the domain gap, multiple encoders to handle multi-channel SAR inputs, prompt-engineering strategies to improve avalanche localization accuracy, and a training algorithm that limits the training time of the encoder, which is recognized as the major bottleneck. We integrate the resulting model into an annotation tool and show experimentally that it speeds up the annotation of SAR images.

</details>


### [52] [UniSH: Unifying Scene and Human Reconstruction in a Feed-Forward Pass](https://arxiv.org/abs/2601.01222)
*Mengfei Li,Peng Li,Zheng Zhang,Jiahao Lu,Chengfeng Zhao,Wei Xue,Qifeng Liu,Sida Peng,Wenxiao Zhang,Wenhan Luo,Yuan Liu,Yike Guo*

Main category: cs.CV

TL;DR: UniSH是一个统一的端到端框架，用于联合重建度量尺度的3D场景和人体，通过创新的训练范式解决合成数据到真实数据的领域差距问题。


<details>
  <summary>Details</summary>
Motivation: 当前领域面临的主要挑战是缺乏大规模标注的真实世界数据，导致依赖合成数据集，从而产生显著的sim-to-real领域差距，表现为泛化能力差、人体几何细节低质量以及野外视频中的对齐问题。

Method: 提出包含两个核心组件的训练范式：(1) 通过从专家深度模型蒸馏高频细节来优化人体表面细节的鲁棒蒸馏策略；(2) 两阶段监督方案，先在合成数据上学习粗略定位，然后在真实数据上通过直接优化SMPL网格与人体点云之间的几何对应关系进行微调。

Result: 实验表明，该模型在人体中心场景重建方面达到最先进性能，在全局人体运动估计方面取得极具竞争力的结果，优于基于优化的框架和仅使用HMR的方法。

Conclusion: UniSH框架能够在单次前向传播中联合恢复高保真场景几何、人体点云、相机参数和连贯的度量尺度SMPL人体，有效解决了合成数据到真实数据的领域差距问题。

Abstract: We present UniSH, a unified, feed-forward framework for joint metric-scale 3D scene and human reconstruction. A key challenge in this domain is the scarcity of large-scale, annotated real-world data, forcing a reliance on synthetic datasets. This reliance introduces a significant sim-to-real domain gap, leading to poor generalization, low-fidelity human geometry, and poor alignment on in-the-wild videos. To address this, we propose an innovative training paradigm that effectively leverages unlabeled in-the-wild data. Our framework bridges strong, disparate priors from scene reconstruction and HMR, and is trained with two core components: (1) a robust distillation strategy to refine human surface details by distilling high-frequency details from an expert depth model, and (2) a two-stage supervision scheme, which first learns coarse localization on synthetic data, then fine-tunes on real data by directly optimizing the geometric correspondence between the SMPL mesh and the human point cloud. This approach enables our feed-forward model to jointly recover high-fidelity scene geometry, human point clouds, camera parameters, and coherent, metric-scale SMPL bodies, all in a single forward pass. Extensive experiments demonstrate that our model achieves state-of-the-art performance on human-centric scene reconstruction and delivers highly competitive results on global human motion estimation, comparing favorably against both optimization-based frameworks and HMR-only methods. Project page: https://murphylmf.github.io/UniSH/

</details>


### [53] [Improved Object-Centric Diffusion Learning with Registers and Contrastive Alignment](https://arxiv.org/abs/2601.01224)
*Bac Nguyen,Yuhta Takida,Naoki Murata,Chieh-Hsin Lai,Toshimitsu Uesaka,Stefano Ermon,Yuki Mitsufuji*

Main category: cs.CV

TL;DR: CODA通过引入寄存器槽和对比对齐损失，解决了Slot Attention在对象中心学习中的槽纠缠和对齐问题，显著提升了对象发现和图像生成性能。


<details>
  <summary>Details</summary>
Motivation: 现有的Slot Attention方法在使用预训练扩散模型进行对象中心学习时存在槽纠缠和槽-图像内容对齐弱的问题，影响了模型性能。

Method: 提出CODA方法：1）使用寄存器槽吸收残差注意力，减少对象槽之间的干扰；2）应用对比对齐损失显式增强槽-图像对应关系。

Result: 在合成数据集（MOVi-C/E）和真实数据集（VOC、COCO）上，CODA在对象发现（如COCO上FG-ARI提升6.1%）、属性预测和组合图像生成方面均优于强基线方法。

Conclusion: CODA作为一种高效可扩展的框架，在复杂真实场景中具有鲁棒对象中心学习的应用潜力，寄存器槽仅增加可忽略的开销。

Abstract: Slot Attention (SA) with pretrained diffusion models has recently shown promise for object-centric learning (OCL), but suffers from slot entanglement and weak alignment between object slots and image content. We propose Contrastive Object-centric Diffusion Alignment (CODA), a simple extension that (i) employs register slots to absorb residual attention and reduce interference between object slots, and (ii) applies a contrastive alignment loss to explicitly encourage slot-image correspondence. The resulting training objective serves as a tractable surrogate for maximizing mutual information (MI) between slots and inputs, strengthening slot representation quality. On both synthetic (MOVi-C/E) and real-world datasets (VOC, COCO), CODA improves object discovery (e.g., +6.1% FG-ARI on COCO), property prediction, and compositional image generation over strong baselines. Register slots add negligible overhead, keeping CODA efficient and scalable. These results indicate potential applications of CODA as an effective framework for robust OCL in complex, real-world scenes.

</details>


### [54] [HyDRA: Hybrid Denoising Regularization for Measurement-Only DEQ Training](https://arxiv.org/abs/2601.01228)
*Markus Haltmeier,Lukas Neumann,Nadja Gruber,Johannes Schwab,Gyeongha Hwang*

Main category: cs.CV

TL;DR: HyDRA是一个仅使用测量数据的深度均衡模型训练框架，结合测量一致性和自适应去噪正则化，无需监督数据对即可实现图像重建。


<details>
  <summary>Details</summary>
Motivation: 解决图像重建问题面临病态性和缺乏大规模监督数据集的挑战，特别是在实际场景中往往只有测量数据而缺乏监督对。

Method: 提出HyDRA框架，将测量一致性与自适应去噪正则化项结合，并采用数据驱动的早停准则，实现仅使用测量数据的DEQ模型训练。

Result: 在稀疏视角CT上的实验表明，该方法实现了具有竞争力的重建质量和快速推理速度。

Conclusion: HyDRA为缺乏监督数据的图像重建问题提供了一种有效的解决方案，在保持重建质量的同时实现了快速推理。

Abstract: Solving image reconstruction problems of the form \(\mathbf{A} \mathbf{x} = \mathbf{y}\) remains challenging due to ill-posedness and the lack of large-scale supervised datasets. Deep Equilibrium (DEQ) models have been used successfully but typically require supervised pairs \((\mathbf{x},\mathbf{y})\). In many practical settings, only measurements \(\mathbf{y}\) are available. We introduce HyDRA (Hybrid Denoising Regularization Adaptation), a measurement-only framework for DEQ training that combines measurement consistency with an adaptive denoising regularization term, together with a data-driven early stopping criterion. Experiments on sparse-view CT demonstrate competitive reconstruction quality and fast inference.

</details>


### [55] [RFAssigner: A Generic Label Assignment Strategy for Dense Object Detection](https://arxiv.org/abs/2601.01240)
*Ziqian Guan,Xieyi Fu,Yuting Wang,Haowen Xiao,Jiarui Zhu,Yingying Zhu,Yongtao Liu,Lin Gu*

Main category: cs.CV

TL;DR: RFAssigner是一种新颖的标签分配策略，通过高斯感受野距离度量候选位置与真实目标的相似性，自适应选择补充正样本，解决小目标正样本不足导致的尺度不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有密集目标检测器的标签分配策略通常为每个训练样本分配正负权重，但这种方法往往无法为小目标分配足够的正样本，导致训练过程中的尺度不平衡。

Method: RFAssigner首先使用基于点的先验建立初始正样本集，然后利用高斯感受野距离度量未分配候选位置与真实目标的相似性，从候选池中自适应选择补充正样本。

Result: 在三个具有不同目标尺度分布的数据集上的实验验证了该方法的有效性，FCOS-ResNet-50检测器配备RFAssigner在所有目标尺度上都达到了最先进性能。

Conclusion: RFAssigner能够有效提升密集检测器的多尺度学习能力，无需辅助模块或启发式方法即可实现优于现有策略的性能。

Abstract: Label assignment is a critical component in training dense object detectors. State-of-the-art methods typically assign each training sample a positive and a negative weight, optimizing the assignment scheme during training. However, these strategies often assign an insufficient number of positive samples to small objects, leading to a scale imbalance during training. To address this limitation, we introduce RFAssigner, a novel assignment strategy designed to enhance the multi-scale learning capabilities of dense detectors. RFAssigner first establishes an initial set of positive samples using a point-based prior. It then leverages a Gaussian Receptive Field (GRF) distance to measure the similarity between the GRFs of unassigned candidate locations and the ground-truth objects. Based on this metric, RFAssigner adaptively selects supplementary positive samples from the unassigned pool, promoting a more balanced learning process across object scales. Comprehensive experiments on three datasets with distinct object scale distributions validate the effectiveness and generalizability of our method. Notably, a single FCOS-ResNet-50 detector equipped with RFAssigner achieves state-of-the-art performance across all object scales, consistently outperforming existing strategies without requiring auxiliary modules or heuristics.

</details>


### [56] [MambaFormer: Token-Level Guided Routing Mixture-of-Experts for Accurate and Efficient Clinical Assistance](https://arxiv.org/abs/2601.01260)
*Hamad Khan,Saddam Hussain Khan*

Main category: cs.CV

TL;DR: 提出MambaFormer混合专家框架，通过动态路由机制在Transformer专家和状态空间模型专家之间智能分配任务，实现医疗问答的高效推理


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在临床应用中计算成本与效率之间的权衡问题

Method: 采用轻量级门控机制进行token级动态路由，定制化ET5和EMamba专家模型，通过多目标损失函数联合优化路由决策和计算成本

Result: 在DentalQA和PubMedQA数据集上表现优异（BERTScore=0.9180），推理延迟极低（0.077秒），比T5-Large快24.4倍

Conclusion: MambaFormer为资源受限的临床部署提供了可扩展的高效解决方案

Abstract: The deployment of large language models (LLMs) in real-world clinical applications is constrained by the fundamental trade-off between computational cost and the efficiency of linear-time models. To address this, we propose an LLM-based MambaFormer hybrid Mixture-of-Experts (MoE) framework for efficient medical question-answering (QA) and clinical assistance. The MambaFormer employs a lightweight gating mechanism that performs token-level dynamic routing to a customized Transformer expert (ET5) for short, complex queries or to a State Space Model expert (EMamba) for long, high-throughput sequences. The customized EMamba and ET5 models are tailored to accommodate input sequence dimensionality, embedding structure, sequence length, and target-specific output heads, and are fine-tuned through transfer learning on a new, custom-designed DentalQA dataset. Moreover, intelligent routing decisions are driven by the contextual complexity of token embeddings, normalized sequence length, and domain-aware features, thereby enforcing a Pareto-optimal trade-off between inference latency and prediction accuracy. Furthermore, a novel utility-guided multi-objective loss jointly optimizes decisions, router parameters, routing behavior, expert utilization, and computational cost by adaptively regulating token-level expert activation. Finally, the proposed MambaFormer is cross-validated (holdout) for medical QA on the new, custom-designed DentalQA and PubMedQA datasets and compared with state-of-the-art techniques. The proposed MambaFormer outperforms (BERTScore = 0.9180) with ultra-low latency (0.077 s), delivering a 24.4 speedup over T5-Large and establishing a scalable solution for resource-constrained clinical deployment.

</details>


### [57] [AI-Powered Deepfake Detection Using CNN and Vision Transformer Architectures](https://arxiv.org/abs/2601.01281)
*Sifatullah Sheikh Urmi,Kirtonia Nuzath Tabassum Arthi,Md Al-Imran*

Main category: cs.CV

TL;DR: 本文评估了四种AI模型（三种CNN和一种Vision Transformer）在深度伪造检测中的性能，发现VFDNET与MobileNetV3结合表现最佳，证明了AI在可靠深度伪造检测方面的能力。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能生成的深度伪造技术日益普及，维护数字真实性面临重大挑战，需要开发可靠的检测方法。

Method: 使用大型人脸图像数据集评估了四种基于AI的模型（三种CNN和一种Vision Transformer），并采用数据预处理和增强技术来提高模型在不同场景下的性能。

Result: VFDNET与MobileNetV3结合显示出卓越的准确性和高效性能，在所有测试模型中表现最优。

Conclusion: 研究表明AI技术具备可靠深度伪造检测的能力，数据预处理和增强技术对提升模型性能至关重要。

Abstract: The increasing use of artificial intelligence generated deepfakes creates major challenges in maintaining digital authenticity. Four AI-based models, consisting of three CNNs and one Vision Transformer, were evaluated using large face image datasets. Data preprocessing and augmentation techniques improved model performance across different scenarios. VFDNET demonstrated superior accuracy with MobileNetV3, showing efficient performance, thereby demonstrating AI's capabilities for dependable deepfake detection.

</details>


### [58] [S2M-Net: Spectral-Spatial Mixing for Medical Image Segmentation with Morphology-Aware Adaptive Loss](https://arxiv.org/abs/2601.01285)
*Md. Sanaullah Chowdhury Lameya Sabrin*

Main category: cs.CV

TL;DR: S2M-Net是一个4.7M参数的医学图像分割架构，通过频谱选择性令牌混合器和形态感知自适应分割损失，在保持全局上下文的同时实现高效计算，在16个医学影像数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像分割中的三难问题：局部精度、全局上下文和计算效率的平衡。传统CNN局部精度好但感受野有限，ViT全局上下文强但计算成本高且容易在小数据集上过拟合。

Method: 提出SSTM模块利用医学图像的频谱特性，通过截断2D FFT和可学习频率滤波实现O(HW log HW)的全局上下文；MASL损失函数自动分析结构特征来调制五个互补损失分量。

Result: 在16个医学影像数据集上表现优异：息肉分割96.12% Dice，手术器械83.77%（比之前最佳提升17.85%），脑肿瘤80.90%，相比专用基线一致提升3-18%，参数比基于Transformer的方法少3.5-6倍。

Conclusion: S2M-Net成功解决了医学图像分割的三难问题，在保持高精度的同时显著降低了计算成本，为临床部署提供了实用解决方案。

Abstract: Medical image segmentation requires balancing local precision for boundary-critical clinical applications, global context for anatomical coherence, and computational efficiency for deployment on limited data and hardware a trilemma that existing architectures fail to resolve. Although convolutional networks provide local precision at $\mathcal{O}(n)$ cost but limited receptive fields, vision transformers achieve global context through $\mathcal{O}(n^2)$ self-attention at prohibitive computational expense, causing overfitting on small clinical datasets. We propose S2M-Net, a 4.7M-parameter architecture that achieves $\mathcal{O}(HW \log HW)$ global context through two synergistic innovations: (i) Spectral-Selective Token Mixer (SSTM), which exploits the spectral concentration of medical images via truncated 2D FFT with learnable frequency filtering and content-gated spatial projection, avoiding quadratic attention cost while maintaining global receptive fields; and (ii) Morphology-Aware Adaptive Segmentation Loss (MASL), which automatically analyzes structure characteristics (compactness, tubularity, irregularity, scale) to modulate five complementary loss components through constrained learnable weights, eliminating manual per-dataset tuning. Comprehensive evaluation in 16 medical imaging datasets that span 8 modalities demonstrates state-of-the-art performance: 96.12\% Dice on polyp segmentation, 83.77\% on surgical instruments (+17.85\% over the prior art) and 80.90\% on brain tumors, with consistent 3-18\% improvements over specialized baselines while using 3.5--6$\times$ fewer parameters than transformer-based methods.

</details>


### [59] [VReID-XFD: Video-based Person Re-identification at Extreme Far Distance Challenge Results](https://arxiv.org/abs/2601.01312)
*Kailash A. Hambarde,Hugo Proença,Md Rashidunnabi,Pranita Samale,Qiwei Yang,Pingping Zhang,Zijing Gong,Yuhao Wang,Xi Zhang,Ruoshui Qu,Qiaoyun He,Yuhang Zhang,Thi Ngoc Ha Nguyen,Tien-Dung Mai,Cheng-Jun Kang,Yu-Fan Lin,Jin-Hui Jiang,Chih-Chung Hsu,Tamás Endrei,György Cserey,Ashwat Rajbhandari*

Main category: cs.CV

TL;DR: 本文提出了VReID-XFD，一个用于极端远距离（XFD）空中到地面人员重识别的视频基准和社区挑战，分析了在严重分辨率退化、极端视角变化等挑战下的性能表现。


<details>
  <summary>Details</summary>
Motivation: 现有的人员重识别系统基于外观假设，但在极端远距离的空中到地面场景中，严重分辨率退化、极端视角变化、不稳定运动线索和服装变化共同削弱了这些假设的有效性。

Method: 基于DetReIDX数据集构建VReID-XFD基准，包含371个身份、11,288个轨迹和1175万帧，覆盖5.8米到120米高度、30度到90度视角、最远120米水平距离的拍摄条件。

Result: 系统分析显示性能随高度和距离单调下降，俯视视角普遍表现较差，存在峰值性能与鲁棒性之间的权衡。即使在最佳方法SAS-PReID下，空中到地面设置的mAP仅为43.93%。

Conclusion: VReID-XFD基准和挑战公开可用，揭示了极端远距离人员重识别的严峻挑战，为未来研究提供了重要基准。

Abstract: Person re-identification (ReID) across aerial and ground views at extreme far distances introduces a distinct operating regime where severe resolution degradation, extreme viewpoint changes, unstable motion cues, and clothing variation jointly undermine the appearance-based assumptions of existing ReID systems. To study this regime, we introduce VReID-XFD, a video-based benchmark and community challenge for extreme far-distance (XFD) aerial-to-ground person re-identification. VReID-XFD is derived from the DetReIDX dataset and comprises 371 identities, 11,288 tracklets, and 11.75 million frames, captured across altitudes from 5.8 m to 120 m, viewing angles from oblique (30 degrees) to nadir (90 degrees), and horizontal distances up to 120 m. The benchmark supports aerial-to-aerial, aerial-to-ground, and ground-to-aerial evaluation under strict identity-disjoint splits, with rich physical metadata. The VReID-XFD-25 Challenge attracted 10 teams with hundreds of submissions. Systematic analysis reveals monotonic performance degradation with altitude and distance, a universal disadvantage of nadir views, and a trade-off between peak performance and robustness. Even the best-performing SAS-PReID method achieves only 43.93 percent mAP in the aerial-to-ground setting. The dataset, annotations, and official evaluation protocols are publicly available at https://www.it.ubi.pt/DetReIDX/ .

</details>


### [60] [LinMU: Multimodal Understanding Made Linear](https://arxiv.org/abs/2601.01322)
*Hongjie Wang,Niraj K. Jha*

Main category: cs.CV

TL;DR: LinMU是一种线性复杂度的视觉语言模型，通过双分支M-MATE模块替代自注意力层，在保持性能的同时显著降低计算复杂度，适用于高分辨率图像和长视频处理。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型的自注意力机制具有二次复杂度，限制了在边缘设备上的部署，且处理高分辨率图像和长视频时计算成本过高。

Method: 提出LinMU架构，用M-MATE双分支模块（Flex-MA全局上下文分支和Local-Swin局部注意力分支）替代自注意力层，并采用三阶段蒸馏框架从预训练VLM转换。

Result: 在多个基准测试上匹配教师模型性能，同时将首token生成时间减少2.7倍，token吞吐量提升9.0倍，特别在分钟级视频处理中表现优异。

Conclusion: 证明了无需二次注意力即可实现最先进的多模态推理，为处理高分辨率图像和长视频的VLM开辟了新途径。

Abstract: Modern Vision-Language Models (VLMs) achieve impressive performance but are limited by the quadratic complexity of self-attention, which prevents their deployment on edge devices and makes their understanding of high-resolution images and long-context videos prohibitively expensive. To address this challenge, we introduce LinMU (Linear-complexity Multimodal Understanding), a VLM design that achieves linear complexity without using any quadratic-complexity modules while maintaining the performance of global-attention-based VLMs. LinMU replaces every self-attention layer in the VLM with the M-MATE block: a dual-branch module that combines a bidirectional state-space model for global context (Flex-MA branch) with localized Swin-style window attention (Local-Swin branch) for adjacent correlations. To transform a pre-trained VLM into the LinMU architecture, we propose a three-stage distillation framework that (i) initializes both branches with self-attention weights and trains the Flex-MA branch alone, (ii) unfreezes the Local-Swin branch and fine-tunes it jointly with the Flex-MA branch, and (iii) unfreezes the remaining blocks and fine-tunes them using LoRA adapters, while regressing on hidden states and token-level logits of the frozen VLM teacher. On MMMU, TextVQA, LongVideoBench, Video-MME, and other benchmarks, LinMU matches the performance of teacher models, yet reduces Time-To-First-Token (TTFT) by up to 2.7$\times$ and improves token throughput by up to 9.0$\times$ on minute-length videos. Ablations confirm the importance of each distillation stage and the necessity of the two branches of the M-MATE block. The proposed framework demonstrates that state-of-the-art multimodal reasoning can be achieved without quadratic attention, thus opening up avenues for long-context VLMs that can deal with high-resolution images and long videos.

</details>


### [61] [Achieving Fine-grained Cross-modal Understanding through Brain-inspired Hierarchical Representation Learning](https://arxiv.org/abs/2601.01339)
*Weihang You,Hanqi Jiang,Yi Pan,Junhao Chen,Tianming Liu,Fei Dou*

Main category: cs.CV

TL;DR: NeuroAlign是一个新的fMRI-视频对齐框架，通过模拟人类视觉系统的层次结构，实现全局语义理解和细粒度模式匹配，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有神经解码方法主要基于生成任务或简单相关性，无法反映大脑视觉处理的层次性和时间动态特性。

Method: 采用两阶段机制：1）通过神经-时间对比学习实现全局语义理解；2）通过增强向量量化进行细粒度模式匹配，使用DynaSyncMM-EMA实现动态多模态融合。

Result: 实验表明NeuroAlign在跨模态检索任务中显著优于现有方法。

Conclusion: 该框架为理解视觉认知机制建立了新范式，能够更好地模拟大脑的层次化视觉处理过程。

Abstract: Understanding neural responses to visual stimuli remains challenging due to the inherent complexity of brain representations and the modality gap between neural data and visual inputs. Existing methods, mainly based on reducing neural decoding to generation tasks or simple correlations, fail to reflect the hierarchical and temporal processes of visual processing in the brain. To address these limitations, we present NeuroAlign, a novel framework for fine-grained fMRI-video alignment inspired by the hierarchical organization of the human visual system. Our framework implements a two-stage mechanism that mirrors biological visual pathways: global semantic understanding through Neural-Temporal Contrastive Learning (NTCL) and fine-grained pattern matching through enhanced vector quantization. NTCL explicitly models temporal dynamics through bidirectional prediction between modalities, while our DynaSyncMM-EMA approach enables dynamic multi-modal fusion with adaptive weighting. Experiments demonstrate that NeuroAlign significantly outperforms existing methods in cross-modal retrieval tasks, establishing a new paradigm for understanding visual cognitive mechanisms.

</details>


### [62] [Slot-ID: Identity-Preserving Video Generation from Reference Videos via Slot-Based Temporal Identity Encoding](https://arxiv.org/abs/2601.01352)
*Yixuan Lai,He Wang,Kun Zhou,Tianjia Shao*

Main category: cs.CV

TL;DR: 本文提出了一种基于身份条件的扩散-Transformer视频生成方法，通过使用短参考视频而非单张肖像来捕捉人物特定的动态特征，解决了在保持身份一致性和运动自然性之间的平衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有模型仅基于单张图像生成视频时，会忽略时间特征，导致姿态锁定、不自然的扭曲以及视角和表情变化时出现'平均'面部的问题。

Method: 引入身份条件的扩散-Transformer视频生成器，使用短参考视频提取人物特定的动态模式。通过Sinkhorn路由编码器学习紧凑的身份令牌，捕捉特征动态并保持与预训练骨干网络的兼容性。

Result: 该方法在大姿态变化和丰富面部表情下显著提升了身份保持能力，同时保持了提示忠实度和视觉真实性，适用于多样化的主体和提示。

Conclusion: 通过利用短参考视频中的动态信息，该方法在身份保留和运动自然性方面取得了显著改进，为生成高质量、身份一致的视频提供了有效解决方案。

Abstract: Producing prompt-faithful videos that preserve a user-specified identity remains challenging: models need to extrapolate facial dynamics from sparse reference while balancing the tension between identity preservation and motion naturalness. Conditioning on a single image completely ignores the temporal signature, which leads to pose-locked motions, unnatural warping, and "average" faces when viewpoints and expressions change. To this end, we introduce an identity-conditioned variant of a diffusion-transformer video generator which uses a short reference video rather than a single portrait. Our key idea is to incorporate the dynamics in the reference. A short clip reveals subject-specific patterns, e.g., how smiles form, across poses and lighting. From this clip, a Sinkhorn-routed encoder learns compact identity tokens that capture characteristic dynamics while remaining pretrained backbone-compatible. Despite adding only lightweight conditioning, the approach consistently improves identity retention under large pose changes and expressive facial behavior, while maintaining prompt faithfulness and visual realism across diverse subjects and prompts.

</details>


### [63] [Advanced Machine Learning Approaches for Enhancing Person Re-Identification Performance](https://arxiv.org/abs/2601.01356)
*Dang H. Pham,Tu N. Nguyen,Hoa N. Nguyen*

Main category: cs.CV

TL;DR: 该论文提出了三种先进的人员重识别方法，分别针对监督学习、无监督域适应和完全无监督场景，通过对比学习、GAN增强和Vision Transformer等技术显著提升了ReID性能


<details>
  <summary>Details</summary>
Motivation: 解决人员重识别中面临的外观变化、域偏移和标注数据有限等关键挑战，提升在复杂监控环境中的实际应用能力

Method: 1) SCM-ReID：结合监督对比学习和混合损失优化；2) IQAGA和DAPRH：使用GAN图像增强、域不变映射和伪标签精炼；3) ViTC-UReID：基于Vision Transformer的特征编码和相机感知代理学习

Result: 在Market-1501、CUHK03等数据集上达到最先进性能，域适应场景下mAP和Rank-1指标提升高达12%，无监督方法显著优于现有方法

Conclusion: 所提方法有效解决了特征学习、域适应和标签噪声处理等关键问题，为实际监控系统的鲁棒部署奠定了基础

Abstract: Person re-identification (ReID) plays a critical role in intelligent surveillance systems by linking identities across multiple cameras in complex environments. However, ReID faces significant challenges such as appearance variations, domain shifts, and limited labeled data. This dissertation proposes three advanced approaches to enhance ReID performance under supervised, unsupervised domain adaptation (UDA), and fully unsupervised settings. First, SCM-ReID integrates supervised contrastive learning with hybrid loss optimization (classification, center, triplet, and centroid-triplet losses), improving discriminative feature representation and achieving state-of-the-art accuracy on Market-1501 and CUHK03 datasets. Second, for UDA, IQAGA and DAPRH combine GAN-based image augmentation, domain-invariant mapping, and pseudo-label refinement to mitigate domain discrepancies and enhance cross-domain generalization. Experiments demonstrate substantial gains over baseline methods, with mAP and Rank-1 improvements up to 12% in challenging transfer scenarios. Finally, ViTC-UReID leverages Vision Transformer-based feature encoding and camera-aware proxy learning to boost unsupervised ReID. By integrating global and local attention with camera identity constraints, this method significantly outperforms existing unsupervised approaches on large-scale benchmarks. Comprehensive evaluations across CUHK03, Market-1501, DukeMTMC-reID, and MSMT17 confirm the effectiveness of the proposed methods. The contributions advance ReID research by addressing key limitations in feature learning, domain adaptation, and label noise handling, paving the way for robust deployment in real-world surveillance systems.

</details>


### [64] [Garment Inertial Denoiser (GID): Endowing Accurate Motion Capture via Loose IMU Denoiser](https://arxiv.org/abs/2601.01360)
*Jiawei Fang,Ruonan Zheng,Xiaoxia Gao,Shifan Jiang,Anjun Chen,Qi Ye,Shihui Guo*

Main category: cs.CV

TL;DR: GID是一种轻量级Transformer模型，通过三阶段分解方法解决松散服装中IMU传感器位移引起的运动捕捉误差问题，能够在有限数据下实现跨用户、动作和服装类型的泛化。


<details>
  <summary>Details</summary>
Motivation: 可穿戴惯性运动捕捉系统需要紧密贴合的传感器，这对日常使用来说不舒适。将IMU嵌入宽松服装是理想替代方案，但传感器-身体位移会导致严重的位置相关误差。

Method: 提出GID（服装惯性去噪器），采用位置感知专家架构：共享时空骨干网络建模全局运动，每个IMU专家头专门处理局部服装动态，轻量级融合模块确保跨部位一致性。

Result: 实验表明GID能够从单用户训练数据中实现准确、实时的去噪，并在未见过的用户、动作和服装类型上具有良好泛化能力，持续提升现有惯性运动捕捉方法性能。

Conclusion: GID作为一种即插即用模块，有效解决了宽松服装惯性运动捕捉的挑战，为舒适可穿戴运动捕捉系统提供了可行解决方案。

Abstract: Wearable inertial motion capture (MoCap) provides a portable, occlusion-free, and privacy-preserving alternative to camera-based systems, but its accuracy depends on tightly attached sensors - an intrusive and uncomfortable requirement for daily use. Embedding IMUs into loose-fitting garments is a desirable alternative, yet sensor-body displacement introduces severe, structured, and location-dependent corruption that breaks standard inertial pipelines. We propose GID (Garment Inertial Denoiser), a lightweight, plug-and-play Transformer that factorizes loose-wear MoCap into three stages: (i) location-specific denoising, (ii) adaptive cross-wear fusion, and (iii) general pose prediction. GID uses a location-aware expert architecture, where a shared spatio-temporal backbone models global motion while per-IMU expert heads specialize in local garment dynamics, and a lightweight fusion module ensures cross-part consistency. This inductive bias enables stable training and effective learning from limited paired loose-tight IMU data. We also introduce GarMoCap, a combined public and newly collected dataset covering diverse users, motions, and garments. Experiments show that GID enables accurate, real-time denoising from single-user training and generalizes across unseen users, motions, and garment types, consistently improving state-of-the-art inertial MoCap methods when used as a drop-in module.

</details>


### [65] [Unsupervised SE(3) Disentanglement for in situ Macromolecular Morphology Identification from Cryo-Electron Tomography](https://arxiv.org/abs/2601.01364)
*Mostofa Rafid Uddin,Mahek Vora,Qifeng Wu,Muyuan Chen,Min Xu*

Main category: cs.CV

TL;DR: 本文提出了一种解耦深度表示学习框架，用于从冷冻电子断层扫描（cryo-ET）数据中分离SE(3)变换与形态内容，解决了传统方法难以捕捉稀有形态和需要大量手动调参的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于期望最大化的方法经常遗漏重要但稀有的形态，且需要大量手动超参数调整。本文旨在通过深度学习方法自动分离形态内容与空间变换，提高形态分析的准确性和效率。

Method: 提出解耦深度表示学习框架，包含新颖的多选择学习模块，能够在高噪声的cryo-ET数据中实现SE(3)变换与形态内容的分离，并利用学习的形态内容生成模板形态。

Result: 在模拟和真实cryo-ET数据集上的实验表明，该方法明显优于现有方法，能够发现以前未识别的大分子形态。

Conclusion: 该框架有效解决了cryo-ET数据中形态分析的逆问题，为生物大分子的原位形态研究提供了更强大的工具。

Abstract: Cryo-electron tomography (cryo-ET) provides direct 3D visualization of macromolecules inside the cell, enabling analysis of their in situ morphology. This morphology can be regarded as an SE(3)-invariant, denoised volumetric representation of subvolumes extracted from tomograms. Inferring morphology is therefore an inverse problem of estimating both a template morphology and its SE(3) transformation. Existing expectation-maximization based solution to this problem often misses rare but important morphologies and requires extensive manual hyperparameter tuning. Addressing this issue, we present a disentangled deep representation learning framework that separates SE(3) transformations from morphological content in the representation space. The framework includes a novel multi-choice learning module that enables this disentanglement for highly noisy cryo-ET data, and the learned morphological content is used to generate template morphologies. Experiments on simulated and real cryo-ET datasets demonstrate clear improvements over prior methods, including the discovery of previously unidentified macromolecular morphologies.

</details>


### [66] [ParkGaussian: Surround-view 3D Gaussian Splatting for Autonomous Parking](https://arxiv.org/abs/2601.01386)
*Xiaobao Wei,Zhangjie Ye,Yuxiang Gu,Zunjie Zhu,Yunfei Guo,Yingying Shen,Shan Zhao,Ming Lu,Haiyang Sun,Bing Wang,Guang Chen,Rongfeng Lu,Hangjun Ye*

Main category: cs.CV

TL;DR: 该论文提出了ParkRecon3D基准和ParkGaussian框架，首次将3D高斯泼溅技术应用于停车场景重建，并通过槽位感知策略提升重建质量与下游停车检测任务的一致性。


<details>
  <summary>Details</summary>
Motivation: 现有工作主要关注2D停车位感知，而3D重建在停车场景中研究不足。单纯提高视觉质量并不能直接帮助自动驾驶停车，因为停车的关键入口是槽位感知模块。

Method: 提出了ParkGaussian框架，集成3D高斯泼溅技术进行停车场景重建，并引入槽位感知重建策略，利用现有停车感知方法提升槽位区域的合成质量。

Result: 在ParkRecon3D基准上的实验表明，ParkGaussian实现了最先进的重建质量，并更好地保持了与下游任务的感知一致性。

Conclusion: 该研究填补了停车场景3D重建的空白，提出的方法在重建质量和任务一致性方面表现出色，代码和数据集将开源。

Abstract: Parking is a critical task for autonomous driving systems (ADS), with unique challenges in crowded parking slots and GPS-denied environments. However, existing works focus on 2D parking slot perception, mapping, and localization, 3D reconstruction remains underexplored, which is crucial for capturing complex spatial geometry in parking scenarios. Naively improving the visual quality of reconstructed parking scenes does not directly benefit autonomous parking, as the key entry point for parking is the slots perception module. To address these limitations, we curate the first benchmark named ParkRecon3D, specifically designed for parking scene reconstruction. It includes sensor data from four surround-view fisheye cameras with calibrated extrinsics and dense parking slot annotations. We then propose ParkGaussian, the first framework that integrates 3D Gaussian Splatting (3DGS) for parking scene reconstruction. To further improve the alignment between reconstruction and downstream parking slot detection, we introduce a slot-aware reconstruction strategy that leverages existing parking perception methods to enhance the synthesis quality of slot regions. Experiments on ParkRecon3D demonstrate that ParkGaussian achieves state-of-the-art reconstruction quality and better preserves perception consistency for downstream tasks. The code and dataset will be released at: https://github.com/wm-research/ParkGaussian

</details>


### [67] [Evaluation of Convolutional Neural Network For Image Classification with Agricultural and Urban Datasets](https://arxiv.org/abs/2601.01393)
*Shamik Shafkat Avro,Nazira Jesmin Lina,Shahanaz Sharmin*

Main category: cs.CV

TL;DR: 该论文开发了一个自定义卷积神经网络（CustomCNN），研究架构设计选择对多领域图像分类任务的影响，并在五个公共数据集上验证其性能。


<details>
  <summary>Details</summary>
Motivation: 研究神经网络架构设计选择如何影响多领域图像分类任务的性能，为智能城市和农业成像应用提供高效解决方案。

Method: 使用残差连接、Squeeze-and-Excitation注意力机制、渐进通道缩放和Kaiming初始化等技术构建自定义CNN，在五个公开数据集上进行训练和测试。

Result: 与主流CNN架构相比，CustomCNN在保持计算效率的同时实现了有竞争力的性能表现。

Conclusion: 研究结果强调了精心设计的网络架构对于现实世界智能城市和农业成像应用的重要性。

Abstract: This paper presents the development and evaluation of a custom Convolutional Neural Network (CustomCNN) created to study how architectural design choices affect multi-domain image classification tasks. The network uses residual connections, Squeeze-and-Excitation attention mechanisms, progressive channel scaling, and Kaiming initialization to improve its ability to represent data and speed up training. The model is trained and tested on five publicly available datasets: unauthorized vehicle detection, footpath encroachment detection, polygon-annotated road damage and manhole detection, MangoImageBD and PaddyVarietyBD. A comparison with popular CNN architectures shows that the CustomCNN delivers competitive performance while remaining efficient in computation. The results underscore the importance of thoughtful architectural design for real-world Smart City and agricultural imaging applications.

</details>


### [68] [SwinIFS: Landmark Guided Swin Transformer For Identity Preserving Face Super Resolution](https://arxiv.org/abs/2601.01406)
*Habiba Kausar,Saeed Anwar,Omar Jamal Hammad,Abdul Bais*

Main category: cs.CV

TL;DR: SwinIFS是一个基于Swin Transformer的面部超分辨率框架，通过结合面部关键点热图先验和分层注意力机制，在中等和极端放大倍数下实现身份保持的重建。


<details>
  <summary>Details</summary>
Motivation: 解决面部超分辨率中因低分辨率输入导致的精细结构细节和身份特征丢失问题，特别是在极端放大倍数下现有方法难以恢复有意义结构。

Method: 采用密集高斯热图表示面部关键点作为输入先验，使用紧凑的Swin Transformer主干网络捕获长距离上下文信息，同时保持局部几何结构。

Result: 在CelebA基准测试中，SwinIFS在8倍放大下仍能产生更逼真的结果，具有优越的感知质量、更清晰的恢复效果和更好的身份保持能力。

Conclusion: SwinIFS在重建精度和计算效率之间取得了良好平衡，适用于面部增强、监控和数字修复等实际应用。

Abstract: Face super-resolution aims to recover high-quality facial images from severely degraded low-resolution inputs, but remains challenging due to the loss of fine structural details and identity-specific features. This work introduces SwinIFS, a landmark-guided super-resolution framework that integrates structural priors with hierarchical attention mechanisms to achieve identity-preserving reconstruction at both moderate and extreme upscaling factors. The method incorporates dense Gaussian heatmaps of key facial landmarks into the input representation, enabling the network to focus on semantically important facial regions from the earliest stages of processing. A compact Swin Transformer backbone is employed to capture long-range contextual information while preserving local geometry, allowing the model to restore subtle facial textures and maintain global structural consistency. Extensive experiments on the CelebA benchmark demonstrate that SwinIFS achieves superior perceptual quality, sharper reconstructions, and improved identity retention; it consistently produces more photorealistic results and exhibits strong performance even under 8x magnification, where most methods fail to recover meaningful structure. SwinIFS also provides an advantageous balance between reconstruction accuracy and computational efficiency, making it suitable for real-world applications in facial enhancement, surveillance, and digital restoration. Our code, model weights, and results are available at https://github.com/Habiba123-stack/SwinIFS.

</details>


### [69] [Mask-Guided Multi-Task Network for Face Attribute Recognition](https://arxiv.org/abs/2601.01408)
*Gong Gao,Zekai Wang,Jian Zhao,Ziqi Xie,Xianhui Liu,Weidong Zhao*

Main category: cs.CV

TL;DR: 提出了一种基于掩码引导的多任务网络（MGMTN），通过自适应掩码学习（AML）和组-全局特征融合（G2FF）来提升人脸属性识别性能，解决了传统方法依赖全局特征导致的冗余问题。


<details>
  <summary>Details</summary>
Motivation: 传统多任务属性识别方法依赖全局区域特征提取，会产生冗余特征，影响识别精度。需要选择特定特征区域进行高效特征学习。

Method: MGMTN包含两个核心模块：AML（利用预训练关键点模型和全卷积网络定位关键面部部位并生成组掩码）和G2FF（融合组特征和全局特征）。

Result: 在两个具有挑战性的人脸属性识别数据集上的实验证明，MGMTN能够有效提升人脸属性识别性能。

Conclusion: 该方法通过选择性特征区域学习和特征融合，显著改善了人脸属性识别的准确性和效率。

Abstract: Face Attribute Recognition (FAR) plays a crucial role in applications such as person re-identification, face retrieval, and face editing. Conventional multi-task attribute recognition methods often process the entire feature map for feature extraction and attribute classification, which can produce redundant features due to reliance on global regions. To address these challenges, we propose a novel approach emphasizing the selection of specific feature regions for efficient feature learning. We introduce the Mask-Guided Multi-Task Network (MGMTN), which integrates Adaptive Mask Learning (AML) and Group-Global Feature Fusion (G2FF) to address the aforementioned limitations. Leveraging a pre-trained keypoint annotation model and a fully convolutional network, AML accurately localizes critical facial parts (e.g., eye and mouth groups) and generates group masks that delineate meaningful feature regions, thereby mitigating negative transfer from global region usage. Furthermore, G2FF combines group and global features to enhance FAR learning, enabling more precise attribute identification. Extensive experiments on two challenging facial attribute recognition datasets demonstrate the effectiveness of MGMTN in improving FAR performance.

</details>


### [70] [AirSpatialBot: A Spatially-Aware Aerial Agent for Fine-Grained Vehicle Attribute Recognization and Retrieval](https://arxiv.org/abs/2601.01416)
*Yue Zhou,Ran Ding,Xue Yang,Xue Jiang,Xingzhao Liu*

Main category: cs.CV

TL;DR: 该论文提出了AirSpatial数据集和AirSpatialBot代理，解决了遥感视觉语言模型在空间理解方面的局限性，通过两阶段训练策略实现了细粒度车辆属性识别和检索。


<details>
  <summary>Details</summary>
Motivation: 现有遥感视觉语言模型在空间理解方面存在不足，限制了其在实际应用中的效果。论文旨在突破这一限制，特别针对无人机拍摄的车辆图像。

Method: 采用两阶段训练策略：图像理解预训练和空间理解微调。构建了包含20.6万条指令的AirSpatial数据集，引入了空间定位和空间问答两个新任务，并首次提供3DBB标注。

Result: 实验验证了方法的有效性，揭示了现有VLMs的空间局限性，同时提供了有价值的见解。开发的AirSpatialBot能够适应多样化的查询需求。

Conclusion: 该研究为遥感视觉语言模型的空间理解能力提供了新的解决方案，数据集、代码和模型将开源发布。

Abstract: Despite notable advancements in remote sensing vision-language models (VLMs), existing models often struggle with spatial understanding, limiting their effectiveness in real-world applications. To push the boundaries of VLMs in remote sensing, we specifically address vehicle imagery captured by drones and introduce a spatially-aware dataset AirSpatial, which comprises over 206K instructions and introduces two novel tasks: Spatial Grounding and Spatial Question Answering. It is also the first remote sensing grounding dataset to provide 3DBB. To effectively leverage existing image understanding of VLMs to spatial domains, we adopt a two-stage training strategy comprising Image Understanding Pre-training and Spatial Understanding Fine-tuning. Utilizing this trained spatially-aware VLM, we develop an aerial agent, AirSpatialBot, which is capable of fine-grained vehicle attribute recognition and retrieval. By dynamically integrating task planning, image understanding, spatial understanding, and task execution capabilities, AirSpatialBot adapts to diverse query requirements. Experimental results validate the effectiveness of our approach, revealing the spatial limitations of existing VLMs while providing valuable insights. The model, code, and datasets will be released at https://github.com/VisionXLab/AirSpatialBot

</details>


### [71] [DreamID-V:Bridging the Image-to-Video Gap for High-Fidelity Face Swapping via Diffusion Transformer](https://arxiv.org/abs/2601.01425)
*Xu Guo,Fulong Ye,Xinghui Li,Pengqi Tu,Pengze Zhang,Qichao Sun,Songtao Zhao,Xiangwang Hou,Qian He*

Main category: cs.CV

TL;DR: DreamID-V是一个基于扩散变换器的视频人脸交换框架，通过创新的模态感知条件模块和双向ID四元组监督，解决了现有方法在身份相似性、属性保持和时间一致性方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有视频人脸交换方法难以同时保持身份相似性和属性保留，同时保证时间一致性。作者希望将图像人脸交换的优势无缝迁移到视频领域。

Method: 提出SyncID-Pipe数据管道预训练身份锚定视频合成器，结合IFS模型构建双向ID四元组监督；开发基于扩散变换器的DreamID-V框架，采用模态感知条件模块区分注入多模态条件；引入合成到真实课程机制和身份一致性强化学习策略。

Result: 在提出的IDBench-V基准测试上，DreamID-V显著优于现有最先进方法，展现出优异的通用性，可无缝适应各种交换相关任务。

Conclusion: 该框架成功解决了视频人脸交换中的关键挑战，为视频域的身份交换提供了有效的解决方案，具有广泛的应用潜力。

Abstract: Video Face Swapping (VFS) requires seamlessly injecting a source identity into a target video while meticulously preserving the original pose, expression, lighting, background, and dynamic information. Existing methods struggle to maintain identity similarity and attribute preservation while preserving temporal consistency. To address the challenge, we propose a comprehensive framework to seamlessly transfer the superiority of Image Face Swapping (IFS) to the video domain. We first introduce a novel data pipeline SyncID-Pipe that pre-trains an Identity-Anchored Video Synthesizer and combines it with IFS models to construct bidirectional ID quadruplets for explicit supervision. Building upon paired data, we propose the first Diffusion Transformer-based framework DreamID-V, employing a core Modality-Aware Conditioning module to discriminatively inject multi-model conditions. Meanwhile, we propose a Synthetic-to-Real Curriculum mechanism and an Identity-Coherence Reinforcement Learning strategy to enhance visual realism and identity consistency under challenging scenarios. To address the issue of limited benchmarks, we introduce IDBench-V, a comprehensive benchmark encompassing diverse scenes. Extensive experiments demonstrate DreamID-V outperforms state-of-the-art methods and further exhibits exceptional versatility, which can be seamlessly adapted to various swap-related tasks.

</details>


### [72] [EdgeNeRF: Edge-Guided Regularization for Neural Radiance Fields from Sparse Views](https://arxiv.org/abs/2601.01431)
*Weiqi Yu,Yiyang Yao,Lin He,Jianming Lv*

Main category: cs.CV

TL;DR: EdgeNeRF提出了一种边缘引导的稀疏视图3D重建算法，通过深度和法线正则化约束非边缘区域，在保持几何边界高频细节的同时减少伪影。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用全局深度正则化会丢失几何边界细节，而深度和法线的突变会产生边缘，因此可以利用边缘先验来改进稀疏视图下的NeRF重建质量。

Method: 首先从输入图像中提取边缘，然后在非边缘区域应用深度和法线正则化约束，增强几何一致性同时保留边界高频细节。

Result: 在LLFF和DTU数据集上的实验表明，EdgeNeRF在保持锐利几何边界和抑制伪影方面表现优异，且该模块可以即插即用地集成到其他方法中。

Conclusion: EdgeNeRF通过边缘引导的深度正则化有效解决了稀疏视图下NeRF的几何伪影问题，在保持边界细节的同时显著提升了重建质量。

Abstract: Neural Radiance Fields (NeRF) achieve remarkable performance in dense multi-view scenarios, but their reconstruction quality degrades significantly under sparse inputs due to geometric artifacts. Existing methods utilize global depth regularization to mitigate artifacts, leading to the loss of geometric boundary details. To address this problem, we propose EdgeNeRF, an edge-guided sparse-view 3D reconstruction algorithm. Our method leverages the prior that abrupt changes in depth and normals generate edges. Specifically, we first extract edges from input images, then apply depth and normal regularization constraints to non-edge regions, enhancing geometric consistency while preserving high-frequency details at boundaries. Experiments on LLFF and DTU datasets demonstrate EdgeNeRF's superior performance, particularly in retaining sharp geometric boundaries and suppressing artifacts. Additionally, the proposed edge-guided depth regularization module can be seamlessly integrated into other methods in a plug-and-play manner, significantly improving their performance without substantially increasing training time. Code is available at https://github.com/skyhigh404/edgenerf.

</details>


### [73] [In defense of the two-stage framework for open-set domain adaptive semantic segmentation](https://arxiv.org/abs/2601.01439)
*Wenqi Ren,Weijie Wang,Meng Zheng,Ziyan Wu,Yang Tang,Zhun Zhong,Nicu Sebe*

Main category: cs.CV

TL;DR: 本文提出SATS方法，通过分离训练策略解决开放集域自适应语义分割问题，将已知/未知类别分离和未知感知域适应分为两个步骤，避免负迁移和欠拟合问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在单一统一阶段处理已知类别域适应和未知类别区分，但由于已知和未知类别标注不平衡，常导致已知类别的负迁移和未知类别的欠拟合。

Method: SATS方法采用分离训练策略：1）已知/未知类别分离；2）未知感知域适应。还提出硬未知探索数据增强方法，让模型接触更困难的未知样本。

Result: 在公开OSDA-SS基准测试中，GTA5到Cityscapes场景H-Score提升+3.85%，SYNTHIA到Cityscapes提升+18.64%，显著优于现有最先进方法。

Conclusion: 分离训练策略能有效平衡已知和未知类别的学习，提供更准确对齐的未知类别，使模型能够发现真正的未知对象。

Abstract: Open-Set Domain Adaptation for Semantic Segmentation (OSDA-SS) presents a significant challenge, as it requires both domain adaptation for known classes and the distinction of unknowns. Existing methods attempt to address both tasks within a single unified stage. We question this design, as the annotation imbalance between known and unknown classes often leads to negative transfer of known classes and underfitting for unknowns. To overcome these issues, we propose SATS, a Separating-then-Adapting Training Strategy, which addresses OSDA-SS through two sequential steps: known/unknown separation and unknown-aware domain adaptation. By providing the model with more accurate and well-aligned unknown classes, our method ensures a balanced learning of discriminative features for both known and unknown classes, steering the model toward discovering truly unknown objects. Additionally, we present hard unknown exploration, an innovative data augmentation method that exposes the model to more challenging unknowns, strengthening its ability to capture more comprehensive understanding of target unknowns. We evaluate our method on public OSDA-SS benchmarks. Experimental results demonstrate that our method achieves a substantial advancement, with a +3.85% H-Score improvement for GTA5-to-Cityscapes and +18.64% for SYNTHIA-to-Cityscapes, outperforming previous state-of-the-art methods.

</details>


### [74] [PartImageNet++ Dataset: Enhancing Visual Models with High-Quality Part Annotations](https://arxiv.org/abs/2601.01454)
*Xiao Li,Zilong Liu,Yining Liu,Zhuhong Li,Na Dong,Sitian Qin,Xiaolin Hu*

Main category: cs.CV

TL;DR: PartImageNet++ (PIN++)是一个包含ImageNet-1K所有类别详细部件标注的数据集，包含10万张图像。基于此提出了多尺度部件监督识别模型(MPM)，通过部件分割和伪标签生成来提升分类性能，并在多个下游任务中验证了部件标注的价值。


<details>
  <summary>Details</summary>
Motivation: 解决现有数据集中高质量部件标注稀缺的问题，探索部件标注在提升模型性能方面的潜力。

Method: 首先使用PIN++训练部件分割网络，生成剩余未标注图像的伪部件标签；然后构建MPM模型，结合传统识别架构和辅助旁路层，通过伪部件标签和原始部件标注进行联合监督。

Result: 实验表明该方法不仅增强了基于部件的模型进行鲁棒目标识别，还为多个下游任务建立了强基线，证明了部件标注在提升模型性能方面的潜力。

Conclusion: PIN++数据集和MPM模型为部件标注研究提供了重要资源和方法，展示了部件信息在计算机视觉任务中的重要作用。

Abstract: To address the scarcity of high-quality part annotations in existing datasets, we introduce PartImageNet++ (PIN++), a dataset that provides detailed part annotations for all categories in ImageNet-1K. With 100 annotated images per category, totaling 100K images, PIN++ represents the most comprehensive dataset covering a diverse range of object categories. Leveraging PIN++, we propose a Multi-scale Part-supervised recognition Model (MPM) for robust classification on ImageNet-1K. We first trained a part segmentation network using PIN++ and used it to generate pseudo part labels for the remaining unannotated images. MPM then integrated a conventional recognition architecture with auxiliary bypass layers, jointly supervised by both pseudo part labels and the original part annotations. Furthermore, we conducted extensive experiments on PIN++, including part segmentation, object segmentation, and few-shot learning, exploring various ways to leverage part annotations in downstream tasks. Experimental results demonstrated that our approach not only enhanced part-based models for robust object recognition but also established strong baselines for multiple downstream tasks, highlighting the potential of part annotations in improving model performance. The dataset and the code are available at https://github.com/LixiaoTHU/PartImageNetPP.

</details>


### [75] [Rethinking Multimodal Few-Shot 3D Point Cloud Segmentation: From Fused Refinement to Decoupled Arbitration](https://arxiv.org/abs/2601.01456)
*Wentao Bian,Fenglei Xu*

Main category: cs.CV

TL;DR: DA-FSS模型解决了多模态少样本3D点云语义分割中的"可塑性-稳定性困境"和CLIP的类间混淆问题，通过解耦几何和语义路径并相互正则化梯度来实现更好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决"Fuse-then-Refine"范式中的可塑性-稳定性困境，以及CLIP模型在多模态少样本3D点云分割中存在的类间混淆导致的语义盲区问题。

Method: 提出DA-FSS模型，包含并行专家精炼模块生成各模态相关性，堆叠仲裁模块进行卷积融合和模态路径仲裁。通过几何专家保持可塑性，语义专家确保稳定性，并使用解耦对齐模块在不传播混淆的情况下转移知识。

Result: 在S3DIS和ScanNet数据集上的实验表明，DA-FSS优于MM-FSS基线，在几何边界、完整性和纹理区分方面都表现更优。

Conclusion: DA-FSS通过解耦几何和语义路径并相互正则化，有效解决了多模态少样本3D点云分割中的关键问题，实现了更好的泛化性能。

Abstract: In this paper, we revisit multimodal few-shot 3D point cloud semantic segmentation (FS-PCS), identifying a conflict in "Fuse-then-Refine" paradigms: the "Plasticity-Stability Dilemma." In addition, CLIP's inter-class confusion can result in semantic blindness. To address these issues, we present the Decoupled-experts Arbitration Few-Shot SegNet (DA-FSS), a model that effectively distinguishes between semantic and geometric paths and mutually regularizes their gradients to achieve better generalization. DA-FSS employs the same backbone and pre-trained text encoder as MM-FSS to generate text embeddings, which can increase free modalities' utilization rate and better leverage each modality's information space. To achieve this, we propose a Parallel Expert Refinement module to generate each modal correlation. We also propose a Stacked Arbitration Module (SAM) to perform convolutional fusion and arbitrate correlations for each modality pathway. The Parallel Experts decouple two paths: a Geometric Expert maintains plasticity, and a Semantic Expert ensures stability. They are coordinated via a Decoupled Alignment Module (DAM) that transfers knowledge without propagating confusion. Experiments on popular datasets (S3DIS, ScanNet) demonstrate the superiority of DA-FSS over MM-FSS. Meanwhile, geometric boundaries, completeness, and texture differentiation are all superior to the baseline. The code is available at: https://github.com/MoWenQAQ/DA-FSS.

</details>


### [76] [Language as Prior, Vision as Calibration: Metric Scale Recovery for Monocular Depth Estimation](https://arxiv.org/abs/2601.01457)
*Mingxing Zhan,Li Zhang,Beibei Wang,Yingjie Wang,Zenglin Shi*

Main category: cs.CV

TL;DR: 该论文提出了一种通过图像特定仿射变换和语言引导的不确定性边界来从相对深度恢复度量深度的方法，在保持相对深度主干和CLIP文本编码器固定的情况下训练轻量级校准头。


<details>
  <summary>Details</summary>
Motivation: 单目度量深度估计由于全局尺度不可识别和域偏移敏感性而难以解决，而相对深度基础模型迁移性好但缺乏度量信息。需要一种方法能够利用语言提供的粗略尺度线索，同时处理其噪声和变化性。

Method: 使用语言预测不确定性边界（包络）来约束可行的校准参数，而不是直接进行点估计。然后利用多尺度冻结视觉特征从包络中选择图像特定的校准参数。通过闭式最小二乘逆深度提供每图像监督来学习包络和校准选择。

Result: 在NYUv2和KITTI数据集上提高了域内精度，零样本迁移到SUN-RGBD和DDAD数据集显示出比纯语言基线更好的鲁棒性。

Conclusion: 该方法通过语言引导的不确定性包络和视觉特征选择，有效解决了单目度量深度估计的尺度不确定性问题，实现了更好的域内精度和跨域鲁棒性。

Abstract: Relative-depth foundation models transfer well, yet monocular metric depth remains ill-posed due to unidentifiable global scale and heightened domain-shift sensitivity. Under a frozen-backbone calibration setting, we recover metric depth via an image-specific affine transform in inverse depth and train only lightweight calibration heads while keeping the relative-depth backbone and the CLIP text encoder fixed. Since captions provide coarse but noisy scale cues that vary with phrasing and missing objects, we use language to predict an uncertainty-aware envelope that bounds feasible calibration parameters in an unconstrained space, rather than committing to a text-only point estimate. We then use pooled multi-scale frozen visual features to select an image-specific calibration within this envelope. During training, a closed-form least-squares oracle in inverse depth provides per-image supervision for learning the envelope and the selected calibration. Experiments on NYUv2 and KITTI improve in-domain accuracy, while zero-shot transfer to SUN-RGBD and DDAD demonstrates improved robustness over strong language-only baselines.

</details>


### [77] [Domain Adaptation of Carotid Ultrasound Images using Generative Adversarial Network](https://arxiv.org/abs/2601.01460)
*Mohd Usama,Belal Ahmad,Christer Gronlund,Faleh Menawer R Althiyabi*

Main category: cs.CV

TL;DR: 本文提出了一种基于GAN的模型，用于解决医学超声图像中因不同设备或参数设置导致的域适应问题，通过图像到图像的转换来调整纹理模式和去除混响噪声，从而提高模型在不同域之间的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 医学影像中，不同设备或参数设置生成的图像具有不同的纹理和噪声，导致模型在一个域上训练后在其他域上表现不佳。重新为每个域训练模型成本高昂，因此需要一种有效的域适应方法。

Method: 使用生成对抗网络（GAN）将域适应任务转化为图像到图像的转换任务，调整测试图像的纹理模式并去除混响噪声，使其与目标域图像一致，同时保持图像内容不变。

Result: 实验结果表明，该方法成功转换了图像的纹理模式并去除了超声图像中的混响噪声。与无适应方法相比，提出的模型在直方图相关性（0.960和0.920）和Bhattacharya距离（0.040和0.085）上均表现更优。

Conclusion: 提出的基于GAN的域适应方法有效解决了医学超声图像中的域偏移问题，无需为每个域重新训练模型，显著提升了模型的跨域性能。

Abstract: Deep learning has been extensively used in medical imaging applications, assuming that the test and training datasets belong to the same probability distribution. However, a common challenge arises when working with medical images generated by different systems or even the same system with different parameter settings. Such images contain diverse textures and reverberation noise that violate the aforementioned assumption. Consequently, models trained on data from one device or setting often struggle to perform effectively with data from other devices or settings. In addition, retraining models for each specific device or setting is labor-intensive and costly. To address these issues in ultrasound images, we propose a novel Generative Adversarial Network (GAN)-based model. We formulated the domain adaptation tasks as an image-to-image translation task, in which we modified the texture patterns and removed reverberation noise in the test data images from the source domain to align with those in the target domain images while keeping the image content unchanged. We applied the proposed method to two datasets containing carotid ultrasound images from three different domains. The experimental results demonstrate that the model successfully translated the texture pattern of images and removed reverberation noise from the ultrasound images. Furthermore, we evaluated the CycleGAN approaches for a comparative study with the proposed model. The experimental findings conclusively demonstrated that the proposed model achieved domain adaptation (histogram correlation (0.960 (0.019), & 0.920 (0.043) and bhattacharya distance (0.040 (0.020), & 0.085 (0.048)), compared to no adaptation (0.916 (0.062) & 0.890 (0.077), 0.090 (0.070) & 0.121 (0.095)) for both datasets.

</details>


### [78] [Robust Ship Detection and Tracking Using Modified ViBe and Backwash Cancellation Algorithm](https://arxiv.org/abs/2601.01481)
*Mohammad Hassan Saghafi,Seyed Majid Noorhosseini,Seyed Abolfazl Seyed Javadein,Hadi Khalili*

Main category: cs.CV

TL;DR: 提出了一种用于海岸视频序列中船舶检测和跟踪的鲁棒实时方法，通过改进ViBe算法降低船舶丢失概率，能够快速更新背景并对海波和光线变化具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 海岸场景具有不可预测性和动态特性，需要能够适应这些条件的鲁棒检测方法。

Method: 改进ViBe算法进行运动物体检测，结合船舶的几何特性和亮度失真等概念提出新的尾流消除方法。

Result: 实验结果表明，所提出的策略和方法在船舶检测和跟踪方面具有出色的性能，实现了实时和精确的性能。

Conclusion: 该方法在海岸视频序列中能够有效地检测和跟踪船舶，对自然海波和光线变化具有鲁棒性。

Abstract: In this paper, we propose a robust real time detection and tracking method for detecting ships in a coastal video sequences. Since coastal scenarios are unpredictable and scenes have dynamic properties it is essential to apply detection methods that are robust to these conditions. This paper presents modified ViBe for moving object detection which detects ships and backwash. In the modified ViBe the probability of losing ships is decreased in comparison with the original ViBe. It is robust to natural sea waves and variation of lights and is capable of quickly updating the background. Based on geometrical properties of ship and some concepts such as brightness distortion, a new method for backwash cancellation is proposed. Experimental results demonstrate that the proposed strategy and methods have outstanding performance in ship detection and tracking. These results also illustrate real time and precise performance of the proposed strategy.

</details>


### [79] [Unified Generation and Self-Verification for Vision-Language Models via Advantage Decoupled Preference Optimization](https://arxiv.org/abs/2601.01483)
*Xinyu Qiu,Heng Jia,Zhengwen Zeng,Shuheng Shen,Changhua Meng,Yi Yang,Linchao Zhu*

Main category: cs.CV

TL;DR: ADPO提出了一种统一的强化学习框架，将答案生成和自我验证联合学习在一个单一策略中，通过偏好验证奖励和解耦优化机制，显著提升了验证能力和推理效率。


<details>
  <summary>Details</summary>
Motivation: 解决并行测试时缩放中需要分别训练生成和验证模型带来的高训练和推理成本问题，实现更高效的联合学习。

Method: 引入偏好验证奖励（通过正负样本计算平均验证分数作为决策阈值）和优势解耦优化（分别计算生成和验证的优势，应用token掩码隔离梯度，结合掩码GRPO目标）。

Result: 验证AUC提升高达+34.1%，推理时间降低-53.5%，MathVista/MMMU准确率提升+2.8%/+1.4%，ReasonSeg提升+1.9 cIoU，AndroidControl/GUI Odyssey步骤成功率提升+1.7%/+1.0%。

Conclusion: ADPO框架有效实现了生成和验证的协同优化，在保持生成质量的同时显著提升了验证能力和推理效率。

Abstract: Parallel test-time scaling typically trains separate generation and verification models, incurring high training and inference costs. We propose Advantage Decoupled Preference Optimization (ADPO), a unified reinforcement learning framework that jointly learns answer generation and self-verification within a single policy. ADPO introduces two innovations: a preference verification reward improving verification capability and a decoupled optimization mechanism enabling synergistic optimization of generation and verification. Specifically, the preference verification reward computes mean verification scores from positive and negative samples as decision thresholds, providing positive feedback when prediction correctness aligns with answer correctness. Meanwhile, the advantage decoupled optimization computes separate advantages for generation and verification, applies token masks to isolate gradients, and combines masked GRPO objectives, preserving generation quality while calibrating verification scores. ADPO achieves up to +34.1% higher verification AUC and -53.5% lower inference time, with significant gains of +2.8%/+1.4% accuracy on MathVista/MMMU, +1.9 cIoU on ReasonSeg, and +1.7%/+1.0% step success rate on AndroidControl/GUI Odyssey.

</details>


### [80] [Higher-Order Domain Generalization in Magnetic Resonance-Based Assessment of Alzheimer's Disease](https://arxiv.org/abs/2601.01485)
*Zobia Batool,Diala Lteif,Vijaya B. Kolachalama,Huseyin Ozkan,Erchan Aptoula*

Main category: cs.CV

TL;DR: 本文提出了Extended MixStyle (EM)框架，通过混合高阶特征矩（偏度和峰度）来模拟不同的分布变化，以解决阿尔茨海默病诊断中因扫描仪、协议和患者人口统计学差异导致的领域偏移问题。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在阿尔茨海默病诊断方面取得进展，但基于结构磁共振成像训练的模型在新队列中表现不佳，主要原因是领域偏移。阿尔茨海默病作为痴呆症的主要驱动因素，其进行性认知和神经解剖学变化（如萎缩和脑室扩张）使得鲁棒、可泛化的分类在现实世界中至关重要。

Method: 引入Extended MixStyle (EM)框架，通过混合高阶特征矩（偏度和峰度）来模拟不同的分布变化。使用国家阿尔茨海默病协调中心的结构磁共振成像数据训练模型，区分正常认知、轻度认知障碍和阿尔茨海默病患者，并在三个未见过的队列上进行测试。

Result: EM在跨领域性能上表现优异，平均宏F1分数比最先进的单领域泛化基准提高了2.4个百分点。

Conclusion: EM框架在异构现实世界环境中展示了不变、可靠的阿尔茨海默病检测潜力，为应对领域偏移问题提供了有效解决方案。

Abstract: Despite progress in deep learning for Alzheimer's disease (AD) diagnostics, models trained on structural magnetic resonance imaging (sMRI) often do not perform well when applied to new cohorts due to domain shifts from varying scanners, protocols and patient demographics. AD, the primary driver of dementia, manifests through progressive cognitive and neuroanatomical changes like atrophy and ventricular expansion, making robust, generalizable classification essential for real-world use. While convolutional neural networks and transformers have advanced feature extraction via attention and fusion techniques, single-domain generalization (SDG) remains underexplored yet critical, given the fragmented nature of AD datasets. To bridge this gap, we introduce Extended MixStyle (EM), a framework for blending higher-order feature moments (skewness and kurtosis) to mimic diverse distributional variations. Trained on sMRI data from the National Alzheimer's Coordinating Center (NACC; n=4,647) to differentiate persons with normal cognition (NC) from those with mild cognitive impairment (MCI) or AD and tested on three unseen cohorts (total n=3,126), EM yields enhanced cross-domain performance, improving macro-F1 on average by 2.4 percentage points over state-of-the-art SDG benchmarks, underscoring its promise for invariant, reliable AD detection in heterogeneous real-world settings. The source code will be made available upon acceptance at https://github.com/zobia111/Extended-Mixstyle.

</details>


### [81] [DeepInv: A Novel Self-supervised Learning Approach for Fast and Accurate Diffusion Inversion](https://arxiv.org/abs/2601.01487)
*Ziyue Zhang,Luxi Lin,Xiaolin Hu,Chao Chang,HuaiXi Wang,Yiyi Zhou,Rongrong Ji*

Main category: cs.CV

TL;DR: 本文提出了一种名为DeepInv的自监督扩散反演方法，通过自监督目标和数据增强策略生成高质量伪噪声，采用迭代多尺度训练机制训练参数化反演求解器，实现了快速准确的图像到噪声映射。


<details>
  <summary>Details</summary>
Motivation: 当前扩散反演任务由于缺乏有效的监督信号而面临挑战，现有方法多采用基于近似的解决方案，但往往以性能或效率为代价。

Method: 提出自监督目标和数据增强策略生成伪噪声，采用迭代多尺度训练机制训练参数化反演求解器，实现逐步预测反演噪声。

Result: 在COCO数据集上，DeepInv相比EasyInv提升40.435% SSIM，相比ReNoise提升9887.5%的推理速度。

Conclusion: DeepInv是首个提出可训练求解器逐步预测反演噪声的方法，在性能和效率上均显著优于现有方法，为相关研究提供了新的思路。

Abstract: Diffusion inversion is a task of recovering the noise of an image in a diffusion model, which is vital for controllable diffusion image editing. At present, diffusion inversion still remains a challenging task due to the lack of viable supervision signals. Thus, most existing methods resort to approximation-based solutions, which however are often at the cost of performance or efficiency. To remedy these shortcomings, we propose a novel self-supervised diffusion inversion approach in this paper, termed Deep Inversion (DeepInv). Instead of requiring ground-truth noise annotations, we introduce a self-supervised objective as well as a data augmentation strategy to generate high-quality pseudo noises from real images without manual intervention. Based on these two innovative designs, DeepInv is also equipped with an iterative and multi-scale training regime to train a parameterized inversion solver, thereby achieving the fast and accurate image-to-noise mapping. To the best of our knowledge, this is the first attempt of presenting a trainable solver to predict inversion noise step by step. The extensive experiments show that our DeepInv can achieve much better performance and inference speed than the compared methods, e.g., +40.435% SSIM than EasyInv and +9887.5% speed than ReNoise on COCO dataset. Moreover, our careful designs of trainable solvers can also provide insights to the community. Codes and model parameters will be released in https://github.com/potato-kitty/DeepInv.

</details>


### [82] [DiffKD-DCIS: Predicting Upgrade of Ductal Carcinoma In Situ with Diffusion Augmentation and Knowledge Distillation](https://arxiv.org/abs/2601.01507)
*Tao Li,Qing Li,Na Li,Hui Xie*

Main category: cs.CV

TL;DR: DiffKD-DCIS框架通过条件扩散模型和知识蒸馏技术，提高DCIS升级为IDC的预测准确性，解决超声数据有限和泛化能力差的问题。


<details>
  <summary>Details</summary>
Motivation: 准确预测导管原位癌（DCIS）升级为浸润性导管癌（IDC）对手术规划至关重要，但传统深度学习方法因超声数据有限和泛化能力差而面临挑战。

Method: 提出DiffKD-DCIS框架，包含三个阶段：1）条件扩散模型生成高质量超声图像进行数据增强；2）深度教师网络从原始和合成数据中提取鲁棒特征；3）紧凑学生网络通过知识蒸馏从教师网络学习，平衡泛化能力和计算效率。

Result: 在多中心1,435例数据集上评估，合成图像质量良好，学生网络参数更少、推理更快。在外部测试集上优于部分组合方法，准确率与资深放射科医生相当，优于初级医生，显示显著临床潜力。

Conclusion: DiffKD-DCIS框架有效解决了数据稀缺和模型泛化问题，在DCIS升级预测中表现出优越性能，具有重要的临床应用价值。

Abstract: Accurately predicting the upgrade of ductal carcinoma in situ (DCIS) to invasive ductal carcinoma (IDC) is crucial for surgical planning. However, traditional deep learning methods face challenges due to limited ultrasound data and poor generalization ability. This study proposes the DiffKD-DCIS framework, integrating conditional diffusion modeling with teacher-student knowledge distillation.
  The framework operates in three stages: First, a conditional diffusion model generates high-fidelity ultrasound images using multimodal conditions for data augmentation. Then, a deep teacher network extracts robust features from both original and synthetic data. Finally, a compact student network learns from the teacher via knowledge distillation, balancing generalization and computational efficiency.
  Evaluated on a multi-center dataset of 1,435 cases, the synthetic images were of good quality. The student network had fewer parameters and faster inference. On external test sets, it outperformed partial combinations, and its accuracy was comparable to senior radiologists and superior to junior ones, showing significant clinical potential.

</details>


### [83] [A Novel Deep Learning Method for Segmenting the Left Ventricle in Cardiac Cine MRI](https://arxiv.org/abs/2601.01512)
*Wenhui Chu,Aobo Jin,Hardik A. Gohel*

Main category: cs.CV

TL;DR: GBU-Net是一种基于组批归一化U-Net框架的新型深度学习网络，专门用于短轴电影MRI扫描中左心室的精确语义分割，在SunnyBrook测试数据集上达到97%的dice分数。


<details>
  <summary>Details</summary>
Motivation: 传统CNN分割方法在心脏MRI分割中往往忽略重要的上下文信息，需要开发能够更好捕捉上下文理解的新型网络结构来提高左心室分割的准确性。

Method: 采用组批归一化U-Net框架，包含下采样路径进行特征提取和上采样路径进行细节恢复，专门针对医学影像进行了优化，包含改进的上下文理解技术。使用45名患者的805个左心室MRI扫描数据进行训练和验证。

Result: GBU-Net在左心室分割任务中显著优于现有方法，在SunnyBrook测试数据集上通过集成方法达到了97%的dice分数，超越了标准的dice系数和平均垂直距离等指标。

Conclusion: GBU-Net通过其创新的设计提供了增强的精度和上下文理解能力，在左心室分割方面表现出色，适用于手术机器人和医学分析应用。

Abstract: This research aims to develop a novel deep learning network, GBU-Net, utilizing a group-batch-normalized U-Net framework, specifically designed for the precise semantic segmentation of the left ventricle in short-axis cine MRI scans. The methodology includes a down-sampling pathway for feature extraction and an up-sampling pathway for detail restoration, enhanced for medical imaging. Key modifications include techniques for better contextual understanding crucial in cardiac MRI segmentation. The dataset consists of 805 left ventricular MRI scans from 45 patients, with comparative analysis using established metrics such as the dice coefficient and mean perpendicular distance. GBU-Net significantly improves the accuracy of left ventricle segmentation in cine MRI scans. Its innovative design outperforms existing methods in tests, surpassing standard metrics like the dice coefficient and mean perpendicular distance. The approach is unique in its ability to capture contextual information, often missed in traditional CNN-based segmentation. An ensemble of the GBU-Net attains a 97% dice score on the SunnyBrook testing dataset. GBU-Net offers enhanced precision and contextual understanding in left ventricle segmentation for surgical robotics and medical analysis.

</details>


### [84] [FastV-RAG: Towards Fast and Fine-Grained Video QA with Retrieval-Augmented Generation](https://arxiv.org/abs/2601.01513)
*Gen Li,Peiyu Liu*

Main category: cs.CV

TL;DR: VideoSpeculateRAG是一个基于推测解码的视觉语言模型检索增强生成框架，通过轻量级草稿模型快速生成候选答案并由重量级模型验证，同时使用相似性过滤策略改进实体对齐，在保持高准确率的同时将推理速度提升约2倍。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在整合外部知识方面存在困难，检索增强生成方法效率低下且难以保持高质量答案。需要解决推理延迟和实体识别错误两大核心问题。

Method: 1) 推测解码管道：轻量级模型快速生成多个候选答案，重量级模型进行验证和精炼；2) 相似性过滤策略：基于相似度过滤检索知识中的错误实体识别，改善实体对齐。

Result: 实验表明VideoSpeculateRAG在达到或超过标准RAG方法准确率的同时，推理速度提升约2倍。

Conclusion: 该框架展示了将推测解码与检索增强推理相结合在复杂知识密集型多模态任务中提高效率和可靠性的潜力。

Abstract: Vision-Language Models (VLMs) excel at visual reasoning but still struggle with integrating external knowledge. Retrieval-Augmented Generation (RAG) is a promising solution, but current methods remain inefficient and often fail to maintain high answer quality. To address these challenges, we propose VideoSpeculateRAG, an efficient VLM-based RAG framework built on two key ideas. First, we introduce a speculative decoding pipeline: a lightweight draft model quickly generates multiple answer candidates, which are then verified and refined by a more accurate heavyweight model, substantially reducing inference latency without sacrificing correctness. Second, we identify a major source of error - incorrect entity recognition in retrieved knowledge - and mitigate it with a simple yet effective similarity-based filtering strategy that improves entity alignment and boosts overall answer accuracy. Experiments demonstrate that VideoSpeculateRAG achieves comparable or higher accuracy than standard RAG approaches while accelerating inference by approximately 2x. Our framework highlights the potential of combining speculative decoding with retrieval-augmented reasoning to enhance efficiency and reliability in complex, knowledge-intensive multimodal tasks.

</details>


### [85] [BARE: Towards Bias-Aware and Reasoning-Enhanced One-Tower Visual Grounding](https://arxiv.org/abs/2601.01526)
*Hongbing Li,Linhui Xiao,Zihan Zhao,Qi Shen,Yixiang Huang,Bo Xiao,Zhanyu Ma*

Main category: cs.CV

TL;DR: BARE是一个用于单塔视觉定位的偏置感知和推理增强框架，通过三个新模块解决多模态表示过度纠缠和语义推理不足的问题，在五个基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 当前单塔视觉定位方法存在两个主要限制：(1) 过度纠缠的多模态表示加剧了欺骗性模态偏置；(2) 语义推理不足阻碍了参考线索的理解。

Method: BARE框架引入三个新模块：语言显著性调制器、视觉偏置校正和参考关系增强，共同减轻多模态干扰并增强参考理解能力。

Result: 在五个基准测试上的广泛实验表明，BARE不仅实现了最先进的性能，而且相比现有方法具有更优越的计算效率。

Conclusion: BARE通过保持模态特定特征和构建参考语义，有效解决了视觉定位中的多模态偏置和推理不足问题，为单塔架构提供了高效的解决方案。

Abstract: Visual Grounding (VG), which aims to locate a specific region referred to by expressions, is a fundamental yet challenging task in the multimodal understanding fields. While recent grounding transfer works have advanced the field through one-tower architectures, they still suffer from two primary limitations: (1) over-entangled multimodal representations that exacerbate deceptive modality biases, and (2) insufficient semantic reasoning that hinders the comprehension of referential cues. In this paper, we propose BARE, a bias-aware and reasoning-enhanced framework for one-tower visual grounding. BARE introduces a mechanism that preserves modality-specific features and constructs referential semantics through three novel modules: (i) language salience modulator, (ii) visual bias correction and (iii) referential relationship enhancement, which jointly mitigate multimodal distractions and enhance referential comprehension. Extensive experimental results on five benchmarks demonstrate that BARE not only achieves state-of-the-art performance but also delivers superior computational efficiency compared to existing approaches. The code is publicly accessible at https://github.com/Marloweeee/BARE.

</details>


### [86] [Improving Flexible Image Tokenizers for Autoregressive Image Generation](https://arxiv.org/abs/2601.01535)
*Zixuan Fu,Lanqing Guo,Chong Wang,Binbin Song,Ding Liu,Bihan Wen*

Main category: cs.CV

TL;DR: ReToK是一种灵活的图像tokenizer，通过冗余token填充和分层语义正则化来解决传统方法中图像信息过度集中在早期token的问题，提升自回归图像生成效果。


<details>
  <summary>Details</summary>
Motivation: 传统灵活图像tokenizer使用嵌套dropout策略，导致图像信息过度集中在序列前部token，限制了长序列下的自回归图像生成效果。

Method: 提出ReToK方法：1）冗余token填充，增加尾部token的激活频率；2）分层语义正则化，对齐早期token与预训练视觉基础模型的解码特征，同时向尾部逐渐降低正则化强度以保留细节。

Result: 在ImageNet 256×256数据集上，ReToK相比固定长度和灵活tokenizer都取得了更优的生成性能。

Conclusion: ReToK通过平衡token间的信息分布和分层语义约束，有效提升了灵活tokenizer在自回归图像生成中的表现。

Abstract: Flexible image tokenizers aim to represent an image using an ordered 1D variable-length token sequence. This flexible tokenization is typically achieved through nested dropout, where a portion of trailing tokens is randomly truncated during training, and the image is reconstructed using the remaining preceding sequence. However, this tail-truncation strategy inherently concentrates the image information in the early tokens, limiting the effectiveness of downstream AutoRegressive (AR) image generation as the token length increases. To overcome these limitations, we propose \textbf{ReToK}, a flexible tokenizer with \underline{Re}dundant \underline{Tok}en Padding and Hierarchical Semantic Regularization, designed to fully exploit all tokens for enhanced latent modeling. Specifically, we introduce \textbf{Redundant Token Padding} to activate tail tokens more frequently, thereby alleviating information over-concentration in the early tokens. In addition, we apply \textbf{Hierarchical Semantic Regularization} to align the decoding features of earlier tokens with those from a pre-trained vision foundation model, while progressively reducing the regularization strength toward the tail to allow finer low-level detail reconstruction. Extensive experiments demonstrate the effectiveness of ReTok: on ImageNet 256$\times$256, our method achieves superior generation performance compared with both flexible and fixed-length tokenizers. Code will be available at: \href{https://github.com/zfu006/ReTok}{https://github.com/zfu006/ReTok}

</details>


### [87] [FAR-AMTN: Attention Multi-Task Network for Face Attribute Recognition](https://arxiv.org/abs/2601.01537)
*Gong Gao,Zekai Wang,Xianhui Liu,Weidong Zhao*

Main category: cs.CV

TL;DR: 本文提出FAR-AMTN，一种用于人脸属性识别的注意力多任务网络，通过权重共享和跨组特征融合来提升泛化性能并减少参数数量。


<details>
  <summary>Details</summary>
Motivation: 传统多任务网络在共享低层模块和独立高层模块的设计导致参数随任务数量指数增长，且限制了高层特征交互和语义关系探索，影响泛化性能。

Method: 提出权重共享组特定注意力模块(WSGSA)减少复杂度，跨组特征融合模块(CGFF)促进属性组间交互，动态权重策略(DWS)实现任务同步收敛。

Result: 在CelebA和LFWA数据集上的实验表明，FAR-AMTN在准确率上优于现有模型，且参数数量显著减少。

Conclusion: FAR-AMTN通过创新的注意力机制和特征融合策略，有效解决了多任务人脸属性识别中的参数效率和泛化性能问题。

Abstract: To enhance the generalization performance of Multi-Task Networks (MTN) in Face Attribute Recognition (FAR), it is crucial to share relevant information across multiple related prediction tasks effectively. Traditional MTN methods create shared low-level modules and distinct high-level modules, causing an exponential increase in model parameters with the addition of tasks. This approach also limits feature interaction at the high level, hindering the exploration of semantic relations among attributes, thereby affecting generalization negatively. In response, this study introduces FAR-AMTN, a novel Attention Multi-Task Network for FAR. It incorporates a Weight-Shared Group-Specific Attention (WSGSA) module with shared parameters to minimize complexity while improving group feature representation. Furthermore, a Cross-Group Feature Fusion (CGFF) module is utilized to foster interactions between attribute groups, enhancing feature learning. A Dynamic Weighting Strategy (DWS) is also introduced for synchronized task convergence. Experiments on the CelebA and LFWA datasets demonstrate that the proposed FAR-AMTN demonstrates superior accuracy with significantly fewer parameters compared to existing models.

</details>


### [88] [EscherVerse: An Open World Benchmark and Dataset for Teleo-Spatial Intelligence with Physical-Dynamic and Intent-Driven Understanding](https://arxiv.org/abs/2601.01547)
*Tianjun Gu,Chenghua Gong,Jingyu Gong,Zhizhong Zhang,Yuan Xie,Lizhuang Ma,Xin Tan*

Main category: cs.CV

TL;DR: 提出了Teleo-Spatial Intelligence (TSI)新范式，结合物理动态推理和意图驱动推理，并推出EscherVerse基准、数据集和模型来推动TSI研究。


<details>
  <summary>Details</summary>
Motivation: 当前空间智能研究忽视了人类意图在空间变化中的作用，需要从被动场景描述转向目的驱动的整体理解。

Method: 引入TSI范式，包含物理动态推理和意图驱动推理两个支柱；构建EscherVerse基准（Escher-Bench）、数据集（Escher-35k）和模型系列；开发新颖的数据筛选流程。

Result: EscherVerse是首个系统评估意图驱动推理的基准，基于真实世界视频，评估对象持久性、状态转换和轨迹预测能力。

Conclusion: 该工作为推进空间智能从被动场景描述转向目的驱动的整体世界理解提供了基础资源。

Abstract: The ability to reason about spatial dynamics is a cornerstone of intelligence, yet current research overlooks the human intent behind spatial changes. To address these limitations, we introduce Teleo-Spatial Intelligence (TSI), a new paradigm that unifies two critical pillars: Physical-Dynamic Reasoning--understanding the physical principles of object interactions--and Intent-Driven Reasoning--inferring the human goals behind these actions. To catalyze research in TSI, we present EscherVerse, consisting of a large-scale, open-world benchmark (Escher-Bench), a dataset (Escher-35k), and models (Escher series). Derived from real-world videos, EscherVerse moves beyond constrained settings to explicitly evaluate an agent's ability to reason about object permanence, state transitions, and trajectory prediction in dynamic, human-centric scenarios. Crucially, it is the first benchmark to systematically assess Intent-Driven Reasoning, challenging models to connect physical events to their underlying human purposes. Our work, including a novel data curation pipeline, provides a foundational resource to advance spatial intelligence from passive scene description toward a holistic, purpose-driven understanding of the world.

</details>


### [89] [Beyond Patches: Global-aware Autoregressive Model for Multimodal Few-Shot Font Generation](https://arxiv.org/abs/2601.01593)
*Haonan Cai,Yuxuan Luo,Zhouhui Lian*

Main category: cs.CV

TL;DR: GAR-Font是一个新颖的自回归多模态少样本字体生成框架，通过全局感知分词器、多模态风格编码器和后处理细化流程，解决了传统方法在结构完整性和风格保真度方面的不足。


<details>
  <summary>Details</summary>
Motivation: 传统少样本字体生成方法存在两个主要问题：1）基于补丁的分词方法忽略了全局依赖关系；2）仅依赖视觉参考而忽视了语言在传达字体设计意图中的作用。

Method: 提出GAR-Font框架，包含：1）全局感知分词器捕捉局部结构和全局风格模式；2）多模态风格编码器通过轻量级语言风格适配器实现灵活风格控制；3）后处理细化流程增强结构保真度和风格一致性。

Result: 大量实验表明，GAR-Font在保持全局风格忠实度和通过文本风格指导获得更高质量结果方面优于现有FFG方法。

Conclusion: GAR-Font通过结合视觉和语言模态，有效解决了少样本字体生成中的结构完整性和风格保真度问题，为自动化字体设计提供了更优的解决方案。

Abstract: Manual font design is an intricate process that transforms a stylistic visual concept into a coherent glyph set. This challenge persists in automated Few-shot Font Generation (FFG), where models often struggle to preserve both the structural integrity and stylistic fidelity from limited references. While autoregressive (AR) models have demonstrated impressive generative capabilities, their application to FFG is constrained by conventional patch-level tokenization, which neglects global dependencies crucial for coherent font synthesis. Moreover, existing FFG methods remain within the image-to-image paradigm, relying solely on visual references and overlooking the role of language in conveying stylistic intent during font design. To address these limitations, we propose GAR-Font, a novel AR framework for multimodal few-shot font generation. GAR-Font introduces a global-aware tokenizer that effectively captures both local structures and global stylistic patterns, a multimodal style encoder offering flexible style control through a lightweight language-style adapter without requiring intensive multimodal pretraining, and a post-refinement pipeline that further enhances structural fidelity and style coherence. Extensive experiments show that GAR-Font outperforms existing FFG methods, excelling in maintaining global style faithfulness and achieving higher-quality results with textual stylistic guidance.

</details>


### [90] [Guiding Token-Sparse Diffusion Models](https://arxiv.org/abs/2601.01608)
*Felix Krause,Stefan Andreas Baumann,Johannes Schusterbauer,Olga Grebenkova,Ming Gui,Vincent Tao Hu,Björn Ommer*

Main category: cs.CV

TL;DR: 本文提出Sparse Guidance（SG）方法，通过利用token级稀疏性来改进稀疏训练的扩散模型在推理时的性能，解决了传统Classifier-free Guidance（CFG）在稀疏训练模型上效果不佳的问题。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像合成中表现出色，但训练和推理成本高昂。现有稀疏训练方法虽然降低了训练成本，但推理时由于对Classifier-free Guidance响应不佳导致性能下降。

Method: 提出Sparse Guidance（SG），使用token级稀疏性而非条件dropout来引导扩散模型，更好地保留条件预测的高方差特性。在推理时利用token级稀疏性，在降低计算量的同时提高保真度。

Result: 在ImageNet-256基准测试上达到1.58 FID，计算量减少25%；在匹配基线质量时最高可节省58%的FLOPs。使用2.5B文本到图像扩散模型验证，在构图和人类偏好评分方面均有提升，同时提高了吞吐量。

Conclusion: Sparse Guidance有效解决了稀疏训练扩散模型在推理时的性能问题，在保持高质量输出的同时显著降低了计算成本，为大规模扩散模型的实际应用提供了可行方案。

Abstract: Diffusion models deliver high quality in image synthesis but remain expensive during training and inference. Recent works have leveraged the inherent redundancy in visual content to make training more affordable by training only on a subset of visual information. While these methods were successful in providing cheaper and more effective training, sparsely trained diffusion models struggle in inference. This is due to their lacking response to Classifier-free Guidance (CFG) leading to underwhelming performance during inference. To overcome this, we propose Sparse Guidance (SG). Instead of using conditional dropout as a signal to guide diffusion models, SG uses token-level sparsity. As a result, SG preserves the high-variance of the conditional prediction better, achieving good quality and high variance outputs. Leveraging token-level sparsity at inference, SG improves fidelity at lower compute, achieving 1.58 FID on the commonly used ImageNet-256 benchmark with 25% fewer FLOPs, and yields up to 58% FLOP savings at matched baseline quality. To demonstrate the effectiveness of Sparse Guidance, we train a 2.5B text-to-image diffusion model using training time sparsity and leverage SG during inference. SG achieves improvements in composition and human preference score while increasing throughput at the same time.

</details>


### [91] [CAP-IQA: Context-Aware Prompt-Guided CT Image Quality Assessment](https://arxiv.org/abs/2601.01613)
*Kazi Ramisa Rifa,Jie Zhang,Abdullah Imran*

Main category: cs.CV

TL;DR: 本文提出了CAP-IQA框架，通过结合文本级先验和实例级上下文提示，并应用因果去偏技术来改进CT图像质量评估。该方法在LDCTIQA挑战基准上表现优异，并在儿科CT数据集上验证了泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于提示的方法在CT图像质量评估中应用有限，且容易因反映理想化定义而产生偏差，无法有效处理真实世界中的噪声、运动伪影等退化问题。

Method: CAP-IQA框架结合CNN视觉编码器和领域特定文本编码器，使用放射学风格提示和上下文感知融合来对齐语义和感知表示，并通过因果去偏分离理想化知识与实际图像退化。

Result: 在2023年LDCTIQA挑战基准上，CAP-IQA获得2.8590的总相关性得分（PLCC、SROCC和KROCC之和），比排行榜第一名高出4.24%。在91,514张儿科CT图像上的评估验证了其泛化能力。

Conclusion: 提示引导融合和简化的编码器设计共同增强了特征对齐和可解释性，CAP-IQA框架在CT图像质量评估中表现出优越性能和良好泛化能力。

Abstract: Prompt-based methods, which encode medical priors through descriptive text, have been only minimally explored for CT Image Quality Assessment (IQA). While such prompts can embed prior knowledge about diagnostic quality, they often introduce bias by reflecting idealized definitions that may not hold under real-world degradations such as noise, motion artifacts, or scanner variability. To address this, we propose the Context-Aware Prompt-guided Image Quality Assessment (CAP-IQA) framework, which integrates text-level priors with instance-level context prompts and applies causal debiasing to separate idealized knowledge from factual, image-specific degradations. Our framework combines a CNN-based visual encoder with a domain-specific text encoder to assess diagnostic visibility, anatomical clarity, and noise perception in abdominal CT images. The model leverages radiology-style prompts and context-aware fusion to align semantic and perceptual representations. On the 2023 LDCTIQA challenge benchmark, CAP-IQA achieves an overall correlation score of 2.8590 (sum of PLCC, SROCC, and KROCC), surpassing the top-ranked leaderboard team (2.7427) by 4.24%. Moreover, our comprehensive ablation experiments confirm that prompt-guided fusion and the simplified encoder-only design jointly enhance feature alignment and interpretability. Furthermore, evaluation on an in-house dataset of 91,514 pediatric CT images demonstrates the true generalizability of CAP-IQA in assessing perceptual fidelity in a different patient population.

</details>


### [92] [An Empirical Study of Monocular Human Body Measurement Under Weak Calibration](https://arxiv.org/abs/2601.01639)
*Gaurav Sekar*

Main category: cs.CV

TL;DR: 本文系统评估了三种弱标定单目RGB图像人体测量方法，分析了标定假设对测量稳定性、鲁棒性和失败模式的影响，揭示了用户标定努力与测量结果稳定性之间的权衡关系。


<details>
  <summary>Details</summary>
Motivation: 单目RGB图像人体测量面临尺度模糊、视角敏感和深度信息缺失等挑战，需要研究不同标定策略在实际消费级设备上的适用性。

Method: 采用三种弱标定单目策略：基于地标的几何方法、姿态驱动回归方法和物体标定轮廓方法，在受控条件下使用消费级相机进行系统性实证评估。

Result: 研究发现标定假设对测量行为有显著影响，不同体型下测量稳定性和失败模式存在差异，用户标定努力与周长测量稳定性呈现明显的权衡关系。

Conclusion: 本研究为面向消费级设备的轻量级单目人体测量系统提供了实证设计参考，强调了标定策略选择对系统性能的重要影响。

Abstract: Estimating human body measurements from monocular RGB imagery remains challenging due to scale ambiguity, viewpoint sensitivity, and the absence of explicit depth information. This work presents a systematic empirical study of three weakly calibrated monocular strategies: landmark-based geometry, pose-driven regression, and object-calibrated silhouettes, evaluated under semi-constrained conditions using consumer-grade cameras. Rather than pursuing state-of-the-art accuracy, the study analyzes how differing calibration assumptions influence measurement behavior, robustness, and failure modes across varied body types. The results reveal a clear trade-off between user effort during calibration and the stability of resulting circumferential quantities. This paper serves as an empirical design reference for lightweight monocular human measurement systems intended for deployment on consumer devices.

</details>


### [93] [Animated 3DGS Avatars in Diverse Scenes with Consistent Lighting and Shadows](https://arxiv.org/abs/2601.01660)
*Aymen Mir,Riza Alp Guler,Jian Wang,Gerard Pons-Moll,Bing Zhou*

Main category: cs.CV

TL;DR: 提出了Deep Gaussian Shadow Maps (DGSM)方法，用于在3D高斯泼溅(3DGS)场景中实现动态角色与场景交互时的一致光照和阴影效果。


<details>
  <summary>Details</summary>
Motivation: 解决3D高斯泼溅场景中动态角色与场景交互时的光照一致性问题，特别是阴影的生成和接收，避免传统方法需要的网格化过程。

Method: 基于经典深度阴影映射思想，利用3DGS的封闭形式光累积特性，在同心径向壳上计算透射率并存储在八面体图集中；使用球形谐波( SH)基表示HDRI探针进行快速每高斯辐射传输来实现角色重光照。

Result: 在AvatarX、ActorsHQ等角色数据集和ScanNet++、DL3DV、SuperSplat等场景中展示了环境一致的光照效果，支持单角色和多角色设置下的阴影交互。

Conclusion: DGSM和SH重光照方法完全在体积3DGS表示中运行，能够产生连贯的阴影和重光照效果，同时避免了网格化的需求。

Abstract: We present a method for consistent lighting and shadows when animated 3D Gaussian Splatting (3DGS) avatars interact with 3DGS scenes or with dynamic objects inserted into otherwise static scenes. Our key contribution is Deep Gaussian Shadow Maps (DGSM), a modern analogue of the classical shadow mapping algorithm tailored to the volumetric 3DGS representation. Building on the classic deep shadow mapping idea, we show that 3DGS admits closed form light accumulation along light rays, enabling volumetric shadow computation without meshing. For each estimated light, we tabulate transmittance over concentric radial shells and store them in octahedral atlases, which modern GPUs can sample in real time per query to attenuate affected scene Gaussians and thus cast and receive shadows consistently. To relight moving avatars, we approximate the local environment illumination with HDRI probes represented in a spherical harmonic (SH) basis and apply a fast per Gaussian radiance transfer, avoiding explicit BRDF estimation or offline optimization. We demonstrate environment consistent lighting for avatars from AvatarX and ActorsHQ, composited into ScanNet++, DL3DV, and SuperSplat scenes, and show interactions with inserted objects. Across single and multi avatar settings, DGSM and SH relighting operate fully in the volumetric 3DGS representation, yielding coherent shadows and relighting while avoiding meshing.

</details>


### [94] [LabelAny3D: Label Any Object 3D in the Wild](https://arxiv.org/abs/2601.01676)
*Jin Yao,Radowan Mahmud Redoy,Sebastian Elbaum,Matthew B. Dwyer,Zezhou Cheng*

Main category: cs.CV

TL;DR: LabelAny3D是一个通过分析-合成框架从2D图像重建3D场景来生成高质量3D边界框标注的系统，并基于此构建了COCO3D基准数据集，显著提升了单目3D检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有单目3D检测模型在真实世界图像上表现不佳，主要原因是缺乏野外3D数据集和3D标注的挑战性。

Method: 采用分析-合成框架，从2D图像重建整体3D场景，高效生成高质量的3D边界框标注。

Result: LabelAny3D生成的标注在多个基准测试中提升了单目3D检测性能，质量优于先前的自动标注方法。

Conclusion: 基础模型驱动的标注方法在扩展现实开放世界环境中的3D识别方面具有广阔前景。

Abstract: Detecting objects in 3D space from monocular input is crucial for applications ranging from robotics to scene understanding. Despite advanced performance in the indoor and autonomous driving domains, existing monocular 3D detection models struggle with in-the-wild images due to the lack of 3D in-the-wild datasets and the challenges of 3D annotation. We introduce LabelAny3D, an \emph{analysis-by-synthesis} framework that reconstructs holistic 3D scenes from 2D images to efficiently produce high-quality 3D bounding box annotations. Built on this pipeline, we present COCO3D, a new benchmark for open-vocabulary monocular 3D detection, derived from the MS-COCO dataset and covering a wide range of object categories absent from existing 3D datasets. Experiments show that annotations generated by LabelAny3D improve monocular 3D detection performance across multiple benchmarks, outperforming prior auto-labeling approaches in quality. These results demonstrate the promise of foundation-model-driven annotation for scaling up 3D recognition in realistic, open-world settings.

</details>


### [95] [Trustworthy Data-Driven Wildfire Risk Prediction and Understanding in Western Canada](https://arxiv.org/abs/2601.01677)
*Zhengsen Xu,Lanying Wang,Sibo Cheng,Xue Rui,Kyle Gao,Yimin Zhu,Mabel Heffring,Zack Dewis,Saeid Taleghanidoozdoozan,Megan Greenwood,Motasem Alkayid,Quinn Ledingham,Hongjie He,Jonathan Li,Lincoln Linlin Xu*

Main category: cs.CV

TL;DR: 提出一个基于长序列多尺度时间建模的可信赖野火风险预测框架，在加拿大西部2023-2024年火灾季节表现优异，F1分数达0.90，PR-AUC达0.98，并支持不确定性量化和过程级解释。


<details>
  <summary>Details</summary>
Motivation: 加拿大西部野火活动加剧导致重大社会经济和环境损失，但传统数据驱动模型因野火点燃和传播的随机性以及多因素非线性相互作用而存在可靠性和可解释性问题。

Method: 基于长序列多尺度时间建模的可信赖数据驱动框架，整合异质驱动因素，显式量化预测不确定性，支持过程级解释。

Result: 在2023-2024年创纪录火灾季节中，模型优于现有时间序列方法，F1分数0.90，PR-AUC 0.98，计算成本低。不确定性分析显示预测置信度的结构化时空模式。

Conclusion: 该框架为野火风险管理提供了可靠工具，SHAP解释揭示了温度相关驱动因素主导野火风险，而湿度相关约束在2024年对空间和土地覆盖特异性对比的影响更强。

Abstract: In recent decades, the intensification of wildfire activity in western Canada has resulted in substantial socio-economic and environmental losses. Accurate wildfire risk prediction is hindered by the intrinsic stochasticity of ignition and spread and by nonlinear interactions among fuel conditions, meteorology, climate variability, topography, and human activities, challenging the reliability and interpretability of purely data-driven models. We propose a trustworthy data-driven wildfire risk prediction framework based on long-sequence, multi-scale temporal modeling, which integrates heterogeneous drivers while explicitly quantifying predictive uncertainty and enabling process-level interpretation. Evaluated over western Canada during the record-breaking 2023 and 2024 fire seasons, the proposed model outperforms existing time-series approaches, achieving an F1 score of 0.90 and a PR-AUC of 0.98 with low computational cost. Uncertainty-aware analysis reveals structured spatial and seasonal patterns in predictive confidence, highlighting increased uncertainty associated with ambiguous predictions and spatiotemporal decision boundaries. SHAP-based interpretation provides mechanistic understanding of wildfire controls, showing that temperature-related drivers dominate wildfire risk in both years, while moisture-related constraints play a stronger role in shaping spatial and land-cover-specific contrasts in 2024 compared to the widespread hot and dry conditions of 2023. Data and code are available at https://github.com/SynUW/mmFire.

</details>


### [96] [Evaluating Deep Learning-Based Face Recognition for Infants and Toddlers: Impact of Age Across Developmental Stages](https://arxiv.org/abs/2601.01680)
*Afzal Hossain,Mst Rumana Sumi,Stephanie Schuckers*

Main category: cs.CV

TL;DR: 本研究评估了四种深度学习人脸识别模型在0-3岁婴幼儿纵向数据集上的表现，发现早期婴儿识别准确率低（30.7% TAR），但随着年龄增长显著提升至64.7%。通过DANN方法减少特征漂移，使TAR提高12%以上。


<details>
  <summary>Details</summary>
Motivation: 婴幼儿人脸识别面临面部快速变化、类间相似度高和数据集稀缺的独特挑战，这对智慧城市中的儿童医疗、安全和身份服务等应用至关重要。

Method: 使用FaceNet、ArcFace、MagFace和CosFace四种模型，在24个月内分7个时段采集的0-3岁儿童纵向数据集上进行测试，并应用DANN方法来减少特征漂移。

Result: 0-6个月婴儿识别准确率仅30.7%（0.1% FAR下），2.5-3岁儿童提升至64.7%。时间间隔越短识别率越高，DANN方法使TAR提升超过12%。

Conclusion: 婴幼儿早期人脸识别具有挑战性，需要开发能处理时间变化的隐私保护生物认证系统，特别是在需要儿童验证的安全城市环境中。

Abstract: Face recognition for infants and toddlers presents unique challenges due to rapid facial morphology changes, high inter-class similarity, and limited dataset availability. This study evaluates the performance of four deep learning-based face recognition models FaceNet, ArcFace, MagFace, and CosFace on a newly developed longitudinal dataset collected over a 24 month period in seven sessions involving children aged 0 to 3 years. Our analysis examines recognition accuracy across developmental stages, showing that the True Accept Rate (TAR) is only 30.7% at 0.1% False Accept Rate (FAR) for infants aged 0 to 6 months, due to unstable facial features. Performance improves significantly in older children, reaching 64.7% TAR at 0.1% FAR in the 2.5 to 3 year age group. We also evaluate verification performance over different time intervals, revealing that shorter time gaps result in higher accuracy due to reduced embedding drift. To mitigate this drift, we apply a Domain Adversarial Neural Network (DANN) approach that improves TAR by over 12%, yielding features that are more temporally stable and generalizable. These findings are critical for building biometric systems that function reliably over time in smart city applications such as public healthcare, child safety, and digital identity services. The challenges observed in early age groups highlight the importance of future research on privacy preserving biometric authentication systems that can address temporal variability, particularly in secure and regulated urban environments where child verification is essential.

</details>


### [97] [FALCON: Few-Shot Adversarial Learning for Cross-Domain Medical Image Segmentation](https://arxiv.org/abs/2601.01687)
*Abdur R. Fayjie,Pankhi Kashyap,Jutika Borah,Patrick Vandewalle*

Main category: cs.CV

TL;DR: FALCON是一个跨域少样本3D医学图像分割框架，通过2D切片处理实现高精度分割，在少量标注数据下达到最先进的边界精度。


<details>
  <summary>Details</summary>
Motivation: 解决3D医学图像分割面临的标注数据稀缺、患者个体差异、数据隐私和计算开销大的挑战。

Method: 先在自然图像上进行元训练学习可泛化的分割先验，然后通过对抗性微调和边界感知学习迁移到医学领域，使用任务感知推理动态适应患者特异性变化。

Result: 在四个基准测试中，FALCON实现了最低的Hausdorff距离（表明边界精度最优），同时保持与最先进模型相当的Dice相似系数，且使用更少的标注数据、无数据增强和显著降低的计算开销。

Conclusion: FALCON框架在3D医学图像分割中实现了高精度和高效性，为临床应用中数据稀缺和计算资源受限的场景提供了可行解决方案。

Abstract: Precise delineation of anatomical and pathological structures within 3D medical volumes is crucial for accurate diagnosis, effective surgical planning, and longitudinal disease monitoring. Despite advancements in AI, clinically viable segmentation is often hindered by the scarcity of 3D annotations, patient-specific variability, data privacy concerns, and substantial computational overhead. In this work, we propose FALCON, a cross-domain few-shot segmentation framework that achieves high-precision 3D volume segmentation by processing data as 2D slices. The framework is first meta-trained on natural images to learn-to-learn generalizable segmentation priors, then transferred to the medical domain via adversarial fine-tuning and boundary-aware learning. Task-aware inference, conditioned on support cues, allows FALCON to adapt dynamically to patient-specific anatomical variations across slices. Experiments on four benchmarks demonstrate that FALCON consistently achieves the lowest Hausdorff Distance scores, indicating superior boundary accuracy while maintaining a Dice Similarity Coefficient comparable to the state-of-the-art models. Notably, these results are achieved with significantly less labeled data, no data augmentation, and substantially lower computational overhead.

</details>


### [98] [Mitigating Longitudinal Performance Degradation in Child Face Recognition Using Synthetic Data](https://arxiv.org/abs/2601.01689)
*Afzal Hossain,Stephanie Schuckers*

Main category: cs.CV

TL;DR: 该研究探讨了使用合成人脸数据作为纵向稳定器，以提高儿童人脸识别模型的时间鲁棒性。通过在YFA数据集上进行实验，发现结合真实和合成数据的微调能显著降低错误率。


<details>
  <summary>Details</summary>
Motivation: 儿童人脸识别面临挑战，因为快速且非线性的面部生长导致模板漂移和验证错误随时间增加。研究旨在验证合成数据能否改善儿童人脸识别的身份持久性。

Method: 使用MagFace嵌入，比较三种设置：预训练模型、仅用真实数据微调、以及结合真实和合成数据微调。合成数据通过StyleGAN2 ADA生成，并经过过滤以避免身份泄漏和伪影。

Result: 实验结果显示，在6到36个月的验证间隔中，合成数据增强的微调显著降低了错误率，优于预训练基准和仅用真实数据微调的方法。

Conclusion: 合成数据增强可以有效提高儿童人脸识别的时序鲁棒性，为儿科人脸识别的身份持久性提供了风险感知的评估。

Abstract: Longitudinal face recognition in children remains challenging due to rapid and nonlinear facial growth, which causes template drift and increasing verification errors over time. This work investigates whether synthetic face data can act as a longitudinal stabilizer by improving temporal robustness of child face recognition models. Using an identity disjoint protocol on the Young Face Aging (YFA) dataset, we evaluate three settings: (i) pretrained MagFace embeddings without dataset specific fine-tuning, (ii) MagFace fine-tuned using authentic training faces only, and (iii) MagFace fine-tuned using a combination of authentic and synthetically generated training faces. Synthetic data is generated using StyleGAN2 ADA and incorporated exclusively within the training identities; a post generation filtering step is applied to mitigate identity leakage and remove artifact affected samples. Experimental results across enrollment verification gaps from 6 to 36 months show that synthetic-augmented fine tuning substantially reduces error rates relative to both the pretrained baseline and real only fine tuning. These findings provide a risk aware assessment of synthetic augmentation for improving identity persistence in pediatric face recognition.

</details>


### [99] [Learnability-Driven Submodular Optimization for Active Roadside 3D Detection](https://arxiv.org/abs/2601.01695)
*Ruiyu Mao,Baoming Zhang,Nicholas Ruozzi,Yunhui Guo*

Main category: cs.CV

TL;DR: 该论文提出了一种基于可学习性的主动学习框架LH3D，用于路边单目3D目标检测，通过选择既信息丰富又可靠可标注的场景，在仅使用25%标注预算的情况下达到接近全数据集的性能。


<details>
  <summary>Details</summary>
Motivation: 现实部署中由于硬件和隐私限制，通常只能标注路边单目数据，但许多场景中存在距离远、模糊或被遮挡的物体，其3D属性在单视角下具有固有模糊性，导致标注困难和成本增加。

Method: 提出基于可学习性的主动学习框架，选择既信息丰富又可靠可标注的场景，抑制固有模糊样本，同时确保覆盖范围。

Result: 在DAIR-V2X-I数据集上，仅使用25%标注预算就达到了车辆86.06%、行人67.32%、骑车人78.67%的全性能，显著优于基于不确定性的基线方法。

Conclusion: 实验证实对于路边3D感知，可学习性而非不确定性才是关键因素。

Abstract: Roadside perception datasets are typically constructed via cooperative labeling between synchronized vehicle and roadside frame pairs. However, real deployment often requires annotation of roadside-only data due to hardware and privacy constraints. Even human experts struggle to produce accurate labels without vehicle-side data (image, LIDAR), which not only increases annotation difficulty and cost, but also reveals a fundamental learnability problem: many roadside-only scenes contain distant, blurred, or occluded objects whose 3D properties are ambiguous from a single view and can only be reliably annotated by cross-checking paired vehicle--roadside frames. We refer to such cases as inherently ambiguous samples. To reduce wasted annotation effort on inherently ambiguous samples while still obtaining high-performing models, we turn to active learning. This work focuses on active learning for roadside monocular 3D object detection and proposes a learnability-driven framework that selects scenes which are both informative and reliably labelable, suppressing inherently ambiguous samples while ensuring coverage. Experiments demonstrate that our method, LH3D, achieves 86.06%, 67.32%, and 78.67% of full-performance for vehicles, pedestrians, and cyclists respectively, using only 25% of the annotation budget on DAIR-V2X-I, significantly outperforming uncertainty-based baselines. This confirms that learnability, not uncertainty, matters for roadside 3D perception.

</details>


### [100] [FFP-300K: Scaling First-Frame Propagation for Generalizable Video Editing](https://arxiv.org/abs/2601.01720)
*Xijie Huang,Chengming Xu,Donghao Luo,Xiaobin Hu,Peng Tang,Xu Peng,Jiangning Zhang,Chengjie Wang,Yanwei Fu*

Main category: cs.CV

TL;DR: 本文提出了一种无需运行时引导的First-Frame Propagation方法，通过构建FFP-300K大规模数据集和引入AST-RoPE架构及自蒸馏策略，解决了视频编辑中外观保持与运动保持的冲突。


<details>
  <summary>Details</summary>
Motivation: 现有FFP方法依赖于繁琐的运行时引导，主要原因是当前训练数据集存在长度短、分辨率低、任务多样性不足等问题，无法学习到稳健的时间先验。

Method: 1. 构建FFP-300K数据集（30万对720p分辨率、81帧的高保真视频对）；2. 提出自适应时空RoPE（AST-RoPE）动态重映射位置编码；3. 采用身份传播任务的自蒸馏策略作为正则化器。

Result: 在EditVerseBench基准测试中，相比现有学术和商业模型，PickScore提升约0.2分，VLM评分提升约0.3分，显著优于竞争对手。

Conclusion: 该方法通过解决数据集不足和架构目标冲突，实现了真正无需引导的FFP，在保持长期时间稳定性和防止语义漂移方面表现出色。

Abstract: First-Frame Propagation (FFP) offers a promising paradigm for controllable video editing, but existing methods are hampered by a reliance on cumbersome run-time guidance. We identify the root cause of this limitation as the inadequacy of current training datasets, which are often too short, low-resolution, and lack the task diversity required to teach robust temporal priors. To address this foundational data gap, we first introduce FFP-300K, a new large-scale dataset comprising 300K high-fidelity video pairs at 720p resolution and 81 frames in length, constructed via a principled two-track pipeline for diverse local and global edits. Building on this dataset, we propose a novel framework designed for true guidance-free FFP that resolves the critical tension between maintaining first-frame appearance and preserving source video motion. Architecturally, we introduce Adaptive Spatio-Temporal RoPE (AST-RoPE), which dynamically remaps positional encodings to disentangle appearance and motion references. At the objective level, we employ a self-distillation strategy where an identity propagation task acts as a powerful regularizer, ensuring long-term temporal stability and preventing semantic drift. Comprehensive experiments on the EditVerseBench benchmark demonstrate that our method significantly outperforming existing academic and commercial models by receiving about 0.2 PickScore and 0.3 VLM score improvement against these competitors.

</details>


### [101] [Point-SRA: Self-Representation Alignment for 3D Representation Learning](https://arxiv.org/abs/2601.01746)
*Lintong Wei,Jian Lu,Haozhe Cheng,Jihua Zhu,Kaibing Zhang*

Main category: cs.CV

TL;DR: Point-SRA是一种3D表示学习方法，通过自蒸馏和概率建模解决现有MAE方法在点云表示学习中的局限性，在多个下游任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有MAE方法使用固定掩码比率，忽略了多级表示相关性和内在几何结构，且基于点对点重构假设与点云多样性相冲突。

Method: 提出Point-SRA方法，为MAE分配不同掩码比率以捕获互补信息，使用MeanFlow Transformer进行多样化概率重构，并引入双自表示对齐机制和流条件微调架构。

Result: 在ScanObjectNN上比Point-MAE提升5.37%，颅内动脉瘤分割达到96.07%平均IoU（动脉）和86.87%（动脉瘤），3D目标检测达到47.3% AP@50，超越MaskPoint 5.12%。

Conclusion: Point-SRA通过多尺度掩码、概率建模和表示对齐，有效提升了3D表示学习性能，在多个任务中取得显著改进。

Abstract: Masked autoencoders (MAE) have become a dominant paradigm in 3D representation learning, setting new performance benchmarks across various downstream tasks. Existing methods with fixed mask ratio neglect multi-level representational correlations and intrinsic geometric structures, while relying on point-wise reconstruction assumptions that conflict with the diversity of point cloud. To address these issues, we propose a 3D representation learning method, termed Point-SRA, which aligns representations through self-distillation and probabilistic modeling. Specifically, we assign different masking ratios to the MAE to capture complementary geometric and semantic information, while the MeanFlow Transformer (MFT) leverages cross-modal conditional embeddings to enable diverse probabilistic reconstruction. Our analysis further reveals that representations at different time steps in MFT also exhibit complementarity. Therefore, a Dual Self-Representation Alignment mechanism is proposed at both the MAE and MFT levels. Finally, we design a Flow-Conditioned Fine-Tuning Architecture to fully exploit the point cloud distribution learned via MeanFlow. Point-SRA outperforms Point-MAE by 5.37% on ScanObjectNN. On intracranial aneurysm segmentation, it reaches 96.07% mean IoU for arteries and 86.87% for aneurysms. For 3D object detection, Point-SRA achieves 47.3% AP@50, surpassing MaskPoint by 5.12%.

</details>


### [102] [MANGO:Natural Multi-speaker 3D Talking Head Generation via 2D-Lifted Enhancement](https://arxiv.org/abs/2601.01749)
*Lei Zhu,Lijian Lin,Ye Zhu,Jiahao Wu,Xuehan Hou,Yu Li,Yunfei Liu,Jie Chen*

Main category: cs.CV

TL;DR: 本文提出了MANGO框架，通过两阶段训练和纯图像级监督来解决多人对话中3D头部生成的自然交互问题，显著提升了3D对话动作的准确性和真实感。


<details>
  <summary>Details</summary>
Motivation: 当前音频驱动的3D头部生成方法主要针对单说话人场景，缺乏自然的双向听-说交互能力。现有方法依赖伪3D标签，无法捕捉细粒度面部动态，导致对话行为不自然。

Method: 提出两阶段框架MANGO：第一阶段使用基于扩散的transformer和双音频交互模块从多人音频建模自然3D动作；第二阶段使用快速3D高斯渲染器生成高保真图像，通过交替训练提供2D级光度监督。

Result: 实验表明，该方法在建模两人3D对话动作方面取得了优异的准确性和真实感，显著提升了音频驱动说话头部的保真度和可控性。

Conclusion: MANGO框架通过纯图像级监督和交替训练策略，有效解决了多人对话场景中3D头部生成的自然交互挑战，为音频驱动的对话头像提供了高质量的解决方案。

Abstract: Current audio-driven 3D head generation methods mainly focus on single-speaker scenarios, lacking natural, bidirectional listen-and-speak interaction. Achieving seamless conversational behavior, where speaking and listening states transition fluidly remains a key challenge. Existing 3D conversational avatar approaches rely on error-prone pseudo-3D labels that fail to capture fine-grained facial dynamics. To address these limitations, we introduce a novel two-stage framework MANGO, which leveraging pure image-level supervision by alternately training to mitigate the noise introduced by pseudo-3D labels, thereby achieving better alignment with real-world conversational behaviors. Specifically, in the first stage, a diffusion-based transformer with a dual-audio interaction module models natural 3D motion from multi-speaker audio. In the second stage, we use a fast 3D Gaussian Renderer to generate high-fidelity images and provide 2D-level photometric supervision for the 3D motions through alternate training. Additionally, we introduce MANGO-Dialog, a high-quality dataset with over 50 hours of aligned 2D-3D conversational data across 500+ identities. Extensive experiments demonstrate that our method achieves exceptional accuracy and realism in modeling two-person 3D dialogue motion, significantly advancing the fidelity and controllability of audio-driven talking heads.

</details>


### [103] [CTIS-QA: Clinical Template-Informed Slide-level Question Answering for Pathology](https://arxiv.org/abs/2601.01769)
*Hao Lu,Ziniu Qian,Yifu Li,Yang Zhou,Bingzheng Wei,Yan Xu*

Main category: cs.CV

TL;DR: 本文提出基于临床诊断模板的病理信息结构化收集流程，构建了CTIS-Align和CTIS-Bench数据集，并开发了CTIS-QA双流模型，在WSI视觉问答任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决病理报告中信息提取不标准化的问题，构建能够反映真实诊断工作流程的视觉问答基准，提升全切片图像（WSI）的自动诊断能力。

Method: 1）设计临床病理报告模板（CPRT）标准化提取病理特征；2）构建CTIS-Align（8万张切片-描述对）和CTIS-Bench（977张WSI的1.4万问答对）数据集；3）提出CTIS-QA双流模型，结合全局上下文和局部区域感知。

Result: 在WSI-VQA、CTIS-Bench和切片级诊断任务上的广泛实验表明，CTIS-QA在多个指标上持续优于现有最先进模型。

Conclusion: 该方法通过标准化模板和双流架构有效提升了WSI的视觉问答性能，为临床病理诊断提供了可靠的技术支持。

Abstract: In this paper, we introduce a clinical diagnosis template-based pipeline to systematically collect and structure pathological information. In collaboration with pathologists and guided by the the College of American Pathologists (CAP) Cancer Protocols, we design a Clinical Pathology Report Template (CPRT) that ensures comprehensive and standardized extraction of diagnostic elements from pathology reports. We validate the effectiveness of our pipeline on TCGA-BRCA. First, we extract pathological features from reports using CPRT. These features are then used to build CTIS-Align, a dataset of 80k slide-description pairs from 804 WSIs for vision-language alignment training, and CTIS-Bench, a rigorously curated VQA benchmark comprising 977 WSIs and 14,879 question-answer pairs. CTIS-Bench emphasizes clinically grounded, closed-ended questions (e.g., tumor grade, receptor status) that reflect real diagnostic workflows, minimize non-visual reasoning, and require genuine slide understanding. We further propose CTIS-QA, a Slide-level Question Answering model, featuring a dual-stream architecture that mimics pathologists' diagnostic approach. One stream captures global slide-level context via clustering-based feature aggregation, while the other focuses on salient local regions through attention-guided patch perception module. Extensive experiments on WSI-VQA, CTIS-Bench, and slide-level diagnostic tasks show that CTIS-QA consistently outperforms existing state-of-the-art models across multiple metrics. Code and data are available at https://github.com/HLSvois/CTIS-QA.

</details>


### [104] [Subimage Overlap Prediction: Task-Aligned Self-Supervised Pretraining For Semantic Segmentation In Remote Sensing Imagery](https://arxiv.org/abs/2601.01781)
*Lakshay Sharma,Alex Marin*

Main category: cs.CV

TL;DR: 该论文提出了一种名为Subimage Overlap Prediction的自监督学习方法，用于遥感图像语义分割，相比传统方法显著减少预训练数据需求，同时实现更快的收敛速度和同等或更好的性能。


<details>
  <summary>Details</summary>
Motivation: 当前自监督学习方法需要大量预训练数据，这在遥感图像领域成本高昂。本文旨在开发一种数据效率更高的预训练方法。

Method: 提出子图像重叠预测任务：从原图像中提取子图像，训练模型预测子图像在原图像中的位置语义掩码。

Result: 该方法在多个架构和数据集上验证，显示能显著加快收敛速度，在标记数据减少时性能优势更明显，且所需预训练数据远少于其他自监督方法。

Conclusion: Subimage Overlap Prediction是一种高效的自监督预训练方法，特别适合数据有限的遥感图像语义分割任务。

Abstract: Self-supervised learning (SSL) methods have become a dominant paradigm for creating general purpose models whose capabilities can be transferred to downstream supervised learning tasks. However, most such methods rely on vast amounts of pretraining data. This work introduces Subimage Overlap Prediction, a novel self-supervised pretraining task to aid semantic segmentation in remote sensing imagery that uses significantly lesser pretraining imagery. Given an image, a sub-image is extracted and the model is trained to produce a semantic mask of the location of the extracted sub-image within the original image. We demonstrate that pretraining with this task results in significantly faster convergence, and equal or better performance (measured via mIoU) on downstream segmentation. This gap in convergence and performance widens when labeled training data is reduced. We show this across multiple architecture types, and with multiple downstream datasets. We also show that our method matches or exceeds performance while requiring significantly lesser pretraining data relative to other SSL methods. Code and model weights are provided at \href{https://github.com/sharmalakshay93/subimage-overlap-prediction}{github.com/sharmalakshay93/subimage-overlap-prediction}.

</details>


### [105] [DDNet: A Dual-Stream Graph Learning and Disentanglement Framework for Temporal Forgery Localization](https://arxiv.org/abs/2601.01784)
*Boyang Zhao,Xin Liao,Jiaxin Chen,Xiaoshuai Wu,Yufeng Wu*

Main category: cs.CV

TL;DR: 提出DDNet框架，通过双流图学习和解缠技术解决视频篡改检测中局部视图限制问题，显著提升时间伪造定位精度和跨域鲁棒性。


<details>
  <summary>Details</summary>
Motivation: AIGC技术的快速发展使得仅篡改视频小片段即可误导观众，现有方法因局限于局部视图而无法捕捉全局异常，导致检测不准确。

Method: DDNet框架包含时间距离流（检测局部伪影）和语义内容流（捕获长程连接），结合痕迹解缠与适应（TDA）技术分离通用伪造指纹，以及跨层级特征嵌入（CLFE）实现层次特征深度融合。

Result: 在ForgeryNet和TVIL基准测试中，AP@0.95指标比现有最优方法提升约9%，跨域鲁棒性显著改善。

Conclusion: DDNet通过全局与局部特征协同分析，有效解决了时间伪造定位问题，为视频篡改检测提供了更可靠的解决方案。

Abstract: The rapid evolution of AIGC technology enables misleading viewers by tampering mere small segments within a video, rendering video-level detection inaccurate and unpersuasive. Consequently, temporal forgery localization (TFL), which aims to precisely pinpoint tampered segments, becomes critical. However, existing methods are often constrained by \emph{local view}, failing to capture global anomalies. To address this, we propose a \underline{d}ual-stream graph learning and \underline{d}isentanglement framework for temporal forgery localization (DDNet). By coordinating a \emph{Temporal Distance Stream} for local artifacts and a \emph{Semantic Content Stream} for long-range connections, DDNet prevents global cues from being drowned out by local smoothness. Furthermore, we introduce Trace Disentanglement and Adaptation (TDA) to isolate generic forgery fingerprints, alongside Cross-Level Feature Embedding (CLFE) to construct a robust feature foundation via deep fusion of hierarchical features. Experiments on ForgeryNet and TVIL benchmarks demonstrate that our method outperforms state-of-the-art approaches by approximately 9\% in AP@0.95, with significant improvements in cross-domain robustness.

</details>


### [106] [VerLM: Explaining Face Verification Using Natural Language](https://arxiv.org/abs/2601.01798)
*Syed Abdul Hannan,Hazim Bukhari,Thomas Cantalapiedra,Eman Ansar,Massa Baali,Rita Singh,Bhiksha Raj*

Main category: cs.CV

TL;DR: 本文提出了一种创新的视觉语言模型，用于人脸验证，不仅能准确判断两张人脸图像是否属于同一个人，还能明确解释其决策理由。


<details>
  <summary>Details</summary>
Motivation: 当前人脸验证系统虽然取得了显著进展，但缺乏决策过程的透明度。

Method: 采用两种互补的解释风格训练模型：简洁解释总结关键因素，详细解释说明图像间的具体差异。通过将音频区分方法跨模态迁移到视觉输入，并整合先进的特征提取和推理能力。

Result: 该方法表现出优越性能，超越了基线方法和现有模型。

Conclusion: 研究结果表明视觉语言模型在人脸验证领域具有巨大潜力，有助于构建更透明、可靠和可解释的人脸验证系统。

Abstract: Face verification systems have seen substantial advancements; however, they often lack transparency in their decision-making processes. In this paper, we introduce an innovative Vision-Language Model (VLM) for Face Verification, which not only accurately determines if two face images depict the same individual but also explicitly explains the rationale behind its decisions. Our model is uniquely trained using two complementary explanation styles: (1) concise explanations that summarize the key factors influencing its decision, and (2) comprehensive explanations detailing the specific differences observed between the images. We adapt and enhance a state-of-the-art modeling approach originally designed for audio-based differentiation to suit visual inputs effectively. This cross-modal transfer significantly improves our model's accuracy and interpretability. The proposed VLM integrates sophisticated feature extraction techniques with advanced reasoning capabilities, enabling clear articulation of its verification process. Our approach demonstrates superior performance, surpassing baseline methods and existing models. These findings highlight the immense potential of vision language models in face verification set up, contributing to more transparent, reliable, and explainable face verification systems.

</details>


### [107] [Causality-Aware Temporal Projection for Video Understanding in Video-LLMs](https://arxiv.org/abs/2601.01804)
*Zhengjian Kang,Qi Chen,Rui Liu,Kangtong Mo,Xingyu Zhang,Xiaoyu Deng,Ye Zhang*

Main category: cs.CV

TL;DR: V-CORE是一个参数高效的视频理解框架，通过引入显式时间顺序约束来解决现有视频大语言模型在时序推理方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有参数高效的视频大语言模型依赖无约束的双向投影器来建模帧间交互，这会模糊时间顺序，因为允许后续帧影响先前表示，缺乏对视频推理方向性的显式架构约束。

Method: V-CORE包含两个核心组件：可学习的空间聚合（LSA）自适应选择显著空间标记以减少冗余，以及因果感知时间投影器（CATP）通过块因果注意力和终端动态摘要标记强制单向信息流。

Result: 在NExT-QA基准测试中达到61.2%的准确率，在MSVD-QA、MSRVTT-QA和TGIF-QA上保持竞争力，在时序和因果推理子类别分别提升3.5%和5.2%。

Conclusion: 显式时间顺序约束对视频理解至关重要，V-CORE在保持参数效率的同时显著提升了时序和因果推理能力。

Abstract: Recent Video Large Language Models (Video-LLMs) have shown strong multimodal reasoning capabilities, yet remain challenged by video understanding tasks that require consistent temporal ordering and causal coherence. Many parameter-efficient Video-LLMs rely on unconstrained bidirectional projectors to model inter-frame interactions, which can blur temporal ordering by allowing later frames to influence earlier representations, without explicit architectural mechanisms to respect the directional nature of video reasoning. To address this limitation, we propose V-CORE, a parameter-efficient framework that introduces explicit temporal ordering constraints for video understanding. V-CORE consists of two key components: (1) Learnable Spatial Aggregation (LSA), which adaptively selects salient spatial tokens to reduce redundancy, and (2) a Causality-Aware Temporal Projector (CATP), which enforces structured unidirectional information flow via block-causal attention and a terminal dynamic summary token acting as a causal sink. This design preserves intra-frame spatial interactions while ensuring that temporal information is aggregated in a strictly ordered manner. With 4-bit QLoRA and a frozen LLM backbone, V-CORE can be trained efficiently on a single consumer GPU. Experiments show that V-CORE achieves strong performance on the challenging NExT-QA benchmark, reaching 61.2% accuracy, and remains competitive across MSVD-QA, MSRVTT-QA, and TGIF-QA, with gains concentrated in temporal and causal reasoning subcategories (+3.5% and +5.2% respectively), directly validating the importance of explicit temporal ordering constraints.

</details>


### [108] [Adaptive Hybrid Optimizer based Framework for Lumpy Skin Disease Identification](https://arxiv.org/abs/2601.01807)
*Ubaidullah,Muhammad Abid Hussain,Mohsin Raza Jafri,Rozi Khan,Moid Sandhu,Abd Ullah Khan,Hyundong Shin*

Main category: cs.CV

TL;DR: LUMPNet是一种基于混合深度学习的早期检测牛结节性皮肤病的方法，通过YOLOv11检测皮肤结节，结合EfficientNet分类器进行疾病分类，并采用新型自适应混合优化器提高训练效果。


<details>
  <summary>Details</summary>
Motivation: 牛结节性皮肤病是一种传染性病毒性疾病，对全球经济和食品安全构成严重威胁。由于其快速传播特性，早期精确识别对于预防疫情暴发和确保及时干预至关重要。

Method: LUMPNet采用YOLOv11检测和定位牛图像中的皮肤结节和病变，利用基于EfficientNet的CNN分类器将局部图像分类为患病或健康类别，并使用新型自适应混合优化器来稳定和加速混合模型的训练。

Result: 在公开数据集上的评估显示，LUMPNet达到99%的训练准确率和98%的验证准确率，优于现有方案。与使用AdamW优化器的EfficientNet-B0模型相比，LUMPNet表现出更优性能。

Conclusion: LUMPNet在牛结节性皮肤病早期检测方面表现出卓越性能，为疾病防控提供了有效的技术支持。

Abstract: Lumpy Skin Disease (LSD) is a contagious viral infection that significantly deteriorates livestock health, thereby posing a serious threat to the global economy and food security. Owing to its rapid spread characteristics, early and precise identification is crucial to prevent outbreaks and ensure timely intervention. In this paper, we propose a hybrid deep learning-based approach called LUMPNet for the early detection of LSD. LUMPNet utilizes image data to detect and classify skin nodules -- the primary indicator of LSD. To this end, LUMPNet uses YOLOv11, EfficientNet-based CNN classifier with compound scaling, and a novel adaptive hybrid optimizer. More precisely, LUMPNet detects and localizes LSD skin nodules and lesions on cattle images. It exploits EfficientNet to classify the localized cattle images into LSD-affected or healthy categories. To stabilize and accelerate the training of YOLOv11 and EfficientNet hybrid model, a novel adaptive hybrid optimizer is proposed and utilized. We evaluate LUMPNet at various stages of LSD using a publicly available dataset. Results indicate that the proposed scheme achieves 99% LSD detection training accuracy, and outperforms existing schemes. The model also achieves validation accuracy of 98%. Moreover, for further evaluation, we conduct a case study using an optimized EfficientNet-B0 model trained with the AdamW optimizer, and compare its performance with LUMPNet. The results show that LUMPNet achieves superior performance.

</details>


### [109] [Robust Egocentric Visual Attention Prediction Through Language-guided Scene Context-aware Learning](https://arxiv.org/abs/2601.01818)
*Sungjune Park,Hongda Mao,Qingshuang Chen,Yong Man Ro,Yelin Kim*

Main category: cs.CV

TL;DR: 提出了一种语言引导的场景上下文感知学习框架，用于鲁棒的自我中心视觉注意力预测，通过语言描述引导上下文感知，在Ego4D和AEA数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 基于场景上下文信息在调节人类注意力中起关键作用的证据，解决动态自我中心场景的复杂性和模糊性带来的挑战。

Method: 设计语言引导的上下文感知器，基于语言场景描述生成上下文感知视频表示，并引入两个训练目标：聚焦目标感兴趣区域和抑制无关区域干扰。

Result: 在Ego4D和AEA数据集上的广泛实验表明，该方法在多样化的动态自我中心场景中实现了最先进的性能和增强的鲁棒性。

Conclusion: 语言引导的场景上下文感知学习框架能够有效提升自我中心视觉注意力预测的性能和鲁棒性。

Abstract: As the demand for analyzing egocentric videos grows, egocentric visual attention prediction, anticipating where a camera wearer will attend, has garnered increasing attention. However, it remains challenging due to the inherent complexity and ambiguity of dynamic egocentric scenes. Motivated by evidence that scene contextual information plays a crucial role in modulating human attention, in this paper, we present a language-guided scene context-aware learning framework for robust egocentric visual attention prediction. We first design a context perceiver which is guided to summarize the egocentric video based on a language-based scene description, generating context-aware video representations. We then introduce two training objectives that: 1) encourage the framework to focus on the target point-of-interest regions and 2) suppress distractions from irrelevant regions which are less likely to attract first-person attention. Extensive experiments on Ego4D and Aria Everyday Activities (AEA) datasets demonstrate the effectiveness of our approach, achieving state-of-the-art performance and enhanced robustness across diverse, dynamic egocentric scenarios.

</details>


### [110] [RSwinV2-MD: An Enhanced Residual SwinV2 Transformer for Monkeypox Detection from Skin Images](https://arxiv.org/abs/2601.01835)
*Rashid Iqbal,Saddam Hussain Khan*

Main category: cs.CV

TL;DR: 本文提出了一种名为Customized Residual SwinTransformerV2 (RSwinV2)的深度学习方法来诊断Mpox，通过使用RSwinV2工具辅助视觉方法增强病变分类能力。该方法在Kaggle公共数据集上取得了96.21的准确率和95.62的F1分数，优于标准CNN模型和SwinTransformers。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够有效识别Mpox病变的计算机辅助诊断工具，通过结合全局和局部模式识别能力，减少Mpox的变异性并增加其与水痘、麻疹和牛痘的区别。

Method: 基于SwinTransformerV2定制化开发RSwinV2方法，包括：1）根据输入维度、嵌入结构和输出目标定制分层变换器结构；2）将输入图像分割为不重叠的补丁并使用移位窗口和注意力机制处理；3）引入逆残差块（IRB）解决梯度消失问题；4）利用多头注意力机制连接全局和局部模式。

Result: 在Kaggle公共数据集上的测试结果显示，RSwinV2达到了96.21%的准确率和95.62%的F1分数，优于传统的CNN模型和标准SwinTransformers。

Conclusion: RSwinV2作为一种计算机辅助工具，在Mpox病变观察解释方面表现出色，其结合全局和局部模式识别的方法有效提升了病变分类能力，为Mpox诊断提供了可靠的技术支持。

Abstract: In this paper, a deep learning approach for Mpox diagnosis named Customized Residual SwinTransformerV2 (RSwinV2) has been proposed, trying to enhance the capability of lesion classification by employing the RSwinV2 tool-assisted vision approach. In the RSwinV2 method, a hierarchical structure of the transformer has been customized based on the input dimensionality, embedding structure, and output targeted by the method. In this RSwinV2 approach, the input image has been split into non-overlapping patches and processed using shifted windows and attention in these patches. This process has helped the method link all the windows efficiently by avoiding the locality issues of non-overlapping regions in attention, while being computationally efficient. RSwinV2 has further developed based on SwinTransformer and has included patch and position embeddings to take advantage of the transformer global-linking capability by employing multi-head attention in these embeddings. Furthermore, RSwinV2 has developed and incorporated the Inverse Residual Block (IRB) into this method, which utilizes convolutional skip connections with these inclusive designs to address the vanishing gradient issues during processing. RSwinV2 inclusion of IRB has therefore facilitated this method to link global patterns as well as local patterns; hence, its integrity has helped improve lesion classification capability by minimizing variability of Mpox and increasing differences of Mpox, chickenpox, measles, and cowpox. In testing SwinV2, its accuracy of 96.21 and an F1score of 95.62 have been achieved on the Kaggle public dataset, which has outperformed standard CNN models and SwinTransformers; RSwinV2 vector has thus proved its valiance as a computer-assisted tool for Mpox lesion observation interpretation.

</details>


### [111] [ESGaussianFace: Emotional and Stylized Audio-Driven Facial Animation via 3D Gaussian Splatting](https://arxiv.org/abs/2601.01847)
*Chuhang Ma,Shuai Tan,Ye Pan,Jiaolong Yang,Xin Tong*

Main category: cs.CV

TL;DR: ESGaussianFace是一个基于3D高斯泼溅的情感化风格化音频驱动面部动画框架，通过情感-音频引导的空间注意力和多阶段训练策略，实现高效生成高质量3D一致的面部视频。


<details>
  <summary>Details</summary>
Motivation: 当前音频驱动面部动画研究主要关注中性情绪视频生成，虽然有些研究涉及情感音频驱动，但如何高效集成情感表达和风格特征生成高质量说话头视频仍是一个重大挑战。

Method: 使用3D高斯泼溅重建3D场景并渲染视频；提出情感-音频引导的空间注意力方法集成情感和音频特征；引入两个3D高斯变形预测器实现情感和风格变形；采用多阶段训练策略分步学习唇部运动、情感变化和风格特征。

Result: 生成结果具有高效率、高质量和3D一致性；在唇部运动准确性、表情变化和风格特征表现力方面优于现有最先进技术。

Conclusion: ESGaussianFace方法在情感化风格化音频驱动面部动画方面表现出色，通过创新的3D高斯泼溅框架和训练策略，成功解决了高质量情感风格面部视频生成的挑战。

Abstract: Most current audio-driven facial animation research primarily focuses on generating videos with neutral emotions. While some studies have addressed the generation of facial videos driven by emotional audio, efficiently generating high-quality talking head videos that integrate both emotional expressions and style features remains a significant challenge. In this paper, we propose ESGaussianFace, an innovative framework for emotional and stylized audio-driven facial animation. Our approach leverages 3D Gaussian Splatting to reconstruct 3D scenes and render videos, ensuring efficient generation of 3D consistent results. We propose an emotion-audio-guided spatial attention method that effectively integrates emotion features with audio content features. Through emotion-guided attention, the model is able to reconstruct facial details across different emotional states more accurately. To achieve emotional and stylized deformations of the 3D Gaussian points through emotion and style features, we introduce two 3D Gaussian deformation predictors. Futhermore, we propose a multi-stage training strategy, enabling the step-by-step learning of the character's lip movements, emotional variations, and style features. Our generated results exhibit high efficiency, high quality, and 3D consistency. Extensive experimental results demonstrate that our method outperforms existing state-of-the-art techniques in terms of lip movement accuracy, expression variation, and style feature expressiveness.

</details>


### [112] [GCR: Geometry-Consistent Routing for Task-Agnostic Continual Anomaly Detection](https://arxiv.org/abs/2601.01856)
*Joongwon Chae,Lihui Luo,Yang Liu,Runming Wang,Dongmei Yu,Zeming Liang,Xi Yuan,Dayan Zhang,Zhenglin Chen,Peiwu Qin,Ilmoon Chae*

Main category: cs.CV

TL;DR: GCR提出了一种基于几何一致性路由的轻量级专家混合框架，用于稳定任务无关的持续异常检测，通过直接在共享嵌入空间中进行路由决策，避免了跨头分数比较问题。


<details>
  <summary>Details</summary>
Motivation: 实际工业部署中需要任务无关的持续类别扩展操作，但现有方法在跨头路由时存在分数分布不一致问题，导致路由决策不稳定。

Method: GCR在共享的冻结补丁嵌入空间中通过最小化累积最近原型距离来进行路由决策，然后仅在选定的专家内使用标准基于原型的评分规则计算异常图。

Result: 在MVTec AD和VisA数据集上的实验表明，几何一致性路由显著提高了路由稳定性，缓解了持续性能崩溃，实现了接近零遗忘，同时保持了竞争力的检测和定位性能。

Conclusion: 许多先前归因于表示遗忘的失败实际上可以解释为跨头路由中决策规则的不稳定性，GCR通过分离路由决策和异常评分有效解决了这一问题。

Abstract: Feature-based anomaly detection is widely adopted in industrial inspection due to the strong representational power of large pre-trained vision encoders. While most existing methods focus on improving within-category anomaly scoring, practical deployments increasingly require task-agnostic operation under continual category expansion, where the category identity is unknown at test time. In this setting, overall performance is often dominated by expert selection, namely routing an input to an appropriate normality model before any head-specific scoring is applied. However, routing rules that compare head-specific anomaly scores across independently constructed heads are unreliable in practice, as score distributions can differ substantially across categories in scale and tail behavior.
  We propose GCR, a lightweight mixture-of-experts framework for stabilizing task-agnostic continual anomaly detection through geometry-consistent routing. GCR routes each test image directly in a shared frozen patch-embedding space by minimizing an accumulated nearest-prototype distance to category-specific prototype banks, and then computes anomaly maps only within the routed expert using a standard prototype-based scoring rule. By separating cross-head decision making from within-head anomaly scoring, GCR avoids cross-head score comparability issues without requiring end-to-end representation learning.
  Experiments on MVTec AD and VisA show that geometry-consistent routing substantially improves routing stability and mitigates continual performance collapse, achieving near-zero forgetting while maintaining competitive detection and localization performance. These results indicate that many failures previously attributed to representation forgetting can instead be explained by decision-rule instability in cross-head routing. Code is available at https://github.com/jw-chae/GCR

</details>


### [113] [RRNet: Configurable Real-Time Video Enhancement with Arbitrary Local Lighting Variations](https://arxiv.org/abs/2601.01865)
*Wenlong Yang,Canran Jin,Weihang Yuan,Chao Wang,Lifeng Sun*

Main category: cs.CV

TL;DR: RRNet是一个轻量级实时视频增强框架，通过虚拟光源参数估计实现局部重照明，在光照不均条件下平衡了视觉质量与效率


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在实时应用中平衡速度与有效曝光控制，特别是在不均匀光照条件下

Method: 使用轻量级编码器和预测头，通过估计虚拟光源参数实现深度感知的局部重照明，无需像素对齐训练数据

Result: RRNet在低光增强、局部光照调整和眩光去除方面持续优于现有方法，支持实时高分辨率性能

Conclusion: RRNet具有可解释的照明控制和高效架构，适用于视频会议、AR人像增强和移动摄影等实际应用

Abstract: With the growing demand for real-time video enhancement in live applications, existing methods often struggle to balance speed and effective exposure control, particularly under uneven lighting. We introduce RRNet (Rendering Relighting Network), a lightweight and configurable framework that achieves a state-of-the-art tradeoff between visual quality and efficiency. By estimating parameters for a minimal set of virtual light sources, RRNet enables localized relighting through a depth-aware rendering module without requiring pixel-aligned training data. This object-aware formulation preserves facial identity and supports real-time, high-resolution performance using a streamlined encoder and lightweight prediction head. To facilitate training, we propose a generative AI-based dataset creation pipeline that synthesizes diverse lighting conditions at low cost. With its interpretable lighting control and efficient architecture, RRNet is well suited for practical applications such as video conferencing, AR-based portrait enhancement, and mobile photography. Experiments show that RRNet consistently outperforms prior methods in low-light enhancement, localized illumination adjustment, and glare removal.

</details>


### [114] [Entity-Guided Multi-Task Learning for Infrared and Visible Image Fusion](https://arxiv.org/abs/2601.01870)
*Wenyu Shao,Hongbo Liu,Yunchuan Ma,Ruili Wang*

Main category: cs.CV

TL;DR: 提出了一种基于实体引导多任务学习的红外与可见光图像融合方法EGMT，通过提取实体级文本信息、构建多任务学习架构和跨模态交互模块，显著提升了融合图像的质量和语义密度。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本的红外与可见光图像融合方法通常依赖句子级文本信息，存在语义噪声问题且未能充分利用文本的深层语义价值。

Method: 1) 从大视觉语言模型生成的图像描述中提取实体级文本信息；2) 构建并行多任务学习架构，将图像融合与多标签分类任务结合；3) 开发实体引导的跨模态交互模块，实现视觉与实体级文本特征的细粒度交互。

Result: 在四个公开数据集上的广泛实验表明，EGMT在保留显著目标、纹理细节和语义一致性方面优于现有最先进方法。

Conclusion: EGMT方法通过实体引导和多任务学习有效解决了语义噪声问题，提升了图像融合质量，相关代码和数据集将公开提供。

Abstract: Existing text-driven infrared and visible image fusion approaches often rely on textual information at the sentence level, which can lead to semantic noise from redundant text and fail to fully exploit the deeper semantic value of textual information. To address these issues, we propose a novel fusion approach named Entity-Guided Multi-Task learning for infrared and visible image fusion (EGMT). Our approach includes three key innovative components: (i) A principled method is proposed to extract entity-level textual information from image captions generated by large vision-language models, eliminating semantic noise from raw text while preserving critical semantic information; (ii) A parallel multi-task learning architecture is constructed, which integrates image fusion with a multi-label classification task. By using entities as pseudo-labels, the multi-label classification task provides semantic supervision, enabling the model to achieve a deeper understanding of image content and significantly improving the quality and semantic density of the fused image; (iii) An entity-guided cross-modal interactive module is also developed to facilitate the fine-grained interaction between visual and entity-level textual features, which enhances feature representation by capturing cross-modal dependencies at both inter-visual and visual-entity levels. To promote the wide application of the entity-guided image fusion framework, we release the entity-annotated version of four public datasets (i.e., TNO, RoadScene, M3FD, and MSRS). Extensive experiments demonstrate that EGMT achieves superior performance in preserving salient targets, texture details, and semantic consistency, compared to the state-of-the-art methods. The code and dataset will be publicly available at https://github.com/wyshao-01/EGMT.

</details>


### [115] [CogFlow: Bridging Perception and Reasoning through Knowledge Internalization for Visual Mathematical Problem Solving](https://arxiv.org/abs/2601.01874)
*Shuhang Chen,Yunqiu Xu,Junjie Xie,Aojun Lu,Tao Feng,Zeying Huang,Ning Zhang,Yi Sun,Yi Yang,Hangjie Yuan*

Main category: cs.CV

TL;DR: CogFlow是一个受认知启发的三阶段框架，通过感知→内化→推理的层次流程解决多模态大语言模型在视觉数学问题解决中的视觉感知瓶颈问题，确保视觉线索的忠实整合和合理利用。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅关注改进视觉输入的提取和解释，但忽略了提取的视觉线索是否被忠实整合和合理利用到后续推理中的关键问题。

Method: 提出CogFlow三阶段框架：1）感知阶段使用协同视觉奖励提升符号和图表的信息提取；2）内化阶段引入知识内化奖励模型确保视觉线索忠实整合；3）推理阶段使用视觉门控策略优化算法防止模型寻求视觉未接地推理捷径。

Result: 在常用视觉数学推理基准测试上的综合实验验证了CogFlow的优越性，并贡献了包含12万+高质量感知-推理对齐注释的MathCog数据集。

Conclusion: CogFlow通过模拟人类推理的层次流程，全面增强感知、内化和推理阶段，有效解决了视觉数学推理中的视觉感知瓶颈问题。

Abstract: Despite significant progress, multimodal large language models continue to struggle with visual mathematical problem solving. Some recent works recognize that visual perception is a bottleneck in visual mathematical reasoning, but their solutions are limited to improving the extraction and interpretation of visual inputs. Notably, they all ignore the key issue of whether the extracted visual cues are faithfully integrated and properly utilized in subsequent reasoning. Motivated by this, we present CogFlow, a novel cognitive-inspired three-stage framework that incorporates a knowledge internalization stage, explicitly simulating the hierarchical flow of human reasoning: perception$\Rightarrow$internalization$\Rightarrow$reasoning. Inline with this hierarchical flow, we holistically enhance all its stages. We devise Synergistic Visual Rewards to boost perception capabilities in parametric and semantic spaces, jointly improving visual information extraction from symbols and diagrams. To guarantee faithful integration of extracted visual cues into subsequent reasoning, we introduce a Knowledge Internalization Reward model in the internalization stage, bridging perception and reasoning. Moreover, we design a Visual-Gated Policy Optimization algorithm to further enforce the reasoning is grounded with the visual knowledge, preventing models seeking shortcuts that appear coherent but are visually ungrounded reasoning chains. Moreover, we contribute a new dataset MathCog for model training, which contains samples with over 120K high-quality perception-reasoning aligned annotations. Comprehensive experiments and analysis on commonly used visual mathematical reasoning benchmarks validate the superiority of the proposed CogFlow.

</details>


### [116] [Agentic AI in Remote Sensing: Foundations, Taxonomy, and Emerging Systems](https://arxiv.org/abs/2601.01891)
*Niloufar Alipour Talemi,Julia Boone,Fatemeh Afghah*

Main category: cs.CV

TL;DR: 本文首次全面综述了遥感领域中的代理人工智能，提出了单代理和多代理系统的统一分类法，分析了规划机制、检索增强生成和记忆结构等架构基础，并展望了自主地理空间智能的发展路线图。


<details>
  <summary>Details</summary>
Motivation: 当前地球观测分析正从静态深度学习模型转向自主代理AI，但现有的视觉基础模型和多模态大语言模型在复杂地理空间工作流中缺乏顺序规划和主动工具协调能力。

Method: 通过系统调研和分析，建立了代理AI在遥感领域的分类体系，重点研究了规划机制、RAG技术和记忆结构等核心架构要素。

Result: 提出了从像素级精度评估转向轨迹感知推理正确性的新兴基准，并识别了在接地性、安全性和协调性方面的关键挑战。

Conclusion: 这项工作为开发稳健、自主的地理空间智能系统制定了战略路线图，指明了未来研究方向。

Abstract: The paradigm of Earth Observation analysis is shifting from static deep learning models to autonomous agentic AI. Although recent vision foundation models and multimodal large language models advance representation learning, they often lack the sequential planning and active tool orchestration required for complex geospatial workflows. This survey presents the first comprehensive review of agentic AI in remote sensing. We introduce a unified taxonomy distinguishing between single-agent copilots and multi-agent systems while analyzing architectural foundations such as planning mechanisms, retrieval-augmented generation, and memory structures. Furthermore, we review emerging benchmarks that move the evaluation from pixel-level accuracy to trajectory-aware reasoning correctness. By critically examining limitations in grounding, safety, and orchestration, this work outlines a strategic roadmap for the development of robust, autonomous geospatial intelligence.

</details>


### [117] [Forget Less by Learning from Parents Through Hierarchical Relationships](https://arxiv.org/abs/2601.01892)
*Arjun Ramesh Kaushik,Naresh Kumar Devulapally,Vishnu Suresh Lokhande,Nalini K. Ratha,Venu Govindaraju*

Main category: cs.CV

TL;DR: 本文提出FLLP框架，通过在双曲空间中引入父子概念学习机制来缓解定制扩散模型中的灾难性遗忘问题


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注最小化概念间干扰，但忽视了概念间正向交互的潜力。定制扩散模型在顺序学习新概念时容易发生灾难性遗忘

Method: FLLP框架在洛伦兹流形中嵌入概念表示，定义父子关系，让先前学习的概念作为新概念适应的指导。利用双曲空间天然适合建模树状层次结构的特性

Result: 在三个公共数据集和一个合成基准上的验证表明，FLLP在鲁棒性和泛化能力方面均取得一致改进

Conclusion: 该方法不仅保留了先验知识，还支持新概念的持续集成，有效缓解了灾难性遗忘问题

Abstract: Custom Diffusion Models (CDMs) offer impressive capabilities for personalization in generative modeling, yet they remain vulnerable to catastrophic forgetting when learning new concepts sequentially. Existing approaches primarily focus on minimizing interference between concepts, often neglecting the potential for positive inter-concept interactions. In this work, we present Forget Less by Learning from Parents (FLLP), a novel framework that introduces a parent-child inter-concept learning mechanism in hyperbolic space to mitigate forgetting. By embedding concept representations within a Lorentzian manifold, naturally suited to modeling tree-like hierarchies, we define parent-child relationships in which previously learned concepts serve as guidance for adapting to new ones. Our method not only preserves prior knowledge but also supports continual integration of new concepts. We validate FLLP on three public datasets and one synthetic benchmark, showing consistent improvements in both robustness and generalization.

</details>


### [118] [Nodule-DETR: A Novel DETR Architecture with Frequency-Channel Attention for Ultrasound Thyroid Nodule Detection](https://arxiv.org/abs/2601.01908)
*Jingjing Wang,Qianglin Liu,Zhuo Xiao,Xinning Yao,Bo Liu,Lu Li,Lijuan Niu,Fugen Zhou*

Main category: cs.CV

TL;DR: 提出Nodule-DETR，一种基于检测变换器的甲状腺结节检测架构，通过多光谱频域通道注意力、分层特征融合和多尺度可变形注意力三个创新模块，显著提升超声图像中甲状腺结节的检测精度。


<details>
  <summary>Details</summary>
Motivation: 甲状腺癌发病率上升，超声检测甲状腺结节时存在图像对比度低、结节边界模糊等问题，限制了诊断准确性。

Method: 设计Nodule-DETR架构，包含三个核心模块：MSFCA模块利用频域分析增强低对比度结节特征；HFF模块实现高效多尺度特征融合；MSDA模块灵活捕捉小型和不规则形状结节。

Result: 在真实临床甲状腺超声数据集上，Nodule-DETR在mAP@0.5:0.95指标上比基线模型显著提升0.149，达到最先进性能。

Conclusion: Nodule-DETR具有显著的临床应用潜力，可作为计算机辅助甲状腺诊断的有效工具。

Abstract: Thyroid cancer is the most common endocrine malignancy, and its incidence is rising globally. While ultrasound is the preferred imaging modality for detecting thyroid nodules, its diagnostic accuracy is often limited by challenges such as low image contrast and blurred nodule boundaries. To address these issues, we propose Nodule-DETR, a novel detection transformer (DETR) architecture designed for robust thyroid nodule detection in ultrasound images. Nodule-DETR introduces three key innovations: a Multi-Spectral Frequency-domain Channel Attention (MSFCA) module that leverages frequency analysis to enhance features of low-contrast nodules; a Hierarchical Feature Fusion (HFF) module for efficient multi-scale integration; and Multi-Scale Deformable Attention (MSDA) to flexibly capture small and irregularly shaped nodules. We conducted extensive experiments on a clinical dataset of real-world thyroid ultrasound images. The results demonstrate that Nodule-DETR achieves state-of-the-art performance, outperforming the baseline model by a significant margin of 0.149 in mAP@0.5:0.95. The superior accuracy of Nodule-DETR highlights its significant potential for clinical application as an effective tool in computer-aided thyroid diagnosis. The code of work is available at https://github.com/wjj1wjj/Nodule-DETR.

</details>


### [119] [Learning Action Hierarchies via Hybrid Geometric Diffusion](https://arxiv.org/abs/2601.01914)
*Arjun Ramesh Kaushik,Nalini K. Ratha,Venu Govindaraju*

Main category: cs.CV

TL;DR: 提出HybridTAS框架，结合欧几里得和双曲几何的扩散模型，利用动作的层次结构进行时序动作分割


<details>
  <summary>Details</summary>
Motivation: 现有迭代优化方法未能充分利用人类动作的层次性特征

Method: 在扩散模型去噪过程中引入双曲几何，利用其树状结构特性实现从粗到细的动作标签去噪

Result: 在GTEA、50Salads和Breakfast三个基准数据集上达到最先进性能

Conclusion: 双曲引导的去噪方法对时序动作分割任务具有显著有效性

Abstract: Temporal action segmentation is a critical task in video understanding, where the goal is to assign action labels to each frame in a video. While recent advances leverage iterative refinement-based strategies, they fail to explicitly utilize the hierarchical nature of human actions. In this work, we propose HybridTAS - a novel framework that incorporates a hybrid of Euclidean and hyperbolic geometries into the denoising process of diffusion models to exploit the hierarchical structure of actions. Hyperbolic geometry naturally provides tree-like relationships between embeddings, enabling us to guide the action label denoising process in a coarse-to-fine manner: higher diffusion timesteps are influenced by abstract, high-level action categories (root nodes), while lower timesteps are refined using fine-grained action classes (leaf nodes). Extensive experiments on three benchmark datasets, GTEA, 50Salads, and Breakfast, demonstrate that our method achieves state-of-the-art performance, validating the effectiveness of hyperbolic-guided denoising for the temporal action segmentation task.

</details>


### [120] [TalkPhoto: A Versatile Training-Free Conversational Assistant for Intelligent Image Editing](https://arxiv.org/abs/2601.01915)
*Yujie Hu,Zecheng Tang,Xu Jiang,Weiqi Li,Jian Zhang*

Main category: cs.CV

TL;DR: TalkPhoto是一个无需训练的图像编辑框架，通过对话交互实现精确图像操作，利用LLM分析用户需求并分层调用现有高级编辑方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于指令的图像编辑方法需要构建多指令数据集进行训练，耗时耗力且效果不佳，因此需要开发无需训练的灵活框架。

Method: 设计专门的提示模板指导开源LLM分析用户指令，分层调用现有的高级图像编辑方法，实现即插即用的高效调用。

Result: 实验表明该方法在减少token消耗的同时提供更准确的调用，并在各种图像编辑任务中实现更高质量的编辑效果。

Conclusion: TalkPhoto框架能够稳定处理复杂和未见过的编辑任务，无需额外训练即可实现高质量图像编辑。

Abstract: Thanks to the powerful language comprehension capabilities of Large Language Models (LLMs), existing instruction-based image editing methods have introduced Multimodal Large Language Models (MLLMs) to promote information exchange between instructions and images, ensuring the controllability and flexibility of image editing. However, these frameworks often build a multi-instruction dataset to train the model to handle multiple editing tasks, which is not only time-consuming and labor-intensive but also fails to achieve satisfactory results. In this paper, we present TalkPhoto, a versatile training-free image editing framework that facilitates precise image manipulation through conversational interaction. We instruct the open-source LLM with a specially designed prompt template to analyze user needs after receiving instructions and hierarchically invoke existing advanced editing methods, all without additional training. Moreover, we implement a plug-and-play and efficient invocation of image editing methods, allowing complex and unseen editing tasks to be integrated into the current framework, achieving stable and high-quality editing results. Extensive experiments demonstrate that our method not only provides more accurate invocation with fewer token consumption but also achieves higher editing quality across various image editing tasks.

</details>


### [121] [AR-MOT: Autoregressive Multi-object Tracking](https://arxiv.org/abs/2601.01925)
*Lianjie Jia,Yuhan Wu,Binghao Ran,Yifan Wang,Lijun Wang,Huchuan Lu*

Main category: cs.CV

TL;DR: AR-MOT是一种基于大语言模型的自回归多目标跟踪范式，将MOT任务转化为序列生成问题，无需特定任务头，具有高度可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有MOT方法架构僵化且任务特定，难以适应通用多模态场景和指令驱动任务，限制了跨任务适用性和灵活性。

Method: 提出AR-MOT自回归范式，使用对象标记器增强区域视觉感知，引入区域感知对齐模块解决全局与局部特征不对齐问题，设计时间记忆融合模块支持长期跟踪。

Result: 在MOT17和DanceTrack数据集上的实验验证了方法的可行性，性能与最先进方法相当。

Conclusion: AR-MOT为构建更通用、灵活的MOT系统奠定了基础，新模态或指令只需修改输出序列格式即可集成，无需改变模型架构。

Abstract: As multi-object tracking (MOT) tasks continue to evolve toward more general and multi-modal scenarios, the rigid and task-specific architectures of existing MOT methods increasingly hinder their applicability across diverse tasks and limit flexibility in adapting to new tracking formulations. Most approaches rely on fixed output heads and bespoke tracking pipelines, making them difficult to extend to more complex or instruction-driven tasks. To address these limitations, we propose AR-MOT, a novel autoregressive paradigm that formulates MOT as a sequence generation task within a large language model (LLM) framework. This design enables the model to output structured results through flexible sequence construction, without requiring any task-specific heads. To enhance region-level visual perception, we introduce an Object Tokenizer based on a pretrained detector. To mitigate the misalignment between global and regional features, we propose a Region-Aware Alignment (RAA) module, and to support long-term tracking, we design a Temporal Memory Fusion (TMF) module that caches historical object tokens. AR-MOT offers strong potential for extensibility, as new modalities or instructions can be integrated by simply modifying the output sequence format without altering the model architecture. Extensive experiments on MOT17 and DanceTrack validate the feasibility of our approach, achieving performance comparable to state-of-the-art methods while laying the foundation for more general and flexible MOT systems.

</details>


### [122] [MacVQA: Adaptive Memory Allocation and Global Noise Filtering for Continual Visual Question Answering](https://arxiv.org/abs/2601.01926)
*Zhifei Li,Yiran Wang,Chenyi Xiong,Yujing Xia,Xiaoju Hou,Yue Zhao,Miao Zhang,Kui Xiao,Bing Yang*

Main category: cs.CV

TL;DR: 本文提出MacVQA框架，通过自适应内存分配和全局噪声过滤解决持续学习VQA任务中的知识保留、适应性和鲁棒特征表示平衡问题。


<details>
  <summary>Details</summary>
Motivation: 当前持续学习方法在视觉问答领域难以平衡知识保留、适应新信息和鲁棒特征表示，需要解决这些挑战。

Method: MacVQA框架融合视觉和问题信息并过滤噪声，采用基于原型的记忆分配来优化特征质量和内存使用。

Result: 在10个持续VQA任务上的实验表明，MacVQA优于现有基线，标准任务平均准确率43.38%，遗忘率2.32%；新组合任务平均准确率42.53%，遗忘率3.60%。

Conclusion: MacVQA能够平衡知识获取、保留和组合泛化，在持续VQA学习中表现出色。

Abstract: Visual Question Answering (VQA) requires models to reason over multimodal information, combining visual and textual data. With the development of continual learning, significant progress has been made in retaining knowledge and adapting to new information in the VQA domain. However, current methods often struggle with balancing knowledge retention, adaptation, and robust feature representation. To address these challenges, we propose a novel framework with adaptive memory allocation and global noise filtering called MacVQA for visual question answering. MacVQA fuses visual and question information while filtering noise to ensure robust representations, and employs prototype-based memory allocation to optimize feature quality and memory usage. These designs enable MacVQA to balance knowledge acquisition, retention, and compositional generalization in continual VQA learning. Experiments on ten continual VQA tasks show that MacVQA outperforms existing baselines, achieving 43.38% average accuracy and 2.32% average forgetting on standard tasks, and 42.53% average accuracy and 3.60% average forgetting on novel composition tasks.

</details>


### [123] [Face Normal Estimation from Rags to Riches](https://arxiv.org/abs/2601.01950)
*Meng Wang,Wenjing Dai,Jiawan Zhang,Xiaojie Guo*

Main category: cs.CV

TL;DR: 提出了一种粗到精的人脸法向量估计方法，通过先训练小规模模型生成粗法向量作为引导，再使用自注意力机制进行细化，显著减少了对大规模配对数据和计算资源的需求。


<details>
  <summary>Details</summary>
Motivation: 现有的人脸法向量估计方法严重依赖大规模配对数据进行训练，本文旨在缓解这种依赖，开发一种更高效的方法。

Method: 采用粗到精的两阶段策略：1）用小数据集训练模型生成粗法向量作为引导；2）使用自注意力机制捕获长距离依赖关系，通过定制细化网络将粗法向量和输入图像映射为高质量细粒度法向量。

Result: 大量实验和消融研究表明，该方法在训练成本和估计质量方面都优于现有最先进方法，证明了设计的有效性。

Conclusion: 该方法通过逻辑功能拆分显著减少了对大规模配对数据和计算资源的需求，同时保持了高质量的法向量估计性能。

Abstract: Although recent approaches to face normal estimation have achieved promising results, their effectiveness heavily depends on large-scale paired data for training. This paper concentrates on relieving this requirement via developing a coarse-to-fine normal estimator. Concretely, our method first trains a neat model from a small dataset to produce coarse face normals that perform as guidance (called exemplars) for the following refinement. A self-attention mechanism is employed to capture long-range dependencies, thus remedying severe local artifacts left in estimated coarse facial normals. Then, a refinement network is customized for the sake of mapping input face images together with corresponding exemplars to fine-grained high-quality facial normals. Such a logical function split can significantly cut the requirement of massive paired data and computational resource. Extensive experiments and ablation studies are conducted to demonstrate the efficacy of our design and reveal its superiority over state-of-the-art methods in terms of both training expense as well as estimation quality. Our code and models are open-sourced at: https://github.com/AutoHDR/FNR2R.git.

</details>


### [124] [MotionAdapter: Video Motion Transfer via Content-Aware Attention Customization](https://arxiv.org/abs/2601.01955)
*Zhexin Zhang,Yifeng Zhu,Yangyang Xu,Long Chen,Yong Du,Shengfeng He,Jun Yu*

Main category: cs.CV

TL;DR: MotionAdapter是一个基于扩散变换器的内容感知运动迁移框架，通过解耦运动与外观并自适应定制运动，实现鲁棒且语义对齐的视频运动迁移。


<details>
  <summary>Details</summary>
Motivation: 当前基于扩散变换器的文本到视频模型在生成高质量视频方面取得显著进展，但在视频间迁移复杂运动仍具挑战性。

Method: 首先通过分析3D全注意力模块中的跨帧注意力来提取注意力驱动的运动场，实现运动与外观的显式解耦；然后引入DINO引导的运动定制模块，基于内容对应关系重新排列和精炼运动场；最后使用定制化的运动场指导DiT去噪过程。

Result: 大量实验表明，MotionAdapter在定性和定量评估中均优于现有最先进方法，并自然支持复杂运动迁移和运动编辑任务（如缩放）。

Conclusion: MotionAdapter通过内容感知的运动迁移框架，有效解决了视频间复杂运动迁移的挑战，实现了语义对齐的运动迁移效果。

Abstract: Recent advances in diffusion-based text-to-video models, particularly those built on the diffusion transformer architecture, have achieved remarkable progress in generating high-quality and temporally coherent videos. However, transferring complex motions between videos remains challenging. In this work, we present MotionAdapter, a content-aware motion transfer framework that enables robust and semantically aligned motion transfer within DiT-based T2V models. Our key insight is that effective motion transfer requires \romannumeral1) explicit disentanglement of motion from appearance and \romannumeral 2) adaptive customization of motion to target content. MotionAdapter first isolates motion by analyzing cross-frame attention within 3D full-attention modules to extract attention-derived motion fields. To bridge the semantic gap between reference and target videos, we further introduce a DINO-guided motion customization module that rearranges and refines motion fields based on content correspondences. The customized motion field is then used to guide the DiT denoising process, ensuring that the synthesized video inherits the reference motion while preserving target appearance and semantics. Extensive experiments demonstrate that MotionAdapter outperforms state-of-the-art methods in both qualitative and quantitative evaluations. Moreover, MotionAdapter naturally supports complex motion transfer and motion editing tasks such as zooming.

</details>


### [125] [AFTER: Mitigating the Object Hallucination of LVLM via Adaptive Factual-Guided Activation Editing](https://arxiv.org/abs/2601.01957)
*Tianbo Wang,Yuqing Ma,Kewei Liao,Zhange Zhang,Simin Li,Jinyang Guo,Xianglong Liu*

Main category: cs.CV

TL;DR: 提出了AFTER方法，通过事实增强的激活引导和查询自适应偏移优化来减少大视觉语言模型中的物体幻觉问题


<details>
  <summary>Details</summary>
Motivation: 现有的大视觉语言模型存在语言偏见，容易产生物体幻觉（包括类别、属性和关系幻觉），阻碍可信AI应用。之前的编辑方法忽视了事实文本语义的有效指导，难以明确缓解语言偏见

Method: AFTER方法包含两个核心组件：事实增强激活引导（FAS）提供事实和通用指导，明确建模精确的视觉-文本关联；查询自适应偏移优化（QAO）引入查询感知的偏移估计器，从通用引导向量建立查询特定的编辑

Result: 在三个广泛采用的大视觉语言模型上的标准幻觉基准测试中验证了AFTER的有效性，在AMBER基准上实现了比基线高达16.3%的幻觉减少

Conclusion: AFTER方法通过自适应地将原始有偏见的激活引导到事实语义，有效缓解了物体幻觉问题，为可信AI应用提供了有力支持

Abstract: Large Vision-Language Models (LVLMs) have achieved substantial progress in cross-modal tasks. However, due to language bias, LVLMs are susceptible to object hallucination, which can be primarily divided into category, attribute, and relation hallucination, significantly impeding the trustworthy AI applications. Editing the internal activations of LVLMs has shown promising effectiveness in mitigating hallucinations with minimal cost. However, previous editing approaches neglect the effective guidance offered by factual textual semantics, thereby struggling to explicitly mitigate language bias. To address these issues, we propose Adaptive Factual-guided Visual-Textual Editing for hallucination mitigation (AFTER), which comprises Factual-Augmented Activation Steering (FAS) and Query-Adaptive Offset Optimization (QAO), to adaptively guides the original biased activations towards factual semantics. Specifically, FAS is proposed to provide factual and general guidance for activation editing, thereby explicitly modeling the precise visual-textual associations. Subsequently, QAO introduces a query-aware offset estimator to establish query-specific editing from the general steering vector, enhancing the diversity and granularity of editing. Extensive experiments on standard hallucination benchmarks across three widely adopted LVLMs validate the efficacy of the proposed AFTER, notably achieving up to a 16.3% reduction of hallucination over baseline on the AMBER benchmark. Our code and data will be released for reproducibility.

</details>


### [126] [Forget Less by Learning Together through Concept Consolidation](https://arxiv.org/abs/2601.01963)
*Arjun Ramesh Kaushik,Naresh Kumar Devulapally,Vishnu Suresh Lokhande,Nalini Ratha,Venu Govindaraju*

Main category: cs.CV

TL;DR: FL2T框架通过跨概念交互学习解决定制扩散模型在连续学习新概念时的灾难性遗忘问题，实现并发、顺序无关的概念学习


<details>
  <summary>Details</summary>
Motivation: 现有定制扩散模型在连续学习新概念时会出现灾难性遗忘，且大多数工作忽略了概念间的交互作用

Method: 提出FL2T框架，引入集合不变性的跨概念学习模块，通过代理指导跨概念特征选择，促进知识保留和迁移

Result: 在三个数据集上的实验表明，该方法显著提高了概念保留能力，在十个任务的增量概念学习中平均CLIP图像对齐分数至少提升2%

Conclusion: 跨概念催化行为在增量概念学习中具有有效性，FL2T能够有效缓解灾难性遗忘问题

Abstract: Custom Diffusion Models (CDMs) have gained significant attention due to their remarkable ability to personalize generative processes. However, existing CDMs suffer from catastrophic forgetting when continuously learning new concepts. Most prior works attempt to mitigate this issue under the sequential learning setting with a fixed order of concept inflow and neglect inter-concept interactions. In this paper, we propose a novel framework - Forget Less by Learning Together (FL2T) - that enables concurrent and order-agnostic concept learning while addressing catastrophic forgetting. Specifically, we introduce a set-invariant inter-concept learning module where proxies guide feature selection across concepts, facilitating improved knowledge retention and transfer. By leveraging inter-concept guidance, our approach preserves old concepts while efficiently incorporating new ones. Extensive experiments, across three datasets, demonstrates that our method significantly improves concept retention and mitigates catastrophic forgetting, highlighting the effectiveness of inter-concept catalytic behavior in incremental concept learning of ten tasks with at least 2% gain on average CLIP Image Alignment scores.

</details>


### [127] [Thinking with Blueprints: Assisting Vision-Language Models in Spatial Reasoning via Structured Object Representation](https://arxiv.org/abs/2601.01984)
*Weijian Ma,Shizhao Sun,Tianyu Yu,Ruiyu Wang,Tat-Seng Chua,Jiang Bian*

Main category: cs.CV

TL;DR: 该论文提出了一种将对象中心蓝图集成到视觉语言模型中的方法，通过构建结构化JSON蓝图来增强空间推理能力，结合监督微调、强化学习和数据增强技术，显著提升了空间语义理解性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么关注局部图像块（削弱全局空间感知），要么标记孤立坐标（忽略对象整体组织），无法有效平衡细粒度感知和全局空间意识。

Method: 1) 构建JSON样式蓝图记录对象位置、尺寸和属性；2) 蓝图嵌入推理轨迹进行监督微调；3) 蓝图感知奖励的强化学习；4) 抗捷径数据增强技术防止模型依赖表面线索。

Result: 实验表明该方法在空间推理任务上一致优于现有视觉语言模型和专用空间推理模型。

Conclusion: 通过对象中心蓝图的结构化表示和因果推理机制，成功将视觉语言模型从视觉感知推进到空间语义理解的新水平。

Abstract: Spatial reasoning -- the ability to perceive and reason about relationships in space -- advances vision-language models (VLMs) from visual perception toward spatial semantic understanding. Existing approaches either revisit local image patches, improving fine-grained perception but weakening global spatial awareness, or mark isolated coordinates, which capture object locations but overlook their overall organization. In this work, we integrate the cognitive concept of an object-centric blueprint into VLMs to enhance spatial reasoning. Given an image and a question, the model first constructs a JSON-style blueprint that records the positions, sizes, and attributes of relevant objects, and then reasons over this structured representation to produce the final answer. To achieve this, we introduce three key techniques: (1) blueprint-embedded reasoning traces for supervised fine-tuning to elicit basic reasoning skills; (2) blueprint-aware rewards in reinforcement learning to encourage the blueprint to include an appropriate number of objects and to align final answers with this causal reasoning; and (3) anti-shortcut data augmentation that applies targeted perturbations to images and questions, discouraging reliance on superficial visual or linguistic cues. Experiments show that our method consistently outperforms existing VLMs and specialized spatial reasoning models.

</details>


### [128] [API: Empowering Generalizable Real-World Image Dehazing via Adaptive Patch Importance Learning](https://arxiv.org/abs/2601.01992)
*Chen Zhu,Huiwen Zhang,Yujie Li,Mu He,Xiaotian Qiao*

Main category: cs.CV

TL;DR: 提出一种自适应块重要性感知（API）框架，用于可泛化的真实世界图像去雾，包含自动雾霾生成模块和密度感知去雾模块，通过多负样本对比损失提升细节恢复效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的方法在复杂真实雾霾场景中性能显著下降，主要由于训练数据有限和雾霾密度分布的内在复杂性。

Method: 框架包含自动雾霾生成模块（提供混合数据增强策略）和密度感知去雾模块（自适应处理不同雾霾密度区域），并引入多负样本对比去雾损失函数。

Result: 在多个真实世界基准测试中达到最先进性能，在定量指标和定性视觉质量方面均表现出色，对不同雾霾分布具有鲁棒泛化能力。

Conclusion: 所提出的API框架能够有效解决真实世界图像去雾的挑战，通过创新的数据增强和自适应处理策略实现了优异的去雾效果和泛化性能。

Abstract: Real-world image dehazing is a fundamental yet challenging task in low-level vision. Existing learning-based methods often suffer from significant performance degradation when applied to complex real-world hazy scenes, primarily due to limited training data and the intrinsic complexity of haze density distributions.To address these challenges, we introduce a novel Adaptive Patch Importance-aware (API) framework for generalizable real-world image dehazing. Specifically, our framework consists of an Automatic Haze Generation (AHG) module and a Density-aware Haze Removal (DHR) module. AHG provides a hybrid data augmentation strategy by generating realistic and diverse hazy images as additional high-quality training data. DHR considers hazy regions with varying haze density distributions for generalizable real-world image dehazing in an adaptive patch importance-aware manner. To alleviate the ambiguity of the dehazed image details, we further introduce a new Multi-Negative Contrastive Dehazing (MNCD) loss, which fully utilizes information from multiple negative samples across both spatial and frequency domains. Extensive experiments demonstrate that our framework achieves state-of-the-art performance across multiple real-world benchmarks, delivering strong results in both quantitative metrics and qualitative visual quality, and exhibiting robust generalization across diverse haze distributions.

</details>


### [129] [Nighttime Hazy Image Enhancement via Progressively and Mutually Reinforcing Night-Haze Priors](https://arxiv.org/abs/2601.01998)
*Chen Zhu,Huiwen Zhang,Mu He,Yujie Li,Xiaotian Qiao*

Main category: cs.CV

TL;DR: 提出一种夜间去雾新框架，通过相互增强雾度和低光照先验知识，在图像、块和像素级别逐步恢复图像可见度。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常单独处理单一类型的退化（如雾度或低光照），忽略了不同退化类型之间的相互作用，导致可见度提升有限。研究发现雾度和低光照先验知识可以相互增强以提升可见度。

Method: 提出一个新颖框架，通过相互渐进地增强雾度和低光照先验知识的内在一致性来提升夜间雾霾图像的可见度。模型利用图像、块和像素级别的专家，在视觉和频率域操作，逐步恢复全局场景结构、区域模式和细粒度细节。引入频率感知路由器自适应指导每个专家的贡献，确保稳健的图像恢复。

Result: 在夜间去雾基准测试中，模型在定量和定性方面均表现出优越性能。

Conclusion: 该模型在夜间去雾任务中表现优异，并展示了在白天去雾和低光照增强任务中的泛化能力。

Abstract: Enhancing the visibility of nighttime hazy images is challenging due to the complex degradation distributions. Existing methods mainly address a single type of degradation (e.g., haze or low-light) at a time, ignoring the interplay of different degradation types and resulting in limited visibility improvement. We observe that the domain knowledge shared between low-light and haze priors can be reinforced mutually for better visibility. Based on this key insight, in this paper, we propose a novel framework that enhances visibility in nighttime hazy images by reinforcing the intrinsic consistency between haze and low-light priors mutually and progressively. In particular, our model utilizes image-, patch-, and pixel-level experts that operate across visual and frequency domains to recover global scene structure, regional patterns, and fine-grained details progressively. A frequency-aware router is further introduced to adaptively guide the contribution of each expert, ensuring robust image restoration. Extensive experiments demonstrate the superior performance of our model on nighttime dehazing benchmarks both quantitatively and qualitatively. Moreover, we showcase the generalizability of our model in daytime dehazing and low-light enhancement tasks.

</details>


### [130] [Enhancing Object Detection with Privileged Information: A Model-Agnostic Teacher-Student Approach](https://arxiv.org/abs/2601.02016)
*Matthias Bartolo,Dylan Seychell,Gabriel Hili,Matthew Montebello,Carl James Debono,Saviour Formosa,Konstantinos Makantasis*

Main category: cs.CV

TL;DR: 本文提出了一种基于LUPI范式的通用目标检测方法，通过教师-学生架构在训练时利用特权信息（如边界框掩码、显著图等）提升检测性能，且不增加推理复杂度。


<details>
  <summary>Details</summary>
Motivation: 利用训练时可用但推理时不可用的细粒度描述性信息（特权信息）来提升目标检测性能，特别是在资源受限和真实场景中。

Method: 采用模型无关的教师-学生架构，将特权信息（边界框掩码、显著图、深度线索等）注入到深度学习目标检测器中，通过中间权重平衡特权信息和标准输入的学习。

Result: 在五个先进目标检测模型和多个公开基准测试中，LUPI训练的学生模型始终优于基线模型，检测准确率显著提升，尤其对中大型物体效果明显，且不增加推理复杂度和模型大小。

Conclusion: LUPI框架为在资源受限和真实场景中推进目标检测系统提供了有效实用的策略。

Abstract: This paper investigates the integration of the Learning Using Privileged Information (LUPI) paradigm in object detection to exploit fine-grained, descriptive information available during training but not at inference. We introduce a general, model-agnostic methodology for injecting privileged information-such as bounding box masks, saliency maps, and depth cues-into deep learning-based object detectors through a teacher-student architecture. Experiments are conducted across five state-of-the-art object detection models and multiple public benchmarks, including UAV-based litter detection datasets and Pascal VOC 2012, to assess the impact on accuracy, generalization, and computational efficiency. Our results demonstrate that LUPI-trained students consistently outperform their baseline counterparts, achieving significant boosts in detection accuracy with no increase in inference complexity or model size. Performance improvements are especially marked for medium and large objects, while ablation studies reveal that intermediate weighting of teacher guidance optimally balances learning from privileged and standard inputs. The findings affirm that the LUPI framework provides an effective and practical strategy for advancing object detection systems in both resource-constrained and real-world settings.

</details>


### [131] [Towards Any-Quality Image Segmentation via Generative and Adaptive Latent Space Enhancement](https://arxiv.org/abs/2601.02018)
*Guangqian Guo,Aixi Ren,Yong Guo,Xuehui Yu,Jiacheng Tian,Wenli Li,Yaoxing Wang,Shan Gao*

Main category: cs.CV

TL;DR: GleSAM++通过生成式潜在空间增强技术，结合退化感知自适应增强机制，显著提升了Segment Anything模型在低质量图像上的分割鲁棒性。


<details>
  <summary>Details</summary>
Motivation: SAM模型在严重退化的低质量图像上性能显著下降，限制了其在真实场景中的应用。需要解决模型对不同质量图像的泛化能力问题。

Method: 提出GleSAM++框架，包含特征分布对齐(FDA)、通道复制扩展(CRE)和退化感知自适应增强(DAE)机制。DAE将重建过程解耦为退化级别预测和退化感知重建两个阶段。

Result: 实验表明GleSAM++在复杂退化条件下显著提升分割鲁棒性，同时保持对清晰图像的泛化能力，且在未见过的退化类型上表现良好。

Conclusion: GleSAM++能够以最小额外参数有效提升SAM和SAM2在低质量图像上的分割性能，具有很好的实用性和泛化能力。

Abstract: Segment Anything Models (SAMs), known for their exceptional zero-shot segmentation performance, have garnered significant attention in the research community. Nevertheless, their performance drops significantly on severely degraded, low-quality images, limiting their effectiveness in real-world scenarios. To address this, we propose GleSAM++, which utilizes Generative Latent space Enhancement to boost robustness on low-quality images, thus enabling generalization across various image qualities. Additionally, to improve compatibility between the pre-trained diffusion model and the segmentation framework, we introduce two techniques, i.e., Feature Distribution Alignment (FDA) and Channel Replication and Expansion (CRE). However, the above components lack explicit guidance regarding the degree of degradation. The model is forced to implicitly fit a complex noise distribution that spans conditions from mild noise to severe artifacts, which substantially increases the learning burden and leads to suboptimal reconstructions. To address this issue, we further introduce a Degradation-aware Adaptive Enhancement (DAE) mechanism. The key principle of DAE is to decouple the reconstruction process for arbitrary-quality features into two stages: degradation-level prediction and degradation-aware reconstruction. Our method can be applied to pre-trained SAM and SAM2 with only minimal additional learnable parameters, allowing for efficient optimization. Extensive experiments demonstrate that GleSAM++ significantly improves segmentation robustness on complex degradations while maintaining generalization to clear images. Furthermore, GleSAM++ also performs well on unseen degradations, underscoring the versatility of our approach and dataset.

</details>


### [132] [Adapting Depth Anything to Adverse Imaging Conditions with Events](https://arxiv.org/abs/2601.02020)
*Shihan Peng,Yuyang Xiong,Hanyu Zhou,Zhiwei Shi,Haoyue Liu,Gang Chen,Luxin Yan,Yi Chang*

Main category: cs.CV

TL;DR: ADAE是一个事件引导的时空融合框架，用于增强Depth Anything在退化场景下的深度估计能力，通过熵感知空间融合和运动引导时间校正来应对极端光照和运动模糊问题。


<details>
  <summary>Details</summary>
Motivation: 当前深度基础模型在理想场景下表现优异，但在极端光照和运动模糊等恶劣成像条件下性能下降。事件相机具有高动态范围和时间分辨率优势，但现有融合模型无法继承基础模型的开放世界知识和泛化能力。

Method: 提出ADAE框架，包含两个核心组件：1）熵感知空间融合 - 基于信息熵策略自适应融合帧基和事件基特征；2）运动引导时间校正 - 利用事件运动线索重新校准模糊区域的特征。

Result: 大量实验验证了所提方法的优越性，在退化场景下显著提升了Depth Anything的深度估计性能。

Conclusion: ADAE框架有效增强了深度基础模型在恶劣成像条件下的鲁棒性，两个组件相互补充，为机器人系统在动态和不利光照条件下提供了可靠的深度估计解决方案。

Abstract: Robust depth estimation under dynamic and adverse lighting conditions is essential for robotic systems. Currently, depth foundation models, such as Depth Anything, achieve great success in ideal scenes but remain challenging under adverse imaging conditions such as extreme illumination and motion blur. These degradations corrupt the visual signals of frame cameras, weakening the discriminative features of frame-based depths across the spatial and temporal dimensions. Typically, existing approaches incorporate event cameras to leverage their high dynamic range and temporal resolution, aiming to compensate for corrupted frame features. However, such specialized fusion models are predominantly trained from scratch on domain-specific datasets, thereby failing to inherit the open-world knowledge and robust generalization inherent to foundation models. In this work, we propose ADAE, an event-guided spatiotemporal fusion framework for Depth Anything in degraded scenes. Our design is guided by two key insights: 1) Entropy-Aware Spatial Fusion. We adaptively merge frame-based and event-based features using an information entropy strategy to indicate illumination-induced degradation. 2) Motion-Guided Temporal Correction. We resort to the event-based motion cue to recalibrate ambiguous features in blurred regions. Under our unified framework, the two components are complementary to each other and jointly enhance Depth Anything under adverse imaging conditions. Extensive experiments have been performed to verify the superiority of the proposed method. Our code will be released upon acceptance.

</details>


### [133] [Leveraging 2D-VLM for Label-Free 3D Segmentation in Large-Scale Outdoor Scene Understanding](https://arxiv.org/abs/2601.02029)
*Toshihiko Nishimura,Hirofumi Abe,Kazuhiko Murasaki,Taiga Yoshida,Ryuichi Tanida*

Main category: cs.CV

TL;DR: 提出一种无需3D标注数据或配对RGB图像的大规模点云3D语义分割方法，通过虚拟相机将点云投影到2D图像，利用基础2D模型和自然语言提示进行语义分割，并通过多视角加权投票实现3D分割。


<details>
  <summary>Details</summary>
Motivation: 传统3D语义分割方法需要大量标注的3D训练数据，成本高昂且难以扩展。本文旨在开发一种无需3D标注的训练自由方法，支持开放词汇识别，突破传统监督方法的限制。

Method: 1) 使用虚拟相机将3D点云投影到多个2D视角；2) 利用基础2D模型和自然语言提示进行2D语义分割；3) 通过多视角预测的加权投票聚合实现3D分割。

Result: 该方法优于现有的训练自由方法，分割精度达到与监督方法相当的水平，同时支持开放词汇识别，用户可以使用任意文本查询检测对象。

Conclusion: 该方法为3D语义分割提供了一种有效的训练自由解决方案，突破了传统方法对标注数据的依赖，具有更好的实用性和扩展性。

Abstract: This paper presents a novel 3D semantic segmentation method for large-scale point cloud data that does not require annotated 3D training data or paired RGB images. The proposed approach projects 3D point clouds onto 2D images using virtual cameras and performs semantic segmentation via a foundation 2D model guided by natural language prompts. 3D segmentation is achieved by aggregating predictions from multiple viewpoints through weighted voting. Our method outperforms existing training-free approaches and achieves segmentation accuracy comparable to supervised methods. Moreover, it supports open-vocabulary recognition, enabling users to detect objects using arbitrary text queries, thus overcoming the limitations of traditional supervised approaches.

</details>


### [134] [AlignVTOFF: Texture-Spatial Feature Alignment for High-Fidelity Virtual Try-Off](https://arxiv.org/abs/2601.02038)
*Yihan Zhu,Mengying Ge*

Main category: cs.CV

TL;DR: AlignVTOFF是一个用于虚拟试穿（VTOFF）任务的并行U-Net框架，通过参考U-Net和纹理-空间特征对齐（TSFA）技术，解决了现有方法在复杂几何变形和高频纹理保持方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有虚拟试穿方法依赖轻量级模块进行快速特征提取，但难以保持结构化图案和细粒度细节，导致生成过程中纹理衰减问题。

Method: 提出并行U-Net框架，包含参考U-Net进行多尺度特征提取增强几何保真度，以及TSFA模块通过混合注意力设计（可训练交叉注意力+冻结自注意力）将参考特征注入冻结去噪U-Net。

Result: 在多个设置下的广泛实验表明，AlignVTOFF持续优于现有最先进方法，生成具有改进结构真实性和高频细节保真度的平铺服装结果。

Conclusion: AlignVTOFF通过创新的并行架构和特征对齐机制，有效解决了虚拟试穿中的纹理衰减问题，显著提升了生成质量。

Abstract: Virtual Try-Off (VTOFF) is a challenging multimodal image generation task that aims to synthesize high-fidelity flat-lay garments under complex geometric deformation and rich high-frequency textures. Existing methods often rely on lightweight modules for fast feature extraction, which struggles to preserve structured patterns and fine-grained details, leading to texture attenuation during generation.To address these issues, we propose AlignVTOFF, a novel parallel U-Net framework built upon a Reference U-Net and Texture-Spatial Feature Alignment (TSFA). The Reference U-Net performs multi-scale feature extraction and enhances geometric fidelity, enabling robust modeling of deformation while retaining complex structured patterns. TSFA then injects the reference garment features into a frozen denoising U-Net via a hybrid attention design, consisting of a trainable cross-attention module and a frozen self-attention module. This design explicitly aligns texture and spatial cues and alleviates the loss of high-frequency information during the denoising process.Extensive experiments across multiple settings demonstrate that AlignVTOFF consistently outperforms state-of-the-art methods, producing flat-lay garment results with improved structural realism and high-frequency detail fidelity.

</details>


### [135] [Agentic Retoucher for Text-To-Image Generation](https://arxiv.org/abs/2601.02046)
*Shaocheng Shen,Jianfeng Liang. Chunlei Cai,Cong Geng,Huiyu Duan,Xiaoyun Zhang,Qiang Hu,Guangtao Zhai*

Main category: cs.CV

TL;DR: 提出Agentic Retoucher框架，通过感知-推理-行动的三层代理架构解决T2I扩散模型中存在的局部失真问题，无需迭代重生成即可实现精准的局部修复


<details>
  <summary>Details</summary>
Motivation: 现有T2I扩散模型（如SDXL、FLUX）虽然实现了高真实感，但在肢体、面部、文字等细节处普遍存在小尺度失真。现有修复方法要么成本高昂，要么依赖空间定位能力弱的视觉语言模型，导致语义漂移和不可靠的局部编辑

Method: 设计三层代理架构：1）感知代理学习上下文显著性进行细粒度失真定位；2）推理代理通过渐进偏好对齐进行人类对齐的诊断推理；3）行动代理根据用户偏好自适应规划局部修复。同时构建GenBlemish-27K数据集用于监督训练

Result: 实验表明Agentic Retoucher在感知质量、失真定位和人类偏好对齐方面均优于现有方法，建立了自校正和感知可靠的T2I生成新范式

Conclusion: 该框架将感知证据、语言推理和可控校正整合到统一的自我校正决策过程中，为解决T2I生成中的局部失真问题提供了有效方案

Abstract: Text-to-image (T2I) diffusion models such as SDXL and FLUX have achieved impressive photorealism, yet small-scale distortions remain pervasive in limbs, face, text and so on. Existing refinement approaches either perform costly iterative re-generation or rely on vision-language models (VLMs) with weak spatial grounding, leading to semantic drift and unreliable local edits. To close this gap, we propose Agentic Retoucher, a hierarchical decision-driven framework that reformulates post-generation correction as a human-like perception-reasoning-action loop. Specifically, we design (1) a perception agent that learns contextual saliency for fine-grained distortion localization under text-image consistency cues, (2) a reasoning agent that performs human-aligned inferential diagnosis via progressive preference alignment, and (3) an action agent that adaptively plans localized inpainting guided by user preference. This design integrates perceptual evidence, linguistic reasoning, and controllable correction into a unified, self-corrective decision process. To enable fine-grained supervision and quantitative evaluation, we further construct GenBlemish-27K, a dataset of 6K T2I images with 27K annotated artifact regions across 12 categories. Extensive experiments demonstrate that Agentic Retoucher consistently outperforms state-of-the-art methods in perceptual quality, distortion localization and human preference alignment, establishing a new paradigm for self-corrective and perceptually reliable T2I generation.

</details>


### [136] [PhysSFI-Net: Physics-informed Geometric Learning of Skeletal and Facial Interactions for Orthognathic Surgical Outcome Prediction](https://arxiv.org/abs/2601.02088)
*Jiahao Bao,Huazhen Liu,Yu Zhuang,Leran Tao,Xinyu Xu,Yongtao Shi,Mengjia Cheng,Yiming Wang,Congshuang Ku,Ting Zeng,Yilang Du,Siyi Chen,Shunyao Shen,Suncheng Xiang,Hongbo Yu*

Main category: cs.CV

TL;DR: 本研究开发了PhysSFI-Net物理信息几何深度学习框架，用于精确预测正颌手术后的软组织变形，在预测精度上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统生物力学模型计算成本高，而几何深度学习方法缺乏可解释性，需要开发既能准确预测又能保持物理可解释性的方法。

Method: PhysSFI-Net包含三个组件：层次图模块提取骨骼-面部交互特征，LSTM序列预测器进行增量软组织变形预测，生物力学启发模块进行高分辨率面部表面重建。

Result: 在135名患者数据上，PhysSFI-Net的点云形状误差为1.070±0.088mm，表面偏差误差为1.296±0.349mm，标志点定位误差为2.445±1.326mm，优于现有最优方法ACMT-Net。

Conclusion: PhysSFI-Net能够实现可解释的高分辨率术后面部形态预测，在正颌手术规划和模拟中具有重要临床应用潜力。

Abstract: Orthognathic surgery repositions jaw bones to restore occlusion and enhance facial aesthetics. Accurate simulation of postoperative facial morphology is essential for preoperative planning. However, traditional biomechanical models are computationally expensive, while geometric deep learning approaches often lack interpretability. In this study, we develop and validate a physics-informed geometric deep learning framework named PhysSFI-Net for precise prediction of soft tissue deformation following orthognathic surgery. PhysSFI-Net consists of three components: a hierarchical graph module with craniofacial and surgical plan encoders combined with attention mechanisms to extract skeletal-facial interaction features; a Long Short-Term Memory (LSTM)-based sequential predictor for incremental soft tissue deformation; and a biomechanics-inspired module for high-resolution facial surface reconstruction. Model performance was assessed using point cloud shape error (Hausdorff distance), surface deviation error, and landmark localization error (Euclidean distances of craniomaxillofacial landmarks) between predicted facial shapes and corresponding ground truths. A total of 135 patients who underwent combined orthodontic and orthognathic treatment were included for model training and validation. Quantitative analysis demonstrated that PhysSFI-Net achieved a point cloud shape error of 1.070 +/- 0.088 mm, a surface deviation error of 1.296 +/- 0.349 mm, and a landmark localization error of 2.445 +/- 1.326 mm. Comparative experiments indicated that PhysSFI-Net outperformed the state-of-the-art method ACMT-Net in prediction accuracy. In conclusion, PhysSFI-Net enables interpretable, high-resolution prediction of postoperative facial morphology with superior accuracy, showing strong potential for clinical application in orthognathic surgical planning and simulation.

</details>


### [137] [MCD-Net: A Lightweight Deep Learning Baseline for Optical-Only Moraine Segmentation](https://arxiv.org/abs/2601.02091)
*Zhehuan Cao,Fiseha Berhanu Tesema,Ping Fu,Jianfeng Ren,Ahmed Nasr*

Main category: cs.CV

TL;DR: 该研究提出了首个大规模仅基于光学影像的冰碛垄分割数据集，并开发了轻量级MCD-Net模型，在保持较高分割精度的同时显著降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 冰川分割对于重建过去冰川动态和评估气候变化驱动的地貌变化至关重要，但弱光学对比度和高分辨率DEM数据的有限可用性阻碍了自动化制图。

Method: 开发MCD-Net模型，集成MobileNetV2编码器、卷积块注意力模块（CBAM）和DeepLabV3+解码器，使用3,340张手动标注的高分辨率Google Earth图像进行训练。

Result: MCD-Net达到62.3%的平均交并比（mIoU）和72.8%的Dice系数，同时计算成本降低超过60%，相比更深的主干网络（ResNet152、Xception）表现更优。

Conclusion: 尽管山脊描绘仍受亚像素宽度和光谱模糊性的限制，但结果表明仅光学影像就能提供可靠的冰碛体分割，为高海拔冰川监测提供了可部署的基准。

Abstract: Glacial segmentation is essential for reconstructing past glacier dynamics and evaluating climate-driven landscape change. However, weak optical contrast and the limited availability of high-resolution DEMs hinder automated mapping. This study introduces the first large-scale optical-only moraine segmentation dataset, comprising 3,340 manually annotated high-resolution images from Google Earth covering glaciated regions of Sichuan and Yunnan, China. We develop MCD-Net, a lightweight baseline that integrates a MobileNetV2 encoder, a Convolutional Block Attention Module (CBAM), and a DeepLabV3+ decoder. Benchmarking against deeper backbones (ResNet152, Xception) shows that MCD-Net achieves 62.3\% mean Intersection over Union (mIoU) and 72.8\% Dice coefficient while reducing computational cost by more than 60\%. Although ridge delineation remains constrained by sub-pixel width and spectral ambiguity, the results demonstrate that optical imagery alone can provide reliable moraine-body segmentation. The dataset and code are publicly available at https://github.com/Lyra-alpha/MCD-Net, establishing a reproducible benchmark for moraine-specific segmentation and offering a deployable baseline for high-altitude glacial monitoring.

</details>


### [138] [InpaintHuman: Reconstructing Occluded Humans with Multi-Scale UV Mapping and Identity-Preserving Diffusion Inpainting](https://arxiv.org/abs/2601.02098)
*Jinlong Fan,Shanshan Zhao,Liang Zheng,Jing Zhang,Yuxiang Yang,Mingming Gong*

Main category: cs.CV

TL;DR: InpaintHuman是一种从单目视频中重建完整可动画3D人体化身的新方法，特别针对严重遮挡情况，通过多尺度UV参数化表示和身份保持扩散修复模块解决现有方法在遮挡区域重建不完整的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于3D高斯泼溅的方法在遮挡情况下难以重建完整的人体化身，常产生几何损坏和时间不一致性。需要一种能够从遮挡单目视频生成高保真、完整且可动画化身的方法。

Method: 提出两个关键创新：(1)多尺度UV参数化表示，采用分层粗到细特征插值，实现遮挡区域鲁棒重建同时保留几何细节；(2)身份保持扩散修复模块，结合文本反演和语义条件指导，实现主体特定、时间一致的补全。与SDS方法不同，采用直接像素级监督确保身份保真度。

Result: 在合成基准数据集(PeopleSnapshot, ZJU-MoCap)和真实场景(OcMotion)上的实验显示，该方法在不同姿态和视角下均实现了重建质量的一致提升，具有竞争优势。

Conclusion: InpaintHuman能够有效解决遮挡单目视频中3D人体化身重建的挑战，生成高质量、完整且可动画的化身，在遮挡情况下表现出优越性能。

Abstract: Reconstructing complete and animatable 3D human avatars from monocular videos remains challenging, particularly under severe occlusions. While 3D Gaussian Splatting has enabled photorealistic human rendering, existing methods struggle with incomplete observations, often producing corrupted geometry and temporal inconsistencies. We present InpaintHuman, a novel method for generating high-fidelity, complete, and animatable avatars from occluded monocular videos. Our approach introduces two key innovations: (i) a multi-scale UV-parameterized representation with hierarchical coarse-to-fine feature interpolation, enabling robust reconstruction of occluded regions while preserving geometric details; and (ii) an identity-preserving diffusion inpainting module that integrates textual inversion with semantic-conditioned guidance for subject-specific, temporally coherent completion. Unlike SDS-based methods, our approach employs direct pixel-level supervision to ensure identity fidelity. Experiments on synthetic benchmarks (PeopleSnapshot, ZJU-MoCap) and real-world scenarios (OcMotion) demonstrate competitive performance with consistent improvements in reconstruction quality across diverse poses and viewpoints.

</details>


### [139] [360-GeoGS: Geometrically Consistent Feed-Forward 3D Gaussian Splatting Reconstruction for 360 Images](https://arxiv.org/abs/2601.02102)
*Jiaqi Yao,Zhongmiao Yan,Jingyi Xu,Songpengcheng Xia,Yan Xiang,Ling Pei*

Main category: cs.CV

TL;DR: 提出了一种基于3D高斯泼溅的360度图像前馈重建框架，通过深度-法向几何正则化提升几何一致性，在保持高质量渲染的同时显著改善表面重建精度


<details>
  <summary>Details</summary>
Motivation: 传统多视角立体方法在稀疏视角或低纹理区域效果不佳，神经渲染方法需要逐场景优化且缺乏实时性，现有3DGS方法侧重于视觉质量而非几何一致性

Method: 引入深度-法向几何正则化，将渲染深度梯度与法向信息耦合，监督高斯基元的旋转、尺度和位置参数，生成几何一致的高斯基元

Result: 实验结果表明，该方法在保持高质量渲染的同时显著提高了几何一致性，为空间感知任务提供了有效的3D重建解决方案

Conclusion: 该方法成功解决了3D高斯泼溅在几何一致性方面的不足，为空间智能应用提供了兼顾渲染质量和几何精度的实用解决方案

Abstract: 3D scene reconstruction is fundamental for spatial intelligence applications such as AR, robotics, and digital twins. Traditional multi-view stereo struggles with sparse viewpoints or low-texture regions, while neural rendering approaches, though capable of producing high-quality results, require per-scene optimization and lack real-time efficiency. Explicit 3D Gaussian Splatting (3DGS) enables efficient rendering, but most feed-forward variants focus on visual quality rather than geometric consistency, limiting accurate surface reconstruction and overall reliability in spatial perception tasks. This paper presents a novel feed-forward 3DGS framework for 360 images, capable of generating geometrically consistent Gaussian primitives while maintaining high rendering quality. A Depth-Normal geometric regularization is introduced to couple rendered depth gradients with normal information, supervising Gaussian rotation, scale, and position to improve point cloud and surface accuracy. Experimental results show that the proposed method maintains high rendering quality while significantly improving geometric consistency, providing an effective solution for 3D reconstruction in spatial perception tasks.

</details>


### [140] [HeadLighter: Disentangling Illumination in Generative 3D Gaussian Heads via Lightstage Captures](https://arxiv.org/abs/2601.02103)
*Yating Wang,Yuan Sun,Xuan Wang,Ran Yi,Boyao Zhou,Yipengjing Sun,Hongyu Liu,Yinuo Wang,Lizhuang Ma*

Main category: cs.CV

TL;DR: HeadLighter是一个基于3D高斯飞溅的头部生成模型，通过双分支架构实现光照与内在外观的物理可解释解耦，支持实时渲染和显式光照编辑。


<details>
  <summary>Details</summary>
Motivation: 现有3D头部生成模型存在光照与内在外观的深度纠缠问题，限制了可控重光照能力。现有解耦方法依赖强假设，难以处理复杂光照场景。

Method: 设计双分支架构分别建模光照不变头部属性和物理渲染组件；采用渐进式解耦训练策略，在受控光照条件下使用多视角图像进行监督；引入蒸馏策略生成高质量法线用于真实渲染。

Result: 实验证明该方法在保持高质量生成和实时渲染的同时，支持显式光照和视角编辑。

Conclusion: HeadLighter成功实现了头部生成模型中外观与光照的物理可解释解耦，为可控重光照提供了有效解决方案，并将公开代码和数据集。

Abstract: Recent 3D-aware head generative models based on 3D Gaussian Splatting achieve real-time, photorealistic and view-consistent head synthesis. However, a fundamental limitation persists: the deep entanglement of illumination and intrinsic appearance prevents controllable relighting. Existing disentanglement methods rely on strong assumptions to enable weakly supervised learning, which restricts their capacity for complex illumination. To address this challenge, we introduce HeadLighter, a novel supervised framework that learns a physically plausible decomposition of appearance and illumination in head generative models. Specifically, we design a dual-branch architecture that separately models lighting-invariant head attributes and physically grounded rendering components. A progressive disentanglement training is employed to gradually inject head appearance priors into the generative architecture, supervised by multi-view images captured under controlled light conditions with a light stage setup. We further introduce a distillation strategy to generate high-quality normals for realistic rendering. Experiments demonstrate that our method preserves high-quality generation and real-time rendering, while simultaneously supporting explicit lighting and viewpoint editing. We will publicly release our code and dataset.

</details>


### [141] [MagicFight: Personalized Martial Arts Combat Video Generation](https://arxiv.org/abs/2601.02107)
*Jiancheng Huang,Mingfu Yan,Songyan Chen,Yi Huang,Shifeng Chen*

Main category: cs.CV

TL;DR: 该论文提出了个性化双人格斗视频生成的新任务MagicFight，解决了现有单人生成模型在双人交互场景中的身份混淆、肢体异常和动作不匹配等问题，并通过Unity游戏引擎创建专用数据集来支持该任务。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到视频生成技术主要集中于单人生成场景，而双人交互（特别是武术格斗）领域仍未被探索。现有单人生成模型无法捕捉双人格斗的复杂性和微妙性，导致身份混淆、肢体异常和动作不匹配等问题。

Method: 提出MagicFight方法，使用Unity游戏物理引擎生成定制数据集，包含多样化的3D角色、武术动作和场景。该方法改进和适配现有模型和策略，生成高保真度的双人格斗视频，保持个体身份并确保连贯的动作序列。

Result: MagicFight能够生成高质量的双人格斗视频，有效解决了身份混淆和动作不匹配等问题，为交互式视频内容创作奠定了基础。

Conclusion: 该研究开创了个性化武术格斗视频生成的新领域，通过专用数据集和优化模型，为未来交互式视频内容创新提供了重要基础。

Abstract: Amid the surge in generic text-to-video generation, the field of personalized human video generation has witnessed notable advancements, primarily concentrated on single-person scenarios. However, to our knowledge, the domain of two-person interactions, particularly in the context of martial arts combat, remains uncharted. We identify a significant gap: existing models for single-person dancing generation prove insufficient for capturing the subtleties and complexities of two engaged fighters, resulting in challenges such as identity confusion, anomalous limbs, and action mismatches. To address this, we introduce a pioneering new task, Personalized Martial Arts Combat Video Generation. Our approach, MagicFight, is specifically crafted to overcome these hurdles. Given this pioneering task, we face a lack of appropriate datasets. Thus, we generate a bespoke dataset using the game physics engine Unity, meticulously crafting a multitude of 3D characters, martial arts moves, and scenes designed to represent the diversity of combat. MagicFight refines and adapts existing models and strategies to generate high-fidelity two-person combat videos that maintain individual identities and ensure seamless, coherent action sequences, thereby laying the groundwork for future innovations in the realm of interactive video content creation.
  Website: https://MingfuYAN.github.io/MagicFight/
  Dataset: https://huggingface.co/datasets/MingfuYAN/KungFu-Fiesta

</details>


### [142] [Towards Long-window Anchoring in Vision-Language Model Distillation](https://arxiv.org/abs/2512.21576)
*Haoyi Zhou,Shuo Li,Tianyu Chen,Qi Song,Chonghan Gao,Jianxin Li*

Main category: cs.CV

TL;DR: LAid方法通过知识蒸馏提升小模型的长上下文理解能力，使用渐进距离加权注意力匹配和可学习RoPE响应增益调制，使小模型的有效上下文窗口扩大3.2倍


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型的小分支由于窗口大小限制，在语言-图像对齐方面表现不佳，需要提升小模型的长上下文理解能力

Method: 提出LAid方法，包含两个互补组件：1）渐进距离加权注意力匹配，动态强调训练中更长的位置差异；2）可学习RoPE响应增益调制，选择性增强位置敏感性

Result: 实验表明LAid蒸馏的模型比基线小模型有效上下文窗口扩大3.2倍，在标准VL基准上保持或提升性能，频谱分析显示成功保留了关键的低频注意力组件

Conclusion: LAid不仅为构建更高效的长上下文VLMs提供了实用技术，还揭示了位置理解在蒸馏过程中如何出现和转移的理论见解

Abstract: While large vision-language models (VLMs) demonstrate strong long-context understanding, their prevalent small branches fail on linguistics-photography alignment for a limited window size. We discover that knowledge distillation improves students' capability as a complement to Rotary Position Embeddings (RoPE) on window sizes (anchored from large models). Building on this insight, we propose LAid, which directly aims at the transfer of long-range attention mechanisms through two complementary components: (1) a progressive distance-weighted attention matching that dynamically emphasizes longer position differences during training, and (2) a learnable RoPE response gain modulation that selectively amplifies position sensitivity where needed. Extensive experiments across multiple model families demonstrate that LAid-distilled models achieve up to 3.2 times longer effective context windows compared to baseline small models, while maintaining or improving performance on standard VL benchmarks. Spectral analysis also suggests that LAid successfully preserves crucial low-frequency attention components that conventional methods fail to transfer. Our work not only provides practical techniques for building more efficient long-context VLMs but also offers theoretical insights into how positional understanding emerges and transfers during distillation.

</details>


### [143] [Car Drag Coefficient Prediction from 3D Point Clouds Using a Slice-Based Surrogate Model](https://arxiv.org/abs/2601.02112)
*Utkarsh Singh,Absaar Ali,Adarsh Roy*

Main category: cs.CV

TL;DR: 本文提出了一种基于切片处理的轻量级代理模型，用于快速预测车辆空气动力学阻力系数，通过将3D点云分解为序列化2D切片并结合PointNet2D和双向LSTM实现高效准确的Cd值预测。


<details>
  <summary>Details</summary>
Motivation: 传统CFD和风洞测试资源消耗大，阻碍早期设计快速迭代；现有机器学习方法存在计算复杂度高、可解释性差或对复杂几何输入精度不足的问题。

Method: 将车辆3D点云沿流向轴分解为有序2D截面切片序列，每个切片通过轻量级PointNet2D编码，切片嵌入序列由双向LSTM处理以捕捉几何演化特征。

Result: 在DrivAerNet++数据集上达到R²>0.9528的高决定系数和MAE≈0.006046的低误差，在消费级GPU上推理时间仅0.025秒/样本。

Conclusion: 该方法提供了快速、准确且可解释的空气动力学反馈，有助于实现更敏捷的汽车设计探索。

Abstract: The automotive industry's pursuit of enhanced fuel economy and performance necessitates efficient aerodynamic design. However, traditional evaluation methods such as computational fluid dynamics (CFD) and wind tunnel testing are resource intensive, hindering rapid iteration in the early design stages. Machine learning-based surrogate models offer a promising alternative, yet many existing approaches suffer from high computational complexity, limited interpretability, or insufficient accuracy for detailed geometric inputs. This paper introduces a novel lightweight surrogate model for the prediction of the aerodynamic drag coefficient (Cd) based on a sequential slice-wise processing of the geometry of the 3D vehicle. Inspired by medical imaging, 3D point clouds of vehicles are decomposed into an ordered sequence of 2D cross-sectional slices along the stream-wise axis. Each slice is encoded by a lightweight PointNet2D module, and the sequence of slice embeddings is processed by a bidirectional LSTM to capture longitudinal geometric evolution. The model, trained and evaluated on the DrivAerNet++ dataset, achieves a high coefficient of determination (R^2 > 0.9528) and a low mean absolute error (MAE approx 6.046 x 10^{-3}) in Cd prediction. With an inference time of approximately 0.025 seconds per sample on a consumer-grade GPU, our approach provides fast, accurate, and interpretable aerodynamic feedback, facilitating more agile and informed automotive design exploration.

</details>


### [144] [Remote Sensing Change Detection via Weak Temporal Supervision](https://arxiv.org/abs/2601.02126)
*Xavier Bou,Elliot Vincent,Gabriele Facciolo,Rafael Grompone von Gioi,Jean-Michel Morel,Thibaud Ehret*

Main category: cs.CV

TL;DR: 提出一种弱时间监督策略，利用现有单时相遥感数据集的额外时间观测来训练变化检测模型，无需新标注。通过假设真实双时相对大多无变化，而不同位置图像配对生成变化示例，并采用对象感知变化图生成和迭代优化处理弱标签噪声。


<details>
  <summary>Details</summary>
Motivation: 解决遥感语义变化检测中标注数据稀缺问题，现有方法依赖合成数据或人工生成变化对，但域外泛化能力有限。

Method: 扩展单时相遥感数据集为多时相观测，基于真实双时相对大多无变化的假设训练模型，使用不同位置图像配对生成变化示例，采用对象感知变化图生成和迭代优化处理弱标签噪声。

Result: 在扩展的FLAIR和IAILD航空数据集上验证，在零样本和低数据场景下在不同基准测试中表现优异，并在法国大区域展示方法的可扩展性。

Conclusion: 弱时间监督策略有效利用现有单时相数据集，无需额外标注即可训练鲁棒的变化检测模型，具有良好泛化能力和可扩展性。

Abstract: Semantic change detection in remote sensing aims to identify land cover changes between bi-temporal image pairs. Progress in this area has been limited by the scarcity of annotated datasets, as pixel-level annotation is costly and time-consuming. To address this, recent methods leverage synthetic data or generate artificial change pairs, but out-of-domain generalization remains limited. In this work, we introduce a weak temporal supervision strategy that leverages additional temporal observations of existing single-temporal datasets, without requiring any new annotations. Specifically, we extend single-date remote sensing datasets with new observations acquired at different times and train a change detection model by assuming that real bi-temporal pairs mostly contain no change, while pairing images from different locations to generate change examples. To handle the inherent noise in these weak labels, we employ an object-aware change map generation and an iterative refinement process. We validate our approach on extended versions of the FLAIR and IAILD aerial datasets, achieving strong zero-shot and low-data regime performance across different benchmarks. Lastly, we showcase results over large areas in France, highlighting the scalability potential of our method.

</details>


### [145] [Beyond Segmentation: An Oil Spill Change Detection Framework Using Synthetic SAR Imagery](https://arxiv.org/abs/2601.02139)
*Chenyang Lai,Shuaiyu Chen,Tianjin Huang,Siyang Song,Guangliang Cheng,Chunbo Luo,Zeyu Fu*

Main category: cs.CV

TL;DR: 本文提出了一种新的双时序油污检测方法OSCD，通过对比溢油前后的SAR图像变化来识别油污，解决了传统单图像分割方法难以区分油污与类似海洋特征的问题。


<details>
  <summary>Details</summary>
Motivation: 传统基于单张SAR图像的深度学习分割方法在区分真实油污与生物油膜、低风区等类似特征时存在高误报率和泛化能力差的问题，特别是在数据稀缺条件下。

Method: 提出了Temporal-Aware Hybrid Inpainting (TAHI)框架，包含高保真混合修复和时序真实性增强两个关键组件，能够从溢油后SAR数据生成合成的溢油前图像，构建首个OSCD数据集。

Result: 实验结果表明，OSCD方法相比传统分割方法显著降低了误报率并提高了检测准确率。

Conclusion: 时序感知方法为真实场景中可靠、可扩展的油污监测提供了重要价值，OSCD任务展示了在油污检测中的有效性。

Abstract: Marine oil spills are urgent environmental hazards that demand rapid and reliable detection to minimise ecological and economic damage. While Synthetic Aperture Radar (SAR) imagery has become a key tool for large-scale oil spill monitoring, most existing detection methods rely on deep learning-based segmentation applied to single SAR images. These static approaches struggle to distinguish true oil spills from visually similar oceanic features (e.g., biogenic slicks or low-wind zones), leading to high false positive rates and limited generalizability, especially under data-scarce conditions. To overcome these limitations, we introduce Oil Spill Change Detection (OSCD), a new bi-temporal task that focuses on identifying changes between pre- and post-spill SAR images. As real co-registered pre-spill imagery is not always available, we propose the Temporal-Aware Hybrid Inpainting (TAHI) framework, which generates synthetic pre-spill images from post-spill SAR data. TAHI integrates two key components: High-Fidelity Hybrid Inpainting for oil-free reconstruction, and Temporal Realism Enhancement for radiometric and sea-state consistency. Using TAHI, we construct the first OSCD dataset and benchmark several state-of-the-art change detection models. Results show that OSCD significantly reduces false positives and improves detection accuracy compared to conventional segmentation, demonstrating the value of temporally-aware methods for reliable, scalable oil spill monitoring in real-world scenarios.

</details>


### [146] [Efficient Unrolled Networks for Large-Scale 3D Inverse Problems](https://arxiv.org/abs/2601.02141)
*Romain Vo,Julián Tachella*

Main category: cs.CV

TL;DR: 提出了一种域分区策略和正规算子近似方法，使训练端到端重建模型能够处理任意大规模问题的前向算子，在3D X射线锥束CT和3D多线圈加速MRI上达到最先进性能，仅需单个GPU即可完成训练和推理。


<details>
  <summary>Details</summary>
Motivation: 深度学习在成像逆问题中表现出色，但现有方法在处理大规模3D成像问题时，由于全局前向算子需要大量内存，无法将成像算子纳入网络架构，限制了性能提升。

Method: 采用域分区策略和正规算子近似技术，将大规模问题的前向算子分解为可管理的部分，使端到端重建模型能够有效整合成像算子。

Result: 在3D X射线锥束CT和3D多线圈加速MRI上实现了最先进的性能表现，同时显著降低了计算资源需求。

Conclusion: 该方法成功解决了大规模成像问题中内存限制的挑战，为深度学习在3D成像领域的应用提供了可行的解决方案。

Abstract: Deep learning-based methods have revolutionized the field of imaging inverse problems, yielding state-of-the-art performance across various imaging domains. The best performing networks incorporate the imaging operator within the network architecture, typically in the form of deep unrolling. However, in large-scale problems, such as 3D imaging, most existing methods fail to incorporate the operator in the architecture due to the prohibitive amount of memory required by global forward operators, which hinder typical patching strategies. In this work, we present a domain partitioning strategy and normal operator approximations that enable the training of end-to-end reconstruction models incorporating forward operators of arbitrarily large problems into their architecture. The proposed method achieves state-of-the-art performance on 3D X-ray cone-beam tomography and 3D multi-coil accelerated MRI, while requiring only a single GPU for both training and inference.

</details>


### [147] [BiPrompt: Bilateral Prompt Optimization for Visual and Textual Debiasing in Vision-Language Models](https://arxiv.org/abs/2601.02147)
*Sunny Gupta,Shounak Das,Amit Sethi*

Main category: cs.CV

TL;DR: 本文提出了一种双边提示优化框架（BiPrompt），通过同时减少视觉和文本模态中的虚假相关性，提升CLIP等视觉语言基础模型在分布变化下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的去偏方法通常只处理单一模态（视觉或文本），导致部分鲁棒性和在分布变化下不稳定的适应。需要同时解决两个模态中的虚假相关性。

Method: BiPrompt框架包含两个核心模块：视觉侧采用结构化注意力引导擦除来抑制背景激活并强制因果区域与虚假区域的正交预测一致性；文本侧引入平衡提示归一化，通过学习性重新中心化机制将类别嵌入对齐到各向同性语义空间。

Result: 在真实世界和合成偏置基准上的广泛评估显示，该方法在平均准确率和最差组准确率上都优于现有测试时去偏方法。

Conclusion: BiPrompt为可信赖和因果基础的视觉语言适应提供了一种轻量级且有效的路径，无需重新训练或领域监督。

Abstract: Vision language foundation models such as CLIP exhibit impressive zero-shot generalization yet remain vulnerable to spurious correlations across visual and textual modalities. Existing debiasing approaches often address a single modality either visual or textual leading to partial robustness and unstable adaptation under distribution shifts. We propose a bilateral prompt optimization framework (BiPrompt) that simultaneously mitigates non-causal feature reliance in both modalities during test-time adaptation. On the visual side, it employs structured attention-guided erasure to suppress background activations and enforce orthogonal prediction consistency between causal and spurious regions. On the textual side, it introduces balanced prompt normalization, a learnable re-centering mechanism that aligns class embeddings toward an isotropic semantic space. Together, these modules jointly minimize conditional mutual information between spurious cues and predictions, steering the model toward causal, domain invariant reasoning without retraining or domain supervision. Extensive evaluations on real-world and synthetic bias benchmarks demonstrate consistent improvements in both average and worst-group accuracies over prior test-time debiasing methods, establishing a lightweight yet effective path toward trustworthy and causally grounded vision-language adaptation.

</details>


### [148] [Why Commodity WiFi Sensors Fail at Multi-Person Gait Identification: A Systematic Analysis Using ESP32](https://arxiv.org/abs/2601.02177)
*Oliver Custance,Saad Khan,Simon Parkinson*

Main category: cs.CV

TL;DR: 本研究评估了使用商用ESP32 WiFi传感器进行多人员步态识别的可行性，发现即使采用多种信号分离方法，识别准确率仍然很低（45-56%），表明硬件信号质量不足是主要限制因素。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在单人员WiFi步态识别并取得高准确率，但多人员识别领域仍待探索。关键问题是多人员识别性能差是算法限制还是硬件固有约束。

Method: 系统评估了六种信号分离方法（FastICA、SOBI、PCA、NMF、小波变换、张量分解）在1-10人场景下的表现，使用商用ESP32 WiFi传感器，并采用新颖的诊断指标（主体内变异性、主体间可区分性、性能退化率）。

Result: 所有方法在多人员识别中准确率都很低（45-56%），统计上无显著差异。即使最佳方法NMF也只有56%准确率。分析显示高主体内变异性、低主体间可区分性，且随着人数增加性能急剧下降。

Conclusion: 商用ESP32传感器无法提供足够信号质量来实现可靠的多人员分离，多人员识别性能差主要是硬件限制而非算法问题。

Abstract: WiFi Channel State Information (CSI) has shown promise for single-person gait identification, with numerous studies reporting high accuracy. However, multi-person identification remains largely unexplored, with the limited existing work relying on complex, expensive setups requiring modified firmware. A critical question remains unanswered: is poor multi-person performance an algorithmic limitation or a fundamental hardware constraint? We systematically evaluate six diverse signal separation methods (FastICA, SOBI, PCA, NMF, Wavelet, Tensor Decomposition) across seven scenarios with 1-10 people using commodity ESP32 WiFi sensors--a simple, low-cost, off-the-shelf solution. Through novel diagnostic metrics (intra-subject variability, inter-subject distinguishability, performance degradation rate), we reveal that all methods achieve similarly low accuracy (45-56\%, $σ$=3.74\%) with statistically insignificant differences (p $>$ 0.05). Even the best-performing method, NMF, achieves only 56\% accuracy. Our analysis reveals high intra-subject variability, low inter-subject distinguishability, and severe performance degradation as person count increases, indicating that commodity ESP32 sensors cannot provide sufficient signal quality for reliable multi-person separation.

</details>


### [149] [QuIC: A Quantum-Inspired Interaction Classifier for Revitalizing Shallow CNNs in Fine-Grained Recognition](https://arxiv.org/abs/2601.02189)
*Cheng Ying Wu,Yen Jui Chang*

Main category: cs.CV

TL;DR: 提出量子启发的交互分类器（QuIC），通过模拟量子态交互来捕获二阶特征协方差，显著提升浅层网络在细粒度视觉分类任务上的性能，同时保持计算效率。


<details>
  <summary>Details</summary>
Motivation: 解决细粒度视觉分类中深层网络计算成本高与浅层网络性能不足的矛盾。传统GAP只能捕获一阶统计特征，而双线性CNN存在特征维度爆炸和训练不稳定问题。

Method: 设计量子启发的交互分类器（QuIC），将特征通道建模为相互作用的量子态，通过可学习的可观测量算子捕获二阶特征协方差。QuIC是轻量级即插即用模块，支持稳定的端到端单阶段训练。

Result: QuIC显著提升浅层骨干网络性能：VGG16的Top-1准确率提升近20%，在ResNet18上优于最先进的注意力机制（SE-Block）。t-SNE可视化证实QuIC能解决模糊案例，关注细粒度判别特征并实现紧凑的类内聚类。

Conclusion: QuIC通过量子力学启发的二阶特征交互建模，有效解决了细粒度视觉分类中效率与精度的平衡问题，为资源受限的边缘设备部署提供了可行方案。

Abstract: Deploying deep learning models for Fine-Grained Visual Classification (FGVC) on resource-constrained edge devices remains a significant challenge. While deep architectures achieve high accuracy on benchmarks like CUB-200-2011, their computational cost is often prohibitive. Conversely, shallow networks (e.g., AlexNet, VGG) offer efficiency but fail to distinguish visually similar sub-categories. This is because standard Global Average Pooling (GAP) heads capture only first-order statistics, missing the subtle high-order feature interactions required for FGVC. While Bilinear CNNs address this, they suffer from high feature dimensionality and instability during training. To bridge this gap, we propose the Quantum-inspired Interaction Classifier (QuIC). Drawing inspiration from quantum mechanics, QuIC models feature channels as interacting quantum states and captures second-order feature covariance via a learnable observable operator. Designed as a lightweight, plug-and-play module, QuIC supports stable, single-stage end-to-end training without exploding feature dimensions. Experimental results demonstrate that QuIC significantly revitalizes shallow backbones: it boosts the Top-1 accuracy of VGG16 by nearly 20% and outperforms state-of-the-art attention mechanisms (SE-Block) on ResNet18. Qualitative analysis, including t-SNE visualization, further confirms that QuIC resolves ambiguous cases by explicitly attending to fine-grained discriminative features and enforcing compact intra-class clustering.

</details>


### [150] [Mind the Gap: Continuous Magnification Sampling for Pathology Foundation Models](https://arxiv.org/abs/2601.02198)
*Alexander Möllers,Julius Hense,Florian Schulz,Timo Milbich,Maximilian Alber,Lukas Ruff*

Main category: cs.CV

TL;DR: 本文提出连续放大倍数采样方法，解决了病理学基础模型在中间放大倍数下的性能下降问题，并开发了优化采样分布策略。


<details>
  <summary>Details</summary>
Motivation: 病理学家在诊断时会同时观察低倍镜下的组织架构和高倍镜下的精细形态，但现有病理学基础模型在不同放大倍数下的性能表现及训练时的放大倍数采样策略影响尚不明确。

Method: 将放大倍数采样建模为多源域适应问题，提出连续放大倍数采样方法替代传统的离散均匀采样，并推导出优化采样分布以提升跨放大倍数的表示质量。

Result: 连续采样在中间放大倍数上比离散采样提升高达4个百分点的平衡分类准确率，优化分布能进一步改善性能。现有病理学基础模型的性能差异主要由放大倍数驱动。

Conclusion: 该研究为开发能在不同放大倍数下可靠工作的未来病理学基础模型奠定了基础。

Abstract: In histopathology, pathologists examine both tissue architecture at low magnification and fine-grained morphology at high magnification. Yet, the performance of pathology foundation models across magnifications and the effect of magnification sampling during training remain poorly understood. We model magnification sampling as a multi-source domain adaptation problem and develop a simple theoretical framework that reveals systematic trade-offs between sampling strategies. We show that the widely used discrete uniform sampling of magnifications (0.25, 0.5, 1.0, 2.0 mpp) leads to degradation at intermediate magnifications. We introduce continuous magnification sampling, which removes gaps in magnification coverage while preserving performance at standard scales. Further, we derive sampling distributions that optimize representation quality across magnification scales. To evaluate these strategies, we introduce two new benchmarks (TCGA-MS, BRACS-MS) with appropriate metrics. Our experiments show that continuous sampling substantially improves over discrete sampling at intermediate magnifications, with gains of up to 4 percentage points in balanced classification accuracy, and that optimized distributions can further improve performance. Finally, we evaluate current histopathology foundation models, finding that magnification is a primary driver of performance variation across models. Our work paves the way towards future pathology foundation models that perform reliably across magnifications.

</details>


### [151] [Parameter-Efficient Domain Adaption for CSI Crowd-Counting via Self-Supervised Learning with Adapter Modules](https://arxiv.org/abs/2601.02203)
*Oliver Custance,Saad Khan,Simon Parkinson,Quan Z. Sheng*

Main category: cs.CV

TL;DR: 提出了一种基于CSI-ResNet-A的两阶段框架，通过自监督对比学习和轻量级适配器模块解决WiFi人群计数中的域偏移问题，在10-shot学习场景下达到MAE 0.44，并在公开基准上创下98.8%准确率的新记录。


<details>
  <summary>Details</summary>
Motivation: 解决WiFi人群计数技术在实际部署中面临的域偏移问题，即在一个环境中训练的模型无法泛化到其他环境，阻碍了隐私保护IoT应用的实用部署。

Method: 提出两阶段框架：1）使用CSI-ResNet-A架构进行自监督对比学习预训练，学习域不变表示；2）利用轻量级适配器模块进行高效微调，最后通过状态计数机处理事件序列生成稳定的占用估计。

Result: 在WiFlow数据集上，无监督方法在10-shot学习场景下达到MAE 0.44（监督基线方法失败）；提出的泛化指数GI接近完美；在WiAR公开基准上达到98.8%准确率；适配器微调性能接近全微调（98.84% vs 99.67%），但参数训练量减少97.2%。

Conclusion: 该工作为开发稳健感知系统提供了实用且可扩展的解决方案，使WiFi人群计数技术能够适应真实世界的IoT部署需求。

Abstract: Device-free crowd-counting using WiFi Channel State Information (CSI) is a key enabling technology for a new generation of privacy-preserving Internet of Things (IoT) applications. However, practical deployment is severely hampered by the domain shift problem, where models trained in one environment fail to generalise to another. To overcome this, we propose a novel two-stage framework centred on a CSI-ResNet-A architecture. This model is pre-trained via self-supervised contrastive learning to learn domain-invariant representations and leverages lightweight Adapter modules for highly efficient fine-tuning. The resulting event sequence is then processed by a stateful counting machine to produce a final, stable occupancy estimate. We validate our framework extensively. On our WiFlow dataset, our unsupervised approach excels in a 10-shot learning scenario, achieving a final Mean Absolute Error (MAE) of just 0.44--a task where supervised baselines fail. To formally quantify robustness, we introduce the Generalisation Index (GI), on which our model scores near-perfectly, confirming its ability to generalise. Furthermore, our framework sets a new state-of-the-art public WiAR benchmark with 98.8\% accuracy. Our ablation studies reveal the core strength of our design: adapter-based fine-tuning achieves performance within 1\% of a full fine-tune (98.84\% vs. 99.67\%) while training 97.2\% fewer parameters. Our work provides a practical and scalable solution for developing robust sensing systems ready for real-world IoT deployments.

</details>


### [152] [NextFlow: Unified Sequential Modeling Activates Multimodal Understanding and Generation](https://arxiv.org/abs/2601.02204)
*Huichao Zhang,Liao Qu,Yiheng Liu,Hang Chen,Yangyang Song,Yongsheng Dong,Shikun Sun,Xian Li,Xu Wang,Yi Jiang,Hu Ye,Bo Chen,Yiming Gao,Peng Liu,Akide Liu,Zhipeng Yang,Qili Deng,Linjie Xing,Jiyang Liu,Zhao Wang,Yang Zhou,Mingcong Liu,Yi Zhang,Qian He,Xiwei Hu,Zhongqi Qi,Jie Shao,Zhiye Fu,Shuai Wang,Fangmin Chen,Xuezhi Chai,Zhihua Wu,Yitong Wang,Zehuan Yuan,Daniel K. Du,Xinglong Wu*

Main category: cs.CV

TL;DR: NextFlow是一个统一的解码器自回归Transformer模型，通过多尺度视觉生成和前缀调优策略，在6万亿文本-图像离散标记上训练，实现了快速高质量的多模态生成。


<details>
  <summary>Details</summary>
Motivation: 解决传统自回归模型在视觉生成中效率低下的问题，同时处理文本的序列性和图像的分层性差异，实现统一的多模态理解与生成。

Method: 采用统一的自回归架构，文本使用下一标记预测，视觉使用下一尺度预测（非传统光栅扫描），结合鲁棒训练方案和前缀调优强化学习策略。

Result: NextFlow在5秒内生成1024x1024图像，比同类AR模型快数个数量级，在统一模型中达到最先进性能，视觉质量可与专用扩散模型相媲美。

Conclusion: 该模型通过创新的多尺度生成方法和统一架构，成功实现了高效的多模态内容生成，为统一模型的发展提供了新方向。

Abstract: We present NextFlow, a unified decoder-only autoregressive transformer trained on 6 trillion interleaved text-image discrete tokens. By leveraging a unified vision representation within a unified autoregressive architecture, NextFlow natively activates multimodal understanding and generation capabilities, unlocking abilities of image editing, interleaved content and video generation. Motivated by the distinct nature of modalities - where text is strictly sequential and images are inherently hierarchical - we retain next-token prediction for text but adopt next-scale prediction for visual generation. This departs from traditional raster-scan methods, enabling the generation of 1024x1024 images in just 5 seconds - orders of magnitude faster than comparable AR models. We address the instabilities of multi-scale generation through a robust training recipe. Furthermore, we introduce a prefix-tuning strategy for reinforcement learning. Experiments demonstrate that NextFlow achieves state-of-the-art performance among unified models and rivals specialized diffusion baselines in visual quality.

</details>


### [153] [Seeing the Unseen: Zooming in the Dark with Event Cameras](https://arxiv.org/abs/2601.02206)
*Dachun Kai,Zeyu Xiao,Huyue Zhu,Jiaxiao Wang,Yueyi Zhang,Xiaoyan Sun*

Main category: cs.CV

TL;DR: RetinexEVSR是一个基于事件驱动的低光视频超分辨率框架，利用高对比度事件信号和Retinex先验来增强低光场景下的视频质量，通过双向跨模态融合策略实现细节恢复。


<details>
  <summary>Details</summary>
Motivation: 现有低光视频超分辨率方法由于对比度有限和高频信息不足，难以恢复精细细节。需要利用事件信号的高对比度特性来克服这些挑战。

Method: 提出双向跨模态融合策略：1）光照引导的事件增强模块，利用Retinex模型的光照图逐步优化事件特征；2）事件引导的反射率增强模块，通过多尺度融合机制动态恢复反射率细节。

Result: 在三个数据集上达到SOTA性能，在SDSD基准上比之前基于事件的方法获得2.95 dB增益，同时减少65%的运行时间。

Conclusion: RetinexEVSR通过有效融合事件信号和RGB帧，在低光视频超分辨率任务中实现了显著的性能提升和效率优化。

Abstract: This paper addresses low-light video super-resolution (LVSR), aiming to restore high-resolution videos from low-light, low-resolution (LR) inputs. Existing LVSR methods often struggle to recover fine details due to limited contrast and insufficient high-frequency information. To overcome these challenges, we present RetinexEVSR, the first event-driven LVSR framework that leverages high-contrast event signals and Retinex-inspired priors to enhance video quality under low-light scenarios. Unlike previous approaches that directly fuse degraded signals, RetinexEVSR introduces a novel bidirectional cross-modal fusion strategy to extract and integrate meaningful cues from noisy event data and degraded RGB frames. Specifically, an illumination-guided event enhancement module is designed to progressively refine event features using illumination maps derived from the Retinex model, thereby suppressing low-light artifacts while preserving high-contrast details. Furthermore, we propose an event-guided reflectance enhancement module that utilizes the enhanced event features to dynamically recover reflectance details via a multi-scale fusion mechanism. Experimental results show that our RetinexEVSR achieves state-of-the-art performance on three datasets. Notably, on the SDSD benchmark, our method can get up to 2.95 dB gain while reducing runtime by 65% compared to prior event-based methods. Code: https://github.com/DachunKai/RetinexEVSR.

</details>


### [154] [Unraveling MMDiT Blocks: Training-free Analysis and Enhancement of Text-conditioned Diffusion](https://arxiv.org/abs/2601.02211)
*Binglei Li,Mengping Yang,Zhiyu Tan,Junping Zhang,Hao Li*

Main category: cs.CV

TL;DR: 本文系统分析了基于MMDiT的扩散模型内部机制，提出了通过移除、禁用和增强文本隐藏状态来研究各模块功能的管道，并基于发现提出了无需训练的策略来改进文本对齐、精确编辑和加速。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要分析特定组件如位置编码和注意力层，但对不同模块及其与文本条件交互如何影响合成过程的全面理解仍不足。

Method: 开发系统管道，通过移除、禁用和增强文本隐藏状态来研究各模块功能；基于发现提出无需训练的策略。

Result: 方法在T2I-Combench++上从56.92%提升到63.00%，在GenEval上从66.42%提升到71.63%，且不牺牲合成质量。

Conclusion: 研究结果增进了对MMDiT模型的理解，为未来改进提供了有价值的见解。

Abstract: Recent breakthroughs of transformer-based diffusion models, particularly with Multimodal Diffusion Transformers (MMDiT) driven models like FLUX and Qwen Image, have facilitated thrilling experiences in text-to-image generation and editing. To understand the internal mechanism of MMDiT-based models, existing methods tried to analyze the effect of specific components like positional encoding and attention layers. Yet, a comprehensive understanding of how different blocks and their interactions with textual conditions contribute to the synthesis process remains elusive. In this paper, we first develop a systematic pipeline to comprehensively investigate each block's functionality by removing, disabling and enhancing textual hidden-states at corresponding blocks. Our analysis reveals that 1) semantic information appears in earlier blocks and finer details are rendered in later blocks, 2) removing specific blocks is usually less disruptive than disabling text conditions, and 3) enhancing textual conditions in selective blocks improves semantic attributes. Building on these observations, we further propose novel training-free strategies for improved text alignment, precise editing, and acceleration. Extensive experiments demonstrated that our method outperforms various baselines and remains flexible across text-to-image generation, image editing, and inference acceleration. Our method improves T2I-Combench++ from 56.92% to 63.00% and GenEval from 66.42% to 71.63% on SD3.5, without sacrificing synthesis quality. These results advance understanding of MMDiT models and provide valuable insights to unlock new possibilities for further improvements.

</details>


### [155] [Prior-Guided DETR for Ultrasound Nodule Detection](https://arxiv.org/abs/2601.02212)
*Jingjing Wang,Zhuo Xiao,Xinning Yao,Bo Liu,Lijuan Niu,Xiangzhi Bai,Fugen Zhou*

Main category: cs.CV

TL;DR: 提出了一种基于先验知识引导的DETR框架，用于超声结节检测，通过多阶段融入几何先验和多尺度结构先验，显著提升了不规则和模糊结节的检测精度。


<details>
  <summary>Details</summary>
Motivation: 超声结节检测面临结节形状不规则、边界模糊、尺度变化大以及斑点噪声等挑战，传统数据驱动方法难以有效处理这些问题。

Method: 设计了SDFPR模块在CNN骨干网络中注入几何先验，MSFFM模块提取多尺度空间-频率特征，DFI机制在编码器层间传播先验调制特征，使解码器在一致的几何和结构指导下增强查询优化。

Result: 在两个临床甲状腺超声数据集和两个公共基准测试上，相比18种检测方法取得了更优的准确率，特别是在检测形态复杂结节方面表现突出。

Conclusion: 该先验引导的DETR框架通过系统性地融入多源先验知识，有效解决了超声结节检测中的关键挑战，为医学图像分析提供了新的解决方案。

Abstract: Accurate detection of ultrasound nodules is essential for the early diagnosis and treatment of thyroid and breast cancers. However, this task remains challenging due to irregular nodule shapes, indistinct boundaries, substantial scale variations, and the presence of speckle noise that degrades structural visibility. To address these challenges, we propose a prior-guided DETR framework specifically designed for ultrasound nodule detection. Instead of relying on purely data-driven feature learning, the proposed framework progressively incorporates different prior knowledge at multiple stages of the network. First, a Spatially-adaptive Deformable FFN with Prior Regularization (SDFPR) is embedded into the CNN backbone to inject geometric priors into deformable sampling, stabilizing feature extraction for irregular and blurred nodules. Second, a Multi-scale Spatial-Frequency Feature Mixer (MSFFM) is designed to extract multi-scale structural priors, where spatial-domain processing emphasizes contour continuity and boundary cues, while frequency-domain modeling captures global morphology and suppresses speckle noise. Furthermore, a Dense Feature Interaction (DFI) mechanism propagates and exploits these prior-modulated features across all encoder layers, enabling the decoder to enhance query refinement under consistent geometric and structural guidance. Experiments conducted on two clinically collected thyroid ultrasound datasets (Thyroid I and Thyroid II) and two public benchmarks (TN3K and BUSI) for thyroid and breast nodules demonstrate that the proposed method achieves superior accuracy compared with 18 detection methods, particularly in detecting morphologically complex nodules.The source code is publicly available at https://github.com/wjj1wjj/Ultrasound-DETR.

</details>


### [156] [FMVP: Masked Flow Matching for Adversarial Video Purification](https://arxiv.org/abs/2601.02228)
*Duoxun Tang,Xueyi Zhang,Chak Hin Wang,Xi Xiao,Dasen Dai,Xinhang Jiang,Wentao Shi,Rui Li,Qing Li*

Main category: cs.CV

TL;DR: FMVP是一种基于流匹配的视频对抗净化方法，通过掩码策略破坏全局对抗结构，使用条件流匹配重建干净视频动态，并设计频率门控损失分离语义内容和对抗噪声。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的净化方法存在采样效率低和轨迹弯曲问题，直接回归干净视频难以恢复忠实内容，需要物理破坏对抗结构。

Method: 采用掩码策略破坏全局对抗结构，使用条件流匹配进行视频修复，设计频率门控损失抑制高频对抗残差，提出攻击感知和通用训练范式。

Result: 在UCF-101和HMDB-51数据集上，FMVP在PGD攻击下鲁棒准确率超过87%，CW攻击下超过89%，对自适应攻击具有优越鲁棒性，零样本检测准确率PGD达98%，CW达79%。

Conclusion: FMVP通过物理破坏对抗结构和频率分离策略，实现了高效的视频对抗净化，在多种攻击下表现出优越性能，同时具备零样本检测能力。

Abstract: Video recognition models remain vulnerable to adversarial attacks, while existing diffusion-based purification methods suffer from inefficient sampling and curved trajectories. Directly regressing clean videos from adversarial inputs often fails to recover faithful content due to the subtle nature of perturbations; this necessitates physically shattering the adversarial structure. Therefore, we propose Flow Matching for Adversarial Video Purification FMVP. FMVP physically shatters global adversarial structures via a masking strategy and reconstructs clean video dynamics using Conditional Flow Matching (CFM) with an inpainting objective. To further decouple semantic content from adversarial noise, we design a Frequency-Gated Loss (FGL) that explicitly suppresses high-frequency adversarial residuals while preserving low-frequency fidelity. We design Attack-Aware and Generalist training paradigms to handle known and unknown threats, respectively. Extensive experiments on UCF-101 and HMDB-51 demonstrate that FMVP outperforms state-of-the-art methods (DiffPure, Defense Patterns (DP), Temporal Shuffling (TS) and FlowPure), achieving robust accuracy exceeding 87% against PGD and 89% against CW attacks. Furthermore, FMVP demonstrates superior robustness against adaptive attacks (DiffHammer) and functions as a zero-shot adversarial detector, attaining detection accuracies of 98% for PGD and 79% for highly imperceptible CW attacks.

</details>


### [157] [VIBE: Visual Instruction Based Editor](https://arxiv.org/abs/2601.02242)
*Grigorii Alekseenko,Aleksandr Gordeev,Irina Tolstykh,Bulat Suleimanov,Vladimir Dokholyan,Georgii Fedorov,Sergey Yakubson,Aleksandra Tsybina,Mikhail Chernyshov,Maksim Kuprashevich*

Main category: cs.CV

TL;DR: 本文提出了一个紧凑高效的基于指令的图像编辑管道，使用2B参数的Qwen3-VL模型指导编辑过程和1.6B参数的Sana1.5扩散模型进行图像生成，在保持高质量的同时显著降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 当前基于指令的图像编辑方法主要依赖大型扩散模型（6B-20B参数），计算成本高昂，限制了实际部署和研究应用。需要开发更紧凑高效的解决方案。

Method: 采用2B参数的Qwen3-VL模型作为编辑指导器，配合1.6B参数的Sana1.5扩散模型进行图像生成。通过架构设计、数据处理和训练配置优化，实现低推理成本和严格源一致性。

Result: 在ImgEdit和GEdit基准测试中，该方法匹配或超越了参数规模大数倍的基线模型性能，特别擅长保持输入图像的编辑任务（属性调整、对象移除、背景编辑等）。模型仅需24GB GPU内存，在H100上4秒内生成2K分辨率图像。

Conclusion: 该紧凑图像编辑管道证明了在显著降低计算成本的同时保持高质量编辑效果的可行性，为实际部署和进一步研究提供了高效解决方案。

Abstract: Instruction-based image editing is among the fastest developing areas in generative AI. Over the past year, the field has reached a new level, with dozens of open-source models released alongside highly capable commercial systems. However, only a limited number of open-source approaches currently achieve real-world quality. In addition, diffusion backbones, the dominant choice for these pipelines, are often large and computationally expensive for many deployments and research settings, with widely used variants typically containing 6B to 20B parameters. This paper presents a compact, high-throughput instruction-based image editing pipeline that uses a modern 2B-parameter Qwen3-VL model to guide the editing process and the 1.6B-parameter diffusion model Sana1.5 for image generation. Our design decisions across architecture, data processing, training configuration, and evaluation target low-cost inference and strict source consistency while maintaining high quality across the major edit categories feasible at this scale. Evaluated on the ImgEdit and GEdit benchmarks, the proposed method matches or exceeds the performance of substantially heavier baselines, including models with several times as many parameters and higher inference cost, and is particularly strong on edits that require preserving the input image, such as an attribute adjustment, object removal, background edits, and targeted replacement. The model fits within 24 GB of GPU memory and generates edited images at up to 2K resolution in approximately 4 seconds on an NVIDIA H100 in BF16, without additional inference optimizations or distillation.

</details>


### [158] [A Comparative Study of Custom CNNs, Pre-trained Models, and Transfer Learning Across Multiple Visual Datasets](https://arxiv.org/abs/2601.02246)
*Annoor Sharara Akhand*

Main category: cs.CV

TL;DR: 本文对三种CNN训练范式进行了对比研究：从头训练小型CNN、使用预训练CNN作为固定特征提取器、以及通过微调进行迁移学习。在五个真实图像分类数据集上的实验表明，迁移学习性能最佳，而小型CNN在计算效率方面具有优势。


<details>
  <summary>Details</summary>
Motivation: 实践中，视觉识别任务通常面临三种CNN训练策略的选择，但缺乏对这些方法在真实场景中的系统性对比研究，特别是考虑到准确性和效率的平衡。

Method: 在五个真实图像分类数据集上（道路缺陷识别、农作物品种识别、水果/叶片病害识别、人行道侵占识别、未授权车辆识别），系统比较了三种CNN训练范式，使用准确率和宏F1分数评估性能，并结合训练时间和参数量等效率指标。

Result: 迁移学习在所有数据集上均表现出最强的预测性能，而自定义CNN在计算和内存受限时提供了更好的效率-准确性权衡。

Conclusion: 迁移学习是获得最佳性能的首选方法，但在资源受限场景下，训练小型自定义CNN是更实用的选择，需要在准确性和效率之间进行权衡。

Abstract: Convolutional Neural Networks (CNNs) are a standard approach for visual recognition due to their capacity to learn hierarchical representations from raw pixels. In practice, practitioners often choose among (i) training a compact custom CNN from scratch, (ii) using a large pre-trained CNN as a fixed feature extractor, and (iii) performing transfer learning via partial or full fine-tuning of a pre-trained backbone. This report presents a controlled comparison of these three paradigms across five real-world image classification datasets spanning road-surface defect recognition, agricultural variety identification, fruit/leaf disease recognition, pedestrian walkway encroachment recognition, and unauthorized vehicle recognition. Models are evaluated using accuracy and macro F1-score, complemented by efficiency metrics including training time per epoch and parameter counts. The results show that transfer learning consistently yields the strongest predictive performance, while the custom CNN provides an attractive efficiency--accuracy trade-off, especially when compute and memory budgets are constrained.

</details>


### [159] [SLGNet: Synergizing Structural Priors and Language-Guided Modulation for Multimodal Object Detection](https://arxiv.org/abs/2601.02249)
*Xiantai Xiang,Guangyao Zhou,Zixiao Wen,Wenshuai Li,Ben Niu,Feng Wang,Lijia Huang,Qiantong Wang,Yuhan Liu,Zongxu Pan,Yuxin Hu*

Main category: cs.CV

TL;DR: SLGNet是一个参数高效的多模态目标检测框架，结合了层次结构先验和语言引导调制，在冻结的ViT基础模型上实现跨模态结构一致性和环境感知


<details>
  <summary>Details</summary>
Motivation: 解决现有基于适配器的方法在跨模态结构一致性方面的不足，以及传统静态多模态融合机制缺乏环境感知的问题，特别是在高对比度或夜间环境等复杂场景下

Method: 提出结构感知适配器提取层次结构表示，并设计语言引导调制模块利用VLM驱动的结构化描述动态重新校准视觉特征

Result: 在LLVIP、FLIR、KAIST和DroneVehicle数据集上达到最先进性能，LLVIP基准上mAP达到66.1，同时比传统全微调减少约87%的可训练参数

Conclusion: SLGNet为多模态感知提供了一个鲁棒且高效的解决方案，能够有效应对复杂动态场景变化

Abstract: Multimodal object detection leveraging RGB and Infrared (IR) images is pivotal for robust perception in all-weather scenarios. While recent adapter-based approaches efficiently transfer RGB-pretrained foundation models to this task, they often prioritize model efficiency at the expense of cross-modal structural consistency. Consequently, critical structural cues are frequently lost when significant domain gaps arise, such as in high-contrast or nighttime environments. Moreover, conventional static multimodal fusion mechanisms typically lack environmental awareness, resulting in suboptimal adaptation and constrained detection performance under complex, dynamic scene variations. To address these limitations, we propose SLGNet, a parameter-efficient framework that synergizes hierarchical structural priors and language-guided modulation within a frozen Vision Transformer (ViT)-based foundation model. Specifically, we design a Structure-Aware Adapter to extract hierarchical structural representations from both modalities and dynamically inject them into the ViT to compensate for structural degradation inherent in ViT-based backbones. Furthermore, we propose a Language-Guided Modulation module that exploits VLM-driven structured captions to dynamically recalibrate visual features, thereby endowing the model with robust environmental awareness. Extensive experiments on the LLVIP, FLIR, KAIST, and DroneVehicle datasets demonstrate that SLGNet establishes new state-of-the-art performance. Notably, on the LLVIP benchmark, our method achieves an mAP of 66.1, while reducing trainable parameters by approximately 87% compared to traditional full fine-tuning. This confirms SLGNet as a robust and efficient solution for multimodal perception.

</details>


### [160] [VAR RL Done Right: Tackling Asynchronous Policy Conflicts in Visual Autoregressive Generation](https://arxiv.org/abs/2601.02256)
*Shikun Sun,Liao Qu,Huichao Zhang,Yiheng Liu,Yangyang Song,Xian Li,Xu Wang,Yi Jiang,Daniel K. Du,Xinglong Wu,Jia Jia*

Main category: cs.CV

TL;DR: 本文提出了一种增强GRPO框架的新方法，通过管理VAR模型中的异步策略冲突来解决视觉生成中的训练不稳定和对齐问题。


<details>
  <summary>Details</summary>
Motivation: VAR模型在生成步骤中存在异构输入结构，导致严重的异步策略冲突，特别是在强化学习场景中造成训练不稳定和次优对齐。

Method: 方法包含三个协同组件：1）稳定中间奖励指导早期生成；2）动态时间步重加权方案进行精确信用分配；3）基于Reward Feedback Learning的新型掩码传播算法，在空间和时间上隔离优化效果。

Result: 相比原始GRPO基线，该方法在样本质量和目标对齐方面取得了显著改进。

Conclusion: 该方法为VAR模型实现了稳健有效的优化，解决了异步策略冲突问题。

Abstract: Visual generation is dominated by three paradigms: AutoRegressive (AR), diffusion, and Visual AutoRegressive (VAR) models. Unlike AR and diffusion, VARs operate on heterogeneous input structures across their generation steps, which creates severe asynchronous policy conflicts. This issue becomes particularly acute in reinforcement learning (RL) scenarios, leading to unstable training and suboptimal alignment. To resolve this, we propose a novel framework to enhance Group Relative Policy Optimization (GRPO) by explicitly managing these conflicts. Our method integrates three synergistic components: 1) a stabilizing intermediate reward to guide early-stage generation; 2) a dynamic time-step reweighting scheme for precise credit assignment; and 3) a novel mask propagation algorithm, derived from principles of Reward Feedback Learning (ReFL), designed to isolate optimization effects both spatially and temporally. Our approach demonstrates significant improvements in sample quality and objective alignment over the vanilla GRPO baseline, enabling robust and effective optimization for VAR models.

</details>


### [161] [DiffProxy: Multi-View Human Mesh Recovery via Diffusion-Generated Dense Proxies](https://arxiv.org/abs/2601.02267)
*Renke Wang,Zhenyu Zhang,Ying Tai,Jian Yang*

Main category: cs.CV

TL;DR: DiffProxy是一个从多视角图像恢复人体网格的新框架，利用扩散生成先验来弥合合成数据训练和真实世界泛化之间的差距，在多个真实世界基准测试中实现了最先进的零样本泛化性能。


<details>
  <summary>Details</summary>
Motivation: 解决真实世界数据集标注不完美导致模型训练偏差，以及合成数据存在领域差距的问题，需要一种能够有效利用精确合成标注同时具备良好泛化能力的方法。

Method: 提出DiffProxy框架，包含多条件机制生成多视角一致的人体代理、基于视觉提示的手部细化模块，以及不确定性感知的测试时缩放方法。

Result: 在五个真实世界基准测试中实现了最先进的性能，特别是在遮挡和部分视角等挑战性场景下表现出强大的零样本泛化能力。

Conclusion: DiffProxy通过扩散生成先验成功地将精确的合成地面真值与生成优势相结合，为人体网格恢复提供了有效的解决方案。

Abstract: Human mesh recovery from multi-view images faces a fundamental challenge: real-world datasets contain imperfect ground-truth annotations that bias the models' training, while synthetic data with precise supervision suffers from domain gap. In this paper, we propose DiffProxy, a novel framework that generates multi-view consistent human proxies for mesh recovery. Central to DiffProxy is leveraging the diffusion-based generative priors to bridge the synthetic training and real-world generalization. Its key innovations include: (1) a multi-conditional mechanism for generating multi-view consistent, pixel-aligned human proxies; (2) a hand refinement module that incorporates flexible visual prompts to enhance local details; and (3) an uncertainty-aware test-time scaling method that increases robustness to challenging cases during optimization. These designs ensure that the mesh recovery process effectively benefits from the precise synthetic ground truth and generative advantages of the diffusion-based pipeline. Trained entirely on synthetic data, DiffProxy achieves state-of-the-art performance across five real-world benchmarks, demonstrating strong zero-shot generalization particularly on challenging scenarios with occlusions and partial views. Project page: https://wrk226.github.io/DiffProxy.html

</details>


### [162] [TopoLoRA-SAM: Topology-Aware Parameter-Efficient Adaptation of Foundation Segmenters for Thin-Structure and Cross-Domain Binary Semantic Segmentation](https://arxiv.org/abs/2601.02273)
*Salim Khazem*

Main category: cs.CV

TL;DR: TopoLoRA-SAM是一种拓扑感知的参数高效适应框架，专门用于二进制语义分割，通过在冻结的ViT编码器中注入LoRA并添加轻量级空间卷积适配器，实现了对薄结构和噪声模态的优异分割性能。


<details>
  <summary>Details</summary>
Motivation: 基础分割模型如SAM在零样本泛化方面表现优异，但适应领域特定的语义分割（特别是薄结构和噪声模态）仍具挑战性。全微调计算成本高且存在灾难性遗忘风险。

Method: 在冻结的ViT编码器中注入低秩适应（LoRA），增强轻量级空间卷积适配器，并通过可微分clDice实现可选的拓扑感知监督。

Result: 在五个基准数据集上评估，TopoLoRA-SAM在视网膜血管分割方面达到最佳平均Dice，整体平均Dice最佳，仅训练模型参数的5.2%（约490万参数）。在CHASE_DB1数据集上显著提升分割精度和鲁棒性。

Conclusion: 拓扑感知的参数高效适应方法能够匹配或超越完全微调的专家模型，证明了该方法在薄结构和噪声模态分割中的有效性。

Abstract: Foundation segmentation models such as the Segment Anything Model (SAM) exhibit strong zero-shot generalization through large-scale pretraining, but adapting them to domain-specific semantic segmentation remains challenging, particularly for thin structures (e.g., retinal vessels) and noisy modalities (e.g., SAR imagery). Full fine-tuning is computationally expensive and risks catastrophic forgetting. We propose \textbf{TopoLoRA-SAM}, a topology-aware and parameter-efficient adaptation framework for binary semantic segmentation. TopoLoRA-SAM injects Low-Rank Adaptation (LoRA) into the frozen ViT encoder, augmented with a lightweight spatial convolutional adapter and optional topology-aware supervision via differentiable clDice. We evaluate our approach on five benchmarks spanning retinal vessel segmentation (DRIVE, STARE, CHASE\_DB1), polyp segmentation (Kvasir-SEG), and SAR sea/land segmentation (SL-SSDD), comparing against U-Net, DeepLabV3+, SegFormer, and Mask2Former. TopoLoRA-SAM achieves the best retina-average Dice and the best overall average Dice across datasets, while training only \textbf{5.2\%} of model parameters ($\sim$4.9M). On the challenging CHASE\_DB1 dataset, our method substantially improves segmentation accuracy and robustness, demonstrating that topology-aware parameter-efficient adaptation can match or exceed fully fine-tuned specialist models. Code is available at : https://github.com/salimkhazem/Seglab.git

</details>


### [163] [InfiniteVGGT: Visual Geometry Grounded Transformer for Endless Streams](https://arxiv.org/abs/2601.02281)
*Shuai Yuan,Yantai Yang,Xiaotian Yang,Xupeng Zhang,Zhonghao Zhao,Lingming Zhang,Zhipeng Zhang*

Main category: cs.CV

TL;DR: InfiniteVGGT是一个因果视觉几何变换器，通过滚动记忆机制解决了流式3D几何理解中可扩展性和长期稳定性的矛盾，支持无限时长的输入，并在长序列上优于现有流式方法。


<details>
  <summary>Details</summary>
Motivation: 现有离线模型（如VGGT）虽然几何能力强大但不适用于实时系统，而流式架构要么无法支持真正无限时长的输入，要么在长序列上出现灾难性漂移。

Method: 采用有界但自适应且持续表达的KV缓存实现滚动记忆机制，并提出无需训练、注意力无关的剪枝策略来智能丢弃过时信息，每帧更新记忆。

Result: InfiniteVGGT在长期稳定性上优于现有流式方法，支持无限时长的流式处理，并与FlashAttention完全兼容。

Conclusion: 该方法最终解决了流式3D几何理解的折衷问题，同时引入了Long3D基准测试（约10,000帧序列）来严格评估长期3D几何估计性能。

Abstract: The grand vision of enabling persistent, large-scale 3D visual geometry understanding is shackled by the irreconcilable demands of scalability and long-term stability. While offline models like VGGT achieve inspiring geometry capability, their batch-based nature renders them irrelevant for live systems. Streaming architectures, though the intended solution for live operation, have proven inadequate. Existing methods either fail to support truly infinite-horizon inputs or suffer from catastrophic drift over long sequences. We shatter this long-standing dilemma with InfiniteVGGT, a causal visual geometry transformer that operationalizes the concept of a rolling memory through a bounded yet adaptive and perpetually expressive KV cache. Capitalizing on this, we devise a training-free, attention-agnostic pruning strategy that intelligently discards obsolete information, effectively ``rolling'' the memory forward with each new frame. Fully compatible with FlashAttention, InfiniteVGGT finally alleviates the compromise, enabling infinite-horizon streaming while outperforming existing streaming methods in long-term stability. The ultimate test for such a system is its performance over a truly infinite horizon, a capability that has been impossible to rigorously validate due to the lack of extremely long-term, continuous benchmarks. To address this critical gap, we introduce the Long3D benchmark, which, for the first time, enables a rigorous evaluation of continuous 3D geometry estimation on sequences about 10,000 frames. This provides the definitive evaluation platform for future research in long-term 3D geometry understanding. Code is available at: https://github.com/AutoLab-SAI-SJTU/InfiniteVGGT

</details>


### [164] [Rank-based Geographical Regularization: Revisiting Contrastive Self-Supervised Learning for Multispectral Remote Sensing Imagery](https://arxiv.org/abs/2601.02289)
*Tom Burgert,Leonard Hackel,Paolo Rota,Begüm Demir*

Main category: cs.CV

TL;DR: GeoRank是一种用于多光谱遥感图像对比自监督学习的新正则化方法，通过优化球面距离将地理关系嵌入特征空间，在多个对比学习算法上表现优异。


<details>
  <summary>Details</summary>
Motivation: 多光谱遥感图像具有地理和时间变异性，现有的自监督学习方法难以有效处理这些特性，需要专门的方法来整合地理元数据。

Method: 提出GeoRank正则化方法，直接优化球面距离来嵌入地理关系；系统研究了对比自监督学习在多光谱遥感图像上的关键适应技术，包括数据增强、数据集规模和图像大小的影响，以及时间视图的任务依赖性。

Result: GeoRank在整合地理元数据的方法中表现优于或匹配现有方法，并能持续改进多种对比自监督学习算法（如BYOL、DINO）。

Conclusion: GeoRank为多光谱遥感图像的自监督学习提供了有效的正则化方法，系统研究为相关应用提供了重要指导。

Abstract: Self-supervised learning (SSL) has become a powerful paradigm for learning from large, unlabeled datasets, particularly in computer vision (CV). However, applying SSL to multispectral remote sensing (RS) images presents unique challenges and opportunities due to the geographical and temporal variability of the data. In this paper, we introduce GeoRank, a novel regularization method for contrastive SSL that improves upon prior techniques by directly optimizing spherical distances to embed geographical relationships into the learned feature space. GeoRank outperforms or matches prior methods that integrate geographical metadata and consistently improves diverse contrastive SSL algorithms (e.g., BYOL, DINO). Beyond this, we present a systematic investigation of key adaptations of contrastive SSL for multispectral RS images, including the effectiveness of data augmentations, the impact of dataset cardinality and image size on performance, and the task dependency of temporal views. Code is available at https://github.com/tomburgert/georank.

</details>


### [165] [SortWaste: A Densely Annotated Dataset for Object Detection in Industrial Waste Sorting](https://arxiv.org/abs/2601.02299)
*Sara Inácio,Hugo Proença,João C. Neves*

Main category: cs.CV

TL;DR: 本文介绍了SortWaste数据集和ClutterScore指标，用于解决垃圾自动分拣中的视觉复杂性问题，并评估了现有目标检测模型在垃圾分拣场景中的性能。


<details>
  <summary>Details</summary>
Motivation: 垃圾产量增加导致分拣挑战，现有自动分拣系统难以处理真实垃圾流的高变异性、杂乱性和视觉复杂性，缺乏真实数据集是主要瓶颈。

Method: 1) 提出SortWaste数据集，来自材料回收设施的密集标注目标检测数据集；2) 提出ClutterScore指标，通过对象数量、类别和大小熵、空间重叠等代理变量评估场景复杂度；3) 对最先进的目标检测模型进行基准测试。

Result: 在仅塑料检测任务中达到59.7%的mAP，但在高杂乱场景中性能显著下降，表明需要更具挑战性的数据集。

Conclusion: 垃圾自动分拣系统在复杂场景中仍面临挑战，需要开发更先进的数据集和算法来应对现实世界的垃圾分拣需求。

Abstract: The increasing production of waste, driven by population growth, has created challenges in managing and recycling materials effectively. Manual waste sorting is a common practice; however, it remains inefficient for handling large-scale waste streams and presents health risks for workers. On the other hand, existing automated sorting approaches still struggle with the high variability, clutter, and visual complexity of real-world waste streams. The lack of real-world datasets for waste sorting is a major reason automated systems for this problem are underdeveloped. Accordingly, we introduce SortWaste, a densely annotated object detection dataset collected from a Material Recovery Facility. Additionally, we contribute to standardizing waste detection in sorting lines by proposing ClutterScore, an objective metric that gauges the scene's hardness level using a set of proxies that affect visual complexity (e.g., object count, class and size entropy, and spatial overlap). In addition to these contributions, we provide an extensive benchmark of state-of-the-art object detection models, detailing their results with respect to the hardness level assessed by the proposed metric. Despite achieving promising results (mAP of 59.7% in the plastic-only detection task), performance significantly decreases in highly cluttered scenes. This highlights the need for novel and more challenging datasets on the topic.

</details>


### [166] [360DVO: Deep Visual Odometry for Monocular 360-Degree Camera](https://arxiv.org/abs/2601.02309)
*Xiaopeng Guo,Yinzhe Xu,Huajian Huang,Sai-Kit Yeung*

Main category: cs.CV

TL;DR: 360DVO是首个基于深度学习的单目全景视觉里程计框架，通过自适应学习抗畸变特征和新颖的全景可微束调整模块，在挑战性场景中显著提升了鲁棒性和精度。


<details>
  <summary>Details</summary>
Motivation: 现有的全景VO系统依赖手工特征或光度目标，在剧烈运动和光照变化等挑战性场景中缺乏鲁棒性，需要更强大的解决方案。

Method: 提出失真感知球面特征提取器(DAS-Feat)自适应学习360度图像的抗畸变特征，结合新颖的全景可微束调整模块(ODBA)进行有效位姿估计。

Result: 在真实世界基准和公开合成数据集上的实验表明，360DVO超越现有最优基线，鲁棒性提升50%，精度提升37.5%。

Conclusion: 360DVO证明了深度学习在全景视觉里程计中的有效性，为挑战性场景提供了更鲁棒和准确的解决方案。

Abstract: Monocular omnidirectional visual odometry (OVO) systems leverage 360-degree cameras to overcome field-of-view limitations of perspective VO systems. However, existing methods, reliant on handcrafted features or photometric objectives, often lack robustness in challenging scenarios, such as aggressive motion and varying illumination. To address this, we present 360DVO, the first deep learning-based OVO framework. Our approach introduces a distortion-aware spherical feature extractor (DAS-Feat) that adaptively learns distortion-resistant features from 360-degree images. These sparse feature patches are then used to establish constraints for effective pose estimation within a novel omnidirectional differentiable bundle adjustment (ODBA) module. To facilitate evaluation in realistic settings, we also contribute a new real-world OVO benchmark. Extensive experiments on this benchmark and public synthetic datasets (TartanAir V2 and 360VO) demonstrate that 360DVO surpasses state-of-the-art baselines (including 360VO and OpenVSLAM), improving robustness by 50% and accuracy by 37.5%. Homepage: https://chris1004336379.github.io/360DVO-homepage

</details>


### [167] [Prithvi-Complimentary Adaptive Fusion Encoder (CAFE): unlocking full-potential for flood inundation mapping](https://arxiv.org/abs/2601.02315)
*Saurabh Kaushik,Lalit Maurya,Beth Tellman*

Main category: cs.CV

TL;DR: Prithvi-CAFE模型通过结合Prithvi GFM预训练编码器和CNN残差分支，在洪水映射任务中显著优于基线模型和其他GFMs，特别是在捕捉局部细节方面表现突出。


<details>
  <summary>Details</summary>
Motivation: 现有的Geo-Foundation Models (GFMs) 在洪水映射任务中难以超越基线U-Net，主要问题在于无法有效捕捉关键的局部细节信息。

Method: 提出Prithvi-CAFE模型，集成Prithvi GFM预训练编码器与并行CNN残差分支，使用卷积注意力模块(CAM)增强，通过适配器实现快速微调，并进行多尺度、多层次特征融合。

Result: 在Sen1Flood11测试数据上，Prithvi-CAFE的IoU达到83.41，显著优于原始Prithvi(82.50)和其他GFMs；在FloodPlanet数据集上，IoU达到64.70，同样超越所有对比模型。

Conclusion: Prithvi-CAFE是一种简单有效的模型，在需要多通道多模态数据互补信息且局部细节关键的分割任务中具有强大潜力。

Abstract: Geo-Foundation Models (GFMs), have proven effective in diverse downstream applications, including semantic segmentation, classification, and regression tasks. However, in case of flood mapping using Sen1Flood11 dataset as a downstream task, GFMs struggles to outperform the baseline U-Net, highlighting model's limitation in capturing critical local nuances. To address this, we present the Prithvi-Complementary Adaptive Fusion Encoder (CAFE), which integrate Prithvi GFM pretrained encoder with a parallel CNN residual branch enhanced by Convolutional Attention Modules (CAM). Prithvi-CAFE enables fast and efficient fine-tuning through adapters in Prithvi and performs multi-scale, multi-level fusion with CNN features, capturing critical local details while preserving long-range dependencies. We achieve state-of-the-art results on two comprehensive flood mapping datasets: Sen1Flood11 and FloodPlanet. On Sen1Flood11 test data, Prithvi-CAFE (IoU 83.41) outperforms the original Prithvi (IoU 82.50) and other major GFMs (TerraMind 82.90, DOFA 81.54, spectralGPT: 81.02). The improvement is even more pronounced on the hold-out test site, where Prithvi-CAFE achieves an IoU of 81.37 compared to the baseline U-Net (70.57) and original Prithvi (72.42). On FloodPlanet, Prithvi-CAFE also surpasses the baseline U-Net and other GFMs, achieving an IoU of 64.70 compared to U-Net (60.14), Terramind (62.33), DOFA (59.15) and Prithvi 2.0 (61.91). Our proposed simple yet effective Prithvi-CAFE demonstrates strong potential for improving segmentation tasks where multi-channel and multi-modal data provide complementary information and local details are critical. The code is released on \href{https://github.com/Sk-2103/Prithvi-CAFE}{Prithvi-CAFE Github}

</details>


### [168] [Meta-Learning Guided Pruning for Few-Shot Plant Pathology on Edge Devices](https://arxiv.org/abs/2601.02353)
*Shahnawaz Alam,Mohammed Mudassir Uddin,Mohammed Kaif Pasha*

Main category: cs.CV

TL;DR: 本文提出DACIS方法，结合神经网络剪枝和少样本学习，显著减小植物病害检测模型大小，使其能在低成本设备上实时运行，同时保持高准确率。


<details>
  <summary>Details</summary>
Motivation: 偏远地区农民需要快速可靠的植物病害检测方法，但缺乏实验室资源且深度学习模型在边缘设备上运行困难，同时收集大量标注数据成本高昂。

Method: 提出Disease-Aware Channel Importance Scoring (DACIS)方法，集成到三阶段Prune-then-Meta-Learn-then-Prune (PMP)流程中，识别神经网络中对区分植物病害最重要的部分。

Result: 在PlantVillage和PlantDoc数据集上，模型大小减少78%，保持92.3%的原始准确率，在Raspberry Pi 4上达到7帧/秒的实时性能。

Conclusion: 该方法使实时田间病害诊断对小农户变得实用，解决了资源受限环境下的植物病害检测挑战。

Abstract: Farmers in remote areas need quick and reliable methods for identifying plant diseases, yet they often lack access to laboratories or high-performance computing resources. Deep learning models can detect diseases from leaf images with high accuracy, but these models are typically too large and computationally expensive to run on low-cost edge devices such as Raspberry Pi. Furthermore, collecting thousands of labeled disease images for training is both expensive and time-consuming. This paper addresses both challenges by combining neural network pruning -- removing unnecessary parts of the model -- with few-shot learning, which enables the model to learn from limited examples. This paper proposes Disease-Aware Channel Importance Scoring (DACIS), a method that identifies which parts of the neural network are most important for distinguishing between different plant diseases, integrated into a three-stage Prune-then-Meta-Learn-then-Prune (PMP) pipeline. Experiments on PlantVillage and PlantDoc datasets demonstrate that the proposed approach reduces model size by 78\% while maintaining 92.3\% of the original accuracy, with the compressed model running at 7 frames per second on a Raspberry Pi 4, making real-time field diagnosis practical for smallholder farmers.

</details>


### [169] [Fusion2Print: Deep Flash-Non-Flash Fusion for Contactless Fingerprint Matching](https://arxiv.org/abs/2601.02318)
*Roja Sahoo,Anoop Namboodiri*

Main category: cs.CV

TL;DR: Fusion2Print (F2P) 是一个新颖的接触式指纹识别框架，通过系统性地捕获和融合闪光-非闪光配对的接触式指纹图像，解决了接触式指纹图像中因光照变化、皮下皮肤变色和镜面反射导致的脊线清晰度下降问题。


<details>
  <summary>Details</summary>
Motivation: 接触式指纹识别虽然提供了卫生和便利的替代方案，但其图像常因光照变化、皮下皮肤变色和镜面反射而出现脊线清晰度下降。闪光捕获能保留脊线细节但引入噪声，非闪光捕获减少噪声但降低脊线对比度。

Method: F2P 框架首先构建了一个自定义的配对数据集 FNF Database，并进行手动闪光-非闪光减法以分离脊线保留信号。然后，一个轻量级的基于注意力的融合网络整合两种模态，强调信息通道并抑制噪声，接着通过 U-Net 增强模块生成最优加权的灰度图像。最后，一个具有跨域兼容性的深度嵌入模型在统一的嵌入空间中生成判别性和鲁棒性表示，兼容接触式和接触式指纹验证。

Result: F2P 显著增强了脊线清晰度，并实现了优于单捕获基线（Verifinger, DeepPrint）的识别性能，AUC 达到 0.999，EER 为 1.12%。

Conclusion: Fusion2Print 框架通过融合闪光和非闪光接触式指纹图像，有效提升了接触式指纹识别的性能，为卫生且高效的指纹识别系统提供了可行的解决方案。

Abstract: Contactless fingerprint recognition offers a hygienic and convenient alternative to contact-based systems, enabling rapid acquisition without latent prints, pressure artifacts, or hygiene risks. However, contactless images often show degraded ridge clarity due to illumination variation, subcutaneous skin discoloration, and specular reflections. Flash captures preserve ridge detail but introduce noise, whereas non-flash captures reduce noise but lower ridge contrast. We propose Fusion2Print (F2P), the first framework to systematically capture and fuse paired flash-non-flash contactless fingerprints. We construct a custom paired dataset, FNF Database, and perform manual flash-non-flash subtraction to isolate ridge-preserving signals. A lightweight attention-based fusion network also integrates both modalities, emphasizing informative channels and suppressing noise, and then a U-Net enhancement module produces an optimally weighted grayscale image. Finally, a deep embedding model with cross-domain compatibility, generates discriminative and robust representations in a unified embedding space compatible with both contactless and contact-based fingerprints for verification. F2P enhances ridge clarity and achieves superior recognition performance (AUC=0.999, EER=1.12%) over single-capture baselines (Verifinger, DeepPrint).

</details>


### [170] [BEDS: Bayesian Emergent Dissipative Structures](https://arxiv.org/abs/2601.02329)
*Laurent Caraffa*

Main category: cs.CV

TL;DR: BEDS框架统一了非平衡热力学、贝叶斯推断、信息几何和机器学习，提出学习本质上是熵输出驱动的通量到结构转换过程。


<details>
  <summary>Details</summary>
Motivation: 建立物理系统、生物系统和计算系统之间统一的学习理论框架，探索学习的基本原理及其在可持续人工智能中的应用。

Method: 基于Prigogine的耗散结构理论，建立热力学过程与贝叶斯更新的形式同构，推导数学常数作为贝叶斯推断的固定点，并提出哥德尔不完备定理与热力学约束的猜想。

Result: 开发了基于BEDS原理的点对点网络架构，实现了比现有分布式共识系统高6个数量级的能效提升，并支持持续学习。

Conclusion: 该工作连接了基础物理、数理逻辑和实际系统设计，为理解学习和计算的本质提供了理论洞见，并为可持续人工智能提供了具体实现路径。

Abstract: We present BEDS (Bayesian Emergent Dissipative Structures), a theoretical framework that unifies concepts from non-equilibrium thermodynamics, Bayesian inference, information geometry, and machine learning. The central thesis proposes that learning, across physical, biological, and computational systems, fundamentally constitutes the conversion of flux into structure through entropy export. Building on Prigogine's theory of dissipative structures, we establish a formal isomorphism between thermodynamic processes and Bayesian updating, demonstrating that sustainable learning systems must follow dissipative patterns where crystallized posteriors become priors for subsequent levels of emergence.
  We derive fundamental mathematical constants (e, π, φ) as fixed points of Bayesian inference under minimal axioms, suggesting these constants emerge necessarily from any system capable of representing and updating uncertainty. Furthermore, we propose a conjecture linking Gödel's incompleteness theorems to thermodynamic constraints, hypothesizing that pathologies of formal systems (incompleteness, undecidability) are structurally analogous to dissipation deficits in physical systems.
  As practical validation, we present a peer-to-peer network architecture implementing BEDS principles, achieving six orders of magnitude improvement in energy efficiency compared to existing distributed consensus systems while enabling continuous learning. This work bridges fundamental physics, mathematical logic, and practical system design, offering both theoretical insights into the nature of learning and computation, and a concrete pathway toward sustainable artificial intelligence.

</details>


### [171] [Joint Semantic and Rendering Enhancements in 3D Gaussian Modeling with Anisotropic Local Encoding](https://arxiv.org/abs/2601.02339)
*Jingming He,Chongyi Li,Shiqi Wang,Sam Kwong*

Main category: cs.CV

TL;DR: 提出了一种联合增强的3D语义高斯建模框架，通过结合语义和渲染分支，使用各向异性3D高斯切比雪夫描述符捕捉细粒度3D形状细节，并基于局部语义和形状信号自适应调整高斯分配，提升分割精度和渲染质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法将语义和渲染分支分开处理，仅依赖2D监督而忽略3D高斯几何，且在纹理稀疏区域的适应性策略不足。

Method: 1. 引入各向异性3D高斯切比雪夫描述符捕捉形状细节；2. 基于局部语义和形状信号自适应调整高斯分配；3. 使用跨场景知识转移模块加速收敛。

Result: 在多个数据集上实验表明，分割精度和渲染质量得到提升，同时保持高渲染帧率。

Conclusion: 该框架通过语义与渲染的协同增强，有效解决了现有方法的局限性，实现了更高效的3D语义建模。

Abstract: Recent works propose extending 3DGS with semantic feature vectors for simultaneous semantic segmentation and image rendering. However, these methods often treat the semantic and rendering branches separately, relying solely on 2D supervision while ignoring the 3D Gaussian geometry. Moreover, current adaptive strategies adapt the Gaussian set depending solely on rendering gradients, which can be insufficient in subtle or textureless regions. In this work, we propose a joint enhancement framework for 3D semantic Gaussian modeling that synergizes both semantic and rendering branches. Firstly, unlike conventional point cloud shape encoding, we introduce an anisotropic 3D Gaussian Chebyshev descriptor using the Laplace-Beltrami operator to capture fine-grained 3D shape details, thereby distinguishing objects with similar appearances and reducing reliance on potentially noisy 2D guidance. In addition, without relying solely on rendering gradient, we adaptively adjust Gaussian allocation and spherical harmonics with local semantic and shape signals, enhancing rendering efficiency through selective resource allocation. Finally, we employ a cross-scene knowledge transfer module to continuously update learned shape patterns, enabling faster convergence and robust representations without relearning shape information from scratch for each new scene. Experiments on multiple datasets demonstrate improvements in segmentation accuracy and rendering quality while maintaining high rendering frame rates.

</details>


### [172] [Talk2Move: Reinforcement Learning for Text-Instructed Object-Level Geometric Transformation in Scenes](https://arxiv.org/abs/2601.02356)
*Jing Tan,Zhaoyang Zhang,Yantao Shen,Jiarui Cai,Shuo Yang,Jiajun Wu,Wei Xia,Zhuowen Tu,Stefano Soatto*

Main category: cs.CV

TL;DR: Talk2Move是一个基于强化学习的扩散框架，用于通过文本指令实现场景中物体的空间变换。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本的编辑方法虽然可以调整外观或风格，但难以执行物体级别的几何变换（如平移、旋转、缩放），主要受限于稀缺的配对监督数据和像素级优化限制。

Method: 采用Group Relative Policy Optimization (GRPO)通过输入图像和轻量级文本变体生成多样化rollout来探索几何动作；使用空间奖励引导模型将几何变换与语言描述对齐；通过离策略步骤评估和主动步骤采样提高学习效率；设计物体中心的空间奖励直接评估位移、旋转和缩放行为。

Result: 在精选基准测试中，Talk2Move实现了精确、一致且语义忠实的目标变换，在空间准确性和场景一致性方面均优于现有文本引导编辑方法。

Conclusion: 该框架无需昂贵的配对数据即可实现可解释且连贯的几何变换，为文本指导的空间操作提供了有效解决方案。

Abstract: We introduce Talk2Move, a reinforcement learning (RL) based diffusion framework for text-instructed spatial transformation of objects within scenes. Spatially manipulating objects in a scene through natural language poses a challenge for multimodal generation systems. While existing text-based manipulation methods can adjust appearance or style, they struggle to perform object-level geometric transformations-such as translating, rotating, or resizing objects-due to scarce paired supervision and pixel-level optimization limits. Talk2Move employs Group Relative Policy Optimization (GRPO) to explore geometric actions through diverse rollouts generated from input images and lightweight textual variations, removing the need for costly paired data. A spatial reward guided model aligns geometric transformations with linguistic description, while off-policy step evaluation and active step sampling improve learning efficiency by focusing on informative transformation stages. Furthermore, we design object-centric spatial rewards that evaluate displacement, rotation, and scaling behaviors directly, enabling interpretable and coherent transformations. Experiments on curated benchmarks demonstrate that Talk2Move achieves precise, consistent, and semantically faithful object transformations, outperforming existing text-guided editing approaches in both spatial accuracy and scene coherence.

</details>


### [173] [VINO: A Unified Visual Generator with Interleaved OmniModal Context](https://arxiv.org/abs/2601.02358)
*Junyi Chen,Tong He,Zhoujie Fu,Pengfei Wan,Kun Gai,Weicai Ye*

Main category: cs.CV

TL;DR: VINO是一个统一的视觉生成器，在单一框架内完成图像和视频的生成与编辑，使用共享扩散主干网络处理多模态输入，避免了任务特定模型的需求。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法需要为每种模态（图像、视频）使用独立模型或模块的问题，实现更高效、统一的视觉内容创作。

Method: 将视觉语言模型与多模态扩散变换器耦合，多模态输入被编码为交错条件令牌来指导扩散过程，采用多阶段训练流程从视频生成基础模型扩展为统一多任务生成器。

Result: 在多样化的生成和编辑基准测试中，VINO展现出强大的视觉质量、准确的指令跟随、改进的参考和属性保持能力，以及更可控的多身份编辑。

Conclusion: VINO为可扩展的统一视觉生成提供了一条实用路径，展示了交错上下文计算作为通用视觉创作基础的潜力。

Abstract: We present VINO, a unified visual generator that performs image and video generation and editing within a single framework. Instead of relying on task-specific models or independent modules for each modality, VINO uses a shared diffusion backbone that conditions on text, images and videos, enabling a broad range of visual creation and editing tasks under one model. Specifically, VINO couples a vision-language model (VLM) with a Multimodal Diffusion Transformer (MMDiT), where multimodal inputs are encoded as interleaved conditioning tokens, and then used to guide the diffusion process. This design supports multi-reference grounding, long-form instruction following, and coherent identity preservation across static and dynamic content, while avoiding modality-specific architectural components. To train such a unified system, we introduce a multi-stage training pipeline that progressively expands a video generation base model into a unified, multi-task generator capable of both image and video input and output. Across diverse generation and editing benchmarks, VINO demonstrates strong visual quality, faithful instruction following, improved reference and attribute preservation, and more controllable multi-identity edits. Our results highlight a practical path toward scalable unified visual generation, and the promise of interleaved, in-context computation as a foundation for general-purpose visual creation.

</details>


### [174] [ExposeAnyone: Personalized Audio-to-Expression Diffusion Models Are Robust Zero-Shot Face Forgery Detectors](https://arxiv.org/abs/2601.02359)
*Kaede Shiohara,Toshihiko Yamasaki,Vladislav Golyanik*

Main category: cs.CV

TL;DR: ExposeAnyone是一种基于扩散模型的自监督方法，通过音频生成表情序列，利用扩散重建误差进行人脸伪造检测，在多个数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前深度伪造检测方法主要依赖监督训练，容易过拟合特定伪造模式，无法泛化到未知伪造技术。自监督方法具有更好的泛化潜力，但现有方法难以仅通过自监督学习到判别性表征。

Method: 提出完全自监督的ExposeAnyone方法：1）使用扩散模型从音频生成表情序列；2）通过参考集对特定主体进行个性化；3）通过扩散重建误差计算疑似视频与个性化主体的身份距离，实现重点人物人脸伪造检测。

Result: 1）在DF-TIMIT、DFDCP、KoDF和IDForge数据集上平均AUC比之前最优方法提高4.22个百分点；2）能够检测Sora2生成的视频，而之前方法表现不佳；3）对模糊和压缩等损坏具有高度鲁棒性。

Conclusion: ExposeAnyone展示了自监督方法在深度伪造检测中的强大潜力，特别是在泛化性和鲁棒性方面优于现有监督方法，适用于现实世界的人脸伪造检测场景。

Abstract: Detecting unknown deepfake manipulations remains one of the most challenging problems in face forgery detection. Current state-of-the-art approaches fail to generalize to unseen manipulations, as they primarily rely on supervised training with existing deepfakes or pseudo-fakes, which leads to overfitting to specific forgery patterns. In contrast, self-supervised methods offer greater potential for generalization, but existing work struggles to learn discriminative representations only from self-supervision. In this paper, we propose ExposeAnyone, a fully self-supervised approach based on a diffusion model that generates expression sequences from audio. The key idea is, once the model is personalized to specific subjects using reference sets, it can compute the identity distances between suspected videos and personalized subjects via diffusion reconstruction errors, enabling person-of-interest face forgery detection. Extensive experiments demonstrate that 1) our method outperforms the previous state-of-the-art method by 4.22 percentage points in the average AUC on DF-TIMIT, DFDCP, KoDF, and IDForge datasets, 2) our model is also capable of detecting Sora2-generated videos, where the previous approaches perform poorly, and 3) our method is highly robust to corruptions such as blur and compression, highlighting the applicability in real-world face forgery detection.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [175] [Value Vision-Language-Action Planning & Search](https://arxiv.org/abs/2601.00969)
*Ali Salamatian,Ke,Ren,Kieran Pattison,Cyrus Neary*

Main category: cs.RO

TL;DR: V-VLAPS框架通过为VLA模型添加轻量级可学习价值函数来增强MCTS搜索，在机器人操作任务中显著提升成功率并减少搜索成本


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型依赖行为克隆，在分布偏移下表现脆弱，而基于MCTS的测试时搜索仅依赖VLA先验，缺乏对未来回报的准确估计

Method: 在固定VLA骨干网络（Octo）的潜在表示上训练简单多层感知机作为价值函数，将其集成到MCTS搜索中提供显式成功信号

Result: 在LIBERO机器人操作套件上，价值引导搜索将成功率提升超过5个百分点，同时将平均MCTS模拟次数减少5-15%

Conclusion: V-VLAPS通过结合价值函数和MCTS搜索，有效解决了VLA模型在分布偏移下的脆弱性问题，实现了更高效可靠的机器人操作策略

Abstract: Vision-Language-Action (VLA) models have emerged as powerful generalist policies for robotic manipulation, yet they remain fundamentally limited by their reliance on behavior cloning, leading to brittleness under distribution shift. While augmenting pretrained models with test-time search algorithms like Monte Carlo Tree Search (MCTS) can mitigate these failures, existing formulations rely solely on the VLA prior for guidance, lacking a grounded estimate of expected future return. Consequently, when the prior is inaccurate, the planner can only correct action selection via the exploration term, which requires extensive simulation to become effective. To address this limitation, we introduce Value Vision-Language-Action Planning and Search (V-VLAPS), a framework that augments MCTS with a lightweight, learnable value function. By training a simple multilayer perceptron (MLP) on the latent representations of a fixed VLA backbone (Octo), we provide the search with an explicit success signal that biases action selection toward high-value regions. We evaluate V-VLAPS on the LIBERO robotic manipulation suite, demonstrating that our value-guided search improves success rates by over 5 percentage points while reducing the average number of MCTS simulations by 5-15 percent compared to baselines that rely only on the VLA prior.

</details>


### [176] [From Perception to Symbolic Task Planning: Vision-Language Guided Human-Robot Collaborative Structured Assembly](https://arxiv.org/abs/2601.00978)
*Yanyi Chen,Min Deng*

Main category: cs.RO

TL;DR: 本文提出了一个基于设计的人类感知规划框架，用于人机协作结构化装配，通过视觉语言模型和最小变更重规划规则提高状态估计和任务规划的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决结构化人机协作装配中噪声感知和人为干预下的可靠状态估计和自适应任务规划挑战。

Method: 框架包含两个耦合模块：PSS模块使用视觉语言模型将RGB-D观测与设计规范对齐，合成可验证的符号装配状态；HPR模块执行任务级多机器人分配，仅在观测状态偏离预期时进行最小变更重规划。

Result: 在27组件木框架装配上验证，PSS模块达到97%的状态合成准确率，HPR模块在不同HRC场景下保持可行的任务进展。

Conclusion: 将基于VLM的感知与知识驱动规划相结合，提高了动态条件下状态估计和任务规划的鲁棒性。

Abstract: Human-robot collaboration (HRC) in structured assembly requires reliable state estimation and adaptive task planning under noisy perception and human interventions. To address these challenges, we introduce a design-grounded human-aware planning framework for human-robot collaborative structured assembly. The framework comprises two coupled modules. Module I, Perception-to-Symbolic State (PSS), employs vision-language models (VLMs) based agents to align RGB-D observations with design specifications and domain knowledge, synthesizing verifiable symbolic assembly states. It outputs validated installed and uninstalled component sets for online state tracking. Module II, Human-Aware Planning and Replanning (HPR), performs task-level multi-robot assignment and updates the plan only when the observed state deviates from the expected execution outcome. It applies a minimal-change replanning rule to selectively revise task assignments and preserve plan stability even under human interventions. We validate the framework on a 27-component timber-frame assembly. The PSS module achieves 97% state synthesis accuracy, and the HPR module maintains feasible task progression across diverse HRC scenarios. Results indicate that integrating VLM-based perception with knowledge-driven planning improves robustness of state estimation and task planning under dynamic conditions.

</details>


### [177] [Simulations of MRI Guided and Powered Ferric Applicators for Tetherless Delivery of Therapeutic Interventions](https://arxiv.org/abs/2601.00981)
*Wenhui Chu,Khang Tran,Nikolaos V. Tsekos*

Main category: cs.RO

TL;DR: 本文提出了一种用于MRI引导血管内介入手术的计算平台，通过处理MRI数据生成血管虚拟走廊作为安全边界，并生成磁梯度波形来控制磁性器械的导航。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够在MRI环境下进行术前规划和实时建模的平台，用于机器人辅助的血管内介入手术，确保器械在血管内安全导航避免穿孔或碰撞。

Method: 采用双向数据管道连接MRI扫描仪、计算核心和操作者，通过多切片MRI数据处理提取血管床，拟合虚拟走廊作为虚拟夹具，结合血管几何特征和MRI安全参数生成磁梯度波形。

Result: 实现了基于Qt框架的实时操作平台，包含PID控制器、虚拟夹具生成和MRI梯度波形生成等模块，能够模拟不同血流条件下的器械导航安全性。

Conclusion: 该计算平台为MRI引导的血管内介入手术提供了有效的术前规划和实时建模工具，未来可支持实验研究的实时操作需求。

Abstract: Magnetic Resonance Imaging (MRI) is a well-established modality for pre-operative planning and is also explored for intra-operative guidance of procedures such as intravascular interventions. Among the experimental robot-assisted technologies, the magnetic field gradients of the MRI scanner are used to power and maneuver ferromagnetic applicators for accessing sites in the patient's body via the vascular network. In this work, we propose a computational platform for preoperative planning and modeling of MRI-powered applicators inside blood vessels. This platform was implemented as a two-way data and command pipeline that links the MRI scanner, the computational core, and the operator. The platform first processes multi-slice MR data to extract the vascular bed and then fits a virtual corridor inside the vessel. This corridor serves as a virtual fixture (VF), a forbidden region for the applicators to avoid vessel perforation or collision. The geometric features of the vessel centerline, the VF, and MRI safety compliance (dB/dt, max available gradient) are then used to generate magnetic field gradient waveforms. Different blood flow profiles can be user-selected, and those parameters are used for modeling the applicator's maneuvering. The modeling module further generates cues about whether the selected vascular path can be safely maneuvered. Given future experimental studies that require a real-time operation, the platform was implemented on the Qt framework (C/C++) with software modules performing specific tasks running on dedicated threads: PID controller, generation of VF, generation of MR gradient waveforms.

</details>


### [178] [Topological Mapping and Navigation using a Monocular Camera based on AnyLoc](https://arxiv.org/abs/2601.01067)
*Wenzheng Zhang,Yoshitaka Hara,Sousuke Nakamura*

Main category: cs.RO

TL;DR: 提出基于单目相机的拓扑建图和导航方法，使用关键帧描述子构建拓扑关系，实现轻量级的回环检测和视觉导航


<details>
  <summary>Details</summary>
Motivation: 传统度量地图需要精确坐标，计算复杂且资源消耗大。拓扑地图通过关键节点简化环境表示，更适合轻量级导航应用

Method: 基于AnyLoc框架，将关键帧转换为描述子构建拓扑关系，通过图像分割与目标节点图像比较确定导航动作，完全依赖单目相机

Result: 在真实和仿真环境中有效实现回环检测和导航，相比基于ResNet的方法平均成功率提升60.2%，同时降低时间和空间成本

Conclusion: 该方法提供了一种轻量级解决方案，无需预训练即可在各种场景下实现高效的机器人及人类导航

Abstract: This paper proposes a method for topological mapping and navigation using a monocular camera. Based on AnyLoc, keyframes are converted into descriptors to construct topological relationships, enabling loop detection and map building. Unlike metric maps, topological maps simplify path planning and navigation by representing environments with key nodes instead of precise coordinates. Actions for visual navigation are determined by comparing segmented images with the image associated with target nodes. The system relies solely on a monocular camera, ensuring fast map building and navigation using key nodes. Experiments show effective loop detection and navigation in real and simulation environments without pre-training. Compared to a ResNet-based method, this approach improves success rates by 60.2% on average while reducing time and space costs, offering a lightweight solution for robot and human navigation in various scenarios.

</details>


### [179] [Towards reliable subsea object recovery: a simulation study of an auv with a suction-actuated end effector](https://arxiv.org/abs/2601.01106)
*Michele Grimaldi,Yosaku Maeda,Hitoshi Kakami,Ignacio Carlucho,Yvan Petillot,Tomoya Inoue*

Main category: cs.RO

TL;DR: 本文提出了一种基于仿真的深海自主物体回收任务研究，使用Hadal小型潜水器和机械臂在模拟极端海沟环境下完成物体检测与回收。


<details>
  <summary>Details</summary>
Motivation: 深海海沟区域（hadal zone）的自主物体回收面临极端水压、能见度低、洋流干扰等挑战，实地实验成本高、风险大且车辆资源有限，难以进行早期自主行为验证。

Method: 使用Stonefish高保真仿真器模拟真实车辆动力学、水动力扰动和传感器特性，结合世界坐标系PID控制器进行车辆导航，以及基于逆运动学的机械臂控制器（含加速度前馈）实现协调操作。

Result: 仿真中HSV成功从海面自主下潜至6000米深度，完成海底覆盖搜索、目标检测和基于吸力的物体回收，验证了仿真在深海干预行为评估中的有效性。

Conclusion: 高保真仿真为深海自主干预任务提供了一种低成本、低风险的预验证手段，可显著降低实地部署的风险和成本。

Abstract: Autonomous object recovery in the hadal zone is challenging due to extreme hydrostatic pressure, limited visibility and currents, and the need for precise manipulation at full ocean depth. Field experimentation in such environments is costly, high-risk, and constrained by limited vehicle availability, making early validation of autonomous behaviors difficult. This paper presents a simulation-based study of a complete autonomous subsea object recovery mission using a Hadal Small Vehicle (HSV) equipped with a three-degree-of-freedom robotic arm and a suction-actuated end effector. The Stonefish simulator is used to model realistic vehicle dynamics, hydrodynamic disturbances, sensing, and interaction with a target object under hadal-like conditions. The control framework combines a world-frame PID controller for vehicle navigation and stabilization with an inverse-kinematics-based manipulator controller augmented by acceleration feed-forward, enabling coordinated vehicle - manipulator operation. In simulation, the HSV autonomously descends from the sea surface to 6,000 m, performs structured seafloor coverage, detects a target object, and executes a suction-based recovery. The results demonstrate that high-fidelity simulation provides an effective and low-risk means of evaluating autonomous deep-sea intervention behaviors prior to field deployment.

</details>


### [180] [Latent Space Reinforcement Learning for Multi-Robot Exploration](https://arxiv.org/abs/2601.01139)
*Sriram Rajasekar,Ashwini Ratnoo*

Main category: cs.RO

TL;DR: 该论文提出了一种基于自动编码器和分层深度强化学习的多智能体自主映射系统，通过维度压缩和复杂环境生成解决了现有方法在连续环境中的扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体系统中运动规划算法的可扩展性限制，特别是在时间受限的未知环境映射场景中。现有强化学习方法因输入尺寸限制而仅限于离散环境。

Method: 使用自动编码器对高保真占据地图进行维度压缩，保留关键空间信息；基于Perlin噪声的程序生成算法创建复杂训练环境；采用分层深度强化学习框架实现分散协调；引入带可调信任参数的加权共识机制。

Result: 实验结果表明，该系统能够有效随智能体数量扩展，在结构不同的陌生环境中具有良好的泛化能力，在通信受限环境下表现出鲁棒性。

Conclusion: 所提出的方法成功解决了多智能体自主映射中的可扩展性和连续性环境适应问题，为复杂环境下的协作导航提供了有效解决方案。

Abstract: Autonomous mapping of unknown environments is a critical challenge, particularly in scenarios where time is limited. Multi-agent systems can enhance efficiency through collaboration, but the scalability of motion-planning algorithms remains a key limitation. Reinforcement learning has been explored as a solution, but existing approaches are constrained by the limited input size required for effective learning, restricting their applicability to discrete environments. This work addresses that limitation by leveraging autoencoders to perform dimensionality reduction, compressing high-fidelity occupancy maps into latent state vectors while preserving essential spatial information. Additionally, we introduce a novel procedural generation algorithm based on Perlin noise, designed to generate topologically complex training environments that simulate asteroid fields, caves and forests. These environments are used for training the autoencoder and the navigation algorithm using a hierarchical deep reinforcement learning framework for decentralized coordination. We introduce a weighted consensus mechanism that modulates reliance on shared data via a tuneable trust parameter, ensuring robustness to accumulation of errors. Experimental results demonstrate that the proposed system scales effectively with number of agents and generalizes well to unfamiliar, structurally distinct environments and is resilient in communication-constrained settings.

</details>


### [181] [VISO: Robust Underwater Visual-Inertial-Sonar SLAM with Photometric Rendering for Dense 3D Reconstruction](https://arxiv.org/abs/2601.01144)
*Shu Pan,Simon Archieri,Ahmet Cinar,Jonatan Scharff Willners,Ignacio Carlucho,Yvan Petillot*

Main category: cs.RO

TL;DR: VISO是一种鲁棒的水下SLAM系统，融合立体相机、IMU和3D声纳，实现精确的6自由度定位和高效的高保真密集3D重建。


<details>
  <summary>Details</summary>
Motivation: 水下环境的视觉挑战严重影响了基于视觉的定位精度和高保真密集重建的质量。

Method: 提出粗到细的在线校准方法用于3D声纳和相机之间的外参估计，并引入3D声纳点云的光度渲染策略来丰富声纳地图的视觉信息。

Result: 在实验室水箱和开放湖泊的广泛实验表明，VISO在定位鲁棒性和准确性方面优于当前最先进的水下和视觉SLAM算法，同时展现出与离线密集建图方法相媲美的实时密集3D重建性能。

Conclusion: VISO系统通过多传感器融合和创新的校准与渲染策略，有效解决了水下SLAM的挑战，实现了高精度的定位和高质量的重建。

Abstract: Visual challenges in underwater environments significantly hinder the accuracy of vision-based localisation and the high-fidelity dense reconstruction. In this paper, we propose VISO, a robust underwater SLAM system that fuses a stereo camera, an inertial measurement unit (IMU), and a 3D sonar to achieve accurate 6-DoF localisation and enable efficient dense 3D reconstruction with high photometric fidelity. We introduce a coarse-to-fine online calibration approach for extrinsic parameters estimation between the 3D sonar and the camera. Additionally, a photometric rendering strategy is proposed for the 3D sonar point cloud to enrich the sonar map with visual information. Extensive experiments in a laboratory tank and an open lake demonstrate that VISO surpasses current state-of-the-art underwater and visual-based SLAM algorithms in terms of localisation robustness and accuracy, while also exhibiting real-time dense 3D reconstruction performance comparable to the offline dense mapping method.

</details>


### [182] [ORION: Option-Regularized Deep Reinforcement Learning for Cooperative Multi-Agent Online Navigation](https://arxiv.org/abs/2601.01155)
*Zhang Shizhe,Liang Jingsong,Zhou Zhitao,Ye Shuhan,Wang Yizhuo,Tan Ming Siang Derek,Chiun Jimmy,Cao Yuhong,Sartoretti Guillaume*

Main category: cs.RO

TL;DR: ORION是一个基于深度强化学习的多智能体在线导航框架，用于部分已知环境中的协作导航，通过结合先验地图和在线感知实现去中心化决策和主动地图不确定性降低。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常假设环境完全已知，无法有效支持仓库、工厂等部分已知场景中的多智能体导航需求，需要智能体在路径优化和环境信息收集共享之间取得平衡。

Method: ORION采用共享图编码器融合先验地图和在线感知，使用选项-批评家框架学习高层协作模式，并引入双阶段协作策略帮助队友降低地图不确定性。

Result: 在迷宫类地图和大规模仓库环境中的仿真结果表明，ORION在不同团队规模下实现了高质量的实时去中心化协作，优于现有的经典和基于学习的方法。

Conclusion: ORION在物理机器人团队上的验证证明了其鲁棒性和实际应用价值，为现实世界中的协作导航提供了实用解决方案。

Abstract: Existing methods for multi-agent navigation typically assume fully known environments, offering limited support for partially known scenarios such as warehouses or factory floors. There, agents may need to plan trajectories that balance their own path optimality with their ability to collect and share information about the environment that can help their teammates reach their own goals. To these ends, we propose ORION, a novel deep reinforcement learning framework for cooperative multi-agent online navigation in partially known environments. Starting from an imperfect prior map, ORION trains agents to make decentralized decisions, coordinate to reach their individual targets, and actively reduce map uncertainty by sharing online observations in a closed perception-action loop. We first design a shared graph encoder that fuses prior map with online perception into a unified representation, providing robust state embeddings under dynamic map discrepancies. At the core of ORION is an option-critic framework that learns to reason about a set of high-level cooperative modes that translate into sequences of low-level actions, allowing agents to switch between individual navigation and team-level exploration adaptively. We further introduce a dual-stage cooperation strategy that enables agents to assist teammates under map uncertainty, thereby reducing the overall makespan. Across extensive maze-like maps and large-scale warehouse environments, our simulation results show that ORION achieves high-quality, real-time decentralized cooperation over varying team sizes, outperforming state-of-the-art classical and learning-based baselines. Finally, we validate ORION on physical robot teams, demonstrating its robustness and practicality for real-world cooperative navigation.

</details>


### [183] [DST-Calib: A Dual-Path, Self-Supervised, Target-Free LiDAR-Camera Extrinsic Calibration Network](https://arxiv.org/abs/2601.01188)
*Zhiwei Huang,Yanwei Fu,Yi Zhou,Xieyuanli Chen,Qijun Chen,Rui Fan*

Main category: cs.RO

TL;DR: 提出首个自监督的LiDAR-相机外参标定网络，无需特定标定目标，支持在线自适应标定，通过双面数据增强和差异图构建显著提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有LiDAR-相机外参标定方法依赖手工标定目标或特定静态场景，限制了在真实自主机器人应用中的适应性和部署能力。

Method: 提出双面数据增强技术生成多视角相机视图，设计双路径自监督标定框架，采用差异图构建替代传统双分支特征提取，增强跨模态特征关联。

Result: 在五个公共基准数据集和自录数据集上的实验表明，该方法在泛化性方面显著优于现有方法。

Conclusion: 该方法解决了现有方法的泛化退化问题，实现了无需标定目标的在线自适应标定，提高了标定精度并降低了模型复杂度。

Abstract: LiDAR-camera extrinsic calibration is essential for multi-modal data fusion in robotic perception systems. However, existing approaches typically rely on handcrafted calibration targets (e.g., checkerboards) or specific, static scene types, limiting their adaptability and deployment in real-world autonomous and robotic applications. This article presents the first self-supervised LiDAR-camera extrinsic calibration network that operates in an online fashion and eliminates the need for specific calibration targets. We first identify a significant generalization degradation problem in prior methods, caused by the conventional single-sided data augmentation strategy. To overcome this limitation, we propose a novel double-sided data augmentation technique that generates multi-perspective camera views using estimated depth maps, thereby enhancing robustness and diversity during training. Built upon this augmentation strategy, we design a dual-path, self-supervised calibration framework that reduces the dependence on high-precision ground truth labels and supports fully adaptive online calibration. Furthermore, to improve cross-modal feature association, we replace the traditional dual-branch feature extraction design with a difference map construction process that explicitly correlates LiDAR and camera features. This not only enhances calibration accuracy but also reduces model complexity. Extensive experiments conducted on five public benchmark datasets, as well as our own recorded dataset, demonstrate that the proposed method significantly outperforms existing approaches in terms of generalizability.

</details>


### [184] [EduSim-LLM: An Educational Platform Integrating Large Language Models and Robotic Simulation for Beginners](https://arxiv.org/abs/2601.01196)
*Shenqi Lu,Liangwei Zhang*

Main category: cs.RO

TL;DR: EduSim-LLM是一个教育平台，将大语言模型与机器人仿真结合，构建语言驱动控制模型，将自然语言指令转换为可执行的机器人行为序列。


<details>
  <summary>Details</summary>
Motivation: 解决自然语言理解与机器人控制集成的挑战，实现直观的人类对复杂机器人系统的控制，提升教育和实践的可及性。

Method: 设计两种人机交互模型（直接控制和自主控制），在CoppeliaSim中进行系统仿真，基于多种语言模型评估多机器人协作、运动规划和操作能力。

Result: LLMs能够可靠地将自然语言转换为结构化机器人动作；应用提示工程模板后指令解析准确率显著提高；在最高复杂度测试中整体准确率超过88.9%。

Conclusion: 该平台证明了LLMs在机器人控制中的有效性，为教育领域提供了直观的人机交互解决方案。

Abstract: In recent years, the rapid development of Large Language Models (LLMs) has significantly enhanced natural language understanding and human-computer interaction, creating new opportunities in the field of robotics. However, the integration of natural language understanding into robotic control is an important challenge in the rapid development of human-robot interaction and intelligent automation industries. This challenge hinders intuitive human control over complex robotic systems, limiting their educational and practical accessibility. To address this, we present the EduSim-LLM, an educational platform that integrates LLMs with robot simulation and constructs a language-drive control model that translates natural language instructions into executable robot behavior sequences in CoppeliaSim. We design two human-robot interaction models: direct control and autonomous control, conduct systematic simulations based on multiple language models, and evaluate multi-robot collaboration, motion planning, and manipulation capabilities. Experiential results show that LLMs can reliably convert natural language into structured robot actions; after applying prompt-engineering templates instruction-parsing accuracy improves significantly; as task complexity increases, overall accuracy rate exceeds 88.9% in the highest complexity tests.

</details>


### [185] [SAHA: Supervised Autonomous HArvester for selective forest thinning](https://arxiv.org/abs/2601.01282)
*Fang Nan,Meher Malladi,Qingqing Li,Fan Yang,Joonas Juola,Tiziano Guadagnino,Jens Behley,Cesar Cadena,Cyrill Stachniss,Marco Hutter*

Main category: cs.RO

TL;DR: 本文提出了一种基于小型机器人采伐机（SAHA）的解决方案，用于在监督自主模式下执行森林选择性疏伐任务。


<details>
  <summary>Details</summary>
Motivation: 森林管理需要劳动密集且复杂的操作，选择性疏伐对于维持森林健康和生产至关重要，但需要熟练的操作人员。机器人技术可以解决这一挑战。

Method: 在4.5吨采伐机平台上进行硬件改造，实现感知和自动控制。采用学习和模型相结合的方法控制液压执行器，通过杂乱环境精确导航，进行鲁棒状态估计和地形可通行性语义估计。

Result: 在北欧森林进行了长达数公里的自主任务实地试验，证明采伐机能够在真实森林环境中自主导航并到达目标树木进行选择性疏伐。

Conclusion: 分析了性能并总结了推进机器人森林管理的经验教训，展示了机器人技术在森林管理中的应用潜力。

Abstract: Forestry plays a vital role in our society, creating significant ecological, economic, and recreational value. Efficient forest management involves labor-intensive and complex operations. One essential task for maintaining forest health and productivity is selective thinning, which requires skilled operators to remove specific trees to create optimal growing conditions for the remaining ones. In this work, we present a solution based on a small-scale robotic harvester (SAHA) designed for executing this task with supervised autonomy. We build on a 4.5-ton harvester platform and implement key hardware modifications for perception and automatic control. We implement learning- and model-based approaches for precise control of hydraulic actuators, accurate navigation through cluttered environments, robust state estimation, and reliable semantic estimation of terrain traversability. Integrating state-of-the-art techniques in perception, planning, and control, our robotic harvester can autonomously navigate forest environments and reach targeted trees for selective thinning. We present experimental results from extensive field trials over kilometer-long autonomous missions in northern European forests, demonstrating the harvester's ability to operate in real forests. We analyze the performance and provide the lessons learned for advancing robotic forest management.

</details>


### [186] [Online Estimation and Manipulation of Articulated Objects](https://arxiv.org/abs/2601.01438)
*Russell Buchanan,Adrian Röfer,João Moura,Abhinav Valada,Sethu Vijayakumar*

Main category: cs.RO

TL;DR: 提出了一种结合视觉先验和本体感知的在线关节估计算法，用于机器人自主操作未知关节物体


<details>
  <summary>Details</summary>
Motivation: 服务机器人需要能够操作任意关节物体来完成家庭任务，但目前方法要么依赖视觉先验要么需要先能操作物体，存在局限性

Method: 使用因子图融合基于Screw Theory的分析模型、学习视觉先验和本体感知信息，实现关节的在线估计

Result: 在仿真和真实机器人实验中，机器人能够自主打开未见过的抽屉，真实硬件实验成功率达到75%

Conclusion: 该方法通过融合视觉和本体感知信息，使机器人能够有效操作未知关节物体，为家庭服务机器人提供了实用解决方案

Abstract: From refrigerators to kitchen drawers, humans interact with articulated objects effortlessly every day while completing household chores. For automating these tasks, service robots must be capable of manipulating arbitrary articulated objects. Recent deep learning methods have been shown to predict valuable priors on the affordance of articulated objects from vision. In contrast, many other works estimate object articulations by observing the articulation motion, but this requires the robot to already be capable of manipulating the object. In this article, we propose a novel approach combining these methods by using a factor graph for online estimation of articulation which fuses learned visual priors and proprioceptive sensing during interaction into an analytical model of articulation based on Screw Theory. With our method, a robotic system makes an initial prediction of articulation from vision before touching the object, and then quickly updates the estimate from kinematic and force sensing during manipulation. We evaluate our method extensively in both simulations and real-world robotic manipulation experiments. We demonstrate several closed-loop estimation and manipulation experiments in which the robot was capable of opening previously unseen drawers. In real hardware experiments, the robot achieved a 75% success rate for autonomous opening of unknown articulated objects.

</details>


### [187] [AIMS: An Adaptive Integration of Multi-Sensor Measurements for Quadrupedal Robot Localization](https://arxiv.org/abs/2601.01561)
*Yujian Qiu,Yuqiu Mu,Wen Yang,Hao Zhu*

Main category: cs.RO

TL;DR: 该论文提出了一种自适应LiDAR-IMU-腿式里程计融合方法AIMS，用于解决四足机器人在狭窄隧道环境中由于几何约束弱而导致的定位精度下降问题。


<details>
  <summary>Details</summary>
Motivation: 四足机器人在长而均匀的隧道环境中运行时，LiDAR测量提供的几何约束较弱，传统传感器融合方法容易积累运动估计误差，导致定位不准确。

Method: 在误差状态卡尔曼滤波框架下，将LiDAR和腿式里程计测量与IMU状态预测相结合，并基于在线退化感知可靠性评估自适应调整测量噪声协方差矩阵。

Result: 在狭窄走廊环境中的实验结果表明，与现有先进方法相比，所提方法显著提高了定位精度和鲁棒性。

Conclusion: AIMS方法通过自适应噪声调整机制，有效解决了退化环境下的定位问题，为四足机器人在复杂场景中的可靠运行提供了技术支撑。

Abstract: This paper addresses the problem of accurate localization for quadrupedal robots operating in narrow tunnel-like environments. Due to the long and homogeneous characteristics of such scenarios, LiDAR measurements often provide weak geometric constraints, making traditional sensor fusion methods susceptible to accumulated motion estimation errors. To address these challenges, we propose AIMS, an adaptive LiDAR-IMU-leg odometry fusion method for robust quadrupedal robot localization in degenerate environments. The proposed method is formulated within an error-state Kalman filtering framework, where LiDAR and leg odometry measurements are integrated with IMU-based state prediction, and measurement noise covariance matrices are adaptively adjusted based on online degeneracy-aware reliability assessment. Experimental results obtained in narrow corridor environments demonstrate that the proposed method improves localization accuracy and robustness compared with state-of-the-art approaches.

</details>


### [188] [HanoiWorld : A Joint Embedding Predictive Architecture BasedWorld Model for Autonomous Vehicle Controller](https://arxiv.org/abs/2601.01577)
*Tran Tien Dat,Nguyen Hai An,Nguyen Khanh Viet Dung,Nguyen Duy Duc*

Main category: cs.RO

TL;DR: 本文提出Hanoi-World，一种基于JEPA的世界模型，使用RNN进行长期规划，在自动驾驶控制中实现安全意识和高效推理


<details>
  <summary>Details</summary>
Motivation: 当前强化学习方法在自动驾驶控制器中数据需求高、性能不稳定、缺乏安全概念，且因像素重建而过度关注噪声特征。JEPA方法模仿人脑通过想象和少量观察学习新技能的能力，是有效替代方案

Method: 基于联合嵌入预测架构(JEPA)构建Hanoi-World世界模型，使用循环神经网络(RNN)进行长期水平规划，在Highway-Env环境中进行实验

Result: 在不同环境中展示了制定驾驶计划的有效能力，具有安全意识，与SOTA基线相比碰撞率显著降低

Conclusion: JEPA-based世界模型在自动驾驶控制中表现出优越的性能，特别是在安全性和样本效率方面

Abstract: Current attempts of Reinforcement Learning for Autonomous Controller are data-demanding while the results are under-performed, unstable, and unable to grasp and anchor on the concept of safety, and over-concentrating on noise features due to the nature of pixel reconstruction. While current Self-Supervised Learningapproachs that learning on high-dimensional representations by leveraging the JointEmbedding Predictive Architecture (JEPA) are interesting and an effective alternative, as the idea mimics the natural ability of the human brain in acquiring new skill usingimagination and minimal samples of observations. This study introduces Hanoi-World, a JEPA-based world model that using recurrent neural network (RNN) formaking longterm horizontal planning with effective inference time. Experimentsconducted on the Highway-Env package with difference enviroment showcase the effective capability of making a driving plan while safety-awareness, with considerablecollision rate in comparison with SOTA baselines

</details>


### [189] [Action-Sketcher: From Reasoning to Action via Visual Sketches for Long-Horizon Robotic Manipulation](https://arxiv.org/abs/2601.01618)
*Huajie Tan,Peterson Co,Yijie Xu,Shanyu Rong,Yuheng Ji,Cheng Chi,Xiansheng Chen,Qiongyu Zhang,Zhongxia Zhao,Pengwei Wang,Zhongyuan Wang,Shanghang Zhang*

Main category: cs.RO

TL;DR: Action-Sketcher是一个视觉语言动作框架，通过视觉草图中间表示来增强机器人长时程操作的空间推理和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决现有VLA策略在复杂场景中依赖纯文本提示导致空间参照模糊、任务分解困难以及动作选择缺乏可解释性的问题。

Method: 引入视觉草图作为空间意图的外部化表示，采用See-Think-Sketch-Act循环工作流，结合多阶段课程学习训练方法。

Result: 在杂乱场景和多对象任务中显著提升了长时程操作成功率、对动态场景变化的鲁棒性以及可解释性。

Conclusion: Action-Sketcher框架通过视觉草图中间表示有效解决了长时程机器人操作中的空间推理和可解释性问题。

Abstract: Long-horizon robotic manipulation is increasingly important for real-world deployment, requiring spatial disambiguation in complex layouts and temporal resilience under dynamic interaction. However, existing end-to-end and hierarchical Vision-Language-Action (VLA) policies often rely on text-only cues while keeping plan intent latent, which undermines referential grounding in cluttered or underspecified scenes, impedes effective task decomposition of long-horizon goals with close-loop interaction, and limits causal explanation by obscuring the rationale behind action choices. To address these issues, we first introduce Visual Sketch, an implausible visual intermediate that renders points, boxes, arrows, and typed relations in the robot's current views to externalize spatial intent, connect language to scene geometry. Building on Visual Sketch, we present Action-Sketcher, a VLA framework that operates in a cyclic See-Think-Sketch-Act workflow coordinated by adaptive token-gated strategy for reasoning triggers, sketch revision, and action issuance, thereby supporting reactive corrections and human interaction while preserving real-time action prediction. To enable scalable training and evaluation, we curate diverse corpus with interleaved images, text, Visual Sketch supervision, and action sequences, and train Action-Sketcher with a multi-stage curriculum recipe that combines interleaved sequence alignment for modality unification, language-to-sketch consistency for precise linguistic grounding, and imitation learning augmented with sketch-to-action reinforcement for robustness. Extensive experiments on cluttered scenes and multi-object tasks, in simulation and on real-world tasks, show improved long-horizon success, stronger robustness to dynamic scene changes, and enhanced interpretability via editable sketches and step-wise plans. Project website: https://action-sketcher.github.io

</details>


### [190] [DemoBot: Efficient Learning of Bimanual Manipulation with Dexterous Hands From Third-Person Human Videos](https://arxiv.org/abs/2601.01651)
*Yucheng Xu,Xiaofeng Mao,Elle Miller,Xinyu Yi,Yang Li,Zhibin Li,Robert B. Fisher*

Main category: cs.RO

TL;DR: DemoBot是一个从单目RGB-D视频学习复杂操作技能的双臂多指机器人框架，通过提取运动轨迹作为强化学习先验，结合时序分割RL、成功门控重置和事件驱动奖励课程等方法，实现长时程双手装配任务。


<details>
  <summary>Details</summary>
Motivation: 解决从人类演示视频直接学习复杂操作技能的挑战，避免从零开始学习，提高机器人技能获取的效率和可扩展性。

Method: 1. 从原始RGB-D视频提取双手和物体的结构化运动轨迹作为运动先验；2. 使用时序分割RL确保状态与演示的时间对齐；3. 采用成功门控重置策略平衡技能精炼和后续阶段探索；4. 设计事件驱动奖励课程指导高精度操作学习。

Result: 框架成功实现了长时程同步和异步双手装配任务，验证了从人类视频直接获取技能的有效性。

Conclusion: DemoBot提供了一种可扩展的方法，能够直接从人类演示视频中获取复杂操作技能，为机器人技能学习开辟了新途径。

Abstract: This work presents DemoBot, a learning framework that enables a dual-arm, multi-finger robotic system to acquire complex manipulation skills from a single unannotated RGB-D video demonstration. The method extracts structured motion trajectories of both hands and objects from raw video data. These trajectories serve as motion priors for a novel reinforcement learning (RL) pipeline that learns to refine them through contact-rich interactions, thereby eliminating the need to learn from scratch. To address the challenge of learning long-horizon manipulation skills, we introduce: (1) Temporal-segment based RL to enforce temporal alignment of the current state with demonstrations; (2) Success-Gated Reset strategy to balance the refinement of readily acquired skills and the exploration of subsequent task stages; and (3) Event-Driven Reward curriculum with adaptive thresholding to guide the RL learning of high-precision manipulation. The novel video processing and RL framework successfully achieved long-horizon synchronous and asynchronous bimanual assembly tasks, offering a scalable approach for direct skill acquisition from human videos.

</details>


### [191] [VisuoTactile 6D Pose Estimation of an In-Hand Object using Vision and Tactile Sensor Data](https://arxiv.org/abs/2601.01675)
*Snehal s. Dikhale,Karankumar Patel,Daksh Dhingra,Itoshi Naramura,Akinobu Hayashi,Soshi Iba,Nawid Jamali*

Main category: cs.RO

TL;DR: 提出了一种结合触觉和视觉数据来估计机器人手中物体6D姿态的方法，使用点云表示触觉数据并通过像素级密集融合网络进行传感器融合。


<details>
  <summary>Details</summary>
Motivation: 解决仅依赖视觉数据时因机器人夹爪遮挡导致的6D姿态估计困难问题，利用触觉传感器补充视觉信息。

Method: 使用点云表示与触觉传感器接触的物体表面，提出基于像素级密集融合的网络架构，扩展NVIDIA深度学习数据集合成器生成合成数据。

Result: 实验表明结合触觉数据能改善6D姿态估计精度，网络能够从合成训练成功泛化到真实机器人场景。

Conclusion: 多模态传感器融合方法有效提升了在复杂遮挡情况下的6D物体姿态估计性能。

Abstract: Knowledge of the 6D pose of an object can benefit in-hand object manipulation. In-hand 6D object pose estimation is challenging because of heavy occlusion produced by the robot's grippers, which can have an adverse effect on methods that rely on vision data only. Many robots are equipped with tactile sensors at their fingertips that could be used to complement vision data. In this paper, we present a method that uses both tactile and vision data to estimate the pose of an object grasped in a robot's hand. To address challenges like lack of standard representation for tactile data and sensor fusion, we propose the use of point clouds to represent object surfaces in contact with the tactile sensor and present a network architecture based on pixel-wise dense fusion. We also extend NVIDIA's Deep Learning Dataset Synthesizer to produce synthetic photo-realistic vision data and corresponding tactile point clouds. Results suggest that using tactile data in addition to vision data improves the 6D pose estimate, and our network generalizes successfully from synthetic training to real physical robots.

</details>


### [192] [Explicit World Models for Reliable Human-Robot Collaboration](https://arxiv.org/abs/2601.01705)
*Kenneth Kwok,Basura Fernando,Qianli Xu,Vigneshwaran Subbaraju,Dongkyu Choi,Boon Kiat Quek*

Main category: cs.RO

TL;DR: 本文提出了一种不同于传统形式化验证方法的可靠具身AI实现路径，强调通过构建可访问的显式世界模型来对齐人类期望与机器人行为。


<details>
  <summary>Details</summary>
Motivation: 传统方法追求模型可预测性和鲁棒性，但忽视了人机交互中动态、模糊和主观的特性。本文认为在人类环境中，可靠性应基于交互情境和人类期望来定义。

Method: 提出构建和更新可访问的显式世界模型，该模型代表人机之间的共同认知基础，用于使机器人行为与人类期望保持一致。

Result: 论证了在社交性、多模态和流动的人类环境中，可靠性需要以情境化的方式实现，而非通过形式化验证。

Conclusion: 实现可靠具身AI需要根本性转变，从追求模型可预测性转向建立以人类期望为中心的可访问世界模型。

Abstract: This paper addresses the topic of robustness under sensing noise, ambiguous instructions, and human-robot interaction. We take a radically different tack to the issue of reliable embodied AI: instead of focusing on formal verification methods aimed at achieving model predictability and robustness, we emphasise the dynamic, ambiguous and subjective nature of human-robot interactions that requires embodied AI systems to perceive, interpret, and respond to human intentions in a manner that is consistent, comprehensible and aligned with human expectations. We argue that when embodied agents operate in human environments that are inherently social, multimodal, and fluid, reliability is contextually determined and only has meaning in relation to the goals and expectations of humans involved in the interaction. This calls for a fundamentally different approach to achieving reliable embodied AI that is centred on building and updating an accessible "explicit world model" representing the common ground between human and AI, that is used to align robot behaviours with human expectations.

</details>


### [193] [Simulations and Advancements in MRI-Guided Power-Driven Ferric Tools for Wireless Therapeutic Interventions](https://arxiv.org/abs/2601.01726)
*Wenhui Chu,Aobo Jin,Hardik A. Gohel*

Main category: cs.RO

TL;DR: 本文开发了一个用于MRI扫描仪内机器人辅助血管内介入的集成计算系统，能够处理MR图像、建立血管路径和边界，并通过定制磁场梯度模式控制设备导航，提高手术精度和安全性。


<details>
  <summary>Details</summary>
Motivation: 解决MRI扫描仪强磁场环境下机器人系统的精度和稳定性问题，增强MRI在血管内介入手术中的引导作用，提高手术的安全性和精确性。

Method: 开发基于Qt框架和C/C++的集成计算系统，包括计算单元和用户界面，处理MR图像以识别血管网络，建立虚拟路径和边界，并生成定制磁场梯度模式来控制设备导航。

Result: 系统能够根据血管几何形状和安全规范生成定制磁场梯度模式，适应不同血流特性进行精细导航，并通过建模评估预设血管路径的安全性和可行性。

Conclusion: 该系统代表了成像技术与机器人辅助技术融合的重要进展，显著提高了血管内手术的精度和安全性。

Abstract: Designing a robotic system that functions effectively within the specific environment of a Magnetic Resonance Imaging (MRI) scanner requires solving numerous technical issues, such as maintaining the robot's precision and stability under strong magnetic fields. This research focuses on enhancing MRI's role in medical imaging, especially in its application to guide intravascular interventions using robot-assisted devices. A newly developed computational system is introduced, designed for seamless integration with the MRI scanner, including a computational unit and user interface. This system processes MR images to delineate the vascular network, establishing virtual paths and boundaries within vessels to prevent procedural damage. Key findings reveal the system's capability to create tailored magnetic field gradient patterns for device control, considering the vessel's geometry and safety norms, and adapting to different blood flow characteristics for finer navigation. Additionally, the system's modeling aspect assesses the safety and feasibility of navigating pre-set vascular paths. Conclusively, this system, based on the Qt framework and C/C++, with specialized software modules, represents a major step forward in merging imaging technology with robotic aid, significantly enhancing precision and safety in intravascular procedures.

</details>


### [194] [AlignDrive: Aligned Lateral-Longitudinal Planning for End-to-End Autonomous Driving](https://arxiv.org/abs/2601.01762)
*Yanhao Wu,Haoyang Zhang,Fei He,Rui Wu,Congpei Qiu,Liang Gao,Wei Ke,Tong Zhang*

Main category: cs.RO

TL;DR: 提出了一种新型级联框架，通过将纵向规划显式地建立在行驶路径上，解决了端到端自动驾驶中横向和纵向规划协调失败的问题，并在Bench2Drive基准测试中取得了新的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的端到端自动驾驶模型在规划阶段将横向和纵向预测解耦为并行任务，这会导致：1）规划的路径和速度之间协调失败；2）未充分利用行驶路径作为纵向规划的先验信息，从而冗余编码静态信息。

Method: 1. 提出路径条件化公式，将行驶路径显式纳入纵向规划；2. 模型沿行驶路径预测纵向位移而非完整的2D轨迹点；3. 引入面向规划的数据增强策略，模拟罕见安全关键事件（如车辆切入）。

Result: 在Bench2Drive基准测试中，该方法取得了驾驶分数89.07和成功率73.18%的新SOTA性能，显著提高了协调性和安全性。

Conclusion: 提出的级联框架通过将纵向规划建立在行驶路径上，实现了更好的横向和纵向规划协调，简化了纵向推理，并提高了整体安全性。

Abstract: End-to-end autonomous driving has rapidly progressed, enabling joint perception and planning in complex environments. In the planning stage, state-of-the-art (SOTA) end-to-end autonomous driving models decouple planning into parallel lateral and longitudinal predictions. While effective, this parallel design can lead to i) coordination failures between the planned path and speed, and ii) underutilization of the drive path as a prior for longitudinal planning, thus redundantly encoding static information. To address this, we propose a novel cascaded framework that explicitly conditions longitudinal planning on the drive path, enabling coordinated and collision-aware lateral and longitudinal planning. Specifically, we introduce a path-conditioned formulation that explicitly incorporates the drive path into longitudinal planning. Building on this, the model predicts longitudinal displacements along the drive path rather than full 2D trajectory waypoints. This design simplifies longitudinal reasoning and more tightly couples it with lateral planning. Additionally, we introduce a planning-oriented data augmentation strategy that simulates rare safety-critical events, such as vehicle cut-ins, by adding agents and relabeling longitudinal targets to avoid collision. Evaluated on the challenging Bench2Drive benchmark, our method sets a new SOTA, achieving a driving score of 89.07 and a success rate of 73.18%, demonstrating significantly improved coordination and safety

</details>


### [195] [DisCo-FLoc: Using Dual-Level Visual-Geometric Contrasts to Disambiguate Depth-Aware Visual Floorplan Localization](https://arxiv.org/abs/2601.01822)
*Shiyong Meng,Tao Zou,Bolei Chen,Chaoxu Mu,Jianxin Wang*

Main category: cs.RO

TL;DR: DisCo-FLoc通过双层次视觉-几何对比方法解决简约平面图中重复结构导致的定位模糊问题，无需额外语义标注即可实现深度感知的视觉平面图定位


<details>
  <summary>Details</summary>
Motivation: 现有平面图定位方法在简约平面图中因重复结构导致定位模糊，且依赖昂贵的语义标注限制了应用范围

Method: 提出射线回归预测器生成定位候选，结合位置级和方向级约束的对比学习方法，将深度感知视觉特征与几何结构严格匹配

Result: 在两个标准视觉平面图定位基准测试中，该方法优于当前最先进的基于语义的方法，在鲁棒性和准确性方面均有显著提升

Conclusion: DisCo-FLoc通过无监督的视觉-几何对比学习有效解决了平面图定位中的模糊问题，展示了无需语义标注的优越性能

Abstract: Since floorplan data is readily available, long-term persistent, and robust to changes in visual appearance, visual Floorplan Localization (FLoc) has garnered significant attention. Existing methods either ingeniously match geometric priors or utilize sparse semantics to reduce FLoc uncertainty. However, they still suffer from ambiguous FLoc caused by repetitive structures within minimalist floorplans. Moreover, expensive but limited semantic annotations restrict their applicability. To address these issues, we propose DisCo-FLoc, which utilizes dual-level visual-geometric Contrasts to Disambiguate depth-aware visual Floc, without requiring additional semantic labels. Our solution begins with a ray regression predictor tailored for ray-casting-based FLoc, predicting a series of FLoc candidates using depth estimation expertise. In addition, a novel contrastive learning method with position-level and orientation-level constraints is proposed to strictly match depth-aware visual features with the corresponding geometric structures in the floorplan. Such matches can effectively eliminate FLoc ambiguity and select the optimal imaging pose from FLoc candidates. Exhaustive comparative studies on two standard visual Floc benchmarks demonstrate that our method outperforms the state-of-the-art semantic-based method, achieving significant improvements in both robustness and accuracy.

</details>


### [196] [CausalNav: A Long-term Embodied Navigation System for Autonomous Mobile Robots in Dynamic Outdoor Scenarios](https://arxiv.org/abs/2601.01872)
*Hongbo Duan,Shangyi Luo,Zhiyuan Deng,Yanbo Chen,Yuanhao Chiang,Yi Liu,Fangming Liu,Xueqian Wang*

Main category: cs.RO

TL;DR: CausalNav是首个基于场景图的语义导航框架，专为动态户外环境设计，通过多层级语义场景图（Embodied Graph）结合LLM和RAG技术实现开放词汇查询下的语义导航和长程规划。


<details>
  <summary>Details</summary>
Motivation: 解决大规模户外环境中自主语言引导导航的挑战，包括语义推理困难、动态条件和长期稳定性问题。

Method: 使用LLM构建多层级语义场景图（Embodied Graph），将粗粒度地图数据与细粒度物体实体分层整合，通过RAG技术实现语义检索和规划，实时感知与离线地图数据融合，动态对象在场景图构建和分层规划模块中显式处理。

Result: 在仿真和真实环境中的大量实验表明，该方法具有优越的鲁棒性和效率。

Conclusion: CausalNav框架通过语义场景图和RAG技术，有效解决了动态户外环境中的语言引导导航问题，展现了良好的实用性和适应性。

Abstract: Autonomous language-guided navigation in large-scale outdoor environments remains a key challenge in mobile robotics, due to difficulties in semantic reasoning, dynamic conditions, and long-term stability. We propose CausalNav, the first scene graph-based semantic navigation framework tailored for dynamic outdoor environments. We construct a multi-level semantic scene graph using LLMs, referred to as the Embodied Graph, that hierarchically integrates coarse-grained map data with fine-grained object entities. The constructed graph serves as a retrievable knowledge base for Retrieval-Augmented Generation (RAG), enabling semantic navigation and long-range planning under open-vocabulary queries. By fusing real-time perception with offline map data, the Embodied Graph supports robust navigation across varying spatial granularities in dynamic outdoor environments. Dynamic objects are explicitly handled in both the scene graph construction and hierarchical planning modules. The Embodied Graph is continuously updated within a temporal window to reflect environmental changes and support real-time semantic navigation. Extensive experiments in both simulation and real-world settings demonstrate superior robustness and efficiency.

</details>


### [197] [From Metrics to Meaning: Insights from a Mixed-Methods Field Experiment on Retail Robot Deployment](https://arxiv.org/abs/2601.01946)
*Sichao Song,Yuki Okafuji,Takuya Iwamoto,Jun Baba,Hiroshi Ishiguro*

Main category: cs.RO

TL;DR: 本研究通过混合方法实地实验，考察了在床品商店部署对话服务机器人对顾客行为的影响。研究发现机器人能增加顾客停留率，但会降低店员引导的后续服务步骤，揭示了人机协作中的时间协调和空间定位问题。


<details>
  <summary>Details</summary>
Motivation: 探索在实体零售环境中部署服务机器人对顾客服务流程的实际影响，特别是在高接触度零售场景下人机协作的复杂动态。

Method: 采用混合方法设计：12天的实地实验交替三种条件（无机器人、仅机器人、机器人+固定装置），结合视频标注服务漏斗数据，并通过6次店员访谈进行解释性分析。

Result: 机器人增加了顾客停留率（固定装置效果最强），但降低了店员引导的下游步骤（接近顾客、进店、协助体验和购买）。访谈显示店员避免打断机器人对话、面临时间协调困难，且机器人主要吸引儿童满足门口好奇心。

Conclusion: 研究提出了从顾客兴趣表达到进店的整合性解释框架，为高接触度零售环境中的服务机器人部署提供了实用建议，强调人机交互中的时空协调挑战。

Abstract: We report a mixed-methods field experiment of a conversational service robot deployed under everyday staffing discretion in a live bedding store. Over 12 days we alternated three conditions--Baseline (no robot), Robot-only, and Robot+Fixture--and video-annotated the service funnel from passersby to purchase. An explanatory sequential design then used six post-experiment staff interviews to interpret the quantitative patterns.
  Quantitatively, the robot increased stopping per passerby (highest with the fixture), yet clerk-led downstream steps per stopper--clerk approach, store entry, assisted experience, and purchase--decreased. Interviews explained this divergence: clerks avoided interrupting ongoing robot-customer talk, struggled with ambiguous timing amid conversational latency, and noted child-centered attraction that often satisfied curiosity at the doorway. The fixture amplified visibility but also anchored encounters at the threshold, creating a well-defined micro-space where needs could ``close'' without moving inside.
  We synthesize these strands into an integrative account from the initial show of interest on the part of a customer to their entering the store and derive actionable guidance. The results advance the understanding of interactions between customers, staff members, and the robot and offer practical recommendations for deploying service robots in high-touch retail.

</details>


### [198] [Learning Diffusion Policy from Primitive Skills for Robot Manipulation](https://arxiv.org/abs/2601.01948)
*Zhihao Gu,Ming Yang,Difan Zou,Dong Xu*

Main category: cs.RO

TL;DR: SDP提出了一种基于技能的扩散策略，通过将复杂任务分解为可解释的原始技能序列，解决了传统方法在动作生成中的对齐问题


<details>
  <summary>Details</summary>
Motivation: 现有扩散策略方法依赖全局指令生成短期控制信号，容易导致动作生成不匹配。作者认为细粒度的原始技能（如"向上移动"、"打开夹爪"）为机器人学习提供了更直观有效的接口

Method: SDP集成了可解释技能学习与条件动作规划：1）抽象出8个跨任务可重用的原始技能；2）使用视觉语言模型从视觉观察和语言指令中提取离散表示；3）设计轻量级路由器网络为每个状态分配期望的原始技能，构建单技能策略生成技能对齐的动作

Result: 在两个具有挑战性的仿真基准测试和真实机器人部署中，SDP始终优于最先进方法

Conclusion: SDP为基于技能的机器人学习与扩散策略提供了新范式，通过技能分解确保跨任务的技能一致性行为

Abstract: Diffusion policies (DP) have recently shown great promise for generating actions in robotic manipulation. However, existing approaches often rely on global instructions to produce short-term control signals, which can result in misalignment in action generation. We conjecture that the primitive skills, referred to as fine-grained, short-horizon manipulations, such as ``move up'' and ``open the gripper'', provide a more intuitive and effective interface for robot learning. To bridge this gap, we propose SDP, a skill-conditioned DP that integrates interpretable skill learning with conditional action planning. SDP abstracts eight reusable primitive skills across tasks and employs a vision-language model to extract discrete representations from visual observations and language instructions. Based on them, a lightweight router network is designed to assign a desired primitive skill for each state, which helps construct a single-skill policy to generate skill-aligned actions. By decomposing complex tasks into a sequence of primitive skills and selecting a single-skill policy, SDP ensures skill-consistent behavior across diverse tasks. Extensive experiments on two challenging simulation benchmarks and real-world robot deployments demonstrate that SDP consistently outperforms SOTA methods, providing a new paradigm for skill-based robot learning with diffusion policies.

</details>


### [199] [What you reward is what you learn: Comparing rewards for online speech policy optimization in public HRI](https://arxiv.org/abs/2601.01969)
*Sichao Song,Yuki Okafuji,Kaito Ariu,Amy Koike*

Main category: cs.RO

TL;DR: 该研究通过12天实地部署，将社交机器人语音策略在线优化建模为多臂老虎机问题，使用Thompson采样在6种语音策略中选择，比较三种不同奖励机制对策略分布和交互行为的影响。


<details>
  <summary>Details</summary>
Motivation: 设计在开放多样环境中既高效又可接受的对话服务机器人策略具有挑战性，在线学习能够适应非平稳条件，而固定参数则无法做到。

Method: 在12天实地部署中，将在线策略优化建模为多臂老虎机问题，使用Thompson采样在6种语音策略（语速：慢/正常/快 × 详细程度：简洁/详细）中选择，比较三种二元奖励机制。

Result: 每种奖励机制（用户评分、对话结束、多轮对话）都诱导出不同的策略分布和交互行为，离线分析还揭示了上下文因素（如人群密度、群体规模）的影响。

Conclusion: 研究为在真实公共人机交互环境中部署语音策略在线优化提供了可直接使用的设计经验。

Abstract: Designing policies that are both efficient and acceptable for conversational service robots in open and diverse environments is non-trivial. Unlike fixed, hand-tuned parameters, online learning can adapt to non-stationary conditions. In this paper, we study how to adapt a social robot's speech policy in the wild. During a 12-day in-situ deployment with over 1,400 public encounters, we cast online policy optimization as a multi-armed bandit problem and use Thompson sampling to select among six actions defined by speech rate (slow/normal/fast) and verbosity (concise/detailed). We compare three complementary binary rewards--Ru (user rating), Rc (conversation closure), and Rt (>=2 turns)--and show that each induces distinct arm distributions and interaction behaviors. We complement the online results with offline evaluations that analyze contextual factors (e.g., crowd level, group size) using video-annotated data. Taken together, we distill ready-to-use design lessons for deploying online optimization of speech policies in real public HRI settings.

</details>


### [200] [Deep Robust Koopman Learning from Noisy Data](https://arxiv.org/abs/2601.01971)
*Aditya Singh,Rajpal Singh,Jishnu Keshavan*

Main category: cs.RO

TL;DR: 本文提出了一种基于自动编码器的神经网络架构，用于从噪声数据中联合学习适当的提升函数和减少偏差的Koopman算子，以提高非线性系统预测和跟踪控制的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据通常含有噪声，导致Koopman算子近似存在噪声引起的偏差，严重影响预测和下游跟踪性能。现有方法对噪声敏感，需要开发更鲁棒的技术。

Method: 提出新型自动编码器神经网络架构，首先学习系统前向和后向时间动态一致的Koopman基函数，然后利用学习到的时间动态合成减少偏差的Koopman算子。

Result: 理论分析证明了在训练噪声存在时显著减少偏差。多个串联机械臂的动态预测和跟踪控制仿真显示，在各种噪声水平下比现有领先方法更具鲁棒性。Franka FR3 7自由度机械臂实验进一步验证了方法的实际有效性。

Conclusion: 所提出的方法能够有效减少噪声引起的偏差，在噪声环境下表现出比现有技术更好的鲁棒性和性能，为实际应用中的非线性系统控制提供了有效解决方案。

Abstract: Koopman operator theory has emerged as a leading data-driven approach that relies on a judicious choice of observable functions to realize global linear representations of nonlinear systems in the lifted observable space. However, real-world data is often noisy, making it difficult to obtain an accurate and unbiased approximation of the Koopman operator. The Koopman operator generated from noisy datasets is typically corrupted by noise-induced bias that severely degrades prediction and downstream tracking performance. In order to address this drawback, this paper proposes a novel autoencoder-based neural architecture to jointly learn the appropriate lifting functions and the reduced-bias Koopman operator from noisy data. The architecture initially learns the Koopman basis functions that are consistent for both the forward and backward temporal dynamics of the system. Subsequently, by utilizing the learned forward and backward temporal dynamics, the Koopman operator is synthesized with a reduced bias making the method more robust to noise compared to existing techniques. Theoretical analysis is used to demonstrate significant bias reduction in the presence of training noise. Dynamics prediction and tracking control simulations are conducted for multiple serial manipulator arms, including performance comparisons with leading alternative designs, to demonstrate its robustness under various noise levels. Experimental studies with the Franka FR3 7-DoF manipulator arm are further used to demonstrate the effectiveness of the proposed approach in a practical setting.

</details>


### [201] [Genie Sim 3.0 : A High-Fidelity Comprehensive Simulation Platform for Humanoid Robot](https://arxiv.org/abs/2601.02078)
*Chenghao Yin,Da Huang,Di Yang,Jichao Wang,Nanshu Zhao,Chen Xu,Wenjun Sun,Linjie Hou,Zhijun Li,Junhui Wu,Zhaobo Liu,Zhen Xiao,Sheng Zhang,Lei Bao,Rui Feng,Zhenquan Pang,Jiayu Li,Qian Wang,Maoqing Yao*

Main category: cs.RO

TL;DR: Genie Sim 3.0是一个统一的机器人操作仿真平台，通过LLM驱动的场景生成工具和自动评估基准，解决了机器人学习数据收集和评估的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有物理世界数据收集成本高昂且难以扩展，而仿真基准存在碎片化、范围狭窄和保真度不足的问题，限制了机器人学习的有效模拟到真实环境的迁移。

Method: 提出Genie Sim Generator（LLM驱动的自然语言场景生成工具）和首个基于LLM的自动评估基准，利用VLM建立自动化评估流程，并发布包含10,000+小时合成数据的开源数据集。

Result: 通过系统实验验证了开源数据集在零样本模拟到真实环境迁移中的鲁棒性，证明合成数据在受控条件下可以有效替代真实世界数据进行可扩展的策略训练。

Conclusion: Genie Sim 3.0为机器人操作提供了高效的数据生成和评估解决方案，推动了机器人学习的可扩展性和实用性发展。

Abstract: The development of robust and generalizable robot learning models is critically contingent upon the availability of large-scale, diverse training data and reliable evaluation benchmarks. Collecting data in the physical world poses prohibitive costs and scalability challenges, and prevailing simulation benchmarks frequently suffer from fragmentation, narrow scope, or insufficient fidelity to enable effective sim-to-real transfer. To address these challenges, we introduce Genie Sim 3.0, a unified simulation platform for robotic manipulation. We present Genie Sim Generator, a large language model (LLM)-powered tool that constructs high-fidelity scenes from natural language instructions. Its principal strength resides in rapid and multi-dimensional generalization, facilitating the synthesis of diverse environments to support scalable data collection and robust policy evaluation. We introduce the first benchmark that pioneers the application of LLM for automated evaluation. It leverages LLM to mass-generate evaluation scenarios and employs Vision-Language Model (VLM) to establish an automated assessment pipeline. We also release an open-source dataset comprising more than 10,000 hours of synthetic data across over 200 tasks. Through systematic experimentation, we validate the robust zero-shot sim-to-real transfer capability of our open-source dataset, demonstrating that synthetic data can server as an effective substitute for real-world data under controlled conditions for scalable policy training. For code and dataset details, please refer to: https://github.com/AgibotTech/genie_sim.

</details>


### [202] [Vision-Based Early Fault Diagnosis and Self-Recovery for Strawberry Harvesting Robots](https://arxiv.org/abs/2601.02085)
*Meili Sun,Chunjiang Zhao,Lichao Yang,Hao Liu,Shimin Hu,Ya Xiong*

Main category: cs.RO

TL;DR: 该论文提出了一种草莓采摘机器人的视觉故障诊断与自恢复框架，通过多任务感知模型SRR-Net整合目标检测、分割和成熟度估计，结合相对误差补偿方法和早期中止策略，解决了采摘过程中的定位偏差、空抓取和果实滑落等问题。


<details>
  <summary>Details</summary>
Motivation: 解决草莓采摘机器人在果园环境中面临的视觉感知集成度低、果实-夹爪定位偏差、空抓取以及因夹持力不足导致的果实滑落等问题，提升采摘稳定性和效率。

Method: 提出SRR-Net多任务感知模型进行同步检测、分割和成熟度估计；设计基于目标-夹爪同步检测的相对误差补偿方法；采用早期中止策略避免空抓取和滑落；利用末端执行器嵌入式微光学相机实时反馈，结合MobileNet V3-Small和LSTM分类器进行抓取检测和滑落预测。

Result: SRR-Net在检测任务上对草莓的精确度为0.895、召回率0.813，对手部的精确度0.972、召回率0.958；分割任务上对草莓的精确度0.887、召回率0.747，对手部0.974/0.947；成熟度估计平均绝对误差0.035；推理速度达163.35 FPS。

Conclusion: 所提出的视觉故障诊断与自恢复框架有效提升了草莓采摘机器人的感知精度和操作稳定性，为解决果园环境中的自动化采摘挑战提供了可行方案。

Abstract: Strawberry harvesting robots faced persistent challenges such as low integration of visual perception, fruit-gripper misalignment, empty grasping, and strawberry slippage from the gripper due to insufficient gripping force, all of which compromised harvesting stability and efficiency in orchard environments. To overcome these issues, this paper proposed a visual fault diagnosis and self-recovery framework that integrated multi-task perception with corrective control strategies. At the core of this framework was SRR-Net, an end-to-end multi-task perception model that simultaneously performed strawberry detection, segmentation, and ripeness estimation, thereby unifying visual perception with fault diagnosis. Based on this integrated perception, a relative error compensation method based on the simultaneous target-gripper detection was designed to address positional misalignment, correcting deviations when error exceeded the tolerance threshold. To mitigate empty grasping and fruit-slippage faults, an early abort strategy was implemented. A micro-optical camera embedded in the end-effector provided real-time visual feedback, enabling grasp detection during the deflating stage and strawberry slip prediction during snap-off through MobileNet V3-Small classifier and a time-series LSTM classifier. Experiments demonstrated that SRR-Net maintained high perception accuracy. For detection, it achieved a precision of 0.895 and recall of 0.813 on strawberries, and 0.972/0.958 on hands. In segmentation, it yielded a precision of 0.887 and recall of 0.747 for strawberries, and 0.974/0.947 for hands. For ripeness estimation, SRR-Net attained a mean absolute error of 0.035, while simultaneously supporting multi-task perception and sustaining a competitive inference speed of 163.35 FPS.

</details>


### [203] [SingingBot: An Avatar-Driven System for Robotic Face Singing Performance](https://arxiv.org/abs/2601.02125)
*Zhuoxiong Xu,Xuanchen Li,Yuhao Cheng,Fei Xu,Yichao Yan,Xiaokang Yang*

Main category: cs.RO

TL;DR: 本文提出了一种基于头像驱动的机器人唱歌框架，通过视频生成模型合成生动的唱歌头像，然后通过语义映射将面部特征转移到机器人上，实现了丰富的情感表达和口型同步。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人面部驱动研究主要集中在对话或模仿静态表情，难以满足唱歌时对连续情感表达和一致性的高要求。

Method: 利用嵌入人类先验知识的肖像视频生成模型合成生动的唱歌头像，然后通过语义导向的映射函数将面部特征转移到机器人上，覆盖广泛的表情空间。

Result: 综合实验证明，该方法在保持口型同步的同时实现了丰富的情感表达，显著优于现有方法。提出的情感动态范围指标显示，宽广的情感谱对吸引人的表演至关重要。

Conclusion: 所提出的头像驱动框架能够有效提升机器人唱歌的情感表现力，为共情人机交互提供了重要技术支撑。

Abstract: Equipping robotic faces with singing capabilities is crucial for empathetic Human-Robot Interaction. However, existing robotic face driving research primarily focuses on conversations or mimicking static expressions, struggling to meet the high demands for continuous emotional expression and coherence in singing. To address this, we propose a novel avatar-driven framework for appealing robotic singing. We first leverage portrait video generation models embedded with extensive human priors to synthesize vivid singing avatars, providing reliable expression and emotion guidance. Subsequently, these facial features are transferred to the robot via semantic-oriented mapping functions that span a wide expression space. Furthermore, to quantitatively evaluate the emotional richness of robotic singing, we propose the Emotion Dynamic Range metric to measure the emotional breadth within the Valence-Arousal space, revealing that a broad emotional spectrum is crucial for appealing performances. Comprehensive experiments prove that our method achieves rich emotional expressions while maintaining lip-audio synchronization, significantly outperforming existing approaches.

</details>


### [204] [Differential Barometric Altimetry for Submeter Vertical Localization and Floor Recognition Indoors](https://arxiv.org/abs/2601.02184)
*Yuhang Zhang,Sören Schwertfeger*

Main category: cs.RO

TL;DR: 本文提出了一种基于差分气压传感的低成本垂直估计框架，可在复杂多层环境中实现亚米级垂直精度和100%楼层识别。


<details>
  <summary>Details</summary>
Motivation: 准确的高度估计和可靠的楼层识别对于移动机器人在复杂多层环境中的定位和导航至关重要，而仅靠视觉或激光SLAM的垂直定位能力不足。

Method: 采用差分气压传感技术，通过固定基站和移动传感器的实时气压数据对比，结合ROS兼容软件包实现无漂移的垂直定位。

Result: 在完全封闭的楼梯间和电梯等挑战性场景中，系统实现了0.29米的垂直精度（RMSE）和100%的楼层识别准确率。

Conclusion: 提出的气压模块为实际机器人部署提供了实用且经济高效的垂直感知解决方案，代码已开源。

Abstract: Accurate altitude estimation and reliable floor recognition are critical for mobile robot localization and navigation within complex multi-storey environments. In this paper, we present a robust, low-cost vertical estimation framework leveraging differential barometric sensing integrated within a fully ROS-compliant software package. Our system simultaneously publishes real-time altitude data from both a stationary base station and a mobile sensor, enabling precise and drift-free vertical localization. Empirical evaluations conducted in challenging scenarios -- such as fully enclosed stairwells and elevators, demonstrate that our proposed barometric pipeline achieves sub-meter vertical accuracy (RMSE: 0.29 m) and perfect (100%) floor-level identification. In contrast, our results confirm that standalone height estimates, obtained solely from visual- or LiDAR-based SLAM odometry, are insufficient for reliable vertical localization. The proposed ROS-compatible barometric module thus provides a practical and cost-effective solution for robust vertical awareness in real-world robotic deployments. The implementation of our method is released as open source at https://github.com/witsir/differential-barometric.

</details>


### [205] [CycleVLA: Proactive Self-Correcting Vision-Language-Action Models via Subtask Backtracking and Minimum Bayes Risk Decoding](https://arxiv.org/abs/2601.02295)
*Chenyang Ma,Guangyu Yang,Kai Lu,Shitong Xu,Bill Byrne,Niki Trigoni,Andrew Markham*

Main category: cs.RO

TL;DR: 本文提出了CycleVLA系统，为视觉-语言-动作模型（VLAs）提供主动自我纠正能力，能够在执行过程中预测即将发生的故障并在其完全显现前进行恢复。


<details>
  <summary>Details</summary>
Motivation: 当前机器人故障检测和纠正方法通常在故障发生后进行分析和修正，这种后验方式效率较低。本文旨在开发一种能够主动预测和预防故障的系统。

Method: CycleVLA集成了三个关键组件：1）进度感知VLA，标记关键子任务转换点；2）基于VLM的故障预测器和规划器，在预测到故障时触发子任务回溯；3）基于最小贝叶斯风险（MBR）解码的测试时扩展策略，提高回溯后的重试成功率。

Result: 大量实验表明，CycleVLA能够提升训练良好和训练不足的VLAs的性能，并且MBR作为VLAs的有效零样本测试时扩展策略。

Conclusion: CycleVLA通过主动自我纠正机制显著提高了机器人任务的可靠性和成功率，为VLA模型的实际应用提供了重要改进。

Abstract: Current work on robot failure detection and correction typically operate in a post hoc manner, analyzing errors and applying corrections only after failures occur. This work introduces CycleVLA, a system that equips Vision-Language-Action models (VLAs) with proactive self-correction, the capability to anticipate incipient failures and recover before they fully manifest during execution. CycleVLA achieves this by integrating a progress-aware VLA that flags critical subtask transition points where failures most frequently occur, a VLM-based failure predictor and planner that triggers subtask backtracking upon predicted failure, and a test-time scaling strategy based on Minimum Bayes Risk (MBR) decoding to improve retry success after backtracking. Extensive experiments show that CycleVLA improves performance for both well-trained and under-trained VLAs, and that MBR serves as an effective zero-shot test-time scaling strategy for VLAs. Project Page: https://dannymcy.github.io/cyclevla/

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [206] [Horizon Reduction as Information Loss in Offline Reinforcement Learning](https://arxiv.org/abs/2601.00831)
*Uday Kumar Nidadala,Venkata Bhumika Guthi*

Main category: cs.LG

TL;DR: 本文证明离线强化学习中的视野缩减策略会导致不可恢复的信息损失，使得最优策略与次优策略在统计上无法区分，即使有无限数据和完美函数逼近。


<details>
  <summary>Details</summary>
Motivation: 尽管经验证据表明视野缩减可以改善离线强化学习的扩展性，但其理论影响尚未充分研究。本文旨在揭示视野缩减在离线RL中的基本局限性。

Method: 将视野缩减形式化为从固定长度轨迹片段中学习，通过最小反例马尔可夫决策过程识别三种结构失效模式，并建立必要安全条件。

Result: 发现视野缩减会导致三种失效模式：前缀不可区分性导致可识别性失败、截断回报引起的目标错误指定、离线数据集支持和表示混淆。

Conclusion: 视野缩减存在固有局限性，无法仅通过算法改进克服，需要满足特定条件才能安全使用，这补充了现有关于保守目标和分布偏移的研究。

Abstract: Horizon reduction is a common design strategy in offline reinforcement learning (RL), used to mitigate long-horizon credit assignment, improve stability, and enable scalable learning through truncated rollouts, windowed training, or hierarchical decomposition (Levine et al., 2020; Prudencio et al., 2023; Park et al., 2025). Despite recent empirical evidence that horizon reduction can improve scaling on challenging offline RL benchmarks, its theoretical implications remain underdeveloped (Park et al., 2025). In this paper, we show that horizon reduction can induce fundamental and irrecoverable information loss in offline RL. We formalize horizon reduction as learning from fixed-length trajectory segments and prove that, under this paradigm and any learning interface restricted to fixed-length trajectory segments, optimal policies may be statistically indistinguishable from suboptimal ones even with infinite data and perfect function approximation. Through a set of minimal counterexample Markov decision processes (MDPs), we identify three distinct structural failure modes: (i) prefix indistinguishability leading to identifiability failure, (ii) objective misspecification induced by truncated returns, and (iii) offline dataset support and representation aliasing. Our results establish necessary conditions under which horizon reduction can be safe and highlight intrinsic limitations that cannot be overcome by algorithmic improvements alone, complementing algorithmic work on conservative objectives and distribution shift that addresses a different axis of offline RL difficulty (Fujimoto et al., 2019; Kumar et al., 2020; Gulcehre et al., 2020).

</details>


### [207] [ShrimpXNet: A Transfer Learning Framework for Shrimp Disease Classification with Augmented Regularization, Adversarial Training, and Explainable AI](https://arxiv.org/abs/2601.00832)
*Israk Hasan Jone,D. M. Rafiun Bin Masud,Promit Sarker,Sayed Fuad Al Labib,Nazmul Islam,Farhad Billah*

Main category: cs.LG

TL;DR: 本文提出了一种基于深度学习的虾病自动分类方法，使用六种预训练模型在包含1,149张图像的四个疾病类别数据集上进行评估，其中ConvNeXt-Tiny模型表现最佳，测试准确率达到96.88%。


<details>
  <summary>Details</summary>
Motivation: 虾是全球消费最广泛的水产品之一，但虾养殖业面临疾病爆发的严重挑战，影响可持续生产。自动疾病分类方法可以提供及时准确的检测。

Method: 使用背景去除和Keras图像管道进行标准化预处理，部署六种预训练深度学习模型（ResNet50、EfficientNet、DenseNet201、MobileNet、ConvNeXt-Tiny、Xception），采用FGSM对抗训练增强鲁棒性，使用CutMix和MixUp数据增强策略防止过拟合，应用Grad-CAM等后验解释方法进行可视化。

Result: ConvNeXt-Tiny模型在测试集上达到96.88%的最高准确率，经过1000次迭代后，99%置信区间为[0.953,0.971]。

Conclusion: 深度学习模型可以有效实现虾病的自动分类，ConvNeXt-Tiny表现最优，为虾养殖业的疾病管理提供了可行的技术解决方案。

Abstract: Shrimp is one of the most widely consumed aquatic species globally, valued for both its nutritional content and economic importance. Shrimp farming represents a significant source of income in many regions; however, like other forms of aquaculture, it is severely impacted by disease outbreaks. These diseases pose a major challenge to sustainable shrimp production. To address this issue, automated disease classification methods can offer timely and accurate detection. This research proposes a deep learning-based approach for the automated classification of shrimp diseases. A dataset comprising 1,149 images across four disease classes was utilized. Six pretrained deep learning models, ResNet50, EfficientNet, DenseNet201, MobileNet, ConvNeXt-Tiny, and Xception were deployed and evaluated for performance. The images background was removed, followed by standardized preprocessing through the Keras image pipeline. Fast Gradient Sign Method (FGSM) was used for enhancing the model robustness through adversarial training. While advanced augmentation strategies, including CutMix and MixUp, were implemented to mitigate overfitting and improve generalization. To support interpretability, and to visualize regions of model attention, post-hoc explanation methods such as Grad-CAM, Grad-CAM++, and XGrad-CAM were applied. Exploratory results demonstrated that ConvNeXt-Tiny achieved the highest performance, attaining a 96.88% accuracy on the test dataset. After 1000 iterations, the 99% confidence interval for the model is [0.953,0.971].

</details>


### [208] [Intrinsic-Metric Physics-Informed Neural Networks (IM-PINN) for Reaction-Diffusion Dynamics on Complex Riemannian Manifolds](https://arxiv.org/abs/2601.00834)
*Julian Evan Chrisnanto,Salsabila Rahma Alia,Nurfauzi Fadillah,Yulison Herry Chrisnanto*

Main category: cs.LG

TL;DR: 本文提出了一种无网格的几何深度学习框架IM-PINN，用于在复杂非欧几里得流形上模拟非线性反应扩散动力学，解决了传统方法的高保真网格生成成本和辛漂移问题。


<details>
  <summary>Details</summary>
Motivation: 在复杂非欧几里得流形上模拟非线性反应扩散动力学面临高保真网格生成成本高和离散时间步进方案中的辛漂移等挑战，需要开发一种更高效、物理更严谨的求解方法。

Method: 通过将黎曼度量张量嵌入自动微分图，IM-PINN框架解析重构拉普拉斯-贝尔特拉米算子，采用双流架构和傅里叶特征嵌入来减轻频谱偏差，直接在连续参数域中求解偏微分方程。

Result: 在具有极端高斯曲率波动的"随机布料"流形上，IM-PINN成功恢复了Gray-Scott模型的"分裂斑点"和"迷宫"模式，全局质量守恒误差为0.157，优于表面有限元法的0.258。

Conclusion: IM-PINN框架为在演化表面上模拟生物模式形成提供了一种内存高效、分辨率无关的范式，弥合了微分几何和物理信息机器学习之间的鸿沟。

Abstract: Simulating nonlinear reaction-diffusion dynamics on complex, non-Euclidean manifolds remains a fundamental challenge in computational morphogenesis, constrained by high-fidelity mesh generation costs and symplectic drift in discrete time-stepping schemes. This study introduces the Intrinsic-Metric Physics-Informed Neural Network (IM-PINN), a mesh-free geometric deep learning framework that solves partial differential equations directly in the continuous parametric domain. By embedding the Riemannian metric tensor into the automatic differentiation graph, our architecture analytically reconstructs the Laplace-Beltrami operator, decoupling solution complexity from geometric discretization. We validate the framework on a "Stochastic Cloth" manifold with extreme Gaussian curvature fluctuations ($K \in [-2489, 3580]$), where traditional adaptive refinement fails to resolve anisotropic Turing instabilities. Using a dual-stream architecture with Fourier feature embeddings to mitigate spectral bias, the IM-PINN recovers the "splitting spot" and "labyrinthine" regimes of the Gray-Scott model. Benchmarking against the Surface Finite Element Method (SFEM) reveals superior physical rigor: the IM-PINN achieves global mass conservation error of $\mathcal{E}_{mass} \approx 0.157$ versus SFEM's $0.258$, acting as a thermodynamically consistent global solver that eliminates mass drift inherent in semi-implicit integration. The framework offers a memory-efficient, resolution-independent paradigm for simulating biological pattern formation on evolving surfaces, bridging differential geometry and physics-informed machine learning.

</details>


### [209] [SLO-Conditioned Action Routing for Retrieval-Augmented Generation: Objective Ablation and Failure Modes](https://arxiv.org/abs/2601.00841)
*Bharath Nunepalli*

Main category: cs.LG

TL;DR: 该论文研究RAG系统的查询级控制问题，提出通过选择检索深度和生成模式来满足服务级别目标（SLOs），并评估了两种简单的策略学习方法。


<details>
  <summary>Details</summary>
Motivation: RAG系统需要根据每个查询动态调整检索深度和生成行为，以平衡成本、拒绝率和幻觉风险等SLOs指标。

Method: 将每个查询的控制建模为离散动作选择（检索深度、生成模式或拒绝），使用SQuAD 2.0构建离线数据集，评估两种策略学习目标：Argmax-CE和Argmax-CE-WT。

Result: 固定基线策略表现良好；学习策略在质量导向SLO下能节省成本，但在成本导向SLO下可能出现拒绝崩溃问题。

Conclusion: 本研究为RAG管道提供了可复现的SLO感知控制案例研究，重点分析了失败模式和报告规范，而非提出新的检索器或语言模型。

Abstract: Retrieval-augmented generation (RAG) introduces a practical control problem: retrieval depth and generation behavior must be chosen per query to satisfy service-level objectives (SLOs) such as cost, refusal rate, and hallucination risk. This work models per-query control as a small discrete action: choose a retrieval depth and a generation mode (guarded vs. auto), or refuse. An offline logged dataset is constructed from SQuAD 2.0 by executing each action and recording accuracy, token cost, hallucination/refusal indicators, and an SLO-weighted reward. Two simple policy-learning objectives are evaluated: supervised classification of the per-state best action (Argmax-CE) and a reward-weighted variant (Argmax-CE-WT). Across the evaluated settings, a strong fixed baseline (low k, guarded prompting) performs competitively; learned policies mainly provide additional cost savings under a quality-focused SLO and can exhibit refusal collapse under a cheap SLO when refusal is heavily rewarded. The contribution is a reproducible case study of SLO-aware control for RAG pipelines, emphasizing failure modes and reporting conventions rather than proposing a new retriever or language model.

</details>


### [210] [Value-guided action planning with JEPA world models](https://arxiv.org/abs/2601.00844)
*Matthieu Destrade,Oumayma Bounou,Quentin Le Lidec,Jean Ponce,Yann LeCun*

Main category: cs.LG

TL;DR: 本文提出了一种增强JEPA世界模型规划能力的方法，通过塑造表示空间，使目标条件值函数近似于状态嵌入之间的距离，从而显著提升规划性能。


<details>
  <summary>Details</summary>
Motivation: JEPA架构虽然能有效建模环境动态，但在支持有效行动规划方面存在局限，需要改进以增强其规划能力。

Method: 通过约束训练过程，使目标条件值函数能够用状态嵌入之间的距离来近似，从而塑造表示空间以支持更好的规划。

Result: 在简单控制任务上，该方法相比标准JEPA模型显著提升了规划性能。

Conclusion: 通过适当塑造表示空间，JEPA世界模型可以有效地支持行动规划，为构建能够推理环境动态的深度学习模型提供了可行方案。

Abstract: Building deep learning models that can reason about their environment requires capturing its underlying dynamics. Joint-Embedded Predictive Architectures (JEPA) provide a promising framework to model such dynamics by learning representations and predictors through a self-supervised prediction objective. However, their ability to support effective action planning remains limited. We propose an approach to enhance planning with JEPA world models by shaping their representation space so that the negative goal-conditioned value function for a reaching cost in a given environment is approximated by a distance (or quasi-distance) between state embeddings. We introduce a practical method to enforce this constraint during training and show that it leads to significantly improved planning performance compared to standard JEPA models on simple control tasks.

</details>


### [211] [You Only Need Your Transformer 25% of the Time: Meaning-First Execution for Eliminating Unnecessary Inference](https://arxiv.org/abs/2601.00847)
*Ryan Shamim*

Main category: cs.LG

TL;DR: 本文提出了一种名为MFEE的控制平面架构，通过语义分析选择性执行transformer推理，在保持100%准确性的同时减少78.1%的计算量。


<details>
  <summary>Details</summary>
Motivation: 现代AI推理系统将transformer执行视为必须，但模型能力与执行必要性之间存在差异。本文旨在重新定义推理为控制平面决策问题，确定何时需要执行，何时可以通过替代路径保持正确性。

Method: 引入Meaning-First Execution (MFEE)控制平面架构，作为现有堆栈之上的门控层，不修改模型、权重或参数。通过语义分析选择性地调用transformer推理。

Result: 在1000个多样化提示下，MFEE实现78.1%的执行减少，同时保持100%的精确匹配等效性。相比基于模式的路由器最多只能实现53.3%的避免率且有正确性失败，MFEE通过语义分析达到100%避免率且零失败。

Conclusion: 执行治理应成为ML系统基础设施的基础层，与模型级优化技术正交。通过定理1证明，仅基于有限特征映射的任何路由器都无法在特征碰撞对上同时保证零错误跳过和正避免率。

Abstract: Modern AI inference systems treat transformer execution as mandatory, conflating model capability with execution necessity. We reframe inference as a control-plane decision problem: determining when execution is necessary versus when correctness can be preserved through alternative pathways. We introduce Meaning-First Execution (MFEE), a control-plane architecture implementing this framework, selectively invoking transformer inference only when required. MFEE operates as a gating layer above existing stacks without modifying models, weights, or parameters. Across 1,000 diverse prompts under deterministic decoding, MFEE achieves 78.1% execution reduction while maintaining 100% exact-match equivalence for invoked executions. Comparative evaluation reveals pattern-based routers achieve at most 53.3% avoidance with correctness failures, while MFEE reaches 100% avoidance with zero failures through semantic analysis. We prove this limitation via Theorem 1: any router operating solely on finite feature maps cannot simultaneously guarantee zero false skips and positive avoidance on feature-collision pairs. These results establish execution governance as a foundational layer in ML systems infrastructure, orthogonal to model-level optimization techniques.

</details>


### [212] [EdgeJury: Cross-Reviewed Small-Model Ensembles for Truthful Question Answering on Serverless Edge Inference](https://arxiv.org/abs/2601.00850)
*Aayush Kumar*

Main category: cs.LG

TL;DR: EdgeJury是一个轻量级集成框架，通过协调多个小型语言模型（3B-8B）的并行生成、交叉评审和合成，显著提高问答系统的真实性和鲁棒性，特别适合边缘计算部署。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的边缘部署中，前沿模型或检索管道可能不实用，幻觉问题严重影响了问答系统的可靠性。需要一种轻量级方法来解决这个问题。

Method: EdgeJury包含四个阶段：1）并行角色专业化生成；2）匿名交叉评审与结构化批评和排名；3）主席合成，整合最强内容并解决标记问题；4）基于模型间一致性的声明级一致性标记。

Result: 在TruthfulQA（MC1）上达到76.2%准确率，相对单个8B基线提升21.4%；在对抗性EdgeCases集上获得48.2%相对增益；人工分析显示事实性幻觉错误减少约55%；在Cloudflare Workers AI上实现8.4秒中位端到端延迟。

Conclusion: 协调的小型模型集成可以在不依赖外部检索或专有大型模型API的情况下，显著提高误解密集型问答基准的真实性，证明了边缘部署的可行性。

Abstract: Hallucinations hinder reliable question answering, especially in resource-constrained deployments where frontier-scale models or retrieval pipelines may be impractical. We present EdgeJury, a lightweight ensemble framework that improves truthfulness and robustness using only small instruction-tuned language models (3B-8B) suitable for serverless edge inference. EdgeJury orchestrates four stages: (1) parallel role-specialized generation, (2) anonymized cross-review with structured critiques and rankings, (3) chairman synthesis that integrates the strongest content while addressing flagged issues, and (4) claim-level consistency labeling based on inter-model agreement. On TruthfulQA (MC1), EdgeJury achieves 76.2% accuracy (95% CI: 72.8-79.6%), a +21.4% relative improvement over a single 8B baseline (62.8%), and outperforms standard baselines including self-consistency and majority voting under transparent compute accounting (total tokens and platform cost reported). On a 200-question adversarial EdgeCases set, EdgeJury yields +48.2% relative gains (95% CI: 44.0-52.4%). Manual analysis on 100 incorrect answers shows an approximately 55% reduction in factual hallucination errors versus the single-model baseline. Deployed on Cloudflare Workers AI, EdgeJury achieves 8.4 s median end-to-end latency, demonstrating that coordinated small-model ensembles can improve truthfulness on misconception-heavy QA benchmarks without external retrieval or proprietary large-model APIs.

</details>


### [213] [FedSCAM (Federated Sharpness-Aware Minimization with Clustered Aggregation and Modulation): Scam-resistant SAM for Robust Federated Optimization in Heterogeneous Environments](https://arxiv.org/abs/2601.00853)
*Sameer Rahil,Zain Abdullah Ahmad,Talha Asif*

Main category: cs.LG

TL;DR: FedSCAM是一种联邦学习算法，通过基于客户端异质性动态调整SAM扰动半径和聚合权重，解决非IID数据下的收敛和泛化问题。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习中的SAM方法对所有客户端使用统一的扰动半径，忽略了客户端特定的异质性，这可能导致高方差客户端破坏全局模型的稳定性。

Method: 提出FedSCAM算法，计算每个客户端的异质性指标，并基于该指标反向调制SAM扰动半径；同时引入异质性感知的加权聚合机制，优先选择与全局优化方向一致的客户端更新。

Result: 在CIFAR-10和Fashion-MNIST数据集上的实验表明，FedSCAM在收敛速度和最终测试准确率方面优于FedSAM、FedLESAM等基线方法。

Conclusion: FedSCAM通过动态调整扰动半径和异质性感知聚合，有效提升了非IID数据下联邦学习的性能，证明了考虑客户端特定异质性的重要性。

Abstract: Federated Learning (FL) enables collaborative model training across decentralized edge devices while preserving data privacy. However, statistical heterogeneity among clients, often manifested as non-IID label distributions, poses significant challenges to convergence and generalization. While Sharpness-Aware Minimization (SAM) has been introduced to FL to seek flatter, more robust minima, existing approaches typically apply a uniform perturbation radius across all clients, ignoring client-specific heterogeneity. In this work, we propose \textbf{FedSCAM} (Federated Sharpness-Aware Minimization with Clustered Aggregation and Modulation), a novel algorithm that dynamically adjusts the SAM perturbation radius and aggregation weights based on client-specific heterogeneity scores. By calculating a heterogeneity metric for each client and modulating the perturbation radius inversely to this score, FedSCAM prevents clients with high variance from destabilizing the global model. Furthermore, we introduce a heterogeneity-aware weighted aggregation mechanism that prioritizes updates from clients that align with the global optimization direction. Extensive experiments on CIFAR-10 and Fashion-MNIST under various degrees of Dirichlet-based label skew demonstrate that FedSCAM achieves competitive performance among state-of-the-art baselines, including FedSAM, FedLESAM, etc. in terms of convergence speed and final test accuracy.

</details>


### [214] [Harvesting AlphaEarth: Benchmarking the Geospatial Foundation Model for Agricultural Downstream Tasks](https://arxiv.org/abs/2601.00857)
*Yuchi Ma,Yawen Shen,Anu Swatantran,David B. Lobell*

Main category: cs.LG

TL;DR: 本研究评估了Google DeepMind的AlphaEarth Foundation（AEF）地理空间基础模型在农业监测任务中的表现，包括作物产量预测、耕作制图和覆盖作物制图，并与传统遥感模型进行对比。


<details>
  <summary>Details</summary>
Motivation: 现有AEF模型主要在土地利用分类任务中表现优异，但缺乏在农业关键下游任务中的全面评估，以及与传统遥感模型的系统比较。

Method: 在美国三个农业下游任务中评估AEF嵌入向量，包括作物产量预测、耕作制图和覆盖作物制图，使用公共和私有数据集在不同尺度和位置进行测试，并训练传统遥感模型作为对比基准。

Result: AEF模型在所有任务中表现良好，在产量预测和县级耕作制图任务中与专门构建的遥感模型具有竞争力，但存在空间迁移性有限、可解释性低和时间敏感性不足等局限性。

Conclusion: 虽然AEF在农业任务中表现强劲，但由于其时间敏感性、泛化能力和可解释性方面的限制，在农业应用中需要谨慎使用。

Abstract: Geospatial foundation models (GFMs) have emerged as a promising approach to overcoming the limitations in existing featurization methods. More recently, Google DeepMind has introduced AlphaEarth Foundation (AEF), a GFM pre-trained using multi-source EOs across continuous time. An annual and global embedding dataset is produced using AEF that is ready for analysis and modeling. The internal experiments show that AEF embeddings have outperformed operational models in 15 EO tasks without re-training. However, those experiments are mostly about land cover and land use classification. Applying AEF and other GFMs to agricultural monitoring require an in-depth evaluation in critical agricultural downstream tasks. There is also a lack of comprehensive comparison between the AEF-based models and traditional remote sensing (RS)-based models under different scenarios, which could offer valuable guidance for researchers and practitioners. This study addresses some of these gaps by evaluating AEF embeddings in three agricultural downstream tasks in the U.S., including crop yield prediction, tillage mapping, and cover crop mapping. Datasets are compiled from both public and private sources to comprehensively evaluate AEF embeddings across tasks at different scales and locations, and RS-based models are trained as comparison models. AEF-based models generally exhibit strong performance on all tasks and are competitive with purpose-built RS-based models in yield prediction and county-level tillage mapping when trained on local data. However, we also find several limitations in current AEF embeddings, such as limited spatial transferability compared to RS-based models, low interpretability, and limited time sensitivity. These limitations recommend caution when applying AEF embeddings in agriculture, where time sensitivity, generalizability, and interpretability is important.

</details>


### [215] [Path Integral Solution for Dissipative Generative Dynamics](https://arxiv.org/abs/2601.00860)
*Xidi Wang*

Main category: cs.LG

TL;DR: 该论文证明纯机械系统可以通过耗散量子动力学产生智能语言，而守恒定律会导致根本性失败。研究表明语言生成本质上是耗散量子场论，智能来源于耗散和非局域性的结合。


<details>
  <summary>Details</summary>
Motivation: 探索纯机械系统是否能够生成智能语言，研究量子动力学在语言生成中的作用，特别是耗散和非局域性对智能涌现的影响。

Method: 使用Koopman算子和闭式路径积分传播子分析耗散量子动力学，通过谱分析揭示特征值结构，分离出衰减模式（遗忘）、增长模式（放大）和中性模式（保持）。

Result: 发现不可逆计算需要受控信息耗散和因果上下文聚合，哈密顿约束会消除耗散模式并降低性能，尽管模型容量不变。

Conclusion: 语言生成是耗散量子场论，机械系统通过耗散和非局域性的结合而非守恒获得智能。

Abstract: Can purely mechanical systems generate intelligent language? We prove that dissipative quantum dynamics with analytically tractable non-local context aggregation produce coherent text generation, while conservation laws cause fundamental failure. Employing Koopman operators with closed-form path integral propagators, we show irreversible computation fundamentally requires both controlled information dissipation and causal context aggregation. Spectral analysis reveals emergent eigenvalue structure, separating into decay modes (forgetting), growth modes (amplification), and neutral modes (preservation) -- the essential ingredients for directed information flow. Hamiltonian constraints force the elimination of these dissipative modes and degrading performance despite unchanged model capacity. This establishes language generation as dissipative quantum field theory, proving mechanical systems acquire intelligence through the combination of dissipation and non-locality, not through conservation.

</details>


### [216] [Universal Battery Degradation Forecasting Driven by Foundation Model Across Diverse Chemistries and Conditions](https://arxiv.org/abs/2601.00862)
*Joey Chan,Huan Wang,Haoyu Pan,Wei Wu,Zirong Wang,Zhen Chen,Ershun Pan,Min Xie,Lifeng Xi*

Main category: cs.LG

TL;DR: 该研究提出了一个统一的电池容量衰减预测框架，使用时间序列基础模型和物理引导的对比学习，在包含1,704个电池的大规模数据集上实现了跨化学体系和操作条件的稳健性能。


<details>
  <summary>Details</summary>
Motivation: 电池容量衰减的准确预测对能源存储系统的安全性和可靠性至关重要，但由于不同电池化学体系、外形尺寸和操作条件的强异质性，构建一个能够泛化到训练领域之外的单一模型非常困难。

Method: 收集20个公开老化数据集构建大规模语料库，采用时间序列基础模型作为主干网络，结合参数高效的LoRA技术和物理引导的对比表示学习来捕捉共享的退化模式。

Result: 实验表明，单一统一模型在已见和未见数据集上都达到了与强基线相当的精度，同时在训练中排除的化学体系、容量尺度和操作条件下保持了稳定性能。

Conclusion: 基于时间序列基础模型的架构展示了作为电池管理系统容量退化预测的可扩展和可转移解决方案的潜力。

Abstract: Accurate forecasting of battery capacity fade is essential for the safety, reliability, and long-term efficiency of energy storage systems. However, the strong heterogeneity across cell chemistries, form factors, and operating conditions makes it difficult to build a single model that generalizes beyond its training domain. This work proposes a unified capacity forecasting framework that maintains robust performance across diverse chemistries and usage scenarios. We curate 20 public aging datasets into a large-scale corpus covering 1,704 cells and 3,961,195 charge-discharge cycle segments, spanning temperatures from $-5\,^{\circ}\mathrm{C}$ to $45\,^{\circ}\mathrm{C}$, multiple C-rates, and application-oriented profiles such as fast charging and partial cycling. On this corpus, we adopt a Time-Series Foundation Model (TSFM) backbone and apply parameter-efficient Low-Rank Adaptation (LoRA) together with physics-guided contrastive representation learning to capture shared degradation patterns. Experiments on both seen and deliberately held-out unseen datasets show that a single unified model achieves competitive or superior accuracy compared with strong per-dataset baselines, while retaining stable performance on chemistries, capacity scales, and operating conditions excluded from training. These results demonstrate the potential of TSFM-based architectures as a scalable and transferable solution for capacity degradation forecasting in real battery management systems.

</details>


### [217] [Selective Imperfection as a Generative Framework for Analysis, Creativity and Discovery](https://arxiv.org/abs/2601.00863)
*Markus J. Buehler*

Main category: cs.LG

TL;DR: materiomusic是一个生成框架，将物质的层次结构与音乐的作曲逻辑联系起来，通过可逆映射将分子光谱转化为音乐音调，三维网络转化为可演奏乐器


<details>
  <summary>Details</summary>
Motivation: 探索声音作为科学探针的功能，实现听觉成为视觉模式的认知反转，音乐创作成为物质蓝图，挖掘从飞秒分子振动到亿年进化历史的深层时间模式

Method: 使用可逆映射方法，从分子光谱到音乐音调，从三维网络到可演奏乐器；通过枚举所有2^12音乐音阶进行定量分析；采用基于群体的AI模型进行音乐创作

Result: 发现文化重要的音乐系统聚集在中熵、中缺陷的走廊中，与材料科学中的Hall-Petch最优值直接平行；AI创作的音乐展现出类似人类的结构特征，如小世界连接性、模块化整合、长程连贯性

Conclusion: 科学和艺术是在约束下进行世界构建的生成行为，振动是跨尺度组织结构的共享语法，选择性不完美提供了恢复连贯性和适应性之间平衡的机制

Abstract: We introduce materiomusic as a generative framework linking the hierarchical structures of matter with the compositional logic of music. Across proteins, spider webs and flame dynamics, vibrational and architectural principles recur as tonal hierarchies, harmonic progressions, and long-range musical form. Using reversible mappings, from molecular spectra to musical tones and from three-dimensional networks to playable instruments, we show how sound functions as a scientific probe, an epistemic inversion where listening becomes a mode of seeing and musical composition becomes a blueprint for matter. These mappings excavate deep time: patterns originating in femtosecond molecular vibrations or billion-year evolutionary histories become audible. We posit that novelty in science and art emerges when constraints cannot be satisfied within existing degrees of freedom, forcing expansion of the space of viable configurations. Selective imperfection provides the mechanism restoring balance between coherence and adaptability. Quantitative support comes from exhaustive enumeration of all 2^12 musical scales, revealing that culturally significant systems cluster in a mid-entropy, mid-defect corridor, directly paralleling the Hall-Petch optimum where intermediate defect densities maximize material strength. Iterating these mappings creates productive collisions between human creativity and physics, generating new information as musical structures encounter evolutionary constraints. We show how swarm-based AI models compose music exhibiting human-like structural signatures such as small-world connectivity, modular integration, long-range coherence, suggesting a route beyond interpolation toward invention. We show that science and art are generative acts of world-building under constraint, with vibration as a shared grammar organizing structure across scales.

</details>


### [218] [Distribution Matching for Graph Quantification Under Structural Covariate Shift](https://arxiv.org/abs/2601.00864)
*Clemens Damke,Eyke Hüllermeier*

Main category: cs.LG

TL;DR: 该论文提出了一种基于结构重要性采样的量化学习方法，用于处理图数据中的结构性分布偏移问题，扩展了KDEy量化方法以在结构变化下保持性能。


<details>
  <summary>Details</summary>
Motivation: 在社交网络等图数据中，预测标签分布（量化学习）时，传统基于先验概率偏移假设的方法无法处理训练集和测试集来自图结构不同区域时的结构性偏移问题。

Method: 扩展了KDEy量化学习方法，引入了结构重要性采样技术，通过考虑图结构信息来调整样本权重，从而适应结构性分布偏移。

Result: 实验表明，提出的方法能够有效适应结构性偏移，在量化学习任务上优于标准量化方法。

Conclusion: 结构重要性采样是解决图数据量化学习中结构性分布偏移问题的有效方法，为图量化学习提供了新的技术路径。

Abstract: Graphs are commonly used in machine learning to model relationships between instances. Consider the task of predicting the political preferences of users in a social network; to solve this task one should consider, both, the features of each individual user and the relationships between them. However, oftentimes one is not interested in the label of a single instance but rather in the distribution of labels over a set of instances; e.g., when predicting the political preferences of users, the overall prevalence of a given opinion might be of higher interest than the opinion of a specific person. This label prevalence estimation task is commonly referred to as quantification learning (QL). Current QL methods for tabular data are typically based on the so-called prior probability shift (PPS) assumption which states that the label-conditional instance distributions should remain equal across the training and test data. In the graph setting, PPS generally does not hold if the shift between training and test data is structural, i.e., if the training data comes from a different region of the graph than the test data. To address such structural shifts, an importance sampling variant of the popular adjusted count quantification approach has previously been proposed. In this work, we extend the idea of structural importance sampling to the state-of-the-art KDEy quantification approach. We show that our proposed method adapts to structural shifts and outperforms standard quantification approaches.

</details>


### [219] [A-PINN: Auxiliary Physics-informed Neural Networks for Structural Vibration Analysis in Continuous Euler-Bernoulli Beam](https://arxiv.org/abs/2601.00866)
*Shivani Saini,Ramesh Kumar Vats,Arup Kumar Sahoo*

Main category: cs.LG

TL;DR: 本文提出了一种改进的辅助物理信息神经网络（A-PINN）框架，结合平衡自适应优化器，用于解决结构振动问题。该模型在数值稳定性和预测精度方面相比基线方法至少提升了40%。


<details>
  <summary>Details</summary>
Motivation: 结构振动问题的准确分析对于捕捉振动现象和确保可靠预测分析至关重要。本研究旨在深入探讨科学机器学习模型在解决振动问题方面的鲁棒性。

Method: 提出改进的A-PINN框架，采用平衡自适应优化器，通过数值模拟近似求解不同场景下的Euler-Bernoulli梁方程。

Result: 数值结果证实了该模型在数值稳定性和预测精度方面的增强性能，相比基线方法至少提升了40%的性能。

Conclusion: 该研究证明了改进的A-PINN框架在结构振动问题分析中的有效性，为科学机器学习模型在工程应用中的鲁棒性提供了重要见解。

Abstract: Recent advancements in physics-informed neural networks (PINNs) and their variants have garnered substantial focus from researchers due to their effectiveness in solving both forward and inverse problems governed by differential equations. In this research, a modified Auxiliary physics-informed neural network (A-PINN) framework with balanced adaptive optimizers is proposed for the analysis of structural vibration problems. In order to accurately represent structural systems, it is critical for capturing vibration phenomena and ensuring reliable predictive analysis. So, our investigations are crucial for gaining deeper insight into the robustness of scientific machine learning models for solving vibration problems. Further, to rigorously evaluate the performance of A-PINN, we conducted different numerical simulations to approximate the Euler-Bernoulli beam equations under the various scenarios. The numerical results substantiate the enhanced performance of our model in terms of both numerical stability and predictive accuracy. Our model shows improvement of at least 40% over the baselines.

</details>


### [220] [SmartFlow Reinforcement Learning and Agentic AI for Bike-Sharing Optimisation](https://arxiv.org/abs/2601.00868)
*Aditya Sreevatsa K,Arun Kumar Raveendran,Jesrael K Mani,Prakash G Shigli,Rajkumar Rangadore,Narayana Darapaneni,Anwesh Reddy Paduri*

Main category: cs.LG

TL;DR: SmartFlow是一个多层框架，结合强化学习和智能AI，通过分层策略解决城市共享单车动态再平衡问题，显著减少网络不平衡并优化运营效率。


<details>
  <summary>Details</summary>
Motivation: 解决城市共享单车系统中车辆分布不均的问题，降低闲置时间，提高单车可用性，减少运营成本。

Method: 采用三层架构：战略层使用深度Q网络在模拟环境中学习再平衡策略；战术层优化多段行程和调度；通信层通过基于大语言模型的智能AI将计划转化为可执行指令。

Result: 评估显示SmartFlow能将网络不平衡减少超过95%，同时最小化车队行驶距离并实现高卡车利用率。

Conclusion: SmartFlow为复杂城市交通网络提供了可解释的AI驱动物流蓝图，实现了机器智能与人工操作的有效结合。

Abstract: SmartFlow is a multi-layered framework that integrates Reinforcement Learning and Agentic AI to address the dynamic rebalancing problem in urban bike-sharing services. Its architecture separates strategic, tactical, and communication functions for clarity and scalability. At the strategic level, a Deep Q-Network (DQN) agent, trained in a high-fidelity simulation of New Yorks Citi Bike network, learns robust rebalancing policies by modelling the challenge as a Markov Decision Process. These high-level strategies feed into a deterministic tactical module that optimises multi-leg journeys and schedules just-in-time dispatches to minimise fleet travel. Evaluation across multiple seeded runs demonstrates SmartFlows high efficacy, reducing network imbalance by over 95% while requiring minimal travel distance and achieving strong truck utilisation. A communication layer, powered by a grounded Agentic AI with a Large Language Model (LLM), translates logistical plans into clear, actionable instructions for operational staff, ensuring interpretability and execution readiness. This integration bridges machine intelligence with human operations, offering a scalable solution that reduces idle time, improves bike availability, and lowers operational costs. SmartFlow provides a blueprint for interpretable, AI-driven logistics in complex urban mobility networks.

</details>


### [221] [Quantum Machine Learning Approaches for Coordinated Stealth Attack Detection in Distributed Generation Systems](https://arxiv.org/abs/2601.00873)
*Osasumwen Cedric Ogiesoba-Eguakun,Suman Rath*

Main category: cs.LG

TL;DR: 本文研究了量子机器学习在检测微电网分布式发电单元协同隐蔽攻击中的应用，发现量子特征嵌入与经典RBF支持向量机结合的混合模型在低维数据集上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 协同隐蔽攻击通过修改控制和测量信号来威胁分布式发电系统安全，且因其接近正常行为而难以被标准入侵检测方法发现，需要更先进的检测技术。

Method: 使用高质量模拟测量数据创建包含三个特征的二分类数据集，评估了经典机器学习基线、全量子变分分类器以及混合量子经典模型。

Result: 混合量子经典模型（量子特征嵌入+经典RBF支持向量机）在准确率和F1分数上略优于强经典SVM基线，而全量子模型因训练不稳定和当前NISQ硬件限制表现较差。

Conclusion: 混合模型训练更可靠，证明量子特征映射可以增强入侵检测能力，即使在完全量子学习尚不实用的情况下。

Abstract: Coordinated stealth attacks are a serious cybersecurity threat to distributed generation systems because they modify control and measurement signals while remaining close to normal behavior, making them difficult to detect using standard intrusion detection methods. This study investigates quantum machine learning approaches for detecting coordinated stealth attacks on a distributed generation unit in a microgrid. High-quality simulated measurements were used to create a balanced binary classification dataset using three features: reactive power at DG1, frequency deviation relative to the nominal value, and terminal voltage magnitude. Classical machine learning baselines, fully quantum variational classifiers, and hybrid quantum classical models were evaluated. The results show that a hybrid quantum classical model combining quantum feature embeddings with a classical RBF support vector machine achieves the best overall performance on this low dimensional dataset, with a modest improvement in accuracy and F1 score over a strong classical SVM baseline. Fully quantum models perform worse due to training instability and limitations of current NISQ hardware. In contrast, hybrid models train more reliably and demonstrate that quantum feature mapping can enhance intrusion detection even when fully quantum learning is not yet practical.

</details>


### [222] [LLMize: A Framework for Large Language Model-Based Numerical Optimization](https://arxiv.org/abs/2601.00874)
*M. Rizki Oktavian*

Main category: cs.LG

TL;DR: LLMize是一个开源Python框架，利用大语言模型进行数值优化，通过迭代提示和上下文学习将优化问题转化为黑盒过程。


<details>
  <summary>Details</summary>
Motivation: 大语言模型展现出超越传统语言任务的推理能力，激发了将其用于数值优化的研究动机。

Method: 框架将优化问题建模为黑盒过程：用自然语言生成候选解，通过外部目标函数评估，利用解-分数反馈进行迭代优化。支持多种策略，包括基于提示的优化和受进化算法、模拟退火启发的混合方法。

Result: 在凸优化、线性规划、旅行商问题、神经网络超参数调优和核燃料晶格优化等任务上评估。结果显示，对于简单问题，LLM优化不如经典求解器，但对于复杂、领域特定的任务，特别是约束和启发式难以形式化的情况，提供了实用且易用的方法。

Conclusion: LLMize为复杂优化问题提供了一种基于自然语言的实用框架，特别适用于领域知识难以形式化的场景。

Abstract: Large language models (LLMs) have recently shown strong reasoning capabilities beyond traditional language tasks, motivating their use for numerical optimization. This paper presents LLMize, an open-source Python framework that enables LLM-driven optimization through iterative prompting and in-context learning. LLMize formulates optimization as a black-box process in which candidate solutions are generated in natural language, evaluated by an external objective function, and refined over successive iterations using solution-score feedback. The framework supports multiple optimization strategies, including Optimization by Prompting (OPRO) and hybrid LLM-based methods inspired by evolutionary algorithms and simulated annealing. A key advantage of LLMize is the ability to inject constraints, rules, and domain knowledge directly through natural language descriptions, allowing practitioners to define complex optimization problems without requiring expertise in mathematical programming or metaheuristic design. LLMize is evaluated on convex optimization, linear programming, the Traveling Salesman Problem, neural network hyperparameter tuning, and nuclear fuel lattice optimization. Results show that while LLM-based optimization is not competitive with classical solvers for simple problems, it provides a practical and accessible approach for complex, domain-specific tasks where constraints and heuristics are difficult to formalize.

</details>


### [223] [LearnAD: Learning Interpretable Rules for Brain Networks in Alzheimer's Disease Classification](https://arxiv.org/abs/2601.00877)
*Thomas Andrews,Mark Law,Sara Ahmadi-Abhari,Alessandra Russo*

Main category: cs.LG

TL;DR: LearnAD是一种神经符号方法，用于从脑部MRI数据预测阿尔茨海默病，学习完全可解释的规则。该方法结合统计模型和符号学习，在保持高可解释性的同时达到与纯统计模型相当的性能。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够从脑部MRI数据中学习完全可解释规则的阿尔茨海默病预测方法，解决传统黑盒模型在临床神经科学中缺乏可解释性的问题。

Method: 首先使用统计模型（决策树、随机森林或GNN）识别相关的脑连接，然后应用FastLAS学习全局规则，形成神经符号混合方法。

Result: 最佳实例性能优于决策树，与支持向量机准确率相当，仅略低于使用所有特征的随机森林和GNN，同时保持完全可解释性。消融研究表明神经符号方法在可解释性方面优于纯统计模型。

Conclusion: LearnAD展示了符号学习如何加深对GNN在临床神经科学中行为的理解，为开发可解释的医疗AI模型提供了有效途径。

Abstract: We introduce LearnAD, a neuro-symbolic method for predicting Alzheimer's disease from brain magnetic resonance imaging data, learning fully interpretable rules. LearnAD applies statistical models, Decision Trees, Random Forests, or GNNs to identify relevant brain connections, and then employs FastLAS to learn global rules. Our best instance outperforms Decision Trees, matches Support Vector Machine accuracy, and performs only slightly below Random Forests and GNNs trained on all features, all while remaining fully interpretable. Ablation studies show that our neuro-symbolic approach improves interpretability with comparable performance to pure statistical models. LearnAD demonstrates how symbolic learning can deepen our understanding of GNN behaviour in clinical neuroscience.

</details>


### [224] [Outlier Detection Using Vector Cosine Similarity by Adding a Dimension](https://arxiv.org/abs/2601.00883)
*Zhongyang Shen*

Main category: cs.LG

TL;DR: 提出了一种基于向量余弦相似度的多维异常值检测方法，通过在原数据基础上添加零值维度构建新数据集，利用观测点与测量点之间的向量相似性比较来识别异常数据


<details>
  <summary>Details</summary>
Motivation: 现有多维数据异常检测方法在处理复杂数据分布时存在局限性，需要一种能够有效识别多维空间中异常点的创新方法

Method: 在原数据基础上添加一个零值维度构建新数据集，通过选择测量点并创建观测点（原点），计算从观测点到测量点及其他点的向量余弦相似度进行异常检测

Result: 开发了优化实现MDOD并在PyPI上发布，https://pypi.org/project/mdod/

Conclusion: 该方法提供了一种有效的多维异常检测解决方案，基于向量余弦相似度的比较能够准确识别异常数据点

Abstract: We propose a new outlier detection method for multi-dimensional data. The method detects outliers based on vector cosine similarity, using a new dataset constructed by adding a dimension with zero values to the original data. When a point in the new dataset is selected as the measured point, an observation point is created as the origin, differing only in the new dimension by having a non-zero value compared to the measured point. Vectors are then formed from the observation point to the measured point and to other points in the dataset. By comparing the cosine similarities of these vectors, abnormal data can be identified. An optimized implementation (MDOD) is available on PyPI: https://pypi.org/project/mdod/.

</details>


### [225] [FANoS: Friction-Adaptive Nosé--Hoover Symplectic Momentum for Stiff Objectives](https://arxiv.org/abs/2601.00889)
*Nalin Dhiman*

Main category: cs.LG

TL;DR: FANoS是一种基于物理启发的优化器，结合了动量更新、Nosé–Hoover恒温器变量和半隐式积分器。在Rosenbrock-100D基准测试中表现优于AdamW和SGD，但不如带梯度裁剪的AdamW和L-BFGS。在凸二次问题和PINN任务中表现不稳定。


<details>
  <summary>Details</summary>
Motivation: 受分子动力学中结构保持积分和恒温器思想的启发，开发一种新的优化启发式方法，特别适用于刚性非凸谷问题。

Method: 结合三个组件：(i) 离散二阶动力系统的动量更新；(ii) 使用动能反馈自适应调整摩擦系数的Nosé–Hoover恒温器变量；(iii) 半隐式积分器，可选配对角RMS预处理器。

Result: 在Rosenbrock-100D基准测试中，FANoS-RMS达到1.74×10⁻²，优于AdamW(48.50)和SGD+momentum(90.76)，但不如带梯度裁剪的AdamW(1.87×10⁻³)和L-BFGS(4.4×10⁻¹⁰)。在病态凸二次问题和PINN任务中表现不佳。

Conclusion: FANoS是现有思想的可解释性综合，在某些刚性非凸谷问题上有帮助，但不是现代基线的通用替代品，其行为对温度调度和超参数选择敏感。

Abstract: We study a physics-inspired optimizer, \emph{FANoS} (Friction-Adaptive Nosé--Hoover Symplectic momentum), which combines (i) a momentum update written as a discretized second-order dynamical system, (ii) a Nosé--Hoover-like thermostat variable that adapts a scalar friction coefficient using kinetic-energy feedback, and (iii) a semi-implicit (symplectic-Euler) integrator, optionally with a diagonal RMS preconditioner. The method is motivated by structure-preserving integration and thermostat ideas from molecular dynamics, but is used here purely as an optimization heuristic.
  We provide the algorithm and limited theoretical observations in idealized settings. On the deterministic Rosenbrock-100D benchmark with 3000 gradient evaluations, FANoS-RMS attains a mean final objective value of $1.74\times 10^{-2}$, improving substantially over unclipped AdamW ($48.50$) and SGD+momentum ($90.76$) in this protocol. However, AdamW with gradient clipping is stronger, reaching $1.87\times 10^{-3}$, and L-BFGS reaches $\approx 4.4\times 10^{-10}$. On ill-conditioned convex quadratics and in a small PINN warm-start suite (Burgers and Allen--Cahn), the default FANoS configuration underperforms AdamW and can be unstable or high-variance.
  Overall, the evidence supports a conservative conclusion: FANoS is an interpretable synthesis of existing ideas that can help on some stiff nonconvex valleys, but it is not a generally superior replacement for modern baselines, and its behavior is sensitive to temperature-schedule and hyperparameter choices.

</details>


### [226] [Hierarchical topological clustering](https://arxiv.org/abs/2601.00892)
*Ana Carpio,Gema Duro*

Main category: cs.LG

TL;DR: 提出了一种分层拓扑聚类算法，无需对数据结构做假设，适用于任意距离选择，能够识别异常值和任意形状的聚类。


<details>
  <summary>Details</summary>
Motivation: 拓扑方法能够在不假设数据结构的情况下探索数据云，现有技术在某些情况下无法提供有意义的聚类。

Method: 分层拓扑聚类算法，可应用于任何距离选择，通过生成的层次结构推断异常值和任意形状聚类的持久性。

Result: 在包含图像、医疗和经济数据的选定数据集上验证了算法的潜力，这些数据中异常值起着重要作用。

Conclusion: 该方法在其他技术失败的情况下仍能提供有意义的聚类，展示了拓扑方法在复杂数据场景中的优势。

Abstract: Topological methods have the potential of exploring data clouds without making assumptions on their the structure. Here we propose a hierarchical topological clustering algorithm that can be implemented with any distance choice. The persistence of outliers and clusters of arbitrary shape is inferred from the resulting hierarchy. We demonstrate the potential of the algorithm on selected datasets in which outliers play relevant roles, consisting of images, medical and economic data. These methods can provide meaningful clusters in situations in which other techniques fail to do so.

</details>


### [227] [When to Ponder: Adaptive Compute Allocation for Code Generation via Test-Time Training](https://arxiv.org/abs/2601.00894)
*Gihyeon Sim*

Main category: cs.LG

TL;DR: PonderTTT是一种基于TTT层自监督重建损失的门控策略，用于选择性触发测试时训练更新，无需训练即可实现高效的推理时适应。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型对所有输入应用统一计算，不考虑难度差异。需要一种无需训练的门控机制来智能选择何时进行测试时训练更新。

Method: 使用TTT层的自监督重建损失作为门控信号，仅需单个标量阈值进行初始校准，并通过指数移动平均持续适应以维持目标更新率。无需学习分类器或辅助网络。

Result: 在GPT-2模型（124M到1.5B）的代码语言建模实验中，重建门控达到82-89%的Oracle恢复率，显著优于随机跳过基线（在OOD语言上损失降低达16%）。

Conclusion: PonderTTT提供了一种推理兼容、完全无需训练的门控方法，能够有效识别需要测试时训练更新的输入，提高模型在分布外数据上的性能。

Abstract: Large language models apply uniform computation to all inputs, regardless of difficulty. We propose PonderTTT, a gating strategy using the TTT layer's self-supervised reconstruction loss to selectively trigger Test-Time Training (TTT) updates. The gating decision itself is training-free--requiring no learned classifier or auxiliary networks; only a single scalar threshold is initially calibrated on unlabeled data and continuously adapted via EMA to maintain target update rates. Our experiments with GPT-2 models (124M to 1.5B) on code language modeling (The Stack v2, teacher-forced perplexity) demonstrate that this signal is inference-compatible, requiring no ground-truth labels. Our Reconstruction Gating achieves 82-89% Oracle Recovery while being fully training-free, significantly outperforming Random Skip baselines (up to 16% lower loss on OOD languages).

</details>


### [228] [Dichotomous Diffusion Policy Optimization](https://arxiv.org/abs/2601.00898)
*Ruiming Liang,Yinan Zheng,Kexin Zheng,Tianyi Tan,Jianxiong Li,Liyuan Mao,Zhihao Wang,Guang Chen,Hangjun Ye,Jingjing Liu,Jinqiao Wang,Xianyuan Zhan*

Main category: cs.LG

TL;DR: DIPOLE是一种新颖的强化学习算法，通过分解策略为奖励最大化和最小化两部分，实现稳定可控的扩散策略优化


<details>
  <summary>Details</summary>
Motivation: 现有扩散策略训练方法存在训练不稳定或计算效率低的问题，需要一种稳定且可控的扩散策略优化方法

Method: 提出贪婪化策略正则化方案，将最优策略分解为一对稳定学习的二分策略，通过线性组合策略分数实现灵活控制

Result: 在ExORL和OGBench基准测试中表现优异，并在自动驾驶任务中验证了其处理复杂现实应用的能力

Conclusion: DIPOLE为扩散策略提供了稳定高效的训练框架，在离线强化学习和复杂现实任务中展现出强大潜力

Abstract: Diffusion-based policies have gained growing popularity in solving a wide range of decision-making tasks due to their superior expressiveness and controllable generation during inference. However, effectively training large diffusion policies using reinforcement learning (RL) remains challenging. Existing methods either suffer from unstable training due to directly maximizing value objectives, or face computational issues due to relying on crude Gaussian likelihood approximation, which requires a large amount of sufficiently small denoising steps. In this work, we propose DIPOLE (Dichotomous diffusion Policy improvement), a novel RL algorithm designed for stable and controllable diffusion policy optimization. We begin by revisiting the KL-regularized objective in RL, which offers a desirable weighted regression objective for diffusion policy extraction, but often struggles to balance greediness and stability. We then formulate a greedified policy regularization scheme, which naturally enables decomposing the optimal policy into a pair of stably learned dichotomous policies: one aims at reward maximization, and the other focuses on reward minimization. Under such a design, optimized actions can be generated by linearly combining the scores of dichotomous policies during inference, thereby enabling flexible control over the level of greediness.Evaluations in offline and offline-to-online RL settings on ExORL and OGBench demonstrate the effectiveness of our approach. We also use DIPOLE to train a large vision-language-action (VLA) model for end-to-end autonomous driving (AD) and evaluate it on the large-scale real-world AD benchmark NAVSIM, highlighting its potential for complex real-world applications.

</details>


### [229] [Conformal Prediction Under Distribution Shift: A COVID-19 Natural Experiment](https://arxiv.org/abs/2601.00908)
*Chorok Lee*

Main category: cs.LG

TL;DR: 该研究分析了分布偏移下保形预测的性能退化问题，发现特征重要性集中度是预测失败的关键因素，并提出基于SHAP集中度的决策框架来指导模型部署和重训练策略。


<details>
  <summary>Details</summary>
Motivation: 保形预测在分布偏移下的性能保证会下降，但不同任务间的性能退化程度差异很大，需要理解这种差异的原因并制定有效的应对策略。

Method: 使用COVID-19作为自然实验，分析8个供应链任务在严重特征变化（Jaccard约等于0）下的表现。通过SHAP分析特征重要性分布，并测试季度重训练的效果。

Result: 覆盖率的下降幅度从0%到86.7%不等，与单特征依赖性显著相关（rho=0.714, p=0.047）。特征重要性集中的任务覆盖率从22%提升到41%，而稳健任务保持99.8%覆盖率。

Conclusion: 特征稳定性而非集中度决定模型鲁棒性，特征集中度效应主要适用于严重分布偏移。建议在部署前监控SHAP集中度，对脆弱任务（>40%集中度）进行季度重训练，对稳健任务可跳过重训练。

Abstract: Conformal prediction guarantees degrade under distribution shift. We study this using COVID-19 as a natural experiment across 8 supply chain tasks. Despite identical severe feature turnover (Jaccard approximately 0), coverage drops vary from 0% to 86.7%, spanning two orders of magnitude. Using SHapley Additive exPlanations (SHAP) analysis, we find catastrophic failures correlate with single-feature dependence (rho = 0.714, p = 0.047). Catastrophic tasks concentrate importance in one feature (4.5x increase), while robust tasks redistribute across many (10-20x). Quarterly retraining restores catastrophic task coverage from 22% to 41% (+19 pp, p = 0.04), but provides no benefit for robust tasks (99.8% coverage). Exploratory analysis of 4 additional tasks with moderate feature stability (Jaccard 0.13-0.86) reveals feature stability, not concentration, determines robustness, suggesting concentration effects apply specifically to severe shifts. We provide a decision framework: monitor SHAP concentration before deployment; retrain quarterly if vulnerable (>40% concentration); skip retraining if robust.

</details>


### [230] [Latent-Constrained Conditional VAEs for Augmenting Large-Scale Climate Ensembles](https://arxiv.org/abs/2601.00915)
*Jacquelyn Shelton,Przemyslaw Polewski,Alexander Robel,Matthew Hoffman,Stephen Price*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large climate-model ensembles are computationally expensive; yet many downstream analyses would benefit from additional, statistically consistent realizations of spatiotemporal climate variables. We study a generative modeling approach for producing new realizations from a limited set of available runs by transferring structure learned across an ensemble. Using monthly near-surface temperature time series from ten independent reanalysis realizations (ERA5), we find that a vanilla conditional variational autoencoder (CVAE) trained jointly across realizations yields a fragmented latent space that fails to generalize to unseen ensemble members. To address this, we introduce a latent-constrained CVAE (LC-CVAE) that enforces cross-realization homogeneity of latent embeddings at a small set of shared geographic 'anchor' locations. We then use multi-output Gaussian process regression in the latent space to predict latent coordinates at unsampled locations in a new realization, followed by decoding to generate full time series fields. Experiments and ablations demonstrate (i) instability when training on a single realization, (ii) diminishing returns after incorporating roughly five realizations, and (iii) a trade-off between spatial coverage and reconstruction quality that is closely linked to the average neighbor distance in latent space.

</details>


### [231] [Attention Needs to Focus: A Unified Perspective on Attention Allocation](https://arxiv.org/abs/2601.00919)
*Zichuan Fu,Wentao Song,Guojing Li,Yejing Wang,Xian Wu,Yimin Deng,Hanyu Yan,Yefeng Zheng,Xiangyu Zhao*

Main category: cs.LG

TL;DR: 本文提出Lazy Attention机制，通过统一视角解决Transformer注意力机制中的过载和欠载问题，实现更聚焦的注意力分布，在多个基准测试中取得竞争性性能并达到59.58%的注意力稀疏度。


<details>
  <summary>Details</summary>
Motivation: 标准注意力机制存在表征崩溃和注意力下沉问题，现有研究孤立看待这些问题。本文认为两者都源于注意力分配不当，需要统一的解决方案。

Method: 提出Lazy Attention机制：1）通过位置区分缓解注意力过载问题；2）使用Elastic-Softmax归一化函数解决注意力欠载问题，抑制无关令牌的注意力。

Result: 在FineWeb-Edu语料库的九个基准测试中，Lazy Attention成功缓解了注意力下沉问题，性能与标准注意力和现代架构相当，注意力稀疏度达到59.58%。

Conclusion: Lazy Attention提供了一个统一的解决方案，有效解决了注意力机制的两个核心问题，为Transformer架构的改进提供了新思路。

Abstract: The Transformer architecture, a cornerstone of modern Large Language Models (LLMs), has achieved extraordinary success in sequence modeling, primarily due to its attention mechanism. However, despite its power, the standard attention mechanism is plagued by well-documented issues: representational collapse and attention sink. Although prior work has proposed approaches for these issues, they are often studied in isolation, obscuring their deeper connection. In this paper, we present a unified perspective, arguing that both can be traced to a common root -- improper attention allocation. We identify two failure modes: 1) Attention Overload, where tokens receive comparable high weights, blurring semantic features that lead to representational collapse; 2) Attention Underload, where no token is semantically relevant, yet attention is still forced to distribute, resulting in spurious focus such as attention sink. Building on this insight, we introduce Lazy Attention, a novel mechanism designed for a more focused attention distribution. To mitigate overload, it employs positional discrimination across both heads and dimensions to sharpen token distinctions. To counteract underload, it incorporates Elastic-Softmax, a modified normalization function that relaxes the standard softmax constraint to suppress attention on irrelevant tokens. Experiments on the FineWeb-Edu corpus, evaluated across nine diverse benchmarks, demonstrate that Lazy Attention successfully mitigates attention sink and achieves competitive performance compared to both standard attention and modern architectures, while reaching up to 59.58% attention sparsity.

</details>


### [232] [MODE: Efficient Time Series Prediction with Mamba Enhanced by Low-Rank Neural ODEs](https://arxiv.org/abs/2601.00920)
*Xingsheng Chen,Regina Zhang,Bo Gao,Xingwei He,Xiaofeng Liu,Pietro Lio,Kwok-Yan Lam,Siu-Ming Yiu*

Main category: cs.LG

TL;DR: MODE是一个统一的时间序列预测框架，结合低秩神经常微分方程和增强型Mamba架构，旨在解决长程依赖和不规则采样数据的效率、可扩展性和准确性平衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列预测方法在长程依赖和不规则采样数据上难以平衡效率、可扩展性和准确性，需要更有效的解决方案。

Method: 提出MODE框架：使用线性标记化层处理输入序列，通过多个Mamba编码器块（包含因果卷积、SiLU激活和低秩神经ODE增强）捕捉时间动态，采用分段选择性扫描机制自适应关注重要子序列。

Result: 在基准数据集上的广泛实验表明，MODE在预测准确性和计算效率方面均优于现有基线方法。

Conclusion: MODE通过低秩近似和动态选择性扫描实现了效率和可扩展性的显著提升，为长期时间序列建模提供了统一高效的架构。

Abstract: Time series prediction plays a pivotal role across diverse domains such as finance, healthcare, energy systems, and environmental modeling. However, existing approaches often struggle to balance efficiency, scalability, and accuracy, particularly when handling long-range dependencies and irregularly sampled data. To address these challenges, we propose MODE, a unified framework that integrates Low-Rank Neural Ordinary Differential Equations (Neural ODEs) with an Enhanced Mamba architecture. As illustrated in our framework, the input sequence is first transformed by a Linear Tokenization Layer and then processed through multiple Mamba Encoder blocks, each equipped with an Enhanced Mamba Layer that employs Causal Convolution, SiLU activation, and a Low-Rank Neural ODE enhancement to efficiently capture temporal dynamics. This low-rank formulation reduces computational overhead while maintaining expressive power. Furthermore, a segmented selective scanning mechanism, inspired by pseudo-ODE dynamics, adaptively focuses on salient subsequences to improve scalability and long-range sequence modeling. Extensive experiments on benchmark datasets demonstrate that MODE surpasses existing baselines in both predictive accuracy and computational efficiency. Overall, our contributions include: (1) a unified and efficient architecture for long-term time series modeling, (2) integration of Mamba's selective scanning with low-rank Neural ODEs for enhanced temporal representation, and (3) substantial improvements in efficiency and scalability enabled by low-rank approximation and dynamic selective scanning.

</details>


### [233] [Practical Geometric and Quantum Kernel Methods for Predicting Skeletal Muscle Outcomes in chronic obstructive pulmonary disease](https://arxiv.org/abs/2601.00921)
*Azadeh Alavi,Hamidreza Khalili,Stanley H. Chan,Fatemeh Kouchmeshki,Ross Vlahos*

Main category: cs.LG

TL;DR: 该研究开发了基于几何和量子核方法的预测模型，用于从血液和支气管肺泡灌洗液生物标志物预测COPD相关的骨骼肌功能障碍，在低数据量、低特征数的生物医学预测问题中取得了优于传统方法的性能。


<details>
  <summary>Details</summary>
Motivation: 骨骼肌功能障碍是COPD的重要肺外表现，与全身和气道炎症密切相关。研究旨在开发基于微创生物标志物的预测模型，用于纵向监测肌肉功能变化。

Method: 使用213只动物的临床前数据集，比较了调优的经典基线模型、几何感知的对称正定描述符（基于Stein散度）以及专为低维表格数据设计的量子核模型。

Result: 在肌肉重量预测中，量子核岭回归使用4个可解释输入（血液C反应蛋白、中性粒细胞计数、支气管肺泡灌洗细胞数和条件）取得了测试RMSE为4.41 mg和R²为0.605，优于相同特征集的岭回归基线（4.70 mg和0.553）。几何方法在仅使用生物标志物的设置中也表现更好。

Conclusion: 几何和量子核提升方法在低数据量、低特征数的生物医学预测问题中能提供可测量的优势，同时保持了可解释性和透明的模型选择。

Abstract: Skeletal muscle dysfunction is a clinically relevant extra-pulmonary manifestation of chronic obstructive pulmonary disease (COPD) and is closely linked to systemic and airway inflammation. This motivates predictive modelling of muscle outcomes from minimally invasive biomarkers that can be acquired longitudinally. We study a small-sample preclinical dataset comprising 213 animals across two conditions (Sham versus cigarette-smoke exposure), with blood and bronchoalveolar lavage fluid measurements and three continuous targets: tibialis anterior muscle weight (milligram: mg), specific force (millinewton: mN), and a derived muscle quality index (mN per mg). We benchmark tuned classical baselines, geometry-aware symmetric positive definite (SPD) descriptors with Stein divergence, and quantum kernel models designed for low-dimensional tabular data. In the muscle-weight setting, quantum kernel ridge regression using four interpretable inputs (blood C-reactive protein, neutrophil count, bronchoalveolar lavage cellularity, and condition) attains a test root mean squared error of 4.41 mg and coefficient of determination of 0.605, improving over a matched ridge baseline on the same feature set (4.70 mg and 0.553). Geometry-informed Stein-divergence prototype distances yield a smaller but consistent gain in the biomarker-only setting (4.55 mg versus 4.79 mg). Screening-style evaluation, obtained by thresholding the continuous outcome at 0.8 times the training Sham mean, achieves an area under the receiver operating characteristic curve (ROC-AUC) of up to 0.90 for detecting low muscle weight. These results indicate that geometric and quantum kernel lifts can provide measurable benefits in low-data, low-feature biomedical prediction problems, while preserving interpretability and transparent model selection.

</details>


### [234] [Complexity-based code embeddings](https://arxiv.org/abs/2601.00924)
*Rares Folea,Radu Iacob,Emil Slusanschi,Traian Rebedea*

Main category: cs.LG

TL;DR: 本文提出了一种将算法源代码转换为数值嵌入的通用方法，通过动态分析程序在不同输入下的行为，并为分析指标定制多个通用复杂度函数。使用基于r-Complexity的算法嵌入，在Codeforces平台的真实代码片段数据集上实现了XGBoost算法的多标签分类，取得了平均F1分数。


<details>
  <summary>Details</summary>
Motivation: 开发一种通用的代码嵌入方法，能够将不同算法的源代码转换为数值表示，以便进行机器学习分析。

Method: 通过动态分析程序行为，针对不同输入定制复杂度函数，使用r-Complexity基础构建算法嵌入，并应用XGBoost算法进行多标签分类。

Result: 在包含11个类别的多标签数据集上（基于Codeforces平台的真实代码片段），实现了较好的平均F1分数。

Conclusion: 提出的代码嵌入方法能够有效表征算法特征，为代码分析和机器学习应用提供了可行的解决方案。

Abstract: This paper presents a generic method for transforming the source code of various algorithms to numerical embeddings, by dynamically analysing the behaviour of computer programs against different inputs and by tailoring multiple generic complexity functions for the analysed metrics. The used algorithms embeddings are based on r-Complexity . Using the proposed code embeddings, we present an implementation of the XGBoost algorithm that achieves an average F1-score on a multi-label dataset with 11 classes, built using real-world code snippets submitted for programming competitions on the Codeforces platform.

</details>


### [235] [Enhanced Data-Driven Product Development via Gradient Based Optimization and Conformalized Monte Carlo Dropout Uncertainty Estimation](https://arxiv.org/abs/2601.00932)
*Andrea Thomas Nava,Lijo Johny,Fabio Azzalini,Johannes Schneider,Arianna Casanova*

Main category: cs.LG

TL;DR: 提出了一种结合联合神经网络和不确定性估计的数据驱动产品开发框架，通过投影梯度下降优化设计参数，使用ConfMC方法提供模型无关的有限样本覆盖保证。


<details>
  <summary>Details</summary>
Motivation: 解决多目标产品开发中相关属性的同时优化问题，并提供可靠的预测不确定性估计，避免调整覆盖水平时的重复训练需求。

Method: 训练神经网络学习设计规格与产品属性的关系，使用投影梯度下降优化输入特征，采用联合神经网络处理多目标相关性，集成ConfMC方法进行不确定性估计。

Result: 在五个真实数据集上的实验表明，该方法在保持最先进性能的同时，能提供自适应非均匀预测区间，且无需重新训练即可调整覆盖水平。

Conclusion: 该框架成功实现了多目标产品优化的数据驱动方法，通过ConfMC技术提供了可靠的预测不确定性，具有实际应用价值。

Abstract: Data-Driven Product Development (DDPD) leverages data to learn the relationship between product design specifications and resulting properties. To discover improved designs, we train a neural network on past experiments and apply Projected Gradient Descent to identify optimal input features that maximize performance. Since many products require simultaneous optimization of multiple correlated properties, our framework employs joint neural networks to capture interdependencies among targets. Furthermore, we integrate uncertainty estimation via \emph{Conformalised Monte Carlo Dropout} (ConfMC), a novel method combining Nested Conformal Prediction with Monte Carlo dropout to provide model-agnostic, finite-sample coverage guarantees under data exchangeability. Extensive experiments on five real-world datasets show that our method matches state-of-the-art performance while offering adaptive, non-uniform prediction intervals and eliminating the need for retraining when adjusting coverage levels.

</details>


### [236] [LOFA: Online Influence Maximization under Full-Bandit Feedback using Lazy Forward Selection](https://arxiv.org/abs/2601.00933)
*Jinyu Xu,Abhishek K. Umrawal*

Main category: cs.LG

TL;DR: 本文提出了一种名为LOFA（Lazy Online Forward Algorithm）的在线影响力最大化算法，在完全强盗反馈模型下实现了更低的经验遗憾。


<details>
  <summary>Details</summary>
Motivation: 现有的在线影响力最大化算法虽然利用了影响函数的子模性来降低遗憾，但在实际性能上仍有提升空间。本文旨在进一步利用子模性特性，设计更高效的在线算法。

Method: 提出了LOFA算法，该算法在完全强盗反馈模型下运行，仅观测每个时间步选择的种子集的影响，无需网络或扩散过程的结构信息。算法充分利用了影响函数的子模性特性。

Result: 在真实社交网络上的实验表明，LOFA在累积遗憾和瞬时奖励方面均优于现有的强盗算法，表现出更优越的性能。

Conclusion: LOFA算法通过更好地利用影响函数的子模性，在在线影响力最大化问题上实现了更低的经验遗憾，为实际应用提供了有效的解决方案。

Abstract: We study the problem of influence maximization (IM) in an online setting, where the goal is to select a subset of nodes$\unicode{x2014}$called the seed set$\unicode{x2014}$at each time step over a fixed time horizon, subject to a cardinality budget constraint, to maximize the expected cumulative influence. We operate under a full-bandit feedback model, where only the influence of the chosen seed set at each time step is observed, with no additional structural information about the network or diffusion process. It is well-established that the influence function is submodular, and existing algorithms exploit this property to achieve low regret. In this work, we leverage this property further and propose the Lazy Online Forward Algorithm (LOFA), which achieves a lower empirical regret. We conduct experiments on a real-world social network to demonstrate that LOFA achieves superior performance compared to existing bandit algorithms in terms of cumulative regret and instantaneous reward.

</details>


### [237] [Contractive Diffusion Policies: Robust Action Diffusion via Contractive Score-Based Sampling with Differential Equations](https://arxiv.org/abs/2601.01003)
*Amin Abyaneh,Charlotte Morissette,Mohamad H. Danesh,Anas El Houssaini,David Meger,Gregory Dudek,Hsiu-Chin Lin*

Main category: cs.LG

TL;DR: 本文提出了收缩扩散策略（CDPs），通过在扩散采样过程中引入收缩行为来增强离线策略学习的鲁棒性，减少求解器和分数匹配误差的影响。


<details>
  <summary>Details</summary>
Motivation: 扩散策略在离线策略学习中表现出强大能力，但其基于分数的随机微分方程建模会导致求解器和分数匹配误差、大数据需求以及动作生成不一致等问题，这些问题在连续控制设置中会累积并导致失败。

Method: 通过诱导扩散采样动态中的收缩行为，将邻近的流拉近以增强对误差的鲁棒性，同时减少不必要的动作方差。开发了理论分析框架和实际实现方法，可以最小化修改和计算成本地集成到现有扩散策略架构中。

Result: 在模拟和真实世界环境中进行的广泛实验表明，CDPs在基准测试中通常优于基线策略，在数据稀缺情况下表现出更明显的优势。

Conclusion: CDPs通过引入收缩机制有效解决了扩散策略在连续控制中的误差累积问题，提高了策略的鲁棒性和性能，特别是在数据有限的情况下。

Abstract: Diffusion policies have emerged as powerful generative models for offline policy learning, whose sampling process can be rigorously characterized by a score function guiding a Stochastic Differential Equation (SDE). However, the same score-based SDE modeling that grants diffusion policies the flexibility to learn diverse behavior also incurs solver and score-matching errors, large data requirements, and inconsistencies in action generation. While less critical in image generation, these inaccuracies compound and lead to failure in continuous control settings. We introduce Contractive Diffusion Policies (CDPs) to induce contractive behavior in the diffusion sampling dynamics. Contraction pulls nearby flows closer to enhance robustness against solver and score-matching errors while reducing unwanted action variance. We develop an in-depth theoretical analysis along with a practical implementation recipe to incorporate CDPs into existing diffusion policy architectures with minimal modification and computational cost. We evaluate CDPs for offline learning by conducting extensive experiments in simulation and real-world settings. Across benchmarks, CDPs often outperform baseline policies, with pronounced benefits under data scarcity.

</details>


### [238] [Reliability Under Randomness: An Empirical Analysis of Sparse and Dense Language Models Across Decoding Temperatures](https://arxiv.org/abs/2601.00942)
*Kabir Grover*

Main category: cs.LG

TL;DR: 该研究探讨了稀疏MoE架构在随机解码下的可靠性问题，发现指令调优而非架构稀疏性是决定模型在确定性任务中对解码随机性鲁棒性的主要因素。


<details>
  <summary>Details</summary>
Motivation: 随着稀疏MoE架构在大型语言模型中的普及，需要了解其在随机解码下的可靠性。虽然条件计算提高了计算效率，但稀疏路由与基于温度的采样之间的相互作用是否会损害输出稳定性尚不清楚。

Method: 评估了三个代表性模型：OLMoE-7B（稀疏基础）、Mixtral-8x7B（稀疏指令调优）和Qwen2.5-3B（密集指令调优），在确定性算术推理任务上进行测试，涵盖四种解码配置（从贪婪解码到T=1.0），共9360次模型生成。

Result: 稀疏指令调优模型在所有解码温度下表现出与密集指令调优模型相当的稳定性，而稀疏基础模型随着温度升高出现系统性退化。

Conclusion: 指令调优而非架构稀疏性是决定模型在确定性任务中对解码随机性鲁棒性的主要因素，这对在可靠性关键应用中部署稀疏语言模型具有重要意义。

Abstract: The increasing prevalence of sparse Mixture-of-Experts (MoE) architectures in large language models raises important questions regarding their reliability under stochastic decoding. While conditional computation enables substantial gains in computational efficiency, it remains unclear whether the interaction between sparse routing and temperature-based sampling compromises output stability relative to dense architectures. This work investigates whether conditional computation in MoE models amplifies decoding-induced randomness, leading to reduced reliability as temperature increases. We evaluate three representative models: OLMoE-7B (sparse base), Mixtral-8x7B (sparse instruction-tuned), and Qwen2.5-3B (dense instruction-tuned) on deterministic arithmetic reasoning tasks with objectively verifiable answers. Experiments span four decoding configurations, ranging from greedy decoding to T=1.0. Our evaluation encompasses accuracy, format compliance, output consistency across repeated generations, and confidence metrics, totaling 9,360 model generations. Results demonstrate that the sparse instruction-tuned model exhibits stability comparable to the dense instruction-tuned model across all decoding temperatures, while the sparse base model shows systematic degradation as temperature increases. These findings indicate that instruction tuning, rather than architectural sparsity, is the primary determinant of robustness to decoding randomness on deterministic tasks. We discuss the implications of these results for deploying sparse language models in reliability-critical applications, highlighting scenarios in which sparse architectures can be safely adopted without sacrificing output stability.

</details>


### [239] [Adapting Feature Attenuation to NLP](https://arxiv.org/abs/2601.00965)
*Tianshuo Yang,Ryan Rabinowitz,Terrance E. Boult,Jugal Kalita*

Main category: cs.LG

TL;DR: 该研究将计算机视觉中的开放集识别方法COSTARR框架移植到NLP领域的Transformer模型（BERT和GPT-2），在176个arXiv主题分类任务上评估开放集识别性能，发现COSTARR在NLP中可直接应用但相比MaxLogit和MSP方法无显著优势。


<details>
  <summary>Details</summary>
Motivation: Transformer分类器在封闭集上表现优异，但在面对未见类别时表现脆弱，这是实际部署NLP系统的常见场景。研究旨在探索文本领域的开放集识别方法。

Method: 将计算机视觉中的COSTARR框架适配到BERT和GPT-2模型，在176个arXiv主题分类任务上，与MSP、MaxLogit和温度缩放自由能评分等方法进行对比评估，使用OOSA和AUOSCR指标。

Result: COSTARR可直接应用于NLP无需重新训练，但在统计上未显著优于MaxLogit或MSP；自由能评分在高类别数设置下表现最差。

Conclusion: 研究显示了将视觉中心OSR思想移植到语言模型的潜力与当前局限性，指出需要更大的骨干网络和任务特定的衰减策略。

Abstract: Transformer classifiers such as BERT deliver impressive closed-set accuracy, yet they remain brittle when confronted with inputs from unseen categories--a common scenario for deployed NLP systems. We investigate Open-Set Recognition (OSR) for text by porting the feature attenuation hypothesis from computer vision to transformers and by benchmarking it against state-of-the-art baselines. Concretely, we adapt the COSTARR framework--originally designed for classification in computer vision--to two modest language models (BERT (base) and GPT-2) trained to label 176 arXiv subject areas. Alongside COSTARR, we evaluate Maximum Softmax Probability (MSP), MaxLogit, and the temperature-scaled free-energy score under the OOSA and AUOSCR metrics. Our results show (i) COSTARR extends to NLP without retraining but yields no statistically significant gain over MaxLogit or MSP, and (ii) free-energy lags behind all other scores in this high-class-count setting. The study highlights both the promise and the current limitations of transplanting vision-centric OSR ideas to language models, and points toward the need for larger backbones and task-tailored attenuation strategies.

</details>


### [240] [Explainability-Guided Defense: Attribution-Aware Model Refinement Against Adversarial Data Attacks](https://arxiv.org/abs/2601.00968)
*Longwei Wang,Mohammad Navid Nayyem,Abdullah Al Rakin,KC Santosh,Chaowei Zhang,Yang Zhou*

Main category: cs.LG

TL;DR: 本文提出了一种基于LIME解释性分析的对抗鲁棒性训练框架，通过抑制虚假特征来同时提升模型的可解释性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在安全关键领域的应用日益广泛，需要同时具备对抗鲁棒性和决策透明度。研究发现虚假特征与对抗脆弱性密切相关。

Method: 提出属性引导的精炼框架，将LIME从被动诊断工具转变为主动训练信号，通过特征掩码、敏感度感知正则化和对抗增强来抑制虚假特征。

Result: 在CIFAR-10、CIFAR-10-C和CIFAR-100数据集上的实验表明，该方法显著提升了对抗鲁棒性和分布外泛化能力。

Conclusion: 该方法建立了可解释性与鲁棒性之间的理论联系，提供了一种无需额外数据或架构修改的实用防御方案。

Abstract: The growing reliance on deep learning models in safety-critical domains such as healthcare and autonomous navigation underscores the need for defenses that are both robust to adversarial perturbations and transparent in their decision-making. In this paper, we identify a connection between interpretability and robustness that can be directly leveraged during training. Specifically, we observe that spurious, unstable, or semantically irrelevant features identified through Local Interpretable Model-Agnostic Explanations (LIME) contribute disproportionately to adversarial vulnerability. Building on this insight, we introduce an attribution-guided refinement framework that transforms LIME from a passive diagnostic into an active training signal. Our method systematically suppresses spurious features using feature masking, sensitivity-aware regularization, and adversarial augmentation in a closed-loop refinement pipeline. This approach does not require additional datasets or model architectures and integrates seamlessly into standard adversarial training. Theoretically, we derive an attribution-aware lower bound on adversarial distortion that formalizes the link between explanation alignment and robustness. Empirical evaluations on CIFAR-10, CIFAR-10-C, and CIFAR-100 demonstrate substantial improvements in adversarial robustness and out-of-distribution generalization.

</details>


### [241] [Zero-shot Forecasting by Simulation Alone](https://arxiv.org/abs/2601.00970)
*Boris N. Oreshkin,Mayank Jauhari,Ravi Kiran Selvam,Malcolm Wolff,Wenhao Pan,Shankar Ramasubramanian,Kin G. Olivares,Tatiana Konstantinova,Andres Potapczynski,Mengfei Cao,Dmitry Efimov,Michael W. Mahoney,Andrew G. Wilson*

Main category: cs.LG

TL;DR: 该论文提出了SarSim0，首个实用的单变量时间序列模拟管道，基于SARIMA模型，通过三步法生成高质量模拟数据，实现了显著的零样本预测性能，在M-Series和GiftEval基准测试中超越传统统计方法和现有基础模型。


<details>
  <summary>Details</summary>
Motivation: 解决零样本时间序列预测面临的挑战：有限且偏置的数据集、易泄露的评估方法、隐私和许可限制，需要一种能够快速生成高质量模拟数据的实用方法。

Method: 基于SARIMA模型的三步模拟流程：1) 从特征多项式稳定区域采样良好轨迹；2) 通过叠加方案组合多个路径生成多季节性轨迹；3) 添加基于速率的重尾噪声模型捕捉突发性和间歇性。

Result: SarSim0比基于核的生成器快数个数量级，能够训练约10亿个纯模拟序列，在零样本协议下，神经网络骨干模型表现出强大的泛化能力，超越了强统计预测器和近期基础基线。在GiftEval上观察到"学生超越教师"效应。

Conclusion: SarSim0提供了一个实用且高效的时间序列模拟解决方案，显著推动了零样本时间序列预测的发展，为工业应用中的趋势/季节性/间歇性模式预测提供了有效工具。

Abstract: Zero-shot time-series forecasting holds great promise, but is still in its infancy, hindered by limited and biased data corpora, leakage-prone evaluation, and privacy and licensing constraints. Motivated by these challenges, we propose the first practical univariate time series simulation pipeline which is simultaneously fast enough for on-the-fly data generation and enables notable zero-shot forecasting performance on M-Series and GiftEval benchmarks that capture trend/seasonality/intermittency patterns, typical of industrial forecasting applications across a variety of domains. Our simulator, which we call SarSim0 (SARIMA Simulator for Zero-Shot Forecasting), is based off of a seasonal autoregressive integrated moving average (SARIMA) model as its core data source. Due to instability in the autoregressive component, naive SARIMA simulation often leads to unusable paths. Instead, we follow a three-step procedure: (1) we sample well-behaved trajectories from its characteristic polynomial stability region; (2) we introduce a superposition scheme that combines multiple paths into rich multi-seasonality traces; and (3) we add rate-based heavy-tailed noise models to capture burstiness and intermittency alongside seasonalities and trends. SarSim0 is orders of magnitude faster than kernel-based generators, and it enables training on circa 1B unique purely simulated series, generated on the fly; after which well-established neural network backbones exhibit strong zero-shot generalization, surpassing strong statistical forecasters and recent foundation baselines, while operating under strict zero-shot protocol. Notably, on GiftEval we observe a "student-beats-teacher" effect: models trained on our simulations exceed the forecasting accuracy of the AutoARIMA generating processes.

</details>


### [242] [Data-Driven Assessment of Concrete Mixture Compositions on Chloride Transport via Standalone Machine Learning Algorithms](https://arxiv.org/abs/2601.01009)
*Mojtaba Aliasghar-Mamaghani,Mohammadreza Khalafi*

Main category: cs.LG

TL;DR: 本文采用数据驱动方法研究混凝土配合比对氯离子时间演化的影响，使用多种机器学习算法预测氯离子渗透，发现KRR、GPR和MLP模型精度较高，揭示了配合比成分与氯离子含量的相关性。


<details>
  <summary>Details</summary>
Motivation: 评估在侵蚀环境下混凝土结构的使用寿命，需要准确预测氯离子在混凝土中的时间演化，这对基础设施的耐久性设计至关重要。

Method: 使用简单和复杂的机器学习算法，包括线性回归、KNN回归、KRR、SVR、GPR、MLP和GRU，基于综合数据集建立预测模型。

Result: KRR、GPR和MLP表现出高精度，GRU由于配合比多样性在测试集上表现不佳。大多数配合比成分与氯离子含量呈负相关，少数呈正相关。

Conclusion: 机器学习方法可作为替代方法有效描述氯离子渗透的物理过程和相关关系，有助于提高基础设施的使用寿命。

Abstract: This paper employs a data-driven approach to determine the impact of concrete mixture compositions on the temporal evolution of chloride in concrete structures. This is critical for assessing the service life of civil infrastructure subjected to aggressive environments. The adopted methodology relies on several simple and complex standalone machine learning (ML) algorithms, with the primary objective of establishing confidence in the unbiased prediction of the underlying hidden correlations. The simple algorithms include linear regression (LR), k-nearest neighbors (KNN) regression, and kernel ridge regression (KRR). The complex algorithms entail support vector regression (SVR), Gaussian process regression (GPR), and two families of artificial neural networks, including a feedforward network (multilayer perceptron, MLP) and a gated recurrent unit (GRU). The MLP architecture cannot explicitly handle sequential data, a limitation addressed by the GRU. A comprehensive dataset is considered. The performance of ML algorithms is evaluated, with KRR, GPR, and MLP exhibiting high accuracy. Given the diversity of the adopted concrete mixture proportions, the GRU was unable to accurately reproduce the response in the test set. Further analyses elucidate the contributions of mixture compositions to the temporal evolution of chloride. The results obtained from the GPR model unravel latent correlations through clear and explainable trends. The MLP, SVR, and KRR also provide acceptable estimates of the overall trends. The majority of mixture components exhibit an inverse relation with chloride content, while a few components demonstrate a direct correlation. These findings highlight the potential of surrogate approaches for describing the physical processes involved in chloride ingress and the associated correlations, toward the ultimate goal of enhancing the service life of civil infrastructure.

</details>


### [243] [Geometric and Dynamic Scaling in Deep Transformers](https://arxiv.org/abs/2601.01014)
*Haoran Su,Chenyu You*

Main category: cs.LG

TL;DR: 本文提出深度Transformer中的表示崩溃本质上是几何问题，而非优化问题，并提出了Manifold-Geometric Transformer (MGT)架构来解决该问题。


<details>
  <summary>Details</summary>
Motivation: 现有研究将深度Transformer的表示崩溃归因于优化不稳定或梯度消失，但无法解释为什么在现代归一化和初始化方案下崩溃仍然存在。作者认为这是一个几何问题，源于标准残差更新缺乏对更新方向和过时信息擦除的约束机制。

Method: 提出了统一的几何框架，包含两个正交原则：1) 流形约束超连接，将残差更新限制在有效的局部切向方向；2) 深度增量学习，引入数据依赖的非单调更新，实现冗余特征的反射和擦除而非无条件累积。

Result: 提出的MGT架构能够解耦特征更新的方向和符号，实现跨深度的稳定几何演化。理论分析表明，强制几何有效性同时允许动态擦除对于避免超深网络中的秩崩溃至关重要。

Conclusion: 几何而非深度本身是深度表示学习的关键限制因素。作者提出了超过100层的Transformer评估协议来验证这一假设。

Abstract: Despite their empirical success, pushing Transformer architectures to extreme depth often leads to a paradoxical failure: representations become increasingly redundant, lose rank, and ultimately collapse. Existing explanations largely attribute this phenomenon to optimization instability or vanishing gradients, yet such accounts fail to explain why collapse persists even under modern normalization and initialization schemes. In this paper, we argue that the collapse of deep Transformers is fundamentally a geometric problem. Standard residual updates implicitly assume that feature accumulation is always beneficial, but offer no mechanism to constrain update directions or to erase outdated information. As depth increases, this leads to systematic drift off the semantic manifold and monotonic feature accumulation, causing representational degeneracy. We propose a unified geometric framework that addresses these failures through two orthogonal principles. First, manifold-constrained hyper-connections restrict residual updates to valid local tangent directions, preventing uncontrolled manifold drift. Second, deep delta learning introduces data-dependent, non-monotonic updates that enable reflection and erasure of redundant features rather than their unconditional accumulation. Together, these mechanisms decouple the direction and sign of feature updates, yielding a stable geometric evolution across depth. We term the resulting architecture the Manifold-Geometric Transformer (MGT). Our analysis predicts that enforcing geometric validity while allowing dynamic erasure is essential for avoiding rank collapse in ultra-deep networks. We outline an evaluation protocol for Transformers exceeding 100 layers to test the hypothesis that geometry, rather than depth itself, is the key limiting factor in deep representation learning.

</details>


### [244] [Improving Variational Autoencoder using Random Fourier Transformation: An Aviation Safety Anomaly Detection Case-Study](https://arxiv.org/abs/2601.01016)
*Ata Akbari Asanjan,Milad Memarzadeh,Bryan Matthews,Nikunj Oza*

Main category: cs.LG

TL;DR: 本文研究了使用随机傅里叶变换（RFT）改进自编码器和变分自编码器的训练过程与推理性能，通过频率原理分析发现RFT使模型能同时学习高低频特征，而传统DNN只能从低频开始逐步学习高频。


<details>
  <summary>Details</summary>
Motivation: 探索傅里叶变换在深度神经网络训练中的作用，特别是对基于重构的异常检测任务的改进潜力，并研究可训练傅里叶变换变体的效果。

Method: 使用随机傅里叶变换和可训练傅里叶变换变体，在自编码器和变分自编码器上进行实验，通过频率原理分析训练行为，并在低维合成数据集和高维航空安全数据集上进行验证。

Result: 带有傅里叶变换的模型在异常检测任务上优于传统模型，但可训练傅里叶变换与随机变体相比的优势尚不确定。

Conclusion: 傅里叶变换能有效改进深度神经网络的训练过程，使模型能同时学习不同频率特征，但在可训练变体方面的优势需要进一步研究。

Abstract: In this study, we focus on the training process and inference improvements of deep neural networks (DNNs), specifically Autoencoders (AEs) and Variational Autoencoders (VAEs), using Random Fourier Transformation (RFT). We further explore the role of RFT in model training behavior using Frequency Principle (F-Principle) analysis and show that models with RFT turn to learn low frequency and high frequency at the same time, whereas conventional DNNs start from low frequency and gradually learn (if successful) high-frequency features. We focus on reconstruction-based anomaly detection using autoencoder and variational autoencoder and investigate the RFT's role. We also introduced a trainable variant of RFT that uses the existing computation graph to train the expansion of RFT instead of it being random. We showcase our findings with two low-dimensional synthetic datasets for data representation, and an aviation safety dataset, called Dashlink, for high-dimensional reconstruction-based anomaly detection. The results indicate the superiority of models with Fourier transformation compared to the conventional counterpart and remain inconclusive regarding the benefits of using trainable Fourier transformation in contrast to the Random variant.

</details>


### [245] [Expanding the Chaos: Neural Operator for Stochastic (Partial) Differential Equations](https://arxiv.org/abs/2601.01021)
*Dai Shi,Lequan Lin,Andi Han,Luke Thompson,José Miguel Hernández-Lobato,Zhiyong Wang,Junbin Gao*

Main category: cs.LG

TL;DR: 该论文基于Wiener混沌展开设计神经网络算子架构，用于求解随机微分方程和随机偏微分方程，通过将噪声路径投影到正交Hermite特征上，并用神经网络算子参数化确定性混沌系数，实现从噪声到解轨迹的单次前向计算。


<details>
  <summary>Details</summary>
Motivation: 开发深度学习模型来近似SDE/SPDE的解算子，不仅能提供快速实用的求解器，还可能从新视角解决经典学习任务。

Method: 基于经典Wiener混沌展开，将驱动噪声路径投影到正交Wick Hermite特征上，用神经网络算子参数化得到的确定性混沌系数，实现从噪声重构完整解轨迹。

Result: 在多个问题上验证了模型效果：经典SPDE基准测试、图像扩散一步采样、图拓扑插值、金融外推、参数估计和洪水预测的流形SDE，展示了竞争性精度和广泛适用性。

Conclusion: 基于WCE的神经网络算子为学习SDE/SPDE解算子提供了一种实用且可扩展的方法，适用于多个领域。

Abstract: Stochastic differential equations (SDEs) and stochastic partial differential equations (SPDEs) are fundamental tools for modeling stochastic dynamics across the natural sciences and modern machine learning. Developing deep learning models for approximating their solution operators promises not only fast, practical solvers, but may also inspire models that resolve classical learning tasks from a new perspective. In this work, we build on classical Wiener chaos expansions (WCE) to design neural operator (NO) architectures for SPDEs and SDEs: we project the driving noise paths onto orthonormal Wick Hermite features and parameterize the resulting deterministic chaos coefficients with neural operators, so that full solution trajectories can be reconstructed from noise in a single forward pass. On the theoretical side, we investigate the classical WCE results for the class of multi-dimensional SDEs and semilinear SPDEs considered here by explicitly writing down the associated coupled ODE/PDE systems for their chaos coefficients, which makes the separation between stochastic forcing and deterministic dynamics fully explicit and directly motivates our model designs. On the empirical side, we validate our models on a diverse suite of problems: classical SPDE benchmarks, diffusion one-step sampling on images, topological interpolation on graphs, financial extrapolation, parameter estimation, and manifold SDEs for flood prediction, demonstrating competitive accuracy and broad applicability. Overall, our results indicate that WCE-based neural operators provide a practical and scalable way to learn SDE/SPDE solution operators across diverse domains.

</details>


### [246] [Wireless Dataset Similarity: Measuring Distances in Supervised and Unsupervised Machine Learning](https://arxiv.org/abs/2601.01023)
*João Morais,Sadjad Alikhani,Akshay Malhotra,Shahab Hamidi-Rad,Ahmed Alkhateeb*

Main category: cs.LG

TL;DR: 提出一个任务和模型感知的无线数据集相似性度量框架，用于预测跨数据集可迁移性，在无线通信任务中优于传统基线方法


<details>
  <summary>Details</summary>
Motivation: 需要一种系统方法来衡量无线数据集之间的相似性，以支持数据集选择、仿真到真实场景转换、任务特定数据生成等应用

Method: 使用UMAP嵌入结合Wasserstein和欧几里得距离的无监督度量方法，以及集成监督UMAP和数据集不平衡惩罚的标签感知距离方法

Result: 在CSI压缩和波束预测任务中，该方法与模型可迁移性的皮尔逊相关系数超过0.85，显著优于传统基线

Conclusion: 该框架能够有效支持无线数据集之间的任务相关比较，为模型训练和部署决策提供可靠依据

Abstract: This paper introduces a task- and model-aware framework for measuring similarity between wireless datasets, enabling applications such as dataset selection/augmentation, simulation-to-real (sim2real) comparison, task-specific synthetic data generation, and informing decisions on model training/adaptation to new deployments. We evaluate candidate dataset distance metrics by how well they predict cross-dataset transferability: if two datasets have a small distance, a model trained on one should perform well on the other. We apply the framework on an unsupervised task, channel state information (CSI) compression, using autoencoders. Using metrics based on UMAP embeddings, combined with Wasserstein and Euclidean distances, we achieve Pearson correlations exceeding 0.85 between dataset distances and train-on-one/test-on-another task performance. We also apply the framework to a supervised beam prediction in the downlink using convolutional neural networks. For this task, we derive a label-aware distance by integrating supervised UMAP and penalties for dataset imbalance. Across both tasks, the resulting distances outperform traditional baselines and consistently exhibit stronger correlations with model transferability, supporting task-relevant comparisons between wireless datasets.

</details>


### [247] [Coarse-Grained Kullback--Leibler Control of Diffusion-Based Generative AI](https://arxiv.org/abs/2601.01045)
*Tatsuaki Tsuruyama*

Main category: cs.LG

TL;DR: 本文提出了一种基于信息论Lyapunov函数V-delta的投影反向扩散方法，用于在扩散模型中控制粗粒度量（如块状强度）的演化，并通过数值实验验证了该方法在保持像素级精度和视觉质量的同时，能将块质量误差控制在预设容差内。


<details>
  <summary>Details</summary>
Motivation: 扩散模型和基于分数的生成模型虽然能合成高质量图像，但缺乏描述粗粒度量（如空间块的强度或类别比例）如何在反向扩散过程中演化的理论框架。作者希望建立一种理论来控制和理解这些粗粒度量的演化。

Method: 作者将之前提出的信息论Lyapunov函数V-delta框架移植到生成模型的反向扩散过程中，提出了V-delta投影反向扩散方案。该方法通过缩放和裁剪操作对块质量进行控制，并证明了在小的泄漏和V-delta投影下，V-delta可作为近似Lyapunov函数。

Result: 使用块常数图像和简化反向核的玩具模型进行数值实验，结果表明所提方法能将块质量误差和泄漏容限势能保持在预设容差内，同时达到与非投影动力学相当的像素级精度和视觉质量。

Conclusion: 该研究将生成采样重新解释为从噪声到数据的信息势能下降过程，为具有显式粗粒度量控制的反向扩散过程提供了设计原则。

Abstract: Diffusion models and score-based generative models provide a powerful framework for synthesizing high-quality images from noise. However, there is still no satisfactory theory that describes how coarse-grained quantities, such as blockwise intensity or class proportions after partitioning an image into spatial blocks, are preserved and evolve along the reverse diffusion dynamics. In previous work, the author introduced an information-theoretic Lyapunov function V for non-ergodic Markov processes on a state space partitioned into blocks, defined as the minimal Kullback-Leibler divergence to the set of stationary distributions reachable from a given initial condition, and showed that a leak-tolerant potential V-delta with a prescribed tolerance for block masses admits a closed-form expression as a scaling-and-clipping operation on block masses.
  In this paper, I transplant this framework to the reverse diffusion process in generative models and propose a reverse diffusion scheme that is projected by the potential V-delta (referred to as the V-delta projected reverse diffusion). I extend the monotonicity of V to time-inhomogeneous block-preserving Markov kernels and show that, under small leakage and the V-delta projection, V-delta acts as an approximate Lyapunov function. Furthermore, using a toy model consisting of block-constant images and a simplified reverse kernel, I numerically demonstrate that the proposed method keeps the block-mass error and the leak-tolerant potential within the prescribed tolerance, while achieving pixel-wise accuracy and visual quality comparable to the non-projected dynamics. This study reinterprets generative sampling as a decrease of an information potential from noise to data, and provides a design principle for reverse diffusion processes with explicit control of coarse-grained quantities.

</details>


### [248] [A UCB Bandit Algorithm for General ML-Based Estimators](https://arxiv.org/abs/2601.01061)
*Yajing Liu,Erkao Bao,Linqi Song*

Main category: cs.LG

TL;DR: ML-UCB是一种将机器学习模型集成到多臂老虎机框架中的广义上置信界算法，通过直接建模估计器的学习曲线行为来克服传统方法对可处理集中不等式的要求。


<details>
  <summary>Details</summary>
Motivation: 解决在序列决策中部署复杂机器学习模型时缺乏可处理集中不等式的问题，为基于ML的探索提供理论保证。

Method: 假设均方误差随训练样本数呈幂律衰减，推导广义集中不等式，并证明ML-UCB能够实现次线性遗憾。该框架支持任何可经验表征学习曲线的ML模型。

Result: 在基于在线矩阵分解的协同过滤推荐系统实验中，使用模拟简化双塔模型的合成数据，ML-UCB相比LinUCB表现出显著改进。

Conclusion: ML-UCB为任意机器学习模型在多臂老虎机中的原理性集成提供了通用框架，无需模型特定的理论分析，仅需经验学习曲线表征。

Abstract: We present ML-UCB, a generalized upper confidence bound algorithm that integrates arbitrary machine learning models into multi-armed bandit frameworks. A fundamental challenge in deploying sophisticated ML models for sequential decision-making is the lack of tractable concentration inequalities required for principled exploration. We overcome this limitation by directly modeling the learning curve behavior of the underlying estimator. Specifically, assuming the Mean Squared Error decreases as a power law in the number of training samples, we derive a generalized concentration inequality and prove that ML-UCB achieves sublinear regret. This framework enables the principled integration of any ML model whose learning curve can be empirically characterized, eliminating the need for model-specific theoretical analysis. We validate our approach through experiments on a collaborative filtering recommendation system using online matrix factorization with synthetic data designed to simulate a simplified two-tower model, demonstrating substantial improvements over LinUCB

</details>


### [249] [SPoRC-VIST: A Benchmark for Evaluating Generative Natural Narrative in Vision-Language Models](https://arxiv.org/abs/2601.01062)
*Yunlin Zeng*

Main category: cs.LG

TL;DR: 本文提出了一种端到端的视觉播客生成管道，通过微调Qwen3-VL-32B模型，在合成到真实的训练策略下，显著提升了多说话者播客对话的自然性和叙事深度，同时保持了视觉基础能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型在描述性任务上表现优异，但在生成引人入胜的长篇叙事（如多说话者播客对话）方面能力不足，且缺乏有效的评估指标。标准指标如BLEU和ROUGE无法捕捉对话自然性、个性和叙事流畅性等细微差别。

Method: 使用精心策划的4000个图像-对话对数据集微调Qwen3-VL-32B模型，采用合成到真实的训练策略：在结构化播客研究语料库（SPoRC）的高质量播客对话与合成生成图像上训练，并在视觉叙事数据集（VIST）的真实世界照片序列上评估。

Result: 微调后的32B模型在对话自然性（胜率>80%）和叙事深度（对话轮次长度+50%）上显著优于235B基础模型，同时保持相同的视觉基础能力（CLIPScore: 20.39）。

Conclusion: 通过合成到真实的训练策略和全面的评估框架，本文展示了视觉语言模型在生成高质量多说话者播客对话方面的潜力，为长篇叙事生成提供了新的方向。

Abstract: Vision-Language Models (VLMs) have achieved remarkable success in descriptive tasks such as image captioning and visual question answering (VQA). However, their ability to generate engaging, long-form narratives -- specifically multi-speaker podcast dialogues -- remains under-explored and difficult to evaluate. Standard metrics like BLEU and ROUGE fail to capture the nuances of conversational naturalness, personality, and narrative flow, often rewarding safe, repetitive outputs over engaging storytelling. In this work, we present a novel pipeline for end-to-end visual podcast generation, and fine-tune a Qwen3-VL-32B model on a curated dataset of 4,000 image-dialogue pairs. Crucially, we use a synthetic-to-real training strategy: we train on high-quality podcast dialogues from the Structured Podcast Research Corpus (SPoRC) paired with synthetically generated imagery, and evaluate on real-world photo sequences from the Visual Storytelling Dataset (VIST). This rigorous setup tests the model's ability to generalize from synthetic training data to real-world visual domains. We propose a comprehensive evaluation framework that moves beyond textual overlap, and use AI-as-a-judge (Gemini 3 Pro, Claude Opus 4.5, GPT 5.2) and novel style metrics (average turn length, speaker switch rate) to assess quality. Our experiments demonstrate that our fine-tuned 32B model significantly outperforms a 235B base model in conversational naturalness ($>$80\% win rate) and narrative depth (+50\% turn length), while maintaining identical visual grounding capabilities (CLIPScore: 20.39).

</details>


### [250] [Tiny Machine Learning for Real-Time Aquaculture Monitoring: A Case Study in Morocco](https://arxiv.org/abs/2601.01065)
*Achraf Hsain,Yahya Zaki,Othman Abaakil,Hibat-allah Bekkar,Yousra Chtouki*

Main category: cs.LG

TL;DR: 本文提出将基于TinyML的低功耗边缘设备集成到水产养殖系统中，实现实时自动化监测和控制，以解决水质波动、疾病爆发和饲料管理低效等问题。


<details>
  <summary>Details</summary>
Motivation: 水产养殖业面临水质管理、疾病防控和饲料效率等挑战，传统人工监测方法耗时且效率低，需要自动化实时监控解决方案。

Method: 采用TinyML技术结合低功耗边缘设备，部署传感器监测pH值、温度、溶解氧、氨氮等关键参数，实现异常检测和自动报警功能。

Result: 系统能够实时监控水产养殖环境参数，提供决策支持数据，优化水处理过程和饲料分配，降低运营成本。

Conclusion: TinyML技术在水产养殖监测中具有可行性，能够促进更可持续和高效的养殖实践发展。

Abstract: Aquaculture, the farming of aquatic organisms, is a rapidly growing industry facing challenges such as water quality fluctuations, disease outbreaks, and inefficient feed management. Traditional monitoring methods often rely on manual labor and are time consuming, leading to potential delays in addressing issues. This paper proposes the integration of low-power edge devices using Tiny Machine Learning (TinyML) into aquaculture systems to enable real-time automated monitoring and control, such as collecting data and triggering alarms, and reducing labor requirements. The system provides real-time data on the required parameters such as pH levels, temperature, dissolved oxygen, and ammonia levels to control water quality, nutrient levels, and environmental conditions enabling better maintenance, efficient resource utilization, and optimal management of the enclosed aquaculture space. The system enables alerts in case of anomaly detection. The data collected by the sensors over time can serve for important decision-making regarding optimizing water treatment processes, feed distribution, feed pattern analysis and improve feed efficiency, reducing operational costs. This research explores the feasibility of developing TinyML-based solutions for aquaculture monitoring, considering factors such as sensor selection, algorithm design, hardware constraints, and ethical considerations. By demonstrating the potential benefits of TinyML in aquaculture, our aim is to contribute to the development of more sustainable and efficient farming practices.

</details>


### [251] [Revisiting Weighted Strategy for Non-stationary Parametric Bandits and MDPs](https://arxiv.org/abs/2601.01069)
*Jing Wang,Peng Zhao,Zhi-Hua Zhou*

Main category: cs.LG

TL;DR: 本文重新审视了非平稳参数化赌博机中的加权策略，提出了一个精炼的分析框架，简化了算法设计并改进了遗憾界限，同时将该框架扩展到具有函数逼近的非平稳马尔可夫决策过程。


<details>
  <summary>Details</summary>
Motivation: 现有的加权策略分析复杂且算法效率低，作者发现这是由于不充分的遗憾分析导致的，希望通过新的分析框架简化推导并提升性能。

Method: 提出精炼分析框架，开发更简单的加权算法，应用于线性赌博机、广义线性赌博机、自协调赌博机，并扩展到线性混合MDP和多项Logit混合MDP。

Result: 在线性赌博机中获得了与窗口/重启算法相同效率但更简单的算法；在广义线性赌博机中改进了遗憾界限；成功扩展到MDP场景并建立了动态遗憾保证。

Conclusion: 新的分析框架有效简化了加权策略的算法设计，提升了理论性能，并展示了在多种参数化赌博机和MDP中的广泛应用潜力。

Abstract: Non-stationary parametric bandits have attracted much attention recently. There are three principled ways to deal with non-stationarity, including sliding-window, weighted, and restart strategies. As many non-stationary environments exhibit gradual drifting patterns, the weighted strategy is commonly adopted in real-world applications. However, previous theoretical studies show that its analysis is more involved and the algorithms are either computationally less efficient or statistically suboptimal. This paper revisits the weighted strategy for non-stationary parametric bandits. In linear bandits (LB), we discover that this undesirable feature is due to an inadequate regret analysis, which results in an overly complex algorithm design. We propose a \emph{refined analysis framework}, which simplifies the derivation and, importantly, produces a simpler weight-based algorithm that is as efficient as window/restart-based algorithms while retaining the same regret as previous studies. Furthermore, our new framework can be used to improve regret bounds of other parametric bandits, including Generalized Linear Bandits (GLB) and Self-Concordant Bandits (SCB). For example, we develop a simple weighted GLB algorithm with an $\tilde{O}(k_μ^{5/4} c_μ^{-3/4} d^{3/4} P_T^{1/4}T^{3/4})$ regret, improving the $\tilde{O}(k_μ^{2} c_μ^{-1}d^{9/10} P_T^{1/5}T^{4/5})$ bound in prior work, where $k_μ$ and $c_μ$ characterize the reward model's nonlinearity, $P_T$ measures the non-stationarity, $d$ and $T$ denote the dimension and time horizon. Moreover, we extend our framework to non-stationary Markov Decision Processes (MDPs) with function approximation, focusing on Linear Mixture MDP and Multinomial Logit (MNL) Mixture MDP. For both classes, we propose algorithms based on the weighted strategy and establish dynamic regret guarantees using our analysis framework.

</details>


### [252] [Flow Equivariant World Models: Memory for Partially Observed Dynamic Environments](https://arxiv.org/abs/2601.01075)
*Hansen Jin Lillemark,Benhao Huang,Fangneng Zhan,Yilun Du,Thomas Anderson Keller*

Main category: cs.LG

TL;DR: 本文提出了一种名为'流等变世界模型'的新框架，将自运动和外部物体运动统一为一参数李群'流'，通过群等变性实现稳定的潜在世界表示，在2D和3D部分观测视频世界建模任务中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有神经网络世界模型忽略了现实世界中连续感官输入流遵循的平滑时间参数化对称性结构，导致需要重复从数据中学习相同的变换。本文旨在利用这种对称性结构来提高世界建模的效率和性能。

Method: 引入流等变世界模型框架，将自运动和外部物体运动统一为一参数李群'流'，实现群等变性，从而提供数百个时间步长的稳定潜在世界表示。

Result: 在2D和3D部分观测视频世界建模基准测试中，该方法显著优于可比较的最先进的基于扩散和记忆增强的世界建模架构，特别是在存在可预测世界动态但超出智能体当前视野的情况下。流等变性对长序列预测特别有益，能够泛化到远超训练时间范围。

Conclusion: 通过将世界模型表示结构与内部和外部运动相结合，流等变性为数据高效、对称性引导的具身智能提供了一条可扩展的路径。

Abstract: Embodied systems experience the world as 'a symphony of flows': a combination of many continuous streams of sensory input coupled to self-motion, interwoven with the dynamics of external objects. These streams obey smooth, time-parameterized symmetries, which combine through a precisely structured algebra; yet most neural network world models ignore this structure and instead repeatedly re-learn the same transformations from data. In this work, we introduce 'Flow Equivariant World Models', a framework in which both self-motion and external object motion are unified as one-parameter Lie group 'flows'. We leverage this unification to implement group equivariance with respect to these transformations, thereby providing a stable latent world representation over hundreds of timesteps. On both 2D and 3D partially observed video world modeling benchmarks, we demonstrate that Flow Equivariant World Models significantly outperform comparable state-of-the-art diffusion-based and memory-augmented world modeling architectures -- particularly when there are predictable world dynamics outside the agent's current field of view. We show that flow equivariance is particularly beneficial for long rollouts, generalizing far beyond the training horizon. By structuring world model representations with respect to internal and external motion, flow equivariance charts a scalable route to data efficient, symmetry-guided, embodied intelligence. Project link: https://flowequivariantworldmodels.github.io.

</details>


### [253] [Discount Model Search for Quality Diversity Optimization in High-Dimensional Measure Spaces](https://arxiv.org/abs/2601.01082)
*Bryon Tjanaka,Henry Chen,Matthew C. Fontaine,Stefanos Nikolaidis*

Main category: cs.LG

TL;DR: DMS（Discount Model Search）是一种新的质量多样性优化算法，通过使用连续折扣模型解决高维度量空间中的探索停滞问题，优于现有的CMA-MAE等算法。


<details>
  <summary>Details</summary>
Motivation: 传统QD算法在低维度量空间表现良好，但在高维空间中容易因度量扭曲而导致探索停滞，需要新的方法来处理高维度量空间的挑战。

Method: DMS使用平滑连续的折扣值模型来指导探索，而不是像CMA-MAE那样使用直方图。这使得算法能够区分度量相似但不同的解，从而在高维空间中持续探索。

Result: 在高维基准测试和图像度量空间的新应用中，DMS显著优于CMA-MAE和其他黑盒QD算法，特别是在处理高维图像空间时表现突出。

Conclusion: DMS通过连续折扣模型有效解决了高维度量空间的探索问题，为QD算法在复杂高维应用中的使用开辟了新途径。

Abstract: Quality diversity (QD) optimization searches for a collection of solutions that optimize an objective while attaining diverse outputs of a user-specified, vector-valued measure function. Contemporary QD algorithms focus on low-dimensional measures because high-dimensional measures are prone to distortion, where many solutions found by the QD algorithm map to similar measures. For example, the CMA-MAE algorithm guides measure space exploration with a histogram in measure space that records so-called discount values. However, CMA-MAE stagnates in domains with high-dimensional measure spaces because solutions with similar measures fall into the same histogram cell and thus receive identical discount values. To address these limitations, we propose Discount Model Search (DMS), which guides exploration with a model that provides a smooth, continuous representation of discount values. In high-dimensional measure spaces, this model enables DMS to distinguish between solutions with similar measures and thus continue exploration. We show that DMS facilitates new QD applications by introducing two domains where the measure space is the high-dimensional space of images, which enables users to specify their desired measures by providing a dataset of images rather than hand-designing the measure function. Results in these domains and on high-dimensional benchmarks show that DMS outperforms CMA-MAE and other black-box QD algorithms.

</details>


### [254] [Central Dogma Transformer: Towards Mechanism-Oriented AI for Cellular Understanding](https://arxiv.org/abs/2601.01089)
*Nobuyuki Ota*

Main category: cs.LG

TL;DR: 中央法则变换器（CDT）是一个整合DNA、RNA和蛋白质预训练语言模型的架构，通过定向交叉注意力机制模拟转录和翻译过程，生成统一的虚拟细胞嵌入。


<details>
  <summary>Details</summary>
Motivation: 当前领域特定的基础模型虽然在各模态上取得成功，但彼此孤立，无法模拟整合的细胞过程。需要开发能够遵循中央法则信息流向的AI架构。

Method: CDT采用定向交叉注意力机制：DNA到RNA注意力模拟转录调控，RNA到蛋白质注意力模拟翻译关系。使用预训练的DNA、RNA和蛋白质语言模型，生成统一的虚拟细胞嵌入。

Result: 在K562细胞的CRISPRi增强子扰动数据上验证，获得0.503的皮尔逊相关系数，达到理论上限的63%。注意力和梯度分析提供了互补的解释窗口，识别出重要的基因组区域。

Conclusion: 与生物信息流向对齐的AI架构既能实现预测准确性，又能提供机制可解释性，为理解细胞机制提供了新途径。

Abstract: Understanding cellular mechanisms requires integrating information across DNA, RNA, and protein - the three molecular systems linked by the Central Dogma of molecular biology. While domain-specific foundation models have achieved success for each modality individually, they remain isolated, limiting our ability to model integrated cellular processes. Here we present the Central Dogma Transformer (CDT), an architecture that integrates pre-trained language models for DNA, RNA, and protein following the directional logic of the Central Dogma. CDT employs directional cross-attention mechanisms - DNA-to-RNA attention models transcriptional regulation, while RNA-to-Protein attention models translational relationships - producing a unified Virtual Cell Embedding that integrates all three modalities. We validate CDT v1 - a proof-of-concept implementation using fixed (non-cell-specific) RNA and protein embeddings - on CRISPRi enhancer perturbation data from K562 cells, achieving a Pearson correlation of 0.503, representing 63% of the theoretical ceiling set by cross-experiment variability (r = 0.797). Attention and gradient analyses provide complementary interpretive windows: in detailed case studies, these approaches highlight largely distinct genomic regions, with gradient analysis identifying a CTCF binding site that Hi-C data showed as physically contacting both enhancer and target gene. These results suggest that AI architectures aligned with biological information flow can achieve both predictive accuracy and mechanistic interpretability.

</details>


### [255] [Community-Based Early-Stage Chronic Kidney Disease Screening using Explainable Machine Learning for Low-Resource Settings](https://arxiv.org/abs/2601.01119)
*Muhammad Ashad Kabir,Sirajam Munira,Dewan Tasnia Azad,Saleh Mohammed Ikram,Mohammad Habibur Rahman Sarker,Syed Manzoor Ahmed Hanifi*

Main category: cs.LG

TL;DR: 开发了一个可解释的机器学习框架，用于南亚人群的早期慢性肾病筛查，相比现有工具在准确性和敏感性方面有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有CKD筛查工具主要基于高收入国家人群开发，在南亚地区表现不佳，且无法有效预测早期CKD。需要针对南亚人群风险特征开发定制化筛查工具。

Method: 使用孟加拉国社区数据集，评估12种机器学习分类器，应用10种特征选择技术，采用10折交叉验证，并在三个独立数据集上进行外部验证，使用SHAP提供模型可解释性。

Result: RFECV特征选择模型达到90.40%的平衡准确率，最小非病理学测试特征集达到89.23%的准确率，外部验证显示78%-98%的敏感性，优于现有筛查工具。

Conclusion: 该机器学习框架为南亚人群提供了准确、可解释的早期CKD筛查方案，具有强泛化能力和临床实用性，特别适合资源有限地区。

Abstract: Early detection of chronic kidney disease (CKD) is essential for preventing progression to end-stage renal disease. However, existing screening tools - primarily developed using populations from high-income countries - often underperform in Bangladesh and South Asia, where risk profiles differ. Most of these tools rely on simple additive scoring functions and are based on data from patients with advanced-stage CKD. Consequently, they fail to capture complex interactions among risk factors and are limited in predicting early-stage CKD. Our objective was to develop and evaluate an explainable machine learning (ML) framework for community-based early-stage CKD screening for low-resource settings, tailored to the Bangladeshi and South Asian population context. We used a community-based dataset from Bangladesh, the first such CKD dataset in South and South Asia, and evaluated twelve ML classifiers across multiple feature domains. Ten complementary feature selection techniques were applied to identify robust, generalizable predictors. The final models were assessed using 10-fold cross-validation. External validation was conducted on three independent datasets from India, the UAE, and Bangladesh. SHAP (SHapley Additive exPlanations) was used to provide model explainability. An ML model trained on an RFECV-selected feature subset achieved a balanced accuracy of 90.40%, whereas minimal non-pathology-test features demonstrated excellent predictive capability with a balanced accuracy of 89.23%, often outperforming larger or full feature sets. Compared with existing screening tools, the proposed models achieved substantially higher accuracy and sensitivity while requiring fewer and more accessible inputs. External validation confirmed strong generalizability with 78% to 98% sensitivity. SHAP interpretation identified clinically meaningful predictors consistent with established CKD risk factors.

</details>


### [256] [Learning from Historical Activations in Graph Neural Networks](https://arxiv.org/abs/2601.01123)
*Yaniv Galron,Hadar Sinai,Haggai Maron,Moshe Eliasof*

Main category: cs.LG

TL;DR: HISTOGRAPH是一种基于注意力的两阶段图池化方法，通过利用中间层的历史激活信息来改进传统图神经网络池化技术。


<details>
  <summary>Details</summary>
Motivation: 传统图池化方法仅使用最后一层GNN的特征，未能充分利用前向传播过程中产生的中间层激活信息，特别是在深层GNN中节点表示可能发生显著变化时，这种信息浪费更为明显。

Method: 提出两阶段注意力机制：首先应用统一的层间注意力对中间激活进行加权，然后应用节点级注意力。通过建模节点表示在不同层间的演化过程，利用节点的激活历史和图结构来优化最终预测特征。

Result: 在多个图分类基准测试中，HISTOGRAPH表现出优于传统技术的稳定性能，特别是在深层GNN中具有更强的鲁棒性。

Conclusion: HISTOGRAPH通过有效利用历史图激活信息，解决了传统池化方法信息利用不足的问题，为深层图神经网络提供了更有效的特征聚合方案。

Abstract: Graph Neural Networks (GNNs) have demonstrated remarkable success in various domains such as social networks, molecular chemistry, and more. A crucial component of GNNs is the pooling procedure, in which the node features calculated by the model are combined to form an informative final descriptor to be used for the downstream task. However, previous graph pooling schemes rely on the last GNN layer features as an input to the pooling or classifier layers, potentially under-utilizing important activations of previous layers produced during the forward pass of the model, which we regard as historical graph activations. This gap is particularly pronounced in cases where a node's representation can shift significantly over the course of many graph neural layers, and worsened by graph-specific challenges such as over-smoothing in deep architectures. To bridge this gap, we introduce HISTOGRAPH, a novel two-stage attention-based final aggregation layer that first applies a unified layer-wise attention over intermediate activations, followed by node-wise attention. By modeling the evolution of node representations across layers, our HISTOGRAPH leverages both the activation history of nodes and the graph structure to refine features used for final prediction. Empirical results on multiple graph classification benchmarks demonstrate that HISTOGRAPH offers strong performance that consistently improves traditional techniques, with particularly strong robustness in deep GNNs.

</details>


### [257] [Wittgenstein's Family Resemblance Clustering Algorithm](https://arxiv.org/abs/2601.01127)
*Golbahar Amanpour,Benyamin Ghojogh*

Main category: cs.LG

TL;DR: 本文基于维特根斯坦的家族相似性概念，提出了一种新的图聚类算法WFR及其核变体，无需预设簇数量或形状假设即可实现非线性聚类。


<details>
  <summary>Details</summary>
Motivation: 受维特根斯坦哲学中家族相似性概念的启发，该概念认为类别成员通过重叠的相似性而非单一共同属性相连，这自然适用于机器学习中的图方法。

Method: 提出WFR聚类算法：计算相邻数据实例的相似度得分，通过阈值处理构建相似图，图的连通分量即形成最终聚类。

Result: 在基准数据集上的实验表明，WFR是一种有效的非线性聚类算法，不需要预先知道聚类数量或对其形状进行假设。

Conclusion: 将哲学概念成功转化为实用的机器学习算法，WFR为无监督学习提供了新的思路，特别适用于复杂形状的聚类问题。

Abstract: This paper, introducing a novel method in philomatics, draws on Wittgenstein's concept of family resemblance from analytic philosophy to develop a clustering algorithm for machine learning. According to Wittgenstein's Philosophical Investigations (1953), family resemblance holds that members of a concept or category are connected by overlapping similarities rather than a single defining property. Consequently, a family of entities forms a chain of items sharing overlapping traits. This philosophical idea naturally lends itself to a graph-based approach in machine learning. Accordingly, we propose the Wittgenstein's Family Resemblance (WFR) clustering algorithm and its kernel variant, kernel WFR. This algorithm computes resemblance scores between neighboring data instances, and after thresholding these scores, a resemblance graph is constructed. The connected components of this graph define the resulting clusters. Simulations on benchmark datasets demonstrate that WFR is an effective nonlinear clustering algorithm that does not require prior knowledge of the number of clusters or assumptions about their shapes.

</details>


### [258] [Self-Training the Neurochaos Learning Algorithm](https://arxiv.org/abs/2601.01146)
*Anusree M,Akhila Henry,Pramod P Nair*

Main category: cs.LG

TL;DR: 该研究提出了一种结合神经混沌学习与自训练的半监督学习混合架构，用于解决小样本和类别不平衡问题，在多个基准数据集上取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，获取大量标注数据困难且昂贵，而无标注数据容易获得。传统监督学习方法在小样本或数据不平衡场景下表现不佳。

Method: 提出自训练神经混沌学习（NL+ST）架构，将输入特征转换为基于混沌的发放率表示来捕捉数据非线性关系，同时通过自训练方法逐步扩展标注集。

Result: 在10个基准数据集和5个机器学习分类器上测试，仅使用15%标注数据，相比单独的自训练模型获得显著性能提升，特别是在Iris（188.66%）、Wine（158.58%）和Glass Identification（110.48%）等非线性不平衡数据集上。

Conclusion: 在低数据场景下，使用基于混沌的特征提取与半监督学习相结合的方法可以提高泛化能力、鲁棒性和分类精度。

Abstract: In numerous practical applications, acquiring substantial quantities of labelled data is challenging and expensive, but unlabelled data is readily accessible. Conventional supervised learning methods frequently underperform in scenarios characterised by little labelled data or imbalanced datasets. This study introduces a hybrid semi-supervised learning (SSL) architecture that integrates Neurochaos Learning (NL) with a threshold-based Self-Training (ST) method to overcome this constraint. The NL architecture converts input characteristics into chaos-based ring-rate representations that encapsulate nonlinear relationships within the data, whereas ST progressively enlarges the labelled set utilising high-confidence pseudo-labelled samples. The model's performance is assessed using ten benchmark datasets and five machine learning classifiers, with 85% of the training data considered unlabelled and just 15% utilised as labelled data. The proposed Self-Training Neurochaos Learning (NL+ST) architecture consistently attains superior performance gain relative to standalone ST models, especially on limited, nonlinear and imbalanced datasets like Iris (188.66%), Wine (158.58%) and Glass Identification (110.48%). The results indicate that using chaos-based feature extraction with SSL improves generalisation, resilience, and classification accuracy in low-data contexts.

</details>


### [259] [Evo-TFS: Evolutionary Time-Frequency Domain-Based Synthetic Minority Oversampling Approach to Imbalanced Time Series Classification](https://arxiv.org/abs/2601.01150)
*Wenbin Pei,Ruohao Dai,Bing Xue,Mengjie Zhang,Qiang Zhang,Yiu-Ming Cheung*

Main category: cs.LG

TL;DR: Evo-TFS是一种新颖的进化过采样方法，通过结合时域和频域特征来解决不平衡时间序列分类问题，在实验中优于现有过采样方法。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习方法假设数据分布平衡，在不平衡数据中容易忽略少数类，而传统过采样方法依赖线性插值，难以保持时间动态和生成多样样本。

Method: 使用强类型遗传编程来进化多样化的高质量时间序列，通过包含时域和频域特征的适应度函数进行指导。

Result: 在不平衡时间序列数据集上的实验表明，Evo-TFS优于现有过采样方法，显著提升了时域和频域分类器的性能。

Conclusion: Evo-TFS通过整合时域和频域特征的进化过采样方法，有效解决了不平衡时间序列分类问题，具有实际应用价值。

Abstract: Time series classification is a fundamental machine learning task with broad real-world applications. Although many deep learning methods have proven effective in learning time-series data for classification, they were originally developed under the assumption of balanced data distributions. Once data distribution is uneven, these methods tend to ignore the minority class that is typically of higher practical significance. Oversampling methods have been designed to address this by generating minority-class samples, but their reliance on linear interpolation often hampers the preservation of temporal dynamics and the generation of diverse samples. Therefore, in this paper, we propose Evo-TFS, a novel evolutionary oversampling method that integrates both time- and frequency-domain characteristics. In Evo-TFS, strongly typed genetic programming is employed to evolve diverse, high-quality time series, guided by a fitness function that incorporates both time-domain and frequency-domain characteristics. Experiments conducted on imbalanced time series datasets demonstrate that Evo-TFS outperforms existing oversampling methods, significantly enhancing the performance of time-domain and frequency-domain classifiers.

</details>


### [260] [Bridging the Semantic Gap for Categorical Data Clustering via Large Language Models](https://arxiv.org/abs/2601.01162)
*Zihua Yang,Xin Liao,Yiqun Zhang,Yiu-ming Cheung*

Main category: cs.LG

TL;DR: ARISE方法利用大语言模型的外部语义知识来增强分类数据的聚类效果，通过语义感知表示弥补传统相似性度量的不足，在多个基准数据集上实现了19-27%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 分类数据聚类面临相似性度量困难的问题，传统方法在处理有限样本时无法可靠推断值之间的关系，导致语义上下文未被充分利用，影响聚类质量。

Method: 提出ARISE方法，利用大语言模型描述属性值来增强表示，将LLM增强的嵌入与原始数据结合，探索语义突出的聚类结构。

Result: 在8个基准数据集上的实验表明，ARISE相比7个代表性对比方法实现了19-27%的性能提升。

Conclusion: ARISE通过整合外部语义知识有效弥补了分类数据聚类的语义鸿沟，显著提升了聚类性能，证明了语义增强表示的重要性。

Abstract: Categorical data are prevalent in domains such as healthcare, marketing, and bioinformatics, where clustering serves as a fundamental tool for pattern discovery. A core challenge in categorical data clustering lies in measuring similarity among attribute values that lack inherent ordering or distance. Without appropriate similarity measures, values are often treated as equidistant, creating a semantic gap that obscures latent structures and degrades clustering quality. Although existing methods infer value relationships from within-dataset co-occurrence patterns, such inference becomes unreliable when samples are limited, leaving the semantic context of the data underexplored. To bridge this gap, we present ARISE (Attention-weighted Representation with Integrated Semantic Embeddings), which draws on external semantic knowledge from Large Language Models (LLMs) to construct semantic-aware representations that complement the metric space of categorical data for accurate clustering. That is, LLM is adopted to describe attribute values for representation enhancement, and the LLM-enhanced embeddings are combined with the original data to explore semantically prominent clusters. Experiments on eight benchmark datasets demonstrate consistent improvements over seven representative counterparts, with gains of 19-27%. Code is available at https://github.com/develop-yang/ARISE

</details>


### [261] [MentalGame: Predicting Personality-Job Fitness for Software Developers Using Multi-Genre Games and Machine Learning Approaches](https://arxiv.org/abs/2601.01206)
*Soroush Elyasi,Arya VarastehNezhad,Fattaneh Taghiyareh*

Main category: cs.LG

TL;DR: 本研究提出了一种基于多类型严肃游戏和机器学习的框架，通过游戏行为数据预测软件开发岗位的适合度，避免了传统自评问卷的偏见问题。


<details>
  <summary>Details</summary>
Motivation: 传统的职业评估使用自评问卷，容易受到回答偏差、疲劳和故意扭曲的影响。游戏化评估通过捕捉游戏过程中的隐式行为信号，提供了一个有前景的替代方案。

Method: 通过系统文献回顾和软件工程师实证研究确定相关人格和行为特征，设计定制移动游戏来引发问题解决、规划、适应性等行为。采用两阶段建模策略，仅使用游戏行为特征预测适合度。

Result: 模型达到97%的精确度和94%的准确率。合适候选人表现出独特的游戏模式，如解谜游戏获胜更多、完成更多侧挑战、更频繁导航菜单、更少暂停/重试/放弃行为。

Conclusion: 游戏过程中捕捉的隐式行为痕迹能够有效预测软件开发适合度，无需显性人格测试，支持严肃游戏作为可扩展、吸引人且偏见较少的职业评估替代方案。

Abstract: Personality assessment in career guidance and personnel selection traditionally relies on self-report questionnaires, which are susceptible to response bias, fatigue, and intentional distortion. Game-based assessment offers a promising alternative by capturing implicit behavioral signals during gameplay. This study proposes a multi-genre serious-game framework combined with machine-learning techniques to predict suitability for software development roles. Developer-relevant personality and behavioral traits were identified through a systematic literature review and an empirical study of professional software engineers. A custom mobile game was designed to elicit behaviors related to problem solving, planning, adaptability, persistence, time management, and information seeking. Fine-grained gameplay event data were collected and analyzed using a two-phase modeling strategy where suitability was predicted exclusively from gameplay-derived behavioral features. Results show that our model achieved up to 97% precision and 94% accuracy. Behavioral analysis revealed that proper candidates exhibited distinct gameplay patterns, such as more wins in puzzle-based games, more side challenges, navigating menus more frequently, and exhibiting fewer pauses, retries, and surrender actions. These findings demonstrate that implicit behavioral traces captured during gameplay is promising in predicting software-development suitability without explicit personality testing, supporting serious games as a scalable, engaging, and less biased alternative for career assessment.

</details>


### [262] [Sparse Bayesian Message Passing under Structural Uncertainty](https://arxiv.org/abs/2601.01207)
*Yoonhyuk Choi,Jiho Choi,Chanran Kim,Yumin Lee,Hawon Shin,Yeowon Jeon,Minjeong Kim,Jiwoo Kang*

Main category: cs.LG

TL;DR: 该论文提出了一种基于贝叶斯后验分布建模的稀疏符号消息传递网络，用于处理图结构中的异质性和边噪声问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界图中的半监督学习经常面临异质性挑战，即观察到的图结构不可靠或标签不匹配。现有图神经网络要么依赖固定邻接结构，要么通过正则化处理结构噪声，缺乏对结构不确定性的显式建模。

Method: 通过建模有符号邻接矩阵的后验分布（允许边为正、负或缺失），提出稀疏符号消息传递网络，结合后验边缘化处理和稀疏符号消息聚合，从贝叶斯角度提供理论解释。

Result: 实验结果表明，该方法在异质性基准测试中，在合成和真实世界结构噪声下均优于强基线模型。

Conclusion: 该方法为处理边噪声和异质性提供了一种原则性方法，通过显式捕捉结构不确定性来提升图神经网络在异质图上的性能。

Abstract: Semi-supervised learning on real-world graphs is frequently challenged by heterophily, where the observed graph is unreliable or label-disassortative. Many existing graph neural networks either rely on a fixed adjacency structure or attempt to handle structural noise through regularization. In this work, we explicitly capture structural uncertainty by modeling a posterior distribution over signed adjacency matrices, allowing each edge to be positive, negative, or absent. We propose a sparse signed message passing network that is naturally robust to edge noise and heterophily, which can be interpreted from a Bayesian perspective. By combining (i) posterior marginalization over signed graph structures with (ii) sparse signed message aggregation, our approach offers a principled way to handle both edge noise and heterophily. Experimental results demonstrate that our method outperforms strong baseline models on heterophilic benchmarks under both synthetic and real-world structural noise.

</details>


### [263] [Adaptive Conformal Prediction via Bayesian Uncertainty Weighting for Hierarchical Healthcare Data](https://arxiv.org/abs/2601.01223)
*Marzieh Amiri Shahbazi,Ali Baheri,Nasibeh Azadeh-Fard*

Main category: cs.LG

TL;DR: 本文提出了一种混合贝叶斯-共形框架，结合贝叶斯层次随机森林和群体感知共形校准，为临床决策提供具有分布无关覆盖保证和风险自适应精度的不确定性量化方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法同时满足临床决策对分布无关覆盖保证和风险自适应精度的需求，需要一种能够提供可靠不确定性量化的新方法。

Method: 采用混合贝叶斯-共形框架，集成贝叶斯层次随机森林与群体感知共形校准，利用后验不确定性对共形得分进行加权，同时保持严格的覆盖有效性。

Result: 在61,538例入院病例（涉及3,793家美国医院和4个地区）的评估中，该方法实现了目标覆盖率（94.3% vs 95%目标），并具有自适应精度：低不确定性病例的区间宽度减少21%，高风险预测的区间适当加宽。

Conclusion: 该框架支持风险分层临床协议、高效资源规划和高置信度预测，为不同医疗环境提供不确定性感知的决策支持，解决了纯贝叶斯方法严重覆盖不足（14.1%）的问题。

Abstract: Clinical decision-making demands uncertainty quantification that provides both distribution-free coverage guarantees and risk-adaptive precision, requirements that existing methods fail to jointly satisfy. We present a hybrid Bayesian-conformal framework that addresses this fundamental limitation in healthcare predictions. Our approach integrates Bayesian hierarchical random forests with group-aware conformal calibration, using posterior uncertainties to weight conformity scores while maintaining rigorous coverage validity. Evaluated on 61,538 admissions across 3,793 U.S. hospitals and 4 regions, our method achieves target coverage (94.3% vs 95% target) with adaptive precision: 21% narrower intervals for low-uncertainty cases while appropriately widening for high-risk predictions. Critically, we demonstrate that well-calibrated Bayesian uncertainties alone severely under-cover (14.1%), highlighting the necessity of our hybrid approach. This framework enables risk-stratified clinical protocols, efficient resource planning for high-confidence predictions, and conservative allocation with enhanced oversight for uncertain cases, providing uncertainty-aware decision support across diverse healthcare settings.

</details>


### [264] [The Dependency Divide: An Interpretable Machine Learning Framework for Profiling Student Digital Satisfaction in the Bangladesh Context](https://arxiv.org/abs/2601.01231)
*Md Muhtasim Munif Fahim,Humyra Ankona,Md Monimul Huq,Md Rezaul Karim*

Main category: cs.LG

TL;DR: 该研究提出了"依赖鸿沟"框架，指出在基础设施不可靠的环境中，高参与度学生反而容易因网络中断而受到更大影响，挑战了传统认为参与度总是有益的假设。


<details>
  <summary>Details</summary>
Motivation: 传统数字鸿沟框架无法解释在相同网络条件下学生满意度差异的问题，需要新的理论框架来理解后接入环境中的数字不平等现象。

Method: 采用三阶段分析方法：K-prototypes聚类识别学生档案、档案特异性随机森林模型分析满意度驱动因素、倾向得分匹配进行交互分析验证依赖鸿沟假设。

Result: 识别出三类学生档案（随意参与58%、高效学习者35%、超参与7%），发现教育设备使用时间与网络可靠性存在显著交互作用，超参与学生最易受基础设施故障影响。政策模拟显示针对性可靠性改进的收益是统一干预的2.06倍。

Conclusion: 在脆弱基础设施环境中，数字能力可能成为负担。数字转型政策应优先保障高依赖用户的可靠性，建立应急系统，并教育学生认识依赖风险，而非一味鼓励参与。

Abstract: Background: While digital access has expanded rapidly in resource-constrained contexts, satisfaction with digital learning platforms varies significantly among students with seemingly equal connectivity. Traditional digital divide frameworks fail to explain these variations.
  Purpose: This study introduces the "Dependency Divide", a novel framework proposing that highly engaged students become conditionally vulnerable to infrastructure failures, challenging assumptions that engagement uniformly benefits learners in post-access environments.
  Methods: We conducted a cross-sectional study of 396 university students in Bangladesh using a three-stage analytical approach: (1) stability-validated K-prototypes clustering to identify student profiles, (2) profile-specific Random Forest models with SHAP and ALE analysis to determine satisfaction drivers, and (3) formal interaction analysis with propensity score matching to test the Dependency Divide hypothesis.
  Results: Three distinct profiles emerged: Casually Engaged (58%), Efficient Learners (35%), and Hyper-Engaged (7%). A significant interaction between educational device time and internet reliability (\b{eta} = 0.033, p = 0.028) confirmed the Dependency Divide: engagement increased satisfaction only when infrastructure remained reliable. Hyper-Engaged students showed greatest vulnerability despite or because of their sophisticated digital workflows. Policy simulations demonstrated that targeted reliability improvements for high-dependency users yielded 2.06 times greater returns than uniform interventions.
  Conclusions: In fragile infrastructure contexts, capability can become liability. Digital transformation policies must prioritize reliability for dependency-prone users, establish contingency systems, and educate students about dependency risks rather than uniformly promoting engagement.

</details>


### [265] [Benchmarking the Computational and Representational Efficiency of State Space Models against Transformers on Long-Context Dyadic Sessions](https://arxiv.org/abs/2601.01237)
*Abidemi Koledoye,Chinemerem Unachukwu,Gold Nwobu,Hasin Rana*

Main category: cs.LG

TL;DR: 该论文对Mamba状态空间模型和LLaMA Transformer在长上下文序列上的性能进行了全面基准测试，重点比较计算效率和表示效率。


<details>
  <summary>Details</summary>
Motivation: 状态空间模型（SSMs）作为Transformer的替代方案，在长序列建模中具有线性计算复杂度优势，需要系统评估其实际性能表现。

Method: 使用心理治疗对话作为测试案例，在512到8,192个token范围内评估两种架构的计算效率（内存使用、推理速度）和表示效率（隐藏状态动态、注意力模式）。

Result: 研究结果提供了SSMs相对于Transformers优势的具体条件，为长上下文应用提供实践指导。

Conclusion: 该基准测试为长序列建模场景下选择SSMs或Transformers提供了明确的决策依据。

Abstract: State Space Models (SSMs) have emerged as a promising alternative to Transformers for long-context sequence modeling, offering linear $O(N)$ computational complexity compared to the Transformer's quadratic $O(N^2)$ scaling. This paper presents a comprehensive benchmarking study comparing the Mamba SSM against the LLaMA Transformer on long-context sequences, using dyadic therapy sessions as a representative test case. We evaluate both architectures across two dimensions: (1) computational efficiency, where we measure memory usage and inference speed from 512 to 8,192 tokens, and (2) representational efficiency, where we analyze hidden state dynamics and attention patterns. Our findings provide actionable insights for practitioners working with long-context applications, establishing precise conditions under which SSMs offer advantages over Transformers.

</details>


### [266] [Accelerated Full Waveform Inversion by Deep Compressed Learning](https://arxiv.org/abs/2601.01268)
*Maayan Gelboim,Amir Adler,Mauricio Araya-Polo*

Main category: cs.LG

TL;DR: 提出一种基于深度学习的全波形反演(FWI)数据降维方法，通过神经网络选择关键数据子集并利用自动编码器进行表示学习，显著降低计算成本


<details>
  <summary>Details</summary>
Motivation: 工业级FWI需要处理TB级地震数据，计算成本高昂，限制了复杂地下情况分析和多场景探索的应用

Method: 使用带有二值化感知层的深度神经网络，通过压缩学习从大量地下模型中学习有效的地震采集布局；然后利用自动编码器计算数据潜在表示，通过K-means聚类进一步选择最相关的FWI数据

Result: 该方法在仅使用10%数据的情况下，在2D FWI中持续优于随机数据采样

Conclusion: 这种分层选择方法为大规模3D反演中加速FWI铺平了道路

Abstract: We propose and test a method to reduce the dimensionality of Full Waveform Inversion (FWI) inputs as computational cost mitigation approach. Given modern seismic acquisition systems, the data (as input for FWI) required for an industrial-strength case is in the teraflop level of storage, therefore solving complex subsurface cases or exploring multiple scenarios with FWI become prohibitive. The proposed method utilizes a deep neural network with a binarized sensing layer that learns by compressed learning a succinct but consequential seismic acquisition layout from a large corpus of subsurface models. Thus, given a large seismic data set to invert, the trained network selects a smaller subset of the data, then by using representation learning, an autoencoder computes latent representations of the data, followed by K-means clustering of the latent representations to further select the most relevant data for FWI. Effectively, this approach can be seen as a hierarchical selection. The proposed approach consistently outperforms random data sampling, even when utilizing only 10% of the data for 2D FWI, these results pave the way to accelerating FWI in large scale 3D inversion.

</details>


### [267] [The Alchemy of Thought: Understanding In-Context Learning Through Supervised Classification](https://arxiv.org/abs/2601.01290)
*Harshita Narnoli,Mihai Surdeanu*

Main category: cs.LG

TL;DR: 本文通过比较上下文学习与监督分类器的行为，研究了LLMs在上下文学习中的工作机制，发现当演示相关性高时，LLMs行为类似于kNN分类器，当相关性低时，LLMs能利用参数记忆获得更好性能。


<details>
  <summary>Details</summary>
Motivation: 尽管上下文学习在实践中被证明有效，但其工作机制尚不明确。本文旨在探究LLMs在上下文学习中的行为模式，特别是与监督分类器的相似性。

Method: 使用文本分类作为用例，在6个数据集和3个LLMs上比较上下文学习与基于梯度下降和k近邻的分类器行为，分析演示相关性对行为相似性的影响。

Result: 当演示相关性高时，LLMs行为与kNN分类器更相似；当演示相关性低时，LLMs表现优于监督分类器，能够利用参数记忆。

Conclusion: 上下文学习的注意力机制更类似于kNN而非梯度下降，LLMs在低相关性情况下能够依赖参数记忆获得优势，这解释了上下文学习的工作机制。

Abstract: In-context learning (ICL) has become a prominent paradigm to rapidly customize LLMs to new tasks without fine-tuning. However, despite the empirical evidence of its usefulness, we still do not truly understand how ICL works. In this paper, we compare the behavior of in-context learning with supervised classifiers trained on ICL demonstrations to investigate three research questions: (1) Do LLMs with ICL behave similarly to classifiers trained on the same examples? (2) If so, which classifiers are closer, those based on gradient descent (GD) or those based on k-nearest neighbors (kNN)? (3) When they do not behave similarly, what conditions are associated with differences in behavior? Using text classification as a use case, with six datasets and three LLMs, we observe that LLMs behave similarly to these classifiers when the relevance of demonstrations is high. On average, ICL is closer to kNN than logistic regression, giving empirical evidence that the attention mechanism behaves more similarly to kNN than GD. However, when demonstration relevance is low, LLMs perform better than these classifiers, likely because LLMs can back off to their parametric memory, a luxury these classifiers do not have.

</details>


### [268] [Sobolev Approximation of Deep ReLU Network in Log-weighted Barron Space](https://arxiv.org/abs/2601.01295)
*Changhoon Song,Seungchan Ko,Youngjoon Hong*

Main category: cs.LG

TL;DR: 本文引入了对数加权的Barron空间ℬ^log，该空间比传统的Barron空间ℬ^s（s>0）具有更弱的正则性假设，并证明了深度ReLU网络在该空间中的逼近能力，阐明了深度如何降低高效表示所需的正则性要求。


<details>
  <summary>Details</summary>
Motivation: 传统的Barron空间理论虽然解释了神经网络在高维数据上的成功，但仍需要比Sobolev空间更强的正则性条件，且现有深度敏感结果往往假设约束如sL≤1/2。为了更精确地解释深度架构的性能，需要研究更弱的正则性假设下的逼近理论。

Method: 1. 引入对数加权的Barron空间ℬ^log；2. 研究该空间的嵌入性质并通过Rademacher复杂度进行统计分析；3. 证明ℬ^log中的函数可由深度ReLU网络以显式深度依赖逼近；4. 定义ℬ^{s,log}族，建立H^1范数下的逼近界，并确定保持这些速率的最大深度尺度。

Result: 1. ℬ^log空间比任何s>0的ℬ^s空间具有更弱的正则性假设；2. 深度ReLU网络在ℬ^log空间中具有显式深度依赖的逼近能力；3. 在ℬ^{s,log}族中建立了H^1范数下的逼近界，并确定了最大深度尺度。

Conclusion: 本文通过引入对数加权的Barron空间，阐明了深度如何降低高效表示所需的正则性要求，为深度架构在传统Barron设置之外的性能提供了更精确的解释，并为其在高维问题中的稳定使用提供了理论支持。

Abstract: Universal approximation theorems show that neural networks can approximate any continuous function; however, the number of parameters may grow exponentially with the ambient dimension, so these results do not fully explain the practical success of deep models on high-dimensional data. Barron space theory addresses this: if a target function belongs to a Barron space, a two-layer network with $n$ parameters achieves an $O(n^{-1/2})$ approximation error in $L^2$. Yet classical Barron spaces $\mathscr{B}^{s+1}$ still require stronger regularity than Sobolev spaces $H^s$, and existing depth-sensitive results often assume constraints such as $sL \le 1/2$. In this paper, we introduce a log-weighted Barron space $\mathscr{B}^{\log}$, which requires a strictly weaker assumption than $\mathscr{B}^s$ for any $s>0$. For this new function space, we first study embedding properties and carry out a statistical analysis via the Rademacher complexity. Then we prove that functions in $\mathscr{B}^{\log}$ can be approximated by deep ReLU networks with explicit depth dependence. We then define a family $\mathscr{B}^{s,\log}$, establish approximation bounds in the $H^1$ norm, and identify maximal depth scales under which these rates are preserved. Our results clarify how depth reduces regularity requirements for efficient representation, offering a more precise explanation for the performance of deep architectures beyond the classical Barron setting, and for their stable use in high-dimensional problems used today.

</details>


### [269] [ARGUS: Adaptive Rotation-Invariant Geometric Unsupervised System](https://arxiv.org/abs/2601.01297)
*Anantha Sharma*

Main category: cs.LG

TL;DR: 本文提出Argus框架，将高维数据流中的分布漂移检测重新概念化为在数据流形的固定空间划分上跟踪局部统计量，解决了现有方法的可扩展性、几何结构保持和身份稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 高维数据流中的分布漂移检测面临三大挑战：全局比较方法扩展性差、基于投影的方法丢失几何结构、重新聚类方法存在身份不稳定性。需要一种既能保持高维结构又具有计算效率的检测方法。

Method: 基于Voronoi剖分在标准正交框架上构建固定空间划分，通过跟踪局部统计量来检测漂移。引入图论方法表征漂移传播，区分相干分布变化与孤立扰动。使用乘积量化剖分技术扩展到超高维度。

Result: 理论证明该框架对正交变换具有不变性，实现每快照O(N)复杂度，并能提供漂移的细胞级空间定位。实验验证该框架在坐标旋转下能正确识别漂移，而现有方法会产生误报。

Conclusion: Argus框架为分布监测提供了有原则的几何基础，在保持高维结构的同时避免了成对比较的计算负担，为高维数据流漂移检测提供了有效的解决方案。

Abstract: Detecting distributional drift in high-dimensional data streams presents fundamental challenges: global comparison methods scale poorly, projection-based approaches lose geometric structure, and re-clustering methods suffer from identity instability. This paper introduces Argus, A framework that reconceptualizes drift detection as tracking local statistics over a fixed spatial partition of the data manifold.
  The key contributions are fourfold. First, it is proved that Voronoi tessellations over canonical orthonormal frames yield drift metrics that are invariant to orthogonal transformations. The rotations and reflections that preserve Euclidean geometry. Second, it is established that this framework achieves O(N) complexity per snapshot while providing cell-level spatial localization of distributional change. Third, a graph-theoretic characterization of drift propagation is developed that distinguishes coherent distributional shifts from isolated perturbations. Fourth, product quantization tessellation is introduced for scaling to very high dimensions (d>500) by decomposing the space into independent subspaces and aggregating drift signals across subspaces.
  This paper formalizes the theoretical foundations, proves invariance properties, and presents experimental validation demonstrating that the framework correctly identifies drift under coordinate rotation while existing methods produce false positives. The tessellated approach offers a principled geometric foundation for distribution monitoring that preserves high-dimensional structure without the computational burden of pairwise comparisons.

</details>


### [270] [Warp-Cortex: An Asynchronous, Memory-Efficient Architecture for Million-Agent Cognitive Scaling on Consumer Hardware](https://arxiv.org/abs/2601.01298)
*Jorge L. Ruiz Williams*

Main category: cs.LG

TL;DR: Warp Cortex提出了一种异步架构，通过Singleton Weight Sharing和Topological Synapse技术，将多智能体LLM框架的内存复杂度从O(N*L)降低到O(1)权重和O(N*k)上下文，实现百万级智能体的认知扩展。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体LLM框架存在线性内存扩展问题，使得"System 2"并行推理在消费级硬件上不可行，需要解决内存瓶颈以实现大规模智能体部署。

Method: 采用异步架构，通过权重共享和拓扑突触技术，将KV缓存视为潜在空间中的点云，应用见证复杂度启发的稀疏化来保留上下文流形的持久同调特征。引入Referential Injection机制实现非侵入式KV缓存更新。

Result: 在单个NVIDIA RTX 4090上实现了100个并发智能体仅占用2.2GB显存，理论容量超过1000个智能体，计算延迟成为主要瓶颈。

Conclusion: Warp Cortex架构成功解决了多智能体LLM的内存扩展问题，为大规模并行推理系统提供了可行的解决方案。

Abstract: Current multi-agent Large Language Model (LLM) frameworks suffer from linear memory scaling, rendering "System 2" parallel reasoning impractical on consumer hardware. We present Warp Cortex, an asynchronous architecture that theoretically enables million-agent cognitive scaling by decoupling agent logic from physical memory. Through Singleton Weight Sharing and a novel Topological Synapse--inspired by hybrid landmarking techniques from Topological Data Analysis (TDA)--we reduce memory complexity from O(N * L) to O(1) for weights and O(N * k) for context, where k << L. By treating the KV-cache as a point cloud in latent space, we apply witness-complex-inspired sparsification to preserve persistent homological features of the context manifold. On a single NVIDIA RTX 4090, we empirically demonstrate 100 concurrent agents at 2.2 GB total VRAM, with theoretical capacity exceeding 1,000 agents before compute latency becomes the bottleneck. We further introduce Referential Injection, a non-intrusive KV-cache update mechanism that allows asynchronous sub-agents to influence primary generation without stream disruption.

</details>


### [271] [Towards a Principled Muon under $μ\mathsf{P}$: Ensuring Spectral Conditions throughout Training](https://arxiv.org/abs/2601.01306)
*John Zhao*

Main category: cs.LG

TL;DR: 本文提出Muon++优化器，通过仅控制优化器更新的谱条件而非显式谱归一化权重，实现了μP理论在长期训练中的实际应用，解决了现有方法计算开销大和实用性差的问题。


<details>
  <summary>Details</summary>
Motivation: μP理论为LLM训练提供了宽度无关的学习动态，但现有矩阵优化器如Muon在长期训练中难以保证谱条件，导致计算开销大或无法在整个训练过程中保持理论兼容性。

Method: 基于"仅控制优化器更新的谱条件即可保持μP兼容性"的洞察，开发了Muon++优化器变体，无需显式谱归一化权重，并首次引入数据依赖的自适应谱条件。

Result: Muon++能够在整个训练过程中可靠保证μP所需的谱条件，填补了理论承诺与实际部署之间的差距，适用于长期LLM训练。

Conclusion: 该工作为矩阵优化器在μP框架下的实际应用提供了可行方案，通过简化谱控制机制降低了计算开销，同时通过自适应谱条件增强了长期训练的适用性。

Abstract: The $μ$-parameterization ($μ$P) provides a principled foundation for large language model (LLM) training by prescribing width-independent learning dynamics, which in turn enables predictable scaling behavior and robust hyperparameter transfer across model sizes. A central requirement of $μ$P is the satisfaction of certain spectral conditions on weight matrices, which ensure consistent feature learning and optimization behavior as model width grows. While these conditions are well understood in theory, guaranteeing their validity in practical training for matrix-based optimizers such as Muon is still under studied. Existing works that study Muon under $μ$P exhibit important limitations: they either do not ensure that the spectral conditions hold throughout the entire training horizon, or require repeated spectral normalization (or Newton-Schulz iterations) applied to both weights and updates, leading to significant computational overhead and reduced practicality. In this work, we show how to reliably guarantee the spectral conditions required by $μ$P for Muon during the entire training process. Our key insight is that for moderately large models, maintaining spectral control at the level of optimizer updates alone is sufficient to preserve $μ$P-compatible scaling, eliminating the need for explicit spectral normalization of the weights. Based on this principle, we develop a variant of Muon, namely Muon++, that satisfies spectral condition throughout the training process. Our results bridge the gap between the theoretical promises of $μ$P and the practical deployment of matrix-based optimizers in long-horizon training. We also take the first step towards an adaptive spectral condition by incorporating data-dependent effects, making it better suited for long-horizon LLM training.

</details>


### [272] [Spectral-Window Hybrid (SWH)](https://arxiv.org/abs/2601.01313)
*Vladimer Khasia*

Main category: cs.LG

TL;DR: 提出了Spectral-Window Hybrid (SWH)架构，通过并行全局分支和局部分支来平衡长序列建模的计算效率和表示能力，解决Transformer的二次复杂度问题。


<details>
  <summary>Details</summary>
Motivation: Transformer的注意力机制虽然提供精确检索，但其O(T²)复杂度限制了在长序列任务中的应用。需要平衡计算效率与表示表达能力。

Method: SWH架构将序列建模解耦为两个并行流：全局分支利用卷积定理在O(T log T)时间内建模长程衰减动态，局部分支使用滑动窗口注意力处理有限上下文内的token交互。通过聚合这两种表示来避免全局注意力的计算瓶颈。

Result: SWH在短上下文上达到标准Transformer的困惑度水平，同时能够高效线性扩展到长序列。

Conclusion: SWH架构成功解决了长序列建模的计算瓶颈问题，在保持局部精度的同时实现了线性扩展能力。

Abstract: Scaling sequence modeling to extreme contexts requires balancing computational efficiency with representational expressivity. While Transformers provide precise retrieval via the attention mechanism, their quadratic $\mathcal{O}(T^2)$ complexity limits their application to long-horizon tasks. In this work, we propose the \textbf{Spectral-Window Hybrid (SWH)}, an architecture that decouples sequence modeling into two \textit{parallel} streams: a global branch utilizing the Convolution Theorem to model long-range decay dynamics in $\mathcal{O}(T \log T)$ time, and a local branch employing sliding-window attention for token interactions within a bounded context. By aggregating these representations, SWH avoids the computational bottleneck of global attention while retaining local precision. We demonstrate that SWH matches the perplexity of standard Transformers on short contexts while enabling efficient linear scaling to extended sequences. The code is available at https://github.com/VladimerKhasia/SWH

</details>


### [273] [From Classification to Generation: An Open-Ended Paradigm for Adverse Drug Reaction Prediction Based on Graph-Motif Feature Fusion](https://arxiv.org/abs/2601.01347)
*Yuyan Pi,Min Jin,Wentao Xie,Xinhua Liu*

Main category: cs.LG

TL;DR: GM-MLG提出了一种基于图-基序特征融合和多标签生成的开放式ADR预测范式，通过将分子结构表示为原子、局部和全局三个层次的双图架构，并将ADR预测从多标签分类转化为基于Transformer解码器的多标签生成，显著提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: 当前药物不良反应预测方法面临数据稀缺导致的冷启动问题、封闭标签集限制以及标签依赖关系建模不足等挑战，需要开发新的开放式预测范式。

Method: 构建原子级、局部分子级（使用BRICS算法动态提取细粒度基序）和全局分子级的双图表示架构；将ADR预测转化为基于Transformer解码器的多标签生成任务，使用位置嵌入显式捕捉标签依赖关系，通过自回归解码动态扩展预测空间。

Result: GM-MLG实现了最高38%的性能提升，平均增益20%，将预测空间从200种扩展到超过10,000种；通过逆合成基序分析揭示了ADR与基序之间的非线性结构-活性关系。

Conclusion: 该方法为药物安全性系统性风险降低提供了可解释的创新支持，开创了开放式ADR预测的新范式。

Abstract: Computational biology offers immense potential for reducing the high costs and protracted cycles of new drug development through adverse drug reaction (ADR) prediction. However, current methods remain impeded by drug data scarcity-induced cold-start challenge, closed label sets, and inadequate modeling of label dependencies. Here we propose an open-ended ADR prediction paradigm based on Graph-Motif feature fusion and Multi-Label Generation (GM-MLG). Leveraging molecular structure as an intrinsic and inherent feature, GM-MLG constructs a dual-graph representation architecture spanning the atomic level, the local molecular level (utilizing fine-grained motifs dynamically extracted via the BRICS algorithm combined with additional fragmentation rules), and the global molecular level. Uniquely, GM-MLG pioneers transforming ADR prediction from multi-label classification into Transformer Decoder-based multi-label generation. By treating ADR labels as discrete token sequences, it employs positional embeddings to explicitly capture dependencies and co-occurrence relationships within large-scale label spaces, generating predictions via autoregressive decoding to dynamically expand the prediction space. Experiments demonstrate GM-MLG achieves up to 38% improvement and an average gain of 20%, expanding the prediction space from 200 to over 10,000 types. Furthermore, it elucidates non-linear structure-activity relationships between ADRs and motifs via retrosynthetic motif analysis, providing interpretable and innovative support for systematic risk reduction in drug safety.

</details>


### [274] [Towards LLM-enabled autonomous combustion research: A literature-aware agent for self-corrective modeling workflows](https://arxiv.org/abs/2601.01357)
*Ke Xiao,Haoze Zhang,Runze Mao,Han Li,Zhi X. Chen*

Main category: cs.LG

TL;DR: FlamePilot是一个专门用于燃烧建模的LLM智能体，通过自动化CFD工作流实现科学文献知识提取与复杂仿真执行的融合，在公开基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前AI在复杂科学领域（如燃烧建模）的应用存在知识整合与工具执行能力的鸿沟，需要将领域文献知识与CFD等专业工具无缝集成。

Method: FlamePilot采用原子工具架构，支持OpenFOAM和DeepFlame等CFD框架的稳健仿真设置与执行，并能从科学文献中提取关键信息指导仿真流程。

Result: 在公开基准测试中，FlamePilot实现了1.0的可执行性得分和0.438的成功率，显著超越之前最佳代理的0.625和0.250得分。案例研究证明其能自主完成从论文到仿真的全流程。

Conclusion: FlamePilot建立了AI赋能燃烧建模的基础框架，通过透明可解释的范式实现人机协作，让研究者专注于高层次分析。

Abstract: The rapid evolution of large language models (LLMs) is transforming artificial intelligence into autonomous research partners, yet a critical gap persists in complex scientific domains such as combustion modeling. Here, practical AI assistance requires the seamless integration of domain literature knowledge with robust execution capabilities for expertise-intensive tools such as computational fluid dynamics (CFD) codes. To bridge this gap, we introduce FlamePilot, an LLM agent designed to empower combustion modeling research through automated and self-corrective CFD workflows. FlamePilot differentiates itself through an architecture that leverages atomic tools to ensure the robust setup and execution of complex simulations in both OpenFOAM and extended frameworks such as DeepFlame. The system is also capable of learning from scientific articles, extracting key information to guide the simulation from initial setup to optimized results. Validation on a public benchmark shows FlamePilot achieved a perfect 1.0 executability score and a 0.438 success rate, surpassing the prior best reported agent scores of 0.625 and 0.250, respectively. Furthermore, a detailed case study on Moderate or Intense Low-oxygen Dilution (MILD) combustion simulation demonstrates its efficacy as a collaborative research copilot, where FlamePilot autonomously translated a research paper into a configured simulation, conducted the simulation, post-processed the results, proposed evidence-based refinements, and managed a multi-step parameter study to convergence under minimal human intervention. By adopting a transparent and interpretable paradigm, FlamePilot establishes a foundational framework for AI-empowered combustion modeling, fostering a collaborative partnership where the agent manages workflow orchestration, freeing the researcher for high-level analysis.

</details>


### [275] [Causal discovery for linear causal model with correlated noise: an Adversarial Learning Approach](https://arxiv.org/abs/2601.01368)
*Mujin Zhou,Junzhe Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种基于f-GAN框架的因果发现方法，用于处理存在未测量混杂因素的数据，通过将结构学习问题转化为最小化贝叶斯自由能量，并利用f-divergence和对抗优化实现图结构学习。


<details>
  <summary>Details</summary>
Motivation: 在存在未测量混杂因素的数据中进行因果发现是一个具有挑战性的问题，传统方法往往依赖于特定的权重值，本文旨在开发一种不依赖于具体权重值的二元因果结构学习方法。

Method: 将结构学习问题重新表述为最小化贝叶斯自由能量，证明该问题等价于最小化真实数据分布与模型生成分布之间的f-divergence。利用f-GAN框架将该目标转化为min-max对抗优化问题，并在离散图空间中使用Gumbel-Softmax松弛实现梯度搜索。

Result: 该方法能够有效学习二元因果结构，且不依赖于特定的权重值配置，为存在未测量混杂因素的因果发现问题提供了新的解决方案。

Conclusion: 基于f-GAN框架的因果发现方法通过对抗优化和离散图空间的梯度搜索，成功解决了存在未测量混杂因素时的因果结构学习问题，为复杂数据环境下的因果推理提供了有效工具。

Abstract: Causal discovery from data with unmeasured confounding factors is a challenging problem. This paper proposes an approach based on the f-GAN framework, learning the binary causal structure independent of specific weight values. We reformulate the structure learning problem as minimizing Bayesian free energy and prove that this problem is equivalent to minimizing the f-divergence between the true data distribution and the model-generated distribution. Using the f-GAN framework, we transform this objective into a min-max adversarial optimization problem. We implement the gradient search in the discrete graph space using Gumbel-Softmax relaxation.

</details>


### [276] [Data Complexity-aware Deep Model Performance Forecasting](https://arxiv.org/abs/2601.01383)
*Yen-Chia Chen,Hsing-Kuo Pao,Hanjuan Huang*

Main category: cs.LG

TL;DR: 提出一个轻量级的两阶段框架，可以在训练前估计深度学习模型性能，通过分析数据集属性和模型结构来预测性能并指导模型选择。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型架构选择通常依赖重复的试错过程，这种方法耗时、资源密集且难以自动化。现有方法需要大量计算开销或缺乏通用性。

Method: 两阶段框架：第一阶段基于数据集的可测量属性预测基线性能；第二阶段结合模型架构和超参数细节调整估计。框架可泛化到不同数据集和模型类型。

Result: 框架不仅能预测模型性能，还能指导架构选择、预处理流程，并在训练前检测有问题的数据集。数据集方差等特征可作为数据质量的早期指标。

Conclusion: 该框架提供了一种计算效率高的替代方案，减少了模型选择的试错成本，同时为数据质量评估和模型选择提供了实用指导。

Abstract: Deep learning models are widely used across computer vision and other domains. When working on the model induction, selecting the right architecture for a given dataset often relies on repetitive trial-and-error procedures. This procedure is time-consuming, resource-intensive, and difficult to automate. While previous work has explored performance prediction using partial training or complex simulations, these methods often require significant computational overhead or lack generalizability. In this work, we propose an alternative approach: a lightweight, two-stage framework that can estimate model performance before training given the understanding of the dataset and the focused deep model structures. The first stage predicts a baseline based on the analysis of some measurable properties of the dataset, while the second stage adjusts the estimation with additional information on the model's architectural and hyperparameter details. The setup allows the framework to generalize across datasets and model types. Moreover, we find that some of the underlying features used for prediction - such as dataset variance - can offer practical guidance for model selection, and can serve as early indicators of data quality. As a result, the framework can be used not only to forecast model performance, but also to guide architecture choices, inform necessary preprocessing procedures, and detect potentially problematic datasets before training begins.

</details>


### [277] [Scale-Adaptive Power Flow Analysis with Local Topology Slicing and Multi-Task Graph Learning](https://arxiv.org/abs/2601.01387)
*Yongzhe Li,Lin Guan,Zihan Cai,Zuxian Lin,Jiyu Huang,Liukai Chen*

Main category: cs.LG

TL;DR: 本文提出了一个尺度自适应多任务电力潮流分析框架（SaMPFA），通过局部拓扑切片采样技术和无参考多任务图学习模型，提高了电力系统在不同规模下的适应性和分支功率预测的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 开发具有强拓扑适应性的深度学习模型对于电力潮流分析具有重要实际意义，旨在增强模型在可变系统规模下的性能并提高分支功率预测的鲁棒性。

Method: 提出了SaMPFA框架，包含局部拓扑切片（LTS）采样技术从完整电网中提取不同尺度的子图，以及无参考多任务图学习（RMGL）模型，该模型预测母线电压和分支功率而非相角，避免了误差放大风险。

Result: 在IEEE 39节点系统和中国某省实际电网上的仿真表明，该模型在可变系统规模下实现了优越的适应性和泛化能力，准确率分别提高了4.47%和36.82%。

Conclusion: 所提出的SaMPFA框架通过创新的采样技术和多任务学习设计，显著提升了电力潮流分析的跨尺度学习能力和物理一致性，为电力系统分析提供了有效的深度学习解决方案。

Abstract: Developing deep learning models with strong adaptability to topological variations is of great practical significance for power flow analysis. To enhance model performance under variable system scales and improve robustness in branch power prediction, this paper proposes a Scale-adaptive Multi-task Power Flow Analysis (SaMPFA) framework. SaMPFA introduces a Local Topology Slicing (LTS) sampling technique that extracts subgraphs of different scales from the complete power network to strengthen the model's cross-scale learning capability. Furthermore, a Reference-free Multi-task Graph Learning (RMGL) model is designed for robust power flow prediction. Unlike existing approaches, RMGL predicts bus voltages and branch powers instead of phase angles. This design not only avoids the risk of error amplification in branch power calculation but also guides the model to learn the physical relationships of phase angle differences. In addition, the loss function incorporates extra terms that encourage the model to capture the physical patterns of angle differences and power transmission, further improving consistency between predictions and physical laws. Simulations on the IEEE 39-bus system and a real provincial grid in China demonstrate that the proposed model achieves superior adaptability and generalization under variable system scales, with accuracy improvements of 4.47% and 36.82%, respectively.

</details>


### [278] [A Graph-based Framework for Online Time Series Anomaly Detection Using Model Ensemble](https://arxiv.org/abs/2601.01403)
*Zewei Yu,Jianqiu Xu,Caimin Li*

Main category: cs.LG

TL;DR: 本文提出GDME，一种基于图的无监督在线时间序列异常检测框架，通过模型集成和动态图结构处理异构流数据，在7个时间序列数据集上优于现有方法，性能提升达24%。


<details>
  <summary>Details</summary>
Motivation: 工业系统中流数据量不断增加，在线异常检测成为关键任务。现有方法多为离线设计或难以有效处理异构流数据，需要能够适应快速变化数据模式的在线检测框架。

Method: GDME维护动态模型池，通过剪枝表现不佳模型和引入新模型持续更新。使用动态图结构表示模型间关系，通过社区检测选择集成子集，并利用图结构变化监测概念漂移以适应流数据演化。

Result: 在7个异构时间序列上的实验表明，GDME优于现有在线异常检测方法，性能提升最高达24%。其集成策略相比单个模型和平均集成具有更优检测性能，同时保持计算效率竞争力。

Conclusion: GDME框架通过动态模型池和图结构集成策略，有效解决了在线时间序列异常检测中的异构流数据适应问题，为工业系统提供了高效的异常检测解决方案。

Abstract: With the increasing volume of streaming data in industrial systems, online anomaly detection has become a critical task. The diverse and rapidly evolving data patterns pose significant challenges for online anomaly detection. Many existing anomaly detection methods are designed for offline settings or have difficulty in handling heterogeneous streaming data effectively. This paper proposes GDME, an unsupervised graph-based framework for online time series anomaly detection using model ensemble. GDME maintains a dynamic model pool that is continuously updated by pruning underperforming models and introducing new ones. It utilizes a dynamic graph structure to represent relationships among models and employs community detection on the graph to select an appropriate subset for ensemble. The graph structure is also used to detect concept drift by monitoring structural changes, allowing the framework to adapt to evolving streaming data. Experiments on seven heterogeneous time series demonstrate that GDME outperforms existing online anomaly detection methods, achieving improvements of up to 24%. In addition, its ensemble strategy provides superior detection performance compared with both individual models and average ensembles, with competitive computational efficiency.

</details>


### [279] [A Depth Hierarchy for Computing the Maximum in ReLU Networks via Extremal Graph Theory](https://arxiv.org/abs/2601.01417)
*Itay Safran*

Main category: cs.LG

TL;DR: 本文证明了ReLU神经网络计算d个实数最大值函数时，在深度3≤k≤log₂(log₂(d))时，需要宽度Ω(d^{1+1/(2^{k-2}-1)})的深度层次结构，这是首个针对k≥3深度下该基本算子的无条件超线性下界。


<details>
  <summary>Details</summary>
Motivation: 研究ReLU神经网络计算最大值函数的内在复杂性，揭示尽管最大值函数看似简单，但其非可微超平面的几何结构导致计算复杂度随深度变化。

Method: 基于组合论证，将最大值函数的非可微分脊线与计算网络第一隐藏层诱导图中的团相关联，利用极值图论中的Turán定理证明足够窄的网络无法捕获最大值函数的非线性特性。

Result: 证明了深度3≤k≤log₂(log₂(d))时，计算最大值函数需要宽度Ω(d^{1+1/(2^{k-2}-1)})的ReLU神经网络，这是首个针对k≥3深度的无条件超线性下界。

Conclusion: 最大值函数具有源于其非可微超平面几何结构的内在复杂性，该证明技术为深度神经网络下界证明提供了新方法。

Abstract: We consider the problem of exact computation of the maximum function over $d$ real inputs using ReLU neural networks. We prove a depth hierarchy, wherein width $Ω\big(d^{1+\frac{1}{2^{k-2}-1}}\big)$ is necessary to represent the maximum for any depth $3\le k\le \log_2(\log_2(d))$. This is the first unconditional super-linear lower bound for this fundamental operator at depths $k\ge3$, and it holds even if the depth scales with $d$. Our proof technique is based on a combinatorial argument and associates the non-differentiable ridges of the maximum with cliques in a graph induced by the first hidden layer of the computing network, utilizing Turán's theorem from extremal graph theory to show that a sufficiently narrow network cannot capture the non-linearities of the maximum. This suggests that despite its simple nature, the maximum function possesses an inherent complexity that stems from the geometric structure of its non-differentiable hyperplanes, and provides a novel approach for proving lower bounds for deep neural networks.

</details>


### [280] [Unveiling the Heart-Brain Connection: An Analysis of ECG in Cognitive Performance](https://arxiv.org/abs/2601.01424)
*Akshay Sasi,Malavika Pradeep,Nusaibah Farrukh,Rahul Venugopal,Elizabeth Sherly*

Main category: cs.LG

TL;DR: 本研究提出了一种跨模态XGBoost框架，将ECG特征映射到EEG认知空间，证明ECG可作为EEG的替代指标进行认知负荷监测。


<details>
  <summary>Details</summary>
Motivation: 虽然EEG是评估心理负荷的金标准，但其便携性限制了实际应用。ECG通过可穿戴设备提供了实用的替代方案，需要验证ECG能否可靠反映认知负荷并作为EEG指标的代理。

Method: 采集多模态数据（工作记忆和被动聆听任务），提取ECG时域HRV指标和Catch22描述符，对应EEG频谱和Catch22特征。提出跨模态XGBoost框架将ECG特征投影到EEG代表性认知空间。

Result: ECG衍生的投影能显著捕捉认知状态变化，支持准确的分类任务。

Conclusion: ECG可作为可解释、实时、可穿戴的日常认知监测解决方案。

Abstract: Understanding the interaction of neural and cardiac systems during cognitive activity is critical to advancing physiological computing. Although EEG has been the gold standard for assessing mental workload, its limited portability restricts its real-world use. Widely available ECG through wearable devices proposes a pragmatic alternative. This research investigates whether ECG signals can reliably reflect cognitive load and serve as proxies for EEG-based indicators. In this work, we present multimodal data acquired from two different paradigms involving working-memory and passive-listening tasks. For each modality, we extracted ECG time-domain HRV metrics and Catch22 descriptors against EEG spectral and Catch22 features, respectively. We propose a cross-modal XGBoost framework to project the ECG features onto EEG-representative cognitive spaces, thereby allowing workload inferences using only ECG. Our results show that ECG-derived projections expressively capture variation in cognitive states and provide good support for accurate classification. Our findings underpin ECG as an interpretable, real-time, wearable solution for everyday cognitive monitoring.

</details>


### [281] [Bayesian Subspace Gradient Estimation for Zeroth-Order Optimization of Large Language Models](https://arxiv.org/abs/2601.01452)
*Jian Feng,Zhihong Huang*

Main category: cs.LG

TL;DR: BSZO是一种基于贝叶斯子空间的零阶优化方法，通过卡尔曼滤波结合多扰动方向的有限差分信息，相比传统ZO方法显著提升收敛速度和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的零阶优化方法依赖单步随机扰动的梯度估计，存在效率低下和收敛慢的问题，需要更有效的梯度估计机制。

Method: 提出BSZO方法，将每个有限差分测量视为噪声观测，通过卡尔曼滤波构建投影梯度的后验分布，并采用基于残差的自适应机制调整扰动尺度。

Result: 理论分析显示BSZO收敛速度比标准ZO方法提升k/γ倍；在RoBERTa、Mistral和OPT模型上的实验表明，BSZO优于MeZO、MeZO-Adam和HiZOO，在OPT-13B上实现6.67%的绝对平均提升，内存使用接近推理基线。

Conclusion: BSZO通过贝叶斯推断有效利用多方向扰动信息，显著提升零阶优化的收敛效率和性能，同时保持低内存占用。

Abstract: Fine-tuning large language models (LLMs) with zeroth-order (ZO) optimization reduces memory by approximating gradients through function evaluations, but existing methods rely on one-step gradient estimates from random perturbations. We introduce Bayesian Subspace Zeroth-Order optimization (BSZO), a ZO optimizer that applies Kalman filtering to combine finite-difference information across multiple perturbation directions. By treating each finite-difference measurement as a noisy observation, BSZO builds a posterior distribution over the projected gradient and updates it through Bayesian inference, with a residual-based adaptive mechanism to adjust perturbation scales. Theoretical analysis shows that BSZO improves the convergence rate by a factor of $k/γ$ compared to standard ZO methods. Experiments on RoBERTa, Mistral, and OPT models show that BSZO outperforms MeZO, MeZO-Adam, and HiZOO across various tasks, achieving up to 6.67\% absolute average improvement on OPT-13B while keeping memory usage close to inference-only baselines (1.00$\times$--1.08$\times$ of MeZO).

</details>


### [282] [Leveraging Flatness to Improve Information-Theoretic Generalization Bounds for SGD](https://arxiv.org/abs/2601.01465)
*Ze Peng,Jian Zhang,Yisen Wang,Lei Qi,Yinghuan Shi,Yang Gao*

Main category: cs.LG

TL;DR: 该论文提出了一个更充分利用平坦性偏差的信息论泛化界，用于分析SGD算法的泛化性能，并通过实验验证了该界在数值上更紧且能正确反映平坦性改善带来的泛化提升。


<details>
  <summary>Details</summary>
Motivation: 现有信息论泛化界未能充分捕捉SGD的平坦性偏差对泛化的影响，导致在平坦性改善时无法正确反映泛化提升，且数值上较为宽松。

Method: 提出"全知轨迹"技术，推导出更充分利用平坦性偏差的信息论泛化界，该界表明当最终权重协方差的大方差方向在损失景观中具有较小局部曲率时，学习模型泛化更好。

Result: 在深度神经网络上的实验表明，新界不仅正确反映了平坦性改善时的泛化提升，数值上也更紧。应用于梯度下降的极小极大超额风险时，将代表性信息论界的Ω(1)率改进为O(1/√n)。

Conclusion: 新提出的信息论泛化界成功捕捉了SGD的平坦性偏差，提供了更紧的泛化保证，并暗示了可以绕过记忆化-泛化权衡。

Abstract: Information-theoretic (IT) generalization bounds have been used to study the generalization of learning algorithms. These bounds are intrinsically data- and algorithm-dependent so that one can exploit the properties of data and algorithm to derive tighter bounds. However, we observe that although the flatness bias is crucial for SGD's generalization, these bounds fail to capture the improved generalization under better flatness and are also numerically loose. This is caused by the inadequate leverage of SGD's flatness bias in existing IT bounds. This paper derives a more flatness-leveraging IT bound for the flatness-favoring SGD. The bound indicates the learned models generalize better if the large-variance directions of the final weight covariance have small local curvatures in the loss landscape. Experiments on deep neural networks show our bound not only correctly reflects the better generalization when flatness is improved, but is also numerically much tighter. This is achieved by a flexible technique called "omniscient trajectory". When applied to Gradient Descent's minimax excess risk on convex-Lipschitz-Bounded problems, it improves representative IT bounds' $Ω(1)$ rates to $O(1/\sqrt{n})$. It also implies a by-pass of memorization-generalization trade-offs.

</details>


### [283] [Accelerating Storage-Based Training for Graph Neural Networks](https://arxiv.org/abs/2601.01473)
*Myung-Hwan Jang,Jeong-Min Park,Yunyong Ko,Sang-Wook Kim*

Main category: cs.LG

TL;DR: AGNES是一个基于存储的GNN训练框架，通过块级存储I/O处理和超批次处理技术，解决了大规模图数据训练中的I/O瓶颈问题，性能比现有最佳方法快4.1倍。


<details>
  <summary>Details</summary>
Motivation: 现有的基于存储的GNN训练方法在处理大规模图数据时，忽视了大量小型存储I/O操作带来的严重瓶颈问题，导致数据准备阶段效率低下。

Method: AGNES采用块级存储I/O处理技术来充分利用高性能存储设备的I/O带宽，并结合超批次处理策略来进一步提高每个存储I/O的效率。

Result: 在五个真实世界图数据集上的综合实验表明，AGNES持续优于四种最先进的方法，比最佳竞争对手快达4.1倍。

Conclusion: AGNES通过创新的存储I/O优化技术，有效解决了大规模GNN训练中的数据准备瓶颈，为处理web级图数据提供了高效的解决方案。

Abstract: Graph neural networks (GNNs) have achieved breakthroughs in various real-world downstream tasks due to their powerful expressiveness. As the scale of real-world graphs has been continuously growing, \textit{a storage-based approach to GNN training} has been studied, which leverages external storage (e.g., NVMe SSDs) to handle such web-scale graphs on a single machine. Although such storage-based GNN training methods have shown promising potential in large-scale GNN training, we observed that they suffer from a severe bottleneck in data preparation since they overlook a critical challenge: \textit{how to handle a large number of small storage I/Os}. To address the challenge, in this paper, we propose a novel storage-based GNN training framework, named \textsf{AGNES}, that employs a method of \textit{block-wise storage I/O processing} to fully utilize the I/O bandwidth of high-performance storage devices. Moreover, to further enhance the efficiency of each storage I/O, \textsf{AGNES} employs a simple yet effective strategy, \textit{hyperbatch-based processing} based on the characteristics of real-world graphs. Comprehensive experiments on five real-world graphs reveal that \textsf{AGNES} consistently outperforms four state-of-the-art methods, by up to 4.1$\times$ faster than the best competitor. Our code is available at https://github.com/Bigdasgit/agnes-kdd26.

</details>


### [284] [Multi-Subspace Multi-Modal Modeling for Diffusion Models: Estimation, Convergence and Mixture of Experts](https://arxiv.org/abs/2601.01475)
*Ruofeng Yang,Yongcan Li,Bo Jiang,Cheng Chen,Shuai Li*

Main category: cs.LG

TL;DR: 本文提出MoLR-MoG建模方法，通过混合低秩高斯混合模型来捕捉数据的多模态特性，解决了扩散模型在高维数据中的维度灾难问题，并在理论和实验上证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型虽然在小数据集上表现良好，但估计误差受数据维度D的影响（n^{-1/D}）。虽然现有工作通过高斯潜在变量建模线性子空间实现了1/√n的误差界，但高斯潜在变量无法捕捉潜在流形的多模态特性。

Method: 提出MoLR-MoG（混合低秩高斯混合）建模：将目标数据建模为K个线性子空间的并集，每个子空间采用高斯混合潜在变量（n_k个模态，维度d_k）。对应的得分函数具有混合专家结构，能捕捉多模态信息并包含非线性特性。

Result: 实验表明MoE潜在MoG神经网络的生成结果优于MoE潜在高斯得分，且与参数多10倍的MoE潜在Unet性能相当。理论分析给出了R^4√(∑n_k)√(∑n_kd_k)/√n的估计误差界，避免了维度灾难。

Conclusion: MoLR-MoG建模合理且适用于真实数据，解释了为什么扩散模型只需要小训练样本和快速优化过程就能获得优异性能，同时提供了优化过程的收敛保证。

Abstract: Recently, diffusion models have achieved a great performance with a small dataset of size $n$ and a fast optimization process. However, the estimation error of diffusion models suffers from the curse of dimensionality $n^{-1/D}$ with the data dimension $D$. Since images are usually a union of low-dimensional manifolds, current works model the data as a union of linear subspaces with Gaussian latent and achieve a $1/\sqrt{n}$ bound. Though this modeling reflects the multi-manifold property, the Gaussian latent can not capture the multi-modal property of the latent manifold. To bridge this gap, we propose the mixture subspace of low-rank mixture of Gaussian (MoLR-MoG) modeling, which models the target data as a union of $K$ linear subspaces, and each subspace admits a mixture of Gaussian latent ($n_k$ modals with dimension $d_k$). With this modeling, the corresponding score function naturally has a mixture of expert (MoE) structure, captures the multi-modal information, and contains nonlinear property. We first conduct real-world experiments to show that the generation results of MoE-latent MoG NN are much better than MoE-latent Gaussian score. Furthermore, MoE-latent MoG NN achieves a comparable performance with MoE-latent Unet with $10 \times$ parameters. These results indicate that the MoLR-MoG modeling is reasonable and suitable for real-world data. After that, based on such MoE-latent MoG score, we provide a $R^4\sqrt{Σ_{k=1}^Kn_k}\sqrt{Σ_{k=1}^Kn_kd_k}/\sqrt{n}$ estimation error, which escapes the curse of dimensionality by using data structure. Finally, we study the optimization process and prove the convergence guarantee under the MoLR-MoG modeling. Combined with these results, under a setting close to real-world data, this work explains why diffusion models only require a small training sample and enjoy a fast optimization process to achieve a great performance.

</details>


### [285] [SGD-Based Knowledge Distillation with Bayesian Teachers: Theory and Guidelines](https://arxiv.org/abs/2601.01484)
*Itai Morad,Nir Shlezinger,Yonina C. Eldar*

Main category: cs.LG

TL;DR: 本文从贝叶斯视角分析知识蒸馏的理论基础，研究从贝叶斯分类概率和噪声近似中学习的收敛行为，发现贝叶斯教师能提高学生模型准确率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 知识蒸馏在应用中表现出色，但其理论基础尚未完全理解。本文旨在通过贝叶斯视角对知识蒸馏的收敛行为进行严格理论分析。

Method: 采用贝叶斯视角，使用随机梯度下降分析学生模型收敛行为，研究两种监督方式：精确贝叶斯分类概率和噪声近似。通过理论分析和实验验证，比较贝叶斯教师与确定性教师的效果。

Result: 分析表明，从贝叶斯分类概率学习能减少方差并消除收敛边界中的邻域项。实验证明，从贝叶斯教师蒸馏的学生模型准确率提高最多4.27%，收敛稳定性提高30%。

Conclusion: 贝叶斯深度学习模型作为教师能提供更好的贝叶斯分类概率估计，从而在知识蒸馏中产生更准确、更稳定的学生模型。

Abstract: Knowledge Distillation (KD) is a central paradigm for transferring knowledge from a large teacher network to a typically smaller student model, often by leveraging soft probabilistic outputs. While KD has shown strong empirical success in numerous applications, its theoretical underpinnings remain only partially understood. In this work, we adopt a Bayesian perspective on KD to rigorously analyze the convergence behavior of students trained with Stochastic Gradient Descent (SGD). We study two regimes: $(i)$ when the teacher provides the exact Bayes Class Probabilities (BCPs); and $(ii)$ supervision with noisy approximations of the BCPs. Our analysis shows that learning from BCPs yields variance reduction and removes neighborhood terms in the convergence bounds compared to one-hot supervision. We further characterize how the level of noise affects generalization and accuracy. Motivated by these insights, we advocate the use of Bayesian deep learning models, which typically provide improved estimates of the BCPs, as teachers in KD. Consistent with our analysis, we experimentally demonstrate that students distilled from Bayesian teachers not only achieve higher accuracies (up to +4.27%), but also exhibit more stable convergence (up to 30% less noise), compared to students distilled from deterministic teachers.

</details>


### [286] [Accelerating Decentralized Optimization via Overlapping Local Steps](https://arxiv.org/abs/2601.01493)
*Yijie Zhou,Shi Pu*

Main category: cs.LG

TL;DR: OLDSGD是一种通过计算-通信重叠加速去中心化训练的新方法，在保持与Local SGD相同平均更新的同时显著减少网络空闲时间。


<details>
  <summary>Details</summary>
Motivation: 现有的去中心化优化方法由于节点间频繁同步而面临通信瓶颈问题，需要一种能够减少通信延迟影响的高效训练方法。

Method: 提出OLDSGD方法，通过精心设计的更新机制实现计算与通信的重叠，在保持与标准Local Decentralized SGD相同迭代复杂度的同时改善每轮迭代的运行时间。

Result: 理论分析表明OLDSGD在平滑非凸目标上具有非渐近收敛率，实证结果在不同通信延迟水平下均显示出wall-clock时间收敛的持续改进。

Conclusion: OLDSGD通过最小化现有框架的修改，提供了一个在不牺牲理论保证的前提下实现更快去中心化学习的实用解决方案。

Abstract: Decentralized optimization has emerged as a critical paradigm for distributed learning, enabling scalable training while preserving data privacy through peer-to-peer collaboration. However, existing methods often suffer from communication bottlenecks due to frequent synchronization between nodes. We present Overlapping Local Decentralized SGD (OLDSGD), a novel approach to accelerate decentralized training by computation-communication overlapping, significantly reducing network idle time. With a deliberately designed update, OLDSGD preserves the same average update as Local SGD while avoiding communication-induced stalls. Theoretically, we establish non-asymptotic convergence rates for smooth non-convex objectives, showing that OLDSGD retains the same iteration complexity as standard Local Decentralized SGD while improving per-iteration runtime. Empirical results demonstrate OLDSGD's consistent improvements in wall-clock time convergence under different levels of communication delays. With minimal modifications to existing frameworks, OLDSGD offers a practical solution for faster decentralized learning without sacrificing theoretical guarantees.

</details>


### [287] [Advanced Global Wildfire Activity Modeling with Hierarchical Graph ODE](https://arxiv.org/abs/2601.01501)
*Fan Xu,Wei Gong,Hao Wu,Lilan Peng,Nan Wang,Qingsong Wen,Xian Wu,Kun Wang,Xibin Zhao*

Main category: cs.LG

TL;DR: HiGO框架通过多层级图结构和连续时间动力学建模，显著提升了全球野火长期预测性能


<details>
  <summary>Details</summary>
Motivation: 野火受地球系统多尺度过程影响，现有深度学习模型在全局野火行为预测方面潜力未得到充分探索

Method: 提出分层图常微分方程框架，将地球系统表示为多层级图结构，采用自适应滤波消息传递机制和GNN参数化神经ODE模块

Result: 在SeasFire Cube数据集上实验表明，HiGO在长期野火预测任务中显著优于现有最优基线，且连续时间预测具有强观测一致性

Conclusion: HiGO框架展现了在真实世界应用中预测多尺度野火动态的潜力，为全球野火建模提供了新思路

Abstract: Wildfires, as an integral component of the Earth system, are governed by a complex interplay of atmospheric, oceanic, and terrestrial processes spanning a vast range of spatiotemporal scales. Modeling their global activity on large timescales is therefore a critical yet challenging task. While deep learning has recently achieved significant breakthroughs in global weather forecasting, its potential for global wildfire behavior prediction remains underexplored. In this work, we reframe this problem and introduce the Hierarchical Graph ODE (HiGO), a novel framework designed to learn the multi-scale, continuous-time dynamics of wildfires. Specifically, we represent the Earth system as a multi-level graph hierarchy and propose an adaptive filtering message passing mechanism for both intra- and inter-level information flow, enabling more effective feature extraction and fusion. Furthermore, we incorporate GNN-parameterized Neural ODE modules at multiple levels to explicitly learn the continuous dynamics inherent to each scale. Through extensive experiments on the SeasFire Cube dataset, we demonstrate that HiGO significantly outperforms state-of-the-art baselines on long-range wildfire forecasting. Moreover, its continuous-time predictions exhibit strong observational consistency, highlighting its potential for real-world applications.

</details>


### [288] [Utilizing Earth Foundation Models to Enhance the Simulation Performance of Hydrological Models with AlphaEarth Embeddings](https://arxiv.org/abs/2601.01558)
*Pengfei Qu,Wenyu Ouyang,Chi Zhang,Yikai Chai,Shuolong Xu,Lei Ye,Yongri Piao,Miao Zhang,Huchuan Lu*

Main category: cs.LG

TL;DR: 该研究探讨了使用AlphaEarth Foundation嵌入（从卫星图像学习的环境表示）是否比传统流域属性更能有效预测未测量流域的河流流量。


<details>
  <summary>Details</summary>
Motivation: 传统流域属性无法完全捕捉自然环境的复杂性，导致在无流量记录流域的流量预测存在挑战。需要更有效的方法来描述流域特征差异。

Method: 使用AlphaEarth Foundation嵌入（从大量卫星图像学习的环境表示）来总结植被、地表特征和长期环境动态模式，并研究如何基于嵌入相似性选择合适的供体流域。

Result: 使用嵌入的模型在未用于训练的流域中预测精度更高，嵌入能更有效地捕捉关键物理差异。基于嵌入相似性选择供体流域能提高预测性能，而添加不相似流域会降低准确性。

Conclusion: 卫星信息驱动的环境表示可以增强水文预报能力，支持开发更容易适应不同景观的模型。

Abstract: Predicting river flow in places without streamflow records is challenging because basins respond differently to climate, terrain, vegetation, and soils. Traditional basin attributes describe some of these differences, but they cannot fully represent the complexity of natural environments. This study examines whether AlphaEarth Foundation embeddings, which are learned from large collections of satellite images rather than designed by experts, offer a more informative way to describe basin characteristics. These embeddings summarize patterns in vegetation, land surface properties, and long-term environmental dynamics. We find that models using them achieve higher accuracy when predicting flows in basins not used for training, suggesting that they capture key physical differences more effectively than traditional attributes. We further investigate how selecting appropriate donor basins influences prediction in ungauged regions. Similarity based on the embeddings helps identify basins with comparable environmental and hydrological behavior, improving performance, whereas adding many dissimilar basins can reduce accuracy. The results show that satellite-informed environmental representations can strengthen hydrological forecasting and support the development of models that adapt more easily to different landscapes.

</details>


### [289] [The Two-Stage Decision-Sampling Hypothesis: Understanding the Emergence of Self-Reflection in RL-Trained LLMs](https://arxiv.org/abs/2601.01580)
*Zibo Zhao,Yuanting Zha,Haipeng Zhang,Xingcheng Xu*

Main category: cs.LG

TL;DR: 本文通过梯度归因属性分析RL后训练如何在大语言模型中产生自反思维能力，提出两阶段决策-采样假说，解释RL相比SFT在自校正方面的优势机制


<details>
  <summary>Details</summary>
Motivation: 理解RL后训练如何通过统一优化目标产生功能不同的生成解决方案和评估修订的能力，揭示RL成功而SFT失败的理论机制

Method: 引入梯度归因属性，形式化两阶段决策-采样假说，将策略分解为生成用的采样策略和验证用的决策策略，分析不同训练方法的梯度分布特性

Result: 证明替代奖励呈现平衡梯度归因，而SFT和KL惩罚呈现不平衡梯度归因，长度加权导致非对称正则化约束采样策略而决策策略优化不足

Conclusion: RL的优越泛化能力主要来自改进的决策能力而非采样能力，为思维模型中的自校正提供了第一性原理的机制解释

Abstract: Self-reflection capabilities emerge in Large Language Models after RL post-training, with multi-turn RL achieving substantial gains over SFT counterparts. Yet the mechanism of how a unified optimization objective gives rise to functionally distinct capabilities of generating solutions and evaluating when to revise them remains opaque. To address this question, we introduce the Gradient Attribution Property to characterize how reward gradients distribute across policy components, formalized through the Two-Stage Decision-Sampling (DS) Hypothesis, which decomposes the policy into sampling ($π_{sample}$) for generation and decision ($π_{d}$) for verification. We prove that surrogate rewards exhibit Balanced Gradient Attribution, while SFT and KL penalties exhibit Unbalanced Gradient Attribution, with length-weighting creating asymmetric regularization that constrains $π_{sample}$ while leaving $π_{d}$ under-optimized, providing an theoretical explanation of why RL succeeds where SFT fails. We also empirically validate our theoretical predictions on arithmetic reasoning demonstrates that RL's superior generalization stems primarily from improved decision-making ($π_{d}$) rather than sampling capabilities, providing a first-principles mechanistic explanation for self-correction in thinking models.

</details>


### [290] [REE-TTT: Highly Adaptive Radar Echo Extrapolation Based on Test-Time Training](https://arxiv.org/abs/2601.01605)
*Xin Di,Xinglin Piao,Fei Wang,Guodong Jing,Yong Zhang*

Main category: cs.LG

TL;DR: 本文提出REE-TTT模型，通过集成自适应测试时训练机制，解决了传统雷达回波外推方法在跨区域和极端天气事件中泛化能力差的问题。


<details>
  <summary>Details</summary>
Motivation: 传统的基于深度学习的雷达回波外推方法依赖高质量本地训练数据和静态模型参数，导致在多样化区域和极端事件中泛化能力不足。

Method: 设计了时空测试时训练块，将TTT层中的标准线性投影替换为任务特定的注意力机制，使模型能够适应非平稳气象分布。

Result: 在跨区域极端降水场景下的实验表明，REE-TTT在预测精度和泛化能力上显著优于现有基准模型。

Conclusion: REE-TTT模型通过自适应测试时训练机制有效提升了降水临近预报的适应性和准确性，特别是在数据分布变化的情况下表现出色。

Abstract: Precipitation nowcasting is critically important for meteorological forecasting. Deep learning-based Radar Echo Extrapolation (REE) has become a predominant nowcasting approach, yet it suffers from poor generalization due to its reliance on high-quality local training data and static model parameters, limiting its applicability across diverse regions and extreme events. To overcome this, we propose REE-TTT, a novel model that incorporates an adaptive Test-Time Training (TTT) mechanism. The core of our model lies in the newly designed Spatio-temporal Test-Time Training (ST-TTT) block, which replaces the standard linear projections in TTT layers with task-specific attention mechanisms, enabling robust adaptation to non-stationary meteorological distributions and thereby significantly enhancing the feature representation of precipitation. Experiments under cross-regional extreme precipitation scenarios demonstrate that REE-TTT substantially outperforms state-of-the-art baseline models in prediction accuracy and generalization, exhibiting remarkable adaptability to data distribution shifts.

</details>


### [291] [Real Time NILM Based Power Monitoring of Identical Induction Motors Representing Cutting Machines in Textile Industry](https://arxiv.org/abs/2601.01616)
*Md Istiauk Hossain Rifat,Moin Khan,Mohammad Zunaed*

Main category: cs.LG

TL;DR: 本文提出了一种基于非侵入式负荷监测（NILM）的实时框架，用于监测孟加拉国纺织工业中相同电机驱动的切割机负荷，开发了硬件和云平台系统，创建了包含18万多个样本的数据集，评估了MATNILM模型在工业条件下的性能。


<details>
  <summary>Details</summary>
Motivation: 孟加拉国纺织工业是能源密集型行业，但监测方法落后，导致能源使用效率低下和运营成本高昂，需要实时监控解决方案来提高能效。

Method: 开发了包含电压电流传感器、Arduino Mega和ESP8266的硬件系统，采集总负荷和单个负荷数据，在云平台存储处理，创建了三个相同感应电机和辅助负荷的数据集，使用MATNILM模型进行评估。

Result: 总能耗估计相对准确，但在多个相同机器同时运行时，单个设备负荷分解面临困难。集成系统通过Blynk应用实现了实用的实时远程监控。

Conclusion: 该研究展示了NILM在工业应用中的潜力和局限性，建议未来通过更高频率数据采集、更大规模数据集和先进深度学习方法来处理相同负荷问题。

Abstract: The textile industry in Bangladesh is one of the most energy-intensive sectors, yet its monitoring practices remain largely outdated, resulting in inefficient power usage and high operational costs. To address this, we propose a real-time Non-Intrusive Load Monitoring (NILM)-based framework tailored for industrial applications, with a focus on identical motor-driven loads representing textile cutting machines. A hardware setup comprising voltage and current sensors, Arduino Mega and ESP8266 was developed to capture aggregate and individual load data, which was stored and processed on cloud platforms. A new dataset was created from three identical induction motors and auxiliary loads, totaling over 180,000 samples, to evaluate the state-of-the-art MATNILM model under challenging industrial conditions. Results indicate that while aggregate energy estimation was reasonably accurate, per-appliance disaggregation faced difficulties, particularly when multiple identical machines operated simultaneously. Despite these challenges, the integrated system demonstrated practical real-time monitoring with remote accessibility through the Blynk application. This work highlights both the potential and limitations of NILM in industrial contexts, offering insights into future improvements such as higher-frequency data collection, larger-scale datasets and advanced deep learning approaches for handling identical loads.

</details>


### [292] [Communication-Efficient Federated AUC Maximization with Cyclic Client Participation](https://arxiv.org/abs/2601.01649)
*Umesh Vangapally,Wenhan Wu,Chen Chen,Zhishuai Guo*

Main category: cs.LG

TL;DR: 本文针对联邦学习中客户周期性参与场景下的AUC最大化问题，提出了两种通信高效的算法，分别在平方替代损失和通用成对AUC损失下建立了最优的通信和迭代复杂度，并通过实验验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有联邦AUC最大化方法通常假设客户完全可用，但实际FL系统中客户往往按固定周期参与训练。这种周期性参与给非可分解的AUC目标带来了独特的优化挑战。

Method: 研究两种设置：1）使用平方替代损失将问题重构为非凸-强凹极小极大优化，利用PL条件；2）考虑通用成对AUC损失。提出了相应的通信高效算法。

Result: 平方损失设置下达到通信复杂度$\widetilde{O}(1/ε^{1/2})$和迭代复杂度$\widetilde{O}(1/ε)$；通用损失下通信复杂度$O(1/ε^3)$，迭代复杂度$O(1/ε^4)$，在PL条件下可提升至$\widetilde{O}(1/ε^{1/2})$和$\widetilde{O}(1/ε)$。

Conclusion: 在图像分类、医学影像和欺诈检测等基准任务上的实验表明，所提方法具有优越的效率和有效性，解决了周期性客户参与下的联邦AUC最大化问题。

Abstract: Federated AUC maximization is a powerful approach for learning from imbalanced data in federated learning (FL). However, existing methods typically assume full client availability, which is rarely practical. In real-world FL systems, clients often participate in a cyclic manner: joining training according to a fixed, repeating schedule. This setting poses unique optimization challenges for the non-decomposable AUC objective. This paper addresses these challenges by developing and analyzing communication-efficient algorithms for federated AUC maximization under cyclic client participation. We investigate two key settings: First, we study AUC maximization with a squared surrogate loss, which reformulates the problem as a nonconvex-strongly-concave minimax optimization. By leveraging the Polyak-Łojasiewicz (PL) condition, we establish a state-of-the-art communication complexity of $\widetilde{O}(1/ε^{1/2})$ and iteration complexity of $\widetilde{O}(1/ε)$. Second, we consider general pairwise AUC losses. We establish a communication complexity of $O(1/ε^3)$ and an iteration complexity of $O(1/ε^4)$. Further, under the PL condition, these bounds improve to communication complexity of $\widetilde{O}(1/ε^{1/2})$ and iteration complexity of $\widetilde{O}(1/ε)$. Extensive experiments on benchmark tasks in image classification, medical imaging, and fraud detection demonstrate the superior efficiency and effectiveness of our proposed methods.

</details>


### [293] [Learning Resilient Elections with Adversarial GNNs](https://arxiv.org/abs/2601.01653)
*Hao Xiang Li,Yash Shah,Lorenzo Giusti*

Main category: cs.LG

TL;DR: 本文提出了一种结合图神经网络和对抗训练的投票规则学习方法，旨在提高投票系统的鲁棒性和社会福利最大化。


<details>
  <summary>Details</summary>
Motivation: 传统投票规则难以满足所有假设场景的需求，而现有的自动化机制设计方法在应对策略性投票等现实问题时存在局限性。

Method: 使用二分图表示选举过程，并利用图神经网络学习投票规则，同时结合对抗训练提高模型的鲁棒性。

Result: 在合成和真实数据集上的评估表明，该方法能够有效解决先前工作的关键限制，提高了投票规则的弹性。

Conclusion: 该方法为机器学习在现实世界选举中的应用开辟了新前沿，展示了图神经网络在投票系统设计中的潜力。

Abstract: In the face of adverse motives, it is indispensable to achieve a consensus. Elections have been the canonical way by which modern democracy has operated since the 17th century. Nowadays, they regulate markets, provide an engine for modern recommender systems or peer-to-peer networks, and remain the main approach to represent democracy. However, a desirable universal voting rule that satisfies all hypothetical scenarios is still a challenging topic, and the design of these systems is at the forefront of mechanism design research. Automated mechanism design is a promising approach, and recent works have demonstrated that set-invariant architectures are uniquely suited to modelling electoral systems. However, various concerns prevent the direct application to real-world settings, such as robustness to strategic voting. In this paper, we generalise the expressive capability of learned voting rules, and combine improvements in neural network architecture with adversarial training to improve the resilience of voting rules while maximizing social welfare. We evaluate the effectiveness of our methods on both synthetic and real-world datasets. Our method resolves critical limitations of prior work regarding learning voting rules by representing elections using bipartite graphs, and learning such voting rules using graph neural networks. We believe this opens new frontiers for applying machine learning to real-world elections.

</details>


### [294] [Length-Aware Adversarial Training for Variable-Length Trajectories: Digital Twins for Mall Shopper Paths](https://arxiv.org/abs/2601.01663)
*He Sun,Jiwoong Shin,Ravi Dhar*

Main category: cs.LG

TL;DR: 本文提出了一种针对变长轨迹生成建模的长度感知采样方法，通过按长度分组采样来减少批次内长度异质性，从而改善分布匹配效果


<details>
  <summary>Details</summary>
Motivation: 标准小批量训练在轨迹长度高度异质时会出现不稳定问题，这会影响轨迹衍生统计量的分布匹配质量

Method: 提出长度感知采样策略，将轨迹按长度分组，从单一长度桶中采样批次，减少批次内长度异质性，并将其整合到带有辅助时间对齐损失的条件轨迹GAN中

Result: 实验表明，LAS在多商场购物者轨迹数据集和多个公共序列数据集上均能一致改善衍生变量分布的匹配效果，优于随机采样

Conclusion: LAS是一种简单有效的批处理策略，无需改变模型结构即可通过减少长度异质性来提升生成模型的分布匹配性能

Abstract: We study generative modeling of \emph{variable-length trajectories} -- sequences of visited locations/items with associated timestamps -- for downstream simulation and counterfactual analysis. A recurring practical issue is that standard mini-batch training can be unstable when trajectory lengths are highly heterogeneous, which in turn degrades \emph{distribution matching} for trajectory-derived statistics. We propose \textbf{length-aware sampling (LAS)}, a simple batching strategy that groups trajectories by length and samples batches from a single length bucket, reducing within-batch length heterogeneity (and making updates more consistent) without changing the model class. We integrate LAS into a conditional trajectory GAN with auxiliary time-alignment losses and provide (i) a distribution-level guarantee for derived variables under mild boundedness assumptions, and (ii) an IPM/Wasserstein mechanism explaining why LAS improves distribution matching by removing length-only shortcut critics and targeting within-bucket discrepancies. Empirically, LAS consistently improves matching of derived-variable distributions on a multi-mall dataset of shopper trajectories and on diverse public sequence datasets (GPS, education, e-commerce, and movies), outperforming random sampling across dataset-specific metrics.

</details>


### [295] [Who is the Winning Algorithm? Rank Aggregation for Comparative Studies](https://arxiv.org/abs/2601.01664)
*Amichai Painsky*

Main category: cs.LG

TL;DR: 该论文提出了一种新的框架，利用算法在基准数据集上的完整排名信息（而不仅仅是获胜次数）来更准确地估计每个算法在未来未见数据集上的获胜概率。


<details>
  <summary>Details</summary>
Motivation: 当前基于最大似然估计的方法只统计每个算法的获胜次数，但忽略了算法排名中的完整信息（如第二名、第三名等），这些信息可能对预测未来表现有重要价值。

Method: 引入了一个新的概念框架，通过分析算法在基准数据集上的完整排名分布来估计每个算法的获胜概率，而不仅仅是统计获胜次数。

Result: 在合成和真实世界的示例中，所提出的框架显著优于当前已知的方法。

Conclusion: 利用完整的排名信息可以更有效地评估机器学习算法的相对性能，为算法选择提供更准确的预测。

Abstract: Consider a collection of m competing machine learning algorithms. Given their performance on a benchmark of datasets, we would like to identify the best performing algorithm. Specifically, which algorithm is most likely to ``win'' (rank highest) on a future, unseen dataset. The standard maximum likelihood approach suggests counting the number of wins per each algorithm. In this work, we argue that there is much more information in the complete rankings. That is, the number of times that each algorithm finished second, third and so forth. Yet, it is not entirely clear how to effectively utilize this information for our purpose. In this work we introduce a novel conceptual framework for estimating the win probability for each of the m algorithms, given their complete rankings over a benchmark of datasets. Our proposed framework significantly improves upon currently known methods in synthetic and real-world examples.

</details>


### [296] [Adversarial Instance Generation and Robust Training for Neural Combinatorial Optimization with Multiple Objectives](https://arxiv.org/abs/2601.01665)
*Wei Liu,Yaoxin Wu,Yingqian Zhang,Thomas Bäck,Yingjie Fan*

Main category: cs.LG

TL;DR: 本文提出了一个面向多目标组合优化问题的统一鲁棒性框架，包含偏好对抗攻击和防御策略，通过生成困难实例和对抗训练来提升神经求解器的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习在多目标组合优化问题中表现出色，但其鲁棒性在复杂问题分布下尚未充分探索，需要系统评估和改进神经求解器的稳健性。

Method: 开发了偏好对抗攻击方法生成困难实例暴露求解器弱点，并引入基于硬度感知偏好选择的防御策略，通过对抗训练减少对受限偏好区域的过拟合。

Result: 在MOTSP、MOCVRP和MOKP问题上的实验表明，攻击方法能成功为不同求解器生成困难实例，防御方法显著增强了神经求解器的鲁棒性和泛化性能。

Conclusion: 该框架有效提升了神经求解器在困难或分布外实例上的性能，为多目标组合优化问题的鲁棒求解提供了系统解决方案。

Abstract: Deep reinforcement learning (DRL) has shown great promise in addressing multi-objective combinatorial optimization problems (MOCOPs). Nevertheless, the robustness of these learning-based solvers has remained insufficiently explored, especially across diverse and complex problem distributions. In this paper, we propose a unified robustness-oriented framework for preference-conditioned DRL solvers for MOCOPs. Within this framework, we develop a preference-based adversarial attack to generate hard instances that expose solver weaknesses, and quantify the attack impact by the resulting degradation on Pareto-front quality. We further introduce a defense strategy that integrates hardness-aware preference selection into adversarial training to reduce overfitting to restricted preference regions and improve out-of-distribution performance. The experimental results on multi-objective traveling salesman problem (MOTSP), multi-objective capacitated vehicle routing problem (MOCVRP), and multi-objective knapsack problem (MOKP) verify that our attack method successfully learns hard instances for different solvers. Furthermore, our defense method significantly strengthens the robustness and generalizability of neural solvers, delivering superior performance on hard or out-of-distribution instances.

</details>


### [297] [HeurekaBench: A Benchmarking Framework for AI Co-scientist](https://arxiv.org/abs/2601.01678)
*Siba Smarak Panigrahi,Jovana Videnović,Maria Brbić*

Main category: cs.LG

TL;DR: HeurekaBench是一个用于评估科学代理系统的基准框架，通过半自动化流程创建基于真实科学研究的开放式研究问题，并在单细胞生物学领域进行了实例化验证。


<details>
  <summary>Details</summary>
Motivation: 当前LLM驱动的科学代理系统缺乏真实、端到端的研究场景评估方法，需要能够整合数据分析、解释和实验数据新见解生成的基准测试。

Method: 采用半自动化流程，利用多个LLM从科学研究和代码库中提取见解并生成候选工作流，然后与报告结果进行验证，创建开放式研究问题的基准。

Result: 在单细胞生物学领域的应用表明，添加批评模块可以将开源LLM代理的错误响应改善高达22%，缩小与闭源模型的差距。

Conclusion: HeurekaBench为科学代理的严格端到端评估设定了路径，将基准构建建立在真实科学工作流程的基础上。

Abstract: LLM-based reasoning models have enabled the development of agentic systems that act as co-scientists, assisting in multi-step scientific analysis. However, evaluating these systems is challenging, as it requires realistic, end-to-end research scenarios that integrate data analysis, interpretation, and the generation of new insights from the experimental data. To address this limitation, we introduce HeurekaBench, a framework to create benchmarks with exploratory, open-ended research questions for experimental datasets. Each such question is grounded in a scientific study and its corresponding code repository, and is created using a semi-automated pipeline that leverages multiple LLMs to extract insights and generate candidate workflows, which are then verified against reported findings. We instantiate the framework in single-cell biology to obtain sc-HeurekaBench benchmark and use it to compare state-of-the-art single-cell agents. We further showcase the benefits of our benchmark for quantitatively analyzing current design choices in agentic systems. We find that the addition of a critic module can improve ill-formed responses for open-source LLM-based agents by up to 22% and close the gap with their closed-source counterparts. Overall, HeurekaBench sets a path toward rigorous, end-to-end evaluation of scientific agents, grounding benchmark construction in real scientific workflows.

</details>


### [298] [DiMEx: Breaking the Cold Start Barrier in Data-Free Model Extraction via Latent Diffusion Priors](https://arxiv.org/abs/2601.01688)
*Yash Thesia,Meera Suthar*

Main category: cs.LG

TL;DR: DiMEx框架利用预训练潜在扩散模型的语义先验，通过随机嵌入贝叶斯优化在潜在空间中合成高保真查询，解决了数据自由模型窃取中的冷启动问题，显著提高了攻击效率。同时提出了混合状态集成防御方法，通过识别潜在空间攻击的优化轨迹来有效防御此类攻击。


<details>
  <summary>Details</summary>
Motivation: 模型窃取攻击对机器学习即服务构成重大威胁，而数据自由模型窃取虽然具有隐蔽性，但受限于GAN从随机噪声到有意义数据的冷启动问题，需要大量查询才能收敛。

Method: 提出DiMEx框架，利用预训练潜在扩散模型的丰富语义先验，在生成器的潜在空间中使用随机嵌入贝叶斯优化，立即合成高保真查询，绕过冷启动初始化障碍。

Result: DiMEx在SVHN数据集上仅用2000次查询就达到52.1%的协议率，比最先进的GAN基线高出16%以上。同时提出的HSE防御通过识别潜在空间攻击的优化轨迹，将攻击成功率抑制到21.6%。

Conclusion: DiMEx有效解决了数据自由模型窃取的冷启动问题，而HSE防御能够有效识别和防御这种基于语义先验的攻击方法，为MLaaS安全提供了新的防护思路。

Abstract: Model stealing attacks pose an existential threat to Machine Learning as a Service (MLaaS), allowing adversaries to replicate proprietary models for a fraction of their training cost. While Data-Free Model Extraction (DFME) has emerged as a stealthy vector, it remains fundamentally constrained by the "Cold Start" problem: GAN-based adversaries waste thousands of queries converging from random noise to meaningful data. We propose DiMEx, a framework that weaponizes the rich semantic priors of pre-trained Latent Diffusion Models to bypass this initialization barrier entirely. By employing Random Embedding Bayesian Optimization (REMBO) within the generator's latent space, DiMEx synthesizes high-fidelity queries immediately, achieving 52.1 percent agreement on SVHN with just 2,000 queries - outperforming state-of-the-art GAN baselines by over 16 percent. To counter this highly semantic threat, we introduce the Hybrid Stateful Ensemble (HSE) defense, which identifies the unique "optimization trajectory" of latent-space attacks. Our results demonstrate that while DiMEx evades static distribution detectors, HSE exploits this temporal signature to suppress attack success rates to 21.6 percent with negligible latency.

</details>


### [299] [Enhanced Multi-model Online Conformal Prediction](https://arxiv.org/abs/2601.01692)
*Erfan Hajihashemi,Yanning Shen*

Main category: cs.LG

TL;DR: 本文提出了一种新颖的多模型在线共形预测算法，通过构建二分图选择有效模型子集，在保证预测集覆盖率的同𠄘时显著提升计算效率和预测集大小。


<details>
  <summary>Details</summary>
Motivation: 传统共形预测依赖单一固定模型，在在线环境中性能不稳定。现有方法从候选模型集中选择模型，但计算成本随模型数量增加而上升，且性能较差的模型会影响整体效果。

Method: 在每个时间步生成二分图来识别有效模型子集，从中选择模型构建预测集，降低计算复杂度并提高预测效率。

Result: 实验表明，该方法在预测集大小和计算效率方面均优于现有的多模型共形预测技术。

Conclusion: 该算法有效解决了多模型共形预测中的计算效率问题，同时提升了预测性能。

Abstract: Conformal prediction is a framework for uncertainty quantification that constructs prediction sets for previously unseen data, guaranteeing coverage of the true label with a specified probability. However, the efficiency of these prediction sets, measured by their size, depends on the choice of the underlying learning model. Relying on a single fixed model may lead to suboptimal performance in online environments, as a single model may not consistently perform well across all time steps. To mitigate this, prior work has explored selecting a model from a set of candidates. However, this approach becomes computationally expensive as the number of candidate models increases. Moreover, poorly performing models in the set may also hinder the effectiveness. To tackle this challenge, this work develops a novel multi-model online conformal prediction algorithm that reduces computational complexity and improves prediction efficiency. At each time step, a bipartite graph is generated to identify a subset of effective models, from which a model is selected to construct the prediction set. Experiments demonstrate that our method outperforms existing multi-model conformal prediction techniques in terms of both prediction set size and computational efficiency.

</details>


### [300] [Digital Twin-Driven Communication-Efficient Federated Anomaly Detection for Industrial IoT](https://arxiv.org/abs/2601.01701)
*Mohammed Ayalew Belay,Adil Rasheed,Pierluigi Salvo Rossi*

Main category: cs.LG

TL;DR: 本文提出了一套数字孪生集成联邦学习方法(DTFL)，通过五种新颖方法解决了工业异常检测中的隐私保护、通信效率和模型性能问题，在80%目标精度下CWA方法仅需33轮训练，显著提升了通信效率。


<details>
  <summary>Details</summary>
Motivation: 工业异常检测面临对真实传感器数据的依赖、标记数据有限、高误报率和隐私问题等挑战，需要一种既能保护数据隐私又能提高模型性能的解决方案。

Method: 提出了五种数字孪生集成联邦学习方法：DTML（数字孪生元学习）、FPF（联邦参数融合）、LPE（分层参数交换）、CWA（循环权重自适应）和DTKD（数字孪生知识蒸馏），通过结合合成和真实世界知识来平衡泛化能力和通信开销。

Result: 在公开的工业物联网异常检测数据集上实验显示，CWA方法在33轮内达到80%目标精度，FPF需41轮，LPE需48轮，DTML需87轮，而标准FedAvg基线和DTKD在100轮内未达到目标。CWA比DTML减少62%通信轮次，比LPE减少31%。

Conclusion: 将数字孪生知识集成到联邦学习中能够显著加速收敛到操作上有意义的精度阈值，为工业物联网异常检测提供了通信效率高且隐私保护良好的解决方案。

Abstract: Anomaly detection is increasingly becoming crucial for maintaining the safety, reliability, and efficiency of industrial systems. Recently, with the advent of digital twins and data-driven decision-making, several statistical and machine-learning methods have been proposed. However, these methods face several challenges, such as dependence on only real sensor datasets, limited labeled data, high false alarm rates, and privacy concerns. To address these problems, we propose a suite of digital twin-integrated federated learning (DTFL) methods that enhance global model performance while preserving data privacy and communication efficiency. Specifically, we present five novel approaches: Digital Twin-Based Meta-Learning (DTML), Federated Parameter Fusion (FPF), Layer-wise Parameter Exchange (LPE), Cyclic Weight Adaptation (CWA), and Digital Twin Knowledge Distillation (DTKD). Each method introduces a unique mechanism to combine synthetic and real-world knowledge, balancing generalization with communication overhead. We conduct an extensive experiment using a publicly available cyber-physical anomaly detection dataset. For a target accuracy of 80%, CWA reaches the target in 33 rounds, FPF in 41 rounds, LPE in 48 rounds, and DTML in 87 rounds, whereas the standard FedAvg baseline and DTKD do not reach the target within 100 rounds. These results highlight substantial communication-efficiency gains (up to 62% fewer rounds than DTML and 31% fewer than LPE) and demonstrate that integrating DT knowledge into FL accelerates convergence to operationally meaningful accuracy thresholds for IIoT anomaly detection.

</details>


### [301] [Entropy-Aligned Decoding of LMs for Better Writing and Reasoning](https://arxiv.org/abs/2601.01714)
*Kareem Ahmed,Sameer Singh*

Main category: cs.LG

TL;DR: EPIC是一种无需超参数的解码方法，通过将未来轨迹的熵纳入语言模型解码，在每一步生成时显式调节不确定性，使采样分布的熵与数据不确定性对齐。


<details>
  <summary>Details</summary>
Motivation: 传统语言模型随机采样生成质量低，现有解码算法依赖贪婪启发式方法，导致生成文本同质化、重复且不连贯。需要一种能更好对齐数据不确定性的解码策略。

Method: EPIC采用熵感知的惰性Gumbel-Max采样方法，在每一步生成时评估未来轨迹的熵，使采样分布与数据分布的熵对齐，同时保持高效性，每步仅需亚线性次数的熵评估。

Result: 在创意写作和摘要任务中，EPIC相比广泛使用的解码策略显著提高了LM-as-judge偏好胜率；自动指标显示EPIC生成更多样化的文本和更忠实的摘要；在数学推理任务中，EPIC优于所有基线方法。

Conclusion: EPIC通过显式调节生成过程中的不确定性，有效解决了传统解码方法的问题，在多个任务上表现出色，为语言模型解码提供了新的有效方法。

Abstract: Language models (LMs) are trained on billions of tokens in an attempt to recover the true language distribution. Still, vanilla random sampling from LMs yields low quality generations. Decoding algorithms attempt to restrict the LM distribution to a set of high-probability continuations, but rely on greedy heuristics that introduce myopic distortions, yielding sentences that are homogeneous, repetitive and incoherent. In this paper, we introduce EPIC, a hyperparameter-free decoding approach that incorporates the entropy of future trajectories into LM decoding. EPIC explicitly regulates the amount of uncertainty expressed at every step of generation, aligning the sampling distribution's entropy to the aleatoric (data) uncertainty. Through Entropy-Aware Lazy Gumbel-Max sampling, EPIC manages to be exact, while also being efficient, requiring only a sublinear number of entropy evaluations per step. Unlike current baselines, EPIC yields sampling distributions that are empirically well-aligned with the entropy of the underlying data distribution. Across creative writing and summarization tasks, EPIC consistently improves LM-as-judge preference win-rates over widely used decoding strategies. These preference gains are complemented by automatic metrics, showing that EPIC produces more diverse generations and more faithful summaries. We also evaluate EPIC on mathematical reasoning, where it outperforms all baselines.

</details>


### [302] [Context-Free Recognition with Transformers](https://arxiv.org/abs/2601.01754)
*Selim Jerad,Anej Svete,Sophie Hao,Ryan Cotterell,William Merrill*

Main category: cs.LG

TL;DR: 本文证明了循环Transformer在O(log n)循环层和O(n^6)填充标记下可以识别所有上下文无关语言，但对于自然子类如无歧义CFL，仅需O(n^3)填充即可实现高效识别。


<details>
  <summary>Details</summary>
Motivation: 标准Transformer在语法处理能力上存在局限，无法识别上下文无关语言（CFL）甚至正则语言。虽然已有研究表明循环层可以帮助识别正则语言，但CFL的识别问题仍未解决。

Method: 使用循环Transformer架构，通过添加O(log n)循环层和不同数量的填充标记来研究CFL识别能力。特别关注无歧义CFL子类的识别效率。

Result: 理论证明：通用CFL识别需要O(n^6)填充标记（可能不实用），但无歧义CFL仅需O(n^3)填充。实验验证了循环机制在需要对数深度的语言上的有效性。

Conclusion: 虽然通用CFL识别可能需要大量填充，但自然约束（如无歧义性）可以显著提高Transformer的语法识别效率，为实际应用提供了可行路径。

Abstract: Transformers excel on tasks that process well-formed inputs according to some grammar, such as natural language and code. However, it remains unclear how they can process grammatical syntax. In fact, under standard complexity conjectures, standard transformers cannot recognize context-free languages (CFLs), a canonical formalism to describe syntax, or even regular languages, a subclass of CFLs (Merrill et al., 2022). Merrill & Sabharwal (2024) show that $\mathcal{O}(\log n)$ looping layers (w.r.t. input length $n$) allows transformers to recognize regular languages, but the question of context-free recognition remained open. In this work, we show that looped transformers with $\mathcal{O}(\log n)$ looping layers and $\mathcal{O}(n^6)$ padding tokens can recognize all CFLs. However, training and inference with $\mathcal{O}(n^6)$ padding tokens is potentially impractical. Fortunately, we show that, for natural subclasses such as unambiguous CFLs, the recognition problem on transformers becomes more tractable, requiring $\mathcal{O}(n^3)$ padding. We empirically validate our results and show that looping helps on a language that provably requires logarithmic depth. Overall, our results shed light on the intricacy of CFL recognition by transformers: While general recognition may require an intractable amount of padding, natural constraints such as unambiguity yield efficient recognition algorithms.

</details>


### [303] [UnPII: Unlearning Personally Identifiable Information with Quantifiable Exposure Risk](https://arxiv.org/abs/2601.01786)
*Intae Jeon,Yujeong Kwon,Hyungjoon Koo*

Main category: cs.LG

TL;DR: UnPII是一种针对PII（个人可识别信息）的机器学习遗忘方法，通过PII风险指数（PRI）对不同类型的PII属性进行差异化遗忘，在保持模型性能的同时提高隐私保护效果。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在金融、医疗等关键领域的广泛应用，处理PII数据时的隐私保护需求日益迫切。现有遗忘技术采用统一策略，无法区分不同PII属性的隐私风险差异，需要更细粒度的解决方案。

Method: 提出PII风险指数（PRI）综合评估PII的七个风险维度，并构建合成PII数据集模拟真实场景。UnPII方法可与现有遗忘算法（如梯度上升、负偏好优化等）无缝集成。

Result: 实验表明UnPII在准确率上提升达11.8%，实用性提升6.3%，泛化能力提升12.4%，同时遗忘过程中的微调开销平均仅为27.5%。

Conclusion: UnPII为PII数据提供了有效的差异化遗忘方案，能够根据具体风险水平调整遗忘策略，在隐私保护和模型性能之间取得良好平衡。

Abstract: The ever-increasing adoption of Large Language Models in critical sectors like finance, healthcare, and government raises privacy concerns regarding the handling of sensitive Personally Identifiable Information (PII) during training. In response, regulations such as European Union's General Data Protection Regulation (GDPR) mandate the deletion of PII upon requests, underscoring the need for reliable and cost-effective data removal solutions. Machine unlearning has emerged as a promising direction for selectively forgetting data points. However, existing unlearning techniques typically apply a uniform forgetting strategy that neither accounts for the varying privacy risks posed by different PII attributes nor reflects associated business risks. In this work, we propose UnPII, the first PII-centric unlearning approach that prioritizes forgetting based on the risk of individual or combined PII attributes. To this end, we introduce the PII risk index (PRI), a composite metric that incorporates multiple dimensions of risk factors: identifiability, sensitivity, usability, linkability, permanency, exposability, and compliancy. The PRI enables a nuanced evaluation of privacy risks associated with PII exposures and can be tailored to align with organizational privacy policies. To support realistic assessment, we systematically construct a synthetic PII dataset (e.g., 1,700 PII instances) that simulates realistic exposure scenarios. UnPII seamlessly integrates with established unlearning algorithms, such as Gradient Ascent, Negative Preference Optimization, and Direct Preference Optimization, without modifying their underlying principles. Our experimental results demonstrate that UnPII achieves the improvements of accuracy up to 11.8%, utility up to 6.3%, and generalizability up to 12.4%, respectively, while incurring a modest fine-tuning overhead of 27.5% on average during unlearning.

</details>


### [304] [HyperCLOVA X 8B Omni](https://arxiv.org/abs/2601.01792)
*NAVER Cloud HyperCLOVA X Team*

Main category: cs.LG

TL;DR: HyperCLOVA X 8B Omni是首个支持文本、音频和视觉任意输入输出的全模态模型，通过统一的多模态序列预测实现多模态理解和生成。


<details>
  <summary>Details</summary>
Motivation: 旨在解决传统多模态模型需要独立模态特定管道的问题，通过单一模型实现任意模态间的理解和生成，推动实用全模态助手的发展。

Method: 采用共享的下一个标记预测接口统一多模态序列，结合视觉和音频编码器注入连续嵌入以实现细粒度理解和接地。

Result: 实证评估显示在韩语和英语的多种输入输出组合中，与同等规模模型相比具有竞争力。

Conclusion: HyperCLOVA X 8B Omni的开源发布将支持广泛的研究和部署场景，是通向实用全模态助手的重要里程碑。

Abstract: In this report, we present HyperCLOVA X 8B Omni, the first any-to-any omnimodal model in the HyperCLOVA X family that supports text, audio, and vision as both inputs and outputs. By consolidating multimodal understanding and generation into a single model rather than separate modality-specific pipelines, HyperCLOVA X 8B Omni serves as an 8B-scale omni-pathfinding point toward practical any-to-any omni assistants. At a high level, the model unifies modalities through a shared next-token prediction interface over an interleaved multimodal sequence, while vision and audio encoders inject continuous embeddings for fine-grained understanding and grounding. Empirical evaluations demonstrate competitive performance against comparably sized models across diverse input-output combinations spanning text, audio, and vision, in both Korean and English. We anticipate that the open-weight release of HyperCLOVA X 8B Omni will support a wide range of research and deployment scenarios.

</details>


### [305] [Distributed Federated Learning by Alternating Periods of Training](https://arxiv.org/abs/2601.01793)
*Shamik Bhattacharyya,Rachel Kalpana Kalaimani*

Main category: cs.LG

TL;DR: 本文提出了一种分布式联邦学习(DFL)方法，通过多服务器架构解决传统联邦学习中单点故障和可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习依赖单一中央服务器，在大规模客户端场景下存在可扩展性差和单点故障风险。

Method: 设计多服务器分布式框架，采用客户端本地训练与服务器间全局训练交替进行的DFL算法。

Result: 理论证明和数值模拟显示，在适当参数选择下，所有服务器能收敛到理想模型的较小容差范围内。

Conclusion: DFL框架有效整合了本地和全局训练模型，提高了联邦学习的可扩展性和容错能力。

Abstract: Federated learning is a privacy-focused approach towards machine learning where models are trained on client devices with locally available data and aggregated at a central server. However, the dependence on a single central server is challenging in the case of a large number of clients and even poses the risk of a single point of failure. To address these critical limitations of scalability and fault-tolerance, we present a distributed approach to federated learning comprising multiple servers with inter-server communication capabilities. While providing a fully decentralized approach, the designed framework retains the core federated learning structure where each server is associated with a disjoint set of clients with server-client communication capabilities. We propose a novel DFL (Distributed Federated Learning) algorithm which uses alternating periods of local training on the client data followed by global training among servers. We show that the DFL algorithm, under a suitable choice of parameters, ensures that all the servers converge to a common model value within a small tolerance of the ideal model, thus exhibiting effective integration of local and global training models. Finally, we illustrate our theoretical claims through numerical simulations.

</details>


### [306] [Sparse Threats, Focused Defense: Criticality-Aware Robust Reinforcement Learning for Safe Autonomous Driving](https://arxiv.org/abs/2601.01800)
*Qi Wei,Junchao Fan,Zhao Yang,Jianhua Wang,Jingkai Mao,Xiaolin Chang*

Main category: cs.LG

TL;DR: CARRL是一种针对自动驾驶安全关键风险的强化学习对抗训练方法，通过风险暴露对手和风险目标鲁棒代理的博弈交互，显著降低碰撞率。


<details>
  <summary>Details</summary>
Motivation: 现有对抗训练方法忽略了代理与对手之间的不对称性，未能反映安全关键风险的稀疏性，导致在实际自动驾驶场景中鲁棒性不足。

Method: 提出CARRL方法，包含风险暴露对手(REA)和风险目标鲁棒代理(RTRA)。REA通过解耦优化机制识别稀疏安全关键时刻，RTRA使用双回放缓冲器联合利用正常和对抗经验。

Result: 实验结果表明，与最先进的基线方法相比，该方法在所有情况下至少降低22.66%的碰撞率。

Conclusion: CARRL通过建模非零和博弈和针对性攻击策略，有效提升了自动驾驶系统在安全关键场景下的鲁棒性。

Abstract: Reinforcement learning (RL) has shown considerable potential in autonomous driving (AD), yet its vulnerability to perturbations remains a critical barrier to real-world deployment. As a primary countermeasure, adversarial training improves policy robustness by training the AD agent in the presence of an adversary that deliberately introduces perturbations. Existing approaches typically model the interaction as a zero-sum game with continuous attacks. However, such designs overlook the inherent asymmetry between the agent and the adversary and then fail to reflect the sparsity of safety-critical risks, rendering the achieved robustness inadequate for practical AD scenarios. To address these limitations, we introduce criticality-aware robust RL (CARRL), a novel adversarial training approach for handling sparse, safety-critical risks in autonomous driving. CARRL consists of two interacting components: a risk exposure adversary (REA) and a risk-targeted robust agent (RTRA). We model the interaction between the REA and RTRA as a general-sum game, allowing the REA to focus on exposing safety-critical failures (e.g., collisions) while the RTRA learns to balance safety with driving efficiency. The REA employs a decoupled optimization mechanism to better identify and exploit sparse safety-critical moments under a constrained budget. However, such focused attacks inevitably result in a scarcity of adversarial data. The RTRA copes with this scarcity by jointly leveraging benign and adversarial experiences via a dual replay buffer and enforces policy consistency under perturbations to stabilize behavior. Experimental results demonstrate that our approach reduces the collision rate by at least 22.66\% across all cases compared to state-of-the-art baseline methods.

</details>


### [307] [Moments Matter:Stabilizing Policy Optimization using Return Distributions](https://arxiv.org/abs/2601.01803)
*Dennis Jabs,Aditya Mohan,Marius Lindauer*

Main category: cs.LG

TL;DR: 本文提出了一种基于分布评论家和高阶矩（偏度和峰度）的PPO改进方法，通过惩罚极端尾部行为来减少策略更新引起的不稳定性，在Walker2D环境中提升稳定性达75%。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习代理在学习相同回报的策略时可能表现出不同的行为，这种不稳定性源于环境和算法因素。连续控制任务中，即使小的参数变化也可能导致不稳定的步态，影响算法比较和实际应用。

Method: 通过分布评论家建模状态-动作回报分布，并利用该分布的高阶矩（偏度和峰度）来偏置PPO的优势函数，从而惩罚极端尾部行为，避免策略进入不稳定的参数区域。

Result: 在Walker2D环境中，该方法将策略稳定性提高了75%，同时保持了可比较的评估回报。

Conclusion: 通过利用环境随机性和分布评论家的高阶矩信息，可以有效减少策略更新的不稳定性，为连续控制任务提供更可靠的强化学习解决方案。

Abstract: Deep Reinforcement Learning (RL) agents often learn policies that achieve the same episodic return yet behave very differently, due to a combination of environmental (random transitions, initial conditions, reward noise) and algorithmic (minibatch selection, exploration noise) factors. In continuous control tasks, even small parameter shifts can produce unstable gaits, complicating both algorithm comparison and real-world transfer. Previous work has shown that such instability arises when policy updates traverse noisy neighborhoods and that the spread of post-update return distribution $R(θ)$, obtained by repeatedly sampling minibatches, updating $θ$, and measuring final returns, is a useful indicator of this noise. Although explicitly constraining the policy to maintain a narrow $R(θ)$ can improve stability, directly estimating $R(θ)$ is computationally expensive in high-dimensional settings. We propose an alternative that takes advantage of environmental stochasticity to mitigate update-induced variability. Specifically, we model state-action return distribution through a distributional critic and then bias the advantage function of PPO using higher-order moments (skewness and kurtosis) of this distribution. By penalizing extreme tail behaviors, our method discourages policies from entering parameter regimes prone to instability. We hypothesize that in environments where post-update critic values align poorly with post-update returns, standard PPO struggles to produce a narrow $R(θ)$. In such cases, our moment-based correction narrows $R(θ)$, improving stability by up to 75% in Walker2D, while preserving comparable evaluation returns.

</details>


### [308] [RealPDEBench: A Benchmark for Complex Physical Systems with Real-World Data](https://arxiv.org/abs/2601.01829)
*Peiyan Hu,Haodong Feng,Hongyuan Liu,Tongtong Yan,Wenhao Deng,Tianrun Gao,Rong Zheng,Haoren Zheng,Chenglei Yu,Chuanrui Wang,Kaiwen Li,Zhi-Ming Ma,Dezhi Zhou,Xingcai Lu,Dixia Fan,Tailin Wu*

Main category: cs.LG

TL;DR: RealPDEBench是首个将真实世界测量数据与配对数值模拟相结合的科学机器学习基准，包含5个数据集、3个任务、8个指标和10个基线方法，旨在解决科学ML中真实数据缺乏的问题。


<details>
  <summary>Details</summary>
Motivation: 当前科学机器学习模型主要依赖模拟数据进行训练和验证，缺乏真实世界数据限制了模型发展和评估，也阻碍了模拟到真实迁移等关键任务的研究。

Method: 构建包含5个真实世界测量数据集及其配对模拟数据集的基准平台，定义3个比较任务，设计8个评估指标（数据导向和物理导向），并对10个代表性基线方法进行基准测试。

Result: 实验显示模拟数据与真实世界数据存在显著差异，但使用模拟数据进行预训练能持续提高准确性和收敛性。

Conclusion: 该工作通过真实世界数据提供见解，推动科学机器学习弥合模拟-真实差距，促进实际部署。

Abstract: Predicting the evolution of complex physical systems remains a central problem in science and engineering. Despite rapid progress in scientific Machine Learning (ML) models, a critical bottleneck is the lack of expensive real-world data, resulting in most current models being trained and validated on simulated data. Beyond limiting the development and evaluation of scientific ML, this gap also hinders research into essential tasks such as sim-to-real transfer. We introduce RealPDEBench, the first benchmark for scientific ML that integrates real-world measurements with paired numerical simulations. RealPDEBench consists of five datasets, three tasks, eight metrics, and ten baselines. We first present five real-world measured datasets with paired simulated datasets across different complex physical systems. We further define three tasks, which allow comparisons between real-world and simulated data, and facilitate the development of methods to bridge the two. Moreover, we design eight evaluation metrics, spanning data-oriented and physics-oriented metrics, and finally benchmark ten representative baselines, including state-of-the-art models, pretrained PDE foundation models, and a traditional method. Experiments reveal significant discrepancies between simulated and real-world data, while showing that pretraining with simulated data consistently improves both accuracy and convergence. In this work, we hope to provide insights from real-world data, advancing scientific ML toward bridging the sim-to-real gap and real-world deployment. Our benchmark, datasets, and instructions are available at https://realpdebench.github.io/.

</details>


### [309] [FAROS: Robust Federated Learning with Adaptive Scaling against Backdoor Attacks](https://arxiv.org/abs/2601.01833)
*Chenyu Hu,Qiming Hu,Sinan Chen,Nianyu Li,Mingyue Zhang,Jialong Li*

Main category: cs.LG

TL;DR: FAROS是一个增强的联邦学习框架，通过自适应差分缩放和鲁棒核心集计算来防御后门攻击，在攻击成功率和主任务准确率方面优于现有防御方法。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习后门攻击防御方法依赖固定的防御参数，存在单点故障风险，无法有效应对复杂的攻击者策略。

Method: 提出FAROS框架，包含自适应差分缩放(ADS)机制和鲁棒核心集计算(RCC)。ADS根据客户端上传梯度的分散度动态调整防御敏感性；RCC通过计算高置信度客户端核心集的质心来降低单点故障风险。

Result: 在多个数据集、模型和攻击场景下的广泛实验表明，该方法在攻击成功率和主任务准确率方面均优于当前最先进的防御方法。

Conclusion: FAROS框架通过动态自适应防御机制有效解决了现有防御方法的局限性，显著提升了联邦学习系统对抗后门攻击的鲁棒性。

Abstract: Federated Learning (FL) enables multiple clients to collaboratively train a shared model without exposing local data. However, backdoor attacks pose a significant threat to FL. These attacks aim to implant a stealthy trigger into the global model, causing it to mislead on inputs that possess a specific trigger while functioning normally on benign data. Although pre-aggregation detection is a main defense direction, existing state-of-the-art defenses often rely on fixed defense parameters. This reliance makes them vulnerable to single-point-of-failure risks, rendering them less effective against sophisticated attackers. To address these limitations, we propose FAROS, an enhanced FL framework that incorporates Adaptive Differential Scaling (ADS) and Robust Core-set Computing (RCC). The ADS mechanism adjusts the defense's sensitivity dynamically, based on the dispersion of uploaded gradients by clients in each round. This allows it to counter attackers who strategically shift between stealthiness and effectiveness. Furthermore, the RCC effectively mitigates the risk of single-point failure by computing the centroid of a core set comprising clients with the highest confidence. We conducted extensive experiments across various datasets, models, and attack scenarios. The results demonstrate that our method outperforms current defenses in both attack success rate and main task accuracy.

</details>


### [310] [Tackling Resource-Constrained and Data-Heterogeneity in Federated Learning with Double-Weight Sparse Pack](https://arxiv.org/abs/2601.01840)
*Qiantao Yang,Liquan Chen,Mingfu Xue,Songze Li*

Main category: cs.LG

TL;DR: FedCSPACK是一种基于余弦稀疏参数打包和双重加权聚合的个性化联邦学习方法，旨在解决数据异构性和客户端资源受限问题，通过参数打包和加权聚合提高通信和计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习方法在处理数据异构性时忽视了客户端通信带宽和计算能力的限制，无法在解决数据异构性和适应有限客户端资源之间取得有效平衡。

Method: 提出FedCSPACK方法：客户端基于余弦相似度打包模型参数并选择最有贡献的参数包共享；生成掩码矩阵提高稀疏更新效率；嵌入方向和分布距离权重实现加权引导聚合机制。

Result: 在四个数据集上的实验表明，FedCSPACK在保持高模型精度的同时，有效提高了通信和计算效率。

Conclusion: FedCSPACK通过参数打包和加权聚合机制，成功解决了联邦学习中的数据异构性和资源受限问题，具有较好的实用价值。

Abstract: Federated learning has drawn widespread interest from researchers, yet the data heterogeneity across edge clients remains a key challenge, often degrading model performance. Existing methods enhance model compatibility with data heterogeneity by splitting models and knowledge distillation. However, they neglect the insufficient communication bandwidth and computing power on the client, failing to strike an effective balance between addressing data heterogeneity and accommodating limited client resources. To tackle this limitation, we propose a personalized federated learning method based on cosine sparsification parameter packing and dual-weighted aggregation (FedCSPACK), which effectively leverages the limited client resources and reduces the impact of data heterogeneity on model performance. In FedCSPACK, the client packages model parameters and selects the most contributing parameter packages for sharing based on cosine similarity, effectively reducing bandwidth requirements. The client then generates a mask matrix anchored to the shared parameter package to improve the alignment and aggregation efficiency of sparse updates on the server. Furthermore, directional and distribution distance weights are embedded in the mask to implement a weighted-guided aggregation mechanism, enhancing the robustness and generalization performance of the global model. Extensive experiments across four datasets using ten state-of-the-art methods demonstrate that FedCSPACK effectively improves communication and computational efficiency while maintaining high model accuracy.

</details>


### [311] [High-Order Epistasis Detection Using Factorization Machine with Quadratic Optimization Annealing and MDR-Based Evaluation](https://arxiv.org/abs/2601.01860)
*Shuta Kikuchi,Shu Tanaka*

Main category: cs.LG

TL;DR: 提出基于因子分解机和二次优化退火的FMQA方法，用于高效检测高阶上位性（基因互作），解决传统MDR方法计算复杂度高的问题。


<details>
  <summary>Details</summary>
Motivation: 高阶上位性检测在遗传关联研究中面临组合爆炸的计算挑战，传统MDR方法在基因位点数量或互作阶数增加时计算不可行。

Method: 将上位性检测定义为黑盒优化问题，使用MDR计算的分类错误率作为目标函数，采用因子分解机结合二次优化退火（FMQA）进行高效搜索。

Result: 在模拟病例对照数据集上的实验表明，该方法能在有限迭代次数内成功识别预设的高阶上位性，适用于不同互作阶数和基因位点数量。

Conclusion: 该方法在检测高阶上位性方面具有有效性和计算效率，为遗传关联研究提供了可行的解决方案。

Abstract: Detecting high-order epistasis is a fundamental challenge in genetic association studies due to the combinatorial explosion of candidate locus combinations. Although multifactor dimensionality reduction (MDR) is a widely used method for evaluating epistasis, exhaustive MDR-based searches become computationally infeasible as the number of loci or the interaction order increases. In this paper, we define the epistasis detection problem as a black-box optimization problem and solve it with a factorization machine with quadratic optimization annealing (FMQA). We propose an efficient epistasis detection method based on FMQA, in which the classification error rate (CER) computed by MDR is used as a black-box objective function. Experimental evaluations were conducted using simulated case-control datasets with predefined high-order epistasis. The results demonstrate that the proposed method successfully identified ground-truth epistasis across various interaction orders and the numbers of genetic loci within a limited number of iterations. These results indicate that the proposed method is effective and computationally efficient for high-order epistasis detection.

</details>


### [312] [Safety at One Shot: Patching Fine-Tuned LLMs with A Single Instance](https://arxiv.org/abs/2601.01887)
*Jiawen Zhang,Lipeng He,Kejia Chen,Jian Lou,Jian Liu,Xiaohu Yang,Ruoxi Jia*

Main category: cs.LG

TL;DR: 本文提出了一种仅需单个安全样本即可完全恢复安全对齐大语言模型的方法，无需牺牲模型效用且成本极低，揭示了安全梯度的低秩结构特性。


<details>
  <summary>Details</summary>
Motivation: 现有安全对齐方法需要大量安全样本或校准集，导致计算开销大且模型效用下降。本文旨在探索更高效的安全对齐恢复方法。

Method: 通过分析发现安全梯度具有低秩结构特性，仅需单个安全示例就能有效纠正模型的安全对齐问题，且收敛速度快。

Result: 该方法在5个安全对齐LLM和多个数据集上验证有效，无论有害样本数量或模型规模如何，都能在几个周期内实现安全对齐恢复。

Conclusion: 安全对齐可以通过极简的方式高效恢复，这为LLM安全研究提供了新的思路和实用方法。

Abstract: Fine-tuning safety-aligned large language models (LLMs) can substantially compromise their safety. Previous approaches require many safety samples or calibration sets, which not only incur significant computational overhead during realignment but also lead to noticeable degradation in model utility. Contrary to this belief, we show that safety alignment can be fully recovered with only a single safety example, without sacrificing utility and at minimal cost. Remarkably, this recovery is effective regardless of the number of harmful examples used in fine-tuning or the size of the underlying model, and convergence is achieved within just a few epochs. Furthermore, we uncover the low-rank structure of the safety gradient, which explains why such efficient correction is possible. We validate our findings across five safety-aligned LLMs and multiple datasets, demonstrating the generality of our approach.

</details>


### [313] [FedBiCross: A Bi-Level Optimization Framework to Tackle Non-IID Challenges in Data-Free One-Shot Federated Learning on Medical Data](https://arxiv.org/abs/2601.01901)
*Yuexuan Xia,Yinghao Zhang,Yalin Liu,Hong-Ning Dai,Yong Xia*

Main category: cs.LG

TL;DR: FedBiCross是一种个性化单次联邦学习框架，通过客户端聚类、双层级跨簇优化和个性化蒸馏来解决非独立同分布数据下传统方法预测冲突导致监督信号弱的问题。


<details>
  <summary>Details</summary>
Motivation: 现有单次联邦学习方法在非独立同分布数据下，由于客户端预测冲突，平均聚合会产生接近均匀的软标签，导致蒸馏监督信号弱，影响模型性能。

Method: 提出三阶段方法：(1)基于模型输出相似性的客户端聚类形成一致性子集成；(2)双层级跨簇优化学习自适应权重，选择性利用有益跨簇知识并抑制负迁移；(3)个性化蒸馏实现客户端特定适应。

Result: 在四个医学图像数据集上的实验表明，FedBiCross在不同非独立同分布程度下均优于现有最优基线方法。

Conclusion: FedBiCross通过聚类和选择性知识迁移有效解决了非独立同分布数据下单次联邦学习的预测冲突问题，在医学图像任务中表现出色。

Abstract: Data-free knowledge distillation-based one-shot federated learning (OSFL) trains a model in a single communication round without sharing raw data, making OSFL attractive for privacy-sensitive medical applications. However, existing methods aggregate predictions from all clients to form a global teacher. Under non-IID data, conflicting predictions cancel out during averaging, yielding near-uniform soft labels that provide weak supervision for distillation. We propose FedBiCross, a personalized OSFL framework with three stages: (1) clustering clients by model output similarity to form coherent sub-ensembles, (2) bi-level cross-cluster optimization that learns adaptive weights to selectively leverage beneficial cross-cluster knowledge while suppressing negative transfer, and (3) personalized distillation for client-specific adaptation. Experiments on four medical image datasets demonstrate that FedBiCross consistently outperforms state-of-the-art baselines across different non-IID degrees.

</details>


### [314] [TT-FSI: Scalable Faithful Shapley Interactions via Tensor-Train](https://arxiv.org/abs/2601.01903)
*Ungsik Kim,Suwon Lee*

Main category: cs.LG

TL;DR: TT-FSI是一种基于矩阵乘积算子的高效算法，用于计算Faithful Shapley Interaction指数，相比现有方法实现了指数级的时间和内存优化。


<details>
  <summary>Details</summary>
Motivation: 现有的FSI计算方法需要O(d^ℓ·2^d)时间和O(4^d)内存，计算成本过高，限制了其在大型数据集上的应用。

Method: 利用FSI的代数结构，通过矩阵乘积算子表示线性算子v↦FSI(v)，开发了一种TT-rank为O(ℓd)的高效扫描算法。

Result: 在6个数据集上的实验显示，TT-FSI相比基线实现了280倍加速，相比SHAP-IQ实现85倍加速，内存使用减少290倍，能够扩展到d=20的情况。

Conclusion: TT-FSI通过MPO表示显著降低了FSI的计算复杂度，使得在大型特征集上计算Shapley交互指数变得可行。

Abstract: The Faithful Shapley Interaction (FSI) index uniquely satisfies the faithfulness axiom among Shapley interaction indices, but computing FSI requires $O(d^\ell \cdot 2^d)$ time and existing implementations use $O(4^d)$ memory. We present TT-FSI, which exploits FSI's algebraic structure via Matrix Product Operators (MPO). Our main theoretical contribution is proving that the linear operator $v \mapsto \text{FSI}(v)$ admits an MPO representation with TT-rank $O(\ell d)$, enabling an efficient sweep algorithm with $O(\ell^2 d^3 \cdot 2^d)$ time and $O(\ell d^2)$ core storage an exponential improvement over existing methods. Experiments on six datasets ($d=8$ to $d=20$) demonstrate up to 280$\times$ speedup over baseline, 85$\times$ over SHAP-IQ, and 290$\times$ memory reduction. TT-FSI scales to $d=20$ (1M coalitions) where all competing methods fail.

</details>


### [315] [Evaluating Feature Dependent Noise in Preference-based Reinforcement Learning](https://arxiv.org/abs/2601.01904)
*Yuxuan Li,Harshith Reddy Kethireddy,Srijita Das*

Main category: cs.LG

TL;DR: 该论文研究强化学习中的偏好学习（PbRL），重点关注特征依赖性噪声问题，发现现有噪声鲁棒方法在某些特征相关噪声场景下性能反而下降，而普通PbRL方法表现更好。


<details>
  <summary>Details</summary>
Motivation: 偏好学习在复杂任务中很有用，但偏好数据往往带有不确定性和噪声。现有研究大多处理均匀分布噪声，而现实中的噪声可能与观察特征相关。

Method: 提出特征依赖性噪声的概念和多种变体（轨迹特征噪声、轨迹相似性噪声、不确定性感知噪声、语言模型噪声），并在DMControl和Meta-world等复杂连续控制任务中进行评估。

Result: 实验表明，在某些特征依赖性噪声设置下，最先进的噪声鲁棒PbRL方法性能显著下降，而无显式去噪的PbRL方法在多数设置中反而表现更好。语言模型噪声表现出与特征依赖性噪声相似的特征。

Conclusion: 特征依赖性噪声模拟了真实人类的噪声模式，需要进一步研究如何鲁棒地学习具有特征依赖性噪声的偏好数据。

Abstract: Learning from Preferences in Reinforcement Learning (PbRL) has gained attention recently, as it serves as a natural fit for complicated tasks where the reward function is not easily available. However, preferences often come with uncertainty and noise if they are not from perfect teachers. Much prior literature aimed to detect noise, but with limited types of noise and most being uniformly distributed with no connection to observations. In this work, we formalize the notion of targeted feature-dependent noise and propose several variants like trajectory feature noise, trajectory similarity noise, uncertainty-aware noise, and Language Model noise.
  We evaluate feature-dependent noise, where noise is correlated with certain features in complex continuous control tasks from DMControl and Meta-world. Our experiments show that in some feature-dependent noise settings, the state-of-the-art noise-robust PbRL method's learning performance is significantly deteriorated, while PbRL method with no explicit denoising can surprisingly outperform noise-robust PbRL in majority settings.
  We also find language model's noise exhibits similar characteristics to feature-dependent noise, thereby simulating realistic humans and call for further study in learning with feature-dependent noise robustly.

</details>


### [316] [Distorted Distributional Policy Evaluation for Offline Reinforcement Learning](https://arxiv.org/abs/2601.01917)
*Ryo Iwaki,Takayuki Osogami*

Main category: cs.LG

TL;DR: 本文提出了一种新的量化扭曲概念，用于解决离线分布强化学习中均匀悲观估计的局限性，通过基于数据可用性的非均匀悲观主义来提高性能。


<details>
  <summary>Details</summary>
Motivation: 现有的离线分布强化学习方法存在均匀低估回报分位数的问题，导致过度保守的价值估计，限制了泛化能力和性能表现。

Method: 引入量化扭曲概念，通过基于支持数据可用性调整保守程度来实现非均匀悲观主义，该方法有理论分析支持。

Result: 实证验证表明，相比均匀悲观主义方法，所提出的量化扭曲方法能够显著提升性能表现。

Conclusion: 量化扭曲为离线分布强化学习提供了一种有效的非均匀悲观估计框架，解决了现有方法过度保守的问题。

Abstract: While Distributional Reinforcement Learning (DRL) methods have demonstrated strong performance in online settings, its success in offline scenarios remains limited. We hypothesize that a key limitation of existing offline DRL methods lies in their approach to uniformly underestimate return quantiles. This uniform pessimism can lead to overly conservative value estimates, ultimately hindering generalization and performance. To address this, we introduce a novel concept called quantile distortion, which enables non-uniform pessimism by adjusting the degree of conservatism based on the availability of supporting data. Our approach is grounded in theoretical analysis and empirically validated, demonstrating improved performance over uniform pessimism.

</details>


### [317] [Theoretical Convergence of SMOTE-Generated Samples](https://arxiv.org/abs/2601.01927)
*Firuz Kamalov,Hana Sulieman,Witold Pedrycz*

Main category: cs.LG

TL;DR: 本文对SMOTE方法的收敛性进行了严格的理论分析，证明了合成随机变量Z在概率上收敛于基础随机变量X，并在X为紧集时证明了更强的均值收敛，同时发现较低的最近邻秩能带来更快收敛。


<details>
  <summary>Details</summary>
Motivation: 不平衡数据广泛影响机器学习应用，SMOTE作为最流行的解决方法之一，需要从理论和实证两方面进行验证。

Method: 通过理论分析证明SMOTE的收敛性质，包括概率收敛和均值收敛，并使用真实和合成数据进行数值实验验证。

Result: 证明了合成变量Z在概率上收敛于X，当X为紧集时存在均值收敛，且较低的最近邻秩能加速收敛。

Conclusion: 该研究为数据增强技术提供了理论基础，其意义不仅限于不平衡数据场景。

Abstract: Imbalanced data affects a wide range of machine learning applications, from healthcare to network security. As SMOTE is one of the most popular approaches to addressing this issue, it is imperative to validate it not only empirically but also theoretically. In this paper, we provide a rigorous theoretical analysis of SMOTE's convergence properties. Concretely, we prove that the synthetic random variable Z converges in probability to the underlying random variable X. We further prove a stronger convergence in mean when X is compact. Finally, we show that lower values of the nearest neighbor rank lead to faster convergence offering actionable guidance to practitioners. The theoretical results are supported by numerical experiments using both real-life and synthetic data. Our work provides a foundational understanding that enhances data augmentation techniques beyond imbalanced data scenarios.

</details>


### [318] [DéjàQ: Open-Ended Evolution of Diverse, Learnable and Verifiable Problems](https://arxiv.org/abs/2601.01931)
*Willem Röpke,Samuel Coward,Andrei Lupu,Thomas Foster,Tim Rocktäschel,Jakob Foerster*

Main category: cs.LG

TL;DR: DéjàQ是一个通过联合演化合成数学问题与模型训练来提升数学推理能力的框架，采用LLM驱动的突变策略让模型自身修改训练数据，从而优化学习效果。


<details>
  <summary>Details</summary>
Motivation: 当前推理模型主要依赖静态数据集，可能导致记忆而非泛化，需要动态适应模型能力的数据生成方法。

Method: 提出DéjàQ框架，在训练过程中共同演化多样化的合成数学问题，使用两种LLM驱动的突变策略：改变上下文细节或直接修改问题结构。

Result: 模型能够生成新颖且有意义的数学问题，LLM驱动的突变策略改善了强化学习训练效果，生成的问題有效性得到验证。

Conclusion: 动态演化训练数据有潜力增强数学推理能力，该方法具有更广泛的适用性，代码将开源。

Abstract: Recent advances in reasoning models have yielded impressive results in mathematics and coding. However, most approaches rely on static datasets, which have been suggested to encourage memorisation and limit generalisation. We introduce DéjàQ, a framework that departs from this paradigm by jointly evolving a diverse set of synthetic mathematical problems alongside model training. This evolutionary process adapts to the model's ability throughout training, optimising problems for learnability. We propose two LLM-driven mutation strategies in which the model itself mutates the training data, either by altering contextual details or by directly modifying problem structure. We find that the model can generate novel and meaningful problems, and that these LLM-driven mutations improve RL training. We analyse key aspects of DéjàQ, including the validity of generated problems and computational overhead. Our results underscore the potential of dynamically evolving training data to enhance mathematical reasoning and indicate broader applicability, which we will support by open-sourcing our code.

</details>


### [319] [SynRXN: An Open Benchmark and Curated Dataset for Computational Reaction Modeling](https://arxiv.org/abs/2601.01943)
*Tieu-Long Phan,Nhu-Ngoc Nguyen Song,Peter F. Stadler*

Main category: cs.LG

TL;DR: SynRXN是一个统一的计算机辅助合成规划（CASP）基准测试框架和开放数据资源，将端到端合成规划分解为五个任务家族，并提供标准化的评估工作流程。


<details>
  <summary>Details</summary>
Motivation: 为了解决CASP领域数据集异质性问题，提供公平的纵向比较方法，支持完整的反应信息学流程的严格消融和压力测试。

Method: 从异构公共来源收集反应语料库，统一表示为版本化数据集，提供透明的数据分割函数，生成防泄漏的训练、验证和测试分区，并制定标准化的评估工作流程和指标套件。

Result: 构建了一个包含五个任务家族的完整基准测试框架，包括反应重新平衡、原子到原子映射、反应分类、反应属性预测和合成路线设计，所有资源都在宽松的开放许可下发布。

Conclusion: SynRXN通过消除数据集异质性并提供透明、可重用的评估框架，为CASP方法提供了公平的比较基准，降低了从业者获得稳健和可比性能估计的门槛。

Abstract: We present SynRXN, a unified benchmarking framework and open-data resource for computer-aided synthesis planning (CASP). SynRXN decomposes end-to-end synthesis planning into five task families, covering reaction rebalancing, atom-to-atom mapping, reaction classification, reaction property prediction, and synthesis route design. Curated, provenance-tracked reaction corpora are assembled from heterogeneous public sources into a harmonized representation and packaged as versioned datasets for each task family, with explicit source metadata, licence tags, and machine-readable manifests that record checksums, and row counts. For every task, SynRXN provides transparent splitting functions that generate leakage-aware train, validation, and test partitions, together with standardized evaluation workflows and metric suites tailored to classification, regression, and structured prediction settings. For sensitive benchmarking, we combine public training and validation data with held-out gold-standard test sets, and contamination-prone tasks such as reaction rebalancing and atom-to-atom mapping are distributed only as evaluation sets and are explicitly not intended for model training. Scripted build recipes enable bitwise-reproducible regeneration of all corpora across machines and over time, and the entire resource is released under permissive open licences to support reuse and extension. By removing dataset heterogeneity and packaging transparent, reusable evaluation scaffolding, SynRXN enables fair longitudinal comparison of CASP methods, supports rigorous ablations and stress tests along the full reaction-informatics pipeline, and lowers the barrier for practitioners who seek robust and comparable performance estimates for real-world synthesis planning workloads.

</details>


### [320] [Refinement Provenance Inference: Detecting LLM-Refined Training Prompts from Model Behavior](https://arxiv.org/abs/2601.01966)
*Bo Yin,Qi Li,Runpeng Yu,Xinchao Wang*

Main category: cs.LG

TL;DR: 本文提出了Refinement Provenance Inference (RPI)任务，旨在通过分析微调模型的token分布来推断训练数据中是否使用了LLM精炼的提示词，并开发了RePro框架来解决这一审计问题。


<details>
  <summary>Details</summary>
Motivation: 随着指令调优越来越多地依赖LLM进行提示词精炼，需要解决训练数据来源的审计问题，即判断微调模型是基于原始提示词还是精炼后的提示词训练的，这对于数据集治理和争议解决具有重要意义。

Method: 提出了RePro框架，利用教师强制token分布的稳定变化特征，结合logit排序信号，通过影子微调学习可迁移表示，使用轻量级线性头在未见过的模型上进行来源推断。

Result: 实验表明RePro在性能上表现稳定且具有很好的迁移性，能够跨不同精炼器有效工作，说明其利用了精炼器无关的分布变化而非重写风格特征。

Conclusion: 提示词精炼会产生可检测的token分布变化，RePro框架为解决训练数据来源审计问题提供了有效方法，具有实际应用价值。

Abstract: Instruction tuning increasingly relies on LLM-based prompt refinement, where prompts in the training corpus are selectively rewritten by an external refiner to improve clarity and instruction alignment. This motivates an instance-level audit problem: for a fine-tuned model and a training prompt-response pair, can we infer whether the model was trained on the original prompt or its LLM-refined version within a mixed corpus? This matters for dataset governance and dispute resolution when training data are contested. However, it is non-trivial in practice: refined and raw instances are interleaved in the training corpus with unknown, source-dependent mixture ratios, making it harder to develop provenance methods that generalize across models and training setups. In this paper, we formalize this audit task as Refinement Provenance Inference (RPI) and show that prompt refinement yields stable, detectable shifts in teacher-forced token distributions, even when semantic differences are not obvious. Building on this phenomenon, we propose RePro, a logit-based provenance framework that fuses teacher-forced likelihood features with logit-ranking signals. During training, RePro learns a transferable representation via shadow fine-tuning, and uses a lightweight linear head to infer provenance on unseen victims without training-data access. Empirically, RePro consistently attains strong performance and transfers well across refiners, suggesting that it exploits refiner-agnostic distribution shifts rather than rewrite-style artifacts.

</details>


### [321] [SerpentFlow: Generative Unpaired Domain Alignment via Shared-Structure Decomposition](https://arxiv.org/abs/2601.01979)
*Julie Keisler,Anastase Alexandre Charantonis,Yannig Goude,Boutheina Oueslati,Claire Monteleoni*

Main category: cs.LG

TL;DR: SerpentFlow是一个用于无配对域对齐的生成框架，通过将数据分解为共享结构和域特定组件，构建合成训练对来学习条件分布。


<details>
  <summary>Details</summary>
Motivation: 解决无配对观测情况下域对齐的挑战，特别是在域共享底层结构模式但具体实现不同的场景中。

Method: 在潜在空间中将数据分解为共享组件和域特定组件，通过替换域特定组件为随机噪声构建合成训练对，使用基于分类器的准则自动确定分解频率。

Result: 在合成图像、物理过程模拟和气候降尺度任务上的实验表明，该方法能有效重建与底层低频模式一致的高频结构。

Conclusion: 共享结构分解是解决无配对域对齐问题的有效策略，SerpentFlow框架具有良好的应用前景。

Abstract: Domain alignment refers broadly to learning correspondences between data distributions from distinct domains. In this work, we focus on a setting where domains share underlying structural patterns despite differences in their specific realizations. The task is particularly challenging in the absence of paired observations, which removes direct supervision across domains. We introduce a generative framework, called SerpentFlow (SharEd-structuRe decomPosition for gEnerative domaiN adapTation), for unpaired domain alignment. SerpentFlow decomposes data within a latent space into a shared component common to both domains and a domain-specific one. By isolating the shared structure and replacing the domain-specific component with stochastic noise, we construct synthetic training pairs between shared representations and target-domain samples, thereby enabling the use of conditional generative models that are traditionally restricted to paired settings. We apply this approach to super-resolution tasks, where the shared component naturally corresponds to low-frequency content while high-frequency details capture domain-specific variability. The cutoff frequency separating low- and high-frequency components is determined automatically using a classifier-based criterion, ensuring a data-driven and domain-adaptive decomposition. By generating pseudo-pairs that preserve low-frequency structures while injecting stochastic high-frequency realizations, we learn the conditional distribution of the target domain given the shared representation. We implement SerpentFlow using Flow Matching as the generative pipeline, although the framework is compatible with other conditional generative approaches. Experiments on synthetic images, physical process simulations, and a climate downscaling task demonstrate that the method effectively reconstructs high-frequency structures consistent with underlying low-frequency patterns, supporting shared-structure decomposition as an effective strategy for unpaired domain alignment.

</details>


### [322] [Prior Diffusiveness and Regret in the Linear-Gaussian Bandit](https://arxiv.org/abs/2601.02022)
*Yifan Zhu,John C. Duchi,Benjamin Van Roy*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We prove that Thompson sampling exhibits $\tilde{O}(σd \sqrt{T} + d r \sqrt{\mathrm{Tr}(Σ_0)})$ Bayesian regret in the linear-Gaussian bandit with a $\mathcal{N}(μ_0, Σ_0)$ prior distribution on the coefficients, where $d$ is the dimension, $T$ is the time horizon, $r$ is the maximum $\ell_2$ norm of the actions, and $σ^2$ is the noise variance. In contrast to existing regret bounds, this shows that to within logarithmic factors, the prior-dependent ``burn-in'' term $d r \sqrt{\mathrm{Tr}(Σ_0)}$ decouples additively from the minimax (long run) regret $σd \sqrt{T}$. Previous regret bounds exhibit a multiplicative dependence on these terms. We establish these results via a new ``elliptical potential'' lemma, and also provide a lower bound indicating that the burn-in term is unavoidable.

</details>


### [323] [Output Embedding Centering for Stable LLM Pretraining](https://arxiv.org/abs/2601.02031)
*Felix Stollenwerk,Anna Lokrantz,Niclas Hertzberg*

Main category: cs.LG

TL;DR: 本文提出输出嵌入中心化(OEC)方法来解决大语言模型预训练中的输出logit发散问题，相比现有的z-loss方法更有效且对超参数调优更不敏感。


<details>
  <summary>Details</summary>
Motivation: 大语言模型预训练不仅成本高昂，还容易出现训练不稳定性。特别是在训练后期使用大学习率时，经常出现输出logit发散的问题。现有的z-loss方法只是治标不治本。

Method: 从输出嵌入几何的角度分析不稳定性原因，提出输出嵌入中心化(OEC)作为新的缓解策略。OEC有两种实现方式：确定性操作μ-centering和正则化方法μ-loss。

Result: 实验表明，两种OEC变体在训练稳定性和学习率敏感性方面都优于z-loss。特别是对于z-loss失效的大学习率情况，OEC方法仍能确保训练收敛。μ-loss对正则化超参数调优的敏感性显著低于z-loss。

Conclusion: OEC方法能够有效抑制输出logit发散，解决了大语言模型预训练中的关键不稳定性问题，为高效训练提供了更可靠的解决方案。

Abstract: Pretraining of large language models is not only expensive but also prone to certain training instabilities. A specific instability that often occurs for large learning rates at the end of training is output logit divergence. The most widely used mitigation strategy, z-loss, merely addresses the symptoms rather than the underlying cause of the problem. In this paper, we analyze the instability from the perspective of the output embeddings' geometry and identify its cause. Based on this, we propose output embedding centering (OEC) as a new mitigation strategy, and prove that it suppresses output logit divergence. OEC can be implemented in two different ways, as a deterministic operation called μ-centering, or a regularization method called μ-loss. Our experiments show that both variants outperform z-loss in terms of training stability and learning rate sensitivity. In particular, they ensure that training converges even for large learning rates when z-loss fails. Furthermore, we find that μ-loss is significantly less sensitive to regularization hyperparameter tuning than z-loss.

</details>


### [324] [GDRO: Group-level Reward Post-training Suitable for Diffusion Models](https://arxiv.org/abs/2601.02036)
*Yiyang Wang,Xi Chen,Xiaogang Xu,Yu Liu,Hengshuang Zhao*

Main category: cs.LG

TL;DR: 本文提出GDRO方法，解决文本到图像校正流扩散模型在奖励对齐中的效率低、依赖随机采样器和奖励黑客问题。


<details>
  <summary>Details</summary>
Motivation: 现有在线强化学习方法在文本到图像校正流扩散模型中存在效率低、依赖随机采样器和奖励黑客问题，需要针对校正流模型特性设计新方法。

Method: 提出组级直接奖励优化（GDRO）方法，支持完全离线训练，无需图像采样，且独立于扩散采样器，避免ODE到SDE近似。

Result: 实验表明GDRO在OCR和GenEval任务中有效提升扩散模型的奖励分数，同时具有强稳定性和鲁棒性，能缓解奖励黑客问题。

Conclusion: GDRO为校正流模型提供了一种高效、稳定的组级奖励对齐后训练范式，解决了现有方法的局限性。

Abstract: Recent advancements adopt online reinforcement learning (RL) from LLMs to text-to-image rectified flow diffusion models for reward alignment. The use of group-level rewards successfully aligns the model with the targeted reward. However, it faces challenges including low efficiency, dependency on stochastic samplers, and reward hacking. The problem is that rectified flow models are fundamentally different from LLMs: 1) For efficiency, online image sampling takes much more time and dominates the time of training. 2) For stochasticity, rectified flow is deterministic once the initial noise is fixed. Aiming at these problems and inspired by the effects of group-level rewards from LLMs, we design Group-level Direct Reward Optimization (GDRO). GDRO is a new post-training paradigm for group-level reward alignment that combines the characteristics of rectified flow models. Through rigorous theoretical analysis, we point out that GDRO supports full offline training that saves the large time cost for image rollout sampling. Also, it is diffusion-sampler-independent, which eliminates the need for the ODE-to-SDE approximation to obtain stochasticity. We also empirically study the reward hacking trap that may mislead the evaluation, and involve this factor in the evaluation using a corrected score that not only considers the original evaluation reward but also the trend of reward hacking. Extensive experiments demonstrate that GDRO effectively and efficiently improves the reward score of the diffusion model through group-wise offline optimization across the OCR and GenEval tasks, while demonstrating strong stability and robustness in mitigating reward hacking.

</details>


### [325] [Multivariate Time-series Anomaly Detection via Dynamic Model Pool & Ensembling](https://arxiv.org/abs/2601.02037)
*Wei Hu,Zewei Yu,Jianqiu Xu*

Main category: cs.LG

TL;DR: DMPEAD是一个动态模型池和集成框架，用于多变量时间序列异常检测，通过构建多样化模型池、动态更新和集成排名靠前的模型来解决现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有多变量时间序列异常检测方法存在三个主要问题：选择方法依赖单一模型且对策略敏感；集成方法通常组合所有模型或仅限于单变量数据；大多数方法依赖固定数据维度，限制了可扩展性。

Method: 提出DMPEAD框架，包括三个步骤：(1)通过参数传递和多样性指标构建多样化模型池；(2)使用元模型和基于相似性的策略进行动态更新，包括自适应池扩展、子集选择和池合并；(3)通过代理指标排名和top-k聚合在选定子集中集成排名靠前的模型。

Result: 在8个真实世界数据集上的广泛实验表明，该模型优于所有基线方法，展示了卓越的适应性和可扩展性。

Conclusion: DMPEAD框架有效解决了多变量时间序列异常检测中现有方法的局限性，通过动态模型池和集成策略实现了更好的性能表现。

Abstract: Multivariate time-series (MTS) anomaly detection is critical in domains such as service monitor, IoT, and network security. While multi-model methods based on selection or ensembling outperform single-model ones, they still face limitations: (i) selection methods rely on a single chosen model and are sensitive to the strategy; (ii) ensembling methods often combine all models or are restricted to univariate data; and (iii) most methods depend on fixed data dimensionality, limiting scalability. To address these, we propose DMPEAD, a Dynamic Model Pool and Ensembling framework for MTS Anomaly Detection. The framework first (i) constructs a diverse model pool via parameter transfer and diversity metric, then (ii) updates it with a meta-model and similarity-based strategy for adaptive pool expansion, subset selection, and pool merging, finally (iii) ensembles top-ranked models through proxy metric ranking and top-k aggregation in the selected subset, outputting the final anomaly detection result. Extensive experiments on 8 real-world datasets show that our model outperforms all baselines, demonstrating superior adaptability and scalability.

</details>


### [326] [Explore the Ideology of Deep Learning in ENSO Forecasts](https://arxiv.org/abs/2601.02050)
*Yanhai Gan,Yipeng Chen,Ning Li,Xingguo Liu,Junyu Dong,Xianyao Chen*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The El Ni{~n}o-Southern Oscillation (ENSO) exerts profound influence on global climate variability, yet its prediction remains a grand challenge. Recent advances in deep learning have significantly improved forecasting skill, but the opacity of these models hampers scientific trust and operational deployment. Here, we introduce a mathematically grounded interpretability framework based on bounded variation function. By rescuing the "dead" neurons from the saturation zone of the activation function, we enhance the model's expressive capacity. Our analysis reveals that ENSO predictability emerges dominantly from the tropical Pacific, with contributions from the Indian and Atlantic Oceans, consistent with physical understanding. Controlled experiments affirm the robustness of our method and its alignment with established predictors. Notably, we probe the persistent Spring Predictability Barrier (SPB), finding that despite expanded sensitivity during spring, predictive performance declines-likely due to suboptimal variable selection. These results suggest that incorporating additional ocean-atmosphere variables may help transcend SPB limitations and advance long-range ENSO prediction.

</details>


### [327] [The Homogeneity Trap: Spectral Collapse in Doubly-Stochastic Deep Networks](https://arxiv.org/abs/2601.02080)
*Yizhi Liu*

Main category: cs.LG

TL;DR: 本文揭示了双随机矩阵在深度架构中的光谱退化现象，称为同质性陷阱，指出高熵约束会限制特征变换的有效感受野，并证明层归一化在噪声主导情况下无法缓解这种崩溃。


<details>
  <summary>Details</summary>
Motivation: 双随机矩阵在结构保持深度架构中广泛使用以确保数值稳定性和概率可解释性，但存在潜在的光谱退化问题需要研究。

Method: 通过理论分析推导光谱边界，证明最大熵偏置导致混合算子趋向均匀重心，抑制次主导奇异值，并分析层归一化在噪声主导机制下的失效。

Result: 发现高熵约束会限制网络的有效深度，当信噪比低于临界阈值时，几何结构会因噪声诱导的正交崩溃而不可逆地丢失。

Conclusion: 双随机矩阵约束网络中存在熵稳定性和光谱表达能力之间的根本权衡，需要重新考虑结构保持约束的设计。

Abstract: Doubly-stochastic matrices (DSM) are increasingly utilized in structure-preserving deep architectures -- such as Optimal Transport layers and Sinkhorn-based attention -- to enforce numerical stability and probabilistic interpretability. In this work, we identify a critical spectral degradation phenomenon inherent to these constraints, termed the Homogeneity Trap. We demonstrate that the maximum-entropy bias, typical of Sinkhorn-based projections, drives the mixing operator towards the uniform barycenter, thereby suppressing the subdominant singular value σ_2 and filtering out high-frequency feature components. We derive a spectral bound linking σ_2 to the network's effective depth, showing that high-entropy constraints restrict feature transformation to a shallow effective receptive field. Furthermore, we formally demonstrate that Layer Normalization fails to mitigate this collapse in noise-dominated regimes; specifically, when spectral filtering degrades the Signal-to-Noise Ratio (SNR) below a critical threshold, geometric structure is irreversibly lost to noise-induced orthogonal collapse. Our findings highlight a fundamental trade-off between entropic stability and spectral expressivity in DSM-constrained networks.

</details>


### [328] [A Differentiable Adversarial Framework for Task-Aware Data Subsampling](https://arxiv.org/abs/2601.02081)
*Jiacheng Lyu,Bihua Bao*

Main category: cs.LG

TL;DR: ASSS框架将数据缩减重构为可微分的端到端学习问题，通过选择器网络和任务网络的对抗博弈，为样本分配连续重要性权重，实现任务感知的数据子采样。


<details>
  <summary>Details</summary>
Motivation: 大规模数据集对模型训练带来计算挑战，传统数据子采样方法作为静态预处理步骤会丢弃对下游预测关键的信息。

Method: 使用选择器网络和任务网络的对抗博弈，通过Gumbel-Softmax松弛实现直接优化，选择器在损失函数指导下识别并保留对特定任务目标信息量最大的样本。

Result: 在四个大规模真实数据集上的实验表明，ASSS始终优于聚类和最近邻稀释等启发式子采样基线，有时甚至能超过使用整个数据集的训练性能。

Conclusion: 该工作将任务感知数据子采样确立为可学习组件，为有效的大规模数据学习提供了原则性解决方案。

Abstract: The proliferation of large-scale datasets poses a major computational challenge to model training. The traditional data subsampling method works as a static, task independent preprocessing step which usually discards information that is critical to downstream prediction. In this paper, we introduces the antagonistic soft selection subsampling (ASSS) framework as is a novel paradigm that reconstructs data reduction into a differentiable end-to-end learning problem. ASSS uses the adversarial game between selector network and task network, and selector network learning assigns continuous importance weights to samples. This direct optimization implemented by Gumbel-Softmax relaxation allows the selector to identify and retain samples with the maximum amount of information for a specific task target under the guidance of the loss function that balances the fidelity and sparsity of the prediction. Theoretical analysis links this framework with the information bottleneck principle. Comprehensive experiments on four large-scale real world datasets show that ASSS has always been better than heuristic subsampling baselines such as clustering and nearest neighbor thinning in maintaining model performance. It is worth noting that ASSS can not only match, but also sometimes exceed the training performance of the entire dataset, showcasing the effect of intelligent denoising. This work establishes task aware data subsampling as a learnable component, providing a principled solution for effective large-scale data learning.

</details>


### [329] [Horizon Activation Mapping for Neural Networks in Time Series Forecasting](https://arxiv.org/abs/2601.02094)
*Hans Krupakar,V A Kandappan*

Main category: cs.LG

TL;DR: 本文提出了Horizon Activation Mapping (HAM)，一种用于时间序列预测模型的可视化可解释性技术，能够跨不同模型家族进行模型选择和比较。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列预测模型的可解释性方法依赖于误差指标和特定架构的方法，无法跨不同模型家族应用。需要一种模型无关的可解释性技术来支持模型选择和验证。

Method: HAM受grad-CAM启发，使用梯度范数平均值来研究时间序列的子序列，引入因果和反因果模式计算每个时间步的梯度更新范数平均值，并分析比例线表示范数平均值的均匀分布。

Result: 研究发现批次大小对活动性的差异表明存在指数近似的潜力，HAM图可以显示NHITS的神经近似定理和SpaceTime的指数自回归活动。HAM可用于细粒度模型选择、验证集选择和跨模型比较。

Conclusion: HAM是一种有效的可视化可解释性技术，能够跨不同神经网络模型家族进行模型分析、选择和比较，为时间序列预测模型提供统一的评估框架。

Abstract: Neural networks for time series forecasting have relied on error metrics and architecture-specific interpretability approaches for model selection that don't apply across models of different families. To interpret forecasting models agnostic to the types of layers across state-of-the-art model families, we introduce Horizon Activation Mapping (HAM), a visual interpretability technique inspired by grad-CAM that uses gradient norm averages to study the horizon's subseries where grad-CAM studies attention maps over image data. We introduce causal and anti-causal modes to calculate gradient update norm averages across subseries at every timestep and lines of proportionality signifying uniform distributions of the norm averages. Optimization landscape studies with respect to changes in batch sizes, early stopping, train-val-test splits, univariate forecasting and dropouts are studied with respect to performances and subseries in HAM. Interestingly, batch size based differences in activities seem to indicate potential for existence of an exponential approximation across them per epoch relative to each other. Multivariate forecasting models including MLP-based CycleNet, N-Linear, N-HITS, self attention-based FEDformer, Pyraformer, SSM-based SpaceTime and diffusion-based Multi-Resolution DDPM over different horizon sizes trained over the ETTm2 dataset are used for HAM plots in this study. NHITS' neural approximation theorem and SpaceTime's exponential autoregressive activities have been attributed to trends in HAM plots over their training, validation and test sets. In general, HAM can be used for granular model selection, validation set choices and comparisons across different neural network model families.

</details>


### [330] [LION-DG: Layer-Informed Initialization with Deep Gradient Protocols for Accelerated Neural Network Training](https://arxiv.org/abs/2601.02105)
*Hyunjun Kim*

Main category: cs.LG

TL;DR: LION-DG是一种针对深度监督架构的层感知初始化方法，通过零初始化辅助分类器头部，实现梯度唤醒机制，无需超参数即可改善训练稳定性


<details>
  <summary>Details</summary>
Motivation: 现有初始化方法大多对层不敏感，而深度监督架构中的未训练辅助分类器会通过梯度干扰破坏早期训练的稳定性

Method: 提出LION-DG初始化方法：对主干网络应用标准He初始化，而对辅助分类器头部进行零初始化，实现梯度唤醒机制

Result: 在CIFAR-10和CIFAR-100上的实验表明：DenseNet-DS收敛速度提升8.3%；与LSUV结合达到81.92%的最佳准确率；ResNet-DS在CIFAR-100上速度提升11.3%

Conclusion: LION-DG方法简单、无需超参数、无计算开销，为深度监督架构提供了有效的初始化解决方案

Abstract: Weight initialization remains decisive for neural network optimization, yet existing methods are largely layer-agnostic. We study initialization for deeply-supervised architectures with auxiliary classifiers, where untrained auxiliary heads can destabilize early training through gradient interference.
  We propose LION-DG, a layer-informed initialization that zero-initializes auxiliary classifier heads while applying standard He-initialization to the backbone. We prove that this implements Gradient Awakening: auxiliary gradients are exactly zero at initialization, then phase in naturally as weights grow -- providing an implicit warmup without hyperparameters.
  Experiments on CIFAR-10 and CIFAR-100 with DenseNet-DS and ResNet-DS architectures demonstrate: (1) DenseNet-DS: +8.3% faster convergence on CIFAR-10 with comparable accuracy, (2) Hybrid approach: Combining LSUV with LION-DG achieves best accuracy (81.92% on CIFAR-10), (3) ResNet-DS: Positive speedup on CIFAR-100 (+11.3%) with side-tap auxiliary design.
  We identify architecture-specific trade-offs and provide clear guidelines for practitioners. LION-DG is simple, requires zero hyperparameters, and adds no computational overhead.

</details>


### [331] [Prototype-Based Learning for Healthcare: A Demonstration of Interpretable AI](https://arxiv.org/abs/2601.02106)
*Ashish Rana,Ammar Shaker,Sascha Saralajew,Takashi Suzuki,Kosuke Yasuda,Shintaro Kato,Toshikazu Wada,Toshiyuki Fujikawa,Toru Kikutsuji*

Main category: cs.LG

TL;DR: ProtoPal框架通过原型学习实现个性化预防医疗的透明化预测和干预，提供前后端模式，在保证性能的同时增强可理解性


<details>
  <summary>Details</summary>
Motivation: 解决当前机器学习在医疗领域预测、干预和推荐缺乏可理解性和可验证性的问题，满足所有医疗利益相关者的需求

Method: 提出ProtoPal原型学习框架，采用前后端模式，通过原型表示来展示干预措施及其模拟结果

Result: 在保持优异量化性能的同时，提供了直观的干预展示和结果模拟

Conclusion: 原型学习是解决医疗领域AI可解释性和可验证性问题的有效方法，ProtoPal框架为个性化预防医疗提供了实用解决方案

Abstract: Despite recent advances in machine learning and explainable AI, a gap remains in personalized preventive healthcare: predictions, interventions, and recommendations should be both understandable and verifiable for all stakeholders in the healthcare sector. We present a demonstration of how prototype-based learning can address these needs. Our proposed framework, ProtoPal, features both front- and back-end modes; it achieves superior quantitative performance while also providing an intuitive presentation of interventions and their simulated outcomes.

</details>


### [332] [Edge-aware GAT-based protein binding site prediction](https://arxiv.org/abs/2601.02138)
*Weisen Yang,Hanqing Zhang,Wangren Qiu,Xuan Xiao,Weizhong Lin*

Main category: cs.LG

TL;DR: 提出了一种基于边缘感知图注意力网络的蛋白质结合位点预测方法，通过整合多维结构特征和方向性边缘信息，在保持计算效率的同时显著提高了预测精度。


<details>
  <summary>Details</summary>
Motivation: 传统预测方法在平衡预测精度和计算效率方面存在困难，特别是在捕捉复杂空间构象时表现不佳。需要一种能够准确识别蛋白质结合位点的新方法。

Method: 构建原子级图结构，整合几何描述符、DSSP二级结构和相对溶剂可及性等多维特征。在注意力机制中引入原子间距离和方向向量作为边缘特征，使用方向张量传播和残基级注意力池化。

Result: 在基准数据集上，蛋白质-蛋白质结合位点预测的ROC-AUC达到0.93，优于多种最先进方法。PyMOL可视化验证了模型的实用性和可解释性。

Conclusion: 该方法为蛋白质功能位点识别提供了一种新颖高效的解决方案，平衡了预测精度、泛化能力和可解释性，并部署了公开可访问的网页服务器。

Abstract: Accurate identification of protein binding sites is crucial for understanding biomolecular interaction mechanisms and for the rational design of drug targets. Traditional predictive methods often struggle to balance prediction accuracy with computational efficiency when capturing complex spatial conformations. To address this challenge, we propose an Edge-aware Graph Attention Network (Edge-aware GAT) model for the fine-grained prediction of binding sites across various biomolecules, including proteins, DNA/RNA, ions, ligands, and lipids. Our method constructs atom-level graphs and integrates multidimensional structural features, including geometric descriptors, DSSP-derived secondary structure, and relative solvent accessibility (RSA), to generate spatially aware embedding vectors. By incorporating interatomic distances and directional vectors as edge features within the attention mechanism, the model significantly enhances its representation capacity. On benchmark datasets, our model achieves an ROC-AUC of 0.93 for protein-protein binding site prediction, outperforming several state-of-the-art methods. The use of directional tensor propagation and residue-level attention pooling further improves both binding site localization and the capture of local structural details. Visualizations using PyMOL confirm the model's practical utility and interpretability. To facilitate community access and application, we have deployed a publicly accessible web server at http://119.45.201.89:5000/. In summary, our approach offers a novel and efficient solution that balances prediction accuracy, generalization, and interpretability for identifying functional sites in proteins.

</details>


### [333] [Entropy-Adaptive Fine-Tuning: Resolving Confident Conflicts to Mitigate Forgetting](https://arxiv.org/abs/2601.02151)
*Muxi Diao,Lele Yang,Wuxuan Gong,Yutong Zhang,Zhonghao Yan,Yufei Han,Kongming Liang,Weiran Xu,Zhanyu Ma*

Main category: cs.LG

TL;DR: 本文提出EAFT方法，通过利用token级熵作为门控机制来区分认知不确定性和知识冲突，从而在保持下游性能的同时显著减轻通用能力的退化。


<details>
  <summary>Details</summary>
Motivation: 监督微调（SFT）会导致灾难性遗忘，而策略性强化学习（RL）能有效保持通用能力。研究发现SFT与模型内部信念存在分布差距，导致"自信冲突"问题。

Method: 提出熵自适应微调（EAFT），使用token级熵作为门控机制，让模型从不确定样本中学习，同时抑制冲突数据的梯度更新。

Result: 在Qwen和GLM系列模型（4B到32B参数）上的数学、医疗和智能体领域实验证实，EAFT在匹配标准SFT下游性能的同时显著减轻了通用能力的退化。

Conclusion: EAFT通过熵自适应机制有效解决了SFT中的灾难性遗忘问题，为领域自适应提供了更优的解决方案。

Abstract: Supervised Fine-Tuning (SFT) is the standard paradigm for domain adaptation, yet it frequently incurs the cost of catastrophic forgetting. In sharp contrast, on-policy Reinforcement Learning (RL) effectively preserves general capabilities. We investigate this discrepancy and identify a fundamental distributional gap: while RL aligns with the model's internal belief, SFT forces the model to fit external supervision. This mismatch often manifests as "Confident Conflicts" tokens characterized by low probability but low entropy. In these instances, the model is highly confident in its own prediction but is forced to learn a divergent ground truth, triggering destructive gradient updates. To address this, we propose Entropy-Adaptive Fine-Tuning (EAFT). Unlike methods relying solely on prediction probability, EAFT utilizes token-level entropy as a gating mechanism to distinguish between epistemic uncertainty and knowledge conflict. This allows the model to learn from uncertain samples while suppressing gradients on conflicting data. Extensive experiments on Qwen and GLM series (ranging from 4B to 32B parameters) across mathematical, medical, and agentic domains confirm our hypothesis. EAFT consistently matches the downstream performance of standard SFT while significantly mitigating the degradation of general capabilities.

</details>


### [334] [Learning with Monotone Adversarial Corruptions](https://arxiv.org/abs/2601.02193)
*Kasper Green Larsen,Chirag Pabbaraju,Abhishek Shetty*

Main category: cs.LG

TL;DR: 该论文研究了标准机器学习算法对数据交换性和独立性的依赖程度，通过引入单调对抗性腐败模型，发现即使面对看似有益的单调腐败，最优学习算法也会表现不佳，而基于均匀收敛的算法则不受影响。


<details>
  <summary>Details</summary>
Motivation: 探讨机器学习算法对数据交换性和独立性的依赖程度，揭示最优算法在面对单调腐败时的脆弱性。

Method: 引入单调对抗性腐败模型，允许对手在查看干净数据集后插入受约束的腐败点，这些点根据真实目标函数进行标记。

Result: 所有已知的二元分类最优学习算法在单调腐败设置下都会在新测试点上达到次优预期误差，而基于均匀收敛的算法则保持其保证不变。

Conclusion: 研究结果表明最优学习算法在面对看似有益的单调腐败时会崩溃，暴露了它们对交换性的过度依赖。

Abstract: We study the extent to which standard machine learning algorithms rely on exchangeability and independence of data by introducing a monotone adversarial corruption model. In this model, an adversary, upon looking at a "clean" i.i.d. dataset, inserts additional "corrupted" points of their choice into the dataset. These added points are constrained to be monotone corruptions, in that they get labeled according to the ground-truth target function. Perhaps surprisingly, we demonstrate that in this setting, all known optimal learning algorithms for binary classification can be made to achieve suboptimal expected error on a new independent test point drawn from the same distribution as the clean dataset. On the other hand, we show that uniform convergence-based algorithms do not degrade in their guarantees. Our results showcase how optimal learning algorithms break down in the face of seemingly helpful monotone corruptions, exposing their overreliance on exchangeability.

</details>


### [335] [ACDZero: Graph-Embedding-Based Tree Search for Mastering Automated Cyber Defense](https://arxiv.org/abs/2601.02196)
*Yu Li,Sizhe Tang,Rongqian Chen,Fei Xu Yu,Guangyu Jiang,Mahdi Imani,Nathaniel D. Bastian,Tian Lan*

Main category: cs.LG

TL;DR: 本文提出了一种基于蒙特卡洛树搜索（MCTS）和图神经网络（GNN）的自动化网络防御方法，通过规划导向的防御策略在CAGE-4挑战中实现了样本高效的学习和更好的防御效果。


<details>
  <summary>Details</summary>
Motivation: 现有的自动化网络防御方法（如深度强化学习）在复杂网络中面临探索困难和大状态空间的问题，需要大量样本。本文旨在开发样本效率更高的防御策略。

Method: 将ACD问题建模为基于上下文的部分可观测马尔可夫决策过程，使用MCTS进行规划，结合GNN嵌入网络观测数据，通过图编辑动作先验和策略蒸馏结合模型泛化和前瞻规划。

Result: 在CC4场景的评估中，该方法相比最先进的RL基线在防御奖励和鲁棒性方面均有提升。

Conclusion: 基于搜索引导和图嵌入的规划方法能够有效改善自动化网络防御的性能，特别是在复杂网络环境中表现出更好的样本效率和决策质量。

Abstract: Automated cyber defense (ACD) seeks to protect computer networks with minimal or no human intervention, reacting to intrusions by taking corrective actions such as isolating hosts, resetting services, deploying decoys, or updating access controls. However, existing approaches for ACD, such as deep reinforcement learning (RL), often face difficult exploration in complex networks with large decision/state spaces and thus require an expensive amount of samples. Inspired by the need to learn sample-efficient defense policies, we frame ACD in CAGE Challenge 4 (CAGE-4 / CC4) as a context-based partially observable Markov decision problem and propose a planning-centric defense policy based on Monte Carlo Tree Search (MCTS). It explicitly models the exploration-exploitation tradeoff in ACD and uses statistical sampling to guide exploration and decision making. We make novel use of graph neural networks (GNNs) to embed observations from the network as attributed graphs, to enable permutation-invariant reasoning over hosts and their relationships. To make our solution practical in complex search spaces, we guide MCTS with learned graph embeddings and priors over graph-edit actions, combining model-free generalization and policy distillation with look-ahead planning. We evaluate the resulting agent on CC4 scenarios involving diverse network structures and adversary behaviors, and show that our search-guided, graph-embedding-based planning improves defense reward and robustness relative to state-of-the-art RL baselines.

</details>


### [336] [CORE: Code-based Inverse Self-Training Framework with Graph Expansion for Virtual Agents](https://arxiv.org/abs/2601.02201)
*Keyu Wang,Bingchen Miao,Wendong Bu,Yu Wu,Juncheng Li,Shengyu Zhang,Wenqiao Zhang,Siliang Tang,Jun Xiao,Yueting Zhuang*

Main category: cs.LG

TL;DR: CORE是一个基于代码的逆自训练框架，通过图扩展解决了行为克隆和强化学习之间的冲突，无需手动奖励设计即可提升行为多样性。


<details>
  <summary>Details</summary>
Motivation: 主流训练范式存在矛盾：行为克隆简单有效但行为多样性低，强化学习能发现新策略但依赖手动奖励设计。需要一种方法既能保持多样性又无需手动奖励。

Method: 引入语义代码抽象自动从专家演示中推断奖励函数（标签函数），通过策略图扩展增强域内行为多样性，利用轨迹引导外推丰富域外行为多样性。

Result: 在Web和Android平台上的实验表明，CORE显著提高了整体性能和泛化能力。

Conclusion: CORE作为一个强大且可泛化的训练范式，具有构建强大虚拟代理的潜力。

Abstract: The development of Multimodal Virtual Agents has made significant progress through the integration of Multimodal Large Language Models. However, mainstream training paradigms face key challenges: Behavior Cloning is simple and effective through imitation but suffers from low behavioral diversity, while Reinforcement Learning is capable of discovering novel strategies through exploration but heavily relies on manually designed reward functions. To address the conflict between these two methods, we present CORE, a Code-based Inverse Self-Training Framework with Graph Expansion that bridges imitation and exploration, offering a novel training framework that promotes behavioral diversity while eliminating the reliance on manually reward design. Specifically, we introduce Semantic Code Abstraction to automatically infers reward functions from expert demonstrations without manual design. The inferred reward function, referred to as the Label Function, is executable code that verifies one key step within a task. Building on this, we propose Strategy Graph Expansion to enhance in-domain behavioral diversity, which constructs a multi-path graph called Strategy Graph that captures diverse valid solutions beyond expert demonstrations. Furthermore, we introduce Trajectory-Guided Extrapolation, which enriches out-of-domain behavioral diversity by utilizing both successful and failed trajectories to expand the task space. Experiments on Web and Android platforms demonstrate that CORE significantly improves both overall performance and generalization, highlighting its potential as a robust and generalizable training paradigm for building powerful virtual agents.

</details>


### [337] [Quantized SO(3)-Equivariant Graph Neural Networks for Efficient Molecular Property Prediction](https://arxiv.org/abs/2601.02213)
*Haoyu Zhou,Ping Xue,Tianfan Fu,Hao Zhang*

Main category: cs.LG

TL;DR: 该论文提出了一种用于压缩和加速SO(3)等变图神经网络的低比特量化技术，通过三个创新方法在保持精度的同时显著提升效率。


<details>
  <summary>Details</summary>
Motivation: 3D等变图神经网络在边缘设备上部署时面临高计算成本挑战，需要解决效率问题以实现在实际化学应用中的部署。

Method: 提出三种创新方法：1）幅度-方向解耦量化方案；2）分支分离的量化感知训练策略；3）鲁棒性增强的注意力归一化机制。

Result: 在QM9和rMD17分子基准测试中，8位模型在能量和力预测方面达到与全精度基线相当的精度，推理速度提升2.37-2.73倍，模型大小减少4倍。

Conclusion: 所提出的技术能够在保持精度和物理对称性的前提下，实现对称感知GNN在实际化学应用中的高效部署。

Abstract: Deploying 3D graph neural networks (GNNs) that are equivariant to 3D rotations (the group SO(3)) on edge devices is challenging due to their high computational cost. This paper addresses the problem by compressing and accelerating an SO(3)-equivariant GNN using low-bit quantization techniques. Specifically, we introduce three innovations for quantized equivariant transformers: (1) a magnitude-direction decoupled quantization scheme that separately quantizes the norm and orientation of equivariant (vector) features, (2) a branch-separated quantization-aware training strategy that treats invariant and equivariant feature channels differently in an attention-based $SO(3)$-GNN, and (3) a robustness-enhancing attention normalization mechanism that stabilizes low-precision attention computations. Experiments on the QM9 and rMD17 molecular benchmarks demonstrate that our 8-bit models achieve accuracy on energy and force predictions comparable to full-precision baselines with markedly improved efficiency. We also conduct ablation studies to quantify the contribution of each component to maintain accuracy and equivariance under quantization, using the Local error of equivariance (LEE) metric. The proposed techniques enable the deployment of symmetry-aware GNNs in practical chemistry applications with 2.37--2.73x faster inference and 4x smaller model size, without sacrificing accuracy or physical symmetry.

</details>


### [338] [ELLA: Efficient Lifelong Learning for Adapters in Large Language Models](https://arxiv.org/abs/2601.02232)
*Shristi Das Biswas,Yue Zhang,Anwesan Pal,Radhika Bhargava,Kaushik Roy*

Main category: cs.LG

TL;DR: ELLA是一个基于选择性子空间去相关原则的持续学习框架，通过惩罚任务特定方向的对齐来避免灾难性遗忘，同时保留低能量子空间的自由度以实现正向迁移。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在持续学习中的灾难性遗忘问题，现有方法存在局限性：基于回放的方法不实用且侵犯隐私，而严格正交方法会减少自由度并消除正向迁移。

Method: ELLA使用轻量级正则化器，通过选择性子空间去相关原则，惩罚高能量任务特定方向的对齐，同时保留低能量残差子空间的自由度。该方法无需数据回放、架构扩展，存储开销极小。

Result: 在三个流行基准测试中达到最先进的持续学习性能，相对准确率提升高达9.6%，内存占用减少35倍。该方法在不同架构上具有良好可扩展性，并能增强模型对未见任务的零样本泛化能力。

Conclusion: ELLA为大规模语言模型提供了原则性且可扩展的终身适应解决方案，通过选择性子空间去相关有效平衡了知识保留和正向迁移。

Abstract: Large Language Models (LLMs) suffer severe catastrophic forgetting when adapted sequentially to new tasks in a continual learning (CL) setting. Existing approaches are fundamentally limited: replay-based methods are impractical and privacy-violating, while strict orthogonality-based methods collapse under scale: each new task is projected onto an orthogonal complement, progressively reducing the residual degrees of freedom and eliminating forward transfer by forbidding overlap in shared representations. In this work, we introduce ELLA, a training framework built on the principle of selective subspace de-correlation. Rather than forbidding all overlap, ELLA explicitly characterizes the structure of past updates and penalizes alignments along their high-energy, task-specific directions, while preserving freedom in the low-energy residual subspaces to enable transfer. Formally, this is realized via a lightweight regularizer on a single aggregated update matrix. We prove this mechanism corresponds to an anisotropic shrinkage operator that bounds interference, yielding a penalty that is both memory- and compute-constant regardless of task sequence length. ELLA requires no data replay, no architectural expansion, and negligible storage. Empirically, it achieves state-of-the-art CL performance on three popular benchmarks, with relative accuracy gains of up to $9.6\%$ and a $35\times$ smaller memory footprint. Further, ELLA scales robustly across architectures and actively enhances the model's zero-shot generalization performance on unseen tasks, establishing a principled and scalable solution for constructive lifelong LLM adaptation.

</details>


### [339] [Neuro-Channel Networks: A Multiplication-Free Architecture by Biological Signal Transmission](https://arxiv.org/abs/2601.02253)
*Emrah Mete,Emin Erkan Korkmaz*

Main category: cs.LG

TL;DR: 本文提出Neuro-Channel Networks (NCN)，一种基于生物神经机制的无乘法神经网络架构，通过通道宽度和神经递质参数替代传统权重，仅使用加法、减法和位运算实现前向传播，旨在降低AI对高性能硬件的依赖。


<details>
  <summary>Details</summary>
Motivation: 深度学习对GPU等高性能硬件的依赖导致成本高、能耗大且供应稀缺，限制了AI在边缘设备的部署。生物神经系统的高效性启发了无乘法架构的设计。

Method: 用通道宽度限制信号幅度，神经递质参数基于符号逻辑调节信号传输。前向传播完全消除浮点乘法，仅使用加法、减法和位运算（最小值、符号）。

Result: NCN在概念验证中能100%准确解决XOR和多数函数等非线性可分问题，证明其无需乘法权重即可形成复杂决策边界。

Conclusion: NCN为下一代神经形态硬件提供了高效替代方案，有望在普通CPU或超低功耗芯片上运行复杂模型，摆脱对昂贵GPU集群的依赖。

Abstract: The rapid proliferation of Deep Learning is increasingly constrained by its heavy reliance on high-performance hardware, particularly Graphics Processing Units (GPUs). These specialized accelerators are not only prohibitively expensive and energy-intensive but also suffer from significant supply scarcity, limiting the ubiquity of Artificial Intelligence (AI) deployment on edge devices. The core of this inefficiency stems from the standard artificial perceptron's dependence on intensive matrix multiplications. However, biological nervous systems achieve unparalleled efficiency without such arithmetic intensity; synaptic signal transmission is regulated by physical ion channel limits and chemical neurotransmitter levels rather than a process that can be analogous to arithmetic multiplication. Inspired by this biological mechanism, we propose Neuro-Channel Networks (NCN), a novel multiplication-free architecture designed to decouple AI from expensive hardware dependencies. In our model, weights are replaced with Channel Widths that physically limit the signal magnitude, while a secondary parameter acts as a Neurotransmitter to regulate Signal Transmission based on sign logic. The forward pass relies exclusively on addition, subtraction, and bitwise operations (minimum, sign), eliminating floating-point multiplication entirely. In this proof-of-concept study, we demonstrate that NCNs can solve non-linearly separable problems like XOR and the Majority function with 100% accuracy using standard backpropagation, proving their capability to form complex decision boundaries without multiplicative weights. This architecture offers a highly efficient alternative for next-generation neuromorphic hardware, paving the way for running complex models on commodity CPUs or ultra-low-power chips without relying on costly GPU clusters.

</details>


### [340] [POSEIDON: Physics-Optimized Seismic Energy Inference and Detection Operating Network](https://arxiv.org/abs/2601.02264)
*Boris Kriuk,Fedor Kriuk*

Main category: cs.LG

TL;DR: POSEIDON是一个基于物理的能量模型，用于统一的多任务地震事件预测，结合了地震学原理作为可学习约束，在三个预测任务上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习方法通常作为黑盒运行，忽略了已建立的物理定律，地震预测和地震危险性评估仍然是地球物理学中的基本挑战。

Method: 引入POSEIDON模型，将Gutenberg-Richter震级-频率关系和Omori-Utsu余震衰减定律等基本地震学原理作为可学习约束嵌入到基于能量的建模框架中。

Result: 实验表明POSEIDON在所有任务上均达到最先进性能，平均F1得分最高，且学习到的物理参数收敛到科学可解释的值。

Conclusion: POSEIDON模型在保持预测准确性的同时增强了科学可解释性，Poseidon数据集为物理信息地震研究提供了重要资源。

Abstract: Earthquake prediction and seismic hazard assessment remain fundamental challenges in geophysics, with existing machine learning approaches often operating as black boxes that ignore established physical laws. We introduce POSEIDON (Physics-Optimized Seismic Energy Inference and Detection Operating Network), a physics-informed energy-based model for unified multi-task seismic event prediction, alongside the Poseidon dataset -- the largest open-source global earthquake catalog comprising 2.8 million events spanning 30 years. POSEIDON embeds fundamental seismological principles, including the Gutenberg-Richter magnitude-frequency relationship and Omori-Utsu aftershock decay law, as learnable constraints within an energy-based modeling framework. The architecture simultaneously addresses three interconnected prediction tasks: aftershock sequence identification, tsunami generation potential, and foreshock detection. Extensive experiments demonstrate that POSEIDON achieves state-of-the-art performance across all tasks, outperforming gradient boosting, random forest, and CNN baselines with the highest average F1 score among all compared methods. Crucially, the learned physics parameters converge to scientifically interpretable values -- Gutenberg-Richter b-value of 0.752 and Omori-Utsu parameters p=0.835, c=0.1948 days -- falling within established seismological ranges while enhancing rather than compromising predictive accuracy. The Poseidon dataset is publicly available at https://huggingface.co/datasets/BorisKriuk/Poseidon, providing pre-computed energy features, spatial grid indices, and standardized quality metrics to advance physics-informed seismic research.

</details>


### [341] [Differential Privacy for Transformer Embeddings of Text with Nonparametric Variational Information Bottleneck](https://arxiv.org/abs/2601.02307)
*Dina El Zein,James Henderson*

Main category: cs.LG

TL;DR: 提出了一种通过共享带噪声的transformer嵌入来保护隐私的文本数据共享方法，使用非参数变分差分隐私(NVDP)在隐私保护和数据效用之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 深度模型学习的隐藏表示可能编码输入中的敏感信息，特别是transformer嵌入包含每个token的多个向量，使得攻击者可能以相当高的准确率恢复输入数据。

Method: 将非参数变分信息瓶颈(NVIB)层集成到transformer架构中，向多向量嵌入注入噪声来隐藏信息，使用Rényi散度及其对应的贝叶斯差分隐私(BDP)保证来衡量隐私保护。

Result: 在GLUE基准测试中，通过调节噪声水平实现了隐私和准确性的有效权衡，较低噪声水平下模型保持高准确性同时提供强隐私保证。

Conclusion: NVDP方法能够有效平衡隐私保护和数据效用，为文本数据的安全共享提供了可行方案。

Abstract: We propose a privacy-preserving method for sharing text data by sharing noisy versions of their transformer embeddings. It has been shown that hidden representations learned by deep models can encode sensitive information from the input, making it possible for adversaries to recover the input data with considerable accuracy. This problem is exacerbated in transformer embeddings because they consist of multiple vectors, one per token. To mitigate this risk, we propose Nonparametric Variational Differential Privacy (NVDP), which ensures both useful data sharing and strong privacy protection. We take a differential privacy approach, integrating a Nonparametric Variational Information Bottleneck (NVIB) layer into the transformer architecture to inject noise into its multi-vector embeddings and thereby hide information, and measuring privacy protection with Rényi divergence and its corresponding Bayesian Differential Privacy (BDP) guarantee. Training the NVIB layer calibrates the noise level according to utility. We test NVDP on the GLUE benchmark and show that varying the noise level gives us a useful tradeoff between privacy and accuracy. With lower noise levels, our model maintains high accuracy while offering strong privacy guarantees, effectively balancing privacy and utility.

</details>


### [342] [Temporal Kolmogorov-Arnold Networks (T-KAN) for High-Frequency Limit Order Book Forecasting: Efficiency, Interpretability, and Alpha Decay](https://arxiv.org/abs/2601.02310)
*Ahmad Makinde*

Main category: cs.LG

TL;DR: 本文提出了Temporal Kolmogorov-Arnold Networks (T-KAN)模型，用于高频交易环境中的限价订单簿预测，相比传统DeepLOB模型在k=100时间窗口上F1分数提升了19.1%，并实现了132.48%的收益回报。


<details>
  <summary>Details</summary>
Motivation: 高频交易环境中的限价订单簿数据噪声大、非线性强，传统模型如DeepLOB随着时间窗口增大预测能力下降（alpha衰减问题），需要更有效的模型来捕捉市场信号的'形状'而不仅仅是幅度。

Method: 使用FI-2010数据集，用可学习的B样条激活函数替代标准LSTM的固定线性权重，构建T-KAN模型，该架构特别优化用于低延迟FPGA实现。

Result: 在k=100时间窗口上F1分数相对提升19.1%；在1.0基点交易成本下，T-KAN实现132.48%回报，而DeepLOB亏损82.76%；模型具有较好的可解释性，样条中的'死区'清晰可见。

Conclusion: T-KAN模型在高频限价订单簿预测中表现出色，不仅预测性能显著提升，还具有更好的可解释性和硬件优化潜力，为解决alpha衰减问题提供了有效方案。

Abstract: High-Frequency trading (HFT) environments are characterised by large volumes of limit order book (LOB) data, which is notoriously noisy and non-linear. Alpha decay represents a significant challenge, with traditional models such as DeepLOB losing predictive power as the time horizon (k) increases. In this paper, using data from the FI-2010 dataset, we introduce Temporal Kolmogorov-Arnold Networks (T-KAN) to replace the fixed, linear weights of standard LSTMs with learnable B-spline activation functions. This allows the model to learn the 'shape' of market signals as opposed to just their magnitude. This resulted in a 19.1% relative improvement in the F1-score at the k = 100 horizon. The efficacy of T-KAN networks cannot be understated, producing a 132.48% return compared to the -82.76% DeepLOB drawdown under 1.0 bps transaction costs. In addition to this, the T-KAN model proves quite interpretable, with the 'dead-zones' being clearly visible in the splines. The T-KAN architecture is also uniquely optimized for low-latency FPGA implementation via High level Synthesis (HLS). The code for the experiments in this project can be found at https://github.com/AhmadMak/Temporal-Kolmogorov-Arnold-Networks-T-KAN-for-High-Frequency-Limit-Order-Book-Forecasting.

</details>


### [343] [Game of Coding: Coding Theory in the Presence of Rational Adversaries, Motivated by Decentralized Machine Learning](https://arxiv.org/abs/2601.02313)
*Hanzaleh Akbari Nodehi,Viveck R. Cadambe,Mohammad Ali Maddah-Ali*

Main category: cs.LG

TL;DR: 本文提出了一种新的博弈论框架"编码博弈"，将编码理论扩展到信任最小化的去中心化系统中，特别针对理性对手而非纯粹恶意对手的场景。该框架能够在对手占多数的情况下实现非零概率的数据恢复，并具有Sybil抵抗性。


<details>
  <summary>Details</summary>
Motivation: 传统编码理论假设最坏情况下的对抗模型，要求诚实节点数量超过对手节点。但在去中心化机器学习等新兴应用中，激励机制导致对手行为更加理性而非纯粹恶意，需要新的编码方法。

Method: 引入博弈论框架"编码博弈"，重点关注重复编码策略，分析理性对手在去中心化系统中的战略行为。

Result: 该框架能够在对手占多数的情况下实现非零概率的数据恢复，且具有Sybil抵抗性（即使对手节点数量增加，均衡状态保持不变）。

Conclusion: 编码博弈为去中心化系统中的可靠计算提供了新思路，特别是在对手策略未知的情况下，为未来研究指明了方向。

Abstract: Coding theory plays a crucial role in enabling reliable communication, storage, and computation. Classical approaches assume a worst-case adversarial model and ensure error correction and data recovery only when the number of honest nodes exceeds the number of adversarial ones by some margin. However, in some emerging decentralized applications, particularly in decentralized machine learning (DeML), participating nodes are rewarded for accepted contributions. This incentive structure naturally gives rise to rational adversaries who act strategically rather than behaving in purely malicious ways.
  In this paper, we first motivate the need for coding in the presence of rational adversaries, particularly in the context of outsourced computation in decentralized systems. We contrast this need with existing approaches and highlight their limitations. We then introduce the game of coding, a novel game-theoretic framework that extends coding theory to trust-minimized settings where honest nodes are not in the majority. Focusing on repetition coding, we highlight two key features of this framework: (1) the ability to achieve a non-zero probability of data recovery even when adversarial nodes are in the majority, and (2) Sybil resistance, i.e., the equilibrium remains unchanged even as the number of adversarial nodes increases. Finally, we explore scenarios in which the adversary's strategy is unknown and outline several open problems for future research.

</details>


### [344] [DatBench: Discriminative, Faithful, and Efficient VLM Evaluations](https://arxiv.org/abs/2601.02316)
*Siddharth Joshi,Haoli Yin,Rishabh Adiga,Ricardo Monti,Aldo Carranza,Alex Fang,Alvin Deng,Amro Abbas,Brett Larsen,Cody Blakeney,Darren Teh,David Schwab,Fan Pan,Haakon Mongstad,Jack Urbanek,Jason Lee,Jason Telanoff,Josh Wills,Kaleigh Mentzer,Luke Merrick,Parth Doshi,Paul Burstein,Pratyush Maini,Scott Loftin,Spandan Das,Tony Jiang,Vineeth Dorna,Zhengping Wang,Bogdan Gaza,Ari Morcos,Matthew Leavitt*

Main category: cs.LG

TL;DR: 本文提出了评估视觉语言模型的三个标准：忠实性、可区分性和效率，并发现了现有评估中的关键问题，通过数据清理和转换创建了更高效、准确的评估套件DatBench。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型的评估方法尚不成熟，存在忠实性不足、区分能力差和计算效率低等问题，需要建立更严谨和可持续的评估体系。

Method: 通过识别现有评估中的问题（如多选题格式、可盲答问题和错误标注样本），对基准数据集进行转换和过滤，创建了DatBench评估套件。

Result: 将多选题转换为生成任务可使能力下降高达35%，过滤问题样本可提高区分能力并降低计算成本，DatBench实现了13倍平均加速。

Conclusion: 通过改进评估方法，可以建立更严谨、高效的视觉语言模型评估体系，为模型发展提供可靠指导。

Abstract: Empirical evaluation serves as the primary compass guiding research progress in foundation models. Despite a large body of work focused on training frontier vision-language models (VLMs), approaches to their evaluation remain nascent. To guide their maturation, we propose three desiderata that evaluations should satisfy: (1) faithfulness to the modality and application, (2) discriminability between models of varying quality, and (3) efficiency in compute. Through this lens, we identify critical failure modes that violate faithfulness and discriminability, misrepresenting model capabilities: (i) multiple-choice formats reward guessing, poorly reflect downstream use cases, and saturate early as models improve; (ii) blindly solvable questions, which can be answered without images, constitute up to 70% of some evaluations; and (iii) mislabeled or ambiguous samples compromise up to 42% of examples in certain datasets. Regarding efficiency, the computational burden of evaluating frontier models has become prohibitive: by some accounts, nearly 20% of development compute is devoted to evaluation alone. Rather than discarding existing benchmarks, we curate them via transformation and filtering to maximize fidelity and discriminability. We find that converting multiple-choice questions to generative tasks reveals sharp capability drops of up to 35%. In addition, filtering blindly solvable and mislabeled samples improves discriminative power while simultaneously reducing computational cost. We release DatBench-Full, a cleaned evaluation suite of 33 datasets spanning nine VLM capabilities, and DatBench, a discriminative subset that achieves 13x average speedup (up to 50x) while closely matching the discriminative power of the original datasets. Our work outlines a path toward evaluation practices that are both rigorous and sustainable as VLMs continue to scale.

</details>


### [345] [Heterogeneous Low-Bandwidth Pre-Training of LLMs](https://arxiv.org/abs/2601.02360)
*Yazan Obeidi,Amir Sarfi,Joel Lidin,Paul Janson,Eugene Belilovsky*

Main category: cs.LG

TL;DR: SparseLoCo（低通信数据并行方法）与低带宽管道模型并行相结合，通过激活和激活梯度压缩，研究异构分布式训练框架，以解决LLM预训练中的带宽限制问题。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型预训练需要分布式计算，但带宽限制使得在资源受限的环境中难以扩展，特别是在模型并行需要频繁、大规模设备间通信时。

Method: 提出异构分布式训练框架：高带宽互连的参与者托管完整副本，资源受限的参与者通过管道并行联合实例化副本，使用子空间投影的级间通信。将子空间管道压缩与SparseLoCo适配，研究选择性（异构）压缩。

Result: 在大型语言建模实验（178M-1B参数）中，激活压缩与SparseLoCo组合成本适中，选择性压缩在激进压缩比下 consistently 改善损失-通信权衡。

Conclusion: 这些结果为将低带宽模型并行和异构参与者纳入LLM预训练提供了实用路径。

Abstract: Pre-training large language models (LLMs) increasingly requires distributed compute, yet bandwidth constraints make it difficult to scale beyond well-provisioned datacenters-especially when model parallelism forces frequent, large inter-device communications. We study whether SparseLoCo, a low-communication data parallel method based on infrequent synchronization and sparse pseudo-gradient exchange, can be combined with low-bandwidth pipeline model parallelism via activation and activation-gradient compression. We introduce a heterogeneous distributed training framework where some participants host full replicas on high-bandwidth interconnects, while resource-limited participants are grouped to jointly instantiate a replica using pipeline parallelism with subspace-projected inter-stage communication. To make the recently introduced subspace pipeline compression compatible with SparseLoCo, we study a number of adaptations. Across large-scale language modeling experiments (178M-1B parameters) on standard pretraining corpora, we find that activation compression composes with SparseLoCo at modest cost, while selective (heterogeneous) compression consistently improves the loss-communication tradeoff relative to compressing all replicas-especially at aggressive compression ratios. These results suggest a practical path to incorporating low-bandwidth model parallelism and heterogeneous participants into LLM pre-training.

</details>
