<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 79]
- [cs.RO](#cs.RO) [Total: 19]
- [cs.LG](#cs.LG) [Total: 78]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Beyond Binary Preference: Aligning Diffusion Models to Fine-grained Criteria by Decoupling Attributes](https://arxiv.org/abs/2601.04300)
*Chenye Meng,Zejian Li,Zhongni Liu,Yize Li,Changle Xie,Kaixin Jia,Ling Yang,Huanghuang Deng,Shiying Ding,Shengyuan Zhang,Jiayi Li,Lingyun Sun*

Main category: cs.CV

TL;DR: 本文提出了一种针对扩散模型的两阶段对齐框架，通过构建层次化细粒度评估标准和复杂偏好优化（CPO）方法，解决了传统对齐方法无法处理复杂人类专业知识的问题


<details>
  <summary>Details</summary>
Motivation: 传统扩散模型对齐方法依赖简化信号（如标量奖励或二元偏好），无法有效对齐具有层次化和细粒度特征的复杂人类专业知识

Method: 1. 与领域专家合作构建层次化细粒度评估标准，将图像质量分解为多个正负属性组成的树状结构；2. 提出两阶段对齐框架：首先通过监督微调将领域知识注入辅助扩散模型，然后提出CPO方法将DPO扩展到非二元层次化标准对齐

Result: 在绘画生成领域的实验表明，CPO显著提升了生成质量和与专业知识的对齐程度

Conclusion: 该方法为细粒度标准对齐开辟了新途径，能够有效处理复杂的人类专业知识

Abstract: Post-training alignment of diffusion models relies on simplified signals, such as scalar rewards or binary preferences. This limits alignment with complex human expertise, which is hierarchical and fine-grained. To address this, we first construct a hierarchical, fine-grained evaluation criteria with domain experts, which decomposes image quality into multiple positive and negative attributes organized in a tree structure. Building on this, we propose a two-stage alignment framework. First, we inject domain knowledge to an auxiliary diffusion model via Supervised Fine-Tuning. Second, we introduce Complex Preference Optimization (CPO) that extends DPO to align the target diffusion to our non-binary, hierarchical criteria. Specifically, we reformulate the alignment problem to simultaneously maximize the probability of positive attributes while minimizing the probability of negative attributes with the auxiliary diffusion. We instantiate our approach in the domain of painting generation and conduct CPO training with an annotated dataset of painting with fine-grained attributes based on our criteria. Extensive experiments demonstrate that CPO significantly enhances generation quality and alignment with expertise, opening new avenues for fine-grained criteria alignment.

</details>


### [2] [Embedding Textual Information in Images Using Quinary Pixel Combinations](https://arxiv.org/abs/2601.04302)
*A V Uday Kiran Kandala*

Main category: cs.CV

TL;DR: 提出一种基于RGB空间五进制像素强度组合的文本嵌入图像新方法，相比传统LSB等方法在单像素内实现完整字符编码，计算效率更高且图像失真小


<details>
  <summary>Details</summary>
Motivation: 现有文本嵌入方法（如LSB、PVD、深度学习方法）存在像素翻转噪声、计算复杂度高、需要多像素编码等问题，需要更高效且低失真的嵌入技术

Method: 在RGB空间使用五进制像素强度组合（每个通道5种强度变化，共125种组合），将组合映射到文本符号（字母、数字、空格、特殊字符），实现单像素完整字符编码

Result: 通过MSE、MAE、SNR、PSNR、SSIM、直方图比较和热图分析评估，编码图像无明显失真，嵌入效率显著提升

Conclusion: 该方法在单像素内实现文本嵌入，相比传统方法具有更高的嵌入效率和更低的计算复杂度，同时保持图像质量

Abstract: This paper presents a novel technique for embedding textual data into images using quinary combinations of pixel intensities in RGB space. Existing methods predominantly rely on least and most significant bit (LSB & MSB) manipulation, Pixel Value Differencing (PVD), spatial perturbations in RGB channels, transform domain based methods, Quantization methods, Edge and Region based methods and more recently through deep learning methods and generative AI techniques for hiding textual information in spatial domain of images. Most of them are dependent on pixel intensity flipping over multiple pixels, such as LSB and combination of LSB based methodologies, and on transform coefficients, often resulting in the form of noise. Encoding and Decoding are deterministic in most of the existing approaches and are computationally heavy in case of higher models such as deep learning and gen AI approaches. The proposed method works on quinary pixel intensity combinations in RGB space, where five controlled different pixel intensity variations in each of the R, G, and B channels formulate up to one hundred and twenty five distinct pixel intensity combinations. These combinations are mapped to textual symbols, enabling the representation of uppercase and lowercase alphabetic characters, numeric digits, whitespace, and commonly used special characters. Different metrics such as MSE, MAE, SNR, PSNR, SSIM, Histogram Comparison and Heatmap analysis, were evaluated for both original and encoded images resulting in no significant distortion in the images. Furthermore, the method achieves improved embedding efficiency by encoding a complete textual symbol within a single RGB pixel, in contrast to LSB and MSB based approaches that typically require multiple pixels or multi-step processes, as well as transform and learning based methods that incur higher computational overhead.

</details>


### [3] [Unified Text-Image Generation with Weakness-Targeted Post-Training](https://arxiv.org/abs/2601.04339)
*Jiahui Chen,Philippe Hansen-Estruch,Xiaochuang Han,Yushi Hu,Emily Dinan,Amita Kamath,Michal Drozdzal,Reyhane Askari-Hemmat,Luke Zettlemoyer,Marjan Ghazvininejad*

Main category: cs.CV

TL;DR: 本文提出了一种通过后训练实现完全统一的文本-图像生成方法，使模型能够在单一推理过程中自主从文本推理过渡到视觉合成，解决了现有系统需要显式模态切换的问题。


<details>
  <summary>Details</summary>
Motivation: 现有统一多模态生成架构依赖显式模态切换，需要先生成推理文本再手动切换到图像生成，这种分离的序列推理过程限制了跨模态耦合，无法实现自动多模态生成。

Method: 采用离线、奖励加权的后训练方法，使用完全自生成的合成数据，探索不同的后训练数据策略，特别设计了针对特定局限性的目标数据集。

Result: 在四个不同的T2I基准测试中，该方法在跨模态图像生成方面取得了改进，证明了奖励加权两种模态和战略性设计的后训练数据的有效性。

Conclusion: 通过后训练实现完全统一的文本-图像生成是可行的，且目标数据集策略比广泛的图像-标题语料库或基准对齐数据效果更好，为多模态生成提供了新的研究方向。

Abstract: Unified multimodal generation architectures that jointly produce text and images have recently emerged as a promising direction for text-to-image (T2I) synthesis. However, many existing systems rely on explicit modality switching, generating reasoning text before switching manually to image generation. This separate, sequential inference process limits cross-modal coupling and prohibits automatic multimodal generation. This work explores post-training to achieve fully unified text-image generation, where models autonomously transition from textual reasoning to visual synthesis within a single inference process. We examine the impact of joint text-image generation on T2I performance and the relative importance of each modality during post-training. We additionally explore different post-training data strategies, showing that a targeted dataset addressing specific limitations achieves superior results compared to broad image-caption corpora or benchmark-aligned data. Using offline, reward-weighted post-training with fully self-generated synthetic data, our approach enables improvements in multimodal image generation across four diverse T2I benchmarks, demonstrating the effectiveness of reward-weighting both modalities and strategically designed post-training data.

</details>


### [4] [ReHyAt: Recurrent Hybrid Attention for Video Diffusion Transformers](https://arxiv.org/abs/2601.04342)
*Mohsen Ghafoorian,Amirhossein Habibian*

Main category: cs.CV

TL;DR: ReHyAt是一种基于循环混合注意力的视频生成模型，通过结合softmax注意力的保真度和线性注意力的效率，实现了线性复杂度注意力机制，显著降低了训练成本。


<details>
  <summary>Details</summary>
Motivation: 解决现有视频扩散模型中基于transformer架构的二次方注意力复杂度问题，该问题限制了模型在长序列上的可扩展性。

Method: 提出循环混合注意力机制（ReHyAt），结合softmax注意力和线性注意力，实现分块循环重构和恒定内存使用，支持从现有softmax模型进行高效蒸馏。

Result: 在VBench和VBench-2.0基准测试以及人类偏好研究中，ReHyAt实现了最先进的视频质量，同时将注意力成本从二次方降低到线性，训练成本降低两个数量级至约160 GPU小时。

Conclusion: ReHyAt为未来基于双向softmax的先进模型提供了一种轻量级蒸馏和微调方案，解锁了长时视频生成和边缘设备视频生成的实用可扩展性。

Abstract: Recent advances in video diffusion models have shifted towards transformer-based architectures, achieving state-of-the-art video generation but at the cost of quadratic attention complexity, which severely limits scalability for longer sequences. We introduce ReHyAt, a Recurrent Hybrid Attention mechanism that combines the fidelity of softmax attention with the efficiency of linear attention, enabling chunk-wise recurrent reformulation and constant memory usage. Unlike the concurrent linear-only SANA Video, ReHyAt's hybrid design allows efficient distillation from existing softmax-based models, reducing the training cost by two orders of magnitude to ~160 GPU hours, while being competitive in the quality. Our light-weight distillation and finetuning pipeline provides a recipe that can be applied to future state-of-the-art bidirectional softmax-based models. Experiments on VBench and VBench-2.0, as well as a human preference study, demonstrate that ReHyAt achieves state-of-the-art video quality while reducing attention cost from quadratic to linear, unlocking practical scalability for long-duration and on-device video generation. Project page is available at https://qualcomm-ai-research.github.io/rehyat.

</details>


### [5] [SCAR-GS: Spatial Context Attention for Residuals in Progressive Gaussian Splatting](https://arxiv.org/abs/2601.04348)
*Diego Revilla,Pooja Suresh,Anand Bhojan,Ooi Wei Tsang*

Main category: cs.CV

TL;DR: 提出一种基于残差向量量化的新型渐进式3D高斯泼溅编解码器，通过多分辨率哈希网格引导的自回归熵模型提高压缩效率


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯泼溅模型存储需求大，阻碍云服务和流媒体部署；标量量化方法无法有效捕捉高维特征向量的相关性，限制了率失真性能

Method: 使用残差向量量化替代传统方法压缩原始特征，构建多分辨率哈希网格引导的自回归熵模型来预测传输索引的条件概率

Result: 实现了粗粒度和细化层的高效压缩，提升了压缩效率

Conclusion: 该方法为3D高斯泼溅模型提供了更有效的渐进式压缩方案，解决了存储和传输瓶颈问题

Abstract: Recent advances in 3D Gaussian Splatting have allowed for real-time, high-fidelity novel view synthesis. Nonetheless, these models have significant storage requirements for large and medium-sized scenes, hindering their deployment over cloud and streaming services. Some of the most recent progressive compression techniques for these models rely on progressive masking and scalar quantization techniques to reduce the bitrate of Gaussian attributes using spatial context models. While effective, scalar quantization may not optimally capture the correlations of high-dimensional feature vectors, which can potentially limit the rate-distortion performance.
  In this work, we introduce a novel progressive codec for 3D Gaussian Splatting that replaces traditional methods with a more powerful Residual Vector Quantization approach to compress the primitive features. Our key contribution is an auto-regressive entropy model, guided by a multi-resolution hash grid, that accurately predicts the conditional probability of each successive transmitted index, allowing for coarse and refinement layers to be compressed with high efficiency.

</details>


### [6] [Comparative Analysis of Custom CNN Architectures versus Pre-trained Models and Transfer Learning: A Study on Five Bangladesh Datasets](https://arxiv.org/abs/2601.04352)
*Ibrahim Tanvir,Alif Ruslan,Sartaj Solaiman*

Main category: cs.CV

TL;DR: 该研究比较了自定义CNN与预训练模型（ResNet-18和VGG-16）在孟加拉国五个图像分类数据集上的表现，发现微调迁移学习始终优于自定义CNN和特征提取方法，准确率提升3%-76%。


<details>
  <summary>Details</summary>
Motivation: 为从业者提供基于数据集特征、计算资源和性能要求选择合适深度学习方法的实用指导，特别是在训练数据有限的情况下。

Method: 使用特征提取和迁移学习两种方法，在五个孟加拉国图像分类数据集上比较自定义CNN与预训练模型（ResNet-18、VGG-16）的性能。

Result: 迁移学习微调方法在所有数据集上表现最佳，ResNet-18微调在道路损伤检测数据集上达到100%准确率。自定义CNN在模型大小和训练效率上有优势，但预训练模型在复杂分类任务上性能更优。

Conclusion: 预训练模型结合迁移学习在图像分类任务中性能更优越，特别是对于复杂任务和有限训练数据的情况；自定义CNN在简单任务和资源受限环境下具有实用价值。

Abstract: This study presents a comprehensive comparative analysis of custom-built Convolutional Neural Networks (CNNs) against popular pre-trained architectures (ResNet-18 and VGG-16) using both feature extraction and transfer learning approaches. We evaluated these models across five diverse image classification datasets from Bangladesh: Footpath Vision, Auto Rickshaw Detection, Mango Image Classification, Paddy Variety Recognition, and Road Damage Detection. Our experimental results demonstrate that transfer learning with fine-tuning consistently outperforms both custom CNNs built from scratch and feature extraction methods, achieving accuracy improvements ranging from 3% to 76% across different datasets. Notably, ResNet-18 with fine-tuning achieved perfect 100% accuracy on the Road Damage BD dataset. While custom CNNs offer advantages in model size (3.4M parameters vs. 11-134M for pre-trained models) and training efficiency on simpler tasks, pre-trained models with transfer learning provide superior performance, particularly on complex classification tasks with limited training data. This research provides practical insights for practitioners in selecting appropriate deep learning approaches based on dataset characteristics, computational resources, and performance requirements.

</details>


### [7] [PackCache: A Training-Free Acceleration Method for Unified Autoregressive Video Generation via Compact KV-Cache](https://arxiv.org/abs/2601.04359)
*Kunyang Li,Mubarak Shah,Yuzhang Shang*

Main category: cs.CV

TL;DR: PackCache是一种无需训练的KV缓存管理方法，通过动态压缩缓存来提升统一自回归视频生成的效率，在48帧长序列上实现1.7-2.2倍加速。


<details>
  <summary>Details</summary>
Motivation: 统一自回归模型的KV缓存大小随生成令牌数线性增长，成为限制推理效率和生成长度的主要瓶颈，特别是在视频生成任务中。

Method: PackCache通过三个协调机制动态压缩KV缓存：条件锚定保留语义参考、跨帧衰减建模根据时间距离分配缓存预算、空间保持位置嵌入在缓存移除时维持连贯的3D结构。

Result: 在48帧长序列上，PackCache将端到端生成加速1.7-2.2倍，最后四帧（受KV缓存扩展影响最大的部分）在A40和H200上分别实现2.6倍和3.7倍加速。

Conclusion: PackCache通过有效管理KV缓存，显著提升了统一自回归视频生成的效率，展示了在长序列视频生成中的强大潜力。

Abstract: A unified autoregressive model is a Transformer-based framework that addresses diverse multimodal tasks (e.g., text, image, video) as a single sequence modeling problem under a shared token space. Such models rely on the KV-cache mechanism to reduce attention computation from O(T^2) to O(T); however, KV-cache size grows linearly with the number of generated tokens, and it rapidly becomes the dominant bottleneck limiting inference efficiency and generative length. Unified autoregressive video generation inherits this limitation. Our analysis reveals that KV-cache tokens exhibit distinct spatiotemporal properties: (i) text and conditioning-image tokens act as persistent semantic anchors that consistently receive high attention, and (ii) attention to previous frames naturally decays with temporal distance. Leveraging these observations, we introduce PackCache, a training-free KV-cache management method that dynamically compacts the KV cache through three coordinated mechanisms: condition anchoring that preserves semantic references, cross-frame decay modeling that allocates cache budget according to temporal distance, and spatially preserving position embedding that maintains coherent 3D structure under cache removal. In terms of efficiency, PackCache accelerates end-to-end generation by 1.7-2.2x on 48-frame long sequences, showcasing its strong potential for enabling longer-sequence video generation. Notably, the final four frames - the portion most impacted by the progressively expanding KV-cache and thus the most expensive segment of the clip - PackCache delivers a 2.6x and 3.7x acceleration on A40 and H200, respectively, for 48-frame videos.

</details>


### [8] [Combining facial videos and biosignals for stress estimation during driving](https://arxiv.org/abs/2601.04376)
*Paraskevi Valergaki,Vassilis C. Nicodemou,Iason Oikonomidis,Antonis Argyros,Anastasios Roussos*

Main category: cs.CV

TL;DR: 本文提出了一种基于3D面部几何和生理信号的跨模态注意力融合方法，用于驾驶压力识别，通过Transformer时序建模实现了92%的AUROC和86.7%的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有压力识别方法主要依赖面部动作单元，但解耦的3D面部几何在压力识别中的作用尚未充分探索。压力的主观性和面部自主控制使得可靠识别具有挑战性。

Method: 使用EMOCA提取的3D表情和姿态系数分析分心驾驶中的压力，提出基于Transformer的时序建模框架，评估单模态、早期融合和跨模态注意力融合策略。

Result: 41/56个系数在基线和压力阶段显示一致的压力响应；跨模态注意力融合（EMOCA+生理信号）达到最佳性能（AUROC 92%，准确率86.7%）。

Conclusion: 时序建模和跨模态注意力融合在压力识别中具有显著效果，3D面部几何为压力识别提供了可靠线索。

Abstract: Reliable stress recognition from facial videos is challenging due to stress's subjective nature and voluntary facial control. While most methods rely on Facial Action Units, the role of disentangled 3D facial geometry remains underexplored. We address this by analyzing stress during distracted driving using EMOCA-derived 3D expression and pose coefficients. Paired hypothesis tests between baseline and stressor phases reveal that 41 of 56 coefficients show consistent, phase-specific stress responses comparable to physiological markers. Building on this, we propose a Transformer-based temporal modeling framework and assess unimodal, early-fusion, and cross-modal attention strategies. Cross-Modal Attention fusion of EMOCA and physiological signals achieves best performance (AUROC 92\%, Accuracy 86.7\%), with EMOCA-gaze fusion also competitive (AUROC 91.8\%). This highlights the effectiveness of temporal modeling and cross-modal attention for stress recognition.

</details>


### [9] [Few-Shot LoRA Adaptation of a Flow-Matching Foundation Model for Cross-Spectral Object Detection](https://arxiv.org/abs/2601.04381)
*Maxim Clouser,Kia Khezeli,John Kalantari*

Main category: cs.CV

TL;DR: 该研究探索了如何通过少量配对样本，将基于RGB图像预训练的流匹配基础模型（FLUX.1 Kontext）适配为跨光谱翻译器，用于生成红外（IR）和合成孔径雷达（SAR）图像，并验证合成数据对下游目标检测任务的提升效果。


<details>
  <summary>Details</summary>
Motivation: 当前视觉基础模型主要基于RGB数据训练，但安全关键应用（如红外和雷达）依赖非可见光模态。研究旨在利用少量配对样本，实现RGB到IR/SAR的跨模态翻译，并验证合成数据能否增强目标检测性能。

Method: 基于FLUX.1 Kontext模型，插入LoRA模块，仅使用每个域100张配对图像进行微调，实现RGB到IR（KAIST数据集）和RGB到SAR（M4-SAR数据集）的像素对齐翻译。通过LPIPS指标选择最佳LoRA适配器，并利用合成数据训练目标检测模型（YOLOv11n和DETR）。

Result: LPIPS指标能有效预测下游检测性能（低LPIPS对应高mAP）。合成IR数据提升了KAIST数据集的行人检测效果，合成SAR数据结合少量真实SAR显著提升了M4-SAR的基础设施检测性能。

Conclusion: 少量样本的LoRA适配流匹配基础模型是实现非可见光模态基础模型支持的有效路径，合成数据能显著增强下游检测任务。

Abstract: Foundation models for vision are predominantly trained on RGB data, while many safety-critical applications rely on non-visible modalities such as infrared (IR) and synthetic aperture radar (SAR). We study whether a single flow-matching foundation model pre-trained primarily on RGB images can be repurposed as a cross-spectral translator using only a few co-measured examples, and whether the resulting synthetic data can enhance downstream detection. Starting from FLUX.1 Kontext, we insert low-rank adaptation (LoRA) modules and fine-tune them on just 100 paired images per domain for two settings: RGB to IR on the KAIST dataset and RGB to SAR on the M4-SAR dataset. The adapted model translates RGB images into pixel-aligned IR/SAR, enabling us to reuse existing bounding boxes and train object detection models purely in the target modality. Across a grid of LoRA hyperparameters, we find that LPIPS computed on only 50 held-out pairs is a strong proxy for downstream performance: lower LPIPS consistently predicts higher mAP for YOLOv11n on both IR and SAR, and for DETR on KAIST IR test data. Using the best LPIPS-selected LoRA adapter, synthetic IR from external RGB datasets (LLVIP, FLIR ADAS) improves KAIST IR pedestrian detection, and synthetic SAR significantly boosts infrastructure detection on M4-SAR when combined with limited real SAR. Our results suggest that few-shot LoRA adaptation of flow-matching foundation models is a promising path toward foundation-style support for non-visible modalities.

</details>


### [10] [Performance Analysis of Image Classification on Bangladeshi Datasets](https://arxiv.org/abs/2601.04397)
*Mohammed Sami Khan,Fabiha Muniat,Rowzatul Zannat*

Main category: cs.CV

TL;DR: 比较自定义CNN与预训练架构（VGG-16、ResNet-50、MobileNet）在图像分类任务中的性能表现，发现预训练模型在准确性和收敛速度上更优，但自定义CNN在计算效率方面具有优势


<details>
  <summary>Details</summary>
Motivation: 解决在图像分类任务中，选择自定义CNN还是预训练架构这一重要实际问题，分析不同方法在性能、复杂度和计算效率方面的权衡

Method: 设计自定义CNN并从头训练，同时使用迁移学习在相同实验设置下应用VGG-16、ResNet-50和MobileNet等预训练架构，使用准确率、精确率、召回率和F1分数等标准指标进行评估

Result: 预训练CNN架构在分类准确率和收敛速度上始终优于自定义CNN，特别是在训练数据有限时；但自定义CNN在参数数量和计算复杂度方面显著更低，表现出竞争性性能

Conclusion: 研究揭示了模型复杂度、性能和计算效率之间的权衡关系，为图像分类问题选择合适的CNN架构提供了实用指导

Abstract: Convolutional Neural Networks (CNNs) have demonstrated remarkable success in image classification tasks; however, the choice between designing a custom CNN from scratch and employing established pre-trained architectures remains an important practical consideration. In this work, we present a comparative analysis of a custom-designed CNN and several widely used deep learning architectures, including VGG-16, ResNet-50, and MobileNet, for an image classification task. The custom CNN is developed and trained from scratch, while the popular architectures are employed using transfer learning under identical experimental settings. All models are evaluated using standard performance metrics such as accuracy, precision, recall, and F1-score. Experimental results show that pre-trained CNN architectures consistently outperform the custom CNN in terms of classification accuracy and convergence speed, particularly when training data is limited. However, the custom CNN demonstrates competitive performance with significantly fewer parameters and reduced computational complexity. This study highlights the trade-offs between model complexity, performance, and computational efficiency, and provides practical insights into selecting appropriate CNN architectures for image classification problems.

</details>


### [11] [3D-Agent:Tri-Modal Multi-Agent Collaboration for Scalable 3D Object Annotation](https://arxiv.org/abs/2601.04404)
*Jusheng Zhang,Yijia Fan,Zimo Wen,Jian Wang,Keze Wang*

Main category: cs.CV

TL;DR: Tri MARF是一个基于三模态输入的多智能体协作框架，通过整合2D多视角图像、文本描述和3D点云，显著提升大规模3D物体标注的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 3D物体标注在自动驾驶、机器人和增强现实等领域具有重要应用价值，但面临空间复杂性、遮挡和视角不一致等挑战。现有单模型方法难以有效解决这些问题。

Method: Tri MARF包含三个专门智能体：视觉语言模型智能体生成多视角描述，信息聚合智能体选择最优描述，门控智能体将文本语义与3D几何对齐进行精细化标注。

Result: 在Objaverse、LVIS、Objaverse XL和ABO数据集上的实验表明，Tri MARF显著优于现有方法，CLIPScore达到88.7，检索准确率分别达到45.2和43.8，在单张NVIDIA A100 GPU上每小时可处理12000个物体。

Conclusion: Tri MARF通过多模态协作架构有效解决了3D标注的复杂挑战，为大规模3D物体标注提供了高效准确的解决方案。

Abstract: Driven by applications in autonomous driving robotics and augmented reality 3D object annotation presents challenges beyond 2D annotation including spatial complexity occlusion and viewpoint inconsistency Existing approaches based on single models often struggle to address these issues effectively We propose Tri MARF a novel framework that integrates tri modal inputs including 2D multi view images textual descriptions and 3D point clouds within a multi agent collaborative architecture to enhance large scale 3D annotation Tri MARF consists of three specialized agents a vision language model agent for generating multi view descriptions an information aggregation agent for selecting optimal descriptions and a gating agent that aligns textual semantics with 3D geometry for refined captioning Extensive experiments on Objaverse LVIS Objaverse XL and ABO demonstrate that Tri MARF substantially outperforms existing methods achieving a CLIPScore of 88 point 7 compared to prior state of the art methods retrieval accuracy of 45 point 2 and 43 point 8 on ViLT R at 5 and a throughput of up to 12000 objects per hour on a single NVIDIA A100 GPU

</details>


### [12] [From Preoperative CT to Postmastoidectomy Mesh Construction:1Mastoidectomy Shape Prediction for Cochlear Implant Surgery](https://arxiv.org/abs/2601.04405)
*Yike Zhang,Eduardo Davalos,Dingjie Su,Ange Lou,Jack Noble*

Main category: cs.CV

TL;DR: 该论文提出了一种结合自监督和弱监督学习的混合框架，用于从术前CT扫描中预测乳突切除术区域，无需人工标注，为人工耳蜗植入手术规划提供高效解决方案。


<details>
  <summary>Details</summary>
Motivation: 人工耳蜗植入手术中，乳突切除术是重要步骤，但现有基于深度学习的相关研究有限，主要挑战在于获取真实标注数据困难。

Method: 提出混合自监督和弱监督学习框架，直接从术前CT扫描预测乳突切除术区域，使用3D T分布损失进行弱监督医学影像分析。

Result: 该方法在预测复杂无边界乳突切除术形状时达到平均Dice分数0.72，优于现有最先进方法。

Conclusion: 这是首个将自监督和弱监督学习结合用于乳突切除术形状预测的工作，为从术前CT扫描构建3D术后表面提供了基础，具有临床应用价值。

Abstract: Cochlear Implant (CI) surgery treats severe hearing loss by inserting an electrode array into the cochlea to stimulate the auditory nerve. An important step in this procedure is mastoidectomy, which removes part of the mastoid region of the temporal bone to provide surgical access. Accurate mastoidectomy shape prediction from preoperative imaging improves pre-surgical planning, reduces risks, and enhances surgical outcomes. Despite its importance, there are limited deep-learning-based studies regarding this topic due to the challenges of acquiring ground-truth labels. We address this gap by investigating self-supervised and weakly-supervised learning models to predict the mastoidectomy region without human annotations. We propose a hybrid self-supervised and weakly-supervised learning framework to predict the mastoidectomy region directly from preoperative CT scans, where the mastoid remains intact. Our hybrid method achieves a mean Dice score of 0.72 when predicting the complex and boundary-less mastoidectomy shape, surpassing state-of-the-art approaches and demonstrating strong performance. The method provides groundwork for constructing 3D postmastoidectomy surfaces directly from the corresponding preoperative CT scans. To our knowledge, this is the first work that integrating self-supervised and weakly-supervised learning for mastoidectomy shape prediction, offering a robust and efficient solution for CI surgical planning while leveraging 3D T-distribution loss in weakly-supervised medical imaging.

</details>


### [13] [CRUNet-MR-Univ: A Foundation Model for Diverse Cardiac MRI Reconstruction](https://arxiv.org/abs/2601.04428)
*Donghang Lyu,Marius Staring,Hildo Lamb,Mariya Doneva*

Main category: cs.CV

TL;DR: 本文提出CRUNet-MR-Univ基础模型，利用时空相关性和提示先验来处理心脏MRI重建中的多样性问题，在多种设置下优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 深度学习在心脏MRI重建中表现出色，但现有方法泛化能力有限，无法处理图像对比度、采样模式、扫描仪厂商、解剖结构和疾病类型等多样性问题。

Method: 提出CRUNet-MR-Univ基础模型，通过利用时空相关性和提示先验来应对CMR扫描的全面多样性。

Result: 该方法在广泛设置下一致优于基线方法。

Conclusion: CRUNet-MR-Univ模型展示了处理多样化CMR场景的有效性和前景。

Abstract: In recent years, deep learning has attracted increasing at- tention in the field of Cardiac MRI (CMR) reconstruction due to its superior performance over traditional methods, particularly in handling higher acceleration factors, highlighting its potential for real-world clini- cal applications. However, current deep learning methods remain limited in generalizability. CMR scans exhibit wide variability in image contrast, sampling patterns, scanner vendors, anatomical structures, and disease types. Most existing models are designed to handle only a single or nar- row subset of these variations, leading to performance degradation when faced with distribution shifts. Therefore, it is beneficial to develop a unified model capable of generalizing across diverse CMR scenarios. To this end, we propose CRUNet-MR-Univ, a foundation model that lever- ages spatio-temporal correlations and prompt-based priors to effectively handle the full diversity of CMR scans. Our approach consistently out- performs baseline methods across a wide range of settings, highlighting its effectiveness and promise.

</details>


### [14] [Addressing Overthinking in Large Vision-Language Models via Gated Perception-Reasoning Optimization](https://arxiv.org/abs/2601.04442)
*Xingjian Diao,Zheyuan Liu,Chunhui Zhang,Weiyi Wu,Keyi Kong,Lin Shi,Kaize Ding,Soroush Vosoughi,Jiang Gui*

Main category: cs.CV

TL;DR: 论文提出GPRO方法，通过动态路由计算路径来解决大型视觉语言模型在链式思考中出现的过度思考问题，同时提升准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型采用链式思考机制时会产生过度思考，导致响应冗长、效率低下甚至准确率下降。现有方法主要忽视了视觉感知失败这一根本瓶颈。

Method: 提出GPRO（门控感知-推理优化）元推理控制器，在每个生成步骤动态选择三种计算路径：轻量快速路径、重新检查视觉输入的慢感知路径、进行内部自省的慢推理路径。通过从79万样本中获取失败归因监督，使用多目标强化学习训练控制器。

Result: 在五个基准测试上的实验表明，GPRO显著提高了准确性和效率，优于最近的慢思考方法，同时生成更短的响应。

Conclusion: GPRO通过动态计算路由有效解决了视觉语言模型的过度思考问题，证明了稳定推理依赖于低层视觉基础，推理错误往往源于不完美的感知而非不足的思考。

Abstract: Large Vision-Language Models (LVLMs) have exhibited strong reasoning capabilities through chain-of-thought mechanisms that generate step-by-step rationales. However, such slow-thinking approaches often lead to overthinking, where models produce excessively verbose responses even for simple queries, resulting in test-time inefficiency and even degraded accuracy. Prior work has attempted to mitigate this issue via adaptive reasoning strategies, but these methods largely overlook a fundamental bottleneck: visual perception failures. We argue that stable reasoning critically depends on low-level visual grounding, and that reasoning errors often originate from imperfect perception rather than insufficient deliberation. To address this limitation, we propose Gated Perception-Reasoning Optimization (GPRO), a meta-reasoning controller that dynamically routes computation among three decision paths at each generation step: a lightweight fast path, a slow perception path for re-examining visual inputs, and a slow reasoning path for internal self-reflection. To learn this distinction, we derive large-scale failure attribution supervision from approximately 790k samples, using teacher models to distinguish perceptual hallucinations from reasoning errors. We then train the controller with multi-objective reinforcement learning to optimize the trade-off between task accuracy and computational cost under uncertainty. Experiments on five benchmarks demonstrate that GPRO substantially improves both accuracy and efficiency, outperforming recent slow-thinking methods while generating significantly shorter responses.

</details>


### [15] [UniDrive-WM: Unified Understanding, Planning and Generation World Model For Autonomous Driving](https://arxiv.org/abs/2601.04453)
*Zhexiao Xiong,Xin Ye,Burhan Yaman,Sheng Cheng,Yiren Lu,Jingru Luo,Nathan Jacobs,Liu Ren*

Main category: cs.CV

TL;DR: UniDrive-WM是一个统一的视觉语言模型世界模型，在单个架构中联合执行驾驶场景理解、轨迹规划和轨迹条件未来图像生成，相比现有方法显著提升了自动驾驶性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将感知、预测和规划作为独立模块处理，缺乏统一的世界模型来整合这些功能，限制了自动驾驶系统的整体性能。

Method: 提出UniDrive-WM模型，通过轨迹规划器预测未来轨迹，并基于VLM的图像生成器生成条件未来帧，这些预测提供额外的监督信号来增强场景理解和迭代优化轨迹生成。

Result: 在Bench2Drive基准测试中，UniDrive-WM相比之前最佳方法在L2轨迹误差上提升5.9%，碰撞率降低9.2%，并生成高质量的未来图像。

Conclusion: 研究表明将VLM驱动的推理、规划和生成式世界建模紧密集成对自动驾驶具有显著优势，为构建更统一的自动驾驶系统提供了新思路。

Abstract: World models have become central to autonomous driving, where accurate scene understanding and future prediction are crucial for safe control. Recent work has explored using vision-language models (VLMs) for planning, yet existing approaches typically treat perception, prediction, and planning as separate modules. We propose UniDrive-WM, a unified VLM-based world model that jointly performs driving-scene understanding, trajectory planning, and trajectory-conditioned future image generation within a single architecture. UniDrive-WM's trajectory planner predicts a future trajectory, which conditions a VLM-based image generator to produce plausible future frames. These predictions provide additional supervisory signals that enhance scene understanding and iteratively refine trajectory generation. We further compare discrete and continuous output representations for future image prediction, analyzing their influence on downstream driving performance. Experiments on the challenging Bench2Drive benchmark show that UniDrive-WM produces high-fidelity future images and improves planning performance by 5.9% in L2 trajectory error and 9.2% in collision rate over the previous best method. These results demonstrate the advantages of tightly integrating VLM-driven reasoning, planning, and generative world modeling for autonomous driving. The project page is available at https://unidrive-wm.github.io/UniDrive-WM .

</details>


### [16] [Vision-Language Agents for Interactive Forest Change Analysis](https://arxiv.org/abs/2601.04497)
*James Brock,Ce Zhang,Nantheera Anantrasirichai*

Main category: cs.CV

TL;DR: 该论文提出了一个基于大语言模型（LLM）的智能体系统，用于集成森林变化分析，支持跨多个遥感图像变化解释任务的自然语言查询。


<details>
  <summary>Details</summary>
Motivation: 解决森林监测中像素级变化检测和语义变化描述的挑战，探索大语言模型与视觉语言模型在遥感图像变化解释中的集成应用。

Method: 构建了一个多级变化解释视觉语言骨干网络，结合基于LLM的编排机制，并引入了包含双时相卫星图像、像素级变化掩码和多粒度语义变化描述的Forest-Change数据集。

Result: 在Forest-Change数据集上达到mIoU 67.10%和BLEU-4 40.17%，在LEVIR-MCI-Trees子集上达到mIoU 88.13%和BLEU-4 34.41%。

Conclusion: 证明了交互式LLM驱动的遥感图像变化解释系统在提高森林变化分析的可访问性、可解释性和效率方面的潜力。

Abstract: Modern forest monitoring workflows increasingly benefit from the growing availability of high-resolution satellite imagery and advances in deep learning. Two persistent challenges in this context are accurate pixel-level change detection and meaningful semantic change captioning for complex forest dynamics. While large language models (LLMs) are being adapted for interactive data exploration, their integration with vision-language models (VLMs) for remote sensing image change interpretation (RSICI) remains underexplored. To address this gap, we introduce an LLM-driven agent for integrated forest change analysis that supports natural language querying across multiple RSICI tasks. The proposed system builds upon a multi-level change interpretation (MCI) vision-language backbone with LLM-based orchestration. To facilitate adaptation and evaluation in forest environments, we further introduce the Forest-Change dataset, which comprises bi-temporal satellite imagery, pixel-level change masks, and multi-granularity semantic change captions generated using a combination of human annotation and rule-based methods. Experimental results show that the proposed system achieves mIoU and BLEU-4 scores of 67.10% and 40.17% on the Forest-Change dataset, and 88.13% and 34.41% on LEVIR-MCI-Trees, a tree-focused subset of LEVIR-MCI benchmark for joint change detection and captioning. These results highlight the potential of interactive, LLM-driven RSICI systems to improve accessibility, interpretability, and efficiency of forest change analysis. All data and code are publicly available at https://github.com/JamesBrockUoB/ForestChat.

</details>


### [17] [TokenSeg: Efficient 3D Medical Image Segmentation via Hierarchical Visual Token Compression](https://arxiv.org/abs/2601.04519)
*Sen Zeng,Hong Zhou,Zheng Zhu,Yang Liu*

Main category: cs.CV

TL;DR: TokenSeg是一个基于边界感知稀疏令牌表示的高效3D医学图像分割框架，通过多尺度层次编码器、边界感知令牌化和稀疏到密集解码器，在保持高精度的同时显著降低计算资源需求。


<details>
  <summary>Details</summary>
Motivation: 解决3D医学图像分割中由于体素处理立方增长和同质区域冗余计算导致的计算需求高的问题。

Method: 1) 多尺度层次编码器提取400个候选令牌；2) 边界感知令牌化器结合VQ-VAE量化和重要性评分选择100个显著令牌；3) 稀疏到密集解码器通过令牌重投影、渐进上采样和跳跃连接重建完整分辨率掩码。

Result: 在960例3D乳腺DCE-MRI数据集上达到94.49% Dice和89.61% IoU，GPU内存和推理延迟分别降低64%和68%。在MSD心脏和脑部MRI基准数据集上表现一致优异。

Conclusion: TokenSeg证明了基于解剖学信息的稀疏表示在实现准确高效3D医学图像分割方面的有效性。

Abstract: Three-dimensional medical image segmentation is a fundamental yet computationally demanding task due to the cubic growth of voxel processing and the redundant computation on homogeneous regions. To address these limitations, we propose \textbf{TokenSeg}, a boundary-aware sparse token representation framework for efficient 3D medical volume segmentation. Specifically, (1) we design a \emph{multi-scale hierarchical encoder} that extracts 400 candidate tokens across four resolution levels to capture both global anatomical context and fine boundary details; (2) we introduce a \emph{boundary-aware tokenizer} that combines VQ-VAE quantization with importance scoring to select 100 salient tokens, over 60\% of which lie near tumor boundaries; and (3) we develop a \emph{sparse-to-dense decoder} that reconstructs full-resolution masks through token reprojection, progressive upsampling, and skip connections. Extensive experiments on a 3D breast DCE-MRI dataset comprising 960 cases demonstrate that TokenSeg achieves state-of-the-art performance with 94.49\% Dice and 89.61\% IoU, while reducing GPU memory and inference latency by 64\% and 68\%, respectively. To verify the generalization capability, our evaluations on MSD cardiac and brain MRI benchmark datasets demonstrate that TokenSeg consistently delivers optimal performance across heterogeneous anatomical structures. These results highlight the effectiveness of anatomically informed sparse representation for accurate and efficient 3D medical image segmentation.

</details>


### [18] [FaceRefiner: High-Fidelity Facial Texture Refinement with Differentiable Rendering-based Style Transfer](https://arxiv.org/abs/2601.04520)
*Chengyang Li,Baoping Cheng,Yao Cheng,Haocheng Zhang,Renshuai Liu,Yinglin Zheng,Jing Liao,Xuan Cheng*

Main category: cs.CV

TL;DR: FaceRefiner提出了一种基于风格迁移的面部纹理优化方法，通过将3D采样纹理作为风格、纹理生成方法输出作为内容，实现多层级信息迁移，提升纹理质量和身份保持能力。


<details>
  <summary>Details</summary>
Motivation: 现有面部纹理生成方法通常使用训练数据或2D人脸生成器构建的UV贴图空间，限制了其对野外输入图像的泛化能力，导致面部细节、结构和身份与输入不一致。

Method: FaceRefiner采用风格迁移方法，将3D采样纹理作为风格图像，纹理生成方法输出作为内容图像，结合可微分渲染技术实现从可见面部区域的低层级（像素级）到高层级信息的多层级迁移。

Result: 在Multi-PIE、CelebA和FFHQ数据集上的实验表明，该方法相比现有技术能够提升纹理质量和面部身份保持能力。

Conclusion: FaceRefiner通过多层级风格迁移有效解决了现有纹理生成方法在细节保持和身份一致性方面的局限性，为面部纹理生成提供了有效的优化方案。

Abstract: Recent facial texture generation methods prefer to use deep networks to synthesize image content and then fill in the UV map, thus generating a compelling full texture from a single image. Nevertheless, the synthesized texture UV map usually comes from a space constructed by the training data or the 2D face generator, which limits the methods' generalization ability for in-the-wild input images. Consequently, their facial details, structures and identity may not be consistent with the input. In this paper, we address this issue by proposing a style transfer-based facial texture refinement method named FaceRefiner. FaceRefiner treats the 3D sampled texture as style and the output of a texture generation method as content. The photo-realistic style is then expected to be transferred from the style image to the content image. Different from current style transfer methods that only transfer high and middle level information to the result, our style transfer method integrates differentiable rendering to also transfer low level (or pixel level) information in the visible face regions. The main benefit of such multi-level information transfer is that, the details, structures and semantics in the input can thus be well preserved. The extensive experiments on Multi-PIE, CelebA and FFHQ datasets demonstrate that our refinement method can improve the texture quality and the face identity preserving ability, compared with state-of-the-arts.

</details>


### [19] [All Changes May Have Invariant Principles: Improving Ever-Shifting Harmful Meme Detection via Design Concept Reproduction](https://arxiv.org/abs/2601.04567)
*Ziyou Jiang,Mingyang Li,Junjie Wang,Yuekai Huang,Jie Huang,Zhiyuan Chang,Zhaoyang Li,Qing Wang*

Main category: cs.CV

TL;DR: RepMD是一种基于设计概念复现的有害表情包检测方法，通过定义设计概念图(DCG)来描述恶意用户设计有害表情包的步骤，并利用多模态大语言模型(MLLM)进行检测。


<details>
  <summary>Details</summary>
Motivation: 有害表情包在互联网社区中不断演变，难以分析。研究发现不同表情包可能共享不变的设计原则，即恶意用户的底层设计概念，这有助于分析为什么这些表情包是有害的。

Method: 1. 参考攻击树定义设计概念图(DCG)；2. 通过设计步骤复现和图剪枝从历史表情包中推导DCG；3. 使用DCG指导多模态大语言模型检测有害表情包。

Result: RepMD达到81.1%的最高准确率，在类型演变和时间演变的泛化测试中准确率下降较小。人工评估显示RepMD可将人工发现有害表情包的效率提升至每张15~30秒。

Conclusion: RepMD方法能够有效检测不断演变的有害表情包，通过捕捉不变的设计概念来应对类型和时间的演变，显著提高了检测效率。

Abstract: Harmful memes are ever-shifting in the Internet communities, which are difficult to analyze due to their type-shifting and temporal-evolving nature. Although these memes are shifting, we find that different memes may share invariant principles, i.e., the underlying design concept of malicious users, which can help us analyze why these memes are harmful. In this paper, we propose RepMD, an ever-shifting harmful meme detection method based on the design concept reproduction. We first refer to the attack tree to define the Design Concept Graph (DCG), which describes steps that people may take to design a harmful meme. Then, we derive the DCG from historical memes with design step reproduction and graph pruning. Finally, we use DCG to guide the Multimodal Large Language Model (MLLM) to detect harmful memes. The evaluation results show that RepMD achieves the highest accuracy with 81.1% and has slight accuracy decreases when generalized to type-shifting and temporal-evolving memes. Human evaluation shows that RepMD can improve the efficiency of human discovery on harmful memes, with 15$\sim$30 seconds per meme.

</details>


### [20] [3D Conditional Image Synthesis of Left Atrial LGE MRI from Composite Semantic Masks](https://arxiv.org/abs/2601.04588)
*Yusri Al-Sanaani,Rebecca Thornhill,Sreeraman Rajan*

Main category: cs.CV

TL;DR: 该研究提出使用3D条件生成模型（Pix2Pix GAN、SPADE-GAN和SPADE-LDM）来合成高保真度的3D LGE MRI图像，以增强左心房分割性能。SPADE-LDM表现最佳，显著提升了分割模型的性能。


<details>
  <summary>Details</summary>
Motivation: 左心房壁和心内膜的准确分割对于量化心房颤动患者的纤维化至关重要，但由于数据稀缺和结构复杂性，开发准确的机器学习分割模型具有挑战性。

Method: 开发了一个流程，从结合解剖学专家注释和无监督组织聚类的复合语义标签图中合成3D LGE MRI图像，使用了三种3D条件生成器（Pix2Pix GAN、SPADE-GAN和SPADE-LDM）。

Result: SPADE-LDM生成的图像最真实且结构最准确，FID为4.063，优于Pix2Pix GAN（FID=40.821）和SPADE-GAN（FID=7.652）。使用合成图像增强后，3D U-Net模型的分割Dice分数从0.908提升至0.936，具有统计学显著性（p < 0.05）。

Conclusion: 标签条件化的3D合成技术有潜力提升对代表性不足的心脏结构的分割效果。

Abstract: Segmentation of the left atrial (LA) wall and endocardium from late gadolinium-enhanced (LGE) MRI is essential for quantifying atrial fibrosis in patients with atrial fibrillation. The development of accurate machine learning-based segmentation models remains challenging due to the limited availability of data and the complexity of anatomical structures. In this work, we investigate 3D conditional generative models as potential solution for augmenting scarce LGE training data and improving LA segmentation performance. We develop a pipeline to synthesize high-fidelity 3D LGE MRI volumes from composite semantic label maps combining anatomical expert annotations with unsupervised tissue clusters, using three 3D conditional generators (Pix2Pix GAN, SPADE-GAN, and SPADE-LDM). The synthetic images are evaluated for realism and their impact on downstream LA segmentation. SPADE-LDM generates the most realistic and structurally accurate images, achieving an FID of 4.063 and surpassing GAN models, which have FIDs of 40.821 and 7.652 for Pix2Pix and SPADE-GAN, respectively. When augmented with synthetic LGE images, the Dice score for LA cavity segmentation with a 3D U-Net model improved from 0.908 to 0.936, showing a statistically significant improvement (p < 0.05) over the baseline.These findings demonstrate the potential of label-conditioned 3D synthesis to enhance the segmentation of under-represented cardiac structures.

</details>


### [21] [MiLDEdit: Reasoning-Based Multi-Layer Design Document Editing](https://arxiv.org/abs/2601.04589)
*Zihao Lin,Wanrong Zhu,Jiuxiang Gu,Jihyung Kil,Christopher Tensmeyer,Lin Zhang,Shilong Liu,Ruiyi Zhang,Lifu Huang,Vlad I. Morariu,Tong Sun*

Main category: cs.CV

TL;DR: 本文提出了MiLDEAgent框架，专门解决多图层设计文档编辑问题，通过结合RL训练的多模态推理器和图像编辑器实现精准的图层感知编辑。


<details>
  <summary>Details</summary>
Motivation: 现实设计文档（如海报）具有多图层特性，现有方法主要关注单图层图像编辑或多图层生成，缺乏对图层结构的细粒度推理能力。

Method: 提出MiLDEAgent框架，包含多模态推理器（RL训练）和图像编辑器，支持图层级理解和针对性修改。同时构建了MiLDEBench基准数据集和MiLDEEval评估协议。

Result: 在14个开源和2个闭源模型上的实验表明，现有方法无法有效处理多图层编辑任务，而MiLDEAgent在图层感知推理和精确编辑方面显著优于开源基线，性能接近闭源模型。

Conclusion: MiLDEAgent为多图层设计文档编辑建立了首个强基线，解决了现有方法在图层结构理解和协调修改方面的不足。

Abstract: Real-world design documents (e.g., posters) are inherently multi-layered, combining decoration, text, and images. Editing them from natural-language instructions requires fine-grained, layer-aware reasoning to identify relevant layers and coordinate modifications. Prior work largely overlooks multi-layer design document editing, focusing instead on single-layer image editing or multi-layer generation, which assume a flat canvas and lack the reasoning needed to determine what and where to modify. To address this gap, we introduce the Multi-Layer Document Editing Agent (MiLDEAgent), a reasoning-based framework that combines an RL-trained multimodal reasoner for layer-wise understanding with an image editor for targeted modifications. To systematically benchmark this setting, we introduce the MiLDEBench, a human-in-the-loop corpus of over 20K design documents paired with diverse editing instructions. The benchmark is complemented by a task-specific evaluation protocol, MiLDEEval, which spans four dimensions including instruction following, layout consistency, aesthetics, and text rendering. Extensive experiments on 14 open-source and 2 closed-source models reveal that existing approaches fail to generalize: open-source models often cannot complete multi-layer document editing tasks, while closed-source models suffer from format violations. In contrast, MiLDEAgent achieves strong layer-aware reasoning and precise editing, significantly outperforming all open-source baselines and attaining performance comparable to closed-source models, thereby establishing the first strong baseline for multi-layer document editing.

</details>


### [22] [Detection of Deployment Operational Deviations for Safety and Security of AI-Enabled Human-Centric Cyber Physical Systems](https://arxiv.org/abs/2601.04605)
*Bernard Ngabonziza,Ayan Banerjee,Sandeep K. S. Gupta*

Main category: cs.CV

TL;DR: 本文讨论了AI赋能的人为中心信息物理系统在不确定条件下的安全风险，提出了一个评估安全策略的框架，并以糖尿病患者的闭环血糖控制为例展示了检测未宣布进餐的新方法。


<details>
  <summary>Details</summary>
Motivation: 随着AI在医疗监控、自动驾驶等人为中心系统中广泛应用，系统在与人类交互时可能进入不确定状态，这会违反系统的安全和安保要求。需要研究如何确保这类系统在部署中的安全性。

Method: 首先分析导致系统进入未知条件的操作偏差，然后建立一个评估不同安全策略的框架，最后以1型糖尿病患者的闭环血糖控制为例，提出一种基于图像的个性化技术来检测未宣布的进餐情况。

Result: 开发了一个系统性的安全评估框架，并通过具体案例验证了检测技术在实际应用中的可行性。

Conclusion: AI赋能的人为中心信息物理系统需要专门的安全保障机制来应对不确定条件下的风险，提出的框架和检测技术为这类系统的安全部署提供了有效解决方案。

Abstract: In recent years, Human-centric cyber-physical systems have increasingly involved artificial intelligence to enable knowledge extraction from sensor-collected data. Examples include medical monitoring and control systems, as well as autonomous cars. Such systems are intended to operate according to the protocols and guidelines for regular system operations. However, in many scenarios, such as closed-loop blood glucose control for Type 1 diabetics, self-driving cars, and monitoring systems for stroke diagnosis. The operations of such AI-enabled human-centric applications can expose them to cases for which their operational mode may be uncertain, for instance, resulting from the interactions with a human with the system. Such cases, in which the system is in uncertain conditions, can violate the system's safety and security requirements. 
  This paper will discuss operational deviations that can lead these systems to operate in unknown conditions. We will then create a framework to evaluate different strategies for ensuring the safety and security of AI-enabled human-centric cyber-physical systems in operation deployment. Then, as an example, we show a personalized image-based novel technique for detecting the non-announcement of meals in closed-loop blood glucose control for Type 1 diabetics.

</details>


### [23] [HUR-MACL: High-Uncertainty Region-Guided Multi-Architecture Collaborative Learning for Head and Neck Multi-Organ Segmentation](https://arxiv.org/abs/2601.04607)
*Xiaoyu Liu,Siwen Wei,Linhao Qu,Mingyuan Pan,Chengsheng Zhang,Yonghong Shi,Zhijian Song*

Main category: cs.CV

TL;DR: 本文提出了一种高不确定性区域引导的多架构协作学习模型（HUR-MACL），用于头颈部多器官分割，通过自适应识别高不确定性区域并利用Vision Mamba和Deformable CNN协同提升分割精度。


<details>
  <summary>Details</summary>
Motivation: 头颈部危及器官的准确分割对放射治疗至关重要，但深度学习模型在小型、复杂形状器官上表现不佳。现有混合架构通常简单拼接特征，未能充分利用各组件优势，导致功能重叠和分割精度有限。

Method: 1. 使用卷积神经网络自适应识别高不确定性区域；2. 在高不确定性区域联合使用Vision Mamba和Deformable CNN提升分割精度；3. 提出异构特征蒸馏损失促进两种架构在高不确定性区域的协作学习。

Result: 在两个公共数据集和一个私有数据集上取得了最先进（SOTA）的结果。

Conclusion: HUR-MACL模型通过高不确定性区域引导和异构架构协作，有效提升了头颈部多器官分割的精度，特别是在复杂形状的小器官上表现优异。

Abstract: Accurate segmentation of organs at risk in the head and neck is essential for radiation therapy, yet deep learning models often fail on small, complexly shaped organs. While hybrid architectures that combine different models show promise, they typically just concatenate features without exploiting the unique strengths of each component. This results in functional overlap and limited segmentation accuracy. To address these issues, we propose a high uncertainty region-guided multi-architecture collaborative learning (HUR-MACL) model for multi-organ segmentation in the head and neck. This model adaptively identifies high uncertainty regions using a convolutional neural network, and for these regions, Vision Mamba as well as Deformable CNN are utilized to jointly improve their segmentation accuracy. Additionally, a heterogeneous feature distillation loss was proposed to promote collaborative learning between the two architectures in high uncertainty regions to further enhance performance. Our method achieves SOTA results on two public datasets and one private dataset.

</details>


### [24] [HyperAlign: Hyperbolic Entailment Cones for Adaptive Text-to-Image Alignment Assessment](https://arxiv.org/abs/2601.04614)
*Wenzhi Chen,Bo Hu,Leida Li,Lihuo He,Wen Lu,Xinbo Gao*

Main category: cs.CV

TL;DR: HyperAlign是一个基于双曲蕴含几何的自适应文本-图像对齐评估框架，通过将CLIP特征映射到双曲空间，设计动态监督蕴含建模机制，并利用自适应调制回归器来校准欧几里得余弦相似度，在单数据库评估和跨数据库泛化任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖欧几里得空间指标，忽略了语义对齐的结构化特性，且缺乏对不同样本的自适应能力。

Method: 1. 使用CLIP提取欧几里得特征并映射到双曲空间；2. 设计动态监督蕴含建模机制，将离散蕴含逻辑转化为连续几何结构监督；3. 提出自适应调制回归器，利用双曲几何特征生成样本级调制参数，自适应校准欧几里得余弦相似度。

Result: HyperAlign在单数据库评估和跨数据库泛化任务中均取得了极具竞争力的性能。

Conclusion: 双曲几何建模在图像-文本对齐评估中具有显著有效性。

Abstract: With the rapid development of text-to-image generation technology, accurately assessing the alignment between generated images and text prompts has become a critical challenge. Existing methods rely on Euclidean space metrics, neglecting the structured nature of semantic alignment, while lacking adaptive capabilities for different samples. To address these limitations, we propose HyperAlign, an adaptive text-to-image alignment assessment framework based on hyperbolic entailment geometry. First, we extract Euclidean features using CLIP and map them to hyperbolic space. Second, we design a dynamic-supervision entailment modeling mechanism that transforms discrete entailment logic into continuous geometric structure supervision. Finally, we propose an adaptive modulation regressor that utilizes hyperbolic geometric features to generate sample-level modulation parameters, adaptively calibrating Euclidean cosine similarity to predict the final score. HyperAlign achieves highly competitive performance on both single database evaluation and cross-database generalization tasks, fully validating the effectiveness of hyperbolic geometric modeling for image-text alignment assessment.

</details>


### [25] [Agri-R1: Empowering Generalizable Agricultural Reasoning in Vision-Language Models with Reinforcement Learning](https://arxiv.org/abs/2601.04672)
*Wentao Zhang,Lifei Wang,Lina Lu,MingKun Xu,Shangyang Li,Yanchao Yang,Tao Fang*

Main category: cs.CV

TL;DR: Agri-R1是一个用于农业领域的推理增强大模型，通过自动化生成高质量推理数据和优化训练方法，在少量样本下实现优于更大模型的性能


<details>
  <summary>Details</summary>
Motivation: 解决农业病害诊断中传统微调方法需要大量标注、缺乏可解释性、泛化能力差的问题，同时应对农业查询的开放性和多样性挑战

Method: 1. 通过视觉语言合成和基于LLM的过滤自动生成高质量推理数据（仅使用19%可用样本）
2. 使用组相对策略优化（GRPO）训练，结合领域特定词典和模糊匹配的新奖励函数
3. 评估开放回答的正确性和语言灵活性

Result: 在CDDMBench评估中，3B参数模型性能与7B-13B基线模型相当：
- 病害识别准确率相对提升23.2%
- 农业知识问答相对提升33.3%
- 跨域泛化能力提升26.10分

Conclusion: 结构化推理数据与GRPO驱动探索的协同作用是性能提升的关键，且随着问题复杂度增加，收益更加明显

Abstract: Agricultural disease diagnosis challenges VLMs, as conventional fine-tuning requires extensive labels, lacks interpretability, and generalizes poorly. While reasoning improves model robustness, existing methods rely on costly expert annotations and rarely address the open-ended, diverse nature of agricultural queries. To address these limitations, we propose \textbf{Agri-R1}, a reasoning-enhanced large model for agriculture. Our framework automates high-quality reasoning data generation via vision-language synthesis and LLM-based filtering, using only 19\% of available samples. Training employs Group Relative Policy Optimization (GRPO) with a novel proposed reward function that integrates domain-specific lexicons and fuzzy matching to assess both correctness and linguistic flexibility in open-ended responses. Evaluated on CDDMBench, our resulting 3B-parameter model achieves performance competitive with 7B- to 13B-parameter baselines, showing a +23.2\% relative gain in disease recognition accuracy, +33.3\% in agricultural knowledge QA, and a +26.10-point improvement in cross-domain generalization over standard fine-tuning. Ablation studies confirm that the synergy between structured reasoning data and GRPO-driven exploration underpins these gains, with benefits scaling as question complexity increases.

</details>


### [26] [DB-MSMUNet:Dual Branch Multi-scale Mamba UNet for Pancreatic CT Scans Segmentation](https://arxiv.org/abs/2601.04676)
*Qiu Guan,Zhiqiang Yang,Dezhang Ye,Yang Chen,Xinli Xu,Ying Tang*

Main category: cs.CV

TL;DR: 提出DB-MSMUNet模型，通过双分支多尺度Mamba UNet架构解决胰腺CT分割中的挑战，在三个数据集上取得优于现有方法的性能


<details>
  <summary>Details</summary>
Motivation: 胰腺及其病变的CT分割对胰腺癌诊断和治疗至关重要，但由于组织对比度低、边界模糊、形状不规则和病变小等因素，该任务极具挑战性

Method: DB-MSMUNet采用编码器-解码器架构，编码器使用多尺度Mamba模块结合可变形卷积和多尺度状态空间建模，双解码器设计包括边缘解码器（带边缘增强路径）和区域解码器（带多层解码器），并添加辅助深度监督头

Result: 在NIH胰腺数据集、MSD数据集和临床胰腺肿瘤数据集上分别获得89.47%、87.59%和89.02%的Dice相似系数，在分割精度、边缘保持和跨数据集鲁棒性方面优于现有方法

Conclusion: DB-MSMUNet在真实世界胰腺CT分割任务中表现出有效性和泛化能力

Abstract: Accurate segmentation of the pancreas and its lesions in CT scans is crucial for the precise diagnosis and treatment of pancreatic cancer. However, it remains a highly challenging task due to several factors such as low tissue contrast with surrounding organs, blurry anatomical boundaries, irregular organ shapes, and the small size of lesions. To tackle these issues, we propose DB-MSMUNet (Dual-Branch Multi-scale Mamba UNet), a novel encoder-decoder architecture designed specifically for robust pancreatic segmentation. The encoder is constructed using a Multi-scale Mamba Module (MSMM), which combines deformable convolutions and multi-scale state space modeling to enhance both global context modeling and local deformation adaptation. The network employs a dual-decoder design: the edge decoder introduces an Edge Enhancement Path (EEP) to explicitly capture boundary cues and refine fuzzy contours, while the area decoder incorporates a Multi-layer Decoder (MLD) to preserve fine-grained details and accurately reconstruct small lesions by leveraging multi-scale deep semantic features. Furthermore, Auxiliary Deep Supervision (ADS) heads are added at multiple scales to both decoders, providing more accurate gradient feedback and further enhancing the discriminative capability of multi-scale features. We conduct extensive experiments on three datasets: the NIH Pancreas dataset, the MSD dataset, and a clinical pancreatic tumor dataset provided by collaborating hospitals. DB-MSMUNet achieves Dice Similarity Coefficients of 89.47%, 87.59%, and 89.02%, respectively, outperforming most existing state-of-the-art methods in terms of segmentation accuracy, edge preservation, and robustness across different datasets. These results demonstrate the effectiveness and generalizability of the proposed method for real-world pancreatic CT segmentation tasks.

</details>


### [27] [Driving on Registers](https://arxiv.org/abs/2601.05083)
*Ellington Kirby,Alexandre Boulch,Yihong Xu,Yuan Yin,Gilles Puy,Éloi Zablocki,Andrei Bursuc,Spyros Gidaris,Renaud Marlet,Florent Bartoccioni,Anh-Quan Cao,Nermin Samet,Tuan-Hung VU,Matthieu Cord*

Main category: cs.CV

TL;DR: DrivoR是一个基于预训练视觉Transformer的端到端自动驾驶架构，通过相机感知寄存器令牌压缩多相机特征，使用轻量级解码器生成和评估候选轨迹，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 开发一种简单高效的纯Transformer架构来解决端到端自动驾驶问题，通过令牌压缩技术减少计算量同时保持准确性，实现可解释的行为条件驾驶。

Method: 基于预训练ViT，引入相机感知寄存器令牌压缩多相机特征，使用两个轻量级Transformer解码器分别生成候选轨迹和基于安全、舒适、效率等子分数进行评分。

Result: 在NAVSIM-v1、NAVSIM-v2和HUGSIM基准测试中优于或匹配现有强基线方法，证明了纯Transformer架构结合令牌压缩的有效性。

Conclusion: 纯Transformer架构结合针对性的令牌压缩足以实现准确、高效和自适应的端到端自动驾驶，代码和检查点将公开。

Abstract: We present DrivoR, a simple and efficient transformer-based architecture for end-to-end autonomous driving. Our approach builds on pretrained Vision Transformers (ViTs) and introduces camera-aware register tokens that compress multi-camera features into a compact scene representation, significantly reducing downstream computation without sacrificing accuracy. These tokens drive two lightweight transformer decoders that generate and then score candidate trajectories. The scoring decoder learns to mimic an oracle and predicts interpretable sub-scores representing aspects such as safety, comfort, and efficiency, enabling behavior-conditioned driving at inference. Despite its minimal design, DrivoR outperforms or matches strong contemporary baselines across NAVSIM-v1, NAVSIM-v2, and the photorealistic closed-loop HUGSIM benchmark. Our results show that a pure-transformer architecture, combined with targeted token compression, is sufficient for accurate, efficient, and adaptive end-to-end driving. Code and checkpoints will be made available via the project page.

</details>


### [28] [HATIR: Heat-Aware Diffusion for Turbulent Infrared Video Super-Resolution](https://arxiv.org/abs/2601.04682)
*Yang Zou,Xingyue Zhu,Kaiqi Han,Jun Ma,Xingyuan Li,Zhiying Jiang,Jinyuan Liu*

Main category: cs.CV

TL;DR: HATIR是一种基于热感知扩散的红外视频超分辨率方法，通过联合建模湍流退化和结构细节损失，解决了传统方法中湍流缓解与超分辨率解耦的问题。


<details>
  <summary>Details</summary>
Motivation: 现有视频超分辨率方法要么忽视红外与可见光图像之间的模态差异，要么无法恢复湍流引起的失真，直接级联湍流缓解算法会导致误差传播和累积。

Method: 提出HATIR方法，将热感知变形先验注入扩散采样路径，构建相量引导的流估计器和湍流感知解码器，选择性抑制不稳定时间线索并增强边缘感知特征聚合。

Result: 构建了首个湍流红外视频超分辨率数据集FLIR-IVSR，包含640个不同场景的LR-HR序列对，为未来红外视频超分辨率研究提供支持。

Conclusion: HATIR通过热感知扩散模型有效解决了红外视频中的湍流和分辨率退化问题，为挑战性环境下的视觉任务提供了新的解决方案。

Abstract: Infrared video has been of great interest in visual tasks under challenging environments, but often suffers from severe atmospheric turbulence and compression degradation. Existing video super-resolution (VSR) methods either neglect the inherent modality gap between infrared and visible images or fail to restore turbulence-induced distortions. Directly cascading turbulence mitigation (TM) algorithms with VSR methods leads to error propagation and accumulation due to the decoupled modeling of degradation between turbulence and resolution. We introduce HATIR, a Heat-Aware Diffusion for Turbulent InfraRed Video Super-Resolution, which injects heat-aware deformation priors into the diffusion sampling path to jointly model the inverse process of turbulent degradation and structural detail loss. Specifically, HATIR constructs a Phasor-Guided Flow Estimator, rooted in the physical principle that thermally active regions exhibit consistent phasor responses over time, enabling reliable turbulence-aware flow to guide the reverse diffusion process. To ensure the fidelity of structural recovery under nonuniform distortions, a Turbulence-Aware Decoder is proposed to selectively suppress unstable temporal cues and enhance edge-aware feature aggregation via turbulence gating and structure-aware attention. We built FLIR-IVSR, the first dataset for turbulent infrared VSR, comprising paired LR-HR sequences from a FLIR T1050sc camera (1024 X 768) spanning 640 diverse scenes with varying camera and object motion conditions. This encourages future research in infrared VSR. Project page: https://github.com/JZ0606/HATIR

</details>


### [29] [RoboVIP: Multi-View Video Generation with Visual Identity Prompting Augments Robot Manipulation](https://arxiv.org/abs/2601.05241)
*Boyang Wang,Haoran Zhang,Shujie Zhang,Jinkun Hao,Mingda Jia,Qi Lv,Yucheng Mao,Zhaoyang Lyu,Jia Zeng,Xudong Xu,Jiangmiao Pang*

Main category: cs.CV

TL;DR: 本文提出了一种使用视觉身份提示的数据增强方法，通过提供示例图像作为条件输入来指导扩散模型生成所需的场景设置，从而解决机器人操作数据稀缺和多视图时间一致性问题。


<details>
  <summary>Details</summary>
Motivation: 由于硬件和物理设置限制，收集大规模真实世界操作数据难以在不同环境中扩展。现有基于文本提示的图像扩散方法无法可靠指定场景设置，且忽视了多视图和时间一致性的实际需求。

Method: 引入视觉身份提示，将示例图像作为条件输入来指导扩散模型生成所需场景设置；构建可扩展的流水线从大型机器人数据集中策划视觉身份池。

Result: 使用增强的操作数据训练下游视觉-语言-动作和视觉运动策略模型，在仿真和真实机器人设置中均获得一致的性能提升。

Conclusion: 视觉身份提示方法有效解决了机器人操作数据增强中的场景设置和多视图一致性问题，为训练更有效的机器人策略提供了可行方案。

Abstract: The diversity, quantity, and quality of manipulation data are critical for training effective robot policies. However, due to hardware and physical setup constraints, collecting large-scale real-world manipulation data remains difficult to scale across diverse environments. Recent work uses text-prompt conditioned image diffusion models to augment manipulation data by altering the backgrounds and tabletop objects in the visual observations. However, these approaches often overlook the practical need for multi-view and temporally coherent observations required by state-of-the-art policy models. Further, text prompts alone cannot reliably specify the scene setup. To provide the diffusion model with explicit visual guidance, we introduce visual identity prompting, which supplies exemplar images as conditioning inputs to guide the generation of the desired scene setup. To this end, we also build a scalable pipeline to curate a visual identity pool from large robotics datasets. Using our augmented manipulation data to train downstream vision-language-action and visuomotor policy models yields consistent performance gains in both simulation and real-robot settings.

</details>


### [30] [WebCryptoAgent: Agentic Crypto Trading with Web Informatics](https://arxiv.org/abs/2601.04687)
*Ali Kurban,Wei Luo,Liangyu Zuo,Zeyu Zhang,Renda Han,Zhaolu Kang,Hao Tang*

Main category: cs.CV

TL;DR: WebCryptoAgent是一个基于多模态代理的加密货币交易框架，通过分离策略推理和实时风险控制来解决异构网络信息整合和市场波动处理的问题。


<details>
  <summary>Details</summary>
Motivation: 现有交易系统难以同时处理多源网络证据的噪声和应对极端市场波动，需要一种能够整合非结构化网络内容、社交情绪和结构化市场信号，并在秒级时间尺度上保持稳健性的解决方案。

Method: 提出WebCryptoAgent框架，将网络信息决策分解为特定模态的代理，并整合其输出到统一证据文档中进行置信度校准推理。采用解耦控制架构，将策略性的小时级推理与秒级实时风险模型分离，实现快速冲击检测和独立于交易循环的保护性干预。

Result: 在真实加密货币市场上的大量实验表明，WebCryptoAgent相比现有基线提高了交易稳定性，减少了虚假活动，并增强了尾部风险处理能力。

Conclusion: 该框架有效解决了加密货币交易中的信息整合和风险控制挑战，为高频交易环境提供了更加稳健和可解释的决策支持。

Abstract: Cryptocurrency trading increasingly depends on timely integration of heterogeneous web information and market microstructure signals to support short-horizon decision making under extreme volatility. However, existing trading systems struggle to jointly reason over noisy multi-source web evidence while maintaining robustness to rapid price shocks at sub-second timescales. The first challenge lies in synthesizing unstructured web content, social sentiment, and structured OHLCV signals into coherent and interpretable trading decisions without amplifying spurious correlations, while the second challenge concerns risk control, as slow deliberative reasoning pipelines are ill-suited for handling abrupt market shocks that require immediate defensive responses. To address these challenges, we propose WebCryptoAgent, an agentic trading framework that decomposes web-informed decision making into modality-specific agents and consolidates their outputs into a unified evidence document for confidence-calibrated reasoning. We further introduce a decoupled control architecture that separates strategic hourly reasoning from a real-time second-level risk model, enabling fast shock detection and protective intervention independent of the trading loop. Extensive experiments on real-world cryptocurrency markets demonstrate that WebCryptoAgent improves trading stability, reduces spurious activity, and enhances tail-risk handling compared to existing baselines. Code will be available at https://github.com/AIGeeksGroup/WebCryptoAgent.

</details>


### [31] [Forge-and-Quench: Enhancing Image Generation for Higher Fidelity in Unified Multimodal Models](https://arxiv.org/abs/2601.04706)
*Yanbing Zeng,Jia Wang,Hanghang Ma,Junqiang Wu,Jie Zhu,Xiaoming Wei,Jie Hu*

Main category: cs.CV

TL;DR: 本文提出Forge-and-Quench框架，通过理解模型增强图像生成的保真度和细节丰富度，利用Bridge Feature作为视觉引导信号，实现高效跨模型迁移。


<details>
  <summary>Details</summary>
Motivation: 探索如何有效利用理解能力来增强图像生成的保真度和细节丰富度，而不仅仅是利用推理能力和世界知识。

Method: 提出Forge-and-Quench框架：MLLM对对话上下文进行推理生成增强文本指令，通过Bridge Adapter映射到Bridge Feature虚拟视觉表示，作为视觉引导信号注入T2I主干模型。

Result: 实验表明该框架显著提升多个模型的图像保真度和细节，同时保持指令跟随准确性并增强世界知识应用能力。

Conclusion: 该框架具有出色的扩展性和灵活性，可在不同MLLM和T2I模型间高效迁移，大幅减少训练开销且不损害MLLM的多模态理解能力。

Abstract: Integrating image generation and understanding into a single framework has become a pivotal goal in the multimodal domain. However, how understanding can effectively assist generation has not been fully explored. Unlike previous works that focus on leveraging reasoning abilities and world knowledge from understanding models, this paper introduces a novel perspective: leveraging understanding to enhance the fidelity and detail richness of generated images. To this end, we propose Forge-and-Quench, a new unified framework that puts this principle into practice. In the generation process of our framework, an MLLM first reasons over the entire conversational context, including text instructions, to produce an enhanced text instruction. This refined instruction is then mapped to a virtual visual representation, termed the Bridge Feature, via a novel Bridge Adapter. This feature acts as a crucial link, forging insights from the understanding model to quench and refine the generation process. It is subsequently injected into the T2I backbone as a visual guidance signal, alongside the enhanced text instruction that replaces the original input. To validate this paradigm, we conduct comprehensive studies on the design of the Bridge Feature and Bridge Adapter. Our framework demonstrates exceptional extensibility and flexibility, enabling efficient migration across different MLLM and T2I models with significant savings in training overhead, all without compromising the MLLM's inherent multimodal understanding capabilities. Experiments show that Forge-and-Quench significantly improves image fidelity and detail across multiple models, while also maintaining instruction-following accuracy and enhancing world knowledge application. Models and codes are available at https://github.com/YanbingZeng/Forge-and-Quench.

</details>


### [32] [On the Holistic Approach for Detecting Human Image Forgery](https://arxiv.org/abs/2601.04715)
*Xiao Guo,Jie Zhu,Anil Jain,Xiaoming Liu*

Main category: cs.CV

TL;DR: HuForDet是一个用于检测人类图像伪造的全面框架，采用双分支架构，结合面部伪造检测和上下文伪造检测，在统一的数据集上实现了最先进的检测性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有检测方法存在碎片化问题，专门针对面部区域伪造或全身合成图像，无法泛化到各种人类图像操作。需要一种能够全面检测人类图像伪造的统一方法。

Method: 提出HuForDet框架，包含：1）面部伪造检测分支，在RGB和频域使用异构专家，包括自适应LoG模块；2）上下文伪造检测分支，利用多模态大语言模型分析全身语义一致性，并采用置信度估计机制动态加权特征融合。

Result: 在统一的人类图像伪造数据集上进行广泛实验，HuForDet实现了最先进的伪造检测性能和优异的鲁棒性。

Conclusion: HuForDet通过双分支架构有效解决了人类图像伪造检测的碎片化问题，在多样化的伪造类型上都表现出色，为全面检测人类图像伪造提供了有效解决方案。

Abstract: The rapid advancement of AI-generated content (AIGC) has escalated the threat of deepfakes, from facial manipulations to the synthesis of entire photorealistic human bodies. However, existing detection methods remain fragmented, specializing either in facial-region forgeries or full-body synthetic images, and consequently fail to generalize across the full spectrum of human image manipulations. We introduce HuForDet, a holistic framework for human image forgery detection, which features a dual-branch architecture comprising: (1) a face forgery detection branch that employs heterogeneous experts operating in both RGB and frequency domains, including an adaptive Laplacian-of-Gaussian (LoG) module designed to capture artifacts ranging from fine-grained blending boundaries to coarse-scale texture irregularities; and (2) a contextualized forgery detection branch that leverages a Multi-Modal Large Language Model (MLLM) to analyze full-body semantic consistency, enhanced with a confidence estimation mechanism that dynamically weights its contribution during feature fusion. We curate a human image forgery (HuFor) dataset that unifies existing face forgery data with a new corpus of full-body synthetic humans. Extensive experiments show that our HuForDet achieves state-of-the-art forgery detection performance and superior robustness across diverse human image forgeries.

</details>


### [33] [Training a Custom CNN on Five Heterogeneous Image Datasets](https://arxiv.org/abs/2601.04727)
*Anika Tabassum,Tasnuva Mahazabin Tuba,Nafisa Naznin*

Main category: cs.CV

TL;DR: 该研究评估了CNN架构在五个异构数据集上的有效性，比较了轻量级自定义CNN与ResNet-18、VGG-16等深度架构的性能，分析了架构复杂性、模型深度和预训练对泛化能力的影响。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索深度学习模型在不同现实世界视觉分类任务中的适应性，特别是在资源受限但高影响力的应用场景中，如农业和城市领域的图像分类问题。

Method: 研究方法包括：使用五个异构数据集进行实验；评估自定义CNN与预训练深度架构；采用系统预处理、数据增强和受控实验；分析架构复杂性、模型深度和迁移学习的影响。

Result: 研究结果：开发了高效的轻量级自定义CNN，在多个应用领域达到有竞争力的性能；通过比较分析明确了迁移学习和深度架构在数据受限环境中的优势。

Conclusion: 结论：该研究为在资源有限的现实世界视觉分类任务中部署深度学习模型提供了实用见解，特别强调了迁移学习和深度架构在数据约束环境中的价值。

Abstract: Deep learning has transformed visual data analysis, with Convolutional Neural Networks (CNNs) becoming highly effective in learning meaningful feature representations directly from images. Unlike traditional manual feature engineering methods, CNNs automatically extract hierarchical visual patterns, enabling strong performance across diverse real-world contexts. This study investigates the effectiveness of CNN-based architectures across five heterogeneous datasets spanning agricultural and urban domains: mango variety classification, paddy variety identification, road surface condition assessment, auto-rickshaw detection, and footpath encroachment monitoring. These datasets introduce varying challenges, including differences in illumination, resolution, environmental complexity, and class imbalance, necessitating adaptable and robust learning models.
  We evaluate a lightweight, task-specific custom CNN alongside established deep architectures, including ResNet-18 and VGG-16, trained both from scratch and using transfer learning. Through systematic preprocessing, augmentation, and controlled experimentation, we analyze how architectural complexity, model depth, and pre-training influence convergence, generalization, and performance across datasets of differing scale and difficulty. The key contributions of this work are: (1) the development of an efficient custom CNN that achieves competitive performance across multiple application domains, and (2) a comprehensive comparative analysis highlighting when transfer learning and deep architectures provide substantial advantages, particularly in data-constrained environments. These findings offer practical insights for deploying deep learning models in resource-limited yet high-impact real-world visual classification tasks.

</details>


### [34] [AIVD: Adaptive Edge-Cloud Collaboration for Accurate and Efficient Industrial Visual Detection](https://arxiv.org/abs/2601.04734)
*Yunqing Hu,Zheming Yang,Chang Zhao,Qi Guo,Meng Gao,Pengcheng Li,Wen Ji*

Main category: cs.CV

TL;DR: AIVD框架通过轻量级边缘检测器与云端MLLM的协作，实现了精确目标定位和高质量语义生成，解决了MLLM在精确定位和边缘部署中的挑战。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在语义理解和视觉推理方面表现出色，但在精确定位和资源受限的边缘-云端部署方面仍面临挑战。

Method: 提出AIVD框架，包含视觉-语义协同增强的高效微调策略和异构资源感知的动态调度算法。

Result: AIVD显著降低了资源消耗，同时提升了MLLM的分类性能和语义生成质量，调度策略在不同场景下实现了更高的吞吐量和更低延迟。

Conclusion: 该框架有效解决了MLLM在边缘计算环境中的部署难题，为实际应用提供了可行的解决方案。

Abstract: Multimodal large language models (MLLMs) demonstrate exceptional capabilities in semantic understanding and visual reasoning, yet they still face challenges in precise object localization and resource-constrained edge-cloud deployment. To address this, this paper proposes the AIVD framework, which achieves unified precise localization and high-quality semantic generation through the collaboration between lightweight edge detectors and cloud-based MLLMs. To enhance the cloud MLLM's robustness against edge cropped-box noise and scenario variations, we design an efficient fine-tuning strategy with visual-semantic collaborative augmentation, significantly improving classification accuracy and semantic consistency. Furthermore, to maintain high throughput and low latency across heterogeneous edge devices and dynamic network conditions, we propose a heterogeneous resource-aware dynamic scheduling algorithm. Experimental results demonstrate that AIVD substantially reduces resource consumption while improving MLLM classification performance and semantic generation quality. The proposed scheduling strategy also achieves higher throughput and lower latency across diverse scenarios.

</details>


### [35] [Skeletonization-Based Adversarial Perturbations on Large Vision Language Model's Mathematical Text Recognition](https://arxiv.org/abs/2601.04752)
*Masatomo Yoshida,Haruto Namura,Nicola Adami,Masahiro Okuda*

Main category: cs.CV

TL;DR: 本文提出了一种利用骨架化减少搜索空间的新型对抗攻击方法，专门针对包含文本（特别是数学公式）的图像，评估基础模型的视觉能力和局限性。


<details>
  <summary>Details</summary>
Motivation: 探索基础模型的视觉能力和局限性，特别是针对复杂结构（如数学公式）的图像理解能力。

Method: 采用骨架化技术来有效减少对抗攻击的搜索空间，专注于文本图像特别是数学公式图像，通过LaTeX转换和结构分析进行详细评估。

Result: 方法在ChatGPT等实际应用中表现出有效性，揭示了模型在视觉解释和推理能力方面的特点。

Conclusion: 该对抗攻击方法为理解基础模型的视觉处理能力提供了新视角，具有实际应用价值。

Abstract: This work explores the visual capabilities and limitations of foundation models by introducing a novel adversarial attack method utilizing skeletonization to reduce the search space effectively. Our approach specifically targets images containing text, particularly mathematical formula images, which are more challenging due to their LaTeX conversion and intricate structure. We conduct a detailed evaluation of both character and semantic changes between original and adversarially perturbed outputs to provide insights into the models' visual interpretation and reasoning abilities. The effectiveness of our method is further demonstrated through its application to ChatGPT, which shows its practical implications in real-world scenarios.

</details>


### [36] [ProFuse: Efficient Cross-View Context Fusion for Open-Vocabulary 3D Gaussian Splatting](https://arxiv.org/abs/2601.04754)
*Yen-Jen Chiou,Wei-Tse Cheng,Yuan-Fu Yang*

Main category: cs.CV

TL;DR: ProFuse是一个高效的上下文感知框架，用于基于3D高斯泼溅的开放词汇3D场景理解，通过引入密集对应引导的预注册阶段和3D上下文提案，在无需渲染监督微调的情况下实现跨视图一致性和掩码内聚性。


<details>
  <summary>Details</summary>
Motivation: 解决现有开放词汇3D场景理解方法在跨视图一致性和掩码内聚性方面的不足，同时避免对预训练3DGS场景的依赖和渲染监督微调的需求。

Method: 1. 密集对应引导的预注册阶段初始化具有准确几何的高斯分布；2. 通过跨视图聚类联合构建3D上下文提案；3. 每个提案携带通过成员嵌入加权聚合获得的全局特征；4. 在直接注册过程中将特征融合到高斯分布上以保持跨视图的语言一致性。

Result: ProFuse在实现强大的开放词汇3DGS理解的同时，每个场景的语义附着仅需约5分钟完成，比当前最先进方法快两倍。

Conclusion: 该方法在保持几何精化的同时无需额外优化，为高效3D场景理解提供了有效解决方案。

Abstract: We present ProFuse, an efficient context-aware framework for open-vocabulary 3D scene understanding with 3D Gaussian Splatting (3DGS). The pipeline enhances cross-view consistency and intra-mask cohesion within a direct registration setup, adding minimal overhead and requiring no render-supervised fine-tuning. Instead of relying on a pretrained 3DGS scene, we introduce a dense correspondence-guided pre-registration phase that initializes Gaussians with accurate geometry while jointly constructing 3D Context Proposals via cross-view clustering. Each proposal carries a global feature obtained through weighted aggregation of member embeddings, and this feature is fused onto Gaussians during direct registration to maintain per-primitive language coherence across views. With associations established in advance, semantic fusion requires no additional optimization beyond standard reconstruction, and the model retains geometric refinement without densification. ProFuse achieves strong open-vocabulary 3DGS understanding while completing semantic attachment in about five minutes per scene, which is two times faster than SOTA.

</details>


### [37] [Segmentation-Driven Monocular Shape from Polarization based on Physical Model](https://arxiv.org/abs/2601.04776)
*Jinyu Zhang,Xu Ma,Weili Chen,Gonzalo R. Arce*

Main category: cs.CV

TL;DR: 本文提出了一种基于分割的单目偏振三维重建方法（SMSfP），通过将全局形状恢复分解为局部凸区域的重建，有效解决了偏振分析中的方位角模糊问题。


<details>
  <summary>Details</summary>
Motivation: 现有单目偏振三维重建方法存在方位角模糊问题，这是偏振分析的固有局限性，严重影响了重建精度和稳定性。

Method: 提出了偏振辅助自适应区域生长（PARG）分割策略，将全局凸性假设分解为局部凸区域；开发了多尺度融合凸性先验（MFCP）约束，确保局部表面一致性。

Result: 在合成和真实数据集上的实验表明，该方法在消歧精度和几何保真度方面相比现有物理基单目SfP技术有显著提升。

Conclusion: 该分割驱动的单目SfP框架通过局部重建策略有效抑制了方位角模糊，提高了三维重建的准确性和稳定性。

Abstract: Monocular shape-from-polarization (SfP) leverages the intrinsic relationship between light polarization properties and surface geometry to recover surface normals from single-view polarized images, providing a compact and robust approach for three-dimensional (3D) reconstruction. Despite its potential, existing monocular SfP methods suffer from azimuth angle ambiguity, an inherent limitation of polarization analysis, that severely compromises reconstruction accuracy and stability. This paper introduces a novel segmentation-driven monocular SfP (SMSfP) framework that reformulates global shape recovery into a set of local reconstructions over adaptively segmented convex sub-regions. Specifically, a polarization-aided adaptive region growing (PARG) segmentation strategy is proposed to decompose the global convexity assumption into locally convex regions, effectively suppressing azimuth ambiguities and preserving surface continuity. Furthermore, a multi-scale fusion convexity prior (MFCP) constraint is developed to ensure local surface consistency and enhance the recovery of fine textural and structural details. Extensive experiments on both synthetic and real-world datasets validate the proposed approach, showing significant improvements in disambiguation accuracy and geometric fidelity compared with existing physics-based monocular SfP techniques.

</details>


### [38] [GeM-VG: Towards Generalized Multi-image Visual Grounding with Multimodal Large Language Models](https://arxiv.org/abs/2601.04777)
*Shurong Zheng,Yousong Zhu,Hongyin Zhao,Fan Yang,Yufei Zhan,Ming Tang,Jinqiao Wang*

Main category: cs.CV

TL;DR: 本文提出了GeM-VG，一种能够进行广义多图像视觉定位的MLLM模型，通过系统分类多图像定位任务、构建MG-Data-240K数据集，并采用混合强化微调策略，显著提升了多图像和单图像定位性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多图像视觉定位方法存在单目标定位限制和实用任务类型有限的问题，缺乏对广义定位任务的统一建模。

Method: 1. 系统分类和整理多图像定位任务；2. 构建MG-Data-240K数据集；3. 提出结合思维链推理和直接回答的混合强化微调策略，采用R1-like算法和基于规则的奖励机制。

Result: 在多图像定位方面，在MIG-Bench和MC-Bench上分别比领先MLLMs提升2.0%和9.7%；在单图像定位方面，在ODINW上比基础模型提升9.1%；同时保持强大的多图像理解能力。

Conclusion: GeM-VG模型在广义多图像视觉定位方面表现出色，验证了所提出方法的有效性，为多模态大语言模型在多图像任务中的应用提供了新思路。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated impressive progress in single-image grounding and general multi-image understanding. Recently, some methods begin to address multi-image grounding. However, they are constrained by single-target localization and limited types of practical tasks, due to the lack of unified modeling for generalized grounding tasks. Therefore, we propose GeM-VG, an MLLM capable of Generalized Multi-image Visual Grounding. To support this, we systematically categorize and organize existing multi-image grounding tasks according to their reliance of cross-image cues and reasoning, and introduce the MG-Data-240K dataset, addressing the limitations of existing datasets regarding target quantity and image relation. To tackle the challenges of robustly handling diverse multi-image grounding tasks, we further propose a hybrid reinforcement finetuning strategy that integrates chain-of-thought (CoT) reasoning and direct answering, considering their complementary strengths. This strategy adopts an R1-like algorithm guided by a carefully designed rule-based reward, effectively enhancing the model's overall perception and reasoning capabilities. Extensive experiments demonstrate the superior generalized grounding capabilities of our model. For multi-image grounding, it outperforms the previous leading MLLMs by 2.0% and 9.7% on MIG-Bench and MC-Bench, respectively. In single-image grounding, it achieves a 9.1% improvement over the base model on ODINW. Furthermore, our model retains strong capabilities in general multi-image understanding.

</details>


### [39] [CounterVid: Counterfactual Video Generation for Mitigating Action and Temporal Hallucinations in Video-Language Models](https://arxiv.org/abs/2601.04778)
*Tobia Poppi,Burak Uzkent,Amanmeet Garg,Lucas Porto,Garin Kessler,Yezhou Yang,Marcella Cornia,Lorenzo Baraldi,Rita Cucchiara,Florian Schiffers*

Main category: cs.CV

TL;DR: 提出CounterVid框架，通过反事实视频生成解决视频语言模型中的幻觉问题，特别是动作和时序推理错误。使用MixDPO方法联合利用文本和视觉偏好进行优化，显著提升了时间排序能力。


<details>
  <summary>Details</summary>
Motivation: 现有视频语言模型容易产生幻觉，尤其是在动作和时序推理方面。现有缓解策略（如文本过滤或随机视频扰动）未能解决根本问题：过度依赖语言先验而非细粒度视觉动态。

Method: 1. 提出可扩展的反事实视频生成框架，合成仅在动作或时间结构上不同但保持场景上下文一致的视频；2. 结合多模态LLM进行动作提议和编辑指导，使用基于扩散的图像和视频模型大规模生成语义硬负样本；3. 构建CounterVid数据集（约26k偏好对）；4. 引入MixDPO方法，联合利用文本和视觉偏好进行直接偏好优化。

Result: 使用MixDPO对Qwen2.5-VL进行微调后，在时间排序方面取得一致改进，并能有效迁移到标准视频幻觉基准测试中。

Conclusion: 提出的CounterVid框架和MixDPO方法有效解决了视频语言模型的幻觉问题，特别是在动作识别和时序推理方面表现出显著提升，为多模态理解提供了新思路。

Abstract: Video-language models (VLMs) achieve strong multimodal understanding but remain prone to hallucinations, especially when reasoning about actions and temporal order. Existing mitigation strategies, such as textual filtering or random video perturbations, often fail to address the root cause: over-reliance on language priors rather than fine-grained visual dynamics. We propose a scalable framework for counterfactual video generation that synthesizes videos differing only in actions or temporal structure while preserving scene context. Our pipeline combines multimodal LLMs for action proposal and editing guidance with diffusion-based image and video models to generate semantic hard negatives at scale. Using this framework, we build CounterVid, a synthetic dataset of ~26k preference pairs targeting action recognition and temporal reasoning. We further introduce MixDPO, a unified Direct Preference Optimization approach that jointly leverages textual and visual preferences. Fine-tuning Qwen2.5-VL with MixDPO yields consistent improvements, notably in temporal ordering, and transfers effectively to standard video hallucination benchmarks. Code and models will be made publicly available.

</details>


### [40] [Defocus Aberration Theory Confirms Gaussian Model in Most Imaging Devices](https://arxiv.org/abs/2601.04779)
*Akbar Saadat*

Main category: cs.CV

TL;DR: 该论文验证了高斯模型在散焦深度估计中的适用性，通过几何光学和衍射极限光学分析，证明高斯模型在大多数成像设备中具有高精度（MAE小于1%）


<details>
  <summary>Details</summary>
Motivation: 解决从2D图像准确估计深度的根本挑战，特别是处理散焦模糊的建模问题，使深度估计问题变得可解

Method: 在几何光学框架内进行散焦分析，使用衍射极限光学理论验证高斯模型与实际模型的拟合精度，分析典型聚焦深度范围（1-100米）

Result: 对于大多数成像设备，高斯模型在最大深度变化10%的情况下，最大平均绝对误差小于1%，验证了模型的准确性和可靠性

Conclusion: 高斯模型是散焦算子的有效近似，特别适用于实时应用，因其数学简单性和计算效率而成为最优选择

Abstract: Over the past three decades, defocus has consistently provided groundbreaking depth information in scene images. However, accurately estimating depth from 2D images continues to be a persistent and fundamental challenge in the field of 3D recovery. Heuristic approaches involve with the ill-posed problem for inferring the spatial variant defocusing blur, as the desired blur cannot be distinguished from the inherent blur. Given a prior knowledge of the defocus model, the problem become well-posed with an analytic solution for the relative blur between two images, taken at the same viewpoint with different camera settings for the focus. The Gaussian model stands out as an optimal choice for real-time applications, due to its mathematical simplicity and computational efficiency. And theoretically, it is the only model can be applied at the same time to both the absolute blur caused by depth in a single image and the relative blur resulting from depth differences between two images. This paper introduces the settings, for conventional imaging devices, to ensure that the defocusing operator adheres to the Gaussian model. Defocus analysis begins within the framework of geometric optics and is conducted by defocus aberration theory in diffraction-limited optics to obtain the accuracy of fitting the actual model to its Gaussian approximation. The results for a typical set of focused depths between $1$ and $100$ meters, with a maximum depth variation of $10\%$ at the focused depth, confirm the Gaussian model's applicability for defocus operators in most imaging devices. The findings demonstrate a maximum Mean Absolute Error $(\!M\!A\!E)$ of less than $1\%$, underscoring the model's accuracy and reliability.

</details>


### [41] [SRU-Pix2Pix: A Fusion-Driven Generator Network for Medical Image Translation with Few-Shot Learning](https://arxiv.org/abs/2601.04785)
*Xihe Qiu,Yang Dai,Xiaoyu Tan,Sijia Li,Fenghao Sun,Lu Gan,Liang Liu*

Main category: cs.CV

TL;DR: 提出增强的Pix2Pix框架，集成SEResNet和U-Net++，在少样本条件下实现高质量MRI图像转换


<details>
  <summary>Details</summary>
Motivation: 解决MRI成像时间长、成本高、分辨率受限的问题，探索Pix2Pix在医学图像转换中的未开发潜力

Method: 结合Squeeze-and-Excitation Residual Networks（增强关键特征表示）和U-Net++（改进多尺度特征融合），使用简化的PatchGAN判别器

Result: 在少于500张图像的少样本条件下，该方法在多个MRI模态转换任务中实现一致的结构保真度和优越的图像质量，展现强泛化能力

Conclusion: 该方法为医学图像转换提供了Pix2Pix的有效扩展，具有临床应用潜力

Abstract: Magnetic Resonance Imaging (MRI) provides detailed tissue information, but its clinical application is limited by long acquisition time, high cost, and restricted resolution. Image translation has recently gained attention as a strategy to address these limitations. Although Pix2Pix has been widely applied in medical image translation, its potential has not been fully explored. In this study, we propose an enhanced Pix2Pix framework that integrates Squeeze-and-Excitation Residual Networks (SEResNet) and U-Net++ to improve image generation quality and structural fidelity. SEResNet strengthens critical feature representation through channel attention, while U-Net++ enhances multi-scale feature fusion. A simplified PatchGAN discriminator further stabilizes training and refines local anatomical realism. Experimental results demonstrate that under few-shot conditions with fewer than 500 images, the proposed method achieves consistent structural fidelity and superior image quality across multiple intra-modality MRI translation tasks, showing strong generalization ability. These results suggest an effective extension of Pix2Pix for medical image translation.

</details>


### [42] [Measurement-Consistent Langevin Corrector: A Remedy for Latent Diffusion Inverse Solvers](https://arxiv.org/abs/2601.04791)
*Lee Hyoseok,Sohwi Lim,Eunju Cha,Tae-Hyun Oh*

Main category: cs.CV

TL;DR: 本文提出了一种名为MCLC的校正模块，用于解决基于潜在扩散模型的逆求解器的不稳定性问题，通过测量一致的Langevin更新来稳定求解过程。


<details>
  <summary>Details</summary>
Motivation: 现有的潜在扩散逆求解器存在不稳定性，表现为不良伪影和质量下降。作者发现这种不稳定性源于求解器与真实反向扩散动态之间的差异。

Method: 提出测量一致的Langevin校正器（MCLC），这是一个基于理论基础的即插即用校正模块，通过测量一致的Langevin更新来修正基于LDM的逆求解器。与依赖线性流形假设的方法不同，MCLC无需此假设。

Result: 实验证明MCLC在多种图像恢复任务中有效，且与现有求解器兼容。作者还分析了斑点伪影并揭示了其根本原因。

Conclusion: MCLC是迈向更稳健的零样本逆问题求解器的关键步骤，能够显著提高求解器的稳定性和可靠性。

Abstract: With recent advances in generative models, diffusion models have emerged as powerful priors for solving inverse problems in each domain. Since Latent Diffusion Models (LDMs) provide generic priors, several studies have explored their potential as domain-agnostic zero-shot inverse solvers. Despite these efforts, existing latent diffusion inverse solvers suffer from their instability, exhibiting undesirable artifacts and degraded quality. In this work, we first identify the instability as a discrepancy between the solver's and true reverse diffusion dynamics, and show that reducing this gap stabilizes the solver. Building on this, we introduce Measurement-Consistent Langevin Corrector (MCLC), a theoretically grounded plug-and-play correction module that remedies the LDM-based inverse solvers through measurement-consistent Langevin updates. Compared to prior approaches that rely on linear manifold assumptions, which often do not hold in latent space, MCLC operates without this assumption, leading to more stable and reliable behavior. We experimentally demonstrate the effectiveness of MCLC and its compatibility with existing solvers across diverse image restoration tasks. Additionally, we analyze blob artifacts and offer insights into their underlying causes. We highlight that MCLC is a key step toward more robust zero-shot inverse problem solvers.

</details>


### [43] [PyramidalWan: On Making Pretrained Video Model Pyramidal for Efficient Inference](https://arxiv.org/abs/2601.04792)
*Denis Korzhenkov,Adil Karjauv,Animesh Karnewar,Mohsen Ghafoorian,Amirhossein Habibian*

Main category: cs.CV

TL;DR: 本文提出了一种将预训练扩散模型转换为金字塔模型的方法，通过低成本微调实现质量无损的转换，并研究比较了多种步数蒸馏策略以提升推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有的开源金字塔视频模型从头开始训练，在视觉逼真度上往往不如最先进的系统。本文旨在通过利用预训练模型来提升金字塔模型的性能。

Method: 开发了一个将预训练扩散模型转换为金字塔模型的流程，采用低成本微调方法，避免输出视频质量下降。同时研究比较了金字塔模型中的多种步数蒸馏策略。

Result: 成功实现了预训练模型到金字塔模型的无质量损失转换，并在推理效率方面取得了显著提升。

Conclusion: 该方法提供了一种高效的金字塔模型构建方案，能够在保持输出质量的同时显著降低计算成本。

Abstract: Recently proposed pyramidal models decompose the conventional forward and backward diffusion processes into multiple stages operating at varying resolutions. These models handle inputs with higher noise levels at lower resolutions, while less noisy inputs are processed at higher resolutions. This hierarchical approach significantly reduces the computational cost of inference in multi-step denoising models. However, existing open-source pyramidal video models have been trained from scratch and tend to underperform compared to state-of-the-art systems in terms of visual plausibility. In this work, we present a pipeline that converts a pretrained diffusion model into a pyramidal one through low-cost finetuning, achieving this transformation without degradation in quality of output videos. Furthermore, we investigate and compare various strategies for step distillation within pyramidal models, aiming to further enhance the inference efficiency. Our results are available at https://qualcomm-ai-research.github.io/PyramidalWan.

</details>


### [44] [Detector-Augmented SAMURAI for Long-Duration Drone Tracking](https://arxiv.org/abs/2601.04798)
*Tamara R. Lenhard,Andreas Weinmann,Hichem Snoussi,Tobias Koch*

Main category: cs.CV

TL;DR: 本文首次系统评估了SAMURAI基础模型在无人机跟踪中的潜力，并提出了一种检测器增强的扩展方法，在复杂城市环境中显著提高了跟踪鲁棒性，特别是在长时间序列和无人机进出场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前无人机跟踪研究有限且主要依赖传统运动模型，而基础模型如SAMURAI在其他领域表现出强大的类别无关跟踪性能，但其在无人机特定场景下的适用性尚未被研究。

Method: 提出了检测器增强的SAMURAI扩展方法，通过结合检测器信息来减轻对边界框初始化和序列长度的敏感性。

Result: 提出的扩展方法在复杂城市环境中显著提升了鲁棒性，特别是在长时间序列和无人机进出事件中。检测器信息的加入相比SAMURAI的零样本性能在多个数据集和指标上均获得一致提升，成功率最高提升+0.393，误报率最高降低-0.475。

Conclusion: SAMURAI基础模型在无人机跟踪中具有显著潜力，检测器增强的扩展方法能够有效提升跟踪性能，特别是在复杂城市环境和长时间序列场景下。

Abstract: Robust long-term tracking of drone is a critical requirement for modern surveillance systems, given their increasing threat potential. While detector-based approaches typically achieve strong frame-level accuracy, they often suffer from temporal inconsistencies caused by frequent detection dropouts. Despite its practical relevance, research on RGB-based drone tracking is still limited and largely reliant on conventional motion models. Meanwhile, foundation models like SAMURAI have established their effectiveness across other domains, exhibiting strong category-agnostic tracking performance. However, their applicability in drone-specific scenarios has not been investigated yet. Motivated by this gap, we present the first systematic evaluation of SAMURAI's potential for robust drone tracking in urban surveillance settings. Furthermore, we introduce a detector-augmented extension of SAMURAI to mitigate sensitivity to bounding-box initialization and sequence length. Our findings demonstrate that the proposed extension significantly improves robustness in complex urban environments, with pronounced benefits in long-duration sequences - especially under drone exit-re-entry events. The incorporation of detector cues yields consistent gains over SAMURAI's zero-shot performance across datasets and metrics, with success rate improvements of up to +0.393 and FNR reductions of up to -0.475.

</details>


### [45] [Integrated Framework for Selecting and Enhancing Ancient Marathi Inscription Images from Stone, Metal Plate, and Paper Documents](https://arxiv.org/abs/2601.04800)
*Bapu D. Chendage,Rajivkumar S. Mente*

Main category: cs.CV

TL;DR: 该论文提出了一种基于二值化和互补预处理技术的图像增强方法，用于去除污渍和增强模糊的古代文字，有效提高了古代马拉地铭文图像的可读性。


<details>
  <summary>Details</summary>
Motivation: 古代文字图像常因老化、环境因素等导致严重背景噪声、低对比度和退化，前景文字与背景视觉特征相似，使得铭文难以阅读。主要目标是改善此类退化古代图像的可读性。

Method: 采用基于二值化和互补预处理技术的图像增强方法，包括去除污渍和增强模糊古代文字的处理步骤。

Result: 实验结果表明，使用K-NN分类器时，对石头、金属板和文档文字的识别准确率分别达到55.7%、62%和65.6%；使用SVM分类器时，准确率分别为53.2%、59.5%和67.8%。

Conclusion: 所提出的增强方法在提高古代马拉地铭文图像可读性方面具有显著效果，验证了该方法的有效性。

Abstract: Ancient script images often suffer from severe background noise, low contrast, and degradation caused by aging and environmental effects. In many cases, the foreground text and background exhibit similar visual characteristics, making the inscriptions difficult to read. The primary objective of image enhancement is to improve the readability of such degraded ancient images. This paper presents an image enhancement approach based on binarization and complementary preprocessing techniques for removing stains and enhancing unclear ancient text. The proposed methods are evaluated on different types of ancient scripts, including inscriptions on stone, metal plates, and historical documents. Experimental results show that the proposed approach achieves classification accuracies of 55.7%, 62%, and 65.6% for stone, metal plate, and document scripts, respectively, using the K-Nearest Neighbor (K-NN) classifier. Using the Support Vector Machine (SVM) classifier, accuracies of 53.2%, 59.5%, and 67.8% are obtained. The results demonstrate the effectiveness of the proposed enhancement method in improving the readability of ancient Marathi inscription images.

</details>


### [46] [SOVABench: A Vehicle Surveillance Action Retrieval Benchmark for Multimodal Large Language Models](https://arxiv.org/abs/2601.04824)
*Oriol Rabasseda,Zenjie Li,Kamal Nasrollahi,Sergio Escalera*

Main category: cs.CV

TL;DR: 该论文提出了SOVABench基准测试，用于评估视频监控中的车辆动作识别能力，并开发了一个基于多模态大语言模型的训练免费框架来生成可解释的嵌入表示。


<details>
  <summary>Details</summary>
Motivation: 现有视频检索基准主要关注场景级相似性，缺乏对监控场景中动作辨别能力的评估，特别是在车辆相关动作识别方面存在空白。

Method: 1) 构建SOVABench真实监控数据集；2) 定义两种评估协议（跨动作辨别和时序方向理解）；3) 利用多模态大语言模型的视觉推理能力，开发训练免费框架生成可解释的嵌入表示。

Result: 实验表明，虽然人类观察者能直观区分动作差异，但现有最先进的视觉和多模态模型在此任务上仍面临挑战。提出的框架在SOVABench以及空间和计数基准测试上表现优异。

Conclusion: SOVABench填补了监控视频动作识别评估的空白，基于MLLM的框架为视频理解提供了有效的解决方案，代码和数据集已公开。

Abstract: Automatic identification of events and recurrent behavior analysis are critical for video surveillance. However, most existing content-based video retrieval benchmarks focus on scene-level similarity and do not evaluate the action discrimination required in surveillance. To address this gap, we introduce SOVABench (Surveillance Opposite Vehicle Actions Benchmark), a real-world retrieval benchmark built from surveillance footage and centered on vehicle-related actions. SOVABench defines two evaluation protocols (inter-pair and intra-pair) to assess cross-action discrimination and temporal direction understanding. Although action distinctions are generally intuitive for human observers, our experiments show that they remain challenging for state-of-the-art vision and multimodal models.
  Leveraging the visual reasoning and instruction-following capabilities of Multimodal Large Language Models (MLLMs), we present a training-free framework for producing interpretable embeddings from MLLM-generated descriptions for both images and videos. The framework achieves strong performance on SOVABench as well as on several spatial and counting benchmarks where contrastive Vision-Language Models often fail. The code, annotations, and instructions to construct the benchmark are publicly available.

</details>


### [47] [Character Detection using YOLO for Writer Identification in multiple Medieval books](https://arxiv.org/abs/2601.04834)
*Alessandra Scotto di Freca,Tiziana D Alessandro,Francesco Fontanella,Filippo Sarria,Claudio De Stefano*

Main category: cs.CV

TL;DR: 本文提出使用YOLO目标检测模型替代传统的模板匹配和CNN方法，用于中世纪手稿的抄写员识别，通过检测字母'a'来更准确地识别不同抄写员的笔迹。


<details>
  <summary>Details</summary>
Motivation: 解决中世纪手稿抄写员识别的难题，传统模板匹配技术需要设定合适阈值且存在局限性，需要更先进的方法来提高识别准确性和可靠性。

Method: 使用YOLOv5目标检测模型替代之前的模板匹配和CNN组合方法，专门检测字母'a'的出现，基于YOLO的置信度得分开发拒绝阈值系统。

Result: YOLO能够提取更多字母实例，实现更准确的第二阶段分类，置信度得分为在未见手稿中实现可靠抄写员识别提供了基础。

Conclusion: YOLO模型在中世纪手稿抄写员识别任务中表现优于传统方法，为古文字学研究提供了更有效的数字工具。

Abstract: Paleography is the study of ancient and historical handwriting, its key objectives include the dating of manuscripts and understanding the evolution of writing. Estimating when a document was written and tracing the development of scripts and writing styles can be aided by identifying the individual scribes who contributed to a medieval manuscript. Although digital technologies have made significant progress in this field, the general problem remains unsolved and continues to pose open challenges. ... We previously proposed an approach focused on identifying specific letters or abbreviations that characterize each writer. In that study, we considered the letter "a", as it was widely present on all pages of text and highly distinctive, according to the suggestions of expert paleographers. We used template matching techniques to detect the occurrences of the character "a" on each page and the convolutional neural network (CNN) to attribute each instance to the correct scribe. Moving from the interesting results achieved from this previous system and being aware of the limitations of the template matching technique, which requires an appropriate threshold to work, we decided to experiment in the same framework with the use of the YOLO object detection model to identify the scribe who contributed to the writing of different medieval books. We considered the fifth version of YOLO to implement the YOLO object detection model, which completely substituted the template matching and CNN used in the previous work. The experimental results demonstrate that YOLO effectively extracts a greater number of letters considered, leading to a more accurate second-stage classification. Furthermore, the YOLO confidence score provides a foundation for developing a system that applies a rejection threshold, enabling reliable writer identification even in unseen manuscripts.

</details>


### [48] [DivAS: Interactive 3D Segmentation of NeRFs via Depth-Weighted Voxel Aggregation](https://arxiv.org/abs/2601.04860)
*Ayush Pande*

Main category: cs.CV

TL;DR: DivAS是一个无需优化的全交互式NeRF分割框架，通过2D SAM掩码和NeRF深度先验实现快速3D分割，比优化方法快2-2.5倍


<details>
  <summary>Details</summary>
Motivation: 现有NeRF分割方法需要缓慢的逐场景优化训练，牺牲了2D基础模型的零样本能力，需要更高效的交互式解决方案

Method: 基于GUI工作流，使用用户点提示生成2D SAM掩码，利用NeRF深度先验进行精炼，通过自定义CUDA内核在200ms内将多视角掩码聚合到统一3D体素网格

Result: 在Mip-NeRF 360°和LLFF数据集上，DivAS达到与优化方法相当的分割质量，端到端速度快2-2.5倍，排除用户提示时间后快一个数量级

Conclusion: DivAS证明了无需优化的交互式NeRF分割的可行性，为实时3D场景理解提供了高效解决方案

Abstract: Existing methods for segmenting Neural Radiance Fields (NeRFs) are often optimization-based, requiring slow per-scene training that sacrifices the zero-shot capabilities of 2D foundation models. We introduce DivAS (Depth-interactive Voxel Aggregation Segmentation), an optimization-free, fully interactive framework that addresses these limitations. Our method operates via a fast GUI-based workflow where 2D SAM masks, generated from user point prompts, are refined using NeRF-derived depth priors to improve geometric accuracy and foreground-background separation. The core of our contribution is a custom CUDA kernel that aggregates these refined multi-view masks into a unified 3D voxel grid in under 200ms, enabling real-time visual feedback. This optimization-free design eliminates the need for per-scene training. Experiments on Mip-NeRF 360° and LLFF show that DivAS achieves segmentation quality comparable to optimization-based methods, while being 2-2.5x faster end-to-end, and up to an order of magnitude faster when excluding user prompting time.

</details>


### [49] [Scaling Vision Language Models for Pharmaceutical Long Form Video Reasoning on Industrial GenAI Platform](https://arxiv.org/abs/2601.04891)
*Suyash Mishra,Qiang Li,Srikanth Patil,Satyanarayan Pati,Baddu Narendra*

Main category: cs.CV

TL;DR: 本文提出了一个工业级GenAI框架，用于处理制药领域的长视频多模态推理，分析了40多个VLM在现实约束下的性能瓶颈和效率提升。


<details>
  <summary>Details</summary>
Motivation: 现有VLM评估主要关注短视频和无限计算资源，而工业场景（如制药内容理解）需要在严格GPU、延迟和成本约束下处理长视频，现有方法难以扩展。

Method: 开发工业级大规模多模态推理架构，在40多个VLM上进行实证分析，使用Video-MME和MMBench基准以及包含25,326个视频的专有数据集，研究多模态性、注意力机制、时间推理和视频分割等关键因素。

Result: 在商用GPU上使用SDPA注意力实现3-8倍效率提升，多模态性在8/12任务领域（特别是长度相关任务）中表现改善，发现时间和关键帧检测在开源和闭源VLM中均存在明显瓶颈。

Conclusion: 本文不是提出新模型，而是刻画了当前VLM在现实部署约束下的实际限制、权衡和失败模式，为研究人员和从业者设计可扩展的多模态系统提供实用指导。

Abstract: Vision Language Models (VLMs) have shown strong performance on multimodal reasoning tasks, yet most evaluations focus on short videos and assume unconstrained computational resources. In industrial settings such as pharmaceutical content understanding, practitioners must process long-form videos under strict GPU, latency, and cost constraints, where many existing approaches fail to scale. In this work, we present an industrial GenAI framework that processes over 200,000 PDFs, 25,326 videos across eight formats (e.g., MP4, M4V, etc.), and 888 multilingual audio files in more than 20 languages. Our study makes three contributions: (i) an industrial large-scale architecture for multimodal reasoning in pharmaceutical domains; (ii) empirical analysis of over 40 VLMs on two leading benchmarks (Video-MME and MMBench) and proprietary dataset of 25,326 videos across 14 disease areas; and (iii) four findings relevant to long-form video reasoning: the role of multimodality, attention mechanism trade-offs, temporal reasoning limits, and challenges of video splitting under GPU constraints. Results show 3-8 times efficiency gains with SDPA attention on commodity GPUs, multimodality improving up to 8/12 task domains (especially length-dependent tasks), and clear bottlenecks in temporal alignment and keyframe detection across open- and closed-source VLMs. Rather than proposing a new "A+B" model, this paper characterizes practical limits, trade-offs, and failure patterns of current VLMs under realistic deployment constraints, and provide actionable guidance for both researchers and practitioners designing scalable multimodal systems for long-form video understanding in industrial domains.

</details>


### [50] [Rotation-Robust Regression with Convolutional Model Trees](https://arxiv.org/abs/2601.04899)
*Hongyi Li,William Ward Armstrong,Jun Xu*

Main category: cs.CV

TL;DR: 本文研究了使用卷积模型树（CMTs）进行图像输入的旋转鲁棒学习，通过几何感知的归纳偏置和部署时方向搜索来提高模型在平面旋转下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决图像输入在旋转变换下的鲁棒性问题，探索几何结构化的模型树如何通过部署时的几何变换来提升旋转不变性。

Method: 使用卷积模型树（CMTs），引入三种几何感知的划分方向偏置（卷积平滑、倾斜优势约束、基于重要性的剪枝），并在部署时采用方向搜索策略选择最优旋转角度。

Result: 方向搜索在严重旋转情况下能提高鲁棒性，但在接近标准方向时可能因置信度与正确性不匹配而产生负面影响。在MNIST数字识别任务中观察到一致趋势。

Conclusion: 基于置信度的方向选择对于模型树集成具有潜力但也存在局限性，几何结构化的模型树为旋转鲁棒学习提供了有前景的方向。

Abstract: We study rotation-robust learning for image inputs using Convolutional Model Trees (CMTs) [1], whose split and leaf coefficients can be structured on the image grid and transformed geometrically at deployment time. In a controlled MNIST setting with a rotation-invariant regression target, we introduce three geometry-aware inductive biases for split directions -- convolutional smoothing, a tilt dominance constraint, and importance-based pruning -- and quantify their impact on robustness under in-plane rotations. We further evaluate a deployment-time orientation search that selects a discrete rotation maximizing a forest-level confidence proxy without updating model parameters. Orientation search improves robustness under severe rotations but can be harmful near the canonical orientation when confidence is misaligned with correctness. Finally, we observe consistent trends on MNIST digit recognition implemented as one-vs-rest regression, highlighting both the promise and limitations of confidence-based orientation selection for model-tree ensembles.

</details>


### [51] [Prototypicality Bias Reveals Blindspots in Multimodal Evaluation Metrics](https://arxiv.org/abs/2601.04946)
*Subhadeep Roy,Gagan Bhatia,Steffen Eger*

Main category: cs.CV

TL;DR: 本文研究了多模态评估中的原型性偏差问题，发现现有自动评估指标倾向于选择视觉上典型但语义错误的图像，而不是语义正确但非典型的图像。作者提出了ProtoBias基准和ProtoScore新指标来解决这一问题。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像模型的自动评估指标存在原型性偏差，即倾向于选择视觉上典型但语义错误的图像，而不是语义正确但非典型的图像。这种偏差可能导致评估结果不准确，无法真实反映模型的语义理解能力。

Method: 作者构建了ProtoBias基准，包含动物、物体和人口统计图像，将语义正确但非典型的图像与语义错误但典型的对抗性图像配对。然后提出了ProtoScore，一个7B参数的鲁棒评估指标。

Result: 实验表明，CLIPScore、PickScore和基于VQA的指标等广泛使用的指标经常错误排名这些图像对，而人类评估始终更倾向于语义正确性。ProtoScore显著降低了失败率，运行速度比GPT-5快几个数量级。

Conclusion: 现有自动评估指标存在严重的原型性偏差，需要开发更注重语义正确性的新指标。ProtoScore在保持高效的同时，接近了更大规模闭源模型的鲁棒性。

Abstract: Automatic metrics are now central to evaluating text-to-image models, often substituting for human judgment in benchmarking and large-scale filtering. However, it remains unclear whether these metrics truly prioritize semantic correctness or instead favor visually and socially prototypical images learned from biased data distributions. We identify and study \emph{prototypicality bias} as a systematic failure mode in multimodal evaluation. We introduce a controlled contrastive benchmark \textsc{\textbf{ProtoBias}} (\textit{\textbf{Proto}typical \textbf{Bias}}), spanning Animals, Objects, and Demography images, where semantically correct but non-prototypical images are paired with subtly incorrect yet prototypical adversarial counterparts. This setup enables a directional evaluation of whether metrics follow textual semantics or default to prototypes. Our results show that widely used metrics, including CLIPScore, PickScore, and VQA-based scores, frequently misrank these pairs, while even LLM-as-Judge systems exhibit uneven robustness in socially grounded cases. Human evaluations consistently favour semantic correctness with larger decision margins. Motivated by these findings, we propose \textbf{\textsc{ProtoScore}}, a robust 7B-parameter metric that substantially reduces failure rates and suppresses misranking, while running at orders of magnitude faster than the inference time of GPT-5, approaching the robustness of much larger closed-source judges.

</details>


### [52] [TEA: Temporal Adaptive Satellite Image Semantic Segmentation](https://arxiv.org/abs/2601.04956)
*Juyuan Kang,Hao Zhu,Yan Zhu,Wei Zhang,Jianing Chen,Tianxiang Xiao,Yike Ma,Hao Jiang,Feng Dai*

Main category: cs.CV

TL;DR: 提出TEA方法解决卫星图像时间序列分割在不同时间长度场景下的泛化问题，通过教师-学生模型实现知识迁移和自适应时间输入


<details>
  <summary>Details</summary>
Motivation: 现有方法在固定时间序列长度下表现良好，但忽略了模型在不同时间长度场景下的泛化能力，导致在变长时间序列上分割效果差

Method: 提出TEA方法：1）使用教师模型封装全局序列知识指导学生模型；2）通过中间嵌入、原型和软标签实现知识迁移；3）动态聚合学生模型防止知识遗忘；4）引入全序列重构作为辅助任务

Result: 在常见基准测试上，该方法在不同时间长度输入下都带来了显著改进

Conclusion: TEA方法有效增强了模型在变长时间序列场景下的鲁棒性和分割性能

Abstract: Crop mapping based on satellite images time-series (SITS) holds substantial economic value in agricultural production settings, in which parcel segmentation is an essential step. Existing approaches have achieved notable advancements in SITS segmentation with predetermined sequence lengths. However, we found that these approaches overlooked the generalization capability of models across scenarios with varying temporal length, leading to markedly poor segmentation results in such cases. To address this issue, we propose TEA, a TEmporal Adaptive SITS semantic segmentation method to enhance the model's resilience under varying sequence lengths. We introduce a teacher model that encapsulates the global sequence knowledge to guide a student model with adaptive temporal input lengths. Specifically, teacher shapes the student's feature space via intermediate embedding, prototypes and soft label perspectives to realize knowledge transfer, while dynamically aggregating student model to mitigate knowledge forgetting. Finally, we introduce full-sequence reconstruction as an auxiliary task to further enhance the quality of representations across inputs of varying temporal lengths. Through extensive experiments, we demonstrate that our method brings remarkable improvements across inputs of different temporal lengths on common benchmarks. Our code will be publicly available.

</details>


### [53] [SparseLaneSTP: Leveraging Spatio-Temporal Priors with Sparse Transformers for 3D Lane Detection](https://arxiv.org/abs/2601.04968)
*Maximilian Pittner,Joel Janai,Mario Faigle,Alexandru Paul Condurache*

Main category: cs.CV

TL;DR: SparseLaneSTP是一种新颖的稀疏车道检测方法，通过集成车道几何特性和时间信息，结合新的时空注意力机制和连续车道表示，在3D车道检测任务中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统密集BEV方法特征表示错误对齐问题，以及现有稀疏方法忽略车道先验知识和历史观测信息的问题。

Method: 提出稀疏车道变换器，集成车道结构几何特性和时间信息，引入车道特定时空注意力机制、连续车道表示和时间正则化。

Result: 在所有检测和误差指标上均达到最先进性能，并在新提出的精确3D车道数据集上验证了有效性。

Conclusion: SparseLaneSTP通过有效利用车道先验和时间信息，显著提升了3D车道检测的准确性和鲁棒性。

Abstract: 3D lane detection has emerged as a critical challenge in autonomous driving, encompassing identification and localization of lane markings and the 3D road surface. Conventional 3D methods detect lanes from dense birds-eye-viewed (BEV) features, though erroneous transformations often result in a poor feature representation misaligned with the true 3D road surface. While recent sparse lane detectors have surpassed dense BEV approaches, they completely disregard valuable lane-specific priors. Furthermore, existing methods fail to utilize historic lane observations, which yield the potential to resolve ambiguities in situations of poor visibility. To address these challenges, we present SparseLaneSTP, a novel method that integrates both geometric properties of the lane structure and temporal information into a sparse lane transformer. It introduces a new lane-specific spatio-temporal attention mechanism, a continuous lane representation tailored for sparse architectures as well as temporal regularization. Identifying weaknesses of existing 3D lane datasets, we also introduce a precise and consistent 3D lane dataset using a simple yet effective auto-labeling strategy. Our experimental section proves the benefits of our contributions and demonstrates state-of-the-art performance across all detection and error metrics on existing 3D lane detection benchmarks as well as on our novel dataset.

</details>


### [54] [OceanSplat: Object-aware Gaussian Splatting with Trinocular View Consistency for Underwater Scene Reconstruction](https://arxiv.org/abs/2601.04984)
*Minseong Kweon,Jinsun Park*

Main category: cs.CV

TL;DR: OceanSplat是一种基于3D高斯泼溅的新方法，用于在水下环境中准确表示3D几何结构，通过三目视图一致性约束和自监督深度正则化来解决水下光学退化问题。


<details>
  <summary>Details</summary>
Motivation: 解决水下场景中由于光学退化导致的多视图不一致性问题，以及散射介质引起的浮点伪影问题，实现对水下物体几何结构的鲁棒表示。

Method: 1) 通过水平垂直平移相机视图并反向变形实现三目视图一致性约束；2) 利用平移视图生成合成极线深度先验作为自监督深度正则化器；3) 提出基于深度和视角方向的alpha调整机制，抑制介质诱导基元的形成。

Result: 在真实水下和模拟场景上的实验表明，OceanSplat在散射介质中的场景重建和恢复方面显著优于现有方法，有效减少浮点伪影。

Conclusion: 该方法成功将3D高斯从散射介质中解耦，实现了对水下物体几何结构的鲁棒表示，为水下3D重建提供了有效解决方案。

Abstract: We introduce OceanSplat, a novel 3D Gaussian Splatting-based approach for accurately representing 3D geometry in underwater scenes. To overcome multi-view inconsistencies caused by underwater optical degradation, our method enforces trinocular view consistency by rendering horizontally and vertically translated camera views relative to each input view and aligning them via inverse warping. Furthermore, these translated camera views are used to derive a synthetic epipolar depth prior through triangulation, which serves as a self-supervised depth regularizer. These geometric constraints facilitate the spatial optimization of 3D Gaussians and preserve scene structure in underwater environments. We also propose a depth-aware alpha adjustment that modulates the opacity of 3D Gaussians during early training based on their $z$-component and viewing direction, deterring the formation of medium-induced primitives. With our contributions, 3D Gaussians are disentangled from the scattering medium, enabling robust representation of object geometry and significantly reducing floating artifacts in reconstructed underwater scenes. Experiments on real-world underwater and simulated scenes demonstrate that OceanSplat substantially outperforms existing methods for both scene reconstruction and restoration in scattering media.

</details>


### [55] [Higher-Order Adversarial Patches for Real-Time Object Detectors](https://arxiv.org/abs/2601.04991)
*Jens Bayer,Stefan Becker,David Münch,Michael Arens,Jürgen Beyerer*

Main category: cs.CV

TL;DR: 本文研究了高阶对抗性攻击对目标检测器的影响，通过连续训练攻击模式和使用对抗性训练来强化目标检测器。结果表明高阶对抗性补丁具有更强的泛化能力，且仅靠对抗性训练不足以有效防御此类攻击。


<details>
  <summary>Details</summary>
Motivation: 高阶对抗性攻击可以被视为猫鼠游戏的结果——涉及持续追逐、接近捕获和重复逃脱的复杂行为。这个比喻最好地描述了对抗性攻击模式和对抗性训练的持久循环训练。

Method: 选择YOLOv10目标检测器作为代表，使用对抗性补丁进行规避攻击，通过连续训练攻击模式和对抗性训练来研究高阶对抗性攻击的影响。

Result: 高阶对抗性补丁不仅影响直接训练的目标检测器，而且与低阶对抗性补丁相比具有更强的泛化能力。结果还表明仅靠对抗性训练不足以有效强化目标检测器抵御此类攻击。

Conclusion: 高阶对抗性攻击对目标检测器构成严重威胁，需要更有效的防御策略，而不仅仅是依赖对抗性训练。

Abstract: Higher-order adversarial attacks can directly be considered the result of a cat-and-mouse game -- an elaborate action involving constant pursuit, near captures, and repeated escapes. This idiom describes the enduring circular training of adversarial attack patterns and adversarial training the best. The following work investigates the impact of higher-order adversarial attacks on object detectors by successively training attack patterns and hardening object detectors with adversarial training. The YOLOv10 object detector is chosen as a representative, and adversarial patches are used in an evasion attack manner. Our results indicate that higher-order adversarial patches are not only affecting the object detector directly trained on but rather provide a stronger generalization capacity compared to lower-order adversarial patches. Moreover, the results highlight that solely adversarial training is not sufficient to harden an object detector efficiently against this kind of adversarial attack. Code: https://github.com/JensBayer/HigherOrder

</details>


### [56] [Patch-based Representation and Learning for Efficient Deformation Modeling](https://arxiv.org/abs/2601.05035)
*Ruochen Chen,Thuy Tran,Shaifali Parashar*

Main category: cs.CV

TL;DR: PolyFit是一种基于面片拟合的曲面表示方法，通过局部拟合jet函数实现高效学习，可应用于曲面变形任务，在形状模板重建和服装悬挂等应用中表现出高效性和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的曲面变形方法需要优化每个顶点的自由度，计算成本高。本文旨在开发一种更高效的曲面表示方法，通过紧凑的jet系数更新来实现快速变形。

Method: 提出PolyFit表示方法，通过局部拟合jet函数学习曲面表示。采用监督学习从解析函数和真实数据中学习，支持测试时优化。应用于形状模板重建和服装悬挂两个任务。

Result: 在形状模板重建任务中，比离线物理求解器更快，比物理引导的神经模拟器更准确；在服装悬挂任务中，推理速度比基线方法快一个数量级，且具有网格和服装无关的泛化能力。

Conclusion: PolyFit提供了一种高效的曲面表示和变形框架，在保持准确性的同时显著提升了计算效率，适用于计算机视觉和图形学中的多种下游任务。

Abstract: In this paper, we present a patch-based representation of surfaces, PolyFit, which is obtained by fitting jet functions locally on surface patches. Such a representation can be learned efficiently in a supervised fashion from both analytic functions and real data. Once learned, it can be generalized to various types of surfaces. Using PolyFit, the surfaces can be efficiently deformed by updating a compact set of jet coefficients rather than optimizing per-vertex degrees of freedom for many downstream tasks in computer vision and graphics. We demonstrate the capabilities of our proposed methodologies with two applications: 1) Shape-from-template (SfT): where the goal is to deform the input 3D template of an object as seen in image/video. Using PolyFit, we adopt test-time optimization that delivers competitive accuracy while being markedly faster than offline physics-based solvers, and outperforms recent physics-guided neural simulators in accuracy at modest additional runtime. 2) Garment draping. We train a self-supervised, mesh- and garment-agnostic model that generalizes across resolutions and garment types, delivering up to an order-of-magnitude faster inference than strong baselines.

</details>


### [57] [From Understanding to Engagement: Personalized pharmacy Video Clips via Vision Language Models (VLMs)](https://arxiv.org/abs/2601.05059)
*Suyash Mishra,Qiang Li,Srikanth Patil,Anubhav Girdhar*

Main category: cs.CV

TL;DR: 本文提出了一种领域适应的视频到视频片段生成框架，结合音频语言模型和视觉语言模型，用于制药行业的多模态内容处理，实现了3-4倍的速度提升和4倍的成本降低。


<details>
  <summary>Details</summary>
Motivation: 传统手动标注异构数据模态存在不一致性、质量下降和效率低下的问题，特别是在处理长视频和音频数据时挑战更大。

Method: 开发了Cut & Merge算法实现平滑过渡和音视频对齐，基于角色定义和提示注入的个性化机制，以及成本高效的端到端流水线策略。

Result: 在Video MME基准测试和16,159个制药视频数据集上评估，显示速度提升3-4倍，成本降低4倍，剪辑连贯性得分(0.348)和信息性得分(0.721)优于现有VLM基线。

Conclusion: 该方法为生命科学领域提供了透明、可定制且符合监管要求的视频摘要解决方案，具有显著的应用潜力。

Abstract: Vision Language Models (VLMs) are poised to revolutionize the digital transformation of pharmacyceutical industry by enabling intelligent, scalable, and automated multi-modality content processing. Traditional manual annotation of heterogeneous data modalities (text, images, video, audio, and web links), is prone to inconsistencies, quality degradation, and inefficiencies in content utilization. The sheer volume of long video and audio data further exacerbates these challenges, (e.g. long clinical trial interviews and educational seminars).
  Here, we introduce a domain adapted Video to Video Clip Generation framework that integrates Audio Language Models (ALMs) and Vision Language Models (VLMs) to produce highlight clips. Our contributions are threefold: (i) a reproducible Cut & Merge algorithm with fade in/out and timestamp normalization, ensuring smooth transitions and audio/visual alignment; (ii) a personalization mechanism based on role definition and prompt injection for tailored outputs (marketing, training, regulatory); (iii) a cost efficient e2e pipeline strategy balancing ALM/VLM enhanced processing. Evaluations on Video MME benchmark (900) and our proprietary dataset of 16,159 pharmacy videos across 14 disease areas demonstrate 3 to 4 times speedup, 4 times cost reduction, and competitive clip quality. Beyond efficiency gains, we also report our methods improved clip coherence scores (0.348) and informativeness scores (0.721) over state of the art VLM baselines (e.g., Gemini 2.5 Pro), highlighting the potential of transparent, custom extractive, and compliance supporting video summarization for life sciences.

</details>


### [58] [UniLiPs: Unified LiDAR Pseudo-Labeling with Geometry-Grounded Dynamic Scene Decomposition](https://arxiv.org/abs/2601.05105)
*Filippo Ghilotti,Samuel Brucker,Nahku Saidy,Matteo Matteucci,Mario Bijelic,Felix Heide*

Main category: cs.CV

TL;DR: 提出了一种无监督多模态伪标签方法，利用LiDAR扫描的时间几何一致性，将文本和2D视觉基础模型的线索直接提升到3D空间，无需人工标注。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶应用中未标注LiDAR数据利用率低的问题，克服人工标注成本高的障碍，通过时间几何一致性实现无监督3D感知。

Method: 基于时间累积LiDAR地图学习强几何先验，采用新颖的迭代更新规则强制执行联合几何-语义一致性，并通过不一致性检测移动物体。

Result: 在三个数据集上展示了稳健的泛化能力，相比现有方法表现更好，即使少量几何一致的稠密LiDAR也能显著改善深度预测性能（80-150米范围MAE提升51.5%，150-250米范围提升22.0%）。

Conclusion: 该方法成功实现了无监督的3D语义标签、3D边界框和稠密LiDAR扫描生成，为自动驾驶感知研究提供了高效且成本低廉的解决方案。

Abstract: Unlabeled LiDAR logs, in autonomous driving applications, are inherently a gold mine of dense 3D geometry hiding in plain sight - yet they are almost useless without human labels, highlighting a dominant cost barrier for autonomous-perception research. In this work we tackle this bottleneck by leveraging temporal-geometric consistency across LiDAR sweeps to lift and fuse cues from text and 2D vision foundation models directly into 3D, without any manual input. We introduce an unsupervised multi-modal pseudo-labeling method relying on strong geometric priors learned from temporally accumulated LiDAR maps, alongside with a novel iterative update rule that enforces joint geometric-semantic consistency, and vice-versa detecting moving objects from inconsistencies. Our method simultaneously produces 3D semantic labels, 3D bounding boxes, and dense LiDAR scans, demonstrating robust generalization across three datasets. We experimentally validate that our method compares favorably to existing semantic segmentation and object detection pseudo-labeling methods, which often require additional manual supervision. We confirm that even a small fraction of our geometrically consistent, densified LiDAR improves depth prediction by 51.5% and 22.0% MAE in the 80-150 and 150-250 meters range, respectively.

</details>


### [59] [From Rays to Projections: Better Inputs for Feed-Forward View Synthesis](https://arxiv.org/abs/2601.05116)
*Zirui Wu,Zeren Jiang,Martin R. Oswald,Jie Song*

Main category: cs.CV

TL;DR: 本文提出了一种投影条件化方法，将视图合成任务从射线空间的几何回归问题转化为目标视图的图像到图像翻译问题，并通过掩码自编码预训练策略提高模型的几何一致性和生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有的前馈视图合成模型使用Plücker射线图编码相机参数，这种方法与任意世界坐标系绑定，对小的相机变换敏感，破坏了几何一致性。本文旨在寻找更稳健的输入条件来提升视图合成的鲁棒性和一致性。

Method: 提出投影条件化方法，用目标视图的投影提示替代原始相机参数，提供稳定的2D输入。同时引入针对该提示的掩码自编码预训练策略，允许使用大规模未校准数据进行预训练。

Result: 该方法在视图一致性基准测试中相比射线条件化基线显示出更高的保真度和更强的跨视图一致性，在标准新视图合成基准测试中达到了最先进的生成质量。

Conclusion: 投影条件化将视图合成任务重新定义为更稳健的图像到图像翻译问题，结合掩码自编码预训练，显著提高了模型的几何一致性和生成性能。

Abstract: Feed-forward view synthesis models predict a novel view in a single pass with minimal 3D inductive bias. Existing works encode cameras as Plücker ray maps, which tie predictions to the arbitrary world coordinate gauge and make them sensitive to small camera transformations, thereby undermining geometric consistency. In this paper, we ask what inputs best condition a model for robust and consistent view synthesis. We propose projective conditioning, which replaces raw camera parameters with a target-view projective cue that provides a stable 2D input. This reframes the task from a brittle geometric regression problem in ray space to a well-conditioned target-view image-to-image translation problem. Additionally, we introduce a masked autoencoding pretraining strategy tailored to this cue, enabling the use of large-scale uncalibrated data for pretraining. Our method shows improved fidelity and stronger cross-view consistency compared to ray-conditioned baselines on our view-consistency benchmark. It also achieves state-of-the-art quality on standard novel view synthesis benchmarks.

</details>


### [60] [Re-Align: Structured Reasoning-guided Alignment for In-Context Image Generation and Editing](https://arxiv.org/abs/2601.05124)
*Runze He,Yiji Cheng,Tiankai Hang,Zhimin Li,Yu Xu,Zijin Yin,Shiyi Zhang,Wenxun Dai,Penghui Du,Ao Ma,Chunyu Wang,Qinglin Lu,Jizhong Han,Jiao Dai*

Main category: cs.CV

TL;DR: Re-Align是一个统一框架，通过结构化推理引导的对齐来弥合理解和生成之间的差距，提升上下文图像生成和编辑任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的统一多模态模型虽然具有强大的理解能力，但这些优势在图像生成任务中未能有效转化，导致用户意图理解和执行不准确。

Method: 提出In-Context Chain-of-Thought (IC-CoT)结构化推理范式，解耦语义引导和参考关联；引入基于替代奖励的强化学习训练方案，衡量结构化推理文本与生成图像的对齐度。

Result: 大量实验验证Re-Align在模型规模和资源相当的情况下，在上下文图像生成和编辑任务上都优于竞争方法。

Conclusion: Re-Align通过结构化推理引导的对齐机制有效提升了多模态模型在图像生成任务中的性能，证明了该方法在理解和生成之间建立桥梁的有效性。

Abstract: In-context image generation and editing (ICGE) enables users to specify visual concepts through interleaved image-text prompts, demanding precise understanding and faithful execution of user intent. Although recent unified multimodal models exhibit promising understanding capabilities, these strengths often fail to transfer effectively to image generation. We introduce Re-Align, a unified framework that bridges the gap between understanding and generation through structured reasoning-guided alignment. At its core lies the In-Context Chain-of-Thought (IC-CoT), a structured reasoning paradigm that decouples semantic guidance and reference association, providing clear textual target and mitigating confusion among reference images. Furthermore, Re-Align introduces an effective RL training scheme that leverages a surrogate reward to measure the alignment between structured reasoning text and the generated image, thereby improving the model's overall performance on ICGE tasks. Extensive experiments verify that Re-Align outperforms competitive methods of comparable model scale and resources on both in-context image generation and editing tasks.

</details>


### [61] [VERSE: Visual Embedding Reduction and Space Exploration. Clustering-Guided Insights for Training Data Enhancement in Visually-Rich Document Understanding](https://arxiv.org/abs/2601.05125)
*Ignacio de Rodrigo,Alvaro J. Lopez-Lopez,Jaime Boal*

Main category: cs.CV

TL;DR: VERSE是一种分析视觉语言模型在视觉丰富文档理解中应用的方法，通过探索视觉嵌入空间来可视化潜在表示、识别问题区域并生成合成数据以提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在视觉丰富文档理解中存在性能瓶颈，需要一种方法来分析模型内部表示并针对性改进，特别是在识别和修复错误倾向区域方面。

Method: VERSE通过可视化视觉嵌入空间的潜在表示来评估模型可行性，识别问题区域，并生成包含特定视觉特征的合成数据（MERIT数据集）来增强模型在这些区域的表现。

Result: 在MERIT Secret数据集上的评估显示，VERSE能有效识别与错误倾向相关的视觉特征，使用这些特征重新训练模型显著提升了F1性能且不损害泛化能力。优化后的本地模型（Donut、Idefics2）性能达到或超过SaaS解决方案（GPT-4、Pixtral）。

Conclusion: VERSE为视觉语言模型提供了一种有效的分析和改进方法，通过针对性数据增强显著提升性能，证明了本地模型经过优化后能够与商业SaaS解决方案竞争。

Abstract: This work introduces VERSE, a methodology for analyzing and improving Vision-Language Models applied to Visually-rich Document Understanding by exploring their visual embedding space. VERSE enables the visualization of latent representations, supporting the assessment of model feasibility. It also facilitates the identification of problematic regions and guides the generation of synthetic data to enhance performance in those clusters. We validate the methodology by training on the synthetic MERIT Dataset and evaluating on its real-world counterpart, MERIT Secret. Results show that VERSE helps uncover the visual features associated with error-prone clusters, and that retraining with samples containing these features substantially boosts F1 performance without degrading generalization. Furthermore, we demonstrate that on-premise models such as Donut and Idefics2, when optimized with VERSE, match or even surpass the performance of SaaS solutions like GPT-4 and Pixtral.

</details>


### [62] [VerseCrafter: Dynamic Realistic Video World Model with 4D Geometric Control](https://arxiv.org/abs/2601.05138)
*Sixiao Zheng,Minghao Yin,Wenbo Hu,Xiaoyu Li,Ying Shan,Yanwei Fu*

Main category: cs.CV

TL;DR: VerseCrafter是一个4D感知的视频世界模型，通过4D几何控制表示实现对相机和物体运动的精确统一控制，解决了现有方法在2D图像平面上难以精确控制动态的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有视频世界模型难以提供对相机和多物体运动的统一精确控制，因为视频本质上是2D投影平面的动态，缺乏对3D几何世界的理解。

Method: 提出4D几何控制表示，通过静态背景点云和每物体3D高斯轨迹编码世界状态；开发自动数据引擎从野外视频提取4D标注数据；将4D控制渲染为预训练视频扩散模型的调节信号。

Result: 能够生成高保真、视角一致的视频，精确遵循指定的动态控制，提供灵活、类别无关的替代方案，优于刚性边界框或参数化模型。

Conclusion: VerseCrafter通过4D几何世界状态表示解决了视频世界模型的控制精度问题，为动态环境模拟提供了新的解决方案。

Abstract: Video world models aim to simulate dynamic, real-world environments, yet existing methods struggle to provide unified and precise control over camera and multi-object motion, as videos inherently operate dynamics in the projected 2D image plane. To bridge this gap, we introduce VerseCrafter, a 4D-aware video world model that enables explicit and coherent control over both camera and object dynamics within a unified 4D geometric world state. Our approach is centered on a novel 4D Geometric Control representation, which encodes the world state through a static background point cloud and per-object 3D Gaussian trajectories. This representation captures not only an object's path but also its probabilistic 3D occupancy over time, offering a flexible, category-agnostic alternative to rigid bounding boxes or parametric models. These 4D controls are rendered into conditioning signals for a pretrained video diffusion model, enabling the generation of high-fidelity, view-consistent videos that precisely adhere to the specified dynamics. Unfortunately, another major challenge lies in the scarcity of large-scale training data with explicit 4D annotations. We address this by developing an automatic data engine that extracts the required 4D controls from in-the-wild videos, allowing us to train our model on a massive and diverse dataset.

</details>


### [63] [A Lightweight and Explainable Vision-Language Framework for Crop Disease Visual Question Answering](https://arxiv.org/abs/2601.05143)
*Md. Zahid Hossain,Most. Sharmin Sultana Samu,Md. Rakibul Islam,Md. Siam Ansary*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级视觉语言框架，结合Swin Transformer视觉编码器和序列到序列语言解码器，用于作物病害识别。采用两阶段训练策略，在分类和自然语言生成指标上表现优异，参数效率高。


<details>
  <summary>Details</summary>
Motivation: 作物病害视觉问答需要准确的视觉理解和可靠的语言生成能力，现有大规模模型参数过多，需要开发更高效的专用框架。

Method: 使用Swin Transformer作为视觉编码器，结合序列到序列语言解码器，采用两阶段训练策略优化视觉表示学习和跨模态对齐。

Result: 在大规模作物病害数据集上，模型在作物和病害识别方面达到高准确率，在BLEU、ROUGE和BERTScore指标上表现强劲，且参数数量显著少于基线模型。

Conclusion: 任务特定的视觉预训练对作物病害视觉问答任务非常有效，提出的轻量级框架在保持高性能的同时显著降低了模型复杂度。

Abstract: Visual question answering for crop disease analysis requires accurate visual understanding and reliable language generation. This work presents a lightweight vision-language framework for crop and disease identification from leaf images. The proposed approach combines a Swin Transformer vision encoder with sequence-to-sequence language decoders. A two-stage training strategy is adopted to improve visual representation learning and cross-modal alignment. The model is evaluated on a large-scale crop disease dataset using classification and natural language generation metrics. Experimental results show high accuracy for both crop and disease identification. The framework also achieves strong performance on BLEU, ROUGE and BERTScore. Our proposed models outperform large-scale vision-language baselines while using significantly fewer parameters. Explainability is assessed using Grad-CAM and token-level attribution. Qualitative results demonstrate robust performance under diverse user-driven queries. These findings highlight the effectiveness of task-specific visual pretraining for crop disease visual question answering.

</details>


### [64] [Atlas 2 -- Foundation models for clinical deployment](https://arxiv.org/abs/2601.05148)
*Maximilian Alber,Timo Milbich,Alexandra Carpen-Amarie,Stephan Tietz,Jonas Dippel,Lukas Muttenthaler,Beatriz Perez Cancer,Alessandro Benetti,Panos Korfiatis,Elias Eulig,Jérôme Lüscher,Jiasen Wu,Sayed Abid Hashimi,Gabriel Dernbach,Simon Schallenberg,Neelay Shah,Moritz Krügener,Aniruddh Jammoria,Jake Matras,Patrick Duffy,Matt Redlon,Philipp Jurmeister,David Horst,Lukas Ruff,Klaus-Robert Müller,Frederick Klauschen,Andrew Norgan*

Main category: cs.CV

TL;DR: 本文提出了Atlas 2系列病理视觉基础模型，通过使用550万张病理切片图像的大规模数据集训练，在性能、鲁棒性和计算效率方面达到先进水平


<details>
  <summary>Details</summary>
Motivation: 现有的病理基础模型在性能、鲁棒性和计算需求之间存在权衡，这限制了其在临床部署中的应用

Method: 使用来自三家医疗机构（柏林Charité大学医院、慕尼黑LMU和梅奥诊所）的550万张病理全切片图像构建了迄今为止最大的病理基础模型数据集进行训练

Result: 在80个公共基准测试中，Atlas 2、Atlas 2-B和Atlas 2-S三个模型在预测性能、鲁棒性和资源效率方面都表现出最先进的水平

Conclusion: Atlas 2系列模型成功解决了现有病理基础模型的局限性，为临床部署提供了更优的解决方案

Abstract: Pathology foundation models substantially advanced the possibilities in computational pathology -- yet tradeoffs in terms of performance, robustness, and computational requirements remained, which limited their clinical deployment. In this report, we present Atlas 2, Atlas 2-B, and Atlas 2-S, three pathology vision foundation models which bridge these shortcomings by showing state-of-the-art performance in prediction performance, robustness, and resource efficiency in a comprehensive evaluation across eighty public benchmarks. Our models were trained on the largest pathology foundation model dataset to date comprising 5.5 million histopathology whole slide images, collected from three medical institutions Charité - Universtätsmedizin Berlin, LMU Munich, and Mayo Clinic.

</details>


### [65] [Multi-Scale Local Speculative Decoding for Image Generation](https://arxiv.org/abs/2601.05149)
*Elia Peruzzo,Guillaume Sautière,Amirhossein Habibian*

Main category: cs.CV

TL;DR: MuLo-SD是一种新颖的多尺度局部推测解码框架，通过结合多分辨率草稿生成和空间感知验证来加速自回归图像生成，在保持质量的同时实现1.7倍加速。


<details>
  <summary>Details</summary>
Motivation: 自回归模型在图像合成中表现出色，但其顺序性质导致显著的延迟限制。现有推测解码方法受限于令牌级模糊性和缺乏空间感知能力。

Method: 使用低分辨率草稿器配合学习的上采样器提出候选图像令牌，然后通过高分辨率目标模型并行验证。引入局部拒绝和重采样机制，专注于空间邻域而非光栅扫描重采样。

Result: 在MS-COCO 5k验证集上，MuLo-SD实现1.7倍加速，在加速方面优于EAGLE-2和LANTERN等基线方法，同时保持可比的语义对齐和感知质量。

Conclusion: 该方法为图像合成的推测解码设定了新的最先进水平，在效率和保真度之间架起了桥梁。

Abstract: Autoregressive (AR) models have achieved remarkable success in image synthesis, yet their sequential nature imposes significant latency constraints. Speculative Decoding offers a promising avenue for acceleration, but existing approaches are limited by token-level ambiguity and lack of spatial awareness. In this work, we introduce Multi-Scale Local Speculative Decoding (MuLo-SD), a novel framework that combines multi-resolution drafting with spatially informed verification to accelerate AR image generation. Our method leverages a low-resolution drafter paired with learned up-samplers to propose candidate image tokens, which are then verified in parallel by a high-resolution target model. Crucially, we incorporate a local rejection and resampling mechanism, enabling efficient correction of draft errors by focusing on spatial neighborhoods rather than raster-scan resampling after the first rejection. We demonstrate that MuLo-SD achieves substantial speedups - up to $\mathbf{1.7\times}$ - outperforming strong speculative decoding baselines such as EAGLE-2 and LANTERN in terms of acceleration, while maintaining comparable semantic alignment and perceptual quality. These results are validated using GenEval, DPG-Bench, and FID/HPSv2 on the MS-COCO 5k validation split. Extensive ablations highlight the impact of up-sampling design, probability pooling, and local rejection and resampling with neighborhood expansion. Our approach sets a new state-of-the-art in speculative decoding for image synthesis, bridging the gap between efficiency and fidelity.

</details>


### [66] [Vision-Language Introspection: Mitigating Overconfident Hallucinations in MLLMs via Interpretable Bi-Causal Steering](https://arxiv.org/abs/2601.05159)
*Shuliang Liu,Songbo Yang,Dong Fang,Sihang Jia,Yuqi Tang,Lingfeng Su,Ruoshui Peng,Yibo Yan,Xin Zou,Xuming Hu*

Main category: cs.CV

TL;DR: 本文提出Vision-Language Introspection（VLI）框架，通过元认知自我修正过程解决多模态大语言模型中的物体幻觉问题，在MMHal-Bench上将物体幻觉率降低12.67%，在POPE上准确率提升5.8%。


<details>
  <summary>Details</summary>
Motivation: 物体幻觉严重削弱多模态大语言模型的可靠性，现有方法（对比解码和潜在引导）存在局限性，无法有效纠正内部语义错位和缺乏实例特异性精度。

Method: VLI框架包含属性内省（通过概率冲突检测诊断幻觉风险并定位因果视觉锚点）和可解释双因果引导（动态隔离视觉证据与背景噪声，通过自适应校准消除盲目置信）。

Result: 在先进模型上实现最先进性能，MMHal-Bench上物体幻觉率降低12.67%，POPE准确率提升5.8%。

Conclusion: VLI是一种无需训练的高效推理框架，通过模拟元认知自我修正过程，显著提升了多模态大语言模型的可靠性。

Abstract: Object hallucination critically undermines the reliability of Multimodal Large Language Models, often stemming from a fundamental failure in cognitive introspection, where models blindly trust linguistic priors over specific visual evidence. Existing mitigations remain limited: contrastive decoding approaches operate superficially without rectifying internal semantic misalignments, while current latent steering methods rely on static vectors that lack instance-specific precision. We introduce Vision-Language Introspection (VLI), a training-free inference framework that simulates a metacognitive self-correction process. VLI first performs Attributive Introspection to diagnose hallucination risks via probabilistic conflict detection and localize the causal visual anchors. It then employs Interpretable Bi-Causal Steering to actively modulate the inference process, dynamically isolating visual evidence from background noise while neutralizing blind confidence through adaptive calibration. VLI achieves state-of-the-art performance on advanced models, reducing object hallucination rates by 12.67% on MMHal-Bench and improving accuracy by 5.8% on POPE.

</details>


### [67] [CoV: Chain-of-View Prompting for Spatial Reasoning](https://arxiv.org/abs/2601.05172)
*Haoyu Zhao,Akide Liu,Zeyu Zhang,Weijie Wang,Feng Chen,Ruihan Zhu,Gholamreza Haffari,Bohan Zhuang*

Main category: cs.CV

TL;DR: 提出Chain-of-View (CoV)提示方法，通过粗到细的探索过程将视觉语言模型转化为主动视角推理器，在3D环境中的具身问答任务上取得显著提升


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型受限于固定的输入视角，无法在推理时获取问题相关的上下文信息，限制了复杂空间推理能力

Method: CoV首先使用视角选择代理过滤冗余帧并识别问题对齐的锚点视角，然后通过迭代推理与离散相机动作交替进行细粒度视角调整，从底层3D场景表示中获取新观察

Result: 在OpenEQA上平均提升11.56%的LLM-Match分数，最高提升13.62%；增加动作预算可额外提升2.51%-3.73%；在ScanQA和SQA3D上也表现强劲

Conclusion: 问题对齐的视角选择结合开放视角搜索是一种无需额外训练的有效、模型无关的策略，可显著提升3D具身问答中的空间推理能力

Abstract: Embodied question answering (EQA) in 3D environments often requires collecting context that is distributed across multiple viewpoints and partially occluded. However, most recent vision--language models (VLMs) are constrained to a fixed and finite set of input views, which limits their ability to acquire question-relevant context at inference time and hinders complex spatial reasoning. We propose Chain-of-View (CoV) prompting, a training-free, test-time reasoning framework that transforms a VLM into an active viewpoint reasoner through a coarse-to-fine exploration process. CoV first employs a View Selection agent to filter redundant frames and identify question-aligned anchor views. It then performs fine-grained view adjustment by interleaving iterative reasoning with discrete camera actions, obtaining new observations from the underlying 3D scene representation until sufficient context is gathered or a step budget is reached.
  We evaluate CoV on OpenEQA across four mainstream VLMs and obtain an average +11.56\% improvement in LLM-Match, with a maximum gain of +13.62\% on Qwen3-VL-Flash. CoV further exhibits test-time scaling: increasing the minimum action budget yields an additional +2.51\% average improvement, peaking at +3.73\% on Gemini-2.5-Flash. On ScanQA and SQA3D, CoV delivers strong performance (e.g., 116 CIDEr / 31.9 EM@1 on ScanQA and 51.1 EM@1 on SQA3D). Overall, these results suggest that question-aligned view selection coupled with open-view search is an effective, model-agnostic strategy for improving spatial reasoning in 3D EQA without additional training.

</details>


### [68] [VideoAuto-R1: Video Auto Reasoning via Thinking Once, Answering Twice](https://arxiv.org/abs/2601.05175)
*Shuming Liu,Mingchen Zhuge,Changsheng Zhao,Jun Chen,Lemeng Wu,Zechun Liu,Chenchen Zhu,Zhipeng Cai,Chong Zhou,Haozhe Liu,Ernie Chang,Saksham Suri,Hongyu Xu,Qi Qian,Wei Wen,Balakrishnan Varadarajan,Zhuang Liu,Hu Xu,Florian Bordes,Raghuraman Krishnamoorthi,Bernard Ghanem,Vikas Chandra,Yunyang Xiong*

Main category: cs.CV

TL;DR: 本文提出VideoAuto-R1框架，采用"必要时才推理"的策略，通过"思考一次，回答两次"的范式，在视频理解任务中实现SOTA准确率，同时显著提升效率。


<details>
  <summary>Details</summary>
Motivation: 研究发现对于RL训练的视频模型，直接回答往往能达到甚至超过CoT推理的性能，但CoT推理会产生更高的计算成本。因此需要探索何时需要显式推理。

Method: 提出VideoAuto-R1框架，训练时采用"思考一次，回答两次"范式：模型先生成初始答案，然后进行推理，最后输出审核后的答案。推理时根据初始答案的置信度决定是否进行推理。

Result: 在视频QA和定位基准测试中，VideoAuto-R1达到SOTA准确率，同时效率显著提升，平均响应长度减少约3.3倍（从149个token降至44个）。在感知导向任务中思考模式激活率低，而在推理密集型任务中激活率高。

Conclusion: 显式语言推理通常有益但并非总是必要，VideoAuto-R1通过自适应推理策略在保持性能的同时大幅提升效率。

Abstract: Chain-of-thought (CoT) reasoning has emerged as a powerful tool for multimodal large language models on video understanding tasks. However, its necessity and advantages over direct answering remain underexplored. In this paper, we first demonstrate that for RL-trained video models, direct answering often matches or even surpasses CoT performance, despite CoT producing step-by-step analyses at a higher computational cost. Motivated by this, we propose VideoAuto-R1, a video understanding framework that adopts a reason-when-necessary strategy. During training, our approach follows a Thinking Once, Answering Twice paradigm: the model first generates an initial answer, then performs reasoning, and finally outputs a reviewed answer. Both answers are supervised via verifiable rewards. During inference, the model uses the confidence score of the initial answer to determine whether to proceed with reasoning. Across video QA and grounding benchmarks, VideoAuto-R1 achieves state-of-the-art accuracy with significantly improved efficiency, reducing the average response length by ~3.3x, e.g., from 149 to just 44 tokens. Moreover, we observe a low rate of thinking-mode activation on perception-oriented tasks, but a higher rate on reasoning-intensive tasks. This suggests that explicit language-based reasoning is generally beneficial but not always necessary.

</details>


### [69] [Cutting AI Research Costs: How Task-Aware Compression Makes Large Language Model Agents Affordable](https://arxiv.org/abs/2601.05191)
*Zuhair Ahmed Khan Taha,Mohammed Mudassir Uddin,Shahnawaz Alam*

Main category: cs.CV

TL;DR: AgentCompress通过智能路由任务到不同压缩程度的模型，显著降低大语言模型在科研任务中的计算成本，同时保持高性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在自主科研任务中的高昂计算成本限制了学术实验室的使用，需要一种经济高效的解决方案。

Method: 使用小型神经网络根据任务开头词语评估任务难度，然后在毫秒级时间内将任务路由到适当压缩的模型变体。

Result: 在四个科学领域的500个研究工作流测试中，计算成本降低了68.3%，同时保持了96.2%的原始成功率。

Conclusion: AgentCompress为预算有限的实验室提供了可行的解决方案，使更多科研团队能够负担得起使用大型语言模型进行实验。

Abstract: When researchers deploy large language models for autonomous tasks like reviewing literature or generating hypotheses, the computational bills add up quickly. A single research session using a 70-billion parameter model can cost around $127 in cloud fees, putting these tools out of reach for many academic labs. We developed AgentCompress to tackle this problem head-on. The core idea came from a simple observation during our own work: writing a novel hypothesis clearly demands more from the model than reformatting a bibliography. Why should both tasks run at full precision? Our system uses a small neural network to gauge how hard each incoming task will be, based only on its opening words, then routes it to a suitably compressed model variant. The decision happens in under a millisecond. Testing across 500 research workflows in four scientific fields, we cut compute costs by 68.3% while keeping 96.2% of the original success rate. For labs watching their budgets, this could mean the difference between running experiments and sitting on the sidelines

</details>


### [70] [Mechanisms of Prompt-Induced Hallucination in Vision-Language Models](https://arxiv.org/abs/2601.05201)
*William Rudman,Michal Golovanevsky,Dana Arad,Yonatan Belinkov,Ritambhara Singh,Carsten Eickhoff,Kyle Mahowald*

Main category: cs.CV

TL;DR: 论文研究了大型视觉语言模型在物体计数任务中的提示诱导幻觉现象，发现当文本提示与图像证据不一致时，模型倾向于遵从文本提示而非视觉证据，特别是在物体数量较多时。通过机制分析识别出少量注意力头，其消融可显著减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型虽然能力强，但经常出现幻觉，倾向于优先处理文本提示而忽视视觉证据。本研究旨在控制条件下系统研究这种失败模式，特别是在物体计数任务中文本提示夸大物体数量时的模型行为。

Method: 在受控的物体计数设置中，使用夸大物体数量的文本提示（如要求描述4朵睡莲但图像中只有3朵）。通过机制分析三个VLMs，识别出导致提示诱导幻觉的特定注意力头，并进行消融实验。

Result: 在低物体数量时模型能纠正提示的夸大，但随着物体数量增加，模型越来越倾向于遵从文本提示。消融识别出的注意力头可使提示诱导幻觉减少至少40%，且无需额外训练。不同模型通过不同的机制实现提示复制。

Conclusion: 研究揭示了提示诱导幻觉的内部机制，识别出模型特定的注意力头在介导这种行为中的关键作用。消融这些注意力头能有效增强模型对视觉证据的校正能力，为理解VLMs的幻觉机制提供了重要见解。

Abstract: Large vision-language models (VLMs) are highly capable, yet often hallucinate by favoring textual prompts over visual evidence. We study this failure mode in a controlled object-counting setting, where the prompt overstates the number of objects in the image (e.g., asking a model to describe four waterlilies when only three are present). At low object counts, models often correct the overestimation, but as the number of objects increases, they increasingly conform to the prompt regardless of the discrepancy. Through mechanistic analysis of three VLMs, we identify a small set of attention heads whose ablation substantially reduces prompt-induced hallucinations (PIH) by at least 40% without additional training. Across models, PIH-heads mediate prompt copying in model-specific ways. We characterize these differences and show that PIH ablation increases correction toward visual evidence. Our findings offer insights into the internal mechanisms driving prompt-induced hallucinations, revealing model-specific differences in how these behaviors are implemented.

</details>


### [71] [MoE3D: A Mixture-of-Experts Module for 3D Reconstruction](https://arxiv.org/abs/2601.05208)
*Zichen Wang,Ang Cao,Liam J. Wang,Jeong Joon Park*

Main category: cs.CV

TL;DR: MoE3D是一个混合专家模块，旨在改善现有前馈3D重建模型的深度边界锐化和减少飞行点伪影，通过动态加权融合多个候选深度图来提升重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有前馈3D重建模型存在深度边界模糊和飞行点伪影问题，需要一种高效的方法来提升重建质量。

Method: MoE3D预测多个候选深度图，并通过动态加权融合这些深度图，集成到预训练的3D重建骨干网络（如VGGT）中。

Result: MoE3D显著提升了3D重建质量，同时计算开销增加很小。

Conclusion: MoE3D模块能有效改善3D重建的边界清晰度和减少伪影，是一种高效的质量提升方案。

Abstract: MoE3D is a mixture-of-experts module designed to sharpen depth boundaries and mitigate flying-point artifacts (highlighted in red) of existing feed-forward 3D reconstruction models (left side). MoE3D predicts multiple candidate depth maps and fuses them via dynamic weighting (visualized by MoE weights on the right side). When integrated with a pre-trained 3D reconstruction backbone such as VGGT, it substantially enhances reconstruction quality with minimal additional computational overhead. Best viewed digitally.

</details>


### [72] [FlowLet: Conditional 3D Brain MRI Synthesis using Wavelet Flow Matching](https://arxiv.org/abs/2601.05212)
*Danilo Danese,Angela Lombardi,Matteo Attimonelli,Giuseppe Fasano,Tommaso Di Noia*

Main category: cs.CV

TL;DR: FlowLet是一个条件生成框架，通过可逆3D小波域中的流匹配来合成年龄条件的3D MRI，解决现有扩散模型推理慢、存在伪影的问题，提升脑年龄预测模型在少数年龄组的性能。


<details>
  <summary>Details</summary>
Motivation: 现有3D MRI数据集存在人口统计学偏差，限制了脑年龄预测模型的公平性和泛化能力。现有生成方法通常基于潜在扩散模型，存在推理速度慢、潜在压缩引入伪影、很少条件化于年龄等问题。

Method: 提出FlowLet框架，在可逆3D小波域中使用流匹配来合成年龄条件的3D MRI，避免重建伪影并降低计算需求。

Result: FlowLet能以少量采样步骤生成高保真体积数据。使用FlowLet生成的数据训练脑年龄预测模型，提升了在代表性不足年龄组上的性能，区域分析证实了解剖结构的保留。

Conclusion: FlowLet通过小波域流匹配有效解决了现有生成方法的局限性，为脑年龄预测提供了高质量的数据增强方案。

Abstract: Brain Magnetic Resonance Imaging (MRI) plays a central role in studying neurological development, aging, and diseases. One key application is Brain Age Prediction (BAP), which estimates an individual's biological brain age from MRI data. Effective BAP models require large, diverse, and age-balanced datasets, whereas existing 3D MRI datasets are demographically skewed, limiting fairness and generalizability. Acquiring new data is costly and ethically constrained, motivating generative data augmentation. Current generative methods are often based on latent diffusion models, which operate in learned low dimensional latent spaces to address the memory demands of volumetric MRI data. However, these methods are typically slow at inference, may introduce artifacts due to latent compression, and are rarely conditioned on age, thereby affecting the BAP performance. In this work, we propose FlowLet, a conditional generative framework that synthesizes age-conditioned 3D MRIs by leveraging flow matching within an invertible 3D wavelet domain, helping to avoid reconstruction artifacts and reducing computational demands. Experiments show that FlowLet generates high-fidelity volumes with few sampling steps. Training BAP models with data generated by FlowLet improves performance for underrepresented age groups, and region-based analysis confirms preservation of anatomical structures.

</details>


### [73] [ObjectForesight: Predicting Future 3D Object Trajectories from Human Videos](https://arxiv.org/abs/2601.05237)
*Rustin Soraki,Homanga Bharadhwaj,Ali Farhadi,Roozbeh Mottaghi*

Main category: cs.CV

TL;DR: ObjectForesight是一个3D物体中心动力学模型，能够从短时第一人称视频序列预测刚性物体的未来6自由度位姿和轨迹，实现几何基础和时序一致的预测。


<details>
  <summary>Details</summary>
Motivation: 让计算系统具备类似人类的预测能力，能够从被动视觉观察中直接预测物体可能的运动变化，捕捉物体的功能性和轨迹。

Method: 采用显式的3D物体层面表示，利用分割、网格重建和3D位姿估计等技术构建包含200万+短片段的数据集，训练物体中心动力学模型。

Result: ObjectForesight在准确性、几何一致性和对未见物体和场景的泛化能力方面取得显著提升。

Conclusion: 建立了一个可扩展的框架，能够直接从观察中学习物理基础的物体中心动力学模型。

Abstract: Humans can effortlessly anticipate how objects might move or change through interaction--imagining a cup being lifted, a knife slicing, or a lid being closed. We aim to endow computational systems with a similar ability to predict plausible future object motions directly from passive visual observation. We introduce ObjectForesight, a 3D object-centric dynamics model that predicts future 6-DoF poses and trajectories of rigid objects from short egocentric video sequences. Unlike conventional world or dynamics models that operate in pixel or latent space, ObjectForesight represents the world explicitly in 3D at the object level, enabling geometrically grounded and temporally coherent predictions that capture object affordances and trajectories. To train such a model at scale, we leverage recent advances in segmentation, mesh reconstruction, and 3D pose estimation to curate a dataset of 2 million plus short clips with pseudo-ground-truth 3D object trajectories. Through extensive experiments, we show that ObjectForesight achieves significant gains in accuracy, geometric consistency, and generalization to unseen objects and scenes, establishing a scalable framework for learning physically grounded, object-centric dynamics models directly from observation. objectforesight.github.io

</details>


### [74] [Plenoptic Video Generation](https://arxiv.org/abs/2601.05239)
*Xiao Fu,Shitao Tang,Min Shi,Xian Liu,Jinwei Gu,Ming-Yu Liu,Dahua Lin,Chen-Hsuan Lin*

Main category: cs.CV

TL;DR: PlenopticDreamer是一个解决多视角视频重渲染中时空一致性问题的新框架，通过自回归训练和相机引导的视频检索策略来保持幻觉内容的同步性。


<details>
  <summary>Details</summary>
Motivation: 现有的相机控制生成视频重渲染方法在单视角下表现良好，但在多视角场景中难以保持时空一致性，特别是在幻觉区域容易产生不一致。

Method: 采用多输入单输出的视频条件模型进行自回归训练，结合相机引导的视频检索策略、渐进上下文缩放、自条件机制和长视频条件机制。

Result: 在Basic和Agibot基准测试中达到最先进的视频重渲染效果，具有出色的视角同步性、高保真视觉效果、准确的相机控制和多样化的视角转换能力。

Conclusion: PlenopticDreamer有效解决了多视角视频重渲染中的时空一致性问题，为机器人操作等应用提供了可靠的视觉生成解决方案。

Abstract: Camera-controlled generative video re-rendering methods, such as ReCamMaster, have achieved remarkable progress. However, despite their success in single-view setting, these works often struggle to maintain consistency across multi-view scenarios. Ensuring spatio-temporal coherence in hallucinated regions remains challenging due to the inherent stochasticity of generative models. To address it, we introduce PlenopticDreamer, a framework that synchronizes generative hallucinations to maintain spatio-temporal memory. The core idea is to train a multi-in-single-out video-conditioned model in an autoregressive manner, aided by a camera-guided video retrieval strategy that adaptively selects salient videos from previous generations as conditional inputs. In addition, Our training incorporates progressive context-scaling to improve convergence, self-conditioning to enhance robustness against long-range visual degradation caused by error accumulation, and a long-video conditioning mechanism to support extended video generation. Extensive experiments on the Basic and Agibot benchmarks demonstrate that PlenopticDreamer achieves state-of-the-art video re-rendering, delivering superior view synchronization, high-fidelity visuals, accurate camera control, and diverse view transformations (e.g., third-person to third-person, and head-view to gripper-view in robotic manipulation). Project page: https://research.nvidia.com/labs/dir/plenopticdreamer/

</details>


### [75] [GREx: Generalized Referring Expression Segmentation, Comprehension, and Generation](https://arxiv.org/abs/2601.05244)
*Henghui Ding,Chang Liu,Shuting He,Xudong Jiang,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: 本文提出了GREx（广义指代表达式分割、理解和生成）任务，扩展了传统的单目标RES/REC/REG任务，支持多目标和无目标表达式。作者构建了首个大规模数据集gRefCOCO，并提出了ReLA基线方法，在GRES和GREC任务上取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 现有的指代表达式任务（RES/REC/REG）仅支持单目标表达式，即一个表达式对应一个目标物体，这限制了实际应用。现实场景中经常需要处理多目标和无目标表达式。

Method: 提出了GREx任务框架，包含GRES、GREC和GREG三个子任务。构建了gRefCOCO数据集，包含多目标、无目标和单目标表达式。提出了ReLA基线方法，通过自适应图像区域划分和显式建模区域-区域、区域-语言依赖关系来处理复杂关系。

Result: ReLA方法在GRES和GREC任务上取得了最先进的结果。gRefCOCO数据集与现有REx方法向后兼容，便于研究现有方法在GREx任务上的性能差距。

Conclusion: GREx任务和gRefCOCO数据集有效扩展了指代表达式任务的适用范围，解决了现实应用中多目标和无目标表达式的需求。ReLA方法为复杂关系建模提供了有效解决方案。

Abstract: Referring Expression Segmentation (RES) and Comprehension (REC) respectively segment and detect the object described by an expression, while Referring Expression Generation (REG) generates an expression for the selected object. Existing datasets and methods commonly support single-target expressions only, i.e., one expression refers to one object, not considering multi-target and no-target expressions. This greatly limits the real applications of REx (RES/REC/REG). This paper introduces three new benchmarks called Generalized Referring Expression Segmentation (GRES), Comprehension (GREC), and Generation (GREG), collectively denoted as GREx, which extend the classic REx to allow expressions to identify an arbitrary number of objects. We construct the first large-scale GREx dataset gRefCOCO that contains multi-target, no-target, and single-target expressions and their corresponding images with labeled targets. GREx and gRefCOCO are designed to be backward-compatible with REx, facilitating extensive experiments to study the performance gap of the existing REx methods on GREx tasks. One of the challenges of GRES/GREC is complex relationship modeling, for which we propose a baseline ReLA that adaptively divides the image into regions with sub-instance clues and explicitly models the region-region and region-language dependencies. The proposed ReLA achieves the state-of-the-art results on the both GRES and GREC tasks. The proposed gRefCOCO dataset and method are available at https://henghuiding.github.io/GREx.

</details>


### [76] [Pixel-Perfect Visual Geometry Estimation](https://arxiv.org/abs/2601.05246)
*Gangwei Xu,Haotong Lin,Hongcheng Luo,Haiyang Sun,Bing Wang,Guang Chen,Sida Peng,Hangjun Ye,Xin Yang*

Main category: cs.CV

TL;DR: 提出基于像素空间扩散变换器的Pixel-Perfect Depth（PPD）模型，通过语义提示和级联架构提升单目深度估计质量；进一步扩展为视频深度估计模型PPVD，通过语义一致性DiT和参考引导令牌传播保持时序一致性。


<details>
  <summary>Details</summary>
Motivation: 现有几何基础模型存在飞像素和细节丢失问题，需要开发能预测高质量、无飞像素点云的视觉几何模型。

Method: 1. PPD：基于像素空间扩散变换器，引入语义提示DiT（利用视觉基础模型的语义表示指导扩散过程）和级联DiT架构（逐步增加图像令牌数量）；2. PPVD：扩展PPD到视频，提出语义一致性DiT（从多视角几何基础模型提取时序一致语义）和参考引导令牌传播（在DiT内保持时序一致性）。

Result: 模型在所有生成式单目和视频深度估计模型中取得最佳性能，生成的点云比其他模型显著更清晰。

Conclusion: 通过像素空间生成建模和语义引导的扩散变换器设计，成功实现了高质量的视觉几何重建，解决了飞像素和细节丢失问题。

Abstract: Recovering clean and accurate geometry from images is essential for robotics and augmented reality. However, existing geometry foundation models still suffer severely from flying pixels and the loss of fine details. In this paper, we present pixel-perfect visual geometry models that can predict high-quality, flying-pixel-free point clouds by leveraging generative modeling in the pixel space. We first introduce Pixel-Perfect Depth (PPD), a monocular depth foundation model built upon pixel-space diffusion transformers (DiT). To address the high computational complexity associated with pixel-space diffusion, we propose two key designs: 1) Semantics-Prompted DiT, which incorporates semantic representations from vision foundation models to prompt the diffusion process, preserving global semantics while enhancing fine-grained visual details; and 2) Cascade DiT architecture that progressively increases the number of image tokens, improving both efficiency and accuracy. To further extend PPD to video (PPVD), we introduce a new Semantics-Consistent DiT, which extracts temporally consistent semantics from a multi-view geometry foundation model. We then perform reference-guided token propagation within the DiT to maintain temporal coherence with minimal computational and memory overhead. Our models achieve the best performance among all generative monocular and video depth estimation models and produce significantly cleaner point clouds than all other models.

</details>


### [77] [RL-AWB: Deep Reinforcement Learning for Auto White Balance Correction in Low-Light Night-time Scenes](https://arxiv.org/abs/2601.05249)
*Yuan-Kang Lee,Kuan-Lin Chen,Chia-Che Chang,Yu-Lun Liu*

Main category: cs.CV

TL;DR: RL-AWB是一个结合统计方法和深度强化学习的夜间白平衡框架，通过统计算法检测显著灰度像素并估计光照，然后使用强化学习动态优化参数，在跨传感器评估中表现出优越的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 夜间色彩恒常性因低光噪声和复杂光照条件而具有挑战性，现有方法难以有效处理。

Method: 首先使用针对夜间场景的统计算法（显著灰度像素检测和光照估计），然后基于此开发首个用于色彩恒常性的深度强化学习方法，动态优化每个图像的参数。

Result: 实验结果表明，该方法在低光和良好光照图像上均表现出优越的泛化能力。

Conclusion: RL-AWB框架成功解决了夜间白平衡问题，通过统计与强化学习的结合实现了跨传感器的优秀性能。

Abstract: Nighttime color constancy remains a challenging problem in computational photography due to low-light noise and complex illumination conditions. We present RL-AWB, a novel framework combining statistical methods with deep reinforcement learning for nighttime white balance. Our method begins with a statistical algorithm tailored for nighttime scenes, integrating salient gray pixel detection with novel illumination estimation. Building on this foundation, we develop the first deep reinforcement learning approach for color constancy that leverages the statistical algorithm as its core, mimicking professional AWB tuning experts by dynamically optimizing parameters for each image. To facilitate cross-sensor evaluation, we introduce the first multi-sensor nighttime dataset. Experiment results demonstrate that our method achieves superior generalization capability across low-light and well-illuminated images. Project page: https://ntuneillee.github.io/research/rl-awb/

</details>


### [78] [QNeRF: Neural Radiance Fields on a Simulated Gate-Based Quantum Computer](https://arxiv.org/abs/2601.05250)
*Daniele Lizzio Bosco,Shuteng Wang,Giuseppe Serra,Vladislav Golyanik*

Main category: cs.CV

TL;DR: QNeRF是第一个用于从2D图像进行新视角合成的混合量子-经典模型，通过量子电路编码空间和视图信息，相比经典NeRF使用不到一半的参数就能达到或超越其性能。


<details>
  <summary>Details</summary>
Motivation: 量子视觉场（QVFs）在模型压缩和收敛速度方面表现出优势，而神经辐射场（NeRFs）在新视角合成方面取得重大进展但模型较大且训练密集。本研究旨在结合量子优势来解决NeRF的模型复杂性问题。

Method: 提出QNeRF模型，使用参数化量子电路通过量子叠加和纠缠来编码空间和视图相关信息。设计了两种架构变体：Full QNeRF（最大化利用所有量子振幅）和Dual-Branch QNeRF（通过分支处理空间和视图信息来降低复杂度）。

Result: 实验表明，在中等分辨率图像训练时，QNeRF使用不到经典NeRF一半的参数数量，就能达到或超越经典NeRF基准性能。

Conclusion: 量子机器学习可以作为计算机视觉中连续信号表示的有竞争力替代方案，特别是在3D表示学习等中等复杂度任务中。

Abstract: Recently, Quantum Visual Fields (QVFs) have shown promising improvements in model compactness and convergence speed for learning the provided 2D or 3D signals. Meanwhile, novel-view synthesis has seen major advances with Neural Radiance Fields (NeRFs), where models learn a compact representation from 2D images to render 3D scenes, albeit at the cost of larger models and intensive training. In this work, we extend the approach of QVFs by introducing QNeRF, the first hybrid quantum-classical model designed for novel-view synthesis from 2D images. QNeRF leverages parameterised quantum circuits to encode spatial and view-dependent information via quantum superposition and entanglement, resulting in more compact models compared to the classical counterpart. We present two architectural variants. Full QNeRF maximally exploits all quantum amplitudes to enhance representational capabilities. In contrast, Dual-Branch QNeRF introduces a task-informed inductive bias by branching spatial and view-dependent quantum state preparations, drastically reducing the complexity of this operation and ensuring scalability and potential hardware compatibility. Our experiments demonstrate that -- when trained on images of moderate resolution -- QNeRF matches or outperforms classical NeRF baselines while using less than half the number of parameters. These results suggest that quantum machine learning can serve as a competitive alternative for continuous signal representation in mid-level tasks in computer vision, such as 3D representation learning from 2D observations.

</details>


### [79] [Mesh4D: 4D Mesh Reconstruction and Tracking from Monocular Video](https://arxiv.org/abs/2601.05251)
*Zeren Jiang,Chuanxia Zheng,Iro Laina,Diane Larlus,Andrea Vedaldi*

Main category: cs.CV

TL;DR: Mesh4D是一个前馈模型，用于单目4D网格重建，能够从单目视频中重建动态对象的完整3D形状和运动，通过紧凑的潜在空间编码整个动画序列。


<details>
  <summary>Details</summary>
Motivation: 现有的动态对象重建方法通常需要复杂的时序处理或多视角输入，而Mesh4D旨在通过单目视频实现高效准确的4D重建，减少对额外信息的依赖。

Method: 使用自编码器学习紧凑潜在空间，编码时通过骨骼结构引导提供变形先验，采用时空注意力机制增强表示稳定性，并基于潜在扩散模型一次性预测完整动画。

Result: 在重建和新视角合成基准测试中，Mesh4D在恢复准确3D形状和变形方面优于现有方法。

Conclusion: Mesh4D通过创新的潜在空间表示和扩散模型，实现了高效的单目4D网格重建，为动态对象建模提供了新思路。

Abstract: We propose Mesh4D, a feed-forward model for monocular 4D mesh reconstruction. Given a monocular video of a dynamic object, our model reconstructs the object's complete 3D shape and motion, represented as a deformation field. Our key contribution is a compact latent space that encodes the entire animation sequence in a single pass. This latent space is learned by an autoencoder that, during training, is guided by the skeletal structure of the training objects, providing strong priors on plausible deformations. Crucially, skeletal information is not required at inference time. The encoder employs spatio-temporal attention, yielding a more stable representation of the object's overall deformation. Building on this representation, we train a latent diffusion model that, conditioned on the input video and the mesh reconstructed from the first frame, predicts the full animation in one shot. We evaluate Mesh4D on reconstruction and novel view synthesis benchmarks, outperforming prior methods in recovering accurate 3D shape and deformation.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [80] [Autonomous Reasoning for Spacecraft Control: A Large Language Model Framework with Group Relative Policy Optimization](https://arxiv.org/abs/2601.04334)
*Amit Jain,Richard Linares*

Main category: cs.RO

TL;DR: 本文提出了一种结合推理增强大语言模型（LLM）和群相对策略优化（GRPO）的学习型制导控制方法，通过两阶段训练在多种动态系统中实现稳定控制策略的合成。


<details>
  <summary>Details</summary>
Motivation: 开发能够同时生成控制序列并提供人类可读决策解释的自主控制系统，为航空航天等安全关键领域应用奠定基础。

Method: 采用两阶段训练流程：首先通过监督微调（SFT）学习格式化和控制原语，然后使用GRPO进行交互驱动的策略改进，为每个环境训练控制器。

Result: 在四个控制问题上的实验表明，经过GRPO优化的具有显式推理能力的LLM能够在一致训练设置下，为线性和非线性系统合成可行的稳定策略。

Conclusion: 该工作为基于GRPO推理的自主控制系统应用建立了基础，两阶段训练方法使模型既能生成控制序列又能提供决策过程的可解释性。

Abstract: This paper presents a learning-based guidance-and-control approach that couples a reasoning-enabled Large Language Model (LLM) with Group Relative Policy Optimization (GRPO). A two-stage procedure consisting of Supervised Fine-Tuning (SFT) to learn formatting and control primitives, followed by GRPO for interaction-driven policy improvement, trains controllers for each environment. The framework is demonstrated on four control problems spanning a gradient of dynamical complexity, from canonical linear systems through nonlinear oscillatory dynamics to three-dimensional spacecraft attitude control with gyroscopic coupling and thrust constraints. Results demonstrate that an LLM with explicit reasoning, optimized via GRPO, can synthesize feasible stabilizing policies under consistent training settings across both linear and nonlinear systems. The two-stage training methodology enables models to generate control sequences while providing human-readable explanations of their decision-making process. This work establishes a foundation for applying GRPO-based reasoning to autonomous control systems, with potential applications in aerospace and other safety-critical domains.

</details>


### [81] [UNIC: Learning Unified Multimodal Extrinsic Contact Estimation](https://arxiv.org/abs/2601.04356)
*Zhengtong Xu,Yuki Shirai*

Main category: cs.RO

TL;DR: UNIC是一个统一的多模态框架，用于无先验知识或相机标定的外接触点估计，通过视觉、本体感觉和触觉模态融合实现可靠的接触估计。


<details>
  <summary>Details</summary>
Motivation: 现有外接触点估计方法依赖预定义接触类型、固定抓取配置或相机标定等限制性假设，难以泛化到新物体和非结构化环境。

Method: 提出基于场景可及性图的统一接触表示，采用带随机掩码的多模态融合机制，直接编码相机帧中的视觉观察并与本体感觉和触觉模态集成。

Result: 在未见接触位置达到9.6mm平均Chamfer距离误差，在未见物体上表现良好，对模态缺失具有鲁棒性，能适应动态相机视角。

Conclusion: UNIC将外接触点估计确立为接触丰富操作中实用且通用的能力。

Abstract: Contact-rich manipulation requires reliable estimation of extrinsic contacts-the interactions between a grasped object and its environment which provide essential contextual information for planning, control, and policy learning. However, existing approaches often rely on restrictive assumptions, such as predefined contact types, fixed grasp configurations, or camera calibration, that hinder generalization to novel objects and deployment in unstructured environments. In this paper, we present UNIC, a unified multimodal framework for extrinsic contact estimation that operates without any prior knowledge or camera calibration. UNIC directly encodes visual observations in the camera frame and integrates them with proprioceptive and tactile modalities in a fully data-driven manner. It introduces a unified contact representation based on scene affordance maps that captures diverse contact formations and employs a multimodal fusion mechanism with random masking, enabling robust multimodal representation learning. Extensive experiments demonstrate that UNIC performs reliably. It achieves a 9.6 mm average Chamfer distance error on unseen contact locations, performs well on unseen objects, remains robust under missing modalities, and adapts to dynamic camera viewpoints. These results establish extrinsic contact estimation as a practical and versatile capability for contact-rich manipulation.

</details>


### [82] [Transformer-based Multi-agent Reinforcement Learning for Separation Assurance in Structured and Unstructured Airspaces](https://arxiv.org/abs/2601.04401)
*Arsyi Aziz,Peng Wei*

Main category: cs.RO

TL;DR: 本文提出了一种基于相对极坐标状态空间和多智能体强化学习的自适应飞机间隔保障方法，通过Transformer编码器在不同交通模式和交叉角度下训练，实现了在结构化和非结构化空域中的优异性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于优化的计量方法依赖预先计算的严格调度，缺乏应对高级空中交通（AAM）随机操作所需的灵活性。现有MARL方法容易过拟合特定空域结构，限制了其对新配置的适应性。

Method: 将MARL问题重新表述为相对极坐标状态空间，使用Transformer编码器模型在不同交通模式和交叉角度下进行训练，为飞机提供速度建议以解决冲突并保持接近期望巡航速度。

Result: 实验表明，单层编码器配置优于深层变体，实现了接近零的空中接近碰撞率和更短的间隔违规时间。该配置还优于纯注意力基线模型。

Conclusion: 新提出的状态表示、神经网络架构设计和训练策略为结构化和非结构化空域提供了适应性强、可扩展的分散式飞机间隔保障解决方案。

Abstract: Conventional optimization-based metering depends on strict adherence to precomputed schedules, which limits the flexibility required for the stochastic operations of Advanced Air Mobility (AAM). In contrast, multi-agent reinforcement learning (MARL) offers a decentralized, adaptive framework that can better handle uncertainty, required for safe aircraft separation assurance. Despite this advantage, current MARL approaches often overfit to specific airspace structures, limiting their adaptability to new configurations. To improve generalization, we recast the MARL problem in a relative polar state space and train a transformer encoder model across diverse traffic patterns and intersection angles. The learned model provides speed advisories to resolve conflicts while maintaining aircraft near their desired cruising speeds. In our experiments, we evaluated encoder depths of 1, 2, and 3 layers in both structured and unstructured airspaces, and found that a single encoder configuration outperformed deeper variants, yielding near-zero near mid-air collision rates and shorter loss-of-separation infringements than the deeper configurations. Additionally, we showed that the same configuration outperforms a baseline model designed purely with attention. Together, our results suggest that the newly formulated state representation, novel design of neural network architecture, and proposed training strategy provide an adaptable and scalable decentralized solution for aircraft separation assurance in both structured and unstructured airspaces.

</details>


### [83] [Fast Continuum Robot Shape and External Load State Estimation on SE(3)](https://arxiv.org/abs/2601.04493)
*James M. Ferguson,Alan Kuntz,Tucker Hermans*

Main category: cs.RO

TL;DR: 提出了一种考虑驱动输入和外部载荷的连续体机器人时空状态估计框架，通过因子图实现实时运动学、力传感和负载估计


<details>
  <summary>Details</summary>
Motivation: 传统的连续体机器人状态估计方法采用简化的Cosserat杆模型，无法直接考虑驱动输入或外部载荷，需要更通用的框架来整合这些因素

Method: 引入包含驱动不确定性、外力力矩、过程噪声、边界条件和任意主干测量的通用框架，通过添加时间先验实现时空联合估计，利用因子图表示进行快速批量稀疏非线性优化

Result: 在仿真中展示了肌腱驱动机器人的实时运动学、基于位置反馈的末端力传感和基于主干应变的分布式负载估计；在实验中验证了手术同心管机器人的精确运动学和末端力估计

Conclusion: 该框架适用于广泛的连续体机器人类型，在手术触诊等应用中具有潜力

Abstract: Previous on-manifold approaches to continuum robot state estimation have typically adopted simplified Cosserat rod models, which cannot directly account for actuation inputs or external loads. We introduce a general framework that incorporates uncertainty models for actuation (e.g., tendon tensions), applied forces and moments, process noise, boundary conditions, and arbitrary backbone measurements. By adding temporal priors across time steps, our method additionally performs joint estimation in both the spatial (arclength) and temporal domains, enabling full \textit{spacetime} state estimation. Discretizing the arclength domain yields a factor graph representation of the continuum robot model, which can be exploited for fast batch sparse nonlinear optimization in the style of SLAM. The framework is general and applies to a broad class of continuum robots; as illustrative cases, we show (i) tendon-driven robots in simulation, where we demonstrate real-time kinematics with uncertainty, tip force sensing from position feedback, and distributed load estimation from backbone strain, and (ii) a surgical concentric tube robot in experiment, where we validate accurate kinematics and tip force estimation, highlighting potential for surgical palpation.

</details>


### [84] [Multiagent Reinforcement Learning with Neighbor Action Estimation](https://arxiv.org/abs/2601.04511)
*Zhenglong Luo,Zhiyong Chen,Aoxiang Liu*

Main category: cs.RO

TL;DR: 提出了一种增强型多智能体强化学习框架，通过动作估计神经网络推断邻近智能体行为，无需显式动作交换即可实现协作决策


<details>
  <summary>Details</summary>
Motivation: 解决现实工程环境中由于通信限制、延迟、能耗和可靠性要求而无法进行显式动作交换的问题

Method: 集成轻量级动作估计模块，每个智能体仅使用局部可观测信息推断邻近智能体行为，与标准TD3算法完全兼容且可扩展

Result: 在双臂机器人协作抓取任务中验证，显著提升机器人系统的鲁棒性和部署可行性，降低对信息基础设施的依赖

Conclusion: 该研究推动了去中心化多智能体人工智能系统的发展，使AI能够在信息受限的动态现实环境中有效运行

Abstract: Multiagent reinforcement learning, as a prominent intelligent paradigm, enables collaborative decision-making within complex systems. However, existing approaches often rely on explicit action exchange between agents to evaluate action value functions, which is frequently impractical in real-world engineering environments due to communication constraints, latency, energy consumption, and reliability requirements. From an artificial intelligence perspective, this paper proposes an enhanced multiagent reinforcement learning framework that employs action estimation neural networks to infer agent behaviors. By integrating a lightweight action estimation module, each agent infers neighboring agents' behaviors using only locally observable information, enabling collaborative policy learning without explicit action sharing. This approach is fully compatible with standard TD3 algorithms and scalable to larger multiagent systems. At the engineering application level, this framework has been implemented and validated in dual-arm robotic manipulation tasks: two robotic arms collaboratively lift objects. Experimental results demonstrate that this approach significantly enhances the robustness and deployment feasibility of real-world robotic systems while reducing dependence on information infrastructure. Overall, this research advances the development of decentralized multiagent artificial intelligence systems while enabling AI to operate effectively in dynamic, information-constrained real-world environments.

</details>


### [85] [Design and Development of Modular Limbs for Reconfigurable Robots on the Moon](https://arxiv.org/abs/2601.04541)
*Gustavo H. Diaz,A. Sejal Jain,Matteo Brugnera,Elian Neppel,Shreya Santra,Kentaro Uno,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 本文介绍了4自由度机器人肢体Moonbots的开发，这些模块化组件可相互连接并与轮模块组合，适应不同环境和任务，主要用于月球探索和建设任务。


<details>
  <summary>Details</summary>
Motivation: 开发模块化机器人系统以满足空间任务中资源受限环境下的灵活性和多功能性需求，特别是在月球探索和建设场景中。

Method: 采用统一的高扭矩-速度比驱动器设计，简化开发和维护；描述硬件实现、模块机械设计和整体软件架构；评估驱动器在不同负载下的控制性能。

Result: 成功开发出9种功能配置：4DOF肢体、8DOF肢体、车辆、龙形、最小化、四足、货物、货物最小化和自行车配置，展示了系统的适应性。

Conclusion: 模块化机器人系统为可重构机器人研究提供了实用基础，展示了在空间任务中通过模块组合实现不同运动策略和任务特定行为的可行性。

Abstract: In this paper, we present the development of 4-DOF robot limbs, which we call Moonbots, designed to connect in various configurations with each other and wheel modules, enabling adaptation to different environments and tasks. These modular components are intended primarily for robotic systems in space exploration and construction on the Moon in our Moonshot project. Such modular robots add flexibility and versatility for space missions where resources are constrained. Each module is driven by a common actuator characterized by a high torque-to-speed ratio, supporting both precise control and dynamic motion when required. This unified actuator design simplifies development and maintenance across the different module types. The paper describes the hardware implementation, the mechanical design of the modules, and the overall software architecture used to control and coordinate them. Additionally, we evaluate the control performance of the actuator under various load conditions to characterize its suitability for modular robot applications. To demonstrate the adaptability of the system, we introduce nine functional configurations assembled from the same set of modules: 4DOF-limb, 8DOF-limb, vehicle, dragon, minimal, quadruped, cargo, cargo-minimal, and bike. These configurations reflect different locomotion strategies and task-specific behaviors, offering a practical foundation for further research in reconfigurable robotic systems.

</details>


### [86] [Data-Driven Terramechanics Approach Towards a Realistic Real-Time Simulator for Lunar Rovers](https://arxiv.org/abs/2601.04547)
*Jakob M. Kern,James M. Hurrell,Shreya Santra,Keisuke Takehana,Kentaro Uno,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 该研究开发了一种结合高视觉保真度和真实地形交互的月球表面模拟器，通过数据驱动的回归模型准确模拟轮-土壤相互作用，支持实时应用。


<details>
  <summary>Details</summary>
Motivation: 当前月球表面模拟器要么注重视觉真实感，要么注重物理准确性，无法全面复制月球条件。这项研究旨在填补这一空白。

Method: 采用数据驱动方法，使用从全车和单轮实验及模拟中收集的数据建立回归模型，用于模拟滑移和下沉行为。改进了地形变形和车轮轨迹可视化的真实感。

Result: 回归型地形力学模型在平坦地形和高达20度的斜坡上准确再现了稳态和动态滑移以及下沉行为，并通过现场测试结果进行了验证。

Conclusion: 该方法能够在需要高视觉保真度和物理合理地形响应的实时应用中，提供真实的月球表面漫游车操作模拟。

Abstract: High-fidelity simulators for the lunar surface provide a digital environment for extensive testing of rover operations and mission planning. However, current simulators focus on either visual realism or physical accuracy, which limits their capability to replicate lunar conditions comprehensively. This work addresses that gap by combining high visual fidelity with realistic terrain interaction for a realistic representation of rovers on the lunar surface. Because direct simulation of wheel-soil interactions is computationally expensive, a data-driven approach was adopted, using regression models for slip and sinkage from data collected in both full-rover and single-wheel experiments and simulations. The resulting regression-based terramechanics model accurately reproduced steady-state and dynamic slip, as well as sinkage behavior, on flat terrain and slopes up to 20 degrees, with validation against field test results. Additionally, improvements were made to enhance the realism of terrain deformation and wheel trace visualization. This method supports real-time applications that require physically plausible terrain response alongside high visual fidelity.

</details>


### [87] [Discrete Fourier Transform-based Point Cloud Compression for Efficient SLAM in Featureless Terrain](https://arxiv.org/abs/2601.04551)
*Riku Suzuki,Ayumi Umemura,Shreya Santra,Kentaro Uno,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 提出了一种基于离散傅里叶变换的点云地图压缩方法，通过去除高频分量来压缩渐进地形数据


<details>
  <summary>Details</summary>
Motivation: 在计算能力和通信带宽受限的无人机器人探索任务中，SLAM处理的点云数据量庞大，需要有效的压缩方法

Method: 将数字高程模型转换为频域2D图像，去除高频分量，专注于处理渐进地形如行星和沙漠

Result: 在两种不同高程剖面的地形上评估，该方法在压缩率和精度方面表现良好

Conclusion: 该方法能有效压缩数据大小而不会显著降低点云质量，特别适用于渐进地形

Abstract: Simultaneous Localization and Mapping (SLAM) is an essential technology for the efficiency and reliability of unmanned robotic exploration missions. While the onboard computational capability and communication bandwidth are critically limited, the point cloud data handled by SLAM is large in size, attracting attention to data compression methods. To address such a problem, in this paper, we propose a new method for compressing point cloud maps by exploiting the Discrete Fourier Transform (DFT). The proposed technique converts the Digital Elevation Model (DEM) to the frequency-domain 2D image and omits its high-frequency components, focusing on the exploration of gradual terrains such as planets and deserts. Unlike terrains with detailed structures such as artificial environments, high-frequency components contribute little to the representation of gradual terrains. Thus, this method is effective in compressing data size without significant degradation of the point cloud. We evaluated the method in terms of compression rate and accuracy using camera sequences of two terrains with different elevation profiles.

</details>


### [88] [UniBiDex: A Unified Teleoperation Framework for Robotic Bimanual Dexterous Manipulation](https://arxiv.org/abs/2601.04629)
*Zhongxuan Li,Zeliang Guo,Jun Hu,David Navarro-Alarcon,Jia Pan,Hongmin Wu,Peng Zhou*

Main category: cs.RO

TL;DR: UniBiDex是一个统一的机器人双手灵巧操作遥操作框架，支持VR和领导者跟随两种输入模式，通过零空间控制实现安全、平滑的双臂运动，在厨房整理任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 开发一个统一的遥操作框架来降低收集大规模高质量人类示范数据集的障碍，加速机器人学习进展。

Method: 集成异构输入设备到共享控制堆栈中，采用零空间控制优化双手配置，确保平滑、无碰撞且能感知奇异点的运动。

Result: 在包含五个连续操作子任务的长期厨房整理任务中验证，相比强基线方法具有更高的任务成功率、更平滑的轨迹和更好的鲁棒性。

Conclusion: 通过开源所有硬件和软件组件，UniBiDex框架有望促进大规模高质量人类示范数据集的收集，推动机器人学习领域的发展。

Abstract: We present UniBiDex a unified teleoperation framework for robotic bimanual dexterous manipulation that supports both VRbased and leaderfollower input modalities UniBiDex enables realtime contactrich dualarm teleoperation by integrating heterogeneous input devices into a shared control stack with consistent kinematic treatment and safety guarantees The framework employs nullspace control to optimize bimanual configurations ensuring smooth collisionfree and singularityaware motion across tasks We validate UniBiDex on a longhorizon kitchentidying task involving five sequential manipulation subtasks demonstrating higher task success rates smoother trajectories and improved robustness compared to strong baselines By releasing all hardware and software components as opensource we aim to lower the barrier to collecting largescale highquality human demonstration datasets and accelerate progress in robot learning.

</details>


### [89] [Model of Spatial Human-Agent Interaction with Consideration for Others](https://arxiv.org/abs/2601.04657)
*Takafumi Sakamoto,Yugo Takeuchi*

Main category: cs.RO

TL;DR: 该研究构建了一个考虑他人意图的计算空间交互模型，通过虚拟现实实验验证了模型在机器人社交互动中的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决通信机器人在公共空间中既要主动发起对话又不能打扰行人的矛盾需求，需要基于他人行为估计其沟通意愿并相应调整自身行为。

Method: 构建了一个考虑他人的计算空间交互模型，将考虑量化为调整自身内部状态到估计他人内部状态的参数。在VR环境中进行人与虚拟机器人互动实验。

Result: 实验结果显示：低考虑值的机器人会抑制参与者移动，而高考虑值的机器人不会；当参与者接近机器人时，机器人也会表现出接近行为，从而减少参与者移动。

Conclusion: 该模型能够有效阐明考虑他人意图的交互行为，验证了模型在机器人社交互动中的实用性。

Abstract: Communication robots often need to initiate conversations with people in public spaces. At the same time, such robots must not disturb pedestrians. To handle these two requirements, an agent needs to estimate the communication desires of others based on their behavior and then adjust its own communication activities accordingly. In this study, we construct a computational spatial interaction model that considers others. Consideration is expressed as a quantitative parameter: the amount of adjustment of one's internal state to the estimated internal state of the other. To validate the model, we experimented with a human and a virtual robot interacting in a VR environment. The results show that when the participant moves to the target, a virtual robot with a low consideration value inhibits the participant's movement, while a robot with a higher consideration value did not inhibit the participant's movement. When the participant approached the robot, the robot also exhibited approaching behavior, regardless of the consideration value, thus decreasing the participant's movement. These results appear to verify the proposed model's ability to clarify interactions with consideration for others.

</details>


### [90] [Optimizing Path Planning using Deep Reinforcement Learning for UGVs in Precision Agriculture](https://arxiv.org/abs/2601.04668)
*Laukik Patade,Rohan Rane,Sandeep Pillai*

Main category: cs.RO

TL;DR: 本研究使用深度强化学习在连续动作空间中优化农业无人地面车辆的路径规划，通过DDPG和TD3算法在动态农业环境中实现95%的成功率。


<details>
  <summary>Details</summary>
Motivation: 传统网格化路径规划方法（如A*和Dijkstra）在动态农业环境中适应性不足，需要开发能够处理连续动作空间的自适应学习策略。

Method: 研究从DQN算法开始，逐步引入Double Q-Networks和Dueling Networks改进，最终采用DDPG和TD3连续动作空间算法，在ROS和Gazebo的三维环境中进行测试。

Result: 预训练的TD3智能体在动态环境中达到95%的成功率，能够有效处理移动障碍物，同时确保作物和机器人的安全。

Conclusion: 连续动作空间的深度强化学习算法在农业无人车路径规划中表现出优越的适应性和鲁棒性，TD3算法特别适合动态农业环境的应用。

Abstract: This study focuses on optimizing path planning for unmanned ground vehicles (UGVs) in precision agriculture using deep reinforcement learning (DRL) techniques in continuous action spaces. The research begins with a review of traditional grid-based methods, such as A* and Dijkstra's algorithms, and discusses their limitations in dynamic agricultural environments, highlighting the need for adaptive learning strategies. The study then explores DRL approaches, including Deep Q-Networks (DQN), which demonstrate improved adaptability and performance in two-dimensional simulations. Enhancements such as Double Q-Networks and Dueling Networks are evaluated to further improve decision-making. Building on these results, the focus shifts to continuous action space models, specifically Deep Deterministic Policy Gradient (DDPG) and Twin Delayed Deep Deterministic Policy Gradient (TD3), which are tested in increasingly complex environments. Experiments conducted in a three-dimensional environment using ROS and Gazebo demonstrate the effectiveness of continuous DRL algorithms in navigating dynamic agricultural scenarios. Notably, the pretrained TD3 agent achieves a 95 percent success rate in dynamic environments, demonstrating the robustness of the proposed approach in handling moving obstacles while ensuring safety for both crops and the robot.

</details>


### [91] [SeqWalker: Sequential-Horizon Vision-and-Language Navigation with Hierarchical Planning](https://arxiv.org/abs/2601.04699)
*Zebin Han,Xudong Wang,Baichen Liu,Qi Lyu,Zhenduo Shang,Jiahua Dong,Lianqing Liu,Zhi Han*

Main category: cs.RO

TL;DR: SeqWalker是一个用于顺序视野视觉语言导航的分层规划模型，通过高层规划器动态选择子指令和低层规划器的探索-验证策略来解决多任务导航中的信息过载问题。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言导航模型在处理复杂长视野多任务指令时性能显著下降，信息过载导致代理难以关注观察相关的细节。

Method: 提出SeqWalker分层规划框架：1）高层规划器基于当前视觉观察动态选择相关子指令；2）低层规划器采用探索-验证策略利用指令逻辑结构进行轨迹纠错。

Result: 通过扩展IVLN数据集建立新基准，大量实验证明了SeqWalker的优越性能。

Conclusion: SeqWalker通过分层规划有效解决了多任务导航中的信息过载问题，在顺序视野视觉语言导航任务中表现出色。

Abstract: Sequential-Horizon Vision-and-Language Navigation (SH-VLN) presents a challenging scenario where agents should sequentially execute multi-task navigation guided by complex, long-horizon language instructions. Current vision-and-language navigation models exhibit significant performance degradation with such multi-task instructions, as information overload impairs the agent's ability to attend to observationally relevant details. To address this problem, we propose SeqWalker, a navigation model built on a hierarchical planning framework. Our SeqWalker features: i) A High-Level Planner that dynamically selects global instructions into contextually relevant sub-instructions based on the agent's current visual observations, thus reducing cognitive load; ii) A Low-Level Planner incorporating an Exploration-Verification strategy that leverages the inherent logical structure of instructions for trajectory error correction. To evaluate SH-VLN performance, we also extend the IVLN dataset and establish a new benchmark. Extensive experiments are performed to demonstrate the superiority of the proposed SeqWalker.

</details>


### [92] [Zero Wrench Control via Wrench Disturbance Observer for Learning-free Peg-in-hole Assembly](https://arxiv.org/abs/2601.04881)
*Kiyoung Choi,Juwon Jeong,Sehoon Oh*

Main category: cs.RO

TL;DR: 提出动态力矩扰动观测器（DW-DOB），通过嵌入任务空间惯性到观测器名义模型中，实现接触丰富操作中的高灵敏度零力矩控制。


<details>
  <summary>Details</summary>
Motivation: 解决传统观测器无法补偿惯性效应的问题，在动态条件下保证稳定的交互，同时保持对小力和力矩的灵敏度。

Method: 设计动态力矩扰动观测器，将任务空间惯性嵌入观测器名义模型，清晰分离内在动态反应和真实外部力矩。基于无源性的分析证明其稳定性。

Result: 在工业公差（H7/h6）的孔轴配合实验中验证，相比传统力矩扰动观测器和PD基线，实现了更深、更柔顺的插入，残余力矩更小。

Conclusion: DW-DOB是接触丰富任务中高精度零力矩控制的实用无学习解决方案。

Abstract: This paper proposes a Dynamic Wrench Disturbance Observer (DW-DOB) designed to achieve highly sensitive zero-wrench control in contact-rich manipulation. By embedding task-space inertia into the observer nominal model, DW-DOB cleanly separates intrinsic dynamic reactions from true external wrenches. This preserves sensitivity to small forces and moments while ensuring robust regulation of contact wrenches. A passivity-based analysis further demonstrates that DW-DOB guarantees stable interactions under dynamic conditions, addressing the shortcomings of conventional observers that fail to compensate for inertial effects. Peg-in-hole experiments at industrial tolerances (H7/h6) validate the approach, yielding deeper and more compliant insertions with minimal residual wrenches and outperforming a conventional wrench disturbance observer and a PD baseline. These results highlight DW-DOB as a practical learning-free solution for high-precision zero-wrench control in contact-rich tasks.

</details>


### [93] [SKATER: Synthesized Kinematics for Advanced Traversing Efficiency on a Humanoid Robot via Roller Skate Swizzles](https://arxiv.org/abs/2601.04948)
*Junchi Gu,Feiyang Yuan,Weize Shi,Tianchen Huang,Haopeng Zhang,Xiaohu Zhang,Yu Wang,Wei Gao,Shiwu Zhang*

Main category: cs.RO

TL;DR: 该论文提出了一种配备被动轮的人形机器人，通过轮滑运动替代传统双足行走，以减少关节磨损并提高能量效率。


<details>
  <summary>Details</summary>
Motivation: 传统双足行走和跑步时频繁的足部撞击地面会产生高瞬时冲击力，导致关节磨损加剧和能量利用率低下。轮滑运动能够利用身体惯性实现快速连续滑动，动能损失最小。

Method: 开发了一种每只脚配备四个被动轮的人形机器人，并基于轮滑内在特性设计了深度强化学习控制框架，用于学习swizzle步态。

Result: 仿真和物理实验表明，轮滑步态在冲击强度和运输成本方面比传统双足行走步态更平滑高效，这两个指标分别降低了75.86%和63.34%。

Conclusion: 轮滑是一种优越的运动模式，能够显著提高能量效率和延长关节寿命。

Abstract: Although recent years have seen significant progress of humanoid robots in walking and running, the frequent foot strikes with ground during these locomotion gaits inevitably generate high instantaneous impact forces, which leads to exacerbated joint wear and poor energy utilization. Roller skating, as a sport with substantial biomechanical value, can achieve fast and continuous sliding through rational utilization of body inertia, featuring minimal kinetic energy loss. Therefore, this study proposes a novel humanoid robot with each foot equipped with a row of four passive wheels for roller skating. A deep reinforcement learning control framework is also developed for the swizzle gait with the reward function design based on the intrinsic characteristics of roller skating. The learned policy is first analyzed in simulation and then deployed on the physical robot to demonstrate the smoothness and efficiency of the swizzle gait over traditional bipedal walking gait in terms of Impact Intensity and Cost of Transport during locomotion. A reduction of $75.86\%$ and $63.34\%$ of these two metrics indicate roller skating as a superior locomotion mode for enhanced energy efficiency and joint longevity.

</details>


### [94] [When to Act: Calibrated Confidence for Reliable Human Intention Prediction in Assistive Robotics](https://arxiv.org/abs/2601.04982)
*Johannes A. Gaus,Winfried Ilg,Daniel Haeufle*

Main category: cs.RO

TL;DR: 提出基于校准概率的安全关键触发框架，用于日常活动中的多模态下一动作预测，通过后处理校准使模型置信度反映真实可靠性，并设计ACT/HOLD决策规则确保辅助行为的安全性。


<details>
  <summary>Details</summary>
Motivation: 辅助设备在提供支持前需要准确预测用户意图及其可靠性，但原始模型置信度往往无法反映真实正确性，存在安全风险。

Method: 采用后处理校准方法对齐预测置信度与经验可靠性，将校准误差降低约一个数量级而不影响准确率；基于校准置信度设计简单的ACT/HOLD决策规则。

Result: 校准后置信度显著改善，校准误差大幅降低；ACT/HOLD规则将置信度阈值转化为可量化的安全参数，实现辅助控制回路中的可验证行为。

Conclusion: 该框架通过概率校准和决策规则为辅助设备提供了安全可靠的触发机制，有效降低了错误辅助动作的风险。

Abstract: Assistive devices must determine both what a user intends to do and how reliable that prediction is before providing support. We introduce a safety-critical triggering framework based on calibrated probabilities for multimodal next-action prediction in Activities of Daily Living. Raw model confidence often fails to reflect true correctness, posing a safety risk. Post-hoc calibration aligns predicted confidence with empirical reliability and reduces miscalibration by about an order of magnitude without affecting accuracy. The calibrated confidence drives a simple ACT/HOLD rule that acts only when reliability is high and withholds assistance otherwise. This turns the confidence threshold into a quantitative safety parameter for assisted actions and enables verifiable behavior in an assistive control loop.

</details>


### [95] [The RoboSense Challenge: Sense Anything, Navigate Anywhere, Adapt Across Platforms](https://arxiv.org/abs/2601.05014)
*Lingdong Kong,Shaoyuan Xie,Zeying Gong,Ye Li,Meng Chu,Ao Liang,Yuhao Dong,Tianshuai Hu,Ronghe Qiu,Rong Li,Hanjiang Hu,Dongyue Lu,Wei Yin,Wenhao Ding,Linfeng Li,Hang Song,Wenwei Zhang,Yuexin Ma,Junwei Liang,Zhedong Zheng,Lai Xing Ng,Benoit R. Cottereau,Wei Tsang Ooi,Ziwei Liu,Zhanpeng Zhang,Weichao Qiu,Wei Zhang,Ji Ao,Jiangpeng Zheng,Siyu Wang,Guang Yang,Zihao Zhang,Yu Zhong,Enzhu Gao,Xinhan Zheng,Xueting Wang,Shouming Li,Yunkai Gao,Siming Lan,Mingfei Han,Xing Hu,Dusan Malic,Christian Fruhwirth-Reisinger,Alexander Prutsch,Wei Lin,Samuel Schulter,Horst Possegger,Linfeng Li,Jian Zhao,Zepeng Yang,Yuhang Song,Bojun Lin,Tianle Zhang,Yuchen Yuan,Chi Zhang,Xuelong Li,Youngseok Kim,Sihwan Hwang,Hyeonjun Jeong,Aodi Wu,Xubo Luo,Erjia Xiao,Lingfeng Zhang,Yingbo Tang,Hao Cheng,Renjing Xu,Wenbo Ding,Lei Zhou,Long Chen,Hangjun Ye,Xiaoshuai Hao,Shuangzhi Li,Junlong Shen,Xingyu Li,Hao Ruan,Jinliang Lin,Zhiming Luo,Yu Zang,Cheng Wang,Hanshi Wang,Xijie Gong,Yixiang Yang,Qianli Ma,Zhipeng Zhang,Wenxiang Shi,Jingmeng Zhou,Weijun Zeng,Kexin Xu,Yuchen Zhang,Haoxiang Fu,Ruibin Hu,Yanbiao Ma,Xiyan Feng,Wenbo Zhang,Lu Zhang,Yunzhi Zhuge,Huchuan Lu,You He,Seungjun Yu,Junsung Park,Youngsun Lim,Hyunjung Shim,Faduo Liang,Zihang Wang,Yiming Peng,Guanyu Zong,Xu Li,Binghao Wang,Hao Wei,Yongxin Ma,Yunke Shi,Shuaipeng Liu,Dong Kong,Yongchun Lin,Huitong Yang,Liang Lei,Haoang Li,Xinliang Zhang,Zhiyong Wang,Xiaofeng Wang,Yuxia Fu,Yadan Luo,Djamahl Etchegaray,Yang Li,Congfei Li,Yuxiang Sun,Wenkai Zhu,Wang Xu,Linru Li,Longjie Liao,Jun Yan,Benwu Wang,Xueliang Ren,Xiaoyu Yue,Jixian Zheng,Jinfeng Wu,Shurui Qin,Wei Cong,Yao He*

Main category: cs.RO

TL;DR: RoboSense 2025挑战赛旨在推动机器人感知在多样化传感场景中的鲁棒性和适应性，通过五个互补研究赛道构建全面基准，吸引了全球143个团队参与，并总结了23个获胜方案的共同设计原则和开放挑战。


<details>
  <summary>Details</summary>
Motivation: 自主系统在开放动态环境中部署时，感知模型需要在传感器噪声、环境变化和平台差异下保持可靠性，但现有方法在未见条件下性能下降，需要提升机器人感知的鲁棒性和泛化能力。

Method: 挑战赛设计了五个研究赛道：语言引导决策、社会合规导航、传感器配置泛化、跨视角跨模态对应、跨平台3D感知，提供标准化数据集、基线模型和统一评估协议。

Result: 吸引了来自16个国家85个机构的143个团队参与，通过分析23个获胜方案，揭示了新兴方法趋势和共享设计原则。

Conclusion: 该挑战赛为评估真实世界传感可靠性提供了综合基准，标志着向构建能够在现实环境中可靠感知、鲁棒行动和跨平台适应的机器人迈出了重要一步。

Abstract: Autonomous systems are increasingly deployed in open and dynamic environments -- from city streets to aerial and indoor spaces -- where perception models must remain reliable under sensor noise, environmental variation, and platform shifts. However, even state-of-the-art methods often degrade under unseen conditions, highlighting the need for robust and generalizable robot sensing. The RoboSense 2025 Challenge is designed to advance robustness and adaptability in robot perception across diverse sensing scenarios. It unifies five complementary research tracks spanning language-grounded decision making, socially compliant navigation, sensor configuration generalization, cross-view and cross-modal correspondence, and cross-platform 3D perception. Together, these tasks form a comprehensive benchmark for evaluating real-world sensing reliability under domain shifts, sensor failures, and platform discrepancies. RoboSense 2025 provides standardized datasets, baseline models, and unified evaluation protocols, enabling large-scale and reproducible comparison of robust perception methods. The challenge attracted 143 teams from 85 institutions across 16 countries, reflecting broad community engagement. By consolidating insights from 23 winning solutions, this report highlights emerging methodological trends, shared design principles, and open challenges across all tracks, marking a step toward building robots that can sense reliably, act robustly, and adapt across platforms in real-world environments.

</details>


### [96] [Compensation Effect Amplification Control (CEAC): A movement-based approach for coordinated position and velocity control of the elbow of upper-limb prostheses](https://arxiv.org/abs/2601.05074)
*Julian Kulozik,Nathanaël Jarrassé*

Main category: cs.RO

TL;DR: 本文提出了一种名为补偿效应放大控制（CEAC）的新颖运动控制范式，利用躯干屈伸作为输入来控制假肢肘部速度，实现了连续和速度调节的直观控制。


<details>
  <summary>Details</summary>
Motivation: 当前上肢假肢设计在控制中间关节（如手腕和肘部）方面仍面临挑战，特别是对于连续和速度调节的运动。需要一种更直观的控制方法来改善假肢使用体验。

Method: CEAC通过放大躯干与假肢之间的自然耦合，并引入可控延迟，使用户能够调节假肢关节的位置和速度。在12名健康参与者中使用超数假肢进行通用绘图任务评估，10名参与者进行多目标到达任务。

Result: 结果显示任务表现与自然手臂运动相当，即使改变手势速度或绘图大小时也能保持符合人体工学的躯干姿势。CEAC有效恢复了关节协调动作，在躯干和肘部之间分配运动努力。

Conclusion: CEAC为上肢假肢中间关节提供了一种有前景的控制策略，特别适用于需要连续和精确协调的任务。

Abstract: Despite advances in upper-limb (UL) prosthetic design, achieving intuitive control of intermediate joints - such as the wrist and elbow - remains challenging, particularly for continuous and velocity-modulated movements. We introduce a novel movement-based control paradigm entitled Compensation Effect Amplification Control (CEAC) that leverages users' trunk flexion and extension as input for controlling prosthetic elbow velocity. Considering that the trunk can be both a functional and compensatory joint when performing upper-limb actions, CEAC amplifies the natural coupling between trunk and prosthesis while introducing a controlled delay that allows users to modulate both the position and velocity of the prosthetic joint. We evaluated CEAC in a generic drawing task performed by twelve able-bodied participants using a supernumerary prosthesis with an active elbow. Additionally a multiple-target-reaching task was performed by a subset of ten participants. Results demonstrate task performances comparable to those obtained with natural arm movements, even when gesture velocity or drawing size were varied, while maintaining ergonomic trunk postures. Analysis revealed that CEAC effectively restores joint coordinated action, distributes movement effort between trunk and elbow, enabling intuitive trajectory control without requiring extreme compensatory movements. Overall, CEAC offers a promising control strategy for intermediate joints of UL prostheses, particularly in tasks requiring continuous and precise coordination.

</details>


### [97] [Generate, Transfer, Adapt: Learning Functional Dexterous Grasping from a Single Human Demonstration](https://arxiv.org/abs/2601.05243)
*Xingyi He,Adhitya Polavaram,Yunhao Cao,Om Deshmukh,Tianrui Wang,Xiaowei Zhou,Kuan Fang*

Main category: cs.RO

TL;DR: CorDex是一个从单个人类演示生成合成数据来学习灵巧机器人功能抓握的框架，通过基于对应的数据引擎和融合视觉几何信息的多模态预测网络，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决灵巧机器人功能抓握的两个关键瓶颈：大规模数据稀缺问题，以及学习模型中缺乏语义和几何推理的集成。

Method: 1) 基于对应的数据引擎：从单个人类演示生成多样化物体实例，通过对应估计将专家抓握转移到生成物体，并通过优化调整抓握；2) 多模态预测网络：集成视觉和几何信息，采用局部-全局融合模块和重要性感知采样机制。

Result: 在多个物体类别上的实验表明，CorDex能够很好地泛化到未见过的物体实例，并显著优于现有最先进的方法。

Conclusion: CorDex框架通过创新的数据生成和融合学习方法，有效解决了灵巧功能抓握的数据稀缺和推理集成问题，为实现工具使用和复杂操作提供了重要能力。

Abstract: Functional grasping with dexterous robotic hands is a key capability for enabling tool use and complex manipulation, yet progress has been constrained by two persistent bottlenecks: the scarcity of large-scale datasets and the absence of integrated semantic and geometric reasoning in learned models. In this work, we present CorDex, a framework that robustly learns dexterous functional grasps of novel objects from synthetic data generated from just a single human demonstration. At the core of our approach is a correspondence-based data engine that generates diverse, high-quality training data in simulation. Based on the human demonstration, our data engine generates diverse object instances of the same category, transfers the expert grasp to the generated objects through correspondence estimation, and adapts the grasp through optimization. Building on the generated data, we introduce a multimodal prediction network that integrates visual and geometric information. By devising a local-global fusion module and an importance-aware sampling mechanism, we enable robust and computationally efficient prediction of functional dexterous grasps. Through extensive experiments across various object categories, we demonstrate that CorDex generalizes well to unseen object instances and significantly outperforms state-of-the-art baselines.

</details>


### [98] [LaST$_{0}$: Latent Spatio-Temporal Chain-of-Thought for Robotic Vision-Language-Action Model](https://arxiv.org/abs/2601.05248)
*Zhuoyang Liu,Jiaming Liu,Hao Chen,Ziyu Guo,Chengkai Hou,Chenyang Gu,Jiale Yu,Xiangju Mi,Renrui Zhang,Zhengping Che,Jian Tang,Pheng-Ann Heng,Shanghang Zhang*

Main category: cs.RO

TL;DR: LaST$_0$是一个通过潜在时空思维链实现高效推理的视觉-语言-动作模型框架，在保持快速推理的同时显著提升机器人操作任务的成功率


<details>
  <summary>Details</summary>
Motivation: 现有VLA方法通过显式生成语言推理轨迹或未来视觉观察来提高动作准确性，但存在推理延迟高和语言表示瓶颈的问题，难以准确捕捉不可言说的物理属性

Method: 提出潜在时空思维链(CoT)空间，建模未来视觉动态、3D结构信息和机器人本体感知状态；采用双系统架构（推理专家和动作专家），通过混合Transformer设计实现异构频率操作

Result: 在10个模拟和6个真实世界操作任务中，相比现有VLA方法分别提升8%和13%的平均成功率，同时实现更快的推理速度

Conclusion: LaST$_0$通过潜在时空推理有效解决了VLA模型中的推理延迟和表示瓶颈问题，为机器人操作任务提供了更高效准确的解决方案

Abstract: Vision-Language-Action (VLA) models have recently demonstrated strong generalization capabilities in robotic manipulation. Some existing VLA approaches attempt to improve action accuracy by explicitly generating linguistic reasoning traces or future visual observations before action execution. However, explicit reasoning typically incurs non-negligible inference latency, which constrains the temporal resolution required for robotic manipulation. Moreover, such reasoning is confined to the linguistic space, imposing a representational bottleneck that struggles to faithfully capture ineffable physical attributes. To mitigate these limitations, we propose LaST$_0$, a framework that enables efficient reasoning before acting through a Latent Spatio-Temporal Chain-of-Thought (CoT), capturing fine-grained physical and robotic dynamics that are often difficult to verbalize. Specifically, we introduce a token-efficient latent CoT space that models future visual dynamics, 3D structural information, and robot proprioceptive states, and further extends these representations across time to enable temporally consistent implicit reasoning trajectories. Furthermore, LaST$_0$ adopts a dual-system architecture implemented via a Mixture-of-Transformers design, where a reasoning expert conducts low-frequency latent inference and an acting expert generates high-frequency actions conditioned on robotics-oriented latent representations. To facilitate coordination, LaST$_0$ is trained with heterogeneous operation frequencies, enabling adaptive switching between reasoning and action inference rates during deployment. Across ten simulated and six real-world manipulation tasks, LaST$_0$ improves mean success rates by 8% and 13% over prior VLA methods, respectively, while achieving substantially faster inference. Project website: https://sites.google.com/view/last0

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [99] [The Forgotten Shield: Safety Grafting in Parameter-Space for Medical MLLMs](https://arxiv.org/abs/2601.04199)
*Jiale Zhao,Xing Mou,Jinlin Wu,Hongyuan Yu,Mingrui Sun,Yang Shi,Xuanwu Yin,Zhen Chen,Zhen Lei,Yaohua Wang*

Main category: cs.LG

TL;DR: 本文提出了一个多维评估框架来系统评估当前最先进的医学多模态大语言模型的安全性，发现现有模型存在普遍脆弱性，并提出了一种新颖的"参数空间干预"方法来实现安全重新对齐。


<details>
  <summary>Details</summary>
Motivation: 医学多模态大语言模型在专业医疗任务上取得了显著进展，但其安全性研究滞后，存在实际部署风险。

Method: 建立多维评估框架进行安全性基准测试；提出参数空间干预方法，从原始基础模型中提取内在安全知识表示，并在构建医疗能力时注入目标模型；设计细粒度参数搜索算法实现安全性与医疗性能的最佳平衡。

Result: 实验结果表明，该方法显著增强了医学MLLMs的安全防护，无需依赖额外的领域特定安全数据，同时最小化核心医疗性能的下降。

Conclusion: 该方法有效解决了医学微调过程中导致的安全对齐遗忘问题，为医学MLLMs的安全部署提供了可行解决方案。

Abstract: Medical Multimodal Large Language Models (Medical MLLMs) have achieved remarkable progress in specialized medical tasks; however, research into their safety has lagged, posing potential risks for real-world deployment. In this paper, we first establish a multidimensional evaluation framework to systematically benchmark the safety of current SOTA Medical MLLMs. Our empirical analysis reveals pervasive vulnerabilities across both general and medical-specific safety dimensions in existing models, particularly highlighting their fragility against cross-modality jailbreak attacks. Furthermore, we find that the medical fine-tuning process frequently induces catastrophic forgetting of the model's original safety alignment. To address this challenge, we propose a novel "Parameter-Space Intervention" approach for efficient safety re-alignment. This method extracts intrinsic safety knowledge representations from original base models and concurrently injects them into the target model during the construction of medical capabilities. Additionally, we design a fine-grained parameter search algorithm to achieve an optimal trade-off between safety and medical performance. Experimental results demonstrate that our approach significantly bolsters the safety guardrails of Medical MLLMs without relying on additional domain-specific safety data, while minimizing degradation to core medical performance.

</details>


### [100] [Green MLOps: Closed-Loop, Energy-Aware Inference with NVIDIA Triton, FastAPI, and Bio-Inspired Thresholding](https://arxiv.org/abs/2601.04250)
*Mustapha Hamdi,Mourad Jabou*

Main category: cs.LG

TL;DR: 本文提出了一种受生物启发的能量感知推理框架，通过将蛋白质折叠能量盆地映射到推理成本景观，使用衰减闭环阈值控制执行，在保证精度的前提下显著降低处理时间。


<details>
  <summary>Details</summary>
Motivation: AI部署中的能源效率是首要关注点，因为长期运行的推理可能超过训练的累积碳影响。需要一种能够平衡效用与能耗的推理控制机制。

Method: 提出生物启发框架，将蛋白质折叠能量盆地映射到推理成本景观，通过衰减闭环阈值控制请求执行。仅当预期效用-能量权衡有利时（高置信度/效用、低边际能量和拥塞）才允许请求，偏向于第一个可接受的局部盆地而非追求昂贵的全局最小值。

Result: 在RTX 4000 Ada GPU上评估DistilBERT和ResNet-18，生物控制器相比标准开环执行减少处理时间42%（A100测试集上从0.50s降至0.29s），精度损失小于0.5%。确定了轻量级本地服务（ORT）与管理批处理（Triton）之间的效率边界。

Conclusion: 该研究将生物物理能量模型与绿色MLOps联系起来，为生产环境中的闭环能量感知推理提供了实用且可审计的基础。

Abstract: Energy efficiency is a first-order concern in AI deployment, as long-running inference can exceed training in cumulative carbon impact. We propose a bio-inspired framework that maps protein-folding energy basins to inference cost landscapes and controls execution via a decaying, closed-loop threshold. A request is admitted only when the expected utility-to-energy trade-off is favorable (high confidence/utility at low marginal energy and congestion), biasing operation toward the first acceptable local basin rather than pursuing costly global minima. We evaluate DistilBERT and ResNet-18 served through FastAPI with ONNX Runtime and NVIDIA Triton on an RTX 4000 Ada GPU. Our ablation study reveals that the bio-controller reduces processing time by 42% compared to standard open-loop execution (0.50s vs 0.29s on A100 test set), with a minimal accuracy degradation (<0.5%). Furthermore, we establish the efficiency boundaries between lightweight local serving (ORT) and managed batching (Triton). The results connect biophysical energy models to Green MLOps and offer a practical, auditable basis for closed-loop energy-aware inference in production.

</details>


### [101] [Safety-Utility Conflicts Are Not Global: Surgical Alignment via Head-Level Diagnosis](https://arxiv.org/abs/2601.04262)
*Wang Cai,Yilin Wen,Jinchang Hou,Du Su,Guoqiu Wang,Zhonghou Lv,Chenfu Bao,Yunfang Wu*

Main category: cs.LG

TL;DR: 本文提出CAST框架，通过分析Transformer中注意力头的冲突分布，选择性跳过高冲突头的更新，在保持安全性的同时减少通用能力下降。


<details>
  <summary>Details</summary>
Motivation: 现有安全对齐方法使用全局梯度几何学，忽视了Transformer中不同注意力头的功能敏感性和冲突程度存在显著差异，导致参数更新不够优化。

Method: CAST框架首先构建预对齐冲突图，综合优化冲突和功能敏感性分析，然后指导选择性参数更新，特别是跳过高冲突注意力头的训练。

Result: 实验发现LLMs中的对齐冲突分布不均，通用能力下降主要来自更新少数高冲突头。跳过这些头可显著减少能力损失且不影响安全性。

Conclusion: CAST提供了一种可解释且参数高效的方法，通过头级诊断和稀疏微调改善安全性与通用能力之间的权衡。

Abstract: Safety alignment in Large Language Models (LLMs) inherently presents a multi-objective optimization conflict, often accompanied by an unintended degradation of general capabilities. Existing mitigation strategies typically rely on global gradient geometry to resolve these conflicts, yet they overlook Modular Heterogeneity within Transformers, specifically that the functional sensitivity and degree of conflict vary substantially across different attention heads. Such global approaches impose uniform update rules across all parameters, often resulting in suboptimal trade-offs by indiscriminately updating utility sensitive heads that exhibit intense gradient conflicts. To address this limitation, we propose Conflict-Aware Sparse Tuning (CAST), a framework that integrates head-level diagnosis with sparse fine-tuning. CAST first constructs a pre-alignment conflict map by synthesizing Optimization Conflict and Functional Sensitivity, which then guides the selective update of parameters. Experiments reveal that alignment conflicts in LLMs are not uniformly distributed. We find that the drop in general capabilities mainly comes from updating a small group of ``high-conflict'' heads. By simply skipping these heads during training, we significantly reduce this loss without compromising safety, offering an interpretable and parameter-efficient approach to improving the safety-utility trade-off.

</details>


### [102] [Learning to Reason: Temporal Saliency Distillation for Interpretable Knowledge Transfer](https://arxiv.org/abs/2601.04263)
*Nilushika Udayangani Hewa Dehigahawattage,Kishor Nandakishor,Marimuthu Palaniswami*

Main category: cs.LG

TL;DR: 本文提出了一种可解释的时间序列知识蒸馏方法Temporal Saliency Distillation，通过传递教师模型的时间显著性来改善学生模型的学习效果。


<details>
  <summary>Details</summary>
Motivation: 当前时间序列知识蒸馏方法主要基于计算机视觉任务开发的logit和特征对齐技术，这些方法存在两个关键问题：1）转移的知识机制不明确，缺乏可解释性；2）仅转移有限知识，主要复制教师预测准确性，导致学生模型预测分布与教师模型差异较大。

Method: 提出Temporal Saliency Distillation方法，扩展传统的logit传递，不仅传递正确预测，还传递教师的推理过程。具体通过从教师logits中提取时间显著性（temporal saliency）知识，该知识捕捉每个输入时间步对教师预测的重要性，从而训练学生模型基于与教师相同的输入特征进行预测。

Result: Temporal Saliency Distillation有效提高了基线方法的性能，同时实现了超出预测准确性的理想特性。该方法无需额外参数或特定架构假设。

Conclusion: 这项工作为时间序列分析中的可解释知识蒸馏建立了新范式，通过传递教师模型的时间显著性知识，使学生模型能够更好地模仿教师的推理过程。

Abstract: Knowledge distillation has proven effective for model compression by transferring knowledge from a larger network called the teacher to a smaller network called the student. Current knowledge distillation in time series is predominantly based on logit and feature aligning techniques originally developed for computer vision tasks. These methods do not explicitly account for temporal data and fall short in two key aspects. First, the mechanisms by which the transferred knowledge helps the student model learning process remain unclear due to uninterpretability of logits and features. Second, these methods transfer only limited knowledge, primarily replicating the teacher predictive accuracy. As a result, student models often produce predictive distributions that differ significantly from those of their teachers, hindering their safe substitution for teacher models. In this work, we propose transferring interpretable knowledge by extending conventional logit transfer to convey not just the right prediction but also the right reasoning of the teacher. Specifically, we induce other useful knowledge from the teacher logits termed temporal saliency which captures the importance of each input timestep to the teacher prediction. By training the student with Temporal Saliency Distillation we encourage it to make predictions based on the same input features as the teacher. Temporal Saliency Distillation requires no additional parameters or architecture specific assumptions. We demonstrate that Temporal Saliency Distillation effectively improves the performance of baseline methods while also achieving desirable properties beyond predictive accuracy. We hope our work establishes a new paradigm for interpretable knowledge distillation in time series analysis.

</details>


### [103] [MemKD: Memory-Discrepancy Knowledge Distillation for Efficient Time Series Classification](https://arxiv.org/abs/2601.04264)
*Nilushika Udayangani,Kishor Nandakishor,Marimuthu Palaniswami*

Main category: cs.LG

TL;DR: 提出了一种名为MemKD的新型知识蒸馏框架，专门针对时间序列模型设计，通过捕捉教师模型和学生模型在时间序列子序列中的记忆保留差异，显著减小模型大小和内存使用，同时保持高性能。


<details>
  <summary>Details</summary>
Motivation: 现有的知识蒸馏方法主要针对计算机视觉任务设计，忽略了时间序列模型特有的时间依赖性和记忆保留特性，难以在资源受限的环境中部署复杂的时间序列分析模型。

Method: MemKD框架使用专门设计的损失函数来量化教师模型和学生模型在时间序列子序列中的记忆保留差异，确保学生模型能有效模仿教师模型的行为。

Result: 实验表明，MemKD显著优于现有最先进的知识蒸馏方法，能将参数大小和内存使用减少约500倍，同时保持与教师模型相当的性能。

Conclusion: MemKD为资源受限环境下的实时时间序列分析提供了一种有效的解决方案，能够开发出紧凑且高性能的循环神经网络模型。

Abstract: Deep learning models, particularly recurrent neural networks and their variants, such as long short-term memory, have significantly advanced time series data analysis. These models capture complex, sequential patterns in time series, enabling real-time assessments. However, their high computational complexity and large model sizes pose challenges for deployment in resource-constrained environments, such as wearable devices and edge computing platforms. Knowledge Distillation (KD) offers a solution by transferring knowledge from a large, complex model (teacher) to a smaller, more efficient model (student), thereby retaining high performance while reducing computational demands. Current KD methods, originally designed for computer vision tasks, neglect the unique temporal dependencies and memory retention characteristics of time series models. To this end, we propose a novel KD framework termed Memory-Discrepancy Knowledge Distillation (MemKD). MemKD leverages a specialized loss function to capture memory retention discrepancies between the teacher and student models across subsequences within time series data, ensuring that the student model effectively mimics the teacher model's behaviour. This approach facilitates the development of compact, high-performing recurrent neural networks suitable for real-time, time series analysis tasks. Our extensive experiments demonstrate that MemKD significantly outperforms state-of-the-art KD methods. It reduces parameter size and memory usage by approximately 500 times while maintaining comparable performance to the teacher model.

</details>


### [104] [Making Tunable Parameters State-Dependent in Weather and Climate Models with Reinforcement Learning](https://arxiv.org/abs/2601.04268)
*Pritthijit Nath,Sebastian Schemm,Henry Moss,Peter Haynes,Emily Shuckburgh,Mark J. Webb*

Main category: cs.LG

TL;DR: 该研究提出了一个基于强化学习的框架，用于在线学习参数化方案的组件，通过在不同理想化测试平台上评估，发现TQC、DDPG和TD3算法表现最佳，能够实现地理专业化控制和物理意义明确的参数修正。


<details>
  <summary>Details</summary>
Motivation: 传统参数化方案依赖离线调谐的固定系数，约束较弱且存在持续偏差，限制了模型对底层物理的适应能力。

Method: 使用强化学习在线学习参数化方案组件，在简单气候偏差校正、辐射对流平衡和区域平均能量平衡模型等理想化测试平台上，评估了九种RL算法在单智能体和联邦多智能体设置下的性能。

Result: TQC、DDPG和TD3算法在各项配置中表现最佳且收敛最稳定。在EBM中，单智能体RL优于静态参数调谐，联邦RL在多智能体设置中实现了地理专业化控制和更快收敛。

Conclusion: 强化学习能够提供具有状态依赖性和区域感知能力的熟练参数化方案，为数值模型中的在线学习提供了可扩展的途径。

Abstract: Weather and climate models rely on parametrisations to represent unresolved sub-grid processes. Traditional schemes rely on fixed coefficients that are weakly constrained and tuned offline, contributing to persistent biases that limit their ability to adapt to the underlying physics. This study presents a framework that learns components of parametrisation schemes online as a function of the evolving model state using reinforcement learning (RL) and evaluates the resulting RL-driven parameter updates across a hierarchy of idealised testbeds spanning a simple climate bias correction (SCBC), a radiative-convective equilibrium (RCE), and a zonal mean energy balance model (EBM) with both single-agent and federated multi-agent settings. Across nine RL algorithms, Truncated Quantile Critics (TQC), Deep Deterministic Policy Gradient (DDPG), and Twin Delayed DDPG (TD3) achieved the highest skill and the most stable convergence across configurations, with performance assessed against a static baseline using area-weighted RMSE, temperature profile and pressure-level diagnostics. For the EBM, single-agent RL outperformed static parameter tuning with the strongest gains in tropical and mid-latitude bands, while federated RL on multi-agent setups enabled geographically specialised control and faster convergence, with a six-agent DDPG configuration using frequent aggregation yielding the lowest area-weighted RMSE across the tropics and mid-latitudes. The learnt corrections were also physically meaningful as agents modulated EBM radiative parameters to reduce meridional biases, adjusted RCE lapse rates to match vertical temperature errors, and stabilised SCBC heating increments to limit drift. Overall, results highlight RL to deliver skilful state-dependent, and regime-aware parametrisations, offering a scalable pathway for online learning within numerical models.

</details>


### [105] [Predictable Gradient Manifolds in Deep Learning: Temporal Path-Length and Intrinsic Rank as a Complexity Regime](https://arxiv.org/abs/2601.04270)
*Anherutowa Calvo*

Main category: cs.LG

TL;DR: 本文提出了一个可测量的可预测梯度流形框架，通过预测路径长度和可预测秩两个可计算量来量化深度学习优化中的梯度结构特性，并证明收敛性和后悔度可以基于这些实际可测量的量而非最坏情况边界来重新表述。


<details>
  <summary>Details</summary>
Motivation: 深度学习优化表现出无法被最坏情况梯度边界捕捉的结构特性，实际训练中的梯度在时间上可预测且存在于低维子空间中，需要建立可测量的框架来形式化这一观察。

Method: 引入预测路径长度和可预测秩两个可计算量，前者衡量梯度从过去信息预测的能力，后者量化梯度增量的内在时间维度。通过实验在卷积网络、视觉Transformer、语言模型等任务上验证梯度轨迹的局部可预测性和低秩结构。

Result: 发现梯度轨迹具有局部可预测性和强低秩时间结构，这些特性在不同架构和优化器上稳定存在，可通过轻量级随机投影直接从记录梯度中诊断。

Conclusion: 研究结果为理解现代深度学习优化动态提供了统一视角，将标准训练重新定义为在低复杂度时间机制中运行，为自适应优化器、秩感知跟踪和基于预测的算法设计提供了新方向。

Abstract: Deep learning optimization exhibits structure that is not captured by worst-case gradient bounds. Empirically, gradients along training trajectories are often temporally predictable and evolve within a low-dimensional subspace. In this work we formalize this observation through a measurable framework for predictable gradient manifolds.
  We introduce two computable quantities: a prediction-based path length that measures how well gradients can be forecast from past information, and a predictable rank that quantifies the intrinsic temporal dimension of gradient increments. We show how classical online and nonconvex optimization guarantees can be restated so that convergence and regret depend explicitly on these quantities, rather than on worst-case variation.
  Across convolutional networks, vision transformers, language models, and synthetic control tasks, we find that gradient trajectories are locally predictable and exhibit strong low-rank structure over time. These properties are stable across architectures and optimizers, and can be diagnosed directly from logged gradients using lightweight random projections.
  Our results provide a unifying lens for understanding optimization dynamics in modern deep learning, reframing standard training as operating in a low-complexity temporal regime. This perspective suggests new directions for adaptive optimizers, rank-aware tracking, and prediction-based algorithm design grounded in measurable properties of real training runs.

</details>


### [106] [Unlocking the Pre-Trained Model as a Dual-Alignment Calibrator for Post-Trained LLMs](https://arxiv.org/abs/2601.04277)
*Beier Luo,Cheng Wang,Hongxin Wei,Sharon Li,Xuefeng Du*

Main category: cs.LG

TL;DR: 本文提出Dual-Align框架，通过双重对齐方法解决后训练语言模型的置信度校准问题，同时修正置信度漂移和过程漂移。


<details>
  <summary>Details</summary>
Motivation: 后训练虽然提升了大语言模型的性能，但会导致系统性的过度自信问题。现有方法仅关注静态输出分布匹配，忽略了后训练引入的推理时动态变化。

Method: 提出Dual-Align框架，包含置信度对齐（修正置信度漂移）和过程对齐（定位轨迹分歧层并重新对齐后续推理稳定性），学习单一温度参数同时修正两种漂移。

Result: 实验表明该方法在减少校准误差方面优于基线方法，接近监督oracle的性能，且不牺牲后训练带来的性能提升。

Conclusion: Dual-Align通过双重对齐策略有效解决了后训练语言模型的校准问题，证明了同时处理置信度漂移和过程漂移的重要性。

Abstract: Post-training improves large language models (LLMs) but often worsens confidence calibration, leading to systematic overconfidence. Recent unsupervised post-hoc methods for post-trained LMs (PoLMs) mitigate this by aligning PoLM confidence to that of well-calibrated pre-trained counterparts. However, framing calibration as static output-distribution matching overlooks the inference-time dynamics introduced by post-training. In particular, we show that calibration errors arise from two regimes: (i) confidence drift, where final confidence inflates despite largely consistent intermediate decision processes, and (ii) process drift, where intermediate inference pathways diverge. Guided by this diagnosis, we propose Dual-Align, an unsupervised post-hoc framework for dual alignment in confidence calibration. Dual-Align performs confidence alignment to correct confidence drift via final-distribution matching, and introduces process alignment to address process drift by locating the layer where trajectories diverge and realigning the stability of subsequent inference. This dual strategy learns a single temperature parameter that corrects both drift types without sacrificing post-training performance gains. Experiments show consistent improvements over baselines, reducing calibration errors and approaching a supervised oracle.

</details>


### [107] [Generation of synthetic delay time series for air transport applications](https://arxiv.org/abs/2601.04279)
*Pau Esteve,Massimiliano Zanin*

Main category: cs.LG

TL;DR: 本文比较了三种生成机场延误时间序列的模型，其中简化遗传算法方法能够生成与真实数据几乎无法区分的高变异性时间序列，并验证了其在延误传播检测中的应用。


<details>
  <summary>Details</summary>
Motivation: 解决数据稀缺和隐私问题，为航空运输领域提供合成数据生成方法，特别关注机场延误时间序列的生成。

Method: 比较了三种模型：两种基于最先进深度学习算法，一种简化遗传算法方法。使用欧洲和美国的大规模运营数据作为基础。

Result: 简化遗传算法方法生成的延误时间序列与真实数据几乎无法区分，同时保持高变异性。在延误传播检测问题中验证了有效性。

Conclusion: 简化遗传算法在生成真实机场延误时间序列方面表现优异，相关合成数据已向科学界开放。

Abstract: The generation of synthetic data is receiving increasing attention from the scientific community, thanks to its ability to solve problems like data scarcity and privacy, and is starting to find applications in air transport. We here tackle the problem of generating synthetic, yet realistic, time series of delays at airports, starting from large collections of operations in Europe and the US. We specifically compare three models, two of them based on state of the art Deep Learning algorithms, and one simplified Genetic Algorithm approach. We show how the latter can generate time series that are almost indistinguishable from real ones, while maintaining a high variability. We further validate the resulting time series in a problem of detecting delay propagations between airports. We finally make the synthetic data available to the scientific community.

</details>


### [108] [LEGATO: Good Identity Unlearning Is Continuous](https://arxiv.org/abs/2601.04282)
*Qiang Chen,Chun-Wun Cheng,Xiu Su,Hongyan Xu,Xi Lin,Shan You,Angelica I. Aviles-Rivero,Yi Chen*

Main category: cs.LG

TL;DR: LEGATO提出了一种基于神经ODE的连续轨迹方法，用于生成模型的身份遗忘，解决了现有遗忘方法效率低、可控性差和灾难性崩溃的问题。


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘方法面临三个主要挑战：效率低下（需要微调所有参数）、可控性有限（无法控制遗忘强度且缺乏可解释性）、灾难性崩溃（遗忘过程中模型保留能力急剧下降）。

Method: LEGATO通过神经ODE适配器将身份遗忘建模为连续轨迹，在保持预训练模型权重冻结的同时，使用可微调的轻量级适配器实现平滑可控的遗忘，并通过轨迹一致性约束防止灾难性崩溃。

Result: 在领域内和领域外身份遗忘基准测试中，LEGATO实现了最先进的遗忘性能，避免了灾难性崩溃，并显著减少了需要微调的参数量。

Conclusion: 将身份遗忘建模为连续轨迹的方法比传统的离散更新方法更有效，LEGATO框架在保持模型性能的同时实现了高效、可控和稳定的遗忘。

Abstract: Machine unlearning has become a crucial role in enabling generative models trained on large datasets to remove sensitive, private, or copyright-protected data. However, existing machine unlearning methods face three challenges in learning to forget identity of generative models: 1) inefficient, where identity erasure requires fine-tuning all the model's parameters; 2) limited controllability, where forgetting intensity cannot be controlled and explainability is lacking; 3) catastrophic collapse, where the model's retention capability undergoes drastic degradation as forgetting progresses. Forgetting has typically been handled through discrete and unstable updates, often requiring full-model fine-tuning and leading to catastrophic collapse. In this work, we argue that identity forgetting should be modeled as a continuous trajectory, and introduce LEGATO - Learn to ForgEt Identity in GenerAtive Models via Trajectory-consistent Neural Ordinary Differential Equations. LEGATO augments pre-trained generators with fine-tunable lightweight Neural ODE adapters, enabling smooth, controllable forgetting while keeping the original model weights frozen. This formulation allows forgetting intensity to be precisely modulated via ODE step size, offering interpretability and robustness. To further ensure stability, we introduce trajectory consistency constraints that explicitly prevent catastrophic collapse during unlearning. Extensive experiments across in-domain and out-of-domain identity unlearning benchmarks show that LEGATO achieves state-of-the-art forgetting performance, avoids catastrophic collapse and reduces fine-tuned parameters.

</details>


### [109] [Mitigating Position-Shift Failures in Text-Based Modular Arithmetic via Position Curriculum and Template Diversity](https://arxiv.org/abs/2601.04283)
*Nikolay Yudin*

Main category: cs.LG

TL;DR: 该论文研究了字符级Transformer在模加法任务中的鲁棒性问题，发现模型在高分布内准确率下对输入格式变化（如位置偏移和模板变化）表现脆弱，并提出了一种结合边界标记、位置课程、多样化模板和一致性训练的训练方法，显著提升了鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 基于grokking文献的见解，研究模型在输入格式变化下的鲁棒性，而不仅仅是分布内准确率，强调了一个被忽视的失败模式：模型在相同表达式被移动到不同字符位置或使用分布外自然语言模板时可能完全失败。

Method: 引入简单的训练配方，包括：(i) 显式表达式边界标记，(ii) 位置课程以扩大训练中看到的绝对位置范围，(iii) 多样化模板混合，(iv) 每个示例多个变体的一致性训练。

Result: 在三个随机种子下，该干预显著提高了对位置偏移和模板分布外变化的鲁棒性，同时保持了高分布内准确率，而ALiBi风格的消融实验在该设置下未能学习任务。

Conclusion: 结果表明，在噪声监督下引导程序泛化受益于显式训练数据分布中缺失的不变性，并提供了可复现的评估协议和工具。

Abstract: Building on insights from the grokking literature, we study character-level Transformers trained to compute modular addition from text, and focus on robustness under input-format variation rather than only in-distribution accuracy. We identify a previously under-emphasized failure mode: models that achieve high in-distribution accuracy can fail catastrophically when the same expression is shifted to different absolute character positions ("position shift") or presented under out-of-distribution natural-language templates. Using a disjoint-pair split over all ordered pairs for p=97, we show that a baseline model reaches strong in-distribution performance yet collapses under position shift and template OOD. We then introduce a simple training recipe that combines (i) explicit expression boundary markers, (ii) position curriculum that broadens the range of absolute positions seen during training, (iii) diverse template mixtures, and (iv) consistency training across multiple variants per example. Across three seeds, this intervention substantially improves robustness to position shift and template OOD while maintaining high in-distribution accuracy, whereas an ALiBi-style ablation fails to learn the task under our setup. Our results suggest that steering procedural generalization under noisy supervision benefits from explicitly training invariances that are otherwise absent from the data distribution, and we provide a reproducible evaluation protocol and artifacts.

</details>


### [110] [Enhancing Robustness of Asynchronous EEG-Based Movement Prediction using Classifier Ensembles](https://arxiv.org/abs/2601.04286)
*Niklas Kueper,Kartik Chari,Elsa Andrea Kirchner*

Main category: cs.LG

TL;DR: 本研究探讨了分类器集成和滑动窗口后处理技术在增强基于EEG信号的异步运动意图检测中的有效性，发现在在线分类中集成方法显著优于单模型。


<details>
  <summary>Details</summary>
Motivation: 脑卒中患者康复需要检测运动意图来触发机器人辅助治疗，但基于EEG信号的异步运动意图检测在在线分类时面临挑战，需要提高分类的鲁棒性。

Method: 使用14名健康受试者的EEG数据集，比较了SVM、MLP和EEGNet分类模型的集成组合，通过离线和伪在线评估分析分类器集成和滑动窗口后处理技术的效果。

Result: 伪在线评估显示，在最优后处理窗口数下，两种模型集成显著优于最佳单模型。滑动窗口后处理显著提高了单模型的分类性能，但在离线评估中集成方法与最佳单模型无显著差异。

Conclusion: 分类器集成和适当的后处理方法能有效增强EEG信号中运动意图的异步检测，特别是在在线分类中效果更明显，能减少误检和早期假阳性。

Abstract: Objective: Stroke is one of the leading causes of disabilities. One promising approach is to extend the rehabilitation with self-initiated robot-assisted movement therapy. To enable this, it is required to detect the patient's intention to move to trigger the assistance of a robotic device. This intention to move can be detected from human surface electroencephalography (EEG) signals; however, it is particularly challenging to decode when classifications are performed online and asynchronously. In this work, the effectiveness of classifier ensembles and a sliding-window postprocessing technique was investigated to enhance the robustness of such asynchronous classification. Approach: To investigate the effectiveness of classifier ensembles and a sliding-window postprocessing, two EEG datasets with 14 healthy subjects who performed self-initiated arm movements were analyzed. Offline and pseudo-online evaluations were conducted to compare ensemble combinations of the support vector machine (SVM), multilayer perceptron (MLP), and EEGNet classification models. Results: The results of the pseudo-online evaluation show that the two model ensembles significantly outperformed the best single model for the optimal number of postprocessing windows. In particular, for single models, an increased number of postprocessing windows significantly improved classification performances. Interestingly, we found no significant improvements between performances of the best single model and classifier ensembles in the offline evaluation. Significance: We demonstrated that classifier ensembles and appropriate postprocessing methods effectively enhance the asynchronous detection of movement intentions from EEG signals. In particular, the classifier ensemble approach yields greater improvements in online classification than in offline classification, and reduces false detections, i.e., early false positives.

</details>


### [111] [Online Action-Stacking Improves Reinforcement Learning Performance for Air Traffic Control](https://arxiv.org/abs/2601.04287)
*Ben Carvell,George De Ath,Eseoghene Benjamin,Richard Everson*

Main category: cs.LG

TL;DR: 本文提出了一种推理时包装器"在线动作堆叠"，可将强化学习策略的小规模离散动作空间输出转换为符合实际空中交通管制需求的复合指令。


<details>
  <summary>Details</summary>
Motivation: 标准强化学习策略与实际的空中交通管制操作需求之间存在差距，需要一种机制将简单的增量调整动作转换为符合领域规范的复合指令。

Method: 使用近端策略优化算法在BluebirdDT数字孪生平台上训练策略，采用简单的航向或高度增量调整动作，并加入动作抑制惩罚来减少指令频率。推理时通过在线动作堆叠将原始动作序列编译成复合指令。

Result: 在横向导航实验中，动作堆叠显著减少了指令数量，仅用5个动作就达到了与37维动作空间策略相当的性能。

Conclusion: 在线动作堆叠有助于弥合标准强化学习与操作ATC要求之间的关键差距，为扩展到更复杂控制场景提供了简单机制。

Abstract: We introduce online action-stacking, an inference-time wrapper for reinforcement learning policies that produces realistic air traffic control commands while allowing training on a much smaller discrete action space. Policies are trained with simple incremental heading or level adjustments, together with an action-damping penalty that reduces instruction frequency and leads agents to issue commands in short bursts. At inference, online action-stacking compiles these bursts of primitive actions into domain-appropriate compound clearances. Using Proximal Policy Optimisation and the BluebirdDT digital twin platform, we train agents to navigate aircraft along lateral routes, manage climb and descent to target flight levels, and perform two-aircraft collision avoidance under a minimum separation constraint. In our lateral navigation experiments, action stacking greatly reduces the number of issued instructions relative to a damped baseline and achieves comparable performance to a policy trained with a 37-dimensional action space, despite operating with only five actions. These results indicate that online action-stacking helps bridge a key gap between standard reinforcement learning formulations and operational ATC requirements, and provides a simple mechanism for scaling to more complex control scenarios.

</details>


### [112] [ArtCognition: A Multimodal AI Framework for Affective State Sensing from Visual and Kinematic Drawing Cues](https://arxiv.org/abs/2601.04297)
*Behrad Binaei-Haghighi,Nafiseh Sadat Sajadi,Mehrad Liviyan,Reyhane Akhavan Kharazi,Fatemeh Amirkhani,Behnam Bahrak*

Main category: cs.LG

TL;DR: 本文提出ArtCognition框架，通过融合数字绘画的静态视觉特征和动态行为运动学线索，结合RAG架构增强可解释性，实现HTP心理测试的自动化分析。


<details>
  <summary>Details</summary>
Motivation: 人类情感和心理状态的客观评估具有挑战性，特别是通过非语言渠道。数字绘画作为一种未被充分探索的情感感知模态，具有丰富的信息价值。

Method: 提出多模态框架ArtCognition，融合计算机视觉模型提取的静态视觉特征和绘画过程中的动态行为运动学线索（如笔画速度、停顿、平滑度），采用RAG架构将低层特征与高层心理学解释相连接。

Result: 视觉和行为运动学线索的融合比单一模态提供更细致的评估，提取的多模态特征与标准化心理指标存在显著相关性，验证了框架作为临床辅助工具的可扩展潜力。

Conclusion: 这项工作为非侵入性情感状态评估提供了新方法，为技术辅助心理健康护理开辟了新途径。

Abstract: The objective assessment of human affective and psychological states presents a significant challenge, particularly through non-verbal channels. This paper introduces digital drawing as a rich and underexplored modality for affective sensing. We present a novel multimodal framework, named ArtCognition, for the automated analysis of the House-Tree-Person (HTP) test, a widely used psychological instrument. ArtCognition uniquely fuses two distinct data streams: static visual features from the final artwork, captured by computer vision models, and dynamic behavioral kinematic cues derived from the drawing process itself, such as stroke speed, pauses, and smoothness. To bridge the gap between low-level features and high-level psychological interpretation, we employ a Retrieval-Augmented Generation (RAG) architecture. This grounds the analysis in established psychological knowledge, enhancing explainability and reducing the potential for model hallucination. Our results demonstrate that the fusion of visual and behavioral kinematic cues provides a more nuanced assessment than either modality alone. We show significant correlations between the extracted multimodal features and standardized psychological metrics, validating the framework's potential as a scalable tool to support clinicians. This work contributes a new methodology for non-intrusive affective state assessment and opens new avenues for technology-assisted mental healthcare.

</details>


### [113] [Transformer-Based Multi-Modal Temporal Embeddings for Explainable Metabolic Phenotyping in Type 1 Diabetes](https://arxiv.org/abs/2601.04299)
*Pir Bakhsh Khokhar,Carmine Gravino,Fabio Palomba,Sule Yildrim Yayilgan,Sarang Shaikh*

Main category: cs.LG

TL;DR: 提出可解释深度学习框架，整合连续血糖监测和实验室数据，识别1型糖尿病患者的代谢亚型


<details>
  <summary>Details</summary>
Motivation: 1型糖尿病具有高度代谢异质性，传统生物标志物如糖化血红蛋白无法充分表征疾病特征

Method: 使用transformer编码器建模多模态时间依赖关系，通过高斯混合模型识别潜在代谢表型，利用注意力可视化和SHAP分析实现模型可解释性

Result: 在577名1型糖尿病患者中识别出5个代谢表型，从代谢稳定到心血管代谢风险升高，这些表型在血糖控制、脂质代谢、肾功能和促甲状腺激素等方面存在差异

Conclusion: 该可解释多模态时间嵌入框架揭示了1型糖尿病中生理学上一致的代谢亚群，支持超越单一生物标志物的风险分层

Abstract: Type 1 diabetes (T1D) is a highly metabolically heterogeneous disease that cannot be adequately characterized by conventional biomarkers such as glycated hemoglobin (HbA1c). This study proposes an explainable deep learning framework that integrates continuous glucose monitoring (CGM) data with laboratory profiles to learn multimodal temporal embeddings of individual metabolic status. Temporal dependencies across modalities are modeled using a transformer encoder, while latent metabolic phenotypes are identified via Gaussian mixture modeling. Model interpretability is achieved through transformer attention visualization and SHAP-based feature attribution. Five latent metabolic phenotypes, ranging from metabolic stability to elevated cardiometabolic risk, were identified among 577 individuals with T1D. These phenotypes exhibit distinct biochemical profiles, including differences in glycemic control, lipid metabolism, renal markers, and thyrotropin (TSH) levels. Attention analysis highlights glucose variability as a dominant temporal factor, while SHAP analysis identifies HbA1c, triglycerides, cholesterol, creatinine, and TSH as key contributors to phenotype differentiation. Phenotype membership shows statistically significant, albeit modest, associations with hypertension, myocardial infarction, and heart failure. Overall, this explainable multimodal temporal embedding framework reveals physiologically coherent metabolic subgroups in T1D and supports risk stratification beyond single biomarkers.

</details>


### [114] [Quantifying the Effect of Test Set Contamination on Generative Evaluations](https://arxiv.org/abs/2601.04301)
*Rylan Schaeffer,Joshua Kazdan,Baber Abbasi,Ken Ziyu Liu,Brando Miranda,Ahmed Ahmed,Abhay Puri,Niloofar Mireshghallah,Sanmi Koyejo*

Main category: cs.LG

TL;DR: 本文研究了测试集污染对生成式评估的影响，发现即使少量污染也能显著提升模型性能，并探讨了训练和推理阶段缓解污染效应的策略。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统在网页规模数据上预训练，测试集污染已成为评估模型能力的严重问题。现有研究主要关注判别式评估，而生成式评估中的污染影响研究较少。

Method: 通过在MATH基准测试数据上预训练语言模型，控制模型大小和测试集副本数量，使用缩放定律分析污染影响，并研究后续训练和推理阶段的缓解策略。

Result: 发现包含单个测试集副本就能使模型损失低于无污染训练的理论极限；过训练和温度采样可缓解污染效应，长文本比短文本更难记忆。

Conclusion: 生成与记忆的相互作用为AI系统可信评估增加了新的复杂性，需要更严谨的评估方法。

Abstract: As frontier AI systems are pretrained on web-scale data, test set contamination has become a critical concern for accurately assessing their capabilities. While research has thoroughly investigated the impact of test set contamination on discriminative evaluations like multiple-choice question-answering, comparatively little research has studied the impact of test set contamination on generative evaluations. In this work, we quantitatively assess the effect of test set contamination on generative evaluations through the language model lifecycle. We pretrain language models on mixtures of web data and the MATH benchmark, sweeping model sizes and number of test set replicas contaminating the pretraining corpus; performance improves with contamination and model size. Using scaling laws, we make a surprising discovery: including even a single test set replica enables models to achieve lower loss than the irreducible error of training on the uncontaminated corpus. We then study further training: overtraining with fresh data reduces the effects of contamination, whereas supervised finetuning on the training set can either increase or decrease performance on test data, depending on the amount of pretraining contamination. Finally, at inference, we identify factors that modulate memorization: high sampling temperatures mitigate contamination effects, and longer solutions are exponentially more difficult to memorize than shorter ones, presenting a contrast with discriminative evaluations, where solutions are only a few tokens in length. By characterizing how generation and memorization interact, we highlight a new layer of complexity for trustworthy evaluation of AI systems.

</details>


### [115] [Causally-Aware Information Bottleneck for Domain Adaptation](https://arxiv.org/abs/2601.04361)
*Mohammad Ali Javidian*

Main category: cs.LG

TL;DR: 该论文提出了一种因果领域适应方法，通过机制稳定表示学习在目标域中插补缺失的目标变量，为线性高斯和非线性/非高斯数据分别提供了闭式解和变分信息瓶颈方法。


<details>
  <summary>Details</summary>
Motivation: 解决因果系统中常见的领域适应问题，即在目标域中目标变量完全缺失的情况下，从其他观测变量中准确插补目标变量，应对各种分布偏移。

Method: 对于线性高斯因果模型，推导出闭式高斯信息瓶颈解（GIB），转化为典型相关分析（CCA）式投影；对于非线性或非高斯数据，引入变分信息瓶颈（VIB）编码器-预测器，可在源数据上训练并零样本部署到目标域。

Result: 在合成和真实数据集上的实验表明，该方法能够持续获得准确的插补结果，支持高维因果模型的实际应用。

Conclusion: 该方法为因果领域适应提供了一个统一、轻量级的工具包，能够在高维设置下实现准确的目标变量插补。

Abstract: We tackle a common domain adaptation setting in causal systems. In this setting, the target variable is observed in the source domain but is entirely missing in the target domain. We aim to impute the target variable in the target domain from the remaining observed variables under various shifts. We frame this as learning a compact, mechanism-stable representation. This representation preserves information relevant for predicting the target while discarding spurious variation. For linear Gaussian causal models, we derive a closed-form Gaussian Information Bottleneck (GIB) solution. This solution reduces to a canonical correlation analysis (CCA)-style projection and offers Directed Acyclic Graph (DAG)-aware options when desired. For nonlinear or non-Gaussian data, we introduce a Variational Information Bottleneck (VIB) encoder-predictor. This approach scales to high dimensions and can be trained on source data and deployed zero-shot to the target domain. Across synthetic and real datasets, our approach consistently attains accurate imputations, supporting practical use in high-dimensional causal models and furnishing a unified, lightweight toolkit for causal domain adaptation.

</details>


### [116] [Phasor Agents: Oscillatory Graphs with Three-Factor Plasticity and Sleep-Staged Learning](https://arxiv.org/abs/2601.04362)
*Rodja Trappe*

Main category: cs.LG

TL;DR: Phasor Agents是一种动态系统，使用耦合的Stuart-Landau振荡器作为计算单元，通过相位跟踪相对时序，振幅跟踪局部增益。系统采用三因素局部可塑性学习耦合权重，无需反向传播。通过分离清醒标记和离线巩固机制，解决了振荡底板的稳定性问题。实验验证了各机制的有效性，包括资格痕迹、压缩进度信号、相位相干检索等，并展示了在迷宫任务中的显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决振荡底板上在线权重更新可能导致网络进入不期望状态（如全局同步）的问题，保持表示多样性。受突触标记捕获和睡眠阶段动力学的启发，分离清醒标记和离线巩固机制以实现稳定学习。

Method: 使用Phasor Graph作为内部状态，由耦合的Stuart-Landau振荡器组成。每个振荡器作为抽象计算单元，相位跟踪相对时序，振幅跟踪局部增益。采用三因素局部可塑性学习耦合权重，无需反向传播。引入清醒/睡眠分离机制：深睡眠阶段的安全变更提交和REM阶段的回放扰动。

Result: 资格痕迹在延迟调制下保持信用；压缩进度信号通过时间戳混洗控制；相位相干检索在噪声下达到4倍扩散基线；清醒/睡眠分离在匹配权重范数预算下扩展稳定学习67%；REM回放提高迷宫成功率45.5个百分点；出现Tolman式潜在学习特征。

Conclusion: Phasor Agents通过振荡器网络和清醒/睡眠分离机制，实现了稳定的在线学习能力，展示了在复杂任务中的有效性能，并涌现出内部模型的特征。所有代码和工件均为开源。

Abstract: Phasor Agents are dynamical systems whose internal state is a Phasor Graph: a weighted graph of coupled Stuart-Landau oscillators. A Stuart-Landau oscillator is a minimal stable "rhythm generator" (the normal form near a Hopf bifurcation); each oscillator is treated as an abstract computational unit (inspired by, but not claiming to model, biological oscillatory populations). In this interpretation, oscillator phase tracks relative timing (coherence), while amplitude tracks local gain or activity. Relative phase structure serves as a representational medium; coupling weights are learned via three-factor local plasticity - eligibility traces gated by sparse global modulators and oscillation-timed write windows - without backpropagation.
  A central challenge in oscillatory substrates is stability: online weight updates can drive the network into unwanted regimes (e.g., global synchrony), collapsing representational diversity. We therefore separate wake tagging from offline consolidation, inspired by synaptic tagging-and-capture and sleep-stage dynamics: deep-sleep-like gated capture commits tagged changes safely, while REM-like replay reconstructs and perturbs experience for planning.
  A staged experiment suite validates each mechanism with ablations and falsifiers: eligibility traces preserve credit under delayed modulation; compression-progress signals pass timestamp-shuffle controls; phase-coherent retrieval reaches 4x diffusive baselines under noise; wake/sleep separation expands stable learning by 67 percent under matched weight-norm budgets; REM replay improves maze success rate by +45.5 percentage points; and a Tolman-style latent-learning signature - immediate competence and detour advantage after unrewarded exploration, consistent with an internal model - emerges from replay (Tolman, 1948).
  The codebase and all artifacts are open-source.

</details>


### [117] [Survival Dynamics of Neural and Programmatic Policies in Evolutionary Reinforcement Learning](https://arxiv.org/abs/2601.04365)
*Anton Roupassov-Ruiz,Yiyang Zuo*

Main category: cs.LG

TL;DR: 该论文研究了在进化强化学习任务中，程序化策略（PERL）能否匹配神经网络策略（NERL）的性能，发现PERL在生存性能上显著优于NERL。


<details>
  <summary>Details</summary>
Motivation: 传统进化强化学习中的神经网络策略缺乏显式模块化结构，限制了行为解释性。研究旨在探索程序化策略是否能在性能上媲美甚至超越神经网络策略。

Method: 使用软可微分决策列表（SDDL）实现程序化策略，并首次提供了1992年人工生命进化强化学习测试平台的完整开源重实现。通过4000次独立试验进行严格的生存分析，使用Kaplan-Meier曲线和限制平均生存时间（RMST）指标。

Result: PERL和NERL之间存在统计显著的生存概率差异。PERL智能体平均比NERL智能体多生存201.69步。仅使用学习的SDDL智能体比同时使用学习和进化的神经网络智能体平均多生存73.67步。

Conclusion: 程序化策略在人工生命环境中可以超越神经网络策略的生存表现，为可解释性AI提供了有前景的方向。

Abstract: In evolutionary reinforcement learning tasks (ERL), agent policies are often encoded as small artificial neural networks (NERL). Such representations lack explicit modular structure, limiting behavioral interpretation. We investigate whether programmatic policies (PERL), implemented as soft, differentiable decision lists (SDDL), can match the performance of NERL. To support reproducible evaluation, we provide the first fully specified and open-source reimplementation of the classic 1992 Artificial Life (ALife) ERL testbed. We conduct a rigorous survival analysis across 4000 independent trials utilizing Kaplan-Meier curves and Restricted Mean Survival Time (RMST) metrics absent in the original study. We find a statistically significant difference in survival probability between PERL and NERL. PERL agents survive on average 201.69 steps longer than NERL agents. Moreover, SDDL agents using learning alone (no evolution) survive on average 73.67 steps longer than neural agents using both learning and evaluation. These results demonstrate that programmatic policies can exceed the survival performance of neural policies in ALife.

</details>


### [118] [Machine Learning Model for Sparse PCM Completion](https://arxiv.org/abs/2601.04366)
*Selcuk Koyuncu,Ronak Nouri,Stephen Providence*

Main category: cs.LG

TL;DR: 提出了一种用于稀疏成对比较矩阵的机器学习模型，结合经典PCM方法和基于图的学习技术


<details>
  <summary>Details</summary>
Motivation: 解决稀疏成对比较矩阵的有效处理问题，将传统方法与现代机器学习技术相结合

Method: 结合经典成对比较矩阵方法和基于图的学习技术，开发机器学习模型

Result: 提供了数值结果来证明所提方法的有效性和可扩展性

Conclusion: 提出的方法在稀疏成对比较矩阵处理方面具有有效性和可扩展性

Abstract: In this paper, we propose a machine learning model for sparse pairwise comparison matrices (PCMs), combining classical PCM approaches with graph-based learning techniques. Numerical results are provided to demonstrate the effectiveness and scalability of the proposed method.

</details>


### [119] [Enhanced-FQL($λ$), an Efficient and Interpretable RL with novel Fuzzy Eligibility Traces and Segmented Experience Replay](https://arxiv.org/abs/2601.04392)
*Mohsen Jalaeian-Farimani*

Main category: cs.LG

TL;DR: 提出Enhanced-FQL(λ)模糊强化学习框架，结合模糊化资格迹和分段经验回放，用于连续控制任务，具有可解释性、高样本效率和理论收敛保证


<details>
  <summary>Details</summary>
Motivation: 解决深度强化学习在安全关键应用中缺乏透明度和计算复杂的问题，同时保持连续控制任务的竞争性能

Method: 使用可解释的模糊规则库替代复杂神经网络，结合模糊化贝尔曼方程、模糊化资格迹进行多步信用分配，以及分段经验回放机制提高样本效率

Result: 在连续控制领域评估显示，相比n步模糊TD和模糊SARSA(λ)基线，具有更优的样本效率和更低的方差，同时计算复杂度显著低于DDPG等深度强化学习方法

Conclusion: 该框架的可解释性、计算效率和理论收敛保证使其特别适合对透明度和资源约束有严格要求的安全关键应用

Abstract: This paper introduces a fuzzy reinforcement learning framework, Enhanced-FQL($λ$), that integrates novel Fuzzified Eligibility Traces (FET) and Segmented Experience Replay (SER) into fuzzy Q-learning with Fuzzified Bellman Equation (FBE) for continuous control tasks. The proposed approach employs an interpretable fuzzy rule base instead of complex neural architectures, while maintaining competitive performance through two key innovations: a fuzzified Bellman equation with eligibility traces for stable multi-step credit assignment, and a memory-efficient segment-based experience replay mechanism for enhanced sample efficiency. Theoretical analysis proves the proposed method convergence under standard assumptions. Extensive evaluations in continuous control domains demonstrate that Enhanced-FQL($λ$) achieves superior sample efficiency and reduced variance compared to n-step fuzzy TD and fuzzy SARSA($λ$) baselines, while maintaining substantially lower computational complexity than deep RL alternatives such as DDPG. The framework's inherent interpretability, combined with its computational efficiency and theoretical convergence guarantees, makes it particularly suitable for safety-critical applications where transparency and resource constraints are essential.

</details>


### [120] [Aligned explanations in neural networks](https://arxiv.org/abs/2601.04378)
*Corentin Lobet,Francesca Chiaromonte*

Main category: cs.LG

TL;DR: 该论文提出模型可读性作为实现解释对齐的设计原则，并介绍了PiNets框架来生成与预测直接相关的忠实解释。


<details>
  <summary>Details</summary>
Motivation: 现有特征归因方法仅松散反映模型的预测过程，无法实现解释与预测的真正对齐，这影响了模型的可信度。

Method: 提出PiNets（伪线性网络）框架，通过生成实例级线性预测来实现线性可读性，确保解释与预测直接关联。

Result: 在图像分类和分割任务上的实验表明，PiNets能够产生符合多个忠实性标准的解释，实现了真正的解释对齐。

Conclusion: PiNets通过模型可读性设计原则，成功解决了深度学习中解释与预测的对齐问题，提升了模型的可信度。

Abstract: Feature attribution is the dominant paradigm for explaining deep neural networks. However, most existing methods only loosely reflect the model's prediction-making process, thereby merely white-painting the black box. We argue that explanatory alignment is a key aspect of trustworthiness in prediction tasks: explanations must be directly linked to predictions, rather than serving as post-hoc rationalizations. We present model readability as a design principle enabling alignment, and PiNets as a modeling framework to pursue it in a deep learning context. PiNets are pseudo-linear networks that produce instance-wise linear predictions in an arbitrary feature space, making them linearly readable. We illustrate their use on image classification and segmentation tasks, demonstrating how PiNets produce explanations that are faithful across multiple criteria in addition to alignment.

</details>


### [121] [Nightmare Dreamer: Dreaming About Unsafe States And Planning Ahead](https://arxiv.org/abs/2601.04686)
*Oluwatosin Oseni,Shengjie Wang,Jun Zhu,Micah Corah*

Main category: cs.LG

TL;DR: Nightmare Dreamer是一种基于模型的安全强化学习算法，通过使用学习的世界模型预测潜在安全违规并规划行动，在保证安全的同时最大化奖励。


<details>
  <summary>Details</summary>
Motivation: 强化学习在现实应用中安全性保证不足，限制了其采用。需要开发能够提供安全保证的强化学习算法。

Method: 使用基于模型的方法，通过学习的世界模型预测潜在安全违规，并据此规划行动。算法仅使用图像观测，在Safety Gymnasium任务上进行测试。

Result: Nightmare Dreamer在Safety Gymnasium任务上实现了近乎零的安全违规，同时最大化奖励。相比无模型基线方法，效率提高了近20倍。

Conclusion: Nightmare Dreamer证明了基于模型的安全强化学习方法的有效性，能够在不牺牲性能的情况下提供强大的安全保证。

Abstract: Reinforcement Learning (RL) has shown remarkable success in real-world applications, particularly in robotics control. However, RL adoption remains limited due to insufficient safety guarantees. We introduce Nightmare Dreamer, a model-based Safe RL algorithm that addresses safety concerns by leveraging a learned world model to predict potential safety violations and plan actions accordingly. Nightmare Dreamer achieves nearly zero safety violations while maximizing rewards. Nightmare Dreamer outperforms model-free baselines on Safety Gymnasium tasks using only image observations, achieving nearly a 20x improvement in efficiency.

</details>


### [122] [Rate or Fate? RLV$^\varepsilon$R: Reinforcement Learning with Verifiable Noisy Rewards](https://arxiv.org/abs/2601.04411)
*Ali Rad,Khashayar Filom,Darioush Keivan,Peyman Mohajerin Esfahani,Ehsan Kamalinejad*

Main category: cs.LG

TL;DR: 本文提出了一种可验证奖励强化学习（RLVR）的分析框架，通过多臂老虎机模型研究验证噪声对学习过程的影响，发现存在基于尤登指数J=TPR-FPR的相变现象。


<details>
  <summary>Details</summary>
Motivation: 现实中验证器往往不完美（测试用例有限、人工标注错误、LLM判断噪声等），特别是在编程等复杂领域。本文旨在探究验证噪声对学习结果的影响是仅减缓学习速度还是会导致学习失败。

Method: 建立可分析处理的多臂老虎机模型来模拟RLVR动态，使用GRPO方法进行实例化，并通过控制实验验证。模型考虑了假阳性和假阴性错误，将完成结果分组为重复推理模式。

Result: 发现存在基于尤登指数J的相变：当J>0时错误模式会被消除（学习成功）；J=0时过程保持中性；J<0时错误模式会放大直至主导（反学习和崩溃）。在J>0的学习状态下，噪声主要影响收敛时间而非最终结果。

Conclusion: 该框架为分析RLVR的稳定性、收敛性和算法干预提供了通用视角，验证噪声在J>0时主要影响学习速率而非命运，但在J≤0时会导致学习失败。

Abstract: Reinforcement learning with verifiable rewards (RLVR) is a simple but powerful paradigm for training LLMs: sample a completion, verify it, and update. In practice, however, the verifier is almost never clean--unit tests probe only limited corner cases; human and synthetic labels are imperfect; and LLM judges (e.g., RLAIF) are noisy and can be exploited--and this problem worsens on harder domains (especially coding) where tests are sparse and increasingly model-generated. We ask a pragmatic question: does the verification noise merely slow down the learning (rate), or can it flip the outcome (fate)?
  To address this, we develop an analytically tractable multi-armed bandit view of RLVR dynamics, instantiated with GRPO and validated in controlled experiments. Modeling false positives and false negatives and grouping completions into recurring reasoning modes yields a replicator-style (natural-selection) flow on the probability simplex. The dynamics decouples into within-correct-mode competition and a one-dimensional evolution for the mass on incorrect modes, whose drift is determined solely by Youden's index J=TPR-FPR. This yields a sharp phase transition: when J>0, the incorrect mass is driven toward extinction (learning); when J=0, the process is neutral; and when J<0, incorrect modes amplify until they dominate (anti-learning and collapse). In the learning regime J>0, noise primarily rescales convergence time ("rate, not fate"). Experiments on verifiable programming tasks under synthetic noise reproduce the predicted J=0 boundary. Beyond noise, the framework offers a general lens for analyzing RLVR stability, convergence, and algorithmic interventions.

</details>


### [123] [Distribution-Guided and Constrained Quantum Machine Unlearning](https://arxiv.org/abs/2601.04413)
*Nausherwan Malik,Zubair Khalid,Muhammad Faryad*

Main category: cs.LG

TL;DR: 提出了一种基于分布引导的量子机器学习遗忘框架，通过可调目标分布和锚点约束实现可控的类别级遗忘，在量子变分分类器上验证了优于传统均匀目标遗忘方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有量子机器学习遗忘方法主要依赖固定的均匀目标分布，无法明确控制遗忘与保留模型行为之间的权衡，需要更精细的遗忘控制机制。

Method: 将遗忘建模为约束优化问题，引入基于模型相似性统计的可调目标分布，并加入锚点保留约束来维持选定保留数据的预测行为，实现可控的优化轨迹。

Result: 在Iris和Covertype数据集上的实验显示，该方法能显著抑制遗忘类别的置信度，最小化保留类别性能下降，与完全重训练基线更接近。

Conclusion: 目标分布设计和约束优化公式对于实现可靠且可解释的量子机器学习遗忘至关重要，该方法为量子模型提供了更精细的遗忘控制能力。

Abstract: Machine unlearning aims to remove the influence of specific training data from a learned model without full retraining. While recent work has begun to explore unlearning in quantum machine learning, existing approaches largely rely on fixed, uniform target distributions and do not explicitly control the trade-off between forgetting and retained model behaviour. In this work, we propose a distribution-guided framework for class-level quantum machine unlearning that treats unlearning as a constrained optimization problem. Our method introduces a tunable target distribution derived from model similarity statistics, decoupling the suppression of forgotten-class confidence from assumptions about redistribution among retained classes. We further incorporate an anchor-based preservation constraint that explicitly maintains predictive behaviour on selected retained data, yielding a controlled optimization trajectory that limits deviation from the original model. We evaluate the approach on variational quantum classifiers trained on the Iris and Covertype datasets. Results demonstrate sharp suppression of forgotten-class confidence, minimal degradation of retained-class performance, and closer alignment with the gold retrained model baselines compared to uniform-target unlearning. These findings highlight the importance of target design and constraint-based formulations for reliable and interpretable quantum machine unlearning.

</details>


### [124] [Improving and Accelerating Offline RL in Large Discrete Action Spaces with Structured Policy Initialization](https://arxiv.org/abs/2601.04441)
*Matthew Landers,Taylor W. Killian,Thomas Hartvigsen,Afsaneh Doryab*

Main category: cs.LG

TL;DR: SPIN是一种两阶段强化学习框架，通过预训练动作结构模型捕捉有效动作流形，然后训练轻量级策略头进行控制，在离散组合动作空间中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决离散组合动作空间中现有方法的问题：要么假设子动作独立导致动作不连贯/无效，要么联合学习动作结构和控制导致训练缓慢不稳定。

Method: 两阶段框架：1）预训练动作结构模型（ASM）捕捉有效动作流形；2）冻结ASM表示，训练轻量级策略头进行控制。

Result: 在离散DM Control基准测试中，平均回报比现有最优方法提升高达39%，收敛时间减少高达12.8倍。

Conclusion: SPIN框架通过分离动作结构学习和控制学习，有效解决了离散组合动作空间中的策略学习问题，实现了更好的性能和更快的收敛。

Abstract: Reinforcement learning in discrete combinatorial action spaces requires searching over exponentially many joint actions to simultaneously select multiple sub-actions that form coherent combinations. Existing approaches either simplify policy learning by assuming independence across sub-actions, which often yields incoherent or invalid actions, or attempt to learn action structure and control jointly, which is slow and unstable. We introduce Structured Policy Initialization (SPIN), a two-stage framework that first pre-trains an Action Structure Model (ASM) to capture the manifold of valid actions, then freezes this representation and trains lightweight policy heads for control. On challenging discrete DM Control benchmarks, SPIN improves average return by up to 39% over the state of the art while reducing time to convergence by up to 12.8$\times$.

</details>


### [125] [When Predictions Shape Reality: A Socio-Technical Synthesis of Performative Predictions in Machine Learning](https://arxiv.org/abs/2601.04447)
*Gal Fybish,Teo Susnjak*

Main category: cs.LG

TL;DR: 本文对机器学习中的执行预测现象进行了系统化知识综述，提出了一个评估框架来帮助从业者评估预测模型在执行性影响下的潜在风险并选择适当的干预措施。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在高风险领域部署时会产生执行预测现象，即模型的预测会反过来影响其预测的环境，导致反馈循环、性能问题和社会风险。现有文献缺乏对这一现象的系统化整理和实用指导。

Method: 通过全面回顾执行预测相关文献，分析执行性表现的主要机制，建立风险分类体系，并总结文献中提出的解决方案。

Result: 开发了"执行强度vs影响矩阵"评估框架，这是一个实用工具，用于评估执行性对部署预测模型的潜在影响和严重程度。

Conclusion: 该SoK填补了执行预测领域系统性知识整理的空白，为从业者提供了实用的评估和干预选择工具，有助于更好地管理执行性带来的风险。

Abstract: Machine learning models are increasingly used in high-stakes domains where their predictions can actively shape the environments in which they operate, a phenomenon known as performative prediction. This dynamic, in which the deployment of the model influences the very outcome it seeks to predict, can lead to unintended consequences, including feedback loops, performance issues, and significant societal risks. While the literature in the field has grown rapidly in recent years, a socio-technical synthesis that systemises the phenomenon concepts and provides practical guidance has been lacking. This Systematisation of Knowledge (SoK) addresses this gap by providing a comprehensive review of the literature on performative predictions. We provide an overview of the primary mechanisms through which performativity manifests, present a typology of associated risks, and survey the proposed solutions offered in the literature. Our primary contribution is the ``Performative Strength vs. Impact Matrix" assessment framework. This practical tool is designed to help practitioners assess the potential influence and severity of performativity on their deployed predictive models and select the appropriate level of algorithmic or human intervention.

</details>


### [126] [Explainable Admission-Level Predictive Modeling for Prolonged Hospital Stay in Elderly Populations: Challenges in Low- and Middle-Income Countries](https://arxiv.org/abs/2601.04449)
*Daniel Sierra-Botero,Ana Molina-Taborda,Leonardo Espinosa-Leal,Alexander Karpenko,Alejandro Hernandez,Olga Lopez-Acevedo*

Main category: cs.LG

TL;DR: 该研究开发了一个预测医院住院时间延长的模型，使用图论特征选择方法和逻辑回归，在验证集上AUC-ROC达到0.82，具有较好的预测性能。


<details>
  <summary>Details</summary>
Motivation: 住院时间延长是医院不良事件的重要风险因素，需要开发可解释的预测模型来帮助医院管理和干预研究。

Method: 使用120,354条住院记录，采用图论特征选择方法筛选9个非相关特征，训练逻辑回归模型预测住院时间是否超过7天。

Result: 模型在验证集上特异性0.83，敏感性0.64，准确率0.76，精确率0.67，AUC-ROC为0.82，表现出较强的预测能力。

Conclusion: 该模型具有良好的预测性能，可为医院管理提供有价值工具，并为未来减少住院时间延长的干预研究提供基础。

Abstract: Prolonged length of stay (pLoS) is a significant factor associated with the risk of adverse in-hospital events. We develop and explain a predictive model for pLos using admission-level patient and hospital administrative data. The approach includes a feature selection method by selecting non-correlated features with the highest information value. The method uses features weights of evidence to select a representative within cliques from graph theory. The prognosis study analyzed the records from 120,354 hospital admissions at the Hospital Alma Mater de Antioquia between January 2017 and March 2022. After a cleaning process the dataset was split into training (67%), test (22%), and validation (11%) cohorts. A logistic regression model was trained to predict the pLoS in two classes: less than or greater than 7 days. The performance of the model was evaluated using accuracy, precision, sensitivity, specificity, and AUC-ROC metrics. The feature selection method returns nine interpretable variables, enhancing the models' transparency. In the validation cohort, the pLoS model achieved a specificity of 0.83 (95% CI, 0.82-0.84), sensitivity of 0.64 (95% CI, 0.62-0.65), accuracy of 0.76 (95% CI, 0.76-0.77), precision of 0.67 (95% CI, 0.66-0.69), and AUC-ROC of 0.82 (95% CI, 0.81-0.83). The model exhibits strong predictive performance and offers insights into the factors that influence prolonged hospital stays. This makes it a valuable tool for hospital management and for developing future intervention studies aimed at reducing pLoS.

</details>


### [127] [Using Large Language Models to Detect Socially Shared Regulation of Collaborative Learning](https://arxiv.org/abs/2601.04458)
*Jiayi Zhang,Conrad Borchers,Clayton Cohn,Namrata Srivastava,Caitlin Snyder,Siyuan Guo,Ashwin T S,Naveeduddin Mohammed,Haley Noh,Gautam Biswas*

Main category: cs.LG

TL;DR: 该研究扩展了预测模型，使用基于嵌入的方法自动检测协作计算建模环境中的社会共享学习调节（SSRL）行为，结合文本嵌入、上下文增强嵌入和日志特征训练模型。


<details>
  <summary>Details</summary>
Motivation: 当前学习分析领域主要关注个体化问题解决，而协作开放式问题解决虽然能提供更丰富数据，但也面临低内聚性等挑战，需要开发相应的行为预测方法。

Method: 利用大型语言模型作为总结工具生成任务感知的学生对话表示，结合文本嵌入、上下文增强嵌入和日志衍生特征训练预测模型。

Result: 文本嵌入在检测与执行或群体动态相关的SSRL行为（如偏离任务或请求帮助）时表现更好，而上下文和多模态特征对规划和反思等结构提供互补优势。

Conclusion: 基于嵌入的模型有望通过实现SSRL行为的可扩展检测来扩展学习分析，最终支持教师重视的协作学习环境中的实时反馈和自适应支架。

Abstract: The field of learning analytics has made notable strides in automating the detection of complex learning processes in multimodal data. However, most advancements have focused on individualized problem-solving instead of collaborative, open-ended problem-solving, which may offer both affordances (richer data) and challenges (low cohesion) to behavioral prediction. Here, we extend predictive models to automatically detect socially shared regulation of learning (SSRL) behaviors in collaborative computational modeling environments using embedding-based approaches. We leverage large language models (LLMs) as summarization tools to generate task-aware representations of student dialogue aligned with system logs. These summaries, combined with text-only embeddings, context-enriched embeddings, and log-derived features, were used to train predictive models. Results show that text-only embeddings often achieve stronger performance in detecting SSRL behaviors related to enactment or group dynamics (e.g., off-task behavior or requesting assistance). In contrast, contextual and multimodal features provide complementary benefits for constructs such as planning and reflection. Overall, our findings highlight the promise of embedding-based models for extending learning analytics by enabling scalable detection of SSRL behaviors, ultimately supporting real-time feedback and adaptive scaffolding in collaborative learning environments that teachers value.

</details>


### [128] [Meta-probabilistic Modeling](https://arxiv.org/abs/2601.04462)
*Kevin Zhang,Yixin Wang*

Main category: cs.LG

TL;DR: 本文提出元概率建模（MPM），一种元学习算法，直接从多个相关数据集中学习生成模型结构，解决传统概率图模型依赖模型规范选择的问题。


<details>
  <summary>Details</summary>
Motivation: 概率图模型的有效性依赖于选择规范良好的模型，但在实践中识别这类模型具有挑战性，通常需要反复试验和修正。

Method: MPM采用分层架构，全局模型规范在数据集间共享，局部参数保持数据集特定。通过双级优化进行学习和推理：局部变量通过坐标上升分析更新，全局参数使用基于梯度的方法训练。

Result: 在面向对象的图像建模和序列文本建模任务上评估MPM，证明其能够使生成模型适应数据并恢复有意义的潜在表示。

Conclusion: MPM提供了一种有效的方法来自动学习生成模型结构，避免了传统方法中手动模型选择的需要。

Abstract: While probabilistic graphical models can discover latent structure in data, their effectiveness hinges on choosing well-specified models. Identifying such models is challenging in practice, often requiring iterative checking and revision through trial and error. To this end, we propose meta-probabilistic modeling (MPM), a meta-learning algorithm that learns generative model structure directly from multiple related datasets. MPM uses a hierarchical architecture where global model specifications are shared across datasets while local parameters remain dataset-specific. For learning and inference, we propose a tractable VAE-inspired surrogate objective, and optimize it through bi-level optimization: local variables are updated analytically via coordinate ascent, while global parameters are trained with gradient-based methods. We evaluate MPM on object-centric image modeling and sequential text modeling, demonstrating that it adapts generative models to data while recovering meaningful latent representations.

</details>


### [129] [When Models Manipulate Manifolds: The Geometry of a Counting Task](https://arxiv.org/abs/2601.04480)
*Wes Gurnee,Emmanuel Ameisen,Isaac Kauvar,Julius Tarng,Adam Pearce,Chris Olah,Joshua Batson*

Main category: cs.LG

TL;DR: 论文研究Claude 3.5 Haiku如何通过仅接收token序列来感知文本的视觉属性，特别是固定宽度文本中的换行机制。研究发现字符计数在低维弯曲流形上表示，通过几何变换实现准确预测，并验证了视觉错觉现象。


<details>
  <summary>Details</summary>
Motivation: 探索语言模型仅通过token序列如何感知文本视觉属性，特别是换行机制的内在工作原理，以理解早期层的丰富感官处理和注意力算法的复杂性。

Method: 通过机械性研究分析Claude 3.5 Haiku的换行任务，包括字符计数在低维弯曲流形上的表示、注意力头对流形的几何变换，以及因果干预验证。

Result: 发现字符计数通过稀疏特征族在低维弯曲流形上离散化表示，准确的换行预测来自几何变换序列，并验证了可以劫持计数机制的视觉错觉序列。

Conclusion: 研究展示了早期层的丰富感官处理、注意力算法的精细性，以及结合基于特征和几何视角的可解释性方法的重要性。

Abstract: Language models can perceive visual properties of text despite receiving only sequences of tokens-we mechanistically investigate how Claude 3.5 Haiku accomplishes one such task: linebreaking in fixed-width text. We find that character counts are represented on low-dimensional curved manifolds discretized by sparse feature families, analogous to biological place cells. Accurate predictions emerge from a sequence of geometric transformations: token lengths are accumulated into character count manifolds, attention heads twist these manifolds to estimate distance to the line boundary, and the decision to break the line is enabled by arranging estimates orthogonally to create a linear decision boundary. We validate our findings through causal interventions and discover visual illusions--character sequences that hijack the counting mechanism. Our work demonstrates the rich sensory processing of early layers, the intricacy of attention algorithms, and the importance of combining feature-based and geometric views of interpretability.

</details>


### [130] [Hybrid Federated Learning for Noise-Robust Training](https://arxiv.org/abs/2601.04483)
*Yongjun Kim,Hyeongjun Park,Hwanjin Kim,Junil Choi*

Main category: cs.LG

TL;DR: 本文提出了一种混合联邦学习（HFL）框架，结合了联邦学习（FL）和联邦蒸馏（FD）的优势，通过自适应用户设备聚类和权重选择来提升低信噪比下的性能。


<details>
  <summary>Details</summary>
Motivation: 联邦学习和联邦蒸馏在噪声鲁棒性和学习速度方面各有优劣，为了克服各自的弱点，需要一种能够结合两者优势的混合方法。

Method: 提出HFL框架，用户设备传输梯度或logits，基站选择每轮FL和FD更新的权重；采用Jenks优化进行自适应用户设备聚类，以及阻尼牛顿法进行自适应权重选择。

Result: 数值结果显示，当同时利用两个自由度时，HFL在低信噪比下实现了更优的测试精度。

Conclusion: HFL框架通过结合FL和FD的优势，在低信噪比环境下表现出更好的性能，证明了混合方法的有效性。

Abstract: Federated learning (FL) and federated distillation (FD) are distributed learning paradigms that train UE models with enhanced privacy, each offering different trade-offs between noise robustness and learning speed. To mitigate their respective weaknesses, we propose a hybrid federated learning (HFL) framework in which each user equipment (UE) transmits either gradients or logits, and the base station (BS) selects the per-round weights of FL and FD updates. We derive convergence of HFL framework and introduce two methods to exploit degrees of freedom (DoF) in HFL, which are (i) adaptive UE clustering via Jenks optimization and (ii) adaptive weight selection via a damped Newton method. Numerical results show that HFL achieves superior test accuracy at low SNR when both DoF are exploited.

</details>


### [131] [IGenBench: Benchmarking the Reliability of Text-to-Infographic Generation](https://arxiv.org/abs/2601.04498)
*Yinghao Tang,Xueding Liu,Boyuan Zhang,Tingfeng Lan,Yupeng Xie,Jiale Lao,Yiyao Wang,Haoxuan Li,Tingting Gao,Bo Pan,Luoxuan Weng,Xiuqi Huang,Minfeng Zhu,Yingchaojie Feng,Yuyu Luo,Wei Chen*

Main category: cs.LG

TL;DR: IGENBENCH是首个评估文本到信息图生成可靠性的基准测试，包含600个测试案例，覆盖30种信息图类型，通过自动化评估框架揭示当前模型在数据准确性方面的关键瓶颈。


<details>
  <summary>Details</summary>
Motivation: 虽然当前文本到图像模型能生成美观的图像，但它们在生成信息图时的可靠性尚不明确，生成的信息图可能表面正确但包含数据编码扭曲或文本内容错误等容易被忽视的问题。

Method: 设计自动化评估框架，将可靠性验证分解为基于10种问题类型的原子是/否问题，使用多模态大语言模型验证每个问题，计算问题级准确率(Q-ACC)和信息图级准确率(I-ACC)。

Result: 评估10个最先进的T2I模型发现：存在三层性能层次，顶级模型Q-ACC达到0.90但I-ACC仅为0.49；数据相关维度成为普遍瓶颈（如数据完整性：0.21）；所有模型都难以实现端到端正确性。

Conclusion: IGENBENCH基准测试揭示了当前文本到信息图生成模型在数据准确性方面的显著挑战，为未来模型开发提供了关键见解，并公开了基准测试平台。

Abstract: Infographics are composite visual artifacts that combine data visualizations with textual and illustrative elements to communicate information. While recent text-to-image (T2I) models can generate aesthetically appealing images, their reliability in generating infographics remains unclear. Generated infographics may appear correct at first glance but contain easily overlooked issues, such as distorted data encoding or incorrect textual content. We present IGENBENCH, the first benchmark for evaluating the reliability of text-to-infographic generation, comprising 600 curated test cases spanning 30 infographic types. We design an automated evaluation framework that decomposes reliability verification into atomic yes/no questions based on a taxonomy of 10 question types. We employ multimodal large language models (MLLMs) to verify each question, yielding question-level accuracy (Q-ACC) and infographic-level accuracy (I-ACC). We comprehensively evaluate 10 state-of-the-art T2I models on IGENBENCH. Our systematic analysis reveals key insights for future model development: (i) a three-tier performance hierarchy with the top model achieving Q-ACC of 0.90 but I-ACC of only 0.49; (ii) data-related dimensions emerging as universal bottlenecks (e.g., Data Completeness: 0.21); and (iii) the challenge of achieving end-to-end correctness across all models. We release IGENBENCH at https://igen-bench.vercel.app/.

</details>


### [132] [Surface-based Molecular Design with Multi-modal Flow Matching](https://arxiv.org/abs/2601.04506)
*Fang Wu,Zhengyuan Zhou,Shuting Jin,Xiangxiang Zeng,Jure Leskovec,Jinbo Xu*

Main category: cs.LG

TL;DR: SurfFlow是一种基于表面的肽生成算法，通过多模态条件流匹配架构，实现了肽序列、结构和表面的全面协同设计，显著提升了肽结合准确性。


<details>
  <summary>Details</summary>
Motivation: 分子表面在蛋白质-蛋白质相互作用中起关键作用，但现有深度生成模型对此关注不足，需要开发能够全面考虑表面几何和生化特性的肽设计方法。

Method: 提出SurfFlow算法，采用多模态条件流匹配(CFM)架构，学习表面几何和生化特性的分布，实现肽序列、结构和表面的协同设计。

Result: 在PepMerge基准测试中，SurfFlow在所有指标上均优于全原子基线方法，证明了考虑分子表面的优势。

Conclusion: 分子表面考虑在从头肽发现中具有重要价值，整合多种蛋白质模态有助于更有效的治疗性肽发现。

Abstract: Therapeutic peptides show promise in targeting previously undruggable binding sites, with recent advancements in deep generative models enabling full-atom peptide co-design for specific protein receptors. However, the critical role of molecular surfaces in protein-protein interactions (PPIs) has been underexplored. To bridge this gap, we propose an omni-design peptides generation paradigm, called SurfFlow, a novel surface-based generative algorithm that enables comprehensive co-design of sequence, structure, and surface for peptides. SurfFlow employs a multi-modality conditional flow matching (CFM) architecture to learn distributions of surface geometries and biochemical properties, enhancing peptide binding accuracy. Evaluated on the comprehensive PepMerge benchmark, SurfFlow consistently outperforms full-atom baselines across all metrics. These results highlight the advantages of considering molecular surfaces in de novo peptide discovery and demonstrate the potential of integrating multiple protein modalities for more effective therapeutic peptide discovery.

</details>


### [133] [TSSR: Two-Stage Swap-Reward-Driven Reinforcement Learning for Character-Level SMILES Generation](https://arxiv.org/abs/2601.04521)
*Jacob Ede Levine,Yun Lyan Luo,Sai Chandra Kosaraju*

Main category: cs.LG

TL;DR: TSSR是一个两阶段强化学习框架，通过字符级SMILES生成解决当前化学语言模型生成不可解析或化学上不合理分子的问题。第一阶段修复语法错误，第二阶段提供化学感知反馈，显著提高分子生成的有效性和新颖性。


<details>
  <summary>Details</summary>
Motivation: 当前基于SMILES字符串的化学语言模型存在复合标记错误问题，导致生成的分子不可解析或化学上不合理。传统硬约束方法限制了化学空间的探索，需要一种能够提高分子生成质量而不牺牲多样性的方法。

Method: TSSR采用两阶段强化学习框架：第一阶段奖励局部标记交换以修复语法，第二阶段通过RDKit诊断提供化学感知反馈，奖励减少价态、芳香性和连接性问题。该方法模型无关，无需任务特定标签或手工语法。

Result: 在MOSES基准测试中，TSSR显著提高了语法有效性和化学有效性。在纯强化学习设置下，有效性、新颖性显著改善；在微调强化学习设置下，保持了药物相似性和可合成性同时提高了有效性和新颖性。

Conclusion: TSSR将稀疏的终端目标转化为更密集和可解释的奖励，在不降低多样性的前提下同时提高了语法和化学质量。该框架数据集无关，可适应各种强化学习方法。

Abstract: The design of reliable, valid, and diverse molecules is fundamental to modern drug discovery, as improved molecular generation supports efficient exploration of the chemical space for potential drug candidates and reduces the cost of early design efforts. Despite these needs, current chemical language models that generate molecules as SMILES strings are vulnerable to compounding token errors: many samples are unparseable or chemically implausible, and hard constraints meant to prevent failure can restrict exploration. To address this gap, we introduce TSSR, a Two-Stage, Swap-Reward-driven reinforcement learning (RL) framework for character-level SMILES generation. Stage one rewards local token swaps that repair syntax, promoting transitions from invalid to parseable strings. Stage two provides chemistry-aware feedback from RDKit diagnostics, rewarding reductions in valence, aromaticity, and connectivity issues. The reward decomposes into interpretable terms (swap efficiency, error reduction, distance to validity), is model agnostic, and requires no task-specific labels or hand-crafted grammars. We evaluated TSSR on the MOSES benchmark using a GRU policy trained with PPO in both pure RL (P-RL) from random initialization and fine-tuning RL (F-RL) starting from a pretrained chemical language model, assessing 10,000 generated SMILES per run. In P-RL, TSSR significantly improves syntactic validity, chemical validity, and novelty. In F-RL, TSSR preserves drug-likeness and synthesizability while increasing validity and novelty. Token-level analysis shows that syntax edits and chemistry fixes act jointly to reduce RDKit detected errors. TSSR converts a sparse terminal objective into a denser and more interpretable reward, improving both syntactic and chemical quality without reducing diversity. TSSR is dataset-agnostic and can be adapted to various reinforcement learning approaches.

</details>


### [134] [Not All Steps are Informative: On the Linearity of LLMs' RLVR Training](https://arxiv.org/abs/2601.04537)
*Tianle Wang,Zhongyuan Wu,Shenghao Jin,Hao Xu,Wei Chen,Ning Miao*

Main category: cs.LG

TL;DR: 论文发现RLVR训练过程中LLMs表现出强线性演化特征，提出通过权重外推和logits外推来预测未来模型状态，显著减少计算需求。


<details>
  <summary>Details</summary>
Motivation: RLVR训练需要数千步才能达到强性能，计算成本高昂。观察到RLVR过程中模型权重和输出log-probabilities与训练步数呈强线性相关，说明RLVR主要放大早期趋势而非持续发现新行为。

Method: 提出两种外推方法：权重外推（Weight Extrapolation）和logits外推（Logits Extrapolation），基于中间检查点预测未来模型状态，避免持续训练。

Result: 权重外推产生的模型性能与标准RL训练相当但计算量显著减少；logits外推在四个基准测试中一致优于持续RL训练，在外推步长范围内表现更稳定。

Conclusion: RLVR的线性特性使得外推方法可行，能大幅降低计算成本同时保持或提升性能，为LLM后训练提供了高效替代方案。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has become a central component of large language model (LLM) post-training. Unlike supervised fine-tuning (SFT), RLVR lets an LLM generate multiple candidate solutions and reinforces those that lead to a verifiably correct final answer. However, in practice, RLVR often requires thousands of training steps to reach strong performance, incurring substantial computation largely attributed to prolonged exploration. In this work, we make a surprising observation: during RLVR, LLMs evolve in a strongly linear manner. Specifically, both model weights and model output log-probabilities exhibit strong linear correlations with RL training steps. This suggests that RLVR predominantly amplifies trends that emerge early in training, rather than continuously discovering new behaviors throughout the entire optimization trajectory. Motivated by this linearity, we investigate whether future model states can be predicted from intermediate checkpoints via extrapolation, avoiding continued expensive training. We show that Weight Extrapolation produces models with performance comparable to standard RL training while requiring significantly less computation. Moreover, Logits Extrapolation consistently outperforms continued RL training on all four benchmarks by extrapolating beyond the step range where RL training remains stable.

</details>


### [135] [Timeliness-Oriented Scheduling and Resource Allocation in Multi-Region Collaborative Perception](https://arxiv.org/abs/2601.04542)
*Mengmeng Zhu,Yuxuan Sun,Yukuan Jia,Wei Chen,Bo Ai,Sheng Zhou*

Main category: cs.LG

TL;DR: 本文提出了一种基于时效性感知的多区域优先调度算法（TAMP），用于解决协同感知中的动态调度问题，在感知精度和通信资源使用之间实现平衡。


<details>
  <summary>Details</summary>
Motivation: 协同感知面临两个主要挑战：环境动态性导致信息时效性对感知性能至关重要；传感器计算能力有限和无线带宽受限需要精心设计通信量。

Method: 提出TAMP调度算法，基于Lyapunov优化策略，将长期平均目标分解为每时隙的优先级问题，通过经验惩罚函数将信息年龄和通信量的联合影响映射到感知性能。

Result: 在真实道路协同感知数据集上的实验表明，TAMP算法在不同配置下相比最佳基线方法，平均精度提升最高达27%。

Conclusion: TAMP算法有效解决了协同感知中的动态调度问题，在保证感知性能的同时优化了通信资源使用。

Abstract: Collaborative perception (CP) is a critical technology in applications like autonomous driving and smart cities. It involves the sharing and fusion of information among sensors to overcome the limitations of individual perception, such as blind spots and range limitations. However, CP faces two primary challenges. First, due to the dynamic nature of the environment, the timeliness of the transmitted information is critical to perception performance. Second, with limited computational power at the sensors and constrained wireless bandwidth, the communication volume must be carefully designed to ensure feature representations are both effective and sufficient. This work studies the dynamic scheduling problem in a multi-region CP scenario, and presents a Timeliness-Aware Multi-region Prioritized (TAMP) scheduling algorithm to trade-off perception accuracy and communication resource usage. Timeliness reflects the utility of information that decays as time elapses, which is manifested by the perception performance in CP tasks. We propose an empirical penalty function that maps the joint impact of Age of Information (AoI) and communication volume to perception performance. Aiming to minimize this timeliness-oriented penalty in the long-term, and recognizing that scheduling decisions have a cumulative effect on subsequent system states, we propose the TAMP scheduling algorithm. TAMP is a Lyapunov-based optimization policy that decomposes the long-term average objective into a per-slot prioritization problem, balancing the scheduling worth against resource cost. We validate our algorithm in both intersection and corridor scenarios with the real-world Roadside Cooperative perception (RCooper) dataset. Extensive simulations demonstrate that TAMP outperforms the best-performing baseline, achieving an Average Precision (AP) improvement of up to 27% across various configurations.

</details>


### [136] [GEnSHIN: Graphical Enhanced Spatio-temporal Hierarchical Inference Network for Traffic Flow Prediction](https://arxiv.org/abs/2601.04550)
*Zhiyan Zhou,Junjie Liao,Manho Zhang,Yingyi Liao,Ziai Wang*

Main category: cs.LG

TL;DR: 提出GEnSHIN模型用于交通流预测，通过注意力增强图卷积循环单元、非对称双嵌入图生成机制和动态记忆库模块，在METR-LA数据集上取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 随着城市化加速，智能交通系统对准确交通流预测的需求日益增长，需要处理复杂的时空依赖性。

Method: 集成三个创新设计：1）注意力增强图卷积循环单元（GCRU）引入Transformer模块增强长期时间依赖性建模；2）非对称双嵌入图生成机制结合真实路网和数据驱动潜在非对称拓扑；3）动态记忆库模块使用可学习交通模式原型和轻量级图更新器。

Result: 在METR-LA数据集上，GEnSHIN在MAE、RMSE、MAPE等多个指标上达到或超越对比模型性能，尤其在早晚高峰时段表现出优秀的预测稳定性。

Conclusion: 消融实验验证了各核心模块的有效性，GEnSHIN模型能够有效处理交通流预测中的复杂时空依赖性。

Abstract: With the acceleration of urbanization, intelligent transportation systems have an increasing demand for accurate traffic flow prediction. This paper proposes a novel Graph Enhanced Spatio-temporal Hierarchical Inference Network (GEnSHIN) to handle the complex spatio-temporal dependencies in traffic flow prediction. The model integrates three innovative designs: 1) An attention-enhanced Graph Convolutional Recurrent Unit (GCRU), which strengthens the modeling capability for long-term temporal dependencies by introducing Transformer modules; 2) An asymmetric dual-embedding graph generation mechanism, which leverages the real road network and data-driven latent asymmetric topology to generate graph structures that better fit the characteristics of actual traffic flow; 3) A dynamic memory bank module, which utilizes learnable traffic pattern prototypes to provide personalized traffic pattern representations for each sensor node, and introduces a lightweight graph updater during the decoding phase to adapt to dynamic changes in road network states. Extensive experiments on the public dataset METR-LA show that GEnSHIN achieves or surpasses the performance of comparative models across multiple metrics such as Mean Absolute Error (MAE), Root Mean Square Error (RMSE), and Mean Absolute Percentage Error (MAPE). Notably, the model demonstrates excellent prediction stability during peak morning and evening traffic hours. Ablation experiments further validate the effectiveness of each core module and its contribution to the final performance.

</details>


### [137] [Improving Semi-Supervised Contrastive Learning via Entropy-Weighted Confidence Integration of Anchor-Positive Pairs](https://arxiv.org/abs/2601.04555)
*Shogo Nakayama,Masahiro Okuda*

Main category: cs.LG

TL;DR: 本文提出了一种基于熵的置信度自适应加权损失函数，用于半监督对比学习，能够为更多样本分配伪标签并实现更稳定的学习性能。


<details>
  <summary>Details</summary>
Motivation: 传统的半监督对比学习方法只对预测概率超过阈值的样本分配伪标签，这限制了训练样本的利用效率。本文旨在通过置信度估计来扩展伪标签分配范围。

Method: 提出新颖的损失函数，基于预测概率分布的熵来估计每个样本的置信度，并应用置信度自适应加权。该方法允许为之前被排除在训练之外的样本分配伪标签，并在对比学习中同时考虑锚点和正样本的置信度。

Result: 实验结果表明，该方法提高了分类准确性，即使在低标签条件下也能实现更稳定的学习性能。

Conclusion: 基于熵的置信度自适应加权方法能够有效提升半监督对比学习的性能，特别是在样本稀缺的情况下表现出更好的鲁棒性。

Abstract: Conventional semi-supervised contrastive learning methods assign pseudo-labels only to samples whose highest predicted class probability exceeds a predefined threshold, and then perform supervised contrastive learning using those selected samples. In this study, we propose a novel loss function that estimates the confidence of each sample based on the entropy of its predicted probability distribution and applies confidence-based adaptive weighting. This approach enables pseudo-label assignment even to samples that were previously excluded from training and facilitates contrastive learning that accounts for the confidence of both anchor and positive samples in a more principled manner. Experimental results demonstrate that the proposed method improves classification accuracy and achieves more stable learning performance even under low-label conditions.

</details>


### [138] [A Vision for Multisensory Intelligence: Sensing, Synergy, and Science](https://arxiv.org/abs/2601.04563)
*Paul Pu Liang*

Main category: cs.LG

TL;DR: 本文提出了未来十年多感官人工智能的研究愿景，旨在将AI从当前的数字模态扩展到涵盖人类所有感官体验的完整多感官系统。


<details>
  <summary>Details</summary>
Motivation: 当前人工智能主要局限于文本、视觉和音频等数字模态，而人类对世界的体验是多感官的。作者希望通过多感官AI技术改变人类与AI的交互方式，连接AI与人类感官及丰富的生理、触觉、环境信号。

Method: 提出通过三个相互关联的主题推进该领域：传感（扩展AI捕捉世界的方式）、科学（开发量化多模态异质性的原则性科学）、协同（学习模态间及人机间的协同）。

Result: 论文提出了多感官AI的研究框架，并配套发布了MIT媒体实验室多感官智能小组的最新项目、资源和演示。

Conclusion: 多感官人工智能是未来AI发展的关键方向，需要建立新的传感技术、科学理论和协同机制，以实现更自然、丰富的人机交互体验。

Abstract: Our experience of the world is multisensory, spanning a synthesis of language, sight, sound, touch, taste, and smell. Yet, artificial intelligence has primarily advanced in digital modalities like text, vision, and audio. This paper outlines a research vision for multisensory artificial intelligence over the next decade. This new set of technologies can change how humans and AI experience and interact with one another, by connecting AI to the human senses and a rich spectrum of signals from physiological and tactile cues on the body, to physical and social signals in homes, cities, and the environment. We outline how this field must advance through three interrelated themes of sensing, science, and synergy. Firstly, research in sensing should extend how AI captures the world in richer ways beyond the digital medium. Secondly, developing a principled science for quantifying multimodal heterogeneity and interactions, developing unified modeling architectures and representations, and understanding cross-modal transfer. Finally, we present new technical challenges to learn synergy between modalities and between humans and AI, covering multisensory integration, alignment, reasoning, generation, generalization, and experience. Accompanying this vision paper are a series of projects, resources, and demos of latest advances from the Multisensory Intelligence group at the MIT Media Lab, see https://mit-mi.github.io/.

</details>


### [139] [Spatial-Temporal Feedback Diffusion Guidance for Controlled Traffic Imputation](https://arxiv.org/abs/2601.04572)
*Xiaowei Mao,Huihu Ding,Yan Lin,Tingrui Wu,Shengnan Guo,Dazhuo Qiu,Feiling Fang,Jilin Hu,Huaiyu Wan*

Main category: cs.LG

TL;DR: FENCE是一种空间-时间反馈扩散引导方法，通过动态调整引导尺度来解决交通数据缺失值插补问题，特别针对高缺失率节点优化性能。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在空间和时间维度上使用统一的引导尺度，对于高缺失率节点来说稀疏观测提供的条件引导不足，导致生成过程偏向先验分布而非条件观测，造成插补性能不佳。

Method: FENCE引入动态反馈机制，基于后验似然近似调整引导尺度，并在聚类级别计算引导尺度，利用空间-时间相关性提供更准确的引导。

Result: 在真实交通数据集上的实验结果表明，FENCE显著提高了插补准确性。

Conclusion: FENCE通过自适应控制引导尺度，有效解决了高缺失率节点插补问题，提升了空间-时间交通数据插补性能。

Abstract: Imputing missing values in spatial-temporal traffic data is essential for intelligent transportation systems. Among advanced imputation methods, score-based diffusion models have demonstrated competitive performance. These models generate data by reversing a noising process, using observed values as conditional guidance. However, existing diffusion models typically apply a uniform guidance scale across both spatial and temporal dimensions, which is inadequate for nodes with high missing data rates. Sparse observations provide insufficient conditional guidance, causing the generative process to drift toward the learned prior distribution rather than closely following the conditional observations, resulting in suboptimal imputation performance.
  To address this, we propose FENCE, a spatial-temporal feedback diffusion guidance method designed to adaptively control guidance scales during imputation. First, FENCE introduces a dynamic feedback mechanism that adjusts the guidance scale based on the posterior likelihood approximations. The guidance scale is increased when generated values diverge from observations and reduced when alignment improves, preventing overcorrection. Second, because alignment to observations varies across nodes and denoising steps, a global guidance scale for all nodes is suboptimal. FENCE computes guidance scales at the cluster level by grouping nodes based on their attention scores, leveraging spatial-temporal correlations to provide more accurate guidance. Experimental results on real-world traffic datasets show that FENCE significantly enhances imputation accuracy.

</details>


### [140] [FedKDX: Federated Learning with Negative Knowledge Distillation for Enhanced Healthcare AI Systems](https://arxiv.org/abs/2601.04587)
*Quang-Tu Pham,Hoang-Dieu Vu,Dinh-Dat Pham,Hieu H. Pham*

Main category: cs.LG

TL;DR: FedKDX是一个联邦学习框架，通过负知识蒸馏(NKD)技术解决医疗AI中的局限性，在保持隐私的同时提高模型泛化能力，在医疗数据集上表现出优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习方法主要关注正向知识转移，但在医疗应用中需要同时捕捉目标和非目标信息来改善模型泛化能力，特别是在非独立同分布数据场景下。

Method: FedKDX整合了多种知识转移技术，包括传统知识蒸馏、对比学习和负知识蒸馏(NKD)，构建统一架构，在保护隐私的同时降低通信成本。

Result: 在SLEEP、UCI-HAR和PAMAP2等医疗数据集上的实验表明，FedKDX相比最先进方法准确率提升达2.53%，收敛速度更快，在非IID数据分布下表现更好。

Conclusion: 该方法在HIPAA和GDPR等监管框架下的隐私敏感医疗应用中具有前景，为去中心化医疗环境提供了性能与实用性之间的平衡解决方案。

Abstract: This paper introduces FedKDX, a federated learning framework that addresses limitations in healthcare AI through Negative Knowledge Distillation (NKD). Unlike existing approaches that focus solely on positive knowledge transfer, FedKDX captures both target and non-target information to improve model generalization in healthcare applications. The framework integrates multiple knowledge transfer techniques--including traditional knowledge distillation, contrastive learning, and NKD--within a unified architecture that maintains privacy while reducing communication costs. Through experiments on healthcare datasets (SLEEP, UCI-HAR, and PAMAP2), FedKDX demonstrates improved accuracy (up to 2.53% over state-of-the-art methods), faster convergence, and better performance on non-IID data distributions. Theoretical analysis supports NKD's contribution to addressing statistical heterogeneity in distributed healthcare data. The approach shows promise for privacy-sensitive medical applications under regulatory frameworks like HIPAA and GDPR, offering a balanced solution between performance and practical implementation requirements in decentralized healthcare settings. The code and model are available at https://github.com/phamdinhdat-ai/Fed_2024.

</details>


### [141] [Density Matrix RNN (DM-RNN): A Quantum Information Theoretic Framework for Modeling Musical Context and Polyphony](https://arxiv.org/abs/2601.04592)
*Joonwon Seo,Mariana Montiel*

Main category: cs.LG

TL;DR: 提出密度矩阵RNN（DM-RNN）架构，使用密度矩阵来捕捉音乐中的模糊性，通过量子通道定义时间动态，并基于Choi-Jamiolkowski同构确保物理有效性。


<details>
  <summary>Details</summary>
Motivation: 传统RNN将音乐上下文总结为确定性隐藏状态向量，形成信息瓶颈，无法捕捉音乐中的固有模糊性。

Method: 使用密度矩阵维持音乐解释的统计集合（混合状态），捕捉经典概率和量子相干性；基于Choi-Jamiolkowski同构的参数化策略确保学习动态保持物理有效性（CPTP）。

Result: DM-RNN提供了一个数学严谨的框架，用于建模复杂、模糊的音乐结构，并通过冯·诺依曼熵和量子互信息量化音乐不确定性和声部间的纠缠。

Conclusion: DM-RNN通过量子力学工具成功解决了传统RNN在音乐建模中的信息瓶颈问题，为处理音乐模糊性提供了理论框架。

Abstract: Classical Recurrent Neural Networks (RNNs) summarize musical context into a deterministic hidden state vector, imposing an information bottleneck that fails to capture the inherent ambiguity in music. We propose the Density Matrix RNN (DM-RNN), a novel theoretical architecture utilizing the Density Matrix. This allows the model to maintain a statistical ensemble of musical interpretations (a mixed state), capturing both classical probabilities and quantum coherences. We rigorously define the temporal dynamics using Quantum Channels (CPTP maps). Crucially, we detail a parameterization strategy based on the Choi-Jamiolkowski isomorphism, ensuring the learned dynamics remain physically valid (CPTP) by construction. We introduce an analytical framework using Von Neumann Entropy to quantify musical uncertainty and Quantum Mutual Information (QMI) to measure entanglement between voices. The DM-RNN provides a mathematically rigorous framework for modeling complex, ambiguous musical structures.

</details>


### [142] [DeepHalo: A Neural Choice Model with Controllable Context Effects](https://arxiv.org/abs/2601.04616)
*Shuhan Zhang,Zhi Wang,Rui Gao,Shuang Li*

Main category: cs.LG

TL;DR: DeepHalo是一个神经建模框架，用于建模受选择集组成影响的上下文依赖决策行为，能够控制交互阶数并提供可解释性


<details>
  <summary>Details</summary>
Motivation: 传统模型假设独立选择行为，但行为研究表明偏好受选择集组成影响（上下文效应），现有模型要么忽略特征，要么交互结构受限或可解释性差

Method: 提出DeepHalo框架，结合特征的同时支持对交互阶数的显式控制和上下文效应的原则性解释，能够系统识别不同阶数的交互效应

Result: 在合成和真实数据集上的实验表明，DeepHalo具有强大的预测性能，同时为选择驱动因素提供更高的透明度

Conclusion: DeepHalo框架成功解决了上下文依赖决策建模中的可解释性问题，在保持高性能的同时提供了对选择驱动因素的深入理解

Abstract: Modeling human decision-making is central to applications such as recommendation, preference learning, and human-AI alignment. While many classic models assume context-independent choice behavior, a large body of behavioral research shows that preferences are often influenced by the composition of the choice set itself -- a phenomenon known as the context effect or Halo effect. These effects can manifest as pairwise (first-order) or even higher-order interactions among the available alternatives. Recent models that attempt to capture such effects either focus on the featureless setting or, in the feature-based setting, rely on restrictive interaction structures or entangle interactions across all orders, which limits interpretability. In this work, we propose DeepHalo, a neural modeling framework that incorporates features while enabling explicit control over interaction order and principled interpretation of context effects. Our model enables systematic identification of interaction effects by order and serves as a universal approximator of context-dependent choice functions when specialized to a featureless setting. Experiments on synthetic and real-world datasets demonstrate strong predictive performance while providing greater transparency into the drivers of choice.

</details>


### [143] [Learning Dynamics in RL Post-Training for Language Models](https://arxiv.org/abs/2601.04670)
*Akiyoshi Tomihari*

Main category: cs.LG

TL;DR: 本文通过神经正切核（NTK）框架分析RL后训练的学习动态，发现特征表示变异性有限会导致模型置信度系统性增加，从而解释输出多样性减少的现象。作者提出了分类器优先强化学习（CF-RL）策略来加速优化。


<details>
  <summary>Details</summary>
Motivation: 理解RL后训练中输出多样性减少的现象，并从监督学习中借鉴NTK分析框架来系统研究RL后训练的学习动态。

Method: 采用经验性NTK框架，将NTK分解为两个组件来分析RL更新如何在训练样本间传播。提出CF-RL策略，先更新分类器再进行标准RL优化。

Result: 分析表明特征表示变异性有限会导致RL更新系统性增加模型置信度。实验验证CF-RL能提高模型置信度并加速优化，且其机制与监督学习中的线性探测再微调不同。

Conclusion: 本研究形式化了RL后训练的学习动态，为后续分析和改进提供了理论基础，CF-RL策略展示了优化RL训练过程的有效途径。

Abstract: Reinforcement learning (RL) post-training is a critical stage in modern language model development, playing a key role in improving alignment and reasoning ability. However, several phenomena remain poorly understood, including the reduction in output diversity. To gain a broader understanding of RL post-training, we analyze the learning dynamics of RL post-training from a perspective that has been studied in supervised learning but remains underexplored in RL. We adopt an empirical neural tangent kernel (NTK) framework and decompose the NTK into two components to characterize how RL updates propagate across training samples. Our analysis reveals that limited variability in feature representations can cause RL updates to systematically increase model confidence, providing an explanation for the commonly observed reduction in output diversity after RL post-training. Furthermore, we show that effective learning in this regime depends on rapidly shaping the classifier, which directly affects the gradient component of the NTK. Motivated by these insights, we propose classifier-first reinforcement learning (CF-RL), a simple two-stage training strategy that prioritizes classifier updates before standard RL optimization. Experimental results validate our theoretical analysis by demonstrating increased model confidence and accelerated optimization under CF-RL. Additional analysis shows that the mechanism underlying CF-RL differs from that of linear-probing-then-fine-tuning in supervised learning. Overall, our study formalizes the learning dynamics of RL post-training and motivates further analysis and improvement.

</details>


### [144] [Estimating Causal Effects in Gaussian Linear SCMs with Finite Data](https://arxiv.org/abs/2601.04673)
*Aurghya Maiti,Prateek Jain*

Main category: cs.LG

TL;DR: 该论文提出了一种集中化高斯线性结构因果模型（CGL-SCMs），用于在存在潜在混淆变量的情况下从观测数据中估计因果效应，并开发了基于EM的估计算法来解决传统GL-SCMs中的过参数化问题。


<details>
  <summary>Details</summary>
Motivation: 观测数据中的因果效应估计是因果推断的基本挑战，特别是在存在潜在混淆变量的情况下。高斯线性结构因果模型（GL-SCMs）虽然具有分析可处理性，但由于过参数化问题，在有限数据下参数估计往往不可行。

Method: 提出了集中化高斯线性结构因果模型（CGL-SCMs），这是一个简化但表达能力强的子类，其中外生变量遵循标准化分布。开发了一种基于EM的新估计算法，可以从有限观测样本中学习CGL-SCM参数并估计可识别的因果效应。

Result: 理论分析通过合成数据和基准因果图的实验得到验证，表明学习到的模型能够准确恢复因果分布。CGL-SCMs在因果效应可识别性方面与GL-SCMs具有同等表达能力。

Conclusion: CGL-SCMs为解决GL-SCMs中的过参数化问题提供了有效的解决方案，其基于EM的估计算法能够在有限数据下准确估计因果效应，为存在潜在混淆变量的因果推断问题提供了实用的工具。

Abstract: Estimating causal effects from observational data remains a fundamental challenge in causal inference, especially in the presence of latent confounders. This paper focuses on estimating causal effects in Gaussian Linear Structural Causal Models (GL-SCMs), which are widely used due to their analytical tractability. However, parameter estimation in GL-SCMs is often infeasible with finite data, primarily due to overparameterization. To address this, we introduce the class of Centralized Gaussian Linear SCMs (CGL-SCMs), a simplified yet expressive subclass where exogenous variables follow standardized distributions. We show that CGL-SCMs are equally expressive in terms of causal effect identifiability from observational distributions and present a novel EM-based estimation algorithm that can learn CGL-SCM parameters and estimate identifiable causal effects from finite observational samples. Our theoretical analysis is validated through experiments on synthetic data and benchmark causal graphs, demonstrating that the learned models accurately recover causal distributions.

</details>


### [145] [Do LLMs Benefit from User and Item Embeddings in Recommendation Tasks?](https://arxiv.org/abs/2601.04690)
*Mir Rayat Imtiaz Hossain,Leo Feng,Leonid Sigal,Mohamed Osama Ahmed*

Main category: cs.LG

TL;DR: 本文提出了一种将协同过滤嵌入投影到LLM标记空间的简单有效方法，通过轻量级投影模块将用户和物品嵌入整合到LLM中，结合文本语义生成推荐。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推荐方法主要依赖文本语义或仅有限地使用协同信号，难以处理用户历史中的多个物品嵌入，导致忽略了丰富的协同信息。

Method: 通过独立的轻量级投影模块将协同过滤学习到的用户和物品嵌入投影到LLM标记空间，微调后的LLM同时基于投影嵌入和文本标记生成推荐。

Result: 初步结果表明该方法能有效利用结构化的用户-物品交互数据，相比仅使用文本的LLM基线提高了推荐性能。

Conclusion: 该方法为传统推荐系统与现代LLM的融合提供了实用路径，成功结合了协同过滤和语言模型的优势。

Abstract: Large Language Models (LLMs) have emerged as promising recommendation systems, offering novel ways to model user preferences through generative approaches. However, many existing methods often rely solely on text semantics or incorporate collaborative signals in a limited manner, typically using only user or item embeddings. These methods struggle to handle multiple item embeddings representing user history, reverting to textual semantics and neglecting richer collaborative information. In this work, we propose a simple yet effective solution that projects user and item embeddings, learned from collaborative filtering, into the LLM token space via separate lightweight projector modules. A finetuned LLM then conditions on these projected embeddings alongside textual tokens to generate recommendations. Preliminary results show that this design effectively leverages structured user-item interaction data, improves recommendation performance over text-only LLM baselines, and offers a practical path for bridging traditional recommendation systems with modern LLMs.

</details>


### [146] [A zone-based training approach for last-mile routing using Graph Neural Networks and Pointer Networks](https://arxiv.org/abs/2601.04705)
*Àngel Ruiz-Fas,Carlos Granell,José Francisco Ramos,Joaquín Huerta,Sergio Trilles*

Main category: cs.LG

TL;DR: 提出一种基于深度学习的最后一公里路由方法，通过将区域划分为地理分区并训练分区特定模型，以最小化非对称旅行时间下的配送时间。


<details>
  <summary>Details</summary>
Motivation: 电子商务快速增长使最后一公里配送网络达到极限，传统启发式方法在旅行时间高度非对称（如单行道、拥堵）时难以适应，需要更智能的路由优化方案。

Method: 使用编码器-解码器架构：图神经网络编码器生成节点嵌入捕捉空间关系，指针网络解码器顺序选择下一个停靠点。将区域划分为相似大小的地理分区，每个分区训练独立的模型实例。

Result: 在亚马逊最后一公里路由挑战赛的洛杉矶路线数据上评估，分区训练相比通用训练平均预测路线长度减少，且停靠点越多性能提升越显著。

Conclusion: 分区化深度学习方法能有效优化非对称旅行时间下的最后一公里路由，特别适用于高密度配送场景。

Abstract: Rapid e-commerce growth has pushed last-mile delivery networks to their limits, where small routing gains translate into lower costs, faster service, and fewer emissions. Classical heuristics struggle to adapt when travel times are highly asymmetric (e.g., one-way streets, congestion). A deep learning-based approach to the last-mile routing problem is presented to generate geographical zones composed of stop sequences to minimize last-mile delivery times.
  The presented approach is an encoder-decoder architecture. Each route is represented as a complete directed graph whose nodes are stops and whose edge weights are asymmetric travel times. A Graph Neural Network encoder produces node embeddings that captures the spatial relationships between stops. A Pointer Network decoder then takes the embeddings and the route's start node to sequentially select the next stops, assigning a probability to each unvisited node as the next destination.
  Cells of a Discrete Global Grid System which contain route stops in the training data are obtained and clustered to generate geographical zones of similar size in which the process of training and inference are divided. Subsequently, a different instance of the model is trained per zone only considering the stops of the training routes which are included in that zone.
  This approach is evaluated using the Los Angeles routes from the 2021 Amazon Last Mile Routing Challenge. Results from general and zone-based training are compared, showing a reduction in the average predicted route length in the zone-based training compared to the general training. The performance improvement of the zone-based approach becomes more pronounced as the number of stops per route increases.

</details>


### [147] [MQ-GNN: A Multi-Queue Pipelined Architecture for Scalable and Efficient GNN Training](https://arxiv.org/abs/2601.04707)
*Irfan Ullah,Young-Koo Lee*

Main category: cs.LG

TL;DR: MQ-GNN是一个多队列流水线框架，通过交错GNN训练阶段和优化资源利用来解决GNN训练中的可扩展性问题，实现了4.6倍的训练加速和30%的GPU利用率提升。


<details>
  <summary>Details</summary>
Motivation: 图神经网络(GNNs)在处理图结构数据时面临可扩展性挑战，包括低效的小批量生成、数据传输瓶颈和昂贵的GPU间同步。现有训练框架无法重叠这些阶段，导致资源利用不充分。

Method: 提出MQ-GNN框架，包含：1) RaCoM模型实现异步梯度共享和模型更新，通过自适应周期性同步确保全局一致性；2) 全局邻居采样与缓存减少数据传输开销；3) 自适应队列大小策略平衡计算和内存效率。

Result: 在四个大规模数据集和十个基线模型上的实验表明，MQ-GNN实现了高达4.6倍的训练加速和30%的GPU利用率提升，同时保持竞争性精度。

Conclusion: MQ-GNN为多GPU GNN训练提供了一个可扩展且高效的解决方案，显著提升了训练效率和资源利用率。

Abstract: Graph Neural Networks (GNNs) are powerful tools for learning graph-structured data, but their scalability is hindered by inefficient mini-batch generation, data transfer bottlenecks, and costly inter-GPU synchronization. Existing training frameworks fail to overlap these stages, leading to suboptimal resource utilization. This paper proposes MQ-GNN, a multi-queue pipelined framework that maximizes training efficiency by interleaving GNN training stages and optimizing resource utilization. MQ-GNN introduces Ready-to-Update Asynchronous Consistent Model (RaCoM), which enables asynchronous gradient sharing and model updates while ensuring global consistency through adaptive periodic synchronization. Additionally, it employs global neighbor sampling with caching to reduce data transfer overhead and an adaptive queue-sizing strategy to balance computation and memory efficiency. Experiments on four large-scale datasets and ten baseline models demonstrate that MQ-GNN achieves up to \boldmath $\bm{4.6\,\times}$ faster training time and 30% improved GPU utilization while maintaining competitive accuracy. These results establish MQ-GNN as a scalable and efficient solution for multi-GPU GNN training.

</details>


### [148] [GPU-Accelerated INT8 Quantization for KV Cache Compression in Large Language Models](https://arxiv.org/abs/2601.04719)
*Maanas Taneja,Purab Shingvi*

Main category: cs.LG

TL;DR: 该论文提出并评估了GPU加速的INT8量化方法用于压缩大语言模型中的KV缓存，实现了4倍内存减少且精度损失极小。


<details>
  <summary>Details</summary>
Motivation: 大语言模型推理过程中，KV缓存存在显著的内存瓶颈，其大小随序列长度线性增长，常常超过模型权重本身的内存占用。

Method: 开发了四种CUDA内核变体（naive、tiled、coarsened和vectorized），在最多10亿元素的真实工作负载规模上进行基准测试，实现INT8量化的KV缓存压缩。

Result: 向量化内核相比CPU基线实现了高达1694倍的加速，重建误差低于0.004，注意力分数误差低于0.1（即使在8K维头的情况下）。计算开销可忽略（6-58ms）。

Conclusion: INT8量化为减少LLM推理中的内存压力提供了一种实用方法，对下游模型行为影响极小。

Abstract: The key-value (KV) cache in large language models presents a significant memory bottleneck during inference, growing linearly with sequence length and often exceeding the memory footprint of model weights themselves. We implement and evaluate GPU-accelerated INT8 quantization for KV cache compression, achieving 4$\times$ memory reduction with minimal accuracy degradation. We develop four CUDA kernel variants -- naive, tiled, coarsened, and vectorized -- and benchmark them across realistic workload sizes up to 1 billion elements. Our vectorized kernel achieves up to 1,694$\times$ speedup over CPU baselines while maintaining reconstruction error below 0.004 and attention score error below 0.1 even for 8K-dimensional heads. These results demonstrate that INT8 quantization provides a practical approach for reducing memory pressure in LLM inference with negligible computational overhead (6--58ms) and minimal impact on downstream model behavior

</details>


### [149] [Excess Description Length of Learning Generalizable Predictors](https://arxiv.org/abs/2601.04728)
*Elizabeth Donoway,Hailey Joren,Fabien Roger,Jan Leike*

Main category: cs.LG

TL;DR: 本文提出了一个信息论框架Excess Description Length (EDL)来衡量微调过程中从训练数据中提取并写入模型参数的结构信息量，区分了能力激发与能力教学的不同机制。


<details>
  <summary>Details</summary>
Motivation: 理解微调是激发语言模型的潜在能力还是教授新能力，这是模型评估和安全性的基本问题。需要量化微调从训练数据中提取的预测结构信息。

Method: 基于预编码理论构建EDL指标，衡量在线训练过程中顺序编码训练标签所需的比特数与最终训练模型下剩余编码成本之间的差距。通过一系列玩具模型验证框架。

Result: EDL在期望上非负，在无限数据极限下收敛到剩余描述长度，并提供期望泛化增益的界限。证明了随机标签的EDL接近零，单个样本可以消除大量不确定性，稀有输入上学习的结构对泛化贡献小，格式学习产生与能力获取不同的早期瞬态。

Conclusion: 该框架为经验观察提供了严格基础，表明能力激发和能力教学具有质的不同的扩展特征，有助于理解微调的本质机制。

Abstract: Understanding whether fine-tuning elicits latent capabilities or teaches new ones is a fundamental question for language model evaluation and safety. We develop a formal information-theoretic framework for quantifying how much predictive structure fine-tuning extracts from the train dataset and writes into a model's parameters. Our central quantity, Excess Description Length (EDL), is defined via prequential coding and measures the gap between the bits required to encode training labels sequentially using an evolving model (trained online) and the residual encoding cost under the final trained model. We establish that EDL is non-negative in expectation, converges to surplus description length in the infinite-data limit, and provides bounds on expected generalization gain. Through a series of toy models, we clarify common confusions about information in learning: why random labels yield EDL near zero, how a single example can eliminate many bits of uncertainty about the underlying rule(s) that describe the data distribution, why structure learned on rare inputs contributes proportionally little to expected generalization, and how format learning creates early transients distinct from capability acquisition. This framework provides rigorous foundations for the empirical observation that capability elicitation and teaching exhibit qualitatively distinct scaling signatures.

</details>


### [150] [Fast Mining and Dynamic Time-to-Event Prediction over Multi-sensor Data Streams](https://arxiv.org/abs/2601.04741)
*Kota Nakamura,Koki Kawabata,Yasuko Matsubara,Yasushi Sakurai*

Main category: cs.LG

TL;DR: TimeCast是一个动态预测框架，用于实时预测机器故障时间，通过分析多传感器数据流来适应数据模式的动态变化。


<details>
  <summary>Details</summary>
Motivation: 解决实时传感器数据流中机器故障预测问题，应对现实世界数据流动态变化的挑战，提供准确、实时的未来事件时间预测。

Method: 提出TimeCast动态预测框架，具有三个关键特性：(a) 动态性：识别时间演化的模式阶段并为每个阶段学习独立模型；(b) 实用性：发现捕捉传感器间时变依赖关系的有效阶段；(c) 可扩展性：算法输入规模线性扩展，支持数据流上的在线模型更新。

Result: 在真实数据集上的大量实验表明，TimeCast相比最先进方法提供更高的预测准确性，同时能够发现数据流中的动态变化，并大幅减少计算时间。

Conclusion: TimeCast框架能够有效处理动态数据流，提供准确的实时故障预测，具有动态适应、实用性和可扩展性等优势。

Abstract: Given real-time sensor data streams obtained from machines, how can we continuously predict when a machine failure will occur? This work aims to continuously forecast the timing of future events by analyzing multi-sensor data streams. A key characteristic of real-world data streams is their dynamic nature, where the underlying patterns evolve over time. To address this, we present TimeCast, a dynamic prediction framework designed to adapt to these changes and provide accurate, real-time predictions of future event time. Our proposed method has the following properties: (a) Dynamic: it identifies the distinct time-evolving patterns (i.e., stages) and learns individual models for each, enabling us to make adaptive predictions based on pattern shifts. (b) Practical: it finds meaningful stages that capture time-varying interdependencies between multiple sensors and improve prediction performance; (c) Scalable: our algorithm scales linearly with the input size and enables online model updates on data streams. Extensive experiments on real datasets demonstrate that TimeCast provides higher prediction accuracy than state-of-the-art methods while finding dynamic changes in data streams with a great reduction in computational time.

</details>


### [151] [Intraday spatiotemporal PV power prediction at national scale using satellite-based solar forecast models](https://arxiv.org/abs/2601.04751)
*Luca Lanzilao,Angela Meyer*

Main category: cs.LG

TL;DR: 本文提出了一个新颖的时空光伏功率预测框架，评估了7种日内光伏功率临近预报模型的性能，发现基于卫星的方法在短预报时效内优于数值天气预报模型，其中SolarSTEPS和SHADECast表现最佳。


<details>
  <summary>Details</summary>
Motivation: 开发一个全面的评估框架来比较不同光伏功率预测模型的性能，填补国家尺度时空光伏预测研究的空白。

Method: 使用基于卫星的深度学习和光流方法、物理数值天气预报模型，将卫星反演的太阳辐射场通过站点特定的机器学习模型转换为光伏功率，并与瑞士6434个光伏电站的数据进行对比验证。

Result: 基于卫星的方法在短时效预报中优于IFS-ENS模型；SolarSTEPS和SHADECast在SSI和光伏功率预测中最准确；SHADECast提供最可靠的集合离散度；预报技巧随海拔升高而降低；国家尺度上82%的日总发电量预测相对误差低于10%。

Conclusion: 基于卫星的预测模型具有稳健性和业务化应用潜力，特别是在短时效预报方面表现优异，为光伏功率预测提供了可靠的技术支持。

Abstract: We present a novel framework for spatiotemporal photovoltaic (PV) power forecasting and use it to evaluate the reliability, sharpness, and overall performance of seven intraday PV power nowcasting models. The model suite includes satellite-based deep learning and optical-flow approaches and physics-based numerical weather prediction models, covering both deterministic and probabilistic formulations. Forecasts are first validated against satellite-derived surface solar irradiance (SSI). Irradiance fields are then converted into PV power using station-specific machine learning models, enabling comparison with production data from 6434 PV stations across Switzerland. To our knowledge, this is the first study to investigate spatiotemporal PV forecasting at a national scale. We additionally provide the first visualizations of how mesoscale cloud systems shape national PV production on hourly and sub-hourly timescales. Our results show that satellite-based approaches outperform the Integrated Forecast System (IFS-ENS), particularly at short lead times. Among them, SolarSTEPS and SHADECast deliver the most accurate SSI and PV power predictions, with SHADECast providing the most reliable ensemble spread. The deterministic model IrradianceNet achieves the lowest root mean square error, while probabilistic forecasts of SolarSTEPS and SHADECast provide better-calibrated uncertainty. Forecast skill generally decreases with elevation. At a national scale, satellite-based models forecast the daily total PV generation with relative errors below 10% for 82% of the days in 2019-2020, demonstrating robustness and their potential for operational use.

</details>


### [152] [Smart IoT-Based Wearable Device for Detection and Monitoring of Common Cow Diseases Using a Novel Machine Learning Technique](https://arxiv.org/abs/2601.04761)
*Rupsa Rani Mishra,D. Chandrasekhar Rao,Ajaya Kumar Tripathy*

Main category: cs.LG

TL;DR: 该论文提出了一种基于物联网和机器学习的智能系统，用于自动化监测奶牛健康状况，旨在解决传统人工观察方法效率低、成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 大规模养殖场中人工监测奶牛疾病存在劳动强度大、效率低、准确性差的问题，需要开发自动化、低成本、可靠的智能系统来提升疾病检测的准确性和效率。

Method: 研究提出了一种物联网支持的物理信息系统框架，结合新颖的机器学习算法，通过分析奶牛的生理和行为数据来诊断多种常见疾病。

Result: 该系统能够通过分析全面的生理和行为特征，准确预测多种奶牛疾病，实现高效的健康评估。

Conclusion: 基于物联网和机器学习的技术能够有效自动化奶牛健康监测，提高疾病检测准确性，降低运营成本，为大规模养殖提供可行的解决方案。

Abstract: Manual observation and monitoring of individual cows for disease detection present significant challenges in large-scale farming operations, as the process is labor-intensive, time-consuming, and prone to reduced accuracy. The reliance on human observation often leads to delays in identifying symptoms, as the sheer number of animals can hinder timely attention to each cow. Consequently, the accuracy and precision of disease detection are significantly compromised, potentially affecting animal health and overall farm productivity. Furthermore, organizing and managing human resources for the manual observation and monitoring of cow health is a complex and economically demanding task. It necessitates the involvement of skilled personnel, thereby contributing to elevated farm maintenance costs and operational inefficiencies. Therefore, the development of an automated, low-cost, and reliable smart system is essential to address these challenges effectively. Although several studies have been conducted in this domain, very few have simultaneously considered the detection of multiple common diseases with high prediction accuracy. However, advancements in Internet of Things (IoT), Machine Learning (ML), and Cyber-Physical Systems have enabled the automation of cow health monitoring with enhanced accuracy and reduced operational costs. This study proposes an IoT-enabled Cyber-Physical System framework designed to monitor the daily activities and health status of cow. A novel ML algorithm is proposed for the diagnosis of common cow diseases using collected physiological and behavioral data. The algorithm is designed to predict multiple diseases by analyzing a comprehensive set of recorded physiological and behavioral features, enabling accurate and efficient health assessment.

</details>


### [153] [AgentOCR: Reimagining Agent History via Optical Self-Compression](https://arxiv.org/abs/2601.04786)
*Lang Feng,Fuchao Yang,Feng Chen,Xin Cheng,Haiyang Xu,Zhenglin Wan,Ming Yan,Bo An*

Main category: cs.LG

TL;DR: AgentOCR是一个利用视觉令牌信息密度优势的框架，通过将累积的观察-行动历史表示为紧凑的渲染图像来解决LLM代理系统中文本历史膨胀导致的令牌预算和内存使用问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型代理系统在多轮交互中面临文本历史快速膨胀的问题，这会显著增加令牌预算和内存使用，成为实际部署的瓶颈。

Method: AgentOCR提出分段光学缓存机制，将历史分解为可哈希的段并维护视觉缓存以消除冗余重渲染；同时引入代理自压缩机制，让代理主动发出压缩率并通过压缩感知奖励进行训练，自适应平衡任务成功和令牌效率。

Result: 在ALFWorld和基于搜索的QA等挑战性代理基准测试中，AgentOCR在保持超过95%基于文本的代理性能的同时，显著减少令牌消耗（>50%），实现一致的令牌和内存效率。分段光学缓存带来20倍渲染加速，自压缩机制有效实现战略平衡。

Conclusion: AgentOCR通过视觉令牌表示和智能缓存压缩机制，有效解决了LLM代理系统中的历史膨胀问题，在保持性能的同时大幅提升了效率，为实际部署提供了可行方案。

Abstract: Recent advances in large language models (LLMs) enable agentic systems trained with reinforcement learning (RL) over multi-turn interaction trajectories, but practical deployment is bottlenecked by rapidly growing textual histories that inflate token budgets and memory usage. We introduce AgentOCR, a framework that exploits the superior information density of visual tokens by representing the accumulated observation-action history as a compact rendered image. To make multi-turn rollouts scalable, AgentOCR proposes segment optical caching. By decomposing history into hashable segments and maintaining a visual cache, this mechanism eliminates redundant re-rendering. Beyond fixed rendering, AgentOCR introduces agentic self-compression, where the agent actively emits a compression rate and is trained with compression-aware reward to adaptively balance task success and token efficiency. We conduct extensive experiments on challenging agentic benchmarks, ALFWorld and search-based QA. Remarkably, results demonstrate that AgentOCR preserves over 95\% of text-based agent performance while substantially reducing token consumption (>50\%), yielding consistent token and memory efficiency. Our further analysis validates a 20x rendering speedup from segment optical caching and the effective strategic balancing of self-compression.

</details>


### [154] [Neural-Symbolic Integration with Evolvable Policies](https://arxiv.org/abs/2601.04799)
*Marios Thoma,Vassilis Vassiliades,Loizos Michael*

Main category: cs.LG

TL;DR: 该论文提出了一个通过进化过程同时学习不可微分符号策略和神经网络权重的神经符号AI框架，突破了现有方法对预定义符号策略或可微分策略的限制。


<details>
  <summary>Details</summary>
Motivation: 现有神经符号AI框架通常需要预定义的符号策略或可微分策略，这在领域专业知识不可用或策略本质不可微分时限制了其适用性。

Method: 将神经符号系统视为种群中的有机体，通过进化过程（包括符号规则添加和神经权重变化的突变）进行演化，使用基于适应度的选择引导收敛到隐藏目标策略。扩展了NEUROLOG架构使符号策略可训练，采用Valiant可进化性框架和机器辅导语义，通过溯因推理训练神经网络。

Result: 实验表明，从空策略和随机神经权重开始的神经符号系统能够成功逼近隐藏的不可微分目标策略，中位正确性能接近100%。

Conclusion: 这项工作为在难以或无法从专家获取符号知识的领域开展神经符号研究迈出了重要一步。

Abstract: Neural-Symbolic (NeSy) Artificial Intelligence has emerged as a promising approach for combining the learning capabilities of neural networks with the interpretable reasoning of symbolic systems. However, existing NeSy frameworks typically require either predefined symbolic policies or policies that are differentiable, limiting their applicability when domain expertise is unavailable or when policies are inherently non-differentiable. We propose a framework that addresses this limitation by enabling the concurrent learning of both non-differentiable symbolic policies and neural network weights through an evolutionary process. Our approach casts NeSy systems as organisms in a population that evolve through mutations (both symbolic rule additions and neural weight changes), with fitness-based selection guiding convergence toward hidden target policies. The framework extends the NEUROLOG architecture to make symbolic policies trainable, adapts Valiant's Evolvability framework to the NeSy context, and employs Machine Coaching semantics for mutable symbolic representations. Neural networks are trained through abductive reasoning from the symbolic component, eliminating differentiability requirements. Through extensive experimentation, we demonstrate that NeSy systems starting with empty policies and random neural weights can successfully approximate hidden non-differentiable target policies, achieving median correct performance approaching 100%. This work represents a step toward enabling NeSy research in domains where the acquisition of symbolic knowledge from experts is challenging or infeasible.

</details>


### [155] [Parallelizing Node-Level Explainability in Graph Neural Networks](https://arxiv.org/abs/2601.04807)
*Oscar Llorente,Jaime Boal,Eugenio F. Sánchez-Úbeda,Antonio Diaz-Cano,Miguel Familiar*

Main category: cs.LG

TL;DR: 该论文提出了一种通过图分区并行化GNN节点级可解释性计算的新方法，解决了大规模图计算效率低下的问题，并在内存受限时通过dropout机制提供可控的权衡。


<details>
  <summary>Details</summary>
Motivation: 传统GNN节点级可解释性计算在大规模图上极其耗时，而批处理策略会降低解释质量，需要一种高效且可扩展的解决方案。

Method: 通过图分区将图分解为不相交子图，实现节点邻居可解释性的并行计算；针对内存受限场景提出基于dropout的重建机制，在内存使用和解释保真度之间提供可控权衡。

Result: 在真实数据集上的实验结果显示该方法实现了显著的速度提升，能够为大规模GNN模型提供可扩展的透明可解释性。

Conclusion: 该方法通过图分区和并行计算有效解决了GNN节点级可解释性的可扩展性问题，同时通过dropout机制适应不同内存约束条件，为大规模图分析提供了实用解决方案。

Abstract: Graph Neural Networks (GNNs) have demonstrated remarkable performance in a wide range of tasks, such as node classification, link prediction, and graph classification, by exploiting the structural information in graph-structured data. However, in node classification, computing node-level explainability becomes extremely time-consuming as the size of the graph increases, while batching strategies often degrade explanation quality. This paper introduces a novel approach to parallelizing node-level explainability in GNNs through graph partitioning. By decomposing the graph into disjoint subgraphs, we enable parallel computation of explainability for node neighbors, significantly improving the scalability and efficiency without affecting the correctness of the results, provided sufficient memory is available. For scenarios where memory is limited, we further propose a dropout-based reconstruction mechanism that offers a controllable trade-off between memory usage and explanation fidelity. Experimental results on real-world datasets demonstrate substantial speedups, enabling scalable and transparent explainability for large-scale GNN models.

</details>


### [156] [Rethinking GNNs and Missing Features: Challenges, Evaluation and a Robust Solution](https://arxiv.org/abs/2601.04855)
*Francesco Ferrini,Veronica Lachi,Antonio Longa,Bruno Lepri,Matono Akiyoshi,Andrea Passerini,Xin Liu,Manfred Jaeger*

Main category: cs.LG

TL;DR: 该论文针对图神经网络处理缺失节点特征的问题，提出了新的评估方法和基线模型GNNmim，在更现实的缺失机制下进行性能比较。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要针对高维稀疏特征和完全随机缺失的良性场景，无法真实反映现实世界中的挑战。需要开发在密集特征和更现实缺失机制下的评估方法。

Method: 1) 引入具有密集语义特征的数据集；2) 设计超越MCAR的评估协议；3) 提出理论分析框架；4) 开发GNNmim基线模型

Result: 理论证明高稀疏性会限制信息损失，使所有模型显得鲁棒。GNNmim在不同数据集和缺失机制下与专用架构相比具有竞争力。

Conclusion: 论文为GNN处理缺失特征提供了更现实的评估框架，证明简单有效的GNNmim基线在多种场景下表现优异，为实际部署提供了实用解决方案。

Abstract: Handling missing node features is a key challenge for deploying Graph Neural Networks (GNNs) in real-world domains such as healthcare and sensor networks. Existing studies mostly address relatively benign scenarios, namely benchmark datasets with (a) high-dimensional but sparse node features and (b) incomplete data generated under Missing Completely At Random (MCAR) mechanisms. For (a), we theoretically prove that high sparsity substantially limits the information loss caused by missingness, making all models appear robust and preventing a meaningful comparison of their performance. To overcome this limitation, we introduce one synthetic and three real-world datasets with dense, semantically meaningful features. For (b), we move beyond MCAR and design evaluation protocols with more realistic missingness mechanisms. Moreover, we provide a theoretical background to state explicit assumptions on the missingness process and analyze their implications for different methods. Building on this analysis, we propose GNNmim, a simple yet effective baseline for node classification with incomplete feature data. Experiments show that GNNmim is competitive with respect to specialized architectures across diverse datasets and missingness regimes.

</details>


### [157] [FibreCastML: An Open Web Platform for Predicting Electrospun Nanofibre Diameter Distributions](https://arxiv.org/abs/2601.04873)
*Elisa Roldan,Kirstie Andrews,Stephen M. Richardson,Reyhaneh Fatahian,Glen Cooper,Rasool Erfani,Tasneem Sabir,Neil D. Reeves*

Main category: cs.LG

TL;DR: FibreCastML是一个基于机器学习的框架，能够预测电纺纤维的完整直径分布，而不仅仅是平均直径，从而更准确地优化电纺支架的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习方法主要预测电纺纤维的平均直径，忽略了完整的直径分布对支架性能的影响，因此需要开发一个能够预测完整分布并解释工艺-结构关系的框架。

Method: 通过收集来自1778项研究的68538个纤维直径测量数据，使用六个标准工艺参数训练了七种机器学习模型，并采用嵌套交叉验证和留一研究外部折叠的方法。模型的可解释性通过变量重要性分析、SHAP、相关矩阵和三维参数图实现。

Result: 非线性模型显著优于线性基线，多个广泛使用的聚合物的决定系数超过0.91。溶液浓度被确定为纤维直径分布的主要驱动因素。实验验证表明预测分布与实测分布高度一致。

Conclusion: FibreCastML能够实现更可重复和数据驱动的电纺支架结构优化，为组织工程、药物递送和伤口护理等应用提供更可靠的工艺优化工具。

Abstract: Electrospinning is a scalable technique for producing fibrous scaffolds with tunable micro- and nanoscale architectures for applications in tissue engineering, drug delivery, and wound care. While machine learning (ML) has been used to support electrospinning process optimisation, most existing approaches predict only mean fibre diameters, neglecting the full diameter distribution that governs scaffold performance. This work presents FibreCastML, an open, distribution-aware ML framework that predicts complete fibre diameter spectra from routinely reported electrospinning parameters and provides interpretable insights into process structure relationships.
  A meta-dataset comprising 68538 individual fibre diameter measurements extracted from 1778 studies across 16 biomedical polymers was curated. Six standard processing parameters, namely solution concentration, applied voltage, flow rate, tip to collector distance, needle diameter, and collector rotation speed, were used to train seven ML models using nested cross validation with leave one study out external folds. Model interpretability was achieved using variable importance analysis, SHapley Additive exPlanations, correlation matrices, and three dimensional parameter maps.
  Non linear models consistently outperformed linear baselines, achieving coefficients of determination above 0.91 for several widely used polymers. Solution concentration emerged as the dominant global driver of fibre diameter distributions. Experimental validation across different electrospinning systems demonstrated close agreement between predicted and measured distributions. FibreCastML enables more reproducible and data driven optimisation of electrospun scaffold architectures.

</details>


### [158] [Learnable Multipliers: Freeing the Scale of Language Model Matrix Layers](https://arxiv.org/abs/2601.04890)
*Maksim Velikanov,Ilyas Chahed,Jingwei Zuo,Dhia Eddine Rhaiem,Younes Belkada,Hakim Hacid*

Main category: cs.LG

TL;DR: 本文提出通过引入可学习的乘数来优化权重衰减（WD）与随机梯度噪声之间的平衡，从而提升大语言模型预训练的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的权重衰减与梯度噪声会导致权重矩阵的布朗式扩展，形成WD-noise平衡，但这种平衡下的权重范数可能不是最优的，限制了模型性能。

Method: 引入可学习的标量乘数、行乘数和列乘数，动态调整权重矩阵的尺度，使其适应数据分布，替代传统的固定乘数方法（如muP）。

Result: 该方法在Adam和Muon优化器上均有效，下游任务评估显示性能提升显著，且减少了乘数调优的计算开销。

Conclusion: 可学习乘数是一种更灵活、表达性更强的尺度调整方法，能够突破WD-noise平衡的限制，提升模型性能，并引发对前向传播对称性和乘数宽度缩放等实际问题的思考。

Abstract: Applying weight decay (WD) to matrix layers is standard practice in large-language-model pretraining. Prior work suggests that stochastic gradient noise induces a Brownian-like expansion of the weight matrices W, whose growth is counteracted by WD, leading to a WD-noise equilibrium with a certain weight norm ||W||. In this work, we view the equilibrium norm as a harmful artifact of the training procedure, and address it by introducing learnable multipliers to learn the optimal scale. First, we attach a learnable scalar multiplier to W and confirm that the WD-noise equilibrium norm is suboptimal: the learned scale adapts to data and improves performance. We then argue that individual row and column norms are similarly constrained, and free their scale by introducing learnable per-row and per-column multipliers. Our method can be viewed as a learnable, more expressive generalization of muP multipliers. It outperforms a well-tuned muP baseline, reduces the computational overhead of multiplier tuning, and surfaces practical questions such as forward-pass symmetries and the width-scaling of the learned multipliers. Finally, we validate learnable multipliers with both Adam and Muon optimizers, where it shows improvement in downstream evaluations matching the improvement of the switching from Adam to Muon.

</details>


### [159] [Distributed Online Convex Optimization with Efficient Communication: Improved Algorithm and Lower bounds](https://arxiv.org/abs/2601.04907)
*Sifan Yang,Wenhao Yang,Wei Jiang,Lijun Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种新的分布式在线凸优化算法，通过两级阻塞更新框架、在线gossip策略和误差补偿方案，显著改进了压缩通信下的遗憾界，并建立了该问题的首个下界。


<details>
  <summary>Details</summary>
Motivation: 现有分布式在线凸优化算法在压缩通信下存在对压缩质量因子ω的二次甚至四次依赖，以及对节点数n的超线性依赖，这些局限性影响了算法的效率和可扩展性。

Method: 提出两级阻塞更新框架，结合在线gossip策略和误差补偿方案，通过更好的学习者间共识实现性能提升。对于bandit反馈场景，还结合经典梯度估计器进行扩展。

Result: 新算法在凸函数下达到Õ(ω^{-1/2}ρ^{-1}n√T)的遗憾界，在强凸函数下达到Õ(ω^{-1}ρ^{-2}nlnT)的遗憾界，显著优于现有结果。

Conclusion: 所提算法在压缩通信的分布式在线凸优化中取得了理论上的突破，建立了最优的遗憾界，并通过下界分析验证了结果的紧致性。

Abstract: We investigate distributed online convex optimization with compressed communication, where $n$ learners connected by a network collaboratively minimize a sequence of global loss functions using only local information and compressed data from neighbors. Prior work has established regret bounds of $O(\max\{ω^{-2}ρ^{-4}n^{1/2},ω^{-4}ρ^{-8}\}n\sqrt{T})$ and $O(\max\{ω^{-2}ρ^{-4}n^{1/2},ω^{-4}ρ^{-8}\}n\ln{T})$ for convex and strongly convex functions, respectively, where $ω\in(0,1]$ is the compression quality factor ($ω=1$ means no compression) and $ρ<1$ is the spectral gap of the communication matrix. However, these regret bounds suffer from a \emph{quadratic} or even \emph{quartic} dependence on $ω^{-1}$. Moreover, the \emph{super-linear} dependence on $n$ is also undesirable. To overcome these limitations, we propose a novel algorithm that achieves improved regret bounds of $\tilde{O}(ω^{-1/2}ρ^{-1}n\sqrt{T})$ and $\tilde{O}(ω^{-1}ρ^{-2}n\ln{T})$ for convex and strongly convex functions, respectively. The primary idea is to design a \emph{two-level blocking update framework} incorporating two novel ingredients: an online gossip strategy and an error compensation scheme, which collaborate to \emph{achieve a better consensus} among learners. Furthermore, we establish the first lower bounds for this problem, justifying the optimality of our results with respect to both $ω$ and $T$. Additionally, we consider the bandit feedback scenario, and extend our method with the classic gradient estimators to enhance existing regret bounds.

</details>


### [160] [Cardinality augmented loss functions](https://arxiv.org/abs/2601.04941)
*Miguel O'Malley*

Main category: cs.LG

TL;DR: 本文提出了一种基于基数增强损失函数的方法来解决神经网络训练中的类别不平衡问题，通过引入数学中的magnitude和spread等基数不变性概念来评估度量空间的'有效多样性'，从而改善少数类别的分类性能。


<details>
  <summary>Details</summary>
Motivation: 类别不平衡是神经网络训练中普遍存在的问题，多数类别往往会主导训练过程，导致分类器性能偏向多数类别结果。为了解决这一问题，需要开发能够有效处理不平衡数据的方法。

Method: 提出了基数增强损失函数，该方法基于现代数学文献中的基数不变性概念（如magnitude和spread），这些概念通过评估度量空间的'有效多样性'来丰富基数的概念。建立了在神经网络训练中应用基数增强损失函数的方法论。

Result: 在人工不平衡数据集和现实世界的不平衡材料科学数据集上进行了实验，观察到少数类别的性能显著提升，同时整体性能指标也有所改善。

Conclusion: 基数增强损失函数是解决类别不平衡问题的有效方法，能够显著提升少数类别的分类性能，并在整体性能上取得改进。

Abstract: Class imbalance is a common and pernicious issue for the training of neural networks. Often, an imbalanced majority class can dominate training to skew classifier performance towards the majority outcome. To address this problem we introduce cardinality augmented loss functions, derived from cardinality-like invariants in modern mathematics literature such as magnitude and the spread. These invariants enrich the concept of cardinality by evaluating the `effective diversity' of a metric space, and as such represent a natural solution to overly homogeneous training data. In this work, we establish a methodology for applying cardinality augmented loss functions in the training of neural networks and report results on both artificially imbalanced datasets as well as a real-world imbalanced material science dataset. We observe significant performance improvement among minority classes, as well as improvement in overall performance metrics.

</details>


### [161] [Precision over Diversity: High-Precision Reward Generalizes to Robust Instruction Following](https://arxiv.org/abs/2601.04954)
*Yirong Zeng,Yufei Liu,Xiao Ding,Yutai Hou,Yuxian Wang,Haonan Song,Wu Ning,Dandan Tu,Qixun Zhang,Bibo Cai,Yuxiang He,Ting Liu*

Main category: cs.LG

TL;DR: 本文挑战了传统观点，发现仅使用硬约束训练的模型在指令跟随任务中表现优于混合约束训练，揭示奖励精度而非约束多样性是有效对齐的关键因素。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为多样化的可验证硬约束和不可验证软约束混合对于指令跟随任务的泛化至关重要，但本文通过实证研究质疑这一共识。

Method: 通过系统实证研究，分析奖励精度的影响，并提出以奖励精度为中心的数据精炼策略。

Result: 在五个基准测试中，该方法优于竞争基线13.4%，同时减少58%的训练时间，并保持强大的泛化能力。

Conclusion: 研究结果支持范式转变：从盲目追求数据多样性转向关注高精度奖励。

Abstract: A central belief in scaling reinforcement learning with verifiable rewards for instruction following (IF) tasks is that, a diverse mixture of verifiable hard and unverifiable soft constraints is essential for generalizing to unseen instructions. In this work, we challenge this prevailing consensus through a systematic empirical investigation. Counter-intuitively, we find that models trained on hard-only constraints consistently outperform those trained on mixed datasets. Extensive experiments reveal that reward precision, rather than constraint diversity, is the primary driver of effective alignment. The LLM judge suffers from a low recall rate in detecting false response, which leads to severe reward hacking, thereby undermining the benefits of diversity. Furthermore, analysis of the attention mechanism reveals that high-precision rewards develop a transferable meta-skill for IF. Motivated by these insights, we propose a simple yet effective data-centric refinement strategy that prioritizes reward precision. Evaluated on five benchmarks, our approach outperforms competitive baselines by 13.4\% in performance while achieving a 58\% reduction in training time, maintaining strong generalization beyond instruction following. Our findings advocate for a paradigm shift: moving away from the indiscriminate pursuit of data diversity toward high-precision rewards.

</details>


### [162] [On the Definition and Detection of Cherry-Picking in Counterfactual Explanations](https://arxiv.org/abs/2601.04977)
*James Hinns,Sofie Goethals,Stephan Van der Veeken,Theodoros Evgeniou,David Martens*

Main category: cs.LG

TL;DR: 该论文研究了反事实解释中可能存在的"樱桃采摘"问题，即解释提供者可以选择性地展示有利的反事实解释而隐藏不利的，并分析了这种操纵在实践中的检测局限性。


<details>
  <summary>Details</summary>
Motivation: 反事实解释被广泛用于说明输入如何改变才能改变模型预测，但存在多个有效反事实的可能性使得解释提供者可能选择性展示有利解释，这引发了公平性和透明性的担忧。

Method: 通过定义可接受解释空间和效用函数来形式化樱桃采摘问题，并在三种访问级别（完全程序访问、部分程序访问、仅解释访问）下研究检测可能性，同时进行实证分析比较樱桃采摘解释与基线解释的质量指标差异。

Result: 研究发现即使有完全程序访问权限，樱桃采摘的解释也往往难以与正常解释区分，因为有效反事实的多样性和解释规范的灵活性为掩盖选择性提供了足够自由度。实证表明这种变异性通常超过樱桃采摘对标准质量指标的影响。

Conclusion: 应该优先考虑可重复性、标准化和程序约束而不是事后检测，并为算法开发者、解释提供者和审计者提供相应建议。

Abstract: Counterfactual explanations are widely used to communicate how inputs must change for a model to alter its prediction. For a single instance, many valid counterfactuals can exist, which leaves open the possibility for an explanation provider to cherry-pick explanations that better suit a narrative of their choice, highlighting favourable behaviour and withholding examples that reveal problematic behaviour. We formally define cherry-picking for counterfactual explanations in terms of an admissible explanation space, specified by the generation procedure, and a utility function. We then study to what extent an external auditor can detect such manipulation. Considering three levels of access to the explanation process: full procedural access, partial procedural access, and explanation-only access, we show that detection is extremely limited in practice. Even with full procedural access, cherry-picked explanations can remain difficult to distinguish from non cherry-picked explanations, because the multiplicity of valid counterfactuals and flexibility in the explanation specification provide sufficient degrees of freedom to mask deliberate selection. Empirically, we demonstrate that this variability often exceeds the effect of cherry-picking on standard counterfactual quality metrics such as proximity, plausibility, and sparsity, making cherry-picked explanations statistically indistinguishable from baseline explanations. We argue that safeguards should therefore prioritise reproducibility, standardisation, and procedural constraints over post-hoc detection, and we provide recommendations for algorithm developers, explanation providers, and auditors.

</details>


### [163] [On the Hidden Objective Biases of Group-based Reinforcement Learning](https://arxiv.org/abs/2601.05002)
*Aleksandar Fontana,Marco Simoni,Giulio Rossolini,Andrea Saracino,Paolo Mori*

Main category: cs.LG

TL;DR: 本文对GRPO等基于群体的强化学习方法进行了理论分析，揭示了其奖励优化与训练目标之间的结构不匹配问题，并指出了梯度偏差、优化器敏感性和动量影响等系统性缺陷。


<details>
  <summary>Details</summary>
Motivation: 尽管GRPO等基于群体的强化学习方法在实证中取得了成功，但其奖励优化与底层训练目标之间存在结构不匹配，需要从理论上分析这些方法的根本局限性。

Method: 通过将GRPO风格方法置于统一的代理公式中进行研究，分析其训练动态和优化器交互作用。

Result: 发现了三个关键问题：(i)非均匀群体加权导致共享前缀令牌的系统性梯度偏差；(ii)与AdamW优化器的交互使训练动态对奖励缩放不敏感；(iii)优化器动量在重复优化步骤下可能使策略更新超出预期的裁剪区域。

Conclusion: 这些发现揭示了当前方法的根本局限性，为未来公式设计提供了原则性指导。

Abstract: Group-based reinforcement learning methods, like Group Relative Policy Optimization (GRPO), are widely used nowadays to post-train large language models. Despite their empirical success, they exhibit structural mismatches between reward optimization and the underlying training objective. In this paper, we present a theoretical analysis of GRPO style methods by studying them within a unified surrogate formulation. This perspective reveals recurring properties that affect all the methods under analysis: (i) non-uniform group weighting induces systematic gradient biases on shared prefix tokens; (ii) interactions with the AdamW optimizer make training dynamics largely insensitive to reward scaling; and (iii) optimizer momentum can push policy updates beyond the intended clipping region under repeated optimization steps. We believe that these findings highlight fundamental limitations of current approaches and provide principled guidance for the design of future formulations.

</details>


### [164] [HMVI: Unifying Heterogeneous Attributes with Natural Neighbors for Missing Value Inference](https://arxiv.org/abs/2601.05017)
*Xiaopeng Luo,Zexi Tan,Zhuowei Wang*

Main category: cs.LG

TL;DR: 提出一种新颖的缺失值填补方法，通过统一框架显式建模异质特征间的跨类型依赖关系，在表格数据中实现准确一致的填补。


<details>
  <summary>Details</summary>
Motivation: 当前填补方法通常独立处理数值和分类属性，忽略了异质特征间的重要相互依赖关系，这限制了填补的准确性。

Method: 在统一框架中显式建模跨类型特征依赖，同时利用完整和不完整实例来确保表格数据中填补的准确性和一致性。

Result: 大量实验结果表明，该方法在性能上优于现有技术，并能显著提升下游机器学习任务的效果。

Conclusion: 该方法为现实世界中存在缺失数据的系统提供了一个稳健的解决方案。

Abstract: Missing value imputation is a fundamental challenge in machine intelligence, heavily dependent on data completeness. Current imputation methods often handle numerical and categorical attributes independently, overlooking critical interdependencies among heterogeneous features. To address these limitations, we propose a novel imputation approach that explicitly models cross-type feature dependencies within a unified framework. Our method leverages both complete and incomplete instances to ensure accurate and consistent imputation in tabular data. Extensive experimental results demonstrate that the proposed approach achieves superior performance over existing techniques and significantly enhances downstream machine learning tasks, providing a robust solution for real-world systems with missing data.

</details>


### [165] [Approximate equivariance via projection-based regularisation](https://arxiv.org/abs/2601.05028)
*Torben Berndt,Jan Stühmer*

Main category: cs.LG

TL;DR: 本文提出了一种基于投影的正则化方法来实现近似等变性，通过线性层的正交分解来惩罚非等变性，相比基于样本的方法具有更高的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 等变性是神经网络中的重要归纳偏置，但现实中存在不完美的对称性，需要近似等变模型来平衡对称性和数据拟合。现有方法依赖数据增强，样本复杂度高，特别是对于连续群如SO(3)。

Method: 使用投影基的正则化器，利用线性层到等变和非等变分量的正交分解，在算子级别惩罚非等变性，而不是逐点惩罚。提供了在空间和谱域中精确高效计算非等变性惩罚的数学框架。

Result: 实验表明，该方法在模型性能和效率上均优于先前的近似等变性方法，相比基于样本的正则化器实现了显著的运行时增益。

Conclusion: 投影基正则化方法为近似等变性提供了一种高效且有效的解决方案，特别适用于连续对称群。

Abstract: Equivariance is a powerful inductive bias in neural networks, improving generalisation and physical consistency. Recently, however, non-equivariant models have regained attention, due to their better runtime performance and imperfect symmetries that might arise in real-world applications. This has motivated the development of approximately equivariant models that strike a middle ground between respecting symmetries and fitting the data distribution. Existing approaches in this field usually apply sample-based regularisers which depend on data augmentation at training time, incurring a high sample complexity, in particular for continuous groups such as $SO(3)$. This work instead approaches approximate equivariance via a projection-based regulariser which leverages the orthogonal decomposition of linear layers into equivariant and non-equivariant components. In contrast to existing methods, this penalises non-equivariance at an operator level across the full group orbit, rather than point-wise. We present a mathematical framework for computing the non-equivariance penalty exactly and efficiently in both the spatial and spectral domain. In our experiments, our method consistently outperforms prior approximate equivariance approaches in both model performance and efficiency, achieving substantial runtime gains over sample-based regularisers.

</details>


### [166] [A Data-Driven Predictive Framework for Inventory Optimization Using Context-Augmented Machine Learning Models](https://arxiv.org/abs/2601.05033)
*Anees Fatima,Mohammad Abdus Salam*

Main category: cs.LG

TL;DR: 本研究探讨了机器学习算法在零售和自动售货机行业需求预测中的应用，比较了XGBoost、ARIMA、Facebook Prophet和SVR四种模型，发现XGBoost在纳入外部因素后表现最佳。


<details>
  <summary>Details</summary>
Motivation: 传统供应链管理中的需求预测方法经常忽略天气、节假日和设备故障等外部因素，导致效率低下。本研究旨在通过机器学习算法提高需求预测的准确性。

Method: 使用四种机器学习算法（XGBoost、ARIMA、Facebook Prophet、SVR）进行库存需求预测，并系统性地纳入工作日、节假日和销售偏差指标等外部因素。

Result: XGBoost在纳入外部变量后达到最低平均绝对误差（MAE）22.7，表现最佳。ARIMAX和Facebook Prophet也有显著改进，而SVR表现较差。

Conclusion: 纳入外部因素能显著提高需求预测模型的准确性，XGBoost被确定为最有效的算法。本研究为优化零售和自动售货机系统的库存管理提供了有力框架。

Abstract: Demand forecasting in supply chain management (SCM) is critical for optimizing inventory, reducing waste, and improving customer satisfaction. Conventional approaches frequently neglect external influences like weather, festivities, and equipment breakdowns, resulting in inefficiencies. This research investigates the use of machine learning (ML) algorithms to improve demand prediction in retail and vending machine sectors. Four machine learning algorithms. Extreme Gradient Boosting (XGBoost), Autoregressive Integrated Moving Average (ARIMA), Facebook Prophet (Fb Prophet), and Support Vector Regression (SVR) were used to forecast inventory requirements. Ex-ternal factors like weekdays, holidays, and sales deviation indicators were methodically incorporated to enhance precision. XGBoost surpassed other models, reaching the lowest Mean Absolute Error (MAE) of 22.7 with the inclusion of external variables. ARIMAX and Fb Prophet demonstrated noteworthy enhancements, whereas SVR fell short in performance. Incorporating external factors greatly improves the precision of demand forecasting models, and XGBoost is identified as the most efficient algorithm. This study offers a strong framework for enhancing inventory management in retail and vending machine systems.

</details>


### [167] [DeepWeightFlow: Re-Basined Flow Matching for Generating Neural Network Weights](https://arxiv.org/abs/2601.05052)
*Saumya Gupta,Scott Biggs,Moritz Laber,Zohair Shafi,Robin Walters,Ayan Paul*

Main category: cs.LG

TL;DR: DeepWeightFlow是一个基于流匹配的生成模型，直接在权重空间中生成多样化且高精度的神经网络权重，支持多种架构和规模，无需微调即可获得良好性能。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型面临高维权重空间和对称性的挑战，要么只能生成部分权重，要么生成速度慢或需要微调，无法有效支持大型神经网络。

Method: 采用流匹配模型直接在权重空间生成，结合Git Re-Basin和TransFusion进行神经网络规范化处理，以应对排列对称性问题并提高大规模模型的生成效率。

Result: 生成的神经网络在迁移学习方面表现优异，数百个神经网络的集成可以在几分钟内完成，远超基于扩散的方法的效率。

Conclusion: DeepWeightFlow为高效、可扩展地生成多样化神经网络集合开辟了新途径。

Abstract: Building efficient and effective generative models for neural network weights has been a research focus of significant interest that faces challenges posed by the high-dimensional weight spaces of modern neural networks and their symmetries. Several prior generative models are limited to generating partial neural network weights, particularly for larger models, such as ResNet and ViT. Those that do generate complete weights struggle with generation speed or require finetuning of the generated models. In this work, we present DeepWeightFlow, a Flow Matching model that operates directly in weight space to generate diverse and high-accuracy neural network weights for a variety of architectures, neural network sizes, and data modalities. The neural networks generated by DeepWeightFlow do not require fine-tuning to perform well and can scale to large networks. We apply Git Re-Basin and TransFusion for neural network canonicalization in the context of generative weight models to account for the impact of neural network permutation symmetries and to improve generation efficiency for larger model sizes. The generated networks excel at transfer learning, and ensembles of hundreds of neural networks can be generated in minutes, far exceeding the efficiency of diffusion-based methods. DeepWeightFlow models pave the way for more efficient and scalable generation of diverse sets of neural networks.

</details>


### [168] [Milestones over Outcome: Unlocking Geometric Reasoning with Sub-Goal Verifiable Reward](https://arxiv.org/abs/2601.05073)
*Jianlong Chen,Daocheng Fu,Shengze Xu,Jiawei Chen,Yuan Feng,Yue Yang,Junchi Yan,Hongyuan Zha,Renqiu Xia*

Main category: cs.LG

TL;DR: 论文提出了一种新的子目标级评估和学习范式，通过GeoGoal基准和SGVR框架解决MLLMs在复杂几何推理中的问题，用密集的骨架率奖励替代稀疏信号，显著提升了几何推理性能并展现出良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在复杂几何推理中存在困难，主要因为基于结果的"黑箱"监督无法区分幸运猜测和严谨推理。需要转向子目标级评估来揭示推理质量与结果准确性之间的关键差异。

Method: 1) 构建GeoGoal基准：通过形式化验证数据引擎将抽象证明转化为可验证的数值子目标；2) 提出SGVR框架：基于骨架率提供密集奖励信号替代稀疏监督。

Result: SGVR框架显著提升了几何推理性能（+9.7%），并在一般数学推理（+8.0%）和其他通用推理任务（+2.8%）上展现出强泛化能力。

Conclusion: 子目标级验证方法不仅能有效提升几何推理性能，还具有广泛的领域适用性，为解决MLLMs的推理能力提供了新的有效途径。

Abstract: Multimodal Large Language Models (MLLMs) struggle with complex geometric reasoning, largely because "black box" outcome-based supervision fails to distinguish between lucky guesses and rigorous deduction. To address this, we introduce a paradigm shift towards subgoal-level evaluation and learning. We first construct GeoGoal, a benchmark synthesized via a rigorous formal verification data engine, which converts abstract proofs into verifiable numeric subgoals. This structure reveals a critical divergence between reasoning quality and outcome accuracy. Leveraging this, we propose the Sub-Goal Verifiable Reward (SGVR) framework, which replaces sparse signals with dense rewards based on the Skeleton Rate. Experiments demonstrate that SGVR not only enhances geometric performance (+9.7%) but also exhibits strong generalization, transferring gains to general math (+8.0%) and other general reasoning tasks (+2.8%), demonstrating broad applicability across diverse domains.

</details>


### [169] [Exploring Student Expectations and Confidence in Learning Analytics](https://arxiv.org/abs/2601.05082)
*Hayk Asatryan,Basile Tousside,Janis Mohr,Malte Neugebauer,Hildo Bijl,Paul Spiegelberg,Claudia Frohn-Schauf,Jörg Frochte*

Main category: cs.LG

TL;DR: 本文使用SELAQ问卷分析不同院系学生对学习分析数据处理的期望和信心，通过聚类算法识别出四类学生群体：热情者、现实主义者、谨慎者和冷漠者。


<details>
  <summary>Details</summary>
Motivation: 随着学习分析在教育系统中的广泛应用和数据隐私法规的日益严格，需要了解学生对学习分析数据处理的期望和态度。

Method: 采用学生学习分析期望问卷（SELAQ）对不同院系学生进行调查，并使用聚类算法对数据进行分析。

Result: 识别出四个学生群体：热情者（积极支持）、现实主义者（理性看待）、谨慎者（持保留态度）和冷漠者（不关心）。

Conclusion: 该结构化分析为理解学生对学习分析的接受度和批评提供了有价值的见解，有助于优化学习分析的实施策略。

Abstract: Learning Analytics (LA) is nowadays ubiquitous in many educational systems, providing the ability to collect and analyze student data in order to understand and optimize learning and the environments in which it occurs. On the other hand, the collection of data requires to comply with the growing demand regarding privacy legislation. In this paper, we use the Student Expectation of Learning Analytics Questionnaire (SELAQ) to analyze the expectations and confidence of students from different faculties regarding the processing of their data for Learning Analytics purposes. This allows us to identify four clusters of students through clustering algorithms: Enthusiasts, Realists, Cautious and Indifferents. This structured analysis provides valuable insights into the acceptance and criticism of Learning Analytics among students.

</details>


### [170] [Sequential Subspace Noise Injection Prevents Accuracy Collapse in Certified Unlearning](https://arxiv.org/abs/2601.05134)
*Polina Dolgova,Sebastian U. Stich*

Main category: cs.LG

TL;DR: 本文提出了一种称为顺序噪声调度的新方法，通过在参数空间的正交子空间中分布噪声预算，显著提高了基于差分隐私的认证遗忘方法的实用性，在保持相同隐私保证的同时大幅提升了模型精度。


<details>
  <summary>Details</summary>
Motivation: 现有的基于差分隐私的认证遗忘方法虽然提供强保证，但严重降低模型精度，缺乏实用性。需要一种既能保持严格隐私保证又能维持实用性能的解决方案。

Method: 提出顺序噪声调度方法，将噪声预算分布在参数空间的正交子空间中，而不是一次性注入所有噪声。扩展了噪声微调的子空间分析，证明可以保持相同的(ε,δ)隐私预算。

Result: 在图像分类基准测试中，该方法在遗忘后显著提高了模型精度，同时保持对成员推理攻击的鲁棒性。验证了认证遗忘既能实现严格保证又能保持实用性的可行性。

Conclusion: 顺序噪声调度方法证明了认证遗忘可以同时实现严格的理论保证和实际效用，为实用化的隐私保护机器学习提供了可行的技术路径。

Abstract: Certified unlearning based on differential privacy offers strong guarantees but remains largely impractical: the noisy fine-tuning approaches proposed so far achieve these guarantees but severely reduce model accuracy. We propose sequential noise scheduling, which distributes the noise budget across orthogonal subspaces of the parameter space, rather than injecting it all at once. This simple modification mitigates the destructive effect of noise while preserving the original certification guarantees. We extend the analysis of noisy fine-tuning to the subspace setting, proving that the same $(\varepsilon,δ)$ privacy budget is retained. Empirical results on image classification benchmarks show that our approach substantially improves accuracy after unlearning while remaining robust to membership inference attacks. These results show that certified unlearning can achieve both rigorous guarantees and practical utility.

</details>


### [171] [Safe Continual Reinforcement Learning Methods for Nonstationary Environments. Towards a Survey of the State of the Art](https://arxiv.org/abs/2601.05152)
*Timofey Tomashevskiy*

Main category: cs.LG

TL;DR: 这篇论文提供了持续安全在线强化学习（COSRL）方法的最新综述，讨论了构建持续在线安全强化学习算法的理论方面、挑战和开放性问题，并基于考虑非平稳性适应的安全学习机制类型对方法进行了分类。


<details>
  <summary>Details</summary>
Motivation: 动机是系统地总结和分析持续在线安全强化学习领域的最新进展，为构建可靠、安全的在线学习算法提供理论指导和方法分类。

Method: 方法包括：1）提供基于安全学习机制类型的分类法；2）对在线强化学习算法的安全约束制定进行归类；3）分析适应非平稳性的不同方法。

Result: 结果包括：建立了持续在线安全强化学习的系统分类框架，识别了关键挑战和开放性问题，并为未来研究方向提供了展望。

Conclusion: 结论是持续安全在线强化学习是一个重要且有挑战性的研究领域，需要进一步发展可靠的安全约束制定方法和适应非平稳环境的有效算法。

Abstract: This work provides a state-of-the-art survey of continual safe online reinforcement learning (COSRL) methods. We discuss theoretical aspects, challenges, and open questions in building continual online safe reinforcement learning algorithms. We provide the taxonomy and the details of continual online safe reinforcement learning methods based on the type of safe learning mechanism that takes adaptation to nonstationarity into account. We categorize safety constraints formulation for online reinforcement learning algorithms, and finally, we discuss prospects for creating reliable, safe online learning algorithms.
  Keywords: safe RL in nonstationary environments, safe continual reinforcement learning under nonstationarity, HM-MDP, NSMDP, POMDP, safe POMDP, constraints for continual learning, safe continual reinforcement learning review, safe continual reinforcement learning survey, safe continual reinforcement learning, safe online learning under distribution shift, safe continual online adaptation, safe reinforcement learning, safe exploration, safe adaptation, constrained Markov decision processes, safe reinforcement learning, partially observable Markov decision process, safe reinforcement learning and hidden Markov decision processes, Safe Online Reinforcement Learning, safe online reinforcement learning, safe online reinforcement learning, safe meta-learning, safe meta-reinforcement learning, safe context-based reinforcement learning, formulating safety constraints for continual learning

</details>


### [172] [FaST: Efficient and Effective Long-Horizon Forecasting for Large-Scale Spatial-Temporal Graphs via Mixture-of-Experts](https://arxiv.org/abs/2601.05174)
*Yiji Zhao,Zihao Zhong,Ao Wang,Haomin Wen,Ming Jin,Yuxuan Liang,Huaiyu Wan,Hao Wu*

Main category: cs.LG

TL;DR: FaST是一个基于异构感知专家混合模型的高效时空图预测框架，专注于大规模网络上的长期预测，能够实现一周前（672步）的预测，并显著降低计算成本和内存消耗。


<details>
  <summary>Details</summary>
Motivation: 现有时空图预测模型主要关注短期预测，且在扩展到长期预测和大规模图时面临高昂的计算成本和内存消耗问题。

Method: 提出自适应图代理注意力机制减轻大规模图上的计算负担，并设计新的并行MoE模块，用门控线性单元替代传统前馈网络，实现高效可扩展的并行结构。

Result: 在真实世界数据集上的实验表明，FaST不仅提供优越的长期预测准确性，而且在计算效率方面显著优于现有最先进基线方法。

Conclusion: FaST框架成功解决了大规模时空图长期预测的计算挑战，为实际应用提供了可行的解决方案。

Abstract: Spatial-Temporal Graph (STG) forecasting on large-scale networks has garnered significant attention. However, existing models predominantly focus on short-horizon predictions and suffer from notorious computational costs and memory consumption when scaling to long-horizon predictions and large graphs. Targeting the above challenges, we present FaST, an effective and efficient framework based on heterogeneity-aware Mixture-of-Experts (MoEs) for long-horizon and large-scale STG forecasting, which unlocks one-week-ahead (672 steps at a 15-minute granularity) prediction with thousands of nodes. FaST is underpinned by two key innovations. First, an adaptive graph agent attention mechanism is proposed to alleviate the computational burden inherent in conventional graph convolution and self-attention modules when applied to large-scale graphs. Second, we propose a new parallel MoE module that replaces traditional feed-forward networks with Gated Linear Units (GLUs), enabling an efficient and scalable parallel structure. Extensive experiments on real-world datasets demonstrate that FaST not only delivers superior long-horizon predictive accuracy but also achieves remarkable computational efficiency compared to state-of-the-art baselines. Our source code is available at: https://github.com/yijizhao/FaST.

</details>


### [173] [An interpretable data-driven approach to optimizing clinical fall risk assessment](https://arxiv.org/abs/2601.05194)
*Fardin Ganjkhanloo,Emmett Springer,Erik H. Hoyer,Daniel L. Young,Holley Farley,Kimia Ghobadi*

Main category: cs.LG

TL;DR: 本研究通过数据驱动建模方法优化约翰霍普金斯跌倒风险评估工具(JHFRAT)，在保持工具可解释性的同时显著提升预测性能，为医院跌倒预防提供更有效的风险评估方案。


<details>
  <summary>Details</summary>
Motivation: 现有JHFRAT工具的预测性能有待提升，需要更好地将跌倒风险预测与临床有意义的指标对齐，同时保持工具的临床可解释性和部署便利性。

Method: 采用约束评分优化(CSO)模型对JHFRAT评分权重进行重新加权，保留其加法结构和临床阈值，基于54,209例住院患者数据进行回顾性队列分析。

Result: CSO模型相比原JHFRAT显著提升预测性能(AUC-ROC从0.86提升至0.91)，相当于每周多保护35名高风险患者，且对风险标签变化表现出更强鲁棒性。

Conclusion: 这种基于证据的方法为医疗系统提供了使用数据驱动优化技术系统性增强住院患者跌倒预防方案的坚实基础，有助于改善风险评估和资源分配。

Abstract: In this study, we aim to better align fall risk prediction from the Johns Hopkins Fall Risk Assessment Tool (JHFRAT) with additional clinically meaningful measures via a data-driven modelling approach. We conducted a retrospective cohort analysis of 54,209 inpatient admissions from three Johns Hopkins Health System hospitals between March 2022 and October 2023. A total of 20,208 admissions were included as high fall risk encounters, and 13,941 were included as low fall risk encounters. To incorporate clinical knowledge and maintain interpretability, we employed constrained score optimization (CSO) models to reweight the JHFRAT scoring weights, while preserving its additive structure and clinical thresholds. Recalibration refers to adjusting item weights so that the resulting score can order encounters more consistently by the study's risk labels, and without changing the tool's form factor or deployment workflow. The model demonstrated significant improvements in predictive performance over the current JHFRAT (CSO AUC-ROC=0.91, JHFRAT AUC-ROC=0.86). This performance improvement translates to protecting an additional 35 high-risk patients per week across the Johns Hopkins Health System. The constrained score optimization models performed similarly with and without the EHR variables. Although the benchmark black-box model (XGBoost), improves upon the performance metrics of the knowledge-based constrained logistic regression (AUC-ROC=0.94), the CSO demonstrates more robustness to variations in risk labeling. This evidence-based approach provides a robust foundation for health systems to systematically enhance inpatient fall prevention protocols and patient safety using data-driven optimization techniques, contributing to improved risk assessment and resource allocation in healthcare settings.

</details>


### [174] [EARL: Energy-Aware Optimization of Liquid State Machines for Pervasive AI](https://arxiv.org/abs/2601.05205)
*Zain Iqbal,Lorenzo Valerio*

Main category: cs.LG

TL;DR: EARL是一个能量感知的强化学习框架，通过贝叶斯优化和自适应强化学习选择策略联合优化准确性和能耗，显著提升液态状态机在资源受限设备上的效率。


<details>
  <summary>Details</summary>
Motivation: 解决液态状态机在部署中面临的高超参数敏感性和传统优化方法忽略能量约束的问题，满足低功耗时序处理在普及AI和神经形态系统中的需求。

Method: 结合贝叶斯优化的代理模型进行全局探索，使用强化学习进行动态候选优先级排序，并采用早期终止机制消除冗余评估，大幅降低计算开销。

Result: 在三个基准数据集上，EARL相比领先的超参数调优框架实现了6-15%的准确率提升、60-80%的能耗降低，以及高达一个数量级的优化时间减少。

Conclusion: 能量感知自适应搜索能有效提高液态状态机在资源受限设备AI应用中的效率和可扩展性。

Abstract: Pervasive AI increasingly depends on on-device learning systems that deliver low-latency and energy-efficient computation under strict resource constraints. Liquid State Machines (LSMs) offer a promising approach for low-power temporal processing in pervasive and neuromorphic systems, but their deployment remains challenging due to high hyperparameter sensitivity and the computational cost of traditional optimization methods that ignore energy constraints. This work presents EARL, an energy-aware reinforcement learning framework that integrates Bayesian optimization with an adaptive reinforcement learning based selection policy to jointly optimize accuracy and energy consumption. EARL employs surrogate modeling for global exploration, reinforcement learning for dynamic candidate prioritization, and an early termination mechanism to eliminate redundant evaluations, substantially reducing computational overhead. Experiments on three benchmark datasets demonstrate that EARL achieves 6 to 15 percent higher accuracy, 60 to 80 percent lower energy consumption, and up to an order of magnitude reduction in optimization time compared to leading hyperparameter tuning frameworks. These results highlight the effectiveness of energy-aware adaptive search in improving the efficiency and scalability of LSMs for resource-constrained on-device AI applications.

</details>


### [175] [Robust Reasoning as a Symmetry-Protected Topological Phase](https://arxiv.org/abs/2601.05240)
*Ilmo Sung*

Main category: cs.LG

TL;DR: 该论文提出将鲁棒推理建模为对称性保护拓扑相，通过非阿贝尔规范对称性实现逻辑操作的拓扑保护，从而解决大语言模型中的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型存在由语义噪声引起的"幻觉"问题，当前架构在"度量相"中运行，因果顺序容易受到自发对称性破缺的影响，需要寻找更鲁棒的推理机制。

Method: 提出全纯网络，将逻辑操作形式化为非阿贝尔任意子编织，用拓扑不变量替代脆弱的几何插值，通过非阿贝尔规范对称性实现拓扑保护。

Result: 实验显示拓扑相变：Transformer和RNN表现无间隙衰减，而全纯网络展现出宏观"质量间隙"，在临界噪声阈值下保持不变的保真度。在S10符号操作任务中，拓扑模型在训练范围外100倍（L=50→5000）仍保持完美保真度，而Transformer失去逻辑一致性。

Conclusion: 这为逻辑推理提供了一个新的普适性类别，将因果稳定性与语义流形的拓扑结构联系起来，证明了非阿贝尔规范对称性在保护逻辑推理中的关键作用。

Abstract: Large language models suffer from "hallucinations"-logical inconsistencies induced by semantic noise. We propose that current architectures operate in a "Metric Phase," where causal order is vulnerable to spontaneous symmetry breaking. Here, we identify robust inference as an effective Symmetry-Protected Topological phase, where logical operations are formally isomorphic to non-Abelian anyon braiding, replacing fragile geometric interpolation with robust topological invariants. Empirically, we demonstrate a sharp topological phase transition: while Transformers and RNNs exhibit gapless decay, our Holonomic Network reveals a macroscopic "mass gap," maintaining invariant fidelity below a critical noise threshold. Furthermore, in a variable-binding task on $S_{10}$ ($3.6 \times 10^6$ states) representing symbolic manipulation, we demonstrate holonomic generalization: the topological model maintains perfect fidelity extrapolating $100\times$ beyond training ($L=50 \to 5000$), consistent with a theoretically indefinite causal horizon, whereas Transformers lose logical coherence. Ablation studies indicate this protection emerges strictly from non-Abelian gauge symmetry. This provides strong evidence for a new universality class for logical reasoning, linking causal stability to the topology of the semantic manifold.

</details>


### [176] [Optimal Lower Bounds for Online Multicalibration](https://arxiv.org/abs/2601.05245)
*Natalie Collina,Jiuyao Lu,Georgy Noarov,Aaron Roth*

Main category: cs.LG

TL;DR: 本文证明了在线多校准的紧下界，建立了与边际校准的信息论分离。在一般设置下，使用三个不相交的二元组证明了Ω(T^{2/3})的多校准误差下界；在组函数仅依赖上下文的情况下，通过正交函数系统构造了Θ(T)大小的组族，建立了Ω̃(T^{2/3})下界。


<details>
  <summary>Details</summary>
Motivation: 研究在线多校准问题的基本复杂度界限，明确多校准与边际校准在计算复杂度上的差异，为算法设计提供理论指导。

Method: 采用信息论方法构造下界证明，通过设计特定的组函数和预测序列来展示多校准误差的最小可能增长率。在第二种情况下使用正交函数系统构造组族。

Result: 1. 一般设置下：Ω(T^{2/3})下界，匹配Noarov等人的上界
2. 仅依赖上下文的组函数：Ω̃(T^{2/3})下界，匹配现有上界
3. 证明了多校准比边际校准更困难（O(T^{2/3-ε}) vs Ω(T^{2/3}))

Conclusion: 多校准问题本质上比边际校准更困难，存在信息论上的分离。本文建立的下界是紧的，为在线多校准算法的最优性能提供了理论基准。

Abstract: We prove tight lower bounds for online multicalibration, establishing an information-theoretic separation from marginal calibration.
  In the general setting where group functions can depend on both context and the learner's predictions, we prove an $Ω(T^{2/3})$ lower bound on expected multicalibration error using just three disjoint binary groups. This matches the upper bounds of Noarov et al. (2025) up to logarithmic factors and exceeds the $O(T^{2/3-\varepsilon})$ upper bound for marginal calibration (Dagan et al., 2025), thereby separating the two problems.
  We then turn to lower bounds for the more difficult case of group functions that may depend on context but not on the learner's predictions. In this case, we establish an $\widetildeΩ(T^{2/3})$ lower bound for online multicalibration via a $Θ(T)$-sized group family constructed using orthogonal function systems, again matching upper bounds up to logarithmic factors.

</details>
