<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 56]
- [cs.LG](#cs.LG) [Total: 51]
- [cs.RO](#cs.RO) [Total: 10]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Bi-Orthogonal Factor Decomposition for Vision Transformers](https://arxiv.org/abs/2601.05328)
*Fenil R. Doshi,Thomas Fel,Talia Konkle,George Alvarez*

Main category: cs.CV

TL;DR: 本文提出了双正交因子分解（BFD）框架，用于系统分析Vision Transformer中注意力机制如何交换位置和内容信息。研究发现注意力主要通过内容交互，DINOv2模型在位置-内容耦合方面表现更优，并揭示了注意力头的专业化分工。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏对Vision Transformer注意力机制中token间信息交换原理的系统理解，特别是位置和内容信息如何通过注意力进行传递。

Method: 提出双正交因子分解（BFD）框架：第一阶段通过ANOVA分解将token激活统计解耦为位置和内容因子；第二阶段通过SVD分析query-key交互矩阵，揭示这些因子如何介导通信。

Result: 发现注意力主要通过内容交互，DINOv2在内容-位置耦合上分配更多能量；注意力头专业化分为内容-内容、内容-位置和位置-位置操作器；DINOv2的优异形状处理能力源于中间层同时保持位置结构和语义内容。

Conclusion: BFD框架揭示了注意力机制中token通过位置和语义因子进行交互的具体方式，为理解视觉Transformer机制提供了实用见解。

Abstract: Self-attention is the central computational primitive of Vision Transformers, yet we lack a principled understanding of what information attention mechanisms exchange between tokens. Attention maps describe where weight mass concentrates; they do not reveal whether queries and keys trade position, content, or both. We introduce Bi-orthogonal Factor Decomposition (BFD), a two-stage analytical framework: first, an ANOVA-based decomposition statistically disentangles token activations into orthogonal positional and content factors; second, SVD of the query-key interaction matrix QK^T exposes bi-orthogonal modes that reveal how these factors mediate communication. After validating proper isolation of position and content, we apply BFD to state-of-the-art vision models and uncover three phenomena.(i) Attention operates primarily through content. Content-content interactions dominate attention energy, followed by content-position coupling. DINOv2 allocates more energy to content-position than supervised models and distributes computation across a richer mode spectrum. (ii) Attention mechanisms exhibit specialization: heads differentiate into content-content, content-position, and position-position operators, while singular modes within heads show analogous specialization. (iii) DINOv2's superior holistic shape processing emerges from intermediate layers that simultaneously preserve positional structure while contextually enriching semantic content.
  Overall, BFD exposes how tokens interact through attention and which informational factors - positional or semantic - mediate their communication, yielding practical insights into vision transformer mechanisms.

</details>


### [2] [Coding the Visual World: From Image to Simulation Using Vision Language Models](https://arxiv.org/abs/2601.05344)
*Sagi Eppel*

Main category: cs.CV

TL;DR: 本文提出Im2Sim方法，探索视觉语言模型（VLMs）通过生成代码来模拟图像中复杂系统的能力。研究发现VLMs在高层系统理解上表现优异，但在细节复制方面存在局限。


<details>
  <summary>Details</summary>
Motivation: 研究视觉理解的核心是构建对图像中系统的代表性模型。本文旨在测试VLMs是否能够识别和模拟图像中描绘的各种复杂系统。

Method: 使用Im2Sim方法：让VLM分析真实世界系统的自然图像，描述系统并编写生成代码，执行代码产生合成图像，然后与原图进行比较。测试范围包括物理系统、植被、城市、材料和地质构造等。

Result: 领先的VLM（GPT、Gemini）展现出理解和建模复杂多组件系统的能力，涵盖多个抽象层次和广泛领域。但VLM在复制精细细节和低层模式排列方面能力有限。

Conclusion: VLMs表现出有趣的不对称性：结合了高层深度视觉理解能力与有限的细节感知能力，揭示了其在系统建模方面的潜力和局限性。

Abstract: The ability to construct mental models of the world is a central aspect of understanding. Similarly, visual understanding can be viewed as the ability to construct a representative model of the system depicted in an image. This work explores the capacity of Vision Language Models (VLMs) to recognize and simulate the systems and mechanisms depicted in images using the Im2Sim methodology. The VLM is given a natural image of a real-world system (e.g., cities, clouds, vegetation) and is tasked with describing the system and writing code that simulates and generates it. This generative code is then executed to produce a synthetic image, which is compared against the original. This approach is tested on various complex emergent systems, ranging from physical systems (waves, lights, clouds) to vegetation, cities, materials, and geological formations. Through analysis of the models and images generated by the VLMs, we examine their understanding of the systems in images. The results show that leading VLMs (GPT, Gemini) demonstrate the capacity to understand and model complex, multi-component systems across multiple layers of abstraction and a wide range of domains. At the same time, the VLMs exhibit limited ability to replicate fine details and low-level arrangements of patterns in the image. These findings reveal an interesting asymmetry: VLMs combine high-level, deep visual understanding of images with limited perception of fine details.

</details>


### [3] [STResNet & STYOLO : A New Family of Compact Classification and Object Detection Models for MCUs](https://arxiv.org/abs/2601.05364)
*Sudhakar Sah,Ravish Kumar*

Main category: cs.CV

TL;DR: 本文提出了STResNet和STYOLO两个轻量级神经网络系列，针对资源受限平台优化精度和效率，在图像分类和目标检测任务上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有轻量级网络在精度和延迟之间存在权衡，限制了在微控制器和神经处理单元设备上的应用，需要更平衡的解决方案。

Method: 设计了STResNet系列（从Nano到Tiny变体）用于图像分类，STYOLO系列用于目标检测，联合优化精度、效率和内存占用。

Result: STResNetMilli在300万参数下达到70.0% Top-1准确率，优于MobileNetV1和ShuffleNetV2；STYOLO在MS COCO数据集上超越YOLOv5n和YOLOX Nano。

Conclusion: 所提出的模型系列在资源受限平台上实现了更好的精度-效率平衡，为边缘设备部署提供了有效解决方案。

Abstract: Recent advancements in lightweight neural networks have significantly improved the efficiency of deploying deep learning models on edge hardware. However, most existing architectures still trade accuracy for latency, which limits their applicability on microcontroller and neural processing unit based devices. In this work, we introduce two new model families, STResNet for image classification and STYOLO for object detection, jointly optimized for accuracy, efficiency, and memory footprint on resource constrained platforms. The proposed STResNet series, ranging from Nano to Tiny variants, achieves competitive ImageNet 1K accuracy within a four million parameter budget. Specifically, STResNetMilli attains 70.0 percent Top 1 accuracy with only three million parameters, outperforming MobileNetV1 and ShuffleNetV2 at comparable computational complexity. For object detection, STYOLOMicro and STYOLOMilli achieve 30.5 percent and 33.6 percent mean average precision, respectively, on the MS COCO dataset, surpassing YOLOv5n and YOLOX Nano in both accuracy and efficiency. Furthermore, when STResNetMilli is used as a backbone with the Ultralytics training environment.

</details>


### [4] [MOSAIC-GS: Monocular Scene Reconstruction via Advanced Initialization for Complex Dynamic Environments](https://arxiv.org/abs/2601.05368)
*Svitlana Morkva,Maximum Wilder-Smith,Michael Oechsle,Alessio Tonioni,Marco Hutter,Vaishakh Patil*

Main category: cs.CV

TL;DR: MOSAIC-GS是一种基于高斯泼溅的高效动态场景重建方法，通过多几何线索和刚性约束解决单目视频重建的模糊性问题，实现快速优化和实时渲染。


<details>
  <summary>Details</summary>
Motivation: 单目视频重建由于缺乏多视角约束而存在模糊性，难以准确恢复物体几何和时序一致性，需要利用多种几何线索来增强重建效果。

Method: 使用深度、光流、动态物体分割和点跟踪等多几何线索，结合刚性运动约束在初始化阶段估计3D场景动态；将场景分解为静态和动态部分，动态高斯的轨迹用时间相关的Poly-Fourier曲线表示。

Result: MOSAIC-GS在标准单目动态场景基准测试中，相比现有方法实现了显著更快的优化和渲染速度，同时重建质量与最先进方法相当。

Conclusion: 该方法通过先验的动态场景估计和高效的运动编码，有效解决了单目动态场景重建的挑战，在保持高质量的同时大幅提升了计算效率。

Abstract: We present MOSAIC-GS, a novel, fully explicit, and computationally efficient approach for high-fidelity dynamic scene reconstruction from monocular videos using Gaussian Splatting. Monocular reconstruction is inherently ill-posed due to the lack of sufficient multiview constraints, making accurate recovery of object geometry and temporal coherence particularly challenging. To address this, we leverage multiple geometric cues, such as depth, optical flow, dynamic object segmentation, and point tracking. Combined with rigidity-based motion constraints, these cues allow us to estimate preliminary 3D scene dynamics during an initialization stage. Recovering scene dynamics prior to the photometric optimization reduces reliance on motion inference from visual appearance alone, which is often ambiguous in monocular settings. To enable compact representations, fast training, and real-time rendering while supporting non-rigid deformations, the scene is decomposed into static and dynamic components. Each Gaussian in the dynamic part of the scene is assigned a trajectory represented as time-dependent Poly-Fourier curve for parameter-efficient motion encoding. We demonstrate that MOSAIC-GS achieves substantially faster optimization and rendering compared to existing methods, while maintaining reconstruction quality on par with state-of-the-art approaches across standard monocular dynamic scene benchmarks.

</details>


### [5] [Ensemble of radiomics and ConvNeXt for breast cancer diagnosis](https://arxiv.org/abs/2601.05373)
*Jorge Alberto Garza-Abdala,Gerardo Alejandro Fumagal-González,Beatriz A. Bosques-Palomo,Mario Alexis Monsivais Molina,Daly Avedano,Servando Cardona-Huerta,José Gerardo Tamez-Pena*

Main category: cs.CV

TL;DR: 该研究评估了放射组学、深度学习和集成方法在乳腺X线筛查中检测癌症的性能，发现集成方法在两种独立数据集上表现最佳（AUC=0.87）。


<details>
  <summary>Details</summary>
Motivation: 早期诊断乳腺癌对提高生存率至关重要，放射组学和深度学习在辅助放射科医生进行早期癌症检测方面显示出巨大潜力。

Method: 使用RSNA 2023乳腺癌检测挑战赛（11,913名患者）和墨西哥TecSalud队列（19,400名患者）两个独立数据集。训练ConvNeXtV1-small深度学习模型和放射组学模型，采用集成方法结合两种预测结果。

Result: 集成方法获得最高AUC（0.87），优于单独的深度学习模型（0.83）和放射组学模型（0.80）。

Conclusion: 结合深度学习和放射组学预测的集成方法能显著提升乳腺X线筛查中乳腺癌的诊断性能。

Abstract: Early diagnosis of breast cancer is crucial for improving survival rates. Radiomics and deep learning (DL) have shown significant potential in assisting radiologists with early cancer detection. This paper aims to critically assess the performance of radiomics, DL, and ensemble techniques in detecting cancer from screening mammograms. Two independent datasets were used: the RSNA 2023 Breast Cancer Detection Challenge (11,913 patients) and a Mexican cohort from the TecSalud dataset (19,400 patients). The ConvNeXtV1-small DL model was trained on the RSNA dataset and validated on the TecSalud dataset, while radiomics models were developed using the TecSalud dataset and validated with a leave-one-year-out approach. The ensemble method consistently combined and calibrated predictions using the same methodology. Results showed that the ensemble approach achieved the highest area under the curve (AUC) of 0.87, compared to 0.83 for ConvNeXtV1-small and 0.80 for radiomics. In conclusion, ensemble methods combining DL and radiomics predictions significantly enhance breast cancer diagnosis from mammograms.

</details>


### [6] [EdgeLDR: Quaternion Low-Displacement Rank Neural Networks for Edge-Efficient Deep Learning](https://arxiv.org/abs/2601.05379)
*Vladimir Frants,Sos Agaian,Karen Panetta*

Main category: cs.CV

TL;DR: EdgeLDR是一个结合四元数通道混合和块循环参数结构的框架，通过FFT实现高效计算，在边缘设备上提供显著压缩和竞争性精度。


<details>
  <summary>Details</summary>
Motivation: 解决边缘设备上深度神经网络部署时内存流量和计算成本高的问题，同时结合四元数网络参数效率高和结构化矩阵计算快的优势。

Method: 提出四元数块循环线性和卷积层，通过复数伴随表示实现基于FFT的评估，并与空间域实现进行比较。

Result: FFT评估相比朴素实现获得显著加速，延迟随块大小增加保持稳定；在多个数据集上实现显著压缩且保持竞争性精度。

Conclusion: EdgeLDR层在边缘设备上提供显著的计算压缩，同时保持竞争性精度，使更大的压缩因子计算可行。

Abstract: Deploying deep neural networks on edge devices is often limited by the memory traffic and compute cost of dense linear operators. While quaternion neural networks improve parameter efficiency by coupling multiple channels through Hamilton products, they typically retain unstructured dense weights; conversely, structured matrices enable fast computation but are usually applied in the real domain. This paper introduces EdgeLDR, a practical framework for quaternion block-circulant linear and convolutional layers that combines quaternion channel mixing with block-circulant parameter structure and enables FFT-based evaluation through the complex adjoint representation. We present reference implementations of EdgeLDR layers and compare FFT-based computation against a naive spatial-domain realization of quaternion circulant products. FFT evaluation yields large empirical speedups over the naive implementation and keeps latency stable as block size increases, making larger compression factors computationally viable. We further integrate EdgeLDR layers into compact CNN and Transformer backbones and evaluate accuracy-compression trade-offs on 32x32 RGB classification (CIFAR-10/100, SVHN) and hyperspectral image classification (Houston 2013, Pavia University), reporting parameter counts and CPU/GPU latency. The results show that EdgeLDR layers provide significant compression with competitive accuracy.

</details>


### [7] [Sketch&Patch++: Efficient Structure-Aware 3D Gaussian Representation](https://arxiv.org/abs/2601.05394)
*Yuang Shi,Simone Gasparini,Géraldine Morin,Wei Tsang Ooi*

Main category: cs.CV

TL;DR: 该论文提出了一种基于高斯混合模型的混合表示方法，将高斯分为Sketch高斯和Patch高斯，实现层次化渐进式流式传输，在保持视觉质量的同时显著减小模型尺寸。


<details>
  <summary>Details</summary>
Motivation: 观察到高斯在3D场景中表现出类似艺术技法的不同角色特征，一些高斯捕捉高频特征（如边缘和轮廓），而另一些表示低频平滑区域，这种语义分离为高效表示提供了可能。

Method: 提出分层自适应分类框架，采用多标准基于密度的聚类和自适应质量驱动优化，直接在3DGS表示上操作，消除对外部3D线基元的依赖。

Result: 在多样化场景评估中，相比均匀剪枝基线，在相同模型大小下PSNR提升1.74dB，SSIM提升6.7%，LPIPS提升41.4%。室内场景仅需原始模型0.5%大小即可保持视觉质量。

Conclusion: 这种结构感知表示实现了高效存储、自适应流式传输和渲染，适用于带宽受限网络和资源受限设备的高保真3D内容处理。

Abstract: We observe that Gaussians exhibit distinct roles and characteristics analogous to traditional artistic techniques -- like how artists first sketch outlines before filling in broader areas with color, some Gaussians capture high-frequency features such as edges and contours, while others represent broader, smoother regions analogous to brush strokes that add volume and depth. Based on this observation, we propose a hybrid representation that categorizes Gaussians into (i) Sketch Gaussians, which represent high-frequency, boundary-defining features, and (ii) Patch Gaussians, which cover low-frequency, smooth regions. This semantic separation naturally enables layered progressive streaming, where the compact Sketch Gaussians establish the structural skeleton before Patch Gaussians incrementally refine volumetric detail.
  In this work, we extend our previous method to arbitrary 3D scenes by proposing a novel hierarchical adaptive categorization framework that operates directly on the 3DGS representation. Our approach employs multi-criteria density-based clustering, combined with adaptive quality-driven refinement. This method eliminates dependency on external 3D line primitives while ensuring optimal parametric encoding effectiveness. Our comprehensive evaluation across diverse scenes, including both man-made and natural environments, demonstrates that our method achieves up to 1.74 dB improvement in PSNR, 6.7% in SSIM, and 41.4% in LPIPS at equivalent model sizes compared to uniform pruning baselines. For indoor scenes, our method can maintain visual quality with only 0.5\% of the original model size. This structure-aware representation enables efficient storage, adaptive streaming, and rendering of high-fidelity 3D content across bandwidth-constrained networks and resource-limited devices.

</details>


### [8] [Multi-task Cross-modal Learning for Chest X-ray Image Retrieval](https://arxiv.org/abs/2601.05399)
*Zhaohui Liang,Sivaramakrishnan Rajaraman,Niccolo Marini,Zhiyun Xue,Sameer Antani*

Main category: cs.CV

TL;DR: 本文提出了一个多任务学习框架来微调BiomedCLIP模型，以提升胸部X光图像与文本的跨模态检索性能，通过结合分类、对比学习和跨模态对齐损失来实现更平衡和临床有意义的检索结果。


<details>
  <summary>Details</summary>
Motivation: CLIP和BiomedCLIP等视觉语言基础模型虽然提供强大的跨模态嵌入，但未针对细粒度医学检索任务（如使用胸部X光图像查询相关放射学报告）进行优化，因此需要领域自适应方法来提升性能。

Method: 使用BiomedCLIP作为主干网络，加入轻量级MLP投影头，采用多任务复合损失函数进行训练，包括：二元交叉熵损失区分正常/异常研究、监督对比损失增强类内一致性、CLIP损失保持跨模态对齐。

Result: 微调后的模型在图像到文本和文本到图像检索任务上均取得更平衡且临床有意义的性能，优于预训练的BiomedCLIP和通用CLIP模型；t-SNE可视化显示正常和异常病例的语义聚类更清晰，表明模型诊断敏感性提升。

Conclusion: 领域自适应的多任务学习对推进生物医学应用中的跨模态检索具有重要价值，能够有效提升模型在细粒度医学任务中的表现。

Abstract: CLIP and BiomedCLIP are examples of vision-language foundation models and offer strong cross-modal embeddings; however, they are not optimized for fine-grained medical retrieval tasks, such as retrieving clinically relevant radiology reports using chest X-ray (CXR) image queries. To address this shortcoming, we propose a multi-task learning framework to fine-tune BiomedCLIP and evaluate improvements to CXR image-text retrieval. Using BiomedCLIP as the backbone, we incorporate a lightweight MLP projector head trained with a multi-task composite loss function that includes: (1) a binary cross-entropy loss to distinguish normal from abnormal CXR studies, (2) a supervised contrastive loss to reinforce intra-class consistency, and (3) a CLIP loss to maintain cross-modal alignment. Experimental results demonstrate that the fine-tuned model achieves more balanced and clinically meaningful performance across both image-to-text and text-to-image retrieval tasks compared to the pretrained BiomedCLIP and general-purpose CLIP models. Furthermore, t-SNE visualizations reveal clearer semantic clustering of normal and abnormal cases, demonstrating the model's enhanced diagnostic sensitivity. These findings highlight the value of domain-adaptive, multi-task learning for advancing cross-modal retrieval in biomedical applications.

</details>


### [9] [Thinking with Map: Reinforced Parallel Map-Augmented Agent for Geolocalization](https://arxiv.org/abs/2601.05432)
*Yuxiang Ji,Yong Wang,Ziyu Ma,Yiming Hu,Hailang Huang,Xuecai Hu,Guanhua Chen,Liaoni Wu,Xiangxiang Chu*

Main category: cs.CV

TL;DR: 本文提出了一种结合地图思维的图像地理定位方法，通过代理在地图中的循环推理和两阶段优化策略，在真实世界图像基准测试中显著超越了现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有的大视觉语言模型方法虽然利用了世界知识、链式推理和代理能力，但忽视了人类常用的地图策略。本文旨在赋予模型"地图思维"能力。

Method: 开发了地图中代理循环的两阶段优化方案：代理强化学习增强采样效率，并行测试时扩展使模型在最终预测前探索多个候选路径。

Result: 在MAPBench基准测试中，方法在大多数指标上优于现有开源和闭源模型，特别是将Acc@500m从8.0%提升到22.1%，相比Gemini-3-Pro有显著改进。

Conclusion: 地图思维的引入和两阶段优化策略有效提升了图像地理定位性能，证明了地图推理在视觉定位任务中的重要性。

Abstract: The image geolocalization task aims to predict the location where an image was taken anywhere on Earth using visual clues. Existing large vision-language model (LVLM) approaches leverage world knowledge, chain-of-thought reasoning, and agentic capabilities, but overlook a common strategy used by humans -- using maps. In this work, we first equip the model \textit{Thinking with Map} ability and formulate it as an agent-in-the-map loop. We develop a two-stage optimization scheme for it, including agentic reinforcement learning (RL) followed by parallel test-time scaling (TTS). The RL strengthens the agentic capability of model to improve sampling efficiency, and the parallel TTS enables the model to explore multiple candidate paths before making the final prediction, which is crucial for geolocalization. To evaluate our method on up-to-date and in-the-wild images, we further present MAPBench, a comprehensive geolocalization training and evaluation benchmark composed entirely of real-world images. Experimental results show that our method outperforms existing open- and closed-source models on most metrics, specifically improving Acc@500m from 8.0\% to 22.1\% compared to \textit{Gemini-3-Pro} with Google Search/Map grounded mode.

</details>


### [10] [TAPM-Net: Trajectory-Aware Perturbation Modeling for Infrared Small Target Detection](https://arxiv.org/abs/2601.05446)
*Hongyang Xie,Hongyang He,Victor Sanchez*

Main category: cs.CV

TL;DR: 本文提出TAPM-Net网络，通过建模红外小目标在特征空间中引发的方向性扰动轨迹，解决红外小目标检测中信号弱、背景杂波等挑战。


<details>
  <summary>Details</summary>
Motivation: 当前基于CNN和ViT的模型缺乏对红外小目标在特征空间中引发层间方向性扰动的建模机制，而这是区分信号与结构化噪声的重要线索。

Method: 提出轨迹感知Mamba传播网络(TAPM-Net)，包含扰动引导路径模块(PGM)和轨迹感知状态块(TASB)。PGM构建扰动能量场并提取梯度跟随特征轨迹，TASB基于Mamba状态空间单元建模沿轨迹的动态传播。

Result: 在NUAA-SIRST和IRSTD-1K数据集上的实验表明，TAPM-Net在红外小目标检测任务上达到了最先进的性能。

Conclusion: TAPM-Net通过显式建模目标诱导特征扰动的空间扩散行为，实现了各向异性、上下文敏感的状态转移，在保持全局一致性的同时以较低计算成本获得优异性能。

Abstract: Infrared small target detection (ISTD) remains a long-standing challenge due to weak signal contrast, limited spatial extent, and cluttered backgrounds. Despite performance improvements from convolutional neural networks (CNNs) and Vision Transformers (ViTs), current models lack a mechanism to trace how small targets trigger directional, layer-wise perturbations in the feature space, which is an essential cue for distinguishing signal from structured noise in infrared scenes. To address this limitation, we propose the Trajectory-Aware Mamba Propagation Network (TAPM-Net), which explicitly models the spatial diffusion behavior of target-induced feature disturbances. TAPM-Net is built upon two novel components: a Perturbation-guided Path Module (PGM) and a Trajectory-Aware State Block (TASB). The PGM constructs perturbation energy fields from multi-level features and extracts gradient-following feature trajectories that reflect the directionality of local responses. The resulting feature trajectories are fed into the TASB, a Mamba-based state-space unit that models dynamic propagation along each trajectory while incorporating velocity-constrained diffusion and semantically aligned feature fusion from word-level and sentence-level embeddings. Unlike existing attention-based methods, TAPM-Net enables anisotropic, context-sensitive state transitions along spatial trajectories while maintaining global coherence at low computational cost. Experiments on NUAA-SIRST and IRSTD-1K demonstrate that TAPM-Net achieves state-of-the-art performance in ISTD.

</details>


### [11] [ROAP: A Reading-Order and Attention-Prior Pipeline for Optimizing Layout Transformers in Key Information Extraction](https://arxiv.org/abs/2601.05470)
*Tingwei Xie,Jinxin He,Yonghong Song*

Main category: cs.CV

TL;DR: ROAP是一个轻量级、架构无关的管道，通过优化注意力分布来解决多模态Transformer在视觉丰富文档理解中的两个关键限制：缺乏逻辑阅读顺序建模和视觉标记干扰文本语义注意力的问题。


<details>
  <summary>Details</summary>
Motivation: 多模态Transformer在视觉丰富文档理解中的性能受到两个固有限制的约束：缺乏对逻辑阅读顺序的显式建模，以及视觉标记干扰导致文本语义注意力被稀释。

Method: 1. 使用自适应XY间隙树（AXG-Tree）从复杂布局中提取分层阅读序列；2. 通过阅读顺序感知相对位置偏置（RO-RPB）将序列集成到注意力机制中；3. 引入文本标记子块注意力先验（TT-Prior）自适应抑制视觉噪声并增强细粒度文本-文本交互。

Result: 在FUNSD和CORD基准测试上的广泛实验表明，ROAP能够持续提升代表性骨干网络（包括LayoutLMv3和GeoLayoutLM）的性能。

Conclusion: 显式建模阅读逻辑和调节模态干扰对于稳健的文档理解至关重要，ROAP为复杂布局分析提供了一个可扩展的解决方案。

Abstract: The efficacy of Multimodal Transformers in visually-rich document understanding (VrDU) is critically constrained by two inherent limitations: the lack of explicit modeling for logical reading order and the interference of visual tokens that dilutes attention on textual semantics.
  To address these challenges, this paper presents ROAP, a lightweight and architecture-agnostic pipeline designed to optimize attention distributions in Layout Transformers without altering their pre-trained backbones.
  The proposed pipeline first employs an Adaptive-XY-Gap (AXG-Tree) to robustly extract hierarchical reading sequences from complex layouts. These sequences are then integrated into the attention mechanism via a Reading-Order-Aware Relative Position Bias (RO-RPB). Furthermore, a Textual-Token Sub-block Attention Prior (TT-Prior) is introduced to adaptively suppress visual noise and enhance fine-grained text-text interactions.
  Extensive experiments on the FUNSD and CORD benchmarks demonstrate that ROAP consistently improves the performance of representative backbones, including LayoutLMv3 and GeoLayoutLM.
  These findings confirm that explicitly modeling reading logic and regulating modality interference are critical for robust document understanding, offering a scalable solution for complex layout analysis. The implementation code will be released at https://github.com/KevinYuLei/ROAP.

</details>


### [12] [Multi-Image Super Resolution Framework for Detection and Analysis of Plant Roots](https://arxiv.org/abs/2601.05482)
*Shubham Agarwal,Ofek Nourian,Michael Sidorov,Sharon Chemweno,Ofer Hadar,Naftali Lazarovitch,Jhonathan E. Ephrath*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的地下植物根系成像系统，结合多图像超分辨率深度学习框架，通过多视角图像融合提升根系可见度和细节，解决了传统视觉方法在地下环境中的成像限制。


<details>
  <summary>Details</summary>
Motivation: 地下环境中植物根系成像面临遮挡、土壤湿度变化和低对比度等挑战，传统视觉方法效果有限，需要开发更有效的成像技术来支持土壤-植物相互作用和表型分析研究。

Method: 构建合成数据集模拟真实地下成像场景，开发基于深度学习的多图像超分辨率框架，利用多视角图像的空间冗余信息重建高分辨率根系图像。

Result: 定量评估显示该方法优于现有超分辨率基线方法，BRISQUE指标降低2.3%，图像质量显著提升，能够准确估计关键根系性状如根毛数量和密度。

Conclusion: 该框架为农业和生态研究提供了稳健的自动化地下植物根系成像和性状量化方法，具有重要的应用前景。

Abstract: Understanding plant root systems is critical for advancing research in soil-plant interactions, nutrient uptake, and overall plant health. However, accurate imaging of roots in subterranean environments remains a persistent challenge due to adverse conditions such as occlusion, varying soil moisture, and inherently low contrast, which limit the effectiveness of conventional vision-based approaches. In this work, we propose a novel underground imaging system that captures multiple overlapping views of plant roots and integrates a deep learning-based Multi-Image Super Resolution (MISR) framework designed to enhance root visibility and detail. To train and evaluate our approach, we construct a synthetic dataset that simulates realistic underground imaging scenarios, incorporating key environmental factors that affect image quality. Our proposed MISR algorithm leverages spatial redundancy across views to reconstruct high-resolution images with improved structural fidelity and visual clarity. Quantitative evaluations show that our approach outperforms state-of-the-art super resolution baselines, achieving a 2.3 percent reduction in BRISQUE, indicating improved image quality with the same CLIP-IQA score, thereby enabling enhanced phenotypic analysis of root systems. This, in turn, facilitates accurate estimation of critical root traits, including root hair count and root hair density. The proposed framework presents a promising direction for robust automatic underground plant root imaging and trait quantification for agricultural and ecological research.

</details>


### [13] [Hippocampal Atrophy Patterns Across the Alzheimer's Disease Spectrum: A Voxel-Based Morphometry Analysis](https://arxiv.org/abs/2601.05494)
*Trishna Niraula*

Main category: cs.CV

TL;DR: 该研究使用CAT12/SPM12体素形态测量分析249名ADNI参与者的MRI数据，发现阿尔茨海默病（AD）相对于认知正常（CN）和轻度认知障碍（MCI）存在显著海马体萎缩，海马体积对MCI向AD转化具有中等预测价值，APOE4状态对海马体积无显著影响。


<details>
  <summary>Details</summary>
Motivation: 研究阿尔茨海默病（AD）和轻度认知障碍（MCI）中灰质损失的模式，特别是内侧颞叶结构的退化，以了解AD进展的关键特征和预测生物标志物。

Method: 使用CAT12/SPM12体素形态测量分析249名ADNI参与者的基线T1加权MRI扫描，采用一般线性模型分析灰质体积，以诊断组为主要预测因子，年龄和总颅内体积作为协变量，统计图阈值设为p < 0.001（体素水平），并使用家族误差（FWE）校正进行多重比较校正（p < 0.05）。

Result: AD相对于CN和MCI存在显著海马体萎缩（Cohen's d分别为2.03和1.61），海马体积对MCI向AD转化的预测价值中等（AUC = 0.66），APOE4状态对海马体积无显著影响。

Conclusion: 内侧颞叶退化是AD进展的关键特征，海马体积可作为预测生物标志物，但APOE4状态对海马体积的遗传影响不显著。

Abstract: Alzheimer's disease (AD) and mild cognitive impairment (MCI) are associated with progressive gray matter loss, particularly in medial temporal structures. In this study, CAT12/SPM12 voxel-based morphometry was applied to baseline T1-weighted MRI scans from 249 ADNI participants (CN = 90, MCI = 129, AD = 30). Gray matter volume was analyzed using a general linear model, with the diagnostic group as primary predictor and age and total intracranial volume as covariates. Statistical maps were thresholded at p < 0.001 (voxelwise) and corrected for multiple comparisons at the cluster level using family-wise error (FWE) correction (p < 0.05). Significant hippocampal atrophy was observed in AD relative to CN and MCI (Cohen's d = 2.03 and 1.61, respectively). Hippocampal volume demonstrated moderate predictive value for conversion from MCI to AD (AUC = 0.66). Stratification by APOE4 status did not reveal significant genetic effects on cross-sectional hippocampal volume. These results support medial temporal degeneration as a key feature of AD progression and provide insights into predictive biomarkers and genetic influences.

</details>


### [14] [MMViR: A Multi-Modal and Multi-Granularity Representation for Long-range Video Understanding](https://arxiv.org/abs/2601.05495)
*Zizhong Li,Haopeng Zhang,Jiawei Zhang*

Main category: cs.CV

TL;DR: MMViR提出了一种多模态、多粒度的结构化表示方法，用于解决长视频理解中的计算复杂性和内容冗余问题，通过关键转折点分割和三层次描述实现高效检索和理解。


<details>
  <summary>Details</summary>
Motivation: 长视频（分钟到小时级别）包含复杂事件、多样场景和长程依赖关系，直接编码计算成本过高，简单视频转文本方法会导致内容冗余或碎片化，需要一种更高效的结构化表示方法。

Method: MMViR通过识别关键转折点对视频进行分割，构建包含全局叙事和细粒度视觉细节的三层次描述结构，支持基于查询的高效检索。

Result: 在QA、摘要和检索三个任务上的广泛评估显示，MMViR优于之前最强的方法，在小时级视频理解上提升19.67%，同时将处理延迟降低到原来的45.4%。

Conclusion: MMViR的多模态多粒度结构化表示方法有效解决了长视频理解的关键挑战，在保持理解质量的同时显著提升了处理效率，具有良好的泛化能力。

Abstract: Long videos, ranging from minutes to hours, present significant challenges for current Multi-modal Large Language Models (MLLMs) due to their complex events, diverse scenes, and long-range dependencies. Direct encoding of such videos is computationally too expensive, while simple video-to-text conversion often results in redundant or fragmented content. To address these limitations, we introduce MMViR, a novel multi-modal, multi-grained structured representation for long video understanding. MMViR identifies key turning points to segment the video and constructs a three-level description that couples global narratives with fine-grained visual details. This design supports efficient query-based retrieval and generalizes well across various scenarios. Extensive evaluations across three tasks, including QA, summarization, and retrieval, show that MMViR outperforms the prior strongest method, achieving a 19.67% improvement in hour-long video understanding while reducing processing latency to 45.4% of the original.

</details>


### [15] [Prompt-Free SAM-Based Multi-Task Framework for Breast Ultrasound Lesion Segmentation and Classification](https://arxiv.org/abs/2601.05498)
*Samuel E. Johnny,Bernes L. Atabonfack,Israel Alagbe,Assane Gueye*

Main category: cs.CV

TL;DR: 该研究提出了一种基于SAM视觉编码器的多任务深度学习框架，用于乳腺超声图像中的病灶分割和诊断分类，在PRECISE 2025数据集上取得了优异性能。


<details>
  <summary>Details</summary>
Motivation: 乳腺超声图像因对比度低、斑点噪声和病灶形态多样，导致准确的分割和分类具有挑战性。

Method: 使用无提示的完全监督方法，通过轻量级卷积头或UNet解码器对SAM特征进行解码，分类分支采用掩码引导注意力机制聚焦病灶特征。

Result: 在PRECISE 2025数据集上达到DSC 0.887和92.3%的准确率，在挑战排行榜中名列前茅。

Conclusion: SAM表示与分割引导学习相结合，能显著提升乳腺超声图像中病灶分割和诊断预测的性能。

Abstract: Accurate tumor segmentation and classification in breast ultrasound (BUS) imaging remain challenging due to low contrast, speckle noise, and diverse lesion morphology. This study presents a multi-task deep learning framework that jointly performs lesion segmentation and diagnostic classification using embeddings from the Segment Anything Model (SAM) vision encoder. Unlike prompt-based SAM variants, our approach employs a prompt-free, fully supervised adaptation where high-dimensional SAM features are decoded through either a lightweight convolutional head or a UNet-inspired decoder for pixel-wise segmentation. The classification branch is enhanced via mask-guided attention, allowing the model to focus on lesion-relevant features while suppressing background artifacts. Experiments on the PRECISE 2025 breast ultrasound dataset, split per class into 80 percent training and 20 percent testing, show that the proposed method achieves a Dice Similarity Coefficient (DSC) of 0.887 and an accuracy of 92.3 percent, ranking among the top entries on the PRECISE challenge leaderboard. These results demonstrate that SAM-based representations, when coupled with segmentation-guided learning, significantly improve both lesion delineation and diagnostic prediction in breast ultrasound imaging.

</details>


### [16] [FlyPose: Towards Robust Human Pose Estimation From Aerial Views](https://arxiv.org/abs/2601.05747)
*Hassaan Farooq,Marvin Brenner,Peter St\ütz*

Main category: cs.CV

TL;DR: FlyPose是一个轻量级自上而下的人体姿态估计流水线，专为无人机视角设计，在多个数据集上显著提升了检测和姿态估计性能，并能在边缘设备上实现实时推理。


<details>
  <summary>Details</summary>
Motivation: 无人机在人类密集环境中应用日益广泛，需要从空中视角准确感知人体姿态和动作，但现有方法面临分辨率低、视角陡峭、遮挡等挑战，特别是在需要实时模型的场景中。

Method: 采用多数据集训练方法，开发了轻量级的自上而下人体姿态估计流水线FlyPose，并在Jetson Orin AGX开发套件上部署实现约20毫秒的推理延迟。

Result: 在Manipal-UAV、VisDrone、HIT-UAV等测试集上人物检测平均提升6.8 mAP，在UAV-Human数据集上2D人体姿态估计提升16.3 mAP，并在四旋翼无人机上成功部署。

Conclusion: FlyPose有效解决了无人机视角下人体姿态估计的挑战，提供了实时可行的解决方案，并发布了具有挑战性的FlyPose-104数据集供研究使用。

Abstract: Unmanned Aerial Vehicles (UAVs) are increasingly deployed in close proximity to humans for applications such as parcel delivery, traffic monitoring, disaster response and infrastructure inspections. Ensuring safe and reliable operation in these human-populated environments demands accurate perception of human poses and actions from an aerial viewpoint. This perspective challenges existing methods with low resolution, steep viewing angles and (self-)occlusion, especially if the application demands realtime feasibile models. We train and deploy FlyPose, a lightweight top-down human pose estimation pipeline for aerial imagery. Through multi-dataset training, we achieve an average improvement of 6.8 mAP in person detection across the test-sets of Manipal-UAV, VisDrone, HIT-UAV as well as our custom dataset. For 2D human pose estimation we report an improvement of 16.3 mAP on the challenging UAV-Human dataset. FlyPose runs with an inference latency of ~20 milliseconds including preprocessing on a Jetson Orin AGX Developer Kit and is deployed onboard a quadrotor UAV during flight experiments. We also publish FlyPose-104, a small but challenging aerial human pose estimation dataset, that includes manual annotations from difficult aerial perspectives: https://github.com/farooqhassaan/FlyPose.

</details>


### [17] [Enabling Stroke-Level Structural Analysis of Hieroglyphic Scripts without Language-Specific Priors](https://arxiv.org/abs/2601.05508)
*Fuwen Luo,Zihao Wan,Ziyue Wang,Yaluo Liu,Pau Tong Lin Xu,Xuanjia Qiao,Xiaolong Wang,Peng Li,Yang Liu*

Main category: cs.CV

TL;DR: HieroSA是一个用于分析象形文字笔画结构的通用框架，能够自动从字符位图提取笔画级结构，无需手工标注数据，支持跨语言泛化。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型和多模态模型对象形文字的内部结构信息处理能力不足：LLMs将字符作为文本标记处理，MLLMs将其视为原始像素网格，两者都无法建模字符笔画的基本逻辑。现有结构分析方法通常针对特定文字且需要大量人工工作。

Method: 提出Hieroglyphic Stroke Analyzer (HieroSA)框架，将现代和古代象形文字字符图像转换为标准化坐标空间中的显式、可解释的线段表示。该方法无需语言特定先验知识，能够自动从字符位图推导出笔画级结构。

Result: 大量实验表明，HieroSA有效捕捉了字符内部结构和语义，无需语言特定先验知识。实验结果突出了该工作作为文字学分析工具的潜力，可用于深入理解象形文字。

Conclusion: HieroSA为象形文字的结构分析提供了一个通用且可扩展的解决方案，填补了现有模型在字符结构理解方面的空白，具有重要的学术和应用价值。

Abstract: Hieroglyphs, as logographic writing systems, encode rich semantic and cultural information within their internal structural composition. Yet, current advanced Large Language Models (LLMs) and Multimodal LLMs (MLLMs) usually remain structurally blind to this information. LLMs process characters as textual tokens, while MLLMs additionally view them as raw pixel grids. Both fall short to model the underlying logic of character strokes. Furthermore, existing structural analysis methods are often script-specific and labor-intensive. In this paper, we propose Hieroglyphic Stroke Analyzer (HieroSA), a novel and generalizable framework that enables MLLMs to automatically derive stroke-level structures from character bitmaps without handcrafted data. It transforms modern logographic and ancient hieroglyphs character images into explicit, interpretable line-segment representations in a normalized coordinate space, allowing for cross-lingual generalization. Extensive experiments demonstrate that HieroSA effectively captures character-internal structures and semantics, bypassing the need for language-specific priors. Experimental results highlight the potential of our work as a graphematics analysis tool for a deeper understanding of hieroglyphic scripts. View our code at https://github.com/THUNLP-MT/HieroSA.

</details>


### [18] [SceneFoundry: Generating Interactive Infinite 3D Worlds](https://arxiv.org/abs/2601.05810)
*ChunTeng Chen,YiChen Hsu,YiWen Liu,WeiFang Sun,TsaiChing Ni,ChunYi Lee,Min Sun,YuanFu Yang*

Main category: cs.CV

TL;DR: SceneFoundry是一个语言引导的扩散框架，用于生成公寓规模的3D世界，包含功能性关节家具和语义多样化的布局，用于机器人训练。


<details>
  <summary>Details</summary>
Motivation: 现有生成方法难以捕捉真实世界内部环境的功能复杂性，特别是包含可移动部件的关节对象，这对机器人操作和导航至关重要。

Method: 使用LLM模块控制楼层布局生成，基于扩散的后验采样从大规模3D资源库中填充场景，并采用可微分指导函数确保物理可用性。

Result: 框架能够生成结构有效、语义连贯且功能交互的环境，适用于不同场景类型和条件。

Conclusion: SceneFoundry能够实现可扩展的具身AI研究，为机器人学习提供大规模、交互式和物理真实的3D环境生成能力。

Abstract: The ability to automatically generate large-scale, interactive, and physically realistic 3D environments is crucial for advancing robotic learning and embodied intelligence. However, existing generative approaches often fail to capture the functional complexity of real-world interiors, particularly those containing articulated objects with movable parts essential for manipulation and navigation. This paper presents SceneFoundry, a language-guided diffusion framework that generates apartment-scale 3D worlds with functionally articulated furniture and semantically diverse layouts for robotic training. From natural language prompts, an LLM module controls floor layout generation, while diffusion-based posterior sampling efficiently populates the scene with articulated assets from large-scale 3D repositories. To ensure physical usability, SceneFoundry employs differentiable guidance functions to regulate object quantity, prevent articulation collisions, and maintain sufficient walkable space for robotic navigation. Extensive experiments demonstrate that our framework generates structurally valid, semantically coherent, and functionally interactive environments across diverse scene types and conditions, enabling scalable embodied AI research.

</details>


### [19] [GaussianSwap: Animatable Video Face Swapping with 3D Gaussian Splatting](https://arxiv.org/abs/2601.05511)
*Xuan Cheng,Jiahao Rao,Chengyang Li,Wenhao Wang,Weilin Chen,Lvqing Yang*

Main category: cs.CV

TL;DR: GaussianSwap是一个基于3D高斯溅射的视频人脸交换框架，能够从目标视频构建3D人脸头像，并将源图像的身份信息转移到该头像上，实现高保真度的视频人脸交换。


<details>
  <summary>Details</summary>
Motivation: 传统视频人脸交换框架仅限于生成基于像素的面部表示，交换后的人脸仅作为一组非结构化像素存在，缺乏动画或交互操作能力。本文旨在实现从传统像素级视频生成到可交互高保真头像创建的范式转变。

Method: 框架首先预处理目标视频提取FLAME参数、相机姿态和分割掩码，然后将3D高斯溅射绑定到FLAME模型上实现动态面部控制。为确保身份保持，提出复合身份嵌入方法，结合三种最先进的人脸识别模型进行头像微调。最后将交换后的人脸头像渲染到背景帧上生成最终视频。

Result: 实验结果表明，GaussianSwap在身份保持、视觉清晰度和时间一致性方面表现优异，同时实现了传统方法无法达到的交互应用能力。

Conclusion: GaussianSwap实现了从像素级到可交互3D头像的范式转变，为视频人脸交换技术开辟了新的应用方向。

Abstract: We introduce GaussianSwap, a novel video face swapping framework that constructs a 3D Gaussian Splatting based face avatar from a target video while transferring identity from a source image to the avatar. Conventional video swapping frameworks are limited to generating facial representations in pixel-based formats. The resulting swapped faces exist merely as a set of unstructured pixels without any capacity for animation or interactive manipulation. Our work introduces a paradigm shift from conventional pixel-based video generation to the creation of high-fidelity avatar with swapped faces. The framework first preprocesses target video to extract FLAME parameters, camera poses and segmentation masks, and then rigs 3D Gaussian splats to the FLAME model across frames, enabling dynamic facial control. To ensure identity preserving, we propose an compound identity embedding constructed from three state-of-the-art face recognition models for avatar finetuning. Finally, we render the face-swapped avatar on the background frames to obtain the face-swapped video. Experimental results demonstrate that GaussianSwap achieves superior identity preservation, visual clarity and temporal consistency, while enabling previously unattainable interactive applications.

</details>


### [20] [Goal Force: Teaching Video Models To Accomplish Physics-Conditioned Goals](https://arxiv.org/abs/2601.05848)
*Nate Gillman,Yinghua Zhou,Zitian Tang,Evan Luo,Arjan Chakravarthy,Daksh Aggarwal,Michael Freeman,Charles Herrmann,Chen Sun*

Main category: cs.CV

TL;DR: 提出了Goal Force框架，通过力向量和中间动力学定义视频生成目标，训练基于物理因果原语的视频生成模型，实现零样本泛化到复杂现实场景


<details>
  <summary>Details</summary>
Motivation: 现有世界模型难以精确指定目标：文本指令过于抽象，目标图像对动态任务不可行，需要更物理直观的目标定义方式

Method: 构建合成因果原语数据集，训练视频生成模型学习力在时空中的传播，通过力向量和中间动力学定义目标

Result: 模型在简单物理数据上训练后，零样本泛化到复杂现实场景（工具操作、多对象因果链），展现出隐含的神经物理模拟器能力

Conclusion: 将视频生成基于基本物理相互作用，模型可成为隐含神经物理模拟器，实现精确的物理感知规划而无需依赖外部引擎

Abstract: Recent advancements in video generation have enabled the development of ``world models'' capable of simulating potential futures for robotics and planning. However, specifying precise goals for these models remains a challenge; text instructions are often too abstract to capture physical nuances, while target images are frequently infeasible to specify for dynamic tasks. To address this, we introduce Goal Force, a novel framework that allows users to define goals via explicit force vectors and intermediate dynamics, mirroring how humans conceptualize physical tasks. We train a video generation model on a curated dataset of synthetic causal primitives-such as elastic collisions and falling dominos-teaching it to propagate forces through time and space. Despite being trained on simple physics data, our model exhibits remarkable zero-shot generalization to complex, real-world scenarios, including tool manipulation and multi-object causal chains. Our results suggest that by grounding video generation in fundamental physical interactions, models can emerge as implicit neural physics simulators, enabling precise, physics-aware planning without reliance on external engines. We release all datasets, code, model weights, and interactive video demos at our project page.

</details>


### [21] [SAS-VPReID: A Scale-Adaptive Framework with Shape Priors for Video-based Person Re-Identification at Extreme Far Distances](https://arxiv.org/abs/2601.05535)
*Qiwei Yang,Pingping Zhang,Yuhao Wang,Zijing Gong*

Main category: cs.CV

TL;DR: 提出SAS-VPReID框架，通过三个互补模块解决远距离视频行人重识别中的分辨率退化、视角变化和外观噪声问题，在VReID-XFD基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决远距离视频行人重识别中因分辨率严重退化、视角剧烈变化和不可避免的外观噪声带来的挑战。

Method: 基于三个模块：1）记忆增强视觉骨干网络（MEVB）使用CLIP视觉编码器和多代理记忆提取判别性特征；2）多粒度时序建模（MGTM）构建多时间粒度序列并自适应强调跨尺度的运动线索；3）先验正则化形状动态（PRSD）捕捉身体结构动态。

Result: 在VReID-XFD基准测试中验证了各模块的有效性，最终框架在VReID-XFD挑战赛排行榜中排名第一。

Conclusion: SAS-VPReID框架能够获得更具判别性的特征表示，有效解决了远距离视频行人重识别的挑战。

Abstract: Video-based Person Re-IDentification (VPReID) aims to retrieve the same person from videos captured by non-overlapping cameras. At extreme far distances, VPReID is highly challenging due to severe resolution degradation, drastic viewpoint variation and inevitable appearance noise. To address these issues, we propose a Scale-Adaptive framework with Shape Priors for VPReID, named SAS-VPReID. The framework is built upon three complementary modules. First, we deploy a Memory-Enhanced Visual Backbone (MEVB) to extract discriminative feature representations, which leverages the CLIP vision encoder and multi-proxy memory. Second, we propose a Multi-Granularity Temporal Modeling (MGTM) to construct sequences at multiple temporal granularities and adaptively emphasize motion cues across scales. Third, we incorporate Prior-Regularized Shape Dynamics (PRSD) to capture body structure dynamics. With these modules, our framework can obtain more discriminative feature representations. Experiments on the VReID-XFD benchmark demonstrate the effectiveness of each module and our final framework ranks the first on the VReID-XFD challenge leaderboard. The source code is available at https://github.com/YangQiWei3/SAS-VPReID.

</details>


### [22] [DIFF-MF: A Difference-Driven Channel-Spatial State Space Model for Multi-Modal Image Fusion](https://arxiv.org/abs/2601.05538)
*Yiming Sun,Zifan Ye,Qinghua Hu,Pengfei Zhu*

Main category: cs.CV

TL;DR: DIFF-MF是一个基于差异驱动的通道-空间状态空间模型的多模态图像融合方法，通过特征差异图指导特征提取，在通道和空间维度进行融合，解决了现有方法在红外强度和可见光细节平衡上的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于状态空间模型的多模态图像融合方法要么过度关注红外强度而损失可见光细节，要么保留可见光结构但降低热目标显著性，需要解决这种平衡问题。

Method: 提出DIFF-MF模型，利用模态间特征差异图指导特征提取，包含通道交换模块（基于交叉注意力双状态空间建模）和空间交换模块（基于跨模态状态空间扫描），在保持线性计算复杂度的同时捕获全局依赖。

Result: 在驾驶场景和低空无人机数据集上的实验表明，该方法在视觉质量和定量评估上均优于现有方法。

Conclusion: DIFF-MF通过差异驱动的通道-空间融合机制，有效整合多模态互补特征，在保持计算效率的同时提升了融合质量。

Abstract: Multi-modal image fusion aims to integrate complementary information from multiple source images to produce high-quality fused images with enriched content. Although existing approaches based on state space model have achieved satisfied performance with high computational efficiency, they tend to either over-prioritize infrared intensity at the cost of visible details, or conversely, preserve visible structure while diminishing thermal target salience. To overcome these challenges, we propose DIFF-MF, a novel difference-driven channel-spatial state space model for multi-modal image fusion. Our approach leverages feature discrepancy maps between modalities to guide feature extraction, followed by a fusion process across both channel and spatial dimensions. In the channel dimension, a channel-exchange module enhances channel-wise interaction through cross-attention dual state space modeling, enabling adaptive feature reweighting. In the spatial dimension, a spatial-exchange module employs cross-modal state space scanning to achieve comprehensive spatial fusion. By efficiently capturing global dependencies while maintaining linear computational complexity, DIFF-MF effectively integrates complementary multi-modal features. Experimental results on the driving scenarios and low-altitude UAV datasets demonstrate that our method outperforms existing approaches in both visual quality and quantitative evaluation.

</details>


### [23] [MoGen: A Unified Collaborative Framework for Controllable Multi-Object Image Generation](https://arxiv.org/abs/2601.05546)
*Yanfeng Li,Yue Sun,Keren Fu,Sio-Kei Im,Xiaoming Liu,Guangtao Zhai,Xiaohong Liu,Tao Tan*

Main category: cs.CV

TL;DR: MoGen是一个用户友好的多对象图像生成方法，通过区域语义锚定模块和自适应多模态引导模块，解决了现有方法在对象数量一致性和属性控制方面的局限性，实现了更精确的文本到图像生成。


<details>
  <summary>Details</summary>
Motivation: 现有多对象图像生成方法难以实现语言描述与图像区域的精确对齐，经常导致对象数量不一致和属性混淆。主流方法依赖外部控制信号，导致输入格式僵化，无法适应不同用户的资源条件和约束需求。

Method: 1. 设计了区域语义锚定模块，在生成过程中将语言描述中的短语单元精确锚定到对应图像区域；2. 提出了自适应多模态引导模块，自适应解析和整合多源控制信号，形成结构化意图，实现选择性约束。

Result: 实验结果表明，MoGen在生成质量、数量一致性和细粒度控制方面显著优于现有方法，同时展现出更好的可访问性和控制灵活性。

Conclusion: MoGen通过创新的区域语义锚定和自适应多模态引导机制，有效解决了多对象图像生成中的对齐和控制问题，为灵活可控的图像生成提供了新思路。

Abstract: Existing multi-object image generation methods face difficulties in achieving precise alignment between localized image generation regions and their corresponding semantics based on language descriptions, frequently resulting in inconsistent object quantities and attribute aliasing. To mitigate this limitation, mainstream approaches typically rely on external control signals to explicitly constrain the spatial layout, local semantic and visual attributes of images. However, this strong dependency makes the input format rigid, rendering it incompatible with the heterogeneous resource conditions of users and diverse constraint requirements. To address these challenges, we propose MoGen, a user-friendly multi-object image generation method. First, we design a Regional Semantic Anchor (RSA) module that precisely anchors phrase units in language descriptions to their corresponding image regions during the generation process, enabling text-to-image generation that follows quantity specifications for multiple objects. Building upon this foundation, we further introduce an Adaptive Multi-modal Guidance (AMG) module, which adaptively parses and integrates various combinations of multi-source control signals to formulate corresponding structured intent. This intent subsequently guides selective constraints on scene layouts and object attributes, achieving dynamic fine-grained control. Experimental results demonstrate that MoGen significantly outperforms existing methods in generation quality, quantity consistency, and fine-grained control, while exhibiting superior accessibility and control flexibility. Code is available at: https://github.com/Tear-kitty/MoGen/tree/master.

</details>


### [24] [VIB-Probe: Detecting and Mitigating Hallucinations in Vision-Language Models via Variational Information Bottleneck](https://arxiv.org/abs/2601.05547)
*Feiran Zhang,Yixin Wu,Zhenghua Wang,Xiaohua Wang,Changze Lv,Xuanjing Huang,Xiaoqing Zheng*

Main category: cs.CV

TL;DR: VIB-Probe：基于变分信息瓶颈理论的视觉语言模型幻觉检测与缓解框架，通过分析内部注意力头信号来识别和减少幻觉


<details>
  <summary>Details</summary>
Motivation: 现有幻觉检测方法主要依赖输出logits或外部验证工具，忽略了模型内部机制。研究发现特定注意力头携带真实生成的主要信号，但直接探测这些高维状态存在挑战

Method: 提出VIB-Probe框架，利用变分信息瓶颈理论提取跨层跨头的判别模式，同时通过信息瓶颈原理过滤语义噪声。利用VIB探针的梯度识别对幻觉有强因果影响的注意力头，并引入推理时干预策略

Result: 在多样化基准测试上的广泛实验表明，VIB-Probe在幻觉检测和缓解两方面均显著优于现有基线方法

Conclusion: 该方法通过分析模型内部注意力机制，提供了一种有效的幻觉检测和缓解方案，代码将公开

Abstract: Vision-Language Models (VLMs) have demonstrated remarkable progress in multimodal tasks, but remain susceptible to hallucinations, where generated text deviates from the underlying visual content. Existing hallucination detection methods primarily rely on output logits or external verification tools, often overlooking their internal mechanisms. In this work, we investigate the outputs of internal attention heads, postulating that specific heads carry the primary signals for truthful generation.However, directly probing these high-dimensional states is challenging due to the entanglement of visual-linguistic syntax and noise. To address this, we propose VIB-Probe, a novel hallucination detection and mitigation framework leveraging the Variational Information Bottleneck (VIB) theory. Our method extracts discriminative patterns across layers and heads while filtering out semantic nuisances through the information bottleneck principle. Furthermore, by leveraging the gradients of our VIB probe, we identify attention heads with strong causal influence on hallucinations and introduce an inference-time intervention strategy for hallucination mitigation. Extensive experiments across diverse benchmarks demonstrate that VIB-Probe significantly outperforms existing baselines in both settings. Our code will be made publicly available.

</details>


### [25] [One Language-Free Foundation Model Is Enough for Universal Vision Anomaly Detection](https://arxiv.org/abs/2601.05552)
*Bin-Bin Gao,Chengjie Wang*

Main category: cs.CV

TL;DR: UniADet是一个简单、通用且有效的通用视觉异常检测框架，通过解耦分类和分割任务以及跨层级特征，仅需少量可学习参数即可在多种基础模型上实现优异的零样本/少样本异常检测性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于视觉语言基础模型的异常检测方法存在复杂的提示工程、精细的适配模块和困难的训练策略等问题，限制了方法的灵活性和通用性。

Method: 1. 发现语言编码器对通用异常检测不必要；2. 提出简单方法完全解耦分类和分割任务，解耦跨层级特征，为不同任务和层级特征学习独立权重。

Result: 在14个真实世界异常检测基准测试中（涵盖工业和医疗领域），UniADet大幅超越最先进的零样本/少样本方法，甚至首次超越全样本方法。

Conclusion: UniADet具有高度简单性（仅学习解耦权重）、参数高效性（仅0.002M可学习参数）、通用性（适配多种基础模型）和有效性，为通用异常检测提供了新的解决方案。

Abstract: Universal visual anomaly detection (AD) aims to identify anomaly images and segment anomaly regions towards open and dynamic scenarios, following zero- and few-shot paradigms without any dataset-specific fine-tuning. We have witnessed significant progress in widely use of visual-language foundational models in recent approaches. However, current methods often struggle with complex prompt engineering, elaborate adaptation modules, and challenging training strategies, ultimately limiting their flexibility and generality. To address these issues, this paper rethinks the fundamental mechanism behind visual-language models for AD and presents an embarrassingly simple, general, and effective framework for Universal vision Anomaly Detection (UniADet). Specifically, we first find language encoder is used to derive decision weights for anomaly classification and segmentation, and then demonstrate that it is unnecessary for universal AD. Second, we propose an embarrassingly simple method to completely decouple classification and segmentation, and decouple cross-level features, i.e., learning independent weights for different tasks and hierarchical features. UniADet is highly simple (learning only decoupled weights), parameter-efficient (only 0.002M learnable parameters), general (adapting a variety of foundation models), and effective (surpassing state-of-the-art zero-/few-shot by a large margin and even full-shot AD methods for the first time) on 14 real-world AD benchmarks covering both industrial and medical domains. We will make the code and model of UniADet available at https://github.com/gaobb/UniADet.

</details>


### [26] [Semi-Supervised Facial Expression Recognition based on Dynamic Threshold and Negative Learning](https://arxiv.org/abs/2601.05556)
*Zhongpeng Cai,Jun Yu,Wei Xu,Tianyu Liu,Jianqing Sun,Jiaen Liang*

Main category: cs.CV

TL;DR: 提出了一种基于动态阈值调整和选择性负学习的半监督面部表情识别算法，在RAF-DB和AffectNet数据集上取得了state-of-the-art性能


<details>
  <summary>Details</summary>
Motivation: 获取大量标注面部表情数据成本高昂，需要设计能充分利用标注和未标注数据的半监督算法

Method: 使用局部注意力增强和特征图随机丢弃策略，结合动态阈值调整和选择性负学习策略，从低置信度未标注样本中挖掘有用信息

Result: 在RAF-DB和AffectNet数据集上达到最先进性能，甚至在不使用完整数据集的情况下超越全监督方法

Conclusion: 该方法通过动态阈值和选择性负学习有效利用了未标注数据，证明了半监督方法在面部表情识别任务中的有效性

Abstract: Facial expression recognition is a key task in human-computer interaction and affective computing. However, acquiring a large amount of labeled facial expression data is often costly. Therefore, it is particularly important to design a semi-supervised facial expression recognition algorithm that makes full use of both labeled and unlabeled data. In this paper, we propose a semi-supervised facial expression recognition algorithm based on Dynamic Threshold Adjustment (DTA) and Selective Negative Learning (SNL). Initially, we designed strategies for local attention enhancement and random dropout of feature maps during feature extraction, which strengthen the representation of local features while ensuring the model does not overfit to any specific local area. Furthermore, this study introduces a dynamic thresholding method to adapt to the requirements of the semi-supervised learning framework for facial expression recognition tasks, and through a selective negative learning strategy, it fully utilizes unlabeled samples with low confidence by mining useful expression information from complementary labels, achieving impressive results. We have achieved state-of-the-art performance on the RAF-DB and AffectNet datasets. Our method surpasses fully supervised methods even without using the entire dataset, which proves the effectiveness of our approach.

</details>


### [27] [What's Left Unsaid? Detecting and Correcting Misleading Omissions in Multimodal News Previews](https://arxiv.org/abs/2601.05563)
*Fanxiao Li,Jiaying Wu,Tingchao Fu,Dayang Li,Herun Wan,Wei Zhou,Min-Yen Kan*

Main category: cs.CV

TL;DR: 该论文提出了一种多阶段管道来解决社交媒体新闻预览（图片-标题对）引起的解释偏差问题，构建了MM-Misleading基准，并开发了OMGuard系统来检测和纠正基于遗漏的误导性内容。


<details>
  <summary>Details</summary>
Motivation: 社交媒体新闻预览通过选择性省略关键背景信息导致读者形成与完整文章不同的判断，这种隐性危害比显性虚假信息更难检测且研究不足。

Method: 开发多阶段管道解构和模拟基于预览与基于背景的理解，构建MM-Misleading基准；提出OMGuard系统，包含解释感知微调和理性引导的误导内容纠正。

Result: OMGuard将8B模型的检测准确率提升至与235B LVLM相当，并提供更强的端到端纠正能力；分析显示误导性通常源于局部叙事变化而非全局框架改变。

Conclusion: 该研究揭示了视觉干预在纠正误导性内容中的必要性，特别是在图像驱动场景下仅文本纠正无法有效工作的情况。

Abstract: Even when factually correct, social-media news previews (image-headline pairs) can induce interpretation drift: by selectively omitting crucial context, they lead readers to form judgments that diverge from what the full article conveys. This covert harm is harder to detect than explicit misinformation yet remains underexplored. To address this gap, we develop a multi-stage pipeline that disentangles and simulates preview-based versus context-based understanding, enabling construction of the MM-Misleading benchmark. Using this benchmark, we systematically evaluate open-source LVLMs and uncover pronounced blind spots to omission-based misleadingness detection. We further propose OMGuard, which integrates (1) Interpretation-Aware Fine-Tuning, which used to improve multimodal misleadingness detection and (2) Rationale-Guided Misleading Content Correction, which uses explicit rationales to guide headline rewriting and reduce misleading impressions. Experiments show that OMGuard lifts an 8B model's detection accuracy to match a 235B LVLM and delivers markedly stronger end-to-end correction. Further analysis reveals that misleadingness typically stems from local narrative shifts (e.g., missing background) rather than global frame changes, and identifies image-driven scenarios where text-only correction fails, highlighting the necessity of visual interventions.

</details>


### [28] [Towards Generalized Multi-Image Editing for Unified Multimodal Models](https://arxiv.org/abs/2601.05572)
*Pengcheng Xu,Peng Tang,Donghao Luo,Xiaobin Hu,Weichu Cui,Qingdong He,Zhennan Chen,Jiangning Zhang,Charles Ling,Boyu Wang*

Main category: cs.CV

TL;DR: 本文提出了一种可扩展的多图像编辑框架，通过引入可学习潜在分离器和正弦索引编码来解决UMMs在多图像处理中的视觉一致性和歧义消除问题。


<details>
  <summary>Details</summary>
Motivation: 现有的统一多模态模型在处理多输入图像时难以保持视觉一致性并消除视觉线索的歧义，限制了其在多图像编辑任务中的应用。

Method: 1) 可学习潜在分离器：在潜在空间中显式区分每个参考图像，实现精确解耦的条件控制；2) 正弦索引编码：为同一图像的视觉标记分配连续的正弦索引嵌入，提供显式图像身份标识并支持可变输入数量的泛化。

Result: 实验表明，该方法在语义一致性、视觉保真度和跨图像集成方面明显优于现有基线，验证了其在一致性和泛化能力方面的优势。

Conclusion: 提出的多图像编辑框架通过创新的分离和编码机制有效解决了UMMs在多图像处理中的关键挑战，为多模态模型的进一步发展提供了有力支持。

Abstract: Unified Multimodal Models (UMMs) integrate multimodal understanding and generation, yet they are limited to maintaining visual consistency and disambiguating visual cues when referencing details across multiple input images. In this work, we propose a scalable multi-image editing framework for UMMs that explicitly distinguishes image identities and generalizes to variable input counts. Algorithmically, we introduce two innovations: 1) The learnable latent separators explicitly differentiate each reference image in the latent space, enabling accurate and disentangled conditioning. 2) The sinusoidal index encoding assigns visual tokens from the same image a continuous sinusoidal index embedding, which provides explicit image identity while allowing generalization and extrapolation on a variable number of inputs. To facilitate training and evaluation, we establish a high-fidelity benchmark using an inverse dataset construction methodology to guarantee artifact-free, achievable outputs. Experiments show clear improvements in semantic consistency, visual fidelity, and cross-image integration over prior baselines on diverse multi-image editing tasks, validating our advantages on consistency and generalization ability.

</details>


### [29] [Orient Anything V2: Unifying Orientation and Rotation Understanding](https://arxiv.org/abs/2601.05573)
*Zehan Wang,Ziang Zhang,Jiayang Xu,Jialei Wang,Tianyu Pang,Chao Du,HengShuang Zhao,Zhou Zhao*

Main category: cs.CV

TL;DR: Orient Anything V2是一个增强的基础模型，用于从单张或配对图像中统一理解物体的3D方向和旋转。相比V1版本，V2能够处理具有不同旋转对称性的物体并直接估计相对旋转。


<details>
  <summary>Details</summary>
Motivation: 为了解决物体3D方向估计中的旋转对称性问题和相对旋转预测需求，扩展V1模型的能力以支持更广泛的应用场景。

Method: 通过四个关键创新：1) 使用生成模型合成可扩展的3D资产；2) 高效的模型在环标注系统识别有效前向面；3) 对称感知的周期性分布拟合目标；4) 多帧架构直接预测相对旋转。

Result: 在11个广泛使用的基准测试中，Orient Anything V2在方向估计、6DoF姿态估计和物体对称性识别方面实现了最先进的零样本性能。

Conclusion: 该模型表现出强大的泛化能力，显著拓宽了方向估计在多样化下游任务中的适用性。

Abstract: This work presents Orient Anything V2, an enhanced foundation model for unified understanding of object 3D orientation and rotation from single or paired images. Building upon Orient Anything V1, which defines orientation via a single unique front face, V2 extends this capability to handle objects with diverse rotational symmetries and directly estimate relative rotations. These improvements are enabled by four key innovations: 1) Scalable 3D assets synthesized by generative models, ensuring broad category coverage and balanced data distribution; 2) An efficient, model-in-the-loop annotation system that robustly identifies 0 to N valid front faces for each object; 3) A symmetry-aware, periodic distribution fitting objective that captures all plausible front-facing orientations, effectively modeling object rotational symmetry; 4) A multi-frame architecture that directly predicts relative object rotations. Extensive experiments show that Orient Anything V2 achieves state-of-the-art zero-shot performance on orientation estimation, 6DoF pose estimation, and object symmetry recognition across 11 widely used benchmarks. The model demonstrates strong generalization, significantly broadening the applicability of orientation estimation in diverse downstream tasks.

</details>


### [30] [Generalizable and Adaptive Continual Learning Framework for AI-generated Image Detection](https://arxiv.org/abs/2601.05580)
*Hanyi Wang,Jun Lan,Yaoyu Kang,Huijia Zhu,Weiqiang Wang,Zhuosheng Zhang,Shilin Wang*

Main category: cs.CV

TL;DR: 提出了一种三阶段领域持续学习框架，用于持续适应不断进化的AI生成图像检测，通过参数高效微调、持续学习和线性插值策略，在包含27个生成模型的基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: AI生成图像的恶意滥用和广泛传播威胁在线信息的真实性，现有检测方法难以泛化到未见过的生成模型，且生成技术的快速演进加剧了这一挑战。

Method: 三阶段框架：1）参数高效微调构建可迁移的离线检测模型；2）持续学习整合未见数据流，使用渐进复杂度的数据增强链和K-FAC方法缓解灾难性遗忘；3）基于线性模式连接的插值策略捕捉生成模型共性。

Result: 在包含GANs、深度伪造和扩散模型等27个生成模型的基准测试中，离线检测器比领先基线平均精度提升5.51%，持续学习策略平均准确率达到92.20%，优于最先进方法。

Conclusion: 该框架有效解决了AI生成图像检测中的泛化和适应性问题，为应对快速演进的生成技术提供了可行的持续学习解决方案。

Abstract: The malicious misuse and widespread dissemination of AI-generated images pose a significant threat to the authenticity of online information. Current detection methods often struggle to generalize to unseen generative models, and the rapid evolution of generative techniques continuously exacerbates this challenge. Without adaptability, detection models risk becoming ineffective in real-world applications. To address this critical issue, we propose a novel three-stage domain continual learning framework designed for continuous adaptation to evolving generative models. In the first stage, we employ a strategic parameter-efficient fine-tuning approach to develop a transferable offline detection model with strong generalization capabilities. Building upon this foundation, the second stage integrates unseen data streams into a continual learning process. To efficiently learn from limited samples of novel generated models and mitigate overfitting, we design a data augmentation chain with progressively increasing complexity. Furthermore, we leverage the Kronecker-Factored Approximate Curvature (K-FAC) method to approximate the Hessian and alleviate catastrophic forgetting. Finally, the third stage utilizes a linear interpolation strategy based on Linear Mode Connectivity, effectively capturing commonalities across diverse generative models and further enhancing overall performance. We establish a comprehensive benchmark of 27 generative models, including GANs, deepfakes, and diffusion models, chronologically structured up to August 2024 to simulate real-world scenarios. Extensive experiments demonstrate that our initial offline detectors surpass the leading baseline by +5.51% in terms of mean average precision. Our continual learning strategy achieves an average accuracy of 92.20%, outperforming state-of-the-art methods.

</details>


### [31] [GS-DMSR: Dynamic Sensitive Multi-scale Manifold Enhancement for Accelerated High-Quality 3D Gaussian Splatting](https://arxiv.org/abs/2601.05584)
*Nengbo Lu,Minghua Pan,Shaohua Sun,Yizhou Liang*

Main category: cs.CV

TL;DR: 本文提出GS-DMSR方法，通过自适应梯度聚焦和多尺度流形增强模块，在3D动态场景重建中平衡收敛速度与渲染质量，实现96 FPS的高帧率和降低存储开销。


<details>
  <summary>Details</summary>
Motivation: 解决3D动态场景重建中模型收敛速度与渲染质量平衡的挑战，特别是在复杂动态运动的高精度建模中。

Method: 1. 定量分析高斯属性动态演化过程，实现自适应梯度聚焦；2. 动态识别高斯模型运动状态差异，应用差异化优化策略；3. 集成多尺度流形增强模块，结合隐式非线性解码器和显式变形场的协同优化。

Result: 在合成数据集上达到96 FPS帧率，有效降低存储开销和训练时间。

Conclusion: GS-DMSR方法通过创新的自适应优化策略，显著提升了3D动态场景重建的效率和性能。

Abstract: In the field of 3D dynamic scene reconstruction, how to balance model convergence rate and rendering quality has long been a critical challenge that urgently needs to be addressed, particularly in high-precision modeling of scenes with complex dynamic motions. To tackle this issue, this study proposes the GS-DMSR method. By quantitatively analyzing the dynamic evolution process of Gaussian attributes, this mechanism achieves adaptive gradient focusing, enabling it to dynamically identify significant differences in the motion states of Gaussian models. It then applies differentiated optimization strategies to Gaussian models with varying degrees of significance, thereby significantly improving the model convergence rate. Additionally, this research integrates a multi-scale manifold enhancement module, which leverages the collaborative optimization of an implicit nonlinear decoder and an explicit deformation field to enhance the modeling efficiency for complex deformation scenes. Experimental results demonstrate that this method achieves a frame rate of up to 96 FPS on synthetic datasets, while effectively reducing both storage overhead and training time.Our code and data are available at https://anonymous.4open.science/r/GS-DMSR-2212.

</details>


### [32] [Quantifying and Inducing Shape Bias in CNNs via Max-Pool Dilation](https://arxiv.org/abs/2601.05599)
*Takito Sawada,Akinori Iwata,Masahiro Okuda*

Main category: cs.CV

TL;DR: 本文提出了一种量化数据集形状-纹理平衡的指标，并基于该指标开发了一种计算高效的适配方法，通过修改最大池化操作的膨胀率来增强CNN的形状偏向，在形状主导的数据集上显著提升分类准确率。


<details>
  <summary>Details</summary>
Motivation: CNN存在固有的纹理偏向，在形状主导的数据集（如插图和草图）上表现不佳。现有形状偏向模型缺乏量化指标来识别哪些数据集真正需要此类改进。

Method: 1. 提出基于SSIM的数据驱动指标，通过计算图像亮度通道与其L0平滑版本之间的结构相似性来量化数据集的形状-纹理平衡；2. 开发计算高效的适配方法，通过修改最大池化操作的膨胀率来增强形状偏向，同时保持卷积权重冻结。

Result: 该方法在形状主导的数据集上显著提升分类准确率，特别是在低数据量场景下效果明显，仅需训练最后的分类层。

Conclusion: 提出的形状-纹理平衡指标能有效识别需要形状偏向改进的数据集，而基于膨胀池化的适配方法为形状主导任务提供了计算高效的解决方案。

Abstract: Convolutional Neural Networks (CNNs) are known to exhibit a strong texture bias, favoring local patterns over global shape information--a tendency inherent to their convolutional architecture. While this bias is beneficial for texture-rich natural images, it often degrades performance on shape-dominant data such as illustrations and sketches. Although prior work has proposed shape-biased models to mitigate this issue, these approaches lack a quantitative metric for identifying which datasets would actually benefit from such modifications. To address this gap, we propose a data-driven metric that quantifies the shape-texture balance of a dataset by computing the Structural Similarity Index (SSIM) between each image's luminance channel and its L0-smoothed counterpart. Building on this metric, we further introduce a computationally efficient adaptation method that promotes shape bias by modifying the dilation of max-pooling operations while keeping convolutional weights frozen. Experimental results show that this approach consistently improves classification accuracy on shape-dominant datasets, particularly in low-data regimes where full fine-tuning is impractical, requiring training only the final classification layer.

</details>


### [33] [SceneAlign: Aligning Multimodal Reasoning to Scene Graphs in Complex Visual Scenes](https://arxiv.org/abs/2601.05600)
*Chuhan Wang,Xintong Li,Jennifer Yuntong Zhang,Junda Wu,Chengkai Huang,Lina Yao,Julian McAuley,Jingbo Shang*

Main category: cs.CV

TL;DR: SceneAlign是一个利用场景图进行结构化视觉干预的框架，通过构建对比性负样本对来提升多模态大语言模型在复杂视觉场景中的忠实推理能力


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在复杂视觉场景中经常出现推理不忠实的问题，如幻觉实体、错误关系定位、跳过步骤和过度指定推理。现有基于偏好的方法无法解决这一问题，因为它们允许模型利用语言先验来绕过视觉定位

Method: 提出SceneAlign框架，利用场景图作为结构化视觉信息进行可控的结构干预。通过识别推理关键节点并采用四种针对性策略进行扰动，构建语言上合理但视觉事实不准确的硬负样本，然后使用直接偏好优化来引导模型进行细粒度的结构忠实推理

Result: 在七个视觉推理基准测试中，SceneAlign一致提高了答案准确性和推理忠实性

Conclusion: SceneAlign证明了基于视觉定位的对齐方法在多模态推理中的有效性，能够显著提升模型在复杂视觉场景中的推理能力

Abstract: Multimodal large language models often struggle with faithful reasoning in complex visual scenes, where intricate entities and relations require precise visual grounding at each step. This reasoning unfaithfulness frequently manifests as hallucinated entities, mis-grounded relations, skipped steps, and over-specified reasoning. Existing preference-based approaches, typically relying on textual perturbations or answer-conditioned rationales, fail to address this challenge as they allow models to exploit language priors to bypass visual grounding. To address this, we propose SceneAlign, a framework that leverages scene graphs as structured visual information to perform controllable structural interventions. By identifying reasoning-critical nodes and perturbing them through four targeted strategies that mimic typical grounding failures, SceneAlign constructs hard negative rationales that remain linguistically plausible but are grounded in inaccurate visual facts. These contrastive pairs are used in Direct Preference Optimization to steer models toward fine-grained, structure-faithful reasoning. Across seven visual reasoning benchmarks, SceneAlign consistently improves answer accuracy and reasoning faithfulness, highlighting the effectiveness of grounding-aware alignment for multimodal reasoning.

</details>


### [34] [Learning Geometric Invariance for Gait Recognition](https://arxiv.org/abs/2601.05604)
*Zengbin Wang,Junjie Li,Saihui Hou,Xu Liu,Chunshui Cao,Yongzhen Huang,Muyi Sun,Siye Wang,Man Zhang*

Main category: cs.CV

TL;DR: 该论文提出了一种基于几何变换不变性的步态识别方法RRS-Gait，通过将不同步态条件的变化建模为反射、旋转和缩放三种几何变换的组合，实现身份不变特征学习。


<details>
  <summary>Details</summary>
Motivation: 大多数步态模型通过数据驱动方式隐式学习不同步态条件下的共同特征，但较少研究明确探索不同步态条件之间的内在关系。本文旨在建立不同步态条件之间的连接关系。

Method: 提出RRS-Gait框架，探索三种常见几何变换（反射、旋转、缩放），通过基于特定几何变换灵活调整卷积核实现近似特征等变性，然后将三个等变感知特征分别输入全局池化操作进行最终的不变性学习。

Result: 在四个流行步态数据集（Gait3D、GREW、CCPG、SUSTech1K）上的大量实验显示，在各种步态条件下都取得了优越性能。

Conclusion: 通过将不同步态条件的变化视为几何变换组合，并实现几何不变性，可以自然获得身份不变性，这为步态识别提供了新的视角。

Abstract: The goal of gait recognition is to extract identity-invariant features of an individual under various gait conditions, e.g., cross-view and cross-clothing. Most gait models strive to implicitly learn the common traits across different gait conditions in a data-driven manner to pull different gait conditions closer for recognition. However, relatively few studies have explicitly explored the inherent relations between different gait conditions. For this purpose, we attempt to establish connections among different gait conditions and propose a new perspective to achieve gait recognition: variations in different gait conditions can be approximately viewed as a combination of geometric transformations. In this case, all we need is to determine the types of geometric transformations and achieve geometric invariance, then identity invariance naturally follows. As an initial attempt, we explore three common geometric transformations (i.e., Reflect, Rotate, and Scale) and design a $\mathcal{R}$eflect-$\mathcal{R}$otate-$\mathcal{S}$cale invariance learning framework, named ${\mathcal{RRS}}$-Gait. Specifically, it first flexibly adjusts the convolution kernel based on the specific geometric transformations to achieve approximate feature equivariance. Then these three equivariant-aware features are respectively fed into a global pooling operation for final invariance-aware learning. Extensive experiments on four popular gait datasets (Gait3D, GREW, CCPG, SUSTech1K) show superior performance across various gait conditions.

</details>


### [35] [LatentVLA: Efficient Vision-Language Models for Autonomous Driving via Latent Action Prediction](https://arxiv.org/abs/2601.05611)
*Chengen Xie,Bin Sun,Tianyu Li,Junjie Wu,Zhihui Hao,XianPeng Lang,Hongyang Li*

Main category: cs.CV

TL;DR: LatentVLA提出了一个无需语言标注的VLA框架，通过自监督潜在动作预测消除语言偏差，实现实时高效的端到端自动驾驶。


<details>
  <summary>Details</summary>
Motivation: 解决当前VLA模型在自动驾驶中的三个关键挑战：轨迹预测数值不精确、语言标注依赖性强、计算效率低影响实时部署。

Method: 采用自监督潜在动作预测训练VLA模型，无需语言标注，通过知识蒸馏将VLA模型的泛化能力迁移到高效视觉网络。

Result: 在NAVSIM基准测试中达到92.4的PDMS分数，在nuScenes基准测试中展示强大的零样本泛化能力。

Conclusion: LatentVLA框架有效解决了VLA模型的语言偏差和计算效率问题，实现了高性能和实时性的平衡。

Abstract: End-to-end autonomous driving models trained on largescale datasets perform well in common scenarios but struggle with rare, long-tail situations due to limited scenario diversity. Recent Vision-Language-Action (VLA) models leverage broad knowledge from pre-trained visionlanguage models to address this limitation, yet face critical challenges: (1) numerical imprecision in trajectory prediction due to discrete tokenization, (2) heavy reliance on language annotations that introduce linguistic bias and annotation burden, and (3) computational inefficiency from multi-step chain-of-thought reasoning hinders real-time deployment. We propose LatentVLA, a novel framework that employs self-supervised latent action prediction to train VLA models without language annotations, eliminating linguistic bias while learning rich driving representations from unlabeled trajectory data. Through knowledge distillation, LatentVLA transfers the generalization capabilities of VLA models to efficient vision-based networks, achieving both robust performance and real-time efficiency. LatentVLA establishes a new state-of-the-art on the NAVSIM benchmark with a PDMS score of 92.4 and demonstrates strong zeroshot generalization on the nuScenes benchmark.

</details>


### [36] [Compressing image encoders via latent distillation](https://arxiv.org/abs/2601.05639)
*Caroline Mazini Rodrigues,Nicolas Keriven,Thomas Maugey*

Main category: cs.CV

TL;DR: 提出一种通过简化知识蒸馏来压缩深度学习图像压缩模型编码器的方法，能够在保持重建质量和统计保真度的同时减少模型大小和训练资源需求。


<details>
  <summary>Details</summary>
Motivation: 深度学习图像压缩模型虽然重建质量高，但通常复杂、重量大，需要大量训练数据和计算资源，在硬件受限的应用中存在实际限制。

Method: 使用简化的知识蒸馏策略来近似原始模型的潜在空间，用更少的数据和更短的训练时间从重量级编码器生成轻量级编码器。

Result: 在两个不同架构上的实验表明，该方法比使用原始损失训练轻量级编码器更好地保持了重建质量和统计保真度。

Conclusion: 该方法在资源受限环境中具有实用性，能够有效压缩图像压缩模型的编码器部分。

Abstract: Deep learning models for image compression often face practical limitations in hardware-constrained applications. Although these models achieve high-quality reconstructions, they are typically complex, heavyweight, and require substantial training data and computational resources. We propose a methodology to partially compress these networks by reducing the size of their encoders. Our approach uses a simplified knowledge distillation strategy to approximate the latent space of the original models with less data and shorter training, yielding lightweight encoders from heavyweight ones. We evaluate the resulting lightweight encoders across two different architectures on the image compression task. Experiments show that our method preserves reconstruction quality and statistical fidelity better than training lightweight encoders with the original loss, making it practical for resource-limited environments.

</details>


### [37] [SGDrive: Scene-to-Goal Hierarchical World Cognition for Autonomous Driving](https://arxiv.org/abs/2601.05640)
*Jingyu Li,Junjie Wu,Dongnan Hu,Xiangkai Huang,Bin Sun,Zhihui Hao,Xianpeng Lang,Xiatian Zhu,Li Zhang*

Main category: cs.CV

TL;DR: SGDrive是一个新颖的框架，通过将视觉语言模型（VLM）的表征学习围绕驾驶特定的知识层次结构进行显式结构化，解决了通用VLM在自动驾驶中缺乏空间-时间结构化表示的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的端到端自动驾驶方法虽然利用视觉语言模型增强了复杂驾驶场景的规划能力，但这些通用模型缺乏对驾驶特定3D空间和时间推理的专业理解，难以建立捕捉几何关系、场景上下文和运动模式的结构化时空表示。

Method: SGDrive基于预训练的VLM骨干网络，将驾驶理解分解为场景-智能体-目标层次结构，模拟人类驾驶认知过程：先感知整体环境（场景上下文），然后关注安全关键的智能体及其行为，最后制定短期目标再执行动作。

Result: 在NAVSIM基准测试上的大量实验表明，SGDrive在仅使用摄像头的方法中，在PDMS和EPDMS指标上都达到了最先进的性能。

Conclusion: 层次化知识结构化对于将通用VLM适应自动驾驶任务具有有效性，SGDrive通过明确的层次分解提供了通用VLM所缺乏的结构化时空表示。

Abstract: Recent end-to-end autonomous driving approaches have leveraged Vision-Language Models (VLMs) to enhance planning capabilities in complex driving scenarios. However, VLMs are inherently trained as generalist models, lacking specialized understanding of driving-specific reasoning in 3D space and time. When applied to autonomous driving, these models struggle to establish structured spatial-temporal representations that capture geometric relationships, scene context, and motion patterns critical for safe trajectory planning. To address these limitations, we propose SGDrive, a novel framework that explicitly structures the VLM's representation learning around driving-specific knowledge hierarchies. Built upon a pre-trained VLM backbone, SGDrive decomposes driving understanding into a scene-agent-goal hierarchy that mirrors human driving cognition: drivers first perceive the overall environment (scene context), then attend to safety-critical agents and their behaviors, and finally formulate short-term goals before executing actions. This hierarchical decomposition provides the structured spatial-temporal representation that generalist VLMs lack, integrating multi-level information into a compact yet comprehensive format for trajectory planning. Extensive experiments on the NAVSIM benchmark demonstrate that SGDrive achieves state-of-the-art performance among camera-only methods on both PDMS and EPDMS, validating the effectiveness of hierarchical knowledge structuring for adapting generalist VLMs to autonomous driving.

</details>


### [38] [SketchVL: Policy Optimization via Fine-Grained Credit Assignment for Chart Understanding and More](https://arxiv.org/abs/2601.05688)
*Muye Huang,Lingling Zhang,Yifei Li,Yaqiang Wu,Jun Liu*

Main category: cs.CV

TL;DR: SketchVL是一个通过FinePO算法实现细粒度信用分配的多模态大语言模型，通过在图像上绘制中间推理步骤来增强图表理解能力，相比基准模型平均性能提升7.23%。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在图表理解任务中存在信用分配问题，无法区分单个生成响应中正确和错误的推理步骤，限制了复杂视觉推理能力。

Method: 提出SketchVL模型，采用FinePO强化学习算法，利用FinePRM对轨迹中的每个绘制动作进行评分，实现细粒度信用分配。模型通过在图像上标记中间推理步骤并反馈给自身，构建多步推理过程。

Result: 实验表明SketchVL在图表数据集、自然图像数据集和数学任务上平均性能提升7.23%，能够将步骤级行为与FinePRM对齐。

Conclusion: SketchVL为训练强大的推理模型提供了有前景的新方向，通过细粒度信用分配显著提升了多模态推理能力。

Abstract: Charts are high-density visual carriers of complex data and medium for information extraction and analysis. Due to the need for precise and complex visual reasoning, automated chart understanding poses a significant challenge to existing Multimodal Large Language Models (MLLMs). Many MLLMs trained with reinforcement learning (RL) face the challenge of credit assignment. Their advantage estimation, typically performed at the trajectory level, cannot distinguish between correct and incorrect reasoning steps within a single generated response. To address this limitation, we introduce SketchVL, a novel MLLM that optimized with FinePO, a new RL algorithm designed for fine-grained credit assignment within each trajectory. SketchVL's methodology involves drawing its intermediate reasoning steps as markers on the image and feeding the annotated image back to itself, creating a robust, multi-step reasoning process. During training, the FinePO algorithm leverages a Fine-grained Process Reward Model (FinePRM) to score each drawing action within a trajectory, thereby precisely assigning credit for each step. This mechanism allows FinePO to more strongly reward correct tokens when a trajectory is globally successful, and more heavily penalize incorrect tokens when the trajectory is globally suboptimal, thus achieving fine-grained reinforcement signals. Experiments show that SketchVL learns to align its step-level behavior with the FinePRM, achieving an average performance gain of 7.23\% over its base model across chart datasets, natural image datasets, and mathematics, providing a promising new direction for training powerful reasoning models.

</details>


### [39] [Rotate Your Character: Revisiting Video Diffusion Models for High-Quality 3D Character Generation](https://arxiv.org/abs/2601.05722)
*Jin Wang,Jianxiang Lu,Comi Chen,Guangzheng Xu,Haoyu Yang,Peng Chen,Na Zhang,Yifan Xu,Longhuang Wu,Shuai Shao,Qinglin Lu,Ping Luo*

Main category: cs.CV

TL;DR: RCM是一个先进的图像到视频扩散框架，专门用于高质量的新视角合成和3D角色生成，能够处理复杂姿势并生成高分辨率轨道视频。


<details>
  <summary>Details</summary>
Motivation: 解决从单张图像生成高质量3D角色时面临的复杂身体姿势和自遮挡问题，提升数字内容创作的效率和质量。

Method: 使用图像到视频扩散框架，将具有复杂姿势的角色转换为规范姿势，支持多视图条件输入（最多4张图像），并实现可控的观察位置和高分辨率（1024x1024）轨道视频生成。

Result: 实验表明，RCM在新视角合成和3D生成质量方面优于现有的最先进方法。

Conclusion: RCM框架通过将复杂姿势角色转换为规范姿势，实现了高质量的新视角合成和3D角色生成，具有高分辨率、可控性和多视图支持等优势。

Abstract: Generating high-quality 3D characters from single images remains a significant challenge in digital content creation, particularly due to complex body poses and self-occlusion. In this paper, we present RCM (Rotate your Character Model), an advanced image-to-video diffusion framework tailored for high-quality novel view synthesis (NVS) and 3D character generation. Compared to existing diffusion-based approaches, RCM offers several key advantages: (1) transferring characters with any complex poses into a canonical pose, enabling consistent novel view synthesis across the entire viewing orbit, (2) high-resolution orbital video generation at 1024x1024 resolution, (3) controllable observation positions given different initial camera poses, and (4) multi-view conditioning supporting up to 4 input images, accommodating diverse user scenarios. Extensive experiments demonstrate that RCM outperforms state-of-the-art methods in both novel view synthesis and 3D generation quality.

</details>


### [40] [TAGRPO: Boosting GRPO on Image-to-Video Generation with Direct Trajectory Alignment](https://arxiv.org/abs/2601.05729)
*Jin Wang,Jianxiang Lu,Guangzheng Xu,Comi Chen,Haoyu Yang,Linqing Wang,Peng Chen,Mingtao Chen,Zhichao Hu,Longhuang Wu,Shuai Shao,Qinglin Lu,Ping Luo*

Main category: cs.CV

TL;DR: 本文提出了TAGRPO，一种针对图像到视频生成模型的鲁棒后训练框架，通过对比学习思想改进GRPO在I2V任务中的效果。


<details>
  <summary>Details</summary>
Motivation: 现有GRPO方法直接应用于图像到视频模型时无法获得一致的奖励提升，需要针对I2V任务特点进行优化。

Method: 基于相同初始噪声生成的视频序列提供更好优化指导的观察，提出在中间潜在空间应用新型GRPO损失，鼓励与高奖励轨迹对齐，同时最大化与低奖励轨迹的距离，并引入视频记忆库增强多样性和降低计算开销。

Result: TAGRPO在I2V生成任务中相比DanceGRPO取得了显著改进。

Conclusion: TAGRPO是一个简单但有效的I2V模型后训练框架，能够显著提升生成质量。

Abstract: Recent studies have demonstrated the efficacy of integrating Group Relative Policy Optimization (GRPO) into flow matching models, particularly for text-to-image and text-to-video generation. However, we find that directly applying these techniques to image-to-video (I2V) models often fails to yield consistent reward improvements. To address this limitation, we present TAGRPO, a robust post-training framework for I2V models inspired by contrastive learning. Our approach is grounded in the observation that rollout videos generated from identical initial noise provide superior guidance for optimization. Leveraging this insight, we propose a novel GRPO loss applied to intermediate latents, encouraging direct alignment with high-reward trajectories while maximizing distance from low-reward counterparts. Furthermore, we introduce a memory bank for rollout videos to enhance diversity and reduce computational overhead. Despite its simplicity, TAGRPO achieves significant improvements over DanceGRPO in I2V generation.

</details>


### [41] [FeatureSLAM: Feature-enriched 3D gaussian splatting SLAM in real time](https://arxiv.org/abs/2601.05738)
*Christopher Thirgood,Oscar Mendez,Erin Ling,Jon Storey,Simon Hadfield*

Main category: cs.CV

TL;DR: 本文提出了一个实时跟踪SLAM系统，将高效相机跟踪与基于3D高斯泼溅的光照真实感特征增强建图相结合，通过在新型视图合成中集成密集特征栅格化来提升语义理解能力。


<details>
  <summary>Details</summary>
Motivation: 传统语义SLAM方法通常嵌入预定义类别标签，限制了应用范围。本文旨在开发一个能够支持自由视角、开放集分割的全新下游任务的实时特征SLAM系统。

Method: 将密集特征栅格化集成到新型视图合成中，并与视觉基础模型对齐，使用3D高斯泼溅技术实现光照真实感的特征增强建图。

Result: 在标准基准测试中，实现了实时跟踪性能，与最先进系统相当，同时提高了跟踪稳定性和地图保真度。相比最近的固定集SLAM基线，姿态误差降低9%，建图精度提高8%。

Conclusion: 实时特征嵌入SLAM不仅能够支持新的下游应用，还能提升底层跟踪和建图子系统的性能，提供与离线3DGS模型相当的语义和语言掩码结果，同时实现最先进的跟踪、深度和RGB渲染。

Abstract: We present a real-time tracking SLAM system that unifies efficient camera tracking with photorealistic feature-enriched mapping using 3D Gaussian Splatting (3DGS). Our main contribution is integrating dense feature rasterization into the novel-view synthesis, aligned with a visual foundation model. This yields strong semantics, going beyond basic RGB-D input, aiding both tracking and mapping accuracy. Unlike previous semantic SLAM approaches (which embed pre-defined class labels) FeatureSLAM enables entirely new downstream tasks via free-viewpoint, open-set segmentation. Across standard benchmarks, our method achieves real-time tracking, on par with state-of-the-art systems while improving tracking stability and map fidelity without prohibitive compute. Quantitatively, we obtain 9\% lower pose error and 8\% higher mapping accuracy compared to recent fixed-set SLAM baselines. Our results confirm that real-time feature-embedded SLAM, is not only valuable for enabling new downstream applications. It also improves the performance of the underlying tracking and mapping subsystems, providing semantic and language masking results that are on-par with offline 3DGS models, alongside state-of-the-art tracking, depth and RGB rendering.

</details>


### [42] [ViTNT-FIQA: Training-Free Face Image Quality Assessment with Vision Transformers](https://arxiv.org/abs/2601.05741)
*Guray Ozgur,Eduarda Caldeira,Tahar Chettaoui,Jan Niklas Kolf,Marco Huber,Naser Damer,Fadi Boutros*

Main category: cs.CV

TL;DR: ViTNT-FIQA是一种无需训练的人脸图像质量评估方法，通过分析ViT中间块的patch嵌入演化稳定性来评估图像质量，仅需单次前向传播且无需修改模型结构


<details>
  <summary>Details</summary>
Motivation: 当前FIQA方法主要利用最终层表示，而无训练方法需要多次前向传播或反向传播，存在效率问题

Method: 通过计算连续Transformer块间L2归一化patch嵌入的欧几里得距离，并聚合为图像级质量分数，利用高质量图像在中间块特征演化更稳定的特性

Result: 在8个基准测试集上达到与最先进方法竞争的性能，同时保持计算效率和即插即用特性

Conclusion: ViTNT-FIQA提供了一种高效、无需训练的质量评估方案，可直接应用于任何预训练的ViT人脸识别模型

Abstract: Face Image Quality Assessment (FIQA) is essential for reliable face recognition systems. Current approaches primarily exploit only final-layer representations, while training-free methods require multiple forward passes or backpropagation. We propose ViTNT-FIQA, a training-free approach that measures the stability of patch embedding evolution across intermediate Vision Transformer (ViT) blocks. We demonstrate that high-quality face images exhibit stable feature refinement trajectories across blocks, while degraded images show erratic transformations. Our method computes Euclidean distances between L2-normalized patch embeddings from consecutive transformer blocks and aggregates them into image-level quality scores. We empirically validate this correlation on a quality-labeled synthetic dataset with controlled degradation levels. Unlike existing training-free approaches, ViTNT-FIQA requires only a single forward pass without backpropagation or architectural modifications. Through extensive evaluation on eight benchmarks (LFW, AgeDB-30, CFP-FP, CALFW, Adience, CPLFW, XQLFW, IJB-C), we show that ViTNT-FIQA achieves competitive performance with state-of-the-art methods while maintaining computational efficiency and immediate applicability to any pre-trained ViT-based face recognition model.

</details>


### [43] [Adaptive Disentangled Representation Learning for Incomplete Multi-View Multi-Label Classification](https://arxiv.org/abs/2601.05785)
*Quanjiang Li,Zhiming Liu,Tianxiang Xu,Tingjin Luo,Chenping Hou*

Main category: cs.CV

TL;DR: ADRL方法通过自适应解缠表示学习，解决多视图多标签学习中的特征缺失和标注不完整问题，实现了鲁棒的特征补全和标签语义建模。


<details>
  <summary>Details</summary>
Motivation: 多视图多标签学习经常面临特征缺失和标注不完整的挑战，现有方法在特征恢复、表示解缠和标签语义建模方面存在局限。

Method: 提出自适应解缠表示学习（ADRL）方法，包括：跨模态特征传播的视图补全、随机掩码策略增强重建、基于互信息的目标函数促进表示一致性、标签原型交互和伪标签生成。

Result: 在公共数据集和实际应用中进行的广泛实验表明，ADRL方法具有优越的性能。

Conclusion: ADRL通过创新的特征补全、表示解缠和标签语义建模机制，有效解决了多视图多标签学习中的关键挑战。

Abstract: Multi-view multi-label learning frequently suffers from simultaneous feature absence and incomplete annotations, due to challenges in data acquisition and cost-intensive supervision. To tackle the complex yet highly practical problem while overcoming the existing limitations of feature recovery, representation disentanglement, and label semantics modeling, we propose an Adaptive Disentangled Representation Learning method (ADRL). ADRL achieves robust view completion by propagating feature-level affinity across modalities with neighborhood awareness, and reinforces reconstruction effectiveness by leveraging a stochastic masking strategy. Through disseminating category-level association across label distributions, ADRL refines distribution parameters for capturing interdependent label prototypes. Besides, we formulate a mutual-information-based objective to promote consistency among shared representations and suppress information overlap between view-specific representation and other modalities. Theoretically, we derive the tractable bounds to train the dual-channel network. Moreover, ADRL performs prototype-specific feature selection by enabling independent interactions between label embeddings and view representations, accompanied by the generation of pseudo-labels for each category. The structural characteristics of the pseudo-label space are then exploited to guide a discriminative trade-off during view fusion. Finally, extensive experiments on public datasets and real-world applications demonstrate the superior performance of ADRL.

</details>


### [44] [Boosting Latent Diffusion Models via Disentangled Representation Alignment](https://arxiv.org/abs/2601.05823)
*John Page,Xuesong Niu,Kai Wu,Kun Gai*

Main category: cs.CV

TL;DR: Send-VAE是一种针对语义解缠的变分自编码器，通过将VAE潜在空间与预训练视觉基础模型的语义层次对齐，解决了传统方法中VAE和LDM使用相同对齐目标的局限性，显著提升了图像生成性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法让VAE和LDM使用相同的对齐目标，但忽略了它们本质不同的表示需求。LDM需要保留高层次语义概念，而VAE应该擅长语义解缠，以结构化方式编码属性级信息。

Method: 提出语义解缠VAE（Send-VAE），通过非线性映射网络将VAE潜在空间与预训练VFMs的语义层次对齐，桥接属性级解缠和高层次语义之间的差距。

Result: 在ImageNet 256x256数据集上，使用Send-VAE训练的SiT模型获得了最先进的FID分数1.21（有分类器引导）和1.75（无分类器引导），且显著加快了训练速度。

Conclusion: Send-VAE通过专门针对语义解缠的优化设计，证明了语义解缠与生成性能之间的强相关性，为图像生成模型提供了更有效的潜在表示学习方法。

Abstract: Latent Diffusion Models (LDMs) generate high-quality images by operating in a compressed latent space, typically obtained through image tokenizers such as Variational Autoencoders (VAEs). In pursuit of a generation-friendly VAE, recent studies have explored leveraging Vision Foundation Models (VFMs) as representation alignment targets for VAEs, mirroring the approach commonly adopted for LDMs. Although this yields certain performance gains, using the same alignment target for both VAEs and LDMs overlooks their fundamentally different representational requirements. We advocate that while LDMs benefit from latents retaining high-level semantic concepts, VAEs should excel in semantic disentanglement, enabling encoding of attribute-level information in a structured way. To address this, we propose the Semantic disentangled VAE (Send-VAE), explicitly optimized for disentangled representation learning through aligning its latent space with the semantic hierarchy of pre-trained VFMs. Our approach employs a non-linear mapper network to transform VAE latents, aligning them with VFMs to bridge the gap between attribute-level disentanglement and high-level semantics, facilitating effective guidance for VAE learning. We evaluate semantic disentanglement via linear probing on attribute prediction tasks, showing strong correlation with improved generation performance. Finally, using Send-VAE, we train flow-based transformers SiTs; experiments show Send-VAE significantly speeds up training and achieves a state-of-the-art FID of 1.21 and 1.75 with and without classifier-free guidance on ImageNet 256x256.

</details>


### [45] [GeoSurDepth: Spatial Geometry-Consistent Self-Supervised Depth Estimation for Surround-View Cameras](https://arxiv.org/abs/2601.05839)
*Weimin Liu,Wenjun Wang,Joshua H. Meng*

Main category: cs.CV

TL;DR: GeoSurDepth是一个利用几何一致性作为主要线索的环绕视图深度估计框架，通过基础模型提供几何先验，结合空间3D空间中的表面法线一致性和2D中的对象纹理一致性深度估计，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的环绕视图深度估计方法主要关注光度级别的跨视图约束，但很少明确利用单目和环绕视图设置中固有的丰富几何结构。本文旨在通过几何一致性来提升深度估计的鲁棒性和准确性。

Method: 提出GeoSurDepth框架，利用基础模型作为伪几何先验和特征表示增强工具，保持空间3D空间中的表面法线一致性，并在2D中正则化对象和纹理一致的深度估计。引入新颖的视图合成流程，通过空间扭曲实现2D-3D提升，并在时间、空间和时空上下文中提供额外的光度监督。采用自适应联合运动学习策略，使网络能够自适应地强调信息性空间几何线索以改进运动推理。

Result: 在DDAD和nuScenes数据集上的大量实验表明，GeoSurDepth实现了最先进的性能，验证了该方法的有效性。

Conclusion: 该框架强调了利用几何一致性和连贯性对于鲁棒的自监督多视图深度估计的重要性，为自动驾驶中的3D场景理解提供了竞争性的替代方案。

Abstract: Accurate surround-view depth estimation provides a competitive alternative to laser-based sensors and is essential for 3D scene understanding in autonomous driving. While prior studies have proposed various approaches that primarily focus on enforcing cross-view constraints at the photometric level, few explicitly exploit the rich geometric structure inherent in both monocular and surround-view setting. In this work, we propose GeoSurDepth, a framework that leverages geometry consistency as the primary cue for surround-view depth estimation. Concretely, we utilize foundation models as a pseudo geometry prior and feature representation enhancement tool to guide the network to maintain surface normal consistency in spatial 3D space and regularize object- and texture-consistent depth estimation in 2D. In addition, we introduce a novel view synthesis pipeline where 2D-3D lifting is achieved with dense depth reconstructed via spatial warping, encouraging additional photometric supervision across temporal, spatial, and spatial-temporal contexts, and compensating for the limitations of single-view image reconstruction. Finally, a newly-proposed adaptive joint motion learning strategy enables the network to adaptively emphasize informative spatial geometry cues for improved motion reasoning. Extensive experiments on DDAD and nuScenes demonstrate that GeoSurDepth achieves state-of-the-art performance, validating the effectiveness of our approach. Our framework highlights the importance of exploiting geometry coherence and consistency for robust self-supervised multi-view depth estimation.

</details>


### [46] [Kidney Cancer Detection Using 3D-Based Latent Diffusion Models](https://arxiv.org/abs/2601.05852)
*Jen Dusseljee,Sarah de Boer,Alessa Hering*

Main category: cs.CV

TL;DR: 提出了一种基于潜在扩散的3D肾脏异常检测方法，使用DDPM、DDIM和VQ-GAN技术，在对比增强腹部CT上实现弱监督的异常检测。


<details>
  <summary>Details</summary>
Motivation: 解决传统切片式方法的局限性，直接在图像体积上操作，仅使用病例级伪标签进行弱监督，旨在实现注释高效的复杂腹部解剖生成建模。

Method: 结合Denoising Diffusion Probabilistic Models (DDPMs)、Denoising Diffusion Implicit Models (DDIMs)和Vector-Quantized Generative Adversarial Networks (VQ-GANs)，构建3D潜在扩散管道。

Result: 当前结果尚未达到监督基线的水平，但证明了3D潜在扩散在弱监督异常检测中的可行性和潜力，揭示了改善重建保真度和病变定位的关键方向。

Conclusion: 该方法为复杂腹部解剖的注释高效生成建模提供了重要步骤，展示了弱监督3D潜在扩散在肾脏异常检测中的前景。

Abstract: In this work, we present a novel latent diffusion-based pipeline for 3D kidney anomaly detection on contrast-enhanced abdominal CT. The method combines Denoising Diffusion Probabilistic Models (DDPMs), Denoising Diffusion Implicit Models (DDIMs), and Vector-Quantized Generative Adversarial Networks (VQ-GANs). Unlike prior slice-wise approaches, our method operates directly on an image volume and leverages weak supervision with only case-level pseudo-labels. We benchmark our approach against state-of-the-art supervised segmentation and detection models. This study demonstrates the feasibility and promise of 3D latent diffusion for weakly supervised anomaly detection. While the current results do not yet match supervised baselines, they reveal key directions for improving reconstruction fidelity and lesion localization. Our findings provide an important step toward annotation-efficient, generative modeling of complex abdominal anatomy.

</details>


### [47] [LayerGS: Decomposition and Inpainting of Layered 3D Human Avatars via 2D Gaussian Splatting](https://arxiv.org/abs/2601.05853)
*Yinghan Xu,John Dingliana*

Main category: cs.CV

TL;DR: 提出了一种新颖的多层3D人体化身分解框架，通过2D高斯和扩散模型解决遮挡区域问题，实现高质量渲染和虚拟试穿。


<details>
  <summary>Details</summary>
Motivation: 传统单层重建方法将衣物锁定在单一身份上，而现有多层方法在遮挡区域处理上存在困难，需要克服这些限制。

Method: 使用2D高斯编码每层几何和渲染，通过预训练2D扩散模型补全遮挡区域。采用三阶段训练策略：先粗重建标准服装，再联合恢复内层身体和外层衣物细节。

Result: 在两个3D人体基准数据集（4D-Dress、Thuman2.0）上取得了优于现有方法的渲染质量和层分解重组效果。

Conclusion: 该方法能够在新视角和姿态下实现逼真的虚拟试穿，为沉浸式应用推进了高保真3D人体资产的实用创建。

Abstract: We propose a novel framework for decomposing arbitrarily posed humans into animatable multi-layered 3D human avatars, separating the body and garments. Conventional single-layer reconstruction methods lock clothing to one identity, while prior multi-layer approaches struggle with occluded regions. We overcome both limitations by encoding each layer as a set of 2D Gaussians for accurate geometry and photorealistic rendering, and inpainting hidden regions with a pretrained 2D diffusion model via score-distillation sampling (SDS). Our three-stage training strategy first reconstructs the coarse canonical garment via single-layer reconstruction, followed by multi-layer training to jointly recover the inner-layer body and outer-layer garment details. Experiments on two 3D human benchmark datasets (4D-Dress, Thuman2.0) show that our approach achieves better rendering quality and layer decomposition and recomposition than the previous state-of-the-art, enabling realistic virtual try-on under novel viewpoints and poses, and advancing practical creation of high-fidelity 3D human assets for immersive applications. Our code is available at https://github.com/RockyXu66/LayerGS

</details>


### [48] [Bidirectional Channel-selective Semantic Interaction for Semi-Supervised Medical Segmentation](https://arxiv.org/abs/2601.05855)
*Kaiwen Huang,Yizhe Zhang,Yi Zhou,Tianyang Xu,Tao Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种双向通道选择性语义交互（BCSI）框架，用于解决半监督医学图像分割中的错误积累和模型复杂性问题，通过语义空间扰动、通道选择路由器和双向通道交互策略提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有半监督医学图像分割方法（如均值教师和双流一致性学习）存在错误积累、模型结构复杂以及忽略标注与未标注数据流交互的问题，需要更有效的解决方案。

Method: 1）语义空间扰动（SSP）机制：使用强增强操作扰动数据，利用弱增强的伪标签进行无监督学习，并对两个强增强预测进行一致性约束；2）通道选择路由器（CR）：动态选择最相关通道进行信息交换，减少噪声；3）双向通道交互（BCI）策略：补充语义信息并增强重要通道表示。

Result: 在多个3D医学数据集上的实验结果表明，该方法优于现有的半监督方法。

Conclusion: BCSI框架通过有效的语义交互和通道选择机制，显著提升了半监督医学图像分割的性能和鲁棒性。

Abstract: Semi-supervised medical image segmentation is an effective method for addressing scenarios with limited labeled data. Existing methods mainly rely on frameworks such as mean teacher and dual-stream consistency learning. These approaches often face issues like error accumulation and model structural complexity, while also neglecting the interaction between labeled and unlabeled data streams. To overcome these challenges, we propose a Bidirectional Channel-selective Semantic Interaction~(BCSI) framework for semi-supervised medical image segmentation. First, we propose a Semantic-Spatial Perturbation~(SSP) mechanism, which disturbs the data using two strong augmentation operations and leverages unsupervised learning with pseudo-labels from weak augmentations. Additionally, we employ consistency on the predictions from the two strong augmentations to further improve model stability and robustness. Second, to reduce noise during the interaction between labeled and unlabeled data, we propose a Channel-selective Router~(CR) component, which dynamically selects the most relevant channels for information exchange. This mechanism ensures that only highly relevant features are activated, minimizing unnecessary interference. Finally, the Bidirectional Channel-wise Interaction~(BCI) strategy is employed to supplement additional semantic information and enhance the representation of important channels. Experimental results on multiple benchmarking 3D medical datasets demonstrate that the proposed method outperforms existing semi-supervised approaches.

</details>


### [49] [Phase4DFD: Multi-Domain Phase-Aware Attention for Deepfake Detection](https://arxiv.org/abs/2601.05861)
*Zhen-Xin Lin,Shang-Kuan Chen*

Main category: cs.CV

TL;DR: Phase4DFD是一个基于相位感知的频率域深度伪造检测框架，通过可学习的注意力机制显式建模相位-幅度交互，在多个数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造检测方法主要依赖频谱幅度信息，对相位信息的研究不足。相位不连续性通常是合成生成过程中引入的伪影，可能包含重要的检测线索。

Method: 提出Phase4DFD框架，将FFT幅度和LBP表示与RGB输入结合，引入输入级相位感知注意力模块，利用相位不连续性指导模型关注最具指示性的频率模式，使用BNext M骨干网络处理多域表示。

Result: 在CIFAKE和DFFD数据集上的实验表明，Phase4DFD优于最先进的空间和基于频率的检测器，同时保持低计算开销。消融研究确认相位建模提供与幅度信息互补的非冗余信息。

Conclusion: 显式相位建模在深度伪造检测中具有重要价值，相位信息为检测提供了独特的补充线索，相位感知方法能够有效提升检测性能。

Abstract: Recent deepfake detection methods have increasingly explored frequency domain representations to reveal manipulation artifacts that are difficult to detect in the spatial domain. However, most existing approaches rely primarily on spectral magnitude, implicitly under exploring the role of phase information. In this work, we propose Phase4DFD, a phase aware frequency domain deepfake detection framework that explicitly models phase magnitude interactions via a learnable attention mechanism. Our approach augments standard RGB input with Fast Fourier Transform (FFT) magnitude and local binary pattern (LBP) representations to expose subtle synthesis artifacts that remain indistinguishable under spatial analysis alone. Crucially, we introduce an input level phase aware attention module that uses phase discontinuities commonly introduced by synthetic generation to guide the model toward frequency patterns that are most indicative of manipulation before backbone feature extraction. The attended multi domain representation is processed by an efficient BNext M backbone, with optional channel spatial attention applied for semantic feature refinement. Extensive experiments on the CIFAKE and DFFD datasets demonstrate that our proposed model Phase4DFD outperforms state of the art spatial and frequency-based detectors while maintaining low computational overhead. Comprehensive ablation studies further confirm that explicit phase modeling provides complementary and non-redundant information beyond magnitude-only frequency representations.

</details>


### [50] [Adapting Vision Transformers to Ultra-High Resolution Semantic Segmentation with Relay Tokens](https://arxiv.org/abs/2601.05927)
*Yohann Perron,Vladyslav Sydorov,Christophe Pottier,Loic Landrieu*

Main category: cs.CV

TL;DR: 本文提出了一种简单有效的多尺度推理方法，通过并行处理局部和全局尺度图像，并使用可学习的relay tokens在分支间聚合特征，解决了超高分辨率图像分割中全局上下文丢失和细节损失的问题。


<details>
  <summary>Details</summary>
Motivation: 当前超高分辨率图像分割方法存在两个主要问题：滑动窗口会丢弃全局上下文，而下采样会丢失精细细节。需要一种能同时保留局部细节和全局感知的方法。

Method: 并行处理图像的局部尺度（高分辨率、小裁剪）和全局尺度（低分辨率、大裁剪），通过一小组可学习的relay tokens在两个分支之间聚合和传播特征。该方法可直接插入标准transformer骨干网络（如ViT和Swin），仅增加不到2%的参数。

Result: 在三个超高分辨率分割基准（Archaeoscape、URUR、Gleason）和传统Cityscapes数据集上的广泛实验显示了一致的性能提升，相对mIoU最高提升达15%。

Conclusion: 该方法有效解决了超高分辨率图像分割中的多尺度挑战，在保持模型简洁性的同时显著提升了分割性能，代码和预训练模型已开源。

Abstract: Current approaches for segmenting ultra high resolution images either slide a window, thereby discarding global context, or downsample and lose fine detail. We propose a simple yet effective method that brings explicit multi scale reasoning to vision transformers, simultaneously preserving local details and global awareness. Concretely, we process each image in parallel at a local scale (high resolution, small crops) and a global scale (low resolution, large crops), and aggregate and propagate features between the two branches with a small set of learnable relay tokens. The design plugs directly into standard transformer backbones (eg ViT and Swin) and adds fewer than 2 % parameters. Extensive experiments on three ultra high resolution segmentation benchmarks, Archaeoscape, URUR, and Gleason, and on the conventional Cityscapes dataset show consistent gains, with up to 15 % relative mIoU improvement. Code and pretrained models are available at https://archaeoscape.ai/work/relay-tokens/ .

</details>


### [51] [Performance of a Deep Learning-Based Segmentation Model for Pancreatic Tumors on Public Endoscopic Ultrasound Datasets](https://arxiv.org/abs/2601.05937)
*Pankaj Gupta,Priya Mudgil,Niharika Dutta,Kartik Bose,Nitish Kumar,Anupam Kumar,Jimil Shah,Vaneet Jearth,Jayanta Samanta,Vishal Sharma,Harshal Mandavdhare,Surinder Rana,Saroj K Sinha,Usha Dutta*

Main category: cs.CV

TL;DR: 本研究评估了基于Vision Transformer的深度学习分割模型在胰腺肿瘤EUS图像分割中的性能，在外部验证集上DSC达到0.657，敏感性71.8%，特异性97.7%，但存在9.7%的多重预测错误。


<details>
  <summary>Details</summary>
Motivation: 胰腺癌生存率低，内镜超声(EUS)是重要诊断工具但受操作者主观性限制。研究旨在开发基于Vision Transformer的深度学习模型来客观准确分割胰腺肿瘤。

Method: 使用USFM框架和Vision Transformer主干网络，在17,367张EUS图像上进行5折交叉验证训练，并在独立数据集（350张图像）上测试。预处理包括灰度转换、裁剪和调整至512x512像素。

Result: 5折交叉验证平均DSC 0.651±0.738，敏感性69.8%，特异性98.8%；外部验证DSC 0.657，敏感性71.8%，特异性97.7%。但9.7%病例出现错误多重预测。

Conclusion: Vision Transformer模型在EUS图像胰腺肿瘤分割中表现良好，但数据集异质性和有限的外部验证表明需要进一步优化、标准化和前瞻性研究。

Abstract: Background: Pancreatic cancer is one of the most aggressive cancers, with poor survival rates. Endoscopic ultrasound (EUS) is a key diagnostic modality, but its effectiveness is constrained by operator subjectivity. This study evaluates a Vision Transformer-based deep learning segmentation model for pancreatic tumors. Methods: A segmentation model using the USFM framework with a Vision Transformer backbone was trained and validated with 17,367 EUS images (from two public datasets) in 5-fold cross-validation. The model was tested on an independent dataset of 350 EUS images from another public dataset, manually segmented by radiologists. Preprocessing included grayscale conversion, cropping, and resizing to 512x512 pixels. Metrics included Dice similarity coefficient (DSC), intersection over union (IoU), sensitivity, specificity, and accuracy. Results: In 5-fold cross-validation, the model achieved a mean DSC of 0.651 +/- 0.738, IoU of 0.579 +/- 0.658, sensitivity of 69.8%, specificity of 98.8%, and accuracy of 97.5%. For the external validation set, the model achieved a DSC of 0.657 (95% CI: 0.634-0.769), IoU of 0.614 (95% CI: 0.590-0.689), sensitivity of 71.8%, and specificity of 97.7%. Results were consistent, but 9.7% of cases exhibited erroneous multiple predictions. Conclusions: The Vision Transformer-based model demonstrated strong performance for pancreatic tumor segmentation in EUS images. However, dataset heterogeneity and limited external validation highlight the need for further refinement, standardization, and prospective studies.

</details>


### [52] [Context-Aware Decoding for Faithful Vision-Language Generation](https://arxiv.org/abs/2601.05939)
*Mehrdad Fazli,Bowen Wei,Ziwei Zhu*

Main category: cs.CV

TL;DR: 本文提出了一种名为Context Embedding Injection (CEI)的训练免费方法，通过分析LVLM的解码层动态来缓解视觉语言模型中的幻觉问题，在多个基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在开放任务（如图像描述和视觉推理）中容易产生与视觉输入不一致的幻觉响应，这是当前模型的关键限制。

Method: 使用Logit Lens分析解码层动态，发现真实token比幻觉token更早积累概率质量。基于此提出CEI方法，利用最后一个输入token的隐藏状态作为接地信号来维持视觉保真度。

Result: 在CHAIR、AMBER和MMHal-Bench基准测试中，CEI在三个LVLM上优于最先进的基线方法，其动态变体实现了最低的整体幻觉率。

Conclusion: 通过将新的机制洞察与可扩展干预相结合，该工作推进了LVLM中幻觉的缓解。

Abstract: Hallucinations, generating responses inconsistent with the visual input, remain a critical limitation of large vision-language models (LVLMs), especially in open-ended tasks such as image captioning and visual reasoning. In this work, we probe the layer-wise generation dynamics that drive hallucinations and propose a training-free mitigation strategy. Employing the Logit Lens, we examine how LVLMs construct next-token distributions across decoder layers, uncovering a pronounced commitment-depth gap: truthful tokens accumulate probability mass on their final candidates earlier than hallucinatory ones. Drawing on this discovery, we introduce Context Embedding Injection (CEI), a lightweight method that harnesses the hidden state of the last input token-the context embedding-as a grounding signal to maintain visual fidelity throughout decoding and curb hallucinations. Evaluated on the CHAIR, AMBER, and MMHal-Bench benchmarks (with a maximum token length of 512), CEI outperforms state-of-the-art baselines across three LVLMs, with its dynamic variant yielding the lowest overall hallucination rates. By integrating novel mechanistic insights with a scalable intervention, this work advances the mitigation of hallucinations in LVLMs.

</details>


### [53] [WaveRNet: Wavelet-Guided Frequency Learning for Multi-Source Domain-Generalized Retinal Vessel Segmentation](https://arxiv.org/abs/2601.05942)
*Chanchan Wang,Yuanfang Wang,Qing Xu,Guanxin Chen*

Main category: cs.CV

TL;DR: WaveRNet是一个基于小波引导频率学习的框架，用于多源域泛化视网膜血管分割，通过频谱引导域调制器、频率自适应域融合模块和分层掩码提示细化器来解决光照和对比度变化下的泛化问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于SAM的方法忽视了频率域信息，且直接上采样会丢失细血管细节，导致在光照和对比度变化下泛化性能下降。

Method: 提出WaveRNet框架，包含频谱引导域调制器（SDM）分离光照鲁棒的低频结构和血管边界的高频信息，频率自适应域融合模块（FADF）进行智能测试时域选择，以及分层掩码提示细化器（HMPR）实现粗到细的细化。

Result: 在四个公共视网膜数据集上的Leave-One-Domain-Out协议实验表明，WaveRNet实现了最先进的泛化性能。

Conclusion: WaveRNet通过小波引导的频率学习有效解决了视网膜血管分割中的域偏移问题，显著提升了泛化能力。

Abstract: Domain-generalized retinal vessel segmentation is critical for automated ophthalmic diagnosis, yet faces significant challenges from domain shift induced by non-uniform illumination and varying contrast, compounded by the difficulty of preserving fine vessel structures. While the Segment Anything Model (SAM) exhibits remarkable zero-shot capabilities, existing SAM-based methods rely on simple adapter fine-tuning while overlooking frequency-domain information that encodes domain-invariant features, resulting in degraded generalization under illumination and contrast variations. Furthermore, SAM's direct upsampling inevitably loses fine vessel details. To address these limitations, we propose WaveRNet, a wavelet-guided frequency learning framework for robust multi-source domain-generalized retinal vessel segmentation. Specifically, we devise a Spectral-guided Domain Modulator (SDM) that integrates wavelet decomposition with learnable domain tokens, enabling the separation of illumination-robust low-frequency structures from high-frequency vessel boundaries while facilitating domain-specific feature generation. Furthermore, we introduce a Frequency-Adaptive Domain Fusion (FADF) module that performs intelligent test-time domain selection through wavelet-based frequency similarity and soft-weighted fusion. Finally, we present a Hierarchical Mask-Prompt Refiner (HMPR) that overcomes SAM's upsampling limitation through coarse-to-fine refinement with long-range dependency modeling. Extensive experiments under the Leave-One-Domain-Out protocol on four public retinal datasets demonstrate that WaveRNet achieves state-of-the-art generalization performance. The source code is available at https://github.com/Chanchan-Wang/WaveRNet.

</details>


### [54] [VideoAR: Autoregressive Video Generation via Next-Frame & Scale Prediction](https://arxiv.org/abs/2601.05966)
*Longbin Ji,Xiaoxiong Liu,Junyuan Shang,Shuohuan Wang,Yu Sun,Hua Wu,Haifeng Wang*

Main category: cs.CV

TL;DR: VideoAR是首个大规模视觉自回归视频生成框架，通过多尺度下一帧预测和自回归建模，在保持高质量的同时显著降低计算成本，性能接近扩散模型但效率提升10倍以上。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成主要依赖计算密集的扩散和流匹配模型，难以扩展。需要开发更高效、可扩展的视频生成方法，缩小自回归模型与扩散模型之间的性能差距。

Method: 结合多尺度下一帧预测与自回归建模，使用3D多尺度分词器编码时空动态，提出多尺度时间RoPE、跨帧错误校正和随机帧掩码等技术来提升长期一致性，采用多阶段预训练管道逐步对齐空间和时间学习。

Result: 在UCF-101上将FVD从99.5提升至88.6，推理步骤减少10倍以上，VBench得分达到81.74，与规模大一个数量级的扩散模型竞争。

Conclusion: VideoAR缩小了自回归与扩散范式之间的性能差距，为未来视频生成研究提供了可扩展、高效且时间一致的基础框架。

Abstract: Recent advances in video generation have been dominated by diffusion and flow-matching models, which produce high-quality results but remain computationally intensive and difficult to scale. In this work, we introduce VideoAR, the first large-scale Visual Autoregressive (VAR) framework for video generation that combines multi-scale next-frame prediction with autoregressive modeling. VideoAR disentangles spatial and temporal dependencies by integrating intra-frame VAR modeling with causal next-frame prediction, supported by a 3D multi-scale tokenizer that efficiently encodes spatio-temporal dynamics. To improve long-term consistency, we propose Multi-scale Temporal RoPE, Cross-Frame Error Correction, and Random Frame Mask, which collectively mitigate error propagation and stabilize temporal coherence. Our multi-stage pretraining pipeline progressively aligns spatial and temporal learning across increasing resolutions and durations. Empirically, VideoAR achieves new state-of-the-art results among autoregressive models, improving FVD on UCF-101 from 99.5 to 88.6 while reducing inference steps by over 10x, and reaching a VBench score of 81.74-competitive with diffusion-based models an order of magnitude larger. These results demonstrate that VideoAR narrows the performance gap between autoregressive and diffusion paradigms, offering a scalable, efficient, and temporally consistent foundation for future video generation research.

</details>


### [55] [Adaptive Conditional Contrast-Agnostic Deformable Image Registration with Uncertainty Estimation](https://arxiv.org/abs/2601.05981)
*Yinsong Wang,Xinzhe Luo,Siyi Du,Chen Qin*

Main category: cs.CV

TL;DR: 提出了一种基于随机卷积对比度增强的自适应条件对比度无关可变形图像配准框架（AC-CAR），能够泛化到训练期间未见过的任意成像对比度。


<details>
  <summary>Details</summary>
Motivation: 解决多对比度图像配准中传统方法耗时且学习型方法泛化性受限的问题，特别是针对不同成像对比度间的复杂非线性强度关系。

Method: 采用随机卷积对比度增强方案，提出自适应条件特征调制器（ACFM）和对比度不变潜在正则化，并集成方差网络提供对比度无关的配准不确定性估计。

Result: 实验结果表明AC-CAR在配准精度上优于基线方法，并对未见过的成像对比度表现出优越的泛化能力。

Conclusion: AC-CAR框架能够实现高效、准确且具有强泛化能力的多对比度图像配准，提高了配准结果的可信度和可靠性。

Abstract: Deformable multi-contrast image registration is a challenging yet crucial task due to the complex, non-linear intensity relationships across different imaging contrasts. Conventional registration methods typically rely on iterative optimization of the deformation field, which is time-consuming. Although recent learning-based approaches enable fast and accurate registration during inference, their generalizability remains limited to the specific contrasts observed during training. In this work, we propose an adaptive conditional contrast-agnostic deformable image registration framework (AC-CAR) based on a random convolution-based contrast augmentation scheme. AC-CAR can generalize to arbitrary imaging contrasts without observing them during training. To encourage contrast-invariant feature learning, we propose an adaptive conditional feature modulator (ACFM) that adaptively modulates the features and the contrast-invariant latent regularization to enforce the consistency of the learned feature across different imaging contrasts. Additionally, we enable our framework to provide contrast-agnostic registration uncertainty by integrating a variance network that leverages the contrast-agnostic registration encoder to improve the trustworthiness and reliability of AC-CAR. Experimental results demonstrate that AC-CAR outperforms baseline methods in registration accuracy and exhibits superior generalization to unseen imaging contrasts. Code is available at https://github.com/Yinsong0510/AC-CAR.

</details>


### [56] [Deepfake detectors are DUMB: A benchmark to assess adversarial training robustness under transferability constraints](https://arxiv.org/abs/2601.05986)
*Adrian Serrano,Erwan Umlil,Ronan Thomas*

Main category: cs.CV

TL;DR: 该研究将DUMB和DUMBer方法扩展到深度伪造检测领域，评估了在现实世界条件下（转移性约束和跨数据集配置）检测器对对抗攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现实环境中部署的深度伪造检测系统面临对抗性攻击威胁，而现有防御策略在攻击者知识有限和数据分布不匹配的实际条件下有效性尚不明确。

Method: 使用5种最先进检测器（RECCE、SRM、XCeption、UCF、SPSL）、3种攻击方法（PGD、FGSM、FPBA）和2个数据集（FaceForensics++、Celeb-DF-V2），在转移性约束和跨数据集配置下进行对抗性训练评估。

Result: 对抗性训练策略在分布内情况下能增强鲁棒性，但在跨数据集配置下可能降低鲁棒性，具体效果取决于采用的策略。

Conclusion: 研究强调了在面临对抗攻击的现实世界应用中需要采用基于具体情况的防御策略。

Abstract: Deepfake detection systems deployed in real-world environments are subject to adversaries capable of crafting imperceptible perturbations that degrade model performance. While adversarial training is a widely adopted defense, its effectiveness under realistic conditions -- where attackers operate with limited knowledge and mismatched data distributions - remains underexplored. In this work, we extend the DUMB -- Dataset soUrces, Model architecture and Balance - and DUMBer methodology to deepfake detection. We evaluate detectors robustness against adversarial attacks under transferability constraints and cross-dataset configuration to extract real-world insights. Our study spans five state-of-the-art detectors (RECCE, SRM, XCeption, UCF, SPSL), three attacks (PGD, FGSM, FPBA), and two datasets (FaceForensics++ and Celeb-DF-V2). We analyze both attacker and defender perspectives mapping results to mismatch scenarios. Experiments show that adversarial training strategies reinforce robustness in the in-distribution cases but can also degrade it under cross-dataset configuration depending on the strategy adopted. These findings highlight the need for case-aware defense strategies in real-world applications exposed to adversarial attacks.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [57] [MoEBlaze: Breaking the Memory Wall for Efficient MoE Training on Modern GPUs](https://arxiv.org/abs/2601.05296)
*Jiyuan Zhang,Yining Liu,Siqi Yan,Lisen Deng,Jennifer Cao,Shuqi Yang,Min Ni,Bi Xue,Shen Li*

Main category: cs.LG

TL;DR: MoEBlaze是一个内存高效的MoE训练框架，通过协同设计系统方法解决现代MoE架构中的内存瓶颈问题，实现4倍加速和50%内存节省。


<details>
  <summary>Details</summary>
Motivation: 现代大规模MoE架构面临严重的"内存墙"瓶颈，稀疏计算特性导致大量激活内存开销，限制了GPU的最大批处理大小和序列长度，并造成过多的数据移动阻碍性能和模型扩展。

Method: 采用协同设计的系统方法：(1)端到端令牌调度和MoE训练方法，使用优化数据结构消除中间缓冲区和激活物化；(2)协同设计的内核与智能激活检查点，减少内存占用同时提升性能。

Result: MoEBlaze相比现有MoE框架可实现超过4倍的加速和超过50%的内存节省。

Conclusion: MoEBlaze通过创新的内存优化技术有效解决了MoE训练中的内存瓶颈问题，为大规模MoE模型的高效训练提供了可行解决方案。

Abstract: The pervasive "memory wall" bottleneck is significantly amplified in modern large-scale Mixture-of-Experts (MoE) architectures. MoE's inherent architectural sparsity leads to sparse arithmetic compute and also introduces substantial activation memory overheads -- driven by large token routing buffers and the need to materialize and buffer intermediate tensors. This memory pressure limits the maximum batch size and sequence length that can fit on GPUs, and also results in excessive data movements that hinders performance and efficient model scaling. We present MoEBlaze, a memory-efficient MoE training framework that addresses these issues through a co-designed system approach: (i) an end-to-end token dispatch and MoE training method with optimized data structures to eliminate intermediate buffers and activation materializing, and (ii) co-designed kernels with smart activation checkpoint to mitigate memory footprint while simultaneously achieving better performance. We demonstrate that MoEBlaze can achieve over 4x speedups and over 50% memory savings compared to existing MoE frameworks.

</details>


### [58] [TIME: Temporally Intelligent Meta-reasoning Engine for Context Triggered Explicit Reasoning](https://arxiv.org/abs/2601.05300)
*Susmit Das*

Main category: cs.LG

TL;DR: TIME框架引入时间感知的元推理引擎，通过上下文敏感的推理机制和四阶段训练方法，在保持性能的同时大幅减少推理标记数量。


<details>
  <summary>Details</summary>
Motivation: 解决现有大语言模型推理机制成本高、可审计性差且无法在回复过程中重新触发的问题，同时增强对话模型对时间结构的感知能力。

Method: 引入ISO 8601时间标签、tick turns和短推理块，采用四阶段课程训练方法，包括最大多样性全批次对齐步骤，训练模型进行简短的就地推理。

Result: 在4B到32B规模上，TIME在TIMEBench基准测试中性能优于基础Qwen3模型，同时将推理标记减少约一个数量级。

Conclusion: TIME框架成功实现了时间感知的紧凑推理，为对话系统提供了更高效和可审计的推理机制。

Abstract: Reasoning oriented large language models often expose explicit "thinking" as long, turn-global traces at the start of every response, either always on or toggled externally at inference time. While useful for arithmetic, programming, and problem solving, this design is costly, blurs claim level auditability, and cannot re-trigger explicit reasoning once the model begins presenting. Dialogue models are also largely blind to temporal structure, treating replies after seconds and replies after weeks as equivalent unless time is stated in text. We introduce TIME, the Temporally Intelligent Meta-reasoning Engine, a behavioral alignment framework that treats explicit reasoning as a context sensitive resource driven by discourse and temporal cues. TIME augments dialogue with optional ISO 8601 <time> tags, tick turns that represent silent gaps, and short <think> blocks that can appear anywhere in a reply. A four-phase curriculum including a small, maximally diverse full-batch alignment step trains Qwen3 dense models to invoke brief, in-place reasoning bursts and keep user facing text compact. We evaluate with TIMEBench, a temporally grounded dialogue benchmark probing chronology, commonsense under gaps and offsets, anomaly detection, and continuity. Across 4B to 32B scales, TIME improves TIMEBench scores over base Qwen3 in both thinking and no-thinking modes while reducing reasoning tokens by about an order of magnitude. Our training data and code are available at https://github.com/The-Coherence-Initiative/TIME and TIMEBench is available at https://github.com/The-Coherence-Initiative/TIMEBench

</details>


### [59] [Ontology Neural Networks for Topologically Conditioned Constraint Satisfaction](https://arxiv.org/abs/2601.05304)
*Jaehong Oh*

Main category: cs.LG

TL;DR: 本文提出了一种增强的神经符号推理框架，通过集成拓扑条件化和梯度稳定机制，在保持语义连贯性的同时满足物理和逻辑约束。


<details>
  <summary>Details</summary>
Motivation: 神经符号推理系统在满足物理和逻辑约束的同时保持语义连贯性面临根本性挑战。基于之前的本体神经网络研究，需要开发能够平衡拓扑结构和梯度优化的新方法。

Method: 采用Forman-Ricci曲率捕捉图拓扑结构，使用Deep Delta Learning实现约束投影中的稳定秩一扰动，并应用协方差矩阵自适应进化策略进行参数优化。

Result: 实验表明该方法在多种问题规模下平均能量降低至1.15（基线为11.68），约束满足任务成功率达95%。框架表现出种子无关的收敛性和良好的可扩展性，可处理多达20个节点的问题。

Conclusion: 拓扑结构可以在不牺牲可解释性或计算效率的情况下为基于梯度的优化提供信息，该框架为神经符号推理提供了有效的解决方案。

Abstract: Neuro-symbolic reasoning systems face fundamental challenges in maintaining semantic coherence while satisfying physical and logical constraints. Building upon our previous work on Ontology Neural Networks, we present an enhanced framework that integrates topological conditioning with gradient stabilization mechanisms. The approach employs Forman-Ricci curvature to capture graph topology, Deep Delta Learning for stable rank-one perturbations during constraint projection, and Covariance Matrix Adaptation Evolution Strategy for parameter optimization. Experimental evaluation across multiple problem sizes demonstrates that the method achieves mean energy reduction to 1.15 compared to baseline values of 11.68, with 95 percent success rate in constraint satisfaction tasks. The framework exhibits seed-independent convergence and graceful scaling behavior up to twenty-node problems, suggesting that topological structure can inform gradient-based optimization without sacrificing interpretability or computational efficiency.

</details>


### [60] [When the Server Steps In: Calibrated Updates for Fair Federated Learning](https://arxiv.org/abs/2601.05352)
*Tianrun Yu,Kaixiang Zhao,Cheng Zhang,Anjun Gao,Yueyang Quan,Zhuqing Liu,Minghong Fang*

Main category: cs.LG

TL;DR: EquFL是一种新颖的服务端去偏方法，旨在解决联邦学习中的公平性问题，通过服务器生成校准更新来减少系统偏见，同时保持与FedAvg相同的收敛性能。


<details>
  <summary>Details</summary>
Motivation: 联邦学习面临确保跨不同人口群体公平性的关键挑战，现有方法要么需要修改客户端训练协议，要么缺乏聚合策略的灵活性。

Method: EquFL在服务器端运行，接收客户端模型更新后生成单一校准更新，然后将校准更新与聚合的客户端更新结合，产生减少偏见的调整后全局模型。

Result: 理论上证明EquFL收敛到FedAvg实现的最优全局模型，并有效减少训练轮次中的公平性损失；实证表明EquFL显著减轻系统偏见。

Conclusion: EquFL是一种有效且实用的服务器端去偏方法，能够在保持性能的同时显著改善联邦学习系统的公平性。

Abstract: Federated learning (FL) has emerged as a transformative distributed learning paradigm, enabling multiple clients to collaboratively train a global model under the coordination of a central server without sharing their raw training data. While FL offers notable advantages, it faces critical challenges in ensuring fairness across diverse demographic groups. To address these fairness concerns, various fairness-aware debiasing methods have been proposed. However, many of these approaches either require modifications to clients' training protocols or lack flexibility in their aggregation strategies. In this work, we address these limitations by introducing EquFL, a novel server-side debiasing method designed to mitigate bias in FL systems. EquFL operates by allowing the server to generate a single calibrated update after receiving model updates from the clients. This calibrated update is then integrated with the aggregated client updates to produce an adjusted global model that reduces bias. Theoretically, we establish that EquFL converges to the optimal global model achieved by FedAvg and effectively reduces fairness loss over training rounds. Empirically, we demonstrate that EquFL significantly mitigates bias within the system, showcasing its practical effectiveness.

</details>


### [61] [GlyRAG: Context-Aware Retrieval-Augmented Framework for Blood Glucose Forecasting](https://arxiv.org/abs/2601.05353)
*Shovito Barua Soumma,Hassan Ghasemzadeh*

Main category: cs.LG

TL;DR: GlyRAG是一个基于检索增强的血糖预测框架，利用LLM从CGM数据中提取临床语义上下文，无需额外传感器即可实现高精度长时程血糖预测。


<details>
  <summary>Details</summary>
Motivation: 当前血糖预测模型将CGM数据视为纯数值序列，忽略了临床上下文信息，或依赖难以大规模部署的额外传感器。LLM在时间序列预测中的潜力及其在糖尿病护理中的上下文提取作用尚未充分探索。

Method: 使用LLM作为上下文提取代理生成临床总结，通过语言模型嵌入并与基于补丁的血糖表示在多模态Transformer中融合，采用交叉翻译损失对齐文本和生理嵌入。检索模块在嵌入空间中识别相似历史事件，通过交叉注意力整合案例类比进行预测。

Result: 在两个T1D队列上的评估显示，GlyRAG显著优于现有方法，RMSE降低达39%，进一步比基线降低1.7%。临床评估显示85%预测位于安全区域，对异常血糖事件的预测准确率提升51%。

Conclusion: 基于LLM的上下文提取和CGM轨迹检索能够在不依赖额外传感器的情况下提高长时程血糖预测的准确性和临床可靠性，为未来糖尿病管理的智能决策支持工具提供支持。

Abstract: Accurate forecasting of blood glucose from CGM is essential for preventing dysglycemic events, thus enabling proactive diabetes management. However, current forecasting models treat blood glucose readings captured using CGMs as a numerical sequence, either ignoring context or relying on additional sensors/modalities that are difficult to collect and deploy at scale. Recently, LLMs have shown promise for time-series forecasting tasks, yet their role as agentic context extractors in diabetes care remains largely unexplored. To address these limitations, we propose GlyRAG, a context-aware, retrieval-augmented forecasting framework that derives semantic understanding of blood glucose dynamics directly from CGM traces without requiring additional sensor modalities. GlyRAG employs an LLM as a contextualization agent to generate clinical summaries. These summaries are embedded by a language model and fused with patch-based glucose representations in a multimodal transformer architecture with a cross translation loss aligining textual and physiological embeddings. A retrieval module then identifies similar historical episodes in the learned embedding space and uses cross-attention to integrate these case-based analogues prior to making a forecasting inference. Extensive evaluations on two T1D cohorts show that GlyRAG consistently outperforms state-of-the art methods, achieving up to 39% lower RMSE and a further 1.7% reduction in RMSE over the baseline. Clinical evaluation shows that GlyRAG places 85% predictions in safe zones and achieves 51% improvement in predicting dysglycemic events across both cohorts. These results indicate that LLM-based contextualization and retrieval over CGM traces can enhance the accuracy and clinical reliability of long-horizon glucose forecasting without the need for extra sensors, thus supporting future agentic decision-support tools for diabetes management.

</details>


### [62] [The Kernel Manifold: A Geometric Approach to Gaussian Process Model Selection](https://arxiv.org/abs/2601.05371)
*Md Shafiqul Islam,Shakti Prasad Padhy,Douglas Allaire,Raymundo Arróyave*

Main category: cs.LG

TL;DR: 提出了基于核几何的贝叶斯优化框架，通过多维缩放将离散核库映射到连续欧几里得流形，实现高效核选择


<details>
  <summary>Details</summary>
Motivation: 高斯过程回归的性能严重依赖于协方差核的选择，但核选择是概率建模中最具挑战性和计算成本最高的步骤之一

Method: 使用基于期望散度的距离度量构建核空间几何，通过多维缩放嵌入将离散核库转换为连续流形，在MDS坐标空间进行贝叶斯优化

Result: 在合成基准测试、真实世界时间序列数据集和增材制造案例研究中，相比基线方法（包括LLM引导搜索）取得了更优的预测精度和不确定性校准

Conclusion: 该框架为核搜索建立了可重用的概率几何结构，对高斯过程建模和深度核学习具有直接相关性

Abstract: Gaussian Process (GP) regression is a powerful nonparametric Bayesian framework, but its performance depends critically on the choice of covariance kernel. Selecting an appropriate kernel is therefore central to model quality, yet remains one of the most challenging and computationally expensive steps in probabilistic modeling. We present a Bayesian optimization framework built on kernel-of-kernels geometry, using expected divergence-based distances between GP priors to explore kernel space efficiently. A multidimensional scaling (MDS) embedding of this distance matrix maps a discrete kernel library into a continuous Euclidean manifold, enabling smooth BO. In this formulation, the input space comprises kernel compositions, the objective is the log marginal likelihood, and featurization is given by the MDS coordinates. When the divergence yields a valid metric, the embedding preserves geometry and produces a stable BO landscape. We demonstrate the approach on synthetic benchmarks, real-world time-series datasets, and an additive manufacturing case study predicting melt-pool geometry, achieving superior predictive accuracy and uncertainty calibration relative to baselines including Large Language Model (LLM)-guided search. This framework establishes a reusable probabilistic geometry for kernel search, with direct relevance to GP modeling and deep kernel learning.

</details>


### [63] [Inverting Non-Injective Functions with Twin Neural Network Regression](https://arxiv.org/abs/2601.05378)
*Sebastian J. Wetzel*

Main category: cs.LG

TL;DR: 该论文提出了一种使用孪生神经网络回归和k近邻搜索的确定性框架，用于反转非单射函数，通过限制子域实现局部可逆性。


<details>
  <summary>Details</summary>
Motivation: 非单射函数通常不可逆，但可以在局部子域上实现可逆性。现有方法难以有效处理非单射函数的反转问题，需要一种能够处理多解情况并选择最优解的方法。

Method: 结合孪生神经网络回归和k近邻搜索：1）使用已知输入变量x^anchor预测调整量来估计未知x^new；2）通过k近邻搜索在目标变量变化时确定输入参数；3）处理数据定义或数学公式描述的非单射函数。

Result: 该方法在玩具问题和机器人臂控制问题上得到验证，能够有效反转非单射函数，无论是基于数据定义的函数还是数学公式描述的函數。

Conclusion: 提出的确定性框架为反转非单射函数提供了有效解决方案，通过局部可逆性和优先解选择机制，解决了非单射函数反转的核心挑战。

Abstract: Non-injective functions are not invertible. However, non-injective functions can be restricted to sub-domains on which they are locally injective and surjective and thus invertible if the dimensionality between input and output spaces are the same. Further, even if the dimensionalities do not match it is often possible to choose a preferred solution from many possible solutions. Twin neural network regression is naturally capable of incorporating these properties to invert non-injective functions. Twin neural network regression is trained to predict adjustments to well known input variables $\mathbf{x}^{\text{anchor}}$ to obtain an estimate for an unknown $\mathbf{x}^{\text{new}}$ under a change of the target variable from $\mathbf{y}^{\text{anchor}}$ to $\mathbf{y}^{\text{new}}$. In combination with k-nearest neighbor search, I propose a deterministic framework that finds input parameters to a given target variable of non-injective functions. The method is demonstrated by inverting non-injective functions describing toy problems and robot arm control that are a) defined by data or b) known as mathematical formula.

</details>


### [64] [Imitation Learning for Combinatorial Optimisation under Uncertainty](https://arxiv.org/abs/2601.05383)
*Prakash Gawas,Antoine Legrain,Louis-Martin Rousseau*

Main category: cs.LG

TL;DR: 本文提出了一个系统性的专家分类框架，用于组合优化中的模仿学习，将专家按不确定性处理方式、最优性水平和交互模式三个维度分类，并开发了支持多专家查询和交互策略的广义DAgger算法。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习研究在组合优化中使用了各种专家构造方法，但缺乏统一的框架来表征其建模假设、计算特性和对学习性能的影响。

Method: 提出了基于三个维度的专家分类框架：(1)不确定性处理方式（短视、确定性、全信息、两阶段随机、多阶段随机）；(2)最优性水平（任务最优和近似专家）；(3)交互模式（一次性监督到迭代交互）。基于此开发了广义DAgger算法。

Result: 在动态医生-患者分配问题上的实验表明，从随机专家学习的策略始终优于确定性或全信息专家，交互式学习能以更少的专家演示获得更好的解质量。当随机优化计算困难时，聚合确定性专家是有效替代方案。

Conclusion: 该分类框架为组合优化中的模仿学习提供了系统分析工具，随机专家和交互式学习策略能显著提升学习性能，为实际应用中的专家选择提供了指导。

Abstract: Imitation learning (IL) provides a data-driven framework for approximating policies for large-scale combinatorial optimisation problems formulated as sequential decision problems (SDPs), where exact solution methods are computationally intractable. A central but underexplored aspect of IL in this context is the role of the \emph{expert} that generates training demonstrations. Existing studies employ a wide range of expert constructions, yet lack a unifying framework to characterise their modelling assumptions, computational properties, and impact on learning performance.
  This paper introduces a systematic taxonomy of experts for IL in combinatorial optimisation under uncertainty. Experts are classified along three dimensions: (i) their treatment of uncertainty, including myopic, deterministic, full-information, two-stage stochastic, and multi-stage stochastic formulations; (ii) their level of optimality, distinguishing task-optimal and approximate experts; and (iii) their interaction mode with the learner, ranging from one-shot supervision to iterative, interactive schemes. Building on this taxonomy, we propose a generalised Dataset Aggregation (DAgger) algorithm that supports multiple expert queries, expert aggregation, and flexible interaction strategies.
  The proposed framework is evaluated on a dynamic physician-to-patient assignment problem with stochastic arrivals and capacity constraints. Computational experiments compare learning outcomes across expert types and interaction regimes. The results show that policies learned from stochastic experts consistently outperform those learned from deterministic or full-information experts, while interactive learning improves solution quality using fewer expert demonstrations. Aggregated deterministic experts provide an effective alternative when stochastic optimisation becomes computationally challenging.

</details>


### [65] [DynaSTy: A Framework for SpatioTemporal Node Attribute Prediction in Dynamic Graphs](https://arxiv.org/abs/2601.05391)
*Namrata Banerji,Tanya Berger-Wolf*

Main category: cs.LG

TL;DR: 提出了一种动态图上的多步节点属性预测模型，通过将动态邻接矩阵作为注意力偏置注入Transformer架构，能够处理不同样本间图结构变化的场景。


<details>
  <summary>Details</summary>
Motivation: 现有时空图神经网络通常假设静态邻接矩阵，无法有效处理动态图结构（如不同主体的脑网络、不同背景的金融系统等）的多步预测需求。

Method: 端到端动态边偏置时空模型，输入节点属性时间序列和邻接矩阵时间序列，使用Transformer架构将邻接矩阵作为可调节的注意力偏置，采用掩码节点-时间预训练目标、计划采样和水平加权损失来缓解长期预测的误差累积。

Result: 在RMSE和MAE指标上 consistently 优于强基线方法。

Conclusion: 该方法能够有效处理动态图结构变化，在多系统设置下实现准确的节点属性多步预测。

Abstract: Accurate multistep forecasting of node-level attributes on dynamic graphs is critical for applications ranging from financial trust networks to biological networks. Existing spatiotemporal graph neural networks typically assume a static adjacency matrix. In this work, we propose an end-to-end dynamic edge-biased spatiotemporal model that ingests a multi-dimensional timeseries of node attributes and a timeseries of adjacency matrices, to predict multiple future steps of node attributes. At each time step, our transformer-based model injects the given adjacency as an adaptable attention bias, allowing the model to focus on relevant neighbors as the graph evolves. We further deploy a masked node-time pretraining objective that primes the encoder to reconstruct missing features, and train with scheduled sampling and a horizon-weighted loss to mitigate compounding error over long horizons. Unlike prior work, our model accommodates dynamic graphs that vary across input samples, enabling forecasting in multi-system settings such as brain networks across different subjects, financial systems in different contexts, or evolving social systems. Empirical results demonstrate that our method consistently outperforms strong baselines on Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE).

</details>


### [66] [Interactive Distillation for Cooperative Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2601.05407)
*Minwoo Cho,Batuhan Altundas,Matthew Gombolay*

Main category: cs.LG

TL;DR: HINT框架通过分层强化学习和伪离策略学习解决多智能体强化学习中知识蒸馏的三个关键瓶颈，在复杂合作任务中显著提升性能


<details>
  <summary>Details</summary>
Motivation: 解决多智能体知识蒸馏面临的三大挑战：1）复杂领域中高性能教学策略合成困难；2）教师策略在分布外状态下的推理难题；3）分散式学生与集中式教师观测空间不匹配

Method: 提出HINT框架：1）使用分层RL构建可扩展的高性能教师；2）引入伪离策略RL，允许教师策略同时使用教师和学生经验进行更新；3）应用基于性能的过滤机制保留结果相关的指导

Result: 在FireCommander资源分配和MARINE战术战斗等挑战性合作领域进行评估，HINT相比基线方法在成功率上提升60%至165%

Conclusion: HINT框架有效解决了多智能体知识蒸馏的关键瓶颈，通过分层教学和伪离策略学习显著提升了多智能体强化学习的性能

Abstract: Knowledge distillation (KD) has the potential to accelerate MARL by employing a centralized teacher for decentralized students but faces key bottlenecks. Specifically, there are (1) challenges in synthesizing high-performing teaching policies in complex domains, (2) difficulties when teachers must reason in out-of-distribution (OOD) states, and (3) mismatches between the decentralized students' and the centralized teacher's observation spaces. To address these limitations, we propose HINT (Hierarchical INteractive Teacher-based transfer), a novel KD framework for MARL in a centralized training, decentralized execution setup. By leveraging hierarchical RL, HINT provides a scalable, high-performing teacher. Our key innovation, pseudo off-policy RL, enables the teacher policy to be updated using both teacher and student experience, thereby improving OOD adaptation. HINT also applies performance-based filtering to retain only outcome-relevant guidance, reducing observation mismatches. We evaluate HINT on challenging cooperative domains (e.g., FireCommander for resource allocation, MARINE for tactical combat). Across these benchmarks, HINT outperforms baselines, achieving improvements of 60% to 165% in success rate.

</details>


### [67] [Efficient Inference for Noisy LLM-as-a-Judge Evaluation](https://arxiv.org/abs/2601.05420)
*Yiqun T Chen,Sizhu Lu,Sijia Li,Moran Guo,Shengyi Li*

Main category: cs.LG

TL;DR: 本文系统研究了大语言模型（LLM）作为评估器时的偏差校正方法，比较了测量误差校正和预测驱动推断（PPI）两种方法，通过半参数效率理论推导了高效估计量，并分析了PPI方法在特定条件下的方差优势。


<details>
  <summary>Details</summary>
Motivation: LLM作为评估器存在系统性误差，需要有效的偏差校正方法来提高评估的准确性。现有方法包括测量误差校正和PPI方法，但缺乏系统的理论比较和性能分析。

Method: 基于半参数效率理论，推导了高效影响函数（EIF）为基础的高效估计量，统一了两种校正方法。通过理论分析和模拟实验验证了PPI方法在特定条件下的方差优势。

Result: 理论分析表明PPI方法在特定条件下具有更小的渐近方差，模拟实验和真实数据案例验证了该结论。

Conclusion: PPI方法在LLM评估偏差校正中具有理论优势，特别是在小样本黄金标准标签可用时，能有效降低估计方差。

Abstract: Large language models (LLMs) are increasingly used as automatic evaluators of generative AI outputs, a paradigm often referred to as "LLM-as-a-judge." In practice, LLM judges are imperfect predictions for the underlying truth and can exhibit systematic, non-random errors. Two main approaches have recently been proposed to address this issue: (i) direct measurementerror correction based on misclassification models such as Rogan-Gladen-style estimators, and (ii) surrogate-outcome approaches such as prediction-powered inference (PPI), which correct bias by calibrating prediction residuals on a small set of gold-standard human labels. In this paper, we systematically study the performance of these two approaches for estimating mean parameters (e.g., average benchmark scores or pairwise win rates). Leveraging tools from semiparametric efficiency theory, we unify the two classes of estimators by deriving explicit forms of efficient influence function (EIF)-based efficient estimators and characterize conditions under which PPI-style estimators attain strictly smaller asymptotic variance than measurement-error corrections. We verify our theoretical results in simulations and demonstrate the methods on real-data examples. We provide an implementation of the benchmarked methods and comparison utilities at https://github.com/yiqunchen/debias-llm-as-a-judge.

</details>


### [68] [Prediction of Fault Slip Tendency in CO${_2}$ Storage using Data-space Inversion](https://arxiv.org/abs/2601.05431)
*Xiaowen He,Su Jiang,Louis J. Durlofsky*

Main category: cs.LG

TL;DR: 该研究提出了基于变分自编码器(VAE)的数据空间反演(DSI)框架，用于CO2封存项目中预测压力、应力、应变场和断层滑移趋势，避免了传统后验地质模型生成的复杂性。


<details>
  <summary>Details</summary>
Motivation: 传统基于模型的历史匹配方法在耦合流动-地质力学问题中应用困难，需要生成校准观测数据的后验地质模型，计算成本高昂。

Method: 使用VAE和DSI框架，通过训练堆叠卷积LSTM层的VAE来表示关键物理场，利用先验模拟结果和观测数据直接推断后验分布，无需生成后验地质模型。

Result: 在合成3D双断层系统中验证，DSI-VAE框架能够准确预测压力、应变、应力场和断层滑移趋势，并显著降低关键地质力学和断层参数的不确定性。

Conclusion: VAE-based DSI框架为耦合流动-地质力学问题提供了一种高效准确的后验预测方法，特别适用于CO2封存等地下工程应用。

Abstract: Accurately assessing the potential for fault slip is essential in many subsurface operations. Conventional model-based history matching methods, which entail the generation of posterior geomodels calibrated to observed data, can be challenging to apply in coupled flow-geomechanics problems with faults. In this work, we implement a variational autoencoder (VAE)-based data-space inversion (DSI) framework to predict pressure, stress and strain fields, and fault slip tendency, in CO${_2}$ storage projects. The main computations required by the DSI workflow entail the simulation of O(1000) prior geomodels. The posterior distributions for quantities of interest are then inferred directly from prior simulation results and observed data, without the need to generate posterior geomodels. The model used here involves a synthetic 3D system with two faults. Realizations of heterogeneous permeability and porosity fields are generated using geostatistical software, and uncertain geomechanical and fault parameters are sampled for each realization from prior distributions. Coupled flow-geomechanics simulations for these geomodels are conducted using GEOS. A VAE with stacked convolutional long short-term memory layers is trained, using the prior simulation results, to represent pressure, strain, effective normal stress and shear stress fields in terms of latent variables. The VAE parameterization is used with DSI for posterior predictions, with monitoring wells providing observed pressure and strain data. Posterior results for synthetic true models demonstrate that the DSI-VAE framework gives accurate predictions for pressure, strain, and stress fields and for fault slip tendency. The framework is also shown to reduce uncertainty in key geomechanical and fault parameters.

</details>


### [69] [RingSQL: Generating Synthetic Data with Schema-Independent Templates for Text-to-SQL Reasoning Models](https://arxiv.org/abs/2601.05451)
*Marko Sterbentz,Kevin Cushing,Cameron Barrie,Kristian J. Hammond*

Main category: cs.LG

TL;DR: RingSQL是一个混合数据生成框架，结合了模式无关的查询模板和基于LLM的自然语言问题转述，解决了文本到SQL系统高质量训练数据稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 文本到SQL系统的进展受限于高质量训练数据的稀缺性。手动创建数据成本高昂，现有的合成方法在可靠性和可扩展性之间存在权衡。

Method: RingSQL采用混合方法：使用模式无关的查询模板确保SQL正确性，结合基于大语言模型的自然语言问题转述来提供语言多样性。

Result: 在六个文本到SQL基准测试中，使用RingSQL生成数据训练的模型平均准确率提升了+2.3%。

Conclusion: RingSQL框架在保持SQL正确性的同时提供了广泛的语言多样性，有效提升了文本到SQL模型的性能。

Abstract: Recent advances in text-to-SQL systems have been driven by larger models and improved datasets, yet progress is still limited by the scarcity of high-quality training data. Manual data creation is expensive, and existing synthetic methods trade off reliability and scalability. Template-based approaches ensure correct SQL but require schema-specific templates, while LLM-based generation scales easily but lacks quality and correctness guarantees. We introduce RingSQL, a hybrid data generation framework that combines schema-independent query templates with LLM-based paraphrasing of natural language questions. This approach preserves SQL correctness across diverse schemas while providing broad linguistic variety. In our experiments, we find that models trained using data produced by RingSQL achieve an average gain in accuracy of +2.3% across six text-to-SQL benchmarks when compared to models trained on other synthetic data. We make our code available at https://github.com/nu-c3lab/RingSQL.

</details>


### [70] [Efficient Differentiable Causal Discovery via Reliable Super-Structure Learning](https://arxiv.org/abs/2601.05474)
*Pingchuan Ma,Qixin Zhang,Shuai Wang,Dacheng Tao*

Main category: cs.LG

TL;DR: ALVGL是一种新颖的可微分因果发现增强方法，通过稀疏低秩分解学习数据精度矩阵，构建超结构来指导优化过程，提高准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有可微分因果发现在高维数据或存在潜变量时面临搜索空间大、目标函数复杂和图形约束困难，需要更有效的超结构指导方法。

Method: 采用稀疏低秩分解学习数据精度矩阵，使用ADMM优化算法识别与因果结构相关的成分，构建包含真实因果图的超结构，用于初始化标准可微分因果发现方法。

Result: 在合成和真实数据集上的实验表明，ALVGL在多种结构因果模型（包括高斯和非高斯设置，有无潜变量）中均达到最先进准确性，并显著提升优化效率。

Conclusion: ALVGL为可微分因果发现提供了可靠有效的解决方案，通过超结构引导显著改善了优化过程的准确性和效率。

Abstract: Recently, differentiable causal discovery has emerged as a promising approach to improve the accuracy and efficiency of existing methods. However, when applied to high-dimensional data or data with latent confounders, these methods, often based on off-the-shelf continuous optimization algorithms, struggle with the vast search space, the complexity of the objective function, and the nontrivial nature of graph-theoretical constraints. As a result, there has been a surge of interest in leveraging super-structures to guide the optimization process. Nonetheless, learning an appropriate super-structure at the right level of granularity, and doing so efficiently across various settings, presents significant challenges.
  In this paper, we propose ALVGL, a novel and general enhancement to the differentiable causal discovery pipeline. ALVGL employs a sparse and low-rank decomposition to learn the precision matrix of the data. We design an ADMM procedure to optimize this decomposition, identifying components in the precision matrix that are most relevant to the underlying causal structure. These components are then combined to construct a super-structure that is provably a superset of the true causal graph. This super-structure is used to initialize a standard differentiable causal discovery method with a more focused search space, thereby improving both optimization efficiency and accuracy.
  We demonstrate the versatility of ALVGL by instantiating it across a range of structural causal models, including both Gaussian and non-Gaussian settings, with and without unmeasured confounders. Extensive experiments on synthetic and real-world datasets show that ALVGL not only achieves state-of-the-art accuracy but also significantly improves optimization efficiency, making it a reliable and effective solution for differentiable causal discovery.

</details>


### [71] [MaxCode: A Max-Reward Reinforcement Learning Framework for Automated Code Optimization](https://arxiv.org/abs/2601.05475)
*Jiefu Ou,Sapana Chaudhary,Kaj Bostrom,Nathaniel Weir,Shuai Zhang,Huzefa Rangwala,George Karypis*

Main category: cs.LG

TL;DR: MaxCode是一个基于推理时搜索的代码优化框架，通过执行反馈和自然语言批评模型来指导LLM迭代优化代码性能


<details>
  <summary>Details</summary>
Motivation: 解决LLM在代码优化中的两个关键挑战：编写优化代码的复杂性（需要系统、算法和语言专业知识）以及解释性能指标（如时序和设备利用率）的困难

Method: 提出MaxCode框架，将现有搜索方法统一到最大奖励强化学习框架下，集成自然语言批评模型将原始执行反馈转换为诊断性见解，并使用生成式奖励模型对潜在解决方案进行重排序

Result: 在KernelBench（CUDA）和PIE（C++）优化基准测试中，MaxCode相比基线方法在绝对加速值和相对加速排名上分别实现了20.3%和10.1%的相对改进

Conclusion: MaxCode通过推理时搜索和丰富的反馈机制有效提升了LLM的代码优化能力，为高性能代码生成提供了新的解决方案

Abstract: Large Language Models (LLMs) demonstrate strong capabilities in general coding tasks but encounter two key challenges when optimizing code: (i) the complexity of writing optimized code (such as performant CUDA kernels and competition-level CPU code) requires expertise in systems, algorithms and specific languages and (ii) requires interpretation of performance metrics like timing and device utilization beyond binary correctness. In this work, we explore inference-time search algorithms that guide the LLM to discover better solutions through iterative refinement based on execution feedback. Our approach, called MaxCode unifies existing search methods under a max-reward reinforcement learning framework, making the observation and action-value functions modular for modification. To enhance the observation space, we integrate a natural language critique model that converts raw execution feedback into diagnostic insights about errors and performance bottlenecks, and the best-discounted reward seen so far. Together, these provide richer input to the code proposal function. To improve exploration during search, we train a generative reward-to-go model using action values from rollouts to rerank potential solutions. Testing on the KernelBench (CUDA) and PIE (C++) optimization benchmarks shows that MaxCode improves optimized code performance compared to baselines, achieving 20.3% and 10.1% relative improvements in absolute speedup value and relative speedup ranking, respectively.

</details>


### [72] [Hi-ZFO: Hierarchical Zeroth- and First-Order LLM Fine-Tuning via Importance-Guided Tensor Selection](https://arxiv.org/abs/2601.05501)
*Feihu Jin,Ying Tan*

Main category: cs.LG

TL;DR: 本文提出Hi-ZFO混合优化框架，结合零阶和一阶优化方法的优势，解决大语言模型微调中的局部最小值和收敛速度问题


<details>
  <summary>Details</summary>
Motivation: 标准一阶优化方法容易使模型陷入尖锐、泛化能力差的局部最小值，而零阶方法虽然探索性强但收敛慢，且在生成任务中估计方差大、效率低

Method: Hi-ZFO通过层次化分区策略，基于层重要性分析，对关键层使用精确的一阶梯度更新，对不敏感层使用零阶优化作为有益随机性来源

Result: 在生成、数学推理和代码推理等任务上的验证表明，Hi-ZFO在获得优越性能的同时显著减少了训练时间

Conclusion: 层次化混合优化框架为LLM微调提供了有效解决方案，证明了结合不同优化方法优势的可行性

Abstract: Fine-tuning large language models (LLMs) using standard first-order (FO) optimization often drives training toward sharp, poorly generalizing minima. Conversely, zeroth-order (ZO) methods offer stronger exploratory behavior without relying on explicit gradients, yet suffer from slow convergence. More critically, our analysis reveals that in generative tasks, the vast output and search space significantly amplify estimation variance, rendering ZO methods both noisy and inefficient. To address these challenges, we propose \textbf{Hi-ZFO} (\textbf{Hi}erarchical \textbf{Z}eroth- and \textbf{F}irst-\textbf{O}rder optimization), a hybrid framework designed to synergize the precision of FO gradients with the exploratory capability of ZO estimation. Hi-ZFO adaptively partitions the model through layer-wise importance profiling, applying precise FO updates to critical layers while leveraging ZO optimization for less sensitive ones. Notably, ZO in Hi-ZFO is not merely a memory-saving surrogate; it is intentionally introduced as a source of "beneficial stochasticity" to help the model escape the local minima where pure FO optimization tends to stagnate. Validated across diverse generative, mathematical, and code reasoning tasks, Hi-ZFO consistently achieves superior performance while significantly reducing the training time. These results demonstrate the effectiveness of hierarchical hybrid optimization for LLM fine-tuning.

</details>


### [73] [Over-Searching in Search-Augmented Large Language Models](https://arxiv.org/abs/2601.05503)
*Roy Xie,Deepak Gopinath,David Qiu,Dong Lin,Haitian Sun,Saloni Potdar,Bhuwan Dhingra*

Main category: cs.LG

TL;DR: 本文系统评估了搜索增强型大语言模型中的过度搜索问题，发现搜索在可回答查询上提高准确性但在不可回答查询上损害弃权能力，并提出了TPC指标来衡量性能-成本权衡。


<details>
  <summary>Details</summary>
Motivation: 搜索增强型LLMs在知识密集型任务中表现出色，但存在过度搜索问题——不必要地调用搜索工具，导致计算效率低下和因引入无关上下文而产生幻觉。

Method: 通过多维度系统评估（包括查询类型、模型类别、检索条件和多轮对话），引入Tokens Per Correctness (TPC)指标来量化过度搜索，并研究查询和检索层面的缓解方法。

Result: 研究发现：(i)搜索提高可回答查询的准确性但损害不可回答查询的弃权能力；(ii)过度搜索在复杂推理模型和深度研究系统中更明显，受噪声检索加剧，在多轮对话中累积；(iii)检索证据的组成至关重要，负面证据的存在改善弃权。

Conclusion: 提出了TPC指标来量化搜索增强型LLMs的性能-成本权衡，并发布OverSearchQA数据集以促进高效搜索增强型LLMs的持续研究。

Abstract: Search-augmented large language models (LLMs) excel at knowledge-intensive tasks by integrating external retrieval. However, they often over-search -- unnecessarily invoking search tool even when it does not improve response quality, which leads to computational inefficiency and hallucinations by incorporating irrelevant context. In this work, we conduct a systematic evaluation of over-searching across multiple dimensions, including query types, model categories, retrieval conditions, and multi-turn conversations. Our finding shows: (i) search generally improves answer accuracy on answerable queries but harms abstention on unanswerable ones; (ii) over-searching is more pronounced in complex reasoning models and deep research systems, is exacerbated by noisy retrieval, and compounds across turns in multi-turn conversations; and (iii) the composition of retrieved evidence is crucial, as the presence of negative evidence improves abstention. To quantify over-searching, we introduce Tokens Per Correctness (TPC), an evaluation metric that captures the performance-cost trade-off for search-augmented LLMs. Lastly, we investigate mitigation approaches at both the query and retrieval levels and release the OverSearchQA to foster continued research into efficient search-augmented LLMs.

</details>


### [74] [Toward an Integrated Cross-Urban Accident Prevention System: A Multi-Task Spatial-Temporal Learning Framework for Urban Safety Management](https://arxiv.org/abs/2601.05521)
*Jiayu Fang,Zhiqi Shao,Haoning Xi,Boris Choy,Junbin Gao*

Main category: cs.LG

TL;DR: 提出了MLA-STNet系统，通过多任务学习解决跨城市事故预测问题，整合时空地理和语义注意力模块，在纽约和芝加哥数据集上验证了优于现有方法的效果。


<details>
  <summary>Details</summary>
Motivation: 城市事故数据存在异质性、不一致报告、稀疏性和噪声等问题，加上碎片化治理和不兼容的报告标准，阻碍了跨城市事故预防系统的开发。

Method: MLA-STNet包含两个互补模块：STG-MA（时空地理注意力）用于抑制不稳定时空波动和加强长期时间依赖；STS-MA（时空语义注意力）通过共享参数设计缓解跨城市异质性。

Result: 在75个实验和两种预测场景下，MLA-STNet相比最先进基线方法实现了RMSE降低6%、召回率提高8%、MAP提高5%，并在50%输入噪声下保持性能变化小于1%。

Conclusion: MLA-STNet有效地将异构城市数据集统一到一个可扩展、鲁棒且可解释的跨城市事故预防系统中，为协调和数据驱动的城市安全管理铺平了道路。

Abstract: The development of a cross-city accident prevention system is particularly challenging due to the heterogeneity, inconsistent reporting, and inherently clustered, sparse, cyclical, and noisy nature of urban accident data. These intrinsic data properties, combined with fragmented governance and incompatible reporting standards, have long hindered the creation of an integrated, cross-city accident prevention framework. To address this gap, we propose the Mamba Local-ttention Spatial-Temporal Network MLA-STNet, a unified system that formulates accident risk prediction as a multi-task learning problem across multiple cities. MLA-STNet integrates two complementary modules: (i)the Spatio-Temporal Geographical Mamba-Attention (STG-MA), which suppresses unstable spatio-temporal fluctuations and strengthens long-range temporal dependencies; and (ii) the Spatio-Temporal Semantic Mamba-Attention (STS-MA), which mitigates cross-city heterogeneity through a shared-parameter design that jointly trains all cities while preserving individual semantic representation spaces. We validate the proposed framework through 75 experiments under two forecasting scenarios, full-day and high-frequency accident periods, using real-world datasets from New York City and Chicago. Compared with the state-of-the-art baselines, MLA-STNet achieves up to 6% lower RMSE, 8% higher Recall, and 5% higher MAP, while maintaining less than 1% performance variation under 50% input noise. These results demonstrate that MLA-STNet effectively unifies heterogeneous urban datasets within a scalable, robust, and interpretable Cross-City Accident Prevention System, paving the way for coordinated and data-driven urban safety management.

</details>


### [75] [DeMa: Dual-Path Delay-Aware Mamba for Efficient Multivariate Time Series Analysis](https://arxiv.org/abs/2601.05527)
*Rui An,Haohao Qu,Wenqi Fan,Xuequn Shang,Qing Li*

Main category: cs.LG

TL;DR: DeMa是一个双路径延迟感知Mamba架构，针对多变量时间序列分析中传统Transformer的二次计算复杂度和Mamba缺乏显式跨变量建模的问题，通过分解时间序列的动态特性和引入延迟感知线性注意力，在保持线性复杂度的同时显著提升了多变量时间序列建模效果。


<details>
  <summary>Details</summary>
Motivation: 解决Transformer在多变量时间序列分析中的高计算复杂度和内存开销问题，同时克服vanilla Mamba在跨变量建模、动态特性解耦和时间延迟交互建模方面的不足。

Method: 提出双路径延迟感知Mamba骨干网络（DeMa）：1）将MTS分解为序列内时间动态和序列间交互；2）时间路径使用Mamba-SSD模块捕获单个序列的长程动态；3）变量路径使用Mamba-DALA模块集成延迟感知线性注意力来建模跨变量依赖关系。

Result: 在五个代表性任务（长短期预测、数据插补、异常检测和序列分类）上的广泛实验表明，DeMa实现了最先进的性能，同时提供了显著的计算效率。

Conclusion: DeMa在保持Mamba线性复杂度优势的同时，显著提升了多变量时间序列建模的适用性，为智能应用提供了高效且准确的MTS分析解决方案。

Abstract: Accurate and efficient multivariate time series (MTS) analysis is increasingly critical for a wide range of intelligent applications. Within this realm, Transformers have emerged as the predominant architecture due to their strong ability to capture pairwise dependencies. However, Transformer-based models suffer from quadratic computational complexity and high memory overhead, limiting their scalability and practical deployment in long-term and large-scale MTS modeling. Recently, Mamba has emerged as a promising linear-time alternative with high expressiveness. Nevertheless, directly applying vanilla Mamba to MTS remains suboptimal due to three key limitations: (i) the lack of explicit cross-variate modeling, (ii) difficulty in disentangling the entangled intra-series temporal dynamics and inter-series interactions, and (iii) insufficient modeling of latent time-lag interaction effects. These issues constrain its effectiveness across diverse MTS tasks. To address these challenges, we propose DeMa, a dual-path delay-aware Mamba backbone. DeMa preserves Mamba's linear-complexity advantage while substantially improving its suitability for MTS settings. Specifically, DeMa introduces three key innovations: (i) it decomposes the MTS into intra-series temporal dynamics and inter-series interactions; (ii) it develops a temporal path with a Mamba-SSD module to capture long-range dynamics within each individual series, enabling series-independent, parallel computation; and (iii) it designs a variate path with a Mamba-DALA module that integrates delay-aware linear attention to model cross-variate dependencies. Extensive experiments on five representative tasks, long- and short-term forecasting, data imputation, anomaly detection, and series classification, demonstrate that DeMa achieves state-of-the-art performance while delivering remarkable computational efficiency.

</details>


### [76] [Scalable Heterogeneous Graph Learning via Heterogeneous-aware Orthogonal Prototype Experts](https://arxiv.org/abs/2601.05537)
*Wei Zhou,Hong Huang,Ruize Shi,Bang Liu*

Main category: cs.LG

TL;DR: HOPE框架通过可学习的原型路由和专家正交化解决异构图神经网络中线性投影瓶颈问题，提升模型性能


<details>
  <summary>Details</summary>
Motivation: 异构图神经网络(HGNNs)的解码阶段仍使用单一共享线性头，无法处理上下文多样性和长尾分布问题，导致语义丢失和节点服务不均

Method: 提出HOPE框架，使用基于可学习原型的路由机制将实例分配给专家，并引入专家正交化来促进多样性并防止专家崩溃

Result: 在四个真实数据集上的实验表明，HOPE在SOTA HGNN骨干网络上取得了一致的性能提升，且开销极小

Conclusion: HOPE是一个即插即用的预测头替代方案，能有效解决异构图中的线性投影瓶颈问题

Abstract: Heterogeneous Graph Neural Networks(HGNNs) have advanced mainly through better encoders, yet their decoding/projection stage still relies on a single shared linear head, assuming it can map rich node embeddings to labels. We call this the Linear Projection Bottleneck: in heterogeneous graphs, contextual diversity and long-tail shifts make a global head miss fine semantics, overfit hub nodes, and underserve tail nodes. While Mixture-of-Experts(MoE) could help, naively applying it clashes with structural imbalance and risks expert collapse. We propose a Heterogeneous-aware Orthogonal Prototype Experts framework named HOPE, a plug-and-play replacement for the standard prediction head. HOPE uses learnable prototype-based routing to assign instances to experts by similarity, letting expert usage follow the natural long-tail distribution, and adds expert orthogonalization to encourage diversity and prevent collapse. Experiments on four real datasets show consistent gains across SOTA HGNN backbones with minimal overhead.

</details>


### [77] [Buffered AUC maximization for scoring systems via mixed-integer optimization](https://arxiv.org/abs/2601.05544)
*Moe Shiina,Shunnosuke Ikeda,Yuichi Takano*

Main category: cs.LG

TL;DR: 本文提出了一种基于混合整数线性优化（MILO）的评分系统构建方法，直接最大化缓冲AUC（bAUC）作为AUC的最紧凹下界。


<details>
  <summary>Details</summary>
Motivation: 现有的评分系统构建方法虽然使用混合整数优化技术，但未直接最大化AUC这一重要评价指标。

Method: 建立MILO框架，在限制评分系统问题数量的组稀疏约束下最大化bAUC。

Result: 在公开真实数据集上的实验表明，该方法相比基于正则化和逐步回归的基线方法能构建具有更高AUC值的评分系统。

Conclusion: 该研究推动了MIO技术在开发高可解释性分类模型方面的进展。

Abstract: A scoring system is a linear classifier composed of a small number of explanatory variables, each assigned a small integer coefficient. This system is highly interpretable and allows predictions to be made with simple manual calculations without the need for a calculator. Several previous studies have used mixed-integer optimization (MIO) techniques to develop scoring systems for binary classification; however, they have not focused on directly maximizing AUC (i.e., area under the receiver operating characteristic curve), even though AUC is recognized as an essential evaluation metric for scoring systems. Our goal herein is to establish an effective MIO framework for constructing scoring systems that directly maximize the buffered AUC (bAUC) as the tightest concave lower bound on AUC. Our optimization model is formulated as a mixed-integer linear optimization (MILO) problem that maximizes bAUC subject to a group sparsity constraint for limiting the number of questions in the scoring system. Computational experiments using publicly available real-world datasets demonstrate that our MILO method can build scoring systems with superior AUC values compared to the baseline methods based on regularization and stepwise regression. This research contributes to the advancement of MIO techniques for developing highly interpretable classification models.

</details>


### [78] [Learn to Evolve: Self-supervised Neural JKO Operator for Wasserstein Gradient Flow](https://arxiv.org/abs/2601.05583)
*Xue Feng,Li Wang,Deanna Needell,Rongjie Lai*

Main category: cs.LG

TL;DR: 本文提出了一种自监督学习方法，无需数值求解JKO子问题即可学习JKO解算子，通过Learn-to-Evolve算法联合学习算子和轨迹，显著降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: JKO方案虽然为计算Wasserstein梯度流提供了稳定的变分框架，但其实际应用受到重复求解JKO子问题的高计算成本限制。

Method: 提出Learn-to-Evolve算法，交替进行轨迹生成和算子更新，通过自监督方式学习JKO解算子，该算子能将输入密度直接映射到对应JKO子问题的最小化解。

Result: 数值实验表明，该方法在不同能量和初始条件下都表现出准确性、稳定性和鲁棒性，生成的数据逐渐逼近真实JKO轨迹。

Conclusion: 该方法通过数据增强显著提高了学习算子的泛化能力，为高效计算Wasserstein梯度流提供了实用解决方案。

Abstract: The Jordan-Kinderlehrer-Otto (JKO) scheme provides a stable variational framework for computing Wasserstein gradient flows, but its practical use is often limited by the high computational cost of repeatedly solving the JKO subproblems. We propose a self-supervised approach for learning a JKO solution operator without requiring numerical solutions of any JKO trajectories. The learned operator maps an input density directly to the minimizer of the corresponding JKO subproblem, and can be iteratively applied to efficiently generate the gradient-flow evolution. A key challenge is that only a number of initial densities are typically available for training. To address this, we introduce a Learn-to-Evolve algorithm that jointly learns the JKO operator and its induced trajectories by alternating between trajectory generation and operator updates. As training progresses, the generated data increasingly approximates true JKO trajectories. Meanwhile, this Learn-to-Evolve strategy serves as a natural form of data augmentation, significantly enhancing the generalization ability of the learned operator. Numerical experiments demonstrate the accuracy, stability, and robustness of the proposed method across various choices of energies and initial conditions.

</details>


### [79] [Poisson Hyperplane Processes with Rectified Linear Units](https://arxiv.org/abs/2601.05586)
*Shufei Ge,Shijia Wang,Lloyd Elliott*

Main category: cs.LG

TL;DR: 该论文建立了泊松超平面过程与两层ReLU神经网络之间的联系，提出了基于PHP的神经网络模型，并通过退火顺序蒙特卡洛算法进行贝叶斯推断，实验证明该方法优于传统两层ReLU神经网络。


<details>
  <summary>Details</summary>
Motivation: 虽然ReLU激活函数在神经网络中表现出色，但传统两层ReLU神经网络在处理大规模问题时存在局限性。作者旨在探索泊松超平面过程与神经网络的理论联系，开发更高效的替代模型。

Method: 提出泊松超平面过程作为两层ReLU神经网络的概率表示，利用高斯先验构建模型，通过分解命题实现大规模问题扩展，并设计退火顺序蒙特卡洛算法进行贝叶斯推断。

Result: 数值实验表明，基于PHP的神经网络模型在性能上优于传统两层ReLU神经网络，特别是在大规模问题上表现更佳。

Conclusion: 泊松超平面过程为两层ReLU神经网络提供了有效的概率表示框架，所提出的方法具有良好的可扩展性和优越性能，为神经网络理论研究和实际应用提供了新思路。

Abstract: Neural networks have shown state-of-the-art performances in various classification and regression tasks. Rectified linear units (ReLU) are often used as activation functions for the hidden layers in a neural network model. In this article, we establish the connection between the Poisson hyperplane processes (PHP) and two-layer ReLU neural networks. We show that the PHP with a Gaussian prior is an alternative probabilistic representation to a two-layer ReLU neural network. In addition, we show that a two-layer neural network constructed by PHP is scalable to large-scale problems via the decomposition propositions. Finally, we propose an annealed sequential Monte Carlo algorithm for Bayesian inference. Our numerical experiments demonstrate that our proposed method outperforms the classic two-layer ReLU neural network. The implementation of our proposed model is available at https://github.com/ShufeiGe/Pois_Relu.git.

</details>


### [80] [PaCoRe: Learning to Scale Test-Time Compute with Parallel Coordinated Reasoning](https://arxiv.org/abs/2601.05593)
*Jingcheng Hu,Yinmin Zhang,Shijie Shang,Xiaobo Yang,Yue Peng,Zhewei Huang,Hebin Zhou,Xin Wu,Jie Cheng,Fanqi Wan,Xiangwen Kong,Chengyuan Yao,Kaiwen Yan,Ailin Huang,Hongyu Zhou,Qi Han,Zheng Ge,Daxin Jiang,Xiangyu Zhang,Heung-Yeung Shum*

Main category: cs.LG

TL;DR: PaCoRe是一个训练推理框架，通过并行协调推理突破语言模型在固定上下文窗口下无法扩展测试时计算的问题。


<details>
  <summary>Details</summary>
Motivation: 解决当前语言模型无法在测试时大幅扩展计算能力，只能进行顺序推理的局限性。

Method: 采用消息传递架构进行多轮并行推理：每轮启动多个并行推理轨迹，压缩结果为上下文有界消息，综合这些消息指导下一轮并最终生成答案。通过大规模基于结果的强化学习进行端到端训练。

Result: 在多个领域取得显著改进，特别是在数学推理方面：8B参数模型在HMMT 2025上达到94.5%，超过GPT-5的93.2%，有效测试时计算扩展到约200万token。

Conclusion: PaCoRe框架能够在不超出上下文限制的情况下扩展到数百万token的有效测试时计算，显著提升了推理能力，并开源了相关资源以促进后续研究。

Abstract: We introduce Parallel Coordinated Reasoning (PaCoRe), a training-and-inference framework designed to overcome a central limitation of contemporary language models: their inability to scale test-time compute (TTC) far beyond sequential reasoning under a fixed context window. PaCoRe departs from the traditional sequential paradigm by driving TTC through massive parallel exploration coordinated via a message-passing architecture in multiple rounds. Each round launches many parallel reasoning trajectories, compacts their findings into context-bounded messages, and synthesizes these messages to guide the next round and ultimately produce the final answer. Trained end-to-end with large-scale, outcome-based reinforcement learning, the model masters the synthesis abilities required by PaCoRe and scales to multi-million-token effective TTC without exceeding context limits. The approach yields strong improvements across diverse domains, and notably pushes reasoning beyond frontier systems in mathematics: an 8B model reaches 94.5% on HMMT 2025, surpassing GPT-5's 93.2% by scaling effective TTC to roughly two million tokens. We open-source model checkpoints, training data, and the full inference pipeline to accelerate follow-up work.

</details>


### [81] [Good Allocations from Bad Estimates](https://arxiv.org/abs/2601.05597)
*Sílvia Casacuberta,Moritz Hardt*

Main category: cs.LG

TL;DR: 该论文提出了一种更高效的样本分配方法，仅需O(M/ε)样本即可达到与CATE方法相同的治疗效果，而传统方法需要O(M/ε²)样本。


<details>
  <summary>Details</summary>
Motivation: 传统条件平均治疗效果(CATE)估计方法需要大量样本来准确估计所有治疗效应，但实际治疗分配只需要粗粒度估计即可实现接近最优的分配效果。

Method: 通过利用治疗效应的自然分布特性，证明粗粒度估计足以实现接近最优的治疗分配，并利用预算灵活性进一步降低样本复杂度。

Result: 在多个真实世界RCT数据集上的评估表明，该方法能够以极少的样本找到接近最优的治疗分配方案。

Conclusion: 治疗效应估计与治疗分配之间存在根本区别：后者所需的样本量远少于前者，这为实际应用中的资源优化提供了重要启示。

Abstract: Conditional average treatment effect (CATE) estimation is the de facto gold standard for targeting a treatment to a heterogeneous population. The method estimates treatment effects up to an error $ε> 0$ in each of $M$ different strata of the population, targeting individuals in decreasing order of estimated treatment effect until the budget runs out. In general, this method requires $O(M/ε^2)$ samples. This is best possible if the goal is to estimate all treatment effects up to an $ε$ error. In this work, we show how to achieve the same total treatment effect as CATE with only $O(M/ε)$ samples for natural distributions of treatment effects. The key insight is that coarse estimates suffice for near-optimal treatment allocations. In addition, we show that budget flexibility can further reduce the sample complexity of allocation. Finally, we evaluate our algorithm on various real-world RCT datasets. In all cases, it finds nearly optimal treatment allocations with surprisingly few samples. Our work highlights the fundamental distinction between treatment effect estimation and treatment allocation: the latter requires far fewer samples.

</details>


### [82] [Orchestrating Tokens and Sequences: Dynamic Hybrid Policy Optimization for RLVR](https://arxiv.org/abs/2601.05607)
*Zijun Min,Bingshuai Liu,Ante Wang,Long Zhang,Anxiang Zeng,Haibo Zhang,Jinsong Su*

Main category: cs.LG

TL;DR: 提出动态混合策略优化(DHPO)方法，在单个裁剪代理目标中结合GRPO和GSPO的优势，通过加权机制融合token级和序列级重要性比率，在数学推理任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR算法在不同粒度上各有优劣：GRPO保持细粒度信用分配但方差大不稳定，GSPO匹配序列级奖励但牺牲token级信用分配。需要融合两者优势。

Method: 提出DHPO方法，包含两种混合机制：平均混合和熵引导混合。采用分支特定裁剪策略，在混合前分别约束token级和序列级比率，防止异常值主导更新。

Result: 在7个挑战性数学推理基准测试中，在Qwen3系列的密集和MoE模型上实验表明，DHPO持续优于GRPO和GSPO。

Conclusion: DHPO成功融合了不同粒度策略优化的优势，在保持训练稳定性的同时提升了性能，为RLVR框架提供了有效的优化方法。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) offers a promising framework for optimizing large language models in reasoning tasks. However, existing RLVR algorithms focus on different granularities, and each has complementary strengths and limitations. Group Relative Policy Optimization (GRPO) updates the policy with token-level importance ratios, which preserves fine-grained credit assignment but often suffers from high variance and instability. In contrast, Group Sequence Policy Optimization (GSPO) applies single sequence-level importance ratios across all tokens in a response that better matches sequence-level rewards, but sacrifices token-wise credit assignment. In this paper, we propose Dynamic Hybrid Policy Optimization (DHPO) to bridge GRPO and GSPO within a single clipped surrogate objective. DHPO combines token-level and sequence-level importance ratios using weighting mechanisms. We explore two variants of the mixing mechanism, including an averaged mixing and an entropy-guided mixing. To further stabilize training, we employ a branch-specific clipping strategy that constrains token-level and sequence-level ratios within separate trust regions before mixing, preventing outliers in either branch from dominating the update. Across seven challenging mathematical reasoning benchmarks, experiments on both dense and MoE models from the Qwen3 series show that DHPO consistently outperforms GRPO and GSPO. We will release our code upon acceptance of this paper.

</details>


### [83] [PiXTime: A Model for Federated Time Series Forecasting with Heterogeneous Data Structures Across Nodes](https://arxiv.org/abs/2601.05613)
*Yiming Zhou,Mingyue Cheng,Hao Wang,Enhong Chen*

Main category: cs.LG

TL;DR: PiXTime是一种专为联邦学习设计的时间序列预测模型，能够处理多粒度异构变量集，通过个性化补丁嵌入和全局变量类别表实现跨节点有效预测。


<details>
  <summary>Details</summary>
Motivation: 分布式时间序列数据因不同采样标准导致时间粒度和变量集异构，阻碍了传统联邦学习的应用，需要开发能够处理这种异构性的新方法。

Method: 采用个性化补丁嵌入将节点特定粒度时间序列映射到统一维度的token序列，使用全局变量类别表对齐变量语义，基于Transformer的共享模型捕获辅助序列表示并通过交叉注意力增强目标序列预测。

Result: 实验表明PiXTime在联邦学习设置下达到最先进性能，并在8个真实世界传统基准测试中表现出优越性能。

Conclusion: PiXTime成功解决了联邦学习中时间序列数据异构性问题，为分布式时序数据分析提供了有效解决方案。

Abstract: Time series are highly valuable and rarely shareable across nodes, making federated learning a promising paradigm to leverage distributed temporal data. However, different sampling standards lead to diverse time granularities and variable sets across nodes, hindering classical federated learning. We propose PiXTime, a novel time series forecasting model designed for federated learning that enables effective prediction across nodes with multi-granularity and heterogeneous variable sets. PiXTime employs a personalized Patch Embedding to map node-specific granularity time series into token sequences of a unified dimension for processing by a subsequent shared model, and uses a global VE Table to align variable category semantics across nodes, thereby enhancing cross-node transferability. With a transformer-based shared model, PiXTime captures representations of auxiliary series with arbitrary numbers of variables and uses cross-attention to enhance the prediction of the target series. Experiments show PiXTime achieves state-of-the-art performance in federated settings and demonstrates superior performance on eight widely used real-world traditional benchmarks.

</details>


### [84] [Dual-Phase LLM Reasoning: Self-Evolved Mathematical Frameworks](https://arxiv.org/abs/2601.05616)
*ShaoZhen Liu,Xinting Huang,Houwen Peng,Xin Chen,Xinyang Song,Qi Li,Zhenan Sun*

Main category: cs.LG

TL;DR: 本文提出了一种新的两阶段训练框架，通过自生成长链思维数据来增强模型的自校正能力，证明监督微调能有效激活模型内在推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要依赖强化学习框架而忽视了监督微调方法，需要探索更高效的复杂推理任务优化路径。

Method: 第一阶段使用多轮对话策略生成包含验证、回溯、子目标分解和反向推理的思维链数据，通过规则筛选高质量样本进行监督微调；第二阶段采用难度感知拒绝采样机制动态优化数据分布。

Result: 实验结果显示在GSM8K和MATH500等数学基准上性能提升，推理链长度扩展4倍以上，在AIME24等竞赛级问题上取得显著改进。

Conclusion: 该方法证明了监督微调能有效激活模型内在推理能力，为复杂任务优化提供了资源高效的路径，具有强可扩展性。

Abstract: In recent years, large language models (LLMs) have demonstrated significant potential in complex reasoning tasks like mathematical problem-solving. However, existing research predominantly relies on reinforcement learning (RL) frameworks while overlooking supervised fine-tuning (SFT) methods. This paper proposes a new two-stage training framework that enhances models' self-correction capabilities through self-generated long chain-of-thought (CoT) data. During the first stage, a multi-turn dialogue strategy guides the model to generate CoT data incorporating verification, backtracking, subgoal decomposition, and backward reasoning, with predefined rules filtering high-quality samples for supervised fine-tuning. The second stage employs a difficulty-aware rejection sampling mechanism to dynamically optimize data distribution, strengthening the model's ability to handle complex problems. The approach generates reasoning chains extended over 4 times longer while maintaining strong scalability, proving that SFT effectively activates models' intrinsic reasoning capabilities and provides a resource-efficient pathway for complex task optimization. Experimental results demonstrate performance improvements on mathematical benchmarks including GSM8K and MATH500, with the fine-tuned model achieving a substantial improvement on competition-level problems like AIME24. Code will be open-sourced.

</details>


### [85] [Continual Learning of Achieving Forgetting-free and Positive Knowledge Transfer](https://arxiv.org/abs/2601.05623)
*Zhi Wang,Zhongbin Wu,Yanni Li,Bing Liu,Guangxi Li,Yuping Wang*

Main category: cs.LG

TL;DR: 本文提出了一种增强型任务持续学习（ETCL）方法，旨在解决持续学习中的灾难性遗忘问题，并实现正向的前向和后向知识迁移。


<details>
  <summary>Details</summary>
Motivation: 理想的持续学习代理不仅需要克服灾难性遗忘，还应鼓励正向的知识迁移，包括利用先前任务的知识学习新任务（前向知识迁移）以及利用新任务知识提升先前任务性能（后向知识迁移）。

Method: ETCL方法包括：1）学习任务特定的二进制掩码来隔离每个任务的稀疏子网络；2）在新任务学习开始时对齐新任务梯度与先前最相似任务的子网络梯度；3）使用双目标优化策略和正交梯度投影方法更新分类层权重以实现后向知识迁移。

Result: 广泛的评估表明，ETCL在不同相似度的任务序列上显著优于强基线方法。

Conclusion: ETCL方法能够有效实现无遗忘的持续学习，并促进正向的知识迁移，在多种任务序列场景下表现出优越性能。

Abstract: Existing research on continual learning (CL) of a sequence of tasks focuses mainly on dealing with catastrophic forgetting (CF) to balance the learning plasticity of new tasks and the memory stability of old tasks. However, an ideal CL agent should not only be able to overcome CF, but also encourage positive forward and backward knowledge transfer (KT), i.e., using the learned knowledge from previous tasks for the new task learning (namely FKT), and improving the previous tasks' performance with the knowledge of the new task (namely BKT). To this end, this paper first models CL as an optimization problem in which each sequential learning task aims to achieve its optimal performance under the constraint that both FKT and BKT should be positive. It then proposes a novel Enhanced Task Continual Learning (ETCL) method, which achieves forgetting-free and positive KT. Furthermore, the bounds that can lead to negative FKT and BKT are estimated theoretically. Based on the bounds, a new strategy for online task similarity detection is also proposed to facilitate positive KT. To overcome CF, ETCL learns a set of task-specific binary masks to isolate a sparse sub-network for each task while preserving the performance of a dense network for the task. At the beginning of a new task learning, ETCL tries to align the new task's gradient with that of the sub-network of the previous most similar task to ensure positive FKT. By using a new bi-objective optimization strategy and an orthogonal gradient projection method, ETCL updates only the weights of previous similar tasks at the classification layer to achieve positive BKT. Extensive evaluations demonstrate that the proposed ETCL markedly outperforms strong baselines on dissimilar, similar, and mixed task sequences.

</details>


### [86] [Transformer Is Inherently a Causal Learner](https://arxiv.org/abs/2601.05647)
*Xinyue Wang,Stephen Wang,Biwei Huang*

Main category: cs.LG

TL;DR: 本文揭示了自回归训练的transformer自然地在学习表示中编码了时间延迟的因果结构，其梯度敏感性可以直接恢复底层因果图，无需显式因果目标。


<details>
  <summary>Details</summary>
Motivation: 探索transformer在时间序列预测中自然学习到的因果结构，为因果发现提供新的视角，并建立基础模型与因果推理之间的桥梁。

Method: 通过分析transformer输出对过去输入的梯度敏感性，开发基于聚合梯度归因的因果图提取方法，理论证明在标准可识别性条件下的有效性。

Result: 在非线性动态、长期依赖和非平稳系统等挑战性场景中，该方法显著超越现有因果发现算法，特别是在数据异质性增加时表现更优，展现出随数据量和异质性增加而提升的扩展潜力。

Conclusion: 这项工作为未来范式奠定了基础：通过基础模型的视角进行因果发现，同时基础模型通过因果视角获得可解释性和增强，统一了两种重要研究方向。

Abstract: We reveal that transformers trained in an autoregressive manner naturally encode time-delayed causal structures in their learned representations. When predicting future values in multivariate time series, the gradient sensitivities of transformer outputs with respect to past inputs directly recover the underlying causal graph, without any explicit causal objectives or structural constraints. We prove this connection theoretically under standard identifiability conditions and develop a practical extraction method using aggregated gradient attributions. On challenging cases such as nonlinear dynamics, long-term dependencies, and non-stationary systems, this approach greatly surpasses the performance of state-of-the-art discovery algorithms, especially as data heterogeneity increases, exhibiting scaling potential where causal accuracy improves with data volume and heterogeneity, a property traditional methods lack. This unifying view lays the groundwork for a future paradigm where causal discovery operates through the lens of foundation models, and foundation models gain interpretability and enhancement through the lens of causality.

</details>


### [87] [From Global to Local: Cluster-Aware Learning for Wi-Fi Fingerprinting Indoor Localisation](https://arxiv.org/abs/2601.05650)
*Miguel Matey-Sanz,Joaquín Torres-Sospedra,Joaquín Huerta,Sergio Trilles*

Main category: cs.LG

TL;DR: 提出基于聚类的Wi-Fi指纹定位方法，通过聚类预处理数据集，在定位阶段仅处理相关子集，提高定位精度但降低楼层检测准确率


<details>
  <summary>Details</summary>
Motivation: Wi-Fi指纹定位性能受限于数据集大小和异质性、RSSI信号波动以及大型多楼层环境的模糊性，全局模型在不考虑结构约束时精度下降

Method: 基于空间或无线电特征对指纹进行聚类（建筑物或楼层级别），定位时通过聚类估计程序将未见指纹分配到最相关聚类，仅在该聚类内进行定位

Result: 在三个公共数据集和多个机器学习模型上评估，结果显示定位误差持续减少（特别是建筑物级策略），但楼层检测准确率降低

Conclusion: 通过聚类显式结构化数据集是室内定位可扩展的有效灵活方法

Abstract: Wi-Fi fingerprinting remains one of the most practical solutions for indoor positioning, however, its performance is often limited by the size and heterogeneity of fingerprint datasets, strong Received Signal Strength Indicator variability, and the ambiguity introduced in large and multi-floor environments. These factors significantly degrade localisation accuracy, particularly when global models are applied without considering structural constraints. This paper introduces a clustering-based method that structures the fingerprint dataset prior to localisation. Fingerprints are grouped using either spatial or radio features, and clustering can be applied at the building or floor level. In the localisation phase, a clustering estimation procedure based on the strongest access points assigns unseen fingerprints to the most relevant cluster. Localisation is then performed only within the selected clusters, allowing learning models to operate on reduced and more coherent subsets of data. The effectiveness of the method is evaluated on three public datasets and several machine learning models. Results show a consistent reduction in localisation errors, particularly under building-level strategies, but at the cost of reducing the floor detection accuracy. These results demonstrate that explicitly structuring datasets through clustering is an effective and flexible approach for scalable indoor positioning.

</details>


### [88] [Do Sparse Autoencoders Identify Reasoning Features in Language Models?](https://arxiv.org/abs/2601.05679)
*George Ma,Zhongyuan Liang,Irene Y. Chen,Somayeh Sojoudi*

Main category: cs.LG

TL;DR: 论文通过因果token注入实验和LLM引导的证伪方法，验证稀疏自编码器（SAE）是否真正识别了LLM中的推理特征。研究发现，大多数被识别为推理特征的特征实际上对token级干预高度敏感，主要捕捉的是推理的语言相关性而非真正的推理计算。


<details>
  <summary>Details</summary>
Motivation: 当前使用对比激活方法识别出的稀疏自编码器特征被认为代表了LLM的推理过程，但作者质疑这些特征是否真正反映了推理计算，还是仅仅捕捉了与推理相关的表面语言特征。

Method: 提出一个证伪导向的框架，结合因果token注入实验（向非推理文本注入少量特征相关token）和LLM引导的证伪方法（生成能激活特征的非推理输入和不能激活特征的推理输入），在20种配置下测试特征对干预的敏感性。

Result: 59%至94%的特征可通过简单token注入被强烈激活，表明其依赖词汇伪影；剩余特征也无法通过证伪测试，没有特征满足真正推理行为的标准；对这些特征进行引导只会导致基准性能的微小变化或轻微下降。

Conclusion: 通过对比方法识别的SAE特征主要捕捉的是推理的语言相关性，而非底层的推理计算本身。

Abstract: We investigate whether sparse autoencoders (SAEs) identify genuine reasoning features in large language models (LLMs). Starting from features selected using standard contrastive activation methods, we introduce a falsification-oriented framework that combines causal token injection experiments and LLM-guided falsification to test whether feature activation reflects reasoning processes or superficial linguistic correlates. Across 20 configurations spanning multiple model families, layers, and reasoning datasets, we find that identified reasoning features are highly sensitive to token-level interventions. Injecting a small number of feature-associated tokens into non-reasoning text is sufficient to elicit strong activation for 59% to 94% of features, indicating reliance on lexical artifacts. For the remaining features that are not explained by simple token triggers, LLM-guided falsification consistently produces non-reasoning inputs that activate the feature and reasoning inputs that do not, with no analyzed feature satisfying our criteria for genuine reasoning behavior. Steering these features yields minimal changes or slight degradations in benchmark performance. Together, these results suggest that SAE features identified by contrastive approaches primarily capture linguistic correlates of reasoning rather than the underlying reasoning computations themselves.

</details>


### [89] [AGDC: Autoregressive Generation of Variable-Length Sequences with Joint Discrete and Continuous Spaces](https://arxiv.org/abs/2601.05680)
*Yeonsang Shin,Insoo Kim,Bongkeun Kim,Keonwoo Bae,Bohyung Han*

Main category: cs.LG

TL;DR: 本文提出AGDC框架，解决Transformer自回归模型在生成高精度连续值时的离散化限制问题，通过混合离散-连续建模实现半导体电路设计等领域的可扩展高精度生成。


<details>
  <summary>Details</summary>
Motivation: 现有基于离散化的方法在处理混合离散-连续序列时存在可扩展性限制，特别是在高精度领域如半导体电路设计中，精度损失可能导致功能失效。

Method: AGDC框架采用混合方法：离散值使用分类预测，连续值使用基于扩散的建模。关键技术包括基于MLP的EOS对数调整机制和集成到损失函数中的长度正则化项。

Result: 在半导体布局、图形布局和SVG数据集上的实验表明，AGDC相比离散化基准和固定模式基准在生成高保真混合向量表示方面表现优异。

Conclusion: AGDC框架能够实现跨领域的可扩展高精度生成，特别是在需要高精度连续值表示的半导体设计等应用中具有重要价值。

Abstract: Transformer-based autoregressive models excel in data generation but are inherently constrained by their reliance on discretized tokens, which limits their ability to represent continuous values with high precision. We analyze the scalability limitations of existing discretization-based approaches for generating hybrid discrete-continuous sequences, particularly in high-precision domains such as semiconductor circuit designs, where precision loss can lead to functional failure. To address the challenge, we propose AGDC, a novel unified framework that jointly models discrete and continuous values for variable-length sequences. AGDC employs a hybrid approach that combines categorical prediction for discrete values with diffusion-based modeling for continuous values, incorporating two key technical components: an end-of-sequence (EOS) logit adjustment mechanism that uses an MLP to dynamically adjust EOS token logits based on sequence context, and a length regularization term integrated into the loss function. Additionally, we present ContLayNet, a large-scale benchmark comprising 334K high-precision semiconductor layout samples with specialized evaluation metrics that capture functional correctness where precision errors significantly impact performance. Experiments on semiconductor layouts (ContLayNet), graphic layouts, and SVGs demonstrate AGDC's superior performance in generating high-fidelity hybrid vector representations compared to discretization-based and fixed-schema baselines, achieving scalable high-precision generation across diverse domains.

</details>


### [90] [FLRQ: Faster LLM Quantization with Flexible Low-Rank Matrix Sketching](https://arxiv.org/abs/2601.05684)
*Hongyaoxing Gul,Lijuan Hu,Shuzi Niu,Fangfang Liu*

Main category: cs.LG

TL;DR: FLRQ是一种新型的低秩量化方法，通过快速识别最优秩并聚合实现最小存储组合，包含R1-FLR和BLC两个组件，在量化质量和算法效率上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 传统低秩PTQ方法需要昂贵的微调来确定不同数据和层的最佳秩，且SVD基低秩近似计算开销大，无法充分发挥大语言模型的潜力。

Method: FLRQ包含两个核心组件：1) R1-FLR使用基于高斯投影的R1-Sketch进行快速低秩近似，实现异常值感知的秩提取；2) BLC通过迭代方法在缩放和裁剪策略下最小化低秩量化误差。

Result: FLRQ在综合实验中表现出强大的有效性和鲁棒性，在量化质量和算法效率方面均达到最先进性能。

Conclusion: FLRQ通过灵活的秩选择和优化的低秩近似，有效解决了传统低秩量化方法的计算开销和秩选择问题，为大语言模型的高效量化提供了创新解决方案。

Abstract: Traditional post-training quantization (PTQ) is considered an effective approach to reduce model size and accelerate inference of large-scale language models (LLMs). However, existing low-rank PTQ methods require costly fine-tuning to determine a compromise rank for diverse data and layers in large models, failing to exploit their full potential. Additionally, the current SVD-based low-rank approximation compounds the computational overhead. In this work, we thoroughly analyze the varying effectiveness of low-rank approximation across different layers in representative models. Accordingly, we introduce \underline{F}lexible \underline{L}ow-\underline{R}ank \underline{Q}uantization (FLRQ), a novel solution designed to quickly identify the accuracy-optimal ranks and aggregate them to achieve minimal storage combinations. FLRQ comprises two powerful components, Rank1-Sketch-based Flexible Rank Selection (R1-FLR) and Best Low-rank Approximation under Clipping (BLC). R1-FLR applies the R1-Sketch with Gaussian projection for the fast low-rank approximation, enabling outlier-aware rank extraction for each layer. Meanwhile, BLC aims at minimizing the low-rank quantization error under the scaling and clipping strategy through an iterative method. FLRQ demonstrates strong effectiveness and robustness in comprehensive experiments, achieving state-of-the-art performance in both quantization quality and algorithm efficiency.

</details>


### [91] [mHC-lite: You Don't Need 20 Sinkhorn-Knopp Iterations](https://arxiv.org/abs/2601.05732)
*Yongyi Yang,Jianyang Gao*

Main category: cs.LG

TL;DR: mHC-lite是一种改进的超连接方法，通过显式构造双随机矩阵来替代mHC中的Sinkhorn-Knopp归一化，确保精确的双随机性并提高训练稳定性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决mHC方法中存在的两个问题：有限SK迭代无法保证精确双随机性导致的稳定性问题，以及SK实现需要专用CUDA内核带来的工程障碍和可移植性问题。

Method: 基于Birkhoff-von Neumann定理，通过排列矩阵的凸组合显式构造双随机矩阵，仅使用原生矩阵操作实现。

Result: 实验表明mHC-lite在性能上匹配或超过mHC，同时使用简单实现即可获得更高的训练吞吐量，并消除了HC和mHC中观察到的残余不稳定性。

Conclusion: mHC-lite提供了一种更简单、更稳定且更高效的超连接实现方案，解决了原有方法的局限性。

Abstract: Hyper-Connections (HC) generalizes residual connections by introducing dynamic residual matrices that mix information across multiple residual streams, accelerating convergence in deep neural networks. However, unconstrained residual matrices can compromise training stability. To address this, DeepSeek's Manifold-Constrained Hyper-Connections (mHC) approximately projects these matrices onto the Birkhoff polytope via iterative Sinkhorn--Knopp (SK) normalization. We identify two limitations of this approach: (i) finite SK iterations do not guarantee exact doubly stochasticity, leaving an approximation gap that can accumulate through network depth and undermine stability; (ii) efficient SK implementation requires highly specialized CUDA kernels, raising engineering barriers and reducing portability. Motivated by the Birkhoff--von Neumann theorem, we propose mHC-lite, a simple reparameterization that explicitly constructs doubly stochastic matrices as convex combinations of permutation matrices. This approach guarantees exact doubly stochasticity by construction and can be implemented using only native matrix operations. Extensive experiments demonstrate that mHC-lite matches or exceeds mHC in performance while achieving higher training throughput with a naive implementation and eliminating the residual instabilities observed in both HC and mHC. The code is publicly available at https://github.com/FFTYYY/mhc-lite.

</details>


### [92] [Variational Autoencoders for P-wave Detection on Strong Motion Earthquake Spectrograms](https://arxiv.org/abs/2601.05759)
*Turkan Simge Ispak,Salih Tileylioglu,Erdem Akagunduz*

Main category: cs.LG

TL;DR: 该研究将P波到达检测重新定义为自监督异常检测任务，通过492种变分自编码器配置的网格搜索，发现注意力机制在P波检测中表现最佳，特别是在近源区域（0-40公里）达到0.91的AUC值。


<details>
  <summary>Details</summary>
Motivation: 强震记录中的P波检测面临高噪声水平、有限标注数据和复杂波形特征的挑战，需要开发更稳健的检测方法。

Method: 使用自监督异常检测框架，通过网格搜索比较492种变分自编码器配置，重点分析跳跃连接和注意力机制对重建保真度与异常辨别能力权衡的影响。

Result: 跳跃连接虽然最小化重建误差（MAE约0.0012），但会导致"过度泛化"问题；而注意力机制优先考虑全局上下文，在0-40公里近源范围内达到0.91的AUC值，检测性能最佳。

Conclusion: 倾向于全局上下文而非像素级完美重建的架构约束对于稳健的自监督P波检测至关重要，注意力机制特别适合即时预警应用。

Abstract: Accurate P-wave detection is critical for earthquake early warning, yet strong-motion records pose challenges due to high noise levels, limited labeled data, and complex waveform characteristics. This study reframes P-wave arrival detection as a self-supervised anomaly detection task to evaluate how architectural variations regulate the trade-off between reconstruction fidelity and anomaly discrimination. Through a comprehensive grid search of 492 Variational Autoencoder configurations, we show that while skip connections minimize reconstruction error (Mean Absolute Error approximately 0.0012), they induce "overgeneralization", allowing the model to reconstruct noise and masking the detection signal. In contrast, attention mechanisms prioritize global context over local detail and yield the highest detection performance with an area-under-the-curve of 0.875. The attention-based Variational Autoencoder achieves an area-under-the-curve of 0.91 in the 0 to 40-kilometer near-source range, demonstrating high suitability for immediate early warning applications. These findings establish that architectural constraints favoring global context over pixel-perfect reconstruction are essential for robust, self-supervised P-wave detection.

</details>


### [93] [Weights to Code: Extracting Interpretable Algorithms from the Discrete Transformer](https://arxiv.org/abs/2601.05770)
*Yifan Zhang,Wei Bi,Kechi Zhang,Dongming Jin,Jie Fu,Zhi Jin*

Main category: cs.LG

TL;DR: 本文提出离散Transformer架构，通过功能解耦和温度退火采样，解决Transformer在算法提取中的特征纠缠问题，实现从连续表示到离散符号逻辑的转换。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer在算法提取任务中存在特征叠加问题，导致难以从训练模型中提取可读的符号表达式，限制了算法发现的可解释性。

Method: 提出离散Transformer架构，强制数值注意力负责信息路由，数值MLP负责逐元素算术运算，实现功能解耦；采用温度退火采样策略促进离散搜索。

Result: 离散Transformer在性能上达到与RNN基线相当的水平，同时在连续变量域实现可解释性；退火过程显示从探索到利用的相变；可通过归纳偏置实现程序细粒度控制。

Conclusion: 离散Transformer为无演示算法发现提供了稳健框架，为Transformer可解释性研究提供了严格路径。

Abstract: Algorithm extraction aims to synthesize executable programs directly from models trained on specific algorithmic tasks, enabling de novo algorithm discovery without relying on human-written code. However, extending this paradigm to Transformer is hindered by superposition, where entangled features encoded in overlapping directions obstruct the extraction of symbolic expressions. In this work, we propose the Discrete Transformer, an architecture explicitly engineered to bridge the gap between continuous representations and discrete symbolic logic. By enforcing a strict functional disentanglement, which constrains Numerical Attention to information routing and Numerical MLP to element-wise arithmetic, and employing temperature-annealed sampling, our method effectively facilitates the extraction of human-readable programs. Empirically, the Discrete Transformer not only achieves performance comparable to RNN-based baselines but crucially extends interpretability to continuous variable domains. Moreover, our analysis of the annealing process shows that the efficient discrete search undergoes a clear phase transition from exploration to exploitation. We further demonstrate that our method enables fine-grained control over synthesized programs by imposing inductive biases. Collectively, these findings establish the Discrete Transformer as a robust framework for demonstration-free algorithm discovery, offering a rigorous pathway toward Transformer interpretability.

</details>


### [94] [Tensor-DTI: Enhancing Biomolecular Interaction Prediction with Contrastive Embedding Learning](https://arxiv.org/abs/2601.05792)
*Manel Gil-Sorribes,Júlia Vilalta-Mor,Isaac Filella-Mercè,Robert Soliva,Álvaro Ciudad,Víctor Guallar,Alexis Molina*

Main category: cs.LG

TL;DR: Tensor-DTI是一个基于对比学习的多模态药物-靶点相互作用预测框架，整合分子图、蛋白质语言模型和结合位点预测信息，显著优于现有单模态方法。


<details>
  <summary>Details</summary>
Motivation: 现有DTI预测模型主要依赖单模态预定义分子描述符或序列嵌入，表征能力有限，需要更全面的多模态信息整合来提高相互作用建模精度。

Method: 提出Tensor-DTI对比学习框架，采用孪生双编码器架构，整合分子图嵌入、蛋白质语言模型嵌入和结合位点预测嵌入，捕捉化学和结构相互作用特征。

Result: 在多个DTI基准测试中优于现有序列和图形模型；在CDK2的大规模化学库推理实验中产生化学合理的命中分布；在严格家族保留分割下，对家族外靶点的高亲和力配体筛选预算需求降低。

Conclusion: 多模态信息与对比目标整合能显著提高相互作用预测准确性，为虚拟筛选提供更可解释和可靠性感知的模型，并适用于蛋白质-RNA和肽-蛋白质相互作用。

Abstract: Accurate drug-target interaction (DTI) prediction is essential for computational drug discovery, yet existing models often rely on single-modality predefined molecular descriptors or sequence-based embeddings with limited representativeness. We propose Tensor-DTI, a contrastive learning framework that integrates multimodal embeddings from molecular graphs, protein language models, and binding-site predictions to improve interaction modeling. Tensor-DTI employs a siamese dual-encoder architecture, enabling it to capture both chemical and structural interaction features while distinguishing interacting from non-interacting pairs. Evaluations on multiple DTI benchmarks demonstrate that Tensor-DTI outperforms existing sequence-based and graph-based models. We also conduct large-scale inference experiments on CDK2 across billion-scale chemical libraries, where Tensor-DTI produces chemically plausible hit distributions even when CDK2 is withheld from training. In enrichment studies against Glide docking and Boltz-2 co-folder, Tensor-DTI remains competitive on CDK2 and improves the screening budget required to recover moderate fractions of high-affinity ligands on out-of-family targets under strict family-holdout splits. Additionally, we explore its applicability to protein-RNA and peptide-protein interactions. Our findings highlight the benefits of integrating multimodal information with contrastive objectives to enhance interaction-prediction accuracy and to provide more interpretable and reliability-aware models for virtual screening.

</details>


### [95] [Fusion Matters: Length-Aware Analysis of Positional-Encoding Fusion in Transformers](https://arxiv.org/abs/2601.05807)
*Mohamed Amine Hallam,Kuo-Kun Tseng*

Main category: cs.LG

TL;DR: 本文研究了Transformer中位置编码与词嵌入的融合机制对性能的影响，发现融合策略在长序列任务中具有显著影响，而在短文本中影响较小。


<details>
  <summary>Details</summary>
Motivation: 大多数现有工作关注设计新的位置编码，而忽略了位置信息与词嵌入的融合机制本身对性能的影响，特别是在长序列场景下。

Method: 在相同Transformer架构、数据划分和随机种子下，对比了三种经典融合策略：逐元素加法、拼接加投影、标量门控融合。在三个文本分类数据集（AG News、IMDB、ArXiv）上进行实验，并进行了配对种子分析和跨数据集比较。

Result: 融合选择在短文本上影响可忽略，但在长文档上产生一致性能提升。可学习融合的收益在多个位置编码家族中具有普适性。轻量级卷积门控机制在长文档上表现出色。

Conclusion: 位置编码融合是长序列Transformer的重要设计选择，应作为明确的建模决策而非固定默认设置。

Abstract: Transformers require positional encodings to represent sequence order, yet most prior work focuses on designing new positional encodings rather than examining how positional information is fused with token embeddings. In this paper, we study whether the fusion mechanism itself affects performance, particularly in long-sequence settings. We conduct a controlled empirical study comparing three canonical fusion strategies--element-wise addition, concatenation with projection, and scalar gated fusion--under identical Transformer architectures, data splits, and random seeds. Experiments on three text classification datasets spanning short (AG News), medium (IMDB), and long (ArXiv) sequences show that fusion choice has negligible impact on short texts but produces consistent gains on long documents. To verify that these gains are structural rather than stochastic, we perform paired-seed analysis and cross-dataset comparison across sequence-length regimes. Additional experiments on the ArXiv dataset indicate that the benefit of learnable fusion generalizes across multiple positional encoding families. Finally, we explore a lightweight convolutional gating mechanism that introduces local inductive bias at the fusion level, evaluated on long documents only. Our results indicate that positional-encoding fusion is a non-trivial design choice for long-sequence Transformers and should be treated as an explicit modeling decision rather than a fixed default.

</details>


### [96] [Learning Reconstructive Embeddings in Reproducing Kernel Hilbert Spaces via the Representer Theorem](https://arxiv.org/abs/2601.05811)
*Enrique Feito-Casares,Francisco M. Melgarejo-Meseguer,José-Luis Rojo-Álvarez*

Main category: cs.LG

TL;DR: 该论文提出了在再生核希尔伯特空间（RKHS）中进行重构式流形学习的新算法，通过核对齐将高维数据的自重构几何结构转移到低维嵌入空间中。


<details>
  <summary>Details</summary>
Motivation: 受表示学习方法揭示高维数据潜在结构的研究兴趣驱动，旨在开发能够有效捕捉数据内在流形结构的重构式学习算法。

Method: 首先在RKHS中将每个观测值重构为其他样本的线性组合，然后通过可分离的算子值核扩展到向量值数据，最后通过核对齐任务将数据投影到低维潜在空间，使其Gram矩阵匹配高维重构核。

Result: 在模拟数据集（同心圆和瑞士卷）和真实数据集（癌症分子活性和物联网网络入侵）上的数值实验证明了该方法的实际有效性。

Conclusion: 提出的算法通过利用和调整核学习理论的已知结果，扩展了自然数据表现的自表示特性，为重构式流形学习提供了有效的解决方案。

Abstract: Motivated by the growing interest in representation learning approaches that uncover the latent structure of high-dimensional data, this work proposes new algorithms for reconstruction-based manifold learning within Reproducing-Kernel Hilbert Spaces (RKHS). Each observation is first reconstructed as a linear combination of the other samples in the RKHS, by optimizing a vector form of the Representer Theorem for their autorepresentation property. A separable operator-valued kernel extends the formulation to vector-valued data while retaining the simplicity of a single scalar similarity function. A subsequent kernel-alignment task projects the data into a lower-dimensional latent space whose Gram matrix aims to match the high-dimensional reconstruction kernel, thus transferring the auto-reconstruction geometry of the RKHS to the embedding. Therefore, the proposed algorithms represent an extended approach to the autorepresentation property, exhibited by many natural data, by using and adapting well-known results of Kernel Learning Theory. Numerical experiments on both simulated (concentric circles and swiss-roll) and real (cancer molecular activity and IoT network intrusions) datasets provide empirical evidence of the practical effectiveness of the proposed approach.

</details>


### [97] [Detecting Autism Spectrum Disorder with Deep Eye Movement Features](https://arxiv.org/abs/2601.05812)
*Zhanpei Huang,Taochen chen,Fangqing Gu,Yiqun Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种针对自闭症谱系障碍（ASD）检测的离散短时序序列（DSTS）建模框架，通过眼动数据分析来区分ASD患者与正常发育个体。


<details>
  <summary>Details</summary>
Motivation: 眼动数据具有离散性和短期时间依赖性的特点，能够反映局部注视焦点，但传统的基于Transformer的全局注意力机制在此类数据上效果有限，需要专门针对眼动数据特性的建模方法。

Method: 设计了包含类感知表示和失衡感知机制的DSTS框架，重点捕捉眼动数据中的短期局部依赖模式，而非全局长期依赖。

Result: 在多个眼动数据集上的实验表明，DSTS框架优于传统机器学习方法和复杂深度学习模型。

Conclusion: 针对眼动数据的离散短时序特性设计的专用建模框架能够更有效地捕捉ASD相关的细微行为模式，为自闭症诊断提供了更有效的工具。

Abstract: Autism Spectrum Disorder (ASD) is a neurodevelopmental disorder characterized by deficits in social communication and behavioral patterns. Eye movement data offers a non-invasive diagnostic tool for ASD detection, as it is inherently discrete and exhibits short-term temporal dependencies, reflecting localized gaze focus between fixation points. These characteristics enable the data to provide deeper insights into subtle behavioral markers, distinguishing ASD-related patterns from typical development. Eye movement signals mainly contain short-term and localized dependencies. However, despite the widespread application of stacked attention layers in Transformer-based models for capturing long-range dependencies, our experimental results indicate that this approach yields only limited benefits when applied to eye movement data. This may be because discrete fixation points and short-term dependencies in gaze focus reduce the utility of global attention mechanisms, making them less efficient than architectures focusing on local temporal patterns. To efficiently capture subtle and complex eye movement patterns, distinguishing ASD from typically developing (TD) individuals, a discrete short-term sequential (DSTS) modeling framework is designed with Class-aware Representation and Imbalance-aware Mechanisms. Through extensive experiments on several eye movement datasets, DSTS outperforms both traditional machine learning techniques and more sophisticated deep learning models.

</details>


### [98] [A Dual Pipeline Machine Learning Framework for Automated Multi Class Sleep Disorder Screening Using Hybrid Resampling and Ensemble Learning](https://arxiv.org/abs/2601.05814)
*Md Sultanul Islam Ovi,Muhsina Tarannum Munfa,Miftahul Alam Adib,Syed Sabbir Hasan*

Main category: cs.LG

TL;DR: 提出双管道机器学习框架用于睡眠障碍多分类筛查，结合统计和包装器方法，在Sleep Health and Lifestyle数据集上达到98.67%准确率


<details>
  <summary>Details</summary>
Motivation: 临床睡眠研究资源密集且难以大规模推广，需要开发自动化筛查工具来改善睡眠障碍分类和患者生活质量

Method: 双管道框架：统计管道（互信息+LDA处理线性可分性）+包装器管道（Boruta特征选择+自编码器非线性表示学习），使用SMOTETomek处理类别不平衡

Result: Extra Trees和KNN模型达到98.67%准确率，显著优于基线，推理延迟低于400毫秒，Wilcoxon检验显示改进具有统计显著性

Conclusion: 双管道设计支持准确高效的自动化睡眠障碍风险分层筛查，具有临床应用潜力

Abstract: Accurate classification of sleep disorders, particularly insomnia and sleep apnea, is important for reducing long term health risks and improving patient quality of life. However, clinical sleep studies are resource intensive and are difficult to scale for population level screening. This paper presents a Dual Pipeline Machine Learning Framework for multi class sleep disorder screening using the Sleep Health and Lifestyle dataset. The framework consists of two parallel processing streams: a statistical pipeline that targets linear separability using Mutual Information and Linear Discriminant Analysis, and a wrapper based pipeline that applies Boruta feature selection with an autoencoder for non linear representation learning. To address class imbalance, we use the hybrid SMOTETomek resampling strategy. In experiments, Extra Trees and K Nearest Neighbors achieved an accuracy of 98.67%, outperforming recent baselines on the same dataset. Statistical testing using the Wilcoxon Signed Rank Test indicates that the improvement over baseline configurations is significant, and inference latency remains below 400 milliseconds. These results suggest that the proposed dual pipeline design supports accurate and efficient automated screening for non invasive sleep disorder risk stratification.

</details>


### [99] [A New Family of Poisson Non-negative Matrix Factorization Methods Using the Shifted Log Link](https://arxiv.org/abs/2601.05845)
*Eric Weine,Peter Carbonetto,Rafael A. Irizarry,Matthew Stephens*

Main category: cs.LG

TL;DR: 该论文提出了使用移位对数链接函数的泊松非负矩阵分解方法，通过调整单个参数来放松传统方法中部分组合必须为加性的假设，允许从加性到乘性组合的灵活变化。


<details>
  <summary>Details</summary>
Motivation: 传统泊松NMF假设部分组合是加性的，这在某些场景下可能不合理。作者希望开发一种更灵活的模型，能够适应不同组合方式的数据特征。

Method: 引入移位对数链接函数，提供最大似然估计算法，并为大型稀疏数据集设计了计算效率更高的近似方法。

Result: 在多个真实数据集上的实验表明，链接函数的选择对结果有实质性影响，移位对数链接函数在某些情况下能提高结果的解释性。

Conclusion: 移位对数链接函数为泊松NMF提供了更灵活的建模能力，能够根据数据特征调整部分组合方式，从而获得更好的解释性。

Abstract: Poisson non-negative matrix factorization (NMF) is a widely used method to find interpretable "parts-based" decompositions of count data. While many variants of Poisson NMF exist, existing methods assume that the "parts" in the decomposition combine additively. This assumption may be natural in some settings, but not in others. Here we introduce Poisson NMF with the shifted-log link function to relax this assumption. The shifted-log link function has a single tuning parameter, and as this parameter varies the model changes from assuming that parts combine additively (i.e., standard Poisson NMF) to assuming that parts combine more multiplicatively. We provide an algorithm to fit this model by maximum likelihood, and also an approximation that substantially reduces computation time for large, sparse datasets (computations scale with the number of non-zero entries in the data matrix). We illustrate these new methods on a variety of real datasets. Our examples show how the choice of link function in Poisson NMF can substantively impact the results, and how in some settings the use of a shifted-log link function may improve interpretability compared with the standard, additive link.

</details>


### [100] [IIB-LPO: Latent Policy Optimization via Iterative Information Bottleneck](https://arxiv.org/abs/2601.05870)
*Huilin Deng,Hongchen Luo,Yue Zhu,Long Li,Zhuoyue Chen,Xinghao Zhao,Ming Li,Jihai Zhang,Mengchang Wang,Yang Cao,Yu Kang*

Main category: cs.LG

TL;DR: 本文提出IIB-LPO方法，通过将探索从token分布的统计扰动转向推理轨迹的拓扑分支，解决了RLVR中探索崩溃问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法面临探索崩溃挑战：随机rollout的语义同质性导致模型陷入狭窄的过优化行为，而全局熵正则化容易产生无意义的冗长输出，局部token选择性更新则受限于预训练模型的强归纳偏置。

Method: IIB-LPO在高熵状态触发潜在分支以多样化推理路径，并利用信息瓶颈原则作为轨迹过滤器和自奖励机制，确保简洁且信息丰富的探索。

Result: 在四个数学推理基准测试中，IIB-LPO实现了最先进的性能，准确率比先前方法高出5.3%，多样性指标高出7.4%。

Conclusion: IIB-LPO通过拓扑分支探索和信息瓶颈机制，有效解决了RLVR中的探索崩溃问题，显著提升了推理性能。

Abstract: Recent advances in Reinforcement Learning with Verifiable Rewards (RLVR) for Large Language Model (LLM) reasoning have been hindered by a persistent challenge: exploration collapse. The semantic homogeneity of random rollouts often traps models in narrow, over-optimized behaviors. While existing methods leverage policy entropy to encourage exploration, they face inherent limitations. Global entropy regularization is susceptible to reward hacking, which can induce meaningless verbosity, whereas local token-selective updates struggle with the strong inductive bias of pre-trained models. To address this, we propose Latent Policy Optimization via Iterative Information Bottleneck (IIB-LPO), a novel approach that shifts exploration from statistical perturbation of token distributions to topological branching of reasoning trajectories. IIB-LPO triggers latent branching at high-entropy states to diversify reasoning paths and employs the Information Bottleneck principle both as a trajectory filter and a self-reward mechanism, ensuring concise and informative exploration. Empirical results across four mathematical reasoning benchmarks demonstrate that IIB-LPO achieves state-of-the-art performance, surpassing prior methods by margins of up to 5.3% in accuracy and 7.4% in diversity metrics.

</details>


### [101] [GlueNN: gluing patchwise analytic solutions with neural networks](https://arxiv.org/abs/2601.05889)
*Doyoung Kim,Donghee Lee,Hye-Sung Lee,Jiheon Lee,Jaeok Yi*

Main category: cs.LG

TL;DR: 提出了一种学习框架，将渐近解析解的积分常数提升为尺度相关函数，通过约束这些系数函数来学习全局有效解，避免传统边界匹配的问题。


<details>
  <summary>Details</summary>
Motivation: 传统分区域匹配方法在复杂微分方程求解中可能失效，因为近似形式在匹配边界附近可能失效，需要一种能平滑插值渐近区域的全局解法。

Method: 将渐近解析解的积分常数推广为尺度相关函数，通过神经网络约束这些系数函数，使其满足原微分方程在整个域上的要求。

Result: 在化学动力学和宇宙学的代表性问题上验证了框架有效性，准确再现全局解并优于传统匹配方法。

Conclusion: 该学习框架能够消除任意边界匹配的需求，通过平滑插值渐近区域获得全局有效解，为解决复杂微分方程提供了新途径。

Abstract: In many problems in physics and engineering, one encounters complicated differential equations with strongly scale-dependent terms for which exact analytical or numerical solutions are not available. A common strategy is to divide the domain into several regions (patches) and simplify the equation in each region. When approximate analytic solutions can be obtained in each patch, they are then matched at the interfaces to construct a global solution. However, this patching procedure can fail to reproduce the correct solution, since the approximate forms may break down near the matching boundaries. In this work, we propose a learning framework in which the integration constants of asymptotic analytic solutions are promoted to scale-dependent functions. By constraining these coefficient functions with the original differential equation over the domain, the network learns a globally valid solution that smoothly interpolates between asymptotic regimes, eliminating the need for arbitrary boundary matching. We demonstrate the effectiveness of this framework in representative problems from chemical kinetics and cosmology, where it accurately reproduces global solutions and outperforms conventional matching procedures.

</details>


### [102] [Auditing Fairness under Model Updates: Fundamental Complexity and Property-Preserving Updates](https://arxiv.org/abs/2601.05909)
*Ayoub Ajarra,Debabrota Basu*

Main category: cs.LG

TL;DR: 本文研究了机器学习模型在适应性更新情况下的群体公平性审计问题，提出了一个基于经验属性优化(EPO)的PAC审计框架，并针对统计均等性建立了由SP维度表征的分布无关审计界限。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习模型在社会基础设施中的广泛应用，审计其偏见变得日益重要。然而在现实部署中，模型所有者会根据环境变化适应性更新模型，这些更新可能改变底层模型类别但保持某些关注属性不变，这引发了在模型变化情况下可靠审计的根本性问题。

Method: 提出了一个通用的PAC审计框架，基于经验属性优化(EPO)预言机。对于统计均等性，建立了由SP维度表征的分布无关审计界限，SP维度是一个新的组合度量，捕捉了允许策略更新的复杂性。

Result: 开发了一个能够处理任意模型更新的审计框架，该框架可高效估计审计属性（如群体公平性），并使用最少的标记样本。框架还自然扩展到其他审计目标，包括预测误差和鲁棒风险。

Conclusion: 该研究为在模型适应性更新环境下进行可靠审计提供了理论框架和方法论，解决了模型变化对审计可靠性的挑战，为实际部署中的机器学习模型审计提供了实用工具。

Abstract: As machine learning models become increasingly embedded in societal infrastructure, auditing them for bias is of growing importance. However, in real-world deployments, auditing is complicated by the fact that model owners may adaptively update their models in response to changing environments, such as financial markets. These updates can alter the underlying model class while preserving certain properties of interest, raising fundamental questions about what can be reliably audited under such shifts.
  In this work, we study group fairness auditing under arbitrary updates. We consider general shifts that modify the pre-audit model class while maintaining invariance of the audited property. Our goals are two-fold: (i) to characterize the information complexity of allowable updates, by identifying which strategic changes preserve the property under audit; and (ii) to efficiently estimate auditing properties, such as group fairness, using a minimal number of labeled samples.
  We propose a generic framework for PAC auditing based on an Empirical Property Optimization (EPO) oracle. For statistical parity, we establish distribution-free auditing bounds characterized by the SP dimension, a novel combinatorial measure that captures the complexity of admissible strategic updates. Finally, we demonstrate that our framework naturally extends to other auditing objectives, including prediction error and robust risk.

</details>


### [103] [Distilling Lightweight Domain Experts from Large ML Models by Identifying Relevant Subspaces](https://arxiv.org/abs/2601.05913)
*Pattarawat Chormai,Ali Hashemi,Klaus-Robert Müller,Grégoire Montavon*

Main category: cs.LG

TL;DR: SubDistill是一种新的知识蒸馏算法，专注于仅蒸馏教师模型中与特定子任务相关的组件，在资源受限环境下实现更高效的知识迁移。


<details>
  <summary>Details</summary>
Motivation: 当前知识蒸馏方法大多对整个模型进行蒸馏，但在实际应用中往往只需要关注特定类别的子任务，现有方法缺乏对相关子任务的针对性蒸馏。

Method: 提出SubDistill算法，在每层仅蒸馏教师模型的相关组件，具有改进的数值特性，专门针对相关子任务进行层间知识蒸馏。

Result: 在CIFAR-100和ImageNet数据集上的实验表明，SubDistill在代表性子任务集上优于现有的层间蒸馏技术，可解释AI分析显示学生模型更接近原始教师模型的决策结构。

Conclusion: SubDistill为特定子任务的知识蒸馏提供了有效解决方案，在资源受限环境中具有实际应用价值。

Abstract: Knowledge distillation involves transferring the predictive capabilities of large, high-performing AI models (teachers) to smaller models (students) that can operate in environments with limited computing power. In this paper, we address the scenario in which only a few classes and their associated intermediate concepts are relevant to distill. This scenario is common in practice, yet few existing distillation methods explicitly focus on the relevant subtask. To address this gap, we introduce 'SubDistill', a new distillation algorithm with improved numerical properties that only distills the relevant components of the teacher model at each layer. Experiments on CIFAR-100 and ImageNet with Convolutional and Transformer models demonstrate that SubDistill outperforms existing layer-wise distillation techniques on a representative set of subtasks. Our benchmark evaluations are complemented by Explainable AI analyses showing that our distilled student models more closely match the decision structure of the original teacher model.

</details>


### [104] [Prophet as a Repro ducible Forecasting Framework: A Methodological Guide for Business and Financial Analytics](https://arxiv.org/abs/2601.05929)
*Sidney Shapiro,Burhanuddin Panvelwala*

Main category: cs.LG

TL;DR: 该论文评估了Meta开发的Prophet开源预测框架在提高预测可复现性方面的作用，通过与ARIMA和随机森林的对比分析，展示了Prophet在可解释性、标准化工作流程和可访问性方面的优势。


<details>
  <summary>Details</summary>
Motivation: 预测研究中的可复现性挑战，特别是在商业和金融分析领域。传统方法需要大量手动调优且难以在专有环境中复现，而机器学习方法虽然灵活但存在可解释性和随机训练过程的问题。

Method: 使用公开的金融和零售数据集，在控制且完全记录实验设计的条件下，比较Prophet与多种ARIMA规格（自动选择、手动指定和季节性变体）以及随机森林的性能和可解释性。

Result: Prophet通过其加法结构、开源实现和标准化工作流程，在透明和可复现的预测实践中表现出优势，支持验证、可审计性和方法严谨性。

Conclusion: Prophet作为可复现研究的方法构建块，为基于Python的研究工作流程中的可复现预测提供了实用的参考框架。

Abstract: Reproducibility remains a persistent challenge in forecasting research and practice, particularly in business and financial analytics where forecasts inform high-stakes decisions. Traditional forecasting methods, while theoretically interpretable, often require extensive manual tuning and are difficult to replicate in proprietary environments. Machine learning approaches offer predictive flexibility but introduce challenges related to interpretability, stochastic training procedures, and cross-environment reproducibility. This paper examines Prophet, an open-source forecasting framework developed by Meta, as a reproducibility-enabling solution that balances interpretability, standardized workflows, and accessibility. Rather than proposing a new algorithm, this study evaluates how Prophet's additive structure, open-source implementation, and standardized workflow contribute to transparent and replicable forecasting practice. Using publicly available financial and retail datasets, we compare Prophet's performance and interpretability with multiple ARIMA specifications (auto-selected, manually specified, and seasonal variants) and Random Forest under a controlled and fully documented experimental design. This multi-model comparison provides a robust assessment of Prophet's relative performance and reproducibility advantages. Through concrete Python examples, we demonstrate how Prophet facilitates efficient forecasting workflows and integration with analytical pipelines. The study positions Prophet within the broader context of reproducible research. It highlights Prophet's role as a methodological building block that supports verification, auditability, and methodological rigor. This work provides researchers and practitioners with a practical reference framework for reproducible forecasting in Python-based research workflows.

</details>


### [105] [On the Robustness of Age for Learning-Based Wireless Scheduling in Unknown Environments](https://arxiv.org/abs/2601.05956)
*Juaren Steiger,Bin Li*

Main category: cs.LG

TL;DR: 本文提出了一种基于头部年龄（head-of-line age）的无线调度策略，解决了传统虚拟队列方法在信道条件突变时队列长度无限增长的问题。


<details>
  <summary>Details</summary>
Motivation: 传统约束组合多臂赌博机模型使用虚拟队列长度来跟踪吞吐量约束违反，但在信道条件突变时约束可能变得不可行，导致虚拟队列长度无限增长。

Method: 设计了一种学习型调度策略，用头部年龄（虚拟队列中最老数据包的年龄）替代虚拟队列长度，使算法在信道条件突变时更加鲁棒。

Result: 在独立同分布网络条件下，该策略达到了最先进性能；在信道条件突变时系统保持稳定，并能快速从约束不可行期恢复。

Conclusion: 头部年龄比虚拟队列长度更适合用于算法设计，特别是在网络条件动态变化的环境中，能够提供更好的稳定性和恢复能力。

Abstract: The constrained combinatorial multi-armed bandit model has been widely employed to solve problems in wireless networking and related areas, including the problem of wireless scheduling for throughput optimization under unknown channel conditions. Most work in this area uses an algorithm design strategy that combines a bandit learning algorithm with the virtual queue technique to track the throughput constraint violation. These algorithms seek to minimize the virtual queue length in their algorithm design. However, in networks where channel conditions change abruptly, the resulting constraints may become infeasible, leading to unbounded growth in virtual queue lengths. In this paper, we make the key observation that the dynamics of the head-of-line age, i.e. the age of the oldest packet in the virtual queue, make it more robust when used in algorithm design compared to the virtual queue length. We therefore design a learning-based scheduling policy that uses the head-of-line age in place of the virtual queue length. We show that our policy matches state-of-the-art performance under i.i.d. network conditions. Crucially, we also show that the system remains stable even under abrupt changes in channel conditions and can rapidly recover from periods of constraint infeasibility.

</details>


### [106] [Community-Based Model Sharing and Generalisation: Anomaly Detection in IoT Temperature Sensor Networks](https://arxiv.org/abs/2601.05984)
*Sahibzada Saadoon Hammad,Joaquín Huerta Guijarro,Francisco Ramos,Michael Gould Carlson,Sergio Trilles Oliver*

Main category: cs.LG

TL;DR: 该论文提出了基于社区兴趣(CoI)范式的物联网传感器网络异常检测框架，通过融合时间相关性、空间邻近性和高程相似性将传感器分组，使用自编码器和贝叶斯超参数优化进行异常检测。


<details>
  <summary>Details</summary>
Motivation: 物联网设备的大规模部署产生了大量异构传感器网络，需要有效的方法来组织这些网络并检测异常。社区兴趣(CoI)范式为组织异构物联网传感器网络提供了有前景的方法。

Method: 1. 使用融合相似性矩阵将传感器分组到社区（包含Spearman系数的时间相关性、高斯距离衰减的空间邻近性、高程相似性）
2. 为每个社区选择基于最佳轮廓的代表性站点
3. 使用三种自编码器架构（BiLSTM、LSTM、MLP）进行训练
4. 采用贝叶斯超参数优化和扩展窗口交叉验证
5. 通过重构误差分析检测异常

Result: 实验结果显示在评估配置中社区内性能稳健，但不同社区之间存在性能差异。基于社区的模型共享在减少计算开销方面具有适用性。

Conclusion: 该框架支持基于社区的模型共享在物联网传感器网络中的应用，能够有效减少计算开销并分析模型在不同网络间的泛化能力。

Abstract: The rapid deployment of Internet of Things (IoT) devices has led to large-scale sensor networks that monitor environmental and urban phenomena in real time. Communities of Interest (CoIs) provide a promising paradigm for organising heterogeneous IoT sensor networks by grouping devices with similar operational and environmental characteristics. This work presents an anomaly detection framework based on the CoI paradigm by grouping sensors into communities using a fused similarity matrix that incorporates temporal correlations via Spearman coefficients, spatial proximity using Gaussian distance decay, and elevation similarities. For each community, representative stations based on the best silhouette are selected and three autoencoder architectures (BiLSTM, LSTM, and MLP) are trained using Bayesian hyperparameter optimization with expanding window cross-validation and tested on stations from the same cluster and the best representative stations of other clusters. The models are trained on normal temperature patterns of the data and anomalies are detected through reconstruction error analysis. Experimental results show a robust within-community performance across the evaluated configurations, while variations across communities are observed. Overall, the results support the applicability of community-based model sharing in reducing computational overhead and to analyse model generalisability across IoT sensor networks.

</details>


### [107] [LookAroundNet: Extending Temporal Context with Transformers for Clinically Viable EEG Seizure Detection](https://arxiv.org/abs/2601.06016)
*Þór Sverrisson,Steinn Guðmundsson*

Main category: cs.LG

TL;DR: LookAroundNet是一个基于transformer的癫痫检测器，通过使用更宽的时间窗口来建模癫痫活动，结合EEG信号前后文信息，在多个数据集上表现出色且具有良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 由于癫痫活动在不同患者、记录条件和临床环境中的巨大变异性，自动癫痫检测仍然具有挑战性。需要开发能够利用更广泛时间上下文的方法。

Method: 提出LookAroundNet transformer模型，使用EEG信号前后时间段的数据来建模癫痫活动，模仿临床医生解读EEG时的上下文分析方法。通过模型集成和多样化训练数据提升性能。

Result: 在包括常规临床EEG和长期动态记录在内的多个数据集上评估，LookAroundNet表现出强大的性能，能够很好地泛化到未见过的记录条件，计算成本适合临床部署。

Conclusion: 扩展的时间上下文、增加训练数据多样性和模型集成是提高性能的关键因素，这项工作推动了自动癫痫检测模型向临床可行解决方案的发展。

Abstract: Automated seizure detection from electroencephalography (EEG) remains difficult due to the large variability of seizure dynamics across patients, recording conditions, and clinical settings. We introduce LookAroundNet, a transformer-based seizure detector that uses a wider temporal window of EEG data to model seizure activity. The seizure detector incorporates EEG signals before and after the segment of interest, reflecting how clinicians use surrounding context when interpreting EEG recordings. We evaluate the proposed method on multiple EEG datasets spanning diverse clinical environments, patient populations, and recording modalities, including routine clinical EEG and long-term ambulatory recordings, in order to study performance across varying data distributions. The evaluation includes publicly available datasets as well as a large proprietary collection of home EEG recordings, providing complementary views of controlled clinical data and unconstrained home-monitoring conditions. Our results show that LookAroundNet achieves strong performance across datasets, generalizes well to previously unseen recording conditions, and operates with computational costs compatible with real-world clinical deployment. The results indicate that extended temporal context, increased training data diversity, and model ensembling are key factors for improving performance. This work contributes to moving automatic seizure detection models toward clinically viable solutions.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [108] [Intent at a Glance: Gaze-Guided Robotic Manipulation via Foundation Models](https://arxiv.org/abs/2601.05336)
*Tracey Yee Hsin Tay,Xu Yan,Jonathan Ouyang,Daniel Wu,William Jiang,Jonathan Kao,Yuchen Cui*

Main category: cs.RO

TL;DR: GAMMA系统利用眼动追踪和视觉语言模型，通过注视点推断用户意图，实现机器人自主操作，无需任务特定训练即可完成技能选择和参数化。


<details>
  <summary>Details</summary>
Motivation: 设计直观的机器人控制界面是促进人机交互的关键挑战，特别是在辅助护理场景中。眼动作为一种快速、非侵入性且富含意图的输入方式，是传达用户目标的有吸引力的渠道。

Method: GAMMA系统结合自我中心眼动追踪和视觉语言模型，将注视点置于场景上下文中，将视觉注意映射到高级语义理解，实现技能选择和参数化。

Result: 在桌面操作任务上的评估显示，GAMMA相比无推理的基线眼动控制方法，提供了更鲁棒、直观和可泛化的控制。

Conclusion: 结合基础模型和眼动技术，为自然且可扩展的机器人自主性提供了潜力。

Abstract: Designing intuitive interfaces for robotic control remains a central challenge in enabling effective human-robot interaction, particularly in assistive care settings. Eye gaze offers a fast, non-intrusive, and intent-rich input modality, making it an attractive channel for conveying user goals. In this work, we present GAMMA (Gaze Assisted Manipulation for Modular Autonomy), a system that leverages ego-centric gaze tracking and a vision-language model to infer user intent and autonomously execute robotic manipulation tasks. By contextualizing gaze fixations within the scene, the system maps visual attention to high-level semantic understanding, enabling skill selection and parameterization without task-specific training. We evaluate GAMMA on a range of table-top manipulation tasks and compare it against baseline gaze-based control without reasoning. Results demonstrate that GAMMA provides robust, intuitive, and generalizable control, highlighting the potential of combining foundation models and gaze for natural and scalable robot autonomy. Project website: https://gamma0.vercel.app/

</details>


### [109] [PRISM: Protocol Refinement through Intelligent Simulation Modeling](https://arxiv.org/abs/2601.05356)
*Brian Hsu,Priyanka V Setty,Rory M Butler,Ryan Lewis,Casey Stone,Rebecca Weinberg,Thomas Brettin,Rick Stevens,Ian Foster,Arvind Ramanathan*

Main category: cs.RO

TL;DR: PRISM框架通过语言模型代理自动化实验协议的设计、验证和执行，实现自主实验室的协议生成与机器人执行的无缝衔接


<details>
  <summary>Details</summary>
Motivation: 解决实验协议设计和执行自动化这一实现自主实验室的关键瓶颈问题

Method: 使用基于语言模型的代理系统，通过规划、批判和验证循环将网络实验流程转换为结构化步骤，并转换为Argonne MADSci协议格式协调多机器人设备

Result: 在Luna qPCR扩增和Cell Painting案例中验证了PRISM作为端到端工作流的可行性，通过NVIDIA Omniverse数字孪生环境检测物理或序列错误

Conclusion: PRISM是一个实用的端到端工作流，成功连接了基于语言的协议生成、基于仿真的验证和自动化机器人执行

Abstract: Automating experimental protocol design and execution remains as a fundamental bottleneck in realizing self-driving laboratories. We introduce PRISM (Protocol Refinement through Intelligent Simulation Modeling), a framework that automates the design, validation, and execution of experimental protocols on a laboratory platform composed of off-the-shelf robotic instruments. PRISM uses a set of language-model-based agents that work together to generate and refine experimental steps. The process begins with automatically gathering relevant procedures from web-based sources describing experimental workflows. These are converted into structured experimental steps (e.g., liquid handling steps, deck layout and other related operations) through a planning, critique, and validation loop. The finalized steps are translated into the Argonne MADSci protocol format, which provides a unified interface for coordinating multiple robotic instruments (Opentrons OT-2 liquid handler, PF400 arm, Azenta plate sealer and peeler) without requiring human intervention between steps. To evaluate protocol-generation performance, we benchmarked both single reasoning models and multi-agent workflow across constrained and open-ended prompting paradigms. The resulting protocols were validated in a digital-twin environment built in NVIDIA Omniverse to detect physical or sequencing errors before execution. Using Luna qPCR amplification and Cell Painting as case studies, we demonstrate PRISM as a practical end-to-end workflow that bridges language-based protocol generation, simulation-based validation, and automated robotic execution.

</details>


### [110] [Assembling Solar Panels by Dual Robot Arms Towards Full Autonomous Lunar Base Construction](https://arxiv.org/abs/2601.05491)
*Luca Nunziante,Kentaro Uno,Gustavo H. Diaz,Shreya Santra,Alessandro De Luca,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 本文提出了一种用于月球基地太阳能板模块自主组装的双臂机器人系统，整合了视觉、控制和硬件系统，成功实现了任意位置面板的连接。


<details>
  <summary>Details</summary>
Motivation: 随着人类重返月球的计划，需要建立月球前哨站，其中太阳能发电塔等基础设施的自主组装至关重要。类似于国际空间站的建造方式，通过模块化运输和现场组装是实用方案。

Method: 设计了专门用于太阳能板模块组装的感知和控制流程，开发了专用硬件并在真实实验中测试。使用模块化太阳能板模拟件和主动-被动连接器，将抓取夹具的控制集成到流程中。

Result: 实验证明，两个机器人操纵器能够有效连接任意放置的面板，展示了视觉、控制和硬件系统在复杂空间应用中的无缝集成。

Conclusion: 该方法成功实现了太阳能板模块的自主组装，为未来月球基础设施的机器人建设提供了可行的技术方案。

Abstract: Since the successful Apollo program, humanity is once again aiming to return to the Moon for scientific discovery, resource mining, and inhabitation. Upcoming decades focus on building a lunar outpost, with robotic systems playing a crucial role to safely and efficiently establish essential infrastructure such as solar power generating towers. Similar to the construction of the International Space Station (ISS), shipping necessary components via modules and assembling them in situ should be a practical scenario. In this context, this paper focuses on the integration of vision, control, and hardware systems within an autonomous sequence for a dual-arm robot system. We explore a perception and control pipeline specifically designed for assembling solar panel modules, one of the benchmark tasks. Ad hoc hardware was designed and tested in real-world experiments. A mock-up of modular solar panels and active-passive connectors are employed, with the control of this grappling fixture integrated into the proposed pipeline. The successful implementation of our method demonstrates that the two robot manipulators can effectively connect arbitrarily placed panels, highlighting the seamless integration of vision, control, and hardware systems in complex space applications.

</details>


### [111] [TOSC: Task-Oriented Shape Completion for Open-World Dexterous Grasp Generation from Partial Point Clouds](https://arxiv.org/abs/2601.05499)
*Weishang Wu,Yifei Shi,Zhiping Cai*

Main category: cs.RO

TL;DR: 本文提出了一种任务导向的形状补全方法FlowGrasp，专注于补全潜在接触区域而非整个形状，通过预训练基础模型生成候选方案，使用3D判别自编码器优化，最终实现任务导向的灵巧抓取。


<details>
  <summary>Details</summary>
Motivation: 解决严重部分观测下机器人抓取中由于缺失数据导致通用形状补全失效的问题，强调抓取任务的形状补全应明确受下游操作任务指导。

Method: 1. 利用预训练基础模型生成多个任务导向形状补全候选；2. 提出3D判别自编码器评估候选合理性并全局优化；3. 开发条件流匹配模型FlowGrasp从优化形状生成任务导向灵巧抓取。

Result: 在任务导向灵巧抓取和形状补全上达到SOTA，抓取位移和Chamfer距离分别提升16.17%和55.26%，对严重缺失数据物体抓取表现良好，具有优秀的开放集类别和任务泛化能力。

Conclusion: 该方法通过任务导向的形状补全有效解决了部分观测下的灵巧抓取问题，展示了在开放世界物体操作中的实用性和泛化性。

Abstract: Task-oriented dexterous grasping remains challenging in robotic manipulations of open-world objects under severe partial observation, where significant missing data invalidates generic shape completion. In this paper, to overcome this limitation, we study Task-Oriented Shape Completion, a new task that focuses on completing the potential contact regions rather than the entire shape. We argue that shape completion for grasping should be explicitly guided by the downstream manipulation task. To achieve this, we first generate multiple task-oriented shape completion candidates by leveraging the zero-shot capabilities of object functional understanding from several pre-trained foundation models. A 3D discriminative autoencoder is then proposed to evaluate the plausibility of each generated candidate and optimize the most plausible one from a global perspective. A conditional flow-matching model named FlowGrasp is developed to generate task-oriented dexterous grasps from the optimized shape. Our method achieves state-of-the-art performance in task-oriented dexterous grasping and task-oriented shape completion, improving the Grasp Displacement and the Chamfer Distance over the state-of-the-art by 16.17\% and 55.26%, respectively. In particular, it shows good capabilities in grasping objects with severe missing data. It also demonstrates good generality in handling open-set categories and tasks.

</details>


### [112] [Learning specifications for reactive synthesis with safety constraints](https://arxiv.org/abs/2601.05533)
*Kandai Watanabe,Nicholas Renninger,Sriram Sankaranarayanan,Morteza Lahijanian*

Main category: cs.RO

TL;DR: 本文提出了一种从演示中学习的新方法，使机器人能够在动态环境中自主执行复杂任务。该方法通过概率形式语言建模潜在任务，并结合安全约束学习和反应式合成框架来平衡机器人成本与用户任务偏好。


<details>
  <summary>Details</summary>
Motivation: 当前机器人学习系统在动态环境中执行复杂任务时面临安全约束和用户偏好平衡的挑战。需要一种能够同时保证安全性、学习任务规范并优化成本-偏好权衡的方法。

Method: 1. 将潜在任务建模为概率形式语言；2. 使用改进的证据驱动状态合并算法学习概率确定性有限自动机（PDFA）；3. 在整个学习过程中融入安全约束；4. 提出多目标反应式合成算法生成确定性策略；5. 将交互建模为机器人与环境的双人博弈；6. 使用可计算的值迭代算法生成帕累托前沿。

Result: 实验结果表明，该方法在各种机器人和任务中均有效：学习的PDFA从不包含不安全行为，合成的策略始终能够完成任务，同时满足机器人成本和用户偏好要求。

Conclusion: 该方法成功实现了在动态环境中安全、有效地学习复杂任务规范并生成优化策略的目标，为机器人自主执行任务提供了可靠的解决方案。

Abstract: This paper presents a novel approach to learning from demonstration that enables robots to autonomously execute complex tasks in dynamic environments. We model latent tasks as probabilistic formal languages and introduce a tailored reactive synthesis framework that balances robot costs with user task preferences. Our methodology focuses on safety-constrained learning and inferring formal task specifications as Probabilistic Deterministic Finite Automata (PDFA). We adapt existing evidence-driven state merging algorithms and incorporate safety requirements throughout the learning process to ensure that the learned PDFA always complies with safety constraints. Furthermore, we introduce a multi-objective reactive synthesis algorithm that generates deterministic strategies that are guaranteed to satisfy the PDFA task while optimizing the trade-offs between user preferences and robot costs, resulting in a Pareto front of optimal solutions. Our approach models the interaction as a two-player game between the robot and the environment, accounting for dynamic changes. We present a computationally-tractable value iteration algorithm to generate the Pareto front and the corresponding deterministic strategies. Comprehensive experimental results demonstrate the effectiveness of our algorithms across various robots and tasks, showing that the learned PDFA never includes unsafe behaviors and that synthesized strategies consistently achieve the task while meeting both the robot cost and user-preference requirements.

</details>


### [113] [EvoQRE: Modeling Bounded Rationality in Safety-Critical Traffic Simulation via Evolutionary Quantal Response Equilibrium](https://arxiv.org/abs/2601.05653)
*Phu-Hoa Pham,Chi-Nguyen Tran,Duy-Minh Dao-Sy,Phu-Quy Nguyen-Lam,Trung-Kiet Huynh*

Main category: cs.RO

TL;DR: EvoQRE是一个基于量子响应均衡和演化博弈动力学的交通仿真框架，用于模拟人类驾驶员的有限理性行为，在安全关键交通场景中实现更真实的行为建模。


<details>
  <summary>Details</summary>
Motivation: 现有交通仿真框架假设完美理性智能体，但人类驾驶员实际上存在认知和感知约束下的有限理性决策行为，需要更准确的建模方法。

Method: 结合预训练生成世界模型与熵正则化复制器动力学，通过量子响应均衡和演化博弈理论建模人类驾驶行为，并扩展到连续动作空间。

Result: 在Waymo Open Motion Dataset和nuPlan基准测试中，EvoQRE实现了最先进的真实性、改进的安全指标，并通过可解释的理性参数生成多样化的安全关键场景。

Conclusion: EvoQRE为安全关键交通交互提供了理论严谨且实用的建模框架，能够更准确地捕捉人类驾驶员的有限理性行为特征。

Abstract: Existing traffic simulation frameworks for autonomous vehicles typically rely on imitation learning or game-theoretic approaches that solve for Nash or coarse correlated equilibria, implicitly assuming perfectly rational agents. However, human drivers exhibit bounded rationality, making approximately optimal decisions under cognitive and perceptual constraints. We propose EvoQRE, a principled framework for modeling safety-critical traffic interactions as general-sum Markov games solved via Quantal Response Equilibrium (QRE) and evolutionary game dynamics. EvoQRE integrates a pre-trained generative world model with entropy-regularized replicator dynamics, capturing stochastic human behavior while maintaining equilibrium structure. We provide rigorous theoretical results, proving that the proposed dynamics converge to Logit-QRE under a two-timescale stochastic approximation with an explicit convergence rate of O(log k / k^{1/3}) under weak monotonicity assumptions. We further extend QRE to continuous action spaces using mixture-based and energy-based policy representations. Experiments on the Waymo Open Motion Dataset and nuPlan benchmark demonstrate that EvoQRE achieves state-of-the-art realism, improved safety metrics, and controllable generation of diverse safety-critical scenarios through interpretable rationality parameters.

</details>


### [114] [Motion Compensation for Real Time Ultrasound Scanning in Robotically Assisted Prostate Biopsy Procedures](https://arxiv.org/abs/2601.05661)
*Matija Markulin,Luka Matijević,Luka Siktar,Janko Jurdana,Branimir Caran,Marko Švaco,Filip Šuligoj,Bojan Šekoranja*

Main category: cs.RO

TL;DR: 开发了一种用于前列腺超声检查的机器人辅助系统，能够在患者移动时保持超声探头与前列腺的相对位置恒定，实现快速准确的前列腺3D重建，为活检规划提供支持。


<details>
  <summary>Details</summary>
Motivation: 前列腺癌诊断活检需要高度专业的外科医生，结果依赖操作者水平。开发机器人系统可降低操作难度，实现更快、更准确、更可及的前列腺活检。

Method: 使用协作机器人臂自主扫描前列腺模型，通过运动补偿保持超声探头与前列腺相对位置恒定。对每个切片进行分割生成前列腺轮廓，转换为3D点云用于活检规划。

Result: 平均扫描时间30秒，3D重建时间3秒。在四种运动场景下，ICP配准显示平均83.2%拟合度和0.35mm RMSE（水平运动），84.1%拟合度和0.37mm RMSE（垂直运动），79.4%拟合度和0.37mm RMSE（复合运动）。最大跟踪误差3mm，运动补偿延迟0.5秒。

Conclusion: 该系统能够有效补偿患者运动，实现稳定的前列腺3D重建，跟踪精度满足活检要求，为前列腺活检提供了可靠的技术支持。

Abstract: Prostate cancer is one of the most common types of cancer in men. Its diagnosis by biopsy requires a high level of expertise and precision from the surgeon, so the results are highly operator-dependent. The aim of this work is to develop a robotic system for assisted ultrasound (US) examination of the prostate, a prebiopsy step that could reduce the dexterity requirements and enable faster, more accurate and more available prostate biopsy. We developed and validated a laboratory setup with a collaborative robotic arm that can autonomously scan a prostate phantom and attached the phantom to a medical robotic arm that mimics the patient's movements. The scanning robot keeps the relative position of the US probe and the prostate constant, ensuring a consistent and robust approach to reconstructing the prostate. To reconstruct the prostate, each slice is segmented to generate a series of prostate contours converted into a 3D point cloud used for biopsy planning. The average scan time of the prostate was 30 s, and the average 3D reconstruction of the prostate took 3 s. We performed four motion scenarios: the phantom was scanned in a stationary state (S), with horizontal motion (H), with vertical motion (V), and with a combination of the two (C). System validation is performed by registering the prostate point cloud reconstructions acquired during different motions (H, V, C) with those obtained in the stationary state. ICP registration with a threshold of 0.8 mm yields mean 83.2\% fitness and 0.35 mm RMSE for S-H registration, 84.1\% fitness and 0.37 mm RMSE for S-V registration and 79.4\% fitness and 0.37 mm RMSE for S-C registration. Due to the elastic and soft material properties of the prostate phantom, the maximum robot tracking error was 3 mm, which can be sufficient for prostate biopsy according to medical literature. The maximum delay in motion compensation was 0.5 s.

</details>


### [115] [InsSo3D: Inertial Navigation System and 3D Sonar SLAM for turbid environment inspection](https://arxiv.org/abs/2601.05805)
*Simon Archieri,Ahmet Cinar,Shu Pan,Jonatan Scharff Willners,Michele Grimald,Ignacio Carlucho,Yvan Petillot*

Main category: cs.RO

TL;DR: InsSo3D是一种基于3D声纳和惯性导航系统的大规模3D SLAM方法，能够有效解决传统声纳缺乏高程信息的问题，在浑浊水域实现高精度定位和建图


<details>
  <summary>Details</summary>
Motivation: 传统声纳只能生成2D图像，缺乏高程信息，存在高程模糊问题。3D声纳能够生成3D点云但需要有效的SLAM框架来处理数据漂移

Method: 开发了适应3D声纳数据的鲁棒SLAM框架，利用INS作为先验信息，检测闭环并进行位姿图优化

Result: 在50分钟任务中平均轨迹误差低于21cm，生成10m×20m地图的平均重建误差为9cm，有效校正了里程计漂移

Conclusion: InsSo3D能够在浑浊水域条件下安全检查自然或人工水下结构，证明了其在复杂水下环境中的有效性

Abstract: This paper presents InsSo3D, an accurate and efficient method for large-scale 3D Simultaneous Localisation and Mapping (SLAM) using a 3D Sonar and an Inertial Navigation System (INS). Unlike traditional sonar, which produces 2D images containing range and azimuth information but lacks elevation information, 3D Sonar produces a 3D point cloud, which therefore does not suffer from elevation ambiguity. We introduce a robust and modern SLAM framework adapted to the 3D Sonar data using INS as prior, detecting loop closure and performing pose graph optimisation. We evaluated InsSo3D performance inside a test tank with access to ground truth data and in an outdoor flooded quarry. Comparisons to reference trajectories and maps obtained from an underwater motion tracking system and visual Structure From Motion (SFM) demonstrate that InsSo3D efficiently corrects odometry drift. The average trajectory error is below 21cm during a 50-minute-long mission, producing a map of 10m by 20m with a 9cm average reconstruction error, enabling safe inspection of natural or artificial underwater structures even in murky water conditions.

</details>


### [116] [Modular Autonomy with Conversational Interaction: An LLM-driven Framework for Decision Making in Autonomous Driving](https://arxiv.org/abs/2601.05806)
*Marvin Seegert,Korbinian Moller,Johannes Betz*

Main category: cs.RO

TL;DR: 本文提出了一个将大型语言模型与自动驾驶系统集成的框架，通过领域特定语言实现自然语言指令到结构化动作的映射，并包含安全验证层以确保执行可靠性。


<details>
  <summary>Details</summary>
Motivation: 利用LLMs为自动驾驶系统创建自然语言界面，解决人类语言复杂性到结构化动作空间的映射挑战，超越传统刚性输入方式。

Method: 采用三组件方法：交互分类法、面向应用的领域特定语言（DSL）用于指令翻译、安全保护验证层；使用两阶段LLM架构确保高透明度。

Result: 评估证实系统具有时间效率和翻译鲁棒性，仿真成功验证了所有五个交互类别的指令执行。

Conclusion: 该工作为模块化和安全意识的自主堆栈中可扩展的DSL辅助交互奠定了基础。

Abstract: Recent advancements in Large Language Models (LLMs) offer new opportunities to create natural language interfaces for Autonomous Driving Systems (ADSs), moving beyond rigid inputs. This paper addresses the challenge of mapping the complexity of human language to the structured action space of modular ADS software. We propose a framework that integrates an LLM-based interaction layer with Autoware, a widely used open-source software. This system enables passengers to issue high-level commands, from querying status information to modifying driving behavior. Our methodology is grounded in three key components: a taxonomization of interaction categories, an application-centric Domain Specific Language (DSL) for command translation, and a safety-preserving validation layer. A two-stage LLM architecture ensures high transparency by providing feedback based on the definitive execution status. Evaluation confirms the system's timing efficiency and translation robustness. Simulation successfully validated command execution across all five interaction categories. This work provides a foundation for extensible, DSL-assisted interaction in modular and safety-conscious autonomy stacks.

</details>


### [117] [Intelligent Singularity Avoidance in UR10 Robotic Arm Path Planning Using Hybrid Fuzzy Logic and Reinforcement Learning](https://arxiv.org/abs/2601.05836)
*Sheng-Kai Chen,Jyh-Horng Wu*

Main category: cs.RO

TL;DR: 本文提出了一种结合模糊逻辑安全系统和强化学习算法的综合方法，用于UR10机械臂路径规划中的奇异性检测与规避。


<details>
  <summary>Details</summary>
Motivation: 解决机器人操作中的奇异性问题，避免控制失效和设备损坏。

Method: 集成实时奇异性检测（使用可操作性度量、条件数分析）和模糊逻辑决策，结合稳定的强化学习框架进行自适应路径规划。

Result: 实验结果显示，在保持与奇异构型安全距离的同时，达到目标位置的成功率为90%。

Conclusion: 该系统通过PyBullet仿真进行训练数据收集，并通过URSim连接实现实际部署，验证了方法的有效性。

Abstract: This paper presents a comprehensive approach to singularity detection and avoidance in UR10 robotic arm path planning through the integration of fuzzy logic safety systems and reinforcement learning algorithms. The proposed system addresses critical challenges in robotic manipulation where singularities can cause loss of control and potential equipment damage. Our hybrid approach combines real-time singularity detection using manipulability measures, condition number analysis, and fuzzy logic decision-making with a stable reinforcement learning framework for adaptive path planning. Experimental results demonstrate a 90% success rate in reaching target positions while maintaining safe distances from singular configurations. The system integrates PyBullet simulation for training data collection and URSim connectivity for real-world deployment.

</details>
